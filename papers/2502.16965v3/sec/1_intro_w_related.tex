\section{Introduction}
\vspace{-1mm}
Large language models (LLMs) have a significant impact on the field of artificial intelligence, changing approaches to addressing traditional challenges in natural language processing and machine learning~\cite{achiam2023gpt,touvron2023llama}. Recently, in the field of image generation, there has been widespread attention on autoregressive (AR) image generation based on the LLMs.
For example, LlamaGen~\cite{sun2024autoregressive} employs the AR model based on the `next-token prediction' paradigm of large language models for image generation, which reduces the inductive biases on visual signals. Under this design, LlamaGen has demonstrated comparable results to popular diffusion-based image generation models~\cite{peebles2023scalable,rombach2022high}, which shows that the AR model can serve as the foundation for advanced image generation systems.

\begin{figure}[t]
  \centering
  % \fbox{\rule{0pt}{2in} \rule{0.9\linewidth}{0pt}}
   \includegraphics[width=0.9\linewidth]{fig/teaser2.pdf}
   \caption{Illustration of the prompt engineering for AR model. The grey module represents prompts. (a) Prompt engineering utilizes designed prompts to perform text tasks. (c) Vision Full-view (VF) Prompt incorporates image-related prompts to perform image generation tasks.}
  % \caption{Illustration of the reasoning process based on LLMs. The grey circles represent reasoning prompts. (a) General AR model reasoning process. (b) Vision Full-view (VF) Prompt incorporates image-related thought prompts to perform image generation tasks.}
   \label{teaser}
\end{figure}
\vspace{-1mm} 
However, directly applying LLMs to the image generation task, which is much more complex than the text generation task, could result in the model struggling to reconstruct the structure and details of the image, thus affecting the accuracy of the generated results and the stability of the generation process. 
Additionally, when humans perceive complex visual information, they typically scan the entire image before focusing on the target. In contrast,  the `next-token prediction' paradigm in AR image generation does not align with the contextual sequence and logical reasoning required for real image generation.

% In the field of natural language processing (NLP), one of the most distinguishing abilities of LLMs is the exceptional reasoning capabilities, with Chain-of-Thought prompting (CoT)~\cite{wei2022chain} serving as a key technique.
% In the field of natural language processing (NLP), prompt engineering is a series of techniques that utilize specific designed prompts to enhance the model's generative ability, such as Chain-of-Thought prompting (CoT)~\cite{wei2022chain} and In-Context Learning (ICL) ~\cite{min2022rethinkingroledemonstrationsmakes}.
% Compared to the general AR model reasoning process in Fig.~\ref{teaser} (a), prompt engineering (Fig.~\ref{teaser} (b)) leverages intermediate reasoning prompts to guide the model, achieving significant performance improvements in complex tasks such as arithmetic, commonsense reasoning, and symbolic inference. This structured reasoning approach enhances the stability of the reasoning process and reduces errors caused by the complexity of the task.
% Moreover, prompt engineering enables the model to reason and solve problems more like humans by incorporating intermediate reasoning prompts, allowing the model to maintain contextual coherence and logical consistency throughout the reasoning process.
In the field of natural language processing (NLP), prompt engineering is a series of techniques that utilize specific designed prompts to enhance the model's generative ability~\cite{sahoo2024systematic,chen2023unleashing,vatsal2024survey}.
As shown in Fig.~\ref{teaser} (a), compared to the general AR model process, prompt engineering leverages specific designed prompts to guide the model, achieving significant performance improvements in complex tasks such as arithmetic, code generation, and knowledge-intensive question answering. 
% 一方面，Prompt 通过提供清晰丰富的指导输入信息，使 LLM 在训练时减少目标函数漂移，增强训练的稳定；在推理时减少输入变异带来的不确定性，增强推理的稳定性。
% 另一方面，Prompt 通过增加逻辑引导的输入，让模型更加模拟人类方式解决问题，从而增强推理过程的连贯性，减少错误推理路径，提高答案的解释性和可靠性。
On the one hand, prompt engineering provides clearer and more informative guidance, reducing objective function drift during training and enhancing training stability. During inference, it reduces uncertainties caused by input, thereby improving the stability of model predictions.
On the other hand, prompt engineering introduces logical guidance and in-context information for input, enabling the model to better simulate human problem-solving approaches. This enhances the coherence of the reasoning process, reduces erroneous reasoning paths, and improves the interpretability and reliability of generated answers.


% Despite differing in task formulation from the logical reasoning tasks commonly encountered in NLP-based LLMs, AR image generation can be attributed to a similar organized structure, where each subtask is solved based on the state of the previous one. 
% As a result, autoregressive image generation also has the powerful reasoning capabilities of LLMs.
% Therefore, inspired by prompt engineering from the field of NLP, to enhance the ability of LLMs to handle complex image generation tasks, we propose autoregressive Vision Full-view (VF) Prompt based on the AR model by adding intermediate reasoning prompts for image generation, without modifying any model structure or the autoregressive raster generation order, which is shown in Fig.~\ref{teaser} (c). Our method improves both the accuracy and stability of the generation and strengthens the logical generation capabilities of the images. 
% Specifically, we design specialized image-related reasoning prompts for AR image generation as the intermediate reasoning process, simulating the human reasoning process by allowing the model to first perceive overall distribution information (such as the universal distribution of the image dataset or the overall distribution information of a specific category) before generating the image. The reasoning prompt enhances contextual reasoning of generation, and also improves stability during the generation process by increasing the inference step.
% Specifically, we design specialized reasoning prompts for AR image generation as the intermediate reasoning process, allowing the model to first perceive overall distribution information (such as the universal distribution of image dataset or the overall distribution information of a specific category) before generating the image. The designed reasoning prompt containing overall distribution information, simulates the human reasoning process by allowing the model to first perceive the overall distribution before generating a specific image, which enhances contextual reasoning of generation, while also improves stability during the generation process by increasing the inference step.
Despite differing in task formulation from the logical reasoning tasks commonly encountered in NLP-based LLMs, AR image generation can be attributed to a similar organized structure, where each subtask is solved based on the state of the previous one. 
% As a result, AR image generation can also benefit from techniques proven effective in NLP, such as prompt engineering.
%
% Therefore, inspired by prompt engineering from the field of NLP, to handle complex image generation tasks, we propose a Vision Full-view (VF) prompt based on the AR model, which guides the model to grasp the overall visual information before progressively refine local details during generation, as illustrated in Fig.~\ref{teaser} (b). 
% VF prompt does not require modifying the model structure or the autoregressive raster generation order.
% VF prompt improves both the accuracy and stability of the generation and strengthens the logical generation capabilities of the images. 
%
% Specifically, we design specialized VF prompt obtained for AR image generation, simulating the human reasoning process by allowing the model to first perceive overall distribution information (such as the universal distribution of the image dataset or representative full-view visual patterns from a specific category) before generating the image. 
% The VF prompt enhances contextual reasoning of generation, and also improves stability during the generation process by increasing the inference step. Compared to the AR method without prompts, our method shows outstanding performance and achieves an approximate improvement of 20\%.
% Despite differing in task formulation from the logical reasoning tasks commonly encountered in NLP-based LLMs, AR image generation can be attributed to a similar organized structure, where each subtask is solved based on the state of the previous one. 
% As a result, AR image generation can also benefit from techniques proven effective in NLP, such as prompt engineering.
%
Therefore, inspired by prompt engineering from the field of NLP, to handle complex image generation tasks, we propose a Vision Full-view (VF) prompt based on the AR model, which guides the model to grasp the overall visual information before progressively genrate local details during generation, as illustrated in Fig.~\ref{teaser} (b). 
% VF prompt improves both the accuracy and stability of the generation and strengthens the logical generation capabilities of the images. 
%
% Specifically, the specialized VF prompt designed for AR image generation mimics the human process of creating images by guiding the model to first perceive global distribution information, such as
% the universal characteristics of the entire image dataset or representative visual patterns from a specific category
% the universal distribution of the entire image dataset or representative full-view visual patterns from a specific category, before the AR model sequentially generates smaller-scale image regions. 
Specifically, we design specialized VF prompt obtained for AR image generation, simulating the human process of creating images by guiding the model to first perceive vision full-view information (such as the universal distribution of the image dataset or representative full-view visual patterns from a specific category) before generating the image. 
Therefore, the VF prompt enhances the contextual logical capability of the model and improves generation stability by increasing inference steps. Experimental results demonstrate that our method significantly outperforms the baseline AR method without prompts, achieving an approximate performance improvement of 20\%.

% Our contributions are as follows:
% \begin{enumerate}
% \item We propose the Vision Full-view (VF) Prompt to address issues of training instability and inconsistency with human perception in AR image generation. 
% \item We design specialized image-related  prompts for AR image generation as the intermediate  process, allowing the model to first perceive overall distribution information before generating the image, which enhances contextual  of generation, and also improves stability during the generation process by increasing the inference step.
% \item  Compared to the AR method without prompts, our method shows outstanding performance and achieves an approximate improvement of 20\%.
% \end{enumerate}

\section{Related Work}
\subsection{Autoregressive Visual Generation Methods}
Visual generation has received significant attention in recent years, especially with the development of deep learning architectures and generative models. 
One key trend is the use of autoregressive models, which show significant generality and potential due to their strong connection with NLP. However, there is no mature or well-established community, and further efforts are needed to overcome challenges and fully realize their capabilities.
Existing autoregressive generation methods are commonly divided into two approaches: BERT-style mask autoregressive models and GPT-style autoregressive models. 
Mask Autoregressive methods~\cite{chang2022maskgit,yu2023magvit,li2023mage,li2024autoregressive}, inspired by BERT-style pre-training~\cite{kenton2019bert}, generate images by predicting the random masked tokens. Instead, another kind of autoregressive method~\cite{esser2021taming,yu2021vector,ramesh2021zero}, inspired by GPT~\cite{radford2018improving}, predicts the next token in a sequence, which applies the image tokenization~\cite{kingma2013auto,van2017neural} to transform images to discrete space. Recently, based on autoregressive methods, LlamaGen~\cite{sun2024autoregressive} adapts large language model architectures like Llama~\cite{touvron2023llama}, to autoregressively predict image tokens by applying the `next-token prediction' paradigm to visual generation, which achieves decent performance in image generation.


\subsection{Other Visual Generation Methods}
In addition to AR visual generation methods, significant efforts have also been made in exploring other forms of visual generation models.
Generative Adversarial Networks (GANs) are the earliest approaches, leveraging adversarial training to generate images~\cite{goodfellow2014generative,brock2018large,kang2023scaling,sauer2022stylegan,karras2019style}.
Diffusion models, an alternative approach, generates images by gradually refining random noise through a series of learned steps~\cite{song2019generative,song2020denoising,dhariwal2021diffusion,ho2022cascaded,rombach2022high,peebles2023scalable}. GANs-based and diffusion-based methods show promising performance because their community are relatively complete. If AR models are to surpass them, further iterations and development of AR models are needed.


\subsection{Prompt Engineering for LLMs}
Prompt engineering, a critical methodology for optimizing interactions with large language models (LLMs), strategically designs structured instructions to guide models toward high-quality outputs. Previous research has extensively explored various prompting strategies. For example, Zero-shot prompting~\cite{radford2019language} guides the model to complete a task solely through task descriptions, relying on its pre-trained knowledge for reasoning and generation. Few-shot prompting~\cite{brown2020language} provides a small number of examples in addition to the task description, helping the model learn task patterns and improving its performance on specific tasks. Chain-of-Thought (CoT) prompting~\cite{wei2022chain,lyu2023faithful, ye2024diffusion} enhances performance in complex tasks such as mathematics and logical reasoning by instructing the model to generate a step-by-step reasoning process (\textit{e.g.}, `Let's think step by step'). In-context Learning (ICL) prompting~\cite{min2022rethinkingroledemonstrationsmakes,dong2024surveyincontextlearning,pan2023incontextlearninglearnsincontext} enables LLMs to learn task patterns directly from the provided context during inference by including task examples or relevant information in the input, eliminating the need for model parameter updates.
Retrieval-Augmented Generation (RAG)~\cite{lewis2020retrieval,yao2023react} combines information retrieval systems to dynamically fetch external knowledge during inference. This approach allows the model to generate more factually accurate responses and reduces hallucinations.

The reasons why prompt engineering achieves excellent success in the LLM are as follows. First, it refines input instructions to establish a more structured and consistent learning signal, thereby mitigating shifts in the objective function during training and improving overall model stability. Additionally, during inference, it helps reduce variability caused by input fluctuations, thereby improving the stability of model predictions.
Second, prompt engineering introduces logical guidance and in-context information directly into the input enabling the model to align more closely with human-like problem-solving strategies, improving the fluency and coherence of generated responses while minimizing logical inconsistencies and hallucinations.
% Prompt engineering enhances LLM performance by refining input instructions for a structured learning signal, improving training stability, and reducing inference variability. It also integrates logical guidance and in-context information, aligning models with human problem-solving, enhancing fluency and coherence, and minimizing inconsistencies and hallucinations.
Based on these two reasons, we apply prompt engineering to autoregressive (AR) image generation to address issues of training instability and inconsistency with human perception in AR image generation. 

% Central to this paradigm are two pivotal techniques: In-context Learning (ICL)~\cite{min2022rethinkingroledemonstrationsmakes} and Chain-of-Thought (CoT)~\cite{wei2022chain} reasoning, which collectively address the limitations of conventional prompting approaches while leveraging the emerging capabilities of LLMs.

% ICL revolutionizes model adaptation by dynamically conditioning LLMs through task-specific demonstrations embedded within prompts. Unlike traditional fine-tuning, ICL eliminates the need for parameter updates, instead enabling models to infer patterns, task formats, and desired behaviors from carefully curated examples~\cite{min2022rethinkingroledemonstrationsmakes,dong2024surveyincontextlearning,pan2023incontextlearninglearnsincontext}. This paradigm capitalizes on LLMs' inherent ability to recognize and extrapolate latent structures from context, achieving remarkable few-shot performance across diverse domains ranging from text classification to code generation.

% CoT reasoning introduces a breakthrough for multi-step cognitive tasks. While early prompting methods~\cite{brown2020language} struggled with logical coherence in complex reasoning, CoT decomposes problems into intermediate reasoning steps, mimicking human progressive cognition~\cite{wei2022chain}. By integrating cognitive science principles~\cite{cobbe2021training,ling2017program}, CoT prompts LLMs to generate self-contained rationales before concluding final answers, resolving the "reasoning shortcuts" prevalent in traditional approaches. This stepwise verification mechanism not only enhances arithmetic, symbolic, and commonsense reasoning accuracy but also improves output interpretability through transparent logical pathways.

% Large language models (LLMs) exhibit impressive reasoning capabilities due to advanced language generation abilities. Chain-of-Thought (CoT), as a key technique, is specifically designed for multi-step reasoning~\cite{wei2022chain}. Traditional prompting methods~\cite{brown2020language} have shown limited effectiveness on complex tasks that require reasoning capabilities. Inspired by the concept of using intermediate steps to address reasoning problems~\cite{cobbe2021training,ling2017program}, CoT simulates the human process of reasoning and problem-solving by incorporating intermediate reasoning prompts, allowing the model to maintain contextual coherence and logical consistency during the reasoning process~\cite{wei2022chain}. CoT has been shown to significantly enhance the performance of LLMs on complex tasks, while also improving the stability of the reasoning process~\cite{wei2022chain}.

% Chain-of-Thought has been applied to many different tasks, including natural language processing~\cite{lyu2023faithful,wang2022self,yao2024tree,ye2024diffusion} and multi-modal large language models~\cite{zhang2023multimodal,mondal2024kam,mu2024embodiedgpt}. To the best of our knowledge, in the field of AR image generation, the capabilities of CoT have not yet been explored, which can provide the intermediate reasoning process for complex image generation tasks, to enhance image generation capabilities, strengthen the logical generation of images, and improve the stability of generation.





