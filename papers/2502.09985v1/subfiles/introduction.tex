% !TEX root = ../ICML.tex

\section{Introduction}

Conformal Prediction (CP) \citep{vovk2005algorithmic} has recently been considered as one of the state-of-art technique to construct distribution-free prediction sets satisfying probabilistic coverage guarantees. Formally, consider a random variable $(X,Y)\in\calX \times \calY$ and some coverage level $\alpha\in[0,1]$, CP techniques construct a set-valued function $C:\calX \rightarrow 2^\calY$ such that: 
%
\begin{equation}
    \label{eq:conform-obj}
    \IP(Y\in C(X)) \geq 1-\alpha\;.
\end{equation}
%
This is particularly useful when the user prefers to be confident with the range of values that $Y$ can take, rather than having only a single predicted scalar value. In Section~\ref{sec:conform-background}, we give a short reminder on CP, and on the most important techniques to construct $C$ satisfying Eq.~\eqref{eq:conform-obj}. While these techniques are completely distribution-free, making them quite powerful in practice, they still suffer from an important limitation: how can we be sure that the trivial prediction set $C(x) = \calY$ is not returned? Indeed, this prediction set necessarily satisfy the condition \eqref{eq:conform-obj}. To prevent this, theoretical analyses of CP methods typically include an upper-bound on the probability of coverage $\IP(Y\in C(X))$. Such upper-bound tends to $1-\alpha$ as the number of sample used to build $C$ grows, which somehow reflects that the prediction set cannot be the full support of $Y$. However, this is still insufficient as one may take $C(x) = \calY$ with probability $1-\alpha$ and $C(x) = \emptyset$ with probability $\alpha$, resulting in a coverage exactly equal to $1-\alpha$, but with an expected size of $(1-\alpha)|\calY|$. Here, $|\calY|$ denotes the size of $\calY$ and will typically be infinite in regression settings where $\calY=\IR$. Such a set is too large and therefore highly uninformative. Hence, the CP literature suggests to also look at the size of the predicted sets to measure the performance of CP methods. The smaller is a prediction set, the more \textit{efficient} it is considered. However, most works do this analysis empirically, while very few has been focusing on the statistical control of the size of CP sets. \looseness = -1

%For all these reasons, 
In this paper, we therefore propose to study when $C(x)$ is in fact a solution of an optimization problem of the form:
%
%\begin{align}
%    \min_{C_\alpha} &\; \IE[\mu(C_\alpha (X))] \label{eq:informal-opt} \\
%     \quad s.t. \quad & \Big\{\IP(Y\in C_\alpha(X)) \geq 1-\alpha\;, \nonumber
%\end{align}
\begin{align}
	&\min_{C} \; \IE[\mu(C(X))] \label{eq:informal-opt} \\
	&\text{s.t.} \quad \IP(Y\in C(X)) \geq 1-\alpha \;, \nonumber
\end{align}
%
where $\mu$ is a measure of the volume of the set $C(x)$, typically the Lebesgue measure in regression problems, or the counting measure in classification. This optimization problem ensures that among all prediction sets $C(x)$ that satisfy the coverage condition~\eqref{eq:conform-obj}, the volume of the returned set is also of minimal size. Looking at problem~\eqref{eq:informal-opt} instead of~\eqref{eq:conform-obj} alone is therefore more meaningful as it encapsulates the two key aspects of CP: coverage and efficiency. %\pie{This problem is therefore what we really want to solve when the goal is to produce meaningful prediction sets with coverage guarantee.}\todo{pas ouf ma phrase mais je pense que c'est important de le dire} %It is therefore quite natural to look at.

\subsection{Main contributions}

\begin{itemize}[leftmargin=*]
    \item After describing the problem in Section~\ref{sec:problem-statement}, in Section~\ref{sec:constant} we restrict the prediction sets to be intervals of constant size, and show in Section~\ref{sec:f-given} that the calibration step of split CP solves an empirical version of problem~\eqref{eq:informal-opt}. This allows us to derive a \textbf{finite-sample bound on the excess volume loss} of the returned prediction set, namely on the volume difference between the learned and the oracle prediction sets.
    %
    \item We then argue that for the learning step to be \emph{efficiency-oriented}, the prediction function should minimize the $(1-\alpha)$-quantile of the absolute error. This motivates~\method, a new split CP approach that finds an empirical minimizer of such quantile. In Theorem~\ref{thme:main-constant}, an \textbf{excess volume bound shows the joint impact of the learning and the calibration step}, supporting the intuition that more data-points should be dedicated to the learning step.
    %
    \item In Section~\ref{sec:adaptive}, we increase the class of prediction sets to intervals with length adaptive to the covariates value, and present~\methodAD, an extension of the previous method. Finally, in Section~\ref{sec:xps}, a set of synthetic data experiments illustrates the empirical performance and the \textbf{robustness of our approaches} on asymmetric and heavy-tailed distributions.
\end{itemize}



