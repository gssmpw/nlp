\definecolor{mygreen}{rgb}{0.173, 0.627, 0.173} 
\definecolor{myorange}{rgb}{1.0, 0.498, 0.055}
\definecolor{myblue}{rgb}{0.122, 0.467, 0.706}
\definecolor{myred}{rgb}{0.839, 0.153, 0.157}
\definecolor{mypurple}{rgb}{0.580, 0.404, 0.741}

\section{Analysis}
\label{sec:analysis}
To further analyze the internal mechanism of the CR of LLMs instead of simply measuring the CR performance of LLMs,
%Benchmarks can measure the CR performance of LLM, 
We try to explore the reasons why most LLMs perform well on original tasks, but only a few models excel at CR tasks. Therefore, we further conduct analytic experiments, including the logit lens~\citep{logitlens}, the neuron activation of LLMs, and analysis on compositional reasoning stages, to explore the reasoning from a more mechanistic and interpretable perspective.
%回顾Method中关于compositional的形式化定义，我们对LLM针对compositional reasoning的推理过程进行形式化定义:

\begin{figure}[h!]
    \centering
    \vskip 0.2in
    \subfigure[Result of Qwen2.5-3B-Instruct]{
        \includegraphics[width=0.3\linewidth]{pics/logit_lens_qwen3b.pdf}
    }
    \subfigure[Result of Qwen2.5-7B-Instruct]{
        \includegraphics[width=0.3\linewidth]{pics/logit_lens_qwen7b.pdf}
    }
    \subfigure[Result of Llama-3.1-8B-Instruct]{
        \includegraphics[width=0.3\linewidth]{pics/logit_lens_llama8b.pdf}
    }
    \caption{The result of logit lens experiments.
The green valid line ``\protect\tikz[baseline] \protect\draw[line width=0.5mm,color=mygreen,yshift=1.2mm] (0,0) -- (0.4,0);'' corresponds to the answer set when encoding 0 words; 
The orange valid line ``\protect\tikz[baseline] \protect\draw[ line width=0.5mm,color=myorange,yshift=1.2mm] (0,0) -- (0.4,0);'' corresponds to the answer set when encoding 3 words;
The blue valid line ``\protect\tikz[baseline] \protect\draw[ line width=0.5mm,color=myblue,yshift=1.2mm] (0,0) -- (0.4,0);'' corresponds to the answer set when encoding 5 words;
The purple dashed line ``\protect\tikz[baseline] \protect\draw[dashed, line width=0.5mm,color=mypurple,yshift=1.2mm] (0,0) -- (0.4,0);'' corresponds to the decoded words set when encoding 3 words;
The red dashed line ``\protect\tikz[baseline] \protect\draw[dashed, line width=0.5mm,color=myred,yshift=1.2mm] (0,0) -- (0.4,0);'' corresponds to the decoded words set when encoding 5 words;}
\label{fig:logit_lens_res}
\vskip -0.2in
\end{figure}


\subsection{Logit Lens}


\begin{table}[h!]
\centering
\caption{Scores of models used in logit lens analysis. We tested these models using 0/3/5 words encoded dataset in the same configuration and methods of the Experiment section.}
\label{tab:scores_logit_lens}
\vskip 0.15in
\resizebox{0.5\linewidth}{!}{%
\begin{tabular}{cccc}
\toprule
\multirow{2}{*}{\textbf{Model}} & \multicolumn{3}{c}{\textbf{MMLU}} \\
\cmidrule{2-4}
 &  \textbf{0} & \textbf{3} & \textbf{5} \\
\midrule
Qwen2.5-3B-Instruct  & 0.722 & 0.305 & 0.266 \\
Qwen2.5-7B-Instruct  & 0.771 & 0.592 & 0.512 \\
Llama-3.1-8B-Instruct & 0.663 & 0.382 & 0.301 \\
\bottomrule
\end{tabular}
}
\vskip -0.1in
\end{table}
Logit lens~\citep{logitlens} is a technique used to interpret the intermediate outputs of language models by mapping hidden states directly to the output vocabulary.
In logit lens analysis experiments, we defined two target sets, $T_1$ and $T_2$. 
$T_1$ consists of the options and content of the answers, while $T_2$ consists of the decoded content from the encoded elements in the question. $T_1=\bigcup\limits_{a\in \mathcal{A}} \sigma(a)$ and $T_2=\bigcup\limits_{w\in \mathcal{E}} \sigma(\mathcal{D}(w))$, where $\mathcal{D}(w)$ denotes the correct decoding process using our codetable. $\mathcal{A}$ denotes the answer set and $\mathcal{E}$ denotes the encoded words set. $\sigma(.)$ denotes the function that transforms the original word into a series of candidate prefix tokens with different tokenization. For example, $\sigma(``water'') = [``wa'', \dots, ``water'']$.

When the question and encoding rules are provided as input to the LLM, we extract the hidden state of the last token $h_{e}$ during the reasoning process and then get the word distribution $p_{e}$ through the word projection. Then, we accumulate the probabilities of all candidate tokens from $T_{1}$ or $T_{2}$ to get the total probability: $p=\sum\limits_{v\in T_{1} \ \text{or} \ v\in T_{2}}\texttt{Softmax}(h_iW_{p})[v]$, where $p$ is denoted as logits lens.

The logit lens result is shown in Figure \ref{fig:logit_lens_res} and the performance of corresponding models is shown in Table \ref{tab:scores_logit_lens}. Through observation and analysis, we reached the following conclusions:

(1) \textbf{Task decomposition and sequential reasoning}. The probability on $ T_1 $ and $ T_2 $ both showed peaks, with the peak for $ T_2 $ occurring earlier than $ T_1 $, which indicates that the model decomposes the compositional problem into a translation problem, an original MMLU problem and then solves them in order.

(2) \textbf{Summary of subtask answers}.We find that there are two peaks on $ T_1 $ and the second peak typically aligns closely with the peak of $ T_2 $ in the last layers. We hypothesize that LLMs tend to summarize the answers of the subtasks to derive the answer of the compositonal quesiton, when providing the final answer to a compositional problem.

\subsection{Neuron Activation Analysis}
Neuron Activation Analysis examines the activation patterns of individual neurons within a language model to understand their specific roles and contributions during the reasoning or prediction process. Specifically, in order to facilitate the division of the token set, this experiment selects base morse as the encoding method.
We categorize the tokens into two sets to conduct Neuron Activation Analysis: 
(1)\textbf{Vocab} contains tokens about the encoding rules (e.g. 'A': '$.-$', 'B': '$-...$',\dots).
(2)\textbf{Encoded} contains encoded tokens of the question (e.g. $..-.|..-|-.|-.-.$ \dots).

We extract the activation values of the neurons in the MLP layers of LLM during reasoning and then normalize them to a range of 0 to 10. 
For each neuron, we examine the activation values of the tokens in the Vocab and Encoded set. 
If the activation value of a token in this range exceeds 7, we classify that neuron as highly activated for this set. 
As shown in the Figure \ref{fig:neuron-level}, we record the number of highly activated neurons of each layer and have following conclusions:


\begin{figure}[h!]
\vskip 0.2in
\begin{center}
\centerline{\includegraphics[width=0.95\textwidth]{pics/neuron-level.pdf}}
\caption{Neuron Activation Analysis:the comparison figure of neuron activation analysis and logit lens on Llama-3.1-8B-Instruct and Qwen2.5-3B-Instruct.}
\label{fig:neuron-level}
\end{center}
\vskip -0.2in
\end{figure}

\begin{table*}[h!]
\centering
\caption{Key tokens, corresponding layers, and their corresponding functions
}
\label{tab:layer_function_table}
\vskip 0.15in
\resizebox{1.0\linewidth}{!}{
\begin{tabular}{ccc}
\toprule
\textbf{Token} & \textbf{Layer} & \textbf{Functions} \\ 
\midrule
createCommand & 6 & Related to the subprocesses in the compositional reasoning process. \\ 
addCriterion & 6 & Related to rules in the reasoning process. \\ 
.GetObject & 2$\sim$5 & Related to capturing key content in the previous layers. \\ 
iteDatabase & 8$\sim$10, 16 & Related to content retrieval, particularly frequent when the original problem is a knowledge-based question. \\ 
Options & 22$\sim$25 & Related to making choices. \\ 
DataExchange & 17$\sim$20 & \makecell{Related to data updates within sub-tasks; these layers are highly sensitive to encoding rules, possibly related to decoding.} \\ 
\bottomrule
\end{tabular}}
\vskip -0.1in
\end{table*}

(1) \textbf{There is a clear nueron activation order in the compositional reasoning}.In the initial layers, both the Vocab and Encoded curves show a brief upward trend, followed by a continuous decline in Encoded curve and a rise and fall in the Vocab curve. This suggests that during the compositional reasoning process, the LLM first focuses on reading the entire question and then shifts its attention to encoding method, decodes the encoded question, and places less focus on the encoding tokens corresponding to already decoded words. Finally, the model concentrates on solving the problem and summarizing the answer. Thereby, When LLMs perform compositional reasoning, neurons exhibit a clear activation sequence corresponding to the order of subtasks.

(2) \textbf{Neuron activation precedes subtasks resolution}. By comparing the logit lens and neuron activation analysis experiments, we observe that in the logit lens, there is a noticeable increase in the decoded words set in the initial layers. Similarly, in the neuron activation analysis, Vocab also shows a significant rise which precedes the increase observed in the Logit Lens. This indicates that, before performing the decoding operation, the LLM first focuses its attention on the encoding rules and uses these rules to decode. Thereby, the activation of neurons helps LLM understand and solve the subtasks during compositional reasoning.

\subsection{Reasoning Stage Analysis}
Reasoning Stage Analysis investigates the sequential steps and intermediate stages a language model goes through during its reasoning process, aiming to identify how the model transitions from input to final output.
To explore the reasoning stages of CR, we extract the top 30 normalized logits and their corresponding tokens for each layer and use \textbf{Explainer LLM} (Doubao-Pro-256K) to explain the functions of each layer. During this process, we divide the reasoning stage according to layer function and identify some key functional tokens that appeared frequently:

\textbf{Layer Functions}.The stages of the compositional reasoning can be summarized as \textbf{Shallow
Reasoning} (layer 1$\sim$11, responsible for task decomposition and information collection), \textbf{Intermediate
Reasoning} (layer 10$\sim$26, responsible for subtask solving)and \textbf{Deep
Reasoning} (layer 18$\sim$31, responsible for Information summarizing and final answer generation). 

\textbf{Functional Tokens}. We find that some tokens appearing in the top 30 logits may be related to the key functions of LLMs during compositional reasoning, which is presented in Table \ref{tab:layer_function_table}. These functional tokens demonstrate that LLMs trigger specific thinking mechanisms when handling complex compositional reasoning tasks, which assist the model in decomposing, processing and summarizing CR tasks and are clearly distributed in specific reasoning stages.