\section{Introduction}
% 衡量组合推理能力的重要性
Compositional reasoning (\textbf{CR}) refers to the ability to break down complex problems into simpler components and then use those components to form new ideas~\citep{hou-etal-2023-towards}.
Existing research works~\citep{wang2024grokked, hou-etal-2023-towards, cheng2024understanding} have pointed out that compositional reasoning plays a key role in the generalization and intelligence emergence of LLMs.
Quantifying the compositional reasoning ability and behavior of LLMs helps reveal how they transfer knowledge and skills from pretraining and alignment data to solve new problems, and uncover patterns of emergent generalization~\citep{Measuring_Massive_Multitask} as the size of LLMs increases.


\begin{figure}[t]
    \centering
    \vskip 0.2in
    \subfigure[Concept of compositional reasoning]{
        \includegraphics[width=0.8\textwidth]{pics/intro/intro-1.pdf}
    }
    \subfigure[Performance gap between original benchmarks and CryptoBench]{
        \includegraphics[width=0.8\textwidth]{pics/intro/intro-2.pdf}
    }
    \caption{(a) shows the concept of compositional reasoning (CR) which involves combining different abilities in one single model run (e.g., A+B) instead of reasoning via individual ability (e.g., A \textbf{or} B). (b) shows the evaluation result of CryptoX. Some LLMs with strong reasoning abilities on the original benchmark have the low-CR abilities on \benchmark{}.}
    \label{fig:concept}
    \vskip -0.2in
\end{figure}

However, existing reasoning-related benchmarks are either tightly coupled with specific domains~\citep{cobbe2021training,hendrycks2021measuring,han2022folio} or pursuing orthogonality of pretraining knowledge~\citep{gui2024logicgame,ma2024kor}.
As a result, despite numerous existing reasoning-related benchmarks, the CR capabilities of LLMs have not been well studied or quantified~\citep{hou-etal-2023-towards}.
Previous research work~\citep{wang2024grokked} emphasizes the importance of CR capabilities by showing how pre-trained models generalize to unseen data processing under toy experiment settings. But these analysis based on toy data suffer from generalizing to LLMs, as the nature of toy data differs significantly from text pretraining data~\citep{ma2024kor}, which exhibit more diverse reasoning patterns.

To address the gap in evaluating CR capabilities, we propose \textbf{\ourmethod{}}\footnote{\url{https://github.com/multimodal-art-projection/CryptoX}}, inspired by cryptographic techniques~\citep{crypto}. 
\ourmethod{} flexibly transforms existing benchmarks into \benchmark{} using \textbf{instruction encryption} and \textbf{instruction transformation}.  
Instruction encryption randomly encodes part of each instruction in the benchmarks using a given codebook.
Instruction transformation defines additional projection rules from the original answer to the \ourmethod{} answer, e.g. the original correct choice answers in MMLU~\citep{MMLU} require an additional Numeric Transformation operation($A \rightarrow 1,B \rightarrow 2
 ,\dots $) to be viewed correct in Crypto-MMLU.
All the additional rules for instruction encryption and transformation are clearly stated in the given concatenated instructions.
By incorporating instruction encryption and instruction transformation, \benchmark{} benchmarks aim to assess LLM's CR capabilities and reveal LLM's inner mechanism of CR in a flexible manner.
We further conduct Mechanistic Interpretability experiments on analysis of LLMs' neuron activation and inner workings via logit lens~\citep{logitlens} to provide more insights about CR behaviour.

Given the results of \benchmark{} and related mechanical interpretability experiments, we share several key insights about LLMs' compositional reasoning: (1) Most existing LLMs have weak CR abilities, and the proposed \benchmark{} can measure the CR ability gap between different LLMs. (2) The CR ability of the model is influenced by various factors, such as model size, architecture, and other relevant factors.
(3) The probing experiments indicate that the LLMs summarize the reasoning results of the subtasks to obtain the answer to the CR problem, emphasizing the importance of the \benchmark{} for evaluating the CR reasoning abilities. (4) The layers of LLMs exhibit a clear hierarchical pattern of executing different subtasks in different layers and then aggregating for compositional reasoning. 

% 本文的贡献如下：
The contributions of this paper are as follows:
\vspace{-10pt}
\begin{itemize}
\item We propose CryptoX, a flexible evaluation method for LLMs' compositional reasoning.
\item We build \benchmark{} and evaluate LLMs' compositional reasoning ability based on it.
\item We reveal the internal mechanism of LLMs' compositional reasoning by analyzing LLMs' neuron activation and inner workings via logit lens.
\end{itemize}