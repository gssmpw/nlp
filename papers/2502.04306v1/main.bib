@inproceedings{hu2024automated,
  title={Automated design of agentic systems},
  author={Hu, Shengran and Lu, Cong and Clune, Jeff},
  booktitle={NeurIPS 2024 Workshop on Open-World Agents},
  year={2024}
}

@article{zhang2024aflow,
  title={Aflow: Automating agentic workflow generation},
  author={Zhang, Jiayi and Xiang, Jinyu and Yu, Zhaoyang and Teng, Fengwei and Chen, Xionghui and Chen, Jiaqi and Zhuge, Mingchen and Cheng, Xin and Hong, Sirui and Wang, Jinlin and others},
  journal={arXiv preprint arXiv:2410.10762},
  year={2024}
}

@article{rafailov2024direct,
  title={Direct preference optimization: Your language model is secretly a reward model},
  author={Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Manning, Christopher D and Ermon, Stefano and Finn, Chelsea},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@article{jiang2024self,
  title={Self-[in] correct: Llms struggle with refining self-generated responses},
  author={Jiang, Dongwei and Zhang, Jingyu and Weller, Orion and Weir, Nathaniel and Van Durme, Benjamin and Khashabi, Daniel},
  journal={arXiv preprint arXiv:2404.04298},
  year={2024}
}

@article{zhu2023fine,
  title={Fine-tuning language models with advantage-induced policy alignment},
  author={Zhu, Banghua and Sharma, Hiteshi and Frujeri, Felipe Vieira and Dong, Shi and Zhu, Chenguang and Jordan, Michael I and Jiao, Jiantao},
  journal={arXiv preprint arXiv:2306.02231},
  year={2023}
}

@article{meng2024simpo,
  title={Simpo: Simple preference optimization with a reference-free reward},
  author={Meng, Yu and Xia, Mengzhou and Chen, Danqi},
  journal={arXiv preprint arXiv:2405.14734},
  year={2024}
}

@article{chen2024preference,
  title={Preference learning algorithms do not learn preference rankings},
  author={Chen, Angelica and Malladi, Sadhika and Zhang, Lily H and Chen, Xinyi and Zhang, Qiuyi and Ranganath, Rajesh and Cho, Kyunghyun},
  journal={arXiv preprint arXiv:2405.19534},
  year={2024}
}

@inproceedings{azar2024general,
  title={A general theoretical paradigm to understand learning from human preferences},
  author={Azar, Mohammad Gheshlaghi and Guo, Zhaohan Daniel and Piot, Bilal and Munos, Remi and Rowland, Mark and Valko, Michal and Calandriello, Daniele},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={4447--4455},
  year={2024},
  organization={PMLR}
}

@inproceedings{park2024disentangling,
  title={Disentangling length from quality in direct preference optimization},
  author={Park, Ryan and Rafailov, Rafael and Ermon, Stefano and Finn, Chelsea},
  booktitle={Findings of the Association for Computational Linguistics (ACL 2024)},
  year={2024}
}


@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

@article{wang2022self,
  title={Self-consistency improves chain of thought reasoning in language models},
  author={Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc and Chi, Ed and Narang, Sharan and Chowdhery, Aakanksha and Zhou, Denny},
  journal={The Eleventh International Conference on Learning Representations},
  year={2022}
}

@article{madaan2024self,
  title={Self-refine: Iterative refinement with self-feedback},
  author={Madaan, Aman and Tandon, Niket and Gupta, Prakhar and Hallinan, Skyler and Gao, Luyu and Wiegreffe, Sarah and Alon, Uri and Dziri, Nouha and Prabhumoye, Shrimai and Yang, Yiming and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{wang2023unleashing,
  title={Unleashing the emergent cognitive synergy in large language models: A task-solving agent through Multi-Persona Self-Collaboration},
  author={Wang, Zhenhailong and Mao, Shaoguang and Wu, Wenshan and Ge, Tao and Wei, Furu and Ji, Heng},
  booktitle={Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)},
  pages={257--279},
  year={2024}
}

@article{zhong2024achieving,
  title={Achieving> 97\% on GSM8K: Deeply understanding the problems makes LLMs perfect reasoners},
  author={Zhong, Qihuang and Wang, Kang and Xu, Ziyang and Liu, Juhua and Ding, Liang and Du, Bo and Tao, Dacheng},
  journal={arXiv preprint arXiv:2404.14963},
  year={2024}
}

@inproceedings{xu2023lemur,
  title={Lemur: Harmonizing natural language and code for language agents},
  author={Xu, Yiheng and Hongjin, SU and Xing, Chen and Mi, Boyu and Liu, Qian and Shi, Weijia and Hui, Binyuan and Zhou, Fan and Liu, Yitao and Xie, Tianbao and others},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024}
}

@article{yang2024supercorrect,
  title={Supercorrect: Supervising and correcting language models with error-driven insights},
  author={Yang, Ling and Yu, Zhaochen and Zhang, Tianjun and Xu, Minkai and Gonzalez, Joseph E and Cui, Bin and Yan, Shuicheng},
  journal={arXiv preprint arXiv:2410.09008},
  year={2024}
}

@article{yang2024buffer,
  title={Buffer of Thoughts: Thought-Augmented reasoning with large language models},
  author={Yang, Ling and Yu, Zhaochen and Zhang, Tianjun and Cao, Shiyi and Xu, Minkai and Zhang, Wentao and Gonzalez, Joseph E and Cui, Bin},
  journal={Advances in Neural Information Processing Systems},
  year={2024}
}

@article{nori2023can,
  title={Can generalist foundation models outcompete special-purpose tuning? case study in medicine},
  author={Nori, Harsha and Lee, Yin Tat and Zhang, Sheng and Carignan, Dean and Edgar, Richard and Fusi, Nicolo and King, Nicholas and Larson, Jonathan and Li, Yuanzhi and Liu, Weishung and others},
  journal={arXiv preprint arXiv:2311.16452},
  year={2023}
}

@article{hong2024data,
  title={Data interpreter: An llm agent for data science},
  author={Hong, Sirui and Lin, Yizhang and Liu, Bang and Liu, Bangbang and Wu, Binhao and Zhang, Ceyao and Wei, Chenxing and Li, Danyang and Chen, Jiaqi and Zhang, Jiayi and others},
  journal={arXiv preprint arXiv:2402.18679},
  year={2024}
}

@article{ridnik2024code,
  title={Code generation with alphacodium: From prompt engineering to flow engineering},
  author={Ridnik, Tal and Kredo, Dedy and Friedman, Itamar},
  journal={arXiv preprint arXiv:2401.08500},
  year={2024}
}

@article{fernando2023promptbreeder,
  title={Promptbreeder: Self-referential self-improvement via prompt evolution},
  author={Fernando, Chrisantha and Banarse, Dylan and Michalewski, Henryk and Osindero, Simon and Rockt{\"a}schel, Tim},
  journal={arXiv preprint arXiv:2309.16797},
  year={2023}
}

@article{yuksekgonul2024textgrad,
  title={TextGrad: Automatic "differentiation" via text},
  author={Yuksekgonul, Mert and Bianchi, Federico and Boen, Joseph and Liu, Sheng and Huang, Zhi and Guestrin, Carlos and Zou, James},
  journal={arXiv preprint arXiv:2406.07496},
  year={2024}
}

@article{yang2023large,
  title={Large language models as optimizers},
  author={Yang, Chengrun and Wang, Xuezhi and Lu, Yifeng and Liu, Hanxiao and Le, Quoc V and Zhou, Denny and Chen, Xinyun},
  journal={arXiv preprint arXiv:2309.03409},
  year={2023}
}

@inproceedings{khattab2024dspy,
  title={DSPy: Compiling declarative language model calls into state-of-the-art pipelines},
  author={Khattab, Omar and Singhvi, Arnav and Maheshwari, Paridhi and Zhang, Zhiyuan and Santhanam, Keshav and Haq, Saiful and Sharma, Ashutosh and Joshi, Thomas T and Moazam, Hanna and Miller, Heather and others},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024}
}

@article{saad2024archon,
  title={Archon: An architecture search framework for inference-time techniques},
  author={Saad-Falcon, Jon and Lafuente, Adrian Gamarra and Natarajan, Shlok and Maru, Nahum and Todorov, Hristo and Guha, Etash and Buchanan, E Kelly and Chen, Mayee and Guha, Neel and R{\'e}, Christopher and others},
  journal={arXiv preprint arXiv:2409.15254},
  year={2024}
}

@article{zhou2024symbolic,
  title={Symbolic learning enables self-evolving agents},
  author={Zhou, Wangchunshu and Ou, Yixin and Ding, Shengwei and Li, Long and Wu, Jialong and Wang, Tiannan and Chen, Jiamin and Wang, Shuai and Xu, Xiaohua and Zhang, Ningyu and others},
  journal={arXiv preprint arXiv:2406.18532},
  year={2024}
}

@article{zhuge2023mindstorms,
  title={Mindstorms in natural language-based societies of mind},
  author={Zhuge, Mingchen and Liu, Haozhe and Faccio, Francesco and Ashley, Dylan R and Csord{\'a}s, R{\'o}bert and Gopalakrishnan, Anand and Hamdi, Abdullah and Hammoud, Hasan Abed Al Kader and Herrmann, Vincent and Irie, Kazuki and others},
  journal={arXiv preprint arXiv:2305.17066},
  year={2023}
}

@article{bradley1952rank,
  title={Rank analysis of incomplete block designs: I. The method of paired comparisons},
  author={Bradley, Ralph Allan and Terry, Milton E},
  journal={Biometrika},
  volume={39},
  number={3/4},
  pages={324--345},
  year={1952},
  publisher={JSTOR}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@article{touvron2023llama,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}

@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@article{anil2023palm,
  title={Palm 2 technical report},
  author={Anil, Rohan and Dai, Andrew M and Firat, Orhan and Johnson, Melvin and Lepikhin, Dmitry and Passos, Alexandre and Shakeri, Siamak and Taropa, Emanuel and Bailey, Paige and Chen, Zhifeng and others},
  journal={arXiv preprint arXiv:2305.10403},
  year={2023}
}

@article{chen2021evaluating,
  title={Evaluating large language models trained on code},
  author={Chen, Mark and Tworek, Jerry and Jun, Heewoo and Yuan, Qiming and Pinto, Henrique Ponde De Oliveira and Kaplan, Jared and Edwards, Harri and Burda, Yuri and Joseph, Nicholas and Brockman, Greg and others},
  journal={arXiv preprint arXiv:2107.03374},
  year={2021}
}

@article{austin2021program,
  title={Program synthesis with large language models},
  author={Austin, Jacob and Odena, Augustus and Nye, Maxwell and Bosma, Maarten and Michalewski, Henryk and Dohan, David and Jiang, Ellen and Cai, Carrie and Terry, Michael and Le, Quoc and others},
  journal={arXiv preprint arXiv:2108.07732},
  year={2021}
}

@article{cobbe2021training,
  title={Training verifiers to solve math word problems},
  author={Cobbe, Karl and Kosaraju, Vineet and Bavarian, Mohammad and Chen, Mark and Jun, Heewoo and Kaiser, Lukasz and Plappert, Matthias and Tworek, Jerry and Hilton, Jacob and Nakano, Reiichiro and others},
  journal={arXiv preprint arXiv:2110.14168},
  year={2021}
}


@inproceedings{dua2019drop,
  author={Dheeru Dua and Yizhong Wang and Pradeep Dasigi and Gabriel Stanovsky and Sameer Singh and Matt Gardner},
  title={  {DROP}: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs},
  booktitle={Proc. of NAACL},
  year={2019}
}



@inproceedings{yang2018hotpotqa,
  title={HotpotQA: A dataset for diverse, explainable multi-hop question answering},
  author={Yang, Zhiyu and Qi, Peng and Zhang, Saizheng and Bengio, Yoshua and Cohen, William W and Salakhutdinov, Ruslan and Manning, Christopher D},
  booktitle={Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  year={2018}
}


@article{shinn2024reflexion,
  title={Reflexion: Language agents with verbal reinforcement learning},
  author={Shinn, Noah and Cassano, Federico and Gopinath, Ashwin and Narasimhan, Karthik and Yao, Shunyu},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{kwon2023efficient,
  title={Efficient memory management for large language model serving with PagedAttention},
  author={Woosuk Kwon and Zhuohan Li and Siyuan Zhuang and Ying Sheng and Lianmin Zheng and Cody Hao Yu and Joseph E. Gonzalez and Hao Zhang and Ion Stoica},
  booktitle={Proceedings of the ACM SIGOPS 29th Symposium on Operating Systems Principles},
  year={2023}
}

@article{chen2023autoagents,
  title={Autoagents: A framework for automatic agent generation},
  author={Chen, Guangyao and Dong, Siwei and Shu, Yu and Zhang, Ge and Sesay, Jaward and Karlsson, B{\"o}rje F and Fu, Jie and Shi, Yemin},
  journal={arXiv preprint arXiv:2309.17288},
  year={2023}
}

@article{li2024autoflow,
  title={Autoflow: Automated workflow generation for large language model agents},
  author={Li, Zelong and Xu, Shuyuan and Mei, Kai and Hua, Wenyue and Rama, Balaji and Raheja, Om and Wang, Hao and Zhu, He and Zhang, Yongfeng},
  journal={arXiv preprint arXiv:2407.12821},
  year={2024}
}

@inproceedings{liu2024dynamic,
  title={A dynamic LLM-powered agent network for task-oriented agent collaboration},
  author={Liu, Zijun and Zhang, Yanzhe and Li, Peng and Liu, Yang and Yang, Diyi},
  booktitle={First Conference on Language Modeling},
  year={2024}
}

@article{song2024adaptive,
  title={Adaptive in-conversation team building for language model agents},
  author={Song, Linxin and Liu, Jiale and Zhang, Jieyu and Zhang, Shaokun and Luo, Ao and Wang, Shijian and Wu, Qingyun and Wang, Chi},
  journal={arXiv preprint arXiv:2405.19425},
  year={2024}
}

@article{zhang2024g,
  title={G-designer: Architecting multi-agent communication topologies via graph neural networks},
  author={Zhang, Guibin and Yue, Yanwei and Sun, Xiangguo and Wan, Guancheng and Yu, Miao and Fang, Junfeng and Wang, Kun and Cheng, Dawei},
  journal={arXiv preprint arXiv:2410.11782},
  year={2024}
}

@article{yang2024qwen2,
  title={Qwen2. 5 technical report},
  author={Yang, An and Yang, Baosong and Zhang, Beichen and Hui, Binyuan and Zheng, Bo and Yu, Bowen and Li, Chengyuan and Liu, Dayiheng and Huang, Fei and Wei, Haoran and others},
  journal={arXiv preprint arXiv:2412.15115},
  year={2024}
}

@article{deepseekai2024deepseekv3technicalreport,
  title={Deepseek-v3 technical report},
  author={Liu, Aixin and Feng, Bei and Xue, Bing and Wang, Bingxuan and Wu, Bochao and Lu, Chengda and Zhao, Chenggang and Deng, Chengqi and Zhang, Chenyu and Ruan, Chong and others},
  journal={arXiv preprint arXiv:2412.19437},
  year={2024}
}




@inproceedings{hu2021lora,
  title={LoRA: Low-Rank Adaptation of Large Language Models},
  author={Hu, Edward J. and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Chen, Weizhu},
  booktitle={International Conference on Learning Representations},
  year={2022}
}


@article{huang2024n+,
  title={The N+ Implementation Details of RLHF with PPO: A Case Study on TL; DR Summarization},
  author={Huang, Shengyi and Noukhovitch, Michael and Hosseini, Arian and Rasul, Kashif and Wang, Weixun and Tunstall, Lewis},
  journal={arXiv preprint arXiv:2403.17031},
  year={2024}
}


@inproceedings{xu2024dpo,
  title={Is DPO Superior to PPO for LLM Alignment? A Comprehensive Study},
  author={Xu, Shusheng and Fu, Wei and Gao, Jiaxuan and Ye, Wenjie and Liu, Weilin and Mei, Zhiyu and Wang, Guangju and Yu, Chao and Wu, Yi},
  booktitle={Proceedings of the 41st International Conference on Machine Learning (ICML)},
  year={2024}
}
