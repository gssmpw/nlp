@book{Alvim20:Book,
	author = {Alvim, M{\'a}rio S. and Chatzikokolakis, Konstantinos and McIver, Annabelle and Morgan, Carroll and Palamidessi, Catuscia and Smith, Geoffrey},
	date-added = {2022-04-29 09:44:15 +1000},
	date-modified = {2022-04-29 09:44:15 +1000},
	hal_id = {hal-01971490},
	hal_version = {v1},
	publisher = {{Springer}},
	title = {{The Science of Quantitative Information Flow}},
	x-int.-audience = {yes},
	x-scientific-popularization = {no},
	x-toappear_pubdate = {yes},
	year = {2020},
	bdsk-url-1 = {https://hal.inria.fr/hal-01971490}}

@article{Canonne_Kamath_Steinke_2022,
	abstractnote = {&amp;lt;p&amp;gt;A key tool for building differentially private systems is adding Gaussian noise to the output of a function evaluated on a sensitive dataset. Unfortunately, using a continuous distribution presents several practical challenges. First and foremost, finite computers cannot exactly represent samples from continuous distributions, and previous work has demonstrated that seemingly innocuous numerical errors can entirely destroy privacy. Moreover, when the underlying data is itself discrete (e.g., population counts), adding continuous noise makes the result less interpretable.&amp;lt;/p&amp;gt; &amp;lt;p&amp;gt;With these shortcomings in mind, we introduce and analyze the discrete Gaussian in the context of differential privacy. Specifically, we theoretically and experimentally show that adding discrete Gaussian noise provides essentially the same privacy and accuracy guarantees as the addition of continuous Gaussian noise. We also present an simple and efficient algorithm for exact sampling from this distribution. This demonstrates its applicability for privately answering counting queries, or more generally, low-sensitivity integer-valued queries.&amp;lt;/p&amp;gt;},
	author = {Canonne, Clement and Kamath, Gautam and Steinke, Thomas},
	doi = {10.29012/jpc.784},
	journal = {Journal of Privacy and Confidentiality},
	month = {Jul.},
	number = {1},
	title = {The Discrete Gaussian for Differential Privacy},
	url = {https://journalprivacyconfidentiality.org/index.php/jpc/article/view/784},
	volume = {12},
	year = {2022},
	bdsk-url-1 = {https://journalprivacyconfidentiality.org/index.php/jpc/article/view/784},
	bdsk-url-2 = {https://doi.org/10.29012/jpc.784}}

@inproceedings{DBLP:conf/uss/Jayaraman019,
	author = {Bargav Jayaraman and David Evans},
	booktitle = {28th {USENIX} Security Symposium, {USENIX} Security 2019, Santa Clara, CA, USA, August 14-16, 2019},
	editor = {Nadia Heninger and Patrick Traynor},
	pages = {1895--1912},
	publisher = {{USENIX} Association},
	title = {Evaluating Differentially Private Machine Learning in Practice},
	year = {2019}}

@article{DBLP:journals/corr/abs-2001-02610,
	author = {Bo Zhao and Konda Reddy Mopuri and Hakan Bilen},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/corr/abs-2001-02610.bib},
	eprint = {2001.02610},
	eprinttype = {arXiv},
	journal = {CoRR},
	timestamp = {Mon, 13 Jan 2020 12:40:17 +0100},
	title = {iDLG: Improved Deep Leakage from Gradients},
	url = {http://arxiv.org/abs/2001.02610},
	volume = {abs/2001.02610},
	year = {2020},
	bdsk-url-1 = {http://arxiv.org/abs/2001.02610}}

@inproceedings{Shahab_ISIT_2020:100rounds,
	author = {Asoodeh, Shahab and Liao, Jiachun and Calmon, Flavio P. and Kosut, Oliver and Sankar, Lalitha},
	booktitle = {2020 IEEE International Symposium on Information Theory (ISIT)},
	doi = {10.1109/ISIT44484.2020.9174015},
	pages = {920-925},
	title = {A Better Bound Gives a Hundred Rounds: Enhanced Privacy Guarantees via f-Divergences},
	year = {2020},
	bdsk-url-1 = {https://doi.org/10.1109/ISIT44484.2020.9174015}}

@inproceedings{Smith09,
	author = {Geoffrey Smith},
	booktitle = {FOSSACS},
	date-added = {2022-05-13 21:50:20 +1000},
	date-modified = {2022-05-13 21:50:20 +1000},
	pages = {288--302},
	publisher = {Springer},
	series = {LNCS},
	title = {On the {F}oundations of {Q}uantitative {I}nformation {F}low},
	volume = {5504},
	year = {2009}}

@inproceedings{abadi-etal:2016:CCS,
	abstract = {Machine learning techniques based on neural networks are achieving remarkable results in a wide variety of domains. Often, the training of models requires large, representative datasets, which may be crowdsourced and contain sensitive information. The models should not expose private information in these datasets. Addressing this goal, we develop new algorithmic techniques for learning and a refined analysis of privacy costs within the framework of differential privacy. Our implementation and experiments demonstrate that we can train deep neural networks with non-convex objectives, under a modest privacy budget, and at a manageable cost in software complexity, training efficiency, and model quality.},
	address = {New York, NY, USA},
	author = {Abadi, Martin and Chu, Andy and Goodfellow, Ian and McMahan, H. Brendan and Mironov, Ilya and Talwar, Kunal and Zhang, Li},
	booktitle = {Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security},
	doi = {10.1145/2976749.2978318},
	isbn = {9781450341394},
	keywords = {deep learning, differential privacy},
	location = {Vienna, Austria},
	numpages = {11},
	pages = {308--318},
	publisher = {Association for Computing Machinery},
	series = {CCS '16},
	title = {Deep Learning with Differential Privacy},
	url = {https://doi.org/10.1145/2976749.2978318},
	year = {2016},
	bdsk-url-1 = {https://doi.org/10.1145/2976749.2978318}}

@inproceedings{balle-etal:2022:IEEE-SP,
	author = {Borja Balle and Giovanni Cherubin and Jamie Hayes},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/conf/sp/BalleCH22.bib},
	booktitle = {43rd {IEEE} Symposium on Security and Privacy, {SP} 2022, San Francisco, CA, USA, May 22-26, 2022},
	doi = {10.1109/SP46214.2022.9833677},
	pages = {1138--1156},
	publisher = {{IEEE}},
	timestamp = {Thu, 21 Sep 2023 15:57:28 +0200},
	title = {Reconstructing Training Data with Informed Adversaries},
	url = {https://doi.org/10.1109/SP46214.2022.9833677},
	year = {2022},
	bdsk-url-1 = {https://doi.org/10.1109/SP46214.2022.9833677}}

@article{balle2018privacy,
	author = {Balle, Borja and Barthe, Gilles and Gaboardi, Marco},
	journal = {Advances in neural information processing systems},
	title = {Privacy amplification by subsampling: Tight analyses via couplings and divergences},
	volume = {31},
	year = {2018}}

@article{cherubinclosed,
	author = {Cherubin, Giovanni and K{\"o}pf, Boris and Paverd, Andrew and Tople, Shruti and Wutschitz, Lukas and Zanella-B{\'e}guelin, Santiago},
	title = {Closed-Form Bounds for DP-SGD against Record-level Inference Attacks}}

@misc{du2024sok,
	archiveprefix = {arXiv},
	author = {Jiacheng Du and Jiahui Hu and Zhibo Wang and Peng Sun and Neil Zhenqiang Gong and Kui Ren},
	eprint = {2404.05403},
	primaryclass = {cs.CR},
	title = {SoK: Gradient Leakage in Federated Learning},
	year = {2024}}

@misc{faustini2023directional,
	archiveprefix = {arXiv},
	author = {Pedro Faustini and Natasha Fernandes and Shakila Tonni and Annabelle McIver and Mark Dras},
	eprint = {2211.04686},
	note = {Accepted for presentation at the 5th AAAI Workshop on Privacy-Preserving Artificial Intelligence},
	primaryclass = {cs.LG},
	title = {Directional Privacy for Deep Learning},
	url = {https://ppai-workshop.github.io/},
	year = {2023},
	bdsk-url-1 = {https://ppai-workshop.github.io/}}

@article{fernandes2022explaining,
	author = {Fernandes, Natasha and McIver, Annabelle and Sadeghi, Parastoo},
	journal = {arXiv preprint arXiv:2210.12916},
	title = {Explaining epsilon in differential privacy through the lens of information theory},
	year = {2022}}

@inproceedings{geiping-etal:2020:NeurIPS,
	author = {Jonas Geiping and Hartmut Bauermeister and Hannah Dr{\"{o}}ge and Michael Moeller},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/conf/nips/GeipingBD020.bib},
	booktitle = {Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual},
	editor = {Hugo Larochelle and Marc'Aurelio Ranzato and Raia Hadsell and Maria{-}Florina Balcan and Hsuan{-}Tien Lin},
	timestamp = {Tue, 19 Jan 2021 15:57:14 +0100},
	title = {Inverting Gradients - How easy is it to break privacy in federated learning?},
	url = {https://proceedings.neurips.cc/paper/2020/hash/c4ede56bbd98819ae6112b20ac6bf145-Abstract.html},
	year = {2020},
	bdsk-url-1 = {https://proceedings.neurips.cc/paper/2020/hash/c4ede56bbd98819ae6112b20ac6bf145-Abstract.html}}

@inproceedings{guo2022bounding,
	author = {Guo, Chuan and Karrer, Brian and Chaudhuri, Kamalika and van der Maaten, Laurens},
	booktitle = {International Conference on Machine Learning},
	organization = {PMLR},
	pages = {8056--8071},
	title = {Bounding training data reconstruction in private (deep) learning},
	year = {2022}}

@inproceedings{hayes2023bounding,
	author = {Jamie Hayes and Borja Balle and Saeed Mahloujifar},
	booktitle = {Thirty-seventh Conference on Neural Information Processing Systems},
	title = {Bounding training data reconstruction in {DP}-{SGD}},
	url = {https://openreview.net/forum?id=7LZ4tZrYlx},
	year = {2023},
	bdsk-url-1 = {https://openreview.net/forum?id=7LZ4tZrYlx}}

@inproceedings{huang-etal:2021:NeurIPS,
	author = {Huang, Yangsibo and Gupta, Samyak and Song, Zhao and Li, Kai and Arora, Sanjeev},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan},
	pages = {7232--7241},
	publisher = {Curran Associates, Inc.},
	title = {Evaluating Gradient Inversion Attacks and Defenses in Federated Learning},
	url = {https://proceedings.neurips.cc/paper_files/paper/2021/file/3b3fff6463464959dcd1b68d0320f781-Paper.pdf},
	volume = {34},
	year = {2021},
	bdsk-url-1 = {https://proceedings.neurips.cc/paper_files/paper/2021/file/3b3fff6463464959dcd1b68d0320f781-Paper.pdf}}

@article{issa2019operational,
	author = {Issa, Ibrahim and Wagner, Aaron B and Kamath, Sudeep},
	date-added = {2022-04-29 09:48:37 +1000},
	date-modified = {2022-04-29 09:48:37 +1000},
	journal = {IEEE Transactions on Information Theory},
	number = {3},
	pages = {1625--1657},
	publisher = {IEEE},
	title = {An operational approach to information leakage},
	volume = {66},
	year = {2020}}

@inproceedings{melis-etal:2019:IEEE-SP,
	author = {Luca Melis and Congzheng Song and Emiliano De Cristofaro and Vitaly Shmatikov},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/conf/sp/MelisSCS19.bib},
	booktitle = {2019 {IEEE} Symposium on Security and Privacy, {SP} 2019, San Francisco, CA, USA, May 19-23, 2019},
	doi = {10.1109/SP.2019.00029},
	pages = {691--706},
	publisher = {{IEEE}},
	timestamp = {Wed, 16 Oct 2019 14:14:51 +0200},
	title = {Exploiting Unintended Feature Leakage in Collaborative Learning},
	url = {https://doi.org/10.1109/SP.2019.00029},
	year = {2019},
	bdsk-url-1 = {https://doi.org/10.1109/SP.2019.00029}}

@article{mironov2019r,
	author = {Mironov, Ilya and Talwar, Kunal and Zhang, Li},
	journal = {arXiv preprint arXiv:1908.10530},
	title = {R$\backslash$'enyi differential privacy of the sampled gaussian mechanism},
	year = {2019}}

@inproceedings{mironov:2017:CSF,
	author = {Ilya Mironov},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/conf/csfw/Mironov17.bib},
	booktitle = {30th {IEEE} Computer Security Foundations Symposium, {CSF} 2017, Santa Barbara, CA, USA, August 21-25, 2017},
	doi = {10.1109/CSF.2017.11},
	pages = {263--275},
	publisher = {{IEEE} Computer Society},
	timestamp = {Wed, 16 Oct 2019 14:14:49 +0200},
	title = {R{\'{e}}nyi Differential Privacy},
	url = {https://doi.org/10.1109/CSF.2017.11},
	year = {2017},
	bdsk-url-1 = {https://doi.org/10.1109/CSF.2017.11}}

@article{sibson1969information,
	author = {Sibson, Robin},
	date-added = {2022-09-03 17:53:54 +1000},
	date-modified = {2022-09-03 17:53:54 +1000},
	journal = {Zeitschrift f{\"u}r Wahrscheinlichkeitstheorie und verwandte Gebiete},
	number = {2},
	pages = {149--160},
	publisher = {Springer},
	title = {Information radius},
	volume = {14},
	year = {1969}}

@inproceedings{wang-etal:2023:AISTATS:reconstructing-provably,
	abstract = {Understanding when and how much a model gradient leaks information about the training sample is an important question in privacy. In this paper, we present a surprising result: Even without training or memorizing the data, we can fully reconstruct the training samples from a single gradient query at a randomly chosen parameter value. We prove the identifiability of the training data under mild assumptions: with shallow or deep neural networks and wide range of activation functions. We also present a statistically and computationally efficient algorithm based on tensor decomposition to reconstruct the training data. As a provable attack that reveals sensitive training data, our findings suggest potential  severe threats to privacy, especially in federated learning.},
	author = {Wang, Zihan and Lee, Jason and Lei, Qi},
	booktitle = {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},
	editor = {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},
	month = {25--27 Apr},
	pages = {6595--6612},
	pdf = {https://proceedings.mlr.press/v206/wang23g/wang23g.pdf},
	publisher = {PMLR},
	series = {Proceedings of Machine Learning Research},
	title = {Reconstructing Training Data from Model Gradient, Provably},
	url = {https://proceedings.mlr.press/v206/wang23g.html},
	volume = {206},
	year = {2023},
	bdsk-url-1 = {https://proceedings.mlr.press/v206/wang23g.html}}

@inproceedings{wang2019subsampled,
	author = {Wang, Yu-Xiang and Balle, Borja and Kasiviswanathan, Shiva Prasad},
	booktitle = {The 22nd International Conference on Artificial Intelligence and Statistics},
	organization = {PMLR},
	pages = {1226--1235},
	title = {Subsampled r{\'e}nyi differential privacy and analytical moments accountant},
	year = {2019}}

@inproceedings{wu-etal:2023:UAI:learning-invert,
	author = {Ruihan Wu and Xiangyu Chen and Chuan Guo and Kilian Q. Weinberger},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/conf/uai/WuCGW23.bib},
	booktitle = {Uncertainty in Artificial Intelligence, {UAI} 2023, July 31 - 4 August 2023, Pittsburgh, PA, {USA}},
	editor = {Robin J. Evans and Ilya Shpitser},
	pages = {2293--2303},
	publisher = {{PMLR}},
	series = {Proceedings of Machine Learning Research},
	timestamp = {Mon, 28 Aug 2023 17:23:08 +0200},
	title = {Learning To Invert: Simple Adaptive Attacks for Gradient Inversion in Federated Learning},
	url = {https://proceedings.mlr.press/v216/wu23a.html},
	volume = {216},
	year = {2023},
	bdsk-url-1 = {https://proceedings.mlr.press/v216/wu23a.html}}

@inproceedings{zhu-etal:2019:NeurIPS,
	author = {Ligeng Zhu and Zhijian Liu and Song Han},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/conf/nips/ZhuLH19.bib},
	booktitle = {Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems 2019, NeurIPS 2019, December 8-14, 2019, Vancouver, BC, Canada},
	editor = {Hanna M. Wallach and Hugo Larochelle and Alina Beygelzimer and Florence d'Alch{\'{e}}{-}Buc and Emily B. Fox and Roman Garnett},
	pages = {14747--14756},
	timestamp = {Mon, 16 May 2022 15:41:51 +0200},
	title = {Deep Leakage from Gradients},
	url = {https://proceedings.neurips.cc/paper/2019/hash/60a6c4002cc7b29142def8871531281a-Abstract.html},
	year = {2019},
	bdsk-url-1 = {https://proceedings.neurips.cc/paper/2019/hash/60a6c4002cc7b29142def8871531281a-Abstract.html}}

@inproceedings{zhu2019poission,
	author = {Zhu, Yuqing and Wang, Yu-Xiang},
	booktitle = {International Conference on Machine Learning},
	organization = {PMLR},
	pages = {7634--7642},
	title = {Poission subsampled r{\'e}nyi differential privacy},
	year = {2019}}

