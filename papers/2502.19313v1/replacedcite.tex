\section{Related Work}
\subsection{V2X Cooperative Perception}

Current research on cooperative perception mainly aims to extend the perception range and improve perception capability of autonomous vehicles~\cite {wang2024emiff,han2023collaborative}. The most intuitive approach is Early Fusion, which transmits raw sensor data____. However, transmitting raw data requires high transmission costs, making it impractical for real-world deployment. Late Fusion that transmits perception results from each agent is the most bandwidth-efficient paradigm____. Yet, its performance relies heavily on the accuracy of each agent's perception result. Most research has shifted toward intermediate fusion, which transmits region-level features for better performance-bandwidth balance____. Although these methods incorporate strategies to reduce transmission costs, such as feature selection via spatial confidence maps____, feature compression____, and flow-based prediction____, region-level feature is still redundant for object detection and lacks interpretability____. QUEST ____ proposes the concept of query-cooperation paradigm but focuses only on a simple V2I scenario involving one vehicle and infrastructure.  To enable more efficient cooperation across multi-agent systems, we propose a unified cooperation perception framework that transmits object-level queries across agents.


\begin{figure*}[t]
	\centering  
	\includegraphics[width=0.9\linewidth]{CoopDETR_Arch.pdf} 
	\caption{The general framework of CoopDETR. For each agent, the query generation module learns $N_q$ object queries from raw data. Each object in the scene will correspond to a query. For the whole multi-agent system, one object may be observed by different agents and be associated with different queries. Take $i$-th agent as ego agent, object queries $Q_{j} = \{q^{j}_{1},\dots,q^{j}_{N_q}\}$ from $j$-th agent and their reference points $r$ will be transmitted to $i$-th agent. In cross-agent query fusion module, all queries will be fused with two steps, the 
 the first step is to associate different queries for co-aware objects through spatial query matching (SQM) and generate object query graph for each object. The second step is to fuse all queries in the same graph using Object Query aggregation (OQA) and generate a set of updated queries $\hat{Q}$, which will be fed to detection heads for category and bounding box prediction. }  
	\label{fig:framework}   
\end{figure*}

\subsection{Transformer-based Perception}
The pioneering work DETR____ regards 2D object detection task as a set-to-set problem. The query mechanism has been increasingly adopted across various perception tasks, including 3D object detection____, object tracking____, semantic segmentatin____, and planning____. Query-based approaches typically leverage sparse, learnable queries for attentive feature aggregation to capture complex relationships among sequential elements. FUTR3D____ predicts 3D query locations and retrieves corresponding multi-modal features from cameras, LiDARs, and radars via projection. BEVFormer____ introduces grid-shaped queries in BEV and updates them by interacting with spatio-temporal features using deformable transformers. While most existing query-based methods focus on individual perception, QUEST____ and TransIFF____ extend it to vehicle-to-infrastructure (V2I) scenarios. In this work, we introduce a novel query fusion mechanism, which facilitates efficient query matching and aggregation tailored for multi-agent systems.