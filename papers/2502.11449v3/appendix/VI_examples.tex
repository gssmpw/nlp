
\begin{example}[Non-Convergence of Gradient Method]\label{example:monotone_non_convergence}
    Consider the VI $(\set, \vioper)$ with $\set \doteq \R^2$ and $\vioper(\var, \othervar) = (-\othervar, \var)$. For this VI, we have $\svi(\set, \vioper) = \mvi(\set, \vioper) = \{ (0, 0) \} $. Suppose that $(\vartuple[][(0)], \othervartuple[][(0)]) \neq (0, 0)$, then for any $\learnrate[ ][ ] > 0$ the iterates generated by the gradient method are given by:
    \begin{align}
        (\var[(\numhorizon)], \othervar[(\numhorizon)]) \doteq \left( \var[(0)] - \learnrate[ ][ ] \sum_{k = 1}^{\numhorizon} \othervar[(k-1)],  \othervar[(0)] + \learnrate[ ][ ] \sum_{k = 1}^{\numhorizon} \var[(k-1)] \right) && \forall \numhorizon \in \N_{++}
    \end{align}
    and as such are unbounded, i.e., $\|(\vartuple[][(\numhorizon)], \othervartuple[][(\numhorizon)]) \| \to \infty$.
\end{example}



\begin{example}[Non-convergence in the absence of the Minty condition]\label{example:non_convergence_non_minty}
    Consider the VI $(\set, \vioper)$ where $\set \doteq \R$ and $\vioper(\var) \doteq 1 - \var[2]$. The set of strong solutions of VI is given by $\svi(\set, \vioper) = \{ -1, 1\}$. Notice that for any any $\var > 1$, $\vioper(\var) < 0$. As such, for the mirror (extra)gradient method, for any choice of step size $\learnrate[ ][ ] > 0$, if the initial iterate is initialized s.t. $\var[(0)] > 1$, then $\var[(0)] \to \infty$.
    % Note that this behavior persists even if one uses higher order information since for any any $\var > 1$, $\vioper^\prime(\var) < 0$. For additional context on variants of the mirror (extra)gradient algorithm, see for instance \citet{huang2022approximation}.
\end{example}