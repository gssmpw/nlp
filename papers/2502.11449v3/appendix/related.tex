\paragraph{Algorithms for Walrasian Economies}
A detailed inquiry into the computational properties of market equilibria was initiated by \citet{devanur2008market}, who studied a special case of the Arrow-Debreu competitive economy known as the \mydef{Fisher market} \cite{brainard2000compute}.
This model, for which Irving Fisher computed equilibrium prices using a hydraulic machine in the 1890s, is essentially the Arrow-Debreu model of a competitive economy, but there are no firms, and buyers are endowed with only one type of commodity---hereafter good%
\footnote{In the context of Fisher markets, commodities are typically referred to as goods \citep{fisher-tatonnement}, as Fisher markets are often analyzed for a single time period only.
More generally, in Arrow-Debreu markets, where commodities vary by time, location, or state of the world, "an apple today" may be different than "an apple tomorrow". For consistency with the literature, we refer to commodities as goods. }---an artificial currency 
%\samy{but we note that}{because this distinction is unnecessary \samy{}{in a single time-period model}.\deni{I feel like this edit is too strong. In particular, a Fisher market is still an arrow-debreu market so you could think of goods as time and space stamped commodities but computer scientists just chose not to because their applications do often not have time and space stamped commodities. The point of the footnote is to say that computer scientists are not being precise but we stick to this terminology for consistency.}}
\cite{brainard2000compute, AGT-book}.
\citet{devanur2002market} exploited a connection first made by \citet{eisenberg1961aggregation} between the \mydef{Eisenberg-Gale program} and Walrasian equilibrium to solve Fisher markets assuming buyers with linear utility functions, thereby providing a (centralized) polynomial-time algorithm for equilibrium computation in these markets~\cite{devanur2002market,devanur2008market}.
Their work was built upon by \citet{jain2005market}, who extended the Eisenberg-Gale program to all Fisher markets in which buyers have \mydef{continuous, quasi-concave, and homogeneous} utility functions, and proved that the equilibrium of Fisher markets with such buyers can be computed in polynomial time by interior point methods. 
% Hereinafter, as is standard in the literature (see e.g., \cite{jain2005market}. functions are cont

Concurrent with this line of work on computing Walrasian equilibrium using centralized methods, a line of work on devising and proving 
% \samy{polynomial-time}{} \amy{maybe you don't want to stress comp'l efficiency until the next paragraph?}
convergence guarantees for price-adjustment processes (i.e., iterative algorithms that update prices according to a predetermined update rule) developed.
% \amy{why is this iterative process decentralized? the description doesn't imply decentralization.} \deni{These price adjustment processes are decentralized in the sense that the adjustment of the price of one good does not depend on the demand or supply of the other goods.} \amy{so it sounds more parallel than decentralized?}
This literature has focused on devising \emph{natural\/} price-adjustment processes, like \emph{t\^atonnement}, which might explain or imitate the movement of prices in real-world markets.
In addition to imitating the law of supply and demand, \emph{t\^atonnement} has been observed to replicate the movement of prices in lab experiments, where participants are given endowments and asked to trade with one another \cite{gillen2020divergence}.
%Beyond interest in understanding the convergence of natural price-adjustment processes for the aforementioned applications,
% \amy{this next sentence does not follow from the lab experiments before it:} 
Perhaps more importantly, the main premise of research on the stability of Walrasian equilibrium in computer science 
% \amy{this literature refers to the lab expts literature, and that is NOT the main premise of the experimental/behavioral literature!}
is that for Walrasian equilibrium to be justified, not only should it be backed by a natural price-adjustment process as economists have long argued, but it should also be computationally efficient \cite{AGT-book}.
% As Kamal Jain put it, ``If your laptop cannot find it, neither can the market'' \cite{AGT-book}.


Another line of work considers price-adjustment processes in variants of Fisher markets.
\citet{cole2008fast} analyzed \emph{t\^atonnement\/} in a real-world-like model satisfying WGS called the ongoing market model.
In this model, \emph{t\^atonnement\/} once-again converges in polynomial-time \cite{cole2008fast, cole2010discrete}, and it has the advantage that it can be seen as an abstraction for market processes.
% \amy{is the reader supposed to know what in-market processes are?}\deni{it's not a really well-defined term, it just means that it is an abstraction of behavior that might occur in real world markets, such as companies storing under sold goods in storage facilities.}\amy{so how about we cross out ``in''? b/c i could imagine what market processes are. but in-market processes sounds like something technical.}
\citeauthor{cole2008fast}'s results were later extended by \citet{cheung2012tatonnement} to ongoing markets with \mydef{weak gross complements}, i.e., the excess demand of any commodity weakly increases if the price of any other commodity weakly decreases, fixing all other prices, and ongoing markets with a mix of WGC and WGS commodities.
The ongoing market model these two papers study contains as a special case the Fisher market; however \citet{cole2008fast} assume bounded own-price elasticity of Marshallian demand, and bounded income elasticity of Marshallian demand, while \citet{cheung2012tatonnement} assume, in addition to \citeauthor{cole2008fast}'s assumptions, bounded adversarial market elasticity, which can be seen as a variant of bounded cross-price elasticity of Marshallian demand, from below.
With these assumptions, these results cover Fisher markets with a small range of the well-known CES utilities, including CES Fisher markets with $\rho \in [0, 1)$ and WGC Fisher markets with $\rho \in (- 1, 0]$.%

\citet{fisher-tatonnement} built on this work by establishing the convergence of \emph{t\^atonnement\/} in polynomial time in nested CES Fisher markets, excluding the limiting cases of linear and Leontief markets, but nonetheless extending polynomial-time convergence guarantees for \emph{t\^atonnement\/} to Leontief Fisher markets as well.
More recently, \citet{cheung2018amortized} showed that \citeauthor{fisher-tatonnement}'s [\citeyear{fisher-tatonnement}] result extends to an asynchronous version of \emph{t\^atonnement}, in which good prices are updated during different time periods. 
In a similar vein, \citet{cheung2019tracing} analyzed \emph{t\^atonnement\/} in online Fisher markets, determining that \emph{t\^atonnement\/} tracks Walrasian equilibrium prices closely provided the market changes slowly.

Another price-adjustment process that has been shown to converge to market equilibria in Fisher markets is \mydef{proportional response dynamics}, first introduced by \citet{first-prop-response} for linear utilities; then expanded upon and shown to converge by \cite{proportional-response} for all CES utilities; and very recently shown to converge in Arrow-Debreu exchange economies with linear and CES ($\rho \in [0,1)$) utilities by \citeauthor{branzei2021proportional}. 
The study of the proportional response process was proven fundamental when \citeauthor{fisher-tatonnement} noticed its relationship to gradient descent.
This discovery opened up a new realm of possibilities in analyzing the convergence of market equilibrium processes.
For example, it allowed \citet{cheung2018dynamics} to generalize the convergence results of proportional response dynamics to Fisher markets for buyers with mixed CES utilities.
This same idea was applied by \citet{fisher-tatonnement} to prove the convergence of \emph{t\^atonnement\/} in Leontief Fisher markets, using the equivalence between mirror descent \cite{boyd2004convex}
on the dual of the Eisenberg-Gale program 
%\sdeni{}{(without explicitly constructing the dual)} %\deni{Are we sure we need a caveat here?} \amy{we are taking the position that no one knew the dual before this paper (although we are not making a big deal about it), so how did they prove this equivalence?} 
and \emph{t\^atonnement}, first observed by \citet{devanur2008market}.
%\amy{didn't one of the reviews say that Devanur was not the first to observe this?}\deni{No, they said that Devanur was the first to observe this.}
% \amy{comment from reviewer: Page 2: Devanur et al. [31] discovered ..." -> It seems this connection was known earlier, e.g., see Eisenberg (1961).}
More recently, \citet{gao2020first} developed 
%first-order 
methods to solve the Eisenberg-Gale convex program in the case of linear, quasi-linear, and Leontief Fisher markets.

An alternative to the (global) competitive economy model, in which an agent's trading partners are unconstrained, is the \citet{kakade2004graphical} model of a graphical economies.
This model features local markets, in which each agent can set its own prices for purchase only by neighboring agents, and likewise can purchase only from neighboring agents. 
Auction-like price-adjustment processes have been shown to converge in variants of this model assuming WGS \cite{andrade2021graphical}.

\paragraph{Algorithms for Variational Inequalities}

Variational inequalities \cite{facchinei2003finite} are a mathematical modeling framework whose study dates back to the early 1960s \cite{lions1967variational, hartman1966some, browder1965nonlinear, grioli1973proprieta, brezis2011methodes}. Their utility lies in their very broad mathematical formulation which allows one to solve other mathematical modeling problems using the tools of functional analysis. They have found a great number of applications to problems in engineering and finance \cite{facchinei2003finite} over the years, and have seen an increased interest due to their novel applications in machine learning, to problems ranging from the training of generative adversarial neural networks \cite{goodfellow2014gan} to robust optimization \cite{ben2009robust}.


Historically, the goal of the literature on solution methods for VIs has been to devise algorithms which are asymptotically guaranteed to converge to a strong or weak solution \cite{brezis2011functional}. An overwhelming majority of these works have focused on first-order methods for computing solutions of VIs, with higher order methods having been considered only in recent years (see, for instance, \citet{he2022convergence, huang2022approximation})
While a strong solution of a VI is guaranteed to exist in continuous VIs, most results on the computational complexity of strong solutions, concerns the class of monotone VIs (see, for instance \citet{cai2022tight}) with a few works focusing on VIs that satisfy the Minty condition (see, for instance, \citet{diakonikolas2020halpern}). 

The canonical algorithm to solve VIs is the projected gradient method \cite{cauchy1847methode, nesterov1998introductory} (also known under the names of the Subgradient method, Gradient Descent Ascent Method or Arrow-Hurwicz-Uzawa method \cite{arrow-hurwicz, arrow1958studies}). While asymptotic convergence of the projected gradient method to a solution can be shown for a subset of monotone VIs known as strongly monotone VIs\footnote{Recall that for monotone VIs, the set of strong and weak solutions are equal, as such here ``solution'' refers to both strong and weak solutions.}, in general monotone VIs, only ergodic asymptotic convergence (i.e., asymptotic convergence of the averaged iterates) to a strong solution can be guaranteed.
The earliest known algorithm with asymptotic convergence guarantees to a solution of a monotone VI, is the extragradient method, attributed to \citet{korpelevich1976extragradient}. Following this earlier success, \citet{popov1980modification} introduced a closely related algorithm called the optimistic gradient method which he also showed to converge to a solution. These initial extragradient and optimistic gradient algorithms would eventually become much more sophisticated with a large body of work appearing on  asymptotic convergence guarantees for variants of these earlier methods (e.g., \cite{solodov1999hybrid}).
of the optimality operator

More recently, the literature has turned its attention to algorithms with non-asymptotic guarantees, and in particular to ones that are guaranteed to compute a $\vepsilon$-strong or $\vepsilon$-weak solution of a VI in polynomial-time, i.e., in a number of evaluations of the optimality operator $\vioperset$ which is polynomial in the inverse of the approximation parameter $\nicefrac{1}{\vepsilon}$, the dimensionality $\spacedim$ of the constraint set, and other relevant assumption specific parameters such as an upper bound on all of the values of the optimality operator. One of the earliest results in this direction was given by \citet{nemirovski2004prox}, who introduced the conceptual mirror-Prox Method, an elegant generalization of the extragradient Method, and established that $\vepsilon$-strong and $\vepsilon$-weak solutions can be computed in $O(\nicefrac{1}{\vepsilon})$ operations by averaging the iterates of the algorithm under the assumption that the the VI is monotone, and the optimality operator is Lipschitz-continuous. \citeauthor{nemirovski2004prox}'s work was subsequently followed by a large body of work on more sophisticated algorithms (e.g., 
\cite{auslender2005interior, diakonikolas2020halpern}) for monotone VIs, and better computational results for the projection method \cite{gidel2018variational}, the extragradient method  \cite{gorbunov2022extragradient, golowich2020tight, cai2022tight} and the optimistic gradient method \cite{gorbunov2022last}.

More recently, a number of works have considered first-order methods to compute a strong solution (e.g., \citet{loizou2021quasiSGDA, he2022convergence, diakonikolas2020halpern}) in VIs or a stationary point of the VI\footnote{A $(\varepsilon, \delta)$ stationary point of a VI $(\set, \vioperset)$ is a point $\vartuple[][*] \in \set$ s.t. for some $\vdelta \geq 0$ there exists $\vartuple \in \ball[\vdelta][{\vartuple[][*]}]$ and $\vartuple$ is a $\vepsilon$-strong solution. Convergence to this weaker solution concept is necessary for VIs in which $\vioperset$ is not singleton-valued for technical reasons, and any future work that seeks to generalize the results in this section should adopt this weaker definition to prove their convergence results.} (e.g., \citet{liu2021first}) that satisfy the Minty condition. The first-order methods considered by this more recent line of work on non-monotone variational inequalities include the extragradient method (e.g., \cite{wang2024extragradient, ofem2023modified}), Tseng's method (e.g., \cite{censor2011strong,thong2020self,uzor2023solving, dung2024convergence,aremu2024modified}), and the optimistic gradient method (e.g., \cite{Lin2022Perseus}) and its variants.



\if 0
\deni{Review}

\begin{definition}[Weakly-Monotone VIs]\label{defn:weakly_monotone_VI}
    A VI $(\set, \vioperset)$ is \mydef{$\wmonotone$-weakly-monotone VI} iff the optimality operator $\vioperset$ is $\wmonotone$-weakly-monotone. 
\end{definition} 

\citet{liu2021first} consider a very large class of continuous VIs in which the optimality operator satisfies weak-monotonicity, and provide non-asymptotic polynomial-time convergence bounds for the \mydef{inexact proximal point method}, an iterative algorithm which at each iteration solves a regularized version of the VI until converence. While these results are positive, at a high-level, the authors' non-asymptotic convergence is not to a $\vepsilon$-strong or $\vepsilon$-weak solution of the VI, but rather, either 1) to a \mydef{$\vepsilon$-stationary point of the VI}, i.e., a point $\vartuple[][*] \in \set$ s.t. for some $\vdelta \geq 0$ there exists $\vartuple \in \ball[\vdelta][{\vartuple[][*]}]$ and $\vartuple$ is a $\vepsilon$-strong solution, or 2) to a distribution over the constraint set $\set$ that in expectation that is a $\vepsilon$-strong solution.
Unfortunately, this computational complexity result can not be translated to a polynomial-time convergence to a $\vepsilon$-strong or $\vepsilon$-weak solution. 
\fi 