\section{Related Works}
Efficient MRTA and path planning are crucial for optimizing order fulfillment, resource management, and obstacle-free navigation in industrial environments such as automated warehouses and manufacturing plants. These processes ultimately enhance overall productivity, which has made MRTA a focal point of research over the past two decades. Research efforts in this area range from heuristic-driven approaches to contemporary learning-based methods~\cite{khamis2015multi}. Early work by~\cite{gerkey2003multi} provided a comparative analysis of state-of-the-art (SOTA) multi-robot coordination strategies within specific domain contexts. Current MRTA research primarily focuses on two key elements: (a) model-driven optimization, as demonstrated by~\cite{wei2020particle}, and (b) communication-efficient decentralized algorithms, as seen in~\cite{chen2021decentralized, agrawal2022dc}.

The problem can also be framed as a multi-agent pickup and delivery (MAPD) challenge, which has been studied through both distributed and centralized approaches~\cite{ma2017lifelong, liu2019task, salzman2020research, xu2022multi}. However, most existing research in this area has concentrated on offline MAPD, whereas our approach emphasizes learning-based methods for online task allocation. This focus is driven by the need for reliable solutions in dynamic environments, where continually solving optimization problems can be computationally intensive.

Recent advancements in reinforcement learning (RL) for solving complex dynamic challenges have led to a trend toward learning-based approaches for managing warehouse complexities~\cite{yang2020multi, agrawal2022dc, agrawal2023rtaw}. These learning strategies address various aspects of end-to-end warehouse management. For instance,~\cite{yang2020multi} proposed a Q-learning framework to generate collision-free, secure paths for multi-robot systems. Conversely, the RL frameworks in~\cite{agrawal2022dc, agrawal2023rtaw} focus on optimal task selection but neglect task-to-robot assignment, assuming constant robot availability post-selection. Additionally, these works leverage $A^*$ coupled with optimal reciprocal collision avoidance~\cite{alonso2013optimal} for collision-free navigation at the low-level path planning stage.

However, as previously discussed, most SOTA learning-based warehouse management approaches, including those mentioned, overlook a key benefit of RL: the ability to integrate multiple levels of warehouse management, and consideration of robots' constraints during the training phase of the RL agent. For instance, the learned policy in~\cite{agrawal2022dc, agrawal2023rtaw} is limited in its applicability to realistic warehouse scenarios due to the neglect of constraints related to robot availability and SOC. Moreover, these approaches often aim for a seamless sequential flow of tasks without considering their generation times. Similarly,~\cite{papoudakis2021benchmarking} utilizes a cooperative multi-agent RL framework under the assumption that robots never collide. Much of the prior work also neglects the complexities of robot dynamics in MRTA for warehouse settings, often simplifying robots to point objects or solving problems in basic square grid environments, without accounting for robot acceleration, deceleration, and collision risks during path planning~\cite{DBLP:conf/ecai/PalCBO24}. %Combining all aspects—task allocation, robot assignment, and the incorporation of robot dynamics for collision-free navigation—creates a complex challenge that is often neglected in previous research.

In our study, we address these gaps by incorporating task arrival times to ensure timely task execution while considering practical factors such as robot availability, SOC, robot dynamics, and collision-free path generation. Our framework also demonstrates robust performance under distribution shifts and with variable-sized fleets. Our \texttt{MRTAgent} addresses these limitations by integrating robot dynamics into the navigation planning process using a linear quadratic regulator (LQR)-based navigation path algorithm within the RL agent framework. This ensures that path planning is both effective and collision-free.  Additionally, we design a reward structure that balances prompt task allocation with the shortest possible execution duration for allocated tasks. This approach ensures competitive runtime during the deployment phase, facilitating real-time task selection and robot allocation, and collision-free navigation considering physical dynamics through proposed \texttt{MRTAgent}.