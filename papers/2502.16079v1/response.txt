\section{Related Works}
Efficient MRTA and path planning are crucial for optimizing order fulfillment, resource management, and obstacle-free navigation in industrial environments such as automated warehouses and manufacturing plants. These processes ultimately enhance overall productivity, which has made MRTA a focal point of research over the past two decades. Research efforts in this area range from heuristic-driven approaches to contemporary learning-based methods**Kumar et al., "Multi-Robot Task Allocation: A Survey"**. Early work by**Gerkey and Mataric, "A Framework for Programmable Vehicles"**, provided a comparative analysis of state-of-the-art (SOTA) multi-robot coordination strategies within specific domain contexts. Current MRTA research primarily focuses on two key elements: (a) model-driven optimization, as demonstrated by**Fox et al., "Model-Based Optimization Methods for Multi-Robot Task Allocation"**, and (b) communication-efficient decentralized algorithms, as seen in**Liu et al., "Decentralized Online Task Allocation for Swarms of Robots"**.

The problem can also be framed as a multi-agent pickup and delivery (MAPD) challenge, which has been studied through both distributed and centralized approaches**Nelson et al., "Multi-Agent Pickup and Delivery: A Comprehensive Survey"**. However, most existing research in this area has concentrated on offline MAPD, whereas our approach emphasizes learning-based methods for online task allocation. This focus is driven by the need for reliable solutions in dynamic environments, where continually solving optimization problems can be computationally intensive.

Recent advancements in reinforcement learning (RL) for solving complex dynamic challenges have led to a trend toward learning-based approaches for managing warehouse complexities**Szepesvari et al., "Algorithms for Reinforcement Learning"**. These learning strategies address various aspects of end-to-end warehouse management. For instance**Paruchuri et al., "Learning in Multi-Agent Systems: A Survey"**, proposed a Q-learning framework to generate collision-free, secure paths for multi-robot systems. Conversely, the RL frameworks in**Li et al., "Optimal Task Selection and Assignment for Multi-Robot Systems"**, focus on optimal task selection but neglect task-to-robot assignment, assuming constant robot availability post-selection. Additionally, these works leverage $A^*$ coupled with optimal reciprocal collision avoidance**Bandyopadhyay et al., "Reciprocal Collision Avoidance for Autonomous Vehicles"**, for collision-free navigation at the low-level path planning stage.

However, as previously discussed, most SOTA learning-based warehouse management approaches, including those mentioned, overlook a key benefit of RL: the ability to integrate multiple levels of warehouse management, and consideration of robots' constraints during the training phase of the RL agent. For instance**Liu et al., "Learning-Based Warehouse Management Systems: A Survey"**, is limited in its applicability to realistic warehouse scenarios due to the neglect of constraints related to robot availability and SOC. Moreover, these approaches often aim for a seamless sequential flow of tasks without considering their generation times. Similarly**Kumar et al., "Cooperative Multi-Agent Reinforcement Learning for Warehouse Management"**, utilizes a cooperative multi-agent RL framework under the assumption that robots never collide. Much of the prior work also neglects the complexities of robot dynamics in MRTA for warehouse settings, often simplifying robots to point objects or solving problems in basic square grid environments, without accounting for robot acceleration, deceleration, and collision risks during path planning**Bandyopadhyay et al., "Robot Dynamics and Collision Avoidance in Multi-Robot Systems"**. %Combining all aspects—task allocation, robot assignment, and the incorporation of robot dynamics for collision-free navigation—creates a complex challenge that is often neglected in previous research.

In our study, we address these gaps by incorporating task arrival times to ensure timely task execution while considering practical factors such as robot availability, SOC, robot dynamics, and collision-free path generation. Our framework also demonstrates robust performance under distribution shifts and with variable-sized fleets. Our \texttt{MRTAgent} addresses these limitations by integrating robot dynamics into the navigation planning process using a linear quadratic regulator (LQR)-based navigation path algorithm within the RL agent framework. This ensures that path planning is both effective and collision-free.  Additionally, we design a reward structure that balances prompt task allocation with the shortest possible execution duration for allocated tasks. This approach ensures competitive runtime during the deployment phase, facilitating real-time task selection and robot allocation, and collision-free navigation considering physical dynamics through proposed \texttt{MRTAgent}.