\section{Appendix} \label{sec:appendix}

\subsection{Implementation Details}

We implement our method using Pytorch, based on the public implementation of RefNeRF~\cite{verbin2022refnerf}. In the iNGP hash grid hierarchy, we use 15 levels (from 32 to 4096) with 4 channels for each level, where each level has 4 channels. Two rounds of proposal sampling are used as in MipNeRF-360~\cite{barron2022mipnerf360}. We also penalize the mean of the sum of squared grid-hash values with a loss multiplier of 0.1. 
Our models are trained on a single A100 GPU for around 2 hours per scene. The code will also be made publically available.

\subsection{Computational requirements}
We require around 30 seconds to render a 500x400 resolution view at inference. This scales linearly with resolution. To perform segmentations and edits as detailed, we require about 60 seconds per frame on average. As for memory, we require an average of ~22GB per scene when considering high-resolution scenes with full-resolution 2D ground views and corresponding semantics. Full per-scene memory requirements will be added in the next revision.


\subsection{Per Scene IOU Results}

In \cref{tab:segmentation_iou_supp}, we provide per-scene and per-object results accompanying Tab.~1 of the main text. As can be seen, our method results in a superior performance, particularly in reflective objects such as the car windshield. 

\input{figures/segmentation/iou_table_supp}

\input{sections/11_figures_only}





\clearpage
