\vspace{-10mm}
\begin{abstract}
\begin{center}
    \textbf{\textcolor{PennRed}{Warning: This paper contains potentially offensive and harmful text.}}
\end{center}


Jailbreak attacks exploit specific prompts to bypass LLM safeguards, causing the LLM to generate harmful, inappropriate, and misaligned content. Current jailbreaking methods rely heavily on carefully designed system prompts and numerous queries to achieve a single successful attack, which is costly and impractical for large-scale red-teaming. To address this challenge, we propose to distill the knowledge of an ensemble of SOTA attackers into a single open-source model, called Knowledge-Distilled Attacker (KDA), which is finetuned to automatically generate coherent and diverse attack prompts without the need for meticulous system prompt engineering. Compared to existing attackers, KDA achieves higher attack success rates and greater cost-time efficiency when targeting multiple SOTA open-source and commercial black-box LLMs. Furthermore, we conducted a quantitative diversity analysis of prompts generated by baseline methods and KDA, identifying diverse and ensemble attacks as key factors behind KDA's effectiveness and efficiency.


% {\color{blue} As large language models (LLMs) become increasingly ubiquitous in today's applications, there is growing need to ensure the alignment of human values in LLMs. Current red-teaming efforts involve developing jailbreak attacks that attempt to bypass LLM safeguards and generate harmful, inappropriate, and misalgined content. Nonetheless, current methods often heavily relies on carefully designed prompts and require a large number of queries to find a single successful attack, making it expensive and sometimes infeasible to up-scale red-teaming efforts in the real-world setting and likely ineffective in the long run. To address these challenges, we propose a Knowledge-Distilled Attacker (KDA) by distilling knowledge from an ensemble of SOTA attackers into a single open-source model. KDA eliminates the need for careful system prompt tuning by being able to generate coherent and diverse attack prompts. Compared to that of existing attackers, our approach demonstrates better attack success rate and cost-time efficiency in attacking multiple SOTA open-source and commercial black-box LLMs, making it scalable to large-scale red-teaming attacks (Buyun: scalable by how much?). Furthermore, we conducted a quantitative and qualitative analysis on the coherence and diversity of attack prompts generated by KDA, highlighting topic diversity and ensembling are key reasons behind KDA's effectiveness and efficiency.}



\end{abstract}


