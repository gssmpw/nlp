
\input{data/harmbench_asr}

% \newpage



\section{Experiments}\label{sec:exp}

% In this section, we present the experiments on comparing our KDA with other SOTA attackers in Section~\ref{sec:jailbreak_performance_comparison}, and pattern analysis  in Section~\ref{sec:large-scale-llm-attack-generation}. We refer the reader to Appendix~\ref{app:transer-attack} for further results and ablation, such as evaluating the transferability of attack prompts and details of the results.




\input{sections/setup}


\subsection{Comprehensive Evaluation}

\subsubsection{Effectiveness Comparison with Harmbench}\label{sec:jailbreak_performance_comparison}

\input{data/sota_comparison_main}

\begin{figure}[h]
% \vspace{-4mm}
\centering
    \includegraphics[width=0.48\textwidth]{data/asr_vs_query_plot.png}
    \vspace{-4mm}
    \caption{
    \textbf{Comparison of ASR vs. target query budget for KDA and SOTA attack methods.} The evaluation is conducted on the Harmful-Behavior dataset~\citep{chao_jailbreaking_2024}. The ASR values in this plot are evaluated using the HB evaluator. Our KDA method employs the format selection strategy $\texttt{trn}$. The curves represent average ASR across different LLM targets, computed over 10,000 bootstrap samples, with shaded regions indicating standard deviations.
    % Comparison of ASR versus target query budget for our KDA and SOTA attack methods across different LLM targets. The reported curves represent averages over 10,000 bootstrap samples, with shaded regions indicating standard deviations.
    }\label{fig:query_efficiency}
   \vspace{-3mm}
\end{figure}


% \begin{figure}[h]
% % \vspace{-4mm}
% \centering
%     \includegraphics[width=0.45\textwidth]{data/asr_tdr_ablation_sota.png}
%     \vspace{-2mm}
%     \caption{\textbf{Ablation study on our KDA single format setting} $\text{KDA}_{\sigma}$ with $\sigma = \{ \text{A},\text{P},\text{G},\text{M}\} $   compared to SOTA baselines AutoDAN, PAIR, and GPTFuzzer. (Top) Attack Success Rate (ASR); (Bottom) Topic Diversity Ratio (TDR). $\text{KDA}_\text{A}$, $\text{KDA}_\text{P}$, and $\text{KDA}_\text{G}$ share the same color scheme as their respective baseline counterparts AutoDAN, PAIR, and GPTFuzzer. The evaluation is conducted on the Harmful-Behavior dataset~\citep{chao_jailbreaking_2024}. Uncertainty is quantified using the standard deviation from 10,000 bootstrap samples drawn with replacement.
%     }\label{fig:asr_tdr_ablation_sota}
%    \vspace{-4mm}
% \end{figure}



First, we conduct an attack performance comparison with SOTA attackers provided in HarmBench~\citep{mazeika_harmbench_2024} and evaluate using the HB evaluator. Results are shown in \autoref{tab:harmbench}. Since the hyperparameters of the SOTA methods in HarmBench are not disclosed, we do not specify the maximum query budget for our baseline methods. For our proposed method KDA, we set the maximum query budget $M=120$ and with the \texttt{uni} format selection strategy. As observed in~\autoref{tab:harmbench}, KDA significantly outperforms most SOTA attackers on both open-source and commercial LLMs, demonstrating the strong effectiveness of our approach. For a detailed analysis of KDA's performance on the Harmbench dataset across different target query budgets and format selection strategies, please refer to~\autoref{app:additional_exp}. 


\subsubsection{Effectiveness and Efficiency Comparison} \autoref{fig:query_efficiency} shows ASR as a function of the increasing target query budget on different target models. We observe that KDA achieves higher ASR compared to SOTA attackers when targeting Llama-2-7B-Chat and GPT-3.5-Turbo, while performing comparably on Vicuna-7B and GPT-4-Turbo. Furthermore, \autoref{tab:harmful_behavior_50_big_table} (Top) provides a more detailed comparison of effectiveness and efficiency using the ASR metric and the average attack time. KDA offers significant improvements over SOTA baselines in both $\text{ASR}^{\text{HB}}_{30}$ and $\text{ASR}^{\text{TM}}_{30}$ compared to all baselines. Given that the HB evaluator is more stringent than TM, KDA's superior performance on $\text{ASR}^{\text{HB}}_{30}$, achieved with significantly lower average attack time $\Bar{t}$, is particularly noteworthy. The reduced average attack time $\Bar{t}$ compared to AutoDAN, GPTFuzzer, and PAIR is primarily due to KDA's ability to achieve successful attacks with fewer queries, highlighting its efficiency advantage. For a detailed analysis of KDA's performance on the Harmful-Behavior dataset across different target query budgets and format selection strategies, please see~\autoref{app:additional_exp}. 


\myparagraph{Generalization to unseen datasets and target models} As discussed in Section~\ref{sec:KDA_training}, KDA is trained on attack prompts generated by SOTA attackers—AutoDAN, PAIR, and GPTFuzzer—targeting Llama-2-7B, Vicuna-7B, GPT-3.5-Turbo, and GPT-4-Turbo on the curated Harmful-100 dataset. The results in~\autoref{tab:harmbench} demonstrate that KDA achieves superior ASR compared to multiple SOTA baseline attackers on the HarmBench~\citep{mazeika_harmbench_2024} dataset, indicating strong generalization to unseen datasets and target models. Furthermore, the superior performance of KDA in terms of effectiveness, efficiency, and diversity, as evaluated on the Harmful-Behavior~\citep{chao_jailbreaking_2024} dataset in~\autoref{tab:harmful_behavior_50_big_table}, further highlights its robust generalization capabilities across different datasets.

% presents the comparison of efficiency and effectiveness, demonstrating that KDA consistently outperforms SOTA baselines in $\text{ASR}^{\text{HB}}_{30}$ and $\text{ASR}^{\text{TM}}_{30}$. Since the HB evaluator is more stringent than TM, KDA's superior performance on $\text{ASR}^{\text{HB}}_{30}$, achieved with significantly lower average attack time, is particularly noteworthy. The reduced average attack time $\Bar{t}$ compared to AutoDAN, GPTFuzzer, and PAIR can be attributed to KDA's capability to achieve successful attacks with fewer queries, highlighting its efficiency advantage.

\subsubsection{Diversity and Coherence Comparison} We measure diversity and coherence using the TDR, TTR, and PPL, as shown in \autoref{tab:harmful_behavior_50_big_table} (Bottom). Relative to our baselines, KDA achieves a higher TDR and comparable TTR, implying that KDA generates attack prompts with diverse topics and tokens. Moreover, KDA generate coherence attack prompts with PPL below 60\footnote{Generations below this threshold is considered coherent, as reported in~\citet{liu_autodan_2024}. Attack prompts that lack coherence, such as those generated by GCG~\citep{zou_universal_2023}, typically exhibit PPL values between 400 and 1600.}. Since all baselines generate semantically meaningful prompts, KDA is capable of generating diverse and coherence prompts, on par with the SOTA baselines.

In summary, the results demonstrate that KDA effectively generates diverse and coherent attack prompts, achieving strong performance across all evaluated metrics.






% As mentioned in Section~\ref{sec:KDA_training}, KDA is trained on attack prompts generated by SOTA attackers AutoDAN, PAIR, and GPTFuzzer when targeting Llama-2-7B, Vicuna-7B, GPT-3.5-Turbo, and GPT-4-Turbo on our curated Harmful-100 dataset. As shown in~\autoref{tab:harmbench}, The superior ASR of our KDA compare with numerous SOTA baseline attackers on Harmbench~\citep{mazeika_harmbench_2024} dataset demonstrate our KDA can generalize to unseen dataset and target model pretty well. The superior performance on effectiveness, efficiency and diverse evaluated on Harmful-Behavior~\citep{chao_jailbreaking_2024} dataset in ~\autoref{tab:harmful_behavior_50_big_table} further shows the good generalization to unseen dataset.




% shows the comparison on diversity of coherence. Notably, KDA outpform or perform very strongly with the SOTA baselines in terms of topic diversity ratio (TDR). Regarding type token ratio (TTR), KDA performs comparably regarding token diversity. For Perplexity, we consider all PPL lower than 60 as coherent\footnote{As reported in~\citep{liu_autodan_2024}, attack prompts without semantic meaning generating (e..g, generated by GCG~\citep{zou_universal_2023}) has PPL between $400-1600$.}, as all our baselines can generate prompts with semantic meaning. In the result, KDA is capable of generating coherent attack prompts as the SOTA baselines. In summary, the result shows KDA can generate diverse and coherent prompts.    



% we focus on the columns corresponding to the baseline methods \{AutoDAN, PAIR, GPT\_Fuzzer\} and KDA with ensemble formats \{$\text{KDA}\text{uni}$, $\text{KDA}\text{ifr}$, $\text{KDA}_\text{trn}$\}. KDA consistently achieves the best or near-best ASR compared to SOTA baselines. Since the HB evaluator is more stringent than TM, KDA's superior performance on HB-ASR, achieved with significantly lower average attack time, is particularly noteworthy. The reduced attack time compared to AutoDAN, GPTFuzzer, and PAIR is primarily due to KDA's ability to achieve successful attacks with fewer queries. Among the different KDA sampling strategies, 
% $\text{KDA}_\text{trn}$ demonstrates among the best effectiveness and efficiency. Therefore, if training time statistics for the target LLM are available, we recommend using the $\text{KDA}_\text{trn}$ ariant; otherwise, $\text{KDA}_\text{ifr}$ is suggested. Further details on KDA's sampling strategies can be found in~\autoref{app:hyperparameters}.


\subsection{Ablation Studies} 

\begin{figure}[h]
% \vspace{-4mm}
\centering
    \includegraphics[width=0.48\textwidth]{data/asr_ablation.png}
    \vspace{-7mm}
    \caption{\textbf{Ablation study on attack success rate for all KDA format selection strategies.} The curves depict $\text{ASR}^{\text{HB}}_{30}$, the attack success rate with a target query budget of $M=30$ using the HB evaluator, comparing single-format settings ($F \in \{\texttt{A}, \texttt{P},\texttt{G}, \texttt{M}\}$) and ensemble-format settings ($ \texttt{uni}, \texttt{ifr}, \texttt{trn}$). The evaluation is conducted on the standard behavior dataset from Harmbench~\citep{mazeika_harmbench_2024}. Solid lines represent ensemble formats while dashed lines indicate single formats. Uncertainty is quantified using the standard deviation from 10,000 bootstrap samples drawn with replacement.
    }\label{fig:asr_ablation}
   \vspace{-3mm}
\end{figure}

\subsubsection{KDA with Single-Format Setting} 



Since the KDA ensemble format outperforms SOTA baselines, we further investigate the contribution of individual components within the ensemble to overall effectiveness and diversity. To achieve this, we restrict KDA's format selection strategy to a single format, denoted as $\text{KDA}_{F}$ with $F \in \{\texttt{A}, \texttt{P},\texttt{G}, \texttt{M}\}$, where KDA generates attack prompts mimicking AutoDAN, PAIR, GPTFuzzer, and a Mixed Style, respectively. For instance, when using $\text{KDA}_{\text{P}}$, the attack prompt generation follows $\hat{A}\sim \text{LLM}_{\text{KDA}}(A|Q, F=\texttt{P})$. 

\myparagraph{$\text{KDA}_{\text{A}}$ vs. AutoDAN} As shown in the blue bars of~\autoref{fig:asr_tdr_ablation_sota}, $\text{KDA}_{\text{A}}$ significantly outperforms AutoDAN in terms of both attack effectiveness and topic diversity. The superior effectiveness of $\text{KDA}_{\text{A}}$ is primarily attributed to the usage of only successful prompts during the KDA training phase. The improvement in topic diversity is due to the exposure to a wide range of prompt formats during training. Despite being conditioned on a single format, the model inherently learns patterns from other formats, leading to a higher topic diversity compared to AutoDAN.

\begin{figure}[h]
% \vspace{-4mm}
\centering
    \includegraphics[width=0.47\textwidth]{data/asr_tdr_ablation_sota.png}
    \vspace{-2mm}
    \caption{\textbf{ASR and Topic Diversity of KDA using single format setting} $\text{KDA}$ with format $F \in \{\texttt{A}, \texttt{P},\texttt{G}, \texttt{M}\}$ compared to SOTA baselines AutoDAN, PAIR, and GPTFuzzer. (Top) Attack Success Rate (ASR); (Bottom) Topic Diversity Ratio (TDR). $\text{KDA}_\text{A}$, $\text{KDA}_\text{P}$, and $\text{KDA}_\text{G}$ share the same color scheme as their respective baseline counterparts AutoDAN, PAIR, and GPTFuzzer. The evaluation is conducted on the Harmful-Behavior dataset~\citep{chao_jailbreaking_2024}. Uncertainty is quantified using the standard deviation from 10,000 bootstrap samples drawn with replacement.
    }\label{fig:asr_tdr_ablation_sota}
   \vspace{-0mm}
\end{figure}

\myparagraph{$\text{KDA}_{\text{P}}$ vs. PAIR} The orange bars in~\autoref{fig:asr_tdr_ablation_sota} show that $\text{KDA}_{\text{P}}$ generally outperforms or matches PAIR in both attack effectiveness and topic diversity. The only exception occurs when attacking the Llama-2-7B-Chat model, where PAIR on its own has a low ASR, limiting the training data for KDA to learn effectively.

\myparagraph{$\text{KDA}_{\text{G}}$ vs. GPTFuzzer} As illustrated by the red bars in~\autoref{fig:asr_tdr_ablation_sota}, $\text{KDA}_{\text{G}}$ performs comparably to GPTFuzzer in terms of effectiveness and significantly outperforms it in topic diversity. Since GPTFuzzer leverages the GPT-3.5/GPT-4 Turbo model for attack prompt mutation and rephrasing, the comparable effectiveness of $\text{KDA}_{\text{G}}$ indicates that our approach successfully distills knowledge from a SOTA commercial model into our open-source 13B model. The higher topic diversity is a result of the diverse training prompt collection used in KDA.

\myparagraph{Mixed formats $\text{KDA}_{\text{M}}$} The green bars in~\autoref{fig:asr_tdr_ablation_sota} represent KDA's mixed-format setting, which blends styles and tones from AutoDAN, PAIR, and GPTFuzzer. This setting achieves superior ASR compared to all SOTA baselines and exhibits the highest topic diversity among all methods. The mixed format setting is a key factor contributing to KDA's ability to generate effective and diverse attack prompts.

In summary, the ablation study demonstrates that each KDA single-format setting provides distinct advantages over its respective baseline, while the mixed format further enhances both effectiveness and diversity.

% As KDA ensemble format has superior performance over SOTA baselines, we hope to further investigate how each component in the ensemble setting helps the overall effectiveness. We control the format selection strategy of KDA to be from single format only, e.g., $\text{KDA}_{\sigma}$ with $\sigma = \{\text{A},\text{P},\text{G},\text{M}\} $, which represents KDA generate attack prompts that mimicking AutoDAN, PAIR, GPTFuzzer, and a Mixed Style. E.g., when using $\text{KDA}_{\text{P}}$, the attack prompt generation is $\hat{A}\sim \text{LLM}_{\text{KDA}}(\cdot | Q, \mathcal{F}=\text{`PAIR'})$. 

% As shown in the blue bars of~\autoref{fig:asr_tdr_ablation_sota}, $\text{KDA}_{\text{A}}$ significantly outperform AutoDAN regarding attack effectiveness and topic diversity.  The superior effectiveness of $\text{KDA}_{\text{A}}$ over AutoDAN
% is mostly owing to only successful prompts is used in our KDA training phase. The supriro performance on topic diversity is mostly because during KDA training phase, attack prompts with a huge variety of formats are provided, even we have the prompt generation condition on the format, the model still learned some patterns from the other formats, which gives the $\text{KDA}_{\text{A}}$ much higher topic diversity than $AutoDAN$.

% As shown in the orange bars of~\autoref{fig:asr_tdr_ablation_sota}, $\text{KDA}_{\text{P}}$ generally outperform or perform comparably to PAIR regarding attack effectiveness and topic diversity., with the only exception when attacking the Llama-2-7B-Chat model, The key reason is the PAIR method has bad performance when attacking Llama series, so we are not able to collect sufficient training data targeting it.

% As shown in the red bars of ~\autoref{fig:asr_tdr_ablation_sota}, $\text{KDA}_{\text{G}}$ perform comparably to GPTFuzzer regarding effectiveness and significantly outperform regarding topic diversity. As GPTFuzzer utilizes GPT-3.5 Turbo model for the attack prompts mutation and rephrasing, it is worth mention that effectiveness means we successful distilled the knowledge from the SOTA commercial model into our 13B opensource models. The topic diversity owing to the collection of diverse training prompts. 

% The Green bar~\autoref{fig:asr_tdr_ablation_sota} is control KDA to generate prompts in a mixed styles and tones from A,P, and G, which has better ASR than SOTA baselines and the best topic diversity among all methods. The Mixed version is another key reason for our KDA's effective and diverse prompts generation. 



\subsubsection{Ablation on All KDA Format Selection Strategies} 





As shown in~\autoref{fig:asr_ablation}, we analyze the impact of single-format and ensemble-format settings in KDA by comparing the $\text{ASR}^{\text{HB}}_{30}$ across single-format ($F\in\{\texttt{A}, \texttt{P},\texttt{G}, \texttt{M}\}$) and ensemble-format ($\texttt{uni}, \texttt{ifr}, \texttt{trn}$) strategies. Among all format selection strategies, the ensemble settings $\text{KDA}_{\texttt{trn}}$ and $\text{KDA}_{\texttt{ifr}}$ achieve the best or near-best $\text{ASR}^{\text{HB}}_{30}$ overall. This demonstrates that combining diverse formats enhances attack effectiveness, primarily due to the increased prompt diversity and improved exploration of various vulnerabilities across different target models. 

Thus, in practice, we recommend using $\text{KDA}_{\text{trn}}$ when performance statistics on the target model are available; otherwise, $\text{KDA}_{\text{ifr}}$ is recommended for general use.







% We evaluate four single-format variants of KDA: \{$\text{KDA}_\text{A}$, $\text{KDA}_\text{P}$, $\text{KDA}_\text{G}$, $\text{KDA}_\text{M}$\}, where the first three correspond to the formats used in AutoDAN, PAIR, and GPTFuzzer, respectively. Most single-format KDA variants outperform their counterparts in terms of effectiveness, as KDA is trained exclusively on successful attack prompts, allowing it to sample effective prompts more efficiently than baseline methods. The only exception is $\text{KDA}_\text{P}$ when attacking Llama-2-7B-Chat, as PAIR does not perform well against Llama-2, resulting in insufficient high-quality data and, consequently, lower performance. In terms of efficiency, $\text{KDA}_\text{A}$ and $\text{KDA}_\text{P}$ are notably more efficient than their counterparts. However, $\text{KDA}_\text{G}$ is slower than GPTFuzzer, as GPTFuzzer relies solely on API calls for attack generation, whereas KDA requires local inference, explaining the speed difference.



\subsubsection{Topic Diversity Analysis} To further explore how the ensemble-format setting in KDA enhances topic diversity, we evaluate the topic distribution of attack prompts generated by KDA in single-format settings. As shown in~\autoref{fig:topic diversity}, the topics covered by $\text{KDA}_\text{A}$, $\text{KDA}_\text{P}$, $\text{KDA}_\text{G}$, and $\text{KDA}_\text{M}$ are often complementary. This indicates that combining multiple single-format styles contributes to greater topic diversity in KDA-generated prompts. For robustness evaluation of LLMs with safety mechanisms, employing an ensemble of attack formats that enhance attack diversity can lead to more reliable results. As discussed in~\citet{liang_implications_2023, liang_optimization_2023}, diverse attack patterns can better assess robust accuracy, as different attack styles may expose distinct vulnerabilities of the target model.



% To further investigate how the ensemble-format setting in KDA helps increase the topic diversity, we conduct evaluation on the topic distribution of attack prompts generated by KDA single-format settings. As shown in~\autoref{fig:topic diversity}, at most time, the topics in different $\text{KDA}_{\sigma}$ are complementary, which means the ensemble of single format style can help increase the topic diversity of the KDA generated prompts. If we hope to use the attack prompts data to test the robustness for LLM with safety mechanisum, use an ensemble of attack formats with increasing attack diversity can help make the results more reliable (see discussion in ~\citet{liang_implications_2023,liang_optimization_2023} about the discussion on attack pattern and robust accuracy), as different attack style may explore different vulnerabilities of the target model.





\begin{figure}[h]
% \vspace{-4mm}
\centering
    \includegraphics[width=0.48\textwidth]{data/topic_diversity.png}
    % \vspace{-5mm}
    \caption{\textbf{Topic distribution heatmap comparing the diversity of successful attack prompts} generated by baseline methods and KDA across different LLM targets. Each subplot corresponds to a different target LLM, with the x-axis representing KDA with different single format selection strategies $F\in\{ \texttt{A}, \texttt{P}, \texttt{G}, \texttt{M} \}$. Topic diversity is measured using the BERTopic model, with color intensity representing the proportion of prompts within a specific topic relative to the total number of prompts. Darker green indicates a higher concentration, while lighter green or white signifies lower or zero concentration. 
    }\label{fig:topic diversity}
    \vspace{-3mm}
   
\end{figure}


% \newpage