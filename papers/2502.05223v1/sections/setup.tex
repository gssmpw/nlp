\subsection{Experimental Setup} \label{sec:exp_setup}
 
All experiments were conducted using eight NVIDIA A5000 GPUs, each with $24.5$ GB of memory.

\myparagraph{Datasets} For attacker performance evaluation, we use two datasets: the HarmBench standard behavior dataset~\citep{mazeika_harmbench_2024} and a smaller harmful behaviors dataset~\citep{chao_jailbreaking_2024}. These datasets contain 200 and 50 diverse harmful behaviors, respectively, designed to trigger the safety mechanisms of LLMs.

\myparagraph{Target LLMs $q_T$} We compare attacker performance  on SOTA open-source LLMs such as Llama-2-7B-Chat, Llama-2-13B-Chat, Vicuna-7B, Vicuna-13B, Qwen-7B-Chat, Qwen-14B-Chat and Mistral-7B, and commercial LLMs such as GPT-3.5-Turbo, GPT-4-Turbo and Claude-2.1. 

\myparagraph{Jailbreak evaluators $J$} We determine jailbreak success using two methods. The first method is Text Matching (TM)~\cite{zou_universal_2023}, which checks for the presence of specific refusal keywords (e.g., ``Apologize'') in the target response $R$. If no refusal keywords are found, the jailbreak is considered successful. The second method is the HarmBench (HB) evaluator~\citep{mazeika_harmbench_2024}, a Llama-2-13B classifier fine-tuned on a human-annotated dataset. HB evaluates $R$ more rigorously, classifying it as a successful jailbreak only if it is both relevant to the harmful query $Q$ and contains harmful content. Consequently, the HB evaluator applies a much stricter criterion than TM in determining successful jailbreaks.


% which classifies $R$ as a jailbreak only if it is both relevant to the harmful question $Q$ and contains harmful content. Thus, HB has a much more strict criterion than TM in identifying successful jailbreaks.

\myparagraph{Metrics} We provide a comprehensive evaluation framework to assess the attack methods on four important axes: effectiveness, efficiency, diversity, and coherence. \textbf{Effectiveness} and \textbf{efficiency} are evaluated using the Attack Success Rate (\textbf{ASR}) under a given target query budget $M$, which is the number of successful jailbreak attacks under a fixed query budget $M$ using TM or HB evaluators. For example, $\text{ASR}_{30}^{\text{HB}}$ denotes the attack success rate assessed by the HB evaluator with a target query budget of 30. \textbf{Efficiency} is also evaluated by the average attack time $\Bar{t}$, the total time taken divided by the number of successful target queries.  \textbf{Diversity} is assessed through two key metrics: the topic diversity ratio (\textbf{TDR}) and the type-token ratio (\textbf{TTR}). TDR is defined as the number of unique topics divided by the total number of prompts, where each prompt’s topic is determined using the BERTopic\_Wikipedia model~\citep{grootendorst_bertopic_2022}. TTR measures lexical diversity by computing the ratio of unique tokens to the total number of tokens within a given window. Finally, \textbf{coherence} is measured by Perplexity (\textbf{PPL}), which is an exponentiated average negative log-likelihood of a sequence, computed using GPT-2~\citep{radford_language_nodate}.

% For effectiveness, we report the Attack Success Rate (\textbf{ASR}) under a given maximum target query budget $M$, evaluated using the TM and HB evaluators. For instance, $\text{ASR}_{30}^{HB}$ represents the attack success rate determined by the HB evaluator with a maximum target query budget of 30.  To evaluate efficiency, we report the average attack time $\Bar{\mathbf{t}}$, computed as the total time divided by the number of successful target queries. 


% To evaluate the topic diversity, we use topic diversity ratio (\textbf{TDR}), which is defined as number of unique topics divided by the total number of prompts, were the topic for each prompt is determined by the BERTopic\_Wikipedia model~\citep{grootendorst_bertopic_2022}. Lexical diversity is quantified using the type-token ratio (\textbf{TTR}), which represents the total number of unique tokens divided by the total number of tokens within a given window.  In terms of coherence  Perplexity (\textbf{PPL}), an exponentiated average negative log-likelihood of a sequence, is computed using GPT-2~\citep{radford_language_nodate} to measure the coherence.

% Additionally, we provide $\overline{\textbf{ASR}}$ to represent the per-query success rate, calculated as the total number of successful target queries divided by the total number of target queries.

\myparagraph{Baseline methods} We conduct an ASR comparison across all SOTA attackers utilized in HarmBench and select three representative attackers—AutoDAN, GPTFuzzer, and PAIR—as baseline methods\footnote{Note that AutoDAN cannot attack commercial models; therefore, no AutoDAN data is presented for GPT-3.5-Turbo and GPT-4-Turbo.} for a comprehensive comparison across the previously defined metrics.

\myparagraph{KDA format selection strategy} When comparing against SOTA baselines, we adopt the ensemble format settings: $\text{KDA}_{\texttt{trn}}$, which is used when performance statistics on the target model are available, and $\text{KDA}_{\texttt{ifr}}$, which is recommended for general use. For the ablation study, we also introduce $\text{KDA}_{\texttt{uni}}$ to assess the effectiveness of the ensemble format. Additionally, we evaluate the single-format setting, denoted as $\text{KDA}_{F}$, where $F \in \{\texttt{A}, \texttt{P}, \texttt{G}, \texttt{M}\}$.

% When comparing with SOTA baselines, we use emsemble format settings: $\text{KDA}_{\texttt{trn}}$, when performance statistics on the target model are available, and $\text{KDA}_{\texttt{inf}}$ is recommended for general use. For ablation study, we also use $\text{KDA}_{\texttt{rnd}}$ to compare the effectiveness of ensemble format, and single format setting $\text{KDA}_{F}$ with $F\in \{ \texttt{A}, \texttt{P}, \texttt{G}, \texttt{M} \}$.

% \paragraph{Uncertainty Measure} The uncertainty of all metrics is quantified by computing the mean and standard deviation from 10,000 bootstrap samples, drawn with replacement.

For further details on all experimental setups, please refer to~\autoref{app:setup}. 














