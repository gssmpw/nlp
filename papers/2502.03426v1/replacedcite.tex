\section{Related Work}
\label{sec:related_work}

\textbf{Pose-guided person image synthesis.}
% 这一部分介绍这个任务的方法发展
% Pose-guided person image synthesis任务聚焦于如何在复杂空间中实现pose的转换并尽可能的保留source image的细节特征一致性。这个任务首次由Ma等人提出，早期的工作聚焦于利用conditional 生成对抗网络将source image作为条件信息来引导target图像的生成，如VUNet利用VAE对source image apperance提取并作为条件引入到UNet来生成图片，Def-GAN通过a set of loacl affine transformations和损失约束来对齐不同pose等。这类GAN-based 方法因为模型自身缺乏学习pose空间变换关系的能力导致效果不佳。之后的一些工作有采用flow-based deformation来帮助解构source image的信息以实现pose的对齐，比如GFLA通过计算图片在flow fields的相关性来提取局部注意力特征实现不同区域的对应；也有引入更为详细稠密的补充信息（如UV[Style and Pose Control for Image Synthesis of Humans from a Single Monocular View]，densepose[Controlllable person image synthesis with attribute-decomposed gan]和parsing map来帮助弥补pose之间的inconsistency）。
% 最近的工作采用diffusion作为生成底模，相比于先前gan或其他生成方法在生成高分辨率图像时细节保留差和不稳定的问题，diffusion通过多步forward-backward denoising 过程不仅训练更为稳定，同时也能保留图片的细节特征生成高分辨的图像。PIDM通过设计一个条件texture diffusion模型和disentangle classifier-free guidance机制来实现pose引导下的图像生成，PoCoLD和PCDM分别通过pose constrained attention和progressively 多stage refine来实现pose的对齐。CFLD通过挖掘source image的corse prompt information 然后不断细化来实现细粒度的生成。以上的diffusion-based方法均依赖于预训练的encoder来实现对source image的apeerance信息进行提取，我们认为这类模型因其本身的缺陷（比如数据集的长尾效应）使其关注于常见区域如人脸/手等区域而无法捕捉细粒度的纹理花纹等细节特征，所以导致先前的diffusion-based方法无法生成具有一致性的复杂图案。
PGPIS achieves pose transformation in a complex spatial context while maintaining consistency with the detailed features of the source image, which was proposed by Ma \etal  ____. 
Early approaches ____ employ conditional generative adversarial networks (CGANs)  ____ to guide the generation of target images using the source image as conditional information ____. However, due to the significant spatial information differences between the source image and the target image, as well as the sparse guidance from the skeleton map, directly achieving pose transfer is highly challenging. To address the challenges, some works decouple and separately optimize pose and appearance information____, or use attention mechanisms to better establish the mapping relationship between pose and appearance____. 
On the other hands, some approaches introduce more detailed and dense supplementary information, such as UV ____, dense-pose ____, and parsing maps ____, to alleviate inconsistencies between poses. 
Recent approaches adopt diffusion as the generative model____. 
%
By incorporating conditional information into iterative forward-backward denoising procedures ____, diffusion-based methods outperform GAN-based approaches in terms of both image generation quality and pose control effectiveness.
PIDM is the pioneering endeavor to integrate the diffusion model into PGPIS, which designs a conditional texture diffusion model and a disentangle classifier-free guidance mechanism ____. 
% 加入latent diffusion描述，ldm方法依赖于预训练
PoCoLD and PCDM aim to achieve pose alignment through a pose-constrained attention mechanism and progressive multi-stage refinement, respectively ____.
CFLD ____ endeavors to attain coarse-to-fine generation by extracting coarse prompt information from the source image, followed by refinement through a learnable Perception-Refined Decoder and Hybrid-Granularity Attention to achieve fine-grained results. 
%

\textbf{Conditional diffusion models.}
% 这一部分介绍条件生成模型的在图片生成发展
The significant potential of diffusion models in traditional unconditional generative tasks has recently been evidenced____. 
In contrast to conventional single-step generative models such as Generative Adversarial Networks (GANs)____ and Variational Autoencoders (VAEs)____, diffusion relies on multi-step denoising sampling of initial noise to generate high-quality data, thereby enabling the production of detailed and diverse outputs. The advancement of various conditional diffusion models further enhances its practicality and versatility. Classifier-free methodologies devise implicit classifiers to guide the weights of controllable and uncontrollable processes, thus facilitating conditional generation____. Furthermore, Latent Diffusion Model(LDM)____ utilize denoising process by encoding original images into a low-dimensional latent space and integrate cross-attention mechanisms to introduce multi-modal conditions, thereby significantly expanding the diversity of control information. 
Prior LDM-based approaches____ rely on pre-trained encoders to extract appearance information from the source image. 
We argue that such encoders are ineffective in capturing fine-grained details, which hinders the generation of complex images. In contrast, our proposed framework utilizes guided attention to capture complex detail features, improving the preservation of full identities and ensuring person consistency.
% In contrast, our proposes Siamese conditional diffusion framework excels in capturing complex details and establishing semantic matching, thereby improving the preservation of Full-IDs and ensuring person consistency. 
Our extensive experimental analysis confirms the limitations of traditional approaches. (\secref{sec:limitation}).
% Recent studies____ have incorporated diffusion models into fashion generation tasks. 
% PCDM introduces a progressive three-stage network consisting of prior-inpainting-refining stages. 
% This model integrates pose alignment relations and utilizes the CLIP model to extract image features, gradually refining image details throughout the three stages. 
% CFLD proposed a coarse-to-fine training paradigm, fully exploiting multiscale information by mining and refining coarse-grained prompts obtained from pre-trained feature extractors (e.g., SwinB) and combining them with a mixed-granularity mechanism. In contrast to previous diffusion-based methods that rely on pre-trained models for extracting semantic or pixel-level appearance details from the source image, this paper introduces a siamese diffusion framework built upon LDM. This framework make full use of the feature extraction and matching abilities of pre-trained diffusion models to blend fine-grained features and facilitate pose transfer within the latent space, achieving higher consistency in pose-guided person image synthesis.