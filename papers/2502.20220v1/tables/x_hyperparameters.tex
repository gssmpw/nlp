\begin{table}[htb]
    \centering
    \begin{tabular}{lll}
        \toprule
        & Hyperparameter & Value \\
        \midrule
            \multirow{5}{*}{\rotatebox[origin=c]{90}{\parbox[c]{2cm}{\centering \small ViT \& GRM}}} 
                & ViT patch size & $8 \times 8$ \\
                & hidden dimension $D$ & 768 \\
                & \#self-attention layers & 8 \\
                & \#cross-attention layers & 8 \\
                & \#GRM transformer upsampler step & 1 \\
         \midrule
            \multirow{5}{*}{\rotatebox[origin=c]{90}{\parbox[c]{2cm}{\centering \small Input \& Output}}} 
                & Sapiens version & 2b \\
                & Sapiens feature dimension & 1920 \\
                & Input image resolution & $512 \times 512$ \\
                & Gaussian attribute map resolution & $512 \times 512$ \\
                & Train render resolution & $667 \times 667$ \\

         \midrule
            \multirow{3}{*}{\rotatebox[origin=c]{90}{\parbox[c]{1.5cm}{\centering \small Expression MLP}}} 
                & Dimension of expression code & 256 \\
                & \#expression sequence MLP layers & 2 \\
                & Dimension of expression sequence MLP & 256 \\
                & Expression sequence MLP activation & ReLU \\
         \bottomrule
         
    \end{tabular}
    \caption{\textbf{Hyperparameters.}}
    \label{tab:x_hyperparameters}
\end{table}
