\section{Introduction}
\label{sec:intro}


\ps{Challenges of technology scaling}

The growing demand for computing performance has always been met by increasing the number of transistors per chip, which is only possible due to CMOS technology scaling.
However, as we keep pushing the boundaries of technology scaling, we encounter multiple challenges.
Firstly, whenever we transition to a more advanced technology node, the non-recurring cost due to physical design, verification, software, mask sets, and prototyping almost doubles \cite{cost-tech-node}.
As a result, designing a chip in an advanced technology node is only economically viable if the chip is manufactured in vast quantities.
Secondly, many chip components such as I/O drivers, analog circuits, or \gls{srams} have reached their scaling limit.
This means that we cannot shrink these components further, even if we use a more advanced technology with a smaller feature size.
Thirdly, advanced technology nodes suffer from high defect rates, diminishing the yield and inflating the recurring cost.
To tackle these challenges, new chip-design paradigms have been developed.

\ps{Why 2.5D integration?}

One of these new paradigms is 2.5D integration, where multiple silicon dies called chiplets are integrated into the same package.
Once designed, a single chiplet can be reused in multiple 2.5D stacked chips, which increases the ratio of production volume to non-recurring cost.
Another advantage is that multiple chiplets - fabricated in different technologies - can be integrated into the same package.
This means that only components that can take full advantage of technology scaling are built in bleeding-edge technologies.
Components that have reached their scaling limit are fabricated in more mature and hence less costly technology nodes.
Furthermore, chiplets are smaller than monolithic chips.
Therefore, manufacturing chiplets results in less silicon area loss due to fabrication defects and hence a higher yield.
Due to these economic advantages, chip vendors such as AMD \cite{amd-chiplet} and NVIDIA \cite{chiplet-book} have adopted the 2.5D integration paradigm.  

\ps{Challenges of 2.5D integration}

An important challenge when designing 2.5D stacked chips is the construction of a low-latency and high-throughput \gls{ici}. 
To build an \gls{ici}, we connect different chiplets using \gls{d2d} links.
These links are fabricated in an organic package substrate, silicon bridge, or silicon interposer, and they are connected to the chiplets using \gls{c4} bumps or microbumps.
The number of bumps per chiplet is limited, and so is the bandwidth of \gls{d2d} links.
In addition to having lower bandwidth than links in monolithic chips, \gls{d2d} links also have higher latency.
This latency is caused by wire delay and by \gls{phys} that are necessary in both the sending and the receiving chiplet.
\gls{phys} are needed to convert between protocols, voltage levels, and frequencies, which are usually different between on-chiplet links and \gls{d2d} links.
Due to these limitations, the \gls{ici} can quickly become a bottleneck.

\ps{How we solve these challenges differently than the related work does.}

Existing approaches to maximize the performance of the \gls{ici} either optimize the placement of chiplets (with potentially heterogeneous shapes) for a predetermined \gls{ici} topology 
\cite{ho,liu,seemuth,eris,osmolovskyi,tap25d,chiou}, select one topology out of a set of candidates \cite{coskun-1, coskun-2}, or they optimize the \gls{ici} topology for a 2D grid of homogeneously shaped chiplets on an active interposer \cite{butterdonut, cluscross, kite}.
To the best of our knowledge, there is no prior work on \gls{ici} topologies for chips with heterogeneously shaped chiplets or with passive silicon interposers or silicon bridges.
To fill this gap, we propose \name, a novel optimization methodology to jointly optimize the chiplet placement and \gls{ici} topology of such architectures.
\ifnb
\else
\newpage
\fi

\ps{Details on \name~and the key idea}

The key idea is as follows: 
We optimize the chiplet placement without a predetermined topology.
For each placement generated by an optimization algorithm, we infer a placement-based \gls{ici} topology by connecting chiplets that are in close proximity in that specific placement.
We then compute the latency and throughput of this combination of placement and topology for different traffic types.
These latencies and throughputs together with the total chip area are used to compute a user-defined quality-score of the placement, which is returned to the optimization algorithm.
Based on this quality score, the algorithm can further optimize the placement.
By following this iterative process, we jointly optimize the chiplet placement and the \gls{ici} topology.

\ps{Short evaluation-summary}

We provide our open-source framework implementing the proposed placement and topology co-optimization methodology, which we evaluate using both synthetic traffic and traffic traces.
A 2D grid of chiplets with a mesh topology is used as a baseline since many proposals for 2.5D stacked chips \cite{dataflow_accel_dnn, cifher, simba, hecaton, dojo} use such an architecture.
We reduce the latency of synthetic L1-to-L2 and L2-to-memory traffic, the two most important traffic types for cache coherency traffic, by up to 28\% and 62\% respectively.
For real traffic traces, we reduce the average packet latency for almost all traces and architectures considered (reduced by an 8\% or 18\% on average depending on the configuration of \gls{phys} within a chiplet).
