\section{Evaluation}
\label{sec:eval}
\vspace{-0.5em}

\ps{Overview of evaluation section}

\input{fig_eval_placements}				% Fix figure placement

We evaluate our proposed chiplet placement and \gls{ici} topology co-optimization methodology on the two homogeneous architectures from \Cref{ssec:homo-opt} and on the two heterogeneous architectures from \Cref{ssec:hetero-opt}.
For each of these four architectures, we design a baseline architecture consisting of a 2D mesh of compute-chiplets in the center with memory- and IO-chiplets on the perimeter.
This type of architecture is the de-facto standard that is used in numerous systems \cite{dataflow_accel_dnn, cifher, simba, hecaton, dojo}.
We perform our evaluation using two different chiplet configurations: 
In the \textit{baseline} configuration, memory- and IO-chiplets only have a single PHY and they cannot relay messages, which is highly unfavorable for \name, as \name~often places memory- and IO-chiplets in the center of the chip (off-chip links of IO-chiplets are routed to the border on the redistribution layer as in AMD's EPYC and Ryzen \cite{amd-chiplet}).
In the \textit{\name} configuration, all chiplets have four \gls{phys} and relay capability.
To ensure a fair comparison, the total memory- and IO-bandwidth stays unchanged and the increased off-chiplet bandwidth due to additional \gls{phys} is only used to relay messages.
\Cref{fig:eval-placements} shows baselines and optimized architectures for the \textit{baseline} configuration.
Unfortunately, a direct comparison to prior work (see \Cref{sec:related-work}) is infeasible since frameworks to optimize the placement are not open-source, or they do not scale to our chiplet counts, and proposals for \gls{ici} topologies on active interposers are not applicable to passive interposers, silicon bridges, and organic substrates.

\vspace{-0.5em}
\subsection{Evaluation Methodology}
\label{ssec:eval-methodology}

\ps{Explain our evaluation methodology and introduce partial trace simulations}

We use RapidChiplet's \cite{rapidchiplet} feature to run simulations in BookSim2 \cite{booksim} using synthetic traffic and application traces from Netrace \cite{netrace}.
BookSim2 is an established, cycle-accurate \gls{noc} simulator and Netrace is a tool for dependency-driven, trace-based \gls{noc} simulations. 
We use the Netrace trace collection \cite{netrace-traces}, which is based on the PARSEC benchmark suite \cite{parsec}.
Each trace is split into five regions (see \Cref{tab:eval-traces}).
Since these traces span across billions of cycles, simulating them in a cycle accurate simulator is extremely time-consuming. 
The \textit{blackscholes\_64c\_simsmall} trace was the only one to terminated within 24 hours, therefore, for the remaining traces, we only simulate the first 1'000'000 cycles of each region.
All traces contain cache coherency traffic between the L1 cache (mapped to compute-chiplets), the L2 cache (mapped to memory-chiplets), and the main memory (mapped to IO-chiplets).

\input{fig_eval_synthetic}
\input{fig_app_eval_synthetic}



\ps{Provide remaining simulation details}

We set the parameters of RapidChiplet and BookSim2 to match the latencies described in \Cref{tab:homo-params,tab:hetero-params}. 
BookSim2 models input-queued \gls{vc} routers with a four-stage pipeline (routing, \gls{vc} allocation, switch allocation, crossbar traversal) and wormhole flow control.
We use 1-flit packets for control messages and 9-flit packets for data transfers \cite{netrace-tr}.
Furthermore, we use shortest path routing, up to 8 virtual channels, and 8-flit buffers.


\input{fig_eval_trace_partial}	% Fix figure placement


\subsection{Performance Comparison using Synthetic Traffic}
\label{ssec:eval-synthetic}

\ps{Explain which synthetic traffic we use and why we care about synthetic traffic.}

We compare our optimized \gls{ici} topologies against the baselines in terms of latency and throughput using synthetic \gls{c2c}, \gls{c2m}, \gls{c2i}, and \gls{m2i} traffic.
The advantage of synthetic traffic over real traces is its generality, as synthetic traffic does not depend on the application.
\Cref{fig:eval-synthetic,fig:app-eval-synthetic} show the latency and throughput results under synthetic traffic for the \textit{baseline} and  \textit{\name} chiplet configurations, respectively.

\ps{Discuss results on synthetic traffic: Latency}

Recall that our primary optimization goal was to minimize \gls{c2m} and \gls{m2i} latency and to improve \gls{c2m} and \gls{m2i} throughput.
We observe that for all combinations of architecture and optimization algorithm, \name~improves \gls{c2m}, \gls{c2i}, and \gls{m2i} latency.
The fact that the baseline provides the best \gls{c2c} latency is not surprising, given that in the baseline, compute-chiplets form a regular grid with a 2D mesh topology.


\ps{Discuss results on synthetic traffic: Throughput}

\name~is only able to significantly outperform the baseline architecture in terms of \gls{c2m} and \gls{m2i} throughput if we use the \textit{\name} chiplet configuration, where memory- and IO-chiplets have four \gls{phys} and relay-capabilities. The \textit{baseline} configuration with only a single PHY per memory- and IO-chiplet turns out to be too restrictive to provide significant throughput improvements.

\input{fig_eval_trace_full}
\input{fig_app_eval_trace_full}

\subsection{Performance Comparison on Full Traffic Trace}
\label{ssec:eval-trace-full}

\ps{Explain the two trace modes we use}

We evaluate the performance of our optimized \gls{ici} topologies using the full blackscholes-trace (see \Cref{tab:eval-traces}).
We simulate this trace in two different simulation modes:
In the \emph{authentic} mode, a packet is only injected if all dependencies are satisfied and the cycle, in which the packet appears in the trace, is reached.
This represents a scenario where after receiving a packet, the compute cores need some time to perform computations before injecting the next packet.
The second mode is called \emph{idealized} and it injects a packet as soon as all dependencies are satisfied, assuming ideal cores that perform computations instantly.
This mode is intended as a stress-test for the \gls{ici} as the packet injection rate is significantly higher than in the \emph{authentic} mode.
Our results in \Cref{fig:eval-trace-full,fig:app-eval-trace-full} show that \name~is able to achieve speedups in average packet latency of up to $1.17\times$ (for the \textit{baseline} configuration) and $1.34\times$ (for the \textit{\name} configuration).


\subsection{Performance Comparison on Partial Traffic Traces}
\label{ssec:eval-trace-partial}


\ps{Discuss results on partial traffic traces}

\Cref{fig:eval-trace-partial} shows our results for the simulation of partial trace regions.
\name~is able to reduce the average packet latency to $92\%$ (\textit{baseline} configuration) and $82\%$ (\textit{\name} configuration) on average.
In \Cref{ssec:homo-opt,ssec:hetero-opt} we observed that the \gls{ga} performed significantly better than \gls{br} with respect to the minimization of the cost function.
However, in our partial trace simulation, we see that this is not always the case and in some instances, \gls{br} is even better than the \gls{ga}.
This shows that either our performance estimate or our cost function does not fully reflect the performance on real traces. 
Nevertheless, co-optimizing the chiplet placement and \gls{ici} topology works, as we outperform the baseline architecture in almost all cases.

\subsection{Area Comparison}
\label{ssec:eval-area}

\ps{Compare Area: No area loss compared to manually placed chiplets}

The area of all homogeneous placements for a given architecture is identical, therefore, we only discuss the area of heterogeneous placements. 
For the 32-core architecture, \gls{br} and \gls{sa} increase the area by $5.4\%$ and $0.8\%$ respectively, but the \gls{ga} reduced the area by $8.1\%$ compared to the baseline.
For the 64-core architecture, \gls{br} and \gls{sa} both increase the area by $3.3\%$ but the \gls{ga} reduced the area by $6.3\%$ compared to the baseline.
We conclude that \name~is able to improve the \gls{ici}-performance without introducing significant area overheads.











