\section{\name~Architecture}
\label{sec:arch}

\ps{State our assumptions}

In this section, we present our open-source implementation of the proposed chiplet placement and \gls{ici} topology co-optimization methodology.
Our framework is based on the following list of assumptions:

\begin{itemize}
	\item Every chiplet is categorized as compute, memory, or IO.
	\item We know the number and locations of \gls{phys} in each chiplet.
	\item \gls{phys} use a common protocol, e.g., \gls{ucie} \cite{ucie} or \gls{bow} \cite{bow}.
	\item The data-width of all \gls{phys} is the same, i.e., we can connect any two \gls{phys} with a \gls{d2d} link.
	\item For each chiplet, we know whether it can relay traffic. Relaying traffic means that a message enters the chiplet through one PHY and leaves it through a different PHY.
	\item Off-chip traffic leaves the chip through an IO-chiplet as in the AMD EPYC and Ryzen processor families \cite{amd-chiplet}.
\end{itemize}

\ps{Give rough outline of the \name~architecture}

\Cref{fig:arch-arch} provides an overview of the \name~architecture. 
The experiment configuration contains the general configuration of \name~and parameters describing the architecture to be optimized (see \Cref{tab:arch-config}) as well as parameters for the three optimization algorithms.
The experiment runner launches multiple runs of each optimization algorithm.
We support the optimization algorithms \acrfull{br}, \acrfull{ga}, and \acrfull{sa}, but custom ones can be added.
Optimization algorithms interact with the placement through the following functions:

\begin{itemize}
	\item	\texttt{random\_placement()}: Return a random placement.
	\item	\texttt{mutate(X)}: Return an altered version of placement X.
	\item	\texttt{merge(X, Y)}: Return a hybrid of placements X and Y.
	\item	\texttt{get\_cost()}: Return the placement's cost.
\end{itemize}

\input{tab_arch_config.tex}

The core of the placement is the placement representation, which implements the first three out of the four functions listed above.
We provide two placement representations, one for homogeneously shaped chiplets (see \Cref{sec:homo}) and one for heterogeneously shaped chiplets (see \Cref{sec:hetero}), but custom ones can be implemented.
In addition to the \texttt{random\_placement()}, \texttt{merge()}, and \texttt{mutate()} functions, the placement representation contains functions to get the area and the placement-based \gls{ici} topology.
To assess the quality of a placement, we infer the placement-based \gls{ici} topology and use it to estimate the \gls{ici} latency and throughput, which we combine with the total chip area to compute a user-defined cost function.
Our performance estimates and cost function are explained in detail in the following sections.

\subsection{Computation of Performance Estimates}
\label{ssec:arch-proxies}

We use the RapidChiplet \cite{rapidchiplet} toolchain to estimate the latency and throughput of the \gls{ici}. RapidChiplet provides high-level latency and throughput proxies for \gls{c2c}, \gls{c2m}, \gls{c2i}, and \gls{m2i} traffic as well as simulation-based results for both synthetic traffic patterns and application traces.

\ps{Explain the cost function}

\input{fig_set_weights}					% Fix figure placement

\subsection{The Cost Function}
\label{ssec:arch-cost}

Specifying the cost function is the most crucial part of applying the \name~framework, as it sets the goal towards which the chiplet placement and \gls{ici} topology are co-optimized.

As a running example, throughput this paper, we use \name~to build a general-purpose cache-coherent system targeted at various scientific simulation workloads from the high-performance computing domain. 
To that end, we use a weighted sum of the latency and throughput of \gls{c2c}, \gls{c2m}, \gls{c2i}, and \gls{m2i} traffic. 
In addition, we incorporate a term for the area of a minimal rectangle fully enclosing all chiplets (from now on referred to as the area) to ensure that \name~produces compact placements.
\Cref{fig:arch-set-weight} visualizes the correlation of the final cost value with its nine components (four latency and four throughput terms plus the area term).

The user-defined cost function makes \name~applicable to a wide range of optimization goals. One could for example use estimates of the \gls{ici} latency and throughput under a certain application trace or a set of application traces to design a domain-specify accelerator, e.g., for machine learning training and inference, image and video processing, or graph analytics.
