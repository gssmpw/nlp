\section{Related Work}
\label{sec:related}
In this paper, we concentrate on two main families of Out-of-Distribution methods: \textit{post-hoc} and \textit{training-based}~\cite{liu2021towards, yang2024generalized}.

\minisection{Post-hoc methods} are applied after the model has been trained and typically involve analyzing its predictions or intermediate representations to identify whether an input is OoD~\cite{guo2017calibration, wei2022mitigating, hendrycks2018baseline}. These methods often focus on computational efficiency and adaptability to pre-trained models, as they avoid retraining~\cite{liu2021towards}.

\minisection{Training-based methods} modify the training process, sometimes completely restructuring the model to accommodate OoD detection~\cite{chang2020generalized, devries2018learning, tack2020csi}. These methods often come at the cost of higher training complexity, and might dilute the efforts to obtain an optimal ID training accuracy~\cite{liu2021towards, masana2018metric}. Additionally, exposure to outliers (real or generated) can be done to improve generalization~\cite{wang2023learning}.

\minisection{Baselines.}
A classic baseline for OoD is considered to be Maximum Softmax Probability (MSP)~\cite{hendrycks2018baseline}, a simple approach that relies on the logit scores to identify OoD samples. However, a major limitation of this approach is the tendency of models to produce overconfident predictions on anomalous data, leading to poor performance~\cite{guo2017calibration}. Temperature scaling~\cite{guo2017calibration} is a simple post-hoc way of tackling the overconfidence issue, where logits are scaled by a temperature $T$, but its results are not optimal~\cite{zhang2024openood}.

\minisection{OoD and intermediate layers.}
Some methods leverage intermediate embeddings within the network. However, most do it to refine the head's detection capabilities, rather than for direct OoD detection. ASH~\cite{djurisic2023extremely} enhances the network's OoD detection capabilities through activation masking of hidden layers. Similarly, ReAct~\cite{sun2021react} proposes to rectify the embeddings of the penultimate layer to reduce overconfidence. However, despite leveraging intermediate embeddings to an extent, the final detection decisions in both methods rely solely on the output logits. Mahalanobis distance-based method (MDSEns)~\cite{lee2018simple} uses features from hidden layers to compute distances from the known distribution. However, this approach relies on the assumption that the class-conditional distributions of hidden layer features are Gaussian, which may not hold true for complex datasets and deep network architectures~\cite{venkataramanan2023gaussian}. Head2Toe~\cite{evci2022head2toe} leverages intermediate representations by training a classifier head on concatenated embeddings from multiple hidden layers to improve generalization during \textit{transfer learning}. This enables the refinement of existing OoD detection techniques through the utilization of hidden layer structures.