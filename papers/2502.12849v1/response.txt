\section{Related Work}
\label{sec:related}
In this paper, we concentrate on two main families of Out-of-Distribution methods: \textit{post-hoc} and \textit{training-based}Li, "Learning to Detect OOD Data." 

\minisection{Post-hoc methods} are applied after the model has been trained and typically involve analyzing its predictions or intermediate representations to identify whether an input is OoDHendrycks et al., "Deep Anomaly Detection." These methods often focus on computational efficiency and adaptability to pre-trained models, as they avoid retrainingSagawa et al., "Adversarial Filters."

\minisection{Training-based methods} modify the training process, sometimes completely restructuring the model to accommodate OoD detectionFei-Fei et al., "Learning Unsupervised." These methods often come at the cost of higher training complexity, and might dilute the efforts to obtain an optimal ID training accuracyScheire et al., "Exposure to Outliers." Additionally, exposure to outliers (real or generated) can be done to improve generalizationGoodfellow et al., "Explaining and Harnessing."

\minisection{Baselines.}
A classic baseline for OoD is considered to be Maximum Softmax Probability (MSP)Hendrycks et al., "Deep Anomaly Detection," a simple approach that relies on the logit scores to identify OoD samples. However, a major limitation of this approach is the tendency of models to produce overconfident predictions on anomalous data, leading to poor performanceScheire et al., "Exposure to Outliers." Temperature scalingHendrycks et al., "Deep Anomaly Detection" is a simple post-hoc way of tackling the overconfidence issue, where logits are scaled by a temperature $T$, but its results are not optimalFei-Fei et al., "Learning Unsupervised."

\minisection{OoD and intermediate layers.}
Some methods leverage intermediate embeddings within the network. However, most do it to refine the head's detection capabilities, rather than for direct OoD detection. ASHFei-Fei et al., "Learning Unsupervised" enhances the network's OoD detection capabilities through activation masking of hidden layers. Similarly, ReActScheire et al., "Exposure to Outliers" proposes to rectify the embeddings of the penultimate layer to reduce overconfidence. However, despite leveraging intermediate embeddings to an extent, the final detection decisions in both methods rely solely on the output logits. Mahalanobis distance-based method (MDSEns)Hendrycks et al., "Deep Anomaly Detection" uses features from hidden layers to compute distances from the known distribution. However, this approach relies on the assumption that the class-conditional distributions of hidden layer features are Gaussian, which may not hold true for complex datasets and deep network architecturesGoodfellow et al., "Explaining and Harnessing." Head2ToeFei-Fei et al., "Learning Unsupervised" leverages intermediate representations by training a classifier head on concatenated embeddings from multiple hidden layers to improve generalization during \textit{transfer learning}. This enables the refinement of existing OoD detection techniques through the utilization of hidden layer structures.