\section{Discussion and Conclusion}
\subsection{Experts Value AI Creative Support and Use Their Creativity Where AI Leaves Off}

We found that when AI presents a solution, that solution, unless obviously flawed, is generally adopted. 
The user then applies their creativity to the parts of the project not solved by AI. 
There may be something to be learned from other areas of design.
Lars Lerup, in a book called \emph{Building the Unfinished}, observed that the physical environment will change over time: for example, we renovate buildings \cite{lerup1977building}. 
Instead of designing something that is a finished product, it might be better to build it in a way that encourages or facilitates later modification. 
A contemporaneous and related idea from architecture has to do with planning and building incrementally rather than all at once \cite{alexander1977pattern}.

AI leaves many things unfinished. 
In the newsroom study, AI failed in spectacular ways, leaving people to complete the task. 
AI also does not know what the next trend will be. 
In the newsroom study, we saw how the results from the market research were immediately used by journalists to keep up with social media engagement trends that AI was unaware of. 
Creativity is about discovering what comes next, and so AI has not shown abilities to do that.

With all automated tools there is a fear that human skills will atrophy from disuse. 
However, in this study, we saw rampant use of creativity, especially where the tool left off. 
This incompleteness of AI could be thought of as a feature rather than a bug---it is an opportunity to keep us engaged with the tool. 
Future work might explore the different ways of leaving an artifact unfinished and their effects on the quality of the end product, the overall level of productivity, and the long-term effect on human skill. 

\subsection{Creating Vigilance to AI Errors}
AI makes errors. 
Often it makes obvious errors like using totally made up phrases. It was surprising to see that journalists, even professionals, filmed videos without fixing them. 
There seems to be a pervasive assumption that AI is an expert, even when AI is operating in a field in which the human is the expert and the AI is meant to play a supporting role. 

Whatever the reason for their deference, people need to develop a vigilance towards AI errors. 
AI is so easy to generate that it seems to lull us into System I reasoning~\cite{kahneman2011thinking}, where we think fast and mostly go with the flow. 
However, when working with AI, we need to develop ways to help people shift into System II reasoning, where we think slowly and think critically. 
System I is our natural state because it will take more than just willpower to develop this vigilance. 

Teams and organizations will have to design ways to avoid falling for AI errors. 
Editors are needed to be critical; editors will need to learn the new flaws that AI is introducing into creative work. 
For example, AI is known to lean toward cliches in creative domains ~\cite{tuhin_artifice, deepmind_humor}, known to make up phrases (as shown here), known to lack social context, and known to be bad at simple math~\cite{toolformer}. 
When possible, it might also be helpful to constantly track what text or images were AI-generated so editors know where to focus their attention.  

\subsection{Limitations and Future Work}
These studies attempt to explore AI at work in a newsroom, but we only studied one news team---and it was one that we assembled for this purpose. 
Although it had many of the traits of a real small-town newsroom, there are limitations in how much we can generalize to all newsrooms.  
Although the study lasted 14 weeks, there is no telling what would have happened if the study had continued after those 14 weeks. 
While we did not see any skill atrophy in the 14-week period, perhaps we would have after a year. 

This paper focused on one particular tool for one particular social media phenomenon, but different tools and trends may have different benefits and challenges. 
However, factors such as accepting AI errors seem to be pervasive problems. 
ReelFramer as a tool is certainly not perfect. If its workflow had been better, perhaps creators would not have had so many opportunities to be creative when it failed. 
However, the most important failures were the ones when the new reel form did not fit an article---which was not a property of the tool, but of the narrative form. 

It would be interesting future work to see if people were still using the tool in a year or whether they had embodied the news reel form so well the tool no longer brought them cognitive benefit. 
Or perhaps they might even find it too limiting over time, as they started to understand the design space and perhaps start to innovate on it. 
It would also be interesting to study how the team might improve the tool for themselves. 
Since the tool is basically a structured prompting technique, the creators could easily edit the tool by simply editing the prompts in the text. 
Another form of creativity would be to use prompts within the tool to innovate on the form.
