\section{Study 1 Findings: Newsroom Field Study}

\subsection{AI Usage: AI as a Creative Springboard}

Overall, the student group made 26 news reels, 16 of which were published by the editor. 
The 10 that were unpublished were still being iterated at the end of the session or had been abandoned (Section \ref{sec:AI_failure}).
Altogether, the 16 videos published by the team garnered over 500,000 views. 
Four of the five student journalists chose to use the tool for all or most of their videos. 
13 of 16 published videos used ReelFramer in a significant manner to help achieve an output the editor deemed publishable. 

\subsubsection{Reasons for AI Tool Usage}
Creators choose to use the AI tool a majority of the time---for 20 of 26 reels created.
Creators who chose to use the tool often described it as ``a creative springboard.'' 
There were two main uses. 

1. \textbf{Selecting the narrative framing and premise.} 
They all used the reframing features of ReelFramer to find the characters, premise, and key news facts in the web article that they could use to transform into a role-play script.  
They described this as a cognitively demanding task to ``see the story'' from a different narrative frame. ReelFramer's suggestions were typically accurate, creating a reliable premise for a script.

2. \textbf{Drafting multiple scripts.} 
They used the scriptwriting writing features of ReelFramer to initiate a draft of the script. 
However, the users consistently reported editing ``about half'' of the AI-generated script. 
They found they had to improve many of the writing mechanisms, such as taking out awkward phrases, increasing clarity, or removing lines with too little content. 
Overall, it was a helpful starting point.

On the other hand, none of the students used the storyboarding features, as they did not find this part of the task cognitively demanding. 
They said they could ``see'' how the story would be filmed and apparently did not use the prop, costume, or gesture suggestions---often because they were constrained by their personal set of potential props, costumes, and acting ability. 

\subsubsection{Reasons and Risks of Not Using the Tool}

Creators chose not to use the AI tool for 6 of the 26 reels made during the study. 
There were several legitimate reasons not to use the tool.
However, choosing not to use the tool sometimes resulted in problems.

1. \textbf{Strong understanding of the initial news story.} 
Two times, a participant who had used ReelFramer previously chose not to use the tool when making a news reel for a story they had reported. 
Because they conducted the initial research and interviews and framed the original written story, it was easier to understand the key points in the story and imagine it from multiple perspectives,  making it cognitively easier to reframe around a role-play narrative. 

2. \textbf{Task deemed easy.} P5 made his first news reel with ReelFramer but chose to make the other three without it because he understood the framework well enough to do it on his own. 
However, this decision had trade-offs. 
When the editor reviewed the reels made without ReelFramer, she appreciated several creative additions that the tool would not have suggested (Section \ref{sec:creativity}). 
However, the scripts were insufficient for publication---as they all lacked sufficient information about the story.
The task of creating news reels is often more difficult than it looks; balancing between information and entertainment is hard, and the tool seems to help balance those competing design requirements.

3. \textbf{Independent inspiration.} 
P2 typically used ReelFramer, but for his fourth video, he had an inspiration for a role-play narrative and developed the framing and script on his own. 
However, he deviated from the role-play framing and wrote the script as a monologue, which the editor and other creators found confusing.
Once he iterated to return it to role-play form, it was published.
This incident also shows the risks of not using the scaffolding provided by the tool, although this creator was able to recover.

4. \textbf{AI narratives inappropriate for a serious topic.}
P1 typically used ReelFramer, but for her second video, ReelFramer was not producing a narrative that was serious enough for her topic, which dealt with domestic abuse. 
ReelFramer's ``quirky'' and ``fun'' narratives clashed with the gravity of the topic. 
This clash led her to create the news reel on her own. 
However, she had written the initial news story, so she had a strong understanding of it, and she took inspiration from the tool and followed a role-play format that delivered three news facts. 
The editor approved it for publication, and this news reel received by far the most views. 
There could be many reasons for this success---topic, timing, luck, or unknown quirks of the platform's sharing algorithm. 
This is discussed in Section \ref{market_research}. 
Despite her success in making a news reel without the tool, she chose to return to using ReelFramer for all her future videos due to the cognitive support it provided.

Generally, the group was successful in their task, producing 16 news reels garnering over 500,000 views. 
The tool was treated as a creative springboard, assisting with cognitively demanding tasks of reframing a narrative, and writing a script that balanced entertainment and information. 
However, creators did not need a creative springboard when they had independent inspiration or when they had a strong understanding of the original web article. 
Additionally, when the tool failed to provide an appropriate framing or script, they had to fall back on their own creativity.

\begin{figure*}
\centering
\includegraphics[width=0.65\textwidth]{fig/rf_long_additions.png}
\caption{Creative additions made by humans that AI does and does not support.}
\label{fig:creative_adaptions}
\end{figure*}

\subsection{Role of Human Creativity: Human Creativity Where AI Left off}
\label{sec:creativity}

To understand when and how creators chose to use their own creativity rather than relying on AI, we analyzed all their creative additions made to news reels created during the study that ReelFramer did not (or could not) make.
Every week, when the editor reviewed news reels made by the creators (both published and unpublished), she noted all the instances when the creator did something creative outside of what ReelFramer suggested. 
After the study, we analyzed the types of tasks creators choose to innovate on, and found three clear groups of times when creators made creative additions. 

\subsubsection{Human Creativity to Improve AI Outputs} In the study, the editor noted a few tasks that were supported by AI, but for which the creators decided to improve with their own creativity by using their own framing or scriptwriting choices.

For framing, there were two times when a creator rejected AI character suggestions, and came up with characters that AI would not have: using an inanimate object (a gas pump, to talk about oil prices) or introducing characters not in the story (an Uber Driver, and a passenger to talk about a new bridge). 
For scriptwriting, one creator merged facts from two different web articles about the same topic (a local election) to tell a better story. 
ReelFramer only supported creating scripts from a single web article, so the creator had to add details to the script herself. 

Creators frequently had to edit AI's attempts at humor in scripts. AI often used puns, which creators did not like. 
In the middle of scripts, creators typically removed the attempted humor, but at the end of scripts, creators needed to come up with a new ending like saying something sarcastic. 
One creator added a curse word for emphasis said by a construction worker character. 
AI would never have suggested a curse word, and although the editor made him bleep it out before publishing, the audience still understood the effect, and it was a bold and creative choice.
Although editing humor was common, the other creative framing and scripting edits were rare---occurring in only 4 of the 26 news reels. 



\subsubsection{Human Creativity for Major AI Failures} 
\label{sec:AI_failure}
Major AI failures were rare---occurring in 3 of the 26 videos, but required significant creativity on the part of creators. 
In all three cases, AI made socially inappropriate suggestions because it lacked context of the story or the creators. 

The first story was about new doula services offered for expecting mothers. 
The original web story featured quotes and reactions from women of color, since they are disproportionately at risk during pregnancies.
AI suggested roleplaying characters from the story who were pregnant Black women. 
However, the creators did not feel like they could play this in a respectful way. 
But since the service is generally available for all people, they changed the characters to be people indirectly affected by the service (concerned family) and were able to report on the effects for women of all races. 
By creatively changing the characters, the creators were able to reframe the story in a socially appropriate way.

The second story was about domestic violence, which was a subject that was too serious for the lighthearted tone in the AI-suggested script.  
The creator chose to write the script herself, although she was able to creatively adapt the role-play framing by making the Domestic Women's Shelter the expert explaining the dangers of emergency alert testing to the ``naive'' FCC---emergency alerts can expose hidden phones that domestic abuse victims often have. 


The third, and most difficult case was when the team decided it was inappropriate to make a news reel out of a story. 
The article was titled ``Women’s Club Basketball Discusses What Black History Month Means to Them''. 
None of the journalists identified as both Black and female, and thus role-play style narrative felt socially inappropriate. 
Additionally, they did not want to reframe the narrative around a different set of characters because it would displace the voices of the very people it was trying to center. 
Ultimately, they decided that not making the reel was the right decision.

Although major AI failures were relatively rare, they required human creativity to detect and address them.



\subsubsection{Human Creativity Where AI Leaves off} 

In the study, the editor noted many tasks that were not supported by AI that creators decided to add their creativity to. 
This happened in 12 of 26 news reels (Figure \ref{fig:creative_adaptions}).
ReelFramer was designed to address the full creative process from framing to storyboarding. 
However, the creative process has no bounds, and the creators found many tasks to do creatively that the tool did not address.

There were four instances of creators \textbf{adding personality to the characters}, which was largely shown through acting ability. 
For example, making a teenager have an aggressively dismissive attitude about a new college program, to bring drama and realism to the character (as well as making it sound less like an advertisement).

There were three instances of \textbf{using props in highly effective ways}.
First, using a real dog or baby instead of a doll, and second, in an episode about a soup kitchen, had a chef-like character actually making a dish and using a different cooking utensil in every scene to show progress. 
None of these were suggested by AI, but were things creators realized they had on hand.

The market research done in week 10 (Section \ref{market_research}) revealed that the videos would be more interesting if there were more movement, especially at the beginning. 
Thus, in the last week, creators added two more \textbf{actions} to videos -- pouring maple syrup, jogging, and unwrapping food.

There were four other notable creative additions, like using \textbf{animations} of a truck for a story on monster trucks, adding \textbf{sound effects}, and adding \textbf{colored lights and captions} to reflect elements in a story.

Although the AI tool attempted to cover the entire creative process, creators found new dimensions where the tool left off, and they were able to add many of their own creative touches.


\subsection{AI Risks: Need for Training Humans to Critique due to AI Overreliance}
AI is widely known to produce errors---as are humans. 
The newsroom in this study had an editor who was in charge of quality control. 
This is typical of all newsrooms. 
Similar to typical editorial newsroom dynamics, creators submit drafts, receive critique and edits from the editor and have to iterate to produce a new draft. 
Iteration continues until the editor decides to publish the piece, or decide not to run it. 

To understand the nature of the edits, we tracked two things: the magnitude of the error (major, minor or none), and the attribution of the error (whether the error was introduced by the AI or the human journalist). 
For error magnitude, major edits are those that required reshooting the entire news reel; minor edits required reshooting only part of the video (e.g., a localized scene or dialog edits); no edits meant it was ready for publication.
Table \ref{learning_edits} shows the magnitude of edits for each news reel's first iteration.

We also tracked whether the errors were introduced by AI or by the creators, as judged by the editor from discussions with the creator.
If the script contained incorrect information, and the script was drafted by AI and edited by a creator, the editor attributed this error to being introduced by AI. 
Although it should have been caught by a human, it might not have needed to be caught if it had not been introduced by AI. 
However, if the human writes a script with incorrect information, this error is attributed to the human.


Surprisingly, a vast majority of the errors were introduced by the AI tool. 
11 of 15 major errors, and 15 of 19 minor errors were introduced by AI (Tables \ref{major_issues} and \ref{minor_issues}).
These errors were accepted by the creators, and they filmed news reels with these errors in them. 
Although it is expected that AI will make errors, and that many people using AI on a deadline might simply accept AI content at face value, skimming the content and not checking it carefully. 
However, this case is different---creators actually had to speak the lines AI wrote, so they were fully cognizant of the dialog they were including. 
This was true for both student journalists and professional journalists (Section \ref{findings_professionals}).
It was surprising to the editor because being critical is an essential aspect of journalism training.  

\begin{table}
\centering
\begin{adjustbox}{width=0.46\textwidth}
\begin{tabular}{|l|l|}
\hline
\multicolumn{2}{|c|}{\textbf{Major Issues (15)}} \\ \hline
\textbf{AI Attributed (11)} & \textbf{Non-AI Attributed (4)}        \\ \hline
too positive/promotional (4)                & slow paced (2)                        \\ 
too long (2)                                & confusing format - monologue (1)       \\ 
too few facts (2)                           & biased narrative (1)                      \\ 
unclear narrative (1)                       &                                       \\ 
too wordy (1)                               &                                       \\ 
abrupt intro (1)                            &                                       \\ \hline
\end{tabular}
\end{adjustbox}
\caption{Major Issues: AI vs Non-AI Attributed issues in news reels created in the newsroom study.}
\label{major_issues}
\end{table}



\begin{table}
\centering
\begin{adjustbox}{width=0.46\textwidth}
\begin{tabular}{|l|l|}
\hline
\multicolumn{2}{|c|}{\textbf{Minor Issues (19)}} \\ \hline
\textbf{AI Attributed (15)}          & \textbf{Non-AI Attributed(4)}                  \\ \hline
awkward AI phrase (4)                & labels too long (1)                  \\ 
confusing character names (3)        & added curse word (1)                 \\ 
ending lacks polish (2)              & add relevancy to the present (1)     \\ 
too positive/promotional (1)         & missing facts (1)                    \\ 
strays from news (1)                 &                                      \\ 
tone shift (1)                       &                                      \\ 
unclear/missing fact (2)             &                                      \\ 
unnecessary dialog (1)               &                                      \\ \hline
\end{tabular}
\end{adjustbox}
\caption{Minor Issues: AI vs Non-AI Attributed issues in news reels created in the newsroom study.}
\label{minor_issues}
\end{table}

The most common major issue was clearly attributed to the AI tool---sounding too positive. 
The AI is trying to balance entertainment and information in a ``quirky'' way, and the stories should not sound sad and serious like traditional evening news anchors.
However, the AI leaned too heavily toward a positive tone and this bias clashed with the content in different ways. 
For stories that were serious or sad (stories about homelessness, domestic violence, or climate change), the ``quirky'' tone was inappropriate for the topic. 
For many lighter stories---like a small town winning an award for being charming---AI's positive tone was also a problem. 
The positive tone made the video feel like an advertisement rather than news. 
In all cases, the team had to find creative ways to fix the narratives to be more appropriate. 

The most common minor issue clearly attributed to the AI tool (and accepted by creators) was including bizarre and awkward AI phrases.
These stick out badly and are fairly localized changes to make, so the effort to change them should have been minimal. 
Phrases like \textit{``a little bird told me'}' are awkward AI phrases that were inappropriate for a news reel because all news should make some effort to attribute information to sources. 
Other awkward phrases include \textit{``a comedy of wonders''} and distracting attempts at wordplay such as \textit{``a two-tiered system? is that kind getting rewarded with two kinds of deserts?''}
When asked why they included these phrases, the typical response was ``I guess it seemed OK.''

This acceptance indicates an implicit trust in the AI, even when AI does a task in the creator's realm of expertise. 
A crucial role of human creativity is to be critical of AI outputs.
Even journalists who are trained to be critical may require additional training to learn to be critical in this new way.


\subsection{Human Creative Role Over Time}
We also tracked the magnitude and attribution of errors in the first iteration of all 26 news reels to track errors over time. 
As expected, every creator's first video required major edits, but later videos needed more minor edits, or even no edits.

\color{black}

\begin{table}
\centering
\begin{adjustbox}{width=0.48\textwidth}
\begin{tabular}{|l|l|l|l|l|l|l|}
\hline
\textbf{Participant} & \textbf{Article 1} & \textbf{Article 2} & \textbf{Article 3} & \textbf{Article 4} & \textbf{Article 5} & \textbf{Article 6} \\ \hline
\textbf{P1}      & \color{red}\textbf{Major}\color{black}               & Minor              & Minor              & Minor              & \color{teal}No edits \color{black}              & \color{teal}No edits \color{black}               \\ \hline
\textit{AI errors}   & 2                  & 1                  & 1                  & 1                  &                    &                    \\ 
\textit{Non-AI errors} & 1                & 1                  &                    &                    &                    &                    \\ \hline
\textbf{P2}        & \color{red}\textbf{Major}\color{black}               & Minor              & \color{red}\textbf{Major}\color{black}              & \color{red}\textbf{Major}\color{black}               & \color{red}\textbf{Major}\color{black}               & Minor              \\ \hline
\textit{AI errors}   & 3                  & 1                  & 3                  &                    & 1                  &                    \\ 
\textit{Non-AI errors} &                  &                    &                    & 1                  &                    & 1                  \\ \hline
\textbf{P3}      & \color{red}\textbf{Major}\color{black}              & Minor              & Minor              & \color{red}\textbf{Major}\color{black}               &       /            &     /                \\ \hline
\textit{AI errors}   & 3                  & 2                  & 2                  & 2                  &         /            &         /            \\ 
\textit{Non-AI errors} &                  &                     &                    &                    &    /                &      /             \\ \hline
\textbf{P4}       & \color{red}\textbf{Major}\color{black}               & Minor              & \color{red}\textbf{Major}\color{black}               & Minor              & Minor              & \color{teal}No edits \color{black}               \\ \hline
\textit{AI errors}   & 1                  & 1                  & 2                  & 1                  & 1                  &                    \\ 
\textit{Non-AI errors} &                  &                    &                    &                    &                    &                    \\ \hline
\textbf{P5}        & \color{red}\textbf{Major}\color{black}               & \color{red}\textbf{Major}\color{black}               & \color{red}\textbf{Major}\color{black}               & Minor              &     /               &              /     \\ \hline
\textit{AI errors}   & 2                  &                    &                    &                    &     /               &      /              \\ 
\textit{Non-AI errors} & 1                & 1                  & 1                  & 1                  &      /              &      /              \\ \hline
\end{tabular}
\end{adjustbox}
\caption{Classification of the amount of editing needed for news reels made for each article and each participant. Edits were either major (requiring a full reshoot), minor (localized scene or line edits) or no edits. Errors are broken into those introduced by AI (and accepted by creators without realizing), or errors not introduced by AI. Cells filled with a slash indicate creators did not make news reels (some participants made more than others).}
\label{learning_edits}
\end{table}

\subsubsection{Learning the Limits of the Tool, and Reasserting Professional Standards}
Early news reels were problematic because the news conveyed in them was unclear.
This was likely due to a combination of problems: being too long, having meaningless dialog lines, and not containing enough facts. 
Additionally, when the tone was too positive, the reels felt like ads, not news, and when the roles of the characters were unclear, the video was hard to follow. 
All these problems could be attributed to AI, and creators' early over-reliance on the tool. 
Through conversations with the editor and each other, they were able to overcome this. 
It seemed to be correlated with both more group and editorial critique, as well as students having a better mental model of the strengths and weaknesses of the tool through repeated usage. 
The editor pointed out that \textit{``at some point [the students] were able to anticipate what the tool was going to suggest (to a point) because they understood how it was translating between genres [web stories to reels].''} 

In the early videos, students often ``miss the heart of the story.''
For example, in a video about falling gas prices, the student ``missed the main connection between the winter months and the change in gas prices''. 
Many exchanges in the early videos are wordy and contentless and do not help convey the news.
It was important for students to understand the “news value” so the videos focused on the information rather than entertainment. 
The editor said that the students' ``learning/improvement happened when they made connections between the tool and their occupational standards.'' 
Balancing between news and entertainment was one of the goals of the tool, and whereas it did help, it was still important for the creators to have their own understanding of this, so they could make good edits to what the tool was suggesting.

\color{black}


\subsubsection{Learning from market research}
In week 10 of the newsroom study, the team was given a report from the market research team detailing ways their news reels could be improved. 
This included more attention-grabbing elements early in the video, and more character motion-like actions within the scene (Section \ref{market_research}). 
These suggestions provided valuable insights because these were all emerging trends appearing in non-news-based social media videos that had not yet become integrated with news reels and were imbued into ReelFramer. 
Since news reels have to compete for attention with all the other reels, they will eventually have to adopt these trends to maintain their audience. 

Working as a team, the creators brainstormed relevant actions they could put in their current videos and found several compelling ways to do this. 
For an article about tapping maple syrup trees early due to global warming, the video started with the character pouring syrup on waffles while talking. 
Another video about the opening of baseball season had several characters using props and doing simple, yet interesting actions like unwrapping food. 
A third added fun animation of a truck for a story about a monster truck rally. 

The market research feedback was insightful, relevant and easy to apply. 
It was also outside the scope of AI, which cannot keep up with emerging trends. 
