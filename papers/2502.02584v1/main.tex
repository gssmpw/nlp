%%%%%%%% ICML 2025 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}

% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{template/math_commands.tex}
\input{paper/notation}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{float}
\usepackage{booktabs} % for professional tables

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2025} with \usepackage[nohyperref]{icml2025} above.
\usepackage{hyperref}


% Attempt to make hyperref and algorithmic work together better:
% \newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
% \usepackage{icml2025}

% If accepted, instead use the following line for the camera-ready submission:
\usepackage[accepted]{icml2025}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
% \usepackage{algpseudocode}
% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}
\usepackage[textsize=tiny]{todonotes}

\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{algorithm}
\usepackage{algorithmic}
 
\newlength\myindent
\setlength\myindent{2em}
\newcommand\bindent{%
    \begingroup
    \setlength{\itemindent}{\myindent}
    \addtolength{\algorithmicindent}{\myindent}
}
\newcommand\eindent{\endgroup}

\usepackage{wrapfig}

\usepackage{verbatim}
\usepackage{multirow}
\usepackage{multicol}
\usepackage{booktabs, multirow} % for borders and merged ranges
\usepackage{soul}% for underlines
\usepackage{changepage,threeparttable} % for wide tables

% \title{Q* AGENT: Explicit Q-learning Makes A More Generalized LLM Agent}
% \title{{\ours}: Scaling inference-time compute of Language Agents Via Q-guided Exploration}

% Authors must not appear in the submitted version. They should be hidden
% as long as the \iclrfinalcopy macro remains commented out below.
% Non-anonymous submissions will be rejected without review.
\author{Zongyu Lin$^{1}$$^\star$ \and Yao Tang$^{1}$$^\star$\thanks{This work was done during her visit at UCLA. \\ \quad $^{1}$First authors  \quad $^\diamond$Co-Senior authors} \and
Da Yin$^{1}$$^\star$ \and
Xingcheng Yao$^{1}$$^\star$ \and
Ziniu Hu$^\star$ \and
\quad Yizhou Sun$^\diamond$$^\star$ \quad Kai-Wei Chang$^\diamond$$^\star$\\[1em]
\quad $^\star$University of California, Los Angeles
}
\usepackage[textsize=tiny]{todonotes}
\usepackage{ulem}
\usepackage{fdsymbol}


\DeclareMathOperator*{\arginf}{arg\inf}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}
\newcommand{\YS}[1]{\textcolor{red}{[YS: #1]}}

%\iclrfinalcopy % Uncomment for camera-ready version, but NOT for submission.
\icmltitlerunning{QLASS: Boosting Language Agent Inference via Q-Guided Stepwise Search}

\begin{document}

\twocolumn[
% \icmltitle{{\ours}: Boosting Language Agent Inference via Q-Guided Stepwise Search}
\icmltitle{{\ours}: Boosting Language Agent Inference via Q-Guided Stepwise Search}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2025
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
\icmlsetsymbol{equal}{*}
\icmlsetsymbol{advisor}{$\dagger$}

\begin{icmlauthorlist}
  \icmlauthor{Zongyu Lin}{ucla,equal}
  \icmlauthor{Yao Tang}{sjtu,equal}
  \icmlauthor{Xingcheng Yao}{ucla,equal}
  \icmlauthor{Da Yin}{ucla,equal}
  \icmlauthor{Ziniu Hu}{ucla}
  \icmlauthor{Yizhou Sun}{ucla,advisor}
  \icmlauthor{Kai-Wei Chang}{ucla,advisor}
\end{icmlauthorlist}

\icmlaffiliation{ucla}{University of California, Los Angeles, USA}
\icmlaffiliation{sjtu}{Shanghai Jiaotong University, Shanghai, China}

\icmlcorrespondingauthor{Yizhou Sun}{yizhou.sun@ucla.edu}
\icmlcorrespondingauthor{Kai-Wei Chang}{kaiwei.chang@ucla.edu}

\icmlkeywords{Machine Learning, ICML}

\vskip 0.3in
]
\printAffiliationsAndNotice{%
  * Equal contribution. $\dagger$ Equal advising.
}

% \maketitle

\input{paper/0-abstract}
\input{paper/1-introduction}
\input{paper/2-relatedwork}
\input{paper/3-0preliminary}
\input{paper/3-1method}
\input{paper/4-experiment}
\input{paper/5-conclusion}

\begin{thebibliography}{41}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Bansal et~al.(2024)Bansal, Lin, Xie, Zong, Yarom, Bitton, Jiang, Sun, Chang, and Grover]{bansal2024videophy}
Bansal, H., Lin, Z., Xie, T., Zong, Z., Yarom, M., Bitton, Y., Jiang, C., Sun, Y., Chang, K.-W., and Grover, A.
\newblock Videophy: Evaluating physical commonsense for video generation.
\newblock \emph{arXiv preprint arXiv:2406.03520}, 2024.

\bibitem[Bellman \& Dreyfus(2015)Bellman and Dreyfus]{bellman2015applied}
Bellman, R.~E. and Dreyfus, S.~E.
\newblock \emph{Applied dynamic programming}, volume 2050.
\newblock Princeton university press, 2015.

\bibitem[Chen et~al.(2023)Chen, Shu, Shareghi, Collier, Narasimhan, and Yao]{chen2023fireact}
Chen, B., Shu, C., Shareghi, E., Collier, N., Narasimhan, K., and Yao, S.
\newblock Fireact: Toward language agent fine-tuning.
\newblock \emph{arXiv preprint arXiv:2310.05915}, 2023.

\bibitem[Chen et~al.(2024)Chen, Zhao, Zhu, Zhang, Li, Raj, and Yao]{autoprm-chen-etal-2024}
Chen, Z., Zhao, Z., Zhu, Z., Zhang, R., Li, X., Raj, B., and Yao, H.
\newblock {A}uto{PRM}: Automating procedural supervision for multi-step reasoning via controllable question decomposition.
\newblock In Duh, K., Gomez, H., and Bethard, S. (eds.), \emph{Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)}, pp.\  1346--1362, Mexico City, Mexico, June 2024. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2024.naacl-long.73}.
\newblock URL \url{https://aclanthology.org/2024.naacl-long.73}.

\bibitem[Dou et~al.(2024)Dou, Yang, Wu, Chang, and Peng]{dou2024re-rest}
Dou, Z.-Y., Yang, C.-F., Wu, X., Chang, K.-W., and Peng, N.
\newblock Reflection-reinforced self-training for language agents.
\newblock \emph{arXiv preprint arXiv:2406.01495}, 2024.

\bibitem[Feng et~al.(2023)Feng, Wan, Wen, Wen, Zhang, and Wang]{tsllm}
Feng, X., Wan, Z., Wen, M., Wen, Y., Zhang, W., and Wang, J.
\newblock Alphazero-like tree-search can guide large language model decoding and training.
\newblock \emph{arXiv preprint arXiv:2309.17179}, 2023.

\bibitem[Gulcehre et~al.(2023)Gulcehre, Paine, Srinivasan, Konyushkova, Weerts, Sharma, Siddhant, Ahern, Wang, Gu, Macherey, Doucet, Firat, and de~Freitas]{gulcehre2023rest}
Gulcehre, C., Paine, T.~L., Srinivasan, S., Konyushkova, K., Weerts, L., Sharma, A., Siddhant, A., Ahern, A., Wang, M., Gu, C., Macherey, W., Doucet, A., Firat, O., and de~Freitas, N.
\newblock Reinforced self-training (rest) for language modeling, 2023.
\newblock URL \url{https://arxiv.org/abs/2308.08998}.

\bibitem[Guo et~al.(2025)Guo, Yang, Zhang, Song, Zhang, Xu, Zhu, Ma, Wang, Bi, et~al.]{guo2025deepseek}
Guo, D., Yang, D., Zhang, H., Song, J., Zhang, R., Xu, R., Zhu, Q., Ma, S., Wang, P., Bi, X., et~al.
\newblock Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning.
\newblock \emph{arXiv preprint arXiv:2501.12948}, 2025.

\bibitem[Hosseini et~al.(2024)Hosseini, Yuan, Malkin, Courville, Sordoni, and Agarwal]{vstar}
Hosseini, A., Yuan, X., Malkin, N., Courville, A., Sordoni, A., and Agarwal, R.
\newblock V-star: Training verifiers for self-taught reasoners.
\newblock \emph{arXiv preprint arXiv:2402.06457}, 2024.

\bibitem[Jin et~al.(2018)Jin, Allen-Zhu, Bubeck, and Jordan]{NEURIPS2018_inefficentQ}
Jin, C., Allen-Zhu, Z., Bubeck, S., and Jordan, M.~I.
\newblock Is q-learning provably efficient?
\newblock In Bengio, S., Wallach, H., Larochelle, H., Grauman, K., Cesa-Bianchi, N., and Garnett, R. (eds.), \emph{Advances in Neural Information Processing Systems}, volume~31. Curran Associates, Inc., 2018.
\newblock URL \url{https://proceedings.neurips.cc/paper_files/paper/2018/file/d3b1fb02964aa64e257f9f26a31f72cf-Paper.pdf}.

\bibitem[Lightman et~al.(2023)Lightman, Kosaraju, Burda, Edwards, Baker, Lee, Leike, Schulman, Sutskever, and Cobbe]{verifystepbystep}
Lightman, H., Kosaraju, V., Burda, Y., Edwards, H., Baker, B., Lee, T., Leike, J., Schulman, J., Sutskever, I., and Cobbe, K.
\newblock Let's verify step by step.
\newblock \emph{arXiv preprint arXiv:2305.20050}, 2023.

\bibitem[Putta et~al.(2024)Putta, Mills, Garg, Motwani, Finn, Garg, and Rafailov]{putta2024agentq}
Putta, P., Mills, E., Garg, N., Motwani, S., Finn, C., Garg, D., and Rafailov, R.
\newblock Agent q: Advanced reasoning and learning for autonomous ai agents.
\newblock \emph{arXiv preprint arXiv:2408.07199}, 2024.

\bibitem[Rafailov et~al.(2024)Rafailov, Sharma, Mitchell, Manning, Ermon, and Finn]{rafailov2024direct}
Rafailov, R., Sharma, A., Mitchell, E., Manning, C.~D., Ermon, S., and Finn, C.
\newblock Direct preference optimization: Your language model is secretly a reward model.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem[Schulman et~al.(2017)Schulman, Wolski, Dhariwal, Radford, and Klimov]{schulman2017proximal}
Schulman, J., Wolski, F., Dhariwal, P., Radford, A., and Klimov, O.
\newblock Proximal policy optimization algorithms.
\newblock \emph{arXiv preprint arXiv:1707.06347}, 2017.

\bibitem[Setlur et~al.(2024)Setlur, Garg, Geng, Garg, Smith, and Kumar]{setlur2024-8fold}
Setlur, A., Garg, S., Geng, X., Garg, N., Smith, V., and Kumar, A.
\newblock Rl on incorrect synthetic data scales the efficiency of llm math reasoning by eight-fold.
\newblock \emph{arXiv preprint arXiv:2406.14532}, 2024.

\bibitem[Shen et~al.(2024)Shen, Song, Tan, Li, Lu, and Zhuang]{shen2024hugginggpt}
Shen, Y., Song, K., Tan, X., Li, D., Lu, W., and Zhuang, Y.
\newblock Hugginggpt: Solving ai tasks with chatgpt and its friends in hugging face.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem[Shinn et~al.(2023)Shinn, Cassano, Gopinath, Narasimhan, and Yao]{shinn2023reflexion}
Shinn, N., Cassano, F., Gopinath, A., Narasimhan, K.~R., and Yao, S.
\newblock Reflexion: language agents with verbal reinforcement learning.
\newblock In \emph{Thirty-seventh Conference on Neural Information Processing Systems}, 2023.
\newblock URL \url{https://openreview.net/forum?id=vAElhFcKW6}.

\bibitem[Shridhar et~al.(2021)Shridhar, Yuan, Cote, Bisk, Trischler, and Hausknecht]{shridhar2021alfworld}
Shridhar, M., Yuan, X., Cote, M.-A., Bisk, Y., Trischler, A., and Hausknecht, M.
\newblock {\{}ALFW{\}}orld: Aligning text and embodied environments for interactive learning.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[Singh et~al.(2023)Singh, Co-Reyes, Agarwal, Anand, Patil, Liu, Harrison, Lee, Xu, Parisi, et~al.]{singh2023rest-em}
Singh, A., Co-Reyes, J.~D., Agarwal, R., Anand, A., Patil, P., Liu, P.~J., Harrison, J., Lee, J., Xu, K., Parisi, A., et~al.
\newblock Beyond human data: Scaling self-training for problem-solving with language models.
\newblock \emph{arXiv preprint arXiv:2312.06585}, 2023.

\bibitem[Snell et~al.(2024)Snell, Lee, Xu, and Kumar]{snell2024scaling}
Snell, C., Lee, J., Xu, K., and Kumar, A.
\newblock Scaling llm test-time compute optimally can be more effective than scaling model parameters.
\newblock \emph{arXiv preprint arXiv:2408.03314}, 2024.

\bibitem[Song et~al.(2023)Song, Xiong, Zhu, Wu, Qian, Song, Huang, Li, Wang, Yao, et~al.]{song2023restgpt}
Song, Y., Xiong, W., Zhu, D., Wu, W., Qian, H., Song, M., Huang, H., Li, C., Wang, K., Yao, R., et~al.
\newblock Restgpt: Connecting large language models with real-world restful apis.
\newblock \emph{arXiv preprint arXiv:2306.06624}, 2023.

\bibitem[Song et~al.(2024)Song, Yin, Yue, Huang, Li, and Lin]{song-etal-2024-eto}
Song, Y., Yin, D., Yue, X., Huang, J., Li, S., and Lin, B.~Y.
\newblock Trial and error: Exploration-based trajectory optimization of {LLM} agents.
\newblock In Ku, L.-W., Martins, A., and Srikumar, V. (eds.), \emph{Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)}, pp.\  7584--7600, Bangkok, Thailand, August 2024. Association for Computational Linguistics.
\newblock URL \url{https://aclanthology.org/2024.acl-long.409}.

\bibitem[Sutton(1988)]{sutton1988learning}
Sutton, R.~S.
\newblock Learning to predict by the methods of temporal differences.
\newblock \emph{Machine learning}, 3:\penalty0 9--44, 1988.

\bibitem[Team et~al.(2025)Team, Du, Gao, Xing, Jiang, Chen, Li, Xiao, Du, Liao, et~al.]{team2025kimi}
Team, K., Du, A., Gao, B., Xing, B., Jiang, C., Chen, C., Li, C., Xiao, C., Du, C., Liao, C., et~al.
\newblock Kimi k1. 5: Scaling reinforcement learning with llms.
\newblock \emph{arXiv preprint arXiv:2501.12599}, 2025.

\bibitem[Uesato et~al.(2022)Uesato, Kushman, Kumar, Song, Siegel, Wang, Creswell, Irving, and Higgins]{mathprocessoutcome}
Uesato, J., Kushman, N., Kumar, R., Song, F., Siegel, N., Wang, L., Creswell, A., Irving, G., and Higgins, I.
\newblock Solving math word problems with process- and outcome-based feedback, 2022.

\bibitem[Wang et~al.(2024)Wang, Deng, Lv, Yan, and Bo]{wang2024q*}
Wang, C., Deng, Y., Lv, Z., Yan, S., and Bo, A.
\newblock Q*: Improving multi-step reasoning for llms with deliberative planning.
\newblock \emph{arXiv preprint arXiv:2406.14283}, 2024.

\bibitem[Wang et~al.(2023)Wang, Li, Shao, Xu, Dai, Li, Chen, Wu, and Sui]{math-shepherd}
Wang, P., Li, L., Shao, Z., Xu, R., Dai, D., Li, Y., Chen, D., Wu, Y., and Sui, Z.
\newblock Math-shepherd: A label-free step-by-step verifier for llms in mathematical reasoning.
\newblock \emph{arXiv preprint arXiv:2312.08935}, 2023.

\bibitem[Wang et~al.(2022{\natexlab{a}})Wang, Jansen, C{\^o}t{\'e}, and Ammanabrolu]{wang2022scienceworld}
Wang, R., Jansen, P., C{\^o}t{\'e}, M.-A., and Ammanabrolu, P.
\newblock {S}cience{W}orld: Is your agent smarter than a 5th grader?
\newblock In Goldberg, Y., Kozareva, Z., and Zhang, Y. (eds.), \emph{Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing}, pp.\  11279--11298, Abu Dhabi, United Arab Emirates, December 2022{\natexlab{a}}. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2022.emnlp-main.775}.
\newblock URL \url{https://aclanthology.org/2022.emnlp-main.775}.

\bibitem[Wang et~al.(2022{\natexlab{b}})Wang, Lin, Liu, ZHeng, Wen, Chen, Chen, and Yang]{wang2022learning}
Wang, Z., Lin, Z., Liu, P., ZHeng, G., Wen, J., Chen, X., Chen, Y., and Yang, Z.
\newblock Learning to detect noisy labels using model-based features.
\newblock \emph{arXiv preprint arXiv:2212.13767}, 2022{\natexlab{b}}.

\bibitem[Watkins \& Dayan(1992)Watkins and Dayan]{qlearning}
Watkins, C.~J. and Dayan, P.
\newblock Q-learning.
\newblock \emph{Machine learning}, 8:\penalty0 279--292, 1992.

\bibitem[Wei et~al.(2022)Wei, Wang, Schuurmans, Bosma, Xia, Chi, Le, Zhou, et~al.]{cot}
Wei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F., Chi, E., Le, Q.~V., Zhou, D., et~al.
\newblock Chain-of-thought prompting elicits reasoning in large language models.
\newblock \emph{Advances in neural information processing systems}, 35:\penalty0 24824--24837, 2022.

\bibitem[Wu et~al.(2024)Wu, Lin, Zhao, Wu, Lu, Peng, and Chang]{wu2024vdebugger}
Wu, X., Lin, Z., Zhao, S., Wu, T.-L., Lu, P., Peng, N., and Chang, K.-W.
\newblock Vdebugger: Harnessing execution feedback for debugging visual programs.
\newblock \emph{arXiv preprint arXiv:2406.13444}, 2024.

\bibitem[Xu et~al.(2022)Xu, Lin, Zhou, Zheng, and Yang]{xu2022universal}
Xu, H., Lin, Z., Zhou, J., Zheng, Y., and Yang, Z.
\newblock A universal discriminator for zero-shot generalization.
\newblock \emph{arXiv preprint arXiv:2211.08099}, 2022.

\bibitem[Yao et~al.(2022)Yao, Chen, Yang, and Narasimhan]{yao2022webshop}
Yao, S., Chen, H., Yang, J., and Narasimhan, K.
\newblock Webshop: Towards scalable real-world web interaction with grounded language agents.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 20744--20757, 2022.

\bibitem[Yao et~al.(2023)Yao, Zhao, Yu, Du, Shafran, Narasimhan, and Cao]{yao2023react}
Yao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan, K.~R., and Cao, Y.
\newblock React: Synergizing reasoning and acting in language models.
\newblock In \emph{The Eleventh International Conference on Learning Representations}, 2023.

\bibitem[Yin et~al.(2024)Yin, Brahman, Ravichander, Chandu, Chang, Choi, and Lin]{yin2024lumos}
Yin, D., Brahman, F., Ravichander, A., Chandu, K., Chang, K.-W., Choi, Y., and Lin, B.~Y.
\newblock Agent lumos: Unified and modular training for open-source language agents.
\newblock In Ku, L.-W., Martins, A., and Srikumar, V. (eds.), \emph{Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)}, pp.\  12380--12403, Bangkok, Thailand, August 2024. Association for Computational Linguistics.
\newblock URL \url{https://aclanthology.org/2024.acl-long.670}.

\bibitem[Yuan et~al.(2024)Yuan, Li, Chen, Cui, Ding, Zhang, Zhou, Liu, and Peng]{yuan2024free}
Yuan, L., Li, W., Chen, H., Cui, G., Ding, N., Zhang, K., Zhou, B., Liu, Z., and Peng, H.
\newblock Free process rewards without process labels.
\newblock \emph{arXiv preprint arXiv:2412.01981}, 2024.

\bibitem[Yuan et~al.(2023)Yuan, Yuan, Li, Dong, Lu, Tan, Zhou, and Zhou]{yuan2023RFT}
Yuan, Z., Yuan, H., Li, C., Dong, G., Lu, K., Tan, C., Zhou, C., and Zhou, J.
\newblock Scaling relationship on learning mathematical reasoning with large language models.
\newblock \emph{arXiv preprint arXiv:2308.01825}, 2023.

\bibitem[Zhai et~al.(2024)Zhai, Yang, Xu, Dawei, Yang, Ding, and Wang]{zhai2024enhancing}
Zhai, Y., Yang, T., Xu, K., Dawei, F., Yang, C., Ding, B., and Wang, H.
\newblock Enhancing decision-making for llm agents via step-level q-value models.
\newblock \emph{arXiv preprint arXiv:2409.09345}, 2024.

\bibitem[Zhang et~al.(2024)Zhang, Zhoubian, Hu, Yue, Dong, and Tang]{zhang2024rest-mcts}
Zhang, D., Zhoubian, S., Hu, Z., Yue, Y., Dong, Y., and Tang, J.
\newblock Re{ST}-{MCTS}*: {LLM} self-training via process reward guided tree search.
\newblock In \emph{The Thirty-eighth Annual Conference on Neural Information Processing Systems}, 2024.
\newblock URL \url{https://openreview.net/forum?id=8rcFOqEud5}.

\bibitem[Zhou et~al.(2024)Zhou, Yan, Shlapentokh-Rothman, Wang, and Wang]{zhou2024language}
Zhou, A., Yan, K., Shlapentokh-Rothman, M., Wang, H., and Wang, Y.-X.
\newblock Language agent tree search unifies reasoning, acting, and planning in language models.
\newblock In \emph{Forty-first International Conference on Machine Learning}, 2024.
\newblock URL \url{https://openreview.net/forum?id=njwv9BsGHF}.

\end{thebibliography}

% \bibliography{main}
% \bibliographystyle{icml2025}
\newpage
\input{paper/6-appendix}



\end{document}


% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was created
% by Iain Murray in 2018, and modified by Alexandre Bouchard in
% 2019 and 2021 and by Csaba Szepesvari, Gang Niu and Sivan Sabato in 2022.
% Modified again in 2023 and 2024 by Sivan Sabato and Jonathan Scarlett.
% Previous contributors include Dan Roy, Lise Getoor and Tobias
% Scheffer, which was slightly modified from the 2010 version by
% Thorsten Joachims & Johannes Fuernkranz, slightly modified from the
% 2009 version by Kiri Wagstaff and Sam Roweis's 2008 version, which is
% slightly modified from Prasad Tadepalli's 2007 version which is a
% lightly changed version of the previous year's version by Andrew
% Moore, which was in turn edited from those of Kristian Kersting and
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.
