\section{Related Work}
\label{sec:re}
\subsection{Sound Generation}
First, we discuss monaural sound generation. Recent advancements in universal sound generation, such as AudioLDM \cite{liu2023audioldm,liu2024audioldm} and Tango \cite{ghosal2023tango,majumder2024tango}, have already been discussed. In addition, related monaural sound generation works can be categorized based on input types (text, image, video) and output types (speech, music, universal sound). These input-output combinations lead to various tasks, such as text to speech \cite{tan2024naturalspeech}, text to music \cite{chen2024musicldm}, image to music \cite{wang2023continuous}, video to audio \cite{ghose2023foleygan}, and text to audible video \cite{liu2023sounding}, etc.

Regarding binaural sound generation, both MusicGen \cite{copet2024simple} and Stable Audio \cite{evans2024stable} can produce binaural audio without relying on monaural reference audio. However, they lack the ability to specify the precise locations of sound events, i.e., the spatial perception is randomly generated. In contrast, with monaural reference audio, the spatial control information can be classified into different input modalities. The input in \cite{richard2021neural, leng2022binauralgrad} is location values (DOA or quaternion), while the input in \cite{gao20192, li2024cross, li2024cyclic} is video, aligning the spatial perception of sound events with the visual scene.

\subsection{Sound Separation and Localization}
The monaural-to-binaural approach in \cite{gao20192, li2024cross, li2024cyclic} follows a paradigm where monaural audio is treated as a mixture of binaural audio. It separates the two channels from monaural audio using a method similar to speech separation \cite{wang2018supervised}. Their training objective is a complex mask or complex ideal ratio mask (cIRM) \cite{williamson2016complex} derived from speech separation. From the input-output perspective, the text-driven monaural-to-binaural generation is similar to text-driven target sound separation \cite{liu2022separate,liu2024separate,ma2024clapsep,ma2024language}, both being audio-to-audio conversion tasks controlled by text.

From the time delay perspective, the input audio used in \cite{richard2021neural, leng2022binauralgrad} involves the warping of the monaural audio, which is a technique of adding time delay from the sound source to the ears. This is similar to the concept of direct sound in dereverberation tasks \cite{zhao2024multi, guo2024graph}. From a spatial information perspective, the monaural-to-binaural task can be seen as generating spatial information for sound, while sound source localization \cite{feng2023soft,feng2024learning,feng2025eliminating} is the task of recognizing spatial information from sound.
% Therefore, monaural-to-binaural generation can be viewed as a reverse dereverberation process, where the warping is enhanced with attenuation, reflections, and scattering effects.