@misc{simon2024interplmdiscoveringinterpretablefeatures,
      title={InterPLM: Discovering Interpretable Features in Protein Language Models via Sparse Autoencoders}, 
      author={Elana Simon and James Zou},
      year={2024},
      eprint={2412.12101},
      archivePrefix={arXiv},
      primaryClass={q-bio.BM},
}

@misc{vig2021bertologymeetsbiologyinterpreting,
      title={BERTology Meets Biology: Interpreting Attention in Protein Language Models}, 
      author={Jesse Vig and Ali Madani and Lav R. Varshney and Caiming Xiong and Richard Socher and Nazneen Fatema Rajani},
      year={2021},
      eprint={2006.15222},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
}

@article {Zhang2024,
	author = {Zhang, Zhidian and Wayment-Steele, Hannah K. and Brixi, Garyk and Wang, Haobo and Dal Peraro, Matteo and Kern, Dorothee and Ovchinnikov, Sergey},
	title = {Protein language models learn evolutionary statistics of interacting sequence motifs},
	elocation-id = {2024.01.30.577970},
	year = {2024},
	doi = {10.1101/2024.01.30.577970},
	publisher = {Cold Spring Harbor Laboratory},
	abstract = {Protein language models (pLMs) have emerged as potent tools for predicting and designing protein structure and function, and the degree to which these models fundamentally understand the inherent biophysics of protein structure stands as an open question. Motivated by a discovery that pLM-based structure predictors erroneously predict nonphysical structures for protein isoforms, we investigated the nature of sequence context needed for contact predictions in the pLM ESM-2. We demonstrate by use of a {\textquotedblleft}categorical Jacobian{\textquotedblright} calculation that ESM-2 stores statistics of coevolving residues, analogously to simpler modelling approaches like Markov Random Fields and Multivariate Gaussian models. We further investigated how ESM-2 {\textquotedblleft}stores{\textquotedblright} information needed to predict contacts by comparing sequence masking strategies, and found that providing local windows of sequence information allowed ESM-2 to best recover predicted contacts. This suggests that pLMs predict contacts by storing motifs of pairwise contacts. Our investigation highlights the limitations of current pLMs and underscores the importance of understanding the underlying mechanisms of these models.Significance Statement Protein language models (pLMs) have exhibited remarkable capabilities in protein structure prediction and design. However, the extent to which they comprehend the intrinsic biophysics of protein structures remains uncertain. We present a suite of analyses that dissect how the flagship pLM ESM-2 predicts structure. Motivated by a consistent error of protein isoforms predicted as structured fragments, we developed a completely unsupervised method to uniformly evaluate any protein language model that allows for us to compare coevolutionary statistics to older linear models. We further identified t hat E SM-2 a ppears to have a precise context size that is needed to predict inter-residue contacts. Our study highlights the current limitations of pLMs and contributes to a deeper understanding of their underlying mechanisms, paving the way for more reliable protein structure predictions.Competing Interest StatementThe authors have declared no competing interest.},
	journal = {bioRxiv}
}

@misc{kipf2017semisupervisedclassificationgraphconvolutional,
      title={Semi-Supervised Classification with Graph Convolutional Networks}, 
      author={Thomas N. Kipf and Max Welling},
      year={2017},
      eprint={1609.02907},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
}
@article{bricken2023monosemanticity,
       title={Towards Monosemanticity: Decomposing Language Models With Dictionary Learning},
       author={Bricken, Trenton and Templeton, Adly and Batson, Joshua and Chen, Brian and Jermyn, Adam and Conerly, Tom and Turner, Nick and Anil, Cem and Denison, Carson and Askell, Amanda and Lasenby, Robert and Wu, Yifan and Kravec, Shauna and Schiefer, Nicholas and Maxwell, Tim and Joseph, Nicholas and Hatfield-Dodds, Zac and Tamkin, Alex and Nguyen, Karina and McLean, Brayden and Burke, Josiah E and Hume, Tristan and Carter, Shan and Henighan, Tom and Olah, Christopher},
       year={2023},
       journal={Transformer Circuits Thread},
       note={https://transformer-circuits.pub/2023/monosemantic-features/index.html}
    }

@inproceedings{rush-2018-annotated,
    title = "The Annotated Transformer",
    author = "Rush, Alexander",
    editor = "Park, Eunjeong L.  and
      Hagiwara, Masato  and
      Milajevs, Dmitrijs  and
      Tan, Liling",
    booktitle = "Proceedings of Workshop for {NLP} Open Source Software ({NLP}-{OSS})",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W18-2509",
    doi = "10.18653/v1/W18-2509",
    pages = "52--60",
    abstract = "A major goal of open-source NLP is to quickly and accurately reproduce the results of new work, in a manner that the community can easily use and modify. While most papers publish enough detail for replication, it still may be difficult to achieve good results in practice. This paper presents a worked exercise of paper reproduction with the goal of implementing the results of the recent Transformer model. The replication exercise aims at simple code structure that follows closely with the original work, while achieving an efficient usable system.",
}
@inproceedings{Velickovic:2018we,
author = {Veli{\v c}kovi{\'c}, Petar and Cucurull, Guillem and Casanova, Arantxa and Romero, Adriana and Li{\`o}, Pietro and Bengio, Yoshua},
title = {{Graph Attention Networks}},
booktitle = {ICLR},
year = {2018}
}
@misc{yun2020graph,
      title={Graph Transformer Networks}, 
      author={Seongjun Yun and Minbyul Jeong and Raehyun Kim and Jaewoo Kang and Hyunwoo J. Kim},
      year={2020},
      eprint={1911.06455},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{brody2022attentive,
      title={How Attentive are Graph Attention Networks?}, 
      author={Shaked Brody and Uri Alon and Eran Yahav},
      year={2022},
      eprint={2105.14491},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@inproceedings{Hamilton:2017tp,
author = {Hamilton, William L. and Ying, Zhitao and Leskovec, Jure},
title = {{Inductive Representation Learning on Large Graphs}},
booktitle = {NIPS},
year = {2017},
pages = {1024--1034},
}

@misc{ying2019gnnexplainer,
      title={GNNExplainer: Generating Explanations for Graph Neural Networks}, 
      author={Rex Ying and Dylan Bourgeois and Jiaxuan You and Marinka Zitnik and Jure Leskovec},
      year={2019},
      journal={Advances in Neural Information Processing Systems},
}

@misc{magister2021gcexplainer,
      title={GCExplainer: Human-in-the-Loop Concept-based Explanations for Graph Neural Networks}, 
      author={Lucie Charlotte Magister and Dmitry Kazhdan and Vikash Singh and Pietro Liò},
      year={2021},
      eprint={2107.11889},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{joshi2020transformers,
author = {Joshi, Chaitanya},
title = {Transformers are Graph Neural Networks},
journal = {The Gradient},
year = {2020},
note = {https://thegradient.pub/transformers-are-gaph-neural-networks/},
}

@misc{vaswani2023attention,
      title={Attention Is All You Need}, 
      author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
      year={2017},
      journal={NeurIPS}
}

@article{cammarata2020thread:,
  author = {Cammarata, Nick and Carter, Shan and Goh, Gabriel and Olah, Chris and Petrov, Michael and Schubert, Ludwig and Voss, Chelsea and Egan, Ben and Lim, Swee Kiat},
  title = {Thread: Circuits},
  journal = {Distill},
  year = {2020},
  note = {https://distill.pub/2020/circuits},
  doi = {10.23915/distill.00024}
}

@article{elhage2021mathematical,
   title={A Mathematical Framework for Transformer Circuits},
   author={Elhage, Nelson and Nanda, Neel and Olsson, Catherine and Henighan, Tom and Joseph, Nicholas and Mann, Ben and Askell, Amanda and Bai, Yuntao and Chen, Anna and Conerly, Tom and DasSarma, Nova and Drain, Dawn and Ganguli, Deep and Hatfield-Dodds, Zac and Hernandez, Danny and Jones, Andy and Kernion, Jackson and Lovitt, Liane and Ndousse, Kamal and Amodei, Dario and Brown, Tom and Clark, Jack and Kaplan, Jared and McCandlish, Sam and Olah, Chris},
   year={2021},
   journal={Transformer Circuits Thread},
   note={https://transformer-circuits.pub/2021/framework/index.html}
}

@article{olsson2022context,
   title={In-context Learning and Induction Heads},
   author={Olsson, Catherine and Elhage, Nelson and Nanda, Neel and Joseph, Nicholas and DasSarma, Nova and Henighan, Tom and Mann, Ben and Askell, Amanda and Bai, Yuntao and Chen, Anna and Conerly, Tom and Drain, Dawn and Ganguli, Deep and Hatfield-Dodds, Zac and Hernandez, Danny and Johnston, Scott and Jones, Andy and Kernion, Jackson and Lovitt, Liane and Ndousse, Kamal and Amodei, Dario and Brown, Tom and Clark, Jack and Kaplan, Jared and McCandlish, Sam and Olah, Chris},
   year={2022},
   journal={Transformer Circuits Thread},
   note={https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html}
}

@article{Alishahi_Chrupała_Linzen_2019, 
title={Analyzing and interpreting neural networks for NLP: A report on the first BlackboxNLP workshop}, volume={25}, DOI={10.1017/S135132491900024X}, 
number={4}, 
journal={Natural Language Engineering}, 
author={Alishahi, Afra and Chrupała, Grzegorz and Linzen, Tal}, 
year={2019}, 
pages={543-557}}
@misc{brown2020languagemodelsfewshotlearners,
      title={Language Models are Few-Shot Learners}, 
      author={Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
      year={2020},
      eprint={2005.14165},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
}
@article{jumper2021highly, 
    title = {Highly accurate protein structure prediction with AlphaFold}, 
    author = {Jumper, John and Evans, Ritchie and Pritzel, Alexander and et al.}, 
    journal = {Nature}, 
    volume = {596}, 
    pages = {583-589}, 
    year = {2021}, 
    doi = {10.1038/s41586-021-03819-2} 
} 

@inproceedings{
wang2023interpretability,
title={Interpretability in the Wild: a Circuit for Indirect Object Identification in {GPT}-2 Small},
author={Kevin Ro Wang and Alexandre Variengien and Arthur Conmy and Buck Shlegeris and Jacob Steinhardt},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
}

@misc{dong2021attention,
      title={Attention is Not All You Need: Pure Attention Loses Rank Doubly Exponentially with Depth}, 
      author={Yihe Dong and Jean-Baptiste Cordonnier and Andreas Loukas},
      year={2021},
      eprint={2103.03404},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{hu2021open,
      title={Open Graph Benchmark: Datasets for Machine Learning on Graphs}, 
      author={Weihua Hu and Matthias Fey and Marinka Zitnik and Yuxiao Dong and Hongyu Ren and Bowen Liu and Michele Catasta and Jure Leskovec},
      year={2021},
      eprint={2005.00687},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@inproceedings{10.1145/3534678.3539203,
author = {Palowitch, John and Tsitsulin, Anton and Mayer, Brandon and Perozzi, Bryan},
title = {GraphWorld: Fake Graphs Bring Real Insights for GNNs},
year = {2022},
isbn = {9781450393850},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
booktitle = {Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
}
@misc{kakkad2023survey,
      title={A Survey on Explainability of Graph Neural Networks}, 
      author={Jaykumar Kakkad and Jaspal Jannu and Kartik Sharma and Charu Aggarwal and Sourav Medya},
      year={2023},
      eprint={2306.01958},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{kipf2017semisupervised,
      title={Semi-Supervised Classification with Graph Convolutional Networks}, 
      author={Thomas N. Kipf and Max Welling},
      year={2018},
      booktitle={International Conference on Learning Representations},
}

@incollection{GNNBook-ch7-liu,
author = "Liu, Ninghao and Feng, Qizhang and Hu, Xia",
editor = "Wu, Lingfei and Cui, Peng and Pei, Jian and Zhao, Liang",
title = "Interpretability in Graph Neural Networks",
booktitle = "Graph Neural Networks: Foundations, Frontiers, and Applications",
year = "2022",
publisher = "Springer Singapore",
address = "Singapore",
pages = "121--147",
}

@inproceedings{
platonov2023a,
title={A critical look at the evaluation of {GNN}s under heterophily: Are we really making progress?},
author={Oleg Platonov and Denis Kuznedelev and Michael Diskin and Artem Babenko and Liudmila Prokhorenkova},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
}

@misc{zeiler2014visualizing,
      title={Visualizing and Understanding Convolutional Networks}, 
      author={Matthew D Zeiler and Rob Fergus},
      year={2014},
      eprint={1311.2901},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{springenberg2015striving,
      title={Striving for Simplicity: The All Convolutional Net}, 
      author={Jost Tobias Springenberg and Alexey Dosovitskiy and Thomas Brox and Martin Riedmiller},
      year={2015},
      eprint={1412.6806},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{sundararajan2016gradients,
      title={Gradients of Counterfactuals}, 
      author={Mukund Sundararajan and Ankur Taly and Qiqi Yan},
      year={2016},
      eprint={1611.02639},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{selvaraju2017grad,
      title={Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization}, 
      author={Ramprasaath R. Selvaraju and Michael Cogswell and Abhishek Das and Ramakrishna Vedantam and Devi Parikh and Dhruv Batra},
      year={2017},
      eprint={1610.02391},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{ribeiro2016should,
author = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
title = {"Why Should I Trust You?": Explaining the Predictions of Any Classifier},
year = {2016},
isbn = {9781450342322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2939672.2939778},
doi = {10.1145/2939672.2939778},
abstract = {Despite widespread adoption, machine learning models remain mostly black boxes. Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model. Such understanding also provides insights into the model, which can be used to transform an untrustworthy model or prediction into a trustworthy one.In this work, we propose LIME, a novel explanation technique that explains the predictions of any classifier in an interpretable and faithful manner, by learning an interpretable model locally varound the prediction. We also propose a method to explain models by presenting representative individual predictions and their explanations in a non-redundant way, framing the task as a submodular optimization problem. We demonstrate the flexibility of these methods by explaining different models for text (e.g. random forests) and image classification (e.g. neural networks). We show the utility of explanations via novel experiments, both simulated and with human subjects, on various scenarios that require trust: deciding if one should trust a prediction, choosing between models, improving an untrustworthy classifier, and identifying why a classifier should not be trusted.},
booktitle = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {1135–1144},
numpages = {10},
keywords = {black box classifier, explaining machine learning, interpretability, interpretable machine learning},
location = {San Francisco, California, USA},
series = {KDD '16}
}

@misc{olah2022mechanistic,
  title={Mechanistic Interpretability, Variables, and the Importance of Interpretable Bases},
  author={Olah, Chris},
  year={2022},
  month={Jun},
  howpublished={https://www.transformer-circuits.pub/2022/mech-interp-essay},
}

@inproceedings{
      conmy2023towards,
      title={Towards Automated Circuit Discovery for Mechanistic Interpretability},
      author={Arthur Conmy and Augustine N. Mavor-Parker and Aengus Lynch and Stefan Heimersheim and Adri{\`a} Garriga-Alonso},
      booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
      year={2023},
}
@misc{dwivedi2022benchmarking,
      title={Benchmarking Graph Neural Networks}, 
      author={Vijay Prakash Dwivedi and Chaitanya K. Joshi and Anh Tuan Luu and Thomas Laurent and Yoshua Bengio and Xavier Bresson},
      year={2022},
      eprint={2003.00982},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{dwivedi2021generalization,
      title={A Generalization of Transformer Networks to Graphs}, 
      author={Vijay Prakash Dwivedi and Xavier Bresson},
      year={2021},
      eprint={2012.09699},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@inproceedings{ying2021do,
title={Do Transformers Really Perform Badly for Graph Representation?},
author={Chengxuan Ying and Tianle Cai and Shengjie Luo and Shuxin Zheng and Guolin Ke and Di He and Yanming Shen and Tie-Yan Liu},
booktitle={Advances in Neural Information Processing Systems},
editor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},
year={2021},
}
@misc{bronstein2021geometric,
      title={Geometric Deep Learning: Grids, Groups, Graphs, Geodesics, and Gauges}, 
      author={Michael M. Bronstein and Joan Bruna and Taco Cohen and Petar Veličković},
      year={2021},
      eprint={2104.13478},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@inproceedings{
Pei2020Geom-GCN:,
title={Geom-GCN: Geometric Graph Convolutional Networks},
author={Hongbin Pei and Bingzhe Wei and Kevin Chen-Chuan Chang and Yu Lei and Bo Yang},
booktitle={International Conference on Learning Representations},
year={2020},
}

@inproceedings{zhu2020homophily,
 author = {Zhu, Jiong and Yan, Yujun and Zhao, Lingxiao and Heimann, Mark and Akoglu, Leman and Koutra, Danai},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Beyond Homophily in Graph Neural Networks: Current Limitations and Effective Designs},
 year = {2020}
}

@inproceedings{
platonov2023characterizing,
title={Characterizing Graph Datasets for Node Classification: Homophily-Heterophily Dichotomy and Beyond},
author={Oleg Platonov and Denis Kuznedelev and Artem Babenko and Liudmila Prokhorenkova},
booktitle={The Second Learning on Graphs Conference},
year={2023},
}

@inproceedings{abuaisheh:hal-01168816,
  TITLE = {{An Exact Graph Edit Distance Algorithm for Solving Pattern Recognition Problems}},
  AUTHOR = {Abu-Aisheh, Zeina and Raveaux, Romain and Ramel, Jean-Yves and Martineau, Patrick},
  URL = {https://hal.science/hal-01168816},
  BOOKTITLE = {{4th International Conference on Pattern Recognition Applications and Methods 2015}},
  ADDRESS = {Lisbon, Portugal},
  YEAR = {2015},
  MONTH = Jan,
  DOI = {10.5220/0005209202710278},
  KEYWORDS = {Graph Matching ; Graph Edit Distance ; Pattern Recognition ; Classification},
  PDF = {https://hal.science/hal-01168816/file/Abu-Aisheh%20-%20ICPRAM_2015_71.pdf},
  HAL_ID = {hal-01168816},
  HAL_VERSION = {v1},
}

@book{MolnarChristoph2022Iml:,
booktitle = {Interpretable machine learning : a guide for making black box models explainable},
isbn = {9798411463330},
year = {2022},
title = {Interpretable machine learning : a guide for making black box models explainable},
edition = {Second},
language = {eng},
author = {Molnar, Christoph},
keywords = {Artificial intelligence; Machine learning},
}

@article{Rozemberczki2019,
  author       = {Benedek Rozemberczki and
                  Carl Allen and
                  Rik Sarkar},
  title        = {Multi-scale Attributed Node Embedding},
  journal = {arXiv preprint},
  year         = {2019},
}

@inproceedings{Yang2016revisiting,
author = {Yang, Zhilin and Cohen, William W. and Salakhutdinov, Ruslan},
title = {Revisiting semi-supervised learning with graph embeddings},
year = {2016},
booktitle = {International Conference on International Conference on Machine Learning},
}

@article{Jumper2021,
  title={Highly accurate protein structure prediction with AlphaFold},
  author={Jumper, J. and Evans, R. and Pritzel, A. and Green, T. and Figurnov, M. and Ronneberger, O. and Tunyasuvunakool, K. and Bates, R. and Zídek, A. and Potapenko, A. and Bridgland, A. and Meyer, C. and Kohl, S. A. A. and Ballard, A. and Cowie, A. and Romera-Paredes, B. and Nikolov, S. and Jain, R. and Adler, J. and Back, T. and Petersen, S. and Reiman, D. and Clancy, E. and Zielinski, M. and Steinegger, M. and Pacholska, M. and Berghammer, T. and Bodenstein, S. and Silver, D. and Vinyals, O. and Senior, A. and Kavukcuoglu, K. and Kohli, P. and Hassabis, D.},
  journal={Nature},
  volume={596},
  pages={583--589},
  year={2021},
  publisher={Nature Publishing Group},
  doi={10.1038/s41586-021-03819-2},
}

@misc{luo2020parameterized,
      title={Parameterized Explainer for Graph Neural Network}, 
      author={Dongsheng Luo and Wei Cheng and Dongkuan Xu and Wenchao Yu and Bo Zong and Haifeng Chen and Xiang Zhang},
      year={2020},
      eprint={2011.04573},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{
brody2022how,
title={How Attentive are Graph Attention Networks? },
author={Shaked Brody and Uri Alon and Eran Yahav},
booktitle={International Conference on Learning Representations},
year={2022},
}

@inproceedings{
geiger2021causal,
title={Causal Abstractions of Neural Networks},
author={Atticus Geiger and Hanson Lu and Thomas F Icard and Christopher Potts},
booktitle={Advances in Neural Information Processing Systems},
editor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},
year={2021},
}

@misc{räuker2023transparent,
      title={Toward Transparent AI: A Survey on Interpreting the Inner Structures of Deep Neural Networks}, 
      author={Tilman Räuker and Anson Ho and Stephen Casper and Dylan Hadfield-Menell},
      year={2023},
      eprint={2207.13243},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{olah2017feature,
  author = {Olah, Chris and Mordvintsev, Alexander and Schubert, Ludwig},
  title = {Feature Visualization},
  journal = {Distill},
  year = {2017},
  note = {https://distill.pub/2017/feature-visualization},
  doi = {10.23915/distill.00007}
}

@misc{elhage2022toy,
      title={Toy Models of Superposition}, 
      author={Nelson Elhage and Tristan Hume and Catherine Olsson and Nicholas Schiefer and Tom Henighan and Shauna Kravec and Zac Hatfield-Dodds and Robert Lasenby and Dawn Drain and Carol Chen and Roger Grosse and Sam McCandlish and Jared Kaplan and Dario Amodei and Martin Wattenberg and Christopher Olah},
      year={2022},
      eprint={2209.10652},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{chughtai2023toy,
      title={A Toy Model of Universality: Reverse Engineering How Networks Learn Group Operations}, 
      author={Bilal Chughtai and Lawrence Chan and Neel Nanda},
      year={2023},
      eprint={2302.03025},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{
nanda2023progress,
title={Progress measures for grokking via mechanistic interpretability},
author={Neel Nanda and Lawrence Chan and Tom Lieberum and Jess Smith and Jacob Steinhardt},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
}

@inproceedings{
fu2023hungry,
title={Hungry Hungry Hippos: Towards Language Modeling with State Space Models},
author={Daniel Y Fu and Tri Dao and Khaled Kamal Saab and Armin W Thomas and Atri Rudra and Christopher Re},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
}

@misc{brundage2018malicious,
      title={The Malicious Use of Artificial Intelligence: Forecasting, Prevention, and Mitigation}, 
      author={Miles Brundage and Shahar Avin and Jack Clark and Helen Toner and Peter Eckersley and Ben Garfinkel and Allan Dafoe and Paul Scharre and Thomas Zeitzoff and Bobby Filar and Hyrum Anderson and Heather Roff and Gregory C. Allen and Jacob Steinhardt and Carrick Flynn and Seán Ó hÉigeartaigh and Simon Beard and Haydn Belfield and Sebastian Farquhar and Clare Lyle and Rebecca Crootof and Owain Evans and Michael Page and Joanna Bryson and Roman Yampolskiy and Dario Amodei},
      year={2018},
      eprint={1802.07228},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@misc{barak2023hidden,
      title={Hidden Progress in Deep Learning: SGD Learns Parities Near the Computational Limit}, 
      author={Boaz Barak and Benjamin L. Edelman and Surbhi Goel and Sham Kakade and Eran Malach and Cyril Zhang},
      year={2023},
      eprint={2207.08799},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{wei2022emergent,
      title={Emergent Abilities of Large Language Models}, 
      author={Jason Wei and Yi Tay and Rishi Bommasani and Colin Raffel and Barret Zoph and Sebastian Borgeaud and Dani Yogatama and Maarten Bosma and Denny Zhou and Donald Metzler and Ed H. Chi and Tatsunori Hashimoto and Oriol Vinyals and Percy Liang and Jeff Dean and William Fedus},
      year={2022},
      eprint={2206.07682},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{
meng2022locating,
title={Locating and Editing Factual Associations in {GPT}},
author={Kevin Meng and David Bau and Alex J Andonian and Yonatan Belinkov},
booktitle={Advances in Neural Information Processing Systems},
editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
year={2022},
}

@inproceedings{geva-etal-2021-transformer,
    title = "Transformer Feed-Forward Layers Are Key-Value Memories",
    author = "Geva, Mor  and
      Schuster, Roei  and
      Berant, Jonathan  and
      Levy, Omer",
    editor = "Moens, Marie-Francine  and
      Huang, Xuanjing  and
      Specia, Lucia  and
      Yih, Scott Wen-tau",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-main.446",
    doi = "10.18653/v1/2021.emnlp-main.446",
    pages = "5484--5495",
    abstract = "Feed-forward layers constitute two-thirds of a transformer model{'}s parameters, yet their role in the network remains under-explored. We show that feed-forward layers in transformer-based language models operate as key-value memories, where each key correlates with textual patterns in the training examples, and each value induces a distribution over the output vocabulary. Our experiments show that the learned patterns are human-interpretable, and that lower layers tend to capture shallow patterns, while upper layers learn more semantic ones. The values complement the keys{'} input patterns by inducing output distributions that concentrate probability mass on tokens likely to appear immediately after each pattern, particularly in the upper layers. Finally, we demonstrate that the output of a feed-forward layer is a composition of its memories, which is subsequently refined throughout the model{'}s layers via residual connections to produce the final output distribution.",
}

@misc{mu2021compositional,
      title={Compositional Explanations of Neurons}, 
      author={Jesse Mu and Jacob Andreas},
      year={2021},
      eprint={2006.14032},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{hernandez2022natural,
      title={Natural Language Descriptions of Deep Visual Features}, 
      author={Evan Hernandez and Sarah Schwettmann and David Bau and Teona Bagashvili and Antonio Torralba and Jacob Andreas},
      year={2022},
      eprint={2201.11114},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{vig2020,
 author = {Vig, Jesse and Gehrmann, Sebastian and Belinkov, Yonatan and Qian, Sharon and Nevo, Daniel and Singer, Yaron and Shieber, Stuart},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {12388--12401},
 publisher = {Curran Associates, Inc.},
 title = {Investigating Gender Bias in Language Models Using Causal Mediation Analysis},
 url = {https://proceedings.neurips.cc/paper_files/paper/2020/file/92650b2e92217715fe312e6fa7b90d82-Paper.pdf},
 volume = {33},
 year = {2020}
}

@misc{li2019deepgcns,
      title={DeepGCNs: Can GCNs Go as Deep as CNNs?}, 
      author={Guohao Li and Matthias Müller and Ali Thabet and Bernard Ghanem},
      year={2019},
      eprint={1904.03751},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{elhaijamixhop,
 author={Sami Abu-El-Haija AND Bryan Perozzi AND Amol Kapoor AND Hrayr Harutyunyan
         AND Nazanin Alipourfard AND Kristina Lerman AND Greg Ver Steeg AND Aram Galstyan},
 title={MixHop: Higher-Order Graph Convolution Architectures via Sparsified Neighborhood Mixing},
 booktitle = {International Conference on Machine Learning (ICML)},
 year = {2019},
}

@article{newman2003mixing,
  title = {Mixing patterns in networks},
  author = {Newman, M. E. J.},
  journal = {Phys. Rev. E},
  year = {2003},
  publisher = {American Physical Society},
}

@article{JMLR:v15:srivastava14a,
  author  = {Nitish Srivastava and Geoffrey Hinton and Alex Krizhevsky and Ilya Sutskever and Ruslan Salakhutdinov},
  title   = {Dropout: A Simple Way to Prevent Neural Networks from Overfitting},
  journal = {Journal of Machine Learning Research},
  year    = {2014},
  volume  = {15},
  number  = {56},
  pages   = {1929--1958},
}

@article{MATTHEWS1975442,
title = {Comparison of the predicted and observed secondary structure of T4 phage lysozyme},
journal = {Biochimica et Biophysica Acta (BBA) - Protein Structure},
volume = {405},
number = {2},
pages = {442-451},
year = {1975},
issn = {0005-2795},
author = {B.W. Matthews},
abstract = {Predictions of the secondary structure of T4 phage lysozyme, made by a number of investigators on the basis of the amino acid sequence, are compared with the structure of the protein determined experimentally by X-ray crystallography. Within the amino terminal half of the molecule the locations of helices predicted by a number of methods agree moderately well with the observed structure, however within the carboxyl half of the molecule the overall agreement is poor. For eleven different helix predictions, the coefficients giving the correlation between prediction and observation range from 0.14 to 0.42. The accuracy of the predictions for both β-sheet regions and for turns are generally lower than for the helices, and in a number of instances the agreement between prediction and observation is no better than would be expected for a random selection of residues. The structural predictions for T4 phage lysozyme are much less successful than was the case for adenylate kinase (Schulz et al. (1974) Nature 250, 140–142). No one method of prediction is clearly superior to all others, and although empirical predictions based on larger numbers of known protein structure tend to be more accurate than those based on a limited sample, the improvement in accuracy is not dramatic, suggesting that the accuracy of current empirical predictive methods will not be substantially increased simply by the inclusion of more data from additional protein structure determinations.}
}

@misc{battaglia2018relational,
      title={Relational inductive biases, deep learning, and graph networks}, 
      author={Peter W. Battaglia and Jessica B. Hamrick and Victor Bapst and Alvaro Sanchez-Gonzalez and Vinicius Zambaldi and Mateusz Malinowski and Andrea Tacchetti and David Raposo and Adam Santoro and Ryan Faulkner and Caglar Gulcehre and Francis Song and Andrew Ballard and Justin Gilmer and George Dahl and Ashish Vaswani and Kelsey Allen and Charles Nash and Victoria Langston and Chris Dyer and Nicolas Heess and Daan Wierstra and Pushmeet Kohli and Matt Botvinick and Oriol Vinyals and Yujia Li and Razvan Pascanu},
      year={2018},
      eprint={1806.01261},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{pytorchmultiheadattention,
  author = {PyTorch Contributors},
  title = {torch.nn.modules.activation - MultiheadAttention},
  year = {2024},
  howpublished = {\url{https://pytorch.org/docs/stable/_modules/torch/nn/modules/activation.html#MultiheadAttention}},
  note = {Accessed: 20-03-2024}
}

@misc{bodnar2023neural,
      title={Neural Sheaf Diffusion: A Topological Perspective on Heterophily and Oversmoothing in GNNs}, 
      author={Cristian Bodnar and Francesco Di Giovanni and Benjamin Paul Chamberlain and Pietro Liò and Michael M. Bronstein},
      year={2023},
      eprint={2202.04579},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{lucic2022cfgnnexplainer,
      title={CF-GNNExplainer: Counterfactual Explanations for Graph Neural Networks}, 
      author={Ana Lucic and Maartje ter Hoeve and Gabriele Tolomei and Maarten de Rijke and Fabrizio Silvestri},
      year={2022},
      eprint={2102.03322},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{rogers2020primer,
      title={A Primer in BERTology: What we know about how BERT works}, 
      author={Anna Rogers and Olga Kovaleva and Anna Rumshisky},
      year={2020},
      eprint={2002.12327},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{knyazev2019understanding,
      title={Understanding Attention and Generalization in Graph Neural Networks}, 
      author={Boris Knyazev and Graham W. Taylor and Mohamed R. Amer},
      year={2019},
      eprint={1905.02850},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{joshi2024expressive,
      title={On the Expressive Power of Geometric Graph Neural Networks}, 
      author={Chaitanya K. Joshi and Cristian Bodnar and Simon V. Mathis and Taco Cohen and Pietro Liò},
      year={2024},
      eprint={2301.09308},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{Yuan_2020,
   title={XGNN: Towards Model-Level Explanations of Graph Neural Networks},
   booktitle={International Conference on Knowledge Discovery and Data Mining},
   author={Yuan, Hao and Tang, Jiliang and Hu, Xia and Ji, Shuiwang},
   year={2020},
}

@misc{park2017attentive,
      title={Attentive Explanations: Justifying Decisions and Pointing to the Evidence}, 
      author={Dong Huk Park and Lisa Anne Hendricks and Zeynep Akata and Bernt Schiele and Trevor Darrell and Marcus Rohrbach},
      year={2017},
      eprint={1612.04757},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{Deac_2019,
   title={Attentive Cross-Modal Paratope Prediction},
   volume={26},
   ISSN={1557-8666},
   DOI={10.1089/cmb.2018.0175},
   number={6},
   journal={Journal of Computational Biology},
   publisher={Mary Ann Liebert Inc},
   author={Deac, Andreea and Veli{\v c}kovi{\'c}, Petar and Sormanni, Pietro},
   year={2019},
   month=jun, pages={536–545} }

@article{zhang2023artificial,
  title={Artificial intelligence for science in quantum, atomistic, and continuum systems},
  author={Zhang, Xuan and Wang, Limei and Helwig, Jacob and Luo, Youzhi and Fu, Cong and Xie, Yaochen and Liu, Meng and Lin, Yuchao and Xu, Zhao and Yan, Keqiang and others},
  journal={arXiv preprint arXiv:2307.08423},
  year={2023}
}

@misc{hassabis2024ai,
  author = {Demis Hassabis},
  howpublished = {Google DeepMind: The Podcast},
  title = {AI for Science with Sir Paul Nurse, Demis Hassabis, Jennifer Doudna, and John Jumper},
  note = {Quote: \emph{"You have to build the artifact of interest first, and then once you have it, you can then use the scientific method to reduce it down and understand its components."}},
  year = {2024}
}

@article{cranmer2020discovering,
  title={Discovering symbolic models from deep learning with inductive biases},
  author={Cranmer, Miles and Sanchez Gonzalez, Alvaro and Battaglia, Peter and Xu, Rui and Cranmer, Kyle and Spergel, David and Ho, Shirley},
  journal={Advances in neural information processing systems},
  year={2020}
}

@inproceedings{gilmer2017neural,
  title     = {Neural message passing for quantum chemistry},
  author    = {Gilmer, Justin and Schoenholz, Samuel S and Riley, Patrick F and Vinyals, Oriol and Dahl, George E},
  booktitle = {ICML},
  year      = {2017}
}

@inproceedings{xu2019powerful,
  title={How powerful are graph neural networks?},
  author={Xu, Keyulu and Hu, Weihua and Leskovec, Jure and Jegelka, Stefanie},
  booktitle={ICLR},
  year={2019}
}

@inproceedings{di2023over,
  title={On over-squashing in message passing neural networks: The impact of width, depth, and topology},
  author={Di Giovanni, Francesco and Giusti, Lorenzo and Barbero, Federico and Luise, Giulia and Lio, Pietro and Bronstein, Michael M},
  booktitle={International Conference on Machine Learning},
  pages={7865--7885},
  year={2023},
  organization={PMLR}
}

@article{dong2024flex,
  title={Flex Attention: A Programming Model for Generating Optimized Attention Kernels},
  author={Dong, Juechu and Feng, Boyuan and Guessous, Driss and Liang, Yanbo and He, Horace},
  journal={arXiv preprint arXiv:2412.05496},
  year={2024}
}

@article{velivckovic2023everything,
  title={Everything is connected: Graph neural networks},
  author={Veli{\v{c}}kovi{\'c}, Petar},
  journal={Current Opinion in Structural Biology},
  volume={79},
  pages={102538},
  year={2023},
  publisher={Elsevier}
}

@article{simon2024interplm,
  title={InterPLM: Discovering Interpretable Features in Protein Language Models via Sparse Autoencoders},
  author={Simon, Elana and Zou, James},
  journal={bioRxiv},
  year={2024},
}

@article{adams2025from,
  title={From Mechanistic Interpretability to Mechanistic Biology: Training, Evaluating, and Interpreting Sparse Autoencoders on Protein Language Models},
  author={Etowah Adams and Liam Bai and Minji Lee and Yiyang Yu and Mohammed AlQuraishi},
  journal={bioRxiv},
  year={2025},
}

@article{lawrence2024understanding,
  title={Understanding Biology in the Age of Artificial Intelligence},
  author={Lawrence, Elsa and El-Shazly, Adham and Seal, Srijit and Joshi, Chaitanya K and Li{\`o}, Pietro and Singh, Shantanu and Bender, Andreas and Sormanni, Pietro and Greenig, Matthew},
  journal={arXiv preprint},
  year={2024}
}

@article{rampavsek2022recipe,
  title={Recipe for a general, powerful, scalable graph transformer},
  author={Ramp{\'a}{\v{s}}ek, Ladislav and Galkin, Michael and Dwivedi, Vijay Prakash and Luu, Anh Tuan and Wolf, Guy and Beaini, Dominique},
  journal={Advances in Neural Information Processing Systems},
  year={2022}
}

@article{muller2023attending,
  title={Attending to graph transformers},
  author={M{\"u}ller, Luis and Galkin, Mikhail and Morris, Christopher and Ramp{\'a}{\v{s}}ek, Ladislav},
  journal={arXiv preprint},
  year={2023}
}

@inproceedings{
darcet2024vision,
title={Vision Transformers Need Registers},
author={Timoth{\'e}e Darcet and Maxime Oquab and Julien Mairal and Piotr Bojanowski},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
}

@article{buterez2024masked,
  title={Masked Attention is All You Need for Graphs},
  author={Buterez, David and Janet, Jon Paul and Oglic, Dino and Lio, Pietro},
  journal={arXiv preprint arXiv:2402.10793},
  year={2024}
}

@article{barabasi2012network,
  title={The network takeover},
  author={Barab{\'a}si, Albert-L{\'a}szl{\'o}},
  journal={Nature Physics},
  year={2012},
}

@article{rathkopf2018network,
  title={Network representation and complex systems},
  author={Rathkopf, Charles},
  journal={Synthese},
  volume={195},
  pages={55--78},
  year={2018},
  publisher={Springer}
}

@article{krickel2023and,
  title={How and when are topological explanations complete mechanistic explanations? The case of multilayer network models},
  author={Krickel, Beate and de Bruin, Leon and Douw, Linda},
  journal={Synthese},
  year={2023},
}