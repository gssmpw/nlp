\section{Related Work}
Our work bridges GNN explainability and mechanistic interpretability of Transformers, aiming to understand how information flows through these architectures during inference from the perspective of graph theory and network science \citep{rathkopf2018network,krickel2023and}.

\textbf{GNN Explainability.} Early work on explaining GNNs focused on identifying influential subgraphs for specific predictions \citep{ying2019gnnexplainer}. This spawned several approaches including concept-based methods \citep{magister2021gcexplainer}, counterfactual explanations \citep{lucic2022cfgnnexplainer}, and generative explanations \citep{Yuan_2020}. While valuable, these methods primarily analyze input-output relationships rather than internal model dynamics. Other work has investigated physical laws learned by GNNs using symbolic regression \citep{cranmer2020discovering}, but a systematic framework for understanding information flow in GNNs remains lacking.

\textbf{Mechanistic Interpretability of Transformers.} Recent advances in mechanistic interpretability aim to reverse-engineer neural networks into human-understandable components \citep{olah2022mechanistic,elhage2021mathematical}. This has led to breakthroughs in understanding model features \citep{olah2017feature,elhage2022toy}, identifying computational circuits \citep{nanda2023progress,cammarata2020thread:}, and explaining emergent behaviors \citep{barak2023hidden,wei2022emergent}. These insights have practical benefits - enabling better out-of-distribution generalization \citep{mu2021compositional}, error correction \citep{hernandez2022natural}, and prediction of model behavior \citep{meng2022locating}. 
Our work aims to extend the principles of mechanistic interpretability to GNNs by leveraging their mathematical connection to Transformers. 
A complementary effort is emerging around mechanistic interpretability of biological language models \citep{Zhang2024, simon2024interplm, adams2025from}, sharing our goal of extracting scientific insights from AI systems trained on structured scientific data. 

%%%