\section{Analysis}
\label{sec:theoretical-contribution}

This section aims to demonstrate that \textbf{signSGD can still converge in a non-convex scenario} to a critical point, even when up to $\alpha < 1 - \frac{1}{2p}$ of the workers are \textbf{omniscient and colluding adversaries}. Here, $p$ denotes the probability of a worker correctly guessing the sign of the true gradient at an arbitrary index $i$.


\subsection{Assumptions}

For our analysis, we take the following assumptions as in the original work of \cite{bernstein2018signsgd}.

\begin{assumption} \textnormal{ (Lower Bound).}
    For all $x$ and some constant $f^*$, we have objective value $\obj \geq f^*$. This assumption is standard and necessary for guaranteed convergence to a stationary point.
\end{assumption}

The next three assumptions naturally encode notions of heterogeneous curvature and gradient noise.

\begin{assumption} \textnormal{(Smooth).}
    Let $g(x)$ denote the gradient of the objective function $f(\cdot)$ evaluated at point $x$. Then $\forall x, y$ we require that for a non-negative constant $L$,
    \begin{equation*}
    f(y)  - \obj  \leq  \gradtrue^T(y-x) + \frac{L}{2} \|(y - x)\|^2.
    \end{equation*}
\end{assumption}

\begin{assumption} \textnormal{(Variance Bound).}
    Upon receiving query $x \in \mathbb{R}^d$, the stochastic gradient oracle gives us an independent unbiased estimate \gradest{} that has coordinate bounded variance:
    \begin{equation*}
    \E\left[\tilde{g}(x)\right] = g(x), \quad \E\left[(\gradest - \gradtrue)^2\right] \leq \sigma^2
    \end{equation*}
for a of non-negative constant $\sigma$.
\end{assumption}

\begin{assumption} \textnormal{(Unimodal, Symmetric Gradient Noise).}
    At any given point x, each component of the stochastic gradient vector \gradest{} has a unimodal distribution that is also symmetric about the mean.
\end{assumption}


\subsection{Narrowing Down the Damage of an Arbitrary Attack}


Due to the filtering effect of sign-based methods, the damage caused by an arbitrary attack is upper-bounded by flipping the the majority vote outcome for each component.
This is the core difference compared to magnitude-based approache, where the adversaries can performe more fine-grained gradient manipulations. 
Thus, the maximum damage adversaries can inflict on the convergence of signSGD is to act on the objective function $\obj$ by consistently attempting to flip the majority vote of $\gradest$, thereby pushing its outcome as far as possible from the true optimization direction. This is achieved by flipping every possible component of the gradient, ensuring that the estimated gradient direction is maximally misaligned with the true gradient direction at each step.


\begin{theorem} \textnormal{(Strongest Damage\footnote{Note that this is about bounding the damage of an arbitrary attack, and not assuming a particular attack.} on signSGD with Majority Vote).} \label{theorem_strongest_attack}
The strongest attack to maximally damage the objective function $\obj$ at time $t$ that omniscient adversaries (controlling $\alpha Q$ workers) can execute is to transmit:
\begin{equation*} 
K'_t = \sum\nolimits_{v \in \calB} -\signgradtrue_t = \alpha Q (-\signgradtrue_t),
\end{equation*}
forcing the majority vote toward the opposite of $\gradtrue_t$.
\end{theorem}

\begin{proof}
Due to the sign-based nature of signSGD, adversaries cannot manipulate gradient magnitudes but can only influence the direction of the majority vote. This restricts attack strategies to merely altering the number of incorrect signs in $\gradest_t$. Since signSGD acts as a "filter," removing magnitude information, and adversaries have access only to the gradient estimate $\gradest_{t, w}$ of the honest workers and the true gradient $\gradtrue_t$ at the current time $t$, without the ability to brute-force all possible future values of $f(x)$ to devise a more sophisticated attack, the optimal strategy for maximally disrupting the convergence of signSGD is purely directional: flipping as many signs as possible to push away the the outcome of the objective function $\obj$ from its closest convergent value.
The \emph{strongest attack} maximizes the deviation from the true gradient direction by ensuring: \begin{itemize} \item $\forall \gradtrue_{i,t}, \quad \sign{K'_{i,t}} \neq \sign{\gradtrue_{i,t}}$.
\item $\forall \gradtrue_{i,t}, \quad K'_{i,t} = \argmax{K'_{i,t}} |\gradtrue_{i,t} - K'_{i,t}|$.
\end{itemize}
Thus, adversaries optimally shift $\gradest_i$ in the opposite direction of $\gradtrue_i$ before the majority vote finalizes the sign.
Applying this to all $d$ dimensions maximizes the number of flipped gradient directions, making it the strongest possible attack within the constraints of sign-based SGD.
\end{proof}


\subsection{Convergence of signSGD in Presence of Omniscient Adversaries}
First, we need to bound the probability of a worker guessing the wrong sign. The following proof closely follows the approach in \cite{bernstein2018signsgd}, specifically their Lemma 1.

\begin{lemma}
\textnormal{(Accuracy of Sign Guessing).}
\label{Lemma 1}
Let $\gradest_i$ be an unbiased stochastic approximation to the gradient component $\gradtrue_i$, with variance bounded by $\sigma^2_i$. Assume the noise distribution is unimodal and symmetric. Define the signal-to-noise ratio (SNR) as $S_i := \frac{|\gradtrue_i|}{\sigma_i} > 0$. Then, we have that:
\begin{equation*}
    1 - p = \Prob[\sign{\gradest_i} \neq \sign{\gradtrue_i}] \leq \frac{1}{2} - \frac{S_i}{2\sqrt{4 + S_i^2}}.
\end{equation*}
which in all cases is less than or equal to $\frac{1}{2}$. Thus,

\begin{equation*}
    \frac{p(1 - p)}{(p - \frac{1}{2})^2} \leq \frac{4}{S_i^2}
\end{equation*}
\end{lemma}

\paragraph{Proof Sketch and Remarks.} For the first equality, the proof consists in a direct straightforward computation, obtained by comparing the inequalities with the bound proposed in Lemma 1 in \cite{bernstein2018signsgd}. As for the second inequality, a direct straightforward computation can be found in appendix \ref{prooflemma} along with the full proof of Lemma \ref{Lemma 1}. In addition to the proofs (deferred to the appendix), we can add the two following remarks.

\paragraph{Monotonicity.} The probability of guessing the wrong sign monotonically decreases from $\frac{1}{2}$ to 0 as the SNR increases. This behavior makes sense, as a higher gradient compared to the noise provides more information.

\paragraph{Critical Points.} When the norm of the gradient approaches 0, the SNR tends to 0, and the bound results in a probability of guessing the wrong sign of $\frac{1}{2}$, as in random guessing. However, it has been argued in the past that when the gradient becomes such, BFT stops \cite{mhamdi2018hidden, baruch2019little}, since a Byzantine worker can exploit small gradient norms to hinder learning\footnote{more precisely, small ratio between the norm of the gradients from correct workers and the variance of the correct workers' gradients increase the likelihood of successful attacks that exploit legitimate disagreements between honest workers~\cite{momentum}}. Hence, it is necessary to introduce conditions on the accuracy of gradient estimator, which is why momentum techniques \cite{momentum}) are often introduced to improve the convergence speed of gradient-based methods.


\begin{theorem} \textnormal{(Non-convex Convergence Rate of signSGD with Majority Vote Against Omniscient Adversaries).}
Execute Algorithm \ref{singSGD algo} for $K$ iterations under Assumptions 1 to 4. Disable weight decay ($\lambda = 0$). Set the learning rate $\eta$, and mini-batch size $n$ for each worker as
\begin{equation*}
    \eta = \sqrt{\frac{f_0 - f_*}{\|L\|_{1}K}}, \quad n = K.
\end{equation*}
Assuming that a fraction $\alpha < 1 - \frac{1}{2p}$, where $p = \Prob[\text{sign}(\gradest_i) = \text{sign}(\gradtrue_i)]$ (i.e., the probability of a worker correctly guessing the sign of $\gradtrue_i$ under the unimodal, symmetric gradient noise assumption), of the $Q$ workers behaves adversarially as defined by omniscient adversaries, then the majority vote converges at rate:
\begin{equation*}
  \left[\frac{1}{K}\sum^{K - 1}_{k = 0} E\|g_k\|_1\right]^2 \leq \frac{4}{\sqrt{N}}  \left[\frac{\|\sigma\|_1}{4\sqrt{Q}}\frac{\sqrt{(1- \alpha)p}}{((1 - \alpha)p - \frac{1}{2})}  + \sqrt{\|L\|_1(f_0 - f_*)} \right] ^2
\end{equation*}
where $N=K^2$ is the total number of stochastic gradient calls per worker up to step $K$.
\end{theorem}

\begin{proof}
\noindent We aim to bound the failure probability of the vote in the worst-case scenario, when adversaries behave the damage, and use this bound to derive a convergence rate. As demonstrated in \emph{Theorem \ref{theorem_strongest_attack}}, the strongest attack omniscient adversaries can craft is to \emph{send the opposite sign value of the real gradient for each entry $i$}. Thus, we limit our analysis to this scenario to find an upper bound for the convergence rate of signSGD with majority vote.

Consider $(1 - \alpha)Q$ honest machines and $\alpha Q$ adversaries. The honest workers compute a stochastic gradient estimate, evaluate its sign, and transmit it to the server. The adversaries send the opposite sign of the true gradient $g(x)$. Depending on the adversaries' proportion $\alpha$ and on the probability $p$ of a honest workers of correctly guessing the sign, the honest workers will, on average, win the vote. Our goal is to determine how many adversarial workers, $\alpha Q$, can be tolerated, depending on $p$, while still allowing signSGD with majority vote to converge to a critical point.

We now bound the probability of failure for a gradient estimate $\gradest_i$. For a given gradient component $\gradtrue_i$, let the random variable $Z \in [0, Q]$ denote the number of correct sign bits received by the parameter server. Let $G$ and $B$ be the random variables denoting the number of honest and adversarial workers, respectively, who sent the correct sign bit. In our scenario, $B = 0$, as adversaries always send the wrong sign when executing their \emph{strongest attack}, thus never contributing to $Z$. We can now express $Z$ as follows:
\begin{align*}
    &Z = G + B = G, \\
    &G \sim \text{Binomial}\left[(1 - \alpha)Q, p\right], \\
    &\E[Z] = (1 - \alpha)Qp, \\
    &\Var[Z] = (1 - \alpha)Q p(1 - p).
\end{align*}
 The vote fails on index $i$ if $Z < \frac{Q}{2}$, which occurs with probability:
\begin{align*}
    \Prob[\text{vote fails for }  i^\text{th} \text{ coordinate}] %\\ 
    &=\Prob\left[Z < \frac{Q}{2}\right] \\
    &= \Prob\left[\E[Z] - Z \geq \E[Z] - \frac{Q}{2}\right] \\
    &\leq \frac{1}{1 + \frac{(\E[Z] - \frac{Q}{2})^2}{\Var[Z]}} \quad \text{(Cantelli's inequality)} \\
    &\leq \frac{1}{2}\sqrt{\frac{\Var[Z]}{(\E[Z] - \frac{Q}{2})^2}} \quad \text{(since } 1 + x^2 \geq 2x \text{)} \\
    &= \frac{1}{2\sqrt{Q}}\frac{\sqrt{(1 - \alpha)p(1- p)}}{((1 - \alpha)p - \frac{1}{2})} \\
    &= \frac{\sqrt{(1- p)}}{2\sqrt{Q}}\frac{\sqrt{(1 - \alpha)p}}{((1 - \alpha)p - \frac{1}{2})} \\
    &= \frac{\sqrt{(1- p)p}}{2\sqrt{Q}}\frac{\sqrt{(1 - \alpha)}}{((1 - \alpha)p - \frac{1}{2})}\sqrt{\frac{(p - \frac{1}{2})^2}{(p - \frac{1}{2})^2}}\\
    &\leq \frac{1}{4S_i\sqrt{Q}}\frac{\sqrt{(1 - \alpha)}(p - \frac{1}{2})}{((1 - \alpha)p - \frac{1}{2})} \quad \text{(Lemma \ref{Lemma 1}).}
\end{align*}

From the above result, we infer that for the probability to be non-negative we need $\alpha < 1 - \frac{1}{2p}$ and $p > \frac{1}{2}$.

The second stage of the proof involves deriving the convergence rate by substituting this bound into the convergence analysis of signSGD as presented by \cite{bernstein2018signsgd}. For brevity, we omit these details (refer to the original paper) and directly conclude:
\begin{equation*}
\begin{split}
    \left[\frac{1}{K}\sum^{K - 1}_{k = 0} \E\|g_k\|_1\right]^2 \leq \frac{4}{\sqrt{N}} \left[\frac{\|\sigma\|_1}{4\sqrt{Q}}\frac{\sqrt{(1 - \alpha)}(p - \frac{1}{2})}{((1 - \alpha)p - \frac{1}{2})} + \sqrt{\|L\|_1(f_0 - f_*)}\right]^2.
\end{split}
\end{equation*}
\end{proof}

 
The following remarks can be made from the analysis of the bound, with $\alpha \leq 1 - \frac{1}{2p}$ and $p > \frac{1}{2}$.

\paragraph{Linear Relationship Between $\alpha$ and $p$:} The allowed percentage of adversaries, $\alpha$, that still permits convergence to a critical point, increases linearly with the probability $p$ of the honest workers correctly identifying the gradient sign at a given index $i$. This relationship implies that the more accurate the honest workers are ("better" in terms of predicting gradient signs), the higher the tolerance for the presence of adversaries. Specifically, taking the extreme case where $p = 1$ leads to $\alpha < 1 - \frac{1}{2p} = \frac{1}{2}$, indicating that up to, but not including, half of the total workers can be adversarial while still achieving convergence on average.


\paragraph{Implications of the Bound on $\alpha$ and $p$:} The bounds $\alpha \leq 1 - \frac{1}{2p}$ and $p > \frac{1}{2}$ inherently imply that $\alpha < \frac{1}{2}$ and $p > \frac{1}{2}$ are necessary conditions for convergence. This aligns intuitively with the design of Majority Vote mechanisms, which are robust against up to half of the participants being adversarial in signSGD contexts. Moreover, if $p \leq \frac{1}{2}$, this suggests that random guessing or even inverting the sign might yield better results. This highlights the importance of having a majority of honest workers who are more likely than not to correctly predict the sign of the true gradient.


\paragraph{Analysis of the Fraction Involving $p$ and $\alpha$:} Focusing on the fraction $\frac{\sqrt{(1- \alpha)}(p - \frac{1}{2})}{(1 - \alpha)p - \frac{1}{2}}$, it is observed that while the numerator always exceeds the denominator when considering $\alpha \leq 1 - \frac{1}{2p}$ and $p > \frac{1}{2}$, its rate of increase is slower for all growing values of $p$ within the interval $[\frac{1}{2}, 1]$ or for diminishing values of $\alpha$. This behavior suggests that the bound not only provides a meaningful restriction but also reflects the expectation of diminishing failure rates as the probability $p$ of correct gradient sign prediction increases or the percentage of adversaries diminish.

These considerations underscore the nuanced relationship between the accuracy of honest workers' gradient sign predictions and the system's resilience to adversarial presence, elucidating the theoretical foundation for ensuring convergence in signSGD under adversarial conditions.