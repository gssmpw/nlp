\section{Comparative Analysis}
\label{sec:comparative}

In \cite{jin2024sign}, the authors claimed to have proven the BFT of generalized sign-based compressors under both heterogeneous and homogeneous conditions. The main points of their study can be summarized as follows:

\begin{itemize}
    \item Threat Model: non-traditional Byzantine framework. 
    \item Incorrect aggregation considering both $\calB$ adversaries and $M$ honest workers, where $Q = \calB + M$.
\end{itemize}

In contrast to our scenario, their threat model framework measures the strength of attackers based on the probability that they will send the gradient’s opposite sign, this is inconsistent with the fact that Byzantine attackers are by definition arbitrary, omniscient and are allowed to know what prediction we make about their behaviour. Their framework lacks a formal definition of the strongest damage and does not address cooperation among attackers. In addiction, attackers use the same procedure as regular workers to estimate the gradient. The concept of omniscience is not explicitly defined, yet the framework considers a heterogeneous environment where each honest worker has a probability \( p_i \) of identifying the correct gradient $ \forall i \in M$.

Theorem 4 of \cite{jin2024sign} briefly introduces the strongest attack, noting that if the average probability of adversary workers sending the gradient's opposite sign is 1, then a limit can be derived on the maximum number of adversary workers required to maintain convergence. Average capacity of attackers is defined as a function of the average probability of honest workers recognizing the correct sign (see Definition 2, Section V in \cite{jin2024sign}).
This results in a probabilistic measure of the strength of the adversaries, which is maximized (on coordinate $i$) when \( q_{j,i}^{(t)} = 1 \), $\forall j \in \calB$.

Within their threat model the authors demonstrate the convergence of the signSGD algorithm through two steps. First, they limit the probability of incorrect aggregation with only \( M \) honest workers. Second, they introduce the presence of \( \calB \) attackers, each with a probability of choosing the gradient's opposite sign. This provides a limit on the number of adversarial workers, depending on the honest workers’ probability of selecting the correct sign. Step 1 is proved in Theorem 1, while Step 2 is proved in Theorem 4 of~\cite{jin2024sign}.


In the following section, we analyze our Byzantine scheme compared to the one presented in~\cite{jin2024sign}.


\subsection{Incorrect Aggregation Considering Both \(\calB\) Attackers and \(M\) Honest Workers}
By defining \(\calB\) adversaries as in \cite{jin2024sign}, the non-convergence bound is established using a positive constant \(c\) that bounds the probability of incorrect aggregation when more than half of the workers send the wrong sign. This considers both honest workers  and attackers. The strongest attack leads to the same bound regarding adversarial workers: \(\alpha Q < (2p - 1) M\), where \( p \) is the probability of a worker correctly identifying the sign. Suppose, without loss of generality, that $p_{i,j}^{(t)} = p$, $\forall i = 1,...,d$, $\forall t = 1,...,T$, $\forall j \in M$. Let \( K \in \calB\) denote the subset of attackers such that, given \( Q \) total workers, \( K = \alpha  Q \) and \( M = (1 - \alpha) Q \).

\paragraph{Proof Sketch.}
Let $\alpha \leq 1 - \frac{1}{2p}$, thus $ K < (1 - \frac{1}{2p})Q$ as in our findings, a straightforward computation leads to $K < (2p - 1) M$.


Let $K$ denote the bound on the $i$-th dimension, as consequence of the constant probability $p$ across the $d$-dimensions, the latter coincide with the bound found in the strongest attack claimed in Theorem 4 of \cite{jin2024sign}, by considering $\bar p = 1 -p$ in accordance to the notation used by the authors.\\
Lastly, a direct comparison on the probability bounds is challenging because a closed form to compute the constant \( c \) is not provided. Instead, leveraging the noise distribution assumption, we present a closed form based on aggregation errors.

In conclusion, while both studies examine the incorrect aggregation and convergence bounds of signSGD against adversaries, our work extends the framework with a comprehensive definition of adversary omniscience and strongest damage, considers the collusion of attackers and ultimately, provides explicit probability bounds without resorting to an unknown constant.

