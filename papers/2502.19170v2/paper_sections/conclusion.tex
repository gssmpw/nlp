\section{Conclusion}
\label{sec:conclusion}
In conclusion, this work closes the gap on the Byzantine fault tolerance of signSGD in distributed learning settings. We provide a formal definition of the strongest attack in the context of the signSGD algorithm, thus focusing on the majority vote aggregation rule. We identify the maximum number of Byzantine workers that the algorithm can tolerate and ultimately provide the convergence rate under this scenario. Lastly, we compare our contribution with similar approaches in the literature that address the BFT properties of signSGD.

\paragraph{Limitations.} An important limitation that is beyond the scope of our work is the extent of vulnerability of signSGD when the model is of very high dimensionality. For instance, this latter limitation concerns not only signSGD but the standard formalism of BFT distributed learning~\cite{blanchard2017machine} in its entirety. Recently, lower bounds~\cite{jungle} have been proven, arguing for the practical difficulty~\cite{mhamdi2018hidden, baruch2019little} to secure distributed learning in very high dimension, and learning from different and heterogeneous sources~\cite{karimireddy2021byzantine}. These limitations take form either in the assumptions or in the security guarantees on robust machine learning as the latter are heterogeneity and dimension-dependent~\cite{el2022impossible}.
In this regard, signSGD will at least suffer from the same limitations when used with extremely large models, the precise loss of robustness that is specific to signSGD and not general to any distributed learning scheme is yet to be studied.
