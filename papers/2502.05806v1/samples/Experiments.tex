

\section{Experiments}

% In this section, we validate the effectiveness of our method based on the question repetition rate, the efficiency in the number of rounds and the success rate of the task. We compare our approach with multiple competitors by providing quantitative and qualitative analysis. 
% To demonstrate the effectiveness and generalization of each component in TSADE, we provide analysis on both SL and RL baselines~\cite{de2017guesswhat,strub2017end}.

\subsection{Dataset}

\textbf{GuessWhat?!.} We evaluate our method on the GuessWhat?! dataset~\cite{de2017guesswhat}, which contains 155k dialogs based on 66k images, including 134k distinct objects. The dataset consists of 821k question-answer pairs with a vocabulary size of 4900 words. We use the standard dataset split of 70\% for training, 15\% for validation, and 15\% for testing.

\textbf{VisDial.} To demonstrate the generalization of TSADE and its broader application scope, we additionally conduct experiments on the VisDial dataset~\cite{2017Visual}.
The VisDial dataset includes images, and each with a caption and 10-round Q\&A. We evaluate the performance in a Questioner-Answerer image-guessing setting (namely GuessWhich~\cite{das2017learning})  on the VisDial v1.0.
Then the Guesser predicts the unseen image. 
Lastly, candidate images in the validation split are ranked based on their similarity to the prediction, and the rank of the target image is computed.
In each round, the change of similary score can be regarded as the bianary Q\&A in GuessWhat. In our experiments, increase in similarity is considered a ``yes'', and a decrease is considered a ``no'' to implement our method.




\subsection{Evaluation Metrics}

\textbf{GuessWhat?!.} Following previous studies~\cite{de2017guesswhat}, we report the success rate of end-to-end models 
for different rounds in New Game or New Object. New Game refers to situations where the image and target have never been seen before. The New Object refers to an image that has been seen before, but the target object within that image has not been seen before. We measure the quality of dialogue using the question repetition rate. 
% In previous studies~\cite{pang2020visual}, the definition of question repetition rate is usually the proportion of games with at least one repeated question out of all games. It is dialog-level. However, many dialogues have multiple repeated questions, making this definition unable to capture the occurrence of this phenomenon. Repeated questions often indicate a dead end in exploring target actions. To better measure whether the model keeps trying to explore the target in a dialogue, we define it as the proportion of rounds with repeated questions in this dialogue. It is round-level.

\textbf{VisDial.} The evaluation metrics include: 1) MRR: mean reciprocal rank of the target image; 2) R@k: the existence of target image in the top-k images.
% 3) Mean: mean rank of the target image; 4) PMR: percentile mean rank.







\subsection{Implementation Details}

We conduct experiments on different QGen models (DV~\cite{de2017guesswhat}, FS~\cite{strub2017end} and ADVSE~\cite{2020Answer}).
We follow the source code of the above models.
ADVSE is a strong baseline that is comparable to the current state-of-the-art QGen. 
The QGen models are all combined with the Oracle-baseline~\cite{strub2017end} and Guesser-baseline~\cite{strub2017end} to complete end-to-end training. 
We follow all the experimental conditions of DV~\cite{de2017guesswhat} and FS~\cite{strub2017end}.
% In the original papers, the ADVSE and VDST~\cite{pang2020visual} train 500 epochs in RL, which approximately requires more than two weeks.
% It is too time-consuming.
To make the comparison as fair as possible, we train all models for 40 epochs in SL or 150 epochs in RL with stochastic gradient descent (SGD)~\cite{bottou2010large}.
And we usually set the maximum number of rounds to 5.
% So our reproduction results differ from those reported in the original papers for DV, FS, and ADVSE.
The learning rate and batch size are 0.001 and 64. After the grid search, $\alpha$, $\beta$, $\gamma$ are set to 4, 0.7, 0.8.
When we train QGen, the image encoder is usually VGG~\cite{simonyan2014very}. So we replace the image encoder with CLIP~\cite{radford2021learning} and make a verification experiment.
And we make experiments on computational requirement analysis.
%Readers can refer to the supplementary materials for more details about these experiments.





\input{images/table2}

\input{images/table5}

\subsection{Comparison of Question Repetition Rate}

Although traditional methods have greatly improved the end-to-end accuracy with $r_s$ in the RL framework, a common issue is the high question repetition rate. 
% Therefore, we compare the improvements of our method with previous models in RL in terms of question repetition rate. 
% For the sake of fair comparison, the maximum round is all set to 5. 
As shown in Table~\ref{tab:2}, TSADE significantly reduces the question repetition rate for each QGen. 
G/S/B refer to the three methods of sampling questions: greedy, sampling, and beam-search (beam size 5). 
% At the round-level, TSADE can reduce the question repetition rate of the FS by up to 10.82\% and the ADVSE by up to 3.25\%. 
% At the dialog-level, 
TSADE can improve the result of the FS by up to 40.77\% and the ADVSE by up to 13.43\%. 
These significant improvements clearly demonstrate the superiority of the proposed Tree-structured strategy. 
% The goal of question generation is no longer to focus on the target object excessively but rather to effectively divide the candidate objects in each round.
When question generation is not limited to goal-oriented, its scope is broader and diversity is better.
% Our method significantly enhances the diversity of questions.

% Furthermore, we compare the improvements of TSADE on previous models under RL in terms of question repetition rate. It is based on different rounds at dialog-level. As shown in Figure~\ref{fig:3}, TSADE consistently and significantly reduces the question repetition rate of the QGen at various rounds. It indicates the robustness of our method for improving dialogue quality.

% We can see that our method (TSADE) enables each model to achieve a high accuracy rate with fewer rounds. For the combination with baseline(SL) as the question generator, the previous model had a lower accuracy rate before max turn 4 and a steeper rising curve before it could reach a high accuracy rate of 61.6\%. However, with our method improvement, the model achieved a high accuracy rate of 60\% at max turn 2. 
% For the combination with VDST-QGen as the question generator, the accuracy rate of the previous model varied greatly under different max turns, while with our method improvement, the model achieved a high accuracy rate of 43.9\% at max turn 2, which is higher than the original model's accuracy rate of 43.3\% at max turn 5.

% In summary, our method improved the end-to-end success rate of all previous models and achieved a high accuracy rate with fewer rounds.


% \begin{figure}[h]
%   \centering
%   \includegraphics[width=\linewidth]{images/fig7.pdf}
%   \caption{Trend of question repetition Rate of three QGen model under different max turns}
%   % \Description{A woman and a girl in white dresses sit in an open car.}
% \end{figure}




\subsection{Comparison on Efficiency}

As shown in Table~\ref{tab:table5}, T represents the average number of rounds to reach a single candidate object, while R represents the proportion of games where a single candidate object is reached.
We hope to reach a single candidate object in fewer rounds. When we measure the ability, smaller T and higher R indicate better results. 

However, the games that can reach a single candidate object under different models are different and their base numbers are also different.
Apparently, it is unfair to simply compare the size of T. Therefore, we employ a coefficient T/R to measure this ability. Obviously, a smaller T/R indicates that the model is more efficient.
As evident from the results, with the TSADE enhancement, there is a reduction in T/R compared to the existing methods. It means that TSADE makes the models to achieve the goal more efficiently.


\input{images/table4}

\input{images/table_re4}

\subsection{Comparison on Success Rate of End-to-end}

We show the task success rate of different models with/without our method at maximum round 5. 
As shown in Table~\ref{tab:4}, compared with ADVSE model without $r_s$, the ADVSE+TSADE improves the task success rate by 1.72\% on greedy case in New Image. 
It indicates that TSADE can improve the task success rate of the model~(SL) after RL training.
Compared with the ADVSE with $r_s$, TSADE achieves a 0.68\% improvement and on greedy case in New Image.
In New Image, TSADE achieves a new state-of-the-art task success rate under RL.
It indicates that TSADE can also improve the task success rate of the model~(RL).
% Our model does not surpass VDST's performance in New Object because VDST is trained for 500 epochs, while our model is only trained for 150 epochs.

% Compared to New Object, New Image means that the test images are unseen by the model. The performance comparison between them can reflect the model's robustness against overfitting to a certain extent. Under the greedy case, from New Object to New Image, the success rate of ADVSE with $r_s$ decreased by 0.89\%, while the success rate of ADVSE+TSADE with $r_s$ only decreased by 0.48\%. 
% It demonstrates TSADE's better robustness against overfitting.

In addition, we use a large visual-language model (LVLM) to test the effectiveness of TSADE.
We use GPT-4-vision-preview~\cite{yang2023dawn} API as Oracle, Guesser, and QGen respectively, and use preset prompts to let three agents understand their roles and task settings. 
We prompt QGen with questioning strategy by TSADE to generate questions. This strategy involves:
\begin{itemize}
    \item a) In each round, the question is raised based on the concept of binary search, aiming to eliminate half of the remaining set of candidates in the image when answered.
    \item b) The goal is to narrow down the set of remaining candidates to as few objects as possible.
\end{itemize}
As shown in Table~\ref{tab: Comparison result on LVLM-based method}, TSADE still achieves constant improvement against the LVLM-based baseline. 
In addition, it is interesting to note that LVLM performs much worse than traditional small models on this task. Although LVLM has strong visual understanding ability, the goal-oriented visual dialogue task requires the model to have good spatial reasoning ability, which may be the ability that LVLM lacks~\cite{kamath2023s}.

% Compared with previous QGens, the QGen with our method achieves a new state-of-the-art results in two settings.
% For the sake of fair comparison, the
% maximum round is all set to 5.
% But under the same experimental conditions, our reproduction of the results for DV~\cite{de2017guesswhat} and FS~\cite{strub2017end} differs from those reported in the original paper.


% Figure~\ref{fig:3} shows the curve of the task success rate under different max round settings. With the improvement by TSADE, the task success rate of model is consistently enhanced across all rounds. Furthermore, the larger the number of max round, the stronger the improvement achieved by TSADE. This indicates that TSADE focuses on turn-by-turn optimization, and as the number of rounds increases, the cumulative effect becomes more pronounced. This indicates that it has great potential to improve performance in high-round dialogues.

% The repetition rate of the modified model was comparable to that of the previous model at max turn 8, and there was a significant change between max turn 5 and max turn 8. The reason is that in the GuessWhat?!\cite{de2017guesswhat}, the number of objects in each image is usually around 20. For only these limited number of objects, based on our method, the target can usually be found at max turn 5, so the subsequent questions will appear redundant.

% Overall, our method can reduce the problem repetition rate for QGen with fewer turns and keep it at a lower level.

\input{images/table3}

\input{images/table_re1}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=1\linewidth]{images/fig5-CVPR.pdf}
  \caption{The generated dialogue examples show the strategy for question generation with and without TSADE.}
  % \Description{A woman and a girl in white dresses sit in an open car.}
  \label{fig:5}
\end{figure}



\subsection{Ablation Study}

In Table~\ref{tab:3}, we evaluate the individual contribution of the 
\emph{binary} reward ($r_b$) and \emph{candidate-minimization} reward ($r_c$). We conduct ablation studies based on the FS~\cite{strub2017end} with $r_s$ at maximum round 5. 
% As shown in Table~\ref{tab:3}, the results of the game success rate and question repetition rate are presented at different conditions. 
In terms of the question repetition rate, the repetition increases by around 14\% without $r_b$, while it slightly decreases without $r_c$. Regarding the game success rate, it decreases by approximately 2\% without $r_b$ and 5\% without $r_c$. It indicates that $r_b$ not only improves the success rate to some extent but has a greater impact on reducing question repetition. On the other hand, $r_c$ primarily helps the model to significantly improve success rate by selecting higher-quality successful dialogues under RL. It can help the model identify the target object precisely.





\subsection{Qualitative Analysis of the Strategy}

In Figure~\ref{fig:5}, we present an example of a dialogue with/without TSADE for qualitative analysis. We only show examples with eight objects. As shown in Figure~\ref{fig:5} (a), when the model asks the first question, the feature represented by ``electric appliance'' matches four of the eight objects. After receiving the answer ``No'' from the Oracle, half of the objects are excluded. In the second round, the model selects two plants and two chairs from the candidate objects and asks a question about a shared feature of some objects, rather than asking about the specific feature of each object. After receiving the answer ``Yes'', two chairs are eliminated. Finally, the model asks a question about one of the candidate objects to identify the target object. In the Figure~\ref{fig:5} (b), the model tends to query ergodically, and a small number of objects can be eliminated in each round. It is very inefficient.
%Please refer to the supplementary materials for more qualitative results.




\subsection{Generalization and Limitation Analysis}

%of the Broader Application Scope

To demonstrate the generalization of TSADE, we provide experiments on VisDial v1.0~\cite{2017Visual} with the ReeQ~\cite{Zheng_Xu_Meng_Wang_Wang_Zhou_2021} model for GuessWhich~\cite{das2017learning} task.
% GuessWhich is a Questioner-Answerer image-guessing setting to evaluate the performance.
% The Questioner and Answerer generate a 10-round dialogue, then the Guesser predicts the unseen image. 
% Lastly, candidate images in the validation split are ranked based on their similarity to the prediction, and the rank of the target image is computed.
% In each round, the change of similary score can be regarded as the bianary Q\&A in GuessWhat. In our experiments, increase in similarity is considered a ``yes'', and a decrease is considered a ``no'' to implement our method.
$r_o$ refers to the original reward in ReeQ under RL.
% The evaluation metrics include: 1) MRR: mean reciprocal rank of the target image; 2) R@k: the existence of target image in the top-k images; 3) Mean: mean rank of the target image; 4) PMR: percentile mean rank.
As shown in Table~\ref{tab:re1}, it could be seen that our method achieves  performance improvements under most metrics.
It further verifies that our method could be generalized to other datasets. 
% In fact, most complex scenarios can be broken down into binary sub-questions suitable for application. From this perspective, TSADE can extend to more complex datasets exceeding simple yes/no Oracles.
% The thought of divide-and-conquer can be regarded as a way to improve search efficiency in the process of reducing the generalized search space.
% In the broader visual dialogue scenarios, our method can serve as a specific implementation approach for reference.
Furthermore, the thought also has potential exploration space in non-dialogue goal-oriented tasks. 
% For example, we can quickly narrow down the physics search space in goal navigation~\cite{chaplot2020object} by applying a divide-and-conquer approach.
For example, we can try goal navigation~\cite{chaplot2020object}, where a set of candidate paths are established in the navigation process.
Based on whether the probability of each path increases or decreases, one can use ``yes" or ``no" to divide candidate paths set into halves. 
% In goal oriented action planning~\cite{long2007enhanced}, the thought enables game agents to rapidly narrow down the action search space in order to complete predefined tasks.








