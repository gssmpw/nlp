\begin{abstract}
Goal-oriented visual dialogue involves multi-round interaction between artificial agents, which has been of remarkable attention due to its wide applications. Given a visual scene, this task occurs when a Questioner asks an action-oriented question and an Answerer responds with the intent of letting the Questioner know the correct action to take.
%Based on the question, Oracle provides different answers, and Questioner focuses on different visual content in the image and raises further questions based on different answers. 
The quality of questions affects the accuracy and efficiency of the target search progress. However, existing methods lack a clear strategy to guide the generation of questions, resulting in the randomness in the search process and inconvergent results. We propose a Tree-Structured Strategy with Answer Distribution Estimator (TSADE) which guides the question generation by excluding half of the current candidate objects in each round. 
The above process is implemented by maximizing a binary reward inspired by the ``divide-and-conquer'' paradigm.
We further design a candidate-minimization reward which encourages the model to narrow down the scope of candidate objects toward the end of the dialogue. %We use Reinforcement learning to apply strategy to the model. 
% Moreover, similar to the popular state tracking mechanism, we align the state weight of the Questioner and the Guesser for each round, which enhances the correlation between the two agents, making the final decision more convincing.
We experimentally demonstrate that our method can enable the agents to achieve high task-oriented accuracy with fewer repeating questions and rounds compared to traditional ergodic question generation approaches. Qualitative results further show that TSADE facilitates agents to generate higher-quality questions. 
% Code will be available at \url{https://github.com/caishuo-C/TSADE}.
\end{abstract}
\begin{links}
\link{Code}{https://github.com/caishuo-C/TSADE}
\end{links}