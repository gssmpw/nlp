%% 
%% Copyright 2007-2020 Elsevier Ltd
%% 
%% This file is part of the 'Elsarticle Bundle'.
%% ---------------------------------------------
%% 
%% It may be distributed under the conditions of the LaTeX Project Public
%% License, either version 1.2 of this license or (at your option) any
%% later version.  The latest version of this license is in
%%    http://www.latex-project.org/lppl.txt
%% and version 1.2 or later is part of all distributions of LaTeX
%% version 1999/12/01 or later.
%% 
%% The list of all files belonging to the 'Elsarticle Bundle' is
%% given in the file `manifest.txt'.
%% 

%% Template article for Elsevier's document class `elsarticle'
%% with numbered style bibliographic references
%% SP 2008/03/01
%%
%% 
%%
%% $Id: elsarticle-template-num.tex 190 2020-11-23 11:12:32Z rishi $
%%
%%
\documentclass[preprint,12pt]{elsarticle}

%% Use the option review to obtain double line spacing
%% \documentclass[authoryear,preprint,review,12pt]{elsarticle}

%% Use the options 1p,twocolumn; 3p; 3p,twocolumn; 5p; or 5p,twocolumn
%% for a journal layout:
%% \documentclass[final,1p,times]{elsarticle}
%% \documentclass[final,1p,times,twocolumn]{elsarticle}
%% \documentclass[final,3p,times]{elsarticle}
%% \documentclass[final,3p,times,twocolumn]{elsarticle}
%% \documentclass[final,5p,times]{elsarticle}
%% \documentclass[final,5p,times,twocolumn]{elsarticle}

%% For including figures, graphicx.sty has been loaded in
%% elsarticle.cls. If you prefer to use the old commands
%% please give \usepackage{epsfig}

%% The amssymb package provides various useful mathematical symbols
\usepackage{amssymb}
%% The amsthm package provides extended theorem environments
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{color}
\usepackage{ulem}
\usepackage{cancel}
\usepackage{subfig}
\usepackage{array} 
\usepackage{verbatim}
\usepackage{graphicx}
\usepackage{booktabs}
%% The lineno packages adds line numbers. Start line numbering with
%% \begin{linenumbers}, end it with \end{linenumbers}. Or switch it on
%% for the whole article with \linenumbers.
%% \usepackage{lineno}

% \journal{Biomedical Signal Processing and Control}
\makeatletter
\def\ps@pprintTitle{%
 \let\@oddhead\@empty
 \let\@evenhead\@empty
 \let\@oddfoot\@empty
 \let\@evenfoot\@empty}
\makeatother
\begin{document}
\captionsetup[figure]{labelfont={bf},labelformat={default},labelsep=period,name={Fig.}}
\begin{frontmatter}

%% Title, authors and addresses

%% use the tnoteref command within \title for footnotes;
%% use the tnotetext command for theassociated footnote;
%% use the fnref command within \author or \address for footnotes;
%% use the fntext command for theassociated footnote;
%% use the corref command within \author for corresponding author footnotes;
%% use the cortext command for theassociated footnote;
%% use the ead command for the email address,
%% and the form \ead[url] for the home page:
%% \title{Title\tnoteref{label1}}
%% \tnotetext[label1]{}
%% \author{Name\corref{cor1}\fnref{label2}}
%% \ead{email address}
%% \ead[url]{home page}
%% \fntext[label2]{}
%% \cortext[cor1]{}
%% \affiliation{organization={},
%%             addressline={},
%%             city={},
%%             postcode={},
%%             state={},
%%             country={}}
%% \fntext[label3]{}

\title{Joint Attention Mechanism Learning to Facilitate Opto-physiological Monitoring during Physical Activity}

%% use optional labels to link authors explicitly to addresses:
%% \author[label1,label2]{}
%% \affiliation[label1]{organization={},
%%             addressline={},
%%             city={},
%%             postcode={},
%%             state={},
%%             country={}}
%%
%% \affiliation[label2]{organization={},
%%             addressline={},
%%             city={},
%%             postcode={},
%%             state={},
%%             country={}}

\affiliation[inst1]{organization={Wolfson School of Mechanical, Electrical and Manufacturing Engineering},%Department and Organization
            addressline={Loughborough University}, 
            city={Loughborough},
            postcode={LE11 3TU}, 
            country={UK}}

% \affiliation[inst2]{organization={Carelight Ltd},%Department and Organization
%             addressline={Advanced Technology Innovation Centre, Loughborough University Science and Enterprise Park}, 
%             city={Loughborough},
%             postcode={LE11 3QF}, 
%             country={UK}}

\affiliation[inst3]{organization={School of Sport, Exercise and Health Sciences},%Department and Organization
            addressline={Loughborough University}, 
            city={Loughborough},
            postcode={LE11 3TU}, 
            country={UK}}

\affiliation[inst4]{organization={Digital Environment Research  (DERI)},%Department and Organization
            addressline={Queen Mary University of London}, 
            city={London},
            postcode={E1 1HH}, 
            country={UK}}


\author[inst1,inst4]{Xiaoyu Zheng}
\author[inst1]{Sijung Hu\corref{mycorrespondingauthor}}
\cortext[mycorrespondingauthor]{Corresponding author}
\ead{s.hu@lboro.ac.uk}
\author[inst1]{Vincent Dwyer}
\author[inst1]{Mahsa Derakhshani}
\author[inst3]{Laura Barrett}


\begin{abstract}
%% Text of abstract
Opto-physiological monitoring is a non-contact technique for measuring cardiac signals, i.e., photoplethysmography (PPG). Quality PPG signals directly lead to reliable physiological readings. However, PPG signal acquisition procedures are often accompanied by spurious motion artefacts (MAs), especially during low-to-high-intensity physical activity. This study proposes a practical adversarial learning approach for opto-physiological monitoring by using a generative adversarial network with an attention mechanism (AM-GAN) to model motion noise and to allow MA removal. The AM-GAN learns an MA-resistant mapping from raw and noisy signals to clear PPG signals in an adversarial manner, guided by an attention mechanism to directly translate the motion reference of triaxial acceleration to the MAs appearing in the raw signal. The AM-GAN was experimented with three various protocols engaged with 39 subjects in various physical activities. The average absolute error for heart rate (HR) derived from the MA-free PPG signal via the AM-GAN, is 1.81 beats/min for the IEEE-SPC dataset and 3.86 beats/min for the PPGDalia dataset. The same procedure applied to an in-house LU dataset resulted in average absolute errors for HR and respiratory rate (RR) of less than 1.37 beats/min and 2.49 breaths/min, respectively. The study demonstrates the robustness and resilience of AM-GAN, particularly during low-to-high-intensity physical activities.
\end{abstract}

%%Graphical abstract
% \begin{graphicalabstract}
% \includegraphics{grabs}
% \end{graphicalabstract}

% %%Research highlights
% \begin{highlights}
% \item Attention mechanism suitable machine learning and GAN for the multi-sensor fusion to effectively remove in-band and out-of-band motion artefact.
% \item Joint attention machine learning to facilitate opto-physiological monitoring at various intensities of physical activity with a range of acceleration (0.1 and 4.0 Hz).
% \item Increasing capacity of opto-physiological monitoring via precision parameters (HR and RR) extracted from the in-house and publicly available datasets.
% \item Lower absolute error while using the proposed AM-GAN, than using other state-of-the-art (SOTA) methods.
% \end{highlights}

\begin{keyword}
%% keywords here, in the form: keyword \sep keyword
photoplethysmography(PPG)\sep generative adversarial network(GAN)\sep motion artefacts(MAs)\sep attention mechanism\sep opto-physiological monitoring
%% PACS codes here, in the form: \PACS code \sep code
% \PACS 0000 \sep 1111
% %% MSC codes here, in the form: \MSC code \sep code
% %% or \MSC[2008] code \sep code (2000 is the default)
% \MSC 0000 \sep 1111
\end{keyword}

\end{frontmatter}

%% \linenumbers

%% main text
\section{Introduction}
\label{sec:intro}
Pulsatile waveform extracted from the PPG signal is a key component in obtaining physiological parameters, including heart rate (HR), respiration rate (RR) and oxygen saturation (SpO$_2$). Obtaining reliable physiological parameters from PPG relies upon a high-quality signal.  MAs, frequently generated during physical activity, impede the acquisition of clear PPG signals, thereby diminishing the stability and accuracy of vital sign measurements. MAs can arise due to alterations in the contact between the wearable sensor and the skin surface caused by movement, as well as from hemodynamic effects \cite{b3turcott2008hemodynamic}. Various techniques have been investigated to extract MA to produce MA-reduced PPG signals. These methods include Empirical Mode Decomposition (EMD), Fast Fourier Transform (FFT), Independent Component Analysis (ICA), wavelet denoising \cite{b4pankaj2022review}, Adaptive Noise Cancellation (ANC) with Recursive Least Squares (RLS) and Adaptive-Size Least Mean Squares (AS-LMS) \cite{b5ram2011novel}. These approaches tend to underperform during medium-to-high-intensity physical activities, a challenge addressed by the TROIKA algorithm \cite{b6zhang2014troika}. Also, such MA-removal methods are complex and a challenge for efficient embedding in a wearable system \cite{b7nabavi2020robust}. Although these studies adopt an acceleration reference for MA removal, the acceleration reference usually fails to precisely capture MA associated with subtle finger or wrist movements and gestures, leading to potentially uncorrelated MA behaviour. There has been a growing demand for additional, reliable physiological parameters beyond HR estimates, such as RR and SpO$_2$, where obtaining a higher-quality pulsatile waveform is key. Consequently, additional PPG algorithms are required to extract relevant parameters/biomarkers during physical activities that are applicable for wearable opto-physiological monitoring. Such a prospect may well lie in the domain of Artificial Intelligence. 

Inspired by the rapid development of deep-learning (DL) techniques, several DL algorithms to extract physiological parameters from raw PPG signals have been recently presented. These techniques can be categorised into two types: \textit{end-to-end} methods and \textit{feature extraction} methods. The former directly establishes a mapping from raw PPG signals to the target physiological parameters \cite{b8luque2018end}, while the latter obtains the target parameters by extracting features pre-processed from raw PPG signals \cite{b9biswas2019cornet}. Data-driven, with strong fitting abilities, these neural networks often outperform traditional methods \cite{b10esgalhado2021application}. However, most DL end-to-end and feature extraction methods focus on extracting only the specific physiological parameter from input raw PPG signals, and often ignore the high-quality PPG signals extraction that dominates the reliable physiological parameter estimation.

Some recent studies have demonstrated that using DL methods can benefit the noise and motion detection from the input noisy PPG signals \cite{b11goh2020robust}. Specifically, a one-dimensional (1D) Convolutional Neural Network (CNN) has been proposed to automatically learn the intrinsic features of the PPG signals and perform the required classification of 'clean' or 'with artefacts' \cite{b11goh2020robust}. Other DL methods transform PPG signals into two-dimensional (2D) images and employ a 2D CNN model for the signal quality classification on static and low-intensity exercise \cite{b12chen2021signal}, \cite{b13afandizadeh2023accurate}. Although these approaches have achieved high accuracy in HR evaluation, medium-to-high-intensity activities have not been evaluated, which is more challenging as MAs during these activities are more complex, with diverse morphologies. Attention mechanisms have emerged as a critical component in the advancement of sequence modelling and transduction models across a range of tasks, facilitating the modelling of dependencies irrespective of their positional distance within the input or output sequences \cite{b30ashish2017attention}. Recent work combining generative adversarial network (GAN) and Attention has shown considerable promise: for instance, the study in \cite{b31sarkar2021cardiogan} employed an attention-based generator, for the identification of local salient features, and incorporated dual discriminators to ensure the fidelity of the synthesised data across both time and frequency domains, in an attempt to generate synthetic ECG from PPG. A general issue with the method in \cite{b31sarkar2021cardiogan}, is that MAs are not to be considered. In contrast, a GAN was employed to eliminate low-intensity motion noise from PPG signals by transforming the PPG into a two-dimensional correlation image array, which enabled the use of a conventional image-based GAN architecture \cite{b13afandizadeh2023accurate}. Similarly, the elimination of ocular artefacts from electroencephalography (EEG) data, crucial for numerous brain-computer interface applications, was explored in \cite{b17sawangjai2021eeganet}.

To address these issues, this study presents an attention mechanism learning approach for robust PPG-based physiological parameters extraction by using an attention mechanism combined with the GAN for multi-sensor fusion to remove MAs from the raw PPG signals during low-to-high intensity physical activities. Pre-filtered, motion-contaminated PPG signals from an optoelectronic patch sensor, triaxial acceleration signals from an accelerometer sensor, and associated velocities were adopted as the inputs of the proposed AM-GAN model. Once the model learns how to map the contaminated PPG signals to MAs-free PPG signals, the generator generates the PPG signal similar to the ground-truth PPG signal, while the discriminator distinguishes the generated PPG signal from the ground-truth PPG signal. The attention mechanism is suitable for multi-sensor fusion to significantly enhance the generator's ability to focus attention on the manner in which motion impacts the PPG waveform characteristics, thereby enhancing its capacity to eliminate MAs across a spectrum of physical activities ranging from low to high intensity. The contributions of this work are as follows:

\begin{enumerate}
\item  To research how an Attention Mechanism learning suitable for multi-sensor fusion to be applied in a GAN network to effectively remove in-band and out-of-band noises.
\item To assess the ability of the attention-based GAN model to obtain a clean PPG pulsatile waveform by MA removal from raw PPG signal inputs using the outputs of the triaxial accelerometer in various scenarios of low-to-high intensity physical activities that the frequency range was shown to be between 0.1 and 4.0 Hz.
\item To validate the proposed AM-GAN model for extracting HR and RR for both intra-dataset and cross-dataset testing against other state-of-the-art (SOTA) methods. 
\item To provide the benefit while utilising the attention mechanism to be justified with comparative output time and frequency-domain waveform, with and without the attention mechanism.
\end{enumerate}


\section{Methods and Materials}
\begin{figure}[!hbt]
    \centering
    \includegraphics[width=0.8\textwidth]{Fig_new1.eps}
    \caption{The proposed AM-GAN comprising a joint attention mechanism together with a GAN.}
    \label{Fig1}
\end{figure}
In this study, we propose an AM-GAN (depicted in Fig.~\ref{Fig1}) comprising an attention mechanism together with a GAN to learn the mapping from the MA-corrupted PPG signal to the MA-free PPG signal. Particularly, the proposed AM-GAN consists of three main parts: 1) Generator ($G$) together with the Attention Mechanism, 2) Discriminator ($D$), and (during training) 3) Motion removal algorithm. 

During the training, the generator takes an MA-corrupted PPG signal $p(t)\in\mathcal{P}_{Tr}$ (where $\mathcal{P}_{Tr}$ denotes the training data set) as an input as well as triaxial acceleration signals $a_{x,y,z}(t)$ as a conditional input and generates an approximation to the MA-free PPG signal $s(t)=G(p(t), a_{x,y,z}(t))$ as its output. An attention mechanism is incorporated into the generator to force it to focus on features of the encoded PPG signal with the greatest importance. The discriminator is designed to distinguish the ground truth $s_{ref}(t)$ from the signals $s(t)=G(p(t), a_{x,y,z}(t))$. Finally, the motion removal algorithm, MR algorithm \cite{b21zheng2023rapid}, extracts the reference PPG signals from MA-corrupted PPG signal $p(t)$, i.e., $s_{ref}(t)=MR(p(t))$, for training purposes.

To verify the performance of the trained network, the output of the generator is compared to the reference signal for signals in the testing data set, i.e., $p(t)\in\mathcal{P}_{Te}$. The physiological parameters (HR and RR) are also extracted from the MA-free PPG signals and compared with the ones from reference signals. The details of the proposed AM-GAN are described in the following subsections.

\subsection{U-Net Generator Aligned with Attention Mechanism}
\begin{figure*}[!hbt]
    \centering
    \includegraphics[width=1\textwidth]{Fig_new2.eps}
    \caption{The generator network aligned with the attention mechanism. In the cross-attention mechanism, the noisy PPG (P) feature map is set as the \textit{Query} tensor, while the combined feature maps for the triaxial ACC and VEL are set as \textit{Key} and \textit{Value} tensors.}
    \label{Fig2}
\end{figure*}

The U-Net generator was initially proposed for image classification \cite{b20ronneberger2015u}. Fig. \ref{Fig2} shows the modified U-Net generator as a de-noising encoder-decoder with skip connections and the attention mechanism to take the noisy PPG signal as an input and the triaxial acceleration (ACC) as the conditional input. Meanwhile, the triaxial velocity (VEL) is created using the acceleration signal and constant matrix $Z$, i.e., $v_x=\frac{1}{f_s}Z[a_x]$, where $f_s$ is the sampling rate and $Z$ is the lower triangular matrix of constants (constant is 1). 

In the modified U-Net generator architecture, 1D convolution and deconvolution functions are utilised instead of the typical 2D functions, and the latent vector $z$ is omitted, or more properly is replaced in essence by the motion reference proxy obtained from the triaxial ACC and VEL. These changes adapt the network better for processing 1D signals and help to minimise overfitting during the generation of the targeted PPG signals. Specifically, the encoding phases include four convolutional layers, each followed by batch normalisation (BN) and leaky rectified linear units (LeakyReLU). These components are integrated within a strided convolution process using a stride of two. The decoding process is the reversal of the encoding process, which is implemented through deconvolution layers followed by batch normalisation (BN) and rectified linear (ReLU) units to decode the de-noised PPG feature map culminating in the acquisition of the desired de-noised PPG signal. Additionally, the generator network employs skip connections that link each encoding layer to its corresponding decoding layer, effectively circumventing the central compression stage of the generator network. These skip connections enable the direct transfer of fine-grained features from the encoding stage to the decoding stage, addressing the potential loss of low-level details that can occur when all feature information pass through the central compression bottleneck of the network\cite{b20ronneberger2015u}. In the AM-GAN generator structure, the PPG signal encoding layer and motion reference encoding layer are concatenated to link the corresponding decoding layer. 

Instead of directly merging features calculated in the contracting path at the same hierarchical level within the upsample block, the attention mechanism is employed for multi-sensor fusion to identify the MAs and target the relevant PPG features from the downsample block. This could be achieved by using the conditional motion reference signal, i.e., encoded triaxial ACC with related VEL, to guide the attention over the encoded input-noisy PPG signal (P).

\subsection{Attention Mechanism}
\subsubsection{Problem Formulation}
Referring to the simplest version of our MR model~\cite{b21zheng2023rapid}, the noise $n[i]$, in the measured noisy PPG signal $p[i]$, can be approximated by a linear combination of acceleration outputs $a_x[i], a_y[i], a_z[i]$ and associated velocity (the integrated outputs $v_x[i], v_y[i]$ and $v_z[i]$) from the triaxial ACC, thus $n[i] =\boldsymbol{a}[i]\Xi$  where the columns of the $(N\times 6)$ array $\boldsymbol{a}[i]$are the six motion signals with coefficients given by the $(6\times 1)$ array $\boldsymbol{\Xi}$. An orthonormal basis for this subspace may be obtained from the six columns of the $(N \times 6)$ array $\boldsymbol{\Phi}=\boldsymbol{a}\boldsymbol{U}^\intercal\boldsymbol{D^{-1/2}}$, where $\boldsymbol{U}$ and $\boldsymbol{D}$ are the unitary matrix that diagonalises the $6\times 6$ array $\boldsymbol{a}^\intercal\boldsymbol{a}$, and the resulting diagonal form (i.e. $\boldsymbol{a}^\intercal\boldsymbol{a}=\boldsymbol{U}^\intercal\boldsymbol{D}\boldsymbol{U}$). The motion-suppressed PPG signal is then rewritten as the more obvious: 
\begin{equation}
\label{MinRes}
    \boldsymbol{s}= \boldsymbol{p} - \boldsymbol{\Phi}\boldsymbol{\Phi}^\intercal \boldsymbol{p}
\end{equation}
where $\boldsymbol{\Phi}$ plays the role of a unit vector in standard Euclidean geometry.  From \eqref{MinRes}, $\boldsymbol{s}^\intercal\boldsymbol{n}=0$, meaning that the method assumes that the clean signal and the noise are separable in the frequency domain. In the case that the spectra of $\boldsymbol{s}$ and $\boldsymbol{n}$ do overlap, \eqref{MinRes} should remove some, but not necessary all, of the MAs; it will represent motion suppression rather than motion removal. 

One advantage of choosing this method to trial the hypothesis that 'Motion Removal' algorithms may be learned by an NN is its relative insensitivity to data scaling, which occurs in standard neural network pre-processing, often to improve convergence. This maintains a focus on the behaviour of the network to mimic the algorithm. This is clear from the fact that the orthonormal basis $\boldsymbol{\Phi}$ in \eqref{MinRes} is independent of any individual scaling of the motion components because the scaled accelerometer reading $\boldsymbol{a}'=\boldsymbol{a}\boldsymbol{\Lambda}$, for any diagonal $(6 \times 6)$ scaling matrix $\boldsymbol{\Lambda}$, occupies the same subspace as $\boldsymbol{a}$ and so has $\boldsymbol{\Phi}$ as a basis (more precisely the array $\boldsymbol{\Phi}\boldsymbol{\Phi}^\intercal$ is unchanged). Likewise, \eqref{MinRes} is linear in $\boldsymbol{p}$ so that scaling $\boldsymbol{p}'=\lambda \boldsymbol{p}$ simply scales $\boldsymbol{s}$ by $\lambda$ also. Second, the final term in \eqref{MinRes} demonstrates a simple mathematical form of ‘traditional attention mechanism’.

\subsubsection{Cross-attention Mechanism for Multi-sensor Fusion}
A self-attention mechanism was proposed as a core component of the transformer model \cite{b30ashish2017attention}. The self-attention accepts a tensor comprising sequential data and establishes its self-correlation. Specifically, it involves linear projections of the input $X$ into  \textit{queries} ($Q$),  \textit{keys} ($K$), and  \textit{values} ($V$) using different learned weight matrices for each attention head $i$:
\begin{equation}
\label{e1}
Q(i) = W{_q}(i)X, K(i) = W{_k}(i)X, V(i) = W{_v}(i)X 
\end{equation}
where here $1 \le i \le [h=8]$ and $X$ is a concatenation of the encoded network inputs (i.e. the encoder output). The scaled dot-product attention ($A$) is then applied to these projections as
\begin{equation}
\label{e2}
A(i) = softmax((Q(i) K(i)^T) / \sqrt{d_k}) V(i)
\end{equation}
where $d{_k}$ is the dimensionality of the queries and keys, and the division by $\sqrt{d_k}$ is done to prevent the dot product from growing too large as the dimensionality increases. 

In contrast to the self-attention mechanism that correlates the input $X$ with itself, the multi-head cross-attention mechanism is proposed for multi-sensor fusion. They are two inputs $X_1$ and $X_2$, where $X_1$ represents \textit{query} $Q$ tensors and $X_2$ represents the \textit{key} $K$ and \textit{value} $V$ tensors as shown in \eqref{e1} and \eqref{e2}. In the proposed attention mechanism, these tensors are related to different sensor inputs, including encoded noisy PPG and encoded triaxial ACC with related VEL feature maps after four downsample blocks of the generator. The encoded feature maps are fed into the attention mechanism, as shown in Fig. \ref{Fig2}. Specifically, the proposed attention mechanism takes the generated PPG encoded feature map processed by a (feature pooling) $1\times1$ convolution layer to create the \textit{query} $Q$. Also, the \textit{key} $K$ and \textit{value} $V$ pair is formed through a similar $1\times1$ convolution layer of generated combined encoded feature map with triaxial ACC and the related VEL. The $K$ and $V$ vectors are used to calculate the attention weights, indicating to the model which parts of the MAs to focus on. The $Q$ vector is the information that these attention weights will be applied to, with the aim of highlighting the MA features in the PPG encoded feature map that are most relevant to the ACC and VEL combined encoded feature map. 

Inspired by the previous successful MR model and the structure of\eqref{MinRes}, the modified multi-head cross-attention mechanism is utilised as an alternative to the multi-sensor fusion and the traditional computation of $\boldsymbol{\Phi}$ matrix for focusing on the MAs at different exercise intensities. Furthermore, the target output of the modified cross-attention mechanism $S$ is calculated by:
\begin{equation}
\label{e4}
S = P \ominus softmax((QK^T) / \sqrt{d_k}) V
\end{equation}
where $\ominus$ represents the elementwise subtraction. Specifically, the inner product of $Q$ and $K$ depends upon the angle between the two vectors. In other words, it is the projection of one vector on the other vector, which means that the larger the projection value, the higher the correlation between the two vectors. As delineated in \eqref{e4}, the process involves computing the correlation between $Q$ (encoded PPG feature maps) and $K$ (encoded motion reference feature maps, including ACC and VEL), followed by the application of the $Softmax$ activation function for normalisation to derive the attention weights. Consequently, the components related to the MA feature map are removed to obtain a noise-free PPG feature map through \eqref{e4}.

Meanwhile, the `multi-head' in the proposed attention mechanism signifies that this attention computation is performed multiple times in parallel, with each 'head' learning different attention patterns, thereby capturing different types of relationships between the encoded PPG and motion reference (ACC and VEL) feature maps. In this work, we considered that the number of heads is eight  for the proposed attention mechanism (i.e., $h=8$.)

\subsection{Discriminator for Selective Inputs }
The Discriminator is a network structure with four 1D-convolutional layers followed by a global average pooling (GAP) layer and a fully connected (FC) as the final layer (illustrated in Fig.~\ref{Fig4}). The discriminator adopts the leaky rectified linear (LeakyReLU) activation function and incorporates batch normalisation to accelerate convergence. The discriminator evaluates probabilities, specifically assessing the probability of the output of the generator, $D(G(p(t), a_{x,y,z}(t)))$, and the probability associated with the reference signal, $D(s_{ref}(t))$.

\begin{figure}[!hbt]
    \centering
    \includegraphics[width=0.8\textwidth]{Fig4.eps}
    \caption{The discriminator structure.}
    \label{Fig4}
\end{figure}

\subsection{Loss function}
Noise removal in the PPG signal can be expressed by the equation $p(t)=s(t)+n(t), t \geq 0$ where $p(t)$ represents the raw PPG signal that includes MAs, $s(t)$ denotes the target PPG signal, and $n(t)$ is the noise that needs to be eliminated. In the discrete case
\begin{equation}
\label{e5}
s[i]=p[i]-n[i], i=1,2,3...
\end{equation}
where $i$ is the sampling index, and the $\pmb{p}=[p[i]]$, $\pmb{n}=[n[i]]$ and $\pmb{s}=[s[i]]$ are all 1D vectors. By capitalising on its strong ability to distinguish between noisy PPG signals, $\pmb{p}$, and reference PPG signals, $\pmb{s}_{ref}$, the method effectively learns the distribution features of both. This capability allows it to generate the de-noised PPG signal, $G(\pmb{p},\pmb{a}_{x,y,z})$.  
The waveform error loss, Mean Squared Error ($L_{MSE}$), is defined as calculating the point-wise error between $\pmb{s}_{ref}$ and $G(\pmb{p},\pmb{a}_{x,y,z})$ in the time domain, is given by
\begin{equation}
\label{e6}
L_{MSE}=\frac{1}{n} \sum_{i=1}^{n} \left \|\pmb{s}_{ref} - G(\pmb{p, a}_{x,y,z})\right\|_{2}
\end{equation}
where $\left \| \cdot \right\|_{2}$ represents the $L2$ norm. 

In summary, the overall loss function for the generator can be defined as:
\begin{equation}
\label{e8}
L_{G}= \log(1-D(G(\pmb{p, a_{x,y,z}}))+\lambda L_{MSE} 
\end{equation}
where the first item denotes the binary cross-entropy loss, and $\lambda$ is the balancing weight. In our experiments, the $\lambda$ is set to 1000 empirically based on the individual loss scales.

The discriminator binary cross entropy loss function is~\cite{b20ronneberger2015u} 
\begin{equation}
\label{e9}
\begin{split}
L_{D} =\log(D(\pmb{s}_{ref}))+\log(1-D(G(\pmb{p, a_{x,y,z}})))
\end{split}
\end{equation}
with which the discriminator differentiates between the generated and reference PPG signals. Through the adversarial learning process between the generator and the discriminator, the generator consistently acquires both global and local features. This learning ensures that the PPG signal produced closely mirrors the characteristics of the reference signal.

\section{Selective Measurement Protocols}
Three datasets provided by Loughborough University (in-house LU dataset), the IEEE Signal Processing Cup 2015 (IEEE-SPC dataset) and the publicly available PPG dataset (PPGDalia dataset) with their ethical approvals are experimented with the proposed AM-GAN.

The in-house LU dataset was collected with a multi-wavelength illumination optoelectronic patch sensor (mOEPS) at a sampling rate of 256Hz. It includes data from 12 subjects, aged between 23 and 37 years, recorded while they exercised on a treadmill \cite{b21zheng2023rapid}. The subjects engaged in exercise at four varying intensities, including 3$km/h$, 6$km/h$, 9$km/h$, and 12$km/h$, with each stage lasting four minutes and a 60-second recovery period between them. Additionally, the subjects engaged in cycling at a constant rate of 60 Revolutions Per Minute (RPM) across four different intensity levels, with power outputs set at 60 W, 100 W, 120 W, and 150 W. Each stage lasted four minutes with a 60-second recovery break in between. A ground-truth HR was captured using a Polar Bluetooth$^\circledR$ Smart chest strap (Polar Electro, Kempele, Finland), and a ground-truth RR was measured using a Vyntus$^\text{TM}$ CPX Metabolic cart (JAEGER$^\text{TM}$ Vyntus$^\text{TM}$ CPX, Carefusion, Germany).


The IEEE-SPC dataset features a two-channel PPG signal using green (515 nm) LEDs, a triaxial ACC signal, and an ECG reference, collected from 12 male subjects aged between 18 and 35 years. These datasets were sampled at a frequency of 125 Hz \cite{b6zhang2014troika}. The IEEE-SPC includes the training and testing datasets. In the training datasets, 12 subjects ran at varying speeds. Furthermore, 10 subjects (aged 19-58 years) performed intensive arm movements, i.e., boxing, in the testing datasets.

The PPGDalia includes synchronised recordings of ECG, wrist-worn PPG, and acceleration data from 15 subjects. Each subject contributed approximately two hours of recorded data. A consistent time shift between PPG and triaxial ACC signals was identified and manually fixed \cite{b29reiss2019deep}.

\section{Experimental Results}
The experimental studies constituting the three listed datasets were carried out to obtain physiological measurements allowing the extraction of two types of physiological parameters, i.e., HR and RR. These were used to evaluate the performance of the proposed AM-GAN with three physical activity datasets comprising: 1) network ablation experiments to assess the effectiveness of the proposed method; 2) performance evaluation of the proposed AM-GAN against some other recently reported methods; 3) effectiveness examination of the proposed AM-GAN in handling cross-dataset physiological parameter estimation. 

\subsection{Experimental Setup}
An eight-second sliding window technique is applied to analyse both the input and reference PPG signals, advancing one second at each step. All input and reference PPG signals are downsampled to 32 $Hz$. During the experiments, the proposed AM-GAN undergoes training for 100 epochs, with both the generator and discriminator networks being optimised concurrently using the Adam optimiser at a learning rate of 0.0002. The input PPG data is pre-processed with an eighth-order Butterworth band-pass filter with band edges set at 0.2 $Hz$ and 6.5 $Hz$. In all experiments, HR and RR are computed using the extraction algorithms defined in \cite{b21zheng2023rapid}.

\subsection{Experimental Results} 
\textbf{Waveform quality on in-house LU dataset:} Fig. \ref{Fig14} shows the selected PPG waveform in the time domain from the different physical activity intensities (subject-M10, treadmill), i.e., rest, low-intensity (6$km/h$), medium-intensity (9$km/h$) and high-intensity (12$km/h$). The generated PPG signals illustrate that the AM-GAN is capable of yielding results that closely approximate the reference signals across various levels of exercise intensity, thereby achieving satisfactory outcomes.

\begin{figure}[!hbt]
 \vspace{-0.5cm}
    \centering
    \setlength{\belowcaptionskip}{-0.3cm} 
    \begin{minipage}[b]{1\textwidth}
        \subfloat[]{
            \includegraphics[width=0.48\textwidth]{Fig14_rest.eps}
            \label{label_for_cross_ref_1}
        }\hspace{0mm}
        \subfloat[]{
    	\includegraphics[width=0.48\textwidth]{Fig14_low-intensity.eps}
            \label{label_for_cross_ref_2}
        }\hspace{0mm}
        \quad    
        \subfloat[]{
        	\includegraphics[width=0.48\textwidth]{Fig14_medium-intensity.eps}
            \label{label_for_cross_ref_3}
        }\hspace{0mm}%\hspace{-3.5mm}
        \subfloat[]{
    	\includegraphics[width=0.48\textwidth]{Fig14_high-intensity.eps}
            \label{label_for_cross_ref_4}
        }
    \end{minipage}
    \caption{A representative example for the waveform comparison of the original noisy signal, the reference signal and the generated signal at different physical activity intensities; i.e., (a) at rest, (b) low-intensity activity (6$km/h$), (c) medium-intensity activity (9$km/h$), and (d) high-intensity activity (12$km/h$).}
    \label{Fig14}
\end{figure}

\begin{equation}
\label{e10}
R= \frac{\int_{0}^{T} G(p(t), a_{x,y,z}(t))s_{ref}(t)dt}{\sqrt{\int_{0}^{T} G(p(t), a_{x,y,z}(t))^2dt} \sqrt{\int_{0}^{T} s_{ref}(t)^2dt}}
\end{equation}
To validate the error of the PPG signal generated by the AM-GAN method with respect to the reference PPG signal, the Pearson correlation ($R$) was applied for quantifying waveform, as shown in \eqref{e10}, where $G(p(t),a_{x,y,z}(t))$ is the zero-mean generated PPG signal and $s_{ref}(t)=MR(p(t),a_{x,y,z}(t))$ is the zero-mean reference signal, for each vector $p(t)$ in the test set, $\mathcal{P}_{Te}$. An eight-second sliding time window was employed for the calculation of the waveform quality. The waveform quality index ($R$), for the treadmill exercise test cases of subject F01, is shown in Fig. \ref{Fig13}(a). The mean Pearson correlation ($\overline{\langle R \rangle}$) for all LU testing subjects is illustrated in Fig. \ref{Fig13}(b). It is clear the AM-GAN outputs are highly correlated with the reference signals with a high level of consistency across the entire set of test vectors and for all testing subjects, and the $Mean$ value of all testing subjects' waveform quality ($\overline{\langle R \rangle}$) is 0.9522.

\begin{figure}[hbt]
    \setlength{\belowcaptionskip}{-0.3cm} 
    \begin{minipage}[b]{1\textwidth}
    \centering
    \subfloat[]{
        \includegraphics[width=0.48\textwidth]{Fig13_a.eps}
    }\hspace{-3mm}
    \subfloat[]{
        \includegraphics[width=0.48\textwidth]{Fig13_b.eps}
    }
    \caption{Waveform quality validation on LU subjects (F-female, M-male, T-treadmill, C-cycling). (a) Waveform quality ($R$) for F01-treadmill. (b)Mean waveform quality ($\overline{\langle R \rangle}$) across all LU testing subjects.}
    \label{Fig13}
    \end{minipage}
\end{figure}

\textbf{HR and RR calculation on in-house LU dataset:} To evaluate the effectiveness of the method, heart rate (HR) and respiratory rate (RR) are independently computed for both the generated signals $G(p(t),a_{x,y,z}(t))$ and the reference PPG signals $s_{ref}(t)$. These results are then compared with readings from commercial devices using the in-house dataset. Following the in-house protocol, the first eight subjects are used for training and validation with a ratio of 0.7 and 0.3, adopting the green-channel illumination during the treadmill exercise and the remaining four subjects are used for testing. Also, data from these 12 subjects during cycling exercise at different intensities is applied in the procedure.

The outcomes of continuous HR monitoring during treadmill and cycling exercises are shown in Fig.~\ref{Fig5}(a) and \ref{Fig5}(b), where they are compared to the reference values from a commercial device. In Fig.~\ref{Fig5}, \textit{Polar} refers to the reference heart rate recorded with a Polar Bluetooth Smart chest strap. In both figures, the MA-removal reference uses our previously published algorithm~\cite{b21zheng2023rapid}. The accuracy in capturing HR is consistent and closely matches the provided reference.
\begin{figure}[hbt]
    \setlength{\belowcaptionskip}{-0.3cm} 
    \begin{minipage}[b]{1\textwidth}
    \centering
    \subfloat[]{
        \includegraphics[width=0.48\textwidth]{Fig5_a.eps}
    }\hspace{-3mm}
    \subfloat[]{
        \includegraphics[width=0.48\textwidth]{Fig5_b.eps}
    }
    \caption{HR calculation outcomes for two randomly selected datasets (in BPM: beats/min) are displayed. (a) Shows the results for the M10 dataset during treadmill exercise, while (b) shows results for the M08 dataset during cycling exercise. The top of the figure indicates the various exercise intensities, with the red arrow pointing to the rest status.}
    \label{Fig5}
    \end{minipage}
\end{figure}

The Bland-Altman plot comparing the ground truth to the computed outcome is depicted in Fig. \ref{Fig6}(a). In this case, the limits of agreement (LOA) ranged from $[-4.04, 3.80]$ beats/min, with 95\% of the differences falling within this interval. Fig. \ref{Fig6}(b) shows the scatter plot comparing the ground-truth HR values to those calculated for 16 test subjects (12 undergoing cycling and 4 on treadmill exercises). Additionally, the line of best fit, represented as 
$y=1.005x-0.7492$, is displayed, where $x$ is the ground-truth HR and  $y$ is the calculated HR. The Pearson correlation coefficient $R$ achieved using the proposed AM-GAN is 0.9970.
\begin{figure}[hbt]
    \setlength{\belowcaptionskip}{-0.3cm} 
    \begin{minipage}[b]{1\textwidth}
    \centering
    \subfloat[]{
        \includegraphics[width=0.48\textwidth]{Fig6_a.eps}
    }\hspace{-3mm}
    \subfloat[]{
        \includegraphics[width=0.48\textwidth]{Fig6_b.eps}
    }
    \caption{HR results calculated from the 16 testing subject datasets (in BPM: beats/min) in the cycling and treadmill exercises. (a) Bland-Altman plot. (b) Scatter plot of Pearson correlation.}
    \label{Fig6}
    \end{minipage}
\end{figure}

The RR performance in the presence of MAs is demonstrated in Figs. \ref{Fig7} and \ref{Fig8}. Fig. \ref{Fig7} presents the RR derived from two randomly selected datasets. The blue line showcases the computed RR, while the red line indicates the true RR as measured by the Vyntus$^\text{TM}$ CPX Metabolic cart. As illustrated in Fig.\ref{Fig7}, the computed RR closely aligns with the structure of the ground-truth RR. Furthermore, due to significant fluctuations in the continuously measured RR shown in Fig.\ref{Fig7}, a blue-shaded area is included to depict the average RR across various exercise stages. This provides a more intuitive representation of changes in the RR.
\begin{figure}[!hbt]
    \setlength{\belowcaptionskip}{-0.3cm} 
    \begin{minipage}[b]{1\textwidth}
    \centering
    \subfloat[]{
        \includegraphics[width=0.48\textwidth]{Fig7_a.eps}
    }\hspace{-3mm}
    \subfloat[]{
        \includegraphics[width=0.48\textwidth]{Fig7_b.eps}
    }
    \caption{RR calculation results on two randomly selected datasets (in breaths/minute, bpm). (a) Results from the F01 dataset during treadmill exercise. (b) Results from the M04 dataset during cycling exercise. The top of the figure indicates the various exercise intensities, with the red arrow pointing to rest periods.}
    \label{Fig7}
    \end{minipage}
\end{figure}

The Bland-Altman plot for all subjects is presented in Fig. \ref{Fig8}(a). The LOA between the ground-truth and the calculated RR data is [-6.48, 7.26] breaths/min, and 95\% of all differences were inside this range. Furthermore, a fit line $y=0.8886x+3.3014$ has been constructed to represent the relationship between the ground-truth and calculated RR, demonstrating a Pearson correlation coefficient ($R=0.9253$), as illustrated in Fig. \ref{Fig8}(b).
\begin{figure}[hbt]
    \setlength{\belowcaptionskip}{-0.3cm} 
    \begin{minipage}[b]{1\textwidth}
    \centering
    \subfloat[]{
        \includegraphics[width=0.48\textwidth]{Fig8_a.eps}
    }\hspace{-3mm}
    \subfloat[]{
        \includegraphics[width=0.48\textwidth]{Fig8_b.eps}
    }
    \caption{RR results, measured in breaths/minute (bpm), were derived from the datasets of 16 test subjects during cycling and treadmill exercises. Displayed are (a) a Bland-Altman plot and (b) a scatter plot illustrating the Pearson correlation.}
    \label{Fig8}
    \end{minipage}
\end{figure}

The average absolute error ($Err1$), the average absolute error percentage ($Err2$) and the standard deviation ($SD$) are defined to further evaluate the accuracy of the proposed AM-GAN by performing HR and RR calculations. Table \ref{Tab1} presents the $Err1$ and $Err2$ values for the cycling and treadmill exercise. The average across the 16 testing subject datasets, $\overline{Err1}$ of the proposed AM-GAN is $1.37 \pm 0.32 $ beats/min (Mean $\pm$ SD), and that of $\overline{Err2}$ is $1.29\% \pm 0.35\%$ for the HR calculation. $\overline{Err1}$ is $2.49 \pm 0.52$ breaths/min (Mean $\pm$ SD) and $\overline{Err2}$ is $10.78\% \pm 1.94\%$ for the RR calculation.

\begin{table}[!hbt]
\renewcommand{\arraystretch}{1.5}
\centering
\resizebox{1\textwidth}{!}{
\begin{tabular}{p{0.65cm} p{0.65cm} p{0.65cm} p{0.65cm} p{0.65cm} p{0.65cm} p{0.65cm} p{0.65cm} p{0.65cm} p{0.65cm} p{0.65cm} p{0.65cm} p{0.65cm} p{0.65cm} p{0.65cm} p{0.65cm} p{0.65cm} p{0.65cm}}
\toprule
	& Subj & F01T& M04& M07& M10&   F01C	&F02 &F03&	M04&	M05	&M06&	M07&	M08&	M09&	M10&	M11&	M12\\
\hline
HR	& $Err1$ &	1.25&	1.61&	1.61&	1.99&	1.44&	0.94&	1.10&	1.96&	1.09&	0.99&	1.37&	1.34& 1.28&  1.38&1.30& 0.99\\
&$Err2$&	0.94&	1.26&	1.43&	1.85&	1.22&	0.71&	0.96&	1.83&	1.13&	0.82&	1.44&	1.73& 1.22&  1.59&1.23& 0.93\\
\hline
RR	&$Err1$&	2.67&	2.83&	3.15&	3.43&	2.75&	2.94&	2.19&	2.32&	1.55&	3.10&	1.96&	2.50& 2.21& 2.19&  2.06& 1.93\\
&$Err2$&	7.31&	7.54&	11.66&	12.83&	9.06&	9.75&	12.10&	11.04&	10.46&	13.43&	10.16&	14.55& 9.90& 11.03& 10.28& 11.43\\
\bottomrule
\end{tabular}
}
\caption{Average Absolute Error ($Err1$) (in beats/min) and Average Error Percentage ($Err2$) (\%) for all subjects (F-female, M-male, T-treadmill, C-cycling) of the in-house LU dataset during the cycling and treadmill exercises.}
\label{Tab1}
%\vspace{-0.3cm}
\end{table}

\textbf{HR calculation on IEEE-SPC dataset:} The performance of AM-GAN was assessed using the IEEE SPC dataset as a benchmark, which includes 12 training datasets and 10 testing datasets, detailed in Table \ref{Tab2}. $Err1$, $Err2$, and $SD$ were calculated and compared with results from other methods using a testing dataset of 10 subjects. This dataset included data collected under strenuous exercise conditions such as weight-lifting, swimming, boxing, and handshaking. In these scenarios, the prominence of MAs can make the assessment of physiological parameters more difficult. This table shows that, for 10 test subjects with the most noise, the AM-GAN produced HR calculations with $Err1$ of 1.81 and $SD$ of 0.76 beats/min, and also with $Err2$ of 1.86 and $SD$ of 1.63 \%. From the $Err1$ and $Err2$ values, the AM-GAN has a better performance compared to the other traditional de-noised methods, but it is not yet as accurate as the CorNET \cite{b9biswas2019cornet} network that adopts a deep learning architecture. CorNET and AM-GAN use different forms of output; the input of CorNET is the PPG signal and the output is the HR value, which is more of a black-box structure and does not clearly reflect the characteristics of the signals corresponding to different HRs. On the contrary, the AM-GAN has an input of PPG signal with noise and an output of noise-free PPG signal, which is used to calculate HR as well as other physiological parameters using the noise-free PPG signal. Additionally, the difference in $Err1$ between the proposed AM-GAN and the reference method (MR) suggests a fundamental similarity in their performance. Meanwhile, the $SD$ of the proposed method ($SD=0.76$  beats/min) is smaller than that of the MR method ($SD=1.42$  beats/min), it signifies a reduced intergroup error value for the proposed AM-GAN, indicative of superior robustness. Furthermore, the proposed AM-GAN incorporates an Attention Mechanism ($Err1=1.81$  beats/min), enhancing the precision of physiological parameter calculation, in contrast to our previous PPG-GAN method without utilising such a mechanism ($Err1=1.93$  beats/min). 

\begin{table}[!hbt]
\renewcommand{\arraystretch}{2}
\centering
\resizebox{1\textwidth}{!}{
\begin{tabular}{
 >{\centering\arraybackslash}p{1cm}
>{\centering\arraybackslash}p{1.1cm}
>{\centering\arraybackslash}p{1.7cm}
>{\centering\arraybackslash}p{1.5cm}
>{\centering\arraybackslash}p{1.7cm}
>{\centering\arraybackslash}p{1.7cm}
>{\centering\arraybackslash}p{1.7cm}
>{\centering\arraybackslash}p{1.7cm}
>{\centering\arraybackslash}p{1.7cm}
>{\centering\arraybackslash}p{1.5cm}
>{\centering\arraybackslash}p{1.5cm}
>{\centering\arraybackslash}p{1.5cm}
}
\toprule
Subject	& Activity& TROIKA \cite{b6zhang2014troika} & JOSS \cite{b25zhang2015photoplethysmography}  & SPECMAR \cite{b26islam2019specmar}   & MURAD \cite{b27chowdhury2016real}  &  Temko \cite{b28temko2017accurate} & ANFA \cite{b18zheng2022adaptive}& MR method \cite{b21zheng2023rapid}& CorNET\cite{b9biswas2019cornet} & PPG-GAN \cite{b29zheng2022ppg}& Proposed AM-GAN\\
\hline

1& T2& 6.63(8.76)& 8.07(10.90)&   6.57&   6.35(7.99)&     9.59(10.90)&    4.99(7.52)&  5.69(7.63)& 1.60& 3.67& 3.46(6.29)\\
2& T2& 1.94(2.56)& 1.61(2.01)&   1.76&   1.15(1.58)&    3.65(2.43)&   1.46(1.99)&  1.02(1.35)&  0.24&  1.35&   1.21(1.45)\\
3& T3& 1.35(1.04)& 3.10(2.69)&   2.28&   1.51(1.25)&    3.90(1.51)&   1.77(0.94)&  1.02(0.83)&  1.60&  1.53&   1.46(0.89)\\
4& T3& 7.82(4.88)& 7.01(4.49)&   2.77&   2.96(1.87)&    2.44(1.49)&   2.89(1.51)&  1.89(1.27)&  2.04&  2.75&   2.66(1.53)\\
5& T3& 2.46(2.00)& 2.99(2.52)&   2.94&   2.78(2.24)&    2.14(1.70)&   2.93(0.93)&  1.83(1.55)&  0.95&  2.25&   2.09(1.81)\\
6& T3& 1.73(1.27)& 1.67(1.23)&   4.80&   1.54(1.12)&    2.60(0.90)&   1.98(1.01)&  1.15(0.85)&  0.28&  1.44&   1.31(0.99)\\
7& T2& 3.33(3.90)&	2.80(3.46)&	  2.72&	  2.03(2.24)&	1.86(1.78)&	  2.01(3.65)&  1.82(2.10)&  0.28&  1.96&   1.73(2.45)\\
8& T3& 3.41(2.43)&	1.88(1.32)&	  3.28&	  2.02(1.61)&	0.85(1.96)&	  1.92(1.31)&  1.73(1.22)&  0.67&  1.77&   1.68(1.21)\\
9& T3& 2.69(2.12)&	0.92(0.74)&	  1.55&	  0.97(0.76)&	3.06(0.80)&	  1.86(1.04)&  0.99(0.80)&  0.42&  1.58&   1.52(1.13)\\
10& T2& 0.51(0.59)&	0.49(0.57)&	  0.82&	  0.83(0.66)&	3.38(0.59)&	  1.16(0.97)&  0.84(0.98)&  0.57&  0.99&   0.93(0.90)\\
 
\hline

Mean&	1-10& 3.19(2.96)&	3.05(2.99)&	2.95&	2.21(2.13)&		3.35(2.41)&	       2.30(2.09)&    1.80(1.85)& 0.86& 1.93& 1.81(1.86)\\
SD  &   1-10&   2.32(2.41)   &   2.53(3.04)&   1.67&   1.62(2.13)&    2.37(3.04)&  1.99(2.08)&  1.42(2.06)& 0.65& 0.79& 0.76(1.63)\\

\bottomrule
\end{tabular}
}
\caption{$Err1(Err2)$ (in beats/min and \%) values for the AM-GAN method compared to some other recently reported results, obtained on the IEEE-SPC dataset.}
\label{Tab2}
% \vspace{-0.3cm}
\end{table}

\textbf{Cross-dataset HR validation:} Generalisation capacity is crucial for real-time physiological monitoring. To validate this aspect, cross-database evaluations have been performed to assess the generalisation ability of the proposed AM-GAN. The AM-GAN is trained on the in-house LU dataset and tested on the PPGDalia dataset for HR calculation. The proposed AM-GAN is compared with our previous adversarial network model without attention mechanism, i.e., PPG-GAN \cite{b29zheng2022ppg}. The cross-dataset HR calculation results of the proposed AM-GAN and the PPG-GAN are demonstrated in Table \ref{Tab3}.

\begin{table}[!hbt]
\renewcommand{\arraystretch}{2}
\centering
\resizebox{1\textwidth}{!}{
\begin{tabular}{
 >{\centering\arraybackslash}p{3.5cm}
>{\centering\arraybackslash}p{0.7cm}
>{\centering\arraybackslash}p{0.7cm}
>{\centering\arraybackslash}p{0.7cm}
>{\centering\arraybackslash}p{0.7cm}
>{\centering\arraybackslash}p{0.7cm}
>{\centering\arraybackslash}p{0.7cm}
>{\centering\arraybackslash}p{0.7cm}
>{\centering\arraybackslash}p{0.7cm}
>{\centering\arraybackslash}p{0.7cm}
>{\centering\arraybackslash}p{0.7cm}
>{\centering\arraybackslash}p{0.7cm}
>{\centering\arraybackslash}p{0.7cm}
>{\centering\arraybackslash}p{0.7cm}
>{\centering\arraybackslash}p{0.7cm}
>{\centering\arraybackslash}p{0.7cm}
>{\centering\arraybackslash}p{2.5cm}
}
\toprule
	& S1& S2 & S3& S4&  S5&  S6& S7& S8& S9& S10& S11& S12& S13& S14& S15& Mean (SD)\\
\hline
DeepPPG \cite{b29reiss2019deep}& 7.73& 6.74& 4.03& 5.90& 18.51& 12.88&	3.91&	10.87&	8.79&	4.03&	9.22&	9.35&	4.29&	4.37&	4.17& 7.65 (4.15)\\
NAS-PPG \cite{b30risso2021robust} & 5.46&	5.01&	3.74&	6.48&	12.68&	10.52&	3.31&	8.07&	7.91&	3.29&	7.05&	6.76&	3.84&	4.85&	3.57& 6.17 (2.77)\\
Q-PPG \cite{b31burrello2021q} & 4.29&	3.62&	2.44&	5.73&	10.33&	5.26&	\textbf{2.00}&	\textbf{7.09}&	8.60&	3.09&	4.99&	\textbf{6.25}&	1.92&	3.02&	3.55& 4.81 (2.46)\\
Aug-TEMPONet \cite{b32burrello2022improving}&  4.97&	4.34&	2.39&	6.14&	9.41&	\textbf{3.63}&	2.23&	9.14&	10.98&	3.40&	5.27&	7.64&	2.05&	2.84&	3.61& 5.20 (2.86)\\
\hline
Ours& &&&&&&&&&&&&&& \\ 
\hline
PPG-GAN \cite{b29zheng2022ppg}& 4.81&	3.85&	2.62&	5.31&	9.63&	4.69&	2.32&	9.99&	8.06&	3.54&	3.93&	6.68&	1.84&	3.42&	2.95&   4.91 (2.57)\\
AM-GAN & \textbf{3.01}&	\textbf{2.98}&	\textbf{2.04}&	\textbf{3.97}&	\textbf{7.9}&	4.64&	2.41&	7.12&	\textbf{5.83}&	\textbf{2.33}&	\textbf{3.09}&	6.38&	\textbf{1.73}&	\textbf{2.49}&	\textbf{2.01}&   \textbf{3.86 (2.02)}\\

\bottomrule
\end{tabular}
}
\caption{$Err1$ values for cross-dataset HR calculation (training on LU dataset and testing on PPGDalia dataset) by the proposed AM-GAN and PPG-GAN method to compare with the SOTA methods. }
\label{Tab3}
% \vspace{-0.3cm}
\end{table}

The comprehensive cross-dataset HR calculation outcomes for both the proposed AM-GAN and the PPG-GAN are presented in Table \ref{Tab3}. The proposed AM-GAN illustrated the best results, given mean HR calculations with $\overline{Err1}$ of $3.86$ and $SD$ of $2.02$ beats/min, compared with PPG-GAN and SOTA methods. However, subjects S5, S6 and S8 have posed challenges with high $Err1$ values. Comparison of S5, S6 and S8 shows that the underlying causes of high errors are different. S5 and S6 are primarily affected by the out-of-distribution samples, and S8 is mainly affected by the lower signal quality of collected data. In summary, the cross-dataset HR validations indicate that the proposed AM-GAN exhibits robust generalisation capabilities in scenarios characterised by unknown noise and MAs.

\textbf{Ablation study:} The ablation study is performed to evaluate the performance of AM-GAN using the in-house LU dataset. The following ablation study is covered: (I) without triaxial ACC as input; (II) without discriminator; (III) without attention mechanism; and (IV) the whole AM-GAN method. The results are presented in Table \ref{Tab4} 

\begin{table}[!hbt]
\normalsize
\renewcommand{\arraystretch}{1.5}
\centering
\resizebox{1\textwidth}{!}{
\begin{tabular}{
 >{\centering\arraybackslash}p{3.5cm}
>{\centering\arraybackslash}p{3cm}
>{\centering\arraybackslash}p{3cm}
>{\centering\arraybackslash}p{2cm}
>{\centering\arraybackslash}p{2cm}
>{\centering\arraybackslash}p{2cm}
>{\centering\arraybackslash}p{2cm}
}
\toprule
	Attention Mechanism& Discriminator& triaxial ACC Input & $\overline{Err1}$(HR)& $\overline{Err2}$(HR)&  $\overline{Err1}$(RR)&  $\overline{Err2}$(RR)\\
\hline
w/o & w/o& w/o& 3.81&   3.90&   4.99&   14.86\\
w/o & w.&  w/o&	3.22&	3.69&	4.63&	14.43\\
w/o & w/o& w.&	2.99&	3.03&	4.11&	13.98\\
w/o & w.&  w.&	2.45&	2.71&	3.65&	13.12\\
w. & w/o&  w.&	1.89&	1.73&	3.01&	12.35\\
w. & w.&  w.&	\textbf{1.37}&	\textbf{1.29}&	\textbf{2.49}&	\textbf{10.78}\\

\bottomrule

\end{tabular}
}
\caption{Ablation study of proposed AM-GAN in terms of attention mechanism, discriminator and triaxial ACC input for HR and RR validation on in-house LU dataset. }
\label{Tab4}
% \vspace{-0.3cm}
\end{table}

Comparing the results by (I) and (II), we can observe that using triaxial ACC input can reduce the $\overline{Err1}$($\overline{Err2}$) by 0.23(0.66) beats/min(\%) for HR validation and 0.52(0.45) breaths/min(\%) for RR. This suggests that the triaxial ACC input as multi-sensor fusion is helpful for improving HR and RR validation accuracy. Similarly, using the attention mechanism for multi-sensor fusion can greatly improve HR and RR validation accuracy. These results indicate that the attention mechanism integrates inputs from multiple sensors for multi-sensor feature fusion to learn a good distribution about the MAs mixed with the PPG signals. It leads to better PPG feature disentanglement.

\begin{figure}[!hbt]
    \centering
    \begin{minipage}[b]{1\textwidth}
    \subfloat[]{
        \includegraphics[width=0.48\textwidth]{Fig11_a.eps}
    }\hspace{0mm}
    \subfloat[]{
        \includegraphics[width=0.48\textwidth]{Fig11_b.eps}
    }
    \vspace{0mm} % Adjust the space here
    \subfloat[]{
        \includegraphics[width=0.48\textwidth]{Fig11_c.eps}
    }\hspace{-4mm}
    \subfloat[]{
        \includegraphics[width=0.48\textwidth]{Fig11_d.eps}
    }
    \vspace{0mm} % And here
    \subfloat[]{
        \includegraphics[width=0.48\textwidth]{Fig11_e.eps}
    }\hspace{0mm}
    \subfloat[]{
        \includegraphics[width=0.48\textwidth]{Fig11_f.eps}
    }
    \vspace{0mm} % And here
    \subfloat[]{
        \includegraphics[width=0.48\textwidth]{Fig11_g.eps}
    }\hspace{0mm}
    \subfloat[]{
        \includegraphics[width=0.48\textwidth]{Fig11_h.eps}
    }
    \caption{Raw signal and de-noised PPG signals in time and frequency domains. (a) Time-domain raw PPG signal. (b) Frequency-domain raw PPG signal (P) and triaxial ACC signals (Ax, Ay and Az). (c,d) Time and frequency-domain generated de-noised PPG signal from PPG-GAN \cite{b29zheng2022ppg}. (e,f) Time and frequency-domain de-noised PPG signal from MR \cite{b21zheng2023rapid}. (g,h) Time and frequency-domain generated de-noised PPG signal from AM-GAN.}
    \label{Fig11}
    \end{minipage}
    \vspace{-6mm}
\end{figure}

Additionally we present a visualisation of the synthetic outcomes by comparing results (III) and (IV). The generated de-noised PPG signals are demonstrated in time and frequency domains by the without attention mechanism method (PPG-GAN), the SOTA MA-removal algorithm (MR) and the proposed AM-GAN in Fig. \ref{Fig11}. This demonstration presents a complex example from the MW dataset in which the period of the HR and the motion period detected by the three-axis accelerometer sensor align closely, as depicted in Fig. \ref{Fig11}(b). The MR method, which employs triaxial ACC as the motion reference, inadvertently filters out the real HR frequency owing to the exact overlap between the motion reference period and the HR period, as illustrated in Fig. \ref{Fig11}(e) and (f). PPG-GAN is not effective in dealing with this scenario, as shown in Fig. \ref{Fig11}(c) and (d). This also explains why the AM-GAN is able to work as a noise-reduced model across varying intensities of exercise to enhance the robustness in calculating physiological parameters, i.e., HR and RR. Additionally, the loss incurred by the generator in both PPG-GAN and AM-GAN during the training and validation phases for the LU dataset is depicted in Fig. \ref{Fig12}. Notably, both models employ an identical loss function for their generators, \eqref{e8}. The proposed AM-GAN exhibits lower loss values and a superior alignment of the training loss curve with the validation loss curve, indicating a more effective model generalisation. Conversely, the PPG-GAN without the attention mechanism demonstrates a minor degree of overfitting, as evidenced by the analysis in Fig. \ref{Fig12}(a). 

\begin{figure}[!hbt]
    \setlength{\belowcaptionskip}{-0.3cm} 
    \begin{minipage}[b]{1\textwidth}
    \centering
    \subfloat[]{
        \includegraphics[width=0.48\textwidth]{Fig12_a.eps}
    }
    \hspace{-3mm} % Optional: for alignment
    \subfloat[]{
        \includegraphics[width=0.48\textwidth]{Fig12_b.eps}
    }
    \caption{Generator loss comparison of (III) and (IV). (a)PPG-GAN. (b) AM-GAN.}
    \label{Fig12}
    \end{minipage}
\end{figure}

\section{Discussion} 
The study has created an adversarial learning strategy with an attention mechanism to obtain clinically acceptable physiological parameters through PPG signals acquired from those subjects engaged in exercise at varying intensities. In these scenarios of high intensity, the measured signals exhibit substantial distortion, primarily due to the incorporation of MAs, a situation exacerbated by the potential overlap between motion frequencies and those found within the cardiac waveform. It is imperative, therefore, that MAs are eliminated prior to the assessment of any physiological parameter. The output from the triaxial accelerometer to act as motion reference signals was acquired along with four-channel PPG signals of mOEPS, and MAs were removed using the adversarial network with an attention mechanism (AM-GAN). The values for HR and RR were extracted from the generated MA-free signal showing the AM-GAN to have accurate vital signs even in the state of higher-intensity exercise. The analysis of these outcomes across three distinct datasets reveals a substantial enhancement in accuracy attributable to the consolidation of the modified GAN and the multi-head cross-attention mechanism.

The quality of the pulsatile waveform, quantified by the Pearson correlation coefficient $R$, is illustrated in Table \ref{Fig13}. Fig. \ref{Fig13}(a) and (b) evidence a high degree of consistency between the generated PPG signals and the reference signal across all LU datasets ($\overline{\langle R \rangle}>90$). The incorporation of the in-house LU dataset has facilitated the acquisition of benchmark readings for HR and RR. This benchmarking is crucial for assessing the accuracy of the AM-GAN method in extracting these vital measurements. The IEEE-SPC dataset and PPGDalia dataset served as a benchmark for comparing the performance of the AM-GAN against SOTA algorithms. 

Table \ref{Tab2} demonstrates that the proposed AM-GAN achieves higher accuracy in HR extraction from the IEEE-SPC dataset compared to SOTA algorithms. The CorNET framework achieves more precise HR extraction (0.86 beats/min \textless 1.81 beats/min) compared to the AM-GAN; however, it is limited to assessing only HR. In contrast, the AM-GAN is designed to deliver a complete pulsatile waveform with MAs removed, enabling the extraction of multiple physiological parameters. The precision of RR extraction demonstrates satisfactory alignment with the Vyntus$^\text{TM}$ CPX Metabolic cart, manifesting an average absolute error of $3.02$ breaths/min and $2.31$ breaths/min for cycling and treadmill exercises, respectively. The average absolute error associated with RR measurements exceeds that of HR measurements. This difference can be attributed to the fact that RR frequencies fall within a lower frequency range (0.1-1.0 Hz), rendering them more vulnerable to motion interference compared to HR extraction. Furthermore, AM-GAN also has a better performance for cross-dataset (PPGDalia) HR validation with $\overline{Err1}$ of $3.86$ and $SD$ of $2.02$ beats/min compared with the SOTA methods, as shown in Table \ref{Tab3}. 

It is presented that the AM-GAN has robust generalisation capabilities in scenarios characterised by unknown noise and MAs. However, some of the subject data have posed challenges with high $Err1$ values, such as S5, S6 and S8. A comparison of S5, S6 and S8 demonstrates that the lower signal quality of collected data and out-of-distribution HR values could cause the high $Err1$ values. Therefore, experimental outcomes using the in-house LU dataset, PPGDalia dataset, and IEEE-SPC dataset indicate that the proposed AM-GAN effectively eliminates MAs and improves the quality of noisy input PPG signals. The resulting clean PPG signal enables the determination of HR and RR with an accuracy exceeding 95\% when compared to gold standard references. Additionally, the ablation study is performed to validate the interpretability of the AM-GAN method, as shown in Table \ref{Tab4}. The visualisation of the generated de-noised PPG signals also presents better performance in the challenge scenarios, i.e., high-intensity exercise.

Although we achieved highly satisfactory results, there is still a lot of room to be improved. Firstly, we mainly focus on removing motion artefacts due to the availability of these published datasets. However, other artefacts, like muscular artefacts, may need to be eliminated in some scenarios. Second, we need the reference PPG signal from the SOTA MA-removal algorithms during the training phase. The performance of AM-GAN could significantly drop since it is bound to be inferior to generate the ground truth. There could be a rare straightforward solution to deliver quality ground truth yet its impact could be mitigated. The usage of unique training techniques, model architectures and model layers could decrease the data requirements in the training process.


\section{Conclusion} 
The cardiac signal plays a crucial role in the computation of physiological parameters, including HR and RR. The study presents an AM-GAN approach to extract high-quality pulsatile waveforms for opto-physiological monitoring. The AM-GAN framework combines the generative adversarial and attention mechanisms, with error losses defined in both the time and frequency domains.

A noisy PPG signal, together with the triaxial ACC signals, comprises the network inputs; its output is an enhanced pulsatile waveform through the deep generative model that can be easily incorporated with existing opto-physiological monitoring methods.

The experimental results on two in-house datasets and one public dataset demonstrate that the AM-GAN consistently improves the quality of noisy input PPG signals to generate quality pulsatile waveforms, thus achieving accurate physiological parameters, i.e., HR and RR, both within-dataset and cross-dataset. The comparison results with other recently reported PPG methods, such as $Err1(Err2)$, verify the better performance of AM-GAN to calculate the accuracy of HR by generating high-quality pulsatile waveforms.

The AM-GAN has demonstrated its ability to learn an MA removal algorithm (here the MR algorithm, \cite{b21zheng2023rapid}), providing a fixed structure that can be updated as more effective algorithms are developed. Interestingly, it has also shown greater capability than the original MR algorithm in handling more complex situations, such as instances where cardiac cycle frequency coincides with the motion frequency during a higher-intensity exercise. While the results presented in the study are relatively preliminary, these efforts are significant in broadening the application spectrum of opto-physiological monitoring.

\section*{Acknowledgments} 
The authors would like to acknowledge the support of Loughborough University in the conduction of this study and the shared datasets from the IEEE-SPC and PPGDalia.

\section*{Conflict of interest} The authors declare that there is no any conflict of interest for this study.

% \section*{Author Contributions}
% XZ carried out the study, validation, software, methodology and original draft. VMD provided background knowledge and advised on original work, co-supervised the study. LAB provided exercise protocol and advised on original work, co-supervised the study. MD jointly supervised the study and reviewed the manuscript. SH structured the manuscript, analyzed the outcomes, and supervised the study.

%% The Appendices part is started with the command \appendix;
%% appendix sections are then done as normal sections
% \appendix

%% If you have bibdatabase file and want bibtex to generate the
%% bibitems, please use
%%
\bibliographystyle{elsarticle-num} 
\bibliography{main}

%% else use the following coding to input the bibitems directly in the
%% TeX file.

% \begin{thebibliography}{00}

% %% \bibitem{label}
% %% Text of bibliographic item

% \bibitem{}

% \end{thebibliography}
\end{document}
\endinput
%%
%% End of file `elsarticle-template-num.tex'.
