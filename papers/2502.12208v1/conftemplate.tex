\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
%Template version as of 6/27/2024

\usepackage{cite}
\usepackage[OT1]{fontenc} 
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{comment}
\usepackage[ruled,norelsize]{algorithm2e}
\newcommand{\red}[1]{\textcolor{red}{#1}}

\newcommand{\noteBK}[1]{\textcolor{purple}{[{\bf #1}]}}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

%\title{Morphing Reality: Smarter Tests for Autonomous Driving Systems
%}
\title{AI-Augmented Metamorphic Testing for Comprehensive Validation of Autonomous Vehicles}
\author{
    \IEEEauthorblockN{Tony Zhang$^{*}$, Burak Kantarci$^{*}$, Umair Siddique$^{**}$}
    \IEEEauthorblockA{
        $^{*}$School of Electrical Engineering and Computer Science, University of Ottawa, Canada\\
        \texttt{\{yzhan117,burak.kantarci\}@uOttawa.ca}\\[2mm]
        $^{**}$reasonX Labs Inc., Ottawa, Canada\\
        \texttt{umair@reasonx.ai}
    }
}

\maketitle

\begin{abstract}
%Autonomous Driving Systems (ADS) promise transformative transportation advancements, yet ensuring their safety remains a critical challenge due to real-world unpredictability and system complexity. Traditional testing approaches face limitations like the oracle problem and difficulty in simulating diverse environments. Metamorphic Testing (MT) addresses these challenges but often relies on simplistic transformations, limiting its scope. This posiyion paper proposes combining MT with generative models, such as Stable Diffusion, to enhance ADS testing. Generative models can create controlled variations in scenarios—e.g., minor environmental changes, weather variations, or lane adjustments—while maintaining essential properties to evaluate ADS performance. This approach enables reproducible tests, reusable oracles, and systematic robustness assessment. By leveraging generative models, this framework overcomes traditional MT limitations, advancing ADS safety and reliability.

Self-driving cars have the potential to revolutionize transportation, but ensuring their safety remains a significant challenge. These systems must navigate a variety of unexpected scenarios on the road, and their complexity poses substantial difficulties for thorough testing. Conventional testing methodologies face critical limitations, including the oracle problem—determining whether the system’s behavior is correct—and the inability to exhaustively recreate a range of situations a self-driving car may encounter. While Metamorphic Testing (MT) offers a partial solution to these challenges, its application is often limited by simplistic modifications to test scenarios. In this position paper, we propose enhancing MT by integrating AI-driven image generation tools, such as Stable Diffusion, to improve testing methodologies. These tools can generate nuanced variations of driving scenarios within the operational design domain (ODD)—for example, altering weather conditions, modifying environmental elements, or adjusting lane markings—while preserving the critical features necessary for system evaluation.
This approach enables reproducible testing, efficient reuse of test criteria, and comprehensive evaluation of a self-driving system’s performance across diverse scenarios, thereby addressing key gaps in current testing practices.
\end{abstract}

\begin{IEEEkeywords}
Metamorphic Testing, Autonomous Driving Systems, Metamorphic Testing, Version Model, Image Transformation.
\end{IEEEkeywords}

\section{Introduction}
The development and validation of Autonomous Driving Systems (ADS) \cite{zhao2023autonomous} present significant challenges due to the complexity of real-world environments. Unlike traditional software systems with well-defined inputs and outputs, ADS must operate in dynamic, unpredictable environments that demand sophisticated testing methodologies. Further complicating this challenge, many modern ADS architectures operate as black-box systems \cite{9284628}, making their decision-making processes opaque and their outputs difficult to verify comprehensively.

Metamorphic Testing (MT)\cite{chen2018metamorphic} has emerged as a promising approach for validating ADS, particularly in scenarios lacking a definitive test oracle. MT evaluates system behavior by examining invariant relationships between outputs when inputs undergo controlled transformations. However, conventional MT approaches often rely on elementary transformations and limited metamorphic relationships \cite{segura2016survey}. This simplicity can lead to systems that adapt to specific test patterns rather than developing genuine robustness, potentially resulting in models that perform adequately under test conditions but fail to generalize to real-world scenarios \cite{10.1145/3597503.3639191}.



To address these limitations, we propose integrating advanced generative models, specifically Stable Diffusion \cite{rombach2021highresolution}, to enhance MT capabilities in ADS testing. These generative models excel at producing sophisticated, controlled variations in input data while maintaining environmental coherence \cite{10419041}. By incorporating them into the MT framework, we can generate nuanced scenario modifications—such as variations in lighting conditions, weather patterns, and lane configurations—to rigorously evaluate ADS decision-making processes. As illustrated in Figure 1, the Stable Diffusion-XL model is employed to preserve the lane direction in the original photograph while subtly modifying the background on both sides of the lane. This approach aims to generate variations suitable for application as metamorphic testing cases.

Our approach improves test reproducibility by generating consistent yet diverse scenarios and establishing reusable test oracles based on ADS behavioral invariants. Using generative transformations on camera inputs, we evaluate key ADS components like path planning and obstacle detection. By overcoming traditional MT limitations and leveraging modern generative models, our framework provides a more robust method for validating autonomous system safety.

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.48\textwidth]{transformedimages.pdf} 
    \caption{The case of using Stable Diffusion-XL to slightly change the background of a real image}
\end{figure}

% \section{Background}
% Testing and validating Autonomous Driving Systems (ADS) require innovative approaches to address their inherent complexity and the unpredictability of real-world environments. Traditional software testing methodologies struggle to provide the rigor needed for ADS, particularly due to challenges like the oracle problem and the difficulty of creating diverse yet controlled test scenarios. As a result, research has focused on two promising directions: Metamorphic Testing (MT), which leverages invariant properties for validation, and large generative models, which excel in producing realistic and flexible input variations. This section explores the advantages, limitations, and synergistic potential of these two methodologies in enhancing ADS testing.

% \subsection{Metamorphic Testing}\label{AA}
% Metamorphic Testing (MT) is a property-based testing approach designed to validate systems where defining explicit oracles—precise expected outcomes—is challenging or infeasible. MT addresses the oracle problem by leveraging metamorphic relations (MRs): properties or relationships that should hold true across multiple test cases, even under certain input transformations. By focusing on these invariant properties, MT enables the systematic evaluation of software systems without requiring absolute correctness criteria for every individual test case.

% Advantages of Metamorphic Testing


% \begin{itemize}
% \item Oracle Problem Mitigation: MT is especially effective in domains like ADS, where real-world outcomes are difficult to define precisely, making traditional testing approaches inadequate.
% \item Efficiency in Test Case Generation: MT automates the generation of additional test cases by applying defined transformations to existing inputs, significantly reducing the need for manual test creation.
% \item Revealing Hidden Defects: MT can expose flaws in complex systems by evaluating their consistency under varied but semantically valid transformations.
% \item Applicability to Black-Box Models: Since MRs rely on output behavior rather than internal logic, MT is well-suited for testing black-box systems, such as deep learning models used in ADS.
% \end{itemize}

% Despite its strengths, traditional MT often falls short in highly complex systems like ADS:

% \begin{itemize}
% \item Simplistic Transformations: Many traditional MRs involve straightforward input changes, such as scaling or rotation, which may not sufficiently challenge the system under test.
% \item Overfitting Risk: Models may learn to produce correct outputs for specific transformations without genuinely improving their generalization to unanticipated scenarios.
% \item Limited Scope: Traditional MT focuses primarily on small-scale transformations that fail to reflect the nuanced environmental variations encountered by ADS in real-world conditions.
% \end{itemize}

% These limitations underscore the need for integrating MT with more advanced tools, such as generative models, to create meaningful and controlled transformations that better represent real-world variability.

% \subsection{ Large Generative Models}
% Large generative models, such as Stable Diffusion, represent a significant leap in machine learning capabilities, particularly in the domain of image generation and manipulation. These models are trained on extensive datasets and can generate highly realistic images or transform existing images while maintaining essential contextual properties. Their flexibility and robustness make them ideal for simulating diverse scenarios in ADS testing.
% Advantages of Large Generative Models
% \begin{itemize}
% \item High-Quality Image Manipulation: Models like Stable Diffusion can create nuanced variations in lighting, weather, and environmental features while preserving semantic coherence. This capability aligns with the need for controlled but realistic transformations in ADS testing.
% \item Flexibility and Control: These models allow precise parameter tuning, enabling testers to generate specific variations, such as subtle lane shifts or slight changes in obstacle positions, to evaluate ADS performance under diverse conditions.
% \item Scalability: Generative models can produce a virtually unlimited number of transformations, supporting large-scale testing efforts without significant manual intervention.
% \item Realism in Variations: The outputs of generative models closely mimic real-world conditions, providing a more realistic testing environment compared to traditional MT transformations.
% \end{itemize}
% Features Beneficial for ADS Testing
% \begin{itemize}
% \item Reproducibility: Generative models ensure that variations can be recreated consistently, which is critical for systematic testing and debugging.
% \item Diverse Transformations: These models can simulate a wide range of environmental factors, including rare scenarios that are difficult to capture in physical testing.
% \item Adaptability to Complex Scenarios: Generative models can combine multiple environmental factors (e.g., low light and rain) to test the robustness of ADS under compound conditions.
% \item Integration with MT: When combined with MT, generative models enhance the scope of metamorphic relationships, enabling more meaningful validation of ADS decision-making processes.
% \end{itemize}

% By integrating the strengths of Metamorphic Testing and large generative models, this approach addresses the limitations of traditional testing methods. Metamorphic Testing provides a structured framework for evaluating ADS, while generative models like Stable Diffusion offer the flexibility and realism required to simulate complex, real-world scenarios. Together, these tools create a powerful synergy that enhances the rigor and reliability of ADS testing.

\section{Background}

The validation of Autonomous Driving Systems (ADS) requires careful consideration of both testing methodologies and operational constraints. This section examines three interconnected concepts: Operational Design Domain (ODD) \cite{ISO34503:2023}, Metamorphic Testing (MT), and generative models \cite{oussidi2018deep}.

\subsection{Operational Design Domain}
ODD specifies conditions for ADS functionality, defined as a tuple: $P$ (infrastructure), $E$ (environment), $O$ (constraints), $T$ (temporal), and $C$ (connectivity).

\begin{equation}
    \text{ODD} = (P, E, O, T, C)
\end{equation}



Each component can be further decomposed into specific parameters. For example, the $E$(environment) can be broken down into the following parameters:

\begin{equation}
    \begin{split}
        E = \{&e_w \text{ (weather)}, e_l \text{ (lighting)}, \\
        &e_v \text{ (visibility)}, e_t \text{ (temperature)}\}
    \end{split}
\end{equation}

\subsection{Metamorphic Testing with ODD}
Metamorphic Testing within an ODD framework requires that relations maintain validity within specified operational bounds. For an ADS $S$, input domain $I$, and output domain $O$, we define ODD-constrained metamorphic relations:

\begin{equation}
    \begin{split}
        \text{MR}_{\text{ODD}} \subseteq \{&(x, S(x), x', S(x')) \mid \\
        &x, x' \in I_{\text{ODD}}, \\
        &R(x, S(x), x', S(x')) = \text{true}\}
    \end{split}
\end{equation}

where $I_{\text{ODD}}$ represents inputs valid within the ODD constraints:

\begin{equation}
    I_{\text{ODD}} = \{x \in I \mid \forall c \in \text{ODD}: V(x,c) = \text{true}\}
\end{equation}

Here, $V(x,c)$ verifies compliance with ODD constraint $c$.

\subsection{Generative Models with ODD Integration}
We extend the generative model framework to incorporate ODD constraints. For a generative model $G$ and manually defined transformation specification $\tau$ :

\begin{equation}
    G(x, \tau, \text{ODD}) \rightarrow x' \text{ where } x, x' \in I_{\text{ODD}}
\end{equation}

The transformation specification $\tau$ is now ODD-aware:

\begin{equation}
    \tau_{\text{ODD}} = \{\varepsilon \in E, \gamma \in P, \sigma \in O \times T \times C\}
\end{equation}


This enables the definition of ODD-compliant metamorphic relations:

\begin{equation}
    \begin{split}
        \text{MR}_{G,\text{ODD}} = \{&(x, S(x), G(x,\tau_{\text{ODD}}), \\
        &S(G(x,\tau_{\text{ODD}}))) \mid \\
        &R(x, S(x), G(x,\tau_{\text{ODD}}), \\
        &S(G(x,\tau_{\text{ODD}}))) = \text{true} \wedge \\
        &x, G(x,\tau_{\text{ODD}}) \in I_{\text{ODD}}\}
    \end{split}
\end{equation}

This formulation ensures: 1) Generated scenarios remain within ODD boundaries, 2) transformations preserve ODD-critical properties,  3) test cases maintain operational validity, and
4) validation results are meaningful within the intended operational context.

Integrating ODD with MT and generative models aims to ensure relevant ADS testing within intended conditions while maintaining mathematical validation rigor.






% \section{Proposed Approach}
% To rigorously test and validate the perception systems of Autonomous Driving Systems (ADS), this paper proposes a novel approach that integrates Metamorphic Testing (MT) with large generative models. This approach addresses key challenges such as the oracle problem, model uncertainty, and the need for diverse but controlled test scenarios. By leveraging MT principles and the capabilities of generative models like Stable Diffusion, the proposed method systematically evaluates the robustness and reliability of ADS perception systems under varying environmental conditions.

% \begin{figure}[h!]
%     \centering
%     \includegraphics[width=0.5\textwidth]{Frame.png} 
%     \caption{Architecture of metamorphic testing for ADS}
% \end{figure}

% \subsection{Framework Overview}
% The method proposed in this paper is shown in Figure 1. The proposed approach involves two main components:
% \begin{enumerate}
%     \item Transformation of camera input images using generative models guided by Metamorphic Relations (MRs).
%     \item Re-execution of the ADS model with transformed inputs to analyze decision-making consistency and calculate uncertainty scores.
% \end{enumerate}



% \subsection{Defining and Implementing Metamorphic Relations}
% Metamorphic Relations are the cornerstone of the proposed approach, providing a formal mechanism to validate ADS behavior. Each MR defines specific transformations to input images and the expected relationships between the corresponding outputs. The key MRs implemented in this approach include:



% \begin{itemize}
% \item 
% \textbf{MR1-Environmental Variations Without Lane Impact:}

% Slight changes to the environment, such as adding minor objects or altering background elements, while keeping the lane configuration unchanged. Figure 1 demonstrates the result of using Stable Diffusion-XL to slightly change the background of a real image.\\
% Relation: The pathfinding results should remain identical, as these changes do not affect the driving lane.

% \begin{figure}[h!]
%     \centering
%     \includegraphics[width=0.5\textwidth]{mr1} 
%     \caption{The case of using Stable Diffusion-XL to slightly change the background of a real image}
% \end{figure}

% \item 
% \textbf{MR2-Weather Variations Transformation:}
% Weather Variations Transformation: Adjusting weather conditions, such as introducing rain, snow, or low-light scenarios.\\
% \textbf{Relation:} Pathfinding results should remain consistent, as weather changes do not directly alter lane configurations.

% \item
% \textbf{MR3-Lane ReversalTransformation:}
% Reversing the direction of the lane.\\
% \textbf{Relation:} Pathfinding results should change correspondingly, guiding the vehicle in the opposite direction.

% \item 
% \textbf{MR4-Obstacle Introduction Transformation:}
% Placing obstacles such as pedestrians, vehicles, or debris in the driving lane.\\
% \textbf{Relation:} The ADS should generate pathfinding results that avoid or stop for obstacles.

% \item 
% \textbf{MR5-Lane Rescaling Transformation:}
% Increasing or decreasing the number and width of lanes.\\
% \textbf{Relation:}Pathfinding results should adapt to the new lane configuration while maintaining consistency in navigation.
% \end{itemize}
% %\begin{equation}
% %a+b=\gamma\label{eq}
% %\end{equation}



% \subsection{Input Transformation Using Generative Models}
% Large generative models, such as Stable Diffusion, are employed to generate realistic input transformations based on the defined MRs. These models are capable of:
% \begin{itemize}
% \item Simulating diverse environmental and weather variations.
% \item Adding or modifying objects in the scene while maintaining semantic coherence.
% \item Adjusting lane configurations with high precision.
% \end{itemize}

% The transformed images serve as the follow-up inputs for the ADS model, ensuring that the variations are both realistic and controlled.


% \subsection{Re-execution and Comparison}
% The ADS model is re-executed with the transformed inputs. For each MR, the outputs are compared to evaluate whether the defined relationships hold true. This step involves:
% \begin{itemize}
% \item Calculating uncertainty scores to quantify the model’s confidence in its decisions.
% \item Using a time-based smoothing mechanism to avoid false alarms caused by single-frame anomalies (e.g., sudden data fluctuations).
% \end{itemize}



% \subsection{Analysis and Validation}
% The results of the re-execution are analyzed to determine the robustness of the ADS model under various conditions. Metrics such as the frequency of MR violations, the magnitude of uncertainty, and the smoothness of time-based scores are used to assess model reliability.

\section{Proposed Approach}

ADSs demand thorough validation within their ODD. We propose a novel framework that integrates MT with generative AI to systematically validate ADS perception systems, addressing three key challenges: 1) Oracle problem \cite{barr2014oracle} in ADS testing, 2) environmental complexity and scenario diversity, 3) uncertainty in perception systems.
\subsection{Framework Overview}



\begin{figure}[h!]
    \centering
    \includegraphics[width=0.48\textwidth]{frameworkup.png} 
    \caption{Architecture of metamorphic testing for ADS and its three key components: (1) ODD-Aware Scenario Generation, (2) Integrated Validation, (3) Time Series Analysis.}
    \label{fig:arch}
\end{figure}




Our framework operates through a systematic workflow (Fig. 2) with two core components:
\begin{itemize}
    \item \textbf{ODD-Aware Generation}: Creates controlled variations in test scenarios while maintaining ODD compliance.
    \item \textbf{Metamorphic Validation}: Evaluates ADS behavior consistency under these variations.
\end{itemize}

Formally, let $S$ represent an ADS under test as follows where $I$ denotes the input space (camera images), $O$ represents the output space (driving decisions), and $h, w$ and $c$ stand for image height, width, and channels, respectively:

\begin{equation}
    S: I \rightarrow O, \text{ where } I \subset \mathbb{R}^{h \times w \times c}
\end{equation}



The framework components are defined as:

\begin{equation}
    \begin{split}
        G_{\text{ODD}}&: I \times \tau \rightarrow I \\
        V_{\text{MR}}&: (I \times O) \times (I \times O) \rightarrow \{0,1\}
    \end{split}
\end{equation}

where $G_{\text{ODD}}$ generates ODD-compliant transformations and $V_{\text{MR}}$ validates metamorphic relations.

\subsection{ODD-Aware Scenario Generation}

\subsubsection{Transformation Space}
For a source image $x \in I$, we define ODD-compliant transformations with the following components:
     Environmental conditions  such as weather and lighting ($\varepsilon$),
    geometric transformations such as perspective and scale ($\gamma$), and
  semantic modifications such as objects, road features ($\sigma$).

\begin{equation}
    \begin{split}
        \tau_{\text{ODD}} = \{&\varepsilon \in E, \gamma \in P, \sigma \in O\} \\
        \text{subject to: } &\forall c \in \text{ODD}: V(G(x,\tau),c) = \text{true}
    \end{split}
\end{equation}



\subsubsection{Generation Process}
involves generation of transformed images that adhere to ODD specifications, utilizing a visual generation model to produce metamorphic testing samples. This is detailed in Algorithm 1, and also illustrated as an integral component (1) of the metamorphic testing architecture for ADS in Fig. \ref{fig:arch}.
\begin{algorithm}[h]
\caption{ODD-Aware Scenario Generation}
\SetAlgoLined
\KwIn{Source image $x$, ODD specifications}
\KwOut{Transformed image $x'$}
Define $\tau$ based on ODD constraints\;
Verify transformation validity: $V(x,\tau) = \text{true}$\;
Generate candidate: $x' \leftarrow G_{\text{ODD}}(x,\tau)$\;
\eIf{ValidateODDCompliance($x'$)}{
    \Return{$x'$}\;
}{
    \Return{GenerateNewTransform($x$)}\;
}
\end{algorithm}

\subsection{Metamorphic Relations and Validation}

\subsubsection{Uncertainty-Aware Relations}
We enhance traditional MRs with uncertainty quantification as follows where $u(\cdot)$ denotes uncertainty quantification, $\theta_u$ represents the uncertainty threshold, and $R(\cdot,\cdot)$ stands for the relation validator:

\begin{equation}
    \begin{split}
        \text{MR}_u(x,x') = \{&(S(x), S(x'), u(S(x)), u(S(x'))) \mid \\
        &R(S(x), S(x')) = \text{true} \wedge \\
        &u(S(x')) \leq \theta_u\}
    \end{split}
\end{equation}


\subsubsection{Validation Criteria}
For each MR category validation criteria are formulated as follows with the following three key components: 
    Path extraction ($P(\cdot)$), Object detection ($D(\cdot)$), and tolerance thresholds ($\epsilon_p, \epsilon_d$).

MR1 and MR2 require that the error threshold is not exceeded, as the generator utilizes similar images for testing. In contrast, MR3 employs an inverse validation relationship, as the generator completely reverses the direction of the lane.


\begin{equation}
    \begin{split}
        V_{\text{MR1}}(x,x') &= \|P(S(x)) - P(S(x'))\| \leq \epsilon_p \\
        V_{\text{MR2}}(x,x') &= \|D(S(x)) - D(S(x'))\| \leq \epsilon_d \\
        V_{\text{MR3}}(x,x') &= P(S(x)) \approx -P(S(x'))
    \end{split}
\end{equation}


\subsection{Temporal Validation}

The third key component of the metamorphic testing framework in Fig. \ref{fig:arch} is time series analysis which aims to ensure robust validation across time sequences as formulated below where   $w$, $\epsilon_t$, and $S_t(\cdot)$ denote time window size, temporal threshold and smoothed prediction, respectively.

\begin{equation}
    \begin{split}
        S_t(x) &= \frac{1}{w}\sum_{i=t-w}^t S(x_i) \\
        V_{\text{temporal}}(x,x') &= \|S_t(x) - S_t(x')\| \leq \epsilon_t
    \end{split}
\end{equation}

\subsection{Integrated Validation Framework}
Integrated validation assesses whether outputs satisfy safety expectations by applying metamorphic relationships, as defined mathematically and outlined in Algorithm 2. This framework serves as the second core component of the metamorphic testing architecture for ADS, illustrated in Fig. \ref{fig:arch}.

\begin{algorithm}[h]
\caption{Integrated Validation Framework}
\SetAlgoLined
\KwIn{Image sequence $X$, ADS $S$, ODD specifications}
\KwOut{Validation report $R$}
Initialize empty report $R$\;
\ForEach{$x_t \in X$}{
    Generate ODD-compliant $\tau_t$\;
    $x'_t \leftarrow G_{\text{ODD}}(x_t, \tau_t)$\;
    $s_t \leftarrow S(x_t)$\;
    $s'_t \leftarrow S(x'_t)$\;
    $u_t \leftarrow$ ComputeUncertainty($s_t$)\;
    $u'_t \leftarrow$ ComputeUncertainty($s'_t$)\;
    $v_{\text{mr}} \leftarrow$ ValidateRelations($s_t, s'_t$)\;
    $v_{\text{temp}} \leftarrow$ TemporalValidation($s_{t-w:t}, s'_{t-w:t}$)\;
    UpdateReport($R, v_{\text{mr}}, v_{\text{temp}}, u_t ,u'_t $)\;
}
\Return{$R$}\;
\end{algorithm}

\subsection{Framework Properties}

The presented framework ensures four essential properties:

\begin{itemize}
    \item \textbf{ODD Compliance:} All transformations respect operational bounds
    \item \textbf{Uncertainty Awareness:} Validation considers prediction confidence
    \item \textbf{Temporal Coherence:} Results remain stable across time
    \item \textbf{Comprehensive Coverage:} Multiple MRs ensure thorough testing
\end{itemize}

This systematic framework enables rigorous validation of ADS perception systems while maintaining practical relevance within specified operational bounds.





% \section{Conclusion}
% Ensuring the safety and reliability of Autonomous Driving Systems (ADS) is critical, as failures in these systems can lead to catastrophic outcomes, undermining public trust and jeopardizing the future of autonomous transportation. In this position paper, we propose a novel approach that integrates Metamorphic Testing (MT) with large generative models to enhance the testing and validation of ADS perception systems. By leveraging generative models such as Stable Diffusion to create realistic and diverse input transformations, our approach addresses key challenges such as the oracle problem, model uncertainty, and reproducibility.
% This method has the potential to redefine the validation of ADS by systematically testing their behavior across a wide range of realistic scenarios, including rare and edge cases. By focusing on reusable metamorphic relations and robust evaluation metrics, our approach aims to support the development of safer and more reliable autonomous systems. Ultimately, the proposed framework contributes to advancing the dynamic safety assurance of ADS, paving the way for innovative testing methodologies and more resilient machine learning-enabled systems in real-world environments.


\section{Discussions and Ongoing Research}

\subsection{Extension to Multiple Sensor Modalities}
The proposed framework naturally extends to other sensor types:

\begin{itemize}
    \item \textbf{LiDAR Integration:} The metamorphic relations can be adapted for point cloud data as follows     where $p, p'$ represent point clouds and $R_{\text{3D}}$ defines spatial relationships:
    \begin{equation}
        \begin{split}
            \text{MR}_{\text{LiDAR}}(p,p') = \{&(S(p), S(p'), u(S(p)), u(S(p'))) \mid \\
            &R_{\text{3D}}(S(p), S(p')) = \text{true}\}
        \end{split}
    \end{equation}

    
    \item \textbf{Radar Systems:} Similar principles apply to radar data where where $D_{\text{velocity}}$ extracts velocity measurements:
    \begin{equation}
        V_{\text{radar}}(r,r') = \|D_{\text{velocity}}(S(r)) - D_{\text{velocity}}(S(r'))\| \leq \epsilon_v
    \end{equation}
    
\end{itemize}


\subsection{Reusability Across ADS Platforms}
Our framework’s modular architecture aims to promote reusability in ADS implementations, enabling shared libraries of metamorphic relations and transformations, thus reducing validation overhead across multiple levels:

\begin{itemize}
    \item \textbf{Test Scenarios:} Once generated, transformations can be reused across different ADS versions and configurations
    \item \textbf{Validation Logic:} Metamorphic relations can be encapsulated as reusable components within testing frameworks or pipelines.
    \item \textbf{ODD Specifications:} Formal ODD definitions can be shared across multiple validation campaigns
\end{itemize}

\subsection{Scalability Benefits}

The framework demonstrates remarkable scalability across three critical dimensions:\\
\textbf{Horizontal Scalability:} The system scales seamlessly across autonomous systems, including passenger vehicles, commercial trucks, delivery robots, and industrial AGVs, covering autonomy levels from L2 to L4.

\textbf{Vertical Scalability:} The framework efficiently handles increasing complexity on three fronts:
 1) Single to multi-sensor setups, 2) Simple to complex scenarios, 3) Component to system validation.

\textbf{Operational Scalability:} Testing scales across 1) Development to production, 2) Single to distributed testing, 3) Manual to automated validation.

\subsection{Sensor Fusion Architectures}

The framework's inherent scalability makes it particularly effective for complex sensor fusion architectures \cite{elmenreich2002introduction}, supporting both early and late fusion while ensuring consistent validation. Its modular design enables seamless scaling from single-sensor to multi-sensor systems without requiring major modifications.


\section{Concluding Remarks}
This position paper has introduced a method to transform ADS validation by systematically testing behaviors across diverse scenarios, including rare edge cases. Using reusable metamorphic relations and robust metrics, it aims to enhance safety assurance and fosters innovative testing for more resilient machine learning systems in real-world environments. Our immediate step involves first expanding the diversity of scenarios, including dynamic and adversarial edge cases, and further validating the robustness of the proposed method. 


\section*{Acknowledgement}
This work is supported in part by MITACS Accelerate Program under project IT40981 and in part by the NSERC CREATE TRAVERSAL program.
\bibliographystyle{ieeetr}
%\bibliography{references}
\begin{thebibliography}{10}

\bibitem{zhao2023autonomous}
J.~Zhao, W.~Zhao, B.~Deng, Z.~Wang, F.~Zhang, W.~Zheng, W.~Cao, J.~Nan, Y.~Lian, and A.~F. Burke, ``Autonomous driving system: A comprehensive survey,'' {\em Expert Systems with Applications}, p.~122836, 2023.

\bibitem{9284628}
K.~Muhammad, A.~Ullah, J.~Lloret, J.~D. Ser, and V.~H.~C. de~Albuquerque, ``Deep learning for safe autonomous driving: Current challenges and future directions,'' {\em IEEE Transactions on Intelligent Transportation Systems}, vol.~22, no.~7, pp.~4316--4336, 2021.

\bibitem{chen2018metamorphic}
T.~Y. Chen, F.-C. Kuo, H.~Liu, P.-L. Poon, D.~Towey, T.~Tse, and Z.~Q. Zhou, ``Metamorphic testing: A review of challenges and opportunities,'' {\em ACM Computing Surveys (CSUR)}, vol.~51, no.~1, pp.~1--27, 2018.

\bibitem{segura2016survey}
S.~Segura, G.~Fraser, A.~B. Sanchez, and A.~Ruiz-Cort{\'e}s, ``A survey on metamorphic testing,'' {\em IEEE Transactions on software engineering}, vol.~42, no.~9, pp.~805--824, 2016.

\bibitem{10.1145/3597503.3639191}
X.~Gao, Z.~Wang, Y.~Feng, L.~Ma, Z.~Chen, and B.~Xu, ``Multitest: Physical-aware object insertion for testing multi-sensor fusion perception systems,'' in {\em Proceedings of the IEEE/ACM 46th International Conference on Software Engineering}, ICSE '24, (New York, NY, USA), Association for Computing Machinery, 2024.

\bibitem{rombach2021highresolution}
R.~Rombach, A.~Blattmann, D.~Lorenz, P.~Esser, and B.~Ommer, ``High-resolution image synthesis with latent diffusion models,'' 2021.

\bibitem{10419041}
H.~Cao, C.~Tan, Z.~Gao, Y.~Xu, G.~Chen, P.-A. Heng, and S.~Z. Li, ``A survey on generative diffusion models,'' {\em IEEE Transactions on Knowledge and Data Engineering}, vol.~36, no.~7, pp.~2814--2830, 2024.

\bibitem{ISO34503:2023}
``Road vehicles — test scenarios for automated driving systems — specification for operational design domain,'' 2023.

\bibitem{oussidi2018deep}
A.~Oussidi and A.~Elhassouny, ``Deep generative models: Survey,'' in {\em International conference on intelligent sytems and computer vision (ICSV)}, pp.~1--8, IEEE, 2018.

\bibitem{barr2014oracle}
E.~T. Barr, M.~Harman, P.~McMinn, M.~Shahbaz, and S.~Yoo, ``The oracle problem in software testing: A survey,'' {\em IEEE transactions on software engineering}, vol.~41, no.~5, pp.~507--525, 2014.

\bibitem{elmenreich2002introduction}
W.~Elmenreich, ``An introduction to sensor fusion,'' {\em Vienna University of Technology, Austria}, vol.~502, pp.~1--28, 2002.

\end{thebibliography}

\vspace{12pt}


\end{document}
