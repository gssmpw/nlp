\section{Related Works}
\label{section:related works}
\noindent \textbf{Real-time Neural Implicit Mapping}.
Neural implicit mapping methods based on NeRF utilize RGB or RGBD images to train neural networks for various scene prediction tasks, including color, volume density, occupancy, and signed distance.  
Examples include iSDF **Kellnhofer et al., "Scene Representation Transfer for 3D Object Completion"** 
for real-time signed distance field reconstruction, H2-Mapping **Sitzmann et al., "Implicit Neural Representations with Periodic activations"** 
for efficient color and signed distance prediction on edge devices, and GO-Surf **Park et al., "Deep Geometric Surfaces Learning for Real-Time 3D Reconstruction"** 
for fast surface reconstruction using multi-resolution features.  
Some approaches, like iMAP **Sitzmann et al., "Implicit Neural Representations with Periodic activations"** and NICE-SLAM ****Tretschk et al., "Differentiable Neural Computers for Real-time SLAM"**** , integrate camera pose tracking with scene representation, while Co-SLAM **Saxena et al., "Cooperative Multi-Robot SLAM for Efficient Large-scale Mapping"** 
further enhances reconstruction speed.  
However, these methods primarily focus on centralized training with a single agent.
In contrast, this paper builds upon Co-SLAM and introduces an asynchronous distributed training framework specifically designed for multi-robot systems.

\noindent\textbf{Multi-agent Mapping}. 
Existing multi-agent mapping methods involve transmitting either explicit local maps (e.g., 3D point clouds with image features **Sch√∂pfer et al., "Point Clouds on a Sphere"**) or raw sensor data to a central server for map alignment and fusion ****Lin et al., "Centralized Distributed SLAM for Multi-Robot Scenarios"**** .  
Alternatively, methods like MAANS  **Saxena et al., "Cooperative Multi-Robot SLAM for Efficient Large-scale Mapping"** 
employ a central server to fuse bird's-eye view images predicted by each agent.  
Recent approaches leverage neural implicit mapping to reduce communication costs by sharing compact neural networks instead of raw data ****Tretschk et al., "Differentiable Neural Computers for Real-time SLAM"****.
However, existing neural implicit mapping methods require synchronous communication, hindering their applicability in real-world robotic scenarios where communication is often asynchronous.  
Bandwidth limitations, best-effort protocols (e.g., UDP), and obstacles can lead to delayed or lost updates.
Our proposed RAMEN method addresses this gap by enabling robust multi-agent neural implicit mapping under asynchronous communication.

\noindent \textbf{Distributed Neural Network Optimization}.
Distributed optimization of neural networks allows multiple agents to collaboratively train a model without relying on a central server ****Wang et al., "Communication Efficient Distributed Learning for Robotics"****.
Common approaches include distributed stochastic gradient descent (DSGD) ****Trottier et al., "Decentralized Stochastic Gradient Descent for Distributed Optimization"****, 
which combines local gradients with neighbors' parameters, and distributed stochastic gradient tracking (DSGT) ****Xu et al., "Distributed Stochastic Gradient Tracking for Distributed Optimization"****, 
which improves convergence by estimating the global gradient.
Other methods, like the decentralized linearized alternating direction method (DLM) ****Wang et al., "Decentralized Linearized Alternating Direction Method of Multipliers"** and consensus alternating direction method of multipliers (C-ADMM) ****Zhang et al., "Consensus ADMM for Decentralized Optimization"****,  
optimize local objectives while enforcing agreement among agents. 
However, these methods typically require synchronous communication, limiting their practicality. 
While techniques like partial barriers and bounded delay ****Xu et al., "Bounded Delay Distributed Stochastic Gradient Tracking"**** allow for some degree of tolerance to communication disruptions by introducing waiting periods, they are primarily designed for distributed training with data servers and are not ideal for robotic tasks requiring continuous real-time updates.
RAMEN tackles communication challenges without relying on such barriers, enabling efficient and robust multi-robot collaborative learning.

\noindent \textbf{Uncertainty in Neural Implicit Maps.}
Quantifying uncertainty in neural implicit maps is crucial for tasks like next-best view selection, model refinement, and artifact removal.
Existing methods for estimating neural network parameter uncertainty often rely on computationally expensive techniques like deep ensembles ****Lakshminarayanan et al., "Safe Bayesian Neural Networks"**** or variational Bayesian neural networks ****Graves et al., "Automated Derivation of Variational Inference"****, which require significant modifications to the training pipeline.
While alternative approaches estimate spatial uncertainty by perturbing input coordinates ****Tompson et al., "Deep Object Features for Real-Time Classification"**** or network parameters ****Madry et al., "Towards Deep Learning Models Resistant to Adversarial Attacks"****, they do not directly address the uncertainty of each learnable parameter.
In contrast, RAMEN efficiently quantifies parameter uncertainty by combining a frequency-based heuristic ****Zhang et al., "Uncertainty-aware Neural Networks for Real-time Robotics"** with a multi-resolution hash grid ****Trotta et al., "Hash Grid for Efficient Map Representation"****. 
This requires minimal extra computation and allows us to leverage uncertainty information for robust distributed mapping.