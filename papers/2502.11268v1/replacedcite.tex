\section{Related Work}
\textbf{Statistical watermarks.} ____ refined the statistical watermarking framework initially introduced by ____, showcasing the efficacy of this technique via comprehensive experiments on large language models. They divided the language model tokens into red and green lists and favored the green list tokens by adjusting their logits with a fixed increment $\delta$. ____ introduced a unigram watermark approach that employs single-gram hashing to generate watermark keys, enhancing the robustness of statistical watermarks. ____ further increased the robustness of statistical watermarking by using the semantics of generated texts as watermark keys. Additionally, ____ developed a scheme for unforgeable watermarks that utilizes neural networks to alter token distributions, moving away from conventional watermark keys. Nevertheless, such methods can substantially alter the text distribution, potentially diminishing the quality of the content.

\noindent\textbf{Unbiased watermarks.} To maintain the original output distribution in watermarked content, several researchers have investigated novel approaches for token distribution modification. ____ pioneered an unbiased watermarking method using Gumbel-max to adjust token distribution and employing prefix n-grams as watermark keys. ____ used inverse sampling for modifying the token distributions of watermarked content on a binary language model with watermark keys based on token positioning. ITS-edit and EXP-edit ____ utilized inverse-sampling and Gumbel-max respectively for modifying the token distributions of watermarked content, with a predetermined watermark key list. ____ combined inverse-sampling and $\gamma$-reweight strategies for watermarking, though their detection method is not model-agnostic. DiPmark ____ enhanced the $\gamma$-reweight technique and introduced a model-agnostic detector. STA-1 ____ optimized the quality of the watermarked text under the low-entropy scenarios.