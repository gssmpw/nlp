\section{Introduction}
\label{sec:intro}
\acresetall

\Acfp{LLM} have driven significant advancements across various industries and domains~\cite{bharathi2024analysis}, including natural language processing~\cite{kaplan2020scaling}, healthcare~\cite{haltaufderheide2024ethics} and decision support systems~\cite{eigner2024determinants}.
Despite their widespread adoption, it remains difficult to ensure the reliability of their outputs~\cite{shi2025know}.
One major concern is their tendency to \emph{hallucinate}, generating false or misleading responses with high confidence, which diminishes their usability in critical applications~\cite{ji2023towards}.
Additionally, their responses can vary \emph{inconsistently} across queries, particularly in specialized or intricate domains, often requiring the verification of responses by domain experts~\cite{lee2024one}.

A well-known method for enhancing the reliability of \ac{LLM} responses is to use \ac{RAG}~\cite{lewis2020retrieval}.
\ac{RAG} integrates \ac{LLM} text generation with external information retrieval, enabling models to ground their responses in credible sources.
This approach first retrieves relevant documents from an external database and then incorporates them into the \ac{LLM} prompt before response generation.
By leveraging external knowledge sources, \ac{RAG} allows \acp{LLM} to provide more accurate and contextually relevant answers without requiring model parameter updates through compute-expensive retraining or fine-tuning~\cite{csakar2025maximizing}.



\ac{RAG} workflows typically query embeddings from a single monolithic vector database~\cite{kukreja2024performance}.
However, in many industries, it is natural for information to be scattered across multiple repositories~\cite{bhavnani2009information}.
Medical professionals, for example, need to retrieve patient records, clinical guidelines, and recent research findings from multiple information systems~\cite{jiang2024clinical}.
Similarly, legal professionals must consult multiple independent sources to build a case or provide legal advice.
This calls for \emph{federated RAG search}, which is essentially a mechanism that can query multiple data sources and aggregate relevant information~\cite{shokouhi2011federated}.
Such a mechanism has multiple advantages over using a single database.
Firstly, it sidesteps the need to move data to a central database, which might be complicated due to regulatory constraints~\cite{kairouz2021advances}.
Secondly, it allows for seamless extension of existing databases, without requiring data migration or duplication across sites, since data is represented by high-dimensional vectors, or \emph{embeddings}.
Thirdly, it ensures that organizations can reuse their existing infrastructure while enabling users to query multiple sources efficiently, reducing storage overhead and maintaining data consistency.


The effectiveness of federated \ac{RAG} search depends on a resource selection mechanism that decides which data stores are most likely to contain relevant documents~\cite{wang2024feb4rag}.
Without such a mechanism, a \ac{RAG} system would query all available data sources indiscriminately, leading to several  problems:
\begin{enumerate*}[label=\emph{(\roman*)}]
\item obtaining information from irrelevant sources might increase the chances for \acp{LLM} to hallucinate and reduce the quality of the generated responses~\cite{wang2024feb4rag}; and 
\item the overhead, in terms of communication volume and computational cost of retrieving embeddings from every possible source can be significant.
\end{enumerate*}
This overhead becomes particularly problematic in large-scale deployments, where response times and cost-effectiveness are critical.









This work introduces \sys, a new routing mechanism that enables federated \ac{RAG} search by dynamically selecting relevant sources at query time.
\sys is powered by a lightweight neural network classifier.
\sys first trains a neural network classifier on the characteristics of available data sources, which is then used to route subsequent queries efficiently.
This approach significantly reduces the number of accessed nodes, thereby lowering resource consumption while maintaining high retrieval quality.
Thus, \sys proactively learns a routing policy tailored to the structure of the data sources and the nature of queries.

We evaluate the effectiveness and efficiency of \sys using two standard benchmarks: \mirage and \mmlu.
\sys achieves high retrieval recall and shows excellent performance in determining whether data sources are relevant for a given query.
Notably, \sys reduces the total number of queries up to 77.5\% and communication volume up to 76.2\%.

Our contributions are as follows:

\begin{enumerate}
    \item We introduce \sys, a novel and efficient approach for federated \ac{RAG} search (\Cref{sec:design}).
    At the core of \sys lies a lightweight neural network classifier that determines the relevance of each data source and routes subsequent queries accordingly.
    This sidesteps the need for a given user query to contact all, possibly irrelevant data sources.
    \item We implement \sys and conduct an experimental evaluation (\Cref{sec:evaluation}).
    Our evaluation with two standard benchmarks demonstrates that \sys is both effective and efficient, underscoring the potential of our approach for federated \ac{RAG} search.
\end{enumerate}



