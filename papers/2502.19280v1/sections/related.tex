\section{Related work}
\label{sec:related}

\textbf{\ac{RAG} with multiple data sources.}
Expanding the \ac{RAG} workflow to support multiple data sources is an emerging area of research.
\textsc{FeB4RAG} examines federated search within the RAG paradigm and focuses on optimizing resource selection and result merging to enhance retrieval efficiency~\cite{wang2024feb4rag}.
The underlying idea consists of introducing a dataset for federated search and incorporating \ac{LLM}-based relevance judgments to benchmark resource selection strategies.
Notably, the paper emphasizes the importance of developing novel federated search strategies to enhance \ac{RAG} effectiveness.
Salve et al. propose a multi-agent \ac{RAG} system where different agents handle the querying of databases with differing data formats (\eg, relational or NoSQL)~\cite{salve2024collaborative}.

Other approaches focus on privacy when querying data sources across organizations.
\textsc{Raffle} is a framework that integrates \ac{RAG} into the federated learning pipeline and leverages public datasets during training while using private data only at inference time~\cite{muhamedcache}.
\textsc{C-FedRag} is a federated \ac{RAG} approach that enables queries across multiple data sources and leverages hardware-based \acp{TEE} to ensure data confidentiality~\cite{addison2024c}.
\textsc{FRAG} leverages homomorphic encryption to enable parties to collaboratively perform \ac{ANN} searches on encrypted query vectors and data stored in distributed vector databases, ensuring that no party can access others' data or queries~\cite{zhao2024frag}.
These schemes can benefit from \sys while ensuring privacy-preserving federated search.







\textbf{\ac{ML}-assisted resource selection.}
\ac{ML} models have been explored to support resource selection in federated search~\cite{garba2023federated}.
Wang et al. propose a \ac{LLM} fine-tuning method that predicts the relevance of previously logged queries and snippets from resources~\cite{wang2024resllm}.
Arguello et al. leverage different features, \eg, the topic of queries, and train a classifier for resource selection~\cite{arguello2009classification}.
Learn-to-rank approaches such as \textsc{SVMrank}~\cite{dai2017learning} and the LambdaMART-based \textsc{LTRRS}~\cite{wu2019ltrrs} refine relevance rankings by leveraging diverse feature sets.
However, these models typically are more computationally expensive than the lightweight router used in \sys.


