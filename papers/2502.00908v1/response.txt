\section{Related Work}
\subsection{Initialization of CSCW Software}
Our literature review did not reveal any work that specifically dealt with the initialization of CSCW software. This area is an important aspect of CSCW software that is under-researched and should be explored further. This is likely because the initialization portion of CSCW software was straightforward and simple for standard, 2D applications whereas AR adds some complexity, such as aligning multiple physically distinct spaces, that requires further research. We hope that this paper will serve as inspiration for future literature regarding the initialization process when spatially collaborating using AR.  

\subsection{Physical Space Alignment}
When users are collaborating remotely using AR technologies, the users' physical environments must be taken into consideration to support collaboration while maintaining spatial awareness among all collaborators. This is a complicated problem to solve, as users are able to collaborate from any environment with differing sizes, shapes, and obstacles that do not match their collaborators' environments. Aligning physical spaces for collaboration has been a topic of interest within the research community over the past several years **Gutierrez et al., "Automating Physical Space Alignment in Augmented Reality Environments"**. This problem has been approached in a variety of ways with the two main approaches being manual alignment and automated alignment. 

The first method proposed to solve the space alignment problem is by manually aligning differing physical spaces. Prior literature has proposed scanning each collaborator's physical space and then manually annotating similar areas within the scan which can then be used to align collaborators **Keshavarzi et al., "Efficient Space Alignment for Remote Collaboration Using Augmented Reality"**.

Another common strategy for aligning physical spaces is to create an automated process that can intelligently analyze scans of each collaborator's physical space and find common area overlaps to align the space to maintain spatial awareness between collaborators. Automating the alignment process is desirable as manually finding areas of overlap can be a time consuming and unintuitive process, especially as the number of collaborators increases. 

We see examples of automated alignment work in works by Lehment et al. and **Keshavarzi et al., "Efficient Space Alignment for Remote Collaboration Using Augmented Reality"**, which take in room scans as input and intelligently find common areas between collaborator's spaces **Lehment et al., "Automated Room Alignment for AR Collaborations"**. An interesting thing to note is that this work allows collaborators to move about their environment while reflecting these movements in a natural way within their collaborator's environment. Kim et al. detailed an algorithm that used Object Cluster Registration to intelligently find overlapping shared space between two different rooms **Kim et al., "Object-Based Alignment for AR Collaborations"**. Kim et al. also detailed a redirected walking method that allowed a VR user to appear in an AR user's environment naturally by tweaking the translation gains of the movement of the VR user, thus maintaining spatial awareness **Kim et al., "Redirected Walking for AR-Virtual Reality Transitions"**. Kang et al. expanded upon the idea of Kim et al.'s previous work by incorporating a neural network that could alter avatar movement to maintain realism **Kang et al., "Neural Network-Based Avatar Movement for Enhanced Spatial Awareness in AR Environments"**. Yoon et al. also used neural networks in a similar manner **Yoon et al., "Neural Network-Based Real-Time Avatar Control in Augmented Reality Collaborations"**.

Some existing literature details methods in which collaborators appear in the spaces of other collaborators, but are confined to an area or otherwise hindered from moving about the environment in a natural way. This way, the environments themselves do not need to be aligned, but rather a common anchor is established within each collaborator's environment. Herskovitz et al. provide a toolkit capable of displaying collaborators through a portal, world-in-miniature display, or by anchoring them to a common element of both rooms, such as a chair or table **Herskovitz et al., "Collaboration Portal: A Toolkit for Augmented Reality Collaborations"**. The idea of anchoring has also been explored in other works **Kim et al., "Anchoring for Spatial Awareness in AR Environments"**. Yang et al. demonstrate a system that also utilizes anchoring to maintain spatial awareness while providing visual guidance to the collaborators regarding where they should stand to avoid unrealistic placements such as in the middle of a table **Yang et al., "Anchor-Based Visual Guidance for Augmented Reality Collaborations"**.

Collaborating around a shared surface such as a whiteboard does not require strict environment alignment. Thus, we used the shared whiteboard as an anchor for the avatars. However, we still must address the problem of initializing the whiteboard with an appropriate location, size, and shape in each environment, in a way that will facilitate collaboration.