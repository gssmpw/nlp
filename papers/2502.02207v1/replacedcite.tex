\section{Related Work}
\label{sec:related_work}

In an \gls{ADS}, seamless integration of decision-making and trajectory planning layers is essential.
These two components serve distinct yet interconnected roles.
The decision-making layer determines the strategic behavior of the system, selecting maneuvers such as lane changes or speed adjustments based on the current situation.
In contrast, the trajectory planning layer realizes these decisions by generating specific trajectories that satisfy both the behavioral goals and the physical constraints of the system.
If no reasonable trajectory can be found by the \gls{ADS} in a disengagement scenario, a human \gls{RO} can support on planning level which will also be introduced in this chapter.
%

\subsection{Decision-Making}
\label{sec:decision_making}

Historically, \textbf{\glsentrylongpl{FSM}} have been a popular choice for decision-making due to their simplicity and ease of implementation____.
However, their scalability is limited as the complexity of the system increases, leading to a massive growth in states and transitions.

In contrast, \textbf{\glsentrylongpl{BT}} provide a scalable and transparent structure for behavior generation____.
They allow for modular design and facilitate the addition of new behaviors without extensive reconfiguration.
Despite these advantages, \glsentrylong{BT} lack inherent safety guarantees as their safety and robustness is heavily dependent on the arrangement of the nodes.
Additionally, the return type of a behavior node is a simple binary or ternary value, which limits the flexibility of the system.

\textbf{Arbitration graphs} are a hierarchical and modular decision-making framework designed for autonomous systems originally developed for robot soccer____.
They have since been successfully applied to autonomous driving____.
By combining simple atomic behavior components, they generate complex behavior in a bottom-up approach.
This enables incremental integration of behavior components without modifying existing ones.
\cref{fig:arbitration-graph-active-teleoperation} shows a visualization of an arbitration graph.

Behavior components are the leaf nodes of the arbitration graph and compute a command given the current situation.
Their \glsentrylong{IC} specifies whether a behavior component is applicable in the current situation provided by sensor data or an interpreted environment model.
An activated behavior component can signalize that its execution can be continued using the \glsentrylong{CC}.
The internal nodes, called arbitrators, decide between applicable options depending on the arbitrator's decision policy.
Arbitrators can be nested, allowing for a hierarchical decision-making structure.
The icon in front of the arbitrator's name in \cref{fig:arbitration-graph-active-teleoperation} indicates the decision policy: \arbitrator{Automated Driving} is a priority arbitrator whereas \arbitrator{Urban Driving} makes a decision based on the cost of its options.
Arbitrators and behavior components share a generic interface which supports the integration of complex behavior commands such as trajectories.

As a meta-framework, arbitration graphs offer great flexibility by allowing the integration of diverse underlying planning algorithms into a single decision-making structure.
The modular structure of arbitration graphs allows for great maintainability and extensibility while ensuring a high level of transparency and interpretability.
Safety can be reinforced through a tightly integrated verification step, which ensures that only valid and safe commands are executed____.
This combination of flexibility, safety, and robustness makes arbitration graphs ideal for complex and dynamic applications such as autonomous driving and robotics.

\begin{figure*}[hbp]
    \centering 
    \begin{subfigure}{0.33\textwidth}
        \includegraphics[width=\linewidth, trim={4.5cm 3.5cm 4.5cm 3.5cm}, clip]{figures/trajectory_guidance}
        \\[-0.3 cm]
        \caption{Trajectory Guidance}
        \label{fig:tg}
    \end{subfigure}%
    \hfill
    \begin{subfigure}{0.33\textwidth}
        \includegraphics[width=\linewidth, trim={4.5cm 3.5cm 4.5cm 3.5cm}, clip]{figures/waypoint_guidance}
        \\[-0.3 cm]
        \caption{Waypoint Guidance}
        \label{fig:wg}
    \end{subfigure}%
    \hfill
    \begin{subfigure}{0.33\textwidth}
        \includegraphics[width=\linewidth, trim={4.5cm 3.5cm 4.5cm 3.5cm}, clip]{figures/collaborative_planning}
        \\[-0.3 cm]
        \caption{Collaborative Planning}
        \label{fig:cp}
    \end{subfigure}
    %
    \caption{Overview of trajectory based teleoperation concepts. In trajectory guidance, the \gls{RO} defines all aspects (i.e. curvature and velocity) of the trajectory the \gls{ADS} shall execute. In waypoint guidance, the \gls{RO} inputs waypoints which a planner on the vehicle side takes as input to plan a modified trajectory. In collaborative planning, the \gls{RO} and \gls{ADS} negotiate a trajectory. Figures are taken from____}
    \label{fig:test}
\end{figure*}

\subsection{Trajectory Planning}

Arbitration graphs enable the integration of multiple trajectory planning algorithms into one \gls{ADS}.
Trajectory planning algorithms are diverse, ranging from rule-based approaches to learned methods.
We refer to \textcite{schwartingPlanningDecisionMakingAutonomous2018} for a detailed overview of trajectory planning methods.

For the \behavior{Teleoperation} behavior component presented in this paper, we use the \gls{MPCC} algorithm as introduced by~\textcite{paulsRealtimeCooperativeMotion2022} which is suitable due to its real-time capability and interpretable constraints.
We are using this algorithm since it is already used by other behavior components of the given system, significantly reducing additional implementation effort.
In the following, we provide a brief overview over the key concepts relevant to this paper.
Refer to the original publication for a more in-depth explanation.

\gls{MPCC} optimizes vehicle motion by maximizing progress along a reference path while minimizing lateral error.
The planning problem for the prediction horizon $N$ is formulated as

\begin{equation}
\min_{z_{1:N+1}} \sum_{k=1}^{N+1} J(\boldsymbol{z}_k),
\end{equation}

subject to system dynamics $\boldsymbol{x}_{k+1} = \mathbf{f}(\boldsymbol{x}_k,\boldsymbol{u}_k)$ for $k~\in~[1,~N]$
and inequality constraints $\boldsymbol{g}(\boldsymbol{z}_k) \leq 0$ for $k \in [1, N+1]$.
The initial state is set to $\boldsymbol{x}_1 = \boldsymbol{x}_\text{init}$.
The input and state variables of stage $k$, $\boldsymbol{u}_k$ and $\boldsymbol{x}_k$, and can be combined into a single vector of stage variables $\boldsymbol{z}_k = [\boldsymbol{x}_k; \boldsymbol{u}_k]$.

A key aspect of MPCC is the introduction of the progress variable $\theta_k$, which represents the arc length of the vehicle along the reference path.
It is part of the state vector $\boldsymbol{x}_k$, its derivative $\dot{\theta}_k$ is included in the control vector $\boldsymbol{u}_k$.

The inequality constraints include the \textbf{lateral constraints}

\begin{equation}
    \boldsymbol{g}_{\text{lat},k} = 
    \begin{bmatrix}
    g_{\text{lat},k}^\text{left} \\
    g_{\text{lat},k}^\text{right}
    \end{bmatrix}
    =
    \begin{bmatrix}
    - E_c^\text{left}(\theta_k) + R_c + \hat{E}_c(\boldsymbol{x}_k) \\
    E_c^\text{right}(\theta_k) + R_c - \hat{E}_c(\boldsymbol{x}_k)
    \end{bmatrix}
\end{equation}

which ensure that the vehicle remains within the drivable corridor.
The boundaries $E_c^\text{left}(\theta_k)$ and $E_c^\text{right}(\theta_k)$ define the feasible lateral region, cf.~\cref{fig:simulation}.
The lateral contouring error $\hat{E}_c(\boldsymbol{x}_k)$ approximates the deviation of the vehicleâ€™s center from the reference path.
The vehicle geometry is approximated using circular primitives with radius $R_c$.

Movement along the path can be limited by a \textbf{longitudinal constraint}

\begin{equation}
    g_{\text{lon},k} = \theta_k - \theta_\text{stop}
\end{equation}

which prevents the vehicle from exceeding a predefined progress limit $\theta_\text{stop}$, e.g., at a stop line.

\begin{figure}[!h]
    \centering
    \includegraphics[width=\columnwidth]{figures/coincar-sim}
    \caption{
        The simulation environment used to evaluate the presented concept.
        It shows the ego vehicle during a lane change.
        Grey lines represent the lane topology.
        The lateral constraints are visualized as a red ($E_c^\text{left}$) and a green ($E_c^\text{right}$) line.
        The blue line represents the longitudinal constraint $\theta_\text{stop}$.
        The resulting trajectory is shown in dark green.
    }
    \label{fig:simulation}
\end{figure}

\begin{figure*}[!b]
    \centering
    \includegraphics[width=1\linewidth]{figures/teleoperation_process_v3}
    \caption{Overview of interaction process between remote operator and automated driving system. The process starts with the \glsentrylong{IC} becoming True if a disengagement is present. The remote operator is requested and supports the automation by providing a set of modified boundary conditions to the planner that plans a modified trajectory the remote operator approves. After trajectory execution, the remote operator checks if the situation was resolved, ending the teleoperation process by manually setting the \glsentrylong{CC} to False.}   
    \label{fig:teleoperation_process}
\end{figure*}


\subsection{Teleoperation on Trajectory Level}
\label{sec:teleoperation-sota}
If no feasible solution to a specific scenario can be found by the \gls{ADS}, a \gls{RO} can support the system remotely.
\textcite{Maj2022bSurveyTeleoperationConcepts} proposed a classification of teleoperation concepts into different classes according to how the \gls{RO} interacts with the \gls{AV}.  
Three teleoperation concepts that assist the \gls{ADS} on trajectory level can be distinguished and are introduced in the following.

The first concept to remotely interact on trajectory level is \textbf{trajectory guidance} where the \gls{RO} defines all parameters of the trajectory, i.e. curvature and velocity, the vehicle shall follow, cf. \cref{fig:tg}.
This can be realized using a steering wheel and pedals____ or by inputting a set of waypoints with input devices such as mouse and keyboard____. 
In \textbf{waypoint guidance}, the \gls{RO} defines a set of waypoints that the planner of the \gls{ADS} takes as an input to plan a new trajectory that allows to solve the disengagement scenario, cf. \cref{fig:wg}____.
In \textbf{collaborative planning}, cf. \cref{fig:cp}, the \gls{RO} provides high-level input, such as modifying the drivable space____ or adjusting specific ODD parameters____. Based on this input, the vehicle's planner generates a new trajectory to resolve the disengagement.

Collaborative planning offers various advantages over trajectory guidance and waypoint guidance, including lower mental demand, reduced risk from erroneous human input and robustness against network instability____.
These advantages mainly stem from the \gls{RO} interacting directly with the planning module. 
%

%
%
%

%
%
%
%

However, the tight coupling of collaborative planning with the \gls{ADS} software modules increases system complexity and limits applicability across different \gls{ADS} architectures. 
To address this issue and facilitate easy implementation of teleoperation solutions into the \gls{ADS} software stack, we use arbitration graphs.
While collaborative planning is not the only approach suitable for integrating teleoperation into the arbitration graph framework, we adopt it due to its benefits outlined above. 
Additionally, this approach allows to utilize the existing planner, further simplifying integration while preserving the advantages of collaborative planning.
 %
%
%