\section{RELATED WORKS}
\label{related works}
This section establishes a systematic and comprehensive theoretical framework to support the development of the proposed self-supervised UVGL method. Although this work focuses on UVGL as a sub-task of cross-view geo-localization (CVGL), we first review the overall progress in supervised CVGL. We then discuss recent advances in self-supervised CVGL methods. Finally, we summarize main methodes in self-supervised ReID.
\subsection{Supervised Cross-View Geo-localization}
CVGL aims to achieve high-precision localization of query images by retrieving GPS-tagged satellite images. Early research in CVGL primarily focused on the ground-view CVGL ____, leading to the development of several benchmark datasets, such as CVUSA ____, CVACT ____, and VIGOR ____. To address the challenge of ground-view CVGL, researchers have proposed various methods. CVM-Net 
____ employed NetVLAD ____ to encode images as global descriptors, thereby reducing visual discrepancies caused by viewpoint variations. TransGeo ____ utilized attention-based zooming and sharpness-aware optimization to enhance detail learning and improve model generalization. GeoDTR ____ leveraged a Transformer-based ____ feature extractor to disentangle geometric features, effectively addressing perspective shifts. Sample4Geo ____ introduced a hard negative mining strategy, focusing on challenging negative samples to further improve discriminative capability.

With the continuous development and application of drone technology, UVGL has gradually become an important research direction and achieves significant progress ____. Several benchmark datasets for UVGL have been proposed, such as University-1652____, SUES-200, ____ and DenseUAV ____, which have driven further research in this field. In this scenario, a variety of methods have been proposed by researchers. LPN ____ mined fine-grained features through local pattern partitioning, improving the ability to capture local details. IFS ____ utilized a multi-branch strategy to effectively fuse global and local features, enhancing the diversity and robustness of feature representations. CAMP ____ improved cross-view matching accuracy by contrastive attribute mining and position-aware partitioning, while DAC ____ enhanced feature consistency and matching accuracy by introducing domain alignment and scene consistency constraints. MEAN ____ adopted progressive embedding diversification, global-to-local associations, and cross-domain enhanced alignment to further improve feature representation and alignment.

Nevertheless, the remarkable performances exhibited by these UVGL methods require extensive pre-processed UAV-satellite image pairs. In this work, we pivot our focus to the realm of self-supervised UVGL, where prior pairing relationships are absent, presenting important applications for real-world UVGL deployments.

\subsection{Self-Supervised Cross-View Geo-localization}
Due to the dependence of CVGL on extensive pre-processed image pairs, which significantly increases costs and limits applications for real-world, researchers have begun to explore self-supervised CVGL methods. The work in ____ proposed a self-supervised method that leveraged correspondence-free projection to transform ground panorama images into birdâ€™s-eye view images. It also applied CycleGAN ____ to generate fake satellite images, coupled with an additional SAFA module ____ to reduce discrepancies. However, this explicit alignment method has inherent limitations in capturing the deep semantic relationships of cross-view features and may introduce noise. Furthermore, the non-end-to-end training framework employed significantly increases training time and computational costs, reducing the efficiency and practical applicability. Additionally, existing work ____ utilized frozen foundation models (FMs) ____ to extract features, and a self-supervised adapter was introduced to mitigate visual discrepancies between different point of view. However, this method heavily relied on the ability of FMs for feature extraction. When FMs fail to effectively handle viewpoint discrepancies, the performance of the adapter is also affected. To reduce reliance on the feature extractor, CDIKTNet ____ trained with a small amount of paired UAV-satellite images to optimize the initial feature distribution, and then performed clustering to generate pseudo-labels, thereby improving the quality of pseudo-labels generation. However, this method inherently depends on the feature extractor, as it still requires limited paired UAV-satellite images for effective learning. 

The above methods have made meaningful exploratory attempts. However, these methods still face challenges, such as the additional computation time and overhead introduced by non-end-to-end frameworks, as well as dependence on the capability of feature extractor. In contrast, our method is fully end-to-end, eliminating the need for additional training processes and completely removing the reliance on feature extractor initialization.

\subsection{Self-Supervised Person Re-Identification}
ReID ____ aims at matching the same person image captured by non-overlapping cameras. Due to its critical role in video surveillance, ReID has attracted extensive research attention and achieved remarkable progress. However, these achievements are facilitated by extensive human-labeled data. To address this limitation, self-supervised learning methods ____ have been proposed. Among them, clustering algorithms are widely employed to generate pseudo-labels, which serve as supervision signals for model training. In addition, benefiting from the introduction of instance-level contrastive learning ____ with memory banks and momentum update strategies ____, many methods ____ consider each unlabeled sample as an individual class to learn discriminative instance-level feature representations. However, these instance-level features was modified largely during training, resulting in unstable representations ____. To address this issue, recent studies ____ have begun exploring cluster-level relationships to discover more stable and robust associations among pedestrian representations. Cluster Contrast ____ addresses the problem of cluster inconsistency by performing clustering and introducing a distinct representation for each cluster. Nevertheless, in cross-modal ReID scenarios, where images are captured by heterogeneous sensors, modality discrepancies hinder the effectiveness of these methods in learning modality-invariant features. ADCA____ introduced a dual-path contrastive framework to bridge modality gaps and enhance cross-modal feature alignment. Building on this, SDCL ____ employs a dual-path Transformer for shallow-to-deep contrastive learning, and refines pseudo-labels via consistency constraints across feature hierarchies, leading to more stable and discriminative cross-modal representations.

The above methods focus on alleviating the dependency on human-labeled data in the ReID and provide valuable insights for UVGL. However, UVGL suffers from more severe viewpoint and scale variations. Furthermore, the spatial continuity of geographic environments inevitably induces feature ambiguity, severely degrading clustering effectiveness. Thereby, we incorporate instance-level and cluster-level features into a self-supervised UVGL method to learn more discriminative and robust cross-view representations.
\begin{figure*}[t]
  \centering
  \includegraphics[width=7.2in]{3.pdf}
  \caption{The overall pipeline of our method consists of a lightweight backbone, a dual-path contrastive learning strategy, a dynamic hierarchical memory learning module, and an information consistency evolution module. Specifically, the dual-path contrastive learning is designed to learn discriminative and consistent intra-view feature representations. The dynamic hierarchical memory module further captures intra-view feature variations under different perspectives and scales, thereby enhancing the robustness and discriminability of the learned representations. The information consistency evolution module focuses on modeling cross-view feature consistency through a neighborhood-driven learning strategy, and further improves the training process by integrating a pseudo-label enhancement strategy.}
  \label{fig3}
  \end{figure*}