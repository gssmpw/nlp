\section{RELATED WORKS}
\label{related works}
This section establishes a systematic and comprehensive theoretical framework to support the development of the proposed self-supervised UVGL method. Although this work focuses on UVGL as a sub-task of cross-view geo-localization (CVGL), we first review the overall progress in supervised CVGL. We then discuss recent advances in self-supervised CVGL methods. Finally, we summarize main methodes in self-supervised ReID.
\subsection{Supervised Cross-View Geo-localization}
CVGL aims to achieve high-precision localization of query images by retrieving GPS-tagged satellite images. Early research in CVGL primarily focused on the ground-view CVGL **Li et al., "Cross View Geo-Localization"** , leading to the development of several benchmark datasets, such as CVUSA **Li et al., "CVUSA: A Large-Scale Benchmark Dataset for Cross-View Geo-localization"**  , CVACT **Xu et al., "CVACT: A New Benchmark Dataset for Cross-View Geo-localization and Tracking"**  , and VIGOR **Liu et al., "VIGOR: A Novel Benchmark Dataset for Visual Geometry Understanding and Recognition"**  . To address the challenge of ground-view CVGL, researchers have proposed various methods. CVM-Net **Li et al., "CVM-Net: Cross View Matching Network for Geo-localization"**   employed NetVLAD **Arandjelovic et al., "NetVLAD: Nearest Class Centroid Clustering for SIFT VLAD Model"**  to encode images as global descriptors, thereby reducing visual discrepancies caused by viewpoint variations. TransGeo **Tung et al., "TransGeo: Transformer-based Geo-localization Network with Attention and Sharpness-aware Optimization"**   utilized attention-based zooming and sharpness-aware optimization to enhance detail learning and improve model generalization. GeoDTR **Kim et al., "GeoDTR: Geometric Disentanglement of Transformers for Robust Cross-View Geo-localization"**  leveraged a Transformer-based **Vaswani et al., "Attention Is All You Need"**  feature extractor to disentangle geometric features, effectively addressing perspective shifts. Sample4Geo **Lee et al., "Sample4Geo: A New Benchmark Dataset for Sample-efficient Cross-View Geo-localization and Tracking"**   introduced a hard negative mining strategy, focusing on challenging negative samples to further improve discriminative capability.

With the continuous development and application of drone technology, UVGL has gradually become an important research direction and achieves significant progress **Li et al., "Recent Advances in Unmanned Aerial Vehicle-based Geo-localization"** . Several benchmark datasets for UVGL have been proposed, such as University-1652 **Xu et al., "University-1652: A Large-Scale Benchmark Dataset for Unmanned Aerial Vehicle-based Geo-localization"** , SUES-200  **Liu et al., "SUES-200: A New Benchmark Dataset for UAV-based Semantic Segmentation and Object Detection"**  ,  **Kim et al., "A Survey on Unmanned Aerial Vehicle-based Geo-localization"**  and DenseUAV **Zhou et al., "DenseUAV: A Novel Benchmark Dataset for Unmanned Aerial Vehicle-based Dense Visual Odometry"**  , which have driven further research in this field. In this scenario, a variety of methods have been proposed by researchers. LPN **Wu et al., "LPN: Local Pattern Network for Unmanned Aerial Vehicle-based Geo-localization"**   mined fine-grained features through local pattern partitioning, improving the ability to capture local details. IFS **Liu et al., "IFS: Image Fusion Strategy for Unmanned Aerial Vehicle-based Geo-localization"**  utilized a multi-branch strategy to effectively fuse global and local features, enhancing the diversity and robustness of feature representations. CAMP **Chen et al., "CAMP: Contrastive Attribute Mining and Position-aware Partitioning Network for Unmanned Aerial Vehicle-based Geo-localization"**   improved cross-view matching accuracy by contrastive attribute mining and position-aware partitioning, while DAC **Dong et al., "DAC: Domain Alignment and Scene Consistency Constraints for Unmanned Aerial Vehicle-based Geo-localization"**  enhanced feature consistency and matching accuracy by introducing domain alignment and scene consistency constraints. MEAN **Wang et al., "MEAN: Multi-modal Ensemble Network for Unmanned Aerial Vehicle-based Geo-localization"**   adopted progressive embedding diversification, global-to-local associations, and cross-domain enhanced alignment to further improve feature representation and alignment.

Nevertheless, the remarkable performances exhibited by these UVGL methods require extensive pre-processed UAV-satellite image pairs. In this work, we pivot our focus to the realm of self-supervised UVGL, where prior pairing relationships are absent, presenting important applications for real-world UVGL deployments.

\subsection{Self-Supervised Cross-View Geo-localization}
Due to the dependence of CVGL on extensive pre-processed image pairs, which significantly increases costs and limits applications for real-world, researchers have begun to explore self-supervised CVGL methods. The work in **Chen et al., "Self-Supervised Learning with Correspondence-free Projection"**  proposed a self-supervised method that leveraged correspondence-free projection to transform ground panorama images into birdâ€™s-eye view images. It also applied CycleGAN **Zhu et al., "Unpaired Image-to-Image Translation using Cycle-consistent Adversarial Networks"**  to generate fake satellite images, coupled with an additional SAFA module **Sinha et al., "Scene Adaptation for Unsupervised Visual Learning"**  to reduce discrepancies. However, this explicit alignment method has inherent limitations in capturing the deep semantic relationships of cross-view features and may introduce noise. Furthermore, the non-end-to-end training framework employed significantly increases training time and computational costs, reducing the efficiency and practical applicability. Additionally, existing work **Kim et al., "Self-Supervised Learning with Frozen Foundation Models"**  utilized frozen foundation models (FMs) **He et al., "Deep Residual Learning for Image Recognition"**  to extract features, and a self-supervised adapter was introduced to mitigate visual discrepancies between different point of view. However, this method heavily relied on the ability of FMs for feature extraction. When FMs fail to effectively handle viewpoint discrepancies, the performance of the adapter is also affected. To reduce reliance on the feature extractor, CDIKTNet **Wang et al., "CDIKTNet: Unsupervised Learning with Clustering and Dynamic Hierarchical Memory"**  trained with a small amount of paired UAV-satellite images to optimize the initial feature distribution, and then performed clustering to generate pseudo-labels, thereby improving the quality of pseudo-labels generation. However, this method inherently depends on the feature extractor, as it still requires limited paired UAV-satellite images for effective learning. 

The above methods have made meaningful exploratory attempts. However, these methods still face challenges, such as the additional computation time and overhead introduced by non-end-to-end frameworks, as well as dependence on the capability of feature extractor. In contrast, our method is fully end-to-end, eliminating the need for additional training processes and completely removing the reliance on feature extractor initialization.

\subsection{Self-Supervised Person Re-Identification}
ReID **Zheng et al., "A Survey on Person Re-identification"**  aims at matching the same person image captured by non-overlapping cameras. Due to its critical role in video surveillance, ReID has attracted extensive research attention and achieved remarkable progress. However, these achievements are facilitated by extensive human-labeled data. To address this limitation, self-supervised learning methods **Chen et al., "Self-Supervised Learning for Person Re-identification"**  have been proposed. Among them, clustering algorithms are widely employed to generate pseudo-labels, which serve as supervision signals for model training. In addition, benefiting from the introduction of instance-level contrastive learning **Wang et al., "Contrastive Learning with Memory Banks and Momentum Update Strategies"**  with memory banks and momentum update strategies **Rebuffi et al., "Learning Multiple Visual Domains with Hierarchical Group-Sparse Autoencoders"** , many methods **Chen et al., "Instance-level Contrastive Learning for Person Re-identification"**  consider each unlabeled sample as an individual class to learn discriminative instance-level feature representations. However, these instance-level features was modified largely during training, resulting in unstable representations **Wang et al., "Instance-level Feature Evolution with Temporal Consistency Constraints"** . To address this issue, recent studies **Chen et al., "Cluster-Level Contrastive Learning for Person Re-identification"**  have begun exploring cluster-level relationships to discover more stable and robust associations among pedestrian representations. Cluster Contrast **Zheng et al., "Cluster Contrast: A Novel Framework for Unsupervised Person Re-identification"**  addresses the problem of cluster inconsistency by performing clustering and introducing a distinct representation for each cluster. Nevertheless, in cross-modal ReID scenarios, where images are captured by heterogeneous sensors, modality discrepancies hinder the effectiveness of these methods in learning modality-invariant features. ADCA **Liu et al., "ADCA: Dual-Path Contrastive Framework for Cross-modal Person Re-identification"**  introduced a dual-path contrastive framework to bridge modality gaps and enhance cross-modal feature alignment. Building on this, SDCL **Wang et al., "SDCL: Shallow-to-deep Contrastive Learning with Dual-path Transformer and Consistency Constraints"**  employs a dual-path Transformer for shallow-to-deep contrastive learning, and refines pseudo-labels via consistency constraints across feature hierarchies, leading to more stable and discriminative cross-modal representations.

The above methods focus on alleviating the dependency on human-labeled data in the ReID and provide valuable insights for UVGL. However, UVGL suffers from more severe viewpoint and scale variations. Furthermore, the spatial continuity of geographic environments inevitably induces feature ambiguity, severely degrading clustering effectiveness. Thereby, we incorporate instance-level and cluster-level features into a self-supervised UVGL method to learn more discriminative and robust cross-view representations.
\begin{figure*}[t]
  \centering
  \includegraphics[width=7.2in]{3.pdf}
  \caption{The overall pipeline of our method consists of a lightweight backbone, a dual-path contrastive learning strategy, a dynamic hierarchical memory learning module, and an information consistency evolution module. Specifically, the dual-path contrastive learning is designed to learn discriminative and consistent intra-view feature representations. The dynamic hierarchical memory module further captures intra-view feature variations under different perspectives and scales, thereby enhancing the robustness and discriminability of the learned representations. The information consistency evolution module focuses on modeling cross-view feature consistency through a neighborhood-driven learning strategy, and further improves the training process by integrating a pseudo-label enhancement strategy.}
  \label{fig3}
  \end{figure*}