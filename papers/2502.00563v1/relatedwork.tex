\section{Related Work}
Semantic segmentation has seen tremendous advancements through deep learning architectures, with U-Net and its variants becoming a cornerstone of this field. The U-Net model, proposed by \cite{ronneberger2015u}, utilizes a symmetric encoder-decoder architecture with skip connections to preserve spatial details while capturing global context. Its success has inspired numerous adaptations in its convolutional blocks \cite{huang2019fixed,diakogiannis2020resunet} and skip connections \cite{zhou2018unet++,chen2021transunet}. Inspired by the transformer model, the attention mechanism has also been incorporated into the U-Net structure, which has shown significant performance enhancement, as in Attention U-Net \cite{islam2020brain}, TransUNet \cite{chen2021transunet}, etc. In this study, we compare our proposed CWMI loss using U-Net and Attention U-Net to test the generalization and superiority of CWMI, while the general idea is adaptable to other architectures as well. 

\subsection{Loss Functions for Semantic Segmentation}
While the architectural advancements in segmentation models have been significant, the performance of these networks is highly influenced by the design of the loss functions. Pixel-wise cross entropy loss (CE) minimizes the log likelihood of the prediction error but is significantly prone to class imbalance. To address this issue, class balanced cross entropy (BCE), proposed by \cite{long2015fully}, employs higher weights for classes with fewer pixels. Focal loss assigns higher weights to misclassified pixels with high probabilities \cite{ross2017focal}. Region-based losses, including Dice loss \cite{milletari2016v}, Tversky loss \cite{salehi2017tversky}, and Jaccard loss \cite{rahman2016optimizing}, inherently handle class imbalance but fail to address instance imbalance within the same class, such as thin boundaries and small objects.

To tackle instance imbalance, weighted loss functions have been proposed. In the original U-Net paper \cite{ronneberger2015u}, the weighted cross entropy (WCE) was introduced, employing a distance-based weight map to emphasize thin boundaries between objects. However, WCE assigns weights only to boundary pixels, neglecting object pixels. The adaptive boundary weighted (ABW) loss \cite{liu2022boundary} extends this approach by applying distance-based weights to both boundary and object pixels, while the Skea-Topo loss further improved the weight map based on boundary and object skeletons \cite{liu2024enhancing}. Despite their contributions, weighted losses suffer from two major limitations: (1) the weight maps are precomputed and fixed, failing to adapt to errors during training, and (2) they often generate thicker boundaries, which preserve topology but compromise metrics like Dice score and mIoU, as observed in our qualitative results.

Several methods address instance imbalance dynamically during training but at the cost of computational efficiency. Topology-based approaches, such as persistent homology methods \cite{stucki2023topologically,oner2023persistent}, describe image topologies and identify critical pixels but are computationally expensive, with cubic complexity to image size. The clDice loss \cite{shit2021cldice} employs a soft skeletonization algorithm to detect topological errors, primarily focusing on thin-boundary objects like retinal blood vessels. Similarly, Boundary Loss \cite{kervadec2019boundary} and Hausdorff Distance Loss \cite{karimi2019reducing} refine boundaries but incur significant computational overhead. Region Mutual Information (RMI) loss \cite{zhao2019region} captures pixel interdependencies over regions, but struggles with scalability for large-scale regional analysis due to the high computation cost. These losses either prioritize small regions at the expense of global accuracy or require extensive computational resources, necessitating more efficient and balanced approaches.


\begin{figure*}
    \centering
    \includegraphics[width=0.8\linewidth]{Figure_1.PNG}
    \vspace{-10pt}
    \caption{Illustration of the proposed Complex Wavelet Mutual Information (CWMI) Loss. The prediction and label images are decomposed using a complex steerable pyramid, which generates subbands at different scales and orientations. Mutual information is calculated for each corresponding pair of subbands, and the CWMI is computed as the sum of these mutual information values. \(\mathbf{Y}_{B_n},\mathbf{P}_{B_n}\): complex steerable decomposition of label and prediction image at level \(n\); \(I(\mathbf{Y}_{B_n}, \mathbf{Y}_{B_n})\): mutual information between \(\mathbf{Y}_{B_n}\) and \(\mathbf{P}_{B_n}\)}
    \label{fig:schematic}
\end{figure*}

\subsection{Wavelet-Based Loss Functions}

Wavelet-based metrics were first introduced as Complex Wavelet Structural Similarity (CW-SSIM) \cite{sampat2009complex}, known for their robustness to small translations and rotations. In the deep learning era, wavelet-based methods have been employed in loss functions, leveraging their ability to analyze multiscale and multiresolution features. These methods have shown promise in tasks like sketch-to-image translation \cite{kim2023whfl}, image super-resolution \cite{korkmaz2024training}, image dehazing \cite{yang2020net}, and material analysis \cite{prantl2022wavelet}. However, to the best of our knowledge, wavelet-based loss functions have yet to be explored in semantic segmentation.

Existing wavelet-based loss functions typically rely on $L_1$ \cite{zhu2021wavelet,korkmaz2024training,prantl2022wavelet} or $L_2$ distances \cite{kim2023whfl}, or structural similarity (SSIM) \cite{yang2020net} in the decomposed domain. While effective, these methods are less suited for handling high-dimensional data with complex directional features, as in wavelet transforms, and may be vulnerable to noise. The proposed CWMI loss leverages mutual information between wavelet-based subband images, effectively capturing multiscale dependencies. As demonstrated in later ablation tests, CWMI outperforms traditional metrics like $L_1$, $L_2$, and SSIM, offering superior segmentation performance and robustness.