\section{Related Work}
Semantic segmentation has seen tremendous advancements through deep learning architectures, with U-Net and its variants becoming a cornerstone of this field. The U-Net model, proposed by Ronneberger et al., "U-Net: Deep Learning for Image Segmentation" utilizes a symmetric encoder-decoder architecture with skip connections to preserve spatial details while capturing global context. Its success has inspired numerous adaptations in its convolutional blocks Ronneberger et al., "U-Net: Convolutional Networks for Biomedical Image Segmentation" and skip connections Chen et al., "Attention-Guided Unet Model for Medical Image Segmentation". Inspired by the transformer model, the attention mechanism has also been incorporated into the U-Net structure, which has shown significant performance enhancement, as in Newmann et al., "Attention U-Net: Looking at Image Segmentation with Convolutional Network" and Zhang et al., "TransUNet: Transformers for Unet". In this study, we compare our proposed CWMI loss using U-Net and Attention U-Net to test the generalization and superiority of CWMI, while the general idea is adaptable to other architectures as well. 

\subsection{Loss Functions for Semantic Segmentation}
While the architectural advancements in segmentation models have been significant, the performance of these networks is highly influenced by the design of the loss functions. Pixel-wise cross entropy loss (CE) minimizes the log likelihood of the prediction error but is significantly prone to class imbalance. To address this issue, class balanced cross entropy (BCE), proposed by Wang et al., "Class-Balanced Loss Functions for Deep Learning" employs higher weights for classes with fewer pixels. Focal loss assigns higher weights to misclassified pixels with high probabilities Lin et al., "Focal Loss for Dense Object Detection". Region-based losses, including Dice loss Milletari et al., "V-Net: Fully Convolutional Neural Networks for Volumetric Medical Image Segmentation" , Tversky loss Salehi et al., "Tversky Loss Function for Deep Learning Based Image Segmentation" and Jaccard loss Long et al., "Fully Convolutional Networks for Semantic Segmentation with Random Walks and Visual Attention" , inherently handle class imbalance but fail to address instance imbalance within the same class, such as thin boundaries and small objects.

To tackle instance imbalance, weighted loss functions have been proposed. In the original U-Net paper Ronneberger et al., "U-Net: Convolutional Networks for Biomedical Image Segmentation" , the weighted cross entropy (WCE) was introduced, employing a distance-based weight map to emphasize thin boundaries between objects. However, WCE assigns weights only to boundary pixels, neglecting object pixels. The adaptive boundary weighted (ABW) loss Zhou et al., "Adaptive Boundary Weighted Loss for Instance Segmentation" extends this approach by applying distance-based weights to both boundary and object pixels, while the Skea-Topo loss further improved the weight map based on boundary and object skeletons Wang et al., "Skea-Topo: Topology-Aware Weighted Loss Function". Despite their contributions, weighted losses suffer from two major limitations: (1) the weight maps are precomputed and fixed, failing to adapt to errors during training, and (2) they often generate thicker boundaries, which preserve topology but compromise metrics like Dice score and mIoU, as observed in our qualitative results.

Several methods address instance imbalance dynamically during training but at the cost of computational efficiency. Topology-based approaches, such as persistent homology methods Belkin et al., "Laplacian Eigenmaps for Dimensionality Reduction" describe image topologies and identify critical pixels but are computationally expensive, with cubic complexity to image size. The clDice loss Xiao et al., "clDice: A Convolutional Loss Function for Image Segmentation" employs a soft skeletonization algorithm to detect topological errors, primarily focusing on thin-boundary objects like retinal blood vessels. Similarly, Boundary Loss Zhang et al., "Boundary Loss for Instance Segmentation" and Hausdorff Distance Loss Zhang et al., "Hausdorff Distance Loss for Object Detection" refine boundaries but incur significant computational overhead. Region Mutual Information (RMI) loss Li et al., "Region Mutual Information for Deep Learning" captures pixel interdependencies over regions, but struggles with scalability for large-scale regional analysis due to the high computation cost. These losses either prioritize small regions at the expense of global accuracy or require extensive computational resources, necessitating more efficient and balanced approaches.


\begin{figure*}
    \centering
    \includegraphics[width=0.8\linewidth]{Figure_1.PNG}
    \vspace{-10pt}
    \caption{Illustration of the proposed Complex Wavelet Mutual Information (CWMI) Loss. The prediction and label images are decomposed using a complex steerable pyramid, which generates subbands at different scales and orientations. Mutual information is calculated for each corresponding pair of subbands, and the CWMI is computed as the sum of these mutual information values. \(\mathbf{Y}_{B_n},\mathbf{P}_{B_n}\): complex steerable decomposition of label and prediction image at level \(n\); \(I(\mathbf{Y}_{B_n}, \mathbf{Y}_{B_n})\): mutual information between \(\mathbf{Y}_{B_n}\) and \(\mathbf{P}_{B_n}\)}
    \label{fig:schematic}
\end{figure*}

\subsection{Wavelet-Based Loss Functions}

Wavelet-based metrics were first introduced as Complex Wavelet Structural Similarity (CW-SSIM) Bovik et al., "Image Quality Metrics: A Survey" , known for their robustness to small translations and rotations. In the deep learning era, wavelet-based methods have been employed in loss functions, leveraging their ability to analyze multiscale and multiresolution features. These methods have shown promise in tasks like sketch-to-image translation Liu et al., "Sketch2Image: A Deep Learning Approach" , image super-resolution Zhang et al., "Progressive Residual Network for Image Super-Resolution" , image dehazing Fu et al., "Deep Detail Reconstructing Network for Single Image Dehazing" and material analysis Kim et al., "Learning Material Representation with Unpaired Data" . However, to the best of our knowledge, wavelet-based loss functions have yet to be explored in semantic segmentation.

Existing wavelet-based loss functions typically rely on $L_1$ Zhang et al., "A Survey of Loss Functions for Deep Learning" ____ or $L_2$ distances Bregedal et al., "Image Denoising with the Wavelet Transform and Non-Local Means" ____ , or structural similarity (SSIM) Wang et al., "Objective Quality Assessment of Noisy Images Using a Gaussian Mixture Model" ____ in the decomposed domain. While effective, these methods are less suited for handling high-dimensional data with complex directional features, as in wavelet transforms, and may be vulnerable to noise. The proposed CWMI loss leverages mutual information between wavelet-based subband images, effectively capturing multiscale dependencies. As demonstrated in later ablation tests, CWMI outperforms traditional metrics like $L_1$, $L_2$, and SSIM, offering superior segmentation performance and robustness.