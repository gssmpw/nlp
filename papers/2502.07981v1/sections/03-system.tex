\section{System}
\begin{figure*}[h]
    \centering
    \includegraphics[width=.85\textwidth]{fig/SYSTEM_IMAGE_TEST_FLIPPED.png}
    \caption{HumorSkills System Diagram. Given an image, the system first extracts visual details with a visual language model, then performs visual humor ideation to analyze the image and propose humorous angles. It then generates ten potential conflicts that could be used to extrapolate the image into a relatable experience. The system then generates humor with and without the narratives, for diversity. A separate instance of the LLM trained to rank gen-Z humor ranks all the captions and returns the top five.}
    \Description{HumorSkills System Diagram}
    \label{fig:system}
\end{figure*}

HumorSkills is a system that takes an input image and outputs 5 image captions. 
The architecture has three key steps that mimic human skills needed for humor. \textit{Visual Detail Extraction}, is a step that describes the image in depth in order to make non-obvious observations about it. \textit{Narrative and Conflict Extrapolation} is a step that finds narratives not in the image that could be related to it, to expand the topic of jokes to things that are not just in the image but also analogous to it.  \textit{Fine-tuning} the joke generator with examples of good Gen-Z humor helps the jokes be more relatable to the target audience by using references, slang, topics, and insecurities that resonate with this group.

% first, 
% a \textbf{divergent stage} where the image is analysed and multiple observations, angle, alternative narratives and humorous angles are generated. 
% Second, a \textbf{generation stage} where two types of captions are generated: 1) captions focusing on image content directly 2) captions that bring in an outside narrative to the image, often bringing in outside references. It generates 15 captions of each type. (Figure 1 has examples Of the Content Focused, and Narrative Expanded Captions). Finally, a \textbf{ranking stage} where a separate AI agent selects the top 5 captions

The system generates two types of captions: image-focused captions which common directly on the content in the image, and narrative-driven captions. Variety is important to humor. Humor relies on surprise, and jokes that are too similar start to become more predictable. Additionally, with an infinite set of input images with different subjects and situations, there are more strategies needed to find a humorous angle that fits the content. 

% With caption-based humor, often the humor can be focused on finding something in the image that is inherently interesting. 

% For example, the caption ”little man really thought he could escape bedtime” relies solely on information in the image. However, some images don’t have something funny in and of themselves, and it’s easier to make a joke by bringing in a new unrelated angle. For example, ``the police chasing me when I'm broke and in debt to the tune of \$100,000 for student loans''. Generally, Images with people doing interesting things lend themselves to visual humor because there are many stories one could tell about it. However, for images with only static objects, it's more difficult to tell a story on only the objects, so bringing a new story in is another way to find humor. 

\subsection{AI Humor Generation Walk Through}
Figure \ref{fig:system} contains a visual diagram and example of intermediate outputs when generating captions for an image. We describe each phase and implementation in detail.  
% The main contribution of this paper is the evaluation, rather than the system, but it is still it is important to understand the mechanism used to generate humor.
% Although the individual components of the system are not totally, the combination of features including the

\subsubsection{Visual Detail Extraction}

The first phase of the system’s workflow involves the Visual Detail Extraction component, which utilizes GPT-4o’s vision capabilities to analyze the input image. This system incorporates a prompt that asks for a detailed paragraph that explains the who/what/where of the image, distinguishing between identifying the subject of the image, the main action of the image if it exists, and the background elements of the image. This component is responsible for extracting key visual elements such as objects, human expressions, background settings, and any notable aspects that could serve as the foundation for humor.

For instance, in the demolition site example from the system diagram, the system identifies a large industrial demolition excavator and a person with a hose spraying the demolition site. 

\subsubsection{Visual Humor Ideation}

On top of the visual detail extraction, the system ideates on possible humorous elements from the visual of the image. This incorporates an additional prompt using GPT-4o that intakes the image and asks it to identify and ideate on potential humorous visual elements in the image, whether they are directly humorous elements, such as funny facial expressions, or more analogous elements. For example, for the system diagram image, the system noted the visual contrast of the excavator and person, reminiscent of a David versus Goliath scenario, which provides a foundational metaphor for generating humorous captions. 

\begin{figure*}[b]
    \centering
    \includegraphics[width=.95\textwidth]{fig/Workflow.png}
    \caption{A diagram for how narrative extrapolation works}
    % \Description{}
    \label{fig:systemLines}
\end{figure*}

\subsubsection{Narrative and Conflict Extrapolation}

In this next step, the system generates a narrative and conflict framework by drawing upon common and relatable Gen Z experiences such as work, school, family, social interactions, relationships, and more. 
The system chains together the results of the previous steps, into a new prompt sent to GPT-4o. 
% The system prompts GPT-4o to 
% GPT-4o is utilized by incorporating the text description of the image and potential humorous elements of the image, then being prompted to generate relatable scenarios applicable to the image description from a list of common Gen Z experiences. 
The prompt contains the visual details, the visual humor ideation, and a list of common Gen Z experiences,  and the instruction to "generate narratives that reflect the essence of the image that is set within the framework of the Gen Z experience."
This narrative generation adds depth to the humorous captions by applying relatable themes and conflicts to the visual elements identified earlier.

For instance, our system diagram generates narratives such as “Tackling student loans”, "Group Project Disaster", and “Relationship Issues” based on the image, both of which are common experiences among those who identify as Gen Z. These particular narratives are likely inspired by the imagery of a disaster site, referring to how the effort of paying off student loans, attempting to complete group projects during school, or addressing relationship -- all of which can feel like disaster clean up. These relatable conflicts can transform the visual of a demolition scene -- a setting that is not particularly relatable -- into a relatable scenario that has the potential for humor, thereby expanding the humorous possibilities by connecting the visual input with broader life experiences.



\subsubsection{Humorous Caption Generation}

Following the narrative and conflict extrapolation, the system generates humorous captions in the generation stage using a fine-tuned version of GPT-3.5 trained on humorous Instagram comments. This involves producing captions through two distinct strategies: one focused on the visual humor of the image, and the other by bringing in the previously generated external narratives. Caption generation is segmented into two separate prompts utilizing the fine-tuned GPT-3.5 model. For captions without generated external narratives, the prompt asks to generate 15 humorous captions in the style of Gen Z that bases the generation off the visual extraction and visual humor ideation of the input image. For captions with the external narratives, the prompt also asks to generate 15 humorous captions in the style of Gen Z that bases the generation off the visual extraction and visual humor ideation of the input image, but also asks the system to incorporate the list of generated narrative/conflict extrapolations to base the humorous captions off of.

Image-focused captions rely solely on the visual details in the image, such as “bro out here getting paid \textdollar8 an hour to spray some water on some bricks,” which references the direct visual elements in the scene in order to generate a caption. This particular caption directly references the humor of the image, poking fun at the minimal impact of the person spraying water on bricks while an excavator clearly has more impact on the demolition site. Narrative-driven captions, on the other hand, introduce external references to add humor. For instance, a caption like “The entitled bro you tried to make the group presentation with” introduces an outside, exaggerated, interpretation of the scene from earlier, "Group Project Disaster." This caption takes the group project narrative and pairs it with the visual of the image, analogizing the person spraying the hose with minimal impact on the demolition site to an entitled person who has not done much to complete the group project. 

This variety between visual humor and narrative-driven humor is crucial because jokes that are too similar become predictable, losing their element of surprise. Additionally, humor strategies need to adapt to the varying content in input images. Some images lend themselves to humor based on their inherent visual details, while others require bringing in outside references to create a joke. For instance, an image of static objects might not be inherently funny, such as the demolition image shown in the system diagram, but a caption introducing an unrelated, exaggerated narrative, such as “Eboy doin' his part to stop climate change” can inject humor and absurdity by making an unexpected connection.

\subsubsection{Caption Ranking using Gen Z Agent}

The final component of the system architecture is the Caption Ranking and Filtering Agent, a GPT-4o-based agent fine-tuned to evaluate humor from a Gen Z perspective. This agent receives the list of 30 total captions from the narrative and visual humor-based caption generations and ranks the captions generated in the previous stage based on humor, relatability, and alignment with the image and narrative.

As illustrated in our system diagram, this agent ranks captions such as “Me mopping up my last relationship” and “me pulling the emotional weight of the friend group” based on their relevance to Gen Z humor. Captions that fail to meet the humor threshold are filtered out, such as "Demolition worker really said 1v1 me bro," because although the phrase like "1v1 me bro" invokes Gen Z phrases, the content of the caption seems less relevant and relatable than a caption talking about school or relationships, ensuring that only the most effective and relatable captions are presented to the user.

\subsubsection{Fine-tuning}

To fine-tune a GPT-3.5 model, a dataset of 80 humorous comments were extracted from popular Instagram images. From three popular Instagram meme pages with over 400,000 followers, the top five comments of each image post were collected. All fit the style of Gen-Z humor. 
% The fine-tuning process ensured that the generated captions align with the humor style favored by Gen Z. 
Examples of the visual description of the images in addition to an explanation of potential humorous elements of the image were written in the fine-tuning prompts, then followed by the actual comment itself. This reflected the visual extraction and humor ideation being incorporated into the prompt of our current system.


