

\section{Discussion}
\subsection{Giving Human-like Skills to AI} 
This study showed that for one form of humor - Gen-Z style Instagram image captioning humor - our AI-written humor was funnier than GPT's native humorsense, and as funny at the top 5 highest rated Instagram captions. We attribute this to a variety of features we added to the system. First, the visual detail extraction was able to find aspects of the image to poke fun at that were often sharper than GPT's joke target and more similar to the Instagram captions' joke target. Second, the narrative extrapolation step allowed the system to broaden its base of relatable joke targets - moving the focus away from making fun of the literal objects in the image, but using them as metaphors for relatable joke targets like relationship disasters, teamwork breakdowns, and the burden of student loans. This opened more creativity possibilities for joke targets. Lastly, we used an LLM-as-judge to rank the outputs accord to Gen-Z humor taste, thus giving the system some notion of the audience. These skills - detail observation, finding analogous and relatable social situations, and modeling the audience through fine tuning - are all considered somewhat ``human.'' Skills like reasoning and chaining are considered more typical of machines. But this shows that machines might be able to approach these more human skills with the right architecture and training.  


% In this paper, we showed that a model of GPT that is enhanced to have 3 human-like skills used in humor 
% \color{red}
% (observation, sense of story, and in-group knowledge) 
% \color{black}
% outperforms standard GPT-4o. Many other researchers have devised prompting techniques and architectures for improving LLM's reasoning capabilities such as reflection, chain-of-thought, and prompt chaining. However, fewer papers have explored how social skills can enhance LLMs communication abilities. Systems like Generative Agents ~\cite{joon_agents}
% and Character.AI \cite{characterAI} do this to great success. In this paper, we gave VLMs a few simple ``skills'' that were relevant to humor generation and showed that overall, it improved AI's ability to write humor. The focus of this paper was the human evaluation to see whether AI could get closer to parity with most upvoted human captions. However, if even a simple system like this can improve humor, perhaps more sophisticated systems could do better. 

There are many ways to improve the skills in HumorSkills. Building and testing a better Gen Z humor ranking would probably improve the filtering of bad captions. More fine-tuning could improve the breadth of Gen Z slang and references. More narratives and conflicts would expand its vocabulary of relatable situations. Finding ways to automatically collect narratives and conflicts to be applied would accelerate this process. Adding new skills would also be future research. Theories of humor abound. With recent advances in LLM's ability to do long chains of logical reasoning in DeepSeek and GPT-4o, it would be interesting to have AI try to analyze the humor and extract it's own theories or techniques for humor.

One of biggest shortcomings of the captions is that some of them are not logical enough to make sense, but are also not illogical enough to be absurd. These sound like mistakes. As future work, one could test whether an AI-based reflection step could think through the logic of a joke and decide whether it actually made sense or not. 
% The current rating system seems to let some of these by. 

% Other papers have tried fine-tuning b

Further testing or ablation studies could help shed light on which skills are most helpful. However, humor ratings have high variance among raters, and the data required to get statistical significance is often quite high. There may not be an effect of each skill individually - they might only work together. 



\subsection{Implications of Machine with Human-like Social Skills}
Human-like social skills - like humor - are often used for human bonding. If AI can write humor as well as the best people, the AI has the potential to both disingenuously create human bonding ~\cite{diresta2024spammersscammersleverageaigenerated,naaman_opinion} and to augment human's ability to bond~\cite{socialglue}. Either way, this has the potential to change the nature of human trust and communication.
In many ways, this is already happening in other domains. 
ChatGPT and Gmail SmartCompose~\cite{smartcompose} can already rewrite emails to sound more polite and we really are.
AI sales and scams can trick people into giving money to what they think are friend or loved ones in need~\cite{ai_scams}. 
AI has successfully been integrated into Gen Z dating apps that suggest messages to send to potential dates based on both a dating profile (for the opening line) or message history (for continued conversation)~\cite{majic2024rizz}. Many apps attempt this, but the quality of the suggested text sets them apart - the apps that generate more human-like texts have millions of active paying users~\cite{majic2024rizz}.
To some, this potential for disingenuousness is horrifying. Although disingenuous portrayals of oneself for dating purposes far precede the invention of generative AI, there is a possibility that AI will amplify this ability. 


As AI for social, cultural, and personally relevant communication improves, we may need a way to discern genuine from disingenuous communication. There are high-tech ways of doing this, such as making a video of oneself (until AI can do that). There are also low-tech ways of doing this, like talking in person. It would be highly ironic if the advancement of AI drives people to abandon technology, because it could not be trusted to be genuine. 

% For people who adopt these products, a common reason is that the bar for texting banter is so high for Gen Z, that help is appreciated, even when the sentiment is genuine. 

% Even at work, polite communication is socially demanded, and with ever-increasing amounts of communication, the emotional labor of even typing simple pleasantries is tiring. Early generative AI applications like Gmail Smart Compose~\cite{smartcompose} were noted for lowering the burden of writing a polite introductory line in emails. Although these lines are perfunctory and don't necessarily need to be genuine, it makes a difference to readers whether they are there or not. Social effort matters.



% \textit{Although hopefully AI will not force civilization back into a barter economy that necessatiate personal interaction to establish trust.} (LYDIA: TOO MUCH?)


% emotional labor. 

% Also with AI friends like Persona aI?



\section{Limitations}
This study targeted only one form of humor for only one audience:  Gen Z humor Instagram captions. This type of humor tends toward absurdities, which can be easier to generate than something that needs to be logically sound. Being illogically surprising is probably easier than being logical and surprising. Future work would have to test whether similar techniques work on other humor tastes. Some of our techniques, like fine-tuning, would likely work generically for all humor types, but other skills might need to be tried.

The caption humor is difficult, but it is more well-defined than other forms of humor. Caption humor only requires a punchline for a given image (the setup). Other forms of humor like standup comedy and popular humor magazines require generating both the setup and the punchline. A future direction is to explore what additional "skills" are needed to generate jokes with both setup and punchline. 

The humor generated here is for a public audience, but most humor made spontaneously is made for friends, and often users insider knowledge about the friends, their background, and their shared experiences. LLMs would likely struggle to make in-joke humor without a source of inside information to train on.

In our baseline captions, we crafted a simple prompt for GPT-4o to write humor. It is possible that with a better prompt or multiple generations, one could generate similar results. However, that is effectively what the system performs. It might be possible that there are prompts that don't employ any humor skills that can also generate jokes funnier than baseline GPT. Future work should test more prompts - both with and without skills to see if there are approaches other than skills that can enhance LLM humor generation.

% ensuring better generations and more consistent 






