\documentclass[journal]{IEEEtran}
\IEEEoverridecommandlockouts
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{float}
\usepackage{subfigure}
\usepackage{upquote}
\usepackage{multirow}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Take What You Need: Flexible Multi-Task Semantic Communications with Channel Adaptation}
\author{Xiang Chen, Shuying Gan, Chenyuan Feng, Xijun~Wang, and Tony Q. S. Quek, \IEEEmembership{Fellow, IEEE}
\thanks{Xiang Chen, Shuying Gan, and Xijun Wang are with the School of Electronics and Information Technology, Sun Yat-sen University, China (email: chenxiang@mail.sysu.edu.cn, ganshy7@mail2.sysu.edu.cn, wangxijun@mail.sysu.edu.cn).}
\thanks{Chenyuan Feng is with EURECOM, Sophia Antipolis, France (email: Chenyuan.Feng@eurecom.fr).}
\thanks{Tony. Q. S. Quek is with Singapore University of Technology and Design, Singapore (email: tonyquek@sutd.edu.sg).} 
}

\maketitle

\begin{abstract}
The growing demand for efficient semantic communication systems capable of managing diverse tasks and adapting to fluctuating channel conditions has driven the development of robust, resource-efficient frameworks. This article introduces a novel channel-adaptive and multi-task-aware semantic communication framework based on a masked auto-encoder architecture. Our framework optimizes the transmission of meaningful information by incorporating a multi-task-aware scoring mechanism that identifies and prioritizes semantically significant data across multiple concurrent tasks. A channel-aware extractor is employed to dynamically select relevant information in response to real-time channel conditions. By jointly optimizing semantic relevance and transmission efficiency, the framework ensures minimal performance degradation under resource constraints. Experimental results demonstrate the superior performance of our framework compared to conventional methods in tasks such as image reconstruction and object detection. These results underscore the framework’s adaptability to heterogeneous channel environments and its scalability for multi-task applications, positioning it as a promising solution for next-generation semantic communication networks.
\end{abstract}

\section{Introduction}

In the age of pervasive connectivity and advanced intelligent systems, conventional communication systems face a fundamental limitation: they excel at transmitting data but often fail to capture and convey meaning efficiently. These conventional frameworks, designed primarily for accurate data delivery, operate without understanding the significance and effectiveness of the information they transmit, particularly at the lower levels of network architecture \cite{Popovski2022,DZG2025}. This limitation has sparked the development of semantic communication, a revolutionary paradigm that prioritizes understanding and conveying the meaning inherent in information.   
%conventional communication frameworks—primarily concerned with the precise delivery of raw data—are increasingly being challenged by the rising need for more efficient and context-sensitive communication solutions. Traditional approaches often overlook the intrinsic value and effectiveness of the messages being transmitted, especially within the lower layers of network architecture. This has led to the emergence of a novel communication paradigm known as semantic communication.
Instead of simply transmitting bits, semantic communication focuses on the relevance and utility of information in relation to specific communication goals, ensuring that what gets transmitted serves a clear purpose. By ``understanding before transmitting", the system can significantly reduce data redundancy while maintaining or even improving the quality of service, making it particularly valuable in resource-constrained environments \cite{YC2025}.
%Unlike its predecessors, semantic communication prioritizes the accurate conveyance of the meaning and intent behind transmitted symbols, focusing on the relevance and utility of information in achieving specific communication goals. This approach not only enhances communication efficiency but is especially beneficial in environments where resources are limited \cite{nikos2021}.   By emphasizing "understanding before transmitting”, this paradigm significantly curtails data redundancy and elevates the overall quality of service. 
The potential of semantic communication has been increasingly recognized across a spectrum of applications, including but not limited to image and video transmission, natural language processing, and speech recognition, marking a significant shift in how information is communicated and processed in the digital age \cite{nikos2021}.

However, the majority of existing methodologies operate under the assumption of static or ideal channel conditions, a scenario that rarely reflects real-world environments. To address this, researchers have started investigating channel-adaptive semantic communications that combine semantic understanding with adaptive communication strategies. This integration allows systems to dynamically respond to fluctuating channel conditions while maintaining the integrity and relevance of the transmitted information \cite{ChanAda2024}.  Specifically, semantic encoding and decoding techniques are employed to extract and reconstruct the core meaning of information, thereby reducing the volume of data that must be transmitted. By focusing on transmitting only the essential semantic content, these techniques help mitigate the impact of limited bandwidth or suboptimal channel conditions. Moreover, channel estimation and prediction methods are utilized to monitor and forecast changes in channel conditions, facilitating proactive adjustments to communication parameters. Adaptive transmission strategies, such as dynamic modulation, coding, and resource allocation, are also implemented to optimize system performance based on real-time channel quality \cite{Yang2023, Zhang2024,Gao2024}. By continuously adjusting these parameters, the system can maintain optimal communication efficiency and data integrity despite changing conditions. Despite its potential, channel-adaptive semantic communication encounters several significant challenges. A primary obstacle is the complexity of semantic modeling, as accurately capturing and representing the meaning of diverse data types demands sophisticated algorithms and considerable computational resources. Another challenge lies in achieving real-time adaptability in dynamic environments, where rapid fluctuations in channel conditions necessitate low-latency decision-making and efficient resource allocation. Addressing these challenges is critical to realizing the full potential of this approach in practical applications. 

\begin{figure*}[!t]
\centering\includegraphics[width=0.98\textwidth]{figs/framework}
\caption{Illustration of the end-to-end channel-adaptive and multi-task-aware semantic communication framework.}
\label{Fig:framework}
\end{figure*}

Furthermore, the majority of existing methodologies are predominantly tailored for single-task scenarios, wherein the communication system is fine-tuned for a specific type of data or task. This stands in stark contrast to the multifaceted nature of real-world communication systems, which are frequently required to serve a variety of tasks concurrently, such as generating image captions, detecting objects, and reconstructing images simultaneously. Addressing this complexity, multi-task semantic communication has surfaced as a viable solution, harnessing several pivotal techniques \cite{Multitask2024,CSG2024}. Primarily, it adopts sophisticated semantic encoding and decoding strategies to distill and reconstruct the essence of information, thereby minimizing the volume of data necessitating transmission. Secondly, it capitalizes on multi-task learning algorithms to facilitate information sharing among interconnected tasks, enhancing both the generalization capabilities and the efficiency of the communication system. Despite its promising prospects, multi-task semantic communication is confronted with several formidable challenges. A primary concern is the issue of task conflict, wherein the optimization of one task's performance may inadvertently detrimentally affect another. Navigating these trade-offs demands the development of intricate algorithms and meticulous system design. Another challenge lies in the precise modeling of semantic content across varied data types, which requires the application of advanced machine learning techniques and access to comprehensive datasets. 

In the rest of this work, we first introduce various cases relevant to multi-task semantic communications. Then, we present an end-to-end semantic communication framework designed to handle multiple tasks within a unified architecture. This framework integrates adaptive communication strategies that dynamically adjust the amount of transmitted information based on both the semantic significance of the data and the prevailing conditions of the communication channel. To validate the effectiveness and advantages of the proposed framework, we will provide comprehensive experimental results. Finally, we will discuss several open challenges in this domain that require further investigation and development.




\section{Tasks in Semantic Communications}
Multi-task semantic communication aims to enhance communication efficiency by supporting multiple downstream tasks within a unified transmission framework. Unlike traditional systems that focus on raw data fidelity, multi-task semantic communication prioritizes the delivery of task-aware semantic information tailored to application-specific needs. These tasks are broadly categorized into three types based on their objectives: perception tasks, generation tasks, and decision tasks. 

Perception tasks form the foundational layer of semantic communication, aiming to extract and interpret semantically meaningful features from raw data. For example, image classification involves categorizing an image into predefined classes based on its content, such as distinguishing between a cat and a dog. Object detection extends this by identifying and locating objects within an image using bounding boxes, which is critical for autonomous driving systems to detect pedestrians and vehicles. Semantic segmentation further enhances this by classifying each pixel in the image, enabling fine-grained scene understanding, such as separating road lanes from sidewalks in urban environments. Additional tasks like image captioning bridges visual and linguistic semantics by generating textual descriptions of images. These tasks enable systems to prioritize task-relevant features while suppressing redundant or irrelevant details. 

Generation tasks focus on synthesizing new multimedia content from semantic representations extracted from images or other modalities. Image generation techniques, such as Generative Adversarial Networks (GANs) and Diffusion Models, produce realistic or stylized images from semantic descriptors or latent representations. These techniques are widely used in applications like virtual reality scene construction, artistic content creation, and medical imaging augmentation. Beyond static images, image-to-video generation extends this capability by predicting temporal sequences from single or sparse image inputs. For instance, reconstructing a dynamic 3D scene from a single 2D image for autonomous driving simulations or generating animated video summaries from keyframes in surveillance systems. Emerging cross-modal generation tasks further bridge visual semantics with audio content. Image-to-audio synthesis converts visual semantics into speech or music, enabling applications such as generating descriptive audio narrations for visually impaired users or creating background music aligned with image mood.
%Generation tasks are focused on creating new data samples based on input information, often tied to content synthesis. For example, image generation involves techniques like Generative Adversarial Networks (GANs) to produce realistic images from noise or existing data. This is used in creative industries, data augmentation, and simulations. Text generation tasks aim to produce coherent and contextually relevant text, whether it’s generating summaries, personalized dialogue in chatbots, or creating new articles. Similarly, speech generation converts textual data into human-like speech, which is essential in virtual assistants and accessibility tools. These tasks are critical for systems that need to synthesize or transform data into human-readable or usable formats.

Decision tasks translate semantic information into real-world actions, particularly in dynamic environments that require low latency and high reliability. Autonomous driving systems are a prime example of this category, where semantic data from cameras and LiDAR sensors inform obstacle avoidance, path planning, and lane-keeping decisions. In robotics, decision tasks enable object manipulation by interpreting visual semantics to guide grasping motions or navigation through unstructured environments, often using techniques like semantic Simultaneous Localization and Mapping (SLAM). These tasks typically demand tight integration between semantic extraction and control policies, as delayed or inaccurate semantic transmission can compromise system safety.

%By supporting these diverse tasks within a unified communication framework, multi-task semantic communication enables systems to transmit not only raw data but also relevant, actionable information. This makes the communication process more efficient and intelligent, ensuring that the transmitted content meets the specific needs of each task. Whether it's understanding and generating content, or making decisions based on sensory input, multi-task semantic communication plays a crucial role in enhancing the overall capability and utility of modern communication systems.

The synergy between these task categories enhances cross-functional efficiency in multi-task semantic communication frameworks. Perception outputs, such as detected objects in a traffic scene, can simultaneously support decision-making (e.g., path planning) and generation tasks (e.g., real-time incident reporting). This interdependence enables the reuse of shared semantic features, eliminating redundant data transmission. Furthermore, tasks can be prioritized based on channel conditions and task criticality—for example, prioritizing obstacle detection over image reconstruction in low-bandwidth scenarios, ensuring system safety without compromising functionality. By integrating these diverse tasks within a unified communication framework, multi-task semantic communication allows systems to transmit task-relevant, actionable information. This approach makes the communication process more efficient and intelligent, ensuring that the transmitted content meets the specific requirements of each task.

% The framework dynamically prioritizes tasks based on context: in low-bandwidth scenarios, it allocates resources to critical tasks like obstacle detection over high-resolution image generation. This unified approach transforms communication from raw data transfer to semantic intent delivery, ensuring transmitted information is actionable, adaptive, and minimally redundant.



\section{Channel-Adaptive Multi-Task Semantic Communication Framework}
To address the dual challenges of multi-task adaptability and resource-efficient communication, we propose a channel-adaptive and multi-task-aware semantic communication framework, as shown in Fig. \ref{Fig:framework}. The framework jointly optimizes task performance and channel utilization through three cascaded stages: multi-task-aware scoring, channel-adaptive extraction, and masked auto-encoding. First, a scoring module, trained via aggregated losses from downstream tasks, dynamically assigns relevance scores to image patches based on their semantic importance to each task. Guided by real-time channel state information (CSI), a channel-adaptive extractor then selects a minimal subset of high-priority patches for transmission, adaptively adjusting the selection to bandwidth constraints (e.g., prioritizing edge-critical patches in low-SNR scenarios). A pre-trained masked auto-encoder processes the selected patches. At the transmitter, it encodes the unmasked patches, while at the receiver, it reconstructs task-compatible semantic features from the received data. This enables concurrent execution of diverse tasks, from image reconstruction to object detection, without requiring separate communication streams. This innovative approach yields a communication system that is both flexible and robust, capable of accommodating diverse downstream tasks even under stringent communication resource limitations. Detailed descriptions of each module within the framework will be provided in the subsequent sections. 

%To enhance communication and learning efficiency, we propose a channel-adaptive and multi-task-aware semantic communication framework, as shown in Fig. \ref{Fig:framework}.  This framework is designed to achieve high robustness in handling multiple tasks while minimizing the consumption of communication resources. The core implementation process involves several key steps:  First, the loss from various downstream tasks is aggregated to train a scoring module that is adapt to multiple tasks. This module establishes a scoring relationship between tasks and image patches. Subsequently, a channel-aware extractor comes into play, providing real-time constraints on channel resources and selecting a limited set of image patches for transmission to the receiver. Finally, the receiver utilizes a pre-trained model to reconstruct the original features from the received ones and feeds them to downstream networks for specific inference tasks (e.g., image reconstruction, object detection, semantic segmentation, etc.). This innovative approach yields a communication system that is both flexible and robust, capable of accommodating diverse downstream tasks even under stringent communication resource limitations. Detailed descriptions of each module within the framework will be provided in the subsequent sections. 



\begin{figure*}[!t]
\centering\includegraphics[width=0.98\textwidth]{figs/networks}
\caption{Network architecture details of the transceiver. In the Multi-Head Attention mechanism, \( Q \) (Query) represents the feature vector corresponding to the current context or focus, \( K \) (Key) acts as the reference information used for matching with the Query, and \( V \) (Value) denotes the feature vector from which relevant information is extracted once a match is found. }
\label{Fig:network architecture}
\end{figure*}

\subsection{Multi-task-aware Scoring}
The multi-task-aware scoring module serves as the cornerstone of this framework, establishing crucial relationships between downstream tasks and image features. We implement this scoring module using a modified Visual Transformer (ViT) \cite{Dosovitskiy2021} architecture, as shown in Fig. \ref{Fig:network architecture}. The architecture consists of two main components: an embedding layer for initial feature extraction and a transformer layer for task-aware scoring.

%To implement this scoring mechanism, we employ the Visual Transformer (ViT) \cite{Dosovitskiy2021} network architecture, as illustrated in Fig. \ref{Fig:network architecture}. This scoring module is composed of two integral components: the embedding layer and the transformer layer. 

The embedding layer processes input images through several sequential steps. First, it divides each image into fixed-size patches, which are then flattened and projected through a linear transformation to create feature vectors. To preserve spatial context, these vectors are augmented with positional embeddings that encode each patch's location within the original image.

%The embedding layer functions to transform the input image into a sequence of patches, thereby facilitating subsequent processing. Specifically, the embedding layer initially segments the input image into fixed-size patches. Each patch is then flattened and passed through a linear transformation layer, converting it into a feature vector. To capture the spatial information, a position embedding is appended to each feature vector, representing the relative position of the patch within the original image. 

The transformer layer, comprising multiple stacked transformer blocks, serves as the core component for learning task-patch relationships. Upon receiving the feature vectors from the embedding layer, the transformer layer encodes them using a multi-head attention mechanism. This mechanism learns the correlations between the feature vectors and the multiple downstream tasks, effectively identifying which patches are most relevant to each task. In the final transformer block, we depart from the standard architecture by replacing the normalization layer \cite{Dosovitskiy2021} with dedicated softmax layers for each attention head. These attention weights are then averaged across all heads to produce a single, unified importance score for each patch. This architecture outputs reconstructed patch vectors, each assigned an attention score that quantifies its relevance to downstream tasks. Higher scores indicate greater importance for task execution, enabling efficient prioritization of information during communication. 

%The transformer layer, which is the core component for learning task-patch relationships, consists of multiple stacked transformer blocks. Upon receiving the feature vectors from the embedding layer, the transformer layer encodes them using a multi-head attention mechanism. This mechanism learns the correlations between the feature vectors and the multiple downstream tasks, effectively identifying which patches are most relevant to each task. After the multi-head attention mechanism in the final transformer block, rather than connecting a normalization layer as typically done \cite{Dosovitskiy2021}, we introduce a softmax layer for each attention head. The output attention weights from all heads are then averaged. This approach ensures that the attention scores are normalized and reflect the relative importance of each patch across different tasks. The feature vectors are subsequently reconstructed into patch vectors, with each patch assigned an attention score. This score quantifies the correlation between the patch and the downstream tasks. A higher attention score indicates that the patch is more critical for the downstream tasks, thereby enabling the system to prioritize important information for efficient communication and task execution. 

To implement multi-task-aware scoring, we train the network through joint optimization across multiple downstream image tasks, including image reconstruction, semantic segmentation, and keypoint recognition. The scoring module is optimized using a weighted aggregation of task-specific losses (e.g., reconstruction L1 loss, segmentation Dice loss, and keypoint detection MSE loss). During each training iteration, these losses are weighted and combined into a global loss that guides the scoring network's optimization. This joint training strategy enables the network to identify cross-task critical features while balancing task-specific biases. During inference, the learned scoring mechanism guides channel-aware patch selection, ensuring the transmission of only the most task-relevant semantic information. This scoring module creates a dynamic bridge between visual features and task requirements, facilitating resource-efficient multi-task processing.
%To implement the multi-task-aware scoring, we begin by training it through a joint optimization process across multiple downstream image tasks, such as image reconstruction, semantic segmentation, and keypoint recognition. Specifically, during each training iteration, the loss values from the downstream networks of each image task are weighted and summed to form the global loss, which is then transmitted back to the multi-task-aware scoring network. The scoring network is trained by minimizing the global loss. Once the network has been trained, its parameters can be leveraged for inference on new datasets. Additionally, for well-established tasks, such as image classification, object detection, and image captioning, pre-trained models can be directly fine-tuned, enabling faster convergence and reducing computational overhead. 

\subsection{Channel-adaptive Extraction }
Our framework operates over wireless channels with dynamic variations, where channel capacity follows the Shannon Capacity Formula. The channel-adaptive extractor monitors real-time channel state information (CSI) through feedback, accounting for fading, noise, and path loss effects \cite{Judd2008}. This continuous CSI monitoring enables precise estimation of the current transmission rate and allows our framework to dynamically adjust the source encoding rate to match available channel capacity.

The extraction process begins by dividing input images into fixed-size patches. Using the scores from multi-task-aware scoring, the channel-adaptive extractor selects patches for transmission in order of descending importance. This score-guided selection ensures that patches most critical for downstream tasks are prioritized when channel conditions limit transmission capacity. By integrating task-aware scoring with channel-adaptive extraction, our framework maintains high performance on downstream tasks even under varying channel constraints, as the receiver reconstructs images with high fidelity in semantically important regions.

%This work considers a wireless channel with dynamic variations, where the channel capacity is calculated using the Shannon Capacity Formula. To adapt to these fluctuations, the channel-aware extractor continuously retrieves real-time channel state information (CSI) from feedback, accounting for key factors such as fading, noise, and path loss \cite{Judd2008}. Leveraging this information, the extractor accurately determines the channel’s current transmission rate. Consequently, our framework dynamically adjusts the source encoding rate of transmitted images in response to the available channel capacity, ensuring efficient and adaptive communication.

%Since the encoding size of each image is fixed, the image is divided into patches. The channel-aware extractor then selects a subset of these patches for adaptive transmission, prioritizing them based on their scores, which are ranked from highest to lowest. This real-time adaptive transmission ensures that the reconstructed image at the receiver side retains high fidelity in the critical areas, thereby enhancing the performance of downstream tasks during inference. The relevance of each image patch to the downstream tasks is assessed using the multi-task-aware scoring mechanism. By integrating this scoring mechanism with the channel-adaptive extractor, our framework effectively adapts to channel constraints while meeting the specific requirements of downstream tasks.

\begin{figure*}[!t]
\centering\includegraphics[width=0.98\textwidth]{figs/total_results}
\caption{Visualization results of multi-task semantic communication under different mask ratio and different strategies. }
\label{Fig:total-figs}
\end{figure*}



\subsection{MAE-based Encoder and Decoder}
Our framework leverages a pre-trained masked autoencoder (MAE) \cite{He2022} as its backbone for encoding and decoding operations. The encoder processes selected patches into feature representations, while the decoder reconstructs features for the entire image using only the transmitted patches, enabling downstream task execution.
We modify the original MAE architecture by replacing its random masking mechanism with channel-adaptive patch selection. The encoder processes patches selected by the extractor. Specifically, the encoder first receives the patches from the extractor, applies linear projection, and incorporates positional embeddings (using the sine-cosine version). These processed patches are then passed through transformer blocks to generate feature vectors for the retained patches. These features are then transmitted over the wireless channel.

At the receiver, the decoder reconstructs the complete image using the received feature vectors and their positional embeddings. The reconstructed output serves as input to various pre-trained task-specific networks (e.g., ResNet-50 for object detection \cite{He2016}), ensuring that the framework effectively facilitates task-specific inference. During training of the multi-task scoring module, both encoder and decoder parameters remain frozen to preserve pre-trained feature representations and reduce computational overhead.  This architecture enables task-aware reconstruction that adapts to both channel conditions and downstream task requirements, producing reconstructions that preserve task-critical features even under varying channel constraints.

%In the proposed framework, we employ a pre-trained masked auto-encoder (MAE) \cite{He2022} as the backbone network for both the encoder and decoder. The encoder encodes the selected patches into features and the decoder utilize the transmitted patches to reconstruct the features of the remaining patches of the original image, thereby supporting the completion of downstream tasks. The output of the decoder are fed into different pre-trained task-specific networks for the downstream tasks, ensuring that the framework effectively facilitates task-specific inference.

%A key innovation in our framework lies in the modification of the original MAE’s random masking mechanism. Instead of employing random masking, the encoder directly retains the patches selected by the extractor and masks the remaining ones. Specifically, the encoder first receives the patches from the extractor, applies linear projection, and incorporates positional embeddings (using the sine-cosine version). These processed patches are then passed through transformer blocks to generate feature vectors for the retained patches. The encoder’s output is transmitted through the wireless channel to the decoder, which reconstructs the original image based on the feature vectors and their corresponding positional embeddings. Depending on the specific downstream tasks, the reconstructed image can be input into various pre-trained networks for inference (e.g., ResNet-50 for object detection \cite{He2016}). Note that during the training of the multi-task scoring module, the parameters of both the encoder and decoder remain frozen. Importantly, different downstream tasks and channel requirements will reconstruct images with different focuses. This approach represents a novel way of integrating channel-aware and task-specific considerations in the reconstruction process.


%We weigh the losses from the decoder’s multiple downstream task networks and aggregate them to compute the global loss. This global loss is then propagated back into the scoring mechanism, leading to the development of a highly robust and adaptive scoring system.


\begin{table*}[tp]
\caption{Multi-task Performance Comparison in terms of latency, image reconstruction loss and object detection accuracy}
\label{Tab: results}\renewcommand{\arraystretch}{1.5}
\centering{}%
\begin{tabular}{c|c|r@{\extracolsep{0pt}.}l|r@{\extracolsep{0pt}.}l|r@{\extracolsep{0pt}.}l|r@{\extracolsep{0pt}.}l|r@{\extracolsep{0pt}.}l|r@{\extracolsep{0pt}.}l|r@{\extracolsep{0pt}.}l|r@{\extracolsep{0pt}.}l|r@{\extracolsep{0pt}.}l}
\hline 
\multirow{2}{*}{Mask ratio} & \multirow{2}{*}{Latency (ms)} & \multicolumn{2}{c|}{\multirow{2}{*}{Mechanism}} & \multicolumn{8}{c|}{Image Reconstruction} & \multicolumn{8}{c}{Object Detection}\tabularnewline
\cline{5-20} \cline{7-20} \cline{9-20} \cline{11-20} \cline{13-20} \cline{15-20} \cline{17-20} \cline{19-20} 
 &  & \multicolumn{2}{c|}{\multirow{2}{*}{ }} & \multicolumn{2}{c|}{MSE} & \multicolumn{2}{c|}{PSNR} & \multicolumn{2}{c|}{SSIM} & \multicolumn{2}{c|}{LPIPS} & \multicolumn{2}{c|}{IoU} & \multicolumn{2}{c|}{Acc} & \multicolumn{2}{c|}{F1-Score} & \multicolumn{2}{c}{mAP}\tabularnewline
\hline 
0 (Original) & 0.2936 & \multicolumn{2}{c|}{-} & \multicolumn{2}{c|}{-} & \multicolumn{2}{c|}{-} & \multicolumn{2}{c|}{-} & \multicolumn{2}{c|}{-} & 0&6219 & 0&4057 & 0&4830 & 0&4672\tabularnewline
\hline 
0.2 & 0.2349 & \multicolumn{2}{c|}{Random} & 910&1873 & 18&5395 & 0&6789 & 0&3099 & 0&4230 & 0&1570 & 0&2512 & 0&2852\tabularnewline
\hline 
0.2 & 0.2349 & \multicolumn{2}{c|}{Our} & 54&5836 & 30&7602 & 0&8755 & 0&0815 & 0&6115 & 0&3518 & 0&4729 & 0&4603\tabularnewline
\hline 
0.4 & 0.1761 & \multicolumn{2}{c|}{Random} & 1332&6553 & 16&8836 & 0&4847 & 0&4101 & 0&1377 & 0&0694 & 0&1585 & 0&1875\tabularnewline
\hline 
0.4 & 0.1761 & \multicolumn{2}{c|}{Our} & 134&3788 & 26&8474 & 0&7442 & 0&1398 & 0&5989 & 0&3327 & 0&4658 & 0&4560\tabularnewline
\hline 
0.6 & 0.1174 & \multicolumn{2}{c|}{Random} & 1596&9192 & 16&5644 & 0&3507 & 0&4536 & 0&1173 & 0&0341 & 0&0601 & 0&1098\tabularnewline
\hline 
0.6 & 0.1174 & \multicolumn{2}{c|}{Our} & 266&4309 & 23&8749 & 0&5692 & 0&2111 & 0&5750 & 0&3177 & 0&4431 & 0&3895\tabularnewline
\hline 
0.8 & 0.0587 & \multicolumn{2}{c|}{Random} & 1434&3153 & 16&0979 & 0&2529 & 0&4946 & 0&1098 & 0&0336 & 0&0552 & 0&0714\tabularnewline
\hline 
0.8 & 0.0587 & \multicolumn{2}{c|}{Our} & 767&9826 & 19&2773 & 0&3459 & 0&3785 & 0&4955 & 0&2866 & 0&3808 & 0&2917\tabularnewline
\hline 
\end{tabular}
\end{table*}


\section{Experimental Results}

In this section, we present the training and evaluation of the framework for image reconstruction and object detection tasks. %We begin by outlining the experimental setup, which includes the environment, dataset, training strategy, evaluation metrics, and the methods used for comparison. Next, we analyze the framework's performance in multi-task scenarios. Finally, we assess the adaptability of the proposed framework to varying channel conditions.

\subsection{Experiment Setups}
\subsubsection{Experimental environment}
The experiments are conducted on a server equipped with two NVIDIA A100 GPUs, each with 80 GB of memory. The server runs Ubuntu 22.04.3 LTS, and the experiments are implemented using PyTorch 2.5.1 with CUDA 12.4. These resources are employed to simulate the receiver, transmitter, and wireless channel within the framework, as well as to perform both training and evaluation.

\subsubsection{Datasets}
To train and evaluate the proposed framework, we use the COCO 2014 dataset, a large-scale dataset for object detection, semantic segmentation, and captioning provided by Microsoft\footnote{https://cocodataset.org}. The dataset includes training, validation, and test sets. Given that COCO 2014 contains images of varying sizes, all images are resized to 224x224 pixels, with the patch size set to 16x16. The coordinate information in the dataset is scaled accordingly. The training set is used to train the multi-task-aware scoring mechanism within the framework, while the validation set is employed to assess the performance of our framework.

\subsubsection{Training strategy}
During the framework's training, we use the pre-trained MAE (mae-vit-base-patch16) network \cite{He2022} provided by Meta as the backbone for the encoder, decoder, and image reconstruction tasks. For object detection, we leverage the pre-trained DETR ResNet-50 network \cite{ResNet}, also from Meta. After freezing the parameters of these networks, we train the multi-task-aware scoring mechanism using the training set. The scoring mechanism is built upon the ViT-base-patch16-224 architecture \cite{He2022}, with an embedding dimension of 768 and 12 Transformer encoder layers, where the self-attention mechanism employs 12 attention heads. In this framework, the image patch size is set to 16x16, the batch size is 32, and the learning rate is configured to 1e-4.


\subsubsection{Performance metrics}
For the image reconstruction task, we utilize the following four performance metrics: 
i) Mean Squared Error (MSE), which measures the image difference by averaging the squared pixel errors. Lower values indicate greater image similarity, though MSE does not capture structural information.
ii) Peak Signal-to-Noise Ratio (PSNR), which evaluates pixel-level consistency, with higher values indicating better image quality. However, it overlooks structural details.
iii) Structural Similarity Index (SSIM), which assesses image quality by considering brightness, contrast, and structural similarity. Higher SSIM values reflect greater similarity between images, making it more sensitive to structural information than MSE and PSNR.
iv) Learned Perceptual Image Patch Similarity (LPIPS), which leverages deep learning to focus on perceptual differences. LPIPS captures higher-level perceptual variations more effectively than SSIM, with lower values indicating greater perceptual similarity between images.
SSIM and LPIPS effectively address the limitations of MSE and PSNR by better representing the structural and perceptual qualities of the images.

For the object detection task, we employ the following performance metrics: 
i) Intersection over Union (IoU), which measures the overlap between the predicted and ground truth bounding boxes. Higher IoU values indicate more accurate predictions.
ii) Accuracy, which represents the overall proportion of correct predictions. However, in object detection, accuracy may be influenced by false negatives and might not fully reflect the model’s performance.
iii) F1 Score, which is the harmonic mean of precision and recall, making it particularly useful for evaluating models on imbalanced datasets.
iv) Mean Average Precision (mAP), which assesses the model's detection accuracy across multiple classes, taking into account different IoU thresholds (e.g., 0.5 and 0.75). mAP evaluates the model’s performance at various levels of overlap. Higher values in these metrics correspond to better model performance, with each metric providing unique insights into the model’s effectiveness in detecting objects.

\subsubsection{Baseline method}
For the comparison method, we selected a communication framework based on the original MAE model. In this baseline framework, the original MAE utilizes a random masking mechanism, where image reconstruction or subsequent downstream tasks are performed based on the unmasked patches. In the baseline method, random masking is applied, followed by passing the masked image through the pre-trained MAE and downstream task models for image reconstruction and object detection. To ensure the validity and fairness of the experiments, both the proposed and baseline methods share identical structures, with the only difference being the parameters associated with the masking mechanism.


\subsection{Multi-task Performance Evaluation}

Table \ref{Tab: results} compares the multi-task performance of our proposed framework in terms of transmission latency and various task-specific metrics. Fig. \ref{Fig:total-figs} illustrates the visual results under different mask ratios. In this experiment, we simulate an AWGN channel with an SNR of 16 dB and a bandwidth of 1 MHz. Each image is approximately 150 KB in size, with a resolution of 224$\times$224$\times$3, representing a size of 150 KB.

In terms of image reconstruction, our proposed framework demonstrates exceptional performance. As shown in Table \ref{Tab: results}, whether evaluated using traditional pixel-level metrics such as MSE and PSNR, or semantic metrics like SSIM and LPIPS, our framework consistently outperforms the random masking-based method. Furthermore, when the mask ratio is small (i.e., 0.2 and 0.4), the images reconstructed by our framework exhibit minimal differences from the original images. Even when the mask ratio is larger (i.e., 0.8), the reconstructed images, though displaying some differences, still show significant improvements—our framework achieves an 83.32\% reduction in MSE and a 53.46\% reduction in LPIPS. This indicates that our framework effectively identifies and prioritizes key semantic information, enabling it to optimize transmission. With limited communication resources, it ensures the closest possible reconstruction of the image by focusing on transmitting only the most critical information.

In the object detection task, our framework also surpasses the baseline method. As shown in Table \ref{Tab: results}, the advantages of our method become even more pronounced as the mask ratio increases. Once the mask ratio exceeds 0.4, the performance of the random mask-based method deteriorates sharply, with several metrics approaching zero. In contrast, while the performance of our approach does decrease as the mask ratio grows, the decline is gradual and more controlled. Notably, when the original image is transmitted (mask ratio = 0), the metric values represent the optimal results for the current object detection model. Even with a mask ratio of 0.4, our method performs almost optimally. This is due to the fact that, unlike image reconstruction tasks, object detection tasks only require a subset of the image, with background information being less important. Our framework effectively identifies and prioritizes the essential information for transmission, thereby saving communication resources while maintaining strong object detection performance.

When combining the evaluation metrics from both tasks, it is evident that our framework excels across all metrics. Even with higher mask ratios, our method continues to deliver robust results. In contrast to the high sensitivity of the random masking mechanism, our approach exhibits remarkable resilience. This suggests that our framework is not only extendable to other downstream tasks but also capable of operating effectively in suboptimal communication environments. Additionally, the comparison of transmission latency shows that higher mask ratios can accelerate the completion speed of tasks. Thus, different mask ratios can be adaptively adjusted depending on the downstream task to balance transmission latency and task performance quality, ultimately resulting in enhanced overall service quality.

\begin{figure}[!t]
\centering\includegraphics[width=0.48\textwidth]{figs/Reconstruction_SNR}
\caption{Image Reconstruction Performance Comparison under different SNR. }
\label{Fig:recon}
\end{figure}



\subsection{Channel Adaptability Analysis}

To assess the adaptability of the framework to varying channel qualities, Fig. \ref{Fig:recon} and Fig. \ref{Fig:obj-dect} present the performance of the proposed framework in both image reconstruction and object detection tasks under different SNR levels. We consider an AWGN channel with a bandwidth of 1 MHz and configure the transmission latency to 0.15 ms. 

As illustrated in Fig. \ref{Fig:recon}, our method consistently outperforms the random masking mechanism in terms of PSNR and SSIM, irrespective of the SNR value. As the SNR increases and channel quality improves, both our approach and the baseline method show enhanced performance, with the gap between them progressively widening. This indicates that our method exhibits remarkable adaptability to varying channel conditions, consistently delivering high performance across different SNR levels.

In Fig. \ref{Fig:obj-dect}, it is evident that the proposed method significantly outperforms the random masking approach in object detection across all SNR levels. Notably, at lower SNR values, where the random mechanism struggles, our framework maintains strong performance. This further underscores the effectiveness of our approach, demonstrating its robustness and ability to operate efficiently even under challenging channel conditions.

\begin{figure}[!t]
\centering\includegraphics[width=0.48\textwidth]{figs/Object_Detection_SNR}
\caption{Object Detection Performance Comparison under different SNR.}
\label{Fig:obj-dect}
\end{figure}



\section{Open Issues}
While the proposed framework offers notable advantages, several open issues remain that must be addressed before it can be effectively deployed at scale in real-world applications. These following issues require further exploration.

\subsection{Scalability in Large-scale Semantic Communication Networks}
Scaling the proposed system to accommodate a wide array of tasks and a large number of users simultaneously, while maintaining efficiency and robustness, presents a significant challenge. As the volume of tasks and users escalates, the complexity associated with resource allocation, interference management, and real-time adaptation correspondingly increases. This can potentially result in heightened latency and diminished performance. To mitigate these challenges, hierarchical resource allocation strategies can be implemented to effectively prioritize critical tasks and users, ensuring that essential operations receive the necessary resources. Additionally, leveraging distributed computing frameworks to offload processing tasks to edge devices can significantly reduce the load on the central server, thereby enhancing overall system efficiency. Moreover, utilizing dynamic task scheduling algorithms can optimize the order and timing of task execution based on the current system load and channel conditions, thereby improving resource utilization and performance. These approaches collectively aim to enhance the scalability and robustness of the system, ensuring it can efficiently handle a large-scale communication network.

\subsection{Cross-domain Adaption Issue for Data-scarce Networks}
Another challenge is adapting the communication system to function effectively across different application domains (e.g., healthcare, industrial IoT) without extensive retraining. Each domain may have unique data characteristics, communication requirements, and performance metrics. This heterogeneity complicates the development of a universal solution that can seamlessly operate across different domains without extensive retraining.
To address this challenge, several advanced techniques can be employed. Specifically, transfer learning is a powerful approach that leverages pre-trained models from one domain and fine-tunes them for another. This significantly reduces the need for extensive retraining and accelerates the adaptation process. Secondly, domain adaptation algorithms (e.g., adversarial training and domain-invariant feature learning) focus on minimizing the discrepancy between different domains by adjusting model parameters. These algorithms aim to align the feature distributions of source and target domains, thereby reducing the negative impact of domain shift. Moreover, meta-learning, or "learning to learn," involves creating models that can quickly adapt to new tasks and domains with minimal data and training. By learning a generalizable representation that captures the underlying structure of various domains, meta-learning models can rapidly fine-tune themselves to new tasks using only a small amount of data. This approach is particularly useful for scenarios where data is scarce or computational resources are limited. %By leveraging transfer learning, domain adaptation algorithms and meta-learning techniques, the system can achieve greater flexibility and adaptability, ultimately enhancing its ability to function effectively across diverse application domains.

\subsection{Security and Privacy Issue for Information-sensitive Communication}
Ensuring the security and privacy of data transmitted over shared communication channels is also a critical concern. As multiple tasks and users share the same communication infrastructure, the risk of eavesdropping, data tampering, and unauthorized access increases. Additionally, the dynamic nature of channel adaptation and multi-task communication introduces vulnerabilities that can be exploited by adversaries. Protecting sensitive information while maintaining efficient communication is a complex challenge. To this end,  incorporating differential privacy techniques to add noise to data or model parameters before transmission can protect user privacy without significantly compromising utility.  Using homomorphic encryption also allows computations to be performed on encrypted data without decryption. Secure Multi-Party Computation enables multiple parties to jointly compute a function over their inputs while keeping those inputs private.  Furthermore, implementing blockchain can provide a decentralized and tamper-proof ledger for recording communication transactions. This ensures data integrity and traceability, making it difficult for adversaries to tamper with the data without detection. Lastly,  robust access control mechanisms and strong authentication protocols can prevent unauthorized access to the communication system. Multi-factor authentication and role-based access control can further enhance security.

\section{Conclusions}

This paper introduces a novel framework for channel-adaptive and multi-task semantic communication, designed to enhance both communication and learning efficiency in complex, real-world scenarios.  The proposed framework incorporates a multi-task-aware scoring mechanism to effectively capture and prioritize the transmission of semantically relevant information across multiple tasks.  A channel-aware extractor dynamically adapts to varying channel conditions, optimizing resource allocation and ensuring efficient communication.  Experimental results validate the effectiveness of our framework, demonstrating significant improvements in image reconstruction and object detection tasks compared to traditional methods.  The framework's ability to adapt to different channel qualities and handle multiple tasks concurrently highlights its potential for diverse applications in future communication systems.

\appendices{\bibliographystyle{IEEEtran}
\bibliography{IEEEabrv,IEEEexample,Mag-SemCom}
}


\end{document}
