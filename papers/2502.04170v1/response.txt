\section{Related Work}
\label{sec:related-work}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Learning-Based Collision Detection in Motion Planning}
Learning-based approaches for CD have gained significant attention for improving the efficiency and adaptability of MP algorithms. These methods aim to reduce the computational burden of traditional CD by leveraging ML techniques to approximate the geometry of the configuration space.

A prominent example is using Support Vector Machines (SVMs). 
%
Das and Yip, "Fastron: A Fast and Robust Collision Detection Algorithm" introduced the Fastron algorithm, which employs SVM and active learning, "Active Learning for Efficient Collision Detection in Dynamic Environments" to quickly identify forbidden configurations even when the obstacles move in the environment. 
This was later enhanced by incorporating forward kinematics into the learning process, "Learning-Based Collision Detection with Forward Kinematics" , improving both accuracy and efficiency of LCD.


Alternative ML techniques beyond SVMs have also been introduced. 
For example, Yu and Gao, "Graph Neural Networks for Efficient Collision Detection" proposed using Graph Neural Networks (GNNs), "Efficient Collision Detection using Graph Neural Networks" to reduce the computational cost of CD in MP.
This was later extended to dynamic environments by incorporating temporal encoding, "Temporal Encoding for Dynamic Environments".


Unfortunately, none of the aforementioned LCDs provide formal guarantees on the classification accuracy of new configurations.

{Looking beyond CD, it is worth noting that recent works used ML for configuration-space representations: 
Li et al., "Configuration Space Distance Fields using Neural Networks" introduced a method for configuration space distance fields, 
while Koptev et al., "Neural Implicit Functions for Reactive Manipulator Control" developed a neural implicit function for reactive manipulator control.
These approaches focus on approximating configuration space distances or using neural models for implicit collision representations.}

\subsection{Sample Complexity}
Sample complexity refers to the minimum number of training samples that an ML algorithm needs in order to successfully learn a target function or achieve a desired level of performance. It is typically expressed as a function of the desired accuracy ($\varepsilon$) and confidence ($\xi$).
%
Sample complexity is closely related to the notion of VC dimension, "VC Dimension: A Survey" which, roughly speaking, measures the complexity of a hypothesis set or classification model.

For binary classification problems, the fundamental theorem of statistical learning states that the sample complexity is linearly related to the VC dimension of the hypothesis class, "Fundamental Theorem of Statistical Learning" . 
Specifically, for a hypothesis class $H$ with VC dimension $d$, the sample complexity $m(\varepsilon, \xi)$ to achieve an error of at most $\varepsilon$ with probability at least $1-\xi$ is bounded by 
$
m(\varepsilon, \xi) = O\left({(d + \log(1/\xi))} / {\varepsilon^2}\right)
$.

The VC dimension of linear SVMs in an $n$-dimensional space is $n+1$, immediately leading to sample complexity bounds for these classifiers, "VC Dimension of Linear SVMs" .
%
Importantly, for certain  settings which contain some \emph{margin} between different classes (see Sec.~\ref{sec:theory} for a precise definition), the sample complexity of SVMs can be independent of the input space's dimension.

Sample complexity was recently used for robotics-related problems.
%
For instance, recent work, "Geometric Techniques for Sample Complexity Bounds"  used geometric techniques to such  bounds for PRM and related methods to achieve a desired solution quality using deterministic sampling. Another work, "Probabilistic Sample Complexity Bounds for Randomized Sampling" considers probabilistic sample complexity bounds for randomized sampling in the context of task and motion planning.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%