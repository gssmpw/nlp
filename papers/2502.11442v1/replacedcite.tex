\section{Related Work}
\header{Conversational question clarification.}
Query clarification improves search by refining user queries with additional context____, addressing ambiguities in various tasks including entity disambiguation____, voice-based interactions ____, question answering____ and recommendation____.
In mixed-initiative search systems, where the conversational initiative alternates between users and agents, targeted clarifying questions have been shown to improve retrieval performance and user satisfaction____. For instance, ____ introduced the ClariQ benchmark, which employs clarifying questions to disambiguate vague queries. Building on these foundations, ____ advanced the field further by developing Melon, a system that integrates visual inputs into the clarification process, thereby helping users refine their queries more effectively. Despite these advances, challenges remain in effectively merging multi-modality with multi-turn conversational interactions.









\header{Multi-modal information retrieval.} Multi-modal information retrieval has gained substantial growth by integrating different modalities to provide accurate search results ____. These modalities, including text, images, audio, and video, are effective in addressing queries across diverse scenarios ____. By leveraging multi-modal data, retrieval systems can offer better and more accurate responses, which result in user satisfaction and engagement____. Inspired by the advancements in generative large language models, new waves of multi-modal pretrained generative models have emerged which further exploit the capabilities of IR systems ____. Recent work has demonstrated the effectiveness of these multi-modal models in various IR tasks, such as query reformulation ____, question answering ____, and cross-modal retrieval ____. Based on this, our work focuses on asking multi-modal clarifying questions in a multi-turn \ac{CS} system and investigates whether it results in better retrieval performance.