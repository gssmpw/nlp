\section{Related Work}
\header{Conversational question clarification.}
Query clarification improves search by refining user queries with additional context~\cite{queryclarification}, addressing ambiguities in various tasks including entity disambiguation~\cite{Coden2015DidYM}, voice-based interactions \cite{10.1145/3209978.3210160}, question answering~\cite{QAclarifyingquestion} and recommendation~\cite{recommenderCQ}.
In mixed-initiative search systems, where the conversational initiative alternates between users and agents, targeted clarifying questions have been shown to improve retrieval performance and user satisfaction~\cite{rahmani-etal-2024-clarifying,DBLP:journals/corr/abs-2410-19692}. For instance, \citet{DBLP:journals/corr/abs-2009-11352} introduced the ClariQ benchmark, which employs clarifying questions to disambiguate vague queries. Building on these foundations, \citet{yuan2024askingmultimodalclarifyingquestions} advanced the field further by developing Melon, a system that integrates visual inputs into the clarification process, thereby helping users refine their queries more effectively. Despite these advances, challenges remain in effectively merging multi-modality with multi-turn conversational interactions.









\header{Multi-modal information retrieval.} Multi-modal information retrieval has gained substantial growth by integrating different modalities to provide accurate search results \cite{MMIR}. These modalities, including text, images, audio, and video, are effective in addressing queries across diverse scenarios \cite{MMIR,yuan2024askingmultimodalclarifyingquestions}. By leveraging multi-modal data, retrieval systems can offer better and more accurate responses, which result in user satisfaction and engagement~\cite{DBLP:journals/corr/cs-IR-0311029}. Inspired by the advancements in generative large language models, new waves of multi-modal pretrained generative models have emerged which further exploit the capabilities of IR systems \cite{DBLP:journals/corr/abs-2103-00020,DBLP:journals/corr/abs-2005-09801}. Recent work has demonstrated the effectiveness of these multi-modal models in various IR tasks, such as query reformulation \cite{garg2021multimodal}, question answering \cite{Xu2019AskingCQ}, and cross-modal retrieval \cite{DBLP:journals/corr/abs-2005-09801}. Based on this, our work focuses on asking multi-modal clarifying questions in a multi-turn \ac{CS} system and investigates whether it results in better retrieval performance.