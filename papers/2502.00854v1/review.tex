\section{Bayesian optimization}
\label{sec:BO}

\subsection{The general framework}

To solve the unconstrained optimization problem~\eqref{eq:opt_prob}, the \textit{Bayesian optimization} (BO) framework~\cite{MockusBayesianmethodsseeking1975,JonesEfficientglobaloptimization1998} builds a surrogate model (using a Gaussian process~\cite{RasmussenGaussianprocessesmachine2006, Krigestatisticalapproachbasic1951}) of the objective function $f$ using a set of $l$ sampled points in the design domain $\Omega$, known as the \textit{Design of Experiments} (DoE).
The optimal solution is estimated by iteratively enriching a \textit{Gaussian process} (GP)~\cite{RasmussenGaussianprocessesmachine2006,Krigestatisticalapproachbasic1951} via a search strategy that balances the exploration of the design space $\Omega$ and the minimization of the surrogate model of $f$.
Namely, at each iteration of a given BO method, the search strategy requires solving a maximization sub-problem where the objective is referred as the acquisition function~\cite{frazierTutorialBayesianOptimization2018, ShahriariTakingHumanOut2016, WangMaxvalueentropysearch2017,bartoliAdaptiveModelingStrategy2019,tranAphBO2GP3BBudgetedAsynchronouslyparallel2020}.
The acquisition function being fully defined using the GP, the search strategy is computationally inexpensive and straightforward compared to the original optimization problem~\eqref{eq:opt_prob} in which the function $f$ is assumed to be expensive-to-evaluate.
The DoE is updated iteratively using the optimal solutions of the sub-problems.
The same process is repeated until a maximum number of evaluations is reached. %(i.e., the maximal budget). 
The main steps of the BO framework, when applied to solve the optimization problem~\eqref{eq:opt_prob}, are summarized in Algorithm~\ref{alg:BO}.
\begin{algorithm}[ht!]
     \begin{algorithmic}[1]
        \INPUT{: Objective function, initial DoE, a maximum number of iterations max\_nb\_it\;}
        \FOR{$l = 0$ \TO \mbox{max\_nb\_it} - 1}
            \STATE {Build the surrogate model using a GP\;}
            \STATE {Find $\bm{x}^{(l+1)}$ a solution of the enrichment maximization sub-problem\;}
            \STATE {Evaluate the objective function at $\bm{x}^{(l+1)}$\;}
            \STATE {Update the DoE\;}
        \ENDFOR
        \OUTPUT{: The best point found in the DoE\;}
    \end{algorithmic}
    \caption{The Bayesian optimization framework.}
    \label{alg:BO}
\end{algorithm}

In the next two sections, we give more details on the GP and the enrichment process.

\subsection{Gaussian process}
\label{ssec:GP}
In the context of a BO process, a scalar GP~\cite{RasmussenGaussianprocessesmachine2006, Krigestatisticalapproachbasic1951} is a surrogate model whose distribution is fully described by a prior mean function, a covariance kernel and a set of sampled points.
The global behavior of the GP is depicted by the prior mean function whereas the covariance kernel characterizes the similarities between two sampled points of the design space $\Omega$.
Let a non-conditioned scalar GP defined by a prior mean function $\mu: \mathbb{R}^d \mapsto \mathbb{R}$ and a covariance kernel $k: \mathbb{R}^{d \times 2} \mapsto \mathbb{R}$.
A conditioned scalar GP of $f$ by the DoE of $l$ sampled points $\mathcal{D}^{(l)} = \left\{ \x^{(k)}, y^{(k)} \right\}_{k=0,\ldots,l-1}$, where  $\x^{(k)} \in \Omega$ and $y^{(k)} = f\left(\x^{(k)}\right)$, defines a Gaussian distribution  $\mathcal{N} \left( \hat\mu^{(l)}, \left[\hat\sigma^{(l)}\right]^2 \right)$ for each $\x \in \Omega$.
The mean $\hat\mu^{(l)} : \mathbb{R}^d \mapsto \mathbb{R}$ and standard deviation $\hat\sigma^{(l)} : \mathbb{R}^d \mapsto \mathbb{R}$ are expressed as follows:
\begin{gather}
    \label{eq:mmu}
    \hat\mu^{(l)}(\x) =  \mu(\x) + \bm{k}^{(l)}(\x)^\top \left[{\bm{K}^{(l)}}\right]^{-1} \left(\bm{Y}^{(l)} - \bm{\mu}^{(l)}\right), \\
    \label{eq:sigma}
    \hat\sigma^{(l)}(\x) = \left( k(\x,\x) - \bm{k}^{(l)}(\x)^\top \left[{\bm{K}^{(l)}}\right]^{-1} \bm{k}^{(l)}(\x) \right)^{\frac{1}{2}},
\end{gather}
where $\bm{\mu}^{(l)} = \left[\mu\left(\x^{(0)}\right), \ldots, \mu\left(\x^{(l-1)}\right) \right]^\top$ is the prior mean vector computed on the sampled points of $\mathcal{D}^{(l)}$,  \mbox{$\bm{k}^{(l)} = \left[k\left(\x, \x^{(0)}\right), \ldots, k\left( \x, \x^{(l-1)}\right) \right]^\top$} is the covariance vector between $\x$ and the sampled points of $\mathcal{D}^{(l)}$, \linebreak $\bm{K}^{(l)} = \left[k\left(\bm{x}^{(i)},\bm{x}^{(j)}\right)\right]_{i,j=0, \ldots, l-1}$ is the covariance matrix computed on the  $\mathcal{D}^{(l)}$, and $\bm{Y}^{(l)}= \left[y^{(0)}, \ldots, y^{(l-1)}\right]^\top$
is a vector of outputs of $f$.
Note that there is a wide range of prior mean functions and covariance kernels~\cite{duvenaudStructureDiscoveryNonparametric2013} and their selection is very case dependent.
Most of these functions depend on hyper-parameters, denoted by $\bm{\theta}^{(l)} \in \left[\mathbb{R}^+\right]^n$, that need to be estimated to explain the best the DoE of the objective function $f$.
To estimate the hyper-parameters $\bm{\theta}^{(l)}$ of the GP at each iteration, a maximum likelihood estimator is typically used~\cite{gelmanBayesianDataAnalysis2014}.

\subsection{The enrichment sub-problem}

The BO framework combines the information provided by the GP (namely, $\hat\mu^{(l)}$ and $\hat\sigma^{(l)}$) to build the enrichment strategy. The latter is guided by the following maximization sub-problem:
\begin{equation}
    \max\limits_{\x \in \Omega} \alpha^{(l)}(\x),
    \label{eq:iner_opt}
\end{equation}
where $\alpha^{(l)}: \mathbb{R}^d \mapsto \mathbb{R}$ is the acquisition function.
There are numerous acquisition functions in the literature~\cite{frazierTutorialBayesianOptimization2018, ShahriariTakingHumanOut2016, WangMaxvalueentropysearch2017, bartoliAdaptiveModelingStrategy2019}, their choice is essential for the enrichment process.
The \textit{Expected Improvement} (EI)~\cite{JonesEfficientglobaloptimization1998} acquisition function is the most used in BO.
Considering the $l^{\mbox{th}}$ iteration of the BO framework, the expression $\alpha_{EI}^{(l)}$ depends on the $\hat\mu^{(l)}$ and $\hat\sigma^{(l)}$.
For a given point $\x\in \Omega$, if  $\hat\sigma^{(l)}(\x) = 0$, then $\alpha_{EI}^{(l)}(\x)=0$.
Otherwise,
\begin{equation}
    \small
    \alpha_{EI}^{(l)}(\x)=\left(y_{min}^{(l)} - \hat{\mu}^{(l)}(\x)\right) \Phi \left( \frac{y_{min}^{(l)} - \hat{\mu}^{(l)}(\x)}{\hat\sigma^{(l)}(\x)} \right) + \hat\sigma^{(l)}(\x) \phi \left(  \frac{y_{min}^{(l)} - \hat{\mu}^{(l)}(\x)}{\hat\sigma^{(l)}(\x)} \right),
    \label{eq:EI}
\end{equation}
where the functions $\Phi$ and $\phi$ are, respectively, the cumulative distribution function and the probability density function of the standard normal distribution. The current minimum is given by $y_{min}^{(l)} = \min \bm{Y}^{(l)}$.
In this framework, it is possible to tackle problems with non linear constraints~\cite{frazierTutorialBayesianOptimization2018,priemOptimisationBayesienneSous2020,ShahriariTakingHumanOut2016} using different mechanisms with different computational costs.  
However, the classical BO process can not handle high dimensional problem because of the GP model.
Indeed, building a conventional GP in high-dimension can be problematic due to the likelihood maximization step used to estimate the hyper-parameters.
Moreover, classical GPs tend to miss some information in high dimension as the distance between points increase.
In the next section, we propose a solution to help overcome these challenges.