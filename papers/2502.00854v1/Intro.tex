\section{Introduction}

{\color{black} The \textit{Multidisciplinary Design Analysis and Optimization} (MDAO) methodology~\cite{cramerProblemFormulationMultidisciplinary1994} is becoming a crucial pillar in many industries, especially in aircraft design. It considers a set of interacting disciplines required to design an aircraft at the beginning of the design process. For instance, one can tackle the aerodynamics, propulsion, and structural coupling by considering the design variables of these three disciplines. Motivated by the desire to improve the environmental footprint of aviation, new cutting-edge aircraft architectures are being studied to drastically decrease aircraft consumption~\cite{schmollgruber2019multidisciplinary, priemEfficientApplicationBayesian2020a, bartoliAdaptiveModelingStrategy2019, BouhlelEfficientglobaloptimization2018,Mixed_Paul_PLS}.
In this context, it is not desirable to perform MDAO procedures with low-fidelity models developed for classical tube-and-wing aircraft configurations. Aircraft designers often use high-fidelity models, even at the beginning of the process, to accurately assess the performance of the aircraft under consideration. The resulting MDAO procedures are  thus performed on computationally time-consuming tasks to find the best architecture. Furthermore, the disciplines are often blackboxes because of their complexity, meaning that no information (i.e., derivatives) other than the objective function value is available. For this reason, MDAO cannot be completed with classical gradient-based algorithms, for which the finite-difference method would be not adapted (due to the presence of noise) or too costly.  The MDAO problems for aircraft design are computationally expensive, noisy constrained, blackbox optimization problems with a large number of design variables~\cite{bartoliAdaptiveModelingStrategy2019, feliot2016design}. In this setting, evolutionary-based optimization algorithms, for which the number of function evaluations required for optimization is often too large, are not adapted as well~\cite{schmollgruber2019multidisciplinary}. }


In the last two decades, this issue is tackled with \textit{Bayesian Optimization} (BO) framework~\cite{frazierTutorialBayesianOptimization2018,JonesEfficientglobaloptimization1998,MockusBayesianmethodsseeking1975,ShahriariTakingHumanOut2016} relying on iterative enrichments of surrogate models (i.e. a \textit{Gaussian Process} (GP)) to seek for the optimum in a given design space $\Omega \subset \mathbb{R}^d$ where $d \in \mathbb{N}^+$ is the number of design variables. 
{\color{black} BO is particularly well-suited for MDAO due to its reliance on GP for the automatic enrichment of the surrogate model. 
By leveraging the predictions and uncertainties provided by GP, the enrichment process effectively targets promising areas and highly uncertain regions where the optimum may be concealed.}
Because of the characteristics of the aircraft design, like safety constraints and the important number of design variables, the resulting MDAO procedures need specific BO algorithms to be solved.
\textit{Constrained Bayesian Optimization} (CBO)~\cite{frazierTutorialBayesianOptimization2018,gelbartBayesianOptimizationUnknown2014a,ShahriariTakingHumanOut2016,bartoliAdaptiveModelingStrategy2019,YDIOUANE_2023} deals with the constraints whereas \textit{High Dimensional Bayesian Optimization} (HDBO) undertakes the high number of design variables~\cite{erikssonScalableGlobalOptimization2019a,WangBayesianoptimizationbillion2016,WangBatchedHighdimensionalBayesian2018,binoisChoiceLowdimensionalDomain2020,KandasamyHighdimensionalBayesian2015} in these problems. HDBO problems can be mathematically described as follows:
\begin{equation}
    \min\limits_{\x \in \Omega} f(\x),
    \label{eq:opt_prob}
\end{equation}
where $f : \mathbb{R}^d \mapsto \mathbb{R}$ is the objective function, the design space $\Omega = [-1,1]^d$ is a bounded domain and $d \gg 20$ corresponds to  a high number of design variables.

In the context of BO, two approaches are mainly investigated to handle the high number of design variables.
The first one is typically based on a specific adaptation of the GP structure~\cite{BouhlelEfficientglobaloptimization2018,KandasamyHighdimensionalBayesian2015,erikssonScalableConstrainedBayesian2020} to deal with the large number of design variables, e.g., EGO-KPLS~\cite{BouhlelEfficientglobaloptimization2018} where a \textit{partial least squares} (PLS) method is used to reduce the number of the GP hyper-parameters.
The second approach focuses on the use of dimension reduction methods to scale down the design space~\cite{WangBayesianoptimizationbillion2016,WangBatchedHighdimensionalBayesian2018,binoisChoiceLowdimensionalDomain2020}, e.g., REMBO~\cite{WangBayesianoptimizationbillion2016} where a random linear embedding of the initial space is used.
The dimension of the obtained subspace can be hence much lower than the original one.
Most of the methods based on the REMBO paradigm have difficulties particularly to derive the new bounds for the reduced-dimension optimization problem~\cite{WangBatchedHighdimensionalBayesian2018}.
An important computational effort in~\cite{binoisChoiceLowdimensionalDomain2020} is in general needed to complete the optimization.


Two drawbacks of most existing HDBO methods are the computational effort needed to perform the optimization process and the construction of accurate bounds (over the subspace) in which the optimization is performed. 
In this paper, a new HDBO method, named \textit{Efficient Global Optimization coupled with Random and Supervised Embedding} (EGORSE) is introduced to overcome the challenges previously detailed.
First, the standard BO framework is described in Section \ref{sec:BO}.
Then, in Section \ref{sec:EGFORSE}, the proposed methodology is detailed. A sensitivity analysis study with respect to EGORSE hyper-parameters is detailed in Section \ref{sec:sensitivity-anal}. Using academic benchmark problems, a comparison with state-of-art HDBO methods shows the high potential of EGORSE both in terms the efficiency and the global computational effort (see Sections \ref{sec:num} and \ref{sec:rover}). Conclusions and perspectives are drawn in Section \ref{sec:conclusion}.