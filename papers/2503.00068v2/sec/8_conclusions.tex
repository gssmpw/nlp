\section{Conclusion}

In this work, we present a general framework for in-bed human shape estimation with pressure images, bridging from pseudo-label generation to algorithm design. For label generation, we present SMPLify-IB, a low-cost monocular optimization approach to generate SMPL p-GTs for in-bed scenes. By introducing gravity constraints and a lightweight but efficient self-penetration detection module, we regenerate higher-quality SMPL labels for a public dataset TIP. For model design, we introduce PI-HMR, a pressure-based HPS network to predict in-bed motions from pressure sequences. By fusing pressure distribution and spatial priors, accompanied with KD and TTO exploration, PI-HMR outperforms previous methods. Results verify the feasibility of enhancing model's performance by exploiting pressure's nature.


% This work would provide a whole tool-chain and baseline to support the development of in-bed HPS with pressure images and other modalities.


% In this paper, we propose PIMesh, a temporal human shape estimation network to directly generate human meshes from input pressure image sequences that are collected by a pressure-sensing bedsheet. Moreover, to overcome the dataset bottleneck for the human shape estimation task in in-bed scenarios, we present TIP, the first-of-its-kind multi-modal temporal human in-bed pose dataset with multiple human representation labels including posture, 2D joints, and 3D meshes. TIP contains 156K synchronized temporal images from 9 volunteers in three modalities~(RGB, depth, and pressure images). To generate reliable 3D mesh ground truths, we leverage state-of-the-art RGB-based human shape estimators and propose a 3D mesh label generation pipeline for in-bed scenarios. By deploying a SMPLify-based optimizer with strong human-scene penetration penalty terms, our optimized 3D shape ground truths present 25mm joint prediction errors compared with the manually annotated 2D joint ground truths. Finally, PIMesh achieves 79.17mm of MPJPE, 91.01mm of MPVE, and a minimum of 5.8mm/s$^2$ acceleration errors on the TIP dataset. This work provides a privacy-preserving approach to estimating in-bed human meshes in non-line-of-sight environments and demonstrates more potential application scenarios of pressure-sensing bedsheets