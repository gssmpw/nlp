

\section{Experiments}

% \begin{minipage}{\textwidth}
% \begin{minipage}[c]{0.5\textwidth}
% \centering 
%     \begin{tabular}{c|cc}
%     \toprule[2pt]
%     Sampling Method      & MPJPE  & PA-MPJPE \\
%     \midrule[1.4pt]
%     Top 8       &    58.62   &   44.42   \\
%     Top 32      &    57.66   &   43.48   \\
%     Top 128     &    \textbf{57.13}   &   \textbf{42.98}   \\
%     Top 256     &   58.64    &  44.65    \\
%     \bottomrule[2pt]
% \end{tabular}
% \captionof{table}{\textbf{Ablations for the K selection in TopK algorithm.}} \label{tab: ablations for topk}
% \end{minipage}
% \begin{minipage}[c]{0.5\textwidth}
% \centering
%     \begin{tabular}{l|cc}
%     \toprule[2pt]
%     Method      & MPJPE  & PA-MPJPE \\
%     \midrule[1.5pt]
%     w/o. Learnable Masks            &   60.95    &    46.27  \\
%     w/o. Spatial Position Embedding           &   60.65    &   46.28   \\
%     w/o. AttentionPooling            &    59.21   &  45.08    \\
%     \hline
%     All               &    \textbf{57.13}   &  \textbf{42.98}    \\
%     \hline
%     \bottomrule[2pt]
%     \end{tabular}
%     \captionof{table}{\textbf{Ablations for other components in MFF.}} \label{tab: ablations for PI-HMR}
% \end{minipage}
% \end{minipage}

% \begin{table*}[t]
%     % \label{Tab}
%     \begin{subtable}{.33\linewidth}
%     \vspace{0pt}
%     \small
%     \centering
%         \resizebox{!}{1cm}{
%         \begin{tabular}{c|cc}
%         \toprule[2pt]
%         Sampling Mode      & MPJPE  & PA-MPJPE \\
%         \midrule[1.4pt]
%         Top 8       &    58.62   &   44.42   \\
%         Top 32      &    57.66   &   43.48   \\
%         Top 128     &    \textbf{57.13}   &   \textbf{42.98}   \\
%         Top 256     &   58.64    &  44.65    \\
%         \bottomrule[2pt]
%     \end{tabular}
%     }
%     \caption{\textbf{Ablations for the K selection in TopK algorithm.}} \label{tab: ablations for topk}
%     \end{subtable}%
%     \begin{subtable}{.33\linewidth}
%     \vspace{0pt}
%     \small
%     \centering
%       \resizebox{!}{1cm}{
%             \begin{tabular}{l|cc}
%             \toprule[2pt]
%             Method      & MPJPE  & PA-MPJPE \\
%             \midrule[1.5pt]
%             w/o. Learnable Masks            &   60.95    &    46.27  \\
%             w/o. Spatial Position Embedding           &   60.65    &   46.28   \\
%             w/o. AttentionPooling            &    59.21   &  45.08    \\
%             \hline
%             All               &    \textbf{57.13}   &  \textbf{42.98}    \\
%             \hline
%             \bottomrule[2pt]
%             \end{tabular}
%             }
%             \caption{\textbf{Ablations for other components in MFF.}} \label{tab: ablations for PI-HMR}
%     \end{subtable} 
%     \begin{subtable}{.33\linewidth}
%     \vspace{0pt}
%     \centering
%       \small
%       \resizebox{!}{1cm}{
%         \begin{tabular}{ccc|cc} 
%         \toprule[2pt]
%         GT         & Output-KD   & Feat.-KD       & MPJPE  & PA-MPJPE\\
%         \midrule[1.4pt]
%         \checkmark &            &            &  75.06     & 57.97 \\
%         \checkmark & \checkmark &            &   77.86  & 59.41\\
%         \checkmark &            & \checkmark &  67.34     &  52.16 \\
%         \checkmark & \checkmark & \checkmark &  \textbf{66.3}    &  \textbf{52.41}\\
%         \bottomrule[2pt]
%         \end{tabular} 
%         }
%         \caption{\textbf{Ablations for cross-modal KD}. GT, Output-KD, and Feat-KD represent supervision with GTs, CLIFF's outputs, and CLIFF's hidden feature maps, respectively.} \label{tab: ablations_kd} 
%     \end{subtable} 
% \end{table*}


We evaluate PI-HMR on the TIP dataset. Following~\cite{wu2024seeing},  we choose the second-to-last group of each subject as the val. set, the last group of each subject as the test set, and the remains as the training set. For evaluation, We use standard evaluation metrics including MPJPE~(without pelvis alignment), PA-MPJPE, MPVE for shape errors, and Acceleration errors~(ACC-ERR) to evaluate smoothness. The first three metrics are measured in millimeters~($mm$), and the rest are measured in $mm/s^2$.

We compare our model with previous SOTAs and vison-based classic structures, including: HMR~\cite{kanazawa2018end} and HMR-KD (HMR structure with and without cross-modal KD), BodyMap-WS~\cite{tandon2024bodymap}, TCMR~\cite{choi2021beyond}, MPS-NET~\cite{wei2022capturing}, and PI-Mesh~\cite{wu2024seeing}. All methods are re-trained on TIP with our re-generated SMPL p-GTs, and follow the same training setups with PI-HMR. We provide detailed implementation details of these approaches and PI-HMR in Sup. Mat.  

\subsection{Overall Results for PI-HMR} \label{sec:exp_overall_results}
We present quantitative evaluations in~\cref{tab: overall_results}. Our methods outperform all image or sequence-based methods, presenting about 17.01mm MPJPE decrease compared to PI-Mesh and also outperforms SOTA vision-based architecture HMR, TCMR with 15.6mm, 4.91mm MPJPE improvement, while maintaining comparable ACC-ERR compared with SOTA approaches. Moreover, our introduced cross-modal KD and TTO strategy further improve the robustness of PIHMR, bringing 2.33mm and 1.7mm MPJPE improvements compared with basic structure. In particular, the TTO strategy, as an unsupervised, entirely prior-based optimization strategy, demonstrates the effectiveness of learning and refinement based on user habits. We provide visual comparisons between CLIFF, PI-Mesh and PI-HMR in~\cref{fig: overall_vis}. 

\subsection{Ablations for PI-HMR}

In this section, we present various ablation studies to fully explore the best setup of PI-HMR. We select PI-HMR as shorthand to mean PI-HMR + KD, without the TTO routine, as the basic model for evaluation. All models are trained and tested with the same data as PI-HMR. 

\begin{table}[]
\footnotesize
\centering 
\begin{tabular}{cccc|cc}
\toprule[2pt]
GF & LF & SF-P & SF-K & MPJPE & PA-MPJPE\\
\midrule[1.4pt]
% \checkmark   &    &      &      &   57.61  &  \\
%    &  \checkmark  &      &      &      & \\
%    &    &   \checkmark   &      &   80.48  &  \\
%    &    &      &   \checkmark   &   100.73  &  \\
%    &    &   \checkmark   &  \checkmark    & 80.11   &   \\
%  \cline{1-4}
 \checkmark  &  \checkmark  &      &      &   57.84  &  43.18 \\
 \checkmark  &    &  \checkmark    &      &  59.26   &  45.27\\
 \checkmark &    &      &    \checkmark  &   58.31  &  43.92\\
 \checkmark  &    &    \checkmark  &  \checkmark    &  59.03  &  44.45  \\
 \cline{1-4}
 \checkmark  &  \checkmark  &   \checkmark   &      &   62.23  &  44.91 \\
 \checkmark  &  \checkmark  &      &   \checkmark   &   58.48  &  44.27\\
 \checkmark  &   \checkmark &    \checkmark  &  \checkmark    &  \textbf{57.13}  &  \textbf{42.98} \\
\bottomrule[2pt]
\end{tabular}
\caption{\textbf{Ablations for model structures}. GF, LF, SF-P, SF-K are the global features, local features, sampling features from high-pressure areas and joints, respectively.} \label{tab: res_comp_eff}
\end{table}

\textbf{Model Structures.} In~\cref{tab: res_comp_eff}, we summarize the results with different feature combinations in the MFF module. The method that integrates all branches surpasses other setups. Notably, we observe accuracy drops when sampling features are solely sampled from high-pressure areas, without joints. This could be attributed to the model's tendency to focus more on high pressure, neglecting the local distribution in boardline areas and low-pressure regions related with joints, thereby failing due to information ambiguity.

\textbf{Top-K Sampling.} We explore the rational selection K for the high-pressure masks in~\cref{tab: ablations for topk}. With an increase number of sampling points, the model's performance initially improves and then declines when K is 256. This implies that the model seeks a balance in multi-feature fusion: more sampling points entail more abundant contact and contour information and a broader field of perception, but bringing in redundancy and noises.

\textbf{Other Components in MFF.} We also conducted experiments to evaluate three essential modules including AttentionPooling for local features, learnable masks and spatial position embedding in MFF, as shown in~\cref{tab: ablations for PI-HMR}. Our results suggest that these components provide strong priors for supervision and significantly improve the prediction accuracy.

\begin{table}[]
    \small
    \centering
    \begin{tabular}{c|cc}
    \toprule[2pt]
    Sampling Method      & MPJPE  & PA-MPJPE \\
    \midrule[1.4pt]
    Top 8       &    58.62   &   44.42   \\
    Top 32      &    57.66   &   43.48   \\
    Top 128     &    \textbf{57.13}   &   \textbf{42.98}   \\
    Top 256     &   58.64    &  44.65    \\
    %                                            & Random 128  &      &      \\
    % \hline
    % \multirow{3}{*}{Temporal Encoder}           & RNN         &    60.26   &      \\
    %                                             & GRU         &    62.37   &      \\
    %                                             & Transformer &    \textbf{57.13}   &     \\
    \bottomrule[2pt]
\end{tabular}
\caption{\textbf{Ablations for the K selection in TopK algorithm.}} \label{tab: ablations for topk}
\end{table}

% Please add the following required packages to your document preamble:
% \usepackage{multirow}
\begin{table}[] \vspace{-0.08cm}
    \footnotesize
    \centering
    \begin{tabular}{l|cc}
    \toprule[2pt]
    Method      & MPJPE  & PA-MPJPE \\
    \midrule[1.5pt]
    w/o. Learnable Masks            &   60.95    &    46.27  \\
    w/o. Spatial Position Embedding           &   60.65    &   46.28   \\
    w/o. AttentionPooling            &    59.21   &  45.08    \\
    \hline
    All               &    \textbf{57.13}   &  \textbf{42.98}    \\
    \hline
    \bottomrule[2pt]
    \end{tabular}
    \caption{\textbf{Ablations for other components in MFF.}} \label{tab: ablations for PI-HMR}
    \vspace{-0.1cm}
\end{table}





% \begin{figure}[htbp]
%   \centering
%   \includegraphics[width=\linewidth]{images/exp_selection_principle.pdf}
%   \caption{A glimpse of our TIP dataset~(From left to right: RGB, RGB with 2D joints, depth, pressure images, pressure images with 2D joints, 3D shape~(rendering), 3D shape in side view).}
%   \label{fig: exp_selection_principle}
% \end{figure}



% model structure for PI-HMR

% model designs for PI-HMR

    % temporal encoder
    % w/o Atten Pooling
    % W/o mask
    % sampling numbers (random, 8, 32, 128, 256)
    % KD

\textbf{Ablations for KD.} We conduct experiments to evaluate cross-modal KD. \cref{tab: ablations_kd} shows that feature-based transfer plays a pivotal role in enhancing the performance, while CLIFF's results might, to some extent, misguide the learning of HMR, due to domain gaps~(CLIFF's encoder is pre-trained on ImageNet). When both supervisions coexist, HMR could learn the complete cognitive thought-chain of CLIFF, leading to refinement in predictions.

%  表
\begin{table}[] \vspace{-0.08cm}
    \footnotesize
    \centering
    \begin{tabular}{ccc|cc} 
    \toprule[2pt]
    GT         & Output-KD   & Feat.-KD       & MPJPE  & PA-MPJPE\\
    \midrule[1.4pt]
    \checkmark &            &            &  75.06     & 57.97 \\
    \checkmark & \checkmark &            &   77.86  & 59.41\\
    \checkmark &            & \checkmark &  67.34     &  52.16 \\
    \checkmark & \checkmark & \checkmark &  \textbf{66.3}    &  \textbf{52.41}\\
    \bottomrule[2pt]
    \end{tabular} 
    \caption{\textbf{Ablations for cross-modal KD}. GT, Output-KD, and Feat-KD represent supervision with GTs, CLIFF's outputs, and CLIFF's hidden feature maps, respectively.} \label{tab: ablations_kd} \vspace{-0.08cm}
\end{table} 

\subsection{Results for SMPLify-IB} \label{subsec:exp_re_SIB} 
% \small
\begin{table}[t]
    \footnotesize
    \centering
    \begin{tabular}{l||cc}
    \toprule[2pt]
        ~ & 2D MPJPE & Limb height \\ \midrule[1.4pt]
        CLIFF & 25.20 & - \\ \hline
        TIP & 14.02 & 142.84  \\ \hline
        SMPLify-IB & \textbf{9.65} & \textbf{66.68}  \\ 
    \bottomrule[2pt]
    \end{tabular}
    \caption{\textbf{Qualitative results for SMPLify-IB, compared with the p-GTs in TIP, and CLIFF's outputs}. We calculate the 2D projection errors~(in pixels), and the average height of limbs marked as stationary relative to the bed.} \label{tab:results_dataset}
\end{table}
\cref{tab:results_dataset} provides the evaluation of p-GTs generated by SMPLify-IB. Besides the 2D projection errors and acceleration metrics, we introduce the static limb height as an objective assessment of our refinement in implausible limb lifts. Given the prevalence of limbs placed on other body parts within TIP, this metric can only serve as a rough estimate under limited self-penetration premise. We provide visual results in the Sup. Mat. to present our enhancements.

\begin{table}[t] \vspace{-0.08cm}
    \footnotesize
    \centering
    \begin{tabular}{l||cccc}
    \toprule[2pt]
        ~ & recall & precision & accuracy & time  \\ \midrule[1.4pt]
        SMPLify-XMC & 100\% & 100\% & 100\% & 22.62s  \\ \hline
        Ours & 70.93\% & 80.64\% & 98.32\% & 0.42s  \\ \hline
        Ours (ds 1/3) & 65.66\% & 73.59\% & 98.03\% & 0.036s  \\ 
    \bottomrule[2pt]
    \end{tabular}
    \caption{\textbf{Comparisons between our penetration detection algorithm with SMPLify-XMC.} Time means time consumption in an iteration when deploying detection algorithms in our optimization. 'ds 1/3' means downsample SMPL vertices to their 1/3 scales. } \label{tab: res_detection}
\end{table}

We use SMPLify-XMC's detection results as the GTs and conduct comparison experiments to evaluate our light-weight self-penetration detection algorithm in~\cref{tab: res_detection}. The experiment run on the first group of the TIP dataset. For each batch with 128 images, we integrate both detection algorithms in our optimization routine, record the runtime for each iteration~(1000 iterations for a batch) and calculate the accuracy, precision, and recall of the detection. Compared with SMPLify-XMC, our detection module achieves 53.9 times faster while maintaining a detection accuracy of 98.32\%. We also implement a more lightweight version by downsampling the SMPL vertices into their 1/3 scale. The downsampled version further yields a more than tenfold increase in speed, accompanied by limited precision decrease. 

% \begin{figure}[t]
%   \centering
%   \includegraphics[width=\linewidth]{images/ib_on_slp_1.pdf}
%   \caption{\textbf{Visualizations of SMPLify-IB on SLP.}} 
%   \label{fig: ib_slp}
% \end{figure}

% We also implemented SMPLify-IB on the SLP dataset. Results show the 2D MPJPE drops from 37.6 to 6.9 pixels compared to CLIFF's outputs. \cref{fig: ib_slp} shows our pros in alleviating depth ambiguity.
% 

% 附录

% TTO VQ-VAE隐向量重建结果