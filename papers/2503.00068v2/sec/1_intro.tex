\section{Introduction}

Long-term and automatic in-bed monitoring draws increasing attention in recent years for the growing need in heathcare, such as sleep studies~\cite{chang2018sleepguard}, bedsore prevention~\cite{yousefi2011bed}, and detection of bed-exit and fall events~\cite{hoque2010monitoring}. The advancement of parameterized human representation~(\eg SMPL~\cite{loper2023smpl}) and human pose and shape estimation~(HPS) technologies further furnish technical underpinning for the reconstruction and visualization of patient motions, facilitating caregivers to comprehend patients' behavioral patterns in time. However, vision-based techniques, trained on in-lab or in-wild public datasets, fail in in-bed scenarios for more challenges are raised like poor illumination, occlusion by blankets, domain gaps with existing datasets~(\eg 3DPW~\cite{von2018recovering}), and privacy issues in both at-home or ICUs.

Our intuition lies in that tactile serves as a crucial medium for human perception of the surroundings. Especially for in-bed scenarios, lying postures prompt full engagement between humans and environment; simultaneously, this tactile perception also encompasses valuable information about their physiques. Reconstructing human motions from this tactile feedback might provide a privacy-preserving solution to automatic in-bed management for patients and elders. Thus, many efforts have been devoted to capturing the contact pressure with a pressure-sensing bedsheet, which integrates a pressure-sensitive sensor array and collects matrix-formatted pressure distribution~(named pressure images), and exploring potentials of full-body human reconstruction from these tactile sensors~\cite{clever20183d, clever2020bodies, tandon2024bodymap}. However, current methods are often constrained by model design, dataset diversity and label quality. The limitations can be categorized into three points: 

(1) \textbf{Lack of explorations on the pressure nature}. Despite both RGB and pressure images sharing similar structures, the meaning of each pixel differs significantly. For visual images, both foreground and background pixels are non-trivial, conveying texture and semantics. Nonetheless, with single-channel pressure data, regions lacking applied pressure are denoted as zeros, resulting in a dearth of semantic cues regarding the background. Furthermore, the relationship between pressure contours and human shapes introduces information ambiguity~\cite{tandon2024bodymap, yin2022multimodal} when some crucial joints do not directly interact with sensors. Previous research~\cite{clever2020bodies, tandon2024bodymap} attempted to estimate pressure based on the penetration depth of the human model and contact surfaces, thereby explicitly introducing pressure supervision. However, due to limitations in SMPL vertices granularity, sensor resolution, and tissue deformation, SMPL struggles to describe the contact mode with outsides, thus potentially impairing model performance. Consequently, hasty adoption of visual pipelines, without tailored design for pressure characteristics, might restrict model performance.

(2) \textbf{Limited data diversity}. Data diversity implicates models' generalization to unseen situations. For vision-based HPS tasks, the flourishing of HPS community is contributed by large-scale general~(\eg ImageNet~\cite{deng2009imagenet}) or task-specific~(\eg AMASS~\cite{mahmood2019amass}) datasets and mass of unlabeled data from Internet. However, as a human-centric and sensor-based task, in addition to the SLP~\cite{liu2022simultaneously} dataset that contains data from 102 individuals, most in-bed pressure datasets include fewer than 20 participants. Furthermore, the disparities of the sensor scale and performance across different studies, making it challenging to integrate these datasets, thus leading to poor performance to out-of-distribution users or motions. Therefore, how to learn priors across datasets and modalities is of paramount significance.


% large-scale datasets like ImageNet~\cite{deng2009imagenet} play as the core foundation of the robustness of feature encoders, while small ones~(\eg AMASS~\cite{mahmood2019amass} and 3DPW~\cite{von2018recovering}) and mass of unlabeled data from Internet provide strong priors of human shapes and motions. All factors have contributed to the flourishing of the current HPS community

% However, as a human-centric and sensor-based task, in addition to the SLP~\cite{liu2022simultaneously} dataset that contains data from 102 individuals, most in-bed pressure datasets include fewer than 20 participants. Furthermore, the disparities of the sensor scale and performance across different studies, making it challenging to integrate these datasets, thus leading to poor performance to out-of-distribution users or motions. Therefore, how to learn priors across datasets, and even modalities is of paramount significance.

(3) \textbf{Limited 3D label quality}. One main factor limiting the data diversity is the challenge of acquiring accurate 3D labels, especially for an in-bed setting. Currently, only SLP~\cite{liu2022simultaneously} and TIP~\cite{wu2024seeing} datasets offer both SMPL pseudo-ground truth~(p-GTs) and RGB images, with annotations in TIP being seriously doubted by depth ambiguity and penetrations due to monocular SMPLify-based optimization~(in~\cref{fig: dataset_vis}). Limited label quality might lead the model to misinterpret pressure cues, thus calling for a low-cost and accurate label annotation approach for in-bed scenes.

To tackle aforesaid disparities, in this work, we present a general framework bridging from annotations, model design and evaluation for pressure-based in-bed HPS tasks. Concretely, we firstly present PI-HMR, a pressure-based in-bed human shape estimation network to predict human motions from pressure sequences, as a preliminary exploration to utilize pressure characteristics. Our core philosophy falls that both joint positions and contours of high-pressure areas are essential to sense pressure distribution and its variation patterns from the redundant zero-value backgrounds. Thus, we achieve this by explicitly introducing these semantic cues, compelling the model to focus on core regions by feature sampling. Furthermore, considering that the sensing mattress is often fixed in the environment, we leverage these positional priors and feed them into the model to learn the spatial relationship between humans and sensors. Experiments show that PI-HMR brings 17.01mm MPJPE decrease compared to PI-Mesh~\cite{wu2024seeing} and outperforms vision-based temporal SOTA architecture TCMR~\cite{choi2021beyond}~(re-trained on pressure images) with 4.91mm MPJPE improvement.

Moreover, to further expand prior distribution within limited pressure datasets, we realize (1) a Knowledge Distillation~(KD)~\cite{hinton2015distilling} framework to pre-train PI-HMR's encoder with RGB-based SOTA method CLIFF~\cite{li2022cliff}, to facilitate cross-modal body and motion priors transfer; and (2) a pre-trained VQ-VAE~\cite{van2017neural} network as in-bed motion priors in a unsupervised Test-Time Optimization to alleviate information ambiguity. Experiments show that both modules bring 2.33mm and 1.7mm MPJPE decrease, respectively.

Finally, for a low-cost but efficient label annotation method tailored for in-bed scenes, we present a monocular optimization approach, SMPLify-IB. It incorporates a gravity-constraint term to address depth ambiguity issues in in-bed scenes, and integrates a potential-based penalty term with a lightweight self-contact detection module to alleviate limb penetrations. We re-generated 3D p-GTs in the TIP~\cite{wu2024seeing} dataset and results show that SMPLify-IB not only provides higher-quality annotations but also mitigates implausible limb lifts. This suggests the feasibility of addressing depth ambiguity issues with physical constraints in specific scenarios. Besides, results prove that our detection module is 53.9 times faster than SMPLify-XMC~\cite{muller2021self} while achieving 98.32\% detection accuracy. 

We highlight our key contributions: (1) a general framework for pressure-based in-bed human shape estimation task, spanning from label generation to algorithm design. (2) PI-HMR, a temporal network to directly predict 3D meshes from in-bed pressure image sequences and outperforms both SOTA pressure-based and vision-field architectures. (3) SMPLify-IB, a gravity-based optimization technique to generate reliable SMPL p-GTs for monocular in-bed scenes. Based on SMPLify-IB, we re-generate 3D annotations for a public dataset, TIP, providing higher-quality SMPL p-GTs and mitigating implausible limb lifts due to depth ambiguity. (4) We explore the feasibility of prior expansion with knowledge distillation and TTO strategy.  
