\section{Collberg, Thomborson, and Low}

In 1997 and 1998 Collberg, Thomborson, and Low (CTL) proposed three criteria to evaluate obfuscating transformations~\cite{collberg1997taxonomy,collberg1998manufacturing}.

\subsection{Definitions}

\subsubsection{Potency}
In 1997, CTL~\cite{collberg1997taxonomy} introduced the term potency to denote the degree to which an obfuscation confuses a \emph{human} reader trying to understand a given program, i.e., to quantify how the obfuscated program is more obscure, complex, or unreadable than the original program. They defined the potency that is obtained on a given program as
the ratio between a complexity metric computed on that program after and before the obfuscation~\cite{collberg1997taxonomy}.

\if false
follows~\cite{collberg1997taxonomy}:
\begin{quote}
  Let $\mathcal{T}$ be a behavior-conserving transformation such that $P \overset{\mathcal{T}}{\rightarrow} P'$ transforms a source program $P$ into a target program $P'$. Let $E(P)$ be the complexity of P, as defined by one of the metrics [...].

  $\mathcal{T}_{\text{pot}}(P)$, the \emph{potency} of $\mathcal{T}$ with respect to a program $P$, is a measure of the extent to which $\mathcal{T}$ changes the complexity of $P$. It is defined as
  $$\mathcal{T}_{\text{pot}}(P) \defeq E(P')/E(P)-1.$$ 
$\mathcal{T}$ is a \emph{potent obfuscating transformation} if $\mathcal{T}(P)>0$.
\end{quote}
\fi

They proposed considering software complexity metrics such as program length~\cite{halstead}, cyclomatic complexity~\cite{mccabe1976}, nesting complexity~\cite{harrison1981}, data flow complexity~\cite{oviedo80}, fan-in/out complexity~\cite{flow_metrics}, data structure complexity~\cite{munson1993}, and OO Metric~\cite{OO-metric}. CTL then derived and suggested that obfuscations should aim to directly impact these metrics, by increasing program size and introducing new classes and methods, by introducing new predicates and increasing nesting levels of conditional and looping constructs, etc.~\cite{collberg1997taxonomy}.

In line with the suggestion, various other complexity metrics have been used in SP research since then, such as QMOOD understandability~\cite{Foket14,qmood}. Various more advanced forms of complexity metrics have been proposed, some of which are specific for evaluating obfuscations, e.g., based on entropy~\cite{entropy_metric}, others more general, such as the cost of mental simulation~\cite{mental_metrics}.
Several authors have later revisited the idea of combining many different metrics~\cite{anckaert,D4.06}.

\subsubsection{Resilience}
\label{sec:resilience}
CTL observed that it is trivial to increase potency in ways that will not confuse a human reader, e.g., by injecting code that can immediately be identified as dead. They then presented the additional quality criterion of \emph{resilience} to differentiate useless transformations and useless impacts on complexity metrics from useful ones. In their proposal~\cite{collberg1997taxonomy}, resilience ``measures how well a transformation holds under attack from an automatic deobfuscator.'' 

It does so in terms of two measures. The \emph{programmer effort} is ``the amount of time required to construct an automatic deobfuscator that is able to effectively reduce [the obfuscation's] potency.'' The \emph{deobfuscator effort} is ``the execution time and space required by such an automatic deobfuscator to effectively reduce [the obfuscation's] potency.'' They scaled programmer effort in terms of the scope of the analyses and transformations underlying the deobfuscator, which can be local, global, interprocedural, or interprocess. The deobfuscator effort is based on the computational complexity of the underlying analysis: polynomial or exponential. Based on these properties, resilience is measured on a scale of \emph{trivial} to \emph{full}, plus the level \emph{one-way} that was based on the then realistic assumption that some information about the original program can never be recovered from the obfuscated program, such as identifiers names (of variables, classes, functions, etc.) and code layout.

\subsubsection{Stealth}
Although resilient transformations may not be susceptible to attacks by automated deobfuscation, they may still be susceptible to attacks by humans. In 1998, CTL~\cite{collberg1998manufacturing} hence added the \emph{stealth} criterion, which denoted ``How well does obfuscated code blend in with the original code?'' They initially did not formalize this criterion beyond stating that obfuscated code should resemble original code as much as possible, pointing out that stealth obviously is a highly context-sensitive metric. For example, they argued that graph-based opaque predicates will be stealthy in many Java programs as those often involve pointer-rich data structures. % (that is, data structures implemented with pointers in languages with pointers, such as C).

\subsubsection{Cost}
Finally, CTL argued that the impact of obfuscations on execution time and space should be assessed~\cite{collberg1997taxonomy}. Like stealth, \emph{cost} is a context-sensitive metric: injecting code into an inner loop or at the topmost program level will have a radically different impact. 

\subsection{Critique}
\label{sec:9798-critiques}
CTL's definitions of potency, resilience, and stealth do not satisfy. 

\subsubsection{Complexity Metrics Unfit for Obfuscated Code}
\label{sec:unfit_complexity_metrics}
The validity of software complexity metrics for code comprehension is questionable. Feitelson argues that most metrics are based on intuition instead of systematic empirical validation and that they fail to adequately quantify comprehension difficulty~\cite{feitelson}. The most popular metrics of code length and cyclometic complexity do not capture that the code reader's prior experience and background knowledge also contribute significantly~\cite{halstead,mccabe1976,code_metrics}. Other metrics such as cognitive functional size~\cite{cognitive_functional_size} do take into account how the human brain perceives different code structures and patterns, but only to a limited extent. If complexity metrics to model comprehension difficulty of regular software are already contested, expanding their use to assess the potency on obfuscated code is even more controversial. With their observation that the proposed metrics can trivially be increased with transformations that lack any utility as obfuscations, CTL themselves admit that complexity metrics cannot be reused as is for assessing the qualities of obfuscated code. 

When Foket et al.~\cite{Foket14} used validated complexity metrics for object-oriented software, they had to admit that their use was problematic. Additional qualitative analysis was needed to ensure that the quantitative metrics results were correctly interpreted and to avoid drawing invalid conclusions. 

Feitelson also assessed the importance of meaningful variable names for program comprehension~\cite{feitelson}, and found that their impact on comprehension difficulty varies from program to program. In obfuscated code, one should not expect to find meaningful variable names, at least not without using machine learning techniques to reconstruct them~\cite{2017_recovering_clear_natural_identifiers_from_obfuscated_js_names,banerjee2021variablerecoverydecompiledbinary}. This difference alone puts in doubt whether software complexity metrics developed on regular software can be reused as is for obfuscated code.  


\subsubsection{Unclear How to Compute Complexity Metrics}
\label{sec:unclear_computations}
The definition of potency does not specify which software fragments to measure.  

First, the definition is vague about the program representation on which to compute the complexity metrics. Should one use ground-truth representations from the forward engineering process (e.g., source code, IR code used in a compiler, assembly code, binary code with full symbol and relocation information) or representations built during the reverse engineering process (e.g., IR code built by a disassembler, IR obtained by code lifting, or source code obtained after decompilation)? Which representations are more relevant: the ones being transformed to deploy the obfuscations, or the ones on which adversaries might get their hands?

For managed languages such as Java, this question might not be that important. The semantic gap between the Java source code and the distributed bytecode is relatively small~\cite{batchelder2007obfuscating} and a representation to compute metrics on (such as a call graph and method CFGs) can be built mechanistically from the distributed bytecode. 
For stripped binaries, the reconstruction of a suitable representation is much more complex. For example, when control flow and design obfuscations such as those by Van den Broeck et al.~\cite{jens21} are deployed, the difference between what the obfuscator knows to be the functions and what the disassembler thinks to be the possible functions is huge. Each disassembler, possibly even each version, configuration, and customization by means of scripts or plug-ins will yield different CFGs and different functions. In other words, there is no one representation on which attackers can get their hands. Even if all disassemblers would behave the same, do you compute the control complexity metrics on the assembly code, on the low-level IR lifted from the assembly, on the high-level IR built on top, or on the decompiled source code? These are open questions. Some work even skips disassembly and decompilation entirely, e.g., by interpreting executable files as bitstreams and then applying image processing machine learning techniques on those bitstreams to classify malware~\cite{ni2018malware,marastoni2021data} and to classify used obfuscations~\cite{secrypt21}.

Secondly, on what part of the software should the metrics be computed? Although adversaries might initially not know which part to study, they have many ways to zoom in on the most relevant parts, thus only requiring deeper study of parts of the program. But which parts exactly? And what about the parts they prune from their search space? Obfuscation can be useful in hindering that pruning~\cite{coppens2013feedback,reganoL2P}, rather than in hindering the understanding of the code that actually embeds the assets the adversaries are after. On which parts of the code should the metrics then be computed?

\subsubsection{Fuzzy and Confusing Boundary between Automated and Human Analysis}
\label{sec:fuzzy_boundary}
The definitions by CTL attempt to make a clear separation between automated analysis and deobfuscation on the one hand and human analysis on the other. We think this is not warranted. In practice, reverse engineers often make use of interactive tools that mix automated and human analysis, such as interactive disassemblers and decompilers of which the built-in heuristics can be overridden on demand by their users. Moreover, they always perform their manual tasks on data produced by automated tools: No one starts studying the bits of a binary executable manually. There is ample evidence for this in the literature~\cite{emse2019,Sutherland2006,Votipka2019,practice_malware,desutter2024evaluation}.

Moreover, by binding automation to deobfuscation in the term resilience and by binding human activities to confusion in potency, CTL beg the question of where to place automated attacks that do not deobfuscate code, such as automatic secret extraction attacks~\cite{khunt++,banescu15}. Banescu et al.\ use the term resilience to denote the impact of SPs on the time that symbolic execution engines need to extract a secret~\cite{banescu15,2017_predicting_the_resilience_of_obfuscated_code_against_symbolic_execution_attacks_via_machine_learning}, even though these engines make no attempt at producing deobfuscated code. This is a clear example of how hard it is to use CTL's terms resilience and potency consistently. 

\subsubsection{Tool Availability and Sharing over Time}
\label{sec:tool_availability}
The dependence of resilience on programmer effort neglects that once someone publishes an analysis tool or deobfuscator, everyone can reuse it. This certainly has an impact on the practical value of obfuscations. For example, in experiments with professional pen testers~\cite{emse2019}, it mattered a lot to them that QEMU was not able to correctly simulate binaries with anti-debugging~\cite{abrath2016tightly}, and that valgrind had to be adapted to support trace sizes beyond 2 GiB. 

Tool availability raises an interesting question for academics that can be illustrated with a well-known example: Intel's Pin instrumentation tool only works on the x86 architectures, with no similar tool being available for ARM these days. Then does that mean that dynamic analysis of ARM code is fundamentally harder than dynamic analysis of x86? For an academic studying reverse engineering, that seems intuitively wrong, even though, for a practicing reverse engineer, it may be actually true.

\subsubsection{Narrow Definition of Programmer Effort}
Using only one dimension to estimate the effort required to program an analysis is flawed. In addition to the scope, at least the sensitivity~\cite{path-sensitive} and polyvariance~\cite{polyvariance} of the analysis should also be considered.  However, it is not clear whether more precise analyses are always more difficult to implement than less precise ones. It is hence not clear how to rank different forms of precision in terms of programmer effort. Then again, if a framework were available to instantiate various forms (i.e., different scopes and different sensitivities) of a custom analysis with a simple configuration, the programmer effort would no longer be dependent on them. 
   
\subsubsection{Narrow Scope of Deobfuscation}
Resilience was defined in terms of deobfuscation, meaning ``returning the obfuscated code into a form that is as easily understandable as the original source''. Pure deobfuscation is rarely used in practice. Instead, adversaries often try to bypass SPs and work around them~\cite{emse2019}.

Moreover, the local, global, and interprocedural programmer effort levels proposed by CTL~\cite{collberg1997taxonomy} are strongly biased toward static analyses and static program representations such as call graphs and CFGs, as opposed to dynamic representations such as traces that are also used for dynamic deobfuscation~\cite{generic_deobfuscation,mariano24}. Should we hence not use other aspects to rate the effort required to obtain dynamic information with a certain precision? Some dynamic approaches, such as the bit-level tracking by Yadegari et al.~\cite{bitleveltaint}, are clearly more complex to implement and execute than the simpler taint-tracking approaches proposed by Faingnaert et al.~\cite{khunt++} or the alternative from Li et al.~\cite{khunt}, so it seems that a more flexible scheme is necessary to rate deobfuscation techniques.

\subsubsection{Asset and Attack Goal Independence}
The definitions of potency and resilience are asset independent. They qualify and quantify how confusing obfuscations are, in general, for human readers, and how susceptible they are to an adversary's countermeasures. Their formulation does not take into account that adversaries aim to violate specific security requirements on specific assets, such as the confidentiality or integrity of specific code fragments. 

The literature is clear on the fact that for assessing the strength of obfuscations, both the adversary's goal and the deployed software analysis methods need to be considered. Schrittwieser et al.\ distinguish four different goals: finding the location of data, finding the location of program functionality, extraction of code fragments, and understanding the program~\cite{survey2016}. The latter can be interpreted broadly. For example, determining invariants of a program, determining preconditions for the execution of some fragment, or obtaining concise summaries of its functionality can all be considered program understanding goals. Schrittwieser et al.\ also distinguish four classes of software analysis methods that obfuscations might aim to mitigate: pattern matching, automatic static analysis, automatic dynamic analysis, and human analysis. While one could argue that different software metrics should be used depending on the type of assets to be protected and on the considered attack goals and used analysis methods, as has been done in the past~\cite{anckaert}, it is all but clear which complexity metrics to use when.

Furthermore, the proposed code artificiality metric for stealth only is applicable in the face of specific attacks, namely those considering n-grams or related syntactical code properties, but meaningless for other code and data location finding attacks. 

\subsubsection{Layering is Missing in Action}
\label{sec:layering_missing}
Nowhere do CTL's definitions stress the need to evaluate the marginal strength of obfuscations when they are composed and layered on top of each other, despite the fact that layering obfuscations is the best practice~\cite{layering,collbergbook,recipes}.

Because the obfuscation (singular) being evaluated could consist of a composition of multiple transformations (plural), the definitions by CTL support layering and compositions and are technically fine. 
However, to help the community, we do think that the concepts of layering and composability need to be put forward explicitly, and potential pitfalls or consequences deserve to be discussed, if only because layering increases the relevance of other critiques, such as those discussed in Section~\ref{sec:unclear_computations}. 
When only one obfuscation deployed in isolation is being evaluated, the semantic gap between the different representations on which defenders and attackers can compute the relevant metrics might be small enough that we do not need to worry about which representation to compute it. But once obfuscations are composed, the semantic gap can grow quickly and the question of how to compute the metrics becomes much more difficult again. De Sutter et al.\ discuss this in more detail where they observe the lack of layered SP evaluation in research~\cite{desutter2024evaluation}.

\subsubsection{Machine Learning Changed the Nature of the Game}
The concept of one-way resilience no longer applies in this day and age of machine learning as it did in the previous millennium. Even if machine learning techniques offer no guarantee of reconstructing the original identifier names or the original code layout, they have been proven capable of reconstructing meaningful, useful names and layouts that help human reverse engineers~\cite{2017_recovering_clear_natural_identifiers_from_obfuscated_js_names,banerjee2021variablerecoverydecompiledbinary}. However, one-way resilience might still be meaningful when obfuscations rely on one-way functions, such as hash functions~\cite{hash1,hash2}.

\subsubsection{Lack of Sensitivity}
\label{sec:sensitivity_missing}
CTL neglect the sensitivity of potency, resilience, and stealth with respect to features of the program being obfuscated. An example of an obfuscation that can be highly sensitive to (local) program features is the source-level injection of mixed Boolean arithmetic expressions that compute constant values~\cite{mba}. If the variables used in the expressions happen to have constant values, or are uninitialized, compilers can optimize away (part of) the obfuscation.\footnote{%One might argue that if an optimizing compiler can undo an obfuscation, it probably was not a strong one. This is not a valid reasoning, however. 
Source code gives compilers much richer information than adversaries get from a binary. The fact that a compiler can deduce some property hence does not imply an adversary can do so, i.e., that the obfuscation fails to hide the property for an adversary.} Another example is bogus control flow and bogus code inserted by means of, e.g., opaque predicates. The effect on complexity there depends entirely on which data dependencies and which control dependencies happen to be impacted by the bogus code. In general, combining obfuscation with program optimization is known to be a difficult problem~\cite{optimization}.

This sensitivity is an issue for at least two practical reasons. First, if the impact of an obfuscation is sensitive to features of the program being obfuscated, a mechanism is needed to assess that impact every time the obfuscation is considered as a candidate for deployment. Predictive techniques or actual measurements can be used for this. The latter is not really feasible, however, given the large design space that needs to be explored~\cite{Basile23}, and the former has significant limitations today~\cite{reganoMetric}. Secondly, programs evolve over time. So even when users of an obfuscation tool have somehow obtained a suitable composition of obfuscations for their software v1.0, if that composition is sensitive to program features, they will need to reassess its suitability for later versions. Clearly, the user-friendliness of obfuscators and/or their need to include predictive capabilities depends on the sensitivity of the supported obfuscations with respect to program features. 

CTL also neglect the sensitivity of an obfuscation to its configuration parameters. If an obfuscation's impact is sensitive to them, this again impacts the user-friendliness of obfuscators and the need to include prediction mechanisms, because the parameters will need to be optimized. One could argue that if two configurations of some obfuscation have significantly different impacts, then they should be treated as two different obfuscations. Although documenting obfuscations as such may make an obfuscation tool more transparent, it does not make the obfuscation selection and optimization problems any easier. For these reasons, the sensitivity of obfuscations should be considered a prime quality criterion. 

\subsubsection{Learnability Neglected}
\label{sec:learnability_missing}
Defining stealth as the artificiality of transformed code compared to original code neglects that adversaries can learn to single out obfuscated fragments even if they are similar to original code. If an obfuscation is implemented with exactly the same instruction sequence every time it is deployed, it does not matter that this sequence also occurs a few times in the original code: Pattern matchers will quickly achieve 100\% recall.
