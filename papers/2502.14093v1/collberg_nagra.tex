\section{Nagra and Collberg}
In 2009, Nagra and Collberg (NC) redefined potency and stealth~\cite{collbergbook}.

\subsection{Updated Definitions}
\label{sec:collberg_nagra_def}
NC now defined potency in relation to a program's property that some adversary might try to reveal, and in relation to analyses that can be used to reveal that property. First, they paraphrased the meaning of an \emph{effective obfuscating transformation} as one that ``makes it harder to perform the necessary analyses that reveal the secret property on the obfuscated program than it is on the original.''

Given a specific program, a specific property thereof, and some specific analysis that can reveal that property on the original program, an obfuscation is considered \emph{effective} if the analysis can no longer reveal an equivalent property on the obfuscated program or requires more resources to do so. The obfuscation is considered \emph{ineffective} if the analysis can still reveal an equivalent property using the same amount of resources and \emph{defective} if the analysis can reveal an equivalent property using less resources. 

In their definition, the term ``equivalent'' $\approx$ was not defined formally. Although in many cases an adversary aims for revealing a property exactly, NC argued that there can also be cases in which an adversary is happy with an approximation. Scenarios in which approximation may suffice include data or code localization attacks, in which it can suffice if a tool prunes most of the search space that the attacker has to explore manually, or cryptographic key extraction, in which it can suffice if an analysis tool can severely prune the search space for a brute-force attack. 

The analysis considered in the definition need not necessarily be a single analysis. It can in fact be a sequence of analyses and (deobfuscating) transformations; such as when analyses reveal properties that are useful to deobfuscate the code, and the property ultimately targeted by the adversary is the deobfuscated code. 

Based on the above definition, NC then defined \emph{potent obfuscating transformations} in terms of a specific program, a specific property, and a \emph{set of analyses}. An obfuscation is \emph{potent} if it is effective against at least one of the analyses and not defective against any of them: ``a potent obfuscating transformation makes at least one analysis harder to perform, and no analyses easier.''

NC omitted resilience as a separate, complementary quality criterion. The reason is, of course, that the above redefinition of potency already incorporates the original concept of resilience.

For stealth, NC distinguish between \emph{local stealth} and \emph{steganographic stealth}~\cite{collbergbook}. A transformation is steganographically stealthy if an adversary's detector function cannot determine if a program has been transformed with it or not. A transformation is locally stealthy if the adversary's locator function cannot tell the locations where the transformation has been applied.

Formally, they propose to define the local/steganographic stealth of an obfuscation with respect to a considered class of programs and a considered locator/detector function as the maximum of the expected false positive rate and the expected false negative rate of that function over all programs in the class after obfuscation. 

With respect to detector and locator functions, there exists quite a bit of research on automatic techniques for the classification of software as obfuscated versus unobfuscated and for the automatic determination of the deployed obfuscations and obfuscators. Such techniques are invariably based on the observation of software features that form fingerprints of obfuscations whose presence can be considered as indicators of (a lack of) stealth~\cite{obfuscation_detection}.

Schrittwieser et al.~\cite{modeling_stealth} used complexity metrics as fingerprints. Raubitzek et al.~\cite{obfuscation_detection4} convert binary code bytes to grayscale values and use singular value decomposition to uncover patterns created by different obfuscation techniques in images. Jiang et al.~\cite{obfuscation_detection2} use the number of different types of instructions in basic blocks and a basic block adjacency matrix of function control flow graphs as features, as well as the number of string constants in basic blocks. Bacci et al.~\cite{obfuscation_detection3} and Wang and Rountev~\cite{obfuscation_detection5} use strings and bytecode n-grams as features. Kim et al.~\cite{obfuscation_detection6} use opcode distribution. Tofighi-Shirazi et al.~\cite{obfuscation_detection7} obtain symbolic expressions from disassembled function bodies through symbolic execution and then use the words in them and their frequencies as features in a bag-of-words approach. Tian et al.~\cite{obfuscation_recognition} represent functions by their so-called reduced shortest paths. Zhao et al.~\cite{obfuscation_detection8} use assembly instruction embeddings based on skip-grams, convolutional neural networks (CNNs) to generate basic block embeddings from the instruction embeddings, and long-short-term memory networks (LSTM) to encode the semantics of basic blocks and their relations into features. Kanzaki, Monden, and Collberg proposed a code artificiality metric based on an N-gram instructions model~\cite{code_artificiality}.

These features are all used in classifiers, of which the models serve to quantify stealth in the sense that an obfuscation can be considered more stealthy if the models perform more poorly on it. 

\subsection{Critique}
\label{sec:2009-critiques}
The redefinition of potency answered many of the critiques from Section~\ref{sec:9798-critiques}. However, it still lacks in numerous ways. Some critiques still apply, such as those on layering (\ref{sec:layering_missing}), sensitivity (\ref{sec:sensitivity_missing}), and learnability (\ref{sec:learnability_missing}). Additional critiques are the following. 

\subsubsection{All Analyses Treated Equally}
\label{sec:all_equal}
In the definition of a potent obfuscation, the characteristics of the analyses against which it must be effective and must not be defective are not considered. Suppose that an obfuscation is defective with respect to one analysis because it decreases its computation time on a program from 10s to 5s, while being effective for another analysis because it increases that analysis' computation time from 2s to 8s. If the adversary has both analyses available, their minimal execution time increased from 2s to 5s with the obfuscation; their combined time increased from 12s to 13s. So should that be considered a potent obfuscating transformation? According to the current definition, it is not. 

The new definition of potent transformations implicitly treats all considered analyses equally important to mitigate, as if attackers have an oracle at their disposal that tells them which of all potentially useful analyses they should use given a concrete program they need to analyze. This worst-case scenario assumption can definitely be relevant in a risk management approach~\cite{Basile23} to ensure that potentially relevant attack strategies are not overlooked. However, for evaluating the practical strength of obfuscations, one clearly needs to consider which analyses adversaries are more likely to deploy. 
To some extent, this relates to stealth: When a deployed obfuscation is not stealthy, this might enable attackers to select the most appropriate analyses, or even to customize them. 

One might argue that one can counter this critique by selecting not a set of individual program analysis techniques to evaluate potency, but a set of multi-step attack strategies, in which each strategy consists of pre-pass analysis that is first deployed to select the most appropriate actual analysis technique to go after the targeted property, after which that technique is then used. However, this reformulation would only shift the problem from the actual analysis techniques to the pre-pass analyses, rather than solve it.

In computer security, in general, a clear distinction is made between security assessments and risk assessments. The former focus solely on the technical identification of vulnerabilities and exploits, while the latter also considers the likelihood that attackers know about an existing vulnerability and corresponding exploit, the likelihood that the attackers are willing to use that exploit, and the potential damage that such exploitation would have on the victim and their business. The proposed definitions of potent transformations and stealth provide no guidance on how to incorporate or evaluate the likelihood that adversaries will choose custom analyses, or how difficult it is for them to do so, i.e., how attackers can decide on the most fit-for-purpose analysis.

\subsubsection{Comparing Obfuscations}
One shortcoming of NC's definition of potency is that it does not allow one to compare different obfuscating transformations, e.g., to determine which one is more potent for some program, against which analyses. They in fact acknowledge that, and refer to the work by Dalla Preda et al.\ for a solution~\cite{mila07}. Section ~\ref{sec:abstract_interpretation} will focus on this solution.

\subsubsection{Ad Hoc Formulas}
NC's formulas for computing stealth compute the maximum of false positive and false negative rates. We do not see why this would be advisable over using more standardized metrics such as recall, precision, or the F1 metric. Many authors seem to agree with us. In the post-2009 literature on obfuscation detection techniques, including a 2016 paper co-authored by Collberg~\cite{code_artificiality}, not a single paper uses the formulas proposed by NC. %This to be a good example of progressive insights. 

\subsubsection{Resilience Missing in Action}
With the redefinition of potency, the original distinction between potency and resilience has become moot. Their unification definitely offers advantages, such as moving away from the artificial distinction between confusing humans performing manual work and confusing tools that automate analyses (and deobfuscating transformations). However, it also comes with major disadvantages. As observed by De Sutter et al., many publications in the domain of software obfuscations feature sub-par evaluations~\cite{desutter2024evaluation}. Particularly relevant for this work are their observations that few papers that present novel obfuscation techniques evaluate those obfuscations against real-world attacks and against adversaries that adapt their attack strategies to the fact that certain obfuscations have been deployed, as is commonly the case in the cat-and-mouse game of SP, and as has been observed in human experiments by H\"ansch et al.~\cite{2018_programming_experience_might_not_help_in_comprehending_obfuscated_source_code_efficiently}.

De Sutter et al.\ advocate to differentiate between potency and resilience because authors of obfuscation papers are recommended to consider at least two classes of attacks against which to evaluate the strength of their obfuscation techniques. In their vision, attacks on the assets being protected with some obfuscation determine its potency, and attacks on the SP itself determine its resilience. The distinction between potency and resilience is then still pretty vague, but the continued usage of the two terms can help to raise awareness about the best practices of SP evaluation methodologies.

\subsubsection{Confusion about Potency and Resilience}
These updated definitions have not been picked up by many colleagues. Instead, the original definitions of potency and resilience are still often used, and sometimes inconsistently, as we mentioned in Section~\ref{sec:fuzzy_boundary}. Perhaps this should come as no surprise: In 2017, 8 years after the redefinition of potency that abandons resilience in his book~\cite{collbergbook}, Collberg himself co-authored the work of Banescu et al.~\cite{2017_predicting_the_resilience_of_obfuscated_code_against_symbolic_execution_attacks_via_machine_learning} that still uses resilience when assessing the capability of symbolic execution to extract secrets instead of deobfuscating code.

\subsubsection{Layering Neglected, of Protections and Analyses}
Layering of SPs, and hence assessing the marginal strength of SPs, is still neglected. So is the combination of analyses. In practice, attackers rarely rely on a single analysis method or a single attack step. The definitions of NC do not reflect this. One could argue that it is the responsibility of the individual researchers to consider analyses that are combinations of code analysis techniques rather than individual ones. We believe that anyone defining the aspects to be evaluated should stress the usefulness of this and discuss, in general, the options to do so. 

\subsubsection{Narrow Scope of Stealth}
\label{sec:narrow_stealth}
The updated definition of stealth based on the accuracy of detector and locator functions instead of on the similarity between transformed code and original application code is certainly an improvement. When the results of locator and detector functions are merely used as data inputs to later attack steps, measuring their accuracy on obfuscated code can suffice to evaluate the obfuscation's stealth.

When their results are used as control inputs, i.e., to make strategic decisions on which attack steps to apply next or on how to configure the next attack steps, measuring their accuracy is still useful. In such cases, however, one has to raise the question if there might be other ways to enable the same decisions. For example, maybe an adversary only needs to know which obfuscation tool has been used to make a strategic decision. Or maybe they need to know a specific configuration parameter with which an obfuscation was applied in some location to make a strategic decision? 

By relying only on obfuscation locator and detector functions, one cannot assess to what extent other fingerprints of deployed protections can be revealed that enable strategic decisions. 
