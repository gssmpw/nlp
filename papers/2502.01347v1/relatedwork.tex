\section{Related work}
\label{sec:rel}


\paragraph{Spurious correlations.} Learning from spurious correlations in a training dataset is rather common %in machine learning 
\cite{geirhos2018imagenettrained, arjovsky2020invariant, geirhos2020, sagawa2020a, xiao2021noise, singla2022salient} and it has % which has been shown to have 
unwanted consequences, e.g., lack of robustness towards domain shift, prediction bias and compromised algorithmic fairness \cite{zliobaite15, geirhos2018imagenettrained, zhou21combating, veitch2021counterfactual, seonguk22bias}.
Thus, multiple mitigation approaches have been proposed, with \cite{sagawa2020a, zhang2021coping} or without \cite{liu2021just, ahmed2021systematic} available annotations. Specifically, \cite{tiwari2023overcoming} exploit the difference in the features learned at different layers of a deep neural network; \cite{izmailov2022on, kirichenko2023last} re-train the last layer of the ERM solution to adapt the features to the distribution shift; and \cite{chang21augmentation, plumb2022finding} mitigate the problem via data augmentation.






\vspace{-0.2cm}

\paragraph{Simplicity bias.}
Recent work has shown that deep learning models have a bias towards learning from ``easier'' patterns \cite{Belkin19, rahaman2019spectral, kalimeris2019sgd}. In %the context of 
shortcut learning, this property is formalized in different ways across the %related 
literature. The difficulty of a feature is defined in terms of the minimum complexity of a network that learns it by \cite{Hermann2020whatshapes} and in terms of the smallest amount of linear segments that separate different classes by \cite{shah2020pitfalls}. \cite{moayeri2022hard}
connect the simplicity to the position and size of the features in an image. % and to the overall space they occupy. %by  and to the noise added to them by \cite{sagawa2020b}. %  and to the overall space they occupy; and  tune the difficulty via the noise added to the separate features. %, as in the conditions of their Theorem 1.
\cite{morwani2023simplicity} define the simplicity bias in 1-hidden layer neural networks via the rank of a projection operator that does not alter them substantially, and they focus on a dataset generated via an independent features model learned via the NTK. The NTK is also used to analyze gradient starvation \cite{pezeshki2021gradient} and feature availability \cite{hermann2024on}, regarded as explanations of the simplicity bias. \cite{qiu2024complexity} focus on parity functions and staircases, analyzing the learning dynamics of features having different complexity.


\vspace{-0.2cm}

\paragraph{High-dimensional regression.}
The test loss of linear regression when the input dimension $d$ scales proportionally with the sample size $n$ has been 
%Linear regression with high-dimensional data, i.e., when the number of input dimensions $d$ scales proportionally with the number of training samples $n$, has recently been object of extensive investigation \cite{misiakiewicz2024six}, also because of its connections with %. %, which has demystified 
%phenomena often occurring in deep learning, such as benign overfitting \cite{bartlett2020benign}. % or double descent \cite{Belkin19}. 
%The usual quantity of interest is the test loss which has been 
characterized precisely both in-distribution  \cite{hastie2019surprises, cheng2024dimension} and under covariate shift \cite{yang2023precise, mallinar2024minimumnorm,song2024generalization}. Furthermore, 
\cite{montanari2019generalization,chang2021provable,han2023distribution} have studied the distribution of the ERM solution via %the framework of 
the convex Gaussian min-max Theorem %(CGMT)
\cite{thrampoulidis2015regularized}. % in terms of a corresponding Gaussian sequence model. 
Specifically, our work builds on the non-asymptotic characterization provided by \cite{han2023distribution}. 

\vspace{-0.1cm}

In contrast with linear regression where the number of parameters equals the input dimension, random features models \cite{rahimi2007random} %are able to 
capture the effects of over-parameterization, as the number of parameters is independently of $d$ and $n$.
\cite{mei2022generalization} have characterized the test loss of random features, showing that it displays a double descent \cite{Belkin19}. Furthermore, the RF model has been used to understand a wide family of phenomena such as feature learning \cite{ba2022highdimensional, damian2022neural, moniri2023theory}, robustness under adversarial attacks \cite{dohmatob2022non, bombari2023universal, hassani2024curse}, and distribution shift \cite{tripuraneni2021overparameterization, lee2023demystifying}. The equivalence between an over-parameterized RF model and a regularized linear one has also been studied in detail %in a recent line of work 
\cite{goldt2022gaussian, goldt2020modeling, hu23universality, montanari2022universality}. However, existing rigorous results show the equivalence at the level of training and test error. In contrast, we are interested in the covariance defined in \eqref{eq:spurcov} and, for this reason, we prove an equivalence at the level of the predictor (Theorem \ref{thm:rf}). %The perspective of our paper differs in the sense that existing focus focuses on training/test error, while we are interested in a different function of the prediction, namely the covariance (see \eqref{}), which have prompted to provide a general result valid at the level of the prediction (Theorem \ref{}).



%\vspace{-0.1cm}