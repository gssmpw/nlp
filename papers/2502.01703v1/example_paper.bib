%----- Data Valuation ----------------
@inproceedings{influence,
  title={Understanding black-box predictions via influence functions},
  author={Koh, Pang Wei and Liang, Percy},
  booktitle={International conference on machine learning},
  pages={1885--1894},
  year={2017},
  organization={PMLR}
}

@inproceedings{trak,
author = {Park, Sung Min and Georgiev, Kristian and Ilyas, Andrew and Leclerc, Guillaume and Madry, Aleksander},
title = {TRAK: attributing model behavior at scale},
year = {2023},
publisher = {JMLR.org},
booktitle = {Proceedings of the 40th International Conference on Machine Learning},
articleno = {1128},
numpages = {40},
location = {Honolulu, Hawaii, USA},
series = {ICML'23}
}

@inproceedings{tracin,
author = {Garima and Liu, Frederick and Kale, Satyen and Sundararajan, Mukund},
title = {Estimating training data influence by tracing gradient descent},
year = {2020},
isbn = {9781713829546},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
booktitle = {Proceedings of the 34th International Conference on Neural Information Processing Systems},
articleno = {1672},
numpages = {11},
location = {Vancouver, BC, Canada},
series = {NIPS '20}
}

@inproceedings{less,
author = {Xia, Mengzhou and Malladi, Sadhika and Gururangan, Suchin and Arora, Sanjeev and Chen, Danqi},
title = {LESS: selecting influential data for targeted instruction tuning},
year = {2025},
publisher = {JMLR.org},
booktitle = {Proceedings of the 41st International Conference on Machine Learning},
articleno = {2221},
numpages = {29},
location = {Vienna, Austria},
series = {ICML'24}
}

@misc{loGra,
      title={What is Your Data Worth to GPT? LLM-Scale Data Valuation with Influence Functions}, 
      author={Sang Keun Choe and Hwijeen Ahn and Juhan Bae and Kewen Zhao and Minsoo Kang and Youngseog Chung and Adithya Pratapa and Willie Neiswanger and Emma Strubell and Teruko Mitamura and Jeff Schneider and Eduard Hovy and Roger Grosse and Eric Xing},
      year={2024},
      eprint={2405.13954},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2405.13954}, 
}

@inproceedings{
DataInf,
title={DataInf: Efficiently Estimating Data Influence in Lo{RA}-tuned {LLM}s and Diffusion Models},
author={Yongchan Kwon and Eric Wu and Kevin Wu and James Zou},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=9m02ib92Wz}
}

%----- Gradient Quantization ----------------
@inproceedings{Grad8bit,
  author={Tim Dettmers},
  title={8-Bit Approximations for Parallelism in Deep Learning},
  year={2016},
  cdate={1451606400000},
  url={http://arxiv.org/abs/1511.04561},
  booktitle={ICLR (Poster)},

}

@inproceedings{TernGrad,
author = {Wen, Wei and Xu, Cong and Yan, Feng and Wu, Chunpeng and Wang, Yandan and Chen, Yiran and Li, Hai},
title = {TernGrad: ternary gradients to reduce communication in distributed deep learning},
year = {2017},
isbn = {9781510860964},
booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
pages = {1508–1518},
numpages = {11},
location = {Long Beach, California, USA},
series = {NIPS'17}
}
@inproceedings{QSGD,
author = {Alistarh, Dan and Grubic, Demjan and Li, Jerry Z. and Tomioka, Ryota and Vojnovic, Milan},
title = {QSGD: communication-efficient SGD via gradient quantization and encoding},
year = {2017},
isbn = {9781510860964},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems},
pages = {1707–1718},
numpages = {12},
location = {Long Beach, California, USA},
series = {NIPS'17}
}



@inproceedings{SignSGD,
  title={signSGD: Compressed optimisation for non-convex problems},
  author={Bernstein, Jeremy and Wang, Yu-Xiang and Azizzadenesheli, Kamyar and Anandkumar, Animashree},
  booktitle={International Conference on Machine Learning},
  pages={560--569},
  year={2018},
  organization={PMLR}
}
@inproceedings{SparseGD1,
    title = "Sparse Communication for Distributed Gradient Descent",
    author = "Aji, Alham Fikri  and
      Heafield, Kenneth",
    editor = "Palmer, Martha  and
      Hwa, Rebecca  and
      Riedel, Sebastian",
    booktitle = "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing",
    month = sep,
    year = "2017",
    address = "Copenhagen, Denmark",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D17-1045/",
    doi = "10.18653/v1/D17-1045",
    pages = "440--445",
}

@inproceedings{SparseGD2,
 author = {Wangni, Jianqiao and Wang, Jialei and Liu, Ji and Zhang, Tong},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Gradient Sparsification for Communication-Efficient Distributed Optimization},
 url = {https://proceedings.neurips.cc/paper_files/paper/2018/file/3328bdf9a4b9504b9398284244fe97c2-Paper.pdf},
 volume = {31},
 year = {2018}
}
@inproceedings{SparseGD3,
author = {Stich, Sebastian U. and Cordonnier, Jean-Baptiste and Jaggi, Martin},
title = {Sparsified SGD with memory},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {4452–4463},
numpages = {12},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

%----- PEFT ----------------

@article{LoRA,
  title   = {Lora: Low-rank adaptation of large language models},
  author  = {Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  journal = {arXiv preprint arXiv:2106.09685},
  year    = {2021}
}

@misc{LLMint8,
      title={LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale}, 
      author={Tim Dettmers and Mike Lewis and Younes Belkada and Luke Zettlemoyer},
      year={2022},
      eprint={2208.07339},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2208.07339}, 
}

@inproceedings{QLoRa,
author = {Dettmers, Tim and Pagnoni, Artidoro and Holtzman, Ari and Zettlemoyer, Luke},
title = {QLORA: efficient finetuning of quantized LLMs},
year = {2024},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
booktitle = {Proceedings of the 37th International Conference on Neural Information Processing Systems},
articleno = {441},
numpages = {28},
location = {New Orleans, LA, USA},
series = {NIPS '23}
}

@inproceedings{
AdaLoRA,
title={Adaptive Budget Allocation for Parameter-Efficient Fine-Tuning },
author={Qingru Zhang and Minshuo Chen and Alexander Bukharin and Pengcheng He and Yu Cheng and Weizhu Chen and Tuo Zhao},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=lq62uWRJjiY}
}


@inproceedings{
LoHa,
title={FedPara: Low-rank Hadamard Product for Communication-Efficient Federated Learning},
author={Nam Hyeon-Woo and Moon Ye-Bin and Tae-Hyun Oh},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=d71n4ftoCBy}
}

@inproceedings{
LoKr,
title={Navigating Text-To-Image Customization: From Ly{CORIS} Fine-Tuning to Model Evaluation},
author={SHIH-YING YEH and Yu-Guan Hsieh and Zhidong Gao and Bernard B W Yang and Giyeong Oh and Yanmin Gong},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=wfzXa8e783}
}


@inproceedings{
OFT,
title={Controlling Text-to-Image Diffusion by Orthogonal Finetuning},
author={Zeju Qiu and Weiyang Liu and Haiwen Feng and Yuxuan Xue and Yao Feng and Zhen Liu and Dan Zhang and Adrian Weller and Bernhard Sch{\"o}lkopf},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
year={2023},
url={https://openreview.net/forum?id=K30wTdIIYc}
}


@inproceedings{
BOFT,
title={Parameter-Efficient Orthogonal Finetuning via Butterfly Factorization},
author={Weiyang Liu and Zeju Qiu and Yao Feng and Yuliang Xiu and Yuxuan Xue and Longhui Yu and Haiwen Feng and Zhen Liu and Juyeon Heo and Songyou Peng and Yandong Wen and Michael J. Black and Adrian Weller and Bernhard Sch{\"o}lkopf},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=7NzgkEdGyr}
}


%----- QRP ----------------
@article{JohnsonLindenstrauss,
  title   = {Extensions of Lipschitz mappings into Hilbert space},
  author  = {William B. Johnson and Joram Lindenstrauss},
  journal = {Contemporary mathematics},
  year    = {1984},
  volume  = {26},
  pages   = {189-206}
}


@article{QuantizedJL,
  author={Jacques, Laurent},
  journal={IEEE Transactions on Information Theory}, 
  title={A Quantized Johnson–Lindenstrauss Lemma: The Finding of Buffon’s Needle}, 
  year={2015},
  volume={61},
  number={9},
  pages={5012-5027},
  keywords={Needles;Quantization (signal);Additives;Random variables;Nonlinear distortion;Measurement;Compressed sensing;quantization;Johnson Lindenstrauss lemma;nonlinear dimensionality reduction;random projections},
  doi={10.1109/TIT.2015.2453355}
}

@inproceedings{QRPCosine,
 author = {Li, Ping and Mitzenmacher, Michael and Slawski, Martin},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {D. Lee and M. Sugiyama and U. Luxburg and I. Guyon and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Quantized Random Projections and Non-Linear Estimation of Cosine Similarity},
 url = {https://proceedings.neurips.cc/paper_files/paper/2016/file/186a157b2992e7daed3677ce8e9fe40f-Paper.pdf},
 volume = {29},
 year = {2016}
}

@article{QRPGuarantee,
    author = {Jacques, Laurent and Cambareri, Valerio},
    title = {Time for dithering: fast and quantized random embeddings via the restricted isometry property},
    journal = {Information and Inference: A Journal of the IMA},
    volume = {6},
    number = {4},
    pages = {441-476},
    year = {2017},
    month = {04},
    issn = {2049-8764},
    doi = {10.1093/imaiai/iax004},
    url = {https://doi.org/10.1093/imaiai/iax004},
    eprint = {https://academic.oup.com/imaiai/article-pdf/6/4/441/22874344/iax004.pdf},
}

@inproceedings{Simhash,
author = {Charikar, Moses S.},
title = {Similarity estimation techniques from rounding algorithms},
year = {2002},
isbn = {1581134959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/509907.509965},
doi = {10.1145/509907.509965},
booktitle = {Proceedings of the Thiry-Fourth Annual ACM Symposium on Theory of Computing},
pages = {380–388},
numpages = {9},
location = {Montreal, Quebec, Canada},
series = {STOC '02}
}
@inproceedings{VerySparseRP,
author = {Li, Ping and Hastie, Trevor J. and Church, Kenneth W.},
title = {Very sparse random projections},
year = {2006},
isbn = {1595933395},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1150402.1150436},
doi = {10.1145/1150402.1150436},
booktitle = {Proceedings of the 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {287–296},
numpages = {10},
keywords = {sampling, rates of convergence, random projections},
location = {Philadelphia, PA, USA},
series = {KDD '06}
}

@INPROCEEDINGS{QRPImage,
  author={Li, Mu and Rane, Shantanu and Boufounos, Petros},
  booktitle={2012 IEEE 14th International Workshop on Multimedia Signal Processing (MMSP)}, 
  title={Quantized embeddings of scale-invariant image features for mobile augmented reality}, 
  year={2012},
  volume={},
  number={},
  pages={1-6},
  keywords={Quantization;Databases;Servers;Vectors;Mobile handsets;Feature extraction;Augmented reality},
  doi={10.1109/MMSP.2012.6343406}}

@InProceedings{RPCoding,
  title = 	 {Coding for Random Projections},
  author = 	 {Li, Ping and Mitzenmacher, Michael and Shrivastava, Anshumali},
  booktitle = 	 {Proceedings of the 31st International Conference on Machine Learning},
  pages = 	 {676--684},
  year = 	 {2014},
  editor = 	 {Xing, Eric P. and Jebara, Tony},
  volume = 	 {32},
  number =       {2},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Bejing, China},
  month = 	 {22--24 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v32/lie14.pdf},
  url = 	 {https://proceedings.mlr.press/v32/lie14.html},
}

@article{JLBinaryCoins,
title = {Database-friendly random projections: Johnson-Lindenstrauss with binary coins},
journal = {Journal of Computer and System Sciences},
volume = {66},
number = {4},
pages = {671-687},
year = {2003},
note = {Special Issue on PODS 2001},
issn = {0022-0000},
doi = {https://doi.org/10.1016/S0022-0000(03)00025-4},
url = {https://www.sciencedirect.com/science/article/pii/S0022000003000254},
author = {Dimitris Achlioptas},
abstract = {A classic result of Johnson and Lindenstrauss asserts that any set of n points in d-dimensional Euclidean space can be embedded into k-dimensional Euclidean space—where k is logarithmic in n and independent of d—so that all pairwise distances are maintained within an arbitrarily small factor. All known constructions of such embeddings involve projecting the n points onto a spherically random k-dimensional hyperplane through the origin. We give two constructions of such embeddings with the property that all elements of the projection matrix belong in {−1,0,+1}. Such constructions are particularly well suited for database environments, as the computation of the embedding reduces to evaluating a single aggregate over k random partitions of the attributes.}
}






%----- Models ----------------
@article{Llama2,
  title   = {Llama 2: Open foundation and fine-tuned chat models},
  author  = {Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal = {arXiv preprint arXiv:2307.09288},
  year    = {2023}
}

@article{Mistral7B,
  title   = {Mistral 7B},
  author  = {Jiang, Albert Q and Sablayrolles, Alexandre and Mensch, Arthur and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Bressand, Florian and Lengyel, Gianna and Lample, Guillaume and Saulnier, Lucile and others},
  journal = {arXiv preprint arXiv:2310.06825},
  year    = {2023}
}

@article{Llama3,
  title={The llama 3 herd of models},
  author={Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and others},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}

@misc{Qwen25,
      title={Qwen2.5 Technical Report}, 
      author={Qwen and : and An Yang and Baosong Yang and Beichen Zhang and Binyuan Hui and Bo Zheng and Bowen Yu and Chengyuan Li and Dayiheng Liu and Fei Huang and Haoran Wei and Huan Lin and Jian Yang and Jianhong Tu and Jianwei Zhang and Jianxin Yang and Jiaxi Yang and Jingren Zhou and Junyang Lin and Kai Dang and Keming Lu and Keqin Bao and Kexin Yang and Le Yu and Mei Li and Mingfeng Xue and Pei Zhang and Qin Zhu and Rui Men and Runji Lin and Tianhao Li and Tianyi Tang and Tingyu Xia and Xingzhang Ren and Xuancheng Ren and Yang Fan and Yang Su and Yichang Zhang and Yu Wan and Yuqiong Liu and Zeyu Cui and Zhenru Zhang and Zihan Qiu},
      year={2025},
      eprint={2412.15115},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2412.15115}, 
}



%----- Train Dataset ----------------
@article{flanv2,
  title   = {The flan collection: Designing data and methods for effective instruction tuning},
  author  = {Longpre, Shayne and Hou, Le and Vu, Tu and Webson, Albert and Chung, Hyung Won and Tay, Yi and Zhou, Denny and Le, Quoc V and Zoph, Barret and Wei, Jason and others},
  journal = {arXiv preprint arXiv:2301.13688},
  year    = {2023}
}

@article{COT,
  title   = {Chain-of-thought prompting elicits reasoning in large language models},
  author  = {Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal = {Advances in Neural Information Processing Systems},
  volume  = {35},
  pages   = {24824--24837},
  year    = {2022}
}

@misc{Dolly,
  author  = {Mike Conover and Matt Hayes and Ankit Mathur and Jianwei Xie and Jun Wan and Sam Shah and Ali Ghodsi and Patrick Wendell and Matei Zaharia and Reynold Xin},
  title   = {Free {Dolly}: Introducing the World's First Truly Open Instruction-Tuned {LLM}},
  year    = {2023},
  urldate = {2023-06-30}
}

@inproceedings{OpenAssistant,
  title     = {{OpenAssistant} Conversations--Democratizing Large Language Model Alignment},
  author    = {K{\"o}pf, Andreas and Kilcher, Yannic and von R{\"u}tte, Dimitri and Anagnostidis, Sotiris and Tam, Zhi-Rui and Stevens, Keith and Barhoum, Abdullah and Duc, Nguyen Minh and Stanley, Oliver and Nagyfi, Rich{\'a}rd and others},
  booktitle = neurips_db,
  year      = {2023}
}

%----- Eval Dataset ----------------
@article{tydiqa,
  title   = {{TyDi QA}: A Benchmark for Information-Seeking Question Answering in Typologically Diverse Languages},
  author  = {Jonathan H. Clark and Eunsol Choi and Michael Collins and Dan Garrette and Tom Kwiatkowski and Vitaly Nikolaev and Jennimaria Palomaki},
  year    = {2020},
  journal = {Transactions of the Association for Computational Linguistics}
}

@inproceedings{mmlu,
  title     = {Measuring Massive Multitask Language Understanding},
  author    = {Hendrycks, Dan and Burns, Collin and Basart, Steven and Zou, Andy and Mazeika, Mantas and Song, Dawn and Steinhardt, Jacob},
  booktitle = {International Conference on Learning Representations},
  year      = {2020}
}

@inproceedings{bbh,
  title     = {Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them},
  author    = {Suzgun, Mirac and Scales, Nathan and Sch{\"a}rli, Nathanael and Gehrmann, Sebastian and Tay, Yi and Chung, Hyung Won and Chowdhery, Aakanksha and Le, Quoc and Chi, Ed and Zhou, Denny and others},
  booktitle = {Findings of the Association for Computational Linguistics: ACL 2023},
  pages     = {13003--13051},
  year      = {2023}
}



@misc{dettmers2023qloraefficientfinetuningquantized,
      title={QLoRA: Efficient Finetuning of Quantized LLMs}, 
      author={Tim Dettmers and Artidoro Pagnoni and Ari Holtzman and Luke Zettlemoyer},
      year={2023},
      eprint={2305.14314},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2305.14314}, 
}

@misc{pruthi2020estimatingtrainingdatainfluence,
      title={Estimating Training Data Influence by Tracing Gradient Descent}, 
      author={Garima Pruthi and Frederick Liu and Mukund Sundararajan and Satyen Kale},
      year={2020},
      eprint={2002.08484},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2002.08484}, 
}

@misc{hu2021loralowrankadaptationlarge,
      title={LoRA: Low-Rank Adaptation of Large Language Models}, 
      author={Edward J. Hu and Yelong Shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen},
      year={2021},
      eprint={2106.09685},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2106.09685}, 
}