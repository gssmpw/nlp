\section{Chinese HellaSwag} \label{sec:chinese_hellaswag}
Given the limitation that most existing benchmarks for commonsense reasoning are in English, we begin by building a Chinese benchmark for commonsense reasoning that captures unique aspects of Chinese cultural context.
Firstly, we structure the dataset following the format of HellaSwag \cite{zellers2019hellaswag}, a widely recognized English commonsense reasoning benchmark, which consists of multiple-choice questions with four answer options.
Secondly, to minimize manual effort, we incorporate Qwen-Max \cite{yang2024qwen2}, a state-of-the-art Chinese LLM, into the dataset construction process.
Finally, to enhance the diversity of the dataset, we develop a hierarchical taxonomy of commonsense knowledge, as shown in Figure~\ref{cn_hellaswag}. Our taxonomy consists of seven broad categories summarized from existing literature \cite{zellers2019hellaswag, koupaee2018wikihow, caba2015activitynet}, each containing eight subcategories. We aim to construct our dataset based on the taxonomy, where we inject the categorical information into the instruction for LLM generation. 

We propose a two-stage data construction pipeline, \textbf{\textit{initial dataset generation}} and \textbf{\textit{difficult sample replacement}}, as shown in Figure \ref{overview}. 

\begin{figure}[t] 
\centering
\setlength{\abovecaptionskip}{0.05cm}
\setlength{\belowcaptionskip}{0cm}
\includegraphics[width=\linewidth,scale=0.95]{images/chinese_hellaswag.pdf}
\caption{The two-stage data construction pipeline for Chinese HellaSwag. See an example in Table \ref{case}.}
\label{overview}
% \vspace{-15pt}
\end{figure}

\begin{figure}[t]   
\centering
\setlength{\abovecaptionskip}{0.1cm}
\setlength{\belowcaptionskip}{0cm}
\includegraphics[width=\linewidth,scale=0.8]{images/cn_hellaswag_v1.pdf}
\caption{Overview of Chinese HellaSwag categories. There are seven broad categories in total, each with eight detailed subcategories.}
\label{cn_hellaswag}
\vspace{-8pt}
\end{figure}


\paragraph{Initial Dataset Generation} 
In this stage, we employ an over-generate-then-filter (\citealp{yuan2023distilling}) approach, \ie generating excessive question-answer pairs and filtering for high quality ones, to obtain the initial dataset. The generation of the initial dataset consists of three steps. 

\begin{itemize}[leftmargin=*]
\setlength{\itemsep}{0pt}
    \item \textbf{Step 1: Context over-generation.}
    We employ the LLM to create a Chinese context of the question via in-context learning \cite{brown2020language}, incorporating category information, length requirement, and carefully crafted five-shot Chinese examples similar to HellaSwag. 
    For the length requirement, we assign three tiers: short (under 20 characters), medium (20-40 characters), and long (over 40 characters). 
    We then filter the generated contexts based on character count and Jaccard similarity, eliminating samples that do not meet the length requirement or are too similar to other samples. 
    \item \textbf{Step 2: Choice over-generation. } For each context, we instruct the LLM to over-generate ten potential choices, forming a question.   
    
    \item \textbf{Step 3: Choice filtering.} 
    We instruct the LLM to evaluate each question on a ten-point scale and select six choices: one correct answer (10 points) and five high-scoring incorrect choices. 
    Then, human annotators select four choices, ensuring a single correct answer and three challenging incorrect choices, and check the category labels for the question. 
    After the LLM scoring, we obtain 12,960 samples, which human annotators further refine to 12,287. To maintain category balance, we ultimately select 12,000 samples, allocating 1,500 to each broad category. 

\end{itemize}

\paragraph{Difficult Sample Replacement}
After initial dataset generation, we notice that some incorrect choices are rather simple for LLMs to identify, making the Chinese HellaSwag much easier than its English counterpart. 
Following the adversarial filtering \cite{zellers2018swag}, we use a human-in-the-loop adversarial filtering method (\textbf{Step 4}) to further enhance the dataset's difficulty.
This process involves using a generator LLM to rewrite existing incorrect choices into more challenging ones, and then evaluating the generated choices on multiple discriminator LLMs. 
If the generated choice successfully misleads the discriminator LLMs, we replace the original choice with the newly generated one. 
Finally, human annotators filter out the generated choices that are too difficult for humans to identify (see detail in Appendix~\ref{cn_hellaswag_annotation}). We iterative perform this process until the Chinese HellaSwag achieves accuracy comparable to the English HellaSwag, resulting in replacing 2451 samples. 
% We utilize four strong LLMs and alternate their roles as generator and discriminator. 为什么这么做？
The dataset statistics of the Chinese HellaSwag can be found in Table~\ref{tab:statistics}. The complete evaluation of it is given in Appendix ~\ref{cn_eval}. 

\begin{table}[t]
    \centering
\setlength{\abovecaptionskip}{0.05cm}
\setlength{\belowcaptionskip}{0cm}
\resizebox{0.8\linewidth}{!}{
\begin{tabular}{l|llll}
\toprule
Length Type  & Long  & Medium & Short & Total  \\
\midrule
\# Questions & 4,179 & 4,033  & 3,788 & 12,000 \\
\bottomrule
\end{tabular} }
    \caption{Statistics for Chinese HellaSwag.}
    \label{tab:statistics}
\vspace{-10pt}
\end{table}


