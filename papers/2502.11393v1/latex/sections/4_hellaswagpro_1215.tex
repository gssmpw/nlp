\section{HellaSwag-Pro}

Based on the English-Chinese HellaSwag datasets, we construct HellaSwag-Pro, the benchmark for extensive robustness evaluation of commonsense reasoning. 
We begin by designing the seven-type question variants for robustness evaluation, then detail our data generation process. 
% 双语数据集和pro数据集的关系不太清楚。

% To comprehensively assess the robustness of LLMs in commonsense reasoning, we construct the HellaSwag-Pro adversarial dataset based on the bilingual English-Chinese HellaSwag. Inspired by the Bloom Cognitive Model (\citealp{krathwohl1973taxonomy}), we design seven variants for each question to examine the robustness of LLMs from multiple perspectives, as illustrated in Table \ref{variant type}.

\subsection{Variant Types}
We aim to evaluate the robustness of commonsense reasoning on question variants of changed reasoning forms for the same commonsense knowledge. 
The rationality is that the diverse reasoning forms disables the reliance on superficial patterns, ensuring that correct answers from LLMs demonstrate a robust understanding of the underlying commonsense knowledge. 
Building on existing research \cite{guo2024exploring, ma2024kor, balepur2024s} and our own designs, we maintain seven types of variants, as detailed below. 

\begin{itemize}[leftmargin=*]
    % \setlength{}
    \setlength{\itemsep}{0pt}
    \item \textbf{Problem restatement} aims to test the impact of textual description variations on model understanding. We rephrase the context and correct choice while keeping the incorrect choices unchanged, thereby increasing the difficulty of identifying the correct answer. 

    \item \textbf{Reverse conversion} evaluates the capability for reverse reasoning, \ie inferring the context from the outcome, which has been shown to be challenging for LLMs \cite{guo2024exploring}. We utilize the original correct choice as the context, the original context as the correct choice, and generate three additional incorrect choices. 

    \item \textbf{Causal inference} evaluates the understanding of the causality of the event.  We merge the context and the correct choice and ask for the reason. We generate one correct reason and produce three additional incorrect reasons as the choices.

    \item \textbf{Sentence ordering} focuses on the understanding of inter-sentence relationships, such as progression or contrast.     
    We concatenate the context and correct choice into a complete paragraph, then shuffle the order of the sentences. The correct choice refers to the original sentence ordering. 
    %The correct choice represents the sentences' order in the original paragraph with three incorrect choices featuring erroneous sequences.

    \item \textbf{Scenario refinement} investigates the ability to infer counterfactual situations \cite{ma2024kor}. We select a relatively plausible choice from the original incorrect choices, then minimally modify the context to make this choice correct, where the original correct choice becomes incorrect. 

    \item \textbf{Negation transformation} examines the robustness to negation, a known challenge for LLMs \cite{balepur2024s}. This involves altering the context by introducing negations, such as changing "the man will" to "the man will not." In this transformation, the least plausible choice in the original question becomes the correct answer for the variant, while the original correct answer is retained, and two additional plausible options are generated as distractors. 
    
    \item \textbf{Critical testing} evaluates the model's ability to abstain from answering when the context lacks sufficient information to determine a correct answer. We remove key details from the context to make all original choices invalid. 
    We keep the context minimally modified to increase difficulty. 
    % The context is minimally modified to ensure no answer is appropriate. 
    A new choice, \emph{``None of the above four options are suitable''},  is introduced as the correct choice. 
\end{itemize}

\subsection{Data Generation}

To construct these variants, we also employ Qwen-Max due to its comparatively strong language ability in reforming the questions. % 这里有比较实验吗？
We design in-context examples and instructions with transformation rules to guide Qwen-Max to generate the question variants (\cf Appendix~\ref{appe:hellaswag_pro_annotation}). 
However, we observe that Qwen-Max is not consistently reliable, exhibiting issues such as: 
(1) generating variants inconsistent with the definitions,  
(2) producing multiple correct choices or overly simple incorrect choices, 
and (3) generating invalid contexts, particularly in \emph{scenario refinement}. 

To tackle these issues, we leverage manual quality control over the generated data. 
For \emph{reverse conversion} and \emph{causal inference}, we adopt an over-generate-then-filter approach (\cf Section~\ref{sec:chinese_hellaswag}) to control the correctness and the quality of the generated choices. 
Finally, we conduct comprehensive manual verification of all variants generated to ensure data quality. We initially generate 24,260 variants, and eventually filter down to 11,200 high-quality variants from 1,600 original questions. 
% Through this comprehensive quality verification, we ultimately produce a high-quality bilingual robust commonsense reasoning dataset, HellaSwag-Pro.


