

\begin{table*}[ht]
\centering
\setlength{\tabcolsep}{8pt}
% \footnotesize
\scalebox{0.75}{
% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% \usepackage[table,xcdraw]{xcolor}
% Beamer presentation requires \usepackage{colortbl} instead of \usepackage[table,xcdraw]{xcolor}
% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% \usepackage[table,xcdraw]{xcolor}
% Beamer presentation requires \usepackage{colortbl} instead of \usepackage[table,xcdraw]{xcolor}
\begin{tabular}{ccccccccccccc}
\hline
\multicolumn{1}{c|}{{ }}& \multicolumn{4}{c|}{Chinese}& \multicolumn{4}{c|}{English}& \multicolumn{4}{c}{Total}\\ \cline{213} 
\multicolumn{1}{c|}{\multirow{2}{*}{{ Model}}} & { OA}& { ARA} & {RLA}& \multicolumn{1}{l|}{{CRA}} & { OA}& { ARA} & { RLA}& \multicolumn{1}{l|}{{CRA}} & {OA}& { ARA} & {RLA}& { CRA} \\ \hline
\multicolumn{1}{c|}{{ Human}} & 96.41& 97.79& 1.38 & \multicolumn{1}{l|}{92.03}& 95.56& 96.04& 0.48 & \multicolumn{1}{l|}{90.02}& 95.99 & 96.92 & 0.93& 91.03 \\ \hline
\multicolumn{13}{c}{Closesourced LLMs}\\ \hline
\multicolumn{1}{c|}{{ GPT4o}}& { 91.37} & { 81.97} & { 9.40}& \multicolumn{1}{l|}{{ 75.55}} & { 88.63} & { 70.17} & { 18.46} & \multicolumn{1}{l|}{{ 63.06}} & { 90.00} & { 76.07} & { 13.93} & { 69.31} \\
\multicolumn{1}{c|}{{ Claude3.5}}& { 95.37} & { 80.15} & { 15.22} & \multicolumn{1}{l|}{{ 75.04}} & { 85.11} & { 66.02} & { 19.08} & \multicolumn{1}{l|}{{ 57.20}} & { 90.24} & { 73.09} & { 17.15} & { 66.12} \\
\multicolumn{1}{c|}{{ Gemini1.5Pro}}& { 90.62} & { 78.36} & { 12.26} & \multicolumn{1}{l|}{{ 70.48}} & { 87.75} & { 60.74} & { 27.01} & \multicolumn{1}{l|}{{ 58.27}} & { 89.19} & { 69.55} & { 19.63} & { 64.38} \\
\multicolumn{1}{c|}{{ QwenMax}}& { 93.50} & { 84.82} & { 8.68}& \multicolumn{1}{l|}{{ 78.91}} & { 87.60} & { 62.61} & { 24.99} & \multicolumn{1}{l|}{{ 59.65}} & { 90.55} & { 73.72} & { 16.83} & { 69.28} \\ \hline
\multicolumn{13}{c}{{ Chineses opensourced LLMs}} \\ \hline
\multicolumn{1}{c|}{{ Qwen2.50.5B}}& { 60.75} & { 45.18} & { 15.57} & \multicolumn{1}{l|}{{ 28.70}} & { 49.50} & { 38.21} & { 11.29} & \multicolumn{1}{l|}{{ 20.57}} & { 55.13} & { 41.70} & { 13.43} & { 24.64} \\
\multicolumn{1}{c|}{{ Qwen2.51.5B}}& { 63.25} & { 46.16} & { 17.09} & \multicolumn{1}{l|}{{ 29.89}} & { 56.88} & { 39.57} & { 17.30} & \multicolumn{1}{l|}{{ 23.48}} & { 60.06} & { 42.87} & { 17.20} & { 26.69} \\
\multicolumn{1}{c|}{{ Qwen2.53B}}& { 67.50} & { 48.75} & { 18.75} & \multicolumn{1}{l|}{{ 33.79}} & { 61.75} & { 39.98} & { 21.77} & \multicolumn{1}{l|}{{ 25.75}} & { 64.63} & { 44.37} & { 20.26} & { 29.77} \\
\multicolumn{1}{c|}{{ Qwen2.57B}}& { 67.63} & { 50.59} & { 17.04} & \multicolumn{1}{l|}{{ 35.62}} & { 65.63} & { 43.93} & { 21.70} & \multicolumn{1}{l|}{{ 30.77}} & { 66.63} & { 47.26} & { 19.37} & { 33.20} \\
\multicolumn{1}{c|}{{ Qwen2.514B}} & { 69.00} & { 51.41} & { 17.59} & \multicolumn{1}{l|}{{ 35.84}} & { 68.50} & { 45.20} & { 23.30} & \multicolumn{1}{l|}{{ 32.12}} & { 68.75} & { 48.30} & { 20.45} & { 33.98} \\
\multicolumn{1}{c|}{{ Qwen2.532B}} & { 69.75} & { 53.11} & { 16.64} & \multicolumn{1}{l|}{{ 37.54}} & { 70.00} & { 46.10} & { 23.90} & \multicolumn{1}{l|}{{ 32.68}} & { 69.88} & { 49.61} & { 20.27} & { 35.11} \\
\multicolumn{1}{c|}{{ Qwen2.572B}} & { 70.87} & { 54.75} & { 16.12} & \multicolumn{1}{l|}{{ 39.64}} & { 72.00} & { 47.75} & { 24.25} & \multicolumn{1}{l|}{{ 35.12}} & { 71.44} & { 51.25} & { 20.19} & { 37.38} \\
\multicolumn{1}{c|}{{ Baichuan27B}}& { 67.00} & { 46.16} & { 20.84} & \multicolumn{1}{l|}{{ 31.50}} & { 60.62} & { 39.04} & { 21.58} & \multicolumn{1}{l|}{{ 25.21}} & { 63.81} & { 42.60} & { 21.21} & { 28.36} \\
\multicolumn{1}{c|}{{ Baichua213B}}& { 69.13} & { 46.98} & { 22.15} & \multicolumn{1}{l|}{{ 33.45}} & { 64.62} & { 38.82} & { 25.80} & \multicolumn{1}{l|}{{ 26.07}} & { 66.88} & { 42.90} & { 23.97} & { 29.76} \\
\multicolumn{1}{c|}{{ DeepSeek7B}} & { 68.13} & { 47.96} & { 20.17} & \multicolumn{1}{l|}{{ 33.30}} & { 63.38} & { 40.39} & { 22.99} & \multicolumn{1}{l|}{{ 26.70}} & { 65.76} & { 44.18} & { 21.58} & { 30.00} \\
\multicolumn{1}{c|}{{ DeepSeek67B}}& { 71.50} & { 49.21} & { 22.29} & \multicolumn{1}{l|}{{ 35.89}} & { 71.37} & { 40.63} & { 30.75} & \multicolumn{1}{l|}{{ 29.71}} & { 71.44} & { 44.92} & { 26.52} & { 32.80} \\
\multicolumn{1}{c|}{{ InternLM2.51.8B}}& { 61.62} & { 42.07} & { 19.55} & \multicolumn{1}{l|}{{ 26.99}} & { 55.37} & { 38.46} & { 16.91} & \multicolumn{1}{l|}{{ 22.61}} & { 58.50} & { 40.27} & { 18.23} & { 24.80} \\
\multicolumn{1}{c|}{{ InternLM2.57B}}& { 67.25} & { 49.77} & { 17.48} & \multicolumn{1}{l|}{{ 34.57}} & { 69.50} & { 40.89} & { 28.61} & \multicolumn{1}{l|}{{ 29.75}} & { 68.38} & { 45.33} & { 23.04} & { 32.16} \\
\multicolumn{1}{c|}{{ InternLM2.520B}} & { 67.37} & { 44.75} & { 22.62} & \multicolumn{1}{l|}{{ 33.21}} & { 73.62} & { 41.11} & { 32.51} & \multicolumn{1}{l|}{{ 31.23}} & { 70.50} & { 42.93} & { 27.57} & { 32.22} \\
\multicolumn{1}{c|}{{ Yi1.56B}} & { 67.00} & { 49.59} & { 17.41} & \multicolumn{1}{l|}{{ 34.27}} & { 64.38} & { 39.37} & { 25.01} & \multicolumn{1}{l|}{{ 26.62}} & { 65.69} & { 44.48} & { 21.21} & { 30.45} \\
\multicolumn{1}{c|}{{ Yi1.59B}} & { 68.50} & { 50.18} & { 18.32} & \multicolumn{1}{l|}{{ 35.55}} & { 66.37} & { 39.58} & { 26.79} & \multicolumn{1}{l|}{{ 27.48}} & { 67.44} & { 44.88} & { 22.56} & { 31.52} \\
\multicolumn{1}{c|}{{ Yi1.534B}}& { 71.00} & { 52.23} & { 18.77} & \multicolumn{1}{l|}{{ 38.09}} & { 71.00} & { 40.75} & { 30.25} & \multicolumn{1}{l|}{{ 29.91}} & { 71.00} & { 46.49} & { 24.51} & { 34.00} \\ \hline
\multicolumn{13}{c}{{ English opensourced LLMs}} \\ \hline
\multicolumn{1}{c|}{{ LLaMA38B}} & { 59.13} & { 46.62} & { 12.51} & \multicolumn{1}{l|}{{ 28.23}} & { 66.25} & { 40.21} & { 26.04} & \multicolumn{1}{l|}{{ 27.34}} & { 62.69} & { 43.42} & { 19.27} & { 27.79} \\
\multicolumn{1}{c|}{{ LLaMA370B}}& { 65.75} & { 48.63} & { 17.12} & \multicolumn{1}{l|}{{ 32.70}} & { 72.50} & { 41.27} & { 31.23} & \multicolumn{1}{l|}{{ 30.63}} & { 69.13} & { 44.95} & { 24.18} & { 31.67} \\
\multicolumn{1}{c|}{{ Mistral7Bv0.2}} & { 57.75} & { 46.25} & { 11.50} & \multicolumn{1}{l|}{{ 27.57}} & { 67.50} & { 41.52} & { 25.98} & \multicolumn{1}{l|}{{ 28.93}} & { 62.63} & { 43.88} & { 18.74} & { 28.25} \\
\multicolumn{1}{c|}{{ Mixtral8x7Bv0.1}} & { 63.62} & { 46.80} & { 16.82} & \multicolumn{1}{l|}{{ 30.82}} & { 69.75} & { 41.21} & { 28.54} & \multicolumn{1}{l|}{{ 29.39}} & { 66.69} & { 44.01} & { 22.68} & { 30.11} \\
\multicolumn{1}{c|}{{ Mixtral8x22Bv0.1}}& { 66.00} & { 50.73} & { 15.27} & \multicolumn{1}{l|}{{ 34.32}} & { 72.12} & { 41.25} & { 30.87} & \multicolumn{1}{l|}{{ 30.61}} & { 69.06} & { 45.99} & { 23.07} & { 32.47} \\
\multicolumn{1}{c|}{{ Gemma22B}}& { 61.88} & { 45.38} & { 16.51} & \multicolumn{1}{l|}{{ 29.02}} & { 59.62} & { 39.13} & { 20.50} & \multicolumn{1}{l|}{{ 24.88}} & { 60.75} & { 42.25} & { 18.50} & { 26.95} \\
\multicolumn{1}{c|}{{ Gemma29B}}& { 69.13} & { 46.75} & { 22.38} & \multicolumn{1}{l|}{{ 33.29}} & { 64.88} & { 39.80} & { 25.08} & \multicolumn{1}{l|}{{ 26.91}} & { 67.01} & { 43.28} & { 23.73} & { 30.10} \\
\multicolumn{1}{c|}{{ Gemma227B}} & { 63.38} & { 48.52} & { 14.86} & \multicolumn{1}{l|}{{ 31.96}} & { 71.88} & { 40.91} & { 30.97} & \multicolumn{1}{l|}{{ 30.25}} & { 67.63} & { 44.71} & { 22.92} & { 31.11} \\ \hline
\end{tabular}
}
\caption{Accuracy of existing LLMs on HellaSwagpro.}
\label{tab:main experiment.}
\end{table*}