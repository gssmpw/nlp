\section{Related Work}
\subsection{Deep Learning Approaches for Medical Image Segmentation}
Deep learning has fundamentally transformed medical image segmentation over the past decade \cite{wang2022medical}. 
Early architectures such as U-Net~\cite{ronneberger2015u} and its numerous variants~\cite{qamar2020variant,lin2024mm} employ an encoder-decoder structure with skip connections to effectively capture both contextual and spatial information~\cite{azad2024medical}. 
These models have achieved remarkable success in various segmentation tasks across different imaging modalities, including MRI~\cite{guo2022cardiac}, CT~\cite{yang2024novel}, and ultrasound~\cite{chen2023rrcnet}. 
More recently, transformer-based models like TransUNet~\cite{chen2021transunet} and Swin-UNet~\cite{cao2022swin} have further improved performance by integrating self-attention mechanisms to capture long-range dependencies, demonstrating superior results in tasks such as brain tumor segmentation~\cite{zhang2021transfuse} and organ segmentation. 
Despite these advances, many current approaches struggle with preserving fine anatomical boundaries and maintaining spatial coherence, particularly in challenging scenarios such as postoperative nasopharyngeal carcinoma imaging, where critical airway-related structures lie nearby. 
These limitations motivate the need for models that can more effectively capture both local details and global context, as highlighted in recent studies~\cite{zhang2022understanding,rayed2024deep}.

\subsection{Frequency Domain Analysis and Wavelet-based Methods in Medical Imaging}
Frequency domain analysis has long been a powerful tool in image processing, with wavelet transforms playing a central role in multi-scale feature extraction \cite{sun2021mwq}. 
Wavelet-based techniques excel at decomposing images into components that capture both local details (high-frequency components) and global structures (low-frequency components) \cite{liang2024rskd}. 
Recent research has integrated wavelet transforms into deep learning frameworks to bolster the extraction of robust features and enhance segmentation performance~\cite{tan2024wavelet,yang2024sffnet}. By leveraging both spatial and frequency domain information, such methods can better capture subtle textural variations and edge details~\cite{liu2024freqsnet}. 
The integration of wavelet transforms into frameworks allows for efficient processing of multi-scale features, thereby improving the reliability and accuracy of segmentation outputs~\cite{qian2024adaptive}. 
% Furthermore, wavelet-based approaches have been shown to outperform traditional methods across various imaging modalities, including MRI and CT~\cite{alijamaat2021multiple,agnes2024wavelet}. 
This trend emphasizes the potential of wavelet transforms when combined with machine learning techniques to enhance medical image analysis.

\subsection{State Space Sequence Models and Topology-aware Techniques}
State space sequence models (SSMs) have emerged as an attractive alternative to traditional attention mechanisms, particularly due to their ability to model long-range dependencies with linear computational complexity \cite{zhu2024vision}. 
The Mamba architecture~\cite{gu2023mamba} is a notable example, employing selective state space modeling to capture global contextual cues that are crucial for maintaining anatomical consistency across complex structures. 
% SSMs proposed by Gu et al.~\cite{gu2021efficiently} have shown great promise in various medical imaging tasks, leveraging their efficiency in handling sequential information.
In parallel, topology-aware techniques have been proposed to ensure that segmentation outputs preserve the natural spatial relationships among anatomical structures \cite{sadikine2024deep,puunsupervised}. 
Techniques such as topology-preserving segmentation~\cite{santhirasekaram2023topology,shi2023nextou} address common issues like fragmented or disconnected segmentations, which can lead to clinically unacceptable results. 
For instance, Gupta et al.~\cite{gupta2022learning} demonstrated how incorporating topological constraints can enhance the robustness of segmentation algorithms, particularly in challenging cases such as airway-related structure delineation.
In our work, we extend these ideas by introducing a topology-aware snake-scan module that adaptively reorders feature patches to enhance boundary delineation and preserve the inherent topology of airway-related structures.

\begin{figure*}[htbp]
\setlength{\abovecaptionskip}{2pt}
\setlength{\belowcaptionskip}{0pt}
\centering
\includegraphics[width=\textwidth]{Figure2.pdf}
\caption{(a)The architectural design of TopoWMamba. TopoWMamba is an encoder-decoder segmentation framework that employs Mamba-based modules for effective feature extraction while maintaining low-level details through residual connections. (b)The overall structure of the SCVSS. The SCVSS features three parallel branchesâ€”conventional convolution, VSS, and SnakeVSS. (c)The illustration of Wavelet-based Mamba Block (WMB). WMB utilizes a 2D discrete wavelet transform to separate feature maps into low and high-frequency components, processing them with specialized modules to enhance long-range dependencies and global context.}
\label{fig:fig2}
\end{figure*}

\begin{figure}[htbp]
\centering
\includegraphics[width=2.5in]{Figure5.pdf}
\caption{Details of SnakeVSS and VSS structure. In this diagram, the symbol $\oplus$ represents element-wise addition. The SnakeVSS branch reorders feature patches in serpentine patterns, capturing complex curvilinear structures, while the VSS branch focuses on conventional scanning directions to extract spatial features effectively.}
\label{fig:fig4}
\end{figure}

% \begin{figure}[htbp]
% \centering
% \includegraphics[width=2.5in]{Figure5.pdf}
% \caption{Details of SnakeVSS and VSS structure. In this diagram, the symbol $\oplus$ represents element-wise addition. The SnakeVSS branch reorders feature patches in serpentine patterns, capturing complex curvilinear structures, while the VSS branch focuses on conventional scanning directions to extract spatial features effectively.}
% \label{fig:fig4}
% \end{figure}


\begin{figure}[htbp]
\setlength{\abovecaptionskip}{2pt}
\setlength{\belowcaptionskip}{0pt}
\centering
\includegraphics[width=0.5\textwidth]{Figure4.pdf}
\caption{Details of spatial and channel attention structure. The symbol $\otimes$ denotes element-wise multiplication, and $\oplus$ represents element-wise addition.  This structure enhances feature representation by focusing on important spatial regions and channel-wise dependencies, allowing the model to better capture relevant information.}
\label{fig:fig5}
\end{figure}

% 


%