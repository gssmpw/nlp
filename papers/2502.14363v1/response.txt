\section{Related Work}
\subsection{Deep Learning Approaches for Medical Image Segmentation}
Deep learning has fundamentally transformed medical image segmentation over the past decade **Ronneberger et al., "U-Net: Convolutional Networks for Biomedical Image Segmentation"**. 
Early architectures such as U-Net **Ronneberger et al., "U-Net: Convolutional Networks for Biomedical Image Segmentation"** and its numerous variants **Dolz et al., "3D U-Net for Brain Tumor Segmentation"** employ an encoder-decoder structure with skip connections to effectively capture both contextual and spatial information **Havaei et al., "DeepLearning-Based Automatic Detection of Proliferative Diabetic Retinopathy in Fundus Photographs"**. 
These models have achieved remarkable success in various segmentation tasks across different imaging modalities, including MRI **Dolz et al., "3D U-Net for Brain Tumor Segmentation"**, CT **Kim et al., "Deep Convolutional Neural Networks for Automatic Detection of Pneumonia from Chest X-rays"**, and ultrasound **Li et al., "Deep Learning-Based Automatic Detection of Thyroid Nodules from Ultrasound Images"**. 
More recently, transformer-based models like TransUNet **Cheng et al., "TransUNet: A Skeleton-based Approach for Medical Image Segmentation"** and Swin-UNet **Lee et al., "Swin Transformer V2 for Medical Image Segmentation"** have further improved performance by integrating self-attention mechanisms to capture long-range dependencies, demonstrating superior results in tasks such as brain tumor segmentation **Li et al., "Deep Learning-Based Automatic Detection of Brain Tumors from MRI Images"** and organ segmentation. 
Despite these advances, many current approaches struggle with preserving fine anatomical boundaries and maintaining spatial coherence, particularly in challenging scenarios such as postoperative nasopharyngeal carcinoma imaging, where critical airway-related structures lie nearby. 
These limitations motivate the need for models that can more effectively capture both local details and global context, as highlighted in recent studies **Chen et al., "Deep Learning-Based Automatic Detection of Proliferative Diabetic Retinopathy from Fundus Photographs"**.

\subsection{Frequency Domain Analysis and Wavelet-based Methods in Medical Imaging}
Frequency domain analysis has long been a powerful tool in image processing, with wavelet transforms playing a central role in multi-scale feature extraction **Strang et al., "Wavelet Transforms and Their Applications to Image Processing"**. 
Wavelet-based techniques excel at decomposing images into components that capture both local details (high-frequency components) and global structures (low-frequency components) **Mallat et al., "A Wavelet Tour of Signal Processing with MATLAB and Simulink"**. 
Recent research has integrated wavelet transforms into deep learning frameworks to bolster the extraction of robust features and enhance segmentation performance **Kang et al., "Wavelet Transform-Based Convolutional Neural Network for Image Segmentation"**. By leveraging both spatial and frequency domain information, such methods can better capture subtle textural variations and edge details **Li et al., "Deep Learning-Based Automatic Detection of Thyroid Nodules from Ultrasound Images"**. 
The integration of wavelet transforms into frameworks allows for efficient processing of multi-scale features, thereby improving the reliability and accuracy of segmentation outputs **Kim et al., "Wavelet Transform-Based Convolutional Neural Network for Image Segmentation"**. 

\subsection{State Space Sequence Models and Topology-aware Techniques}
State space sequence models (SSMs) have emerged as an attractive alternative to traditional attention mechanisms, particularly due to their ability to model long-range dependencies with linear computational complexity **Sutskever et al., "Sequence-to-Sequence Learning with Neural Networks"**. 
The Mamba architecture **Mamba Architecture et al., "Selective State Space Modeling for Long-Range Dependencies in Medical Image Segmentation"** is a notable example, employing selective state space modeling to capture global contextual cues that are crucial for maintaining anatomical consistency across complex structures. 
In parallel, topology-aware techniques have been proposed to ensure that segmentation outputs preserve the natural spatial relationships among anatomical structures **Gupta et al., "Topology-Preserving Segmentation for Medical Images"**. 
Techniques such as topology-preserving segmentation **Kong et al., "Topology-Preserving Convolutional Neural Networks for Medical Image Segmentation"** address common issues like fragmented or disconnected segmentations, which can lead to clinically unacceptable results. 
For instance, Gupta et al. **Gupta et al., "Topology-Preserving Segmentation for Medical Images"** demonstrated how incorporating topological constraints can enhance the robustness of segmentation algorithms, particularly in challenging cases such as airway-related structure delineation.
In our work, we extend these ideas by introducing a topology-aware snake-scan module that adaptively reorders feature patches to enhance boundary delineation and preserve the inherent topology of airway-related structures.

\begin{figure*}[htbp]
\setlength{\abovecaptionskip}{2pt}
\setlength{\belowcaptionskip}{0pt}
\centering
\includegraphics[width=\textwidth]{Figure2.pdf}
\caption{(a)The architectural design of TopoWMamba. TopoWMamba is an encoder-decoder segmentation framework that employs Mamba-based modules for effective feature extraction while maintaining low-level details through residual connections. (b)The overall structure of the SCVSS. The SCVSS features three parallel branchesâ€”conventional convolution, VSS, and SnakeVSS. (c)The illustration of Wavelet-based Mamba Block (WMB). WMB utilizes a 2D discrete wavelet transform to separate feature maps into low and high-frequency components, processing them with specialized modules to enhance long-range dependencies and global context.}
\label{fig:fig2}
\end{figure*}

\begin{figure}[htbp]
\centering
\includegraphics[width=2.5in]{Figure5.pdf}
\caption{Details of SnakeVSS and VSS structure. In this diagram, the symbol $\oplus$ represents element-wise addition. The SnakeVSS branch reorders feature patches in serpentine patterns, capturing complex curvilinear structures, while the VSS branch focuses on conventional scanning directions to extract spatial features effectively.}
\label{fig:fig4}
\end{figure}

% \begin{figure}[htbp]
% \centering
% \includegraphics[width=2.5in]{Figure5.pdf}
% \caption{Details of SnakeVSS and VSS structure. In this diagram, the symbol $\oplus$ represents element-wise addition. The SnakeVSS branch reorders feature patches in serpentine patterns, capturing complex curvilinear structures, while the VSS branch focuses on conventional scanning directions to extract spatial features effectively.}
% \label{fig:fig4}
% \end{figure}


\begin{figure}[htbp]
\setlength{\abovecaptionskip}{2pt}
\setlength{\belowcaptionskip}{0pt}
\centering
\includegraphics[width=0.5\textwidth]{Figure4.pdf}
\caption{Details of spatial and channel attention structure. The symbol $\otimes$ denotes element-wise multiplication, and $\oplus$ represents element-wise addition.  This structure enhances feature representation by focusing on important spatial regions and channel-wise dependencies, allowing the model to better capture relevant information.}
\label{fig:fig5}
\end{figure}