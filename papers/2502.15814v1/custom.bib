@article{twist,
  title={Textually pretrained speech language models},
  author={Hassid, Michael and Remez, Tal and Nguyen, Tu Anh and Gat, Itai and Conneau, Alexis and Kreuk, Felix and Copet, Jade and Defossez, Alexandre and Synnaeve, Gabriel and Dupoux, Emmanuel and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{geiping2023cramming,
  title={Cramming: Training a Language Model on a single GPU in one day.},
  author={Geiping, Jonas and Goldstein, Tom},
  booktitle={International Conference on Machine Learning},
  pages={11117--11143},
  year={2023},
  organization={PMLR}
}

@article{cuervo2024scaling,
  title={Scaling Properties of Speech Language Models},
  author={Cuervo, Santiago and Marxer, Ricard},
  journal={arXiv preprint arXiv:2404.00685},
  year={2024}
}

@inproceedings{maimon2023dissc,
  title={Speaking Style Conversion in the Waveform Domain Using Discrete Self-Supervised Units},
  author={Maimon, Gallil and Adi, Yossi},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2023},
  pages={8048--8061},
  year={2023}
}

@article{maimon2024salmon,
  title={A suite for acoustic language model evaluation},
  author={Maimon, Gallil and Roth, Amit and Adi, Yossi},
  journal={arXiv preprint arXiv:2409.07437},
  year={2024}
}

@article{gslm,
  title={On generative spoken language modeling from raw audio},
  author={Lakhotia, Kushal and Kharitonov, Eugene and Hsu, Wei-Ning and Adi, Yossi and Polyak, Adam and Bolte, Benjamin and Nguyen, Tu-Anh and Copet, Jade and Baevski, Alexei and Mohamed, Abdelrahman and others},
  journal={Transactions of the Association for Computational Linguistics},
  volume={9},
  pages={1336--1354},
  year={2021},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}


@article{spiritlm,
  title={Spirit-lm: Interleaved spoken and written language model},
  author={Nguyen, Tu Anh and Muller, Benjamin and Yu, Bokai and Costa-Jussa, Marta R and Elbayad, Maha and Popuri, Sravya and Ropers, Christophe and Duquenne, Paul-Ambroise and Algayres, Robin and Mavlyutov, Ruslan and others},
  journal={Transactions of the Association for Computational Linguistics},
  volume={13},
  pages={30--52},
  year={2025},
  publisher={MIT Press 255 Main Street, 9th Floor, Cambridge, Massachusetts 02142, USA~…}
}

@inproceedings{salmonn,
  title={{SALMONN}: Towards Generic Hearing Abilities for Large Language Models},
  author={Changli Tang and Wenyi Yu and Guangzhi Sun and Xianzhao Chen and Tian Tan and Wei Li and Lu Lu and Zejun MA and Chao Zhang},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024},
  url={https://openreview.net/forum?id=14rn7HpKVk}
}

@article{qwen_audio,
  title={Qwen-audio: Advancing universal audio understanding via unified large-scale audio-language models},
  author={Chu, Yunfei and Xu, Jin and Zhou, Xiaohuan and Yang, Qian and Zhang, Shiliang and Yan, Zhijie and Zhou, Chang and Zhou, Jingren},
  journal={arXiv preprint arXiv:2311.07919},
  year={2023}
}
@article{rafailov2024dpo,
  title={Direct preference optimization: Your language model is secretly a reward model},
  author={Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Manning, Christopher D and Ermon, Stefano and Finn, Chelsea},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{lin2024alignslm,
  title={Align-SLM: Textless Spoken Language Models with Reinforcement Learning from AI Feedback},
  author={Lin, Guan-Ting and Shivakumar, Prashanth Gurunath and Gourav, Aditya and Gu, Yile and Gandhe, Ankur and Lee, Hung-yi and Bulyko, Ivan},
  journal={arXiv preprint arXiv:2411.01834},
  year={2024}
}


@inproceedings{liu2024efficient,
  title={Efficient Training of Self-Supervised Speech Foundation Models on a Compute Budget},
  author={Liu, Andy T and Lin, Yi-Cheng and Wu, Haibin and Winkler, Stefan and Lee, Hung-yi},
  booktitle={2024 IEEE Spoken Language Technology Workshop (SLT)},
  pages={961--968},
  year={2024},
  organization={IEEE}
}


@inproceedings{mobilellm,
  title={MobileLLM: Optimizing Sub-billion Parameter Language Models for On-Device Use Cases},
  author={Liu, Zechun and Zhao, Changsheng and Iandola, Forrest and Lai, Chen and Tian, Yuandong and Fedorov, Igor and Xiong, Yunyang and Chang, Ernie and Shi, Yangyang and Krishnamoorthi, Raghuraman and others},
  booktitle={Forty-first International Conference on Machine Learning},
  year={2024}
}

@INPROCEEDINGS{ls,
  author={Panayotov, Vassil and Chen, Guoguo and Povey, Daniel and Khudanpur, Sanjeev},
  booktitle={2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Librispeech: An ASR corpus based on public domain audio books}, 
  year={2015},
  volume={},
  number={},
  pages={5206-5210},
  keywords={Resource description framework;Genomics;Bioinformatics;Blogs;Information services;Electronic publishing;Speech Recognition;Corpus;LibriVox},
  doi={10.1109/ICASSP.2015.7178964}}


@inproceedings{ll,
  title={Libri-light: A benchmark for asr with limited or no supervision},
  author={Kahn, Jacob and Riviere, Morgane and Zheng, Weiyi and Kharitonov, Evgeny and Xu, Qiantong and Mazar{\'e}, Pierre-Emmanuel and Karadayi, Julien and Liptchinsky, Vitaliy and Collobert, Ronan and Fuegen, Christian and others},
  booktitle={ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={7669--7673},
  year={2020},
  organization={IEEE}
}

@article{swc,
  title={The Spoken Wikipedia Corpus collection: Harvesting, alignment and an application to hyperlistening},
  author={Timo Baumann and Arne K{\"o}hn and Felix Hennig},
  journal={Language Resources and Evaluation},
  year={2018},
  volume={53},
  pages={303 - 329},
  url={https://api.semanticscholar.org/CorpusID:52825870}
}

@inproceedings{people,
title={The People{\textquoteright}s Speech: A Large-Scale Diverse English Speech Recognition Dataset for Commercial Usage},
author={Daniel Galvez and Greg Diamos and Juan Manuel Ciro Torres and Juan Felipe Cer{\'o}n and Keith Achorn and Anjali Gopi and David Kanter and Max Lam and Mark Mazumder and Vijay Janapa Reddi},
booktitle={Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 1)},
year={2021},
url={https://openreview.net/forum?id=R8CwidgJ0yT}
}

@inproceedings{tedlium,
  title={TED-LIUM 3: Twice as much data and corpus repartition for experiments on speaker adaptation},
  author={Hernandez, Fran{\c{c}}ois and Nguyen, Vincent and Ghannay, Sahar and Tomashenko, Natalia and Esteve, Yannick},
  booktitle={Speech and Computer: 20th International Conference, SPECOM 2018, Leipzig, Germany, September 18--22, 2018, Proceedings 20},
  pages={198--208},
  year={2018},
  organization={Springer}
}

@inproceedings{vp,
    title = "{V}ox{P}opuli: A Large-Scale Multilingual Speech Corpus for Representation Learning, Semi-Supervised Learning and Interpretation",
    author = "Wang, Changhan  and
      Riviere, Morgane  and
      Lee, Ann  and
      Wu, Anne  and
      Talnikar, Chaitanya  and
      Haziza, Daniel  and
      Williamson, Mary  and
      Pino, Juan  and
      Dupoux, Emmanuel",
    editor = "Zong, Chengqing  and
      Xia, Fei  and
      Li, Wenjie  and
      Navigli, Roberto",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-long.80/",
    doi = "10.18653/v1/2021.acl-long.80",
    pages = "993--1003",
    abstract = "We introduce VoxPopuli, a large-scale multilingual corpus providing 400K hours of unlabeled speech data in 23 languages. It is the largest open data to date for unsupervised representation learning as well as semi-supervised learning. VoxPopuli also contains 1.8K hours of transcribed speeches in 15 languages and their aligned oral interpretations into 15 target languages totaling 17.3K hours. We provide speech recognition (ASR) baselines and validate the versatility of VoxPopuli unlabeled data in semi-supervised ASR and speech-to-text translation under challenging out-of-domain settings. The corpus is available at \url{https://github.com/facebookresearch/voxpopuli}."
}


@inproceedings{pythia,
  title={Pythia: A suite for analyzing large language models across training and scaling},
  author={Biderman, Stella and Schoelkopf, Hailey and Anthony, Quentin Gregory and Bradley, Herbie and O’Brien, Kyle and Hallahan, Eric and Khan, Mohammad Aflah and Purohit, Shivanshu and Prashanth, USVSN Sai and Raff, Edward and others},
  booktitle={International Conference on Machine Learning},
  pages={2397--2430},
  year={2023},
  organization={PMLR}
}

@article{tinystories,
  title={Tinystories: How small can language models be and still speak coherent english?},
  author={Eldan, Ronen and Li, Yuanzhi},
  journal={arXiv preprint arXiv:2305.07759},
  year={2023}
}


@article{scaling_interleaving,
  title={Scaling speech-text pre-training with synthetic interleaved data},
  author={Zeng, Aohan and Du, Zhengxiao and Liu, Mingdao and Zhang, Lei and Jiang, Shengmin and Dong, Yuxiao and Tang, Jie},
  journal={arXiv preprint arXiv:2411.17607},
  year={2024}
}

@article{fairseq,
  title={fairseq s\^{} 2: A scalable and integrable speech synthesis toolkit},
  author={Wang, Changhan and Hsu, Wei-Ning and Adi, Yossi and Polyak, Adam and Lee, Ann and Chen, Peng-Jen and Gu, Jiatao and Pino, Juan},
  journal={arXiv preprint arXiv:2109.06912},
  year={2021}
}

@article{qwen2,
  title={Qwen2.5 technical report},
  author={Yang, An and Yang, Baosong and Zhang, Beichen and Hui, Binyuan and Zheng, Bo and Yu, Bowen and Li, Chengyuan and Liu, Dayiheng and Huang, Fei and Wei, Haoran and others},
  journal={arXiv preprint arXiv:2412.15115},
  year={2024}
}

@article{opt,
  title={Opt: Open pre-trained transformer language models},
  author={Zhang, Susan and Roller, Stephen and Goyal, Naman and Artetxe, Mikel and Chen, Moya and Chen, Shuohui and Dewan, Christopher and Diab, Mona and Li, Xian and Lin, Xi Victoria and others},
  journal={arXiv preprint arXiv:2205.01068},
  year={2022}
}

@article{peng2024survey,
  title={A survey on speech large language models},
  author={Peng, Jing and Wang, Yucheng and Xi, Yu and Li, Xu and Zhang, Xizhuo and Yu, Kai},
  journal={arXiv preprint arXiv:2410.18908},
  year={2024}
}

@article{cui2024recent,
  title={Recent advances in speech language models: A survey},
  author={Cui, Wenqian and Yu, Dianzhi and Jiao, Xiaoqi and Meng, Ziqiao and Zhang, Guangyan and Wang, Qichao and Guo, Yiwen and King, Irwin},
  journal={arXiv preprint arXiv:2410.03751},
  year={2024}
}

@article{ji2024wavchat,
  title={Wavchat: A survey of spoken dialogue models},
  author={Ji, Shengpeng and Chen, Yifu and Fang, Minghui and Zuo, Jialong and Lu, Jingyu and Wang, Hanting and Jiang, Ziyue and Zhou, Long and Liu, Shujie and Cheng, Xize and others},
  journal={arXiv preprint arXiv:2411.13577},
  year={2024}
}

@article{latif2023sparks,
  title={Sparks of large audio models: A survey and outlook},
  author={Latif, Siddique and Shoukat, Moazzam and Shamshad, Fahad and Usama, Muhammad and Ren, Yi and Cuay{\'a}huitl, Heriberto and Wang, Wenwu and Zhang, Xulong and Togneri, Roberto and Cambria, Erik and others},
  journal={arXiv preprint arXiv:2308.12792},
  year={2023}
}

@article{valle,
  title={Neural codec language models are zero-shot text to speech synthesizers},
  author={Wang, Chengyi and Chen, Sanyuan and Wu, Yu and Zhang, Ziqiang and Zhou, Long and Liu, Shujie and Chen, Zhuo and Liu, Yanqing and Wang, Huaming and Li, Jinyu and others},
  journal={arXiv preprint arXiv:2301.02111},
  year={2023}
}

@article{yang2023uniaudio,
  title={Uniaudio: An audio foundation model toward universal audio generation},
  author={Yang, Dongchao and others},
  journal={arXiv preprint arXiv:2310.00704},
  year={2023}
}

@article{yang2024uniaudio,
  title={UniAudio 1.5: Large Language Model-driven Audio Codec is A Few-shot Audio Task Learner},
  author={Yang, Dongchao and others},
  journal={arXiv preprint arXiv:2406.10056},
  year={2024}
}

@article{audioplam,
  title={Audiopalm: A large language model that can speak and listen},
  author={Rubenstein, Paul K and Asawaroengchai, Chulayuth and Nguyen, Duc Dung and Bapna, Ankur and Borsos, Zal{\'a}n and Quitry, F{\'e}lix de Chaumont and Chen, Peter and Badawy, Dalia El and Han, Wei and Kharitonov, Eugene and others},
  journal={arXiv preprint arXiv:2306.12925},
  year={2023}
}

@article{park2024long,
  title={Long-Form Speech Generation with Spoken Language Models},
  author={Park, Se Jin and Salazar, Julian and Jansen, Aren and Kinoshita, Keisuke and Ro, Yong Man and Skerry-Ryan, RJ},
  journal={arXiv preprint arXiv:2412.18603},
  year={2024}
}

@article{gu2021efficiently,
  title={Efficiently modeling long sequences with structured state spaces},
  author={Gu, Albert and Goel, Karan and R{\'e}, Christopher},
  journal={arXiv preprint arXiv:2111.00396},
  year={2021}
}

@article{borsos2023audiolm,
  title={Audiolm: a language modeling approach to audio generation},
  author={Borsos, Zal{\'a}n and Marinier, Rapha{\"e}l and Vincent, Damien and Kharitonov, Eugene and Pietquin, Olivier and Sharifi, Matt and Roblek, Dominik and Teboul, Olivier and Grangier, David and Tagliasacchi, Marco and others},
  journal={IEEE/ACM transactions on audio, speech, and language processing},
  volume={31},
  pages={2523--2533},
  year={2023},
  publisher={IEEE}
}

@article{defossez2024moshi,
  title={Moshi: a speech-text foundation model for real-time dialogue},
  author={D{\'e}fossez, Alexandre and Mazar{\'e}, Laurent and Orsini, Manu and Royer, Am{\'e}lie and P{\'e}rez, Patrick and J{\'e}gou, Herv{\'e} and Grave, Edouard and Zeghidour, Neil},
  journal={arXiv preprint arXiv:2410.00037},
  year={2024}
}

@article{izsak2021train,
  title={How to train BERT with an academic budget},
  author={Izsak, Peter and Berchansky, Moshe and Levy, Omer},
  journal={arXiv preprint arXiv:2104.07705},
  year={2021}
}

@article{kharitonov2021text,
  title={Text-free prosody-aware generative spoken language modeling},
  author={Kharitonov, Eugene and others},
  journal={arXiv preprint arXiv:2109.03264},
  year={2021}
}

@article{polyak2021speech,
  title={Speech resynthesis from discrete disentangled self-supervised representations},
  author={Polyak, Adam and others},
  journal={arXiv preprint arXiv:2104.00355},
  year={2021}
}

@article{nguyen2022generative,
  title={Generative Spoken Dialogue Language Modeling},
  author={Nguyen, Tu Anh and others},
  journal={arXiv preprint arXiv:2203.16502},
  year={2022}
}

@article{kreuk2021textless,
  title={Textless speech emotion conversion using decomposed and discrete representations},
  author={Kreuk, Felix and others},
  journal={arXiv preprint arXiv:2111.07402},
  year={2021}
}

@article{kharitonov2023speak,
  title={Speak, read and prompt: High-fidelity text-to-speech with minimal supervision},
  author={Kharitonov, Eugene and others},
  journal={Transactions of the Association for Computational Linguistics},
  volume={11},
  pages={1703--1718},
  year={2023},
  publisher={MIT Press One Broadway, 12th Floor, Cambridge, Massachusetts 02142, USA~…}
}

@article{sicherman2023analysing,
  title={Analysing Discrete Self Supervised Speech Representation for Spoken Language Modeling},
  author={Sicherman, Amitay and Adi, Yossi},
  journal={arXiv preprint arXiv:2301.00591},
  year={2023}
}

@article{peng2024mslm,
  title={MSLM-S2ST: A Multitask Speech Language Model for Textless Speech-to-Speech Translation with Speaker Style Preservation},
  author={Peng, Yifan and others},
  journal={arXiv preprint arXiv:2403.12408},
  year={2024}
}

@article{popuri2022enhanced,
  title={Enhanced Direct Speech-to-Speech Translation Using Self-supervised Pre-training and Data Augmentation},
  author={Popuri, Sravya and others},
  journal={arXiv preprint arXiv:2204.02967},
  year={2022}
}


@inproceedings{lee-etal-2022-textless,
  title={Textless Speech-to-Speech Translation on Real Data},
  author={Lee, Ann and others},
  booktitle={NAACL},
  pages={860--872},
  year={2022}
}

@article{bapna2021slam,
  title={SLAM: A unified encoder for speech and language modeling via speech-text joint pre-training},
  author={Bapna, Ankur and others},
  journal={arXiv preprint arXiv:2110.10329},
  year={2021}
}

@article{bapna2022mslam,
  title={mslam: Massively multilingual joint pre-training for speech and text},
  author={Bapna, Ankur and others},
  journal={arXiv preprint arXiv:2202.01374},
  year={2022}
}

@article{cheng2022mu,
  title={Mu$^2$ SLAM: Multitask, Multilingual Speech and Language Models},
  author={Cheng, Yong and others},
  journal={arXiv preprint arXiv:2212.09553},
  year={2022}
}

@article{ao2021speecht5,
  title={Speecht5: Unified-modal encoder-decoder pre-training for spoken language processing},
  author={Ao, Junyi and others},
  journal={arXiv preprint arXiv:2110.07205},
  year={2021}
}

@inproceedings{chen2023maestro,
  title={Maestro-U: Leveraging joint speech-text representation learning for zero supervised speech ASR},
  author={Chen, Zhehuai and others},
  booktitle={2022 IEEE Spoken Language Technology Workshop (SLT)},
  year={2023},
  organization={IEEE}
}

@inproceedings{nachmani2023spoken,
  title={Spoken Question Answering and Speech Continuation Using Spectrogram-Powered LLM},
  author={Nachmani, Eliya and others},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024}
}


@article{fang2024llama,
  title={Llama-omni: Seamless speech interaction with large language models},
  author={Fang, Qingkai and Guo, Shoutao and Zhou, Yan and Ma, Zhengrui and Zhang, Shaolei and Feng, Yang},
  journal={arXiv preprint arXiv:2409.06666},
  year={2024}
}

@article{xie2024mini,
  title={Mini-omni: Language models can hear, talk while thinking in streaming},
  author={Xie, Zhifei and Wu, Changqiao},
  journal={arXiv preprint arXiv:2408.16725},
  year={2024}
}


@misc {kokoro,
	author       = { {Hexgrad} },
	title        = { Kokoro-82M (Revision d8b4fc7) },
	year         = 2025,
	url          = { https://huggingface.co/hexgrad/Kokoro-82M },
	doi          = { 10.57967/hf/4329 },
	publisher    = { Hugging Face }
}

@misc{elmakies2025unsupervisedspeechsegmentationgeneral,
      title={Unsupervised Speech Segmentation: A General Approach Using Speech Language Models}, 
      author={Avishai Elmakies and Omri Abend and Yossi Adi},
      year={2025},
      eprint={2501.03711},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2501.03711}, 
}

@misc{dao2023flashattention2fasterattentionbetter,
      title={FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning}, 
      author={Tri Dao},
      year={2023},
      eprint={2307.08691},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2307.08691}, 
}
@article{FA3,
  title={Flashattention-3: Fast and accurate attention with asynchrony and low-precision},
  author={Shah, Jay and Bikshandi, Ganesh and Zhang, Ying and Thakkar, Vijay and Ramani, Pradeep and Dao, Tri},
  journal={arXiv preprint arXiv:2407.08608},
  year={2024}
}

@inproceedings{li2024flexattention,
  title={Flexattention for efficient high-resolution vision-language models},
  author={Li, Junyan and Chen, Delin and Cai, Tianle and Chen, Peihao and Hong, Yining and Chen, Zhenfang and Shen, Yikang and Gan, Chuang},
  booktitle={European Conference on Computer Vision},
  pages={286--302},
  year={2024},
  organization={Springer}
}

@article{shen2023efficient,
  title={On efficient training of large-scale deep learning models: A literature review},
  author={Shen, Li and Sun, Yan and Yu, Zhiyuan and Ding, Liang and Tian, Xinmei and Tao, Dacheng},
  journal={arXiv preprint arXiv:2304.03589},
  year={2023}
}
@article{hajimolahoseini2023swiftlearn,
  title={SwiftLearn: A Data-Efficient Training Method of Deep Learning Models using Importance Sampling},
  author={Hajimolahoseini, Habib and Awad, Omar Mohamed and Ahmed, Walid and Wen, Austin and Asani, Saina and Hassanpour, Mohammad and Javadi, Farnoosh and Ahmadi, Mehdi and Ataiefard, Foozhan and Liu, Kangling and others},
  journal={arXiv preprint arXiv:2311.15134},
  year={2023}
}
@inproceedings{wang2024greats,
  title={GREATS: Online Selection of High-Quality Data for LLM Training in Every Iteration},
  author={Wang, Jiachen T and Wu, Tong and Song, Dawn and Mittal, Prateek and Jia, Ruoxi},
  booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
  year={2024}
}
@article{rawat2024little,
  title={A Little Help Goes a Long Way: Efficient LLM Training by Leveraging Small LMs},
  author={Rawat, Ankit Singh and Sadhanala, Veeranjaneyulu and Rostamizadeh, Afshin and Chakrabarti, Ayan and Jitkrittum, Wittawat and Feinberg, Vladimir and Kim, Seungyeon and Harutyunyan, Hrayr and Saunshi, Nikunj and Nado, Zachary and others},
  journal={arXiv preprint arXiv:2410.18779},
  year={2024}
}
@article{muhamed2024grass,
  title={Grass: Compute efficient low-memory llm training with structured sparse gradients},
  author={Muhamed, Aashiq and Li, Oscar and Woodruff, David and Diab, Mona and Smith, Virginia},
  journal={arXiv preprint arXiv:2406.17660},
  year={2024}
}
@article{lv2024scalable,
  title={Scalable Efficient Training of Large Language Models with Low-dimensional Projected Attention},
  author={Lv, Xingtai and Ding, Ning and Zhang, Kaiyan and Hua, Ermo and Cui, Ganqu and Zhou, Bowen},
  journal={arXiv preprint arXiv:2411.02063},
  year={2024}
}
@article{neiterman2024layerdropback,
  title={LayerDropBack: A Universally Applicable Approach for Accelerating Training of Deep Networks},
  author={Neiterman, Evgeny Hershkovitch and Ben-Artzi, Gil},
  journal={arXiv preprint arXiv:2412.18027},
  year={2024}
}
@article{warner2024modernbert,
  title={Smarter, better, faster, longer: A modern bidirectional encoder for fast, memory efficient, and long context finetuning and inference},
  author={Warner, Benjamin and Chaffin, Antoine and Clavi{\'e}, Benjamin and Weller, Orion and Hallstr{\"o}m, Oskar and Taghadouini, Said and Gallagher, Alexis and Biswas, Raja and Ladhak, Faisal and Aarsen, Tom and others},
  journal={arXiv preprint arXiv:2412.13663},
  year={2024}
}
@article{li2023flm,
  title={Flm-101b: An open llm and how to train it with \$100 k budget},
  author={Li, Xiang and Yao, Yiqun and Jiang, Xin and Fang, Xuezhi and Meng, Xuying and Fan, Siqi and Han, Peng and Li, Jing and Du, Li and Qin, Bowen and others},
  journal={arXiv preprint arXiv:2309.03852},
  year={2023}
}


@article{baade2024syllablelm,
  title={Syllablelm: Learning coarse semantic units for speech language models},
  author={Baade, Alan and Peng, Puyuan and Harwath, David},
  journal={arXiv preprint arXiv:2410.04029},
  year={2024}
}


@inproceedings{swag,
    title={SWAG: A Large-Scale Adversarial Dataset for Grounded Commonsense Inference},
    author={Zellers, Rowan and Bisk, Yonatan and Schwartz, Roy and Choi, Yejin},
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    year={2018}
}

@inproceedings{hellaswag,
    title={HellaSwag: Can a Machine Really Finish Your Sentence?},
    author={Zellers, Rowan and Holtzman, Ari and Bisk, Yonatan and Farhadi, Ali and Choi, Yejin},
    booktitle ={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
    year={2019}
}

@article{hubert,
  title={Hubert: Self-supervised speech representation learning by masked prediction of hidden units},
  author={Hsu, Wei-Ning and Bolte, Benjamin and Tsai, Yao-Hung Hubert and Lakhotia, Kushal and Salakhutdinov, Ruslan and Mohamed, Abdelrahman},
  journal={IEEE/ACM transactions on audio, speech, and language processing},
  volume={29},
  pages={3451--3460},
  year={2021},
  publisher={IEEE}
}

@article{ctrl,
  title={Ctrl: A conditional transformer language model for controllable generation},
  author={Keskar, Nitish Shirish and McCann, Bryan and Varshney, Lav R and Xiong, Caiming and Socher, Richard},
  journal={arXiv preprint arXiv:1909.05858},
  year={2019}
}

@article{divpo,
  title={Diverse Preference Optimization},
  author={Lanchantin, Jack and Chen, Angelica and Dhuliawala, Shehzaad and Yu, Ping and Weston, Jason and Sukhbaatar, Sainbayar and Kulikov, Ilia},
  journal={arXiv preprint arXiv:2501.18101},
  year={2025}
}

@misc{qwen2025qwen25technicalreport,
      title={Qwen2.5 Technical Report}, 
      author={Qwen and : and An Yang and Baosong Yang and Beichen Zhang and Binyuan Hui and Bo Zheng and Bowen Yu and Chengyuan Li and Dayiheng Liu and Fei Huang and Haoran Wei and Huan Lin and Jian Yang and Jianhong Tu and Jianwei Zhang and Jianxin Yang and Jiaxi Yang and Jingren Zhou and Junyang Lin and Kai Dang and Keming Lu and Keqin Bao and Kexin Yang and Le Yu and Mei Li and Mingfeng Xue and Pei Zhang and Qin Zhu and Rui Men and Runji Lin and Tianhao Li and Tianyi Tang and Tingyu Xia and Xingzhang Ren and Xuancheng Ren and Yang Fan and Yang Su and Yichang Zhang and Yu Wan and Yuqiong Liu and Zeyu Cui and Zhenru Zhang and Zihan Qiu},
      year={2025},
      eprint={2412.15115},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2412.15115}, 
}

@article{loshchilov2017decoupled,
  title={Decoupled weight decay regularization},
  author={Loshchilov, I},
  journal={arXiv preprint arXiv:1711.05101},
  year={2017}
}
@article{dunbar2021zero,
  title={The zero resource speech challenge 2021: Spoken language modelling},
  author={Dunbar, Ewan and Bernard, Mathieu and Hamilakis, Nicolas and Nguyen, Tu Anh and De Seyssel, Maureen and Roz{\'e}, Patricia and Rivi{\`e}re, Morgane and Kharitonov, Eugene and Dupoux, Emmanuel},
  journal={arXiv preprint arXiv:2104.14700},
  year={2021}
}

@article{smollm2,
  title={SmolLM2: When Smol Goes Big--Data-Centric Training of a Small Language Model},
  author={Allal, Loubna Ben and Lozhkov, Anton and Bakouch, Elie and Bl{\'a}zquez, Gabriel Mart{\'\i}n and Penedo, Guilherme and Tunstall, Lewis and Marafioti, Andr{\'e}s and Kydl{\'\i}{\v{c}}ek, Hynek and Lajar{\'\i}n, Agust{\'\i}n Piqueres and Srivastav, Vaibhav and others},
  journal={arXiv preprint arXiv:2502.02737},
  year={2025}
}

@inproceedings{ansel2024pytorch,
  title={Pytorch 2: Faster machine learning through dynamic python bytecode transformation and graph compilation},
  author={Ansel, Jason and Yang, Edward and He, Horace and Gimelshein, Natalia and Jain, Animesh and Voznesensky, Michael and Bao, Bin and Bell, Peter and Berard, David and Burovski, Evgeni and others},
  booktitle={Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2},
  pages={929--947},
  year={2024}
}

@misc{dettmers20228bitoptimizersblockwisequantization,
      title={8-bit Optimizers via Block-wise Quantization}, 
      author={Tim Dettmers and Mike Lewis and Sam Shleifer and Luke Zettlemoyer},
      year={2022},
      eprint={2110.02861},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2110.02861}, 
}

@misc{shazeer2018adafactoradaptivelearningrates,
      title={Adafactor: Adaptive Learning Rates with Sublinear Memory Cost}, 
      author={Noam Shazeer and Mitchell Stern},
      year={2018},
      eprint={1804.04235},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1804.04235}, 
}

@misc{pagliardini2024ademamix,
      title={The AdEMAMix Optimizer: Better, Faster, Older}, 
      author={Matteo Pagliardini and Pierre Ablin and David Grangier},
      year={2024},
      eprint={2409.03137},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2409.03137}, 
}

@misc{chen2023lion,
      title={Symbolic Discovery of Optimization Algorithms}, 
      author={Xiangning Chen and Chen Liang and Da Huang and Esteban Real and Kaiyuan Wang and Yao Liu and Hieu Pham and Xuanyi Dong and Thang Luong and Cho-Jui Hsieh and Yifeng Lu and Quoc V. Le},
      year={2023},
      eprint={2302.06675},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2302.06675}, 
}

@article{mostafazadeh2016corpus,
  title={A corpus and evaluation framework for deeper understanding of commonsense stories},
  author={Mostafazadeh, Nasrin and Chambers, Nathanael and He, Xiaodong and Parikh, Devi and Batra, Dhruv and Vanderwende, Lucy and Kohli, Pushmeet and Allen, James},
  journal={arXiv preprint arXiv:1604.01696},
  year={2016}
}

@inproceedings{radford2023robust,
  title={Robust speech recognition via large-scale weak supervision},
  author={Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and McLeavey, Christine and Sutskever, Ilya},
  booktitle={International conference on machine learning},
  pages={28492--28518},
  year={2023},
  organization={PMLR}
}

@article{hoffmann2022training,
  title={Training compute-optimal large language models},
  author={Hoffmann, Jordan and Borgeaud, Sebastian and Mensch, Arthur and Buchatskaya, Elena and Cai, Trevor and Rutherford, Eliza and Casas, Diego de Las and Hendricks, Lisa Anne and Welbl, Johannes and Clark, Aidan and others},
  journal={arXiv preprint arXiv:2203.15556},
  year={2022}
}

@misc{grattafiori2024llama3herdmodels,
      title={The Llama 3 Herd of Models}, 
      author={LLama, Team},
      year={2024},
      eprint={2407.21783},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2407.21783}, 
}

@article{su2023roformerenhancedtransformerrotary,
  title={Roformer: Enhanced transformer with rotary position embedding},
  author={Su, Jianlin and Ahmed, Murtadha and Lu, Yu and Pan, Shengfeng and Bo, Wen and Liu, Yunfeng},
  journal={Neurocomputing},
  volume={568},
  pages={127063},
  year={2024},
  publisher={Elsevier}
}

@article{roziere2023code,
  title={Code llama: Open foundation models for code},
  author={Roziere, Baptiste and Gehring, Jonas and Gloeckle, Fabian and Sootla, Sten and Gat, Itai and Tan, Xiaoqing Ellen and Adi, Yossi and Liu, Jingyu and Sauvestre, Romain and Remez, Tal and others},
  journal={arXiv preprint arXiv:2308.12950},
  year={2023}
}

@article{weber2024redpajama,
	title   = {RedPajama: an Open Dataset for Training Large Language Models},
	author  = {Maurice Weber and Daniel Y. Fu and Quentin Anthony and Yonatan Oren and Shane Adams and Anton Alexandrov and Xiaozhong Lyu and Huu Nguyen and Xiaozhe Yao and Virginia Adams and Ben Athiwaratkun and Rahul Chalamala and Kezhen Chen and Max Ryabinin and Tri Dao and Percy Liang and Christopher Ré and Irina Rish and Ce Zhang},
	journal = {NeurIPS Datasets and Benchmarks Track},
	year    = 2024,
}

@article{rae2021scaling,
  title={Scaling language models: Methods, analysis \& insights from training gopher},
  author={Rae, Jack W and Borgeaud, Sebastian and Cai, Trevor and Millican, Katie and Hoffmann, Jordan and Song, Francis and Aslanides, John and Henderson, Sarah and Ring, Roman and Young, Susannah and others},
  journal={arXiv preprint arXiv:2112.11446},
  year={2021}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@article{loshchilov2016sgdr,
  title={Sgdr: Stochastic gradient descent with warm restarts},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={arXiv preprint arXiv:1608.03983},
  year={2016}
}

@article{kalamkar2019study,
  title={A study of BFLOAT16 for deep learning training},
  author={Kalamkar, Dhiraj and Mudigere, Dheevatsa and Mellempudi, Naveen and Das, Dipankar and Banerjee, Kunal and Avancha, Sasikanth and Vooturi, Dharma Teja and Jammalamadaka, Nataraj and Huang, Jianyu and Yuen, Hector and others},
  journal={arXiv preprint arXiv:1905.12322},
  year={2019}
}

@article{lv2023adalomo,
  title={Adalomo: Low-memory optimization with adaptive learning rate},
  author={Lv, Kai and Yan, Hang and Guo, Qipeng and Lv, Haijun and Qiu, Xipeng},
  journal={arXiv preprint arXiv:2310.10195},
  year={2023}
}
@inproceedings{wang2021fairseq,
  title={fairseq Sˆ2: A Scalable and Integrable Speech Synthesis Toolkit},
  author={Wang, Changhan and Hsu, Wei-Ning and Adi, Yossi and Polyak, Adam and Lee, Ann and Chen, Peng-Jen and Gu, Jiatao and Pino, Juan},
  booktitle={Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing: System Demonstrations},
  pages={143--152},
  year={2021}
}