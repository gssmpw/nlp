\section{Conclusion and Open Questions}\label{sec:con}

In this paper, we studied the power of convex relaxations for contrastive PAC learning. We showed that even for learning linear representations via contrastive learning, the problem is generally intractable, which is in stark contrast to the classic problem of PAC learning linear models. We then proposed a convex program based on techniques from semi-definite programming. Under a contrastive large-margin condition, we proved that the solution to the convex program enjoys PAC guarantees.

This is the first work that establishes PAC guarantees for contrastive learning for arbitrary domain, while the very recent work is confined to finite domains (and considers a more involved learning scenario). Our convex relaxation techniques seem suitable for the $\ell_2$-distance between contrastive samples. An important question is whether there exists more general approach to dealing with other distance metrics such as the $\ell_1$-distance. We expect that this is possible, since $\ell_1$-norm is closely related to a family of linear functions by introducing additional variables. Another important question is whether it is possible to learn nonlinear representation functions, for example, the family of polynomial threshold functions or neural networks. It appears that one needs to carefully design convex surrogate functions whenever the underlying representation functions are modified. Does there exist a principled approach that guides the design? Lastly, we ask whether it is necessary to consider convex surrogate functions for the problem. In the literature of PAC learning halfspaces, there have been a rich set of algorithmic results showing that one may optimize certain non-convex loss functions whose stationary point really enjoys PAC guarantees. Can we show similar results for contrastive PAC learning? In particular, can we design non-convex loss functions that may serve as a proxy to \eqref{eq:erm-org} and that a good stationary point can be efficiently found? We believe that our work will serve as a first step towards these questions.
