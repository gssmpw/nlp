@inproceedings{Krapels1990SecondLW,
  title={Second Language Writing: An overview of second language writing process research},
  author={Alexandra Rowe Krapels},
  year={1990},
  url={https://api.semanticscholar.org/CorpusID:60659113}
}

@inproceedings{chakrabarty-etal-2022-help,
    title = "Help me write a Poem - Instruction Tuning as a Vehicle for Collaborative Poetry Writing",
    author = "Chakrabarty, Tuhin  and
      Padmakumar, Vishakh  and
      He, He",
    editor = "Goldberg, Yoav  and
      Kozareva, Zornitsa  and
      Zhang, Yue",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.460",
    doi = "10.18653/v1/2022.emnlp-main.460",
    pages = "6848--6863",
    abstract = "Recent work in training large language models (LLMs) to follow natural language instructions has opened up exciting opportunities for natural language interface design. Building on the prior success of large language models in the realm of computer assisted creativity, in this work, we present \textit{CoPoet}, a collaborative poetry writing system, with the goal of to study if LLM{'}s actually improve the quality of the generated content. In contrast to auto-completing a user{'}s text, CoPoet is controlled by user instructions that specify the attributes of the desired text, such as \textit{Write a sentence about {`}love{'}} or \textit{Write a sentence ending in {`}fly{'}}. The core component of our system is a language model fine-tuned on a diverse collection of instructions for poetry writing. Our model is not only competitive to publicly available LLMs trained on instructions (InstructGPT), but also capable of satisfying unseen compositional instructions. A study with 15 qualified crowdworkers shows that users successfully write poems with CoPoet on diverse topics ranging from \textit{Monarchy} to \textit{Climate change}, which are preferred by third-party evaluators over poems written without the system.",
}

@article{chan2017using,
  title={Using keystroke logging to understand writers’ processes on a reading-into-writing test},
  author={Chan, Sathena},
  journal={Language Testing in Asia},
  volume={7},
  pages={1--27},
  year={2017},
  publisher={Springer}
}

@inproceedings{dang2023choice,
  title={Choice over control: How users write with large language models using diegetic and non-diegetic prompting},
  author={Dang, Hai and Goller, Sven and Lehmann, Florian and Buschek, Daniel},
  booktitle={Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
  pages={1--17},
  year={2023}
}

@inproceedings{darcy-etal-2024-aries,
    title = "{ARIES}: A Corpus of Scientific Paper Edits Made in Response to Peer Reviews",
    author = "D{'}Arcy, Mike  and
      Ross, Alexis  and
      Bransom, Erin  and
      Kuehl, Bailey  and
      Bragg, Jonathan  and
      Hope, Tom  and
      Downey, Doug",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.377",
    doi = "10.18653/v1/2024.acl-long.377",
    pages = "6985--7001",
    abstract = "We introduce the task of automatically revising scientific papers based on peer feedback and release ARIES, a dataset of review comments and their corresponding paper edits. The data is drawn from real reviewer-author interactions from computer science, and we provide labels linking each reviewer comment to the specific paper edits made by the author in response. We automatically create a high-precision silver training set, as well as an expert-labeled test set that shows high inter-annotator agreement. In experiments with 10 models covering the state of the art, we find that they struggle even to identify which edits correspond to a comment{---}especially when the relationship between the edit and the comment is indirect and requires reasoning to uncover. We also extensively analyze GPT-4{'}s ability to generate edits given a comment and the original paper. We find that it often succeeds on a superficial level, but tends to rigidly follow the wording of the feedback rather than the underlying intent, and lacks technical details compared to human-written edits.",
}

@article{diederich1974measuring,
  title={Measuring growth in English.},
  author={Diederich, Paul B},
  year={1974},
  publisher={ERIC}
}

@inproceedings{du-etal-2022-understanding-iterative,
    title = "Understanding Iterative Revision from Human-Written Text",
    author = "Du, Wanyu  and
      Raheja, Vipul  and
      Kumar, Dhruv  and
      Kim, Zae Myung  and
      Lopez, Melissa  and
      Kang, Dongyeop",
    editor = "Muresan, Smaranda  and
      Nakov, Preslav  and
      Villavicencio, Aline",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.250",
    doi = "10.18653/v1/2022.acl-long.250",
    pages = "3573--3590",
    abstract = "Writing is, by nature, a strategic, adaptive, and, more importantly, an iterative process. A crucial part of writing is editing and revising the text. Previous works on text revision have focused on defining edit intention taxonomies within a single domain or developing computational models with a single level of edit granularity, such as sentence-level edits, which differ from human{'}s revision cycles. This work describes IteraTeR: the first large-scale, multi-domain, edit-intention annotated corpus of iteratively revised text. In particular, IteraTeR is collected based on a new framework to comprehensively model the iterative text revisions that generalizes to a variety of domains, edit intentions, revision depths, and granularities. When we incorporate our annotated edit intentions, both generative and action-based text revision models significantly improve automatic evaluations. Through our work, we better understand the text revision process, making vital connections between edit intentions and writing quality, enabling the creation of diverse corpora to support computational modeling of iterative text revisions.",
}

@article{f508427a-e4c0-3d6a-8abf-03a5d21ec6c4,
 ISSN = {0010096X},
 URL = {http://www.jstor.org/stable/356600},
 author = {Linda Flower and John R. Hayes},
 journal = {College Composition and Communication},
 number = {4},
 pages = {365--387},
 publisher = {National Council of Teachers of English},
 title = {A Cognitive Process Theory of Writing},
 urldate = {2024-08-20},
 volume = {32},
 year = {1981}
}

@article{ippolito2022creative,
  title={Creative writing with an ai-powered writing assistant: Perspectives from professional writers},
  author={Ippolito, Daphne and Yuan, Ann and Coenen, Andy and Burnam, Sehmon},
  journal={arXiv preprint arXiv:2211.05030},
  year={2022}
}

@article{ito2019diamonds,
  title={Diamonds in the rough: Generating fluent sentences from early-stage drafts for academic writing assistance},
  author={Ito, Takumi and Kuribayashi, Tatsuki and Kobayashi, Hayato and Brassard, Ana and Hagiwara, Masato and Suzuki, Jun and Inui, Kentaro},
  journal={arXiv preprint arXiv:1910.09180},
  year={2019}
}

@inproceedings{jiang-etal-2022-arxivedits,
    title = "ar{X}iv{E}dits: Understanding the Human Revision Process in Scientific Writing",
    author = "Jiang, Chao  and
      Xu, Wei  and
      Stevens, Samuel",
    editor = "Goldberg, Yoav  and
      Kozareva, Zornitsa  and
      Zhang, Yue",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.641",
    doi = "10.18653/v1/2022.emnlp-main.641",
    pages = "9420--9435",
    abstract = "Scientific publications are the primary means to communicate research discoveries, where the writing quality is of crucial importance. However, prior work studying the human editing process in this domain mainly focused on the abstract or introduction sections, resulting in an incomplete picture. In this work, we provide a complete computational framework for studying text revision in scientific writing. We first introduce arXivEdits, a new annotated corpus of 751 full papers from arXiv with gold sentence alignment across their multiple versions of revision, as well as fine-grained span-level edits and their underlying intentions for 1,000 sentence pairs. It supports our data-driven analysis to unveil the common strategies practiced by researchers for revising their papers. To scale up the analysis, we also develop automatic methods to extract revision at document-, sentence-, and word-levels. A neural CRF sentence alignment model trained on our corpus achieves 93.8 F1, enabling the reliable matching of sentences between different versions. We formulate the edit extraction task as a span alignment problem, and our proposed method extracts more fine-grained and explainable edits, compared to the commonly used diff algorithm. An intention classifier trained on our dataset achieves 78.9 F1 on the fine-grained intent classification task. Our data and system are released at tiny.one/arxivedits.",
}

@article{johansson2010looking,
  title={Looking at the keyboard or the monitor: relationship with text production processes},
  author={Johansson, Roger and Wengelin, {\AA}sa and Johansson, Victoria and Holmqvist, Kenneth},
  journal={Reading and writing},
  volume={23},
  pages={835--851},
  year={2010},
  publisher={Springer}
}

@article{jourdan2023text,
  title={Text revision in scientific writing assistance: An overview},
  author={Jourdan, L{\'e}ane and Boudin, Florian and Dufour, Richard and Hernandez, Nicolas},
  journal={arXiv preprint arXiv:2303.16726},
  year={2023}
}

@article{jourdan2024casimir,
  title={CASIMIR: A Corpus of Scientific Articles enhanced with Multiple Author-Integrated Revisions},
  author={Jourdan, L{\'e}ane and Boudin, Florian and Hernandez, Nicolas and Dufour, Richard},
  journal={arXiv preprint arXiv:2403.00241},
  year={2024}
}

@inproceedings{kim-etal-2022-improving,
    title = "Improving Iterative Text Revision by Learning Where to Edit from Other Revision Tasks",
    author = "Kim, Zae Myung  and
      Du, Wanyu  and
      Raheja, Vipul  and
      Kumar, Dhruv  and
      Kang, Dongyeop",
    editor = "Goldberg, Yoav  and
      Kozareva, Zornitsa  and
      Zhang, Yue",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.678",
    doi = "10.18653/v1/2022.emnlp-main.678",
    pages = "9986--9999",
    abstract = "Iterative text revision improves text quality by fixing grammatical errors, rephrasing for better readability or contextual appropriateness, or reorganizing sentence structures throughout a document.Most recent research has focused on understanding and classifying different types of edits in the iterative revision process from human-written text instead of building accurate and robust systems for iterative text revision.In this work, we aim to build an end-to-end text revision system that can iteratively generate helpful edits by explicitly detecting editable spans (where-to-edit) with their corresponding edit intents and then instructing a revision model to revise the detected edit spans.Leveraging datasets from other related text editing NLP tasks, combined with the specification of editable spans, leads our system to more accurately model the process of iterative text refinement, as evidenced by empirical results and human evaluations.Our system significantly outperforms previous baselines on our text revision tasks and other standard text revision tasks, including grammatical error correction, text simplification, sentence fusion, and style transfer.Through extensive qualitative and quantitative analysis, we make vital connections between edit intentions and writing quality, and better computational modeling of iterative text revisions.",
}

@inproceedings{kobayashi-etal-2022-dataset,
    title = "Dataset Construction for Scientific-Document Writing Support by Extracting Related Work Section and Citations from {PDF} Papers",
    author = "Kobayashi, Keita  and
      Koyama, Kohei  and
      Narimatsu, Hiromi  and
      Minami, Yasuhiro",
    editor = "Calzolari, Nicoletta  and
      B{\'e}chet, Fr{\'e}d{\'e}ric  and
      Blache, Philippe  and
      Choukri, Khalid  and
      Cieri, Christopher  and
      Declerck, Thierry  and
      Goggi, Sara  and
      Isahara, Hitoshi  and
      Maegaard, Bente  and
      Mariani, Joseph  and
      Mazo, H{\'e}l{\`e}ne  and
      Odijk, Jan  and
      Piperidis, Stelios",
    booktitle = "Proceedings of the Thirteenth Language Resources and Evaluation Conference",
    month = jun,
    year = "2022",
    address = "Marseille, France",
    publisher = "European Language Resources Association",
    url = "https://aclanthology.org/2022.lrec-1.609",
    pages = "5673--5682",
    abstract = "To augment datasets used for scientific-document writing support research, we extract texts from {``}Related Work{''} sections and citation information in PDF-formatted papers published in English. The previous dataset was constructed entirely with Tex-formatted papers, from which it is easy to extract citation information. However, since many publicly available papers in various fields are provided only in PDF format, a dataset constructed using only Tex papers has limited utility. To resolve this problem, we augment the existing dataset by extracting the titles of sections using the visual features of PDF documents and extracting the Related Work section text using the explicit title information. Since text generated from the figures and footnotes appearing in the extraction target areas is considered noise, we remove instances of such text. Moreover, we map the cited paper{'}s information obtained using existing tools to citation marks detected by regular expression rules, resulting in pairs of cited paper information and text of the Related Work section. By evaluating body text extraction and citation mapping in the constructed dataset, the accuracy of the proposed dataset was found to be close to that of the previous dataset. Accordingly, we demonstrated the possibility of building a significantly augmented dataset.",
}

@article{koo2023decoding,
  title={Decoding the End-to-end Writing Trajectory in Scholarly Manuscripts},
  author={Koo, Ryan and Martin, Anna and Wang, Linghe and Kang, Dongyeop},
  journal={arXiv preprint arXiv:2304.00121},
  year={2023}
}

@article{kuznetsov2022revise,
  title={Revise and resubmit: An intertextual model of text-based collaboration in peer review},
  author={Kuznetsov, Ilia and Buchmann, Jan and Eichler, Max and Gurevych, Iryna},
  journal={Computational Linguistics},
  volume={48},
  number={4},
  pages={949--986},
  year={2022},
  publisher={MIT Press One Broadway, 12th Floor, Cambridge, Massachusetts 02142, USA~…}
}

@article{leijten2013keystroke,
  title={Keystroke logging in writing research: Using Inputlog to analyze and visualize writing processes},
  author={Leijten, Mari{\"e}lle and Van Waes, Luuk},
  journal={Written Communication},
  volume={30},
  number={3},
  pages={358--392},
  year={2013},
  publisher={Sage Publications Sage CA: Los Angeles, CA}
}

@book{lindgren2019observing,
  title={Observing writing: Insights from keystroke logging and handwriting},
  author={Lindgren, Eva and Sullivan, Kirk},
  volume={38},
  year={2019},
  publisher={Brill}
}

@article{macarthur2016writing,
  title={Writing research from a cognitive perspective.},
  author={MacArthur, Charles A and Graham, Steve},
  year={2016},
  publisher={The Guilford Press}
}

@inproceedings{mirowski2023co,
  title={Co-writing screenplays and theatre scripts with language models: Evaluation by industry professionals},
  author={Mirowski, Piotr and Mathewson, Kory W and Pittman, Jaylen and Evans, Richard},
  booktitle={Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
  pages={1--34},
  year={2023}
}

@article{mita2022towards,
  title={Towards automated document revision: Grammatical error correction, fluency edits, and beyond},
  author={Mita, Masato and Sakaguchi, Keisuke and Hagiwara, Masato and Mizumoto, Tomoya and Suzuki, Jun and Inui, Kentaro},
  journal={arXiv preprint arXiv:2205.11484},
  year={2022}
}

@inproceedings{narimatsu2021task,
  title={Task definition and integration for scientific-document writing support},
  author={Narimatsu, Hiromi and Koyama, Kohei and Dohsaka, Kohji and Higashinaka, Ryuichiro and Minami, Yasuhiro and Taira, Hirotoshi},
  booktitle={Proceedings of the Second Workshop on Scholarly Document Processing},
  pages={18--26},
  year={2021}
}

@article{perl1979composing,
  title={The composing processes of unskilled college writers},
  author={Perl, Sondra},
  journal={Research in the Teaching of English},
  volume={13},
  number={4},
  pages={317--336},
  year={1979},
  publisher={ncte. org}
}

@inproceedings{pinto2023large,
  title={Large language models for education: Grading open-ended questions using chatgpt},
  author={Pinto, Gustavo and Cardoso-Pereira, Isadora and Monteiro, Danilo and Lucena, Danilo and Souza, Alberto and Gama, Kiev},
  booktitle={Proceedings of the XXXVII Brazilian Symposium on Software Engineering},
  pages={293--302},
  year={2023}
}

@inproceedings{raheja-etal-2023-coedit,
    title = "{C}o{E}d{IT}: Text Editing by Task-Specific Instruction Tuning",
    author = "Raheja, Vipul  and
      Kumar, Dhruv  and
      Koo, Ryan  and
      Kang, Dongyeop",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-emnlp.350",
    doi = "10.18653/v1/2023.findings-emnlp.350",
    pages = "5274--5291",
    abstract = "We introduce CoEdIT, a state-of-the-art text editing system for writing assistance. CoEdIT takes instructions from the user specifying the attributes of the desired text, such as {``}Make the sentence simpler{''} or {``}Write it in a more neutral style,{''} and outputs the edited text. We present a large language model fine-tuned on a diverse collection of task-specific instructions for text editing (a total of 82K instructions). Our model (1) achieves state-of-the-art performance on various text editing benchmarks, (2) is competitive with publicly available largest-sized LLMs trained on instructions while being {\textasciitilde}60x smaller, (3) is capable of generalizing to unseen edit instructions, and (4) exhibits abilities to generalize to composite instructions containing different combinations of edit actions. Through extensive qualitative and quantitative analysis, we show that writers prefer the edits suggested by CoEdIT relative to other state-of-the-art text editing models. Our code, data, and models are publicly available at https://github.com/vipulraheja/coedit.",
}

@inproceedings{yuan2022wordcraft,
  title={Wordcraft: story writing with large language models},
  author={Yuan, Ann and Coenen, Andy and Reif, Emily and Ippolito, Daphne},
  booktitle={Proceedings of the 27th International Conference on Intelligent User Interfaces},
  pages={841--852},
  year={2022}
}

