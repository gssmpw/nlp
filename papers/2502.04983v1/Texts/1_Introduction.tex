\section{Introduction}
{Interactive scenes combine} %2D interactive scene combines 
artistic visuals with interactive elements, allowing users to immerse themselves in a richly crafted environment{. They} %, which 
are widely used in various scenarios, including video games \cite{supermario, tetris, zelda}, educational tools \cite{khanacademy, scratch}, and interactive demonstrations \cite{phET, exploratorium}. {Creating} %While it serve as a vibrant canvas for creativity and engagement, creating 2D 
interactive scenes {often} involves coding with engines like Unity \cite{unity}, or frameworks like Phaser \cite{phaser}, requiring skills in scripting interactivity, managing animations, and debugging. This complexity %can be difficult for beginners but 
is crucial for delivering engaging user experiences {but can be difficult for beginners} \yh{\cite{myers2008designers,kazi2014kitty, zhang2020flowmatic, yang2024gpt, sweetser2024large}}.

Recently, Large Language Models (LLMs) like ChatGPT \cite{openai_chatgpt} have emerged as powerful {tools} %resources 
for users, enabling them to generate code {given} %with given 
natural text as input. {They} %It 
can assist users in writing scripts \cite{de2024llmr}, creating {simple} animations \cite{lan2023application}, and even debugging \cite{zhang2023critical}, significantly reducing the time and effort required for coding tasks \cite{tian2023chatgpt}. Some ad-hoc tools for code generation and refinement \yh{\cite{github_copilot,jupyter, codepen, glitch, claud_artifacts}} have also been proposed to provide real-time suggestions. 

However, {directly using LLMs to generate code for interactive scenes}
% it \hbc{what does "it" refer to? coding with such tools} 
may have four main {issues:}
% challenges: 
1) \textbf{code quality} -- %\pfc{two-level colons?}\yhc{what do you mean? two-level columns?}\pfc{too many `:' symbols...refine the format if possible}\yhc{updated} 
{LLM-based code generation approaches}
% \hb{these tools} %it
may produce incomplete or incorrect code sometimes \cite{li2022competition,nijkamp2022codegen,roziere2023code}. {They} %These tools 
often require a clear context to generate relevant code, which may be challenging in complex projects. {Generating} %For generating 2D 
interactive scenes %, it 
usually requires scripting how elements in {a} scene 
interact with each other and how users {interact} %interactive 
with the scene. The logic and relationship can become complex, especially when multiple elements are involved. {The generated code tends to be error-prone, so users need to provide extra text input to refine it.}
% It leads to be more prone to error in generated code\pfc{`The generated code tends to be error-prone' or `It tends to be error-prone in generating code'?}. 
% In this case, users have needs\pfc{`have need'to `need'?} to provide extra text input to refine it\pfc{`it' refers to `the generated code'?}. 
2) \textbf{lack of {editing} independency} -- the linear conversational nature of LLMs limits independent editing of individual elements\yh{, especially for non-expert users \cite{zamfirescu2023johnny}}. 
The model{s} may forget previous interactions, leading to disjointed responses, {especially when the conversation is long and involves many {scene} elements}. \yh{The modular code generation and refinement in emerging AI tools often require understanding project and code structures for hard modularization, otherwise the updated results may intertwine codes across other files to produce unintended modification.}
% Managing the state{s}, interactions, and relationships of multiple elements in a {scene} 
% often requires ongoing context about their current status and interactions. However, the linear conversation may fail to capture the dynamic nature of these states, leading to logical errors in the generated code. 
3) \textbf{lack of graphical control} -- %\pfc{a minor comment: inconsistent style, see 1) and 2)}\yhc{updated} 
{it is difficult} to directly integrate graphical information into the text input. {Users} need to manually estimate the {exact} 
graphical information (e.g., position, size, path, region) and translate it into textual input, which is not intuitive and direct \cite{masson2024directgpt}. %\yhc{do i need to add the point that GPT requries to input text to refine and "lack of precise control" (using sliders to adjust effects) here?}\hbc{Yes, since this feature is considered as part of our contribution.} 
{4) \textbf{lack of precise control} -- fine modifications on the generated effects (e.g., effect parameters) require users to adjust text prompts iteratively \yh{\cite{dang2022prompt}}, which usually traverse users between excessive and inadequate controlling.}

By reviewing videos on using LLMs to create interactive scenes and comparing existing tools on code generation using content analysis \cite{harwood2003overview}, we identified the challenges of applying existing tools for generating codes for 2D dynamic and interactive scenes. Based on the insights, we design and develop \sysName, an interactive system for creating interactive scenes using modular LLM and graphical control without coding. To enable independent code generation for individual {scene} elements, %in the scene, 
we \yh{integrate an \emph{element-level modularization}}
% \hbc{\emph{element-level modularization}?} 
{technique}, which {maintains} %opens 
independent LLM modules for {individual elements}, %each element, 
where users can input text descriptions to generate class codes for the element features and actions. On top of individual modules, a central LLM module manages the relationships and interactions of all the elements. 
To avoid {the central module's lack of} context-specific details, we guide LLM to {distill}
% generate 
contextual information about the variables and functions along with the generated code for individual elements. So the central LLM can generate correct and desired interaction code based on the contextual information. We implement this concept in the \sysName~system, a graphical interface for users {to create} %creating 
2D interactive scenes using modular LLM and graphical control. In \sysName, users draw/import their prepared elements or ask the system to generate elements and then input the text for each element and multiple-element interaction separately. Four types of graphical proxy, including point, line, curve, and region, can be specified by direct pointing and drawing, and then %can 
be explicitly mentioned in the text prompt. The positions, \yh{orientations},
% \pfc{orientations}, 
and sizes of elements can be adjusted manually and %automatically 
integrated {into} the generated code {automatically}. Our system automatically generates sliders from the code for users {to interactively adjust the} %' adjusting 
parameters of the effects in the code, {to reduce the text description input}. \yh{{A comparative study}
% Two evaluations 
%\hbc{What are those two evalutions? Better to be more explicit} 
shows %From the two evaluations
%\hbc{what are two evaluations?}, we found 
that \sysName~outperforms \yh{{a state-of-the-art} %an 
AI coding tool, Cursor Composer}} %, as the baseline system}}
% the baseline system Cursor}
%\pfc{explain what cursor is?}
% \yhc{only mention "baseline system Cursor" here?} 
in \yh{creating interactive scenes}
% generating codes 
for fixed tasks{. An open-ended study demonstrates \sysName} {enables users to} %, and users can 
create diverse 2D games, animations, and demonstrations easily.

This work makes the following main contributions:
\begin{itemize}
\item{A content analysis
% \pfc{content analysis or context analysis?} 
of video tutorials on creating interactive scenes using ChatGPT and existing AI tools for code generation.}
\item{\yh{The integration of \emph{element-level modularization}}
% A novel {technique}
% % concept 
% {of} \emph{modularization} 
for controlling independent code generation for individual elements in individual LLM modules, as well as interaction generation and overall management for all elements based on element context in the central module.}
\item{A graphical interface allowing users to create interactive scenes by inputting text prompts to modular LLMs, integrating graphical information into prompts directly, and iteratively adjusting generation results and parameters using {additional text inputs} %text 
and sliders precisely.}
\item{Two evaluations that compare the performance of {\sysName} and \yh{Cursor Composer} and {validate} the system usability.
% of \pf{target} users.
}
\end{itemize}








