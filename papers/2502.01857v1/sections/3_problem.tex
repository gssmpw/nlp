This paper addresses a human-robot cooperative navigation task under incomplete information. The remote human operator possesses an outdated map of the environment, while the robot can acquire accurate local observations. The human provides navigation guidance, and the robot communicates environmental updates. Together, they aim to reach a set of goal locations as efficiently as possible.

We design a simulated maze environment, \emph{CoNav-Maze}, adapted from MemoryMaze~\cite{pasukonis2022evaluating} to study this setting. In CoNav-Maze, the robot has perfect knowledge of its position and uses motion primitives to navigate between adjacent grid cells. This setup abstracts away low-level control and estimation errors, focusing on high-level human-robot coordination.

Formally, the environment is modeled as a Markov Decision Process (MDP) defined by the tuple $(\Scal, \Acal, T, R_\mathrm{env}, \gamma)$. \( \mathcal{S} \) is a product space comprising the robot’s discrete finite state and the set of remaining goal locations, capturing both its position and task progress. $\Acal$ is a finite set of actions, including movement to adjacent grids and transmitting a first-person image from one of eight evenly spaced camera angles. $T: \mathcal{S} \times \mathcal{A} \to \mathcal{S}$ is a deterministic transition function. $R_\mathrm{env}: \mathcal{S} \to \mathbb{R}$: is a real-valued reward function. $\gamma \in [0, 1)$ is a discount factor.

At each step $t$, the robot collects a local observation of nearby traversable and blocked cells within a radius $r$. It may also receive a human-provided trajectory $\zeta_t$. The robot then selects an action $a_t$ to either move or transmit an image.

The human operator starts with an inaccurate global map $x \in \mathcal{X}$, representing traversable and blocked cells. By analyzing the robot’s trajectory and image transmissions, the human refines their map to provide more accurate guidance.