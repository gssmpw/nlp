\begin{figure*}[t]
    \centering
    \vskip -0.05in
    \includegraphics[width=\linewidth]{figures/main.pdf}
    \vskip -0.1in
    \caption{We enable efficient human-robot collaboration in a shared maze navigation setting. \textbf{Left:} The robot and human have incomplete knowledge of the environment. The robot gathers local observations through its sensors, while the human relies on an imprecise global map. The robot can transmit images to improve the human’s understanding of the environment, while the human assists by suggesting paths. \textbf{Right:} Our study includes: (1) Crowdsourcing a dataset to capture how a human operator’s perception evolves as the robot shares information. (2) Training a human perception dynamics model to estimate this process, enabling us to quantify the expected information gain from a robot's message. (3) Developing Information Gain Monte Carlo Tree Search (IG-MCTS), a planning algorithm that balances task progress with informative communication. (4) Conducting a human study where both eye-tracking and task performance metrics validate the effectiveness of our approach.}
    \label{fig:overview_figure}
    \vskip -0.1in
\end{figure*}

In novel environments, autonomous robots often face a ``cold-start" problem, where they lack prior knowledge about the surroundings. Without human guidance, the robot may make inefficient or suboptimal decisions, wasting time and resources while exploring. Human operators can provide guidance to help robots overcome this limitation. Beyond improving efficiency, human involvement is essential for addressing safety, ethical, and moral considerations~\cite{sterz2024quest,van2020allocation,van2021moral}.
% Autonomous robots, such as those employing motion planning algorithms, often miss the guidance and information humans can offer, potentially leading to inefficient task completion. \vivian{see motivation example}. 

% describe and justify the problem
Collaboration between humans and robots in environments under incomplete information presents a realistic and challenging problem.
% why realistic: 
Humans and robots often receive information from distinct sources. While they may synchronize their knowledge in static, offline settings, maintaining this synchronization becomes increasingly difficult in dynamic or unfamiliar environments, where sudden changes can quickly render the initial synchronization inaccurate.
% why challenging: 
The challenge lies in enabling robots to achieve effective human-robot synergy by leveraging human knowledge to complement the robot’s local observations.
% why important:
Such robots hold the potential to assist human operators in search-and-rescue missions~\cite{doroodgar2010search,nourbakhsh2005human} and support individuals with disabilities in daily tasks~\cite{jain2019probabilistic,gopinath2016human}.
% specific problem
% We focus on the navigation version of this challenge, referred to as human-robot cooperative navigation.


% current gaps
% Existing approaches to robot control span the spectrum from fully autonomous to fully human-controlled, each with its respective limitations. 
% Current robot control approaches involving human differ by the degree of human control needed and the amount of communication bandwidth used.
% Teleoperation, on the other hand, relies heavily on low-level human inputs, which can lead to cognitive overload and delayed decision-making, particularly in time-sensitive scenarios. 
% Approaches like instruction-following, which allow robots to execute tasks based on human-provided high-level plans. 
% What is needed is an approach that lies in the middle of the spectrum, enabling robots to coordinate effectively with their human partners by fully leveraging the combined information from both.
Current human-in-the-loop robot control approaches differ in the degree of control required and the communication bandwidth utilized. Teleoperation relies on low-level human inputs, leading to high cognitive load and communication demands~\cite{moniruzzaman2022teleoperation}. Instruction-following, in contrast, reduces direct human control by allowing robots to execute high-level human plans \cite{anderson2018vision}. However, this approach still requires substantial communication for the human to provide detailed and accurate instructions. These limitations highlight the need for a more autonomous approach that reduces human workload while maintaining effective collaboration.


% problem
This paper studies the human-robot cooperative navigation problem in a simulated environment called \emph{CoNav-Maze}, where the robot obtains local SLAM observations while the human provides guidance based on an initially inaccurate global map. The goal is to develop a control algorithm that does not merely follow instructions but actively collaborates by transmitting images to improve the human's understanding of the environment, integrating human trajectory guidance, and maintaining sufficient autonomy to reach target locations efficiently.

% first say we propose a MCTS-based algorithm with the objective of maximizing human's info gain
Therefore, we introduce \emph{Information Gain Monte Carlo Tree Search} (IG-MCTS), an online planning algorithm that embodies the idea that \emph{communication is action}. Aside from task-centric objectives, IG-MCTS strategically decides between movement and communication actions based on their potential to enhance the human’s understanding of the environment.
% maximizes the human’s information gain during collaboration. 
Inspired by evidence that humans read to minimize perceptual errors and extract relevant features under limited processing capacity~\cite{kangassalo2020information}, we hypothesize that a similar cognitive strategy applies to visual tasks.
To align with this cognitive pattern, IG-MCTS chooses camera angles that maximize an information reward that measures the change in the human's perception of the environment.
IG-MCTS also incorporates human-guided trajectories as reward augmentations~\cite{chen2025human}.


% human perception dynamics model
% To compute information gain effectively, our approach requires a human belief dynamics model that predicts how humans update their understanding based on the robot’s observations and communications. 
At the core of IG-MCTS is a data-driven human perception dynamics model that predicts how humans update their understanding of the environment in response to the robot’s actions. We introduce a fully convolutional neural network (FCNN) that unifies the effects of both robot movements and communication while incorporating spatial structure and contextual awareness.
To train this model, we crowdsource a dataset of human-robot interactions in CoNav-Maze, capturing human information-processing patterns in navigation tasks. The model learns to estimate the human operator’s evolving perception by fitting to human annotations. Evaluation results show that the FCNN-based approach achieves higher prediction accuracy than a psychometric function-based model~\cite{treutwein1999fitting}.

% experiment and key results
We evaluate the performance of IG-MCTS in CoNav-Maze against two baselines: teleoperation and instruction-following. 
A user study with $10$ eye-tracked participants shows that interacting with the IG-MCTS robot significantly reduces communication demands while yielding eye-tracking metrics indicative of lower cognitive load, all while maintaining task performance on par with the baselines.