
%In this study, we introduce the Hierarchical Tool Stacking Strategy (HTSS) to enhance the tool invocation process for large language models (LLMs) in chemistry-related tasks. Our approach addresses key limitations in existing methodologies, particularly the inability of LLMs to effectively integrate and synergize multiple specialized tools. By establishing a two-stage optimization framework—comprising initial tool screening and progressive tool stacking, we demonstrate that HTSS significantly improves computational efficiency and task completion accuracy across various chemistry applications, including molecule design, property prediction, and reaction prediction.
%Our findings indicate that tool stacking is a critical factor in enhancing the computational reasoning of LLMs. Specifically, we identify four advanced patterns of tool stacking, highlighting the nonlinear performance gains achieved as stacking depth increases. Moreover, the discovery of Optimal Stacking Pathways (OSP) suggests that systematic optimization of tool selection and arrangement can yield substantial improvements over baseline approaches. These insights pave the way for further exploration of automated tool integration strategies, potentially enabling LLMs to tackle even more complex scientific challenges.
Our study proposes \textbf{ChemHTS}, a hierarchical tool stacking method to enhance tool utilization in LLM-driven chemistry tasks. By addressing key challenges such as bias from single tool calls and lack of tool collaboration, ChemHTS improves reasoning and computational efficiency.
Experiments across four chemistry tasks show that ChemHTS outperforms both general LLMs and chemistry-specific models. Additionally, we identify four tool stacking behavioral patterns—Correct, Modify, Judge, and Reserve—which enhance interpretability.
In summary, our work highlights the importance of tool collaboration in scientific AI, providing a systematic framework for optimizing LLM-agent interactions in chemistry.

\section*{Limitations}
Despite the promising results of ChemHTS in optimizing tool invocation pathways for chemical tasks, several limitations remain. First, the method relies on predefined toolsets, which may not generalize well to novel or underrepresented chemistry tasks. Expanding the adaptability of ChemHTS to dynamically incorporate new tools remains an open challenge. Second, the hierarchical stacking strategy assumes that optimal tool combinations can be effectively learned from limited training data, yet real-world chemistry problems often require extensive domain expertise, which LLMs may struggle to acquire solely through tool interactions. Finally, while ChemHTS improves tool collaboration, its computational cost increases with the number of tool-stacking layers, potentially limiting its scalability in large-scale applications. Future work should explore more efficient optimization strategies and adaptive learning mechanisms to enhance both generalizability and efficiency.
