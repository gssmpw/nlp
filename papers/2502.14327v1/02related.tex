\subsection{Large Language Models for Chemistry}
%化学agent，大语言模型（LLMs）在化学领域展现出巨大的潜力，被广泛应用于分子生成、性质预测、反应建模、逆合成分析等任务。例如，ChemDFM模型通过在化学文献和教科书上进行预训练，并使用大量指令进行微调，提升了多种化学任务上的表现。论文2介绍了一个名为ChemCrow的新型大型语言模型（LLM）驱动的化学助手，它通过整合多种专家设计的化学工具来增强LLM在化学领域的表现。
%尽管 LLM 已展现出强大的潜力，但它们在应对复杂的化学计算任务时仍存在诸多局限性。即使通过微调（fine-tuning）或指令调控，LLMs 仍难以适应高度复杂或需要精确计算的化学任务，且其泛化能力在面对不同化学任务时表现出不足。并且LLM 无法高效调用现有的化学计算工具，如SMILES 解析工具、分子动力学模拟工具等，更无法有效探索和利用工具之间的组合和堆叠关系。

Large language models (LLMs) have demonstrated significant potential in chemistry, with applications spanning molecular generation, property prediction, reaction modeling, and retrosynthetic analysis~\cite{fang2024molinstructionslargescalebiomolecularinstruction,tang2024prioritizingsafeguardingautonomyrisks,liao2024wordsmoleculessurveylarge}. For instance, the ChemDFM ~\cite{zhao2024chemdfmlargelanguagefoundation} pretrained on chemical literature and textbooks and further refined through extensive instruction tuning, has exhibited enhanced performance across various chemical tasks. Similarly, ChemCrow~\cite{bran2023chemcrowaugmentinglargelanguagemodels}, an LLM-powered chemistry assistant, integrates multiple expert-designed chemical tools to improve LLM performance in chemistry-related applications.Despite these advancements, LLMs continue to face challenges in handling complex chemical computations and generalizing across diverse chemical problems~\cite{ouyang2024structuredchemistryreasoninglarge,han2024generalistspecialistsurveylarge}. Moreover, they remain inefficient in utilizing existing computational chemistry tools~\cite{shi2023relmleveraginglanguagemodels}, and struggle to navigate the combinatorial and hierarchical relationships between these tools.

\subsection{Tool-augmented LLMs}
LLMs~\cite{anil2023palm,achiam2023gpt,touvron2023llama} have demonstrated strong reasoning capabilities in natural language processing and scientific computing. However, they face limitations in specialized tasks in fields such as chemistry and physics~\cite{yang2024moosechemlargelanguagemodels}, including constrained computational accuracy, insufficient numerical reasoning abilities, and a lack of collaboration with external tools. To address these shortcomings, researchers have recently proposed the tool-augmented LLMs approach~\cite{qin2023toolllmfacilitatinglargelanguage,wang2024gtabenchmarkgeneraltool,yang2023autogptonlinedecisionmaking}, enabling LLMs to dynamically call external tools and thereby enhance their task execution capabilities.
Representative methods include ReAct~\cite{yao2023reactsynergizingreasoningacting}, which combines chain-of-thought reasoning (CoT)~\cite{wei2023chainofthoughtpromptingelicitsreasoning} with tool invocation to allow LLMs to dynamically acquire external information during decision-making, and Toolformer~\cite{schick2023toolformerlanguagemodelsteach}, which enables LLMs to autonomously decide when to call tools, improving the accuracy of computational tasks. 
Despite these advancements, existing research primarily focuses on single-tool invocation and has yet to explore hierarchical combinations of tools. A single tool is often insufficient to solve complex scientific problems, whereas the collaborative invocation of multiple tools holds promise for enhancing the reasoning capabilities of LLMs in chemical tasks.