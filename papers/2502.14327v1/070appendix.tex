\input{figures/appenx_name_1}

\section{Stacking Agent Details}
\label{Stacking Agent Details}
\input{tables/apendix_molecule_design}
We conducted several experiments and selected three optimal hierarchical stacking toolsets, and now we will present the stacking results and scores for each stacking agent in the Tab.~\ref{tab:appendix_molecule_design}, along with the corresponding prompts:
\subsection{Stacking Agent}
\subsubsection{Prompt}
Our Agent framework is based on the ReAct method~\cite{yao2023reactsynergizingreasoningacting} to implement tool  and reasoning processes. 
\subsubsection{Naming Rule}
To facilitate the comprehension of Hierarchical-Tool-Stacking, we propose a systematic hierarchical naming rules as follows in Fig.~\ref{fig:appendix_name}. In addition, in order to prevent the tool name from affecting the agent call, we choose to anonymously process the agent tool, that is, \{task name\}\_\{num\}.
\begin{itemize}
    \item \textbf{Self-Stacking Tools}: Hierarchical proxies are constructed through a recursive generation strategy, with the depth of the hierarchy dynamically extendable via the numerical suffix. For instance in Fig.~\ref{fig:appendix_name}, "["Name2SMILES\_0"]" denotes the base tool, while "["Name2SMILES\_1"]" signifies a first-layer tool, referred to as an Agent Tool (which encapsulates both the tool and the Agent into a new tool) and "["ChemDFM\_2"]".

    \item \textbf{Multiple Tool Combinations}: The combination of multiple tools within an Agent is represented in a list format, utilizing depth-first traversal to generate sub-tools, thereby forming the final toolset for the agent. For example in Fig.~\ref{fig:appendix_name}, the structure "["Name2SMILES\_1", "ChemDFM\_2"]" represents a flat structure with tools at the same level ([A, B, ...]), while the structure "[['Name2SMILES\_0','ChemDFM\_1'],'Nam
    e2SMILES\_1','ChemDFM\_0']" illustrates a nested structure ([[A, B], C, D]), where tools A and B are first combined before being integrated with tool C and D.
\end{itemize}



% 本系统采用层级化命名规则实现化学信息处理工具的灵活组合。具体而言，每个工具标识符采用"工具名称_嵌套层级"的命名格式（如"Name2SMILES_2"），其中下划线后的数字表示代理工具的嵌套深度，
% 1. 工具自我叠加：通过递归生成策略构建层级化代理，层级深度可通过数字后缀动态扩展。例如，Name2SMILES_0表示基础工具，Name2SMILES_1表示包含基础工具的一级代理，即Agent Tool（将工具和Agent共同封装为一个新的工具）。
% 2. 复合工具组合： 通过列表的形式来表示Agent的多工具组合，采用深度优先遍历生成子工具，形成最终的复合工具叠加。如图中"["Name2SMILES_1", "ChemDFM_2"]([A,B,...]平级结构)"和"[['Name2SMILES_0','ChemDFM_1'],'Name2SMILES_1']"([[A,B],C]嵌套结构，先组合工具A和B，再与工具C组合)

\subsection{Text-based Molecule Design}
\subsubsection{Task Introduction}
The test set of ChEBI-20-MM is exploited for this task in ChemLLMBench. Models are asked to predict the SMILES of the molecule that fits the given description. Considering the low accuracy of the models, we use BLEU-2 as the training metric and use metrics such as Exact, Dis and others during the testing stage.
\subsubsection{Prompt}
We use a simpler prompt compared with the prompt introduced in \cite{guo2023largelanguagemodelschemistry}
\begin{tcolorbox}[colback=gray!10, colframe=black, title=Prompt: Text-based Molecule Design]
You are an expert chemist. Given the molecular requirements description, your task is to design a new molecule SMILES:\\
Molecular requirements description::
\end{tcolorbox}
\subsection{Molecule Captioning}
\subsubsection{Task Introduction}
The test set  is the same with the Text-based Molecule Design task. Because this is the mirroring task, which generates a detailed description by giving a SMILES to the models. In this task, we also choose the BLEU-2 as the metric in the training stage. When in the test stage, more metrics, like BLEU and ROUGE, are utilized to Measure the performance of the model.
\subsubsection{Prompt}
We also use a simpler prompt compared with the prompt introduced in \cite{guo2023largelanguagemodelschemistry}
\begin{tcolorbox}[colback=gray!10, colframe=black, title=Prompt: Molecule Captioning]
You are an expert chemist. Given the molecular SMILES, your task is to provide the detailed description((The molecule is ...) of the molecule. \\Please strictly follow the format, no other information can be provided.\\Molecular SMILES:
\end{tcolorbox}

\subsection{Molecular Property Prediction}
\subsubsection{Task Introduction}
The molecular property prediction tasks in ChemLLMBench consist of five tasks from MoleculeNet benchmark~\cite{wu2018moleculenetbenchmarkmolecularmachine}, including BACE, BBBP, HIV, ClinTox, and Tox21. Among these, BACE and BBBP are balanced binary classification tasks, while HIV represents an unbalanced binary classification task. ClinTox consists of 2 unbalanced binary classification tasks, and Tox21 comprises 21 unbalanced binary classification tasks. In this task, we choose the AUC-ROC as the first metric in the training stage. Considering the calculation method of AUC-ROC for large language models, we also introduced Accuracy as a second metric for test stage.
\subsubsection{Prompt}
We use the same prompts introduced in ~\cite{guo2023largelanguagemodelschemistry}

\subsection{Reaction Prediction}
\subsubsection{Task Introduction}
The reaction prediction task asks the model to predict the product of the given reaction. ChemLLMBench utilizes the USPTO-MIT dataset for this task. Since the benchmark metric is Accuracy, we also chose Accuracy as the training metric, and considering that the answer is also SMILES, we adopted the same metric as Molecular Design task for measurement during the testing stage.
\subsubsection{Prompt}
We reformat the prompt provided ~\cite{guo2023largelanguagemodelschemistry}.
\begin{tcolorbox}[colback=gray!10, colframe=black, title=Prompt: Reaction Prediction]
Given an incomplete chemical reaction equation in SMILES notation (format: reactants>>product, where multiple reactants are separated by dots '.'), predict and complete the missing products marked as '\_\_\_'. The response should only contain the only one SMILES representation of the missing molecule, without any additional explanation (Note: Please only output only one final product). Please answer the question based on the following Chemical reaction equation:
\end{tcolorbox}

\section{Multi-agent Implementation Details}

In this section, we will discuss how to implement multi-agent systems and specific ways of information transmission, including chain, random, star, full-connected, layered, and debate graphs.

\subsection{Framework}
\label{Framework}
In order to complete chemical tasks, we divided multi-agent into two types: agents with tools and agents without tools, and tested them on the first task, the Text-based Molecule Design task. The overall of our multi-agent framework is a modification of the framework of ~\cite{zhang2024cutcrapeconomicalcommunication} and ~\cite{qian2024scalinglargelanguagemodelbasedmultiagentcollaboration} that utilized different spatial and temporal masks to complete in the following six multi-agent structures: Chain, Random, FullConnected, Layered, Star and Debate mode. \\
However, since we are modifying their approach with a greater focus on information transmission and are also limited by API calls, we can only make a one-sided comparison regarding the recording of tokens and time.
\subsection{Implementation Details}
In multi-agent systems, information transmission is a critical factor for enhancing performance. By utilizing various structures, information can be conveyed through multiple pathways. To improve the efficiency of information collection, we have adopted the Final decision approach. Specifically, at the end of all structures, we have integrated a FinalRefer Agent to perform the final summary and decision-making. The FinalRefer prompt is followed:
\begin{tcolorbox}[colback=gray!10, colframe=black, title=Prompt: FinalRefer]
You are a strategic planning and final integration agent. You will be given a graduate-level question and reasoning outputs from all other agents.
Your task is to integrate all the information into a single, cohesive answer with detailed reasoning and evidence.\\
Your final output should:
1. Summarize the contributions from all agents, highlighting key insights.\\
3. Provide the final answer with a clear and detailed explanation.\\
4. Conclude with the final answer on a new line with the format: "The final answer is 'SMILES'\\
Here is the question:{question}. At the same time, the output of other agents is as follows:\\
{answers}
\end{tcolorbox}

In the implementation of the agents with tools, we modified all agents along the path except for the Final agent, while still following the ReAct framework for tool calling. During this process, due to the constraints of API calls, both the time required and the number of tokens used will be greater compared to agents without tools.
\subsection{Spatial Communication Topologies}
\subsubsection{Chain}
The chain graph (Fig.~\ref{fig:chain}) is one of the most widely utilized communication architectures in contemporary multi-agent systems. In this architecture, the first agent receives input from the user, transforms it into new instruction, and subsequently forwards it to the next agent. Generally, the final agent in the chain provides a summary and answers.
\begin{figure}[!h] 
    \centering
    \includegraphics[width=0.35\textwidth]{figures/files/Chain.png}
    \captionsetup{font={small}} 
    \caption{
    Demonstration of \textbf{chain} structure}
    \label{fig:chain}
\end{figure}
\subsubsection{Random}
The random graph refers to a sparse graph randomly sampled from a complete graph, as shown in the Fig.~\ref{fig:random}. They will execute asynchronously in multiple rounds and then randomly transmit information to the target agent. Finally, all the answers and information will transmit to the Final agent to make a final answer.
\begin{figure}[!h] 
    \centering
    \includegraphics[width=0.19\textwidth]{figures/files/Random.png}
    \captionsetup{font={small}} 
    \caption{
    Demonstration of \textbf{random} structure}
    \label{fig:random}
\end{figure}
\subsubsection{FullConnected}
The fullconnected graph (Fig.~\ref{fig:fullconnected}) is a directed graphs compared to traditional fully linked undirected graphs, which transmit information in a certain order to complete this topology structure. The final agent summarizes the dialogue and provides a concluding output or reflection.
\begin{figure}[!h] 
    \centering
    \includegraphics[width=0.29\textwidth]{figures/files/FullConnected.png}
    \captionsetup{font={small}} 
    \caption{
    Demonstration of \textbf{FullConnected} structure}
    \label{fig:fullconnected}
\end{figure}
\subsubsection{Layered}
The layered graph (Fig.~\ref{fig:Layered},~\cite{qian2024scalinglargelanguagemodelbasedmultiagentcollaboration}) refers to a stacked configuration similar to a multilayer perceptron (MLP). The first layer agents will feed to the agents in the second layer, and the final layer will make the summary and final-decision.
\begin{figure}[!h] 
    \centering
    \includegraphics[width=0.35\textwidth]{figures/files/Layered.png}
    \captionsetup{font={small}} 
    \caption{
    Demonstration of \textbf{Layered} structure}
    \label{fig:Layered}
\end{figure}
\subsubsection{Star}
The star grpah (Fig.~\ref{fig:Star}) resembles the tree structure. Firstly, the problem will be handed over to the external leaf nodes for processing, and the obtained answer will be passed to the central root node, which will be repeated multiple times. Finally, the root node will give a summary and make the descision.
\begin{figure}[!h] 
    \centering
    \includegraphics[width=0.23\textwidth]{figures/files/Star.png}
    \captionsetup{font={small}} 
    \caption{
    Demonstration of \textbf{Star} structure}
    \label{fig:Star}
\end{figure}
\subsubsection{Debate}
The debate graph (Fig.~\ref{fig:Debate},~\cite{du2023improvingfactualityreasoninglanguage}) is multiple agents to engage in a debate, where in each round, every agent receives the outputs of all agents from the previous round before making their own statements. Generally, the finalRefer agent will help them to make the final descision.
\begin{figure}[!h] 
    \centering
    \includegraphics[width=0.29\textwidth]{figures/files/Debate.png}
    \captionsetup{font={small}} 
    \caption{
    Demonstration of \textbf{Debate} structure}
    \label{fig:Debate}
\end{figure}

\subsubsection{Tree-like\&Ours}
In order to better understand our stacking structure, we will compare it with a tree like multi-agent pipeline that is relatively similar. The tree graph usually has the root node as the manager to supervise the nodes below to complete various tasks, and finally return the results of the leaf nodes to the root node for processing. Overall, this is just a top-down process of information transmission. As showin in the Fig.~\ref{fig:Stacking}\\
As for our stacking structure, from the perspective of information transmission, the main agent of the root node also receives the information completed from below, but there is a difference. For the so-called tool node, it is a bottom-up process. After continuous information superposition step by step, it is passed upward through the parent node and then given to the main agent for processing. It can be seen from the figure that in each transmission process, whether it is the root node or the parent node, they all selectively accept the information from the child node, and it is not like a tree structure that is passed downward.

\begin{figure}[!h] 
    \centering
    \includegraphics[width=0.5\textwidth]{figures/files/stacking.png}
    \captionsetup{font={small}} 
    \caption{
    Demonstration of \textbf{Tree} and \textbf{Ours} structure. In the stacking structure, the icon '\includegraphics[height=1em]{figures/files/creative.png}' means the parent node can choose which child node's information to accept.}
    \label{fig:Stacking}
\end{figure}
\section{Multi-agent Experimental Results}
\label{multi-agent results}
The experimental results are shown in the Tab.~\ref{tab:multiagent}. From the table, it can be observed that for different structures, there is an initial performance improvement as the value of num increases. However, when num reaches 8, only the Random, Layered, and Star modes show some improvement, with a maximum score of 0.891. In contrast, our best combined structure ([[‘ChemDFM\_0’, ‘Name2SMILES\_1’], ‘ChemDFM\_1’]) achieves a score of \textbf{0.925} with a num of only 4, indicating a significant enhancement.\\
Furthermore, since our multi-agent framework has been modified from others, the number of rounds for information transmission has not been optimized, leading to a substantial increase in both token count and time. This also suggests that even in complex and prolonged reasoning scenarios, relying solely on information transmission does not yield particularly high improvements. 
\input{tables/appendix_multiagent}
\label{appendix mulagent results}


\section{Case Study}
\label{casestudy}
As stated in Section \ref{6.4}, there are four distinct stacking behavior patterns-\textbf{correct}, \textbf{modify}, \textbf{judge} and \textbf{reserve} that make the stacking works. Here are three other cases for these patterns in the Tab.~\ref{tab:modify}:
\subsection{Correct}
As analyzed in Section \ref{6.4}, "Correct" is a very important pattern for agents. It was able to leverage the complementary strengths of multiple tools, significantly improving the accuracy of the final performance. 
\subsection{Modify}
As shown in the table, this is a common approach to using various tools. First, the problem is decomposed, and the RAG tool is used to retrieve information on each sub-question to obtain a preliminary answer. Then, subsequent processing is carried out using computational tools. Alternatively, one can first obtain an answer through computational tools, then have the agent self-assess the correctness of that answer, and finally use the RAG tool for cross-verify, thereby refining the answer and improving accuracy.
\input{tables/case-study-modify}
\subsection{Judge}
Judge refers to the process of selecting between two candidate answers based on the model’s knowledge in chemistry. This usually happens when two agent tools are available. When confronted with two anonymous tools that have the same descriptions, the model often opts to call both tools simultaneously before making a judgment. Furthermore, when using GPT-4o as the agent model, it typically demonstrates excellent judgment abilities.
\subsection{Reserve}
Reserve is a relatively uncommon phenomenon for large language models. Due to the hallucination problem, they usually choose to cover up knowledge blind spots to generate answers. However, when faced with multiple tools, the agent faces several answers. After thinking, it does not judge which one is more suitable, so it chooses to reserve opinions. Although this will reduce accuracy, in some ways it is a good thing to emerge this ability.

