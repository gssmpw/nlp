\setlength\tabcolsep{1pt}
%
\begin{table}[!htb]
    \centering
    \tiny
    \definecolor{lightgray}{gray}{0.9} % 定义浅灰色
    \resizebox{0.5\textwidth}{!}{
    \begin{tabular}{lccccccc}
        \toprule
        \textbf{Model} & \textbf{Exact↓} & \textbf{BLEU↑} & \textbf{Dis↑} & \textbf{Validity↑} & \textbf{MACCS↑} & \textbf{RDK↑} & \textbf{Morgan↑} \\
        \midrule
        \rowcolor{lightgray} \multicolumn{8}{c}{\textit{Task-specific specialist models}} \\

        Chemformer~\cite{irwin_chemformer_2022} & \textbf{0.91} & 96.1 & \underline{1.26} & 1.00 & \underline{0.97} & \underline{0.97} & \underline{0.96} \\
Text+ChemT5~\cite{textchemt5}&0.83&96.0&7.42&0.98&0.96&0.96&0.94\\
        InstructMol~\cite{cao2024instructmolmultimodalintegrationbuilding} & 0.54 & 96.7 & 10.85 & 1.00 & 0.88 & 0.78 & 0.74 \\
        Mol-Instruction~\cite{fang2024molinstructionslargescalebiomolecularinstruction} & 0.05 & 65.4 & 27.26 & 1.00 & 0.51 & 0.31 & 0.26 \\
        
        \midrule
        \rowcolor{lightgray} \multicolumn{8}{c}{\textit{LLM-based generalist models}} \\

        GPT-4o~\cite{openai2024gpt4ocard}      & 0.01 & 65.8 & 27.24  & 0.81 & 0.54 & 0.39 & 0.33 \\
Deepseek-R1~\cite{deepseekai2025deepseekr1incentivizingreasoningcapability} & 0.10 & 76.2 & 16.04  & 0.75 & 0.60 & 0.53 & 0.48 \\
Llama3-70b~\cite{llama3modelcard}  & 0.00 & 55.2 & 282.46 & 0.85 & 0.48 & 0.35 & 0.31 \\
Llama3-8B~\cite{llama3modelcard}   & 0.00 & 37.6 & 148.15 & 0.41 & 0.18 & 0.14 & 0.11 \\
ChemDFM-13B~\cite{zhao2024chemdfmlargelanguagefoundation} & 0.39 & 80.6 & 10.38  & 0.96 & 0.77 & 0.69 & 0.65 \\
        \midrule
        \rowcolor{lightgray} \multicolumn{8}{c}{\textit{Tool-based Agent models}} \\
Agent (1-tool , SMILES2Property) & 0.05       & 43.6          & 33.17         & 0.83          & 0.40          & 0.29          & 0.27          \\
Agent (1-tool , Chemformer)      & 0.89       & 96.4          & 2.44          & 1.00          & 0.97          & 0.97          & 0.95          \\
Agent (2-tool)                   & 0.87       & \underline{97.1}    & 1.6           & 1.00          & 0.97          & 0.97          & 0.95          \\
Ours (Stacking Agent)            & \underline{0.90} & \textbf{98.4} & \textbf{0.97} & \textbf{1.00} & \textbf{0.98} & \textbf{0.98} & \textbf{0.96}
\\
        \bottomrule
    \end{tabular}
    }
    \caption{Benchmark results of different models in reaction prediction tasks. All LLM-based generalist models are evaluated on 0-shot.}
    \label{tab:reaction_prediction}
\end{table}

