%为了验证 层次化工具堆叠策略（ChemHTS） 在大语言模型（LLM）驱动的化学任务中的有效性，我们在四个典型的化学任务上进行了实验。实验的核心目标是评估 ChemHTS 在不同任务上的计算能力提升情况，并分析其性能优越性的来源。

\subsection{Experiment Setup}

\paragraph{Dataset}

%我们使用ChemLLMBench对ChemHTS在化学方面的能力进行定量评估。ChemLLMBench由一系列化学任务组成，涵盖广泛的化学相关主题。针对选取的四个典型的任务，本研究分别选取与chemdfm评估实验中一致的100个评估数据集实例作为测试集。
%由于chemllmbench只有每个任务的100条评估数据集，因此我们参考xxx论文，对于Text-Based Molecule Design和Molecule Captioning任务，我们从ChEBI-20-MM中除去对应的测试集，各随机抽取相应任务的100条作为训练集。对于Reaction Prediction任务，我们从USPTO-MIT除去对应的测试集，各随机抽取相应任务的100条作为训练集。对于Molecular Property Prediction任务，我们从BBBP,HIV,BACE,Tox21,ClinTox除去对应的测试集，各随机抽取相应任务的50条作为训练集。
%。为确保公平比较，除非另有说明，否则我们在比较不同的 LLM 时使用相同的 100 个样本。

We evaluate the performance of ChemHTS in the field of chemistry using ChemLLMBench. ChemLLMBench~\cite{guo2023largelanguagemodelschemistry} comprises a series of chemistry-related tasks that cover a wide range of chemical topics. 
In this study, we focus on four representative tasks and select 100 evaluation instances for each task, consistent with the evaluation experiments in ChemDFM, as the test set.
%由于 ChemLLMBench 中每个任务的评估数据集仅包含 100 个实例，我们采用与 ~\cite{guo2023largelanguagemodelschemistry} 中类似的方法来选取训练集。
Since the evaluation dataset for each task in ChemLLMBench contains only 100 instances, we adopt a similar approach to that in ~\cite{guo2023largelanguagemodelschemistry} to select the training set. 
For the \textbf{Text-Based Molecule Design and Molecule Captioning} tasks, we randomly sample 100 instances from the ChEBI-20-MM~\cite{liu2025quantitativeanalysisknowledgelearningpreferences}
dataset, excluding the corresponding test set, as the training set. 
For the \textbf{Reaction Prediction} task, we randomly sample 100 instances from the USPTO-MIT~\cite{jin2017predictingorganicreactionoutcomes} dataset, excluding the corresponding test set, as the training set. 
For the \textbf{Molecular Property Prediction} task, we randomly sample 50 instances for each dataset from the BBBP, HIV, BACE, Tox21, and ClinTox~\cite{wu2018moleculenetbenchmarkmolecularmachine} datasets, excluding the corresponding test sets, as the training set.
The details of our dataset are shown in Tab.~\ref{tab:dataset}.
\input{tables/dataset}
\paragraph{Models}
%本研究的模型主要分为Task-specific specialist models，LLM-based generalist models以及Tool-based Agent models三类，Task-specific specialist models即为在可用的情况下，使用一些非 LLM 任务特定的模型进行比较。Tool-based Agent models是基于chatgpt-4o作为agent智能体，另提供任务给定的tool。为确保公平比较，除非另有说明，否则我们在比较不同的 LLM 时使用相同的100个样本。
We categorize current models into three primary groups: task-specific specialist models, LLM-based generalist models, and tool-based agent models. Task-specific specialist models refer to non-LLM models designed for specific tasks. Tool-based agent models leverage GPT-4o~\cite{openai2024gpt4ocard} as the core agent, augmented with additional tools tailored to the specific task. 
To ensure fair comparisons, we use the same test set for evaluating different models on each task.
\paragraph{Tools}
%由于本研究主要聚焦在ChemHTS方法寻求该任务的最优stacking结构路径，因此对于每个任务给定2个相关且性能良好的tool。对于Text-based Molecule Design任务，给定Name2SMILES、ChemDFM，对于Molecule Captioning，给定SMILES2Description和TextChemT5，对于Molecular Property Prediction，给定SMILES2Property和unimol-v2。对于Reaction Prediction，给定SMILES2Property和chemformer
To facilitate the experimental process, for each task, we provide only the most relevant tools for the two categories: computational tools and retrieval tools. 
Details can be found in Tab.~\ref{tab:dataset}.

%For the Text-based Molecule Design task, Name2SMILES and ChemDFM are provided. For the Molecule Captioning task, SMILES2Description and TextChemT5 are utilized. For the Molecular Property Prediction task, SMILES2Property and unimol-v2 are supplied. For the Reaction Prediction task, SMILES2Property and Chemformer are employed.
\subsection{Results}
\subsubsection{Text-based Molecule Design}
%化学任务介绍，有点太虚了
In the text-based molecule design task, LLMs predict a molecule’s SMILES (Simplified Molecular Input Line Entry System) representation based on a given description, testing their ability to interpret and translate chemical language into valid molecular structures~\cite{zhao2024chemdfmlargelanguagefoundation}.
%任务的目的和内容
%为了评估 LLM 制作合格分子设计的效率，ChemLLMBench 反转了分子说明任务，并要求模型根据分子描述生成分子。具体而言，在基于文本的分子设计任务中，要求模型预测符合给定描述的分子的 SMILES。
%评估指标
Our study employs two sets of metrics to evaluate the performance of the task. The first set of metrics measures the text-based similarity between the predicted SMILES and the gold standard SMILES, including exact match, BLEU, and Levenshtein distance~\cite{haldar2011levenshteindistancetechniquedictionary}. 
The second set of metrics assesses the chemical similarity between the predicted molecules and the reference molecules, encompassing the validity of the predicted SMILES and the FTS (Fingerprint Tanimoto Similarity)~\cite{tanimoto1958elementary}, calculated based on MACCS, RDK, and Morgan~\cite{Morgan1965TheGO}.
%实验结果
%从结果来看，工具增强的智能体模型整体表现最佳，其中**“Ours (Stacking Agent)”** 在多个关键指标上均达到了最优，表明其生成的分子结构既符合目标要求，又保持较高的分子合理性。相比之下，单一工具智能体（如Name2SMILES或ChemDFM）虽然在某些指标上表现良好，但在整体准确性和相似性上不及多工具融合的智能体模型。基于大语言模型的通用模型整体表现不佳，尤其是在Exact和BLEU指标上，GPT-4o（0-shot）的Exact仅为0.01，表明该模型在零样本情况下难以精确生成目标分子。然而，当GPT-4o采用10-shot学习时，性能有所提升，Exact提高至0.12（random）和0.11（scaffold），BLEU也相应提高。然而，其分子失真度（Dis）仍较高，表明大语言模型在缺乏外部工具支持的情况下，难以有效捕捉分子结构信息。
\input{tables/text_based}
From the results in Tab.~\ref{tab:text_based}, our Stacking Agent outperforms other models in this task. Not only do the generated molecular structures meet the target requirements, but they also maintain high molecular validity. In contrast, models based on large language models perform poorly, particularly in terms of Exact and BLEU scores, suggesting difficulty in accurately generating target molecules in a 0-shot setting. This highlights the challenge of capturing molecular structural information without external tool support. The chemistry-specific ChemDFM performs well in the 0-shot setting, surpassing other task-specific models. However, our Stacking Agent, by combining ChemDFM with the Name2SMILES tool, achieves the best results across multiple key metrics, with a BLEU score of 0.93, outperforming ChemDFM’s 0.85.

\subsubsection{Molecule captioning}
%Molecular captioning~\cite{guo2023largelanguagemodelschemistry} is an important task in computational chemistry, offering valuable insights and applications across various domains such as drug discovery, materials science, and chemical synthesis. Given a molecule as input, the goal of this task is to generate a textual description that accurately captures the key features, properties, and functional groups of the molecule.
%为了评估模型将复杂化学信息转化为人类易于理解的语言描述的能力，我们引入了 Molecule Captioning 任务。该任务要求 LLM 不仅能够准确识别给定的 SMILES（Simplified Molecular Input Line Entry System）符号所代表的分子，还需使用自然语言生成该分子的简明描述。为衡量模型在此任务上的表现，我们采用了传统的自然语言处理评价指标，如 BLUE 和 ROUGE，以评估模型在测试集上生成的分子描述与参考描述之间的相似性。
To evaluate the ability of the model to translate complex chemical information into human-readable language descriptions, we introduce the Molecule Captioning task~\cite{guo2023largelanguagemodelschemistry}. This task requires LLMs not only to accurately recognize the molecule represented by a given SMILES string, but also to generate a concise natural language description of the molecule. 
%评估指标
To assess the model's performance on this task, we employ traditional natural language processing evaluation metrics, such as BLEU and ROUGE, to measure the similarity between the molecule descriptions generated by the model and the reference descriptions in the test set.
\input{tables/mol-captioning}
%分析实验结果
%综合来看，实验表明任务特定的专家模型在分子描述任务上仍然具有较大的优势，而通用大语言模型在该任务上表现较差。然而，通过工具增强的智能体模型，特别是 Stacking Agent，能够有效提升文本生成质量，所有指标均显著提升,甚至超越任务特定模型.这表明智能体方法通过有效集成多种工具，能够显著提高分子描述任务的生成质量。此外，对比 Agent（1-tool） 和 Agent（2-tool），可以发现随着工具数量的增加，模型的性能有所提升（如 BLEU-4 从 0.54 提升至 0.56），但单纯增加工具并未带来突破性的改进，而通过ChemHTS方法构建的Stacking Agent 通过更高效的工具组合策略，达到了最佳性能。
As shown in Tab.~\ref{tab:captioning}, Stacking Agent, built using the more efficient ChemHTS method, achieves the best overall performance across all metrics. For text generation tasks, task-specific models still hold a significant advantage in molecule captioning, while , aside from large parameters models like GPT-4o and Deepseek-R1, other large language models still perform poorly. Additionally, a comparison between Agent (1-tool) and Agent (2-tool) shows that increasing the number of tools boosts performance (e.g., BLEU-4 improves from 0.54 to 0.56). However, simply adding more tools doesn’t lead to major gains.

\subsubsection{Molecular Property Prediction}
Molecular property prediction~\cite{Guo_2021,wang2021chemicalreactionawaremoleculerepresentationlearning} is a fundamental task in computational chemistry that has garnered significant attention in recent years due to its potential applications in drug discovery, materials science, and other areas of chemistry. 
%该任务要求这模型根据给定分子的结构预测其化学和物理特性，其数据集由 MoleculeNet 中的五个任务组成 [Wu et al., 2018]，包括 BACE、BBBP、HIV、ClinTox 和 Tox21。其中，BACE 和 BBBP 各包含一个平衡的二元分类任务。HIV 包含一个不平衡的二元分类任务。ClinTox 和 Tox21 分别包含两个和二十一个不平衡的二元分类任务。为了解决这些任务中严重的标签不平衡问题，本研究引入了接收者操作特性曲线下面积 (AUCROC) 指标作为评估指标 [Bradley, 1997]。
The task requires models to predict the chemical and physical properties of a given molecule based on its structure. The dataset consists of five tasks drawn from MoleculeNet~\cite{wu2018moleculenetbenchmarkmolecularmachine}, including BACE, BBBP, HIV, ClinTox, and Tox21. Among them, BACE and BBBP each consist of a balanced binary classification task. HIV includes an imbalanced binary classification task. ClinTox and Tox21 contain two and twenty-one imbalanced binary classification tasks, respectively. To address the severe label imbalance in these tasks, our study employs the Area Under the Receiver Operating Characteristic Curve (AUC-ROC) as the primary evaluation metric~\cite{tafvizi2022attributingaucrocanalyzebinary}. However, considering the computational challenges associated with large language models and the balanced binary task, we also incorporate Accuracy as an additional metric to provide a more comprehensive assessment.

\input{tables/mol-perdiction}

%从表4的结果来看，任务专用模型（Task-specific specialist models）整体表现最佳，其中UniMol-v2在五个任务上的平均AUC-ROC值与Acc值高于其余模型。这表明针对分子性质预测任务进行特定优化的模型能够更有效地学习化学分子结构与生物活性之间的关系。
%而通过ChemHTS找到的Stacking Agent结构在该任务的表现优于基于LLM的大规模通用模型（LLM-based generalist models）在该任务上的表现，尤其在非平衡的双分类任务HIV和Tox21上。这表明工具融合方法能够在一定程度上弥补通用模型的劣势，提高预测任务的准确性。我们的方法最终，虽然在AUC-ROC上低于SOTA的UniMol-v2 1.5分，但在平均Accuarcy（0.81）上超过了Uni-Molv2的0.74.

From the results in Tab.~\ref{tab:prediction}, task-specific specialist models demonstrate the best overall performance. Among the models, UniMol-v2 achieves the highest average AUC-ROC and Accuracy values across the five tasks, outperforming the other models. These findings indicate that models specifically optimized for molecular property prediction tasks are more effective at learning the relationships between chemical molecular structures and their biological activities.
Moreover, the Stacking Agent structure identified through ChemHTS outperformed LLM-based generalist models on this task, especially in the imbalanced binary classification tasks of HIV and Tox21. This suggests that tool integration methods can, to some extent, compensate for the limitations of generalist models and enhance the accuracy of prediction tasks.
Finally, while our ChemHTS method falls 1.5 AUC score behind the state-of-the-art UniMol-v2 , it surpasses its average accuracy (0.74) with a score of 0.81.
\subsubsection{Reaction Prediction}
%任务简介
Reaction prediction is a core task in the field of chemistry, with significant importance for drug discovery, materials science, and the development of novel synthetic pathways. Given a set of reactants, the goal of this task is to predict the most likely products formed during the chemical reaction~\cite{guo2024modeling,Schwaller_2019}.
%评估指标
Similarly to the results of the text-based molecule design task, we used the same metrics to measure the task performance.
\input{tables/reaction-prediction}
%实验结果
As shown in the Tab.~\ref{tab:reaction_prediction}, It can be observed that the Chemformer model performs exceptionally well in this task, achieving a product prediction accuracy of 0.91. It also outperforms other task-specific models across all metrics. In contrast, LLMs face significant challenges, with Deepseek-R1, despite its deep reasoning capabilities, only achieving 0.10 accuracy in product prediction. Similarly, the chemistry-specific ChemDFM struggles under 0-shot conditions. The ChemHTS model excels across all metrics, except for a slightly lower exact score (0.01), surpassing the Chemformer model on all other measures. For Agent (1-tool), relying solely on the SMILES2Property tool leads to poor performance. However, leveraging the additional information provided by the RAG tool through integration, the agent also achieves significantly better performance.
\section{Analysis}
\subsection{Does it improve performance if the agent can choose from more tools?}
%为了进一步分析agent的tool数量对化学任务性能的影响，本研究进一步分析了不同tool数量在Text-based Molecule Design任务上的影响。从表6可以看出，在一定的训练数据下，当工具数量从2增加到4时，BLEU-2的得分变化较小。平均BLEU-2得分（AVG）方面，Tool Number = 2 和 Tool Number = 4 的得分均为0.86，而 Tool Number = 3 的得分略低，为0.85。这表明工具数量的增加在一定程度上对BLEU-2得分的提升作用有限，可能是因为工具之间的贡献存在冗余，以及工具本身的质量决定了其对最终结果的影响程度。
To further analyze the impact of the number of tools on the performance of chemical tasks, this study investigates the effect of varying tool numbers on the text-based molecule design task. 
As shown in Tab.~\ref{tab:analysis1}, under a fixed amount of training data, increasing the number of tools from 2 to 4 results in only minor changes in BLEU-2 scores. Regarding the average BLEU-2 score, both Tool Number = 2 and Tool Number = 4 achieve a score of 0.86, while Tool Number = 3 slightly underperforms with a score of 0.85. This indicates that increasing the number of tools has limited benefits for BLEU-2 score improvement, which may be attributed to redundancy in contributions among tools and the fact that the quality of individual tools determines their impact on the final performance.
\input{tables/analysis1}
\subsection{Does more training data lead to better performance?}
%同样的，本研究深入分析了在不同数量的训练数据用ChemHTS方法找到的最优stacking结构之间的在text-based molecule design任务的性能差异。
Our study also conducts an in-depth analysis of the performance differences in the text-based molecule design task among the optimal stacking structures identified by the ChemHTS method under varying amounts of training data.
%从表8可以得到，随着训练数据的增加（从5到30），BLEU-2得分总体上呈现上升趋势。例如，对于Tool Number = 2，在训练数据为5时，BLEU-2得分为0.79，而当训练数据增加到30时，BLEU-2得分提升至0.87。其他工具也表现出类似趋势，说明增加训练数据有助于提高模型的翻译质量。这一趋势符合预期，但是不是越多的训练数据，性能越好，因此需要对不同任务的训练数据数量要进一步做实验分析，选取最优的组合。
As shown in Tab.~\ref{tab:analysis1}, BLEU-2 scores generally exhibit an upward trend with the increase in training data (from 5 to 30). For example, for Tool Number = 2, the BLEU-2 score is 0.79 when the training data is 5, and it improves to 0.87 when the training data increases to 30. Similar trends are observed for other tool numbers, indicating that increasing the amount of training data enhances the model's translation quality. This trend aligns with expectations; however, more training data does not always guarantee better performance. Therefore, further experimental analysis is required to determine the optimal amount of training data for different tasks and select the best combination.
%另外我们也能看到

\input{tables/analysis2}

\subsection{Does increasing the number of stacking layers improve performance?}
%本部分以text-based molecule design 任务为代表，主要探讨增加堆叠层数（stacking layers）是否能够提升性能。
%从表7的结果来看，增加堆叠层数对性能的提升存在一定的上限。当层数较少（如1或2层）时，模型可能无法充分捕捉复杂的特征，因此BLEU-2分数较低。随着层数增加至7，模型的学习能力增强，生成质量达到最佳。然而，进一步增加层数后，性能未能持续提升，可能的原因有过多的层数可能引入冗余信息，导致模型生成的文本质量下降或过度拟合训练数据。

This section uses the text-based molecule design task as a representative to explore whether increasing the number of stacking layers can improve performance.  
As shown in the results from Tab.~\ref{tab:analysis2}, there appears to be an upper limit to the performance improvement achieved by increasing the number of stacking layers. 
When the number of layers is small (e.g., 1 or 2 layers), the model may fail to sufficiently capture complex features, resulting in lower BLEU-2 scores. As the number of layers increases to 7, the model's learning capacity improves, and the generation quality reaches its peak. However, further increasing the number of layers does not lead to continued performance improvement. This could be attributed to the introduction of redundant information with excessive layers, causing a decline in text generation quality or overfitting to the training data.

\input{tables/case-study}
\subsection{Why tool stacking works?}
\label{6.4}
%本章节主要通过案例分析来探讨agent在tool stacking过程中出现的一些行为模式，来解释tool stacking能提升模型任务表现的原因。通过我们的案例总结，我们发现了四种stacking行为pattern，所有案例细节见附录C。由于篇幅限制，我们仅举1个correct的stacking patter例子，如表8所示。
%我们在text-based molecule design task中，给模型两个tool以供调用。首先，实验调用了ChemDFM工具进行SMILES预测。该工具返回了C1(C)CC1，但该结果不符合环丙烷的标准SMILES表示。这一错误可能来源于ChemDFM在解析化学结构描述时对环状结构的理解存在偏差，未能正确识别单一的三元环结构，而是错误地引入了额外的支链。为修正错误，实验进一步调用Name2SMILES工具，并输入“Cyclopropane”作为查询。该工具正确返回了C1CC1，并在后续分析中被确认符合环丙烷的已知结构。因此，最终输出的SMILES被修正为C1CC1，符合标准答案。本实验表明，单一工具在处理化学结构预测任务时可能存在局限性，例如ChemDFM的错误预测。然而，通过工具堆叠策略，实验成功利用多个工具互补优势，提高了最终预测的准确性。
This chapter explores the behavioral patterns exhibited by agents during the process of tool stacking through case analysis and examines how tool stacking enhances task performance. From the case studies, we identify \textbf{four distinct stacking behavior patterns—correct, modify, judge and reserve}, with detailed information on all cases provided in Appendix.~\ref{casestudy}. Due to space limitations, this paper illustrates only one \textbf{correct} stacking behavior pattern as shown in Tab.~\ref{tab:case study}.
In the text-based molecular design task, two callable tools are provided to the model. The experiment first invokes the ChemDFM tool for SMILES prediction, which returns "C1(C)CC1". However, this result does not conform to the standard SMILES representation of cyclopropane. The error likely arises from ChemDFM's misinterpretation of cyclic structures, as it fails to correctly identify the single three-membered ring and instead erroneously introduces an additional branch. To address this issue, the experiment subsequently invokes the Name2SMILES tool with "Cyclopropane" as the query. This tool correctly returns "C1CC1", which is confirmed through subsequent analysis to align with the known standard structure of cyclopropane. Consequently, the final SMILES output is corrected to "C1CC1", meeting the requirements of the standard answer.
This experiment shows that individual tools may have certain limitations when handling chemical structure prediction tasks, as evidenced by ChemDFM's erroneous prediction. However, by employing the tool stacking strategy, the experiment effectively leverages the complementary strengths of multiple tools, significantly improving the accuracy of the final prediction.



\subsection{Comparison with LLM-based Multi-Agent Systems}
%由于多智能体系统（Multi-Agent System, MAS）与工具增强型大语言模型（Tool-augmented LLMs）在任务分解、工具调用和信息共享等方面存在相似性。因此，本研究重点分析了 6 种不同通信结构的多智能体系统与我们提出的 ChemHTS 方法在 text-based 分子设计任务中寻求的最优堆叠智能体路径的性能比较。关于具体的多智能体系统细节，请参见附录 A。
%从图 2 可以看出，随着智能体规模的增加，各种通信结构的质量值均有所提升，但增长趋势存在显著差异。当智能体规模增大（Scale ≥ 4）时，不同结构的性能开始分化。其中，Fully Connected（全连接）和 Layered（分层）结构的质量值显著高于其他结构。然而，最优堆叠智能体路径的性能超越了多智能体系统的性能上限。这是因为最优路径能够更高效地利用任务分解和工具调用的能力，同时避免了多智能体系统中可能出现的通信开销和协调瓶颈。
LLM-based Multi-Agent Systems (MAS) and Tool-augmented LLM share similarities in areas such as task decomposition, tool invocation, and information sharing. Therefore, our study focuses on comparing the performance of six multi-agent systems with different communication structures against the optimal stacking agent path proposed by our ChemHTS method in the text-based molecule design task. For details on the specific multi-agent systems, please refer to Appendix.~\ref{Framework},~\ref{multi-agent results}.
\input{figures/multi-agent}
As shown in Fig.~\ref{fig:multiagent}, the BLEU-2 scores of various communication structures improve as the scale of agents increases. However, the growth trends differ significantly. When the agent scale becomes larger, the performance of different structures begins to diverge. Among them, the Full-Connected and Layered structures demonstrate significantly higher quality values compared to other structures. 
Nevertheless, the performance of the optimal stacking agent path surpasses the upper performance limit of the multi-agent systems. This is because the optimal path can more effectively leverage task decomposition and tool invocation capabilities while avoiding potential communication overhead and coordination bottlenecks inherent in multi-agent systems. 
%更多的multi-agent的具体实验结果见附录B
More specific experimental results of multi-agent can be found in Appendix.~\ref{appendix mulagent results}.



