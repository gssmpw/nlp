
\section{Profile Swap Regret}

\subsection{Defining Profile Swap Regret}

Like polytope swap regret, profile swap regret involves performing a convex decomposition of the sequence of play of the learner into elements that we can then compute the swap regret of and aggregate. However, unlike polytope swap regret (which decomposes the strategy of the learner in each round of the game), in profile swap regret we will do this decomposition on the average CSP of play. In particular, profile swap regret can be computed as a function of just the resulting CSP $\csp$ of play -- note that this is a property shared with linear swap regret, but that polytope swap regret and normal-form swap regret do not possess.

To define the \emph{profile swap regret} $\CorrSwap(\csp)$ of a CSP $\csp$, we perform the following steps\footnote{In Appendix~\ref{app:alternate-formulation}, we present an alternate formulation of profile swap regret in a way that is more directly comparable with the definition of polytope swap regret above.}:

\begin{enumerate}
    \item First, decompose $\csp$ into a convex combination of independent (product) strategy profiles

    \begin{equation}\label{eq:csp-decomp}
        \csp = \sum_{k=1}^{K} \lambda_{k} (x_{(k)} \otimes y_{(k)}).
    \end{equation}

    for some choice of $x_{(k)} \in \learnset$, $y_{(k)} \in \optset$, and $\lambda_k \geq 0$ with $\sum_{k} \lambda_k = 1$.  As with polytope swap regret, there are likely multiple ways to do this decomposition; we will eventually choose the decomposition that minimizes our eventual regret. Also note that we can freely choose the number of parts $K$ in this decomposition.

    \item For any $x \in \learnset$ and $y \in \optset$, let $\Reg(x, y) = \max_{x^* \in \learnset} u_L(x^{*}, y) - u_L(x, y)$ (this can be thought of as the ``instantaneous'' regret from playing $x$ in response to $y$). We define

    \begin{equation}
    \label{eq:profile_swap_regret}
    \CorrSwap(\csp) = T \cdot \left(\min_{x_{(k)}, y_{(k)}, \lambda_k} \sum_{k=1}^{K} \lambda_{k}\Reg(x_{(k)}, y_{(k)})\right),
    \end{equation}

    \noindent
    where, as mentioned above, this minimum is over all valid convex decompositions of $\csp$ into the form in \eqref{eq:csp-decomp}.
\end{enumerate}

We will eventually demonstrate that profile swap regret is the analogue of swap regret in polytope games that preserves the game-theoretic properties mentioned in Section~\ref{sec:manipulability}. Before we do so, we first remark that profile swap regret is bounded between linear swap regret and polytope swap regret.%Before we do so, we present a couple of clarifying remarks on the above definition. (UNCOMMENT / MOVE BACK for arxiv)

% First, we show that in the above definition, it suffices to consider decompositions (of the form \eqref{eq:csp-decomp}) where each $x_{(k)}$ is a vertex of $\learnset$.

% \begin{lemma}\label{lem:decomp-equiv}
% Let $\csp = \sum_{k=1}^{K} \lambda_{k} (x_{(k)} \otimes y_{(k)})$ be an arbitrary decomposition of the CSP $\csp$. Then there exists another decomposition $\csp = \sum_{k=1}^{K'} \lambda'_{k} (x'_{(k)} \otimes y'_{(k)})$ where each $x'_{(k)} \in \learnvert$, all $x'_{(k)}$ are distinct, and

% \begin{equation}
% \label{eq:decomp_equiv}
% \sum_{k=1}^{K'} \lambda'_{k}\Reg(x'_{(k)}, y'_{(k)}) \leq \sum_{k=1}^{K} \lambda_{k}\Reg(x_{(k)}, y_{(k)}).
% \end{equation}
% \end{lemma}

% One consequence of Lemma~\ref{lem:decomp-equiv} is that it allows us to write profile swap regret as a ``swap regret'': that is, regret with respect to the set of swap functions $\pi: \learnvert \rightarrow \learnvert$ (swapping vertices of $\learnset$), something not immediately clear from the original definition. In particular, we can equivalently define the profile swap regret $\CorrSwap(\csp)$ of a CSP via the following steps:

% \begin{enumerate}
%     \item Decompose $\csp$ into a convex combination of strategy profiles of the form

%     \begin{equation}\label{eq:vertex-decomp}
%     \csp = \sum_{v \in \learnvert} \lambda_{v} (v \otimes y_{v}),
%     \end{equation}

%     \noindent
%     where $\lambda_v \geq 0$, $\sum_{v}\lambda_{v} = 1$ and $y_{v} \in \optset$.

%     \item Define $\CorrSwap(\csp)$ to equal

%     \begin{equation}\label{eq:vertex-csp}
%     \CorrSwap(\csp) = T \cdot \left(\min_{y_{v}, \lambda_{v}} \max_{\pi^{*}:\learnvert \rightarrow \learnvert} \sum_{v \in \learnvert} \lambda_{v} \left(u_L(\pi^{*}(v), y_{v}) - u_L(v, y_{v})\right)\right),
%     \end{equation}

%     \noindent
%     where the outer minimum is over all valid decompositions of the form \eqref{eq:vertex-decomp}.
% \end{enumerate}

% This reformulation also makes it easier to compare profile swap regret to polytope swap regret (which also can be formulated as a swap regret with respect to the same set of swap functions, albeit with a different constraint on decomposition). In particular, we can use this to show that profile swap regret lies between linear swap regret and polytope swap regret.

\begin{theorem}\label{thm:comp-prof-swap}
Let $\bx = (x_1, x_2, \dots, x_T)$ and $\by = (y_1, y_2, \dots, y_T)$ be a transcript of play for a given polytope game. Then $\LinSwap(\bx, \by) \leq \CorrSwap(\bx, \by) \leq \PolySwap(\bx, \by)$.

Moreover, both of these inequalities are asymptotically strict in the following sense: for each inequality, there exists a family of transcripts for which the larger swap regret grows as $\Omega(T)$ but the smaller swap regret is zero. 
\end{theorem}


Similar to the no-swap-regret menu, we will define the \emph{no-profile-swap-regret menu} $\cM_{NPSR}$ to be the set of CSPs $\csp$ satisfying $\CorrSwap(\csp) = 0$. Likewise, just as $\SwapDist$ is the relevant quantity in Theorem~\ref{thm:nfg_nonmanip_quant}, in many of our more quantitative results it will be more convenient to work with the following ``distance'' variant of $\CorrSwap$, where we define the \emph{profile swap distance} $\CorrDist(\csp) = \mathrm{dist}(\csp, \cM_{NPSR})$ to equal the minimal Euclidean distance from $\csp$ to the no-profile-swap-regret menu $\cM_{NPSR}$. 

% NOTE: commenting out this lemma for now, but we should still try to understand this
% \begin{lemma}
% If $\learnset$ and $\optset$ are both bounded and $\norm{u_L}_{1} \leq 1$, then for any CSP $\csp \in \learnset \otimes \optset$,

% $$C_L\CorrDist(\csp) \leq \CorrSwap(\csp) \leq C_H\CorrDist(\csp),$$
% \end{lemma}
% \begin{proof}
% \jon{what are the correct constant factors in this lemma? do we need this lemma?}
% \end{proof}

\subsection{Game-Theoretic Properties of Profile Swap Regret}

We will now show that the three game-theoretic properties possessed by no-swap-regret algorithms in normal-form games -- non-manipulability, minimality, and Pareto-optimality -- hold for no-profile-swap-regret algorithms in general polytope games. 

Our main tool to prove these results will be the same menu-based techniques used to prove Theorems \ref{thm:nfg_nonmanip}, \ref{thm:nfg_minimal}, and \ref{thm:nfg_pareto}, albeit extended from the standard normal-form setting to the setting of polytope games. Underlying most of these results will be the following characterization of the no-profile-swap-regret menu as the convex hull of all ``best-response CSPs'' for the learner. 

\begin{lemma}\label{lem:menu_char}
The no-profile-swap-regret menu $\cM_{NPSR}$ is the convex hull of all CSPs of the form $x \otimes y$ where $y \in \optset$ and $x \in \BR_{L}(y)$. In particular, $\Stack(G, u_O) = V_{O}(\cM_{NPSR}, u_{O})$.
\end{lemma}
\begin{proof}
\sloppy{This follows almost directly from the definition of profile swap regret. Note that if $\CorrSwap(\csp) = 0$, then this implies that we can write it in the form $\csp = \sum \lambda_{k} (x'_k \otimes y'_k)$ where each pair $(x'_k, y'_k)$ satisfies $\Reg(x'_k, y'_k) = 0$, and therefore that $x'_k \in \BR_{L}(y'_k)$ (and so we have expressed $\csp$ as a convex combination of such points). Conversely, if $x \in \BR_{L}(y)$, then $\CorrSwap(x \otimes y) = 0$ (since $\Reg(x, y) = 0$).}
\end{proof}



\subsubsection{Non-manipulability}

We begin by establishing the analogue of Theorem~\ref{thm:nfg_nonmanip} for polytope games: that for learning algorithms in polytope games, the property of having no-profile-swap-regret is equivalent to the property of being non-manipulable by a dynamic optimizer. At the same time, we establish the analogue of Theorem~\ref{thm:nfg_nonmanip_quant}, providing quantitative bounds on the degree of manipulation in terms of profile swap distance (importantly, this is the quantity we will minimize in Section \ref{sec:algorithms}, when we turn our attention to designing no-profile-swap-regret learning algorithms). 

\begin{theorem}\label{thm:poly_nonmanip}
Fix a polytope game $G$. Let $\cA$ be a no-profile-swap-regret algorithm for $G$. Then the asymptotic menu $\cM(\cA)$ is non-manipulable. Conversely, if the asymptotic menu $\cM(\cA)$ of an algorithm $\cA$ is non-manipulable, then the algorithm $\cA$ must be a no-profile-swap-regret algorithm. 

Moreover, if $\cA$ has the guarantee that $\CorrDist(\cA^{T}) \leq R(T)$, then $\cM(\cA^{T})$ is $\sqrt{d_Ld_O} (R(T)/T)$-non-manipulable. Conversely, if $\cM(\cA^{T})$ is $R(T)/T$-non-manipulable, then $\CorrDist(\cA^{T}) \leq R(T)$.
\end{theorem}

\begin{proof}
We will first show that the no-profile-swap-regret menu $\cM_{NPSR}$ is non-manipulable (therefore implying that any no-profile-swap-regret algorithm is non-manipulable). It suffices to show that, for any optimizer payoff $u_O$ and any CSP $\csp \in \cM_{NPSR}$, $u_O(\csp) \leq \Stack(G, u_O)$. But since $\Stack(G, u_O) = V_{O}(\cM_{NPSR}, u_O)$ (by Lemma~\ref{lem:menu_char}), this is immediately true. 

Conversely, if $\cA$ is not a no-profile-swap-regret algorithm, then $\cM(\cA)$ must contain a CSP $\csp \not\in \cM_{NPSR}$. By the separating hyperplane theorem, there must exist a linear payoff function $u_O$ such that $u_O(\csp) > 0$ but $u_O(\csp') \leq 0$ for all $\csp' \in \cM_{NPSR}$. But if $u_O(\csp') \leq 0$ for all $\csp' \in \cM_{NPSR}$, then we must also have $\Stack(G, u_O) \leq 0$ (by Lemma~\ref{lem:menu_char}). Therefore $V_{O}(\cM(\cA), u_O) \geq u_{O}(\csp) > \Stack(G, u_O)$, and $\cM(\cA)$ is therefore manipulable. 

\sloppy{Finally, we can quantify the degree of manipulation in the above argument as follows. If $\CorrDist(\cA^{T}) \leq R(T)$, then for any $\csp \in \cM(\cA^{T})$, there exists a $\csp' \in \cM_{NPSR}$ such that $||\csp - \csp'||_{2} \leq R(T)/T$. In particular, for any optimizer payoff $u_O$, we have that $u_{O}(\csp) - \Stack(G, u_O) \leq u_{O}(\csp) - u_{O}(\csp') \leq ||u_O||_{2}\cdot ||\csp - \csp'||_{2} \leq \sqrt{d_Ld_O}(R(T)/T)$ (where the last inequality follows from the fact that $||u_O||_{2} \leq \sqrt{d_Ld_O}$ if $||u_{O}||_{\infty} \leq 1$). }

Likewise, if $\CorrDist(\cA^{T}) \geq R(T)$, then there is a $\csp \in \cM$ such that $||\csp - \csp'||_{2} \geq R(T)/T$ for any $\csp' \in \cM_{NPSR}$. By the separating hyperplane theorem there then exists a $u_O$ with unit $||u_{O}||_{2} = 1$ such that $u_{O}(\csp) - \max_{\csp' \in \cM_{NPSR}}u_O(\csp') \geq R(T)/T$. Since $\Stack(G, u_O) = \max_{\csp' \in \cM_{NPSR}} u_O(\csp')$, this implies that the menu $\cM$ is at least $(R(T)/T)$-manipulable.
\end{proof}

We briefly remark that the $\sqrt{d_Ld_O}$ gap between the two bounds in Theorem~\ref{thm:poly_nonmanip} is an artifact of the specific boundedness constraints we placed on the optimizer's utility $u_O$ (namely, that $||u_O||_{\infty} \leq 1$). If we instead imposed the constraint $||u_O||_2 \leq 1$, then $\CorrDist$ would be an exact measure of non-manipulability.

\subsubsection{Minimality}

Next, we establish the analogue of Theorem \ref{thm:nfg_minimal}, proving that the no-profile-swap-regret menu is \emph{minimal}: in particular, for any polytope game, every CSP $\csp$ in the no-profile-swap-regret menu is a CSP that is implementable against any no-external-regret algorithm. 

\begin{theorem}\label{thm:poly_minimal}
Fix a polytope game $G$. All no-profile-swap-regret algorithms $\cA$ for $G$ share the same asymptotic menu $\cM(\cA) = \cM_{NPSR}$. Moreover, if $\cA$ is a no-regret algorithm, then $\cM_{NPSR} \subseteq \cM(\cA)$.
\end{theorem}
\begin{proof}
We will begin by showing the second part of this theorem: that any no-(external)-regret algorithm $\cA$ for $G$ has the property that $\cM_{NPSR} \subseteq \cM(\cA)$. 

Recall that $\cM_{NPSR}$ is the convex hull of all points of the form $\BR_L(y) \otimes y$. We will show that every point of this form is in $\cM(\cA)$. For every $\hat{x} \otimes \hat{y}$ pair such that $\hat{x} = \BR_L(\hat{y})$, there are two possibilities:
\begin{itemize}
\item $\hat{x}$ is the unique best response to $\hat{y}$. Assume for contradiction that $\hat{x} \otimes \hat{y}$ is not in $\cM(\cA)$. By Theorem~\ref{thm:menu_char}, there must exist at least one point of the form $x \otimes \hat{y}$ in $\cM(\cA)$. Thus, there exists a point of the form $x \otimes \hat{y}$ such that $x$ is not a best response to $\hat{y}$. But this point incurs external regret, and therefore this is a contradiction.   
\item $\hat{x}$ is not the unique best response to $\hat{y}$. Then, note that by our non-degeneracy assumption on $u_{L}$, $\hat{x}$ is not weakly dominated. Thus there must exist a $y^{*} \in \optset$ that uniquely incentivizes $\hat{x}$. Therefore, all points of the form $y(\alpha) = \alpha y^{*} + (1 - \alpha) \hat{y}$ uniquely incentivize $\hat{x}$ for $\alpha \in [0,1]$. Therefore, all points $\hat{x} \otimes y(\alpha)$ are contained within $\cM(\cA)$. As $\cM(\cA)$ is closed, taking the limit of $\alpha \rightarrow 0$ implies that $\hat{x} \otimes y(0) = \hat{x} \otimes \hat{y} \in \cM(\cA)$.  
\end{itemize}

To establish the first part of this theorem, note that by the definition of $\cM_{NPSR}$, if $\cA$ is a no-profile-swap-regret algorithm, then $\cM(\cA) \subseteq \cM_{NPSR}$. On the other hand, since no-profile-swap-regret implies no-external-regret, by the above argument we have that $\cM_{NPSR}  \subseteq \cM(\cA)$. Therefore, $\cM_{NPSR} = \cM(\cA)$.
\end{proof}

\subsubsection{Pareto-optimality}
Finally, we establish the analogue of Theorem~\ref{thm:nfg_pareto}, and show that in polytope games, no-profile-swap-regret algorithms are Pareto optimal. This provides a natural counterpart to Theorem~\ref{thm:nfg_nonmanip} (not only can no-profile-swap-regret algorithms never be manipulated by a strategizing opponent, there are always situations where the learner strictly prefers not to be manipulated).

\begin{theorem}\label{thm:poly_pareto}
Fix a polytope game $G$. Let $\cA$ be a learning algorithm for $G$ with $\CorrSwap(\cA) = \Omega(T)$. Then there exists an optimizer utility $u_O$ such that $V_{L}(\cM_{NPSR}, u_O) > V_{L}(\cM(\cA), u_O)$; i.e., there exists an optimizer against whom it is strictly better to play any no-profile-swap-regret algorithm than $\cA$.
\end{theorem}

The proof of Theorem~\ref{thm:poly_pareto} uses Lemma 4.4 from~\cite{paretooptimal}. While~\cite{paretooptimal} study the setting of normal-form games, in which the strategy polytopes are simplices, their proof of this lemma makes no such assumptions. Given a menu $\cM$, let $\cM^{+}$ represent the set of all extreme points of $\cM$ where $u_{L}$ achieves its maximum value. Furthermore, let $\cM^{-}$ represent the set of all extreme points of $\cM$ where $u_L$ achieves its minimum value.

\begin{lemma}[Lemma 4.4 in~\cite{paretooptimal}]\label{lem:other_paper}
    Let $\cM_{1}$ and $\cM_{2}$ be two distinct asymptotic menus where $\cM_{1}^{+} = \cM_{2}^{+}$. If 
      $\cM_{2} \setminus \cM_{1} \neq \emptyset$, then there exists a $u_{O}$ for which $V_{L}(\cM_{1},u_{O}) > V_{L}(\cM_{2},u_{O})$.
\end{lemma}

We can now prove Theorem~\ref{thm:poly_pareto}.

\begin{proof}[Proof of Theorem~\ref{thm:poly_pareto}]
    Consider an algorithm $\cA$ with menu $\cM = \cM(\cA)$ which incurs $\Omega(T)$ profile swap regret in the worst case. Then, by definition, $\cM \setminus \cM_{NPSR} \neq \emptyset$. Let $\max_{x \in \learnset, y \in \optset}u_{L}(x,y) = u_{L}^{\max}$. By Lemma~\ref{lem:menu_char}, $\cM_{NPSR}$ is the convex hull of all CSPs of the form $x \otimes y$, where $y \in \optset$ and $x \in \BR_{L}(y)$. Thus, $\cM^{+}_{NPSR}$ is the convex hull of all CSPs $x^{*} \otimes y^{*}$ where $u_{L}(x^{*},y^{*}) = u_{L}^{\max}$ (in particular, $\cM^{+}_{NPSR}$ contains every CSP $\csp$ where $u_{L}(\csp) = u_{L}^{\max}$). 
    
    Now, let $\overline{\cM} = \conv(\cM(\cA) \cup \cM^{+}_{NPSR})$. Note that as $\cM(\cA) \subseteq \overline{\cM}$, $\overline{\cM} \setminus \cM_{NPSR} \neq \emptyset$. Furthermore, by construction, $\cM^{+}_{NPSR} = \overline{\cM}^{+}$. Thus, we can invoke Lemma~\ref{lem:other_paper} to show that there exists a $u_{O}$ such that $V_{L}(\cM_{NPSR},u_{O}) > V_{L}(\overline{\cM},u_{O})$. Now, there are two possibilities:
    \begin{itemize}
        \item The extreme point of $u_{O}$ in $\overline{\cM}$ is the same as that in $\cM(\cA)$. Then $V_{L}(\cM(\cA), u_{O}) = V_{L}(\overline{\cM},u_{O}) < V_{L}(\cM_{NPSR}, u_{O})$. 
        \item The extreme point of $u_{O}$ in $\overline{\cM}$ is \emph{not} the same as that in $\cM(\cA)$. Then, the extreme point of $u_{O}$ in $\overline{\cM}$ must belong to $\cM_{NPSR}^{+}$. But for all CSPs $\csp \in \cM_{NPSR}^{+}$, $u_{L}(\csp) = u_{L}^{\max}$, which would imply that $V_{L}(\cM_{NPSR},u_{O}) > u_{L}^{\max}$. This is a contradiction, and therefore this case cannot occur. 
    \end{itemize}
\end{proof}



% \jon{Probably move this section to the appendix. Todos for this section:

% \begin{enumerate}
%     \item Discuss how polytope swap regret can be computed and minimized just as a function of the reward vectors $r_{t} \in \learnset^*$ the learner faces, independent of the actual actions $y_{t} \in \optset$ of the Optimizer (``game-agnostic'').
%     \item Point out that it is not sufficient to run a profile-swap-regret minimizing algorithm under the assumption $\cY = \cX^{*}$ to minimize polytope swap regret
%     \item Can we get efficient polytope-swap-regret minimization algorithms under some assumptions?
% \end{enumerate}

% }