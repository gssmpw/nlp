@inproceedings{borovik2023scoreperformer,
  title={ScorePerformer: Expressive Piano Performance Rendering With Fine-Grained Control.},
  author={Borovik, Ilya and Viro, Vladimir},
  booktitle={ISMIR},
  pages={588--596},
  year={2023}
}

@inproceedings{brunner2018symbolic,
  title={Symbolic music genre transfer with cyclegan},
  author={Brunner, Gino and Wang, Yuyi and Wattenhofer, Roger and Zhao, Sumu},
  booktitle={2018 ieee 30th international conference on tools with artificial intelligence (ictai)},
  pages={786--793},
  year={2018},
  organization={IEEE}
}

@article{chang2021variable,
  title={Variable-length music score infilling via XLNet and musically specialized positional encoding},
  author={Chang, Chin-Jui and Lee, Chun-Yi and Yang, Yi-Hsuan},
  journal={arXiv preprint arXiv:2108.05064},
  year={2021}
}

@article{cifka2020groove2groove,
  title={Groove2groove: One-shot music style transfer with supervision from synthetic data},
  author={C{\'\i}fka, Ond{\v{r}}ej and {\c{S}}im{\c{s}}ekli, Umut and Richard, Ga{\"e}l},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={28},
  pages={2638--2650},
  year={2020},
  publisher={IEEE}
}

@inproceedings{colton2024automatic,
  title={Automatic Generation of Expressive Piano Miniatures},
  author={Colton, Simon and Bradshaw, Louis and Banar, Berker and Bhandari, Keshav and others},
  year={2024},
  organization={International Conference on Computational Creativity (ICCC)}
}

@inproceedings{ding2022steelygan,
  title={Steelygan: semantic unsupervised symbolic music genre transfer},
  author={Ding, Zhaoxu and Liu, Xiang and Zhong, Guoqiang and Wang, Dong},
  booktitle={Chinese Conference on Pattern Recognition and Computer Vision (PRCV)},
  pages={305--317},
  year={2022},
  organization={Springer}
}

@inproceedings{fu2020transfer,
title={Transfer symbolic music style from latent representation},
author={Fu, Yingfeng and Tanimura, Yusuke and Nakada, Hidemoto},
booktitle={Proceedings of the 34th Annual Conference of the Japanese Society for Artificial Intelligence (2020)},
pages={2K4ES201--2K4ES201},
year={2020},
organization={The Japanese Society for Artificial Intelligence}
}

@inproceedings{hadjeres2017deepbach,
  title={Deepbach: a steerable model for bach chorales generation},
  author={Hadjeres, Ga{\"e}tan and Pachet, Fran{\c{c}}ois and Nielsen, Frank},
  booktitle={International conference on machine learning},
  pages={1362--1371},
  year={2017},
  organization={PMLR}
}

@article{hadjeres2021piano,
  title={The piano inpainting application},
  author={Hadjeres, Ga{\"e}tan and Crestel, L{\'e}opold},
  journal={arXiv preprint arXiv:2107.05944},
  year={2021}
}

@article{higgins2017beta,
  title={beta-vae: Learning basic visual concepts with a constrained variational framework.},
  author={Higgins, Irina and Matthey, Loic and Pal, Arka and Burgess, Christopher P and Glorot, Xavier and Botvinick, Matthew M and Mohamed, Shakir and Lerchner, Alexander},
  journal={ICLR (Poster)},
  volume={3},
  year={2017}
}

@article{huang2019counterpoint,
  title={Counterpoint by convolution},
  author={Huang, Cheng-Zhi Anna and Cooijmans, Tim and Roberts, Adam and Courville, Aaron and Eck, Douglas},
  journal={arXiv preprint arXiv:1903.07227},
  year={2019}
}

@inproceedings{jeong2019graph,
  title={Graph neural network for music score data and modeling expressive piano performance},
  author={Jeong, Dasaem and Kwon, Taegyun and Kim, Yoojin and Nam, Juhan},
  booktitle={ICML},
  pages={3060--3070},
  year={2019},
  organization={PMLR}
}

@inproceedings{jeong2019virtuosonet,
  title={VirtuosoNet: A Hierarchical RNN-based System for Modeling Expressive Piano Performance.},
  author={Jeong, Dasaem and Kwon, Taegyun and Kim, Yoojin and Lee, Kyogu and Nam, Juhan},
  booktitle={ISMIR},
  pages={908--915},
  year={2019}
}

@article{jiang2020counterpoint,
  title={When counterpoint meets Chinese folk melodies},
  author={Jiang, Nan and Jin, Sheng and Duan, Zhiyao and Zhang, Changshui},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={16258--16270},
  year={2020}
}

@article{lenz2024pertok,
  title={PerTok: Expressive Encoding and Modeling of Symbolic Musical Ideas and Variations},
  author={Lenz, Julian and Mani, Anirudh},
  journal={arXiv preprint arXiv:2410.02060},
  year={2024}
}

@article{lv2023getmusic,
  title={Getmusic: Generating any music tracks with a unified representation and diffusion framework},
  author={Lv, Ang and Tan, Xu and Lu, Peiling and Ye, Wei and Zhang, Shikun and Bian, Jiang and Yan, Rui},
  journal={arXiv preprint arXiv:2305.10841},
  year={2023}
}

@inproceedings{maezawa2019rendering,
  title={Rendering Music Performance With Interpretation Variations Using Conditional Variational RNN.},
  author={Maezawa, Akira and Yamamoto, Kazuhiko and Fujishima, Takuya},
  booktitle={ISMIR},
  pages={855--861},
  year={2019}
}

@article{min2023polyffusion,
  title={Polyffusion: A diffusion model for polyphonic score generation with internal and external controls},
  author={Min, Lejun and Jiang, Junyan and Xia, Gus and Zhao, Jingwei},
  journal={arXiv preprint arXiv:2307.10304},
  year={2023}
}

@INPROCEEDINGS{nakamura2019unsupervised,
  author={Nakamura, Eita and Shibata, Kentaro and Nishikimi, Ryo and Yoshii, Kazuyoshi},
  booktitle={ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Unsupervised Melody Style Conversion}, 
  year={2019},
  volume={},
  number={},
  pages={196-200},
  keywords={Manganese;Hidden Markov models;Data models;Rhythm;C# languages;Syntactics;Bars;Symbolic music processing;music arrangement;style conversion;statistical music language models;unsupervised grammar induction},
  doi={10.1109/ICASSP.2019.8682331}}

@misc{performance-rnn-2017,
    author = {Ian Simon and Sageev Oore},
    title = {
        Performance RNN: Generating Music with Expressive Timing and Dynamics
    },
    journal = {Magenta Blog},
    type = {Blog},
    year = {2017},
    howpublished = {\url{https://magenta.tensorflow.org/performance-rnn}}
}

@inproceedings{ren2020popmag,
  title={Popmag: Pop music accompaniment generation},
  author={Ren, Yi and He, Jinzheng and Tan, Xu and Qin, Tao and Zhao, Zhou and Liu, Tie-Yan},
  booktitle={Proceedings of the 28th ACM international conference on multimedia},
  pages={1198--1206},
  year={2020}
}

@mastersthesis{sulaiman2022genre,
   author = {Sulaiman, Leif and Larsson, Sebastian},
   institution = {Halmstad University, School of Information Technology},
   pages = {74},
   school = {Halmstad University, School of Information Technology},
   title = {Genre style transfer : Symbolic genre style transfer utilising GAN with additional genre-enforcing discriminators},
   keywords = {Artificial Intelligence, Machine Learning, Deep Learning, Generative Adversarial Network, Variational Autoencoder, CycleGAN, Music, Style Transfer, Neural Network},
   year = {2022}
}

@inproceedings{tan2020music,
  title={Music fadernets: Controllable music generation based on high-level features via low-level feature modelling},
  author={Tan, Hao Hao and Herremans, Dorien},
  booktitle={ISMIR},
  year={2020}
}

@article{thickstun2023anticipatory,
  title={Anticipatory music transformer},
  author={Thickstun, John and Hall, David and Donahue, Chris and Liang, Percy},
  journal={arXiv preprint arXiv:2306.08620},
  year={2023}
}

@incollection{wu2023c2,
  title={C2-MAGIC: Chord-Controllable Multi-track Accompaniment Generation with Interpretability and Creativity},
  author={Wu, Jingcheng and Ji, Zihao and Li, Pengfei},
  booktitle={Summit on Music Intelligence},
  pages={108--121},
  year={2023},
  publisher={Springer}
}

@article{wu2023musemorphose,
  title={MuseMorphose: Full-song and fine-grained piano music style transfer with one transformer VAE},
  author={Wu, Shih-Lun and Yang, Yi-Hsuan},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={31},
  pages={1953--1967},
  year={2023},
  publisher={IEEE}
}

@article{wu2024generating,
  title={Generating chord progression from melody with flexible harmonic rhythm and controllable harmonic density},
  author={Wu, Shangda and Yang, Yue and Wang, Zhaowen and Li, Xiaobing and Sun, Maosong},
  journal={EURASIP Journal on Audio, Speech, and Music Processing},
  volume={2024},
  number={1},
  pages={4},
  year={2024},
  publisher={Springer}
}

@article{xiao2024music,
  title={Music performance style transfer for learning expressive musical performance},
  author={Xiao, Zhe and Chen, Xin and Zhou, Li},
  journal={Signal, Image and Video Processing},
  volume={18},
  number={1},
  pages={889--898},
  year={2024},
  publisher={Springer}
}

@article{zhao2021accomontage,
  title={Accomontage: Accompaniment arrangement via phrase selection and style transfer},
  author={Zhao, Jingwei and Xia, Gus},
  journal={arXiv preprint:2108.11213},
  year={2021}
}

@inproceedings{zhaostructured,
  title={Structured Multi-Track Accompaniment Arrangement via Style Prior Modelling},
  author={Zhao, Jingwei and Xia, Gus and Wang, Ziyu and Wang, Ye},
  booktitle={The 38th Annual Conference on Neural Information Processing Systems},
  year={2024}
}

@inproceedings{zhu2017unpaired,
  title={Unpaired image-to-image translation using cycle-consistent adversarial networks},
  author={Zhu, Jun-Yan and Park, Taesung and Isola, Phillip and Efros, Alexei A},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2223--2232},
  year={2017}
}

