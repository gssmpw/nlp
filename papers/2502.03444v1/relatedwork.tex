\section{Related Work}
\label{sec:related}


\textbf{Image Tokenization}. 
Imgae tokenization aims at transforming the high-dimension images into more compact and structured latent representations. 
% It has served as a cornerstone in numerous applications of modern computer vision, such as latent diffusion models \cite{ramesh2021zero,rombach2022high,midjourney,sora} and multi-modality models \cite{zhou2024transfusion,xie2024show,wang2024emu3,wu2024vila,wu2024janus}.
Early explorations mainly used autoencoders \cite{hinton2006reducing,vincent2008extracting}, which learn latent codes reduced dimensionality. 
These foundations soon inspired methods with variational posteriors,
% that balance detail-preserving compression with the ability to encapsulate complex visual concepts, 
such as VAEs \cite{van2017neural,razavi2019generating} and VQ-GAN \cite{esser2021taming,razavi2019generatingdiversehighfidelityimages}. 
% They introduced new ways to structure latent spaces. 
% By imposing priors or quantization constraints, these tokenizers yielded representations that can facilitate more efficient generation and editing processes. 
Recent work has further improved compression fidelity and scalability \cite{lee2022autoregressive,yu2024language,mentzer2023finite,zhu2024scaling}, showing the importance of latent structure.
% that preserves both low-level details and high-level semantics.
% Meanwhile, the growing large-scale pre-training and vision-language modeling \cite{vaswani2023attentionneed} has further encouraged the alignment of latent representations with rich semantic signals. 
% For example, tokens derived from text-aligned embeddings enable more intuitive manipulation and classification \cite{dosovitskiy2021imageworth16x16words,zhu2010deformable}. 
More recent efforts have shown methods that bridge high-fidelity reconstruction and semantic understanding within a single tokenizer \cite{yu2024an,li2024imagefolder,chen2024softvq,wu2024vila,gu2023rethinkingobjectivesvectorquantizedtokenizers}. 
Complementary to them, we further highlight the importance of discriminative latent space, which allows us to use a simple AE yet achieve better generation. 



\textbf{Image Generation}.  
The paradigms of image generation 
%can be broadly divided into 
mainly categorize to autoregressive and diffusion models.
Autoregressive models initially relied on CNN architectures \cite{van2016conditional} and were later augmented with Transformer-based models \cite{vaswani2023attentionneed,yu2024randomized,lee2022autoregressive,liu2024customize,sun2024autoregressive} for improved scalability \cite{chang2022maskgitmaskedgenerativeimage,tian2024visualautoregressivemodelingscalable}. 
% The latest models are designed in an autoregressive fashion on a scale that further improves efficiency .
% including VAR \cite{}, MAR \cite{li2024autoregressiveimagegenerationvector} further enhance efficiency and image quality by optimizing factorized likelihoods and leveraging large-scale training.
Diffusion models show strong performance since their debut \citet{sohldickstein2015deepunsupervisedlearningusing}. 
Key developments \cite{nichol2021improveddenoisingdiffusionprobabilistic,dhariwal2021diffusion,song2022denoisingdiffusionimplicitmodels} refined the denoising process for sharper samples. 
A pivotal step in performance and efficiency came with latent diffusion \cite{vahdat2021scorebasedgenerativemodelinglatent,rombach2022highresolutionimagesynthesislatent}, which uses tokenizers to reduce dimension and conduct denoising in a compact latent space \cite{van2017neural,esser2021taming, peebles2023scalablediffusionmodelstransformers}. 
% Subsequent improvements, such as Transformer-based backbones \cite{}, have broadened the range of achievable image resolutions and enabled more flexible conditioning schemes. 
Recent advances include designing better tokenizers \cite{chen2024softvq,zha2024language,yao2025reconstruction}
% , such as the proposed \method, 
and combining diffusion with autoregressive models \cite{li2024autoregressiveimagegenerationvector}. 

% These methodological strides have fueled a diverse spectrum of applications, from text-guided image generation \cite{nichol2021glide,ding2021cogview} to photorealistic editing \cite{gafni2022make,saharia2022photorealistic}, culminating in commercial systems \cite{ramesh2021zero,rombach2022high,midjourney,sora} that highlight diffusion’s practical impact. As diffusion models continue to evolve, understanding the role of latent spaces—particularly how they balance semantic structure and fidelity—has emerged as a central challenge in large-scale image generation research.