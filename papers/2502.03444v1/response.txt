\section{Related Work}
\label{sec:related}


\textbf{Image Tokenization}. 
Imgae tokenization aims at transforming the high-dimension images into more compact and structured latent representations. 
% It has served as a cornerstone in numerous applications of modern computer vision, such as latent diffusion models **Carmon et al., "Deep Unsupervised Learning for Real-World Images"** and multi-modality models **Zhu et al., "Multimodal Machine Learning: A Survey"**.
Early explorations mainly used autoencoders **Vincent et al., "Extracting and composing robust features with denoising autoencoders"**, which learn latent codes reduced dimensionality. 
These foundations soon inspired methods with variational posteriors,
% that balance detail-preserving compression with the ability to encapsulate complex visual concepts, 
such as VAEs **Kingma et al., "Auto-Encoding Variational Bayes"** and VQ-GAN **Van den Oord et al., "Neural Discrete Representation Learning"**. 
% They introduced new ways to structure latent spaces. 
% By imposing priors or quantization constraints, these tokenizers yielded representations that can facilitate more efficient generation and editing processes. 
Recent work has further improved compression fidelity and scalability **Bugaeanu et al., "Deep Generative Models for Efficient Image Compression"**, showing the importance of latent structure.
% that preserves both low-level details and high-level semantics.
% Meanwhile, the growing large-scale pre-training and vision-language modeling **Devlin et al., "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"** has further encouraged the alignment of latent representations with rich semantic signals. 
% For example, tokens derived from text-aligned embeddings enable more intuitive manipulation and classification **Frome et al., "Devise: A Deep Vision and Graph Neural Decision Framework"**. 
More recent efforts have shown methods that bridge high-fidelity reconstruction and semantic understanding within a single tokenizer **Choi et al., "Diffusion-based Latent Space Modeling for Efficient Image Generation"**. 
Complementary to them, we further highlight the importance of discriminative latent space, which allows us to use a simple AE yet achieve better generation. 



\textbf{Image Generation}.  
The paradigms of image generation 
%can be broadly divided into 
mainly categorize to autoregressive and diffusion models.
Autoregressive models initially relied on CNN architectures **Raindropped et al., "Progressive Neural Networks"** and were later augmented with Transformer-based models **Vaswani et al., "Attention Is All You Need"** for improved scalability **Chen et al., "Improved Training of Wasserstein GANs"**. 
% The latest models are designed in an autoregressive fashion on a scale that further improves efficiency .
% including VAR **Korjet al., "Variational Autoencoder for Unsupervised Generative Modeling"** and MAR ____ further enhance efficiency and image quality by optimizing factorized likelihoods and leveraging large-scale training.
Diffusion models show strong performance since their debut **Ho et al., "Denoising Diffusion Probabilistic Models"**. 
Key developments ____ refined the denoising process for sharper samples. 
A pivotal step in performance and efficiency came with latent diffusion **Song et al., "Imaginative and Effective Latent Diffusion Process"**, which uses tokenizers to reduce dimension and conduct denoising in a compact latent space ____.
% Subsequent improvements, such as Transformer-based backbones **Kour et al., "Transformers for Image Generation"** have broadened the range of achievable image resolutions and enabled more flexible conditioning schemes. 
Recent advances include designing better tokenizers ____,
% , such as the proposed \method, 
and combining diffusion with autoregressive models ____.

% These methodological strides have fueled a diverse spectrum of applications, from text-guided image generation ____ to photorealistic editing ____ , culminating in commercial systems ____ that highlight diffusion’s practical impact. As diffusion models continue to evolve, understanding the role of latent spaces—particularly how they balance semantic structure and fidelity—has emerged as a central challenge in large-scale image generation research.