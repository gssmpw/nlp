[
  {
    "index": 0,
    "papers": [
      {
        "key": "ramesh2021zero",
        "author": "Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray, Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and Sutskever, Ilya",
        "title": "Zero-shot text-to-image generation"
      },
      {
        "key": "rombach2022high",
        "author": "Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\\\"o}rn",
        "title": "High-resolution image synthesis with latent diffusion models"
      },
      {
        "key": "midjourney",
        "author": "{MidJourney Inc.}",
        "title": "MidJourney"
      },
      {
        "key": "sora",
        "author": "OpenAI",
        "title": "Video Generation Models as World Simulators"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "zhou2024transfusion",
        "author": "Zhou, Chunting and Yu, Lili and Babu, Arun and Tirumala, Kushal and Yasunaga, Michihiro and Shamis, Leonid and Kahn, Jacob and Ma, Xuezhe and Zettlemoyer, Luke and Levy, Omer",
        "title": "Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"
      },
      {
        "key": "xie2024show",
        "author": "Xie, Jinheng and Mao, Weijia and Bai, Zechen and Zhang, David Junhao and Wang, Weihao and Lin, Kevin Qinghong and Gu, Yuchao and Chen, Zhijie and Yang, Zhenheng and Shou, Mike Zheng",
        "title": "Show-o: One single transformer to unify multimodal understanding and generation"
      },
      {
        "key": "wang2024emu3",
        "author": "Wang, Xinlong and Zhang, Xiaosong and Luo, Zhengxiong and Sun, Quan and Cui, Yufeng and Wang, Jinsheng and Zhang, Fan and Wang, Yueze and Li, Zhen and Yu, Qiying and others",
        "title": "Emu3: Next-token prediction is all you need"
      },
      {
        "key": "wu2024vila",
        "author": "Wu, Yecheng and Zhang, Zhuoyang and Chen, Junyu and Tang, Haotian and Li, Dacheng and Fang, Yunhao and Zhu, Ligeng and Xie, Enze and Yin, Hongxu and Yi, Li and others",
        "title": "Vila-u: a unified foundation model integrating visual understanding and generation"
      },
      {
        "key": "wu2024janus",
        "author": "Wu, Chengyue and Chen, Xiaokang and Wu, Zhiyu and Ma, Yiyang and Liu, Xingchao and Pan, Zizheng and Liu, Wen and Xie, Zhenda and Yu, Xingkai and Ruan, Chong and others",
        "title": "Janus: Decoupling visual encoding for unified multimodal understanding and generation"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "hinton2006reducing",
        "author": "Hinton, Geoffrey E and Salakhutdinov, Ruslan R",
        "title": "Reducing the dimensionality of data with neural networks"
      },
      {
        "key": "vincent2008extracting",
        "author": "Vincent, Pascal and Larochelle, Hugo and Bengio, Yoshua and Manzagol, Pierre-Antoine",
        "title": "Extracting and composing robust features with denoising autoencoders"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "van2017neural",
        "author": "Van Den Oord, Aaron and Vinyals, Oriol and others",
        "title": "Neural discrete representation learning"
      },
      {
        "key": "razavi2019generating",
        "author": "Razavi, Ali and Van den Oord, Aaron and Vinyals, Oriol",
        "title": "Generating diverse high-fidelity images with vq-vae-2"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "esser2021taming",
        "author": "Esser, Patrick and Rombach, Robin and Ommer, Bjorn",
        "title": "Taming transformers for high-resolution image synthesis"
      },
      {
        "key": "razavi2019generatingdiversehighfidelityimages",
        "author": "Ali Razavi and Aaron van den Oord and Oriol Vinyals",
        "title": "Generating Diverse High-Fidelity Images with VQ-VAE-2"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "lee2022autoregressive",
        "author": "Lee, Doyup and Kim, Chiheon and Kim, Saehoon and Cho, Minsu and Han, Wook-Shin",
        "title": "Autoregressive image generation using residual quantization"
      },
      {
        "key": "yu2024language",
        "author": "Lijun Yu and Jose Lezama and Nitesh Bharadwaj Gundavarapu and Luca Versari and Kihyuk Sohn and David Minnen and Yong Cheng and Agrim Gupta and Xiuye Gu and Alexander G Hauptmann and Boqing Gong and Ming-Hsuan Yang and Irfan Essa and David A Ross and Lu Jiang",
        "title": "Language Model Beats Diffusion - Tokenizer is key to visual generation"
      },
      {
        "key": "mentzer2023finite",
        "author": "Fabian Mentzer and David Minnen and Eirikur Agustsson and Michael Tschannen",
        "title": "Finite Scalar Quantization: VQ-VAE Made Simple"
      },
      {
        "key": "zhu2024scaling",
        "author": "Zhu, Lei and Wei, Fangyun and Lu, Yanye and Chen, Dong",
        "title": "Scaling the Codebook Size of VQGAN to 100,000 with a Utilization Rate of 99\\%"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "vaswani2023attentionneed",
        "author": "Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin",
        "title": "Attention Is All You Need"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "dosovitskiy2021imageworth16x16words",
        "author": "Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby",
        "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"
      },
      {
        "key": "zhu2010deformable",
        "author": "Zhu, X and Su, W and Lu, L and Li, B and Wang, X and Dai, J",
        "title": "Deformable detr: Deformable transformers for end-to-end object detection. arXiv 2020"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "yu2024an",
        "author": "Qihang Yu and Mark Weber and Xueqing Deng and Xiaohui Shen and Daniel Cremers and Liang-Chieh Chen",
        "title": "An Image is Worth 32 Tokens for Reconstruction and Generation"
      },
      {
        "key": "li2024imagefolder",
        "author": "Li, Xiang and Chen, Hao and Qiu, Kai and Kuen, Jason and Gu, Jiuxiang and Raj, Bhiksha and Lin, Zhe",
        "title": "ImageFolder: Autoregressive Image Generation with Folded Tokens"
      },
      {
        "key": "chen2024softvq",
        "author": "Chen, Hao and Wang, Ze and Li, Xiang and Sun, Ximeng and Chen, Fangyi and Liu, Jiang and Wang, Jindong and Raj, Bhiksha and Liu, Zicheng and Barsoum, Emad",
        "title": "SoftVQ-VAE: Efficient 1-Dimensional Continuous Tokenizer"
      },
      {
        "key": "wu2024vila",
        "author": "Wu, Yecheng and Zhang, Zhuoyang and Chen, Junyu and Tang, Haotian and Li, Dacheng and Fang, Yunhao and Zhu, Ligeng and Xie, Enze and Yin, Hongxu and Yi, Li and others",
        "title": "Vila-u: a unified foundation model integrating visual understanding and generation"
      },
      {
        "key": "gu2023rethinkingobjectivesvectorquantizedtokenizers",
        "author": "Yuchao Gu and Xintao Wang and Yixiao Ge and Ying Shan and Xiaohu Qie and Mike Zheng Shou",
        "title": "Rethinking the Objectives of Vector-Quantized Tokenizers for Image Synthesis"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "van2016conditional",
        "author": "Van den Oord, Aaron and Kalchbrenner, Nal and Espeholt, Lasse and Vinyals, Oriol and Graves, Alex and others",
        "title": "Conditional image generation with pixelcnn decoders"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "vaswani2023attentionneed",
        "author": "Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin",
        "title": "Attention Is All You Need"
      },
      {
        "key": "yu2024randomized",
        "author": "Yu, Qihang and He, Ju and Deng, Xueqing and Shen, Xiaohui and Chen, Liang-Chieh",
        "title": "Randomized Autoregressive Visual Generation"
      },
      {
        "key": "lee2022autoregressive",
        "author": "Lee, Doyup and Kim, Chiheon and Kim, Saehoon and Cho, Minsu and Han, Wook-Shin",
        "title": "Autoregressive image generation using residual quantization"
      },
      {
        "key": "liu2024customize",
        "author": "Liu, Wenze and Zhuo, Le and Xin, Yi and Xia, Sheng and Gao, Peng and Yue, Xiangyu",
        "title": "Customize your visual autoregressive recipe with set autoregressive modeling"
      },
      {
        "key": "sun2024autoregressive",
        "author": "Sun, Peize and Jiang, Yi and Chen, Shoufa and Zhang, Shilong and Peng, Bingyue and Luo, Ping and Yuan, Zehuan",
        "title": "Autoregressive Model Beats Diffusion: Llama for Scalable Image Generation"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "chang2022maskgitmaskedgenerativeimage",
        "author": "Huiwen Chang and Han Zhang and Lu Jiang and Ce Liu and William T. Freeman",
        "title": "MaskGIT: Masked Generative Image Transformer"
      },
      {
        "key": "tian2024visualautoregressivemodelingscalable",
        "author": "Keyu Tian and Yi Jiang and Zehuan Yuan and Bingyue Peng and Liwei Wang",
        "title": "Visual Autoregressive Modeling: Scalable Image Generation via Next-Scale Prediction"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "",
        "author": "Unknown",
        "title": "Unknown"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "li2024autoregressiveimagegenerationvector",
        "author": "Tianhong Li and Yonglong Tian and He Li and Mingyang Deng and Kaiming He",
        "title": "Autoregressive Image Generation without Vector Quantization"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "sohldickstein2015deepunsupervisedlearningusing",
        "author": "Jascha Sohl-Dickstein and Eric A. Weiss and Niru Maheswaranathan and Surya Ganguli",
        "title": "Deep Unsupervised Learning using Nonequilibrium Thermodynamics"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "nichol2021improveddenoisingdiffusionprobabilistic",
        "author": "Alex Nichol and Prafulla Dhariwal",
        "title": "Improved Denoising Diffusion Probabilistic Models"
      },
      {
        "key": "dhariwal2021diffusion",
        "author": "Dhariwal, Prafulla and Nichol, Alexander",
        "title": "Diffusion models beat gans on image synthesis"
      },
      {
        "key": "song2022denoisingdiffusionimplicitmodels",
        "author": "Jiaming Song and Chenlin Meng and Stefano Ermon",
        "title": "Denoising Diffusion Implicit Models"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "vahdat2021scorebasedgenerativemodelinglatent",
        "author": "Arash Vahdat and Karsten Kreis and Jan Kautz",
        "title": "Score-based Generative Modeling in Latent Space"
      },
      {
        "key": "rombach2022highresolutionimagesynthesislatent",
        "author": "Robin Rombach and Andreas Blattmann and Dominik Lorenz and Patrick Esser and Bj\u00f6rn Ommer",
        "title": "High-Resolution Image Synthesis with Latent Diffusion Models"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "van2017neural",
        "author": "Van Den Oord, Aaron and Vinyals, Oriol and others",
        "title": "Neural discrete representation learning"
      },
      {
        "key": "esser2021taming",
        "author": "Esser, Patrick and Rombach, Robin and Ommer, Bjorn",
        "title": "Taming transformers for high-resolution image synthesis"
      },
      {
        "key": "peebles2023scalablediffusionmodelstransformers",
        "author": "William Peebles and Saining Xie",
        "title": "Scalable Diffusion Models with Transformers"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "",
        "author": "Unknown",
        "title": "Unknown"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "chen2024softvq",
        "author": "Chen, Hao and Wang, Ze and Li, Xiang and Sun, Ximeng and Chen, Fangyi and Liu, Jiang and Wang, Jindong and Raj, Bhiksha and Liu, Zicheng and Barsoum, Emad",
        "title": "SoftVQ-VAE: Efficient 1-Dimensional Continuous Tokenizer"
      },
      {
        "key": "zha2024language",
        "author": "Zha, Kaiwen and Yu, Lijun and Fathi, Alireza and Ross, David A and Schmid, Cordelia and Katabi, Dina and Gu, Xiuye",
        "title": "Language-Guided Image Tokenization for Generation"
      },
      {
        "key": "yao2025reconstruction",
        "author": "Yao, Jingfeng and Wang, Xinggang",
        "title": "Reconstruction vs. Generation: Taming Optimization Dilemma in Latent Diffusion Models"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "li2024autoregressiveimagegenerationvector",
        "author": "Tianhong Li and Yonglong Tian and He Li and Mingyang Deng and Kaiming He",
        "title": "Autoregressive Image Generation without Vector Quantization"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "nichol2021glide",
        "author": "Nichol, Alex and Dhariwal, Prafulla and Ramesh, Aditya and Shyam, Pranav and Mishkin, Pamela and McGrew, Bob and Sutskever, Ilya and Chen, Mark",
        "title": "Glide: Towards photorealistic image generation and editing with text-guided diffusion models"
      },
      {
        "key": "ding2021cogview",
        "author": "Ding, Ming and Yang, Zhuoyi and Hong, Wenyi and Zheng, Wendi and Zhou, Chang and Yin, Da and Lin, Junyang and Zou, Xu and Shao, Zhou and Yang, Hongxia and others",
        "title": "Cogview: Mastering text-to-image generation via transformers"
      }
    ]
  },
  {
    "index": 22,
    "papers": [
      {
        "key": "gafni2022make",
        "author": "Gafni, Oran and Polyak, Adam and Ashual, Oron and Sheynin, Shelly and Parikh, Devi and Taigman, Yaniv",
        "title": "Make-a-scene: Scene-based text-to-image generation with human priors"
      },
      {
        "key": "saharia2022photorealistic",
        "author": "Saharia, Chitwan and Chan, William and Saxena, Saurabh and Li, Lala and Whang, Jay and Denton, Emily L and Ghasemipour, Kamyar and Gontijo Lopes, Raphael and Karagol Ayan, Burcu and Salimans, Tim and others",
        "title": "Photorealistic text-to-image diffusion models with deep language understanding"
      }
    ]
  },
  {
    "index": 23,
    "papers": [
      {
        "key": "ramesh2021zero",
        "author": "Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray, Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and Sutskever, Ilya",
        "title": "Zero-shot text-to-image generation"
      },
      {
        "key": "rombach2022high",
        "author": "Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\\\"o}rn",
        "title": "High-resolution image synthesis with latent diffusion models"
      },
      {
        "key": "midjourney",
        "author": "{MidJourney Inc.}",
        "title": "MidJourney"
      },
      {
        "key": "sora",
        "author": "OpenAI",
        "title": "Video Generation Models as World Simulators"
      }
    ]
  }
]