\setlength{\tabcolsep}{4pt}
\begin{table*}[t!]
\centering

\resizebox{0.85\linewidth}{!}{%
\begin{tabular}{@{}l c | c c c c | c c | c c@{}}
\toprule
\multirow{2}{*}{Model (G)} &
\multirow{2}{*}{\# Params (G)} &
\multirow{2}{*}{Model (T)} &
\multirow{2}{*}{\# Params (T)} &
\multirow{2}{*}{\# Tokens $\downarrow$} &
\multirow{2}{*}{rFID $\downarrow$} &
\multicolumn{2}{c|}{w/o CFG} &
\multicolumn{2}{c}{w/ CFG} \\

& & & & & & gFID $\downarrow$ & IS $\uparrow$ & gFID $\downarrow$ & IS $\uparrow$ \\
\toprule
\multicolumn{10}{l}{\textit{GAN}\vspace{0.02in}} \\

\pz\pz  BigGAN \cite{chang2022maskgitmaskedgenerativeimage}
 & -- & -- & -- & -- & -- 
 & -- & -- 
 & 8.43 & 177.9 \\

\pz\pz  StyleGAN-XL \cite{karras2019style}
 & 168M & -- & -- & -- & -- 
 & -- & -- 
 & 2.41 & 267.7 \\
\arrayrulecolor{gray}\cmidrule(lr){1-10}

\multicolumn{10}{l}{\textit{Auto-regressive}\vspace{0.02in}} \\

\pz\pz  MaskGIT \cite{chang2022maskgitmaskedgenerativeimage}
 & 227M & VQ & 66M & 1024 & 1.97
 & 7.32 & 156.0
 & -- & -- \\

\pz\pz  TiTok-B-64 \cite{yu2024an}
 & 177M & VQ & 202M & 128 & 1.52
 & -- & --
 & 2.13 & 261.2 \\

\pz\pz  MAGVIT-v2 \cite{yu2024language}
 & 307M & LFQ & 116M & 1024 & -
 & -- & --
 & 1.91 & 324.3 \\
 
 \pz\pz MAR-H \cite{li2024autoregressiveimagegenerationvector} & 943M & KL & 66M & 1024 & -- & 2.74 & 205.2 & 1.73  & 279.9  \\
\arrayrulecolor{gray}\cmidrule(lr){1-10}

\multicolumn{10}{l}{\textit{Diffusion-based}\vspace{0.02in}} \\

 \pz\pz ADM \cite{dhariwal2021diffusion}
 & -- & -- & -- & -- & -- 
 & 23.24 & 58.06
 & 3.85 & 221.7 \\


% -----------------------------
% Shared (KL, 4096, 0.62) block
 \pz\pz U-ViT-H/4 \cite{bao2023all}
 & 501M & \multirow{3}{*}{KL$^\dagger$} & \multirow{3}{*}{84M} 
 & \multirow{3}{*}{4096} & \multirow{3}{*}{0.62}
 & -- & --
 & 4.05 & 263.8 \\

 % \pz\pz EDM-XXL \cite{karras2022elucidating}
 % & 1.5B &  &  &  &  
 % & 1.91 & -
 % & 1.81 & - \\

 \pz\pz DiT-XL/2 \cite{peebles2023scalablediffusionmodelstransformers}
 & 675M  &  &  &  & 
 & 9.62 & 121.5
 & 3.04 & 240.8 \\

 \pz\pz SiT-XL/2 \cite{ma2024sit}
 & 675M   &  &  &  & 
 & -- & --
 & 2.62 & 252.2 \\

% -----------------------------
% Shared (AE, 256, 0.22) block
 \pz\pz DiT-XL \cite{chen2024deep}
 & 675M & \multirow{5}{*}{AE$^\dagger$} & \multirow{5}{*}{323M} 
 & \multirow{5}{*}{256} & \multirow{5}{*}{0.22}
 & 9.56 & --
 & 2.84 & -- \\

 \pz\pz UViT-H \cite{chen2024deep}
 & 501M &  &  &  & 
 & 9.83 & --
 & 2.53 & -- \\

% -----------------------------
% Shared (AE, 64, 0.22) block
 \pz\pz UViT-H \cite{chen2024deep}
 & 501M &  & 
 &  & 
 & 12.26 & --
 & 2.66 & -- \\

 \pz\pz UViT-2B \cite{chen2024deep}
 & 2B &  &  &  & 
 & 6.50 & --
 & 2.25 & -- \\

 \pz\pz USiT-2B \cite{chen2024deep}
 & 2B &  &  &  & 
 & 2.90 & --
 & 1.72 & -- \\
 % \midrule
\arrayrulecolor{gray}\cmidrule(lr){1-10}


\multicolumn{10}{l}{\textit{Ours}\vspace{0.02in}} \\
\grayrow
\pz\pz  MAETok + LightningDiT 
 & 675M &  &   &   & 
 &  \textbf{2.56} &  \textbf{224.5}  &   1.72  &  307.3 \\
\grayrow
\pz\pz  MAETok + SiT-XL  
 & 675M & \multirow{-2}{*}{
 AE}  & \multirow{-2}{*}{176M} & \multirow{-2}{*}{
 \textbf{128}} &  \multirow{-2}{*}{0.62}
 &  2.79 &  204.3  &  \textbf{1.69}  &  304.2 \\

\bottomrule
\end{tabular}%
}
\vspace{-0.1in}
\caption{System-level comparison on ImageNet 512$\times$512 conditional generation.
SiT-XL and LightningDiT trained on \method achieve state-of-the-art performance using plain AE with only 128 tokens, outperforming USiT of 2B parameters using only 675M parameters.  
}
\label{tab:main_512}
\vspace{-0.15in}
\end{table*}
