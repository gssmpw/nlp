\begin{table}[h]
\centering
\resizebox{0.5\linewidth}{!}{%
\begin{tabular}{l|l}
\toprule
\textbf{Configuration} & \textbf{Value} \\
\midrule
% -- First block
image resolution        & 256$\times$256, 512$\times$512 \\
enc/dec hidden dimension        & 768 \\
enc/dec  \#heads                 & 12 \\
enc/dec  \#layers                & 12 \\
enc/dec  patch size              & 16 \\
enc/dec positional embedding    & 2D RoPE (image), 1D APE (latent) \\
\midrule
% -- Second block
optimizer               & AdamW \cite{loshchilov2017decoupled} \\
base learning rate      & 1e$^{-4}$ \\
weight decay            & 1e$^{-4}$ \\
optimizer momentum      & $\beta_{1}, \beta_{2} = 0.9,\;0.95$ \\
global batch size              & 512 \\
learning rate schedule  & cosine \\
warmup steps         & 10K \\
training steps         & 500K \\
augmentation            & horizontal flip, center crop \\
\midrule
% -- Third block
discriminator       & DINOv2-S  \\
discriminator weight         & 0.4 with adaptive weight \\
discriminator start         &  30K \\
discriminator LeCAM         &  0.001 \cite{tseng2021regularizinggenerativeadversarialnetworks} \\
perceptual weight        & 1.0 \\
evaluation metric       & FID-50k \\
\bottomrule
\end{tabular}
}
\caption{Training configuration of \method on 256$\times$256 and 512$\times$512 ImageNet.}
\label{tab:ae_config_table}
\end{table}