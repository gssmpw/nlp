\section{Conclusion}
This paper addressed the negative impact of preference conflicts on achieving a superior Pareto Front in DPO-based MOA. 
Through extensive analysis and experiments, we revealed the impact of preference conflicts on Pareto Front optimization. 
To mitigate this issue, we proposed SIPO, a framework that automatically generates and leverages Pareto-optimal responses to resolve preference conflicts, which outperformed baseline methods in achieving a superior Pareto Front. 
In the future, we plan to extend our experiments to more than two objectives and additional DPO-based methods. 
We will also explore how to improve the efficiency of obtaining Pareto-optimal responses to reduce the cost. 






