\section{Introduction}

Sequence modeling lies at the core of numerous applications, ranging from natural language processing to time-series forecasting. Traditional recurrent neural networks (RNNs) such as LSTM~\cite{hochreiter1997long} have shown impressive capabilities; however, their sequential nature limits parallelization and hampers long-range dependency modeling. Recent transformer models~\cite{vaswani2017attention} have addressed some of these issues by leveraging self-attention to capture global interactions, but they often incur high computational costs and struggle with subtle temporal dynamics.

In response to these challenges, we propose \textbf{LDN}, a novel recurrent architecture that models temporal evolution as a diffusion process. By reinterpreting hidden state updates as a blend of gradual diffusion and local nonlinear transformations, our method naturally propagates information across all time steps. This innovative approach not only facilitates full parallelization but also ensures that each tokenâ€™s representation is enriched by contributions from the entire sequence.

The key contributions of our work are threefold: \ballnumber{1} We formulate a unified diffusion framework that combines continuous, diffusive updates with discrete attention mechanisms, thereby achieving both global interaction and local sensitivity.
    \ballnumber{2} We provide theoretical guarantees that our diffusion operations preserve global interactions, ensuring that every token contributes to the final representation.
    \ballnumber{3} We empirically demonstrate the efficacy of LDN on diverse sequential tasks, where it outperforms traditional RNNs and recent transformer-based models in terms of efficiency and performance.

By bridging the gap between efficient computation and robust representation learning, LDN represents a significant step forward in the field of sequential modeling.
