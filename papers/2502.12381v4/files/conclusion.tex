\section{Conclusion}
In this work, we introduced LDN, a novel recurrent architecture that reinterprets temporal information sharing as a diffusion process. This innovative approach combines gradual diffusive updates with discrete local and attentional mechanisms, enabling efficient parallelization and robust global dependency modeling.

Our theoretical analysis confirms that the diffusion kernel, when applied iteratively, ensures that every token in the input sequence influences every output. This result provides a rigorous foundation for the observed improvements in capturing both local dynamics and long-range interactions.

Empirical evaluations on ImageNet, CIFAR-10, and the LRA benchmark demonstrate that LDN outperforms competitive baselines such as ViT~\cite{dosovitskiy2020image}, BERT~\cite{devlin2019bert}, and RoBERTa~\cite{liu2019roberta}. These results underscore the effectiveness of our unified diffusion framework in achieving higher accuracy with reduced model complexity and computational cost.

Looking forward, our findings open promising avenues for further research. Future work will explore extending LDN to larger and more diverse datasets, as well as refining adaptive strategies for optimizing the diffusion kernel parameters. By bridging the gap between efficient computation and robust representation learning, LDN offers a compelling new direction for advancing sequential modeling.

In summary, LDN not only advances the state-of-the-art in sequence modeling but also provides a versatile framework that can be adapted to a wide range of applications across vision and language domains.
