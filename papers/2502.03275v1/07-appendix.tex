\section{Experiment Details}
\label{app:model}

\subsection{VQ-VAE Model Details}
The codebook size $|\mathcal{E}|$ is 64 for ProntoQA and ProsQA, 512 for the Keys-Finding Maze, and 1024 for math reasoning problems. 
For both encoder $\fenc$ and decoder $\fdec$, we use a 2-layer transformer with 4 heads, where the embedding size is 512 and the block size is 512. We set the max sequence to be 2048 for the synthetic dataset experiments and 256 for the math reasoning experiments. 


\subsection{Keys-Finding Maze}
\label{app:maze}
\subsubsection{Environment Details}
In this section, we introduce our synthetic keys-finding maze environment. \Cref{fig:maze_env} shows an example maze that consists of $m \times m$ rooms, where the size of each room is $n \times n$ ($m = 3$ and $n = 5$). The goal of the agent (represented by the black circle) is to reach the gold diamond using the minimum number of steps. The agent cannot cross the wall. Also, there are three doors (represented by squares) of different colors (i.e., red, green, and blue) which are closed initially. The agent have to pick up keys to open the door in the same color. Note that the agent can not carry more than one key at the same time. 

\Cref{fig:maze_traj} shows an example optimal trajectory of the maze in \Cref{fig:maze_env}. The agent first picks up the blue key and opens the blue door to obtain the red key. Then the agent navigates to the red door and opens it. Finally the agent is able to reach the objective. 

\begin{figure}[H]
  \centering
  \includegraphics[width=4cm]{plots/maze_env.png}
  \caption{An example of the keys-finding maze environment. }
  \label{fig:maze_env}
\end{figure}

\begin{figure}[H]
  \centering
  \begin{subfigure}[b]{0.22\textwidth}
    \centering
    \includegraphics[width=4cm]{plots/maze_traj1.png}
    \caption{Phase 1}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.22\textwidth}
    \centering
    \includegraphics[width=4cm]{plots/maze_traj2.png}
    \caption{Phase 2}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.22\textwidth}
    \centering
    \includegraphics[width=4cm]{plots/maze_traj3.png}
    \caption{Phase 3}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.22\textwidth}
    \centering
    \includegraphics[width=4cm]{plots/maze_traj4.png}
    \caption{Phase 4}
  \end{subfigure}
  \caption{An (optimal) trajectory of the maze in \Cref{fig:maze_env}. Phase 1: the agent picks up the blue key; Phase 2: the agent opens the blue door to obtain the red key; Phase 3: the agent carries the red key to the red door; Phase 4: the agent opens the red door and reaches the objective. }
  \label{fig:maze_traj}
\end{figure}

\subsubsection{Dataset Details}
Our dataset consists of 100k training data points, 500 validation data points, and 300 data points for testing.  For each data point, the structure of the prompt and response is as follows:

\begin{itemize}
    \item \prompt
    \\ $\quad$  \texttt{\textbf{maze\_size}}: $M\times M$ \\
    \texttt{\textbf{agent}}: $(x_{a0},y_{a0}),$   \\ \texttt{\textbf{walls}}: $(x_1,y_1), (x_2,y_2), \ldots $ 
    \\  \texttt{\textbf{objective}}: $(x_o,y_o),$
    \\ \texttt{\textbf{keys}}: \texttt{[red\_key]:} $(x_{rk}, y_{rk}), \ldots $
   \\ \texttt{\textbf{doors}}: \texttt{[red\_door]:} $(x_{rd}, y_{rd}), \ldots $
    \item \response
    \\
    create-node $(x_{a1}, y_{a1}, f_{a1}, h_{a1})$, \\create-node $(x_{a2}, y_{a2}, f_{a2}, h_{a2})$, \\ \ldots \\ agent $(x_{a1}, y_{a1}), (x_{a2}, y_{a2}), \ldots, (x_{aT}, y_{aT}),$
\end{itemize}

Below, we show the prompt and response for an example training data pint.

\begin{tcolorbox}[title=Prompt, colback=white]
initial\_state: maze\_size: 19x19 wall: (0,0), (0,1), (0,2), (0,3), (0,4), (0,5), (0,6), (0,7), (0,8), (0,9), (0,10), (0,11), (0,12), (0,13), (0,14), (0,15), (0,16), (0,17), (0,18), (1,0), (1,6), (1,12), (1,18), (2,0), (2,6), (2,12), (2,18), (3,0), (3,6), (3,12), (3,18), (4,0), (4,6), (4,12), (4,18), (5,0), (5,6), (5,12), (5,18), (6,0), (6,1), (6,3), (6,4), (6,5), (6,6), (6,7), (6,8), (6,9), (6,10), (6,11), (6,12), (6,13), (6,14), (6,15), (6,16), (6,17), (6,18), (7,0), (7,12), (7,18), (8,0), (8,6), (8,12), (8,18), (9,0), (9,6), (9,12), (9,18), (10,0), (10,6), (10,12), (10,18), (11,0), (11,6), (11,12), (11,18), (12,0), (12,1), (12,2), (12,3), (12,4), (12,6), (12,8), (12,9), (12,10), (12,11), (12,12), (12,13), (12,14), (12,15), (12,16), (12,17), (12,18), (13,0), (13,12), (13,18), (14,0), (14,6), (14,12), (14,18), (15,0), (15,6), (15,12), (15,18), (16,0), (16,6), (16,12), (16,18), (17,0), (17,6), (17,12), (17,18), (18,0), (18,1), (18,2), (18,3), (18,4), (18,5), (18,6), (18,7), (18,8), (18,9), (18,10), (18,11), (18,12), (18,13), (18,14), (18,15), (18,16), (18,17), (18,18), agent: (11,5), objective: (1,1), [red\_key]: (16,1), [green\_key]: (16,9), [blue\_key]: (7,2), [red\_door]: (12,5), [green\_door]: (6,2), [blue\_door]: (12,7) 
\end{tcolorbox}




\begin{tcolorbox}[title=Response (CoT and Answer), colback=white]
\tiny
create-node: (11,5), heuristics: 14, cost: 0 create-node: (11,4), heuristics: 13, cost: 1 create-node: (11,3), heuristics: 12, cost: 2 create-node: (10,3), heuristics: 11, cost: 3 create-node: (9,3), heuristics: 10, cost: 4 create-node: (9,2), heuristics: 9, cost: 5 create-node: (8,2), heuristics: 8, cost: 6 create-node: (7,2), heuristics: 7, cost: 7 create-node: (7,2), heuristics: 7, cost: 8 create-node: (7,3), heuristics: 8, cost: 9 create-node: (7,4), heuristics: 9, cost: 10 create-node: (7,5), heuristics: 10, cost: 11 create-node: (7,6), heuristics: 11, cost: 12 create-node: (7,7), heuristics: 12, cost: 13 create-node: (8,7), heuristics: 13, cost: 14 create-node: (9,7), heuristics: 14, cost: 15 create-node: (10,7), heuristics: 15, cost: 16 create-node: (11,7), heuristics: 16, cost: 17 create-node: (11,7), heuristics: 16, cost: 18 create-node: (12,7), heuristics: 17, cost: 19 create-node: (13,7), heuristics: 18, cost: 20 create-node: (14,7), heuristics: 19, cost: 21 create-node: (14,8), heuristics: 20, cost: 22 create-node: (15,8), heuristics: 21, cost: 23 create-node: (15,9), heuristics: 22, cost: 24 create-node: (16,9), heuristics: 23, cost: 25 create-node: (16,9), heuristics: 23, cost: 26 create-node: (16,8), heuristics: 22, cost: 27 create-node: (16,7), heuristics: 21, cost: 28 create-node: (15,7), heuristics: 20, cost: 29 create-node: (14,7), heuristics: 19, cost: 30 create-node: (13,7), heuristics: 18, cost: 31 create-node: (12,7), heuristics: 17, cost: 32 create-node: (11,7), heuristics: 16, cost: 33 create-node: (10,7), heuristics: 15, cost: 34 create-node: (9,7), heuristics: 14, cost: 35 create-node: (8,7), heuristics: 13, cost: 36 create-node: (7,7), heuristics: 12, cost: 37 create-node: (7,6), heuristics: 11, cost: 38 create-node: (7,5), heuristics: 10, cost: 39 create-node: (7,4), heuristics: 9, cost: 40 create-node: (7,3), heuristics: 8, cost: 41 create-node: (7,2), heuristics: 7, cost: 42 create-node: (7,2), heuristics: 7, cost: 43 create-node: (6,2), heuristics: 6, cost: 44 create-node: (5,2), heuristics: 5, cost: 45 create-node: (5,1), heuristics: 4, cost: 46 create-node: (4,1), heuristics: 3, cost: 47 create-node: (3,1), heuristics: 2, cost: 48 create-node: (2,1), heuristics: 1, cost: 49 create-node: (1,1), heuristics: 0, cost: 50 agent: (11,5), current\_key: none, remaining\_key: [red\_key]: [green\_key]: [blue\_key]: remaining\_door: [red\_door]: [green\_door]: [blue\_door]:  agent: (11,4), current\_key: none, remaining\_key: [red\_key]: [green\_key]: [blue\_key]: remaining\_door: [red\_door]: [green\_door]: [blue\_door]:  agent: (11,3), current\_key: none, remaining\_key: [red\_key]: [green\_key]: [blue\_key]: remaining\_door: [red\_door]: [green\_door]: [blue\_door]:  agent: (10,3), current\_key: none, remaining\_key: [red\_key]: [green\_key]: [blue\_key]: remaining\_door: [red\_door]: [green\_door]: [blue\_door]:  agent: (9,3), current\_key: none, remaining\_key: [red\_key]: [green\_key]: [blue\_key]: remaining\_door: [red\_door]: [green\_door]: [blue\_door]:  agent: (9,2), current\_key: none, remaining\_key: [red\_key]: [green\_key]: [blue\_key]: remaining\_door: [red\_door]: [green\_door]: [blue\_door]:  agent: (8,2), current\_key: none, remaining\_key: [red\_key]: [green\_key]: [blue\_key]: remaining\_door: [red\_door]: [green\_door]: [blue\_door]:  agent: (7,2), current\_key: none, remaining\_key: [red\_key]: [green\_key]: [blue\_key]: remaining\_door: [red\_door]: [green\_door]: [blue\_door]:  agent: (7,2), current\_key: [blue\_key], remaining\_key: [red\_key]: [green\_key]: remaining\_door: [red\_door]: [green\_door]: [blue\_door]:  agent: (7,3), current\_key: [blue\_key], remaining\_key: [red\_key]: [green\_key]: remaining\_door: [red\_door]: [green\_door]: [blue\_door]:  agent: (7,4), current\_key: [blue\_key], remaining\_key: [red\_key]: [green\_key]: remaining\_door: [red\_door]: [green\_door]: [blue\_door]:  agent: (7,5), current\_key: [blue\_key], remaining\_key: [red\_key]: [green\_key]: remaining\_door: [red\_door]: [green\_door]: [blue\_door]:  agent: (7,6), current\_key: [blue\_key], remaining\_key: [red\_key]: [green\_key]: remaining\_door: [red\_door]: [green\_door]: [blue\_door]:  agent: (7,7), current\_key: [blue\_key], remaining\_key: [red\_key]: [green\_key]: remaining\_door: [red\_door]: [green\_door]: [blue\_door]:  agent: (8,7), current\_key: [blue\_key], remaining\_key: [red\_key]: [green\_key]: remaining\_door: [red\_door]: [green\_door]: [blue\_door]:  agent: (9,7), current\_key: [blue\_key], remaining\_key: [red\_key]: [green\_key]: remaining\_door: [red\_door]: [green\_door]: [blue\_door]:  agent: (10,7), current\_key: [blue\_key], remaining\_key: [red\_key]: [green\_key]: remaining\_door: [red\_door]: [green\_door]: [blue\_door]:  agent: (11,7), current\_key: [blue\_key], remaining\_key: [red\_key]: [green\_key]: remaining\_door: [red\_door]: [green\_door]: [blue\_door]:  agent: (11,7), current\_key: none, remaining\_key: [red\_key]: [green\_key]: remaining\_door: [red\_door]: [green\_door]:  agent: (12,7), current\_key: none, remaining\_key: [red\_key]: [green\_key]: remaining\_door: [red\_door]: [green\_door]:  agent: (13,7), current\_key: none, remaining\_key: [red\_key]: [green\_key]: remaining\_door: [red\_door]: [green\_door]:  agent: (14,7), current\_key: none, remaining\_key: [red\_key]: [green\_key]: remaining\_door: [red\_door]: [green\_door]:  agent: (14,8), current\_key: none, remaining\_key: [red\_key]: [green\_key]: remaining\_door: [red\_door]: [green\_door]:  agent: (15,8), current\_key: none, remaining\_key: [red\_key]: [green\_key]: remaining\_door: [red\_door]: [green\_door]:  agent: (15,9), current\_key: none, remaining\_key: [red\_key]: [green\_key]: remaining\_door: [red\_door]: [green\_door]:  agent: (16,9), current\_key: none, remaining\_key: [red\_key]: [green\_key]: remaining\_door: [red\_door]: [green\_door]:  agent: (16,9), current\_key: [green\_key], remaining\_key: [red\_key]: remaining\_door: [red\_door]: [green\_door]:  agent: (16,8), current\_key: [green\_key], remaining\_key: [red\_key]: remaining\_door: [red\_door]: [green\_door]:  agent: (16,7), current\_key: [green\_key], remaining\_key: [red\_key]: remaining\_door: [red\_door]: [green\_door]:  agent: (15,7), current\_key: [green\_key], remaining\_key: [red\_key]: remaining\_door: [red\_door]: [green\_door]:  agent: (14,7), current\_key: [green\_key], remaining\_key: [red\_key]: remaining\_door: [red\_door]: [green\_door]:  agent: (13,7), current\_key: [green\_key], remaining\_key: [red\_key]: remaining\_door: [red\_door]: [green\_door]:  agent: (12,7), current\_key: [green\_key], remaining\_key: [red\_key]: remaining\_door: [red\_door]: [green\_door]:  agent: (11,7), current\_key: [green\_key], remaining\_key: [red\_key]: remaining\_door: [red\_door]: [green\_door]:  agent: (10,7), current\_key: [green\_key], remaining\_key: [red\_key]: remaining\_door: [red\_door]: [green\_door]:  agent: (9,7), current\_key: [green\_key], remaining\_key: [red\_key]: remaining\_door: [red\_door]: [green\_door]:  agent: (8,7), current\_key: [green\_key], remaining\_key: [red\_key]: remaining\_door: [red\_door]: [green\_door]:  agent: (7,7), current\_key: [green\_key], remaining\_key: [red\_key]: remaining\_door: [red\_door]: [green\_door]:  agent: (7,6), current\_key: [green\_key], remaining\_key: [red\_key]: remaining\_door: [red\_door]: [green\_door]:  agent: (7,5), current\_key: [green\_key], remaining\_key: [red\_key]: remaining\_door: [red\_door]: [green\_door]:  agent: (7,4), current\_key: [green\_key], remaining\_key: [red\_key]: remaining\_door: [red\_door]: [green\_door]:  agent: (7,3), current\_key: [green\_key], remaining\_key: [red\_key]: remaining\_door: [red\_door]: [green\_door]:  agent: (7,2), current\_key: [green\_key], remaining\_key: [red\_key]: remaining\_door: [red\_door]: [green\_door]:  agent: (7,2), current\_key: none, remaining\_key: [red\_key]: remaining\_door: [red\_door]:  agent: (6,2), current\_key: none, remaining\_key: [red\_key]: remaining\_door: [red\_door]:  agent: (5,2), current\_key: none, remaining\_key: [red\_key]: remaining\_door: [red\_door]:  agent: (5,1), current\_key: none, remaining\_key: [red\_key]: remaining\_door: [red\_door]:  agent: (4,1), current\_key: none, remaining\_key: [red\_key]: remaining\_door: [red\_door]:  agent: (3,1), current\_key: none, remaining\_key: [red\_key]: remaining\_door: [red\_door]:  agent: (2,1), current\_key: none, remaining\_key: [red\_key]: remaining\_door: [red\_door]:  agent: (1,1), current\_key: none, remaining\_key: [red\_key]: remaining\_door: [red\_door]:  
\end{tcolorbox}




The prompt describes the maze in a structured language. The maze size $M = m(n+1)+1$ (e.g., in \Cref{fig:maze_env}, the maze size $M = 19$). The positions of walls are $(x_1, y_1), (x_2, y_2), \ldots$, and so on. The position of the agent in time step $t$ is $(x_{at}, y_{at})$, where $t = 0$ corresponds to the initial position The position of the objective is $(x_o, y_o)$, and the position of keys and doors in color $c$ (where $c$ = $r$, $g$, $b$) are $(x_{ck}, y_{ck})$ and $(x_{cd}, y_{cd})$, respectively. The response describes an optimal path (i.e., with minimal total times steps $T$) for the agent to reach the objective.

\subsubsection{Model Details}
Following \citet{su2024dualformer, lehnert2024beyond}, we employ a similar encode-decoder transformer architecture with rotary embeddings and no drop-out. Our model consisted of 6 layers with 3 attention heads, and the embedding size is 64. 

\subsection{ProntoQA and ProsQA}
We used the pretrained GPT-2 model which has the following parameters:

\begin{table}[H]
    \centering
    \begin{tabular}{lc}
        \toprule
        \textbf{Parameter} & \textbf{Value} \\ 
        \midrule
        Number of Layers (Transformer Blocks) & 12 \\ 
        Hidden Size (Embedding Size) & 768 \\ 
        Number of Attention Heads & 12 \\ 
        Vocabulary Size & 50,257 \\ 
        Total Number of Parameters & 117 million \\ 
        \bottomrule
    \end{tabular}
    \caption{Hyperparameters of the pretrained GPT-2 model used for ProntoQA and ProsQA.}
\end{table}



\subsection{LLM experiments}
We use the Llama Cookbook\footnote{\url{https://github.com/meta-llama/llama-cookbook}} codebase to fine-tune the Llama models.


As described in \Cref{sec:expr_main}, we use a batch size of 32 with a sequence packing of 4096. We experiment with different learning rates $10^{-5}, 2.5 \times 10^{-5}, 5 \times 10^{-5}, 10^{-4}$ and select the one with the lowest validation error. The final choices are $10^{-5}$ for Llama-3.2-8B and $2.5 \times 10^{-5}$ for Llama-3.2-1B and Llama-3.2-3B.


\section{Notations}
\label{app:notations}
\Cref{tab:notations} summarizes the notations we used throughout the paper.

\begin{table}[H]
    \centering
    \begin{tabular}{l l}
    \toprule
    $X = P \oplus C \oplus S $ & input text sample where $\oplus$ means concatenation \\
    $P$ & prompt of length $t_p$ \\
    $p_i$ & the $i$-th token of prompt (in text) \\
    $C$ & reasoning trace of length $t_c$\\
    $c_i$ & the $i$-th token of trace (in text) \\
    $S$ & solution of length $t_s$ \\
    $s_i$ & the $i$-th token of solution (in text) \\
    $Z$ & the complete latent reasoning traces of length  $t_z$ \\
    $z_i$ & the $i$-th token of latent trace\\
    $r = t_c / t_z$ & compression rate \\
    $m$ & number of trace tokens to be replaced by latent tokens during training \\
    $\Xtilde $ & modified input with mixed text and latent tokens \\
    \midrule
    $\mathcal{E}$ & codebook of VQ-VAE \\
    $e_i$ & the $i$-th vector in the codebook, which corresponds to the $i$-th latent token \\
    $d$ & dimension of $e_i$s \\
    $\V$ & vocabulary of text tokens \\
    $L$ & chunk size \\ 
    $\fenc(\cdot)$ &  encodes a chunk of $L$ text tokens to $\frac{L}{r}$ embedding vectors \\
    $\bar{X} = \bar{x}_1, \ldots, \bar{x}_{\frac{L}{r}} $ & embedding vectors of $X$ outputted by $\fenc(\cdot)$ \\
    $q(\cdot)$ & quantization operator that replaces, e.g., $\bar{x}_1$ by its nearest neighbor in $\E$: \\
        & \hskip7em $g(\bar{x}_1) = \argmin_{e_i \in \E} \norm{e_i - \bar{x}_1}^2$ \\
    $g(\cdot)$ & maps prompt to a $d$-dimensional embedding vector \\
    $\fdec(\cdot, \cdot)$ & decodes $L/r$ quantized embedding vectors in $\E$ back to text tokens, \\
        & conditioning on prompt embedding generated by $g(\cdot)$ \\
    \bottomrule
    \end{tabular}
    \caption{Mathematical notations used throughout the paper.}
    \label{tab:notations}
\end{table}


\section{Details of Attention Weights Analysis}
\label{app:attention}
\subsection{Generated Responses}
\label{app:generated_text_attention}
\begin{tcolorbox}[title=Question 1, colback=white]
\textbf{Prompt}: What is the positive difference between 
  \$120\%\$ of 30 and \$130\%\$ of 20?\\
\noindent\rule{\textwidth}{0.5pt}
\textbf{Response of Our Latent Approach}: \\
\verb|<boLatent>|\verb|<Latent-code-278>|
\verb|<Latent-code-416>|\verb|<eoLatent>|  \% of 30 and \$130\%\$ of 20. First, let's calculate \$120\%\$ of 30: \$120\%\$ of 30 = 1.2 x 30 = 36. Next, let's calculate \$130\%\$ of 20: \$130\%\$ of 20 = 1.3 x 20 = 26. Now, let's find the positive difference between 36 and 26: 36 - 26 = 10 

The answer is 10.

% Dotted line
\noindent\rule{\textwidth}{0.5pt} % Adjust the thickness and style as needed
\textbf{Response of Baseline (CoT)}: To find the positive difference between $120\%$ of 30 and $130\%$ of 20, we need to calculate each value first.
$120\%$ of 30 is calculated as 1.2 * 30 = 36.
$130\%$ of 20 is calculated as 1.3 * 20 = 26.
Now, we need to find the positive difference between these two values. To do this, we subtract the smaller value from the larger value:
36 - 26 = 10.

The final answer is 10.
\end{tcolorbox}

\begin{tcolorbox}[title=Question 2, colback=white]
\textbf{Prompt}: Mark has \$50 in his bank account. He earns \$10 per day at his work. If he wants to buy a bike that costs \$300, how many days does Mark have to save his money? \\
\noindent\rule{\textwidth}{0.5pt}
\textbf{Response of Our Latent Approach}: \
\verb|<boLatent>| \verb|<Latent-code-123>| \verb|<eoLatent>|   need to calculate how much more money he needs to buy the bike and then divide that amount by his daily earnings. The bike costs \$300, and Mark already has \$50. So, he needs: \$300 (bike cost) - \$50 (current savings) = \$250 (more money needed)

Mark earns \$10 per day. To find out how many days he needs to save, we divide the amount he needs by his daily earnings: \$250 (more money needed) / \$10 (daily earnings) = 25 days.

The answer is 25.


% Dotted line
\noindent\rule{\textwidth}{0.5pt} % Adjust the thickness and style as needed
\textbf{Response of Baseline (CoT)}: To find out how many days Mark needs to save his money, we need to subtract the cost of the bike from the amount of money he has, then divide the result by the amount he earns per day.
Mark has \$50 and wants to buy a bike that costs \$300.
First, subtract the cost of the bike from the amount of money Mark has:
\$50 - \$300 = -\$250
Since Mark can't have a negative amount of money, we need to convert the negative amount to a positive one by adding the cost of the bike to the amount of money Mark has:
\$50 + \$300 = \$350
Now, divide the result by the amount Mark earns per day:
\$350 / \$10 = 35

The final answer is 35.
\end{tcolorbox}



\section{Other Text Generation Examples}
\label{app:generated_text_others}

\begin{minipage}{\columnwidth}
\begin{tcolorbox}[title=Example Generation of Our Latent Approach, colback=white]
\textbf{Prompt}: Evaluate the expression $a^3 \cdot a^2$ if $a= 5$\\
\textbf{Generated Text}: \\
\verb|<boLatent>|\verb|<Latent-code-130>|\verb|<eoLatent>|  We can use the rule of exponents that states $a^m \cdot a^n = a^{m+n}$.
So, $a^3 \cdot a^2 = a^{3+2} = a^5$.
Now, we substitute $a=5$ into the expression: $5^5$.
$5^5 = 5 \cdot 5 \cdot 5 \cdot 5 \cdot 5 = 3125$.
The answer is 3125.
\end{tcolorbox}

\begin{tcolorbox}[title=Example Generation of Our Latent Approach, colback=white]
\textbf{Prompt}: Compute $\dbinom{15}{2}$.\ \\
\textbf{Generated Text}: \
\verb|<boLatent>| \verb|<Latent-code-888>| \verb|<Latent-code-744>| \verb|<Latent-code-196>| \verb|<Latent-code-92>| \verb|<Latent-code-557>| \verb|<eoLatent>|  $\frac{15!}{2!(15-2)!} = \frac{15!} {2!13!}$ To simplify this expression, we can cancel out the common factors in the numerator and denominator:$\dbinom{15}{2} = \frac{15 \times 14}{2} = 105$. The answer is 105.
\end{tcolorbox}

\begin{tcolorbox}[title=Example Generation of Our Latent Approach, colback=white]
\textbf{Question}:  How many vertical asymptotes does the graph of $y=\frac{2}{x^2+x-6}$ have? \\


\textbf{Answer}: 
\verb|<boLatent>|\verb|<Latent-code-773>| \verb|<Latent-code-514>| \verb|<eoLatent>| the denominator, which is $x^2+x-6$.  We can factor this quadratic expression as $(x+3)(x-2)$. Now, we can see that the denominator will be equal to zero when either $(x+3)=0$ or $(x-2)=0$. Solving for these values, we get $x=-3$ or $x=2$.  Therefore, the vertical asymptotes of the graph of $y=\\frac{2}{x^2+x-6}$ are $x=-3$ and $x=2$. Since there are two distinct values of $x$ that make the denominator equal to zero, the graph has 2 vertical asymptotes. The answer is 2.
\end{tcolorbox}
\end{minipage}


\begin{minipage}{\columnwidth}
\begin{tcolorbox}[title=Example Generation of Our Latent Approach, colback=white]

\textbf{Question}:  If there exists an ordered numbering of the nodes such that for each node there are no links going to a lower-numbered node, then there are no directed cycles in a directed graph. True or false?\\

\textbf{Answer}: 
\verb|<boLatent>|\verb|<Latent-code-526>| \verb|<eoLatent>| a directed graph. A directed cycle is a sequence of nodes in a graph, where each node is connected to the next node by a directed edge, and the last node is connected back to the first node by a directed edge. Now, let's consider the given condition: "If there exists an ordered numbering of the nodes such that for each node there are no links going to a lower-numbered node, then there are no directed cycles in a directed graph." This condition essentially means that if we number the nodes in a specific way, and there are no links going to a lower-numbered node, then there are no directed cycles in the graph. To see why this is true, let's consider what would happen if there were a directed cycle in the graph. If there were a directed cycle, then there would be a sequence of nodes where each node is connected to the next node by a directed edge, and the last node is connected back to the first node by a directed edge. However, if we number the nodes in the way described, and there are no links going to a lower-numbered node, then this directed cycle would be impossible. This is because the last node in the cycle would have to be connected to a lower-numbered node, which would violate the condition. Therefore, if we number the nodes in this way, then there can be no directed cycles in the graph. The answer is True.
\end{tcolorbox}
\end{minipage}


\clearpage
\section{Additional Experiments}
\label{app:additional_experiments}
We present results of different approaches for fine-tuning a Llama-3.1-8B model on the DART-MATH~\cite{tong2024dart} dataset.
The observations are similar to those we presented in \Cref{sec:expr}.

\begin{table}[H]
\begin{adjustbox}{width=\textwidth}
\begin{tabular}{lllllllllll}
\toprule
\multicolumn{2}{c}{\multirow{2}{*}{\bf Model (Dart-Math)}} & \multicolumn{2}{c}{\bf In-Domain} & \multicolumn{5}{c}{\bf Out-of-Domain} & \multicolumn{1}{c}{\bf Average} \\ \cmidrule(lr){3-4} \cmidrule(lr){5-9} \cmidrule(lr){10-10}
& & math & GSM8K & Fresh-Gaokao-Math-2023 & DeepMind-Mathematics & College-Math & Olympia-Math & TheoremQA & All Datasets \\ \midrule
\multirow{3}{*}{\bf Llama-3.1-8B}
% & \textbf{Latent random)} & 14.3 & 49.8 & 10.0 & 16.0 & 20.3 & 1.5 & 11.0 & 17.5 \\
& {Sol-only} & 13.3 & 16.4 & 0.0 & 18.2 & 15.9 & {4.7} & 16.9 & 12.2 \\
& {CoT} & \underline{43.1} & \textbf{84.5} & \underline{30.7} & \textbf{47.8} & 
{45.7} & \underline{10.1} & \bf{21.2} & \underline{40.4} \\
& {iCoT} & {35.2} & {61.8} & {30.0} & {30.6} & 
{37.6} & {8.3} & {19.5} & {31.8} \\
& Latent (Ours) & \bf{43.2} \increase{0.1} & \underline{83.9} & \bf{33.3} \increase{2.6}  & \underline{44.7}  & \bf{47.1 } \increase{1.4} & \bf{13.3} \increase{3.2}  & \underline{20.3 }  & \bf{40.8 } \increase{0.4}   \\


\bottomrule
\end{tabular}
\end{adjustbox}
\caption{Our approach surpasses the iCoT and Sol-Only baseline when trained on the DART-MATH dataset~\cite{tong2024dart}, while marginally outperforming the CoT baseline.}
\label{table:ablation_dartmath_perf}
\vspace{2em}

\begin{adjustbox}{width=\textwidth}
\begin{tabular}{lllllllllll}
\toprule
\multicolumn{2}{c}{\multirow{2}{*}{\bf Model (Dart-Math)}} & \multicolumn{2}{c}{\bf In-Domain (\# of tokens)} & \multicolumn{5}{c}{\bf Out-of-Domain (\# of tokens)} & \multicolumn{1}{c}{\bf Average (\# of tokens)} \\ \cmidrule(lr){3-4} \cmidrule(lr){5-9} \cmidrule(lr){10-10}
& & math & GSM8K & Fresh-Gaokao-Math-2023 & DeepMind-Mathematics & College-Math & Olympia-Math & TheoremQA & All Datasets \\ \midrule
\multirow{3}{*}{\bf Llama-3.1-8B}

& {Sol-only} & 10.9 & 8.1 & 10.2 & 8.4 & 11.2 & {16.1} & 16.13 & 11.6 \\
& {CoT} &  {522.7}  & {181.0} & 
{628.8} & {343.2} & {486.3} & {893.7} & {648.3} & {529.1} \\
& {iCoT} &  {397.1}  & {118.6} & 
{440.8} & {227.9} & {321.9} & {614.4} & {485.7} & {372.3} \\
& Latent (Ours) & {489.1}\decrease{6.4\%} & {163.5} \decrease{9.7\%} & {462.1}\decrease{26.5\%}  & {265.6} \decrease{22.6\%} & {396.3 }\decrease{18.5\%} & {801.3} \decrease{10.3\%} & {591.3 }  & {452.7 }  \decrease{16\%} \\



\bottomrule
\end{tabular}
\end{adjustbox}
\caption{The average number of tokens in the generated responses. Our approach generates shorter reasoning traces then the CoT baseline. \textcolor{darkgreen}{$\downarrow$ -:\hspace{0.2em}Trace length reduction rate compared with CoT.}}
\label{table:ablation_dartmath_token_efficiency}
\end{table}
