@article{Cobbe2021TrainingVT,
  title={Training Verifiers to Solve Math Word Problems},
  author={Karl Cobbe and Vineet Kosaraju and Mohammad Bavarian and Mark Chen and Heewoo Jun and Lukasz Kaiser and Matthias Plappert and Jerry Tworek and Jacob Hilton and Reiichiro Nakano and Christopher Hesse and John Schulman},
  journal={ArXiv},
  year={2021},
  volume={abs/2110.14168},
  url={https://api.semanticscholar.org/CorpusID:239998651}
}

@inproceedings{Kocsis2006BanditBM,
  title={Bandit Based Monte-Carlo Planning},
  author={Levente Kocsis and Csaba Szepesvari},
  booktitle={European Conference on Machine Learning},
  year={2006},
  url={https://api.semanticscholar.org/CorpusID:15184765}
}

@article{Nakano2021WebGPTBQ,
  title={WebGPT: Browser-assisted question-answering with human feedback},
  author={Reiichiro Nakano and Jacob Hilton and Suchir Balaji and Jeff Wu and Ouyang Long and Christina Kim and Christopher Hesse and Shantanu Jain and Vineet Kosaraju and William Saunders and Xu Jiang and Karl Cobbe and Tyna Eloundou and Gretchen Krueger and Kevin Button and Matthew Knight and Benjamin Chess and John Schulman},
  journal={ArXiv},
  year={2021},
  volume={abs/2112.09332},
  url={https://api.semanticscholar.org/CorpusID:245329531}
}

@article{Yu2024DistillingS2,
  title={Distilling System 2 into System 1},
  author={Ping Yu and Jing Xu and Jason Weston and Ilia Kulikov},
  journal={ArXiv},
  year={2024},
  volume={abs/2407.06023},
  url={https://api.semanticscholar.org/CorpusID:271050364}
}

@article{chen2024not,
  title={Do NOT Think That Much for 2+ 3=? On the Overthinking of o1-Like LLMs},
  author={Chen, Xingyu and Xu, Jiahao and Liang, Tian and He, Zhiwei and Pang, Jianhui and Yu, Dian and Song, Linfeng and Liu, Qiuzhi and Zhou, Mengfei and Zhang, Zhuosheng and others},
  journal={arXiv preprint arXiv:2412.21187},
  year={2024}
}

@misc{cheng2024compressedchainthoughtefficient,
      title={Compressed Chain of Thought: Efficient Reasoning Through Dense Representations}, 
      author={Jeffrey Cheng and Benjamin Van Durme},
      year={2024},
      eprint={2412.13171},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2412.13171}, 
}

@misc{deepseekai2025deepseekr1incentivizingreasoningcapability,
      title={DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning}, 
      author={DeepSeek-AI},
      year={2025},
      eprint={2501.12948},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2501.12948}, 
}

@misc{deng2024explicitcotimplicitcot,
      title={From Explicit CoT to Implicit CoT: Learning to Internalize CoT Step by Step}, 
      author={Yuntian Deng and Yejin Choi and Stuart Shieber},
      year={2024},
      eprint={2405.14838},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2405.14838}, 
}

@article{guan2025rstar,
  title={rStar-Math: Small LLMs Can Master Math Reasoning with Self-Evolved Deep Thinking},
  author={Guan, Xinyu and Zhang, Li Lyna and Liu, Yifei and Shang, Ning and Sun, Youran and Zhu, Yi and Yang, Fan and Yang, Mao},
  journal={arXiv preprint arXiv:2501.04519},
  year={2025}
}

@misc{hao2024traininglargelanguagemodels,
      title={Training Large Language Models to Reason in a Continuous Latent Space}, 
      author={Shibo Hao and Sainbayar Sukhbaatar and DiJia Su and Xian Li and Zhiting Hu and Jason Weston and Yuandong Tian},
      year={2024},
      eprint={2412.06769},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2412.06769}, 
}

@misc{hoffmann2022trainingcomputeoptimallargelanguage,
      title={Training Compute-Optimal Large Language Models}, 
      author={Jordan Hoffmann and Sebastian Borgeaud and Arthur Mensch and Elena Buchatskaya and Trevor Cai and Eliza Rutherford and Diego de Las Casas and Lisa Anne Hendricks and Johannes Welbl and Aidan Clark and Tom Hennigan and Eric Noland and Katie Millican and George van den Driessche and Bogdan Damoc and Aurelia Guy and Simon Osindero and Karen Simonyan and Erich Elsen and Jack W. Rae and Oriol Vinyals and Laurent Sifre},
      year={2022},
      eprint={2203.15556},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2203.15556}, 
}

@article{jaech2024openai,
  title={Openai o1 system card},
  author={Jaech, Aaron and Kalai, Adam and Lerer, Adam and Richardson, Adam and El-Kishky, Ahmed and Low, Aiden and Helyar, Alec and Madry, Aleksander and Beutel, Alex and Carney, Alex and others},
  journal={arXiv preprint arXiv:2412.16720},
  year={2024}
}

@misc{kang2024c3otgeneratingshorterchainofthought,
      title={C3oT: Generating Shorter Chain-of-Thought without Compromising Effectiveness}, 
      author={Yu Kang and Xianghui Sun and Liangyu Chen and Wei Zou},
      year={2024},
      eprint={2412.11664},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2412.11664}, 
}

@article{luo2025o1,
  title={O1-Pruner: Length-Harmonizing Fine-Tuning for O1-Like Reasoning Pruning},
  author={Luo, Haotian and Shen, Li and He, Haiying and Wang, Yibo and Liu, Shiwei and Li, Wei and Tan, Naiqiang and Cao, Xiaochun and Tao, Dacheng},
  journal={arXiv preprint arXiv:2501.12570},
  year={2025}
}

@inproceedings{meng2024simpo,
   title={SimPO: Simple Preference Optimization with a Reference-Free Reward},
   author={Meng, Yu and Xia, Mengzhou and Chen, Danqi},
   booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
   year={2024}
}

@misc{qwq-32b-preview,
    title = {QwQ: Reflect Deeply on the Boundaries of the Unknown},
    url = {https://qwenlm.github.io/blog/qwq-32b-preview/},
    author = {Qwen Team},
    month = {November},
    year = {2024}
}

@article{team2025kimi,
  title={Kimi k1. 5: Scaling Reinforcement Learning with LLMs},
  author={Team, Kimi and Du, Angang and Gao, Bofei and Xing, Bowei and Jiang, Changjiu and Chen, Cheng and Li, Cheng and Xiao, Chenjun and Du, Chenzhuang and Liao, Chonghua and others},
  journal={arXiv preprint arXiv:2501.12599},
  year={2025}
}

@inproceedings{wang-etal-2024-math,
    title = "Math-Shepherd: Verify and Reinforce {LLM}s Step-by-step without Human Annotations",
    author = "Wang, Peiyi  and
      Li, Lei  and
      Shao, Zhihong  and
      Xu, Runxin  and
      Dai, Damai  and
      Li, Yifei  and
      Chen, Deli  and
      Wu, Yu  and
      Sui, Zhifang",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.510/",
    doi = "10.18653/v1/2024.acl-long.510",
    pages = "9426--9439",
    abstract = "In this paper, we present an innovative process-oriented math process reward model called Math-shepherd, which assigns a reward score to each step of math problem solutions. The training of Math-shepherd is achieved using automatically constructed process-wise supervision data, breaking the bottleneck of heavy reliance on manual annotation in existing work. We explore the effectiveness of Math-shepherd in two scenarios: 1) $\textit{Verification}$: Math-shepherd is utilized for reranking multiple outputs generated by Large Language Models (LLMs); 2) $\textit{Reinforcement Learning (RL)}$: Math-shepherd is employed to reinforce LLMs.With Math-shepherd, a series of open-source LLMs demonstrates exceptional performance. For instance, process RL with Math-shepherd significantly enhances Mistral-7B (77.9{\%}$\to$84.1{\%} on GSM8K and 28.6{\%}$\to$33.0{\%} on MATH).The accuracy can be further improved to 89.1{\%} and 43.5{\%} on two benchmarks with verification of Math-shepherd.We believe that automatic process supervision holds significant potential for the future evolution of LLMs."
}

@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

