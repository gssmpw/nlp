\section{Related Work}
\paragraph{Chain-of-Thought.}
Chain-of-thought____ reasoning has shown promising progress in recent years, especially the success of OpenAi-O1____ and Deepseek-R1 models____. This introduces the test-time scaling law, apart from the traditional scaling law for training____. Several approaches have been proposed to boost the language model to have better problem-solving abilities, including the model has its self-reasoning abilities____ or use Best-of-N____, beam search and Monte Carlo Tree Search____ to search and refine the solution without further finetune the large language models. The outcome reward model and process reward models are also introduced to evaluate the score for the entire solution, especially the final answer____ and the 
quality of the reasoning path____

\paragraph{Chain Compression in reasoning model.} Due to the high computational cost associated with inference in reasoning models, particularly for long-chain reasoning, chain compression has become a critical area of research. ____ attempts to distill the chain-of-thought into System 1 but fails to observe improvements when intermediate steps are omitted. ____ proposes internalizing reasoning steps within the hidden states of models, while several implicit-based approaches____ aim to compress token-wise generation by transitioning from language space to hidden space. Other studies focus on skipping intermediate reasoning steps____ or using summarization techniques to generate shorter reasoning chains____.
Additionally, ____ addresses the overthinking issue in QwQ____ and employs SimPO____ for optimization. Kimi K1.5____ proposes merging long-CoT models with short-CoT models in a training-free manner. O1-Pruner____ adopts reinforcement learning to shorten responses.  


\begin{figure*}
    \centering
    \includegraphics[width=\linewidth]{figures/main_v8.pdf}
    \caption{Illustration of \methodname. In Stage 1, we first determine $\Delta\theta$ from distilling or post-training. Then, the trained $\Delta\theta$ is utilized to construct the MixChain dataset. Using this dataset, we can then apply two enhanced training methods to achieve more precise control over reasoning paths, or to shorten the reasoning paths as needed.}
    \label{fig:main}
\end{figure*}