%% 
%% Copyright 2007-2025 Elsevier Ltd
%% 
%% This file is part of the 'Elsarticle Bundle'.
%% ---------------------------------------------
%% 
%% It may be distributed under the conditions of the LaTeX Project Public
%% License, either version 1.3 of this license or (at your option) any
%% later version.  The latest version of this license is in
%%    http://www.latex-project.org/lppl.txt
%% and version 1.3 or later is part of all distributions of LaTeX
%% version 1999/12/01 or later.
%% 
%% The list of all files belonging to the 'Elsarticle Bundle' is
%% given in the file `manifest.txt'.
%% 
%% Template article for Elsevier's document class `elsarticle'
%% with harvard style bibliographic references

\documentclass[preprint,12pt]{elsarticle}

%% Use the option review to obtain double line spacing
%% \documentclass[preprint,review,12pt]{elsarticle}

%% Use the options 1p,twocolumn; 3p; 3p,twocolumn; 5p; or 5p,twocolumn
%% for a journal layout:
%% \documentclass[final,1p,times]{elsarticle}
%% \documentclass[final,1p,times,twocolumn]{elsarticle}
%% \documentclass[final,3p,times]{elsarticle}
%% \documentclass[final,3p,times,twocolumn]{elsarticle}
%% \documentclass[final,5p,times]{elsarticle}
%% \documentclass[final,5p,times,twocolumn]{elsarticle}

%% For including figures, graphicx.sty has been loaded in
%% elsarticle.cls. If you prefer to use the old commands
%% please give \usepackage{epsfig}

%% The amssymb package provides various useful mathematical symbols
\usepackage{amssymb}
%% The amsmath package provides various useful equation environments.
%\usepackage{amsmath}
%% The amsthm package provides extended theorem environments
%% \usepackage{amsthm}

\usepackage{amsmath,amsfonts}
\usepackage{algorithmic}
\usepackage{algorithm}
\usepackage{array}
% \usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
\usepackage{textcomp}
\usepackage{stfloats}
\usepackage{url}
\usepackage{verbatim}
\usepackage{graphicx}
%\usepackage{cite}
% updated with editorial comments 8/9/2021
% extra packages
\usepackage{caption}
\usepackage{hyperref}
\usepackage{enumitem}
\usepackage{subfigure}
\usepackage{ragged2e}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{soul}
\usepackage{xcolor}

\sethlcolor{yellow} % Set your desired color here


\journal{Robotics and Autonomous Systems}
%% The lineno packages adds line numbers. Start line numbering with
%% \begin{linenumbers}, end it with \end{linenumbers}. Or switch it on
%% for the whole article with \linenumbers.
%% \usepackage{lineno}

\begin{document}

\begin{frontmatter}

%% Title, authors and addresses

%% use the tnoteref command within \title for footnotes;
%% use the tnotetext command for theassociated footnote;
%% use the fnref command within \author or \affiliation for footnotes;
%% use the fntext command for theassociated footnote;
%% use the corref command within \author for corresponding author footnotes;
%% use the cortext command for theassociated footnote;
%% use the ead command for the email address,
%% and the form \ead[url] for the home page:
%% \title{Title\tnoteref{label1}}
%% \tnotetext[label1]{}
%% \author{Name\corref{cor1}\fnref{label2}}
%% \ead{email address}
%% \ead[url]{home page}
%% \fntext[label2]{}
%% \cortext[cor1]{}
%% \affiliation{organization={},
%%             addressline={},
%%             city={},
%%             postcode={},
%%             state={},
%%             country={}}
%% \fntext[label3]{}

\title{Early Detection of Human Handover Intentions in Human-Robot Collaboration: \\ Comparing EEG, Gaze, and Hand Motion} %% Article title

%=\author
%{Parag Khanna,$^{1,\ast,+}$ Nona Rajabi,$^{1,+}$ Sumeyra U. Demir Kanik,$^{2}$ Danica Kragic,$^{1}$ \\Mårten Björkman,$^{1}$ Christian Smith$^{1}$\\
%\\
%\normalsize{$^{1}$KTH Royal Institute of Technology, Stockholm, Sweden}\\
%\normalsize{$^{2}$Ericsson Research, Stockholm, Sweden}\\
%\\
%\normalsize{$^{+}$These authors contributed equally to this work}\\
%\normalsize{$^\ast$To whom correspondence should be addressed; E-mail: paragk@kth.se.}
%}

%% use optional labels to link authors explicitly to addresses:
\author[label1]{Parag Khanna \fnref{label3,label4}}
\author[label1]{Nona Rajabi \fnref{label3}}
\author[label2]{Sumeyra U. Demir Kanik}
\author[label1]{Danica Kragic}
\author[label1]{Mårten Björkman}
\author[label1]{Christian Smith}
\fntext[label3]{These authors contributed equally to this work}
\fntext[label4]{To whom correspondence should be addressed; E-mail: paragk@kth.se.}

\affiliation[label1]{organization={KTH Royal Institute of Technology, Stockholm},
             city={Stockholm},
             country={Sweden}}

\affiliation[label2]{organization={Ericsson Research},
             city={Stockholm},
             country={Sweden}}
             

%\author{Parag Khanna} %% Author name

%% Author affiliation
%\affiliation{organization={RPL,KTH Royal Institute of Technology, Stockholm, Sweden},%Department and Organization
%            addressline={}, 
%           city={Stockholm},
%            postcode={}, 
%            state={},
%            country={Sweden}}
%%Graphical abstract
\begin{comment}
    \begin{graphicalabstract}
\vspace{50pt}
\includegraphics[width=0.98\textwidth]{figures/graphical_abstract.pdf}
\end{graphicalabstract}
%%Research highlights
\begin{highlights}
\item Demonstrates the potential of non-movement-based physiological signals for improving HRC applications.
\item Comprehensive comparison of electroencephalography (EEG) brain signals, gaze, and hand motion for predicting handover intent.
\item Gaze data demonstrates the fastest and most accurate detection of handover intentions.
\item A multimodal approach significantly enhances the performance of weaker modalities in detection.
\item Introduces a novel dataset with synchronized EEG, gaze, and hand motion for handovers in HRC context.
\end{highlights}
\end{comment}


%% Abstract
\begin{abstract}
%% Text of abstract
Human-robot collaboration (HRC) relies on accurate and timely recognition of human intentions to ensure seamless interactions. 
Among common HRC tasks, human-to-robot object handovers have been studied extensively for planning the robot's actions during object reception, assuming the human intention for object handover. However, distinguishing handover intentions from other actions has received limited attention. Most research on handovers has focused on visually detecting motion trajectories, which often results in delays or false detections when trajectories overlap. 
This paper investigates whether human intentions for object handovers are reflected in non-movement-based physiological signals. We conduct a multimodal analysis comparing three data modalities: electroencephalogram (EEG), gaze, and hand-motion signals. Our study aims to distinguish between handover-intended human motions and non-handover motions in an HRC setting, evaluating each modality's performance in predicting and classifying these actions before and after human movement initiation.
We develop and evaluate human intention detectors based on these modalities, comparing their accuracy and timing in identifying handover intentions. To the best of our knowledge, this is the first study to systematically develop and test intention detectors across multiple modalities within the same experimental context of human-robot handovers. 
Our analysis reveals that handover intention can be detected from all three modalities. Nevertheless, gaze signals are the earliest as well as the most accurate to classify the motion as intended for handover or non-handover.
\end{abstract}




%% Keywords
\begin{keyword}
Human-Robot Collaboration (HRC)
\sep Human-Robot Handovers
\sep EEG
\sep Gaze
\sep Motion Analysis
%% keywords here, in the form: keyword \sep keyword
%% PACS codes here, in the form: \PACS code \sep code
%% MSC codes here, in the form: \MSC code \sep code
%% or \MSC[2008] code \sep code (2000 is the default)
\end{keyword}
\end{frontmatter}

%% Add \usepackage{lineno} before \begin{document} and uncomment 
%% following line to enable line numbers
%% \linenumbers

%% main text
%%

%% Use \section commands to start a section

\section{Introduction}
\input{sections/introduction.tex}

\section{Experimental Design}
\input{sections/experimental_design}

\section{Dataset Preparation}
\input{sections/dataset}
\section{Data Analysis}
\input{sections/data_analysis}

\section{Handover Intention Detection}
%\section{Results}
In this section, we compare the performance of gaze and EEG for handover detection against motion trajectories recorded by an RGBD camera, evaluating both detection timing and accuracy. We also assess the performance of single modalities versus multiple modalities. 
%All model performances are reported using the area under the receiver operating characteristic curve (AUC-ROC), as detailed in the \emph{Materials and Methods} section.
\input{sections/materials_and_methods.tex}
\input{sections/results}

\section{Discussion}
\input{sections/discussion}

% use section* for acknowledgment
\section*{Acknowledgment}
This work was supported by Digital Futures at KTH,
the Swedish Foundation for Strategic Research (BOS), Knut
and Alice Wallenberg Foundation, the Swedish Research
Council and ERC BIRD 884807.

\bibliographystyle{elsarticle-num-names} 
\bibliography{jrnl}

\include{supplementary}
%% else use the following coding to input the bibitems directly in the
%% TeX file.

%% Refer following link for more details about bibliography and citations.
%% https://en.wikibooks.org/wiki/LaTeX/Bibliography_Management

\begin{comment}

\section{Example Section}
\label{sec1}
%% Labels are used to cross-reference an item using \ref command.

Section text. See Subsection \ref{subsec1}.

%% Use \subsection commands to start a subsection.
\subsection{Example Subsection}
\label{subsec1}

Subsection text.

%% Use \subsubsection, \paragraph, \subparagraph commands to 
%% start 3rd, 4th and 5th level sections.
%% Refer following link for more details.
%% https://en.wikibooks.org/wiki/LaTeX/Document_Structure#Sectioning_commands

\subsubsection{Mathematics}
%% Inline mathematics is tagged between $ symbols.
This is an example for the symbol $\alpha$ tagged as inline mathematics.

%% Displayed equations can be tagged using various environments. 
%% Single line equations can be tagged using the equation environment.
\begin{equation}
f(x) = (x+a)(x+b)
\end{equation}

%% Unnumbered equations are tagged using starred versions of the environment.
%% amsmath package needs to be loaded for the starred version of equation environment.
\begin{equation*}
f(x) = (x+a)(x+b)
\end{equation*}

%% align or eqnarray environments can be used for multi line equations.
%% & is used to mark alignment points in equations.
%% \\ is used to end a row in a multiline equation.
\begin{align}
 f(x) &= (x+a)(x+b) \\
      &= x^2 + (a+b)x + ab
\end{align}

\begin{eqnarray}
 f(x) &=& (x+a)(x+b) \nonumber\\ %% If equation numbering is not needed for a row use \nonumber.
      &=& x^2 + (a+b)x + ab
\end{eqnarray}

%% Unnumbered versions of align and eqnarray
\begin{align*}
 f(x) &= (x+a)(x+b) \\
      &= x^2 + (a+b)x + ab
\end{align*}

\begin{eqnarray*}
 f(x)&=& (x+a)(x+b) \\
     &=& x^2 + (a+b)x + ab
\end{eqnarray*}

%% Refer following link for more details.
%% https://en.wikibooks.org/wiki/LaTeX/Mathematics
%% https://en.wikibooks.org/wiki/LaTeX/Advanced_Mathematics

%% Use a table environment to create tables.
%% Refer following link for more details.
%% https://en.wikibooks.org/wiki/LaTeX/Tables
\begin{table}[t]%% placement specifier
%% Use tabular environment to tag the tabular data.
%% https://en.wikibooks.org/wiki/LaTeX/Tables#The_tabular_environment
\centering%% For centre alignment of tabular.
\begin{tabular}{l c r}%% Table column specifiers
%% Tabular cells are separated by &
  1 & 2 & 3 \\ %% A tabular row ends with \\
  4 & 5 & 6 \\
  7 & 8 & 9 \\
\end{tabular}
%% Use \caption command for table caption and label.
\caption{Table Caption}\label{fig1}
\end{table}


%% Use figure environment to create figures
%% Refer following link for more details.
%% https://en.wikibooks.org/wiki/LaTeX/Floats,_Figures_and_Captions
\begin{figure}[t]%% placement specifier
%% Use \includegraphics command to insert graphic files. Place graphics files in 
%% working directory.
\centering%% For centre alignment of image.
\includegraphics{example-image-a}
%% Use \caption command for figure caption and label.
\caption{Figure Caption}\label{fig1}
%% https://en.wikibooks.org/wiki/LaTeX/Importing_Graphics#Importing_external_graphics
\end{figure}


%% The Appendices part is started with the command \appendix;
%% appendix sections are then done as normal sections
\appendix
\section{Example Appendix Section}
\label{app1}

Appendix text.

%% For citations use: 
%%       \citet{<label>} ==> Lamport [21]
%%       \citep{<label>} ==> [21]
%%
Example citation, See \citet{lamport94}.

%% If you have bib database file and want bibtex to generate the
%% bibitems, please use
%%

\begin{thebibliography}{00}

%% For authoryear reference style
%% \bibitem[Author(year)]{label}
%% Text of bibliographic item

\bibitem[Lamport(1994)]{lamport94}
  Leslie Lamport,
  \textit{\LaTeX: a document preparation system},
  Addison Wesley, Massachusetts,
  2nd edition,
  1994.

\end{thebibliography}    
\end{comment}

\end{document}

\endinput
%%
%% End of file `elsarticle-template-num-names.tex'.
