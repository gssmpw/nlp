

\begin{figure*}[t]
    \centering
    \subfigure[Hard negative study]{\includegraphics[width=0.32\textwidth]{figure/LLM_alignment_gsm8k_mathstral7b_neg_study.pdf}}
    \subfigure[Temperature \& hard negatives]{\includegraphics[width=0.32\textwidth]{figure/LLM_alignment_mistral_temperature_study.pdf}}
    \subfigure[Candidate list length study]{\includegraphics[width=0.32\textwidth]{figure/LLM_alignment_mistral_length_study.pdf}}
    % \vspace{-0.1in}
    \caption{Hard negative and candidate list study. (a) Hard negative study with $\mathcal{L}_{\text{pair}}$ on GSM8K with Mathstral-7b-it model. We explore four negative settings: (1) a random response not related to the given prompt; (2) a response to a related prompt; (3) an incorrect response to the given prompt with high temperature; (4) an incorrect response to the given prompt with suitable temperature. Hardness: (4)$>$(3)$>$(2)$>$(1). The harder the negatives are, the stronger the trained LLM is.
    (b) Training temperature study with $\mathcal{L}_{\text{pair}}$ on Mistral-7b-it and Alpaca Eval 2. Within a specific range ($>$ 1), lower temperature leads to harder negative and benefit the trained LLM. However, much lower temperature could lead to less diverse responses and finally lead to LLM alignment performance drop.
    (c) Candidate list size study with $\mathcal{L}_{\text{con}}$ on Mistral-7b-it. As the candidate list size increases, alignment performance improves.}\label{fig:merge-study}
    % \vspace{-0.1in}
\end{figure*}


% \begin{figure}[h!]
% \centering
% \includegraphics[scale=0.3]{figure/LLM_alignment_mistral_length_study.pdf}
% \vskip -1em
% \caption{Candidate list size study with $\mathcal{L}_{\text{con}}$ on Mistral-7b-it. As the candidate list size increases, alignment performance improves.}\label{fig:length-study}\vspace{-10pt}
% \end{figure}


% \begin{figure}[h!]
% \centering
% \includegraphics[scale=0.3]{figure/LLM_alignment_mistral_temperature_study.pdf}
% \vskip -1em
% \caption{Training temperature study with $\mathcal{L}_{\text{pair}}$ on Mistral-7b-it and Alpaca Eval 2. Within a specific range ($>$ 1), lower temperature leads to harder negative and benefit the trained LLM. However, temperature lower than this range can cause preferred and rejected responses non-distinguishable and lead to degrade training.}\label{tab:temp-hard}
% \end{figure}


% \begin{figure}[h!]
% \centering
% \includegraphics[scale=0.3]{figure/LLM_alignment_gsm8k_mathstral7b_neg_study.pdf}
% \vskip -1em
% \caption{Hard negative study with $\mathcal{L}_{\text{pair}}$ on GSM8K with Mathstral-7b-it model. We explore four negative settings: (1) a random response not related to the given prompt; (2) a response to a related prompt; (3) an incorrect response to the given prompt with high temperature; (4) an incorrect response to the given prompt with suitable temperature. Hardness: (4)$>$(3)$>$(2)$>$(1). The harder the negatives are, the stronger the trained LLM is.}\label{fig:mathstral-gsm8k-hard}
% \end{figure}
