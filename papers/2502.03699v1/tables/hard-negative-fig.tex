

\begin{figure}[h!]
\centering
\includegraphics[scale=0.3]{figure/LLM_alignment_gsm8k_mathstral7b_neg_study.pdf}
\vskip -1em
\caption{Hard negative study with $\mathcal{L}_{\text{pair}}$ on GSM8K with Mathstral-7b-it model. We explore four negative settings: (1) a random response not related to the given prompt; (2) a response to a related prompt; (3) an incorrect response to the given prompt with high temperature; (4) an incorrect response to the given prompt with suitable temperature. Hardness: (4)$>$(3)$>$(2)$>$(1). The harder the negatives are, the stronger the trained LLM is.}\label{fig:mathstral-gsm8k-hard}
\end{figure}

% \begin{table}[t]
%     \centering
%     % \renewcommand{\arraystretch}{1.2}
%     \caption{Temperature study results for Gemma2-2b-it and Mistral-7b-it. We conduct RLHF (iterative DPO) for 3 iterations. $\uparrow$, $\rightarrow$ and $\downarrow$ denote RLHF with high, medium and low temperature. We use \texttt{alpaca\_eval\_llama3\_70b\_fn} as the evaluator.}\label{tab:temp-hard}
%     \scalebox{0.9}{\begin{tabular}{llcc}
%         \toprule
%         & & \multicolumn{2}{c}{Alpaca Eval 2} \\
%          \cmidrule(r){3-4}
%         & Method & LC Winrate & Winrate \\
%         \midrule
%         \multirow{5}{*}{\rotatebox{90}{Gemma2}} & SFT & 47.03 & 48.38 \\
%         \cmidrule{2-4}
%         & RLHF ($\uparrow$) & 54.45 & 67.50 \\
%         & RLHF ($\rightarrow$) & 59.31 & 69.77 \\
%         & RLHF ($\downarrow$) & 59.04 & 71.38  \\
%         \midrule
%         \multirow{5}{*}{\rotatebox{90}{Mistral}} & SFT & 27.04 & 17.41  \\
%         \cmidrule{2-4}
%         & RLHF ($\uparrow$) & 49.75 & 55.07 \\
%         & RLHF ($\rightarrow$) & 53.29 & 60.52 \\
%         & RLHF ($\downarrow$) & 54.78 & 64.33 \\
%         \bottomrule
%     \end{tabular}}
% \end{table}


% \begin{figure}[h!]
% \centering
% \includegraphics[scale=0.3]{figure/LLM_alignment_mistral_temperature_study.pdf}
% \vskip -1em
% \caption{Training temperature study with $\mathcal{L}_{\text{pair}}$ on Mistral-7b-it and Alpaca Eval 2. Within a specific range ($>$ 1), lower temperature leads to harder negative and benefit the trained LLM. However, temperature lower than this range can cause preferred and rejected responses non-distinguishable and lead to degrade training.}\label{tab:temp-hard}
% \end{figure}
