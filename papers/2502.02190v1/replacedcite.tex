\section{Related Work}
\textbf{Diversity in Genetic Algorithms.}
Evolution's remarkable capacity for generating diverse, well-adapted species has inspired numerous algorithmic approaches in evolutionary computation. Early diversity maintenance techniques focused on preventing premature convergence through mechanisms like fitness sharing____ and hierarchical fair competition____, which restrict competition to occur within species or niches. The NEAT algorithm____ demonstrated the power of this approach by using speciation to protect structural innovations in evolving neural networks, allowing novel architectures to optimize before competing with established solutions. Novelty Search____ took a radical step by completely abandoning the objective function, instead rewarding solutions solely for being different from their predecessors. This approach proved effective at avoiding deception by discovering valuable stepping stones that initially appeared suboptimal.

\textbf{Quality-Diversity.}
Building on these insights, QD optimization emerged as a distinct family of algorithms that combine novelty with local competition. Novelty Search with Local Competition____ pioneered this approach by having solutions compete only against behavioral neighbors, while MAP-Elites____ formalized it through a grid-based architecture where each cell maintains its highest-performing solution. These approaches have proven particularly valuable in robotics____, where diverse behavioral repertoires enable adaptation. However, current QD algorithms often rely on simple heuristics --- grid-based approaches impose rigid discretization, while nearest-neighbor methods may miss important relationships between distant solutions. This suggests an opportunity to discover more sophisticated competition mechanisms that better capture the dynamics driving natural evolution's success.

\textbf{Discovering Algorithms via Meta-Optimization.}
Over the course of machine learningâ€™s evolution, handcrafted components have gradually been replaced by modules learned directly from data.
Recent work continues this trend by pursuing end-to-end discovery of gradient descent-based optimizers ____, objective functions in Reinforcement Learning____, the online tuning of hyperparameter schedules____, and the meta-learning of complete learning algorithms____.
In these methods, appropriate inductive biases supplied by neural network parametrizations can guide and constrain the meta-search process. Here, our proposed LQD architecture leverages the equivariance properties encoded by the self-attention mechanism____, thereby defining a family of QD algorithms parameterized by neural networks.

\textbf{Population-Based Optimization via Meta-Optimization.}
Several attempts have been made to automatically optimize evolutionary algorithms. E.g. ____ explored meta-learning entire algorithms for low-dimensional BBO using a sequence model to process solution candidates and/or their fitness values. ____, on the other hand, introduced a meta-optimized policy to control the scalar search scale of CMA-ES____. However, these methods often have limited generalization capabilities and are restricted to certain optimization domains, fixed population sizes, or fixed search dimensions.
Most closely related to our work are LES____ and LGA____. Both approaches relied on the invariance of dot-product self-attention____ to generalize to unseen meta-training settings.
Here, we successfully meta-optimize a parametrized Transformer model to discover various QD algorithms, which can outperform baseline algorithms on unseen optimization tasks. 
% Moreover, our LQD algorithm does not depend on having access to a teacher algorithm____ or prior knowledge____.