@article{oh2020discovering,
  title={Discovering reinforcement learning algorithms},
  author={Oh, Junhyuk and Hessel, Matteo and Czarnecki, Wojciech M and Xu, Zhongwen and van Hasselt, Hado P and Singh, Satinder and Silver, David},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={1060--1070},
  year={2020}
}

@article{xu2020meta,
  title={Meta-gradient reinforcement learning with an objective discovered online},
  author={Xu, Zhongwen and van Hasselt, Hado P and Hessel, Matteo and Oh, Junhyuk and Singh, Satinder and Silver, David},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={15254--15264},
  year={2020}
}

@inproceedings{lu2022discovered,
  title={Discovered Policy Optimisation},
  author={Lu, Chris and Kuba, Jakub Grudzien and Letcher, Alistair and Metz, Luke and de Witt, Christian Schroeder and Foerster, Jakob Nicolaus},
  booktitle={Decision Awareness in Reinforcement Learning Workshop at ICML 2022},
  year={2022}
}


@article{zahavy2020self,
    title={A self-tuning actor-critic algorithm},
    author={Zahavy, Tom and Xu, Zhongwen and Veeriah, Vivek and Hessel, Matteo and Oh, Junhyuk and van Hasselt, Hado P and Silver, David and Singh, Satinder},
    journal={Advances in Neural Information Processing Systems},
    volume={33},
    pages={20913--20924},
    year={2020}
}

@article{flennerhag2021bootstrapped,
    title={Bootstrapped meta-learning},
    author={Flennerhag, Sebastian and Schroecker, Yannick and Zahavy, Tom and van Hasselt, Hado and Silver, David and Singh, Satinder},
    journal={arXiv preprint arXiv:2109.04504},
    year={2021}
}

@article{xu2018meta,
    title={Meta-gradient reinforcement learning},
    author={Xu, Zhongwen and van Hasselt, Hado P and Silver, David},
    journal={Advances in neural information processing systems},
    volume={31},
    year={2018}
}

@article{wang2016learning,
    title={Learning to reinforcement learn},
    author={Wang, Jane X and Kurth-Nelson, Zeb and Tirumala, Dhruva and Soyer, Hubert and Leibo, Joel Z and Munos, Remi and Blundell, Charles and Kumaran, Dharshan and Botvinick, Matt},
    journal={arXiv preprint arXiv:1611.05763},
    year={2016}
}

@inproceedings{kirsch2022introducing,
    title={Introducing symmetries to black box meta reinforcement learning},
    author={Kirsch, Louis and Flennerhag, Sebastian and van Hasselt, Hado and Friesen, Abram and Oh, Junhyuk and Chen, Yutian},
    booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
    volume={36},
    number={7},
    pages={7202--7210},
    year={2022}
}

@inproceedings{lange2024evolution,
  title={Evolution transformer: In-context evolutionary optimization},
  author={Lange, Robert and Tian, Yingtao and Tang, Yujin},
  booktitle={Proceedings of the Genetic and Evolutionary Computation Conference Companion},
  pages={575--578},
  year={2024}
}


@inproceedings{lee2019set,
    title={Set transformer: A framework for attention-based permutation-invariant neural networks},
    author={Lee, Juho and Lee, Yoonho and Kim, Jungtaek and Kosiorek, Adam and Choi, Seungjin and Teh, Yee Whye},
    booktitle={International conference on machine learning},
    pages={3744--3753},
    year={2019},
    organization={PMLR}
}

@article{kossen2021self,
    title={Self-attention between datapoints: Going beyond individual input-output pairs in deep learning},
    author={Kossen, Jannik and Band, Neil and Lyle, Clare and Gomez, Aidan N and Rainforth, Thomas and Gal, Yarin},
    journal={Advances in Neural Information Processing Systems},
    volume={34},
    pages={28742--28756},
    year={2021}
}

@incollection{bengio_1992,
    title={On the optimization of a synaptic learning rule},
    author={Bengio, Samy and Bengio, Yoshua and Cloutier, Jocelyn and Gescei, Jan},
    booktitle={Optimality in Biological and Artificial Networks?},
    pages={281--303},
    year={1992},
    publisher={Routledge}
}

@article{andrychowicz_2016,
    title={Learning to learn by gradient descent by gradient descent},
    author={Andrychowicz, Marcin and Denil, Misha and Gomez, Sergio and Hoffman, Matthew W and Pfau, David and Schaul, Tom and Shillingford, Brendan and De Freitas, Nando},
    journal={Advances in neural information processing systems},
    volume={29},
    year={2016}
}

@inproceedings{metz2019understanding,
    title={Understanding and correcting pathologies in the training of learned optimizers},
    author={Metz, Luke and Maheswaranathan, Niru and Nixon, Jeremy and Freeman, Daniel and Sohl-Dickstein, Jascha},
    booktitle={International Conference on Machine Learning},
    pages={4556--4565},
    year={2019},
    organization={PMLR}
}

@inproceedings{merchant2021learn2hop,
  title={Learn2hop: Learned optimization on rough landscapes},
  author={Merchant, Amil and Metz, Luke and Schoenholz, Samuel S and Cubuk, Ekin D},
  booktitle={International Conference on Machine Learning},
  pages={7643--7653},
  year={2021},
  organization={PMLR}
}

@article{kirsch2021meta,
    title={Meta learning backpropagation and improving it},
    author={Kirsch, Louis and Schmidhuber, J{\"u}rgen},
    journal={Advances in Neural Information Processing Systems},
    volume={34},
    pages={14122--14134},
    year={2021}
}

@article{metz_2020tasks,
    title={Tasks, stability, architecture, and compute: Training more effective learned optimizers, and using them to train themselves},
    author={Metz, Luke and Maheswaranathan, Niru and Freeman, C Daniel and Poole, Ben and Sohl-Dickstein, Jascha},
    journal={arXiv preprint arXiv:2009.11243},
    year={2020}
}

@article{metz2022practical,
    title={Practical tradeoffs between memory, compute, and performance in learned optimizers},
    author={Metz, Luke and Freeman, C Daniel and Harrison, James and Maheswaranathan, Niru and Sohl-Dickstein, Jascha},
    journal={arXiv preprint arXiv:2203.11860},
    year={2022}
}

@inproceedings{shala2020learning,
    title={Learning step-size adaptation in CMA-ES},
    author={Shala, Gresa and Biedenkapp, Andr{\'e} and Awad, Noor and Adriaensen, Steven and Lindauer, Marius and Hutter, Frank},
    booktitle={International Conference on Parallel Problem Solving from Nature},
    pages={691--706},
    year={2020},
    organization={Springer}
}

@article{hansen2001completely,
    title={Completely derandomized self-adaptation in evolution strategies},
    author={Hansen, Nikolaus and Ostermeier, Andreas},
    journal={Evolutionary computation},
    volume={9},
    number={2},
    pages={159--195},
    year={2001},
    publisher={MIT Press}
}

@inproceedings{tv2019meta,
    title={Meta-learning for black-box optimization},
    author={TV, Vishnu and Malhotra, Pankaj and Narwariya, Jyoti and Vig, Lovekesh and Shroff, Gautam},
    booktitle={Joint European Conference on Machine Learning and Knowledge Discovery in Databases},
    pages={366--381},
    year={2019},
    organization={Springer}
}

@article{gomes2021meta,
    title={Meta learning black-box population-based optimizers},
    author={Gomes, Hugo Siqueira and L{\'e}ger, Benjamin and Gagn{\'e}, Christian},
    journal={arXiv preprint arXiv:2103.03526},
    year={2021}
}

@inproceedings{chen_2017,
    title = 	 {Learning to Learn without Gradient Descent by Gradient Descent},
    author =       {Yutian Chen and Matthew W. Hoffman and Sergio G{\'o}mez Colmenarejo and Misha Denil and Timothy P. Lillicrap and Matt Botvinick and Nando de Freitas},
    booktitle = 	 {Proceedings of the 34th International Conference on Machine Learning},
    pages = 	 {748--756},
    year = 	 {2017},
    editor = 	 {Precup, Doina and Teh, Yee Whye},
    volume = 	 {70},
    series = 	 {Proceedings of Machine Learning Research},
    month = 	 {06--11 Aug},
    publisher =    {PMLR},
    pdf = 	 {http://proceedings.mlr.press/v70/chen17e/chen17e.pdf},
    url = 	 {https://proceedings.mlr.press/v70/chen17e.html},
    abstract = 	 {We learn recurrent neural network optimizers trained on simple synthetic functions by gradient descent. We show that these learned optimizers exhibit a remarkable degree of transfer in that they can be used to efficiently optimize a broad range of derivative-free black-box functions, including Gaussian process bandits, simple control objectives, global optimization benchmarks and hyper-parameter tuning tasks. Up to the training horizon, the learned optimizers learn to trade-off exploration and exploitation, and compare favourably with heavily engineered Bayesian optimization packages for hyper-parameter tuning.}
}

@article{parker2022automated,
  title={Automated reinforcement learning (autorl): A survey and open problems},
  author={Parker-Holder, Jack and Rajan, Raghu and Song, Xingyou and Biedenkapp, Andr{\'e} and Miao, Yingjie and Eimer, Theresa and Zhang, Baohe and Nguyen, Vu and Calandra, Roberto and Faust, Aleksandra and others},
  journal={Journal of Artificial Intelligence Research},
  volume={74},
  pages={517--568},
  year={2022}
}

@book{greatness,
    author = {Stanley, Kenneth O. and Lehman, Joel},
    title = {Why Greatness Cannot Be Planned: The Myth of the Objective},
    year = {2015},
    isbn = {3319155237},
    publisher = {Springer Publishing Company, Incorporated},
    abstract = {Why does modern life revolve around objectives? From how science is funded, to improving how children are educated -- and nearly everything in-between -- our society has become obsessed with a seductive illusion: that greatness results from doggedly measuring improvement in the relentless pursuit of an ambitious goal. In Why Greatness Cannot Be Planned, Stanley and Lehman begin with a surprising scientific discovery in artificial intelligence that leads ultimately to the conclusion that the objective obsession has gone too far. They make the case that great achievement can't be bottled up into mechanical metrics; that innovation is not driven by narrowly focused heroic effort; and that we would be wiser (and the outcomes better) if instead we whole-heartedly embraced serendipitous discovery and playful creativity. Controversial at its heart, yet refreshingly provocative, this book challenges readers to consider life without a destination and discovery without a compass.}
}

@article{neat,
    title={Evolving Neural Networks Through Augmenting Topologies},
    author={Kenneth O. Stanley and Risto Miikkulainen},
    volume={10},
    journal={Evolutionary Computation},
    number={2},
    pages={99-127},
    url="http://nn.cs.utexas.edu/?stanley:ec02",
    year={2002}
}

@misc{finck_RealParameterBlackBoxOptimization_noisy,
	title = {Real-{Parameter} {Black}-{Box} {Optimization} {Benchmarking} 2010: {Presentation} of the {Noisy} {Functions}},
	language = {en},
	author = {Finck, Steﬀen and Hansen, Nikolaus and Ros, Raymond and Auger, Anne},
    year = {2010},
}

@misc{finck_RealParameterBlackBoxOptimization_noiseless,
	title = {Real-{Parameter} {Black}-{Box} {Optimization} {Benchmarking} 2010: {Presentation} of the {Noiseless} {Functions}},
	language = {en},
	author = {Finck, Steﬀen and Hansen, Nikolaus and Ros, Raymond and Auger, Anne},
    year = {2010},
}

@misc{lange_DiscoveringEvolutionStrategies_2023,
	title = {Discovering {Evolution} {Strategies} via {Meta}-{Black}-{Box} {Optimization}},
	url = {http://arxiv.org/abs/2211.11260},
	doi = {10.48550/arXiv.2211.11260},
	abstract = {Optimizing functions without access to gradients is the remit of black-box methods such as evolution strategies. While highly general, their learning dynamics are often times heuristic and inflexible - exactly the limitations that meta-learning can address. Hence, we propose to discover effective update rules for evolution strategies via meta-learning. Concretely, our approach employs a search strategy parametrized by a self-attention-based architecture, which guarantees the update rule is invariant to the ordering of the candidate solutions. We show that meta-evolving this system on a small set of representative low-dimensional analytic optimization problems is sufficient to discover new evolution strategies capable of generalizing to unseen optimization problems, population sizes and optimization horizons. Furthermore, the same learned evolution strategy can outperform established neuroevolution baselines on supervised and continuous control tasks. As additional contributions, we ablate the individual neural network components of our method; reverse engineer the learned strategy into an explicit heuristic form, which remains highly competitive; and show that it is possible to self-referentially train an evolution strategy from scratch, with the learned update rule used to drive the outer meta-learning loop.},
	urldate = {2025-01-06},
	publisher = {arXiv},
	author = {Lange, Robert Tjarko and Schaul, Tom and Chen, Yutian and Zahavy, Tom and Dallibard, Valentin and Lu, Chris and Singh, Satinder and Flennerhag, Sebastian},
	month = mar,
	year = {2023},
	note = {arXiv:2211.11260 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Neural and Evolutionary Computing},
}

@misc{lange_DiscoveringAttentionBasedGenetic_2023,
	title = {Discovering {Attention}-{Based} {Genetic} {Algorithms} via {Meta}-{Black}-{Box} {Optimization}},
	url = {http://arxiv.org/abs/2304.03995},
	doi = {10.48550/arXiv.2304.03995},
	abstract = {Genetic algorithms constitute a family of black-box optimization algorithms, which take inspiration from the principles of biological evolution. While they provide a general-purpose tool for optimization, their particular instantiations can be heuristic and motivated by loose biological intuition. In this work we explore a fundamentally different approach: Given a sufficiently flexible parametrization of the genetic operators, we discover entirely new genetic algorithms in a data-driven fashion. More specifically, we parametrize selection and mutation rate adaptation as cross- and self-attention modules and use Meta-Black-Box-Optimization to evolve their parameters on a set of diverse optimization tasks. The resulting Learned Genetic Algorithm outperforms state-of-the-art adaptive baseline genetic algorithms and generalizes far beyond its meta-training settings. The learned algorithm can be applied to previously unseen optimization problems, search dimensions \& evaluation budgets. We conduct extensive analysis of the discovered operators and provide ablation experiments, which highlight the benefits of flexible module parametrization and the ability to transfer (`plug-in') the learned operators to conventional genetic algorithms.},
	urldate = {2025-01-06},
	publisher = {arXiv},
	author = {Lange, Robert Tjarko and Schaul, Tom and Chen, Yutian and Lu, Chris and Zahavy, Tom and Dalibard, Valentin and Flennerhag, Sebastian},
	month = apr,
	year = {2023},
	note = {arXiv:2304.03995 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
}

@article{pugh_QualityDiversityNew_2016,
	title = {Quality {Diversity}: {A} {New} {Frontier} for {Evolutionary} {Computation}},
	volume = {3},
	issn = {2296-9144},
	shorttitle = {Quality {Diversity}},
	url = {https://www.frontiersin.org/journals/robotics-and-ai/articles/10.3389/frobt.2016.00040/full},
	doi = {10.3389/frobt.2016.00040},
	abstract = {{\textless}p{\textgreater}While evolutionary computation and evolutionary robotics take inspiration from nature, they have long focused mainly on problems of performance optimization. Yet, evolution in nature can be interpreted as more nuanced than a process of simple optimization. In particular, natural evolution is a divergent search that optimizes locally within each niche as it simultaneously diversifies. This tendency to discover both quality and diversity at the same time differs from many of the conventional algorithms of machine learning, and also thereby suggests a different foundation for inferring the approach of greatest potential for evolutionary algorithms. In fact, several recent evolutionary algorithms called {\textless}italic{\textgreater}quality diversity (QD) algorithms{\textless}/italic{\textgreater} (e.g., novelty search with local competition and MAP-Elites) have drawn inspiration from this more nuanced view, aiming to fill a space of possibilities with the best possible example of each type of achievable behavior. The result is a new class of algorithms that return an archive of diverse, high-quality behaviors in a single run. The aim in this paper is to study the application of QD algorithms in challenging environments (in particular complex mazes) to establish their best practices for ambitious domains in the future. In addition to providing insight into cases when QD succeeds and fails, a new approach is investigated that hybridizes multiple views of behaviors (called {\textless}italic{\textgreater}behavior characterizations{\textless}/italic{\textgreater}) in the same run, which succeeds in overcoming some of the challenges associated with searching for QD with respect to a behavior characterization that is not necessarily sufficient for generating both quality and diversity at the same time.{\textless}/p{\textgreater}},
	language = {English},
	urldate = {2025-01-06},
	journal = {Frontiers in Robotics and AI},
	author = {Pugh, Justin K. and Soros, Lisa B. and Stanley, Kenneth O.},
	month = jul,
	year = {2016},
	note = {Publisher: Frontiers},
	keywords = {behavior characterization, Behavioral diversity, Evolutionary computation, neuroevolution, non-objective search, novelty search, quality diversity},
}

@inproceedings{faldor_ArtificialOpenEndedEvolution_2024,
    author = {Faldor, Maxence and Cully, Antoine},
    title = {Toward Artificial Open-Ended Evolution within Lenia using Quality-Diversity},
    volume = {ALIFE 2024: Proceedings of the 2024 Artificial Life Conference},
    series = {Artificial Life Conference Proceedings},
    pages = {85},
    year = {2024},
    month = {07},
    abstract = {From the formation of snowflakes to the evolution of diverse life forms, emergence is ubiquitous in our universe. In the quest to understand how complexity can arise from simple rules, abstract computational models, such as cellular automata, have been developed to study self-organization. However, the discovery of self-organizing patterns in artificial systems is challenging and has largely relied on manual or semi-automatic search in the past. In this paper, we show that Quality-Diversity, a family of Evolutionary Algorithms, is an effective framework for the automatic discovery of diverse self-organizing patterns in complex systems. Quality-Diversity algorithms aim to evolve a large population of diverse individuals, each adapted to its ecological niche. Combined with Lenia, a family of continuous cellular automata, we demonstrate that our method is able to evolve a diverse population of lifelike self-organizing autonomous patterns. Our framework, called Leniabreeder, can leverage both manually defined diversity criteria to guide the search toward interesting areas, as well as unsupervised measures of diversity to broaden the scope of discoverable patterns. We demonstrate both qualitatively and quantitatively that Leniabreeder offers a powerful solution for discovering self-organizing patterns. The effectiveness of unsupervised Quality-Diversity methods combined with the rich landscape of Lenia exhibits a sustained generation of diversity and complexity characteristic of biological evolution. We provide empirical evidence that suggests unbounded diversity and argue that Leniabreeder is a step toward replicating open-ended evolution in silico.},
    doi = {10.1162/isal_a_00827},
    url = {https://doi.org/10.1162/isal\_a\_00827},
}

@misc{mouret_IlluminatingSearchSpaces_2015,
	title = {Illuminating search spaces by mapping elites},
	url = {http://arxiv.org/abs/1504.04909},
	doi = {10.48550/arXiv.1504.04909},
	abstract = {Many fields use search algorithms, which automatically explore a search space to find high-performing solutions: chemists search through the space of molecules to discover new drugs; engineers search for stronger, cheaper, safer designs, scientists search for models that best explain data, etc. The goal of search algorithms has traditionally been to return the single highest-performing solution in a search space. Here we describe a new, fundamentally different type of algorithm that is more useful because it provides a holistic view of how high-performing solutions are distributed throughout a search space. It creates a map of high-performing solutions at each point in a space defined by dimensions of variation that a user gets to choose. This Multi-dimensional Archive of Phenotypic Elites (MAP-Elites) algorithm illuminates search spaces, allowing researchers to understand how interesting attributes of solutions combine to affect performance, either positively or, equally of interest, negatively. For example, a drug company may wish to understand how performance changes as the size of molecules and their cost-to-produce vary. MAP-Elites produces a large diversity of high-performing, yet qualitatively different solutions, which can be more helpful than a single, high-performing solution. Interestingly, because MAP-Elites explores more of the search space, it also tends to find a better overall solution than state-of-the-art search algorithms. We demonstrate the benefits of this new algorithm in three different problem domains ranging from producing modular neural networks to designing simulated and real soft robots. Because MAP- Elites (1) illuminates the relationship between performance and dimensions of interest in solutions, (2) returns a set of high-performing, yet diverse solutions, and (3) improves finding a single, best solution, it will advance science and engineering.},
	urldate = {2025-01-07},
	publisher = {arXiv},
	author = {Mouret, Jean-Baptiste and Clune, Jeff},
	month = apr,
	year = {2015},
	note = {arXiv:1504.04909 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Neural and Evolutionary Computing, Computer Science - Robotics, Quantitative Biology - Populations and Evolution},
}

@article{faldor_SynergizingQualityDiversityDescriptorConditioned_2024,
    author = {Faldor, Maxence and Chalumeau, F\'{e}lix and Flageat, Manon and Cully, Antoine},
    title = {Synergizing Quality-Diversity with Descriptor-Conditioned Reinforcement Learning},
    year = {2024},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3696426},
    doi = {10.1145/3696426},
    abstract = {A hallmark of intelligence is the ability to exhibit a wide range of effective behaviors. Inspired by this principle, Quality-Diversity algorithms, such as, are evolutionary methods designed to generate a set of diverse and high-fitness solutions. However, as a genetic algorithm, relies on random mutations, which can become inefficient in high-dimensional search spaces, thus limiting its scalability to more complex domains, such as learning to control agents directly from high-dimensional inputs. To address this limitation, advanced methods like and have been developed, which combine actor-critic techniques from Reinforcement Learning with, significantly enhancing the performance and efficiency of Quality-Diversity algorithms in complex, high-dimensional tasks. While these methods have successfully leveraged the trained critic to guide more effective mutations, the potential of the trained actor remains underutilized in improving both the quality and diversity of the evolved population. In this work, we introduce, an extension of that utilizes the descriptor-conditioned actor as a generative model to produce diverse solutions, which are then injected into the offspring batch at each generation. Additionally, we present an empirical analysis of the fitness and descriptor reproducibility of the solutions discovered by each algorithm. Finally, we present a second empirical analysis shedding light on the synergies between the different variations operators and explaining the performance improvement from to.},
    journal = {ACM Trans. Evol. Learn. Optim.},
    month = sep,
    keywords = {Quality-Diversity, Reinforcement Learning, Neuroevolution, MAP-Elites, Policy Gradient}
}

@inproceedings{faldor_MAPElitesDescriptorConditionedGradients_2023,
	address = {New York, NY, USA},
	series = {{GECCO} '23},
	title = {{MAP}-{Elites} with {Descriptor}-{Conditioned} {Gradients} and {Archive} {Distillation} into a {Single} {Policy}},
	isbn = {9798400701191},
	url = {https://dl.acm.org/doi/10.1145/3583131.3590503},
	doi = {10.1145/3583131.3590503},
	abstract = {Quality-Diversity algorithms, such as MAP-Elites, are a branch of Evolutionary Computation generating collections of diverse and high-performing solutions, that have been successfully applied to a variety of domains and particularly in evolutionary robotics. However, MAP-Elites performs a divergent search based on random mutations originating from Genetic Algorithms, and thus, is limited to evolving populations of low-dimensional solutions. PGA-MAP-Elites overcomes this limitation by integrating a gradient-based variation operator inspired by Deep Reinforcement Learning which enables the evolution of large neural networks. Although high-performingin many environments, PGA-MAP-Elites fails on several tasks where the convergent search of the gradient-based operator does not direct mutations towards archive-improving solutions. In this work, we present two contributions: (1) we enhance the Policy Gradient variation operator with a descriptor-conditioned critic that improves the archive across the entire descriptor space, (2) we exploit the actor-critic training to learn a descriptor-conditioned policy at no additional cost, distilling the knowledge of the archive into one single versatile policy that can execute the entire range of behaviors contained in the archive. Our algorithm, DCG-MAP-Elites improves the QD score over PGA-MAP-Elites by 82\% on average, on a set of challenging locomotion tasks.},
	urldate = {2025-01-07},
	booktitle = {Proceedings of the {Genetic} and {Evolutionary} {Computation} {Conference}},
	publisher = {Association for Computing Machinery},
	author = {Faldor, Maxence and Chalumeau, Félix and Flageat, Manon and Cully, Antoine},
	month = jul,
	year = {2023},
	pages = {138--146},
}

@inproceedings{cully_AutonomousSkillDiscovery_2019,
	address = {New York, NY, USA},
	series = {{GECCO} '19},
	title = {Autonomous skill discovery with quality-diversity and unsupervised descriptors},
	isbn = {978-1-4503-6111-8},
	url = {https://doi.org/10.1145/3321707.3321804},
	doi = {10.1145/3321707.3321804},
	abstract = {Quality-Diversity optimization is a new family of optimization algorithms that, instead of searching for a single optimal solution to solving a task, searches for a large collection of solutions that all solve the task in a different way. This approach is particularly promising for learning behavioral repertoires in robotics, as such a diversity of behaviors enables robots to be more versatile and resilient. However, these algorithms require the user to manually define behavioral descriptors, which is used to determine whether two solutions are different or similar. The choice of a behavioral descriptor is crucial, as it completely changes the solution types that the algorithm derives. In this paper, we introduce a new method to automatically define this descriptor by combining Quality-Diversity algorithms with unsupervised dimensionality reduction algorithms. This approach enables robots to autonomously discover the range of their capabilities while interacting with their environment. The results from two experimental scenarios demonstrate that robot can autonomously discover a large range of possible behaviors, without any prior knowledge about their morphology and environment. Furthermore, these behaviors are deemed to be similar to hand-crafted solutions that uses domain knowledge and significantly more diverse than when using existing unsupervised methods.},
	urldate = {2025-01-07},
	booktitle = {Proceedings of the {Genetic} and {Evolutionary} {Computation} {Conference}},
	publisher = {Association for Computing Machinery},
	author = {Cully, Antoine},
	month = jul,
	year = {2019},
	pages = {81--89},
}

@inproceedings{tang_SensoryNeuronTransformer_2021,
	title = {The {Sensory} {Neuron} as a {Transformer}: {Permutation}-{Invariant} {Neural} {Networks} for {Reinforcement} {Learning}},
	volume = {34},
	shorttitle = {The {Sensory} {Neuron} as a {Transformer}},
	url = {https://proceedings.neurips.cc/paper_files/paper/2021/hash/be3e9d3f7d70537357c67bb3f4086846-Abstract.html},
	abstract = {In complex systems, we often observe complex global behavior emerge from a collection of agents interacting with each other in their environment, with each individual agent acting only on locally available information, without knowing the full picture. Such systems have inspired development of artificial intelligence algorithms in areas such as swarm optimization and cellular automata. Motivated by the emergence of collective behavior from complex cellular systems, we build systems that feed each sensory input from the environment into distinct, but identical neural networks, each with no fixed relationship with one another. We show that these sensory networks can be trained to integrate information received locally, and through communication via an attention mechanism, can collectively produce a globally coherent policy. Moreover, the system can still perform its task even if the ordering of its inputs is randomly permuted several times during an episode. These permutation invariant systems also display useful robustness and generalization properties that are broadly applicable. Interactive demo and videos of our results: https://attentionneuron.github.io},
	urldate = {2025-01-07},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Tang, Yujin and Ha, David},
	year = {2021},
	pages = {22574--22587},
}

@misc{lee_SetTransformerFramework_2019,
	title = {Set {Transformer}: {A} {Framework} for {Attention}-based {Permutation}-{Invariant} {Neural} {Networks}},
	shorttitle = {Set {Transformer}},
	url = {http://arxiv.org/abs/1810.00825},
	doi = {10.48550/arXiv.1810.00825},
	abstract = {Many machine learning tasks such as multiple instance learning, 3D shape recognition, and few-shot image classification are defined on sets of instances. Since solutions to such problems do not depend on the order of elements of the set, models used to address them should be permutation invariant. We present an attention-based neural network module, the Set Transformer, specifically designed to model interactions among elements in the input set. The model consists of an encoder and a decoder, both of which rely on attention mechanisms. In an effort to reduce computational complexity, we introduce an attention scheme inspired by inducing point methods from sparse Gaussian process literature. It reduces the computation time of self-attention from quadratic to linear in the number of elements in the set. We show that our model is theoretically attractive and we evaluate it on a range of tasks, demonstrating the state-of-the-art performance compared to recent methods for set-structured data.},
	urldate = {2025-01-07},
	publisher = {arXiv},
	author = {Lee, Juho and Lee, Yoonho and Kim, Jungtaek and Kosiorek, Adam R. and Choi, Seungjin and Teh, Yee Whye},
	month = may,
	year = {2019},
	note = {arXiv:1810.00825 [cs]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{vaswani_AttentionAllYou_2017,
	address = {Red Hook, NY, USA},
	series = {{NIPS}'17},
	title = {Attention is all you need},
	isbn = {978-1-5108-6096-4},
	abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.0 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature.},
	urldate = {2025-01-07},
	booktitle = {Proceedings of the 31st {International} {Conference} on {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates Inc.},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Łukasz and Polosukhin, Illia},
	month = dec,
	year = {2017},
	pages = {6000--6010},
}

@misc{soros_OpenendednessLastGrand_2017,
	title = {Open-endedness: {The} last grand challenge you've never heard of},
	shorttitle = {Open-endedness},
	url = {https://www.oreilly.com/radar/open-endedness-the-last-grand-challenge-youve-never-heard-of/},
	abstract = {While open-endedness could be a force for discovering intelligence, it could also be a component of AI itself.},
	language = {en-US},
	urldate = {2025-01-09},
	journal = {O’Reilly Media},
	author = {Soros, Lisa and Lehman, Joel and Stanley 0., Kenneth},
	month = dec,
	year = {2017},
}

@inproceedings{pegasus,
    author = {Ng, Andrew Y. and Jordan, Michael I.},
    title = {PEGASUS: A policy search method for large MDPs and POMDPs},
    year = {2000},
    isbn = {1558607099},
    publisher = {Morgan Kaufmann Publishers Inc.},
    address = {San Francisco, CA, USA},
    booktitle = {Proceedings of the 16th Conference on Uncertainty in Artificial Intelligence},
    pages = {406–415},
    numpages = {10},
    series = {UAI '00}
}

@article{evosax2022github,
    author = {Robert Tjarko Lange},
    title = {evosax: JAX-based Evolution Strategies},
    journal={arXiv preprint arXiv:2212.04180},
    year = {2022},
}

@incollection{sepcmaes,
	address = {Berlin, Heidelberg},
	title = {A {Simple} {Modification} in {CMA}-{ES} {Achieving} {Linear} {Time} and {Space} {Complexity}},
	volume = {5199},
	isbn = {978-3-540-87699-1 978-3-540-87700-4},
	url = {http://link.springer.com/10.1007/978-3-540-87700-4_30},
	abstract = {This paper proposes a simple modiﬁcation of the Covariance Matrix Adaptation Evolution Strategy (CMA-ES) for high dimensional objective functions, reducing the internal time and space complexity from quadratic to linear. The covariance matrix is constrained to be diagonal and the resulting algorithm, sep-CMA-ES, samples each coordinate independently. Because the model complexity is reduced, the learning rate for the covariance matrix can be increased. Consequently, on essentially separable functions, sep-CMA-ES signiﬁcantly outperforms CMA-ES. For dimensions larger than a hundred, even on the nonseparable Rosenbrock function, the sep-CMA-ES needs fewer function evaluations than CMA-ES.},
	language = {en},
	urldate = {2025-01-09},
	booktitle = {Parallel {Problem} {Solving} from {Nature} – {PPSN} {X}},
	publisher = {Springer Berlin Heidelberg},
	author = {Ros, Raymond and Hansen, Nikolaus},
	editor = {Rudolph, Günter and Jansen, Thomas and Beume, Nicola and Lucas, Simon and Poloni, Carlo},
	year = {2008},
	doi = {10.1007/978-3-540-87700-4_30},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {296--305},
}

@misc{cmaes,
	title = {The {CMA} {Evolution} {Strategy}: {A} {Tutorial}},
	shorttitle = {The {CMA} {Evolution} {Strategy}},
	url = {http://arxiv.org/abs/1604.00772},
	doi = {10.48550/arXiv.1604.00772},
	abstract = {This tutorial introduces the CMA Evolution Strategy (ES), where CMA stands for Covariance Matrix Adaptation. The CMA-ES is a stochastic, or randomized, method for real-parameter (continuous domain) optimization of non-linear, non-convex functions. We try to motivate and derive the algorithm from intuitive concepts and from requirements of non-linear, non-convex search in continuous domain.},
	urldate = {2025-01-09},
	publisher = {arXiv},
	author = {Hansen, Nikolaus},
	month = mar,
	year = {2023},
	note = {arXiv:1604.00772 [cs]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{jamil_LiteratureSurveyBenchmark_2013,
	title = {A {Literature} {Survey} of {Benchmark} {Functions} {For} {Global} {Optimization} {Problems}},
	volume = {4},
	doi = {10.1504/IJMMNO.2013.055204},
	abstract = {Test functions are important to validate and compare the performance of optimization algorithms. There have been many test or benchmark functions reported in the literature; however, there is no standard list or set of benchmark functions. Ideally, test functions should have diverse properties so that can be truly useful to test new algorithms in an unbiased way. For this purpose, we have reviewed and compiled a rich set of 175 benchmark functions for unconstrained optimization problems with diverse properties in terms of modality, separability, and valley landscape. This is by far the most complete set of functions so far in the literature, and tt can be expected this complete set of functions can be used for validation of new optimization in the future.},
	journal = {Int. J. of Mathematical Modelling and Numerical Optimisation},
	author = {Jamil, Momin and Yang, Xin-She},
	month = aug,
	year = {2013},
}

@article{vassiliades_UsingCentroidalVoronoi_2018,
    title = {Using {Centroidal} {Voronoi} {Tessellations} to {Scale} {Up} the {Multidimensional} {Archive} of {Phenotypic} {Elites} {Algorithm}},
    volume = {22},
    issn = {1941-0026},
    url = {https://ieeexplore.ieee.org/document/8000667},
    doi = {10.1109/TEVC.2017.2735550},
    abstract = {The recently introduced multidimensional archive of phenotypic elites (MAP-Elites) is an evolutionary algorithm capable of producing a large archive of diverse, high-performing solutions in a single run. It works by discretizing a continuous feature space into unique regions according to the desired discretization per dimension. While simple, this algorithm has a main drawback: it cannot scale to high-dimensional feature spaces since the number of regions increase exponentially with the number of dimensions. In this paper, we address this limitation by introducing a simple extension of MAP-Elites that has a constant, predefined number of regions irrespective of the dimensionality of the feature space. Our main insight is that methods from computational geometry could partition a high-dimensional space into well-spread geometric regions. In particular, our algorithm uses a centroidal Voronoi tessellation (CVT) to divide the feature space into a desired number of regions; it then places every generated individual in its closest region, replacing a less fit one if the region is already occupied. We demonstrate the effectiveness of the new “CVT-MAP-Elites” algorithm in high-dimensional feature spaces through comparisons against MAP-Elites in maze navigation and hexapod locomotion tasks.},
    number = {4},
    urldate = {2025-01-13},
    journal = {IEEE Transactions on Evolutionary Computation},
    author = {Vassiliades, Vassilis and Chatzilygeroudis, Konstantinos and Mouret, Jean-Baptiste},
    month = aug,
    year = {2018},
    note = {Conference Name: IEEE Transactions on Evolutionary Computation},
    keywords = {Behavioral diversity, centroidal Voronoi tessellation (CVT), Clustering algorithms, Evolutionary computation, illumination algorithms, Legged locomotion, Lighting, multidimensional archive of phenotypic elites (MAP-Elites), Optimization, Partitioning algorithms, quality diversity (QD)},
    pages = {623--630},
}

@article{ga,
    ISSN = {00368733, 19467087},
    URL = {http://www.jstor.org/stable/24939139},
    author = {John H. Holland},
    journal = {Scientific American},
    number = {1},
    pages = {66--73},
    publisher = {Scientific American, a division of Nature America, Inc.},
    title = {Genetic Algorithms},
    urldate = {2025-01-12},
    volume = {267},
    year = {1992}
}

@book{rechenberg_EvolutionsstrategieOptimierungTechnischer_1973,
    address = {Stuttgart-Bad Cannstadt},
    series = {Problemata},
    title = {Evolutionsstrategie: {Optimierung} technischer {Systeme} nach {Prinzipien} der biologischen {Evolution}},
    isbn = {978-3-7728-0373-4 978-3-7728-0374-1},
    shorttitle = {Evolutionsstrategie},
    language = {de},
    number = {15},
    publisher = {Frommann-Holzboog},
    author = {Rechenberg, Ingo and Eigen, Manfred},
    year = {1973},
}

@misc{lange_EvolutionTransformerInContext_2024,
	title = {Evolution {Transformer}: {In}-{Context} {Evolutionary} {Optimization}},
	shorttitle = {Evolution {Transformer}},
	url = {http://arxiv.org/abs/2403.02985},
	doi = {10.48550/arXiv.2403.02985},
	abstract = {Evolutionary optimization algorithms are often derived from loose biological analogies and struggle to leverage information obtained during the sequential course of optimization. An alternative promising approach is to leverage data and directly discover powerful optimization principles via meta-optimization. In this work, we follow such a paradigm and introduce Evolution Transformer, a causal Transformer architecture, which can flexibly characterize a family of Evolution Strategies. Given a trajectory of evaluations and search distribution statistics, Evolution Transformer outputs a performance-improving update to the search distribution. The architecture imposes a set of suitable inductive biases, i.e. the invariance of the distribution update to the order of population members within a generation and equivariance to the order of the search dimensions. We train the model weights using Evolutionary Algorithm Distillation, a technique for supervised optimization of sequence models using teacher algorithm trajectories. The resulting model exhibits strong in-context optimization performance and shows strong generalization capabilities to otherwise challenging neuroevolution tasks. We analyze the resulting properties of the Evolution Transformer and propose a technique to fully self-referentially train the Evolution Transformer, starting from a random initialization and bootstrapping its own learning progress. We provide an open source implementation under https://github.com/RobertTLange/evosax.},
	urldate = {2025-01-14},
	publisher = {arXiv},
	author = {Lange, Robert Tjarko and Tian, Yingtao and Tang, Yujin},
	month = mar,
	year = {2024},
	note = {arXiv:2403.02985 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Neural and Evolutionary Computing},
}

@software{jax,
  author = {James Bradbury and Roy Frostig and Peter Hawkins and Matthew James Johnson and Chris Leary and Dougal Maclaurin and George Necula and Adam Paszke and Jake Vander{P}las and Skye Wanderman-{M}ilne and Qiao Zhang},
  title = {{JAX}: composable transformations of {P}ython+{N}um{P}y programs},
  url = {http://github.com/jax-ml/jax},
  version = {0.3.13},
  year = {2018},
}

@article{qdax,
	title = {{QDax}: a library for quality-diversity and population-based algorithms with hardware acceleration},
	volume = {25},
	url = {http://jmlr.org/papers/v25/23-1027.html},
	number = {108},
	journal = {Journal of Machine Learning Research},
	author = {Chalumeau, Felix and Lim, Bryan and Boige, Raphaël and Allard, Maxime and Grillotti, Luca and Flageat, Manon and Macé, Valentin and Richard, Guillaume and Flajolet, Arthur and Pierrot, Thomas and Cully, Antoine},
	year = {2024},
	pages = {1--16},
}

@inproceedings{jedi,
author = {Templier, Paul and Grillotti, Luca and Rachelson, Emmanuel and Wilson, Dennis and Cully, Antoine},
title = {Quality with Just Enough Diversity in Evolutionary Policy Search},
year = {2024},
isbn = {9798400704949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3638529.3654047},
doi = {10.1145/3638529.3654047},
abstract = {Evolution Strategies (ES) are effective gradient-free optimization methods that can be competitive with gradient-based approaches for policy search. ES only rely on the total episodic scores of solutions in their population, from which they estimate fitness gradients for their update with no access to true gradient information. However this makes them sensitive to deceptive fitness landscapes, and they tend to only explore one way to solve a problem. Quality-Diversity methods such as MAP-Elites introduced additional information with behavior descriptors (BD) to return a population of diverse solutions, which helps exploration but leads to a large part of the evaluation budget not being focused on finding the best performing solution. Here we show that behavior information can also be leveraged to find the best policy by identifying promising search areas which can then be efficiently explored with ES. We introduce the framework of Quality with Just Enough Diversity (JEDi) which learns the relationship between behavior and fitness to focus evaluations on solutions that matter. When trying to reach higher fitness values, JEDi outperforms both QD and ES methods on hard exploration tasks like mazes and on complex control problems with large policies.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
pages = {105–113},
numpages = {9},
keywords = {evolution, quality diversity, evolution strategies},
location = {Melbourne, VIC, Australia},
series = {GECCO '24}
}

@inproceedings{GeneticAlgorithmsSharing1987,
    title = {Genetic Algorithms with Sharing for Multimodal Function Optimization},
    booktitle = {Genetic Algorithms and their Applications: Proceedings of the Second International Conference on Genetic Algorithms},
    author = {Goldberg, David E. and Richardson, Jon},
    year = {1987},
    pages = {41--49}
}

@inproceedings{alps,
    author = {Hornby, Gregory S.},
    title = {ALPS: the age-layered population structure for reducing the problem of premature convergence},
    year = {2006},
    isbn = {1595931864},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/1143997.1144142},
    doi = {10.1145/1143997.1144142},
    abstract = {To reduce the problem of premature convergence we define a new method for measuring an individual's age and propose the Age-Layered Population Structure (ALPS). This new measure of age measures how long the genetic material has been evolving in the population: offspring start with an age of 1 plus the age of their oldest parent instead of starting with an age of 0 as with traditional measures of age. ALPS differs from a typical evolutionary algorithm (EA) by segregating individuals into different age-layers by their age and by regularly introducing new, randomly generated individuals in the youngest layer. The introduction of randomly generated individuals at regular intervals results in an EA that is never completely converged and is always exploring new parts of the fitness landscape. By using age to restrict competition and breeding, younger individuals are able to develop without being dominated by older ones. Analysis of the search behavior of ALPS finds that the offspring of individuals that are randomly generated mid-way through a run are able to move the population out of mediocre local-optima to better parts of the fitness landscape. In comparison against a traditional EA, a multi-start EA and two other EAs with diversity maintenance schemes we find that ALPS produces significantly better designs with a higher reliability than the other EAs.},
    booktitle = {Proceedings of the 8th Annual Conference on Genetic and Evolutionary Computation},
    pages = {815–822},
    numpages = {8},
    keywords = {age, computer-automated design, evolutionary algorithms, open-ended design, premature convergence},
    location = {Seattle, Washington, USA},
    series = {GECCO '06}
}

@article{hfc,
    author = {Hu, Jianjun and Goodman, Erik and Seo, Kisung and Fan, Zhun and Rosenberg, Rondal},
    title = {The Hierarchical Fair Competition (HFC) Framework for Sustainable Evolutionary Algorithms},
    year = {2005},
    issue_date = {June 2005},
    publisher = {MIT Press},
    address = {Cambridge, MA, USA},
    volume = {13},
    number = {2},
    issn = {1063-6560},
    url = {https://doi.org/10.1162/1063656054088530},
    doi = {10.1162/1063656054088530},
    abstract = {Many current Evolutionary Algorithms (EAs) suffer from a tendency to converge prematurely or stagnate without progress for complex problems. This may be due to the loss of or failure to discover certain valuable genetic material or the loss of the capability to discover new genetic material before convergence has limited the algorithm's ability to search widely. In this paper, the Hierarchical Fair Competition (HFC) model, including several variants, is proposed as a generic framework for sustainable evolutionary search by transforming the convergent nature of the current EA framework into a non-convergent search process. That is, the structure of HFC does not allow the convergence of the population to the vicinity of any set of optimal or locally optimal solutions. The sustainable search capability of HFC is achieved by ensuring a continuous supply and the incorporation of genetic material in a hierarchical manner, and by culturing and maintaining, but continually renewing, populations of individuals of intermediate fitness levels. HFC employs an assembly-line structure in which subpopulations are hierarchically organized into different fitness levels, reducing the selection pressure within each subpopulation while maintaining the global selection pressure to help ensure the exploitation of the good genetic material found. Three EAs based on the HFC principle are tested - two on the even-10-parity genetic programming benchmark problem and a real-world analog circuit synthesis problem, and another on the HIFF genetic algorithm (GA) benchmark problem. The significant gain in robustness, scalability and efficiency by HFC, with little additional computing effort, and its tolerance of small population sizes, demonstrates its effectiveness on these problems and shows promise of its potential for improving other existing EAs for difficult problems. A paradigm shift from that of most EAs is proposed: rather than trying to escape from local optima or delay convergence at a local optimum, HFC allows the emergence of new optima continually in a bottom-up manner, maintaining low local selection pressure at all fitness levels, while fostering exploitation of high-fitness individuals through promotion to higher levels.},
    journal = {Evol. Comput.},
    month = jun,
    pages = {241–277},
    numpages = {37}
}

@article{fitnessUniform,
    author = {Hutter, M. and Legg, S.},
    title = {Fitness uniform optimization},
    year = {2006},
    issue_date = {October 2006},
    publisher = {IEEE Press},
    volume = {10},
    number = {5},
    issn = {1089-778X},
    url = {https://doi.org/10.1109/TEVC.2005.863127},
    doi = {10.1109/TEVC.2005.863127},
    abstract = {In evolutionary algorithms, the fitness of a population increases with time by mutating and recombining individuals and by a biased selection of fitter individuals. The right selection pressure is critical in ensuring sufficient optimization progress on the one hand and in preserving genetic diversity to be able to escape from local optima on the other hand. Motivated by a universal similarity relation on the individuals, we propose a new selection scheme, which is uniform in the fitness values. It generates selection pressure toward sparsely populated fitness regions, not necessarily toward higher fitness, as is the case for all other selection schemes. We show analytically on a simple example that the new selection scheme can be much more effective than standard selection schemes. We also propose a new deletion scheme which achieves a similar result via deletion and show how such a scheme preserves genetic diversity more effectively than standard approaches. We compare the performance of the new schemes to tournament selection and random deletion on an artificial deceptive problem and a range of NP hard problems: traveling salesman, set covering, and satisfiability},
    journal = {Trans. Evol. Comp},
    month = oct,
    pages = {568–589},
    numpages = {22},
    keywords = {Fitness tree model, fitness uniform deletion scheme, fitness uniform selection scheme, local optima, preserve diversity, satisfiability, set covering, traveling salesman}
}

@phdthesis{mahfoud_NichingMethodsMultimodal_1995,
    title = {Niching Methods for Genetic Algorithms},
    author = {Mahfoud, Samir W.},
    year = {1995},
    school = {University of Illinois at Urbana-Champaign},
    address = {Urbana}
}

@article{lehman_AbandoningObjectivesEvolution_2011,
    title = {Abandoning {Objectives}: {Evolution} {Through} the {Search} for {Novelty} {Alone}},
    volume = {19},
    issn = {1063-6560, 1530-9304},
    shorttitle = {Abandoning {Objectives}},
    url = {https://direct.mit.edu/evco/article/19/2/189-223/1365},
    doi = {10.1162/EVCO_a_00025},
    abstract = {In evolutionary computation, the ﬁtness function normally measures progress towards an objective in the search space, effectively acting as an objective function. Through deception, such objective functions may actually prevent the objective from being reached. While methods exist to mitigate deception, they leave the underlying pathology untreated: Objective functions themselves may actively misdirect search towards dead ends. This paper proposes an approach to circumventing deception that also yields a new perspective on open-ended evolution: Instead of either explicitly seeking an objective or modeling natural evolution to capture open-endedness, the idea is to simply search for behavioral novelty. Even in an objective-based problem, such novelty search ignores the objective. Because many points in the search space collapse to a single behavior, the search for novelty is often feasible. Furthermore, because there are only so many simple behaviors, the search for novelty leads to increasing complexity. By decoupling open-ended search from artiﬁcial life worlds, the search for novelty is applicable to real world problems. Counterintuitively, in the maze navigation and biped walking tasks in this paper, novelty search signiﬁcantly outperforms objective-based search, suggesting the strange conclusion that some problems are best solved by methods that ignore the objective. The main lesson is the inherent limitation of the objective-based paradigm and the unexploited opportunity to guide search through other means.},
    language = {en},
    number = {2},
    urldate = {2025-01-17},
    journal = {Evolutionary Computation},
    author = {Lehman, Joel and Stanley, Kenneth O.},
    month = jun,
    year = {2011},
    pages = {189--223},
}

@inproceedings{nslc,
    author = {Lehman, Joel and Stanley, Kenneth O.},
    title = {Evolving a diversity of virtual creatures through novelty search and local competition},
    year = {2011},
    isbn = {9781450305570},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/2001576.2001606},
    doi = {10.1145/2001576.2001606},
    abstract = {An ambitious challenge in artificial life is to craft an evolutionary process that discovers a wide diversity of well-adapted virtual creatures within a single run. Unlike in nature, evolving creatures in virtual worlds tend to converge to a single morphology because selection therein greedily rewards the morphology that is easiest to exploit. However, novelty search, a technique that explicitly rewards diverging, can potentially mitigate such convergence. Thus in this paper an existing creature evolution platform is extended with multi-objective search that balances drives for both novelty and performance. However, there are different ways to combine performance-driven search and novelty search. The suggested approach is to provide evolution with both a novelty objective that encourages diverse morphologies and a local competition objective that rewards individuals outperforming those most similar in morphology. The results in an experiment evolving locomoting virtual creatures show that novelty search with local competition discovers more functional morphological diversity within a single run than models with global competition, which are more predisposed to converge. The conclusions are that novelty search with local competition may complement recent advances in evolving virtual creatures and may in general be a principled approach to combining novelty search with pressure to achieve.},
    booktitle = {Proceedings of the 13th Annual Conference on Genetic and Evolutionary Computation},
    pages = {211–218},
    numpages = {8},
    keywords = {artificial life, natural evolution, novelty search, virtual creatures},
    location = {Dublin, Ireland},
    series = {GECCO '11}
}


@article{cully_RobotsThatCan_2015,
    title = {Robots that can adapt like animals},
    volume = {521},
    issn = {1476-4687},
    url = {https://doi.org/10.1038/nature14422},
    doi = {10.1038/nature14422},
    abstract = {An intelligent trial-and-error learning algorithm is presented that allows robots to adapt in minutes to compensate for a wide variety of types of damage.},
    number = {7553},
    journal = {Nature},
    author = {Cully, Antoine and Clune, Jeff and Tarapore, Danesh and Mouret, Jean-Baptiste},
    month = may,
    year = {2015},
    pages = {503--507},
}

@software{brax,
    author = {C. Daniel Freeman and Erik Frey and Anton Raichuk and Sertan Girgin and Igor Mordatch and Olivier Bachem},
    title = {Brax - A Differentiable Physics Engine for Large Scale Rigid Body Simulation},
    url = {http://github.com/google/brax},
    version = {0.12.1},
    year = {2021},
}

@article{Johnson1984ExtensionsOL,
    title={Extensions of Lipschitz mappings into Hilbert space},
    author={William B. Johnson and Joram Lindenstrauss},
    journal={Contemporary mathematics},
    year={1984},
    volume={26},
    pages={189-206},
    url={https://api.semanticscholar.org/CorpusID:117819162}
}

@book{darwin,
    title={On the Origin of Species by Means of Natural Selection, or the Preservation of Favoured Races in the Struggle for Life},
    author={Darwin, Charles},
    year={1859},
    publisher={John Murray},
    address={London},
    edition={1},
}

@article{csc,
    author={Grillotti, Luca and Cully, Antoine},
    journal={IEEE Transactions on Evolutionary Computation}, 
    title={Unsupervised Behavior Discovery With Quality-Diversity Optimization}, 
    year={2022},
    volume={26},
    number={6},
    pages={1539-1552},
    keywords={Containers;Robots;Magnetosphere;Ion radiation effects;Robot sensing systems;Task analysis;Optimization;Behavioral diversity;optimization methods;quality-diversity (QD) optimization;robotics;unsupervised learning},
    doi={10.1109/TEVC.2022.3159855},
}

@inproceedings{cqd,
    address = {Massachusetts, Boston},
    title = {A discretization-free metric for assessing quality diversity algorithms},
    isbn = {978-1-4503-9268-6},
    url = {https://doi.org/10.1145/3520304.3534018},
    doi = {10.1145/3520304.3534018},
    language = {en-GB},
    urldate = {2025-01-29},
    booktitle = {{GECCO} '22: {Proceedings} of the {Genetic} and {Evolutionary} {Computation} {Conference} {Companion}},
    publisher = {ACM},
    author = {Kent, Paul and Branke, Juergen and Gaier, Adam and Mouret, Jean-Baptiste},
    month = jul,
    year = {2022},
    pages = {2131--2135},
}

@inproceedings{vassiliades_ComparisonIlluminationAlgorithms_2017,
	address = {Berlin Germany},
	title = {A comparison of illumination algorithms in unbounded spaces},
	isbn = {978-1-4503-4939-0},
	url = {https://dl.acm.org/doi/10.1145/3067695.3082531},
	doi = {10.1145/3067695.3082531},
	abstract = {Illumination algorithms are a new class of evolutionary algorithms capable of producing large archives of diverse and high-performing solutions. Examples of such algorithms include Novelty Search with Local Competition (NSLC), the Multi-dimensional Archive of Phenotypic Elites (MAP-Elites) and the newly introduced Centroidal Voronoi Tessellation (CVT) MAP-Elites. While NSLC can be used in unbounded behavioral spaces, MAP-Elites and CVTMAP-Elites require the user to manually specify the bounds. In this study, we introduce variants of these algorithms that expand their bounds based on the discovered solutions. In addition, we introduce a novel algorithm called “Cluster-Elites” that can adapt its bounds to non-convex spaces. We compare all algorithms in a maze navigation problem and illustrate that Cluster-Elites and the expansive variants of MAP-Elites and CVT-MAP-Elites have comparable or be er performance than NSLC, MAP-Elites and CVT-MAP-Elites.},
	language = {en},
	urldate = {2025-01-09},
	booktitle = {Proceedings of the {Genetic} and {Evolutionary} {Computation} {Conference} {Companion}},
	publisher = {ACM},
	author = {Vassiliades, Vassilis and Chatzilygeroudis, Konstantinos and Mouret, Jean-Baptiste},
	month = jul,
	year = {2017},
	pages = {1578--1581},
}

@misc{dns,
    title = {Dominated Novelty Search: Rethinking Local Competition in Quality-Diversity},
    publisher = {arXiv},
    author = {Bahlous-Boldi, Ryan and Faldor, Maxence and Grillotti, Luca and Janmohamed, Hannah and Coiffard, Lisa and Spector, Lee and Cully, Antoine},
    year = {2024},
}
