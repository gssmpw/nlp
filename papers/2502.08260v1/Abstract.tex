\begin{abstract}
Autonomous Vehicles (AVs) are advancing rapidly, with Level-4 AVs already operating in real-world conditions.
Current AVs, however, still lag behind human drivers in adaptability and performance, often exhibiting overly conservative behaviours and occasionally violating traffic laws.
Existing solutions, such as runtime enforcement, mitigate this by automatically repairing the AV's planned trajectory at runtime, but such approaches lack transparency and should be a measure of last resort.
It would be preferable for AV repairs to generalise beyond specific incidents and to be interpretable for users.
In this work, we propose \coolname, a framework that analyses driving records from near-misses or law violations to generate AV driving strategy repairs that reduce the chance of such incidents occurring again.
These repairs are captured in $\mu$Drive, a high-level domain-specific language for specifying driving behaviours in response to event-based triggers.
Implemented for the state-of-the-art autonomous driving system Apollo, \coolname identifies and visualises critical moments from driving records, then uses a Multimodal Large Language Model~(MLLM) with zero-shot learning to generate $\mu$Drive programs.
We tested \coolname on various benchmark scenarios, and found that the generated repairs improved the AV's performance with respect to following traffic laws, avoiding collisions, and successfully reaching destinations.
Furthermore, the direct costs of repairing an AV---15 minutes of offline analysis and \$0.08 per violation---are reasonable in practice.

\end{abstract}

\begin{IEEEkeywords}
autonomous vehicles, autonomous driving systems, multimodal large language models, driving compliance
\end{IEEEkeywords}