\section{Background and Problem}
\label{sec:overview_and_background}
In this section, we review the architecture of ADSs, DSLs for specifying safety properties and specifying high-level driving behaviours, the current capabilities of MLLMs, and then formally define our problem.

\subsection{Overview of ADSs}
State-of-the-art open-source ADSs such as Apollo~\cite{apollo90} and Autoware~\cite{autoware} share similar architectures. These systems are typically organised into loosely-coupled modules that communicate via message-passing. Three of these modules are particularly relevant in our context: perception, motion planning, and control.

The perception module receives sensor readings (e.g.~from cameras or LiDAR), processes them, and publishes the resulting data to the motion planning module. The motion planning module then classifies the current driving scenario into categories such as \emph{lane follow}, \emph{borrow lane}, and \emph{traffic light handling}. Each scenario has distinct processing logic and key parameters. For example, the \emph{emergency pull-over} scenario involves two key parameters: \emph{Expected\_speed} and \emph{Stopping\_distance}. During an emergency pull over, the vehicle is expected to rapidly decrease to the \emph{Expected\_speed} and then proceed to pull over, with the \emph{Stopping\_distance} indicating how far the vehicle should travel before coming to a complete stop. For more detailed information on how these key parameters work, we refer the reader to~\cite{apollo90, autoware}.

For each scenario, the motion planning module generates a corresponding \emph{planned trajectory} based on the map, destination, sensor inputs, and the state of the \emph{ego vehicle} (i.e.~the vehicle under ADS control). This planned trajectory outlines the vehicle's future positions at various time points, taking into account the predicted environment, which includes factors such as the anticipated movements of other vehicles (NPCs), pedestrians, and traffic light states.
Finally, the control module translates the planned trajectory into control commands (e.g.~braking, acceleration, steering, and signaling) so that the ego vehicle follows the planned trajectory, passing through the waypoints with the desired speed, acceleration, steering angle, and gear position. 

\begin{figure}[t]
    \centering\footnotesize
    \begin{align*}
    \phi\;:=&\;\mu \;
     |\;\neg\phi\;
     |\;\phi_1 \lor \phi_2\;|\; \phi_1 \land \phi_2\;|\; \phi_1 \;\mathtt{U}_I\; \phi_2\;\\
    \mu\;:=&\;f(x_0,x_1,\cdots, x_k) \sim 0 \ \ \sim \;:= > \;| \geq\;| <\;| \leq\;| \neq\;| =;
    \end{align*}
    \captionsetup{skip=0pt}
    \caption{Specification language syntax, where $\phi$, $\phi_1$ and $\phi_2$ are STL formulas, $I$ is an interval, and $f$ is a multivariate linear continuous function over language variables $x_i$}
    \label{syntax}\vspace{-10pt}
\end{figure}


\subsection{Specifying Safety Properties}
\label{sec:Specification definition}
In the context of AVs, safety should not simply mean the absence of collisions, but also adherence to the rules of the road that drivers are supposed to abide by.
To that end, we adopt the property specification language used by LawBreaker~\cite{Sun-Poskitt-et_al22a}, as well as the project's existing specifications of the traffic laws of China and Singapore.
The specification language is based on Signal Temporal Logic~(STL), and is evaluated with respect to traces of scenes, providing a way to automatically determine whether a tester-defined property was violated or not in a simulated run of the ADS.
We highlight the key features of the specification language below (the full syntax and semantics is given in~\cite{Sun-Poskitt-et_al22a}).


The high-level syntax of the language is shown in Figure~\ref{syntax}.
A time interval $I$ is of the form $[l,u]$, where $l$ and $u$ are respectively the lower and upper bounds of the interval. 
Following convention, we write $\Diamond_I \; \phi$ to denote $true \; \mathtt{U}_I \; \phi$; and $\Box_I \; \phi$ to denote $\neg \; \Diamond_I \; \neg \phi$. Intuitively, $\mathtt{U}$, $\Box$, and $\Diamond$ are modal operators that are respectively interpreted as `until', `always', and `eventually'.
We omit the time interval when it is $[0, \infty]$.



In general, $\mu$ can be regarded as a proposition of the form $f(x_0,x_1,   \cdots, x_k) \sim 0$, where $f$ is a multivariate function and $x_i$ for all $i$ in $[0,k]$ is a variable supported in the language.
\begin{example}
    Suppose we have a signal variable $speed = \langle speed(0),   speed(1), \dots, speed(n) \rangle$, which represents the autonomous vehicle's speed throughout its journey.
    % \todo{Formula overhangs into the margin} 
    Then, we can create a simple Boolean Expression $\mu = speed(t) < 60$ to test whether the speed of the vehicle is larger than $60km/h$. 
    Note that $\mu$ can be regarded as a proposition of the form $60 - speed(t) > 0$ or $speed(t) - 60 < 0$.
    To verify whether $\mu$ holds true at all time steps, we can use the temporal logic symbol `always', resulting in the formula $\varphi = \Box (speed < 60)$.
\end{example}


A specification is evaluated with respect to a trace $\pi$ of \emph{scenes}, denoted as $\pi=\langle \pi_0, \pi_1, \pi_2 \ldots, \pi_n \rangle$, where each scene $\pi_i$ is a valuation of the propositions at time step $i$, and $\pi_0$ reflects the state at the start of a simulation.
The language follows the standard semantics of STL (see e.g.~\cite{maler2004monitoring}).






\begin{figure}[t]
\begin{center}
\renewcommand{\arraystretch}{1.2}\footnotesize
\begin{tabular}{lcl}
program & ::= & \{rule\}+~ \\
rule & ::= &  '$\mathtt{rule}$' string\_literal \\
  && '$\mathtt{trigger}$' event\_trigger \\
  && ['$\mathtt{condition}$' \{['$\mathtt{!}$'] condition\}+] \\
  && '$\mathtt{then}$' \{action\}+~ \\
  && ['$\mathtt{until}$' event\_trigger] \\
  && '$\mathtt{end}$' \\
event\_trigger & ::= & event $\mid$ '$\mathtt{always}$' \\
\end{tabular}
\end{center}
\vspace{-0.2cm}
	\caption{Abstract syntax of $\mu$Drive programs}
	\label{fig:abstract_syntax}
 \vspace{-0.5cm}
\end{figure}

\subsection{Specifying Driving Behaviours}
\label{sec:udrive grammar}
The default output of a large language model (LLM) is natural language, which can be vague and challenging to utilise. To obtain specific and actionable behaviours for AVs, we need a robust method to ensure that the output of the LLM is always valid and directly applicable to AVs.
To achieve this, we utilise the high-level DSL $\mu$Drive~\cite{wang2024mudrive}, which allows driving behaviours to be specified in simple rules that are triggered by contextual events (e.g.~approaching a traffic light). 

The abstract syntax of $\mu$Drive in EBNF format is shown in Figure~\ref{fig:abstract_syntax}.
A $\mu$Drive program contains one or more rules, each consisting of up to five parts: 
1) a \emph{name} or description expressed as a string;
2) a \emph{trigger}, which is an event that causes the rule to be applied;
3) zero or more \emph{conditions}, which constrain the application of the rule;
4) one or more \emph{actions}, which are assignments of driving-related variables that are applied for the duration of the rule;
5) at most one \emph{exit trigger}, which is an event that ends the application of the rule.

\begin{figure}[t]
\begin{minted}[fontsize=\scriptsize,frame=single,obeytabs=true,tabsize=4,numbersep=-10pt,escapeinside=||]{yaml}
|\textbf{\textcolor{green!50!black}{rule}}| |\textcolor{red!70!black}{"Drive slowly through a junction when there is }
\textcolor{red!70!black}{an obstacle."}|
|\textbf{\textcolor{green!50!black}{trigger}}| 
    entering_junction 
|\textbf{\textcolor{green!50!black}{condition}}| 
    obstacle_distance_leq(20)
    is_traffic_light(green)
|\textbf{\textcolor{green!50!black}{then}}|
    cruise_speed(30)
|\textbf{\textcolor{green!50!black}{until}}|
    exiting_junction
|\textbf{\textcolor{green!50!black}{end}}|
    \end{minted}
  \caption{\textsc{$\mu$Drive} driving strategy repair example}
  \label{lst:example}
  \vspace{-0.5cm}
\end{figure}


Intuitively, events represent states monitored by $\mu$Drive as the AV drives through its environment. For example, the events $\mathtt{entering\_junction}$ and $\mathtt{exiting\_junction}$ are set to \texttt{True} when the AV is entering or exiting a junction, respectively.
Conditions specify what must be true of the current environment to allow the rule to be applied. For example, the conditions $\mathtt{is\_traffic\_light(green)}$ and $\mathtt{obstacle\_distance\_leq(20)}$ indicate that the rule can take effect only when the traffic light ahead is green and the AV is within 20 metres of an obstacle.
Actions are tasks executed throughout the duration of a rule application. For example, the action $\mathtt{cruise\_speed(30)}$ sets the default planning speed of the AV to 30 km/h.
An overall example of a $\mu$Drive program is shown in Figure~\ref{lst:example}. This program indicates that within a junction, if an obstacle is detected within 20 metres and the traffic light ahead is green, the default planning speed of the AV should be set to 30 km/h.
For a detailed introduction to the grammar of $\mu$Drive, we refer readers to \cite{wang2024mudrive}.

\subsection{Multimodal Large Language Models (MLLMs)}
MLLMs integrate and process multiple types of data, including text, images, audio, and video. These models utilise the capabilities of large-scale neural networks to comprehend and generate content across different modalities, thereby offering more comprehensive and versatile AI functionalities.
State-of-the-art MLLMs, such as OpenAI's GPT-4~\cite{openaichatgpt} and Google's PaLM-E~\cite{driess2023palm}, exemplify the advancements in this field. GPT-4, for instance, can process textual inputs while simultaneously understanding and interpreting images, enabling it to describe images, answer related questions, and seamlessly integrate visual information with textual content. Similarly, PaLM-E, a large multimodal embodied language model, integrates textual and visual data to enhance its ability to comprehend and interact with the physical environment.

These models are trained on extensive datasets that encompass diverse forms of media, which allows them to acquire a vast amount of general knowledge. This training enables MLLMs to perform a wide variety of tasks, such as generating detailed image captions, providing contextually aware responses, and enhancing search engines with improved understanding of visual queries.
The multimodal approach significantly enhances the model's utility, making it capable of tasks beyond the scope of single-modality models. By integrating multiple types of data, MLLMs are advancing the frontier of AI, creating more intuitive and intelligent systems that better mimic human cognition and understanding.

\subsection{The Problem}
Assuming the availability of a powerful MLLM, such as ChatGPT, with the capability to comprehend driving conditions and provide appropriate suggestions, the challenge lies in efficiently leveraging this MLLM to analyse records of AV violations and generate driving strategy repairs in $\mu$Drive that would prevent such violations occurring again in the future.
We formulate our problem as follows:


\begin{definition}[Problem Definition]
\label{def:problem_def}
    Given an MLLM, a record $\alpha$ of the AV in a scenario, and a property specification of ADS behaviour $\varphi$, suppose that $\alpha \nvDash \varphi$.
    The objective is to utilise the MLLM to generate $\mu$Drive programs based on the combination of $\alpha$ and $\varphi$. 
    Let $\alpha'$ denote the resulting record of the AV by replaying the same scenario with the $\mu$Drive programs generated by the MLLM applied.
    The goal is to increase the likelihood of $\alpha' \vDash \varphi$.
\end{definition}



Intuitively, when a scenario is identified in which the AV violates specified properties, we provide relevant information in the prompt to the MLLM to enable it to understand the current situation. The MLLM then offers suggestions in the form of a $\mu$Drive program to help ensure such a violation does not occur again. To maintain minimal and interpretable additional control logic, the $\mu$Drive programs should be kept as small as possible.
This context highlights two critical requirements for our approach:
1) develop a method to automatically provide accurate and relevant information to the MLLM;
2) ensure that the MLLM's suggestions are translated into valid and effective $\mu$Drive programs.



