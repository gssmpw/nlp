\section{Introduction}
%AVs are good, but not as good as human drivers
Autonomous Vehicles (AVs) are currently undergoing rapid and promising development. Notably, several Level-4 AVs, which do not require driver intervention, have been successfully deployed in real-world traffic scenarios~\cite{sae2018taxonomy}. Prominent examples include Google Waymo~\cite{waymo}, Baidu Apollo~\cite{apolloauto}, and TuSimple~\cite{TuSimple}. These AVs are capable of performing critical tasks such as perception, trajectory planning, and actuation control. However, despite these advancements, AVs are far from perfect and still lag significantly behind human drivers in terms of performance and adaptability. 
For instance, AVs sometimes exhibit overly conservative driving behaviour, which can lead to situations where they become stuck on the road~\cite{wan2022too}. 
Furthermore, Autonomous Driving Systems~(ADSs)---the `brains' of AVs, responsible for perception, decision-making, and control---can also be overly aggressive and cause accidents under specific conditions~\cite{Bashetty20DeepCrashTest, li2020av, Sun-Poskitt-et_al22a, Zhou-et_al23a}.  Such behaviours are often easily recognisable and avoidable by human drivers, underscoring the need for significant improvements before AVs can match or surpass human driving capabilities.



Existing work offers two categories of solutions to address these problems. The first category uses rule-based runtime enforcement to correct problematic behaviour directly~\cite{sun2024redriver, Grieser-et_al20a, hong2020avguardian, Cheng-et_al21a, Shankar-et_al20a, Mauritz-et_al16a, d2005lola, Watanabe-et_al18a}. For example, when an ADS encounters potential violations of specific property specifications (e.g.~traffic laws), one proposed solution, outlined in REDriver~\cite{sun2024redriver}, uses a gradient-based algorithm to modify the AV's planned trajectory. 
However, these repairs are limited in scope and lack transparency, since they are very low-level and difficult for users to interpret.
Furthermore, they are meant to be a measure of last resort rather than a general correction to driving strategies.



The second category involves learning-based methods, which train ADSs to behave like human drivers using real driving data. These approaches focus on exploring and summarising human driver behaviour patterns to guide the driving modes of ADSs~\cite{chen2023end, prakash2021multi}, such as imitation learning to replicate expert behaviour and train the ADS to drive in a human-like manner~\cite{sama2020extracting, wei2010learning, xu2015establishing, xu2020learning, le2022survey}. However, these approaches often fall short due to the difficulty of capturing the nuanced decision-making processes of human drivers from limited data, leading to poor generalisation or overfitting to specific tasks. Consequently, there is a need for an AV driving strategy repair approach that generalises beyond specific incidents and is interpretable for users.


Multimodal Large Language Models (MLLMs) appear to be intelligent and ideally suited for improving ADSs due to their advanced text and image understanding and reasoning capabilities~\cite{brown2020language, achiam2023gpt, yin2023survey}. Trained on massive datasets, MLLMs can interpret and replicate human driving behaviour, thereby making ADS decisions more explainable~\cite{cui2024survey}.
Existing works (e.g.~\cite{chen2023driving, mao2023gpt, wen2024road}) explore utilising MLLMs to replace parts of the ADS, such as perception, planning, and control, thereby making the decision-making logic more understandable. For example, GPT-Driver~\cite{mao2023gpt} abstracts the perception and prediction results of the ADS into language tokens, then uses OpenAI GPT 3.5 to directly produce the planned trajectory along with explanations.
However, the inherent latencies and uncertainty associated with generative models make it impractical to build an ADS based solely on online MLLMs.
Additionally, there is a significant gap between natural language and the actual control commands for autonomous vehicles, making it challenging to directly apply MLLM-generated solutions to real-world driving tasks.
Currently, there are no practical approaches that leverage MLLMs in a manner that is both offline and compatible with existing ADS frameworks such as Apollo~\cite{apolloauto} and Autoware~\cite{autoware}.




\begin{figure}
    \centering
    \includegraphics[width=\linewidth, trim={5cm 6cm 5cm 5cm}, clip]{workflow.pdf}
    \vspace{-0.4cm}
    \caption{Overview of \coolname}
    \label{fig:overflow}
    \vspace{-0.6cm}
\end{figure}

In this work, we propose \coolname, a method that analyses records (i.e.~comprehensive log files) from bad driving behaviours such as collisions, near misses, or law violations, then generates general AV driving strategy repairs to reduce the chance of such incidents occurring again.
Rather than modifying code~\cite{LeGouesDFW12} or applying opaque low-level fixes~\cite{sun2024redriver}, \coolname produces repairs in $\mu$Drive~\cite{wang2024mudrive}, a high-level Domain-Specific Language~(DSL) for specifying the driving behaviours that should occur upon certain triggers (e.g.~approaching a traffic light).
\coolname identifies and visualises critical moments from incident records, then utilises an MLLM with zero-shot learning to generate $\mu$Drive programs that repair the driving strategy.
This translation is executed offline and once per violation, allowing our approach to leverage the reasoning capabilities of MLLMs while mitigating their latency issues.
Additionally, by generating repairs in a high-level DSL, they are more interpretable compared to those of low-level gradient-based approaches like REDriver~\cite{sun2024redriver}.
Note that we categorise methods as either offline or online based on how they interact with runtime driving decisions. For example, an MLLM that generates real-time driving decisions based on the current driving context is classified as an online method. Conversely, \coolname is an offline framework, enhancing the ADS through repair scripts generated \emph{before} further runs.



An overview of \coolname is shown in Figure~\ref{fig:overflow}.
Users need only provide records from executed driving scenarios and the corresponding property specifications (e.g.~traffic laws, collision avoidance) that were violated.
\coolname automatically identifies two critical moments from the records (the `near miss' and the `violation' moments), visualises them for a multimodal prompt, then utilises a state-of-the-art MLLM (OpenAI GPT 4~\cite{openaichatgpt}) to generate driving strategy repair scripts in the $\mu$Drive~\cite{wang2024mudrive} DSL.
Additionally, OpenAI's function calling~\cite{gpt_function_calling} is used to ensure that the MLLM generates syntactically valid $\mu$Drive programs, which are specified via a JSON Schema.
The resulting program is then applied to the Apollo ADS~\cite{apollo90}, dynamically adjusting the parameter settings of the planning module to repair its driving strategy at runtime.


We evaluated \coolname on a set of benchmark scenarios in which the ADS violated various property specifications, such as different traffic laws, collision avoidance, and successful journey completion. \coolname provided effective general driving strategy repairs that helped the ADS successfully navigate these problematic scenarios without adversely affecting performance in normal scenarios. Additionally, \coolname consistently generated effective AV driving strategy repairs with practically reasonable direct costs, i.e.~less than 15 minutes (and typically around 10 minutes) of offline analysis and \$0.08 per violation.
