%\documentclass[10pt,journal,letterpaper,twosides,twocolumns]{IEEEtran}
% \documentclass{article}
\documentclass[review]{elsarticle}
\usepackage{geometry}
\geometry{
	a4paper,
	left=33mm,
	right=33mm,
}

\newcommand*{\ARXIV}{}%  % when uncommented it uses the *.bbl file

\usepackage{comment}
\newcommand{\CFiles}{Common.Files}
\newcommand{\CFilesBib}{Common.Files.Bib}
%\newcommand{\CFiles}{/Users/leszek/Dropbox/Common.Files}
%\newcommand{\CFilesBib}{/Users/leszek/Dropbox/Common.Files.Bib}

\input{\CFiles/included_packages.tex}
\input{\CFiles/commands.tex}

%%%%  T I K Z definitions
\pgfplotsset{compat=1.12}
\usetikzlibrary{positioning,shadows,shapes,fit,arrows,backgrounds}
\input{\CFiles/tikz.definitions.tex}
%%%%

\newcommand{\siz}{0.9}  %%%%% taille des figures 0.85 two columns, 1.2 one column
\newcommand{\sizf}{0.8}
\newcommand{\sizfs}{0.65}   %%%%% taille des figures 1 two columns, 0.65 one column
\newcommand{\sizfb}{0.6} 

%%------------------------------------
%%-- To be commented in the final version
%%\usepackage[colorlinks=true,linkcolor=blue]{hyperref}%
%\usepackage[color,notcite,notref]{showkeys}%
%\renewcommand{\showkeyslabelformat}[1]{\fbox{\normalfont\tiny\ttfamily#1}}%
%\definecolor{refkey}{rgb}{0.2,0.8,0.6}% change the colors
%\definecolor{labelkey}{rgb}{0.2,0.3,0.4}%
%%------------------------------------

%-------------
%-- glossaries
\usepackage[acronym,nonumberlist]{glossaries} % make a separate list of acronyms
\usepackage{hyperref}
\usepackage{empheq}
\usepackage{verbatim}
\usepackage{graphicx}
\usepackage{enumitem}
\usepackage[title]{appendix}  %
\input{\CFiles/acronyms.tex}

\renewcommand*{\glspostdescription}{}% To void the period
\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}
\newtheorem{definition}{Definition}
\newtheorem{proposition}{Proposition}
\newtheorem{lemma}{Lemma}
\newtheorem{conjecture}{Conjecture}
\newtheorem{example}{Example}


\begin{document}

\title{A Unified Bayesian Perspective for\\
Conventional and Robust Adaptive Filters}

\author[1]{Leszek~Szczecinski\corref{cor1}}
\ead{leszek.szczecinski@inrs.ca}

\author[1]{Jacob~Benesty}
\ead{jacob.benesty@inrs.ca}

\author[2]{Eduardo~Vinicius~Kuhn}
\ead{kuhn@utfpr.edu.br}

\cortext[cor1]{Corresponding author.}

\address[1]{INRS–Institut National de la Recherche  Scientific, Montreal, QC, H5A-1K6, Canada.}
\address[2]{LAPSE–Electronics and Signal Processing Laboratory, Department of Electronics Engineering, Federal University of Technology - Paran\'a, Toledo, Paran\'a, 85902-490, Brazil.}
% \author{Leszek Szczecinski, Eduardo Kuhn, and Jacob Benesty}


\begin{abstract}
    In this work, we present a new perspective on the origin and interpretation of adaptive filters. By applying Bayesian principles of recursive inference from the state-space model and using a series of simplifications regarding the structure of the solution, we can present, in a unified framework, derivations of many adaptive filters which depend on the probabilistic model of the observational noise. In particular, under a Gaussian model, we obtain solutions well-known in the literature (such as LMS, NLMS, or Kalman filter), while using non-Gaussian noise, we obtain new families of adaptive filter. Notably, under assumption of Laplacian noise, we obtain a family of robust filters of which the signed-error algorithm is a well-known member, while other algorithms, derived effortlessly in the proposed framework, are entirely new. Numerical examples are shown to illustrate the properties and provide a better insight into the performance of the derived adaptive filters. 
\end{abstract}

\begin{keyword}
Adaptive filters\sep
Robust adaptive filters\sep
LMS\sep
NLMS\sep
Kalman filter\sep
Bayesian inference
\end{keyword}

\maketitle

\section{Introduction}\label{Sec:Introduction}

In this work, we propose a Bayesian perspective which can be used to explain the origins and properties of the conventional and robust adaptive filters, which are arguably among the most important tools in the area of signal processing with countless applications such as system identification \cite{Dogariu21}, equalization \cite[Ch.~5.4]{Sayed08_Book},  antenna processing \cite[Ch.~6.5]{Sayed08_Book}, and many others.

The Bayesian formulation was often used in the estimation literature \eg in \cite{Szczecinski21} \cite{Lange24}, and is also not new in signal processing applications; \eg the well-known Kalman filter can be derived from Bayesian principles \cite[Ch.~13.2]{Moon00_Book}. On the other hand, we are not aware of a Bayesian framework in which most popular adaptive filters are deduced from the common first principles. 

Our work fills this gap: using the well-known state-space model, we show the framework in which adaptive algorithms with a varying degree of complexity can be derived in a well-defined and systematic way. In particular, for a Gaussian state-space model, the well-known adaptive filters such as least-mean-square (LMS), normalized LMS (NLMS), and others can be derived as particular cases of \gls{kf}.

Such a perspective not only has a unifying and educational value, allowing us to see all adaptive algorithms in a common framework, but it also leads to a meaningful interpretation of their parameters (such as adaptation step and/or regularization coefficient) in terms of the statistical quantities (such as variances of the estimates).

More importantly, however, the common framework we propose allows us to derive new adaptive algorithms suited to deal with non-Gaussian models. In particular, we are interested in robust filters to deal with frequent outliers. Indeed, using the generalized Gaussian distribution of the observational noise in the state-space model, we derive an entire class of new robust adaptive algorithms, which generalize those already known in the literature. 

By specializing the proposed algorithms to Laplacian noise (which is a particular case of a generalized Gaussian distribution), we derive algorithms which are natural generalizations of the signed-error LMS algorithm, which is a well-known adaptive filter commonly used to deal well with outliers.

In the non-Gaussian formulation, the problems we deal with have no closed-form solutions, and thus the filtering equations are approximate. However, they can be enhanced by iterative operations, which is an intriguing and rarely used approach in signal processing, which, as we show, can improve the performance of adaptive filtering.

The algorithms are tested using synthetic data with numerical results validating the derivations, where the performance deteriorates when we increase the number of simplifying assumptions. The performance is notably improved by the new robust adaptive filters in the presence of non-Gaussian noise.


%%%%%%%%%%%%%%%%%%%%%%%%
\section{Approximate Bayesian inference in state-space models}\label{Sec:Bayesian.inference}

Consider the following state-space model:
\begin{align}
\label{state.equation.general}
        \btheta_{t} &=\btheta_{t-1} + \bxi_t,\\
\label{output.equation.general}
    y_t &= \bx_t\T\btheta_t + \eta_t ,
\end{align}
where $\btheta_t\in\Real^M$ is the random vector-state at time $t=1,2,\ld$, $y_t\in\Real$ -- the observation at time $t$, $\eta_t$, is the observational noise modeled as a zero-mean, random variable with distribution $\pdf(\eta_t)$, and $\bxi_t\in\Real^M$, $t=1,2,\ld$ are independent zero-mean Gaussian vectors composed of independent elements: 
\begin{align}
\label{pdf(u_t)}
    \pdf(\bxi_t) &= \mcN(\bxi_t; \bzero, \varepsilon_t \matI),
\end{align}
where $\mcN(\bu;\bw,\matV)$ is the Normal \gls{pdf} in $\bu$ with the mean $\bw$ and covariance matrix $\matV$. For simplicity of notation, we use $\varepsilon_t=\varepsilon$. Moreover, we assume the unconditional prior distribution of the state $\btheta_0$ given by $\pdf(\btheta_0)$. 

Equations \eqref{state.equation.general}-\eqref{output.equation.general} are often used in a signal processing context, as it is common to assume that the output, $y_t$, is affected by a linear combination of the input $\bx_t$, and the state variables in $\btheta_t$. The Markov process \eqref{state.equation.general} is also often used to model the fact that the state variables, $\btheta_t$, $t=1,2,\ld$, may vary over time. %It is also convenient to express the idea that the changes in the estimates of $\btheta_t$ may be different in the early convergence stage (large $\varepsilon_t$ for small $t$) and after convergence, \ie during the tracking (small $\varepsilon_t$ for large $t$). 


Our objective is to obtain the posterior distribution of $\btheta_t$ from all available information at time $t$, \ie $y_{1:t}=\set{y_1,\ld, y_t}$, and it  can be calculated as \cite[Ch.~12]{Moon00_Book}
\begin{align}
    \pdf(\btheta_t| y_{1:t})
    &=
\pdf(\btheta_t|  y_{1:t-1}, y_t )
=
\frac{\pdf(y_t, \btheta_t, y_{1:t-1})}{\pdf(y_{1:t-1}, y_t )}\\
&\propto
\pdf(y_t|\btheta_t) \pdf(\btheta_t| y_{1:t-1}) ,
\end{align}
where
\begin{align}
\pdf(\btheta_t| y_{1:t-1})
% &=
% \pdf(y_t|\btheta_t) \int  \pdf(\btheta_t , \btheta_{t-1}|  y_{1:t-1} ) \dd \btheta_{t-1}\\
\label{theta.aposteriori.2}
&=
\int  
\pdf(\btheta_t|\btheta_{t-1})
\pdf(\btheta_{t-1}|  y_{1:t-1})
\dd \btheta_{t-1}.
\end{align}


From \eqref{state.equation.general} and \eqref{pdf(u_t)}, we easily obtain
\begin{align}
\label{pdf.theta.t.theta.t1}
    \pdf(\btheta_t | \btheta_{t-1}) = \mcN(\btheta_t;\btheta_{t-1},\varepsilon \matI),
\end{align}
and, from \eqref{output.equation.general}, we know that
\begin{align}
\label{pdf.y_t.generalized.linear}
    \pdf(y_t|\btheta_t) &\equiv \pdf_{\eta_t}(y_t-\bx_t\T\btheta_t).
\end{align}

In particular, if $\eta_t$ is a zero-mean Gaussian noise with variance $v_\eta$, \ie $\pdf(\eta_t) =\mcN(\eta_t;0,v_{\eta})$, \eqref{pdf.y_t.generalized.linear} is given by
\begin{align}
\label{y_t.Gaussian}
    \pdf(y_t|\btheta_t) &= \mcN(y_t-\bx_t\T\btheta_t; 0, v_\eta),
\end{align}
and if $\pdf(\btheta_0)$ is also Gaussian, all variables in the model are Gaussian, so \eqref{theta.aposteriori.2} can be obtained in closed-form producing the Kalman filter equations. However, in general, this is not possible, and approximations will be necessary.

Note that we abuse the notation, and the distributions $\pdf(\cd)$ and $\pdf(\cd|\cd)$ are identified by their arguments. Only when it might lead to confusion, we are specific, \eg as in \eqref{pdf.y_t.generalized.linear}, where $\pdf_{\eta_t}(e)$ denotes the \gls{pdf} of $\eta_t$ evaluated for $\eta_t=e$.


%%%%%%%
\subsection{Gaussian approximations}\label{Sec:Gaussian.approximation}
The simplest approach is to approximate the terms in \eqref{theta.aposteriori.2} using Gaussian distributions (denoted by tilde), \ie
\begin{align}
    \pdf(\btheta_t|y_{1:t})&\approx\tilde\pdf(\btheta_t|y_{1:t})=\mcN(\btheta_t;\bw_t,\matV_t) ,
\end{align}
as then we can easily calculate \eqref{pdf.theta.t.theta.t1} as follows:
\begin{align}
\label{integral.theta_t_1}
    \tilde\pdf(\btheta_t|y_{1:t-1})
    &=\int  \pdf(\btheta_{t}|\btheta_{t-1})\tilde{\pdf}(\btheta_{t-1}|  y_{1:t-1}) \dd \btheta_{t-1}\\
\label{theta.t_1.is.Gaussian}
    &=
\mcN(  \btheta_{t} ; \bw_{t-1} , \ov{\matV}_t  ),
\end{align}
where
\begin{align}
\label{ov.matV}
    \ov{\matV}_t = \matV_{t-1} +\varepsilon \matI.
\end{align}

Then, we can use \eqref{integral.theta_t_1} to approximate  \eqref{theta.aposteriori.2}:
\begin{align}
\label{Projection}
    \tilde \pdf(\btheta_{t}|  y_{1:t}) 
&=
\mfP\big[\phi(\btheta_t|y_{1:t}) \big]=\mcN(\btheta_t; \bw_t, \matV_t),\\
\label{phi(theta_t)}
\phi(\btheta_t|y_{1:t})
&=\pdf(y_t|\btheta_t)
\tilde\pdf(\btheta_{t}|y_{1:t-1}) ,
%     \mcN(\btheta_t; \bw_t,\matV_t)
% &=
% \mfP\left[\pdf(y_t|\btheta_t)
% \int  \pdf(\btheta_{t}|\btheta_{t-1})\mcN(\btheta_{t-1}; \bw_{t-1},\matV_{t-1}) \dd \btheta_{t-1}\right]
\end{align}
where 
$\mfP\big[\phi(\btheta_t|y_{1:t})\big]$ is an operator ``projecting" a distribution $\phi(\btheta_t|y_{1:t})$ into the space of the Gaussian distributions, which boils down to finding the mean $\bw_t$ and covariance $\matV_t$. We assume that, when necessary, the argument $\phi(\btheta_t|y_{1:t})$ may be always normalized to become a true distribution, \ie $\phi(\btheta_t|y_{1:t})\leftarrow \phi(\btheta_t|y_{1:t})/\int \phi(\btheta_t|y_{1:t})\dd\btheta_t$. Note that $\phi(\btheta_t|y_{1:t})$ (the distribution before projection) already contains approximations due to the use of $\tilde\pdf(\btheta_t|y_{1:t-1})$. However, it is not Gaussian because, in general, $\pdf(y_t|\btheta_t)$ is not Gaussian.

To define the projection operator $\mfP[\cd]$, we might find the Gaussian \gls{pdf} which minimizes the \gls{kl} divergence with $\phi(\btheta_t|y_{1:t})$, in which case we obtain
\begin{align}
\label{KL.mean}
    \bw_t & = \Ex[\btheta_t] , \\
\label{KL.variance}
    \matV_t &= \Ex[\btheta_t\btheta_t\T]-  \bw_t\bw_t\T,
\end{align}
where the expectation is calculated with respect to the distribution $\phi(\btheta_t|y_{1:t})$ being projected. The latter requires integration (over the $M$-dimensional space of $\btheta_t$), which is impractical. 

Thus, searching for simpler solutions, we approximate the mean with the mode of the distribution and the variance -- with the inverted Hessian of its logarithm, \ie
\begin{align}
%    \mfP[f(\btheta_t)] &= \mcN(\btheta_t; \bw_t, \matV_t)\\
\label{mu_t.from.max}
    \bw_t & = \argmax_{\btheta_t} \log \phi(\btheta_t|y_{1:t}) , \\
\label{V_t.from.Hessian}
    \matV_t & = [-\nabla_{\btheta_t}^2 \log \phi(\btheta_t|y_{1:t})\big|_{\btheta_t=\bw_t}]^{-1} ,
\end{align}
and, of course, if $\phi(\btheta_t|y_{1:t})$ was Gaussian, \eqref{mu_t.from.max}-\eqref{V_t.from.Hessian} would be equivalent to \eqref{KL.mean}-\eqref{KL.variance}.

%%%%%%%%%%
\subsection{Approximate Kalman filter}\label{Sec:Approximate.Kalman}


The projection \eqref{Projection} requires solving the problem \eqref{mu_t.from.max}:
\begin{align}
\label{w_t=argmax}
    \bw_t &= \argmax_{\btheta}
    \Big\{ \ell(y_t-\bx_t\T\btheta) +\log \tilde\pdf_{\btheta_t}(\btheta|y_{1:t-1})\Big\} ,
    % \\
    % &=\arg_{\btheta}
    % \left\{\nabla_{\btheta} \big[\ell(y_t-\bx_t\T\btheta)] -\ov{\matV}_{t}^{-1} (\btheta-\bw_{t-1})
    %  =0\right\}
\end{align}
where
\begin{align}
\label{ell.definition}
    \ell(e)&=\log \pdf_{\eta_t}(e).
\end{align}

Since $\tilde\pdf(\btheta_t|y_{1:t-1})$ is Gaussian, $\log\tilde\pdf(\btheta_t|y_{1:t-1})$ is quadratic in $\btheta_t$, so \eqref{w_t=argmax} can be solved in closed form if we approximate $\ell(e)$ by a concave and quadratic function of $e$, \ie if instead of \eqref{w_t=argmax}, we solve its approximate version:
\begin{align}
\label{w_t=argmax.approx}
    \bw_t &\approx \argmax_{\btheta_t}
    \Big\{q(y_t-\bx_t\T\btheta_t) +\log \tilde\pdf(\btheta_t|y_{1:t-1})\Big\} ,
\end{align}
where
\begin{align}
\label{ell(z).approx.quadratic}
    \ell(e)\approx q(e)= - \frac{1}{2}h_t e^2 + C_q ,
\end{align}
with $C_q$ being a constant, independent of $e$, 
and 
\begin{align}
    h_t = h(e_t) >0,
\end{align}
\ie the form of the approximation may depend on the approximation error $e_t$.

Note that we limit our attention to the case $q(e)=q(-e)$ because in most practically interesting cases the noise $\eta_t$ has a symmetric distribution, i.e., $\pdf_{\eta_t}(e)=\pdf_{\eta_t}(-e)$.

The approximation sign $\approx$ will be dropped in the following, and we will use it only when a new approximation is introduced.

Now, using \eqref{ell(z).approx.quadratic} and \eqref{theta.t_1.is.Gaussian} in \eqref{w_t=argmax.approx}, after simple algebra yields
\begin{align}
\label{ov.matV_t.Kalman.full}
    \ov{\matV}_t &= \matV_{t-1} +\varepsilon \matI,\\
\label{partial.Kalman.gain.full}
    \bkappa_t&=\ov{\matV}_t\bx_t,\\
\label{omega_t.definition}
    s_t &= \bx_t\T\bkappa_t,\\
% \label{Kalman.gain.full}
% \bk_t&=\ov{\matV}_t\bx_t\frac{h_t}{1+h_t s_t}\\
\label{e_t.definition}
    e_t&= y_t-\bx_t\T\bw_{t-1},    \\
\label{h.t.definition}
    h_t & = h(e_t),\\
\label{a_t.definition}
   \alpha_t & = \frac{h_t}{1+h_t s_t},\\
\label{w_t.update}
    \bw_{t}&=\bw_{t-1} + \bkappa_t\alpha_t e_t,\\
\label{V_t.update}
    \matV_{t}
    &=
    \ov{\matV}_t(\matI -\bx_{t}\bkappa_t\T\alpha_t),
\end{align}
where $e_t$ is the prediction error, $s_t$
is the second moment of the predictor $\bx_t\T\btheta_t$ calculated from the conditional distribution $\pdf(\btheta_t|y_{1:t-1})$, and the update of the covariance matrix in \eqref{V_t.update} is obtained from \eqref{V_t.from.Hessian} via matrix inversion lemma.

In the Gaussian case, \ie if $h_t=\frac{1}{v_\eta}$, \eqref{ov.matV_t.Kalman.full}--\eqref{V_t.update} becomes the well-known \gls{kf} estimation algorithm for the model \eqref{state.equation.general}--\eqref{output.equation.general}.
Here $\bkappa_t$ is the ``preliminary" Kalman gain vector, and $\alpha_t$ is the gain multiplier (so the actual Kalman gain is given by the product $\bkappa_t\alpha_t$). This separation will be conceptually useful in non-Gaussian case, which we treat in the following. 


To initialize the recursion \eqref{ov.matV_t.Kalman.full}-\eqref{V_t.update}, we can use, \eg $\bw_0=\bzero$, and $\matV_0=v_0\matI$, where $v_0$ -- the prior variance of elements of $\btheta_0$ is a parameter to be set.

\subsection{Differences with the conventional Kalman filter}
The presentation of the problem \eqref{w_t=argmax} points to two issues that do not appear in the conventional Kalman filter derived from the assumption that the noise $\eta_t$ is Gaussian.

First, we note that the quadratic approximation of $\ell(e_t)$ may be defined in many ways. Here we postulate to choose it so as to guarantee that the update step \eqref{w_t.update}, which solves \eqref{w_t=argmax.approx}, also increases the objective  function in \eqref{w_t=argmax}, \ie we want to guarantee that
\begin{align}
\nonumber
    \big[\ell(y_t-\bx_t\T\btheta_t)
    &+\log\tilde\pdf(\btheta_t|y_{1:t-1})\big]_{\btheta_t=\bw_t}\\
\label{increase.objecfive.condition}
    &>
    \big[\ell(y_t-\bx_t\T\btheta_t)+\log\tilde\pdf(\btheta_t|y_{1:t-1})\big]_{\btheta_t=\bw_{t-1}}.
\end{align}
This requirement is quite natural, as we expect the approximation not only to provide us with closed-form expressions but also to address meaningfully the maximization problem \eqref{w_t=argmax}, that is, at least we want the objective function under maximization to increase.

It is simple to show that, by applying minorization:
\begin{align}\label{minorization}
    q(e) &\le \ell(e), \quad e\neq e_t , \\    \label{minorization.equality}
    q(e_t)&= \ell(e_t) ,
\end{align}
we guarantee that \eqref{increase.objecfive.condition} is, indeed, satisfied. This approach is, of course, inspired by the minorization-maximization \cite{Hunter04a}, and the parameter $h_t$, for which \eqref{minorization}-\eqref{minorization.equality} are satisfied depends, in general, on $e_t$. The obvious exception occurs if $\eta_t$ is Gaussian with variance $v_{\eta}$, then $q(e_t)=\ell(e_t)=-\frac{e_t^2}{2v_{\eta}}$ and $h_t=\frac{1}{v_{\eta}}$.

The second issue is that the maximization in \eqref{w_t=argmax} is solved only approximately by \eqref{w_t.update} and may be improved by  invoking \eqref{e_t.definition}-\eqref{w_t.update} iteratively, as follows:
\begin{align}
\label{w_t.0}
\bw_{t,0}&=\bw_{t-1}\\
    \label{w_t.update.iterations}
&\begin{rcases}
    e_{t,i} = y_t - \bx_t\T\bw_{t,i}\\ 
    h_{t,i}=h(e_{t,i})\\
    \alpha_{t,i}=\displaystyle \frac{h_{t,i}}{1+h_{t,i} s_t}\\
    \bw_{t,i+1}=\bw_{t-1} + \bkappa_{t} \alpha_{t,i}e_{t,0}\\
\end{rcases} \quad i=0, \ld, I\\
\alpha_{t}&=\alpha_{t,I}\\
\label{w_t.I+1}
\bw_t&=\bw_{t,I+1},
\end{align}
where $\alpha_{t,i}$  is the gain multiplier updated iteratively.

For $I=0$, operations in \eqref{w_t.update.iterations} are equivalent to \eqref{w_t.update}. In other words, $I$ is the number of iterations executed beyond the one-step update \eqref{w_t.update} and, by the minorization form of $q(e_t)$, we have a guarantee that the function under maximization in \eqref{w_t=argmax} cannot decrease.

Note that the update of $\bw_{t,i+1}$ always depends on the initial approximation error $e_{t,0}$ and will change with $i$ only if the Kalman gain multiplier $\alpha_{t,i}$ (and, thus, the coefficient $h_{t,i}$) depends on $i$. Therefore, in the conventional Gaussian case, when $h_{t,i}\equiv h_t=\frac{1}{v_\eta}$, there is no point in using this iterative approach.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Simplifications for adaptive filtering}\label{Sec:Simplification.covariance}

We take one more step to come closer to the reality of adaptive filtering. Namely, we restrict the covariance $\matV_t$ produced via the projection $\mfP[\cd]$ in \eqref{Projection} as follows:
\begin{align}\label{V_t.constrained}
    \matV_t=
    \begin{cases}
        \tnr{diag}(\bv_t)&\tnr{vector-variance model}\\
        v_t\matI&\tnr{scalar-variance model}\\
        v\matI&\tnr{fixed-variance model}
    \end{cases},
\end{align}
which corresponds to adopting different models for $\btheta_t$:
in the vector-variance model, we assume that the parameters $\btheta_t$ are independent Gaussian variables, characterized by the means and variances kept, respectively, in $\bw_t$ and in $\bv_t$. In the scalar-variance model, we assume that the variance of each elements of $\btheta_t$ equals to $v_t$, while, in the fixed-variance model, the variance is also common to all elements of $\btheta_t$, but it does not change with the index $t$. 

\begin{lemma}\label{Lemma:1}
    If $\matV_t$ is obtained through \eqref{KL.variance}, the \gls{kl} divergence is minimized for
\begin{align}
\label{vec_t.from.diagonal}
    \bv_t = \tnr{di}(\matV_t),
\end{align}
where  $\tnr{di}(\matV)$ is the diagonal of $\matV$, 
while $v_t$ is obtained as the average of the diagonal elements in $\matV_{t}$, \ie
\begin{align}
\label{v_t.from.avarage}
    v_t = \frac{\tnr{Tr}(\matV_t)}{M}=\frac{\bone\T\bv_t}{M},
\end{align}
where $\tnr{Tr}(\cd)$ is the trace of the matrix.

\textbf{Proof}: see \cite[Appendix~A]{Szczecinski21}.
\end{lemma}

Therefore, to obtain the approximations defined in \eqref{V_t.constrained}, we can find the unconstrained solution \eqref{KL.variance} and apply \eqref{vec_t.from.diagonal} or \eqref{v_t.from.avarage}. 

If the projection is carried out via \eqref{mu_t.from.max}-\eqref{V_t.from.Hessian}, we can still apply \eqref{vec_t.from.diagonal} and \eqref{v_t.from.avarage}, but, because the projection is not based on the minimization of the \gls{kl} divergence, these equations are a heuristic inspired by Lemma~\ref{Lemma:1}. 

To obtain new, adaptive algorithms, we replace the covariance $\matV_t$ with a diagonal matrix given by the model \eqref{V_t.constrained}, where, depending on how we constrain the covariance, we will obtain the \gls{vkf} (where we apply \eqref{vec_t.from.diagonal}), the \gls{skf} (where we use \eqref{v_t.from.avarage}), and the \gls{fkf} algorithms (where we always use $\matV= \ov{v}\matI$, see \eqref{V_t.constrained}), which we summarize as follows:
\begin{align}
\nonumber
    &\tnr{vKF}& &\tnr{sKF}&  &\tnr{fKF}&\\
    &\ov\bv_{t}= \bv_{t-1}+\varepsilon \bone&
    &\ov{v}_{t}= v_{t-1}+\varepsilon&
    \\
    &\bkappa_t=\ov\bv_{t}\odot\bx_t&
    &\bkappa_t=\ov{v}_{t}\bx_t&
    &\bkappa_t=\ov{v} \bx_t&
    \\
    &s_t = \bx_t\T\bkappa_t&
    &s_t = \ov{v}_t\|\bx\|^2&
    &s_t = \ov{v}\|\bx\|^2&\\
    \nonumber
    &&&\vdots\\
    \nonumber
    &&&\tnr{Eqs.~}\eqref{e_t.definition}-\eqref{w_t.update}
    \\
    \nonumber
    &&&\tnr{or}\quad \tnr{Eqs.}\eqref{w_t.0}-\eqref{w_t.I+1}&
    \\
    \nonumber
    &&&\vdots\\
\label{variance.update}
    &\bv_{t} = \ov\bv_{t} \odot(\bone  - \bkappa_t\odot \bx_t\alpha_t)&
    &v_{t}=
    \ov{v}_{t} \Big(1 - s_t\alpha_t/M
    \Big),
\end{align}
where $\odot$ denotes the element-by-element multiplication between vectors.

% Using the vector-variance model $\matV_t=\tnr{diag}(\bv_t)$, yields the \gls{vkf} algorithm:
% \begin{align}
% \label{v_bar.t.vKF}
%     \ov\bv_{t}&= \bv_{t-1}+\varepsilon \bone,\\
%     s_t &= \ov\bx_{t}\T(\ov{\bv}_t\odot\bx_t),\\
% \label{k.t.vKF}
%     \bk_{t} &=  \ov\bv_{t}\odot\bx_t\frac{h_t}{1+h_ts_t},\\
%     \bw_{t}&=\bw_{t-1} + \bk_t e_t,\\
% \label{v.t.vKF}
%     \bv_{t}
%     &=
%     \ov\bv_{t} \odot(\bone  - \bk_t\odot \bx_t),
% \end{align}
% where $\odot$ denotes the element-by-element multiplication between vectors.

% Similarly, using $\matV_t=v_t\matI$, we obtain the \gls{skf} algorithm:
% \begin{align}
% \label{v_bar.t.sKF}
%     \ov{v}_{t}&= v_{t-1}+\varepsilon,\\
%     s_t &= \ov{v}_{t}\|\bx_t\|^2,\\
%     \bw_{t}&=\bw_{t-1} + \bx_t\frac{\ov{v}_t h_t e_t}{1+h_t s_t} ,\\
% \label{v.t.sKF}
%     v_{t}
%     &=
%     \ov{v}_{t} \Big(1 - \frac{1}{M}
%     \frac{ h_t s_t}{1+h_t s_t}\Big).
% \end{align}

Of course, the above equations can be simplified. In particular,  the \gls{fkf} algorithm may be written as
\begin{align}\label{fixed.variance}
    \bw_{t}&=\bw_{t-1} + \bx_t\frac{\ov{v}h_te_t}{1+\ov{v} h_t\|\bx_t\|^2},
\end{align}
that, for large posterior variance,  $\ov{v}$, becomes
\begin{align}\label{fixed.variance.large.v}
    \bw_{t}&=\bw_{t-1} + \bx_t\frac{e_t}{\|\bx_t\|^2},
\end{align}
which is the \gls{nlms} algorithm.

Furthermore, for $h_t \|\bx_t\|^2 \ov{v} \ll 1$, we obtain
\begin{align}
\label{SG.algoritm}
    \bw_{t}
    &=\bw_{t-1} + \ov{v}\bx_t h_t e_t,\\
\label{SG.algoritm.2}
    &=\bw_{t-1} + \ov{v} \Big[\nabla_{\btheta} q(y_t-\bx_t\T\btheta)\Big]_{\btheta=\bw_{t-1}},
\end{align}
which we recognize \eqref{SG.algoritm.2} to be the \gls{sg} maximization (with respect to $\btheta$) of the function $q(y_t-\bx_t\T\btheta)$ with the adaptation step $\ov{v}$, which is equal to the assumed posterior variance of the elements in $\btheta_t$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Sanity check: Gaussian case}\label{Sec:Sanity.check.Gaussian.case}
As a sanity check, before delving into non-Gaussian noise $\eta_t$, let us assume that $\eta_t$ are \gls{iid} zero-mean, Gaussian variables with variance $v_\eta$, \ie using  \eqref{y_t.Gaussian}, we have
\begin{align}
    \ell(e) &= q(e)= -\frac{e^2}{2v_\eta}+\tnr{Const.} ,\\
\label{h_t.Gaussian}
    h_t & = \frac{1}{v_{\eta}}.
\end{align}
Thus, the quadratic representation of $\ell(e)$ is unique, independent of $e$ and, therefore, no iterations are needed, \ie we may set $I=0$.

It is easy to see that the algorithms derived in the general case correspond to those already known from the literature, as explained below.
\begin{itemize}
    \item \gls{sg} algorithm, \eqref{SG.algoritm} yields
\begin{align}
\label{LMS.algorithm}
    \bw_{t}&=\bw_{t-1} + \mu\bx_t e_t,\\
    \mu & = \frac{\ov{v}}{v_\eta},
\end{align}
which is the LMS algorithm. Its step, $\mu$, is defined as a ratio between the variance of the estimate and the variance of the observational noise. Although the simplicity of this interpretation of the LMS step is appealing, it is a reminder of the series of approximations we adopted because we know from the literature, \eg \cite[Ch.~16]{Sayed08_Book}, that the optimal step depends on the eigenvalues of the covariance matrix of the data. 

    \item \gls{fkf} algorithm, \eqref{fixed.variance}, becomes
\begin{align}
\label{Regularized.NLMS}
    \bw_{t}&=\bw_{t-1} + \bx_t\frac{e_t}{v_\eta/\ov{v}+\|\bx_t\|^2 },
\end{align}
which is a regularized \gls{nlms} algorithm, with the regularization parameter, $v_\eta/\ov{v}$, directly proportional to the variance of the noise $v_\eta$ and inversely proportional to the assumed variance, $\ov{v}$, of elements in $\btheta_t$.
    
    \item \gls{skf} algorithm, 
    %\eqref{v_bar.t.sKF}-\eqref{v.t.sKF},
    produces the update:
\begin{align}
\label{w.t.BKF}
    \bw_{t}&= \bw_{t-1} + \bx_t\frac{e_t}{v_\eta/\ov{v}_t+\|\bx_t\|^2 },
\end{align}
    where $\ov{v}_t$ is defined by \eqref{variance.update} for the \gls{skf} filter, and we recognize \eqref{w.t.BKF} to be the broadband Kalman filter \cite{Enzner10}, \cite[Sec. VII]{Paleologu13}, which generalizes the regularized \gls{nlms} in \eqref{Regularized.NLMS} by using the time-variable regularization factor $v_\eta/\ov{v}_t$.
\end{itemize}

For completeness, we show also the update for the \gls{vkf} algorithm:
\begin{align}
\label{w.t.vKF.Gaussian.case}
    \bw_{t}&= \bw_{t-1} + \ov\bv_t\odot\bx_t\frac{e_t}{v_\eta+\ov\bv_t\T\bx_t^2 },
\end{align}
where $\bx_t^2=\bx_t\odot\bx_t$, and $\ov\bv_t$ is calculated as shown in the first column of \eqref{variance.update}. It is easily seen to be a generalization of 
\eqref{w.t.BKF}. 

Before going further, let us recall that the \gls{vkf} algorithm models each of the elements in $\btheta_t$ using a different variance, $v_{t,m}$, which expresses the uncertainty of estimation of $\theta_{t,m}$. 

Since the estimates of $\theta_{t,m}$ are updated only if $x_{t,m}\neq 0$ and their variance, $v_{t,m}$ depends on how often this happens, a per-variable variance may be useful if $\bx_t$ is sparse (\eg if it contains only a few non-zero elements $x_{t,m}$) and some elements of $\theta_{t,m}$ are updated more often than the others.

However, sparse $\bx_t$ are not common in the signal processing context and, in our examples, $\bx_t$ were not sparse. Consequently, the \gls{skf} and the \gls{vkf} algorithms performed in a practically identical way, and thus, to not overcrowd the presentation, we do not show the results for the latter.

Most likely, this is also the reason why the update \eqref{w.t.vKF.Gaussian.case} is not well known in the signal processing literatures, although a similar formulation appears in \cite[Sec.~V]{Paleologu13}.%, which, however, relies on empirically estimated variance for each element in $\btheta_t$.

Of course, this is not to say that the \gls{vkf} algorithm is not useful and examples can be found in data processing, where the application of the \gls{vkf} algorithm provides advantages over the \gls{skf} algorithm; see \cite[Sec.~5.1.2]{Szczecinski21}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Generalized Gaussian noise and robust adaptive filters}\label{Sec:Generalized.Gaussian}

By robust filters, we understand those that can cope with non-Gaussian noise $\eta_t$, which essentially means that large-amplitude errors $\eta_t$ may occur with a much higher probability than is the case in the Gaussian model.  

The idea is thus to use a generic non-Gaussian noise model and apply it to the general formulation of filtering, we presented in Sec.~\ref{Sec:Approximate.Kalman} and Sec.~\ref{Sec:Simplification.covariance}.

To this end, we assume the noise to follow the generalized Gaussian distribution with the shape parameter $\beta$, \ie the \gls{pdf} is defined as
\begin{align}
    \pdf_{\eta_t}(e) &=\frac{\beta}{2c\Gamma(1/\beta)}\exp\big[-(|e|/c)^\beta\big]\\
    &\propto \exp\Big[-\Big(\frac{|e|}{\sigma_\eta \kappa(\beta)}\Big)^\beta\Big],
\end{align}
where
\begin{align}
    \kappa(\beta)&=\sqrt{\frac{\Gamma(1/\beta)}{\Gamma(3/\beta)}}
\end{align}
and
\begin{align}
    \sigma_\eta = \sqrt{\Ex[\eta_t^2]}=\frac{c}{\kappa(\beta)}
\end{align}
is the standard deviation of $\eta_t$; thus the variance is given by $v_{\eta}=\frac{c^2}{\kappa^2(\beta)}$. 

With $\beta<1$, we obtain a ``heavy-tailed" distribution, where the ``outliers" have a large probability of occurrence, while, with $\beta=1$, we obtain the Laplace distribution and for $\beta=2$ -- the Gaussian one, with variance $v_{\eta}=c^2/2$. Examples of the \gls{pdf}s are shown in Fig.~\ref{fig:log_PDF}.


\begin{figure}[tb]
    \centering
    \includegraphics[width=1.0\linewidth]{figures/log_pdf.png}
    \caption{\gls{pdf}s of a generalized Gaussian variable with zero-mean and unit variance. By changing the shape parameters we obtain the Gaussian ($\beta=2.0$), the Laplace ($\beta=1.0$), and a heavy-tailed distributions ($\beta=0.2$).}
    \label{fig:log_PDF}
\end{figure}


The likelihood \eqref{ell.definition} is then given by
\begin{align}
\label{ell.Gen.Gaussian}
    \ell(e)&=-\frac{|e|^\beta}{c^\beta}+ \tnr{Const.}
\end{align}
and, as we show in Appendix~\ref{App:Minorization}, the minorization function \eqref{ell(z).approx.quadratic} is defined by the quadratic term $h_t=h(e_t)$, where
\begin{align}
\label{h_t.Gen.Gaussian}
    h(e_t) &= \frac{\beta}{c^\beta} |e_t|^{\beta-2}=\frac{\beta}{\big(\sigma_{\eta} \kappa(\beta)\big)^\beta} |e_t|^{\beta-2},
\end{align}
and the dependence on the prediction error $e_t$ can be appreciated, although, of course, it disappears in the Gaussian case, \ie for $\beta=2$, $h_t=\frac{1}{v_\eta}$.

We may now use \eqref{h_t.Gen.Gaussian} in the \gls{kf}, \gls{skf}, \gls{fkf}, or \gls{sg} algorithms, shown in Sec.~\ref{Sec:Simplification.covariance}, which will produce a new family of robust adaptive filters parameterized with $\beta\in[1, 2]$. For $\beta=2$, we recover, of course, the conventional solutions we have already shown at the end of Sec.~\ref{Sec:Simplification.covariance}. On the other hand, for $\beta<2$, we obtain robust adaptive filters that can be tailored to the distribution of the observational noise.


%%%%%%%%%%%%%%%%%%%%%%
\subsection{Robust adaptive filters} \label{Sec:Algorithms.General_case}

We can now use the previous formulation and specialize them to the expression in the generalized Gaussian case.

The \gls{sg} algorithm, \eqref{SG.algoritm}, becomes
\begin{align}
\label{SG.Gen.Gaussian}
    \bw_{t}
    &=\bw_{t-1} + \mu \bx_t  |e_t|^{\beta-1}\tnr{sign}(e_t) ,\\
    %&=\bw_{t-1} + \tau \bx_t  e_t\\
    \mu &= \frac{\beta \ov{v}}{\big[\sigma_{\eta} \kappa(\beta)\big]^\beta},
\end{align}
with the step depending not only on the variances of the noise $\eta_t$ and of the estimates $\btheta_t$ (\ie on $v_\eta=\sigma_\eta^2$ and $\ov{v}$), but also on the shape parameter $\beta$. 


The \gls{fkf} algorithm, shown in \eqref{fixed.variance}, becomes
\begin{align}
\label{fixed.variance.Gen.Gaussian}
    \bw_{t}
    &=\bw_{t-1} + \bx_t\frac{|e_t|^{\beta-1}\tnr{sign}(e_t)}
    {\tau/\ov{v}+\|\bx_t\|^2/|e_t|^{2-\beta}}  \\
\label{fixed.variance.Gen.Gaussian.stable}
    &=\bw_{t-1} + \bx_t\frac{e_t}
    {|e_t|^{2-\beta}\tau/\ov{v}+\|\bx_t\|^2} , \\
    \tau
    &=\frac{\big(\sigma_{\eta} \kappa(\beta)\big)^\beta}{\beta} ,
\end{align}
where \eqref{fixed.variance.Gen.Gaussian.stable} is the numerically convenient representation, which has also an appealing interpretation: for $\beta\in(1,2)$, the regularization of the \gls{nlms} increases with the absolute value of the prediction error $|e_t|^{2-\beta}$.

The \gls{skf} algorithm becomes
\begin{align}
\label{v_bar.t.sKF.Gen.Gaussian}
    \ov{v}_{t}&= v_{t-1}+\varepsilon , \\
    \bw_{t}
    &=\bw_{t-1} + \bx_t\frac{|e_t|^{\beta-1}\tnr{sign}(e_t)}
    {\tau/\ov{v}_t+\|\bx_t\|^2/|e_t|^{2-\beta}}\\
    &=\bw_{t-1} + \bx_t\frac{e_t}
    {|e_t|^{2-\beta}\tau/\ov{v}_t+\|\bx_t\|^2} , \\
\label{v.t.sKF.Gen.Gaussian}
    v_{t}
    &=
    \ov{v}_{t} \left(1 - \frac{1}{M}
    \frac{  \|\bx_t\|^2}
    {|e_t|^{2-\beta}\tau/\ov{v}_t+\|\bx_t\|^2}\right). 
\end{align}

The \gls{vkf} and \gls{kf} algorithms require the gain multiplier $\alpha_t$ which is calculated as follows:
\begin{align}
\label{a.t.KF}
    \alpha_t 
    &=  \frac{|e_t|^{\beta-2}}{\tau + |e_t|^{\beta-2} s_t}\\
    &= \frac{1}{\tau |e_t|^{2-\beta} +s_t}.
\end{align}

%%%%%%%%%%%%%%%%%%%%%%
\subsection{Signed-error algorithms} \label{Sec:Algorithms.signed.error}
Akin to the particular Gaussian noise case we considered in Sec.~\ref{Sec:Sanity.check.Gaussian.case} we can now consider the particular case of $\beta=1$, \ie assume that the noise $\eta_t$ is Laplacian. We get the following.
\begin{itemize}
    \item 
    \gls{sg} algorithm, \eqref{SG.algoritm}, becomes
\begin{align}
\label{signed.LMS}
    \bw_{t}
    &=\bw_{t-1} + \mu \bx_t  \tnr{sign}(e_t) , \\
    \mu &= \frac{\ov{v}}{\sqrt{2}\sigma_{\eta}},
\end{align}
which we recognize as the signed-error LMS algorithm \cite[Ch.~12.1]{Sayed08_Book}.
    \item 
    \gls{fkf} algorithm, shown in \eqref{fixed.variance}, becomes
\begin{align}
\label{fixed.variance.Laplace}
    \bw_{t}
    &=\bw_{t-1} + \bx_t\frac{\tnr{sign}(e_t)}
    {\tau/\ov{v}+\|\bx_t\|^2/|e_t|}\\
    &=\bw_{t-1} + \bx_t\frac{e_t}
    {|e_t|\tau/\ov{v}+\|\bx_t\|^2},\\
\label{tau.beta=1}
    \tau
    &=\sigma_{\eta} \sqrt{2},
\end{align}
which is a regularized version of the normalized signed-error LMS algorithm. 
    \item 
    \gls{skf} algorithm becomes
a variable-step version of the regularized, normalized signed-error LMS algorithm:
\begin{align}
\label{v_bar.t.sKF.Gen.Gaussian.beta=1}
    \ov{v}_{t}&= v_{t-1}+\varepsilon , \\
    \bw_{t}
    &=\bw_{t-1} + \bx_t\frac{\tnr{sign}(e_t)}
    {\tau/\ov{v}_t+\|\bx_t\|^2/|e_t|} \\
    &=\bw_{t-1} + \bx_t\frac{e_t}
    {|e_t|\tau/\ov{v}_t+\|\bx_t\|^2} , \\
\label{v.t.sKF.Gen.Gaussian.beta=1}
    v_{t}
    &=
    \ov{v}_{t} \left(1 - \frac{1}{M}
    \frac{  \|\bx_t\|^2}
    {|e_t|\tau/\ov{v}_t+\|\bx_t\|^2}\right), 
\end{align}
and $\tau$ is given by \eqref{tau.beta=1}.
    \item
    \gls{kf} algorithm is obtained applying \eqref{ov.matV_t.Kalman.full}-\eqref{V_t.update} but replacing \eqref{h.t.definition}-\eqref{a_t.definition} with 
\begin{align}
\label{a.t.KF.beta=1}
    \alpha_t 
    &= \frac{1}{\tau |e_t| +s_t}.
\end{align}
\end{itemize}

Note that, beside the signed-error LMS algorithm in \eqref{signed.LMS} (which gives name to this family of algorithms), all other algorithms are new. This is notable, as they are obtained almost effortlessly by applying the generic equations we derived in Sec.~\ref{Sec:Approximate.Kalman}.


    
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Numerical examples}\label{Sec:Numerical.examples}

We consider the scenario, where we observe the acoustic signals: output signal, $y_t$, and input signal, $x_t$, which are linearly related as
\begin{align}
\label{linear.convolution}
    y_t=\bx_t\T \bh + \eta_t,
\end{align}
where 
\begin{align}
    \bx_t &= \big[ x_{t}, x_{t-1},\dots, x_{t-M+1} \big]\T,
\end{align}
and
\begin{align}
    \bh &= [h_0, h_1,\ld h_{M-1}]\T
\end{align}
is the acoustic impulse response shown in Fig.~\ref{fig:h_t}, which is calculated using the software in~\cite{Werner23} for a room of dimensions $(5, 10, 6)$~m, where the source is in position $(1, 2.5, 2)$~m and the receiver is in position $(1, 1.5, 1)$~m, with a sampling rate of $8$~kHz and a reverberation time of $200$~ms. 

The input signal is generated from the autoregressive process, $x_t=-a x_{t-1} + u_t$, where we use $a=0.9$ and $u_t$ is a zero-mean white Gaussian noise with variance $v_u$. The noise $\eta_t$ is generated as a zero-mean, white generalized Gaussian variables with shape parameter $\ov{\beta}$ and variance $v_\eta$.

We define the output \gls{snr} as
\begin{align}
\label{SNR.definition}
\tnr{SNR} & = 10\log_{10}\left\{ \frac{\Ex[|\bx_t\T \bh|^2]}{v_\eta}\right\}~[\tnr{dB}] ,
\end{align}
where $\Ex[\cd]$ is the expectation with respect to $x_t$. For any given $v_u$ and $\tnr{SNR}$, we thus find $v_\eta$ via \eqref{SNR.definition}.

Our goal is to identify the impulse response, $\bh$, and, since the observation equation \eqref{output.equation.general} perfectly matches the model \eqref{linear.convolution}, we treat the result of adaptive filtering $\bw_t$, as estimates of $\bh$.

The estimation quality is assessed by the misalignment:
\begin{align}    
\label{Misalignement.def}
\mfm_t &= \frac{\|\bw_t - \bh\|^2_2}{\|\bh\|^2_2},
\end{align}
or, by its average:
\begin{align}    
\label{Avg.Misalignement.def}
\ov{\mfm}_t & = \Ex[\mfm_t],
\end{align}
where the expectation is taken over $x_t$ and $\eta_t$. In practice, this is done by averaging $\mfm_t$ over $N$ independent realizations of the noise $\eta_t$ and of the input signal $x_t$; here we use $N=100$.

\begin{figure}[tb]
    \centering
    \includegraphics[width=1.0\linewidth]{figures/h_t.png}
    \caption{Impulse response, $h_t$, used in numerical examples.}
    \label{fig:h_t}
\end{figure}

Although the algorithms are derived assuming, in \eqref{state.equation.general}, that the state $\btheta_t$ varies in time, the impulse response, $\bh$, in our example is constant; so, with appropriately set algorithm parameters, the misalignment should converge to a useful/small value $\ov\mfm_\infty$. 

Thus, by choosing different parameters of the algorithms, we will trade the convergence rate against the misalignment at convergence $\ov{\mfm}_\infty$. For example, a larger step size $\mu$ in the \gls{sg} algorithm increases the rate at the cost of increased misalignment) \cite[Ch.~5.4]{Haykin02_Book}. 

To simplify the comparison, it is customary to assess convergence while setting the misalignment fixed. Here, we do it by running the algorithm on a parameter grid and choosing those that reach the ``small'' target misalignment $\ov\mfm_\infty$ (\eg $\ov\mfm_\infty=0.01=-20$~dB).

To simplify the comparison of the algorithms, we assume that the variance of the noise $v_\eta$ is known (\eg estimated from $y_t$ in the absence of the input signal $x_t$). However, we note that this information can be exploited in a meaningful way only in the \gls{skf}, \gls{vkf}, and \gls{kf} algorithms, where the Kalman gain $\bkappa_t$ (which depends on $v_\eta$) interacts, respectively, with $\ov{v}_t$, $\ov{\bv}_t$, or $\ov\matV_t$. On the other hand, the \gls{sg} and \gls{fkf} algorithms depend on the regularization factor defined by a ratio $\tau/\ov{v}$, where we must \emph{assume} a suitable variance $\ov{v}$. However, instead of assuming that we know $\tau$ and $\ov{v}$, we might assume that we know directly the regularization factor.

In the examples, we use non-Gaussian noise $\eta_t$, with $\ov\beta =0.2$ while, for the adaptive algorithms, we consider two cases. The first is the ``conventional'' adaptive filtering, which assumes Gaussian noise, \ie uses $\beta=2.0$. The second case corresponds to a robust filter, which assumes the Laplacian noise, \ie  is based on $\beta=1.0$, which, as mentioned before, is the smallest value of $\beta$ that guarantees that the function $\ell_y(z)$ is concave, and thus the solution of \eqref{w_t=argmax.approx} is unique.

Thus, in all cases, the adaptive filters are mismatched with respect to the distribution of the noise but, to approximate the heavy-tailed noise, we expect the Laplacian assumption ($\beta=1.0$) be more suitable than the Gaussian one ($\beta=2.0$).

As already mentioned in Sec.~\ref{Sec:Sanity.check.Gaussian.case}, in the conventional case, \ie for $\beta=2.0$, the \gls{sg} algorithm corresponds to the LMS algorithm, the \gls{fkf} algorithm is the same as the regularized \gls{nlms}, while the \gls{skf} corresponds to the broadband Kalman filter.

On the other hand, among robust filters, the \gls{sg} algorithm corresponds to the signed-error LMS, while the \gls{fkf}, \gls{skf}, and \gls{kf} algorithms are new members of the signed-error family of algorithms, see Sec.~\ref{Sec:Algorithms.signed.error}.

While we compare the performance of the algorithms, we emphasize that our goal is not to study their properties in detail. Rather, we want to show that, using the Bayesian framework, the algorithms can be almost effortlessly derived from the generic equations we have shown, and their performance decreases when the simplifications increase.





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{example}[Non-iterative solutions]


The conventional adaptive filters results are shown in Fig.~\ref{fig:Heavytail.noise}a while the results obtained using the robust filters are presented in Fig.~\ref{fig:Heavytail.noise}b; we set $\ov\mfm_\infty=-20$~dB and use non-iterative versions, that is, $I=0$. For reproducibility purposes, the parameters used to obtain these results are shown in Table~\ref{Tab:parameters_algorithms.Heavytail}.

\begin{figure}
    \centering
\includegraphics[width=0.9\linewidth]{figures/mis=KF,SG,fKF,sKF_beta_sim=0.2_beta_algo=2.0_K_iter=0_SNR=5_mis_target=-20.0.png}\\
a) Conventional adaptive filters, $\beta=2.0$, thus \gls{sg}=LMS, \gls{fkf}= regularized \gls{nlms}, \gls{skf} = Broadband Kalman filter \\   
\includegraphics[width=0.9\linewidth]{figures/mis=KF,SG,fKF,sKF_beta_sim=0.2_beta_algo=1.0_K_iter=0_SNR=5_mis_target=-20.0.png}\\
b) Robust adaptive filters, $\beta=1.0$, thus \gls{sg}=signed-error LMS
    \caption{Convergence in heavy-tailed noise ($\ov\beta=0.2$) for (a) conventional filters ($\beta=2.0$), and (b) robust filters ($\beta=1.0$); $\tnr{SNR}=5$~dB and target misalignment $\ov\mfm_{\infty}=-20$~dB.}
    \label{fig:Heavytail.noise}
\end{figure}
    
\begin{table}[h]
    \centering
    \begin{tabular}{cc|l|l}
            & & \multicolumn{1}{c|}{$\beta=2.0$} & 
            \multicolumn{1}{c}{$\beta=1.0$} \\
        \hline
        SG & $\mu$  & $1.1\cd 10^{-4}$ & $2.7\cd 10^{-5}$\\
        \hline
        fKF & $\tau/\ov{v}$ & $8.2\cd 10^{3}$ & $1.1\cd 10^{4}$ \\
        \hline
        sKF & $\varepsilon$ & $3.2\cd 10^{-10}$ & $2.7\cd 10^{-8}$ \\
        \hline
        KF  & $\varepsilon$ & $ 3.6\cd 10^{-11}$ & $2.2\cd 10^{-8}$
    \end{tabular}
    \caption{Parameters of the adaptive algorithm used to obtain results shown in Fig.~\ref{fig:Heavytail.noise}.}
    \label{Tab:parameters_algorithms.Heavytail}
\end{table}

These results follow our intuition: by increasing the number of simplifying assumptions related to the dynamics of the filter, the convergence/performance of the algorithm deteriorates. This is less visible in conventional algorithms (see Fig.~\ref{fig:Heavytail.noise}a, where the \gls{fkf} and \gls{skf} algorithms perform similarly to the \gls{sg} algorithm) because the improvement in the model dynamics is tempered by the severe mismatch between the model of the noise (Gaussian) and the actual distribution (heavy-tailed). 

On the other hand, by using the robust filters, which better match the statistics of the observation noise, the convergence improves notably: pay attention to the ten-fold difference in the time scales used in Fig.~\ref{fig:Heavytail.noise}a and in Fig.~\ref{fig:Heavytail.noise}b. Moreover, this also clarifies the gains due to improvement in model dynamics, where the \gls{sg} algorithm is clearly outperformed by the \gls{fkf} and \gls{skf} algorithms.


\end{example}

\begin{example}[Iterative calculation and variable target misalignment] 

In this example, we illustrate two effects: a) gains due to iterative recalculation of the Kalman gain multiplier $\alpha_t$ as defined in \eqref{w_t.update.iterations} (note that we only show the results for $I=1$ as the improvements observed when $I>1$ are negligible), and b) differences in convergence for different scenarios, which we enforce by changing the target misalignment $\ov\mfm_{\infty}\in\set{-15,-20,-25}$~dB. The parameters used to obtain these results are given in Table~\ref{Tab:variable.misalignment}.

\begin{table}[h]
    \centering
\scalebox{0.9}
{
    \begin{tabular}{cc|l|l|l|l|l|l}
            &  & \multicolumn{2}{c|}{$\ov\mfm_{\infty}=-15$~dB} & \multicolumn{2}{c|}{$\ov\mfm_{\infty}=-20$~dB} & \multicolumn{2}{c}{$\ov\mfm_{\infty}=-25$~dB}\\
            &  & $I=0$ & $I=1$ & $I=0$ & $I=1$ & $I=0$ & $I=1$\\
        \hline
        SG  & $\mu$ & $5.4\cd 10^{-5}$ & & 
        $2.7\cd 10^{-5}$ & & 
        $1.4\cd 10^{-5}$ \\
        \hline
        fKF & $\tau/\ov{v}$ & 
        $3.5\cd 10^{3}$ & $5.0\cd 10^{3}$ &
        $1.1\cd 10^{4}$ & $1.6\cd 10^{4}$ &
        $3.4\cd 10^{4}$ & $4.3\cd 10^{4}$\\
        \hline
        sKF & $\varepsilon$ & 
        $1.0\cd 10^{-7}$ & $7.1\cd 10^{-8}$ &
        $2.7\cd 10^{-8}$ & $2.2\cd 10^{-8}$ &
        $7.7\cd 10^{-9}$ & $6.6\cd 10^{-9}$\\
        \hline
        KF  & $\varepsilon$ & 
        $7.3\cd 10^{-8}$ & $6.0\cd 10^{-8}$ &
        $2.2\cd 10^{-8}$ & $2.2\cd 10^{-8}$ &
        $6.0\cd 10^{-9}$ & $6.0\cd 10^{-9}$
    \end{tabular}
}
    \caption{Parameters of the adaptive algorithm used to obtain the results shown in Fig.~\ref{Fig:variable.misalignment}.}
    \label{Tab:variable.misalignment}
\end{table}

\begin{figure}
    \centering
    \includegraphics[width=0.9\linewidth]{figures/mis=KF,SG,fKF,sKF_beta_sim=0.2_beta_algo=1.0_K_iter=0,1_SNR=5_mis_target=-15.0.png}\\
    a) $\ov\mfm_{\infty}=-15$~dB\\
    \includegraphics[width=0.9\linewidth]{figures/mis=KF,SG,fKF,sKF_beta_sim=0.2_beta_algo=1.0_K_iter=0,1_SNR=5_mis_target=-20.0.png}\\
    b) $\ov\mfm_{\infty}=-20$~dB\\
    \includegraphics[width=0.9\linewidth]{figures/mis=KF,SG,fKF,sKF_beta_sim=0.2_beta_algo=1.0_K_iter=0,1_SNR=5_mis_target=-25.0.png}\\
    c) $\ov\mfm_{\infty}=-25$~dB\\
    \caption{Convergence of robust algorithms ($\beta=1.0$) in heavy-tailed noise ($\ov\beta=0.2$) for target misalignment a) $\ov\mfm_{\infty}=-15$~dB, b) $\ov\mfm_{\infty}=-20$~dB, and c) $\ov\mfm_{\infty}=-25$~dB.}
    \label{Fig:variable.misalignment}
\end{figure}

To improve the performance (misalignment), we obviously require more time to converge (note the change in the time-axis in Fig.~\ref{Fig:variable.misalignment}a--Fig.~\ref{Fig:variable.misalignment}c) and must adjust the parameters: decrease the adaptation step $\mu$ in the \gls{sg} algorithm, increase the regularization factor $\tau/\ov{v}$ in the \gls{fkf} algorithm, or decrease the variance $\varepsilon$ in the \gls{skf} and \gls{kf} algorithms.

These are rather well known properties except the one referring to the regularization in the \gls{fkf} filter, where we note that the regularization is not a ``small'' value as it is sometimes stated to be \cite[Ch.~11]{Sayed08_Book}. In fact, being inversely proportional to the assumed variance $\ov{v}$, the regularization is also inversely proportional to the target misalignment $\ov\mfm_{\infty}$,\footnote{
This is because we may assume that $\bw_t$ are unbiased estimates of $\bh$, \ie $\Ex[\bw_\infty]=\bh$ (which, as we verified empirically, holds at the convergence) and thus the variance of the estimate of $\theta_{t,m}$ may be approximated as
\begin{align}
    \ov{v}_\infty  &\approx \frac{\ov\mfm_{\infty} \|\bh\|^2}{M}.
\end{align}
} 
which explains why the regularization grows when the latter decreases; in particular, in Table~\ref{Tab:variable.misalignment}, we see that the tenfold decrease of $\ov\mfm_{\infty}$ (from $-15$~dB to $-25$~dB) is obtained by a tenfold increase in the regularization value $\tau/\ov{v}$ (from $3.5\cd10^3$ to $3.4\cd10^4$).

Bottom line is that, by decreasing the target misalignment, we decide to operate in the small-variance (\ie small estimation error) regime, which accentuates the importance of accurate modelling, where the loss due to simplifications in the adaptive filters becomes more evident; indeed, we can observe a) the advantage of the \gls{skf} algorithm over the \gls{fkf} algorithm, and the advantage of the latter over the \gls{sg} filter, as well as, b) the added value of the iterative processing.

On the other hand, iterative recalculation of the Kalman gain multiplier $\alpha_t$ provides very modest improvement in the \gls{kf} filter. This should be attributed to the very fast convergence, where the gains of iterative refinement have no opportunity to materialize.
 
\end{example}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusions}\label{Sec:Conclusions}

In this work, using the concept of Bayesian filtering in the state-space model, we propose a unifying perspective for conventional and robust adaptive filters. The following points are developed.
\begin{itemize}
    \item We explain how the well-known adaptive filters may be seen as particular cases of our Bayesian formulation if the Gaussian model of noise is adopted. Such point of view explains, in the common framework, the origin of the well-known algorithms (such as the LMS, \gls{nlms}, regularized \gls{nlms}, and broadband Kalman filter), which are seen as simplified versions of the Kalman filter itself. 
        
    \item We apply the Bayesian formulation in more general (non-Gaussian) cases as well, which produces an entire family of adaptive filters depending on the parameters of the generalized Gaussian distribution.
    
    Here, beyond the general formulation, we also focus on the assumption of the Laplacian noise, for which we obtain a family of signed-error algorithms, which generalize the well known signed-error LMS filter. What is remarkable is that these robust algorithms are derived effortlessly from the general Bayesian filtering formulations. This includes a robust Kalman filter, which is straightforwardly derived for a non-Gaussian noise.
    
    \item We show that, due to the non-Gaussian nature of the noise, the filtering operation may be enhanced by iterative calculation of the Kalman gain. The validity of this proposition is valided by simulations and is shown to improve the performance when the adaptive filter target low-error estimation.
\end{itemize}

We should note that although the relationship between the Kalman filter and other adaptive filters is not new \cite{Paleologu13}, it is not widely adopted. In fact, the literature more often associates the LMS filter with the approximate solution of the Wiener equations \cite[Ch.~10.1]{Sayed08_Book} and compares the LMS to the \gls{rls} \cite[Ch.~21.6]{Sayed08_Book}. While the latter can be related to the Kalman filter \cite[Ch.~31]{Sayed08_Book}, it requires a very specific transformation of the data and, in our view, is counterintuitive. Indeed, in the \gls{rls} formulation the estimated parameters are deterministic, while in the \gls{kf} formulation, they are random and must be tracked. In that perspective, the LMS algorithm, as well as other adaptive filters, which can be used for tracking, have a better interpretation as approximate Kalman filters. 

Thus, beyond the derivation of new adaptive robust algorithms suited to operate in non-Gaussian noise, our formulation provides a unifying perspective on the adaptive filters. We believe that the possibility of deriving the well-known adaptive algorithms in a common framework is very useful from a pedagogical perspective and offers clear paths to derive new algorithms.

Moreover, by applying the simplifications, which yield the \gls{sg} and \gls{fkf} algorithms, we also obtain an insightful interpretation of the parameters (such an adaptation step and the regularization factor). In particular, we dispel the myth that the regularization factor should be a ``small" value. Rather, we show that it is inversely proportional to the target estimation variance and, therefore, depending on the application, may be rather large. 
    
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{appendices}
\section{Minorization by quadratic function}\label{App:Minorization}

We start by removing the irrelevant constant term from $\ell(e)$ in \eqref{ell.Gen.Gaussian}, that is, we consider $\ell(e)=-\frac{|e|^\beta}{c^\beta}$. 

In addition, we exploit the property suggested in \cite[Sec.~ 3.4]{Hunter04a}, which says that $\ell(e)=-\frac{|e|^\beta}{c^\beta}$ can be minorized by $q(e)=-\frac{1}{2}h_t e^2 + C_q$ if (i) $\ell(e_t)=q(e_t)$, (ii) $\ell'(e_t)=q'(e_t)$, and (iii) $\forall e , \ q''(e)\le\ell''(e)$. 

We focus on $e>0$ because both $\ell(e)$ and $q(e)$ are symmetric.

First, it is easy to show that the constant $C_q=(e_t/c)^\beta(\frac{1}{2}\beta-1)$ satisfies (i). Note that $C_q$ is irrelevant from an optimization perspective, but will be useful later in the proof.

The condition (ii) allows us to find $h_t=h(e_t)$ by making the first derivatives equal:
\begin{align}
    \ell'(e)|_{e=e_t}&=q'(e)|_{e=e_t} , \\
    -\beta\frac{|e_t|^{\beta-1}}{c^\beta}
    &=-h_t |e_t|,
\end{align}
which yields $h_t=\frac{\beta}{c^\beta} |e_t|^{\beta-2}$ shown in \eqref{h_t.Gen.Gaussian}.

We can now verify the condition (iii):
\begin{align}
    q''(e) &\le \ell''(e) ,\\
    -\frac{\beta}{c^\beta} e_t^{\beta-2} 
    &\le
    -\frac{\beta(\beta-1)e^{\beta-2}}{c^\beta} , \\
    e_t^{\beta-2} &\ge (\beta-1)e^{\beta-2},
\end{align}
which holds for $e>e_t$ and for all $\beta<2$. Moreover, if $\beta\le 1$, it also holds for any $e$.

If $\beta\in(1,2)$ and $0<e<e_t$, we proceed by definition, writing explicitly the minorization condition:
\begin{align}
    q(e)&\le \ell(e) ,\\
    -\frac{1}{2}\beta e_t^{\beta-2}e^2
    +e_t^\beta(\frac{1}{2}\beta-1)
    &\le 
    -e^\beta , \\
\label{u(x).p(x)}
    u(x)=x^\beta(\frac{1}{2}\beta-1)
    &\le 
    \frac{1}{2}\beta x^{\beta-2}-1=p(x),
\end{align}
where we set $x=e_t/e\ge1$. 

Both sides of inequality \eqref{u(x).p(x)} are equal for $x=1$, \ie $u(1)=p(1)$, and $u(x)$ is concave (for $\beta<2$) while $v(x)$ is convex, \ie $u''(x)<0$ and $p''(x)>0$. Thus, $u(x)$ is upper-bounded by $u(1)+u'(1)(x-1)$ while $p(x)$ is lower-bounded by $p(1)+p'(1)(x-1)$. Since $u'(1)<p'(1)$, the inequality is satisfied for the bounds when $x>1$, and thus, it must hold for the functions as well.

An example of the minorization for $\beta=1$ is shown in Fig.~\ref{fig:minorization}.

\begin{figure}[tb]
    \centering
    \includegraphics[width=1.0\linewidth]{figures/minorization_beta=1.png}
    \caption{Minorization example for $\beta=1$ and $e_t=1.5$, which is the value where $\ell(e_t)=q(e_t)$.}
    \label{fig:minorization}
\end{figure}


\end{appendices}

\ifdefined\ARXIV
\input{\CFilesBib/output.bbl.my}
\bibliographystyle{\CFilesBib/IEEEtran}
\else
\bibliography{\CFilesBib/IEEEabrv,\CFilesBib/references_rank,\CFilesBib/references_all}
\bibliographystyle{\CFilesBib/IEEEtran}
\fi

\end{document}