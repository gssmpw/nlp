
\section{Conclusions}
\label{sec:conclusions}

% In this paper, we introduce SEM-CLIP, a novel few-shot learning approach that innovatively integrates defect classification and segmentation functionalities.
% This method utilizes carefully crafted prompts, enriched with expert knowledge, to optimize the vision-language model for more effective text-guided learning.
% Additionally, it features a customized architecture designed specifically for efficient feature extraction and processing tailored to the distinct needs of segmentation and classification tasks. By fine-tuning the model with few-shot samples, SEM-CLIP effectively minimizes the impact of complex backgrounds inherent in SEM defect data and addresses the challenges of intricate defect textures. 
% Finally, we validated our approach through comprehensive experiments on the SEM dataset collected from an actual production line, encompassing six types of defects. Experiment results confirmed that our model achieves SOTA performance.

In this paper, we introduce SEM-CLIP, a novel few-shot learning approach that innovatively integrates defect classification and segmentation functionalities.
This method utilizes carefully crafted prompts to optimize the vision-language model for more effective text-guided learning.
Additionally, it features a customized architecture for the distinct needs of segmentation and classification tasks. SEM-CLIP effectively minimizes the impact of complex backgrounds inherent in SEM defect data and addresses the challenges of intricate defect textures.

\section*{Acknowledgments}
This work is supported by the Zhejiang University Education Foundation Qizhen Scholar Foundation, the Zhejiang Provincial Key R\&D Programs (Grant No.~2024C01002, No.~2024SJCZX0031).