
\section{Preliminaries}
\label{sec:preliminaries}

\subsection{Pre-trained Vision-language Model}

%Vision-language models are designed to process and understand both visual and textual data simultaneously, integrating inputs from both domains to perform tasks that require a cohesive understanding of images and text. Embracing the pre-training philosophy further stimulates the widespread applications of vision-language models. The CLIP model \cite{radford2021learning}, which was pre-trained on 400 million image-text pairs, has robust generalization and enables it to utilize natural language to refer to learned visual concepts. It involves two main components: an image encoder and a text encoder. These encoders are typical Transformer structures \cite{DNN-2017NeurIPS-Attention}, relying on the self-attention mechanism. They encode image and text inputs to visual and textual feature spaces, respectively. These features are then projected into a shared embedding space where their similarity can be computed. CLIP is trained using a contrastive loss function that encourages the model to align the embeddings of matching text and image pairs closely together while pushing non-matching pairs apart. This approach enables CLIP to effectively perform a variety of image and text-based tasks without task-specific training, showcasing its flexibility and generalization capabilities in downstream tasks \cite{luddecke2022image, zhou2022maskclip, Zhou_Zhang_Lei_Liu_Liu_2022, Chen_Si_Zhang_Wang_Wang_Tan_2023}. 
Vision-language models process and integrate visual and textual data, enabling tasks that require a cohesive understanding of both domains. The CLIP model \cite{radford2021learning}, which was pre-trained on 400 million image-text pairs, has robust generalization and enables it to utilize natural language to refer to learned visual concepts. These Transformer-based encoders \cite{DNN-2017NeurIPS-Attention} project features into a shared embedding space where similarity is computed, guided by a contrastive loss function that aligns matching pairs and separates non-matching pairs. This design allows CLIP to generalize effectively across various tasks without task-specific training, demonstrating its flexibility in downstream applications \cite{luddecke2022image, zhou2022maskclip, Zhou_Zhang_Lei_Liu_Liu_2022, Chen_Si_Zhang_Wang_Wang_Tan_2023}.

% Vision-language models are at the forefront of artificial intelligence research, leveraging multimodal learning and feature alignment to process and generate responses across the visual content and natural language. The significant cognitive capabilities of pre-trained Vision-language models have recently led to their widespread application. Notably, the CLIP model \cite{radford2021learning}, which was pre-trained on 400 million image-text pairs, has robust generalization and enables it to utilize natural language to refer to learned visual concepts. This feature has allowed it to exhibit excellent zero/few-shot recognition capabilities in downstream visual detection tasks \cite{luddecke2022image, zhou2022maskclip, Zhou_Zhang_Lei_Liu_Liu_2022, Chen_Si_Zhang_Wang_Wang_Tan_2023}.

\subsection{Wafer Surface Defect Detection}

%（8.11）Defect detection is critical to yield enhancements in integrated circuit fabrication lines. Previous research has primarily focused on wafer map (as shown in \Cref{fig:workflow}) data, which engineers produce by marking faulty chips with different colors based on test results. The specific spatial distributions of defects on a wafer can provide insights into the causes and help determine the ill steps. While some techniques have been proposed \cite{Wafer-2020TSM-DCNN, Wafer-2022TSM-FusionTransformer, Wafer-2023ASPDAC-Survey}, the continuous evolution of process nodes, along with the increasing complexity and density of chip components, has significantly heightened the challenges of wafer map-level detection. Lacking detailed information makes the wafer map-level analysis too rough and difficult to accurately locate the problems, leading to potential risks \cite{ma2023review}. 
%（8.11）Consequently, it becomes imperative to utilize magnified imaging techniques, \textit{i.e.}, scanning electron microscopy (SEM), to scrutinize the wafer surface closely. The imaging flow is shown in \Cref{fig:workflow}. More sophisticated methodologies are required to detect, classify, and analyze the locations and shapes of microscopic defects to identify the process steps where these defects originate accurately. 

Defect detection is essential for improving yields in integrated circuit fabrication. Traditional research has focused on wafer maps, where faulty chips are marked with colors based on test results. While these maps can provide spatial insights into defects, the increasing complexity of chip components has made wafer map-level detection more challenging and less precise \cite{Wafer-2020TSM-DCNN, Wafer-2022TSM-FusionTransformer, Wafer-2023ASPDAC-Survey, ma2023review}.
To address these limitations, magnified imaging techniques like scanning electron microscopy (SEM) are crucial for closely examining wafer surfaces. As shown in \Cref{fig:workflow}, advanced methods are needed to accurately detect, classify, and analyze microscopic defects, pinpointing the exact process steps where defects originate.

\subsection{SEM Image Defect Data}

In the absence of a public SEM Image dataset, we collect some data from an in-house 12-inch, 55$nm$ CMOS fabrication line.
%This dataset comprises 1332 grayscale images, including 226 non-defect and 1106 defective images. The defect data contains six common detect types, including 59 images of bridges, 141 images of copper residue, 230 images of holes, 77 images of infilm defects, 455 images of particles, and 144 images of scratches. \Cref{dataset} illustrates some examples. 
The dataset includes 1332 grayscale images, with 226 non-defective and 1106 defective images, categorized into six common defect types: 59 bridges, 141 copper residues, 230 holes, 77 infilm defects, 455 particles, and 144 scratches. \Cref{dataset} illustrates some examples.

\begin{figure}[h]
  \centering
  \includegraphics[width=0.98\linewidth, trim={5cm 4.8cm 5cm 3.1cm}, clip]{figs/dataset1.pdf}
  \caption{Non-defect and defective images.} 
  \label{dataset}
\end{figure}

% Defect detection is critical to ensure the yield of integrated circuit manufacturing lines and reduce faults. Previous research has primarily focused on wafer map data, which engineers produce by marking faulty chips with different colors based on test results. The specific spatial distributions, shapes, and locations of defects on a wafer can provide insights into the causes, thereby helping to determine which stage of the manufacturing process is responsible for the issues. Although such research is relatively mature, the continual miniaturization of integrated circuits and the increasing complexity and density of chip components have made chip-level detection more challenging, leading to potential risks \cite{ma2023review}. Consequently, there is a need to combine this approach with magnified imaging of the wafer surface using scanning electron microscopes (SEMs) to detect, classify, and analyze specific microscopic defects, thus helping to identify the particular process steps where defects originate.

\subsection{Related Work}

%（8.11）Previously, wafer surface defect detection was primarily conducted by experienced engineers. This relies heavily on the engineers' expertise, which is time-consuming and lacks uniform standards. With the advancements of artificial intelligence, deep learning-based techniques have proven highly effective for this task \cite{gao2022review}.

%（8.11）Researchers have developed numerous classification approaches. For instance, Chen \textit{et al.} presented a defect recognition and classification algorithm rooted in PCA and SVM \cite{chen2008defect}. Chang \textit{et al.} utilized SVM, drawing on features like smoothness and texture intricacy, for classifying high-intensity defect images \cite{chang2013hybrid}.  Cheon \textit{et al.} proposed a single CNN model adept at feature extraction \cite{cheon2019convolutional}. 

%（8.11）Segmentation of defects is necessary to locate defect positions and gather information such as the defect sizes. Segmentation networks often use classic encoder-decoder structures, such as UNet \cite{ronneberger2015u} and SegNet \cite{badrinarayanan2017segnet}, which focus on effectively leveraging both local and global feature information. Han Hui \textit{et al.} proposed to integrate a Region Proposal Network (RPN) with a UNet architecture to suggest defect areas before conducting defect segmentation \cite{han2020polycrystalline}. 
%（8.11）Subhrajit Nag \textit{et al.} introduced WaferSegClassNet \cite{nag2022wafersegclassnet}, which extracts multi-scale local features in the encoder and performs classification and segmentation tasks in the decoder. 
%（8.11）Recently, Vic De Ridder \textit{et al.} introduced diffusion models \cite{de2023semi}. This approach treats the instance segmentation task as a denoising process from noise to a filter, utilizing diffusion models to predict and reconstruct instance masks for semiconductor defects. While achieving high precision, the expensive computations of the diffusion model require substantial resources. Moreover, the diffusion method can only handle a single defect type, limiting its practical utility in industrial scenarios.

%（8.11）Despite these achievements, following the supervised learning mechanism, their performance heavily relies on an abundance of accurately labeled training data, which is scarce. They also suffer from poor transferability when dealing with new defects. 

Wafer surface defect detection was traditionally performed by engineers, relying on expertise that is time-consuming and inconsistent. With advancements in artificial intelligence, deep learning techniques have become highly effective for this task \cite{gao2022review}. Several classification approaches have been developed. Chen \textit{et al.} proposed a defect recognition algorithm using PCA and SVM \cite{chen2008defect}. Chang \textit{et al.} utilized SVM with features like smoothness and texture \cite{chang2013hybrid}. Cheon \textit{et al.} introduced a CNN model for feature extraction \cite{cheon2019convolutional}. Defect segmentation is crucial for determining defect locations and sizes. Encoder-decoder networks like UNet \cite{ronneberger2015u} and SegNet \cite{badrinarayanan2017segnet} are commonly used. Han Hui \textit{et al.} combined a Region Proposal Network (RPN) with UNet for defect area suggestion \cite{han2020polycrystalline}. Subhrajit Nag \textit{et al.} introduced WaferSegClassNet, which performs both classification and segmentation \cite{nag2022wafersegclassnet}. Recently, Vic De Ridder \textit{et al.} applied diffusion models to predict and reconstruct masks for semiconductor defects, achieving high precision but at a high computational cost, and with limitations in handling only a single defect type \cite{de2023semi}.

Despite these advancements, these methods rely heavily on large amounts of accurately labeled data, which is scarce, and they struggle with transferring to new defect types.

% In the task of defect classification, it is typical to use a model structure that initially extracts features through convolutional and pooling layers, followed by classification via fully connected layers. Researchers have recently developed numerous classification model structures tailored to specific problems. These models primarily focus on how to extract defect features effectively. For instance, Chen \textit{et al}. presented a defect recognition and classification algorithm rooted in PCA and classification SVM \cite{chen2008defect}. Chang \textit{et al}. utilized SVM, drawing on features like smoothness and texture intricacy, for classifying high-intensity defect images \cite{chang2013hybrid}.  Cheon \textit{et al.} proposed a single CNN model adept at feature extraction \cite{cheon2019convolutional}. 
% When applied to new or unseen defects, these models necessitate retraining, incurring computational overheads. Besides, the classification of defect images requires an abundance of accurately labeled data, making data acquisition challenging.
% They achieved a granular classification of wafer surface defects by recognizing misclassified images and employing a k-nearest neighbors (k-NN) classifier algorithm to gauge the aggregate squared distance between each image feature vector and its k-neighbors within the same category. 

% The classification of defect images requires the formulation of numerous classifiers tailored for myriad inspection steps and an Abundance of accurately labeled data, making data acquisition challenging.
% Moreover, with escalating CNN complexity, the computational demands surge.

% Segmentation of defects is necessary to locate defect positions and gather information such as the size of defects. Unlike classification networks, segmentation networks often use classic encoder-decoder structures such as UNet \cite{ronneberger2015u}, and SegNet \cite{badrinarayanan2017segnet}, which focus on effectively leveraging both local and global feature information. Han Hui \textit{et al}. proposed integrating a Region Proposal Network (RPN) with a UNet architecture to suggest defect areas before conducting defect segmentation \cite{han2020polycrystalline}. This approach enables the segmentation of various defects in wafers with only a limited set of roughly labeled images, enhancing the efficiency of training and application in environments where detailed annotations are scarce. Subhrajit Nag \textit{et al}. introduced a new network structure, WaferSegClassNet \cite{nag2022wafersegclassnet}, which extracts multi-scale local features in the encoder and performs classification and segmentation tasks in the decoder. This model represents the first detection system capable of simultaneously classifying and segmenting surface defects on wafers. However, it relies on extensive data training and annotation for high accuracy and reliability. 

% Recently, Vic De Ridder \textit{et al}. introduced a novel approach for defect segmentation using diffusion models \cite{de2023semi}. This approach treats the instance segmentation task as a denoising process from noise to a filter, utilizing diffusion models to predict and reconstruct instance masks for semiconductor defects. This method achieves high precision and improved defect classification and segmentation detection performance. However, the complex network structure and the computational process of the diffusion model require substantial computational resources. Moreover, the performance of this model heavily relies on high-quality and large amounts of training data. These issues make it less suitable for industrial applications. Additionally, the model has only been applied to detecting and segmenting a single type of defect(bridges) following a specific manufacturing process step, limiting its practical utility in diverse industrial scenarios.

\subsection{Few-shot Anomaly Detection}

%（8.11）Traditional anomaly detection techniques rely on extensive training data to train models for identifying and locating anomalies. However, these methods often face limitations in rapidly changing production environments and diverse anomaly types. Recent research has started exploring effective anomaly detection using few or zero samples to address these challenges.
Traditional anomaly detection relies on extensive training data, which limits its effectiveness in dynamic environments with diverse anomaly types. Recent research has focused on using few or zero samples to overcome these challenges.
Ding \textit{et al.} introduced DRA \cite{ding2022catching}, which, although not specifically mentioning the concept of few-shot learning, effectively identifies both seen and unseen anomalies through disentangled representations by learning from a small number of labeled samples. %of known anomalies.
%Huang \textit{et al.} was the first to propose the anomaly detection method RegAD for few-shot \cite{huang2022regad}. This method pre-trains an object-agnostic registration network with various images to establish the normality of unseen objects. It achieves promising results by aligning image features to identify anomalies, requiring only a small number of normal images and not requiring fine-tuning for new categories.
%（8.9 remove）Huang \textit{et al.} first proposed using few-shot learning in anomaly detection with their method, RegAD \cite{huang2022regad}. This approach achieves promising results by aligning image features to detect anomalies, requiring only a few normal images and no fine-tuning when applying new anomalies.
%（8.9 remove）Despite these advancements, implementing few-shot settings in anomaly detection remains an area ripe for further exploration. 
Recent studies show that pre-trained vision-language models such as CLIP can significantly enhance performance in this task.
%（5.6 remove）Dong \textit{et al.} introduced the MaskCLIP framework, which employs masked self-distillation to enhance contrastive language-image pre-training \cite{zhou2022maskclip}. This approach strengthens the visual encoder's learning of local image patches and uses indirect language supervision to enhance semantic understanding. 
%（5.6 remove）Li \textit{et al.} propose Myriad \cite{li2023myriad}, which incorporates a pre-trained Industrial Anomaly Detection (IAD) model to embed anomaly images as tokens interpretable by the language model, thus providing both detailed descriptions and accurate detections. 
%（8.11）Jeong \textit{et al.} crafted the WinCLIP framework \cite{Jeong_2023_CVPR}, the first method to propose leveraging visual language-based models to improve anomaly detection performance under few-shot settings. They innovatively integrated state words and prompt templates to accurately characterize normal and anomalous states. A novel window-based technique is also introduced to extract and aggregate multi-scale spatial features, boosting the anomaly detection performance.
%（8.11）Gu \textit{et al.} presented AnomalyGPT \cite{gu2024anomalygpt}, a method based on large vision-language models trained using simulated anomalous images and corresponding textual descriptions, which can effectively evaluate anomalies' locations.
%（8.11）Chen \textit{et al.} introduced CLIP-AD (zero-shot) \cite{chen2023clip}, and Li \textit{et al.} proposed PromptAD (few-shot) \cite{li2024promptad}, both employing dual-path model structures and feature surgery \cite{li2023clip}. These methods effectively address the challenges of using the CLIP model directly for anomaly detection.
%These approaches effectively address issues encountered when directly calculating anomaly maps using the CLIP model. 
Jeong \textit{et al.} developed WinCLIP \cite{Jeong_2023_CVPR}, the first framework to use visual language models for few-shot anomaly detection, integrating state words and prompt templates with a novel window-based technique for improved performance. Gu \textit{et al.} introduced AnomalyGPT \cite{gu2024anomalygpt}, leveraging large vision-language models trained on simulated anomalies to effectively locate them.
Chen \textit{et al.} proposed CLIP-AD (zero-shot) \cite{chen2023clip}, and Li \textit{et al.} introduced PromptAD (few-shot) \cite{li2024promptad}, both using dual-path models and feature surgery to enhance CLIP’s anomaly detection capabilities.

%（5.6 remove）These studies extend the boundaries of traditional anomaly detection techniques and demonstrate how to effectively address changing and sample-scarce environments rapidly through few-shot learning methods. Despite these advancements, implementing few-shot settings in anomaly detection remains an area ripe for further exploration. Recent studies show that pre-trained vision-language models such as CLIP and MiniGPT can significantly enhance performance in anomaly detection tasks. Our research extends the CLIP method to support SEM image defect detection. 
%（8.11）These studies extend the boundaries of traditional anomaly detection techniques and demonstrate how to effectively address changing and sample-scarce environments rapidly through few-shot learning methods. Our research extends the CLIP method to support SEM image defect detection. 
These studies push the boundaries of traditional anomaly detection, showing how few-shot learning can rapidly and effectively address dynamic, data-scarce environments. Our research extends the CLIP method to support SEM image defect detection. 

% Specifically, CLIP-AD optimizes the utilization of multi-layer features, corrects feature misalignment, and enhances model performance through additional linear layer fine-tuning. PromptAD connects normal prompts with anomaly suffixes to form anomaly prompts, enabling contrastive learning in a single-class setting.
% Despite these advancements, implementing few-shot settings in anomaly detection remains an area ripe for further exploration. Recent studies show that pre-trained vision-language models such as CLIP and MiniGPT can significantly enhance performance in anomaly detection tasks.
% It significantly improves transferability and pretraining outcomes across various visual tasks, although it requires substantial computational resources.

\subsection{Problem Definition}
\begin{myproblem} [Few-shot Learning for SEM Image Defect Detection]

Given dataset of $N$-way $K$-shot SEM images $\vec{X} = \{\vec{x}_1, \vec{x}_2 \cdots, \vec{x}_{K \cdot N}\}$, annotated with classification labels $ \vec{Y}^c = \{\vec{y}_1^c, \vec{y}_2^c, \cdots, \vec{y}_{K \cdot N}^c\}$ and segmentation masks $\vec{Y} ^s = \{\vec{y}_1^s, \vec{y}_2^s, \cdots, \vec{y}_{K \cdot N}^s\}$. Typically, $N$ represents the total number of categories in the dataset, including the ``good'' (non-defect) category, and all defect categories. $K$ is a small number denoting the number of images for each category, such as 1, 2, or 10, which is why this is referred to as few-shot learning. 
We aim to construct a model with few-shot learning capabilities based on the $\vec{X}$. It can generate accurate defect classification labels and pixel-level segmentation results for the $M$ SEM image testing set with $M \gg K$. By default, $N=7$ in our context without further explanations. 

\end{myproblem}
