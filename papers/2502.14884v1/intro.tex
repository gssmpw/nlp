
\section{Introduction}
\label{sec:introduction}

Semiconductor manufacturing is a complex and multifaceted process where defects occur due to ill processes or equipment issues. To provide real-time monitoring for the fabrication, SEM images are captured and then classified based on the appearance of the defects, helping the defect detection and root cause analysis. 
Unlike rough wafer-level defect maps, SEM images can provide more detailed characteristics of defects, thereby helping to determine the specific process steps and equipment. Currently, defect detection primarily relies on manual efforts, making it both cumbersome and error-prone. Developing an automated defect detection system has become a trend.

The current wafer surface defect detection and classification research predominantly employs supervised learning methods, requiring substantial amounts of data and detailed annotated labels. Some methods are presented to classify defects \cite{chen2008defect, chang2013hybrid, cheon2019convolutional}. Furthermore, some segmentation methods are proposed to provide detailed location and shape information \cite{ronneberger2015u, badrinarayanan2017segnet, nag2022wafersegclassnet}. Although these methods achieve outstanding performance, they usually require many annotated data for training, resulting in heavy workloads. Besides, these methods also suffer from poor transferability for new defect detection due to a lack of adequate training data. Annotated data is always precious in industry.

\begin{figure}[tb!]
  \centering
  \includegraphics[width=\linewidth]{figs/flow.pdf}
  \caption{The workflow of SEM image defect analysis. We replace the cumbersome manual defect detection flow with our automatic SEM-CLIP method, substantially enhancing defect detection performance with few-shot learning as the shining point. 
}
  \label{fig:workflow}
\end{figure}

Consequently, there has been a shift in the field of industrial defect detection toward unsupervised or self-supervised anomaly segmentation methods \cite{zavrtanik2021draem, jiang2022masked, jiang2022softpatch, wang2023multimodal}. These approaches only require normal samples to learn their distribution, and they detect anomalies by calculating the distributional differences between test samples and normal samples. However, this method still requires a substantial number of normal samples for training. Due to the highly variable backgrounds where defects occur, there are significant differences among normal samples, making applying this approach in wafer surface defect detection scenarios challenging.

Recently, pre-trained vision-language models like CLIP \cite{radford2021learning} and SAM \cite{kirillov2023segany} have rapidly advanced, utilizing prompts to access stored prior knowledge and thus exhibiting strong zero-shot visual perception capabilities \cite{Li_Li_Li_Niebles_Hoi_2022}. Considering this, we are exploring using a CLIP model-based approach to address data scarcity issues. However, given the unique aspects of integrated circuit application scenarios, the text-image pairs used in network pre-training may contain minimal or no SEM images of semiconductors. Consequently, it becomes essential to adjust the base structure of the CLIP model and to incorporate a small number of SEM images of both normal and anomalous samples as support images for the target categories. These adaptations will enable the model to more effectively recognize and classify the specific types of defects encountered in semiconductor manufacturing.

This strategy allows us to leverage the model's inherent ability to understand complex visual concepts through minimal samples, adapting it to the specific requirements of semiconductor manufacturing. We can create a more efficient and effective model for detecting and classifying wafer surface defects without heavily relying on large, annotated datasets. To this end, we propose SEM-CLIP, a crafted CLIP method for defect detection, following the few-shot learning mechanism. The contributions of our work are summarized as follows:
\begin{itemize}
    \item We propose a novel few-shot learning-based approach, SEM-CLIP, for accurate SEM image defect classification and segmentation with little data and label requirements. To the best of our knowledge, it is the first few-shot learning work for SEM-level IC defect detection tasks. 
    \item We customize the Contrastive Language-Image Pretraining model to focus on the defect areas and adopt a novel feature extraction method by adding $V$-$V$ attention blocks to minimize the complex background distractions and improve the segmentation accuracies.
    \item Prompts enriched with expert knowledge are crafted and employed as prior information to guide both classification and segmentation processes. Feature engineering with textual guidance is incorporated with a classification head to boost the classification performance. 
    \item We conduct comprehensive experiments across various few-shot settings, benchmarked on an in-house SEM image defect dataset. The results demonstrate that our method significantly outperforms others in terms of iAUROC, pAUROC, and $F1$-$max$ scores. For instance, 
    %SEM-CLIP surpasses the recent SOTA method AnomalyGPT, showing improvements of $13.4$, $2.1$, and $17.1$, 
    SEM-CLIP surpasses the recent SOTA method PromptAD, showing improvements of $2.0\%$, $1.3\%$, and $21.1\%$, respectively, under the 10-shot setting. Our approach will help fabs alleviate the issues of insufficient labeling and expensive labor, thereby facilitating intelligent manufacturing.
    
\end{itemize}

% The remainder of this paper is organized as follows.
% \Cref{sec:preliminaries} introduces the related work and our dataset.
% \Cref{sec:framework} provides detailed explanations of our SEM-CLIP.
% \Cref{sec:experiments} conducts comprehensive experiments on the SEM image dataset to confirm the outstanding performance of the proposed framework.
% Finally, \Cref{sec:conclusions} concludes this paper.

