\begin{figure}[h]
\centering

\begin{subfigure}[b]{0.5\linewidth}
\centering
\includegraphics[decodearray={1 0}, width=0.33\linewidth]{figures/images/rope_dynamic_0.png}%
\includegraphics[decodearray={1 0}, width=0.33\linewidth]{figures/images/rope_dynamic_1.png}%
\includegraphics[decodearray={1 0}, width=0.33\linewidth]{figures/images/rope_dynamic_2.png}%
\caption{Dynamic Extend (SelfExtend-style)}
\end{subfigure}%
\begin{subfigure}[b]{0.5\linewidth}
\centering
\includegraphics[decodearray={1 0}, width=0.33\linewidth]{figures/images/rope_streaming_0.png}%
\includegraphics[decodearray={1 0}, width=0.33\linewidth]{figures/images/rope_streaming_1.png}%
\includegraphics[decodearray={1 0}, width=0.33\linewidth]{figures/images/rope_streaming_2.png}%
\caption{Chunk-indexed}
\end{subfigure}%

\begin{subfigure}[b]{0.5\linewidth}
\centering
\includegraphics[decodearray={1 0}, width=0.33\linewidth]{figures/images/rope_relative_0.png}%
\includegraphics[decodearray={1 0}, width=0.33\linewidth]{figures/images/rope_relative_1.png}%
\includegraphics[decodearray={1 0}, width=0.33\linewidth]{figures/images/rope_relative_2.png}%
\caption{Relative}
\end{subfigure}%
\begin{subfigure}[b]{0.5\linewidth}
\centering
\includegraphics[decodearray={1 0}, width=0.33\linewidth]{figures/images/rope_infllm_0.png}%
\includegraphics[decodearray={1 0}, width=0.33\linewidth]{figures/images/rope_infllm_1.png}%
\includegraphics[decodearray={1 0}, width=0.33\linewidth]{figures/images/rope_infllm_2.png}%
\caption{InfLLM}
\end{subfigure}%

\caption{\textbf{Visualization of Each Stage of Each RoPE Adjustment Method.} From left, we visualize the output of stages 1, 2, and 3. We use Llama 3.2 1B and T=256K. The model's pretrained context length is 128K. The horizontal axis represents the key sequence dimension, and the vertical axis represents the query sequence dimension. We color non-zero entries in the attention matrix as blocks and masked-out entries as white.}
\label{fig:stages}
\end{figure}