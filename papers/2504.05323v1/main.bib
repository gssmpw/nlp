\\introduction
@article{10.1111/jcc4.12178,
    author = {Liang, Hai and Fu, King-wa},
    title = {Information Overload, Similarity, and Redundancy: Unsubscribing Information Sources on Twitter},
    journal = {Journal of Computer-Mediated Communication},
    volume = {22},
    number = {1},
    pages = {1-17},
    year = {2016},
    month = {11},
    abstract = {The emergence of social media has changed individuals' information consumption patterns. The purpose of this study is to explore the role of information overload, similarity, and redundancy in unsubscribing information sources from users' information repertoires. In doing so, we randomly selected nearly 7,500 ego networks on Twitter and tracked their activities in 2 waves. A multilevel logistic regression model was deployed to test our hypotheses. Results revealed that individuals (egos) obtain information by following a group of stable users (alters). An ego's likelihood of unfollowing alters is negatively associated with their information similarity, but is positively associated with both information overload and redundancy. Furthermore, relational factors can modify the impact of information redundancy on unfollowing.},
    issn = {1083-6101},
    doi = {10.1111/jcc4.12178},
    url = {https://doi.org/10.1111/jcc4.12178},
    eprint = {https://academic.oup.com/jcmc/article-pdf/22/1/1/22316339/jjcmcom0001.pdf},
}

@article{doi:10.1287/orsc.1100.0634,
author = {Mariotti, Francesca and Delbridge, Rick},
title = {Overcoming Network Overload and Redundancy in Interorganizational Networks: The Roles of Potential and Latent Ties},
journal = {Organization Science},
volume = {23},
number = {2},
pages = {511-528},
year = {2012},
doi = {10.1287/orsc.1100.0634},
URL = {  https://doi.org/10.1287/orsc.1100.0634},
eprint = {  https://doi.org/10.1287/orsc.1100.0634},
abstract = { This paper builds on Granovetter's distinction between strong and weak ties [Granovetter, M. S. 1973. The strength of weak ties. Amer. J. Sociol. 78(6) 1360–1380] in order to respond to recent calls for a more dynamic and processual understanding of networks. The concepts of potential and latent tie are deductively identified, and their implications for understanding how and why networks emerge, evolve, and change are explored. A longitudinal empirical study conducted with companies operating in the European motorsport industry reveals that firms take strategic actions to search for potential ties and reactivate latent ties in order to solve problems of network redundancy and overload. Examples are given, and their characteristics are examined to provide theoretical elaboration of the relationship between the types of tie and network evolution. These conceptual and empirical insights move understanding of the managerial challenge of building effective networks beyond static structural contingency models of optimal network forms to highlight the processes and capabilities of dynamic relationship building and network development. In so doing, this paper highlights the interrelationship between search and redundancy and the scope for strategic action alongside path dependence and structural influences on network processes. }
}

@ARTICLE{10.3389/fpsyg.2023.1122200,

AUTHOR={Arnold, Miriam  and Goldschmitt, Mascha  and Rigotti, Thomas },

TITLE={Dealing with information overload: a comprehensive review},

JOURNAL={Frontiers in Psychology},

VOLUME={14},

YEAR={2023},

URL={https://doi.org/10.3389/fpsyg.2023.1122200},

DOI={10.3389/fpsyg.2023.1122200},

ISSN={1664-1078},

ABSTRACT={<p>Information overload is a problem that is being exacerbated by the ongoing digitalization of the world of work and the growing use of information and communication technologies. Therefore, the aim of this systematic literature review is to provide an insight into existing measures for prevention and intervention related to information overload. The methodological approach of the systematic review is based on the PRISMA standards. A keyword search in three interdisciplinary scientific databases and other more practice-oriented databases resulted in the identification of 87 studies, field reports, and conceptual papers that were included in the review. The results show that a considerable number of papers have been published on interventions on the behavioral prevention level. At the level of structural prevention, there are also many proposals on how to design work to reduce information overload. A further distinction can be made between work design approaches at the level of information and communication technology and at the level of teamwork and organizational regulations. Although the identified studies cover a wide range of possible interventions and design approaches to address information overload, the strength of the evidence from these studies is mixed.</p>}}


@INPROCEEDINGS{4781121,
  author={Hu, Yifan and Koren, Yehuda and Volinsky, Chris},
  booktitle={2008 Eighth IEEE International Conference on Data Mining}, 
  title={Collaborative Filtering for Implicit Feedback Datasets}, 
  year={2008},
  volume={},
  number={},
  pages={263-272},
  keywords={Filtering;Recommender systems;History;TV;Motion pictures;Negative feedback;Watches;Data mining;International collaboration;Demography;Collaborative filtering;recommender system;implicit feedback},
  doi={10.1109/ICDM.2008.22},
  url={https://doi.org/10.1109/ICDM.2008.22}
}
\\\\协同过滤
@inproceedings{10.1145/3460231.3478854,
author = {Kawakami, Yuhi and Sugiyama, Mahito},
title = {Investigating Overparameterization for Non-Negative Matrix Factorization in Collaborative Filtering},
year = {2021},
isbn = {9781450384582},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3460231.3478854},
doi = {10.1145/3460231.3478854},
abstract = {Overparameterization is one of the key techniques in modern machine learning, where a model with the higher complexity can generalize better on test data against the common knowledge of the bias-variance trade-off in classical statistical learning theory. In this paper, we empirically investigate the effect of overparameterization for matrix factorization-based models in collaborative filtering. Surprisingly, we firstly show that the performance of overparameterized non-negative matrix factorization (NMF) on test data gets better than that of the underparameterized NMF, which is commonly used to date, and is even competitive with the state-of-the-art collaborative filtering techniques. Moreover, we also show that the double descent phenomenon occurs when we increase the number of parameters of the NMF, where the test error decreases, increases, and decreases again as the model complexity grows, which has been recently reported in various machine learning methods such as deep learning models and kernel methods.},
booktitle = {Proceedings of the 15th ACM Conference on Recommender Systems},
pages = {685–690},
numpages = {6},
keywords = {collaborative filtering, non-negative matrix factorization, overparameterization, recommender system},
location = {Amsterdam, Netherlands},
series = {RecSys '21}
}

@article{FANG2022109044,
title = {Differentially private recommender system with variational autoencoders},
journal = {Knowledge-Based Systems},
volume = {250},
pages = {109044},
year = {2022},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2022.109044},
url = {https://doi.org/10.1016/j.knosys.2022.109044},
author = {Le Fang and Bingqian Du and Chuan Wu},
keywords = {Recommender system, Differential privacy, Variational autoencoders},
abstract = {To provide precise recommendations, traditional recommender systems (RS) collect personal data, user preference and feedback, which are sensitive to each user if such information is maliciously used for extra analysis. In recent years, differential privacy (DP) has been widely applied in RS to provide privacy protection for sensitive information. Prior studies explored the combination of DP and RS, while neglecting the disparate effect on model accuracy of imbalanced subgroups as large user groups control the trained model, and DP can worsen the disparate effect of degrading the performance of recommender systems significantly. Besides, the number of uploaded contributions can differ among users for training a recommender system, so it is necessary to set the user-level privacy guarantee. In this paper, we make four contributions. First, we propose an efficient way of constructing datasets for training a recommender system based on prior theories. Second, we compute the user-level priors based on user metadata to optimize the VAE model. Besides, we add noise into the calculation process to protect user metadata. Third, we analyze and propose a tighter theoretical bound on gradient updates for DP Stochastic Gradient Descent (DPSGD). Finally, we exploit these theoretical results and propose a novel DP-VAE based recommender system. Extensive experimental results on multiple datasets show that our system can achieve high recommendation precision while maintaining a reasonable privacy guarantee.}
}

@inproceedings{10.1145/3459637.3482354,
author = {Xia, Jiafeng and Li, Dongsheng and Gu, Hansu and Lu, Tun and Zhang, Peng and Gu, Ning},
title = {Incremental Graph Convolutional Network for Collaborative Filtering},
year = {2021},
isbn = {9781450384469},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3459637.3482354},
doi = {10.1145/3459637.3482354},
abstract = {Graph neural networks (GNN) recently achieved huge success in collaborative filtering (CF) due to the useful graph structure information. However, users will continuously interact with items, which causes the user-item interaction graphs to change over time and well-trained GNN models to be out-of-date soon. Naive solutions such as periodic retraining lose important temporal information and are computationally expensive. Recent works that leverage recurrent neural networks to keep GNN up-to-date may suffer from the "catastrophic forgetting'' issue, and experience a cold start with new users and items. To this end, we propose the incremental graph convolutional network (IGCN) --- a pure graph convolutional network (GCN) based method to update GNN models when new user-item interactions are available. IGCN consists of two main components: 1) a historical feature generation layer, which generates the initial user/item embedding via model agnostic meta-learning and ensures good initial states and fast model adaptation; 2) a temporal feature learning layer, which first aggregates the features from local neighborhood to update the embedding of each user/item within each subgraph via graph convolutional network and then fuses the user/item embeddings from last subgraph and current subgraph via incremental temporal convolutional network. Experimental studies on real-world datasets show that IGCN can outperform state-of-the-art CF algorithms in sequential recommendation tasks.},
booktitle = {Proceedings of the 30th ACM International Conference on Information \& Knowledge Management},
pages = {2170–2179},
numpages = {10},
keywords = {incremental recommendation, graph neural network, collaborative filtering},
location = {Virtual Event, Queensland, Australia},
series = {CIKM '21}
}

\\\\应用领域
@inproceedings{10.1145/3411564.3411572,
author = {Campos, Rodrigo and dos Santos, Rodrigo Pereira and Oliveira, Jonice},
title = {A Recommendation System based on Knowledge Gap Identification in MOOCs Ecosystems},
year = {2020},
isbn = {9781450388733},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411564.3411572},
doi = {10.1145/3411564.3411572},
abstract = {The consolidation of recommendation systems in a big data era brings opportunities in different scenarios to customize methods that recommend data. In the scenarios of the Massive Open Online Courses (MOOCs) ecosystems, these recommenders mainly support students in choosing the best courses from the platforms. However, the expansion of course platforms and the scarcity of student data increases the difficulty in finding courses, or even part of courses, that fill a given knowledge gap. In this paper, we propose a recommendation system to support students in finding the best modules or courses in these ecosystems. First, topic modeling techniques were implemented with Non-negative Matrix Factorization (NMF) to find similarities between multiple MOOCs providers. Then, a content-based recommendation provides recommendations to a user interested in acquiring new knowledge, based on a history extraction on those platforms. We evaluate our approach through an experiment with real data collected in multiple MOOCs providers. In addition, by comparing the NMF approach with a baseline Latent Dirichlet Allocation (LDA) technique, we verify the model effectiveness and show that our system is useful to this context.},
booktitle = {Proceedings of the XVI Brazilian Symposium on Information Systems},
articleno = {2},
numpages = {8},
keywords = {topic modeling, recommendation system, non-negative matrix factorization, MOOCs ecosystems},
location = {S\~{a}o Bernardo do Campo, Brazil},
series = {SBSI '20}
}

@inproceedings{10.1145/1458082.1458205,
author = {Ma, Hao and Yang, Haixuan and Lyu, Michael R. and King, Irwin},
title = {SoRec: social recommendation using probabilistic matrix factorization},
year = {2008},
isbn = {9781595939913},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1458082.1458205},
doi = {10.1145/1458082.1458205},
abstract = {Data sparsity, scalability and prediction quality have been recognized as the three most crucial challenges that every collaborative filtering algorithm or recommender system confronts. Many existing approaches to recommender systems can neither handle very large datasets nor easily deal with users who have made very few ratings or even none at all. Moreover, traditional recommender systems assume that all the users are independent and identically distributed; this assumption ignores the social interactions or connections among users. In view of the exponential growth of information generated by online social networks, social network analysis is becoming important for many Web applications. Following the intuition that a person's social network will affect personal behaviors on the Web, this paper proposes a factor analysis approach based on probabilistic matrix factorization to solve the data sparsity and poor prediction accuracy problems by employing both users' social network information and rating records. The complexity analysis indicates that our approach can be applied to very large datasets since it scales linearly with the number of observations, while the experimental results shows that our method performs much better than the state-of-the-art approaches, especially in the circumstance that users have made few or no ratings.},
booktitle = {Proceedings of the 17th ACM Conference on Information and Knowledge Management},
pages = {931–940},
numpages = {10},
keywords = {collaborative filtering, matrix factorization, recommender systems, social recommendation},
location = {Napa Valley, California, USA},
series = {CIKM '08}
}

@article{Braunhofer2014TechniquesFC,
  title={Techniques for cold-starting context-aware mobile recommender systems for tourism},
  author={Matthias Braunhofer and Mehdi Elahi and Francesco Ricci},
  journal={Intelligenza Artificiale},
  year={2014},
  volume={8},
  pages={129-143},
  url={https://doi.org/10.3233/IA-140069}
}

\\\\基于内容
@article{HUANG2022108596,
title = {Context-aware road travel time estimation by coupled tensor decomposition based on trajectory data},
journal = {Knowledge-Based Systems},
volume = {245},
pages = {108596},
year = {2022},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2022.108596},
url = {https://doi.org/10.1016/j.knosys.2022.108596},
author = {Liping Huang and Yongjian Yang and Hechang Chen and Yunke Zhang and Zijia Wang and Lifang He},
keywords = {Sparse data, Context aware, Trajectory, Tensor decomposition, Road travel time},
abstract = {Urban road travel time estimation and prediction on a citywide scale is a necessary and important task for recommending optimal travel paths. However, this problem has not yet been well addressed: most existing approaches face serious data sparsity issues, e.g., lack of sensor data on several road segments; and it is a difficult task to capture context patterns around the road and incorporate context-aware information into travel time estimation models. Because of this, we propose to utilize trajectory data to model road travel times as this type of data covers more urban road segments than data from traditional traffic monitoring systems. Moreover, the trajectory itself has involved both travel times and the context of road congestion. A general framework for context-aware road travel time estimation (CARTE) is then put forward. Specifically, we adopt a third-order tensor to model spatiotemporal road travel times by setting the congestion level as a third dimension. By incorporating another context-aware information, namely points of interest (POI), a coupled tensor decomposition algorithm is proposed to fill in missing data. Eventually, we propose an algorithm to calculate an ultimate two-dimensional (spatial and temporal) travel time matrix by weighting the congestion probabilities of each congestion level. The effectiveness of the CARTE was validated on two real-world datasets and it was compared to the state-of-the-art methods. The experimental results demonstrate that the proposed travel time prediction approach always achieves the best performance in terms of accuracy with different data sparsity and prediction horizons.}
}

@article{DELCARMENRODRIGUEZHERNANDEZ2021106740,
title = {AI-based mobile context-aware recommender systems from an information management perspective: Progress and directions},
journal = {Knowledge-Based Systems},
volume = {215},
pages = {106740},
year = {2021},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2021.106740},
url = {https://doi.org/10.1016/j.knosys.2021.106740},
author = {María {del Carmen Rodríguez-Hernández} and Sergio Ilarri},
keywords = {Context-Aware Recommender Systems, Mobile computing, Context-aware computing, Personalization, Information management},
abstract = {In the Artificial Intelligence (AI) field, and particularly within the area of Machine Learning (ML), recommender systems have attracted significant research attention. These systems attempt to alleviate the increasing information overload that users can experience in the current Big Data era, by providing personalized recommendations of items that they may find relevant. Besides, given the importance of mobile computing, these systems have evolved to consider also the dynamic context of the mobile users (location, time, weather conditions, etc.) to offer them more appropriate suggestions and information while on the move. In this paper, we provide an extensive survey of recent advances towards intelligent mobile Context-Aware Recommender Systems (mobile CARS) from an information management perspective, with an emphasis on mobile computing and AI techniques, along with an analysis of existing research gaps and future research directions. We focus on approaches that go beyond just considering the location of the user and exploit also other context information. In this study, we have identified that deep learning approaches are promising artificial intelligence models for mobile CARS. Additionally, in a near future, we expect a higher prominence of push-based recommendation solutions where at least part of the recommendation engine could be executed in the mobile devices, which could share data and tasks in a distributed way.}
}

@INPROCEEDINGS{9773925,
  author={Nawara, Dina and Kashef, Rasha},
  booktitle={2022 IEEE International Systems Conference (SysCon)}, 
  title={Context-Aware Recommendation Systems Using Consensus-Clustering}, 
  year={2022},
  volume={},
  number={},
  pages={1-8},
  keywords={Scalability;Conferences;Clustering algorithms;Real-time systems;Bipartite graph;Time factors;Context-Aware Recommenders;Scalability;Sparsity Consensus Clustering;Pre-Filtering;Post-Filtering},
  doi={https://doi.org/10.1109/SysCon53536.2022.9773925}}


\\\\混合的
@inproceedings{10.1145/3460231.3474272,
author = {Polignano, Marco and Musto, Cataldo and de Gemmis, Marco and Lops, Pasquale and Semeraro, Giovanni},
title = {Together is Better: Hybrid Recommendations Combining Graph Embeddings and Contextualized Word Representations},
year = {2021},
isbn = {9781450384582},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3460231.3474272},
doi = {10.1145/3460231.3474272},
abstract = {In this paper, we present a hybrid recommendation framework based on the combination of graph embeddings and contextual word representations. Our approach is based on the intuition that each of the above mentioned representation models heterogeneous (and equally important) information, that is worth to be taken into account to generate a recommendation. Accordingly, we propose a strategy to combine both the features, which is based on the following steps: first, we separately generate graph embeddings and contextual word representations by exploiting state-of-the-art techniques. Next, these embeddings are used to feed a deep architecture that learns a hybrid representation based on the combination of the single groups of features. Finally, we exploit the resulting embedding to identify suitable recommendations. In the experimental session, we evaluate the effectiveness of our strategy on two datasets and results show that the use of a hybrid representation leads to an improvement of the predictive accuracy. Moreover, our approach overcomes several competitive baselines, thus confirming the validity of this work.},
booktitle = {Proceedings of the 15th ACM Conference on Recommender Systems},
pages = {187–198},
numpages = {12},
keywords = {recommender systems, graph embeddings, deep learning, USE embeddings, BERT embeddings},
location = {Amsterdam, Netherlands},
series = {RecSys '21}
}

@inproceedings{10.1145/3511808.3557354,
author = {Luo, Sichun and Zhang, Xinyi and Xiao, Yuanzhang and Song, Linqi},
title = {HySAGE: A Hybrid Static and Adaptive Graph Embedding Network for Context-Drifting Recommendations},
year = {2022},
isbn = {9781450392365},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3511808.3557354},
doi = {10.1145/3511808.3557354},
abstract = {The recent popularity of edge devices and Artificial Intelligent of Things (AIoT) has driven a new wave of contextual recommendations, such as location based Point of Interest (PoI) recommendations and computing resource-aware mobile app recommendations. In many such recommendation scenarios, contexts are drifting over time. For example, in a mobile game recommendation, contextual features like locations, battery, and storage levels of mobile devices are frequently drifting over time. However, most existing graph-based collaborative filtering methods are designed under the assumption of static features. Therefore, they would require frequent retraining and/or yield graphical models burgeoning in sizes, impeding their suitability for context-drifting recommendations.In this work, we propose a specifically tailor-made Hybrid Static and Adaptive Graph Embedding (HySAGE) network for context-drifting recommendations. Our key idea is to disentangle the relatively static user-item interaction and rapidly drifting contextual features. Specifically, our proposed HySAGE network learns a relatively static graph embedding from user-item interaction and an adaptive embedding from drifting contextual features. These embeddings are incorporated into an interest network to generate the user interest in some certain context. We adopt an interactive attention module to learn the interactions among static graph embeddings, adaptive contextual embeddings, and user interest, helping to achieve a better final representation. Extensive experiments on real-world datasets demonstrate that HySAGE significantly improves the performance of the existing state-of-the-art recommendation algorithms.},
booktitle = {Proceedings of the 31st ACM International Conference on Information \& Knowledge Management},
pages = {1389–1398},
numpages = {10},
keywords = {attention, context-aware recommendation, graph embedding, recommender system},
location = {Atlanta, GA, USA},
series = {CIKM '22}
}

@ARTICLE{9723533,
  author={Zhu, Yaochen and Chen, Zhenzhong},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={Variational Bandwidth Auto-Encoder for Hybrid Recommender Systems}, 
  year={2023},
  volume={35},
  number={5},
  pages={5371-5385},
  keywords={Collaboration;Uncertainty;Feature extraction;Bandwidth;Recommender systems;Noise measurement;Measurement uncertainty;Auto-encoders;information bottleneck;recommender systems;uncertainty modeling;variational inference},
  doi={https://doi.org/10.1109/TKDE.2022.3155408}}

\\\\序列推荐
@inproceedings{10.1145/3511808.3557268,
author = {Wang, Yu and Zhang, Hengrui and Liu, Zhiwei and Yang, Liangwei and Yu, Philip S.},
title = {ContrastVAE: Contrastive Variational AutoEncoder for Sequential Recommendation},
year = {2022},
isbn = {9781450392365},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3511808.3557268},
doi = {10.1145/3511808.3557268},
abstract = {Aiming at exploiting the rich information in user behaviour sequences, sequential recommendation has been widely adopted in real-world recommender systems. However, current methods suffer from the following issues: 1) sparsity of user-item interactions, 2) uncertainty of sequential records, 3) long-tail items. In this paper, we propose to incorporate contrastive learning into the framework of Variational AutoEncoders to address these challenges simultaneously. Firstly, we introduce ContrastELBO, a novel training objective that extends the conventional single-view ELBO to two-view case and theoretically builds a connection between VAE and contrastive learning from a two-view perspective. Then we propose Contrastive Variational AutoEncoder (ContrastVAE in short), a two-branched VAE model with contrastive regularization as an embodiment of ContrastELBO for sequential recommendation. We further introduce two simple yet effective augmentation strategies named model augmentation and variational augmentation to create a second view of a sequence and thus making contrastive learning possible. Experiments on four benchmark datasets demonstrate the effectiveness of ContrastVAE and the proposed augmentation methods. Codes are available at https://github.com/YuWang-1024/ContrastVAE},
booktitle = {Proceedings of the 31st ACM International Conference on Information \& Knowledge Management},
pages = {2056–2066},
numpages = {11},
keywords = {contrastive learning, sequential recommendation, variational autoencoder},
location = {Atlanta, GA, USA},
series = {CIKM '22}
}

@inproceedings{10.1145/3604915.3608857,
author = {Bao, Keqin and Zhang, Jizhi and Zhang, Yang and Wang, Wenjie and Feng, Fuli and He, Xiangnan},
title = {TALLRec: An Effective and Efficient Tuning Framework to Align Large Language Model with Recommendation},
year = {2023},
isbn = {9798400702419},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3604915.3608857},
doi = {10.1145/3604915.3608857},
abstract = {Large Language Models (LLMs) have demonstrated remarkable performance across diverse domains, thereby prompting researchers to explore their potential for use in recommendation systems. Initial attempts have leveraged the exceptional capabilities of LLMs, such as rich knowledge and strong generalization through In-context Learning, which involves phrasing the recommendation task as prompts. Nevertheless, the performance of LLMs in recommendation tasks remains suboptimal due to a substantial disparity between the training tasks for LLMs and recommendation tasks, as well as inadequate recommendation data during pre-training. To bridge the gap, we consider building a Large Recommendation Language Model by tunning LLMs with recommendation data. To this end, we propose an efficient and effective Tuning framework for Aligning LLMs with Recommendations, namely TALLRec. We have demonstrated that the proposed TALLRec framework can significantly enhance the recommendation capabilities of LLMs in the movie and book domains, even with a limited dataset of fewer than 100 samples. Additionally, the proposed framework is highly efficient and can be executed on a single RTX 3090 with LLaMA-7B. Furthermore, the fine-tuned LLM exhibits robust cross-domain generalization. Our code and data are available at https://github.com/SAI990323/TALLRec.},
booktitle = {Proceedings of the 17th ACM Conference on Recommender Systems},
pages = {1007–1014},
numpages = {8},
keywords = {Instruction Tuning, Large Language Models, Recommendation},
location = {Singapore, Singapore},
series = {RecSys '23}
}

@inproceedings{ijcai2023p254,
  title     = {Self-supervised Graph Disentangled Networks for Review-based Recommendation},
  author    = {Ren, Yuyang and Zhang, Haonan and Li, Qi and Fu, Luoyi and Wang, Xinbing and Zhou, Chenghu},
  booktitle = {Proceedings of the Thirty-Second International Joint Conference on
               Artificial Intelligence, {IJCAI-23}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  editor    = {Edith Elkind},
  pages     = {2288--2295},
  year      = {2023},
  month     = {8},
  note      = {Main Track},
  doi       = {10.24963/ijcai.2023/254},
  url       = {https://doi.org/10.24963/ijcai.2023/254},
}

@inproceedings{10.1145/3539618.3591679,
author = {Du, Hanwen and Yuan, Huanhuan and Zhao, Pengpeng and Zhuang, Fuzhen and Liu, Guanfeng and Zhao, Lei and Liu, Yanchi and Sheng, Victor S.},
title = {Ensemble Modeling with Contrastive Knowledge Distillation for Sequential Recommendation},
year = {2023},
isbn = {9781450394086},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3539618.3591679},
doi = {10.1145/3539618.3591679},
abstract = {Sequential recommendation aims to capture users' dynamic interest and predicts the next item of users' preference. Most sequential recommendation methods use a deep neural network as sequence encoder to generate user and item representations. Existing works mainly center upon designing a stronger sequence encoder. However, few attempts have been made with training an ensemble of networks as sequence encoders, which is more powerful than a single network because an ensemble of parallel networks can yield diverse prediction results and hence better accuracy. In this paper, we present Ensemble Modeling with contrastive Knowledge Distillation for sequential recommendation (EMKD). Our framework adopts multiple parallel networks as an ensemble of sequence encoders and recommends items based on the output distributions of all these networks. To facilitate knowledge transfer between parallel networks, we propose a novel contrastive knowledge distillation approach, which performs knowledge transfer from the representation level via Intra-network Contrastive Learning (ICL) and Cross-network Contrastive Learning (CCL), as well as Knowledge Distillation (KD) from the logits level via minimizing the Kullback-Leibler divergence between the output distributions of the teacher network and the student network. To leverage contextual information, we train the primary masked item prediction task alongside the auxiliary attribute prediction task as a multi-task learning scheme. Extensive experiments on public benchmark datasets show that EMKD achieves a significant improvement compared with the state-of-the-art methods. Besides, we demonstrate that our ensemble method is a generalized approach that can also improve the performance of other sequential recommenders. Our code is available at this link: https://github.com/hw-du/EMKD.},
booktitle = {Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {58–67},
numpages = {10},
keywords = {contrastive learning, knowledge distillation, sequential recommendation},
location = {Taipei, Taiwan},
series = {SIGIR '23}
}


@InProceedings{pmlr-v235-silva24b,
  title = 	 {On the Unexpected Effectiveness of Reinforcement Learning for Sequential Recommendation},
  author =       {Silva, \'{A}lvaro Labarca and Parra, Denis and Icarte, Rodrigo Toro},
  booktitle = 	 {Proceedings of the 41st International Conference on Machine Learning},
  pages = 	 {45432--45450},
  year = 	 {2024},
  editor = 	 {Salakhutdinov, Ruslan and Kolter, Zico and Heller, Katherine and Weller, Adrian and Oliver, Nuria and Scarlett, Jonathan and Berkenkamp, Felix},
  volume = 	 {235},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {21--27 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://raw.githubusercontent.com/mlresearch/v235/main/assets/silva24b/silva24b.pdf},
  url = 	 {https://proceedings.mlr.press/v235/silva24b.html},
  abstract = 	 {In recent years, Reinforcement Learning (RL) has shown great promise in session-based recommendation. Sequential models that use RL have reached state-of-the-art performance for the Next-item Prediction (NIP) task. This result is intriguing, as the NIP task only evaluates how well the system can correctly recommend the next item to the user, while the goal of RL is to find a policy that optimizes rewards in the long term – sometimes at the expense of suboptimal short-term performance. Then, how can RL improve the system’s performance on short-term metrics? This article investigates this question by exploring proxy learning objectives, which we identify as goals RL models might be following, and thus could explain the performance boost. We found that RL – when used as an auxiliary loss – promotes the learning of embeddings that capture information about the user’s previously interacted items. Subsequently, we replaced the RL objective with a straightforward auxiliary loss designed to predict the number of items the user interacted with. This substitution results in performance gains comparable to RL. These findings pave the way to improve performance and understanding of RL methods for recommender systems.}
}
@article{Guo2024,
    author = {Guo, Yupu and Cai, Fei and Zheng, Jianming and Zhang, Xin and Chen, Honghui},
    title = {Disentangled variational auto-encoder enhanced by counterfactual data for debiasing recommendation},
    journal = {Complex Intell. Syst.},
    year = {2024},
    doi = {https://doi.org/10.1007/s40747-023-01314-x},
    pages = {3119–3132},
    numpages = {10},
}

@INPROCEEDINGS{9778074,
  author={Liu, Ying Chieh and Huang, Min Qi},
  booktitle={2021 International Conference on Technologies and Applications of Artificial Intelligence (TAAI)}, 
  title={Examining the Matthew Effect on YouTube Recommendation System}, 
  year={2021},
  volume={},
  number={},
  pages={146-148},
  keywords={Video on demand;Statistical analysis;Behavioral sciences;Artificial intelligence;Python;Business;YouTube;recommendation;views;subscriptions;the Matthew effect},
  doi={10.1109/TAAI54685.2021.00035}}

\\相关工作
@inproceedings{10.1145/1772690.1772773,
author = {Rendle, Steffen and Freudenthaler, Christoph and Schmidt-Thieme, Lars},
title = {Factorizing personalized Markov chains for next-basket recommendation},
year = {2010},
isbn = {9781605587998},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1772690.1772773},
doi = {10.1145/1772690.1772773},
abstract = {Recommender systems are an important component of many websites. Two of the most popular approaches are based on matrix factorization (MF) and Markov chains (MC). MF methods learn the general taste of a user by factorizing the matrix over observed user-item preferences. On the other hand, MC methods model sequential behavior by learning a transition graph over items that is used to predict the next action based on the recent actions of a user. In this paper, we present a method bringing both approaches together. Our method is based on personalized transition graphs over underlying Markov chains. That means for each user an own transition matrix is learned - thus in total the method uses a transition cube. As the observations for estimating the transitions are usually very limited, our method factorizes the transition cube with a pairwise interaction model which is a special case of the Tucker Decomposition. We show that our factorized personalized MC (FPMC) model subsumes both a common Markov chain and the normal matrix factorization model. For learning the model parameters, we introduce an adaption of the Bayesian Personalized Ranking (BPR) framework for sequential basket data. Empirically, we show that our FPMC model outperforms both the common matrix factorization and the unpersonalized MC model both learned with and without factorization.},
booktitle = {Proceedings of the 19th International Conference on World Wide Web},
pages = {811–820},
numpages = {10},
keywords = {basket recommendation, markov chain, matrix factorization},
location = {Raleigh, North Carolina, USA},
series = {WWW '10}
}

@inproceedings{10.1145/2766462.2767694,
author = {Wang, Pengfei and Guo, Jiafeng and Lan, Yanyan and Xu, Jun and Wan, Shengxian and Cheng, Xueqi},
title = {Learning Hierarchical Representation Model for NextBasket Recommendation},
year = {2015},
isbn = {9781450336215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2766462.2767694},
doi = {10.1145/2766462.2767694},
abstract = {Next basket recommendation is a crucial task in market basket analysis. Given a user's purchase history, usually a sequence of transaction data, one attempts to build a recommender that can predict the next few items that the user most probably would like. Ideally, a good recommender should be able to explore the sequential behavior (i.e., buying one item leads to buying another next), as well as account for users' general taste (i.e., what items a user is typically interested in) for recommendation. Moreover, these two factors may interact with each other to influence users' next purchase. To tackle the above problems, in this paper, we introduce a novel recommendation approach, namely hierarchical representation model (HRM). HRM can well capture both sequential behavior and users' general taste by involving transaction and user representations in prediction. Meanwhile, the flexibility of applying different aggregation operations, especially nonlinear operations, on representations allows us to model complicated interactions among different factors. Theoretically, we show that our model subsumes several existing methods when choosing proper aggregation operations. Empirically, we demonstrate that our model can consistently outperform the state-of-the-art baselines under different evaluation metrics on real-world transaction data.},
booktitle = {Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {403–412},
numpages = {10},
keywords = {sequential behavior, next basket recommendation, hierarchical representation model, general taste},
location = {Santiago, Chile},
series = {SIGIR '15}
}

\\注意力机制
@inproceedings{10.1609/aaai.v33i01.33015941,
author = {Zhou, Guorui and Mou, Na and Fan, Ying and Pi, Qi and Bian, Weijie and Zhou, Chang and Zhu, Xiaoqiang and Gai, Kun},
title = {Deep interest evolution network for click-through rate prediction},
year = {2019},
isbn = {978-1-57735-809-1},
publisher = {AAAI Press},
url = {https://doi.org/10.1609/aaai.v33i01.33015941},
doi = {10.1609/aaai.v33i01.33015941},
abstract = {Click-through rate (CTR) prediction, whose goal is to estimate the probability of a user clicking on the item, has become one of the core tasks in the advertising system. For CTR prediction model, it is necessary to capture the latent user interest behind the user behavior data. Besides, considering the changing of the external environment and the internal cognition, user interest evolves over time dynamically. There are several CTR prediction methods for interest modeling, while most of them regard the representation of behavior as the interest directly, and lack specially modeling for latent interest behind the concrete behavior. Moreover, little work considers the changing trend of the interest. In this paper, we propose a novel model, named Deep Interest Evolution Network (DIEN), for CTR prediction. Specifically, we design interest extractor layer to capture temporal interests from history behavior sequence. At this layer, we introduce an auxiliary loss to supervise interest extracting at each step. As user interests are diverse, especially in the e-commerce system, we propose interest evolving layer to capture interest evolving process that is relative to the target item. At interest evolving layer, attention mechanism is embedded into the sequential structure novelly, and the effects of relative interests are strengthened during interest evolution. In the experiments on both public and industrial datasets, DIEN significantly outperforms the state-of-the-art solutions. Notably, DIEN has been deployed in the display advertisement system of Taobao, and obtained 20.7\% improvement on CTR.},
booktitle = {Proceedings of the Thirty-Third AAAI Conference on Artificial Intelligence and Thirty-First Innovative Applications of Artificial Intelligence Conference and Ninth AAAI Symposium on Educational Advances in Artificial Intelligence},
articleno = {729},
numpages = {8},
location = {Honolulu, Hawaii, USA},
series = {AAAI'19/IAAI'19/EAAI'19}
}

@INPROCEEDINGS{8594844,
  author={Kang, Wang-Cheng and McAuley, Julian},
  booktitle={2018 IEEE International Conference on Data Mining (ICDM)}, 
  title={Self-Attentive Sequential Recommendation}, 
  year={2018},
  volume={},
  number={},
  pages={197-206},
  keywords={Adaptation models;Context modeling;Task analysis;Recommender systems;Markov processes;Recurrent neural networks;Predictive models;Sequential Recommendation;Collaborative Filtering},
  doi={10.1109/ICDM.2018.00035}}

@inproceedings{10.5555/3295222.3295349,
author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, \L{}ukasz and Polosukhin, Illia},
title = {Attention is all you need},
year = {2017},
isbn = {9781510860964},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.0 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature.},
booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems},
pages = {6000–6010},
numpages = {11},
location = {Long Beach, California, USA},
series = {NIPS'17}
}

@inproceedings{10.1145/3357384.3357895,
author = {Sun, Fei and Liu, Jun and Wu, Jian and Pei, Changhua and Lin, Xiao and Ou, Wenwu and Jiang, Peng},
title = {BERT4Rec: Sequential Recommendation with Bidirectional Encoder Representations from Transformer},
year = {2019},
isbn = {9781450369763},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3357384.3357895},
doi = {10.1145/3357384.3357895},
abstract = {Modeling users' dynamic preferences from their historical behaviors is challenging and crucial for recommendation systems. Previous methods employ sequential neural networks to encode users' historical interactions from left to right into hidden representations for making recommendations. Despite their effectiveness, we argue that such left-to-right unidirectional models are sub-optimal due to the limitations including: begin enumerate* [label=seriesitshapealph*upshape)] item unidirectional architectures restrict the power of hidden representation in users' behavior sequences; item they often assume a rigidly ordered sequence which is not always practical. end enumerate* To address these limitations, we proposed a sequential recommendation model called BERT4Rec, which employs the deep bidirectional self-attention to model user behavior sequences. To avoid the information leakage and efficiently train the bidirectional model, we adopt the Cloze objective to sequential recommendation, predicting the random masked items in the sequence by jointly conditioning on their left and right context. In this way, we learn a bidirectional representation model to make recommendations by allowing each item in user historical behaviors to fuse information from both left and right sides. Extensive experiments on four benchmark datasets show that our model outperforms various state-of-the-art sequential models consistently.},
booktitle = {Proceedings of the 28th ACM International Conference on Information and Knowledge Management},
pages = {1441–1450},
numpages = {10},
keywords = {sequential recommendation, cloze, bidirectional sequential model},
location = {Beijing, China},
series = {CIKM '19}
}

@inproceedings{10.1145/3357384.3357818,
author = {Lv, Fuyu and Jin, Taiwei and Yu, Changlong and Sun, Fei and Lin, Quan and Yang, Keping and Ng, Wilfred},
title = {SDM: Sequential Deep Matching Model for Online Large-scale Recommender System},
year = {2019},
isbn = {9781450369763},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3357384.3357818},
doi = {10.1145/3357384.3357818},
abstract = {Capturing users' precise preferences is a fundamental problem in large-scale recommender system. Currently, item-based Collaborative Filtering (CF) methods are common matching approaches in industry. However, they are not effective to model dynamic and evolving preferences of users. In this paper, we propose a new sequential deep matching (SDM) model to capture users' dynamic preferences by combining short-term sessions and long-term behaviors. Compared with existing sequence-aware recommendation methods, we tackle the following two inherent problems in real-world applications: (1) there could exist multiple interest tendencies in one session. (2) long-term preferences may not be effectively fused with current session interests. Long-term behaviors are various and complex, hence those highly related to the short-term session should be kept for fusion. We propose to encode behavior sequences with two corresponding components: multi-head self-attention module to capture multiple types of interests and long-short term gated fusion module to incorporate long-term preferences. Successive items are recommended after matching between sequential user behavior vector and item embedding vectors. Offline experiments on real-world datasets show the superior performance of the proposed SDM. Moreover, SDM has been successfully deployed on online large-scale recommender system at Taobao and achieves improvements in terms of a range of commercial metrics.},
booktitle = {Proceedings of the 28th ACM International Conference on Information and Knowledge Management},
pages = {2635–2643},
numpages = {9},
keywords = {sequential recommendation, deep matching},
location = {Beijing, China},
series = {CIKM '19}
}

@article{Shin_Choi_Wi_Park_2024, title={An Attentive Inductive Bias for Sequential Recommendation beyond the Self-Attention}, volume={38}, url={https://ojs.aaai.org/index.php/AAAI/article/view/28747}, DOI={10.1609/aaai.v38i8.28747}, abstractNote={Sequential recommendation (SR) models based on Transformers have achieved remarkable successes. The self-attention mechanism of Transformers for computer vision and natural language processing suffers from the oversmoothing problem, i.e., hidden representations becoming similar to tokens. In the SR domain, we, for the first time, show that the same problem occurs. We present pioneering investigations that reveal the low-pass filtering nature of self-attention in the SR, which causes oversmoothing. To this end, we propose a novel method called Beyond Self-Attention for Sequential Recommendation (BSARec), which leverages the Fourier transform to i) inject an inductive bias by considering fine-grained sequential patterns and ii) integrate low and high-frequency information to mitigate oversmoothing. Our discovery shows significant advancements in the SR domain and is expected to bridge the gap for existing Transformer-based SR models. We test our proposed approach through extensive experiments on 6 benchmark datasets. The experimental results demonstrate that our model outperforms 7 baseline methods in terms of recommendation performance. Our code is available at https://github.com/yehjin-shin/BSARec.}, number={8}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Shin, Yehjin and Choi, Jeongwhan and Wi, Hyowon and Park, Noseong}, year={2024}, month={Mar.}, pages={8984-8992} }

@inproceedings{10.1145/3539618.3591717,
author = {Liu, Langming and Cai, Liu and Zhang, Chi and Zhao, Xiangyu and Gao, Jingtong and Wang, Wanyu and Lv, Yifu and Fan, Wenqi and Wang, Yiqi and He, Ming and Liu, Zitao and Li, Qing},
title = {LinRec: Linear Attention Mechanism for Long-term Sequential Recommender Systems},
year = {2023},
isbn = {9781450394086},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3539618.3591717},
doi = {10.1145/3539618.3591717},
abstract = {Transformer models have achieved remarkable success in sequential recommender systems (SRSs). However, computing the attention matrix in traditional dot-product attention mechanisms results in a quadratic complexity with sequence lengths, leading to high computational costs for long-term sequential recommendation. Motivated by the above observation, we propose a novel L2-Normalized Linear Attention for the Transformer-based Sequential Recommender Systems (LinRec), which theoretically improves efficiency while preserving the learning capabilities of the traditional dot-product attention. Specifically, by thoroughly examining the equivalence conditions of efficient attention mechanisms, we show that LinRec possesses linear complexity while preserving the property of attention mechanisms. In addition, we reveal its latent efficiency properties by interpreting the proposed LinRec mechanism through a statistical lens. Extensive experiments are conducted based on two public benchmark datasets, demonstrating that the combination of LinRec and Transformer models achieves comparable or even superior performance than state-of-the-art Transformer-based SRS models while significantly improving time and memory efficiency. The implementation code is available online at https://github.com/Applied-Machine-Learning-Lab/LinRec.>},
booktitle = {Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {289–299},
numpages = {11},
keywords = {efficient transformer, l2 normalization, linear complexity, sequential recommender systems},
location = {Taipei, Taiwan},
series = {SIGIR '23}
}

@inproceedings{10.1145/3511808.3557095,
author = {Lin, Qianying and Zhou, Wen-Ji and Wang, Yanshi and Da, Qing and Chen, Qing-Guo and Wang, Bing},
title = {Sparse Attentive Memory Network for Click-through Rate Prediction with Long Sequences},
year = {2022},
isbn = {9781450392365},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3511808.3557095},
doi = {10.1145/3511808.3557095},
abstract = {Sequential recommendation predicts users' next behaviors with their historical interactions. Recommending with longer sequences improves recommendation accuracy and increases the degree of personalization. As sequences get longer, existing works have not yet addressed the following two main challenges. Firstly, modeling long-range intra-sequence dependency is difficult with increasing sequence lengths. Secondly, it requires efficient memory and computational speeds. In this paper, we propose a Sparse Attentive Memory (SAM) network for long sequential user behavior modeling. SAM supports efficient training and real-time inference for user behavior sequences with lengths on the scale of thousands. In SAM, we model the target item as the query and the long sequence as the knowledge database, where the former continuously elicits relevant information from the latter. SAM simultaneously models target-sequence dependencies and long-range intra-sequence dependencies with O(L) complexity and O(1) number of sequential updates, which can only be achieved by the self-attention mechanism with O(L2) complexity. Extensive empirical results demonstrate that our proposed solution is effective not only in long user behavior modeling but also on short sequences modeling. Implemented on sequences of length 1000, SAM is successfully deployed on one of the largest international E-commerce platforms. This inference time is within 30ms, with a substantial 7.30\% click-through rate improvement for the online A/B test. To the best of our knowledge, it is the first end-to-end long user sequence modeling framework that models intra-sequence and target-sequence dependencies with the aforementioned degree of efficiency and successfully deployed on a large-scale real-time industrial recommender system.},
booktitle = {Proceedings of the 31st ACM International Conference on Information \& Knowledge Management},
pages = {3312–3321},
numpages = {10},
keywords = {click-through rate prediction, long sequences, long user behavior modeling, memory networks, sequential recommenders},
location = {Atlanta, GA, USA},
series = {CIKM '22}
}

\\图神经网络
@inproceedings{
kipf2017semisupervised,
title={Semi-Supervised Classification with Graph Convolutional Networks},
author={Thomas N. Kipf and Max Welling},
booktitle={International Conference on Learning Representations},
year={2017},
url={https://openreview.net/forum?id=SJU4ayYgl}
}

@inproceedings{10.1145/3331184.3331267,
author = {Wang, Xiang and He, Xiangnan and Wang, Meng and Feng, Fuli and Chua, Tat-Seng},
title = {Neural Graph Collaborative Filtering},
year = {2019},
isbn = {9781450361729},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3331184.3331267},
doi = {10.1145/3331184.3331267},
abstract = {Learning vector representations (aka. embeddings) of users and items lies at the core of modern recommender systems. Ranging from early matrix factorization to recently emerged deep learning based methods, existing efforts typically obtain a user's (or an item's) embedding by mapping from pre-existing features that describe the user (or the item), such as ID and attributes. We argue that an inherent drawback of such methods is that, the collaborative signal, which is latent in user-item interactions, is not encoded in the embedding process. As such, the resultant embeddings may not be sufficient to capture the collaborative filtering effect.In this work, we propose to integrate the user-item interactions - more specifically the bipartite graph structure - into the embedding process. We develop a new recommendation framework Neural Graph Collaborative Filtering (NGCF), which exploits the user-item graph structure by propagating embeddings on it. This leads to the expressive modeling of high-order connectivity in user-item graph, effectively injecting the collaborative signal into the embedding process in an explicit manner. We conduct extensive experiments on three public benchmarks, demonstrating significant improvements over several state-of-the-art models like HOP-Rec [39] and Collaborative Memory Network [5]. Further analysis verifies the importance of embedding propagation for learning better user and item representations, justifying the rationality and effectiveness of NGCF. Codes are available at https://github.com/xiangwang1223/neural_graph_collaborative_filtering.},
booktitle = {Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {165–174},
numpages = {10},
keywords = {collaborative filtering, embedding propagation, graph neural network, high-order connectivity, recommendation},
location = {Paris, France},
series = {SIGIR'19}
}

@inproceedings{10.1145/3397271.3401063,
author = {He, Xiangnan and Deng, Kuan and Wang, Xiang and Li, Yan and Zhang, YongDong and Wang, Meng},
title = {LightGCN: Simplifying and Powering Graph Convolution Network for Recommendation},
year = {2020},
isbn = {9781450380164},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3397271.3401063},
doi = {10.1145/3397271.3401063},
abstract = {Graph Convolution Network (GCN) has become new state-of-the-art for collaborative filtering. Nevertheless, the reasons of its effectiveness for recommendation are not well understood. Existing work that adapts GCN to recommendation lacks thorough ablation analyses on GCN, which is originally designed for graph classification tasks and equipped with many neural network operations. However, we empirically find that the two most common designs in GCNs -- feature transformation and nonlinear activation -- contribute little to the performance of collaborative filtering. Even worse, including them adds to the difficulty of training and degrades recommendation performance.In this work, we aim to simplify the design of GCN to make it more concise and appropriate for recommendation. We propose a new model named LightGCN, including only the most essential component in GCN -- neighborhood aggregation -- for collaborative filtering. Specifically, LightGCN learns user and item embeddings by linearly propagating them on the user-item interaction graph, and uses the weighted sum of the embeddings learned at all layers as the final embedding. Such simple, linear, and neat model is much easier to implement and train, exhibiting substantial improvements (about 16.0\% relative improvement on average) over Neural Graph Collaborative Filtering (NGCF) -- a state-of-the-art GCN-based recommender model -- under exactly the same experimental setting. Further analyses are provided towards the rationality of the simple LightGCN from both analytical and empirical perspectives.},
booktitle = {Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {639–648},
numpages = {10},
keywords = {collaborative filtering, embedding propagation, graph neural network, recommendation},
location = {Virtual Event, China},
series = {SIGIR '20}
}

@inproceedings{10.1145/3626772.3657721,
author = {Zhang, Peiyan and Yan, Yuchen and Zhang, Xi and Li, Chaozhuo and Wang, Senzhang and Huang, Feiran and Kim, Sunghun},
title = {TransGNN: Harnessing the Collaborative Power of Transformers and Graph Neural Networks for Recommender Systems},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3657721},
doi = {10.1145/3626772.3657721},
abstract = {Graph Neural Networks (GNNs) have emerged as promising solutions for collaborative filtering (CF) through the modeling of user-item interaction graphs. The nucleus of existing GNN-based recommender systems involves recursive message passing along user-item interaction edges to refine encoded embeddings. Despite their demonstrated effectiveness, current GNN-based methods encounter challenges of limited receptive fields and the presence of noisy "interest-irrelevant" connections. In contrast, Transformer-based methods excel in aggregating information adaptively and globally. Nevertheless, their application to large-scale interaction graphs is hindered by inherent complexities and challenges in capturing intricate, entangled structural information. In this paper, we propose TransGNN, a novel model that integrates Transformer and GNN layers in an alternating fashion to mutually enhance their capabilities. Specifically, TransGNN leverages Transformer layers to broaden the receptive field and disentangle information aggregation from edges, which aggregates information from more relevant nodes, thereby enhancing the message passing of GNNs. Additionally, to capture graph structure information effectively, positional encoding is meticulously designed and integrated into GNN layers to encode such structural knowledge into node attributes, thus enhancing the Transformer's performance on graphs. Efficiency considerations are also alleviated by proposing the sampling of the most relevant nodes for the Transformer, along with two efficient sample update strategies to reduce complexity. Furthermore, theoretical analysis demonstrates that TransGNN offers increased expressiveness compared to GNNs, with only a marginal increase in linear complexity. Extensive experiments on five public datasets validate the effectiveness and efficiency of TransGNN. Our code is available at https://github.com/Peiyance/TransGNN-torch.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {1285–1295},
numpages = {11},
keywords = {graph neural networks, recommender systems, transformers},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@article{Wu_Tang_Zhu_Wang_Xie_Tan_2019, title={Session-Based Recommendation with Graph Neural Networks}, volume={33}, url={https://ojs.aaai.org/index.php/AAAI/article/view/3804}, DOI={10.1609/aaai.v33i01.3301346}, abstractNote={&lt;p&gt;The problem of session-based recommendation aims to predict user actions based on anonymous sessions. Previous methods model a session as a sequence and estimate user representations besides item representations to make recommendations. Though achieved promising results, they are insufficient to obtain accurate user vectors in sessions and neglect complex transitions of items. To obtain accurate item embedding and take complex transitions of items into account, we propose a novel method, i.e. &lt;em&gt;Session-based Recommendation with Graph Neural Networks&lt;/em&gt;, SR-GNN for brevity. In the proposed method, session sequences are modeled as graphstructured data. Based on the session graph, GNN can capture complex transitions of items, which are difficult to be revealed by previous conventional sequential methods. Each session is then represented as the composition of the global preference and the current interest of that session using an attention network. Extensive experiments conducted on two real datasets show that SR-GNN evidently outperforms the state-of-the-art session-based recommendation methods consistently.&lt;/p&gt;}, number={01}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Wu, Shu and Tang, Yuyuan and Zhu, Yanqiao and Wang, Liang and Xie, Xing and Tan, Tieniu}, year={2019}, month={Jul.}, pages={346-353} }

@inproceedings{10.1145/3404835.3462968,
author = {Chang, Jianxin and Gao, Chen and Zheng, Yu and Hui, Yiqun and Niu, Yanan and Song, Yang and Jin, Depeng and Li, Yong},
title = {Sequential Recommendation with Graph Neural Networks},
year = {2021},
isbn = {9781450380379},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3404835.3462968},
doi = {10.1145/3404835.3462968},
abstract = {Sequential recommendation aims to leverage users' historical behaviors to predict their next interaction. Existing works have not yet addressed two main challenges in sequential recommendation. First, user behaviors in their rich historical sequences are often implicit and noisy preference signals, they cannot sufficiently reflect users' actual preferences. In addition, users' dynamic preferences often change rapidly over time, and hence it is difficult to capture user patterns in their historical sequences. In this work, we propose a graph neural network model called SURGE (short forSeqUential Recommendation with Graph neural nEtworks) to address these two issues. Specifically, SURGE integrates different types of preferences in long-term user behaviors into clusters in the graph by re-constructing loose item sequences into tight item-item interest graphs based on metric learning. This helps explicitly distinguish users' core interests, by forming dense clusters in the interest graph. Then, we perform cluster-aware and query-aware graph convolutional propagation and graph pooling on the constructed graph. It dynamically fuses and extracts users' current activated core interests from noisy user behavior sequences. We conduct extensive experiments on both public and proprietary industrial datasets. Experimental results demonstrate significant performance gains of our proposed method compared to state-of-the-art methods. Further studies on sequence length confirm that our method can model long behavioral sequences effectively and efficiently.},
booktitle = {Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {378–387},
numpages = {10},
keywords = {dynamic user preferences, graph neural networks, sequential recommendation},
location = {Virtual Event, Canada},
series = {SIGIR '21}
}

@article{Ma_Ma_Zhang_Sun_Liu_Coates_2020, title={Memory Augmented Graph Neural Networks for Sequential Recommendation}, volume={34}, url={https://ojs.aaai.org/index.php/AAAI/article/view/5945}, DOI={10.1609/aaai.v34i04.5945}, abstractNote={&lt;p&gt;The chronological order of user-item interactions can reveal time-evolving and sequential user behaviors in many recommender systems. The items that users will interact with may depend on the items accessed in the past. However, the substantial increase of users and items makes sequential recommender systems still face non-trivial challenges: (1) the hardness of modeling the short-term user interests; (2) the difficulty of capturing the long-term user interests; (3) the effective modeling of item co-occurrence patterns. To tackle these challenges, we propose a memory augmented graph neural network (MA-GNN) to capture both the long- and short-term user interests. Specifically, we apply a graph neural network to model the item contextual information within a short-term period and utilize a shared memory network to capture the long-range dependencies between items. In addition to the modeling of user interests, we employ a bilinear function to capture the co-occurrence patterns of related items. We extensively evaluate our model on five real-world datasets, comparing with several state-of-the-art methods and using a variety of performance metrics. The experimental results demonstrate the effectiveness of our model for the task of Top-K sequential recommendation.&lt;/p&gt;}, number={04}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Ma, Chen and Ma, Liheng and Zhang, Yingxue and Sun, Jianing and Liu, Xue and Coates, Mark}, year={2020}, month={Apr.}, pages={5045-5052} }

\\对比学习
@inproceedings{10.1145/3539618.3591692,
author = {Ye, Yaowen and Xia, Lianghao and Huang, Chao},
title = {Graph Masked Autoencoder for Sequential Recommendation},
year = {2023},
isbn = {9781450394086},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3539618.3591692},
doi = {10.1145/3539618.3591692},
abstract = {While some powerful neural network architectures (e.g., Transformer, Graph Neural Networks) have achieved improved performance in sequential recommendation with high-order item dependency modeling, they may suffer from poor representation capability in label scarcity scenarios. To address the issue of insufficient labels, Contrastive Learning (CL) has attracted much attention in recent methods to perform data augmentation through embedding contrasting for self-supervision. However, due to the hand-crafted property of their contrastive view generation strategies, existing CL-enhanced models i) can hardly yield consistent performance on diverse sequential recommendation tasks; ii) may not be immune to user behavior data noise. In light of this, we propose a simple yet effective Graph Masked AutoEncoder-enhanced sequential Recommender system (MAERec) that adaptively and dynamically distills global item transitional information for self-supervised augmentation. It naturally avoids the above issue of heavy reliance on constructing high-quality embedding contrastive views. Instead, an adaptive data reconstruction paradigm is designed to be integrated with the long-range item dependency modeling, for informative augmentation in sequential recommendation. Extensive experiments demonstrate that our method significantly outperforms state-of-the-art baseline models and can learn more accurate representations against data noise and sparsity. Our implemented model code is available at https://github.com/HKUDS/MAERec.},
booktitle = {Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {321–330},
numpages = {10},
keywords = {graph neural networks, masked autoencoder, self-supervised learning, sequential recommendation},
location = {Taipei, Taiwan},
series = {SIGIR '23}
}

@misc{lee2023hierarchicalcontrastivelearningmultiple,
      title={Hierarchical Contrastive Learning with Multiple Augmentation for Sequential Recommendation}, 
      author={Dongjun Lee and Donggeun Ko and Jaekwang Kim},
      year={2023},
      eprint={2308.03400},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2308.03400}, 
}

@INPROCEEDINGS{9835621,
  author={Xie, Xu and Sun, Fei and Liu, Zhaoyang and Wu, Shiwen and Gao, Jinyang and Zhang, Jiandong and Ding, Bolin and Cui, Bin},
  booktitle={2022 IEEE 38th International Conference on Data Engineering (ICDE)}, 
  title={Contrastive Learning for Sequential Recommendation}, 
  year={2022},
  volume={},
  number={},
  pages={1259-1273},
  keywords={Computer vision;Conferences;Multitasking;Data engineering;Data models;Behavioral sciences;Data mining;Contrastive Learning;Deep Learning;Recom-mender Systems},
  doi={10.1109/ICDE53745.2022.00099}}

@inproceedings{10.1145/3488560.3498433,
author = {Qiu, Ruihong and Huang, Zi and Yin, Hongzhi and Wang, Zijian},
title = {Contrastive Learning for Representation Degeneration Problem in Sequential Recommendation},
year = {2022},
isbn = {9781450391320},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3488560.3498433},
doi = {10.1145/3488560.3498433},
abstract = {Recent advancements of sequential deep learning models such as Transformer and BERT have significantly facilitated the sequential recommendation. However, according to our study, the distribution of item embeddings generated by these models tends to degenerate into an anisotropic shape, which may result in high semantic similarities among embeddings. In this paper, both empirical and theoretical investigations of this representation degeneration problem are first provided, based on which a novel recommender model DuoRec is proposed to improve the item embeddings distribution. Specifically, in light of the uniformity property of contrastive learning, a contrastive regularization is designed for DuoRec to reshape the distribution of sequence representations. Given the convention that the recommendation task is performed by measuring the similarity between sequence representations and item embeddings in the same space via dot product, the regularization can be implicitly applied to the item embedding distribution. Existing contrastive learning methods mainly rely on data level augmentation for user-item interaction sequences through item cropping, masking, or reordering and can hardly provide semantically consistent augmentation samples. In DuoRec, a model-level augmentation is proposed based on Dropout to enable better semantic preserving. Furthermore, a novel sampling strategy is developed, where sequences having the same target item are chosen hard positive samples. Extensive experiments conducted on five datasets demonstrate the superior performance of the proposed DuoRec model compared with baseline methods. Visualization results of the learned representations validate that DuoRec can largely alleviate the representation degeneration problem.},
booktitle = {Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining},
pages = {813–823},
numpages = {11},
keywords = {sequential recommendation, contrastive learning},
location = {Virtual Event, AZ, USA},
series = {WSDM '22}
}

@inproceedings{10.1145/3543507.3583361,
author = {Yang, Yuhao and Huang, Chao and Xia, Lianghao and Huang, Chunzhen and Luo, Da and Lin, Kangyi},
title = {Debiased Contrastive Learning for Sequential Recommendation},
year = {2023},
isbn = {9781450394161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3543507.3583361},
doi = {10.1145/3543507.3583361},
abstract = {Current sequential recommender systems are proposed to tackle the dynamic user preference learning with various neural techniques, such as Transformer and Graph Neural Networks (GNNs). However, inference from the highly sparse user behavior data may hinder the representation ability of sequential pattern encoding. To address the label shortage issue, contrastive learning (CL) methods are proposed recently to perform data augmentation in two fashions: (i) randomly corrupting the sequence data (e.g., stochastic masking, reordering); (ii) aligning representations across pre-defined contrastive views. Although effective, we argue that current CL-based methods have limitations in addressing popularity bias and disentangling of user conformity and real interest. In this paper, we propose a new Debiased Contrastive learning paradigm for Recommendation (DCRec) that unifies sequential pattern encoding with global collaborative relation modeling through adaptive conformity-aware augmentation. This solution is designed to tackle the popularity bias issue in recommendation systems. Our debiased contrastive learning framework effectively captures both the patterns of item transitions within sequences and the dependencies between users across sequences. Our experiments on various real-world datasets have demonstrated that DCRec significantly outperforms state-of-the-art baselines, indicating its efficacy for recommendation. To facilitate reproducibility of our results, we make our implementation of DCRec publicly available at: https://github.com/HKUDS/DCRec.},
booktitle = {Proceedings of the ACM Web Conference 2023},
pages = {1063–1073},
numpages = {11},
keywords = {Contrastive Learning, Popularity Bias, Sequential Recommendation},
location = {Austin, TX, USA},
series = {WWW '23}
}

@misc{zhu2020deepgraphcontrastiverepresentation,
      title={Deep Graph Contrastive Representation Learning}, 
      author={Yanqiao Zhu and Yichen Xu and Feng Yu and Qiang Liu and Shu Wu and Liang Wang},
      year={2020},
      eprint={2006.04131},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2006.04131}, 
}

@inproceedings{10.1145/3477495.3532058,
author = {Xia, Lianghao and Huang, Chao and Xu, Yong and Zhao, Jiashu and Yin, Dawei and Huang, Jimmy},
title = {Hypergraph Contrastive Collaborative Filtering},
year = {2022},
isbn = {9781450387323},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3477495.3532058},
doi = {10.1145/3477495.3532058},
abstract = {Collaborative Filtering (CF) has emerged as fundamental paradigms for parameterizing users and items into latent representation space, with their correlative patterns from interaction data. Among various CF techniques, the development of GNN-based recommender systems, e.g., PinSage and LightGCN, has offered the state-of-the-art performance. However, two key challenges have not been well explored in existing solutions: i) The over-smoothing effect with deeper graph-based CF architecture, may cause the indistinguishable user representations and degradation of recommendation results. ii) The supervision signals (i.e., user-item interactions) are usually scarce and skewed distributed in reality, which limits the representation power of CF paradigms. To tackle these challenges, we propose a new self-supervised recommendation framework Hypergraph Contrastive Collaborative Filtering (HCCF) to jointly capture local and global collaborative relations with a hypergraph-enhanced cross-view contrastive learning architecture. In particular, the designed hypergraph structure learning enhances the discrimination ability of GNN-based CF paradigm, in comprehensively capturing the complex high-order dependencies among users. Additionally, our HCCF model effectively integrates the hypergraph structure encoding with self-supervised learning to reinforce the representation quality of recommender systems, based on the hypergraph self-discrimination. Extensive experiments on three benchmark datasets demonstrate the superiority of our model over various state-of-the-art recommendation methods, and the robustness against sparse user interaction data. The implementation codes are available at https://github.com/akaxlh/HCCF.},
booktitle = {Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {70–79},
numpages = {10},
keywords = {collaborative filtering, recommendation, self-supervised learning},
location = {Madrid, Spain},
series = {SIGIR '22}
}

\\基线
@inproceedings{10.1145/3159652.3159656,
author = {Tang, Jiaxi and Wang, Ke},
title = {Personalized Top-N Sequential Recommendation via Convolutional Sequence Embedding},
year = {2018},
isbn = {9781450355810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3159652.3159656},
doi = {10.1145/3159652.3159656},
abstract = {Top-N sequential recommendation models each user as a sequence of items interacted in the past and aims to predict top-N ranked items that a user will likely interact in a »near future». The order of interaction implies that sequential patterns play an important role where more recent items in a sequence have a larger impact on the next item. In this paper, we propose a Convolutional Sequence Embedding Recommendation Model »Caser» as a solution to address this requirement. The idea is to embed a sequence of recent items into an »image» in the time and latent spaces and learn sequential patterns as local features of the image using convolutional filters. This approach provides a unified and flexible network structure for capturing both general preferences and sequential patterns. The experiments on public data sets demonstrated that Caser consistently outperforms state-of-the-art sequential recommendation methods on a variety of common evaluation metrics.},
booktitle = {Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining},
pages = {565–573},
numpages = {9},
keywords = {sequential prediction, recommender system, convolutional neural networks},
location = {Marina Del Rey, CA, USA},
series = {WSDM '18}
}

@misc{hidasi2016sessionbasedrecommendationsrecurrentneural,
      title={Session-based Recommendations with Recurrent Neural Networks}, 
      author={Balázs Hidasi and Alexandros Karatzoglou and Linas Baltrunas and Domonkos Tikk},
      year={2016},
      eprint={1511.06939},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://doi.org/10.48550/arXiv.1511.06939}, 
}
