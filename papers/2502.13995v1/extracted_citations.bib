@inproceedings{DECA:Siggraph2021,
  title={Learning an Animatable Detailed {3D} Face Model from In-The-Wild Images},
  author={Feng, Yao and Feng, Haiwen and Black, Michael J. and Bolkart, Timo},
  journal = {ACM Transactions on Graphics, (Proc. SIGGRAPH)}, 
  volume = {40}, 
  number = {8}, 
  year = {2021}, 
  url = {https://doi.org/10.1145/3450626.3459936} 
}

@incollection{blanz2023morphable,
  title={A morphable model for the synthesis of 3D faces},
  author={Blanz, Volker and Vetter, Thomas},
  booktitle={Seminal Graphics Papers: Pushing the Boundaries, Volume 2},
  pages={157--164},
  year={2023}
}

@article{chen2024echomimic,
  title={Echomimic: Lifelike audio-driven portrait animations through editable landmark conditions},
  author={Chen, Zhiyuan and Cao, Jiajiong and Chen, Zhiquan and Li, Yuming and Ma, Chenguang},
  journal={arXiv preprint arXiv:2407.08136},
  year={2024}
}

@inproceedings{deng2019arcface,
  title={Arcface: Additive angular margin loss for deep face recognition},
  author={Deng, Jiankang and Guo, Jia and Xue, Niannan and Zafeiriou, Stefanos},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={4690--4699},
  year={2019}
}

@article{gal2022image,
  title={An image is worth one word: Personalizing text-to-image generation using textual inversion},
  author={Gal, Rinon and Alaluf, Yuval and Atzmon, Yuval and Patashnik, Or and Bermano, Amit H and Chechik, Gal and Cohen-Or, Daniel},
  journal={arXiv preprint arXiv:2208.01618},
  year={2022}
}

@article{guo2023animatediff,
  title={Animatediff: Animate your personalized text-to-image diffusion models without specific tuning},
  author={Guo, Yuwei and Yang, Ceyuan and Rao, Anyi and Liang, Zhengyang and Wang, Yaohui and Qiao, Yu and Agrawala, Maneesh and Lin, Dahua and Dai, Bo},
  journal={arXiv preprint arXiv:2307.04725},
  year={2023}
}

@article{guo2024pulid,
  title={Pulid: Pure and lightning id customization via contrastive alignment},
  author={Guo, Zinan and Wu, Yanze and Chen, Zhuowei and Chen, Lang and Zhang, Peng and He, Qian},
  journal={arXiv preprint arXiv:2404.16022},
  year={2024}
}

@article{he2024id,
  title={Id-animator: Zero-shot identity-preserving human video generation},
  author={He, Xuanhua and Liu, Quande and Qian, Shengju and Wang, Xin and Hu, Tao and Cao, Ke and Yan, Keyu and Zhang, Jie},
  journal={arXiv preprint arXiv:2404.15275},
  year={2024}
}

@article{hu2021lora,
  title={Lora: Low-rank adaptation of large language models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  journal={arXiv preprint arXiv:2106.09685},
  year={2021}
}

@inproceedings{khakhulin2022realistic,
  title={Realistic one-shot mesh-based head avatars},
  author={Khakhulin, Taras and Sklyarova, Vanessa and Lempitsky, Victor and Zakharov, Egor},
  booktitle={European Conference on Computer Vision},
  pages={345--362},
  year={2022},
  organization={Springer}
}

@article{li2017learning,
  title={Learning a model of facial shape and expression from 4D scans.},
  author={Li, Tianye and Bolkart, Timo and Black, Michael J and Li, Hao and Romero, Javier},
  journal={ACM Trans. Graph.},
  volume={36},
  number={6},
  pages={194--1},
  year={2017}
}

@article{lugaresi2019mediapipe,
  title={Mediapipe: A framework for building perception pipelines},
  author={Lugaresi, Camillo and Tang, Jiuqiang and Nash, Hadon and McClanahan, Chris and Uboweja, Esha and Hays, Michael and Zhang, Fan and Chang, Chuo-Ling and Yong, Ming Guang and Lee, Juhyun and others},
  journal={arXiv preprint arXiv:1906.08172},
  year={2019}
}

@inproceedings{ma2024cvthead,
  title={CVTHead: One-shot Controllable Head Avatar with Vertex-feature Transformer},
  author={Ma, Haoyu and Zhang, Tong and Sun, Shanlin and Yan, Xiangyi and Han, Kun and Xie, Xiaohui},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={6131--6141},
  year={2024}
}

@software{opensora,
  author = {Zangwei Zheng and Xiangyu Peng and Tianji Yang and Chenhui Shen and Shenggui Li and Hongxin Liu and Yukun Zhou and Tianyi Li and Yang You},
  title = {Open-Sora: Democratizing Efficient Video Production for All},
  month = {March},
  year = {2024},
  url = {https://github.com/hpcaitech/Open-Sora}
}

@inproceedings{pang2023dpe,
  title={Dpe: Disentanglement of pose and expression for general video portrait editing},
  author={Pang, Youxin and Zhang, Yong and Quan, Weize and Fan, Yanbo and Cun, Xiaodong and Shan, Ying and Yan, Dong-ming},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={427--436},
  year={2023}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@inproceedings{ruiz2023dreambooth,
  title={Dreambooth: Fine tuning text-to-image diffusion models for subject-driven generation},
  author={Ruiz, Nataniel and Li, Yuanzhen and Jampani, Varun and Pritch, Yael and Rubinstein, Michael and Aberman, Kfir},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={22500--22510},
  year={2023}
}

@article{sun2023eva,
  title={Eva-clip: Improved training techniques for clip at scale},
  author={Sun, Quan and Fang, Yuxin and Wu, Ledell and Wang, Xinlong and Cao, Yue},
  journal={arXiv preprint arXiv:2303.15389},
  year={2023}
}

@inproceedings{wang2021one,
  title={One-shot free-view neural talking-head synthesis for video conferencing},
  author={Wang, Ting-Chun and Mallya, Arun and Liu, Ming-Yu},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={10039--10049},
  year={2021}
}

@article{wang2024instantid,
  title={Instantid: Zero-shot identity-preserving generation in seconds},
  author={Wang, Qixun and Bai, Xu and Wang, Haofan and Qin, Zekui and Chen, Anthony and Li, Huaxia and Tang, Xu and Hu, Yao},
  journal={arXiv preprint arXiv:2401.07519},
  year={2024}
}

@inproceedings{wiles2018x2face,
  title={X2face: A network for controlling face generation using images, audio, and pose codes},
  author={Wiles, Olivia and Koepke, A and Zisserman, Andrew},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={670--686},
  year={2018}
}

@article{yang2024cogvideox,
  title={CogVideoX: Text-to-Video Diffusion Models with An Expert Transformer},
  author={Yang, Zhuoyi and Teng, Jiayan and Zheng, Wendi and Ding, Ming and Huang, Shiyu and Xu, Jiazheng and Yang, Yuanming and Hong, Wenyi and Zhang, Xiaohan and Feng, Guanyu and others},
  journal={arXiv preprint arXiv:2408.06072},
  year={2024}
}

@inproceedings{yao2020mesh,
  title={Mesh guided one-shot face reenactment using graph convolutional networks},
  author={Yao, Guangming and Yuan, Yi and Shao, Tianjia and Zhou, Kun},
  booktitle={Proceedings of the 28th ACM international conference on multimedia},
  pages={1773--1781},
  year={2020}
}

@article{yuan2024identity,
  title={Identity-Preserving Text-to-Video Generation by Frequency Decomposition},
  author={Yuan, Shenghai and Huang, Jinfa and He, Xianyi and Ge, Yunyuan and Shi, Yujun and Chen, Liuhan and Luo, Jiebo and Yuan, Li},
  journal={arXiv preprint arXiv:2411.17440},
  year={2024}
}

@inproceedings{zhang2023sadtalker,
  title={Sadtalker: Learning realistic 3d motion coefficients for stylized audio-driven single image talking face animation},
  author={Zhang, Wenxuan and Cun, Xiaodong and Wang, Xuan and Zhang, Yong and Shen, Xi and Guo, Yu and Shan, Ying and Wang, Fei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8652--8661},
  year={2023}
}

