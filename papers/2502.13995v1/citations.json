[
  {
    "index": 0,
    "papers": [
      {
        "key": "gal2022image",
        "author": "Gal, Rinon and Alaluf, Yuval and Atzmon, Yuval and Patashnik, Or and Bermano, Amit H and Chechik, Gal and Cohen-Or, Daniel",
        "title": "An image is worth one word: Personalizing text-to-image generation using textual inversion"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "ruiz2023dreambooth",
        "author": "Ruiz, Nataniel and Li, Yuanzhen and Jampani, Varun and Pritch, Yael and Rubinstein, Michael and Aberman, Kfir",
        "title": "Dreambooth: Fine tuning text-to-image diffusion models for subject-driven generation"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "hu2021lora",
        "author": "Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu",
        "title": "Lora: Low-rank adaptation of large language models"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "radford2021learning",
        "author": "Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others",
        "title": "Learning transferable visual models from natural language supervision"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "radford2021learning",
        "author": "Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others",
        "title": "Learning transferable visual models from natural language supervision"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "guo2024pulid",
        "author": "Guo, Zinan and Wu, Yanze and Chen, Zhuowei and Chen, Lang and Zhang, Peng and He, Qian",
        "title": "Pulid: Pure and lightning id customization via contrastive alignment"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "sun2023eva",
        "author": "Sun, Quan and Fang, Yuxin and Wu, Ledell and Wang, Xinlong and Cao, Yue",
        "title": "Eva-clip: Improved training techniques for clip at scale"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "wang2024instantid",
        "author": "Wang, Qixun and Bai, Xu and Wang, Haofan and Qin, Zekui and Chen, Anthony and Li, Huaxia and Tang, Xu and Hu, Yao",
        "title": "Instantid: Zero-shot identity-preserving generation in seconds"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "deng2019arcface",
        "author": "Deng, Jiankang and Guo, Jia and Xue, Niannan and Zafeiriou, Stefanos",
        "title": "Arcface: Additive angular margin loss for deep face recognition"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "he2024id",
        "author": "He, Xuanhua and Liu, Quande and Qian, Shengju and Wang, Xin and Hu, Tao and Cao, Ke and Yan, Keyu and Zhang, Jie",
        "title": "Id-animator: Zero-shot identity-preserving human video generation"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "guo2023animatediff",
        "author": "Guo, Yuwei and Yang, Ceyuan and Rao, Anyi and Liang, Zhengyang and Wang, Yaohui and Qiao, Yu and Agrawala, Maneesh and Lin, Dahua and Dai, Bo",
        "title": "Animatediff: Animate your personalized text-to-image diffusion models without specific tuning"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "yang2024cogvideox",
        "author": "Yang, Zhuoyi and Teng, Jiayan and Zheng, Wendi and Ding, Ming and Huang, Shiyu and Xu, Jiazheng and Yang, Yuanming and Hong, Wenyi and Zhang, Xiaohan and Feng, Guanyu and others",
        "title": "CogVideoX: Text-to-Video Diffusion Models with An Expert Transformer"
      },
      {
        "key": "opensora",
        "author": "Zangwei Zheng and Xiangyu Peng and Tianji Yang and Chenhui Shen and Shenggui Li and Hongxin Liu and Yukun Zhou and Tianyi Li and Yang You",
        "title": "Open-Sora: Democratizing Efficient Video Production for All"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "yuan2024identity",
        "author": "Yuan, Shenghai and Huang, Jinfa and He, Xianyi and Ge, Yunyuan and Shi, Yujun and Chen, Liuhan and Luo, Jiebo and Yuan, Li",
        "title": "Identity-Preserving Text-to-Video Generation by Frequency Decomposition"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "yang2024cogvideox",
        "author": "Yang, Zhuoyi and Teng, Jiayan and Zheng, Wendi and Ding, Ming and Huang, Shiyu and Xu, Jiazheng and Yang, Yuanming and Hong, Wenyi and Zhang, Xiaohan and Feng, Guanyu and others",
        "title": "CogVideoX: Text-to-Video Diffusion Models with An Expert Transformer"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "khakhulin2022realistic",
        "author": "Khakhulin, Taras and Sklyarova, Vanessa and Lempitsky, Victor and Zakharov, Egor",
        "title": "Realistic one-shot mesh-based head avatars"
      },
      {
        "key": "wiles2018x2face",
        "author": "Wiles, Olivia and Koepke, A and Zisserman, Andrew",
        "title": "X2face: A network for controlling face generation using images, audio, and pose codes"
      },
      {
        "key": "yao2020mesh",
        "author": "Yao, Guangming and Yuan, Yi and Shao, Tianjia and Zhou, Kun",
        "title": "Mesh guided one-shot face reenactment using graph convolutional networks"
      },
      {
        "key": "pang2023dpe",
        "author": "Pang, Youxin and Zhang, Yong and Quan, Weize and Fan, Yanbo and Cun, Xiaodong and Shan, Ying and Yan, Dong-ming",
        "title": "Dpe: Disentanglement of pose and expression for general video portrait editing"
      },
      {
        "key": "wang2021one",
        "author": "Wang, Ting-Chun and Mallya, Arun and Liu, Ming-Yu",
        "title": "One-shot free-view neural talking-head synthesis for video conferencing"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "blanz2023morphable",
        "author": "Blanz, Volker and Vetter, Thomas",
        "title": "A morphable model for the synthesis of 3D faces"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "DECA:Siggraph2021",
        "author": "Feng, Yao and Feng, Haiwen and Black, Michael J. and Bolkart, Timo",
        "title": "Learning an Animatable Detailed {3D} Face Model from In-The-Wild Images"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "li2017learning",
        "author": "Li, Tianye and Bolkart, Timo and Black, Michael J and Li, Hao and Romero, Javier",
        "title": "Learning a model of facial shape and expression from 4D scans."
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "ma2024cvthead",
        "author": "Ma, Haoyu and Zhang, Tong and Sun, Shanlin and Yan, Xiangyi and Han, Kun and Xie, Xiaohui",
        "title": "CVTHead: One-shot Controllable Head Avatar with Vertex-feature Transformer"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "chen2024echomimic",
        "author": "Chen, Zhiyuan and Cao, Jiajiong and Chen, Zhiquan and Li, Yuming and Ma, Chenguang",
        "title": "Echomimic: Lifelike audio-driven portrait animations through editable landmark conditions"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "lugaresi2019mediapipe",
        "author": "Lugaresi, Camillo and Tang, Jiuqiang and Nash, Hadon and McClanahan, Chris and Uboweja, Esha and Hays, Michael and Zhang, Fan and Chang, Chuo-Ling and Yong, Ming Guang and Lee, Juhyun and others",
        "title": "Mediapipe: A framework for building perception pipelines"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "zhang2023sadtalker",
        "author": "Zhang, Wenxuan and Cun, Xiaodong and Wang, Xuan and Zhang, Yong and Shen, Xi and Guo, Yu and Shan, Ying and Wang, Fei",
        "title": "Sadtalker: Learning realistic 3d motion coefficients for stylized audio-driven single image talking face animation"
      }
    ]
  }
]