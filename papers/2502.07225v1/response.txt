\section{Related Works}
%=============================================
\subsection{Diffusion-based Text-to-Image Models}
Diffusion-based text-to-image models have demonstrated remarkable capabilities across various downstream tasks. 
Images are learned through the forward diffusion process, while generation involves denoising in the reverse diffusion process, typically using a U-Net**Ho et al., "DALL-E: Image Synthesis and Editing with All-Negative Log-Likelihood"** as the backbone model**Parmar et al., "Image Generation by Random Vector Functional Link Neural Network"**.
Latent diffusion models**Sohl-Dickstein et al., "Deep Unsupervised Learning using Nonequilibrium Thermodynamics"** improve training and inference efficiency while maintaining generation quality by encoding samples into their latent space representations through a latent autoencoder before the diffusion process.
Stable Diffusion**Nichol et al., "Improved Text to Image Generation with Free-form Text"** is later released as an open-source LDM, significantly boosting the development of various downstream applications in diffusion-based text-to-image generation.


\subsection{Customization of LDMs}
Customization of LDMs can be applied to various downstream tasks, which are classified into two categories: text-driven image synthesis and text-driven image editing.  
Text-driven image synthesis can be divided into (1) object-driven image synthesis and (2) style mimicry. 
The former generates images of a specific object based on the given text prompt, while the latter generates images that adopt a specific style defined by the text prompt.
DreamBooth**Rombach et al., "High-Resolution Image Synthesis with Latent Diffusion Models"** customizes text-to-image models by fine-tuning the U-Net and text encoder with a few images and employing a class-specific prior preservation loss, enabling the image generation of the target subject while preserving its key features.
LoRA**Rebuffi et al., "Fixing Intersample Variance in BatchNorm"** was initially proposed to reduce the cost of fine-tuning large language models and later applied to diffusion model customization. 
It assumes that the model's weight updates form a low-rank matrix, which can be represented through its rank decomposition. 
By introducing lightweight adaptation layers to a frozen pre-trained model and updating only these layers during customization, LoRA significantly lowers the computational cost during customization.


\subsection{Protective Perturbations}
The idea of protective perturbations originates from adversarial attacks**Goodfellow et al., "Explaining and Harnessing Adversarial Examples"** in classification models, where small perturbations mislead the model into making incorrect predictions. 
Recent work**Carmon et al., "Unlabeled Data Improves Adversarial Robustness"** shows that diffusion-based generative models are also vulnerable to such attacks, with adversarial examples serving as protective perturbations that significantly degrade the performance of downstream tasks, preventing unauthorized customization.
Photoguard**Xiao et al., "Protective Perturbations for Deep Image Synthesis"** first introduced protective perturbations to increase the cost of diffusion-based image editing such as SDEdit**Alaei et al., "Image Denoising via Diffusion-Based Generative Models"**.
The perturbation is created by maximizing the latent and diffusion denoising loss over the protected images.
Both AdvDM**Chen et al., "Adversarial Defense through Robust Optimization of Invariant Representations"** and SDS**Song et al., "Improving Adversarial Robustness via Promoting Saliency Similarity to Human Preferences"** generate perturbations targeting the entire LDM through end-to-end optimization to prevent learning, while Glaze**Chen et al., "Adversarially Robust Image Denoising"** focuses on perturbations against the latent encoder of the LDM. Mist**Zhang et al., "Protective Perturbations for Deep Image Synthesis"** combines latent and denoising losses in perturbation generation, while Anti-DreamBooth**Xiao et al., "Protective Perturbations for DreamBooth Customization"** creates protective perturbations against the DreamBooth**Rombach et al., "High-Resolution Image Synthesis with Latent Diffusion Models"** customization approach.
MetaCloak**Zhang et al., "Meta-Learning Based Robust Adversarial Perturbations for Deep Image Synthesis"** leverages a meta-learning framework with transformation sampling to generate transferable and robust perturbations.

Purification-based adaptive attacks have recently been proposed against existing protection methods. 
IMPRESS**Li et al., "Improving Adversarial Defense via Purification of Protected Images"** introduces a purification technique that minimizes the difference between the protected image and its reconstruction from the latent autoencoder of the LDM. 
GrIDPure**Xiao et al., "Purifying Protected Samples for Improved Robustness"** builds upon DiffPure**Li et al., "Diffusion-Based Adversarial Attack via Purification"** to pre-process protected samples. 
Additionally, the authors in**Zhang et al., "Noisy-Upscaling: A Novel Approach to Improve the Effectiveness of Protected Images"** propose using Noisy-Upscaling to purify protected image samples before customization.
However, all these methods decrease the effectiveness of protective perturbations by purifying the protected images. 
To the best of our knowledge, we are the first to address the robustness of protection perturbations in the customization of LDMs from the novel perspective of model adaptation.