\section{Related Work}
\label{sec:related-work}
The computation of Gram matrices for signature-transformed time series was first recognized and systematically studied by Kir√°ly and Oberhauser \cite{kiraly2019kernels} as a foundational step in the principled application of rough path theory to data science and machine learning, as broadly envisioned by Lyons \cite{lyons2014rough}. Building on the conceptual framework of RKHS, Chevyrev and Oberhauser \cite{chevyrev2022signature} then extended the theoretical foundations of the signature kernel and introduced a statistically robust variant achieved through appropriate scaling of the constituent time series. Computationally, a significant advancement beyond the dynamic programming approach proposed by \cite{kiraly2019kernels} for calculating Gram matrices of \emph{truncated} signature transforms was achieved by Salvi et al.\ \cite{salvi2021signature}. In this work, the authors characterize the signature kernel as the solution to a linear second-order hyperbolic PDE on the unit square, thus enabling its numerical computation through specialized PDE solvers. This characterization introduced a new computational framework for the signature kernel, exemplified by the widely used libraries \texttt{sigkernel} and \texttt{ksig} \cite{toth2025user}, with the latter offering GPU-accelerated implementations of the Goursat-based finite difference approximation of \cite{salvi2021signature}.\\[-0.5em] 

\noindent
While PDE solvers typically provide highly parallelizable and fast routines for moderate-length time series, they suffer from excessive memory usage that scales poorly to long or rough time series. In practice, users have reported that the PDE-based approaches can become infeasible beyond a few thousands or ten thousands of time-steps \cite{toth2025user}, particularly when GPU memory is limited. (In our testing on 4090 RTX GPUs, the length of time series that the existing algorithms can operate on is limited to $\sim 10^3$ for SigKernel \cite{salvi2021signature} and $~16 \times 10 ^4$ for KSig \cite{toth2025user}.) Dynamic programming remains an option for computing kernels of truncated signatures \cite{kiraly2019kernels}, although it likewise suffers from poor scalability. Recent efforts to reduce this cost through random Fourier features or other low-rank approximations \cite{toth2023random} often degrade in accuracy for larger time-series length or higher dimensionality.\\[-0.5em]

\noindent
By contrast, our work focuses on tilewise local expansions of the signature kernel, avoiding the need for a global $\mathcal{O}(\ell^2)$ storage footprint. Specifically, each tile of the full temporal domain of the signature kernel is handled with a Neumann-type integral expansion that converges rapidly, allowing for a truncated power-series representation of the kernel localized to that subregion. In this approach, which naturally lends itself to the integral-equation viewpoint on Volterra-type PDEs, we store only local series coefficients rather than a full two-dimensional array. This allows our \texttt{PowerSig} algorithm to compute signature kernels for time series of length of over $5 \times 10^5$ on a single GPU, while retaining superior accuracy. The principal appeal of our method thus lies in its memory efficiency and ability to scale to very long, high-dimensional time series where PDE or DP approaches risk overwhelming storage capacities.