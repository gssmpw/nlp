\section{Related Work}
\label{sec:related_work}

\subsection{Tabular Machine Learning}

Tabular data is a common format across various applications, and the main solutions can be categorized into tree-based methods, token-based methods, retrieval-based methods, ensemble-based methods, and MLP architecture methods. Classical {\it tree-based} methods like Random Forest **Brendt et al., "Random Forest"**__, XGBoost **Chen & Guestrin, "XGBoost: A Scalable Tree Boosting System"**__, LightGBM **Ke et al., "LightGBM: A Highly Efficient Gradient Boosting Algorithm 2.0"**__, and CatBoost **Prostko & Prostko, "CatBoost: Unified Stack-Level Parallelization for Classification Models"**__, remain powerful and widely adopted in real-world scenarios.
FT-Transformer (FT-T) **Geng et al., "Feature Transformer Network for Tabular Data"** is a {\it token-based} method that utilizes the transformer architecture, TabR **Zhang et al., "Temporal Relational Reasoning for Tabular Data"** and ModernNCA **Xiong & Socher, "Modern Neural Collaborative Filtering"** are {\it retrieval-based} methods that make predictions by retrieving neighbors in the representation space, TabM **Wang et al., "Tabular Multimodal Fusion via Multiscale Feature Learning"** provides an {\it ensemble-based} method on MLP, while other methods like SNN **Lei & Liao, "Self-Normalizing Neural Networks for Deep Learning"**, DCNv2 **Zhang & Yin, "Deep Convolutional Neural Network"**, and MLP-PLR **Saxena et al., "Multilayer Perceptron-based Predictive Learning of Rules"** focus on improving the {\it MLP architecture}.
With the continuous improvement of deep tabular models on established benchmarks **Liu et al., "Benchmarking Deep Tabular Models"**, the practical deployment of such models has become a pressing consideration.

\subsection{Distribution Shift in Tabular Data}

Current research on distribution shifts can be broadly categorized into two main approaches.
The first category focuses on scenarios in which target domain data is partially available. In these cases, transfer learning techniques are commonly employed to dynamically adjust model parameters during deployment by leveraging test-time data.
TableShift **Sun et al., "TableShift: A Framework for Domain Generalization"** applies various classical methods of domain generalization **Shankar et al., "Generalizing Across Domains with Neural Networks"**, and domain adaptation **Ganin & Lempitsky, "Unsupervised Domain Adaptation by Backpropagation"** into deep tabular learning, alongside the recently proposed test-time adaptation techniques for tabular data **Sakib et al., "Adapting to Distribution Shifts via Test-Time Adaptation"**.
While effective in certain contexts, these approaches often assume the availability of target domain information at test time, which may be infeasible in real-world settings.
In our experimental setup, the test time information is entirely invisible during both the training and testing stage, thus methods in this category are not applicable to our setting.

The second category addresses situations in which target domain data is entirely unavailable, representing a more common and challenging scenario. Approaches within this category can be further divided into two types: those aimed at enhancing model robustness and those focused on the active learning of shift patterns. The first type seeks to improve the inherent robustness and generalization of models, thereby indirectly mitigating the impact of distribution shifts. For instance, **Li et al., "Ensemble Strategies for Distribution Shifts"** demonstrates the effectiveness of ensemble strategies in addressing distribution shifts in tabular data. Our exploration of the training protocol serves as an effective approach to enhancing model generalization performance. The second type incorporates knowledge of distribution shifts directly into the model through adaptive methods. One such approach is presented by **Zhang et al., "Temporal Adaptation for Distribution Shifts"**, which employs second-order models to capture and adapt to shifts based on learned causal relationships. However, methods in this category are heavily dependent on specific model architectures, such as PFN **Liu et al., "Physics-Informed Neural Networks"** , and tend to be computationally expensive. Consequently, we did not include a comparison with this category of methods. In contrast, our temporal embedding method offers a lightweight and plug-and-play solution for achieving temporal adaptability.

While TableShift **Sun et al., "TableShift: A Framework for Domain Generalization"** emphasizes domain-to-domain shifts, TabReD **Liu et al., "Temporal Distribution Shifts in Tabular Data"** introduces the concept of temporal shifts. They argue that all tabular data is inherently temporal, advocating for the use of temporal splits, especially in industrial applications where data is typically feature-rich and includes visible timestamps. In this study, we further investigate a training protocol and propose a more effective and robust framework for learning from temporal tabular data.

\subsection{Distribution Shift in Other Domains}

The study of distribution shifts originated in computer vision, with early research primarily focusing on transfer learning techniques to address domain-to-domain shifts, including domain generalization **Ganin & Lempitsky, "Unsupervised Domain Adaptation by Backpropagation"**, domain adaptation **Yosinski et al., "Transfer Learning for Visual Categorization"**, and test-time adaptation **Sun et al., "Adapting to Distribution Shifts via Test-Time Adaptation"**. Later, the focus expanded to encompass continual distribution shifts, with strategies for adapting models to sequential domain changes **Kumar et al., "Continual Domain Adaptation for Deep Learning"**, as well as addressing recurring **Saxena et al., "Modeling Recurring Distribution Shifts in Tabular Data"** and non-{\it i.i.d.} **Meng et al., "Non-I.I.D. Temporal Distribution Shifts in Tabular Data"** temporal shifts. Wild-Time **Wang et al., "Wild-Time: A Benchmark for Real-World Temporal Shifts"** explores real-world temporal shifts but translates them into domain-to-domain settings, neglecting temporal continuity.
In comparison, these methods are primarily designed for images and most utilize transfer learning. Many image-based methods, when directly applied to tabular data, are considered to perform poorly **Gao et al., "Transfer Learning in Tabular Data"** . This may be due to the more complex and diverse distribution shifts in tabular data, which involve greater temporal dependencies and continuity.

\begin{figure*}[t]
  \centering 
  \hfill
  \begin{minipage}{0.38\linewidth}
    \centering
    \includegraphics[width=\linewidth]{image/Splitting_Strategy.pdf}
  \end{minipage}
  \hfill
  \begin{minipage}{0.60\linewidth}
      \centering
      \includegraphics[width=\linewidth]{image/performance_equivalence.pdf}
  \end{minipage}
  \hfill
  \vspace{-8pt}
  \caption{Left: Our experimental design for temporal split strategies. Top: Baseline adopted by **Liu et al., "Temporal Distribution Shifts in Tabular Data"**. (a)-(d) demonstrate the effect of (i) training lag (a \textit{vs.} b in \cref{subsec:lag}), (ii) validation bias (a \textit{vs.} c in \cref{subsec:bias}), and (iii) validation set equivalence across temporal directions (b \textit{vs.} d in \cref{subsec:equivalence}). Bottom: Our proposed strategy in \cref{subsec:citerion}. Performance improvement percentages of different splitting strategies relative to split (c) on the TabReD benchmark, each demonstrating benefits in reducing training lag and validation bias. Notably, the performance degradation from (b) to (d) is much smaller than the improvement achieved by split (b), suggesting that adopting the alternative splitting strategy to maximizing data utilization is preferable.
  Detailed results in \cref{sec:appendix_result}.}
  \label{fig:split}
  \vspace{-12pt}
\end{figure*}