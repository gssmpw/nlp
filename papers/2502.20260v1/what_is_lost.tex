\section{What is Lost in Temporal Training?}
\label{sec:what_is_lost}

Looking back to the MMD heatmap in \cref{fig:mmd} right, we observe that the original data distribution offers a rich source of temporal information, including the periodicity and the trend. \cref{fig:periodic} left presents a detailed MMD heatmap visualization of the Homesite Insurance dataset, revealing both yearly and weekly periodicity, as well as the underlying trend.
We further investigate the impact of temporal shifts on deep tabular methods from the perspective of feature representations.

Unexpectedly, by comparing the MMD heatmaps of the learned representations of MLP in our training protocol (shown in \cref{fig:periodic} mid), we observe that the periodicity and the trend are lost in the model representations. Instead of the diagonal stripes observed in the original data distribution, the learned representations exhibit only shallow grids and a more uniform distribution, suggesting that temporal information has not been effectively preserved. This indicates that the model has captured the distinction between weekdays and weekends but failed to capture the long-term periodicity and finer details of short-term cycles.

This phenomenon may account for the suboptimal performance of datasets with clear periodic patterns, such as Cooking Time, Delivery ETA, and Maps Routing datasets, which are socially related and exhibit distinct weekly cycles, while the Weather dataset, being influenced by natural cycles, shows a clear yearly pattern. We would expect models using temporal splits to capture long-term periodicity and trends, enabling them to learn extrapolative knowledge. However, this critical knowledge does not seem to be effectively learned. In contrast, random splits appear more proficient at capturing local patterns, particularly those associated with short-term periodicity. This could explain why temporal splitting does not consistently outperform random splitting in these cases. Furthermore, it also explains the reasons why existing methods encounter challenges in dealing with temporal shifts.