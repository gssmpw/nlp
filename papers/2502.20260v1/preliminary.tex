\section{Preliminary}
\label{sec:preliminary}

Generally, a tabular dataset with \(n\) instance is represented as \( \mathcal{D} = \{(\mathbf{x}_i, \mathbf{y}_i)\}_{i=1}^n \), where \(\mathbf{x}_i \in \mathcal{X}\) is the input feature and \(\mathbf{y}_i \in \mathcal{Y}\) is the target label. Here, \( \mathcal{X} \) denotes the feature space ({\it e.g.}, \(\mathbb{R}^d\)) and \( \mathcal{Y} \) denotes the label space ({\it e.g.}, classes or real values). 
The goal is to learn a mapping \( f: \mathcal{X} \to \mathcal{Y} \) that can generalize from the observed data to unseen instances, effectively predicting \( \hat{\mathbf{y}}_i = f(\mathbf{x}_i) \) for a given input \( \mathbf{x}_i \).

The objective function \( f \) can be decomposed into two components: \( f = g \circ h \), where \( g \) for feature extraction and \( h \) for prediction. In \textit{MLP architectures}, both \( g \) and \( h \) are neural networks, with \( g \) consisting of multiple layers and \( h \) being the final output layer. In \textit{ensemble-based methods}, multiple models \( f_i = g_i \circ h_i \) are trained, and the final prediction is obtained by averaging the outputs, which reduces variance and improves generalization. \textit{Retrieval-based methods} use a neural network for \( g \) and a non-parametric prediction method, such as a soft KNN adopted in ModernNCA \cite{ye2024modern}, for \( h \), 
where predictions are based on the closest neighbors of ``candidates'' â€” instances from the training set that are mapped to the representation space and serve as potential reference points during prediction.

A temporal tabular dataset collected before \( T_{\text{train}} \) for model training and deployment can be represented as \( \mathcal{D}_{\text{trainval}} = \bigcup_{t \leq T_{\text{train}}} \mathcal{D}_t \), where \( \mathcal{D}_t = \{(\mathbf{x}_i, \mathbf{y}_i, t)\}_{i=1}^{n_t} \) denotes the set of \(n_t\) instances collected at time \(t\), each attached with its timestamp.
\( T_{\text{train}} \) is the time at which training is performed.
After training, the model is deployed to an open environment and evaluated on \( \mathcal{D}_{\text{test}} = \bigcup_{t > T_{\text{train}}}\mathcal{D}_t \).
The training data \( \mathcal{D}_{\text{trainval}} \) need to be further split into training and validation set in training stage. 
TabReD \cite{rubachev2024tabred} adopts a temporal split where the data is divided at \( T_\text{val} \), such that \( \mathcal{D}_\text{train} = \bigcup_{t \leq T_{\text{val}}}\mathcal{D}_t\) and \( \mathcal{D}_\text{val} = \bigcup_{T_\text{val} < t \leq T_{\text{train}}}\mathcal{D}_t\).

A \textit{temporal distribution shift} refers to a specific type of distribution shift where the data is collected sequentially over time, and the underlying data distribution evolves as time progresses. Formally, let \( \mathcal{X}_t \), \( \mathcal{Y}_t \) denote the feature space and label space at time \( t \), respectively. A temporal distribution shift concurrently suffer from covariant shift, label shift, and concept shift, {\it i.e.}, \( \mathcal{X}_t \neq \mathcal{X}_{t'} \), \( \mathcal{Y}_t \neq \mathcal{Y}_{t'} \), or \( P\left(\mathcal{Y}_t \mid \mathcal{X}_t\right) \neq P\left(\mathcal{Y}_{t'} \mid \mathcal{X}_{t'}\right) \) for some \( t \neq t' \).

Conventional approaches for tabular data analysis have primarily relied on the {\it i.i.d.} assumption, where the feature extraction function \( g \) typically maps all input data to a shared representation space, implicitly assuming that the data distribution remains stationary over time.
As a result, the impact of temporal dynamics on the effectiveness of these methods remains largely unexplored and warrants investigation.