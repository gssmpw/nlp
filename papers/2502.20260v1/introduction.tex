\section{Introduction}
\label{sec:introduction}
Tabular data is one of the most prevalent data formats in a wide range of real-world applications, such as e-commerce \cite{nederstigt2014floppies} and healthcare \cite{hassan2020machine}. It consists of instances (rows) and features (columns), where the label can either be categorical or continuous, corresponding to classification and regression tasks, respectively. The goal is to learn a mapping strategy from features to labels that can be directly applied to independent and identically distributed ({\it i.i.d.}) test data for accurate predictions \cite{bishop2007pattern, mohri2012foundations}. While tree-based methods remain powerful \cite{breiman2001random, chen2016xgboost, ke2017lightgbm, prokhorenkova2018catboost}, recent advancements in deep learning methods for tabular data have demonstrated promising results \cite{klambauer2017self, wang2021dcn, gorishniy2021revisiting, gorishniy2024tabr, gorishniy2024tabm, hollmann2022tabpfn, hollmann2025accurate, holzmuller2024better, ye2023rethinkingpretrainingtabulardata, ye2024modern, liu2025tabpfnunleashed}. 

\begin{figure}[t]
  \centering
  \vspace{-2pt}
  \includegraphics[width=\linewidth]{image/iid.pdf}
  \vspace{-22pt}
  \caption{Illustration of the challenges posed by temporal shifts. The change in data distribution over time is represented by dots on a line, with the dashed line depicting the underlying data distribution at different time slices. The shaded box indicates the mapping \( f \) learned from the training data at \( T_\text{train} \), while the training data is typically treated as {\it i.i.d.} on \( \mathcal{X}_\text{train} \) and \( \mathcal{Y}_\text{train} \) in classical training processes. On {\it i.i.d.} data, the model can directly apply the learned mapping \( f \) to make accurate predictions on test data, but it fails to generalize effectively when temporal shifts occur.}
  \label{fig:setting}
  \vspace{-15pt}
\end{figure}

Most machine learning approaches are built on the assumption of {\it i.i.d.} data. However, in open environments \cite{zhou2022open}, distribution shifts \cite{gardner2023benchmarking, tschalzev2024data} frequently occur between the training and testing data, which can manifest as shifts in the feature space, label space, or the mapping between them.
Moreover, in practical applications, data often exhibits temporal distribution shifts \cite{rubachev2024tabred}, a particularly common type of distribution shift that introduces additional challenges: instead of just shifts between training and test sets, temporal shifts can occur within the training set or the test set itself. 
For example, in house price prediction \cite{matveev2017sberbank}, the task is to predict future house prices using historical transaction data, which includes features such as location, neighborhood conditions, and economic factors. 
However, in actual practice, the trend of housing policies or the periodic fluctuations of public sentiment can also play crucial roles in influencing house prices.

These temporal shifts  lead to the failure of the model when the training process assumes the data to be {\it i.i.d.}
The challenge of training on temporal shift data is illustrated in \cref{fig:setting}. Formally, we aim to perform model training and validation using data prior to \(T_\text{train}\), and subsequently use the trained model to make predictions on data after \(T_\text{train}\). 
Once the temporal shift occurs, it leads to discrepancies between the mapping learned during training and the one required for deployment, making the model ineffective.

Since temporal shifts are common and present significant challenges, we have turned our attention on whether tabular data models that perform well in classic {\it i.i.d.} scenarios can effectively manage temporal shifts.
In recent studies, \citet{rubachev2024tabred} introduced the TabReD benchmark. By comparing the performance differences of various methods on the original temporal shift dataset and the {\it i.i.d.} dataset constructed through shuffling, their observations revealed that while models with MLP architectures exhibit relative robustness during temporal shifts, retrieval-based methods, which are highly competitive in current benchmarks \cite{ye2024closer}, suffer a marked performance degradation in temporal shift scenarios. 
This observation demonstrates that the occurrence of temporal shifts can introduce significant biases in the evaluation of model performance, further emphasizing the importance of understanding and managing these temporal shifts.

\begin{figure*}[t]
  \centering 
  \vspace{-5pt}
  \includegraphics[width=\linewidth]{image/performance_comparison.pdf}
  \vspace{-28pt}
  \caption{Performance comparison between temporal split in \citet{rubachev2024tabred} and random split on TabReD benchmark, where only the data splitting strategy before \(T_{\text{train}}\) is changed. The percentage change represents the \textit{robust average} of performance difference \textit{compared to the MLP with temporal split}. 
  A positive percentage change indicates that the method outperforms the MLP with temporal split. 
  Left: We reproduced the experiment from \citet{rubachev2024tabred}, and ensured a fair comparison by removing numerical embeddings and fixing the categorical embeddings to one-hot embedding when needed. In this case, the performance of retrieval-based methods significantly declines, falling behind tree-based methods and MLP-PLR, while TabM achieves the best performance.
  Right: The performance improvement observed when using the random splitting strategy. Retrieval-based methods show the greatest improvement, and the performance rankings of the models aligned more closely with conventional findings.
  Detailed results are provided in \cref{sec:appendix_result}.}
  \label{fig:random}
  \vspace{-12pt}
\end{figure*}

In temporal shift tasks, the absence of accurate test data validation during the training stage \cite{blanchard2021domain} makes model selection more impactful, as deep learning models are optimized epoch-wise.
TabReD employs a temporal splitting strategy to match the test scenario, utilizing earlier data for training and later data prior to \( T_\text{train} \) as the  validation set for model selection.
Surprisingly, we discovered that by merely altering the splitting strategy on the same training data, even when randomly splitting the training and validation sets and ignoring temporal order, the model outperformed the temporal split, resulting in significantly enhanced performance, as illustrated in \cref{fig:random}. Moreover, the performance rankings of the models became more consistent with established results on {\it i.i.d.} data, with retrieval-based methods showing more distinct improvements. This unexpected finding underscores the urgent need to investigate effective data splitting strategies to accurately assess model performance and reveal its true capabilities in the presence of temporal shifts. Despite the performance improvement, the random split exhibits pronounced instability in temporal shift context, which also requires attention.

We begin by {\bf analyzing the factors contributing to the ineffectiveness of temporal splitting in this context}. 
While temporal-based splitting is commonly employed in forecasting tasks to maintain causal relationships \cite{bergmeir2012use}, 
the most intuitive difference when adopting a temporal split in tabular learning lies in the \textit{time lag between the training and test sets}, and the \textit{bias in validation}, since the data closest to the test time are not used for training, and the shift degree of test set relative to validation set is more significant in temporal splits.
By investigating the impact of these two factors, we find that 
minimizing the training lag concentrates the model's performance closer to the test time, 
while reducing validation bias by aligning the shift degree makes the model better generalize on test data.
Building on these insights, we propose a training protocol along with an improved temporal split that leverages these advantages, resulting in a comparable performance to random splitting while providing better stability.

We further {\bf investigate the impact of temporal shifts on deep tabular methods from the perspective of \textit{feature representations}}. Through the visualization of the model's deep-layer representations, we observe that the trends and periodic information, which are prevalent in the raw data, gradually diminish in the feature representations. 
This indicates a loss of temporal information in the representation, leading to the restriction of the model's temporal prediction ability. This also explains why existing methods encounter challenges in addressing temporal shifts.

Based on the analysis presented above, it is essential to effectively incorporate temporal information into the model. To address this gap, we {\bf develop a lightweight, plug-and-play \textit{temporal embedding} method} based on Fourier series expansion. This approach equips the model with learnable periodic and trend information while preserving its original capabilities.
Experiments demonstrate that temporal embedding further enhances the capacity of all models to address shift problems. Furthermore, this method can be regarded as a {\it temporally adaptive approach}. Once the model is provided with temporal information, it can acquire knowledge specific to different temporal stages. This capability allows the model to adjust adaptively after deployment.

In summary, this paper investigates the challenges posed by temporal distribution shifts in tabular data and explores effective strategies to address them. Starting with a training protocol that fully leverages temporal data, we delve into the impact of temporal shifts during the model training process. We further propose a temporal embedding method to compensate for the loss of temporal information, thereby enhancing the model’s ability to adapt to temporal shifts and improve its real-world performance. These insights offer crucial guidance for the future development of deep tabular methods in temporal shift scenario.