\section{Related Work}
\label{sec:related_work}

\subsection{Tabular Machine Learning}

Tabular data is a common format across various applications, and the main solutions can be categorized into tree-based methods, token-based methods, retrieval-based methods, ensemble-based methods, and MLP architecture methods. Classical {\it tree-based} methods like Random Forest \cite{breiman2001random}, XGBoost \cite{chen2016xgboost}, LightGBM \cite{ke2017lightgbm}, and CatBoost \cite{prokhorenkova2018catboost}, remain powerful and widely adopted in real-world scenarios.
FT-Transformer (FT-T) \cite{gorishniy2021revisiting} is a {\it token-based} method that utilizes the transformer architecture, TabR \cite{gorishniy2024tabr} and ModernNCA \cite{ye2024modern} are {\it retrieval-based} methods that make predictions by retrieving neighbors in the representation space, TabM \cite{gorishniy2024tabm} provides an {\it ensemble-based} method on MLP, while other methods like SNN \cite{klambauer2017self}, DCNv2 \cite{wang2021dcn} and MLP-PLR \cite{gorishniy2022embeddings} focus on improving the {\it MLP architecture}.
With the continuous improvement of deep tabular models on established benchmarks \cite{mcelfresh2023when, ye2024closer}, the practical deployment of such models has become a pressing consideration.

\subsection{Distribution Shift in Tabular Data}

Current research on distribution shifts can be broadly categorized into two main approaches.
The first category focuses on scenarios in which target domain data is partially available. In these cases, transfer learning techniques are commonly employed to dynamically adjust model parameters during deployment by leveraging test-time data.
TableShift \cite{gardner2023benchmarking} applies various classical methods of domain generalization \cite{ganin2016domain} and domain adaptation \cite{sun2016deepcoral} into deep tabular learning, alongside the recently proposed test-time adaptation techniques for tabular data \cite{kim2024adaptable}.
While effective in certain contexts, these approaches often assume the availability of target domain information at test time, which may be infeasible in real-world settings.
In our experimental setup, the test time information is entirely invisible during both the training and testing stage, thus methods in this category are not applicable to our setting.

The second category addresses situations in which target domain data is entirely unavailable, representing a more common and challenging scenario. Approaches within this category can be further divided into two types: those aimed at enhancing model robustness and those focused on the active learning of shift patterns. The first type seeks to improve the inherent robustness and generalization of models, thereby indirectly mitigating the impact of distribution shifts. For instance, \citet{gorishniy2024tabm} demonstrates the effectiveness of ensemble strategies in addressing distribution shifts in tabular data. Our exploration of the training protocol serves as an effective approach to enhancing model generalization performance. The second type incorporates knowledge of distribution shifts directly into the model through adaptive methods. One such approach is presented by \citet{helli2024drift}, which employs second-order models to capture and adapt to shifts based on learned causal relationships. However, methods in this category are heavily dependent on specific model architectures, such as PFN \cite{hollmann2022tabpfn}, and tend to be computationally expensive. Consequently, we did not include a comparison with this category of methods. In contrast, our temporal embedding method offers a lightweight and plug-and-play solution for achieving temporal adaptability.

While TableShift \cite{gardner2023benchmarking} emphasizes domain-to-domain shifts, TabReD \cite{rubachev2024tabred} introduces the concept of temporal shifts. They argue that all tabular data is inherently temporal, advocating for the use of temporal splits, especially in industrial applications where data is typically feature-rich and includes visible timestamps. In this study, we further investigate a training protocol and propose a more effective and robust framework for learning from temporal tabular data.

\subsection{Distribution Shift in Other Domains}

The study of distribution shifts originated in computer vision, with early research primarily focusing on transfer learning techniques to address domain-to-domain shifts, including domain generalization \cite{blanchard2011generalizing, blanchard2021domain}, domain adaptation \cite{ganin2015unsupervised}, and test-time adaptation \cite{wang2021tent}. Later, the focus expanded to encompass continual distribution shifts, with strategies for adapting models to sequential domain changes \cite{wang2022continual}, as well as addressing recurring \cite{hoang2024persistent} and non-{\it i.i.d.} \cite{gong2022note} temporal shifts. Wild-Time \cite{yao2022wild} explores real-world temporal shifts but translates them into domain-to-domain settings, neglecting temporal continuity.
In comparison, these methods are primarily designed for images and most utilize transfer learning. Many image-based methods, when directly applied to tabular data, are considered to perform poorly \cite{gardner2023benchmarking}. This may be due to the more complex and diverse distribution shifts in tabular data, which involve greater temporal dependencies and continuity.

\begin{figure*}[t]
  \centering 
  \hfill
  \begin{minipage}{0.38\linewidth}
    \centering
    \includegraphics[width=\linewidth]{image/Splitting_Strategy.pdf}
  \end{minipage}
  \hfill
  \begin{minipage}{0.60\linewidth}
      \centering
      \includegraphics[width=\linewidth]{image/performance_equivalence.pdf}
  \end{minipage}
  \hfill
  \vspace{-8pt}
  \caption{Left: Our experimental design for temporal split strategies. Top: Baseline adopted by \citet{rubachev2024tabred}. (a)-(d) demonstrate the effect of (i) training lag (a \textit{vs.} b in \cref{subsec:lag}), (ii) validation bias (a \textit{vs.} c in \cref{subsec:bias}), and (iii) validation set equivalence across temporal directions (b \textit{vs.} d in \cref{subsec:equivalence}). Bottom: Our proposed strategy in \cref{subsec:citerion}. Performance improvement percentages of different splitting strategies relative to split (c) on the TabReD benchmark, each demonstrating benefits in reducing training lag and validation bias. Notably, the performance degradation from (b) to (d) is much smaller than the improvement achieved by split (b), suggesting that adopting the alternative splitting strategy to maximizing data utilization is preferable.
  Detailed results in \cref{sec:appendix_result}.}
  \label{fig:split}
  \vspace{-12pt}
\end{figure*}