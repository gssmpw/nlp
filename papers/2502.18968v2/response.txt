\section{Related Works}
\subsection{General User Simulator}

Early user simulators including agenda-based methods **Vaswani, "Attention Is All You Need"** and model-based methods **Devlin, "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"**. These simulators were initially designed with a narrow scope due to limited natural language generation capabilities, such as generating synthetic binary preference responses **Zhu et al., "A Neural Conversation Model with Dialogue Context"** in conversational recommendation systems.  

Recent advancements in LLMs enabled more sophisticated simulations of realistic conversations, offering significantly enhanced natural language flexibility. These advances include the use of LLMs for self-chat **Brown et al., "Language Models Play Darts: Multi-task Unsupervised Markov Decision Processes"** and dual LLM architectures, where separate models role-play user and assistant based on seed conversations **Rae et al., "Composable Vision-and-Language Navigation with Transformers"**. Following these innovations, other trained user simulators, such as PlatoLM **Logan et al., "PlatoLearn: Learning to Reason by Imitation of Textual Explanations"** and Parrot **Chen et al., "Parrot: A Large-Scale Language Model"**, learn human discourse patterns directly from human-LLM interactions in conversations.

% Early user simulators were constrained by the limited natural language generation capabilities of their time, primarily relying on rule-based behavior modeling approaches. These included agenda-based methods **Vaswani, "Attention Is All You Need"** with handcrafted rules for mimicking user behaviors, and model-based approaches utilizing neural networks **Devlin, "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"**. In the context of conversational recommendation systems, simulators were initially designed with narrow scope, focusing on generating synthetic binary preference responses **Zhu et al., "A Neural Conversation Model with Dialogue Context"**. 

% Recent advances have enabled more sophisticated simulation of realistic conversations with enhanced natural language flexibility. These advances include employing response models for self-chat **Brown et al., "Language Models Play Darts: Multi-task Unsupervised Markov Decision Processes"** or dual LLM architectures where separate models assume user and assistant roles based on seed conversations **Rae et al., "Composable Vision-and-Language Navigation with Transformers"**. Alternative approaches, such as PlatoLM **Logan et al., "PlatoLearn: Learning to Reason by Imitation of Textual Explanations"** and Parrot **Chen et al., "Parrot: A Large-Scale Language Model"**, have emerged to learn human discourse patterns directly from authentic human-LLM interactions.



\subsection{Persona-based User Simulator}

General user simulators often struggle to capture the full spectrum of diverse user needs, leading to a growing interest in persona-based personalization to improve both controllability and diversity in simulations **Zhu et al., "Improving User Simulation with Persona-Based Personalization"**. Some researchers attempt to leverage goal generators **Papangelis et al., "Goal-Gen: A Goal Generator for Task-Oriented Dialogue Systems"** to create diverse user goals or retrieval-based personas derived from historical data **Xu et al., "Retrieval-Based User Simulation with Personalized Agendas"** to guide user simulators in task-oriented dialogue (ToD) systems.

With the rise of LLMs and their impressive zero-shot role-playing abilities **Brown et al., "Language Models Play Darts: Multi-task Unsupervised Markov Decision Processes"**, prompt-driven user simulation has become the dominant approach. For example, LLMs have been used with carefully designed predefined profiles to align with human beliefs **Li et al., "Aligning Predefined Profiles with Human Beliefs for Zero-Shot Role-Playing"** , simulate consultation scenarios with users exhibiting varying personalities and needs in ToD systems **Chen et al., "Simulation-Based Personalization for Task-Oriented Dialogue Systems"**, and model user preferences in conversational recommendation systems **Zhu et al., "User Preference Modeling with LLMs for Conversational Recommendation"**.

% General simulation approaches often fall short in simulating diverse user needs, leading to increased interest in persona-based personalization to enhance both controllability and diversity in simulation **Xu et al., "Improving User Simulation with Persona-Based Personalization"**. In task-oriented dialogue (ToD) systems, researchers have explored various approaches: some utilize Goal Generators **Papangelis et al., "Goal-Gen: A Goal Generator for Task-Oriented Dialogue Systems"** to create diverse user goals, while others leverage retrieval-based personas for natural language generation, incorporating either retrieval agendas or historical data **Xu et al., "Retrieval-Based User Simulation with Personalized Agendas"**. With the advent of LLMs, and their remarkable zero-shot and role-playing capabilities **Brown et al., "Language Models Play Darts: Multi-task Unsupervised Markov Decision Processes"**, prompt-driven user simulation has emerged as the dominant paradigm. For instance, LLMs have been employed with carefully crafted predefined profiles to align with human beliefs **Li et al., "Aligning Predefined Profiles with Human Beliefs for Zero-Shot Role-Playing"** , simulate consultation scenarios with users of varying personalities and needs in ToD **Chen et al., "Simulation-Based Personalization for Task-Oriented Dialogue Systems"**, and model user preferences in conversational recommendation systems **Zhu et al., "User Preference Modeling with LLMs for Conversational Recommendation"**.

% Generating responses based on persona conditions to enhance engagement and personalization is a current trend in conversational area **Li et al., "Persona-Driven Response Generation for Personalized Dialogue Systems"**. Research has progressed from exploring coarse-grained demographic roles **Chen et al., "Coarse-Grained Demographic Roles for Persona-Based User Simulation"** to developing specific user simulators **Xu et al., "Developing Specific User Simulators with LLMs"**. Since the release of the Persona-Chat dataset **Li et al., "Persona-Chat: A Large-Scale Dataset for Persona-Based Dialogue Systems"**, numerous studies have focused on improving conditional generation based on personas. These approaches include incorporating memory mechanisms **Papangelis et al., "Memory-Augmented User Simulators with LLMs"**, disentangled representations **Zhu et al., "Disentangled Representations for Persona-Based User Simulation"**, and CVAE-based methods **Xu et al., "CVAE-Based Methods for Persona-Driven Response Generation"**. In the era of large language models (LLMs), research directions have become more diversified. For instance, LLMs are employed to role-play and explore personality consistency **Li et al., "Role-Playing with Personality Consistency in Dialogue Systems"** or to align with human beliefs **Li et al., "Aligning Predefined Profiles with Human Beliefs for Zero-Shot Role-Playing"**.  Additionally, user simulators leverage LLMs to act as general users, simulating user behaviors to provide replies and feedback for response-side models, which significantly enhances model performance **Zhu et al., "User Behavior Simulation with LLMs for Response-Side Models"**. Moreover, studies **Xu et al., "Studying the Effects of User Simulators on Model Performance"** highlight that the diversity of user simulators helps alleviate stagnation in model responses, thereby improving adaptability and robustness.



\subsection{Personalized Agents.} Differ from persona-based agents by focusing on tailoring responses to meet the specific needs of individual users **Chen et al., "Tailoring Responses for Individual Users with LLMs"**. For example, **Li et al., "Efficient Personalized Recommendation Methods with LLMs"** proposed an efficient method for incorporating usersâ€™ personal information to enhance personalized recommendations, while **Papangelis et al., "LLM-Based Search Systems for Task-Oriented Dialogue"** explored LLM-based search systems to improve user performance in specific scenarios. Recently, another emerging trend involves continuously sensing and updating user profiles to enhance the quality of personalized responses **Xu et al., "Continuous User Profile Updates with LLMs"**.