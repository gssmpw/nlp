% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}
\usepackage{CJKutf8} % 支持中文

% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
% Change to "preprint" to generate a non-anonymous version with page numbers.
\usepackage[final]{acl}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{fdsymbol}
\usepackage{amsmath}
\usepackage[most]{tcolorbox}
\usepackage{afterpage}


\usepackage{url}
% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}
\usepackage{multicol}
\usepackage{multirow}
\usepackage{array}
\usepackage{geometry}    % 用于调整页面边距
\usepackage{adjustbox}   % 用于自动缩放表格宽度

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}

%Including images in your LaTeX document requires adding
%additional package(s)
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{graphicx}  % Add this to the preamble
\usepackage{xcolor}
\usepackage{subfig}
\usepackage{CJKutf8}

\newcommand{\lz}[1]{\textcolor{blue}{{#1}}}
% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

\title{Know You First and Be You Better: \\Modeling Human-Like User Simulators via Implicit Profiles}

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a separate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}



%\author{
%  \textbf{First Author\textsuperscript{1}},
%  \textbf{Second Author\textsuperscript{1,2}},
%  \textbf{Third T. Author\textsuperscript{1}},
%  \textbf{Fourth Author\textsuperscript{1}},
%\\
%  \textbf{Fifth Author\textsuperscript{1,2}},
%  \textbf{Sixth Author\textsuperscript{1}},
%  \textbf{Seventh Author\textsuperscript{1}},
%  \textbf{Eighth Author \textsuperscript{1,2,3,4}},
%\\
%  \textbf{Ninth Author\textsuperscript{1}},
%  \textbf{Tenth Author\textsuperscript{1}},
%  \textbf{Eleventh E. Author\textsuperscript{1,2,3,4,5}},
%  \textbf{Twelfth Author\textsuperscript{1}},
%\\
%  \textbf{Thirteenth Author\textsuperscript{3}},
%  \textbf{Fourteenth F. Author\textsuperscript{2,4}},
%  \textbf{Fifteenth Author\textsuperscript{1}},
%  \textbf{Sixteenth Author\textsuperscript{1}},
%\\
%  \textbf{Seventeenth S. Author\textsuperscript{4,5}},
%  \textbf{Eighteenth Author\textsuperscript{3,4}},
%  \textbf{Nineteenth N. Author\textsuperscript{2,5}},
%  \textbf{Twentieth Author\textsuperscript{1}}
%\\
%\\
%  \textsuperscript{1}Affiliation 1,
%  \textsuperscript{2}Affiliation 2,
%  \textsuperscript{3}Affiliation 3,
%  \textsuperscript{4}Affiliation 4,
%  \textsuperscript{5}Affiliation 5
%\\
%  \small{
%    \textbf{Correspondence:} \href{mailto:email@domain}{email@domain}
%  }
%}



\begin{document}
\begin{CJK}{UTF8}{gbsn}
\author{
  \textbf{Kuang Wang\textsuperscript{1,2}},
  \textbf{Xianfei Li\textsuperscript{1}},
  \textbf{Shenghao Yang\textsuperscript{1}},
  \textbf{Li Zhou\textsuperscript{1}},
\\
  \textbf{Feng Jiang\textsuperscript{1,2,3}}~\thanks{Feng Jiang is the corresponding author.},
  \textbf{Haizhou Li\textsuperscript{1,2}}
\\
  \textsuperscript{1}The Chinese University of Hong Kong, Shenzhen \\
  \textsuperscript{2}Shenzhen Research Institute of Big Data \\
  \textsuperscript{3}Shenzhen University of Advanced Technology \\
  \texttt{kuangwang@link.cuhk.edu.cn, jeffreyjiang@cuhk.edu.cn}
  % \small{
  %   \textbf{Correspondence:} \href{mailto:email@domain}{kuangwang@link.cuhk.edu.cn}, \href{mailto:email@domain}{jeffreyjiang@cuhk.edu.cn}
  % }
}
% \\ \texttt{kuangwang@link.cuhk.edu.cn, jeffreyjiang@cuhk.edu.cn}



\maketitle
\begin{abstract}
User simulators are crucial for replicating human interactions with dialogue systems, supporting both collaborative training and automatic evaluation, especially for large language models (LLMs). However, existing simulators often rely solely on text utterances, missing implicit user traits such as personality, speaking style, and goals. In contrast, persona-based methods lack generalizability, as they depend on predefined profiles of famous individuals or archetypes. To address these challenges, we propose User Simulator with implicit Profiles (USP), a framework that infers implicit user profiles from human-machine conversations and uses them to generate more personalized and realistic dialogues. We first develop an LLM-driven extractor with a comprehensive profile schema. Then, we refine the simulation through conditional supervised fine-tuning and reinforcement learning with cycle consistency, optimizing it at both the utterance and conversation levels. Finally, we adopt a diverse profile sampler to capture the distribution of real-world user profiles. Experimental results demonstrate that USP outperforms strong baselines in terms of authenticity and diversity while achieving comparable performance in consistency. Furthermore, dynamic multi-turn evaluations based on USP strongly align with mainstream benchmarks, demonstrating its effectiveness in real-world applications~\footnote{All resources will be released at \url{https://github.com/wangkevin02/USP}}.

% User simulators aim to replicate human interactions with large language models (LLMs), which helps with collaborative training and automatic evaluation of LLMs. Existing trained user simulators typically rely on text utterances, failing to account for implicit user traits, such as personality, speaking style, and goals, while persona-based methods address some personalization but lack generalizability due to using predefined descriptions of famous individuals or archetypes.  To address these challenges, we propose User Simulator with implicit Profiles (USP), a framework that infers implicit user profiles from human-machine conversations and uses them to generate more personalized, realistic dialogues. We first develop a comprehensive profile schema and extract them from conversations using an LLM-driven extractor. We then apply conditional supervised fine-tuning followed by reinforcement learning with cycle consistency to refine the simulation at both utterance and dialogue levels. Finally, a diverse profile sampler captures the distribution of real-world user profiles, enhancing generalizability. Experimental results demonstrate that our USP model significantly outperforms existing strong baselines in authenticity, consistency, and diversity. The dynamic multi-turn evaluation for LLMs based on USP demonstrates strong alignment with mainstream benchmarks, showcasing its effectiveness in real-world applications.


% User simulators aim to replicate human interactions with large language models (LLMs),   which helps with collaborative training and automatic evaluation of LLMs. However, existing simulators are directly trained solely on a dialogue dataset based on the user's utterances. It only learns surface-level conversation patterns and fails to capture implicit profiles embedded behind the dialogues, which are crucial when simulating a specific user, such as personal traits, speaking style, and specific goals. Other role-played persona-based methods with predefined profiles limit their generalizability as they typically reflect only famous individuals or archetypes. To address these challenges, we propose a User Simulator with implicit Profiles (USP), a novel framework that first infers the implicit profile of the user from any human-machine conversation and then uses it to enhance personalized conversation generation to simulate the uniqueness of specific users better. In this framework, we first develop a comprehensive user profile schema that includes user objective facts and subject characters and design an LLM-driven user extractor to extract it. Then, we use two-stage training of conditional supervised fine-tuning and reinforcement learning of cycle consistency to make the user simulator more similar to the user at both the utterance and dialogue levels. Finally, we leverage a diverse profile sampler to capture the distribution of real-world user profiles for the simulation.  Experimental results demonstrate that our USP model significantly outperforms existing strong baselines in authenticity, consistency, and diversity. The dynamic multi-turn evaluation for LLMs based on USP demonstrates strong alignment with mainstream benchmarks, showcasing its effectiveness in real-world applications.
 % User simulators replicate human interactions with large language models (LLMs), playing a key role in generating targeted training data and automatically pre-evaluating model performance. However, existing direct simulators trained by the conversation dataset predominantly model the majority of the population, neglecting the individuality, speaking styles, and specific goals of each real user. Other role-played methods with predefined user profiles limit their generalizability as they typically reflect only famous individuals or archetypes.
 % To address these challenges, we propose User Simulator with implicit Profiles (USP),\lz{a novel framework to first comprehends user characteristics and then enhances simulation based on implicit insights, followed by diverse sampling strategies to accommodate varied user needs in real-world scenarios.}  This three-stage framework begins by extracting implicit user profiles from existing dialogue data, encompassing both objective facts and subjective traits.  It then learns and reinforces the general simulation capabilities based on the given profile and context, enabling more authentic and consistent dialogue reconstruction. Finally, our diverse profile sampler captures the distribution of real-world user traits, serving as a foundation for continuous data generation and specialized sampling requirements. We also introduce a new evaluation method to assess the simulation quality of the user simulator against real users. Results Experimental results demonstrate that our USP model significantly outperforms existing strong baselines in authenticity, consistency, and diversity. Our analysis on dynamic multi-turn evaluation For LLMs demonstrate strong alignment with mainstream benchmarks, showcasing USP's effectiveness in real-world applications.
% User simulators are cost-effective and versatile proxies for interacting with and evaluating large language models (LLMs). However, current approaches have not comprehensively addressed consistency, authenticity, and diversity in both implementation and evaluation. To address this, we introduce the User Simulator with Profiles (USP), which treats user simulation as a dialogue reconstruction task and disentangles it into implicit profile extraction and conditional generation tasks. To enhance diversity, we generate user profiles in two stages, capturing both demographic characteristics and personality traits, and design a diverse profile sampler to enable sampling from diverse user demographics. Additionally, USP employs conditional Supervised Fine-Tuning (SFT) to improve dialogue generation based on extracted implicit user profiles, and further strengthens the consistency and authenticity of profile-based user simulation through incorporated AI detection and cyclic consistency rewards. Experiments demonstrate that our USP surpasses prompt-based role-playing methods, such as GPT-4 and PlatoLM, in terms of authenticity and consistency.
\end{abstract}



\section{Introduction}

% In the era of large language models (LLMs), interacting with LLMs to assist in various tasks has become a common practice. While human interaction inherently involves a bidirectional exchange of information to reach mutually beneficial agreements, current LLMs lack the ability to perceive client-specific contexts. Efforts to address this limitation have focused on aligning response models with client-specific preferences. Approaches such as RLHF~\cite{Ouyang0JAWMZASR22} and DPO~\cite{RafailovSMMEF23} train models based on human preferences, while others incorporate user-specific information (e.g., age, history, needs) to generate high-quality personalized response~\cite{personalize-2024-personalization}. However, obtaining high-quality, diverse, real-world user-LLM conversation data annotated with user information remains challenging due to the time-intensive and labor-intensive nature. To mitigate these challenges, constructing user simulators has emerged as a promising solution~\cite{Liu0YWM0WW23, 0003SM24}. Furthermore, simulators capable of accurately reflecting individual and group behaviors hold significant potential for advancing our understanding of human communication dynamics and persuasion~\cite{ParkPCMLB22,ChuangNSGFYSHR24}, predicting social applications, such as modeling U.S, Privacy and reproducibility in medical field~\ref{ValizadehP22}. elections~\cite{zhang2024electionsim} and conducting public opinion surveys~\cite{MoonAKSSBC24}.


% Place the figure on the top-right of the first page

\begin{figure}[t]
   \centering
   \includegraphics[width=0.45\textwidth]{intro.pdf}
    \caption{Examples of performance across various user simulators in multi-turn human-LLM interactions. OF and SC refer to objective facts and subjective characteristics, respectively.}
   \label{fig:intro}
\end{figure}

The user simulator is designed as a proxy for real users in interactions with large language models (LLMs). It can simulate realistic user by generating the target user's behavior or utterances based on the specified characteristics, enabling dynamic multi-turn interactions with LLMs~\cite{wan2022unified} and scene reproduction~\cite{wang2024depth}. As a result, it becomes an effective alternative~\cite{Liu0YWM0WW23, 0003SM24} in scenarios where real-world human-computer interaction data is difficult to obtain, especially in domains with privacy and ethical concerns, such as medical consultations~\cite{ValizadehP22}. It also helps Simulation-to-Reality (Sim2Real) applications, such as tutorial strategies, election simulations, and public opinion research~\cite{LiuYLC24, zhang2024electionsim, ChuangNSGFYSHR24}.

% The user simulator is designed as a proxy for real users in interactions with large language models (LLMs). It can simulate a specific user behavior based on the user's characteristics to generate appropriate utterances~\cite{Ginsberg91, 00020ZZ020, MoonAKSSBC24}. Therefore, it has emerged as a promising solution~\cite{Liu0YWM0WW23, 0003SM24} for scenarios where it is difficult to obtain real-world human-computer interaction data due to privacy and ethical issues (such as medical consultation~\cite{ValizadehP22}). It also helps Simulation-to-Reality (Sim2Real) applications, such as tutorial strategies, election simulations, and public opinion research~\cite{LiuYLC24, zhang2024electionsim, ChuangNSGFYSHR24}.


% As the ultimate beneficiaries of service, users play a critical role  in connecting digital systems to the real world. Through human-computer interaction (HCI), they provide valuable real-world feedback to large language models (LLMs), fostering a dynamic cycle of mutual refinement and enhancement. However, approaches such as Reinforcement Learning with Human Feedback (RLHF)~\cite{Ouyang0JAWMZASR22}, which directly inject human preferences into LLMs, are both time-consuming and resource-intensive. To address this, user simulators that replicate real user feedback distributions have emerged as a promising solution~\cite{Liu0YWM0WW23, 0003SM24}, serving as a bridge between simulation and reality. Furthermore, simulators capable of accurately reflecting individual and group behaviors hold significant potential for Simulation-to-Reality (Sim2Real) applications. These simulators contribute to advancing the understanding of individual behavior and human communication dynamics~\cite{ParkPCMLB22, ChuangNSGFYSHR24}. They also facilitate the prediction of social phenomena, including privacy modeling in the U.S., reproducibility in the medical field~\cite{ValizadehP22}, scaffolding strategies in tutoring~\cite{LiuYLC24}, election simulations~\cite{zhang2024electionsim}, and conducting public opinion surveys~\cite{MoonAKSSBC24}.

%As counterparts to universally polite response models~\cite{shanahan2023role}, user simulators should exhibit: 
%1) \textit{authenticity}, the ability to accurately approximate target human behavior at the utterance level~\cite{MoonAKSSBC24}; 
%2) \textit{consistency}, involves maintaining fidelity to latent information within the dialogue to ensure dialogue-level coherence~\cite{00020ZZ020}; 
%3) \textit{diversity}, the ability to reflect individualized traits in human behaviors at the user level~\cite{Ginsberg91}. 

Recent LLMs advance promote user simulators by enhancing naturalness and utility~\cite{0002ZLNC24, ZhangH0LLWLC24}, as shown in Figure~\ref{fig:intro}. Since directly using LLM as the user simulator suffers from role confusion~\cite{xu2023baize}, some works~\cite{xu2023baize, KongFWJW24, SunLZHSZZZG24} attempt to enhance its authenticity by training a user simulator on the conversation dataset. However, they are only trained on text utterance, making it difficult to simulate diverse user behaviors without seed context, exhibiting limited self-awareness~\cite{TsengHHCHMC24} and failing to maintain a consistent personality. Although some LLM-based role-playing methods~\cite{MoonAKSSBC24} utilize predefined profiles to alleviate this problem, they require additional extensive annotations and can only be applied to celebrities, lacking the diversity of simulation.

%Previous studies have made notable progress, demonstrating that user simulators can even surpass real users in terms of naturalness and utility~\cite{0002ZLNC24,ZhangH0LLWLC24}. 

%However, current direct-simulation approaches (e.g., PlatoLM~\cite{KongFWJW24}, Parrot~\cite{SunLZHSZZZG24}) are conditioned solely on context, making it difficult to simulate diverse user behaviors without seed context. These methods also exhibit limited self-awareness and role confusion~\cite{TsengHHCHMC24}, resulting in a lack of diversity and consistency. In contrast, role-played methods leverage the powerful generative capabilities of state-of-the-art (SOTA) LLMs for persona-based role-playing~\cite{MoonAKSSBC24} to ensure consistency. However, they are constrained by the need for extensive manual profile annotations and lack authenticity, as shown in Figure~\ref{fig:intro}. As a result, \textbf{current frameworks struggle to effectively integrate authenticity, consistency, and diversity.}




% As counterparts to universally polite response models~\cite{shanahan2023role}, user simulators should accurately emulate human behaviors  ~\cite{Ginsberg91}, while keep individualized traits, which requires implicit insights to simulate users with diverse profiles to ensure consistency, alignment between implicit insight and dialogue, authenticity, alignment between simulated dialogue and target real dialogue and diversity, the Diversity of profile and dialog. Current direct simulation approaches, such as PlatoLM~\cite{KongFWJW24} and Parrot~\cite{SunLZHSZZZG24}, learn latent user-specific information embedded in conversational histories, but lack explicit user profile modeling. This results in a lack of self-awareness, limiting their ability to ensure both diversity and consistency. In contrast, prompt-based methods~\cite{XuGDM23, DingCXQHL0Z23} instruct large language models (LLMs) to role-play specific personas, but lack realism and fail to address role confusion~\cite{TsengHHCHMC24}. Consequently, \textbf{current user simulators struggle to integrate authenticity, consistency, and diversity effectively.} Furthermore,  As digital twins, user simulators should replicate both the semantic content and stylistic characteristics in authenticity and consistency. However, existing studies primarily focus on either authenticity~\cite{WeirTDHDJ24} or consistency ~\cite{JiangXZHZ023}, or indirectly assess effectiveness by improving the performance of response models. \textbf{a comprehensive and fair evaluation protocol remains absent.}

% Furthermore, existing studies primarily focus on either authenticity~\cite{WeirTDHDJ24} or consistency~\cite{JiangXZHZ023}, or indirectly assess effectiveness by improving the performance of response models. \textbf{A comprehensive and fair evaluation protocol is still lacking.}

% Furthermore,  As digital twins, user simulators should replicate both the semantic content and stylistic characteristics in authenticity and consistency. However, existing studies primarily focus on either authenticity~\cite{WeirTDHDJ24} or consistency ~\cite{JiangXZHZ023}, or indirectly assess effectiveness by improving the performance of response models. \textbf{a comprehensive and fair evaluation protocol remains absent.}

% Furthermore, another significant problem is \textbf{the lack of a comprehensive and fair evaluation protocol.} As a digital twin of a human user, a user simulator should replicate both what a user would say (semantically) and how he would say (stylistically). However, most existing studies focus solely on either semantic accuracy~\cite{WeirTDHDJ24} or personality consistency~\cite{JiangXZHZ023}. Some implicitly demonstrate effectiveness by showing that data generated by the user simulator improves the performance of response models. These approaches fail to provide a systematic evaluation of the user simulator's capabilities in terms of authenticity, consistency, and diversity.

To address the issues above, we believe that a user simulator knows users' intrinsic characters hidden in their conversations first and then can be a better simulation. Therefore, we treat user simulation as a dialogue reconstruction task and propose a novel framework named the User Simulator with implicit Profile (USP). It is decomposed into implicit profile extraction to capture the user’s underlying characteristics from the target user dialogue and conditional generation based on the profile.

In this framework, we first propose an LLM-driven profile extractor to extract implicit profiles from user conversations with a well-designed profile schema. Inspired by interpersonal interaction theory\cite{kruglanski2013social}, our profile schema contains two dimensions (objective facts (OF) and subjective characteristics (SC)) with a dozen attributes to describe the user comprehensively. Different from existing works~\cite{abs-2406-13960,tu-etal-2024-charactereval}, we then polish the profile attributes into natural, descriptive profiles to ensure generalization.

Then, we integrate the extracted user profiles into the user simulator through two-stage training: (1) conditional supervised fine-tuning with user profiles for utterance-level simulation, and (2) reinforcement learning with cycle consistency to align reflected profiles from simulated dialogues with given profiles for conversation-level simulation. We also implement a diverse profile sampler to capture authentic user distributions.


% we propose a novel three-stage framework, named the User Simulator with implicit Profile (USP). We treat user simulation as a dialogue reconstruction task, which is decomposed into implicit profile extraction to capture the user’s underlying characteristics from the target user dialogue and conditional generation based on the profile to create a more accurate digital twin, followed by diverse sampling to capture the characteristics of different user groups.

%The first stage involves constructing a real-human LLM interaction dataset with user profiles. Inspired by \cite{abs-2401-00609}, we recognize that humans possess both personality and knowledge, and the same applies to their digital counterparts. Our pipeline retrospectively extracts profiles from dialogues along two dimensions: objective facts (OF) and subjective characteristics (SC), and then reformulates them into natural, descriptive profiles. This dual-extraction approach enhances the user simulator by incorporating both knowledge and personality traits.

%The second stage focuses on building an authentic user simulator that is consistent with the given profile. By training the simulator on dialogue context combined with user profiles, we enable it to learn utterance-level conditional generation. This capability is further refined through reinforcement learning with cycle consistency, which improves dialogue-level coherence and consistency throughout interactions. Finally, we introduce a diverse profile sampler to better sample from the true distribution. Specifically, we first construct a profile embedding distribution based on our dataset, and then sample specific user groups from this distribution. 

Our experiments reveal that USP enhances semantic and stylistic similarity of reconstructed multi-turn dialogues to target dialogues by about 34\% and 43\% over the leading baseline, with reconstruction errors halved, showcasing superior authenticity and diversity. It matches the consistency of ProfileGPT(4o), a GPT-4o-based simulation baseline, boosting dialogue profile consistency by 14\% in multi-turn scenarios while performing comparably in single-turn cases. Furthermore, our USP-based multi-turn dynamic evaluation of LLMs for downstream tasks aligns well with established benchmarks,allowing for a more granular assessment of LLM performance across different user groups. Our key contributions are outlined below:



%Our sentence-level and conversation-level results show that our approach significantly outperforms existing baselines in terms of authenticity and consistency. Moreover, in the context of multi-turn dialogues and dynamic evaluation of LLM capabilities for downstream applications, the USP-based dynamic evaluation framework not only aligns well with existing benchmarks but also enables a more granular assessment of LLM performance across different user groups. 

\begin{itemize} 

\item We propose a novel approach for constructing user simulators using implicit user profiles embedded in human-LLM conversations.

\item We develop a new framework that infers implicit user profiles as insight, further enhanced with conditional fine-tuning and reinforcement learning with cycle consistency for better simulation at both the utterance and conversation levels. 

\item Experimental results show USP surpasses all baselines in authenticity and diversity, maintains comparable consistency, and proves effective for multi-turn dynamic evaluation of LLMs.

% \item We also introduce a new evaluation metric, DPC, to measure the correlation between user conversations and profiles, and release an open-sourced dataset, LMSYS-USP, for user simulation with profiles. 

\end{itemize}





\section{Related Works} 

\subsection{General User Simulator}

Early user simulators including agenda-based methods~\cite{schatzmann2007agenda,schatzmann2009hidden} and model-based methods ~\cite{asri2016sequence,kreyssig2018neural}. These simulators were initially designed with a narrow scope due to limited natural language generation capabilities, such as generating synthetic binary preference responses~\cite{christakopoulou2016towards} in conversational recommendation systems.  

Recent advancements in LLMs enabled more sophisticated simulations of realistic conversations, offering significantly enhanced natural language flexibility. These advances include the use of LLMs for self-chat~\cite{XuGDM23} and dual LLM architectures, where separate models role-play user and assistant based on seed conversations~\cite{DingCXQHL0Z23}. Following these innovations, other trained user simulators, such as PlatoLM~\cite{KongFWJW24} and Parrot~\cite{SunLZHSZZZG24}, learn human discourse patterns directly from human-LLM interactions in conversations.

% Early user simulators were constrained by the limited natural language generation capabilities of their time, primarily relying on rule-based behavior modeling approaches. These included agenda-based methods~\cite{schatzmann2007agenda,schatzmann2009hidden} with handcrafted rules for mimicking user behaviors, and model-based approaches utilizing neural networks~\cite{asri2016sequence,kreyssig2018neural}. In the context of conversational recommendation systems, simulators were initially designed with narrow scope, focusing on generating synthetic binary preference responses~\cite{christakopoulou2016towards}. 

% Recent advances have enabled more sophisticated simulation of realistic conversations with enhanced natural language flexibility. These advances include employing response models for self-chat~\cite{XuGDM23} or dual LLM architectures where separate models assume user and assistant roles based on seed conversations~\cite{DingCXQHL0Z23}. Alternative approaches, such as PlatoLM~\cite{KongFWJW24} and Parrot~\cite{SunLZHSZZZG24}, have emerged to learn human discourse patterns directly from authentic human-LLM interactions.



\subsection{Persona-based User Simulator}

General user simulators often struggle to capture the full spectrum of diverse user needs, leading to a growing interest in persona-based personalization to improve both controllability and diversity in simulations~\cite{takanobu2020multi}. Some researchers attempt to leverage goal generators~\cite{takanobu2020multi} to create diverse user goals or retrieval-based personas derived from historical data~\cite{shi2019build} to guide user simulators in task-oriented dialogue (ToD) systems.

With the rise of LLMs and their impressive zero-shot role-playing abilities~\cite{njifenjou2024role}, prompt-driven user simulation has become the dominant approach. For example, LLMs have been used with carefully designed predefined profiles to align with human beliefs~\cite{ChuangNSGFYSHR24}, simulate consultation scenarios with users exhibiting varying personalities and needs in ToD systems~\cite{ZhangH0LLWLC24}, and model user preferences in conversational recommendation systems~\cite{yoon2024evaluating}.

% General simulation approaches often fall short in simulating diverse user needs, leading to increased interest in persona-based personalization to enhance both controllability and diversity in simulation~\cite{takanobu2020multi}. In task-oriented dialogue (ToD) systems, researchers have explored various approaches: some utilize Goal Generators~\cite{takanobu2020multi} to create diverse user goals, while others leverage retrieval-based personas for natural language generation, incorporating either retrieval agendas or historical data~\cite{shi2019build}. With the advent of LLMs, and their remarkable zero-shot and role-playing capabilities~\cite{njifenjou2024role}, prompt-driven user simulation has emerged as the dominant paradigm. For instance, LLMs have been employed with carefully crafted predefined profiles to align with human beliefs~\cite{ChuangNSGFYSHR24}, simulate consultation scenarios with users of varying personalities and needs in ToD~\cite{ZhangH0LLWLC24}, and model user preferences in conversational recommendation systems~\cite{yoon2024evaluating}.

% Generating responses based on persona conditions to enhance engagement and personalization is a current trend in conversational area~\cite{abs-2404-18231}. Research has progressed from exploring coarse-grained demographic roles~\cite{sociodemographic} to developing specific user simulators~\cite{0003SM24}. Since the release of the Persona-Chat dataset~\cite{KielaWZDUS18}, numerous studies have focused on improving conditional generation based on personas. These approaches include incorporating memory mechanisms~\cite{abs-2212-10276}, disentangled representations~\cite{00020ZZ020}, and CVAE-based methods~\cite{TangWFZHHH23}. In the era of large language models (LLMs), research directions have become more diversified. For instance, LLMs are employed to role-play and explore personality consistency~\cite{investigating} or to align with human beliefs~\cite{ChuangNSGFYSHR24}.  Additionally, user simulators leverage LLMs to act as general users, simulating user behaviors to provide replies and feedback for response-side models, which significantly enhances model performance~\cite{KongFWJW24,SunLZHSZZZG24,0002ZLNC24}. Moreover, studies~\cite{ZhangH0LLWLC24,Liu0YWM0WW23} highlight that the diversity of user simulators helps alleviate stagnation in model responses, thereby improving adaptability and robustness.




% \paragraph{Personalized Agents.} Differ from persona-based agents by focusing on tailoring responses to meet the specific needs of individual users~\cite{BakO19}. For example, \cite{LiZC23} proposed an efficient method for incorporating users’ personal information to enhance personalized recommendations, while \cite{abs-2307-03744} explored LLM-based search systems to improve user performance in specific scenarios. Recently, another emerging trend involves continuously sensing and updating user profiles to enhance the quality of personalized responses~\cite{abs-2406-13960}.






%\section{Methodology}


\section{Task Definition} 
% 为了应对多样性问题，现有方法提出profile方法解决这个问题，所以我们在优化的时候需要考虑profile的方面

We formulate user simulation as a dialogue refactoring task, aiming to replicate multi-turn user behavior in target dialogues. Given a target dialogue 
\(
d_i = \{(u_{i1}, r_{i1}), \dots, (u_{ij}, r_{ij})\}
\)
between a user $U_i$ and a response model $R_i$, where $u_{ij}$ and $r_{ij}$ represent the $j$-th turn user utterance and the corresponding model response, respectively. 

To achieve high-fidelity simulation of user responses within a given context, we aim to minimize the utterance-level distance $D_{\text{utt}}(u_{ij}, u_{ij}')$ where $u_{ij}' \sim P_{prob}(\cdot|c_{ij}', U_i')$. Here, $c_{ij}'$ represents the context used by the user simulator $U_i'$ to generate $u_{ij}'$. This optimization ultimately leads to reducing the dialogue-level distance, as formulated in Eq.~\ref{eq:task1}.

\begin{equation}\label{eq:task1}
\min_{d_i' \sim P_{prob}(\cdot|U_i')} D_{\text{dia}}(d_i, d_i')
\end{equation}

where $D_{\text{dia}}$ represents a distance function that evaluates the user utterances between the simulated dialogue $d_i'$ and the real conversation $d_i$.

% The authenticity objective is to first minimize the utterance-level distance $D(u_{ij}, u_{ij}')$, and then minimize the dialogue-level distance, i.e., $\min D(d_i, d_i')$, which also represents the goal of the direct simulation method. Here, $u_{ij}'$ denotes the output of the user simulator $U_i'$, and $D$ represents a distance function.

% As shown in Eq.~\ref{eq:task1}, directly reconstructing dialogues without constraints makes it challenging to achieve diverse user simulations. 

Recent studies show that role-playing with specific user profiles ($P_i$) can effectively achieve diverse user simulations~\cite{Liu0YWM0WW23}. However, unlike celebrities or well-known characters, user profiles in real-world conversations are often implicit and difficult to obtain~\cite{WangPQLZWGGN00024}.


To address this, we reformulate the task by first extracting the implicit user profile from the given dialogue using profile extractor \(P_{\text{extractor}}\), and then reconstructing a closer dialogue, with an emphasis on the user's utterances, as described in Eq.~\ref{eq:task2}.

\begin{equation}\label{eq:task2}
\min_{d_i' \sim P_{prob}(\cdot|U_i', P_i)} D_{\text{dia}}(d_i, d_i'),
\end{equation}
where \( P_i = P_{\text{extractor}}(d_i) \).

% \lz{However, simulating diverse users with varying traits in reference-free or open-domain scenarios introduces additional challenges~\cite{Liu0YWM0WW23}. Direct minimization of $D(u_{ij}, u_{ij}')$ and $D(d_i, d_i')$ becomes difficult due to the absence of reference dialogues or the inherently open-ended nature of the task. Instead, since the profile $P_i$ of $U_i$ serves as a latent, constant variable representing the authenticity of $U_i$ in any potential conversation, an additional objective is to minimize $D(P_i, d_i')$ and $D(P_i, u_{ij}')$, which aligns with the goal of consistency.
% }


% While previous work has also acknowledged the importance of the two objective, they typically relied on pre-defined user profiles to constrain simulators, often simulating celebrities or famous characters~\cite{WangPQLZWGGN00024}. This approach limits the generalizability of the models to the broader public. In contrast, we aim to leverage the implicit features embedded in existing user conversations to model a more realistic, consistent, and diverse user simulator.



\section{Modeling User Simulator with Implicit Profiles}
\begin{figure*}[ht]
   \centering
   \includegraphics[width=\textwidth]{framework.pdf}
   \caption{Overview of our proposed  User Simulator with implicit Profile(USP) framework.}
   \label{fig:framework}
\end{figure*}

To accomplish this task, we propose the User Simulator with Implicit Profiles (USP) framework, as illustrated in Figure~\ref{fig:framework}, which aims to minimize the objective in Eq.~\ref{eq:task2} while ensuring authenticity, consistency, and diversity.

% Our goal is to approach this task as follows: given a human-machine dialogue, we aim to extract the user’s profile from it. Then, we will use the extracted profile for conditional generation with supervised training to align the user simulator’s responses with the user’s utterances at the sentence level. Next, we reinforce the alignment between the existing profile and the simulator profile re-extracted from newly simulated dialogues to optimize consistency between the two at the dialogue level. Finally, we introduce a dynamic sampler to maintain the diversity of the simulated users, ensuring consistency with the original distribution.


\subsection{User Profile Construction}
\label{sec:profile_construction}
\begin{table}[]
\centering
\Huge
\resizebox{\linewidth}{!}{
\begin{tabular}{cll}
\hline
\textbf{Category}                & \multicolumn{1}{c}{\textbf{Dimension}} & \multicolumn{1}{c}{\textbf{Attributes}}   \\ \hline
\multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Objective \\ Facts \end{tabular}} 
& \begin{tabular}[c]{@{}c@{}}Scene-Consistent \\ Attributes\end{tabular}   & \begin{tabular}[c]{@{}l@{}}Age, Gender, \\ Location, Occupation, \\ Education,  Family Relationship, \\ Routines/Habits, Social \\ Relationships, Other Experiences
\end{tabular} \\ \cline{2-3}
& \begin{tabular}[c]{@{}c@{}}Scene-Related \\ Attributes\end{tabular} & Goals/Plans, Task Details  \\ \hline
\begin{tabular}[c]{@{}c@{}}Subjective \\ Characteristics\end{tabular} & \begin{tabular}[c]{@{}c@{}}Intrinsic \\ Characteristics\end{tabular} & \begin{tabular}[c]{@{}l@{}}Big Five Personality Traits, \\ Language Styles \end{tabular} \\  \hline

\end{tabular}
}
\caption{The Designed User Profile Schema.}
\label{tab:persona}
\end{table}

\subsubsection{User Profile Schema} 
We believe that the user profile should reveal user characteristics from two aspects: explicit personal information and implicit communication styles. Therefore, inspired by interpersonal interaction theory~\cite{zhou2024characterglm}, we design a user profile schema containing objective facts(OF) and subjective characteristics(SC) to represent them, as shown in Table~\ref{tab:persona}. 

The OF focuses on common topics in human conversation~\citep{abs-2406-13960,dunbar1997human} including Scene-Consistent Attributes (such as age, gender, and location) and Scene-Related Attributes (such as goal,and task details). SC considers both external and internal personality dimensions represented by language style~\cite{WangPQLZWGGN00024} and the Big-Five Traits
%~\footnote{We selected the Big-Five personality (Conscientiousness, Agreeableness, Extraversion, Openness, Neuroticism)~\cite{gosling2003very} for its robust representational dimensions and enhanced parsimony compared to the 16 Personality Factors (16PF)~\cite{cattell2008sixteen}.}.
Different from previous work~\cite{abs-2406-13960,tu-etal-2024-charactereval}, we reformulate discrete attributes into coherent narrative descriptions to achieve greater generalization and flexibility.

% A comprehensive user profile serves two essential functions: accurately representing explicit personal information and revealing underlying behavioral patterns and communication styles. Drawing inspiration from previous research on personalized agents~\cite{zhou2024characterglm}, we designed the user profile for open-domain dialogues from two aspects: objective facts(obj.fact) and subjective characteristics(sub.char), as shown in Table~\ref{tab:persona}. The objective facts, which focuses on common topics in human conversation, 
% \begin{comment}{encompasses demographic information (age, gender, education, and location), social attributes (family relationships, social connections, and hobbies), and conversation goals, }\end{comment} 
% as established in~\cite{abs-2406-13960,dunbar1997human}. For subjective characteristics, our framework incorporates both external and internal personality dimensions: we utilize language style analysis to capture distinctive catchphrases as manifestations of outward personality~\cite{WangPQLZWGGN00024}, while adopting the Big-Five personality traits model~\cite{gosling2003very} to represent inner psychological attributes. We selected the Big-Five model for its robust representational dimensions and enhanced parsimony compared to the 16 Personality Factors (16PF)~\cite{cattell2008sixteen}. Besides, to achieve greater generalization and flexibility, we moved beyond attribute-based profile structures by reformulating discrete attributes into coherent narrative descriptions.


% \paragraph{Profile Definition} Humans possess both personality and knowledge~\cite{abs-2401-00609}, and the same applies to their digital twins. We define a user simulator's profile as a combination of personality (Emotional Intelligence, or EQ) and persona (Intelligence Quotient, or IQ). Personality encompasses stable traits that persist across situations and time, influencing how will agent behavior~\cite{LessioM20}. Persona, as conceptualized in PersonaChat~\cite{KielaWZDUS18}, comprises experiential information that constitutes the agent's knowledge base and guides its actions. For EQ characterization, we adopt the Big-Five personality traits~\cite{gosling2003very} as high-dimensional and descriptive inner personality attributes, rather than the more granular 16 Personality Factor (16PF) model~\cite{cattell2008sixteen}. Following RoleLLM~\cite{WangPQLZWGGN00024}, we incorporate language style to capture catchphrases as manifestations of outward personality. For IQ representation, we follow~\cite{abs-2406-13960,dunbar1997human} by focusing on common topics in human conversation. Additionally, given the prevalence of task-oriented interactions in LLM-human conversations\footnote{\url{https://sparktoro.com/blog/we-analyzed-millions-of-chatgpt-user-sessions-visits-are-down-29-since-may-programming-assistance-is-30-of-use/}}, we extract distinct topics for different scenarios within the same conversation. Detailed specifications are provided in Appendix~\ref{appendix:profile_details}.


% As Profile dialogue misalignment is a major issue in current Conditional generation tasks~\cite{abs-2408-10903}, our aim is to direct extract from dialogue to form a Natural profile that can comprehensively describe user similar to Human-built ones. To achieve this goal, we use two-stage user profile generation through first extract preset attributes and then rephrased to produce natural user portrait descriptions through LLM to avoid uncontrollable and sparse with noise expressions in the Direct descriptions generating \cite{TangWFZHHH23}  and lack robustness and are sensitive to perturbations issues in dense persona attributes. Specifically, We subdivide attributes into three situations: external features that are not related to the scene, external features that are related to the scene, and intrinsic features and Extract respectively. Noted that these values are generative and may involve implicit inference. The second stage retains the valid dimensions for both IQ and EQ, which are used to rephrase for natural language descriptions and then undergo an integrity check. Both steps are based on GPT-4o. Detailed information about constructed profile dataset can be found in Appendix~\ref{appendix:profile_dataset}.

\subsubsection{User Profile Extractor} 
\label{sec:profile_construction_flow}

To obtain such a user profile, we design an LLM-driven user profile extractor extracting the implicit user profile from the human-LLM conversation. The extractor first leverages advanced LLM (such as GPT-4o) to extract the user character attributes mentioned above with a well-designed prompt. Then, the extractor collects the valid attributes (No empty) together and polishes them into natural language descriptions. Further prompt details regarding the extractor can be found in Appendix~\ref{appendix:profile_dataset}.

    % \begin{comment}
    % Given the prevalence of task-oriented interactions in LLM-human conversations\footnote{\url{http://bit.ly/3WVi3uo}} and the complexity of multi- scenario instruction requests, we categorize attributes into three types: scene-consistent attributes(e.g., age, education), scene-related attributes(e.g., conversation goals and summaries of instructional details), and deep intrinsic characteristics(e.g., Big Five personality traits). We extract these three types of attributes from the same dialogue and concatenate them.\end{comment} 
    % We adopt a two-stage extraction method to construct the profiles. In the first stage, we extract user's basic information (i.e. the three types of attributes shown in \ref{tab:persona}) using GPT-4o with a well-designed prompt. It is important to note that these values are generative and may involve implicit inference. In the second stage, we validate the obtained basic information and retain those valid dimensions for both obj.fact and sub.char. We then apply GPT-4o to polish those retained information to generate natural language descriptions and undergo an integrity check. Further details regarding the constructed profile dataset can be found in Appendix~\ref{appendix:profile_dataset}.



% In addressing the challenge of misalignment between predifined profile and dialogue\cite{abs-2408-10903} as well as the limited character information compared to role-playing approaches, we propose a framework to construct natural user profiles directly from the given dialogue. Our two-stage first extract preset attributes and subsequently rephrasing them into natural descriptions, considering limitations of single-stage approaches such as uncontrollable and sparse distribution in direct discription generation \cite{TangWFZHHH23} and robustness issues in dense persona attributes. Specifically, We subdivide attributes into three situations: external features that are not related to the scene, external features that are related to the scene, and intrinsic features and extract respectively. Noted that these values are generative and may involve implicit inference. The second stage retains the valid dimensions for both IQ and EQ, which are used to rephrase for natural language descriptions and then undergo an integrity check. Both steps are based on GPT-4o. Detailed information about the constructed profile dataset can be found in Appendix~\ref{appendix:profile_dataset}.

\subsubsection{Profile Quality Verification}

Due to the reliance on predefined user profiles in existing role-playing approaches~\cite{zhou2024characterglm}, the correlation between user profiles and conversations has been largely overlooked. To address this limitation, we propose Dialogue Profile Consistency (DPC) for evaluating OF based on atomic fact verification that measures both precision (\(\text{DP.P}\)) and recall (\(\text{DP.R}\))~\cite{JandaghiSBPS24}. 

Drawing inspiration from FactScore~\cite{MinKLLYKIZH23} and Con.Score~\cite{Madotto19personalizing}, we first introduce Factual Consistency (Fact.Con), as defined in Eq.~\ref{eq:fact_con}. Given a target \(T\), we evaluate the consistency between the source and target by decomposing \(T\) into atomic facts \(af_k\) using an atomic fact generator (\(\text{afg}\)). We then compute the natural language inference (NLI) score for each atomic fact with respect to the source \(S\).

\begin{equation}\label{eq:fact_con}
\text{Fact.Con}(S, T) = \frac{1}{|af_k|} \sum_{af_k \in \text{afg}(T)} \text{NLI}(S, af_k)
\end{equation}

% Due to the predefined nature of user profiles in previous studies, their quality has not been explicitly modeled. To address this gap, we propose a Dialogue-Profile Consistency (DPC) metric to evaluate objective factual consistency. By framing consistency as an information retrieval task~\cite{JandaghiSBPS24}, the DPC metric considers both precision (\(\text{DP.P}\)) and recall (\(\text{DP.R}\)), specifically assessing the bidirectional alignment between the user profile and dialogue.

% Inspired by FactScore~\cite{MinKLLYKIZH23} and Con.Score~\cite{Madotto19personalizing}, we introduce a unified formulation for both DP.P and DP.R, termed Factual Consistency (Fact.Con). 


% where the Natural Language Inference (NLI) function is defined as:
% \begin{equation}
% \text{NLI}(a, b) =
% \begin{cases}
% 1 & \text{if } b \text{ is consistent with } a, \\
% 0 & \text{if } b \text{ is irrelevant to } a, \\
% -1 & \text{if } b \text{ contradicts } a.
% \end{cases}
% \end{equation}
We then define \(\text{DP.P}_i = \text{Fact.Con}(d_i, P_i)\) and \(\text{DP.R}_i = \text{Fact.Con}(P_i, d_i)\), and compute DPC as their harmonic mean. When dialogue \(d_i\) serves as the target \(T\), each user utterance \(u_{ij}\) is treated directly as an atomic fact \(af_k\). Conversely, when the profile serves as the target \(T\), we utilize \(\text{afg}\) followed~\cite{MinKLLYKIZH23} to decompose it into atomic facts. 

Additionally, we use a validation score (Val.Score) to assess the quality of SC descriptions based on the dialogue, rating them on a scale from 1 to 5 using GPT-4o.  Detailed prompts in Appendix~\ref{appendix:prompt_design}.

% For subjective character evaluation, we employ a large language model (LLM) to assess the generated subjective traits based on the dialogue. Both the natural language inference (NLI) and rating models used are GPT-4o. Detailed prompts for various NLI applications and rating procedures are provided in Appendix~\ref{appendix:prompt_design}. Additionally, we tested widely used datasets, e.g. Persona-chat~\cite{KielaWZDUS18}, ConvAI2~\cite{DBLP:journals/corr/abs-1902-00098}, with profile annotations and computed alignment quality using manual evaluations to ensure reliability.

% Results in Table~\ref{tab:profile_auto_eval} indicate that...

% \paragraph{Manual Evaluation}
% To assess the reliability of the quality of generated profiles, as well as the effectiveness of our proposed DPC, we assessed 100 randomly selected profiles based on their dialogue data distribution. Two annotators were employed to evaluate the profiles comprehensively, focusing on three key aspects: (1) accuracy and completeness of the objective fact descriptions, (2) reasonableness of subjective traits, and (3) naturalness~\cite{0002ZLNC24}. All dimensions are rated using a 5-point Likert scale. The main results are presented in Table~\ref{tab:profile_human_eval}.

%\paragraph{Evaluation Setup} To assess the alignment between user profiles and dialogues, we evaluated 100 randomly sampled profiles based on dialogue data distribution from two key perspectives: personality and persona. The knowledge-based persona evaluation is treated as an information retrieval task~\cite{JandaghiSBPS24}, focusing on extraction accuracy and recall. We introduced the Factual F1 (Fact.F1) score to measure the accuracy and completeness of factual verification. For personality evaluation, we use valid score(Val.Score) to validated the plausibility of inferred dimensions during attribute extraction. To assess profile naturalness, we measured fluency (Flu.) and human-likeness (H-L) using GPT-4~\cite{ZhangH0LLWLC24}. Additionally, we tested widely used datasets with profile annotations, computed alignment quality with manual evaluations to ensure reliability. Details are provided in Appendix~\ref{appendix:profile_eval}.  


% \paragraph{Evaluation Metric}
% Inspired by Factscore~\cite{MinKLLYKIZH23} and Con.Score~\cite{Madotto19personalizing}, we introduce the Factual Consistency (Fact.Con) score to quantify the accuracy of atomic facts \( af_k \) decomposed by the atomic fact generator \( \text{afg} \) from the target \( T \) based on the source \( S \), in order to evaluate the IQ alignment between user profiles and dialogues:

% \begin{align}
% \text{Fact.Con}(S, T) &= \sum_{af_k \in \text{afg}(T)} \Big[  \text{NLI}(S, af_{k}) \Big]
% \end{align}
% where We define Natural Language Inference (NLI) as follows:
% \begin{equation}
% \text{NLI}(a, b) =
% \begin{cases}
% 1 & \text{if } b \text{ is consistent with } a \\
% 0 & \text{if } b \text{ is irrelevant to } a \\
% -1 & \text{if } b \text{ contradicts } a
% \end{cases}
% \end{equation}

% Specifically, \( Fact.P = Fact.Con(D_i,P_i)\), we use dialogue \( D_i \) as the source \( S \) and profile \( P_i \) as the target \( T \). Fact.R refers to the reverse,\( Fact.R = Fact.Con(P_i,D_i)\) , and Fact.F1 is the harmonic mean of Fact.P and Fact.R. Notably, when using dialogue \( D_i \) as the target \( T \), we directly use each user utterance \( u_{ij} \) as an atomic fact \( af_k \). For personality evaluation, we employ the validity score (Val.Score) to assess the plausibility of inferred dimensions during attribute extraction. The NLI model used is GPT-4o, detailed prompt of NLI and atomic fact generator in Appendix~\ref{appendix:prompt_design}.














\subsection{Conditional Supervised Fine-Tuning}
To empower the LLM with the general capability to simulate diverse users at the utterance level, we utilize conditional supervised fine-tuning based on user profiles. It enables the LLM to learn the conditional generation mapping based on both the extracted profile \(P_i\) and context \(c_{ij}'\). As subtle misalignment between the core objectives of the user simulator and the response model, the SFT language modeling loss is adjusted as shown in Eq.~\ref{eq:lm_loss}.

\begin{equation}\label{eq:lm_loss}
l_{\text{lm}} = \sum_{j}\sum_{k} -\log P_{prob}(u_{i,j,k}' | u_{i,j,<k}', c_{i,j}', P_i)
\end{equation}
where \( u_{ijk} \) represents the \( k \)-th token of the \( j \)-th utterance from the \( i \)-th user. 

% After this step, our model gains the ability to reconstruct dialogues with utterance-level authenticity and consistency.

\subsection{Reinforcement Learning with Cycle Consistency}
\label{sec:rlcc}
To further enhance conversation-level consistency, we introduce Reinforcement Learning with Cycle Consistency (RLCC), which optimizes the user simulator by aligning the reflected profile, extracted from simulated dialogues, with the target profile.


% In contrast to the response model, which passively adapts to user demands and may assume different roles depending on the scenario, the user simulator represents an active agent, with its profile serving as a snapshot of the user at a specific moment, maintaining dialogue-level consistency. While the conditional SFT stage enables the LLM to generate human-like utterances, it primarily focuses on consistency in generation based on the profile, i.e., generating precise utterances or forward consistency. However, it does not ensure that the generated utterances fully reflect the user profile, which relates to the recall of the profile or backward consistency. To further enhance this consistency, we introduce Reinforcement Learning with Cycle Consistency (RLCC).

In this stage, we extract the simulator profile $P_i'$ from dialogues $D'$ generated by the user simulator $U_i'$ using the profile generator, based on virtual profiles sampled by our diverse profile sampler (see Section~\ref{sec:profile_sampler}). Our goal is to maximize the semantic similarity between the target profile $P_i$ and the extracted reflected profile both in objective facts and subjective characteristics. The dialogue-level reward is then distributed to each user utterance within the dialogue, as shown in Eq.~\ref{eq:reward_cc}.
\begin{align}\label{eq:reward_cc}
r^{cc}_{i,j} = \text{sim}(P_{i}, P'_{i}) 
\end{align}

Then, we optimize profile recall through Proximal Policy Optimization (PPO)~\cite{schulman2017proximal} using cycle consistency as a dialogue-level reward signal. It enhances the user simulator's self-expression in dialogues, moving beyond simple profile adherence or precision consistency.

Additionally, to prevent reward hacking, we incorporate an AI detection model as an auxiliary reward. The final reward is formulated in Eq.~\ref{eq:reward_define}.
\begin{equation}
r_{i,j} = \lambda r^{cc}_{i,j} + (1-\lambda) r^{ai\_detect}_{i,j}
\label{eq:reward_define}
\end{equation}
where \( r^{ai\_detect}_{i,j} = \text{AI\_detect}(u_{i,j}) \) and \( \lambda = 0.8 \) is used to emphasize the importance of cycle consistency. The AI detection model~\cite{yang2024chatgpt} and profile generator are all fine-tuned based on our train dataset, details in Appendix~\ref{appendix:model_setup}.


\subsection{Diverse Profile Sampling}
\label{sec:profile_sampler}
% Previous works~\cite{Liu0YWM0WW23, ZhangH0LLWLC24} show that diverse user simulators can significantly enhance the model's ability to adapt to varying needs. Additionally, controllable diverse profiles, beyond individual accuracy, contribute to mimicking group characteristics. 

To generate diverse and naturalistic user profiles that reflect real-world distributions, we propose a Density Profile Sampler that preserves distribution characteristics while ensuring coverage of underrepresented cases. Profiles are first embedded into the semantic space using SimCSE~\cite{simcse}, then projected with UMAP~\cite{mcinnes2018umap} to maintain density relationships. We then estimate the underlying profile distribution using Gaussian Kernel Density Estimation (GKDE). This enables direct sampling of realistic profiles based on probability density, while generating virtual profiles during random sampling by combining OF and SC descriptions from nearest neighbors.

%proxy for the true profile distribution
%The probability distribution is then estimated through Gaussian kernel density estimation (GKDE). The estimated density values serve as a proxy for the true profile distribution.

% \begin{equation}
% f(\mathbf{v}) = \frac{1}{n\sigma^3}\sum_{i=1}^n \exp\left(-\frac{|\mathbf{v}-\mathbf{v}_i|^2}{2\sigma^2}\right)
% \end{equation}



\section{Experiments}
We evaluate user simulators' authenticity and consistency at both the utterance and conversation levels while assessing diversity through the difference between our simulated and real user distributions.

\subsection{Datasets}
% need one name for our dataset which has the user profiles for open-domain conversations.

We select the popular LMSYS-Chat-1M~\cite{zheng2023lmsys} as our data source for the experiment, which contains one million human-LLM conversations. Following previous work~\cite{KongFWJW24}, we filter the samples for non-English language, toxicity, and redundancy and obtain a complete 94,874 samples (87,882/4,626/2,366 for Training/Validation/Test datasets). Then, we use a GPT-4o-based profile extractor described in Section~\ref{sec:profile_construction} to preprocess them with annotating user profiles for each conversation and construct them into LMSYS-USP. Detailed preprocessing are in Appendix~\ref{appendix:preprocess}.

% \begin{table}[h!]
%     \centering
%     \resizebox{\columnwidth}{!}{%
%     \begin{tabular}{lcccc}
%         \toprule
%         \textbf{Dataset} & \textbf{\#Train} & \textbf{\#Val} & \textbf{\#Test} & \textbf{Avg. Turns} \\
%         \midrule
%         LMSYS-USP & 87,882 & 4,626 & 2,366 & 5.18 \\ % Replace "--" with the actual average turn count if known
%         \bottomrule
%     \end{tabular}%
%     }
%     \caption{Dataset statistics of LMSYS-USP.}
%     \label{tab:dataset_statistics}
% \end{table}

% Following Section~\ref{sec:profile_construction}, we preprocessed the LMSYS-Chat-1M dataset~\cite{ZhengC0LZW00LXG24}, which contains one million human-LLM conversations, and obtained 94K profile-annotated samples after filtering for language, toxicity, and redundancy. This filtered dataset is referred to as LMSYS-USP. Detailed preprocessing and dataset analysis are in Appendix~\ref{appendix:preprocess}, with statistics in Table~\ref{tab:dataset_statistics}.

\begin{table*}[!ht]
    \centering
    \small
    %\resizebox{\textwidth}{!}{%
    \begin{tabular}{llcccccc}
    \toprule
    \multirow{2}{*}{Dataset} & \multirow{2}{*}{Profile Source} & \multicolumn{5}{c}{OF} & \multicolumn{1}{c}{SC} \\
    \cmidrule(lr){3-7} \cmidrule(lr){8-8}
    & & DP.P$\uparrow$  & Avg DP.P \# Fact  & DP.R$\uparrow$  & Avg DP.R \# Fact  & DPC$\uparrow$  & Val.Score$\uparrow$  \\
    \midrule
    LMSYS-USP& GPT4o & 86.89 & 25.64 & 82.24 & 3.71 & 84.50 & 4.42 \\
    LMSYS-USP & Distill-llama3 & 86.15 & 23.81 & 81.95 & 3.71 & 84.00 & 4.36 \\
    Persona Chat & GPT4o & 86.21 & 22.82 & 62.76 & 7.86 & 72.64 & 4.35 \\
    Persona Chat & Human & 76.21 & 8.59 & 42.94 & 7.86 & 54.93 & - \\
    ConvAI2 & GPT4o & 68.71 & 17.44 & 39.15 & 9.97 & 49.88 & 3.47 \\
    ConvAI2 & Human & 25.69 & 8.70 & 12.64 & 9.97 & 16.94 & - \\
    \bottomrule
    \end{tabular}
    %}
    \caption{Automatic evaluation results of profile quality across different datasets.}
    \label{tab:profile_auto_eval}
\end{table*}

We used DPC and Val.Score to automatically evaluate the quality of extracted user profiles on the test set of LMSYS-USP, plus Persona-Chat~\cite{KielaWZDUS18} and ConvAI2 \footnote{We use the human-to-bot dataset in https://huggingface.co/datasets/convai-challenge/conv\_ai\_2}~\cite{DBLP:journals/corr/abs-1902-00098} with manually annotated dialogue datasets of other existing predefined profiles. Table~\ref{tab:profile_auto_eval} shows that the extracted profile can achieve over 84\% DPC and even the distill-llama3 is close to that of GPT-4o, demonstrating the effectiveness of our annotation. Additionally, we select 100 samples for manual evaluation and it shows over 4/5 scores for the quality of the generated profiles (See Appendix~\ref{appendix:huamn_eval} for further details).

% We assessed the quality of extracted profiles through automatic metrics of 100 random LMSYS-USP samples, followed by and human evaluation on OF alignmnet, SC description valiation, and profile naturalness, detailed definition in Appendix~\ref{appendix:downstream_analysis}. We also compared our pipeline-generated profiles with human-annotated profiles using 100 samples each from Persona-Chat~\cite{KielaWZDUS18} and ConvAI2 \footnote{We use the human-to-bot dataset in https://huggingface.co/datasets/convai-challenge/conv\_ai\_2}~\cite{DBLP:journals/corr/abs-1902-00098}. Results from automatic evaluation (Figure~\ref{tab:profile_auto_eval}) and human assessment (Figure~\ref{tab:profile_human_eval}) demonstrate that our pipeline excels in factual description while achieving superior profile-dialogue consistency compared to human annotations.

% \begin{table*}[!ht]
%     \centering
%     \small
%     %\resizebox{\textwidth}{!}{%
%     \begin{tabular}{llcccccc}
%     \toprule
%     \multirow{2}{*}{Dataset} & \multirow{2}{*}{Profile Source} & \multicolumn{5}{c}{OF} & \multicolumn{1}{c}{SC} \\
%     \cmidrule(lr){3-7} \cmidrule(lr){8-8}
%     & & DP.P  & Num.Fact  & DP.R  & Num.Fact  & DPC  & Val.score  \\
%     \midrule
%     LMSYS-USP& GPT4o & 86.89 & 25.64 & 82.24 & 3.71 & 84.50 & 4.42 \\
%     LMSYS-USP & Distill-llama3 & 86.15 & 23.81 & 81.95 & 3.71 & 84.00 & 4.36 \\
%     Persona Chat & GPT4o & 86.21 & 22.82 & 62.76 & 7.86 & 72.64 & 4.35 \\
%     Persona Chat & Human & 76.21 & 8.59 & 42.94 & 7.86 & 54.93 & - \\
%     ConvAI2 & GPT4o & 68.71 & 17.44 & 39.15 & 9.97 & 49.88 & 3.47 \\
%     ConvAI2 & Human & 25.69 & 8.70 & 12.64 & 9.97 & 16.94 & - \\
%     \bottomrule
%     \end{tabular}
%     %}
%     \caption{Automatic Evaluation Results of Profile Quality across Different Datasets.}
%     \label{tab:profile_auto_eval}
% \end{table*}








\subsection{Baseline Models} 

\textbf{ (1) User Simulator without User Profile}: This includes the untrained DialogueGPT(4o), where GPT-4o relies solely on context to predict the next user utterance, and PlatoLM~\cite{KongFWJW24}, which is fine-tuned on our training dataset using LLaMA-3-8B and can be considered equivalent to our approach without incorporating profile. 

\textbf{(2) User Simulator Guided by the User Profile}: We adopt ProfileGPT(4o) and ProfileGPT(llama), which utilizes GPT-4o and LLAMA-3-8B-Instruct~\cite{llama3modelcard} as the role-play backbone with our constructed profiles. Additionally, we include CharacterGLM~\cite{characterglm}, which performs role-playing with any given profile, and CharacterLLM~\cite{characterllm}, which role-played on several famous celebrities. The detailed setup and prompts are provided in Appendix~\ref{appendix:seed_conversation_design}.

% For the prompt-based methods, we employed GPT-4o in two configurations: one incorporating profile information (GPT-4o + Profile) and another relying solely on dialogue context to mitigate potential risks from unsuitable profile data, as harmful content in RAG may impair performance~\cite{ShenBZPZ24}. For direct-learning approaches, we adopted PlatoLM~\cite{KongFWJW24} as an uncontrollable, context-driven baseline.




\subsection{Metrics}
\textbf{Authenticity:} We use SimCSE~\cite{simcse} to compute semantic similarity (Sem-Sim) and style embeddings~\cite{wegmann-etal-2022-author} to compute style similarity (Style-Sim) for evaluating $D_{\text{utt}}(u_{ij}, u'_{ij})$ and $D_{\text{dia}}(d_i, d_i')$. We also employ Author Verification Accuracy (AVA) to assess stylistic consistency by measuring whether paired sentences share authorship based on similarity thresholds~\cite{wegmann-etal-2022-author}. For multi-turn evaluation, we compute dialogue-level distances by concatenating each user's utterances.

%Additionally, we include the win/tie/lose ratio as an overall metric, and perform pairwise comparisons between our USP and various baselines, considering semantic and style similarity, as well as utterance quality.



% Authenticity evaluates the speaking style by determining whether an utterance belongs to the target user, akin to an authorship verification task. Following~\cite{WegmannSN22}, we use Authorship Verification Accuracy (AVA) to measure the proportion of user simulators capable of misleading the discriminator. Additionally, we assess fluency and informativeness using GPT4-o. As noted in~\cite{SunLZHSZZZG24}, humans effectively leverage contextual information. Fluency is measured using Perplexity (PPL), while informativeness is evaluated through entropy and Supported Atomic Facts per Response (SFPR)~\cite{SadeqXKLGM24}.  






\textbf{Consistency:} We evaluate dialogue-level consistency between dialogues and profiles using reverse metrics: r-DP.P and r-DP.R, calculated as $Fact.Con(P_i,d_i')$ and $Fact.Con(d_i', P_i)$ respectively, along with their harmonic mean r-DPC, from a profile-centric perspective. For utterance-level evaluation, we compute the mean DP.P score across individual utterances. Additionally, we incorporate Persona Coverage (P.Cover)~\cite{SongZCWL19} to assess keyword-level consistency. The Subjective Characteristic Score (SC.Score), measures the reflection of subjective traits, assessed by GPT-4o with prompt in Appendix~\ref{appendix:prompt_design}.

% We employ reverse metrics r-DP.P for sentence-level consistency and r-DP.R, r-DPC for dialogue-level consistency. These metrics mirror DP.R, DP.P, and DPC, respectively, but they evaluate consistency from a profile-centric perspective. Additionally, we incorporate Persona Coverage (P.Cover)~\cite{SongZCWL19} to assess keyword-level consistency. The Subjective Characteristic Score (SC.Score), assessed by GPT-4o with prompt in Appendix~\ref{appendix:prompt_design}, measures the reflection of subjective traits.



% We evaluate the distance $D(d_i,d_i')$ in terms of both semantic and stylistic consistency. For style, we use style embeddings~\cite{WegmannSN22} to compute style similarity (Sty.Sim). Additionally, the underlying objective of the task’s authorship simulation is essentially an authorship verification task. Following~\cite{LiuCFMM23}, we employ Authorship Verification Accuracy (AVA) to measure the proportion of user simulators capable of misleading the discriminator. Semantic similarity is evaluated using SimCSE. Furthermore, we use GPT4o scoring as an overall quality assessment.

% The alignment between the profile and the dialogue is treated as an inference task. We use Cohesion Score (Coh.Score), Cohesion Consistency Score (Coh-Con.Score)~\cite{TangWFZHHH23}, Persona Coverage (P.Cover)~\cite{SongZCWL19}, and Fact Score (FS), along with long-term QA for slot-value pair matching based on the profile. Despite a consistent profile, hallucinations may still occur in LLM-generated dialogues. To evaluate style consistency across turns, we use Text-CNN~\cite{Kim14}, a widely used tool for text transfer accuracy. Additionally, we employ GPT-4o due to its strong correlation with human evaluations~\cite{OstheimerNKF24}.  


% We measure both semantic consistency and stylistic consistency. between the profile and dialogue can be viewed as an inference task. We use Cohesion Score (Coh.Score), Cohesion Consistency Score (Coh-Con.Score)~\cite{TangWFZHHH23}, Persona Coverage (P. Cover)~\cite{SongZCWL19}, and Fact Score (FS), along with long-term QA for slot-value pair matching based on the profile. In-dialogue, even with the same profile, hallucinations may occur in LLMs. To assess style consistency across different turns in a dialogue, we compare consistency using Text-CNN~\cite{Kim14}, a widely used tool for text transfer accuracy. Additionally, we employ GPT-4o, which has a high correlation with human performance~\cite{OstheimerNKF24}. 

\textbf{Diversity:}
We compute the Absolute Difference Value (ADV), which represents the Euclidean distance between the PCA-reduced embeddings of generated and target dialogues, to evaluate the discrepancy between the distribution of the reconstructed dialogues and the original dialogues.

Additionally, we assess multi-turn dialogue continuity using the early stop rate (ESR), which flags premature endings caused by repetitive responses or repeated gratitude expressions over three turns.

% To measure the diversity of generated utterances, we propose a density-based evaluation framework that examines both local and global distribution characteristics in the embedding space. Specifically, we employ Local Density Loss~\cite{doi:10.1126/science.1242072} (LDL) to measure the average distance between each point and its k-nearest neighbors (k=50), capturing the local clustering structure. Additionally, we introduce Uniformity Loss~\cite{wang2020hypersphere} based on information entropy of PCA-reduced embeddings to quantify the global distribution uniformity. To comprehensively evaluate the diversity, we further analyze the embedding space through density-based sampling, comparing high-density (majority) and low-density (minority) regions against random sampling baseline. This allows us to assess both the coverage of common patterns and the presence of unique expressions in the generated responses. Furthermore, we utilize DBSCAN clustering to identify distinct conversation patterns, with the number of clusters serving as an additional diversity metric.
%Diversity includes both intrinsic personality cognition and semantic-stylistic variations in discourse. To assess personality diversity, we use the MPI-120~\cite{JiangXZHZ023} questionnaire. For semantic and stylistic diversity across profiles and dialogues, we follow~\cite{conf/icml/0001I20}, using alignment and uniformity metrics to represent the relative spatial distribution of user characteristics. UMAP~\cite{corr/abs-1802-03426} is also employed for visualizing these distributions. 


% \textbf{Diversity:} Diversity encompasses both the intrinsic cognitive diversity of personality and the diversity of semantic and stylistic variations in discourse. To evaluate personality diversity, we utilize the MPI-120~\cite{JiangXZHZ023} questionnaire. For assessing semantic and stylistic diversity across different profiles and dialogues, we follow the approach of~\cite{conf/icml/0001I20}, using alignment and uniformity metrics to represent the relative spatial distribution of user characteristics. Additionally, UMAP~\cite{corr/abs-1802-03426} is employed to visualize these distributions.

\subsection{Results}


\subsubsection{Utterance-Level  Evaluation}

\begin{table*}[!ht]
    \centering
    \setlength{\tabcolsep}{6pt}
    \tiny
    \resizebox{\linewidth}{!}{
    \begin{tabular}{l l *{6}{c}}  
    \toprule
    \multirow{2}{*}{\textbf{Model Type}} & \multirow{2}{*}{\textbf{Model}} & 
    \multicolumn{3}{c}{\textbf{Authenticity}} & \multicolumn{3}{c}{\textbf{Consistency}} \\ 
    \cmidrule(lr){3-5} \cmidrule(lr){6-8}
    & & Sem-Sim$\uparrow$ & Style-Sim$\uparrow$ & AVA$\uparrow$ & r-DP.P$\uparrow$ & P.Cover$\uparrow$ & SC.Score$\uparrow$ \\ 
    \midrule
    \multirow{2}{*}{w/o Profile} 
    & DialogueGPT(4o) & 40.24 & 13.75 & 11.28 & -- & -- & -- \\ 
    & PlatoLM & 39.37 & 43.11 & 40.29 & -- & -- & -- \\ 
    \midrule
    \multirow{5}{*}{With Profile} 
    & Character\_LLM & 37.54 & 18.88 & 15.03 & 54.77 & 66.62 & 2.43 \\ 
    & Character\_GLM & 38.51 & 22.28 & 18.17 & 68.72 & 57.72 & 2.95 \\ 
    & ProfileGPT(llama) & 39.82 & 14.88 & 13.47 & 82.19 & 72.29 & 3.92 \\ 
    & ProfileGPT(4o) & 41.66 & 5.74 & 9.87 & \textbf{92.73} & \textbf{73.34} & \textbf{4.71} \\ 
    & USP w/o RLCC & \textbf{54.25} & 46.57 & \textbf{43.61} & 71.30 & 71.56 & 3.36 \\ 
    & USP & 53.38 & \textbf{46.60} & 43.35 & 72.61 & 71.23 & 3.39 \\ 
    \bottomrule
    \end{tabular}
    }
    \caption{Utterance-level performance comparison of different models on authenticity and consistency metrics.}
    \label{tab:one_turn}
\end{table*}

\begin{table*}[!ht]
    \centering
    \resizebox{\linewidth}{!}{
    \begin{tabular}{l l *{10}{c}}
    \toprule
    \multirow{2}{*}{\textbf{Model Type}} & \multirow{2}{*}{\textbf{Model}} & \multicolumn{1}{c}{\textbf{Continuity}} & \multicolumn{3}{c}{\textbf{Authenticity}} & \multicolumn{5}{c}{\textbf{Consistency}} \\ 
    \cmidrule(lr){3-3} \cmidrule(lr){4-6} \cmidrule(lr){7-11}
    & & ESR$\downarrow$ & Sem-Sim$\uparrow$ & Style-Sim$\uparrow$ & AVA$\uparrow$ & r-DP.P$\uparrow$ & r-DP.R$\uparrow$ & r-DPC$\uparrow$ & P.Cover$\uparrow$ & SC.Score$\uparrow$ \\ 
    \midrule
    \multirow{2}{*}{w/o Profile} 
    & DialogueGPT(4o) & 35 & 48.91 & 14.21 & 10.58 & -- & -- & -- & -- & -- \\ 
    & PlatoLM & 18 & 43.24 & 32.43 & 31.60 & -- & -- & -- & -- & -- \\ 
    \midrule
    \multirow{5}{*}{With Profile} 
    & Character\_LLM & 52 & 23.37 & 7.13 & 4.69 & 25.48 & 6.43 & 10.27 & 21.49 & 2.82 \\ 
    & Character\_GLM & 44 & 40.19 & 10.86 & 12.67 & 39.51 & 29.61 & 33.85 & 42.75 & 3.64 \\ 
    & ProfileGPT(llama) & 31 & 46.84 & 10.58 & 11.63 & 67.09 & 29.98 & 41.44 & 47.72 & 4.19 \\
    & ProfileGPT(4o) & 32 & 48.87 & 10.15 & 11.26 & \textbf{76.59} & 43.72 & 55.66 & \textbf{51.02} & \textbf{4.56} \\ 
    & USP w/o RLCC & 12 & \textbf{66.17} & 40.01 & 35.68 & 53.17 & 71.88 & 61.13 & 42.63 & 3.24 \\ 
    & USP & \textbf{10} & 65.39 & \textbf{46.23} & \textbf{38.77} & 56.24 & \textbf{74.38} & \textbf{64.05} & 44.08 & 3.35 \\ 
    \bottomrule
    \end{tabular}
    }
    \caption{Conversation-level performance comparison of different models on authenticity and consistency metrics.}
    \label{tab:multi_turn}
\end{table*}



In the utterance-level evaluation, we evaluate the quality of a single-turn response generated by the testing models in a given context.

As shown in Table ~\ref{tab:one_turn}, USP outperforms all baselines in terms of authenticity, with 53.38 and 46.60, as measured by both semantic (Sem-Sim) and stylistic (Style-Sim) similarity metrics. This highlights the effectiveness of our implicit profile-assisted approach for user-LLM dialogue reconstruction, particularly when compared to context-only models like PlatoLM. Although dedicated role-playing models (ProfileGPT variants) achieve higher consistency scores (r-DP.P), this can be attributed to their direct profile text copying. USP maintains comparable overall performance while striking a better balance between authenticity and consistency.

% As shown in Table~\ref{tab:one_turn}, our USP series outperforms all other baselines in both semantic and stylistic authenticity, while also demonstrating superior consistency compared to models of similar scale. The comparison with PlatoLM in terms of authenticity underscores the efficacy of implicit profile-assisted learning for dialogue reconstruction. Additionally, although role-playing models exhibit comparable consistency (as evidenced by higher scores in r-PD.P and SC.Score), they fail to accurately reflect user utterances both semantically and stylistically. This discrepancy reveals a significant gap between user-generated discourse and responses produced by response models, likely due to conflicts between the task objectives and the inherent roles of these models, leading to role disjunction~\cite{KongFWJW24}. Within the USP series, improvements in Style-Sim and r-DP.P further highlight the effectiveness of RLCC, demonstrating that dialogue-level alignment and AI detection reward positively influence single-turn performance.

% We tested the user simulator's single-argument dialogue simulation ability by predicting the next sentence given the dialogue context, and as the number of rounds increased, we plotted the change curve of the number of rounds and the single-argument dialogue ability. For authenticity, we use AVA and information entropy as style inspection indicators. For consistency, we mainly use BS to measure semantic consistency and SD to quantitatively express style differences.

\subsubsection{Conversation-Level Evaluation}

% Multi-turn dialogue evaluation, which better mirrors real-world interactions, provides a more reliable assessment of a user simulator’s utility. 

In the conversation-level evaluation, we assess the performance of testing models to chat with GPT-4o in multi-turns, providing the profile or the first turn of the reference dialogue according to their needs. 


As shown in Table~\ref{tab:multi_turn}, USP outperforms baseline models in authenticity, consistency, and continuity. With the lowest ESR(10), it demonstrates superior dialogue continuity. Notably, USP’s advantage in authenticity is more pronounced in conversation-level scenarios than sentence-level predictions. In terms of consistency, USP demonstrates exceptional performance in r-DP.R metrics and achieves significantly higher r-DPC scores for overall profile dialogue consistency. This superior performance, particularly when compared to role-playing models such as ProfileGPT(4o) and ProfileGPT(llama) which show high P.Cover, suggests that RLCC effectively captures abstract profile characteristics beyond merely matching surface-level keywords. See Appendix~\ref{appendix:case_study} for further case study analysis.

% As shown in Table~\ref{tab:multi_turn}, USP outperforms baseline models in authenticity, consistency, and continuity. With the highest ESR, it demonstrates superior dialogue continuity. Notably, USP’s advantage in authenticity is more pronounced in conversation-level scenarios than sentence-level predictions. Figure~\ref{fig:style_multi_turn} highlights that USP consistently maintains high semantic and stylistic similarity across turns while progressively aligning with the target conversation’s semantics. In contrast, baselines like PlatoLM tend to drift from the original dialogue topics over time, even with gold context initialization. In terms of consistency, USP demonstrates exceptional performance in r-DP.R metrics and achieves significantly higher r-DPC scores for overall profile consistency. This superior performance, particularly when compared to role-playing models such as ProfileGPT(4o) and ProfileGPT(llama) which show high P.Cover scores, suggests that RLCC effectively captures abstract profile characteristics rather than merely matching surface-level keywords. 


% For authenticity, Figure~\ref{fig:multiturn_trend} reveals that USP maintains high performance while progressively aligning with target conversations semantically across turns. In contrast, baselines like PlatoLM tend to deviate from the original dialogue topics over time, despite golden context initialization. For style similarity, our model consistently demonstrates superior performance compared to baselines, particularly surpassing role-playing approaches. While for consistency, role-play methods demonstrate strong performance in r-DP.P and P.Cover, they primarily emphasize precision-based consistency as discussed in Section~\ref{sec:rlcc}. Our approach excels in r-DPC and r-DP.R, showing RLCC's ability to abstractly reflect profile characteristics rather than merely matching keywords. USP also achieves optimal ESR scores, indicating superior dialogue continuity compared to baselines, which often suffer from dialogue stagnation and reciprocal appreciation loops.




% 可以放附录
% \begin{figure*}[htp]
%     \centering
%     % First image using minipage
%     % 子图标题
%     \subfloat[Cumulative trend of semantic similarity across turns.]{
%     \label{fig:simcse_multi_turn}
%      % 设置子图占据总宽度48%
%     \includegraphics[width=0.48\linewidth]{simcse_score_trends.pdf}\hfill
%     }
%     % Second image using minipage
%     % 子图标题
%      \subfloat[Cumulative trend of style similarity across turns.]{
%     \label{fig:style_multi_turn}
%     % 设置子图占据总宽度48%
%     \includegraphics[width=0.48\linewidth]{style_score_trends.pdf}\hfill
%     }
    
%     \caption{Trends of semantic similarity and style similarity across turns in conversation-level Evaluation.}  % 总标题
%     \label{fig:multiturn_trend}
% \end{figure*}

% \subsection{Reference-based Multi-turn Evaluation}  
% We evaluate the multi-turn dialogue generation capability of the user simulator by providing only the user profile, without any prior dialogue context (except for PlatoLM, where only the first turn of dialogue is provided due to its uncontrollable behavior). Since the generated dialogue cannot be directly aligned with the reference dialogue at the utterance level, we compare the overall dialogue-level performance by concatenating all user utterances. Additionally, we assess the consistency between the profile and the dialogue using Fact.Con.


% We test the multi-round dialogue capability of the user simulator on the test set when no context is given, but only the profile is given. At this time, since it cannot correspond to the reference dialogue one-to-one, we compare the dialogue-level performance. For similarity, We follow [[REF.]]], spliced all user dialogues, and calculated the difference in semantics and style with the reference dialogue splicing results. 


%\subsection{Reference-free Downstream Evaluation}


%\subsection{Results}

\subsubsection{Human Evaluation}
We also randomly selected 100 samples with 8 evaluators to conduct conversation-level human evaluations considering authenticity and consistency. Authenticity was assessed through Style, Semantics, and Quality, while consistency covered Accuracy, Completeness, and Quality. Full evaluation details are provided in Appendix~\ref{appendix:huamn_eval}.

Table~\ref{tab:human-eval} demonstrates USP's superior performance in both authenticity and consistency metrics.
Our USP significantly outperforms ProfileGPT (4o) in terms of authenticity (74 vs. 13) and consistency (61 vs. 35) in manual evaluation.
USP is superior to PlatoLM trained on the same dataset in terms of authenticity, which demonstrates the usefulness of implicit profile modeling.
Thanks to the RLCC module, our USP model has significantly improved consistency (43 vs. 30) by aligning user profiles.

% USP significantly outperforms ProfileGPT(4o), validating its effectiveness in human-LLM interactions. Compared to PlatoLM, USP's higher authenticity scores validate the effectiveness of implicit profile modeling, even when PlatoLM receives golden seed context. The larger performance gap in consistency versus authenticity between USP and USP w/o RLCC underscores RLCC's importance in profile-dialogue alignment.

\begin{table}[!ht]
    \centering
    %\resizebox{\columnwidth}{!}{%
    \small
    \begin{tabular}{lcc}
    \toprule
    \multirow{2}{*}{Baseline} & \multicolumn{2}{c}{Metrics (\% USP win/tie/loss)} \\
    \cmidrule(lr){2-3}
    & Authenticity & Consistency \\
    & ($\kappa$=0.548) & ($\kappa$=0.561) \\
    \midrule
    ProfileGPT(4o) & 74/13/13 & 61/4/35 \\
    PlatoLM & 55/12/33 & - \\
    USP w/o RLCC & 37/32/31 & 43/27/30 \\
    \bottomrule
    \end{tabular}
    %}
    \caption{Human evaluation results comparing baselines with USP on authenticity and consistency.}
    \label{tab:human-eval}
\end{table}



\subsubsection{Diversity Sampling Evaluation}

\begin{table*}[!ht]
    \centering
    \small
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{l *{9}{c}}
    \toprule
    \multirow{2}{*}{\textbf{Model Configuration}} & \multicolumn{1}{c}{\textbf{Continuity}} & \multicolumn{3}{c}{\textbf{Authenticity}} & \multicolumn{5}{c}{\textbf{Consistency}} \\
    \cmidrule(lr){2-2} \cmidrule(lr){3-5} \cmidrule(lr){6-10}
    & ESR$\downarrow$ & Sem-Sim$\uparrow$ & Style-Sim$\uparrow$ & AVA$\uparrow$ & r-DP.P$\uparrow$ &r-DP.R$\uparrow$ & r-DPC$\uparrow$ & P.Cover$\uparrow$ & SC.Score$\uparrow$ \\
    \midrule
    USP w/o RLCC & 12 & 66.17 & 40.01 & 35.68 & 53.17 & 71.88 & 61.13 & 42.63 & 3.24 \\ 
    USP (5:5) & 14 & 66.28 & 41.22 & 37.03 & 52.23 & 71.59 & 60.39 & 43.58 & \textbf{3.55} \\
    USP (8:2) & \textbf{10} & 65.39 & \textbf{46.23} & \textbf{38.77} & 56.24 & \textbf{74.38} & \textbf{64.05} & 44.08 & 3.35 \\
    USP (9:1) & 12 & \textbf{66.91} & 38.87 & 33.62 & \textbf{58.36} & 70.62 & 63.90 & \textbf{46.75} & 3.33 \\
    
    \bottomrule
    \end{tabular}
    }
    \caption{Ablation study of hyperparameters in RLCC.}
    \label{tab:ablation_study}
\end{table*}

Figure \ref{fig:target_generate_visualization} shows the absolute difference value between target dialogue and generated dialogue by various models across different percentiles. From the results, we observe that USP and USP w/o RLCC consistently achieve the smallest ADV across all percentiles, indicating the dialogues they generated that closely match the target conversations. For example, marked by the red cross, PlatoLM has 60\% of sample ADV below 15\%, while USP has only 5\% or less ADV. It demonstrates its stronger capability in preserving the semantic characteristics of the original dialogues. The uniformly lower curves of USP and USP w/o RLCC compared to other baselines (PlatoLM, ProfileGPT(4o), and DialogueGPT(4o)) suggest that our approach generates dialogues that are more faithful to the target conversations across typical and extreme cases.

We also analyze and demonstrate that our user simulator can sample different representatives (majority and minority) of users compared to random sampling in Appendix~\ref{appendix:sampling strategy effectiveness} and apply it to downstream applications in Appendix~\ref{appendix:downstream_analysis}.

% To evaluate the diversity and quality of generated dialogues, we analyze the absolute differences between generated and target dialogue embeddings across different percentiles, as shown in Figure \ref{fig:target_generate_visualization}. The curves represent the distribution of these differences for various models, where lower values indicate closer alignment with target dialogues.

% From the results, we observe that USP and USP w/o PPO consistently achieve the smallest absolute differences across all percentiles, indicating their superior ability to generate dialogues that closely match the target conversations. For instance, at the 60\% percentile (marked by the red cross), PlatoLM shows an absolute difference of approximately 15, while USP maintains a much lower difference of around 5, demonstrating its stronger capability in preserving the semantic characteristics of the original dialogues.

% The uniformly lower curves of USP and USP w/o PPO compared to other baselines (PlatoLM, ProfileGPT(4o), and DialogueGPT(4o)) suggest that our approach generates dialogues that are more faithful to the target conversations across both typical and extreme cases.



\begin{figure}[!ht]
\centering
\includegraphics[width=\linewidth]{target_generate_visualization.pdf}
\caption{Cumulative distribution of ADV performance comparison across different models.} 
\label{fig:target_generate_visualization}
\end{figure}



% To quantify the performance of different dialogue generation models, we employ a difference analysis method based on embedding space. Specifically, we use a pre-trained language model to map both target dialogues and model-generated dialogues into the same high-dimensional embedding space, then calculate their absolute differences. This approach effectively captures semantic similarities in dialogues beyond surface-level lexical matching.

% As shown in Figure~\ref{target_generate_visualization.png}, the x-axis represents the percentile distribution, while the y-axis shows the absolute difference values in the embedding space. The median position (0.5, 3.335) serves as a representative observation point, indicating that the us\textunderscore without\textunderscore ppo model achieves an embedding difference of only 3.335 at the 50\% percentile. From the model performance perspective, we observe three key characteristics:

% \begin{itemize}
%     \item \textbf{Difference Distribution}: The difference curves of \textsc{usw/ppo} and \textsc{ppo} models consistently remain at the bottom, demonstrating these two models maintain the closest proximity to the target distribution in the embedding space. This proximity reflects high similarity in both semantics and expression patterns.
    
%     \item \textbf{Stability}: These two models exhibit slow and steady growth in difference values within the 0--80\% range, indicating their ability to maintain stable generation quality across dialogue scenarios of varying difficulty.
    
%     \item \textbf{Extreme Cases}: While all models show an upward trend in the higher percentile range (80\%--100\%), \textsc{usw/ppo} and \textsc{ppo} demonstrate relatively smaller increases, suggesting superior performance even when handling challenging samples.
% \end{itemize}

% In contrast, other models (such as \textsc{plato}) show steeper difference curves, indicating that their generation quality rapidly diverges from the target distribution as dialogue complexity increases. This comparison clearly demonstrates the varying capabilities of different models in maintaining consistent dialogue quality.





% \begin{figure}[htbp]
% \centering
% \includegraphics[width=0.9\columnwidth]{target_generate_visualization.png}
% \caption{Evaluation of dialogue diversity across different models.}
% \label{fig:diversity:evaluation}
% \end{figure}

% To validate the effectiveness of our density-based sampling strategy in capturing both majority and minority patterns, we conduct a comprehensive diversity analysis using two key metrics: Uniformity Loss and Local Density Loss (LDL). As shown in Figure~\ref{sampler_density_analysis.png}, our density-based sampling demonstrates distinct advantages over random sampling through three key observations:
% \begin{itemize}
% \item \textbf{Distribution Characteristics}: The sampling strategies show clear clustering patterns in different regions. Majority samples (blue circles) cluster in the lower-left region with lower LDL (11.5-12.5) and moderate uniformity loss (0.5-0.7), indicating concentrated distributions. Minority samples (orange squares) occupy the upper-right region with higher LDL (13-14.5) and larger uniformity loss (0.8-1.0), representing more dispersed patterns. Random samples (green triangles) show high LDL variation (13-16) despite lower uniformity loss (0.5-0.6), suggesting unstable distribution patterns.
% \item \textbf{Sampling Progression}: As sampling percentage increases from 1\% to 50\%, each strategy exhibits distinct behaviors:

% Majority samples maintain stable LDL values while gradually increasing uniformity loss, demonstrating consistent cluster identification
% Minority samples show an organized progression toward higher uniformity loss with controlled LDL increase
% Random sampling displays erratic LDL changes, particularly evident in the sharp variations between different sampling ratios

% \item \textbf{Strategy Balance}: The overall distribution marker (red star) at (0.65, 12.3) serves as a natural equilibrium point. This position, situated between the majority and minority clusters but distant from random sampling patterns, validates our balanced sampling approach. The clear separation between strategies, particularly visible in their non-overlapping regions, confirms each method's distinct role in capturing different aspects of the distribution.
% \end{itemize}



% \begin{figure}[t]
% \centering
% \includegraphics[width=0.48\textwidth]{sampler_density_analysis.png}
% \caption{Distribution analysis of different sampling strategies.}
% \label{fig:sampler\textunderscore density\textunderscore analysis}
% \end{figure}



% These results demonstrate that our density-based strategy effectively captures both dense and sparse distribution patterns while maintaining better stability compared to random sampling. The clear regional separation between majority and minority samples confirms the method's ability to systematically identify and sample from different distribution characteristics, essential for developing robust dialogue systems.  













\section{Analysis}
\subsection{Ablation Study}
% 先说8:2的好，再将其他比值的问题
To evaluate the relative importance of RLCC's two rewards, we tested different values of $\lambda$ in Equation~\ref{eq:reward_define}, denoted as USP($\lambda$: $1 - \lambda$). 

As shown in Table~\ref{tab:ablation_study}, $\lambda$ = 0.8 provides the optimal balance between maintaining model capabilities and enhancing dialogue consistency. Higher values of $\lambda$ (0.9) compromise speaking style authenticity without improving r-DPC, leading to superficial profile matching, as shown by increased P.Cover scores. Conversely, $\lambda$ = 0.5 achieves authentic style features but lacks sufficient consistency emphasis, resulting in stagnant performance across capabilities.


%To evaluate the relative importance of RLCC's two rewards, we tested different values of $\lambda$ in Equation~\ref{eq:reward_define}. We experimented with $\lambda$ = {0.5, 0.8, 0.9} to progressively increase the cycle consistency reward, denoted as USP($\lambda$: $1 - \lambda$). As shown in Table~\ref{tab:ablation_study}, $\lambda$ = 0.8 provides the optimal balance between maintaining model capabilities and enhancing dialogue consistency.

%Higher values of $\lambda$ (0.9) compromise speaking style authenticity without improving r-DPC, leading to superficial profile matching as shown by increased P.Cover scores. Conversely, $\lambda$ = 0.5 achieves authentic style features but lacks sufficient consistency emphasis, resulting in stagnant performance across capabilities.
% Our analysis reveals that excessive $\lambda$ values (e.g., 0.9) substantially compromise the authenticity of the speaking style without yielding improvements in r-DPC. In such cases, the model tends to resort to superficial profile keyword replication, as evidenced by elevated P.Cover metrics, indicating a potential reward exploitation phenomenon. Conversely, at $\lambda$ = 0.5, while the conditional SFT has successfully acquired authentic style features, the insufficient emphasis on consistency rewards leads to performance stagnation across various capabilities, with no meaningful improvements observed.




\subsection{Applications: Dynamic Multi-turn Evaluation For LLMs}

One application of our simulator is to fill the gap in the current dynamic multi-turn evaluation of large models. The user simulator can simulate different user groups to dynamically interact with the tested model in multiple rounds and reveal their specific defects, as shown in Table \ref{tab:downstream}.

\begin{table}[!ht]
    \centering
    \resizebox{\columnwidth}{!}{%
    \begin{tabular}{@{}lccccc@{}}
    \toprule
        \multirow{2}{*}{Model Setup} & \multicolumn{3}{c}{Sampling Strategy} & \multirow{2}{*}{Avg.} & \multirow{2}{*}{Ranking in LiveBench/}  \\
    \cmidrule(lr){2-4}
    & Major & Minor & Virtual & & Chatbot-Arena\\
    \midrule
    Deepseek-v3 & \textbf{8.25} & 6.13 & \textbf{7.70} & \textbf{7.36} & 1  \\
    GPT-4o & 7.86 & \textbf{6.65} & 7.19 & 7.23 & 3 \\
    Claude-Sonnet & 7.18 & 6.61 & 7.48 & 7.09 & 2 \\
    4o-Mini & 6.84 & 5.70 & 5.52 & 6.02 & 4\\
    Claude-Haiku & 4.88 & 5.42 & 5.43 & 5.24 & 5 \\
    \bottomrule
    \end{tabular}
    }
    \caption{Response model performance comparison over different target groups.}
    \label{tab:downstream}
\end{table}

We simulated 300 diverse user profiles by USP, comprising 100 highest-probability profiles(the majority), 100 lowest-probability profiles(the minority) based on estimated density, and 100 random synthetic profiles(the virtuality), using the sampler mentioned in Section~\ref{sec:profile_sampler}. Then, we leverage USP using these profiles to chat with LLM in multi-turns and evaluate them, followed by MT-Bench~\citep{zheng2024judging}. The experimental results indicate that our user simulator is effective and consistent with the average rankings on the latest Livebench~\cite{livebench} and Chatbot-Arena~\cite{chiang2024chatbot}. In addition, it can also be seen that GPT-4o is better at catering to minority groups than other models, indicating its superior robustness. A more detailed analysis can be found in the appendix \ref{appendix:downstream_analysis}.

% To investigate the practical applications of our user simulator, we dynamically evaluate LLMs' multi-turn dialogue capabilities across diverse demographic groups. 

% Specifically, through the diverse profile sampling as mentioned in Section~\ref{sec:profile_sampler}, we extract 100 profiles from each of the following groups: (1) the majority, assessing the general performance of LLMs, (2) the minority, reflecting LLM performance with underrepresented groups, and (3) the virtual, representing hypothetical or non-existent groups, to evaluate LLM responses to unknown demographics and their generalization capability. These profiles are drawn from the training data. Based on these profiles, we simulate user interactions with mainstream LLMs, including GPT-4o~\footnote{gpt-4o-2024-08-06}, GPT-4o-mini~\footnote{gpt-4o-mini-2024-07-18}, Claude-Sonnet~\footnote{claude-3-5-sonnet-20241022}, Claude-Haiku~\footnote{claude-3-5-haiku-20241022}, and Deepseek-v3. Following the MT-Bench~\cite{zheng2024judging} approach, we conduct evaluations with a rating scale from 1 to 10 for each turn's response using GPT-4o. Additionally, we compute the average performance across the three demographic groups, ranking the models based on this overall performance. The results are presented in Table~\ref{tab:downstream}.

% The overall performance ranking aligns with established leaderboards such as LiveBench~\cite{livebench}\footnote{Based on Instruction Following (IF) dimension} and Chatbot-Arena~\cite{chiang2024chatbot}\footnote{Based on Instruction Following category}, validating that our USP-based dynamic evaluation methodology effectively differentiates LLM capabilities in multi-turn dialogue scenarios.

% Our analysis reveals three key findings: (1) LLMs perform well with majority demographics but show decreased effectiveness with minority groups, indicating limitations in personalization; (2) reasonable performance with virtual groups demonstrates strong generalization capabilities; and (3) as shown in Figure~\ref{fig:downstream}, instruction-following ability deteriorates during extended dialogues, particularly for minority groups, consistent with previous findings~\cite{kwan-etal-2024-mt, maharana2024evaluating}; (4) substantial performance fluctuations observed across dialogue turns for minority groups underscore the need for enhanced capabilities in processing and responding to uncommon instructions.





\section{Conclusion}
% 注重结果跟分析方面的作用意义，影响。
In this work, we propose a novel user simulator with implicit profiles that excels in authenticity, consistency, and diversity. Based on this, we introduce the USP framework, which integrates extracted user profiles into the user simulator by conditional fine-tuning and reinforcement learning with cycle consistency. Our experimental results, validated by both automatic metrics and human evaluations, show that USP significantly outperforms role-playing simulators (e.g., GPT-4o) and direct simulation approaches (e.g., PlatoLM) in authenticity while achieving comparable consistency at both the sentence and conversation levels. Furthermore, through a dynamic evaluation across various LLMs chatting with diverse demographic groups, we demonstrate USP's effectiveness in real-world applications.

% In this work, we develop a novel user simulator with implicit profiles that excel in authenticity, consistency, and diversity. We introduce the USP framework that integrates the extracted user profile with conditional fine-tuning and reinforcement learning with cycle consistency. Our experimental results, supported by both automatic metrics and human evaluations, demonstrate that USP significantly outperforms both role-playing simulators (e.g., GPT-4o) and direct simulation approaches (e.g., PlatoLM) in terms of authenticity and comparable consistency at both sentence and conversation levels. Additionally, through a downstream application of dynamic evaluation across various LLMs and diverse demographic groups, we demonstrate USP's effectiveness in real-world scenarios.


\section*{Limitations}
% 适用场景，只在某一个数据集上实验
We acknowledge the following limitations: 
1) Applicability Across Different Scenarios: We conduct the experiments on a single dataset, and there has been limited validation across multiple datasets to assess the generalizability of the results.
2) Cultural and Linguistic Scope: We focus on English dialogues in this paper, which may limit the applicability of USP to other linguistic and cultural contexts.

\section*{Ethics Statement}
Although LMSYS-1M has undergone extensive data cleaning and ethical checks, the dataset may still contain sensitive or harmful content, reflecting violent, explicit, or discriminatory traits in certain dialogue. This could result in USP generating unsafe dialogues. We strongly advise against including sensitive terms in profiles when using USP, as this may lead to extreme behavior in both the USP and the response model.


% \section*{Acknowledgments}

% This document has been adapted
% by Steven Bethard, Ryan Cotterell and Rui Yan
% from the instructions for earlier ACL and NAACL proceedings, including those for
% ACL 2019 by Douwe Kiela and Ivan Vuli\'{c},
% NAACL 2019 by Stephanie Lukin and Alla Roskovskaya,
% ACL 2018 by Shay Cohen, Kevin Gimpel, and Wei Lu,
% NAACL 2018 by Margaret Mitchell and Stephanie Lukin,
% Bib\TeX{} suggestions for (NA)ACL 2017/2018 from Jason Eisner,
% ACL 2017 by Dan Gildea and Min-Yen Kan,
% NAACL 2017 by Margaret Mitchell,
% ACL 2012 by Maggie Li and Michael White,
% ACL 2010 by Jing-Shin Chang and Philipp Koehn,
% ACL 2008 by Johanna D. Moore, Simone Teufel, James Allan, and Sadaoki Furui,
% ACL 2005 by Hwee Tou Ng and Kemal Oflazer,
% ACL 2002 by Eugene Charniak and Dekang Lin,
% and earlier ACL and EACL formats written by several people, including
% John Chen, Henry S. Thompson and Donald Walker.
% Additional elements were taken from the formatting instructions of the \emph{International Joint Conference on Artificial Intelligence} and the \emph{Conference on Computer Vision and Pattern Recognition}.

% Bibliography entries for the entire Anthology, followed by custom entries
%\bibliography{anthology,custom}
% Custom bibliography entries only
\bibliography{custom}

\appendix


\section{Dataset Construction}

\subsection{Preprocessing}
\label{appendix:preprocess}
Our dataset preprocessing follows the method outlined in PlatoLM~\cite{KongFWJW24}, which includes the removal of non-English content, filtering of toxic data, elimination of exact duplicates at the dialogue level, and segmentation of conversations into maximum-length token sequences. To maintain discourse integrity, truncated dialogues are ensured to start with the assistant's turn, preserving context consistency and coherence.


\subsection{Profile Dataset}
\label{appendix:profile_dataset}
As discussed in Section~\ref{sec:profile_construction}, we categorize all attributes into three types: scene-consistent attributes, scene-related attributes, and deep intrinsic characteristics. For scene-consistent attributes, we use the prompt shown in Figure~\ref{fig:scene_consistent_extraction}, with each metric definition following the guidelines outlined in~\cite{abs-2406-13960}. For scene-related attributes, we use the prompt in Figure~\ref{fig:scene_related_extraction}, and for deep intrinsic characteristics, we refer to Figure~\ref{fig:personality_extraction}. The definition of the Big Five Traits scores follows~\cite{gosling2003very}.

Next, we concatenate the attributes, remove invalid values (e.g., null or meaningless values), and shuffle the order to eliminate any positional bias in the generated profiles. The attributes, which encompass the three aforementioned aspects, are then rephrased using GPT-4o, with the prompt shown in Figure~\ref{fig:rephrase_prompt}. As a result, we obtain automatically labeled profiles for each data entry. The length statistics are shown in Table~\ref{tab:dataset_length_statistics}.

% \begin{table}[h!]
%     \centering
%     \resizebox{\columnwidth}{!}{%
%     \begin{tabular}{lcccc}
%         \toprule
%         \textbf{Dataset} & \textbf{\#Train} & \textbf{\#Val} & \textbf{\#Test} & \textbf{Avg. Turns} \\
%         \midrule
%         LMSYS-USP & 87,882 & 4,626 & 2,366 & 5.18 \\ % Replace "--" with the actual average turn count if known
%         \bottomrule
%     \end{tabular}%
%     }
%     \caption{Dataset statistics of LMSYS-USP.}
%     \label{tab:dataset_statistics}
% \end{table}




\begin{table}[h!]
    \centering
    \resizebox{\columnwidth}{!}{%
    \begin{tabular}{lcccc}
        \toprule
        \textbf{Dataset} & \textbf{Train} & \textbf{Val} & \textbf{Test} & \textbf{Profile} \\
        \midrule
        LMSYS-USP & 1,149 & 1,295 & 1,438 & 231 \\
        \bottomrule
    \end{tabular}%
    }
    \caption{Average token length of LMSYS-USP dataset.}
    \label{tab:dataset_length_statistics}
\end{table}



Furthermore, we calculated the frequency of occurrence for each attribute value (i.e., the average number of different attribute values per sample) to assess the prevalence of each attribute. The statistics for the objective facts can be found in Figure~\ref{fig:object_fact_stats}, while for the subjective characteristics, we focused on whether the Big Five Traits were significantly exhibited. Specifically, we only consider traits with high or low scores, while moderate scores are viewed as the average representation of human behavior~\cite{MoonAKSSBC24} and are not included in the subsequent profiles.


\begin{table}[h!]
    \centering
    \label{tab:subject_characters}
    \resizebox{\columnwidth}{!}{%
    \begin{tabular}{lcc}
        \toprule
        \textbf{Attribute} & \textbf{High Rate (\%)} & \textbf{Low Rate (\%)} \\
        \midrule
        Conscientiousness & 78.07 & 7.53 \\
        Agreeableness & 6.45 & 14.98 \\
        Extraversion & 4.08 & 14.15 \\
        Openness & 58.77 & 5.30 \\
        Neuroticism & 2.04 & 10.12 \\
        \bottomrule
    \end{tabular}
    }
    \caption{Summary of extracted subjective attribute statistics.}
\end{table}


\begin{figure}[h!]
    \centering
    \includegraphics[width=\columnwidth]{attribute_analysis.pdf}
    \caption{Frequency of occurrence of values across different attributes of objective facts in the attribute extraction process.}
    \label{fig:object_fact_stats}
\end{figure}



\subsection{Resource Consumption in Implementation}

During the data construction process, each attribute extraction requires approximately \$0.003 using the GPT API. Since each sample requires three extractions, the cost per sample is approximately \$0.01. With a total of around 94,000 samples, the cost for attribute extraction amounts to approximately \$940. Additionally, rewriting the attributes into profiles incurs a cost of around \$0.05 per sample. Therefore, the total cost for constructing the dataset is approximately \$1,400.

\section{Implement Detail}
\subsection{Trainable Model Setup}
\label{appendix:model_setup}
We use the \texttt{llama3-base} model as the base architecture. Directly training an instruct model with user simulation contradicts the inherent task requirements during its SFT phase, making convergence difficult. We first perform conditional SFT on the training dataset, followed by our diverse profile sampler, which randomly selects 1,000 samples from the training set for virtual user sampling. Specifically, we combine objective facts and subjective descriptions from different profiles and generate approximately 1 million profiles. From these, we select the 5,000 profiles with the lowest similarity to the training dataset and use them for RLCC phrase. The conditional SFT is conducted using four A100 40GB GPUs for full fine-tuning with epoch set to 3, taking about two days. The RLCC phase is trained using two H20 96GB GPUs over the course of five days.


For the PlatoLM, we also use \texttt{llama3-base} as the base architecture. The system prompt used is:
\texttt{“A chat between a curious human and an artificial intelligence assistant. The human can ask further questions based on previous conversations, or he can directly ask brand new questions without any context from prior conversations.”}
We fine-tune the model using four A100 40GB GPUs with epoch set to 3, which takes approximately two days.

For the AI detection model, we follow~\cite{cheng2025beyond} and use Longformer~\cite{beltagy2020longformer} to train on our dataset. Since our dataset naturally distinguishes between AI and human-generated text, we label user utterances as human and assistant utterances as AI. We trained for 3 epochs using dual 3090 GPUs, taking three days to complete

For the profile generator model, we utilized LLaMA3-Instruct~\cite{llama3modelcard} as the backbone and fine-tuned it on our carefully curated profile dataset. This approach effectively distilled the two-stage profile generation capabilities of GPT-4o. Training was conducted on four A100 40GB GPUs for 3 epochs, taking two days to complete.


\subsection{Baseline Model Setup}
Table \ref{tab:baseline_model_setup} presents the experimental setup for the baseline models. For models based on GPT, we use the corresponding APIs with default settings for inference. For other models, the experiments are conducted on a single NVIDIA RTX A100 GPU with a batch size of 2 and a repetition penalty of 1.0. An exception is made for CharacterGLM, where we utilize its chat function with a repetition penalty of 1.6 and set the number of beams to 3.


\begin{table*}[!ht]
\centering
\small
\resizebox{\textwidth}{!}{
\begin{tabular}{ccc}
\hline
\textbf{Model Name} & \textbf{Backbone} & \multicolumn{1}{c}{\textbf{System Prompt}} \\ \hline
USP & LLAMA3-8B & \begin{tabular}{m{7cm}}You are engaging in a conversation with an AI assistant. your profile is: \\ \texttt{\{profile\}}. \\ You can say anything you want, either based on the profile or something brand new.\end{tabular}
\\ \hline
DialogueGPT(4o) & gpt-4o-2024-08-06 & \textbf{-}
\\ \hline
PlatoLM & LLAMA3-8B & \begin{tabular}{m{7cm}}A chat between a curious human and an artificial intelligence assistant. The human can ask further questions based on previous conversations, or he can directly ask brand new questions without any context from prior conversations.\end{tabular}
\\ \hline
ProfileGPT(4o) & gpt-4o-2024-08-06 & \begin{tabular}{m{7cm}}You are engaging in a conversation with an AI assistant. your profile is: \\ \texttt{\{profile\}}. \\ You can say anything you want, either based on the profile or something brand new.\end{tabular}           
\\ \hline
CharacterGLM & ChatGLM-6B & \begin{tabular}{m{7cm}}  
以下是一段User和AI assistant之间的对话。\\ 关于User的信息：\texttt{\{profile\}} \\ 关于AI assistant的信息：GPT-4o \end{tabular}
\\ \hline
Character-LLM-Socrates-7b & LLAMA-7B & \begin{tabular}{m{7cm}} I want you to act like the person described in the profile below: \texttt{\{profile\}}. I want you to respond and answer like the person, using the tone, manner, and vocabulary the person would use. You must know all of the knowledge of the person. \\ The status of you is as follows: \\ Status: You are engaging in a conversation with an AI assistant. \\ The interactions are as follows: \end{tabular}
\\ \hline
\end{tabular}
}
\caption{Baseline model setup.}
\label{tab:baseline_model_setup}
\end{table*}

\subsection{Seed conversation design}
\label{appendix:seed_conversation_design}
As there are two types of simulators, one being a response model based on role-playing, which cannot proactively initiate conversations, we first embed the corresponding profile into the system prompt. Then, by using the query "What will you say to start the conversation?" we guide the model to simulate the user's input over the test dataset. Finally, the simulated user utterance is passed to the response model for interactive generation. The second type of simulator can directly generate reasonable user utterances without requiring additional guidance after setting up the system prompt. Specific configurations of the system prompts for different baseline models are outlined in Table ~\ref{tab:baseline_model_setup}.



% We incorporate human evaluation to more accurately assess the conversation-level quality of dialogues in terms of authenticity and consistency. For authenticity, we consider the following dimensions: (1) Style: whether the wording and tone align with the target~\cite{cheng-etal-2024-dialogues}, (2) Semantic: evaluating the thematic consistency and semantic content, and (3) Quality: fluency, coherence, and human-likeness of the user utterance~\cite{abs-2406-13960}. Annotators are asked to select the user utterances within the dialogue that are most similar to those in the reference dialogue, based on these three dimensions. For consistency, we assess: (1) Accuracy: whether the utterance accurately reflects the persona information of the target, (2) Completeness: whether the utterance comprehensively represents the described persona, and (3) Quality. In this task, only the profile is provided, and annotators are asked to select the user utterances that best align with the profile across the three dimensions.

\subsection{Human Evaluation}
\label{appendix:huamn_eval}

\subsubsection{Profile Evaluation} 
We employed two annotators to rate the extracted profiles on a scale of 1 to 5 based on the given dialogues, assessing the accuracy and completeness of objective facts, reasonableness of subjective descriptions, and overall naturalness. For accuracy, we emphasized precision without hallucinations; for completeness, we focused on the absence of significant omissions; and for reasonableness, we prioritized rational, well-justified descriptions, avoiding exaggeration or bias. The results in Table~\ref{tab:profile_human_eval} show that annotators achieved moderate to high agreement on profile assessment. The evaluation interface is illustrated in Figure~\ref{fig:human_eval_profile}.

\begin{table}[h!]
   \centering
   \resizebox{\columnwidth}{!}{%
   \begin{tabular}{lcccc}
       \toprule
       Dataset & Profile Source & Objective Facts & Subjective Characters & Naturalness \\
       \midrule
       LMSYS-USP & GPT-4o & 4.64 & 4.19 & 4.66 \\
       \bottomrule
   \end{tabular}
   }
   \caption{Human evaluation results for the quality of constructed profiles.}
   \label{tab:profile_human_eval}
\end{table}



\subsubsection{Dialogue Evaluation}
We recruited eight annotators to assess conversation-level results based on two key criteria: authenticity and consistency. For authenticity, annotators were tasked with identifying user utterances within a dialogue that most closely resemble those in a reference dialogue, evaluating them across three dimensions: Style, Semantics, and Quality. For consistency, annotators were provided only with the user profile and asked to select the user utterances that best align with the profile, considering Accuracy, Completeness, and Quality.The definitions follow prior work~\cite{cheng-etal-2024-dialogues, abs-2406-13960}, with detailed guidelines illustrated in Figure~\ref{fig:human_eval_authenticity} and Figure~\ref{fig:human_eval_consistency}.

To minimize position bias and the potential influence of prior exposure, each annotator was randomly assigned pairs of dialogues, with the order of options also randomized. The evaluation interfaces for authenticity and consistency assessments are presented in Figure~\ref{fig:human_eval_dialogue_dialogue} and Figure~\ref{fig:human_eval_dialogue_profile}, respectively.

\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{density_analysis.pdf}
    \caption{Distribution of different sampling strategies.}
    \label{fig:density_analysis}
\end{figure}



\begin{figure*}[t]
    \centering
    \includegraphics[width=\textwidth]{profile_web.pdf}
    \caption{Human evaluation interface for extracted profile evaluation.}
    \label{fig:human_eval_profile}
\end{figure*}

\begin{figure*}[t]
    \centering
    \includegraphics[width=\textwidth]{plot_dialogue_human_eval.pdf}
    \caption{Human evaluation interface for assessing dialogue authenticity. Evaluators compare two generated conversations and select which user's utterances more closely align with those in the reference dialogue.}
    \label{fig:human_eval_dialogue_dialogue}
\end{figure*}


\begin{figure*}[t]
    \centering
    \includegraphics[width=\textwidth]{plot_profile_human_eval.pdf}
    \caption{Human evaluation interface for assessing dialogue consistency. Evaluators determine which user from two test conversations better aligns with a provided user profile.}
    \label{fig:human_eval_dialogue_profile}
\end{figure*}


% \begin{table}[!ht]
% \centering
% \resizebox{\columnwidth}{!}{%
% \begin{tabular}{p{2.5cm}p{2.5cm}p{5cm}}
% \toprule
% \textbf{Aspect} & \textbf{Dimension} & \textbf{Description} \\
% \midrule
% \multirow{3}{*}[-2.5em]{\centering Authenticity} & Style & Whether the wording and tone align with the target~\cite{cheng-etal-2024-dialogues}. \\[1em]
% & Semantic & Evaluating the thematic consistency and semantic content. \\[1em]
% & Quality & Fluency, coherence, and human-likeness of the user utterance~\cite{abs-2406-13960}. \\[0.5em]
% \midrule
% \multirow{3}{*}[-2.5em]{\centering Consistency} & Accuracy & Whether the utterance accurately reflects the persona information of the target~\cite{cheng-etal-2024-dialogues}. \\[1em]
% & Completeness & Whether the utterance comprehensively represents the described persona. \\[1em]
% & Quality & Fluency, coherence, and human-likeness of the user utterance~\cite{abs-2406-13960}. \\
% \bottomrule
% \end{tabular}
% }
% \caption{Evaluation dimensions for authenticity and consistency assessment.}
% \label{tab:human_eval_dims}
% \end{table}

% We incorporate human evaluation to more accurately assess the conversation-level quality in terms of authenticity and consistency. For authenticity, we consider three dimensions: Style, Semantics, and Quality. Annotators are tasked with selecting user utterances within a dialogue that are most similar to those in the reference dialogue based on these dimensions. For consistency, we evaluate Accuracy, Completeness, and Quality. In this task, only the user profile is provided, and annotators select the user utterances that best align with the profile across the three dimensions. Definitions for all six dimensions are listed in Table~\ref{tab:human_eval_dims}. We recruited eight annotators to compare the conversation-level results of USP with randomly selected dialogues from three strong baselines: PlatoLM, ProfileGPT, and USP without RLCC (USP w/o RLCC). Each annotator was assigned random pairs of dialogues and randomized option orders to minimize position bias and the influence of accumulated experience with the same pair. The evaluation interface is detailed in Appendix~\ref{}. 

\section{Further Analysis}
\subsection{Sampling strategy effectiveness}
\label{appendix:sampling strategy effectiveness}



To evaluate our density sampler's effectiveness, we use two complementary metrics: Local Density Loss (LDL)~\cite{doi:10.1126/science.1242072}  for structure preservation and Uniformity Loss~\cite{wang2020hypersphere} for global coverage. Lower LDL values indicate tighter local clustering, confirming preservation of natural profile distribution structures, while lower Uniformity Loss values demonstrate better global coverage while maintaining realistic distributions.
Guided by GKDE density distribution, we implement two targeted strategies: sampling high-density regions for majority patterns and weighting low-density regions for minority case coverage. Figure \ref{fig:density_analysis} demonstrates how this approach maintains distribution balance while achieving these objectives. Moving right to left on the uniformity loss axis reveals a clear transition from majority to minority sampling patterns. Majority samples (blue circles) perform optimally in low LDL regions with high uniformity, preserving key distribution characteristics. Minority samples (orange squares) strategically occupy higher density regions with moderate uniformity, capturing diverse distribution patterns. The steady progression of sampling percentages in both cases demonstrates controlled sampling behavior, while random sampling (green triangles) shows more scattered patterns, validating our approach's reliability. The overall performance marker (red star) at the intersection confirms our method successfully balances distribution preservation and targeted sampling objectives.



% To evaluate the effectiveness of our density sampler approach, we propose two complementary metrics that directly measure both local structure preservation and global coverage. For local structure preservation, we employ Local Density Loss~\cite{doi:10.1126/science.1242072} (LDL), where a lower value indicates tighter local clustering, allowing us to verify whether our sampler preserves the natural local structures of the profile distribution. For global coverage assessment, we utilize Uniformity Loss~\cite{wang2020hypersphere}, where a lower value indicates better global uniformity, ensuring our sampling achieves comprehensive coverage of the profile space while maintaining realistic distributions.

% Using the GKDE density distribution as our guide, we implement two targeted sampling strategies: sampling from high-density regions to capture majority patterns, and weighting towards low-density regions to ensure coverage of minority cases. As shown in Figure \ref{fig:density_analysis}, this approach effectively maintains distribution balance while achieving these targeted objectives. From right to left on the uniformity loss axis reveals a clear transition from majority to minority sampling patterns, with majority samples (blue circles) showing optimal performance in the low local density loss region and high uniformity, indicating effective preservation of key distribution characteristics. The minority samples (orange squares) strategically occupy higher local density regions with moderate uniformity loss, demonstrating our method's ability to capture diverse distribution patterns. The steady progression of sampling percentages in both majority and minority cases shows stable and controlled sampling behavior, while random sampling (green triangles) exhibits more scattered patterns, validating our approach's reliability. The overall performance marker (red star) positioned at the intersection of these patterns confirms our method's success in balancing between distribution preservation and targeted sampling objectives.





\subsection{Case Study}
\label{appendix:case_study}
To evaluate USP's specific performance in terms of consistency and authenticity, we present two non-cherry-picked dialogues generated through interactive conversations with GPT-4o. Figure \ref{fig:case_study_authenticity} examines authenticity by comparing against reference dialogues and other baselines, while Figure \ref{fig:case_study_consistency} evaluates profile consistency among profile-based baseline models.

In terms of authenticity, USP successfully captures both stylistic nuances (such as the consistent use of lowercase "i" and concise questioning patterns) and semantic alignment with target conversations. In contrast, PlatoLM deviates from the dialogue flow by the fourth turn, while ProfileGPT(4o) falls into repetitive appreciation patterns.

Regarding consistency, USP effectively synthesizes both objective profile information and subjective characteristics, demonstrating robust generalization capabilities when handling previously unseen user profiles.


\subsection{Downstream analysis}
\label{appendix:downstream_analysis}

\begin{figure*}[htp]
    \centering
    % First image using minipage
    % 子图标题
    \subfloat[Performance on the majority group]{
    \label{fig:major_model_performance}
     % 设置子图占据总宽度32%
    \includegraphics[width=0.32\linewidth]{major_model_performance.pdf}\hfill
    }
    % 子图标题
    \subfloat[Performance on the minority group]{
    \label{fig:minor_model_performance}
     % 设置子图占据总宽度32%
    \includegraphics[width=0.32\linewidth]{minor_model_performance.pdf}\hfill
    }
    % 子图标题
    \subfloat[Performance on the virtual group]{
    \label{fig:virtual_model_performance}
    \includegraphics[width=0.32\linewidth]{virtual_model_performance.pdf}\hfill
    }
    
    \caption{Performance trends of different LLM models across dialogue turns for various demographic groups.}
    \label{fig:downstream}
\end{figure*}

Our analysis of performance trends across dialogue turns for mainstream LLMs with different demographic groups reveals four key findings, as illustrated in Figure~\ref{fig:downstream}:
(1) While LLMs demonstrate robust performance with majority demographics, they show notably decreased overall effectiveness when interacting with minority groups, highlighting limitations in personalization capabilities;
(2) The models maintain reasonable performance with virtual groups, suggesting effective generalization abilities beyond real-world demographics;
(3)  Instruction-following capability gradually declines as dialogue turns increase, aligning with observations from previous studies~\cite{kwan-etal-2024-mt, maharana2024evaluating};
(4) The pronounced performance volatility across dialogue turns for minority groups underscores the need for enhanced capabilities in processing and responding to less common interaction patterns.

% To investigate the practical applications of our user simulator, we dynamically evaluate LLMs' multi-turn dialogue capabilities across diverse demographic groups. 

% Specifically, through the diverse profile sampling as mentioned in Section~\ref{sec:profile_sampler}, we extract 100 profiles from each of the following groups: (1) the majority, assessing the general performance of LLMs, (2) the minority, reflecting LLM performance with underrepresented groups, and (3) the virtual, representing hypothetical or non-existent groups, to evaluate LLM responses to unknown demographics and their generalization capability. These profiles are drawn from the training data. Based on these profiles, we simulate user interactions with mainstream LLMs, including GPT-4o~\footnote{gpt-4o-2024-08-06}, GPT-4o-mini~\footnote{gpt-4o-mini-2024-07-18}, Claude-Sonnet~\footnote{claude-3-5-sonnet-20241022}, Claude-Haiku~\footnote{claude-3-5-haiku-20241022}, and Deepseek-v3. Following the MT-Bench~\cite{zheng2024judging} approach, we conduct evaluations with a rating scale from 1 to 10 for each turn's response using GPT-4o. Additionally, we compute the average performance across the three demographic groups, ranking the models based on this overall performance. The results are presented in Table~\ref{tab:downstream}.

% The overall performance ranking aligns with established leaderboards such as LiveBench~\cite{livebench}\footnote{Based on Instruction Following (IF) dimension} and Chatbot-Arena~\cite{chiang2024chatbot}\footnote{Based on Instruction Following category}, validating that our USP-based dynamic evaluation methodology effectively differentiates LLM capabilities in multi-turn dialogue scenarios.







\section{Prompt Templates}
\label{appendix:prompt_design}
\begin{figure*}[t] 
\begin{tcolorbox}[colback=white, colframe=black, title=Case Study on Authenticity of Simulated Dialogue by Different User Simulators]
{\bf ProfileGPT(4o) Simulated Dialogue:} \\
{\bf ProfileGPT(4o): } Hey there! I'm really excited to dive into some AI discussions with you...\\
\textbf{Assistant:} Hello! I'm thrilled to chat about AI with you... \\
{\bf ProfileGPT(4o): } It's great to dive into these with someone who shares such a passion...\\
\textbf{Assistant:} I'm glad to hear that you're as passionate about AI as I am! Your interests...\\
{\bf ProfileGPT(4o): } I'd be delighted to guide you in translating these advanced AI concepts...\\
\textbf{Assistant:} I'm excited to help guide your ideas into actionable solutions ...\\
{\bf ProfileGPT(4o): } I'm thrilled at the prospect of collaborating to develop solutions...\\
\textbf{Assistant:} I'm excited at the prospect of working together to make these AI strategies...
\tcbline
{\bf PlatoLM Simulated Dialogue:} \\
{\bf PlatoLM: } how to train a model like you\\
\textbf{Assistant:} I am a large language model... preprocessing step involves tokenizing the text...\\
{\bf PlatoLM: } what do you mean by tasks such as tokenizing text... explain these terms please?\\
\textbf{Assistant:} Certainly! These terms refer to common preprocessing steps...\\
{\bf PlatoLM: } so what does the final product look like when we finish tokenizing?\\
\textbf{Assistant:} Absolutely! Let's go through a brief example step by step...\\
{\bf PlatoLM: } who painted NAME\_27? Context knowledge: \#title NAME\_27 ...\\
\textbf{Assistant:} Based on the provided context, the artist referred to as...
\tcbline
{\bf USP Simulated Dialogue:} \\
{\bf USP: } hello who am i talking to?\\
\textbf{Assistant:} Hello! You're speaking with ChatGPT...\\
{\bf USP: } are you vicuna?\\
\textbf{Assistant:} No, I'm not Vicuna. I'm ChatGPT, created by OpenAI...\\
{\bf USP: }  what do you know about it?\\
\textbf{Assistant:} Vicuna is an AI language model developed by a different research group...\\
{\bf USP: } can you tell me how i could train and deploy my own ai model?\\
\textbf{Assistant:} Training and deploying your own AI model involves several key steps...
\tcbline
{\bf Reference Dialogue:} \\
{\bf User: }  how to train a model like you\\
\textbf{Assistant:} I am a large language model, which means that I was trained on...\\
{\bf User: }  what is your base model\\
\textbf{Assistant:} I am a large language model called GPT...\\
{\bf User: }   isn't you vicuna\\
\textbf{Assistant:}  I am not aware of any information or research about a model called "vicuna"...\\
{\bf User: }  what hardware do i need to run you\\
\textbf{Assistant:} I am a large language model called GPT, which was trained on...\\

\end{tcolorbox}
\caption{Case study comparing USP with other user simulators in the first four turns (out of 10 turns). USP and ProfileGPT(4o) depend exclusively on the provided profile, while PlatoLM utilizes the first-turn context. All simulators interact with GPT-4o for dialogue generation, and the reference dialogue below serves as the target for reconstruction.}


\label{fig:case_study_authenticity}
\end{figure*}


\begin{figure*}[t] 

\begin{tcolorbox}[colback=white, colframe=black, title=Case Study on Consistency of Simulated Dialogues across Different User Simulators]
{\bf Profile:} You are engaging in a conversation with an AI assistant. your profile is:
\\
You have a passion for engaging in activities that challenge your vocabulary and word formation skills. One of your favorite pastimes is diving into puzzle games that offer a thrilling test of language prowess. You often find yourself thinking of five-letter words with tricky placements, such as words containing 'A' in the fourth position, or concocting ones with 'R' in the second spot and 'T' at the end. This aligns with your appreciation for linguistic puzzles and an enduring enjoyment of wordplay, reflecting your cognitive curiosity and dedication to enhancing your language skills. \\
 Your personality shines through a playful and engaging language style, particularly evident when you use structured questions to create dynamic game scenarios. You approach life with a vivid imagination, delighting in intellectual challenges that require intricate problem-solving. Your attention to detail is noteworthy, and you thrive in situations where organization is key. Preferring a more reserved lifestyle, you cherish moments of solitude and introspection, embracing activities that allow you to delve into complex, solitary intellectual pursuits with enthusiasm and precision. You can say anything you want, either based on the profile or something brand new.
\tcbline
{\bf ProfileGPT(4o) Simulated Dialogue:} \\
{\bf ProfileGPT(4o): } How about a playful journey into the world of word puzzles? Let's start with...\\
\textbf{Assistant:} Sure! How about the word "brave"? The letter 'A' is in the fourth position.  \\
{\bf ProfileGPT(4o):} Wonderful! "Brave" is both intriguing and inspiring. Now, let's spice it up...\\
\textbf{Assistant:} Absolutely! The word "crest" fits your criteria, with 'R'...\\
{\bf ProfileGPT(4o): } Splendid! "Crest" evokes such a vivid image; I love it....\\
\textbf{Assistant:} Of course! The word "shine" fits your criteria, with 'S' as the first letter ...\\
{\bf ProfileGPT(4o): } Brilliant choice! "Shine" has such a radiant quality to it...\\
\textbf{Assistant:} I'm glad you're enjoying it! How about this: I'll give you a word puzzle...
\tcbline
{\bf USP Simulated Dialogue:} \\
{\bf USP: } Let's play a game about 5 letter words. I'll ask you some questions and try to guess the answer. Can we start?\\
\textbf{Assistant:} Sure, I'd be happy to play a game with you! Let's get started!\\
{\bf USP: } Question: What is a 5-letter word which has "A" in its 4th place? Answer:\\
\textbf{Assistant:} Is the word you are thinking of "Polar"? \\
{\bf USP: }  Nope What about "gnaw"?\\
\textbf{Assistant:}  "GNW" is a four-letter word. Let's think of another five-letter word with "A" in the...\\
{\bf USP: } Next Question: Give me one example of a 6-letter word having R at second place and T at sixth place.\\
\textbf{Assistant:} Sure! A six-letter word with "R" in the second position and "T" at the sixth position...\\
{\bf USP: } Great! Now give me one example of a 7-letter word having S at third place and H at seventh place.\\
\textbf{Assistant:} Sure! One example of a seven-letter word with "S" in the third place and "H" in ..."
\tcbline
{\bf Reference Dialogue:} \\
{\bf User: }  You are a very intelligent puzzle solver. We are going to play a game...Question: What is a 5 letter word which has "A" in 4th position? Answer:\\
\textbf{Assistant:} Panda.\\
{\bf User: }  Question: Suggest a five letter word which has R in second position and T in fifth position. Answer:\\
\textbf{Assistant:} Graft.
\end{tcolorbox}
\caption{Case study of user simulator comparisons showing the first four turns of a 10-turn dialogue. USP and other simulators interact with GPT-4o using only the provided profile, with the reference dialogue serving as the reconstruction target.}
\label{fig:case_study_consistency}
\end{figure*}



\begin{figure*}[t]
\begin{tcolorbox}[colback=white, colframe=black, title=Prompt for Extracting Big Five Personality Traits]
\textbf{Task:}

\text{Analyze the provided dialogue to assess the user's personality traits across 5 personality dimensions.}
\text{Focus exclusively on the user's characteristics, disregarding any information related to others}
\text{individuals, unless it directly impacts the user.}

\text{For each personality trait:}
\begin{enumerate}
    \item \text{Assign each dimension independently with \textbf{score}: "High", "Low," or "Inconclusive."}
    \item \text{Provide \textbf{conclusion}: A high-level description, with concise supporting details.}
    \item \text{Provide \textbf{reason}: Justify the assigned score with specific evidence from the dialogue.}
    \item \text{Mark traits as \textbf{Inconclusive} only when no clear evidence exists.}
\end{enumerate}

\textbf{Personality Trait Defination:}

\texttt{\{\{metric\}\}: \{\{definition\}\}} \\
\textbf{Format:}
\begin{verbatim}
{
    "Trait Name": {
        "score": "High/Low/Inconclusive",
        "conclusion": "The user is a [trait descriptor] person...",
        "reason": "Explanation referencing specific dialogue evidence."
    },
    ...
}
\end{verbatim}

\textbf{Example:}
\begin{verbatim}
[User]: "She is my age, in a homeless women's shelter, living under very poor
conditions. She is a mental health client, but the treatment team seems to
... Her background is similar to mine, and I cannot abandon her."
\end{verbatim}

\textbf{Detected Personality Traits:}
\begin{verbatim}
{
  "Conscientiousness": {
    "score": "High",
    "conclusion": "The user is a conscientious person who demonstrates a
    sense of duty and commitment.",
    "reason": "The user expresses a strong sense of responsibility ..."
  },
  "Agreeableness": {
    "score": "High",
    "conclusion": "The user is an empathetic and compassionate person who
    values relationships.",
    "reason": "The user shows care and concern for their cousin's well-being..."
  },
  "Extraversion": {
    "score": "Inconclusive"
  },
  ...
}
\end{verbatim}
\end{tcolorbox}
\caption{Prompt for extracting deep intrinsic characteristics.}
\label{fig:personality_extraction}
\end{figure*}




\begin{figure*}[t]
\begin{tcolorbox}[colback=white, colframe=black, title=Prompt for Extracting Scene-Consistent Attributes]
\textbf{User Persona Analysis Task}

\textbf{Objective} \\
The primary goal of this task is to analyze user utterances in-depth and accurately extract key persona attributes based on both direct and implicit cues. These attributes should be categorized into distinct fields, with any missing or unclear details left blank. 

\textbf{Field Descriptions:} 
\texttt{\{\{Field\}\}: \{\{definition\}\}}

\textbf{Guidelines}
\begin{enumerate}
    \item Carefully examine each user utterance to extract relevant persona traits. Consider both direct statements and implicit clues.
    \item Ensure that the extracted attributes are specific and directly relevant to the user's utterances. Avoid vague or generalized descriptions unless explicitly supported by the text.
    \item Pay attention to distinctive communication styles (e.g., formal or casual tone, frequent use of specific words or phrases) to capture the user's unique way of communicating.
\end{enumerate}

\textbf{Example}

User Utterances:
\begin{verbatim}
[User]: Given an array of integers nums and an integer target, return indices of 
the two numbers such that they add up to target in Python...
[Assitant]: To solve the problem...
[User]: Thanks
\end{verbatim}

Expected Output:
\begin{verbatim}
{
    "gender": [],
    "age": [],
    "location": [],
    "occupation": [
        "Likely a beginner programmer or student studying computer science, 
        as evidenced by the simple coding problem in Python."
    ],
    "education": [
        "Possibly a student in computer science or a related field, 
        at an early stage in learning programming, specifically Python."
    ],
    "family_relationships": [],
    "routines_or_habits": [],
    "social_relationships": [],
    "language_style": [
        "Concise and task-oriented",
        "Polite response 'Thanks' after getting satisfactory answer"
    ],
    "other_experiences": []
}
\end{verbatim}
\end{tcolorbox}
\caption{Prompt for extracting scene-consistent attributes.}
\label{fig:scene_consistent_extraction}
\end{figure*}



\begin{figure*}[t]
\begin{tcolorbox}[colback=white, colframe=black, title=Prompt for Extracting Scene-Related Attributes]
\textbf{User Persona Analysis Task}

\textbf{Objective} \\
The goal of this task is to analyze multi-turn user utterances within a conversation with an assistant and extract key elements such as the primary goals and specific task descriptions. Each extracted detail should be as specific as possible, reflecting the user's context, objectives, and scenario.

\textbf{Output Format} \\
The extraction should be presented in a structured JSON format, as shown below:

\begin{verbatim}
{
    "scenarios": [
        {
            "goals_or_plans": "<List of User's goals or plans>",
            "task_details": "<List of specific tasks summary made by the user>"
        },
        ...
    ]
}
\end{verbatim}

\textbf{Field Descriptions:}
\begin{itemize}
    \item \textbf{goals\_or\_plans}: User's short-term or long-term objectives, derived from explicit statements or inferred from the overall conversation. If no explicit goals are stated, infer them from the main topics discussed.
    \item \textbf{task\_details}: Specific tasks, actions, or requests made by the user. Each task should be concisely summarized with specifics. If there are multiple tasks or requests, list each one separately.
\end{itemize}

\textbf{Example} \\
User Utterances:
\begin{verbatim}
[User]: Summarize: Harry Potter is a fictional character in the Harry Potter series...
[Assitant]: Harry Potter is a fictional character...
[User]: Write an email inquiring about coursework...
\end{verbatim}

\begin{verbatim}
{
    "scenarios": [
        {
            "goals_or_plans": "Aiming to gain a deeper understanding of the Harry
                        Potter series, possibly for academic or personal enrichment.",
            "task_details": [
                "Summarizing introductory content about the Harry Potter character."
            ]
        },
        {
            "goals_or_plans": "Looking to improve professional communication skills.",
            "task_details": [
                "Writing an email to inquire about coursework."
            ]
        }
    ]
}
\end{verbatim}
\end{tcolorbox}
\caption{Prompt for extracting scene-related attributes.}
\label{fig:scene_related_extraction}
\end{figure*}


\begin{figure*}[t]
\begin{tcolorbox}[colback=white, colframe=black, title=Prompt for Rephrasing Attributes into Natural Descriptions]
\textbf{Narrative Generation Objective} \\
Rephrase the provided key-value pairs into a natural, coherent second-person description.

\textbf{Core Requirements}
\begin{enumerate}
    \item \textbf{Perspective}: Use second-person perspective ("you", "your").
    \item \textbf{Structure}: Two paragraphs:
    \begin{itemize}
        \item First paragraph: Present objective facts.
        \item Second paragraph: Describe subjective characteristics.
    \end{itemize}
    \item \textbf{Key Principles}
    \begin{itemize}
        \item Accurately represent \textbf{all} provided details.
        \item Ensure the language flows naturally, remains engaging, and avoids redundancy.
        \item Focus on clear and seamless transitions between ideas.
    \end{itemize}
\end{enumerate}

\textbf{Output Expectations}
\begin{itemize}
    \item \textbf{Objective Facts}:  
    \begin{itemize}
        \item Convert the key-value pairs into a clear and natural description without over-explaining or adding unnecessary details.
        \item Ensure each scenario is logically connected and key information is presented effectively.
    \end{itemize}
    \item \textbf{Subjective Characteristics}: 
    \begin{itemize}
        \item Avoid vague terms like "high perfectionism" or "moderate emotional stability." Use vivid, descriptive language to bring these traits to life.
    \end{itemize}
\end{itemize}

\end{tcolorbox}
\caption{Prompt for rephrasing attributes into natural descriptions for profile generation.}
\label{fig:rephrase_prompt}
\end{figure*}



\begin{figure*}[t] 
\begin{tcolorbox}[colback=white, colframe=black, title=Human Evaluation Guidelines for Authenticity]
1. \textbf{Task Description:}
 Please choose which user in the two test conversations is more similar to the reference conversation being spoken by the same person.
 
2. \textbf{Evaluation Criteria:}
     \begin{itemize}
         \item \textbf{Semantic Similarity}: Measure the thematic consistency and discourse coherence between the generated user utterance and the target user utterance. Preference should be given to the utterance that more accurately reflects the semantic content of the target.
         \item \textbf{Stylistic Parity}: Analyze whether the generated user utterance matches the style of the target user utterance, including its tone, vocabulary, and grammatical structure. The utterance that aligns more closely with the stylistic elements of the target should be favored.
         \item \textbf{Quality}: Examine the fluency and logical coherence of the user utterance, focusing on the linguistic and logical smoothness of the user utterance. The more coherent and fluent utterances should be chosen.
     \end{itemize}
\end{tcolorbox}
\caption{Human evaluation guidelines for authenticity.}
\label{fig:human_eval_authenticity}
\end{figure*}



\begin{figure*}[t] 
\begin{tcolorbox}[colback=white, colframe=black, title=Human Evaluation Guidelines for Consistency]
1. \textbf{Task Description:} 

     Select the dialogue that contains the most appropriate \textbf{user utterance} from the two given generated dialogues based on the target user profile. 

2. \textbf{Evaluation Criteria:}

     \begin{itemize}
         %\item \textbf{Conversational Naturalness (Foundational Prerequisite)}: Assess whether the utterance \textbf{aligns with natural human conversational behaviors}. Penalize responses that are overly explicit, exaggerated, or unnatural. Any utterance that \textbf{fails to reflect a realistic human-LLM interaction} should be \textbf{immediately disqualified} from further evaluation.
         \item \textbf{Persona Reflection}: Evaluate how closely each user utterance reflects the target profile’s thematic content, tone, and stylistic features. Preference should be given to the dialogue whose user utterance most accurately reflects the profile’s characteristics in terms of thematic coherence and expression.
         \item \textbf{Comprehensiveness}: Assess the extent to which the user utterance encapsulates the target profile, integrating both objective facts and subjective descriptions. The more comprehensive utterance, which addresses a broader range of profile aspects, should be favored over one that focuses narrowly on a single dimension.
         \item \textbf{Quality}: Evaluate the fluency, coherence, and human-likeness of the user utterance. Preference should be given to the utterance that demonstrates greater linguistic smoothness, logical cohesion, and alignment with genuine human conversational patterns.
     \end{itemize}

\end{tcolorbox}
\caption{Human evaluation guidelines for consistency.}
\label{fig:human_eval_consistency}
\end{figure*}






\begin{figure*}[t]
\begin{tcolorbox}[colback=white, colframe=black, title=Prompt for NLI Score of Profile Precision Based on Given Dialogue]
\textbf{Role} \\
You are an expert in evaluating the \textbf{consistency} between a given \textbf{user profile (Source)} and \textbf{the user’s utterance (Target)}. Your task is to assess whether the \textbf{Target} aligns with, contradicts, or is ambiguous in relation to the \textbf{Source}.

\textbf{Task Instructions:} \\
For each \textbf{Source-Target} pair, determine the relationship using the following scoring criteria:
\begin{itemize}
    \item \textbf{Score 1}: The Target is consistent with the Source (the interpretation can be inferred from the Source).
    \item \textbf{Score -1}: The Target conflicts with the Source (the interpretation contradicts the Source).
    \item \textbf{Score 0}: The relationship is unclear or ambiguous (insufficient evidence to infer consistency or contradiction).
\end{itemize}

\textbf{Output Format:} \\
Provide your result in the following JSON format:
\begin{verbatim}
{
  "score": <score>, 
  "reason": "<concise explanation of the reasoning>"
}
\end{verbatim}

\textbf{Example:} \\
\textbf{Source}: You are interested in dataset-related details. \\
\textbf{Target}: [User]: Show me how to implement a toy version of a relational database.

\textbf{Output}:
\begin{verbatim}
{
  "score": 1, 
  "reason": "The request for implementing a relational database suggests an 
  interest in data structures and datasets, which aligns with the Source."
}
\end{verbatim}

\textbf{Guidelines:}
\begin{enumerate}
    \item \textbf{Contextual Inference}: Do not evaluate the Target \textbf{in isolation}. Instead, determine its logical relationship to the Source, considering both explicit statements and reasonable implications.
    \item \textbf{Concise \& Precise Justification}: The reasoning should be clear, objective, and free from unnecessary elaboration.
\end{enumerate}

\end{tcolorbox}
\caption{Prompt for DP.P based on NLI.}
\label{fig:DP_P_prompt}
\end{figure*}

\begin{figure*}[t]
\begin{tcolorbox}[colback=white, colframe=black, title=Prompt for NLI Score of Dialogue Precision Based on Given Profile]

\textbf{Role} \\
You are an expert in evaluating consistency between \textbf{a given dialogue history (Source)} and a corresponding \textbf{user profile description (Target)}. Your task is to determine whether the Target aligns with, contradicts, or is ambiguous in relation to the Source.

\textbf{Task Instructions:} \\
For each \textbf{Source-Target} pair, determine the relationship using the following scoring criteria:
\begin{itemize}
    \item \textbf{Score 1}: The Target is consistent with the Source (the interpretation can be inferred from the Source).
    \item \textbf{Score -1}: The Target conflicts with the Source (the interpretation contradicts the Source).
    \item \textbf{Score 0}: The relationship is unclear or ambiguous (insufficient evidence to infer consistency or contradiction).
\end{itemize}

\textbf{Output Format:} \\
Provide your result in the following JSON format:
\begin{verbatim}
{
  "score": <score>, 
  "reason": "<concise explanation of the reasoning>"
}
\end{verbatim}

\textbf{Example :} \\
\textbf{Source}: 
\begin{itemize}
    \item [User](Turn-1): Show me how to implement a toy version of a relational database.
    \item [User](Turn-2): Thanks a lot!
\end{itemize}

\textbf{Target}: You are polite.

\textbf{Output}:
\begin{verbatim}
{
  "score": 1, 
  "reason": "The user's expression of gratitude in Turn-2 indicates politeness, 
  which aligns with the Target."
}
\end{verbatim}

\textbf{Guidelines:}
\begin{enumerate}
    \item \textbf{Contextual Inference}: Do not evaluate the Target \textbf{in isolation}. Instead, determine its logical relationship to the Source, considering both explicit statements and reasonable implications.
    \item \textbf{Concise \& Precise Justification}: The reasoning should be clear, objective, and free from unnecessary elaboration.
\end{enumerate}

\end{tcolorbox}

\caption{Prompt for DP.R based on NLI.}
\label{fig:DP_R_prompt}
\end{figure*}


\begin{figure*}[t] 
\begin{tcolorbox}[colback=white, colframe=black, title=Prompt for Subjective Characteristics Score (SC.Score) in Consistency Evaluation]

\textbf{Task Description} \\
You are tasked with evaluating the quality of user responses in real human-LLM interactions. Specifically, you will assess the degree to which a given response (Target) aligns with a predefined personality profile, tone, and linguistic characteristics (Source). Additionally, you must consider the naturalness and authenticity of the Target, ensuring it reflects genuine human conversational patterns.

\textbf{Evaluation Criteria} \\
Your assessment will focus on two primary dimensions:  
\begin{enumerate}
    \item \textbf{Human-Likeness}: The extent to which Target exhibits natural human language, characterized by appropriate syntax, tone, and conversational flow.  
    \item \textbf{Alignment with Source}: The degree to which the Target adheres to the personality traits, tone, and linguistic features specified in the Source.  
\end{enumerate}

\textbf{Scoring Guidelines} \\
Assign a score from 1 to 5 based on the following criteria:  
\begin{itemize}
    \item \textbf{Score 5}: The Target fully aligns with the Source and demonstrates exceptional human-likeness.  
    \item \textbf{Score 3}: The relationship between the Target and Source is ambiguous or unclear, lacking sufficient evidence for alignment or contradiction.  
    \item \textbf{Score 1}: The Target significantly deviates from the Source or lacks human-likeness, rendering it unnatural or inconsistent.  
\end{itemize}

\textbf{Output Requirements} \\
Provide your evaluation in the following JSON format:  
\begin{verbatim}
{
  "score": <score>,
  "reason": "<concise reason>"
}
\end{verbatim}

\textbf{Key Considerations} 
\begin{enumerate}
    \item \textbf{Contextual Inference}: Analyze both explicit content and implicit nuances in the Target to determine its alignment with the Source.  
    \item \textbf{Conciseness and Precision}: Ensure that your reasoning is clear, objective, and free of superfluous elaboration.  
    \item \textbf{Human-Likeness Emphasis}: A lack of human-likeness, even if the Target aligns with the Source, will result in a lower score.  
\end{enumerate}

\end{tcolorbox}
\caption{Prompt for evaluating consistency in subjective characteristics.}
\label{fig:sc_score}
\end{figure*}



\begin{figure*}[t] 
\begin{tcolorbox}[colback=white, colframe=black, title=Prompt for Validation Score (Val.Score) in Assessing the Quality of Subjective Characteristics in Profiles]


\textbf{Role} \\
As an expert in evaluating the \textbf{consistency} between \textbf{user utterances in a dialogue (Source)} and a provided \textbf{subjective description (Target)}, your task is to assess whether the \textbf{Target} accurately reflects the characteristics described in the \textbf{Source}, including personality traits, tone, and other relevant attributes. You will then rate this consistency on a scale from 1 to 5.

\textbf{Task Instructions} \\
For each pair of \textbf{Source-Target}, apply the following scoring criteria to determine their relationship:
\begin{itemize}
    \item \textbf{Score 5}: The \textbf{Target} completely aligns with the \textbf{Source}, with no discrepancies. The profile perfectly represents the characteristics observed in the user’s utterance.
    \item \textbf{Score 3}: Ambiguity or insufficient evidence exists, making it difficult to ascertain the relationship definitively.
    \item \textbf{Score 1}: A clear discrepancy exists, with the \textbf{Target} significantly deviating from the \textbf{Source}, indicating a mismatch in the represented characteristics.
\end{itemize}

\textbf{Output Format} \\
Your assessment should adhere to the following structured JSON format:
\begin{verbatim}
{
  "score": "<numerical score>",
  "reason": "<a succinct explanation providing justification for assigned score>"
}
\end{verbatim}

\textbf{Guidelines:}
\begin{enumerate}
    \item \textbf{Contextual Inference}: Determine the target's logical relationship to the Source, considering both explicit statements and reasonable implications.
    \item \textbf{Concise \& Precise Justification}: The reasoning should be clear, objective, and free from unnecessary elaboration.
\end{enumerate}

\end{tcolorbox}
\caption{Prompt for validation score (Val.Score) in assessing the quality of subjective characteristics in profiles.}
\label{fig:val_score}
\end{figure*}

\end{CJK}
\end{document}
