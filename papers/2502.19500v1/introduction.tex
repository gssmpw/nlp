\label{sec:intro}

Consider would happens when we ask another person about a complex real-life task, such as planning a vacation,  learning how to draw, or improve one's fitness level. If the person does not know you, they would first ask you a couple of questions to clarify your preferences, your skill level, and your goals. Having gained a better understanding about you and the task, they might provide some suggestions for you to consider, and then keep adapting those as you provide more feedback through conversation. For example, for the vacation planning task, they might start with steps such as "determine the budget" and "figure out the preferred kind of vacation", and "narrow down potential destinations". For each step, they might ask clarifying questions, or answer your questions and provide some relevant resources like a web site for a relevant city or airline. As you start getting more concrete about the specifics of your goal, and take actions such as choosing the destination, you need help with the next step, such as booking accommodations and planning specific activities.  Therefore, the plan evolves---either the person recommends new steps, revises some existing steps to account for the updated information, or asks further questions. A similar \emph{conversational planning} process is followed whenever a fitness coach is asked to provide a plan adapted for their client, and whenever a tutor needs to provide a personalized learning plan.  All of these plans need to evolve over time based on the updated needs of the user.

However, when we ask the popular conversational interfaces of today to help with long term real-life tasks or goals, they behave very differently than people. They tend to generate long responses with bulleted lists of steps to follow. They do not ask questions proactively, but only respond in a reactive way to user queries. Also, they do not provide a structured plan for the user to follow that can be adapted over time based on user feedback. In this work, we aim to bridge this gap between how conversational agents and humans solve long-term tasks and goals.

We argue that, thanks to the impressive reasoning and natural language generation capabilities of large language models (LLMs), doing interactive hierarchical planning via natural language is an effective approach for artificial intelligence (AI) agents to assist and collaborate with users about their plans for real-life goals and tasks. We propose a framework where a chain-of-thought (CoT)-prompted LLM \cite{wei2022chain} plays the role of the meta-controller deciding the next macro-action, which is then executed by options/policies powered via the same or different LLM, CoT-prompted with different examples. The meta-controller receives natural language feedback from the user, allowing for interactive planning over time. This general LLM-based hierarchical framework can be used for various long-term planning tasks---we instantiate it in the context of assisting a user with a long-term real-life goal. Thus, the macro-actions are instantiated to "ask a question", "add a step", or "alter a step", so that the AI agent can operate in a similar fashion as a person would if they were to be asked to help with coaching or tutoring or assisting with making a plan. For each step of the plan, as executed by the LLM-based policy, the system also fetches and ranks content via tool use and LLM CoT prompting \cite{yao2022react}, so that the agent can point to specific resources the user might want to look at to further explore that step of the plan. The plan can be adapted over time via  natural language user feedback, obtained either via user's answers to the questions or via user's free-form feedback. We qualitatively demonstrate the effectiveness of the approach across domains of learning and health.%, and other real-life tasks.

