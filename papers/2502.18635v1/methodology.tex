\section{Preliminaries and problem formulation}
\label{sec:prelims}

\paragraph{Multi-Objective Optimization (MOO).}
The goal of MOO is to find a solution $\mathbf{x} \in \mathcal{X}$ that maximizes (or minimizes) a set of objective functions, where $\mathbf{x} = [x_1, x_2, \dots x_l]$ corresponds to a series of input values, and $\mathcal{X}$ is said to be the solution space. We then define each objective as $f : \mathcal{X} \rightarrow \mathbb{R}$ and use $\mathbf{f} : \mathcal{X} \rightarrow\mathbb{R}^k$ to represent $k$ objective functions. Using these definitions, we aim to solve the following optimization problem:

\begin{equation}
\max_{\mathbf{x} \in \mathcal{X}} ~\mathbf{f(x)} := \max_{\mathbf{x} \in \mathcal{X}} \left[ f_1(\mathbf{x}),f_2(\mathbf{x}), \dots f_k(\mathbf{x})\right]
\label{eq:moo}
\end{equation}

Rather than identifying a single solution, MOO algorithms identify a set of non-dominated solutions~\citep{deb2016multi}. We use $\mathbf{f(x^*)} \succ \mathbf{f(x)}$ to signify that $\mathbf{f(x^*)}$ dominates $\mathbf{f(x)}$:
\begin{equation}
\forall i \in \{1, \dots, k\}, \quad f_i(\mathbf{x}) \leq f_i(\mathbf{x^*}),  \quad \text{and}\quad  \exists j \text{ s.t. } f_j(\mathbf{x}) < f_j(\mathbf{x^*})
\end{equation}
Hence, and following \cite{daulton2021parallel}, we define the \emph{Pareto set} as $\mathcal{P}^* = \{ \mathbf{f(x^*)} \mid \mathbf{x^*}\in \mathcal{X}, \nexists \; \mathbf{x} \in \mathcal{X} \text{ s.t. } \mathbf{f(x)} \succ \mathbf{f(x^*)} \}$, and the corresponding \emph{Pareto optimal solutions} as $\mathcal{X^*} = \{ \mathbf{x^*} \mid \mathbf{f(x^*)} \in \mathcal{P}^*\}$. In practice, the Pareto optimal set often consists of an infinite set of points. Given a set of observed solutions from $\mathcal{X}$, %$\mathcal{X'} \subset \mathcal{X}$, 
we aim to identify an approximate Pareto optimal set, $\mathcal{\hat{P}} \subset \mathbb{R}^k$, and its associated Pareto optimal solutions, $\mathcal{\hat{X}}$. We then use the hypervolume (HV) indicator, $\mathcal{HV}$, to evaluate the quality of $\mathcal{\hat{P}}$ given a reference point $\mathbf{r} \in \mathbb{R}^k$. Our optimization problem then becomes:
\begin{equation}
    \label{eq:objective}
    \max_{\mathcal{\hat{P}}} \mathcal{HV}(\mathcal{\hat{P}}|\mathbf{r})
\end{equation}

In this work, we seek to find the Pareto-optimal combinations of parameters of a RAG system (those indicated in Table~\ref{tab:system_params}). We represent a \emph{configuration} of a RAG system as a solution vector $\mathbf{x} \in \mathcal{X}$, where each value corresponds to a system parameter. We aim to find the solution set containing different RAG pipeline configurations that maximizes $\mathcal{HV}$ for the objectives in Section \ref{sec:objectives}.

\paragraph{Bayesian Optimization (BO).} Objective function evaluations herein are obtained using an entire RAG pipeline, meaning there is no single analytic expression or gradient available for solving Equation (\ref{eq:objective}). BO is a derivative-free optimization method that works by constructing probabilistic surrogate models to capture the uncertainty of objective functions. The core methodology employs Gaussian process regression to model the unknown objective landscape, where each function $f_i$ is represented as a stochastic process with a posterior distribution $p(f_i \mid \mathcal{D})$ conditioned on observed data \citep{williams2006gaussian}. Importantly, BO makes use of an acquisition function to balance exploration of unknown regions and exploitation of promising solutions. BO has been known to perform well compared to other optimization methods when objective functions are expensive to evaluate, as in our setting~\citep{gramacy2020surrogates, diessner2022investigating,guerreiro2021hypervolume}.

\section{Methodology}
\label{sec:methodology}

Our approach works by defining a solution space (over the configurations of a RAG pipeline), objectives, and a train-test paradigm, then using BO to find the optimal configuration. BO is well-suited to exploit patterns in objective evaluations, for example the tendency for latency to increase with chunk size. We allow that the solution space has a mixture of continuous variables (\eg temperature of LLM) and categorical variables (\eg choice of LLM). In addition, we allow for constraints on the inputs, such as asserting that the chunk overlap must be less than the chunk size.

We make use of two state-of-the-art algorithms that implement and extend BO. The first, \texttt{qLogEHVI}, takes advantage of recent advances in programming models and hardware acceleration to parallelize multi-objective BO using the LogEI variant~\citep{ament2023unexpected} of \emph{expected hypervolume improvement} to guide the acquisition of new candidate solutions~\citep{daulton2020differentiable}. The second is \texttt{qLogNEHVI}, which extends \texttt{qLogNEHVI} by using a novel acquisition function that was theoretically motivated and empirically demonstrated to outperform benchmark methods in settings with noisy objective evaluations~\citep{daulton2021parallel}. The noisy variant is particularly useful since the probabilistic nature of LLMs can cause noisy objective function evaluations.
% are noisy, and we choose the acquisition function accordingly.}
BO is also well-suited to exploit patterns in objective evaluations, for example the tendency for latency to increase with chunk size. Following \cite{daulton2021parallel}, we initialize both BO algorithms with $N_\text{init}$ points from a scrambled Sobol sequence.

We outline our proposed methodology in Algorithm \ref{alg:1}, and provide implementation details in Section~\ref{sec:experiments}. We also provide a method of approximating each objective function in Appendix \ref{sec:approx_objective}.

\begin{algorithm}
\caption{Train-test multi-objective optimization of RAG or LLM system}\label{alg:1}
\begin{algorithmic}[1]
\Require set of documents $\mathcal{D}$, solution space $\mathcal{X}$, reference point $\mathbf{r}$, number of iterations $N$, number of iterations for BO initialization $N_{\text{init}}$ 
\State $Q, Q_{\text{test}} \gets \texttt{Generate}(\mathcal{D})$ \Comment{Generate train-test queries from documents}
\State $H, H_{\text{test}}\gets [~], [~]$ \Comment{Start with empty train and test history}

\For{$n = 1...N$} \Comment{Parameter optimization}
\If{$n\leq N_{\text{init}}$}
    \State $\mathbf{x} \gets \texttt{Sobol}(H, \mathcal{X})$ \Comment{Sobol sampling for $N_{\text{init}}$ iterations}
\Else
    \State $\mathbf{x} \gets \texttt{qLogNEHVI}(H, \mathcal{X})$ \Comment{\texttt{qLogNEHVI} acquisition function}
\EndIf
\State $\mathbf{f} \gets  \texttt{ObjectiveEvaluations}(\mathbf{x}, Q)$ \Comment{Evaluate solution on $Q$}
\State $H.\texttt{append} (\{\mathbf{x}, \mathbf{f}\})$ \Comment{Save to history}

\State $\mathcal{\hat{X}}, \mathcal{\hat{P}} \gets \texttt{ParetoOptimalSet} (H)$ \Comment{Find Pareto-optimal set}
\State $\text{HV} \gets \mathcal{HV} (\mathcal{\hat{P}} | \mathbf{r})$ \Comment{Find hypervolume w.r.t reference point}

\State $\mathbf{f}_{\text{test}} \gets \texttt{ObjectiveEvaluations}(\mathbf{x}, Q_{\text{test}})$ \Comment{Evaluate solution on $Q_{\text{test}}$}
\State $H_{\text{test}}.\texttt{append}(\{ \mathbf{x}, \mathbf{f}_{\text{test}}\})$ \Comment{Save to history}
\State $\mathcal{\hat{X}}_\text{test}, \mathcal{\hat{P}}_\text{test} \gets \texttt{ParetoOptimalSet} (H_{\text{test}})$ \Comment{Find test Pareto-optimal set}
\State $\text{HV}_\text{test} \gets \mathcal{HV} (\mathcal{\hat{P}}_{\text{test}} | \mathbf{r})$ \Comment{Find test hypervolume w.r.t reference point}
\EndFor
\State $X_{\text{opt}} \gets \texttt{SelectOptimalConfig}(\hat{\mathcal{X}}_{\text{test}},\mathcal{\hat{P}}_{\text{test}})$ \Comment{Select optimal configuration(s)}
\end{algorithmic}
\end{algorithm}

\subsection{Generating Train-Test Queries}
\label{sec:synthetic_data}
A frequent challenge encountered by the authors in industry is a lack of existing queries for RAG Q\&A tasks.
To this end, we use LLMs to help generate queries from the data, which may be PDF documents or large documents of text. LLMs are a reasonable choice for this approach because they have been shown to be effective at generating synthetic data \citep{long2024llms}.
For our \texttt{FinancialQA} dataset described in Section \ref{sec:datasets}, we generate train and test queries using an LLM (GPT-4o). We publicly release the synthetic questions as part of our datasets, and provide the prompt used to generate the questions in Appendix \ref{sec:prompts}.

\subsection{Objectives}
\label{sec:objectives}

Motivated by experiences in industry, we consider four objectives that practitioners commonly consider important: safety, alignment, cost and latency.

\paragraph{Safety.} In this work, we use the term ``safety'' to refer to \emph{hallucination risks}, or the risk that a RAG pipeline will return false information to the user. Hallucinations can cause significant downstream harm, particularly in high-stakes domains such as healthcare.
In our experiments, we evaluate safety using the \emph{faithfulness} metric defined in the Trustwise API.\footnote{\label{docnote} Trustwise documentation available at: \url{https://trustwise.ai/docs}} Like previous work \citep{min2023factscore, es2023ragas}, faithfulness detects hallucinations by evaluating whether or not the response from a RAG system is supported by the context. The response is split into individual, ``atomic'' claims that are verified with respect to the context. Scores of these verifications are then aggregated into a single faithfulness score between 0 and 100 for each response, where 100 represents a completely ``safe'' response with no hallucinations.\footnote{For those aiming to replicate our approach, there are open-source alternatives for evaluating safety that could be used instead, such as LlamaGuard~\citep{inan2023llama}.}

\paragraph{Alignment.}
While hallucination risks are an immediate concern, the alignment of a response is often just as important in enterprise use-cases. To evaluate alignment, we follow the definition of \emph{helpfulness} popularized by Anthropic~\citep{bai2022training}. We measure alignment using the \emph{helpfulness} metric as implemented in the Trustwise API which judges how useful, detailed and unambiguous a response is. This metric assigns a score between 0 and 100 for each response, where a higher score indicates a more helpful response.

\paragraph{Cost.} To calculate the cost of an evaluation, we consider all the components of a RAG pipeline, including the query embedding cost, reranker embedding cost, LLM input token cost and LLM output token cost. Importantly, the cost of a RAG pipeline is a function of its configuration:
\begin{align}
\begin{split}
    \text{cost} = ~&\text{number of query tokens} \times \text{cost per embedding token} \\
    &+\text{number of context tokens} \times \text{cost per reranker token} \\
    &+ \text{number of prompt input tokens} \times \text{cost per LLM input token} \\
    &+ \text{number of output tokens} \times \text{cost per LLM output token}
\end{split}
\end{align}

The embedding cost per query token, reranker token cost, LLM input token cost, and LLM output token cost are based on the specific choices of those models, as well as the hardware being used to run the RAG pipeline. In enterprise use-cases, these costs may also include overhead and maintenance.

\paragraph{Latency.} We define latency as the time it takes for a complete end-to-end run of the RAG pipeline, from the moment an initial query is sent to the system to the moment a full response is returned to the user. As with cost, we can calculate the latency of a system as a function of its configuration:
\begin{equation}
    \text{latency} = \text{embedding latency} + \text{reranker latency} + \text{LLM response latency} + \text{evaluation latency}
\end{equation}
We note that response evaluations can take as long as, or longer than, response generation and thus the end-to-latency is vital to consider in enterprise settings where evaluations are a requirement.