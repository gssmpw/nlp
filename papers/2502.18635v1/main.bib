@inproceedings{kour2014real,
  title={Real-time segmentation of on-line handwritten arabic script},
  author={Kour, George and Saabne, Raid},
  booktitle={Frontiers in Handwriting Recognition (ICFHR), 2014 14th International Conference on},
  pages={417--422},
  year={2014},
  organization={IEEE}
}

@article{jacovi2025facts,
  title={The FACTS Grounding Leaderboard: Benchmarking LLMs' Ability to Ground Responses to Long-Form Input},
  author={Jacovi, Alon and Wang, Andrew and Alberti, Chris and Tao, Connie and Lipovetz, Jon and Olszewska, Kate and Haas, Lukas and Liu, Michelle and Keating, Nate and Bloniarz, Adam and others},
  journal={arXiv preprint arXiv:2501.03200},
  year={2025}
}

@inproceedings{kour2014fast,
  title={Fast classification of handwritten on-line Arabic characters},
  author={Kour, George and Saabne, Raid},
  booktitle={Soft Computing and Pattern Recognition (SoCPaR), 2014 6th International Conference of},
  pages={312--318},
  year={2014},
  organization={IEEE}
}

@article{hadash2018estimate,
  title={Estimate and Replace: A Novel Approach to Integrating Deep Neural Networks with Existing Applications},
  author={Hadash, Guy and Kermany, Einat and Carmeli, Boaz and Lavi, Ofer and Kour, George and Jacovi, Alon},
  journal={arXiv preprint arXiv:1804.09028},
  year={2018}
}

@article{tribes2023hyperparameter,
  title={Hyperparameter optimization for large language model instruction-tuning},
  author={Tribes, Christophe and Benarroch-Lelong, Sacha and Lu, Peng and Kobyzev, Ivan},
  journal={arXiv preprint arXiv:2312.00949},
  year={2023}
}

@article{hu2021lora,
  title={Lora: Low-rank adaptation of large language models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  journal={arXiv preprint arXiv:2106.09685},
  year={2021}
}

@article{suzgun2022challenging,
  title={Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them},
  author={Suzgun, Mirac and Scales, Nathan and Sch{\"a}rli, Nathanael and Gehrmann, Sebastian and Tay, Yi and Chung, Hyung Won and Chowdhery, Aakanksha and Le, Quoc V and Chi, Ed H and Zhou, Denny and and Wei, Jason},
  journal={arXiv preprint arXiv:2210.09261},
  year={2022}
}

@misc{chen2021evaluating,
      title={Evaluating Large Language Models Trained on Code},
      author={Mark Chen and Jerry Tworek and Heewoo Jun and Qiming Yuan and Henrique Ponde de Oliveira Pinto and Jared Kaplan and Harri Edwards and Yuri Burda and Nicholas Joseph and Greg Brockman and Alex Ray and Raul Puri and Gretchen Krueger and Michael Petrov and Heidy Khlaaf and Girish Sastry and Pamela Mishkin and Brooke Chan and Scott Gray and Nick Ryder and Mikhail Pavlov and Alethea Power and Lukasz Kaiser and Mohammad Bavarian and Clemens Winter and Philippe Tillet and Felipe Petroski Such and Dave Cummings and Matthias Plappert and Fotios Chantzis and Elizabeth Barnes and Ariel Herbert-Voss and William Hebgen Guss and Alex Nichol and Alex Paino and Nikolas Tezak and Jie Tang and Igor Babuschkin and Suchir Balaji and Shantanu Jain and William Saunders and Christopher Hesse and Andrew N. Carr and Jan Leike and Josh Achiam and Vedant Misra and Evan Morikawa and Alec Radford and Matthew Knight and Miles Brundage and Mira Murati and Katie Mayer and Peter Welinder and Bob McGrew and Dario Amodei and Sam McCandlish and Ilya Sutskever and Wojciech Zaremba},
      year={2021},
      eprint={2107.03374},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{balandat2020botorch,
  title={BoTorch: A framework for efficient Monte-Carlo Bayesian optimization},
  author={Balandat, Maximilian and Karrer, Brian and Jiang, Daniel and Daulton, Samuel and Letham, Ben and Wilson, Andrew G and Bakshy, Eytan},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={21524--21538},
  year={2020}
}

@article{long2024llms,
  title={On llms-driven synthetic data generation, curation, and evaluation: A survey},
  author={Long, Lin and Wang, Rui and Xiao, Ruixuan and Zhao, Junbo and Ding, Xiao and Chen, Gang and Wang, Haobo},
  journal={arXiv preprint arXiv:2406.15126},
  year={2024}
}

@article{bai2022training,
  title={Training a helpful and harmless assistant with reinforcement learning from human feedback},
  author={Bai, Yuntao and Jones, Andy and Ndousse, Kamal and Askell, Amanda and Chen, Anna and DasSarma, Nova and Drain, Dawn and Fort, Stanislav and Ganguli, Deep and Henighan, Tom and others},
  journal={arXiv preprint arXiv:2204.05862},
  year={2022}
}

@inproceedings{bakshy2018ae,
  title={AE: A domain-agnostic platform for adaptive experimentation},
  author={Bakshy, Eytan and Dworkin, Lili and Karrer, Brian and Kashin, Konstantin and Letham, Benjamin and Murthy, Ashwin and Singh, Shaun},
  booktitle={Conference on neural information processing systems},
  pages={1--8},
  year={2018}
}

@article{es2023ragas,
  title={Ragas: Automated evaluation of retrieval augmented generation},
  author={Es, Shahul and James, Jithin and Espinosa-Anke, Luis and Schockaert, Steven},
  journal={arXiv preprint arXiv:2309.15217},
  year={2023}
}

@article{min2023factscore,
  title={Factscore: Fine-grained atomic evaluation of factual precision in long form text generation},
  author={Min, Sewon and Krishna, Kalpesh and Lyu, Xinxi and Lewis, Mike and Yih, Wen-tau and Koh, Pang Wei and Iyyer, Mohit and Zettlemoyer, Luke and Hajishirzi, Hannaneh},
  journal={arXiv preprint arXiv:2305.14251},
  year={2023}
}

@book{williams2006gaussian,
  title={Gaussian processes for machine learning},
  author={Williams, Christopher KI and Rasmussen, Carl Edward},
  volume={2},
  number={3},
  year={2006},
  publisher={MIT press Cambridge, MA}
}

@article{emmerich2006single,
  title={Single-and multiobjective evolutionary optimization assisted by Gaussian random field metamodels},
  author={Emmerich, Michael TM and Giannakoglou, Kyriakos C and Naujoks, Boris},
  journal={IEEE Transactions on Evolutionary Computation},
  volume={10},
  number={4},
  pages={421--439},
  year={2006},
  publisher={IEEE}
}

@article{jones1998efficient,
  title={Efficient global optimization of expensive black-box functions},
  author={Jones, Donald R and Schonlau, Matthias and Welch, William J},
  journal={Journal of Global optimization},
  volume={13},
  pages={455--492},
  year={1998},
  publisher={Springer}
}

@article{hendrycks2020measuring,
  title={Measuring massive multitask language understanding},
  author={Hendrycks, Dan and Burns, Collin and Basart, Steven and Zou, Andy and Mazeika, Mantas and Song, Dawn and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2009.03300},
  year={2020}
}

@article{dua2019drop,
  title={DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs},
  author={Dua, Dheeru and Wang, Yizhong and Dasigi, Pradeep and Stanovsky, Gabriel and Singh, Sameer and Gardner, Matt},
  journal={arXiv preprint arXiv:1903.00161},
  year={2019}
}

@article{hutter2010sequential,
  title={Sequential model-based optimization for general algorithm configuration (extended version)},
  author={Hutter, Frank and Hoos, Holger H and Leyton-Brown, Kevin},
  journal={Technical Report TR-2010--10, University of British Columbia, Computer Science, Tech. Rep.},
  year={2010}
}

@article{audet2006mesh,
  title={Mesh adaptive direct search algorithms for constrained optimization},
  author={Audet, Charles and Dennis Jr, John E},
  journal={SIAM Journal on optimization},
  volume={17},
  number={1},
  pages={188--217},
  year={2006},
  publisher={SIAM}
}

@article{wu2024beta,
  title={$\beta$-DPO: Direct Preference Optimization with Dynamic $\beta$},
  author={Wu, Junkang and Xie, Yuexiang and Yang, Zhengyi and Wu, Jiancan and Gao, Jinyang and Ding, Bolin and Wang, Xiang and He, Xiangnan},
  journal={arXiv preprint arXiv:2407.08639},
  year={2024}
}

@article{rafailov2024direct,
  title={Direct preference optimization: Your language model is secretly a reward model},
  author={Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Manning, Christopher D and Ermon, Stefano and Finn, Chelsea},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{wang2021economic,
  title={Economic hyperparameter optimization with blended search strategy},
  author={Wang, Chi and Wu, Qingyun and Huang, Silu and Saied, Amin},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@inproceedings{wu2021frugal,
  title={Frugal optimization for cost-related hyperparameters},
  author={Wu, Qingyun and Wang, Chi and Huang, Silu},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={12},
  pages={10347--10354},
  year={2021}
}

@article{bergstra2011algorithms,
  title={Algorithms for hyper-parameter optimization},
  author={Bergstra, James and Bardenet, R{\'e}mi and Bengio, Yoshua and K{\'e}gl, Bal{\'a}zs},
  journal={Advances in neural information processing systems},
  volume={24},
  year={2011}
}

@inproceedings{wang2023cost,
  title={Cost-effective hyperparameter optimization for large language model generation inference},
  author={Wang, Chi and Liu, Xueqing and Awadallah, Ahmed Hassan},
  booktitle={International Conference on Automated Machine Learning},
  pages={21--1},
  year={2023},
  organization={PMLR}
}

@article{narayan2018don,
  title={Don't give me the details, just the summary! topic-aware convolutional neural networks for extreme summarization},
  author={Narayan, Shashi and Cohen, Shay B and Lapata, Mirella},
  journal={arXiv preprint arXiv:1808.08745},
  year={2018}
}

@article{hendrycks2021measuring,
  title={Measuring mathematical problem solving with the math dataset},
  author={Hendrycks, Dan and Burns, Collin and Kadavath, Saurav and Arora, Akul and Basart, Steven and Tang, Eric and Song, Dawn and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2103.03874},
  year={2021}
}

@article{wang2024llm,
  title={LLM can Achieve Self-Regulation via Hyperparameter Aware Generation},
  author={Wang, Siyin and Li, Shimin and Sun, Tianxiang and Fu, Jinlan and Cheng, Qinyuan and Ye, Jiasheng and Ye, Junjie and Qiu, Xipeng and Huang, Xuanjing},
  journal={arXiv preprint arXiv:2402.11251},
  year={2024}
}

@inproceedings{houlsby2019parameter,
  title={Parameter-efficient transfer learning for NLP},
  author={Houlsby, Neil and Giurgiu, Andrei and Jastrzebski, Stanislaw and Morrone, Bruna and De Laroussilhe, Quentin and Gesmundo, Andrea and Attariyan, Mona and Gelly, Sylvain},
  booktitle={International conference on machine learning},
  pages={2790--2799},
  year={2019},
  organization={PMLR}
}

@article{kim2024autorag,
  title={AutoRAG: automated framework for optimization of retrieval augmented generation pipeline},
  author={Kim, Dongkyu and Kim, Byoungwook and Han, Donggeon and Eibich, Matou{\v{s}}},
  journal={arXiv preprint arXiv:2410.20878},
  year={2024}
}

@article{lyu2024crud,
  title={Crud-rag: A comprehensive chinese benchmark for retrieval-augmented generation of large language models},
  author={Lyu, Yuanjie and Li, Zhiyu and Niu, Simin and Xiong, Feiyu and Tang, Bo and Wang, Wenjin and Wu, Hao and Liu, Huanyong and Xu, Tong and Chen, Enhong},
  journal={ACM Transactions on Information Systems},
  year={2024},
  publisher={ACM New York, NY}
}

@article{fu2024autorag,
  title={AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation},
  author={Fu, Jia and Qin, Xiaoting and Yang, Fangkai and Wang, Lu and Zhang, Jue and Lin, Qingwei and Chen, Yubo and Zhang, Dongmei and Rajmohan, Saravan and Zhang, Qi},
  journal={arXiv preprint arXiv:2406.19251},
  year={2024}
}

@article{yadav2024ties,
  title={Ties-merging: Resolving interference when merging models},
  author={Yadav, Prateek and Tam, Derek and Choshen, Leshem and Raffel, Colin A and Bansal, Mohit},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{li2024s,
  title={It's Morphing Time: Unleashing the Potential of Multiple LLMs via Multi-objective Optimization},
  author={Li, Bingdong and Di, Zixiang and Yang, Yanting and Qian, Hong and Yang, Peng and Hao, Hao and Tang, Ke and Zhou, Aimin},
  journal={arXiv preprint arXiv:2407.00487},
  year={2024}
}

@article{daulton2020differentiable,
  title={Differentiable expected hypervolume improvement for parallel multi-objective Bayesian optimization},
  author={Daulton, Samuel and Balandat, Maximilian and Bakshy, Eytan},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={9851--9864},
  year={2020}
}

@article{daulton2021parallel,
  title={Parallel bayesian optimization of multiple noisy objectives with expected hypervolume improvement},
  author={Daulton, Samuel and Balandat, Maximilian and Bakshy, Eytan},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={2187--2200},
  year={2021}
}

@article{ament2023unexpected,
  title={Unexpected improvements to expected improvement for bayesian optimization},
  author={Ament, Sebastian and Daulton, Samuel and Eriksson, David and Balandat, Maximilian and Bakshy, Eytan},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={20577--20612},
  year={2023}
}

@ARTICLE{pymoo,
    author={J. {Blank} and K. {Deb}},
    journal={IEEE Access},
    title={pymoo: Multi-Objective Optimization in Python},
    year={2020},
    volume={8},
    number={},
    pages={89497-89509},
}

@article{li2020deep,
  title={Deep reinforcement learning for multiobjective optimization},
  author={Li, Kaiwen and Zhang, Tao and Wang, Rui},
  journal={IEEE transactions on cybernetics},
  volume={51},
  number={6},
  pages={3103--3114},
  year={2020},
  publisher={IEEE}
}

@inproceedings{zhou2024beyond,
  title={Beyond one-preference-fits-all alignment: Multi-objective direct preference optimization},
  author={Zhou, Zhanhui and Liu, Jie and Shao, Jing and Yue, Xiangyu and Yang, Chao and Ouyang, Wanli and Qiao, Yu},
  booktitle={Findings of the Association for Computational Linguistics ACL 2024},
  pages={10586--10613},
  year={2024}
}

@article{mukherjee2024multi,
  title={Multi-Objective Alignment of Large Language Models Through Hypervolume Maximization},
  author={Mukherjee, Subhojyoti and Lalitha, Anusha and Sengupta, Sailik and Deshmukh, Aniket and Kveton, Branislav},
  journal={arXiv preprint arXiv:2412.05469},
  year={2024}
}

@article{gupta2024rag,
  title={RAG vs Fine-tuning: Pipelines, Tradeoffs, and a Case Study on Agriculture},
  author={Gupta, Aman and Shirgaonkar, Anup and Balaguer, Angels de Luis and Silva, Bruno and Holstein, Daniel and Li, Dawei and Marsman, Jennifer and Nunes, Leonardo O and Rouzbahman, Mahsa and Sharp, Morris and others},
  journal={arXiv preprint arXiv:2401.08406},
  year={2024}
}

@inproceedings{wortsman2022model,
  title={Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time},
  author={Wortsman, Mitchell and Ilharco, Gabriel and Gadre, Samir Ya and Roelofs, Rebecca and Gontijo-Lopes, Raphael and Morcos, Ari S and Namkoong, Hongseok and Farhadi, Ali and Carmon, Yair and Kornblith, Simon and others},
  booktitle={International conference on machine learning},
  pages={23965--23998},
  year={2022},
  organization={PMLR}
}

@incollection{deb2016multi,
  title={Multi-objective optimization},
  author={Deb, Kalyanmoy and Sindhya, Karthik and Hakanen, Jussi},
  booktitle={Decision sciences},
  pages={161--200},
  year={2016},
  publisher={CRC Press}
}

@article{guerreiro2021hypervolume,
  title={The hypervolume indicator: Computational problems and algorithms},
  author={Guerreiro, Andreia P and Fonseca, Carlos M and Paquete, Lu{\'\i}s},
  journal={ACM Computing Surveys (CSUR)},
  volume={54},
  number={6},
  pages={1--42},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@book{gramacy2020surrogates,
  title={Surrogates: Gaussian process modeling, design, and optimization for the applied sciences},
  author={Gramacy, Robert B},
  year={2020},
  publisher={Chapman and Hall/CRC}
}

@article{diessner2022investigating,
  title={Investigating Bayesian optimization for expensive-to-evaluate black box functions: Application in fluid dynamics},
  author={Diessner, Mike and O'Connor, Joseph and Wynn, Andrew and Laizet, Sylvain and Guan, Yu and Wilson, Kevin and Whalley, Richard D},
  journal={Frontiers in Applied Mathematics and Statistics},
  volume={8},
  pages={1076296},
  year={2022},
  publisher={Frontiers Media SA}
}

@article{inan2023llama,
  title={Llama guard: Llm-based input-output safeguard for human-ai conversations},
  author={Inan, Hakan and Upasani, Kartikeya and Chi, Jianfeng and Rungta, Rashi and Iyer, Krithika and Mao, Yuning and Tontchev, Michael and Hu, Qing and Fuller, Brian and Testuggine, Davide and others},
  journal={arXiv preprint arXiv:2312.06674},
  year={2023}
}

@article{loh1996latin,
  title={On Latin hypercube sampling},
  author={Loh, Wei-Liem},
  journal={The annals of statistics},
  volume={24},
  number={5},
  pages={2058--2080},
  year={1996},
  publisher={Institute of Mathematical Statistics}
}