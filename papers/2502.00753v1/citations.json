[
  {
    "index": 0,
    "papers": [
      {
        "key": "Zhang2020Why",
        "author": "Jingzhao Zhang and Tianxing He and Suvrit Sra and Ali Jadbabaie",
        "title": "Why Gradient Clipping Accelerates Training: A Theoretical Justification for Adaptivity"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "merity2018regularizing",
        "author": "Stephen Merity and Nitish Shirish Keskar and Richard Socher",
        "title": "Regularizing and Optimizing {LSTM} Language Models"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "mikolov2012statistical",
        "author": "Mikolov, Tom{\\'a}{\\v{s}} and others",
        "title": "Statistical language models based on neural networks"
      },
      {
        "key": "pmlr-v28-pascanu13",
        "author": "Pascanu, Razvan and Mikolov, Tomas and Bengio, Yoshua",
        "title": "On the difficulty of training recurrent neural networks"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "carmon2020lower",
        "author": "Carmon, Yair and Duchi, John C and Hinder, Oliver and Sidford, Aaron",
        "title": "Lower bounds for finding stationary points I"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "pmlr-v202-koloskova23a",
        "author": "Koloskova, Anastasia and Hendrikx, Hadrien and Stich, Sebastian U",
        "title": "Revisiting Gradient Clipping: Stochastic bias and tight convergence guarantees"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "takezawa2024polyak",
        "author": "Takezawa, Yuki and Bao, Han and Sato, Ryoma and Niwa, Kenta and Yamada, Makoto",
        "title": "Parameter-free Clipped Gradient Descent Meets\nPolyak"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "polyak1987introduction",
        "author": "Polyak, Boris T",
        "title": "Introduction to optimization"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "gorbunov2024methods",
        "author": "Gorbunov, Eduard and Tupitsa, Nazarii and Choudhury, Sayantan and Aliev, Alen and Richt{\\'a}rik, Peter and Horv{\\'a}th, Samuel and Tak{\\'a}{\\v{c}}, Martin",
        "title": "Methods for convex {$(L_0,L_1)$}-smooth optimization: Clipping, acceleration, and adaptivity"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "malitsky2020adaptive",
        "author": "Malitsky, Yura and Mishchenko, Konstantin",
        "title": "Adaptive Gradient Descent without Descent"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "gasnikov2018universal",
        "author": "Gasnikov, Alexander Vladimirovich and Nesterov, Yu E",
        "title": "Universal method for stochastic composite optimization problems"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "Zhang2020Why",
        "author": "Jingzhao Zhang and Tianxing He and Suvrit Sra and Ali Jadbabaie",
        "title": "Why Gradient Clipping Accelerates Training: A Theoretical Justification for Adaptivity"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "pmlr-v235-xian24a",
        "author": "Xian, Wenhan and Chen, Ziyi and Huang, Heng",
        "title": "Delving into the Convergence of Generalized Smooth Minimax Optimization"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "hao2024bilevel",
        "author": "Jie Hao and Xiaochuan Gong and Mingrui Liu",
        "title": "Bilevel Optimization under Unbounded Smoothness: A New Algorithm and Convergence Analysis"
      },
      {
        "key": "pmlr-v235-gong24d",
        "author": "Gong, Xiaochuan and Hao, Jie and Liu, Mingrui",
        "title": "A Nearly Optimal Single Loop Algorithm for Stochastic Bilevel Optimization under Unbounded Smoothness"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "zhang2024MOO",
        "author": "Zhang, Qi and Xiao, Peiyao and Ji, Kaiyi and Zou, Shaofeng",
        "title": "On the Convergence of Multi-objective Optimization under Generalized Smoothness"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "crawshaw2022robustness",
        "author": "Crawshaw, Michael and Liu, Mingrui and Orabona, Francesco and Zhang, Wei and Zhuang, Zhenxun",
        "title": "Robustness to unbounded smoothness of generalized signsgd"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "jin2021nonconvexdro",
        "author": "Jin, Jikai and Zhang, Bohang and Wang, Haiyang and Wang, Liwei",
        "title": "Non-convex Distributionally Robust Optimization: Non-asymptotic Analysis"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "vankov2024adaptive",
        "author": "Vankov, Daniil and Nedich, Angelia and Sankar, Lalitha",
        "title": "Generalized Smooth Variational Inequalities: Methods with Adaptive Stepsizes"
      },
      {
        "key": "vankov2024generalized",
        "author": "Vankov, Daniil and Nedich, Angelia and Sankar, Lalitha",
        "title": "Generalized Smooth Stochastic Variational Inequalities: Almost Sure Convergence and Convergence Rates"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "reisizadeh2023variance",
        "author": "Reisizadeh, Amirhossein and Li, Haochuan and Das, Subhro and Jadbabaie, Ali",
        "title": "Variance-reduced clipping for non-convex optimization"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "zhang2020improved",
        "author": "Zhang, Bohang and Jin, Jikai and Fang, Cong and Wang, Liwei",
        "title": "Improved analysis of clipping algorithms for non-convex optimization"
      },
      {
        "key": "pmlr-v130-qian21a",
        "author": "Qian, Jiang and Wu, Yuren and Zhuang, Bojin and Wang, Shaojun and Xiao, Jing",
        "title": " Understanding Gradient Clipping In Incremental Gradient Methods "
      },
      {
        "key": "DBLP:journals/chinaf/ZhaoXL21",
        "author": "Shen{-}Yi Zhao and\nYin{-}Peng Xie and\nWu{-}Jun Li",
        "title": "On the convergence and improvement of stochastic normalized gradient\ndescent"
      },
      {
        "key": "pmlr-v238-hubler24a",
        "author": "H\\\"{u}bler, Florian and Yang, Junchi and Li, Xiang and He, Niao",
        "title": "Parameter-Agnostic Optimization under Relaxed Smoothness"
      },
      {
        "key": "yang2024independently",
        "author": "Yang, Yufeng and Tripp, Erin and Sun, Yifan and Zou, Shaofeng and Zhou, Yi",
        "title": "Independently-Normalized SGD for Generalized-Smooth Nonconvex Optimization"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "khirirat2024error",
        "author": "Khirirat, Sarit and Sadiev, Abdurakhmon and Riabinin, Artem and Gorbunov, Eduard and Richt{\\'a}rik, Peter",
        "title": "Error Feedback under {$(L_0, L_1)$}-Smoothness: Normalization and Momentum"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "Xie2024trustregion",
        "author": "Xie, Chenghan and Li, Chenxi and Zhang, Chuwen and Deng, Qi and Ge, Dongdong and Ye, Yinyu",
        "title": "Trust Region Methods for Nonconvex Stochastic Optimization beyond Lipschitz Smoothness"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "pmlr-v178-faw22a",
        "author": "Faw, Matthew and Tziotis, Isidoros and Caramanis, Constantine and Mokhtari, Aryan and Shakkottai, Sanjay and Ward, Rachel",
        "title": "The Power of Adaptivity in SGD: Self-Tuning Step Sizes with Unbounded Gradients and Affine Variance"
      },
      {
        "key": "pmlr-v195-faw23a",
        "author": "Faw, Matthew and Rout, Litu and Caramanis, Constantine and Shakkottai, Sanjay",
        "title": "Beyond Uniform Smoothness: A Stopped Analysis of Adaptive SGD"
      },
      {
        "key": "pmlr-v195-wang23a",
        "author": "Wang, Bohan and Zhang, Huishuai and Ma, Zhiming and Chen, Wei",
        "title": "Convergence of AdaGrad for Non-convex Objectives: Simple Proofs and Relaxed Assumptions"
      },
      {
        "key": "Li23adam",
        "author": "Li, Haochuan and Rakhlin, Alexander and Jadbabaie, Ali",
        "title": "Convergence of Adam Under Relaxed Assumptions"
      },
      {
        "key": "wang2024provable",
        "author": "Wang, Bohan and Zhang, Yushun and Zhang, Huishuai and Meng, Qi and Sun, Ruoyu and Ma, Zhi-Ming and Liu, Tie-Yan and Luo, Zhi-Quan and Chen, Wei",
        "title": "Provable adaptivity of adam under non-uniform smoothness"
      },
      {
        "key": "zhang2024gs",
        "author": "Qi Zhang and Yi Zhou and Shaofeng Zou",
        "title": "Convergence Guarantees for RMSProp and Adam in Generalized-smooth Non-convex Optimization with Affine Noise Variance"
      }
    ]
  },
  {
    "index": 22,
    "papers": [
      {
        "key": "JMLR:v12:duchi11a",
        "author": "John Duchi and Elad Hazan and Yoram Singer",
        "title": "Adaptive Subgradient Methods for Online Learning and Stochastic Optimization"
      }
    ]
  },
  {
    "index": 23,
    "papers": [
      {
        "key": "hinton2012neural",
        "author": "Hinton, Geoffrey and Srivastava, Nitish and Swersky, Kevin",
        "title": "Neural networks for machine learning lecture 6a overview of mini-batch gradient descent"
      }
    ]
  },
  {
    "index": 24,
    "papers": [
      {
        "key": "kingma15adam",
        "author": "Diederik P. Kingma and Jimmy Ba",
        "title": "Adam: A Method for Stochastic Optimization"
      }
    ]
  },
  {
    "index": 25,
    "papers": [
      {
        "key": "khirirat2024communication",
        "author": "Khirirat, Sarit and Sadiev, Abdurakhmon and Riabinin, Artem and Gorbunov, Eduard and Richt{\\'a}rik, Peter",
        "title": "Communication-efficient Algorithms Under Generalized Smoothness Assumptions"
      },
      {
        "key": "demidovich2024methods",
        "author": "Demidovich, Yury and Ostroukhov, Petr and Malinovsky, Grigory and Horv{\\'a}th, Samuel and Tak{\\'a}{\\v{c}}, Martin and Richt{\\'a}rik, Peter and Gorbunov, Eduard",
        "title": "Methods with Local Steps and Random Reshuffling for Generally Smooth Non-Convex Federated Optimization"
      }
    ]
  },
  {
    "index": 26,
    "papers": [
      {
        "key": "chayti2024metalearning",
        "author": "Chayti, El Mahdi and Jaggi, Martin",
        "title": "A New First-Order Meta-Learning Algorithm with Convergence Guarantees"
      }
    ]
  },
  {
    "index": 27,
    "papers": [
      {
        "key": "chen2023generalized",
        "author": "Chen, Ziyi and Zhou, Yi and Liang, Yingbin and Lu, Zhaosong",
        "title": "Generalized-smooth nonconvex optimization is as efficient as smooth nonconvex optimization"
      }
    ]
  },
  {
    "index": 28,
    "papers": [
      {
        "key": "chen2023generalized",
        "author": "Chen, Ziyi and Zhou, Yi and Liang, Yingbin and Lu, Zhaosong",
        "title": "Generalized-smooth nonconvex optimization is as efficient as smooth nonconvex optimization"
      }
    ]
  },
  {
    "index": 29,
    "papers": [
      {
        "key": "nesterov1984minimization",
        "author": "Nesterov, Yurii",
        "title": "Minimization methods for nonsmooth convex and quasiconvex functions"
      },
      {
        "key": "cortes2006finite",
        "author": "Cort{\\'e}s, Jorge",
        "title": "Finite-time convergent gradient flows with applications to network consensus"
      }
    ]
  },
  {
    "index": 30,
    "papers": [
      {
        "key": "fang2018spider",
        "author": "Fang, Cong and Li, Chris Junchi and Lin, Zhouchen and Zhang, Tong",
        "title": "SPIDER: Near-Optimal Non-Convex Optimization via Stochastic Path-Integrated Differential Estimator"
      }
    ]
  },
  {
    "index": 31,
    "papers": [
      {
        "key": "chen2023generalized",
        "author": "Chen, Ziyi and Zhou, Yi and Liang, Yingbin and Lu, Zhaosong",
        "title": "Generalized-smooth nonconvex optimization is as efficient as smooth nonconvex optimization"
      }
    ]
  },
  {
    "index": 32,
    "papers": [
      {
        "key": "chen2023generalized",
        "author": "Chen, Ziyi and Zhou, Yi and Liang, Yingbin and Lu, Zhaosong",
        "title": "Generalized-smooth nonconvex optimization is as efficient as smooth nonconvex optimization"
      }
    ]
  },
  {
    "index": 33,
    "papers": [
      {
        "key": "chen2023generalized",
        "author": "Chen, Ziyi and Zhou, Yi and Liang, Yingbin and Lu, Zhaosong",
        "title": "Generalized-smooth nonconvex optimization is as efficient as smooth nonconvex optimization"
      }
    ]
  },
  {
    "index": 34,
    "papers": [
      {
        "key": "nesterov1984minimization",
        "author": "Nesterov, Yurii",
        "title": "Minimization methods for nonsmooth convex and quasiconvex functions"
      },
      {
        "key": "cortes2006finite",
        "author": "Cort{\\'e}s, Jorge",
        "title": "Finite-time convergent gradient flows with applications to network consensus"
      }
    ]
  },
  {
    "index": 35,
    "papers": [
      {
        "key": "fang2018spider",
        "author": "Fang, Cong and Li, Chris Junchi and Lin, Zhouchen and Zhang, Tong",
        "title": "SPIDER: Near-Optimal Non-Convex Optimization via Stochastic Path-Integrated Differential Estimator"
      }
    ]
  },
  {
    "index": 36,
    "papers": [
      {
        "key": "chen2023generalized",
        "author": "Chen, Ziyi and Zhou, Yi and Liang, Yingbin and Lu, Zhaosong",
        "title": "Generalized-smooth nonconvex optimization is as efficient as smooth nonconvex optimization"
      },
      {
        "key": "vankov2024optimizing",
        "author": "Vankov, Daniil and Rodomanov, Anton and Nedich, Angelia and Sankar, Lalitha and Stich, Sebastian U",
        "title": "Optimizing {$(L_0, L_1)$}-Smooth Functions by Gradient Methods"
      }
    ]
  },
  {
    "index": 37,
    "papers": [
      {
        "key": "NeurIPS:2024:Jiang",
        "author": "Wei Jiang and Sifan Yang and Wenhao Yang and Lijun Zhang",
        "title": "Efficient Sign-Based Optimization: Accelerating Convergence via Variance Reduction"
      }
    ]
  },
  {
    "index": 38,
    "papers": [
      {
        "key": "chzhen2023signsvrg",
        "author": "Chzhen, Evgenii and Schechtman, Sholom",
        "title": "SignSVRG: fixing SignSGD via variance reduction"
      }
    ]
  },
  {
    "index": 39,
    "papers": [
      {
        "key": "Li2023GS",
        "author": "Li, Haochuan and Qian, Jian and Tian, Yi and Rakhlin, Alexander and Jadbabaie, Ali",
        "title": "Convex and Non-convex Optimization Under Generalized Smoothness"
      }
    ]
  },
  {
    "index": 40,
    "papers": [
      {
        "key": "devlin-etal-2019-bert",
        "author": "Devlin, Jacob  and\nChang, Ming-Wei  and\nLee, Kenton  and\nToutanova, Kristina",
        "title": "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding"
      },
      {
        "key": "caron2021emerging",
        "author": "Caron, Mathilde and Touvron, Hugo and Misra, Ishan and J{\\'e}gou, Herv{\\'e} and Mairal, Julien and Bojanowski, Piotr and Joulin, Armand",
        "title": "Emerging properties in self-supervised vision transformers"
      },
      {
        "key": "radford2021learning",
        "author": "Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others",
        "title": "Learning transferable visual models from natural language supervision"
      }
    ]
  },
  {
    "index": 41,
    "papers": [
      {
        "key": "cooper2024theoretical",
        "author": "Cooper, Y",
        "title": "A theoretical study of the {$(L_0, L_1)$}-smoothness condition in deep learning"
      }
    ]
  },
  {
    "index": 42,
    "papers": [
      {
        "key": "nesterov1983method",
        "author": "Nesterov, Yurii",
        "title": "A method for solving the convex programming problem with convergence rate {$O(1/k^2)$}"
      }
    ]
  },
  {
    "index": 43,
    "papers": [
      {
        "key": "arjevani2023lower",
        "author": "Arjevani, Yossi and Carmon, Yair and Duchi, John C and Foster, Dylan J and Srebro, Nathan and Woodworth, Blake",
        "title": "Lower bounds for non-convex stochastic optimization"
      }
    ]
  },
  {
    "index": 44,
    "papers": [
      {
        "key": "tyurin2024toward",
        "author": "Tyurin, Alexander",
        "title": "Toward a Unified Theory of Gradient Descent under Generalized Smoothness"
      }
    ]
  },
  {
    "index": 45,
    "papers": [
      {
        "key": "Li2023GS",
        "author": "Li, Haochuan and Qian, Jian and Tian, Yi and Rakhlin, Alexander and Jadbabaie, Ali",
        "title": "Convex and Non-convex Optimization Under Generalized Smoothness"
      }
    ]
  },
  {
    "index": 46,
    "papers": [
      {
        "key": "NeurIPS'24:LocalSmooth",
        "author": "Yan-Feng Xie and Peng Zhao and Zhi-Hua Zhou",
        "title": "Gradient-Variation Online Learning under Generalized Smoothness"
      }
    ]
  },
  {
    "index": 47,
    "papers": [
      {
        "key": "nesterov2018lectures",
        "author": "Nesterov, Yurii and others",
        "title": "Lectures on convex optimization"
      }
    ]
  },
  {
    "index": 48,
    "papers": [
      {
        "key": "Bauschke17descentlemma",
        "author": "Bauschke, Heinz H. and Bolte, J\\'{e}r\\^{o}me and Teboulle, Marc",
        "title": "A Descent Lemma Beyond Lipschitz Gradient Continuity: First-Order Methods Revisited and Applications"
      },
      {
        "key": "lu18relativesmooth",
        "author": "Lu, Haihao and Freund, Robert M. and Nesterov, Yurii",
        "title": "Relatively Smooth Convex Optimization by First-Order Methods, and Applications"
      }
    ]
  },
  {
    "index": 49,
    "papers": [
      {
        "key": "mishkin2024directional",
        "author": "Aaron Mishkin and Ahmed Khaled and Yuanhao Wang and Aaron Defazio and Robert M. Gower",
        "title": "Directional Smoothness and Gradient Methods: Convergence and Adaptivity"
      }
    ]
  },
  {
    "index": 50,
    "papers": [
      {
        "key": "sagun2016eigenvalues",
        "author": "Sagun, Levent and Bottou, Leon and LeCun, Yann",
        "title": "Eigenvalues of the hessian in deep learning: Singularity and beyond"
      },
      {
        "key": "pan2022eigencurve",
        "author": "Rui Pan and Haishan Ye and Tong Zhang",
        "title": "Eigencurve: Optimal Learning Rate Schedule for {SGD} on Quadratic Objectives with Skewed Hessian Spectrums"
      }
    ]
  },
  {
    "index": 51,
    "papers": [
      {
        "key": "jiang2024convergence",
        "author": "Jiang, Ruichen and Maladkar, Devyani and Mokhtari, Aryan",
        "title": "Convergence analysis of adaptive gradient methods under refined smoothness and noise assumptions"
      },
      {
        "key": "liu2024adagrad",
        "author": "Liu, Yuxing and Pan, Rui and Zhang, Tong",
        "title": "AdaGrad under Anisotropic Smoothness"
      }
    ]
  }
]