[
  {
    "index": 0,
    "papers": [
      {
        "key": "qing2023surveyexplainablereinforcementlearning",
        "author": "Yunpeng Qing and Shunyu Liu and Jie Song and Huiqiong Wang and Mingli Song",
        "title": "A Survey on Explainable Reinforcement Learning: Concepts, Algorithms, Challenges"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "liu2019lmut",
        "author": "Liu, Guiliang and Schulte, Oliver and Zhu, Wang and Li, Qingcan",
        "title": "Toward interpretable deep reinforcement learning with linear model u-trees"
      },
      {
        "key": "verma2018programmatically",
        "author": "Verma, Abhinav and Murali, Vijayaraghavan and Singh, Rishabh and Kohli, Pushmeet and Chaudhuri, Swarat",
        "title": "Programmatically interpretable reinforcement learning"
      },
      {
        "key": "landajuela2021discovering",
        "author": "Landajuela, Mikel and Petersen, Brenden K and Kim, Sookyung and Santiago, Claudio P and Glatt, Ruben and Mundhenk, Nathan and Pettit, Jacob F and Faissol, Daniel",
        "title": "Discovering symbolic policies with deep reinforcement learning"
      },
      {
        "key": "delfosse2024interpretable",
        "author": "Delfosse, Quentin and Sztwiertnia, Sebastian and Rothermel, Mark and Stammer, Wolfgang and Kersting, Kristian",
        "title": "Interpretable concept bottlenecks to align reinforcement learning agents"
      },
      {
        "key": "payani2020incorporating",
        "author": "Payani, Ali and Fekri, Faramarz",
        "title": "Incorporating relational background knowledge into reinforcement learning via differentiable inductive logic programming"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "zabounidis2023concept",
        "author": "Zabounidis, Renos and Campbell, Joseph and Stepputtis, Simon and Hughes, Dana and Sycara, Katia P",
        "title": "Concept learning for interpretable multi-agent reinforcement learning"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "ye2024conceptbased",
        "author": "Zhuorui Ye and Stephanie Milani and Fei Fang and Geoff Gordon",
        "title": "Concept-Based Interpretable Reinforcement Learning with Limited to No Human Labels"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "yu2023causal",
        "author": "Yu, Zhongwei and Ruan, Jingqing and Xing, Dengpeng",
        "title": "Explainable reinforcement learning via a causal world model"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "boggess2023explainable",
        "author": "Boggess, Kayla and Kraus, Sarit and Feng, Lu",
        "title": "Explainable multi-agent reinforcement learning for temporal queries"
      },
      {
        "key": "hayes2017improving",
        "author": "Hayes, Bradley and Shah, Julie A",
        "title": "Improving robot controller transparency through autonomous policy explanation"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "nikulin2019free",
        "author": "Nikulin, Dmitry and Ianina, Anastasia and Aliev, Vladimir and Nikolenko, Sergey",
        "title": "Free-lunch saliency via attention in atari agents"
      },
      {
        "key": "rizzo2019reinforcement",
        "author": "Rizzo, Stefano Giovanni and Vantini, Giovanna and Chawla, Sanjay",
        "title": "Reinforcement learning with explainability for traffic signal control"
      },
      {
        "key": "joo2019visualization",
        "author": "Joo, Ho-Taek and Kim, Kyung-Joong",
        "title": "Visualization of deep reinforcement learning using grad-CAM: how AI plays atari games?"
      },
      {
        "key": "shi2020self",
        "author": "Shi, Wenjie and Huang, Gao and Song, Shiji and Wang, Zhuoyuan and Lin, Tingyu and Wu, Cheng",
        "title": "Self-supervised discovering of interpretable features for reinforcement learning"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "bau2017network",
        "author": "Bau, David and Zhou, Bolei and Khosla, Aditya and Oliva, Aude and Torralba, Antonio",
        "title": "Network dissection: Quantifying interpretability of deep visual representations"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "kim2018interpretability",
        "author": "Kim, Been and Wattenberg, Martin and Gilmer, Justin and Cai, Carrie and Wexler, James and Viegas, Fernanda and others",
        "title": "Interpretability beyond feature attribution: Quantitative testing with concept activation vectors (tcav)"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "ghorbani2019towards",
        "author": "Ghorbani, Amirata and Wexler, James and Zou, James Y and Kim, Been",
        "title": "Towards automatic concept-based explanations"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "mu2020compositional",
        "author": "Mu, Jesse and Andreas, Jacob",
        "title": "Compositional explanations of neurons"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "xuanyuan2023global",
        "author": "Xuanyuan, Han and Barbiero, Pietro and Georgiev, Dobrik and Magister, Lucie Charlotte and Li{`o}, Pietro",
        "title": "Global concept-based interpretability for graph neural networks via neuron analysis"
      }
    ]
  }
]