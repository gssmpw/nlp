
\subsection{Tasks Description}

The experiment consists of four distinct tasks, in which one participant and a robot collaboratively solve Tangram puzzles. In each task, participants were required to create a unique shape using Tangram pieces. The sequence of shapes to solve is Rocket, Rabbit, Turtle, and Cat. We chose puzzles of similar difficulty to ensure the difficulty would not affect participants’ perception and behaviour towards the robot.

Each Tangram puzzle consisted of seven pieces. The robot handled four pieces (two small triangles, a square, and a parallelogram), while the participant had to place correctly three pieces (a medium-sized triangle and two large triangles). The Tangram pieces were 3D printed, and when assembled, formed a square of $200\,\text{mm}$ in side. Each piece was $20\,\text{mm}$ high. Besides, an cube ($32\,\text{mm} \times 32\,\text{mm} \times 40\,\text{mm}$) was attached on top of each piece to act as a handle and to facilitate the robot's ability to pick up the pieces. The puzzles' silhouettes were printed in black on A2 white paper, slightly larger than the Tangram pieces to avoid the need for very precise placement, with approximately 1 cm clearance on each side. These papers were fixed to the table, and the participant and the robot had to place each of their pieces in the correct position. The participant was asked to move a piece only after the robot had completed its action.

The robot always placed the first piece. To reduce confusion about when the participant should place their piece, the robot said: ``Now it is your turn.'', after placing each piece, except for the last one, when it said: ``Now, let’s solve the next puzzle.'' If the participant placed a piece incorrectly, the robot responded,``You have placed the object in the wrong location.''

The robot's pieces were placed next to the paper and near the robot, as shown in Figure \ref{fig:Robot}. In each puzzle, the arrangement of the pieces varied from the previous one, and the robot first determined the placement and orientation of each piece before picking it up. To facilitate this process, an ArUco marker was attached to the top of each piece, allowing the robot to accurately locate them. The Tiago robot, programmed using ROS1, then utilised the tf library to transform the pose of the desired object to the coordinate frame associated with its arm, and subsequently employed inverse kinematics to move its arm to the correct location. The robot's head movements were pre-programmed to approximately mimic human gaze behaviour. During its turn, the robot maintained its gaze on the Tangram piece while picking it up and placing it. Once the robot finished placing a piece, it started looking at the participant.

