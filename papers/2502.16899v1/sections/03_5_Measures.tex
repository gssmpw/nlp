\subsection{Measures}
\subsubsection{Objective Gaze Measures}\label{gaze_measures}

For each puzzle and each piece, we recorded the robot’s current action— such as moving above the target object, and lowering to pick up the object—along with whether a failure occurred and the type of failure, all based on Unix time. We recorded users’ gaze data during the whole experiment.


Gaze data was collected during the tasks as participants collaborated with the Tiago robot to solve the puzzles. In our experiment, the gaze data during the robot's turn was particularly important, from the moment it started moving until it completed its turn. Data was captured using Neon Eye Tracking Glasses from Pupil Labs. The gaze data included the participant’s field of view image frame along with the x and y coordinates of their gaze within that frame. This data was recorded in real-time on a computer. The gaze data was captured at a rate of 30 Hz for both the image frames and gaze coordinates.


To facilitate the identification of participants' areas of interest (AoIs), we attached ArUco markers near the areas of interest. The AoIs in our experiment included the robot body (comprising the robot's face and torso), the Tangram figure, the end effector, the robot’s pieces, the participant’s pieces, and the experimenter. These areas of interest are illustrated in Figure \ref{fig:Robot}.

%one on the head of the robot, one on the body, one on the end effector, one near the robot pieces’ place on the left side of the task, one on the top of the task, one on the left side of the task, one on the left side of the participant’s pieces, and one on the right side of the participant’s pieces.

% We quantified the proportion of time each area of interest was observed during the task, the total number of gaze shifts, and the total number of shifts towards each area of interest. Utilising the gaze data, we developed transition matrices to facilitate comparative analysis across different conditions \cite{krejtz_gaze_2015, ebeid_analyzing_2019}.


We calculated several gaze-related measures to analyse user behaviour during the interaction. These metrics included: (1) the number of gaze shifts toward the robot body, (2) the number of gaze shifts across all AoIs, (3) the proportional distribution of gaze directed toward the robot body, the Tangram figure, and the robot’s end effector, and (4) transition and stationary entropy derived from gaze transition matrices \cite{krejtz_gaze_2015, ebeid_analyzing_2019}. Each of these measures captures different aspects of gaze behaviour. The number of gaze shifts reflects the frequency of visual transitions between specific areas, providing insight into user engagement and focus dynamics. The proportional distribution of gaze indicates how much time users spent looking at each AoI, offering a measure of relative visual attention. Transition entropy quantifies the unpredictability of gaze transitions between AoIs, while stationary entropy measures the overall distribution of gaze within the AoIs, highlighting how scattered or concentrated the gaze behaviour was during the task.


The gaze measures were calculated during a specific time window for both failure and non-failure conditions: from the moment the robot began moving to pick up an object until it placed the object and returned to its initial position.
%For each puzzle task, the robot correctly placed three of its own pieces and introduced one intentional failure. 
Since failure timing is not applicable in non-failure conditions, the analysis of these measures was conducted in two ways. First, we analysed the data by failure type (no failure, executional failure, decisional failure) and acknowledgement (yes vs. no). Second, we analysed it by failure type (executional failure, decisional failure), timing (early vs. late), and acknowledgement (yes vs. no).


\subsubsection{Subjective Measures}\label{Subjective_Measures}

After each puzzle, participants rated their perceptions of the robot's behaviour in terms of perceived intelligence, perceived safety, and performance trust. Perceived intelligence and safety were measured using items from the Godspeed questionnaire \cite{bartneck_measurement_2009}, while performance trust was assessed using items from the Multi-Dimensional Measure of Trust (MDMT) questionnaire \cite{ullman_mdmt_2023}.

To evaluate the level of intelligence participants attributed to the robot, we used three items from the Godspeed questionnaire: “Incompetent/Competent,” “Irresponsible/Responsible,” and “Foolish/Sensible.” For perceived safety, we included one item from the Godspeed questionnaire: “Anxious/Relaxed.” To assess performance trust across various robot failures, we utilised the “performance trust” dimension from the MDMT. This included two items from the Reliable subscale (“Reliable” and “Predictable”) and two items from the Competent subscale (“Skilled” and “Capable”).

The analysis of these measures was conducted based on failure type (executional failure, decisional failure), timing (early vs. late), and acknowledgement (yes vs. no).

%The items taken from the Godspeed questionnaire are presented as semantic differential 5-point scales, while the items from the MDMT are presented as semantic differential 7-point scales.
\begin{comment}
    
\subsubsection{Perceived Intelligence}

To measure the level of intelligence that participants attribute to our robots, we extracted three items from the Godspeed questionnaire. These items are presented as semantic differential 5-point scales: “Incompetent/Competent,” “Irresponsible/Responsible,” “Foolish/Sensible.”

\subsubsection{Perceived Safety}

To measure the level of safety that participants feel towards our robots, we extracted one item from the Godspeed questionnaire. These item is presented as semantic differential 5-point scales: “Anxious/Relaxed,”

\subsubsection{Trust}

The literature has previously identified trust as a critical factor that can be adversely impacted by robot failures. To assess and compare levels of trust across various robot failures, we utilized the "performance trust" dimension from the MDMT. Additionally, we incorporated two items from the Reliable subscale (“Reliable” and “Predictable”) and two items from the Competent subscale (“Skilled” and “Capable”). All questions were rated using a 7-point Likert scale.


\end{comment}