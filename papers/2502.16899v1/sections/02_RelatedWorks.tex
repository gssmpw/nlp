\section{RELATED WORKS}



 
\subsection{Social Signals to Robot's Failure}

 Social signals have been found to be reliable indicators of errors, as people react to robot errors socially due to their unexpectedness. Specifically, users display more social signals during situations with errors than those without \cite{stiber_using_2023}. Common instinctive responses to robot errors include gaze \cite{kontogiorgos_embodiment_2020, peacock_gaze_2022, kontogiorgos_systematic_2021}, facial expressions \cite{mirnig_impact_2015, stiber_modeling_2022, kontogiorgos_systematic_2021, wachowiak_time_2024}, verbalization \cite{kontogiorgos_embodiment_2020, mirnig_impact_2015, kontogiorgos_systematic_2021}, and body movements \cite{mirnig_impact_2015, trung_head_2017, wachowiak_time_2024}.



%Participants show reaction to failrue to robot failures
Several studies have demonstrated that participants exhibit distinct social signals in response to robot failures. For instance, Aronson et al. \cite{aronson_gaze_2018} observed that participants' gaze patterns deviate from the norm during unexpected robot actions. Wachowiak et al. \cite{wachowiak_analysing_2022} further found that during failures, participants focus more on the entity they are collaborating with, whereas in error-free scenarios, their gaze is more evenly distributed. Similarly, Peacock et al. \cite{peacock_gaze_2022} noted that gaze initially increases in motion during failures and then stabilizes as users recognize and correct the error. Stiber et al. \cite{stiber_using_2023} identified that specific facial muscles, such as those involved in smiling and brow lowering, become more active during robot errors. Kontogiorgos et al. \cite{kontogiorgos_systematic_2021, kontogiorgos_embodiment_2020} found that robot failures lead to increases in spoken words, utterance duration, and gaze shifts towards the robot, indicating heightened engagement during errors. While there is substantial research on human reactions to interacting with a failing robot, there is limited understanding of how this interaction affects the perception of the robot as a teammate in highly collaborative tasks and its impact on human gaze behaviour. This gap is significant, as existing research indicates that individuals exhibit distinct social reactions depending on the type of robot failure encountered \cite{mirnig_impact_2015, kontogiorgos_systematic_2021}.




\subsection{Types of Failure}

 Robot failures can be classified into different types depending on the nature of the issue. Mirnig et al. \cite{mirnig_impact_2015} identified two main types: technical failures, where the robot fails to perform its task correctly, and social norm violations, which occur when the robot deviates from expected social behaviour. 
%Their study highlighted that social norm violations have a more significant impact on participants. 
Honig and Oron-Gilad \cite{honig_understanding_2018} offered a taxonomy distinguishing between (a) technical failures, involving hardware malfunctions and software issues, and (b) interaction failures, arising from uncertainties during interactions with the environment, other agents, or humans. Similarly, Tian et al. \cite{tian_taxonomy_2021} categorised errors into performance errors, which affect perceived intelligence and task competence, and social errors, which impact socio-affective competence. Kontogiorgos et al. \cite{kontogiorgos_embodiment_2020} further classified conversational failures into task-oriented failures, such as incorrect guidance or incomplete instructions, and social protocol violations, like disengagement. Additionally, Morales et al. \cite{morales_interaction_2019} categorised robot failures into Personal Risk Failures (e.g., throwing objects or erratic movements), Property Risk Failures (e.g., dropping or crushing objects), and an Assistance scenario where the robot seeks participant help without posing direct risks.



%Time of failure happening
\subsection{Timing of Failure}
Research has shown that the timing of failures during a task influences people's perceptions of the robot in various ways. Desai et al. \cite{desai_impact_2013} found that early failures significantly reduce trust and make it harder to recover compared to failures occurring later in the interaction. Similarly, Rossi et al. \cite{rossi_how_2017} observed that participants' trust in the robot did not increase when severe mistakes happened early in the interaction. In contrast, Morales et al. \cite{morales_interaction_2019} discovered that the order of failures significantly impacts participants' perceptions, with severe failures occurring last leaving a stronger impression and making participants more likely to believe the robot will fail again in future tasks. Lucas et al. \cite{lucas_getting_2018} also found that early errors can be somewhat recovered from, especially with positive social interaction, but late errors are more damaging. On the other hand, Kontogiorgos et al. \cite{kontogiorgos_systematic_2021} demonstrated that reactions to failures remain consistent, regardless of whether they occur early or late in the interaction. Existing research shows contrasting results regarding the effects of robot failure timing on trust, highlighting the need for further study to understand how failure timing affects user perception of the robot. Furthermore, to the best of the author's knowledge, no research has explored the impacts of failure timing on human gaze behaviour.



%repair ? 
%subsection{Acknowledging Failure vs Repair}
\subsection{Failure Repair}
Previous studies have investigated how different trust repair strategies used by robots influence users' perceptions. For example, LeMasurier et al. \cite{lemasurier_reactive_2024} considered three strategies for explaining failures: 1) The robot only acknowledges its failure, 2) The robot explains what went wrong and why after the failure, and 3) The robot predicts and explains potential failures before they occur. Their results highlight that both explaining and predicting failures enhance users' perceptions of a robot's intelligence and trustworthiness compared to providing no explanation at all.
%Similarly, Karli et al. \cite{karli_what_2023} examined two different approaches to repairing trust after a failure: a promise to improve future performance and an explanation of the reason for the failure. They found that participants who experienced the promise strategy exhibited a greater increase in trust.
In \cite{esterwood_you_2021}, four trust repair approaches (promises, denials, explanations, apologies) were compared during a collaborative robot task. Apologies, explanations, and promises were similarly effective and outperformed denials for the ability measure, while apologies and promises were most effective for benevolence.
%In another study, Kraus et al. \cite{kraus_sorry_2023} examined six trust repair strategies following a failure: acknowledging the error, apologizing, providing an empty explanation, offering a technical explanation, giving an anthropomorphic explanation, and denying responsibility. Their findings indicated that technical explanations and apologies were the most effective for trust recovery. 
Additionally, Wachowiak et al. \cite{wachowiak_when_2024} found that participants preferred apologies most and silence least when a robot made an error.
%Wachowiak et al. \cite{wachowiak_when_2024} aimed to identify the most needed explanations in specific scenarios. They found that when a robot makes an error, participants highly preferred an apology, while continuing without any comments was the least favoured option.
While previous studies have shown that apologies and explanations for failures help people regain trust in the robot, we wonder if this could also affect their social behaviour, specifically their gaze behaviour.


%\\The literature suggests that human gaze behaviour and other social signals provide valuable feedback for detecting and addressing errors in human-robot collaboration. This paper will contribute to this field by 




\subsection{Gaze in HRC}
The gaze behaviour in human-robot collaboration has been studied widely, focusing on both the robot’s gaze behaviour while collaborating with a human and the human’s gaze behaviour while interacting with a robot \cite{srinivasan_survey_2011, admoni_social_2017}. Most studies in human-robot collaboration emphasise the human’s gaze behaviour, as it can indicate human intent and focus, allowing the robot to determine its next move and adapt its behaviour accordingly.  

%Here I talk about Intent
The literature collectively highlights the significant role of gaze in intent recognition. Huang et al. \cite{huang_anticipatory_2016} focused on enabling robots to proactively perform task actions by predicting the task intent of their human partners based on observed gaze patterns. Their anticipatory control method significantly improved task efficiency, allowing the robot to respond faster compared to the reactive method. %Similarly, Gomez Cubero et al. \cite{gomez_cubero_intention_2021} developed an intention recognition algorithm using eye-tracking data in a virtual reality setting, achieving high accuracy two seconds before item selection. 
Additionally, Shi et al. \cite{shi_gazeemd_2021} also developed an effective model for accurately determining which object a person intends to focus on during interactions with a robot. The literature demonstrates that gaze can be a reliable indicator of a person's intent and by extension their anticipation of upcoming actions. This leads us to wonder whether gaze also has the potential to help the robot repair from its failure.
% \\While substantial research exists on human reactions to interacting with a failing robot, there is limited understanding of how these interactions influence the perception of the robot as a teammate in collaborative tasks and their impact on human gaze behaviour. Additionally, there is a gap in understanding how user gaze changes based on the timing of the failure and whether the robot's acknowledgement of the failure affects user gaze. To address these gaps, we define the following research questions:


Despite extensive research on human reactions to robot failures, little is known about how such failures influence perceptions of the robot as a teammate or affect human gaze behavior. Moreover, the impact of failure timing and the robot's acknowledgment on user gaze remains unclear. To explore these gaps, we address the following research questions:

\vspace{0.5em} % Add vertical space here

\begin{itemize}
\item \textbf{RQ1} How does human gaze behaviour change in response to different robot failures during a collaborative task?
%\item \textbf{RQ2} Can gaze patterns be utilized to detect failures in human-robot collaboration?
\vspace{0.5em} % Add vertical space here

\item \textbf{RQ2} How do different robotic failures affect human perception of the robot as a teammate?
\end{itemize}


