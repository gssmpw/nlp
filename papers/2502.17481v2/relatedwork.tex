\section{Related Work}
\subsection{Self-Supervised Learning Methodology for Sleep Assessment with Single-Modal Physiological Signals}

SSL methodologies designed for single-modal physiological signals primarily target sleep-stage classification, focusing predominantly on EEG. BENDR \cite{ref15} incorporates a convolution neural network (CNN)-based module to extract EEG features and a transformer to capture temporal contexts across signals. This model employs contrastive learning by designing output vectors from the CNN-based module and transformer as positive pairs if they correspond to the same time point while treating others as negative pairs. ContraWR \cite{ref16} replaces the standard InfoNCE loss used in contrastive learning with triplet loss, which minimizes and maximizes the distances between positive and negative pairs, respectively. In this framework, negative pairs are defined as the mean of each sample. TS-TCC \cite{ref17} applies two distinct augmentations to the same EEG data and utilizes a temporal contrasting module to enhance similarity between the contexts of identical samples while reducing similarity between different contexts of distinct samples. Similarly, mulEEG \cite{ref18} drops the augmentation methodology of TS-TCC \cite{ref17} but extends it using multiview SSL to improve learning. This approach incorporates EEG signals and spectrograms as input data, leveraging a diverse loss function to extract complementary information across multiple views. NeuroNet \cite{ref19} introduces an integrated approach combining masked-prediction-based SSL with contrastive-learning-based SSL to derive unique and discriminative representations. Employing a masked autoencoder structure, NeuroNet \cite{ref19} performs masked prediction while simultaneously processing two differently sampled vectors through an encoder. The network optimizes learning using the NT-Xent loss for contrastive learning, enhancing its ability to identify meaningful patterns and representations in EEG data.


\subsection{Multimodal Self-Supervised Learning Methodology for Sleep Assessment with Multimodal Physiological Signals}

Several multimodal SSL methodologies have been designed for sleep-stage classification, leveraging multiple physiological signal modalities. MVCC \cite{ref20} incorporates an intra-view temporal contrastive module to extract temporal features within individual modalities and an inter-view consistency contrastive module to ensure coherence across multiple signal modalities. COCOA \cite{ref21} introduces a cross-modality correlation loss to maximize the similarity between representations of different modalities for the same sample while minimizing the similarity between representations of different time intervals within the same modality. This is achieved using an intra-modality discriminator loss, which refines representation quality. CroSSL \cite{ref22} is distinguished by its robust flexibility, particularly in scenarios with missing data. The method employs the VICReg loss to minimize the dissimilarity between representations of different modalities. SleepFM \cite{ref23} adopts a leave-one-out contrastive learning strategy based on the InfoNCE loss and applies it to various sleep-related downstream tasks. MVCC \cite{ref20}, COCOA \cite{ref21}, CroSSL \cite{ref22}, and SleepFM \cite{ref23} represent contrastive-learning-based multimodal SSL methodologies.


\begin{figure*}[!t]
\centering
\includegraphics[width=1\textwidth]{figures/SynthSleepNet.pdf}
\caption{Overall architecture. (A) Training process of the modality-specific backbone, which extracts features from physiological signals for each modality. The pretrained backbone serves as the encoder for SynthSleepNet. (B) Training workflow of SynthSleepNetâ€”a multimodal hybrid self-supervised learning framework. (C) The pretrained SynthSleepNet (excluding the decoder) is applied to three downstream tasks: sleep stage classification, apnea detection, and hypopnea detection.}
\label{fig:figure1}
\end{figure*}