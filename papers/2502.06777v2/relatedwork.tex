\section{Related Work}
\paragraph{Learning in Assortment Optimization.} The data-driven dynamic assortment optimization problem under the MNL choice model, where the seller does not know the problem parameters but can interact with customers repeatedly over $T$ rounds, has been extensively studied in the literature \citep{caro2007dynamic,rusmevichientong2010dynamic,saure2013optimal,agrawal2017thompson,agrawal2019mnl,chen2021optimal,saha2024stop}. 
Notably, for the problem with cardinality constraints, the works of \citet{agrawal2017thompson,agrawal2019mnl} and \citet{chen2018note} have established the $\widetilde{\Theta}(\sqrt{NT})$ minimax optimal regret bound. 
Beyond the basic MNL setting, learning problems involving additional constraints \citep{cheung2017assortment,aznag2021mnl,chen2024re} or under more complex choice models \citep{ou2018multinomial,oh2021multinomial,perivier2022dynamic,lee2024nearly,chen2021dynamic,li2022onlineassortment,zhang2024online} have also been explored during the past few years.

However, most of these results focus on the dynamic learning setting, with \citet{dong2023pasta} as a exception. Specifically, the work by \citet{dong2023pasta} presents the only study on offline assortment optimization problems, where their algorithm relies on the optimal assortment coverage condition on data. 
In contrast, our algorithm requires only a much weaker optimal item coverage, and we prove this condition to be minimal.


\paragraph{Offline Decision-Making and Pessimism Principle.} 
While optimism in the face of uncertainty is a well-established principle to design algorithms for various online learning problems, including the online assortment optimization problem, offline learning presents a different paradigm where pessimistic or conservative methods \citep{yu2020mopo,kumar2020conservative} have shown more effectiveness in terms of data efficiency and requirement. 
A line of recent works \citep{jin2021pessimism,rashidinejad2021bridging,xie2021bellman,uehara2021pessimistic,zhong2022pessimistic,zhan2022offline,liu2022welfare,shi2022pessimistic,lu2023pessimism,xiong2023nearly,rashidinejad2023optimal, blanchet2024double} theoretically demonstrates that in offline data-driven decision making, pessimistic algorithms achieve provable efficiency while only requiring good coverage of (the trajectories induced by) the optimal decision policy. 
Unfortunately, the settings addressed in all these results are not applicable to the MNL choice feedback in assortment optimization problems we consider here.