In our experiments, we investigate the effectiveness of target selection methods in identifying worthwhile targets for directed fuzzers. For this, we treat target selection as an information retrieval problem and compile a dataset from the source code and tracebacks of various crashes we reproduced from the \ossfuzz{} project.

\boldpar{False positives}
Underlying our analysis is the assumption that a target which is part of a crash's traceback would also have constituted a valuable target for a directed fuzzer. However, there is a semantic gap between a target's occurrence in a traceback and its value for a directed fuzzer, i.e., how well it aids in triggering the root cause of a crash. It is possible that in some scenarios the root cause of the crash is not part of the traceback, for example, in case of intricate data-dependencies which have to be met or for multi-threaded or multi-process applications. As we resort to the traceback for our label source, this could lead to false positive labels in our dataset. Yet, previous work has shown that using the traceback of crashes as targets for a directed fuzzer does in fact reduce the time to expose the crashes compared to an undirected fuzzing approach \cite{CheXueLiChe+18, DuLiLiuMao+22, BoePhaNguRoy17}. This indicates that the traceback is indeed a good approximation of the crash's root cause for this application.

\boldpar{False negatives}
As the ground truth for our evaluation, we resort to crashes found by the \ossfuzz{} project. This poses the risk of missing crashes that have not yet been identified by the project. In particular, individual targets could be erroneously assigned as not being involved in any crash, when in fact the respective crash has just not yet been found by the fuzzers (i.e., a false negative). While this could potentially lead to an underestimation of the actual scoring quality of the target selection methods, the fact that \ossfuzz{} continuously fuzzes each project with >200 cores per project on average\footnote{as of March 2021} alleviates this risk.

\boldpar{Target granularity}
In our experiments, we focus on function level target granularity. While some selection methods and our ground-truth information from the tracebacks would have allowed for a more fine-grained evaluation, for example on line level, this would have excluded several of the other methods. We thus adopted a meet-in-the-middle approach on function level which allows for all target selection methods to be compared to one other while still offering a fine enough granularity to be useful for directed fuzzing. This is shown by the fact that most publications from our literature analysis in Section \ref{sec:localization}, which introduce a new target selection method, use a function level granularity \cite{CaoHeSunOuy+23, ZhaLiaXiaZha+22, ZheZhaHuaRen+23, DuCheLiGuo+19, KruGriRos22}.