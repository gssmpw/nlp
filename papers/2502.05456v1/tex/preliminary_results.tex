\section{Research Progress}

Our preliminary framework addresses key components of the input refinement process, specifically in \textbf{P1.1} (Input Validation for Code-based Encoder Models), \textbf{P2.1} (Input Transformation for Code Data), and \textbf{P3} (Optimal Search via Adaptation by Evolutionary Search). Results from this framework have been accepted at ICSE 2025~\cite{rathnasuriya2025codeimprove}.

%Our preliminary framework addresses key components of the input refinement process by solving for \textbf{P1.1} (Input Validation for Code-based Encoder Models), \textbf{P2.1} (Input Transformation for Code Data), and \textbf{P3} (Optimal Search via Adaptation by Evolutionary Search). The results of this framework have been accepted at ICSE’25. 

\textbf{P1.1} introduces a novel layerwise validation approach tailored for encoder architectures, addressing limitations of traditional uncertainty metrics~\cite{guo2017calibration,wang2020dissector,hendrycks2018baseline,gal2016dropout, alon2019code2vec,xiao2019quantifying,vasudevan2019towards,corbiere2019addressing, monarch2021human, steinhardt2016unsupervised,shannon1948mathematical} with structured, discrete data like code. We developed a Dropout-Based Sub-model Generation (DSMG) technique to capture layerwise processing of nuanced structural elements that includes variable dependencies and control flow. This enhances uncertainty estimation, enabling more accurate classification of out-of-scope inputs.

%\textbf{P1.1} focuses on identifying out-of-scope inputs by introducing a novel, layer-sensitive validation approach specific to encoder architectures. Traditional uncertainty metrics often fall short with structured, discrete data like code. To address this, our method employs a set of sub-models that capture layer-wise dynamics across the encoder, isolating inconsistencies in the representation of out-of-scope inputs. We developed a novel, Dropout-Based Sub-model Generation (DSMG) technique to examine layer-specific processing, this approach detects nuanced structural elements such as variable dependencies and control flow, improving uncertainty estimation and enabling more accurate classification of input scope. 

\textbf{P2.1} applies semantic-preserving transformations to align out-of-scope code inputs with the model’s learned representations without altering functional intent. Transformations include restructuring and reordering statements to maintain operational meaning while improving compatibility with the model’s processing. Our framework includes 15 semantic-preserving code transformation operators. 

%\textbf{P2.1} applies semantic-preserving transformations to out-of-scope inputs, aligning them with the model’s learned representations without altering functional intent. For code data, these transformations include restructuring or reordering code statements in ways that maintain their operational meaning, enhancing compatibility with the model’s internal processing. 

\textbf{P3} utilizes an Adaptation by Evolutionary Search (AES) strategy to iteratively identify the best possible refinement for each out-of-scope inputs by applying a sequence of semantic-preserving transformations and sampling adjustments guided by DSMG validity scores. AES enables the dynamic evolution of out-of-scope inputs into compatible forms at inference time, thereby improving the model's performance without retraining.

%For \textbf{P3}, my work utilizes an Adaptation by Evolutionary Search (AES) strategy to iteratively identify the best possible refinement for each out-of-scope input. Guided by DSMG-based validity scores, AES applies a sequence of semantic transformations and sampling adjustments, evolving flagged inputs into in-scope forms that the model can reliably process. This adaptive search strategy allows for dynamic refinement at inference, ensuring robust model performance without the need for retraining.

The experimental evaluation of this proposed framework is conducted on encoder models, specifically CodeBERT~\cite{fengCodeBERTPreTrainedModel2020}, RoBERTa~\cite{Liu2019RoBERTa}, and GraphCodeBERT~\cite{guo2021graphcodebert} . The research assess  effectiveness across various software engineering tasks, focusing on classification tasks (vulnerability detection and defect prediction). For each task, the research use well-established datasets such as devign dataset ~\cite{zhou2019devign} for vulnerability detection and CodeChef dataset~\cite{phan2017conv} for defect prediction. 

%My approach is evaluated based on specific research questions (RQs) to examine its impact on model performance, out-of-scope data detection, input refinement effectiveness (only using semantic preserving code transformations), and overall efficiency. The results of this framework have been accepted at ICSE’25.

\subsection{Overall Performance}
This proposed work is compared with Input-Reflector~\cite{xiao2022repairing}, a similar technique to used to repair failure inducing inputs in image data. I adapted Input-Reflector to code domain. Notably, the findings include: (1) This work achieved the best model improvement ranging upto 8.78\% in accuracy, 8.48\% in precision,
16.9\% in recall, and 13.5\% in F1-score on all the subjects; (2) My work is successfully capable of correcting around 23.1\% to 39.9\% of the mispredicted inputs on both vulnerability detection and defect prediction tasks; (3) Input-Reflector cannot be applied to code data. Our results indicate that Input-Reflector negatively impacts the model performance for the CodeBERT model on both vulnerability detection and defect prediction tasks; (4) The negative impact of this framework is minimal. At most, this framework will only mispredict 2.6\% of the correct predictions to become mispredictions. 

\subsection{Effectiveness of Input Validation}
\label{validation_results}

This frameworks’s DSMG is compared with the
Cross-Layer Dissection (CLD)~\cite{wang2020dissector}. Additionally, I evaluated the DSMG approach with the uncertainty metrics: vanilla~\cite{hendrycks2018baseline}, temperature scaling~\cite{guo2017calibration}, predictive entropy~\cite{steinhardt2016unsupervised,shannon1948mathematical}, entropy~\cite{steinhardt2016unsupervised,shannon1948mathematical}, mutual information~\cite{steinhardt2016unsupervised,shannon1948mathematical}, least confidence~\cite{monarch2021human}, ratio confidence~\cite{monarch2021human}, and margin confidence~\cite{monarch2021human}, monte-carlo dropout~\cite{gal2016dropout}, and deep ensemble~\cite{lakshminarayanan2017simple}. 

Based on the results, the findings include: (1) DSMG achieved higher AUC scores across all models and tasks (i.e., AUC 0.781- 0.924) compared to uncertainty metrics which achieved an AUC score of 0.624; (2) The Correction validation rate (CVR), i.e., the successfully validated misprediction on DSMG is higher than all other baselines. Moreover, DSMG can detect 70.4\% of the out-of-scope inputs for the CodeBERT model on vulnerability detection tasks; (3) The Mis-correction validation rate (MVR), i.e., correct predictions validated
as mispredictions on DSMG is lower than other approaches, concluding that DSMG is better
at differentiating in-scope inputs. MVR for defect prediction task shows 3.0\%, 3.1\%, and 3.3\% for CodeBERT, RoBERTa, and GraphCodeBERT models; (4) other uncertainty metrics did not produce promising results on AUC, CVR, or MVR. For example, predictive entropy obtained a CVR of 43.5\% and an MVR of 35.3\%, which are not significant indicators of effective performance.

\subsection{Effectiveness of Search Strategies}
The proposed AES algorithm is compared with  two search strategies; namely random search (Rand)~\cite{zabinsky2009random} that applies random transformations until identifying the optimal candidate and Hill climbing (HC) algorithm~\cite{selman2006hill}. 

AES algorithm achieved the highest accuracy across all evaluated tasks, with improvements of up to 8.78\%, outperforming both Rand and HC, which showed gains of only up to 2.13\%. While Rand and HC improve model performance, their search algorithms are limited by early stopping at local minima. These algorithms terminate as soon as they identify an improved candidate, whereas AES continues evolving candidates over multiple generations to achieve the best possible outcome. 

\subsection{Semantic Integrety and Overhead}
The proposed framework’s refinement techniques are specifically designed to maintain the semantic integrity of code inputs. In evaluations, the transformations consistently preserve original code functionality, a key advantage over alternative methods, which may alter functionality. 

The proposed framework also achieves competitive runtime efficiency, with transformation rates (TPS) between 1.2 and 2.04 TPS. Online adaptation times per input range from 49.92 to 59.4 seconds, demonstrating manageable overheads for practical deployment. Moreover, this framework is more efficient and offers a practical, scalable solution to enhance model performance without the significant cost and time investment required by traditional methods such as retraining and model replacement.


\section{Timeline for completion}
I plan to complete the \textbf{P1.2, P2.3} along with \textbf{P3} of this project—refining inputs specifically for generative tasks—by January 2025. Following this, I will incorporate \textbf{P2.2}, with an expected completion by February 2025. By the end of March 2025, my goal is to complete \textbf{P1.3}.

For the current framework, I will focus on expanding transformation rules, reducing transformation times, and refining the validation metric, with the goal of finalizing the complete framework by March 2025. My primary aim is to submit several papers to top-tier conferences throughout this period. Once these project phases are completed, I plan to finish writing my dissertation and aim to defend my doctoral thesis by December 2025.


%I plan to complete the second phase of this project on refining inputs for generative tasks by January 2025. This phase incudes adopting the DSMG validation metric towards decoder-only models and incorporating sampling techniques to input refinement search. Meanwhile I will incorporate both encoder-only model's technique and decoder-only model's technique to input refinement for encoder-decoder only models. This step is expected to complete by February 2025. Also, for my current approach, I will work on adding more transformation rules, minimizing transformation times, and improve the validation metric. All of this framework is planned for complete by March 2025. The goal is to submit several Top Tier conference publications. Once I complete these tasks, my plan is to finish writing the dissertation and defend my doctoral thesis by December 2025.










