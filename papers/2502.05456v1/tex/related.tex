\section{Related Work}
\label{related}
%Our work in this paper provides a method to improve deep code models' ability to deal with shifted code data without retraining deployed models, through program transformation techniques. Therefore, this section will briefly introduce some recent representative work in these fields, including code transformation, input validation and input adaptation. 
%\vspace{-1em}
\textbf{Input Validation for Deep Learning Model.} %As deep learning models are deployed in many critical scenarios, several works have been proposed to check if the model can correctly process given input, i.e. compute the trustworthiness of a result predicted by a deployed DNN.
Several work has been proposed to compute the trustworthiness of a DL model. Hendrycks et. al~\cite{hendrycks2018baseline} propose a baseline for detecting misclassified samples. \cite{guo2017calibration} propose re-calibration of probabilities on a held-out validation set. \cite{wang2020dissector} proposed Dissector, to validate inputs by crossing-layer dissection. 
\cite{xiao2021selfchecking} proposed SelfChecker by leveraging Kernel Density Estimation(KDE)\cite{terrell1992variable}. ConfidNet\cite{corbiere2019addressing} is designed to learn the confidence criterion using True Class Probability for predicting failures. InputReflector \cite{xiao2022repairing} identifies failure-inducing inputs on Image data. In addition to the aforementioned techniques on code data, we show that existing uncertainty metrics~\cite{guo2017calibration,wang2020dissector,hendrycks2018baseline, li2021estimating, alon2019code2vec, vasudevan2019towards,corbiere2019addressing} do not perform promising results on code data.  


   

%which leverages the maximum value of the softmax layer outputs as the uncertainty score. \cite{guo2017calibration} propose re-calibration of probabilities on a held-out validation set through Temp Scale. Recently, \cite{wang2020dissector} proposed DISSECTOR, which trains several submodels on top of the pre-trained model, and leverages internal classification results result to validate a given input.  \cite{xiao2021selfchecking} proposed SelfChecker, which validates inputs using Kernel Density Estimation(KDE)\cite{terrell1992variable}. SelfChecker triggers an alarm if the internal layer features of the model are inconsistent with the final prediction, and achieves better performance than DISSECTOR. \cite{corbiere2019addressing} introduce a novel confidence model called ConfidNet, which is built upon the pre-trained model, designed to learn the confidence criterion using True Class Probability for predicting failures. However, it suffers from overfitting problems since trained on a dataset has few wrong predictions. \cite{xiao2022repairing} proposed InputReflector, which identifies failure-inducing by computing the distance between input and the nearest sample in the training set through an embedding in the siamese network. Although InputReflector can outperform DISSECTOR and SelfChecker on the image classification tasks, like other distance-based input validation methods, it can not effectively deal with the code data shifts problem since pre-trained models give unbelievable embedding when processing shifted code data, making the distance computing not effective. In addition to the aforementioned techniques, we show that existing uncertainty metrics~\cite{guo2017calibration,wang2020dissector,hendrycks2018baseline, li2021estimating, alon2019code2vec, vasudevan2019towards,corbiere2019addressing} do not perform promising results on code data. 

\textbf{Related Work on Code Inputs.} 
Several techniques\cite{zhang2020generating,yefet2020adversarial, naturalattack, carrot,srikant2021generating} for generating adversarial code to challenge these models have been proposed in recent years. Tian et al.\cite{tian2023code} claim they designed a code-difference-guided generation technique, which can improve the efficiency further. CodeDenoise\cite{tian2023fly} is the most advanced technique to improve the performance of deployed models without retraining, however, it can only relieve the noise introduced by different identifier names and consequential mispredictions. In contrast, CodeImprove leverages 15 unique transformation operators. To the best of our knowledge, CodeImprove is the first attempt to use the inference-time program transformation technique to enhance the performance of code models 

%CodeDenoise~\cite{tian2023fly} that aims adapt program inputs through de noising the variable names. However, the validation phase requires more sample generation and renaming a variable will only change the model's understanding on the variable, not the semantics. In contrast, our work can solve the code shift problem by adding new transformation rules and be more efficient since we do not need more model finetuning Our work more focused on code structures by employing both structure and identifier based transformations. Our work does not aim at generating adversarial samples because their primary goal is to confuse the model's predictions. 


%However, adversarial training-based techniques can not solve the problem of code shifts and need additional model training. In contrast, our work can solve the code shift problem by adding new transformation rules and be more efficient since we do not need more model finetuning.

%Since an increasing number of studies have made progress in processing code with deep learning methods\cite{zhang2019astnn, alon2019code2vec, fengCodeBERTPreTrainedModel2020,guo2021graphcodebert,wang2021codet5}, several techniques\cite{zhang2020generating,yefet2020adversarial, naturalattack, carrot,srikant2021generating} for generating adversarial code to challenge these models have been proposed in recent years. Yefet et al.\cite{yefet2020adversarial} propose generating adversarial examples by gradient-guided local variables replacing. But it only works on the models using one-hot encoding, thus cannot generate adversarial examples for models using BPE encoding such as CodeBERT\cite{fengCodeBERTPreTrainedModel2020}, GraphCodeBERT\cite{guo2021graphcodebert} and CodeT5\cite{wang2021codet5}. Furthermore, Srikant et al.\cite{srikant2021generating} model adversarial examples generation as a joint optimization problem and apply PGD to solve it. Zhang et al.\cite{zhang2020generating} proposed MHM, a Metropolis-Hastings algorithm-based technique which renames identifiers iteratively. Recently, Yang et al.\cite{naturalattack} claimed the neglect of code naturalness in attack examples generated by existing methods and proposed a naturalness-aware attack technique ALERT. Zhang et al.\cite{carrot} proposed CARROT, which uses the hill-climbing algorithm with the guidance of gradients to apply designed program transformation rules more efficiently and effectively. Tian et al.\cite{tian2023code} claim they designed a code-difference-guided generation technique, which can improve the efficiency further. However, adversarial training-based techniques can not solve the problem of code shifts and need additional model training. In contrast, our work can solve the code shift problem by adding new transformation rules and be more efficient since we do not need more model finetuning. }


%oopsla
%\textbf{Leveraging Code Models with SE Tasks.}In recent years, researchers have explored various techniques in the intersection of software engineering with DL code model~\cite{alon2019code2vec, bui2021infercode,hoang2020cc2vec,li2019deepfl,lou2021boosting, wang2020reinforcement,wei2022free,zeng2021deep,zhang2018deeproad,zhou2020deepbillboard, lu2021codexglue,degiovanni2022mubert,fu2022vulrepair,chen2020software,xia2022practical,zhang2022coditt5,liu2020multi,nijkamp2023codegen,le2022coderl,xu2022systematic,rozi√®re2023code,brockschmidt2018generative}. Various program related tasks such as clone detection, defect detection, vulnerability prediction, code search, code generation etc. combine machine learning to leverage deep code models to solve these tasks. For instance, ~\cite{yang2022natural} are the first to highlight the naturalness requirement in generating adversarial examples for models of code. ~\cite{alon2019code2vec} generated distributed representations of code using neural network techniques. InferCode proposed in ~\cite{bui2021infercode} learns program representations from the program ASTs. ~\cite{carrot} proposes a framework CARROT for robustness detection, measurement, and enhancement of DL models for source code processing. CodeXGLUE~\cite{lu2021codexglue} with its leaderboard mainly presents a benchmark for various SE tasks and evaluates baselines with limited analytical results and hardly evaluates all studied models simultaneously on universal benchmarks. Our work, as a task-transparent algorithm, can be used to enhance the performance of all kinds of code-as-input models when dealing with shifted inputs, without additional settings needed, showing its great potential in practical use.
%\textbf{Robustness of Deep Code Models.} Since an increasing number of studies have made progress in processing code with deep learning methods\cite{zhang2019astnn, alon2019code2vec, fengCodeBERTPreTrainedModel2020,guo2021graphcodebert,wang2021codet5}, the robustness problems of such code models also came into researchers' vision. Towards higher robustness, the most well-studied approach is adversarial training. 

%\textbf{Model Trustworthiness Measurement.}



%\textbf{Program Transformation} Program transformation is an important technique for automated software engineering tasks which can be classified into two categories: semantic preserving code transformation and semantic-not-preserving transformations (also known as code mutation). Code mutation is widely applied in mutation testing, which involves introducing faults (mutations) through semantic-not-preserving transformations to test if the testing process can detect them. Numerous mutation techniques such as MuJava\cite{ma2005mujava}, Javalanche\cite{schuler2009javalanche}, Major\cite{just2014major}, and PIT\cite{coles2016pit} have been introduced. In contrast, semantic preserving code transformation generates semantic equivalence between the original code and the transformed code. \cite{Zhang2023Challenging} proposed an approach using code transformation techniques to generate adversarial samples for the adversarial attacks on clone detection models.  \cite{yuDataAugmentationProgram2022} leveraged code transformation as a method of data augmentation, which can automatically generate labelled data that can be used to enlarge the training data sets for supervised learning code models. \textcolor{red}{CodeDenoise\cite{tian2023fly} is the most advanced technique to improve the performance of deployed models without retraining, however, it can only relieve the noise introduced by different identifier names and consequential mispredictions. In contrast, CodeImprove leverages 15 kinds of unique transformation operators, through which it can solve data shift problems and gain better extensibility by developing more transformation rules. To the best of our knowledge, CodeImprove is the first attempt to use the inference-time program transformation technique to enhance the performance of code models.}
%\vspace{-1em}