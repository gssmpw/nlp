\textbf{Story}

Improving code analysis tool. Two options: improving the tools or adapting the inputs. \\

These code analysis suffer from performance issues that is mispredictions that negatively affects the software quality.  There are two approaches to improve the performance of code analysis tools: improving the tools or adapting the inputs. 



Related work focus on tools based on symbolic reasoning but not AI-driven tools. (ICSE 20, oakland 18).
It’s more costly to revise AI-driven tool than symbolic reasoning tool. (symbolic: adding huristics or rules, but AI tools needs retraining, expensive data and retraining process, potential alignment after retraining) \textcolor{red}{second para from ISSTA)\\
In this work, we investigate the potential of improving the learning-based code analysis tool by adapting the inputs. 
Two steps…. First, identifying inputs that are out-of-scope, second correcting these out-of-scope inputs to become in-scope inputs without breaking the meaning of the program (semantic preserving) \\

challenging… (get from the ISSTA)

we need to improve's tools performance. Improving tool is costly (no matter AI-driven or non AI driven). Eg. Improve the tool for some data but other data performance issue. Find a reason to show cost. 

second paragraph AI tools are more costly. Fundamental, no perfect ai model. there is some data that model can handle. to make these data there are things we need to do (retrain, pruning), for third, it may work for other data. 

then people find to adapt the input to the tool. Can achieve the same purpose but easier to adapt the tool. 


input adaptation, knowing which input is to adapt (information theory). try to see a pattern, because 






\textbf{Problem}

Problem: Given a code model M and an input S we aim to develop a systematic method called CodeImprove for determining whether the code
model will validate the test instance and adapt the out-of-scope test instance to become an in-scope instance. There can be two critical questions to answer. 1) Whether the model is capable of identifying the input is able to validate the input.This can be answered by  2) Once an input is validated, how can we adapt these out-of-scope inputs to become in-scope inputs. This question is answered by leveraging search-based method to identify code semantics and transform these semantics while preserving. 

Problem->solution: validation -> Oracle problem: discrete or continuous. We need to have a continuous oracle to guide our transformation. Add some oracle baseline in addition to uncertainty;
Our approach: Sub-model construction (sparsity related)
Transformation -> search:  different commonly used search algorithms including genetic algorithms. Baseline on other searching algorithm. A*, mcts, multi-arm bandit.




TODOs: 

High priority: Build the website. 

1. Implement dropout as uncertainty

2. Try different hyper-parameters for dropout. 
3.Activate dropout in the inference. Apply dropout in previous layers too. 

4. Try different hyper-parameters for sub-models 

5. actual value distribution of correctly classified and mispredicted examples. 


