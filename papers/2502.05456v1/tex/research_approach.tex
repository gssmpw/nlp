\section{Research Overview}

Figure~\ref{fig:Overview} provides an overview of the proposed framework, which addresses the ongoing challenge of mispredictions in deep learning models across code, natural language processing (NLP), and image-based tasks. This framework introduces three key phases: \textbf{input validation (P1), input transformation (P2)}, and \textbf{optimal search strategy (P3)} to improve model performance during inference, thereby reducing dependency on costly retraining. Each phase employs distinct mechanisms tailored to different data domains, making the approach both adaptable and comprehensive.

%%%Figure~\ref{fig:Overview}  provides an overview of my proposed research. This research proposes a novel framework to address the persistent challenge of mispredictions in deep learning models, particularly in the nuanced environments of code, natural language processing (NLP), and image-based tasks. The framework leverages input validation \textbf{(P1)}, transformation \textbf{(P2)}, and an adaptive search strategy \textbf{(P3)} to improve the model performance at inference, reducing dependency on retraining. Each phase contributes a distinct mechanism to improve model reliability across different data domains, making this approach both comprehensive and flexible.

\textbf{P1: Input Validation.} The objective of \textbf{(P1)} is to identify inputs likely to produce unreliable predictions (out-of-scope inputs), even if they fall within the model's training distribution. To accommodate the unique characteristics of various model architectures, this phase is organized into three sub-phases: validations for encoder models \textbf{(P1.1)}, decoder models \textbf{(P1.2)}, and encoder-decoder models \textbf{(P1.3)}.

%\textbf{P1: Input Validation.} The goal of \textbf{(P1)} is to identify inputs that may lead to unreliable predictions (i.e., out-of-scope), even if they align with the model’s learned data distribution. This phase is designed to address the unique characteristics of various model architectures, employing specialized techniques for each type. Input Validation is structured into three sub-phases:  approaches for encoder models \textbf{(P1.1)}, decoder models \textbf{(P1.2)}, and encoder-decoder models \textbf{(P1.3)}.

 The \textbf{P1.1} sub-phase applies a set of sub-models to assess input consistency through variance and distance metrics within data representations. By generating slightly varied sub-models, this approach evaluates how an input propagates across layers, examining consistency in token representation and feature extraction. In addition, a distance-based metric is employed to assess the coherence of token propagation, identifying anomalies that may signal out-of-scope inputs. Through these variance and distance-based metrics, encoder models gain an enhanced capacity to detect inputs that introduce discrepancies in hidden state representations, thereby improving validation.
 
 %%For \textbf{P1.1}, input validation utilizes a set of sub-models that analyze variance and distance metrics within the data representation. By generating sub-models with slight variations, this approach can examine how consistently an input propagates through each layer, detecting potential discrepancies in token representation or syntactic structure. Additionally, a distance-based approach can be applied to assess the coherence of token propagation, identifying anomalies in the encoded representation that might signal an out-of-scope input. This variance and distance-based validation approach allows encoder models to flag inputs that introduce inconsistencies in foundational representations. 

 The \textbf{P1.2} sub-phase where the primary task involves generating sequences or predictions, the validation process focuses on identifying inconsistencies in output generation. This sub-phase uses sampling techniques to evaluate how each generated sequence or prediction changes across layers. By measuring the variance of generated outputs and detecting unexpected deviations, this method flags inputs that are prone to lead to unstable or incorrect generations. Sampling-based validation allows for early detection of inconsistencies in the decoding process, ensuring each generated output remains stable and aligned with intended meanings.

 % In \textbf{P1.2}, where the primary task often involves generating sequences or predictions, validation is focused on identifying inconsistencies in output generation. To accomplish this, validation checks how each generated sequence or prediction varies across layers, employing sampling techniques to evaluate consistency at each stage. By measuring the variance of generated outputs and identifying unexpected deviations, this sub-phase can highlight inputs that are likely to lead to unstable or incorrect generation. Sampling-based approaches allow the model to detect generation inconsistencies early in the decoding process, ensuring that each generated output remains stable and aligned with the intended meaning. 

The \textbf{P1.3} sub-phase combines elements from both \textbf{P1.1} and \textbf{P1.2} to provide a comprehensive validation framework. This integration enables consistency checks across both encoding and decoding stages, tracking how encoded representations are transformed during decoding. By merging validation techniques from encoder and decoder models, this approach effectively detects inputs that could cause conflicts between encoding and decoding interpretations, thereby improving the robustness of validation in complex architectures.

%%%For \textbf{P1.3}, validation integrates checks across both \textbf{P1.2} and \textbf{P1.2} to provide a comprehensive assessment of each input’s validation. This sub-phase incorporates consistency evaluations in both the encoding and decoding layers, tracking how encoded representations are transformed during decoding. By combining the strengths of both \textbf{P1.1} and \textbf{P1.2} validation techniques, this approach improves the model’s ability to detect inputs that introduce conflicts between encoding and decoding interpretations, resulting in more robust validation for complex architectures.

   
\textbf{P2: Input Transformation.}  The \textbf{P2} addresses inputs flagged as out-of-scope during validation by applying targeted transformations to align these inputs more closely with the model’s handling capabilities. This phase is divided into two main categories based on data type: \textbf{Discrete Data Transformation (Code (P2.1)} and \textbf{Text (P2.2)}) and \textbf{Continuous Data Transformation (P2.3)}. Each category is designed to preserve the input’s original meaning or function while making adjustments to reduce interpretive inconsistencies. Tailoring transformations to each data type ensures that inputs are modified in ways that manage complexity without altering essential content.

%addresses inputs that are identified as out-of-scope  during validation by applying targeted transformations to better align these inputs with the model’s handling capability. This phase is divided into two main categories based on data type: Discrete Data Transformation (\textbf{P2.1} and \textbf{P2.2}) and Continuous Data Transformation (\textbf{P2.3}). Each category is designed to preserve the input’s original meaning or function while adjusting it to reduce interpretive inconsistencies. By tailoring transformations to each data type, this phase ensures that inputs are transformed in ways that mitigate their complexity without altering their essential content.

Discrete Data Transformation includes structured data like code and text, where maintaining original meaning and functionality is crucial. This transformation uses specific techniques to make minor adjustments that reduce interpretive challenges without changing the intended purpose of the data.

%%Discrete data includes structured information like code and text, where maintaining the original meaning or functionality is critical. For both data types, transformation techniques ensure that minor modifications reduce interpretive challenges without altering the data’s intended purpose.

For \textbf{P2.1} sub-phase focuses on semantic-equivalent transformations and latent space adjustments. Semantic-equivalent transformations modify code syntax or structure while preserving its functionality, helping to clarify complex or ambiguous constructs. For instance, a conditional loop could be refactored into a functional equivalent, or redundant sections could be simplified for improved clarity. Additionally, latent space transformations adjust the encoded representation of code, enabling the model to interpret structural nuances more effectively. Together, these transformations ensure that code inputs align with the model’s learned patterns, reducing the risk of misinterpretation due to syntactic variability.

%For \textbf{P2.1} refinement focuses on semantic-equivalent transformations and adjustments in the latent space. Semantic-equivalent transformations apply modifications that preserve the code’s functionality but alter its syntax or structure, which can help clarify complex or ambiguous constructs. For example, a conditional loop could be refactored into a functional equivalent, or redundant code could be simplified to improve clarity. Additionally, latent space transformations adjust the encoded representation of code, enabling the model to better interpret structural nuances. These transformations ensure that code inputs remain aligned with the model’s learned patterns, minimizing the chance of misinterpretation due to syntactic variability.

In \textbf{P2.2}  sub-phase applies techniques such as synonym replacement and text rephrasing with large language models (LLMs). Synonym replacement changes specific words within the text to reduce ambiguity or simplify language without altering the overall meaning. For instance, in a sentiment analysis task, “joyful” might replace “happy” to match the model’s vocabulary. Additionally, LLM-based rephrasing enables comprehensive sentence or phrase rewording to standardize informal or complex language. For example, “I’m over the moon about this product” could be rephrased to “I’m extremely happy with this product,” making it more compatible with the model’s expected input patterns. To ensure transformations align with the model’s learned vocabulary, we use token probability distributions and reranking based on log likelihood, refining selections beyond greedy or beam search. These text transformations help reduce interpretive errors by bringing language closer to the model’s trained structure.

%In \textbf{P2.2}, transformation uses techniques such as synonym replacement and text rephrasing with large language models (LLMs). Synonym replacement adjusts specific words within the text to reduce ambiguities or simplify language, without changing the overall meaning. For example, in a sentiment analysis task, the word "joyful" might replace "elated" to match the model’s training vocabulary. Additionally, leveraging LLMs enables full rephrasing of sentences or phrases to standardize informal or complex language. For instance, "I’m over the moon about this product" could be rephrased to "I’m extremely happy with this product," aligning with more formal patterns that the model may interpret more reliably. These text refinements help mitigate interpretive errors by bringing language closer to the model’s expected input structure. 

Continuous Data Transformation targets high-dimensional data like images, which are sensitive to environmental factors.  In \textbf{P2.3} sub-phase includes small perturbations and transformations to normalize aspects such as lighting, contrast, and angle, stabilizing the model’s interpretation of visual features. This includes brightness adjustments can address counteract poor lighting, contrast normalization can make subtle details more noticeable, and geometric transformations like slight rotations or cropping to standardize perspective. For example, brightness adjustments can address lighting inconsistencies, while contrast normalization increases feature visibility. Geometric transformations ensure that objects remain within the model’s learned visual range, regardless of minor changes in viewpoint. Additionally, noise reduction techniques remove sensor artifacts, creating a cleaner input that reduces the likelihood of misclassification. These transformations establish a consistent visual baseline, allowing the model to interpret high-dimensional visual data more effectively.

%%%Continuous data, such as images, presents unique challenges due to its high-dimensional nature and sensitivity to environmental factors.  In \textbf{P2.3}, small perturbations or transformations help normalize lighting, contrast, and angle to stabilize the model’s interpretation of visual features. For example, brightness adjustments can counteract the effects of poor lighting, while contrast normalization makes subtle details more discernible. Geometric transformations like slight rotations or cropping help standardize perspective, ensuring that objects remain within the model’s learned visual range. Additionally, noise reduction techniques can remove sensor artifacts, creating a cleaner input that reduces the likelihood of misclassification. These transformations provide continuous data with a consistent visual baseline, allowing models to interpret high-dimensional inputs more effectively.

\textbf{P3: Search Strategies.} \textbf{P3} combines the insights from \textbf{P1} and \textbf{P2} to systematically identify the optimal modifications that convert out-of-scope inputs into forms the model can reliably interpret. This phase leverages different search-based approaches such as greedy, beam, and evolutionary searches to evaluate and select the best transformation for each input type, whether through syntax adjustments in code, rephrasing in text, or visual enhancements in images.

An adaptive search strategy is crucial for aligning complex inputs with the model’s learned patterns, as it allows for the dynamic exploration of transformation options. By iteratively refining inputs through this search process, the framework ensures reliable model performance on real-world data without the need for retraining.

%\textbf{P3: Search Strategies.} \textbf{P3} combines \textbf{P1} and \textbf{P2} to identify the optimal transformation that converts out-of-scope inputs into in-scope ones. For each out-of-scope input, the search process systematically evaluates various transformations, such as syntax adjustments in code, rephrasings in text, or image enhancements to select the transformation that best aligns the input with the model’s learned patterns. By iteratively testing each transformation and assessing its compatibility, this phase finds the optimal solution that ensures reliable model interpretation without retraining. This adaptive search approach allows the model to handle complex, real-world inputs with improved accuracy.














%Figure~\ref{fig:Overview}  provides an overview of my proposed research. This consists of two main technical phases: \textit{Input validation} phase to detect out-of-scope inputs from normal inputs, and \textit{Input refinement} phase to transform out-of-scope inputs to in-scope inputs.  These components are designed to address the unique challenges of improving CLMs for various software engineering tasks, including classification tasks (vulnerability detection, defect prediction etc.) and generation tasks (code completion etc.) ~\cite{tian2023fly, naturalattack, Zhang2023Challenging, lu2021codexglue,svyatkovskiy2020intellicode,Devlin2019BERT,Sanh2020DistilBERT,guo2021graphcodebert,Chen2021Evaluating}. The framework is adaptable across different CLM architectures, including encoder-only, decoder-only, and encoder-decoder models, enhancing its applicability for diverse software engineering applications. 

%\subsection{Input validation}

%The goal of input validation is to identify "out-of-scope" inputs-those that exceed the model’s handling capacity and are likely to produce unreliable predictions. Traditional uncertainty metrics, commonly used for continuous data such as images, are often ineffective for code data, which is inherently discrete and structured (Section~\ref{validation_results}). These metrics tend to fall short with code inputs for several reasons. First, they are designed for smooth, continuous data distributions and thus struggle to capture the abrupt, structured variations typical of code. Additionally, traditional metrics focus on the hidden state representations of the final few layers, overlooking the layer-by-layer transformations that can reveal more nuanced patterns within code data. This layer-blind approach leads to overconfident predictions on out-of-scope inputs, as intermediate layer information that could signal uncertainty is ignored. Furthermore, standard metrics lack adaptation for the unique syntactic and semantic dependencies in code, such as control flow and variable relationships, which are essential for accurate uncertainty estimation.

%To address these limitations, my research propose a novel validation approach rooted in the insight that “the more intermediate layers align with the model’s final prediction, the more reliable the prediction is.” As inputs are processed by the model, the focus across layers may vary, shifting between structural information, variable dependencies, and other features intrinsic to code. This layer-sensitive approach enables a more comprehensive understanding of how the model interprets each input, rather than relying solely on final-layer outputs. 

%My approach leverages sub-models, inspired by sub-ensemble methods~\cite{gawlikowski2023survey}, to reveal the layerwise internal processing dynamics of the model on a given input. Sub-models introduce prediction diversity by isolating different network architectures within each layer, enabling them to capture distinct aspects of the data. This configuration provides a clearer, layer-specific view of how each component of the model contributes to overall predictions, highlighting areas of uncertainty that traditional metrics overlook.

%Training sub-models independently allows them to focus on uncertainties that emerge at different layers by isolating specific processing stages. By training only the dense layer and freezing earlier layers, sub-models provide robust signals of the model’s confidence across categories, improving differentiation between in-scope and out-of-scope inputs. Research has shown that in code models, shallower layers~\cite{maunveiling} often capture critical structural information better than deeper layers, making sub-models particularly suited to code input validation. This method enables each sub-model to concentrate on unique aspects of the data, resulting in a more accurate and reliable classification of input scope.


%%%These limitations underscore the need for a more granular approach to input validation, one that captures the layer-by-layer transformations unique to code data. By examining data processing at each layer, our method aims to leverage nuanced patterns to detect out-of-scope inputs more accurately, thus enhancing the model’s validation capabilities and reliability when handling complex code inputs. To address this limitation, we propose a novel validation approach based on the insight that \textit{“the more intermediate layers agree with the model’s final prediction, the more accurate the prediction is.”} When inputs are fed into the DL model, the focus of the model’s layers may shift across various aspects of the inputs, such as from structural information to variable names. The intuition for using sub-models is based on the observation that a group of sub-models can reveal layerwise internal understanding of the model on a given input. Inspired by subensemble methods [40], sub-models introduce diversity in predictions by employing varied network architectures. 


%These limitations motivate a more granular approach to input validation, one that examines data behavior across each layer to capture the complex, structured patterns inherent in code. By assessing uncertainty at multiple stages, our approach aims to improve the model’s ability to detect out-of-scope inputs more accurately, enhancing validation accuracy for code language models.


%%The purpose of input validation is to identify "out-of-scope" inputs, i.e., the inputs beyond the model's handling capability that are likely to yield unreliable predictions. Traditional uncertainty metrics, which are effective in continuous domains such as image processing, are often inadequate for the discrete and highly structured nature of code data (Section~\ref{validation_results}). These metrics assume smooth data distributions, making them unsuited to code, where small syntactic variations can result in significant semantic differences. Moreover, conventional uncertainty metrics primarily rely on the hidden state representations of only the final layers of the deep learning model, which limits their sensitivity to the incremental transformations that occur in intermediate layers. This limitation leads to overconfidence on out-of-scope inputs, as the model’s cumulative uncertainty across layers remains unassessed. Additionally, traditional metrics do not account for the complex, hierarchical dependencies inherent in code, such as control flows and variable interactions, which are critical for precise uncertainty estimation in code language models.


%%%These metrics often fall short for code inputs because they primarily rely on the hidden state representations of the final few layers of the deep learning model, neglecting the nuanced layer-by-layer processing of inputs. This limitation motivates a more granular approach, prompting us to examine data behavior across each layer to better capture complex patterns and improve validation accuracy. 

%The goal of input validation is to identify "out-of-scope" inputs, those that fall beyond the model’s handling capability and are likely to produce unreliable predictions. Traditional uncertainty metrics, often used in continuous data domains like image processing, prove ineffective for code data, which is inherently discrete and structured (Section~\ref{validation_results}). Existing uncertainty metrics fall short for code inputs because they focus on hidden state outputs of the final few layers of the DL model, rather than the layer-by-layer processing of inputs.  The findings motivates us to observe the data behaviors in a granular fashion. 

%%To address this limitation, we propose a novel validation approach based on the insight that \textit{“the more intermediate layers agree with the model’s final prediction, the more accurate the prediction is.”} When inputs are fed into the DL model, the focus of the model’s layers may shift across various aspects of the inputs, such as from structural information to variable names. The intuition for using sub-models is based on the observation that a group of sub-models can reveal layerwise internal understanding of the model on a given input. Inspired by subensemble methods [40], sub-models introduce diversity in predictions by employing varied network architectures.


%%%Specifically, we employ a layer-wise information consistency approach using a Dropout-based Sub-Model Generation (DSMG) technique. DSMG generates sub-models by isolating intermediate representations at each layer, allowing us to independently assess prediction confidence at various stages of the model’s internal processing. By examining these layer-wise confidence levels, the framework can more accurately classify inputs as either in-scope or out-of-scope based on their behavior across the model’s layers, providing a more reliable measure of input validity for code data. 




%\subsection{Input Refinement} For inputs identified as out-of-scope, the framework performs input refinement to adapt them into forms that align with the model's processing scope. This refinement process combines semantic-preserving code transformations with sampling techniques such as top-k sampling and temperature scaling etc. While transformations restructure the input to improve model compatibility without altering the code’s functional semantics, sampling techniques adjust the output probabilities in generative models to enhance prediction confidence and reliability.

%Our input refinement process employs an Adaptation by Evolutionary Search (AES) approach, which iteratively applies transformations and sampling adjustments based on the DSMG-based validity score. This iterative process allows the framework to evolve the input through a sequence of semantic-preserving modifications until it falls within the model’s scope. Sampling techniques like top-k sampling and temperature scaling are used to fine-tune the probability distributions in generative tasks, improving the model’s ability to generate accurate predictions for out-of-scope inputs. This balanced approach ensures that refined inputs retain their original meaning and functionality while increasing the model’s accuracy and reliability without requiring costly retraining.

