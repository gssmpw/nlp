\section{Background}
\label{background}

%%%%ISSTAAA \textcolor{red}{Organize according ly. Problem \texttt{->} there are two sub problems \texttt{->} 1) input valudation, 2) how to adapt the inputs. Show different ways in the following sections.  Input validation-> we have adifferent ways to search for the metric. however, the challenge is if we can detect it with minimum false positive rates. As solution, we have uncertainty, cross-validation, multi-model etc. From here uncertainty is the widely used approach to detect mispredicted inputs. Input adaptation, Once we find the inputs to fix, our next challenge is to how to implement a search a strategy to understand the most influential part of code. This can be achieved via search based testing. There are many techniques employed for this task. Eg: random search, hill climbing, A*, genetics algorithms. Now we can leverage these search techniques to find the code variants to transform without breaking semantics. Then we can utilize our guiding metric to determine which input is the best candidate to adaptation.}

%ISSTA In this section we review uncertainty in DL, genetic algorithms and program transformations, which are key to our solution.

% \jiajun{In general, the intention of the background is not so clear. Some of them are well-known concepts, such as the phases in GA. Maybe, more detailed information that will be used in the subsequent presentation should be introduced. For example, a formalization of the working process?}

\subsection{Problem Definition}

\textcolor{blue}{Given a code model \( M \) and an input code snippet \( x \), the class with the highest probability is the final prediction result of \( M \) for \( x \), denoted as \(y = M(x) \). During deployment, ensuring the correctness of every prediction is challenging. Thus, the objective is to enhance model performance on test inputs through code adaptation.} 

\textcolor{blue}{The validation metric \(V(M,x)\)  evaluates \(M\)'s uncertainty on input \(x\) to determine whether the input is in-scope or out-of-scope. If \(V(M,x)\) is less than the predefined threshold \(c\), it indicates uncertainty, and \(x\) requires adaptation. Otherwise, the \(x\) is considered in-scope. The set of transformations \(T = \{T_1, T_2, \ldots, T_n\}\) refers to a sequence of code transformation operators applied to the out-of-scope input \(x\), resulting in a modified input \(x'\).} \textcolor{blue}{Let \( \hat y \) represent the ground truth of \( x \) and let \( y' = M(x') \) be the prediction result after adapting \( x \) to \( x' \) via  \( T \).} 


\textcolor{blue}{The goal is to compute \( V \) and apply \( T \) such that the loss function of the adapted prediction \( L(y') \) is smaller than the original loss \( L(y) \).} \textcolor{blue}{We aim to find \( V \) and \( T \) to make \( L(y') < L(y) \) where:} 
\vspace{-1mm}
\textcolor{blue}{\begin{equation*}
y' = 
\begin{cases} 
M(T_1, T_2, \ldots, T_n(x)), & \text{if } V(M,x) \leq c, \\ 
y, & \text{if } V(M,x) > c,
\end{cases}
\end{equation*}}
% \begin{flushright} 
% \text{where \( c \) is a threshold.}
% \end{flushright}}



\textcolor{blue}{The loss \( L(y) \) is characterized by the distance from the ground truth \(\hat{y} \): 
{\small\begin{equation*}
L(y) = \|y - \hat{y}\|
\end{equation*}} }

\textcolor{blue}{This can be generalized to any distance metric (e.g., \( L_1 \),\( L_2 \), \(L_{\infty}\))~\cite{carlini2017towards, papernot2016distillation, szegedy2013intriguing, papernot2016effectiveness} to accommodate for any SE task. }

%%edited \textcolor{blue}{This formulation represents the \( L_n \), allowing the use of any distance measure such as \( L_1 \) or \( L_2 \), making it suitable for any SE task.}

%\textcolor{blue}{The loss \( L \) is characterized by the distance from the ground truth:}

% \begin{equation*}
% y' = M(T_1, T_2, \ldots, T_n(x)), \text{ if } V(M(x)) < c, 
% \end{equation*}

% and 

% \begin{equation*}
% y' = \hat y, \text{ if } V(M(x)) > c, 
% \end{equation*}
% \noindent where \( c \) is a threshold

%%%edited one
% \textcolor{blue}{\begin{enumerate}
%     \item \( y = M(x) \)
%     \item If \( V(M(x)) \leq c \), where \( c \) is a threshold, then:
%     \begin{enumerate}
%         \item Apply transformations \( T_n \) to obtain \( x' \):
%         \[
%         x' = T_1, T_2, \ldots, T_n(x)
%         \]
%         \item Predict the new input \( x' \) with \( M \) to obtain \( y' \):
%         \[
%         y' = M(x')
%         \]
%         \item Ensure the loss of \( y' \) such that the new loss \( L(y') \) is smaller than the original loss \( L(y) \):
%         \[
%         L(y') < L(y)
%         \]
%     \end{enumerate}
% \end{enumerate} }

% \textcolor{blue}{The loss \( L \) is characterized by the distance from the ground truth:}% For example, a simple loss function could be:}

% \textcolor{blue}{\[
% L(y') = 
% \begin{cases} 
% 0, & \text{if } y' = y \\
% 1, & \text{if } y' \neq y
% \end{cases}
% \]}
%%edited one end


\textcolor{blue}{The challenge is to develop an effective validation metric \( V \) (Oracle problem) and a determine a sequence of transformations \( T \) (Search problem) that adapt out-of-scope inputs.}% and improve the model's performance without retraining. }




%Given a code model $M$ and an input code snippet $x$, the class with the largest probability is the final prediction result of $M$ for $x$, denoted as $M(x)$. If $M(x)$ is different from the ground truth label of $x$, it \textcolor{blue}{indicates} that $M$ \textcolor{blue}{has made} a misprediction on $x$; otherwise \textcolor{blue}{it indicates} a correct prediction. However, \textcolor{blue}{$M$ does} not guarantee the correct prediction for each test input during the deployment. This work aims to improve the model performance on test inputs via code adaptation, which makes it an effective technique different from others that require retraining \textcolor{blue}{or replacing the model}~\cite{yuDataAugmentationProgram2022, xiao2021selfchecking,xiao2022repairing}. 

%The process of input adaptation for code data possesses two challenges: 1) \textbf{Oracle problem:} validating a given test input as in-scope or out-of-scope, and 2) \textbf{Search problem: } how to adapt the out-of-scope input to become in-scope input. \textcolor{blue}{Due to space limitations, the formal definitions can be found on our project website~\cite{CodeImprove}.}

\subsection{\textcolor{blue}{Oracle Problem- Developing V}}
\textcolor{blue}{During deployment, determining whether a prediction is correct without manual analysis is challenging. An effective validation metric \(V\) is needed to automatically guide \(M\) to accurately make decisions, thus reducing false positives.}  A substantial progress has been made in this direction such as handling uncertainty\textcolor{blue}{~\cite{guo2017calibration,wang2020dissector,hendrycks2018baseline,gal2016dropout, alon2019code2vec,xiao2019quantifying,vasudevan2019towards,corbiere2019addressing, monarch2021human, steinhardt2016unsupervised,shannon1948mathematical}}, deep emsemble~\cite{lakshminarayanan2017simple}, and cross-layer dissection~\cite{wang2020dissector}.


%%%edited During the deployment, \textcolor{blue}{it is not feasible to precisely determine whether the prediction for a given code input is correct without manual analysis.} 
%we cannot exactly determine whether the prediction for a given code input is correct or not without manual analysis.
%edited This means that it is \textcolor{blue}{challenging} to automatically decide whether a given code input is correctly predicted or not. \textcolor{blue}{To} automate this process, it is crucial to design an effective metric that can guide these code models to accurately make decisions (i.e., reducing false positives). A substantial progress has been made in this direction such as handling uncertainty\textcolor{blue}{~\cite{guo2017calibration,wang2020dissector,hendrycks2018baseline,gal2016dropout, alon2019code2vec,xiao2019quantifying,vasudevan2019towards,corbiere2019addressing, monarch2021human, steinhardt2016unsupervised,shannon1948mathematical}}, deep emsemble~\cite{lakshminarayanan2017simple}, and cross-layer dissection~\cite{wang2020dissector}. %Although these 
%~\cite{guo2017calibration,wang2020dissector,hendrycks2018baseline, li2021estimating, alon2019code2vec,} 

%\textcolor{blue}{~\cite{guo2017calibration,wang2020dissector,hendrycks2018baseline, li2021estimating, alon2019code2vec,monarch2021human, steinhardt2016unsupervised,shannon1948mathematical}}

\subsection{\textcolor{blue}{Search Problem- Transformation Sequence T}}
Beyond validation, the process of adapting the out-of-scope inputs to become in-scope inputs necessitates efficient search algorithms to explore program syntax for potential transformations. The goal of search techniques is to optimize the code transformations while preserving the program semantics. \textcolor{blue}{Search techniques like random search~\cite{zabinsky2009random}, hill climbing search~\cite{selman2006hill}, and genetics algorithms~\cite{harman2001search} offer solutions for code transformations. }
%The variants of search techniques, such as random search~\cite{zabinsky2009random}, hill climbing search~\cite{selman2006hill}, and genetics algorithms~\cite{harman2001search} offer solutions to code transformations for search. 
\textcolor{blue}{The} search strategy begins with a set of candidate solution(s) generated by applying semantic preserving code transformation. 
\textcolor{blue}{These candidates are then evaluated using \(V\) to select the most promising one.} 
%Then, these candidate solutions are guided by the metrics in the validation phase to select the most promising candidate. 
\textcolor{blue}{The search algorithm iteratively refines the candidates until a termination criterion is reached or an optimal solution is found.}
%\textcolor{blue}{The search algorithm evolves iteratively, refining the candidates until a termination criterion is reached or an optimal solution is found.}
%The search algorithm evolve until reached a termination criteria or reached the optimal solution. 

%by leveraging the guiding metric from validation to guide our candidate solutions to select the best candidate. T  

%Initially, the search process involves generating a set of candidate solutions by applying code transformations that preserve semantics. Subsequently, these candidate solutions are guided by validation metrics to select the most promising one



%\textcolor{red}{can we describe in terms SE tasks. The introduction only talks about NLP. Also, introduce some pretrained models like roberta, codebert, bert etc. Just a general background on pretrained models}

%The advent of pretrained language models marks a notable advancement in the realm of artificial intelligence (AI) and natural language processing (NLP), fundamentally altering the methodology used in various tasks, including many in the realm of Software Engineering. A multitude of researchers have repurposed these models by training them on big codes, thereby enabling solutions for software engineering tasks like clone detection, code completion, and text-to-code generation etc. 

%%%oopsla
%\subsection{Pre-trained Language Models} 
%A pre-trained language model refers to pre-training a large model on a massive set of unlabelled data using a self-supervised objectives, and fine-tuning the model on downstream tasks (i.e., program classification and generations tasks. Many pre-trained models models~\cite{Devlin2019BERT,Liu2019RoBERTa,Sanh2020DistilBERT,fengCodeBERTPreTrainedModel2020,Chen2021Evaluating} have been proposed in the exiting literature. In particular, these pre-trained models contain two stages: first for pre-training on a large NL-PL data, and second for fine-tuning. Pre-training tasks can include Masked language Modeling~\cite{Devlin2019BERT} and Language Modeling~\cite{radford2019language} while fine-tuning for software engineering tasks such as defect prediction~\cite{tian2023code}, vulnerability detection~\cite{lu2021codexglue}, clone detection~\cite{lu2021codexglue}, and text-to-code generation~\cite{lu2021codexglue}. 

%BERT\cite{Devlin2019BERT} is a prominent pre-trained language model that utilizes attention mechanism, leading to the evolution of language models. Once pretrained, BERT can be finetuned to deal with many downstream NLP tasks and SE tasks. After the release of BERT, many optimization approaches for BERT were proposed, including RoBERTa\cite{Liu2019RoBERTa} and DistilBERT\cite{Sanh2020DistilBERT}. Previous researchers~\cite{lu2021codexglue} have proved that these models can be applied to various program understanding and generation problems which shows the effectiveness of using pre-trained Languages models to deal with code. Furthermore, many pre-trained code models have also been proposed to solve specific software engineering tasks. CodeBERT\cite{fengCodeBERTPreTrainedModel2020} is a programming counterpart of BERT and also the first large NL-PL pre-trained model for multiple programming languages. Additionally, Codex\cite{Chen2021Evaluating}, a GPT language model fine-tuned on large-scale code, powers GitHub Copilot, and can intelligently complete code with context and handle many other tasks on code.
%%%OOPSLA
% encoder-based models such as CodeBERT [18], GraphCodeBERT [21], and ContraCode [27], they randomly mask parts
% of the input sequence (e.g., ‘main’, and ‘{’ are replaced by the
% [MASK] token) where the objective of their models is to recover the
% masked tokens (Masked language Modeling). Meanwhile, in Figure 1b, the decoder-based model such as CodeGPT [43] is trained
% auto-regressively, i.e., each generated output will be extended into
% the original input sequence for subsequent token generation until
% it reaches an [SEP] (Language Modeling). The encoder-decoderbased models such as CodeT5 [71], CodeTrans [16], CoTexT [53]
% and PLBART [3] jointly train encoder and decoder for comprehensive modeling of the language. 


%%%%ISSTA%%%%\subsection{Uncertainty in DL}
% The predictions made by the code models are uncertain as the models are prone to noises and wrong model inference besides the inductive assumptions that are inherent in case of uncertainty. The uncertainty arises from two sources: 1) the aleatoric uncertainty~\cite{xiao2019quantifying} that occurs due to the noise in the observed labels, and 2) epistemic uncertainty~\cite{xiao2019quantifying} occurs from the selection of model parameters and structures. At present, uncertainty metrics~\cite{guo2017calibration,wang2020dissector,hendrycks2018baseline, li2021estimating, alon2019code2vec, vasudevan2019towards,corbiere2019addressing} have been designed and applied for input validation. During input validation, existing uncertainty metrics are applied to detect out-of-scope inputs (i.e., inputs that are beyond the model's handling capability). 


% An out-of-scope program is defined when an input data is mispredicted (i.e., a data sample that is incorrectly classified)
% %\jiajun{Again, the definition of ``out-of-scope'' is unclear and contradicts the previous definition. Actually, I do not think considering mispredicted inputs as out-of-scope is appropriate.} 
% and clearly distinguished using an uncertainty metric. Therefore, filtering the out-of-scope program data can be achieved by applying the concept of uncertainty. In the following sections, we denote the uncertainty score of given input $S$ and model $M$ as $U(M,S)$.

%The uncertainty arises from two sources, the aleatoric uncertainty and the epistemic uncertainty~\cite{}. The former arises from the noise 209 in the observed labels (e.g., natural evolution, artificial corruption), while the latter comes from the selection of model parameters and structures (e.g., invertible ResNet can be more generative for inputs sampled from a different distribution). Bayesian machine learning [47–49] which works with probabilistic models and uncertainty, defines probability distributions over functions and are used to learn the more and less likely ways to generalize from observed 216 data. Existing uncertainty measurements [24, 34, 50] which enhance the effectiveness and efficiency of Bayesian machine learning have achieved some progress.

%%%%ISSTAAA
% \subsection{Genetic Algorithms}
% Genetic Algorithms (GA)~\cite{harman2001search} are evolutionary search techniques that imitate the process of evolution to solve optimization problems, especially when traditional approaches are ineffective or inefficient. GA consists of five phases. 

% \textbf{Initial Population: }The set of initial individuals is called a population. Each individual is a solution to the problem. 

% \textbf{Fitness Function: }The fitness function determines how fit an individual is by getting a fitness score to each individual. 

% \textbf{Selection: } The fittest individuals are selected based on the fitness score. 

% \textbf{Crossover: }Crossover is applied to those selected individuals by reproducing one off-spring that is applied with a high probability. 

% \textbf{Mutation: }Apply helps to maintain diversity within the population by forming new offsprings with a low probability. 



% \subsection{Program Transformations}
% %\jiajun{This section is more like presenting related work.}

% Following previous work~\cite{yuDataAugmentationProgram2022}, we formally define the semantics of a program (denoted as $S$) as a function (denoted as $\mathbb{S}(S)$) that maps a program state into another program state. A program state is a function which maps variable names ($Var$) to values($Value$), which can be written as:
% {\small
% $$
%     State: Var \xrightarrow{} Value $$
% $$
%     \mathbb{S}(S): State \xrightarrow{} State
% $$ 
% }
% Then, we define two program $P$ and $Q$ are semantically equivalent as:
% $$
%    \mathbb{S}(P) = \mathbb{S}(Q) \iff \forall{State}, \  \mathbb{S}(P)(State) = \mathbb{S}(Q)(State)
% $$
% Therefore, the transformation rule $R$ is defined as a function which inputs a legal program string, and outputs another one. For each rule, we include a condition $C(R,S)$ indicating only whether rule $R$ is applicable to the program S. Therefore, a semantic-preserving program transformation rule can be defined as:
% {\small
% $$
% \forall{S} \quad C(R,S) \rightarrow (\mathbb{S}(R(S)) = \mathbb{S}(S))
% $$
% }

%END ISSTA%%%%%%%%%



%Program transformation is a process of transforming a given program into a new syntactic-different program with the same semantics as the original program. We can do such transformation by applying some unique semantic-preserving operators such as variable renaming, adding junk code, deleting irrelevant code, reordering independent code, etc. 

%Program Transformation techniques have been widely used to solve semantic-related but syntactic-unrelated tasks such as clone detection or method name prediction, etc. For example, Zhang et al \cite{Zhang2023Challenging} proposed an approach using code transformation techniques to generate adversarial samples for the adversarial attacks on Clone Detection models. Yu et al \cite{yuDataAugmentationProgram2022} leveraged code transformation as a method of data augmentation, which can automatically generate labelled data that can be used to enlarge the training data sets for supervised learning software engineering models.

%\textcolor{red}{zeqing and zijie. Add more content to this paragraph}


%%%%ISSTA
% \subsection{\textcolor{red}{Problem Definition}}

% Given a code model $M$ and an input $S$, we aim to develop a systematic method called CodeImprove for determining whether the code model will validate the test instance and adapt the out-of-scope test instance to become an in-scope instance. First, CodeImprove's input validation should trigger the potential out-of-scope test input. Second, CodeImprove aims to select a series of transformation rules $R_1, R_2 \ldots, R_n$, making the transformed input ($R_1\circ R_2 \circ \ldots \circ R_n) (S)$ have the best candidate that likely to become an in-scope input. Formally, the task is to:
% $$ \argmax_{R_1, R_2,\ldots, R_n} U(M, (R_1\circ R_2 \circ \ldots \circ R_n) (S)) $$ such that $U(M, R()(S))$ is the validity score analysis of CodeImprove. Our goal is to adapt programs for code models without altering the model.
% END ISSTA %%%






% Given a code model $M$ and an input $S$, CodeImprove aims to select a series of transformation rules $R_1, R_2 \ldots, R_n$, making the transformed input ($R_1\circ R_2 \circ \ldots \circ R_n) (S)$ have the minimal uncertainty score on the model. Formally, the task is to:
% $$ \argmin_{R_1, R_2,\ldots, R_n} U(M, (R_1\circ R_2 \circ \ldots \circ R_n) (S)) $$
% \zijie{Alternative version:
% $$ \minimize U(M, (R_1\circ R_2 \circ \ldots \circ R_n) (S)) $$
% }













