In this section, we first formalize our problem statement and describe the conventional algorithmic framework. We then describe a \naive anytime framework and why it is ineffective.
Finally, we give an overview of our guided anytime framework and its advantages over previous approaches. 

\vspace{-3mm}
\subsection{Problem Statement}

Consider a $k$ degree of freedom robot manipulator whose joint configuration and end-effector pose are denoted by $\mathbf{q} {\in} \mathbb{R}^k$ and $\mathbf{p} {\in} SE(3)$, respectively. 
End-effector trajectory tracking refers to the problem of computing a joint space trajectory $\xi{:}[0,T_\chi] {\rightarrow} \mathbb{R}^k$ that drives the robot's end-effector along a desired trajectory $\chi{:}[0,T_\chi] {\rightarrow} SE(3)$, where $T_\chi$ represents the total time duration of the end-effector trajectory. In practice, the target end-effector trajectory $\chi$ is often represented in a discrete form $\{(t_1, \mathbf{p}_1), ..., (t_{n}, \mathbf{p}_{n})\}$, where $\mathbf{p}_i$ is the end-effector pose at timestamp $t_i$. We assume that the waypoints are sufficiently dense to accurately approximate $\chi$. 

In general, there are some requirements for joint space continuity, \textit{e.g.}, in a short time interval $\tau {>} 0$, all joint movements are within their velocity limits, $v_{min} {\leq}[\xi(t{+}\tau)_j$
$ {-} \xi(t)_j]/\tau {\leq} v_{max}, \forall j {\in} \{1,...,k\}, \forall t {\in} [0, T_\chi {-} \tau]$. However, in scenarios where the input trajectory is complex and can not be tracked as a single, continuous path, exceptions to this requirement may be permissible if the task allows for interruptions. In such instances, joint discontinuities may be introduced deliberately. Each joint discontinuity requires the robot to perform an \textit{arm reconfiguration}, in which the robot pauses the task execution, relocates itself in the joint space, and resumes task execution from another configuration. 

This work focuses on the cases where the robot manipulator has some redundancy; it is either a redundant arm ($k>6$) or a non-redundant arm performing semi-constrained trajectory tracking, where certain tolerances are permitted on the end-effector poses. 
Due to the redundancy, the trajectory can be tracked by infinitely many possible motions, requiring optimization criteria to select the best solution.


Graph-based trajectory tracking algorithms maintain a layered graph $G{=}(V, E)$, where each layer corresponds to a waypoint on the reference trajectory. $V$ and $E$ denote vertices and edges in the graph, respectively. The notation $V[x]$ denotes all vertices in the layer corresponding to the $x$-th waypoint. $V[x][y]$ represents the $y$-th IK solution that aligns the end-effector with the $x$-th waypoint. $|V[x]|$ denotes the total number of vertices in $V[x]$.


\begin{figure}[tb]
\includegraphics[width=3.4in]{figures/methods.pdf}
\caption{Three algorithmic frameworks described and evaluated in this paper} 
\label{fig:methods}
\vspace{-5mm}
\end{figure}


\vspace{-3mm}
\subsection{Baseline 1: Conventional Algorithmic Framework} \label{sec: conventional}

Many existing graph-based trajectory tracking algorithms use a sequential framework. As shown in Figure \ref{fig:methods}-A, these approaches sample inverse kinematics (IK) solutions for each waypoint on the end-effector trajectory, use these IK solutions as graph vertices, and search for a solution in the graph. 


\subsubsection{IK Sampling} \label{sec:conventional_sampling}
The two primary goals of IK sampling are to find IK solutions that are \textit{diverse} enough to cover the entire solution space and \textit{dense} enough to construct a smooth motion. 
In order to generate diverse IK solutions, one common approach is to randomly sample starting configurations in a robot's joint space and find IK solutions that are closest to the starting configurations using an optimization-based IK solver, such as Trac-IK \cite{beeson2015trac} or RelaxedIK \cite{rakita2018relaxedik}, or an iterative IK solver, such as Orocos KDL %\cite{KDL} 
%\footnote{\url{https://www.orocos.org/kdl.html}}
or the damped least squares IK algorithm \cite{wampler1986manipulator}. Another approach \cite{morgan2024cppflow} uses a learned generative IK solver, IKFlow \cite{ames2022ikflow}, which learns the distribution of uniformly sampled IK solutions and efficiently generates a diverse set of IK solutions. 

To ensure sufficient density of IK solutions, many previous approaches specify a fixed number of IK solutions for each waypoint, represented by $m$. For example, Stampede \cite{rakita2019stampede} sets $m{=}250$, IKLink \cite{wang2024iklink} sets $m{=}300$, and CppFlow \cite{morgan2024cppflow} sets $m{=}175$. We note that these numbers are used for a 7-DoF robotic arm to track a fully constrained end-effector trajectory. For scenarios involving a more redundant robot (DoF$>$7) or a semi-constrained trajectory, more IK solutions may be necessary. This is because the solution space is larger and requires more IK solutions to densely cover the entire space. 
    

\subsubsection{Graph Construction} \label{sec:conventional_graph}
The sampled IK solutions are used as vertices to construct a layered graph where each layer corresponds to a waypoint on the end-effector trajectory. Edges connect vertices in consecutive layers if the robot can move between the two IK solutions within the time budget specified by the reference trajectory. Edge weights are defined based on various problem formulations such as total joint movement \cite{rakita2019stampede} or maximum joint movement \cite{morgan2024cppflow}.


\subsubsection{Graph Search} \label{sec:conventional_search}
Once the graph is constructed, any paths within the graph represent possible robot motions by connecting the IK solutions. The shortest path from the first layer to the last layer corresponds to a high-quality motion that tracks the trajectory. Different methods are utilized to search for the shortest path. For example, Descartes \cite{Descartes} uses Dijkstra's algorithm, Niyaz \textit{et al.} \cite{niyaz2020following} uses lifelong planning $A^*$, Stampede \cite{rakita2019stampede} uses value iteration, and IKLink \cite{wang2024iklink} uses a dynamic programming method with two objectives.


\textit{Analysis}:
Although multiple IK solutions are sampled for a waypoint, ultimately, only one IK solution is selected to construct the robot motion. Hence, we seek ways to improve the sampling process, \textit{i.e.}, biasing sampling towards areas with a high probability of being selected. Additionally, the number of IK solutions decides the number of edges in the graph; a small set of IK solutions can reduce the time for connectivity checking and graph search.

\iffalse
\begin{algorithm}
    \caption{Conventional algorithmic framework}
    \label{alg:existing}
    \SetKwProg{Fn}{Function}{}{}
    \SetKwProg{For}{for}{\ do}{}
    \SetKwProg{If}{if}{\ then}{}
    \SetKwInOut{Input}{input}
    \SetKwInOut{Output}{output}
    \SetKwInOut{Hyper}{hparam}
    \SetKw{KwTo}{to}
    \SetKw{KwOr}{or}
    \SetKw{KwAnd}{and}
    \SetKwFunction{SEARCH}{SEARCH}%
    \SetKwFunction{SAMPLING}{SAMPLING}%
    \SetKwFunction{CDG}{ADD\_DENSE\_GRAPH}%
    %\Fn{\FDP{$S$\added{,$t$}}}{

    \Input{an end-effector trajectory $\xi = \{(t_0, \mathbf{p}_0), (t_1, \mathbf{p}_1), ..., (t_{n-1}, \mathbf{p}_{n-1})\}$}
    \Output{a joint space trajectory $p$}
    \Hyper{number of IK solutions for each waypoint $m$}
    \Comment*[l]{IK Sampling}
    $V \leftarrow \SAMPLING(\xi, step=1, m)$ \\
    \Comment*[l]{Graph Construction}
    $E \leftarrow \CDG(V)$ \\
    $G \leftarrow (V, E)$ \\
    \Comment*[l]{Graph Search}
    $p =$ \SEARCH(G)
\end{algorithm}
\fi


\vspace{-3mm}
\subsection{Baseline 2: \Naive Anytime Algorithmic Framework} \label{sec:naive}
The aforementioned conventional framework does not provide a solution until completion. 
In contrast, an anytime algorithm provides an initial solution and then iteratively refines it, enabling the process to be stopped at any time and allowing for tradeoffs between solution quality and computation time. 
As shown in Figure \ref{fig:methods}-B,  a \naive anytime framework uses the same random sampling process to initially sample a smaller set of IK solutions, from which a layered graph is constructed. A graph search is then conducted to identify an initial solution.
The solution is iteratively refined by sampling additional IK solutions, expanding the graph, and performing further graph searches to find new solutions. 
The solutions are always at least as good as, if not better than, the previous ones because the graph incorporates all vertices and edges from its previous version. The algorithm continues until it reaches a predefined threshold, such as running time or the number of iterations.


\textit{Analysis}:
The \naive anytime framework has the advantage of generating an initial solution quickly and refining it over time. 
However, it requires some heuristic to find an effective initial solution. In our implementation, we use an optimization-based IK solver to find IK solutions that are close to those of the previous waypoints, which helps ensure smooth motion. This heuristic is similar to GreedyIK in Wang \textit{et al}. \cite{wang2024iklink}.
Despite this, the \naive framework often converges slowly, because the samples are added in a random order. 
This effect is demonstrated in the experiments in \cref{sec: experiments}. 
Meanwhile, our proposed algorithmic framework uses heuristics to bias sampling such that initial solutions are likely to be effective, and the additional sampling focuses on adding samples likely to improve the solution.

\iffalse
\begin{algorithm}
    \caption{\Naive Anytime Algorithmic Framework}
    \label{alg:incre_existing}
    \SetKwProg{Fn}{Function}{}{}
    \SetKwProg{For}{for}{\ do}{}
    \SetKwProg{If}{if}{\ then}{}
    \SetKwInOut{Input}{input}
    \SetKwInOut{Output}{output}
    \SetKwInOut{Hyper}{hparam}
    \SetKw{KwTo}{to}
    \SetKw{KwOr}{or}
    \SetKw{KwAnd}{and}
    \SetKwFunction{SEARCH}{SEARCH}%
    \SetKwFunction{SAMPLING}{SAMPLING}%
    \SetKwFunction{CDG}{ADD\_DENSE\_GRAPH}%

    \Input{an end-effector trajectory $\xi = \{(t_0, \mathbf{p}_0), (t_1, \mathbf{p}_1), ..., (t_{n-1}, \mathbf{p}_{n-1})\}$}
    \Output{a joint space trajectory $p$}
    \Hyper{number of IK solutions per iteration $\Delta m$ \\
        max iteration $i_{max}$ }
    $V \leftarrow \emptyset$ \\
    $E \leftarrow \emptyset$ \\
    $i \leftarrow 0$ \\
    \While {$i < i_{max}$} {
        \Comment*[l]{Sampling}
        $V \leftarrow V \cup \SAMPLING(\xi, step=1, \Delta m)$ \\
        \Comment*[l]{Graph Search}
        $E \leftarrow E \cup  \CDG(V)$ \\
        $G \leftarrow (V, E)$ \\
        $p =$ \SEARCH(G) \\
        $i \leftarrow i + 1$ 
    }
\end{algorithm}
\fi


\begin{figure*}[tb]
\includegraphics[width=7.0in]{figures/illustration.pdf}
\vspace{-3mm}
\caption{An illustration of the guided anytime algorithmic framework. In the 1\textsuperscript{st} iteration, \protect\circled{A} a limited set of IK solutions are sampled for specific waypoints. \protect\circled{B} The IK solutions construct a graph with \textit{sparse edges} (dashed lines) and a \textit{guide path} (red) is identified by searching in the graph. \protect\circled{C} Additional IK solutions are sampled with a bias toward the guide path. \protect\circled{D} \textit{Dense edges} (solid lines) are added to connect vertices in adjacent layers and an initial \textit{solution} (red) is identified by searching through the dense edges. In the 2\textsuperscript{nd} iteration, \protect\circled{E} additional sparse edges are added to connect the newly added vertices, and a new guide path (red) is found by searching through both sparse and dense edges. \protect\circled{F} More vertices are sampled, biasing toward the new guide path. \protect\circled{G} After additional dense edges are added, a new solution (red) is identified in the new graph.  In subsequent iterations, the algorithm continues to densify the graph and refine the solutions. } 
\vspace{-5mm}
\label{fig:illustration}
\end{figure*}


\vspace{-3mm}
\subsection{Overview of Guided Anytime Algorithmic Framework} \label{sec: alg_overview}

Similar to the aforementioned approaches, the proposed framework maintains a layered graph, in which a layer corresponds to a waypoint on the reference trajectory and a vertex represents an IK solution. 
The key idea of our method is to bias sampling toward \emph{guide paths}. A guide path is a sequence of vertices that approximately tracks the reference trajectory. It typically includes \emph{sparse edges} that connect vertices that are a few layers apart. Upon refinement, guide paths are likely to be good \textit{solutions}. A solution is a path through the graph with a vertex at every time step, thus accurately tracking the trajectory. During refinement, sparse edges within guide paths are potentially replaced by \textit{dense edges} which connect vertices with adjacent timestamps, thereby gradually converting guide paths to solutions. 



As shown in Figure \ref{fig:illustration}, our algorithm starts by constructing a graph in which IK solutions are sampled for certain waypoints and connected using sparse edges. An initial guide path is identified by searching over these sparse edges. The guide path is refined by adding vertices near it and connecting them with dense edges. An initial solution is found by searching over the dense edges. The process is repeated by identifying new guide paths, performing further sampling around them, and finding new solutions. 

\textit{Stages}:
Our framework contains six stages, briefly described here. The details of the stages are outlined in \cref{sec: technical_details}.

\subsubsection{Sparse Vertex Sampling} In contrast to the conventional framework which samples IK solutions for every waypoint, this stage samples a limited number of IK solutions for a subset of waypoints spaced apart. We sample at every $s$ waypoint, where the sparse step size $s$ is a hyperparameter.

\subsubsection{Sparse Edge Addition} This stage adds sparse edges to the graph, connecting vertices that are $s$ layers apart. While sparse edges still correspond to feasible motion segments, they typically do not accurately track the reference trajectory because intermediate waypoints are omitted.

\subsubsection{Guide Path Search} 
This stage identifies a guide path by finding the shortest path from the first to the last layer, using both dense and sparse edges. Guide paths correspond to motions that approximately track the reference end-effector trajectory. The heuristic assumes that high-quality solutions are likely to be found near guide paths. 

\subsubsection{Additional Vertex Sampling}
This stage adds vertices to the graph through a combination of random sampling and targeted sampling around a guide path. The underlying assumption is that IK solutions near the guide path are more likely to yield high-quality solutions. In addition, we also randomly sample an equivalent number of IK solutions. 
This helps avoid local minima where guide paths are misleading and ensures that the algorithm converges to the same worst-case expected performance as the conventional approach. 


\subsubsection{Dense Edge Addition}
This stage adds dense edges to the graph to connect vertices in adjacent layers. In addition, certain sparse edges are superseded by the dense edges. 

\subsubsection{Solution Search} 
This stage identifies a solution by finding the shortest path from the first to the last layer using only dense edges. The solution, containing only dense edges, precisely tracks the reference trajectory.


\textit{Incremental Improvement}:
As shown in Algorithm \ref{alg:proposed}, after generating a solution, the algorithm repeats the process, which involves identifying a new guide path, sampling additional vertices with a bias toward this new guide path, adding dense edges to connect the new vertices, and finding a new solution in the new graph. Because each new graph contains vertices and dense edges from its predecessor, each new solution is at least as good as, if not better than, the solution before, thus ensuring incremental improvement. The algorithm terminates upon reaching a predefined threshold, such as maximum running time or sampling capacity.

\textit{Analysis}:
The proposed framework involves random sampling IK solutions, which mimics the process of the baseline approaches. Therefore, given sufficient time, our method will generate the same (probabilistic) sample set as the baseline approaches.
With finite time and sampling budget, even the baseline approaches cannot provide guarantees of optimality, although Holladay \cite{holladay2019minimizing} has proven that a similar algorithm converges towards optimality as the sampling density grows.
Most prior works \cite{rakita2019stampede,wang2024iklink,morgan2024cppflow} empirically show the effectiveness of their algorithms. Similarly, we empirically demonstrate that our sampling strategy often more quickly finds solutions with better or equal quality in \cref{sec: experiments}.


