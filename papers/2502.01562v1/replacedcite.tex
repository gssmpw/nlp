\section{Related Work}
\label{sec:related_work}



\paragraph{Reasoning with language models}
Prior works on eliciting reasoning in LLMs have proposed to decompose reasoning tasks into unit steps ____ so that the deployed computation can scale with the complexity of the task. Generating code as a structured format to support reasoning is another common approach ____. To improve reasoning through experience, a line of work has produced self-critiques by prompting the model to reflect on its past behavior ____. These reflections resemble our corrective hints, but are bounded by the agent's ability to spot its own mistakes and self-correct, a known limitation ____; we instead leverage efficient human feedback for more accurate corrections.

\paragraph{Human feedback in LLM training} Multiple frameworks have incorporated human feedback in LLM training, e.g., by ranking several model answers ____, or providing a list of ground rules a model should not break ____. 

\paragraph{Interactive LLM frameworks} Several prior works embed LLMs in interactive environments ____. The most common approach has been to leverage in-context learning and add both the list of available tools and the agent's history to the current prompt, without changing the model itself.
However, LLMs can struggle with information overload when prompts are the only source of new knowledge, as we show experimentally in Section \ref{sec:baseline}. For proprietary models that cannot be improved through training, some works aim to remedy these limitations by instead optimizing the agent framework, such as the available actions ____, or employ Retrieval Augmented Generation ____ systems ____.

\paragraph{Supervised fine-tuning for interactive settings} Supervised fine-tuning is another approach to teach pre-trained LLMs new skills, but depends on having access to high-quality, usually human-generated data. Efforts to collect and train agents on high-quality trajectories for agentic tasks include ____. This is diffcult to scale due to cost, especially for multi-turn agent trajectories, and using labeled examples as the primary source of training data ultimately caps performance at the skill level of the annotators. For tasks with known answers, synthetic trajectories from the agent itself can be filtered to produce training data ____, and we compare with this approach in our ablation.

\paragraph{Knowledge Distillation}
In knowledge distillation, the outputs of a larger model or ensemble of models (the teacher) are used as targets for a smaller model (the student) to transfer knowledge or capabilities ____. This approach is only viable if a more capable model already exists. Moreover, it is not always clear if a smaller model has the representational capacity to accurately imitate the larger model, without resorting to memorizing spurious correlations in the training data ____. In \textbf{context distillation}, in contrast, the same model is used as teacher and student, but with different inputs: the teacher model has access to additional context not shown to the student ____. Our work is the first to extend this approach to training LLM agents for interactive tasks.

\begin{table*}
\centering
\caption{Example question templates and possible solution strategies from the ToolQA benchmark.}
\begin{tabular}{
>{\raggedright\arraybackslash}p{8mm}
>{\raggedright\arraybackslash}p{52mm}
>{\raggedright\arraybackslash}p{97mm}
}
\toprule
Group & Question template & Solution steps \\
\midrule
Yelp & Which \mytt{[business category]} has the highest review count in \mytt{[city]}, \mytt{[state]}? & 1. Load Yelp database. 2. Filter by \mytt{[city]} and \mytt{[state]}. 3. Select rows for which the category column includes \mytt{[business category]}. 4.~Fetch the review count column. 5. Use the index of the max review count to select and return the name of the business.\\
Flights & How many extra minutes did the \mytt{[flight ID]} flight take from \mytt{[departure]} to \mytt{[destination]} on \mytt{[date]}? & 1. Load flights database. 2. Separate \mytt{[flight ID]} into \mytt{[airline ID]} and \mytt{[flight number]}. 3. Filter by \mytt{[airline ID]}, \mytt{[flight number]}, \mytt{[departure]}, \mytt{[destination]} and \mytt{[date]}. 4. Fetch departure delay and arrival delay columns and return arrival delay - departure delay.\\
\bottomrule
\end{tabular}
\label{tab:toolqa_question_types}
\end{table*}