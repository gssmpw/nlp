\section{Related Work}
% add papers on online regret minimizations for related work
\paragraph{2p0s games with incomplete information.}
\cite{harsanyi1967games} introduced a Bayesian game framework to solve incomplete-information normal-form games by transforming the game into an imperfect-information one involving a chance mechanism. The seminal work of \cite{aumann1995repeated} extended this idea to repeated games and established the connection between value convexification and belief manipulation. Within the same framework, Blackwell's approachability theorem~\citep{blackwell1956analog} naturally becomes the theoretical support for the optimal strategy of the uninformed player (P2). Building on top of \cite{aumann1995repeated}, \cite{de1996repeated} introduced the concept of a dual game in which the behavioral strategy of the uninformed player becomes Markov. This concept later helped \cite{cardaliaguet2007differential,ghimire24a} to establish the value existence proof for 2p0s differential games with incomplete information. Unlike repeated games in which belief manipulation occurs only in the first round of the game, differential games may have multiple critical collocation points in the joint space of time, state, and public belief where belief manipulations are necessary to achieve Nash equilibrium, depending on the specifications of system dynamics, payoffs, and state constraints~\citep{ghimire24a}. For this reason, scalable value and strategy approximation for 2p0s differential games with incomplete information has not yet been achieved. 

% provided the theoretical foundation for characterizing how much information should be revealed and the gains that the revelation produces. 
% While repeated game captures the realistic decision-making scenario, it is still limited as it is assumed that the same normal-form game is repeated. 
\vspace{-0.05in}
\paragraph{Imperfect information extensive-form games.} IIEFGs represent the more general set of simultaneous or sequential multi-agent decision-making problems with finite horizons. Since any 2p0s IIEFG with finite action sets has a normal-form formulation, a unique Nash equilibrium always exists in the space of mixed strategies. Significant efforts have been taken to find equilibrium of large IIEFGs such as poker~\citep{koller1992complexity, billings2003approximating, gilpin2006finding, gilpin2007gradient, sandholm2010state, pluribus}, with a converging set of algorithms that are no-regret, average- or last-iterate converging, and with sublinear or linear convergence rates~\citep{zinkevich2007regret, abernethy2011blackwell, pmlr-v15-mcmahan11b, tammelin2014solving, johanson2012finding, lanctot2009monte, brown2019deep, brown2020combining, perolat2021poincare, sokota2022unified, stratego, sog} (see summary in Tab.~\ref{tab:complexity}). These algorithms all have computational complexities increasing with $|\mathcal{A}|$, provided that the equilibrium behavioral strategy lies in the interior of the simplex $\Delta(|\mathcal{A}|)$. Critically, this assumption does not hold for differential games equipped with the Isaacs' condition, in which case the equilibrium strategy is mostly pure along the game tree, and is atomic on $\mathcal{A}$ when mixed.
\begin{table}[h!]
    \centering
        \caption{Solver computational complexity with respect to action space $\mathcal{A}$ and equilibrium error $\varepsilon$}
        \vspace{-0.1in}
    \begin{tabularx}{\linewidth}{ X | p{0.24\linewidth} }
    \hline
         Algorithm & Complexity \\
         \hline
         CFR variants~\citep{zinkevich2007regret, lanctot2009monte, brown2019deep, tammelin2014solving,johanson2012finding} & $\mathcal{O}\left(\textcolor{red}{|\mathcal{A}|}\varepsilon^{-2}\right)$ to $\varepsilon$-Nash \\ \hline
         FTRL variants \& MMD ~\citep{pmlr-v15-mcmahan11b, perolat2021poincare, sokota2022unified} & $\mathcal{O}\left(\frac{\ln(\textcolor{red}{|\mathcal{A}|})}{\varepsilon}\ln\left(\frac{1}{\varepsilon}\right)\right)$ to $\varepsilon$-QRE \\
    \hline
    \end{tabularx}
    \label{tab:complexity}
    \vspace{-0.2in}
\end{table}
\paragraph{Descent-ascent algorithms for nonconvex-nonconcave minimax problems.} Existing developments in IIEFGs focused on convex-concave minimax problems due to the bilinear form of the expected payoff through the conversion of games to their normal forms. This paper, on the other hand, investigates the nonconvex-nonconcave minimax problems to be solved at every infostate when actions are considered continuous. To this end, we use the doubly smoothed gradient descent ascent method (DS-GDA) which has a worst-case complexity of $\mathcal{O}(\varepsilon^{-4})$
~\citep{zheng2023universal}.