\section{Related Works}
\label{sec_background}
\subsection{Omni-Directional Image Machine Vision}
ODI-oriented machine vision research emphasizes understanding the object deformation caused by non-uniform sampling due to sphere-to-planar projection.
%
Preliminary works focused on modifying and adapting regular convolution kernels to produce deformation-aware features.
%
In special, Su \textit{et al.}~\cite{su2017learning} made the first attempt that leverages the knowledge distillation to obtain adaptive kernel sizes for 2D convolution filters.
%
%
%
The following studies have directed their attention toward the adaptation of sampling grid positions of convolution filters~\cite{tateno2018distortion}.
%
SphereNet~\cite{coors2018spherenet}, for instance, is a notable work that has demonstrated the effectiveness of this methodology in tasks such as classification and object detection.
%
Zhao \textit{et al.}~\cite{zhao2018distortion} further leveraged a non-regular grid for each pixel based on its distortion level and convolved the sampled grid using square kernels shared by all pixels, facilitating end-to-end training.
%
Apart from adapting 2D CNN kernels, another approach involves establishing spherical convolution kernels to achieve rotational equivariance and invariance.
%
For instance, Esteves \textit{et al.}~\cite{esteves2018learning} made the first attempt to implement spherical harmonic domain CNN filters via group convolutions.
 %
Meanwhile, Yang \textit{et al.}~\cite{yang2020rotation} and Perraudin \textit{et al.}~\cite{perraudin2019deepsphere} took a different approach by leveraging a graph to represent the spherical image and achieving resilient isometric equivariance transformation through via hierarchical equal area isolatitude pixelization.

%
\subsection{Omni-Directional Image Super-Resolution}
Preliminary ODR-SR models adopted a naive strategy that straightforwardly adopted the checkpoints of planar image SR models and fine-tuned them on the ODIs, resulting in limited performance~\cite{ozcinar2019super}.
%
LAU-Net~\cite{deng2021lau} proposed the first ODI-SR approach that considered the non-uniform sampling characteristics of ODR images. Specifically, a tile-based strategy was introduced, where the ERP images were first split into several regions according to latitude, and the upsampling factors were adaptively assigned.
%
Yoon \textit{et al.}~\cite{yoon2022spheresr} explored the usage of icosahedron projection to minimize sphere-to-planar distortion and proposed a new kernel weight-sharing scheme aligned with the icosahedron projection.
%
Although these methods successfully enhance the performance of ODI-SR by incorporating the spherical characteristics of ODI, the specially designed models involve tedious operations, posing significant obstacles to both running speed and practical implementation and hindering further research of ODI-SR.
%
Moreover, other works have tended to incorporate sphere-to-planar knowledge as side information into the feature extraction process, such as the stretching ratio or distortion map~\cite{yu2023osrt}.
%
However, the naive incorporation method and the sole focus on the feature extraction process prevent these approaches from achieving state-of-the-art performance.
%

\subsection{Implicit Image/Neural Representation}
The implicit neural representation (INR) originates from the modeling of 3D object-shape surfaces~\cite{atzmon2020sal,chen2019learning,michalkiewicz2019implicit} and involves leveraging a multi-layer perceptron function to map coordinates to the signal.
%
Inspired by INR's favorable capacity for recovering fine details of shapes, it has started to be employed in representing planar images, such as in image restoration~\cite{anokhin2021image,dupont2022generative,skorokhodov2021adversarial} and image compression~\cite{strumpler2022implicit}.
%
Preliminary INR involves learning a specific mapping function for a single image, raising concerns about inference time in practical implementation scenarios.
%
As such, recent works tend to explore an implicit representation function space shared by different images~\cite{chen2021learning,song2023ope,nguyen2023single}, where the extracted deep features are also regarded as inputs alongside the coordinates for mapping to the signals, denoted as implicit image function.
%
In the context of image SR, the implicit image function has obtained significant progress, especially in arbitrary-scale image SR, such as SIREN~\cite{sitzmann2020implicit} and LIIF~\cite{chen2021learning}, since the coordinate-to-signal function is well-aligned with continuous image representation.
%
Furthermore, in the ODR-SR domain, SphereSR~\cite{yoon2022spheresr} made the first effort to incorporate INR into spherical coordinates to achieve arbitrary-scale SR processing.
%
However, the spherical implicit image function is performed on a reprojected icosahedron surface and involves a complex convolutional kernel modification process to align with the icosahedron ODI pixel representation. This inevitably limits the performance and inference speed.