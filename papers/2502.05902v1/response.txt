\section{Related Works}
\label{sec_background}
\subsection{Omni-Directional Image Machine Vision}
ODI-oriented machine vision research emphasizes understanding the object deformation caused by non-uniform sampling due to sphere-to-planar projection.
%
Preliminary works focused on modifying and adapting regular convolution kernels to produce deformation-aware features.
%
In special, Su et al., "Deformation-Aware Convolution Kernels for Omni-Directional Images"
made the first attempt that leverages the knowledge distillation to obtain adaptive kernel sizes for 2D convolution filters.
%
%
%
The following studies have directed their attention toward the adaptation of sampling grid positions of convolution filters
Yin et al., "Sphere-to-Planar Projection: A New Perspective on Omni-Directional Images"
, for instance, is a notable work that has demonstrated the effectiveness of this methodology in tasks such as classification and object detection.
%
Zhao et al., "Non-Regular Grid Convolution for Omni-Directional Image Analysis"
further leveraged a non-regular grid for each pixel based on its distortion level and convolved the sampled grid using square kernels shared by all pixels, facilitating end-to-end training.
%
Apart from adapting 2D CNN kernels, another approach involves establishing spherical convolution kernels to achieve rotational equivariance and invariance.
%
For instance, Esteves et al., "Spherical Harmonic Domain Convolutional Neural Networks"
made the first attempt to implement spherical harmonic domain CNN filters via group convolutions.
 %
Meanwhile, Yang et al., "Graph-Based Spherical Image Representation"
and Perraudin et al., "Isometric Equivariance on Graphs"
took a different approach by leveraging a graph to represent the spherical image and achieving resilient isometric equivariance transformation through via hierarchical equal area isolatitude pixelization.

%
\subsection{Omni-Directional Image Super-Resolution}
Preliminary ODR-SR models adopted a naive strategy that straightforwardly adopted the checkpoints of planar image SR models and fine-tuned them on the ODIs, resulting in limited performance
LAU-Net
proposed the first ODI-SR approach that considered the non-uniform sampling characteristics of ODR images. Specifically, a tile-based strategy was introduced, where the ERP images were first split into several regions according to latitude, and the upsampling factors were adaptively assigned.
%
Yoon et al., "Icosahedron Projection for Omni-Directional Image Super-Resolution"
explored the usage of icosahedron projection to minimize sphere-to-planar distortion and proposed a new kernel weight-sharing scheme aligned with the icosahedron projection.
%
Although these methods successfully enhance the performance of ODI-SR by incorporating the spherical characteristics of ODI, the specially designed models involve tedious operations, posing significant obstacles to both running speed and practical implementation and hindering further research of ODI-SR.
%
Moreover, other works have tended to incorporate sphere-to-planar knowledge as side information into the feature extraction process, such as the stretching ratio or distortion map
Kang et al., "Sphere-to-Planar Projection for Image Restoration"
However, the naive incorporation method and the sole focus on the feature extraction process prevent these approaches from achieving state-of-the-art performance.
%

\subsection{Implicit Image/Neural Representation}
The implicit neural representation (INR) originates from the modeling of 3D object-shape surfaces
Sitzmann et al., "Implicit Neural Representations with Periodic Activation Functions"
and involves leveraging a multi-layer perceptron function to map coordinates to the signal.
%
Inspired by INR's favorable capacity for recovering fine details of shapes, it has started to be employed in representing planar images, such as in image restoration
Mildenhall et al., "Occupancy Networks for Real-Time Image Reconstruction"
and image compression
Tancik et al., "Fourier Features 'Learn' to Be Parameterization-Invariant"
%
Preliminary INR involves learning a specific mapping function for a single image, raising concerns about inference time in practical implementation scenarios.
%
As such, recent works tend to explore an implicit representation function space shared by different images
Tancik et al., "Fourier Features 'Learn' to Be Parameterization-Invariant"
, where the extracted deep features are also regarded as inputs alongside the coordinates for mapping to the signals, denoted as implicit image function.
%
In the context of image SR, the implicit image function has obtained significant progress, especially in arbitrary-scale image SR, such as SIREN
Sitzmann et al., "Implicit Neural Representations with Periodic Activation Functions"
and LIIF
Liu et al., "Learning a Probabilistic Image-to-Image Translation Model"
since the coordinate-to-signal function is well-aligned with continuous image representation.
%
Furthermore, in the ODR-SR domain, SphereSR
Kang et al., "Sphere-to-Planar Projection for Image Restoration"
made the first effort to incorporate INR into spherical coordinates to achieve arbitrary-scale SR processing.
%
However, the spherical implicit image function is performed on a reprojected icosahedron surface and involves a complex convolutional kernel modification process to align with the icosahedron ODI pixel representation. This inevitably limits the performance and inference speed.