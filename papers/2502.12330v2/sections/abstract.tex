\begin{abstract}
% The design of modern imitation learning (IL) policies requires many design choices, such as feature encoding, architecture, type of policy representation, and many more. With the recent fast progress, the number of options grows rapidly, leading to a vast design space for IL policies that remains largely unexplored. In this work, we present an accessible open-source framework that systematically explores the design space of imitation learning policies. Its modular design facilitates easy swapping of policy components, enabling thorough experimentation and yielding novel policy configurations that outperform existing methods on recent robot learning benchmarks. Our experiments not only demonstrate significant performance gains but also offer valuable insights into the strengths and weaknesses of different design choices. This study serves as a valuable reference for practitioners and informs future research in the field.  

Designing modern imitation learning (IL) policies requires making numerous decisions, including the selection of feature encoding, architecture, policy representation, and more. As the field rapidly advances, the range of available options continues to grow, creating a vast and largely unexplored design space for IL policies.
In this work, we present \textbf{X-IL}, an accessible open-source framework designed to systematically explore this design space. The framework's modular design enables seamless swapping of policy components, such as backbones (e.g., Transformer, Mamba, xLSTM) and policy optimization techniques (e.g., Score-matching, Flow-matching). This flexibility facilitates comprehensive experimentation and has led to the discovery of novel policy configurations that outperform existing methods on recent robot learning benchmarks. Our experiments demonstrate not only significant performance gains but also provide valuable insights into the strengths and weaknesses of various design choices. This study serves as both a practical reference for practitioners and a foundation for guiding future research in imitation learning. Code available at this  \href{https://github.com/ALRhub/X_IL}{link}.

    % We introduce a modular imitation learning framework that integrates diverse input modalities, architectures, and policy designs for robotic learning. Supporting 2D RGB and 3D point cloud inputs, it features flexible encoders (MLP, ResNet, ViT) and architectures (Transformer, Mamba, XLSTM) in decoder-only and encoder-decoder designs. Notably, Mamba and xLSTM, rarely explored in imitation learning, provide alternatives to Transformer-based policies. The framework also supports various policy heads (BC, DDPM, BESO, Flow Matching) and allows components to be interchanged and combined, facilitating the creation of new model configurations. We evaluate it extensively on push-T, LIBERO, and RoboCasa with both 2D and 3D inputs, demonstrating strong performance across tasks. Our results highlight XLSTMâ€™s superiority over Transformer and Mamba, showcasing its potential for imitation learning. This modular approach enables efficient experimentation and deployment, advancing imitation learning in robotics.
    %

%     Imitation learning (IL) is the standard approach for teaching robot dexterous skills. However, we identify several shortcomings of the current state of IL: 

%     Why do we need this thing? What is the draw-back of current frameworks
%     \begin{enumerate}
%         \item (Some representations are under-explored). Exploring 3D representations (Point clouds) 
%         \item Different diffusion variants are typically compared in different settings and tasks. 
%         \item Some new architectures are under-explored or haven't even been tested in the context of IL.
%         \item Often implementations are distributed across various code bases making it hard to compare them and slowing down research
%     \end{enumerate}
%     %
%     \begin{enumerate}
%         \item Easy-to-use
%     \end{enumerate}

% Main contribution:
% - We have Mamba, xLSTM (show very good performance)
% - Support point clouds and 2D vision based
% - We have modularity and we show that certain combinations are able to outperform current state-of-the-art models
% - Our findings provide insights into strengths
% and weaknesses of existing IL methods,
% serving as a valuable reference for future developments.


% Ellucidating the design space of policies for imitation learning
% Learning Transformer-based Diffusion models based on RGB inputs has emerged as the standard method for training imitation learning policies. While there are several works that investigate XYZ, other design choices remain largely unexplored, such as the type of sequence model, input modality, policy representation, and many more. 

%  We introduce an easy-to-use open-source framework that investigates the design space of imitation learning policies. The modular structure allows for easily exchanging different components of the policy allowing for a systematic analysis. Trough this modular structure, we find novel policy configurations which significantly outperform existing ones. Moreover, our experiments provide insights into strengths and weaknesses of existing design choices,
% serving as a valuable reference for both, practioneer and future research. 


    
\end{abstract}