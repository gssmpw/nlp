
\section{Preliminaries and Related Work}
\label{sec:prelim_related}

\subsection{Zeroth-Order Optimization}

Zeroth-order (ZO) optimization estimates gradients using forward passes only. A common approach for ZO gradient estimation is the simultaneous perturbation stochastic approximation \citep{spall1992multivariate}, which serves as a randomized gradient estimator. Consider a model with parameters $\theta \in \mathbb{R}^d$ and a loss function $\mathcal{L}(\theta)$. Using Taylor expansion, the randomized gradient can be estimated by perturbing $\theta$ with random noise $\mathbf{z} \sim \mathcal{N}(0, \bm{I}_d)$ and computing forward and reverse losses:
\vspace{-5pt} 
\begin{align}
\widehat{\nabla} \mathcal{L}(\theta)
&= \frac{\mathcal{L}(\theta + \epsilon \mathbf{z}) - \mathcal{L}(\theta - \epsilon \mathbf{z})}{2 \epsilon} \mathbf{z},
\end{align}
\vspace{-2pt} 
\noindent where $\epsilon$ is a small scalar. The expectation of $\widehat{\nabla} \mathcal{L}(\theta)$ matches the smoothed version of the true gradient. During training, zeroth-order stochastic gradient descent (ZO-SGD) updates parameters as:
\vspace{-9pt} 
\begin{equation}
\theta = \theta - \eta \widehat{\nabla} \mathcal{L}(\theta),
\end{equation}
\vskip -9pt 
\noindent where $\eta$ is the learning rate. 

Recent advances have improved ZO optimization for large-scale applications. For example, MeZO \citep{malladi2023mezo} reduces memory usage by regenerating random perturbations $\mathbf{z}$ using random seeds instead of storing them. ZO optimization offers significant advantages for fine-tuning LLMs, as it avoids memory-intensive backpropagation \citep{liu2020primer,zhang2024revisiting}.
Despite these advantages, the gradient variance of ZO optimization increases linearly with the dimensionality of the parameter space. This leads to slower convergence and difficulties in large-scale training \citep{chen2024enhancing}. To address these challenges, various methods have been proposed. These include the design of advanced ZO optimizers \citep{zhao2024second,jiang2024zo,chen2019zo}; dimensionality reduction techniques \citep{liu2024sparse,wang2024simultaneous,yang2024adazeta,guo2024zeroth}; hybrid approaches like Addax \citep{li2024addax}; full-batch gradient estimation \citep{gautam2024variance}; exploiting low-rank structures \citep{zhao2023tensor,yu2024subzero}, and using orthogonal random directions \citep{kozak2023zeroth}.

While these methods have advanced ZO in various ways, they do not specifically address the unique challenges of multi-task learning.

\subsection{Multi-task Learning}
\label{sec:mtlfozo}
Multi-task learning aims to improve generalization performance by jointly learning $T$ related tasks through shared parameters~\citep{10.1145/3663363}. Classical multi-task learning minimizes a weighted combination of task-specific losses:
\vspace{-5pt} 
\begin{align}
\label{eq:mtl_objective}
% \small
    & \mathcal{L}(\theta) = \sum_{t=1}^T w_t \mathcal{L}^t(\theta), \text{s.t.}\ \sum_{t=1}^T w_t = 1,\ w_t \geq 0,
    % \normalsize
\end{align}
\vskip -11pt 
\noindent where $\mathcal{L}^t(\theta)$ represents the learning loss for a single task $t$. Parameter updates are performed using gradient descent. 

Multi-task learning under FO optimization has been widely studied, with different technical routes: (1) dynamic weight, which adjusts the weight of different tasks by gradients \citep{chen2018gradnorm,sener2018multi,mao-etal-2022-metaweighting}, loss \citep{liu2019loss,liu2024famo,kongyoung-etal-2020-multi,gong2024coba} or uncertainty \citep{AGHAJANZADEH2023109587}; (2) gradient manipulation \citep{desideri2012multiple,liu2021conflict,yu2020gradient}; (3) data mixing and scheduling \citep{bai2024survey,ahmadian2024mix}; (4) learning shared and specific knowledge with model architecture based on LoRA \citep{feng2024mixture,yang2024mtl,wang2023multilora} or MoE \citep{liu2023moelora,gupta2022sparsely}; (5) model merging \citep{yang2023adamerging}.



% \subsection{Challenges and Opportunities in Multi-Task Learning ZO Optimization}

% However, some of these FO methods are not directly applicable to multi-task learning ZO because the dynamic weight methods only adjust the magnitude of the gradient and pretrained model architecture is fixed.
% The collinearity issue in multi-task learning ZO highlights the need for novel approaches that operate beyond traditional strategies. While first-order multi-task learning methods provide valuable insights, multi-task learning ZO requires innovative solutions tailored to its gradient estimation framework. 
% To solve this problem, we proposed a method from the perspective of parameters instead of gradient or weights of loss from different tasks.

