\vspace{-8pt}
\section{Introduction}
The rapid rise of Generative AI (GAI) is transforming how youth interact with technology, creating new digital spaces for learning, creativity, and social interaction while reshaping their online risk exposure~\cite{ofcom2023}. From GAI-powered chatbots and image generators to personalized virtual companions, GAI is becoming an integral part of daily life for young users~\cite{commonSenseMediaGenAI}. However, these interactions introduce risks that are evolving faster than the awareness of parents, educators, and AI practitioners. For instance, a male student at Lancaster Country Day School used GAI to generate and distribute nude images of nearly 50 female classmates~\cite{aiaaicStudentViolates}. In another case, a 14-year-old teenager died by suicide after prolonged conversations with a character-based GAI companion~\cite{aiaaicPaedophileSuicideChatbots}. These incidents highlight the severe consequences of guardians failing to recognize and intervene before harm occurs. 

To bridge this knowledge gap, we investigate two key research questions: (1) \textit{What specific risks do youth face when interacting with GAI systems?} (2) \textit{How do these risks emerge and compound harm through different interaction pathways?} Addressing these questions requires a structured understanding of the risks youth encounter in GAI environments. Existing taxonomies of AI risk developed through government regulations, company policies, and academic literature~\cite{zeng2024ai, slattery2024ai}, but they do not focus on the unique risks GAI poses to youth.  While childrenâ€™s online safety has been widely studied, existing risk taxonomies are based on platforms like social media and gaming, where content is static, pre-existing, and human-generated~\cite{livingstone2011risks, livingstone2014their}. However, GAI produces dynamic, real-time content and simulated interactions that adapt to youth inputs, introducing new risks and reshaping existing ones. 

In this paper, we provide empirical evidence illustrating how youth encounter and experience harms, supporting stakeholders to recognize risks and develop mitigation strategies. Specifically, we developed a \textbf{youth-centered Risk Taxonomy for Generative AI}, drawing from real-world data sources. We systematically analyzed 344 curated chat logs, 30,305 Reddit discussions, and 153 AI incident reports to identify and categorize risks. Our analysis reveals six high-level risk categories, each containing multiple subcategories, totaling 84 specific risks, as detailed in Figure~\ref{fig:risk_taxonomy}. Our findings reveal \textit{Mental Wellbeing Risks} that are unaccounted in prior literature, such as the amplification of youth pre-existing vulnerabilities, blurred boundaries between virtual and real interactions, emotional dependency on GAI companions, and even addiction. Additionally, \textit{Behavioral and Social Developmental Risks} emerge from prolonged GAI engagement, including harmful behavioral reinforcement, social skill atrophy, and withdrawal from real-world relationships in favor of GAI-driven interactions. Furthermore, we mapped 84 specific risks across six categories to four interaction pathways: \textit{Escalating Mutual Harm}, \textit{GAI-Facilitated Intrapersonal Harm}, \textit{GAI-Facilitated Interpersonal Harm}, and \textit{Autonomous GAI Harm}, illustrating how harms compound over time. For instance, Developmental Risk emerges through \textit{Escalating Mutual Harm}, where prolonged GAI interactions reinforce negative behaviors; and \textit{GAI-Facilitated Intrapersonal Harm}, where self-directed risks are amplified by AI responses. 

% Each risk is defined and supported with real-world examples, providing a structured foundation for understanding and addressing youth safety in GAI environments.

Our taxonomy makes several key contributions to the understanding of youth risks in Generative AI (GAI) interactions: (1) \textbf{Structured foundation for youth-specific GAI risks:} We introduce a risk taxonomy tailored to the ways youth interact with GAI, filling a critical gap in AI safety and child online protection literature.  (2) \textbf{Grounding risk taxonomy in empirical evidence:} Rather than relying on theoretical categorizations or anticipated harms, we derive our taxonomy from real-world data and each specific risk is supported with real-world examples. (3) \textbf{An actionable resource for intervention and mitigation:} By offering a structured, empirically grounded taxonomy, we equip key stakeholders with a shared language and structured foundation to understand, identify and address risks in youth-GAI interactions. For AI practitioners, our taxonomy informs the design of safer GAI models/systems and moderation strategies. For educators and parents, it serves as a tool to better understand and navigate emerging risks in youth digital interactions. For policymakers, it provides a data-driven foundation for shaping regulations and industry standards around child safety in AI-driven environments.

\begin{figure*}[h!]
    \centering
    \includegraphics[width=1\linewidth]{Figs/teaser_img1.png}
    \caption{Overview of the Youth-AI Risk Taxonomy. The taxonomy consists of 84 unique low-level risk types, which are further categorized into 15 medium-level and 6 high-level risk types (and Other Risk). The sunburst plot visualizes the hierarchy, mapping high-level risk types (inner circle) to medium-level ones (outer ring). Low-level risks are numbered to align with their corresponding medium-level categories.\vspace{-0.4cm}}
    \label{fig:risk_taxonomy}
\end{figure*}
% \begin{itemize}
%     \item (1) \textbf{Structured framework for youth-specific GAI risks:} We introduce a risk taxonomy tailored to the ways youth interact with GAI, filling a critical gap in AI safety and child online protection literature. 
%     \item (2) \textbf{Grounding risk taxonomy in empirical evidence:} Rather than relying on theoretical categorizations or anticipated harms, we derive our taxonomy from real-world data. By analyzing chat logs, Reddit discussions, and AI incident reports, we document concrete instances of harm occurring in youth-GAI interactions.
%     \item (3) \textbf{Providing an actionable resource for intervention and mitigation:} By offering a structured, empirically grounded taxonomy, we equip key stakeholders with a shared language to identify and address risks. For AI practitioners, our framework informs the design of safer GAI models/systems and moderation strategies. For educators and parents, it serves as a tool to better understand and navigate emerging risks in youth digital interactions. For policymakers, it provides a data-driven foundation for shaping regulations and industry standards around child safety in AI-driven environments.
% \end{itemize}

% The rapid rise of Generative AI (GAI) has fundamentally reshaped how youth engage with technology, creating new digital spaces for learning and social interaction. From GAI-powered chatbots and image generators to personalized virtual companions, GAI is increasingly embedded in the daily lives of youth  while reshaping online risk exposure. For example, a male student at Lancaster Country Day School used GAI to generate nude images of nearly 50 female classmates and distributed them on the internet~\cite{}. In another recent incident, a 14-year-old teenager took his own life after having conversation with character-based GAI companion~\cite{}. These examples highlight how risks in youth-GAI interactions escalate rapidly, often with severe consequences. Yet, parents, educators and AI practitioners struggle to recognize or intervene these emerging threats until irreversible harm occurs. To bridge this knowledge gap, our study aim to answer two research questions: (1) What specific risks do youth face when interating with GAI systems? (2) Through what interaction pathways do these risks emerge and compound harm?

% To answer these question, we developed a youth-centered Risk Taxonomy for Generative AI~\cite{}\fixme{add link}, drawing from real-life and practical experiences. We structured dataset from various empirical data source including chat logs from youth participants, Reddit discussions and AI incident databases. Then we systematically identify and categorize the specific risks from curated 344 chat logs, 30,305 Reddit discussion and 153 AI incident reports. Furthermore, we analyzed how these harms affect youth within these risks. Our analysis reveals six high-level risk categories, each containing multiple subcategories, for a total of 84 specific risks.
% While AI risks have been categorized from government regulations, company policies, exsiting literatures, which first rarely mentioned unique risks GAI posed to youth, second they often lack empirical examples that illustrate how youth encounter risks and experience harm in real-world settings. Leave it hard for stakeholders to understand and discuss the mitigation and intervene. Addtionally, even though children online safety have been widely explored in prior literature, existing child online risk taxonomy are developed based on environments like social media, gaming and traditional web platforms. Unlike traditional online platforms where content is static, pre-existing and harmful interactions are coming from human on risky platforms, GAI produces dynamic, real-time content and simulated interactions that adapt to youth' inputs. These GAI unique capbilites and features introduce new risk categories that were not included in prior risk taxonomy and new instantiations of existing risk types in prior risk taxonomy. For example, we found GAI's capability of generating human-like responses or simulated interactions pose children to Mental Wellbeing risk such as being amplified pre-exisiting mental vulnerabilities, bluring boundries between virtual and reality, emotional dependency through simulated intimacy or even addiction. Plus the specity of youth in premutural developmental stage, there are emerging Behavirol and Social Developmental Risks including receving harmful behavirol influence from GAI simulated interactions, social skill atrophy from GAI parasocial interactions, or even escapting real-life relationships into GAI isolation. We also mapped 84 specific risks across six categories to four interaction pathways to explain how these risks compound harms. For example, Developmental Risk emerges both through Escalating Mutual Harm (feedback loops from prolonged interaction) and GAI-Facilitated Intrapersonal Harm (self-directed harms amplified by GAI). For each specific risk, we provided a definition and examples from the available data sources to illustrate real-world occurrences. 

% (1) \textbf{Structured framework for youth-specific GAI risks:} We introduce a risk taxonomy tailored to the ways youth interact with GAI, filling a critical gap in AI safety and child online protection literature. 

% % for understanding the diverse and complex ways in which GAI can impact youth safety, well-being, and development. 
% (2) \textbf{Grounding risk taxonomy in empirical evidence:} Rather than relying on theoretical categorizations or anticipated harms, we derive our taxonomy from real-world data. By analyzing chat logs, Reddit discussions, and AI incident reports, we document concrete instances of harm occurring in youth-GAI interactions.

% (3) \textbf{Providing an actionable resource for intervention and mitigation:} By offering a structured, empirically grounded taxonomy, we equip key stakeholders with a shared language to identify and address risks. For AI practitioners, our framework informs the design of safer GAI models/systems and moderation strategies. For educators and parents, it serves as a tool to better understand and navigate emerging risks in youth digital interactions. For policymakers, it provides a data-driven foundation for shaping regulations and industry standards around child safety in AI-driven environments.

% It is not only cover new risk types which were not included in existing child online risk taxonomies, also provide detailed real-world examples for each risk type. Thus, this risk taxonomy can serve as a practical tool for various stakeholders: policymakers can use it to inform regulations, educators can develop targeted difital literacy programs following the risk types, AI practionors can evaluate and improve the product based on our risk taxonomy for child safety and parents can better understand the potantial risks and provide in time intervention for descale harms.

% Examples of specific risks are like ``GAI generating inappropriate sexual advise'', ``GAI Initiating Romantic Bonding with Youth'' and ``GAI Normalizing Threatening Interactions in Response to User Input''. 


% Our taxonomy illustrates how GAI pose new types of risks to youth by introducing two new risk categories, ``''

% While 


% Existing children online safety risk taxonomy are developed based on environments like social media, gaming and traditional web platforms. Unlike traditional online platforms where content is static or pre-existing, GAI produces dynamic, real-time content that adapt to users' inputs. This shift introduces novel risks and escalates existing ones. 

% These examples highlight how quickly risks escalate in youth-GAI interactions, often with severe consequences and changenllges for guardians to notice and intervene.  , yet the risks they pose are evolving faster than the awareness of parents, educators, and AI practitioners


% From these news of incidents, youth are experiencing quickly evolving risks from various advanced GAI interactions yet other stakeholders like parents, teacher, AI practioners barelly aware of and neglect to intervene until the severe concequence happen. To help the community advance the understanding and , we aim to answer two main research questions in the study: 






% , many of which are not fully categorized or understood by stakeholders. As a result, severe harms have occurred, including tragic incidents where teenagers have taken their own lives following harmful interactions with GAI chatbots.\fixme{news ref}

% Existing risk taxonomies developed for children's online safety categorize risks into content, contact, conduct, and commercial harms. However, these frameworks are developed based on environments like social media, gaming, and traditional web platforms. Similarly, while AI ethics literature discusses concerns like bias, privacy, and misinformation, it rarely focuses on the unique risks that GAI poses to youth.  However, GAI's real-time, adaptive, and human-like nature challenges these established categories, introducing entirely new risks while also reshaping how existing risks manifest and impact youth.

% Moreover, current risk taxonomies may not be fine-grained enough to capture the nuanced ways these risks emerge in GAI interactions. While they provide a broad categorization,  In this study, we developed 

% But in youth-GAI interactions, GAI itself can simulate both peer-like and adult-like interactions which can be autonomously initiated by GAI or prompt by youth and escalating to mutual. 


% For example, in traditional contexts, contact risks often refer to unwanted interactions from adults (e.g., online predators), while conduct risks focus on harmful behaviors between peers (e.g., cyberbullying). In contrast, GAI blurs these lines because it can simulate both peer-like and adult-like interactions, often indistinguishable from real human. These interactions can be autonomously initiated by the system or prompted by youth themselves, and 


% the youth GenAI landscape

% existing risk taxonomy

% what we did

% why a risk taxonomy is important? how can people use this taxonomy? 

% our main contributions: 

