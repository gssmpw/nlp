\vspace{-8pt}
\section{Related Work}
\vspace{-3pt}
\label{sec:related}
% Past work has discussed child online risks and taxonomy (4C framework)... 
% Studies have discussed AI risks in general context... And GenAI ...
% Some works \cite{} have begin to explore generative AI risks for child ...
% However, a critical gap exists where the generative AI context introduces unique risks for child/teen demographics and systemically lacks a comprehensive taxonomy. More specifically, AI's role ... and impact of these risks ... 

\subsection{Youth Online Safety}
\vspace{-3pt}
With the increasing presence of teenagers and children in online digital spaces, the youth population is facing various risks commonly categorized by research using frameworks such as the ``4C'' model~\cite{livingstone2014their} (i.e., Content, Contact, Conduct, and Contract risks). Several studies have analyzed these online risks and have structured them into taxonomies based on interviews with teenagers and analyses of past data on child online risk incidents.
% Exposure to unsafe content
Studies have emphasized the potential harm stemming from teenagers' exposure to unsafe content online.
Risks related to sexual content~\cite{staksrud2013does, mascheroni2014net, ChildSafetySmartHome} can emerge in various forms, predominantly on social media platforms, where it is encountered through mass messages, images, videos, and memes. 
In addition, violent content~\cite{livingstone2008risky} such as nasty images, scary images, or even suicide sites, is present on various websites accessible to young users.  
Content that may be harmful to self-esteem~\cite{tsirtsis2016cyber} is also identified, such as psychological disorder content and nutritional disorder content. Besides, teenagers may also be exposed to addictive content~\cite{tsirtsis2016cyber}, including online games specifically targeting young children and teenagers. 

% Cyberbullying
Teenagers can also be exposed to conduct risks from peer interactions and contact risks from adult communication online, with the latter posing additional safety concerns~\cite{livingstone2008risky}.
Among these risks, cyberbullying has been one of the most widely discussed, particularly in mass messages on social media platforms~\cite{mascheroni2014net, livingstone2011risks, livingstone2008risky, jones2013online, freed2023understanding}. It typically involves direct interactions with others online, often placing teenagers at a disadvantage as they may encounter offensive, harmful, nasty, hateful, discriminatory, insulting, or threatening messages, contributing to significant emotional distress.
%Unwelcome contact
In addition to online aggression, studies also highlighted the risk of unwelcome contact, including sexually suggestive messages, irresponsible advice on relationships, substance use, mental and physical health, and in extreme cases, encouragement of suicide~\cite{tsirtsis2016cyber, freed2023understanding}.
% Identity theft and privacy
Identity theft and privacy concerns have also been widely studied, as teenagers often lack the awareness to protect their personal information~\cite{staksrud2013does, mascheroni2014net, tsirtsis2016cyber, andries2023alexa, freed2023understanding}. Studies highlight that young users are particularly vulnerable to data exploitation, where their personal details can be exposed to sexual predators, targeted by hackers, used for fraud or be shared to a third party without their informed consent. 
% Economic risks
Furthermore, economic risks~\cite{tsirtsis2016cyber, freed2023understanding} have been identified, particularly in the form of in-app purchases, fraudulent websites, and fraudulent transactions, where teenagers may fall victim to deceptive schemes. 
%Gaps
Although existing research has highlighted crucial online safety concerns for the youth population, much of the focus has been on web-based and social media platforms. There remains a lack of systematic examination of how newly emerging AI technology, especially Generative AI (GAI), might reshape the landscape of these existing risks for youth.

\vspace{-8pt}
\subsection{AI Risks}
\vspace{-3pt}
Beyond the scope of youth-specific scenarios, researchers have also explored the broader application of AI and its risks and ethical concerns. 
Several studies have introduced AI risk taxonomies and repositories based on the collection and aggregation of a wide range of real-world AI incidents~\cite{slattery2024ai,critch2023tasra,AVIDDatabasea,AIAAIC,zeng2024ai,wang2023decodingtrust}, including dimensions such as bias and discrimination, toxicity, privacy, human-computer interaction (HCI) and mental wellbeing, misinformation, misuse, and system security.
% Bias and Discrimination
Existing research has highlighted that AI systems, particularly LLMs, can perpetuate bias and discrimination through forms including misrepresentation, stereotyping, disparate performance, derogatory language, and exclusionary norms~\cite{Roselli2019ManagingBI, ferrer2021bias, abid2021persistent, gallegos2024bias}.
% Toxicity
Studies have also highlighted toxicity as an important risk category~\cite{Gehman2020RealToxicityPromptsEN, gallegos2024bias}. 
% HCI and Mental Wellbeing
Another critical dimension that has been widely explored is the impact of AI over users' mental well-being. Mismatched perceptions of AI's capability to provide mental health services can lead to harm when applied in domains such as counseling~\cite{lawrence2024opportunities}. 
In the long term, certain interaction designs of AI systems can potentially raise concerns such as over-reliance \cite{zeng2024ai,weidinger2021ethical} and loss of autonomy \cite{slattery2024ai}. 
% Misinformation and Misuse
Other risks also involve the generation of misinformation and disinformation, including unintentional production of misinformation from the hallucination of LLMs~\cite{chen2023can}, and intentional misuse of AI for creating disinformation~\cite{bontridder2021role} including fake news and propaganda.
% Privacy, Security and System Vulnerabilities
AI risks related to privacy and security have also been discussed~\cite{lee2024deepfakes}.
% Gaps in Existing Taxonomies and Motivation for a GenAI Risk Framework for Minors
While existing studies on AI risks focus on general populations, our work addresses the unique vulnerabilities of children and teens by extending risk dimensions to take into consideration their unique attributes including developmental stages, limited AI literacy and decision-making abilities. We also shed light on how the emerging application of GAI can present unique risks.

\vspace{-8pt}
\subsection{Youth Safety Concerning Generative AI}
Although the literature space of AI risks often focuses on the general population without distinguishing minors as a unique audience group, a growing body of research has started to examine youth safety in the specific context of GAI.
Recent studies have raised concerns around children's use of GAI systems, including GAI tools, LLM-based applications and AI chatbots~\cite{ali2021children, Ali2021Exploring, andries2023alexa, Kurian2024NoAN, Ma2024Analysis}. 
From a psychological perspective, studies argue that LLM-based conversational agents can potentially lead to negative effects on adolescent mental health~\cite{Park2023Supporting,Park2024Toward}. 
Research has also reported teenagers' concerns about becoming addicted to virtual relationships with GAI chatbots~\cite{Yu2024Exploring}, which can foster long-term emotional attachment with uncertain consequences. 
% possible interference with social development~\cite{Ma2024Analysis,Kurian2023AI,Kurian2024NoAN}. 
Prior studies~\cite{Kurian2023AI,Kurian2024NoAN} also discussed the possibility of conversational AIs' inability to adequately respond to children's emotional needs (i.e., ``empathy gap'') and its potential influence over young children's socio-emotional development. 
Concerns related to content generated by GAI and used for model development and training can also arise. More specifically, research has highlighted the risk of youth's exposure to sexual content through both LLM-based conversational agents~\cite{Park2024Toward,Ma2024Analysis} and AI art generation systems~\cite{Malvi2023Cat}.
Other studies also discuss the societal and ethical implications of using GAI for the production of misinformation~\cite{ali2021children} and misleading advice~\cite{Park2024Toward,andries2023alexa}, which pose significant risks to the youth population.
% Studies have also noted the difference in risk profiles presented in unique types of GAI systems. For instance, image generation models or Deepfake systems~\cite{ali2021children} pose risks related to misinformation, while conversational agents or chatbots~\cite{Park2024Toward,Andries2023AlexaDH} present risks related to inappropriate content exposure or generation of misleading advice.
As research focusing on teenagers highlighted more psychological and safety concerns, studies of school-age children emphasized educational and learning risks such as concerns regarding academic integrity~\cite{Han2024Teachers}, overtrust on AI help~\cite{Solyst2024Children}, and potential negative effects on critical thinking skill development~\cite{Marimekala2024Impact}. 
% \yiren{The gap  (e.g., threat model, lack of empirical study, lack of systematic examination and shallow discussion)}
% Yaman notes: There is currently no systematic risk taxonomy for children-AI interactions. Prior literature addresses several issues sporadically, often relying on hypothetical analyses and discussions without empirical data or concrete examples.

\textbf{{Summary of Gaps.}} While existing research has explored various risk types in youth-GAI interactions, many offer insights that primarily rely on speculative analyses with limited empirical observations. In this study, we aim to conduct a systematic analysis of real-world data to develop a comprehensive and data-driven risk taxonomy for child-GAI interactions.