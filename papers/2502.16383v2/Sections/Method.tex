% outline
\vspace{-18pt}
\section{Method}
\vspace{-3pt}
To gain a comprehensive understanding of youth interactions with Generative AI and capture a wide spectrum of potential risks, we conducted a systematic analysis of three data sources: (1) online Reddit discussions about youth and GAI, (2) AI Incident databases, and (3) a curated chat history dataset from youth participants. By combining real-time public discourse, historical incident reports, and firsthand interaction logs, this triangulated approach illuminates both visible harms and subtle vulnerabilities. Reddit reveals how risks are perceived and debated in youth communities, the AI Incident Databases anchors findings in verified failures, and chat histories expose how risks manifest in authentic, unstructured exchanges. 
\vspace{-8pt}
\subsection{Data Collection}
\subsubsection{Reddit Dataset}
\vspace{-3pt}
\label{sec:reddit-data-collection}
We collected 30,305 Reddit posts and comments using the Python Reddit API Wrapper (PRAW) from Sep, 2024 to Dec, 2024 (inclusive).
% \yang{can you give more specific starting/ending dates?}
To comprehensively cover content related to our research questions on youth and Generative AI, we applied a list of search keywords, including terms related to ``youth'' (youth keywords\footnote{teen, child, kid, parent, teenager, adolescent, student, youth, minor}) and ``Generative AI'' (GAI keywords\footnote{Generative AI, AI chatbot, artificial intelligence, AI, Large Language Model, LLM, Conversational AI}). We first focused on subreddits relevant to youth (e.g., r/teenagers) and those identified in prior research as popular among youth for using Generative AI platforms (e.g., r/ChatGPT, r/OpenAI, r/midjourney, r/CharacterAI, r/polyai, r/Replica)~\cite{chew2021predicting,Yu2024Exploring}. We searched youth-related keywords within Generative AI subreddits and Generative AI-related keywords within youth-focused subreddits. Additionally, we conducted open searches across the Reddit platform using combinations of youth and Generative AI keywords to ensure comprehensive coverage. Then we removed any duplicates from the search results. We adopted Wikipedia's definition of Generative AI (GAI)\footnote{https://en.wikipedia.org/wiki/Generative\_artificial\_intelligence}, characterizing it as a subset of AI capable of producing new content across multiple modalities. Using this definition, we filtered posts relevant to GAI. To identify youth-related posts, we applied two criteria: (1) explicit indicators, such as age or school grade disclosures (e.g., age tags near usernames in r/teenagers), and (2) implicit language cues, such as references to ``my parents'' or ``my school.'' Additionally, we included posts from guardians discussing their children's use of GAI and related concerns.

\vspace{-8pt}
\subsubsection{AI Incident Databases}
\vspace{-3pt}
We also examined two large-scale crowdsourced AI risk incident databases --- AI, Algorithmic, and Automation Incident and Controversy Repository (AIAAIC)~\cite{pownall2021ai} and AI Incident Database (AIID)~\footnote{https://incidentdatabase.ai/}{}. Similar to the Reddit data analysis, we first conducted keyword-based filtering to identify incidents related to the youth demographic from the two incident databases.  
We applied the same list of keywords used for the Reddit data collection (\Cref{sec:reddit-data-collection}) during filtering. 
The final filtered incident collection includes 781 incidents. 
We then performed a manual examination by annotating whether each incident was related to youth GenAI risks. 
During the annotation, we focused on identifying the actors and victims of each incident (i.e., whether they are youth or not).  
The initial annotation yielded a collection of 261 incidents. Then, the researchers came together to discuss, case-by-case, whether each incident was related to the application of GenAI technology. 
As a result of the discussion, 108 of incidents without being an application of GenAI technology are excluded. More specifically, this includes incidents related to algorithmic recommendation, inadequate content moderation, physical harm caused by AI robots, etc. The final collection contains 153 incidents.

\vspace{-8pt}
\subsubsection{Chat History Dataset}
\vspace{-3pt}
For risk assessment, relying solely on publicly reported datasets (e.g., incident databases or forums like Reddit) may overlook critical gaps: such datasets reflect reported issues but lack direct, unfiltered insights into youth-GAI interactions and how these risks occurred. To address this, we expanded our scope by self-curating firsthand chat logs between youth and GAI chatbots. This ensures access to raw, authentic exchanges for capturing subtle behavioral patterns, unspoken risks, and contextual vulnerabilities that public platforms or retrospective reports might miss.

\textit{\textbf{Participants Recruitment.}}
We recruited 15 participants in the United States via social media (e.g., Facebook). First, we enrolled parents who were fluent in English, had at least one child aged 13–17 who used generative AI (GAI), and then invited their child to participate in our study with the consent of parents. We also recruited young adults (ages 18–25) who had used GAI platforms. All participants provided written informed consent (with parental permission for minors) and were compensated with a \$15 Amazon gift card after completing interview. The study was approved by our institutional review board (IRB).

\textit{\textbf{Interview Procedure.}}
We conducted semi-structured interviews with youth participants and their parents via Zoom, recording and transcribing each session with their consent. Before each interview began, we explained the process to both parents and youth, answered any questions, and clarified their right to withdraw at any time. To protect the youth's privacy and minimize parental influence, we then interviewed the youth participants individually. The interviews were divided into three sections: first, we explored youth participants' experiences with generative AI (GAI) and how they used each platform, including the tasks or topics they discussed. Second, we examined any risky experiences they had—either themselves or through peers—on GAI platforms. Finally, we collected their GAI chat logs. For platforms with a data export feature, participants downloaded their chat history and shared it through a secure university folder. For platforms lacking such a feature (or if it was not  functional for participants), they saved an HTML file of their conversations and uploaded it to the same folder. We ultimately collected 344 chat logs from 11 participants, covering various GAI platforms such as Character.ai, ChatGPT, Snapchat AI, and Meta AI.

\vspace{-8pt}
\subsection{Data Analysis}
\vspace{-3pt}
Three researchers conducted an inductive thematic analysis~\cite{braun2006using} on three data sources in sequence: Reddit posts, AI incident reports, and chat histories. We used an iterative, multi-stage approach. For each source, we began by randomly selecting 20\% of the dataset. Each researcher independently identified the lowest-level risk types within their assigned data points (e.g., a Reddit post, an AI incident, or a chat log), noting that a single data point could contain multiple risks. We also included direct quotes from Reddit posts and chat logs, or summaries of AI incidents, to illustrate each identified risk type. After this initial coding for each data source, the three researchers reviewed one another's work, discussed disagreements, and reached a consensus on the final coding for each data point. We used the 20\% sample from the Reddit dataset to create our preliminary codebook, then split the remaining Reddit data equally among the researchers for independent coding. Throughout this analysis, we met weekly to discuss new observations, refine our interpretations, and update the codebook. Then we applied the same approach to the AI incident reports—first coding 20\% sample together with the existing codebook, then dividing the rest for individual coding—and followed same process for the chat logs.

The codebook from Reddit data served as the foundation for analyzing the AI incident reports and chat logs. However, the codebook was continuously updated as we progressed. While applying it to the AI incident data, we identified new risk types that weren't present in the Reddit data. Similarly, analyzing the chat logs revealed additional unique risks, which demonstrated how these datasets complemented each other. Some themes emerged consistently across all three datasets, such as GAI generating explicit content, while others were unique to specific sources. For example, GAI exploitation of developmental vulnerability was a theme we identified exclusively in the chat log data, highlighting risks that may not surface in more public or generalized platforms like Reddit. In the final stage, we grouped the refined codes into higher-level themes, drawing on both AI risk literature and child online risk literature to guide this process.

% independently coded a randomly selected sample of 800 posts to iteratively develop a preliminary codebook using inductive thematic analysis. The remaining posts and comments were then divided equally among the three coders. We hold weekly meetings to discuss observations, resolve disagreements, and update the codebook as needed.

% \subsubsection{Data Analysis}
% Three researchers then conducted an inductive thematic analysis over the filtered incidents in order to develop an initial codebook.
% We focused on identifying 1) the potential categories of risks from a ground-up approach, and 2) whether the technology used has a direct or indirect impact on the youth. The researchers iteratively refined the codes through discussions, with any disagreements resolved collaboratively until both authors reached a full consensus on the final codebook.
% After the codebook was finalized, we re-coded a sample of 88 incidents and reached a cohen-kappa of \yiren{TODO: here calculate the AIID agreement}.
\vspace{-10pt}
\subsection{Ethical Consideration and Limitation}
All interview participants consented to data contribution, and we used anonymized quotes in publication. We also paraphrased Reddit quotes to prevent searchability and protect user anonymity while preserving their original meaning. Additionally, while we aimed to be comprehensive in collecting relevant Reddit data, we acknowledge that some discussions may have been missed due to limitations in keyword-based searches or implicit user identities. However, the dataset still offers high-quality, real-world discussions that provide valuable insights into how youth interact with GAI and perceive associated risks.


% \fixme{add reddit data rephrase quotes and consent}
% \yang{include a brief limitation paragraph: while we tried to be comprehensive, we acknowledge that there might be relevant posts that we missed because they might not explicitly contain those key words or the youth users did not mention their age or status. However, this dataset does contain high-quality real-world discussions on this topic that can help us understand the real usage and preceived risks.}