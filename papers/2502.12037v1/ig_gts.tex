\documentclass[preprint,11pt]{amsart}

\usepackage{graphicx,subfigure}
\usepackage{epstopdf}
\usepackage{amsmath,amsthm,amssymb}
\usepackage{rotating}
\usepackage{morefloats}
\usepackage{comment}
\usepackage{amsmath}
\DeclareMathOperator{\Tr}{Tr}
\newtheorem{thm}{Theorem}
\newtheorem{crl}{Corollary}
\newtheorem{lem}{Lemma}
\newtheorem{cmt}{Comment}
\newtheorem{exmp}{Example}

\begin{document}
\title{Information geometry of tempered stable processes}
\author{Jaehyung Choi}
\address{Goldman Sachs \& Co., 200 West Street, New York, NY 10282, USA}
\email{jj.jaehyung.choi@gmail.com}

\begin{abstract}
	We find information geometry of tempered stable processes. Starting with the derivation of $\alpha$-divergence between two tempered stable processes, Fisher information matrices of tempered stable processes and $\alpha$-connections of their statistical manifolds are obtained. Additionally, we also provide statistical applications for the information geometry of tempered stable processes. Various tempered stable processes such as generalized tempered stable processes, classical tempered stable processes, and rapidly decreasing tempered stable processes are given as examples. 
\end{abstract}

\maketitle
\section{Introduction}
\label{sec_intro}
	Information geometry is an interdisciplinary study across differential geometry, probability theory, statistics, and information theory. With the mathematically elegant structure of Riemannian geometry, information geometry provides new interpretations on statistics and probability theory. Not limited to the mathematical elaboration, the differential geometry of statistical manifolds also provides many practical applications to various probabilistic models.
	
	Time series analysis and signal processing have been empowered by such applications of information geometry. Since the derivation for the information geometry of autoregressive and moving average (ARMA) models \cite{ravishanker1990differential} and fractionally-integrated ARMA (ARFIMA) \cite{ravishanker2001differential}, there have been several approaches to mathematical elaboration for the statistical manifolds of time series models and signal processing filters by introducing symplectic geometry and K\"ahler geometry \cite{barndorff1997statistics, barbaresco2006information, barbaresco2012information, zhang2013symplectic, barbaresco2014koszul, choi2015kahlerian,choi2021kahlerian}. Moreover, the mathematical sophistication and enhancements produce practical applications such as Bayesian predictive priors outperforming the Jeffreys priors and its easier derivation \cite{komaki2006shrinkage, tanaka2008superharmonic, tanaka2018superharmonic, choi2015kahlerian, choi2015geometric, oda2021shrinkage}.
	
	Applications of information geometry are not restricted to time series analysis and signal processing. Information geometry also provides pragmatic applications to statistical inference and parameter estimation for probability distributions. For exponential families, statistical curvature was introduced based on the concept of differential geometry \cite{efron1975defining, efron1978geometry}. Additionally, the differential-geometric approach enables to take advantages of bias reduction in parameter estimation \cite{firth1993bias,kosmidis2009bias,kosmidis2010generic}. Similar to time series analysis and signal processing, we also can leverage information geometry for finding outperforming Bayesian predictive priors for probability distributions \cite{komaki2006shrinkage}. 
	
	However, these benefits and advantages of information geometry are not eligible for every probability distributions and statistical models, because we have difficulties and limitations in finding the information geometry of some probability distributions and statistical models. For example, some distributions do not have closed forms of probability density functions. Even if we have the closed form of the probability density function for an underlying probability distribution, finite Fisher information matrix would not exist or it is not easy to obtain the metric tensor of information geometry due to technicality and complexity of the geometric calculation.
	
	Classical tempered stable (CTS) distribution, suggested by Rosinski \cite{rosinski2007tempering} and also known as CGMY distribution \cite{carr2002fine}, is one of such probability distributions with the difficulties in finding the information geometry. Although the distribution has been used for various financial applications such as financial time series modeling using ARMA-GARCH-CTS model \cite{kim2009computing, kim2010tempered, kim2011time}, and portfolio management and options pricing \cite{tsuchida2012mean, beck2013empirical, choi2015reward, georgiev2015periodic, anand2017equity, kim2023deep, choi2024diversified}, a closed form of its probability density function does not exist. The non-existence of the probability density function is the reason why it is difficult to find the information geometry of CTS processes. This reason is also applied to not only the generalized version of CTS processes called as generalized tempered stable (GTS) processes \cite{rachev2011financial} but also other tempered stable processes such as rapidly-decreasing tempered stable (RDTS) processes \cite{kim2010tempered}.
	
	A continuing effort on finding the information geometry of tempered stable processes such as CTS processes and GTS processes can be found in the work by Kim and Lee \cite{kim2007relative}. They derived the relative entropy between two equivalent martingale CTS processes based on the Radon-Nikodym derivatives. However, the information geometry of CTS processes is not derived in their work. Moreover, the statistical manifolds of CTS processes and GTS processes still remain unknown and even the relative entropy of GTS processes is also not found.
	
	In this paper, we find the information geometry of tempered stable processes. Generalizing the result found by Kim and Lee \cite{kim2007relative} not only from relative entropy to $\alpha$-divergence but also from CTS processes to tempered stable processes, information geometry such as Fisher information matrices of tempered stable processes and $\alpha$-connections of the tempered stable process geometry are calculated. Additionally, we also derive the information geometry of RDTS processes. Moreover, we leverage the geometric calculations to statistical applications such as bias reduction and Bayesian predictive priors for the tempered stable processes. 
	
	The structure of this paper is as follows. In next section, we provide the fundamentals of tempered stable processes. Additionally, we re-visit Kim and Lee's work on the relative entropy of CTS processes \cite{kim2007relative}. Section \ref{sec_ig} provides main results of this paper such as information geometry of various tempered stable processes. In section \ref{sec_apps}, statistical applications of the information geometry of GTS processes are covered. And then we conclude the paper.
	
\section{Tempered stable processes}
	In this section, we provide the fundamentals of various tempered stable processes such as CTS processes, GTS processes, and RDTS processes. We also review the prior work on the relative entropy of CTS processes. These materials will be the foundation for deriving our main results in next section.

	A tempered stable distribution is an infinitely divisible distribution with the L\'evy triplet of $(0,\nu,\gamma)$ \cite{rachev2011financial} such that its L\'evy measure is defined as
	\begin{align}
	\label{levy_measure_ts}
		\nu(dx;\boldsymbol{\xi})=t(x;\boldsymbol{\xi})\nu_{\textrm{stable}}(dx;\boldsymbol{\xi})=\lambda(x;\boldsymbol{\xi})dx,
	\end{align}
	where $t(x)$ is a tempering function and $\nu_{\textrm{stable}}$ is the L\'evy measure of stable distribution. The L\'evy measure of stable distribution is represented with
	\begin{align}
	\label{levy_measure_stable}
		\nu_{\textrm{stable}}(dx;\boldsymbol{\xi})=\Big(\frac{C_+}{x^{a_++1}} 1_{x>0}(x)+\frac{C_-}{|x|^{a_-+1}} 1_{x<0}(x)\Big)dx.
	\end{align}
	where $C_+, C_-$ are positive, $a_+, a_-\in(0,2)\setminus \{1\}$, and $1_A(x)$ is the indicator function such that $1_A(x)=1$ when $x\in A$ and 0 otherwise. 
	
	The characteristic function of tempered stable distributions can be obtained by L\'evy-Khinchin formula \cite{rachev2011financial}:
	\begin{align}
	\label{charac_ftn_ts}
		\phi(u)=\exp\Big(iu\gamma+\int_{-\infty}^{\infty}({\rm e}^{iux}-1-iux 1_{|x|\leq1})\nu(dx)\Big).
	\end{align}
	
	With tempered stable distributions, it is possible to define tempered stable processes. A process $(X_t, \mathbb{P})_{t\in[0,T]}$ is referred to as a tempered stable process if $X_t$ is a random variable from a tempered stable distribution.
	
	More details on tempered stable distributions and processes can be found in Rachev et al. \cite{rachev2011financial} and references therein.
	
\subsection{CTS processes and GTS processes}
	After Rosinski suggested CTS distribution \cite{rosinski2007tempering} to tempering the stable distribution, it has been broadly used in various fields. In particular, since the distribution, also know as CGMY distribution \cite{carr2002fine}, is able to model heavy-tailedness and skewness, its financial applications can be found in time series modeling such as ARMA-GARCH-CTS model \cite{kim2009computing, kim2010tempered, kim2011time}, and portfolio management and options pricing \cite{tsuchida2012mean, beck2013empirical, choi2015reward, georgiev2015periodic, anand2017equity, kim2023deep, choi2024diversified}.
	
	 In CTS distribution, there are five parameters, $\boldsymbol{\xi}=(a, C,\lambda_+,\lambda_-,m)$: $m$ is the location parameter, $a$ is the tail index, $C$ is the scale parameter, $\lambda_+$ and $\lambda_-$ are the decay rates of the upper and lower tails, respectively. $C, \lambda_+, \lambda_-$ are positive, $a\in(0,2)\setminus \{1\}$, and $m\in\mathbb{R}$.
	 
	By considering the following CTS condition for tempered stable distributions in Eq. (\ref{levy_measure_stable}):
	\begin{align}
	\label{cts_condition}
		\left\{ 
		\begin{array}{ll}
			a_+=a_-=a\\
			C_+=C_-=C
		\end{array}
		\right.,
	\end{align}
	and using the CTS tempering function of
	\begin{align}
	\label{temp_fns_cts}
	 	t_{\textrm{CTS}}(x;\boldsymbol{\xi})={\rm e}^{-\lambda_{+}x} 1_{x>0}(x)+{\rm e}^{-\lambda_{-} |x|} 1_{x<0}(x),
	\end{align}
	the L\'evy measure of CTS distribution \cite{rachev2011financial} is given as
	\begin{align}
	\label{levy_measure_cts}
		\nu(dx;\boldsymbol{\xi})=C\Big(\frac{{\rm e}^{-\lambda_{+}x}}{x^{a+1}} 1_{x>0}(x)+\frac{{\rm e}^{-\lambda_{-} |x|}}{|x|^{a+1}} 1_{x<0}(x)\Big)dx.
	\end{align}
	
	Based on Eq. (\ref{charac_ftn_ts}) and Eq. (\ref{levy_measure_cts}), the characteristic function of CTS distribution is represented as
	\begin{align}
	\label{charac_ftn_cts}
	\begin{split}
		\phi(u)=&\exp\Big(ium-iuC\Gamma(1-a)(\lambda_+^{a-1}-\lambda_-^{a-1})\\
		&+C\Gamma(-a)\big(\big((\lambda_+-iu)^a-\lambda_+^a\big)+\big((\lambda_-+iu)^a-\lambda_-^a\big)\big)\Big),
	\end{split}
	\end{align}
	where $\Gamma$ is the Gamma function. Meanwhile, the probability density function of CTS distribution does not exist.
		
	In stead of controlling the upper and lower tails by the same tail index and scale parameter, we can introduce additional degrees of freedom to both parameters. The upper and lower tails can be modeled by separate tail indexes and scale parameters. The distribution with these extra parameters is called GTS distribution \cite{rachev2011financial}. 
	
	We have seven parameters for GTS distribution, $\boldsymbol{\xi}=(a_+, a_-, C_+, C_-,\lambda_+,\lambda_-,m)$: $m$ is the location parameter, $a_+$ and $a_-$ are the tail indexes, $C_+$ and $C_-$ are the scale parameters, $\lambda_+$ and $\lambda_-$ are the decay rates of the upper and lower tails, respectively. $C_+, C_-, \lambda_+,\lambda_-$ are positive, $a_+, a_-\in(0,2)\setminus \{1\}$, and $m\in\mathbb{R}$.
	
	By plugging the same tempering function of CTS distribution, Eq. (\ref{temp_fns_cts}), to Eq. (\ref{levy_measure_ts}), the L\'evy measure of GTS distribution \cite{rachev2011financial} is given as
	\begin{align}
	\label{levy_measure_gts}
		\nu(dx;\boldsymbol{\xi})=\Big(\frac{C_+{\rm e}^{-\lambda_+ x}}{x^{a_++1}} 1_{x>0}(x)+\frac{C_-{\rm e}^{-\lambda_- |x|}}{|x|^{a_-+1}} 1_{x<0}(x)\Big)dx.
	\end{align}
	
	From Eq. (\ref{charac_ftn_ts}) and Eq. (\ref{levy_measure_gts}), the characteristic function of GTS distribution \cite{rachev2011financial} is represented as
	\begin{align}
	\label{charac_ftn_gts}
	\begin{split}
		\phi(u)=&\exp\big(ium-iu(C_+\Gamma(1-a_+)\lambda_+^{a_+-1}-C_-\Gamma(1-a_-)\lambda_-^{a_--1})\\
		&+C_+\Gamma(-a_+)\big((\lambda_+-iu)^{a_{+}}-\lambda_+^{a_{+}}\big)+C_-\Gamma(-a_-) \big((\lambda_-+iu)^{a_{-}}-\lambda_-^{a_{-}}\big)\big),
	\end{split}
	\end{align}
	where $\Gamma$ is the Gamma function. Similar to CTS distribution, the probability density function of GTS distribution does not exist.
		
	It is straightforward to check that CTS distribution is a special case of GTS distribution. As described above, Eq. (\ref{cts_condition}) implies that the upper and lower tails are controlled by the same tail index, $a$, and the same scale parameter, $C$, but different decay rates, $\lambda_{+}$ and $\lambda_{-}$, respectively. By applying the CTS condition of Eq. (\ref{cts_condition}), it is obvious to derive Eq. (\ref{levy_measure_cts}) and Eq. (\ref{charac_ftn_cts}) from Eq. (\ref{levy_measure_gts}) and Eq. (\ref{charac_ftn_gts}), respectively.
	
	 As tempered stable processes are defined above, it is possible to define CTS processes and GTS processes from their underlying distributions. For example, a process $(X_t, \mathbb{P})_{t\in[0,T]}$ is referred to as the GTS process with parameters $\boldsymbol{\xi}=(a_+, a_-, C_+, C_-, \lambda_+, \lambda_-, m)$ if $X_t\sim\mathrm{GTS}(a_+, a_-, C_+, C_-,\lambda_+,\lambda_-,m)$. Similarly, a process $(X_t, \mathbb{P})_{t\in[0,T]}$ is referred to as the CTS process with parameters $\boldsymbol{\xi}=(a, C, \lambda_+, \lambda_-, m)$ if $X_t\sim\mathrm{CTS}(a, C, \lambda_+, \lambda_-, m)$.
	
	 A next step is defining the Radon-Nikodym derivatives between two GTS processes. Let $(X_t, \mathbb{P})_{t\in[0,T]}$ and $(X_t, \mathbb{Q})_{t\in[0,T]}$ be GTS processes with parameters $\boldsymbol{\xi}=(a_+, a_-, C_+, C_-, \lambda_+, \lambda_-, m)$ and $\tilde{\boldsymbol{\xi}}=(\tilde{a}_+, \tilde{a}_-, \tilde{C}_+,\tilde{C}_-, \tilde{\lambda}_{+}, \tilde{\lambda}_{-}, \tilde{m})$, respectively. GTS processes requires the equivalent martingale measure conditions for the existence of the Radon-Nikodym derivatives between GTS processes based the on L\'evy measures of Eq. (\ref{levy_measure_gts}) \cite{kim2007relative}.
	
	The equivalent martingale measure (EMM) conditions for GTS processes \cite{rachev2011financial} are as follows:
	\begin{align}
	\label{emm_gts}
	\left\{ 
		\begin{array}{ll}
			C_+=\tilde{C}_+\\
			C_-=\tilde{C}_-\\
			a_+=\tilde{a}_+\\
			a_-=\tilde{a}_-\\
			m=\tilde{m}+C_+\Gamma(1-a_+)(\lambda_+^{a_+-1}-\tilde{\lambda}_{+}^{a_+-1})-C_-\Gamma(1-a_-)(\lambda_-^{a_--1}-\tilde{\lambda}_{-}^{a_--1})
		\end{array}
		\right.,
	\end{align}
	and by using Eq. (\ref{cts_condition}), the equivalent martingale measure conditions for CTS processes \cite{rachev2011financial} are given as
	\begin{align}
	\label{emm_cts}
	\left\{ 
		\begin{array}{ll}
			C=\tilde{C}\\ 
			a=\tilde{a}\\
			m=\tilde{m}+C\Gamma(1-a)\big((\lambda_+^{a-1}-\tilde{\lambda}_{+}^{a-1})-(\lambda_-^{a-1}-\tilde{\lambda}_{-}^{a-1})\big)
		\end{array}
		\right..
	\end{align}
	
	With the equivalent martingale measure conditions, the Radon-Nikodym derivatives of CTS processes and GTS processes \cite{rachev2011financial} are obtained from Eq. (\ref{levy_measure_cts}) and Eq. (\ref{levy_measure_gts}), respectively:
	\begin{align}
	\label{radon_nikodym_gts}
		\frac{d\nu^\mathbb{P}}{d\nu^\mathbb{Q}}={\rm e}^{-(\lambda_+-\tilde{\lambda}_+)x} 1_{x>0}(x)+{\rm e}^{-(\lambda_{-}-\tilde{\lambda}_{-})|x|} 1_{x<0}(x),
	\end{align}
	and it is noteworthy that CTS processes and GTS processes have the same Radon-Nikodym derivative.
	
	For further calculation, it is also convenient to introduce the logarithmic Radon-Nikodym derivative:
	\begin{align}
	\label{log_radon_nikodym}
		\psi(x;\boldsymbol{\xi})=\log{\Bigg(\frac{d\nu^\mathbb{P}}{d\nu^\mathbb{Q}}\Bigg)}.
	\end{align}
	The logarithmic Radon-Nikodym derivative between two equivalent martingale GTS processes is expressed with
	\begin{align}
	\label{log_radon_nikodym_gts}
		\psi(x;\boldsymbol{\xi})=-(\lambda_+-\tilde{\lambda}_+)x 1_{x>0}(x)-(\lambda_{-}-\tilde{\lambda}_{-})|x| 1_{x<0}(x),
	\end{align}
	and it is obvious that the logarithmic Radon-Nikodym derivative between two equivalent martingale CTS processes is also identical to Eq. (\ref{log_radon_nikodym_gts}).
	
	The Kullback-Leibler divergence (relative entropy) between two tempered stable processes, $(X_t, \mathbb{P})_{t\in[0,T]}$ and $(X_t, \mathbb{Q})_{t\in[0,T]}$, is expressed in terms of the logarithmic Radon-Nikodym derivative, Eq. (\ref{log_radon_nikodym}) \cite{cont2004nonparametric, kim2007relative}:
	\begin{align}
	\label{kld_measure}
		KL(\mathbb{P}||\mathbb{Q})=T\int (\psi(x){\rm e}^{\psi(x)}-{\rm e}^{\psi(x)}+1)\nu^\mathbb{Q}(dx).
	\end{align}
	
	Based on Eq. (\ref{kld_measure}), the Kullback-Leibler divergence between two CTS processes can be found from Theorem 2 in Kim and Lee \cite{kim2007relative}.
	\begin{thm}[Kim and Lee 2007]
		Let $(X_t, \mathbb{P})_{t\in[0,T]}$ and $(X_t, \mathbb{Q})_{t\in[0,T]}$ be CTS processes with parameters $(a, C, \lambda_+, \lambda_-, m)$ and $(\tilde{a}, \tilde{C}, \tilde{\lambda}_{+}, \tilde{\lambda}_{-}, \tilde{m})$, respectively. Suppose $\mathbb{P}$ and $\mathbb{Q}$ are equivalent measures satisfying Eq. (\ref{emm_cts}). If $\lambda_{+}<2\tilde{\lambda}_{+}$ and $\lambda_{-}<2\tilde{\lambda}_{-}$, then we have
		\begin{align}
		\label{kld_cts}
			KL(\mathbb{P}||\mathbb{Q})=TC\Gamma(-a)\Big(\big((a-1)\lambda_+^{a}-a\tilde{\lambda}_{+}\lambda_+^{a-1}+\tilde{\lambda}_{+}^a\big)+\big((a-1)\lambda_-^{a}-a\tilde{\lambda}_{-}\lambda_-^{a-1}+\tilde{\lambda}_{-}^a\big)\Big)
		\end{align}
	\end{thm}
	\begin{proof}
		Please check Theorem 2 and its proof in Kim and Lee \cite{kim2007relative}. Simply speaking, plugging Eq. (\ref{log_radon_nikodym}) to Eq. (\ref{kld_measure}) provides the proof.
	\end{proof}
	Note that some parts of the original theorem in Kim and Lee \cite{kim2007relative} are modified based on the parametrization and equivalent martingale measure conditions given in this paper.
	
	As mentioned in section \ref{sec_intro}, the Kullback-Leibler divergence for GTS processes has not been found.
	
\subsection{RDTS processes}
	Another tempered stable process we cover in this paper is RDTS processes \cite{kim2010tempered,rachev2011financial}. 
	
	Similar to GTS distribution, $\boldsymbol{\xi}=(a_+, a_-, C_+, C_-,\lambda_+,\lambda_-,m)$ are seven parameters in RDTS distribution: $m$ is the location parameter, $a_+$ and $a_-$ are the tail indexes, $C_+$ and $C_-$ are the scale parameters, $\lambda_+$ and $\lambda_-$ are the decay rates of the upper and lower tails, respectively. $C_+, C_-, \lambda_+,\lambda_-$ are positive, $a_+, a_-\in(0,2)\setminus \{1\}$, and $m\in\mathbb{R}$.
	
	For RDTS distribution, we use the following tempering function:
	 \begin{align}
	 \label{temp_fns_rdts}
	 	t_{\textrm{RDTS}}(x;\boldsymbol{\xi})={\rm e}^{-\frac{\lambda_{+}}{2}x^2} 1_{x>0}(x)+{\rm e}^{-\frac{\lambda_{-}}{2} |x|^2} 1_{x<0}(x),
	 \end{align}
	and the L\'evy measure of RDTS distribution from Eq. (\ref{levy_measure_ts}) is given \cite{rachev2011financial} as
	\begin{align}
	\label{levy_measure_rdts}
		\nu(dx;\boldsymbol{\xi})=\Big(\frac{C_+{\rm e}^{-\frac{\lambda_+}{2} x^2}}{x^{a_++1}} 1_{x>0}(x)+\frac{C_-{\rm e}^{-\frac{\lambda_-}{2} |x|^2}}{|x|^{a_-+1}} 1_{x<0}(x)\Big)dx.
	\end{align}
	
	From Eq. (\ref{charac_ftn_ts}), the characteristic function of RDTS distribution is represented as
	\begin{align}
	\label{charac_ftn_rdts}
		\phi(u)=&\exp\Big(ium+C_+G(iu;a_+,\lambda_+)+C_-G(-iu;a_-,\lambda_-)\Big),
	\end{align}
	where
	\begin{align}
		G(x;a,\lambda)=&2^{-1-\frac{a}{2}}\lambda^a\Gamma(-\frac{a}{2})\big(M(-\frac{a}{2},\frac{1}{2};\frac{x^2}{2\lambda^2})-1\big)\nonumber\\
		&+2^{-\frac{1}{2}-\frac{a}{2}}x\lambda^{a-1}\Gamma(\frac{1-a}{2})\big(M(\frac{1-a}{2},\frac{3}{2};\frac{x^2}{2\lambda^2})-1\big)\nonumber,
	\end{align}
	such that $M$ is the confluent hypergeometric function, and $\Gamma$ is the Gamma function. However, the probability density function of RDTS distribution does not exist.
		
	Similar to GTS processes and CTS processes, we can define RDTS processes. A process $(X_t, \mathbb{P})_{t\in[0,T]}$ is referred to as the RDTS process with parameters $\boldsymbol{\xi}=(a_+, a_-, C_+, C_-, \lambda_+, \lambda_-, m)$ if $X_t\sim\mathrm{RDTS}(a_+, a_-, C_+, C_-,\lambda_+,\lambda_-,m)$.
	
	The equivalent martingale measure conditions for RDTS processes \cite{rachev2011financial} are as follows:
	\begin{align}
	\label{emm_rdts}
	\left\{ 
		\begin{array}{ll}
			C_+=\tilde{C}_+\\
			C_-=\tilde{C}_-\\
			a_+=\tilde{a}_+\\
			a_-=\tilde{a}_-\\
			m=\tilde{m}+2^{-\frac{1+a_+}{2}}C_+\Gamma(\frac{1-a_+}{2})(\lambda_+^{a_+-1}-\tilde{\lambda}_{+}^{a_+-1})-2^{-\frac{1+a_-}{2}}C_-\Gamma(\frac{1-a_-}{2})(\lambda_-^{a_--1}-\tilde{\lambda}_{-}^{a_--1})
		\end{array}
		\right..
	\end{align}
	
	For equivalent martingale measures, the Radon-Nikodym derivatives of RDTS processes are obtained from Eq. (\ref{levy_measure_rdts}) as
	\begin{align}
	\label{radon_nikodym_rdts}
		\frac{d\nu^\mathbb{P}}{d\nu^\mathbb{Q}}={\rm e}^{-\frac{(\lambda_+-\tilde{\lambda}_+)}{2}x^2} 1_{x>0}(x)+{\rm e}^{-\frac{(\lambda_{-}-\tilde{\lambda}_{-})}{2}|x|^2} 1_{x<0}(x).
	\end{align}
	
	The logarithmic Radon-Nikodym derivative between two equivalent martingale RDTS processes is expressed with
	\begin{align}
	\label{log_radon_nikodym_rdts}
		\psi(x;\boldsymbol{\xi})=-\frac{(\lambda_+-\tilde{\lambda}_+)}{2}x^2 1_{x>0}(x)-\frac{(\lambda_{-}-\tilde{\lambda}_{-})}{2}|x|^2 1_{x<0}(x).
	\end{align}
	
\section{Information geometry for tempered stable processes}
\label{sec_ig}
	In this section, we present main results of this paper. Starting with the derivation of the $\alpha$-divergence between two tempered stable processes, we find the information geometry of tempered stable processes. The metric tensor and $\alpha$-connection of the geometry are calculated for various tempered stable processes.
	 
	Our starting point is the $\alpha$-divergence between two probability density functions. The $\alpha$-divergence between two probability density functions $p(x;\boldsymbol{\xi})$ and $q(x;\tilde{\boldsymbol{\xi}})$ \cite{amari2000methods} is defined as 
	 \begin{align}
	 \label{alpha_div}
	D^{(\alpha )}(p(x;\boldsymbol{\xi})||q(x;\tilde{\boldsymbol{\xi}}))=\left\{ 
	\begin{array}{ll}
	\frac{4}{1-\alpha^{2}}\int (\frac{1-\alpha}{2}p(x;\boldsymbol{\xi})+\frac{1+\alpha}{2}q(x;\tilde{\boldsymbol{\xi}})-p(x;\boldsymbol{\xi})^{\frac{1-\alpha}{2}}q(x;\tilde{\boldsymbol{\xi}})^{\frac{1+\alpha}{2}})dx & (\alpha \neq \pm 1)\\ 
	\int (p(x;\boldsymbol{\xi}) \log{\frac{p(x;\boldsymbol{\xi})}{q(x;\tilde{\boldsymbol{\xi}})}}-p(x;\xi)+q(x;\tilde{\xi}))dx & (\alpha =-1)\\
	\int (q(x;\tilde{\boldsymbol{\xi}}) \log{\frac{q(x;\tilde{\boldsymbol{\xi}})}{p(x;\boldsymbol{\xi})}}-q(x;\tilde{\xi})+p(x;\xi))dx & (\alpha =1)
	\end{array}
	\right.,
	\end{align}
	where $\boldsymbol{\xi}$ and $\tilde{\boldsymbol{\xi}}$ are parameters of $p$ and $q$, respectively. It is straightforward to check that $\alpha$-divergence is not symmetric under the exchange between $p$ and $q$ except for $\alpha=0$.
	
	It is noteworthy that several $\alpha$ values are related to well-known divergences and distances. When $\alpha=-1$, $D^{(\alpha)}(p||q)$ is the Kullback-Leibler divergence, also known as relative entropy. The Hellinger distance corresponds to $\alpha=0$.
	
	The $\alpha$-divergence is featured with an interesting characteristics called $\alpha$-duality \cite{amari2000methods} that changing the signature of $\alpha$ corresponds to the exchange between $p$ and $q$ such that
	\begin{align}
	\label{a_duality}
		D^{(\alpha )}(p||q)=D^{(-\alpha )}(q||p).
	\end{align}
	It is straightforward to check that the Hellinger distance, which is $0$-divergence, is self-dual and symmetric in the exchange of $p$ and $q$. When $\alpha=+1$, $D^{(\alpha)}(p||q)$ is the dual to the Kullback-Leibler divergence.
			
	It is also known that the Kullback-Leiber divergence for distributions is represented with Radon-Nikodym derivative:
	\begin{align}
		KL(\mathbb{P}||\mathbb{Q})=\int \Big(\Big(\frac{d\nu^\mathbb{P}}{d\nu^\mathbb{Q}}\Big) \log{\Big(\frac{d\nu^\mathbb{P}}{d\nu^\mathbb{Q}}\Big)}- \Big(\frac{d\nu^\mathbb{P}}{d\nu^\mathbb{Q}}\Big)+1\Big) \nu^\mathbb{Q}(dx).\nonumber
	\end{align}
	This expression is identical to Eq. (\ref{kld_measure}) up to the factor of $T$.
	
	As given in Eq. (\ref{kld_measure}), the Kullback-Leiber divergence for tempered stable processes is given \cite{cont2004nonparametric,kim2007relative} as
	\begin{align}
	\label{kld_measure_ts}
		KL(\mathbb{P}||\mathbb{Q})=T \int \Big(\Big(\frac{d\nu^\mathbb{P}}{d\nu^\mathbb{Q}}\Big) \log{\Big(\frac{d\nu^\mathbb{P}}{d\nu^\mathbb{Q}}\Big)}- \Big(\frac{d\nu^\mathbb{P}}{d\nu^\mathbb{Q}}\Big)+1\Big) \nu^\mathbb{Q}(dx).
	\end{align}
	
	It is possible to extend Eq. (\ref{kld_measure_ts}) to $\alpha$-divergence by using $f$-divergence. 
	\begin{thm}
	\label{thm_div_ts}
	Let $(X_t, \mathbb{P})_{t\in[0,T]}$ and $(X_t, \mathbb{Q})_{t\in[0,T]}$ be tempered stable processes with L\'evy triplets of $(0,\nu^\mathbb{P},\gamma^{\mathbb{P}})$ and $(0,\nu^\mathbb{Q},\gamma^{\mathbb{Q}})$, respectively. Suppose $\mathbb{P}$ and $\mathbb{Q}$ are equivalent measures. Then we have $\alpha$-divergence between two tempered stable processes as
	 \begin{align}
	 \label{a_div_measure_ts}
	D^{(\alpha )}(\mathbb{P}||\mathbb{Q})=\left\{ 
	\begin{array}{ll}
	\frac{4T}{1-\alpha ^{2}}\int \Big(\frac{1-\alpha}{2}\Big(\frac{d\nu^\mathbb{P}}{d\nu^\mathbb{Q}}\Big) +\frac{1+\alpha}{2}-\Big(\frac{d\nu^\mathbb{P}}{d\nu^\mathbb{Q}}\Big)^{\frac{1-\alpha}{2}}\Big) \nu^\mathbb{Q}(dx) & (\alpha \neq \pm 1)\\ 
	T\int \Big(\Big(\frac{d\nu^\mathbb{P}}{d\nu^\mathbb{Q}}\Big) \log{\Big(\frac{d\nu^\mathbb{P}}{d\nu^\mathbb{Q}}\Big)}- \Big(\frac{d\nu^\mathbb{P}}{d\nu^\mathbb{Q}}\Big)+1\Big) \nu^\mathbb{Q}(dx) & (\alpha =-1)\\
	T\int \Big(\Big(\frac{d\nu^\mathbb{Q}}{d\nu^\mathbb{P}}\Big) \log{\Big(\frac{d\nu^\mathbb{Q}}{d\nu^\mathbb{P}}\Big)}- \Big(\frac{d\nu^\mathbb{Q}}{d\nu^\mathbb{P}}\Big)+1\Big) \nu^\mathbb{P}(dx) & (\alpha =1)
	\end{array}
	\right..
	\end{align}
	\end{thm}
	\begin{proof}
	The $\alpha=-1$ case for tempered stable processes is already proven by Cont and Tankov \cite{cont2004nonparametric}and Kim and Lee \cite{ kim2007relative}. Additionally, the $\alpha=1$ case can be easily proven by $\alpha$-duality of Eq (\ref{a_duality}). 
	
	There is the well-known $f$-divergence which produces $\alpha$-divergence \cite{amari2000methods}:
	\begin{align}
		D_{f^{(\alpha)}}(\mathbb{P}||\mathbb{Q})=\int f^{(\alpha)}\Big(\frac{d\nu^\mathbb{P}}{d\nu^\mathbb{Q}}\Big)\nu^\mathbb{Q}(dx)
	\end{align}
	where
	\begin{align}
		f^{(\alpha)}(t)=\left\{ 
	\begin{array}{ll}
	\frac{4}{1-\alpha ^{2}}(\Big(\frac{1-\alpha}{2} t +\frac{1+\alpha}{2}-t^{\frac{1-\alpha}{2}}\Big) & (\alpha \neq \pm 1)\\ 
	t \log{t} - t +1 & (\alpha =-1)\\
	- \log{t} +t - 1 & (\alpha =1)
	\end{array}
	\right..
	\end{align}
	From the $f$-divergence, the $\alpha\neq\pm1$ case can be easily proven. Moreover, we are also able to derive the Kullback-Leibler divergence and its dual from the $\alpha\neq\pm1$ case by using L'Hopital's rule.
	\end{proof}
	
	The $\alpha$-divergence between two tempered stable processes can be represented with $\lambda(x;\boldsymbol{\xi})$ in Eq. (\ref{levy_measure_ts}):
	\begin{align}
	 \label{a_div_measure_ts_lambda}
	D^{(\alpha )}(\mathbb{P}||\mathbb{Q})=\left\{ 
	\begin{array}{ll}
	\frac{4T}{1-\alpha ^{2}}\int \Big(\frac{1-\alpha}{2}\Big(\frac{\lambda^\mathbb{P}}{\lambda^\mathbb{Q}}\Big) +\frac{1+\alpha}{2}-\Big(\frac{\lambda^\mathbb{P}}{\lambda^\mathbb{Q}}\Big)^{\frac{1-\alpha}{2}}\Big) \lambda^\mathbb{Q}dx & (\alpha \neq \pm 1)\\ 
	T\int \Big(\Big(\frac{\lambda^\mathbb{P}}{\lambda^\mathbb{Q}}\Big) \log{\Big(\frac{\lambda^\mathbb{P}}{\lambda^\mathbb{Q}}\Big)}- \Big(\frac{\lambda^\mathbb{P}}{\lambda^\mathbb{Q}}\Big)+1\Big) \lambda^\mathbb{Q}dx & (\alpha =-1)\\
	T\int \Big(\Big(\frac{\lambda^\mathbb{Q}}{\lambda^\mathbb{P}}\Big) \log{\Big(\frac{\lambda^\mathbb{Q}}{\lambda^\mathbb{P}}\Big)}- \Big(\frac{\lambda^\mathbb{Q}}{\lambda^\mathbb{P}}\Big)+1\Big) \lambda^\mathbb{P}dx & (\alpha =1)
	\end{array}
	\right..
	\end{align}
	
	It is noteworthy that Eq. (\ref{a_div_measure_ts_lambda}) can be represented only with the tempering function $t(x;\boldsymbol{\xi})$ in Eq. (\ref{levy_measure_ts}) if the equivalent martingale measure condition on a tempered stable distribution includes the parameters in the L\'evy measure of stable distribution, Eq. (\ref{levy_measure_stable}), i.e., $C$ and $a$. In this case, since the Radon-Nikodym derivative can be expressed with
	\begin{align}
		\frac{d\nu^\mathbb{P}}{d\nu^\mathbb{Q}}=\frac{\lambda^\mathbb{P}}{\lambda^\mathbb{Q}}=\frac{t^\mathbb{P}}{t^\mathbb{Q}},\nonumber
	\end{align}
	the $\alpha$-divergence is also given in terms of tempering function $t$.
			
	Additionally, the $\alpha$-divergence between two tempered stable processes, Eq. (\ref{a_div_measure_ts}), can be expressed in terms of the logarithmic Radon-Nikodym derivative, Eq. (\ref{log_radon_nikodym}):
	\begin{align}
	\label{a_div_measure_ts_psi}
	D^{(\alpha )}(\mathbb{P}||\mathbb{Q})=\left\{ 
	\begin{array}{ll}
	\frac{4T}{1-\alpha ^{2}}\int(\frac{1-\alpha}{2}{\rm e}^{\psi(x)} +\frac{1+\alpha}{2}-{\rm e}^{\frac{1-\alpha}{2}\psi(x)})\nu^\mathbb{Q}(dx) & (\alpha \neq \pm 1)\\ 
	T\int (\psi(x){\rm e}^{\psi(x)}-{\rm e}^{\psi(x)}+1)\nu^\mathbb{Q}(dx) & (\alpha =-1)\\
	T\int (-\psi(x){\rm e}^{-\psi(x)}-{\rm e}^{-\psi(x)}+1)\nu^\mathbb{P}(dx) & (\alpha =1)
	\end{array}
	\right..
	\end{align}
	
	It is straightforward to derive information geometry from the $\alpha$-divergence given in Theorem \ref{thm_div_ts}. The next theorem tells how to obtain the information geometry of tempered stable processes.
	\begin{thm}
	\label{thm_geo_ts}
	Let $(X_t, \mathbb{P})_{t\in[0,T]}$ be a tempered process with the L\'evy triplet of $(0,\nu,\gamma)$. The metric tensor and $\alpha$-connection for information geometry of tempered stable processes are given as
	\begin{align}
		\label{metric_ts}
		g_{ij}=&T\int \partial_i \log{\Big(\frac{d\nu}{dx}\Big)} \partial_j \log{\Big(\frac{d\nu}{dx}\Big)} \nu(dx),\\
		\label{conn_ts}
		\Gamma^{(\alpha)}_{ij,k}=&T\int \Big(\partial_i \partial_j \log{\Big(\frac{d\nu}{dx}\Big)}+\frac{1-\alpha}{2}\partial_i \log{\Big(\frac{d\nu}{dx}\Big)} \partial_j \log{\Big(\frac{d\nu}{dx}\Big)}\Big)\partial_k \log{\Big(\frac{d\nu}{dx}\Big)} \nu(dx),
	\end{align}
	where $i,j,$ and $k$ run for coordinate system $\boldsymbol{\xi}$.
	\end{thm}
	\begin{proof}
	For a given divergence $D$, the metric tensor and the connection of the geometry are derived \cite{amari2000methods} as
	\begin{align}
		\label{ig_metric}
		g_{ij}&=-D(\partial_i, \tilde{\partial}_j)|_{\boldsymbol{\xi}=\tilde{\boldsymbol{\xi}}},\\
		\label{ig_connection}
		\Gamma_{ij,k}&=-D(\partial_i \partial_j,\tilde{\partial}_k)|_{\boldsymbol{\xi}=\tilde{\boldsymbol{\xi}}},
	\end{align}
	where $i,j,$ and $k$ run for coordinate system $\boldsymbol{\xi}$.
	
	By plugging the $\alpha$-divergence of Eq. (\ref{a_div_measure_ts}) to Eq. (\ref{ig_metric}) and Eq. (\ref{ig_connection}), we easily obtain the followings:
	\begin{align}
		g_{ij}=&T\int \partial_i \log{\Big(\frac{d\nu}{dx}\Big)} \partial_j \log{\Big(\frac{d\nu}{dx}\Big)} \nu(dx),\nonumber\\
		\Gamma^{(\alpha)}_{ij,k}=&T\int \Big(\partial_i \partial_j \log{\Big(\frac{d\nu}{dx}\Big)}+\frac{1-\alpha}{2}\partial_i \log{\Big(\frac{d\nu}{dx}\Big)} \partial_j \log{\Big(\frac{d\nu}{dx}\Big)}\Big)\partial_k \log{\Big(\frac{d\nu}{dx}\Big)} \nu(dx),\nonumber
	\end{align}
	where $i,j,$ and $k$ run for coordinate system $\boldsymbol{\xi}$.
	\end{proof}
	
	It is noteworthy that the metric tensor of information geometry is the Fisher information matrix, i.e., Eq. (\ref{metric_ts}) is the Fisher information matrix of tempered stable processes.
	
	Similar to $\alpha$-divergence, we can express the metric tensor and the $\alpha$-connection of information geometry in terms of $\lambda(x;\boldsymbol{\xi})$ in Eq. (\ref{levy_measure_ts}):
	\begin{align}
	\label{metric_ts_lambda}
		g_{ij}=&T\int \partial_i \log{\lambda(x;\boldsymbol{\xi})} \partial_j \log{\lambda(x;\boldsymbol{\xi})} \lambda(x;\boldsymbol{\xi}) dx,\\
	\label{conn_ts_lambda}
		\Gamma^{(\alpha)}_{ij,k}=&T\int \Big(\partial_i \partial_j \log{\lambda(x;\boldsymbol{\xi})}+\frac{1-\alpha}{2}\partial_i \log{\lambda(x;\boldsymbol{\xi})} \partial_j \log{\lambda(x;\boldsymbol{\xi})}\Big)\Big(\partial_k \log{\lambda(x;\boldsymbol{\xi})}\Big) \lambda(x;\boldsymbol{\xi}) dx,
	\end{align}
	where $i,j,$ and $k$ run for coordinate system $\boldsymbol{\xi}$. 
	
	If the equivalent martingale measure condition on a tempered stable distribution includes the parameters in the L\'evy measure of stable distribution in Eq. (\ref{levy_measure_stable}), the metric tenor and $\alpha$-connection are expressed with the L\'evy measure and the tempering function $t(x;\boldsymbol{\xi})$ in Eq. (\ref{levy_measure_ts}):
	\begin{align}
	\label{metric_ts_t}
		g_{ij}=&T\int \partial_i \log{t(x;\boldsymbol{\xi})} \partial_j \log{t(x;\boldsymbol{\xi})} \nu(dx),\\
	\label{conn_ts_t}
		\Gamma^{(\alpha)}_{ij,k}=&T\int \Big(\partial_i \partial_j \log{t(x;\boldsymbol{\xi})}+\frac{1-\alpha}{2}\partial_i \log{t(x;\boldsymbol{\xi})} \partial_j \log{t(x;\boldsymbol{\xi})}\Big)\Big(\partial_k \log{t(x;\boldsymbol{\xi})}\Big) \nu(dx),
	\end{align}
	where $i,j,$ and $k$ run for coordinate system $\boldsymbol{\xi}$.
	
	It is noteworthy that Eq. (\ref{metric_ts_lambda}) and Eq. (\ref{conn_ts_lambda}) are in the same form with those using probability density function given in Amari and Nagaoka \cite{amari2000methods}.
	
\subsection{GTS processes}
	Theorem \ref{thm_div_ts} can be applied to GTS processes. By plugging Eq. (\ref{radon_nikodym_gts}) to Eq. (\ref{a_div_measure_ts}) in Theorem \ref{thm_div_ts}, the $\alpha$-divergence of GTS processes can be obtained. 
	
	\begin{crl}
	\label{crl_div_gts}
		Let $(X_t, \mathbb{P})_{t\in[0,T]}$ and $(X_t, \mathbb{Q})_{t\in[0,T]}$ be GTS processes with parameters $\boldsymbol{\xi}=(a_+, a_-, C_+, C_-,\lambda_+,\lambda_-,m)$ and $\tilde{\boldsymbol{\xi}}=(\tilde{a}_+, \tilde{a}_-, \tilde{C}_+, \tilde{C}_-,\tilde{\lambda}_+,\tilde{\lambda}_-,\tilde{m})$, respectively. Suppose $\mathbb{P}$ and $\mathbb{Q}$ are equivalent measures satisfying Eq. (\ref{emm_gts}). Then we have $\alpha$-divergence between two GTS processes as
	\begin{align}
	\label{a_div_gts}
	D^{(\alpha )}(\mathbb{P}||\mathbb{Q})=\left\{ 
	\begin{array}{ll}
	\frac{4}{1-\alpha^2}\Big(TC_+\Gamma(-a_+)\big( \frac{1-\alpha}{2} \lambda_+^{a_+}+\frac{1+\alpha}{2} \tilde{\lambda}_+^{a_+}-( \frac{1-\alpha}{2} \lambda_++\frac{1+\alpha}{2} \tilde{\lambda}_+)^{a_+}\big)\\
	+TC_-\Gamma(-a_-)\big( \frac{1-\alpha}{2} \lambda_-^{a_-}+\frac{1+\alpha}{2} \tilde{\lambda}_-^{a_-}-( \frac{1-\alpha}{2} \lambda_-+\frac{1+\alpha}{2} \tilde{\lambda}_-)^{a_-}\big)\Big) & (\alpha \neq \pm 1)\\ 
	TC_+\Gamma(-a_+)\big((a_+-1)\lambda_+^{a_+}-a_+\tilde{\lambda}_+\lambda_+^{a_+-1}+\tilde{\lambda}_+^{a_+}\big)\\
	+TC_-\Gamma(-a_-)\big((a_--1)\lambda_-^{a_-}-a_-\tilde{\lambda}_-\lambda_-^{a_--1}+\tilde{\lambda}_-^{a_-}\big) & (\alpha =-1)\\
	TC_+\Gamma(-a_+)\big((a_+-1)\tilde{\lambda}_+^{a_+}-a_+\lambda_+\tilde{\lambda}_+^{a_+-1}+\lambda_+^{a_+}\big)\\
	+TC_-\Gamma(-a_-)\big((a_--1)\tilde{\lambda}_-^{a_-}-a_-\lambda_-\tilde{\lambda}_-^{a_--1}+\lambda_-^{a_-}\big) & (\alpha =1)
	\end{array}
	\right.
	\end{align}
	\end{crl}
	\begin{proof}
	We start with $\alpha \neq \pm 1$. The $\alpha$-divergence for $\alpha \neq \pm 1$ is given by Eq. (\ref{a_div_measure_ts}):
	\begin{align}
		D^{(\alpha)}(\mathbb{P}||\mathbb{Q})=\frac{4T}{1-\alpha ^{2}}\int \Big(\frac{1-\alpha}{2}\Big(\frac{d\nu^\mathbb{P}}{d\nu^\mathbb{Q}}\Big) +\frac{1+\alpha}{2}-\Big(\frac{d\nu^\mathbb{P}}{d\nu^\mathbb{Q}}\Big)^{\frac{1-\alpha}{2}}\Big) \nu^\mathbb{Q}(dx).\nonumber
	\end{align}
	
	We can decompose $\alpha$-divergence to the positive $x$ part and the negative $x$ part. For positive $x$, the $\alpha$-divergence is expressed with
	\begin{align}
		&D^{(\alpha)}(\mathbb{P}||\mathbb{Q})|_{+}=\frac{4T}{1-\alpha ^{2}}\int_0^\infty \Big(\frac{1-\alpha}{2}{\rm e}^{-(\lambda_+-\tilde{\lambda}_+)x} +\frac{1+\alpha}{2}- \Big({\rm e}^{-(\lambda_+-\tilde{\lambda}_+)x}\Big)^{\frac{1-\alpha}{2}}\Big)\frac{C_+{\rm e}^{-\tilde{\lambda}_+ x}}{x^{a_++1}} dx\nonumber\\
	&\propto C_+\int_0^\infty \Big(\frac{1-\alpha}{2}\frac{{\rm e}^{-\lambda_+ x}}{x^{a_++1}} +\frac{1+\alpha}{2}\frac{{\rm e}^{-\tilde{\lambda}_+ x}}{x^{a_++1}} -\frac{{\rm e}^{-(\frac{1-\alpha}{2}\lambda_++\frac{1+\alpha}{2}\tilde{\lambda}_+) x}}{x^{a_++1}} \Big)dx\nonumber\\
	&=C_+\int_0^\infty \Big(\frac{1-\alpha}{2}\frac{\lambda_+^{a_+}{\rm e}^{-t}}{t^{a_++1}} +\frac{1+\alpha}{2}\frac{\tilde{\lambda}_+^{a_+}{\rm e}^{-t}}{t^{a_++1}} -\frac{(\frac{1-\alpha}{2}\lambda_++\frac{1+\alpha}{2}\tilde{\lambda}_+)^{a_+}{\rm e}^{-t}}{t^{a_++1}} \Big)dt\nonumber\\
	&=C_+\Gamma(-a_+)\Big(\frac{1-\alpha}{2}\lambda_+^{a_+}+\frac{1+\alpha}{2}\lambda_+^{a_+}-\big(\frac{1-\alpha}{2}\lambda_++\frac{1+\alpha}{2}\tilde{\lambda}_+\big)^{a_+}\Big).\nonumber
	\end{align}
	After the similar calculation is done for the negative $x$ part, the $\alpha$-divergence for $\alpha \neq \pm 1$ is given by
	\begin{align}
	D^{(\alpha)}(\mathbb{P}||\mathbb{Q})=&\frac{4T}{1-\alpha ^{2}}\bigg(C_+\Gamma(-a_+)\Big(\frac{1-\alpha}{2}\lambda_+^{a_+}+\frac{1+\alpha}{2}\lambda_+^{a_+}-\big(\frac{1-\alpha}{2}\lambda_++\frac{1+\alpha}{2}\tilde{\lambda}_+\big)^{a_+}\Big)\nonumber\\
	%% (-)
	&+C_-\Gamma(-a_-)\Big(\frac{1-\alpha}{2}\lambda_-^{a_-}+\frac{1+\alpha}{2}\lambda_-^{a_-}-\big(\frac{1-\alpha}{2}\lambda_-+\frac{1+\alpha}{2}\tilde{\lambda}_-\big)^{a_-}\Big)\bigg).\nonumber
	\end{align}
	
	For $\alpha=-1$, there are two ways for proof. The first proof is based on the direct computation by plugging Radon-Nikodym derivative of Eq. (\ref{radon_nikodym_gts}) to $\alpha=-1$ of Eq. (\ref{a_div_measure_ts}). Another proof of calculating the Kullback-Leibler divergence is by the application of L'Hopital's rule to $\alpha \neq \pm1$ in the limit of $\alpha\to-1$. By these two ways of proof, the same result is obtained.
	
	We show the first proof here. Similar to $\alpha \neq \pm1$, let us start with the positive $x$ part of the Kullback-Leibler divergence:
	\begin{align}
	D^{(-1)}(\mathbb{P}||\mathbb{Q})|_{+}&=TC_+\int_0^\infty \Big(\frac{{\rm e}^{-\lambda_+x}}{x^{a_++1}}\big(-(\lambda_+-\tilde{\lambda}_+)x-1\big) + \frac{{\rm e}^{-\tilde{\lambda}_+x}}{x^{a_++1}}\Big)dx\nonumber\\
	&=TC_+\Gamma(-a_+)\big(\lambda_+^{a_+-1}a_+(\lambda_+-\tilde{\lambda}_+)-\lambda_+^{a_+}+\tilde{\lambda}_+^{a_+}\big)\nonumber\\
	&=TC_+\Gamma(-a_+)\big((a_+-1)\lambda_+^{a_+}-a_+\tilde{\lambda}_+\lambda_+^{a_+-1}+\tilde{\lambda}_+^{a_+}\big).\nonumber
	\end{align}
	
	Repeating the same step for negative $x$, the Kullback-Leibler divergence between two GTS processes is given as
	\begin{align}
	D^{(-1)}(\mathbb{P}||\mathbb{Q})=&TC_+\Gamma(-a_+)\big((a_+-1)\lambda_+^{a_+}-a_+\tilde{\lambda}_+\lambda_+^{a_+-1}+\tilde{\lambda}_+^{a_+}\big)\nonumber\\
	&+TC_-\Gamma(-a_-)\big((a_--1)\lambda_-^{a_-}-a_-\tilde{\lambda}_-\lambda_-^{a_--1}+\tilde{\lambda}_-^{a_-}\big).\nonumber
	\end{align}
	It is trivial that we obtain the same result given above when we apply L'Hopital's rule to $\alpha \neq \pm1$.
	
	For $\alpha=1$, it is possible to use the same ways mentioned above. Alternatively, we also can leverage $\alpha$-duality with $\alpha=-1$. By following the similar calculation, the $\alpha$-divergence is obtained as
	\begin{align}
	D^{(1)}(\mathbb{P}||\mathbb{Q})=&D^{(-1)}(\mathbb{Q}||\mathbb{P})\nonumber\\
	=&TC_+\Gamma(-a_+)\big((a_+-1)\tilde{\lambda}_+^{a_+}-a_+\lambda_+\tilde{\lambda}_+^{a_+-1}+\lambda_+^{a_+}\big)\nonumber\\
	&+TC_-\Gamma(-a_-)\big((a_--1)\tilde{\lambda}_-^{a_-}-a_-\lambda_-\tilde{\lambda}_-^{a_--1}+\lambda_-^{a_-}\big).\nonumber
	\end{align}
	It is also straightforward to obtain the same result by using the direct calculation or L'Hopital's rule.
	\end{proof}

	In another way, we also can derive the $\alpha$-divergence between GTS processes from Eq. (\ref{log_radon_nikodym_gts}) and Eq. (\ref{a_div_measure_ts_psi}). Additionally, the $\alpha$-divergence can be obtained from Eq. (\ref{a_div_measure_ts_lambda}) or the similar expression with the tempering function of GTS processes.
	
	It is noteworthy that although the GTS processes have seven parameters, its geometry is reduced to two-dimensional manifolds due to the equivalent martingale measure conditions of Eq. (\ref{emm_gts}). The coordinate system for the GTS geometry is $\boldsymbol{\xi}=(\lambda_+,\lambda_-)$.
	
	From Eq. (\ref{levy_measure_gts}) and Eq. (\ref{metric_ts}) of Theorem \ref{thm_geo_ts}, the Fisher information matrix of GTS processes is found as
	\begin{align}
	\label{metric_gts}
		g_{ij}=\Bigg(
		\begin{array}{cc}
			\frac{TC_+\Gamma(2-a_+)}{\lambda_+^{2-a_+}} &0 \\ 
			0 & \frac{TC_-\Gamma(2-a_-)}{\lambda_-^{2-a_-}}
		\end{array}\Bigg),
	\end{align}
	where $i, j$ run for $\lambda_+$ and $\lambda_-$. We can obtain the same result from Eq. (\ref{metric_ts_lambda}) with the L\'evy measure or Eq. (\ref{metric_ts_t}) with the tempering function.
	
	It is easy to check that the metric tensor is diagonal. This diagonality makes sense due to the fact that the L\'evy measure of GTS processes, Eq. (\ref{levy_measure_gts}), is split by the $\lambda_+$ part and the $\lambda_-$ part using the indicator function. Additionally, $2-a_{\pm}$ are positive based on the parametrization of GTS distribution.
	
	Since Levi-Civita connection, that is the $0$-connection, is defined as
	\begin{align}
	\label{lc_conn}
		\Gamma^{LC}_{ij,k}=\frac{1}{2}(\partial_i g_{jk} +\partial_j g_{ik}-\partial_k g_{ij}),
	\end{align}
	the non-trivial components of the Levi-Civita connection in GTS geometry are obtained as
	\begin{align}
	\label{lc_conn_gts_p}
		\Gamma^{LC}_{\lambda_+\lambda_+,\lambda_+}&=-\frac{1}{2}\frac{TC_+\Gamma(3-a_+)}{\lambda_+^{3-a_+}},\\
	\label{lc_conn_gts_m}
		\Gamma^{LC}_{\lambda_-\lambda_-,\lambda_-}&=-\frac{1}{2}\frac{TC_-\Gamma(3-a_-)}{\lambda_-^{3-a_-}}.
	\end{align}

	From Eq. (\ref{levy_measure_gts}) and Eq. (\ref{conn_ts}) in Theorem \ref{thm_geo_ts}, the non-trivial $\alpha$-connection components of the GTS manifolds are given as
	\begin{align}
	\label{a_conn_gts_p}
	\Gamma^{(\alpha)}_{\lambda_+\lambda_+,\lambda_+}&=
	-\frac{1-\alpha}{2}\frac{TC_+\Gamma(3-a_+)}{ \lambda_+^{3-a_+}},\\
	\label{a_conn_gts_m}
	\Gamma^{(\alpha)}_{\lambda_-\lambda_-,\lambda_-}&=
	-\frac{1-\alpha}{2}\frac{TC_-\Gamma(3-a_-)}{ \lambda_-^{3-a_-}}.
	\end{align}
	All other components are vanishing. By plugging $\alpha=0$ to Eq. (\ref{a_conn_gts_p}) and Eq. (\ref{a_conn_gts_m}), we can obtain the same Levi-Civita connection, Eq. (\ref{lc_conn_gts_p}) and Eq. (\ref{lc_conn_gts_m}), respectively. This is expected because $0$-connection is the Levi-Civita connection. The same result can be calculated from Eq. (\ref{conn_ts_lambda}) with the L\'evy measure or Eq. (\ref{conn_ts_t}) with the tempering function. It is also noteworthy that the GTS geometry is e-flat.
	
	
\subsection{CTS processes}
	It is straightforward to obtain CTS geometry from all the results we obtained above for GTS processes by applying the CTS condition, Eq. (\ref{cts_condition}). 
	
	The $\alpha$-divergence between CTS processes are obtained as
	\begin{align}
	\label{a_div_cts}
	D^{(\alpha )}(\mathbb{P}||\mathbb{Q})=\left\{ 
	\begin{array}{ll}
	\frac{4TC\Gamma(-a)}{1-\alpha^2}\Big(\big( \frac{1-\alpha}{2} \lambda_+^{a}+\frac{1+\alpha}{2} \tilde{\lambda}_+^{a}-( \frac{1-\alpha}{2} \lambda_++\frac{1+\alpha}{2} \tilde{\lambda}_+)^{a}\big)\\
	+\big( \frac{1-\alpha}{2} \lambda_-^{a}+\frac{1+\alpha}{2} \tilde{\lambda}_-^{a}-( \frac{1-\alpha}{2} \lambda_-+\frac{1+\alpha}{2} \tilde{\lambda}_-)^{a}\big)\Big) & (\alpha \neq \pm 1)\\ 
	TC\Gamma(-a)\Big(\big((a-1)\lambda_+^{a}-a\tilde{\lambda}_+\lambda_+^{a-1}+\tilde{\lambda}_+^{a}\big)\\
	+\big((a-1)\lambda_-^{a}-a\tilde{\lambda}_-\lambda_-^{a-1}+\tilde{\lambda}_-^{a}\big)\Big) & (\alpha =-1)\\
	TC\Gamma(-a)\Big(\big((a-1)\tilde{\lambda}_+^{a}-a\lambda_+\tilde{\lambda}_+^{a-1}+\lambda_+^{a}\big)\\
	+\big((a-1)\tilde{\lambda}_-^{a}-a\lambda_-\tilde{\lambda}_-^{a-1}+\lambda_-^{a}\big)\Big) & (\alpha =1)
	\end{array}
	\right..
	\end{align}
	It is easily checked that the $\alpha=-1$ case in Eq. (\ref{a_div_cts}) is matched with Eq. (\ref{kld_cts}), which was originally obtained by Kim and Lee \cite{kim2007relative}.
	
	The Fisher information matrix of CTS processes can be obtained in three ways: Plugging the CTS condition of Eq. (\ref{cts_condition}) into the Fisher information matrix of GTS processes, Eq. (\ref{metric_gts}), using Eq. (\ref{metric_ts_lambda}) or Eq. (\ref{metric_ts_t}), or directly deriving from the $\alpha$-divergence of Eq. (\ref{a_div_cts}). These ways produce the same metric tensor of the CTS geometry as
	\begin{align}
	\label{metric_cts}
		g_{ij}=\Bigg(
		\begin{array}{cc}
			\frac{TC\Gamma(2-a)}{\lambda_+^{2-a}} &0 \\ 
			0 & \frac{TC\Gamma(2-a)}{\lambda_-^{2-a}}
		\end{array}\Bigg),
	\end{align}
	where $i,j$ run for $\lambda_+$ and $\lambda_-$. 
	
	Similar to the Fisher information matrix, the Levi-Civita connection of the CTS geometry are calculated from Eq. (\ref{lc_conn}) or by imposing the CTS condition of Eq. (\ref{cts_condition}) to Eq. (\ref{lc_conn_gts_p}) and Eq. (\ref{lc_conn_gts_m}). The non-trivial components of the Levi-Civita connection for the CTS geometry are found as
	\begin{align}
	\label{lc_conn_cts_p}
	\Gamma^{LC}_{\lambda_+\lambda_+,\lambda_+}&=-\frac{1}{2}\frac{TC\Gamma(3-a)}{\lambda_+^{3-a}},\\
	\label{lc_conn_cts_m}
	\Gamma^{LC}_{\lambda_-\lambda_-,\lambda_-}&=-\frac{1}{2}\frac{TC\Gamma(3-a)}{\lambda_-^{3-a}}.
	\end{align}
		
	By plugging the CTS condition of Eq. (\ref{cts_condition}) to Eq. (\ref{a_conn_gts_p}) and Eq. (\ref{a_conn_gts_m}) or using Eq. (\ref{levy_measure_cts}) and Eq. (\ref{conn_ts}) of Theorem \ref{thm_geo_ts}, the non-trivial components of the $\alpha$-connection for CTS processes are given as
	\begin{align}
	\label{a_conn_cts_p}
	\Gamma^{(\alpha)}_{\lambda_+\lambda_+,\lambda_+}&=
	-\frac{1-\alpha}{2}\frac{TC\Gamma(3-a)}{ \lambda_+^{3-a}},\\
	\label{a_conn_cts_m}
	\Gamma^{(\alpha)}_{\lambda_-\lambda_-,\lambda_-}&=
	-\frac{1-\alpha}{2}\frac{TC\Gamma(3-a)}{ \lambda_-^{3-a}}.
	\end{align}
	All other components are vanishing. Similar to the $\alpha$-connection of the GTS geometry, by plugging $\alpha=0$ to Eq. (\ref{a_conn_cts_p}) and Eq. (\ref{a_conn_cts_m}), we obtain the same Levi-Civita connection, Eq. (\ref{lc_conn_cts_p}) and Eq. (\ref{lc_conn_cts_m}), respectively. It is also possible to obtain the same result from Eq. (\ref{conn_ts_lambda}) or Eq. (\ref{conn_ts_t}). Similar to the GTS geometry, the CTS geometry is also e-flat.

\subsection{RDTS processes}
	In similar ways, we can derive the $\alpha$-divergence between RDTS processes from Theorem \ref{thm_div_ts}.
	
	\begin{crl}
		Let $(X_t, \mathbb{P})_{t\in[0,T]}$ and $(X_t, \mathbb{Q})_{t\in[0,T]}$ be RDTS processes with parameters $\boldsymbol{\xi}=(a_+, a_-, C_+, C_-,\lambda_+,\lambda_-,m)$ and $\tilde{\boldsymbol{\xi}}=(\tilde{a}_+, \tilde{a}_-, \tilde{C}_+, \tilde{C}_-,\tilde{\lambda}_+,\tilde{\lambda}_-,\tilde{m})$, respectively. Suppose $\mathbb{P}$ and $\mathbb{Q}$ are equivalent measures satisfying Eq. (\ref{emm_rdts}). Then we have $\alpha$-divergence between two RDTS processes as
	\begin{align}
	\label{a_div_rdts}
	D^{(\alpha )}(\mathbb{P}||\mathbb{Q})=\left\{ 
	\begin{array}{ll}
	\frac{4T}{1-\alpha ^{2}}\bigg(2^{-1-\frac{a_+}{2}}C_+\Gamma(-\frac{a_+}{2})\Big(\frac{1-\alpha}{2}\lambda_+^{\frac{a_+}{2}}+\frac{1+\alpha}{2}\lambda_+^{\frac{a_+}{2}}-\big(\frac{1-\alpha}{2}\lambda_++\frac{1+\alpha}{2}\tilde{\lambda}_+\big)^{\frac{a_+}{2}}\Big)\\
	%% (-)
	+2^{-1-\frac{a_-}{2}}C_-\Gamma(-\frac{a_-}{2})\Big(\frac{1-\alpha}{2}\lambda_-^{\frac{a_-}{2}}+\frac{1+\alpha}{2}\lambda_-^{\frac{a_-}{2}}-\big(\frac{1-\alpha}{2}\lambda_-+\frac{1+\alpha}{2}\tilde{\lambda}_-\big)^{\frac{a_-}{2}}\Big)\bigg) & (\alpha \neq \pm 1)\\ 
	2^{-1-\frac{a_+}{2}}TC_+\Gamma(-\frac{a_+}{2})\big((\frac{a_+}{2}-1)\lambda_+^{\frac{a_+}{2}}-\frac{a_+}{2}\tilde{\lambda}_+\lambda_+^{\frac{a_+}{2}-1}+\tilde{\lambda}_+^{\frac{a_+}{2}}\big)\\
	+2^{-1-\frac{a_-}{2}}TC_-\Gamma(-\frac{a_-}{2})\big((\frac{a_-}{2}-1)\lambda_-^{\frac{a_-}{2}}-\frac{a_-}{2}\tilde{\lambda}_-\lambda_-^{\frac{a_-}{2}-1}+\tilde{\lambda}_-^{\frac{a_-}{2}}\big) & (\alpha =-1)\\
	2^{-1-\frac{a_+}{2}}TC_+\Gamma(-\frac{a_+}{2})\big((\frac{a_+}{2}-1)\tilde{\lambda}_+^{\frac{a_+}{2}}-\frac{a_+}{2}\lambda_+\tilde{\lambda}_+^{\frac{a_+}{2}-1}+\lambda_+^{\frac{a_+}{2}}\big)\\
	+2^{-1-\frac{a_-}{2}}TC_-\Gamma(-\frac{a_-}{2})\big((\frac{a_-}{2}-1)\tilde{\lambda}_-^{\frac{a_-}{2}}-\frac{a_-}{2}\lambda_-\tilde{\lambda}_-^{\frac{a_-}{2}-1}+\lambda_-^{\frac{a_-}{2}}\big) & (\alpha =1)
	\end{array}
	\right.
	\end{align}
	\end{crl}
	\begin{proof}
	Since other cases can be derived from $\alpha \neq \pm 1$, let us start with $\alpha \neq \pm 1$.
	
	For $\alpha \neq \pm 1$, the $\alpha$-divergence is given by Eq. (\ref{a_div_measure_ts}):
	\begin{align}
		D^{(\alpha)}(\mathbb{P}||\mathbb{Q})=\frac{4T}{1-\alpha ^{2}}\int \Big(\frac{1-\alpha}{2}\Big(\frac{d\nu^\mathbb{P}}{d\nu^\mathbb{Q}}\Big) +\frac{1+\alpha}{2}-\Big(\frac{d\nu^\mathbb{P}}{d\nu^\mathbb{Q}}\Big)^{\frac{1-\alpha}{2}}\Big) \nu^\mathbb{Q}(dx).\nonumber
	\end{align}
	
	For positive $x$, the $\alpha$-divergence of RDTS processes is expressed by
	\begin{align}
		&D^{(\alpha)}(\mathbb{P}||\mathbb{Q})|_{+}=\frac{4T}{1-\alpha ^{2}}\int_0^\infty \Big(\frac{1-\alpha}{2}{\rm e}^{-\frac{(\lambda_+-\tilde{\lambda}_+)}{2}x^2} +\frac{1+\alpha}{2}- \Big({\rm e}^{-\frac{(\lambda_+-\tilde{\lambda}_+)}{2}x^2}\Big)^{\frac{1-\alpha}{2}}\Big)\frac{C_+{\rm e}^{-\frac{\tilde{\lambda}_+}{2} x^2}}{x^{a_++1}} dx\nonumber\\
	&\propto C_+\int_0^\infty \Big(\frac{1-\alpha}{2}\frac{{\rm e}^{-\frac{\lambda_+}{2} x^2}}{x^{a_++1}} +\frac{1+\alpha}{2}\frac{{\rm e}^{-\frac{\tilde{\lambda}_+}{2} x^2}}{x^{a_++1}} -\frac{{\rm e}^{-\frac{1}{2}(\frac{1-\alpha}{2}\lambda_++\frac{1+\alpha}{2}\tilde{\lambda}_+) x^2}}{x^{a_++1}} \Big)dx\nonumber\\
	&=\frac{C_+}{2}\int_0^\infty \Big(\frac{1-\alpha}{2}\frac{(\frac{\lambda_+}{2})^{a_+/2}{\rm e}^{-t}}{t^{a_+/2+1}} +\frac{1+\alpha}{2}\frac{(\frac{\tilde{\lambda}_+}{2})^{a_+/2}{\rm e}^{-t}}{t^{a_+/2+1}} -\frac{(\frac{1-\alpha}{2}\lambda_++\frac{1+\alpha}{2}\tilde{\lambda}_+)^{a_+/2}{\rm e}^{-t}}{t^{a_+/2+1}} \Big)dt\nonumber\\
	&=2^{-1-\frac{a_+}{2}}C_+\Gamma(-\frac{a_+}{2})\Big(\frac{1-\alpha}{2}\lambda_+^{\frac{a_+}{2}}+\frac{1+\alpha}{2}\lambda_+^{\frac{a_+}{2}}-\big(\frac{1-\alpha}{2}\lambda_++\frac{1+\alpha}{2}\tilde{\lambda}_+\big)^{\frac{a_+}{2}}\Big).\nonumber
	\end{align}
	After the similar calculation is done to the negative $x$ part, the $\alpha$-divergence for $\alpha \neq \pm 1$ is given by
	\begin{align}
	D^{(\alpha)}(\mathbb{P}||\mathbb{Q})=&\frac{4T}{1-\alpha ^{2}}\bigg(2^{-1-\frac{a_+}{2}}C_+\Gamma(-\frac{a_+}{2})\Big(\frac{1-\alpha}{2}\lambda_+^{\frac{a_+}{2}}+\frac{1+\alpha}{2}\lambda_+^{\frac{a_+}{2}}-\big(\frac{1-\alpha}{2}\lambda_++\frac{1+\alpha}{2}\tilde{\lambda}_+\big)^{\frac{a_+}{2}}\Big)\nonumber\\
	%% (-)
	&+2^{-1-\frac{a_-}{2}}C_-\Gamma(-\frac{a_-}{2})\Big(\frac{1-\alpha}{2}\lambda_-^{\frac{a_-}{2}}+\frac{1+\alpha}{2}\lambda_-^{\frac{a_-}{2}}-\big(\frac{1-\alpha}{2}\lambda_-+\frac{1+\alpha}{2}\tilde{\lambda}_-\big)^{\frac{a_-}{2}}\Big)\bigg).\nonumber
	\end{align}
	
	For $\alpha=-1$, there are two ways for proof. The first way is plugging Eq. (\ref{radon_nikodym_rdts}) to Eq. (\ref{a_div_measure_ts}) (or Eq. (\ref{log_radon_nikodym_rdts}) to Eq. (\ref{a_div_measure_ts_psi}). Another way of calculating the Kullback-Leibler divergence is applying L'Hopital's rule to $\alpha \neq \pm1$ in the limit of $\alpha\to-1$. We obtain the same result.
	
	We show the first. Similar to $\alpha \neq \pm1$, we can start with the positive $x$ part of the Kullback-Leibler divergence:
	\begin{align}
	D^{(-1)}(\mathbb{P}||\mathbb{Q})|_{+}&=TC_+\int_0^\infty \Big(\frac{{\rm e}^{-\frac{\lambda_+}{2}x^2}}{x^{a_++1}}\big(-\frac{(\lambda_+-\tilde{\lambda}_+)}{2}x^2-1\big) + \frac{{\rm e}^{-\frac{\tilde{\lambda}_+}{2}x^2}}{x^{a_++1}}\Big)dx\nonumber\\
	&=2^{-1-\frac{a_+}{2}}TC_+\Gamma(-\frac{a_+}{2})\big(\frac{a_+}{2}\lambda_+^{\frac{a_+}{2}-1}(\lambda_+-\tilde{\lambda}_+)-\lambda_+^{\frac{a_+}{2}}+\tilde{\lambda}_+^{\frac{a_+}{2}}\big)\nonumber\\
	&=2^{-1-\frac{a_+}{2}}TC_+\Gamma(-\frac{a_+}{2})\big((\frac{a_+}{2}-1)\lambda_+^{\frac{a_+}{2}}-\frac{a_+}{2}\tilde{\lambda}_+\lambda_+^{\frac{a_+}{2}-1}+\tilde{\lambda}_+^{\frac{a_+}{2}}\big).\nonumber
	\end{align}
	
	Repeating the same step for negative $x$, the Kullback-Leibler divergence between two RDTS processes is given as
	\begin{align}
	D^{(-1)}(\mathbb{P}||\mathbb{Q})=&2^{-1-\frac{a_+}{2}}TC_+\Gamma(-\frac{a_+}{2})\big((\frac{a_+}{2}-1)\lambda_+^{\frac{a_+}{2}}-\frac{a_+}{2}\tilde{\lambda}_+\lambda_+^{\frac{a_+}{2}-1}+\tilde{\lambda}_+^{\frac{a_+}{2}}\big)\nonumber\\
	&+2^{-1-\frac{a_-}{2}}TC_-\Gamma(-\frac{a_-}{2})\big((\frac{a_-}{2}-1)\lambda_-^{\frac{a_-}{2}}-\frac{a_-}{2}\tilde{\lambda}_-\lambda_-^{\frac{a_-}{2}-1}+\tilde{\lambda}_-^{\frac{a_-}{2}}\big).\nonumber
	\end{align}
		
	For $\alpha=1$, we can exploit the same ways mentioned above. Additionally, we also can leverage $\alpha$-duality with $\alpha=-1$. By following the similar calculation, the $\alpha$-divergence is obtained as
	\begin{align}
	D^{(1)}(\mathbb{P}||\mathbb{Q})=&D^{(-1)}(\mathbb{Q}||\mathbb{P})\nonumber\\
	=&2^{-1-\frac{a_+}{2}}TC_+\Gamma(-\frac{a_+}{2})\big((\frac{a_+}{2}-1)\tilde{\lambda}_+^{\frac{a_+}{2}}-\frac{a_+}{2}\lambda_+\tilde{\lambda}_+^{\frac{a_+}{2}-1}+\lambda_+^{\frac{a_+}{2}}\big)\nonumber\\
	&+2^{-1-\frac{a_-}{2}}TC_-\Gamma(-\frac{a_-}{2})\big((\frac{a_-}{2}-1)\tilde{\lambda}_-^{\frac{a_-}{2}}-\frac{a_-}{2}\lambda_-\tilde{\lambda}_-^{\frac{a_-}{2}-1}+\lambda_-^{\frac{a_-}{2}}\big)\nonumber.
	\end{align}
	\end{proof}
	
	It is noteworthy that the $\alpha$-divergence of RDTS processes is similar to those of CTS processes and GTS processes. It has additional scale factors, $2^{-1-\frac{a_\pm}{2}}$, and $a_{\pm}$ is replaced with $a_{\pm}/2$.

	From Eq. (\ref{levy_measure_rdts}) and Eq. (\ref{metric_ts}) in Theorem \ref{thm_geo_ts}, the Fisher information matrix of RDTS processes is found in the coordinate system of $\xi=(\lambda_+,\lambda_-)$ as
	\begin{align}
	\label{metric_rdts}
		g_{ij}=\Bigg(
		\begin{array}{cc}
			\frac{2^{-1-\frac{a_+}{2}}TC_+\Gamma(2-\frac{a_+}{2})}{\lambda_+^{2-\frac{a_+}{2}}} &0 \\ 
			0 & \frac{2^{-1-\frac{a_-}{2}}TC_-\Gamma(2-\frac{a_-}{2})}{\lambda_-^{2-\frac{a_-}{2}}}
		\end{array}\Bigg),
	\end{align}
	where $i, j$ run for $\lambda_+$ and $\lambda_-$. We can obtain the same Fisher information matrix from Eq. (\ref{metric_ts_lambda}) or Eq. (\ref{metric_ts_t}).
	
	The diagonal metric tensor is explainable due to the same rationale regarding the indicator function with CTS processes and GTS processes. Additionally, based on the parametrization of RDTS distribution, $2-\frac{a_{\pm}}{2}$ are positive.
	
	By Eq. (\ref{lc_conn}), the non-trivial Levi-Civita connection components of the RDTS geometry are obtained as
	\begin{align}
	\label{lc_conn_rdts_p}
		\Gamma^{LC}_{\lambda_+\lambda_+,\lambda_+}&=-\frac{1}{2}\frac{2^{-1-\frac{a_+}{2}}TC_+\Gamma(3-\frac{a_+}{2})}{\lambda_+^{3-\frac{a_+}{2}}},\\
	\label{lc_conn_rdts_m}
		\Gamma^{LC}_{\lambda_-\lambda_-,\lambda_-}&=-\frac{1}{2}\frac{2^{-1-\frac{a_-}{2}}TC_-\Gamma(3-\frac{a_-}{2})}{\lambda_-^{3-\frac{a_-}{2}}}.
	\end{align}

	From Eq. (\ref{levy_measure_rdts}) and Eq. (\ref{conn_ts}) in Theorem \ref{thm_geo_ts}, the non-trivial $\alpha$-connection components of the RDTS manifolds are given as
	\begin{align}
	\label{a_conn_rdts_p}
	\Gamma^{(\alpha)}_{\lambda_+\lambda_+,\lambda_+}&=
	-\frac{1-\alpha}{2}\frac{2^{-1-\frac{a_+}{2}}TC_+\Gamma(3-\frac{a_+}{2})}{ \lambda_+^{3-\frac{a_+}{2}}},\\
	\label{a_conn_rdts_m}
	\Gamma^{(\alpha)}_{\lambda_-\lambda_-,\lambda_-}&=
	-\frac{1-\alpha}{2}\frac{2^{-1-\frac{a_-}{2}}TC_-\Gamma(3-\frac{a_-}{2})}{ \lambda_-^{3-\frac{a_-}{2}}}.
	\end{align}
	All other components are vanishing. By plugging $\alpha=0$ to Eq. (\ref{a_conn_rdts_p}) and Eq. (\ref{a_conn_rdts_m}), we can calculate the same Levi-Civita connection, Eq. (\ref{lc_conn_rdts_p}) and Eq. (\ref{lc_conn_rdts_m}). The same $\alpha$-connection can be obtained from Eq. (\ref{conn_ts_lambda}) or Eq. (\ref{conn_ts_t}). Similar to the GTS geometry and the CTS geometry, it is also obvious that the RDTS geometry is e-flat.

\section{Applications}
\label{sec_apps}
	In this section, we introduce statistical applications for GTS processes based on the information geometry. Since the geometry of CTS processes and RDTS processes is similar to the GTS geometry, we can apply the findings in this section to those two processes.

\subsection{Bias reduction}
	First of all, we apply our findings to bias reduction in maximum likelihood estimates. Firth \cite{firth1993bias} suggested a more systematic bias reduction in maximum likelihood estimation process. When the geometry is e-flat, the penalized log-likelihood given in Firth \cite{firth1993bias} can be written as
	\begin{align}
	\label{penalized_ll}
		l^{*}(\xi)=l(\xi)+\log \mathcal{J},
	\end{align}
	where $l(\xi)$ is log-likelihood and $\mathcal{J}$ is the Jeffreys prior. From the penalized log-likelihood, we can find bias reduced parameters.
	
	Jeffreys prior, a non-informative prior distribution, is defined as follows \cite{jeffreys1946invariant}:
	\begin{align}
		\mathcal{J}(\xi)\propto g^{\frac{1}{2}},
	\end{align}
	where $g$ is the determinant of the Fisher information matrix which is the metric tensor of information geometry.
	
	From the Fisher information matrix of GTS processes, Eq. (\ref{metric_gts}), it is easy to obtain the Jeffreys prior of GTS processes as
	\begin{align}
		\label{jeffreys_gts}
		\mathcal{J}(\xi)\propto T\sqrt{\frac{C_+\Gamma(2-a_+)}{\lambda_+^{2-a_+}} \frac{C_-\Gamma(2-a_-)}{\lambda_-^{2-a_-}}}.
	\end{align}
	
	By applying Eq. (\ref{jeffreys_gts}) to Eq. (\ref{penalized_ll}), we can estimate bias reduction parameters for GTS processes.
	
\subsection{Bayesian predictive priors}
	Another application is finding Bayesian predictive priors for GTS processes. From the metric tensor of the GTS geometry, we calculate several ansatz satisfying the superharmonicity for obtaining the shrinkage priors \cite{komaki2006shrinkage}.
		
	Komaki derived Bayesian predictive priors outperforming the Jeffreys prior \cite{komaki2006shrinkage}. The Bayesian predictive prior is represented with
	\begin{align}
		\tilde{\mathcal{J}}=\phi \mathcal{J},
	\end{align}
	where $\phi$ is a superharmonic function and $\mathcal{J}$ is the Jeffreys prior.
	
	Komaki-style shrinkage priors for time series models and signal filters are already well-known. We have explicit forms of the predictive priors for AR models \cite{komaki2006shrinkage,tanaka2018superharmonic}, ARMA model \cite{choi2015kahlerian, choi2015geometric, oda2021shrinkage}, and signal processing filters \cite{choi2015geometric}.
	
	Similar to the previous work on finding ansatze for Bayesian predictive priors of signal processing filters \cite{choi2015geometric}, we can calculate ansatze for GTS processes. Let us try to find ansatze for superharmonic functions $\phi$ based on the GTS geometry. 
	
	The first ansatz is a function in $\lambda_+$:
	\begin{align}
		\phi_1=\lambda_+^k,
	\end{align}
	where $\min(0,a_+-1)<k<\max(0,a_+-1)$. It is easy to check that it is a positive superharmonic function.

	Similarly, we can construct another ansatz in $\lambda_-$:	
	\begin{align}
		\phi_2=\lambda_-^l,
	\end{align}
	where $\min(0,a_--1)<l<\max(0,a_--1)$. It is also straightforward to check the superharmonicitiy of the ansatz.
	
	We can consider positive linear combination and multiplication of $\phi_1$ and $\phi_2$:
	\begin{align}
		\phi_3&= c_1\phi_1+c_2\phi_2,\\
		\phi_4&= \phi_1\phi_2,
	\end{align}
	where $c_1>0$ and $c_2>0$. It is straightforward to check that these are also positive superharmonic functions.
		
\section{Conclusion}
	We derive the information geometry of tempered stable processes. First of all, finding $\alpha$-divergence between two tempered stable processes is the two-folded generalization of the work by Kim and Lee \cite{kim2007relative}: From CTS processes to tempered stable processes and from the Kullback-Leibler divergence to the $\alpha$-divergence. 
	
	From the $\alpha$-divergence of tempered stable processes, we obtain the information geometry of tempered stable processes: Fisher information matrix and $\alpha$-connection. Since the GTS process parameters for the upper and lower tails are not entangled with each other, the metric tensor of the GTS process geometry is diagonal. Additionally, the $\alpha$-connection of the geometry is e-flat. 

	With these geometric objects, we also provide several information-geometric applications for GTS processes. First of all, we consider bias reduction in maximum likelihood estimation for parameter estimation. Additionally, Bayesian predictive priors outperforming the Jeffreys prior are also found. 

\section*{Acknowledgment}
	We thank Young Shin Kim for useful discussions on tempered stable process/distribution and the relative entropy of CTS processes.
	
\bibliographystyle{plain}
\bibliography{ig_gts}

\end{document}