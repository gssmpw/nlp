\newpage

\section{Results}

\subsection{Evaluating Warning Banner Prevalence and Characteristics}
\label{sec:evaluating}

\para{Warning banners are rare} 
Using our dataset of 1.4M unique search queries that were shared on social media (Methods~\ref{sec:methods-directives}), we collected the corresponding SERP for each query in three primary waves (October 2023, March 2024, and September 2024; Methods~\ref{sec:methods-serps}).
Across all waves, we found that Google displayed one of its three distinct banner types (Figure~\ref{fig:banner_ex}) in the search results for about 1\% of our queries.
Low-relevance banners were the most common banner type, accounting for 97.9\% or more of the banners seen in each crawl.
Low-quality banners were the next most prevalent, accounting for 2.1\% of all banners in crawl-1 and 1.5\% in crawl-2, but never appeared in crawl-3.
In contrast, rapidly-changing banners consistently appeared across crawls but were exceedingly rare, appearing only twice in crawl-1 and crawl-2 (for different queries), and 10 times in crawl-3.
Given how rare rapidly-changing banners were, which was expected due to their time-sensitive nature, our analysis focuses on the low-relevance and low-quality banners.
Additional details on the warning banner types we observed are available in Appendix~\ref{sec:appendix-banners}.

\para{Warning banners are associated with low-quality domains, longer queries, and conspiracy-related queries} 
To evaluate the factors associated with warning banner presence, we used a set of features related to each search query (Methods~\ref{sec:methods-queries}), its corresponding search results, and several domain-level metrics (Methods~\ref{sec:methods-domains}), as dependent variables in logistic regression models (Methods~\ref{sec:methods-logit}).
This includes the presence of partisan or conspiracy-related terms in the search query, and quality scores for the domains appearing in the search results.
In line with its stated purpose, having a low average domain quality score (at the SERP level) was the feature most associated with the presence of low-quality banners.
For low-relevance banners, having longer search queries (word count) was the feature most associated with their presence (Figure~\ref{fig:logit}), which also aligns with their stated purpose, as finding relevant results for long queries may be a challenging task and Google has a 32-word limit on query length (Methods~\ref{sec:methods-directives-queries}).

For both banner types, the use of conspiracy-related keywords in the search query was consistently the second largest positive association with banner presence, and political keywords had a consistent positive association for low-relevance but not low-quality banners.
With respect to negative associations, the estimated total number of results---Google's self-reported estimate for the number of webpage matches found for the query across their full index---and average domain traffic both consistently had a negative association with the presence of either banner type across all crawls.
In contrast to its relationship with low-quality banners, low domain quality had a directionally inconsistent association with the presence of low-relevance banners.

\begin{figure}[t!]
    \centering
    \begin{subfigure}[t]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth,trim={0.6cm 0 0.2cm 0.1cm},clip]{figs/plots/logit/coef-banner_quality-no-impute.pdf}
        \label{fig:logit-quality}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth,trim={0.6cm 0 0.2cm 0.1cm},clip]{figs/plots/logit/coef-banner_topicality-no-impute.pdf}
        \label{fig:logit-relevance}
    \end{subfigure}
    \caption{Across crawls, having low-quality domains in the SERP was the feature most associated with the presence of low-quality banners (left), while the length of a search query was the feature most associated with low-relevance banners (right).
    For both banner types, the use of conspiracy-related keywords in the search query was consistently the second largest positive association.
    In contrast, Google's estimated total number of results, average domain traffic, and the number of news domains on a SERP all had a consistent negative association with the presence of either banner type.
    The use of an advanced operator in a search query had a consistent strong negative association with low-relevance banners, but queries containing such operators never produced a low-quality banner.
    Detailed regression tables are available in Appendix~\ref{sec:appendix-logit}.}
    \label{fig:logit}
\end{figure}

\para{Low-quality banners do not appear when queries contain advanced operators} 
In total, 1.5\% of our search queries contained an advanced operator (Methods~\ref{sec:methods-queries-operators}).
These can be used, for example, to restrict one's search results to a specific website (e.g., ``site:cnn.com''), such that the results only consist of matches for that query within that website.
While our logistic regression models suggest that the use of an advanced operator consistently had a strong negative association with the presence of low-relevance banners across crawls, none of our queries containing such operators ever returned a low-quality banner.
Examining the queries with advanced operators that returned low-quality SERPs (average domain quality < 0.5), we found a number of cases in which the advanced operator was designed to limit the search results to one or more domains with low domain quality scores.
For example, the queries ``ginko site:naturalnews.com'' (which has a quality score of 0), ``site:stormfront.org "sleepy eyes"'' (quality score 0.05), and ``"deep state" site:infowars.com'' (quality score 0.05), all returned search results exclusively from those domains, but never produced a low-quality banner.
We also found more complex queries that combine advanced operators to exert greater control over the results returned (see Methods~\ref{sec:methods-queries-operators}).
In the context of people being intentionally guided into data voids~(\cite{tripodi2023your}; \cite{robertson2023identifying}), these results suggest that the use of advanced operators may provide a loophole for evading Google's warning banners. 

\subsection{Measuring Warning Banner Consistency and Stability}
\label{sec:measuring}

\para{There is substantial churn in low-quality banner presence over time, but small improvements to average domain quality}
Between our first two crawls, we found a decrease in the number of queries that received a low-quality banner (from 0.021\% of all queries in crawl-1 to 0.015\% in crawl-2), and substantial churn in which queries received a low-quality banner.
Among the 301 queries that received a low-quality banner in the first crawl, 154 no longer received one in crawl-2, and 74 queries that had not previously received a banner then did.
These changes were accompanied by substantial churn in the search results returned for our queries, and only 35.7\% (SD=18.0\%) of the URLs returned for a given query in October 2023 were still returned when we searched the same query in March 2024.
We found a similar rate of turnover the gap between the crawl-2 and crawl-3, with only 33.7\% (SD=17.9\%) of the URLs returned in March 2024 still present in September 2024.
Despite this high rate of change in URLs, the average domain quality of the SERPs we collected only improved by 1.0\% overall, from crawl-1 (0.782) to crawl-3 (0.792), and by 0.5\% (SD=6.4\%) when using query-paired differences.
These results suggest that the three core updates and two spam updates that Google completed during our study~\citep{google2025google} did not have a large impact on average domain quality, but these overall averages may hide differences among specific subsets of queries, such as those that received a low-quality warning banner in one of the first two crawls.

\para{Queries that used to receive low-quality banners still return low quality SERPs}
To consider the changes that might have led to the absence of the low-quality banners in crawl-3, we examined the subset of queries that received such a banner in either of the first two crawls (N=375, 0.03\% of all queries).
Although they no longer received a low-quality banner in crawl-3, many of these queries continued to produce low-quality SERPs (Figure~\ref{fig:banner_change_quality}).
For example, among these 375 queries, 34.7\% received a low-quality banner in both of the first two crawls but no banner in the third crawl.
Examining this subset, we found an increase in average domain quality between the first two crawls (0.035 paired, from 0.538 to 0.627) when the banner was present, and a smaller decrease between the second and third crawls when the banner no longer appeared (0.022 paired; from  0.627 to 0.619).
A similar pattern held for the 33.3\% of these queries that received a low-quality banner in the first crawl but no banner in either of the subsequent crawls.
Last, for the 17.9\% of these queries that received a low-quality banner in the second crawl, but no banner in the first or third crawls, we found that their average domain quality scores consistently increased across crawls (0.077 paired crawl-1 to crawl-2, 0.072 paired crawl-2 to crawl-3).
These results suggest that, rather than no longer being needed due to a shift in quality, the low-quality banners may have been discontinued.

One of the queries that received a low-quality banner in both crawls 1 and 2, but not 3, is ``naturalnews "the coming delta lockdown is designed to invoke nationwide protests".''
This query consistently returned the same exact webpage in top ranked result---a naturalnews.com article that claims the COVID lockdowns for the delta strain were ``designed to invoke nationwide protests ... to blame "anti-vaxxers"''---and other results that generally support a similar narrative.
Another example is ``vril lizards droning process,'' which had more turnover in the results, but ultimately returned a similar set of websites supporting a conspiracy theory about mythical parasite lizards (see Appendix~\ref{fig:appendix-vril}). 
Last, the query ``"underground war" qanon blessed2teach'' returned results leading to QAnon-related content in every crawl, and searching this query at the time of this writing (February 2025), the top result leads to a webpage titled ``Is Trump Safe? CIA, MI6, Mossad Plot ...''

\begin{figure}[t!]
    \centering
    \includegraphics[width=\textwidth]{figs/plots/banner-change-quality.png}
    \caption{Many of the queries that received a low-quality banner in either (or both) of the first two crawls, continued to produce low-quality SERPs in the third crawl without a banner. Here we present the domain quality score distributions for the top three banner histories, which account for 85.9\% of all banner histories that include a low-quality banner.}
    \label{fig:banner_change_quality}
\end{figure}

\para{Low-quality banner presence is inconsistent over short time spans} 
Prior to the discontinuation of the low-quality banners, we collected a temporally dense set of search results using the 301 queries that received a low-quality banner in the first crawl. 
We conducted these queries on a more rapid collection schedule for a period of 73 time steps spaced about 4.5 hours apart (Methods~\ref{sec:methods-stability}), resulting in 1.05M search results over 22K SERPs. We collected the first 100 results for each query, but many queries consistently had fewer than 100 results. Using the Jaccard index as a pairwise measure of similarity between each timestep, we found that the minimum similarity between any two time periods was 0.79, the average similarity (excluding the diagonal) was 0.88 (Figure~\ref{fig:jaccard_qry}), and there was only one instance in which two time steps shared the exact same set of queries.
These results are consistent with a similar dataset that we collected in March 2024, where we used the same set of 301 queries, but collected data every 1.5 hours for 34 time steps (see Appendix~\ref{sec:appendix-consistency-pilot}).
These results suggest that Google's policy for placing low-quality banners is not based solely on text of the search query, turning our attention to the distribution of results returned for a query.

\begin{figure}[tb!]
    \centering
    \begin{subfigure}[t]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figs/plots/jac_sim_qry.png}
        \caption{Heatmap cells show the pairwise Jaccard similarity of the set of queries that returned a quality banner over all 73 time-steps. Data collection issues resulted in gaps at steps 18 and 41, which account for the steepest plot gradient changes (see Appendix~\ref{sec:appendix-consistency}).}
        \label{fig:jaccard_qry}
    \end{subfigure}
    \hfill %
    \begin{subfigure}[t]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figs/plots/quality_RBO_groups_12.png}
        \caption{Similarity of SERPs measured by using mean \(RBO_k\) (y-axis) over 12 window sizes (x-axis). Queries were divided into groups based on whether the SERPs they produced received a banner in 0, 1-20, 21-51, 52-72, or all 73 time steps (legend).
        }
        \label{fig:rbogroups}
    \end{subfigure}
    \caption{The set of queries that receives a low-quality banner frequently change over short time spans, and queries that consistently receive banners also have relatively consistent search results.}
\end{figure}

\para{Low-quality banner presence is more consistent for stable results} 
To examine differences over time, we used Rank-Biased Overlap (RBO), a similarity metric well suited for comparing ranked lists~\citep{webber2010similarity}, with a sliding window ($RBO_k$; see Methods~\ref{sec:methods-stability}).
We found that the queries that consistently received a low-quality banner in the temporally dense dataset also had the most consistent search results over time (Figure~\ref{fig:rbogroups}). 
Among the 301 queries used to construct this dataset, five did not return search results at any time step, 166 did not produce a low-quality banner at any timestep, and 40 always produced one, leaving 90 with at least some variation in their banner production.
To help account for these cases, we calculated $RBO_k$ for several different banner-count groups, but found that RBO monotonically decreases as window size $k$ increases across all groups, highlighting a consistent churn in search results over time.
However, despite sharing this general pattern, the queries that always returned low-quality banners had the most stable search results across all window sizes, and the queries that did not produce any low-quality banners had the least stable search results at every $k$. 
Consistent with our logistic regressions on the main crawl data, these results suggest that the search results, rather than the search query, may be the more important factor for determining why a low-quality banner was shown.

\begin{figure}[tb!]
    \centering
    \begin{subfigure}[t]{0.49\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figs/plots/advancedsearchbarplot_annotated.png}
    \caption{The presence of the first archive.ph URL (``archive.ph...aocz'') can explain all banners displayed for ``advanced search result manipulation technology'' observed over 73 time steps.}
    \label{fig:cip_bar}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.49\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figs/plots/mrna_annotated.png}
    \caption{While some URLs are more associated with banners than others, no single URL can explain every banner for ``mrna prions''.}
    \label{fig:mrnaq1}
    \end{subfigure}
    \caption{The presence of specific URLs can sometimes fully explain the presence of low-quality banners for certain queries (left), but not for others (right). The vertical line indicates the total number of banners observed for the query. If every time a URL appears there is a banner (red bar) and never appears with no banner (black bar), the URL can fully explain observed banners for the query.}
\end{figure}

\para{The presence of specific URLs does not fully explain low-quality banner presence} 
To examine whether the presence of certain URLs might trigger low-quality banners, we used the subset of data for the 90 queries in our temporally dense dataset that produced SERPs both with and without low-quality banners.
We use this subset of queries because the variance in their banner presence can be leveraged to compare the conditions under which a banner does or does not appear (Appendix~\ref{sec:methods-stability-dependency}). 
For 25 of these 90 queries, we were able to pinpoint a single URL that was always present in its search results when it received a low-quality banner, but never present when it did not (Figure~\ref{fig:cip_bar}).
However, the remaining majority of queries did not have a single URL that met the same conditions.
For example, the query \textit{``mrna prions''}---which consistently surfaced anti-vaccine articles and social media posts in its top 10 results (Appendix \ref{sec:appendix-examples-prions})---returned a low-quality banner in 56 of the 73 timesteps and had a URL that was highly associated with banner presence, but its presence in the SERP was not required for the query to receive a banner (Figure \ref{fig:mrnaq1}).
Extending this measure to account for the presence of two URLs only helped to explain low-quality banner presence for four additional queries (29 of the 90 queries). 
Further extending this measure to three URLs allowed us to fully explain 67 of the 90 queries.

\para{URL rankings do not fully explain low-quality banner presence}
We further examined the role of URL presence by conditioning URL-pairs on rank cutoffs.
This approach allowed us to check for determinative cases where a pair of URLs appeared in the search results, within a specific range of rankings, and always received a banner (see Appendix~\ref{sec:appendix-consistency} for a formal definition).
We found that at least one rank cutoff could explain the presence of low-quality banners for 65 queries of 90 across all timesteps, and a cutoff of $c=1$ (i.e., the top-ranked URL) was able to explain the largest proportion of those queries (48 of 65). 
Although some queries were fully explainable with larger cutoff values (i.e. $c>1$), the proportion of banners explainable by subsequent cutoffs ($c=\{2, \dots, 50\}$) decreases monotonically.
These results suggest that the first results on a SERP are an important factor in determining banner placement, but still do not fully explain the presence of low-quality banners.

\subsection{Predicting Warning Banner Presence}
\label{sec:predicting}

Advancing on our evaluation of the policies that govern Google's warning banners, we also used our dataset to develop deep learning models that can incorporate additional context and potentially aid in proactively identifying data voids. 
To that end, we built and tested three models: a homogeneous Graph Neural Network (GNN) and a heterogeneous GNN trained on a bipartite query to domain graph, and a fine-tuned DistilBERT model trained on query text (see Methods \ref{sec:methods-models}). Domain features are constructed only from content on SERP pages, and contain no domain-level features or domain reliability annotations. We demonstrate that even a relatively small GNNs with 1.05M parameters can effectively identify data voids and surface SERPs associated with unreliable domains. While we already demonstrated that query text alone cannot explain all banners, the association of quality banners with conspiratorial terms suggests some linguistic patterns may be present. We therefore elect to include DistilBERT as a text-only baseline. Given the small set of low-quality banners we observed, and the propensity of deep learning models to overfit, we include multiple evaluations that demonstrate the effectiveness of our proposed models.

\para{The GNN models outperform DistilBERT}
In line with our finding that low-quality banners do not depend on the text of the search query text alone, the DistilBERT (text-only) baseline was outperformed by the GNN approaches on all metrics except precision (Table~\ref{tbl:GNNResults}).
Among the GNN models, the heterogeneous GNN performed the best, outperforming both DistilBERT and the homogeneous GNN on accuracy, F1, precision, and recall. 
To calculate these statistics, we trained and evaluated each model ten times, each time drawing a different negative sample for the non-bannered class to mitigate the possibility of overfitting to a single negative sample. 
Additional details on these models, including preprocessing and model design, are available in Methods~\ref{sec:methods-models}.

\begin{table}[t!]
    \small
    \centering
    \caption{GNNs perform best on hold-out data and best identify new out-of-sample queries with low-quality banners. This table provides the mean and standard deviation for evaluation metrics over 10 runs on the hold-out test-set (left), and the out-of-sample evaluation (right), which includes the number of queries (out of the 74 queries that received a low-quality banner in crawl-2 but not crawl-1) in each model's $K$ most confident predictions.}
    \label{tbl:GNNResults}
    \input{tables/gnn-table-joined}
\end{table}

\para{GNNs best identify out-of-sample low-quality banners} 
We assessed our models' out-of-sample performance by using the differences in low-quality banner presence between crawl-1 and crawl-2.
Specifically, we examined how well each model confidently identified the 74 queries that did not have a low-quality banner in crawl-1 (October 2024), but did have one in crawl-2 (March 2024). 
To do so, we assessed how many of these 74 queries our models detected within their $K$ most confident quality banner predictions (with labeled data excluded).
The GNN models again outperformed the DistilBERT model, with the homogeneous model correctly including more of the newly-bannered 74 queries in its most confident 50, 500, and 1K predictions, and the heterogeneous model correctly including more of these queries in its most confident 100, 5K, and 10K predictions (Table~\ref{tbl:GNNResults}; see Appendix~\ref{sec:appendix-gnn} for additional details).
While these tests help establish the utility and validity of our GNN models~\citep{inoue2005sample}, we note that the inconsistencies we observed in low-quality banner placement over short time periods (Section~\ref{sec:measuring}) means the set of 74 queries and their corresponding SERPs that we used are not necessarily reflective of those that should receive a low-quality banner.

\para{GNNs identify SERPs with low average domain quality} 
Given the focus on reliability in the stated purpose of the low-quality banners (Figure~\ref{fig:banner_ex}A), the prevalence of domains with low-quality scores in a query's SERP provides a useful proxy for model evaluation.
A model's most confident ``low-quality banner'' predictions should be associated, on average, with the presence of less-reliable domains.
To investigate this relationship, we used the rolling mean of average domain quality over the 500 most confident banner predictions obtained from each model, and found the heterogeneous GNN model's predictions had the strongest relationship with domain quality (Figure~\ref{fig:qualwindow}). 
Average domain quality was calculated for each query as the simple average over all of its returned search results in each crawl, and we used a rolling mean with a window size of 10 to account for inherent noise in this metric.
Across crawls 1, 2, and 3, the heterogeneous model displayed the most robustness, and continued to identify queries associated with low-reliability domains on data extracted 5 months after its training data. As only 890k SERPs in crawl 1 had at least one non-social media website with a domain quality label,
many predictions across models are excluded. We note that the heterogeneous model is able to confidently predict SERPs associated with lower-quality domains despite our models not including any explicit domain-level reliability features.
These results suggest that the heterogeneous GNN model best learned to identify queries associated with unreliable domains, which helps validate our findings, and again point to the heterogeneous model as the best performer.

\begin{figure}[tb!]
\centering
\includegraphics[width=0.9\textwidth]{figs/plots/crawl1_and_crawl2_quality.png}
\caption{Heterogeneous GNNs best identify SERPs associated with unreliable domains. Each graph displays the rolling mean (window size of 10) of Domain Quality Scores over the 500 highest-confidence model predictions (lower scores indicate less reliable websites). With models trained on Crawl-1, we evaluated quality banner predictions for Crawl-1 (top), Crawl-2 (middle), and Crawl-3 (bottom).}
\label{fig:qualwindow}
\end{figure}

\para{GNNs identify queries that annotators agreed should have low-quality banners}
After manually examining the 301 queries that received a low-quality banner in crawl-1 (October 2023), two annotators labeled the top 20 predictions of each model based on their corresponding SERPs. 
One of these labels indicated whether or not the SERPs produced by each query should receive a low-quality banner (i.e. returned results that appeared to be low-quality), and there was substantial agreement (Cohen's $\kappa = 0.73$) between the two annotators~\citep{landis1977measurement}.
Both annotators agreed that the heterogeneous GNN model yielded the highest precision for the top 5, 10, and 20 predictions (Appendix~\ref{sec:appendix-gnn}, Table~\ref{tbl:precisionCIP}).

\subsection{Proactively Identifying Data Voids}
\label{sec:identifying}

To evaluate the prevalence of data voids on Google Search, we consider defining data voids in three ways.
First, we can consider a data void to be present when a query returns a low-quality banner, as we did in our initial analysis.
Second, we can consider a data void to be present when a query returns a SERP with an average domain quality below 0.5.
Last, we can consider a data void to be present when a query returns a SERP that our $GNN_{het}$ model predicts a low-quality banner for with a high confidence threshold.

\para{There is a disconnect between low-quality SERPs and low-quality banners}
If we define a low-quality SERP as one whose average domain quality score is less than or equal to 0.5 (on a scale of 0--1), then 0.83\% of queries in crawl-1, 0.72\% in crawl-2, and 0.63\% in crawl-3 returned low-quality SERPs.
While this rate is relatively small, it still represents a \(\approx40\times\) increase in SERPs classified as data voids relative to the proportion of SERPs that Google placed a low-quality warning banner on in crawl-1 (0.021\%) and crawl-2 (0.015\%), and continued to identify a similar percentage of SERPs as data voids in crawl-3 when Google displayed zero low-quality banners. 
Using this definition, we found that Google only applied its low-quality banner to 0.45\% of low-quality SERPs in crawl-1 and 0.28\% in crawl-2. 
Put differently, 17.9\% of the SERPs that Google placed a low-quality banner on were low-quality data voids in crawl-1, and 13.1\% in crawl-2.

\para{The number of low-quality banner predictions exceeds observed banner prevalence}
Another approach to defining a data void is to use Google's warning banners as labeled data for building a classifier as we did (Section~\ref{sec:predicting}). 
Using predictions from our $GNN_{het}$ model, which we found to be the most reliable for identifying searches that should have received a banner, we considered its most confident predictions for whether a SERP should receive a low-quality warning banner. 
Here we define a low-quality data void as one which the model predicts a banner for, with a \(\geq 90\%\) confidence score threshold. 
Applied across our dataset, this definition suggests that 1.16\% of SERPs in crawl-1, 0.44\% of SERPs in crawl-2, and 0.72\% of SERPs in crawl-3 should have received a banner.
Similar to our definition of data voids based on an average domain quality threshold, our model's predictions suggest that there were about \(\approx58\times\) more data void SERPs than Google's low-quality banners covered in crawl-1 (about \(\approx29\times\) for crawl-2).
Among those data void SERPs, Google only applied a low-quality banner to 2.0\% in crawl-1 and 2.6\% in crawl-2.
These results suggest that Google's low-quality banners may have been tuned to a very conservative confidence threshold, weighing the consequences of false positives (an unnecessary banner) higher than false negatives (no banner when needed).

