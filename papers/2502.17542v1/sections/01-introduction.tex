
\section{Introduction}

The content moderation practices of large online platforms, and how they're applied to information on important topics like health and elections, are a topic of widespread interest to researchers, the public, and policymakers around the world. 
One practice that has been widely debated is the use of ``warning labels'' to alert and inform users about the accuracy, context, or quality of a specific piece of content.
For example, social media sites have placed warning labels on posts classified as inaccurate by fact-checkers, and recent research suggests that such labels can be effective for reducing the belief and spread of misinformation~\citep{martel2023misinformation}.
However, the policies detailing when a platform will use a warning label are often opaque or absent~\citep{krishnan2021research}, can rapidly change, and research on how such labels are applied in practice has often been limited due to the challenges of surfacing examples to study~\citep{bradshaw2023investigation}.

Research in this vein has often focused on social media, but search engines also play a central role in online information seeking and employ similar content moderation practices~\citep{urman2024user}.
On Google Search, a close equivalent to the warning labels used on social media are the warning banners that Google places at the top of its search results to address \textit{data voids}: when the search results available for a given query are scarce, unstable, or dominated by unreliable or irrelevant websites~\citep{golebiewski2019data}. 
Such data voids are concerning because research suggests that search engines are widely trusted, but can increase belief in misinformation~\citep{aslett2024online}, influence political preferences~\citep{epstein2015search}, and be exploited as an indirect intermediary for guiding people into data voids~(\cite{golebiewski2019data}; \cite{tripodi2022propagandists}).
Google uses three distinct warning banners (Figure~\ref{fig:banner_ex}) to combat low-quality~\citep{nayak2022new}, low-relevance~\citep{tucker2020getting}, and rapidly-changing data voids~\citep{sullivan2021new}.
Similar to warning labels in social media, the use of warning banners in web search appears to generally help users evaluate low-quality or biased search results (\cite{epstein2017suppressing}; \cite{ludolph2016manipulating}), though warnings about sources having unknown reputations may have a small backfire effect on trust in accurate sources~\citep{williams-ceci2024misinformation}.
However, aside from brief blog posts announcing the rollout of Google's warning banners, little is known about when or why they're deployed in practice. 

In this study, we develop methods for discovering and evaluating Google's warning banners, build deep learning models to predict the presence of those banners, and use those models to identify unlabeled data voids in web search.
To do so, we used a diverse set of 1.4M unique search queries that were shared on social media.
We obtained these search queries by collecting a larger dataset of \textit{search directives}, which are defined as attempts to prompt people into conducting an online search---e.g., a social media post that tells viewers to search for ``vaccines cause autism''---and have been shown to lead to data voids of low-quality results~\citep{robertson2023identifying}.
Using best practices developed in algorithm auditing studies~\citep{metaxa2021auditing}, we collected the first Search Engine Results Page (SERP) on Google for each of our queries using automated requests from a fixed location, extracted features from those SERPs (e.g., web domains), and merged those features with metrics validated in past work (e.g., the domain quality scores from \cite{lin2023high}).
To account for changes in Google's search results and warning banner systems over time~\citep{munger2019limited}, we collected the search results for all 1.4M queries in three waves that were conducted about five months apart, in October 2023, March 2024, and September 2024.

\begin{figure}[t!]
\centering
\includegraphics[width=\textwidth, trim={0.05cm 0.05cm 0.05cm 0cm}, clip]{figs/banner-screenshots.pdf}
\caption{Examples of warning banners for low-quality (A) and low-relevance (B) data voids on Google Search. Google displays the low-quality banner (A) at the top of its results when their ``systems don't have high confidence in the overall quality of the results available for the search''~\citep{nayak2022new}, and the low-relevance banner (B) ``when Google hasn't been able to find anything that matches your search particularly well''~\citep{tucker2020getting}. Google also has a rapidly-changing banner, but these are rare due to their time-sensitive nature and not a focus of this study (see Appendix~\ref{sec:appendix-banners-rapidly}, Figure~\ref{fig:freshness_banner}).}
\label{fig:banner_ex}
\end{figure}

Across all three data collection waves, about 1\% of the 1.4M search queries produced a warning banner of any type when searched on Google.
Among Google's three distinct warning banners (Figure~\ref{fig:banner_ex}), low-relevance banners were the most common, accounting for 98--99\% of the banners we observed in any wave.
In contrast, and in line with their time-sensitive nature, rapidly-changing banners were the least common, and only 2-10 queries produced one in any wave.
Low-quality banners accounted for 2.1\% of all banners (0.021\% of all queries) seen in October 2023, 1.5\% of all banners seen in March 2024 (0.015\% of all queries), and never appeared in September 2024. 
Though there was substantial churn in the search results between each crawl, with only 37--38\% of the URLs returned at one time step still appearing for the same query about five months later, we found that average domain quality only improved about 0.3\% between crawls.
These results suggest that Google may have discontinued their use of low-quality warning banners around August 2024, despite the quality of their search results remaining largely unchanged.

When low-quality banners did appear, they were consistently more likely to appear on SERPs with lower domain quality scores and for queries containing conspiracy-related keywords.
Low-quality banners also never appeared for search queries containing an advanced query operator, such as ```deep state' site:infowars.com,'' where the site operator (``site:infowars.com'') limits the results for that search to webpages only from that domain.
This absence may be somewhat surprising, especially given the presence of queries in our dataset that contained an advanced query operator to effectively guarantee a data void by filtering the search results to come from a domain with an extremely low quality score (e.g., ``covid vaccine detox site:naturalnews.com'', which has a quality score of 0).
This apparent loophole may follow from the non-committal language used in the banner itself (``some of [these results] may not have reliable information on this topic''); if a low-quality banner appeared on a SERP that was produced by a query with a single ``site:'' operator, then there would be no ambiguity as to which website triggered it.

Before the low-quality banners stopped appearing, we gathered a complementary dataset of SERPs using the subset of queries that produced such a banner in our October 2023 wave.
We collected this dataset in June 2024 using a more rapid collection schedule, with searches conducted roughly four hours apart, for 73 time steps.
To assess the stability of the low-quality banners, we checked for differences in the set of queries that produced a low-quality banner at each time step, and whether differences in the search results returned at each time step might explain the presence or absence of that banner.
On average, 3.2\% of queries that had a low-quality banner in one time step no longer had one when conducted again four hours later, and we found no successive time steps in which the exact same subset of queries received a low-quality banner.
We also could not find a determinative rule for the presence of low-quality banners using the presence and ranking of certain URLs on a SERP, suggesting substantial inconsistencies or randomness in the system that placed the low-quality warning banners.

To identify data voids beyond Google's classifications, we fine-tuned three deep learning models---DistilBERT, a homogeneous Graph Neural Network (GNN), and a heterogeneous GNN---to predict the presence of a low-quality banner given a search query and details about its corresponding SERP. 
We found that the heterogeneous GNN outperformed the other models on a comprehensive set of evaluations, including standard metrics, annotated precision@K, out-of-sample testing, and correlations between the models' predictions and the corresponding SERP domain quality scores.
Using this model, we classified between 0.44\% and 1.16\% of all SERPs as low-quality data voids, which is 29 to 58 times more SERPs than Google placed a low-quality banner on.
These results are consistent with a simpler data voids definition, using an average domain quality cutoff, which identified between 0.63\% and 0.83\% SERPs in our data as low-quality data voids.

Our findings shed light on an important yet understudied content moderation system---Google's warning banners---and highlight the challenges of conducting such studies when the system of interest is a moving target that can frequently undergo rapid, unannounced, and substantive changes~\citep{bagchi2024social}.
One potential explanation for the sudden absence of the low-quality banners is that Google's August 2024 ``core updates''~\citep{aug2024update} improved the quality of its search results such that the low-quality banners were no longer needed.
However, comparing across our main data collection waves and finer-grain datasets, we found little evidence of substantive changes to the domain quality of the SERPs produced for queries that had previously received a low-quality banner.
Instead, we found that many of those queries continued to return low-quality domains in September 2024, they just no longer received a low-quality warning banner.

Discontinuing these warning banners, without replacement or substantial improvements in domain quality, would be a surprising change to make in the months preceding the 2024 US elections.
While we do not measure the impact of that change in this study, events with breaking news updates provide fertile grounds for data voids~\citep{golebiewski2019data}, the use of search directives is not new to political campaigns (e.g., ``Google Ron Paul'';~\cite{baker2008google}), and emerging technologies have made it easier than ever to create misleading content~\citep{feuerriegel2023research}, all of which suggest that keeping the low-quality banners would have been helpful to users.
As such, our findings highlight the need for greater transparency around Google's warning banners, their prevalence, and the effects that their presence or absence has on real users.
Given that we focus on Google Search and use a predominantly English sample of search queries, our results may underestimate the prevalence of data voids, and future work is needed to evaluate them using a broader set of languages, and on a broader set of search engines, including newer LLM-powered ones.
Last, our study also highlights the need for long-term longitudinal studies of online platforms more widely, as changes like the one we observed may otherwise go unnoticed.

