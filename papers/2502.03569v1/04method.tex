

The input to \name are a multivariate sequence $\mathbf{x}_{:,t_0:t_i}$ with $V$ measured variables, and a condition $s$ and time $t_j > t_i$ for which to forecast $\hat{\mathbf{x}}^s_{:,t_j}$. \name consists of four major components: a sequence encoder $F$, a condition adapter $H$, a concept encoder $E$, and a concept decoder $G$.

\xhdr{Sequence encoder $F$}\label{sec:seq_enc}
%
The sequence encoder~$F$ extracts features from $\mathbf{x}_{:, t_0:t_i}$ such that $\mathbf{h}_\mathbf{x} = F(\mathbf{x}_{:,t_0:t_i})$. Any encoder, including a pretrained multivariate foundation model, can be used. The time encoder in $F$ generates a time positional embedding $\mathbf{h}_t$ for any time $t$ via element-wise summation of the year (sinusoidal), month, date, and hour embeddings. It is additionally used to compute the time delta embedding~$\Delta_{t_i,t_j} = \mathbf{h}_{t_j} - \mathbf{h}_{t_i}$ for the concept encoder~$E$. 


\xhdr{Condition adapter $H$}\label{sec:cond_adp}
%
The embedding~$\mathbf{z}_s$ corresponding to the input condition~$s$ is retrieved from a frozen pretrained embedding model (denoted as~\textsc{pt} in Figure~\ref{fig:clef}a). The condition adapter $H$ projects $\mathbf{z}_s$ into hidden representation~$\mathbf{h}_{s} = H(\mathbf{z}_s)$.

\xhdr{Concept encoder $E$}\label{sec:concept_enc}
%
Given the hidden representations generated by sequence encoder~$F$ and condition adapter~$H$, concept encoder~$E$ learns temporal concept $\mathbf{c} = E(\mathbf{h}_\mathbf{x}, \Delta_{t_i,t_j}, \mathbf{h}_s)$. First, the time delta embedding $\Delta_{t_i,t_j}$ is combined via summation with the condition embedding $\mathbf{h}_s$ to generate a time- and condition-specific embedding $\mathbf{h}_s^{t_j} = \Delta_{t_i,t_j} \oplus \mathbf{h}_s$. Temporal concept $\mathbf{c}$ is learned via an element-wise multiplication of $\mathbf{h}_\mathbf{x}$ and $\mathbf{h}_s^{t_j}$, an optional linear projection using a feedforward neural network~(FNN), and a GELU activation to approximate the trajectory between $t_i$ and $t_j$
\begin{equation}
    \mathbf{c} = \text{GELU}(\text{FFN}(\mathbf{h}_{\mathbf{x}} \odot \mathbf{h}_s^{t_j}))
\end{equation}





\xhdr{Concept decoder $G$}
%
The concept decoder $G$ forecasts $\hat{\mathbf{x}}^s_{:,t_j}$ by performing element-wise multiplication of the latest time~$t_i$ of the input sequence $\mathbf{x}_{:,t_0:t_i}$ (denoted as $\mathbf{x}_{:,t_i}$) and the learned concept~$\mathbf{c}$
\begin{equation}
    \hat{\mathbf{x}}^s_{:,t_j} = \mathbf{c} \odot \mathbf{x}_{:,t_i} 
\end{equation}


\xhdr{Objective function $\mathcal{L}$}
%
The sequence editing objective function $\mathcal{L}$ quantifies the reconstruction error of the predicted $\hat{\mathbf{x}}^s_{:,t_j}$ and the ground truth $\mathbf{x}^s_{:,t_j}$. Here, we use Huber loss
\begin{equation}
    \mathcal{L}(\mathbf{x}^s_{:,t_j}, \hat{\mathbf{x}}^s_{:,t_j}) = \begin{cases}
        0.5 \mathbf{a}^2, & \text{if $\vert \mathbf{a} \vert \leq \delta$} \\
        \delta(\vert \mathbf{a} \vert - 0.5\delta), & \text{otherwise}
    \end{cases}
\end{equation}
where $\mathbf{a} = \mathbf{x}^s_{:,t_j} - \hat{\mathbf{x}}^s_{:,t_j}$.
