

\begin{figure*}[ht]
\begin{center}
\centerline{\includegraphics[width=\textwidth]{FIG/figure3_benchmark.pdf}}
\caption{Benchmarking the performance of \name, baselines, and ablation models on \textbf{(a)} immediate and \textbf{(b)} delayed sequence editing. The models are trained using a standard cell- or patient-centric random split. Not shown for visualization purposes are the performances of VAR models on eICU and MIMIC-IV datasets: on immediate sequence editing, MAE for eICU and MIMIC-IV are $55982.74$ and $886.05$, respectively; on delayed sequence editing, MAE for eICU and MIMIC-IV are $3.02 \times 10^{39}$ and $8.62 \times 10^{23}$, respectively.}
\label{fig:benchmark}
\end{center}
\vskip -0.35in
\end{figure*}




We evaluate \name's performance on controllable sequence editing across multiple datasets and tasks. We aim to answer the following research questions. 
\textbf{R1:} How well does \name perform in immediate sequence editing?
\textbf{R2:} How well does \name perform in delayed sequence editing?
\textbf{R3:} How does \name generalize to unseen/new sequences?
\textbf{R4:} Can \name perform zero-shot counterfactual generation?
\textbf{R5:} How can \name be leveraged for real-world counterfactual patient trajectory simulations?
We establish that \name outperforms state-of-the-art baselines in sequence editing, demonstrating both immediate and delayed sequence editing capabilities, strong generalizability, and real-world applicability.


\subsection{\underline{R1}: Immediate sequence editing}\label{results:r1}

Immediate sequence editing involves forecasting the next time step of a sequence under a counterfactual condition. This is useful in settings where interventions take effect instantaneously, such as introducing a genetic perturbation in cellular systems or administering a drug to a patient~(Definition~\ref{def:cse}). Example counterfactual scenarios in which immediate sequence editing is applicable are: \textit{What if we treat the cells with the candidate drug now?} and \textit{What if we perform surgery on the patient today?}




\name models consistently outperform baseline models across all datasets~(Figure~\ref{fig:benchmark}a; Appendix Figures~\ref{fig:supp_benchmark_full_mae}-\ref{fig:supp_benchmark_full_rmse}). The SimpleLinear baseline, which assumes minimal temporal changes, performs comparably in some cases, but \name outperforms it on datasets where short-term dynamics are more complex. On WOT, all \name models outperform or perform comparably to the time series forecasting model, VAR. This is particularly exciting given recent findings that linear models can achieve competitive or better forecasting performance than neural network models~\cite{toner2024analysis, ahlmann2024deep}. These results highlight \name's ability to accurately modify trajectories at the right points while preserving unaffected portions of the sequence, an advantage in counterfactual reasoning.

Regardless of the sequence encoder used with \name, these models tend to outperform or perform comparably to non-\name models~(Figure~\ref{fig:benchmark}a). However, the performance of \name can be affected by the ability of the sequence encoder to capture the temporal dynamics of the input sequences. For instance, models with the MOMENT encoder yield the highest MAE in all three datasets, with and without help from \name~(Figure~\ref{fig:benchmark}a). Nevertheless, \name models with the MOMENT encoder reduce the MAE of non-\name models.


\subsection{\underline{R2}: Delayed sequence editing}\label{results:r2}


Delayed sequence editing requires forecasting a counterfactual trajectory at a future time step while maintaining causal consistency. This task is challenging, as small errors can compound over longer horizons. Example scenarios in which delayed sequence editing is applicable are: \textit{What if we treat the cells with the candidate drug in ten days?} and \textit{What if we perform the surgery on the patient next year?}

\name outperforms or performs competitively against SimpleLinear and VAR on the patient datasets, eICU and MIMIC-IV~(Figure~\ref{fig:benchmark}b; Appendix Figures~\ref{fig:supp_benchmark_full_mae}-\ref{fig:supp_benchmark_full_rmse}). \name-transformer and \name-xLSTM achieve lower MAE than SimpleLinear, whereas non-\name transformer and MOMENT baselines perform comparably or worse. As in immediate sequence editing, models using MOMENT as the sequence encoder (i.e.,~using temporal concepts with the MOMENT sequence encoder) yield the highest MAE. However, incorporating \name with MOMENT reduces the MAE to levels comparable to SimpleLinear and VAR.


On WOT, SimpleLinear and VAR outperform neural network models in delayed sequence editing~(Figure~\ref{fig:benchmark}b). This suggests that cellular developmental trajectories exhibit small and possibly noisy changes at each time step, favoring linear models~\cite{ahlmann2024deep, toner2024analysis}. Additionally, given the relatively small number of training trajectories compared to the high-dimensional state space, nonlinear models may overfit to noise more readily than linear models. Nevertheless, \name significantly reduces the MAE of non-\name models, demonstrating its effectiveness as a regularizer that mitigates short-term noise while preserving long-term trends.


\subsection{\underline{R3}: Generalization to new patient trajectories}


We assess the ability of \name models to generalize to new patient sequences. To evaluate robustness, we use the SPECTRA approach~\cite{ektefaie2024evaluating} to create challenging data splits where the test sets have minimal similarity to the training data (Appendix~\ref{appendix:labs}).

Across both the eICU and MIMIC-IV patient datasets, \name models exhibit stronger generalization than non-\name models (Figure~\ref{fig:spectra}; Appendix Figures~\ref{fig:supp_spectra_full}-\ref{fig:supp_spectra_full_rmse} and Table~\ref{tab:auspc}). For immediate and delayed sequence editing on eICU, \name-transformer and \name-xLSTM maintain stable and strong performance even as train/test divergence increases. In contrast, their non-\name counterparts degrade significantly. Although baseline MOMENT models show relatively stable performance across train/test splits in delayed sequence editing, they generalize poorly compared to \name-MOMENT models. Despite similar performance between xLSTM and \name-xLSTM in delayed sequence editing on both patient datasets (Figure~\ref{fig:benchmark}b), \name-xLSTM demonstrates superior generalizability (Figure~\ref{fig:spectra}b), highlighting the effectiveness of \name in adapting to unseen data distributions.




\begin{figure*}[ht]
\begin{center}
\centerline{\includegraphics[width=\textwidth]{FIG/figure4_spectra.pdf}}
\caption{Generalizability of \name on \textbf{(a)}~eICU and \textbf{(b)}~MIMIC-IV patient datasets in immediate and delayed sequence editing. As the SPECTRA parameter increases, the train/test split similarity decreases~(Appendix Figure~\ref{fig:supp_spectra_cso}). The area under the spectral performance curve (AUSPC) evaluation is in Appendix Table~\ref{tab:auspc}.}
\label{fig:spectra}
\end{center}
\vskip -0.35in
\end{figure*}



\subsection{\underline{R4}: Zero-shot counterfactual generation of cellular trajectories}

In addition to evaluating \name's generalizability to new patient lab test trajectories, we assess on zero-shot counterfactual generation for cellular trajectories~(Figure~\ref{fig:wot_cf}; Appendix Figure~\ref{fig:supp_wot_cf_full}). Using the Waddington-OT model, we generate sequences that remain consistent until a specified divergence time step, where an alternative condition—such as the activation of a different transcription factor—introduces a shift~(Appendix~\ref{appendix:cells}). This process yields \(1,273\) pairs of ``original" and ``counterfactual" trajectories, totaling \(2,546\) individual sequences~(Table~\ref{tab:data}). Models are trained on the ``original" trajectories and evaluated on the ``counterfactual" trajectories in a zero-shot setting.

\name-based models consistently outperform non-\name models in both immediate and delayed sequence editing~(Appendix Figure~\ref{fig:supp_wot_cf_full}). To more closely analyze delayed sequence editing performance, we examine the predictions for cellular trajectories of length 23, the most common sequence length in the dataset~(Figure~\ref{fig:wot_cf}). Since \(t_i = 10\) is the earliest divergence time step, we provide the first nine time steps \(\mathbf{x}_{:,0:9}\), the counterfactual condition, and \(t_j \in [10, 23]\) to the model. Comparing the generated and ground truth counterfactual sequences, we find that \name significantly outperforms non-\name models after time step 10, which is when the trajectories begin to diverge (Figure~\ref{fig:wot_cf}). 







\begin{figure}[ht]
\begin{center}
\centerline{\includegraphics[width=\columnwidth]{FIG/figure5_wot_cf.pdf}}
\caption{Zero-shot counterfactual generation of cellular developmental trajectories. Shown are the MAE of predictions at each time step for counterfactual sequences of length 23 (the most common sequence length in the dataset) starting at time step 10 (the earliest divergence time step of a counterfactual trajectory).}
\label{fig:wot_cf}
\end{center}
\vskip -0.35in
\end{figure}


\subsection{\underline{R5}: Case studies using real-world patient datasets}

We evaluate \name's ability to simulate counterfactual patient trajectories through temporal concept intervention. We conduct case studies on two independent cohorts of patients with type 1 diabetes mellitus (T1D), a chronic autoimmune disease in which the immune system attacks insulin-producing cells in the pancreas~\cite{quattrin2023type}.

Unlike counterfactual generation methods that rely on condition tokens to guide generation~\cite{narasimhan2024time, jing2024towards, zhang2023survey}, \name allows \textit{direct edits to the generated outputs} to produce counterfactual sequences. This capability is particularly valuable when condition tokens are insufficient, such as when prescribing medication dosage. Instead of relying on predefined conditions, \name can precisely modify the values of specific lab tests to explore their longitudinal effects.

\xhdr{Setup}
%
For an individual patient, we intervene on the temporal concepts corresponding to specific lab tests to simulate the ``reversal" or ``worsening" of symptoms, thereby generating ``healthier" or ``more severe" trajectories, respectively. Formally, given temporal concept \(\mathbf{c}\) learned from \(\mathbf{x}_{:,t_0:t_i}\) and an optional condition \(s\), we modify \(\mathbf{c}^I \neq \mathbf{c}\) such that at least one element satisfies \(\mathbf{c}_k \neq \mathbf{c}^I_k\).  

From the eICU and MIMIC-IV datasets, we construct two independent cohorts of T1D patients and matched healthy individuals~(Appendix~\ref{appendix:labs}). The eICU-T1D dataset contains \(59\) T1D patients and \(579\) matched healthy controls, while MIMIC-IV-T1D includes \(25\) T1D patients and \(226\) matched healthy controls.  

To generate counterfactual sequences, we modify specific values in temporal concept \(\mathbf{c}\), such as glucose levels, and allow \name to simulate future trajectories of length \(T = 10\). We then compare these counterfactual trajectories (i.e.,~\name-generated patients) against observed sequences from matched healthy individuals, other healthy individuals, and other T1D patients. Our hypothesis is that clinically meaningful edits will produce ``healthier" (i.e.,~more similar to healthy patients) or ``sicker" (i.e.,~more similar to other T1D patients) trajectories.  




\xhdr{Results}
%
First, we modify \name's concepts to reduce glucose levels by half, aligning them closer to normal physiological ranges. The resulting counterfactual patient trajectories exhibit higher \(R^2\) similarity with both matched and other healthy individuals compared to other T1D patients (Figure~\ref{fig:t1d}a). This suggests that \name effectively generates counterfactual trajectories indicative of a healthier state.  

Next, we simulate a worsening condition by doubling glucose levels. The resulting counterfactual trajectories generated by \name show higher \(R^2\) similarity with other T1D patients than with healthy individuals~(Figure~\ref{fig:t1d}a), as would be expected based on clinical evidence.  

Beyond direct interventions, we examine indirect changes in \name-generated patients' lab values resulting from glucose modifications. In both eICU-T1D and MIMIC-IV-T1D cohorts, lowering glucose also leads to a reduction in white blood cell (WBC) count~(Figure~\ref{fig:t1d}b; Appendix Figure~\ref{fig:supp_t1d}a). This aligns with clinical knowledge, as T1D is an autoimmune disorder where immune activity, including WBC levels, plays a critical role~\cite{quattrin2023type}. Further, when we intervene on \name to reduce WBC levels instead of glucose, we observe a concurrent drop in glucose across both cohorts~(Appendix Figure~\ref{fig:supp_t1d}b,c), reinforcing the interconnected nature of these physiological markers.  




\begin{figure}[ht]
\begin{center}
\centerline{\includegraphics[width=\columnwidth]{FIG/figure6_pt_int.pdf}}
\caption{\name-generated counterfactual patients via intervention on temporal concepts. We intervene on \name to \textbf{(a)}~halve~(top) or double~(bottom) a T1D patient's glucose levels to infer a ``healthier" or ``sicker" counterfactual patient, respectively. \textbf{(b)}~Observed and \name patients from the eICU-T1D cohort are compared to quantify the differences between their lab test trajectories (indirect effects) as a result of the intervention to halve T1D patients' glucose levels.}
\label{fig:t1d}
\end{center}
\vskip -0.35in
\end{figure}

Finally, we demonstrate that modifying multiple lab tests simultaneously can produce compounding effects. When we intervene on \name to reduce both glucose and WBC levels, the resulting \name-generated patients resemble healthy individuals even more closely than other T1D patients~(Appendix Figure~\ref{fig:supp_t1d}d). This finding suggests that \name can integrate multiple simultaneous edits, capturing their joint impact on a patient's future state.


