\section{Introduction} \label{intro}
With the approximate human knowledge, large language models have revolutionized the way of simulations of social and psychological phenomena \citep{Park2023GenerativeAgents, gao2023s}. By processing and generating human-like language, LLMs offer unprecedented opportunities to model complex interactions and behaviors that were previously challenging to simulate. This capability opens doors to exploring societal trends, market dynamics, and individual psychological states through a new lens.

However, there is a notable lack of comprehensive studies examining whether LLM simulations can accurately reflect real-world human behaviors. Some studies have explored this dimension from various angles. First, recent studies \citep{wang2023not, wang2024new, wang2025limits} show that the inner knowledge of LLMs exhibit strong cultural bias, decision preference \citep{huang2024far}, and prior psychological character \citep{pan2023llms}. Second, the current training datasets of LLMs lack personal inner psychological states, thoughts, and life experiences. LLMs may reflect the common cognition of all humans instead of individual persons. Third, unlike humans who make decisions and act based on motivations from living, emotions, and achievements \citep{felin2024theory}, LLMs lack intrinsic motivations, emotions, and consciousness. They operate based on resultant patterns in training data, not from lived experiences. These fundamental differences motivate rethinking how we use LLMs for simulation purposes and to critically assess their ability to replicate the depth and complexity of human society.

In this paper, we delve into the limitations of LLM-driven social simulations. We discuss and summarize the challenges these models face in capturing human psychological depth, intrinsic motivation, and ethical considerations. These challenges provide insights for future LLM evaluation and development. Nevertheless, we compare traditional simulation and LLM-based simulation, and find that the LLM-based approach remains a promising direction due to its cost-effectiveness – exemplified by LLMs like DeepSeek that can reduce simulation expenses compared to human participant studies \citep{bi2024deepseek, guo2025deepseek} – scalability, and ability to simulate emergent behaviors. Furthermore, we propose future research directions to better align LLM simulations with human realities.