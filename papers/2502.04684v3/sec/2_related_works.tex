\section{Related Works}
\label{sec:related_works}

\begin{figure*}[t]
    \centering
    % \vspace{+0.5em}
    \includegraphics[width=1\linewidth]{img/overview-fig.pdf}
    \vspace{-1.6em}
    \caption{\textbf{G2PDiffusion for genotype-to-phenotype image synthesis.} It first utilizes the MMseq to retrieve evolutionary alignments (in Section~\ref{sec:Constructing}). Then the retrieved MSA are fed into an environment-enhanced MSA conditioner that integrates them with environmental factors, i.e., longitude and latitude (in Section~\ref{sec:G2P}). Additionally, a cross-modality alignment guidance mechanism is employed to ensure genotype-phenotype consistency during sampling (in Section~\ref{sec:Alignment}).}
    % We also retrieve phenotypes based on genotype similarity to enhance the generative performance in long tail class, as well as improving the intra modality (phenotype-phenotype) consistency. 
    \vspace{-1em}
    \label{fig:2_diffusion}
\end{figure*}

\paragraph{Genotype-to-Phenotype Prediction.}
Predicting phenotypes from genotypes is a fundamental challenge in biology, requiring the integration of genetic makeup and environmental influences \cite{via1985genotype,bochner2003new,dowell2010genotype}. The genotype encodes hereditary information in DNA, while the phenotype manifests as observable traits, including physical characteristics, behaviors, physiological functions, and clinical outcomes \cite{klose1999genotypes}. Here, we focus on physical characteristics as phenotypes.
Conventional genomic analysis methodologies, exemplified by genome-wide association studies (GWAS) \cite{uffelmann2021genome,tam2019benefits} and quantitative trait loci (QTL) mapping \cite{khatkar2004quantitative,kendziorski2006review}, primarily aim to identify statistical associations between genetic markers and phenotypic characteristics. The emergence of deep learning architectures—particularly convolutional neural networks (CNNs) and recurrent neural networks (RNNs)—has shifted paradigm toward decoding intricate genotype-phenotype interactions through automated pattern discovery in high-dimensional genomic datasets \cite{wang2024prediction,magnusson2022deep,danilevicz2022plant,wang2024lstm,annan2023machine}. While these computational approaches demonstrate proficiency in value regression (e.g., crop height prediction) or categorical classification (e.g., barley grain yield estimation) through supervised learning frameworks, they face notable limitations in cross-species and cross-trait generalizability due to inherent biological complexity and model dependency on domain-specific training data.  To overcome these limitations, we propose a novel paradigm that utilizes image-derived phenomic representations as biologically interpretable proxies, establishing a domain-agnostic framework for cross-species predictive modeling from morphological patterns.





% 加了额外输入的生成模型
\paragraph{DM-based Conditional Image Synthesis.}

Diffusion models (DMs) have shown remarkable success in generating high-quality images conditioned on additional input. Text-to-image models, such as GLIDE \cite{nichol2021glide}, Stable Diffusion \cite{rombach2022high}, and DALL-E 3 \cite{betker2023improving}, utilize semantic text encoders \cite{radford2021learning} to translate descriptive language into detailed and coherent visual outputs. Similarly, image-to-image models, including inpainting \cite{wang2023imagen,saharia2022palette,tumanyan2023plug}, super-resolution \cite{li2022srdiff,li2022srdiff}, and style transfer \cite{zhang2023inversion}, refine or transform images by leveraging diffusion-based priors.
Beyond conventional applications, DMs have been extended to specialized domains, such as medical imaging \cite{li2023zero}, where they assist in data augmentation and anomaly detection, as well as graph-to-image synthesis \cite{yang2022diffusion} and satellite imagery generation \cite{graikos2024learned}.
These advancements show the versatility of diffusion-based approaches in capturing complex structures and domain-specific patterns.






