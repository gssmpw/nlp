% \section{Method}
% \label{sec:methods}



% We propose G2PDiffusion, a novel evolution-aware diffusion framework for genotype-to-phenotype image synthesis. We first describe the overall architecture of the proposed method in section~\ref{sec:Framework Overview}. Then we will introduce the strategy of constructing evolutionary alignments in section~\ref{sec:Constructing}. The environment-enhanced MSA encoder and evolution-aware genotype-to-phenotype diffusion model are introduced in section~\ref{sec:G2P}. We present the sampling strategy, a novel alignment approach designed to enhance genotype-to-phenotype consistency in section~\ref{sec:Alignment}. Finally, we introduce the model training and inference in section~\ref{sec:T&I}.

% The whole framework consists mainly of three parts: (i) an environment-enhanced DNA sequence conditioner to incorporate genetic and environmental factors simultaneously; (ii) an evolution-aware mechanism that leverages phylogenetic relationships and evolutionary constraints to improve cross-species generalization; and (iii) a novel alignment method to improve genotype-to-phenotype consistency.

% \subsection{Framework Overview}
% \label{sec:Framework Overview}
% Figure~\ref{fig:2_diffusion} shows the overall architecture of G2PDiffusion. We establish the whole pipeline based on Stable Diffusion, a generative model that synthesizes high-quality images by iteratively refining noise through a latent diffusion process.
% Building upon its powerful capabilities, we develop an evolution-aware genotype-to-phenotype image synthesis framework that integrates genetic and evolutionary information into the generation process.
% During denoising steps, G2PDiffusion first retrieves evolutionary alignments from the database $\mathcal{D}$ based on the input DNA sequence.
% The retrieved evolutionary alignments are tokenized alongside the original sequence and integrated with environmental tokens before being processed by the encoder. This fusion extracts evolutionary features within the multiple sequence alignment (MSA) under environmental influences, providing a biologically informed conditioning signal for the diffusion model. Through the denoising process, G2PDiffusion effectively distills and incorporates relevant evolutionary knowledge.
% Furthermore, we introduce an adaptive alignment strategy to dynamically refine the latent space during inference, improving the fidelity of genotype-to-phenotype mapping. The following subsections elaborate on each component in detail.

% G2PDiffusion is designed to leverage evolutionary information for improved phenotype image synthesis from genotype sequences.
% The framework consists of three key components: (1) evolutionary alignment construction, which retrieves homologous sequences to enrich the input genotype representation; (2) an environment-enhanced MSA encoder that captures evolutionary and contextual signals; and (3) a diffusion-based synthesis model that generates phenotype images conditioned on the processed genotype features. By integrating these components, G2PDiffusion effectively encodes evolutionary relationships and environmental dependencies to improve synthesis quality and generalization.

% \vspace{-1em}
% \subsection{Multiple Sequence Alignments Retrieval Engine}
\subsection{M\hspace{-0.15pt}u\hspace{-0.15pt}l\hspace{-0.15pt}t\hspace{-0.15pt}i\hspace{-0.15pt}p\hspace{-0.15pt}l\hspace{-0.15pt}e \hspace{-0.15pt}S\hspace{-0.15pt}e\hspace{-0.15pt}q\hspace{-0.15pt}u\hspace{-0.15pt}e\hspace{-0.15pt}n\hspace{-0.15pt}c\hspace{-0.15pt}e \hspace{-0.15pt}A\hspace{-0.15pt}l\hspace{-0.15pt}i\hspace{-0.15pt}g\hspace{-0.15pt}n\hspace{-0.15pt}m\hspace{-0.15pt}e\hspace{-0.15pt}n\hspace{-0.15pt}t\hspace{-0.15pt}s \hspace{-0.15pt}R\hspace{-0.15pt}e\hspace{-0.15pt}t\hspace{-0.15pt}r\hspace{-0.15pt}i\hspace{-0.15pt}e\hspace{-0.15pt}v\hspace{-0.15pt}a\hspace{-0.15pt}l \hspace{-0.15pt}E\hspace{-0.15pt}n\hspace{-0.15pt}g\hspace{-0.15pt}i\hspace{-0.15pt}n\hspace{-0.15pt}e}

\label{sec:Constructing}
Considering that Multiple Sequence Alignments (MSA) aggregate homologous DNA sequences across species, it serves as a crucial tool for capturing evolutionary constraints and conserved functional regions in the DNA sequence \citep{zhang2024historical, zou2015halign}. We utilize MMseqs2 \citep{steinegger2017mmseqs2}, a fast and scalable sequence search tool, to construct evolutionary alignments by retrieving homologous sequences from a reference database.
Given a query DNA sequence $G_q$ and an external sequence database $\{G_i\}_{i=1}^{N_{\mathcal{D}}}$, we utilize MMseqs2’s sensitive search module to efficiently scan the database and retrieve a set of homologous sequences with top-$m$ high evolutionary similarity.
% \begin{verbatim}
% mmseqs search data data result tmp 
% --search-type 3 --max-seqs m
% \end{verbatim}
We write the retrieved homologous sequence pool:
\begin{equation}
\mathcal{D}(G_q,m) := \text{top}_m (\{G_i\}_{i=1}^{N_{\mathcal{D}}}, \text{MMseqs}(\cdot, G_q)).
\end{equation}




% An illustrative example in Figure~\ref{fig:2_diffusion}(Stage I. below) showcases that the Evolutionary Alignments 


The resulting MSA captures conserved sequence motifs, co-evolutionary relationships, and functionally significant variations, providing a biologically meaningful prior for guiding the phenotype synthesis process.

% We can identify conserved genetic elements and infer evolutionary trajectories, facilitating genotype-to-phenotype modeling. 

% Evolutionary alignments provide essential insights into conserved regions, functional motifs, and phylogenetic relationships, which can enhance downstream genetic analyses and phenotype predictions.


\subsection{Environment-aware MSA Conditioner}
\label{sec:G2P}
To accurately capture the genotype-to-phenotype mapping across diverse species, it is necessary to design a conditioner that captures the complex interplay between MSA-derived genetic information and environmental contexts.
The MSA-derived genetic information reveals how conserved regions maintain core functions and variable sites contribute to phenotypic diversity, while environmental factors drive phenotypic adaptation through selective pressures over evolutionary timescales. Methodological details are as follows:


% The following details the methodological design of these aspects.

% This genetic context provides critical insights into how mutations and sequence variations contribute to phenotype formation.
% Second, environmental factors impose selective pressures that drive phenotypic adaptation over evolutionary timescales.
% The following details the methodological design of these aspects.


% Two key evolutionary factors are considered 

% gene and environmental
% In this subsection, we introduce the Evolution-aware conditioning module, which incorporates evolutionary information from two aspects.
% First, MSA captures evolutionary constraints by aligning homologous sequences, preserving conserved functional elements that influence phenotypic traits. 


% By encoding environmental information, we account for the interaction between genetic composition and external conditions, refining the genotype-to-phenotype mapping.
% The following details the methodological design of these aspects.
% Phenotypic variations, the observable differences among individuals within a species, are not solely determined by genes; but are also molded by the external environment and the intricate interactions between genotype and environment.
% As a result, it is necessary to incorporate environmental factors into the genotype-phenotype mapping to achieve more precise and reliable predictions.

\paragraph{$k$-mer Tokenization \& Input Format.}
DNA sequences, consisting of long chains of nucleotides (adenine, cytosine, guanine, and thymine), are inherently complex and require a systematic approach to capture meaningful patterns.
Instead of regarding each base as a single token, we tokenize a DNA sequence with the $k$-mer representation \cite{chor2009genomic}, an approach that has been widely used in analyzing DNA sequences.
This method treats a subsequence of $k$ consecutive nucleotides as a ``word" to be tokenized, enabling the model to capture local sequence patterns and motifs that may influence phenotypic traits. For example, given the original DNA sequence $G=[A,C,C,T,C,...]$, the $3$-mer representation is $\texttt{Tokenizer}(G,3)=[ACC, CCT,CTC,...]$. 
We write the $k$-mer token as $\mathcal{T}=\texttt{Tokenizer}(G,k)=[t_1, t_2, ..., t_l]$, where $l$ is the length of the tokenized sequence. When retrieving $m$ MSA sequences $\{G_i\}_{i=1}^m$, we compare nucleotides column-wise to obtain the evolution vector $V = [v_1, v_2, \dots, v_l]$, where $v_i \in \{0,1\}$ indicates whether position $i$ is conserved: if all nucleotides in the column are identical, $v_i = 1$; otherwise, $v_i = 0$. The evolution vector, tokenized MSA, and environments $\{E_i\}_{i=1}^m$ together form the complete input as:
\begin{equation*}
\langle
    \begin{array}
    {c@{\, ,\,}c@{\, ,\,}c}
    % {c@{\,\big\|\,}c@{\,\big\|\,}c}
        \begin{bmatrix}
            v_1 & v_2 & \cdots & v_l
        \end{bmatrix} 
        &
        \begin{bmatrix}
            \mathcal{T}_{1,1} & \mathcal{T}_{1,2} & \cdots  &
            \mathcal{T}_{1,l}
            \\
            \mathcal{T}_{2,1} & \mathcal{T}_{2,2} & \cdots  &
            \mathcal{T}_{2,l}
            \\
            \cdots & \cdots & \cdots & \cdots 
            \\
            
            \mathcal{T}_{m,1} & \mathcal{T}_{m,2} & \cdots  &
            \mathcal{T}_{m,l}
            
        \end{bmatrix} 
        &
        \begin{bmatrix}
            E_{1} \\
            E_{2} \\
            \cdots  \\
            E_{m} 
        \end{bmatrix}
        
    \end{array}
\rangle
\end{equation*}
where $v_i \in \{0,1\}$ indicates whether position $i$ is conservation, $\mathcal{T}_{i,j}$ represents the $j$-th token in the $i$-th MSA token sequence, and $E_i$ is the $i$-th environment. 







% We can use Bert model to get  DNA embedding as $\vh_{d} = [\vh_{d,1}, \vh_{d,2}, \cdots, \vh_{d,L}]$, where $L$ is the number of tokens.

% \paragraph{$k$-mer MSA Tokenizing and Encoding.}

% Multiple Sequence Alignment (MSA) arranges homologous DNA sequences into a coherent framework, capturing conserved motifs and evolutionary constraints.
% To effectively encode these alignments, we adopt a $k$-mer representation \cite{chor2009genomic}, a widely used approach in genomic sequence analysis.
% Instead of treating individual nucleotides as discrete tokens, we segment each sequence within the MSA into overlapping substrings of $k$ consecutive nucleotides. This method enhances the model’s ability to capture local sequence dependencies and co-evolutionary signals relevant to phenotypic variation. Each aligned sequence in the MSA is then tokenized and processed through a transformer-based encoder, yielding an embedding representation $\vh_{\text{MSA}} = [\vh_{\text{MSA},1}, \vh_{\text{MSA},2}, \cdots, \vh_{\text{MSA},L}]$, where $L$ denotes the tokenized sequence length.


\paragraph{Evolution-aware Row Attention.} 
We employ an MLP to transform the evolution vector into a gating weight \(\boldsymbol{w}_v \in \mathbb{R}^{1 \times l}\), which modulates the row attention mechanism:  
\begin{equation}
    H^{\text{row}}_{i,:} = \text{Softmax} \left( \frac{Q(\mathcal{T}_{i,:}) K(\mathcal{T}_{i,:})^\top \odot \boldsymbol{w}_v}{\sqrt{d}} \right) V(\mathcal{T}_{i,:}),
\end{equation}
where \( Q(\cdot), K(\cdot), V(\cdot) \) are MLPs for computing query, key, and value, respectively; $\odot$ denotes element-wise multiplication, \( d \) is the feature dimension, and \(\mathcal{T}_{i,:}\) is the \(i\)-th row of the MSA matrix.
Row attention applies position-wise evolutionary gating to the intra-sequence attention weights, allowing adaptive modulation of attention scores for conserved and evolutionary regions.
% Row attention injects evolutionary information into single-sequence representation learning.


% We take a MLP to convert evolution vector as $\boldsymbol{w}_v \in \mathbb{R}^{1,l}$, which serves a gating weight when applying row attention:
% \begin{equation}
%     H^{\text{row}}_i = \text{Softmax} \left( \frac{Q(\mathcal{T}_{i,:}) K(\mathcal{T}_{i,:}^\top) \odot \boldsymbol{w}_v}{\sqrt{d}  } \right) V(\mathcal{T}_{i,:})
% \end{equation}
% where $Q(\cdot), K(\cdot), V(\cdot)$ are the query, key and value MLP for attention computation, $d$ is the feature dimension, and $\mathcal{T}_{i,:}$ is the $i$-th column in the MSA matrix.

% \begin{equation}
%     H^{\text{col}} = \text{Softmax} \left( \frac{Q_c K_c^\top}{\sqrt{d}} \right) V_c
% \end{equation}



\paragraph{Environment-aware Column Attention.} Considering the inherent spherical nature of Earth's geographic coordinates, we map latitude $(\beta)$ and longitude $(\lambda)$ to spherical coordinates $(x,y,z)=(\cos\beta \cos\lambda, \cos\beta  \sin\lambda, \sin\beta )$, which are fed to an MLP to obtain the environment weighting vector $\boldsymbol{w}_e \in \mathbb{R}^{m \times 1} $. We take $\boldsymbol{w}_e$ to modulate the column attention:
\begin{equation}
    H^{\text{col}}_{:,j} = \text{Softmax} \left( \frac{Q(\mathcal{T}_{:,j}) K(\mathcal{T}_{:,j})^\top \odot \boldsymbol{w}_e}{\sqrt{d}} \right) V(\mathcal{T}_{:,j}),
\end{equation}
where \(\mathcal{T}_{:,j}\) represents the \(j\)-th row of the MSA matrix. The column attention mechanism injects environment information into cross-sequence representation learning. 



% \begin{align}
% x &= ,\nonumber\\
% y &= ,\nonumber\\
% z &= ,\nonumber\\
% \vh_e &= \texttt{MLP}([x,y,z]).
% % \nonumber
% \end{align}

% \paragraph{Spherical Geodesic Encoding.}

% This transformation allows us to encode geographic locations in a way that captures their true spherical geometry, which is particularly useful when considering the influence of environment and geographic position on biological phenomena.


\paragraph{Environment-enhanced MSA Encoder.}
To incorporate both genetic and environmental information, we employ a transformer-based encoder using row and column attentions that integrate information from multiple sequence alignments (MSAs) and environmental features. In addition, we use the MSA LayerNorm to stabilize model training: 
\begin{equation}
    H^{\text{MSA}} = \text{LayerNorm} \left( H^{\text{row}} + H^{\text{col}} \right).
\end{equation}
In the final layer, we obtain the genotype-environment representation via average pooling:
\begin{align}
\label{eq:condition}
C = \frac{1}{m} \sum_{i=1}^{m} H^{\text{MSA}}_{i,j} \in \mathbb{R}^{l\times d},
\end{align}
where $m$ represents the number of sequences in MSA.
This conditioning strategy enables the generative model to leverage MSA evolution patterns and environmental dependencies, leading to biologically plausible phenotype synthesis.

% Specifically, we concatenate environmental embeddings with MSA embeddings and process them using the BERT model:
% \begin{align}
% \label{eq:condition}
% c = \texttt{BERT}([\vh_e, \vh_{MSA,1}, \cdots, \vh_{MSA,L}]).
% \end{align}



% The model consists of 12 layers of transformer modules, each with 12 attention heads and an embedding of size 768. The maximum length of token sequence is set to 1024, allowing the model to process longer sequences of input data. 



% \subsection{Dynamic Cross-modality Alignment}
% \label{sec:Alignment}
% % 参考GLIDE https://arxiv.org/pdf/2112.10741
% To enhance genotype-phenotype consistency, we introduce a cross-modal alignment strategy that integrates the reverse diffusion process with the MSA encoder. 
% Specifically, we propose a gradient-guided alignment framework, where an alignment model $g_{\phi}(X_t, t)$ is trained to align noisy image embedding $X_t$ to the associated DNA embedding.
% This process, termed dynamic alignment, leverages noisy images at multiple diffusion steps to refine phenotype representations.
% Mathematically, the conditional diffusion score \cite{ho2022classifier} is 
% \begin{align}
%     \epsilon(X_t, c) \approx -\sqrt{1-\alpha_t} \nabla_{X_t} \left[\log{p_{\theta}(X_t|c)} + w \log{p_{\phi}(c|X_t)}\right].
%     \label{eq:align}
% \end{align} where $w$ controls the strength of alignment guidance.
% % The alignment model $g_{\phi}$ is implemented as a transformer with parameters $\phi$ to encode noisy image $X_t$.
% % To enhance the consistency between the ground-truth genotype and the predicted phenotype, w
% We define the learning objective of $g_{\phi}(X_t, t)$ based on contrastive loss as
% \begin{align}
%     \gL_{con} = - \log \frac{\exp{\left[g_{\phi}(X_t,t) \cdot c^+ \right]}}{\sum_{j=1}^B \exp{\left[g_{\phi}(X_t,t) \cdot c_j \right]}}.
% \end{align}
% where $B$ is the batch size, $X_t$ is the noised image at diffusion step $t$,  $c^+$ is the ground-truth environment-DNA embedding related to the phenotype, and $g_{\phi}(X_t,t)$ represents the embedding of the noised phenotype, respectively.

% Compared to previous research \cite{kim2022diffusionclip} that directly uses CLIP loss for gradient guidance, our method can dynamically align noisy images to the DNA embeddings during diffusion trajectory, which is better suited to the noisy nature of the diffusion process \cite{nichol2021glide}.


\subsection{A\hspace{-0.26pt}l\hspace{-0.26pt}i\hspace{-0.26pt}g\hspace{-0.26pt}n\hspace{-0.26pt}e\hspace{-0.26pt}d \hspace{-0.4pt}G\hspace{-0.26pt}e\hspace{-0.26pt}n\hspace{-0.26pt}o\hspace{-0.26pt}t\hspace{-0.26pt}y\hspace{-0.26pt}p\hspace{-0.26pt}e-t\hspace{-0.26pt}o-P\hspace{-0.26pt}h\hspace{-0.26pt}e\hspace{-0.26pt}n\hspace{-0.26pt}o\hspace{-0.26pt}t\hspace{-0.26pt}y\hspace{-0.26pt}p\hspace{-0.26pt}e\hspace{-0.4pt} D\hspace{-0.26pt}i\hspace{-0.26pt}f\hspace{-0.26pt}f\hspace{-0.26pt}u\hspace{-0.26pt}s\hspace{-0.26pt}i\hspace{-0.26pt}o\hspace{-0.26pt}n\hspace{-0.4pt} M\hspace{-0.26pt}o\hspace{-0.26pt}d\hspace{-0.26pt}e\hspace{-0.26pt}l}


\label{sec:Alignment}

We propose an aligned genotype-to-phenotype diffusion model, which leverages a conditional diffusion backbone enhanced by a dynamic cross-modality alignment mechanism to improve the consistency between generated phenotypic images and the corresponding genotypic information.

\vspace{-3.5mm}
\paragraph{Conditional Genotype-to-Phenotype Diffusion Models.}
\label{sec:diffusion}
Inspired by the success of conditional diffusion models in text-to-image generation \cite{ho2020denoising, betker2023improving,saharia2022photorealistic,zhang2023adding}, we adopt a conditional diffusion framework where the condition is the learned GxE representation $C$. The diffusion process consists of two main stages: forward diffusion and reverse denoising\cite{ho2020denoising}.

% \textit{Forward Diffusion Process.} 
During the forward process, gaussian noise is progressively added to a phenotypic image $X_0$ over $T$ steps, which is formally defined as a Markov chain:
\begin{align}
    q\left(X_{t} \mid X_{t-1}\right)=\mathcal{N}\left(X_{t} \mid \sqrt{\alpha_{t}} X_{t-1},\left(1-\alpha_{t}\right) \bf I\right).
\end{align}
Here, $\alpha_{t}$ controls the noise intensity. By denoting $\Bar{\alpha}_t = \prod\nolimits_{i=1}^{t} \alpha_i$, we can describe the entire diffusion process as:
\begin{gather}
    q\left( X_{1:T} \mid X_{0} \right) = \prod\nolimits_{t=1}^{T} q \left( X_t \mid X_{t-1} \right), \\
    q \left( X_t \mid X_{0} \right) = \mathcal{N} \left( X_t; \sqrt{\Bar{\alpha}_t} X_{0}, (1 - \Bar{\alpha}_t) \bf I \right).
\end{gather}

% \textit{Reverse Denoising Process.}

During the reverse process, it gradually removes noise from the sample $X_T$, eventually recovering $X_0$. A denoising model $\epsilon_{\theta} (X_t, t, C)$ is trained to estimate the noise $\epsilon$ from $X_t$ and a condition embedding $C$, % = \mathcal{C} (G, E)$, where $\mathcal{C} (\cdot)$ is the MSA conditioner. 
which is formally denoted as 
\begin{align}
    p_{\theta} \left( X_{t-1} | X_{t}, t, C \right) &= \mathcal{N} \left( X_{t-1}; \epsilon_{\theta} (X_t, t, C), \sigma_{t}^{2} \bf I \right).
\end{align}

The denoising process is trained by maximizing the likelihood of the data under the model or, equivalently, by minimizing the variational lower bound on the negative log-likelihood of the data. \cite{ho2020denoising} shows that this is equivalent to minimizing the KL divergence between the predicted distribution $p_{\theta} (X_{t-1} | X_{t}, C)$ and the ground-truth distribution $q (X_{t-1} | X_{t}, X_{0}, C)$ at each time step $t$ during the backward process. The training objective then becomes:
%
\begin{align}
    \min\nolimits D_{KL} \left( q \left( X_{t-1} | X_{t}, X_{0}, C \right) \big\| p_{\theta} \left( X_{t-1} | X_{t}, C \right) \right),
\end{align}
%
which can be simplified as:
%
\begin{align}
    L_{DM} &= \mathbb{E}_{\epsilon, t} \left[\| \epsilon - \epsilon_{\theta} (X_t, t, C) \|_{2}^{2}\right]. 
    \label{eq:loss}
\end{align}






\paragraph{Dynamic Alignment Sampling Mechanism.}    To enhance genotype-phenotype consistency, we introduce a cross-modal alignment strategy that integrates the reverse diffusion process with the MSA encoder. 
Specifically, we propose a gradient-guided alignment framework, where an alignment model $g_{\phi}(X_t, t)$ is trained to align noisy image embedding $X_t$ to the associated DNA embedding.
This process, termed dynamic alignment, leverages noisy images at multiple diffusion steps to refine phenotype representations.
Mathematically, the conditional diffusion score \cite{ho2022classifier} is 
{\small
\begin{align*}
    \epsilon(X_t, t, C) \approx -\sqrt{1-\alpha_t} \nabla_{X_t} \left[\log{p_{\theta}(X_t|C)} + w \log{p_{\phi}(C|X_t)}\right],
\end{align*}
}
where $w$ controls the strength of alignment guidance.
% The alignment model $g_{\phi}$ is implemented as a transformer with parameters $\phi$ to encode noisy image $X_t$.
% To enhance the consistency between the ground-truth genotype and the predicted phenotype, w
We define the learning objective of the aligner $g_{\phi}(\cdot,\cdot)$  as
\begin{align}
\label{eq:aligner}
    \gL_{align} = - \log \frac{\exp{\left[g_{\phi}(X_t,t) \cdot C^+ \right]}}{\sum_{j=1}^B \exp{\left[g_{\phi}(X_t,t) \cdot C_j \right]}},
\end{align}
where $\phi$ is learnable parameter, $B$ is  batch size, $X_t$ is the noised image at diffusion step $t$,  $C^+$ is the ground-truth GxE representation related to the phenotype. %, and $g_{\phi}(X_t,t)$ is the embedding of the noised phenotype image, respectively.

\vspace{-3mm}
\paragraph{Sampling.} Compared to previous research \cite{kim2022diffusionclip} that directly uses CLIP loss for gradient guidance, our method can dynamically align noisy images to the DNA embeddings during diffusion trajectory, which is better suited to the noisy nature of the diffusion process \cite{nichol2021glide}.
% \paragraph{Dynamic Alignment Sampling Mechanism.}  
% The conditional diffusion score is extended to incorporate both objectives:
% \begin{align}
%     \epsilon(X_t, C) \approx -\sqrt{1-\alpha_t} \nabla_{X_t} \left[\log{p_{\theta}(X_t|C)} + w \log{p_{\phi}(C|X_t)}\right]
%     \label{eq:align}
% \end{align}
% where $w$ controls the alignment strength. 
% \paragraph{G2PDiffusion Design \& Inference.} We carefully design the conditioner $C=\phi(G,E)$ and an aligner $g_{\phi}(X_t, t)$ to enhance the genotype-phenotype consistency. During each denoising step, the denoised diffusion model $f_{\theta}(X_t, t, C)$ gradually refines the initial random noise $X_T$ into the target phenotype image $X_0$. 
Algorithm~\ref{alg:sample} summarizes the guided genotype-to-phenotype sampling process.

\begin{algorithm}
\caption{Diffusion Model Sampling with Guidance}
\label{alg:sample}
\begin{algorithmic}[1]
\STATE \textbf{Input:} Initial noise $X_T$, DNA sequence $G_q$, environment context $E$,  retrival database $\mathcal{D}$, environment-enhanced MSA encoder $\mathcal{C}(\cdot)$, conditional diffusion model $\epsilon_{\theta}(X_t, t, C)$, aligner $g_{\phi}(X_t, t)$, guidance strength $w$, update rate $\eta$
%\STATE \textbf{Output:} Sample $X_0$

\STATE \textbf{Initialize} $X_T$ as random noise
\STATE Retrieve $m$ similar DNA sequences $\{G_i\}_{i=1}^m$ from $\mathcal{D}$ according to $G_q$, and get GxE representation $C= \mathcal{C}(G_q, \{G_i\}_{i=1}^m, E)$
\FOR{$t = T$ down to 1}
    \STATE Compute $\nabla_{X_t} \log p_{\theta}(X_t| C)$ using the conditional diffusion model $\epsilon_{\theta}(X_t, t, C)$;  
    \STATE Compute $\gL_{align}$ using the aligner $g_{\phi}(X_t, t)$ and $C$, referring to Eq.~\ref{eq:aligner};
    \STATE Update gradient:\\
    \scalebox{0.87}{ $\nabla_{X_t}\log p_{\theta,\phi}(X_t| C) \leftarrow \nabla_{X_t}\log p_{\theta}(X_t|C)+w\nabla_{X_t} \gL_{align}$}
    \STATE Estimate $X_{t-1}$ using the updated gradient:\\
    $
    X_{t-1} = X_{t} - \eta \cdot \nabla_{X_{t}} \log p_{\theta, \phi}(X_{t} \mid C)
    $
    \ENDFOR
%\STATE \textbf{Return:} The final sample $X_{0}$
\STATE \textbf{Output:} Sample $X_0$
\end{algorithmic}
\end{algorithm}

