\section{Methods}
\label{sec:Preliminary}

\subsection{Problem Formulation}

We focus on the task of genotype-to-phenotype prediction, aiming to generate phenotypic images given the corresponding DNA sequence and environmental factors. Formally, the training set is denoted as $\mathcal{S} = \{(E_i, G_i, X_i)\}_{i=1}^{N_\mathcal{S}}$, where $E_i \in \mathbb{R}^2$ represents the environmental factors (e.g., longitude and latitude), $G_i \in \mathcal{G}$ denotes the DNA sequence, and $X_i \in \mathcal{X}$ represents the phenotypic image associated with $(E_i, G_i)$.
This objective is to learn a conditional generator with learnable parameters $\theta$:
\begin{align}
\label{eq:forward_ddpm2}
    f_{\theta}: (E, G) \rightarrow X.
\end{align}

% that accurately synthesizes phenotypic images $X$ conditioned on the corresponding genomic and environmental information.

\subsection{Framework Overview}
\label{sec:Framework Overview}

% We propose G2PDiffusion, a novel evolution-aware diffusion framework for genotype-to-phenotype image synthesis. We first describe the overall architecture of the proposed method in section~\ref{sec:Framework Overview}. Then we will introduce the strategy of constructing evolutionary alignments in section~\ref{sec:Constructing}. The environment-enhanced MSA encoder and evolution-aware genotype-to-phenotype diffusion model are introduced in section~\ref{sec:G2P}. We present the sampling strategy, a novel alignment approach designed to enhance genotype-to-phenotype consistency in section~\ref{sec:Alignment}. Finally, we introduce the model training and inference in section~\ref{sec:T&I}.

We propose G2PDiffusion, a novel evolution-aware diffusion framework for genotype-to-phenotype image synthesis, as shown in Figure~\ref{fig:2_diffusion}.
It contains three novel components: a highly-efficient MSA retrieval engine, an environment-aware MSA conditioner, and a dynamic phenomic alignment module.
Firstly, the MSA engine retrieves MSA from an external database to identify evolutionarily conserved and variable sequence regions (Section~\ref{sec:Constructing}). Then, the retrieved MSA together with environment contexts are fed into a conditional encoder to learn the genotype-environment (GxE) interaction (Section~\ref{sec:G2P}). Finally, we build a diffusion model based on GxE representation to generate images recording morphological features. 
% During each step of the diffusion process, we apply alignment loss to enhance genotype-phenotype consistency 
During each denoising step, a dynamic phenomic alignment module is employed to refine phenotypic representations
(Section~\ref{sec:Alignment}).

% Figure~\ref{fig:2_diffusion} shows the overall architecture of G2PDiffusion, a generative model that synthesizes high-quality images by iteratively refining noise through a latent diffusion process. 
% Evolutionary factors such as multiple sequence alignment (MSA) and environment context are used for prompting the conditional generation process.









% During denoising steps, G2PDiffusion first retrieves evolutionary alignments from the database $\mathcal{D}$ based on the input DNA sequence.
% The retrieved evolutionary alignments are tokenized alongside the original sequence and integrated with environmental tokens before being processed by the encoder. 


% Through the denoising process, G2PDiffusion effectively distills and incorporates relevant evolutionary knowledge.
% Furthermore, we introduce an adaptive alignment strategy to dynamically refine the latent space during inference, improving the fidelity of genotype-to-phenotype mapping. The following subsections elaborate on each component in detail.

 % This fusion extracts evolutionary features within the multiple sequence alignment (MSA) under environmental influences, providing a biologically informed conditioning signal for the diffusion model.


% We carefully design the conditioner $C=\phi(G,E)$.



% \TODO{add retrivial and environment-MSA encoder in Algorithm 1}


% To enhance the consistency between genotype and phenotype, a dynamic aligner $g_{\phi}(X_t, t)$ is used to align the generated image $X_t$ with DNA embedding $c$, with the consistency loss $\gL_{con}$ serving as the alignment guidance, as detailed in Sec.~\ref{sec:Alignment}.





