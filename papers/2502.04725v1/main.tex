%%%%%%%% ICML 2025 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables
\usepackage{multirow}
\usepackage{multicol}
\usepackage{makecell}
\usepackage{wrapfig} 
\usepackage{amssymb}
\usepackage{array}
\usepackage{xcolor}
\usepackage{colortbl}
\usepackage[textsize=tiny]{todonotes}

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2025} with \usepackage[nohyperref]{icml2025} above.
\usepackage{hyperref}


% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
% \usepackage{icml2025}

% If accepted, instead use the following line for the camera-ready submission:
\usepackage[accepted]{icml2025}
% \usepackage{icml2025}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{etoc} % Include the etoc package
% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}








%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}
\newcommand{\indicator}{\mathbb{1}}
\newcommand{\grayrow}{\rowcolor[gray]{0.9}}
\newcommand{\cellc}{\cellcolor{lightgray!20}}
\newcommand{\yj}[1]{\todo[linecolor=red,backgroundcolor=red!25,bordercolor=red,size=\scriptsize]{(YJ): #1}}


\newcommand{\wh}[1]{\todo[linecolor=blue,backgroundcolor=blue!25,bordercolor=blue,size=\scriptsize]{(WH): #1}}

\newcommand{\AHcomment}[1]{{\color{purple}#1}}

\def\gN{{\mathcal{N}}}
\def\sN{{\mathbb{N}}}
\def\sR{{\mathbb{R}}}
\def\sE{{\mathbb{E}}}

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\def\grad{{\mathrm{grad}}}
\def\gP{{\mathcal{P}}}
\def\gM{{\mathcal{M}}}
\def\gC{{\mathcal{C}}}
\def\sP{{\mathbb{P}}}
\def\gS{{\mathcal{S}}}
\def\gD{{\mathcal{D}}}
\def\gE{{\mathcal{E}}}

\def\bw{{\mathbf w}}
\def\bu{{\mathbf u}}
\def\bv{{\mathbf v}}
\def\bz{{\mathbf z}}
\def\by{{\mathbf y}}
\def\bI{{\mathbf{I}}}
\def\bxi{{\boldsymbol{\xi}}}
\def\bx{{\mathbf{x}}}
\def\bW{{\mathbf{W}}}
\def\beps{{\boldsymbol{\epsilon}}}
\def\bzero{{\boldsymbol{0}}}
\def\bmu{{\boldsymbol{\mu}}}
\def\bSigma{{\boldsymbol{\Sigma}}}
\def\bone{{\boldsymbol{1}}}
\def\SNR{{\mathrm{SNR}}}
\def\bomega{{\boldsymbol{\omega}}}

\usepackage{enumitem}





% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}


% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Can Diffusion Models Learn Hidden Inter-Feature Rules Behind Images?}

\begin{document}
% \captionsetup[subfigure]{margin=0pt, skip=0pt} 
\twocolumn[
\icmltitle{Can Diffusion Models Learn Hidden Inter-Feature Rules Behind Images?}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2025
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Yujin Han}{equal,yyy}
\icmlauthor{Andi Han}{equal,comp}
\icmlauthor{Wei Huang}{comp}
\icmlauthor{Chaochao Lu}{sch}
\icmlauthor{Difan Zou}{yyy}
% \icmlauthor{Firstname6 Lastname6}{sch,yyy,comp}
% \icmlauthor{Firstname7 Lastname7}{comp}
% %\icmlauthor{}{sch}
% \icmlauthor{Firstname8 Lastname8}{sch}
% \icmlauthor{Firstname8 Lastname8}{yyy,comp}
%\icmlauthor{}{sch}
%\icmlauthor{}{sch}
\end{icmlauthorlist}

\icmlaffiliation{yyy}{The University of Hong Kong}
\icmlaffiliation{comp}{RIKEN AIP}
\icmlaffiliation{sch}{Shanghai AI Laboratory}
\emailauthor{Yujin Han}{yujinhan@connect.hku.hk}
\emailauthor{Andi Han}{andi.han@riken.jp}
\icmlcorrespondingauthor{Difan Zou}{dzou@cs.hku.hk}
% \icmlcorrespondingauthor{Firstname2 Lastname2}{first2.last2@www.uk}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Diffusion Model, Deep Generative Model}

\vskip 0.3in
]
% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

% \printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
\printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.

\begin{abstract}
Despite the remarkable success of diffusion models (DMs) in data generation, they exhibit specific failure cases with unsatisfactory outputs. We focus on one such limitation: the ability of DMs to learn hidden rules between image features. Specifically, for image data with dependent features ($\bx$) and ($\by$) (e.g., the height of the sun ($\bx$) and the length of the shadow ($\by$)), we investigate whether DMs can accurately capture the inter-feature rule ($p(\by|\bx)$). Empirical evaluations on mainstream DMs (e.g., Stable Diffusion 3.5) reveal consistent failures, such as inconsistent lighting-shadow relationships and mismatched object-mirror reflections. Inspired by these findings, we design four synthetic tasks with strongly correlated features to assess DMs' rule-learning abilities. Extensive experiments show that while DMs can identify coarse-grained rules, they struggle with fine-grained ones. Our theoretical analysis demonstrates that DMs trained via denoising score matching (DSM) exhibit constant errors in learning hidden rules, as the DSM objective is not compatible with rule conformity. To mitigate this, we introduce a common technique - incorporating additional classifier guidance during sampling, which achieves (limited) improvements. Our analysis reveals that the subtle signals of fine-grained rules are challenging for the classifier to capture, providing insights for future exploration.
\end{abstract}
\section{Introduction}
\label{sec:intro}
Despite the remarkable capabilities demonstrated by diffusion models (DMs) in generating realistic images \cite{ho2020denoising,song2020score,vahdat2021score,dhariwal2021diffusion,karras2022elucidating,tian2024visual}, videos \cite{ho2022video,yu2024efficient,yuan2024instructvideo}, and audio \cite{liu2023audioldm,yang2024usee,lemercier2024diffusion}, they still encounter specific failures in synthesis quality, such as anatomically incorrect human poses \cite{borji2023qualitative,zhang2024diffbody,huang2024humannorm} and misalignment between generated content and prompts \cite{feng2022training,borji2023qualitative,chefer2023attend,liu2023discovering,lim2024addressing}, which could harm the reliability and applicability of DMs in real-world scenarios.
% \wh{demonstrate the consequences of failures}.

We focus on a specific type of failure with limited attention: the failure of DMs in learning hidden inter-feature rules behind images. Specifically, consider image data containing dependent feature pairs $(\bx,\by)$, such as the height of the sun ($\bx$) affecting the length of a pole's shadow ($\by$). Our investigation centers on whether DMs targeting the joint distribution $p(\bx, \by)$ can accurately capture the underlying relationships between $\bx$ and $\by$, effectively recovering the conditional distribution $p(\by|\bx)$. Theoretically, a diffusion model that perfectly estimates the joint distribution should naturally capture the conditional distribution, thereby learning the latent rules between features. However, in practice, numerous factors, such as non-negligible score function estimation errors, can cause the sampled joint distribution to deviate significantly from the true distribution \cite{chen2022sampling,chen2023improved,benton2024nearly}. How do these deviations propagate to inter-feature rule learning? This gap between theory and practice remains largely unexplored. 
\begin{figure*}
\setlength{\abovecaptionskip}{-1cm}
  \centering
  \includegraphics[width=1.\textwidth, height=0.34\textheight]{figures/real_synthetic.pdf}
% width=1.0\textwidth, 
\vspace*{-8mm}
  \caption{\textbf{Synthetic Tasks Inspired by Real-World Insights.} Based on whether inter-feature rules involve spatial dependencies, we categorize the failure cases into spatial and non-spatial rules. \textbf{Spatial rules} include: (a) Light-shadow, where evaluated DMs generate unreasonable multiple shadows or incorrect shadow flips; (b) Reflection/Refraction, showing incorrect mirror rules or missing refraction effects below water surface; (c) Semantics, such as inconsistencies between sunflower orientation and sun position, or brush and canvas colors. \textbf{Non-spatial rules} involve: (d) Size-Texture, like mismatches between tree diameter and growth rings; (e) Size/Region-Color, where evaluated models fail to capture burning candle's color variations and star size-color relationships (e.g., red giants and white dwarf); (f) Color-Color, as in Eclectus parrots' body-beak color correlations that DMs fail to maintain. \cref{app:Details and More Example on Real-Wold Hidden Inter-Feature Rules} provides detailed explanations for each case. These failures of mainstream DMs in handling real-world inter-feature rules inspire our design of four synthetic tasks.}
  \label{fig:real_synthetic}
  \vspace{-0.2cm}
\end{figure*}

Although existing studies have explored whether DMs can learn specific rules, they primarily focus on independent features, such as DMs' compositional capabilities \cite{okawa2024compositional,deschenauxgoing,wiedemer2024compositional}. Some works have investigated inter-feature dependencies in DMs, but the varying complexity of rules has led to contradictory findings. For example, DDPM has been reported to fail in generating images satisfying numerical equality constraints \cite{anonymous2025towards}, while succeeding in reasoning about shape patterns in RAVEN task \cite{wangdiffusion}. These inconsistencies highlight the need for a unified experimental setting that allows for adjustable rule difficulty, enabling an accurate evaluation of DMs' rule-learning capabilities. Moreover, existing studies rely heavily on empirical observations, lacking theoretical analysis to elucidate the limitations of DMs in rule conformity.


Our investigation into inter-feature rules begins with observing the limited ability of mainstream DMs (e.g., \texttt{SD-3.5 Large}, \texttt{Flux.1 Dev}) to capture real-world inter-feature rules, as illustrated in~\cref{fig:real_synthetic}, even though these models perform well on metrics such as FID  \footnote{\cref{app:Low FID and Worse Inter-Feature Leaning: A Gaussian Mixture Case} lists Mixture Gaussian as an example to demonstrate that low FID and incorrect inter-feature relationships in DMs' generations are not contradictory.}. Their errors in inter-feature relationships are evident in various scenarios, such as inconsistent relationships between sun positions and building shadows, mismatched reflections of toys in mirrors, and sunflowers failing to face the sun. Then, we carefully design four synthetic tasks to reflect real-world rule failures, ensuring the practical relevance of our findings. The rule of each task features two difficulty levels: coarse-grained rules (e.g., the sun and a pole's shadow should be on opposite sides) and fine-grained rules (e.g., the shadow's length as a precise function of the sun's height). This hierarchical, controllable framework enables a comprehensive evaluation of DMs' rule-learning capabilities. Next, through extensive experiments considering various factors including model architectures, training data size, and image resolution, we reach a consistent conclusion: \textit{DMs effectively learn coarse-grained rules but struggle with fine-grained ones}. 

Furthermore, we develop a rigorous theoretical analysis using a multi-patch data model with an inter-feature rule specified in terms of norm. We prove a constant error lower bound on learning the hidden rule via optimizing the DSM objective \cite{ho2020denoising} with a two-layer network. This demonstrates the incompatibility between learning joint distributions and identifying specific inter-feature rules.


% develop a feature learning-based theoretical analysis \citep{han2024feature} to investigate the 

Recognizing DMs' difficulty in learning inter-feature rules, we mitigate this issue by constructing contrastive pairs that satisfy either fine-grained or coarse-grained rules and then using them to train a classifier as additional guidance. While this strategy enhances rule-compliant sample generation, further improvements are still achievable. The in-depth analysis identifies that fine-grained rules exhibit weak signals, making accurate classifier training particularly challenging. We summarize our \textbf{key contributions} as follows:

% \AHcomment{this part seems repetitive and may be better merged. Then we write a paragraph}
\textit{Empirically}, inspired by mainstream DMs' struggles with real-world inter-feature rules, we innovatively create synthetic tasks with coarse/fine-grained rules to systematically assess DMs' rule learning ability in \cref{sec:real-world rule}.  Extensive experiments in \cref{sec:results} show that while DMs can learn coarse rules, their ability to grasp precise rules is limited.

\textit{Theoretically},
we rigorously analyze DMs on a synthetic multi-patch data distribution with a hidden norm dependency in \cref{sec:Theory}. 
We prove that the unconditional DDPM cannot learn the precise rule of norm constraint, which exhibits at least a constant error in approximating the desired score function. This identifies the limitation of the current DMs training paradigm and necessitates further improvements for learning hidden rules behind images.

\textit{Methodologically}, we mitigate DMs' inability to learn fine-grained rules by introducing guided diffusion with a contrastive-trained classifier in \cref{sec:mitigation}. However, the challenges of accurately classifying fine-grained rules identify room for improvement in our strategy. This problem, distinct from traditional classification tasks, involves detecting subtle distinctions between fine-grained and coarse-grained rules, highlighting valuable insights for future exploration.

\section{Related Work}
\label{sec:related}

We summarize prior studies on the ability of DMs to learn specific rules, and discuss the relations to inter-feature rules.

% Many studies have examined the ability of DMs to learn specific rules. We classify these into three types and discuss their relation to inter-feature rules.

\textbf{Factual Knowledge Rules.} The violation of factual rules in DMs refers to generated images failing to accurately reflect factual information and common sense, often characterized as hallucinations in existing work \cite{aithal2024understanding,lim2024addressing,anonymous2025towards}. Typical examples include violating common sense, such as extra, missing, or distorted fingers \cite{aithal2024understanding,pelykh2024giving,ye2023diffusion}, unreadable text \cite{gong2022diffuseq,tang2023can,xu2024energy} and snowy deserts \cite{lim2024addressing}. Additionally, inconsistencies between generated images and given textual prompts \cite{liu2023discovering,fu2024enhancing,mahajan2024prompting,li2024sd4match} can be regarded as violations of prompt-based knowledge. Unlike inter-feature rules, factual knowledge rules \textit{do not involve relationships between multiple features} and are typically attributed to imbalanced training data distribution \cite{samuel2024generating} or mode interpolation caused by inappropriate smoothing of training data \cite{aithal2024understanding}.

\textbf{Independent Features Rules.}  Prior work has investigated DMs' ability to combine independent features, i.e., compositionality. Through controlled studies with independent concepts (e.g., color, shape, size), \citet{okawa2024compositional} observe that DDPM can successfully compose different independent features. Similar findings are reported in \cite{deschenauxgoing}, where interpolation between portraits without and with clear smiles resulted in generations with mild smiles. However, numerous studies highlight DMs' limitations in complex compositional tasks \cite{liu2022compositional,gokhale2022benchmarking,feng2022training,marioriyad2024diffusion}, potentially due to insufficient training data for reconstructing each individual feature \cite{wiedemer2024compositional}. These studies primarily examine compositional tasks with \textit{independent features}, in contrast to our focus on feature dependencies.
% —a key factor in our research.

\textbf{Abstract (Dependent Feature) Rules.} This type closely aligns with our work, which studies feature relationships like shape consistency in generations. Prior studies give mixed conclusions on DDPM's rule-learning ability. For example, DDPM struggles with numerical addition rule \cite{anonymous2025towards} but maintains shape consistency rule in RAVEN task \cite{wangdiffusion}. Inconsistent rule complexity leads to ambiguous evaluation conclusions, and the lack of theoretical analysis leaves the underlying factors behind DMs' performance in rule learning poorly understood. Through controlled experiments with adjustable rule complexity, we provide a unified assessment of DMs' rule-learning abilities and offer a theoretical explanation of their fundamental limitations, as a result of their training paradigm.


\section{Exploring Hidden Inter-feature Rule Learning via Synthetic Tasks}
\label{sec:Synthetic Tasks}
In real-world image generation tasks, rules between features are often complex and difficult to define or quantify precisely. To systematically investigate DMs' ability in rule learning, as previous work \cite{okawa2024compositional,deschenauxgoing,anonymous2025towards,wangdiffusion}, we design simplified and controllable synthetic tasks in~\cref{fig:real_synthetic}. These synthetic tasks not only provide explicitly defined inter-feature rules but also abstract essential feature rules present in real-world data, thereby making our conclusions practically relevant. For example, Synthetic Task A in~\cref{fig:real_synthetic} simulates the \textit{Light-Shadow} relationship, while Task B simplifies the physical rules of \textit{Reflection/Refraction}.

% The remainder of this section is organized as follows: \cref{sec:real-world rule} examines typical inter-feature rule scenarios and evaluates the generation abilities of popular text-to-image DMs using corresponding prompts. \cref{sec:synthetic tasks} abstracts these rules into four synthetic tasks with coarse-grained and fine-grained variants to quantify DMs' rule-learning capacity. Next, \cref{sec:setup} outlines the experimental setup and metrics for measuring inter-feature relationships in generated images. Finally, \cref{sec:results} presents the evaluation results for all tasks.
\subsection{Synthetic Tasks Inspired by Real-World Insights}
\label{sec:real-world-synthetic rule}
% type of real - cate /the design /the coarse rule and  fined rule
\subsubsection{Real-World Hidden Inter-Feature Rules}
\label{sec:real-world rule}
% While the failures of DMs have been extensively studied, prior works primarily focus on issues such as the poor quality of (minority) samples \cite{sehwag2022generating,lee2023exploring,borji2023qualitative,um2023don,qin2023class} and misalignment between generated content and prompts \cite{feng2022training,liu2023discovering,lim2024addressing}, with limited attention given to the correctness of inter-feature rules in DMs' generations. 
Inspired by \citet{borji2023qualitative}, we investigate several common scenarios where inter-feature rules exist, as illustrated in~\cref{fig:real_synthetic}. Specially, we categorize these hidden rules into two types, \textit{spatial rules} and \textit{non-spatial rules}, based on whether the inter-feature relationships exist in the form of spatial arrangements or feature attributes themselves.

\textbf{Spatial Rules} are defined as constraints on the relative positions and layouts between features, such as the correlation between the sun's height and the shadow's length. In \cref{fig:real_synthetic}, scenario \textit{Light-shadow} demonstrates how the position of a light source should precisely determine the placement of building shadows. However, both 8-billion Multimodal \texttt{SD-3.5 Large}\footnote{https://huggingface.co/spaces/stabilityai/stable-diffusion-3.5-large}\cite{rombach2022high} and 12-billion model \texttt{Flux.1 Dev}\footnote{https://fal.ai/models/fal-ai/flux/dev}\cite{flux2023}, fail to generate proper shadows, either producing incorrect directions or merely creating symmetrical duplicates of the actual buildings. Similarly, in scenario  \textit{Reflection/Refraction}, while objects in front of mirrors should dictate the layout of their reflections, we observe completely unreasonable generations from both models. Furthermore, semantic consistency in \textit{Semantics} scenario is violated, as shown by sunflowers not facing the sun and mismatched paint colors between brush and canvas. 

\textbf{Non-Spatial Rules} are defined as correlations between intrinsic feature attributes, such as the relationship between an object's size and its color. For instance, in type \textit{Size -Texture}, tree trunk features should exhibit precise correlations between the diameter and annual ring count, and candle flames in type \textit{Size/Region- Color} should show constrained relationships between different flame zones and their colors. However, these fine-grained inter-feature constraints are ignored by both \texttt{SD-3.5 Large} and \texttt{Flux.1 Dev}. More detailed discussion and additional experiments for more advanced DMs are deferred to \cref{app:Details and More Example on Real-Wold Hidden Inter-Feature Rules}.
% provides more detailed reasons for DMs' failures in both spatial and non-spatial rule cases, as illustrated in~\cref{fig:real_synthetic}, including detailed prompts and additional evaluations on more text-guided DMs such as \texttt{SDXL} \cite{podell2023sdxl}, \texttt{Flux.1.1 Ultra} \cite{flux2023}, \texttt{DALL$\cdot$E 3} \cite{betker2023improving}, and VAR-based \cite{VAR} text-to-image model \texttt{Infinity} \cite{Infinity}. Although these mainstream models perform impressively on metrics such as FID, they fail to faithfully reproduce fine-grained rules in generations.

% Notably, categorizing rules into spatial and non-spatial types highlights distinct patterns and reveals their differing responses to mitigation strategies. Specifically, for spatial rules, incorporating spatial structural information between features during training—such as first learning the distribution $p(\mathbf{x})$ of feature $\mathbf{x}$ and then learn $p(\mathbf{y}|\mathbf{x})$ with conditional DMs—effectively addresses the limitations of DMs in capturing fine-grained rules between features $\mathbf{x}$ and $\mathbf{y}$. However, this mitigation approach proves less ineffective for non-spatial rules as further discussed in detail in \cref{sec:mitigation}.

\subsubsection{Synthetic Tasks}
\label{sec:synthetic tasks}
Inspired by real-world rules in \cref{sec:real-world rule}, we design four synthetic tasks (A-D), each with two levels of rule granularity (coarse and fine), as shown in~\cref{fig:real_synthetic}. We provide a brief overview of synthetic tasks here, with more details presented in~\cref{app:Details and More Example on Synthetic Tasks}. Specially,

\textbf{Task A} is inspired by the spatial rules behind the \textit{Light-shadow} case, simulating the physical law between the sun and pole shadows. In Task A of \cref{fig:real_synthetic}, the \textit{coarse-grained rule} requires the sun and shadow to be on opposite sides of the pole, while the \textit{fine-grained rule} requires sun's center, pole top, and shadow endpoint align linearly, i.e., satisfying $l_1h_2=l_2h_1$ (see notations in Task A, \cref{fig:real_synthetic}).

\textbf{Task B} abstracts the spatial rule from the \textit{Reflection/Refraction} case, where an object's reflection size depends on its size and distance from the mirror. Task B uses two rectangles with lengths $h_1$ and $h_2$ (notations shown in Task B, \cref{fig:real_synthetic}) to simulate this perspective rule, where size diminishes with distance. Assuming the viewpoint is at the leftmost edge, the \textit{coarse-grained rule} requires the left rectangle (closer to the viewpoint) to be longer than the right one (farther from the viewpoint), i.e., $h_1 > h_2$, while the \textit{fine-grained rule} dictates rectangle lengths be proportional to their distances from the viewpoint, i.e., $l_1h_2=l_2h_1$.

\textbf{Task C} consists of two tangent circles of different radii, aiming to capture the relationship between shape/outlook and size as illustrated in non-spatial rule. The \textit{coarse-grained rule }simply requires distinct radii for the two circles, i.e., $r_1 \neq r_2$, while the \textit{fine-grained rule} specifies a precise ratio between the radii, requiring $r_2 = \sqrt{2} r_1$.

\textbf{Task D} simplifies the non-spatial rule from scenario \textit{Size/Region- Color} in \cref{fig:real_synthetic}, where, in candle flame generations, colors transition from blue near the wick to yellow at the outer regions. We construct two such squares, with smaller squares positioned in the upper half and larger ones in the lower half of the image. The \textit{coarse-grained rule} requires that the upper square's side length $l_1$ be smaller than the lower square's side length $l_2$, i.e., $l_1 < l_2$, while the \textit{fine-grained rule} specifically requires $l_2 = 1.5l_1$.
\begin{figure}[]
  \centering
  % \setlength{\abovecaptionskip}{-0.01cm} width=0.5\textwidth, height=0.32\textheight
  \includegraphics[width=0.50\textwidth]{figures/metric_vis_v4.pdf}
% width=1.0\textwidth, 
\vspace*{-8mm}
  \caption{\textbf{Pipeline for extracting features.} Given an image, we first apply a color-based mask by using predefined colors, then count whether the number of masks meets expectations, and finally extract features of interest by marking the key points within masks.}
  \label{fig:metric_vis}
    \vspace{-0.6cm} 
\end{figure}
    % \vspace{-0.3cm} 
\subsection{Experimental and Evaluation Setup}
\label{sec:setup}
% sample size / model /image size / DDPM hyper
After designing synthetic tasks with well-defined inter-feature rules, we can systematically investigate the capability of DMs to learn these underlying relationships. 
% Before proceeding further, we briefly outline our synthetic experimental setup and evaluation method, which enable the quantitative assessment of various DMs with different architectures, training sample sizes, and image resolutions.

\textbf{Experimental Setup.}  In subsequent experiments, we train an unconditional DDPM \cite{ho2020denoising} on four synthetic tasks. Unlike latent-space DMs (e.g., \texttt{SD-3.5 Large}), pixel-space DDPM makes the conformity of inter-feature relationships potentially simpler, as no additional compression-induced information loss occurs \cite{rombach2022high,yao2025reconstruction}. Following the training setting \cite{aithal2024understanding}, we fix the total timesteps at $T=1000$ and employ the widely-used U-Net architecture \cite{ronneberger2015u} as the denoiser. $4000$, $2000$, $2000$, and $2000$ samples are generated for synthetic task A, B, C and D, respectively, with an image size of $32 \times 32$. Additionally, in \cref{app:More Setting of Synthetic Tasks}, we explore more advanced architectures such as DiT \cite{peebles2023scalable} and SiT \cite{ma2024sit}, alongside larger synthetic datasets of $20000$ and $40000$ samples and higher image resolutions of $64 \times 64$. These factors enhance the training of DMs, thus leading to better alignment between generated and real data distributions \cite{chen2022sampling,benton2024nearly,chen2023improved} and enabling more effective learning of hidden rules. More experimental details  are in \cref{app:Details of DMs' Training}.
\begin{figure*}[t!]
\centering
    \hfill
    \subfigure[Task A]{\label{fig:metric_training_A}\includegraphics[width=0.24\textwidth]{figures/taska_rule.pdf}}
    \hfill
    \subfigure[Task B]{\label{fig:metric_training_B}\includegraphics[width=0.24\textwidth]{figures/taskb_rule.pdf}}
    \hfill
    \subfigure[Task C]{\label{fig:metric_training_C}\includegraphics[width=0.235\textwidth]{figures/taskc_rule.pdf}}
    \hfill
    \subfigure[Task D]{\label{fig:metric_training_D}\includegraphics[width=0.24\textwidth]{figures/taskd_rule.pdf}}
    \hfill
\vspace{-0.15in}
\caption{\textbf{Synthetic training data satisfies fine-grained rules.} To validate the evaluation method, we extract relevant features from the synthetic training data and check if they meet expectations, focusing on generations within the interval $[2.5\%,97.5\%]$ for stability. The closely matching Estimation and Ground Truth lines, along with an $R^2$ value near $1$, demonstrate effectiveness of the evaluation method.}
\vspace{-0.15in}
\label{fig:metict_training}
\end{figure*}

\begin{figure*}[t!]
\centering
    \hfill
    \subfigure[Task A]{\label{metric_gen_A}\includegraphics[width=0.24\textwidth]{figures/taska_rule_gen.pdf}}
    \hfill
    \subfigure[Task B]{\label{metric_gen_B}\includegraphics[width=0.24\textwidth]{figures/taskb_rule_gen.pdf}}
    \hfill
    \subfigure[Task C]{\label{metric_gen_C}\includegraphics[width=0.24\textwidth]{figures/taskc_rule_gen.pdf}}
    \hfill
    \subfigure[Task D]{\label{metric_gen_D}\includegraphics[width=0.24\textwidth]{figures/taskd_rule_gen.pdf}}
    \hfill
\vspace{-0.15in}
\caption{\textbf{Generated data does not satisfy fine-grained rules.} Considering generated samples within the $[2.5\%, 97.5\%]$ range, we extract focused features and check if they meet fine-grained rules. The Estimation line, far from the Ground Truth line, and an $R^2$ value less than $1$, reveal DMs' failure in learning fine-grained rules. \cref{app:More Results of Synthetic Tasks} shows generated images that violate the fine-grained rules.}
\vspace{-0.15in}
\label{fig:gen_metric}
\end{figure*}

\textbf{Evaluation Method.} To evaluate whether generated images follow the inter-feature rules, \cref{fig:metric_vis} designs a three-step feature extraction pipeline: (1) Color-based Mask: Segment element masks (e.g., sun, pole, shadow in Task A) based on predefined color (HSV) ranges when synthesizing training data; (2) Elements Count: Apply contour detection based on masks to verify the presence of essential elements, marking images as \texttt{Invalid} if any are missing; (3) Feature Extraction: Extract key feature points (e.g., sun center, pole top/center and shadow endpoint in~\cref{fig:metric_vis}) and compute geometric features of interest, such as horizontal sun-to-pole distance $l_1$, vertical sun-to-pole-top distance $h_1$, pole height $h_2$, shadow length $l_2$. All features are scaled to $[0,1]$ by dividing them by the image size to eliminate scale effects.

With these features, we can verify whether generated images satisfy predefined rules. For example, in Task A, we examine: (1) Coarse-grained rule: the sun and shadow are on opposite sides of the pole by comparing the relative positions of the sun center, pole center, and shadow endpoint; (2) Fine-grained rule: validate the precise geometric relationship $l_1h_2 = l_2h_1$. We extend the same feature extraction approach in~\cref{fig:metric_vis} to validate inter-feature rules in Tasks $B$, $C$, and $D$. We apply the evaluation method to synthetic training data to validate our approach's effectiveness, as shown in \cref{fig:metict_training}, which demonstrates a close alignment between the estimation and ground truth across all tasks.

% Before presenting the main results, we validate our feature extraction method on the training datasets. \cref{fig:metict_training} visualizes the fine-grained rules across all four synthetic tasks, with the ground truth line representing the true rule in the synthetic data, and the estimation line showing the relationships detected by proposed evaluation method. The close alignment between the estimation and ground truth across all tasks confirms the effectiveness of our approach.

\subsection{Experimental Results}
\label{sec:results}
% coarse rule and  fined rule

For each synthetic task, we generate 2000 samples and report the evaluated results as follows:
\input{tables/coarse_rule}

\textbf{DMs' Success on Coarse-Grained Rules.} \cref{tab:coarse-grained rule} demonstrates that DMs rarely generate samples that violate the coarse-grained rules across all tasks. This observation aligns with expectations: generating samples that violate coarse-grained rules requires DMs to generate out of the (training) distribution (OOD) - an extrapolation challenge for DMs observed in prior work \cite{okawa2024compositional,kang2024far}. In Task A, for example, all training samples place the sun and shadow on opposite sides of the pole; violating this rule would require generating a never-seen mode with both elements on the same side. 

\textbf{DMs' Failure on Fine-Grained Rules.} While following coarse-grained rules only requires DMs to avoid unreasonable OOD generations, fine-grained rules are much harder, demanding accurate learning of the in-distribution training data. \cref{fig:gen_metric} demonstrates the models' performance across four synthetic tasks, where deviations from the ground truth in linear fitting and the coefficient of determination $R^2$ below 1 indicate that DMs fail to fully capture the predefined fine-grained rules. Additionally, we observe that DMs struggle more with learning non-spatial rules, such as Task C, compared to spatial rules, such as Task A, as evidenced by worse linear fitting and smaller $R^2$. This discrepancy likely arises from the fact that non-spatial rules are more implicit and lack explicit cues, such as object positions and lengths, which are readily available in spatial relationships. More experiments for various settings (e.g., other backbone models) are deferred to 
\cref{app:More Setting of Synthetic Tasks}, which shows consistent empirical observations that DMs can capture coarse-grained rules but struggle to master fine-grained ones.

\textbf{Despite Instabilities, DMs Can Generate Fine-Grained Samples.} While fine-grained rule experiments show DMs generally struggle to exactly 
satisfy underlying rules, we observe that they can occasionally generate rule-conforming samples in \cref{fig:rule_conforming}, albeit with instability. For example, in Task A, there are $10$ generated samples that (almost) satisfy the fine-grained rule, i.e., $\frac{l_2h_1}{l_1h_2} \in [0.99,1.01]$. 
\begin{figure}[t!]
\vspace{-0.04in}  
\centering
    \hfill
    \subfigure[Rule-conforming generations acrross four tasks.]
    {\label{fig:rule_conforming}\includegraphics[width=0.23\textwidth]{figures/highquality_gen.pdf}}
    \hfill
    \subfigure[Memorization with different thresholds in Task A.]
    {\label{fig:taska_memory_rates_13d}\includegraphics[width=0.22\textwidth]{figures/taska_memory_rates_13d.pdf}}
    \hfill
\vspace{-0.15in} 
\caption{\textbf{DMs generate rule-conforming samples.} Define Rule-conforming generations have ratios (e.g., \(\frac{l_2h_1}{l_1h_2}\) in Task A) within \(\pm 0.01\) of true ratio ($1$ in Task A). \cref{fig:rule_conforming} shows DDPM's ability to generate rule-conforming samples across tasks. \cref{fig:taska_memory_rates_13d} indicates that nearest neighbor distances between $10$ rule-conforming samples in Task A and training data are large ($>0.3$), suggesting novel generation rather than memorization.}
\vspace{-0.3in}  
\label{fig:mem_gen}
\end{figure}
To determine whether these 10 ideal samples originate from DDPM's generation or are merely training data replicas \cite{somepalli2023diffusion,somepalli2023understanding,wang2024discrepancy}, we analyze their memorization behaviors. For Task A, we represent each sample with a 13D vector capturing key features $(l_1,l_2,h_1,h_2)$ and encoding RGB colors of sun, pole, and shadow. We then compute Euclidean distances to their nearest neighbors, considering samples as replicas if the distance is below a given threshold.
\cref{fig:taska_memory_rates_13d} shows rule-conforming generations are not mere duplicates, achieving $100\%$ memorization at a large threshold ($0.3$). \cref{app:More Results of Synthetic Tasks} shows $10$ ideal samples and their nearest neighbors, highlighting differences. This suggests that, although unstable, DMs can generate rule-conforming samples. Inspired by this, \cref{sec:mitigation} presents a mitigation strategy with additional guidance to improve generation consistency.

% using two coordinate systems: a 4D representation capturing key features $(l_1,l_2,h_1,h_2)$ and a 13D representation that additionally encodes the RGB colors of the sun, pole, and shadow. This dual-coordinate analysis allows us to distinguish whether differences between generated and training samples arise from structural variations or merely from different color combinations within similar structures \cite{okawa2024compositional}. We compute the Euclidean distances between each generated sample and its nearest neighbor in both 4D and 13D spaces. If the distance falls below the given threshold, the sample is considered a replica of its neighbor.
% While generated samples show close structural similarity to their nearest neighbors in 4D coordinates, they only achieve 100\% memorization rate in 13D space at a relatively large threshold ($0.5$). This observation reveals DMs do possess the capability to generate samples satisfying fine-grained rules but inconsistently. This observation shows that DMs can generate samples satisfying fine-grained rules, but inconsistently. This motivates our mitigation strategy in \cref{sec:mitigation}, where we use classifier guidance to encourage more stable rule-conforming generations and avoid low-quality samples.
\begin{figure*}[t!]
\centering
    \hfill
    \subfigure[$t = 0.2$]{\label{fig:diff_0.2}\includegraphics[width=0.23\textwidth]{figures/diff_0.2.pdf}}
    \hfill
    \subfigure[$t = 0.4$]{\label{fig:diff_0.4}\includegraphics[width=0.23\textwidth]{figures/diff_0.4.pdf}}
    \hfill
    \subfigure[$t = 0.6$]{\label{fig:diff_0.6}\includegraphics[width=0.23\textwidth]{figures/diff_0.6.pdf}}
    \hfill
    \subfigure[$t = 0.8$]{\label{fig:diff_0.8}\includegraphics[width=0.23\textwidth]{figures/diff_0.8.pdf}}
    \hfill
\vspace{-0.1in}
\caption{\textbf{Diffusion model exhibits non-vanishing error on synthetic multi-patch data with norm constraint.} We observe for a variety of timestep $t$ and activation functions (ReLU, linear, quadratic and cubic), 
a (two-layer) diffusion model cannot learn precisely the hidden norm constraint as in Definition \ref{def:data_distr}, with both bias and variance error.}
\vspace{-0.15in}
\label{fig:diff}
\end{figure*}

\section{DMs' Failure from a Theoretical Perspective}
\label{sec:Theory}
This section provides theoretical explanations for our observed phenomenon - DMs' inability to effectively learn precise rules. {Our analysis reveals that without prior knowledge on the hidden rules, DMs trained by minimizing the DDPM loss \cite{ho2020denoising} exhibit a constant error in rule conformity, indicating that they cannot accurately learn the ground-truth rule.}

We consider the following multi-patch data setup, which has been widely employed for theoretical analysis of classification \cite{allen2020towards,cao2022benign,zou2023benefits,lu2024benign}, and
recently for diffusion models \cite{han2024feature}.
%
\begin{definition}[Data distribution with Inter-Feature Rules]
\label{def:data_distr}
Let $\bu, \bv \in \sR^d$ be two orthogonal feature vectors with unit norm, i.e., $\| \bu\| = \| \bv\| = 1$ and $\langle \bu, \bv \rangle = 0$. 
Let $\zeta$ be a random variable with its distribution $\gD_\zeta$ supporting on a bounded domain $[\underline{c}_\zeta, \overline{c}_\zeta]$ for some constants $0 < \underline{c}_\zeta < \overline{c}_\zeta < \infty$. Each image data consists of multiple patches
\begin{align*}
    &\bx = [\bx^{(1)\top}, \bx^{(2)\top}, ..., \bx^{(P)\top}]^\top, \\
    \text{ where }\quad &\bx^{(1)} = \zeta \bu, \,  \bx^{(2)} = (1-\zeta) \bv,
\end{align*}
and $\bx^{(1)}, \bx^{(2)}$ are \textit{independent} with the remaining patches.
\end{definition}
% Such a data setup is motivated by image representation where features can be segemented into multiple patches. 
Definition \ref{def:data_distr} specifies a \textit{inter-feature rule} on the first two patches of the data, requiring that the norm of the first two feature patches sum up to one, i.e., $\| \bx^{(1)} \| + \| \bx^{(2)}\| = 1$. Furthermore, we show such a rule will further lead to a structural constraint on the score function. Specifically, let $\bx_0 = [\zeta \bu^\top, (1- \zeta) \bv^\top, \bx^{(3)\top}, ..., \bx^{(P)\top}]$ represent an input image. 
For arbitrary noise scedules $\{\alpha_t, \beta_t\}$, $\bx_t = \alpha_t \bx_0 + \beta_t \beps_t$ represents the noised image at timestep $t$. 
We derive the score function along the diffusion path as follows. 

\begin{theorem}
\label{thm:score}
The score function is $\nabla \log p_t(\bx_t) = [\nabla \log p_t(\bx_t^{(1)}, \bx_t^{(2)})^\top, \nabla \log p_t(\bx_t^{(3)}, ..., \bx_t^{(P)})^\top]^\top$, where 
\begin{align*}
    &\nabla \log p_t(\bx_t^{(1)}, \bx_t^{(2)}) \\
    &= - \frac{1}{\beta_t^2} \bx_t + \frac{\alpha_t}{\beta_t^2}
    \begin{bmatrix}
        \sE_{\gD_\zeta} [\pi_t(\zeta, \bx_t) \zeta  ] \bu \\
        \sE_{\gD_\zeta} [\pi_t(\zeta, \bx_t) (1-\zeta) ] \bv 
    \end{bmatrix} 
\end{align*}
where $\pi_t(\zeta, \bx_t) = \frac{\gN(\bx_t; \bmu_t( \zeta), \beta_t^2 \bI_{2d})}{\sE_{D_\zeta} [\gN(\bx_t; \bmu_t( \zeta), \beta_t^2 \bI_{2d})]}$,  $\bmu_t(\zeta) = [\alpha_t  \zeta \bu^\top, \alpha_t  (1- \zeta) \bv^\top ]^\top$.
\end{theorem}
It is clearly noted that the ground truth score (restricted to the first two patches) exhibits the following identity:
\begin{align}
    \sE_{\gD_\zeta} [\pi_t(\zeta, \bx_t) \zeta]  + \sE_{\gD_\zeta} [\pi_t(\zeta, \bx_t) (1-\zeta)]  &= \sE_{\gD_\zeta} [\pi_t(\zeta, \bx_t) ] \nonumber\\
    &= 1. \tag{\textasteriskcentered} \label{eq:hidden_rule}
\end{align}
Then, we aim to investigate whether a score network, trained via DSM objective, can accurately conform to such a hidden rule \eqref{eq:hidden_rule}. Specifically, we follow \citep{han2024feature} and consider the following two-layer neural network model: $s_{w}(\bx_t) = [s_{w}^{(1)}(\bx_t)^\top, ..., s_{w}^{(P)}(\bx_t)^\top ]^\top$, with 
\begin{align}
    % &s_{w}(\bx_t) = [s_{w}^{(1)}(\bx_t)^\top, ..., s_{w}^{(P)}(\bx_t)^\top ]^\top \nonumber \\
    &s_{w}^{(p)}(\bx_t) =  -\frac{1}{\beta_t^2} \bx_t^{(p)} + \sum_{r=1}^m \sigma(\langle \bw_{r,t}^{(p)}, \bx_t^{(p)} \rangle ) \bw_{r,t}^{(p)}, \label{eq:score_network_main}
\end{align}
where each patch is processed with a separate set of $m$ neurons, and  $\sigma(\cdot)$ is an (non-constant) polynomial activation function.
%
Such a network mimics the structure of U-Net \cite{ronneberger2015u} with shared encoder and decoder weights. 
The network also contains a residual connection that aligns with the score function (Theorem \ref{thm:score}). Similar network design has been considered in \cite{shah2023learning,han2024feature}. 
We train the score network by minimizing the DSM loss \cite{ho2020denoising} with expectation on the diffusion noise and the input: 
\begin{align}
    L(\bW_t) =  \sE_{\beps_{t}, \bx_{0}} 
    \sum_{p=1}^P \Big\|  s_w^{(p)}(\bx_t^{(p)}) - \beps_{t}^{(p)} \Big\|^2 \label{eq:ddpm_loss}
\end{align}
where $\bx_{t}^{(p)} = \alpha_t \bx_{0}^{(p)} + \beta_t \beps_{t}^{(p)}$. We next define the \textit{rule-conforming error} to measure the learning outcome of the hidden rule \eqref{eq:hidden_rule}.
\begin{definition}[Rule-conforming error]
For the score network $s_w$ of a diffusion model with weights $\bw_{r,t}^{(p)*}$, let 
 \begin{align*}
     \psi_t (\bx_t) 
     \coloneqq \big\langle s_{w}^{(1)}(\bx_t) + \frac{1}{\beta_t^2} \bx_t^{(1)}, \bu \big\rangle+ \big\langle  s_{w}^{(2)}(\bx_t) + \frac{1}{\beta_t^2} \bx_t^{(2)}, \bv \big\rangle
     % \rangle \\
     % &= \big\langle \sum_{r=1}^m \sigma(\langle \bw_{r,t}^{(1)*}, \bx_t^{(1)} \rangle) \bw_{r,t}^{(1)*}, \bu  \big\rangle \\
     % &\qquad + \big\langle \sum_{r=1}^m \sigma(\langle \bw_{r,t}^{(2)*}, \bx_t^{(2)} \rangle) \bw_{r,t}^{(2)*}, \bv  \big\rangle 
 \end{align*}
 be the coefficient along directions $\bu, \bv$ at time $t$ for $\bx_t$. We say the diffusion model conforms to {rule \eqref{eq:hidden_rule}} if $\psi_t(\bx_t) = \frac{\alpha_t}{\beta_t^2}$ holds for \textit{any} $\bx_t$. 
 We define the \textit{rule-conforming error} as:
 \begin{equation*}
     \gE = \sE_{\bx_t} \bigg[ \bigg( \psi_t(\bx_t)  - \frac{\alpha_t}{\beta_t^2}\bigg)^2  \bigg].
 \end{equation*}
% for any noised input $\bx_t$ and any diffusion timestep $t$.   
\end{definition}
Then, we consider training ${s}_w$ by gradient descent over \eqref{eq:ddpm_loss} starting from initialization $\{\bw_{r,t}^{(p),0}\}_{r\in[m], p\in [P]}$. The following theorem derives a lower bound on the rule-conforming error for the trained score network model.


\begin{theorem}
\label{them:multi_poly}
Let $\bw_{r,t}^{(p)*}$, $r \in [m]$ be a stationary point of the DDPM loss \eqref{eq:ddpm_loss}. Then we can lower bound 
\begin{align*}
    \gE &\geq \sE_{\zeta, \beps_{t,-}^{(1)}} \Big[ {\rm Var}_{|\zeta, \beps_{t,-}^{(1)}} \big( \widetilde \sigma^{(1)}( \langle \bu, \beps_{t, \perp}^{(1)} \rangle ) \big) \Big] \\
    &\quad+ \sE_{\zeta, \beps_{t,-}^{(2)}}  \Big[ {\rm Var}_{|\zeta, \beps_{t,-}^{(2)}} \big( \widetilde \sigma^{(2)}( \langle \bv, \beps_{t, \perp}^{(2)} \rangle ) \big) \Big]
\end{align*}
where we decompose $\beps_t^{(p)} = \beps_{t,-}^{(p)} + \beps_{t, \perp}^{(p)}$ with $\beps_{t,-}^{(p)}$ being the projection of $\beps_t^{(p)}$ onto ${\rm span}( \bw_{1,t}^{(p),0}, ..., \bw_{m,t}^{(p),0} )$. 
${\rm Var}_{(|A) } (\cdot) \coloneqq {\rm Var}(\cdot|A)$ is the conditional variance and $\widetilde \sigma^{(p)}(\cdot)$ is a polynomial with coefficients depending on $\langle \bw_{r,t}^{(1)*}, \bu \rangle, \langle \bw_{r,t}^{(2)*}, \bv \rangle$.
\end{theorem}
Theorem \ref{them:multi_poly} immediately suggests a non-vanishing rule-conforming error, as long as the polynomial $\widetilde{\sigma}$ is non-constant and dimension $d$ is sufficiently larger than network width $m$ to ensure variability in the random noise $\beps_{t, \perp}$, which is independent of $\bu$ and $\bv$. 

We now show that when simplifying the model to linear activation $\sigma(x) = x$ and single neuron ($\bw_{t}^{(p)}$), the rule-conforming error can be computed as the sum of bias and variance errors, both of them are lower bounded by some constants. 
Specifically, we decompose
\begin{align*}
    \gE &=\underbrace{\Big| \sE_{\bx_t} \big[  \psi_t(\bx_t) \big] - \frac{\alpha_t}{\beta_t^2} \Big|^2}_{\gE_{\rm bias}^2} + \underbrace{\mathrm{Var}\big[\psi_t(\bx_t)\big]}_{\gE_{\rm variance} }.
    % \underbrace{ \sE_{\bx_t} \Big[  \psi_t(\bx_t)^2 \Big]  - \big( \sE_{\bx_t} \big[  \psi_t(\bx_t) \big] \big)^2}_{\gE_{\rm variance} }.  
    % := \gE_{\rm bias}^2 + \gE_{\rm variance} \\
    % \text{where } &\gE_{\rm bias}  = \Big| \sE_{\bx_t} \big[  \psi_t(\bx_t) \big] - \frac{\alpha_t}{\beta_t^2} \Big| \\
    % % &= \Big| \alpha_t \sE[\zeta] \langle \bw_t^{(1)}, \bu \rangle^2 + \alpha_t \sE[1-\zeta] \langle \bw_t^{(2)}, \bv\rangle^2 - \frac{\alpha_t}{\beta_t^2} \Big| \\
    % &\gE_{\rm variance} = \sE_{\bx_t} \Big[  \psi_t(\bx_t)^2 \Big]  - \big( \sE_{\bx_t} \big[  \psi_t(\bx_t) \big] \big)^2 
\end{align*}
% For simplicity of analysis, we consider linear activation with $\sigma(x) = x$. 
%
%
The following theorem suggests there exist a constant bias and variance error for any stationary point $\bw_{t}^{*}$.
\begin{theorem}
\label{thm:main_linear}
Suppose $\sigma(x) = x$, $m=1$ and consider $t$ such that $\alpha_t, \beta_t = \Theta(1)$. We train the network with the gradient descent on DDPM loss \eqref{eq:ddpm_loss} from small Gaussian initialization, i.e., $\bw_t^{(p),0} \sim \gN(0, \sigma_0^2 \bI_d)$,  $\sigma_0 =  O(d^{-1/2})$ and $d = \widetilde \Omega(1)$. Let $\bw_{t}^{(p)*}$ be any stationary point. Then 
\begin{itemize}[leftmargin=0.1in,nosep]
    \item $\langle \bw_t^{(1)*}, \bu\rangle, \langle \bw_t^{(2)*}, \bv \rangle = \Theta(1)$. 
    
    \item There exists constants $C_0, C_1 > 0$ (depending on $\sE[\zeta], \sE[\zeta^2], \alpha_t, \beta_t$) such that $\gE_{\rm bias} = C_0, \gE_{\rm variance} = C_1$.
\end{itemize}
\end{theorem}
Theorem \ref{thm:main_linear} shows that (1) all data features $\bu$ and $\bv$ can be discovered, which is consistent with the results in \citet{han2024feature} and verifies the ability of DMs to conform to coarse rules in the data, i.e., the existence of the key features. (2) It also verifies that DMs fail to learn the fine-grained hidden rule when no constraint or guidance is imposed over the training of DMs. Both of these two results are consistent with our empirical findings in Section \ref{sec:Synthetic Tasks}.

\textbf{Empirical verification.} We further train score networks based on the theoretical setup and evaluate the rule-conforming error in Figure \ref{fig:diff}, where we consider four different activation functions (see Appendix \ref{app:synthe_two_layer} for details). We calculate the error of DMs in learning the hidden rule \eqref{eq:hidden_rule} and plot the distribution of $\psi_t(\bx_{t})$ over $5000$ sampled $\bx_t$. It is clear that for all activation functions, the rule-conforming error is significant, verifying our theoretical results and suggesting the inability of DMs to precisely learn the hidden rules.




\section{Mitigation Strategy with Guided Diffusion}
\label{sec:mitigation}
% \subsection{Mitigation Method}
Motivated by our finding that DMs can produce rule-conforming samples but instability, we mitigate this by a common technique, \textbf{Guided DDPM}, which introduces additional classifier guidance \cite{dhariwal2021diffusion} during sampling. Specifically, we train the classifier $f_{\theta}(\mathbf{x}, t)$ through contrastive learning with constructed contrasting data pairs, where positive samples follow fine-grained rules while negative samples violate fine rules while maintaining coarse-grained compliance. The training objective is
% As shown in \cref{fig:taskd_contrastive_training}, at the forward diffusion step $t$, we frame a three-class classification problem and train a classifier $f_{\theta}(\mathbf{x}, t)$ with minimizing the following training objective:
\begin{equation}
    \mathcal{L}_{\text{total}} = \mathcal{L}_{\text{classification}} + \lambda \cdot \mathcal{L}_{\text{contrastive}},
\end{equation}
where $\lambda$ is weight parameter, $\mathcal{L}_{\text{classification}}$ is Cross-Entropy loss and $\mathcal{L}_{\text{contrastive}}$ is NT-Xent loss \cite{sohn2016improved}. More details on NT-Xent loss are in \cref{app:Details of Guided Diffusion}. Then, following \citet{dhariwal2021diffusion}, gradients from $f_{\theta}(\mathbf{x}, t)$ are used to guide sampling toward fine-grained rule compliance.

Additionally, based on constructed contrastive data, we directly train a classifier in raw images to determine whether a generation satisfies fine-grained rules. We filter samples predicted as non-rule-conforming to ensure generation quality. This approach, called \textbf{Filtered DDPM}, which directly provides guidance based on the noise-free pixel space, can be seen as the upper bound for guided diffusion strategies.

\subsection{Experiment Results}
\textbf{Setup.} We use a U-Net classifier $f_{\theta}(\mathbf{x}, t)$ with guidance weight $\lambda = 1$.  Details of the data construction and training process are provided in \cref{app:Details of Guided Diffusion}.

\textbf{Results.}
In addition to $R^2$, inspired by the theorical analysis in~\cref{sec:Theory}, we introduce Error, a metric capturing how well DMs learn hidden rules from variance and bias. Given the Ground Truth line $y = \beta_1 x$ and the Estimation line $\hat{y} = \hat{\beta}_1 x + \hat{\beta}_0$ in \cref{fig:metict_training} and \ref{fig:gen_metric}, Error is defined as:
\begin{align}
\label{eq:error}
    \text{Error} := \underbrace{|{\hat{\beta}_1-\beta_1| +|\hat{\beta}_0|}}_{\text{Bias Error}}+  \underbrace{\sqrt{\text{Var}(\hat{y}-{y})}}_{\text{Variance Error}}
\end{align}
We measure the bias error $|\mathbb{E}[y - \hat{y}]|$ with the deviation in the estimated coefficients $\hat \beta_1, \hat \beta_0$.
The variance error in \eqref{eq:error} corresponds to the square root of $\gE_{\rm variance}$ in \cref{sec:Theory}. 
% Similarly, the bias error in \cref{eq:error} is related to $\gE_{\rm bias}$ in \cref{sec:Theory} as
% \begin{align}
% \gE_{\rm bias} &= \Big|\mathbb{E}[y - \hat{y}]\Big| \propto \Big|\beta_1 - \hat{\beta}_1 + \hat{\beta}_0-0\Big|
% \end{align}

\cref{tab:mitigation} presents results, Error and $R^2$, before (DDPM) and after applying classifier guidance (Guided DDPM), along with DDPM filtered by pixel-space classifier (Filtered DDPM). Both Guided DDPM and Filtered DDPM outperform the baseline DDPM across all tasks, showing reduced Error and improved $R^2$, with Filtered DDPM achieving the best performance on most tasks.
\input{tables/guided_ddpm}
\subsection{Discussions on the Limitation of Guided Diffusion}
\label{sec:limitation}
% \begin{figure}[t!]
% \centering
% \begin{minipage}{0.235\textwidth}
%     \centering
%     \includegraphics[width=\textwidth]{figures/taskd_contrastive_training.pdf}
%     \vspace{-0.3in}
%     \caption{\textbf{Contrastive Data Construction}. Class $1$ samples satisfy fine-grained rules, while Classes $0$ and $2$ only conform to coarse-grained ones.}
%     \label{fig:taskd_contrastive_training}
% \end{minipage}
% \hfill
% \begin{minipage}{0.235\textwidth}
%     \centering
%     \includegraphics[width=\textwidth]{figures/taskd_clip.pdf}
%     \vspace{-0.3in}
%     \caption{\textbf{Contrastive Data Embedding}. The CLIP representations (reduced by UMAP) of the three classes of training data are indistinguishable.}
%     \label{fig:taskd_clip}
% \end{minipage}
%   \vspace{-0.3in}
% \end{figure}

% \begin{figure}[t!]
% \centering
%     \hfill
%     \subfigure[Task B]{\label{fig:taskb_contrastive_training}\includegraphics[width=0.235\textwidth]{figures/taskb_contrastive_training.pdf}}
%     \hfill
%     \subfigure[Task D]{\label{fig:taskd_contrastive_training}\includegraphics[width=0.235\textwidth]{figures/taskd_contrastive_training.pdf}}
%     \hfill
% \vspace{-0.1in}
% \caption{data.}
% \vspace{-0.15in}
% \label{fig:contrastive_data}
% \end{figure}

% While guided diffusion provides some mitigation for rule learning, we acknowledge that this improvement is limited. The limited improvement stems from the inherent nature of our problem: unlike conventional classification tasks, the fine-grained rules that differentiate our contrastive samples exhibit extremely subtle signals, making effective classifier training particularly challenging. Taking Task D, which shows the largest improvement in \cref{tab:mitigation}, as an example, \cref{fig:taskd_clip} visualizes the dimensionality-reduced representations of contrastive data through CLIP \cite{bianchi2021contrastive}. We observe that the three classes are nearly inseparable, explaining the modest classifier accuracy of around 0.6 and the limited improvement in guidance performance. \cref{app:Details of Guided Diffusion} presents similar findings for other synthetic tasks, supporting our hypothesis that the limited effectiveness of guidance stems from the classifier's difficulty in discriminating samples with subtle differences.
While guided and filtered diffusion provides some mitigation for rule learning, we acknowledge that this improvement is limited. The limited improvement stems from the inherent nature of our problem: unlike conventional classification tasks, the fine-grained rules that differentiate our contrastive samples exhibit subtle signals, making effective classifier training particularly challenging. In \cref{app:Details of Guided Diffusion}, we provide additional experimental evidence that, even on such simple synthetic tasks, the classification accuracy on the test set remains between $60\%$ and $80\%$, supporting the difficulty of precise classification in contrastive data.

Additionally, the effectiveness of this strategy relies on prior knowledge of fine-grained rules. In real-world scenarios, fine-grained rules are often difficult to accurately define and detect, making the construction of contrastive data impossible. We leave the solution to DMs' inability to learn fine-grained rules in real-world scenarios for future work.
\section{Conclusion}
This study evaluates DMs from the perspective of inter-feature rule learning, revealing through carefully designed synthetic experiments that DMs can capture coarse rules but struggle with fine-grained ones. Theoretical analysis attributes this limitation to a fundamental inconsistency in DMs' training objective with the goal of rule alignment. We further explore some common techniques, such as guided diffusion, to enhance fine-grained rule learning, but observe limited success. Our in-depth findings underscore the inherent difficulty of capturing subtle fine-grained rules, providing valuable insights for future advancements.

% \section*{Impact Statement}
% This paper aims to advance the fundamental understanding of machine learning, with a focus on diffusion-based image generation. We aim to enhance the interpretability of these models, shedding light on how they manage inter-feature relationships during generation. By deepening our understanding, we hope to drive community attention toward developing image generative methods that align better with real-world needs, such as adherence to physical laws. Acknowledging the societal impact of image synthesis, including its creative potential and risks like image forgery, we strive to promote principled methods and responsible use through our study of these popular diffusion techniques.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Reference
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \newpage
\nocite{langley00}
\bibliography{ref}
\bibliographystyle{icml2025}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\input{appendix/appendix}
% \appendix
% \onecolumn
% \section{}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%






\end{document}


% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was created
% by Iain Murray in 2018, and modified by Alexandre Bouchard in
% 2019 and 2021 and by Csaba Szepesvari, Gang Niu and Sivan Sabato in 2022.
% Modified again in 2023 and 2024 by Sivan Sabato and Jonathan Scarlett.
% Previous contributors include Dan Roy, Lise Getoor and Tobias
% Scheffer, which was slightly modified from the 2010 version by
% Thorsten Joachims & Johannes Fuernkranz, slightly modified from the
% 2009 version by Kiri Wagstaff and Sam Roweis's 2008 version, which is
% slightly modified from Prasad Tadepalli's 2007 version which is a
% lightly changed version of the previous year's version by Andrew
% Moore, which was in turn edited from those of Kristian Kersting and
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.
