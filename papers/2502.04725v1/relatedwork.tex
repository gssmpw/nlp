\section{Related Work}
\label{sec:related}

We summarize prior studies on the ability of DMs to learn specific rules, and discuss the relations to inter-feature rules.

% Many studies have examined the ability of DMs to learn specific rules. We classify these into three types and discuss their relation to inter-feature rules.

\textbf{Factual Knowledge Rules.} The violation of factual rules in DMs refers to generated images failing to accurately reflect factual information and common sense, often characterized as hallucinations in existing work \cite{aithal2024understanding,lim2024addressing,anonymous2025towards}. Typical examples include violating common sense, such as extra, missing, or distorted fingers \cite{aithal2024understanding,pelykh2024giving,ye2023diffusion}, unreadable text \cite{gong2022diffuseq,tang2023can,xu2024energy} and snowy deserts \cite{lim2024addressing}. Additionally, inconsistencies between generated images and given textual prompts \cite{liu2023discovering,fu2024enhancing,mahajan2024prompting,li2024sd4match} can be regarded as violations of prompt-based knowledge. Unlike inter-feature rules, factual knowledge rules \textit{do not involve relationships between multiple features} and are typically attributed to imbalanced training data distribution \cite{samuel2024generating} or mode interpolation caused by inappropriate smoothing of training data \cite{aithal2024understanding}.

\textbf{Independent Features Rules.}  Prior work has investigated DMs' ability to combine independent features, i.e., compositionality. Through controlled studies with independent concepts (e.g., color, shape, size), \citet{okawa2024compositional} observe that DDPM can successfully compose different independent features. Similar findings are reported in \cite{deschenauxgoing}, where interpolation between portraits without and with clear smiles resulted in generations with mild smiles. However, numerous studies highlight DMs' limitations in complex compositional tasks \cite{liu2022compositional,gokhale2022benchmarking,feng2022training,marioriyad2024diffusion}, potentially due to insufficient training data for reconstructing each individual feature \cite{wiedemer2024compositional}. These studies primarily examine compositional tasks with \textit{independent features}, in contrast to our focus on feature dependencies.
% â€”a key factor in our research.

\textbf{Abstract (Dependent Feature) Rules.} This type closely aligns with our work, which studies feature relationships like shape consistency in generations. Prior studies give mixed conclusions on DDPM's rule-learning ability. For example, DDPM struggles with numerical addition rule \cite{anonymous2025towards} but maintains shape consistency rule in RAVEN task \cite{wangdiffusion}. Inconsistent rule complexity leads to ambiguous evaluation conclusions, and the lack of theoretical analysis leaves the underlying factors behind DMs' performance in rule learning poorly understood. Through controlled experiments with adjustable rule complexity, we provide a unified assessment of DMs' rule-learning abilities and offer a theoretical explanation of their fundamental limitations, as a result of their training paradigm.