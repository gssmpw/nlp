\begin{figure}[t!]
\centering
\begin{tikzpicture}
    \node[anchor=south west,inner sep=0] (image) at (0,0) 
        {\includegraphics[width=1.\linewidth]{figures/raw/mol.pdf}};
    
    \begin{scope}[x={(image.south east)},y={(image.north west)}]
        \node[color=black] at (0.24,0.935) {MHSA};
    \end{scope}

    \begin{scope}[x={(image.south east)},y={(image.north west)}]
        \node[color=black] at (0.4,0.935) {MHSA};
    \end{scope}

    \begin{scope}[x={(image.south east)},y={(image.north west)}]
        \node[color=black, font=\fontsize{9}{9}\selectfont] at (0.58,0.46) {layer $1$};
    \end{scope}

    \definecolor{customcolor}{HTML}{F0EDE4}
    \begin{scope}[x={(image.south east)},y={(image.north west)}]
        \node[color=black, font=\fontsize{9}{9}\selectfont, fill=customcolor, fill opacity=0.8, rounded corners, inner sep=1pt] at (0.93,0.75) {layer $2$};
    \end{scope}
    
    \begin{scope}[x={(image.south east)},y={(image.north west)}]
        \node[color=black, font=\fontsize{9}{9}\selectfont] at (0.93,0.455) {layer $3$};
    \end{scope}

    \begin{scope}[x={(image.south east)},y={(image.north west)}]
        \node[color=black] at (0.16,0.365) {runtime vs. size};
    \end{scope}

    \begin{scope}[x={(image.south east)},y={(image.north west)}]
        \node[color=black] at (0.4975,0.365) {runtime};
    \end{scope}

    \begin{scope}[x={(image.south east)},y={(image.north west)}]
        \node[color=black] at (0.835,0.359) {receptive field};
    \end{scope}

    \begin{scope}[x={(image.south east)},y={(image.north west)}]
        \node[color=black, font=\fontsize{3}{3}\selectfont] at (0.84,0.97) {MHSA};
    \end{scope}

    \begin{scope}[x={(image.south east)},y={(image.north west)}]
        \node[color=black, rotate=90, font=\fontsize{3}{3}\selectfont] at (0.704,0.458) {MHSA};
    \end{scope}

\end{tikzpicture}

\vspace{-1pt}
\caption{\textbf{Top:} Ball tree attention over a molecular graph. Multi-head self-attention (MHSA) is computed in parallel at fixed hierarchy levels (bold circles). In the following layers, the tree is progressively coarsened to learn global features, while the partition size is fixed. \textbf{Bottom:} Computational advantages of our model.}
\vspace{-3pt}
\end{figure}
