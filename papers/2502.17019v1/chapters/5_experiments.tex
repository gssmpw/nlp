\vspace{-10pt}
\section{Experiments}
\input{figures/results/scaling_and_rf}
Implementation details for all experiments are given in Appendix~\ref{appendix:experimental_detail}. The code is available at \texttt{anonymized link}. Extended experiments are given in Appendix~\ref{appendix:additional_experiments}, including an additional experiment on airflow pressure modelling.


\vspace{-5pt}
\paragraph{Computational cost}
To experimentally evaluate Erwin's scaling, we learn the power-law\footnote{We only use data for $n \geq 1024$ to exclude overhead costs.} form $\mathrm{Runtime} = C \cdot n^\beta$ by first applying the logarithm transform to both sides and then using the least square method to evaluate $\beta$. The result is an approximately linear scaling with $\beta = 1.054$ with $R^2 = 0.999$, see Fig.~\ref{fig:scaling_and_rf}, left. Ball tree construction accounts for only a fraction of the overall time, proving the efficiency of our method for linearizing attention for point clouds.

\vspace{-5pt}
\paragraph{Receptive field}
One of the theoretical properties of our model is that with sufficiently many layers, its receptive field is global. To verify this claim experimentally, for an arbitrary target node, we run the forward pass of Erwin and MPNN and compute gradients of the node output with respect to all input nodes' features. If the gradient is non-zero, the node is considered to be in the receptive field of the target node. The visualization is provided in Fig.~\ref{fig:scaling_and_rf}, right, where we compare the receptive field of our model with that of MPNN. As expected, the MPNN has a limited receptive field, as it cannot exceed $N$ hops, where $N$ is the number of message-passing layers. Conversely, Erwin implicitly computes all-to-all interactions, enabling it to capture long-range interactions in data.


\vspace{-5pt}
\subsection{Cosmological simulations}
\input{figures/results/glx_node_plot}
To demonstrate our model's ability to capture long-range interactions, we use the cosmology benchmark \cite{Balla2024ACB} which consists of large-scale point clouds representing potential galaxy distributions.

\vspace{-5pt}
\paragraph{Dataset}
The dataset is derived from N-body simulations that evolve dark matter particles from the early universe to the present time. After the simulation, gravitationally bound structures (halos) are indicated, from which the $5000$ heaviest ones are selected as potential galaxy locations. The halos form local clusters through gravity while maintaining long-range correlations that originated from interactions in the early universe before cosmic expansion, reflecting the initial conditions of simulations.

\vspace{-5pt}
\paragraph{Task}
The input is a point cloud $\mathbf{X} \in \mathbb{R}^{5000 \times 3}$, where each row corresponds to a galaxy and column to $x,y,z$ coordinate respectively. The task is a regression problem to predict the velocity of every galaxy $\mathbf{Y} \in \mathbb{R}^{5000 \times 3}$. We vary the size of the training dataset from $64$ to $8192$, while the validation and test datasets have a fixed size of $512$. The models are trained using mean squared error loss
\vspace{-2pt}
\begin{equation*}
    \mathcal{L} = \text{MSE}(\hat{Y}, Y)
\vspace{-2pt}
\end{equation*}
between predicted and ground truth velocities.

\vspace{-5pt}
\paragraph{Results}
The results are shown in Fig.~\ref{fig:glx_results}. We compare against multiple equivariant (NequIP \cite{Batzner2021E3equivariantGN}, SEGNN \cite{Brandstetter2021GeometricAP}) and non-equivariant (MPNN \cite{gilmer2017neuralmessagepassingquantum}, PointTransformer v3 \cite{Wu2023PointTV}) baselines. In the small data regime, graph-based equivariant models are preferable. However, as the training set size increases, their performance plateaus. We note that this is also the case for non-equivariant MPNN, suggesting that the issue might arise from failing to capture medium to large-scale interactions, where increased local expressivity of the model has minimal impact. Conversely, transformer-based models scale favorably with the training set size and eventually surpass graph-based models, highlighting their ability to capture both small and large-scale interactions. Our model demonstrates particularly strong performance and significantly outperforms other baselines for larger training set sizes. 


\vspace{-5pt}
\subsection{Molecular dynamics}
\input{figures/results/md_plot}
Molecular dynamics (MD) is essential for understanding physical and biological systems at the atomic level but remains computationally expensive even with neural network potentials due to all-atom force calculations and femtosecond timesteps required to maintain stability and accuracy. \citet{Fu2022SimulateTC} suggested accelerating MD simulation through coarse-grained dynamics with MPNN. In this experiment, we take a different approach and instead operate on the original representation but improve the runtime by employing our hardware-efficient model. Therefore, the question we ask is how much we can accelerate a simulation w.r.t. an MPNN without compromising the performance.

\vspace{-5pt}
\paragraph{Dataset}
The dataset consists of single-chain coarse-grained polymers \cite{Webb2020TargetedSD, Fu2022SimulateTC} simulated using MD. Each system includes 4 types of coarse-grained beads interacting through bond, angle, dihedral, and non-bonded potentials. The training set consists of polymers with the repeated pattern of the beads while the polymers in the test set are constructed by randomly sampling sequences of the beads thus introducing a challenging distribution shift. The training set contains $100$ short trajectories ($50k$ $\tau$), while the test set contains $40$ trajectories that are $100$ times longer. Each polymer chain contains approximately $890$ beads on average.

\vspace{-5pt}
\paragraph{Task}
We follow the experimental setup from \citet{Fu2022SimulateTC}. The model takes as input a polymer chain of $N$ coarse-grained beads. Each bead has a specific weight and is associated with the history $\{\dot{\mathbf{x}}_{t - 16\Delta t}, ..., \dot{\mathbf{x}}_{t - \Delta t} \}$ of (normalized) velocities from $16$ previous timesteps at intervals of $\Delta t = 5 \tau$. The model predicts the mean $\mathbf{\mu}_t \in \mathbb{R}^{N \times 3}$ and variance $\mathbf{\sigma}_t^2 \in \mathbb{R}_+^{N \times 3}$ of (normalized) acceleration for each bead, assuming a normal distribution. We train using negative log-likelihood loss
\vspace{-2pt}
\begin{equation*}
    \mathcal{L} = -\log \mathcal{N}(\hat{\ddot{\mathbf{x}}}_t|\mathbf{\mu}_t, \mathbf{\sigma}_t^2)
\vspace{-2pt}
\end{equation*}
between predicted and ground truth accelerations computed from the ground truth trajectories.

\input{tables/ablation_ball_size}
\input{tables/ablation_arch}

\vspace{-5pt}
\paragraph{Results}
The results are given in Fig.~\ref{fig:md_results}. As baselines, we use MPNN \cite{gilmer2017neuralmessagepassingquantum} as well as two hardware-efficient architectures: PointNet++ \cite{Qi2017PointNetDH} and PointTransformer v3 \cite{Wu2023PointTV}. Notably, model choice has minimal impact on performance, potentially due to the absence of long-range interactions as the CG beads do not carry any charge. Furthermore, it is sufficient to only learn local bonded interactions. There is, however, a considerable improvement in runtime for Erwin ($1.7-2.5$ times depending on the size), which is only matched by smaller MPNN or PointNet++, both having significantly higher test loss. 




\subsection{Turbulent fluid dynamics}
In the last experiment, we demonstrate the expressivity of our model by simulating turbulent fluid dynamics. The problem is notoriously challenging due to multiple factors: the inherently nonlinear behaviour of fluids, the multiscale and chaotic nature of turbulence, and the presence of long-range dependencies. Moreover, the geometry of the simulation domain and the presence of objects introduce complex boundary conditions thus adding another layer of complexity.

\vspace{-5pt}
\paragraph{Dataset}
We use EAGLE \cite{Janny2023EagleLL}, a large-scale benchmark of unsteady fluid dynamics. Each simulation includes a flow source (drone) that moves in 2D environments with different boundary geometries producing airflow. The time evolution of velocity and pressure fields is recorded along with dynamically adapting meshes. The dataset contains $600$ different geometries of $3$ types, with approximately $1.1$ million 2D meshes averaging $3388$ nodes each. The total dataset includes $1184$ simulations with $990$ time steps per simulation. The dataset is split with 80\% for training and 10\% each for validation and testing.

\vspace{-5pt}
\paragraph{Task}
We follow the original experimental setup of the benchmark. The input is the velocity $V \in \mathbb{R}^{N \times 2}$ and pressure $P \in \mathbb{R}^{N \times 2}$ fields evaluated at every node of the mesh in the time step $t$ along with the type of the node. The task is to predict the state of the system at the next time step $t+1$. The training is done by predicting a trajectory of states of length $5$ and optimizing the loss
\vspace{-5pt}
\begin{equation*}
\mathcal{L} = \sum_{i=1}^{5} \left( \text{MSE}(V_{t+i}, \hat{V}_{t+i}) + \alpha \;\text{MSE}(P_{t+i}, \hat{P}_{t+i}) \right),
\end{equation*}
where $\alpha = 0.1$ is the parameter that balances the importance of the pressure field over the velocity field.

\vspace{-5pt}
\paragraph{Results}
\input{figures/results/eagle_velocity}
For comparison, we include the baselines from the original benchmark: MeshGraphNet (MGN; \citeauthor{Pfaff2020LearningMS}, \citeyear{Pfaff2020LearningMS}), GAT \cite{Velickovic2017GraphAN}, DilResNet (DRN; \citeauthor{Stachenfeld2021LearnedCM}, \citeyear{Stachenfeld2021LearnedCM}) and EAGLE \cite{Janny2023EagleLL}\footnote{We additionally trained UPT \cite{alkin2024upt}, but were not able to obtain competitive results in our initial experiments.}. The first two baselines are based on message-passing, while DilResNet operates on regular grids hence employing interpolation for non-uniform meshes. EAGLE uses message-passing to pool the mesh to a coarser representation with a fixed number of clusters, on which attention is then computed. The quantitative results are given in Table~\ref{table:eagle} and unrolling trajectories are shown in Fig.~\ref{fig:eagle_velocity} and in Appendix~\ref{appendix:additional_experiments}. Erwin demonstrates strong results on the benchmark and outperforms every baseline, performing especially well at predicting pressure. In terms of inference time and memory consumption, Erwin achieves substantial gains over EAGLE, being $3$ times faster and using $8$ times less memory.
\input{tables/eagle_table}

\vspace{-5pt}
\subsection{Ablation study}

We also conducted an ablation study to examine the effect of increasing ball sizes on the model's performance in the cosmology experiment, see Table \ref{table:ablation_ball_size}. Given the presence of long-range interactions in the data, larger window sizes (and thus receptive fields) improve model performance, albeit at the cost of increased computational runtime. Our architectural ablation study on the MD task (Table \ref{table:ablation_arch}) reveals that using MPNN at the embedding step produces substantial improvements, likely due to its effectiveness in learning local interactions. 
