\input{tables/examples}

Reasoning about situations often involves weighing multiple pieces of information to draw inferences. 
%
Consider the last row in Table~\ref{table:atom-examples}. 
%
A human determining that $H$ contradicts $P$ will attribute the contradiction to the fact that $P$ mentions a father and daughter, but $H$ mentions two men.
%
Implicitly, they will have also weighed the fact that $H$'s mention of ``cutting grass'' is entailed by $P$'s mention of a lawnmower, and so it does not contribute to the contradiction.
%
We treat these two determinations as distinct \textit{atomic sub-problems}.


Hypotheses in \snli, and in turn, \dsnli, can be complex sentences, and while solving inference problems, models must weigh all pieces of information in both $P$ and $H$.
% 
We expect humans to make inferences about constituent pieces of information in a manner that is consistent with their overall judgment, an equally desirable property in models.
%
Not only does it signal holistic understanding of the situation described in the problem, but it can help pinpoint exactly what types of inferences models struggle with.
%
Identifying atomic sub-problems also allows us to understand the granular inferences that are evaluated in benchmark datasets.
%
In turn, this helps to understand the \textit{diversity} in the dataset: despite there being thousands of examples, certain inferences may come up repeatedly.

%
To identify the constituent sub-problems, we break \textit{hypotheses} in \snli~and \dsnli~into atomic propositions~\cite{wanner2024closer} to use in subsequent analyses. 
%
Each atomic decomposition represents a single piece of information.
%
Formally, given an \snli~example with $P$ and $H$, we generate atomic decompositions of $H$ represented by $a_1...a_n$. 
%
Each atomic sub-problem then involves predicting the relation between a ($P$, $a_i$) tuple (\S\ref{sec:snli-atoms:rules}).
%
Given a \dnli~example with $P$, $H$, and $U$, atomic sub-problems involve a ($P$, $a_i$, $U$) tuple where the task is to determine whether $U$ strengthens, weakens, or has no effect on $a_i$ (\S\ref{sec:dnli-atoms}).


\subsection{Generating Atomic Propositions}
\label{subsec:generate-atoms}
To generate atomic propositions, we draw on Neo-Davidsonian event-based semantic representations of sentences~\cite{castaneda1967, parsons1990events}.
%
Sentences can be represented in first-order logical form as conjunctions of predicates representing entities, where actions are explicitly represented with event variables and predicate arguments are mapped to semantic roles~\cite{dowty1991thematic}. 
%
For example, the sentence \textit{``The juggler performs at a party''} could be represented as: 
\[
\small
\begin{aligned}
    &\exists x_1 \exists e \ (\text{Juggler}(x_1) \land \text{Perform}(e) \land \text{Agent}(e, x_1) \land \\
    &\quad \exists x_2 \ (\text{Party}(x_2) \land \text{At}(e, x_2)))
\end{aligned}
\]

\noindent Each conjunct can then be mapped to a natural language expression, called an \textit{atom}.
%
This ensures that both arguments of actions \textit{and} the actions themselves are included as separate atoms.

We draw on this intuition to carefully hand-construct exemplars, a methodology shown to improve the atomicity and groundedness of decompositions~\cite{wanner2024closer}.
%
We prompt \texttt{llama-3-8b-instruct} with these exemplars (Appendix~\ref{appendix:atom-generation}) to generate atoms for each example in the \dsnli~test set (henceforth, \dsnlitest),  as well as for 1000 randomly sampled examples in the SNLI test set (\snlitest). See Table~\ref{tab:dataset-sizes} for dataset statistics.

\subsection{Validating Atomic Decompositions}
\label{subsec:validate-atoms}
Valid atomic decompositions of hypotheses must be logically entailed from the hypothesis they were decomposed from.
%
For our experiments on \snlitest~(\S\ref{sec:snli-atoms}), we do not validate atom entailment ourselves, letting each model determine whether $H$ entails each $a_i$ itself (\S\ref{sec:snli-atoms:rules}), and only measuring consistency on the atomic sub-problems that the model itself admits as ``valid''.
%

However, we \textit{do} validate all generated atoms in \dsnlitest, since non-monotonic reasoning does not give rise to clear constraints between an original problem and its constituent atomic sub-problems.
%
Our two-step validation process involves pruning decompositions with a strong, finetuned NLI model followed by human validation.

\paragraph{Pruning.} For each example in \dsnlitest, we use a \abr{DeBERTa}-large model finetuned on popular NLI datasets\footnote{MNLI~\cite{williams-etal-2018-broad}, Fever-NLI~\cite{thorne-etal-2018-fever}, Adversarial NLI~\cite{nie-etal-2020-adversarial}, LingNLI~\cite{parrish-etal-2021-putting-linguist}, and WANLI~\cite{liu-etal-2022-wanli}} and remove all generated atoms that are not entailed by the hypothesis.
%
By design, $P$-$H$ pairs in \dsnli~have a neutral relation, and updates strengthen or weaken propositions in the \textit{hypothesis}.
%
Hence, we run a secondary pruning stage to retain only those atoms that are \textit{not} entailed by the premise (see Table~\ref{tab:dataset-sizes}).
%
See Appendix~\ref{appendix:atom-generation} for a discussion of coverage.
%
\paragraph{Human Validation.} An author annotated all atoms that survived pruning as either \textit{invalid} or \textit{valid} (see Table~\ref{table:atom-examples} for examples of invalid atoms).
%
Valid \dsnli~atoms had to (1) be grammatical, (2) entail from $H$, (3) not entail from $P$.
%
Atoms introducing new information were considered invalid, including those that were \textit{pragmatic} inferences of $H$~\cite{jeretic-etal-2020-natural, srikanth-etal-2024-pregnant}.
%

95.7\% of pruned atoms were determined as valid by the author annotator.
%
An external annotator also annotated a sample of 100 atoms for validity for an agreement of $\kappa=0.82$ measured by Cohen's Kappa~\cite{cohen1960coefficient}.
%
The remaining analysis in this work is done on the set of \textit{valid} \dsnli~atoms.