Atomic decomposition involves breaking sentences down into \textit{atomic propositions}, or granular facts that are explicitly supported by the original text.
%
This style of decomposition has widespread applications, including assessing the factual precision of generated text~\cite{min-etal-2023-factscore}, claim verification~\cite{chen-etal-2024-complex}, and multihop QA~\cite{perez-etal-2020-unsupervised}, since it allows for careful, finer-grained inspection of text.

We use atomic decomposition as tool to dive deeper into two types of natural language reasoning: traditional NLI~\cite{giampiccolo2007third} and defeasible inference~\cite{rudinger-etal-2020-thinking}, a mode of reasoning where inferences may change in light of new evidence.
%
In both tasks, atomic decomposition of hypotheses into \textit{atoms} breaks complex sentences into granular pieces of information that models must weigh when drawing higher level inferences, producing \textit{atomic sub-problems}.
%
We use these sub-problems not only for better insight into the structure and nuances of NLI and defeasible NLI, but also to assess accompanying benchmarks and to more deeply probe the robustness of models' situational understanding.\footnote{Code and data available at \url{https://github.com/nehasrikn/nli-atoms}.}
%

\begin{figure}[t!]
\centering
\includegraphics[scale=0.715]{figures/teaser_with_dnli_snli.pdf}
\caption{Top: Atomic hypothesis decomposition breaks down hypotheses ($H$) into  entailed propositional ``atoms'' ($a_1-a_3$). Middle: Pairing the premise ($P$) with each atom yields a set of NLI sub-problems ($P+a$); the sub-problem labels predict the full NLI problem ($P+H$) label. Bottom: Paired with an update ($U$), each atom yields a defeasible NLI sub-problem ($P+a+U$); the set of sub-problem labels are predictive of the full problem ($P+H+U$) label, but the non-monotonic relationship is more complex than for traditional NLI.}
\label{fig:teaser-example}
\end{figure}


Consider the example in Figure~\ref{fig:teaser-example} of a premise and hypothesis with a neutral relationship. 
%
When predicting an overall neutral relation, a model must determine the relation between the premise and each of the three atomic propositions that together form the hypothesis --- in this case, all of which are neutral.
%
If the model predicts an entailment or a contradiction between the premise and one of the atoms, its understanding of the situation may be called into question.

We first present our two tasks of interest (\S\ref{sec:task-background}) and discuss the utility of atomic sub-problems and their construction (\S\ref{sec:atom-generation}).
%
Then, we analyze the behavior of large language models (LLMs) on atomic sub-problems in traditional NLI (\S\ref{sec:snli-atoms}) where we evaluate their logical consistency between each original \snli~instance and its corresponding sub-problems.
%
We find that despite high accuracy, LLMs still struggle with logical consistency.
%
Then, we study atomic sub-problems in defeasible NLI (\S\ref{sec:dnli-atoms}) and propose a framework to pinpoint the inference(s) evaluated in each example by way of the \textit{question under discussion} of examples, a well-studied linguistic phenomenon~\cite{benz2017questions, wu-etal-2023-qudeval}.
%
Finally, we present a method to group defeasible NLI examples based on related atomic sub-problems (\S\ref{sec:diversity}) and measure the \textit{inferential consistency} of a model, a metric capturing the likelihood that its prediction for a particular inference will remain \textbf{consistently} correct or incorrect under different contexts.