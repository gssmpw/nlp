We now turn to defeasible inference to explore how atomic sub-problems can help us better understand the complexities of the task, model performance, and the knowledge evaluated in the \dsnli~dataset.

\begin{figure*}[t!]
\centering
\includegraphics[width=\textwidth]{figures/label_distributions.pdf}
\caption{A rug plot visualization of 1,761 \dsnli~instances and their corresponding distribution of atomic sub-problem labels. Each vertical slice represents one full \dsnli~instance. Slice color (red or green) represents the full instance label (weakener or strengthener). For each \dsnli~problem, we manually label each corresponding atomic sub-problem on a -2 (strongly weakens) to +2 (strongly strengthens) scale. Each vertical slice uses shading (light/dark) to represent the resulting distribution of atomic sub-problem labels (-2 to +2). Slices are ordered left to right by proportion of weakener labels, showing relatively high separation between red and green instances. When atomic sub-problems contain a mix of positive and negative labels, the full problem label may be a strengthener or a weakener, as illustrated by the two center-most exemplars.}


\label{fig:label-distribution}
\end{figure*}

In traditional NLI (\S\ref{sec:snli-atoms}), labels of atomic sub-problems function like terms in an equation---the overall relation between $P$ and $H$ can be computed from strict logical rules over relations between $P$ and individual $a_i$.
%
In contrast, defeasible inference functions akin to fuzzy logic~\cite{castro1998non}.
%
Determining the overall effect of the update $U$ on $H$ involves a softer weighing of the direction and magnitude of its effect on each atom.
%

For example, consider the second row in Table~\ref{table:atom-examples}. 
%
A human reading the update $U$ (\textit{``The person is wearing a city uniform''}) would conclude that $U$ \textit{strengthens} their belief in $H$ (\textit{``The garbage man sweeps up where the can spilled''}) as opposed to weakens it.
%
Looking at this problem through the lens of atomic decomposition helps pinpoint why.
%
$H$ consists of five atoms, each representing pieces of evidence \textit{not} present in $P$ ripe for targeting by updates.
%
Two of the five atoms are most strongly supported by $U$: the person is wearing a city uniform strongly strengthens our belief that they may be a garbage man ($a_1$) as well as that they may be sweeping up a spill ($a_5$). 
%
However, $U$ has no effect on our belief that there is a can in the scenario ($a_3$).
%
The co-occurrence of $a_1$ and $a_5$ compound the strengthening effect, leading to an overall strengthening effect of $U$ on $H$.


Breaking down \dsnli~hypotheses and forming atomic sub-problems in this manner gives us a framework to understand the intricacies of defeasible inference.
%
We begin by benchmarking recent LLMs to understand the state of defeasible inference capabilities of models.
%
Then, we introduce the idea of a \textit{critical atom}, or the primary piece of information an update acts on.
%
Finally, we use critical atoms as a way to better understand and interpret model behavior, as well as argue that critical atoms serve as a useful representation for measuring the type of knowledge evaluated in \dsnli.

\subsection{Understanding Defeasible Inference with Atomic Sub-Problems}

\paragraph{Benchmarking LLMs on \dnli.} We benchmark a suite of recent models on full examples from \dsnlitest, including encoder models and prompt-based models, open-source and proprietary systems, as well as models of various sizes. 
%
We finetune encoder-only models (\texttt{roberta-large} and \texttt{deberta-v3-large}) on the train set of \dsnli~for 2 epochs with a learning rate of 2e-5 and a batch size of 32.
%
For all prompt-based models, we do few-shot evaluation with Prompt~\ref{prompt:defeasible} and 10 in-context examples evenly split between strengtheners and weakeners.

Many of the models in our suite surpass the human performance benchmarked by~\citet{rudinger-etal-2020-thinking}, with \texttt{gpt-4o} as the top performing model at 92\% accuracy (Table~\ref{tab:benchmarking-dnli}).
%
However, since it remains unclear whether this accuracy is indicative of a holistic understanding of situations in \dsnli, we turn to studying performance on the atomic reasoning problems that compose each \dsnli~example to better contextualize these results.
%
\paragraph{Annotating Atoms.} Each atomic sub-problem in \dsnli~is $(P, a_i, U)$ tuple capturing the effect of the update on a specific atom $a_i$. 
%
An author annotated all valid (as determined in \S\ref{subsec:validate-atoms}) atomic sub-problems for each example in \dsnlitest~according to the five-point scale used in~\citet{rudinger-etal-2020-thinking} for validation (Table~\ref{tab:dataset-sizes}) ranging from \textit{strongly weakens} (-2) to \textit{strongly strengthens} (+2)  with a midpoint value of \textit{no effect} (0) for atoms on which $U$ had no effect. 
%
The same external annotator from \S\ref{subsec:validate-atoms} annotated a random sample of 100 \textit{valid} atomic sub-problems on the same -2 to +2 scale (Appendix~\ref{appendix:instructions}), obtaining an agreement of $\tau=0.79$ with Kendall's Tau~\cite{kendall1938new}.
\input{tables/benchmarking_dnli}
\paragraph{Ground Truth Label Distribution.} Figure~\ref{fig:label-distribution} visualizes the label distribution ($-2$ to $+2$) of atomic sub-problems of each \dsnlitest~example as a thin vertical strip. Strips are green if the original example is a strengthener and red for weakeners.
%
While some examples have all atomic labels of the \textit{same} polarity, \textbf{a significant chunk of the dataset includes atomic sub-problems with no effect or the \textit{opposite} polarity}.
%
Examples depicted across the spectrum in Figure~\ref{fig:label-distribution} illustrate the non-monotonicity of defeasible inference. % \textit{within the same example}. 

\paragraph{Atomic Sub-Problem Performance.} 
We first measure the performance of models on atomic sub-problems using annotated ground-truth labels.
%
The original \dsnli~dataset was designed as a binary prediction task. 
%
However, as Figure~\ref{fig:label-distribution} depicts, updates may also have no effect on atoms.
%
We adapt Prompt~\ref{prompt:defeasible} to accommodate this ternary task (Prompt~\ref{prompt:defeasible-atom}) and use atoms in exemplars instead of full hypotheses.
%including four more in-context examples for the ``no effect'' class and using
%
Since the train set of \dnli~only admits binary labels, we reuse the finetuned models (\texttt{deberta} and \texttt{roberta}), and report atom accuracy on non-neutral atoms (80\% of atoms, Figure~\ref{fig:atom-label-hist}). 

Across the board, models perform worse on atomic sub-problems than on full examples (Table \ref{tab:benchmarking-dnli}, Column 2).
%
Since updates often act on multiple parts $U$ (Table~\ref{table:atom-examples}), we hypothesize that this compounding effect may contribute to higher performances on full examples.
%

We observe that some atomic sub-problems are more critical contributors to the overall effect of $U$ on $H$.
%
Consider the example in row 2 of Table~\ref{table:atom-examples}.
%
Since $U$ acts most strongly on $a_1$ and $a_5$, \textbf{we can assume that they are critical in determining the overall effect of $U$ on $H$}, and correctly understanding the effect of $U$ on $a_3$ or $a_4$ is not essential to the overall problem.
%
We formalize this below.

\subsection{Critical Atoms as Questions Under Discussion (QUD)}
\label{subsec:quds}

As established, updates vary in which atom they most strongly affect.
%
Consider $H$ and the three updates in Figure~\ref{fig:qud-examples}.
%
Each $U$ targets a distinct (or \textit{critical}) atom without having an effect on the others.
%
We formalize this notion by recognizing that hypotheses (or more broadly, sentences in discourse) serve as an answer to a large space of possible questions: all three questions in the right-most column could be answered with $H$.
%
However, when updates target particular atoms, the \textit{strategy} by which they do so favors a particular question $Q$, making it more likely that $H$ is the answer to $Q$ as opposed to any other question.


\begin{figure}[h!]
\centering
\includegraphics[scale=0.7]{figures/qud.pdf}
\caption{Updates ($U$) may act on the same hypothesis $H$ in different ways by targeting different atoms. Here, each $U$ strongly targets a different atom, while having no effect on the other atoms derived from $H$ (e.g. the $U$ in the first row has no effect on $a_3$ in the last row). We refer to the atom(s) which an update most strongly affects as the ``critical'' atom of the $(P, H, U)$ \dnli~example. Critical atoms help identify the \textit{question under discussion} of the example.}
\label{fig:qud-examples}
\end{figure}

\noindent These questions function as \textit{questions under discussion} (QUD), a well-studied linguistic phenomenon~\cite{benz2017questions}. 
%
The update \textit{``The man smiles on his boat''} has no effect on the atom about vest color and hence does not pick out the QUD associated with that atom.
%
We call the atoms above the \textit{critical atom} for each corresponding update, as they uniquely pick out particular QUDs over others.
%
\textbf{Critical atoms correspond to the particular inference or piece of knowledge a defeasible NLI example aims to test.}
%
As such, we use them as a framework to measure consistency as well as the diversity of the \dsnli~dataset.
%
This formulation of QUDs relates to question answering-based semantics~\cite{he-etal-2015-question, pyatkin-etal-2021-asking, klein-etal-2022-qasem} in which QA pairs capture semantic information, such as semantic roles.

\paragraph{Identifying Critical Atoms of Updates.} In order to identify the critical atom for a defeasible NLI example, we identify the subset of its \textit{valid} atoms with the strongest labels that match its overall polarity.
%
The majority of \dsnlitest~examples have one critical atom (Figure~\ref{fig:num-atoms}), but it is possible for example to have multiple if the effect is equally strong, as in row 2 of Table~\ref{table:atom-examples}.

\paragraph{Performance on Critical Atomic Sub-Problems versus Full Examples.}
Across the board, models are stronger on the subset of critical atomic sub-problems than on all atomic problems (Table~\ref{tab:benchmarking-dnli}). 
%
We hypothesize that LLMs may be better at modeling stronger, \textbf{direct} inferences such as those in critical sub-problems, but may struggle when the effects are \textit{indirect} or weaker.\footnote{For example, $U$ in Row 2 of Table~\ref{table:atom-examples} has no effect on $a_3$, but that effect is slightly strengthened upon mention of a spill in $a_4$, since donning a city uniform is likelier at spill sites.}
%
%
Such nuanced distinctions require a robust understanding of the multiple factors that control the underlying inference, a skill that even larger models seem to struggle with.

We also measure the probability that a model correctly predicts the label for the full example \textit{given} that it has correctly (Column 4) and incorrectly (Column 5) solved all critical atomic sub-problems (Table~\ref{tab:benchmarking-dnli}).
%
Correctly solving all atomic sub-problems is a strong indicator that a model is likely to predict the full problem correctly.
%
However, some models still have as high as a 75\% probability of predicting the full answer even having incorrectly predicted critical sub-problems, calling into question the robustness of their reasoning process in the face of such inconsistency.
