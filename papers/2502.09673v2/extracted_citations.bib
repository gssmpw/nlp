@inproceedings{10.1609/aaai.v38i16.29776,
author = {He, Liqi and Li, Zuchao and Cai, Xiantao and Wang, Ping},
title = {Multi-modal latent space learning for chain-of-thought reasoning in language models},
year = {2025},
booktitle = {AAAI},
}

@article{Chua2024BiasAugmentedCT,
  title={Bias-Augmented Consistency Training Reduces Biased Reasoning in Chain-of-Thought},
  author={James Chua and Edward Rees and Hunar Batra and Samuel R. Bowman and Julian Michael and Ethan Perez and Miles Turpin},
  journal={arXiv},
  year={2024}
}

@inproceedings{Ethics-Reasoning,
    title = "Rethinking Machine Ethics {--} Can {LLM}s Perform Moral Reasoning through the Lens of Moral Theories?",
    author = "Zhou, Jingyan  and
      Hu, Minda  and
      Li, Junan  and
      Zhang, Xiaoying  and
      Wu, Xixin  and
      King, Irwin  and
      Meng, Helen",
    booktitle = "ACL",
    year = "2024",
}

@inproceedings{Persona-Reasoning,
title={Bias Runs Deep: Implicit Reasoning Biases in Persona-Assigned {LLM}s},
author={Shashank Gupta and Vaishnavi Shrivastava and Ameet Deshpande and Ashwin Kalyan and Peter Clark and Ashish Sabharwal and Tushar Khot},
booktitle={ICLR},
year={2024},
}

@article{Radhakrishnan2023QuestionDI,
  title={Question Decomposition Improves the Faithfulness of Model-Generated Reasoning},
  author={Ansh Radhakrishnan and Karina Nguyen and Anna Chen and Carol Chen and Carson E. Denison and Danny Hernandez and Esin Durmus and Evan Hubinger and John Kernion and Kamil.e Lukovsiut.e and Newton Cheng and Nicholas Joseph and Nicholas Schiefer and Oliver Rausch and Sam McCandlish and Sheer El Showk and Tamera Lanham and Tim Maxwell and Venkat Chandrasekaran and Zac Hatfield-Dodds and Jared Kaplan and Janina Brauner and Sam Bowman and Ethan Perez},
  journal={arXiv},
  year={2023}
}

@article{Self-correct-reasoning,
  title={Large Language Models Cannot Self-Correct Reasoning Yet},
  author={Jie Huang and Xinyun Chen and Swaroop Mishra and Huaixiu Steven Zheng and Adams Wei Yu and Xinying Song and Denny Zhou},
  journal={arXiv},
  year={2023},
}

@inproceedings{han-etal-2024-context,
    title = "In-Context Learning May Not Elicit Trustworthy Reasoning: A-Not-{B} Errors in Pretrained Language Models",
    author = "Han, Pengrui  and
      Song, Peiyang  and
      Yu, Haofei  and
      You, Jiaxuan",
    booktitle = "EMNLP",
    year = "2024"
}

@article{jaech2024openai,
  title={Openai o1 system card},
  author={Jaech, Aaron and Kalai, Adam and Lerer, Adam and Richardson, Adam and El-Kishky, Ahmed and Low, Aiden and Helyar, Alec and Madry, Aleksander and Beutel, Alex and Carney, Alex and others},
  journal={arXiv},
  year={2024}
}

@inproceedings{kojima2022large,
 author = {Takeshi Kojima and Shixiang Shane Gu and Machel Reid and Yutaka Matsuo and Yusuke Iwasawa},
 booktitle = {NeurIPS},
 title = {Large Language Models are Zero-Shot Reasoners},
 year = {2022}
}

@inproceedings{li-etal-2024-deceptive,
    title = "Deceptive Semantic Shortcuts on Reasoning Chains: How Far Can Models Go without Hallucination?",
    author = "Li, Bangzheng  and
      Zhou, Ben  and
      Wang, Fei  and
      Fu, Xingyu  and
      Roth, Dan  and
      Chen, Muhao",
    booktitle = "NAACL",
    year = "2024",
}

@article{liu2023retrieval,
  title={Retrieval-augmented multi-modal chain-of-thoughts reasoning for large language models},
  author={Liu, Bingshuai and Lyu, Chenyang and Min, Zijun and Wang, Zhanyu and Su, Jinsong and Wang, Longyue},
  journal={arXiv},
  year={2023}
}

@article{lohman2011intelligence,
  title={Intelligence and reasoning},
  author={Lohman, David F and Lakin, Joni M},
  journal={The Cambridge handbook of intelligence},
  year={2011},
  publisher={Cambridge University Press New York, NY}
}

@inproceedings{lu2022learn,
 author = {Pan Lu and Swaroop Mishra and Tony Xia and Liang Qiu and Kai-Wei Chang and Song-Chun Zhu and Oyvind Tafjord and Peter Clark and Ashwin Kalyan},
 booktitle = {NeurIPS},
 title = {Learn to Explain: Multimodal Reasoning via Thought Chains for Science Question Answering},
 year = {2022}
}

@inproceedings{multimodel-reasoning,
title={Stop Reasoning! When Multimodal {LLM} with Chain-of-Thought Reasoning Meets Adversarial Image},
author={Zefeng Wang and Zhen Han and Shuo Chen and Fan Xue and Zifeng Ding and Xun Xiao and Volker Tresp and Philip Torr and Jindong Gu},
booktitle={COLM},
year={2024}
}

@inproceedings{not-think,
    title = "On Second Thought, Let`s Not Think Step by Step! Bias and Toxicity in Zero-Shot Reasoning",
    author = "Shaikh, Omar  and
      Zhang, Hongxin  and
      Held, William  and
      Bernstein, Michael  and
      Yang, Diyi",
    booktitle = {ACL},
    year = {2023}
}

@inproceedings{paul-etal-2024-making,
    title = "Making Reasoning Matter: Measuring and Improving Faithfulness of Chain-of-Thought Reasoning",
    author = "Paul, Debjit  and
      West, Robert  and
      Bosselut, Antoine  and
      Faltings, Boi",
    booktitle = "EMNLP",
    year = "2024"
}

@article{shum2023automatic,
  title={Automatic prompt augmentation and selection with chain-of-thought from labeled data},
  author={Shum, KaShun and Diao, Shizhe and Zhang, Tong},
  journal={arXiv},
  year={2023}
}

@misc{steenhoek2025errmachinevulnerabilitydetection,
      title={To Err is Machine: Vulnerability Detection Challenges LLM Reasoning}, 
      author={Benjamin Steenhoek and Md Mahbubur Rahman and Monoshi Kumar Roy and Mirza Sanjida Alam and Hengbo Tong and Swarna Das and Earl T. Barr and Wei Le},
      year={2025},
      archivePrefix={arXiv}
}

@article{wang2024drt,
  title={DRT-o1: Optimized Deep Reasoning Translation via Long Chain-of-Thought},
  author={Wang, Jiaan and Meng, Fandong and Liang, Yunlong and Zhou, Jie},
  journal={arXiv},
  year={2024}
}

@article{wang2024openr,
  title={Openr: An open source framework for advanced reasoning with large language models},
  author={Wang, Jun and Fang, Meng and Wan, Ziyu and Wen, Muning and Zhu, Jiachen and Liu, Anjie and Gong, Ziqin and Song, Yan and Chen, Lei and Ni, Lionel M and others},
  journal={arXiv},
  year={2024}
}

@inproceedings{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  booktitle={NeurIPS},
  year={2022}
}

@article{yang2024qwen25mathtechnicalreportmathematical,
  title={Qwen2.5-Math Technical Report: Toward Mathematical Expert Model via Self-Improvement}, 
  author={An Yang and Beichen Zhang and Binyuan Hui and Bofei Gao and Bowen Yu and Chengpeng Li and Dayiheng Liu and Jianhong Tu and Jingren Zhou and Junyang Lin and Keming Lu and Mingfeng Xue and Runji Lin and Tianyu Liu and Xingzhang Ren and Zhenru Zhang},
  journal={arXiv},
  year={2024}
}

@article{zhang2022automatic,
 author = {Zhang, Zhuosheng and Zhang, Aston and Li, Mu and Smola, Alex},
 journal = {arXiv},
 title = {Automatic Chain of Thought Prompting in Large Language Models},
 year = {2022}
}

@article{zhao2023verify,
  title={Verify-and-edit: A knowledge-enhanced chain-of-thought framework},
  author={Zhao, Ruochen and Li, Xingxuan and Joty, Shafiq and Qin, Chengwei and Bing, Lidong},
  journal={arXiv},
  year={2023}
}

@article{zhao2024marco,
  title={Marco-o1: Towards open reasoning models for open-ended solutions},
  author={Zhao, Yu and Yin, Huifeng and Zeng, Bo and Wang, Hao and Shi, Tianqi and Lyu, Chenyang and Wang, Longyue and Luo, Weihua and Zhang, Kaifu},
  journal={arXiv},
  year={2024}
}

