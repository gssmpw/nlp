\section{Related Work}
\label{sec::related_work}
\textbf{Reasoning for LLM: } Since a large part of human intelligence is attributed to reasoning capacity____, reasoning like humans has become a hot research topic in the studies of LLMs, including the prompt-based and fine-tuning-based methods. Prompt-based methods improve the reasoning capability at the inference stage and one of the most representative ones is the chain-of-thought (CoT) method. As proposed in____, they firstly elucidate that better reasoning capacities will emerge once a few chain of thought demonstrations are provided. Following variants reveal that it can be further enhanced with zero-shot prompting____, prompt augmentation____ or external knowledge____. In contrast, fine-tuning-based methods train the LLM parameters to improve reasoning. Owe to the success of o1 family models____, their power is well recognized by recent works. For example, by fine-tuning on CoT data, we will see the performance of Marco-o1____ in math improves in a novel margin (+6.17\%). The significance of it is also demonstrated by other reasoning-enhanced models, \textit{e.g.} OpenR____, Qwen2.5-Math____ and DRT-o1____, making it a sharping tool for reasoning enhancement.

\noindent\textbf{Trustworthiness of LLM reasoning: }The trustworthiness of LLM reasoning has been evaluated from various perspectives. ____ have measured the faithfulness of LLM reaasoning. The focus of the evaluation by ____ is the robustness of reasoning. There also have been assessments studying the influence of reasoning on the toxicity ____, social bias ____ and machine ethics ____ of LLMs. For reasoning in the Multi-modal LLMs (MLLMs) ____, ____ have noticed the improvement in resilience of the models against image adversarial examples brought by \textit{step-by-step} reasoning and designed an adaptive attack accordingly. Except for the various aspects of trustworthiness mentioned above, it is still unclear how safety will change as we increase the reasoning ability of LLMs, which is of paramount concern given the rapid evolvement of methods to enhanced LLM reasoning and the potential risks brought by the consequent models.