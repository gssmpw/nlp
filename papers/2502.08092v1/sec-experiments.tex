\section{Experiments}
In this section, we conduct experiments to evaluate \model, and analyze the empirical results.

\begin{table}[tbp]
\center
\small
\addtolength{\tabcolsep}{-1mm}
\caption{Summary of datasets. 
\label{table.datasets}}
\resizebox{1\columnwidth}{!}{%
\begin{tabular}{@{}c|rrrrrrr@{}}
\toprule
    Datasets & \makecell[c]{Graphs} & \makecell[c]{Graph \\ classes} & \makecell[c]{Avg.\\ nodes} & \makecell[c]{Avg. \\ edges} & \makecell[c]{Node \\ features} & \makecell[c]{Node \\ classes} & \makecell[c]{Task$^*$ \\ (N/G)}\\
\midrule
     Cora & 1 & - & 2,708 & 5,429 & 1,433 & 7 & N\\ 
     Citeseer & 1 & - & 3,327 & 4,732 & 3,703 & 6 & N\\ 
     Pubmed & 1 & - & 19717 & 88648 & 500 & 3 & N\\
     Photo & 1 & - & 7650 & 238162 & 745 & 8 & N\\
     MUTAG & 188 & 2 & 17.9 & 18.9 & 7 & - & G\\
     COX2 & 467 & 2 & 41.2 & 43.5 & 3 & - & G\\
     BZR & 405 & 2 & 35.8 & 38.4 & 3 & - & G\\
     PROTEINS & 1,113 & 2 & 39.1 & 72.8 & 4 & 3 & G\\
 \bottomrule
\end{tabular}}
\parbox{1\columnwidth}{\raggedright \footnotesize \( ^* \) indicates the downstream task category for each dataset: "N" corresponds to node classification, while "G" signifies graph classification.}
\end{table}

\begin{table*}[tbp] % [!t]
    \centering
    \small
     \addtolength{\tabcolsep}{1mm}
    \caption{Accuracy (\%) evaluation on node and graph classification.
    }
    \label{table.node-graph-classification}%
    \resizebox{1\linewidth}{!}{%
    \begin{tabular}{@{}l|cccc|cccc@{}}
    \toprule
  \multirow{2}*{Methods} & \multicolumn{4}{c|}{Node classification} & \multicolumn{4}{c}{Graph classification} \\ 
  & Cora  & Citeseer & Pubmed & Photo & MUTAG & COX2 & BZR & PROTEINS \\\midrule\midrule
    \method{GCN} & 32.50\text{\scriptsize ±14.21}  & 26.36\text{\scriptsize ±9.03}  & 52.18\text{\scriptsize ±8.70}  & 60.18\text{\scriptsize ±12.04}
    &  43.44\text{\scriptsize ±15.14}  & 50.95\text{\scriptsize ±23.48}  & 47.25\text{\scriptsize ±16.59 } & 40.28\text{\scriptsize ±0.03} \\
    \method{GAT} & 31.00\text{\scriptsize ±16.22}  & 27.71\text{\scriptsize ±8.74}  & 50.02\text{\scriptsize ±8.88}  & 51.79\text{\scriptsize ±12.85 }
    &  37.33\text{\scriptsize ±10.81}  & 50.58\text{\scriptsize ±26.16}  & 46.55\text{\scriptsize ±16.57}  & 40.39\text{\scriptsize ±0.04}\\
    \midrule
    \method{DGI/InfoGraph} & 54.11\text{\scriptsize ±9.60}  & 45.00\text{\scriptsize ±9.19}  & 57.98\text{\scriptsize ±11.36}  & 64.48\text{\scriptsize ±10.04} 
    &  53.17\text{\scriptsize ±17.29 } & 53.82\text{\scriptsize ±14.19}  & 49.33\text{\scriptsize ±15.11}  & 52.51\text{\scriptsize ±10.29}\\
    \method{GraphCL} & 51.96\text{\scriptsize ±9.43}  & 43.12\text{\scriptsize ±9.61}  & 61.18\text{\scriptsize ±11.60}  & 63.93\text{\scriptsize ±10.21 }
    &  54.92\text{\scriptsize ±17.09}  & 53.81\text{\scriptsize ±14.21}  & 49.73\text{\scriptsize ±14.66}  & 53.81\text{\scriptsize ±8.97}\\
    \midrule
    \method{ProG} & 51.35\text{\scriptsize ±13.92} & 35.08\text{\scriptsize ±8.63}  & 64.07\text{\scriptsize ±14.74}  & 68.85\text{\scriptsize ±9.99 }
    & 51.99\text{\scriptsize ±4.50 } & 53.45\text{\scriptsize ±15.01}  & 53.52\text{\scriptsize ±11.97}  & 52.73\text{\scriptsize ±6.57}\\
    \method{GPF} & 57.35\text{\scriptsize ±13.87}  & 43.04\text{\scriptsize ±8.85}  & 57.61\text{\scriptsize ±11.26}  & 65.26\text{\scriptsize ±9.89 }
    &  56.55\text{\scriptsize ±13.95}  & 54.16\text{\scriptsize ±14.07}  & 48.65\text{\scriptsize ±13.96} & 53.05\text{\scriptsize ±7.62}\\
    \method{GPF+} & \underline{64.91}\text{\scriptsize ±15.49}  & 42.28\text{\scriptsize ±8.71}  & 57.85\text{\scriptsize ±10.86}  & \underline{69.80}\text{\scriptsize ±10.84}
    &  \underline{56.81}\text{\scriptsize ±12.93}  & \underline{55.24}\text{\scriptsize ±13.29}  & 50.83\text{\scriptsize ±19.74} & \underline{54.58}\text{\scriptsize ±8.70} \\
    \method{GraphPrompt} & 54.56\text{\scriptsize ±12.56}  & \underline{46.23}\text{\scriptsize ±8.70} & \underline{64.85}\text{\scriptsize ±10.72}  & 68.99\text{\scriptsize ±9.28 }
    &  55.44\text{\scriptsize ±12.56}  & 54.34\text{\scriptsize ±14.77}  & \underline{54.59}\text{\scriptsize ±10.52}  & 53.80\text{\scriptsize ±7.93}\\
    \midrule
    \model & \textbf{66.09}\text{\scriptsize ±15.17}  & \textbf{47.77}\text{\scriptsize ±10.93}  & \textbf{70.57}\text{\scriptsize ±17.10}  & \textbf{77.51}\text{\scriptsize ±11.76} 
    & \textbf{58.75}\text{\scriptsize ±15.42}  & \textbf{56.26}\text{\scriptsize ±15.52}  & \textbf{58.03}\text{\scriptsize ±23.44}  & \textbf{56.24}\text{\scriptsize ±8.60}\\
    \bottomrule
        \end{tabular}}
       \parbox{1\linewidth}{\footnotesize Best results are \textbf{bolded} and runner-up results are \underline{underlined}.}
\end{table*}


\subsection{Experimental Setup}
\stitle{Datasets.}
We conduct experiments on eight widely used benchmark datasets, spanning citation networks, e-commerce, protein structures, and molecular graphs.
\textit{Cora} \cite{mccallum2000automating}, \textit{Citeseer} \cite{sen2008collective}, and \textit{Pubmed} \cite{sen2008collective} are citation networks, each consisting of a single graph. In these datasets, nodes represent academic papers and edges denote citation relationships between them.
\textit{Photo} \cite{shchur2018pitfalls} is an e-commerce co-purchase network derived from Amazon's photography-related product category, where nodes correspond to products and edges indicate frequently co-purchased items.
\textit{PROTEINS} \cite{borgwardt2005protein} is a dataset of protein structures. In each graph, nodes correspond to secondary structures, and edges capture spatial or sequential relationships within the amino acid sequence.
\textit{MUTAG} \cite{nr}, \textit{BZR} \cite{nr}, and \textit{COX2} \cite{nr} are molecular graph datasets, representing nitroaromatic compounds, ligands associated with benzodiazepine receptors, and \textit{COX2} contains molecular structures related to cyclooxygenase-2 inhibitors, respectively.
A detailed summary of these datasets is presented in Table~\ref{table.datasets}, with further descriptions in Appendix~\ref{app.dataset}.

\stitle{Baselines.}
We compare \model\ with state-of-the-art methods across three categories:
(1) \emph{Supervised GNNs}: GCN \cite{kipf2016semi} and GAT \cite{velivckovic2017graph} are trained directly on downstream labels in a fully supervised manner, without any pre-training.
(2) \emph{Graph pre-training models}: DGI/InfoGraph\footnote{DGI is originally designed for node-level tasks, while InfoGraph extends it to graph-level classification. In our experiments, we apply DGI to node classification and InfoGraph to graph classification.} \cite{velivckovic2017graph,sun2019infograph} and GraphCL \cite{you2020graph} adopt a “pre-train, fine-tune” strategy. These models first perform self-supervised pre-training using unlabeled graphs and are later fine-tuned for downstream tasks, where a classifier is trained with few-shot labels while keeping the pre-trained encoder frozen in single step.
(3) \emph{Graph prompt learning models}: ProG \cite{sun2023all}, GPF \cite{fang2024universal}, GPF+ \cite{fang2024universal}, and GraphPrompt \cite{liu2023graphprompt} employ self-supervised pre-training followed by prompt tuning. Unlike the fine-tuning methods, these methods leverage a unified task template, and train task-specific prompts in single step for downstream adaptation.
% Note that ProG \cite{sun2023all} are based on the meta-learning paradigm \cite{finn2017model}, requiring a set of labeled base classes in addition to the few-shot classes.
Further descriptions of these baselines and implementation details are shown in Appendix~\ref{app.baselines} \& ~\ref{app.parameters}, respectively.

% \stitle{Parameter settings.}
% For all baselines, we adhere to their original implementations and  recommended settings. To ensure fair and optimal comparisons, we further tune their hyperparameters. We provide detailed descriptions of the implementations and settings for baselines and our \model\ in Appendix~\ref{app.parameters}.

\stitle{Downstream tasks and evaluation.}
We perform experiments on two downstream tasks: node classification and graph classification. Both tasks follow an \( m \)-shot classification setup, where for each class, we randomly select \( m \) instances (nodes or graphs) as labeled examples.
In our main results, we set \( m = 1 \) for both node and graph classification tasks. Additionally, to examine the robustness of our method, we vary \( m \) within the range \( 1 \leq m \leq 10 \), allowing us to analyze performance under different few-shot scenarios.
We construct 100 independent \( m \)-shot tasks for each classification setting through repeated sampling. Each task is evaluated using five different random seeds, resulting in a total of 500 experimental runs per task type. We report both the mean and standard deviation across these results.
We evaluate performance using accuracy, in line with previous studies \cite{wang2020graph,liu2021relative,liu2023graphprompt}.

\subsection{Performance Evaluation}\label{sec.exp.per}
We first evaluate one-shot classification tasks. Then, we examine the effect of increasing the number of shots on model performance.

\stitle{One-shot performance.}\label{exp.main}
We present the results for one-shot node and graph classification tasks in Tables~\ref{table.node-graph-classification}. We observe that:
(1) \model\ consistently outperforms most baseline methods, surpassing the best competitor by margins of up to 11.05\% in node classification and 6.03\% in graph classification. These results underscore the advantage of incorporating multiple reasoning steps to better adapt to diverse tasks.
(2) Standard graph prompt learning approaches---ProG, GPF, GPF+, and GraphPrompt---exhibit significantly weaker performance compared to \model. Their limitations arise from relying on a single-step inference process that lacks iterative refinement of the final answer. This contrast highlights the effectiveness of our chain-of-thought prompting, which enables step-by-step inference and captures individualized learning patterns for each node.

\stitle{Few-shot performance.}
To evaluate the impact of labeled data availability on \model's performance, we vary the number of shots in both node and graph classification tasks. The results, shown in Fig.~\ref{fig.fewshot}, compare \model\ against several competitive baselines.
First, \model\ consistently outperforms the baselines, particularly in low-shot scenarios (e.g., \( m \leq 5 \)), where labeled data is scarce. Second, as the number of labeled samples increases (e.g., \( m > 5 \)), all methods generally exhibit improved performance, which aligns with expectations. Nevertheless, \model\ remains highly competitive, often achieving the best results.
Note that on certain datasets, such as \emph{PROTEINS}, performance across methods tends to show high variance. A possible reason is that this dataset exhibits greater variability in graph sizes compared to other datasets: The standard deviation of graph sizes in \emph{PROTEINS} is 45.78, whereas other datasets fall within the range of 4.04 to 15.29. This may contribute to unstable performance.
Despite this, \model\ demonstrates greater robustness than the competing methods. For the rest of the experiments, we focus on the one-shot classification setting.



% \begin{table*}[tbp] % [!t]
%     \centering
%     \small
%      \addtolength{\tabcolsep}{1mm}
%     \caption{Accuracy (\%) evaluation on node and graph classification.
%     }
%     \label{table.node-graph-classification}%
%     \resizebox{1\linewidth}{!}{%
%     \begin{tabular}{@{}l|cccc|cccc@{}}
%     \toprule
%   \multirow{2}*{Methods} & \multicolumn{4}{c|}{Node classification} & \multicolumn{4}{c}{Graph classification} \\ 
%   & Cora  & Citeseer & Pubmed & Photo & MUTAG & COX2 & BZR & PROTEINS \\\midrule\midrule
%     \method{GCN} & 32.50 $\pm$ 14.21  & 26.36 $\pm$ \phantom{0}9.03  & 52.18 $\pm$ \phantom{0}8.70  & 60.18 $\pm$ 12.04 
%     &  43.44 $\pm$ 15.14  & 50.95 $\pm$ 23.48  & 47.25 $\pm$ 16.59  & 40.28 $\pm$ \phantom{0}0.03 \\
%     \method{GAT} & 31.00 $\pm$ 16.22  & 27.71 $\pm$ \phantom{0}8.74  & 50.02 $\pm$ \phantom{0}8.88  & 51.79 $\pm$ 12.85 
%     &  37.33 $\pm$ 10.81  & 50.58 $\pm$ 26.16  & 46.55 $\pm$ 16.57  & 40.39 $\pm$ \phantom{0}0.04\\
%     \midrule
%     \method{DGI/InfoGraph} & 54.11 $\pm$ \phantom{0}9.60  & 45.00 $\pm$ \phantom{0}9.19  & 57.98 $\pm$ 11.36  & 64.48 $\pm$ 10.04 
%     &  53.17 $\pm$ 17.29  & 53.82 $\pm$ 14.19  & 49.33 $\pm$ 15.11  & 52.51 $\pm$ 10.29\\
%     \method{GraphCL} & 51.96 $\pm$ \phantom{0}9.43  & 43.12 $\pm$ \phantom{0}9.61  & 61.18 $\pm$ 11.60  & 63.93 $\pm$ 10.21 
%     &  54.92 $\pm$ 17.09  & 53.81 $\pm$ 14.21  & 49.73 $\pm$ 14.66  & 53.81 $\pm$ \phantom{0}8.97\\
%     \midrule
%     \method{ProG} & 51.35 $\pm$ 13.92 & 35.08 $\pm$ \phantom{0}8.63  & 64.07 $\pm$ 14.74  & 68.85 $\pm$ \phantom{0}9.99 
%     & 51.99 $\pm$ 14.50  & 53.45 $\pm$ 15.01  & 53.52 $\pm$ 11.97  & 52.73 $\pm$ \phantom{0}6.57\\
%     \method{GPF} & 57.35 $\pm$ 13.87  & 43.04 $\pm$ \phantom{0}8.85  & 57.61 $\pm$ 11.26  & 65.26 $\pm$ \phantom{0}9.89 
%     &  56.55 $\pm$ 13.95  & 54.16 $\pm$ 14.07  & 48.65 $\pm$ 13.96 & 53.05 $\pm$ \phantom{0}7.62\\
%     \method{GPF+} & \underline{64.91} $\pm$ 15.49  & 42.28 $\pm$ \phantom{0}8.71  & 57.85 $\pm$ 10.86  & \underline{69.80} $\pm$ 10.84 
%     &  \underline{56.81} $\pm$ 12.93  & \underline{55.24} $\pm$ 13.29  & 50.83 $\pm$ 19.74 & \underline{54.58} $\pm$ \phantom{0}8.70 \\
%     \method{GraphPrompt} & 54.56 $\pm$ 12.56  & \underline{46.23} $\pm$ \phantom{0}8.70 & \underline{64.85} $\pm$ 10.72  & 68.99 $\pm$ \phantom{0}9.28 
%     &  55.44 $\pm$ 12.56  & 54.34 $\pm$ 14.77  & \underline{54.59} $\pm$ 10.52  & 53.80 $\pm$ \phantom{0}7.93\\
%     \midrule
%     \model & \textbf{66.09} $\pm$ 15.17  & \textbf{47.77} $\pm$ 10.93  & \textbf{70.57} $\pm$ 17.10  & \textbf{77.51} $\pm$ 11.76 
%     & \textbf{58.75} $\pm$ 15.42  & \textbf{56.26} $\pm$ 15.52  & \textbf{58.03} $\pm$ 23.44  & \textbf{56.24} $\pm$ \phantom{0}8.60\\
%     \bottomrule
%         \end{tabular}}
%        \parbox{1\linewidth}{\footnotesize Best results are \textbf{bolded} and runner-up results are \underline{underlined}.}
% \end{table*}



% \begin{table*}[tbp] % [!t]
%     \centering
%     \small
%      \addtolength{\tabcolsep}{1mm}
%     \caption{Evaluation on node classification.
%     }
%     \label{table.node-classification}%
%     \resizebox{1\linewidth}{!}{%
%     \begin{tabular}{@{}l|cc|cc|cc|cc@{}}
%     \toprule
%   \multirow{2}*{Methods} & \multicolumn{2}{c|}{Cora} & \multicolumn{2}{c|}{Citeseer} & \multicolumn{2}{c|}{Pubmed} & \multicolumn{2}{c}{Photo} \\ & Acc (\%)  & MacroF (\%) & Acc (\%) & MacroF (\%) & Acc (\%) & MacroF (\%) & Acc (\%) & MacroF (\%) \\\midrule\midrule
%     \method{GCN} & 32.50 $\pm$ 14.21 & 25.02 $\pm$ 9.47 & 26.36 $\pm$ 9.03 & 18.95 $\pm$ 8.00 & 52.18 $\pm$ 8.70 & 48.98 $\pm$ 11.17 & 60.18 $\pm$ 12.04 & 59.14 $\pm$ 11.32\\
%     \method{GAT} & 31.00 $\pm$ 16.22 & 24.41 $\pm$ 11.54 & 27.71 $\pm$ 8.74 & 19.75 $\pm$ 7.71 & 50.02 $\pm$ 8.88 & 45.18 $\pm$ 11.54 & 51.79 $\pm$ 12.85 & 49.62 $\pm$ 11.23\\
%     \midrule
%     \method{DGI} & 54.11 $\pm$ 9.60 & 46.45 $\pm$ 8.75 & 45.00 $\pm$ 9.19 & 42.10 $\pm$ 9.32 & 57.98 $\pm$ 11.36 & 49.19 $\pm$ 9.43 & 64.48 $\pm$ 10.04 & 64.06 $\pm$ 10.03\\
%     \method{GraphCL} & 51.96 $\pm$ 9.43 & 48.22 $\pm$ 8.23 & 43.12 $\pm$ 9.61 & 40.98 $\pm$ 8.74 & 61.18 $\pm$ 11.60 & 52.24 $\pm$ 10.37 & 63.93 $\pm$ 10.21 & 63.55 $\pm$ 9.96\\
%     \midrule
%     \method{ProG} & 51.35 $\pm$ 13.92 & 39.75 $\pm$ 9.39 & 35.08 $\pm$ 8.63 & 32.48 $\pm$ 7.78 & 64.07 $\pm$ 14.74 & 63.74 $\pm$ 15.12 & 68.85 $\pm$ 9.99 & 69.35 $\pm$ 9.38\\
%     \method{GPF} & 57.35 $\pm$ 13.87 & 44.60 $\pm$ 10.45 & 43.04 $\pm$ 8.85 & 37.17 $\pm$ 8.04 & 57.61 $\pm$ 11.26 & 55.81 $\pm$ 13.26 & 65.26 $\pm$ 9.89 & 64.64 $\pm$ 9.53\\
%     \method{GPF+} & 64.91 $\pm$ 15.49 & 51.67 $\pm$ 13.11 & 42.28 $\pm$ 8.71 & 37.43 $\pm$ 8.07 & 57.85 $\pm$ 10.86 & 56.23 $\pm$ 12.53 & 69.80 $\pm$ 10.84 & 69.19 $\pm$ 10.47\\
%     \method{GraphPrompt} & 54.56 $\pm$ 12.56 & 41.76 $\pm$ 9.61 & 46.23 $\pm$ 8.70 & 41.97 $\pm$ 7.87 & 64.85 $\pm$ 10.72 & 64.56 $\pm$ 11.06 & 68.99 $\pm$ 9.28 & 68.63 $\pm$ 9.15\\
%     \midrule
%     \model & 66.09 $\pm$ 15.17 & 46.34 $\pm$ 11.27 & 47.77 $\pm$ 10.93 & 42.47 $\pm$ 9.42 & 70.57 $\pm$ 17.10 & 69.28 $\pm$ 19.51 & 77.51 $\pm$ 11.76 & 78.41 $\pm$ 11.56\\
%     \bottomrule
%         \end{tabular}}
%        \parbox{1\textwidth}{\footnotesize Best results are \textbf{bolded} and runner-up results are \underline{underlined}.}
% \end{table*}



% \begin{table*}[tbp] % [!t]
%     \centering
%     \small
%      \addtolength{\tabcolsep}{1mm}
%     \caption{Evaluation on graph classification.
%     }
%     \label{table.graph-classification}%
%     \resizebox{1\linewidth}{!}{%
%     \begin{tabular}{@{}l|cc|cc|cc|cc@{}}
%     \toprule
%   \multirow{2}*{Methods}   & \multicolumn{2}{c|}{MUTAG} & \multicolumn{2}{c|}{COX2} & \multicolumn{2}{c|}{BZR} & \multicolumn{2}{c}{PROTEINS} \\ & Acc (\%)  & MacroF (\%) & Acc (\%) & MacroF (\%) & Acc (\%) & MacroF (\%) & Acc (\%) & MacroF (\%)  \\\midrule\midrule
%     \method{GCN} &  43.44 $\pm$ 15.14 & 35.17 $\pm$ 14.47 & 50.95 $\pm$ 23.48 & 42.42 $\pm$ 8.63 & 47.25 $\pm$ 16.59 & 40.38 $\pm$ 10.64 & 40.28 $\pm$ 0.03 & 38.22$\pm$0.11\\
%      \method{GAT} &  37.33 $\pm$ 10.81 & 28.57 $\pm$ 9.35 & 50.58 $\pm$ 26.16 & 43.46 $\pm$ 8.52 & 46.55 $\pm$ 16.57 & 39.64 $\pm$ 10.42 & 40.39 $\pm$ 0.04 & 37.36 $\pm$0.10\\\midrule
%     \method{DGI} &  53.17 $\pm$ 17.29 & 51.45 $\pm$ 17.68 & 53.82 $\pm$ 14.19 & 42.85 $\pm$ 7.03 & 49.33 $\pm$ 15.11 & 43.73 $\pm$ 10.69 & 52.51 $\pm$ 10.29 & 45.10$\pm$8.3\\
%     \method{GraphCL}  &  54.92 $\pm$ 17.09 & 53.88 $\pm$ 17.32 & 53.81 $\pm$ 14.21 & 42.86 $\pm$ 7.09 & 49.73 $\pm$ 14.66 & 41.27 $\pm$ 11.23 & 53.81 $\pm$ 8.97 & 51.72$\pm$8.63\\
%     \midrule
%     \method{ProG}&  51.99 $\pm$ 14.50 & 47.10 $\pm$ 11.40 & 53.45 $\pm$ 15.01 & 44.97 $\pm$ 8.72 & 53.52 $\pm$ 11.97 & 45.73 $\pm$ 6.26 & 52.73 $\pm$ 6.57 & 49.13$\pm$6.59 \\
%     \method{GPF}&  56.55 $\pm$ 13.95 & 53.37 $\pm$ 13.81 & 54.16 $\pm$ 14.07 & 43.67 $\pm$ 6.00 & 48.65 $\pm$ 13.96 & 42.58 $\pm$ 9.28 & 53.05 $\pm$ 7.62 & 49.06$\pm$6.17 \\
%     \method{GPF+}&  56.81 $\pm$ 12.93 & 54.11 $\pm$ 13.10 & 55.24 $\pm$ 13.29 & 44.54 $\pm$ 6.59 & 50.83 $\pm$ 19.74 & 44.71 $\pm$ 9.67 & 54.58 $\pm$ 8.70 & 50.42$\pm$9.60 \\
%     \method{GraphPrompt} &  55.44 $\pm$ 12.56 & 53.33 $\pm$ 13.30 & 54.34 $\pm$ 14.77 & 43.23 $\pm$ 7.08 & 54.59 $\pm$ 10.52 & 42.48 $\pm$ 18.28 & 53.80 $\pm$ 7.93 & 52.93$\pm$7.78\\\midrule
%     \model & 58.75 $\pm$ 15.42 & 53.64 $\pm$ 14.02 & 56.26 $\pm$ 15.52 & 44.74 $\pm$ 8.40 & 58.03 $\pm$ 23.44 & 46.68 $\pm$ 16.01 & 56.24 $\pm$ 8.60 & 50.73$\pm$ 8.73\\
%     \bottomrule
%         \end{tabular}}
% \end{table*}


\begin{figure}[t]
\centering
\includegraphics[width=1\linewidth]{figures/fewshot6.pdf}
\caption{Impacts of shots on node and graph classification.}
\label{fig.fewshot}
\end{figure}

\subsection{Ablation Study and Visualization}\label{sec.ablation}
To thoroughly evaluate the impact of chain-of-thought prompt learning in \model, we conduct an ablation study comparing \model\ with four  variants:  
(1) \model$\backslash$CoT, which applies single-step prompting without chain-of-thoughts;  
(2) \model-L1, (3) \model-L2, and (4) \model-L3, where each variant utilizes only the hidden embedding from the first, second, or third layer of the pre-trained graph encoder (we employ a 3 layer GCN as the backbone) as the thought, respectively.
As shown in Table~\ref{table.ablation}, \model\ consistently outperforms all variants except in one case, where it remains highly competitive. This underscore the importance of iterative learning for refining predictions and demonstrate the effectiveness of integrating hierarchical knowledge from different layers of the pre-trained graph encoder to generate thought.

To further demonstrate the impact of our chain-of-thought design, we visualize the output embedding space of nodes computed by \model$\backslash$CoT, \model, and the thought constructed at the first inference step on the \textit{Pubmed} and \textit{Photo} datasets, as shown in Fig.~\ref{fig.visualization}. The results reveal that, with chain-of-thought prompting, node embeddings from different classes exhibit a clearer separation compared to those from \model$\backslash$CoT, underscoring the effectiveness of \model\ in enhancing class distinction. Moreover, based on the thought generated in the first step, %which exhibits sparse clusters with clear separation, 
the output embedding from the second step ( \model\ uses a total of two steps) results in denser clusters with even clearer separation. 


\begin{table}[tbp] % [!t]
    \centering
    \small
     \addtolength{\tabcolsep}{1mm}
    \caption{Ablation study on the effects of key components.
    }
    \label{table.ablation}%
    \resizebox{1\linewidth}{!}{%
    \begin{tabular}{@{}l|cc|cc@{}}
    \toprule
  \multirow{2}*{Methods} & \multicolumn{2}{c|}{Node classification} & \multicolumn{2}{c}{Graph classification}\\
  & {Cora} & {Pubmed} & {MUTAG} & {PROTEINS} \\\midrule\midrule
    \model$\textbackslash$CoT & 57.22\text{\scriptsize ±14.14}  & 67.81\text{\scriptsize ±15.53}  & 56.49\text{\scriptsize ±16.61}  & 53.40\text{\scriptsize ±6.66} \\
    \model-L1 & 61.45\text{\scriptsize ±15.82}  & 59.94\text{\scriptsize ±14.84}  & 56.54\text{\scriptsize ±14.12} & 54.71\text{\scriptsize ±8.57}\\
    \model-L2 & 66.95\text{\scriptsize ±16.07}  & 63.05\text{\scriptsize ±15.13}  & 57.68\text{\scriptsize ±13.84} & 54.77\text{\scriptsize ±8.81}\\
    \model-L3 & 64.39\text{\scriptsize ±15.76}  & 69.27\text{\scriptsize ±18.20}  & 57.85\text{\scriptsize ±16.10}  & 56.22\text{\scriptsize ±8.45}\\
    \model & 66.09\text{\scriptsize ±15.17}  & 70.57\text{\scriptsize ±17.10}  & 58.75\text{\scriptsize ±15.42}  & 56.24\text{\scriptsize ±8.60} \\
    \bottomrule
        \end{tabular}}
\end{table}

\begin{figure}[t]
\centering
\includegraphics[width=1\linewidth]{figures/visusilization.pdf}
\caption{Visualization of output embedding space of nodes.  Different colors represents different classes.}
\label{fig.visualization}
\end{figure}


% \begin{table*}[tbp] % [!t]
%     \centering
%     \small
%      \addtolength{\tabcolsep}{1mm}
%     \caption{Ablation study on the effects of key components.
%     }
%     \label{table.ablation}%
%     \resizebox{1\linewidth}{!}{%
%     \begin{tabular}{@{}l|cccc|cccc@{}}
%     \toprule
%   \multirow{3}*{Methods} & \multicolumn{4}{c|}{Node classification} & \multicolumn{4}{c}{Graph classification}\\
%   & \multicolumn{2}{c}{Cora} & \multicolumn{2}{c|}{Pubmed} & \multicolumn{2}{c}{MUTAG} & \multicolumn{2}{c}{PROTEINS} \\ & Acc (\%)  & MacroF (\%) & Acc (\%) & MacroF (\%) & Acc (\%) & MacroF (\%) & Acc (\%) & MacroF (\%)  \\\midrule\midrule
%     \model$\textbackslash$CoT & 57.22 $\pm$ 14.14 & 44.02 $\pm$ 10.58 & 67.81 $\pm$ 15.53 & 66.37 $\pm$ 17.06 & 56.49 $\pm$ 16.61 & 53.52 $\pm$ 15.49 & 53.40 $\pm$ 6.66 & 53.01$\pm$ 6.93\\
%     \model$\textbackslash$L1 & 61.45 $\pm$ 15.82 & 43.27 $\pm$ 9.79 & 59.94 $\pm$ 14.84 & 58.63 $\pm$ 16.79 & 56.54 $\pm$ 14.12 & 52.44 $\pm$ 13.28 & 54.71 $\pm$ 8.57 & 49.11$\pm$ 8.10\\
%     \model$\textbackslash$L2 & 66.95 $\pm$ 16.07 & 47.51 $\pm$ 10.74 & 63.05 $\pm$ 15.13 & 61.62 $\pm$ 17.37 & 57.68 $\pm$ 13.84 & 53.81 $\pm$ 12.99 & 54.77 $\pm$ 8.81 & 49.58$\pm$ 8.32\\
%     \model$\textbackslash$L3 & 64.39 $\pm$ 15.76 & 48.36 $\pm$ 12.23 & 69.27 $\pm$ 18.20 & 68.13 $\pm$ 20.15 & 57.85 $\pm$ 16.10 & 52.05 $\pm$ 14.24 & 56.22 $\pm$ 8.45 & 50.89 $\pm$ 8.88\\
%     \model & 66.09 $\pm$ 15.17 & 46.34 $\pm$ 11.27 & 70.57 $\pm$ 17.10 & 69.28 $\pm$ 19.51 & 58.75 $\pm$ 15.42 & 53.64 $\pm$ 14.02 & 56.24 $\pm$ 8.60 & 50.73$\pm$ 8.73\\
%     \bottomrule
%         \end{tabular}}
% \end{table*}

% \subsection{Link Prediction}

% \begin{table}[tbp] % [!t]
%     \centering
%     \small
%      \addtolength{\tabcolsep}{1mm}
%     \caption{AUC-ROC (\%) evaluation on link prediction.
%     }
%     \label{table.link-prediction}%
%     \resizebox{0.65\linewidth}{!}{%
%     \begin{tabular}{@{}l|cc@{}}
%     \toprule
%   {Methods}   & xxx & xxx  \\\midrule\midrule
%     xxx & 57.22 $\pm$ 14.14  & 57.22 $\pm$ 14.14  \\
%     xxx &  &   \\
%     \model &   &  \\
%     \bottomrule
%         \end{tabular}}
% \end{table}



\subsection{Heterophily Sensitivity}\label{sec.hetero}
To examine the robustness of \model\ on heterophilic graphs \cite{pei2020geom,yu2024non}, we conduct one-shot node classification on heterophilic datasets (\textit{Wisconsin} \cite{pei2020geom} and \textit{Squirrel} \cite{rozemberczki2021multi}). We provide the detailed description of these datasets in Appendix~\ref{app.hetero}.
As shown in Table~\ref{table.hetero}, \model\ consistently outperforms other competing baselines, further validating its effectiveness. These results indicates that the iterative inference process in \model\ successfully generalizes across both homophilic and heterophilic graphs. %Note that we focus on node classification in this analysis, as homophily is inherently linked to node attributes and is thus a key factor in node-level tasks.


\begin{table}[tbp] % [!t]
    \centering
    \small
     \addtolength{\tabcolsep}{1mm}
    \caption{Accuracy (\%) evaluation on heterophilic datasets.
    }
    \label{table.hetero}%
    \resizebox{0.7\linewidth}{!}{%
    \begin{tabular}{@{}l|cc@{}}
    \toprule
  {Methods}   & Wisconsin & Squirrel  \\\midrule\midrule
    DGI & 28.04 $\pm$ 6.47 & 20.00 $\pm$ 1.86 \\
    GraphCL & 29.85 $\pm$ 8.46 & \underline{21.42} $\pm$ 2.22 \\\midrule
    ProG & \underline{32.95} $\pm$ 11.42 & 20.61 $\pm$ 3.01 \\
    GPF & 30.29 $\pm$ 10.04 & 19.89 $\pm$ 3.19 \\
    GPF+ & 29.26 $\pm$ 9.61 & 20.93 $\pm$ 3.98 \\
    GraphPrompt & 29.96 $\pm$ 9.40 & 21.22 $\pm$ 1.80 \\\midrule
    \model & \textbf{33.04} $\pm$ 9.71 & \textbf{22.03} $\pm$ 4.94 \\
    \bottomrule
        \end{tabular}}
\end{table}


\subsection{Flexibility of Graph Prompting Methods} \label{sec.backbone-flexibility}
To evaluate the flexibility and robustness of \model, we evaluate its performance using various standard graph prompting methods as the task prompt. Specifically, we integrate \textsc{ProG} \citep{sun2023all}, \textsc{GPF} \citep{fang2024universal}, \textsc{GPF+} \citep{fang2024universal}, and \textsc{GraphPrompt} \citep{liu2023graphprompt} into our framework.
The results for both node and graph classification on four datasets are presented in Table~\ref{table.backbone}. Across nearly all cases, \model\ consistently outperforms its single-step prompting counterparts, regardless of the task prompt employed. These findings highlight the robustness of our approach and further confirm the advantage of chain-of-thought prompting over previous single-step prompting.



\begin{table}[tbp]
    \centering
    \caption{Evaluation of \model\ with different standard prompting methods.}
    \label{table.backbone}%
    \resizebox{1\linewidth}{!}{%
    \begin{tabular}{@{}l|l|cc|cc@{}}
    \toprule
    \multirow{2}*{Prompting} &\multirow{2}*{Thinking} & \multicolumn{2}{c|}{Node classification} & \multicolumn{2}{c}{Graph classification}\\
    & &{Cora} & {Pubmed} & {MUTAG} & {PROTEINS} \\\midrule\midrule
    \multirow{2}{*}{\textsc{ProG}} 
    & - & 51.35\text{\scriptsize ±13.92}  & 64.07\text{\scriptsize ±14.74}   & 51.99\text{\scriptsize ±14.50 }  & 52.73\text{\scriptsize ±6.57}   \\
    & \model & \textbf{59.62}\text{\scriptsize ±14.20}   & \textbf{72.19}\text{\scriptsize ±14.92}   & \textbf{58.42}\text{\scriptsize ±15.39}  & \textbf{55.82}\text{\scriptsize ±8.79}  \\\midrule
    \multirow{2}{*}{\textsc{GPF}} 
    & - & 57.35\text{\scriptsize ±13.87}   & 57.61\text{\scriptsize ±11.26}   & 56.55\text{\scriptsize ±13.95}   & 53.05\text{\scriptsize ±7.62}  \\
    & \model & \textbf{60.28}\text{\scriptsize ±15.69}   & \textbf{66.24}\text{\scriptsize ±12.61}  & \textbf{57.66}\text{\scriptsize ±13.11}   & \textbf{56.98}\text{\scriptsize ±8.30}  \\\midrule
    \multirow{2}{*}{\textsc{GPF+}} 
    & - & \textbf{64.91}\text{\scriptsize ±15.49 }  & 57.85\text{\scriptsize ±10.86}  & 56.81\text{\scriptsize ±12.93}   & 54.58\text{\scriptsize ±8.70}   \\
    & \model & 62.71\text{\scriptsize ±15.18}  & \textbf{65.97}\text{\scriptsize ±11.09}   & \textbf{58.54}\text{\scriptsize ±13.29}   & \textbf{55.45}\text{\scriptsize ±9.20}\\\midrule
    \multirow{2}{*}{\textsc{GraphPrompt}} 
    & - & 54.56\text{\scriptsize ±12.56}   & 64.85\text{\scriptsize ±10.72}   & 55.44\text{\scriptsize ±12.56}   & 53.80\text{\scriptsize ±7.93}   \\
    & \model & \textbf{55.83}\text{\scriptsize ±13.69}   & \textbf{72.73}\text{\scriptsize ±16.18}   & \textbf{58.28}\text{\scriptsize ±15.47}   & \textbf{55.32}\text{\scriptsize ±8.43}  \\
    \bottomrule
    \end{tabular}}
     \parbox{1\linewidth}{\scriptsize \ \ \ ``-'' refers to standard graph prompting without our CoT design.}
\end{table}

% \subsection{Flexibility of Graph Prompting Methods} \label{sec.backbone-flexibility}
% \begin{table*}[tbp]
%     \centering
%     \caption{Evaluation of \model\ with different standard prompting methods.}
%     \label{table.backbone}%
%     \resizebox{1\linewidth}{!}{%
%     \begin{tabular}{@{}l|l|cccc|cccc@{}}
%     \toprule
%     \multirow{3}*{Prompting} &\multirow{3}*{Thinking} & \multicolumn{4}{c|}{Node classification} & \multicolumn{4}{c}{Graph classification}\\
%     & &\multicolumn{2}{c}{Cora} & \multicolumn{2}{c|}{Pubmed} & \multicolumn{2}{c}{MUTAG} & \multicolumn{2}{c}{PROTEINS} \\ & & Acc (\%)  & MacroF (\%) & Acc (\%) & MacroF (\%) & Acc (\%) & MacroF (\%) & Acc (\%) & MacroF (\%)  \\\midrule
%     \multirow{2}{*}{\textsc{ProG}} 
%     & - & 51.35 $\pm$ 13.92 & 39.75 $\pm$ 9.39 & 64.07 $\pm$ 14.74 & 63.74 $\pm$ 15.12 & 51.99 $\pm$ 14.50 & 47.10 $\pm$ 11.40 & 52.73 $\pm$ 6.57 & 49.13$\pm$6.59 \\
%     & \model & 59.62 $\pm$ 14.20 & 46.90 $\pm$ 12.58 & 72.19 $\pm$ 14.92 & 71.78 $\pm$ 16.01 & 58.42 $\pm$ 15.39 & 52.95 $\pm$ 14.28 & 55.82 $\pm$ 8.79 & 50.44 $\pm$ 8.81 \\\midrule
%     \multirow{2}{*}{\textsc{GPF}} 
%     & - & 57.35 $\pm$ 13.87 & 44.60 $\pm$ 10.45 & 57.61 $\pm$ 11.26 & 55.81 $\pm$ 13.26 & 56.55 $\pm$ 13.95 & 53.37 $\pm$ 13.81 & 53.05 $\pm$ 7.62 & 49.06$\pm$6.17\\
%     & \model & 60.28 $\pm$ 15.69 & 47.58 $\pm$ 13.24 & 66.24 $\pm$ 12.61 & 66.15 $\pm$ 13.86 & 57.66 $\pm$ 13.11 & 52.70 $\pm$ 11.74 & 56.98 $\pm$ 8.30 & 51.75$\pm$ 8.68\\\midrule
%     \multirow{2}{*}{\textsc{GPF+}} 
%     & - & 64.91 $\pm$ 15.49 & 51.67 $\pm$ 13.11 & 57.85 $\pm$ 10.86 & 56.23 $\pm$ 12.53 & 56.81 $\pm$ 12.93 & 54.11 $\pm$ 13.10 & 54.58 $\pm$ 8.70 & 50.42$\pm$9.60 \\
%     & \model & 62.71 $\pm$ 15.18 & 50.21 $\pm$ 12.27 & 65.97 $\pm$ 11.09 & 65.90 $\pm$ 11.98 & 58.54 $\pm$ 13.29 & 53.91 $\pm$ 12.29 & 55.45 $\pm$ 9.20& 48.63$\pm$9.07\\\midrule
%     \multirow{2}{*}{\textsc{GraphPrompt}} 
%     & - & 54.56 $\pm$ 12.56 & 41.76 $\pm$ 9.61 & 64.85 $\pm$ 10.72 & 64.56 $\pm$ 11.06 & 55.44 $\pm$ 12.56 & 53.33 $\pm$ 13.30 & 53.80 $\pm$ 7.93 & 52.93$\pm$7.78 \\
%     & \model & 55.83 $\pm$ 13.69 & 43.62 $\pm$ 11.02 & 72.73 $\pm$ 16.18 & 72.29 $\pm$ 17.14 & 58.28 $\pm$ 15.47 & 52.82 $\pm$ 14.35 & 55.32 $\pm$ 8.43 & 50.03 $\pm$8.43\\
%     \bottomrule
%     \end{tabular}}
%      \parbox{1\linewidth}{\scriptsize \ \ \ ``-'' refers to standard graph prompting without our CoT design.}
% \end{table*}

\subsection{Hyperparameter Analysis for Condition-Net}
In our experiments, we implement the condition-net as a two-layer MLP with a bottleneck design. To examine its effect on performance, we vary the hidden dimension \( s \) and present the results in Fig.~\ref{fig.hiddendim}. Our findings reveal that \( s = 32 \) generally yields competitive results for node classification, and \( s = 8 \) for graph classification, leading us to adopt these settings in our experiments. A smaller \( s \) may restrict the model's representational capacity, limiting its effectiveness, whereas a larger \( s \) introduces additional trainable parameters and increases the likelihood of overfitting in few-shot learning scenarios.


\begin{figure}[t]
\centering
\includegraphics[width=1\linewidth]{figures/hyperdim5.pdf}
\caption{Impact of hidden dimension $s$ in the condition-net.}
\label{fig.hiddendim}
\end{figure}

\subsection{Effect of Varying Number of Inference Steps}
We further vary the number \(K\) of inference steps to analyze their impact, with the results presented in Fig.~\ref{fig.think}. We observe that for both node and graph classification tasks, \(K=2\) generally yields optimal performance. Hence, we adopt \(K=2\) in our experiments. For Proteins, \(K=3\) achieves the best result, likely due to its inherent complexity as described in Sect.~\ref{sec.exp.per}.

\begin{figure}[t]
\centering
\includegraphics[width=1\linewidth]{figures/hyperlayer5.pdf}
\caption{Impact of number of inference steps $K$.}
\label{fig.think}
\end{figure}
