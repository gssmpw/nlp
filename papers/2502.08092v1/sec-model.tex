\section{Chain-of-Thought Graph Prompt Learning}

In this section, we propose our model, \model, starting with an overview of its framework. Then we detail its core components and conclude with a complexity analysis of the algorithm.

\subsection{Overall framework}
We illustrate the overall framework of \model\ in Fig.~\ref{fig.framework}, consisting of two key stages: pre-training and CoT prompting. 
First, we pre-train a graph encoder as shown in Fig.~\ref{fig.framework}(a). %Specifically, we adopt a universal task template based on similarity calculation \citep{liu2023graphprompt}, which provides a unified framework for diverse graph-based tasks, including node classification and graph classification.
Details of pre-training are provided in Sect.~\ref{sec.preliminaries}.
Second, given a pre-trained graph encoder, to guide the model take additional inference step before finalizing predictions, we propose CoT prompting, as shown in Fig.~\ref{fig.framework}(c). Specifically, we design an inference step with three substages: prompt-based inference, thought construction, and thought-conditioned prompt learning. We first feed the prompt modified query graph into the pre-trained graph encoder. Then we construct a thought by fusing embeddings of all hidden layers of the pre-trained graph encoder. Conditioned on the thought from the previous step, we employ a condition-net to generate a series of node-specific conditional prompts that capture individualized learning patterns for nodes in a fine-grained and parameter-efficient manner, as shown in in Fig.~\ref{fig.framework}(b). We repeat the inference steps until obtain a final answer, as shown in Fig.~\ref{fig.framework}(c). Moreover, to enhance alignment between downstream tasks and the pre-training objective, we incorporate an initial prompt to adjust features or embeddings, same as prior graph prompting methods \cite{liu2023graphprompt,fang2024universal}.

\subsection{Chain-of-Thought Prompting}
To bridge the gap between the objectives between pre-training and downstream tasks, we adhere to previous graph prompting methods, leveraging an initial prompt to modify node features \cite{sun2022gppt,fang2024universal} or output embeddings \cite{liu2023graphprompt,yu2024non}, as shown in Fig.~\ref{fig.framework}(c). Note that our framework is fully compatible with any standard graph prompting techniques and can further enhance their performance, as demonstrated in Sect.~\ref{sec.backbone-flexibility}. In our experiments, we employ an attention mechanism to generate prompts that modify the output embedding of the final step, as detailed in the \textit{Prompt tuning} section.

\stitle{Prompt-based inference}
For the \(k\)-th inference step, we first feed the prompt modified query graph into the pre-trained encoder:
\begin{equation}
    \{\vec{H}_k^1, \vec{H}_k^2, \cdots, \vec{H}_k^L\} = \textsc{GraphEncoder}(\vec{X}_{k},G;\Theta_0)
\end{equation}
where $\Theta_0$ is the pre-trained parameters in the graph encoder, $\vec{X}_{k}$ is the modified feature  by prompts, which will be introduced in the \textit{Thought conditioned prompt learning} section. 

\stitle{Thought construction}
% Previous graph learning methods, whether supervised learning approaches \cite{kipf2016semi,velivckovic2017graph}, pre-training and fine-tuning methods \cite{you2020graph,velickovic2019deep}, or graph prompting methods \cite{liu2023graphprompt,yu2024generalized}, typically produce an answer in a single inference step. Specifically, in the downstream encoding phase, they feed the query graphs into a (pre-trained) graph encoder and leverage adaptation mechanism to generate the final answer. Inspired by CoT prompting in the language domain, we decompose this single inference step into several steps to refine the answer incrementally. Specifically, 
To leverage the hierarchical knowledge across multiple layers of the graph encoder, we construct the thought  by fusing the hidden embeddings from each layer of the pre-trained graph encoder as follows:
\begin{equation}
    \vec{T}_{k} = \mathtt{Fuse}(\vec{H}_k^1, \vec{H}_k^2, \cdots, \vec{H}_k^L),
\end{equation}
where \(\vec{H}_k^l\) denotes the hidden embedding from the \(l\)-th layer during the \(k\)-th inference step. The $\mathtt{Fuse}(\cdot)$ function can be implemented in various type. In our experiments, we employ weighted summation as the fusion function:
\begin{equation}
    \vec{T}_{k} = w^1\cdot\vec{H}_k^1+w^2\cdot\vec{H}_k^2+\cdots+w^L\cdot\vec{H}_k^L,
\end{equation}
where $w^1,w^2,\cdots,w^L$ are learnable parameters. The thought $\vec{T}_{k}$ is then used to guide the the next inference step.

\stitle{Thought conditioned prompt learning}
The thought generated in the previous inference step stores hierarchical structural knowledge, which guides the learning in the subsequent step. Since different nodes may exhibit distinct characteristics with respect to the downstream task, rather than learn all node's representation in the same manner, the pre-trained model should be steered to learn node-specific patterns. To this end, we propose leveraging a condition-net \cite{zhou2022conditional,yu2024dygprompt,yu2024non} to generate node-specific prompts, guiding node-specific adaptation. Specifically, conditioned on the thought from the previous step, \(\vec{T}_{k}\), the condition-net generates a series of thought prompts as follows:
\begin{align}\label{eq.prompt-generation}
    \vec{P}_{k} = \mathtt{CondNet}(\vec{T}_{k}; \phi),
\end{align}
where \(\mathtt{CondNet}\) is the condition-net parameterized by \(\phi\). Note that condition-net is a lightweight hypernetwork \cite{ha2022hypernetworks}, where our condition-net $\mathtt{CondNet}$ functions as an auxiliary network to generate the prompts conditioned on the thoughts parameter-efficiently. In our implementation, we utilize a simple multi-layer perceptron (MLP) with a bottleneck structure for improved efficiency \cite{wu2018reducing}.
The $i$-th row of \(\vec{P}_{k}\) represents a unique node-specific prompt vector \( \vec{p}_{i,k} \) for node $v_i$, which is derived from the thought \(\vec{T}_{k}\). This prompt vector then guides the next inference step by modifying the node features as follows:
\begin{align}\label{eq.thought-prompting}
    \vec{X}_{k+1} = \vec{P}_k \odot \vec{X},
\end{align}
where \(\odot\) denotes element-wise multiplication, and \(\vec{X}_{k+1}\) represents the input to the pre-trained graph encoder in the \(k+1\) step. After repeating \(K\) inference steps, the final step outputs the nodes embeddings \(\vec{H}_{K}\).


\stitle{Prompt tuning}\label{sec.prompt-tuning}
For initial prompts, all standard graph prompting methods can be applied within our framework. In our experiments, we adhere to GPF+ \cite{fang2024universal} to generate initial prompts. Specifically, we train \( N \) bias prompts $\{\vec{p}_\text{bias}^1, \vec{p}_\text{bias}^2, \ldots, \vec{p}_\text{bias}^N\}$, 
and leverage attention-based aggregation to generate node-specific prompts. However, unlike GPF+, which uses these prompts to modify graph features, we use them to modify the final embeddings. Specifically, the task prompt for node \( i \) is computed as:
\begin{equation}
    \vec{p}_\text{init}^i = \sum_{j=1}^{N} \alpha_{i,j} \vec{p}_\text{bias}^j,\quad \text{where} \quad \alpha_{i,j} = \frac{\exp\big(\vec{a}^{j}\vec{h}_{K}^i\big)}{\sum_{l=1}^{N} \exp\big(\vec{a}^{l}\vec{h}_{K}^i\big)}.
\end{equation}
Here, \( \vec{h}_{K}^i \) denotes the \( i \)-th row of the final embedding matrix \( \vec{H}_{K} \), which serves as the embedding for node \( i \), and \(\vec{A}= \{\vec{a}^1, \vec{a}^2, \ldots, \vec{a}^N\} \) are \( N \) learnable linear projection vectors. The generated initial prompts form the matrix \( \vec{P}_\text{init} \), which is then used to modify the final output embeddings as follows:
\begin{equation}\label{eq.initial-prompt}
    \vec{\Tilde{H}} = \vec{P}_\text{init} \odot \vec{H}_{K}.
\end{equation}
Note that for clarity and to maintain a unified representation of the various task prompt mechanisms, we use \(\vec{P}_\text{init}\) to denote the trainable parameters associated with these mechanisms throughout the remainder of this paper.


Finally, for a given task with a labeled training set 
\[
\mathcal{D}_t = \{(x_1, y_1), (x_2, y_2), \dots\},
\]
where each \( x_i \) represents either a node or a graph and \( y_i \in Y \) denotes its corresponding class label, the downstream loss function is defined as:
\begin{align}\label{eq.prompt-loss}
    \bL_{\text{down}}(\phi,\vec{P}_\text{init}) = -\sum_{(x_i, y_i) \in \mathcal{D}_t} \ln \frac{\exp\left(\text{sim}\left(\vec{\tilde{h}}_{x_i}, \vec{\bar{h}}_{y_i}\right)/\tau\right)}{\sum_{c \in Y} \exp\left( \text{sim}\left(\vec{\tilde{h}}_{x_i}, \vec{\bar{h}}_{c}/\right)\tau\right)},
\end{align}
where \( \vec{\tilde{h}}_{x_i} \) represents the final embedding of a node \( v \) or a graph \( G \). Specifically, for node classification, \( \vec{\tilde{h}}_{v} \) corresponds to a row in the answer matrix \( \vec{\tilde{H}} \), while for graph classification, we compute the graph embedding as
\[
    \vec{\tilde{h}}_{G} = \sum_{v \in V} \vec{\tilde{h}}_{v},
\]
incorporating an additional graph readout step.
The prototype embedding for each class \( c \), denoted as \( \vec{\bar{h}}_{c} \), is obtained by averaging the embeddings of all labeled nodes or graphs belonging to that class.
During prompt tuning, only the task prompts and lightweight parameters of the condition network (\( \phi \)) are updated, while the pre-trained GNN weights remain frozen. This parameter-efficient design makes our approach well-suited for few-shot learning, where the training set \( \mathcal{D}_t \) contains only a limited number of labeled examples.

\subsection{Algorithm and Complexity Analysis}
\stitle{Algorithm.}
We detail the main steps for Chain-of-Thought graph prompting in Algorithm~\ref{alg.prompt}. In lines 3--12, we iterate through \( K \) inference steps during the downstream adaptation phase while keeping the pre-trained weights \( \Theta_0 \) frozen. Specifically, in lines 4--7, we generate the thought for the \( k \)-th inference step by fusing the output embeddings from each layer of the pre-trained graph encoder. In lines 8--12, we leverage this thought to generate node-specific prompts that guide the subsequent inference step to capture node-specific patterns. In lines 13--14, we employ a standard task prompt to modify the output embedding of the last inference step. Note that, based on the task prompt mechanism described in the original paper, these prompts can also be applied to modify the input features at the first inference step. Finally, in lines 15--17, we update the embeddings for the prototypical nodes/graphs based on the few-shot labeled data.


\begin{algorithm}[tbp]
\small
\caption{\textsc{Chain-of-Thought Graph Prompt Learning}}
\label{alg.prompt}
\begin{algorithmic}[1]
    \Require Pre-trained graph encoder with parameters $\Theta_0$.
    \Ensure Optimized parameters $\phi$ of condition-net, and task prompt $\vec{P}_{\text{init}}$.
    \While{not converged} 
        \State $\phi_i \leftarrow$ initialization
        % \State \slash* Task prompt modify the input *\slash
        % \State \vec{\tilde{X}}\leftarrow \vec{p}_{\text{task}}\odot X
        % \State $\vec{H}_k^1, \vec{H}_k^2, \cdots, \vec{H}_k^L \leftarrow \textsc{GraphEncoder}(G,X;\Theta_0)$ 
        \State $\vec{X}_1\leftarrow \vec{X}$
        \State \slash* 1 to $K-1$ inference steps*\slash
        \While{inference step $1\leq k< K$}
            \State \slash* Encoding by the pre-trained graph encoder *\slash
            \State $\vec{H}_k^1, \vec{H}_k^2, \cdots, \vec{H}_k^L \leftarrow \textsc{GraphEncoder}(G,\vec{X}_k;\Theta_0)$
            \State \slash* Thought construction *\slash
            \State $\vec{T}_{k} \leftarrow \mathtt{Fuse}(\vec{H}_k^1, \vec{H}_k^2, \cdots, \vec{H}_k^L)$
            \State \slash* Thought prompting *\slash
            \State \slash*  Generate thought prompts by Eq.~\ref{eq.prompt-generation} *\slash
            \State $\vec{P}_{k} \leftarrow \mathtt{CondNet}(\vec{T}_{k}; \phi)$
            \State \slash* Thought prompts modification by Eq.~\ref{eq.thought-prompting} *\slash
            \State $\vec{X}_{k+1} \leftarrow \vec{P}_{k} \odot \vec{X}$
        \EndWhile
            \State \slash* $K$-th inference step *\slash
            \State $\{\vec{H}_K^1, \vec{H}_K^2, \cdots, \vec{H}_K^L\} \leftarrow \textsc{GraphEncoder}(G,\vec{X}_K;\Theta_0)$
            \State $\vec{H}_{K}\leftarrow \vec{H}_K^L$
            \State \slash* Initial prompt modification by Eq.~\ref{eq.initial-prompt}*\slash
            \State $\vec{\tilde{H}} \leftarrow \vec{P}_\text{init} \odot \vec{H}_{K}$
            \State \slash* Update prototypical instance *\slash
            \For{each class $c$} 
                \State ${\vec{\bar{h}}}_{c} \leftarrow \textsc{Average}(\vec{\tilde{h}}_{x}$: instance $x$ belongs to class $c$)
            \EndFor
            \State \slash* Optimizing the parameters in condition-net *\slash
            \State Calculate $\bL_\text{down}(\phi,\vec{P}_\text{init})$ by Eq.~\eqref{eq.prompt-loss}
            \State Update $\phi$ by backpropagating  $\bL_\text{down}(\phi,\vec{P}_\text{init})$
        \EndWhile    
    \State \Return $\{\phi,\vec{P}_\text{task}\}$
\end{algorithmic}
\end{algorithm}

\stitle{Complexity analysis.}
For a downstream graph \( G \), we perform \( K \) iterative inference steps. Each step comprises two key components: (1) thought generation using a pre-trained GNN (executed for \( K \) iterations) and (2) thought-based conditional prompt learning (executed for \( K-1 \) iterations).
The computational complexity of the first component is largely determined by the GNN architecture. In a standard GNN, each node aggregates information from up to \( D \) neighboring nodes per layer. Consequently, computing node embeddings over \( L \) layers incurs a complexity of \( O(D^L \cdot |V|) \), where \( |V| \) denotes the number of nodes. Aggregating the outputs from all \( L \) layers adds an extra complexity of \( O(L\cdot |V|) \). Since the thought generation process is repeated \( K \) times, its overall complexity is:$O(K\cdot (D^L+L \cdot |V| ))$.
The second component, thought-based conditional prompt learning, refines the learning process by leveraging the thought representation from the previous step. This component consists of two stages: prompt generation and prompt tuning. In the prompt generation stage, the thought is fed into the condition-net, with a complexity of \( O(|V|) \). In the prompt tuning stage, each node is adjusted via a prompt vector, also incurring a complexity of \( O(|V|) \). Since this process is executed for \( K-1 \) iterations, the total complexity for this phase is: $O(2(K-1) \cdot |V|)$.
Additionally, we employ a standard task prompt to modify node features or embeddings. The complexity of this process depends on the specific prompting mechanism. Here, we assign it a complexity of \(O(|V|)\), which is common among graph prompting methods \cite{liu2023graphprompt,fang2024universal}.
In summary, the overall computational complexity of \model\ is: $O((D^L+L + 2(K-1) + 1) \cdot |V|)$.
% Given that both \( L \) and \( K \) are small constants, the two computational components exhibit comparable complexity.

\subsection{Why \model\ Works}
% To explain why \model\ works, we compare it with CoT prompting in NLP and standard graph prompting methods, as shown in Table~\ref{table.compariion}. 
In \model, we adapt the following mechanism. (1) All three approaches leverage a universal task template to unify pre-training and downstream tasks, ensuring that \model\ can efficiently adapt to different downstream tasks, particularly in few-shot settings. (2) The chain-of-thought mechanism enables \model\ to perform multiple inference steps, thereby refining the final answer more effectively. (3) The thoughts in \model\ fuse hierarchical topological knowledge from graphs, allowing it to better capture structural information. (4) Conditioned on the thought from the previous step, \model\ generates a series of node-specific prompts that efficiently capture fine-grained node characteristics, thus effectively refining answer step by step. The combination of above mechanisms ensures the effectiveness of \model.



% \begin{table}[tbp]
% \center
% \small
% \addtolength{\tabcolsep}{-1mm}
% \caption{Comparison among CoT prompting in NLP, standard graph prompting, and \model. 
% \label{table.compariion}}
% \resizebox{0.6\columnwidth}{!}{%
% \begin{tabular}{@{}c|ccc@{}}
% \toprule
%    Component &\makecell{CoT \\in NLP} & \makecell{Standard\\GP} &\makecell{\model}\\
% \midrule
%      Task prompts & $\checkmark$ & $\checkmark$ & $\checkmark$ \\ 
%      Chain-of-thoughts & $\checkmark$ & $\times$ & $\checkmark$ \\ 
%      Thought prompts & $\times$ & $\times$ & $\checkmark$ \\
%  \bottomrule
% \end{tabular}}
% \end{table}
