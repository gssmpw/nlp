\section{Related Work}
\label{secii}

There are existing research works that address data handling in sensor networks, primarily from the standpoint of managing communication bandwidth costs and minimizing sensing energy expenditure. Several approaches have been proposed in the literature, focusing on data compression techniques. As outlined in ____, these methods can be divided into two primary categories: local data compression and distributed data compression. In distributed data compression ____, data from multiple neighboring sensor nodes is aggregated to remove redundant information before transmission. This aggregation typically occurs at a central base station or a cluster head within the network. For this to be effective, spatial correlations must exist in the data collected by multiple sensor nodes. However, this assumption is not always valid for certain applications. In contrast, local data compression techniques rely on temporal correlations within individual sensor nodes to reduce the amount of data that needs to be transmitted ____. The work in ____ introduced a compression technique that utilizes both spatial and temporal correlations in sensor data. These methods compress the data at the sensor nodes, either in a lossless or lossy manner. Lossless compression methods, such as Huffman coding, run-length encoding, and other statistical techniques, have been developed in ____. Lossy compression techniques, including Bayesian Predictive Coding and piecewise linear approximation, have been proposed in ____, but they often suffer from irreversible data loss while also imposing a computational burden on sensor nodes.

Additionally, several research efforts focus on leveraging machine learning for data compression in resource-constrained sensor and IoT networks, aimed at improving energy efficiency. A much-explored methodology in these works is to encode or compress time-series data into relevant features, which are then transmitted to the cloud for further analysis. Common dimensionality reduction techniques such as Principal Component Analysis (PCA) ____, Singular Value Decomposition (SVD) ____, and Linear Discriminant Analysis (LDA) ____ have been widely adopted for compressive sensing in wireless environments. In these methods, the optimal number of components to retain is determined by factors specific to the application, which adds complexity. Furthermore, these techniques require storing the original data matrix, presenting challenges for sensor nodes with limited memory and computational power. Other machine learning-based compression techniques, including autoencoders ____ and reinforcement learning ____, have also been explored. Downstream task-driven semantic communication techniques ____ have also been applied to wireless networks as a novel data compression strategy. 

The concept of Synthetic Sensing and General Purpose Sensing, as proposed in ____, offers an alternative approach by reducing the number of sensing modalities required for a smart home IoT system. This approach involves deploying a small number of sensors on a single Printed Circuit Board (PCB), capable of generating machine learning features to monitor multiple secondary events. In ____, the authors demonstrate how a single complex sensor can indirectly monitor a large context, without direct instrumentation of objects. The paper also demonstrates the system's ability to virtualize raw sensor data into actionable feeds, whilst simultaneously lowering immediate privacy issues. Similarly, in paper____, the authors explore the feasibility of sensing hand activities from commodity smartwatches. The work presented in ____ develops an approach to sense activities in a room using long-range laser vibrometry as an alternative to using sensing units relying camera or microphone. While this approach of synthetic/general-purpose sensing simplifies sensor deployment and reduces privacy issues, it still requires significant processing complexity at the sensor nodes. Furthermore, it does not support the fine-grained real-time estimation of multiple modalities that is often needed in smart city IoT networks, which demand more dynamic and scalable solutions.

However, in most of these approaches, the data processing required for compression takes place at the sensor nodes. This introduces significant challenges for resource-constrained IoT devices that lack the necessary hardware support, such as processing and storage capabilities, to execute computationally intensive learning algorithms. For instance, in the context of smart city IoT networks, where a large number of sensors are deployed, executing complex machine learning algorithms at the sensor nodes can lead to significant energy consumption, which poses a limitation from both processing and energy efficiency perspectives. Moreover, these methodologies primarily focus on data management and do not address the broader issue of managing the large number of sensors deployed in smart city IoT networks.

\label{seciii}
\begin{figure*}[h]
	\centering
	\includegraphics[width=16cm,height=10.0cm]{sys_diag.png}
	\caption{System model representing smart city IoT data collection, processing and analysis}
	\label{sys_dia}
\end{figure*}