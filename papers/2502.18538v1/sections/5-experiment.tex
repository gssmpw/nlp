

% \subsection{Pretraining}
\section{Experiments}
\label{experiments}
% \begin{wrapfigure}{r}{0.5\textwidth}
% \vspace{-30pt}
%   \centering
%   \includegraphics[width=0.5\textwidth]{imgs/runtime_vs_seqlen.png}
%   \caption{Runtime for HyenaDNA, Caduceus, and ConvNova: all models around 7M, batch size=1, tested on A100 80GB.}
%   \label{fig:speed}
%   \vspace{-20pt}
% \end{wrapfigure}
% [moved to intro]
Some other studies have demonstrated that adopting multispecies data for pretraining can enhance downstream task performance. However, in this work, all pretraining tasks are performed on the human reference genome\footnote{\url{https://www.ncbi.nlm.nih.gov/assembly/GCF_000001405.26}} to align with the previous work (HyenaDNA and Caduceus). In addition, we employ a tokenization scheme at the character or base pair level, which has been proven to function well in SSM-inspired models. We also show the speed comparison between ConvNova and other models along sequence length ($10^3$ to $10^6$). At a sequence length of $10^6$, ConvNova is 1.35 times faster
than its fastest counterpart--HyenaDNA, as shown in Figure  \ref{fig:topresults}. Please refer to \ref{app:pretrain} for additional details on the pretraining dataset and recipes.
% 这里放速度的对比fig

% For other models, we tried to replicate them using the same settings as much as possible. However, for some downstream tasks, we did not follow the original paper's hyperparameters, such as the number of finetuning epochs, to reduce training costs.
\begin{table}[t]
  \caption{\textbf{NT Benchmark results.} MCC/F1-score is reported for pretrained NTv2, HyenaDNA, DNABERT-2, Caduceus-Ph, and ConvNova. The best values per task are bold, and the second-best are underlined. ± indicates the error range across five random seeds.}
  \label{table:nt benchmark}
  \centering

  \adjustbox{max width=\textwidth}{
  \begin{tabular}{lrrrr>{\columncolor{low}}r}
    \toprule
    & \textbf{NTv2} & \textbf{HyenaDNA} & \textbf{DNABERT-2} & \textbf{Caduceus-Ph} & \textbf{ConvNova} \\ 
    & (500M)     & (1.6M)      & (117M)    & (1.9M)    & (1.7M)   \\
    \midrule
    \rowcolor{titlebg} \textit{\textbf{Histone}} & & & & & \\
    \midrule
    H3              & 78.17 \small{±2.54} & 78.14 \small{±1.70} & 79.31 \small{±0.68} & \underline{80.48} \small{±1.04} & \textbf{81.50} \small{±0.80}     \\
    H3K4me1         & 51.64 \small{±1.12} & 44.52 \small{±2.59} & 48.34 \small{±4.63} & \underline{52.83} \small{±0.96} & \textbf{56.60} \small{±1.01}     \\
    H3K4me2         & 37.24 \small{±2.25} & 42.68 \small{±2.66} & 43.02 \small{±2.92} & \underline{49.88} \small{±2.65} & \textbf{57.45} \small{±2.27}   \\
    H3K4me3         & 50.30 \small{±1.77} & 50.41 \small{±3.15} & 45.43 \small{±3.33} & \underline{56.72} \small{±2.58} & \textbf{67.15} \small{±0.93}  \\
    H3K9ac          & 61.05 \small{±1.40} & 58.50 \small{±1.75} & 60.04 \small{±1.27} & \underline{63.27} \small{±2.29} & \textbf{68.10} \small{±1.91}  \\
    H3K14ac         & 57.22 \small{±2.19} & 56.71 \small{±2.40} & 54.49 \small{±4.99} & \underline{60.84} \small{±2.94} & \textbf{70.71} \small{±2.32}  \\
    H3K36me3        & 60.50 \small{±1.75} & 59.92 \small{±1.06} & 57.58 \small{±2.38} & \underline{61.12} \small{±1.44} & \textbf{68.31} \small{±1.19} \\
    H3K79me3        & 65.78 \small{±2.34} & 66.25 \small{±3.65} & 64.38 \small{±0.48} & \underline{67.17} \small{±2.03} & \textbf{72.08} \small{±1.23}  \\
    H4              & 79.87 \small{±1.34} & 78.15 \small{±1.58} & 78.18 \small{±0.98} & \underline{80.10} \small{±1.00} & \textbf{81.12} \small{±0.93}  \\
    H4ac            & 55.22 \small{±2.20} & 54.15 \small{±2.96} & 51.80 \small{±0.10} & \underline{59.26} \small{±3.67} & \textbf{66.10} \small{±1.20}  \\
    \midrule
    \rowcolor{titlebg} \textit{\textbf{Regulatory}} & & & & & \\
    \midrule
    Enhancer        & 54.51 \small{±1.94} & 53.13 \small{±4.52} & 52.50 \small{±1.44} & \underline{55.20} \small{±2.56} & \textbf{57.60} \small{±2.52}  \\
    Enhancer Types  & 43.36 \small{±1.75} & \underline{48.16} \small{±2.48} & 44.32 \small{±1.18} & 47.17 \small{±2.85} & \textbf{49.75} \small{±2.82}  \\
    Promoter All    & \textbf{96.82} \small{±0.47} & 95.57 \small{±0.18} & 96.23 \small{±0.17} & \underline{96.65} \small{±0.16} & \textbf{96.82} \small{±0.22}  \\
    Promoter non-TATA & \textbf{97.45} \small{±0.69} & 95.86 \small{±0.37} & \underline{97.17} \small{±0.17} & 96.31 \small{±0.50} & 96.76 \small{±0.21}  \\
    Promoter TATA   & \underline{96.53} \small{±0.81} & 95.88 \small{±0.53} & \textbf{96.99} \small{±0.49} & 96.21 \small{±0.81} & 96.34 \small{±0.38}  \\
    \midrule
    \rowcolor{titlebg} \textit{\textbf{Splice sites}} & & & & & \\
    \midrule
    Splice Acceptor & \textbf{97.99} \small{±0.66} & 96.98 \small{±0.49} & \underline{97.49} \small{±0.36} & 94.21 \small{±0.37} & 96.23 \small{±0.41}  \\
    Splice Donor    & \textbf{98.50} \small{±0.43} & 95.27 \small{±1.07} & 94.33 \small{±0.27} & 94.69 \small{±0.67} & \underline{96.62} \small{±0.61}  \\
    Splice All      & \textbf{98.15} \small{±1.01} & 94.05 \small{±1.08} & 93.75 \small{±1.25} & 92.87 \small{±1.73} & \underline{96.33} \small{±0.31}  \\
    \bottomrule
  \end{tabular}
  }
\end{table}
\subsection{Short Range}
\subsubsection{Nucleotide Transformer Benchmark}\label{exp:NT}
We start the evaluation with the recently proposed Nucleotide Benchmark~\citep{dalla2023nucleotide}. These datasets encompass three types of tasks: histone marker prediction, regulatory annotation prediction, and splice site annotation prediction.

To assess performance, we follow the methodology outlined in \citep{nguyen2024hyenadna}, applying different metrics depending on the task: Matthews Correlation Coefficient (MCC) for histone marker tasks and various enhancer-related tasks, F1 score for various promoter-related tasks and splice site annotation tasks. The baselines consist of NT-v2(500M), DNABERT-2, similar-sized HyenaDNA, and Caduceus-ph. Because in ~\citep{schiff2024caduceus}, Caduceus-ph outperforms Caduceus-ps in almost all functions except promoter TATA and H3K36me3, we only choose Caduceus-ph as our baseline. For HyenaDNA and ConvNova, we adopt the pooling methodology from HyenaDNA~\citep{nguyen2024hyenadna} and implement a linear layer to derive the logits.

Furthermore, we recognize the instability inherent in the datasets, where different random seeds may result in variations of up to 5 points. Therefore, we provide the mean and standard deviation (±) calculated from 10 random seeds.

The results of this benchmark suite are showcased in Table \ref{table:nt benchmark}, demonstrating the competitive performance of ConvNova. Notably, ConvNova outperforms Caduceus-ph, the second-best model, by 10 points despite having fewer parameters. Across nearly all tasks, ConvNova exhibits superior performance compared to a similarly sized HyenaDNA model, except for the splice sites acceptor. Additionally, ConvNova surpasses the transformer-based DNABERT-2 in 15 out of 18 tasks and NT-v2 in 12 out of 18 tasks despite having significantly fewer parameters. For more details, see \ref{app:nt}. 


Furthermore, we have also included previously popular supervised CNNs, LegNet~\citep{penzar2023legnet} and Basenji~\citep{kelley2018sequential}, in this benchmark. For more details, please refer to \ref{app:supvsfoundation}.

% \begin{figure}
% \raggedleft
% \begin{minipage}[b]{0.5\columnwidth}
% \centering
%   \rule{30pt}{40pt}

%   \caption{hhh}

%   \vspace{0pt}
% \end{minipage}%
% \begin{minipage}[b]{0.5\columnwidth}
% \centering

%   \begin{tabular}{ c c c }
%   \toprule
%   A & B & C \\
%   \midrule
%   1000 & 100 & 900 \\
%   \bottomrule
%   \end{tabular}

%   \vspace{0pt}
% \end{minipage}

% \subsubsection{DeepSTARR}
% DeepSTARR ~\citep{de2022deepstarr} is a regression problem aimed at predicting the functionality of enhancers, which are classified into development enhancers, active during developmental processes, and housekeeping enhancers, involved in basic cellular functions. The dataset consists of positive and negative samples, each with a length of 249 base pairs. Performance is evaluated using the mean Pearson correlation coefficient of Dev (Developmental) and HK (Housekeeping) enhancers. We compare ConvNova with HyenaDNA, Caduceus models, and a baseline CNN introduced in ~\citep{de2022deepstarr} finetuned for 20 epochs. As shown in Table \ref{table:deepstarr}, ConvNova surpasses all the baselines.
% \begin{wraptable}{r}{0.58\textwidth}

\subsubsection{Genomic Benchmark}
\begin{table}[bht]
  \caption{\textbf{Genomic Benchmark results.} Top-1 accuracy (↑) is reported for pretrained HyenaDNA, Caduceus-Ph, ConvNova, and the original CNN baseline (trained from scratch). The best values are in bold, and the second-best is underlined. ± indicates the error range across five random seeds.}
  \label{table:genomic_benchmark}
  \centering
  \adjustbox{max width=0.9\textwidth}{
  \begin{tabular}{lrrr>{\columncolor{low}}r}
    \toprule
    Task    & \textbf{CNN}        & \textbf{HyenaDNA}   & \textbf{Caduceus-Ph} & \textbf{ConvNova}  \\
             & (264K)     & (436K)     & (470K)      & (386K)   \\
    \midrule
    \rowcolor{titlebg} \textit{\textbf{Enhancers}} & & & & \\
    \midrule
    Mouse Enhancers         &  0.730 \small{±0.032} &  \underline{0.779} \small{±0.013} &  0.754 \small{±0.074} &  \textbf{0.784} \small{±0.009}     \\
    Human Enhancers Cohn    &  0.702 \small{±0.021} &  0.718 \small{±0.008} &  \textbf{0.747} \small{±0.004} &  \underline{0.743} \small{±0.005}  \\
    Human Enhancer Ensembl  &  0.744 \small{±0.122} &  0.832 \small{±0.006} &  \underline{0.893} \small{±0.008} &  \textbf{0.900} \small{±0.004}  \\
    \midrule
    \rowcolor{titlebg} \textit{\textbf{Species Classification}} & & & & \\
    \midrule
    Coding vs. Intergenomic &  0.892 \small{±0.008} &  0.904 \small{±0.008} &  \underline{0.915} \small{±0.003} &  \textbf{0.943} \small{±0.001}     \\
    Human vs. Worm          &  0.942 \small{±0.002} &  0.961 \small{±0.002} &  \textbf{0.973} \small{±0.001} &  \underline{0.967} \small{±0.002}   \\
    \midrule
    \rowcolor{titlebg} \textit{\textbf{Regulatory Elements}} & & & & \\
    \midrule
    Human Regulatory        &  0.872 \small{±0.005} &  0.862 \small{±0.004} &  \underline{0.872} \small{±0.011} &  \textbf{0.873} \small{±0.002}  \\
    Human Non-TATA Promoters &  0.861 \small{±0.009} &  0.887 \small{±0.005} &  \underline{0.946} \small{±0.007} &  \textbf{0.951} \small{±0.003}  \\
    Human OCR Ensembl       &  0.698 \small{±0.013} &  0.744 \small{±0.019} &  \textbf{0.828} \small{±0.006} &  \underline{0.793} \small{±0.004} \\
    \bottomrule
  \end{tabular}
  }
\end{table}
Next, we conduct a comprehensive evaluation using eight datasets introduced by GenomicsBenchmarks~\citep{grevsova2023genomic} with eight regulatory element classification tasks with sequence lengths spanning from 200 to approximately 2000bps. Our baselines comprise HyenaDNA, Caduceus-ph, and the original CNN model described in ~\citep{grevsova2023genomic}. We conduct experiments using five distinct random seeds and report the mean and the disparity between the maximum/minimum and the mean results.
 
As shown in Table \ref{table:genomic_benchmark}, ConvNova models outperform baselines in 5 tasks. In other tasks, ConvNova is competitive with the best models. Additionally, we also compared the performance of supervised CNNs, LegNet and Basenji, in this benchmark. See \ref{app:genomicbenchmark} and \ref{app:supvsfoundation} for additional experiment details.


\subsection{Long Range}
\subsubsection{BEND Gene Finding}
\begin{table}
\caption{\textbf{Gene Finding results.} MCC-score is reported for ConvNova and baseline models. The best value is in bold.}
\label{table:deepstarr}
\centering


\begin{tabular}{crrrr>{\columncolor{low}}r}
\toprule
% \multirow{3}{*}{DeepStarr}   & ConvNova        & HyenaDNA & Caduceus-Ph & Caduceus-Ps & CNN (from scratch) \\
%                              & (1.7M)         & (1.6M)   & (1.9M)      & (1.9M)      & (686K)            \\ \cmidrule(r){2-6}
%                              & \textbf{61.74} & 58.45    & 60.76       & 59.57       & 57.55             \\ \midrule
\multirow{3}{*}{\textbf{GeneFinding}} & \textbf{NT-H}     & \textbf{DNABERT-2}   & \textbf{GENA-LM}   & \textbf{HyenaDNA}   & \textbf{ConvNova}          \\
& (500M)   & (117M)      & (336M)    & (6.5M)     & (7.4M)            \\ \cmidrule(r){2-6}
                             & 0.41     & 0.43        & 0.52      & 0.35       & \textbf{0.55}     \\ \bottomrule
\end{tabular}


\vspace{0pt}
\end{table}
%7.4M
% Gene finding (~\citep{marin2023bend})is a multiclass classification task where every nucleotide is classified as either an exon (EF/ER), intron (IF/IR), donor splice site (DF/DR), acceptor splice site (AF/AR), or a noncoding region (NC), with the subscript F/R indicating the gene's strand orientation, forward or reverse. It is essential for understanding the functional roles of protein-coding regions within the genome.
Gene finding ~\citep{marin2023bend} is a multiclass classification task aimed at predicting the nucleotide types within DNA sequences (exons, introns, donors, acceptors, noncoding regions). This task aids in gene annotation and coding sequence identification. The dataset, derived from GENCODE annotations, includes labels $\{E_{F}, D_{F}, I_{F}, A_{F}, E_{R}, D_{R}, I_{R}, A_{R}, NC\}$.

\begin{wrapfigure}{r}{0.6\textwidth}
  \centering
  \vspace{-1.1em}
  \includegraphics[width=0.5\textwidth]{imgs/deepsea.png}
  \caption{\textbf{Chromatin Profile Prediction results.} AUC Score (↑) is reported for ConvNova, HyenaDNA, NT v2, DNABERT-2, and DeepATT performance on transcription factors (TF), DNase I hypersensitive sites (DHS), histone modifications (HM), and average score.}
  \label{fig:deepsea}
  \vspace{-1.1em}
\end{wrapfigure}

The task employs the GENCODE dataset ~\citep{harrow2012gencode}, comprising 5,976 DNA sequences spanning 1,433 to 14,000 bps. The objective is to classify each nucleotide based on its gene structure context, using local signals to predict exon-intron boundaries and long-range dependencies for accurate annotation. As shown in Table \ref{table:deepstarr}, our ConvNova model achieved the highest MCC of 0.55 on the gene-finding task, outperforming NT-H (0.41), DNABERT-2 (0.43), GENA-LM (0.52), and HyenaDNA (0.35). This demonstrates ConvNova's ability to leverage local and long-range dependencies for improved gene annotation.

% We employ the GENCODE dataset ~\citep{harrow2012gencode}, comprising 5,976 DNA sequences with lengths spanning from 1,433 to 14,000 base pairs. We perform finetuning of our pretrained ConvNova models on GENCODE and compare their performance with existing models such as HyenaDNA, Nucleotide Transformer, DNABERT-2 and GENA-LM. As demonstrated in Table \ref{table:deepstarr}, our ConvNova models outperform all the baselines. 

\subsubsection{Chromatin Profile Prediction}
This classification task~\citep{zhou2015predicting}  focuses on predicting chromatin profiles and epigenetic markers from DNA sequences, which is crucial for quantifying the functional effects of non-coding variants. The dataset comprises 919 chromatin features, including transcription factor (TF) binding profiles, DNase I hypersensitive sites (DHS), and histone mark (HM) profiles. For a given DNA sequence of length 1,000 bps, the task involves jointly predicting 919 binary classes corresponding to the chromatin profile of a central region of the sequence. We fine-tune our pretrained ConvNova models for 10 epochs, along with all baseline models, which range from 436K (tiny HyenaDNA) to 500M (NT-v2). Notably, ConvNova outperforms all baseline models, including DeepATT~\citep{li2021deepatt}, which is a previously state-of-the-art supervised model for this task, as illustrated in Figure \ref{fig:deepsea}.


\begin{wraptable}{r}{0.6\textwidth}
% \vspace{-20pt}
% \raggedleft
% \begin{minipage}[h!]{0.55\columnwidth}
\caption{\textbf{Comparison of dilation and downsampling in ConvNova.} Performance (MCC-score or F1-score) is reported on selected NT benchmark tasks. The best values are in bold.}
\centering
\setlength\tabcolsep{9.00pt}
\resizebox{0.5\textwidth}{!}{
\begin{tabular}{lr>{\columncolor{low}}rr}
\toprule
    \textbf{Task}   & \textbf{Downsampling}  & \textbf{Dilation}  \\ 
       & (1.7M) & (1.7M) \\
    % \multicolumn{7}{c}{xxx}                   \\
    % \cmidrule(r){1-7}
    \midrule
    H3               & 65.20     & \textbf{81.62}          \\ 
    H3K4me1          & 34.88     & \textbf{56.37}          \\
    H3K9ac           & 48.81     & \textbf{68.98}          \\
    Promoter All     & 93.69     & \textbf{96.99}          \\
    Splice Sites All & 45.65     & \textbf{96.45}          \\
\bottomrule
\end{tabular}
\label{table:downsample}
}
\end{wraptable}

Moreover, we provide compelling evidence of ConvNova's scalability when ample data is available. As we augment the model's parameter count from 6.8M to 51.1M, ConvNova shows a discernible improvement in the performance capabilities exhibited. See Appendix~\ref{app:deepsea} for experiment details and comparing different model sizes and training methods, whether pretrained or from scratch. Remarkably, without pretraining, ConvNova outperforms all Hyena-DNA models and DeepATT under the same epoch hyperparameter settings, even with a smaller parameter size.

% We use dilation to control the receptive field in histone tasks from NT-benchmark. H3K4me2, H3K4me3, and H3K14ac show significantly improved classification accuracy when the receptive field covers about 15\% of the input length, compared to a global receptive field.

% The enhancement effects of H3K14ac and H3K4me3 align with previous biological research~\citep{ramakrishnan2016counteracting}, which observed that H3K14ac and H3K4me3 are highly enriched within approximately 200 bps, indicating their strong localized characteristics.

% \textbf{H3K4me2} also exhibited a similar enhancement effect under the one dilation setting. However, to our knowledge, no existing studies on H3K14ac have found similar characteristics in the former two histones. This suggests that there might be unknown biological mechanisms at play.

% \begin{table}
% \caption{Gene Finding}
% \label{table:genefinding}
% \centering
% % \resizebox{0.8\columnwidth}{!}{
% \begin{tabular}{l|lllll}
% \toprule
%   Model & ConvNova & NT-H & DNABERT-2 & GENA-LM BERT & HyenaDNA-large  \\ & (7.4M) & (500M) & (117M) & (336M) & (6.5M) \\
%     % \multicolumn{7}{c}{xxx}                   \\
%     % \cmidrule(r){1-7}
%     \midrule
%    mcc &   \textbf{0.55}      & 0.41 & 0.43      & 0.52         & 0.35    \\ 
% \bottomrule
% \end{tabular}
% % }
% \end{table}



\subsection{Ablation}

\subsection{Dilation or Downsampling}\label{downsample}
In image processing, the U-Net~\citep{ronneberger2015u} architecture has been proven highly effective through its use of downsampling and upsampling. Downsampling reduces image size while increasing the receptive field, enabling the capture of broader contextual information. Additionally, dilation, another method to increase the receptive field, expands the convolutional operation's receptive field by introducing gaps within the convolution kernel.


In DNA sequence modeling tasks, both the upsampling-downsampling structure and dilation convolution represent potentially viable approaches. For the dilation mechanism, we use the design shown in Figure \ref{fig:dnacnn}. For the downsampling architecture, we implement a variant of ConvNova with U-Net style, maintaining the gating mechanism. We retain the same pretraining settings and parameter size (1.7M) and conduct comparative experiments on randomly selected tasks within the NT benchmark. 

Due to the significant performance gap observed as shown in Table \ref{table:downsample}, we opt not to conduct multiple experiments using ten different random seeds. Instead, we only utilize a single random seed. It is evident that while the downsampling (U-Net style) architecture can approximate the performance achieved using dilation in the `promoter all' task, it significantly lags behind in other tasks, even decreasing by 50 points in `splice sites all'. 

\subsection{Key Designs}\label{keydeign}
\begin{wraptable}{r}{0.6\textwidth}
  \vspace{-1.1em}
  \caption{\textbf{Ablation study results.} MCC-score (↑) is reported for performance comparison across different models. `w/o Gate' represents the ablation of the Gate mechanism, while `Single Branch' is the ablation of the double-branch structure in ConvNova. The best values are in bold, and the second-best is underlined. ± indicates the error range across experiments}
  \label{table:ablation}
  \centering
  \resizebox{0.5\textwidth}{!}{
  \begin{tabular}{lrr>{\columncolor{low}}rr}
    \toprule
    \rowcolor{gray!20} \textbf{Task}        & \textbf{w/o Gate}   & \textbf{Single Branch} & \textbf{ConvNova}        \\
    \midrule
    H3                  &   78.96 \small{±1.46}  &  \underline{80.95} \small{±1.61}   &  \textbf{81.50} \small{±0.80}    \\ 
    H3K4me1             &  \textbf{57.83} \small{±1.87}  &   \underline{56.45} \small{±1.58}   &   56.60 \small{±1.01}    \\ 
    H3K4me2             &   52.52 \small{±2.59}  &   50.20 \small{±1.92}   &  \textbf{53.72} \small{±2.42}    \\
    H3K4me3             &   54.45 \small{±1.31}  &   \underline{58.66} \small{±0.97}   &  \textbf{60.20} \small{±1.91}    \\ 
    H3K9ac              &   63.54 \small{±2.20}  &   \underline{66.87} \small{±0.69}   &  \textbf{68.10} \small{±1.91}    \\
    H3K14ac             &   63.83 \small{±1.03}  &   \underline{65.34} \small{±2.12}   &  \textbf{66.19} \small{±1.84}    \\
    H3K36me3            &   64.12 \small{±1.46}  &   \underline{66.77} \small{±1.42}   &  \textbf{68.31} \small{±1.19}    \\
    H3K79me3            &   69.49 \small{±1.75}  &   \underline{71.23} \small{±1.37}   &  \textbf{72.08} \small{±1.23}    \\
    H4                  &   79.27 \small{±1.09}  &   \underline{80.55} \small{±0.61}   &  \textbf{81.12} \small{±0.93}    \\
    H4ac                &   62.02 \small{±2.28}  &   \underline{63.07} \small{±1.10}   &  \textbf{64.75} \small{±1.90}    \\   
    \bottomrule
  \end{tabular}}
  \vspace{-1.1em}
\end{wraptable}
We conduct ablation experiments on the gate mechanism and the double-branch design in ConvNova. We implement an ordinary gate convolution model with the same parameter count (1.7M) named ``Single Branch'' in Table \ref{table:ablation} to compare with the double-branch structure, and an additive aggregation model (1.7M) named ``w/o Gate'' in Table \ref{table:ablation} to assess the role of the gate mechanism. We select homologous protein tasks from the NT benchmark and maintain the same method of selecting ten random seeds as described in 
%Section.
\S 
\ref{exp:NT} for comparison. For the details, refer to \S \ref{app:ablation}.

The results indicate that both the feature aggregation method and the gate mechanism in ConvNova are crucial design components, effectively supporting the overall model capability.

For detailed ablation on kernel size, dilation rate, please refer to \S \ref{app:dilation_kernel_ablation}.