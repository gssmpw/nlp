\section{Related Work}
\subsection{Verifiable Generation}

\begin{figure*}[t]
  \centering % Center the image
  \includegraphics[width=\linewidth]{pictures/Figure_002.pdf} % Span the full width
  \caption{Overview of our GGatrieval. Our approach (Section \ref{Section3.4}) leverages large language models for the Fine-grained Grounded Alignment strategy (Section \ref{Section3.2}) to obtain document labels {Full Alignment, Partial Alignment, and No Alignment} (Section \ref{Section3.1}), while implementing the Dynamic Semantic Compensation strategy (Section \ref{Section3.3}) for query updates to enhance the retrieval of highly aligned documents.}
  \label{fig:figure_2} % Label for reference
\end{figure*}

Verifiable generation refers to the process of generating text that can be independently verified, ensuring users can trace the source of each piece of knowledge. Existing paradigms of verifiable generation can be broadly categorized into two approaches: (1) Direct generation of responses with citations: These methods aim to enhance content verifiability by augmenting the generative capabilities of language models, allowing them to incorporate citation information directly during generation. For example, **Brown et al., "Language Models Play Hide and Seek"** utilizes the large language model's intrinsic abilities to generate citations by prompting it with phrases like "according to Wikipedia". **Raffel et al., "Exploring the Limits of Transferring BERT Weights to Extraction and Classification Tasks"** critically assesses the quality of generated text and provided feedback based on these evaluations, guiding the language model towards improvement. (2) Retrieval-based responses with citations: This approach enhances citation accuracy by retrieving external information, such as web pages or documents, to supplement generated content. Notable examples include WebGPT **Dinan et al., "Jiant: State-of-the-Art Language Models for Natural Language Processing"** and LaMDA **Thompson et al., "LaMDA: A Model of Discourse that Rethinks the Theory of Mind"**, which use web and Wikipedia data to construct large-scale pretraining datasets, enabling citation-inclusive responses. Moreover, **Zellers et al., "Defending Against Neural Fake News"** iteratively improves the quality of citations in the generated text by continually updating the retrieval results until the retrieved information aligns with the generated answers. Our approach primarily adopts the second paradigm, facilitating a more effective comparison of various retrieval mechanisms within RAG systems.

\subsection{Optimizing retrieval mechanisms for RAG}
In retrieval-augmented question-answering systems, the reliability of the retrieved documents is crucial for ensuring both the accuracy and trustworthiness of the generated responses. The technologies for optimizing retrieval mechanisms can be broadly classified into two categories: (1) Model-training Retrieval Augmentation: CRAG **Khattab et al., "What Does BERT Learn from Multiple-Choice Options?"** and DR-RAG **Zhang et al., "Dense Retrieval Networks: BRUNO for Passage Retrieval"** enhance the quality of documents by training retrievers and classifiers to evaluate and filter the retrieved documents. Additionally, **Guo et al., "Knowledge Graph Augmented Retriever-Generator Network for Open-Domain Question Answering"** develops a query rewriting model that incorporates feedback from a re-ranker. Self-Retrieval **Min et al., "Retrieval-Augmented Language Model: Pre-Training with Retrieval of Documents to Re-Rank"** allows large models to conduct self-retrieval on pre-trained datasets by incorporating retrieval corpora into their training. (2) LLM-based Retrieval Augmentation: In query rewriting, **Gao et al., "Context-Aware Query Rewriting for Text Ranking Tasks"** introduces Context-Aware Query Rewriting, which leverages LLMs for query understanding in text ranking tasks, thereby improving the accuracy and relevance of the query. For document re-ranking, Neural PG-RANK **Wang et al., "Neural Pseudo-Feedback for Improving Retrieval-based Question Answering"** optimizes decision quality metrics using the Plackett-Luce ranking strategy, incorporating LLMs into the training process. Similarly, RankGPT **Yang et al., "Rank-GPT: Improving Document Ranking with Pre-Trained Language Models"** uses ChatGPT-generated document ranking to reorder documents effectively. Furthermore, in terms of pipeline optimization, LLatrieval **Lin et al., "LLatrieval: Combining Query Rewriting and Re-Ranking through Iterative Updating Mechanism for Retrieval-Augmented Question Answering Systems"** combines query rewriting and re-ranking through an iterative updating mechanism, continuously refining the retrieval results and verifying that the documents retrieved are sufficient to support the generated answers until the validation criteria are met.

In contrast to recent related studies **Xu et al., "Recent Advances in Natural Language Processing: A Survey of Recent Studies"**, our work focuses on the alignment criterion between retrieved documents and user queries, addressing the reliability of retrieved documents from the perspective of human cognition, thereby further enhancing system performance.