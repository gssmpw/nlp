@inproceedings{li-etal-2024-llatrieval,title = "{LL}atrieval: {LLM}-Verified Retrieval for Verifiable Generation",author = "Li, Xiaonan and Zhu, Changtai and Li, Linyang and Yin, Zhangyue and Sun, Tianxiang and Qiu, Xipeng",editor = "Duh, Kevin and Gomez, Helena and Bethard, Steven",booktitle = NAACL:2024:long,month = jun,year = "2024",address = "Mexico City, Mexico",publisher = acl,url = anth # {2024.naacl-long.305/},doi = "10.18653/v1/2024.naacl-long.305",pages = "5453--5471"
}

@article{ref22,
  title={Towards reliable and fluent large language models: Incorporating feedback learning loops in qa systems},
  author={Lee, Dongyub and Whang, Taesun and Lee, Chanhee and Lim, Heuiseok},
  journal={arXiv preprint arXiv:2309.06384},
  year={2023}
}

@article{ref26,
  title={Webgpt: Browser-assisted question-answering with human feedback},
  author={Nakano, Reiichiro and Hilton, Jacob and Balaji, Suchir and Wu, Jeff and Ouyang, Long and Kim, Christina and Hesse, Christopher and Jain, Shantanu and Kosaraju, Vineet and Saunders, William and others},
  journal={arXiv preprint arXiv:2112.09332},
  year={2021}
}

@article{ref28,
  title={Lamda: Language models for dialog applications},
  author={Thoppilan, Romal and De Freitas, Daniel and Hall, Jamie and Shazeer, Noam and Kulshreshtha, Apoorv and Cheng, Heng-Tze and Jin, Alicia and Bos, Taylor and Baker, Leslie and Du, Yu and others},
  journal={arXiv preprint arXiv:2201.08239},
  year={2022}
}

@article{ref31,
  title={Corrective retrieval augmented generation},
  author={Yan, Shi-Qi and Gu, Jia-Chen and Zhu, Yun and Ling, Zhen-Hua},
  journal={arXiv preprint arXiv:2401.15884},
  year={2024}
}

@article{ref32,
  title={Dr-rag: Applying dynamic document relevance to retrieval-augmented generation for question-answering},
  author={Hei, Zijian and Liu, Weiling and Ou, Wenjie and Qiao, Juyi and Jiao, Junming and Song, Guowen and Tian, Ting and Lin, Yi},
  journal={arXiv preprint arXiv:2406.07348},
  year={2024}
}

@article{ref33,
  title={RaFe: Ranking Feedback Improves Query Rewriting for RAG},
  author={Mao, Shengyu and Jiang, Yong and Chen, Boli and Li, Xiao and Wang, Peng and Wang, Xinyu and Xie, Pengjun and Huang, Fei and Chen, Huajun and Zhang, Ningyu},
  journal={arXiv preprint arXiv:2405.14431},
  year={2024}
}

@article{ref34,
  title={Self-Retrieval: Building an Information Retrieval System with One Large Language Model},
  author={Tang, Qiaoyu and Chen, Jiawei and Yu, Bowen and Lu, Yaojie and Fu, Cheng and Yu, Haiyang and Lin, Hongyu and Huang, Fei and He, Ben and Han, Xianpei and others},
  journal={arXiv preprint arXiv:2403.00801},
  year={2024}
}

@article{ref41,
  title={Context Aware Query Rewriting for Text Rankers using LLM},
  author={Anand, Abhijit and Venktesh, V and Setty, Vinay and Anand, Avishek},
  journal={CoRR},
  year={2023}
}

@inproceedings{ref43,
  title={Policy-Gradient Training of Language Models for Ranking},
  author={Gao, Ge and Chang, Jonathan Daniel and Cardie, Claire and Brantley, Kiant{\'e} and Joachims, Thorsten},
  booktitle={NeurIPS 2023 Foundation Models for Decision Making Workshop}
}

@inproceedings{sun-etal-2023-chatgpt,title = "Is {C}hat{GPT} Good at Search? Investigating Large Language Models as Re-Ranking Agents",author = "Sun, Weiwei and Yan, Lingyong and Ma, Xinyu and Wang, Shuaiqiang and Ren, Pengjie and Chen, Zhumin and Yin, Dawei and Ren, Zhaochun",editor = "Bouamor, Houda and Pino, Juan and Bali, Kalika",booktitle = EMNLP:2023:main,month = dec,year = "2023",address = "Singapore",publisher = acl,url = anth # {2023.emnlp-main.923/},doi = "10.18653/v1/2023.emnlp-main.923",pages = "14918--14937"
}

@inproceedings{weller-etal-2024-according,title = "{\textquotedblleft}According to . . . {\textquotedblright}: Prompting Language Models Improves Quoting from Pre-Training Data",author = "Weller, Orion and Marone, Marc and Weir, Nathaniel and Lawrie, Dawn and Khashabi, Daniel and Van Durme, Benjamin",editor = "Graham, Yvette and Purver, Matthew",booktitle = EACL:2024:long,month = mar,year = "2024",address = "St. Julian{'}s, Malta",publisher = acl,url = anth # {2024.eacl-long.140/},pages = "2288--2301"
}

