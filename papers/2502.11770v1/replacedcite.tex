\section{Related Work}
\subsection{Verifiable Generation}

\begin{figure*}[t]
  \centering % Center the image
  \includegraphics[width=\linewidth]{pictures/Figure_002.pdf} % Span the full width
  \caption{Overview of our GGatrieval. Our approach (Section \ref{Section3.4}) leverages large language models for the Fine-grained Grounded Alignment strategy (Section \ref{Section3.2}) to obtain document labels {Full Alignment, Partial Alignment, and No Alignment} (Section \ref{Section3.1}), while implementing the Dynamic Semantic Compensation strategy (Section \ref{Section3.3}) for query updates to enhance the retrieval of highly aligned documents.}
  \label{fig:figure_2} % Label for reference
\end{figure*}

Verifiable generation refers to the process of generating text that can be independently verified, ensuring users can trace the source of each piece of knowledge. Existing paradigms of verifiable generation can be broadly categorized into two approaches: (1) Direct generation of responses with citations: These methods aim to enhance content verifiability by augmenting the generative capabilities of language models, allowing them to incorporate citation information directly during generation. For example, ____ utilizes the large language model's intrinsic abilities to generate citations by prompting it with phrases like "according to Wikipedia". ____ critically assesses the quality of generated text and provided feedback based on these evaluations, guiding the language model towards improvement. (2) Retrieval-based responses with citations: This approach enhances citation accuracy by retrieving external information, such as web pages or documents, to supplement generated content. Notable examples include WebGPT ____ and LaMDA ____, which use web and Wikipedia data to construct large-scale pretraining datasets, enabling citation-inclusive responses. Moreover, ____ iteratively improves the quality of citations in the generated text by continually updating the retrieval results until the retrieved information aligns with the generated answers. Our approach primarily adopts the second paradigm, facilitating a more effective comparison of various retrieval mechanisms within RAG systems.

\subsection{Optimizing retrieval mechanisms for RAG}
In retrieval-augmented question-answering systems, the reliability of the retrieved documents is crucial for ensuring both the accuracy and trustworthiness of the generated responses. The technologies for optimizing retrieval mechanisms can be broadly classified into two categories: (1) Model-training Retrieval Augmentation: CRAG ____ and DR-RAG ____ enhance the quality of documents by training retrievers and classifiers to evaluate and filter the retrieved documents. Additionally, ____ develops a query rewriting model that incorporates feedback from a re-ranker. Self-Retrieval ____ allows large models to conduct self-retrieval on pre-trained datasets by incorporating retrieval corpora into their training. (2) LLM-based Retrieval Augmentation: In query rewriting, ____ introduces Context-Aware Query Rewriting, which leverages LLMs for query understanding in text ranking tasks, thereby improving the accuracy and relevance of the query. For document re-ranking, Neural PG-RANK ____ optimizes decision quality metrics using the Plackett-Luce ranking strategy, incorporating LLMs into the training process. Similarly, RankGPT ____ uses ChatGPT-generated document ranking to reorder documents effectively. Furthermore, in terms of pipeline optimization, LLatrieval ____ combines query rewriting and re-ranking through an iterative updating mechanism, continuously refining the retrieval results and verifying that the documents retrieved are sufficient to support the generated answers until the validation criteria are met.

In contrast to recent related studies ____, our work focuses on the alignment criterion between retrieved documents and user queries, addressing the reliability of retrieved documents from the perspective of human cognition, thereby further enhancing system performance.