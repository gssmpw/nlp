@article{bai2024measuring,
  title={Measuring implicit bias in explicitly unbiased large language models},
  author={Bai, Xuechunzi and Wang, Angelina and Sucholutsky, Ilia and Griffiths, Thomas L},
  journal={arXiv preprint arXiv:2402.04105},
  year={2024}
}

@article{bi2023group,
  title={A Group Fairness Lens for Large Language Models},
  author={Bi, Guanqun and Shen, Lei and Xie, Yuqiang and Cao, Yanan and Zhu, Tiangang and He, Xiaodong},
  journal={arXiv preprint arXiv:2312.15478},
  year={2023}
}

@article{del2024angry,
  title={Angry Men, Sad Women: Large Language Models Reflect Gendered Stereotypes in Emotion Attribution.},
  author={del Arco, Flor Miriam Plaza and Curry, Amanda Cercas and Curry, Alba and Abercrombie, Gavin and Hovy, Dirk},
  journal={CoRR},
  year={2024}
}

@inproceedings{kotek2023gender,
  title={Gender bias and stereotypes in large language models},
  author={Kotek, Hadas and Dockum, Rikker and Sun, David},
  booktitle={Proceedings of the ACM collective intelligence conference},
  pages={12--24},
  year={2023}
}

