[
  {
    "index": 0,
    "papers": [
      {
        "key": "parrish-etal-2022-bbq",
        "author": "Parrish, Alicia and Chen, Angelica and Nangia, Nikita and Padmakumar, Vishakh and Phang, Jason and Thompson, Jana and Htut, Phu Mon and Bowman, Samuel",
        "title": "{BBQ}: A hand-built bias benchmark for question answering"
      },
      {
        "key": "nangia-etal-2020-crows",
        "author": "Nangia, Nikita and Vania, Clara and Bhalerao, Rasika and Bowman, Samuel R.",
        "title": "{C}row{S}-Pairs: A Challenge Dataset for Measuring Social Biases in Masked Language Models"
      },
      {
        "key": "nadeem-etal-2021-stereoset",
        "author": "Nadeem, Moin and Bethke, Anna and Reddy, Siva",
        "title": "{S}tereo{S}et: Measuring stereotypical bias in pretrained language models"
      },
      {
        "key": "marchiori-manerba-etal-2024-social",
        "author": "Marchiori Manerba, Marta and Stanczak, Karolina and Guidotti, Riccardo and Augenstein, Isabelle",
        "title": "Social Bias Probing: Fairness Benchmarking for Language Models"
      },
      {
        "key": "bi2023group",
        "author": "Bi, Guanqun and Shen, Lei and Xie, Yuqiang and Cao, Yanan and Zhu, Tiangang and He, Xiaodong",
        "title": "A Group Fairness Lens for Large Language Models"
      },
      {
        "key": "del2024angry",
        "author": "del Arco, Flor Miriam Plaza and Curry, Amanda Cercas and Curry, Alba and Abercrombie, Gavin and Hovy, Dirk",
        "title": "Angry Men, Sad Women: Large Language Models Reflect Gendered Stereotypes in Emotion Attribution."
      },
      {
        "key": "kotek2023gender",
        "author": "Kotek, Hadas and Dockum, Rikker and Sun, David",
        "title": "Gender bias and stereotypes in large language models"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "bai2024measuring",
        "author": "Bai, Xuechunzi and Wang, Angelina and Sucholutsky, Ilia and Griffiths, Thomas L",
        "title": "Measuring implicit bias in explicitly unbiased large language models"
      },
      {
        "key": "smith-etal-2022-im",
        "author": "Smith, Eric Michael and Hall, Melissa and Kambadur, Melanie and Presani, Eleonora and Williams, Adina",
        "title": "{\\textquotedblleft}{I}`m sorry to hear that{\\textquotedblright}: Finding New Biases in Language Models with a Holistic Descriptor Dataset"
      }
    ]
  }
]