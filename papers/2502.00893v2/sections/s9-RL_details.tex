\subsection{Reinforcement Learning Details}
\label{sec:rl_details}

\input{captions/ts5-RL_parameters}
\input{captions/ts6-RL_reward}

The RL implementation leverages MuJoCo XLA~\citep{todorov2012mujoco} and Brax~\citep{brax2021github}. We train the policy using PPO~\citep{schulman2017proximal} with hyperparameters listed in Table~\ref{tab:hyperparameters}.
Inspired by prior work~\citep{gu2024humanoidgym, gu2024advancing}, our reward function is shaped by three categories of reward terms as detailed in Table~\ref{tab:reward_scales}. Domain randomization is applied to body mass, geometry friction, and all parameters of the actuation model listed in Table~\ref{tab:motor_parameters}. Full implementation details are available in our open-source codebase.
During inference, the RL policy runs on the CPU of Jetson Orin NX 16GB, achieving a $50~\mathrm{Hz}$ control loop while leaving the GPU available for other policies and models.