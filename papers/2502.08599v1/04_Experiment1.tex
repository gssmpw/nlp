\section{Automated Evaluation with Fictional Characters}
To examine the viability of the framework in capturing and representing an individual’s self-concept, we first conducted an automated evaluation using popular U.S. drama characters. Specifically, we aimed to assess how well each component (S, P, and C), both individually and in combination, represents key aspects of an individual’s identity.

In doing so, we performed a comprehensive analysis to evaluate the contribution of each component by testing all possible combinations, resulting in seven distinct conditions (S, P, C, SP, SC, PC, and SPC). The composition of the character profiles varied according to these conditions. This systematic approach allowed us to investigate the individual and combined effects of each element on the overall performance of the framework. Building on this, we conducted experiments using fictional characters from popular U.S. TV dramas, assuming that these characters provided S, P, and C information as specified by our framework. Specifically, we used the ``Guess Who Test'' and the ``Twenty Statements Test'' (TST), as outlined below.


\begin{figure*}[h]
    \centering
    \includegraphics[width=\linewidth, height=0.60\linewidth, keepaspectratio]{Figure2_eval_procedure.png}
    \caption{Guess Who \& TST Evaluation Procedure}
    \label{fig:2}
\end{figure*}

\subsection{Building Fictional Character Profile}

To build the dataset for automated evaluation, we began by reviewing the top 100 most-watched TV shows on IMDb \footnote{https://www.imdb.com/list/ls512407256/}, specifically limiting our selection to programs set in the U.S. within the drama or comedy genres. Our goal was to represent the multidimensional identities of ordinary people rather than real-world celebrities or extraordinary characters (e.g., vampires). Accordingly, many sitcoms were naturally chosen for their portrayal of realistic, day-to-day situations and character dynamics, aligning with our objective of modeling typical individuals. Based on these criteria, we selected six shows, including \textit{Friends, Modern Family, New Girl, and The Big Bang Theory}, which feature relatable, everyday characters. We then finalized a list of 45 characters from these series, all of whom appeared in more than 60\% of the episodes. A detailed list of characters is available in  \ref{sec:appendix_automatic_evalcharacter_list}.


To simulate data where these characters hypothetically provided information for the SPC components, we employed GPT-4o \citep{yuan_evaluating_2024} using a zero-shot learning approach. This allowed us to generate the profile of each drama character (see \ref{sec:appendix_profile_example_S_A1} to \ref{sec:appendix_profile_example_C_A3}, created based on Sheldon Cooper from \textit{The Big Bang Theory}).


Subsequently, a rigorous manual validation process of this data was conducted involving two independent coders familiar with the selected TV shows. Each coder independently assessed the character profiles to ensure the accuracy and consistency of the generated information. Additionally, to address potential self-alignment bias in LLMs, particular attention was given to anonymizing direct references to character names and specific locations within the profile data. For instance, identifiable elements, such as ``Central Perk'' from \textit{Friends}, were replaced with generic descriptions (e.g., “a park”). This anonymization step was essential in preventing LLMs from ``memorizing'' or ``reproducing'' known character details. Additionally, the profiles were cross-checked with relevant wiki pages to ensure alignment with publicly available data.


\subsection{Guess Who Evaluation}
We evaluated the SPeCtrum framework's ability to capture character identity using a ``Guess Who?'' paradigm, building on \citet{sang_tvshowguess_2022}. In this method, we tested the accuracy of identifying characters and TV series from generated profiles across conditions. By comparing identification accuracy across seven conditions, we assessed the contribution of each element to character identification (see Figure \ref{fig:2}). For this experiment, we utilized four LLMs for testing: Claude-3.5-Sonnet, Claude-3-Sonnet, GPT-4o, and GPT-3.5 Turbo. Each model was presented with character profiles consisted under the seven conditions and prompted to identify the character and their corresponding TV series with reasons behind their choices, ensuring that their guesses resulted from a valid reasoning process (see \ref{sec:appendix_automatic_guess_who}). 


\subsubsection{Results: Dominant Role of Personal Life Context (C) in Character Identification}
To determine whether statistically significant differences existed in the number of correct identifications (TRUE) across conditions, we conducted chi-squared tests. The results revealed a significant relationship between the conditions and identification accuracy across all LLMs (\textit{p} < .001) (see Figure \ref{fig:3}). Post-hoc analyses were then performed to identify specific differences between conditions. To address the multiple comparisons issue, we applied the Benjamini-Hochberg procedure for all pairwise comparisons (\citealp{thissen2002quick}).

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{Figure3_guess_who_result.png}
    \caption{Character Identification Accuracy in Guess Who Evaluation across LLMs and Conditions}
    \label{fig:3}
\end{figure}


The post-hoc analyses revealed a consistent hierarchy in predictive abilities: P < S < C, with significant differences across all models (adjusted \textit{p} < .001). The effectiveness of combining elements was also examined. SP < C was significant across all models (adjusted \textit{p} < .001). Furthermore, no significant differences were found between SPC - C, PC - C, and SC - C, suggesting that C alone was just as effective as combining all components. These findings underscore the substantial impact of C in capturing one's identity, while the minimal benefit of combining C with other elements challenges the assumption that more information always improves character representation.


\subsection{TST Evaluation Adopting the Johari Window}
Next, we evaluated the SPeCtrum framework in capturing diverse aspects of self-concept using the Twenty Statements Test (TST), a psychological assessment tool used to measure an individual's self-concept by asking them to complete twenty sentences starting with ``I am...'' \citep{kuhn2017empirical}. Specifically, based on the Johari Window model \citep{luft1955johari}, we prompted the LLMs to generate 10 open-self statements (traits known to both the self and others) and 10 hidden-self statements (traits known only to the self) based on the provided profile information for each of the conditions (see \ref{sec:appendix_automatic_tst}).

Parallel to the previous evaluation, the same set of four LLMs was provided with profiles constructed based on the seven conditions. The LLMs were then tasked with embodying each character and instructed to generate 10 open-self and 10 hidden-self statements (see \ref{sec:appendix_automatic_tst_evaluation}). (Sheldon Cooper's example TST statements across conditions are provided in \ref{sec:appendix_automatic_tst_examples}.)

To assess the validity of the generated TST statements, we utilized GPT-4o, the SOTA model at the time, as an evaluator agent. GPT-4o assumed the role of the specific character and evaluated each TST statement for its relevance and accuracy, providing a binary 'Yes' or 'No' response with an explanation (see Figure \ref{fig:2}). This allowed us to assess how well the personas generated under each condition captured both the open and hidden facets of the character's self-concept.

\subsubsection{Results: Role of Personal Identity (P) in Enhancing Self-Concept Representation}

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{tst_size_up.png}
    \caption{Accuracy of TST Statements across LLMs and Conditions}
    \label{fig:4}
\end{figure}


Chi-squared tests revealed significant differences across the seven conditions for all four LLMs overall (\textit{p} < .001 for all LLMs) (see Figure \ref{fig:4}). Consistent with the ``Guess Who'' evaluation results, C consistently emerged as the most explanatory factor in representing characters' self-concept, outperforming S and P alone (adjusted \textit{p} < .001). Additionally, C consistently outperformed the combination of S and P (S, P, SP) across all models (adjusted \textit{p} < .001) and performed comparably to SPC, highlighting the critical role of contextual information (C) in capturing characters' self-concept.

When examining the open and hidden self conditions separately, we observed a similar pattern of results as when they were not differentiated. Notably, the difference between the S and SP conditions was only pronounced in hidden-self statements. While the explanatory power of P and S did not significantly differ in representing the open self, P exhibited significantly higher explanatory power than S for the hidden self in three out of four LLM models (adjusted \textit{p} < .001). This suggests that P may play some role in capturing the hidden aspects of an individual's self-concept.


\subsection{Inferring Social (S) and Personal (P) Attributes from Personal Life Context (C)}
\label{sec:inference_test}
The surprising effectiveness of C in identifying characters and describing self-concepts prompted further exploration. Specifically, since C involves short essays about daily routines and preferences—rather than directly asking questions about one's self-concept—its greater explanatory power compared to the standardized and direct measures of S and P was intriguing. This led us to hypothesize that the contextual information in C might encompass both S and P.

To test this hypothesis, we employed GPT-4o to infer S and P from C alone for 45 characters, running five iterations for robustness. LLM agents, initialized only with C, were tasked with completing demographic (S), personality, and value assessments (P). We then compared their responses to verified character profiles, using these as the ``golden answers.'' High accuracy (for categorical items such as race) and strong correlation (for ordinal variables such as education level) would support C as an integrated identity representation, explaining its strong effectiveness in automated evaluations.

In the results, Social Identity (S) inference from C produced robust results for most categorical items: sex (97\% accuracy), gender (95\%), disability status (96\%), nationality (89\%), race (86\%), and sexual orientation (79\%).  However, inference performance for ethnicity (45\%) and religion (40\%) was relatively lower. For most ordinal variables, the results showed moderately strong correlations: age (Spearman's $\rho$ = 0.59, \textit{p} < .001),  socioeconomic indicators (household income: $\rho$ = 0.68, perceived income position: $\rho$ = 0.62), and social class ($\rho$ = 0.67). However, Education level ($\rho$ = 0.41) and political stance ($\rho$ = 0.45) showed weaker yet moderate correlations, suggesting these aspects could be challenging to infer from C alone.

The reconstruction of Personal Identity elements (P) from C demonstrated significantly positive correlations. For BFI-2-S personality traits, we observed a moderately strong Pearson correlation of 0.686 (SD = 0.29). PVQ value traits also showed strong alignment, with a mean correlation of 0.71 (SD = 0.25).

Overall, these results provide robust evidence for our hypothesis that C may serve as a holistic representation of identity, effectively encompassing both S and P, at least for popular drama characters.


