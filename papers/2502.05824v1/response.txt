\section{Related Work}
\label{sec:Related Work}

\par This section comprehensively introduces major related studies about UAV communications, collaborative beamforming, and multi-objective optimization.

\subsection{UAV-assisted Terrestrial Communications}
\label{subsec:UAV-assisted Terrestrial Communications}

\par Several existing works have utilized UAVs to support terrestrial communications. For instance, the authors in Chen et al., "Joint Optimization of Radio Resource Allocation and Flight Altitude for Energy Efficiency in UAV-Assisted D2D Networks" investigated a UAV-assisted device-to-device communication network wherein a UAV acts as an aerial BS to provide communication services for ground terminals. In this scenario, energy efficiency is optimized through the joint optimization of radio resource allocation and flight altitude, considering the imperfections in channel state and coordinate information. The authors in Li et al., "Swarm Intelligence-Based Deployment of UAVs for Search and Rescue Scenarios" envisioned a search and rescue scenario in which a swarm of UAVs is employed to provide downlink communication coverage over an unknown mission area. The objective is to maximize the wireless coverage provided by the UAVs by designing the quasistationary deployment of the UAVs. The authors in Zhang et al., "Free Space Optical Communication System for Aerial Terrestrial Networks" studied an air-to-ground free space optical communication system, which provides communication between a UAV and terrestrial terminals, proposing a low-complexity approach aimed at maximizing the flight time of the UAV. The authors in Wang et al., "Resource Allocation for Multiuser Downlink UAV Communication Systems" considered a robust resource allocation method for a multiuser downlink UAV communication system with the objective of minimizing total power consumption. Moreover, the authors in Gao et al., "UAV-Assisted IoT Communication Network" investigated a UAV-assisted Internet-of-Things (IoT) communication network. In this study, a group of UAVs was dispatched in an urban area by using the wireless resources of the base station (BS) to serve IoT applications and proposed a game theory approach aimed at maximizing the communication rate for the users involved.

\par The distinctions between our study and the previously mentioned works can be analyzed as follows. First, prior research has not considered the use of CB as an alternative to the independent operation of UAVs in communication networks. This work introduces CB to extend communication ranges, enhance signal quality, and reduce the energy consumption of UAVs, especially in long-distance transmission scenarios affected by interference. Moreover, most of the aforementioned works focus on optimizing a single objective, such as coverage or communication rate. In real-world UAV-assisted communication systems, multiple conflicting objectives must often be considered, such as balancing the achievable rate with energy efficiency. In contrast, this work addresses this gap by incorporating a multi-objective optimization approach that balances both transmission performance and energy consumption, making it more suitable for practical deployments in dynamic environments.


\subsection{Collaborative Beamforming Methods}
\label{subsec:Collaborative Beamforming}

\par Several studies have explored the application of CB to enhance the transmission capabilities in various wireless communication scenarios. For example, the authors in Huang et al., "Reinforcement Learning-Based Signal Amplification for Collaborative Beamforming" applied CB in wireless sensor networks and introduced a reinforcement learning approach aimed at optimizing the signal-to-noise ratio. However, such studies were limited to static sensor nodes. Notably, the application of CB in mobile nodes introduces greater complexity than in static environments. Moreover, the authors in Liu et al., "Linear Antenna Array Formed by UAVs for Wireless Communications" utilized UAVs to form a linear antenna array to enhance wireless communications, thereby minimizing the airborne service time by optimizing UAV locations and rotor speeds. However, this study was limited by its reliance on a simplified line-of-sight (LoS) channel model, which may not be applicable to realistic air-to-ground (A2G) communication links because of the lack of consideration for multipath fading. The authors in Chen et al., "Secure Communication Network for Multiple UAVs" examined a secure communication network for multiple UAVs and explored a stochastic virtual antenna array to maximize energy efficiency. Moreover, the authors in Zhang et al., "UAV-Assisted Aerial Relay System with Virtual Antenna Array" investigated a novel UAV-assisted aerial relay system in which UAVs form a virtual antenna array to communicate with distant ground users by using CB, and they proposed a multi-objective optimization approach aimed at maximizing the secrecy rate and minimizing energy costs. 

\par While these studies demonstrate the efficiency and advantages of CB, none of them have explicitly explored its integration with dynamic terrestrial mobile users in more realistic CB-enabled communication environments. Such a gap is particularly challenging due to the uncertainty and rapid changes in such environments, requiring systems to exhibit high adaptability. In contrast, this work models and captures the mobility of the users, and proposes a DRL-based optimization method with real-time response ability, which can provide a more comprehensive and practical solution to the challenges of UAV-assisted communication networks in real-world settings.


\subsection{Multi-objective Optimization}
\label{Multi-objective Optimization}

\par In practical UAV-assisted communication networks, multiple conflicting optimization objectives often arise. Methods to address MOPs can generally be categorized into two main approaches which are traditional methods and deep reinforcement learning (DRL) techniques.

\par There have been several studies employing traditional methods to address the MOP within the context of UAV-assisted communication networks. For instance, the authors in Yang et al., "Gravitational Search Algorithm for Multi-Objective Resource Management" considered a multi-objective resource management optimization problem in heterogeneous cellular networks and designed a gravitational search algorithm aimed at minimizing the dispersion degree of throughputs and the total energy consumption. In Li et al., "Weighted Tchebycheff Approach for UAV-Assisted Wireless Communication Networks", a weighted Tchebycheff approach was introduced to concurrently maximize the achievable sum rate and minimizing the downlink transmission power in a UAV-assisted wireless communication network. The authors in Wang et al., "Difference of Convex Optimization Algorithm" introduce a difference of convex optimization algorithm designed to minimize both the energy consumption and the SNR outage in a UAV-assisted data ferrying network. Moreover, the authors in Gao et al., "Modified Salp Swarm Algorithm for UAV-Assisted Data Harvesting and Dissemination" introduced and modified the multi-objective salp swarm algorithm for a UAV-assisted data harvesting and dissemination system, with the goals of reducing data transmission time, conserving energy for the UAV swarm, and enhancing secure performance. However, these traditional methods become impractical for real-time decisions in highly dynamic environments.

\par Some existing research considers the use of the DRL approach to solve the MOP. For example, the authors in Liu et al., "Twin-Delayed Deep Deterministic Policy Gradients for UAV-Enabled IoT Networks" considered a UAV-enabled IoT network, utilizing twin-delayed deep deterministic policy gradients to minimize the weighted sum of the age of information and UAV energy consumption. The authors in Zhang et al., "Multi-Agent Q-Learning Resource Allocation Algorithm" introduce a resource allocation algorithm based on multi-agent Q-Learning, aimed at optimizing both the achieved throughput and the power consumption. In Wang et al., "Q-Learning for Max-Min Optimization", Q-learning was utilized to maximize the uplink throughput while minimizing the energy consumption in a UAV-based data collection system. The authors in Gao et al., "Dueling Double Deep Q Network for UAV Trajectory Control" addressed a UAV trajectory optimization problem with the objectives of minimizing mission completion time and expected communication outage duration and introduced a dueling double deep Q network for UAV trajectory control. Moreover, the authors in Li et al., "Multi-Agent Deep Deterministic Policy Gradient Algorithm" used a multi-agent deep deterministic policy gradient algorithm to maximize geographical fairness and minimize energy consumption in UAV trajectory control. 

\par Nevertheless, the aforementioned DRL methods employ single-policy approaches. For example, multiple objectives are usually combined into one reward by using various arithmetic methods, which complicates the determination of weights to harmonize these objectives effectively. Moreover, this method tends to yield one single solution, which may potentially overlook conflicts between objectives and reduce the solution space. Our previous work has proposed an evolutionary multi-objective DRL algorithm that may overcome this issue Wang et al., "Evolutionary Multi-Objective Deep Reinforcement Learning Algorithm for UAV-Assisted Communication Networks". However, the previous work targeted periodic low Earth orbit (LEO) satellites, which cannot handle the high dynamics and temporal dependencies of the considered scenario raised by the mobile user. Moreover, the potential decision variables of this work such as UAV trajectories are continuous and high dimensions. Compared to our previous work that focused on static scenarios with fixed ground terminals and periodic LEO satellites, this work involves fundamentally different system components including 3D-controllable UAVs, randomly moving users, and highly dynamic channel conditions. Furthermore, from the mathematical perspective, it requires handling continuous decision variables, temporal dependencies, and more complex multi-objective optimization. As such, the considered scenario requires a significantly different algorithm design and improvement from our previous work in Li et al., "Evolutionary Multi-Objective Deep Reinforcement Learning Algorithm for UAV-Assisted Communication Networks". Consequently, our objective is to introduce a novel evolutionary multi-objective DRL algorithm capable of deriving a collection of high-quality, non-dominated policies and handling high dynamics and temporal dependencies.