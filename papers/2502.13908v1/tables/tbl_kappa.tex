\begin{table}[]
    \centering
    \caption{Cohen's $\kappa$ correlation in 4-point scale agreement and difference binarize the judgment scale. Judgment levels to the left of the pipe are considered irrelevant, while those to the right are considered relevant.}
    \adjustbox{max width=\columnwidth}{%
    \begin{tabular}{lcccc}
    \toprule
    \textbf{Submission ID} & \textbf{4-point} & \textbf{0|123} & \textbf{01|23} & \textbf{012|3} \\
    \midrule
    NISTRetrieval-instruct0 & 0.1877 & 0.3116 & 0.3021 & 0.0000 \\
    NISTRetrieval-instruct1 & 0.1874 & 0.3106 & 0.3021 & 0.0000 \\
    NISTRetrieval-instruct2 & 0.1880 & 0.3126 & 0.3013 & 0.0000 \\
    NISTRetrieval-reason0   & 0.1844 & 0.2911 & 0.3390 & 0.0097 \\
    NISTRetrieval-reason1   & 0.1845 & 0.2906 & 0.3394 & 0.0097 \\
    NISTRetrieval-reason2   & 0.1838 & 0.2902 & 0.3397 & 0.0097 \\
    Olz-exp                 & 0.2519 & 0.3997 & 0.3577 & 0.2936 \\
    Olz-gpt4o               & 0.2625 & \textbf{0.4228} & 0.3657 & 0.3066 \\
    Olz-halfbin             & 0.2064 & 0.4008 & 0.2587 & 0.2449 \\
    Olz-multiprompt         & 0.2445 & 0.3764 & 0.3934 & 0.2150 \\
    Olz-somebin             & 0.2109 & 0.3854 & 0.3883 & 0.1137 \\
    RMITIR-GPT4o            & 0.2388 & 0.3499 & 0.3961 & 0.2580 \\
    RMITIR-llama38b         & 0.2006 & 0.3280 & 0.3194 & 0.1344 \\
    RMITIR-llama70B         & 0.2654 & \textit{0.4166} & 0.3916 & 0.2843 \\
    TREMA-4prompts          & 0.1829 & 0.3022 & 0.2697 & 0.1664 \\
    TREMA-CoT               & 0.1961 & 0.3181 & 0.3208 & 0.1836 \\
    TREMA-all               & 0.1471 & 0.3244 & 0.2978 & 0.0717 \\
    TREMA-direct            & 0.1742 & 0.3205 & 0.3462 & 0.1763 \\
    TREMA-naiveBdecompose   & 0.1741 & 0.3085 & 0.2916 & 0.0153 \\
    TREMA-nuggets           & 0.0604 & 0.1505 & 0.0992 & -0.0077 \\
    TREMA-other             & 0.1408 & 0.2740 & 0.2015 & 0.1411 \\
    TREMA-questions         & 0.1137 & 0.2636 & 0.2876 & 0.0441 \\
    TREMA-rubric0           & 0.0779 & 0.1714 & 0.0308 & 0.0369 \\
    TREMA-sumdecompose      & 0.2088 & 0.3228 & 0.3512 & 0.2047 \\
    h2oloo-fewself          & 0.2774 & 0.4172 & 0.4280 & 0.3048 \\
    h2oloo-zeroshot1        & 0.2817 & 0.4094 & 0.3901 & 0.3084 \\
    h2oloo-zeroshot2        & 0.2589 & 0.3691 & 0.3278 & 0.2789 \\
    llmjudge-cot1           & 0.1284 & 0.2219 & 0.2833 & 0.1287 \\
    llmjudge-cot2           & 0.1560 & 0.2507 & 0.2944 & 0.2048 \\
    llmjudge-cot3           & 0.2271 & 0.3856 & 0.3978 & 0.2335 \\
    llmjudge-simple1        & 0.0754 & 0.1278 & 0.2880 & 0.1582 \\
    llmjudge-simple2        & 0.1327 & 0.2349 & 0.3241 & 0.2004 \\
    llmjudge-simple3        & 0.2110 & 0.3590 & 0.3972 & 0.2157 \\
    llmjudge-thomas1        & 0.1236 & 0.2087 & 0.2843 & 0.1802 \\
    llmjudge-thomas2        & 0.1723 & 0.2944 & 0.3043 & 0.2267 \\
    llmjudge-thomas3        & 0.2293 & 0.3910 & 0.3947 & 0.2438 \\
    prophet-setting1        & 0.1823 & 0.3502 & 0.2903 & 0.1677 \\
    prophet-setting2        & 0.1757 & 0.3102 & 0.2382 & 0.0284 \\
    prophet-setting4        & 0.1471 & 0.2375 & 0.1409 & 0.0371 \\
    willia-umbrela1         & 0.2863 & 0.4161 & \textbf{0.3985} & 0.3145 \\
    willia-umbrela2         & 0.2688 & 0.4109 & 0.3421 & 0.3194 \\
    willia-umbrela3         & 0.2741 & 0.4114 & 0.3447 & \textbf{0.3215} \\
    \bottomrule
    \end{tabular}
    }
    
    \label{tab:kappa}
\end{table}