\section{Introduction}\label{sec:intro}
%
%
%
%
%
High-quality data is crucial for training Large Language Models (LLMs) to superior performance \cite{yang2024smalltolarge,li2023synthetic}. However, collecting and curating high-quality data is often very expensive and hard to obtain in many domains. In addition, as LLMs can memorize their training data \cite{hartmann2023sok}, ensuring the privacy of training examples hinders training the model directly on the training data.
%
Thus, generating small subsets of synthetic data that can train an LLM to superior performance on the target task becomes handy.
%
To do so, synthetic text should be generated in a way that ensures similar dynamics to that of training on the real data.  
%
However, text is discrete in nature and optimization in the discrete space is very challenging.

Existing approaches for synthetic text generation mostly rely on advanced LLMs such as GPT-4 to generate synthetic text for the target categories \cite{ye2022zerogen,meng2022generating,li2023synthetic,gupta2023targen,tao2024textual,wu2024unigen,dekoninckcontrolled,yu2024large}.
%
%
LLM-generated text either suffers from lack of diversity and faithfulness to real data \cite{ye2022zerogen,meng2022generating,li2023synthetic}, or requires %
meticulous prompt engineering and highly complex  pipelines, such as multi-agent frameworks, iterative sampling, and processing mechanisms \cite{gupta2023targen,dekoninckcontrolled,wu2024unigen}. 
The complexity of the pipelines, efforts for manual prompt engineering, and the cost of querying advanced models limits the applicability of such approaches.
%
%
A few recent studies explored the use of VAEs and diffusion for %
controllable text generation \cite{li2022diffusion,gong2022diffuseq,zhou2024difflm}. But, training diffusion models is computationally heavy and difficult in practice.
%
Importantly, none of the above approaches provide any guarantee for the performance of the LLM trained on the synthetic text. %
%
%
%

%
%
%
%
%
%
%
The above limitations raise a key question: \textit{Can we generate a small subset of synthetic text that can train an LLM with similar dynamics to that of real data?}
For vision models, Dataset Distillation (DD) addresses the above question by generating a small number of synthetic images that minimize the training loss \cite{wang2018dataset,loo2022efficient,nguyen2020dataset}, match the training gradient \cite{zhao2020dataset,zhao2021dataset} or model's weight trajectory during training \cite{cazenavette2022dataset,wang2022cafe}. 
For images, gradient-based methods can easily operate in the pixel-wise continuous space.
However, for LLMs, the discrete nature of text and the very large number of LLM's parameters make DD much more challenging. 
%
The few existing approaches generate synthetic embeddings that minimize the training loss \cite{sucholutsky2021soft,li2021data,sahni2023exploring,maekawa2023dataset}, or by training a generator model to match the gradient of an LLM trained on the data %
%
\cite{maekawa2024dilm}. However, the synthetic embeddings are not readable and cannot be transferred to train other LLMs, and synthetic data generated by matching dynamics of a model trained on real data may include real training examples and is not privacy preserving.\looseness=-1
%

In this work, we propose the first theoretically-rigorous method to generate readable synthetic text that guarantees similar dynamics to that of fine-tuning on real data.
First, we formulate a discrete optimization problem to find text embeddings that have a similar gradient to that of real data, under the constraint that the optimized embeddings should correspond to tokens in the vocabulary. Moreover, to ensure readability, we add another constraint that requires the sequence to have a low perplexity.
%
%
Then, we solve this discrete optimization problem using Alternating Direction Method of Multipliers (ADMM) that iteratively optimizes the embeddings of synthetic data to match the gradient of the real data, and maps them to a sequence of text tokens with low perplexity. We prove that the synthetic text generated by our method guarantees convergence to a close neighborhood of the solution obtained by fine-tuning the model on real data.

We conduct extensive experiments to evaluate the effectiveness of our approach, namely \alg, for generating synthetic data using Phi for multiple classification %
tasks. %
First, we consider the case where only a small number of validation examples are available and we apply \alg\ to generate a larger fine-tuning data. We show that with only 5 to 50 examples, \alg\ can successfully generate 100 %
synthetic data that outperform training on the real examples by up to 32.4\%. 
%
Next, we apply \alg\ to generate a small synthetic data based on an existing fine-tuning data. We show that the synthetic data generated by \alg\ outperforms zero-shot and few-shot generation by LLMs as well as real examples selected by coreset selection methods by up to 10.4\%, while ensuring the privacy of the training data. 
%
We also confirm the transferability of \alg's  generated text via Phi for fine-tuning other LLMs, including Llama-3.2-1B and OPT-1.3B.



