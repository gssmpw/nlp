\section{Problem Formulation}\label{sec: preliminary}
Here, we formalize the problem of generating small human-readable synthetic text that can fine-tune an LLM with similar dynamics to that of real data. We also discuss two common use cases where such synthetic data is useful.

%
\textbf{Setting.} Consider a pretrained LLM with parameters $\thet$ and vocabulary $V=\{v_1,\cdots,v_{|V|}\}$ containing all the words it has been trained to recognize and use. Consider a supervised fine-tuning dataset $\gD_T = \{ s^i \}$, where each example $s^i = (\vct{p}^i, \vct{r}^i)$ is a pair of prompt $\vct{p}^i$ and response $\vct{r}^i$ containing words in the vocabulary. The negative log likelihood loss is defined as $\ell(s^i, \thet) = - \log (\vct{r}^i | \vct{p}^i)$. The fine-tuning objective is thus to minimize the negative log likelihood loss over the whole dataset $\gD$ as $\ell(\gD, \thet) = \frac{1}{|\gD|} \sum_{i=1}^{|\gD|} \ell(s^i, \thet)$.


\textbf{Problem formulation.} 
%
%
Given a subsets of real examples from the fine-tuning data $\gD_\text{real}\subset\gD_T$, our goal is to generate synthetic data $\gD_\text{syn}=\{q^i\}_{i=1}^k, q^i\notin \gD_T ~\forall i$, containing $r$ synthetic examples that do not belong to $\gD_T$, such that fine-tuning the model on $\gD_\text{syn}$ minimizes the loss on $\gD_\text{real}$.
%
Formally,
%
\begin{equation}\label{eq:problem}
    \argmin_{\gD_\text{syn}, |\gD_\text{syn}|\leq r} \ell(\gD_\text{real},\thet^*), \quad s.t. \quad \thet^*\in\argmin_{\thet} \ell(\gD_\text{syn},\thet).
\end{equation}

%
\textbf{Readability constraint.} Importantly, we want the synthetic data to be human-readable. That is we want every synthetic example to be a sequence of %
words in the vocabulary. Besides, to ensure that the sequence is meaningful, we require that the synthetic data has low perplexity.
Thus, we wish to solve the following constrained optimization problem:\looseness=-1
%
\begin{equation}\label{eq:problem_with_constraint}
    \argmin_{\substack{\gD_\text{syn}, |\gD_\text{syn}|\leq k, \\ s \in \Gamma, \text{ppl}(s) \leq \epsilon \\~\forall s\in \gD_\text{syn}}} \ell(\gD_\text{real},\thet^*), \quad s.t. \quad \thet^*\in\argmin_{\thet} \ell(\gD_\text{syn},\thet),
\end{equation}
where $\Gamma \!=\! \{s\!=\!(\vct{p},\vct{r})|p_j, r_j\in V\}$ is the set of all prompts and responses that consist of words in vocabulary $V$. %

\textbf{Use cases for synthetic data generations.} The above formulation is applicable to two settings: (1) Data is scarce for the target task, and we want to generate a larger synthetic fine-tuning data based on a small number of examples from the target task.
(2) A relatively large supervised fine-tuning data is available, and we wish to generate a smaller synthetic data to replace the real data to preserve the privacy of training examples or to improve the training efficiency.

%
%

