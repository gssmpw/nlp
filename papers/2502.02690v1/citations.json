[
  {
    "index": 0,
    "papers": [
      {
        "key": "yang2024cogvideox",
        "author": "Yang, Zhuoyi and Teng, Jiayan and Zheng, Wendi and Ding, Ming and Huang, Shiyu and Xu, Jiazheng and Yang, Yuanming and Hong, Wenyi and Zhang, Xiaohan and Feng, Guanyu and others",
        "title": "Cogvideox: Text-to-video diffusion models with an expert transformer"
      },
      {
        "key": "singer2022make",
        "author": "Singer, Uriel and Polyak, Adam and Hayes, Thomas and Yin, Xi and An, Jie and Zhang, Songyang and Hu, Qiyuan and Yang, Harry and Ashual, Oron and Gafni, Oran and others",
        "title": "Make-a-video: Text-to-video generation without text-video data"
      },
      {
        "key": "ho2022video",
        "author": "Ho, Jonathan and Salimans, Tim and Gritsenko, Alexey and Chan, William and Norouzi, Mohammad and Fleet, David J",
        "title": "Video diffusion models"
      },
      {
        "key": "zhou2022magicvideo",
        "author": "Zhou, Daquan and Wang, Weimin and Yan, Hanshu and Lv, Weiwei and Zhu, Yizhe and Feng, Jiashi",
        "title": "Magicvideo: Efficient video generation with latent diffusion models"
      },
      {
        "key": "opensora",
        "author": "Zangwei Zheng and Xiangyu Peng and Tianji Yang and Chenhui Shen and Shenggui Li and Hongxin Liu and Yukun Zhou and Tianyi Li and Yang You",
        "title": "Open-Sora: Democratizing Efficient Video Production for All"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "tu2024stableanimator",
        "author": "Tu, Shuyuan and Xing, Zhen and Han, Xintong and Cheng, Zhi-Qi and Dai, Qi and Luo, Chong and Wu, Zuxuan",
        "title": "StableAnimator: High-Quality Identity-Preserving Human Image Animation"
      },
      {
        "key": "zhu2025champ",
        "author": "Zhu, Shenhao and Chen, Junming Leo and Dai, Zuozhuo and Dong, Zilong and Xu, Yinghui and Cao, Xun and Yao, Yao and Zhu, Hao and Zhu, Siyu",
        "title": "Champ: Controllable and consistent human image animation with 3d parametric guidance"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "yang2024direct",
        "author": "Yang, Shiyuan and Hou, Liang and Huang, Haibin and Ma, Chongyang and Wan, Pengfei and Zhang, Di and Chen, Xiaodong and Liao, Jing",
        "title": "Direct-a-video: Customized video generation with user-directed camera movement and object motion"
      },
      {
        "key": "wang2024motionctrl",
        "author": "Wang, Zhouxia and Yuan, Ziyang and Wang, Xintao and Li, Yaowei and Chen, Tianshui and Xia, Menghan and Luo, Ping and Shan, Ying",
        "title": "Motionctrl: A unified and flexible motion controller for video generation"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "liu2024stablev2v",
        "author": "Liu, Chang and Li, Rui and Zhang, Kaidong and Lan, Yunwei and Liu, Dong",
        "title": "StableV2V: Stablizing Shape Consistency in Video-to-Video Editing"
      },
      {
        "key": "xing2024make",
        "author": "Xing, Jinbo and Xia, Menghan and Liu, Yuxin and Zhang, Yuechen and Zhang, Yong and He, Yingqing and Liu, Hanyuan and Chen, Haoxin and Cun, Xiaodong and Wang, Xintao and others",
        "title": "Make-your-video: Customized video generation using textual and structural guidance"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "hyvarinen2016unsupervised",
        "author": "Hyvarinen, Aapo and Morioka, Hiroshi",
        "title": "Unsupervised feature extraction by time-contrastive learning and nonlinear ica"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "hyvarinen2017nonlinear",
        "author": "Hyvarinen, Aapo and Morioka, Hiroshi",
        "title": "Nonlinear ICA of temporally dependent stationary sources"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "khemakhem2020variational",
        "author": "Khemakhem, Ilyes and Kingma, Diederik and Monti, Ricardo and Hyvarinen, Aapo",
        "title": "Variational autoencoders and nonlinear ica: A unifying framework"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "yao2021learning",
        "author": "Yao, Weiran and Sun, Yuewen and Ho, Alex and Sun, Changyin and Zhang, Kun",
        "title": "Learning temporally causal latent processes from general temporal data"
      },
      {
        "key": "yao2022temporally",
        "author": "Yao, Weiran and Chen, Guangyi and Zhang, Kun",
        "title": "Temporally disentangled representation learning"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "chen2024caring",
        "author": "Chen, Guangyi and Shen, Yifan and Chen, Zhenhao and Song, Xiangchen and Sun, Yuewen and Yao, Weiran and Liu, Xiao and Zhang, Kun",
        "title": "CaRiNG: Learning Temporal Causal Representation under Non-Invertible Generation Process"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "lippe2022citris",
        "author": "Lippe, Phillip and Magliacane, Sara and L{\\\"o}we, Sindy and Asano, Yuki M and Cohen, Taco and Gavves, Stratis",
        "title": "{CITRIS}: Causal Identifiability from Temporal Intervened Sequences"
      },
      {
        "key": "lippe2023causal",
        "author": "Phillip Lippe and Sara Magliacane and Sindy L{\\\"o}we and Yuki M Asano and Taco Cohen and Efstratios Gavves",
        "title": "Causal Representation Learning for Instantaneous and Temporal Effects in Interactive Systems"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "li2024identification",
        "author": "Li, Zijian and Shen, Yifan and Zheng, Kaitao and Cai, Ruichu and Song, Xiangchen and Gong, Mingming and Zhu, Zhengmao and Chen, Guangyi and Zhang, Kun",
        "title": "On the identification of temporally causal representation with instantaneous dependence"
      }
    ]
  }
]