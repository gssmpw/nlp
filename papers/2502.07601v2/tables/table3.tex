\begin{table*}
\small
\centering
\begin{tabular}{lccccccccc}
\toprule
\multicolumn{1}{l}{\multirow{2}{*}{Model}} & \multicolumn{4}{c}{Anomaly Detection} & \multicolumn{3}{c}{Low-level Reasoning} &  \multicolumn{2}{c}{Complex Reasoning}\\ 
\cmidrule(lr){2-5}\cmidrule(lr){6-8}\cmidrule(lr){9-10}
                 & Accuracy           & Precision & Recall & F1-score & ROUGE-L               & SBERT & GPT-Score & SBERT                & GPT-Score \\
\hline
GPT-4V \cite{gpt-api-4vision}          & 0.68              & 0.90      & 0.49   & 0.55     &        0.16             &   0.65    &      3.31     &  0.77                    &     5.64      \\
GPT-4o \cite{gpt-api-4o}          & 0.70              & 0.83      & 0.71   & 0.68     &           0.24          &    0.71   &    \textbf{4.84}       &  0.81                    &      \textbf{6.89}     \\
Qwen2-VL-2B \cite{qwen2vl}      & 0.65              & 0.87      & 0.55   & 0.59     & 0.22                    &   0.55    &  1.94         & 0.74                     &   4.26        \\
Qwen2-VL-7B \cite{qwen2vl}     & 0.76              & \underline{0.91}      & 0.69   & 0.75     & 0.25                    &  0.61     &  3.09         & 0.68                     &  4.62         \\
InternVL-2-8B \cite{internvl}   & 0.74              & 0.78      & 0.81   & 0.76     & 0.23                    & 0.73      &  3.69         & 0.80                     & 5.08          \\
InternVL-2-26B \cite{internvl}  & 0.73              & 0.86      & 0.66   & 0.68     & 0.21                    & \textbf{0.74}      &  4.13         & 0.80                     &   5.49        \\
IXC-2.5-7B \cite{ixc25}      & 0.72              & 0.88      & 0.63   & 0.67     & 0.21                    &  0.58     &  2.45         & 0.77                     &   5.14        \\
LLaVA-OV-0.5B \cite{llavaonevision}   & 0.54              & 0.70      & 0.19   & 0.28     & 0.20                    & 0.63      &  2.54         & 0.81                     &   4.34        \\
LLaVA-OV-7B \cite{llavaonevision}     & 0.71              & \textbf{0.95}      & 0.56   & 0.63     & 0.24                    & 0.66      &  3.57         &   0.79                   &  5.44         \\
\hline
LLaVA-OV-0.5B*   & 0.71              & 0.77      & \underline{0.84}   & 0.76     & 0.31                    &  0.70     & 3.69          & 0.82                     &  5.31         \\
Anomaly-OV-0.5B & \textbf{0.79}              & 0.86      & 0.83   & \underline{0.82}     & \underline{0.33}                    & 0.72      & 3.87          &  \underline{0.83}                    &  5.67         \\
Anomaly-OV-7B    & \textbf{0.79}                  & 0.83          & \textbf{0.86}      & \textbf{0.83}         &  \textbf{0.34}                   & \underline{0.73}      & \underline{4.26}          & \textbf{0.84}                     &  \underline{6.34}        \\
\bottomrule
\end{tabular}
\caption{Quantitative comparison of text-based anomaly detection and reasoning for MLLMs. Notably, the Accuracy and F1-score for the anomaly expert of Anomaly-OV can be calculated as $\{0.78, 0.77\}$ with threshold $0.5$. * indicates the model is fine-tuned on our dataset.}
\label{Tab:3}
 \vspace{-3mm}
\end{table*}