\begin{abstract}
In recent years, there has been a growing recognition of the need to incorporate lay-people's input into the governance and acceptability assessment of AI usage. 
However, how and why people judge different AI use cases to be acceptable or unacceptable remains under-explored.
In this work, we investigate the attitudes and reasons that influence people's judgments about AI's development via a survey administered to demographically diverse participants (N=197). We focus on ten distinct professional (e.g., Lawyer AI) and personal (e.g., Digital Medical Advice AI) AI use cases to understand how characteristics of the use cases and the participants' demographics affect acceptability. We explore the relationships between participants' judgments and their rationales such as reasoning approaches (cost-benefit reasoning vs. rule-based). Our empirical findings reveal number of factors that influence acceptance such as general negative acceptance and higher disagreement of professional usage over personal, significant influence of demographics factors such as gender, employment, and education as well as AI literacy level, and reasoning patterns such as rule-based reasoning being used more when use case is unacceptable. Based on these findings, we discuss the key implications for soliciting acceptability and reasoning of AI use cases to collaboratively build consensus. Finally, we shed light on how future FAccT researchers and practitioners can better incorporate diverse perspectives from lay people to better develop AI that aligns with public expectations and needs.

%Thus, this study uncovers diverse perspectives that influence societal AI decisions, helping align its development with public expectations and concerns.
% that influence people's acceptability of AI usage (e.g., use case, AI's risk level, AI literacy). Interestingly, both judgments and factors in decision making showed more variation for professional usage compared to personal usage with only one professional use case, IT Support Specialist having a positive effect on acceptance. 
% These results underscore the importance of categorizing and understanding use cases further to identify and address contentious AI usage. This study uncovers diverse perspectives that influence societal AI decisions, helping align its development with public expectations and concerns.
% \maarten{I'm wondering if we wanna mirror some more of the intro framing, particularly around the points that (1) we need more democratic/lay people input into AI governance/acceptability of AI, but (2) we don't really know what attitudes and reasoning factors affect people's decisions. Thus, we conduct...
% (I don't think we need to mention dilemmas here, unless we have a paper title that contains the words dilemmas)}
% As AI's capabilities expand, it presents numerous dilemmas stemming from its dual positive and negative impacts. However, we do not yet understand how people with various backgrounds make these decisions, which could provide insights into potential disagreements around AI and possible solutions. 
% As a first step towards understanding the reasoning process regarding AI dilemmas, we construct two studies to understand the effects of use cases (e.g., Lawyer AI, Digital Medical Advice AI), explicit reasoning and various reasoning factors such as moral values and reasoning type (e.g., cost-benefit, rule-based), and demographic factors. We conduct our studies with N=198 and N=199 demographically diverse participants and found that personal use cases were more positively perceived with less disagreements compared to labor related use cases. \jimin{talk more about some coherent findings here and our discussion points}
\end{abstract}