In recent years, there has been a growing call for adequately regulating AI in its development and integration into society \citep{pistilli2023stronger}. These efforts, as reflected in the EU AI act \citep{AIAct_2023}, NIST AI Risk Management framework \citep{NIST_2021}, and the recent U.S. Executive Order \citep{executiveorder2023}, have resulted in a discussion regarding underline the importance of scrutinizing whether certain AI use cases should be pursued at all. Although these efforts aim to regulate AI, concerns persist regarding their adequacy to actually address the wide and growing impact of AI \citep{dominguez2024mapping}, highlighting the need to integrate lay people, especially those from marginalized community, to understand the diverse and disparate impact of AI \citep{}. 

A major challenge in AI development is the ambiguity surrounding the acceptability and impact of various use cases, as there are typically arguments both for and against each one \citep{mun2024participaidemocraticsurveyingframework}. Making informed decisions requires understanding how people resolve these conflicts. Firstly, it is essential to grasp both the \emph{perceptions and disagreements} related to use cases and the \emph{personal factors influencing these perceptions} to address demographic differences. Secondly, examining deeper reasoning processes beyond surface factors can provide valuable insights. These understandings are crucial for forming governance and policy decisions that anticipate and address disagreements, especially across diverse populations.