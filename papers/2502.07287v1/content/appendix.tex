\appendix

\section{Additional Survey Details}
\label{app:survey-details}

\subsection{Survey Questions}\label{sssec:a-questions}
In our survey we ask participants to read one or more descriptions of AI use cases and to make two judgments: 1) ``Do you think a technology like this should exist?'' (Q1) and 2) ``If the <\textit{use case}> exists, would you use its services?'' (Q5). A question to indicate their level of confidence is asked following each question (Q5, Q6). The participants are asked to both elaborate on their decisions (Q3) and specify the conditions under which they would switch their decisions (Q4). The detailed wordings for the questions are shown in Table \ref{app:part-1-questions}.

Following the main use case questions in both the main and second study, we also asked participants questions about their demographics and literacy levels in AI, and the questions can be found in Table \ref{app:demographic-questions} and \ref{app:ai-literacy-questions} respectively. 

Lastly, while not included in the main text, we asked participants 3 questionnaires about decision making styles to explore the relationship between several decision making styles and the actual decisions of the participants. These included: (1) Oxford Utilitarianism Scale, (2) Toronto Empathy Questionnaire and (3) Moral Foundations Questionnaire. The decision making style questions can be found in Table \ref{app:util-questions}, \ref{app:empathy-questions} and \ref{app:mfq} respectively.

\input{tables/questions/part1-questions}
\input{tables/questions/demographic-questions}
\input{tables/questions/ai-literacy-questions}
\input{tables/questions/utilitarianism-questions}
\input{tables/questions/empathy-questions}
\input{tables/questions/mfq-questions}

\subsection{Participant Details}
\label{app:participant-details}
The demographics of the participants for our study is shown in Tables \ref{app:demographics-1-jobs-p1} to \ref{app:demographics-3-personal-p2}. There was a fairly balanced distribution of participants across the different age groups, although there was a slightly higher proportion of participants in the 25-34 years old and 45-54 years old age ranges. In terms of racial distribution, there were more White/Caucasian participants compared to the other races. The gender distribution was relatively balanced in terms of males vs non-males. The participants were mostly employed or looking for work and a majority of them also had at least some form of college education. Most participants identified as liberal in terms of political leaning. Participants' AI literacy scores are shown in Table~\ref{tab:ai-literacy-distr} and AI Ethics score are shown in Table~\ref{tab:ai-ethics-distr}.

Participants were allocated 5 use cases from one of the scenarios and the allocation between the 2 scenarios are well-balanced and can be found in Table \ref{tab:study1-use-case}.
\input{tables/demographic-data/study-1-use-case-split}

\input{tables/demographic-data/demographics-1-jobs-p1}
\input{tables/demographic-data/demographics-2-jobs-p1}
\input{tables/demographic-data/demographics-3-jobs-p1}
\input{tables/demographic-data/demographics-1-personal-p1}
\input{tables/demographic-data/demographics-2-personal-p1}
\input{tables/demographic-data/demographics-3-personal-p1}
\input{tables/ai-literacy-data/ai-lit-distribution}
\input{tables/ai-literacy-data/ai-ethics-distr}
\subsection{Open-text Annotation Dimensions}
\label{sssec:reasoning-dim}
\paragraph{Reasoning Type}
% still would like to answer, for rule-based reasoning, what kind of rules? Are norms and definitions also rule-based reasoning?
% also, for cost-benefit reasoning, is this the only reasoning pattern for decision making if the dilemma is not moral?
Inspired by previous works in moral psychology, we used two main reasoning types to characterize participants' decision making pattern as expressed in their open-text answers: cost-benefit reasoning and rule-based reasoning \citep{cheung2024measuring}. These two reasoning types are rooted in two decision making processes in moral and wider decision making literature: utilitarian and deontological reasoning, respectively. Cost-benefit reasoning thus considers the possible outcomes and their expected utility or value when making decisions, and rule-based reasoning shows more inherent value in action or entities. See \S~\ref{ssec:moral-decision-making} for further discussion.
% maybe add examples here?

\paragraph{Moral Values}
To annotate which values were prevalent in participants' considerations of use cases, we used five moral values: care, fairness, loyalty, authority, and purity \citep{graham2011mapping,graham2008moral}. While these dimensions have been re-defined to include more diverse values from participants beyond WEIRD (white, educated, industrialized, rich, and democratic) \citep{atari2023morality}, we used these five dimensions due to brevity of the questionnaire, which was used in the survey to provide importance of each values to participants. 

\paragraph{Switching Conditions}
We annotated concerns expressed in switching conditions using three categories: functionality (e.g., errors, bias in systems, limited capabilities), usage (e.g., errors, bias in systems, limited capabilities), and societal impact (e.g., job loss, over-reliance), inspired by harm taxonomy developed by \citeauthor{solaiman2023evaluating} and user concern annotation practice adopted by \citeauthor{mun2024participaidemocraticsurveyingframework}.

\section{Open-text Annotation Details}
\label{app:open-text-annotation-details}
\subsection{Automatic Annotation}
\subsubsection{Methods}
We used Open-AI's o1-mini model with maximum tokens set to 1024 to control response length, use a temperature of 0.7 to manage randomness, and keep top\_p at 1 with default settings for frequency and presence penalties at 0. Prompts will be released with data upon acceptance. 

\subsubsection{Results}
Results for inter-rater reliability analysis of o1's annotations are shown in Table~\ref{tab:irr-results}.
\input{tables/irr-results}

\section{Factors Impacting Acceptability Judgments}
\subsection{Use Case Factors}
Additional analysis of use case factors showing distribution of judgments by use case sorted by standard deviation is shown in Figure~\ref{fig:decisions-by-use-case-violin}. Table~\ref{table:use-case-effect-anova} shows analysis of use case effect using ANOVA.
\input{figures/judgments_by_use_case_violin}
\input{tables/use-case-effect-anova}

\subsection{Demographics Factors}
Additional analysis using ANOVA for demographic factors is shown in Table~\ref{tab:demographics-anova}.
\input{tables/demographics-factor-anova}

\input{tables/reasoning-factors-questionnaires-effects}
\subsubsection{Questionnaires}
Interestingly, only Loyalty had a significant effect on both existence ($0.20, p<.001$) and usage ($0.20, p<.01$) as shown in Table~\ref{tab:reasoning-factors-questionnaires}. Moreover, Empathy had a positive and marginally significant effect for usage ($.09, p<.1$). However, Loyalty, as shown in Figure~\ref{fig:moral_values_proportions}, does not appear as frequently in participants' open text responses compared to values such as Care and Fairness and is the only value that did not have a significant association with use cases. 

\section{Factors in Participant Rationale}

\subsection{Reasoning Types}
We show the flow of participants' decisions and corresponding rationales throughout use cases in Figure~\ref{fig:reasoning-type-sankey}, which shows interesting distribution and switching of reasoning types, which would be interesting for future studies to consider. Moreover, Table~\ref{tab:reasoning-type-questionnaire} shows that there are almost no relation between reasoning types used by the participants and the decision-making style questionnaire results signifying that the reasoning types might be highly use-case specific rather than a character trait. It would be interesting to study the factors that actually influence the choice of reasoning types. 
\input{figures/sankey}
\input{tables/reasoning-type-questionnaire}

\subsection{Impact of Rationale Factors on Judgment}
We display the analysis results using ANOVA to understand the effect of rationale factors on judgment in Table~\ref{tab:reasoning-factors-judgment-anova}.
\input{tables/reasoning-factors-judgment-anova}

\subsection{Factors Influencing Moral Foundations in  Rationale}
In Table~\ref{tab:reasoning-fators-moral-values-annotations} we display analysis result using linear mixed effects on factors that may influence moral foundations appealed to in participants' rationales. We find greater relations with the use cases than personal factors. 
\input{tables/reasoning-factors-moral-values-annotations}

\section{Survey 2: Explicit Weighing of Harms and Benefits of Use Cases}
Although not included in main text, we administered a variation of our main study where we asked participants to explicitly reason through harms and benefits. The decisions were measured before and after the explicit weighing of harms and benefits. However, we saw almost no effect. 

\subsection{Study Overview}
To better understand the reasoning behind participants decisions about the judgment and usage of the use cases, we conducted a second study with 1 survey for each category (Labor Replacement Use Cases and Personal Use Cases). The second study includes an additional set of questions to elicit the harms and benefits of developing and not developing an use case to better understand the reasoning behind participants decisions. Furthermore, we asked participants the judgment and usage decision questions before and after the set of harms and benefits questions to see if listing out reasons about an use case would elicit any change in their decisions. The details of the second study can be found in \ref{sssec:a-details} and the results can be found in \ref{sssec:a-results}.

\subsection{Setup and Details}\label{sssec:a-details}
While these same set of questions are asked for all five use cases for our main study, in our second study, participants are randomly allocated a single use case. The second study differs from the main study with an initial set of judgment questions without open-text rationales (Q1 - Initial to Q4 - Initial), which are followed by explicit listing and weighing of the possible harms and benefits of the use case in the context of both developing and not developing the use case. We then again ask participants the same set of judgment questions along with the open-text questions to elaborate on their reasoning, similar to the main study. To understand how the judgment and usage decisions are affected by other factors, we asked the participants about their demographics, ai literacy levels and several other reasoning factors after the main set of questions, and these questions can be found in \S\ref{sssec:a-questions} The main questions for the second study can be found in Table \ref{app:part-2-questions}. The participant demographics for the second study can be found in Tables \ref{app:demographics-1-jobs-p2} to \ref{app:demographics-3-personal-p2}. The distribution of each use case within each scenario (Labor Replacement Use Cases and Personal Use Cases) for the second study is relatively well-balanced and can be found in Table \ref{tab:study2-use-case}.

\input{tables/demographic-data/study-2-use-case-split}
\input{tables/questions/part2-questions}
\input{tables/demographic-data/demographics-1-jobs-p2}
\input{tables/demographic-data/demographics-2-jobs-p2}
\input{tables/demographic-data/demographics-3-jobs-p2}
\input{tables/demographic-data/demographics-1-personal-p2}
\input{tables/demographic-data/demographics-2-personal-p2}
\input{tables/demographic-data/demographics-3-personal-p2}


\subsection{Results}\label{sssec:a-results}
To explore the possible impact of explicitly weighing harms and benefits of a use case on participant's decision, we analyzed the participant's judgment of acceptability before and after explicit weighing of harms and benefits (Study 2; see \S~\ref{sssec:survey-qs} for details on questions asked). The Type III ANOVA with Satterthwaite's method for measurement time (before, after) indicated a marginally significant effect \( F(1, 201.05) = 3.371, p = 0.0678 \) on usage judgment weighed by confidence, which suggests that explicit harms and benefits weighing may have an influence, albeit not at conventional significance levels. We further analyzed reasoning effect on each subset of data pertinent to each use case through a mixed effects regression model with judgment metric as a dependent variable and measurement time as an independent variable with random effect from subject. Interestingly, the result was significant for Customized Lifestyle Coach AI across different judgments including, existence ($\beta=-0.40,SE=0.18,p<.05$), confidence-weighed existence ($\beta=-1.05,SE=0.51,p<.05$), and confidence-weighed usage judgments ($\beta=-0.75,SE=0.38,p<.05$). Explicit weighing also had a significant effect on confidence of existence judgment for Digital Medical Advice AI ($\beta=0.30,SE=0.11,p<.01$). The negative coefficients for Customized Lifestyle AI suggests that weighing harms and benefits caused participants to lower acceptance and positive coefficient to confidence on judgments on Digital Medical AI suggests that weighing harms and benefits solidified decisions. These diverging effects signify an interesting interaction between use cases and explicit weighing of harms and benefits.

% \input{tables/stakeholders-def}
% \paragraph{Stakeholders}
% Similarly, we annotated stakeholders mentioned in the participants' answers and their relations to the participant (i.e., self or other). We used a taxonomy of stakeholders inspired by previous works \citep{golpayegani2023risk} and labeled for mentions of AI user, subject, developer, deployer, regulator, and supervisor. Please refer to Table~\ref{tab:stakeholders-def} for definitions of each stakeholder category. Additionally, we annotated whether the stakeholders' relations to the participants, specifically, whether the stakeholder represented self or other to further analyze the differences in decision making processes when thinking of either self or others. 
% should i expand more on the difference between the perception of harms to self vs harms to others here or later in the discussion? also refer to the robotics study about beneficial to others here

% below are bunch of tables:
