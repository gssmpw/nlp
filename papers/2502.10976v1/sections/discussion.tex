\section{Discussion}
\label{sec:discussion}
This work has demonstrated how the use of questions to augment representations of documents can yield significant improvement in information retrieval for RAG applications. The need for deduplication introduced by our approach does not incur a significant overhead and can instead improve retrieval quality across a range of benchmarks. 

There are several possible directions of future work. One promising direction is the development of a \emph{self-improving} indexing strategy, possibly with an LLM fine-tuning approach, that adapts over time. 
Specifically, we could monitor user queries and their corresponding feedback (e.g., whether the user found the retrieved context helpful) and selectively ingest \emph{new or corrected} query--context pairs into the index. 
%Such a system would gradually refine its question embeddings, capturing recurring query patterns and emerging topics not present during initial indexing. 

A second direction of future research involves developing \emph{prompt optimization} frameworks (e.g., through automated prompt search or via reinforcement learning) to improve question-generation quality. 
By systematically tuning prompts, we may generate more precise and context-rich questions for each chunk. 

%Such refinement could further boost retrieval performance across diverse domains and user query styles, ultimately making the system more robust and responsive to evolving information needs.
Finally, we can imagine embedding some documents as-is and others with our augmented questions, developing a hybrid approach to RAG. To support the design of such systems, we intend to explore the development of scaling laws w.r.t. all the parameters studied here.
%
%Future work: some docs embed directly, some docs embed with questions
%Future work: Scaling laws
