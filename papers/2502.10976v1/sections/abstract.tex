\begin{abstract}
We present QuOTE (Question-Oriented Text Embeddings), a novel enhancement to retrieval-augmented generation (RAG) systems, aimed at improving document representation for accurate and nuanced retrieval. Unlike traditional RAG pipelines, which rely on embedding raw text chunks, QuOTE augments chunks with hypothetical questions that the chunk can potentially answer, enriching the representation space. This better aligns document embeddings with user query semantics, and helps address issues such as ambiguity and context-dependent relevance. Through extensive experiments across diverse benchmarks, we demonstrate that QuOTE significantly enhances retrieval accuracy, including in multi-hop question-answering tasks. Our findings highlight the versatility of question generation as a fundamental indexing strategy, opening new avenues for integrating question generation into retrieval-based AI pipelines.
%Retrieval-augmented generation (RAG) systems have become a cornerstone of information retrieval, yet they often struggle with aligning document embeddings to the nuances of user queries. We introduce a new paradigm that leverages synthetic questions to enhance document representations and bridge this gap. By generating hypothetical questions that encapsulate the key ideas within text chunks, our approach transforms the retrieval process into one that anticipates user intent. Extensive experiments across diverse benchmarks, including multi-hop question-answering tasks, demonstrate that integrating synthetic questions significantly boosts retrieval performance. Our findings suggest that synthetic question generation is not merely an auxiliary tool but a powerful indexing strategy, offering a fresh perspective on the interplay between document representation and query understanding in RAG pipelines.

\end{abstract}

\keywords{Retrieval Augmented Generation, Question Generation, Synthetic Questions.}
