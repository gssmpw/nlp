\section{Related Work}
\red{Here, we first describe existing AIMC systems designed to support email writing and highlight their limitations.
Second, we review QA-based approaches in goal-oriented tasks and their potential to assist with composing email replies. 
Finally, we examine the psychological and relational impacts of AIMC tools, focusing on the dynamics of recipient-sender relationships and the sender's self-perception.}

\subsection{AI-Mediated Communication Systems for Supporting Writing Emails}
Various machine learning-based approaches have been employed to enhance the productivity of writers.
Earlier writing assistants had modest AI intervention, primarily providing short or single-word suggestions~\cite{hohenstein2018AI-Supported, dunlop2012multidimensional, fowler2015effects, quinn2016cost} and basic grammar correction~\cite{Grammarly}.
With the advancement of LLMs~\cite{chang2024survey}, which allows users to obtain the long and natural-from text output by manipulating prompts, AIMC tools could enhance user input efficiency by suggesting more useful long-form text~\cite{Fu2023Comparing, dhillon2024shaping}.
Several AIMC tools allow users to select preferred tone, style, length~\cite{Grammarly, Foodman2022LaMPost, fu2024text, bastola2024llmbasedsmartreplylsr}, as well as specific content options~\cite{Grammarly, bastola2024llmbasedsmartreplylsr}, such as \textit{``decline politely''} or \textit{``ask a follow-up question''}, without manual crafting of prompt.
However, as these tools only offer simple suggestions, in situations where complex and polite replies are necessary (\textit{e.g.,} exchanging workplace emails with colleagues), users still need to carefully craft their prompts, which can impose a high workload.
Crafting effective prompts for replying to emails requires prompt engineering skills and can be a challenging task~\cite{Zhou2024GlassMail}.
When the initial output does not meet expectations, users may need to create prompts multiple times~\cite{fu2024text}, resulting in negative user satisfaction and task engagement.
% To address this challenge, we propose a LLM-powered QA-based approach, where the AI presents users with questions and answer options, then generates a draft response based on their selections.
\red{To address this, we propose replacing open-ended prompt creation with an LLM-powered QA-based approach, where the system leads the user through a structured question-and-answer process, effectively performing prompt engineering behind the scenes.
This method aims to reduce users’ cognitive load and reliance on prompt expertise while maintaining the quality and personalization of the email reply.}

\subsection{QA-based Approaches in Goal-Oriented Tasks}
% comment by R1
% QA-based communication of AI application intents between stakeholders may also be related work that the authors could consider including into the paper (Section 2.2), although these are non-AI/LLM based approaches. E.g., worksheets included in the Google People + AI Guidebook, AINeedsPlanner (DIS ‘24) (I think this one points to some potential AI support of the QA process). There are also similar approaches where questions are used as a way to gather underlying intents and information (questionnaire / survey), some of which may be relevant.
\label{sec:2.2}
\red{Answering questions is one of the effective approaches for users to clarify their needs~\cite{kim2024aineedsplanner,aiguidebook}. 
For example, Kim~\textit{et al.}~\cite{kim2024aineedsplanner} designed a workbook using questions that guide users to organize their thoughts for developing AI projects.
In particular, answering questions has demonstrated its effectiveness in helping users get engaged in goal-oriented tasks, such as writing tasks.} 
%previous research suggests that a QA-based approach could have various positive effects in supporting users to get engaged, such as writing tasks.
Specifically, \red{asking questions} may be effective in extracting people's intent and aligning LLM outputs more closely with users' expectations~\cite{cao2023comprehensive}.
For instance, in conversational recommender systems~\cite{jannach2021survey}, chatbot questions are helpful in providing item suggestions tailored to users' preferences.
AI-driven questioning, inspired by Socratic methods, has been shown to promote critical thinking and improve users' ability to identify logical fallacies~\cite{danry2023dont}.
Moreover, \red{asking questions} may also facilitate task initiation, which can be particularly beneficial for individuals with a tendency to procrastinate, as they often delay responding to work-related emails~\cite{shirren2011decisional}.
This idea is derived from Fogg’s behavior model~\cite{fogg2009behavior}, which indicates that behavior change occurs when motivation, trigger, and ability converge.
Since AI outputs can capture users’ interest~\cite{brandtzaeg2017why, ling2021factors}, they may stimulate curiosity, increase motivation~\cite{berlyne1960conflict}, and serve as an effective trigger for task initiation.

% The literature above motivated us to explore a QA-based approach for utilizing LLMs to assist with email replies.
\red{Applying these insights to email communication, we anticipate that a QA-based approach will not only simplify prompt creation for LLMs but also act as a cognitive scaffold for understanding incoming messages.}
\red{By breaking down the content of the received email into manageable questions, the system can highlight key information and intentions from the sender. 
This reduces the cognitive load associated with interpreting lengthy or ambiguous emails, enabling users to respond more efficiently and effectively.}
Thus, our goal is to investigate how a QA-based approach during email replies affects people's efficiency, cognitive load, task satisfaction, difficulty in initiating action, and the quality of the emails.


% Google People + AI Guidebook
% Googleの「People + AI Guidebook」は、AIプロダクトを設計・開発する際のベストプラクティスやツールを提供するガイドブックです。この中には、ワークシートやQA形式の設問が含まれており、これを使うことでプロジェクトの目標やニーズを体系的に整理できます。

% AINeedsPlanner (DIS ‘24)
% AINeedsPlannerは、AIプロジェクトの計画段階におけるクライアントとAI専門家のコラボレーションを円滑にするために設計されたワークブック（ドキュメント形式のガイド）です

% For instance, AINeedsPlanner~\cite{kim2024aineedsplanner}, a workbook designed to support collaboration between clients and AI experts during the planning stages of AI projects, demonstrated that structured questions help clients organize their thoughts and reduce the risk of overlooking necessary information or key discussion points. 
% Examples include interviews, surveys, and resources like the People + AI Guidebook~\footnote{https://pair.withgoogle.com/guidebook/}.
% Furthermore, by leveraging LLMs, it is possible to dynamically generate more contextually relevant questions, which may enhance these effects.

\subsection{The Psychological and Relational Impact of AIMC Tools}
Previous research has extensively discussed the impact of AIMC tools on the psychological aspects of both recipients and senders, as well as on their relationships. 
These effects can be broadly categorized into two areas:
(1) The impact on the recipient and sender relationships
(2) The impact on the sender’s self-perception.

\subsubsection{Impact on Recipient and Sender Relationships}
Emails can influence recipient-sender relationships through their content, speed, and context. 

Regarding the \textit{content} of the email, Robertson \textit{et al.}~\cite{Robertson2021ICant} identified three key elements of email content that, when missing, negatively impact the sender’s perception.
The first element, structural features, refers to whether the email includes structural components such as greetings, signatures, and closings. 
The second element, personal authenticity, measures the extent to which the suggested email aligns with the user’s personal tone. 
The third element, semantic and tone coherence, concerns whether the proposed email reflects the user’s intent and the broader context of the communication.
Failure to meet these criteria can lead to confusion on the recipient’s part and might reveal or raise suspicions about the use of AI, ultimately damaging the sender’s impression~\cite{hohenstein2023artificial, Jakesch2019AI-Mediated, Liu2022Will}. 
Therefore, we see the QA-based approach has the potential to address these issues by preserving the three key components of email while reflecting the user’s intent.

The \textit{speed} of email responses also influences receivers' impressions of the sender. 
Kalman and Rafaeli~\cite{yoram2011online} found that responding to business emails more quickly led to better evaluations, including increased credibility and attractiveness.
However, many people (\textit{e.g.}, administrative staff and information workers) have to manage large volumes of emails on a daily basis ~\cite{McKinseySocialEconomy}. 
As the number of incoming messages increases, response rates decline, and the content of email replies becomes shorter~\cite{kooti2015evolution}, which can potentially influence the impression formation between senders and receivers.
Our hypothesis is that a QA-based approach potentially enhances the speed of reply by lowering the barrier to task initiation.

The importance of these elements depends on \textit{context}. 
Relationships are influenced by factors such as social hierarchy, vested interests, and intimacy. 
Research indicates that in hierarchical or formal settings, both content and speed significantly affect the sender’s impression~\cite{francis2015influence, stephens2011organizational}. 
Consequently, the utility of AIMC tools also varies with social context~\cite{fu2024text, Robertson2021ICant}. 
Fu~\textit{et al.}~\cite{fu2024text} found that satisfaction with AI-generated suggestions depends on communication stakes (high vs. low) and relationship dynamics (formal vs. informal). 
They further suggested that AIMC tools are especially useful in formal settings, where established norms prevail, while their necessity decreases in informal contexts.
Thus, we mainly investigate our research questions in the formal context, where AIMC tools are known to be useful.

\subsubsection{Impact on Sender's Self-Perception}
Previous research indicates that significant AI intervention, with minimal operator input, tends to reduce people's sense of agency~\cite{Fu2023Comparing, mieczkowski2022examining} and control~\cite{Draxler2024The, Buschek2021The, kobiella2024if}. 
The agency is often characterized by action initiation~\cite{moore2012sense} and determination~\cite{bandura2001social}, both by the user. 
Sankaran~\textit{et al.}\cite{Sankaran2021Exploring} identified factors critical to maintaining people's agency, such as considering user preferences and allowing decision-making.
For instance, tasks like creating prompts and revising AI output have been found to foster a sense of accomplishment in users~\cite{kobiella2024if}.
However, in a QA-based approach, it is still unclear whether users have an increased or decreased sense of agency and control.
Thus, this study examines how the QA-based approach affects users’ sense of agency and control and how they perceive the trade-off between these feelings and the system’s benefits to better understand the approach’s advantages and risks.