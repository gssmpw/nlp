\appendix

\lstset{
  backgroundcolor=\color{gray!20}, % 20% gray background
  basicstyle=\ttfamily\footnotesize, % Monospaced font with smaller size
  breaklines=true,                 % Automatically break long lines
  frame=single,                    % Frame the listing
  framerule=0pt,                   % No frame border
  xleftmargin=5pt, xrightmargin=5pt % Add some margin around the text
}


\section{Prompt}
In this section, we list the full prompts given to the LLM, which were used in this paper.
\subsection{Prompt to Generate Questions}
\begin{lstlisting}
###Instruction###
You are assisting the audience who has received an email and needs to respond.
You're like a secretary for your audience, asking them questions and creating email responses on their behalf based on their answers.
Your goal is to make it as clear as possible what and how your audience wants to answer in response to all requirements of the email.
Therefore, you must create as specific questions as possible.
Specifically, you will assist your audience in composing emails by following 3 steps:

Step 1: Create Questions:  
    To achieve your goal, you must create well-thought-out questions without omission by considering the sender's intent and requirements. 
    The number and content of the questions must be determined with this in mind.
Step 2: Receive Answers:  
    Ask your audience the questions you created and collect their responses. 
    These will guide the crafting of the reply.
Step 3: Propose a Reply:  
    Based on the answers received, suggest a reply that your audience can edit and send.
    From now on, you will perform step 1.  

You must consider the following 7 matters in generating your response.

1. You must create questions with choices for your audience and output the results in JSON format.
2. The questions must be created in the native language of your audience.
3. If necessary, your audience can write any free answers to your questions, so you will be penalized if you create an "other" option.
4. In 'corresponding_part', you must quote a part of the provided 'Incoming Mail' verbatim. That is, output corresponding_part = IncomingMail_HTML[x:x+h]. 
5. You must quote spaces, `<br>`, periods, and commas exactly as in the provided 'Incoming Mail'. 
6. You will be penalized if you edit or combine multiple parts of the 'Incoming Mail' for your questions.
7. You will be penalized if you create unhelpful questions to compose a reply. You must keep the number of questions to a minimum.

I'm going to tip $100 for a better solution!
Ensure that your output is unbiased and avoids relying on stereotypes.

###Output JSON Format###
{
    "questions": [
        {
            "id": "1",
            "question": "Will you participate in the event on October 24th?", 
            "choices": ["Yes", "No"], 
            "corresponding_part": "We will hold an event on October 24th."
        },
        {
            "id": "2",
            "question": "Please select the available dates (multiple selections possible).", 
            "choices": ["July 10th", "July 11th", "July 12th", "July 13th", "July 14th", "July 15th", "July 16th"], 
            "corresponding_part": "Please let us know your available dates within a week."
        }
    ]
}
\end{lstlisting}

\subsection{Prompt to Generate Reply Draft}
Below is the prompt used to generate a balanced-length description.
\begin{lstlisting}
Please provide a draft reply to the sender of this email on behalf of the user.
\end{lstlisting}

% \section{Proposed LLM-Powered QA-Based Approach: ResQ}
% % 本セクションでは、電子メール対応タスクをサポートするために提案されたアプローチ「ResQ」について説明する
% This section describes the proposed approach, ResQ, for supporting email response tasks. 
% % \input{figures_tables/fig_overview_of_process}
% % \input{figures_tables/fig_interface}
% % 図は、ResQのアプローチの全体的な流れについて説明している
% % (A) ユーザが返信作業を開始したことを検知すると、大規模言語モデル (本研究ではGPT-4o) を使用して、多肢選択式の質問を生成する。
% % ユーザは、この質問に対して回答を行うことで、自身の返信方針をAIに伝える
% % (B) 最後に、ユーザが"Generate Reply'' buttonを押したことを検知したら、返信のドラフトをユーザに提示する
% % 図は、実際のResQのinterfaceである
% % 以下のセクションでは、それぞれの手順における具体的な機能について説明する
% Fig.~\ref{fig_overview_of_process} illustrates the overview of the process of a reply message using ResQ.
% % (A) After the system detects users' initiation of the reply task, it generates multiple-choice questions using an LLM (in this study, GPT-4o~\cite{GPT4o}). 
% % (B) Then, users communicate their reply strategy to the AI by responding to these questions.
% % (C) When the system detects that users have pressed the ``Generate Reply'' button, it presents a draft of the reply to users.
% % (D) Finally, users review and revise the reply draft generated by the LLM and send the response.
% Fig.~\ref{fig_interface} shows the actual interface of ResQ.
% The following sections describe the specific functions involved in each step of this process.

% \paragraph{\textbf{A: Generate Questions}}
% \label{sec:generate_questions}
% % ResQは返信の必要性を検知すると、大規模言語モデル (本研究ではGPT-4o) を使用して、多肢選択式の質問を生成する
% % また我々は、ユーザが質問をクリックすると、その質問が受信メールのどの部分に対応しているかがハイライトされるようにした
% % 我々はこれらの機能を実現するために、まずモデルに対して、モデルの役割（ユーザに対する質問と有益そうな選択肢のペアを複数生成すること）と、作成する質問の目的（メールに含まれる全ての要求を抽出し、送信者がそれぞれに対してどのように返答したいかを明確にすること）をプロンプトとして与えた
% % さらに、モデルに受信メールの文章、タイトル、送信者の情報（名前、メールアドレス）、受信メールの過去のやり取りの文章、ユーザの情報（名前、メールアドレス）を提供した
% When the first activates ResQ to reply to an email, the system uses an LLM (in this study, GPT-4o~\cite{GPT4o}) to generate multiple-choice questions (Fig.~\ref{fig_interface}-C). 
% Additionally, when users click on the generated question, the relevant part of the email is highlighted (Fig.~\ref{fig_interface}-A).
% To implement these features, we first provided the LLM with the email's text, subject, sender information, text from past email interactions, and the user's information (name and email address).
% The LLM then extracts all parts that require a user's reply, presents the possible response options, and generates a question for the user. 
% % プロンプトは~\cite{relatedwork}を参考に作成し、文脈を踏まえており、返信を作成する上で役に立ち、適切な数の（メールのすべての要件に対しては漏れなく）質問と、それに役立つ選択肢を生成するように指示した。
% % またプロンプトには質問と選択肢の生成例を含めることで、XXXした。
% \red{We designed the prompt with reference to~\cite{bsharat2023principled}, incorporating contextual considerations to ensure it effectively supports reply composition. 
% We instructed the LLM to generate an appropriate number of questions that comprehensively cover all the email's requirements without omissions, along with relevant response options. 
% To further guide the model and improve output accuracy, we included examples of question and option generation within the prompt.}
% The detailed prompt used for this function is shown in the appendix. 
% The prompt used for this function is shown in the appendix. 

% \paragraph{\textbf{B: Answer Questions}}
% % 次にユーザは受信メールと生成された質問、選択肢を同時に見ながら、質問に回答する
% % 我々は有益な選択肢がない場合を想定して、ユーザ自身が選択肢を追加できるようにした
% % また、LLMにメールのcontextを伝えることができるように、送信者と受信者の関係性を記入できるboxを設置した
% % さらに以前の研究に基づき~\cite{fu2024text}、ユーザがAIメールの文章をカスタマイズできるように、ユーザが期待する返信のトーンやスタイル、長さを調整するための選択肢を提供した
% % また、ユーザがそれ以外のリクエストをAIに対してできるように、AIに対する自由記述欄を設置した
% % ユーザはこれらの作業が完了するとGenerate Replyボタンを押す
% Next, users view the incoming email (Fig.~\ref{fig_interface}-B) alongside the generated questions (Fig.~\ref{fig_interface}-C) and options and proceed to answer them. 
% In anticipation of situations where none of the provided options are useful, we enabled users to add their own options (Fig.~\ref{fig_interface}-D). 
% Additionally, to help the LLM better understand the context of the email, we introduced a box where users can specify the relationship between the sender and the recipient (Fig.~\ref{fig_interface}-E, top). 
% Furthermore, following previous research~\cite{fu2024text}, we provided users with controls to adjust the tone, style, and length of the reply to match their preferences better, thereby giving them more flexibility in customizing the AI-generated response (Fig.~\ref{fig_interface}-E, middle). 
% A free-text field was also included to allow users to make other specific AI requests (Fig.~\ref{fig_interface}-E, bottom). 
% After completing these steps, users can click the ``Generate Reply'' button (Fig.~\ref{fig_interface}-F).

% \paragraph{\textbf{C: Generate Reply Draft}}
% % ResQはユーザが"Generate Reply"ボタンを押したことを検知すると、大規模言語モデルを使用して、返信のドラフトを作成する
% % ユーザの期待するような返信のドラフトが出力されるように、我々はモデルに対して、受信メールとその関連情報、AIの質問とそれに対応するユーザの回答、ユーザが返信案に期待する他の要素（トーン、スタイル、長さ、その他の要望）、ユーザの情報を提供した
% When the user clicks the ``Generate Reply'' button, ResQ detects the action and uses the LLM to generate a reply draft.
% To ensure that the draft aligns with users' expectations, we first provided the LLM with the information provided when Sec.~\ref{sec:generate_questions}, the generated questions, corresponding users' answers, and users' preferences (\textit{e.g.}, tone, style, length, and any additional requests).
% Then, the LLM generates a draft of the reply.
% The prompt used for this function is shown in the appendix.

% \paragraph{\textbf{D: Review Reply Draft}}
% Once the draft reply is generated, users can review the draft in detail (Fig.~\ref{fig_interface}-G).
% Moreover, if users find that extensive revisions are needed or if they want to explore alternative phrasing, they have the option to request the AI to regenerate a new draft based on updated input or preferences.
% After completing these steps, users can click the ``Reply'' button (Fig.~\ref{fig_interface}-H).

% \section{User Comments in Study 1}
% % We added a new subsection, "User Comments," to present follow-up interview results, including participant feedback on useful questions (Sec.6.4). 
% \subsection{Participants' Email-Replying Process (RQ1)}
% \paragraph{Enhanced Efficiency and Reduced Cognitive Load when Replying to Emails (H1-a, H1-b)}
% % 参加者のコメントから、QA-based conditionは期待通り機能し、参加者の効率向上や負担低減に貢献したことが確認できます。
% % 質問で要点をまとめてくれ、メール本文の対応箇所がハイライトされてたので、メールの理解の効率が上がり、負担が減りました [P10]
% % QA-based条件では、Prompt作成の技術がなくても、期待する出力を簡単に得ることができました。[P6]
% % Prompt-based条件では、結局自分で相手のメールを全て読み、回答すべきことを整理する必要がありました [P4]
% % Prompt-based条件では、自分でAIに対する指示を一から考える必要があり、手動の条件と効率や負担に差を感じませんでした。一方でQA-based条件は、圧倒的に早く返信を作成することができました。[P5]
% \red{
% Participants' comments confirmed that the QA-based improved efficiency and reduced workload when replying to emails. 
% P10 explained, \textit{``In the QA-based condition, AI summarized key points through questions and highlighted relevant sections of the email body, which facilitated my understanding of the email and reduced my overall burden''}.
% P6 shared, \textit{``In the QA-based condition, I could easily obtain the desired output even without the technical skills to create prompts''}.
% In contrast, the Prompt-based condition required extra effort. 
% P4 noted, \textit{``In the Prompt-based condition, I had to read the counterpart's email completely and decide what to respond to''}. 
% P5 elaborated, \textit{``In the Prompt-based condition, I had to think of instructions for the AI from scratch, making it feel no different from the No-AI condition in terms of efficiency and workload. On the other hand, the QA-based condition allowed me to compose responses faster''}.
% }

% \paragraph{Reduced Difficulty in Initiating the Action for Replying to Emails (H1-d)}
% % 参加者のコメントから、QA-based conditionでは、全体的な労力が下がるとともに、作業開始時のAIによるの質問が、タスク開始の障壁の低下に役立つことがわかりました。
% % 最初にAIが質問を投げかけてくれるので、作業開始時の思考の労力がなくなり、作業に取り掛かる際のストレスが減りました[P10]
% % 相手の文章を読む時間が省けたことで、作業開始の心理的障壁が下がりました。[P5]
% \red{
% Comments from participants indicated that the QA-based condition helped lower the barriers to task initiation through AI-generated questions at the start of the process. 
% P10 explained, \textit{``Since the AI prompted me with questions at the beginning, the mental effort required to start thinking about the task was eliminated, reducing the stress associated with initiating the work''}. 
% P5 noted, \textit{``By saving the time needed to read the counterpart's text, the psychological barrier to starting the task was lowered''}.
% }

% \paragraph{Decreased Sense of Agency and Control (H1-e)}
% % QA-based conditionでは、agencyやcontrolの感覚が他の条件に比べて低下したと回答した参加者は、次のようにコメントした。
% % 「agencyとcontrolの感覚は、プロンプトを自分で打った量に比例しました。」[P7, 8, 9, 10]
% % 「QA-based条件では、要点も絞ってくれたので、AIに任せようという思いが強くなりました。」[P4]
% % 一方で感覚が変化しなかったと回答した参加者は「AIに任せても、自分で確認と修正を行ったので、agencyやcontrolの感覚に変化はありませんでした」[P3]と説明した。
% \red{
% Participants reported a decrease in their sense of agency and control in the QA-based condition.
% \textit{``The sense of agency and control was proportional to the amount of text I typed myself''} [P7, P8, P9, P10]. 
% \textit{``Under the QA-based condition, since the AI helped narrow down the key points, I felt a stronger inclination to leave the task to the AI''} [P4].
% On the other hand, one participant who reported no change in their sense of agency or control explained, \textit{``Even though I relied on the AI, I reviewed and edited the output myself, so there was no change in my sense of agency or control''} [P3].
% }

% \paragraph{Future Preference (H1-c)}
% % 多くの参加者はメール返信の効率が上がる、負担が減る、質が高いメールを執筆できるという理由から、QA-based conditionで返信をしたいと回答しました。
% % 自分で返信を考えるより、AIを使った方が、質の高い返信を早く作ることができました。特にQA-based conditionではその効果が大きかったので、将来はQA-based conditionで返信したいと思いました。[P6]
% % 一方でsense of agencyの低下や、AIへの依存の危惧を理由に、QA-based conditionでのメール返信を忌避する参加者もいました。
% % 時間がない時や、スピードを重視したい時[P4]、重要度が低い時[P5]は、QA-based conditionで返信をしたいと思ったが、そうでない場合は自分で執筆したいと思いました。
% % 「Prompt-based条件では、QA-based条件より思考する必要が多く、それが楽しかったです」 [P7]
% % 返信作業が楽にはなりましたが、メールを細部まで読まなくなり、内容が頭に入っていない感じがしたので、将来使いたいとは思いませんでした。[P11]
% \red{
% Participants expressed a preference for using the QA-based condition for email responses, citing increased efficiency, reduced workload, and the ability to produce high-quality emails as the primary reasons. 
% One participant explained, \textit{``Using AI allowed me to compose high-quality responses faster than if I had written them myself. The effect was particularly significant in the QA-based condition, which is why I would prefer to use it in the future''} [P6].
% }
% \red{However, some participants were hesitant to adopt the QA-based condition due to concerns about a reduced sense of agency or over-reliance on AI. 
% Participants noted that they preferred the QA-based condition \textit{``when time is limited or speed is important''} [P4] or \textit{when the email is of low importance''} [P5], but in other situations, they favored writing responses themselves.
% One participant reflected, \textit{``In the prompt-based condition, I found that I needed to think more actively compared to the QA-based condition, and I enjoyed that process''} [P7].
% Another observed, \textit{``While the QA-based condition made responding easier, I felt that I was no longer fully reading and absorbing the content of emails, which made me hesitant to use it in the future''} [P11].
% }

% \paragraph{Quality of AI-generated Questions and Options}
% % 参加者はQA-based conditionにおいて生成された質問や選択肢について、有益であったものとそうでなかったものがあったとコメントした。
% % 参加者は有益でない質問の例として、メール送信者の意図を汲み取れていないもの [P2, P11]、自分と相手の立場を勘違いしているもの [P4, P8]を挙げた。
% % またある参加者は、「自分が言いたいことに関連する質問がない場合、質問機能自体が役に立たなかった」[P8]と回答した。
% % また参加者は、質問の数についても意見を述べた
% % 参加者は「用件ごとに質問を生成してくれたのが、メールを理解する上で役に立った」[P4, P5, P8, P9, P10, P11]と回答した一方で、「質問が多すぎると煩雑に感じることもあった。またそれに全て答えると、返信が冗長になってしまった。」[P7, P12]と回答する参加者もいた。
% % また、参加者は選択肢についても意見を述べた
% % 参加者は、「（日程調整のシチュエーションにおいて）選択肢の中に自分が選びたい日程がなかったので、自分で日程を入力する必要があった」[P2]と説明し「より多くの選択肢を生成して欲しかった」と説明した[P8]。
% % 一方である参加者は、「必要以上に多くの選択肢があったときに、煩わしさを感じた」[P4]と説明した。
% \red{
% Participants commented on the questions and options generated by the QA-based condition, noting that some were useful while others were not. 
% Examples of less useful questions included those that failed to accurately capture the sender's intent [P2, P11] or misinterpreted the relationship between the sender and recipient [P4, P8]. 
% Additionally, one participant remarked, \textit{``when there were no questions related to what I wanted to say, the question feature itself was not helpful''} [P8].
% }

% \red{
% Participants also shared mixed opinions on the number of questions generated. 
% Some participants noted that \textit{``generating questions for each topic helped understand the email''} [P4, P5, P8, P9, P10, P11].
% However, others felt \textit{``an excessive number of questions felt overwhelming, and responding to all of them made the reply unnecessarily lengthy''} [P7, P12].
% }

% \red{
% Feedback on the generated options was similarly divided. 
% For instance, in scheduling scenarios, one participant shared that \textit{``none of the suggested dates matched what I wanted, so I had to input the date myself''} [P2] and another participant \textit{``wished for more options or a more flexible input type''} [P8].
% In contrast, another participant stated that \textit{``having more options than necessary felt burdensome''} [P4].
% }

% \subsection{Quality of the Email Responses (RQ2)}
% % ほとんどの参加者は、AIを使うと、構造・丁寧さ・言葉遣いが改善され、全体的に良い文章を書けたと述べた
% % また参加者は、「Prompt-based条件だと、相手の要求を見落としていたかもしれないが、QA-based条件では自信を持って返信を作成することができた」 [P2, 4]と述べた
% % さらにある参加者は、「QA-based条件では、回答してもしなくても良いこと「XXの件、承知しました、など。」にも丁寧に返答を書いてくれた」 [P9]と述べ、QA-based条件によってメールの丁寧さが向上したことを強調した
% \paragraph{Scaffolding a structured response}
% \red{
% Most participants stated that using AI improved their writing structure, politeness, and choice of words, ultimately enabling them to produce better overall responses. 
% Furthermore, participants remarked, \textit{``Under the prompt-based condition, I might have overlooked the recipient's requests, but under the QA-based condition, I was able to craft responses with confidence''} [P2, P4]. 
% Additionally, one participant emphasized that \textit{``Under the QA-based condition, the AI even provided polite responses to matters where a reply was optional, such as acknowledging something with phrases like 'I Understood regarding XX, etc.'''} [P9], highlighting how the QA-based condition enhanced the politeness of email communication.
% }

% \subsection{Relationship between Participants and Their Counterpart (RQ3)}
% % 参加者は、``相手との間に知覚する心理的距離は労力に比例した''と報告し、PXXは``特にQA-based条件では選択肢を選ぶだけだった相手のことを考えることが少なかった''と報告した。
% % 一方でPXXは、``自分で返信を考えるより、AIを使うと相手に良い印象を与えられるメッセージを作ることができたので、関係性を近く感じた''と報告した
% \red{
% Participants shared differing views on how AI's involvement affected their psychological distance from their counterparts.
% Several participants reported that the psychological distance they felt from the other person was directly related to the amount of effort they put in [P2, P9, P11].
% % \textit{``the psychological distance I perceived from the counterpart was proportional to the effort exerted''} [P2, P9, P11].
% Furthermore, P6 noted that \textit{``especially under QA-based condition, I barely thought about the counterpart because I only selected options to create responses''}.
% In contrast, P8 reported that \textit{``compared to composing replies myself, using AI allowed me to create messages that left a better impression on my counterpart, which made the relationship feel closer''}.
% }
% % \subsubsection{Psychological Distance between Participants and Their Counterpart (H3-b)}

\section{\blue{Order Effect in Study 1}}
\blue{We conducted analyses to examine whether the order of conditions influenced various dependent variables. 
Table~\ref{tab_ordereffects} summarizes the results of the order effect and its interaction with the condition. 
Depending on the nature of the data, we employed either a Mixed-Design ANOVA or the Aligned Rank Transform (ART) method.}

\begin{table*}[t]
\caption{Order effects in Study 1 (* indicates significance at the 0.05 level).}
\Description{The table presents the order effects observed in Study 1, examining whether the order of conditions influenced various measurements. It reports p-values for the main effect of Order and the interaction effect between Condition and Order, with asterisks indicating statistical significance at the 0.05 level. The statistical method used for each measurement is also specified, including Mixed-Design ANOVA and Mixed-Design ANOVA with Aligned Rank Transform (ART). For Efficiency of Replying to Emails, the Order effect has a p-value of 0.643, and the Condition × Order interaction has a p-value of 0.454, analyzed using Mixed-Design ANOVA. Prompt Character Count shows an Order effect p-value of 0.052, close to significance, while the Condition × Order interaction has a p-value of 0.186, also analyzed using Mixed-Design ANOVA. Raw TLX, which measures subjective workload, has a significant Order effect (p < 0.05), indicating that workload perception is influenced by order, whereas its Condition × Order interaction is non-significant (p = 0.978), analyzed using Mixed-Design ANOVA. For Difficulty in Understanding Email Content, the Order effect p-value is 0.188, and the Condition × Order interaction p-value is 0.232, analyzed using Mixed-Design ANOVA with ART. Satisfaction with Completing Tasks shows non-significant effects, with an Order effect p-value of 0.348 and a Condition × Order interaction p-value of 0.175, analyzed using Mixed-Design ANOVA. Similarly, Difficulty for Task Initiation has an Order effect p-value of 0.131 and a Condition × Order interaction p-value of 0.515, analyzed using Mixed-Design ANOVA with ART. Psychological perceptions are also analyzed. Sense of Agency shows non-significant results, with an Order effect p-value of 0.982 and a Condition × Order interaction p-value of 0.911, analyzed using Mixed-Design ANOVA with ART. Sense of Control similarly has an Order effect p-value of 0.825 and a Condition × Order interaction p-value of 0.871, analyzed using Mixed-Design ANOVA with ART. Regarding Perceived Quality of the Email, the Order effect is 0.930, and the Condition × Order interaction is 0.433, analyzed using Mixed-Design ANOVA. Perceived Impression of Participants also shows non-significant effects, with an Order effect p-value of 0.963 and a Condition × Order interaction p-value of 0.481, analyzed using Mixed-Design ANOVA. Finally, Psychological Distance presents an Order effect p-value of 1.000, indicating no effect of order, but its Condition × Order interaction is significant (p < 0.05), suggesting that condition effects on psychological distance are influenced by order. This measurement is analyzed using Mixed-Design ANOVA with ART.}
\label{tab_ordereffects}
\blue{
\begin{tabular}{cccc}
\hline
Measurements                              & Order (p-value) & Condition $\times$ Order (p-value) & Statistical Method          \\ \hline
Efficiency of Replying to Emails          & 0.643            & 0.454                        & Mixed-Design ANOVA          \\
Prompt Character Count                    & 0.052           & 0.186                       & Mixed-Design ANOVA          \\
Raw TLX                                   & $<0.05$*         & 0.978                       & Mixed-Design ANOVA          \\
Difficulty in Understanding Email Content & 0.188           & 0.232                       & Mixed-Design ANOVA with ART \\
Satisfaction with Completing Tasks        & 0.348           & 0.175                       & Mixed-Design ANOVA          \\
Difficulty for Task Initiation            & 0.131           & 0.515                       & Mixed-Design ANOVA with ART \\
Sense of Agency                           & 0.982           & 0.911                       & Mixed-Design ANOVA with ART \\
Sense of Control                          & 0.825           & 0.871                       & Mixed-Design ANOVA with ART \\
Perceived Quality of the Email            & 0.93            & 0.433                       & Mixed-Design ANOVA          \\
Perceived Impression of Participants      & 0.963           & 0.481                       & Mixed-Design ANOVA          \\
Psychological Distance                    & 1.000           & $<0.05$*                     & Mixed-Design ANOVA with ART \\ \hline
\end{tabular}
}
\end{table*}

\blue{The results indicate that the order effect was not significant for most dependent variables. 
However, a significant effect was observed for Raw TLX ($p = 0.041$), suggesting that task load perception may have been influenced by the presentation order. 
Additionally, a significant interaction effect between condition and order was found for IOS ($p = 0.043$), indicating that the order of presentation might have impacted this specific measure.}

\section{Future Preference in Study 1}
\input{figures_tables/fig_study1_preference}
\red{We evaluated participants' preferences for future use across all conditions using a 7-point Likert scale.
Participants rated their agreement with the statement, ``I would prefer to use this approach for replying to emails in the future,'' where 1 indicates strongly disagree, 4 indicates neutral, and 7 indicates strongly agree.}

\red{The questionnaire survey results about participants' future preferences are shown in Fig.~\ref{fig_study1_preference}.
According to the Friedman test, a significant difference in participants' future preferences was observed among the three conditions $(\chi^2(2)=8.8, p=0.012, W=0.37)$.
Post-hoc analysis using the Durbin-Conover test with Holm correction revealed that participants would prefer responding in the QA-based condition compared to the No-AI condition $(p=0.012, r=0.67)$.
However, no significant difference was found between the Prompt-based and QA-based conditions $(p=0.800, r=0.27)$.}

\section{Technical Details of ResQ}
\input{figures_tables/fig_UI}
\red{In this section, we provide the specific implementation details and user interface used in Study 2.
We developed a prototype system consisting of a Chrome extension and a backend service to enable participants to reply to emails using Gmail on a PC.
The Chrome extension detected the initiation of the reply task when participants clicked the ``Reply with AI'' button in the Gmail reply box (see Fig.~\ref{fig_UI}).
Upon clicking the button, the extension extracted the email content directly from Gmail’s DOM structure using JavaScript and sent it to a backend API endpoint implemented with FastAPI~\footnote{\url{https://fastapi.tiangolo.com}}.
The backend, hosted on an AWS EC2 instance~\footnote{\url{https://aws.amazon.com/ec2/}}, received the email content and forwarded it to the OpenAI API~\footnote{\url{https://platform.openai.com/docs/}} to generate questions or reply suggestions. 
These outputs were then returned to the Chrome extension and displayed to participant in a new reply editor.
Finally, participants revise the reply suggestions and submit them back to the Gmail reply box by clicking the ``Reply'' button.
To ensure privacy, neither the email content nor the participants' responses were accessible to the experimenters or stored on the server.}

\red{Additionally, to implement ResQ's features for generating questions and options, we provided the LLM with various contextual inputs, including the email text, subject, sender information, text from prior email interactions, and the user's details (such as name and email address). 
Furthermore, to ensure that the generated draft aligned with user expectations, the LLM was further given information outlined in Sec.~\ref{sec:generate_questions}, including the generated questions, corresponding user answers, and user preferences (\textit{e.g.}, tone, style, length, and any specific requests). 
Based on this input, the LLM produced a draft of the email reply.}