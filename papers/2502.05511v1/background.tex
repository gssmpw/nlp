\section{Background and Setup}
\label{sec:background}



\subsection{Markov Paging}
\label{sec:markov-paging}

The Markov Paging model assumes that the page requests are drawn from a time-homogeneous Markov chain, whose state space is the set of all pages. More precisely, the Markov Paging model is specified by an initial distribution on the $n$ pages, and a transition matrix $M \in [0,1]^{n \times n}$, where $M_{i,j}$ specifies the probability that page $j$ is requested next, conditioned on the most recently requested page being $i$. The form of the initial distribution will not be too important for our purposes, but for concreteness, we can assume it to be the uniform distribution on the $n$ pages. It is typically assumed that the transition matrix $M$ is completely known to the paging algorithm/page eviction policy---however, the realized page sequence is not. Upon drawing $T$ page requests from the Markov chain, the objective function that a page eviction policy $\mcA$ seeks to minimize is:
\begin{align}
    \label{eqn:objective}
    \E[\cost(\mcA, T)] &= \E_{M, \mcA}\left[\sum_{t=1}^T\Ind[\text{$\mcA$ suffers a cache miss at time $t$}]\right],
\end{align}
where the expectation is with respect to both the random page request sequence drawn from $M$, and the randomness in the policy $\mcA$. We denote by $\opt$ the policy that minimizes the objective in \eqref{eqn:objective}. For $c \ge 1$, an eviction policy $\mcA$ is said to $c$-competitive against $\opt$ if for every $T$, $ \E[\cost(\mcA, T)] \le c \cdot \E[\cost(\opt, T)]$.

It is worth emphasizing again that the competitive analysis above is with respect to the optimal \textit{online} strategy, in that $\opt$ does not know beforehand the realized sequence of page requests. Contrast this to the best \textit{offline} strategy, which also additionally knows the realized sequence of page requests. As mentioned previously, the Farthest-in-Future policy \citep{belady1966study}, which at any cache miss, evicts the page that is next requested latest in the remainder of the sequence, is known to be an optimal offline policy. %

It is indeed possible to compute $\opt$ exactly---however, the best known ways do this are computationally very expensive, requiring an exponential amount of computation in $k$.

\begin{theorem}[Theorems 1, 2 in \cite{karlin1992markov}]
    \label{thm:opt-computation}
    The optimal online policy that minimizes $\lim_{T \to \infty}\frac{1}{T}\cdot\E[\cost(\mcA, T)]$ over all policies $\mcA$ can be computed exactly by solving a linear program in $n\binom{n}{k}$ variables. Furthermore, for any finite $T$, an optimal online policy that minimizes $\E[\cost(\mcA, T)]$ can be computed in time $T \cdot n^{\Omega(k)}$. %
\end{theorem}

In the latter case above when $T$ is finite, the optimal online policy can be computed, for example, via dynamic programming (using the ``Bellman operator''), where one writes the recurrence for taking a single step of the optimal policy, and unrolls time backwards from $T$. However, the state space in the dynamic program comprises of all $\{$cache state, requested page$\}$ pairs---there are $n^{\Omega(k)}$ many of these. Similarly, the linear program in the case where $T \to \infty$ also comprises of a single variable for each such state. Unfortunately, we do not know of any better algorithms that are both optimal and run in polynomial time in $k$. Therefore, one seeks efficient polynomial time (in $k$) algorithms that are approximately optimal, i.e., achieve $c$-competitiveness with $\opt$ for $c$ as close to $1$ as possible.

Towards this, \cite{karlin1992markov} showed that several intuitive eviction policies (e.g., on a cache miss, evict the page in cache that has the largest \textit{expected} time to be requested next) are necessarily at least an $\Omega(k)$ factor suboptimal compared to $\opt$. They then showed a policy $\mcA$ that is provably $O(1)$-competitive against $\opt$; however, the constant in the $O(1)$ is somewhat large. Thereafter, \cite{lund1999paging}\footnote{We reference the journal version \citep{lund1999paging} in lieu of the conference version \citep{lund1994ip} hereafter.} proposed a simple and elegant polynomial-time policy, referred to as the \textit{dominating distribution algorithm}, and showed that it achieves $4$-competitiveness against $\opt$. We describe this policy ahead.

\subsection{Dominating Distribution Algorithm}
\label{sec:dominating-distribution}

The dominating distribution algorithm, which was proposed by \cite{lund1999paging} and is denoted $\mcA_\dom$ hereon, operates as follows. At any page request, if $\mcA_\dom$ suffers a cache miss, it computes a so-called \textit{dominating} distribution $\mu$ over the currently-existing pages in the cache. Thereafter, it draws a page $p \sim \mu$, and evicts $p$. First, we will specify the properties of this dominating distribution. 

Intuitively, we want $\mu$ to be a distribution such that a \textit{typical} page drawn from $\mu$ will be highly likely to be next requested later than \textit{every} other page in the cache. Formally, suppose that the most recently requested page (that caused a cache miss) is $s$. Fix any two pages $p$ and $q$ (not necessarily in the cache), and let
\begin{align}
    \label{eqn:alpha-q-p-def}
    \alpha(p<q|s) := \Pr_M[\text{$p$ is next requested before $q$ }|\text{ $s$ is the most recently requested page}],
\end{align}
and let $\alpha(p<p|s)=0$ for all pages $p$. Here, the probability is only over the draw of page requests from the Markov chain.
The claim is that these $\alpha(p<q|s)$ values can be computed efficiently, in total time $O(n^4)$ for all pairs $p,q$ in cache, provided that we know the transition matrix $M$. To see this, let $x_s=\alpha(p<q|s)$. Note that $x_p=1$, $x_q=0$. For any other page $r \neq p,q$, note that
\begin{align*}
    x_r = M_{r,1}x_1 + \dots + M_{r,n}x_n.
\end{align*}
Thus, upon solving the linear system given by
\begin{align}
    \label{eqn:linear-system-for-alpha}
    \begin{bmatrix}
        M_{1,1} - 1 & M_{1,2} & \dots & M_{1,n} \\
        M_{2,1} & M_{2,2} -1 & \dots & M_{1,n} \\
        \vdots & \vdots & \cdots & \vdots\\
        \boldsymbol{e_p} \\
        \vdots & \vdots & \cdots &\vdots \\
        \boldsymbol{e_q} \\
        \vdots & \vdots & \cdots & \vdots \\
        M_{n,1} & M_{n,2} & \dots & M_{n,n}-1
    \end{bmatrix}
    \begin{bmatrix}
        x_1 \\ x_2 \\ \vdots \\ x_p \\ \vdots \\ x_q \\ \vdots \\ x_n
    \end{bmatrix} = 
    \begin{bmatrix}
        0 \\ 0 \\ \vdots \\ 1 \\ \vdots \\ 0 \\ \vdots \\ 0
    \end{bmatrix},
\end{align}
where $\boldsymbol{e_p}$ and $\boldsymbol{e_q}$ are row vectors with a $1$ in the $p^{\text{th}}$ and $q^{\text{th}}$ coordinates, respectively, and $0$ elsewhere, $x_s$ is the desired value $\alpha(p<q|s)$. %
In this way, we can solve a linear system for each of the $\le n^2$ possible pairs for $q,p$, and compute all $\alpha(p<q|s)$ values in time $O(n^4)$. For notational convenience, we will hereafter frequently denote $\alpha(p<q|s)$ simply by $\alpha(p<q)$, implicitly assuming conditioning on the most frequently requested page.


Equipped with all these $\alpha(p<q)$ values, let us define $\mu$ to be a distribution over the pages in the cache satisfying the following property: for every fixed page $q$ in the cache,
\begin{align}
    \label{eqn:dominating-distribution-property}
    \E_{p \sim \mu}[\alpha(p<q)] \le \frac{1}{2}.
\end{align}
This is the required dominating distribution. What may be somewhat surprising here is that such a dominating distribution, which satisfies the condition in \eqref{eqn:dominating-distribution-property} provably \textit{always} exists, and furthermore can be constructed efficiently by solving a linear program with just $O(k)$ variables (i.e., in $\poly(k)$ time).
\begin{theorem}[Theorem 3.4 in \cite{lund1999paging}]
    \label{thm:dominating-distribution-exists}
    A distribution $\mu$ satisfying the condition in \eqref{eqn:dominating-distribution-property} necessarily exists and can be computed by solving a linear program in $O(k)$ variables.
\end{theorem}
Thus, the total computation required by $\mcA_\dom$ at each cache miss is only $\poly(k)$ (to solve the linear program that constructs $\mu$), assuming all $\alpha(p<q)$ values are precomputed initially. In summary, the overall computation cost of $\mcA_\dom$ across $T$ page requests is at most $T \cdot \poly(n, k)$.

It remains to argue that if $\mcA_\dom$ evicts $p \sim \mu$ whenever it suffers a cache miss, then it fares well in comparison to $\opt$. A convenient observation towards showing this is the following claim, whose proof follows from the definition of $\mu$:
\begin{claim}
    \label{claim:dominating-distribution-probability}
    Let $s$ be the most recently requested page. The dominating distribution $\mu$ satisfies the following property: for every fixed page $q$ in the cache, we have that
    \begin{align}
        \Pr_{p \sim \mu, M}[\text{$q$ is next requested no later than $p$ }|\text{ $s$ is the most recently requested page}] \ge \frac{1}{2}.
    \end{align}
\end{claim}
\begin{proof}
    Writing out the condition \eqref{eqn:dominating-distribution-property} that $\mu$ satisfies more explicitly, we have that for every fixed page $q$ in cache,
    \begin{align*}
        &\sum_{\text{$p$ in cache}}\mu(p)\cdot \alpha(p<q|s) \le \frac{1}{2} \\
        \implies \quad & \sum_{\text{$p$ in cache}}\mu(p)\cdot \Pr_M[\text{$p$ is next requested before $q$ }|\text{ $s$ is the most recently requested page}] \le \frac{1}{2} \\
        \implies \quad &\Pr_{p \sim \mu, M}[\text{$p$ is next requested before $q$ }|\text{ $s$ is the most recently requested page}] \le \frac12 \\
        \implies \quad &\Pr_{p \sim \mu, M}[\text{$q$ is next requested no later than $p$ }|\text{ $s$ is the most recently requested page}] \ge \frac{1}{2}.
    \end{align*}
\end{proof}

Using this property of $\mu$, \cite{lund1999paging} show that $\mcA_\dom$ incurs only $4$ times as many cache misses as $\opt$ in expectation. The following section provides this part of their result.

