\section{Learning the Markov Chain from Samples}
\label{sec:robustness}

It is worth pointing out that the form of \Cref{lem:tight-analysis} allows us to obtain performance guarantees even when we only have approximate estimates of the $\alpha(p<q)$ values, as also noted in passing by \cite{lund1999paging}. In particular, suppose that we only have $\eps$-approximate (multiplicate or additive) estimates $\hat{\alpha}(p<q)$ of $\alpha(p<q)$, that still satisfy $\hat{\alpha}(p<q) + \hat{\alpha}(q<p)=1$, and $\hat{\alpha}(p<p)=0$. Suppose that at each cache miss, we use these $\hat{\alpha}(p<q)$ values to compute a dominating distribution $\hat{\mu}$, and draw the page $p$ to evict from $\hat{\mu}$.

Even with such an approximate dominating distribution, we can still guarantee either $\frac{2}{1-2\eps}$-competitiveness (in the case that $\hat{\alpha}(p<q) \in [\alpha(p<q)-\eps, \alpha(p<q)+\eps]$), or $\frac{2-2\eps}{1-2\eps}$-competitiveness (in the case that $\hat{\alpha}(p<q) \in [(1-\eps)\alpha(p<q), (1+\eps)\alpha(p<q)]$). This follows as a direct consequence of \Cref{claim:dominating-distribution-probability} and \Cref{lem:tight-analysis}.

Perhaps the first scenario to consider here is when we do not assume prior knowledge of the transition matrix $M$, but only have access to samples previously drawn from the Markov chain. For example, we can imagine that the algorithm designer has available a large training dataset of past page requests. This dataset can be used to derive estimates of the entries in the transition matrix $M$, for instance, using one of the several existing estimators \citep{hao2018learning, wolfer2021statistical, huang2024non}. In fact, recall that the computation of the $\alpha(p<q)$ values requires only for us to solve a linear system determined by the entries in the transition matrix (\Cref{eqn:linear-system-for-alpha}). Hence, if we have accurate estimates for the entries in $M$, we can use the theory of perturbed linear systems to bound the resulting error in the estimates of the $\alpha(p<q)$ values. Thereafter, using the argument from the previous paragraph, we can obtain a performance guarantee for the competitiveness of a dominating distribution algorithm that uses these estimates.

We can turn the above informal argument into a formal learning-theoretic result. Formally, suppose that every entry in $M$ is at least some $\delta > 0$. In this case, the Markov chain is irreducible (meaning that there is a positive, and unique probability of eventually getting from any state to another). Thus, in this case, for every fixed $p,q$, the linear system \eqref{eqn:linear-system-for-alpha} has a (unique) solution, meaning that matrix associated with it is invertible. The relevant quantity here will be the conditioning of the \textit{worst} linear system that we might ever have to solve. Towards this, let $L_{p,q}$ be the matrix associated with the linear system in \eqref{eqn:linear-system-for-alpha} for pages $p,q$, and define:
\begin{align}
    \label{eqn:gamma-def}
    \gamma &= \sup_{p \neq q} \|L_{p,q}^{-1}\|_\infty,
\end{align}
where for a square matrix $A \in \R^{n \times n}$, $\|A\|_\infty = \sup_i \sum_{j}|A_{i,j}|$. Observe from \eqref{eqn:linear-system-for-alpha} that $1 \le \|L_{p,q}\|_\infty \le 2$ for every $p,q$.

We choose to adopt the following result of \cite{hao2018learning} for our exposition:

\begin{theorem}[Theorem 4 in \cite{hao2018learning}]
    \label{thm:learning-markov-chains}
    Suppose we unroll a Markov chain to obtain $m$ samples $X_1,\dots,X_m$, where the initial distribution of $X_1$ is arbitrary, but the transition matrix $M \in [0,1]^{n \times n}$ of the Markov chain satisfies $M_{i,j} \ge \delta > 0$ for every $i,j$. Then, there exists an estimator $\hat{M}=\hat{M}(X_1,\dots,X_m)$ that satisfies
    \begin{align*}
        \E_{X_1,\dots,X_m}\|M(i,:) - \hat{M}(i,:)\|_2^2 \le O \left(\frac{1}{m\delta}\right)
    \end{align*}
    for every $i \in [n]$, where $M(i,:)$ (respectively $\hat{M}(i,:)$) denotes the $i^\text{th}$ row of $M$ (respectively $\hat{M}$).
\end{theorem}

Using this theorem, we can obtain the following result:

\begin{theorem}
    \label{thm:approx-lpr-from-samples}
    Suppose that the page requests are generated from an unknown Markov chain where every entry in the transition matrix $M$ is at least $\delta > 0$. Let $\gamma$ be as defined in \eqref{eqn:gamma-def}. Given a training dataset of $m = O\left(\frac{\gamma^2n^2}{\eps^2\delta}\right)$ past page requests from $M$, there is an algorithm $\mcA$ which is $\frac{2}{1-2\eps}$-competitive against $\opt$ with probability at least $0.99$ over the $m$ samples.
\end{theorem}
\begin{proof}
    From the initial $m$ page requests, $\mcA$ constructs the estimator $\hat{M}$ given by \Cref{thm:learning-markov-chains}. Applying Markov's inequality to the in-expectation guarantee on $\hat{M}$, for every fixed $i \in [n]$, we have that with probability at least $1-0.01 \cdot \frac{1}{n}$, 
    \begin{align*}
        \|M(i,:) - \hat{M}(i,:)\|_2^2 \le O \left(\frac{n}{m\delta}\right).
    \end{align*}
    A union bound over the universe of $n$ pages gives that with probability at least $0.99$, we have that 
    \begin{align*}
        \sup_{i \in [n]}\|M(i,:) - \hat{M}(i,:)\|_2^2 \le O \left(\frac{n}{m\delta}\right)
    \end{align*}
    The Cauchy-Schwarz inequality then implies that with probability at least $0.99$,
    \begin{align*}
        \sup_{i \in [n]}\sum_{j=1}^n |M(i,j)-\hat{M}(i,j)| \le O \left(\frac{n}{\sqrt{m\delta}}\right).
    \end{align*}
    Denoting $\Delta = \hat{M}-M$, we have effectively argued that $\|\Delta\|_\infty \le O \left(\frac{n}{\sqrt{m\delta}}\right)$ with probability at least $0.99$.

    The algorithm $\mcA$ plays the dominating distribution algorithm as its eviction policy on a cache miss; however, it constructs the dominating distribution using the estimator $\hat{M}$. Namely, for every pair $p,q$, let $\hat{L}_{p,q}$ be the matrix associated with the linear system in \eqref{eqn:linear-system-for-alpha}, where instead of the entries in $M$, we plug in entries from our estimator $\hat{M}$. Consider the solution $\hat{x}$ of the perturbed linear system $\hat{L}_{p,q} \cdot \hat{x} = b_{p,q}$, where $b_{p,q}$ is the right-hand side of \eqref{eqn:linear-system-for-alpha}. We care about bounding the difference between $\hat{x}$ and $x$, where $x$ is the solution to $L_{p,q} \cdot x = b_{p,q}$. Note that the right-hand side in both the perturbed and unperturbed systems (namely $b_{p,q}$) is still the same.
    
    From a standard analysis of solutions to perturbed linear systems (e.g., see Theorem 1 in \citep{falknotes}), we have that
    \begin{align*}
        \|\hat{x}-x\|_\infty &\le \frac{\|L_{p,q}^{-1}\|_\infty \|\hat{L}_{p,q}-L_{p,q}\|_\infty \|x\|_\infty}{1-\|L_{p,q}^{-1}\|_\infty \|\hat{L}_{p,q}-L_{p,q}\|_\infty}.
    \end{align*}
    Now, observe that $\|\hat{L}_{p,q}-L_{p,q}\|_\infty \le \|\Delta\|_\infty$, and also that $\|x\|_\infty=1$. Plugging in our bound above on $\Delta$, we get
    \begin{align*}
        \|\hat{x}-x\|_\infty &\le \frac{O(\gamma n/\sqrt{m\delta})}{1-O(\gamma n/\sqrt{m\delta})}.
    \end{align*}
    Setting $m=C \cdot \frac{\gamma^2n^2}{\eps^2\delta}$ for a constant $C$ is sufficient to make the right-hand side above to be at most $\eps$.\footnote{In fact, this is also sufficient to satisfy the technical condition of Theorem 1 in \citep{falknotes} that we used.} But this means that all the $\hat{\alpha}(p<q)$ estimates that $\mcA$ constructs satisfy
    \begin{align*}
        {\alpha}(p<q)-\eps \le \hat{\alpha}(p<q) \le {\alpha}(p<q) + \eps.
    \end{align*}
    Thus, the dominating distribution $\hat{\mu}$ that $\mcA$ constructs at every cache miss has the property that for every fixed $q$ in the cache,
    \begin{align*}
        \E_{p \sim \hat{\mu}}[\hat{\alpha}(p<q)] \le \frac{1}{2} 
        \quad\implies\quad \E_{p \sim \hat{\mu}}[{\alpha}(p<q)] \le \frac{1}{2}+\eps.
    \end{align*}
    Instantiating \Cref{claim:dominating-distribution-probability} and \Cref{lem:tight-analysis} then gives the desired result.
\end{proof}
