\section{Experiment}

We evaluate FlexControl against state-of-the-art methods across different image conditions: depth maps (MultiGen-20M, \cite{zhao2024uni}), canny edges (LLAVA-558K, \cite{liu2024visual}), segmentation masks (ADE20K, \cite{zhou2017scene}), and \textit{etc}.

\subsection{Quantitative comparison}

\paragraph{Comparison of image quality.}

To evaluate the impact of dynamic controllable generation on image quality, we compare the FID metrics of different methods across multiple conditional generation tasks (\cref{tab:table1}). We set $\gamma$ to 0.5, aligning FlexControl’s FLOPs with ControlNet’s. Our model achieves superior FID results across all conditions, outperforming existing methods. We also examine ControlNet-Large, which replicates the SD model as an additional network. Although its larger parameter count enhances conditional feature extraction and control, its performance remains inferior to FlexControl$_{\gamma=0.5}$. This confirms that adaptive control—selectively applying conditions instead of enforcing them across all blocks and timesteps—maximizes controllability. Beyond spatial conditions, we assess text influence using CLIP score. As shown in \cref{tab:table1}, FlexControl$_{\gamma=0.5}$ outperforms other methods, demonstrating that precise control enhances spatially guided generation without compromising text-guided synthesis. Additionally, we evaluate ControlNet and T2I-Adapter on the SDXL backbone \cite{podell2023sdxl}, revealing that a larger backbone does not necessarily improve image quality.

\begin{table}
    \centering
    \resizebox{\linewidth}{!}{
    \begin{tabular}{c|c|c|c|c} 
        \toprule[1.0px]
        \textbf{Method}  &\textbf{Base Model}& \textbf{Depth Map}& \textbf{Canny Edge}&\textbf{Seg. Mask}\\ & & \textbf{(RMSE $\downarrow$)}& \textbf{(SSIM $\uparrow$)}&\textbf{(mIoU $\uparrow$)}\\ 
        \midrule
        ControlNet &SDXL& 0.4001& 0.4178& 0.2058\\
        T2I-Adapter &SDXL& 0.3976& 0.3969& 0.1912\\ 
        \midrule
        GLIGEN &SD1.4& 0.3882& 0.4226& 0.2076\\
        T2I-Adapter &SD1.5& 0.4840& 0.4622& 0.1839\\
        ControlNet & SD1.5& 0.2988& 0.5197& 0.2764\\
        ControlNet++ &SD1.5& 0.2832& 0.5436& 0.3435\\
        ControlNet-Large &SD1.5& \textcolor{blue}{0.2372}& \textcolor{red}{0.5642}& \textcolor{blue}{0.3668}\\ 
        \midrule
        \rowcolor{gray!20}
        \textbf{FlexControl}$_{\gamma=0.5}$&SD1.5& \textcolor{red}{0.2358}& \textcolor{blue}{0.5612}& \textcolor{red}{0.3751}\\ 
        \bottomrule[1.0px]
    \end{tabular}
    }
    \caption{
        \textbf{Controllability comparison across different conditioning types.} 
        We report RMSE (↓) for Depth Map and SSIM (↑) for Canny Edge and mIoU (↑) for Seg. Mask.
        The best and second-best results are highlighted in \textcolor{red}{red} and \textcolor{blue}{blue}. FlexControl achieve similar but slightly better controllability than ControlNet-Large with only \textbf{half} activation blocks.
    }
    \label{tab:table2}
\end{table}

\paragraph{Comparison of controllability.}
We exam generation controllability in detail by comparing results across different spatial conditions. ControlNet and its variants generally achieve stronger controllability than other existing methods. Within a similar computational budget, FlexControl further improves controllability across various conditions.  Numerically, FlexControl reduces RMSE by 6.30\% and 4.74\% compared to ControlNet and ControlNet++ on the depth map task. For canny edge and segmentation mask, FlexControl shows improvements of 4.15\%/1.76\% in SSIM and 9.87\%/3.16\% in mIoU, respectively. Moreover, our method outperforms ControlNet-Large on both the depth map and segmentation mask datasets, and achieves similar performance on the canny edge task. Similarly, we show the results of the SDXL-based ControlNet and T2I-Adapter show only marginal improvements for specific tasks.

\begin{table}
    \centering
    \resizebox{\linewidth}{!}{
    \begin{tabular}{c|c|c|c|c} 
        \toprule[1.0px]
        \textbf{Method}  &\textbf{Base Model}& \textbf{Param.}& \textbf{FLOPs}&\textbf{Speed}\\ 
        \midrule
        ControlNet &SD1.5&\textcolor{red}{0.36 G} &\textcolor{blue}{233 G} &\textcolor{blue}{{5.23\scriptsize{$\pm$0.07}} it/s}\\
        ControlNet-Large &SD1.5&0.72 G &561 G & 4.02{\scriptsize{$\pm$0.05}} it/s\\
        \rowcolor{gray!10}
        \textbf{FlexControl}$_{\gamma=0.7}$&SD1.5&0.73 G &393 G &4.94{\scriptsize{$\pm$0.07}} it/s\\ 
        \rowcolor{gray!10}
        \textbf{FlexControl}$_{\gamma=0.5} $&SD1.5&0.73 G &280 G &\textcolor{blue}{{5.21\scriptsize{$\pm$0.12}} it/s}\\
        \rowcolor{gray!10}
        \textbf{FlexControl}$_{\gamma=0.3} $&SD1.5&0.73 G &\textcolor{red}{168 G} &\textcolor{red}{{5.64\scriptsize{$\pm$0.12}} it/s}\\ 
        \midrule
        ControlNet &SD3.0& \textcolor{red}{1.06 G}&3.25 T &48.34{\scriptsize{$\pm$1.78}} s/it\\
        ControlNet-Large &SD3.0& 2.02 G&6.22 T &59.46{\scriptsize{$\pm$1.82}} s/it\\
        \rowcolor{gray!10}
        \textbf{FlexControl}$_{\gamma=0.7}$&SD3.0& 2.03 G&4.35 T &52.15{\scriptsize{$\pm$2.86}} s/it\\ 
        \rowcolor{gray!10}
        \textbf{FlexControl}$_{\gamma=0.5}$&SD3.0& 2.03 G&\textcolor{blue}{3.11 T} &\textcolor{blue}{45.74{\scriptsize{$\pm$3.25}} s/it}\\
        \rowcolor{gray!10}
        \textbf{FlexControl}$_{\gamma=0.3}$&SD3.0& 2.03 G&\textcolor{red}{1.86 T} &\textcolor{red}{40.84{\scriptsize{$\pm$3.09}} s/it}\\
        \bottomrule[1.0px]
    \end{tabular}
    }
    \caption{
        \textbf{Complexity comparison on SD1.5 and SD3.0.} 
        We compare model parameters, FLOPs, and inference speed (it/s (↑), iterations per second and s/it (↓), seconds per iteration). The best values are highlighted in \textcolor{red}{red}, while the second-best values are shown in \textcolor{blue}{blue}. FlexControl significant reduce overall FLOPs and inference time from ControlNet-Large.
    }
    \label{tab:table3}
\end{table}

\subsection{Qualitative comparison}

In \cref{diode}, we compare different methods across depth map, canny edge, and segmentation mask tasks. All models use SD1.5 as the backbone, except for the last two columns. FlexControl consistently outperforms others in visual quality and spatial/text alignment.For depth maps, FlexControl produces smoother transitions and more natural textures. Under canny edge conditions, it better preserves edge fidelity and fine details. For segmentation masks, it enhances mask reconstruction and visual consistency. These results demonstrate FlexControl’s ability to selectively inject control information into relevant diffusion backbone blocks based on timestep and input characteristics, improving image fidelity.Finally, we compare against ControlNet and ControlNet-Large. While ControlNet-Large benefits from a larger control network for improved generation and condition alignment, FlexControl surpasses it in both accuracy and visual fidelity, showcasing the strength of our approach.

% width=8.25cm
\begin{figure}[!t]
    \centering
        \includegraphics[width=1.0\columnwidth]{pic/seg_mask.png}
        \caption{
        \textbf{Comparison of FlexControl and existing methods on SD1.5 for semantic consistency.} 
        FlexControl achieves better semantic alignment and structure preservation with varying sparsity levels, while ControlNet-based methods show inconsistencies in segmentation accuracy (highlighted in yellow boxes). \textit{ Captions: A stone building  surrounded by a stone wall and a grassy lawn.}
        }
    \label{ade20k}
\end{figure}
\begin{table}
    \centering
    \resizebox{\linewidth}{!}{
    \begin{tabular}{c|c|c|c|c} 
        \toprule[1.0px]
        \textbf{Method}  &\textbf{Base Model}& \textbf{FID $\downarrow$}& \textbf{CLIP\_score $\uparrow$}&\textbf{mIoU $\uparrow$}\\ 
        \midrule
        VQGAN \cite{esser2021taming} & \ding{55}& 26.28& 0.17& N/A \\ 
        LDM \cite{rombach2022high} & \ding{55}& 25.35& 0.18& N/A \\
        PIPT \cite{wang2022pretraining} & \ding{55}& 19.74& 0.20& N/A \\
        \midrule
        ControlNet &SD1.5& 21.33& 0.2531& 0.2764 \\
        ControlNet++ &SD1.5& 19.89& 0.2640& 0.3435 \\ 
        ControlNet-Large &SD1.5& 16.78& 0.2796&  0.3668 \\ 
        \midrule
        \rowcolor{gray!10}
        \textbf{FlexControl}$_{\gamma=0.3}$&SD1.5& 17.21& 0.2713& 0.3572 \\
        \rowcolor{gray!10}
        \textbf{FlexControl}$_{\gamma=0.5}$&SD1.5& \textcolor{blue}{14.80}& \textcolor{red}{0.2842}& \textcolor{blue}{0.3751} \\
        \rowcolor{gray!10}
        \textbf{FlexControl}$_{\gamma=0.7}$&SD1.5& \textcolor{red}{14.71}& \textcolor{blue}{0.2840}& \textcolor{red}{0.3775} \\ 
        \bottomrule[1.0px]
    \end{tabular}
    }
    \caption{
    \textbf{Quantitative comparison with existing methods on SD1.5.} 
    We report FID (↓), CLIP\_score (↑), and mIoU (↑) across different models. The best values and second-best are highlighted in \textcolor{red}{red} and \textcolor{blue}{blue}. FlexControl outperform original ControlNet with less computation, while increasing the blocks budgets observed performance increasing. Noticeable, ControlNet-Large activate all blocks yet not out-perform our methods, highlight effective of our dynamic strategy.
    }
    \label{tab:table4}
\end{table}

\subsection{Ablation study}

In this section, we analyze how the proportion of activated control blocks impacts FlexControl. To better understand model complexity, we present the number of parameters, FLOPs, and diffusion speed in \cref{tab:table3}. The diffusion iterations per second (\textit{i.e.}, it/s) for SD1.5-based models and seconds per iteration (\textit{i.e.}, s/it) for SD3.0-based models are measured on a single Nvidia RTX 2080 Ti GPU. We randomly select batch samples and compute the average single-step iteration time for each sample. 

\paragraph{Results on UNet-based model.}
Recall the cost loss defined in \cref{eq:losscost}, we train FlexControl with three different sparsity levels by adjusting the value of $\gamma$.  For the SD1.5-based backbone, experiments are conducted on the ADE20K dataset. At $\gamma=0.3$ ($~$30\% sparsity), FlexControl surpasses ControlNet and ControlNet++ in controllability and generation quality but falls short of ControlNet-Large. Increasing $\gamma$ to 0.5 activates more control blocks, leading to performance that surpasses ControlNet-Large. Further increasing $\gamma$ to 0.7 yields no significant performance gains (suggesting the dataset is already saturated by the model capacity).  For visual comparisons in \cref{ade20k}, FlexControl with $\gamma=0.5$ and $\gamma=0.7$ demonstrate superior structure preservation and mask information reconstruction. Meanwhile, the more lightweight configuration with $\gamma=0.3$ achieves a generation quality comparable to ControlNet++ and ControlNet-Large.

\begin{figure}[!t]
    \centering
        \includegraphics[width=1.0\columnwidth]{pic/canny.png}
        \caption{
        \textbf{Comparison of FlexControl and existing methods on SD3.0 for edge preservation.} 
        FlexControl maintains better spatial consistency and object integrity across different sparsity levels, while ControlNet-based methods introduce distortions and inconsistencies (highlighted in red boxes). \textit{Captions: A room with large windows, a gray sofa, a table, and a TV stand.}
        }

    \label{canny}
\end{figure}
\begin{table}
    \centering
    \resizebox{\linewidth}{!}{
    \begin{tabular}{c|c|c|c|c} 
        \toprule[1.0px]
        \textbf{Method}  &\textbf{Base Model}& \textbf{FID} $\downarrow$& \textbf{CLIP\_score} $\uparrow$&\textbf{SSIM} $\uparrow$\\ 
        \midrule
        ControlNet &SD3.0& 27.21& 0.2512& 0.3749\\
        ControlNet-Large &SD3.0& \textcolor{blue}{21.64}& \textcolor{blue}{0.2690}& \textcolor{red}{0.4828}\\
        \midrule
        \rowcolor{gray!10}
        \textbf{FlexControl}$_{\gamma=0.3}$ &SD3.0& 24.39& 0.2581& 0.4286\\
        \rowcolor{gray!10}
        \textbf{FlexControl}$_{\gamma=0.5}$ &SD3.0& 22.47& \textcolor{red}{0.2714}& 0.4598\\
        \rowcolor{gray!10}
        \textbf{FlexControl}$_{\gamma=0.7}$ &SD3.0& \textcolor{red}{20.54}& \textcolor{red}{0.2714}& \textcolor{blue}{0.4775}\\ 
        \bottomrule[1.0px]
    \end{tabular}
    }
    \caption{
        \textbf{Quantitative comparison with existing methods on SD3.0.} 
        We report FID (↓), CLIP\_score (↑), and SSIM (↑). 
        The best and second-best values are highlighted in \textcolor{red}{red} and \textcolor{blue}{blue}. FlexControl outperform original ControlNet with less computation, while increasing the blocks budgets observed performance increasing even more significant improvement than we observed in SD1.5.
        }
    \label{tab:table5}
\end{table}

\paragraph{Results on DiT-based model.}
For the SD3.0-based backbone, experiments were conducted on the LLAVA-558K dataset. As detailed in \cref{tab:table5}, FlexControl$_{\gamma=0.3}$ and FlexControl$_{\gamma=0.5}$ outperform ControlNet with fewer FLOPs. Notably, while ControlNet has half as many blocks as the backbone, each control block's output is shared by two adjacent backbone blocks, providing more conditional controls than FlexControl at all sparsity levels. FlexControl$_{\gamma=0.7}$ achieves superior image quality and comparable controllability to ControlNet-Large while being more efficient. Visualization results in \cref{canny} further demonstrate the advantage of FlexControl in edge reproduction and image fidelity over ControlNet.


