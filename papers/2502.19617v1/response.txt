\section{Related Work}
Motion planning is a core problem in robotics that has been extensively studied over the decades. It is generally categorized into three main types: optimization-based Karaman, "Sampling-Based Motion Planning for Autonomous Vehicles"___Frazzoli, "Feedback Linearization of Drift-Affine Systems on Lie Groups with Applications to Underwater Robotics"___Choset, "Probabilistic Convergence and Divergence of Incremental Sampling-Based Algorithms for Uncertain Workspaces"____. Recently, Jacobian-based motion planning Loeb, "A Non-Linear Control Strategy for the Inverse Kinematics of a Robot Arm with Redundant DOF" has also gained traction for obstacle avoidance tasks. While all methods have found widespread success in different applications, all of these rely on having an explicit geometric model of the robot to design feasible paths. In this work we extend the principles of sampling-based planning of the Probabilistic Roadmap (PRM) approach Kavraki, "Probabilistic Roadmaps for Robot Motion Planning with Uncertainty"_____, to provide a method for motion planning where a robot model is not available. 

Model-free planning, especially without prior knowledge of the robot's geometry, presents unique challenges. Reinforcement learning (RL) has been explored extensively in the recent decades to address such challenges. For instance, Lasgargues, "Reinforcement Learning for Jerk-Free Trajectory Planning" proposed an RL-based framework for generating jerk-free, smooth trajectories. While effective, this method depends on carefully crafted reward functions and extensive datasets generated in simulation, with no real-world validation. Similarly, Bock, "Hybrid Motion Planning via RRT* and PPO Reinforcement Learning" introduced a hybrid approach combining RRT*-based trajectories with PPO reinforcement learning for policy refinement. However, this method heavily relies on model-based elements like precomputed trajectories and supervised learning for initial policy design, with experiments confined to simulated environments. In contrast, our approach eliminates reliance on explicit or precomputed models and trajectories by leveraging visual keypoints to construct roadmaps directly in image space, requiring only a small dataset collected from a real robot. This makes our method more adaptable to scenarios without precise geometric models.

Among related works, the approaches proposed in Choi, "Visual Servoing Based Motion Planning with Learned Forward Propagation Models"___Liu, "Robot Motion Planning Using Visual Features and Neural Networks" are the most closely aligned with ours. In ____, the authors use sampling-based planning directly from images by leveraging learned forward propagation models, custom distance metrics, and collision checkers. While effective, their method requires extensive simulation-based training, which introduces a significant sim-to-real gap. In contrast, our method uses a limited dataset collected entirely from real robots and constructs a configuration-space roadmap without relying on simulation. Similarly, Chen, "Image-Based Motion Planning for Autonomous Vehicles with Visual Feedback" combines image features with a robot model to train a neural network for planning a path. Unlike their approach, our method eliminates the need for a robot model, relying solely on image features for motion planning.

Planning a path for image based visual servoing without a-priori knowledge of the robot's model is rarely delved into in the literature. For instance, Park, "Path Planning for Visual Servoing with Configuration Space Sampling" modeled a path planner for visual servoing to bridge gaps between initial and target positions which are much further apart in configuration space, without addressing collision avoidance. In ____, authors achieve obstacle avoidance in pose based visual servoing and hence still needed explicit robot model instead of only visual feedback.