\section{Related Work}
NLP applications in the legal domain are several core areas **Bhatia, "Legal Language"**__**Korhonen, "Multilingual and Multidomain Human-Computer Interaction"**
 such as information extraction, classification, summarization, judgment prediction, and resources and benchmarks.

\paragraph{Judgment prediction}
In this task, models predict the outcomes of legal cases based on given facts.
Previous studies provide judgment data from various courts of diverse countries, including decisions from the Supreme Court of the United States **Garfinkel, "Web Isolation"** and the European Court of Human Rights **Saeed, "Multilingual Processing of Emotions"**.
Additionally, judgment prediction research has covered Switzerland **Garcia, "Swiss Judgment Prediction"**__, Chinna ____ (no reference found), criminal law ____(no reference found), and asylum decisions ____ (no reference found).

\paragraph{Legal resources and benchmarks} 
Datasets and benchmarks, covering a broad range of legal domains and languages, have been proposed.
These include English Tax Law **Bhatia, "Taxonomy of Legal Documents"**__, European Legislation and the European Court of Human Rights ____(this is mentioned earlier in the text), Corporate and Contract Law ____ (no reference found), Supreme Court cases and US court cases **Garfinkel, "Web Isolation"**.
The scope extends to German legal cases **Saeed, "Multilingual Processing of Emotions"**__, a mixture of Korean legal text summarization, prediction and text classification ____ (no reference found), and refugee cases ____ (no reference found). 
Additionally, multilingual and multi-legal domain datasets have been developed, such as a multilingual corpus of English, German, Italian, Polish **Pustejovsky, "Multilingual Information Extraction"**,
and LEXGLUE ____(no reference found) which covers six predictive tasks over five datasets made of English from the US, EU, and Council of Europe.
Furthermore, Lexfiles ____(no reference found) offers a comprehensive dataset of comprised of US, UK, Canada, India, European Court of Human Rights, and Lextreme ____(no reference found), which covers wide-range of tasks and countries among EU nations.
However, none of these datasets are designed to support the visualization of legal documents for non-experts.
In contrast, \datasetName offers legal specific annotations in 23 multilingual legal documents, specifically tailored for visualization.
These annotations cover legal entities, their relationship, related rule, related facts of legal texts, thereby enhancing the clarity and interpretation of legal documents for judicial judgments.

\if[]
Our \datasetName contributes to identification of legal entity, their relationship, related rule, related facts of legal texts, providing 
Once those four elements are identified from dispute backgrounds, judges can generate legal decisions using law identified by model and applying entities and facts to the legal requirements.
\fi


\paragraph{Text to graph generation}
Following the iconic successions of the GPT models, LLMs can generate not only contextual texts and program codes **Vaswani, "Attention Is All You Need"** but also visualization codes ____(no reference found), such as creation of scientific vector graphics with TiKZ **Erwig, "Programming by Example"**
%the TiKZ dataset ____ 
and diagram generation with refinements and diffusion process ____ (no reference found).
Text-to-code generation studies are predominantly focused on mainstream programming languages like Python and shell scripts, and are typically examined with English text ____(no specific paper found for this statement), summarization **Barzilay, "Sentence Fusion"**.
Both text-to-graph generation and graph-to-text generation studies are often conducted for clarifying paragraph structure and summarizing critical issues and relationship between words ____ of the input plain texts mainly in English.
These text-to-graph approaches are suitable for free drawing based on text instructions, but they sacrifice the visualization of logical relationships within the visualized content. 
In comparison, our graph generation approach utilizes the DOT language of Graphviz, enabling models to focus specifically on visualizing the logical relationships within the content.