@inproceedings{10.1145/3086512.3086537,
author = {Dunn, Matt and Sagun, Levent and \c{S}irin, Hale and Chen, Daniel},
title = {Early predictability of asylum court decisions},
year = {2017},
isbn = {9781450348911},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3086512.3086537},
doi = {10.1145/3086512.3086537},
abstract = {In the United States, foreign nationals who fear persecution in their home country can apply for asylum under the Refugee Act of 1980. Over the past decade, legal scholarship has uncovered significant disparities in asylum adjudication by judge, by region of the United States in which the application is filed, and by the applicant's nationality. These disparities raise concerns about whether applicants are receiving equal treatment under the law. Using machine learning to predict judges' decisions, we document another concern that may violate our notions of justice: we are able to predict the final outcome of a case with 80\% accuracy at the time the case opens using only information on the identity of the judge handling the case and the applicant's nationality. Moreover, there is significant variation in the degree of predictability of judges at the time the case is assigned to a judge. We show that highly predictable judges tend to hold fewer hearing sessions before making their decision, which raises the possibility that early predictability is due to judges deciding based on snap or predetermined judgments rather than taking into account the specifics of each case. Early prediction of a case with 80\% accuracy could assist asylum seekers in their applications.},
booktitle = {Proceedings of the 16th Edition of the International Conference on Articial Intelligence and Law},
pages = {233–236},
numpages = {4},
keywords = {judicial analytics, judicial decision-making, snap judgments},
location = {London, United Kingdom},
series = {ICAIL '17}
}

@inproceedings{10.1145/3086512.3086538,
author = {Chen, Daniel L. and Eagel, Jess},
title = {Can machine learning help predict the outcome of asylum adjudications?},
year = {2017},
isbn = {9781450348911},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3086512.3086538},
doi = {10.1145/3086512.3086538},
abstract = {In this study, we analyzed 492,903 asylum hearings from 336 different hearing locations, rendered by 441 unique judges over a 32 year period from 1981-2013. We define the problem of asylum adjudication prediction as a binary classification task, and using the random forest method developed by Breiman [1], we predict 27 years of refugee decisions. Using only data available up to the decision date, our model correctly classifies 82 percent of all refugee cases by 2013. Our empirical analysis suggests that decision makers exhibit a fair degree of autocorrelation in their rulings, and extraneous factors such as, news and the local weather may be impacting the fate of an asylum seeker. Surprisingly, granting asylum is predominantly driven by trend features and judicial characteristics- features that may seem unfair- and roughly one third-driven by case information, news events, and court information.},
booktitle = {Proceedings of the 16th Edition of the International Conference on Articial Intelligence and Law},
pages = {237–240},
numpages = {4},
keywords = {refugee, machine learning, legal prediction, data science},
location = {London, United Kingdom},
series = {ICAIL '17}
}

@inproceedings{10.1145/3462757.3466088,
author = {Zheng, Lucia and Guha, Neel and Anderson, Brandon R. and Henderson, Peter and Ho, Daniel E.},
title = {When does pretraining help? assessing self-supervised learning for law and the CaseHOLD dataset of 53,000+ legal holdings},
year = {2021},
isbn = {9781450385268},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3462757.3466088},
doi = {10.1145/3462757.3466088},
abstract = {While self-supervised learning has made rapid advances in natural language processing, it remains unclear when researchers should engage in resource-intensive domain-specific pretraining (domain pretraining). The law, puzzlingly, has yielded few documented instances of substantial gains to domain pretraining in spite of the fact that legal language is widely seen to be unique. We hypothesize that these existing results stem from the fact that existing legal NLP tasks are too easy and fail to meet conditions for when domain pretraining can help. To address this, we first present CaseHOLD (Case <u>H</u>oldings <u>O</u>n <u>L</u>egal <u>D</u>ecisions), a new dataset comprised of over 53,000+ multiple choice questions to identify the relevant holding of a cited case. This dataset presents a fundamental task to lawyers and is both legally meaningful and difficult from an NLP perspective (F1 of 0.4 with a BiLSTM baseline). Second, we assess performance gains on CaseHOLD and existing legal NLP datasets. While a Transformer architecture (BERT) pretrained on a general corpus (Google Books and Wikipedia) improves performance, domain pretraining (on a corpus of ≈3.5M decisions across all courts in the U.S. that is larger than BERT's) with a custom legal vocabulary exhibits the most substantial performance gains with CaseHOLD (gain of 7.2\% on F1, representing a 12\% improvement on BERT) and consistent performance gains across two other legal tasks. Third, we show that domain pretraining may be warranted when the task exhibits sufficient similarity to the pretraining corpus: the level of performance increase in three legal tasks was directly tied to the domain specificity of the task. Our findings inform when researchers should engage in resource-intensive pretraining and show that Transformer-based architectures, too, learn embeddings suggestive of distinct legal language.},
booktitle = {Proceedings of the Eighteenth International Conference on Artificial Intelligence and Law},
pages = {159–168},
numpages = {10},
keywords = {benchmark dataset, law, natural language processing, pretraining},
location = {S\~{a}o Paulo, Brazil},
series = {ICAIL '21}
}

@article{10.1371/journal.pone.0174698,
    doi = {10.1371/journal.pone.0174698},
    author = {Katz, Daniel Martin AND Bommarito, II, Michael J. AND Blackman, Josh},
    journal = {PLOS ONE},
    publisher = {Public Library of Science},
    title = {A general approach for predicting the behavior of the Supreme Court of the United States},
    year = {2017},
    month = {04},
    volume = {12},
    url = {https://doi.org/10.1371/journal.pone.0174698},
    pages = {1-18},
    abstract = {Building on developments in machine learning and prior work in the science of judicial prediction, we construct a model designed to predict the behavior of the Supreme Court of the United States in a generalized, out-of-sample context. To do so, we develop a time-evolving random forest classifier that leverages unique feature engineering to predict more than 240,000 justice votes and 28,000 cases outcomes over nearly two centuries (1816-2015). Using only data available prior to decision, our model outperforms null (baseline) models at both the justice and case level under both parametric and non-parametric tests. Over nearly two centuries, we achieve 70.2% accuracy at the case outcome level and 71.9% at the justice vote level. More recently, over the past century, we outperform an in-sample optimized null model by nearly 5%. Our performance is consistent with, and improves on the general level of prediction demonstrated by prior work; however, our model is distinctive because it can be applied out-of-sample to the entire past and future of the Court, not a single term. Our results represent an important advance for the science of quantitative legal prediction and portend a range of other potential applications.},
    number = {4},

}

@inproceedings{10.5555/3600270.3602628,
author = {Hwang, Wonseok and Lee, Dongjun and Cho, Kyoungyeon and Lee, Hanuhl and Seo, Minjoon},
title = {A multi-task benchmark for korean legal language understanding and judgement prediction},
year = {2024},
isbn = {9781713871088},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {The recent advances of deep learning have dramatically changed how machine learning, especially in the domain of natural language processing, can be applied to legal domain. However, this shift to the data-driven approaches calls for larger and more diverse datasets, which are nevertheless still small in number, especially in non-English languages. Here we present the first large-scale benchmark of Korean legal AI datasets, LBOX OPEN, that consists of one legal corpus, two classification tasks, two legal judgement prediction (LJP) tasks, and one summarization task. The legal corpus consists of 147k Korean precedents (259M tokens), of which 63k are sentenced in last 4 years and 96k are from the first and the second level courts in which factual issues are reviewed. The two classification tasks are case names (11.3k) and statutes (2.8k) prediction from the factual description of individual cases. The LJP tasks consist of (1) 10.5k criminal examples where the model is asked to predict fine amount, imprisonment with labor, and imprisonment without labor ranges for the given facts, and (2) 4.7k civil examples where the inputs are facts and claim for relief and outputs are the degrees of claim acceptance. The summarization task consists of the Supreme Court precedents and the corresponding summaries (20k). We also release realistic variants of the datasets by extending the domain (1) to infrequent case categories in case name (31k examples) and statute (17.7k) classification tasks, and (2) to long input sequences in the summarization task (51k). Finally, we release LCUBE, the first Korean legal language model trained on the legal corpus from this study. Given the uniqueness of the Law of South Korea and the diversity of the legal tasks covered in this work, we believe that LBOX OPEN contributes to the multilinguality of global legal research.},
booktitle = {Proceedings of the 36th International Conference on Neural Information Processing Systems},
articleno = {2358},
numpages = {15},
location = {, New Orleans, LA, USA, },
series = {NIPS '22}
}

@inproceedings{Holzenberger2020ADF,
  title={A Dataset for Statutory Reasoning in Tax Law Entailment and Question Answering},
  author={Nils Holzenberger and Andrew Blair-Stanek and Benjamin Van Durme}

@article{Katz2023NaturalLP,
  title={Natural Language Processing in the Legal Domain},
  author={Daniel Martin Katz and Dirk Hartung and Lauritz Gerlach and Abhik Jana and Michael James Bommarito},
  journal={ArXiv},
  year={2023},
  volume={abs/2302.12039},
  url={https://api.semanticscholar.org/CorpusID:256440319}
}

@inproceedings{Kaur2019ConvolutionalNN,
  title={Convolutional Neural Network-based Automatic Prediction of Judgments of the European Court of Human Rights},
  author={Arshdeep Kaur and Bojan Bozic},
  booktitle={Irish Conference on Artificial Intelligence and Cognitive Science},
  year={2019},
  url={https://api.semanticscholar.org/CorpusID:207824257}
}

@article{Medvedeva2020-MEDUML,
	author = {Masha Medvedeva and Michel Vols and Martijn Wieling},
	doi = {10.1007/s10506-019-09255-y},
	journal = {Artificial Intelligence and Law},
	number = {2},
	pages = {237--266},
	publisher = {Springer Verlag},
	title = {Using Machine Learning to Predict Decisions of the European Court of Human Rights},
	volume = {28},
	year = {2020}
}

@article{SparksofAGI,
  title={Sparks of Artificial General Intelligence: Early experiments with GPT-4},
  author={S{\'e}bastien Bubeck and Varun Chandrasekaran and Ronen Eldan and John A. Gehrke and Eric Horvitz and Ece Kamar and Peter Lee and Yin Tat Lee and Yuan-Fang Li and Scott M. Lundberg and Harsha Nori and Hamid Palangi and Marco Tulio Ribeiro and Yi Zhang},
  journal={ArXiv},
  year={2023},
  volume={abs/2303.12712},
  url={https://api.semanticscholar.org/CorpusID:257663729}
}

@article{Xiao2018CAIL2018AL,
  title={CAIL2018: A Large-Scale Legal Dataset for Judgment Prediction},
  author={Chaojun Xiao and Haoxiang Zhong and Zhipeng Guo and Cunchao Tu and Zhiyuan Liu and Maosong Sun and Yansong Feng and Xianpei Han and Zhen Hu and Heng Wang and Jianfeng Xu},
  journal={ArXiv},
  year={2018},
  volume={abs/1807.02478},
  url={https://api.semanticscholar.org/CorpusID:49652844}
}

@article{Zala2023DiagrammerGPT,
        author = {Abhay Zala and Han Lin and Jaemin Cho and Mohit Bansal},
        title = {DiagrammerGPT: Generating Open-Domain, Open-Platform Diagrams via LLM Planning},
        year = {2023},
}

@inproceedings{automatikz,
  title={AutomaTikZ: Text-Guided Synthesis of Scientific Vector Graphics with TikZ},
  author={Jonas Belouadi and Anne Lauscher and Steffen Eger},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2024}
}

@inproceedings{barale-etal-2023-asylex,
    title = "{A}sy{L}ex: A Dataset for Legal Language Processing of Refugee Claims",
    author = "Barale, Claire  and
      Klaisoongnoen, Mark  and
      Minervini, Pasquale  and
      Rovatsos, Michael  and
      Bhuta, Nehal",
    editor = "Preo{\textcommabelow{t}}iuc-Pietro, Daniel  and
      Goanta, Catalina  and
      Chalkidis, Ilias  and
      Barrett, Leslie  and
      Spanakis, Gerasimos (Jerry)  and
      Aletras, Nikolaos",
    booktitle = "Proceedings of the Natural Legal Language Processing Workshop 2023",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.nllp-1.24",
    doi = "10.18653/v1/2023.nllp-1.24",
    pages = "244--257",
    abstract = "Advancements in natural language processing (NLP) and language models have demonstrated immense potential in the legal domain, enabling automated analysis and comprehension of legal texts. However, developing robust models in Legal NLP is significantly challenged by the scarcity of resources. This paper presents AsyLex, the first dataset specifically designed for Refugee Law applications to address this gap. The dataset introduces 59,112 documents on refugee status determination in Canada from 1996 to 2022, providing researchers and practitioners with essential material for training and evaluating NLP models for legal research and case review. Case review is defined as entity extraction and outcome prediction tasks. The dataset includes 19,115 gold-standard human-labeled annotations for 20 legally relevant entity types curated with the help of legal experts and 1,682 gold-standard labeled documents for the case outcome. Furthermore, we supply the corresponding trained entity extraction models and the resulting labeled entities generated through the inference process on AsyLex. Four supplementary features are obtained through rule-based extraction. We demonstrate the usefulness of our dataset on the legal judgment prediction task to predict the binary outcome and test a set of baselines using the text of the documents and our annotations. We observe that models pretrained on similar legal documents reach better scores, suggesting that acquiring more datasets for specialized domains such as law is crucial.",
}

@inproceedings{chalkidis-etal-2019-extreme,
    title = "Extreme Multi-Label Legal Text Classification: A Case Study in {EU} Legislation",
    author = "Chalkidis, Ilias  and
      Fergadiotis, Emmanouil  and
      Malakasiotis, Prodromos  and
      Aletras, Nikolaos  and
      Androutsopoulos, Ion",
    editor = "Aletras, Nikolaos  and
      Ash, Elliott  and
      Barrett, Leslie  and
      Chen, Daniel  and
      Meyers, Adam  and
      Preotiuc-Pietro, Daniel  and
      Rosenberg, David  and
      Stent, Amanda",
    booktitle = "Proceedings of the Natural Legal Language Processing Workshop 2019",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W19-2209",
    doi = "10.18653/v1/W19-2209",
    pages = "78--87",
    abstract = "We consider the task of Extreme Multi-Label Text Classification (XMTC) in the legal domain. We release a new dataset of 57k legislative documents from EURLEX, the European Union{'}s public document database, annotated with concepts from EUROVOC, a multidisciplinary thesaurus. The dataset is substantially larger than previous EURLEX datasets and suitable for XMTC, few-shot and zero-shot learning. Experimenting with several neural classifiers, we show that BIGRUs with self-attention outperform the current multi-label state-of-the-art methods, which employ label-wise attention. Replacing CNNs with BIGRUs in label-wise attention networks leads to the best overall performance.",
}

@inproceedings{chalkidis-etal-2022-lexglue,
    title = "{L}ex{GLUE}: A Benchmark Dataset for Legal Language Understanding in {E}nglish",
    author = "Chalkidis, Ilias  and
      Jana, Abhik  and
      Hartung, Dirk  and
      Bommarito, Michael  and
      Androutsopoulos, Ion  and
      Katz, Daniel  and
      Aletras, Nikolaos",
    editor = "Muresan, Smaranda  and
      Nakov, Preslav  and
      Villavicencio, Aline",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.297",
    doi = "10.18653/v1/2022.acl-long.297",
    pages = "4310--4330",
    abstract = "Laws and their interpretations, legal arguments and agreements are typically expressed in writing, leading to the production of vast corpora of legal text. Their analysis, which is at the center of legal practice, becomes increasingly elaborate as these collections grow in size. Natural language understanding (NLU) technologies can be a valuable tool to support legal practitioners in these endeavors. Their usefulness, however, largely depends on whether current state-of-the-art models can generalize across various tasks in the legal domain. To answer this currently open question, we introduce the Legal General Language Understanding Evaluation (LexGLUE) benchmark, a collection of datasets for evaluating model performance across a diverse set of legal NLU tasks in a standardized way. We also provide an evaluation and analysis of several generic and legal-oriented models demonstrating that the latter consistently offer performance improvements across multiple tasks.",
}

@inproceedings{chalkidis-etal-2023-lexfiles,
    title = "{L}e{XF}iles and {L}egal{LAMA}: Facilitating {E}nglish Multinational Legal Language Model Development",
    author = "Chalkidis, Ilias  and
      Garneau, Nicolas  and
      Goanta, Catalina  and
      Katz, Daniel  and
      S{\o}gaard, Anders",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.865",
    doi = "10.18653/v1/2023.acl-long.865",
    pages = "15513--15535",
    abstract = "In this work, we conduct a detailed analysis on the performance of legal-oriented pre-trained language models (PLMs). We examine the interplay between their original objective, acquired knowledge, and legal language understanding capacities which we define as the upstream, probing, and downstream performance, respectively. We consider not only the models{'} size but also the pre-training corpora used as important dimensions in our study. To this end, we release a multinational English legal corpus (LeXFiles) and a legal knowledge probing benchmark (LegalLAMA) to facilitate training and detailed analysis of legal-oriented PLMs. We release two new legal PLMs trained on LeXFiles and evaluate them alongside others on LegalLAMA and LexGLUE. We find that probing performance strongly correlates with upstream performance in related legal topics. On the other hand, downstream performance is mainly driven by the model{'}s size and prior legal knowledge which can be estimated by upstream and probing performance. Based on these findings, we can conclude that both dimensions are important for those seeking the development of domain-specific PLMs.",
}

@inproceedings{chen-etal-2019-charge,
    title = "Charge-Based Prison Term Prediction with Deep Gating Network",
    author = "Chen, Huajie  and
      Cai, Deng  and
      Dai, Wei  and
      Dai, Zehui  and
      Ding, Yadong",
    editor = "Inui, Kentaro  and
      Jiang, Jing  and
      Ng, Vincent  and
      Wan, Xiaojun",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-1667",
    doi = "10.18653/v1/D19-1667",
    pages = "6362--6367",
    abstract = "Judgment prediction for legal cases has attracted much research efforts for its practice use, of which the ultimate goal is prison term prediction. While existing work merely predicts the total prison term, in reality a defendant is often charged with multiple crimes. In this paper, we argue that charge-based prison term prediction (CPTP) not only better fits realistic needs, but also makes the total prison term prediction more accurate and interpretable. We collect the first large-scale structured data for CPTP and evaluate several competitive baselines. Based on the observation that fine-grained feature selection is the key to achieving good performance, we propose the Deep Gating Network (DGN) for charge-specific feature selection and aggregation. Experiments show that DGN achieves the state-of-the-art performance.",
}

@inproceedings{christopoulou-etal-2024-text,
    title = "Text-to-Code Generation with Modality-relative Pre-training",
    author = "Christopoulou, Fenia  and
      Zhang, Guchun  and
      Lampouras, Gerasimos",
    editor = "Graham, Yvette  and
      Purver, Matthew",
    booktitle = "Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = mar,
    year = "2024",
    address = "St. Julian{'}s, Malta",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.eacl-long.72",
    pages = "1194--1208",
    abstract = "Large pre-trained language models have recently been expanded and applied to programming language tasks with great success, often through further pre-training of a strictly-natural language model{--}where training sequences typically contain both natural and (linearised) programming language. Such approaches effectively map both modalities of the sequence into the same embedding space. However, programming language keywords (e.g. {``}while{''}

@inproceedings{drawzeski-etal-2021-corpus,
    title = "A Corpus for Multilingual Analysis of Online Terms of Service",
    author = "Drawzeski, Kasper  and
      Galassi, Andrea  and
      Jablonowska, Agnieszka  and
      Lagioia, Francesca  and
      Lippi, Marco  and
      Micklitz, Hans Wolfgang  and
      Sartor, Giovanni  and
      Tagiuri, Giacomo  and
      Torroni, Paolo",
    editor = "Aletras, Nikolaos  and
      Androutsopoulos, Ion  and
      Barrett, Leslie  and
      Goanta, Catalina  and
      Preotiuc-Pietro, Daniel",
    booktitle = "Proceedings of the Natural Legal Language Processing Workshop 2021",
    month = nov,
    year = "2021",
    address = "Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.nllp-1.1",
    doi = "10.18653/v1/2021.nllp-1.1",
    pages = "1--8",
    abstract = "We present the first annotated corpus for multilingual analysis of potentially unfair clauses in online Terms of Service. The data set comprises a total of 100 contracts, obtained from 25 documents annotated in four different languages: English, German, Italian, and Polish. For each contract, potentially unfair clauses for the consumer are annotated, for nine different unfairness categories. We show how a simple yet efficient annotation projection technique based on sentence embeddings could be used to automatically transfer annotations across languages.",
}

@article{hendrycks2021cuad,
      title={CUAD: An Expert-Annotated NLP Dataset for Legal Contract Review}, 
      author={Dan Hendrycks and Collin Burns and Anya Chen and Spencer Ball},
      journal={NeurIPS},
      year={2021}
}

@conference{icaart21,
author={Stefanie Urchs. and Jelena Mitrović. and Michael Granitzer.},
title={Design and Implementation of German Legal Decision Corpora},
booktitle={Proceedings of the 13th International Conference on Agents and Artificial Intelligence - Volume 2: ICAART},
year={2021},
pages={515-521},
publisher={SciTePress},
organization={INSTICC},
doi={10.5220/0010187305150521},
isbn={978-989-758-484-8},
issn={2184-433X},
}

@inproceedings{jin-etal-2020-genwiki,
    title = "{G}en{W}iki: A Dataset of 1.3 Million Content-Sharing Text and Graphs for Unsupervised Graph-to-Text Generation",
    author = "Jin, Zhijing  and
      Guo, Qipeng  and
      Qiu, Xipeng  and
      Zhang, Zheng",
    editor = "Scott, Donia  and
      Bel, Nuria  and
      Zong, Chengqing",
    booktitle = "Proceedings of the 28th International Conference on Computational Linguistics",
    month = dec,
    year = "2020",
    address = "Barcelona, Spain (Online)",
    publisher = "International Committee on Computational Linguistics",
    url = "https://aclanthology.org/2020.coling-main.217",
    doi = "10.18653/v1/2020.coling-main.217",
    pages = "2398--2409",
    abstract = "Data collection for the knowledge graph-to-text generation is expensive. As a result, research on unsupervised models has emerged as an active field recently. However, most unsupervised models have to use non-parallel versions of existing small supervised datasets, which largely constrain their potential. In this paper, we propose a large-scale, general-domain dataset, GenWiki. Our unsupervised dataset has 1.3M text and graph examples, respectively. With a human-annotated test set, we provide this new benchmark dataset for future research on unsupervised text generation from knowledge graphs.",
}

@inproceedings{koncel-kedziorski-etal-2019-text,
    title = "{T}ext {G}eneration from {K}nowledge {G}raphs with {G}raph {T}ransformers",
    author = "Koncel-Kedziorski, Rik  and
      Bekal, Dhanush  and
      Luan, Yi  and
      Lapata, Mirella  and
      Hajishirzi, Hannaneh",
    editor = "Burstein, Jill  and
      Doran, Christy  and
      Solorio, Thamar",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1238",
    doi = "10.18653/v1/N19-1238",
    pages = "2284--2293",
    abstract = "Generating texts which express complex ideas spanning multiple sentences requires a structured representation of their content (document plan), but these representations are prohibitively expensive to manually produce. In this work, we address the problem of generating coherent multi-sentence texts from the output of an information extraction system, and in particular a knowledge graph. Graphical knowledge representations are ubiquitous in computing, but pose a significant challenge for text generation techniques due to their non-hierarchical nature, collapsing of long-distance dependencies, and structural variety. We introduce a novel graph transforming encoder which can leverage the relational structure of such knowledge graphs without imposing linearization or hierarchical constraints. Incorporated into an encoder-decoder setup, we provide an end-to-end trainable system for graph-to-text generation that we apply to the domain of scientific text. Automatic and human evaluations show that our technique produces more informative texts which exhibit better document structure than competitive encoder-decoder methods.",
}

@inproceedings{niklaus-etal-2021-swiss,
    title = "{S}wiss-Judgment-Prediction: A Multilingual Legal Judgment Prediction Benchmark",
    author = {Niklaus, Joel  and
      Chalkidis, Ilias  and
      St{\"u}rmer, Matthias},
    editor = "Aletras, Nikolaos  and
      Androutsopoulos, Ion  and
      Barrett, Leslie  and
      Goanta, Catalina  and
      Preotiuc-Pietro, Daniel",
    booktitle = "Proceedings of the Natural Legal Language Processing Workshop 2021",
    month = nov,
    year = "2021",
    address = "Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.nllp-1.3",
    doi = "10.18653/v1/2021.nllp-1.3",
    pages = "19--35",
    abstract = "In many jurisdictions, the excessive workload of courts leads to high delays. Suitable predictive AI models can assist legal professionals in their work, and thus enhance and speed up the process. So far, Legal Judgment Prediction (LJP) datasets have been released in English, French, and Chinese. We publicly release a multilingual (German, French, and Italian), diachronic (2000-2020) corpus of 85K cases from the Federal Supreme Court of Switzer- land (FSCS). We evaluate state-of-the-art BERT-based methods including two variants of BERT that overcome the BERT input (text) length limitation (up to 512 tokens). Hierarchical BERT has the best performance (approx. 68-70{\%} Macro-F1-Score in German and French). Furthermore, we study how several factors (canton of origin, year of publication, text length, legal area) affect performance. We release both the benchmark dataset and our code to accelerate future research and ensure reproducibility.",
}

@inproceedings{niklaus-etal-2023-lextreme,
    title = "{LEXTREME}: A Multi-Lingual and Multi-Task Benchmark for the Legal Domain",
    author = {Niklaus, Joel  and
      Matoshi, Veton  and
      Rani, Pooja  and
      Galassi, Andrea  and
      St{\"u}rmer, Matthias  and
      Chalkidis, Ilias},
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-emnlp.200",
    doi = "10.18653/v1/2023.findings-emnlp.200",
    pages = "3016--3054",
    abstract = "Lately, propelled by phenomenal advances around the transformer architecture, the legal NLP field has enjoyed spectacular growth. To measure progress, well-curated and challenging benchmarks are crucial. Previous efforts have produced numerous benchmarks for general NLP models, typically based on news or Wikipedia. However, these may not fit specific domains such as law, with its unique lexicons and intricate sentence structures. Even though there is a rising need to build NLP systems for languages other than English, many benchmarks are available only in English and no multilingual benchmark exists in the legal NLP field. We survey the legal NLP literature and select 11 datasets covering 24 languages, creating LEXTREME. To fairly compare models, we propose two aggregate scores, i.e., dataset aggregate score and language aggregate score. Our results show that even the best baseline only achieves modest results, and also ChatGPT struggles with many tasks. This indicates that LEXTREME remains a challenging task with ample room for improvement. To facilitate easy use for researchers and practitioners, we release LEXTREME on huggingface along with a public leaderboard and the necessary code to evaluate models. We also provide a public Weights and Biases project containing all runs for transparency.",
}

@inproceedings{shi-etal-2022-natural,
    title = "Natural Language to Code Translation with Execution",
    author = "Shi, Freda  and
      Fried, Daniel  and
      Ghazvininejad, Marjan  and
      Zettlemoyer, Luke  and
      Wang, Sida I.",
    editor = "Goldberg, Yoav  and
      Kozareva, Zornitsa  and
      Zhang, Yue",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.231",
    doi = "10.18653/v1/2022.emnlp-main.231",
    pages = "3533--3546",
    abstract = "Generative models of code, pretrained on large corpora of programs, have shown great success in translating natural language to code (Chen et al., 2021; Austin et al., 2021; Li et al., 2022, inter alia). While these models do not explicitly incorporate program semantics (i.e., execution results) during training, they are able to generate correct solutions for many problems. However, choosing a single correct program from a generated set for each problem remains challenging. In this work, we introduce execution result{--}based minimum Bayes risk decoding (MBR-EXEC) for program selection and show that it improves the few-shot performance of pretrained code models on natural-language-to-code tasks. We select output programs from a generated candidate set by marginalizing over program implementations that share the same semantics. Because exact equivalence is intractable, we execute each program on a small number of test inputs to approximate semantic equivalence. Across datasets, execution or simulated execution significantly outperforms the methods that do not involve program semantics. We find that MBR-EXEC consistently improves over all execution-unaware selection methods, suggesting it as an effective approach for natural language to code translation.",
}

@inproceedings{tuggener-etal-2020-ledgar,
    title = "{LEDGAR}: A Large-Scale Multi-label Corpus for Text Classification of Legal Provisions in Contracts",
    author = {Tuggener, Don  and
      von D{\"a}niken, Pius  and
      Peetz, Thomas  and
      Cieliebak, Mark},
    editor = "Calzolari, Nicoletta  and
      B{\'e}chet, Fr{\'e}d{\'e}ric  and
      Blache, Philippe  and
      Choukri, Khalid  and
      Cieri, Christopher  and
      Declerck, Thierry  and
      Goggi, Sara  and
      Isahara, Hitoshi  and
      Maegaard, Bente  and
      Mariani, Joseph  and
      Mazo, H{\'e}l{\`e}ne  and
      Moreno, Asuncion  and
      Odijk, Jan  and
      Piperidis, Stelios",
    booktitle = "Proceedings of the Twelfth Language Resources and Evaluation Conference",
    month = may,
    year = "2020",
    address = "Marseille, France",
    publisher = "European Language Resources Association",
    url = "https://aclanthology.org/2020.lrec-1.155",
    pages = "1235--1241",
    abstract = "We present LEDGAR, a multilabel corpus of legal provisions in contracts. The corpus was crawled and scraped from the public domain (SEC filings) and is, to the best of our knowledge, the first freely available corpus of its kind. Since the corpus was constructed semi-automatically, we apply and discuss various approaches to noise removal. Due to the rather large labelset of over 12{'}000 labels annotated in almost 100{'}000 provisions in over 60{'}000 contracts, we believe the corpus to be of interest for research in the field of Legal NLP, (large-scale or extreme) text classification, as well as for legal studies. We discuss several methods to sample subcopora from the corpus and implement and evaluate different automatic classification approaches. Finally, we perform transfer experiments to evaluate how well the classifiers perform on contracts stemming from outside the corpus.",
    language = "English",
    ISBN = "979-10-95546-34-4",
}

@inproceedings{ye-etal-2018-interpretable,
    title = "Interpretable Charge Predictions for Criminal Cases: Learning to Generate Court Views from Fact Descriptions",
    author = "Ye, Hai  and
      Jiang, Xin  and
      Luo, Zhunchen  and
      Chao, Wenhan",
    editor = "Walker, Marilyn  and
      Ji, Heng  and
      Stent, Amanda",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N18-1168",
    doi = "10.18653/v1/N18-1168",
    pages = "1854--1864",
    abstract = "In this paper, we propose to study the problem of court view generation from the fact description in a criminal case. The task aims to improve the interpretability of charge prediction systems and help automatic legal document generation. We formulate this task as a text-to-text natural language generation (NLG) problem. Sequence-to-sequence model has achieved cutting-edge performances in many NLG tasks. However, due to the non-distinctions of fact descriptions, it is hard for Seq2Seq model to generate charge-discriminative court views. In this work, we explore charge labels to tackle this issue. We propose a label-conditioned Seq2Seq model with attention for this problem, to decode court views conditioned on encoded charge labels. Experimental results show the effectiveness of our method.",
}

