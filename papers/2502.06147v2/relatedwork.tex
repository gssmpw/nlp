\section{Related Work}
NLP applications in the legal domain are several core areas~\citep{Katz2023NaturalLP} such as information extraction, classification, summarization, judgment prediction, and resources and benchmarks.

\paragraph{Judgment prediction}
In this task, models predict the outcomes of legal cases based on given facts.
Previous studies provide judgment data from various courts of diverse countries, including decisions from the Supreme Court of the United States~\citep{10.1371/journal.pone.0174698} and the European Court of Human Rights~\citep{Medvedeva2020-MEDUML, Kaur2019ConvolutionalNN}.
Additionally, judgment prediction research has covered Switzerland~\citep{niklaus-etal-2021-swiss}, Chinna~\citep{ye-etal-2018-interpretable}, criminal law~\citep{chen-etal-2019-charge, Xiao2018CAIL2018AL}, and asylum decisions~\citep{10.1145/3086512.3086538, 10.1145/3086512.3086537}.

\paragraph{Legal resources and benchmarks} 
Datasets and benchmarks, covering a broad range of legal domains and languages, have been proposed.
These include English Tax Law~\citep{Holzenberger2020ADF}, European Legislation and the European Court of Human Rights~\citep{chalkidis-etal-2019-extreme}, Corporate and Contract Law~\citep{hendrycks2021cuad, tuggener-etal-2020-ledgar}, Supreme Court cases and US court cases~\citep{10.1145/3462757.3466088}.
The scope extends to German legal cases~\citep{icaart21}, a mixture of Korean legal text summarization, prediction and text classification~\citep{10.5555/3600270.3602628}, and refugee cases~\citep{barale-etal-2023-asylex}. 
Additionally, multilingual and multi-legal domain datasets have been developed, such as a multilingual corpus of English, German, Italian, Polish ~\citep{drawzeski-etal-2021-corpus},
and LEXGLUE~\citep{chalkidis-etal-2022-lexglue} which covers six predictive tasks over five datasets made of English from the US, EU, and Council of Europe.
Furthermore, Lexfiles~\citep{chalkidis-etal-2023-lexfiles} offers a comprehensive dataset of comprised of US, UK, Canada, India, European Court of Human Rights, and Lextreme~\citep{niklaus-etal-2023-lextreme}, which covers wide-range of tasks and countries among EU nations.
However, none of these datasets are designed to support the visualization of legal documents for non-experts.
In contrast, \datasetName offers legal specific annotations in 23 multilingual legal documents, specifically tailored for visualization.
These annotations cover legal entities, their relationship, related rule, related facts of legal texts, thereby enhancing the clarity and interpretation of legal documents for judicial judgments.

\if[]
Our \datasetName contributes to identification of legal entity, their relationship, related rule, related facts of legal texts, providing 
Once those four elements are identified from dispute backgrounds, judges can generate legal decisions using law identified by model and applying entities and facts to the legal requirements.
\fi


\paragraph{Text to graph generation}
Following the iconic successions of the GPT models, LLMs can generate not only contextual texts and program codes~\citep{shi-etal-2022-natural, christopoulou-etal-2024-text} but also visualization codes~\citep{SparksofAGI}, such as creation of scientific vector graphics with TiKZ~\cite{automatikz}
%the TiKZ dataset~\cite{automatikz} 
and diagram generation with refinements and diffusion process~\cite{Zala2023DiagrammerGPT}.
Text-to-code generation studies are predominantly focused on mainstream programming languages like Python and shell scripts, and are typically examined with English text~\citep{shi-etal-2022-natural, christopoulou-etal-2024-text}.
Both text-to-graph generation and graph-to-text generation studies are often conducted for clarifying paragraph structure and summarizing critical issues and relationship between words~\citep{koncel-kedziorski-etal-2019-text, jin-etal-2020-genwiki} of the input plain texts mainly in English.
These text-to-graph approaches are suitable for free drawing based on text instructions, but they sacrifice the visualization of logical relationships within the visualized content. 
In comparison, our graph generation approach utilizes the DOT language of Graphviz, enabling models to focus specifically on visualizing the logical relationships within the content.