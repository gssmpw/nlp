% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").

@misc{olah2022mechanistic,
  author    = {Chris Olah},
  title     = {Mechanistic Interpretability, Variables, and the Importance of Interpretable Bases},
  year      = {2022},
  howpublished = {\url{https://www.transformer-circuits.pub/2022/mech-interp-essay}},
}
@article{yang2024makes,
  title={What makes your model a low-empathy or warmth person: Exploring the Origins of Personality in LLMs},
  author={Yang, Shu and Zhu, Shenzhe and Bao, Ruoxuan and Liu, Liang and Cheng, Yu and Hu, Lijie and Li, Mengdi and Wang, Di},
  journal={arXiv preprint arXiv:2410.10863},
  year={2024}
}
@article{hong2024dissecting,
  title={Dissecting Fine-Tuning Unlearning in Large Language Models},
  author={Hong, Yihuai and Zou, Yuelin and Hu, Lijie and Zeng, Ziqian and Wang, Di and Yang, Haiqin},
  journal={arXiv preprint arXiv:2410.06606},
  year={2024}
}
@article{zhang2024locate,
  title={Locate-then-edit for Multi-hop Factual Recall under Knowledge Editing},
  author={Zhang, Zhuoran and Li, Yongxiang and Kan, Zijian and Cheng, Keyuan and Hu, Lijie and Wang, Di},
  journal={arXiv preprint arXiv:2410.06331},
  year={2024}
}
@article{hu2024dissecting,
  title={Dissecting Misalignment of Multimodal Large Language Models via Influence Function},
  author={Hu, Lijie and Ren, Chenyang and Xie, Huanyi and Saadi, Khouloud and Yang, Shu and Zhang, Jingfeng and Wang, Di},
  journal={arXiv preprint arXiv:2411.11667},
  year={2024}
}
@inproceedings{huimproving,
  title={Improving Interpretation Faithfulness for Vision Transformers},
  author={Hu, Lijie and Liu, Yixin and Liu, Ninghao and Huai, Mengdi and Sun, Lichao and Wang, Di},
  booktitle={Forty-first International Conference on Machine Learning}
}
@article{yang2024moral,
  title={MoRAL: MoE Augmented LoRA for LLMs' Lifelong Learning},
  author={Yang, Shu and Ali, Muhammad Asif and Wang, Cheng-Long and Hu, Lijie and Wang, Di},
  journal={arXiv preprint arXiv:2402.11260},
  year={2024}
}
@article{cheng2024multi,
  title={Multi-hop question answering under temporal knowledge editing},
  author={Cheng, Keyuan and Lin, Gang and Fei, Haoyang and Yu, Lu and Ali, Muhammad Asif and Hu, Lijie and Wang, Di and others},
  journal={arXiv preprint arXiv:2404.00492},
  year={2024}
}
@article{hu2024hopfieldian,
  title={A Hopfieldian View-based Interpretation for Chain-of-Thought Reasoning},
  author={Hu, Lijie and Liu, Liang and Yang, Shu and Chen, Xin and Xiao, Hongru and Li, Mengdi and Zhou, Pan and Ali, Muhammad Asif and Wang, Di},
  journal={arXiv preprint arXiv:2406.12255},
  year={2024}
}
@article{hu2024editable,
  title={Editable concept bottleneck models},
  author={Hu, Lijie and Ren, Chenyang and Hu, Zhengyu and Lin, Hongbin and Wang, Cheng-Long and Xiong, Hui and Zhang, Jingfeng and Wang, Di},
  journal={arXiv preprint arXiv:2405.15476},
  year={2024}
}
@article{vaswani2017attention,
  author    = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Lukasz and Polosukhin, Illia},
  title     = {Attention is All You Need},
  journal   = {Advances in Neural Information Processing Systems},
  volume    = {30},
  pages     = {5998--6008},
  year      = {2017},
}

@inproceedings{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Ichter, Brian and Xia, Fei and Chi, Ed H. and Le, Quoc V. and Zhou, Denny},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2022}
}

@inproceedings{kojima2022large,
  title={Large language models are zero-shot reasoners},
  author={Kojima, Takeshi and Gu, Shixiang Shane and Reid, Machel and Matsuo, Yutaka and Iwasawa, Yusuke},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2022}
}

@article{creswell2022faithful,
  title={Faithful reasoning using large language models},
  author={Creswell, Antonia and Shanahan, Murray},
  journal={CoRR},
  volume={abs/2208.14271},
  year={2022},
  url={https://arxiv.org/abs/2208.14271}
}

@article{creswell2022selection,
  title={Selection-inference: Exploiting large language models for interpretable logical reasoning},
  author={Creswell, Antonia and Shanahan, Murray and Higgins, Irina},
  journal={CoRR},
  volume={abs/2205.09712},
  year={2022},
  url={https://arxiv.org/abs/2205.09712}
}

@article{chen2023reckoning,
  title={RECKONING: Reasoning through dynamic knowledge encoding},
  author={Chen, Zeming and Weiss, Gail and Mitchell, Eric and Celikyilmaz, Asli and Bosselut, Antoine},
  journal={CoRR},
  volume={abs/2305.06349},
  year={2023},
  url={https://arxiv.org/abs/2305.06349}
}

@article{hou2023towards,
  title={Towards a mechanistic interpretation of multi-step reasoning capabilities of language models},
  author={Hou, Y. and Li, J. and Fei, Y. and others},
  journal={arXiv preprint arXiv:2310.14491},
  year={2023}
}

@inproceedings{dong2021fly,
  title={On-the-fly attention modulation for neural generation},
  author={Dong, Yue and Bhagavatula, Chandra and Lu, Ximing and Hwang, Jena D. and Bosselut, Antoine and Cheung, Jackie Chi Kit and Choi, Yejin},
  booktitle={Findings of the Association for Computational Linguistics: ACL/IJCNLP 2021, Online Event, August 1-6, 2021},
  volume={Findings of ACL},
  pages={1261--1274},
  year={2021},
  organization={Association for Computational Linguistics}
}

@inproceedings{NEURIPS2020_1457c0d6,
 author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {1877--1901},
 publisher = {Curran Associates, Inc.},
 title = {Language Models are Few-Shot Learners},
 url = {https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf},
 volume = {33},
 year = {2020}
}
@misc{nanda2023mechanistic,
  author    = {Neel Nanda},
  title     = {Mechanistic Interpretability Quickstart Guide},
  howpublished = {Neel Nandaâ€™s Blog},
  year      = {2023},
  month     = {January},
  note      = {Accessed: 2023-01-26},
}

@article{meng2022locating,
  author    = {Meng, Kevin and Bau, David and Andonian, Alex and others},
  title     = {Locating and Editing Factual Associations in GPT},
  journal   = {Advances in Neural Information Processing Systems},
  volume    = {35},
  pages     = {17359--17372},
  year      = {2022},
}

@article{geiger2021causal,
  author    = {Geiger, Andreas and Lu, Hongjing and Icard, Thomas and others},
  title     = {Causal Abstractions of Neural Networks},
  journal   = {Advances in Neural Information Processing Systems},
  volume    = {34},
  pages     = {9574--9586},
  year      = {2021},
}

@article{geva2020transformer,
  author    = {Geva, Mor and Schuster, Roei and Berant, Jonathan and others},
  title     = {Transformer Feed-Forward Layers are Key-Value Memories},
  journal   = {arXiv preprint arXiv:2012.14913},
  year      = {2020},
}

@article{conmy2023towards,
  author    = {Conmy, Aidan and Mavor-Parker, Alex and Lynch, Anthony and others},
  title     = {Towards Automated Circuit Discovery for Mechanistic Interpretability},
  journal   = {Advances in Neural Information Processing Systems},
  volume    = {36},
  pages     = {16318--16352},
  year      = {2023},
}

@article{olah2020zoom,
  author    = {Chris Olah and Nick Cammarata and Ludwig Schubert and Gabriel Goh and Michael Petrov and Shan Carter},
  title     = {Zoom In: An Introduction to Circuits},
  journal   = {Distill},
  year      = {2020},
  doi       = {10.23915/distill.00024.001},
  url       = {https://distill.pub/2020/circuits/zoom-in},
}

@article{michaud2024quantization,
  author    = {Michaud, Edward and Liu, Ziming and Girit, Ugur and others},
  title     = {The Quantization Model of Neural Scaling},
  journal   = {Advances in Neural Information Processing Systems},
  volume    = {36},
  year      = {2024},
}

@article{radford2019language,
  author    = {Radford, Alec and Wu, Jeffrey and Child, Rewon and others},
  title     = {Language Models are Unsupervised Multitask Learners},
  journal   = {OpenAI Blog},
  volume    = {1},
  number    = {8},
  pages     = {9},
  year      = {2019},
}

@article{miller2024transformer,
  author    = {Miller, John and Chughtai, Bilal and Saunders, William},
  title     = {Transformer Circuit Faithfulness Metrics are not Robust},
  journal   = {arXiv preprint arXiv:2407.08734},
  year      = {2024},
}

@article{hanna2024have,
  author    = {Hanna, Moya and Pezzelle, Sandro and Belinkov, Yonatan},
  title     = {Have Faith in Faithfulness: Going Beyond Circuit Overlap When Finding Model Mechanisms},
  journal   = {arXiv preprint arXiv:2403.17806},
  year      = {2024},
}

@article{wang2022interpretability,
  author    = {Wang, Kai and Variengien, Anna and Conmy, Aidan and others},
  title     = {Interpretability in the Wild: A Circuit for Indirect Object Identification in GPT-2 Small},
  journal   = {arXiv preprint arXiv:2211.00593},
  year      = {2022},
}

@article{he2024dictionary,
  author    = {He, Zhaozhi and Ge, Xinyuan and Tang, Qixun and others},
  title     = {Dictionary Learning Improves Patch-Free Circuit Discovery in Mechanistic Interpretability: A Case Study on Othello-GPT},
  journal   = {arXiv preprint arXiv:2402.12201},
  year      = {2024},
}

@article{bereska2024mechanistic,
  title={Mechanistic Interpretability for AI Safety--A Review},
  author={Bereska, L and Gavves, E},
  journal={arXiv preprint arXiv:2404.14082},
  year={2024}
}

@article{warstadt2020blimp,
  title={BLiMP: The benchmark of linguistic minimal pairs for English},
  author={Warstadt, Alex and Parrish, Alicia and Liu, Haokun and others},
  journal={Transactions of the Association for Computational Linguistics},
  volume={8},
  pages={377--392},
  year={2020}
}

@article{covert2021explaining,
  title={Explaining by removing: A unified framework for model explanation},
  author={Covert, Ian and Lundberg, Scott and Lee, Su-In},
  journal={Journal of Machine Learning Research},
  volume={22},
  number={209},
  pages={1--90},
  year={2021}
}

@inproceedings{casalicchio2018visualizing,
  title={Visualizing the feature importance for black box models},
  author={Casalicchio, Giuseppe and Molnar, Christoph and Bischl, Bernd},
  booktitle={Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2018, Dublin, Ireland, September 10--14, 2018, Proceedings, Part I},
  pages={655--670},
  year={2019},
  publisher={Springer International Publishing}
}

@inproceedings{sundararajan2017axiomatic,
  title={Axiomatic attribution for deep networks},
  author={Sundararajan, Mukund and Taly, Ankur and Yan, Qiqi},
  booktitle={International Conference on Machine Learning},
  pages={3319--3328},
  year={2017},
  organization={PMLR}
}

@article{smilkov2017smoothgrad,
  title={SmoothGrad: Removing noise by adding noise},
  author={Smilkov, Daniel and Thorat, Nikhil and Kim, Been and others},
  journal={arXiv preprint arXiv:1706.03825},
  year={2017}
}

@inproceedings{shrikumar2017learning,
  title={Learning important features through propagating activation differences},
  author={Shrikumar, Avanti and Greenside, Peyton and Kundaje, Anshul},
  booktitle={International Conference on Machine Learning},
  pages={3145--3153},
  year={2017},
  organization={PMLR}
}


@article{belinkov2022probing,
  title={Probing classifiers: Promises, shortcomings, and advances},
  author={Belinkov, Yonatan},
  journal={Computational Linguistics},
  volume={48},
  number={1},
  pages={207--219},
  year={2022},
  publisher={MIT Press}
}


@inproceedings{burns2023discovering,
  title={Discovering Latent Knowledge in Language Models Without Supervision},
  author={Burns, Collin and Ye, Haotian and Klein, Dan and Steinhardt, Jacob},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2023}
}


@article{zou2023representation,
  title={Representation Engineering: A Top-Down Approach to AI Transparency},
  author={Zou, Andy and Phan, Long and Chen, Sarah and Campbell, James and Guo, Phillip and Ren, Richard and Pan, Alexander and Yin, Xuwang and Mazeika, Mantas and Dombrowski, Ann-Kathrin and others},
  journal={CoRR},
  year={2023},
  month={October},
}

@article{syed2023attribution,
  title={Attribution patching outperforms automated circuit discovery},
  author={Syed, Aaquib and Rager, Charles and Conmy, Aidan},
  journal={arXiv preprint arXiv:2310.10348},
  year={2023}
}

@article{yao2024knowledge,
  title={Knowledge Circuits in Pretrained Transformers},
  author={Yao, Yunzhi and Zhang, Ning and Xi, Zhihao and others},
  journal={arXiv preprint arXiv:2405.17969},
  year={2024}
}

@article{cook2000detection,
  title={Detection of influential observation in linear regression},
  author={Cook, R Dennis},
  journal={Technometrics},
  volume={42},
  number={1},
  pages={65--68},
  year={2000},
  publisher={Taylor \& Francis}
}

@article{cook1980characterizations,
  title={Characterizations of an empirical influence function for detecting influential cases in regression},
  author={Cook, R Dennis and Weisberg, Sanford},
  journal={Technometrics},
  volume={22},
  number={4},
  pages={495--508},
  year={1980},
  publisher={Taylor \& Francis}
}

@inproceedings{koh2017understanding,
  title={Understanding black-box predictions via influence functions},
  author={Koh, Pang Wei and Liang, Percy},
  booktitle={International conference on machine learning},
  pages={1885--1894},
  year={2017},
  organization={PMLR}
}

@article{warnecke2021machine,
  title={Machine unlearning of features and labels},
  author={Warnecke, Alexander and Pirch, Lukas and Wressnegger, Christian and Rieck, Konrad},
  journal={Network and Distributed System Security (NDSS) Symposium},
  year={2023}
}

@inproceedings{wu2023gif,
  title={Gif: A general graph unlearning strategy via influence function},
  author={Wu, Jiancan and Yang, Yi and Qian, Yuchun and Sui, Yongduo and Wang, Xiang and He, Xiangnan},
  booktitle={Proceedings of the ACM Web Conference 2023},
  pages={651--661},
  year={2023}
}

@article{zhang2023recommendation,
  title={Recommendation unlearning via influence function},
  author={Zhang, Yang and Hu, Zhiyu and Bai, Yimeng and Feng, Fuli and Wu, Jiancan and Wang, Qifan and He, Xiangnan},
  journal={arXiv preprint arXiv:2307.02147},
  year={2023}
}

@inproceedings{brunet2019understanding,
  title={Understanding the origins of bias in word embeddings},
  author={Brunet, Marc-Etienne and Alkalay-Houlihan, Colleen and Anderson, Ashton and Zemel, Richard},
  booktitle={International conference on machine learning},
  pages={803--811},
  year={2019},
  organization={PMLR}
}

@article{chen2020multi,
  title={Multi-stage influence function},
  author={Chen, Hongge and Si, Si and Li, Yang and Chelba, Ciprian and Kumar, Sanjiv and Boning, Duane and Hsieh, Cho-Jui},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={12732--12742},
  year={2020}
}

@inproceedings{basu2021influence,
  title={Influence Functions in Deep Learning Are Fragile},
  author={Basu, S and Pope, P and Feizi, S},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2021}
}

@inproceedings{golatkar2021mixed,
  title={Mixed-privacy forgetting in deep networks},
  author={Golatkar, Aditya and Achille, Alessandro and Ravichandran, Avinash and Polito, Marzia and Soatto, Stefano},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={792--801},
  year={2021}
}

@inproceedings{golatkar2020eternal,
  title={Eternal sunshine of the spotless net: Selective forgetting in deep networks},
  author={Golatkar, Aditya and Achille, Alessandro and Soatto, Stefano},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9304--9312},
  year={2020}
}

@article{liu2024certified,
  title={Certified minimax unlearning with generalization rates and deletion capacity},
  author={Liu, Jiaqi and Lou, Jian and Qin, Zhan and Ren, Kui},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{agarwal2017second,
  title={Second-order stochastic optimization for machine learning in linear time},
  author={Agarwal, Naman and Bullins, Brian and Hazan, Elad},
  journal={Journal of Machine Learning Research},
  volume={18},
  number={116},
  pages={1--40},
  year={2017}
}

@inproceedings{kwon2023datainf,
  title={DataInf: Efficiently Estimating Data Influence in LoRA-tuned LLMs and Diffusion Models},
  author={Kwon, Yongchan and Wu, Eric and Wu, Kevin and Zou, James},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2023}
}

@inproceedings{guo2021fastif,
  title={FastIF: Scalable Influence Functions for Efficient Model Interpretation and Debugging},
  author={Guo, Han and Rajani, Nazneen and Hase, Peter and Bansal, Mohit and Xiong, Caiming},
  booktitle={Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  pages={10333--10350},
  year={2021}
}

@inproceedings{wang2019repairing,
  title={Repairing without retraining: Avoiding disparate impact with counterfactual distributions},
  author={Wang, Hao and Ustun, Berk and Calmon, Flavio},
  booktitle={International Conference on Machine Learning},
  pages={6618--6627},
  year={2019},
  organization={PMLR}
}

@article{han2020explaining,
  title={Explaining black box predictions and unveiling data artifacts through influence functions},
  author={Han, Xiaochuang and Wallace, Byron C and Tsvetkov, Yulia},
  journal={arXiv preprint arXiv:2005.06676},
  year={2020}
}