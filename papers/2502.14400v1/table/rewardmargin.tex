\begin{table}[b]
\vspace{-17pt}
\caption{Reward margin definitions of  $\textbf{RM}_{\text{DPO}}$ and $\textbf{RM}_{\text{R-DPO}}$  induced by DPO~\cite{dpo} and R-DPO~\cite{rdpo}. For a sample $(x, y_{\tau(1)}, y_{\tau(2)})$,  they denote the margin of implicit rewards between the preferred $y_{\tau(1)}$ and dispreferred $y_{\tau(2)}$, where $|y_{\tau(1)}|$ and $|y_{\tau(2)}|$ are the respective response lengths. \vspace{-1.5em}}
\vspace{-11pt}
\label{tab:rm}
\vskip 0.1in
\begin{center}
\scalebox{0.8}{
\begin{tabular}{ccc}
\toprule
\textbf{Type} & \textbf{Method} & \textbf{Reward Margin Formula} \\
\midrule
$\textbf{RM}_{\text{DPO}}$ & BT-DPO & $\textbf{RM}_{\text{DPO}}=\log\frac{\pi_{\wm}\left(y_{\tau(1)}|x\right)}{\pi_{\text{ref}}\left(y_{\tau(1)}|x\right)}\!-\!\log\frac{\pi_{\wm}\left(y_{\tau(2)}|x\right)}{\pi_{\text{ref}}\left(y_{\tau(2)}|x\right)}$\\
% \textbf{RM1} & SimPO & $\frac{1}{|y_{\tau(1)}|}\log\pi_{\wm}\left(y_{\tau(1)}|x\right)-\frac{1}{|y_{\tau(2)}|}\log\pi_{\wm}\left(y_{\tau(1)}|x\right)\!+\!1$ \\
$\textbf{RM}_{\text{R-DPO}}$ & R-DPO & $\textbf{RM}_{\text{R-DPO}} =\textbf{RM}_{\text{DPO}} - 0.01(|y_{\tau(1)}|-|y_{\tau(2)}|)$ \\
\bottomrule
\end{tabular}}
\end{center}
\vspace{-1.0em}
\end{table}