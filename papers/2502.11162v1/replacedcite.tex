\section{Related Works}
\label{sec:related}

\paragraph{Memorization}

Memorization in neural networks is a well studied field with many established results. ____ proved under different settings that $O(N)$ neurons and parameters are enough to memorize $N$ data points. ____ improved these results and showed that $O(\sqrt{N})$ neurons are enough to memorize $N$ points with a $3$-layer neural networks, although the number of parameters is still $O(N)$.  ____ gave the first sub-linear parameter memorization bound, with $N^{2/3}$ parameters to memorize $N$ points. Finally, ____ proved that memorizing $N$ points can be done using a network with $\tilde{O}(\sqrt{N})$ parameters. This is known to be optimal up to log terms due to VC dimension lower-bounds ____. Note that the width of the memorizing networks in ____ is a universal constant, namely $12$ in ____. Also, note that our results imply that the constructions from ____ cannot achieve optimal robustness

\paragraph{Robust memorization}

Several works proved the existence of networks that memorize robustly using different methods. ____ proved there exists locally Lipschitz classifiers, which implies some form of local robustness, although they did not give specific bounds on the size of the classifier. ____ showed the existence of robust memorization networks through VC dimension arguments. Most closely related to our work is ____, which proves upper and lower bounds for robust memorization. In particular, they show that robust memorization with the optimal robust radius in $l_\infty$ norm (including the constants) cannot be achieved  if the width is smaller than the data dimension. We extend their result by showing the intricate trade-offs between the width of the network and the robustness radius. 

\paragraph{Robustness and width}
Several papers observed empirically that there is a connection between the width of the neural network and its robustness properties. ____ observed that wider networks tend to be more robust, even without adversarial training. ____ study the effect of the width on adversarial training, and provide theoretical justification in the NTK regime ____. Our work focuses on the expressive capacity required for robustness, rather than the optimization process which is studied in these works.