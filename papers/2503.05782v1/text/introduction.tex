\section{Introduction}
\label{sec:introduction}

% --- START (NEW)
% sentence 1. (INTRODUCTION PARAGRAPH) PBL is compelling because fires up people's intrinsic motivation, learn far beyond material covered in class, nurtures autodidactic tendencies

Project-based learning puts students in charge of their own education, giving them the freedom to decide what to learn, what to create, and what success means for them. It is an approach that intends to mimic real life, where answers are not easy to find, and success requires curiosity, critical thinking, and resilience. PBL is frequently used in computer science classes because it encourages students to test their understanding against real-world problems, develop essential project management skills, and explore industry tools and practices outside of the standard classroom curriculum.

% sentence 2. (RELATED WORK PARAGRAPH) BUT PBL is challenging to scale because some students thrive with minimal educator guidance and other flounder. Early evaluation of project proposals can help educators determine which students need more support before stuents run into major issues, yet making this judgement call in may be challenging and time-consuming because it involves reviewing freeform text on arbitary topics, classifying student aptitude based on incomplete knowledge, and depends on the instructor's ability to provide helpful and relevant feedback without overshadowing student motivation for a specific project topic.

However, PBL has shown mixed effectiveness in the classroom, with learning and motivation depending on students' prior ability, educators' ability to support specific projects and topics \citep{Barnes2008:Increasing}, and whether the project idea originated from students or teachers \citep{pucher2011project}. Evaluating project proposals may help educators identify which students require additional guidance or alert educators to major issues that could consume limited motivation, time, and resources. Yet evaluating project proposals is challenging and time-consuming, requiring educators to review freeform text on a broad range of topics and infer student aptitude from incomplete or vague details.

% sentence 3. (SYSTEM DESIGN) IN THIS WORK, we design, build, and conduct user study for using a software system to collect project propsoals and auxiliary information that educators can use to evaulate a student's preparedness to engage with project-based learning.
In this work, we design, implement, and conduct a user study for a software system that collects project proposals and aptitude information that may help educators determine whether a student is ready to engage with PBL. Our design elicits proposals for a high school-level computer science project where students build and design an interactive web application or video game. Our project proposal form asks users to (1) describe a problem they want to work on, (2) propose a solution, (3) recall and analyze design inspirations, (4) predict the effects of their design, (5) plan to evaluate and iterate on their project, (6) describe skills they want to develop, and (7) connect those skills to computer science careers, technical tasks, and popular industry technologies.

% sentence 4. (SYSTEM EVALUTATION) We find that (1) users are excited to use our system to write project proposals and identify tools and technologies to learn more about, (2) users with less experience with the project topic write lower quality project propsoals according to educator ratings, and (3) LLMs' ratings of quality show agreement with educator ratings.
Our preliminary user study ($n=36$) showed our system could engage users' intrinsic motivation, with $88.8\%$ of users wanting to use our system in the future to choose skills and technologies to learn more about, and $91.6\%$ of users wanting to use our system in the future to design project ideas that motivate them to learn more. Two educators and GPT-4o independently graded the quality of each project proposal according to a $29$-item rubric. Educators and GPT-4o showed promising agreement on the relative quality of proposals and tended to give lower quality scores to users with less computer science experience.

% sentence 5. (DISCUSSION) Our work suggests that LLMs have potential to detect issues in students' project proposals. However more work needs to be done to characterize which indicators reliably predict students' success and motivation to learn.
Our findings suggest that LLMs show promise for scaling the automatic grading of project proposals; however, the effectiveness of using LLM grades to guide instructional design decisions hinges on whether project proposals and grading criteria contain information that reliably predicts whether a student can benefit from project-based learning.
% --- END (NEW)

% --- START (NEW)

% --- START (OLD)
%Project Based Learning (PBL) has become a widely used method of instruction in technical subjects like computer science. PBL supports students in exploring tools and methods beyond the classroom curriculum and connecting abstract computer science concepts to meaningful problems. Every iteration of feedback or failure helps students fill gaps in their knowledge and evaluate the trade-offs of different solutions for real-world problems.

%The PBL opportunities are particularly important for novice students who lack professional work experience. These students can leverage their project experience when competing for selective early career opportunities like internships, college admissions, or mentorship programs. Yet, novice students can struggle during the project proposal phase. An inability to draw on domain knowledge can make it difficult for them to assess solutions based on relevant criteria \cite{kirschner2006unguided}, or differentiate between technical projects and creative, non-technical work \citep{PBLWorks}. Teachers thus face the challenge of helping their students success without overshadowing agency and motivation \citep{Barnes2008:Increasing}.

%In this work, we investigate the potential of using large language model (LLMs) to identify early issues in student project proposals. Using an modified project proposal template from Burlington Public High School’s ``CS Pathways Program'' \citep{CSPathway} (more details in section \ref{sec:design}), we collected project proposals and evaluated them using a 29-item rubric. To assess GPT-4o's \citep{hurst2024gpt} ability for detecting issues, we compared its ratings against those made by two teaching assistants using the same rubric.

%Our main contributions include: 

%\begin{enumerate}
    %\item We integrated feedback from teachers to design and implement a tool that assists students in writing project proposals, focusing on analysis, evaluation, prediction, and connecting project skills to careers, tasks, and technologies
    %\item We conducted a user study to assess how students perceive the system and identify areas where they face challenges, and students with less computer science experience struggled more: they wrote down fewer specific computer science skills, struggled to link the skills they wanted to learn to computer science career paths, and produced lower-quality project proposals.
    %\item We found preliminary evidence that GPT-4 is effective detecting issues in the project proposal writing process, and compared its ratings to expert teaching assistants and student self-evaluations.
%\end{enumerate}

%Our preliminary user study ($n=36$) revealed that even with explicit instructions to use the Internet if they needed help, students still struggled to write down specific computer science skills they wanted to learn in their project. Without conducting any prompt-engineering, we found that GPT-4o and two teaching assistants (TA) all rejected $>50\%$ of skills for being vague or irrelevant to computer science technical skills ($>80\%, \kappa > 0.6$)\footnote{agreement percentage between pairs of raters and Cohen's $\kappa$ value}. All three raters judged that students with less computer science experience wrote fewer acceptable skills (on average, all raters accepted 1 out of 3 skills) than students with more computer science experience (on average, all raters accepted 2 out of 3 skills). The low quality of skills written by the students might have made the following activity to connect the skills to careers, tasks, and technologies more challenging to grade. The TAs had a fair inter-agreement rate ($68\%, \kappa=0.25$). GPT-4o showed moderate agreement with TA 1 ($74\%, \kappa=0.46$) and shared a similarly strict $60-62\%$ approval rate for students’ selections of careers, tasks, and technologies. GPT-4o showed fair agreement with TA 2 ($67\%, \kappa=0.20$), who had a $89\%$ approval rate. When grading using a quality checklist, GPT-4o’s scores were lower than TAs' scores and students' self-evalutions on average. Yet, GPT-4o's scores had higher Spearman's rank correlation with TA's scores (Spearman=$0.70$, Spearman=$0.53$) than with TA's scores than students' self-evaluations (Spearman=$0.16$, Spearman=$0.38$).

% --- END (OLD)