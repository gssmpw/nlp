\section{Full Proof and Details of Theorem \ref{thm:convergence}}
\label{sec:convergence-of-the-optimal-policy-proofs}
In this section, we present a complete proof of Theorem~\ref{thm:convergence}, which establishes the convergence of optimal policies after a finite number of rounds. The proof is structured in three parts. First, we introduce and analyze a quantity $c$ that captures the complexity of a given instance. Then, we prove the main theorem using several auxiliary results that characterize the behavior of belief walks and optimal policies. Finally, we provide detailed proof of these auxiliary claims. We conclude the section with an illustrative example showing how optimal belief walks can behave near vertices. Specifically, the example demonstrates why we need to partition vertices into two distinct groups - those that act as stable convergence points and those that can only be temporary stops in the belief walk.


\subsection{Introducing $c$}

Before proving Theorem~\ref{thm:convergence}, we introduce the quantity $c = c(\bm q, \bm P)$. To that end, we define five helpful quantities $c_1, \ldots, c_4$ and use them to define $c$.

\begin{enumerate}
    \item $c_1 = 1 - p_{\max}$ - reflects the maximal amount any user type can like any category and can be used to represent the highest expected social welfare in any belief on the simplex.
    \item $c_2 = \min_{k \in K, m, m' \in M, m \neq m'} \{ \abs{\bm{P}(k, m) - \bm{P}(k, m') } \}$ - can be thought of as a measure of heterogeneity between different user types, as it quantifies the difference in how different user types like the same category.
    \item $c_3 = \min_{m \in M} \{ \max_{k} \bm{P}(k, m)  - \max_{k' \neq k} \bm{P}(k', m) \}$ - quantifies the gap between the favorite and second favorite categories for any user type. It affects the complexity of the recommendation - if this gap is small, it might necessitate more exploration before transitioning to myopic recommendation.
    \item $c_4 = \min_{m \in M} \{ q(m) \}$ - corresponds to "rare" user types that the recommender might need to take their preferences into account.
\end{enumerate}

Finally, we aggregate the above variables into the variable $c$:
\[
c = \min_{i=1, ..., 4} c_i.
\]

For $c_4$ to be larger than $0$, each prior entry should be larger than $0$. This is quite logical - if a user type has zero probability of arriving, it should not affect either the policy or the reward, and we can solve the smaller problem induced by removing its corresponding entries from both $\bm P$ and $\bm q$. 

In contrast to the straightforward justification for positive $c_1$ and $c_4$, the necessity of positive $c_2$ and $c_3$ warrants deeper examination. The condition $c_2 > 0$ rules out situations where various user types display the same preferences across any category. Furthermore, $c_3 > 0$ guarantees that every user type has a distinctly favored category. Although theoretically possible to violate, our convergence outcome relies on these distinctions to facilitate significant belief updates and to ensure that strictly dominant recommendations ultimately arise. The technical implications of these conditions will become apparent in the subsequent proofs, where we demonstrate how they enable both informative Bayesian updates and the eventual transition to pure exploitation. We clearly highlight the necessity of these assumptions and address the implications when they are not present.

It is worth noting that any instance with distinct preferences (DP) - where each entry of the matrix $\bm P$ is distinct - necessarily has $c_2, c_3 \neq 0$. Therefore, if such an instance satisfies the aforementioned logical conditions regarding $c_1$ and $c_4$, then Theorem~\ref{thm:convergence} holds for it. This observation demonstrates the broad applicability of our result to practical scenarios where user preferences exhibit natural variation.

While we have focused on DP instances as a natural example, it is important to emphasize that Theorem~\ref{thm:convergence} holds for any instance where $c > 0$. The DP instances represent a significant subset of such cases, as their structural properties inherently ensure positive values for several components of $c$, but they are by no means exhaustive.

\subsection{Full proof}

\begin{proof}[\normalfont\bfseries Proof of Theorem~\ref{thm:convergence}]

Given a user type $m \in M$ and $\delta > 0$, we say a belief $\bm{b}$ is \emph{$(\delta,m)$-concentrated} if $\bm{b}(m) > 1-\delta$. Typically, the prior $\bm{q}$ is \emph{$c$-unconcentrated}, meaning $\bm{q}(m) < 1-c$ for all $m \in M$, with probability mass distributed across multiple types.

Theorem~\ref{thm:gap-between-value-function} guarantees a strict, positive gap in the optimal value function of two consecutive unconcentrated beliefs in the optimal belief walk. This allows us to derive Corollary~\ref{corr:limited-unconcetrated}, which states that the number of unconcentrated beliefs in the optimal belief walk is finite. It uses potential arguments and the fact that the value function is bounded from above - if there were infinitely many unconcentrated beliefs in the optimal belief walk, then because of the positive gap between them, we would get that the optimal belief walk is unbounded.

Corollary~\ref{corr:limited-unconcetrated} guarantees that the belief walk must eventually reach concentrated beliefs. Our main tool there, Theorem~\ref{thm:myopic-near-boundary} uses the liphshits property of the optimal value function to state that as long as the belief walk remains concentrated near the same type $m$ in the simplex, the optimal policy will continue to recommend the same category $k = \argmax_{k'} \bm P(k',m)$.

At first glance, it seems to be enough - we have shown that the belief walk reaches concentrated beliefs, and as long as it remains concentrated, the recommendation is fixed. We still need to address the following cases:
\begin{enumerate}
    \item \textbf{What if the belief walk returns to unconcentrated beliefs?} Although it might happen, Corollary~\ref{corr:limited-unconcetrated} bounds the number of times it can happen, and therefore, after finitely many returns to unconcentrated beliefs, the belief walk must remain concentrated.
    \item \textbf{What if the belief walk transitions from one concentrated subspace of beliefs that corresponds to a certain type to another subspace of concentrated beliefs?} In this case, Corollary~\ref{corr:limited-unconcetrated} is useless, and the optimal recommendation might change if the types exhibit different preferences. Fortunately, Lemma~\ref{lemma:concentrated-transition} states that this transition is impossible without encountering an unconcentrated belief in between. Now, Corollary~\ref{corr:limited-unconcetrated} is useful - it again bound the number of times this case might happen.
\end{enumerate}

To conclude, after finite $T$ many rounds, the belief walk must remain concentrated near the same type forever. Then, Theorem~\ref{thm:myopic-near-boundary} ensures that the optimal policy will remain fixed.
\end{proof}

\subsection{Proofs of the Auxiliary Claims Used for Proving Theorem~\ref{thm:convergence}}

\begin{proof}[\normalfont\bfseries Proof of Theorem~\ref{thm:gap-between-value-function}]
    Recall that from Observation~\ref{obs:recursive-formula-of-the-value-function} we get that:
    \[
        V^{\star}(\bm{b}) = p_{\pi^{\star}_1(\bm{b})}(\bm{b}) \cdot \left( 1 + V^{\star}(\tau(\bm{b}, \pi^{\star}_1(\bm{b}))) \right) \implies V^{\star}(\tau(\bm{b}, \pi^{\star}_1(\bm{b}))) = \frac{V^{\star}(\bm{b})}{p_{\pi^{\star}_1(\bm{b})}(\bm{b})} - 1.
    \]

    \textbf{Note:} As $\bm P$ is DP, only one entry in each row can be $0$, and since $\bm b$ is $\delta$-unconcentrated, at least two entries in $\bm b$ must be greater than $0$. Therefore, in the sum $p_{\pi^{\star}_1(\bm{b})}(\bm{b}) = \sum_{m \in M} \mathbf{P}(\pi^{\star}_1(\mathbf{b}), m) \cdot \mathbf{b}(m)$, there must be at least one product where both terms are positive. Consequently, $p_{\pi^{\star}_1(\bm{b})}(\bm{b}) > 0$.

    Define $\hat{\pi} = \left( \pi^{\star}_1(\bm{b}) \right)_{i=1}^{\infty}$, the policy that consistently recommends the item $\pi^{\star}_1(\bm{b})$.
    Then:
    \begin{align*}
       V^{\star}(\tau(\mathbf{b}, \pi^{\star}_1(\mathbf{b}))) - V^{\star}(\mathbf{b}) 
       &= \frac{V^{\star}(\mathbf{b})}{p_{\pi^{\star}_1(\mathbf{b})}(\mathbf{b})} - 1 - V^{\star}(\mathbf{b}) \\
       &= \frac{V^{\star}(\mathbf{b}) \left( 1 - p_{\pi^{\star}_1(\mathbf{b})}(\mathbf{b}) \right) - p_{\pi^{\star}_1(\mathbf{b})}(\mathbf{b})}{p_{\pi^{\star}_1(\mathbf{b})}(\mathbf{b})} \\
       &\geq_{(1)} \frac{V^{\hat{\pi}}(\mathbf{b}) \left( 1 - p_{\pi^{\star}_1(\mathbf{b})}(\mathbf{b}) \right) - p_{\pi^{\star}_1(\mathbf{b})}(\mathbf{b})}{p_{\pi^{\star}_1(\mathbf{b})}(\mathbf{b})} \\
       &= \frac{V^{\hat{\pi}}(\mathbf{b})}{p_{\pi^{\star}_1(\mathbf{b})}(\mathbf{b})} - 1 - V^{\hat{\pi}}(\mathbf{b}) \\
       &= V^{\hat{\pi}}(\tau(\mathbf{b}, \pi^{\star}_1(\mathbf{b}))) - V^{\hat{\pi}}(\mathbf{b}) \\
       &= p_{\pi^{\star}_1(\mathbf{b})}(\tau(\mathbf{b}, \pi^{\star}_1(\mathbf{b}))) \cdot \left( 1 + V^{\hat{\pi}}(\tau(\tau(\mathbf{b}, \pi^{\star}_1(\mathbf{b})), \pi^{\star}_1(\mathbf{b}))) \right) \\
       &\quad - p_{\pi^{\star}_1(\mathbf{b})}(\mathbf{b}) \cdot \left( 1 + V^{\hat{\pi}}(\tau(\mathbf{b}, \pi^{\star}_1(\mathbf{b}))) \right) \\
       &\geq_{(2)} \left( p_{\pi^{\star}_1(\mathbf{b})}(\tau(\mathbf{b}, \pi^{\star}_1(\mathbf{b}))) - p_{\pi^{\star}_1(\mathbf{b})}(\mathbf{b}) \right) \cdot \left( 1 + V^{\hat{\pi}}(\tau(\mathbf{b}, \pi^{\star}_1(\mathbf{b}))) \right) \\
       &\geq p_{\pi^{\star}_1(\mathbf{b})}(\tau(\mathbf{b}, \pi^{\star}_1(\mathbf{b}))) - p_{\pi^{\star}_1(\mathbf{b})}(\mathbf{b}),
    \end{align*}
    where:
    \begin{enumerate}
        \item $V^{\star}(\bm{b}) \geq V^{\hat{\pi}}(\bm{b})$ because $\pi^\star$ is optimal and $\left( 1 - p_{\pi^{\star}_1(\bm{b})}(\bm{b}) \right) \geq 0$.
        \item $V^{\hat{\pi}}(\tau(\tau(\bm{b}, \pi^{\star}_1(\bm{b})), \pi^{\star}_1(\bm{b}))) = \sum_{t=1}^{\infty} \prod_{j=1}^{t} p_{\pi^{\star}_1(\bm{b})}(\bm{b}^{\pi^{\star}, \bm{q}}_{j+2}) \geq \sum_{t=1}^{\infty} \prod_{j=1}^{t} p_{\pi^{\star}_1(\bm{b})}(\bm{b}^{\pi^{\star}, \bm{q}}_{j+1}) = V^{\hat{\pi}}(\tau(\bm{b}, \pi^{\star}_1(\bm{b})))$, where the inequality is due to $p_k(\tau(\bm{b}, k)) \geq p_k(\bm{b})$, which will be proven later.
    \end{enumerate}

    To summarize the above steps, we discovered that in order to bound the gap between two consecutive optimal values $V^\star(\bm b), V^\star(\tau(\bm b), \pi^\star_1(b))$ from below, it is enough to bound the expression $p_{\pi^{\star}_1(\bm{b})}(\tau(\bm{b}, \pi^{\star}_1(\bm{b}))) - p_{\pi^{\star}_1(\bm{b})}(\bm{b})$. Let's develop it using Bayesian updates:
    \begin{align*}
       p_{\pi^{\star}_1(\mathbf{b})}(\tau(\mathbf{b}, \pi^{\star}_1(\mathbf{b}))) - p_{\pi^{\star}_1(\mathbf{b})}(\mathbf{b}) 
       &= \sum_{m \in M} \mathbf{P}(\pi^{\star}_1(\mathbf{b}), m) \cdot \tau(\mathbf{b}, \pi^{\star}_1(\mathbf{b}))(m) - \sum_{m \in M} \mathbf{P}(\pi^{\star}_1(\mathbf{b}), m) \cdot \mathbf{b}(m) \\
       &= \sum_{m \in M} \mathbf{P}(\pi^{\star}_1(\mathbf{b}), m) \cdot \frac{\mathbf{P}(\pi^{\star}_1(\mathbf{b}), m) \cdot \mathbf{b}(m)}{\sum_{m' \in M} \mathbf{P}(\pi^{\star}_1(\mathbf{b}), m') \cdot \mathbf{b}(m')} \\
       &\quad - \sum_{m \in M} \mathbf{P}(\pi^{\star}_1(\mathbf{b}), m) \cdot \mathbf{b}(m) \\
       &= \frac{\sum_{m \in M} \mathbf{P}(\pi^{\star}_1(\mathbf{b}), m)^2 \cdot \mathbf{b}(m) - \left( \sum_{m \in M} \mathbf{P}(\pi^{\star}_1(\mathbf{b}), m) \cdot \mathbf{b}(m) \right)^2}{\sum_{m \in M} \mathbf{P}(\pi^{\star}_1(\mathbf{b}), m) \cdot \mathbf{b}(m)}.
    \end{align*}

    Define $X$ to be the following random variable:
    \[
        X = \begin{cases}
              P(\pi^{\star}_1(\bm{b}), m) & \text{with probability } b(m) \quad \forall m \in M . 
        \end{cases}
    \]
    Notice that the numerator of the expression above is the variance of $X$ and the denominator is the expectation of $X$. This proves the claim $p_k(\tau(\bm{b}, k)) \geq p_k(\bm{b})$ which we used earlier, as both of those expressions are non-negative.

    We want to bound away the expression $p_{\pi^{\star}_1(\bm{b})}(\tau(\bm{b}, \pi^{\star}_1(\bm{b}))) - p_{\pi^{\star}_1(\bm{b})}(\bm{b})$ from $0$, and for that, we will use the assumption on $\bm b$ - each entry in $b(m)$ is at most $1 - \delta$. This will help us to bound from below the variance of $X$, as this condition guarantees that $X$ is not all concentrated at a single point.
    The expectation of $X$ is bounded from above by $1 - c$.
    Furthermore, the variance of $X$ can be bounded from below by inserting the mock random variable $\hat{X}$:
    \[
        \hat{X} = \begin{cases}
            0         & \text{with probability } 1 - \delta. \\
            c & \text{with probability } \delta.    
        \end{cases}
    \]
    This will be a lower bound because the distribution of $X$ is more spread out than the distribution of $\hat{X}$ as each entry in $b(m)$ is at most $1 - \delta$, and we defined $c$ to be not bigger than $\min_{k \in K, m, m' \in M, m \neq m'} \{ \abs{\bm{P}(k, m) - \bm{P}(k, m') } \}$, and therefore the distance of the closest entry to the one with the highest mass must be at least of distance $c$.
    The variance of $\hat{X}$ is 
    \[
        \delta \cdot (c^2)- \left( \delta \cdot c \right)^2 = (1 - \delta) \cdot \delta \cdot c^2.
    \]

    In total we find that the expression $p_{\pi^{\star}_1(\bm{b})}(\tau(\bm{b}, \pi^{\star}_1(\bm{b}))) - p_{\pi^{\star}_1(\bm{b})}(\bm{b})$ is at least:
    \[
        \frac{(1 - \delta) \cdot \delta \cdot c^2}{1 - c};
    \]
therefore,
    \[
        V^{\star}(\tau(\bm{b}, \pi^{\star}_1(\bm{b}))) - V^{\star}(\bm{b}) \geq \frac{\delta \cdot (1 - \delta) \cdot c^2}{1 - c}.
    \]
\end{proof}

\paragraph{Note about the definition of $c$} The inequality $0 < c \leq c_2$ plays a crucial role in our analysis, particularly in bounding the variance of the random variable $X$ in Theorem~\ref{thm:gap-between-value-function}. The necessity of maintaining $c_2 > 0$ extends beyond mere technical convenience; it represents a fundamental requirement for the theorem's validity. This condition ensures that each action elicits distinctly differentiated responses across user types, thereby facilitating meaningful Bayesian updates and monotonic growth in potential value. To illustrate the indispensability of this condition, consider a counterexample where an action's corresponding row in matrix $\bm P$ contains identical entries. In such a case, recommendations of this category would fail to modify the prior belief, effectively nullifying the monotonicity property central to our analysis. 

\begin{proof}[\normalfont\bfseries Proof of Corollary~\ref{corr:limited-unconcetrated}]
    Consider the belief walk $(\bm{b}^{\pi^{\star}, \bm{q}}_t)_{t=1}^{\infty}$ induced by the optimal policy $\pi^{\star}$ starting from the prior $\bm{q}$. Let $S$ be the sequence of indices $t$ where $\bm{b}^{\pi^{\star}, \bm{q}}_t$ is $\delta$-unconcentrated. Assume for contradiction that $|S| > H$, and denote $r$ to be the $H+1$'th index in $S$. 
    
    By Theorem~\ref{thm:gap-between-value-function}, each unconcentrated belief in the walk contributes an increase of at least $\frac{\delta \cdot (1 - \delta) \cdot c^2}{(1 - c)}$ to the optimal value function. Therefore, having more than $H$ unconcentrated beliefs would imply that $V^{\star}(\bm{b}^{\pi^{\star}, \bm{q}}_{r+1}) > \frac{1-c}{c}$, contradicting the upper bound on the value function established in Equation~\eqref{eq:bounded-value}.
\end{proof}

\begin{lemma}
    \label{lemma:lipschitz}
    The optimal value function $V^\star$ is Lipschitz continuous with constant $L = \frac{1-c}{c}$.
\end{lemma}

\begin{proof}[\normalfont\bfseries Proof of Lemma~\ref{lemma:lipschitz}]
Let $\bm b, \bm b' \in \Delta(M)$ be two beliefs. Using $|a-b| = max\{a-b, b-a\}$, we have:
\begin{align*}
|V^{\star}(\mathbf{b}) - V^{\star}(\mathbf{b}')| &= \max\{V^{\star}(\mathbf{b}) - V^{\star}(\mathbf{b}'), V^{\star}(\mathbf{b}') - V^{\star}(\mathbf{b})\} \\
&\leq_{(1)} \max\{V^{\pi^{\star}(\mathbf{b})}(\mathbf{b}) - V^{\pi^{\star}(\mathbf{b})}(\mathbf{b}'), V^{\pi^{\star}(\mathbf{b}')}(\mathbf{b}') - V^{\pi^{\star}(\mathbf{b}')}(\mathbf{b})\} \\
&= \max\{\sum_{m \in M} (\mathbf{b}(m) - \mathbf{b}'(m)) \cdot \left( \sum_{t=1}^{\infty} \prod_{i=1}^{t} \mathbf{P}(\pi^\star_i(\mathbf{b}), m) \right), \\
&\quad\quad\quad \sum_{m \in M} (\mathbf{b}'(m) - \mathbf{b}(m)) \cdot \left( \sum_{t=1}^{\infty} \prod_{i=1}^{t} \mathbf{P}(\pi^\star_i(\mathbf{b}'), m) \right)\} \\
&\leq \sum_{m \in M} |\mathbf{b}(m) - \mathbf{b}'(m)| \cdot \left( \sum_{t=1}^{\infty} \prod_{i=1}^{t} p_{\max} \right) \\
&= |\mathbf{b} - \mathbf{b}'|1 \cdot \frac{p_{\max}}{1-p_{\max}} \\
&\leq_{(2)} |\mathbf{b} - \mathbf{b}'|1 \cdot \frac{1-c}{c},
\end{align*}
where:
\begin{enumerate}
    \item $\pi^{\star}(\mathbf{b})$ is optimal for $\bm b$, $\pi^{\star}(\mathbf{b'})$ is optimal for $\bm b'$.
    \item $p{\max} \leq 1 - c \implies \frac{p_{\max}}{1-p_{\max}} \leq \frac{1-c}{c}$.
\end{enumerate}
\end{proof}

\begin{proof}[\normalfont\bfseries Proof of Theorem~\ref{thm:myopic-near-boundary}]
    Let $m \in M$ be a user type, $k = \argmax_{k' \in K} \bm{P}(k', m)$ and $\bm{b} \in \Delta(M)$ such that $\bm b(m) \geq 1 - \frac{c^2}{4}$.

    Denote $\pi^{k} = \left( k \right)_{i=1}^{\infty}$, the policy that always recommends category $k$. Additionally, let some arbitrary policy $\hat{\pi}$ such that $\hat{\pi}(\bm{b})_1 = \hat{k}$ for some $\hat{k} \neq k$. We don't assume anything else about $\hat{\pi}$. We will show that $V^{\pi^k}(\bm{b}) \geq V^{\hat{\pi}}(\bm{b})$ and this will imply that the first recommendation of the optimal policy is $k$.

    Notice that:
    \begin{itemize}
        \item $V^{\pi^k}(\bm{b}) = \sum_{m' \in M} b(m') \cdot \frac{\bm{P}(k, m')}{1 - \bm{P}(k, m')}$ \hfill (due to Lemma~\ref{lemma:closed-form-representations-of-the-value-function}).
        \item $V^{\hat{\pi}}(\bm{b}) = \left( \bm b(m) \cdot \bm{P}(\hat{k}, m) + \sum_{m' \neq m} \bm b(m') \cdot \bm{P}(\hat{k}, m') \right) \cdot \left( 1 + V^{\hat{\pi}[2:]}(\tau(\bm{b}, \hat{k})) \right)$ \hfill (due to Observation~\ref{obs:recursive-formula-of-the-value-function}).
    \end{itemize}
    We will now analyze the relation between $V^{\pi^k}_{L}(\bm{b})$ and $V^{\hat{\pi}}_{U}(\bm{b})$, where $V^{\pi^k}_{L}(\bm{b})$ is a lower bound on $V^{\pi^k}(\bm{b})$ and $V^{\hat{\pi}}_{U}(\bm{b})$ is an upper bound on $V^{\hat{\pi}}(\bm{b})$. We will soon see that $V^{\pi^k}_{L}(\bm{b}) \geq V^{\hat{\pi}}_{U}(\bm{b})$ and this will conclude the proof.

    We define
    \[
        V^{\pi^k}_{L}(\bm{b}) := \left( 1 - \frac{c^2}{4} \right) \cdot \frac{\bm{P}(k, m)}{1 - \bm{P}(k, m)} \overset{\bm b(m) \geq 1 - \frac{c^2}{4}}{\leq} \bm b(m) \cdot \frac{\bm{P}(k, m)}{1 - \bm{P}(k, m)} \leq \sum_{m' \in M} b(m') \cdot \frac{\bm{P}(k, m')}{1 - \bm{P}(k, m')} = V^{\pi^k}(\bm{b}).
    \]

    For constructing the upper bound $V^{\hat{\pi}}_{U}(\bm{b})$, we first note that according to Lemma~\ref{lemma:lipschitz} it holds that:
    \[
        V^{\hat{\pi}[2:]}(\tau(\bm{b}, \hat{k})) \leq V^{\star}(\tau(\bm{b}, \hat{k})) \overset{Lemma~\ref{lemma:lipschitz}}{\leq} V^{\star}(\bm e_m) + \norm{\tau(\bm{b}, \hat{k}) - \bm e_m}_1 \cdot \frac{1-c}{c}.
    \]
    Therefore we can define the upper bound as:
    \begin{align*}
       V^{\hat{\pi}}_{U}(\mathbf{b}) &:= \left( \mathbf{b}(m) \cdot \mathbf{P}(\hat{k}, m) + \sum_{m' \neq m} \mathbf{b}(m') \cdot \mathbf{P}(\hat{k}, m') \right) \cdot \left( 1 + V^\star(\mathbf{e}_m) + \|\tau(\mathbf{b}, \hat{k}) - \mathbf{e}_m\|_1 \cdot \frac{1-c}{c} \right) \\
       &= \left( \mathbf{b}(m) \cdot \mathbf{P}(\hat{k}, m) + \sum_{m' \neq m} \mathbf{b}(m') \cdot \mathbf{P}(\hat{k}, m') \right)
       \cdot \left( \frac{1}{1 - \mathbf{P}(k, m)} + \|\tau(\mathbf{b}, \hat{k}) - \mathbf{e}_m\|_1 \cdot \frac{1-c}{c} \right).
    \end{align*}
    Where the equality is due to $V^{\star}(\bm e_m) = \frac{\bm{P}(k, m)}{1 - \bm{P}(k, m)}$ since $\bm e_m$ is a deterministic belief and therefore recommending the category that is the most liked by the user type $m$ is optimal.    

    The expression $\norm{\tau(\bm{b}, \hat{k}) - \bm e_m}_1$ can be simplified as follows:
    \begin{align*}
       \|\tau(\mathbf{b}, \hat{k}) - \mathbf{e}_m\|_1 
       &= \sum_{m' \in M} |\tau(\mathbf{b}, \hat{k})(m') - \mathbf{e}_m(m')| \\
       &= \left( 1 - \frac{\mathbf{b}(m) \cdot \mathbf{P}(\hat{k}, m)}{\mathbf{b}(m) \cdot \mathbf{P}(\hat{k}, m) + \sum_{m' \neq m} \mathbf{b}(m') \cdot \mathbf{P}(\hat{k}, m')} \right) \\
       &+ \frac{\sum_{m' \neq m} \mathbf{b}(m') \cdot \mathbf{P}(\hat{k}, m')}{\mathbf{b}(m) \cdot \mathbf{P}(\hat{k}, m) + \sum_{m' \neq m} \mathbf{b}(m') \cdot \mathbf{P}(\hat{k}, m')} \\
       &= \frac{2 \cdot \sum_{m' \neq m} \mathbf{b}(m') \cdot \mathbf{P}(\hat{k}, m')}{\mathbf{b}(m) \cdot \mathbf{P}(\hat{k}, m) + \sum_{m' \neq m} \mathbf{b}(m') \cdot \mathbf{P}(\hat{k}, m')}.
    \end{align*}
    Plugging $\norm{\tau(\bm{b}, \hat{k}) - \bm e_m}_1$ into $V^{\hat{\pi}}_{U}(\bm{b})$ yields:
    \begin{align*}
         V^{\hat{\pi}}_{U}(\bm{b}) &= \left( \bm b(m) \cdot \bm{P}(\hat{k}, m) + \sum_{m' \neq m} \bm b(m') \cdot \bm{P}(\hat{k}, m') \right) \\
         &\cdot \left( \frac{1}{1 - \bm{P}(k, m)} + \frac{2 \cdot \sum_{m' \neq m} \bm b(m') \cdot \bm{P}(\hat{k}, m')}{\bm b(m) \cdot \bm{P}(\hat{k}, m) + \sum_{m' \neq m} \bm b(m') \cdot \bm{P}(\hat{k}, m')} \cdot \frac{1-c}{c} \right) \\
         &= \left( \bm b(m) \cdot \bm{P}(\hat{k}, m) + \sum_{m' \neq m} \bm b(m') \cdot \bm{P}(\hat{k}, m') \right) \cdot \left( \frac{1}{1 - \bm{P}(k, m)} \right) \\
         &+ \left( 2 \cdot \sum_{m' \neq m} \bm b(m') \cdot \bm{P}(\hat{k}, m') \right) \cdot \frac{1-c}{c}. \\ 
    \end{align*}
    We again use the fact that $\bm b(m) \geq 1 - \frac{c^2}{4}$ to further bound the expression from above:
    \begin{align*}
        V^{\hat{\pi}}_{U}(\bm{b}) &= \left( \bm b(m) \cdot \bm{P}(\hat{k}, m) + \sum_{m' \neq m} \bm b(m') \cdot \bm{P}(\hat{k}, m') \right) \cdot \left( \frac{1}{1 - \bm{P}(k, m)} \right) \\
        &+ \left( 2 \cdot \sum_{m' \neq m} \bm b(m') \cdot \bm{P}(\hat{k}, m') \right) \cdot \frac{1-c}{c} \\
        &\leq_{(1)} \left( \bm b(m) \cdot \bm{P}(\hat{k}, m) + \frac{c^2}{4} \right) \cdot \left( \frac{1}{1 - \bm{P}(k, m)} \right) + \left( 2 \cdot \frac{c^2}{4} \right) \cdot \frac{1-c}{c} \\
        &\leq_{(2)} \left(\bm{P}(k, m) - c + \frac{c^2}{4} \right) \cdot \left( \frac{1}{1 - \bm{P}(k, m)} \right) + \left( 2 \cdot \frac{c^2}{4} \right) \cdot \frac{1-c}{c} \\
        &= \left(\bm{P}(k, m) - c + \frac{c^2}{4} \right) \cdot \left( \frac{1}{1 - \bm{P}(k, m)} \right) + \frac{c}{2} - \frac{c^2}{2} \\
        &\leq \frac{\bm{P}(k, m) - c + \frac{c^2}{4} + \frac{c (1- \bm P(k, m))}{2}}{1 - \bm{P}(k, m)} \\
        &\leq \frac{\bm{P}(k, m) - c + \frac{c^2}{4} + \frac{c}{2}}{1 - \bm{P}(k, m)} \\
        &= \frac{\bm{P}(k, m) - \frac{c}{2} + \frac{c^2}{4}}{1 - \bm{P}(k, m)} \\
        &\leq \frac{\bm{P}(k, m) - \frac{c}{4}}{1 - \bm{P}(k, m)} \\
        &\leq \frac{\bm{P}(k, m) - \bm{P}(k, m) \frac{c^2}{4}}{1 - \bm{P}(k, m)} \\
        &= \frac{\bm{P}(k, m)}{1 - \bm{P}(k, m)} \cdot \left( 1 - \frac{c^2}{4} \right), \\
    \end{align*}
    Where:
    \begin{enumerate}
        \item $\bm b(m) \geq 1 - \frac{c^2}{4} \implies 1 - \bm b(m) \leq \frac{c^2}{4}$ and $\sum_{m' \neq m} \bm b(m') \cdot \bm{P}(\hat{k}, m') \leq \sum_{m' \neq m} \bm b(m') = 1-\bm b(m) \leq \frac{c^2}{4}$
        \item Since $k = \argmax_{k' \in K} \bm P(k, m)$ we have that $\bm b(m) \cdot \bm{P}(\hat{k}, m) \leq \bm{P}(\hat{k}, m) \leq \bm{P}(k, m) -c$ from the definition of $c$.
    \end{enumerate}
    To summarize, we got that 
    \[
    V^{\pi^k}(\bm b) \geq V^{\pi^k}_{L}(\bm{b}) = \left( 1 - \frac{c^2}{4} \right) \cdot \frac{\bm{P}(k, m)}{1 - \bm{P}(k, m)} \geq V^{\hat{\pi}}_{U}(\bm{b}) \geq V^{\hat{\pi}}(\bm{b}).
    \]
    Therefore, the first category the optimal policy will recommend is $k$, as all of the policies that start with $\hat k \neq k$ are found to be sub-optimal.
\end{proof}

\paragraph{Note about $c_3$ and myopic behavior} The quantity $c_3$ assumes a pivotal role in ensuring the validity of Theorem~\ref{thm:myopic-near-boundary}, particularly in guaranteeing the emergence of a unique optimal recommendation near vertices. The condition $c_3 > 0$ is not merely technical; it ensures that preferences across user types maintain sufficient separation to enable definitive category selection. To understand its necessity, consider what occurs when $c_3 = 0$: this would allow for the existence of a user type whose preferences are identical across multiple categories. In such a scenario, even as our belief concentrates arbitrarily close to the corresponding vertex, we could not distinguish between these equally preferred categories, undermining the theorem's conclusion about convergence to a single optimal action. 

\begin{proof}[\normalfont\bfseries Proof of Lemma~\ref{lemma:concentrated-transition}]
Let $m, m' \in M$ be distinct user types and let $\bm{b}$ be a $(\frac{c^2}{4},m)$-concentrated belief. Let $\bm{b}' = \tau(\bm{b}, \pi^\star_1(\bm b))$ denote the updated belief after recommending the optimal recommendation $\pi^\star_1(\bm b)$. We will show that $\bm{b}'$ cannot be $(\frac{c^2}{4},m')$-concentrated.

By the definition of Bayesian updates, for any user type $\hat{m} \in M$:
\[
   \bm{b}'(\hat{m}) = \tau(\bm{b}, \pi^\star_1(\bm b))(\hat{m}) = \frac{\bm{b}(\hat{m}) \cdot \bm{P}(\pi^\star_1(\bm b), \hat{m})}{\sum_{m'' \in M} \bm{b}(m'') \cdot \bm{P}(\pi^\star_1(\bm b), m'')}.
\]

For the denominator, we can utilize the fact that $\bm{b}$ is $(\frac{c^2}{4},m)$-concentrated:
\[
   \sum_{m'' \in M} \bm{b}(m'') \cdot \bm{P}(\pi^\star_1(\bm b), m'') \geq \bm{b}(m) \cdot \bm{P}(\pi^\star_1(\bm b), m) \geq \left(1 - \frac{c^2}{4}\right) \cdot \bm{P}(\pi^\star_1(\bm b), m).
\]

As $\pi^\star_1(\bm b)$ is the optimal recommendation for $\bm b$, from the definition of $c$ we must have $\bm{P}(\pi^\star_1(\bm b), m') \geq c$. For $m'$, we know that $\bm{b}(m') < \frac{c^2}{4}$ (since $\bm{b}(m) \geq 1 - \frac{c^2}{4}$ and $m \neq m'$). Therefore:
\[
   \bm{b}'(m') = \frac{\bm{b}(m') \cdot \bm{P}(\pi^\star_1(\bm b), m')}{\sum_{m'' \in M} \bm{b}(m'') \cdot \bm{P}(\pi^\star_1(\bm b), m'')} \leq \frac{\frac{c^2}{4} \cdot 1}{\left(1 - \frac{c^2}{4}\right) \cdot c} = \frac{c}{4(1 - \frac{c^2}{4})} = \frac{c}{4 - c^2}.
\]

Now we can use the fact that the function $\frac{c}{4 - c^2}$ is strictly increasing in $[0,1]$ to get that for any $c \in [0,1]$, $\frac{c}{4 - c^2} \leq \frac{1}{3}$. Conversely, the strict decrease of $1 - \frac{c^2}{4}$ in $[0,1]$ implies that for any $c \in [0,1]$, $1 - \frac{c^2}{4} \geq \frac{3}{4}$. Hence, we conclude that $\bm{b}'(m') < 1 - \frac{c^2}{4}$, completing our proof.
\end{proof}

\subsection{Example of moving away from a vertex after starting close to it}

Earlier in this section, we proved Theorem~\ref{thm:myopic-near-boundary}, which argues that when close enough to any vertex of the belief simplex, the optimal single recommendation is the category that is the most liked by the user type that corresponds to the vertex. However, it does not mean that the optimal policy will always recommend the same category for a belief close to a vertex.
Consider the following matrix:
\[
    \bm{P} = \begin{pmatrix}
        0.8 & 0.5 \\
        0.7 & 0.6
    \end{pmatrix}.
\]

For a belief that is close enough to the second user type (corresponding to the second column), the optimal policy will recommend the second category, as this is the preferred category for this user type ($0.6 > 0.5$).
However, notice that the first column is pairwise bigger than the second column.
This means that no matter what category the recommender chooses, the belief will always be updated to be closer to the first user type.
Therefore, after a few steps, the belief will be close enough to the first user type, and the optimal policy will recommend the first category, as this is the preferred category for this user type ($0.8 > 0.7$).
