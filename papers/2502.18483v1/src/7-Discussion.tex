\section{Discussion and Future Work}\label{sec:disc}
We have introduced a model that captures two intertwined challenges: Aggregated user information and the risk of churn. We analyzed the belief walks and showed that the optimal policy must eventually act greedily. We have proposed a lower and upper bound on the optimal social welfare and demonstrated that our B\&B algorithm performs comparably to a state-of-the-art baseline.

We see considerable scope for future work. First, despite the nontrivial analysis, we still lack either a provably optimal polynomial-time algorithm or a formal proof of hardness. Second, future work could model more complex interactions where, e.g., users can dislike a category but continue the user session. In such a case, we can still apply Bayesian updates, but there is no clear notion of belief walks. This forms a technical challenge that is beyond the scope of our current paper (see \apxref{sec:model-extensions} for an elaborated discussion). %Third, another challenge could stem from non-stationary preferences. Namely, if the matrix $\bm P$ changes over time or depends on the history of recommendations in the current session. 
Third, another challenge could stem from non-stationary preferences, namely if the matrix $\bm P$ changes over time or depends on the history of recommendations in the current session. 
Exploring these directions will further reveal how to effectively navigate the balance between exploration and exploitation in the face of aggregated user information. 



% \paragraph{Future work}

% \begin{itemize}
%     \item More complex interactions, such as positive probability of remaining in the system after a negative feedback. This fits well within a traditional POMDP framework, making solvers a viable option. There might be other characteristics in this context to take advantage of.
%     \item Evolving preferences. Various studies investigate the changing preferences of users, which adapt during interactions with the recommendations. This contrasts with the Bayesian update performed in our work, as affects the actual user type rather than the system's belief. If the transitions between types are fully known to the recommender we can simply adjust the Bayesian update to take it into account; alternatively, more advanced methods like DeepRL and similar techniques might be required to approximate optimal behavior in this system.
% \end{itemize}
