\section{Related Work}

In recent years, both news organisations and educational institutions have proactively developed policies to guide the ethical and effective use of artificial intelligence (AI) within their respective domains. 

%%%%%%%% NEWS %%%%%%%%
\textit{\textbf{News Organisations.}}
With the wide uptake of AI, news organisations have been impacted by the use and availability of AI models and systems, requiring them to create clear guidelines and policies on how to use this new technology \cite{simon2023ai}.
%
A comprehensive analysis of 52 news organisations across various countries reveals a concerted effort to address AI's implications on journalistic integrity, transparency, and accountability \cite{simon2023policies}.
%
Previous work has compared the transparency provisions in the European Union's AI Act, particularly Article 50, and their alignment with news readers' expectations \cite{piasecki2024ai}. Similar to our findings, the study highlights the necessity for clear disclosure when AI systems contribute to news content, as transparency is crucial for maintaining reader trust. 
%
\citet{de2022artificial} explore the current perceptions and future outlook of AI in news media, identifying key areas where AI technologies are being adopted, such as machine learning, computer vision, and natural language processing. While they find potential benefits of AI in enhancing news production and distribution, they also caution against challenges related to editorial standards and public trust.
%
In the context of visual AI in news organisations, \citet{thomson2024generative} emphasise the importance of clear guidelines to ensure clear boundaries between human-created and AI-generated images.
%

%%%%%%%% EDUCATION %%%%%%%%
\textit{\textbf{Education.}}
The uptake of AI technologies also impacts educational Institutions, such as universities.
%
Studies point out a set of challenges with the use of ChatGPT in the educational institutions such as the misuse of ChatGPT to trick online exams \cite{susnjak2024chatgpt}; the higher correct answer rate on exams with the improvement of AI technologies \cite{de2023can}; the integration of generative AI technologies into engineering education given the limitations of the training data quality \cite{qadir2023engineering}; superficial or inaccurate responses, potentially misleading students and the risk of bias and discrimination \cite{farrokhnia2024swot}.

%
Hence, educational institutions are also actively formulating AI policies to navigate the integration of AI in academic settings. The 2024 EDUCAUSE Action Plan\footnote{\url{https://www.educause.edu/research/2024/2024-educause-action-plan-ai-policies-and-guidelines}} and UNESCO \cite{holmes2023guidance} outline comprehensive guidelines for AI adoption in higher education, both focusing on ethical considerations and the impact on teaching and learning practices.
%
\citet{ghimire2024guidelines} conducted a survey of academic institutions, such as high schools, to collect information on current policies w.r.t. generative AI. This study gives an insight into the current lack of AI policies in many education institutions in the US. 
%
\citet{slimi2023navigating} emphasise the importance of stakeholders working together to develop AI policies in the education space.
%
A set of studies have focused on the perspective of educators \cite{pischetola2024desirable}, proposing policy implications based on a survey of teachers \cite{chiu2023impact}.
%
%Based on a survey of teachers, \citet{chiu2023impact} proposes three implications for policy: new assessment, AI education, and professional standards. 
%
\citet{dotan2024responsible} propose a ``points to consider'' approach for the responsible adoption of generative AI in higher education, emphasising alignment of AI integration with the unique goals, values, and structural features of higher education institutions.
%


%%%%%%%% EU %%%%%%%%
\textit{\textbf{EU AI Act.}} \aia is the first attempt at a comprehensive international regulation of AI, but %Despite the aspiration to address concerns of data governance, discrimination, and bias, 
many important details are yet to be clarified in the \aia. Given the dynamic nature of AI development, the legislation will need updating over time \cite{cantero2024artificial}.
\citet{cantero2024artificial} highlight the critical role of standards in the \aia's co-regulation strategy, emphasising the need for reform to keep pace with the rapid evolution of AI technologies. 
Scholars have raised multiple concerns about the Act's approach, e.g., arguing that the EU conflates trustworthiness with the acceptability of risk \cite{laux2024trustworthy} and identifying limitations and loopholes in the \aia and related liability directives \cite{wachter2024limitations}. 
\citet{wachter2024limitations} criticise the \aia’s reliance on disclosure rather than substantive requirements, expressing concern that transparency and reporting alone will not adequately tackle systemic risks and societal harms. The legislation’s provisions on environmental impact also stop short of requiring actual reductions in energy consumption. Although the Act takes promising steps toward accountability, it falls short on deeper questions of fairness, acceptable risk, and enforceable standards. 
%
%The European Union introduced the \aia to establish a comprehensive framework for regulating AI technologies. The \aia categorises AI applications based on their risk levels and sets forth obligations for providers and deployers corresponding to these categories. 
%

These critiques underscore the importance of analysing gaps in the \aia and pointing out possible improvements for future iterations, which is the purpose of this work. While previous studies have described organisational policies or analysed the gaps in the \aia, to the best of our knowledge, this is the first attempt to inform analysis of the gaps in the \aia by the existing and practically tested organisational policies as well as issues identified in academic research.\looseness=-1