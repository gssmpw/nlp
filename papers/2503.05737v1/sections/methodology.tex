\section{Methodology}
\label{sec:method}
%In this section, we describe the methodology of selecting organisations from the news and university domains (\S\ref{sec:method:selection}). We then describe the inductive coding method and categories used to summarise the similarities and differences in the reviewed organisational policies (\S\ref{sec:method:coding}).

\begin{table}[t]
\footnotesize

\begin{tabular}{p{2.6cm}p{11.5cm}}
\toprule
\textbf{Code} & \textbf{Description}\\
\midrule 
\multicolumn{2}{c}{\textbf{Suggested Uses}} \\
Illustrations/Graphics & \newspaper Using AI to generate illustrations and graphics for publication.\\
Image generation &  \newspaper Using AI to generate photorealistic images, \student visuals, diagrams, or other graphical representations.\\
Article generation &  \newspaper Using AI to generate long texts to be published as (part of) articles.\\
Data analysis & \newspaper Using AI to process, sort, and analyse large amounts of data.\\
Language tool &  \newspaper \student Using AI as a language assistant, e.g., for grammar and spelling checks, language proofreading, and rephrasing.\looseness=-1 \\
Transcription/Translation & \newspaper Transcription of, e.g., interviews and \student translating content between languages. \\ % , aiding accessibility and providing multilingual support for academic activities
Ideas (Content) &  \newspaper Using AI for headlines, backgrounds, story ideas or sources to be approached.\\
Ideas (Marketing) & \newspaper Using AI for generating ideas for marketing campaigns.\\
Ideas (University) & \student Using AI to brainstorm and generate ideas, e.g., for project planning and curriculum development.\\ 
Content moderation &  \newspaper Using AI to filter spam, hate speech and fake news on social media or website comments.\\
Self-learning      & \student Supporting students' independent learning by providing alternative perspectives or personalised study plans\\ 
Course design      &  \student Generating learning objectives, developing rubrics, creating assessments, drafting assignments, and preparing teaching materials such as presentations and quizzes.\\ 
Personalisation    & \student Adapting content to students' individual needs, levels, and preferences. \\ % This can enhance accessibility and inclusivity, particularly for students with specific learning challenges or disabilities.
Coding             & \student Providing tools for debugging, understanding coding concepts, breaking down problems, and generating code snippets. Offer feedback on code quality and structure.\\
Topic knowledge    & \student  Explain concepts, simulate discussions, provide examples, or suggest further reading materials.\\ % Enhancing understanding of academic topics by using AI to e
Feedback           & \student Provide targeted feedback on academic work, including essays, projects, and coding assignments. Identify areas for improvement, suggest revisions, and help students refine their submissions.\\
Summarisation      &\student Condense academic texts, lecture notes, or research articles.\\ %  making it easier for students to grasp key points and manage large volumes of information.
Assessment         & \student Help with assessment of student assignments.\\
Search             & \student Find relevant academic resources, explore topics, conduct preliminary research, guide literature reviews by summarising key findings and highlighting important sources. \\

\midrule
\multicolumn{2}{c}{\textbf{Issued Warning and Rules}} \\
Human oversight &  \newspaper \student Ensuring that generated outputs are critically reviewed by a human for accuracy, relevance, and appropriateness of the content. Avoiding full reliance on AI for decision-making or content generation.\\
Declaration of use & \newspaper \student Disclosing the use of AI tools. \\
Document AI use & \newspaper Recording all AI use and experiments in an internal register or otherwise document its use in the newsroom. \\
% This transparency helps maintain academic integrity and ensures that AI's role in the work is appropriately acknowledged.
Factual accuracy & \newspaper\student Advising users to cross-check generated outputs against reliable sources to prevent factual inaccuracies or fabricated information.\\
Bias in AI & \newspaper \student Encouraging users to recognise and mitigate biased/discriminatory outputs when interpreting or using generated content.\\
Privacy and sensitive data & \newspaper \student Advising against inputting personal, confidential, or sensitive information into AI tools, particularly those without organisation-approved licenses. \\ % This rule aims to protect user privacy and data security, as well as comply with data protection regulations.
Copyright & \newspaper \student Cautioning users about the copyright status of both generated content and input data. Users must avoid infringing intellectual property rights and ensure proper attribution where required.\\
AI literacy training &  \newspaper \student Organisational employees need to improve their understanding of AI tools, including their limitations, ethical considerations, and effective usage. \\ % This prepares users to interact with AI responsibly and efficiently.
% AI literacy training (University)   & \student \\
% AI literacy training (Teacher)   & \student \\
No prioritisation  & \student Ensuring that AI tools do not unfairly prioritise certain content, viewpoints, or outputs. 
\\ % This rule encourages neutrality and balance in the use of AI systems in educational settings.

Knowledge cut-off  & \student Warning that AI systems may have outdated knowledge due to their training data's temporal limitations. \\
Persuasiveness     & \student Warning that generated content may appear fluent and convincing, even when it is incorrect or nonsensical. \\ % Users are advised to evaluate outputs critically.
Source attribution & \student Warning that generated content does not reference its sources, which could lead to plagiarism issues.\\
Digital inequity   & \student Raising awareness about potentially unequal access/utilisation of AI tools among students or institutions. \\ % , potentially exacerbating socio-economic disparities. Policies aim to ensure equitable access to AI resources. 
Skills assessment     &  \student Warning that AI use might obscure a student’s true abilities.\\ % Emphasizing the need for assessments to evaluate actual skills and knowledge acquired by students, as 
Environment        & \student Raising awareness about the environmental impact of using AI tools, which require significant computational resources and contribute to carbon emissions. \\
Teacher load & \student Recognising the potential increase in workload for educators due to the need to monitor, evaluate, and guide AI use in educational settings, as well as address misuse or quality issues.\\  
\bottomrule
\end{tabular}
\caption{Codes used for annotating the policies of news organisations \newspaper and universities \student. }
\label{tab:coding}
\end{table}


\subsection{Selection of Organisational Policies for Analysis}
\label{sec:method:selection}
\textbf{\textit{News Policies.}}
%
We select 10 news outlets with publicly available policies on generative AI use from across the EU, Switzerland, and the UK, based on \cite{simon2023policies} and \cite{mediumauthor2023guidelines}, which list news organisations' policies. We select from this list the following news outlets by their online availability and under the criteria that they are based in Europe: The Guardian (UK), ANP (Netherlands), Mediahuis (Belgium/Netherlands), Norwegian Tabloid VG (Norway), Le Parisien (France), Financial Times (FT, UK), Süddeutsche Zeitung (SZ, Germany), Der Spiegel (Germany), Ringier (Switzerland) and the BBC (UK). We translate each of the policies into English using Google Translate if they are not available in English. 
We access the latest version of the guidelines, which is documented along with the links to the policies in App., Table \ref{table-app-news-links}. 

\textbf{\textit{University Policies.}} We select 10 universities from across the EU, choosing one top-ranked university from each country\footnote{\url{https://www.topuniversities.com/europe-university-rankings}} which has publicly available guidelines on generative AI use. The selected institutions include: the Technical University of Munich (TUM, Germany), Delft University of Technology (TU Delft, Netherlands), KTH Royal Institute of Technology (KTH, Sweden), Aalto University (Aalto, Finland), Technical University of Denmark (DTU, Denmark), KU Leuven (KUL, Belgium), Swiss Federal Institute of Technology Zurich (ETH, Switzerland), Charles University (CUNI, Czech Republic), University of Vienna (Vie, Austria), University of Lisbon (UdL, Portugal), University of Oslo (UiO, Norway). To reach our target number of ten universities, we checked 27 in total, discarding 17 that did not have public guidelines (six universities from France, three from Spain, two from Sweden, two from Denmark, two from Italy, one from Finland, and one from Switzerland). The guidelines for Vie, UiO, KUL have been automatically translated. We access the latest version of the guidelines, which is documented along with the links to the policies in App., Table \ref{table-app-uni-links}. 
%
\subsection{Coding of Organisational Policies}
\label{sec:method:coding}
% table with breakdown of codes, their definition, etc
Given the set of policies in the news organisations and universities described above,  we perform iterative coding of these policies. From the identified categories in these policies, we focus on those mentioned by at least two organisations within the same domain. Additionally, we discuss points raised by individual organisations in sections \S\ref{sec:policies:news} and \S\ref{sec:policies:uni}. Where possible, we merge the codes identified across the two domains. 

Table \ref{tab:coding} outlines the resulting codes and their definitions in the respective domain. The codes are grouped into two broad categories: suggested uses of AI within the domain and warnings or rules/requirements related to its use. We use the \use\ symbol to denote a category that the organisation listed as a suggested use. Among the suggested uses, some organisations apply certain restrictions, e.g. limiting the scenarios or issuing a particular prompt to use. We denote such cases we denote with \lock. Furthermore, organisations provide lists of warnings about potential challenges and risks connected with AI use, which we denote as \risk. Finally, organisations also issue rules and requirements for using AI tools, such as declarations of use, which we denote as \rules. 

% From Table \ref{tab:coding}, the suggested applications of AI largely differ between the two domains, but the warnings and rules associated with its use in news organisations also appear in university policies. However, universities include additional warnings and rules, either specific to their domain (e.g., assessment of knowledge) or not mentioned in the policies of news organisations (e.g., environment).

%This divergence may indicate gaps in the warnings and rules applied across domains, as is the case with the policies of news organisations in our study. These findings suggest that organisational policies could benefit from systematic cross-domain comparisons or the development of a high-level reference framework to guide different organisations in formulating comprehensive AI policies.