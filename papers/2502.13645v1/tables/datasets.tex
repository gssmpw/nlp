\begin{table*}[t]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{@{}lcccccccc@{}}
\toprule
\textbf{Task} & \makecell[c]{\textbf{Dataset} \\ \textbf{Source}} & \textbf{Task Type} & \makecell[c]{\textbf{Granularity} \\ \textbf{Level}} & \textbf{Domains} & \makecell[c]{\textbf{Evaluation} \\ \textbf{Metrics}} & \makecell[c]{\textbf{\#} \\ \textbf{Transcripts}} & \makecell[c]{\textbf{\#} \\ \textbf{Instances}} & \makecell[c]{\textbf{\# Utts. in Inst.} \\ \textbf{Avg. (min - max)}} \\
\midrule
\makecell[l]{Summarization\\(Generic + Query Focused)} & QMSum & Generation & Transcript & \makecell[c]{Product, Research, \\Parliament meetings} & \makecell[c]{Pairwise Ranking, \\ROUGE-1,2,L} & \makecell[c]{35} & \makecell[c]{281} & \makecell[c]{592 \\ (131 - 1368)} \\
\midrule
Question Answering & QAConv & Extraction & Transcript & \makecell[c]{Court cases, \\ Interviews} & \makecell[c]{Fuzzy match, Exact,\\ Token-level $F_1$} & \makecell[c]{505} & \makecell[c]{2083} & \makecell[c]{104 \\ (5 - 585)} \\
\midrule
Dialog Act Classification & MRDA & Classification & Utterance & Research meetings & Macro-$F_1$, Accuracy & \makecell[c]{12} & \makecell[c]{1200} & \makecell[c]{1} \\
\bottomrule
\end{tabular}%
}
\caption{The test data with which we conduct our experiments, with varying input/output formats and speech domains.
%for three tasks with varying input and output formats, and speech domains. We only use a portion of the QAConv and MRDA original data to cater to our setting of long spoken dialog, and for efficiency purposes. These are only test sets since our task models (Mistral, Llama-3, Llama-3.1, GPT-4o-mini) are executed in zero-shot mode, and no training or validation is required in our experiments.
%The \# of instances depends on the task: queries for summarization, questions for QA, and utterances for dialog-act classification.
\textit{\# Instances} refers to queries for summarization, questions for QA, and utterances for dialog-act classification.}
% utternace segments for DAC
\label{tab_datasets}
\end{table*}