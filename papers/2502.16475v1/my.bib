@article{fischer2023boosting,
  title={Boosting Latent Diffusion with Flow Matching},
  author={Fischer, Johannes S and Gui, Ming and Ma, Pingchuan and Stracke, Nick and Baumann, Stefan A and Ommer, Bj{\"o}rn},
  journal={arXiv preprint arXiv:2312.07360},
  year={2023}
}
@inproceedings{peebles2023scalable,
  title={Scalable diffusion models with transformers},
  author={Peebles, William and Xie, Saining},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={4195--4205},
  year={2023}
}
@article{deng2024detailgen3d,
  title={DetailGen3D: Generative 3D Geometry Enhancement via Data-Dependent Flow},
  author={Deng, Ken and Guo, Yuanchen and Sun, Jingxiang and Zou, Zixin and Li, Yangguang and Cai, Xin and Cao, Yanpei and Liu, Yebin and Liang, Ding},
  journal={arXiv preprint arXiv:2411.16820},
  year={2024}
}
@article{zhang20233dshape2vecset,
  title={3dshape2vecset: A 3d shape representation for neural fields and generative diffusion models},
  author={Zhang, Biao and Tang, Jiapeng and Niessner, Matthias and Wonka, Peter},
  journal={ACM Transactions on Graphics (TOG)},
  volume={42},
  number={4},
  pages={1--16},
  year={2023},
  publisher={ACM New York, NY, USA}
}
@article{zhang20223dilg,
  title={3dilg: Irregular latent grids for 3d generative modeling},
  author={Zhang, Biao and Nie{\ss}ner, Matthias and Wonka, Peter},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={21871--21885},
  year={2022}
}
@article{oquab2023dinov2,
  title={Dinov2: Learning robust visual features without supervision},
  author={Oquab, Maxime and Darcet, Timoth{\'e}e and Moutakanni, Th{\'e}o and Vo, Huy and Szafraniec, Marc and Khalidov, Vasil and Fernandez, Pierre and Haziza, Daniel and Massa, Francisco and El-Nouby, Alaaeldin and others},
  journal={arXiv preprint arXiv:2304.07193},
  year={2023}
}
@article{liu2022flow,
  title={Flow straight and fast: Learning to generate and transfer data with rectified flow},
  author={Liu, Xingchao and Gong, Chengyue and Liu, Qiang},
  journal={arXiv preprint arXiv:2209.03003},
  year={2022}
}
@article{lipman2022flow,
  title={Flow matching for generative modeling},
  author={Lipman, Yaron and Chen, Ricky TQ and Ben-Hamu, Heli and Nickel, Maximilian and Le, Matt},
  journal={arXiv preprint arXiv:2210.02747},
  year={2022}
}
@article{qiu2023richdreamer,
    title={RichDreamer: A Generalizable Normal-Depth Diffusion Model for Detail Richness in Text-to-3D}, 
    author={Lingteng Qiu and Guanying Chen and Xiaodong Gu and Qi zuo and Mutian Xu and Yushuang Wu and Weihao Yuan and Zilong Dong and Liefeng Bo and Xiaoguang Han},
    year={2023},
    journal = {arXiv preprint arXiv:2311.16918}
}
@inproceedings{zuo2024sparse3d,
     title={High-Fidelity 3D Textured Shapes Generation by Sparse Encoding and Adversarial Decoding},
     author={Zuo, Qi and Gu, Xiaodong and Dong, Yuan and Zhao, Zhengyi and Yuan, Weihao and Qiu, Lingteng and Bo, Liefeng and Dong, Zilong},
     booktitle={European Conference on Computer Vision},
     year={2024}
     }
@article{objaverse,
    title={Objaverse: A Universe of Annotated 3D Objects},
    author={Matt Deitke and Dustin Schwenk and Jordi Salvador and Luca Weihs and
            Oscar Michel and Eli VanderBilt and Ludwig Schmidt and
            Kiana Ehsani and Aniruddha Kembhavi and Ali Farhadi},
    journal={arXiv preprint arXiv:2212.08051},
    year={2022}
}
@inproceedings{zou2024triplane,
  title={Triplane meets gaussian splatting: Fast and generalizable single-view 3d reconstruction with transformers},
  author={Zou, Zi-Xin and Yu, Zhipeng and Guo, Yuan-Chen and Li, Yangguang and Liang, Ding and Cao, Yan-Pei and Zhang, Song-Hai},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10324--10335},
  year={2024}
}
@inproceedings{chen2025lara,
  title={Lara: Efficient large-baseline radiance fields},
  author={Chen, Anpei and Xu, Haofei and Esposito, Stefano and Tang, Siyu and Geiger, Andreas},
  booktitle={European Conference on Computer Vision},
  pages={338--355},
  year={2025},
  organization={Springer}
}
@inproceedings{tang2025lgm,
  title={Lgm: Large multi-view gaussian model for high-resolution 3d content creation},
  author={Tang, Jiaxiang and Chen, Zhaoxi and Chen, Xiaokang and Wang, Tengfei and Zeng, Gang and Liu, Ziwei},
  booktitle={European Conference on Computer Vision},
  pages={1--18},
  year={2025},
  organization={Springer}
}
@inproceedings{rombach2022high,
  title={High-resolution image synthesis with latent diffusion models},
  author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={10684--10695},
  year={2022}
}
@article{mildenhall2021nerf,
  title={Nerf: Representing scenes as neural radiance fields for view synthesis},
  author={Mildenhall, Ben and Srinivasan, Pratul P and Tancik, Matthew and Barron, Jonathan T and Ramamoorthi, Ravi and Ng, Ren},
  journal={Communications of the ACM},
  volume={65},
  number={1},
  pages={99--106},
  year={2021},
  publisher={ACM New York, NY, USA}
}
@inproceedings{barron2022mip,
  title={Mip-nerf 360: Unbounded anti-aliased neural radiance fields},
  author={Barron, Jonathan T and Mildenhall, Ben and Verbin, Dor and Srinivasan, Pratul P and Hedman, Peter},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={5470--5479},
  year={2022}
}
@inproceedings{barron2021mip,
  title={Mip-nerf: A multiscale representation for anti-aliasing neural radiance fields},
  author={Barron, Jonathan T and Mildenhall, Ben and Tancik, Matthew and Hedman, Peter and Martin-Brualla, Ricardo and Srinivasan, Pratul P},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={5855--5864},
  year={2021}
}
@inproceedings{barron2023zip,
  title={Zip-nerf: Anti-aliased grid-based neural radiance fields},
  author={Barron, Jonathan T and Mildenhall, Ben and Verbin, Dor and Srinivasan, Pratul P and Hedman, Peter},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={19697--19705},
  year={2023}
}
@article{muller2022instant,
  title={Instant neural graphics primitives with a multiresolution hash encoding},
  author={M{\"u}ller, Thomas and Evans, Alex and Schied, Christoph and Keller, Alexander},
  journal={ACM transactions on graphics (TOG)},
  volume={41},
  number={4},
  pages={1--15},
  year={2022},
  publisher={ACM New York, NY, USA}
}
@article{hedman2021snerg,
    title={Baking Neural Radiance Fields for
           Real-Time View Synthesis},
    author={Peter Hedman and Pratul P. Srinivasan and
            Ben Mildenhall and Jonathan T. Barron and
            Paul Debevec},
    journal={ICCV},
    year={2021}
}
@inproceedings{fridovich2022plenoxels,
  title={Plenoxels: Radiance fields without neural networks},
  author={Fridovich-Keil, Sara and Yu, Alex and Tancik, Matthew and Chen, Qinhong and Recht, Benjamin and Kanazawa, Angjoo},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={5501--5510},
  year={2022}
}
@inproceedings{SunSC22,
  author    = {Cheng Sun and Min Sun and Hwann{-}Tzong Chen},
  title     = {Direct Voxel Grid Optimization: Super-fast Convergence for Radiance Fields Reconstruction},
  booktitle = {CVPR},
  year      = {2022},
}
@inproceedings{wang2021ibrnet,
  title={Ibrnet: Learning multi-view image-based rendering},
  author={Wang, Qianqian and Wang, Zhicheng and Genova, Kyle and Srinivasan, Pratul P and Zhou, Howard and Barron, Jonathan T and Martin-Brualla, Ricardo and Snavely, Noah and Funkhouser, Thomas},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={4690--4699},
  year={2021}
}
@inproceedings{chen2021mvsnerf,
  title={Mvsnerf: Fast generalizable radiance field reconstruction from multi-view stereo},
  author={Chen, Anpei and Xu, Zexiang and Zhao, Fuqiang and Zhang, Xiaoshuai and Xiang, Fanbo and Yu, Jingyi and Su, Hao},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={14124--14133},
  year={2021}
}
@inproceedings{yu2021pixelnerf,
  title={pixelnerf: Neural radiance fields from one or few images},
  author={Yu, Alex and Ye, Vickie and Tancik, Matthew and Kanazawa, Angjoo},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={4578--4587},
  year={2021}
}
@inproceedings{johari2022geonerf,
  title={Geonerf: Generalizing nerf with geometry priors},
  author={Johari, Mohammad Mahdi and Lepoittevin, Yann and Fleuret, Fran{\c{c}}ois},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18365--18375},
  year={2022}
}
@Article{kerbl3Dgaussians,
      author       = {Kerbl, Bernhard and Kopanas, Georgios and Leimk{\"u}hler, Thomas and Drettakis, George},
      title        = {3D Gaussian Splatting for Real-Time Radiance Field Rendering},
      journal      = {ACM Transactions on Graphics},
      number       = {4},
      volume       = {42},
      month        = {July},
      year         = {2023},
      url          = {https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/}
}
@inproceedings{lu2024scaffold,
  title={Scaffold-gs: Structured 3d gaussians for view-adaptive rendering},
  author={Lu, Tao and Yu, Mulin and Xu, Linning and Xiangli, Yuanbo and Wang, Limin and Lin, Dahua and Dai, Bo},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={20654--20664},
  year={2024}
}
@article{zhang2024rade,
  title={RaDe-GS: Rasterizing Depth in Gaussian Splatting},
  author={Zhang, Baowen and Fang, Chuan and Shrestha, Rakesh and Liang, Yixun and Long, Xiaoxiao and Tan, Ping},
  journal={arXiv preprint arXiv:2406.01467},
  year={2024}
}
@inproceedings{yu2024mip,
  title={Mip-splatting: Alias-free 3d gaussian splatting},
  author={Yu, Zehao and Chen, Anpei and Huang, Binbin and Sattler, Torsten and Geiger, Andreas},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={19447--19456},
  year={2024}
}
@inproceedings{zhang2024pixelgs,
  title     = {Pixel-GS: Density Control with Pixel-aware Gradient for 3D Gaussian Splatting},
  author    = {Zhang, Zheng and Hu, Wenbo and Lao, Yixing and He, Tong and Zhao, Hengshuang},
  booktitle = {ECCV},
  year      = {2024}
}
@article{Yu2024GOF,
  author    = {Yu, Zehao and Sattler, Torsten and Geiger, Andreas},
  title     = {Gaussian Opacity Fields: Efficient Adaptive Surface Reconstruction in Unbounded Scenes},
  journal   = {ACM Transactions on Graphics},
  year      = {2024},
}
@inproceedings{huang20242d,
  title={2d gaussian splatting for geometrically accurate radiance fields},
  author={Huang, Binbin and Yu, Zehao and Chen, Anpei and Geiger, Andreas and Gao, Shenghua},
  booktitle={ACM SIGGRAPH 2024 Conference Papers},
  pages={1--11},
  year={2024}
}

%2d diffusion
@article{saharia2022photorealistic,
  title={Photorealistic text-to-image diffusion models with deep language understanding},
  author={Saharia, Chitwan and Chan, William and Saxena, Saurabh and Li, Lala and Whang, Jay and Denton, Emily L and Ghasemipour, Kamyar and Gontijo Lopes, Raphael and Karagol Ayan, Burcu and Salimans, Tim and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={36479--36494},
  year={2022}
}
@article{betker2023improving,
  title={Improving image generation with better captions},
  author={Betker, James and Goh, Gabriel and Jing, Li and Brooks, Tim and Wang, Jianfeng and Li, Linjie and Ouyang, Long and Zhuang, Juntang and Lee, Joyce and Guo, Yufei and others},
  journal={Computer Science. https://cdn. openai. com/papers/dall-e-3. pdf},
  volume={2},
  number={3},
  pages={8},
  year={2023}
}
@inproceedings{liu2023zero,
  title={Zero-1-to-3: Zero-shot one image to 3d object},
  author={Liu, Ruoshi and Wu, Rundi and Van Hoorick, Basile and Tokmakov, Pavel and Zakharov, Sergey and Vondrick, Carl},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={9298--9309},
  year={2023}
}
@article{shi2023mvdream,
  title={Mvdream: Multi-view diffusion for 3d generation},
  author={Shi, Yichun and Wang, Peng and Ye, Jianglong and Long, Mai and Li, Kejie and Yang, Xiao},
  journal={arXiv preprint arXiv:2308.16512},
  year={2023}
}
@article{wang2023imagedream,
  title={Imagedream: Image-prompt multi-view diffusion for 3d generation},
  author={Wang, Peng and Shi, Yichun},
  journal={arXiv preprint arXiv:2312.02201},
  year={2023}
}
@article{shi2023zero123++,
  title={Zero123++: a single image to consistent multi-view diffusion base model},
  author={Shi, Ruoxi and Chen, Hansheng and Zhang, Zhuoyang and Liu, Minghua and Xu, Chao and Wei, Xinyue and Chen, Linghao and Zeng, Chong and Su, Hao},
  journal={arXiv preprint arXiv:2310.15110},
  year={2023}
}
@article{li2023sweetdreamer,
  title={Sweetdreamer: Aligning geometric priors in 2d diffusion for consistent text-to-3d},
  author={Li, Weiyu and Chen, Rui and Chen, Xuelin and Tan, Ping},
  journal={arXiv preprint arXiv:2310.02596},
  year={2023}
}
@inproceedings{long2024wonder3d,
  title={Wonder3d: Single image to 3d using cross-domain diffusion},
  author={Long, Xiaoxiao and Guo, Yuan-Chen and Lin, Cheng and Liu, Yuan and Dou, Zhiyang and Liu, Lingjie and Ma, Yuexin and Zhang, Song-Hai and Habermann, Marc and Theobalt, Christian and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9970--9980},
  year={2024}
}
@inproceedings{tang2025mvdiffusion++,
  title={Mvdiffusion++: A dense high-resolution multi-view diffusion model for single or sparse-view 3d object reconstruction},
  author={Tang, Shitao and Chen, Jiacheng and Wang, Dilin and Tang, Chengzhou and Zhang, Fuyang and Fan, Yuchen and Chandra, Vikas and Furukawa, Yasutaka and Ranjan, Rakesh},
  booktitle={European Conference on Computer Vision},
  pages={175--191},
  year={2025},
  organization={Springer}
}
@inproceedings{liang2024luciddreamer,
  title={Luciddreamer: Towards high-fidelity text-to-3d generation via interval score matching},
  author={Liang, Yixun and Yang, Xin and Lin, Jiantao and Li, Haodong and Xu, Xiaogang and Chen, Yingcong},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6517--6526},
  year={2024}
}
@article{poole2022dreamfusion,
  title={Dreamfusion: Text-to-3d using 2d diffusion},
  author={Poole, Ben and Jain, Ajay and Barron, Jonathan T and Mildenhall, Ben},
  journal={arXiv preprint arXiv:2209.14988},
  year={2022}
}
@article{wang2024prolificdreamer,
  title={Prolificdreamer: High-fidelity and diverse text-to-3d generation with variational score distillation},
  author={Wang, Zhengyi and Lu, Cheng and Wang, Yikai and Bao, Fan and Li, Chongxuan and Su, Hang and Zhu, Jun},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}
@article{yi2023gaussiandreamer,
  title={Gaussiandreamer: Fast generation from text to 3d gaussian splatting with point cloud priors},
  author={Yi, Taoran and Fang, Jiemin and Wu, Guanjun and Xie, Lingxi and Zhang, Xiaopeng and Liu, Wenyu and Tian, Qi and Wang, Xinggang},
  journal={arXiv preprint arXiv:2310.08529},
  year={2023}
}
@article{tang2023dreamgaussian,
  title={Dreamgaussian: Generative gaussian splatting for efficient 3d content creation},
  author={Tang, Jiaxiang and Ren, Jiawei and Zhou, Hang and Liu, Ziwei and Zeng, Gang},
  journal={arXiv preprint arXiv:2309.16653},
  year={2023}
}
@article{xu2024grm,
  title={Grm: Large gaussian reconstruction model for efficient 3d reconstruction and generation},
  author={Xu, Yinghao and Shi, Zifan and Yifan, Wang and Chen, Hansheng and Yang, Ceyuan and Peng, Sida and Shen, Yujun and Wetzstein, Gordon},
  journal={arXiv preprint arXiv:2403.14621},
  year={2024}
}
@article{xu2024instantmesh,
  title={Instantmesh: Efficient 3d mesh generation from a single image with sparse-view large reconstruction models},
  author={Xu, Jiale and Cheng, Weihao and Gao, Yiming and Wang, Xintao and Gao, Shenghua and Shan, Ying},
  journal={arXiv preprint arXiv:2404.07191},
  year={2024}
}
@article{li2023instant3d,
  title={Instant3d: Fast text-to-3d with sparse-view generation and large reconstruction model},
  author={Li, Jiahao and Tan, Hao and Zhang, Kai and Xu, Zexiang and Luan, Fujun and Xu, Yinghao and Hong, Yicong and Sunkavalli, Kalyan and Shakhnarovich, Greg and Bi, Sai},
  journal={arXiv preprint arXiv:2311.06214},
  year={2023}
}
@article{liu2024one,
  title={One-2-3-45: Any single image to 3d mesh in 45 seconds without per-shape optimization},
  author={Liu, Minghua and Xu, Chao and Jin, Haian and Chen, Linghao and Varma T, Mukund and Xu, Zexiang and Su, Hao},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}
@inproceedings{wang2025crm,
  title={Crm: Single image to 3d textured mesh with convolutional reconstruction model},
  author={Wang, Zhengyi and Wang, Yikai and Chen, Yifei and Xiang, Chendong and Chen, Shuo and Yu, Dajiang and Li, Chongxuan and Su, Hang and Zhu, Jun},
  booktitle={European Conference on Computer Vision},
  pages={57--74},
  year={2025},
  organization={Springer}
}
@inproceedings{liu2024one++,
  title={One-2-3-45++: Fast single image to 3d objects with consistent multi-view generation and 3d diffusion},
  author={Liu, Minghua and Shi, Ruoxi and Chen, Linghao and Zhang, Zhuoyang and Xu, Chao and Wei, Xinyue and Chen, Hansheng and Zeng, Chong and Gu, Jiayuan and Su, Hao},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10072--10083},
  year={2024}
}
@article{xu2023dmv3d,
  title={Dmv3d: Denoising multi-view diffusion using 3d large reconstruction model},
  author={Xu, Yinghao and Tan, Hao and Luan, Fujun and Bi, Sai and Wang, Peng and Li, Jiahao and Shi, Zifan and Sunkavalli, Kalyan and Wetzstein, Gordon and Xu, Zexiang and others},
  journal={arXiv preprint arXiv:2311.09217},
  year={2023}
}

% end2end
@article{hong2023lrm,
  title={Lrm: Large reconstruction model for single image to 3d},
  author={Hong, Yicong and Zhang, Kai and Gu, Jiuxiang and Bi, Sai and Zhou, Yang and Liu, Difan and Liu, Feng and Sunkavalli, Kalyan and Bui, Trung and Tan, Hao},
  journal={arXiv preprint arXiv:2311.04400},
  year={2023}
}

@article{tochilkin2024triposr,
  title={Triposr: Fast 3d object reconstruction from a single image},
  author={Tochilkin, Dmitry and Pankratz, David and Liu, Zexiang and Huang, Zixuan and Letts, Adam and Li, Yangguang and Liang, Ding and Laforte, Christian and Jampani, Varun and Cao, Yan-Pei},
  journal={arXiv preprint arXiv:2403.02151},
  year={2024}
}

%3d diffusion
@article{zhang20233dshape2vecset,
  title={3dshape2vecset: A 3d shape representation for neural fields and generative diffusion models},
  author={Zhang, Biao and Tang, Jiapeng and Niessner, Matthias and Wonka, Peter},
  journal={ACM Transactions on Graphics (TOG)},
  volume={42},
  number={4},
  pages={1--16},
  year={2023},
  publisher={ACM New York, NY, USA}
}
@article{zhang2024clay,
  title={CLAY: A Controllable Large-scale Generative Model for Creating High-quality 3D Assets},
  author={Zhang, Longwen and Wang, Ziyu and Zhang, Qixuan and Qiu, Qiwei and Pang, Anqi and Jiang, Haoran and Yang, Wei and Xu, Lan and Yu, Jingyi},
  journal={ACM Transactions on Graphics (TOG)},
  volume={43},
  number={4},
  pages={1--20},
  year={2024},
  publisher={ACM New York, NY, USA}
}
@article{zhao2024michelangelo,
  title={Michelangelo: Conditional 3d shape generation based on shape-image-text aligned latent representation},
  author={Zhao, Zibo and Liu, Wen and Chen, Xin and Zeng, Xianfang and Wang, Rui and Cheng, Pei and Fu, Bin and Chen, Tao and Yu, Gang and Gao, Shenghua},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}
@article{gupta20233dgen,
  title={3dgen: Triplane latent diffusion for textured mesh generation},
  author={Gupta, Anchit and Xiong, Wenhan and Nie, Yixin and Jones, Ian and O{\u{g}}uz, Barlas},
  journal={arXiv preprint arXiv:2303.05371},
  year={2023}
}
@article{nichol2022point,
  title={Point-e: A system for generating 3d point clouds from complex prompts},
  author={Nichol, Alex and Jun, Heewoo and Dhariwal, Prafulla and Mishkin, Pamela and Chen, Mark},
  journal={arXiv preprint arXiv:2212.08751},
  year={2022}
}
@inproceedings{muller2023diffrf,
  title={Diffrf: Rendering-guided 3d radiance field diffusion},
  author={M{\"u}ller, Norman and Siddiqui, Yawar and Porzi, Lorenzo and Bulo, Samuel Rota and Kontschieder, Peter and Nie{\ss}ner, Matthias},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={4328--4338},
  year={2023}
}
%gs diffusion
@article{zhang2024gaussiancube,
  title={GaussianCube: Structuring Gaussian Splatting using Optimal Transport for 3D Generative Modeling},
  author={Zhang, Bowen and Cheng, Yiji and Yang, Jiaolong and Wang, Chunyu and Zhao, Feng and Tang, Yansong and Chen, Dong and Guo, Baining},
  journal={arXiv preprint arXiv:2403.19655},
  year={2024}
}
@article{zhou2024diffgs,
  title={Diffgs: Functional gaussian splatting diffusion},
  author={Zhou, Junsheng and Zhang, Weiqi and Liu, Yu-Shen},
  journal={arXiv preprint arXiv:2410.19657},
  year={2024}
}@inproceedings{he2025gvgen,
  title={Gvgen: Text-to-3d generation with volumetric representation},
  author={He, Xianglong and Chen, Junyi and Peng, Sida and Huang, Di and Li, Yangguang and Huang, Xiaoshui and Yuan, Chun and Ouyang, Wanli and He, Tong},
  booktitle={European Conference on Computer Vision},
  pages={463--479},
  year={2025},
  organization={Springer}
}
@article{liu2024sketchdream,
  title={Sketchdream: Sketch-based text-to-3d generation and editing},
  author={Liu, Feng-Lin and Fu, Hongbo and Lai, Yu-Kun and Gao, Lin},
  journal={ACM Transactions on Graphics (TOG)},
  volume={43},
  number={4},
  pages={1--13},
  year={2024},
  publisher={ACM New York, NY, USA}
}
@inproceedings{dong2024interactive3d,
  title={Interactive3D: Create What You Want by Interactive 3D Generation},
  author={Dong, Shaocong and Ding, Lihe and Huang, Zhanpeng and Wang, Zibin and Xue, Tianfan and Xu, Dan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={4999--5008},
  year={2024}
}
@article{chen2024mvdrag3d,
  title={MvDrag3D: Drag-based Creative 3D Editing via Multi-view Generation-Reconstruction Priors},
  author={Chen, Honghua and Lan, Yushi and Chen, Yongwei and Zhou, Yifan and Pan, Xingang},
  journal={arXiv preprint arXiv:2410.16272},
  year={2024}
}
@article{xiang2024structured,
    title   = {Structured 3D Latents for Scalable and Versatile 3D Generation},
    author  = {Xiang, Jianfeng and Lv, Zelong and Xu, Sicheng and Deng, Yu and Wang, Ruicheng and Zhang, Bowen and Chen, Dong and Tong, Xin and Yang, Jiaolong},
    journal = {arXiv preprint arXiv:2412.01506},
    year    = {2024}
}
@Manual{blender,
   title = {Blender - a 3D modelling and rendering package},
   author = {Blender Online Community},
   organization = {Blender Foundation},
   address = {Stichting Blender Foundation, Amsterdam},
   year = {2018},
   url = {http://www.blender.org},
 }

@article{poisson,
author = {Yuksel, Cem},
title = {Sample Elimination for Generating Poisson Disk Sample Sets},
year = {2015},
issue_date = {May 2015},
publisher = {The Eurographs Association \& John Wiley \& Sons, Ltd.},
address = {Chichester, GBR},
volume = {34},
number = {2},
issn = {0167-7055},
url = {https://doi.org/10.1111/cgf.12538},
doi = {10.1111/cgf.12538},
abstract = {In this paper we describe sample elimination for generating Poisson disk sample sets with a desired size. We introduce a greedy sample elimination algorithm that assigns a weight to each sample in a given set and eliminates the ones with greater weights in order to pick a subset of a desired size with Poisson disk property without having to specify a Poisson disk radius. This new algorithm is simple, computationally efficient, and it can work in any sampling domain, producing sample sets with more pronounced blue noise characteristics than dart throwing. Most importantly, it allows unbiased progressive adaptive sampling and it scales better to high dimensions than previous methods. However, it cannot guarantee maximal coverage. We provide a statistical analysis of our algorithm in 2D and higher dimensions as well as results from our tests with different example applications.},
journal = {Comput. Graph. Forum},
month = may,
pages = {25–32},
numpages = {8}
}
@inproceedings{downs2022google,
  title={Google scanned objects: A high-quality dataset of 3d scanned household items},
  author={Downs, Laura and Francis, Anthony and Koenig, Nate and Kinman, Brandon and Hickman, Ryan and Reymann, Krista and McHugh, Thomas B and Vanhoucke, Vincent},
  booktitle={2022 International Conference on Robotics and Automation (ICRA)},
  pages={2553--2560},
  year={2022},
  organization={IEEE}
}