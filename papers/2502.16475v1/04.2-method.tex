\section{Seed-Point-Driven Anchor Latent Generation and Editing}
\label{sec:seed-point-driven}
% \subsection{Seed-Point-Driven Strategy}

We adopt a Seed-Point-Driven generation approach to progressively obtain the anchor latents $Z$. First, we generate a sparse set of seed points \( \mathbf{X}_\mathcal{S} \in \mathbb{R}^{S \times 3} \) , which can be viewed as a rough representation of the geometry(Sec.~\ref{sec:seed-gen}). And then, through the Seed-Anchor Mapping module, we transform the sparse distribution of seed points into a dense distribution of anchor latents (Sec.~\ref{sec:seed-mapping}). The Seed-Point-Driven strategy enables interactive geometric control of the generated 3DGS by simply \emph{dragging} the seed points (Sec.~\ref{sec:seed-drag}).

% This approach has the following advantages: (1) Directly generating anchor latents $Z$ is too difficult for the generative model to learn, especially when $|\mathcal{N}|$ is large, as in our case $|\mathcal{N}|$=2048. By decomposing the generation of anchor latents into two stages—first generating sparse seed points $\mathbf{X}_\mathcal{S}$, and then using flow matchingto derive the anchor latents from the distribution of seed points—we greatly reduce the learning complexity.
%     % \item This decoupled approach naturally supports geometric editing. By establishing a relationship between the two distributions through the Seed-Anchor Mapping module, we can edit the seed points, which alters the initial geometric information in the mapping process, resulting in different anchor latents and thus deformed 3DGS. % By establishing a relationship between the two distributions through the Seed-Anchor Mapping module, we can edit the seed points, which in turn modifies the corresponding anchor latents. 
%     % This enables interactive geometric control of the generated 3DGS by simply \emph{dragging} the seed points.
% (2) This decoupled approach naturally supports geometric editing. By establishing the seed-anchor mapping module, we can edit the seed points, which leads to different anchor latents, and thus deform 3DGS. This enables interactive geometric control of the generated 3DGS by simply \emph{dragging} the seed points (Sec.~\ref{sec:seed-drag}).

% \JY{
This approach has the following advantages: (1)\textbf{Geometrically Consistent Generation}:We first learn a sparse set of seed points \( \mathbf{X}_\mathcal{S} \) (\( S = 256 \)), which ensures geometrically consistent 3D results due to the sparse nature of seed points and the ease of learning their distribution. (2) \textbf{Support for Geometric Editing}: By constructing the Seed-Anchor Mapping Module, we map seed points to their corresponding anchor latents. This decoupled design naturally supports geometric editing—modifying the seed points results in different anchor latents, enabling deformation of the 3DGS. 
% }


 



% 由于我们的anchor latents的数量N较大，直接进行latents的生成对于构建diffusion比较困难。所以
% 我们采取Control-Point-Driven的生成方式来逐步得到anchor latents，首先生成稀疏的control points ，再通过Control-Anchor Flow module,将稀疏的control points的分布转变为稠密的anchor latents。这种模式有以下好处：
% 1.直接生成N个anchor latents对于生成模型的学习过于困难。而将anchor latents的生成分解为一个稀疏的control points生成，和在control points的分布基础上得到anchor latents分布的flow matching，极大的降低了学习难度。
% 2. 这种解耦的方式天然的支持我们进行几何上的编辑。借助于Control-Anchor Flow module建立起的两个分布之间的联系，我们可以通过对control points进行编辑，从而得到不同的相应的anchor latents。由此，我们可以通过不管改变control points来控制几何，对生成的3DGS进行交互式的编辑。
% Control-Point-Driven的生成可以支持我们进行交互式的拉拽编辑。
% 1. 对点云拉拽，再经过flow module可以得到拉拽后的anchor latents，天然的支持交互式编辑


% The Rectified Flow Model has the capability to establish a mapping between two distributions, \( \pi_0 \) and \( \pi_1 \), making it well-suited for our task.
% So it means 我们可以建立一个从
% \subsection{Recitified Flow Model}
% % Recitified flow modle有建立两个分布\pi_0, \pi_1之间mapping的能力，所以很适合我们的任务。给定x_0 ~ \pi_0 和 相对应的x_1 ~ \pi_1, 我们可以通过liner interpolation  得到 x(t) = (1-t) x_0 + t x_1 at timestamp t. And a vector filed v_sita parameterized by a neural network 被用来drive the flow from source distribution \pi_0 to target distribution \pi_1 by minimizing the conditional flow matching objective:
% The Rectified Flow Model\cite{liu2022flow, lipman2022flow} has the capability to establish a mapping between two distributions, \( \pi_0 \) and \( \pi_1 \), making it well-suited for our task. Given \( x_0 \sim \pi_0 \) and the corresponding \( x_1 \sim \pi_1 \), we can obtain \( x(t) = (1 - t) x_0 + t x_1 \) at timestamp \( t \in [0,1]\) through linear interpolation. A vector field \( v_{\theta} \) parameterized by a neural network is used to drive the flow from the source distribution \( \pi_0 \) to the target distribution \( \pi_1 \) by minimizing the conditional flow matching objective:
% \begin{equation}
%     L(\theta) = E_{t,x_0,x_1,y}||v_{\theta}(x_t, t,y) - (x_1 - x_0)||
%     \label{eq:flow matching}
% \end{equation}
% Here, $v_{\theta}(x_t, t, y)$ is the predicted flow at time $t$ for a given point $x_t$, $y$ refers to the image  condition that guides the flow matching.
% 是图片或者文本的condition guided the flow matching。
% The Rectified Flow Model has the capability to establish a mapping between two distributions, \( \pi_0 \) and \( \pi_1 \), making it well-suited for our task. Given \( x_0 \sim \pi_0 \) and the corresponding \( x_1 \sim \pi_1 \), we can obtain \( x(t) = (1 - t) x_0 + t x_1 \) at timestamp \( t \) through linear interpolation. A vector field \( v_{\theta} \) parameterized by a neural network is used to drive the flow from the source distribution \( \pi_0 \) to the target distribution \( \pi_1 \) by minimizing the conditional flow matching objective:

% \[
% L(\theta) = \mathbb{E}_{t, x_0, x_1} \left\| v_{\theta}(x_t, t) - (x_1 - x_0) \right\|
% \]

\subsection{Seed Points Generation Module}

\label{sec:seed-gen}

% \JY{

Our goal is to generate a sparse set of seed points $\mathbf{X}_\mathcal{S}$ as a rough representation of the geometry from a single image input. To achieve this, we employ a diffusion model conditioned on the image to learn the distribution of $\mathbf{X}_\mathcal{S}$. Given the sparse nature of the seed points \(\mathbf{X}_\mathcal{S}\), where \(|\mathcal{S}| = 256\) in our settings, their distribution is relatively simple to learn directly, without the need for projection into a latent space. The results can be seen in Fig. \ref{fig:seed_gen}. Specifically, we utilize the Rectified Flow model to map Gaussian noise to the seed point distribution \(\pi_S\), treating the noise \(\epsilon\) as \(x_0\) and the data sample \(x_S\) as \(x_1\).

% }
% Due to the sparse nature of the seed points $\mathbf{X}_\mathcal{S}$, where $|\mathcal{S}|$=256  in our settings, we directly leverage a diffusion model for learning without requiring projection into a latent space via a VAE. We also utilize the Rectified Flow model to map Gaussian noise to the seed points distribution $\pi_S$, treating the noise \(\epsilon\) as \(x_0\) and the data sample \(x_S\) as \(x_1\).  
% Treating each point as a token, we design our network using Transformer blocks. Similar to the Seed-Anchor Mapping Module, we incorporate cross-attention to inject image features extracted via DINOv2 and use adaLN for timestamp conditioning.


\subsection{Seed-Anchor Mapping Module}
\label{sec:seed-mapping}
\begin{figure}
  \includegraphics[width=\columnwidth]{figs/token_align_v2.pdf}
  \caption{
  Seed-Anchor Mapping Module: 
(a) We use FPS to establish a correspondence between \( Z \) and \( \mathbf{X}_\mathcal{S} \).  
(b) Dimension Alignment: Encoding the seed points \( \mathbf{X}_\mathcal{S} \) to obtain \( Z_\mathcal{S} \), ensuring dimensional alignment with \( Z \).  
(c) Token Alignment: Each token in the seed latent is treated as a center to partition the tokens of \( Z \) into \( |\mathcal{S}| \) clusters. A repeat operation is then applied to the seed latents, achieving semantic and token count alignment between \( Z_\mathcal{S} \) and \( Z \).
  % Seed-Anchor Mapping Module: (a) We use FPS find a correspondence between Z and XS (b) Dimension Alignment: encode seed points X_S to get Z_S for dimentsion align with Z .(C)Token Alignment: for each token in seed latent, we take it as a center to paition the tokens of Z into |S| clusters, and then 对 seed latets实施repeat。实现Z_S 和 Z 的token在语义和个数上的对应。
  }
  \label{fig:token_align}
\end{figure}

To use an input image $I$ and a set of (deformed) seed points to control the generation of 3DGS, we need to derive the corresponding anchor latents \( Z \).
% Given a set of seed points \( \mathbf{X}_\mathcal{S} \) and an input image $I$, our goal is to derive the corresponding anchor latents \( Z \). 
We model this task as a flow matching problem between two distributions and aim to solve it using the Rectified Flow Model,  as shown in Fig. \ref{fig:token_align}.
% which can be achieved by learning a mapping between these two distributions.

First, we need to establish a one-to-one correspondence between known samples from these two distributions.  Specifically, for each anchor point set \( \mathbf{X}_\mathcal{N} \), we apply Furthest Point Sampling (FPS) to downsample the anchor points to obtain the seed points \( \mathbf{X}_\mathcal{S} \). That ensures for each \( Z \), we can find a corresponding \( \mathbf{X}_\mathcal{S} \).

\paragraph{Dimension Alignment}
% 为了使用Rectified Flow model， the start point and target point应该有相同的dimension. So we need to encode the seed points to the demntion of $Z$, and we do the encode by passing \( \mathbf{X}_\mathcal{S} \) through the encoder \( \mathcal{E} \):
To construct the Rectified Flow model, the starting and targets must share the same dimensionality. Thus, we encode the seed points to align with the dimension of \( Z \) by passing \( \mathbf{X}_\mathcal{S} \) through the freeze encoder \( \mathcal{E} \) of Anchor-GS VAE:
\begin{equation}
  Z_\mathcal{S} = \mathcal{E}(\mathbf{X}_\mathcal{S}| \mathbf{X}_\mathcal{S}, I)  
  \label{eq:encode_seed_latents}
\end{equation}
Here, \( Z_\mathcal{S} \) represents the encoded latents of the seed points. This allows us to simplify the problem into a mapping from \( Z_\mathcal{S} \) to corresponding \( Z\). Using the same pretrained encoder with \( Z \), the \( Z_\mathcal{S} \) distribution becomes better aligned with the target anchor latents \( Z \), providing valuable information about the alignment between the points and the image.
% Starting from \( Z_\mathcal{S} \) rather than other encodings of \( \mathbf{X}_\mathcal{S} \), such as positional encoding, has several benefits. First, using \( \mathcal{E} \) produces a distribution that is more aligned with the target anchor latents \( Z \) and provides useful information of the alignment between the points and the image. This simplifies the learning process for the Seed-Anchor Mapping Module and enables it to focus more effectively on completing information based on the seed points. As a result, this enhances support for subsequent seed point-based editing, as described in Sec. \ref{sec:seed-drag}.

\begin{figure}
  \includegraphics[width=\columnwidth]{figs/control_gen.pdf}
  \caption{
Generation of Seed Points with Multiview Geometry Consistency
  }
  \label{fig:seed_gen}
\end{figure}
\paragraph{Token Alignment.}
To establish flow matching between \( Z_\mathcal{S} \)and \( Z\), we need to ensure that both samples contain the same number of tokens, and each token in the two samples corresponds semantically. Unlike \cite{fischer2023boosting}, which performs 2D grid-based upsampling on images, we cannot simply upsample seed points to match the target size while maintaining semantic correspondence between the points, as our latents are unordered.

To address this, we propose a cluster-based token alignment strategy. Each token in the latents retains the geometric information of the encoded points, allowing us to partition the latents into clusters based on their spatial positions. Specifically, for each token in the seed latents, we identify its neighborhood in the anchor latents using:
% 我们提出了Cluster-based token alignment来解决这个问题.首先，latents中每一个token都保留着被encode的点的几何信息, 所以我们可以根据latents对应的空间的position来对他们进行cluster partition. 具体而言,我们可以对每一个 token of seed latents,找到它在anchor latents中的邻域: 
\begin{equation}
    \forall i \in \mathcal{S}, \quad \text{KNN}(x_i) = \{x_j\}_{j \in \text{Nbr}(i)}
\end{equation}
Here, \( x_j,x_i\) represent the encoded position of $z_j \in Z$ and $z_i \in Z_\mathcal{S}$, respectively, while $\text{Nbr}(i)$ denotes the index set of the $k$-nearest neighbors around \( z_i\).
This partitions \( Z\) partition into $|\mathcal{S}|$ clusters, where the tokens in  each cluster $\text{Nbr}(i)$ are semantically similar to $z_i$  , leveraging their spatial proximity. 
After establishing the semantic similarity between each token in $Z_\mathcal{S}$ and the corresponding cluster of tokens in $Z$, we simply repeat tokens in $Z_\mathcal{S}$ to ensure numerical equivalence. At this point, the alignment results between \( Z \) and \( Z_\mathcal{S} \) can serve as the start point $x_0 $and target $x_1$ for the Rectified Flow model, with the same number of tokens and semantic correspondence.


% This alignment enables flow matching to be performed based on Eq. \ref{eq:flow matching}.


% To establish flow matching between \( Z_\mathcal{S} \)and \( Z\), we need to ensure that both samples contain the same number of tokens, and that these tokens are ordered, meaning that each token in the two samples corresponds semantically.
% % \noindent \textbf{Anchor Rearranging with Seed Points:}
% % To obtain the interpolation data point \( x_t \)
% % to 建立Z_S 和 Z 之间的flow matching
% % , we need to ensure that both samples contain the same number of tokens, and that these tokens are ordered, meaning that each token in the two samples corresponds semantically.
% Unlike \cite{fischer2023boosting}, which performs 2D grid-based upsampling on images, we cannot simply upsample seed points to match the target size while maintaining semantic correspondence between the points, due to the discrete nature of point clouds in space. 
% \todo{modify the flow chart}
% \begin{wrapfigure}{r}{.25\columnwidth}
%     \begin{center}
%     \vspace{-1.5\intextsep}
%     \hspace{-2\intextsep}
%     \includegraphics[width=.3\columnwidth]{figs/token_align.pdf}
%     \vspace{-\intextsep}
%     \end{center}
% \end{wrapfigure}
% To address this, we first repeat the seed latents $Z_\mathcal{S}$ and interleave each token \( k \) times ($k$ is the sampling rate used to select the seed points from the anchor points) to match the number of tokens in the anchor latents $Z$, and this can considered as the starting point $x_0$ in the flow matching:
% \begin{equation}
% x_0 = \textbf{repeat}(Z_\mathcal{S}, k)
% \end{equation}
% % Here the \textbf{repeat} operation interleaves each token in the encoded Z, where the repetition count \( k \) matches the sampling rate used for selecting the seed points. 这样我们保证了fllow matching中starting point和target中token数目是一致的。
% % Then, 为了保证x_0 和 target Z的相同位置的token 的语义匹配， 我们需要对Z进行排序。
% % 首先，我们可以根据X_S 对 X_N进行分cluster：
% % Here, the \textbf{repeat} operation interleaves each token in the encoded \( Z_\mathcal{S} \), with the repetition count \( k \) corresponding to the sampling rate used to select the seed points from the anchor points. This ensures that the number of tokens in the starting point \( x_0 \) matches that of the target \( Z \) in the flow matching process.

% % Next, to ensure semantic alignment between the tokens in \( x_0 \) and their corresponding tokens in the target \( \mathbf{Z} \), we need to sort \( \mathbf{Z} \). First, we partition \( \mathbf{X}_\mathcal{N} \) into clusters based on \( \mathbf{X}_\mathcal{S} \): 

% % \begin{equation}
% %     \forall i \in \mathcal{S},\; \; \;  KNN(x_i) = \{x_j\}_{j \in \mathcal{N}_{i}}
% % \end{equation}
% % 其中 x_j \in X_N, \mathcal{N}_{i}}为x_i的一个大小为k的邻域，这样做，我们就把X_N均分成了以X_S中每个seed点为中心的S个cluster中，每个cluster中的点与他们中心的seed点在几何上是相近的。所以接着我们根据分cluster的结果对Z里面的token进行排序：


% Next, to ensure semantic alignment between the tokens in \( x_0 \) and their corresponding tokens in the target \( Z \), we need to sort \( Z \). First, we partition \( \mathbf{X}_\mathcal{N} \) into $|\mathcal{S}|$ clusters based on \( \mathbf{X}_\mathcal{S} \) using $K$-Nearest Neighbor (KNN) method.
% % : 
% % \begin{equation}
% %     \forall i \in \mathcal{S}, \quad \text{KNN}(x_i) = \{x_j\}_{j \in \mathcal{N}_{i}}
% % \end{equation}
% % Here, \( x_j \in \mathbf{X}_\mathcal{N} \), and \( \mathcal{N}_{i} \) denotes an index set that refers to the neighborhood of size \( k \) around \( x_i \). By doing this, we divide \( \mathbf{X}_\mathcal{N} \) into $|\mathcal{S}|$ clusters, where each cluster is centered around a seed point in \( \mathbf{X}_\mathcal{S} \). 
% Within $i$-th cluster, the points (with indices in $\mathcal{N}_{i}$) are geometrically close to the $i$-th seed point. 
% %
% Using the clustering results, we then sort the tokens in \( Z \) such that the tokens align with their corresponding clusters. Specifically, for each \( \mathcal{N}_i \), we assign an order based on the indices of the points in \( \mathbf{X}_\mathcal{N} \)\YH{why sorting the indices aligns the tokens with its cluster or ensures geometric proximity?}:

% \begin{equation}
%     x_1 = Z^{\text{sorted}} = \{Z[j] \, | \, j \in \mathcal{N}_i, \; \forall i \in \mathcal{S}\}
% \end{equation}

% Here, \( Z^{\text{sorted}} \) represents the result of the sorting process, which also serves as the final target \( x_1 \) for flow matching. This approach ensures that the tokens in \( x_1 = Z^{\text{sorted}} \) are grouped and ordered based on their geometric proximity to the seed points in \( \mathbf{X}_\mathcal{S} \), thereby establishing semantic alignment between \( x_0 \) and \( x_1 \).
% Then, we can perform flow matching based on Eq. \ref{eq:flow matching}, where \( y \) represents the image features extracted using DINOv2\cite{oquab2023dinov2}.




\paragraph{Model Architecture and Details.}
% 我们采用Transformer block来实现我们的Model Architecture，with image condition 作为kv in the cross-attention and 注入timestamp using addLN block used in \cite{peebles2023scalable}.
% Due to the token align, the input tokens x_t 是有序的，在每一个cluster上具有空间相似性，so we can perform downsample and then upsample in each cluster to 减小计算复杂度, with skip-connection to 传递细节信息。
We implement the model using Transformer blocks, with image conditions serving as the key and value in the cross-attention, and inject timestamps via the adaptive layer norm (adaLN) block as described in \cite{peebles2023scalable}. With token alignment, the input tokens \( x_t \) are clustered and exhibit spatial similarity within each cluster. Therefore, we can downsample and then upsample within each cluster to reduce computational complexity, skipping connections to transfer detailed information.
% Similar to \cite{deng2024detailgen3d,fischer2023boosting}, 我们对输入的x0做了噪声增强，这会增强我们训练的稳定性。 and due to 我们infer时的seed points是生成来的，并且会进行多种多样的编辑， this noise argumentation 能使我们的模型能泛化到更多样的seed points下。我们对x0使用cosine schedule 使用噪声增强at 150 timestamp at both train and eval 。
Similar to \cite{deng2024detailgen3d,fischer2023boosting}, we apply noise augmentation to the start point \( x_0 \), which enhances the stability of our training process. Additionally, since the seed points used during inference are generated and subject to various edits, this noise augmentation helps our model generalize to a wider variety of seed points. We apply a cosine schedule for noise augmentation at 150 timesteps during both training and evaluation.
% we can perform down sample in the cluster tokens to 减小计算复杂度。 And our model architecture






\subsection{Seed-Points-Driven Deformation}
\label{sec:seed-drag}
% 1. 由于我们的mapping出发点是seed，所以我们可以对seed进行改变来影响最后的效果
% 2. 由于基于点的优点，我们可以很轻易的对点进行拖拽，基于现有的3D工具，如blender，来得到我们想要的效果
% 3. 我们通过在encode时，只改变拖拽后点的位置信息，保留原本的纹理信息，从而保证纹理信息的连续性。并且没有被拖拽的点，它的encode信息保持不变。

% 这样相比于在2D上进行编辑，能保证在3D上的一致性
% 这样相比于通过prompt的edit，能保证编辑后的结果是我们想要的
Thanks to our Seed-Anchor Mapping module, the mapping  begins with seed points—a sparse set of points that guide and control the overall 3D geometry generation. By adjusting the positions of these seed points, we can intuitively generate various desired geometries, making the editing process flexible and precise. The discrete nature of point clouds enables effective application of drag-style editing. Additionally, mature 3D tools like Blender\cite{blender} already support such operations on point clouds in 3D space, providing an intuitive and user-friendly editing experience.

Specifically, for the initial seed points \( X_\mathcal{S} \) and their corresponding \( Z_\mathcal{S} \), we apply drag-style editing to the seed points, resulting in \( X_{\hat{S}} \). We then encode \( X_{\hat{S}} \) to obtain \( \hat{Z}_\mathcal{S} \), using Eq. \ref{eq:encode_seed_latents}. During encoding, we continue to use the projected features obtained from the projection of \( X_\mathcal{S} \) onto the input image to preserve the correspondence between geometry and texture.

To preserve the consistency of these unedited regions, we introduce a mask to ensure their invariance:
\begin{equation}
    Z^{*}_\mathcal{S} = mask \odot Z_\mathcal{S} + (1 - mask)\odot \hat{Z}_\mathcal{S}
\end{equation}
In this equation, the mask is a Boolean vector indicating whether a point remains unchanged. 
With this, \( Z^{*}_\mathcal{S} \) serves as the new seed latents. By applying the same alignment operation and Seed-Anchor Mapping module, we derive the corresponding anchor latents from the dragged seed points, which are then decoded into the deformed 3DGS. This process ensures that the dragged points remain aligned with their original texture while maintaining consistency in the unedited regions.

% \todo{need modify}Specifically, for the initial seed points \( X_S \), the result of encoding these seed points, denoted as \( Z_{\mathcal{S}} \), serves as an intermediate product for 3D generation, as described in Eq. \ref{eq:encode_seed_latents}. After applying drag-style editing to the seed points, resulting in \( X_{\hat{S}} \), we can derive the edited representation \( \hat{Z}_\mathcal{S} \):

% \begin{equation}
% \begin{aligned}
%     &\hat{Z^{'}}_\mathcal{S} = \mathbf{Transformer}_1(\{(\mathbf{PE}(\hat{x}_i);f_i) \}_{i \in \hat{\mathcal{S}}}, \{\mathbf{PE}(\hat{x}_i)\}_{i \in \hat{\mathcal{S}}})\\
% & \hat{Z}_\mathcal{S} = \mathbf{Transformer}_2(\hat{Z^{'}}, F_I) 
% \end{aligned}
% \label{eq:edit_seed_encode}
% \end{equation}
% 在这里，f_i是drag编辑前的点投影得到的feature，and \hat{x}_i是对应的拉拽后的点的position。In the encoding process, 未被编辑的区域同样会受到影响，所以我们引入mask来保证未被编辑区域的不变性：
% Here, \( f_i \) represents the feature obtained from the projection of the points before the drag editing, and \( \hat{x}_i \) denotes the position of the corresponding dragged point, 我们采用编辑前得到的f_i to ensure 拉拽后的点与纹理的align.
% Here, \( f_i \) represents the feature obtained from the projection of the points before the drag editing, and \( \hat{x}_i \) denotes the position of the corresponding dragged point. We use the features \( f_i \) obtained before editing to ensure the alignment of the dragged points with the original texture. 

% During the encoding process, regions that were not edited may still be affected by the transformation. To preserve the consistency of these unedited regions, we introduce a mask to ensure their invariance:
% \begin{equation}
%     Z^{*}_\mathcal{S} = mask \odot Z_\mathcal{S} + (1 - mask)\odot \hat{Z}_\mathcal{S}
% \end{equation}
% In this equation, the mask is a Boolean vector indicating whether a point has been dragged. Specifically, if \( \text{mask}[i] = 1 \), it means that point \( i \) has been moved due to the drag operation. With this, we can use \( Z^{*}_\mathcal{S} \) as the new starting point for the Seed-Anchor Mapping module, obtaining the desired anchor latents from the dragged seed points, and subsequently decoding them into a deformed new 3DGS. This editing process ensures that the dragged points remain aligned with their original texture, while maintaining the consistency of the unedited regions.
% 在这里mask是一个表示是否被拉拽的bool向量，if mask[i]等于1表示点i的位置经拉拽发生了改变。至此，我们可以将Z^{*}作为新的Seed-Anchor Mapping的出发点，基于拉拽后的seed points得到desired anchor latents and then decode to the new 3DGS. This 编辑的过程可以保证拉拽的点与原本纹理的对其，并且保证没有被编辑的区域的一致性。
% 得益于我们的Seed-Anchor Mapping module, 我们的flow matching的出发点是seed points，which 使用有限的point来控制整体的3D的几何形状。 And很直觉的，我们可以改变我们的出发点-通过改变seed points来得到我们想要的几何-得到不同的我们想要的3D表示， 整个编辑过程是可控的。

% 基于点云离散的特性，我们可以对点云进行可控的拉拽式编辑。并且目前已经有很成熟的3D工具，如blender，可以对点云的拉拽式编辑操作 in a user friendly way。
