\section{Related Work}
\subsection{Neural Dense SLAM}
In contrast to traditional SLAM systems \cite{mur2015orb,mur2017orb,zhang2019hierarchical,campos2021orb,du2022accurate,chung2023orbeez,pan2024robust} that utilize point-clouds or voxels for sparse map representation, neural dense SLAM systems \cite{yan2017dense,zhang2023go,li2023end,huang2023real,deng2024plgslam,zhu2024nicer,zhou2024mod,deng2024neslam,xie2025depth} offer substantial advantages through their dense neural radiance maps, providing a robust foundation for downstream tasks in robotics and AR/XR \cite{deng2023prosgnerf}. iMAP \cite{sucar2021imap} pioneered neural implicit SLAM but suffers from large tracking and mapping error using a single MLP. NICE-SLAM \cite{zhu2022nice} employs multiple MLPs for coarser-to-finer mapping, effectively filling the gaps in reconstruction. ESLAM \cite{johari2023eslam} leverages tri-plane features for efficient scene representation, while Co-SLAM \cite{wang2023co} employs multi-resolution hash-grids for real-time performance. Point-SLAM \cite{sandstrom2023point} relies on neural point clouds for dense scene reconstruction, and Loopy-SLAM \cite{liso2024loopy} introduces map corrections to address scene drift caused by accumulated tracking errors. However, maps reconstructed using NeRF typically lack the quality seen in more recent systems built upon 3D Gaussian Splatting. Furthermore, high-resolution NeRF models often require extensive training and exhibit slower real-time rendering performance \cite{kerbl20233d}, which significantly reduces their practical efficiency.

\subsection{Gaussian Splatting SLAM}

Propelled by advancements in 3DGS \cite{kerbl20233d}, recent Gaussian SLAM systems \cite{yan2024gs,ha2024rgbd,li2025sgs,deng2024compact,hu2025cg} have shown remarkable capabilities in high-fidelity map reconstruction and efficient real-time rendering. Notably, SplaTAM \cite{keetha2024splatam} utilizes isotropic Gaussian representation coupled with dense point-cloud sampling to ensure geometric precision. Conversely, MonoGS \cite{matsuki2024gaussian} employs anisotropic Gaussians to accelerate map reconstruction and enhance texture rendering. Nevertheless, the frame-to-frame tracking mechanisms of these systems do not incorporate loop closure or bundle adjustment, which leads to significant tracking discrepancies in real-world environments. Concurrently, Photo-SLAM \cite{huang2024photo} and RTG-SLAM \cite{peng2024rtg}, which integrate feature-based tracking \cite{mur2017orb,campos2021orb} with dense Gaussian maps, achieve superior tracking accuracy and real-time performance. However, they take the trade-off of diminished rendering quality due to the sparse sampling of scene representation. Moreover, systems such as Gaussian-SLAM \cite{yugay2023gaussian} and LoopSplat \cite{zhu2024loopsplat} propose to implement submap division and fusion strategies to tackle the high memory consumption of fine-grained Gaussian maps. While Gaussian SLAM systems offer superior rendering quality compared to NeRF models, the explicit and discrete nature of their scene representation often results in substantial gaps and holes in the reconstructed map due to unobserved or obstructed views commonly seen in online systems. These deficiencies severely affect their efficiency in real-world applications.

\subsection{Gaussian Splatting with Neural Radiance Prior}

Vanilla 3DGS \cite{kerbl20233d} utilizes the sparse point cloud derived from Structure-from-Motion \cite{bregler2000recovering,schonberger2016structure}, whose reconstruction quality heavily relies on the accuracy of the initial point cloud \cite{jung2024relaxing}. As an alternative, RadSplat \cite{niemeyer2024radsplat} introduces NeRF model \cite{mildenhall2021nerf} into the Gaussian Splatting framework, aiming to achieve robust real-time rendering of complex real-world scenes. RadSplat \cite{niemeyer2024radsplat} specifically employs NeRF as a prior for initialization and supervision, enabling fast training convergence and enhanced quality.

Compared to RadSplat \cite{niemeyer2024radsplat}, our method differs fundamentally in task objectives and motivations. RadSplat \cite{niemeyer2024radsplat} focuses on offline reconstruction scenarios where datasets typically consist of 360-degree or dense viewpoint coverage \cite{barron2022mip,Knapitsch2017}, making completeness and rendering quality the primary goals. In contrast, our method addresses the challenges of real-time SLAM systems deployed in robotic systems, where the limited sensor field of view and navigation path lead to sparse and sequential observations. These factors frequently result in unobserved or partially observed geometry due to obstacles, posing significant challenges for explicit Gaussian representations that often leave critical gaps in the reconstruction. To overcome these issues, our method utilizes NeRF not solely for initialization but as a robust mechanism for interpolating unobserved regions and enabling real-time adaptability in environments with sparse views. These challenges are typically absent in offline scenarios.