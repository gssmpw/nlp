
%\dfc{Add overview of how section is organized. also imo we should state the main algo first, then state epco afterwards.}

In this section we prove that for any concept class $\Phi$, there is a reduction from reward-free RL (\cref{def:strong-rf-rl}) in the episodic access model to two-context regression (\cref{def:two-con-regression}). The formal statement is provided below.

\begin{theorem}[General version of \cref{cor:online-rl-to-regression}]\label{thm:pco-app}
There is a constant $C_{\ref{thm:pco-app}}>0$ and an algorithm $\PCO$ so that the following holds. Let $\Phi \subseteq (\MX\to\MS)$ be any concept class, and let $\Reg$ be a $\Nreg$-efficient two-context regression oracle for $\Phi$. Then $\PCO(\Reg,\Nreg,|\MS|,\cdot)$ %with $N:=\Nreg\left(\left(\frac{\epsilon\delta}{H|\MA||\MS|}\right)^{C_{\ref{cor:online-rl-to-regression}}},\left(\frac{\epsilon\delta}{H|\MA||\MS|}\right)^{C_{\ref{cor:online-rl-to-regression}}}\right)$ 
is an $(\Nrl,\Krl)$-efficient reward-free RL algorithm for $\Phi$ in the episodic access model, with:
\begin{itemize}
    \item $\Krl(\epsilon,\delta,H,|\MA|) \leq H^2|\MS|^2$
    \item $\Nrl(\epsilon,\delta,H,|\MA|) \leq \left(\frac{H|\MA||\MS|}{\epsilon\delta}\right)^{C_{\ref{thm:pco-app}}} \Nreg\left(\left(\frac{\epsilon\delta}{H|\MA||\MS|}\right)^{C_{\ref{thm:pco-app}}},\left(\frac{\epsilon\delta}{H|\MA||\MS|}\right)^{C_{\ref{thm:pco-app}}}\right)$.
\end{itemize}
Moreover, the oracle time complexity of $\PCO$ is at most $\left(\frac{H|\MA||\MS|}{\epsilon\delta}\right)^{C_{\ref{thm:pco-app}}} \Nreg\left(\left(\frac{\epsilon\delta}{H|\MA||\MS|}\right)^{C_{\ref{thm:pco-app}}},\left(\frac{\epsilon\delta}{H|\MA||\MS|}\right)^{C_{\ref{thm:pco-app}}}\right).$
\end{theorem}

In particular, \cref{cor:online-rl-to-regression} follows from \cref{thm:pco-app} by substituting $\Nreg(\epsilon,\delta) := \Nregc/(\epsilon\delta)^{\Creg}$ into the above bounds. Henceforth, fix a concept class $\Phi$, a $\Nreg$-efficient two-context regression oracle $\Reg$, and a $\Phi$-decodable block MDP $M$ with horizon $H$, action set $\MA$, and unknown decoding function $\phi^\st \in \Phi$. We also define truncations of $M$ (see \cref{sec:truncated-mdps}), with the parameters $\trunc,\tsmall>0$ as defined in \cref{alg:pco}.

In \cref{sec:pco-overview}, we give pseudocode and an overview of $\PCO$ and its main subroutine $\EPCO$. In \cref{subsec:epco}, we formally analyze $\EPCO$. In \cref{sec:pco-analysis}, we formally analyze $\PCO$, completing the proof of \cref{thm:pco-app} (and hence \cref{cor:online-rl-to-regression}).

\subsection{$\PCO$ \colt{Pseudocode and }Overview}\label{sec:pco-overview}

We start by giving an overview of the algorithm $\PCO$ (\cref{alg:pco}). The main subroutine of this algorithm is $\EPCO$ (\cref{alg:extend-pc-online}), which is used to extend a set of policy covers from layers $1,\dots,h$ to layer $h+1$. We describe $\EPCO$ first, and then explain how it fits into $\PCO$. As discussed in \cref{sec:online}, $\PCO$ is a direct extension (and, from the perspective of oracles, a simplification) of $\HOMER$ \citep{misra2020kinematic}; we highlight relevant differences in the overview below.

\colt{\input{alg_pco}}

\subsubsection{$\EPCO$: Extending a Policy Cover.} 

\paragraph{Algorithm overview.} As shown in \cref{alg:extend-pc-online}, $\EPCO$ takes as input a two-context regression oracle $\Reg$, a step $h \in [H]$, and a set of policy covers $\Psi_{1:h}$ (as well as several other inputs that will be discussed later as necessary---for now, consider the case $\Gamma = \emptyset$). The desired behavior of $\EPCO$ is that, if $\Psi_{1:h}$ are $(1,\epsilon)$-policy covers for layers $1,\dots,h$ of the MDP $M$ (as defined in \cref{eq:rfrl-pc}), then the output $\Psi_{h+1}$ should be a $(1,\epsilon)$-policy cover for layer $h+1$.

To this end, for each action $a \in \MA$, the algorithm first uses $\Psi_h$ to construct a two-context regression dataset $\MD_a$, via a contrastive learning approach where datapoints $(x_h,x_{h+1})$ with label $y=0$ are sampled independently, whereas datapoints with label $y=1$ are sampled dependently according to the transition dynamics, i.e. $x_{h+1} \sim \BP_{h+1}(\cdot\mid{}x_h,a)$ (in both cases, and throughout the rest of the algorithm, the algorithm rolls in to step $h$ with a random policy from $\Psi_h$). The algorithm then invokes $\Reg$ to compute a predictor $\wh f_{h+1}(\cdot,\cdot;a)$. It can be checked that the Bayes predictor $\EE[y\mid{}x_h,x_{h+1}]$ for this dataset is precisely the kinematics function from $f_{h+1}(\cdot,\cdot;a)$ from \cref{eq:kinematics-intro}. By the Block MDP assumption, this function only depends on $(x_h,x_{h+1})$ through $\phi^\st(x_h)$ and $\phi^\st(x_{h+1})$ (and the distribution of $(x_h,x_{h+1})$ is $\phi^\st$-realizable), so it follows from the guarantee of $\Reg$ that $\wh f_{h+1}(\cdot,\cdot;a)$ approximates the true kinematics function $f_{h+1}(\cdot,\cdot;a)$ with high probability.

Second, the algorithm samples $m$ observations $x_h^{(1)},\dots,x_h^{(m)}$ at step $h$, which will be used as ``test observations'' for evaluating $\wh f_{h+1}$: the idea is that if 
\[\wh f_{h+1}(x_h^{(i)}, x_{h+1};a) \approx \wh f_{h+1}(x_h^{(i)}, x'_{h+1};a)\]
for some $x_{h+1},x'_{h+1}\in\MX$ and all $i \in [m]$ and $a \in \MA$, then so long as these observations have appropriate coverage, in fact $\wh f_{h+1}(x_h,x_{h+1};a)$ should approximate $\wh f_{h+1}(x_h,x'_{h+1};a)$ for all $(x_h,a) \in \MX\times\MA$, i.e. $x_{h+1}$ and $x'_{h+1}$ should have approximately the same kinematics.

Third, the algorithm samples $n$ observations $\xbar_{h+1}^{(1)},\dots,\xbar_{h+1}^{(n)}$ at step $h+1$ (rolling in with a random policy from $\Psi_h$ followed by a random action at step $h$). These observations will serve as candidate ``cluster centers'' for defining internal reward functions. In particular, for each $t \in [n]$, the reward function $\MR^{(t)}:\MX\to[0,1]$ is defined in \lineref{line:rt-def-online} to be large precisely for those $x_{h+1}$ satisfying
\[\wh f_{h+1}(x_h^{(i)}, x_{h+1};a) \approx \wh f_{h+1}(x_h^{(i)}, \xbar_{h+1}^{(t)};a)\]
for all test observations $x_h^{(i)} \in \MX$ and actions $a \in \MA$.

Fourth, for each cluster center that has noticeably different kinematics from previous centers (measured in the same way as above), the algorithm invokes $\PSDP$ (\cref{alg:psdpb}) to compute a policy $\pihat^{(t)}$ that approximately maximizes the reward function $\MR^{(t)}$. This policy is added to $\Psi_{h+1}$.

\paragraph{Comparison with $\HOMER$.} The main differences between $\EPCO$ and the corresponding subroutine of $\HOMER$ arise in ensuring that $\EPCO$ is oracle-efficient with respect to two-context regression: in the first step, we perform an individual regression for each action $a$ (whereas $\HOMER$ performs a single regression joint across all actions), since in our definition of two-context regression, the action is not a covariate. Also, $\HOMER$ uses an implementation of $\PSDP$ with a cost-sensitive classification oracle; it is unclear how to reduce this to two-context regression, so we instead use an implementation of $\PSDP$ due to \cite{mhammedi2023representation}---see \cref{alg:psdpb}. For this implementation, a \emph{one}-context regression oracle suffices (\cref{lemma:psdp-trunc-online}), and this oracle in turn can easily be implemented---via the reduction $\OneTwo$ (\cref{alg:onetwo})---with two-context regression.

\paragraph{Proof outline.} Since $\EPCO$ is very similar (at a technical level) to the corresponding subroutine of $\HOMER$, we do not belabor the details of the proof in this overview. The basic reason why optimizing the reward functions $\MR^{(t)}$ is a good idea is the following. First, if two observations $x_{h+1},x'_{x+1}$ have the same latent state, then they have the same kinematics, i.e. $f_{h+1}(x_h,x_{h+1};a) = f_{h+1}(x_h,x_{h+1}';a)$ for all $x,a$. The converse is not necessarily true. However, something just as good is true: if two states $x_{h+1},x'_{h+1}$ have the same kinematics, then $d^{M,\pi}_{h+1}(x_{h+1}) = C \cdot d^{M,\pi}_{h+1}(x'_{h+1})$ for a constant $C$ that may depend on $x_{h+1}$ and $x'_{h+1}$ but \emph{does not depend on $\pi$}. In this sense, $x_{h+1}$ and $x'_{h+1}$ are ``kinematically inseparable'' \citep{misra2020kinematic}. It follows that the policy that maximizes $d^{M,\pi}_{h+1}(x_{h+1}) + d^{M,\pi}_{h+1}(x'_{h+1})$, i.e. the probability of visiting one of these two observations, also maximizes the probability of visiting either individual observation. More generally, for any set of kinematically inseparable observations, it suffices to maximize a reward function that rewards visiting any of these observations. 

Obviously, in the actual algorithm and actual reward functions there are statistical errors, but these can be handled under appropriate coverage conditions. Indeed, under a \emph{reachability assumption} on the MDP, \cite{misra2020kinematic} show that if $\Psi_{1:h}$ are $(1,\epsilon)$-policy covers for layers $1,\dots,h$, then with high probability $\Psi_{h+1}$ is a $(1,\epsilon)$-policy cover for layer $h+1$. Thus, they can simply run $\EPCO$ iteratively from $h=1,\dots,H$ and produce a set of policy covers $\Psi_{1:H}$. However, we want to avoid making a reachability assumption, so we require a more sophisticated algorithm (which still uses $\EPCO$ as a subroutine)---this is precisely $\PCO$.

We formally analyze $\EPCO$ in \cref{subsec:epco}; the main guarantee is \cref{thm:extend-pc-trunc-online}.

\subsubsection{$\PCO$: Handling Reachability Issues via Iterative Discovery}

\paragraph{Algorithm overview.} The basic idea of $\PCO$ (\cref{alg:pco}) is to essentially put an outer loop around the entire $\HOMER$/$\EPCO$ algorithm; this technique was previously used by \cite{golowich2024exploring} for the same reason of handling reachability issues, in the context of sparse linear MDPs. In particular, $\PCO$ proceeds in $R= |\MS| \cdot H$ rounds. In the first round, $\PCO$ runs $\EPCO$ iteratively from $h=1,\dots,H$ to construct a set of candidate policy covers $\Psi_{1:H}^{(1)}$. It then adds all of these computed policies to a ``backup policy cover'' $\Gamma^{(2)}$, and passes $\Gamma^{(2)}$ to $\EPCO$ in the next round. The outputs of $\EPCO$ are added to $\Gamma^{(3)}$, which is the backup policy cover for round $r=3$, and so forth. The final output of $\PCO$ is the union of all candidate policy covers (of bounded size) that were computed in all rounds. 

\paragraph{Proof outline.} We sketch why the outer loop in $\PCO$ is needed to avoid a reachability assumption (and why it works). Reachability assumptions are common in theoretical reinforcement learning \citep{du2019provably,misra2020kinematic}, but are often an artifact of the analysis. That is, they can often be avoided---without changing the algorithm---by analyzing \emph{truncated MDPs/policies} \citep{golowich2022learning,mhammedi2023efficient}, which essentially avoid issues of compounding errors on hard-to-reach states by truncating away such states. This approach would work in our setting if the reward functions $\MR^{(t)}$ were exact, and hence accurate on all states. However, in $\EPCO$/$\HOMER$, the reward functions are \emph{learned}, so they could be inaccurate on hard-to-reach states (in \cref{lemma:target-error-online}, notice that the error bound holds in expectation over the truncated MDP $\Mbar(\Gamma)$, which doesn't include the hard to reach states from the actual MDP $M$). This means that the policies computed by $\PSDP$ could obtain erroneously high reward without actually being optimal for the ``ideal'' reward functions.

The key idea is that the above pathology only occurs if one of the policies computed by $\PSDP$ ``discovers'' a state that the algorithm previously was unable to cover. This is the motivation for rerunning the entire algorithm with these policies mixed into all data collection procedures via the backup policy cover $\Gamma$. By a win/win argument \citep{golowich2024exploring}, after at most $R = H|\MS|$ rounds, there will be some round $r$ in which the algorithm does not discover any new states; it can be shown that the sets $\Psi^{(r)}_{1:H}$ constructed in this round are indeed policy covers. We discuss this win/win argument in more detail later.

We formally analyze $\PCO$ (and thereby prove \cref{thm:pco-app}) in \cref{sec:pco-analysis}.

%As discussed in \cref{sec:online}, the algorithm $\PCO$ (\cref{alg:pco}) both generalizes and (with respect to the needed oracles) simplifies $\HOMER$ \citep{misra2020kinematic}, but the key ideas are the same. At an algorithmic and technical level, the main difference is the following. In $\PCO$, there is an inner loop over the $H$ layers of the MDP, and an outer loop over $R$ rounds, which builds up ``backup'' policy covers $\Gamma^{(1)} \subseteq \dots \subseteq \Gamma^{(R)}$. In contrast, $\HOMER$ only uses the inner loop; it simply builds the policy covers $\Psi^{(1)}_1,\dots,\Psi^{(1)}_H$ layer-by-layer and then outputs these sets. The reason for this difference is that \cite{misra2020kinematic} make a \emph{reachability} assumption on the MDP, which asserts that every latent state is reachable with non-trivial probability. Under this assumption, it can be shown that $\Psi^{(1)}_{1:H}$ satisfy the coverage requirement of \cref{def:strong-rf-rl} with high probability. However, without the reachability assumption, it is possible that $\Psi^{(1)}_{1:H}$ could fail to satisfy the coverage requirement. The outer loop ensures that even in this case, progress is still made. We discuss this win-win argument more formally later; it was previously used by \cite{golowich2024exploring} in the context of \emph{sparse linear MDPs}.

%\paragraph{The inner loop: extending the policy cover.} For a fixed round $r$, $\PCO$ follows a layer-by-layer approach that is by now standard in oracle-efficient RL: start with a trivial policy cover for the first layer, and for each subsequent layer $h+1$, construct a policy cover $\Psi^{(r)}_{h+1}$ for that layer assuming that $\Psi^{(r)}_{1:h}$ are policy covers for the first $h$ layers \citep{du2019provably,misra2020kinematic,mhammedi2023representation}. In $\PCO$, the subroutine that performs this task of extending the set of policy covers is $\EPCO$ (\cref{alg:extend-pc-online}), for which we prove the following guarantee:







\iffalse
We define truncated block MDPs $\Mbar_1,\dots,\Mbar_H$ with horizon $H$, latent state space $\Sbar := \MS \cup \{\term\}$, observation space $\Xbar := \MX \cup \{\term\}$, and action space $\MA$ as follows. 

\begin{definition}
Let $\lamrch = (\lamrch,\dots,\lamrch_H)$ for some given functions $\lamrch_2,\dots,\lamrch_H: \MS \to [0,1]$. The $\lamrch$-truncation of $M$ is the block MDP $(H, \Sbar,\Xbar,A,(\Pbar_h)_{h\in[H]},(\Obar_h)_{h\in[H]})$ with latent state space $\Sbar := \MS \cup \{\term\}$, emission space $\Xbar := \MX \cup \{\term\}$, emission distribution
\[\Obar_h(x|s) := \begin{cases} \BO_h(x|s) & \text{ if } x \in \MX, s \in \MS \\ 1 & \text{ if } x=s=\term \\ 0 & \text{ otherwise} \end{cases},\]
initial state distribution $\Pbar_1 := \BP_1$, and transition distribution
\[\Pbar_h(s_h|s_{h-1},a) := \begin{cases} \lamrch_h(s_h) \BP_h(s_h|s_{h-1},a) & \text{ if } s_{h-1} \in \MS, s_h \in \MS \\ \sum_{z \in \MS} (1-\lamrch_h(z)) \BP_h(z|s_{h-1},a) &\text{ if } s_{h-1} \in \MS, s_h = \term \\ \mathbbm{1}[s_h=\term] & \text{ if } s_{h-1} = \term \end{cases} \]
for each $h \in \{2,\dots,h\}$.
\end{definition}

Fix a parameter $\sigma > 0$ and a finite set of policies $\Gamma \subset \Pi$. We inductively define functions $\lamrch_2(\Gamma),\dots,\lamrch_H(\Gamma)$ and truncated block MDPs $\Mbar_1(\Gamma),\dots,\Mbar_H(\Gamma)$ as follows. First, let $\Mbar_1(\Gamma)$ be the $(\MS,\dots,\MS)$-truncation of $M$. Next, for each $h \in \{2,\dots,H\}$, define \[\Srch_h := \{s \in \MS: \max_{\pi\in\Pi} d^{\Mbar_{h-1}, \pi}_h(s) \geq \trunc\}\]
and \[\Srch_h(\Gamma) := \Srch_h \cup \left\{s \in \MS: \EE_{\pi\sim\Unif(\Gamma)} d^{M,\pi}_h(s) \geq \tsmall\right\}.\]
Define $\lamrch_h: \MS \to [0,1]$ by 
\[\lamrch_h(s) := 
\begin{cases} 
1 & \text{ if } s \in \Srch_h \\
\trunc^2 & \text{ if } s \in \Srch_h(\Gamma) \setminus \Srch_h \\ 
0 & \text{ otherwise} 
\end{cases}.\]
Then we let $\Mbar_h(\Gamma)$ be the $(\lamrch_2(\Gamma),\dots,\lamrch_h(\Gamma),\MS,\dots,\MS)$-truncation of $M$. Finally, define $\Mbar(\Gamma) := \Mbar_H(\Gamma)$.
\fi



\iffalse
\begin{definition}
For $s,s' \in \MS$, $h \in [H]$, and $L \subseteq \MS$, define
\[\DKI_h(s;s';T) := \inf_{\lambda>0} \max_{(s_h,a_h) \in L\times\MA} \left|\BP^M_h[s|s_h,a_h] - \frac{\BP^M_h[s'|s_h,a_h]}{\lambda}\right|.\]
\end{definition}

Fix a parameter $\sigma > 0$ and finite sets of policies $\Gamma,\Gamma' \subset \Pi$. We inductively define sets $\Srch_2(\Gamma;\Gamma'),\dots,\Srch_H(\Gamma;\Gamma')$ and truncated block MDPs $\Mbar_1(\Gamma;\Gamma'),\dots,\Mbar_H(\Gamma;\Gamma')$ as follows. First, let $\Mbar_1(\Gamma;\Gamma')$ be the $(\MS,\dots,\MS)$-truncation of $M$. Next, for each $h \in \{2,\dots,H\}$, define 
\begin{align*}
\Srchhi_h(\Gamma') &:= \{s \in \MS: \max_{\pi\in\Pi} d^{\Mbar_{h-1}(\emptyset;\Gamma'), \pi}_h(s) \geq \trunc\} \\ 
\Srchki_h(\Gamma',\gamki) &:= \left\{s \in \MS: \left(\max_{\pi\in\Pi} d^{\Mbar_{h-1}(\emptyset;\Gamma'), \pi}_h(s) \geq \trunc^2\right) \land \left(\exists s^\st \in \Srchhi_h(\Gamma') \text{ with } \DKI_h(s;s^\st;\Srch_{h-1}(\Gamma';\Gamma')) \leq \gamki\right)\right\} \\ 
\Srchgam_h(\Gamma) &:= \left\{s \in \MS: \EE_{\pi\sim\Unif(\Gamma)} d^{M,\pi}_h(s) \geq \tsmall\right\}.
\end{align*}
and 
\begin{align*}
\Srch_h(\Gamma;\Gamma') := \Srchhi_h(\Gamma') \cup \Srchki_h(\Gamma',\gamki) \cup \Srchgam(\Gamma).
\end{align*}
Then we let $\Mbar_h(\Gamma;\Gamma')$ be the $(\Srch_2(\Gamma;\Gamma'),\dots,\Srch_h(\Gamma;\Gamma'),\MS,\dots,\MS)$-truncation of $M$. Finally, define $\Mbar(\Gamma;\Gamma') := \Mbar_H(\Gamma;\Gamma')$.
\fi
\subsection{Analysis of $\EPCO$ (\creftitle{alg:extend-pc-online})}\label{subsec:epco}

We now prove the following guarantee for $\EPCO$ (\cref{alg:extend-pc-online}). Recall that we have fixed a concept class $\Phi$, a $\Nreg$-efficient two-context regression oracle $\Reg$, and a $\Phi$-decodable block MDP $M$ with horizon $H$, action set $\MA$, and unknown decoding function $\phi^\st \in \Phi$. We have also defined truncations of $M$ (see \cref{sec:truncated-mdps}), with the parameters $\trunc,\tsmall>0$ as defined in \cref{alg:pco}.

\begin{theorem}\label{thm:extend-pc-trunc-online}
Let $h \in \{1,\dots,H-1\}$. Let $\epsilon,\delta,\alpha > 0$ and $m,n,N \in \NN$. Let $\Gamma \subset \Pi$ be a finite set of policies. Suppose that $\Psi_{1:h}$ are $\alpha$-truncated policy covers (\cref{defn:trunc-pc}) for $M$ at steps $1,\dots,h$. Suppose that $m \geq \frac{2}{\min(\alpha\trunc,\tsmall)}\log(|\MS|/\delta)$, $n \geq \frac{2|\MA|}{\min(\alpha\trunc,\tsmall)\trunc} \log(|\MS|/\delta)$, $N \geq \Nreg(\epsilon,\delta)$, and 
\begin{equation} \epsilon^{1/16} \leq \frac{\alpha^2\trunc^4\tsmall^2}{96H|\MS||\MA|^2\sqrt{m}}.\label{eq:param-assm-online}
\end{equation}
Set $\gamma := \epsilon^{1/16}$ and $\gamma' := 2\epsilon^{1/8}\sqrt{m|\MA|}$ and let $\Psi_{h+1}$ denote the output of $\EPCO$ with inputs $\Reg,h,\Psi_{1:h},\Gamma,n,m,N,\gamma,\gamma'$. Then with probability at least $1 - (2+|\MA|+H|\MA|n)\delta - m|\MA|\epsilon^{1/2} - n\epsilon^{1/4}$, the following two properties hold:
\begin{itemize}
\item $|\Psi_{h+1}| \leq |\MS|$.
\item Either $\Psi_{h+1}$ is a $(1-4\trunc)$-truncated max policy cover (\cref{defn:trunc-max-pc}) for $M$ at step $h+1$, or $\max_{\pi\in\Psi_{h+1}} d^{\Mbar(\Gamma),\pi}_{h+1}(\term) \geq \trunc^2$.
\end{itemize}
\end{theorem}

Informally, $\Mbar(\Gamma)$ refers to a \emph{truncation} of the MDP $M$ in which all latent states that (a) cannot be reached by any policy with probability at least $\trunc$, and (b) cannot be reached by a uniformly random policy in $\Gamma$ with probability at least $\tsmall \ll \trunc$, are ``truncated away'' to an artificial terminal state $\term$. A truncated policy cover (\cref{defn:trunc-pc}) is essentially a set of policies $\Psi$ so that for each latent state $s$ that \emph{can} be reached with probability at least $\trunc$, a \emph{uniformly random} policy from $\Psi$ covers $s$. A truncated max-policy cover (\cref{defn:trunc-max-pc}) is essentially a set of policies so that for each latent state $s$ that \emph{can} be reached with probability at least $\trunc$, the \emph{best} policy from $\Psi$ covers $s$. See \cref{sec:truncated-mdps} for the formal definition of $\Mbar(\Gamma)$ and the truncated policy covers.

With this notation, \cref{thm:extend-pc-trunc-online} essentially asserts that if $\Psi_{1:h}$ are policy covers at steps $1,\dots,h$, then the output of $\EPCO$ is either a policy cover at step $h+1$, or else contains some policy $\pi$ that visits the terminal state in $\Mbar(\Gamma)$ with non-trivial probability. In this second case, it can be shown (via \cref{lemma:term-prob} and the definition of $\Srch_k(\Gamma)$) that $\pi$ visits some latent state in $M$ that was previously nearly-unexplored by all policies in $\Gamma$. Hence, when $\PCO$ adds $\pi$ to the backup policy cover $\Gamma^{(r+1)}$ in the next round, progress will have been made, and so this second case can only happen a bounded number of times---see the proof of \cref{thm:pco-app} in \cref{sec:pco-analysis}.

%This argument is formalized in \cref{sec:pco-analysis}, where we prove \cref{thm:pco-app} using \cref{thm:extend-pc-trunc-online}. In the interim, we analyze $\EPCO$ and prove \cref{thm:extend-pc-trunc-online}.

Let us fix the inputs to $\EPCO$: in addition to the two-context regression oracle $\Reg$ (\cref{def:two-con-regression}), we fix a layer $h \in [H-1]$, sets of policies $\Psi_1,\dots,\Psi_h$ and $\Gamma$, sample counts $n,m,N \in \NN$, and tolerances $\gamma,\gamma' \in (0,1)$. As discussed above, the main idea of $\EPCO$ is to use the oracle to estimate the kinematics $f_{h+1}: \MS\times\MS\times\MA \to [0,1]$ (defined informally in \cref{eq:kinematics-intro} and formally below), and then to apply the $\PSDP$ policy optimization method (\cref{alg:psdpb}) on internal reward functions constructed by clustering the kinematics.

\begin{definition}\label{def:kinematics}
For any $s,s' \in \MS$ and $a \in \MA$, define 
\[f_{h+1}(s,s';a) := \frac{\til\BP^M_{h+1}(s'\mid{}s,a)}{\til\BP^M_{h+1}(s'\mid{}s,a) + F_{h+1}(s')}\]
where 
\[F_{h+1}(s') := \EE_{\pi \sim \frac{1}{2}(\Unif(\Psi_h)+\Unif(\Gamma))\circ_h\Unif(\MA)} \E^{M,\pi}[\til\BP^M_{h+1}(s'\mid{}s_h,a_h)].\] 
\end{definition}

The main technical lemmas in the analysis are (1) \cref{lemma:regression-bound-online}, which shows that the regression problem solved in \lineref{line:hat-f-regression} is a realizable instance of two-context regression, and that the resulting estimator $\wh f_{h+1}$ is therefore a good estimate of $f_{h+1}$; and (2) \cref{lemma:target-error-online}, which shows that if $\wh f_{h+1}$ is close to $f_{h+1}$ then for any reachable latent state $s^\st$, there is some internal reward function $\MR^{(t)}$ computed by $\EPCO$ that approximately optimizes for visiting state $s^\st$. The following notation will be useful: 

\begin{definition}\label{def:marginals}
Let $\mu_{h+1}(a) \in \Delta(\MX\times\MX)$ be the marginal distribution of $(x_h,x_{h+1})$ where $(x_h,x_{h+1},y)$ is the first element of $\MD_a$. Let $\beta_h,\beta_{h+1} \in \Delta(\MS)$ be the marginal distributions of $s_h$ and $s_{h+1}$ respectively, for a trajectory $(s_1,x_1,a_1,\dots,s_{h+1},x_{h+1}) \sim \frac{1}{2}(\Unif(\Psi_h)+\Unif(\Gamma))\circ_h\Unif(\MA)$.
\end{definition}

In words, $\beta_h$ is the visitation distribution at step $h$ of a uniformly random policy $\pi \sim \frac{1}{2}(\Unif(\Psi_h)+\Unif(\Gamma))$, and $\beta_{h+1}$ is the visitation distribution at step $h+1$ obtained by sampling from $x_h \sim \beta_h$, $a_h \sim \Unif(\MA)$, and $x_{h+1} \sim \BP^M_{h+1}(\cdot\mid{}x_h,a_h)$.

We now prove that $\wh f_{h+1}$ approximates the true kinematics $f_{h+1}$ with high probability. This requires checking that each dataset $\MD_a$ constructed by $\EPCO$ satisfies the necessary realizability assumptions, specified in \cref{def:two-con-regression}, with respect to $\Phi$. \cref{item:reg-1-online} is then a direct consequence of the guarantee of $\Reg$ (together with a union bound over actions). \cref{item:reg-2-online} is a useful consequence, which asserts that if we plug in the $m$ ``test observations'' $x_h^{(1)},\dots,x_h^{(m)}$ sampled by $\EPCO$, and all $|\MA|$ actions, the resulting $m|\MA|$-dimensional vector $\wh f_{h+1}(x_h^{(i)},x_{h+1};a)_{i,a}$ is close to the corresponding ``true'' vector $f_{h+1}(\phi^\st(x_h^{(i)}),\phi^\st(x_{h+1});a)_{i,a}$ on average over $x_{h+1}$. This will be needed in \cref{lemma:target-error-online} since ultimately the reward functions $\MR^{(t)}$ are constructed by clustering these vectors.

\begin{lemma}\label{lemma:regression-bound-online}
Let $\epsilon,\delta,\delta' \in (0,1)$. Suppose that $\Reg$ is an $\Nreg$-efficient two-context regression oracle for $\Phi$, and $N \geq \Nreg(\epsilon,\delta)$. Then:
\begin{enumerate}
\item \label{item:reg-1-online} With probability at least $1-\delta|\MA|$, it holds that for all $a \in \MA$,
\[\EE_{(x_h,x_{h+1}) \sim \til\BO_h\beta_h \times \til\BO_{h+1}\beta_{h+1}}\left(\wh f_{h+1}(x_h,x_{h+1};a) - f_{h+1}(\phi^\st(x_h),\phi^\st(x_{h+1});a)\right)^2 \leq 2\epsilon.\]
\item \label{item:reg-2-online} With probability at least $1-\delta|\MA|-\delta'\cdot m|\MA|$, it holds that
\[\EE_{x_{h+1}\sim\til\BO_{h+1}\beta_{h+1}} \max_{(i,a)\in [m]\times\MA} \left(\wh f_{h+1}(x_h^{(i)},x_{h+1};a) - f_{h+1}(\phi^\st(x_h^{(i)}),\phi^\st(x_{h+1});a)\right)^2 \leq \frac{2\epsilon m|\MA|}{\delta'}.\]
\end{enumerate}
\end{lemma}

\begin{proof}
To prove the first claim, fix any $a \in \MA$. The dataset $\MD_a$ constructed by \cref{alg:extend-pc-online} consists of $N$ independent and identically distributed tuples $(x_h^{(i)},x_{h+1}^{(i)},y^{(i)})$. Fix any $i \in [N]$ and let $\mu_0 \in \Delta(\MX\times\MX)$ be the probability density function of $(x_h^{(i)},x_{h+1}^{(i)})$ conditioned on $y^{(i)} = 0$. Similarly, let $\mu_1 \in \Delta(\MX\times\MX)$ be the probability density function of $(x_h^{(i)},x_{h+1}^{(i)})$ conditioned on $y^{(i)} = 1$. For any $x,x' \in \MX$,
\begin{equation} \mu_0(x,x') = \beta_h(\phi^\st(x)) \til\BO_h(x\mid{}\phi^\st(x)) \EE_{(s,\tilde a)\sim \beta_h\times\Unif(\MA)} \til\BP^M_{h+1}(\phi^\st(x')\mid{}s,\tilde a)\til\BO_{h+1}(x'\mid{}\phi^\st(x'))\label{eq:mu0-density}\end{equation}
and
\[\mu_1(x,x') = \beta_h(\phi^\st(x)) \til\BO_h(x\mid{}\phi^\st(x)) \til\BP^M_{h+1}(\phi^\st(x')\mid{}\phi^\st(x),a) \til\BO_{h+1}(x'\mid{}\phi^\st(x')).\]
The unconditional probability density function of $(x_h^{(i)},x_{h+1}^{(i)})$ is therefore $\mu \in \Delta(\MX\times\MX)$ defined as
\begin{align*}
&\mu(x,x')  \\
&= \frac{\mu_0(x,x')+\mu_1(x,x')}{2} \\ 
&= \frac{\beta_h(\phi^\st(x))\til\BO_h(x\mid{}\phi^\st(x))}{2}\Bigg(\til\BP^M_{h+1}(\phi^\st(x')\mid{}\phi^\st(x),a) \til\BO_{h+1}(x'\mid{}\phi^\st(x')) \\
&\hspace{10em}+ \EE_{(s,\tilde a)\sim \beta_h\times\Unif(\MA)} \til\BP^M_{h+1}(\phi^\st(x')\mid{}s,\tilde a)\til\BO_{h+1}(x'\mid{}\phi^\st(x'))\Bigg) \\ 
&= \frac{\beta_h(\phi^\st(x))\til\BO_h(x\mid{}\phi^\st(x))}{2}\left(\til\BP^M_{h+1}(\phi^\st(x')\mid{}\phi^\st(x),a)  + \EE_{(s,\tilde a)\sim \beta_h\times\Unif(\MA)} \til\BP^M_{h+1}(\phi^\st(x')\mid{}s,\tilde a)\right) \\
&\hspace{10em} \cdot \til\BO_{h+1}(x'\mid{}\phi^\st(x')).
\end{align*}
From this expression it is clear that, for any $s \in \MS$, conditioned on the event $\phi^\st(x) = s$, $x_h^{(i)}$ and $x_{h+1}^{(i)}$ are independent. Moreover, for any $s \in \MS$, conditioned on the event $\phi^\st(x') = s$, $x_h^{(i)}$ and $x_{h+1}^{(i)}$ are independent. We conclude that $\mu$ is $\phi^\st$-realizable (\cref{def:realizable-distribution}). Next, for any $x,x' \in \MX$, note that
\begin{align*}
\E[y^{(i)}\mid{}x_h^{(i)}=x,x_{h+1}^{(i)}=x']
&= \frac{\mu_1(x,x')}{\mu_0(x,x') + \mu_1(x,x')} \\ 
&= \frac{\til\BP^M_{h+1}(\phi^\st(x')\mid{}\phi^\st(x),a)}{\til\BP^M_{h+1}(\phi^\st(x')\mid{}\phi^\st(x),a) + \EE_{(s,\tilde a)\sim\beta_h\times\Unif(\MA)} \til\BP^M_{h+1}(\phi^\st(x')\mid{}s,\tilde a)} \\ 
&= f_{h+1}(\phi^\st(x),\phi^\st(x');a)
\end{align*}
by \cref{def:kinematics}. Hence, we can apply the guarantee of $\Reg$ (\cref{def:two-con-regression}) with distribution $\mu$ and ground truth predictor $f_{h+1}$. We get that with probability at least $1-\delta$,
\[\EE_{(x_h,x_{h+1}) \sim \mu} \left(\wh f_{h+1}(x_h,x_{h+1};a) - f_{h+1}(\phi^\st(x_h),\phi^\st(x_{h+1});a)\right)^2 \leq \epsilon.\]
But $\mu(x,x') \geq \frac{1}{2}\mu_0(x,x') = \frac{1}{2}\BO_h \beta_h \times \BO_{h+1} \beta_{h+1}$ by \cref{eq:mu0-density} and definition of $\beta_{h+1}$. The first claim of the lemma statement follows.

In the event that the first claim holds, for each $i \in [m]$ and $a \in \MA$, since $x_h^{(i)}$ has distribution $\BO_h\beta_h$, 
Markov's inequality gives that with probability at least $1-\delta'$,
\[\EE_{x_{h+1} \sim \BO_{h+1}\beta_{h+1}}\left(\wh f_{h+1}(x_h^{(i)},x_{h+1};a) - f_{h+1}(\phi^\st(x_h^{(i)}),\phi^\st(x_{h+1});a)\right)^2 \leq \frac{2\epsilon}{\delta'}.\]
By a union bound, we have with probability at least $1-\delta'm|\MA|$ that 
\[\sum_{(i,a)\in[m]\times\MA} \EE_{x_{h+1} \sim \BO_{h+1}\beta_{h+1}}\left(\wh f_{h+1}(x_h^{(i)},x_{h+1};a) - f_{h+1}(\phi^\st(x_h^{(i)}),\phi^\st(x_{h+1});a)\right)^2 \leq \frac{2\epsilon m|\MA|}{\delta'}.\]
Exchanging the summation and expectation completes the proof of the second claim.
\end{proof}

\iffalse
\begin{lemma}\label{lemma:cover-implications}
Suppose that $\Psi_h$ is an $\alpha$-truncated policy cover for $M$ at step $h$. Then the induced distributions $\beta_h,\beta_{h+1}$ (\cref{def:marginals}) satisfy:
\begin{enumerate}
\item For all $s_h \in \Srch_h(\Gamma)$, \[\beta_h(s_h) \geq \frac{\min(\alpha\trunc,\tsmall)}{2}.\]
 \item For all $s_{h+1} \in \MS$.
\[\beta_{h+1}(s_{h+1}) \geq \frac{\min(\alpha\trunc,\tsmall)}{2|\MA|} \max_{\pi\in\Pi} d^{\Mbar(\Gamma),\pi}_{h+1}(s_{h+1}).\]
\end{enumerate}
\end{lemma}

\begin{proof}
If $s_h \in \Srch_h$, then $\max_{\pi\in\Pi} d^{\Mbar(\emptyset),\pi}_h(s_h) \geq \trunc$ (\cref{fact:trunc-reachability}). Thus $\E_{\pi\sim\Psi_h} d^{M,\pi}_h(s_h) \geq \alpha\trunc$. On the other hand, if $s_h \in \Srch_h(\Gamma)\setminus\Srch_h$, then $\E_{\pi\sim\Unif(\Gamma)} d^{M,\pi}_h(s) \geq \tsmall$. In either case,
\[\beta_h(s) = \frac{1}{2}\EE_{\pi\sim\Unif(\Psi_h)} d^{M,\pi}_h(s) + \frac{1}{2}\EE_{\pi\sim\Unif(\Gamma)} d^{M,\pi}_h(s) \geq \frac{\min(\alpha\trunc,\tsmall)}{2}\]
as claimed. Next, let $s_{h+1} \in \MS$. If $s_{h+1} \in \Srch_{h+1}(\Gamma)$, then for any $\pi \in \Pi$,
\begin{align*}
\beta_{h+1}(s_{h+1})
&= \sum_{s_h \in \MS} \beta_h(s_h) \frac{1}{|\MA|}\sum_{a \in \MA} \BP^M(s_{h+1}\mid{}s_h,a) \\ 
&\geq \sum_{s_h \in \MS} \beta_h(s_h) \frac{1}{|\MA|} \BP^M(s_{h+1}\mid{}s_h,\pi(s_h)) \\
&\geq \frac{\min(\alpha\trunc,\tsmall)}{2}\sum_{s_h\in\Srch_h(\Gamma)} d^{\Mbar(\Gamma),\pi}_h(s_h) \frac{1}{|\MA|} \BP^M(s_{h+1}\mid{}s_h,\pi(s_h)) \\
&= \frac{\min(\alpha\trunc,\tsmall)}{2|\MA|} d^{\Mbar(\Gamma),\pi}_{h+1}(s_{h+1}).
\end{align*}
Moreover, if $s_{h+1} \not \in \Srch_{h+1}(\Gamma)$ then $\max_{\pi\in\Pi} d^{\Mbar(\Gamma),\pi}_{h+1}(s_{h+1}) = 0$, so the inequality is vacuously true.
\end{proof}
\fi

\noindent To prove \cref{lemma:target-error-online}, we need the following preparatory results.

\begin{lemma}\label{lemma:f-ub}
Let $s,s' \in \MS$ and $a \in \MA$. Then 
\[1-f_{h+1}(s,s';a) \geq \frac{\beta_h(s)}{2|\MA|}.\]
\end{lemma}

\begin{proof}
Observe that
\begin{align*}
F_{h+1}(s')
&= \EE_{\pi \sim \frac{1}{2}(\Unif(\Psi_h)+\Unif(\Gamma))\circ_h\Unif(\MA)} \E^{M,\pi}[\til\BP^M_{h+1}(s'\mid{}s_h,a_h)] \\
&\geq \frac{1}{|\MA|} \EE_{\pi \sim \frac{1}{2}(\Unif(\Psi_h)+\Unif(\Gamma))} \E^{M,\pi}[\til\BP^M_{h+1}(s'\mid{}s_h,a)] \\ 
&= \frac{1}{|\MA|} \sum_{s_h \in \MS} \beta_h(s_h) \til\BP^M_{h+1}(s'\mid{}s_h,a) \\ 
&\geq \frac{\beta_h(s)}{|\MA|} \til\BP^M_{h+1}(s'\mid{}s,a).
\end{align*}
It follows that
\begin{align*}
1 - f_{h+1}(s,s';a)
&= \frac{F_{h+1}(s')}{\til\BP^M_{h+1}(s'\mid{}s,a) + F_{h+1}(s')} \\ 
&\geq \frac{\beta_h(s)}{|\MA|} f_{h+1}(s',s;a).
\end{align*}
If $f_{h+1}(s',s;a) \geq 1/2$ then the claim follows; otherwise $1-f_{h+1}(s',s;a) \geq 1/2 \geq \beta_h(s)/(2|\MA|)$ as well.
\end{proof}

\begin{lemma}\label{lemma:lipschitz-bound}
Let $x,y \in [0,1)$. Then
\[\left|\frac{x}{1-x} - \frac{y}{1-y}\right| \leq \frac{2|x-y|}{\min\{1-x,1-y\}^2}.\]
\end{lemma}

\begin{proof}
Define $g: [0,1) \to \RR$ by $g(x) = x/(1-x)$. Then 
\[g'(x) = \frac{1}{1-x} + \frac{x}{(1-x)^2} \leq \frac{2}{(1-x)^2}.\]
Hence, $g'(w) \leq 2/\min\{1-x,1-y\}^2$ for all $w$ in the interval between $x$ and $y$. The lemma follows.
\end{proof}



The following key lemma states for any reachable latent state $s^\st$, there is some reward function $\MR^{(t)}$ so that, under any policy $\pi$, the expected value of $\pi$ under this reward function is roughly proportional to the visitation probability of $s^\st$. Intuitively, this is important because optimizing with respect to $\MR^{(t)}$ then approximately optimizes the probability of reaching $s^\st$. The key to the proof is \cref{eq:dpi-expansion-online}, which shows that for any other state $s$ which has roughly the same \emph{kinematics} as $s^\st$, the probability that any policy $\pi$ visits $s$ is proportional to the probability that $\pi$ visits $s^\st$ (where the constant of proportionality may depend on $s$ and $s^\st$ but not $\pi$).

\begin{lemma}\label{lemma:target-error-online}
Let $\epreg>0$. Condition on $\wh f_{h+1}$ and $x_h^{(1)},\dots,x_h^{(m)}$, and suppose that 
\begin{equation}\EE_{x_{h+1}\sim\BO_{h+1}\beta_{h+1}} \max_{(i,a)\in [m]\times\MA} \left(\wh f_{h+1}(x_h^{(i)},x_{h+1};a) - f_{h+1}(\phi^\st(x_h^{(i)}),\phi^\st(x_{h+1});a)\right)^2 \leq \epreg.\label{eq:reg-bound-applied}\end{equation}
Suppose that for each $s \in \Srch_h(\Gamma)$ there is some $i \in [m]$ with $\phi^\st(x^{(i)}) = s$. Suppose that $\beta_{h+1}(s) \geq \tilde \alpha \cdot \max_{\pi\in\Pi} d^{\Mbar(\Gamma),\pi}_{h+1}(s)$ for all $s \in \MS$. Then for any $t \in [n]$ and $s^\st \in \Srch_{h+1}(\Gamma)$, there is some $K = K(\Gamma,s^\st) \geq 1$ such that
\begin{align*}
&\max_{\pi\in\Pi} \left|\E^{\Mbar(\Gamma),\pi}[\MR^{(t)}(x_{h+1})] - K \cdot d^{\Mbar(\Gamma),\pi}_{h+1}(s^\st)\right| \\ 
&\leq \frac{8\gamma|\MS||\MA|^2}{\min_{s\in\Srch_h(\Gamma)}\beta_h(s)^2} + \frac{\sqrt{\epreg}}{\tilde \alpha \gamma} + \frac{\max_{(i,a)\in[m]\times\MA}\left|\wh f_{h+1}(x_h^{(i)},\bar x_{h+1}^{(t)};a) - f_{h+1}(\phi^\st(x_h^{(i)}),s^\st;a)\right|}{\gamma}
\end{align*}
where for notational convenience we take $\MR^{(t)}(\term) := 0$. %, and\[K(\Gamma,s^\st) := \frac{\sum_{s_{h+1}\in\Srch_{h+1}(\Gamma)} \lamrch_{h+1}(s_{h+1}) F_h(s_{h+1})g(\Delta(s_{h+1},s^\st))}{\lamrch_{h+1}(s^\st)F_h(s^\st)}.\]
\end{lemma}

\begin{proof}
First, observe that by the lemma assumption that $\beta_{h+1}(s) \geq \tilde \alpha \cdot \max_{\pi\in\Pi} d^{\Mbar(\Gamma),\pi}_{h+1}(s)$ for all $s \in \MS$, it follows that 
\begin{equation}
(\BO_{h+1}\beta_{h+1})(x) \geq \tilde \alpha \cdot \max_{\pi\in\Pi} d^{\Mbar(\Gamma),\pi}_{h+1}(x)
\label{eq:beta-x-lb}
\end{equation} 
for all $x \in \MX$. Now fix $\pi \in \Pi$. By definition of $\MR^{(t)}$ (\lineref{line:rt-def-online}), we have
\[\E^{\Mbar(\Gamma),\pi}[\MR^{(t)}(x_{h+1})] = \E^{\Mbar(\Gamma),\pi}\left[g\left(\max_{i,a}\left|\wh f_{h+1}(x_h^{(i)},\bar x_{h+1}^{(t)};a) - \wh f_{h+1}(x_h^{(i)},x_{h+1};a)\right|\right)\mathbbm{1}[s_{h+1} \in \MS]\right]\]
where $g(z) := \max(0,1-z/\gamma)$. For any $s,s' \in \MS$, define $\Delta(s,s') := \max_{i,a}|f(\phi^\st(x_h^{(i)}),s;a) - f(\phi^\st(x_h^{(i)}),s';a)|$. Then define 
\[W^\pi := \E^{\Mbar(\Gamma),\pi}[g(\Delta(s_{h+1},s^\st))\mathbbm{1}[s_{h+1}\in\MS]].\]
Then
\begin{align}
&\left|\E^{\Mbar(\Gamma),\pi}[\MR^{(t)}(x_{h+1})] - W^\pi\right| \nonumber\\ 
&\leq \frac{1}{\gamma} \E^{\Mbar(\Gamma),\pi}\left[\left|\max_{i,a}\left|\wh f_{h+1}(x_h^{(i)},\bar x_{h+1}^{(t)};a) - \wh f_{h+1}(x_h^{(i)},x_{h+1};a)\right|-\Delta(s_{h+1},s^\st)\right|\mathbbm{1}[s_{h+1}\in\MS]\right] \nonumber\\ 
&\leq \frac{1}{\gamma}\E^{\Mbar(\Gamma),\pi}\left[\max_{i,a}\left|\wh f_{h+1}(x_h^{(i)},x_{h+1};a) - f_{h+1}(\phi^\st(x_h^{(i)}),s_{h+1};a)\right| \mathbbm{1}[s_{h+1}\in\MS]\right] \nonumber\\ 
&\qquad+ \frac{\max_{i,a}\left|\wh f_{h+1}(x_h^{(i)},\bar x^{(t)}_{h+1};a) - f_{h+1}(\phi^\st(x_h^{(i)}),s^\st;a)\right|}{\gamma} \nonumber\\ 
&\leq \frac{1}{\tilde\alpha \gamma}\EE_{x_{h+1} \sim \BO_{h+1}\beta_{h+1}}\left[\max_{i,a}\left|\wh f_{h+1}(x_h^{(i)},x_{h+1};a) - f_{h+1}(\phi^\st(x_h^{(i)}),\phi^\st(x_{h+1});a)\right|\right] \nonumber\\ 
&\qquad+ \frac{\max_{i,a}\left|\wh f_{h+1}(x_h^{(i)},\bar x^{(t)}_{h+1};a) - f_{h+1}(\phi^\st(x_h^{(i)}),s^\st;a)\right|}{\gamma} \nonumber\\ 
&\leq \frac{\sqrt{\epreg}}{\tilde \alpha \gamma} + \frac{\max_{i,a}\left|\wh f_{h+1}(x_h^{(i)},\bar x^{(t)}_{h+1};a) - f_{h+1}(\phi^\st(x_h^{(i)}),s^\st;a)\right|}{\gamma},
\label{eq:rt-w-diff}
\end{align}
where the first inequality uses the fact that $g$ is $1/\gamma$-Lipschitz; the second inequality is by definition of $\Delta(s_{h+1},s^\st)$ and the triangle inequality; the third inequality is by \cref{eq:beta-x-lb}; and the fourth inequality is by \cref{eq:reg-bound-applied}. 

Next, for any fixed $s_{h+1} \in \Srch_{h+1}(\Gamma)$, recall that $\til\BP^{\Mbar(\Gamma)}_{h+1}(s_{h+1}\mid{}s_h,a_h) = \til\BP^M_{h+1}(s_{h+1}\mid{}s_h,a_h)$ and $\til\BP^{\Mbar(\Gamma)}_{h+1}(s_{h+1}\mid{}\term,a_h) = 0$ for all $s_h\in\MS$, $a_h \in \MA$ (by \cref{def:truncated-bmdp}); hence,
\begin{align}
d^{\Mbar(\Gamma),\pi}_{h+1}(s_{h+1}) 
&= \sum_{(s_h,a_h) \in \MS\times\MA} d^{\Mbar(\Gamma),\pi}_h(s_h,a_h)  \til\BP^M_{h+1}(s_{h+1}\mid{}s_h,a_h) \nonumber\\ 
&= \left(\sum_{(s_h,a_h)\in\MS\times\MA} d^{\Mbar(\Gamma),\pi}_h(s_h,a_h) \frac{f_{h+1}(s_h,s_{h+1};a_h)}{1-f_{h+1}(s_h,s_{h+1};a_h)}\right) F_{h+1}(s_{h+1})\label{eq:dpi-expansion-online}
\end{align} 
where the second equality is by definition of $f_{h+1},F_{h+1}$ (\cref{def:kinematics}). Substituting \cref{eq:dpi-expansion-online} into the definition of $W^\pi$ and using the fact that $d^{\Mbar(\Gamma),\pi}_{h+1}(s_{h+1}) = 0$ for all $s_{h+1} \in \MS\setminus \Srch_{h+1}(\Gamma)$, we get that 
\[W^\pi = \sum_{s_{h+1}\in\Srch_{h+1}(\Gamma)} \left(\sum_{(s_h,a_h)\in\MS\times\MA} d^{\Mbar(\Gamma),\pi}_h(s_h,a_h) \frac{f_{h+1}(s_h,s_{h+1};a_h)}{1-f_{h+1}(s_h,s_{h+1};a_h)}\right) F_{h+1}(s_{h+1}) g(\Delta(s_{h+1},s^\st)).\]
Define 
\[\widetilde W^\pi :=  \left(\sum_{(s_h,a_h)\in\MS\times\MA} d^{\Mbar(\Gamma),\pi}_h(s_h,a_h) \frac{f_{h+1}(s_h,s^\st;a_h)}{1-f_{h+1}(s_h,s^\st;a_h)}\right) \sum_{s_{h+1}\in\Srch_{h+1}(\Gamma)} F_{h+1}(s_{h+1}) g(\Delta(s_{h+1},s^\st)).\]
Then
\begin{align}
&|W^\pi - \til W^\pi| \nonumber\\ 
&\leq \sum_{s_{h+1}\in\Srch_{h+1}(\Gamma)} \left(\sum_{(s_h,a_h)\in\MS\times\MA} d^{\Mbar(\Gamma),\pi}_h(s_h,a_h) \left|\frac{f_{h+1}(s_h,s_{h+1};a_h)}{1-f_{h+1}(s_h,s_{h+1};a_h)} - \frac{f_{h+1}(s_h,s^\st;a_h)}{1-f_{h+1}(s_h,s^\st;a_h)}\right|\right)  \nonumber\\ &\qquad\qquad \cdot F_{h+1}(s_{h+1}) g(\Delta(s_{h+1},s^\st)) \nonumber\\ 
&\leq \sum_{s_{h+1}\in\Srch_{h+1}(\Gamma)} \left(\max_{(s_h,a_h) \in \Srch_h(\Gamma)\times\MA} \left|\frac{f_{h+1}(s_h,s_{h+1};a_h)}{1-f_{h+1}(s_h,s_{h+1};a_h)} - \frac{f_{h+1}(s_h,s^\st;a_h)}{1-f_{h+1}(s_h,s^\st;a_h)}\right|\right) F_{h+1}(s_{h+1}) g(\Delta(s_{h+1},s^\st)) \nonumber\\ 
&\leq 2\sum_{s_{h+1}\in\Srch_{h+1}(\Gamma)} \left(\frac{\max_{(s_h,a_h) \in \Srch_h(\Gamma)\times\MA} \left|f_{h+1}(s_h,s_{h+1};a_h) - f_{h+1}(s_h,s^\st;a_h)\right|}{\min_{(s_h,a_h,s) \in \Srch_h(\Gamma)\times\MA\times\MS} (1-f_{h+1}(s_h,s;a_h))^2}\right) F_{h+1}(s_{h+1}) g(\Delta(s_{h+1},s^\st)) \nonumber\\
&\leq 2\sum_{s_{h+1}\in\Srch_{h+1}(\Gamma)} \left(\frac{\Delta(s_{h+1},s^\st)}{\min_{(s_h,a_h,s) \in \Srch_h(\Gamma)\times\MA\times\MS} (1-f_{h+1}(s_h,s;a_h))^2}\right) F_{h+1}(s_{h+1}) g(\Delta(s_{h+1},s^\st)) \nonumber\\
&\leq 8|\MA|^2\sum_{s_{h+1}\in\Srch_{h+1}(\Gamma)} \left(\frac{\Delta(s_{h+1},s^\st)}{\min_{s \in \Srch_h(\Gamma)} \beta_h(s)^2}\right) F_{h+1}(s_{h+1}) g(\Delta(s_{h+1},s^\st)) \nonumber\\
&\leq \frac{8\gamma |\MS| |\MA|^2}{\min_{s \in \Srch_h(\Gamma)} \beta_h(s)^2}
\label{eq:w-wtilde-diff}
\end{align}
where the second inequality uses the fact that $d^{\Mbar(\Gamma),\pi}_h(s_h) = 0$ for all $s_h \in \MS \setminus \Srch_h(\Gamma)$; the third inequality uses \cref{lemma:lipschitz-bound}; the fourth inequality uses the definition of $\Delta(s_{h+1},s^\st)$ together with the lemma assumption that $\Srch_h(\Gamma) \subseteq \{\phi^\st(x^{(i)}_h):i\in[m]\}$; the fifth inequality uses \cref{lemma:f-ub}; and the sixth inequality uses the fact that $F_{h+1}(s_{h+1}) \leq 1$ for all $s_{h+1} \in \MS$ (\cref{def:kinematics}) together with the bound $z \cdot g(z) \leq \gamma$ for all $z \geq 0$. 

Finally, note that by definition of $\widetilde W^\pi$ and \cref{eq:dpi-expansion-online} applied to $s^\st$, we have
\begin{align}
\widetilde W^\pi 
&=  \left(\sum_{(s_h,a_h)\in\MS\times\MA} d^{\Mbar(\Gamma),\pi}_h(s_h,a_h) \frac{f_{h+1}(s_h,s^\st;a_h)}{1-f_{h+1}(s_h,s^\st;a_h)}\right) \sum_{s_{h+1}\in\Srch_{h+1}(\Gamma)} F_{h+1}(s_{h+1}) g(\Delta(s_{h+1},s^\st)) \nonumber \\ 
&= \frac{d^{\Mbar(\Gamma),\pi}_{h+1}(s^\st)}{ F_{h+1}(s^\st)} \sum_{s_{h+1}\in\Srch_{h+1}(\Gamma)} F_{h+1}(s_{h+1})g(\Delta(s_{h+1},s^\st)) \nonumber \\ 
&= K(\Gamma,s^\st) \cdot d^{\Mbar(\Gamma),\pi}_{h+1}(s^\st) \label{eq:wtilde-expansion-online}
\end{align}
where \[K(\Gamma,s^\st) := \frac{\sum_{s_{h+1}\in\Srch_{h+1}(\Gamma)}  F_{h+1}(s_{h+1})g(\Delta(s_{h+1},s^\st))}{F_{h+1}(s^\st)}.\]
Since $s^\st \in \Srch_{h+1}(\Gamma)$ and $g(\Delta(s^\st,s^\st)) = g(0) = 1$, we have $K(\Gamma,s^\st) \geq 1$. Combining \cref{eq:rt-w-diff,eq:w-wtilde-diff,eq:wtilde-expansion-online} yields the lemma claim.
\end{proof}



We now prove \cref{thm:extend-pc-trunc-online} by combining \cref{lemma:regression-bound-online,lemma:target-error-online} with a standard guarantee for $\PSDP$ (\cref{lemma:psdp-trunc-online}). We use the assumption that $\Psi_1,\dots,\Psi_h$ are truncateed policy covers for steps $1,\dots,h$ to show that the hypotheses for \cref{lemma:target-error-online} are satisfied with high probability. We remark that $\PSDP$ naturally uses a one-context regression oracle and not two; this is why we invoke it with a one-context regression oracle $\Reg'$ obtained by reduction to two-context regression (\cref{alg:onetwo}; see \cref{prop:onetwo}).

\vspace{1em}

\begin{proof}[Proof of \cref{thm:extend-pc-trunc-online}]
For any fixed $s \in \Srch_h(\Gamma)$ and $i \in [m]$, since $\phi^\st(x_h^{(i)}) \sim \beta_h$ and $\Psi_h$ is an $\alpha$-truncated policy cover for $M$ at step $h$, we have by \cref{item:h-cov-lb} of \cref{lemma:srch-gamma-covering} that
\[\Pr[\phi^\st(x_h^{(i)}) = s] \geq \frac{\min(\alpha\trunc,\tsmall)}{2}.\]
Let $\ME_1$ be the event that for each $s \in \Srch_h(\Gamma)$ there is some $i \in [m]$ with $\phi^\st(x^{(i)}) = s$. Then
\[\Pr[\ME_1] \geq 1 - |\MS|\left(1 - \frac{\min(\alpha\trunc,\tsmall)}{2}\right)^m \geq 1-\delta\]
by the theorem assumption that $m \geq \frac{2}{\min(\alpha\trunc,\tsmall)} \log(|\MS|/\delta)$. Henceforth condition on $x_h^{(1)},\dots,x_h^{(m)}$ and suppose that $\ME_1$ holds.

Let $\ME_2$ be the event that
\[\EE_{x_{h+1}\sim\til\BO_{h+1}\beta_{h+1}} \max_{(i,a)\in [m]\times\MA} \left(\wh f_{h+1}(x_h^{(i)},x_{h+1};a) - f_{h+1}(\phi^\st(x_h^{(i)}),\phi^\st(x_{h+1});a)\right)^2 \leq 2\sqrt{\epsilon} m|\MA|.\]
By the theorem assumptions that $\Reg$ is an $\Nreg$-efficient two-context regression oracle for $\Phi$, and $N \geq \Nreg(\epsilon,\delta)$, we may apply \cref{item:reg-2-online} of \cref{lemma:regression-bound-online} (with parameter $\delta' := \sqrt{\epsilon}$) to get that $\ME_2$ occurs with probability at least $1-\delta|\MA| - \sqrt{\epsilon} m|\MA|$ over the randomness of $(\MD_a)_{a \in \MA}$ and $\Reg$. Condition on this randomness (which determines $\wh f_{h+1}$) and suppose that $\ME_2$ holds.

For each $t \in [n]$, let $\ME_3^t$ be the event that \[\max_{(i,a)\in[m]\times\MA} \left(\wh f_{h+1}(x_h^{(i)},\bar x_{h+1}^{(t)};a) - f_{h+1}(\phi^\st(x_h^{(i)}),\phi^\st(\bar x_{h+1}^{(t)}); a)\right)^2 \leq 2\epsilon^{1/4}m|\MA|.\] Since $\bar x_{h+1}^{(t)} \sim \BO_{h+1}\beta_{h+1}$, we have by Markov's inequality and $\ME_2$ that $\Pr[\lnot \ME_3^t] \leq \epsilon^{1/4}$. Define $\ME_3 := \bigcap_{t=1}^n \ME_3^t$. By the union bound, $\ME_3$ occurs with probability at least $1-n\epsilon^{1/4}$ over the randomness of $\bar x_{h+1}^{(1)},\dots,\bar x_{h+1}^{(n)}$. 

Also, for each $s \in \Srch_{h+1}(\Gamma)$, let $t(s) \in [1,n] \cup \{\infty\}$ be the infimum over $t$ such that $\phi^\st(\bar x^{(t)}_{h+1}) = s$, and let $\ME_4^s$ be the event that $t(s) < \infty$. For each $t \in [1,n]$, since $\phi^\st(\bar x^{(t)}_{h+1})$ has distribution $\beta_{h+1}$, we have 
\begin{align*}
\Pr[\phi^\st(\bar x^{(t)}_{h+1})=s] 
&\geq \frac{\min(\alpha\trunc,\tsmall)}{2|\MA|} \max_{\pi\in\Pi} d^{\Mbar(\Gamma),\pi}_{h+1}(s) \\ 
&\geq \frac{\min(\alpha\trunc,\tsmall)}{2|\MA|}  \max_{\pi\in\Pi} d^{\Mbar(\emptyset),\pi}_{h+1}(s) \\ &\geq \frac{\min(\alpha\trunc,\tsmall)\trunc}{2|\MA|} \end{align*}
where the first inequality is by \cref{item:h-plus-one-cov-lb} of \cref{lemma:srch-gamma-covering}; the second inequality is by \cref{fact:gamma-monotonicity}; and the third inequality is by \cref{fact:trunc-reachability}.
Thus, $\Pr[\lnot \ME_4^s] \leq (1-\frac{\min(\alpha\trunc,\tsmall)\trunc}{2|\MA|})^n \leq \delta/|\MS|$ for any fixed $s \in \Srch_{h+1}$, by the theorem assumption that $n \geq \frac{2|\MA|}{\min(\alpha\trunc,\tsmall)\trunc} \log(|\MS|/\delta)$. Define $\ME_4 := \bigcap_{s \in \Srch_{h+1}} \ME_4^s$. By the union bound, $\ME_4$ occurs with probability at least $1-\delta$ over the randomness of $\bar x_{h+1}^{(1)},\dots,\bar x_{h+1}^{(n)}$. Condition on $\bar x_{h+1}^{(1)},\dots,\bar x_{h+1}^{(n)}$ and suppose that $\ME_3 \cap \ME_4$ holds. 

Finally, for each $t \in \Tclus$ let $\ME_5^t$ be the event that
\[\E^{M,\wh \pi^{(t)}}[\MR^{(t)}(x_{h+1})] \geq \max_{\pi\in\Pi} \E^{\Mbar(\Gamma),\pi}[\MR^{(t)}(x_{h+1})] - \frac{4H\sqrt{|\MA|\epsilon}}{\min(\alpha\trunc,\tsmall)}\]
where $\pihat^{(t)}$ is defined on \lineref{line:psdp-call-online} of \cref{alg:extend-pc-online}. Since $\Reg$ is an $\Nreg$-efficient two-context regression oracle, \cref{prop:onetwo} implies that $\Reg'$ is an $\Nreg$-efficient one-context regression oracle. Hence, by the theorem assumption on $\Psi_{1:h}$, and the fact that $N \geq \Nreg(\epsilon,\delta)$, \cref{lemma:psdp-trunc-online} gives that $\Pr[\ME_5^t] \geq 1-H|\MA|\delta$, so $\Pr[\ME_5] \geq 1-HAn\delta$ where $\ME_5 := \cap_{t \in [n]} \ME_5^t$. Condition on $\ME_5$. We have now restricted to an event of total probability at least $1 - (2+|\MA|+H|\MA|n)\delta - m|\MA|\epsilon^{1/2} - n\epsilon^{1/4}$; we argue that in this event, the properties claimed in the theorem statement hold.

\paragraph{Size of $\Psi_{h+1}$.} First, we argue that $|\Psi_{h+1}| \leq |\MS|$. Indeed, suppose that there are $t,t' \in \Tclus$ with $t<t'$ and $\phi^\st(\bar x_{h+1}^{(t)}) = \phi^\st(\bar x_{h+1}^{(t')})$. By \lineref{line:cluster-threshold-online} of \cref{alg:extend-pc-online}, and by choice of $\gamma'$, we know that 
\[\max_{(i,a) \in [m]\times\MA} \left|\wh f_{h+1}(x_h^{(i)},\bar x_{h+1}^{(t)};a) - \wh f_{h+1}(x_h^{(i)},\bar x_{h+1}^{(t')};a)\right| > \gamma' = 4\epsilon^{1/8}\sqrt{m|\MA|}.\] But this contradicts $\ME_3$ (in particular, the bounds implied by $\ME_3^t$ and $\ME_3^{t'}$ together with the triangle inequality and the fact that $\phi^\st(\bar x_{h+1}^{(t)}) = \phi^\st(\bar x_{h+1}^{(t')})$). We conclude that indeed $|\Psi_{h+1}| \leq |\MS|$.

\paragraph{Coverage of $\Psi_{h+1}$.} It remains to prove the second property of the theorem statement. Fix $s \in \Srch_{h+1}(\emptyset)$. Define $t^\st(s) := t(s)$ if $t(s) \in \Tclus$. Otherwise, let $t^\st(s)$ be the minimal $t \in \Tclus$ such that $\max_{i \in [m]} |\MR_i(\bar x_{h+1}^{(t(s))})-\MR_i(\bar x_{h+1}^{(t)})| \leq \gamma'$ (which exists by \lineref{line:cluster-threshold-online}). In either case, we know that $t^\st(s) \in \Tclus$, and \begin{equation}
\max_{(i,a) \in [m]\times\MA} |\wh f_{h+1}(x_h^{(i)},\bar x_{h+1}^{(t(s))};a)-\wh f_{h+1}(x_h^{(i)},\bar x_{h+1}^{(t^\st(s))};a)| \leq \gamma'.
\label{eq:t-tst-close}
\end{equation}

By $\ME_1$, $\ME_2$, and \cref{item:h-plus-one-cov-lb} of \cref{lemma:srch-gamma-covering}, we may apply \cref{lemma:target-error-online} with target state $s^\st := s$, index $t := t^\st(s)$, and parameters $\epreg := 2\sqrt{\epsilon}m|\MA|$ and $\tilde \alpha := \frac{\min(\alpha\trunc,\tsmall)}{2|\MA|}$. We get that there is some $K(\Gamma,s) \geq 1$ such that
\begin{align}
&\max_{\pi\in\Pi} \left|\E^{\Mbar(\Gamma),\pi}[\MR^{(t^\st(s))}(x_{h+1})] - K(\Gamma,s) \cdot d^{\Mbar(\Gamma),\pi}_{h+1}(s)\right|  \nonumber\\ 
&\leq \frac{8\gamma|\MS||\MA|^2}{\min_{s'\in\Srch_h(\Gamma)}\beta_h(s')^2} + \frac{\sqrt{\epreg}}{\tilde \alpha \gamma} + \frac{\max_{(i,a)\in[m]\times\MA}\left|\wh f_{h+1}(x_h^{(i)},\bar x_{h+1}^{(t^\st(s))};a) - f_{h+1}(\phi^\st(x_h^{(i)}),s;a)\right|}{\gamma} \nonumber\\
&\leq \frac{32\gamma|\MS||\MA|^2}{\min(\alpha^2\trunc^2,\tsmall^2)} + \frac{4\epsilon^{1/4}|\MA|\sqrt{m|\MA|}}{\gamma \cdot \min(\alpha\trunc,\tsmall)} \nonumber\\
&\qquad+ \frac{\max_{(i,a)\in[m]\times\MA}\left|\wh f_{h+1}(x_h^{(i)},\bar x^{(t^\st(s))}_{h+1};a) - f_{h+1}(\phi^\st(x_h^{(i)}),s;a)\right|}{\gamma} \nonumber \\
&\leq \frac{32\gamma|\MS||\MA|^2}{\min(\alpha^2\trunc^2,\tsmall^2)} + \frac{4\epsilon^{1/4}|\MA|\sqrt{m|\MA|}}{\gamma \cdot \min(\alpha\trunc,\tsmall)} \nonumber \\ 
&\qquad+ \frac{\epsilon^{1/8}\sqrt{2m|\MA|}+\max_{(i,a)\in[m]\times\MA}\left|\wh f_{h+1}(x_h^{(i)},\bar x^{(t^\st(s))}_{h+1};a) - \wh f_{h+1}(x_h^{(i)},\bar x_{h+1}^{(t(s))};a)\right|}{\gamma} \nonumber \\
&\leq \frac{32\gamma|\MS||\MA|^2}{\min(\alpha^2\trunc^2,\tsmall^2)} + \frac{4\epsilon^{1/4}|\MA|\sqrt{m|\MA|}}{\gamma \cdot \min(\alpha\trunc,\tsmall)} + \frac{\epsilon^{1/8}\sqrt{2m|\MA|}+\gamma'}{\gamma} \nonumber \\
&\leq \frac{32\epsilon^{1/16}|\MS||\MA|^2}{\min(\alpha^2\trunc^2,\tsmall^2)} + \frac{4\epsilon^{3/16}|\MA|\sqrt{m|\MA|}}{\min(\alpha\trunc,\tsmall)} + 6\epsilon^{1/16}\sqrt{m|\MA|} \nonumber \\
&\leq \trunc^2,\label{eq:rkd-error-online}
\end{align}
where the second inequality is by \cref{item:h-cov-lb} of \cref{lemma:srch-gamma-covering}; the third inequality is by $\ME_3$ and the fact that $s = \phi^\st(\bar x_{h+1}^{(t(s))})$; the fourth inequality is by \cref{eq:t-tst-close}; the fifth inequality is by choice of $\gamma,\gamma'$; and the final inequality is by \cref{eq:param-assm-online}. We now distinguish two cases:

\paragraph{Case I.} Suppose that 
\[\E^{M,\pihat^{(t^\st(s))}}[\MR^{(t^\st(s))}(x_{h+1})] \geq \E^{\Mbar(\Gamma),\pihat^{(t^\st(s))}}[\MR^{(t^\st(s))}(x_{h+1})] + \trunc^2.\]
Then
\begin{align*}
&d^{\Mbar(\Gamma),\pihat^{(t^\st(s))}}_{h+1}(\term) \\ 
&= \sum_{s \in \MS} \left(d^{M,\pihat^{(t^\st(s))}}_{h+1}(s) - d^{\Mbar(\Gamma),\pihat^{(t^\st(s))}}_{h+1}(s))\right) \\ 
&\geq \sum_{s \in \MS} \left(d^{M,\pihat^{(t^\st(s))}}_{h+1}(s) - d^{\Mbar(\Gamma),\pihat^{(t^\st(s))}}_{h+1}(s))\right) \EE_{x\sim\BO_{h+1}(\cdot|s)}[\MR^{(t^\st(s))}(x)] \\ 
&\geq \trunc^2
\end{align*}
where the equality is by the fact that $d^{M,\pihat^{(t^\st(s))}}_{h+1}(\cdot)$ is a distribution supported on $\MS$; the first inequality uses \cref{fact:gamma-monotonicity} and the fact that $\MR^{(t^\st(s))}(x) \leq 1$ for all $x \in \MX$. Thus $\max_{\pi\in\Psi_{h+1}} d^{\Mbar(\Gamma),\pi}(\term) \geq \trunc^2$, so the second property of the theorem statement is satisfied.

\paragraph{Case II.} Suppose that
\begin{equation} \E^{M,\pihat^{(t^\st(s))}}[\MR^{(t^\st(s))}(x_{h+1})] < \E^{\Mbar(\Gamma),\pihat^{(t^\st(s))}}[\MR^{(t^\st(s))}(x_{h+1})] + \trunc^2.\label{eq:m-mbar-closeness-online}\end{equation}
Now, 
\begin{align*}
K(\Gamma, s) \cdot d^{\Mbar(\Gamma), \pihat^{t^\st(s)}}_{h+1}(s) 
&\geq \E^{\Mbar(\Gamma),\pihat^{t^\st(s)}}[\MR^{(t^\st(s))}(x_{h+1})] - \trunc^2 \\ 
&\geq \E^{M,\pihat^{t^\st(s)}}[\MR^{(t^\st(s))}(x_{h+1})] - 2\trunc^2 \\ 
&\geq \max_{\pi\in\Pi} \E^{\Mbar(\Gamma),\pi}[\MR^{(t^\st(s))}(x_{h+1})] -  3\trunc^2 \\ 
&\geq \max_{\pi\in\Pi} K(\Gamma,s) \cdot d^{\Mbar(\Gamma),\pi}_{h+1}(s) -  4\trunc^2 \\
&\geq K(\Gamma,s) (1-4\trunc) \max_{\pi\in\Pi} d^{\Mbar(\Gamma),\pi}_{h+1}(s)
\end{align*}
where the first inequality is by \cref{eq:rkd-error-online}; the second inequality is by \cref{eq:m-mbar-closeness-online}; the third inequality is by $\ME_5$ and \cref{eq:param-assm-online}; the fourth inequality is by \cref{eq:rkd-error-online}; and the fifth inequality uses the fact that $\max_{\pi\in\Pi} d^{\Mbar(\Gamma),\pi}_{h+1}(s) \geq \trunc$ (\cref{fact:trunc-reachability} together with \cref{fact:gamma-monotonicity} and the fact that $s \in \Srch_{h+1}(\emptyset)$) and the bound $K(\Gamma,s) \geq 1$ (\cref{lemma:target-error-online}). Thus, since $\pihat^{(t^\st(s))} \in \Psi_{h+1}$, we have
\begin{align}
\max_{\pi\in\Psi_{h+1}} d^{M,\pi}_{h+1}(s) 
&\geq \max_{\pi\in\Psi_{h+1}} d^{\Mbar(\Gamma),\pi}_{h+1}(s) \nonumber\\ 
&\geq (1-4\trunc)\max_{\pi\in\Pi} d^{\Mbar(\Gamma),\pi}_{h+1}(s) \nonumber\\ 
&\geq (1-4\trunc)\max_{\pi\in\Pi} d^{\Mbar(\emptyset),\pi}_{h+1}(s)
\label{eq:coverage-final-online}
\end{align}
by two applications of \cref{fact:gamma-monotonicity}. Now recall that $s \in \Srch_{h+1}(\emptyset)$ was arbitrary. Moreover, if $s \in \MS\setminus \Srch_{h+1}(\emptyset)$ then $\max_{\pi\in\Pi} d^{\Mbar(\emptyset),\pi}_{h+1}(s) = 0$, so the inequality \cref{eq:coverage-final-online} still holds. We conclude that $\Psi_{h+1}$ is a $(1-4\trunc)$-truncated max policy cover for $M$ at step $h+1$ (\cref{defn:trunc-max-pc}), as needed.
\end{proof}

\subsection{Analysis of $\PCO$ (\creftitle{alg:pco})}\label{sec:pco-analysis}

We now complete the proof of \cref{thm:pco-app}. As previously discussed, \cref{thm:extend-pc-trunc-online} shows that in each round of $\PCO$, either a set of policy covers was constructed, or a new state was discovered. The latter can happen at most $H|\MS|-1$ times, so at least one round must construct a good set of policy covers. In the latter event, the union of all sets produced across all rounds is itself a good policy cover (so long as the individual sets have bounded size). 
Of course, since the guarantee of \cref{thm:extend-pc-trunc-online} is probabilistic, some additional care is needed. We make the argument formal below.

\vspace{1em}

\iffalse
\begin{theorem}\label{thm:pco-final-guarantee}
There is a constant $C>0$ so that the following holds. Let $\epfinal,\delta \in (0,1)$ and $N \in \NN$. Suppose that $\Reg$ is an $\Nreg$-efficient two-context regression oracle, and 
\[N \geq \Nreg\left(\left(\frac{\epfinal\delta}{H|\MA||\MS|}\right)^C,\left(\frac{\epfinal\delta}{H|\MA||\MS|}\right)^C\right).\]
Let $\Psi$ denote the output of $\PCO(\Reg,\delta,\epfinal,N)$. Then $|\Psi| \leq H^2|\MS|^2$ for each $h \in [H]$. Moreover, with probability at least $1-\delta$, it holds for each $h \in [H]$ and $s \in \MS$ that \begin{equation} \max_{\pi' \in \Psi} d^{M,\pi'}_h(s) \geq \max_{\pi \in \Pi} d^{M,\pi}_h(s) - \epfinal.\label{eq:pco-requirement}
\end{equation}
\end{theorem}
\fi

\begin{proof}[Proof of \cref{thm:pco-app}]
Fix the remaining inputs $\epfinal,\delta>0$ to $\PCO(\Reg,\Nreg,|\MS|,\cdot)$. The oracle time complexity bound and bound on $\Nrl$ are clear from the parameter choices and pseudocode, so long as $C_{\ref{thm:pco-app}}$ is a sufficiently large constant. Moreover, it is immediate from the algorithm description that $|\Psi| \leq HR|\MS| \leq H^2|\MS|^2$. In order to show that the algorithm is $(\Nrl,\Krl)$-efficient, it remains to argue that with probability at least $1-\delta$, \cref{eq:rfrl-pc} holds for all $h \in [H]$ and $s \in \MS$, with parameter $\epfinal$.

Recall that $\trunc = \epfinal/(4+H|\MS|)$. Fix some $1 \leq r \leq R$. For convenience, write $\alpha := \frac{1-4\trunc}{|\MS|}$. For each $h \in [H]$, let $\ME_{h,r}$ be the event that $|\Psi_h^{(r)}| \leq |\MS|$ and $\Psi_h^{(r)}$ is a $(1-4\trunc)$-truncated max policy cover for $M$ at step $h$; let $\MF_{h,r}$ be the event that $|\Psi_{h}^{(r)}| \leq |\MS|$ and $\max_{\pi\in\Psi_{h}^{(r)}} d^{\Mbar(\Gamma^{(r)}),\pi}_{h}(\term) \geq \trunc^2$. It's clear that $\Pr[\ME_{1,r}] = 1$ (since $|\Psi_1^{(r)}| = 1$ and $d^{M,\piunif}_1(s) = d^{M,\pi}_1(s)$ for all $s\in\MS$ and $\pi \in \Pi$). Also, note that in the event $\ME_{k,r}$, we have that $\Psi_k^{(r)}$ is an $\alpha$-truncated policy cover for $M$ at step $k$. Thus, by \cref{thm:extend-pc-trunc-online} and choice of parameters (so long as $C_{\ref{thm:pco-app}}$ is a sufficiently large constant), we have for each $h \in \{2,\dots,H\}$ that
\begin{equation} \Pr\left[\lnot (\ME_{h,r} \cup \MF_{h,r}) \cap \bigcap_{1 \leq k < h} \ME_{k,r}\right] \leq \Pr\left[\lnot (\ME_{h,r} \cup \MF_{h,r}) \middle | \bigcap_{1 \leq k < h} \ME_{k,r}\right] \leq \frac{\delta}{HR}.\label{eq:epco-guarantee-symbolic}\end{equation}
In the event that the events $\MF_{1,r},\dots,\MF_{H,r}, \bigcap_{h\in[H]} \ME_{h,r}$ all fail, there is always some maximal $h \in [H]$ such that $\bigcap_{1 \leq k \leq h} \ME_{k,r}$ holds (since $\ME_{1,r}$ always holds); it must be that $1 \leq h<H$, and $\ME_{h+1,r}$ and $\MF_{h+1,r}$ both fail. Thus,
\[\Pr\left[\left(\lnot \bigcap_{h \in [H]} \ME_{h,r}\right) \cap \bigcap_{h \in [H]} \left(\lnot \MF_{h,r}\right)\right] \leq \sum_{h=2}^H \Pr\left[\lnot (\ME_{h,r} \cup \MF_{h,r}) \cap \bigcap_{1 \leq k < h} \ME_{k,r}\right] \leq \frac{\delta}{R}\]
where the final inequality is by \cref{eq:epco-guarantee-symbolic}. Let $\ME_r$ denote the complementary event (i.e. either $\bigcap_{h \in [H]} \ME_{h,r}$ holds, or there is some $h \in [H]$ such that $\MF_{h,r}$ holds), and let $\ME := \bigcap_{1 \leq r \leq R} \ME_r$; we have $\Pr[\ME] \geq 1-\delta$. We claim that $\PCO$ succeeds under event $\ME$. Indeed, there are two cases to consider.

\begin{enumerate}
\item In the first case, there is some $r \in [R]$ such that $\bigcap_{h \in [H]} \ME_{h,r}$ holds. Then for each $h \in [H]$, $|\Psi_h^{(r)}| \leq |\MS|$ and $\Psi_h^{(r)}$ is a $(1-4\trunc)$-truncated max policy cover for $M$ at step $h$. Thus, $\bigcup_{1 \leq r' \leq R: |\Psi_h^{(r')}| \leq |\MS|} \Psi_h^{(r')} \subseteq \Psi$ is also a $(1-4\trunc)$-truncated max policy cover for $M$ at step $h$. Therefore for each $h \in [H]$ and $s \in \MS$, we have by \cref{defn:trunc-max-pc} that
\begin{align*}
\max_{\pi'\in\Psi} d^{M,\pi'}_h(s)
&\geq (1-4\trunc) \max_{\pi\in\Pi} d^{\Mbar(\emptyset),\pi}_h(s) \\ 
&\geq \max_{\pi \in\Pi} d^{\Mbar(\emptyset),\pi}_h(s) - 4\trunc \\ 
&\geq \max_{\pi \in \Pi} d^{M,\pi}_h(s) - (4 + H|\MS|)\trunc
\end{align*}
where the final inequality is by \cref{lemma:term-ub}. Since $\trunc = \epfinal/(4+H|\MS|)$, this bound suffices.
\item In the second case, for each $r \in [R]$, there is some $h \in [H]$ such that $\MF_{h,r}$ holds. For each $r$, define
\[\MV^{(r)} := \left\{(s,h) \in \MS\times[H]: \max_{\pi\in\Gamma^{(r)}} d^{M,\pi}_h(s) \geq \frac{\trunc^2}{|\MS|H}\right\}.\]
Fix any $r \in [R]$. By assumption, there is some $h \in [H]$ so that $\MF_{h,r}$ holds. For this choice of $h$, we have by definition of $\MF_{h,r}$ that 
\[\max_{\pi \in \Psi_{h}^{(r)}} d^{\Mbar(\Gamma),\pi}_h(\term) \geq \trunc^2.\] 
By \cref{lemma:term-prob}, there is some $(s,k) \in (\MS\setminus \Srch_k(\Gamma))\times[h]$ such that \[\max_{\pi\in\Psi_h^{(r)}} d^{M,\pi}_k(s) \geq \frac{\trunc^2}{|\MS|H}.\] Thus $(s,k) \in \MV^{(r+1)}$. Moreover, since $s \not \in \Srch_k(\Gamma^{(r)})$, we have $\E_{\pi\sim\Unif(\Gamma^{(r)})} d^{M,\pi}_k(s) < \tsmall$. Using the fact that $|\Gamma^{(r)}| \leq RH|\MS|$ and choice of $\tsmall$, it follows that \[\max_{\pi\in\Gamma^{(r)}} d^{M,\pi}_k(s) < RH|\MS|\tsmall \leq \frac{\trunc^2}{|\MS|H}.\] So $(s,k) \not \in \MV^{(r)}$. We conclude that $|\MV^{(r+1)}| > |\MV^{(r)}|$. Since this inequality holds for all $r \in [R]$ and $|\MV^{(1)}| \geq H$, we get $|\MV^{(R)}| \geq H + R - 1 > |\MS|H$. Contradiction, so in fact this second case cannot occur.
\end{enumerate}
This completes the proof.
\end{proof}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
