\paragraph{Notation in proofs.} For any MDP $M$, any policy $\pi$ induces a distribution over \emph{trajectories} $(s_1,x_1,a_1,\dots,s_H,x_H,a_H)$, where the trajectory is sampled via an episode of online interaction with $M$, and at step $h$ the action $a_h$ is sampled from $\pi_h(x_h)$. We write $\Pr^{M,\pi}[\cdot]$ (respectively, $\EE^{M,\pi}[\cdot]$) to denote probability (respectively, expectation) over a trajectory sampled from $M$ with policy $\pi$. With this notation, for $h \in [H]$ and $s \in \MS$, we have $d^{M,\pi}_h(s) = \Pr^{M,\pi}[s_h=s]$. In a (minor) overload of notation, for $h \in [H]$ and $x \in \MX$ we also define the visitation probability of observation $x$ at step $h$ as $d^{M,\pi}_h(x) := \Pr^{M,\pi}[x_h = x]$. %Finally, when $M$ is not clear from context, we write $\til\BP^M_h$ to denote the latent transition distribution $\til \BP_h$ of $M$.

In the remaining appendices, we will be explicit about certain dependences on the MDP $M$ (since we will shortly be introducing truncations of $M$). In particular, unless the MDP $M$ is clear from context, we write $\til\BP^M_h$ to denote the latent transition distribution $\til \BP_h$ of $M$, and similarly write $\BP^M_h$ to denote the observed transition distribution.

\paragraph{Notation in pseudocode.} For a sampleable distribution over policies $\rho \in \Delta(\Pi)$, in the pseudocode for our algorithms we may write 
\[(x_1,a_1,\dots,x_k,a_k) \sim \rho\]
to denote sampling a policy $\pi \sim \rho$ and then a sampling (partial) trajectory via an episode of online interaction with the MDP $M$, using policy $\pi$. More generally, for two such distributions $\rho,\rho' \in \Delta(\Pi)$ and a step $h \in [H]$, we may write
\[(x_1,a_1,\dots,x_k,a_k) \sim \rho \circ_h \rho'\]
to denote sampling policies $\pi \sim \rho$ and $\pi' \sim \rho'$, and then sampling a partial trajectory from $M$ using the policy $\pi \circ_h \pi'$, i.e. playing $a_i \sim\pi_i(x_i)$ for each $i < h$ and $a_i \sim \pi'_i(x_i)$ for each $i \geq h$. In the above notation, for an action $a \in \MA$, we may overload $a$ to also denote the policy that deterministically plays action $a$.

\subsection{Truncated MDPs}\label{sec:truncated-mdps}
Fix a Block MDP $M = (H, \MS, \MX, \MA, (\til \BP_h)_{h \in [H]}, (\til\BO_h)_{h\in[H]}, \phi^\st)$. For purposes of analysis, it will be useful to define \emph{truncations} of $M$, as well as \emph{truncated} policy covers defined in terms of certain truncations. To understand the material in \cref{sec:app_online,sec:app_resets} in full generality, these definitions will be important; however, if one is willing to make a reachability assumption on the MDP $M$ \citep{misra2020kinematic}, then one may ignore these definitions and treat $\Mbar(\Gamma)$ and $\Mbar(\emptyset)$ as equivalent to $M$ itself.

In truncated Block MDPs, the latent state space and observation space are augmented with a terminal state/context $\term$, and transitions that would lead to ``difficult-to-reach'' states in $M$ instead lead to $\term$. The following preliminaries are adapted from \cite{golowich2024exploring}. For notational convenience, define $\phi^\star(\term) := \term$. %Block MDPs $\Mbar_1,\dots,\Mbar_H$ with horizon $H$, latent state space $\Sbar := \MS \cup \{\term\}$, observation space $\Xbar := \MX \cup \{\term\}$, and action space $\MA$ as follows. 

\begin{definition}\label{def:truncated-bmdp}
Let $\Srch = (\Srch_1,\dots,\Srch_H)$ for some given sets $\Srch_1,\dots,\Srch_H \subseteq \MS$. The $\Srch$-truncation of $M$ is the Block MDP $(H, \Sbar,\Xbar,\MA,(\Pbar_h)_{h\in[H]},(\Obar_h)_{h\in[H]},\phi^\star)$ with latent state space $\Sbar := \MS \cup \{\term\}$, observation space $\Xbar := \MX \cup \{\term\}$, observation distribution
\[\Obar_h(x|s) := \begin{cases} \til\BO_h(x|s) & \text{ if } x \in \MX, s \in \MS \\ 1 & \text{ if } x=s=\term \\ 0 & \text{ otherwise} \end{cases},\]
initial state distribution 
\[\Pbar_1(s_1) := \begin{cases}
\til\BP_1(s_1) & \text{ if } s_1 \in \Srch_1 \\ 
0 & \text{ if } s_1 \in \MS \setminus \Srch_1 \\ 
\sum_{z \in \MS \setminus \Srch_1} \til\BP_1(z) & \text{ if } s_1 = \term 
\end{cases},\]
and transition distribution
\[\Pbar_h(s_h|s_{h-1},a) := \begin{cases} \til\BP_h(s_h|s_{h-1},a) & \text{ if } s_{h-1} \in \MS, s_h \in \Srch_h \\ 0 & \text{ if } s_{h-1} \in \MS, s_h \in \MS\setminus\Srch_h \\ \sum_{z \in \MS\setminus\Srch_h} \til\BP_h(z|s_{h-1},a) &\text{ if } s_{h-1} \in \MS, s_h = \term \\ \mathbbm{1}[s_h=\term] & \text{ if } s_{h-1} = \term \end{cases} \]
for each $h \in \{2,\dots,h\}$.
\end{definition}

\paragraph{Definition of $\Mbar(\emptyset)$ and $\Mbar(\Gamma$).} Fix parameters $\trunc \geq \tsmall > 0$ and a finite set of policies $\Gamma \subset \Pi$. We inductively define sets $\Srch_1(\Gamma),\dots,\Srch_H(\Gamma)$ and truncated Block MDPs $\Mbar_1(\Gamma),\dots,\Mbar_H(\Gamma)$ as follows. First, define 
\[\Srch_1(\Gamma) := \Srch_1(\emptyset) := \{s \in \MS: \til\BP_1(s) \geq \trunc\}\]
and let $\Mbar_1(\Gamma)$ be the $(\Srch_1(\Gamma),\MS,\dots,\MS)$-truncation of $M$. Next, for each $h \in \{2,\dots,H\}$, define \[\Srch_h(\emptyset) := \{s \in \MS: \max_{\pi\in\Pi} d^{\Mbar_{h-1}, \pi}_h(s) \geq \trunc\}\]
and, if $\Gamma \neq \emptyset$, \[\Srch_h(\Gamma) := \Srch_h(\emptyset) \cup \left\{s \in \MS: \EE_{\pi\sim\Unif(\Gamma)} d^{M,\pi}_h(s) \geq \tsmall\right\}.\]
Then we let $\Mbar_h(\Gamma)$ be the $(\Srch_2(\Gamma),\dots,\Srch_h(\Gamma),\MS,\dots,\MS)$-truncation of $M$. Finally, define $\Mbar(\Gamma) := \Mbar_H(\Gamma)$. As will be evident from the final parameter settings (in \cref{alg:pco,alg:pcr}), one should think of $\tsmall \ll \trunc$.

\paragraph{Truncated policy covers.} To avoid compounding errors in the analysis of algorithms that build policy covers layer-by-layer (such as $\PCO$ and $\PCR$), it is convenient to work with \emph{truncated} policy covers throughout the analysis (e.g. in the inductive hypothesis at layer $h$), and only convert to a standard policy cover (as in \cref{eq:rfrl-pc}) at the end of the analysis. Truncated policy covers are defined below:

\begin{definition}\label{defn:trunc-pc}
Let $\alpha \in (0,1)$. We say that a collection of policies $\Psi \subset \Pi$ is an \emph{$\alpha$-truncated policy cover (for $M$) at step $h\in [H]$} if for all $x \in \MX$,
\begin{align}
\frac{1}{|\Psi|} \sum_{\pi' \in \Psi} d_h^{M,\pi'}(x) \geq \alpha \cdot \max_{\pi \in \Pi} d_h^{\Mbar(\emptyset),\pi}(x)\label{eq:approx-pc}. 
\end{align}
\end{definition}
%\dhruv{non-intuitive name since below definition is weaker than above}
\begin{definition}\label{defn:trunc-max-pc}
Let $\alpha \in (0,1)$. We say that a collection of policies $\Psi \subset \Pi$ is an \emph{$\alpha$-truncated max policy cover at step $h\in [H]$} if for all $x \in \MX$,
\begin{align}
\max_{\pi'\in\Psi} d_h^{M,\pi'}(x) \geq \alpha \cdot \max_{\pi \in \Pi} d_h^{\Mbar(\emptyset),\pi}(x) \label{eq:approx-max-pc}.
\end{align}
\end{definition}

\subsubsection{Useful facts for Truncated MDPs}

Recall that we defined $\Mbar(\Gamma)$ as the final truncated MDP in an iterative process that produced intermediate truncated MDPs $\Mbar_1(\Gamma),\dots,\Mbar_H(\Gamma)$. These intermediate MDPs are only used for certain technical lemmas about $\Mbar(\Gamma)$; nonetheless it is useful to state several facts for later use. 

Recall that $\Mbar_h(\Gamma)$ is, essentially, truncated up to and including the transitions into step $h$. \cref{fact:trunc-dists} formalizes the fact that $\Mbar_h(\Gamma)$ agrees with $\Mbar(\Gamma)$ up to step $h$, and \cref{fact:trunc-trans} formalizes the fact that it agrees with $M$ after step $h$.

\begin{fact}\label{fact:trunc-dists}
For any finite set $\Gamma \subset \Pi$, integers $g,h \in [H]$ with $g \leq h$, policy $\pi \in \Pi$, and state $s \in \Sbar$, it holds that $d^{\Mbar(\Gamma),\pi}_g(s) = d^{\Mbar_h(\Gamma),\pi}_g(s)$.
\end{fact}

\begin{fact}\label{fact:trunc-trans}
For any finite set $\Gamma \subset \Pi$, integer $h \in \{1,\dots,H-1\}$, state $s \in \Sbar$, and action $a \in \MA$, it holds that $\til \BP^{\Mbar_h(\Gamma)}_{h+1}(\cdot|s,a) = \til\BP^M_{h+1}(\cdot|s,a)$.
\end{fact}

The most important property of a truncated MDP is that every state is either reachable (by some policy) with probability at least $\trunc$, or cannot be reached by any policy:

\begin{fact}\label{fact:trunc-reachability}
For every $h \in \{1,\dots,H\}$ and $s \in \MS$, we have $\max_{\pi\in\Pi} d^{\Mbar(\emptyset),\pi}_h(s) \geq \trunc$ if $s \in \Srch_h(\emptyset)$ and $\max_{\pi\in\Pi} d^{\Mbar(\emptyset),\pi}_h(s) = 0$ otherwise.
\end{fact}

The following facts formalize that $\Mbar_h(\Gamma)$ is ``more truncated'' than $\Mbar_{h-1}(\Gamma)$, and that $\Mbar(\Gamma)$ is ``less truncated'' than $\Mbar(\emptyset)$, respectively. The truncation process only takes mass away from non-terminal states.

\begin{fact}\label{fact:trunc-monotonicity}
Fix any finite set $\Gamma \subset \Pi$ and write $\Mbar_0(\Gamma) := M$. For any $h \in [H]$, $s \in \MS$, and $\pi \in \Pi$, it holds that $d^{\Mbar_h(\Gamma),\pi}_h(s) \leq d^{\Mbar_{h-1}(\Gamma),\pi}_h(s)$. Hence, $\E^{\Mbar_h(\Gamma),\pi}[f(x_h)] \leq \E^{\Mbar_{h-1}(\Gamma),\pi}[f(x_h)]$ for any $f: \Xbar \to \RR_{\geq 0}$ with $f(\term)=0$.
\end{fact}



\begin{fact}\label{fact:gamma-monotonicity}
For every $h \in [H]$, $s \in \MS$, $\Gamma \subset \Pi$, and $\pi \in \Pi$, we have $d^{\Mbar(\emptyset),\pi}_h(s) \leq d^{\Mbar(\Gamma),\pi}_h(s) \leq d^{M,\pi}_h(s)$.
\end{fact}

\subsubsection{Facts about truncated policy covers}

In our algorithms, we will often roll in to some step $h$ using a uniformly random policy from $\frac{1}{2}(\Unif(\Psi_h) + \Unif(\Gamma))$. The following lemma gives useful properties of the resulting visitation distribution, under the assumption that $\Psi_h$ is an $\alpha$-truncated policy cover at step $h$.

\begin{lemma}\label{lemma:srch-gamma-covering}
Fix $h \in \{1,\dots,H-1\}$ and $\alpha>0$. Let $\Psi_h, \Gamma \subset \Pi$ be finite sets of policies. Suppose that $\Psi_h$ is an $\alpha$-truncated policy cover at step $h$ (\cref{defn:trunc-pc}) for $M$. %Let $(s_{1:h},x_{1:h},a_{1:h-1})$ be a trajectory drawn from $\frac{1}{2}(\Unif(\Psi_h) + \Unif(\Gamma))$, and let $\beta \in \Delta(\MS)$ be the distribution of $s_h$. 
Then:
\begin{enumerate}
\item\label{item:h-cov-lb} For all $s_h \in \Srch_h(\Gamma)$, it holds that 
\[\EE_{\pi\sim\frac{1}{2}(\Unif(\Psi_h)+\Unif(\Gamma))} d^{M,\pi}_h(s_h) \geq \frac{\min(\alpha\trunc,\tsmall)}{2}.\]
\item\label{item:change-of-measure} For any $f:\Xbar\to\RR_{\geq 0}$ with $f(\term)=0$, it holds that 
\[\EE_{\pi\sim\frac{1}{2}(\Unif(\Psi_h)+\Unif(\Gamma))} \E^{M,\pi}[f(x_h)] \geq \frac{\min(\alpha\trunc,\tsmall)}{2} \max_{\pi\in\Pi} \E^{\Mbar(\Gamma),\pi}[f(x_h)].\]
\item\label{item:h-plus-one-cov-lb} For all $s_{h+1} \in \MS$,
\[\EE_{\pi\sim\frac{1}{2}(\Unif(\Psi_h)+\Unif(\Gamma))\circ_h \Unif(\MA)} d^{M,\pi}_{h+1}(s_{h+1}) \geq \frac{\min(\alpha\trunc,\tsmall)}{2|\MA|} \max_{\pi\in\Pi} d^{\Mbar(\Gamma),\pi}_{h+1}(s_{h+1}).\]
\end{enumerate}
\end{lemma}

\begin{proof}
We start with the first claim. Pick any $s_h \in \Srch_h(\Gamma)$. If $s_h \in \Srch_h(\emptyset)$, then $\max_{\pi\in\Pi} d^{\Mbar(\emptyset),\pi}_h(s) \geq \trunc$ (\cref{fact:trunc-reachability}). Thus, \[\EE_{\pi\sim\Unif(\Psi_h)} d^{M,\pi}_h(s_h) \geq \alpha\trunc\] by \cref{defn:trunc-pc}. On the other hand, if $s_h \in \Srch_h(\Gamma)\setminus\Srch_h(\emptyset)$, then $\E_{\pi\sim\Unif(\Gamma)} d^{M,\pi}_h(s) \geq \tsmall$ by definition of $\Srch_h(\Gamma)$. In either case, we have
\[\frac{1}{2}\EE_{\pi\sim\Unif(\Psi_h)} d^{M,\pi}_h(s_h) + \frac{1}{2}\EE_{\pi\sim\Unif(\Gamma)} d^{M,\pi}_h(s_h) \geq \frac{\min(\alpha\trunc,\tsmall)}{2}\]
which proves the first claim. Next, pick any $f:\Xbar\to\RR_{\geq 0}$ with $f(\term)=0$. We have
\begin{align*}
&\EE_{\pi\sim\frac{1}{2}(\Unif(\Psi_h)+\Unif(\Gamma))} \E^{M,\pi}[f(x_h)] \\ 
&= \sum_{s_h \in \MS} \EE_{\pi\sim\frac{1}{2}(\Unif(\Psi_h)+\Unif(\Gamma)} d^{M,\pi}_h(s_h) \EE_{x_h \sim \BO_h(\cdot|s_h)}[f(x_h)] \\ 
&\geq \sum_{s_h \in \Srch_h(\Gamma)} \EE_{\pi\sim\frac{1}{2}(\Unif(\Psi_h)+\Unif(\Gamma)} d^{M,\pi}_h(s_h) \EE_{x_h \sim \BO_h(\cdot|s_h)}[f(x_h)] \\ 
&\geq \frac{\min(\alpha\trunc,\tsmall)}{2} \sum_{s_h \in \Srch_h(\Gamma)} \max_{\pi\in\Pi} d^{\Mbar(\Gamma),\pi}_h(s_h) \EE_{x_h \sim \BO_h(\cdot|s_h)}[f(x_h)] \\ 
&\geq \frac{\min(\alpha\trunc,\tsmall)}{2} \max_{\pi\in\Pi} \E^{\Mbar(\Gamma),\pi}[f(x_h)]
\end{align*}
where the first inequality uses non-negativity of $f$; the second inequality uses \cref{item:h-cov-lb} together with the fact that $d^{\Mbar(\Gamma),\pi}_h(s_h) \leq 1$ for all $\pi,s_h$; and the third inequality uses the fact that $f(\term) = 0$. This proves the second claim. Finally, pick any $s_{h+1} \in \MS$. If $s_{h+1} \in \Srch_{h+1}(\Gamma)$, then for any $\pi \in \Pi$,
\begin{align*}
&\EE_{\pi\sim\frac{1}{2}(\Unif(\Psi_h)+\Unif(\Gamma))\circ_h \Unif(\MA)} d^{M,\pi}_{h+1}(s_{h+1}) \\ 
&= \sum_{s_h \in \MS} \left(\EE_{\pi\sim\frac{1}{2}(\Unif(\Psi_h)+\Unif(\Gamma)} d^{M,\pi}_h(s_h)\right) \frac{1}{|\MA|}\sum_{a \in \MA} \til\BP^M_{h+1}(s_{h+1}|s_h,a) \\ 
&\geq \sum_{s_h \in \MS} \left(\EE_{\pi\sim\frac{1}{2}(\Unif(\Psi_h)+\Unif(\Gamma)} d^{M,\pi}_h(s_h)\right) \frac{1}{|\MA|} \til\BP^M_{h+1}(s_{h+1}|s_h,\pi(s_h)) \\
&\geq \frac{\min(\alpha\trunc,\tsmall)}{2}\sum_{s_h\in\Srch_h(\Gamma)} d^{\Mbar(\Gamma),\pi}_h(s_h) \frac{1}{|\MA|} \til\BP^M_{h+1}(s_{h+1}|s_h,\pi(s_h)) \\
&= \frac{\min(\alpha\trunc,\tsmall)}{2|\MA|} d^{\Mbar(\Gamma),\pi}_{h+1}(s_{h+1})
\end{align*}
where the second inequality uses \cref{item:h-cov-lb} together with the fact that $d^{\Mbar(\Gamma),\pi}_h(s_h) \leq 1$ for all $s_h$. This proves the third claim whenever $s_{h+1} \in \Srch_{h+1}(\Gamma)$. Moreover, if $s_{h+1} \not \in \Srch_{h+1}(\Gamma)$ then $\max_{\pi\in\Pi} d^{\Mbar(\Gamma),\pi}_{h+1}(s_{h+1}) = 0$, so the inequality is vacuously true.
\end{proof}

\subsubsection{Additional facts about truncated MDPs}

The following lemma will be important in the win/win analyses for $\PCO$ and $\PCR$---specifically, it shows that if we find a policy that visits the terminal state $\term$ with reasonable probability in $\Mbar(\Gamma)$, then it must explore some hard-to-reach state at some earlier layer of $M$ (which is a form of progress).

\begin{lemma}\label{lemma:term-prob}
Let $\pi \in \Pi$ and $\Gamma \subset \Pi$. For any $h \in [H]$, it holds that \[d^{\Mbar(\Gamma),\pi}_h(\term) \leq \sum_{k=1}^h \sum_{s \in \MS\setminus \Srch_k(\Gamma)} d^{M,\pi}_k(s).\]
\end{lemma}

\begin{proof}
Observe that $d^{\Mbar(\Gamma),\pi}_1(\term) = \sum_{s \in \MS\setminus \Srch_1(\Gamma)} \til\BP^M_1(s) = \sum_{s \in \MS\setminus \Srch_1(\Gamma)} d^{M,\pi}_1(s)$ by construction. Moreover, for any $h \in \{2,\dots,H\}$, we have
\begin{align*}
d^{\Mbar(\Gamma),\pi}_h(\term)
&= d^{\Mbar(\Gamma),\pi}_{h-1}(\term) + \sum_{s \in \Srch_{h-1}(\Gamma)} d^{\Mbar(\Gamma),\pi}_{h-1}(s) \sum_{s' \in \MS \setminus \Srch_h(\Gamma)} \til\BP^M_h(s'|s,\pi(s)) \\ 
&\leq d^{\Mbar(\Gamma),\pi}_{h-1}(\term) + \sum_{s \in \MS} d^{M,\pi}_{h-1}(s) \sum_{s' \in \MS \setminus \Srch_h(\Gamma)} \til\BP^M_h(s'|s,\pi(s)) \\ 
&= d^{\Mbar(\Gamma),\pi}_{h-1}(\term) + \sum_{s' \in \MS \setminus \Srch_h(\Gamma)} d^{M,\pi}_h(s')
\end{align*}
where the inequality uses \cref{fact:gamma-monotonicity}. Inducting on $h$ completes the proof.
\end{proof}

The following lemma is in the analyses of $\PCO$ and $\PCR$, to show that a truncated max-policy cover is also a $(1,\epsilon)$-policy cover in the sense of \cref{eq:rfrl-pc}.

\begin{lemma}\label{lemma:term-ub}
Let $\pi \in \Pi$. For any $h \in [H]$ and $s \in \MS$, it holds that
\[d^{\Mbar(\emptyset),\pi}_h(s) \geq d^{M,\pi}_h(s) -  h|\MS|\trunc.\]
\end{lemma}

\begin{proof}
We have $d^{\Mbar(\emptyset),\pi}_h(\term) = d^{\Mbar_h(\emptyset),\pi}_h(\term)$ by \cref{fact:trunc-dists}. Moreover \[d^{\Mbar_1(\emptyset),\pi}_h(\term) = d^{\Mbar_1(\emptyset),\pi}_1(\term) = \sum_{z \in \MS \setminus \Srch_1(\emptyset)} \til\BP_1(z) \leq |\MS| \trunc.\] 
For any $2 \leq k \leq h$, we have
\begin{align*}
d^{\Mbar_k(\emptyset),\pi}_h(\term) - d^{\Mbar_{k-1}(\emptyset),\pi}_h(\term) 
&= d^{\Mbar_k(\emptyset),\pi}_k(\term) - d^{\Mbar_{k-1}(\emptyset),\pi}_k(\term) \\ 
&= \E^{\Mbar_{k-1}(\emptyset),\pi}  \left[\til\BP_k^{\Mbar_k(\emptyset)}(\term\mid{}s_{k-1},a_{k-1}) - \til\BP_k^{\Mbar_{k-1}(\emptyset)}(\term\mid{}s_{k-1},a_{k-1})\right] \\ 
&= \E^{\Mbar_{k-1}(\emptyset),\pi}\left[\sum_{z \in \MS \setminus \Srch_k} \til\BP^M_k(z\mid{}s_{k-1},a_{k-1})\right] \\ 
&= \sum_{z \in \MS \setminus \Srch_k} d^{\Mbar_{k-1}(\emptyset),\pi}_{k-1}(z) \\ 
&\leq |\MS|\trunc.
\end{align*}
Therefore $d^{\Mbar(\emptyset),\pi}_h(\term) \leq h|\MS|\trunc$ by telescoping. Now for any $s \in \MS$, this means that
\begin{align*}
d^{\Mbar(\emptyset),\pi}_h(s)
&= 1 - d^{\Mbar(\emptyset),\pi}_h(\term) - \sum_{s' \in \MS \setminus \{s\}} d^{\Mbar(\emptyset),\pi}_h(s') \\ 
&\geq 1 - h|\MS|\trunc - \sum_{s' \in \MS \setminus \{s\}} d^{M,\pi}_h(s') \\ 
&= d^{M,\pi}_h(s) - h|\MS|\trunc
\end{align*}
where the inequality also uses \cref{fact:gamma-monotonicity}.
\end{proof}


The following result, which will be used in the analysis of $\PSDP$ (\cref{lemma:psdp-trunc-online}), is a variant of the classical Performance Difference Lemma \citep{kakade2002approximately}; see also \cite{golowich2024exploring}.

\begin{lemma}[Performance Difference Lemma for truncated MDPs]\label{lemma:perf-diff-trunc}
Fix a finite set $\Gamma \subset \Pi$ and $k \in \{1,\dots,H-1\}$. Let $R:\Xbar\to[0,1]$ be a function with $R(\term)=0$. Then for any policies $\pi,\pi^\st \in \Pi$ it holds that
\[\E^{\Mbar(\Gamma),\pi}[R(x_{k+1})] - \E^{M,\pi}[R(x_{k+1})] \leq \sum_{h=1}^k \E^{\Mbar(\Gamma),\pi^\st}[Q^{M,\pi,\bfr}_h(x_h,a_h) - V^{M,\pi,\bfr}_h(x_h)]\]
where $\bfr=(\bfr_1,\dots,\bfr_H)$ is defined by $\bfr_{k+1}(x,a) = R(x)$ and $\bfr_h(x,a) = 0$ for all $h \neq k+1$, and we have defined $Q^{M,\pi,\bfr}_h(\term,a) := 0$ and $V^{M,\pi,\bfr}_h(\term) := 0$ for all $h \in [H]$ and $a \in \MA$.
\end{lemma}

\begin{proof}
Observe that for any $h \in \{1,\dots,k\}$, $x_h \in \Xbar$, $a_h \in \MA$, we have
\begin{equation}
Q^{M,\pi,\bfr}_h(x_h,a_h) 
= \EE_{x_{h+1} \sim \BP^M_{h+1}(\cdot|x_h,a_h)}[V^{M,\pi,\bfr}_{h+1}(x_{h+1})]
= \EE_{x_{h+1} \sim \BP^{\Mbar_h(\Gamma)}_{h+1}(\cdot|x_h,a_h)}[V^{M,\pi,\bfr}_{h+1}(x_{h+1})]
\label{eq:qv-equiv}
\end{equation}
by \cref{fact:trunc-trans}. For notation convenience, write $\Mbar_0(\Gamma) := M$. Now we have
\begin{align*}
&\E^{\Mbar(\Gamma),\pi^\st}[R(x_{k+1})] - \E^{M,\pi}[R(x_{h+1})] \\ 
&= \E^{\Mbar_{k+1}(\Gamma),\pi^\st}[Q^{M,\pi,\bfr}_{k+1}(x_{k+1},a_{k+1})] - \E^{M,\pi^\st}[V^{M,\pi,\bfr}_1(x_1)] \\ 
&= \E^{\Mbar_{k+1}(\Gamma),\pi^\st}[Q^{M,\pi,\bfr}_{k+1}(x_{k+1},a_{k+1})] - \E^{M,\pi^\st}[V^{M,\pi,\bfr}_1(x_1)] + \sum_{h=1}^k \E^{\Mbar_h(\Gamma),\pi^\st}[Q^{M,\pi,\bfr}_h(x_h,a_h) - V^{M,\pi,\bfr}_{h+1}(x_{h+1})] \\ 
&= \sum_{h=1}^{k+1}\left ( \E^{\Mbar_h(\Gamma),\pi^\st}[Q^{M,\pi,\bfr}_h(x_h,a_h)] - \E^{\Mbar_{h-1}(\Gamma),\pi^\st}[V^{M,\pi,\bfr}_h(x_h)]\right) \\ 
&\leq \sum_{h=1}^{k+1} \left(\E^{\Mbar_h(\Gamma),\pi^\st}[Q^{M,\pi,\bfr}_h(x_h,a_h)] - \E^{\Mbar_h(\Gamma),\pi^\st}[V^{M,\pi,\bfr}_h(x_h)]\right)
\end{align*}
where the first equality is by \cref{fact:trunc-dists} and the fact that $R(\term)=0$, the second equality is by \cref{eq:qv-equiv}, and the inequality is by \cref{fact:trunc-monotonicity} (along with the fact that $V^{M,\pi,\bfr}_h \geq 0$ and $V^{M,\pi,\bfr}_h(\term) = 0$). Finally, observe that $Q^{M,\pi,\bfr}_{k+1}(x_{k+1},a_{k+1}) = R(x_{k+1}) = V^{M,\pi,\bfr}_{k+1}(x_{k+1})$ for any $x_{k+1} \in \Xbar$, so the final term in the summation vanishes. We conclude that
\begin{align*}
&\E^{\Mbar(\Gamma),\pi^\st}[R(x_{k+1})] - \E^{M,\pi}[R(x_{h+1})] \\
&\leq \sum_{h=1}^{k} \left(\E^{\Mbar_h(\Gamma),\pi^\st}[Q^{M,\pi,\bfr}_h(x_h,a_h)] - \E^{\Mbar_h(\Gamma),\pi^\st}[V^{M,\pi,\bfr}_h(x_h)]\right) \\ 
&= \sum_{h=1}^k \left(\E^{\Mbar(\Gamma),\pi^\st}[Q^{M,\pi,\bfr}_h(x_h,a_h)] - \E^{\Mbar(\Gamma),\pi^\st}[V^{M,\pi,\bfr}_h(x_h)]\right)
\end{align*}
where the final equality uses \cref{fact:trunc-dists}.
\end{proof}
