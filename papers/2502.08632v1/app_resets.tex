
%\dfc{Add short overview of how section is organized and move PCR here. it would also be good to change subsection titles to make it more clear which algorithms they are analyzing.}

In this section we prove that for any concept class $\Phi$, there is a reduction from reward-free RL (\cref{def:strong-rf-rl}) in the reset access model to one-context regression (\cref{def:one-con-regression}). The formal statement is provided below.

\nc{\phisi}{\phi^\st(x^{(i)}_h)}
\nc{\phisj}{\phi^\st(x^{(j)}_h)}

\begin{theorem}[General version of \cref{cor:reset-rl-to-regression}]\label{thm:pcr-app}
There is a constant $C_{\ref{thm:pcr-app}}>0$ and an algorithm $\PCR$ (\cref{alg:pcr}) so that the following holds. Let $\Phi \subseteq (\MX\to\MS)$ be any concept class, and let $\Reg$ be a $\Nreg$-efficient one-context regression oracle for $\Phi$. Then $\PCR(\Reg,\Nreg,|\MS|,\cdot)$ %with $N:=\Nreg\left(\left(\frac{\epsilon\delta}{H|\MA||\MS|}\right)^{C_{\ref{cor:online-rl-to-regression}}},\left(\frac{\epsilon\delta}{H|\MA||\MS|}\right)^{C_{\ref{cor:online-rl-to-regression}}}\right)$ 
is an $(\Nrl,\Krl)$-efficient reward-free RL algorithm for $\Phi$ in the reset access model, with:
\begin{itemize}
    \item $\Krl(\epsilon,\delta,H,|\MA|) \leq H^2|\MS|^2$
    \item $\Nrl(\epsilon,\delta,H,|\MA|) \leq \left(\frac{H|\MA||\MS|}{\epsilon\delta}\right)^{C_{\ref{thm:pcr-app}}} \Nreg\left(\left(\frac{\epsilon\delta}{H|\MA||\MS|}\right)^{C_{\ref{thm:pcr-app}}},\left(\frac{\epsilon\delta}{H|\MA||\MS|}\right)^{C_{\ref{thm:pcr-app}}}\right)$.
\end{itemize}
Moreover, the oracle time complexity of $\PCR$ is at most $\left(\frac{H|\MA||\MS|}{\epsilon\delta}\right)^{C_{\ref{thm:pcr-app}}} \Nreg\left(\left(\frac{\epsilon\delta}{H|\MA||\MS|}\right)^{C_{\ref{thm:pcr-app}}},\left(\frac{\epsilon\delta}{H|\MA||\MS|}\right)^{C_{\ref{thm:pcr-app}}}\right).$
\end{theorem}



In particular, \cref{cor:reset-rl-to-regression} follows from \cref{thm:pcr-app} by substituting $\Nreg(\epsilon,\delta) := \Nregc/(\epsilon\delta)^{\Creg}$ into the above bounds. Henceforth, fix a concept class $\Phi$, a $\Nreg$-efficient one-context regression oracle $\Reg$, and a $\Phi$-decodable block MDP $M$ with horizon $H$, action set $\MA$, and unknown decoding function $\phi^\st \in \Phi$. We also define truncations of $M$ (see \cref{sec:truncated-mdps}), with the parameters $\trunc,\tsmall>0$ as defined in \cref{alg:pcr}.

\subsection{$\PCR$ \colt{Pseudocode and }Overview}\label{subsec:pcr-overview}

\colt{\input{alg_pcr}}

We start by giving an overview of the algorithm $\PCR$ (\cref{alg:pcr}). The structure is similar to that of $\PCO$ (\cref{alg:pco}), our algorithm from the episodic setting. In particular, the differences are entirely within the subroutine $\EPCR$ (\cref{alg:epcr}), the analogue of $\EPCO$ (\cref{alg:extend-pc-online}) from the episodic setting. Within $\EPCO$, the difference is in how the kinematics are estimated (and what precise kinematics function is estimated)---since we no longer have access to a two-context regression oracle, but we do have the ability to reset to any previously-seen state.

\paragraph{Overview of $\EPCR$.} As shown in \cref{alg:epcr}, $\EPCR$ takes as input a one-context regression oracle $\Reg$, a step $h \in [H]$, a set of policy covers $\Psi_{1:h}$, a backup policy cover $\Gamma$, and certain sample complexity and tolerance parameters. As with $\EPCO$, the goal is to produce a policy cover for step $h+1$, and to this end the algorithm estimates a certain kinematics function, defines internal reward functions by (implicitly) clustering together observations with similar kinematics, and uses $\PSDP$ (\cref{alg:psdpb}) to find a policy that $\pihat^{(t)}$ optimizes each reward function $\MR^{(t)}$.

As discussed in \cref{sec:resets}, the main difference compared to $\EPCO$ (and $\HOMER$) is in the estimation of kinematics. Rather than designing a dataset where the Bayes predictor must essentially distinguish between ``real'' and ``fake'' transitions (which inherently requires two contexts), $\EPCR$ samples $m$ discriminator observations $x_h^{(1)},\dots,x_h^{(m)}$ at step $h$ (by rolling in with the given policy cover $\Psi_h$ and backup policy cover $\Gamma$). For each of these observations $x_h^{(i)}$ and each action $a\in\MA$, $\EPCR$ uses reset access to draw many conditional samples from $\BP^M_{h+1}(\cdot\mid{}x_h^{(i)}, a)$, and then constructs a dataset $\MD_{i,a}$ where the Bayes predictor must essentially predict if an observation was conditionally sampled from $(x_h^{(i)},a)$ or from some other observation/action pair.

More formally, as shown in \cref{alg:epcr}, for each $i \in [m]$ and $a \in \MA$, $\EPCR$ constructs a dataset $\MD_{i,a}$ with samples from the following procedure. First, draw $j \sim \Unif([m])$ and $a_h \sim \Unif(\MA)$. Then reset to $x_h^{(j)}$, and sample $x_{h+1} \sim \BP^M_{h+1}(\cdot\mid{}x_h^{(j)},a_h)$. If $j = i$ and $a_h = a$, then add sample $(x_{h+1},1)$ to the dataset; otherwise add $(x_{h+1},0)$. It can be checked that the Bayes predictor $\EE[y\mid{}x_{h+1}]$ for this dataset is the kinematics function $w_{h+1}(\cdot;i,a)$ defined in \cref{eq:pcr-kinematics}.By the Block MDP assumption, $w_{h+1}(x_{h+1};i,a)$ only depends on $x_{h+1}$ through $\phi^\st(x_{h+1})$, so the guarantee of one-context regression applies, and invoking $\Reg$ on $\MD_{i,a}$ gives a good approximation $\wh w_{h+1}(\cdot;i,a)$ of $w_{h+1}(\cdot;i,a)$ with high probability.

This approximation is used in a similar fashion as $\wh f_{h+1}$ is used in $\EPCO$---the only difference henceforth is that there is no need to sample additional ``test observations'', since $x_h^{(1)},\dots,x_h^{(m)}$ serve this purposes.

We formally analyze $\EPCR$ in \cref{sec:epcr-analysis}; the main guarantee is \cref{thm:extend-pc-trunc}.

\paragraph{Overview of $\PCR$.} The algorithm $\PCR$ is identical to $\PCO$ aside from (1) various parameter choices, and (2) invoking $\EPCR$ rather than $\EPCO$. The algorithm proceeds in $R = |\MS|H$ rounds, and in each round $r$, it iteratively uses $\EPCR$ to construct sets $\Psi^{(r)}_{1:H}$, which are added to the backup policy cover for the next round. The output is the union of all sets (of bounded size) that were produced by $\EPCR$.

We formally analyze $\PCR$ (and thereby prove \cref{thm:pcr-app}) in \cref{sec:pcr-analysis}.

%The algorithm $\PCR$ is structured similarly to the episodic RL algorithm $\PCO$ (\cref{alg:pco}), and hence this section is structured similarly to \cref{sec:app_online}. In \cref{sec:epcr-analysis} we prove a guarantee for $\EPCR$ (\cref{alg:epcr}), the main subroutine of $\PCR$. In \cref{sec:pcr-analysis} we complete the proof of \cref{thm:pcr-app}. Henceforth we fix a concept class $\Phi$, a $\Nreg$-efficient one-context regression oracle $\Reg$, and a $\Phi$-decodable block MDP $M$ with horizon $H$ and action set $\MA$. We also define truncations of $M$ (see \cref{sec:truncated-mdps}), with the parameters $\trunc,\tsmall>0$ as defined in \cref{alg:pcr}.


\subsection{Analysis of $\EPCR$ (\creftitle{alg:epcr})}\label{sec:epcr-analysis}

The following theorem is our main guarantee for $\EPCR$ (\cref{alg:epcr}). Recall that we have fixed a concept class $\Phi$, a $\Nreg$-efficient one-context regression oracle $\Reg$, and a $\Phi$-decodable block MDP $M$ with horizon $H$, action set $\MA$, and unknown decoding function $\phi^\st \in \Phi$. We have also defined truncations of $M$ (see \cref{sec:truncated-mdps}), with the parameters $\trunc,\tsmall>0$ as defined in \cref{alg:pcr}.

\begin{theorem}\label{thm:extend-pc-trunc}
Let $h \in \{1,\dots,H-1\}$. Let $\delta,\alpha > 0$ and $m,n,N \in \NN$. Let $\Gamma \subset \Pi$ be a finite set of policies. Suppose that $\Psi_{1:h}$ are $\alpha$-truncated policy covers (\cref{defn:trunc-pc}) for $M$ at steps $1,\dots,h$. Suppose that $m \geq \frac{2}{\min(\alpha\trunc,\tsmall)}\log(|\MS|/\delta)$, $n \geq m|\MA|\trunc^{-1}\log(|\MS|/\delta)$, $N \geq \Nreg(\epsilon,\delta)$, and
\begin{equation} \epsilon^{1/8} \leq \frac{\alpha \trunc^2 \tsmall}{6H(m|\MA|)^{3/2}}.\label{eq:param-assm}
\end{equation}
Consider the execution of $\EPCR$ with $\gamma := \epsilon^{1/8}$ and $\gamma' := 2\epsilon^{1/4}$. Then with probability at least $1-(2+m|\MA|+H|\MA|n)\delta-\sqrt{m|\MA|}n\epsilon^{1/4}$, the following two properties hold:
\begin{itemize}
\item $|\Psi_{h+1}| \leq |\MS|$.
\item Either $\Psi_{h+1}$ is a $(1-4\trunc)$-truncated max policy cover (\cref{defn:trunc-max-pc}) for $M$ at step $h+1$, or else \[\max_{\pi\in\Psi_{h+1}} d^{\Mbar(\Gamma),\pi}_{h+1}(\term) \geq \trunc^2.\]
\end{itemize}
\end{theorem}

See \cref{sec:truncated-mdps} for the definition of the truncated MDP $\Mbar(\Gamma)$ and the truncated policy covers. Like \cref{thm:extend-pc-trunc-online} (the analogous guarantee for $\EPCO$), this result shows that either $\EPCR$ produces a policy cover, or one of the policies in the output reaches the terminal state $\term$ in $\Mbar(\Gamma)$, which means that it discovered a state not well-covered by policies in $\Gamma$.

Let us fix the inputs to $\EPCR$: in addition to the one-context regression oracle $\Reg$ (\cref{def:two-con-regression}), we fix a layer $h \in [H-1]$, sets of policies $\Psi_1,\dots,\Psi_h$ and $\Gamma$, sample counts $n,m,N \in \NN$, and tolerances $\gamma,\gamma' \in (0,1)$. The first step of $\EPCR$ is to use one-context regression and reset access to estimate the kinematics function $w_{h+1}$ defined informally in \cref{eq:pcr-kinematics} and formally below. \cref{lemma:w-est-error} shows that with high probability, the estimate $\wh w_{h+1}(\cdot;i,a)$ is an accurate estimate of $w_{h+1}(\cdot;\phi^\st(x_h^{(i)}),a)$ for all actions $a \in \MA$ and ``test'' observations $x_h^{(1)},\dots,x_h^{(m)}$. Next, \cref{lemma:target-error-trunc} shows that the reward functions $\MR^{(t)}$ designed by clustering with respect to $\wh w_{h+1}$ approximately induce exploration of all latent reachable states. We then use these two lemmas to prove \cref{thm:extend-pc-trunc}.

\begin{definition}\label{def:beta-w}
For fixed $x^{(1)}_h,\dots,x^{(m)}_h$, we define distributions $\betahat_h,\betahat_{h+1} \in \Delta(\MS)$ by 
\[\betahat_h(s) := \frac{1}{m}\sum_{j=1}^m \mathbbm{1}[\phisj=s]\]
and
\[\betahat_{h+1}(s) := \frac{1}{m}\sum_{j=1}^m \EE_{a\sim\Unif(\MA)} \til\BP^M_{h+1}(s\mid{}\phisj, a).\]
For any $a_h \in \MA$ and $s_h,s_{h+1}\in\MS$ we also define
\[w_{h+1}(s_{h+1};s_h,a_h) := \frac{\til \BP^M_{h+1}(s_{h+1}\mid{}s_h,a_h)}{\sum_{j=1}^m\sum_{a \in \MA} \til\BP^M_{h+1}(s_{h+1}\mid{}\phisj,a)}.\]
\end{definition}

\begin{lemma}\label{lemma:w-est-error}
Fix a realization of $\MC = \{x_h^{(1)},\dots,x_h^{(m)}\}$. If $N \geq \Nreg(\epsilon,\delta)$, then it holds with probability at least $1-\delta m |\MA|$ that
\begin{equation}\EE_{x_{h+1} \sim \til\BO_{h+1} \betahat_{h+1}} \max_{(i,a) \in [m]\times\MA} \left|\what_{h+1}(x_{h+1};i,a) - w_{h+1}(\phi^\st(x_{h+1});\phi^\st(x_h^{(i)}),a) \right| \leq \sqrt{m|\MA|\epsilon}.
\label{eq:w-est-error}
\end{equation}
\end{lemma}

\begin{proof}
Fix $i \in [m]$ and $a \in \MA$. The dataset $\MD_{i,a}$ consists of $N$ i.i.d. samples. Let $(x_{h+1},y)$ denote the first sample, so that $x_{h+1} \sim \BP^M_{h+1}(\cdot\mid{}x^{(j)}_h,a_h)$ and $y = \mathbbm{1}[j=i \land a_h=a]$ for latent random variables $j \sim \Unif([m])$ and $a_h \sim \Unif(\MA)$. The marginal distribution of $x_{h+1}$ is exactly $\til\BO_{h+1}\betahat_{h+1}$. Also,
\begin{align*}
\EE[y\mid{}x_{h+1}=x]
&= \Pr[j=i \land a_h=a\mid{}x_{h+1}=x] \\ 
&= \frac{\Pr[x_{h+1}=x\mid{}j=i\land a_h=a]\Pr[j=i \land a_h=a]}{\Pr[x_{h+1}=x]} \\ 
&= \frac{\frac{1}{m|\MA|} \til \BO^M_{h+1}(x\mid{}\phi^\st(x)) \til\BP^M_{h+1}(\phi^\st(x)\mid{}\phi^\st(x_h^{(i)}), a)}{\frac{1}{m|\MA|} \sum_{j=1}^m \sum_{a \in \MA} \til \BO^M_{h+1}(x_{h+1}\mid{}\phi^\st(x_{h+1})) \til\BP^M_{h+1}(\phi^\st(x_{h+1})\mid{}\phi^\st(x_h^{(j)}), a)} \\ 
&= \frac{\til\BP^M_{h+1}(\phi^\st(x)\mid{}\phi^\st(x_h^{(i)}), a)}{ \sum_{j=1}^m \sum_{a \in \MA} \til\BP^M_{h+1}(\phi^\st(x)\mid{}\phi^\st(x_h^{(j)}), a)} \\ 
&= w_{h+1}(\phi^\st(x);\phisi,a)
\end{align*}
by \cref{def:beta-w}. Hence, we can apply the guarantee of $\Reg$ (\cref{def:one-con-regression}) with distribution $\til\BO_{h+1}\betahat_{h+1}$ and ground truth predictor $s_{h+1} \mapsto w_{h+1}(s_{h+1};\phisi,a)$. Since $N \geq \Nreg(\epsilon,\delta)$, we get that with probability at least $1-\delta$, the output $\what(\cdot;i,a)$ of $\Reg(\MD_{i,a})$ satisfies
\[\EE_{x_{h+1}\sim\til\BO_{h+1}\betahat_{h+1}} \left(\what_{h+1}(x_{h+1};i,a) - w_{h+1}(\phi^\st(x_{h+1});\phisi,a)\right)^2 \leq \epsilon.\]
Condition on the event that this bound holds for all $i \in [m]$ and $a \in \MA$, which occurs with probability at least $1-\delta m |\MA|$. Then
\begin{align*}
&\EE_{x_{h+1} \sim \til\BO_{h+1} \betahat_{h+1}} \max_{(i,a) \in [m]\times\MA} \left|\what_{h+1}(x_{h+1};i,a) - w_{h+1}(\phi^\st(x_{h+1});\phi^\st(x_h^{(i)}),a) \right|\\
&\leq \sqrt{\EE_{x_{h+1} \sim \til\BO_{h+1} \betahat_{h+1}} \max_{(i,a) \in [m]\times\MA} \left(\what_{h+1}(x_{h+1};i,a) - w_{h+1}(\phi^\st(x_{h+1});\phi^\st(x_h^{(i)}),a) \right)^2} \\ 
&\leq \sqrt{\sum_{(i,a) \in [m]\times\MA}\EE_{x_{h+1} \sim \til\BO_{h+1} \betahat_{h+1}} \left(\what_{h+1}(x_{h+1};i,a) - w_{h+1}(\phi^\st(x_{h+1});\phi^\st(x_h^{(i)}),a) \right)^2} \\ 
&\leq \sqrt{m|\MA|\epsilon}
\end{align*}
as claimed.
\end{proof}





%\section{General block MDPs}






%\subsection{Learning a Policy Cover}

\begin{lemma}\label{lemma:target-error-trunc}
Suppose that the event of \cref{lemma:w-est-error} holds. Let $\Gamma \subset \Pi$ be a finite set of policies, and let $\ccov > 0$. Suppose that $\{\phi^\st(x_h^{(1)}),\dots,\phi^\st(x_h^{(m)})\} \supseteq \Srch_h(\Gamma)$. Also suppose that $\betahat_{h+1}(s) \geq \ccov \cdot \max_{\pi\in\Pi} d^{\Mbar(\Gamma),\pi}_{h+1}(s)$ for all $s \in \MS$. Then for any $t \in [n]$ and $s^\st \in \Srch_{h+1}(\Gamma)$, there is some $K = K(\Gamma,s^\st) \geq 1$ such that
\begin{align*}
&\max_{\pi\in\Pi} \left|\E^{\Mbar(\Gamma),\pi}[\MR^{(t)}(x_{h+1})] - K \cdot d^{\Mbar(\Gamma),\pi}_{h+1}(s^\st)\right| \\
&\leq m\gamma + \frac{\sqrt{m|\MA|\epsilon}}{\ccov \gamma} + \frac{\max_{(i,a) \in [m]\times\MA} \left|\what_{h+1}(\xbart;i,a) - w_{h+1}(s^\st; \phi^\st(x_h^{(i)}),a)\right|}{\gamma}
\end{align*}
where $\MR^{(t)}, \xbart$ are as defined in \cref{alg:epcr}, and we let $\MR^{(t)}(\term):=0$.
\end{lemma}

\begin{proof}
\iffalse
For any $\pi \in \Pi$, we have by definition of $\MR^{(t)}$ (\lineref{line:rt-def}) that
\[\E^{\Mbar(\Gamma),\pi}[\MR^{(t)}(x_{h+1})] = \E^{\Mbar(\Gamma),\pi} \left[g\left(\max_{(i,a) \in [m]\times\MA} |\what_{h+1}(\xbart;i,a) - \what_{h+1}(x_{h+1};i,a)|\right)\mathbbm{1}[s_{h+1}\in\MS]\right]\]
\fi
Fix $\pi \in \Pi$. For $s,s' \in \MS$, define \[\Delta(s,s') := \max_{(i,a) \in [m]\times\MA} |w_{h+1}(s;\phisi,a)-w_{h+1}(s';\phisi,a)|\] and
\[W^\pi := \E^{\Mbar(\Gamma),\pi} \left[g(\Delta(s_{h+1}, s^\st))\mathbbm{1}[s_{h+1}\in\MS]\right].\]
We start by proving that $\EE^{\Mbar(\Gamma),\pi}[\MR^{(t)}(x_{h+1})]$ is close to $W^\pi$ for all $\pi \in \Pi$. Recall from \lineref{line:rt-def} that for any $x_{h+1} \in \MX$, we have \[\MR^{(t)}(x_{h+1}) = g\left(\max_{(i,a) \in [m]\times\MA} |\what_{h+1}(\xbart;i,a) - \what_{h+1}(x_{h+1};i,a)|\right)\]
where $g(z) = \max(0, 1-z/\gamma)$. Thus, for any $s_{h+1} \in \MS$, we have
\begin{align}
&\left|\EE_{x_{h+1}\sim\BO_{h+1}(\cdot|s_{h+1})}\left[ \MR^{(t)}(x_{h+1}) - g\left(\Delta(s_{h+1},s^\st)\right)\right]\right|\nonumber \\ 
&\leq \frac{1}{\gamma}\EE_{x_{h+1}\sim\BO_{h+1}(\cdot\mid{}s_{h+1})} \Bigg[\max_{(i,a) \in [m]\times\MA} \bigg| \left|\what_{h+1}(x_{h+1};i,a) - \what_{h+1}(\xbart;i,a)\right| \nonumber\\
&\hspace{14.3em}- \left| w_{h+1}(s_{h+1};\phisi,a) - w_{h+1}(s^\st;\phisi,a)\right|\bigg|\Bigg] \nonumber\\ 
&\leq \frac{1}{\gamma}\underbrace{\EE_{x_{h+1}\sim\BO_{h+1}(\cdot\mid{}s_{h+1})} \left[\max_{(i,a) \in [m]\times\MA} \left| \what_{h+1}(x_{h+1};i,a) - w_{h+1}(s_{h+1};\phisi,a)\right|\right]}_{E_1(s_{h+1})} \nonumber\\
&\qquad+ \frac{1}{\gamma} \underbrace{\max_{(i,a) \in [m]\times\MA} \left| \what_{h+1}(\xbart;i,a) - w_{h+1}(s^\st;\phisi,a)\right|}_{E_2} \label{eq:what-w-single}
\end{align}
where the first inequality uses that $g$ is $1/\gamma$-Lipschitz. It follows that
\begin{align}
\left| \E^{\Mbar(\Gamma),\pi}[\MR^{(t)}(x_{h+1})] - W^\pi\right|
&\leq \frac{1}{\gamma} \E^{\Mbar(\Gamma),\pi}[E_1(s_{h+1})] + \frac{E_2}{\gamma} \nonumber\\ 
&\leq \frac{1}{\ccov \gamma} \EE_{s_{h+1} \sim \wh\beta_{h+1}}[E_1(s_{h+1})] + \frac{E_2}{\gamma} \nonumber\\ 
&\leq \frac{\sqrt{m|\MA|\epsilon}}{\ccov \gamma} + \frac{E_2}{\gamma} \label{eq:rt-wpi-diff}
\end{align}
where the first inequality is by \cref{eq:what-w-single}, the second inequality uses the assumption on $\betahat_{h+1}$ and nonnegativity of $E_1$, and the third inequality uses \cref{eq:w-est-error}. 

Next, for any $s_{h+1} \in \Srch_{h+1}(\Gamma)$, note that $\BP^{\Mbar(\Gamma)}_{h+1}(s_{h+1}\mid{}s_h,a_h) = \BP^M_{h+1}(s_{h+1}\mid{}s_h,a_h)$ and $\BP^{\Mbar(\Gamma)}_{h+1}(s_{h+1}\mid{}\term,a_h) = 0$ for all $s_h\in\MS$, $a_h \in \MA$. Thus, the following equality holds for all $s_{h+1} \in \Srch_{h+1}(\Gamma)$:
\begin{align}
d^{\Mbar(\Gamma),\pi}_{h+1}(s_{h+1}) 
&= \sum_{(s_h,a_h) \in \MS\times\MA} d^{\Mbar(\Gamma),\pi}_h(s_h,a_h) \til\BP^M_{h+1}(s_{h+1}\mid{}s_h,a_h) \nonumber\\ 
&= \left(\sum_{(s_h,a_h)\in\MS\times\MA} d^{\Mbar(\Gamma),\pi}_h(s_h,a_h)w_{h+1}(s_{h+1};s_h,a_h)\right)\sum_{j=1}^m\sum_{a\in\MA}\til\BP^M_{h+1}(s_{h+1}\mid{}\phisj,a)
\label{eq:dpi-expansion}
\end{align}
where the final equality is by definition of $w_h(s_{h+1};s_h,a_h)$ (\cref{def:beta-w}). It follows from \cref{eq:dpi-expansion} and the fact that $d^{\Mbar(\Gamma),\pi}_{h+1}(s_{h+1}) = 0$ for all $s_{h+1} \in \MS\setminus\Srch_{h+1}(\Gamma)$ that
\begin{align*}
W^\pi &= \sum_{s_{h+1}\in\Srch_{h+1}(\Gamma)} g(\Delta(s_{h+1},s^\st))\left(\sum_{(s_h,a_h)\in\MS\times\MA} d^{\Mbar(\Gamma),\pi}_h(s_h,a_h)w_{h+1}(s_{h+1};s_h,a_h)\right)\\ 
&\hspace{10em}\cdot\left( \sum_{j=1}^m\sum_{a\in\MA}\til\BP^M_{h+1}(s_{h+1}\mid{}\phi^\st(x_h^{(j)}),a)\right).
\end{align*}
Motivated by this expression, define
\begin{align*}
\til W^\pi &:= \sum_{s_{h+1}\in\Srch_{h+1}(\Gamma)} g(\Delta(s_{h+1},s^\st))\left(\sum_{(s_h,a_h)\in\MS\times\MA} d^{\Mbar(\Gamma),\pi}_h(s_h,a_h)w_{h+1}(s^\st;s_h,a_h)\right)\\ 
&\hspace{10em}\cdot\left( \sum_{j=1}^m\sum_{a\in\MA}\til\BP^M_{h+1}(s_{h+1}\mid{}\phi^\st(x_h^{(j)}),a)\right).
\end{align*}
Observe that
\begin{align}
&\sum_{(s_h,a_h)\in\MS\times\MA} d^{\Mbar(\Gamma),\pi}_h(s_h,a_h)|w_{h+1}(s_{h+1};s_h,a) - w_{h+1}(s^\st;s_h,a)| \nonumber\\
&\leq \max_{s_h \in \Srch_h(\Gamma)} \max_{a \in \MA} |w_{h+1}(s_{h+1};s_h,a) - w_{h+1}(s^\st;s_h,a)|\nonumber\\ 
&\leq \max_{(i,a) \in [m]\times\MA}|w_{h+1}(s_{h+1};\phi^\st(x^{(i)}),a)-w_{h+1}(s^\st;\phi^\st(x^{(i)}),a)| \nonumber\\
&= \Delta(s_{h+1},s^\st),\label{eq:d-sh-st-bound}
\end{align}
where the first inequality uses the fact that $\sum_{(s_h,a_h)\in\MS\times\MA} d^{\Mbar(\Gamma),\pi}_h(s_h,a_h) \leq 1$ and $d^{\Mbar(\Gamma),\pi}_h(s_h,a_h) = 0$ if $s \in \MS \setminus \Srch_h(\Gamma)$, and the second inequality uses the assumption that $\Srch_h(\Gamma) \subseteq \{\phi^\st(x_h^{(1)}),\dots,\phi^\st(x_h^{(m)})\}$. Using \cref{eq:d-sh-st-bound}, we get
\begin{align}
& \left|W^\pi - \til W^\pi \right| \nonumber\\ 
&\leq \sum_{s_{h+1}\in\Srch_{h+1}(\Gamma)} g(\Delta(s_{h+1},s^\st))\Delta(s_{h+1},s^\st) \sum_{j=1}^m \sum_{a\in\MA} \til\BP^M_{h+1}(s_{h+1}\mid{}\phi^\st(x_h^{(j)}),a) \nonumber\\ 
&\leq \gamma \sum_{s_{h+1}\in\Srch_{h+1}(\Gamma)} \sum_{j=1}^m \sum_{a\in\MA}\til\BP^M_{h+1}(s_{h+1}\mid{}\phi^\st(x_h^{(j)}),a) \nonumber \\ 
&= \gamma m \label{eq:wpi-kd-diff}
\end{align}
where the first inequality is by \cref{eq:d-sh-st-bound} and the second inequality uses the fact that $z\cdot g(z) \leq \gamma$ for all $z \geq 0$. Now from the definition of $\til W^\pi$,
\begin{align}
\til W^\pi 
&= \left(\sum_{(s_h,a_h)\in\MS\times\MA} d^{\Mbar(\Gamma),\pi}_h(s_h,a_h)w_{h+1}(s^\st;s_h,a_h)\right) \sum_{s_{h+1} \in \Srch_{h+1}(\Gamma)} g(\Delta(s_{h+1},s^\st))\sum_{j=1}^m \sum_{a\in\MA} \til\BP^M_{h+1}(s_{h+1}\mid{}\phi^\st(x_h^{(j)}),a) \nonumber\\ 
&= \frac{d^{\Mbar(\Gamma),\pi}_{h+1}(s^\st)}{\sum_{j=1}^m \sum_{a\in\MA}\til\BP^M_{h+1}(s^\st\mid{}\phi^\st(x_h^{(j)}),a)} \cdot \sum_{s_{h+1}\in\Srch_{h+1}(\Gamma)}g(\Delta(s_{h+1},s^\st))\sum_{j=1}^m \sum_{a\in\MA} \til\BP^M_{h+1}(s_{h+1}\mid{}\phi^\st(x_h^{(j)}),a)  \nonumber \\ 
&= K(\Gamma,s^\st) \cdot d^{\Mbar(\Gamma),\pi}_{h+1}(s^\st) \label{eq:kd-expr}
\end{align}
where the second equality uses \cref{eq:dpi-expansion} together with the assumption that $s^\st \in \Srch_{h+1}(\Gamma)$, and in the final equality we have defined
\begin{align*}
K(\Gamma,s^\st)
&:= \frac{\sum_{s_{h+1}\in\Srch_{h+1}(\Gamma)}g(\Delta(s_{h+1},s^\st))\sum_{j=1}^m \sum_{a\in\MA} \til\BP^M_{h+1}(s_{h+1}\mid{}\phi^\st(x_h^{(j)}),a)}{\sum_{j=1}^m \sum_{a\in\MA}\til\BP^M_{h+1}(s^\st\mid{}\phi^\st(x_h^{(j)}),a)}.
\end{align*}
Note that $K(\Gamma,s^\st) \geq 1$, since $s^\st \in \Srch_{h+1}(\Gamma)$ and $g(\Delta(s^\st,s^\st)) = g(0) = 1$. Combining \cref{eq:rt-wpi-diff}, \cref{eq:wpi-kd-diff}, and \cref{eq:kd-expr}, we get that
\[\left|\E^{\Mbar(\Gamma),\pi}[\MR^{(t)}(x_{h+1})] - K(\Gamma,s^\st) \cdot d^{\Mbar(\Gamma),\pi}_{h+1}(s^\st)\right| \leq \frac{\sqrt{m|\MA|\epsilon}}{\ccov \gamma} + \frac{E_2}{\gamma} + \gamma m.\]
Substituting in the definition of $E_2$ yields the result.
\end{proof}





\begin{proof}[Proof of \cref{thm:extend-pc-trunc}]
For any fixed $s \in \Srch_h(\Gamma)$ and $i \in [m]$, we have by \cref{item:h-cov-lb} of \cref{lemma:srch-gamma-covering} that
\[\Pr[\phi^\st(x_h^{(i)}) = s] \geq \frac{\min(\alpha\trunc,\tsmall)}{2}.\]
Let $\ME_1$ be the event that for each $s \in \Srch_h(\Gamma)$ there is some $i \in [m]$ with $\phi^\st(x_h^{(i)}) = s$. Then
\[\Pr[\ME_1] \geq 1 - |\MS|\left(1 - \frac{\min(\alpha\trunc,\tsmall)}{2}\right)^m \geq 1-\delta\]
by the assumption that $m \geq \frac{2}{\min(\alpha\trunc,\tsmall)} \log(|\MS|/\delta)$. Henceforth condition on $x_h^{(1)},\dots,x_h^{(m)}$ and suppose that $\ME_1$ holds.

For any $s_{h+1} \in \Srch_{h+1}(\Gamma)$, we have by definition of $\betahat_{h+1}$ (\cref{def:beta-w}) that
\begin{align}
\betahat_{h+1}(s_{h+1}) 
&= \frac{1}{m}\sum_{j=1}^m \EE_{a\sim\Unif(\MA)} \til\BP^M_{h+1}(s_{h+1}|\phi^\st(x^{(j)}),a) \nonumber\\ 
&\geq \frac{1}{m} \max_{s_h \in \Srch_h(\Gamma)} \EE_{a\sim\Unif(\MA)} \til\BP^M_{h+1}(s_{h+1}|s_h,a) \nonumber\\ 
&\geq \frac{1}{m|\MA|} \max_{(s_h,a_h) \in \Srch_h(\Gamma)\times\MA} \til\BP^M_{h+1}(s_{h+1}|s_h,a_h) \nonumber\\ 
&\geq \frac{1}{m|\MA|} \max_{\pi\in\Pi} d^{\Mbar(\Gamma),\pi}_{h+1}(s_{h+1}) \label{eq:betahat-coverage}
\end{align}
where the first inequality uses $\ME_1$ and the final inequality uses the fact that \[d^{\Mbar(\Gamma),\pi}_{h+1}(s_{h+1}) = \sum_{(s_h,a_h) \in \Srch_h(\Gamma)\times\MA} d^{\Mbar(\Gamma),\pi}_h(s_h,a_h)\til\BP^M_{h+1}(s_{h+1}|s_h,a_h).\] 
Since $\max_{\pi\in\Pi} d^{\Mbar(\Gamma),\pi}_{h+1}(s_{h+1}) = 0$ for all $s_{h+1} \in \MS\setminus\Srch_{h+1}(\Gamma)$, in fact the bound
\begin{equation} 
\betahat_{h+1}(s_{h+1}) \geq \frac{1}{m|\MA|} \max_{\pi\in\Pi} d^{\Mbar(\Gamma),\pi}_{h+1}(s_{h+1}) \geq \frac{1}{m|\MA|} \max_{\pi\in\Pi} d^{\Mbar(\emptyset),\pi}_{h+1}(s_{h+1})
\label{eq:betahat-coverage-2}
\end{equation} holds for all $s_{h+1} \in \MS$, where the last inequality is by \cref{fact:gamma-monotonicity}.

Next, let $\ME_2$ be the event that 
\begin{equation}
\EE_{x_{h+1} \sim \til\BO_{h+1} \betahat_{h+1}} \max_{(i,a) \in [m]\times\MA} \left|\what_{h+1}(x_{h+1};i,a) - w_{h+1}(\phi^\st(x_{h+1});\phi^\st(x_h^{(i)}),a) \right| \leq \sqrt{m|\MA|\epsilon}.
\label{eq:w-west-applied}
\end{equation}
By \cref{lemma:w-est-error} and the assumption that $N \geq \Nreg(\epsilon,\delta)$, the event $\ME_2$ occurs with probability at least $1-m|\MA|\delta$ over the randomness of $(\MD_{i,a})_{i,a}$ and $\Reg$. Condition on $\what_{h+1}(\cdot;\cdot,\cdot)$ and suppose that $\ME_2$ holds.

For each $t \in [n]$, let $\ME_3^t$ be the event that 
\[\max_{(i,a)\in[m]\times\MA} |\what_{h+1}(\xbart;i,a) - w_{h+1}(\phi^\st(\xbart); \phi^\st(x_h^{(i)}),a)| \leq \epsilon^{1/4}.\] Since $\xbart \sim \til\BO_{h+1}\betahat_{h+1}$, we have by Markov's inequality and \cref{eq:w-west-applied} that $\Pr[\lnot \ME_3^t] \leq \sqrt{m|\MA|}\epsilon^{1/4}$. Define $\ME_3 := \bigcap_{t=1}^n \ME_3^t$. By the union bound, $\ME_3$ occurs with probability at least $1-\sqrt{m|\MA|}n\epsilon^{1/4}$ over the randomness of $\ol x_{h+1}^{(1)},\dots,\ol x_{h+1}^{(n)}$. 

Also, for each $s \in \Srch_{h+1}(\emptyset)$, let $t(s) \in [1,n] \cup \{\infty\}$ be the infimum over $t$ such that $\phi^\st(\xbart) = s$, and let $\ME_4^s$ be the event that $t(s) < \infty$. For each $t \in [1,n]$, since $\phi^\st(\xbart)$ has distribution $\betahat_{h+1}$, we have 
\[\Pr[\phi^\st(\xbart)=s] = \betahat(s)  \geq \frac{1}{m|\MA|} \max_{\pi\in\Pi} d^{\Mbar(\emptyset),\pi}_{h+1}(s) \geq \frac{\trunc}{m|\MA|}\]
by \cref{eq:betahat-coverage-2} and \cref{fact:trunc-reachability}.
Thus, $\Pr[\lnot \ME_4^s] \leq (1-\trunc/(m|\MA|))^n \leq \delta/|\MS|$ for any fixed $s \in \Srch_{h+1}(\emptyset)$, by the assumption that $n \geq m|\MA|\trunc^{-1} \log(|\MS|/\delta)$. Define $\ME_4 := \bigcap_{s \in \Srch_{h+1}(\emptyset)} \ME_4^s$. By the union bound, $\ME_4$ occurs with probability at least $1-\delta$ over the randomness of $\ol x_{h+1}^{(1)},\dots,\ol x_{h+1}^{(n)}$.

Condition on $\ol x_{h+1}^{(1)},\dots,\ol x_{h+1}^{(n)}$ and suppose that $\ME_3 \cap \ME_4$ holds. Note that the set $\Tclus$ is now determined. For each $t \in \Tclus$ let $\ME_5^t$ be the event that
\[\E^{M,\pihat^{(t)}}[\MR^{(t)}(x_{h+1})] \geq \max_{\pi\in\Pi} \E^{\Mbar(\Gamma),\pi}[\MR^{(t)}(x_{h+1})] - \frac{4H\sqrt{|\MA|\epsilon}}{\min(\alpha\trunc,\tsmall)}\]
where $\pihat^{(t)}$ is defined in \lineref{line:psdp-call}. By the theorem assumptions on $\Reg$ and $\Psi_{1:h}$ and the fact that $N \geq \Nreg(\epsilon,\delta)$, \cref{lemma:psdp-trunc-online} gives $\Pr[\ME_5^t] \geq 1-H|\MA|\delta$, so $\Pr[\ME_5] \geq 1-H|\MA|n\delta$ where $\ME_5 := \cap_{t \in \Tclus} \ME_5^t$. Condition on $\ME_5$. We have now restricted to an event of total probability at least $1 - 2\delta - (m|\MA|+H|\MA|n)\delta - \sqrt{m|\MA|}n\epsilon^{1/4}$; we argue that in this event, the properties claimed in the theorem statement hold.

\paragraph{Size of $\Psi_{h+1}$.} First, we argue that $|\Psi_{h+1}| \leq |\MS|$. Indeed, suppose that there are $t < t'$ with $t,t' \in \Tclus$ and $\phi^\st(\ol x_{h+1}^{(t)}) = \phi^\st(\ol x_{h+1}^{(t')})$. By \lineref{line:cluster-test}, we know that 
\[\max_{(i,a) \in [m]\times\MA} |\what_{h+1}(\ol x_{h+1}^{(t)};i,a) - \what_{h+1}(\ol x_{h+1}^{(t')};i,a)| > \gamma' = 2\epsilon^{1/4}.\] 
But this contradicts $\ME_3$ (in particular, the bounds implied by $\ME_3^t$ and $\ME_3^{t'}$ in combination with the triangle inequality and the assumption that $\phi^\st(\xbart) = \phi^\st(\ol x_{h+1}^{(t')})$). We conclude that indeed $|\Psi_{h+1}| \leq |\MS|$.

\paragraph{Coverage of $\Psi_{h+1}$.} It remains to prove the second property of the theorem statement. Fix $s \in \Srch_{h+1}(\emptyset)$. Let $t^\st(s)$ be the minimal $t \in \Tclus$ such that 
\begin{equation}\max_{(i,a) \in [m]\times\MA} |\what_{h+1}(\ol x_{h+1}^{(t(s))};i,a)-\what(\ol x_{h+1}^{(t)};i,a)| \leq \gamma'.\label{eq:t-tst}\end{equation}
Note that $t^\st(s)$ necessarily exists, because either $t(s) \in \Tclus$ or, if not, \lineref{line:cluster-test} implies that some other $t \in \Tclus$ satisfies the above bound. Next, by $\ME_1$, \cref{eq:betahat-coverage-2}, and \cref{eq:w-west-applied}, we can apply \cref{lemma:target-error-trunc} with coverage parameter $\ccov := 1/(m|\MA|)$, target state $s^\st = s$, and index $t := t^\st(s)$. We get that
\begin{align}
&\max_{\pi\in\Pi} \left|\E^{\Mbar(\Gamma),\pi}[\MR^{(t^\st(s))}(x_{h+1})] - K(\Gamma,s) \cdot d^{\Mbar(\Gamma),\pi}_{h+1}(s)\right|  \nonumber\\ 
&\leq m\gamma + \frac{(m|\MA|)^{3/2}\sqrt{\epsilon}}{\gamma} + \frac{\max_{(i,a)\in[m]\times\MA}\left|\what_{h+1}(\ol x^{(t^\st(s))}_{h+1};i,a) - w_{h+1}(s;\phi^\st(x_h^{(i)}),a)\right|}{\gamma} \nonumber \\ 
&\leq m\gamma + \frac{(m|\MA|)^{3/2}\sqrt{\epsilon}}{\gamma} + \frac{\epsilon^{1/4} + \max_{(i,a)\in[m]\times\MA}\left|\what_{h+1}(\ol x^{(t^\st(s))}_{h+1};i,a) - \what_{h+1}(\ol x^{(t(s))}_{h+1};i,a)\right|}{\gamma} \nonumber \\ 
&\leq m\gamma + \frac{(m|\MA|)^{3/2}\sqrt{\epsilon}}{\gamma} + \frac{\epsilon^{1/4} + \gamma'}{\gamma} \nonumber\\
&\leq \trunc^2,\label{eq:rkd-error}
\end{align}
where the second inequality is by $\ME_3$ and the fact that $s = \phi^\st(\ol x_{h+1}^{(t(s))})$, the third inequality is by \cref{eq:t-tst}, and the final inequality is by choice of $\gamma,\gamma'$ and \cref{eq:param-assm}. We now distinguish two cases.

\paragraph{Case I.} Suppose that 
\[\E^{M,\pihat^{(t^\st(s))}}[\MR^{(t^\st(s))}(x_{h+1})] \geq \E^{\Mbar(\Gamma),\pihat^{(t^\st(s))}}[\MR^{(t^\st(s))}(x_{h+1})] + \trunc^2.\]
Then
\begin{align*}
&d^{\Mbar(\Gamma),\pihat^{(t^\st(s))}}_{h+1}(\term) \\ 
&= \sum_{s \in \MS} \left(d^{M,\pihat^{(t^\st(s))}}_{h+1}(s) - d^{\Mbar(\Gamma),\pihat^{(t^\st(s))}}(s))\right) \\ 
&\geq \sum_{s \in \MS} \left(d^{M,\pihat^{(t^\st(s))}}_{h+1}(s) - d^{\Mbar(\Gamma),\pihat^{(t^\st(s))}}_{h+1}(s))\right) \EE_{x\sim\BO_{h+1}(\cdot|s)}[\MR^{(t^\st(s))}(x)] \\ 
&\geq \trunc^2 
\end{align*}
where the equality is by the fact that $d^{M,\pihat^{(t^\st(s))}}_{h+1}(\cdot)$ is a distribution supported on $\MS$; the first inequality uses \cref{fact:gamma-monotonicity} and the fact that $\MR^{(t^\st(s))}(x) \leq 1$ for all $x \in \MX$. Thus $\max_{\pi\in\Psi_{h+1}} d^{\Mbar(\Gamma),\pi}(\term) \geq \trunc^2$, so the second property of the theorem statement is satisfied. 

\paragraph{Case II.} Suppose that
\begin{equation} \E^{M,\wh\pi^{(t^\st(s))}\circ_h\Unif(\MA)}[\MR^{(t^\st(s))}(x_{h+1})] < \E^{\Mbar(\Gamma),\wh\pi^{(t^\st(s))}\circ_h\Unif(\MA)}[\MR^{(t^\st(s))}(x_{h+1})] + \trunc^2.\label{eq:m-mbar-closeness}\end{equation}
Now, 
\begin{align*}
K(\Gamma, s) \cdot d^{\Mbar(\Gamma), \pihat^{(t^\st(s))}}_{h+1}(s) 
&\geq \E^{\Mbar(\Gamma),\pihat^{(t^\st(s))}}[\MR^{(t^\st(s))}(x_{h+1})] - \trunc^2 \\ 
&\geq \E^{M,\pihat^{(t^\st(s))}}[\MR^{(t^\st(s))}(x_{h+1})] - 2\trunc^2 \\ 
&\geq \max_{\pi\in\Pi} \E^{\Mbar(\Gamma),\pi}[\MR^{(t^\st(s))}(x_{h+1})] - 3\trunc^2 \\ 
&\geq \max_{\pi\in\Pi} K(\Gamma,s) \cdot d^{\Mbar(\Gamma),\pi}_{h+1}(s) -  4\trunc^2 \\ 
&\geq K(\Gamma,s)(1-4\trunc) \max_{\pi\in\Pi} d^{\Mbar(\Gamma),\pi}_{h+1}(s)
\end{align*}
where the first inequality is by \cref{eq:rkd-error}, the second inequality is by \cref{eq:m-mbar-closeness}, the third inequality is by $\ME_5$ and \cref{eq:param-assm}, the fourth inequality is by \cref{eq:rkd-error}, and the fifth inequality uses the fact that $\max_{\pi\in\Pi} d^{\Mbar(\Gamma),\pi}_{h+1}(s) \geq \trunc$ (\cref{fact:trunc-reachability} together with \cref{fact:gamma-monotonicity} and the fact that $s \in \Srch_{h+1}(\emptyset)$) and $K(\Gamma,s) \geq 1$. Thus, since $\pihat^{(t^\st(s))} \in \Psi_{h+1}$, we have 
\begin{align}
\max_{\pi\in\Psi_{h+1}} d^{M,\pi}_{h+1}(s)
&\geq \max_{\pi\in\Psi_{h+1}} d^{\Mbar(\Gamma),\pihat^{(t^\st(s))}}_{h+1}(s) \nonumber\\ 
&\geq (1-4\trunc)\max_{\pi\in\Pi} d^{\Mbar(\Gamma),\pi}_{h+1}(s) \nonumber\\ 
&\geq (1-4\trunc)\max_{\pi\in\Pi} d^{\Mbar(\emptyset),\pi}_{h+1}(s)
\label{eq:coverage-final-reset}
\end{align}
by two applications of \cref{fact:gamma-monotonicity}. Now recall that $s \in \Srch_{h+1}(\emptyset)$ was arbitrary. Moreover, if $s \in \MS\setminus \Srch_{h+1}(\emptyset)$ then $\max_{\pi\in\Pi} d^{\Mbar(\emptyset),\pi}_{h+1}(s) = 0$, so \cref{eq:coverage-final-reset} still holds. We conclude that $\Psi_{h+1}$ is a $(1-4\trunc)$-truncated max policy cover for $M$ at step $h+1$ (\cref{defn:trunc-max-pc}) as needed.
\end{proof}

\iffalse
\begin{proof}
Fix some $1 \leq r \leq R$. For convenience, write $\alpha := \frac{\trunc}{4|\MA|^2|\MS|^2}$. For each $h \in [H]$, let $\ME_{h,r}$ be the event that $|\Psi_h^{(r)}| \leq |\MS|$ and $\Psi_h^{(r)}$ is a $\alpha$-truncated policy cover for $M$ at step $h$; let $\MF_{h,r}$ be the event that $|\Psi_{h}^{(r)}| \leq |\MS|$ and $\max_{\pi\in\Psi_{h}^{(r)}} d^{\Mbar(\Gamma^{(r)}),\pi}_{h}(\term) \geq \frac{\trunc}{8|\MA|}$. It's clear that $\ME_{1,r} = \ME_{2,r} = 1$ (since $\alpha \leq 1/|\MA|$). Also, by \cref{thm:extend-pc-trunc} and choice of parameters, we have for each $h \in \{3,\dots,H\}$ that
\[\Pr\left[\lnot (\ME_{h,r} \cup \MF_{h,r}) \cap \bigcap_{1 \leq k < h} \ME_{k,r}\right] \leq \frac{\delta}{HR}.\]
In the event that the events $\MF_{1,r},\dots,\MF_{H,r}, \bigcap_{h\in[H]} \ME_{h,r}$ all fail, there is always some maximal $h \in [H]$ such that $\bigcap_{1 \leq k \leq h} \ME_{k,r}$ holds; it must be that $2 \leq h<H$, and $\ME_{h+1,r}$ and $\MF_{h+1,r}$ both fail. Thus,
\[\Pr\left[\left(\lnot \bigcap_{h \in [H]} \ME_{h,r}\right) \cap \bigcap_{h \in [H]} \left(\lnot \MF_{h,r}\right)\right] \leq \sum_{h=3}^H \Pr\left[\lnot (\ME_{h,r} \cup \MF_{h,r}) \cap \bigcap_{1 \leq k < h} \ME_{k,r}\right] \leq \frac{\delta}{|\MS|}.\]
Let $\ME_r$ denote the complementary event, and let $\ME := \bigcap_{1 \leq r \leq R} \ME_r$; we have $\Pr[\ME] \geq 1-\delta$. We claim that $\PC$ succeeds under event $\ME$. Indeed, there are two cases to consider.

\begin{enumerate}
\item In the first case, there is some $r \in [R]$ such that $\bigcap_{h \in [H]} \ME_{h,r}$ holds. Then for each $h \in [H]$, $|\Psi_h^{(r)}| \leq |\MS|$ and $\Psi_h^{(r)}$ is a $\alpha$-truncated policy cover for $M$ at step $h$. Thus, $\bigcup_{1 \leq r' \leq R: |\Psi_h^{(r')}| \leq |\MS|} \Psi_h^{(r')}$ is an $\alpha/(|\MS|R)$-truncated policy cover for $M$ at step $h$. Since $R = |\MS|H$, this is as desired.
\item In the second case, for each $r \in [R]$, there is some $h \in [H]$ such that $\MF_{h,r}$ holds. For each $r$, define
\[\MV^{(r)} := \left\{(s,h) \in \MS\times[H]: \max_{\pi\in\Gamma^{(r)}} d^{M,\pi}_h(s) \geq \frac{\trunc}{8|\MA||\MS|H}\right\}.\]
Fix some $r \in [R]$ and pick $h \in [H]$ so that $\MF_{h,r}$ holds. Then $\max_{\pi \in \Psi_{h}^{(r)}} d^{\Mbar(\Gamma),\pi}_h(\term) \geq \frac{\trunc}{8|\MA|}$. By \cref{lemma:term-prob}, there is some $(s,k) \in (\MS\setminus \Srch_k(\Gamma))\times[h]$ such that $\max_{\pi\in\Psi_h^{(r)}} d^{M,\pi}_k(s) \geq \frac{\trunc}{8|\MA||\MS|H}$. Thus $(s,k) \in \MV^{(r+1)}$. Moreover, since $s \not \in \Srch_k(\Gamma^{(r)})$, we have $\E_{\pi\sim\Unif(\Gamma^{(r)})} d^{M,\pi}_k(s) < \tsmall$. Using the fact that $|\Gamma^{(r)}| \leq RH|\MS|$ and choice of $\tsmall$, it follows that $\max_{\pi\in\Gamma^{(r)}} d^{M,\pi}_k(s) < RH|\MS|\tsmall \leq \frac{\trunc}{8|\MA||\MS|H}$. So $(s,k) \not \in \MV^{(r)}$. We conclude that $|\MV^{(r+1)}| > |\MV^{(r)}|$. Since this inequality holds for all $r \in [R]$ and $|\MV^{(1)}| \geq H$, we get $|\MV^{(R)}| \geq H + R - 1 > |\MS|H$. Contradiction, so in fact this second case cannot occur.
\end{enumerate}
This completes the proof.
\end{proof}
\fi

\subsection{Analysis of $\PCR$ (\creftitle{alg:pcr})}\label{sec:pcr-analysis}

We can now use \cref{thm:extend-pc-trunc} to complete the analysis of $\PCR$, proving \cref{thm:pcr-app} (and thus \cref{cor:reset-rl-to-regression}). After modularizing out the analysis of $\EPCR$/$\EPCO$, the analyses of $\PCR$/$\PCO$ are essentially identical, so we omit the details here for brevity.

\vspace{1em}

\begin{proof}[Proof of \cref{thm:pcr-app}]
Fix the remaining inputs $\epfinal,\delta>0$ to $\PCO(\Reg,\Nreg,|\MS|,\cdot)$. The oracle time complexity bound and bound on $\Nrl$ are clear from the parameter choices and pseudocode, so long as $C_{\ref{thm:pcr-app}}$ is a sufficiently large constant. Moreover, it is immediate from the algorithm description that $|\Psi| \leq HR|\MS| \leq H^2|\MS|^2$. In order to show that the algorithm is $(\Nrl,\Krl)$-efficient, it remains to argue that with probability at least $1-\delta$, \cref{eq:rfrl-pc} holds for all $h \in [H]$ and $s \in \MS$, with parameter $\epfinal$.

Recall that $\trunc = \epfinal/(4+H|\MS|)$. Fix some $1 \leq r \leq R$. For convenience, write $\alpha := \frac{1-4\trunc}{|\MS|}$. For each $h \in [H]$, let $\ME_{h,r}$ be the event that $|\Psi_h^{(r)}| \leq |\MS|$ and $\Psi_h^{(r)}$ is a $(1-4\trunc)$-truncated max policy cover for $M$ at step $h$; let $\MF_{h,r}$ be the event that $|\Psi_{h}^{(r)}| \leq |\MS|$ and $\max_{\pi\in\Psi_{h}^{(r)}} d^{\Mbar(\Gamma^{(r)}),\pi}_{h}(\term) \geq \trunc^2$. It's clear that $\Pr[\ME_{1,r}] = 1$ (since $|\Psi_1^{(r)}| = 1$ and $d^{M,\piunif}_1(s) = d^{M,\pi}_1(s)$ for all $s\in\MS$ and $\pi \in \Pi$). Also, note that in the event $\ME_{k,r}$, we have that $\Psi_k^{(r)}$ is an $\alpha$-truncated policy cover for $M$ at step $k$. Thus, by \cref{thm:extend-pc-trunc} and choice of parameters (so long as $C$ is a sufficiently large constant), we have for each $h \in \{2,\dots,H\}$ that
\begin{equation} \Pr\left[\lnot (\ME_{h,r} \cup \MF_{h,r}) \cap \bigcap_{1 \leq k < h} \ME_{k,r}\right] \leq \Pr\left[\lnot (\ME_{h,r} \cup \MF_{h,r}) \middle | \bigcap_{1 \leq k < h} \ME_{k,r}\right] \leq \frac{\delta}{HR}.\label{eq:epcr-guarantee-symbolic}\end{equation}
The remainder of the proof is identical to that of \cref{thm:pco-app}. 
\end{proof}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
