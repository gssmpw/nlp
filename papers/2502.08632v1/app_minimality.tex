
%\dfc{Add short overview of how section is organized and what $\TwoRed$ does.}

In this section we prove \cref{cor:regression-to-online-rl}, restated below. This theorem asserts that for any \emph{regular} (\cref{def:regular}) concept class $\Phiaug$, there is a reduction $\RegToRL$ (\cref{alg:regtorl}) from two-context regression to reward-free episodic RL.

\regtorl*

Any regular concept class can be defined by augmenting some base class $\Phi$ as specified in \cref{def:phiaug}. Accordingly, the main component of $\RegToRL$ is a reduction $\TwoRed$ (\cref{alg:twored}) from two-context regression over $\Phi$ to reward-free episodic RL over $\Phiaug$. The full reduction $\RegToRL$ simply applies $\TwoRed$ in conjunction with a reduction $\TwoAug$ (\cref{alg:twoaug}) from two-context regression over $\Phiaug$ to two-context regression over $\Phi$.

Henceforth, fix sets $\MS,\MX$ and a concept class $\Phi \subset (\MX\to\MS)$. We may define an augmented concept class $\Phiaug \subseteq (\Xaug\to\Saug)$ as follows (in \cref{sec:regtorl} we will formally argue that any regular concept class can be expressed in this way):

\begin{definition}[Augmented concept class]\label{def:phiaug}
Define augmented state space $\Saug := \MS \sqcup \{0,1\}$ and augmented observation space $\Xaug := \MX \sqcup \{0,1\}$. For each $\phi \in \Phi$ define $\aug(\phi): \Xaug \to \Saug$ by
\[\aug(\phi)(x) := \begin{cases} \phi(x) & \text { if } x \in \MX \\ x & \text { otherwise } \end{cases}.\]
Finally, define an extended function class $\Phiaug := \{\aug(\phi): \phi\in\Phi\}$.
\end{definition}
%\dhruv{this might cause notational conflict if we end up analyzing an RL algorithm and introducing truncated MDPs...}

In \cref{sec:regtorl-overview} we give pseudocode and an overview of $\RegToRL$ and its main subroutine $\TwoRed$. In \cref{sec:twored} we formally analyze $\TwoRed$. In \cref{sec:regtorl} we use this to analyze $\RegToRL$, completing the proof of \cref{cor:regression-to-online-rl}. We defer the analysis of $\TwoAug$ to \sssref{sec:twoaug}.

\subsection{$\RegToRL$ Pseudocode and Overview}\label{sec:regtorl-overview}

We start by giving a brief overview of the reduction $\RegToRL$ (\cref{alg:regtorl}); for additional intuition, see also the discussion in \cref{sec:episodic-nec}. The main subroutine is $\TwoRed$ (\cref{alg:twored}), which is used to reduce two-context regression over $\Phi$ to reward-free RL over $\Phiaug$. We start with an overview of this subroutine, and then briefly discuss $\TwoAug$ (\cref{alg:twoaug}), the reduction from two-context regression over $\Phiaug$ to two-context regression over $\Phi$. The full reduction $\RegToRL$ is a direct combination of these two subroutines.



\subsubsection{$\TwoRed$: Simulating an RL Oracle for Two-Context Regression}

\paragraph{Algorithm overview.} As shown in \cref{alg:twored}, $\TwoRed$ takes as input a reward-free episodic RL oracle for $\Phiaug$, a dataset $(x_1^{(i)},x_2^{(i)},y^{(i)})_{i=1}^n$ for two-context regression over $\Phi$, and accuracy parameters $\epsilon,\delta>0$. The goal is to produce and estimate $\MR:\MX\times\MX\to[0,1]$ of the Bayes optimal predictor $\EE[y^{(i)}\mid{}x_1^{(i)},x_2^{(i)}]$ for the dataset. To this end, the first step is to simulate the RL oracle on an MDP with horizon $H=2$, initial observation space $\MX$, final observation space $\MX\sqcup\{0\}$, and action space $\MA \subset [0,1]$. In particular, $\TwoRed$ uses a new sample $(x_1^{(i)},x_2^{(i)},y^{(i)})$ from the dataset for each episode of interaction---this is where it is crucial that the RL oracle does not have reset access. The first observation is $x_1^{(i)}$. When the oracle returns an action $a \in \MA \subset [0,1]$, the second observation is $x_2^{(i)}$ with probability $1-(a-y^{(i)})^2$ and $0$ otherwise.

\input{alg_minimality}

Eventually, the oracle produces a set of policies $\Psi$. Each policy is a map $\pi: \MX\to[0,1]$. To ``stitch'' these into a single predictor on $\MX\times\MX$, $\TwoRed$ estimates an error function for each. In particular, using fresh samples, the algorithm constructs a dataset consisting of samples $(x_2^{(i)}, z^{(i)})$ where $\EE[z^{(i)}\mid{} x_2^{(i)}] = \EE[(\pi(x_1^{(i)})-y^{(i)})^2\mid{} x_2^{(i)}]$ measures the error of $\pi$ on $x_1^{(i)}$, conditional on $x_2^{(i)}$. Applying a one-context regression oracle to this dataset (via \cref{alg:onered}, the reduction from one-context regression to reward-free RL) gives an estimated error function $\MR^\pi:\MX\to[0,1]$. 

Finally, the predictor $\MR$ output by $\TwoRed$ is defined as follows. Given $(x_1,x_2) \in \MX\times\MX$, identify the policy $\pi\in\Psi$ that minimizes $\MR^\pi(x_2)$, and return $\pi(x_1)$.

\paragraph{Proof outline.} As discussed in \cref{sec:episodic-nec}, the basic idea for the analysis of $\TwoRed$ is as follows. Let $M$ denote the simulated MDP, let $\phist$ denote the decoding function for the dataset, and let $f:\MS\times\MS\to[0,1]$ denote the true latent predictor for the dataset. It can be checked that $M$ satisfies $\Phiaug$-decodability (\cref{lemma:phiaug-decodable}). For any latent state $s \in \MS$, a policy $\pi$ that approximately maximizes $d^{M,\pi}_2(s)$ must optimally ``guess'' $y^{(i)}$ conditioned on both $x_1^{(i)}$ and the event $\phist(x_2^{(i)}) = s$; thus, as shown in \cref{lemma:visitation-diffs}, such a $\pi$ must approximately \emph{minimize} the following loss:
\[L_s(\pi) := \EE_{(x_1,x_2) \sim \MD} \left[\mathbbm{1}[\phi^\st(x_2) = s] (\pi(x_1) - f(\phi^\st(x_1),\phi^\st(x_2)))^2\right].\]
By the definition of reward-free RL, it follows that for each $s \in \MS$, there exists some $\pi \in \Psi$ such that $L_s(\pi)$ is small (\cref{lemma:psi-guarantee}), i.e. $\pi$ is a good approximation of $x_1 \mapsto f(\phist(x_1),s)$. 

It remains to argue that the policy selection procedure in the definition of the final predictor $\MR$ (i.e. picking the policy $\pihat^{x_2}$ that minimizes the estimated error $\MR^\pi(x_2)$) appropriately identifies \emph{which} policy is good for a given covariate $(x_1,x_2)$. Indeed, as shown in \cref{lemma:rpi-error}, for fixed $x_2$, $\MR^\pi(x_2)$ is monotonic in $L_{\phist(x_2)}(\pi)$ as $\pi$ varies. Thus, intuitively, the selection procedure makes sense. The remaining technical subtlety is that there is an apparent distributional mismatch. We know that the following loss is small, for each $x_2$ with $\phist(x_2)=s$:
\[L_s(\pihat^{x_2}) = \EE_{(x_1',x_2') \sim \MD} \left[\mathbbm{1}[\phi^\st(x_2') = s] (\pihat^{x_2}(x_1') - f(\phi^\st(x_1'),\phi^\st(x_2')))^2\right].\]
However, to bound the squared error of $\MR$, we would like to bound the following quantity:
\[\EE_{(x_1',x_2') \sim \MD}\left[ \mathbbm{1}[\phi^\st(x_2') = s] (\pihat^{x_2'}(x_1') - f(\phi^\st(x_1'),\phi^\st(x_2')))^2\right],\]
i.e. where context $x_2'$ in the squared error term is the same as the context used to select the policy $\pihat^{x_2'}$. However, it turns out that these two quantities can be related in expectation over $x_2$, using $\phist$-realizability of the context distribution (\cref{lemma:switching}).

We formally analyze $\TwoRed$ in \cref{sec:twored}; see \cref{thm:two-context-reduction} for the formal guarantee.

\subsubsection{$\TwoAug$: Augmenting the regression}

\paragraph{Algorithm overview.} As shown in \cref{alg:twoaug}, $\TwoAug$ takes as input a two-context regression oracle for $\Phi$, samples $(x_1^{(i)},x_2^{(i)},y^{(i)})_{i=1}^n$, and tolerance parameters $\epsilon,\delta\in(0,1/2).$ The goal is to solve two-context regression for $\Phiaug$. The basic idea is that since the extra states $\{0,1\}$ are fully observed, regression onto these states is actually simpler than regression onto the hidden states. In more detail, consider all indices $i$ for which $x_1^{(i)} = 0$ but $x_2^{(i)} \in \MX$. We can define a reduced dataset consisting of the samples $(\xbar, x_2^{(i)})$ for each such $i$, where $\xbar\in\MX$ is an arbitrary fixed observation. It's straightforward to check that this dataset is a valid two-context regression dataset for $\Phi$, so the oracle yields a good predictor for the corresponding conditional distribution (as long as there is enough data). We can do a similar argument for all other cases (e.g. $x_1^{(i)} \in \MX$ and $x_2^{(i)} = 1$, etc.), and it is straightforward to stitch together the predictors on subsets of $\Xaug\times\Xaug$ into a single predictor for the whole covariate space.

We defer the formal analysis of $\TwoAug$ to \sssref{sec:twoaug}; see \cref{prop:twoaug} for the formal guarantee.

\subsection{Analysis of $\TwoRed$ (\creftitle{alg:twored})}\label{sec:twored}

The following theorem states our main guarantee for $\TwoRed$. As discussed above, $\TwoRed$ uses the given dataset to simulate the RL oracle on a horizon-$2$ block MDP for which exploring a latent state $s$ with near-maximal probability corresponds to learning the regression function on a subset of the covariate distribution determined by $s$. Once the oracle produces a policy cover $\Psi$, $\TwoRed$ performs one-context regression to learn a loss function $\MR^\pi$ associated with each policy $\pi \in \Psi$, and then outputs a regressor obtained by stitching together the policies (according to whichever has the best loss on the given query).

\begin{theorem}\label{thm:two-context-reduction}
Suppose that $\MO$ is an $(\Nrl,\Krl)$-efficient reward-free episodic RL oracle (\cref{def:strong-rf-rl}) for $\Phiaug$. Then $\TwoRed(\MO,\cdot)$ is a $\Nreg$-efficient two-context regression algorithm (\cref{def:two-con-regression}) for $\Phi$ with
\[\Nreg(\epsilon,\delta) := 2\Nrl\left(\frac{\epsilon^4}{16|\MS|^4},\frac{\delta}{4K'},2,\frac{4|\MS|^2}{\epsilon^2}\right) + 64|\MS|^8\epsilon^{-8}\log\left(4K'\Krl\left(\frac{\epsilon^4}{16|\MS|^4},\frac{\delta}{4K'},2,\frac{4|\MS|^2}{\epsilon^2}\right)/\delta\right) \]
where $K' = \Krl(\frac{\epsilon^2}{4|\MS|^2},\frac{\delta}{2},2,\frac{2|\MS|}{\epsilon})$.
\end{theorem}

To prove \cref{thm:two-context-reduction}, we fix $\phi^\st \in \Phi$, a $\phi^\st$-realizable distribution $\MD \in \Delta(\MX\times\MX)$, and a function $f:\MS \times \MS \to [0,1]$. For some $n \geq \Nreg(\epsilon,\delta)$, we let $(x_1^{(i)}, x_2^{(i)},y^{(i)})_{i=1}^n$ be i.i.d. samples with $(x_1^{(i)},x_2^{(i)}) \sim \MD$ and $y^{(i)} \sim \Ber(f(\phi^\st(x_1^{(i)}),\phi^\st(x_2^{(i)})))$. In the remainder of the section, we analyze the execution of $\TwoRed(\MO,(x_1^{(i)}, x_2^{(i)},y^{(i)})_{i=1}^n,\epsilon,\delta)$. Ultimately, we must show that with probability at least $1-\delta$, the circuit $\MR$ produced by $\TwoRed$ satisfies 
\begin{equation} \EE_{(x_1,x_2) \sim \MD} \left(\MR(x_1,x_2) - f(\phi^\st(x_1),\phi^\st(x_2))\right)^2 \leq \epsilon.
\label{eq:twored-error-guarantee}
\end{equation}
To begin, in \cref{lemma:phiaug-decodable,lemma:simulate-trajectory} we show that $\TwoRed$ is invoking the RL oracle $\MO$ by simulating episodic access with the $\Phiaug$-decodable block MDP defined below:

\begin{definition}[Block MDP gadget for reduction]
%Fix $\phi^\st \in \Phi$, $f: \MS \times \MS \to [0,1]$, a $\phi^\st$-realizable distribution $\MD \in \Delta(\MX\times\MX)$, and 
Fix $\epa \in (0,1)$. We define a block MDP $M$ by
\[M = M_{\phi^\st,f,\MD,\epa} := (H, \Saug,\Xaug, \MA, (\til \BP_h)_{h\in [2]},(\til \BO)_{h \in [2]}, \aug(\phi^\st))\]
where $H := 2$, the action space is $\MA := \{0,\epa,\dots,\epa\lfloor1/\epa\rfloor\}$, and $\til \BP_1 \in \Delta(\Saug)$ is the marginal distribution of $\phi^\st(x_1)$ for $(x_1,x_2) \sim \MD$. The transition distribution $\til \BP_2$ is defined as follows. For initial state $s_1 \in \MS$, next state $s_2 \in \Saug$, and action $a \in \MA$,
\[\til\BP_2(s_2\mid{}s_1,a) := 
\begin{cases}
\Prr\limits_{(x_1,x_2) \sim \MD}[\phi^\st(x_2)=s_2\mid{}\phi^\st(x_1)=s_1] \EE\limits_{y \sim \Ber(f(s_1,s_2))}\left[1 - (a-y)^2\right] & \text { if } s_2 \in \MS \\ 
\sum\limits_{s_2' \in \MS} \Prr\limits_{(x_1,x_2) \sim \MD}[\phi^\st(x_2)=s_2'\mid{}\phi^\st(x_1)=s_1] \EE\limits_{y \sim \Ber(f(s_1,s_2'))}\left[(a-y)^2\right] & \text { if } s_2 = 0 \\ 
0 & \text { if } s_2 = 1
\end{cases}.\]
Note that $\til\BP_1$ is supported on $\MS$, so it is not necessary to define $\til \BP_2(s_2\mid{}s_1,a)$ for $s_1 \in \{0,1\}$. Finally, for $s \in \MS$ and $h \in [2]$, the observation distribution $\til \BO_h(\cdot|s)$ is defined as the conditional distribution of $x_h\mid{}\phi^\st(x_h)=s$ for $(x_1,x_2) \sim \MD$. The distributions $\til\BO_h(\cdot\mid{}0)$ are fully supported on $0$, and the distributions $\til\BO_h(\cdot\mid{}1)$ are fully supported on $1$. %the second state is sampled as follows. Draw $x_2$ from $\MD$ conditioned on $x_1$, and draw $y \sim \Ber(f(\phi^\st(x_1),\phi^\st(x_2)))$. With probability $(a-y)^2$, the second state is $0$. Otherwise, the second state is $x_2$.
\end{definition}

In order to invoke the guarantees of the RL oracle, we need to verify that $M$ satisfies $\Phiaug$-decodability (\cref{lemma:phiaug-decodable}) and is in fact the MDP that is being simulated in $\TwoRed$ (\cref{lemma:simulate-trajectory}). 

\begin{lemma}\label{lemma:phiaug-decodable}
$M$ is a $\Phiaug$-decodable block MDP.
\end{lemma}

\begin{proof}
First we observe that $\til \BP_1, \til \BP_2$ are well-defined: by construction $\til \BP_1$ is a distribution. Moreover, for any $s_1 \in \MS$ and $a \in \MA$, it is clear that $\til \BP_2(\cdot|s_1,a)$ is non-negative and
\[\sum_{s_2 \in \MS} \til\BP_2(s_2\mid{}s_1,a) = \EE\limits_{\substack{(x_1,x_2) \sim \MD \\ y \sim \Ber(f(\phi^\st(x_1),\phi^\st(x_2)))}}\left[\left(1 - (a-y)^2\right)\middle| \phi^\st(x_1)=s_1\right] = 1 - \til\BP_2(0\mid{}s_1,a).\]
Thus, $\til \BP_2(\cdot\mid{}s_1,a)$ is a distribution. Finally, we observe that for any $h \in [2]$ and $s \in \MS$, the observation distribution $\til\BO_h(\cdot\mid{}s)$ is fully supported on $x_h \in \MX$ such that $\aug(\phi^\st)(x_h) = \phi^\st(x_h) = s$, by construction. Since $\aug(\phi^\st)(0) = 0$ and $\aug(\phi^\st)(1) = 1$, the same holds for $s \in \{0,1\}$.
\end{proof}

\begin{lemma}\label{lemma:simulate-trajectory}
Let $(x_1,x_2) \sim \MD$ and $y \sim \Ber(f(\phi^\st(x_1),\phi^\st(x_2)))$. The following process simulates an episode of interaction with $M$:
\begin{enumerate}
\item Pass observation $x_1$ and receive action $a \in \MA$.
\item With probability $(a-y)^2$, pass observation $0$. Otherwise, pass observation $x_2$.
\end{enumerate}
\end{lemma}

\begin{proof}
Let $p(x_1,x_2)$ denote the density of $\MD$, and observe that by $\phi^\st$-realizability \cref{def:realizable-distribution}) we can write
\[p(x_1,x_2) = \til p(\phi^\st(x_1),\phi^\st(x_2)) \til q_1(x_1\mid{}\phi^\st(x_1)) \til q_2(x_2\mid{}\phi^\st(x_2))\]
for some density $\til p$ and conditional densities $\til q_1,\til q_2$. Also let $\til p(s_2\mid{}s_1)$ denote the conditional density of $\phi^\st(x_2)\mid{}\phi^\st(x_1)$ under $(x_1,x_2) \sim \MD$. Now fix any policy $\pi:\MX \to \Delta(\MA)$ and trajectory $(s_1,x_1,a,s_2,x_2)$ where $x_2 \neq 0$. The likelihood of this trajectory under the described process is
\begin{align*}
&p(x_1,x_2) \mathbbm{1}[s_1=\phi^\st(x_1)]\mathbbm{1}[s_2=\phi^\st(x_2)] \pi(a\mid{}x_1) \EE_{y \sim \Ber(f(s_1,s_2))}[1 - (a - y)^2] \\ 
&= \til p(s_1,s_2) \til q_1(x_1\mid{}s_1) \til q_2(x_2\mid{}s_2) \pi(a\mid{}x_1)  \EE_{y \sim \Ber(f(s_1,s_2))}[1 - (a - y)^2] \\ 
&= \til\BP_1(s_1) \til p(s_2\mid{}s_1) \til\BO_1(x_1\mid{}s_1) \til\BO_2(x_2\mid{}s_2)\pi(a\mid{}x_1) \EE_{y \sim \Ber(f(s_1,s_2))}[1 - (a - y)^2] \\ 
&= \til\BP_1(s_1) \til\BO_1(x_1\mid{}s_1)\til\BO_2(x_2\mid{}s_2)\pi(a\mid{}x_1) \til\BP_2(s_2\mid{}s_1,a)
\end{align*}
which is precisely the likelihood of the trajectory under $M$. Similarly, the likelihood of any trajectory $(s_1,x_1,a,0,0)$ under the described process is
\begin{align*}
&\sum_{s_2 \in \MS} \til p(s_1,s_2) \til q_1(x_1\mid{}s_1) \pi(a\mid{}x_1) \EE_{y \sim \Ber(f(s_1,s_2))}[(a-y)^2] \\ 
&= \til\BP_1(s_1)\til\BO_1(x_1\mid{}s_1) \pi(a\mid{}x_1) \sum_{s_2 \in \MS} \til p(s_2\mid{}s_1) \EE_{y \sim \Ber(f(s_1,s_2))}[(a-y)^2] \\ 
&= \til\BP_1(s_1)\til\BO_1(x_1\mid{}s_1) \pi(a\mid{}x_1)\til \BP_2(s_2\mid{}s_1,a)
\end{align*}
as needed.
\end{proof}

Next, in \cref{lemma:psi-guarantee}, we show that for every latent state $s \in \MS$, the set of policies $\Psi$ computed by the RL oracle contains some approximate minimizer of the loss $L_s(\pi)$ defined below. To this end, the key lemma is \cref{lemma:visitation-diffs}, which characterizes the loss of a policy in terms of its visitation probability for state $s$.

\begin{definition}
For any policy $\pi \in \Pi$ and state $s \in \MS$, define
\[L_s(\pi) := \EE_{(x_1,x_2) \sim \MD} \left[\mathbbm{1}[\phi^\st(x_2) = s] (\pi(x_1) - f(\phi^\st(x_1),\phi^\st(x_2)))^2\right],\]
and for each $s \in \MS$ define
\[Z_s := \EE_{\substack{(x_1,x_2) \sim \MD \\ y \sim \Ber(f(\phi^\st(x_1),\phi^\st(x_2)))}}\left[ \mathbbm{1}[\phi^\st(x_2) = s] \left(y - f(\phi^\st(x_1),\phi^\st(x_2))^2\right)\right].\]
\end{definition}

\begin{lemma}\label{lemma:visitation-diffs}
For any policies $\pi,\pi' \in \Pi$ and state $s \in \MS$, we have $d_2^{M,\pi}(s) - d_2^{M,\pi'}(s) = L_s(\pi') - L_s(\pi)$.
\end{lemma}

\begin{proof}
By the characterization provided by \cref{lemma:simulate-trajectory}, for any policy $\pi$, the visitation distribution for a state $s_2 \in \MS$ at step $2$ is
\begin{align*}
d^{M,\pi}_2(s_2)
&= \EE_{\substack{(x_1,x_2) \sim \MD \\ y \sim \Ber(\phi^\st(x_1),\phi^\st(x_2))}} \left[\mathbbm{1}[\phi^\st(x_2)=s_2] \cdot (1 - (\pi(x_1) - y)^2)\right] \\ 
&= \EE_{\substack{(x_1,x_2) \sim \MD \\ y \sim \Ber(\phi^\st(x_1),\phi^\st(x_2))}}\left[\mathbbm{1}[\phi^\st(x_2)=s_2] \cdot \left(1 - (\pi(x_1) - f(\phi^\st(x_1),\phi^\st(x_2)) + f(\phi^\st(x_1),\phi^\st(x_2)) - y)^2\right)\right] \\ 
&= \Prr_{(x_1,x_2)\sim\MD}[\phi^\st(x_2)=s_2] - L_s(\pi) - \EE_{\substack{(x_1,x_2) \sim \MD \\ y \sim \Ber(\phi^\st(x_1),\phi^\st(x_2))}}\left[\mathbbm{1}[\phi^\st(x_2)=s_2](f(\phi^\st(x_1),\phi^\st(x_2)) - y)^2\right] \\ 
&\qquad - 2 \EE_{\substack{(x_1,x_2) \sim \MD \\ y \sim \Ber(\phi^\st(x_1),\phi^\st(x_2))}}\left[\mathbbm{1}[\phi^\st(x_2)=s_2] (\pi(x_1) - f(\phi^\st(x_1),\phi^\st(x_2)))( f(\phi^\st(x_1),\phi^\st(x_2)) - y)\right].
\end{align*}
The final term is $0$ since $\EE[y\mid{}x_1,x_2] = f(\phi^\st(x_1),\phi^\st(x_2))$. The remaining terms are all independent of $\pi$ except for $-L_s(\pi)$; hence, 
\[d^{M,\pi}_2(s_2) - d^{M,\pi'}_2(s_2) = L_s(\pi') - L_s(\pi)\]
as claimed.
\end{proof}



\begin{lemma}\label{lemma:psi-guarantee}
Suppose that $\MO$ is an $(\Nrl,\Krl)$-efficient reward-free RL oracle (\cref{def:strong-rf-rl}) for $\Phiaug$, and that $n/2 \geq \Nrl(\epsilon^2/(4|\MS|^2),\delta/2,2,2|\MS|/\epsilon)$. Then the set $\Psi$ computed in \lineref{line:oracle-policy-cover} of \cref{alg:twored} satisfies $|\Psi| \leq \Krl(\epsilon^2/(4|\MS|^2),\delta/2,2,2|\MS|/\epsilon)$. Moreover, it holds with probability at least $1-\delta/2$ that for every $s \in \MS$, there is some $\pi \in \Psi$ such that 
$L_s(\pi) \leq \epsilon^2/(2|\MS|^2).$
\end{lemma}

\begin{proof}
By \cref{lemma:simulate-trajectory}, $\MO$ is given interactive access to the MDP $M$. The claimed bound on $|\Psi|$ is immediate from \cref{def:strong-rf-rl} together with the initialization of $\MO$ (\lineref{line:initialize-oracle}) and the fact that $H=2$ and $|\MA| = 2|\MS|/\epsilon$. 

Next, by \cref{def:strong-rf-rl}, it holds with probability at least $1-\delta/2$ that for any $s \in \Saug$ and $h \in [2]$,
\begin{equation} \max_{\pi\in\Psi} d^{M,\pi}_h(s) \geq \max_{\pi \in \Pi} d^{M,\pi}_h(s) - \frac{\epsilon^2}{4|\MS|^2}.\label{eq:pc-applied}
\end{equation}
Condition on this event. Fix any $s \in \MS$ and define $\pi^\st:\Xaug \to \MA$ by $\pi^\st(x_1) := \epa\lfloor f(\phi^\st(x_1),s)/\epa\rfloor \in \MA$ for $x_1 \in \MX$ (define $\pi^\st(0),\pi^\st(1)$ arbitrarily). Note that $L_s(\pi^\st) \leq \epa^2$. By \eqref{eq:pc-applied}, there is some $\pi \in \Psi$ such that
\begin{align*}
\frac{\epsilon^2}{4|\MS|^2}
&\geq d^{M,\pi^\st}_2(s) - d^{M,\pi}_2(s) \\ 
&= L_s(\pi) - L_s(\pi^\st) \\ 
&\geq L_s(\pi) - \epa^2
\end{align*}
where the equality is by \cref{lemma:visitation-diffs}. The lemma follows from the definition of $\epa$.
\end{proof}

The following lemma shows that with high probability, each error function $\MR^\pi$ approximates an affine transformation of the loss $L_{\phist(x_2)}(\pi)$.

\begin{lemma}\label{lemma:rpi-error}
Suppose that $\MO$ is an $(\Nrl,\Krl)$-efficient reward-free RL oracle for $\Phiaug$ (\cref{def:strong-rf-rl}). Set $N = \Nrl(\epsilon^4/(16|\MS|^4), \delta/(4|\Psi|),2,4|\MS|^2/\epsilon^2)$ and $K = \Krl(\epsilon^4/(16|\MS|^4), \delta/(4|\Psi|),2,4|\MS|^2/\epsilon^2)$. If $n/2 \geq N + 64|\MS|^8\epsilon^{-8}\log(4|\Psi|K/\delta)$ then, with probability at least $1-\delta/2$, it holds for all $\pi \in \Psi$ that
\[\EE_{(x_1,x_2)\sim\MD} \left(\MR^\pi(x_2) - \frac{L_{\phi^\st(x_2)}(\pi) + Z_{\phi^\st(x_2)}}{\Prr_{(x_1',x_2') \sim \MD}[\phi^\st(x_2')=\phi^\st(x_2)]}\right)^2 \leq \frac{\epsilon^4}{4|\MS|^4}.\]
\end{lemma}

\begin{proof}
By \cref{prop:onered} and the assumption on $\MO$, we get that $\OneRed(\MO,\cdot)$ is an $\Nreg$-efficient one-context regression oracle for $\Phi$ (\cref{def:one-con-regression}) with 
\[\Nreg\left(\frac{\epsilon^4}{4|\MS|^4}, \frac{\delta}{2|\Psi|}\right) \leq N + \frac{64|\MS|^8 \log(4|\Psi| K/\delta)}{\epsilon^8} \leq n/2.\]
Fix any $\pi \in \Psi$. Observe that $\MC^\pi$ consists of $n/2$ i.i.d. samples $(x_2^{(i)}, z^{(i)})$ with $x_2^{(i)} \in \MX$ and $z^{(i)} \in \{0,1\}$. For any index $i$, by $\phi^\st$-realizability of $\MD$ and the law of $y^{(i)}$, we have that $x_2^{(i)} \perp (\pi(x_1^{(i)})-y^{(i)})^2 \mid{} \phi^\st(x_2^{(i)})$ and hence $x_2^{(i)} \perp z^{(i)} \mid{} \phi^\st(x_2^{(i)})$. Moreover, for any $x_2 \in \MX$ with $s := \phi^\st(x_2)$, we have
\begin{align*}
\EE[z^{(i)}\mid{}x_2^{(i)}=x_2] 
&= \EE[z^{(i)}\mid{}\phi^\st(x_2^{(i)}) = s] \\
&= \EE_{\substack{(x_1',x_2') \sim \MD \\ y \sim \Ber(f(\phi^\st(x_1'),\phi^\st(x_2')))}}[(\pi(x_1') - y')^2\mid{}\phi^\st(x_2')=s] \\ 
&= \EE_{(x_1',x_2') \sim \MD}[(\pi(x_1') - f(\phi^\st(x_1'),\phi^\st(x_2')))^2\mid{}\phi^\st(x_2')=s] \\ 
&\qquad+ \EE_{\substack{(x_1',x_2') \sim \MD \\ y \sim \Ber(f(\phi^\st(x_1'),\phi^\st(x_2')))}}[(f(\phi^\st(x_1'),\phi^\st(x_2')) - y)^2\mid{}\phi^\st(x_2')=s] \\ 
&= \frac{L_s(\pi) + Z_s}{\Pr_{(x_1',x_2') \sim \MD}[\phi^\st(x_2') = s]}
\end{align*}
where the penultimate equality uses that $\EE[y\mid{}x_1',x_2'] = f(\phi^\st(x_1'),\phi^\st(x_2'))$. The result now follows from \cref{def:one-con-regression} and a union bound over $\pi \in \Psi$.
\end{proof}

The following technical lemma is needed to handle the distribution mismatch discussed in \cref{sec:regtorl-overview}. Essentially, it asserts that if we sample $(x_1,x_2)$ and $(x_1',x_2')$ independently and then condition on $x_2, x_2'$ having the same latent state $s$, then $x_1$ and $x_1'$ are exchangeable, i.e. $(x_1,x_2)$ and $(x_1',x_2)$ have the same distribution.

\begin{lemma}\label{lemma:switching}
For any $s \in \MS$ and $g: \MX\times \MX \to \RR$, it holds that
\[\EE_{\substack{(x_1,x_2) \sim \MD \\ (x_1',x_2') \sim \MD}}[g(x_1,x_2)\mid{}\phi^\st(x_2)=\phi^\st(x_2')=s] = \EE_{\substack{(x_1,x_2) \sim \MD \\ (x_1',x_2') \sim \MD}}[g(x_1',x_2)\mid{}\phi^\st(x_2)=\phi^\st(x_2')=s]\]
where the random variables $(x_1,x_2)$ and $(x_1',x_2')$ in the expectation are independent draws from $\MD$.
\end{lemma}

\begin{proof}
By $\phi^\st$-realizability of $\MD$, note that $x_1,x_2$ are conditionally independent under the event $\phi^\st(x_2)=\phi^\st(x_2')=s$. Additionally, for any events $\ME,\ME' \subseteq \MX$, 
\begin{align*}
&\Pr[x_2 \in \ME \land x_1' \in \ME' \land \phi^\st(x_2) = s \land \phi^\st(x_2') = s] \\
&= \Pr[x_1 \in \ME \land \phi^\st(x_2) = s] \Pr[x_2' \in \ME' \land \phi^\st(x_2') = s] \\ 
&= \frac{\Pr[x_2 \in \ME \land \phi^\st(x_2) = s \land \phi^\st(x_2') = s] \Pr[x_1' \in \ME' \land \phi^\st(x_2) = s \land \phi^\st(x_2') = s]}{\Pr[\phi^\st(x_2) = s \land \phi^\st(x_2') = s]},
\end{align*}
so 
\begin{align*}
&\Pr[x_2 \in \ME \land x_1' \in \ME' \mid{} \phi^\st(x_2) = s \land \phi^\st(x_2') = s] \\ 
&= \Pr[x_2 \in \ME \mid{} \phi^\st(x_2) = s \land \phi^\st(x_2') = s]\Pr[x_1' \in \ME' \mid{} \phi^\st(x_2) = s \land \phi^\st(x_2') = s].
\end{align*}
Thus, $x_1',x_2$ are conditionally independent as well. But by symmetry, $x_1\mid{}\phi^\st(x_2)=\phi^\st(x_2') = s$ and $x_1'\mid{}\phi^\st(x_2)=\phi^\st(x_2') = s$ have identical distributions. Thus, $(x_1,x_2)\mid{}\phi^\st(x_2)=\phi^\st(x_2') = s$ and $(x_1',x_2)\mid{}\phi^\st(x_2)=\phi^\st(x_2') = s$ have identical distributions, which implies the claimed equality.
\end{proof}


\iffalse 
\dhruv{Explicit proof:
\begin{align*}
&\sum_{s_1,s_1',x_1,x_2,x_1',x_2'} \til p(s_1, s) \til p(s_1',s) \til q(x_1|s_1) \til q(x_1'|s_1') \til q(x_2|s) \til q(x_2' | s) g(x_1, x_2) \\
&= \sum_{s_1,s_1',x_1,x_2} \til p(s_1, s) \til p(s_1',s) \til q(x_1|s_1)  \til q(x_2|s) g(x_1, x_2)
\end{align*}

\begin{align*}
&\sum_{s_1,s_1',x_1,x_2,x_1',x_2'} \til p(s_1, s) \til p(s_1',s) \til q(x_1|s_1) \til q(x_1'|s_1') \til q(x_2|s) \til q(x_2' | s) g(x_1', x_2) \\
&=\sum_{s_1,s_1',x_2,x_1'} \til p(s_1, s) \til p(s_1',s) \til q(x_1'|s_1') \til q(x_2|s) g(x_1', x_2)\\
&=\sum_{s_1,s_1',x_2,x_1'} \til p(s_1', s) \til p(s_1,s) \til q(x_1'|s_1) \til q(x_2|s) g(x_1', x_2) \\ 
&=\sum_{s_1,s_1',x_2,x_1} \til p(s_1', s) \til p(s_1,s) \til q(x_1|s_1) \til q(x_2|s) g(x_1, x_2)
\end{align*}
}\fi

With the above ingredients, we can now formally conclude the proof of \cref{thm:two-context-reduction}.

\vspace{1em}

\begin{proof}[Proof of \cref{thm:two-context-reduction}]
Consider the event that the claimed bounds of \cref{lemma:psi-guarantee} and \cref{lemma:rpi-error} both hold, which occurs with probability at least $1-\delta$. We argue that in this event, the desired error bound \eqref{eq:twored-error-guarantee} holds.

For each $s \in \MS$ fix any $\pi^s \in \argmax_{\pi \in \Psi} d^{M,\pi}_2(s)$ (i.e. $\pi^s$ is optimal for reaching state $s$, among policies in $\Psi$). For each $x_2 \in \MX$, let $\pihat^{x_2} \in \Psi$ be the policy minimizing $\MR^\pi(x_2)$ (breaking ties as in \cref{alg:twored}). We have by definition of $\MR$ that
\begin{align*}
&\EE_{(x_1,x_2) \sim \MD} \left[(\MR(x_1,x_2) - f(\phi^\st(x_1),\phi^\st(x_2))^2 \right]\\
&= \EE_{(x_1,x_2) \sim \MD} \left[(\pihat^{x_2}(x_1) - f(\phi^\st(x_1),\phi^\st(x_2))^2 \right]\\
&= \sum_{s \in \MS} \EE_{(x_1,x_2) \sim \MD} \left[\mathbbm{1}[\phi^\st(x_2) = s] \cdot (\pihat^{x_2}(x_1) - f(\phi^\st(x_1),\phi^\st(x_2))^2\right].
\end{align*}
Fix any $s \in \MS$. On the one hand, observe that
\begin{equation}
\EE_{(x_1,x_2) \sim \MD} \left[\mathbbm{1}[\phi^\st(x_2) = s]  (\pihat^{x_2}(x_1) - f(\phi^\st(x_1),\phi^\st(x_2)))^2\right]
\leq \Prr_{(x_1,x_2) \sim \MD}[\phi^\st(x_2) = s]
\label{eq:err-bound-1}
\end{equation}
since $\pihat^{x_2}(x_1) \in \MA \subset [0,1]$ and $f(\phi^\st(x_1),\phi^\st(x_2)) \in [0,1]$. On the other hand,
\begin{align}
&\Prr_{(x_1,x_2) \sim \MD}[\phi^\st(x_2) = s] \cdot \EE_{(x_1,x_2) \sim \MD}\left[ \mathbbm{1}[\phi^\st(x_2) = s] (\pihat^{x_2}(x_1) - f(\phi^\st(x_1),\phi^\st(x_2)))^2\right] \nonumber\\ 
&= \EE_{\substack{(x_1,x_2) \sim \MD \\ (x_1',x_2') \sim \MD}}\left[ \mathbbm{1}[\phi^\st(x_2)=s]\mathbbm{1}[\phi^\st(x_2') = s]  (\pihat^{x_2}(x_1) - f(\phi^\st(x_1),\phi^\st(x_2)))^2 \right]\nonumber \\ 
&= \EE_{\substack{(x_1,x_2) \sim \MD \\ (x_1',x_2') \sim \MD}} \left[\mathbbm{1}[\phi^\st(x_2)=s]\mathbbm{1}[\phi^\st(x_2') = s]  (\pihat^{x_2}(x_1') - f(\phi^\st(x_1'),\phi^\st(x_2)))^2\right] \nonumber \\ 
&= \EE_{(x_1,x_2) \sim \MD}\left[\mathbbm{1}[\phi^\st(x_2)=s] \cdot \EE_{(x_1',x_2') \sim \MD}\left[\mathbbm{1}[\phi^\st(x_2') = s]  (\pihat^{x_2}(x_1') - f(\phi^\st(x_1'),\phi^\st(x_2)))^2\right]\right] \nonumber \\
&= \EE_{(x_1,x_2) \sim \MD}\left[\mathbbm{1}[\phi^\st(x_2)=s] \cdot \EE_{(x_1',x_2') \sim \MD}\left[\mathbbm{1}[\phi^\st(x_2') = s]  (\pihat^{x_2}(x_1') - f(\phi^\st(x_1'),\phi^\st(x_2')))^2\right]\right] \nonumber \\
&= \EE_{(x_1,x_2) \sim \MD}\left[ \mathbbm{1}[\phi^\st(x_2)=s]\cdot L_s(\pihat^{x_2}) \right]\nonumber \\ 
&= \EE_{(x_1,x_2) \sim \MD} \left[\mathbbm{1}[\phi^\st(x_2)=s] \cdot \left(L_s(\pihat^{x_2}) - L_s(\pi^s)\right)\right] + \Prr_{(x_1,x_2) \sim \MD}[\phi^\st(x_2) = s]\cdot L_s(\pi^s)
\label{eq:err-bound-2}
\end{align}
where the second equality is by \cref{lemma:switching} with function $g(x_1,x_2) = (\pihat^{x_2}(x_1) - f(\phi^\st(x_1),\phi^\st(x_2)))^2$; the fourth equality is because $\phist(x_2) = \phist(x_2') = s$ (unless one of the indicator functions is zero); and the fifth inequality is by definition of $L_s$. Combining \cref{eq:err-bound-1,eq:err-bound-2}, we get that
\begin{align}
&\EE_{(x_1,x_2) \sim \MD}\left[ \mathbbm{1}[\phi^\st(x_2) = s] (\pihat^{x_2}(x_1) - f(\phi^\st(x_1),\phi^\st(x_2)))^2 \right]\nonumber \\ 
&\leq \sqrt{\EE_{(x_1,x_2) \sim \MD} \left[\mathbbm{1}[\phi^\st(x_2)=s] \cdot \left(L_s(\pihat^{x_2}) - L_s(\pi^s)\right) \right] + \Prr_{(x_1,x_2) \sim \MD}[\phi^\st(x_2) = s]\cdot L_s(\pi^s)}.
\label{eq:err-bound}
\end{align}
By the guarantee of \cref{lemma:psi-guarantee}, we have $L_s(\pi^s) \leq \epsilon^2/(2|\MS|^2)$. Also,
\begin{align*}
&\EE_{(x_1,x_2) \sim \MD} \left[\mathbbm{1}[\phi^\st(x_2)=s] (L_s(\pihat^{x_2}) - L_s(\pi^s))\right] \\ 
&\leq \EE_{(x_1,x_2) \sim \MD} \Big[\mathbbm{1}[\phi^\st(x_2)=s] \Big(L_s(\pihat^{x_2}) - \MR^{\pihat^{x_2}}(x_2)\Prr_{(x_1',x_2')\sim\MD}[\phi^\st(x_2')=s] \\
&\hspace{12em}+ \MR^{\pi^s}(x_2)\Prr_{(x_1',x_2')\sim\MD}[\phi^\st(x_2')=s] - L_s(\pi^s)\Big)\Big] \\ 
&\leq 2\max_{\pi\in\Psi} \EE_{x_1,x_2\sim\MD} \mathbbm{1}[\phi^\st(x_2)=s] \left| L_s(\pi)+Z_s - \MR^\pi(x_2)\Prr_{(x_1',x_2')\sim\MD}[\phi^\st(x_2')=s]\right| \\ 
&\leq 2\max_{\pi\in\Psi} \EE_{x_1,x_2 \sim \MD} \mathbbm{1}[\phi^\st(x_2)=s] \left| \frac{L_s(\pi) + Z_s}{\Prr_{(x_1',x_2')\sim\MD}[\phi^\st(x_2')=s]} - \MR^\pi(x_2)\right| \\ 
&\leq 2\max_{\pi\in\Psi} \sqrt{\EE_{(x_1,x_2) \sim \MD} \mathbbm{1}[\phi^\st(x_2)=s] \left( \frac{L_s(\pi) + Z_s}{\Prr_{(x_1',x_2')\sim\MD}[\phi^\st(x_2')=s]} - \MR^\pi(x_2)\right)^2}
\leq \frac{\epsilon^2}{2|\MS|^2}
\end{align*}
where the first inequality is by minimality of $\MR^{\pihat^{x_2}}(x_2)$ over all $\pi \in \Psi$, and the final inequality is by the guarantee of \cref{lemma:rpi-error}. %\dhruv{third inequality is loose, should be able to improve the rate} 
Substituting into \cref{eq:err-bound} and summing over $s \in \MS$, we get 
\[\EE_{(x_1,x_2)\sim\MD} (\MR(x_1,x_2) - f(\phi^\st(x_1),\phi^\st(x_2)))^2 \leq \epsilon\]
as needed.
\end{proof}

\subsection{Analysis of $\RegToRL$ (\creftitle{alg:regtorl})}\label{sec:regtorl}

The proof of \cref{cor:regression-to-online-rl} is now straightforward from the analysis of $\TwoRed$ (\cref{thm:two-context-reduction}) and the analysis of $\TwoAug$ (\cref{prop:twoaug}).

\vspace{1em}

\begin{proof}[Proof of \cref{cor:regression-to-online-rl}]
Fix a regular concept class $\Phiaug \subseteq (\Xaug\to\Saug)$. By regularity (\cref{def:regular}), $\{0,1\} \subseteq \Xaug,\Saug$ so we can define $\MX := \Xaug \setminus \{0,1\}$ and $\MS := \Saug \setminus \{0,1\}$. Define a concept class $\Phi \subseteq (\MX \to \MS)$ by restricting each $\phi$ to domain $\MX$; regularity ensures that the range of each restricted map is contained in $\MS$, so this definition is well-defined. We now observe that the augmented concept class (\cref{def:phiaug}) with base class $\Phi$ is precisely $\Phiaug$.

Now suppose that $\MO$ is an $(\Nrl,\Krl)$-efficient reward-free episodic RL oracle for $\Phiaug$ with $\Nrl,\Krl$ bounded in terms of the parameters $\Nrlc,\Crl$ as specified in the theorem statement. By \cref{thm:two-context-reduction} and the assumed parametric bounds on $\Nrl,\Krl$, there is a constant $C>0$ so that $\TwoRed(\MO,\cdot)$ is an $\Nreg$-efficient two-context regression algorithm for $\Phi$ with
\[\Nreg(\epsilon,\delta) \leq \Nrlc\left(\frac{|\MS|}{\epsilon\delta}\right)^{C \cdot \Crl}.\]
It follows from \cref{prop:twoaug} that $\TwoAug(\TwoRed(\MO,\cdot),\cdot)$ is an $\Nreg'$-efficient two-context regression algorithm for $\Phiaug$ with 
\[\Nreg'(\epsilon,\delta) \leq \Nrlc \left(\frac{|\MS|}{\epsilon\delta}\right)^{C_{\ref{cor:regression-to-online-rl}} \cdot \Crl}\]
so long as $C_{\ref{cor:regression-to-online-rl}}>0$ is a sufficiently large constant. Note that we are using the fact that $\epsilon,\delta \in (0,1/2)$ to absorb constant factors.

To conclude the proof, we observe that the claimed oracle time complexity bound is immediate from the pseudocode of $\RegToRL$ and its subroutines.
\end{proof}
%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
