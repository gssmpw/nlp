\begin{table}[t]
\begin{center}
\begin{small}
\begin{adjustbox}{width=1\textwidth}
\small
\begin{tabular}{ccccccc}
\toprule
\multirow{2}{*}{Model} & \multirow{2}{*}{Num. Params} & \multirow{2}{*}{Downstream Task} & \multicolumn{2}{c}{Data} & \multicolumn{2}{c}{Checkpoint} \\
\cmidrule(l){4-5}
\cmidrule(l){6-7}
& & & Pretrain & Finetune & Pretrain & Finetune \\
\midrule 
\multirow{2}{*}{VT5} & \multirow{2}{*}{250M} & \multirow{2}{*}{DocVQA} & \multirow{2}{*}{C4+IIT-CDIP} & PFL & \multicolumn{2}{c}{\multirow{2}{*}{https://benchmarks.elsa-ai.eu/?ch=2}} \\
 &  &  &  & DocVQA &  & \\
\midrule 

\multirow{2}{*}{Donut} & \multirow{2}{*}{200M} & \multirow{2}{*}{DocVQA} & \multirow{2}{*}{CDIP 11M + 0.5M synthesized Docs} & PFL &  \multicolumn{2}{c}{Ours}  \\
 &  &  &  & DocVQA & $\text{naver-clova-ix/donut-base}^{\dagger}$ & $\text{naver-clova-ix/donut-base-finetuned-docvqa}^{\dagger}$  \\
\midrule 
Pix2struct-B & 282M & \multirow{2}{*}{DocVQA} & \multirow{2}{*}{BooksCorpus + C4 Web HTML} & \multirow{2}{*}{DocVQA} & $\text{google/pix2struct-base}^{\dagger}$ & $\text{google/pix2struct-docvqa-base}^{\dagger}$ \\
Pix2struct-L & 1.33B &  &  &  & $\text{google/pix2struct-large}^{\dagger}$ & $\text{google/pix2struct-docvqa-large}^{\dagger}$ \\
\bottomrule
\end{tabular}
\end{adjustbox}
\end{small}
\end{center}
\caption{\textbf{Details of the public checkpoints} used as target models in this work. $\dagger$ denotes checkpoint from Hugging Face.}
\label{tab:public_checkpoint}
\vskip -0.1in
\end{table}

