\begin{table}[t]
\begin{center}
\begin{small}
\small
\begin{adjustbox}{width=0.6\textwidth}
\begin{tabular}{lccccc}
\toprule
Dataset & Model & Test Set & ACC & ANLS & Train-Test Gap \\
\midrule
\multirow{6}{*}{{PFL}} & \multirow{3}{*}{{VT5}} & Original &  81.4 & 90.17  & -\\
 &  & MIA & 82.74 & 90.91 & 11.44 \\
 &  & MIA-rephrased & 77.59 & 85.84 & -\\
\cmidrule{2-6}
& \multirow{3}{*}{{Donut}} & Original & 74.73 & 88.66 & -\\
 &  & MIA & 80.15 & 91.64 & 22.2 \\
 &  & MIA-rephrased & 70.46 & 80.96 & -\\
\midrule
\multirow{12}{*}{{DVQA}}& \multirow{3}{*}{{VT5}} & Original & 60.1 & 69.33 & -\\
 &  & MIA & 75.54 & 81.69 & 36.22 \\
 &  & MIA-rephrased & 73.57 & 79.89 & -\\
\cmidrule{2-6}
& \multirow{3}{*}{{Donut}} & Original & 59.26 & 66.91 & -\\
 &  & MIA & 78.55 & 83.42 & 39.78 \\
 &  & MIA-rephrased & 72.57 & 77.12 & -\\
\cmidrule{2-6}
& \multirow{3}{*}{{Pix2Struct-B}} & Original & 57.11 & 68.13 & -\\
 &  & MIA & 64.42 & 79.95 & 25.8 \\
 &  & MIA-rephrased & 63.81 & 74.06 & -\\
\cmidrule{2-6}
& \multirow{3}{*}{{Pix2Struct-L}} & Original & 64.53 & 74.12 & -\\
 &  & MIA & 73.91 & 82.71 & 22.11 \\
 &  & MIA-rephrased & 69.93 & 79.15 & -\\
\bottomrule
\end{tabular}
\end{adjustbox}
\end{small}
\end{center}
\caption{\textbf{DocVQA Performance of the target models on PFL and DocVQA dataset.} Train-Test Gap is computed as the different of DocVQA Accuracy between \textit{member/non-member} documents. $\textsc{MIA}$ denotes the attack evaluation set, which is a subset randomly sampled from the original train/test set, $\textsc{MIA}\text{-rephrased}$ is its variants with rephrased questions by LLM.}
\label{tab:docvqa_performance}
\end{table}
