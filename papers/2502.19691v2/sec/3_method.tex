

\section{Methodology}
\label{sec:method}


\subsection{Preliminaries}

\textbf{Notations.} Consider the problem of ordinary $C$-class classification. In active open-set annotation (AOSA) tasks, we start with a limited labeled dataset $\mathcal{D}_{L}^{kno}=\left \{ \left ( x_i^L,y_i^L \right )  \right \} _{i=1}^{\mathcal{N} _L}$ containing $\mathcal{N} _L$ examples from known classes for training, alongside a sufficiently large unlabeled data pool $\mathcal{D}_{U}=\left \{ x_i^U \right \} _{i=1}^{\mathcal{N} _U}$ consisting of $\mathcal{N} _U$ examples from both known and unknown classes for querying. The label $y_i^L$ of an instance $x_i^L$ belongs to $\left \{ 1,\cdots ,C \right \}$, whereas the label $y_i^U$ of an instance $x_i^U$ is not provided prior to Oracle labeling and falls within $\left \{ 1,\cdots, C+1 \right \}$, with $C+1$ representing all unknown classes. At each active learning (AL) cycle, a batch of $b$ examples, denoted as $X^{query}=X_{kno}^{query}\cup X_{unk}^{query}$, is selected according to a specified query strategy and sent to Oracle for labeling. Then, $\mathcal{D}_{L}^{kno}$ and $\mathcal{D}_{U}$ are updated accordingly, and $X_{unk}^{query}$ forms the unknown class dataset $\mathcal{D}_{L}^{unk}$ with $\mathcal{D}_{L} = \mathcal{D}_{L}^{kno}\cup \mathcal{D}_{L}^{unk}$.


\textbf{Overview.} As outlined in the Introduction, addressing the AOSA problem requires first ensuring that the queried examples exhibit low epistemic uncertainty to approximate a closed set, enabling meaningful aleatoric uncertainty assessment, and then querying examples with high aleatoric uncertainty.
%As discussed in the Introduction, in the AOSA problem, ensuring that the queried examples exhibit low epistemic uncertainty for maintaining a nearly closed set is crucial, which allows for meaningful aleatoric uncertainty before querying examples with high aleatoric uncertainty.
To achieve this goal, we propose an \textbf{E}nergy-based \textbf{A}ctive \textbf{O}pen-set \textbf{A}nnotation (EAOA) framework, as illustrated in Figure \ref{fig:framework}, which primarily consists of three key components: active sampling, detector training, and classifier training. Specifically, we begin by training a detector network to evaluate the epistemic uncertainty of examples from both learning-based and data-driven perspectives, leveraging the labeled data from both known and unknown classes. Next, we assess the aleatoric uncertainty of examples by utilizing the free energy discrepancy in predictions made by the target classifier. Finally, we query a smaller candidate set of examples with low epistemic uncertainty first, with the set dynamically adjusting by rounds, and then acquire the query set with high aleatoric uncertainty.


\subsection{Energy-based Epistemic and Aleatoric Uncertainty for Active Sampling}

\textbf{Energy-based epistemic uncertainty.}
Energy-based models (EBMs) \cite{liu2020energy,wang2021can} build a function $E\left ( x \right ):\mathbb{R}^D \to \mathbb{R}$ to map a $D$-dim data point to a scalar and defines the probability distribution in multi-class settings through logits as:
\begin{equation}
\label{eq1}
    p\left ( y|x \right ) =\frac{e ^{-E\left ( x,y \right ) }}{\int_{y}e^{-E\left ( x,y \right ) } }=\frac{e ^{f_y\left ( x \right ) }}{\sum_{c=1}^{C} e^{f_c\left ( x \right ) } } =\frac{e ^{-E\left ( x,y \right ) }}{e ^{-E\left ( x\right ) }}   ,
\end{equation}
where $f_y(x)$ denotes the predicted logit of model $f$ for instance $x$ regarding label $y$, $E(x,y)=-f_y(x)$, and $E\left ( x\right ) = -\log_{}{\sum_{c=1}^{C}e^{-E\left ( x,c \right ) } } $ is called free energy. The probability density of $x$ in an EBM can be written as:
\begin{equation}
\label{eq2}
    p\left ( x \right ) =\frac{e^{ -E\left ( x \right )}  }{ \int_{x}  e^{ -E\left ( x \right )} }=\frac{\int_{y}e^{-E\left ( x,y \right ) }}{\int_{x}\int_{y}e^{-E\left ( x,y \right ) }} =\frac{e^{ -E\left ( x \right )} }{\mathcal{Z}   } .
\end{equation}
This implies that for two data points, $x_1$ and $x_2$, if $E\left ( x_1 \right ) > E\left ( x_2 \right )$, then $x_1$ lies in a sparser region compared to $x_2$ w.r.t. the marginal distribution. This aligns with epistemic uncertainty: high-uncertainty examples are distributed in low-density regions due to their lower occurrence frequency. 

Nevertheless, free energy is not ideal for directly measuring epistemic uncertainty in the AOSA task, as the underlying EBM does not fully utilize the information contained in the labeled unknown class examples. To counter this, we group all unknown classes into the $C+1$ category, train a multi-class classifier (i.e., the detector), and extend the free energy theory by making the following Remark \ref{remark1}.

\begin{remark}
    For AOSA tasks, the epistemic uncertainty (EU) of $x$ can be expressed through the free energy score on known classes minus that on the unknown class\footnote{$E_{unk}\left ( x \right )$ is determined by label-wise free energy (see \cref{sec:lwfe}).},
    \begin{equation}
    \label{eq3}
    \begin{aligned}
        &EU\left ( x  \right ) =E_{kno}\left ( x \right ) -E_{unk}\left ( x \right ) \\&=-\log_{}{\sum_{c=1}^{C}e^{-E\left ( x,c \right ) } }+\log_{}{\left ( 1+e^{-E\left ( x,C+1 \right ) } \right ) } .
    \end{aligned}
    \end{equation}
    As such, for two given data points $x_1$ and $x_2$, the inequality $EU\left ( x_1 \right )>EU\left ( x_2 \right )$ implies that $x_1$ is occurring from a denser region w.r.t. the unknown class compared to $x_2$.
\label{remark1}
\end{remark}

Since labeled data in AL is often quite limited, relying solely on the detector's predictions to assess the epistemic uncertainty of examples may not be sufficiently reliable. To obtain a more reliable measurement, we evaluate the epistemic uncertainty of examples in two ways: 1) a learning-based perspective that directly uses the detector's predictions, and 2) a data-driven perspective that relies on the similarity to labeled examples from different classes. To this end, we utilize the detector to extract features and emit $K$ arrows from each instance in the labeled data pool $\mathcal{D}_{L}$ to its $K$ nearest neighbors in the unlabeled data pool $\mathcal{D}_{U}$ based on cosine distance. For a data point $x_i^{U}$, its probability given class $y$ can be approximated as:
\begin{equation}
\label{eq4}
p\left ( x_i^{U}|y\right ) =\frac{\text{\# of Arrows}_{(x_j^L,y ) }       }{ \left | X^y \right | }  
\end{equation}
where $\text{\# of Arrows}_{(x_j^L,y ) } $ denotes the total number of arrows directed at $x_i^U$ from examples with label $y$, and $\left | X^y \right |$ represents the total number of examples with label $y$ in $\mathcal{D}_{L}$. If $x_i^{U}$ is in a region where examples with label $y$ densely exist, it is likely to receive more arrows, and vice versa.

Then, by virtue of Bayes' theorem, we define the data-centric class probability distribution of $x_i^{U}$ as
\begin{equation}
\label{eq5}
    p\left (y|x_i^{U}\right ) =\frac{p\left ( x_i^{U}|y\right )p\left ( y \right ) }{\sum_{c=1}^{C+1} p\left ( x_i^{U}|c\right )p\left ( c \right )} .
\end{equation}
Here, the prior $p\left ( y \right )$ is the probability of observing class $y$, and can be approximately determined by the sample count for each class in $\mathcal{D}_{L}$:
\begin{equation}
\label{eq6}
    p\left ( y \right )=\frac{\left | X^y \right | }{\sum_{c=1}^{C+1}\left | X^c \right | } .
\end{equation}
Based on Eqs. \eqref{eq1}, \eqref{eq4}, \eqref{eq5}, and \eqref{eq6}, we can obtain:
\begin{equation}
\label{eq7}
    p\left ( y|x_i^U \right )=\frac{\text{\# of Arrows}_{(x_j^L,y ) }  }{\sum_{c=1}^{C+1}\text{\# of Arrows}_{(x_j^L,c ) } } =\frac{e ^{-E\left ( x_i^U,y \right ) }}{e ^{-E\left ( x_i^U\right ) }}.
\end{equation}
As such, we can define the specific form of the energy function from a data-driven perspective to calculate the epistemic uncertainty of examples, as stated in Remark \ref{remark1}.

Here, for a given data point $x_i^U$, the uncertainty scores calculated in two different ways are denoted as $EU_L(x_i^U)$ and $EU_D(x_i^U)$. We first gather the uncertainty scores for all examples in $\mathcal{D}_{U}$ to form sets $\left \{ EU_L(x_1^U),\dots, EU_L(x_{\mathcal{N} _U}^U) \right \} $ and $\left \{ EU_D(x_1^U),\dots, EU_D(x_{\mathcal{N} _U}^U) \right \} $, and then fit two two-component Gaussian Mixture Models (GMMs) respectively to convert these scores into a probabilistic format. Suppose a tilde is added to denote the probabilistic format, we apply an element-wise product rule to obtain the final epistemic uncertainty score of $x_i^U$:
\begin{equation}
\label{eq8}
    \tilde{EU}(x_i^U)=\tilde{EU}_L(x_i^U)\odot \tilde{EU}_D(x_i^U).
\end{equation}

\textbf{Energy-based aleatoric uncertainty.} Aleatoric uncertainty arises through inherent noise in the data, that is, for the same instance $x$, different labels might be observed if multiple annotators label it independently. This means that aleatoric uncertainty can be defined based on the confusion between classes. As such, we further extend the free energy theory by making the following Remark \ref{remark2}.


\begin{remark}
\label{remark2}
    For AL tasks, the aleatoric uncertainty (AU) of $x$ can be expressed through the free energy scores on all classes minus that on secondary classes,
    \begin{equation}
    \begin{aligned}
        &AU(x)=E(x)-E_{\text{secondary classes}}(x)\\&=-\log_{}{\sum_{c=1}^{C}e^{-E\left ( x,c \right ) } }+\log_{}{\left [ \sum_{c=1}^{C}e^{-E\left ( x,c \right ) }- e^{-E\left ( x,y_{max} \right ) }\right ]  } ,
    \end{aligned}
    \end{equation}
    where $y_{max}$ is the most probable label for $x$. This implies that for two data points $x_1$ and $x_2$, if inequality $AU(x_1) > AU(x_2)$ holds, then $x_1$ occurs in a region closer to the decision boundary compared to $x_2$.
\end{remark}

Similarly, we gather the uncertainty scores for all examples in $\mathcal{D}_{U}$ to form set $\left \{ AU(x_1^U),\dots, AU(x_{\mathcal{N} _U}^U) \right \} $, and then fit a two-component GMM to convert these scores into a probabilistic format, i.e., $\left \{ \tilde{AU}(x_1^U),\dots, \tilde{AU}(x_{\mathcal{N} _U}^U) \right \} $. 

\textbf{Target-driven adaptive active sampling.} After having epistemic uncertainty scores and aleatoric uncertainty scores, we form the query set based on the strategy outlined in Figure \ref{fig:framework}. Specifically, in each active sampling round, we perform the querying in two rounds. In the first round, $kb$ examples with the lowest epistemic uncertainty scores are selected. Then, according to aleatoric uncertainty, we choose the top $b$ examples with the highest scores from the candidates obtained in the first round to query their labels.

Obviously, the choice of the $k$ value is critical. If $k$ is too small, such as $k=1$, it maximizes the likelihood that the queried examples belong to the closed-set classes. However, since the candidate set size matches the query set size, aleatoric uncertainty cannot effectively contribute. On the contrary, if the $k$ value is too large, the closed-set condition of the candidate set cannot be ensured, rendering aleatoric uncertainty meaningless.
Meanwhile, the optimal $k$ value often varies for different datasets. To enhance the strategy's generalizability, we introduce the expected target precision for known class queries to drive the adaptive adjustment of the $k$ value. The relation between the two is as follows:
\begin{equation}
\label{k1}
    k_{t+1}=\begin{cases}
k_t+a  & \text{ if } rP-tP>z ,  \\
k_t-a  & \text{ if } tP-rP>z  , \\
k_t  & \text{ if } \left | tP-rP \right |\le z ,
\end{cases}
\end{equation}
where $k_t$ is the value of $k$ in the $t$-th AL round, $tP$ is the expected target precision, $rP$ is the real query precision calculated as $ rP=\frac{\left | X_{kno}^{query} \right |  }{\left | X^{query} \right | } $ after Oracle labeling, $a$ is the variation amplitude and $z$ is the triggering threshold. Notably, although the number of hyper-parameters increases, setting them becomes significantly easier, and they are less sensitive to dataset variations. %In the paper, $tP$, $k_1$, $a$, and $b$ are set to 0.6, 5, 1, and 0.05 for all settings, respectively.

\subsection{Detector and Target Classifier Training}

\textbf{Detector training.} All labeled examples from the known classes and unknown classes are jointly used to train a detector with $C+1$ classes. For a given data point $x_i$ with label $y_i$, let $p_i$ denote its one-hot label, i.e., $p_{ic}$ is set to 1 and the others to 0, and $q_i$ denote its probability vector predicted by the detector. On the one hand, we use the following cross-entropy loss to train the detector:
\begin{equation}
    \mathcal{L} _{ce}^{x_i}=-p_i\log_{}{q_i} =-\sum_{c=1}^{C+1} p_{ic}\log_{}{q_{ic}} .
\end{equation}
On the other hand, we propose a margin-based energy loss to ensure that, for examples from known classes, the free energy scores for the first $C$ classes are high, while for examples from unknown classes, the free energy score for the $(C+1)$-th class remains low, referring to Remark \ref{remark1}.
The energy loss is calculated by\footnote{Replacing $E_{kno}(x_i)$ with $EU(x_i)$ is also a suitable choice; however, we find that the performance difference between the two is minimal.}:
\begin{equation}
    \mathcal{L} _{energy}^{x_i}=\begin{cases}
\left ( \max\left ( 0, E_{kno}(x_i)-m_{kno}  \right )  \right )^2   \text{ if } x_i \in \mathcal{D}_L^{kno},  \\
\left ( \max\left ( 0, m_{unk} - E_{kno}(x_i)  \right )  \right )^2  \text{if } x_i \in \mathcal{D}_L^{unk},
\end{cases}
\end{equation}
where $m_{kno}$ and $m_{unk}$ are the margins for known classes and unknown classes, respectively.

Thus, the total loss for training the detector is:
\begin{equation}
\label{l_detector}
     \mathcal{L} _{detector}^{x_i}  = \mathcal{L} _{ce}^{x_i} + \lambda _{e}\mathcal{L} _{energy}^{x_i},
\end{equation}
where $\lambda _{e}$ is a hyper-parameter that balances the two losses.


\textbf{Target classifier training.} All labeled examples from the known classes are used to train the target classifier by minimizing the standard cross-entropy loss:
\begin{equation}
\label{l_classifier}
     \mathcal{L} _{classifier}^{x_i}  = -p_i\log_{}{q_i} =-\sum_{c=1}^{C} p_{ic}\log_{}{q_{ic}}.
\end{equation}

The pseudocode of EAOA is shown in \cref{sec:pesudocode}.