[
  {
    "index": 0,
    "papers": [
      {
        "key": "guo2025deepseek",
        "author": "Guo, Daya and Yang, Dejian and Zhang, Haowei and Song, Junxiao and Zhang, Ruoyu and Xu, Runxin and Zhu, Qihao and Ma, Shirong and Wang, Peiyi and Bi, Xiao and others",
        "title": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "snell2024scaling",
        "author": "Snell, Charlie and Lee, Jaehoon and Xu, Kelvin and Kumar, Aviral",
        "title": "Scaling llm test-time compute optimally can be more effective than scaling model parameters"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "wang2024math",
        "author": "Wang, Peiyi and Li, Lei and Shao, Zhihong and Xu, Runxin and Dai, Damai and Li, Yifei and Chen, Deli and Wu, Yu and Sui, Zhifang",
        "title": "Math-shepherd: Verify and reinforce llms step-by-step without human annotations"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "liang2024internal",
        "author": "Liang, Xun and Song, Shichao and Zheng, Zifan and Wang, Hanyu and Yu, Qingchen and Li, Xunkai and Li, Rong-Hua and Wang, Yi and Wang, Zhonghao and Xiong, Feiyu and others",
        "title": "Internal consistency and self-feedback in large language models: A survey"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "chen2023universal",
        "author": "Chen, Xinyun and Aksitov, Renat and Alon, Uri and Ren, Jie and Xiao, Kefan and Yin, Pengcheng and Prakash, Sushant and Sutton, Charles and Wang, Xuezhi and Zhou, Denny",
        "title": "Universal self-consistency for large language model generation"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "wang2022self",
        "author": "Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc and Chi, Ed and Narang, Sharan and Chowdhery, Aakanksha and Zhou, Denny",
        "title": "Self-consistency improves chain of thought reasoning in language models"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "luo2024sed",
        "author": "Luo, Ziqin and Han, Haixia and Zhao, Haokun and Jiang, Guochao and Du, Chengyu and Li, Tingyun and Liang, Jiaqing and Yang, Deqing and Xiao, Yanghua",
        "title": "SED: Self-Evaluation Decoding Enhances Large Language Models for Better Generation"
      }
    ]
  }
]