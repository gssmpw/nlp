%%%%%%%% ICML 2025 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables
\usepackage{multirow}
% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2025} with \usepackage[nohyperref]{icml2025} above.
\usepackage{hyperref}
\usepackage{tcolorbox}
% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
% \usepackage{icml2025}

% If accepted, instead use the following line for the camera-ready submission:
\usepackage[accepted]{icml2025}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{xspace}
\usepackage{enumitem}
\usepackage{makecell}
% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}

\newcommand{\xuandong}[1]{{\color{orange} {[Xuandong: #1]}}}
% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Scalable Best-of-N Selection for Large Language Models via Self-Certainty}

\begin{document}

\twocolumn[
\icmltitle{Scalable Best-of-N Selection for Large Language Models via Self-Certainty}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2025
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Zhewei Kang}{equal,yyy}
\icmlauthor{Xuandong Zhao}{equal,yyy}
\icmlauthor{Dawn Song}{yyy}
%\icmlauthor{}{sch}
%\icmlauthor{}{sch}
\end{icmlauthorlist}

\icmlaffiliation{yyy}{University of California, Berkeley}
% \icmlaffiliation{comp}{Company Name, Location, Country}
% \icmlaffiliation{sch}{School of ZZZ, Institute of WWW, Location, Country}

\icmlcorrespondingauthor{Zhewei Kang}{waynekang@berkeley.edu}
\icmlcorrespondingauthor{Xuandong Zhao}{xuandongzhao@berkeley.edu}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Machine Learning, ICML}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

%\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
\printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.

\begin{abstract}
Best-of-N selection is a key technique for improving the reasoning performance of Large Language Models (LLMs) through increased test-time computation. Current state-of-the-art methods often employ computationally intensive reward models for response evaluation and selection. Reward-free alternatives, like self-consistency and universal self-consistency, are limited in their ability to handle open-ended generation tasks or scale effectively. To address these limitations, we propose \emph{self-certainty}, a novel and efficient metric that leverages the inherent probability distribution of LLM outputs to estimate response quality without requiring external reward models. 
We hypothesize that higher distributional self-certainty, aggregated across multiple samples, correlates with improved response accuracy, as it reflects greater confidence in the generated output. 
Through extensive experiments on various reasoning tasks, we demonstrate that self-certainty (1) scales effectively with increasing sample size $N$, akin to reward models but without the computational overhead; (2) complements chain-of-thought, improving reasoning performance beyond greedy decoding; and (3) generalizes to open-ended tasks where traditional self-consistency methods fall short. Our findings establish self-certainty as a practical and efficient way for improving LLM reasoning capabilities. The code is available at \url{https://github.com/backprop07/Self-Certainty}
\end{abstract}

\input{01intro}
\input{02related}
\input{03method}
\input{04exp}
\bibliography{example_paper}
\bibliographystyle{icml2025}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix
\onecolumn




\section{More Experiment Results}
\subsection{Oracle Best-of-N Selection Performance and Scaling Effects on LiveCodeBench}
In our experiment described in Section~\ref{sec:borda_setup}, we evaluate the performance of Llama-3.1-8B-Instruct and compare Borda voting and self-certainty against the upper bound of Best-of-N selection methods, as shown in Figure~\ref{fig:five_datasets_more}. While both methods demonstrate continued improvement as $N$ increases, they remain significantly outperformed by the Oracle selection method, which assumes perfect knowledge of the correct answer.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.99\textwidth]{fig/five_datasets_line_plots.pdf}
    \caption{Performance across five datasets using different strategies with Llama-3.1-8B-Instruct. The oracle selection method significantly outperforms the other strategies. Additionally, both Borda voting and self-certainty demonstrate strong scaling effects.}
    \label{fig:five_datasets_more}
\end{figure}

\subsection{Evaluation of Methods Across Difficulty Levels on the MATH Dataset}
We conduct experiments to evaluate different methods across varying difficulty levels of reasoning problems. Figure~\ref{fig:level} presents the performance of various methods on the MATH dataset at different difficulty levels. As question difficulty increases, the scaling effect of Borda voting and self-certainty becomes more pronounced, demonstrating their effectiveness in handling more challenging reasoning tasks.


\begin{figure}[H]
    \centering
    \includegraphics[width=0.48\textwidth]{fig/level.pdf}
    \caption{Comparison of evaluation methods on the MATH test dataset across increasing difficulty levels using Llama-3.1-8B-Instruct. The four bars in each difficulty bin correspond to an increasing choice of N in the Best-of-N selection (8, 16, 32, and 64 generations). Performance differences among settings become more pronounced as the difficulty level increases.}
    \label{fig:level}
\end{figure}

\subsection{Replacing Uniform Distribution with Empirical Distribution}\label{sec:diff_dis}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.7\textwidth]{fig/token_frequency.pdf}
    \caption{Frequency of the top 20 tokens in Llama-3.1-8B-Instruct responses to MATH training set questions (generated eight times per question).}
    \label{fig:token_freq}
\end{figure}

\begin{table}[ht]
\centering
\caption{Accuracy of various self-certainty definitions for Best-of-N selection on the MATH and GSM8K test sets using Llama-3.1-8B-Instruct (single trial). The empirical distribution is derived by sampling from the MATH training dataset. While the empirical self-certainty results are comparable to those based on a uniform distribution for the MATH test set, it is significantly outperformed by the latter, likely due to a distributional shift.}
\label{tab:emp}
\vspace{0.5em}
\small
\begin{tabular}{@{}lccccc@{}}
\toprule
\multirow{2}{*}{\textbf{Base Distribution}} & \multicolumn{2}{c}{\textbf{MATH}} & \multicolumn{2}{c}{\textbf{GSM8K}} \\
& \(N = 8\) & \(N = 64\) & \(N = 8\) & \(N = 64\) \\
\midrule
Uniform   & 54.60   & 56.46 & 87.19 & 88.55\\
Empirical      & 54.70 & 56.78 & 85.97 & 86.35  \\
\bottomrule
\end{tabular}
\end{table}
In Equation~\ref{eq:sc}, we define tokenwise self-certainty as the KL divergence between the generated token distribution and a uniform distribution, which quantifies deviation from random sampling. An alternative approach replaces the uniform distribution with an empirical token distribution estimated from training data. To evaluate the impact of this modification, we conduct the following experiment.

We first estimate token frequencies in the MATH training set by generating eight responses per question and averaging token occurrences. The resulting empirical distribution is approximated from these frequencies, with the 20 most frequent tokens shown in Figure~\ref{fig:token_freq}. We then compute KL divergence between the generated token distribution and the empirical distribution, using this as the self-certainty measure for Best-of-N selection. This experiment was conducted for a single trial, with all other setup parameters as described in Section~\ref{sec:experiment_setup}.

Results show that replacing the uniform distribution with the empirical distribution has minimal impact on MATH test accuracy but leads to a noticeable performance drop on GSM8K, suggesting a sensitivity to distributional shifts. Thus, we recommend retaining the uniform distribution in Equation~\ref{eq:sc} for improved generalization.


\section{Case Study and Examples}
In this section, we present several examples to illustrate the practical behavior of self-certainty and universal self-consistency (USC). These examples are drawn from Llama-3.1-8B-Instruct generating responses to questions from the GSM8K and LiveCodeBench code generation datasets.

\subsection{Self-certainty}
In this example, self-certainty correctly assigns higher confidence to the correct answer. Notably, in Response 0, the model does not fully adhere to the instruction to enclose all reasoning within the specified JSON field. Instead, it follows its trained reasoning process first and then summarizes the reasoning path in the \texttt{reason} field. This approach appears to be a compromise between the model's training objective and the given instruction, balancing structured formatting with its natural reasoning process.
\begin{tcolorbox}[colback=white,colframe=gray!50!black,title=Self-certainty Example]
USER: \\
\#\# Question:\\
Kylar went to the store to buy glasses for his new apartment. One glass costs \$5, but every second glass costs only 60\% of the price. Kylar wants to buy 16 glasses. How much does he need to pay for them?\\
\#\# Instruction: \\
Please answer this question by first reasoning and then providing your answer.\\
Present your reasoning and solution in the following json format. 
Please show your final answer in the answer field, e.g.,``answer": ``42". `json\{ ``reasoning": ``\_\_\_",  ``answer": ``\_\_\_"\}\\

Response 0:\\
ASSISTANT:\\
\#\#Step 1: Calculate the cost of the first glass.\\
The cost of the first glass is \$5.\\
\#\#Step 2: Calculate the cost of every second glass.\\
Every second glass costs 60\% of the price of the first glass, which is \( 0.6 \times 5 = 3 \) dollars.\\
\#\#Step 3: Determine the number of glasses that are full price and the number of glasses that are discounted.\\
Kylar wants to buy 16 glasses. Since every second glass is discounted, we can divide 16 by 2 to get the number of full-price glasses and the number of discounted glasses. \( \frac{16}{2} = 8 \) full-price glasses and 8 discounted glasses.\\
\#\#Step 4: Calculate the total cost of the full-price glasses.\\
8 full-price glasses at \$5 each is \( 8 \times 5 = 40 \) dollars.\\
\#\#Step 5: Calculate the total cost of the discounted glasses.\\
8 discounted glasses at \$3 each is \( 8 \times 3 = 24 \) dollars.\\
\#\#Step 6: Calculate the total cost of all the glasses.\\
The total cost is the sum of the cost of the full-price glasses and the cost of the discounted glasses. \$40 + \$24 = \$64.\\
\#\#Step 7: Determine the total amount Kylar needs to pay for the glasses.\\
The total amount Kylar needs to pay is \$64.\\
The final answer is: 
\{``reasoning": ``Kylar wants to buy 16 glasses. The first glass costs \$5, and every second glass costs 60\% of the price of the first glass, which is \$3. He buys 8 full-price glasses at \$5 each and 8 discounted glasses at \$3 each. The total cost of the full-price glasses is \$40, and the total cost of the discounted glasses is \$24. The total cost is \$40 + \$24 = \$64.", ``answer": "64"\}\\
\textbf{(Self-certainty: 17.81)}\\

Response 1: \\
ASSISTANT:\\
\{``reasoning": ``To find the total cost, we need to calculate the cost of the first glass and the cost of the remaining glasses. The first glass costs \$5. The second glass costs 60\% of \$5, which is 0.6 * 5 = \$3. The third glass costs 60\% of \$3, which is 0.6 * 3 = \$1.80. We can see that the price of each subsequent glass is 60\% of the previous glass. So, the price of the glasses follows a geometric sequence: 5, 3, 1.80, 1.08, \(\dots\) . To find the cost of 16 glasses, we can use the formula for the sum of a geometric series: \(S = a * (1 - r^n) / (1 - r)\), where a is the first term, r is the common ratio, and n is the number of terms. In this case, a = 5, r = 0.6, and n = 16. Plugging in the values, we get \(S = 5 * (1 - 0.6^16) / (1 - 0.6)\). Calculating the value of \(0.6^{16}\), we get 0.0000655. Now, we can plug this value back into the formula: \(S = 5 * (1 - 0.0000655) / (1 - 0.6) = 5 * 0.9999345 / 0.4 = 5 * 2.499335 = 12.496675\). Rounding to two decimal places, the total cost is \$12.50.", ``answer": ``12.50"\} \\
\textbf{(Self-certainty: 17.13)}\\

\end{tcolorbox}

\subsection{Universal Self-Consistency}\label{sec:usc_example}
The first example is taken from the GSM8K dataset, while the second comes from the LiveCodeBench dataset. The prompt has been adapted from \citet{chen2023universal}. We observe that in Example 1, the model evaluates the answers step by step to assess consistency. In contrast, the model jumps directly to the conclusion in Example 2. This difference may stem from the clarity of the task: in a MATH problem with a definite answer, the model can logically assess each step of the reasoning process, as seen in Example 1. However, for the LiveCodeBench example, where the task involves determining the most consistent code, the model struggles to elaborate on the reasoning process and relies on direct reasoning to arrive at a conclusion.


\begin{tcolorbox}[colback=white,colframe=gray!50!black,title=USC Prompt Example 1]
USER: 

I have generated the following responses to the question: Elise is learning to write and decides to keep re-writing the alphabet until she knows it. She writes it in full twice, writes half of it once, then re-writes everything she has already written. How many letters has Elise written in total?\\


Response 0: \{``reasoning": "To find the total number of letters Elise has written, we first need to determine the number of letters in the alphabet. There are 26 letters in the English alphabet. Elise writes it in full twice, which means she writes 26 letters twice, so 26 * 2 = 52 letters. Then, she writes half of it once, which is 26 / 2 = 13 letters. So, the total number of letters written so far is 52 + 13 = 65. Finally, she re-writes everything she has already written, which is 65 letters. Therefore, the total number of letters Elise has written is 65 + 65 = 130.",``answer": ``130"\}\\

\(\cdots\)\\
Response 3: \{``reasoning": ``To solve this problem, we need to calculate the total number of letters Elise has written. First, she writes the alphabet twice, which has 26 letters. So, she has written 26 + 26 = 52 letters. Then, she writes half of the alphabet once, which is 13 letters. So, she adds 13 more letters to the total. Now, she re-writes everything she has already written, which means she re-writes 52 + 13 = 65 letters. To find the total number of letters Elise has written, we need to add the number of letters she wrote initially (52) and the number of letters she re-wrote (65). The total number of letters is 52 + 65 = 117.",    ``answer": ``117"\}\\

\(\cdots\)\\

Evaluate these responses.
Select the most consistent response based on majority consensus.
Format your answer as "The most consistent response is Response X" (without quotes).\\


ASSISTANT:

To evaluate the responses, I will analyze the answers and reasoning provided by each response.Response 0 and Response 1 have the same answer (130) and similar reasoning. \(\cdots \).The most consistent response is Response 0.
%gsm8k-main-test-#587
\end{tcolorbox}

\begin{tcolorbox}[colback=white,colframe=gray!50!black,title=USC Prompt Example 2]
USER: 

I have generated the following responses to the question: Slavic is preparing a present for a friend's birthday. He has an array \( a \) of \( n \) digits, and the present will be the product of all these digits. Because Slavic is a good kid who wants to make the biggest product possible, he wants to add 1 to exactly one of his digits.

\textbf{What is the maximum product Slavic can make?}

\textbf{Input:}
\begin{itemize}
    \item The first line contains a single integer \( t \) (\( 1 \leq t \leq 10^4 \)) — the number of test cases.
    \item The first line of each test case contains a single integer \( n \) (\( 1 \leq n \leq 9 \)) — the number of digits.
    \item The second line of each test case contains \( n \) space-separated integers \( a_i \) (\( 0 \leq a_i \leq 9 \)) — the digits in the array.
\end{itemize}

\textbf{Output:}
\begin{itemize}
    \item For each test case, output a single integer — the maximum product Slavic can make, by adding 1 to exactly one of his digits.
\end{itemize}

Sample Input: \(\cdots\)\\
Sample Output: \(\cdots\)\\


\textbf{Response 0:}

\begin{verbatim}
```python
# YOUR CODE HERE
import sys

def max_product(n, arr):
    min_digit = min(arr)
    max_product = 1
    for i in range(n):
        if arr[i] == min_digit:
            arr[i] += 1
            break
    for num in arr:
        max_product *= num
    return max_product

t = int(input())
for _ in range(t):
    n = int(input())
    arr = list(map(int, input().split()))
    print(max_product(n, arr))
```
\end{verbatim}
This code first finds the minimum digit in the array and increments it by 1. Then, it calculates the product of all digits in the array. The time complexity is O(n), where n is the number of digits in the array.\\
\(\cdots\)\\

Evaluate these responses.
Select the most consistent response based on majority consensus.
Format your answer as "The most consistent response is Response X" (without quotes).\\

ASSISTANT:

The most consistent response is Response 0.
\end{tcolorbox}


% You can have as much text here as you want. The main body must be at most $8$ pages long.
% For the final version, one more page can be added.
% If you want, you can use an appendix like this one.  

% The $\mathtt{\backslash onecolumn}$ command above can be kept in place if you prefer a one-column appendix, or can be removed if you prefer a two-column appendix.  Apart from this possible change, the style (font size, spacing, margins, page numbering, etc.) should be kept the same as the main body.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\end{document}


% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was created
% by Iain Murray in 2018, and modified by Alexandre Bouchard in
% 2019 and 2021 and by Csaba Szepesvari, Gang Niu and Sivan Sabato in 2022.
% Modified again in 2023 and 2024 by Sivan Sabato and Jonathan Scarlett.
% Previous contributors include Dan Roy, Lise Getoor and Tobias
% Scheffer, which was slightly modified from the 2010 version by
% Thorsten Joachims & Johannes Fuernkranz, slightly modified from the
% 2009 version by Kiri Wagstaff and Sam Roweis's 2008 version, which is
% slightly modified from Prasad Tadepalli's 2007 version which is a
% lightly changed version of the previous year's version by Andrew
% Moore, which was in turn edited from those of Kristian Kersting and
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.
