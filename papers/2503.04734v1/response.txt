\section{Related Work}
\noindent \textbf{Large Language Model Evaluations.}
%LLMs have demonstrated strong performance across diverse domains**Radford et al., "Improving Language Understanding by Generative Multitask Learning"**.
%\textcolor{red}{Cut down}. 
Rigorous evaluation of LLMs has clarified their strengths and weaknesses. % and identified areas for future work. **Hewlett et al., "Designing and Interpreting Evaluations Merging Multiple Question Answering Datasets"** proposed a framework for evaluating LLMs' answers to medical questions.
%Med-PaLM achieved a passing score on the U.S. Medical Licensing Exam**Davani et al., "PaLM: Scaling Language Modeling with Pathways"**.
**Guo et al., "Evaluating and Improving Large-Scale Language Models for Legal Reasoning Tasks"** identified six types of legal reasoning tasks and evaluated 20 models on them. 
In chemistry, **Chen et al., "Benchmarking and Evaluating Pre-Trained Transformers for Molecule Generation"** established a benchmark of eight tasks, and evaluated five LLMs. 
%In biology, . In mathematics, . 
%Marinka Zitnik - taxonomy of medical tasks. 
However, no work, to our knowledge, has formalized key tasks and evaluated LLMs in the sustainable food domain.% We aim to fill this gap.
%by providing an evaluation framework for sustainable food. 

\noindent \textbf{Large Language Models for Scientific Discovery.}
In chemistry,**Chen et al., "Benchmarking and Evaluating Pre-Trained Transformers for Molecule Generation"** demonstrated that GPT-4 combined with internet search and code execution can perform experimental design and execution.
In genomics,**Guo et al., "Evaluating and Improving Large-Scale Language Models for Legal Reasoning Tasks"** showed that an LLM with access to several tools can design genetic perturbation experiments. In computational nanobody design,**Hewlett et al., "Designing and Interpreting Evaluations Merging Multiple Question Answering Datasets"** propose a framework in which LLM agents receive periodic human feedback, and showed promising performance in the design of novel antibodies. In artificial intelligence research,**Brown et al., "Language Models as Few-Shot Learners"** show that LLMs can generate novel research ideas. However, we are not aware of prior work on LLMs for discovery of novel sustainable foods. 
%NLP research paper____. 
%Leskovec - BioDiscoveryAgent. 
%LLMs - bilevel optimization.
%FlavorPuzzle. NeurIPS, KDD paper: diet planning.
%GNNs for ingredient matching.

\noindent \textbf{Large Language Models for Simulating Human Preferences.}
%Our work studies what LLMs can contribute to modeling human preferences and perceptions related to food. 
While we are not aware of prior work studying how LLMs can model human preferences and perceptions related to food, a growing literature has shown evidence that LLMs can accurately simulate human behavior in tasks such as search behavior, participation in online communities, hiring scenarios, and classic economic, psycholinguistic, and social psychology experiments**Radford et al., "Improving Language Understanding by Generative Multitask Learning"**.%several prior works have studied LLM capabilities for simulating human preferences and opinions in other settings**Hewlett et al., "Designing and Interpreting Evaluations Merging Multiple Question Answering Datasets"**.  
%Horton.
%June from stanford - social simulacra. 
**Guo et al., "Evaluating and Improving Large-Scale Language Models for Legal Reasoning Tasks"**, rigorously studied the question of whose opinions language models reflect and found poor modeling of certain minority groups, e.g. over 65 and widowed individuals. 
%Autogen - microsoft. Agentic AI. Split into micro-simulations. 

\noindent \textbf{Large Language Models and Optimization.}
Our work also pertains to the use of LLMs for mathematical optimization, and combining LLMs with optimization techniques. **Guo et al., "Evaluating and Improving Large-Scale Language Models for Legal Reasoning Tasks"** evaluated LLMs for several optimization problems.**Hewlett et al., "Designing and Interpreting Evaluations Merging Multiple Question Answering Datasets"** introduce OptiMUS, an LLM-based agent for solving optimization problems. Motivated by sustainable food applications, we propose a general framework for integrating LLMs with combinatorial optimization techniques that leverages LLMs' knowledge on topics such as human preferences. We further discuss these works and additional related work in Appendix~\ref{sec:extended-related-work}. %\textcolor{red}{Potentially say it could be more general throughout AI.}%We lay the foundation for using optimization tools and LLMs for the sustainable food development.
%____.

%Some prior works have evaluated LLMs on climate and sustainability related tasks. For example,~
%FlavorPuzzle. 
%Chris Manning's paper**Manning et al., "Evaluating Language Models on Climate and Sustainability Tasks"**. %ICML paper on LLMs for climate information**Hewlett et al., "Designing and Interpreting Evaluations Merging Multiple Question Answering Datasets"**.

%\subsection{Background on Food Science and Quantification of Climate Impacts}