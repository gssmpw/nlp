@inproceedings{aher2023using,
  title={Using large language models to simulate multiple humans and replicate human subject studies},
  author={Aher, Gati V and Arriaga, Rosa I and Kalai, Adam Tauman},
  booktitle={International Conference on Machine Learning},
  pages={337--371},
  year={2023},
  organization={PMLR}
}

@article{boiko2023autonomous,
  title={Autonomous chemical research with large language models},
  author={Boiko, Daniil A and MacKnight, Robert and Kline, Ben and Gomes, Gabe},
  journal={Nature},
  volume={624},
  number={7992},
  pages={570--578},
  year={2023},
  publisher={Nature Publishing Group UK London}
}

@article{bubeck2023sparks,
  title={Sparks of artificial general intelligence: Early experiments with gpt-4},
  author={Bubeck, S{\'e}bastien and Chandrasekaran, Varun and Eldan, Ronen and Gehrke, Johannes and Horvitz, Eric and Kamar, Ece and Lee, Peter and Lee, Yin Tat and Li, Yuanzhi and Lundberg, Scott and others},
  journal={arXiv preprint arXiv:2303.12712},
  year={2023}
}

@article{guha2024legalbench,
  title={{LegalBench}: A collaboratively built benchmark for measuring legal reasoning in large language models},
  author={Guha, Neel and Nyarko, Julian and Ho, Daniel and R{\'e}, Christopher and Chilton, Adam and Chohlas-Wood, Alex and Peters, Austin and Waldon, Brandon and Rockmore, Daniel and Zambrano, Diego and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{guo2023can,
  title={What can large language models do in chemistry? a comprehensive benchmark on eight tasks},
  author={Guo, Taicheng and Nan, Bozhao and Liang, Zhenwen and Guo, Zhichun and Chawla, Nitesh and Wiest, Olaf and Zhang, Xiangliang and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={59662--59688},
  year={2023}
}

@techreport{horton2023large,
  title={Large language models as simulated economic agents: What can we learn from homo silicus?},
  author={Horton, John J},
  year={2023},
  institution={National Bureau of Economic Research}
}

@inproceedings{park2022social,
  title={Social simulacra: Creating populated prototypes for social computing systems},
  author={Park, Joon Sung and Popowski, Lindsay and Cai, Carrie and Morris, Meredith Ringel and Liang, Percy and Bernstein, Michael S},
  booktitle={Proceedings of the 35th Annual ACM Symposium on User Interface Software and Technology},
  pages={1--18},
  year={2022}
}

@InProceedings{pmlr-v235-ahmaditeshnizi24a,
  title = 	 {{O}pti{MUS}: Scalable Optimization Modeling with ({MI}){LP} Solvers and Large Language Models},
  author =       {Ahmaditeshnizi, Ali and Gao, Wenzhi and Udell, Madeleine},
  booktitle = 	 {Proceedings of the 41st International Conference on Machine Learning},
  pages = 	 {577--596},
  year = 	 {2024},
  editor = 	 {Salakhutdinov, Ruslan and Kolter, Zico and Heller, Katherine and Weller, Adrian and Oliver, Nuria and Scarlett, Jonathan and Berkenkamp, Felix},
  volume = 	 {235},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {21--27 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://raw.githubusercontent.com/mlresearch/v235/main/assets/ahmaditeshnizi24a/ahmaditeshnizi24a.pdf},
  url = 	 {https://proceedings.mlr.press/v235/ahmaditeshnizi24a.html},
  abstract = 	 {Optimization problems are pervasive in sectors from manufacturing and distribution to healthcare. However, most such problems are still solved heuristically by hand rather than optimally by state-of-the-art solvers because the expertise required to formulate and solve these problems limits the widespread adoption of optimization tools and techniques. This paper introduces OptiMUS, a Large Language Model (LLM)-based agent designed to formulate and solve (mixed integer) linear programming problems from their natural language descriptions. OptiMUS can develop mathematical models, write and debug solver code, evaluate the generated solutions, and improve its model and code based on these evaluations. OptiMUS utilizes a modular structure to process problems, allowing it to handle problems with long descriptions and complex data without long prompts. Experiments demonstrate that OptiMUS outperforms existing state-of-the-art methods on easy datasets by more than $20$% and on hard datasets (including a new dataset, NLP4LP, released with this paper that features long and complex problems) by more than $30$%. The implementation and the datasets are available at https://github.com/teshnizi/OptiMUS.}
}

@InProceedings{pmlr-v235-bulian24a,
  title = 	 {Assessing Large Language Models on Climate Information},
  author =       {Bulian, Jannis and Sch\"{a}fer, Mike S. and Amini, Afra and Lam, Heidi and Ciaramita, Massimiliano and Gaiarin, Ben and Chen Huebscher, Michelle and Buck, Christian and Mede, Niels G. and Leippold, Markus and Strauss, Nadine},
  booktitle = 	 {Proceedings of the 41st International Conference on Machine Learning},
  pages = 	 {4884--4935},
  year = 	 {2024},
  editor = 	 {Salakhutdinov, Ruslan and Kolter, Zico and Heller, Katherine and Weller, Adrian and Oliver, Nuria and Scarlett, Jonathan and Berkenkamp, Felix},
  volume = 	 {235},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {21--27 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://raw.githubusercontent.com/mlresearch/v235/main/assets/bulian24a/bulian24a.pdf},
  url = 	 {https://proceedings.mlr.press/v235/bulian24a.html},
  abstract = 	 {As Large Language Models (LLMs) rise in popularity, it is necessary to assess their capability in critically relevant domains. We present a comprehensive evaluation framework, grounded in science communication research, to assess LLM responses to questions about climate change. Our framework emphasizes both presentational and epistemological adequacy, offering a fine-grained analysis of LLM generations spanning 8 dimensions and 30 issues. Our evaluation task is a real-world example of a growing number of challenging problems where AI can complement and lift human performance. We introduce a novel protocol for scalable oversight that relies on AI Assistance and raters with relevant education. We evaluate several recent LLMs on a set of diverse climate questions. Our results point to a significant gap between surface and epistemological qualities of LLMs in the realm of climate communication.}
}

@InProceedings{pmlr-v235-ma24m,
  title = 	 {{LLM} and Simulation as Bilevel Optimizers: A New Paradigm to Advance Physical Scientific Discovery},
  author =       {Ma, Pingchuan and Wang, Tsun-Hsuan and Guo, Minghao and Sun, Zhiqing and Tenenbaum, Joshua B. and Rus, Daniela and Gan, Chuang and Matusik, Wojciech},
  booktitle = 	 {Proceedings of the 41st International Conference on Machine Learning},
  pages = 	 {33940--33962},
  year = 	 {2024},
  editor = 	 {Salakhutdinov, Ruslan and Kolter, Zico and Heller, Katherine and Weller, Adrian and Oliver, Nuria and Scarlett, Jonathan and Berkenkamp, Felix},
  volume = 	 {235},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {21--27 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://raw.githubusercontent.com/mlresearch/v235/main/assets/ma24m/ma24m.pdf},
  url = 	 {https://proceedings.mlr.press/v235/ma24m.html},
  abstract = 	 {Large Language Models have recently gained significant attention in scientific discovery for their extensive knowledge and advanced reasoning capabilities. However, they encounter challenges in effectively simulating observational feedback and grounding it with language to propel advancements in physical scientific discovery. Conversely, human scientists undertake scientific discovery by formulating hypotheses, conducting experiments, and revising theories through observational analysis. Inspired by this, we propose to enhance the knowledge-driven, abstract reasoning abilities of LLMs with the computational strength of simulations. We introduce Scientific Generative Agent (SGA), a bilevel optimization framework: LLMs act as knowledgeable and versatile thinkers, proposing scientific hypotheses and reason about discrete components, such as physics equations or molecule structures; meanwhile, simulations function as experimental platforms, providing observational feedback and optimizing via differentiability for continuous parts, such as physical parameters. We conduct extensive experiments to demonstrate our frameworkâ€™s efficacy in constitutive law discovery and molecular design, unveiling novel solutions that differ from conventional human expectations yet remain coherent upon analysis.}
}

@article{roohani2024biodiscoveryagent,
  title={{BioDiscoveryAgent: An AI agent for designing genetic perturbation experiments}},
  author={Roohani, Yusuf and Lee, Andrew and Huang, Qian and Vora, Jian and Steinhart, Zachary and Huang, Kexin and Marson, Alexander and Liang, Percy and Leskovec, Jure},
  journal={arXiv preprint arXiv:2405.17631},
  year={2024}
}

@inproceedings{santurkar2023whose,
  title={Whose opinions do language models reflect?},
  author={Santurkar, Shibani and Durmus, Esin and Ladhak, Faisal and Lee, Cinoo and Liang, Percy and Hashimoto, Tatsunori},
  booktitle={International Conference on Machine Learning},
  pages={29971--30004},
  year={2023},
  organization={PMLR}
}

@article{si2024can,
  title={{Can LLMs generate novel research ideas? A large-scale human study with 100+ NLP researchers}},
  author={Si, Chenglei and Yang, Diyi and Hashimoto, Tatsunori},
  journal={arXiv preprint arXiv:2409.04109},
  year={2024}
}

@article{singhal2023large,
  title={Large language models encode clinical knowledge},
  author={Singhal, Karan and Azizi, Shekoofeh and Tu, Tao and Mahdavi, S Sara and Wei, Jason and Chung, Hyung Won and Scales, Nathan and Tanwani, Ajay and Cole-Lewis, Heather and Pfohl, Stephen and others},
  journal={Nature},
  volume={620},
  number={7972},
  pages={172--180},
  year={2023},
  publisher={Nature Publishing Group}
}

@article{swanson2024virtual,
  title={{The virtual lab: AI agents design new SARS-CoV-2 nanobodies with experimental validation}},
  author={Swanson, Kyle and Wu, Wesley and Bulaong, Nash L and Pak, John E and Zou, James},
  journal={bioRxiv},
  pages={2024--11},
  year={2024},
  publisher={Cold Spring Harbor Laboratory}
}

@inproceedings{zhang2024usimagent,
  title={{USimAgent}: Large language models for simulating search users},
  author={Zhang, Erhan and Wang, Xingzhu and Gong, Peiyuan and Lin, Yankai and Mao, Jiaxin},
  booktitle={Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages={2687--2692},
  year={2024}
}

