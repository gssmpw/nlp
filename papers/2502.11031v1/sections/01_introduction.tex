\label{sec:introduction}



\input{sections/pictures/idea}
\input{sections/tables/teaser_table}













\IEEEPARstart{N}{eural} networks have shown promising advances in many prediction and classification tasks~\cite{imagenet,ResNet,atari_DRL}.
Along with the impressive capability of neural networks, its societal impact has garnered great attention~\cite{Timnit_sex_classification_PPB, CSAD, MvCoM}, particularly regarding \emph{protected attributes} (\eg sex, race, and age), which cannot be used in the decision-making process~\cite{protected_attributes}.
Failing to carefully consider protected attributes while deploying neural networks can lead to bias issues and severely compromise fairness for specific demographic groups in various real-world applications~\cite{Timnit_sex_classification_PPB, COMPAS, diabetes_chapter}.
For instance, facial recognition systems may more correctly recognize males than females~\cite{DebFace}.
\rev{Besides, Artificial Intelligence-assisted bank loan systems may classify a higher proportion of male applicants as having bad credit than female applicants~\cite{CSAD}.}

















\rev{The underlying bias issues of neural networks, involved in the aforementioned examples, lead to important discussions~\cite{CSAD, MvCoM, DebFace, RFW_IMAN, RL_RBN, GAC,BlindEye_IMDB_eb,learn_not_to_learn_Colored_MNIST,DI, LfF_CelebA_Bias_conflicting,End,BCL}.
Specifically, these aforementioned examples highlight the presence of two distinct prevalent types of biases.
Without loss of generality, for disambiguation, these two predominate biases can be summarized as follows:

\begin{itemize}
    \item The model yields uneven performance across different demographic attributes, referred to as \emph{Type I Bias}.
    \item The model depends on demographic attributes to make predictions, referred to as \emph{Type II Bias}. 
\end{itemize}}
\noindent











\rev{Although these two prevalent types of biases differ in many aspects, as highlighted in~\cref{tab:teaser}, the current literature often ambiguously groups them under the general term ``bias" (\eg dataset bias, algorithmic bias, sex bias, or racial bias)~\cite{BlindEye_IMDB_eb, Back_MI, FairCal} and interpret them differently across scenarios.
Furthermore, numerous works addressing one type of bias inadvertently cite the other as their motivation~\cite{RFW_IMAN,RL_RBN,FairCal}.
Additionally, the taxonomy of bias issues in existing survey papers may not sufficiently distinguish between them or explicitly acknowledge their differences~\cite{MLbias_survey,causal_based_fairness,discussion_on_DP_EO}.}



























\rev{Overlooking the distinction between these two types of biases significantly compromises clarity in the current literature and leads to various negative consequences.
Specifically, for new researchers, the lingering question of which specific type of bias a paper addresses creates unnecessary confusion. 
Furthermore, the widespread confusion surrounding these biases and the lack of clear definitions to separate them results in weak motivation, ambiguous statements, and vague contributions in the existing debiasing work, significantly impeding the clarity of the associated research.
Additionally, persistent conflation of these biases, usage of inappropriate references, and unfair comparison between methods addressing different biases can lead to an expanding misunderstanding over time.
Besides, this confusion complicates the resolution of bias issues and hinders the advancement of future work in this field.}

















To that end, the main goal of this paper is to unify the existing literature about Type I Bias and Type II Bias, rectify the common confusion regarding them, and alleviate the cognitive burden for future research.
The contributions of this paper can be summarized as follows:
\begin{itemize}
    \item Proposing General mathematical definitions for Type I Bias and Type II Bias (\cref{sec:definition}) and providing a summary of their corresponding related work (\cref{sec:following}). These can be utilized as a roadmap for future work.

    \item Unifying a comprehensive list of work and relevant fairness criteria under the definition of Type I Bias and Type II Bias (\cref{sec:unifying}).
    
    \item Elucidating the existing phenomena stemming from the confusion between Type I Bias and Type II Bias (\cref{sec:confusion}), and exploring the underlying reasons that contribute to the confusion (\cref{sec:reason}).

    \item Conducting extensive experiments to examine the distinction between Type I Bias and Type II Bias (\cref{sec:distinction}).

    \item Offering some suggestions to foster a clear community regarding these bias issues (\cref{sec:suggestion}).
    
\end{itemize}
