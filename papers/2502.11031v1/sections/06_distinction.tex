\label{sec:distinction}



\input{sections/pictures/illustration_I_compact}

In this section, we empirically investigate the distinction between Type I Bias and Type II Bias.
Specifically, we conduct experiments on two synthetic datasets and two well-known real-world datasets: Adult Income Dataset~\cite{adult_dataset_and_german_dataset} and CelebA Dataset~\cite{CelebA}.
First, we use synthetic data to demonstrate that Type I Bias and Type II Bias are unrelated, \ie one can exist without the presence of the other bias.
Next, we utilize Adult dataset to further illustrate the difference between Type I Bias and Type II Bias in real-world scenarios.
Last, we employ CelebA dataset to evaluate the effectiveness of multiple representative bias assessment metrics in assessing Type I Bias and Type II Bias.
All experimental results are obtained by averaging the results over 10 trials.


\subsection{Unrelated Occurrence}
In this section, we leverage synthetic data to simulate two scenarios: the first scenario showcases the presence of Type I Bias without Type II Bias, while the second scenario showcases the presence of Type II Bias without Type I Bias.


\noindent
\textbf{Setup.}
We construct the synthetic dataset containing instances $(x, y)$, where $x$ denotes a two-dimensional input consisting of the useful feature $u$ and the binary attribute $a$, and $y$ denotes the target label.
Next, we apply a classifier $C: \mathcal{X} \rightarrow \mathcal{Y}$ to consume the input $x$ and produce the prediction $\hat{y} = C(x) = C(u,a) \in \mathcal{Y}$. 
The classifier is a single fully connected layer (FC) followed by the binary cross-entropy loss.
To evaluate Type I Bias, we measure the difference in accuracy. To assess Type II Bias, we utilize the Calders-Verwer discrimination score~\cite{discrimination_score} defined as $|P(\hat{Y}=y|A=1) - P(\hat{Y}=y|A=-1)|$.


\input{sections/pictures/illustration_II_compact}


\subsubsection{Type I Bias exists without Type II Bias}
We synthesize training set \wrt $A,X,Y$ by the following generative model,

\begin{align*}
&A \sim \text{Ber}(1/100) \times 2 - 1; \\
&V_1 \sim \text{Norm}(-1,\sigma=0.2); \\
&V_2 \sim \text{Norm}(1,\sigma=0.2); \\
&T \sim \text{Ber}(1/2); \\
&U|_{A=1} \sim V_1 \times T + V_2 \times (1-T); \\
&U|_{A=-1} \sim U|_{A=1} - 1; \\
&X = [U,A]^T; \\
&Y \sim \mathbbm{1}_{U > 0};
\end{align*}

\noindent
where $\text{Ber}(p)$ represents the Bernoulli distribution with probability $p$, $\text{Norm}(\mu, \sigma)$ represents the normal distribution with mean $\mu$ and standard deviation $\sigma$, and $\mathbbm{1}$ is the indicator function. 
As shown in~\cref{fig:I_exists}, the training set is imbalanced across attribute $A$, with the subset where $A=-1$ being the minority group. 
Furthermore, the optimal classification boundary is set to be varied across $A$ since one widely accepted cause of Type I Bias is that the model trained on the sufficient samples in majority groups might not effectively generalize to minority groups~\cite{spurious_correlation_Underrepresentation}. 
Additionally, the testing set is constructed using the following generative model,
\begin{align*}
&A \sim \text{Ber}(1/2) \times 2 - 1; \\
&V_1 \sim \text{Norm}(-1,\sigma=0.2); \\
&V_2 \sim \text{Norm}(1,\sigma=0.2); \\
&T \sim \text{Ber}(1/3); \\
&U|_{A=1} \sim V_1 \times T + V_2 \times (1-T); \\
&U|_{A=-1} \sim V_1 \times T + V_2 \times (1-T) - 1; \\
&X = [U,A]^T; \\
&Y \sim \mathbbm{1}_{X > 0};
\end{align*}

\noindent
where $A$ is assigned either value 0 or 1 with equal probability.
Hence, the testing set is balanced across values of the attribute.



\noindent
\textbf{Analysis.}
In~\cref{fig:I_exists}, we observe that the learned classification boundary is vertical at $X=0$, which is primarily determined by dominant samples in the majority group.
The vertical boundary suggests that the model does not use attribute $A$ for classification.
Furthermore, as highlighted in~\cref{tab:I_exists}, given that $P(\hat{Y}=y|A=1) = P(\hat{Y}=y|A=-1)~\forall~y \in \{0,1\}$, model prediction $\hat{Y}$ is independent with attribute $A$, \ie Type II Bias does not exist.
However, it is noteworthy that there is a significant performance disparity between the majority and minority groups, which confirms the existence of Type I Bias.













\subsubsection{Type II Bias exists without Type I Bias}
We synthesize training set \wrt $A,X,Y$ by the following generative model,
\begin{align*}
&A \sim \text{Ber}(1/2) \times 2 - 1; \\
&V_1 \sim \text{Norm}(-1,\sigma=0.2); \\
&V_2 \sim \text{Norm}(1,\sigma=0.2); \\
&T \sim \text{Ber}(1/100); \\
&U|_{A=1} \sim V_1 \times (1-T) + V_2 \times T; \\
&U|_{A=-1} \sim V_1 \times T + V_2 \times (1-T); \\
&X = [U,A]^T; \\
&Y \sim \mathbbm{1}_{X > 0}.
\end{align*}

\noindent
As shown in~\cref{fig:II_exists}, the training set yields more samples with combinations $A=1,Y=0$ and $A=-1,Y=1$ compared to other combinations.
This setting is motivated by that the association between target $Y$ and attribute $A$ in the training set is considered one widely-accepted reason for Type II Bias~\cite{LfF_CelebA_Bias_conflicting,CSAD,End}.
The testing set is generated to be balanced across both $Y$ and $A$ with the following generative model,

\begin{align*}
&A \sim \text{Ber}(1/2) \times 2 - 1; \\
&V_1 \sim \text{Norm}(-1,\sigma=0.2); \\
&V_2 \sim \text{Norm}(1,\sigma=0.2); \\
&T \sim \text{Ber}(1/2); \\
&U|_{A=1} \sim V_1 \times (1-T) + V_2 \times T; \\
&U|_{A=-1} \sim V_1 \times T + V_2 \times (1-T); \\
&X = [U,A]^T; \\
&Y \sim \mathbbm{1}_{X > 0}.
\end{align*}




\noindent
\textbf{Analysis.}
In~\cref{fig:II_exists}, we observe that the learned classification boundary is not vertical, which suggests that the classifier relies on $A$ for decision-making.
Furthermore, as highlighted in~\cref{tab:II_exists}, given that $P(\hat{Y}=y|A=1) \neq P(\hat{Y}=y|A=-1)~\forall~y \in \{0,1\}$, model prediction $\hat{Y}$ is not independent with attribute $A$, \ie Type II Bias exists.
However, for Type I Bias, it is noteworthy that there is no significant performance disparity between the majority and minority groups.










\input{sections/pictures/Adult_I}



\subsection{Different Manifestations in Real World}
In this section, we utilize Adult Income Dataset~\cite{adult_dataset_and_german_dataset} to illustrate different manifestations of Type I Bias and Type II Bias in real-world scenarios. 
Adult Dataset is a census dataset where the target is whether a person earns a higher income (over 50K USD per year) and the protected attribute is sex.
As shown in~\cref{tab:stats}, the dataset is partitioned into four quarters based on the combination of target labels and protected attribute labels, given that both are binary in nature.
The statistics illustrate that Adult dataset is well-suited for investigating both Type I Bias and Type II Bias. 
Specifically, the dataset exhibits an uneven distribution across sex, with a larger number of female individuals (16,192) compared to male individuals (32,650), which could induce Type I Bias.
Furthermore, the dataset also exhibits a substantial disparity in the number of samples with higher income between females (1,769) and males (9,918), which could induce Type II Bias.








\noindent
\textbf{Setup.}
We perform data pre-processing on input census data. 
Specifically, we transform the categorical features using one-hot encoding and normalize the numerical features into Gaussian distribution with zero mean and unit variance.
Consequently, each input sample is transformed into a 108-dimensional vector.
For the training model, we employ a three-layer multilayer perceptron (MLP) followed by the binary cross-entropy loss as the baseline classifier.



\input{sections/tables/Adult_statistics}


\subsubsection{Type I Bias}
To investigate Type I Bias, we construct several imbalanced training sets and control the bias strength by modifying the degree of imbalance in the training set.
Specifically, we initially construct a balanced training set across both target $Y$ and attribute $A$ using 80\% of the entire dataset and a balanced testing set with the remaining samples.
We then manually adjust the size of the minority group in the training set while maintaining the size of the majority group to control bias strength.
Additionally, we construct two distinct groups of training sets, with either females or males as the minority group.
For instance, considering the setting where the female is minority group and the minority size is 100, the training set would consist of 50 higher-income females and 50 lower-income females, in addition to all males from the balanced training set.
We conduct experiments under different minority sizes and present the testing performance versus the size of the minority group in~\cref{fig:Adult_I}.





\noindent
\textbf{Analysis.}
Notably, we notice a non-zero accuracy disparity between females (85.15\%{\scriptsize $\pm$1.52}) and males (78.38\%{\scriptsize $\pm$1.90}) at the balance point where the training set is evenly distributed across both target $Y$ and attribute $A$.
We conjecture that this disparity is mainly because certain groups are inherently more difficult to classify than other groups~\cite{FR_inherent_bias}.
To facilitate a clearer analysis of Type I Bias, we use the accuracy difference from the testing accuracy at the balance point to represent the testing performance. 
This difference in testing accuracy, denoted as $Acc_{\text{diff}}$, is calculated by subtracting the testing accuracy at the balance point from the absolute accuracy at a given bias strength, \ie $Acc_{\text{diff}} = Acc_{\text{abs}} - Acc_{\text{balance}}$.
In~\cref{fig:Adult_I}, we observe that the performance disparity exists across the minority group and the majority group.
The accuracy for the minority group tends to decrease as its size diminishes (bias strength increases), especially when there are very limited samples from the minority group.
Furthermore, in~\cref{fig:Adult_I_female}, we observe that stronger bias results in larger performance fluctuations (bigger spread in the boxplot), which highlights the lack of robustness under such conditions.
In summary, the manifestation of Type I Bias in real-world scenarios is uneven performance across demographic groups.
One plausible cause is the imbalance in data representation across these groups in the training set.
For instance, some demographic groups may be underrepresented due to long-tail distribution~\cite{long_tail}, resulting in a skewed distribution of samples across different demographic groups.
Consequently, while data-driven models are more accurately trained on demographic groups with sufficient samples, they may not be as effective for underrepresented groups, which leads to poor prediction accuracy and unfairness towards these groups.









\input{sections/pictures/Adult_II}


\subsubsection{Type II Bias}
To investigate Type II Bias, we construct the training set where the target $Y$ is associated with the attribute $A$ and control the bias strength by adjusting the strength of the association between $Y$ and $A$ in the training set.
Specifically, we initially construct two balanced training datasets consisting of 3538 records, each associating either females or males with higher income: (1) Extreme Bias 1 Balanced (EB1 Balanced) only contains females with higher income and males with lower income, and (2) Extreme Bias 2 Balanced (EB2 Balanced) only contains males with higher income and females with lower income.
Subsequently, we adjust the percentage of bias-conflicting samples (samples with the opposite bias present in the training set) while ensuring a consistent number of biased samples. 
This strategy enables us to construct multiple training sets, each with a distinct conditional entropy $H(Y|A)$ (\ie the smaller $H(Y|A)$, the more predictive the attribute $A$ is of the target $Y$, and the stronger the bias). 
Additionally, we construct a balanced testing set (Balanced) consisting of 7076 records ensuring an even distribution of all combinations of target and attribute labels.
Note that all these datasets are designed to be balanced across attribute to mitigate the effect of Type I Bias.

















\noindent
\textbf{Analysis.}
In~\cref{fig:Adult_II}, we observe that there is a significant prediction disparity between females and males.
Furthermore, this disparity becomes more pronounced as $H(Y|A)$ diminishes (the bias strength increases).
In summary, the manifestation of Type II Bias in real-world scenarios is the dependence on the attribute in decision-making processes.
One widely accepted reason is an uneven distribution of \emph{specific target groups} across attributes, distinguishing it from Type I Bias, which emerges from an uneven distribution of samples across attributes. 
For instance, the collected dataset may contain more negative samples for female individuals and positive samples for male individuals compared to other target-attribute combinations.
During training, the model may leverage sex as the shortcut feature to simplify the learning process, rather than learning more comprehensive features. 
However, such an association between specific targets and attributes does not generally exist in the real world. 
Consequently, during applying, the trained model may still rely on the attribute, which leads to a higher frequency of positive outcomes for specific individuals and further unfair treatment for these groups.









\subsubsection{Summary}
As shown in~\cref{fig:Adult_I}, Type I Bias manifests as the performance disparity across $A$, which is evaluated based on the joint distribution of model prediction $\hat{Y}$ and ground truth $Y$.
Conversely, as shown in~\cref{fig:Adult_II}, Type II Bias manifests as the prediction disparity across $A$, which is evaluated solely based on the distribution of model prediction $\hat{Y}$.
Thus, Type I Bias and Type II Bias are unrelated phenomena and exhibit different impacts on the fairness of neural networks.









\input{sections/pictures/CelebA_I}






\subsection{Evaluation of Various Metrics}
In this section, we employ CelebA dataset~\cite{CelebA} to investigate several representative bias assessment metrics in assessing Type I Bias and Type II Bias. 
CelebA dataset is an image dataset of human faces where facial attributes (\eg blond hair) are prediction target $Y$ and sex is attribute $A$.




\noindent
\textbf{Setup.}
To construct training and testing sets, we follow the setup of Adult explained above.
In the case of Type I Bias, we construct several training sets with varying bias strength by modifying the size of the minority group in training set.
For testing, we construct a testing set that is balanced across both target and attribute.
In the case of Type II Bias, we construct training sets where facial attributes are associated with a particular sex.
Specifically, we construct an extreme bias version of training set consisting of 89754 images with $H(Y|A)=0$, denoted \textit{TrainEx}, where the bias-conflicting samples (samples exhibiting the opposite bias in training set) are removed from the original training set.
Furthermore, we control bias strength by adjusting the proportion of bias-conflicting samples while maintaining the number of biased samples (samples exhibiting the same bias observed in training set).
For testing, we construct two testing sets: (1) \emph{Unbiased} consisting of 720 images which contain the even number of samples across all combinations of target and attribute, and (2) \emph{Bias-conflicting} consisting of 360 images where all biased samples are excluded from \emph{Unbiased} testing set (only bias-conflicting samples remain).
In both studies, we consider \emph{blond hair} as the prediction target.
For the training model, we utilize ResNet18~\cite{ResNet} followed by the binary cross-entropy loss as the baseline classifier without any debiasing techniques. 
For bias assessment, we employ a comprehensive list of representative metrics including accuracy disparity (AP)~\cite{Accuracy_parity}, difference in equality of opportunity (DEO)~\cite{SensitiveNets}, KL-divergence between score distributions (KL)~\cite{divergence_between_score_distributions}, representation-level bias (RLB)~\cite{RLB}, demographic parity distance (DPD)~\cite{DP_FFVAE}, distance correlation (${dcor}^2)$~\cite{distance_correlation}, mutual information (MI)~\cite{CAT}, and bias amplification (BA)~\cite{BA,Directional_BA}.



\input{sections/pictures/CelebA_II}


\noindent
\textbf{Analysis}
In the case of Type I Bias, as shown in~\cref{fig:CelebA_I_male}, there exists a noticeable performance disparity across sex. 
As the size of minority group increases (bias strength diminishes), the performance of the minority group improves and the performance gap between the minority and majority groups is mitigated.
Notably, the performance gap is nonzero even at the balance point, with females achieving higher accuracy than males. 
We hypothesize that this is because blond hair is more visually prominent in females with long hair.
Consequently, even if the dataset is balanced across sex, males may be still relatively underrepresented, \ie male images are still insufficient for the model to learn a robust representation of males.
In the case of Type II Bias, as shown in~\cref{fig:CelebA_II_unbiased}, the testing accuracy of both \emph{Unbiased} and \emph{Bias-conflicting} testing set rises as $H(Y|A)$ increases (bias strength diminishes).



For the evaluation of various bias assessment metrics, in~\cref{fig:CelebA_metrics_I_male,fig:CelebA_metrics_II_unbiased}, we observe a noticeable decline in the metrics tailored for a specific type of bias as the corresponding bias strength diminishes.
It is noteworthy that the mean of accuracy disparity (AD) approaches zero in the extreme bias case of Type II Bias where $H(Y|A)=0$ (the leftmost point).
This can be attributed to the fact that, in such extreme bias situations, the target label is bijectively mapped to the attribute label in the training set. Consequently, the trained model may output arbitrary predictions for both sex in the testing set, which leads to an accuracy disparity that is nearly zero.






