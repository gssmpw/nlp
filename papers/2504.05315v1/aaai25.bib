% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").

@article{neelakantan2022text,
  title={Text and code embeddings by contrastive pre-training},
  author={Neelakantan, Arvind and Xu, Tao and Puri, Raul and Radford, Alec and Han, Jesse Michael and Tworek, Jerry and Yuan, Qiming and Tezak, Nikolas and Kim, Jong Wook and Hallacy, Chris and others},
  journal={arXiv preprint arXiv:2201.10005},
  year={2022}
}

@article{wang2023improving,
  title={Improving text embeddings with large language models},
  author={Wang, Liang and Yang, Nan and Huang, Xiaolong and Yang, Linjun and Majumder, Rangan and Wei, Furu},
  journal={arXiv preprint arXiv:2401.00368},
  year={2023}
}

@article{zeng2022glm,
  title={Glm-130b: An open bilingual pre-trained model},
  author={Zeng, Aohan and Liu, Xiao and Du, Zhengxiao and Wang, Zihan and Lai, Hanyu and Ding, Ming and Yang, Zhuoyi and Xu, Yifan and Zheng, Wendi and Xia, Xiao and others},
  journal={arXiv preprint arXiv:2210.02414},
  year={2022}
}

@misc{openai2023gpt4,
      title={GPT-4 Technical Report}, 
      author={OpenAI},
      year={2023},
      eprint={2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{touvron2023llama,
  title={Llama: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}

@book{Aho:72,
    author  = {Alfred V. Aho and Jeffrey D. Ullman},
    title   = {The Theory of Parsing, Translation and Compiling},
    year    = "1972",
    volume  = "1",
    publisher = {Prentice-Hall},
    address = {Englewood Cliffs, NJ}
}

@book{APA:83,
    author  = {{American Psychological Association}},
    title   = {Publications Manual},
    year    = "1983",
    publisher = {American Psychological Association},
    address = {Washington, DC}
}

@article{Chandra:81,
	author = {Ashok K. Chandra and Dexter C. Kozen and Larry J. Stockmeyer},
	year = "1981",
	title = {Alternation},
	journal = {Journal of the Association for Computing Machinery},
	volume = "28",
	number = "1",
	pages = "114--133",
	doi = "10.1145/322234.322243",
}

@inproceedings{andrew2007scalable,
  title={Scalable training of {L1}-regularized log-linear models},
  author={Andrew, Galen and Gao, Jianfeng},
  booktitle={Proceedings of the 24th International Conference on Machine Learning},
  pages={33--40},
  year={2007},
}

@book{Gusfield:97,
    author  = {Dan Gusfield},
    title   = {Algorithms on Strings, Trees and Sequences},
    year    = "1997",
    publisher = {Cambridge University Press},
    address = {Cambridge, UK}
}

@article{rasooli-tetrault-2015,
    author    = {Mohammad Sadegh Rasooli and Joel R. Tetreault},
    title     = {Yara Parser: {A} Fast and Accurate Dependency Parser},
    journal   = {Computing Research Repository},
    volume    = {arXiv:1503.06733},
    year      = {2015},
    url       = {http://arxiv.org/abs/1503.06733},
    note    = {version 2}
}

@article{Ando2005,
	Acmid = {1194905},
	Author = {Ando, Rie Kubota and Zhang, Tong},
	Issn = {1532-4435},
	Issue_Date = {12/1/2005},
	Journal = {Journal of Machine Learning Research},
	Month = dec,
	Numpages = {37},
	Pages = {1817--1853},
	Publisher = {JMLR.org},
	Title = {A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data},
	Volume = {6},
	Year = {2005}
}

@inproceedings{ECAI23-CER,
	title={The Problem of Coherence in Natural Language Explanations of Recommendations},
	author={Raczyński, Jakub and Lango, Mateusz and Stefanowski, Jerzy},
	booktitle={ECAI},
	year={2023}
}
@inproceedings{ACL21-PETER,
	title={Personalized Transformer for Explainable Recommendation},
	author={Li, Lei and Zhang, Yongfeng and Chen, Li},
	booktitle={ACL},
	year={2021}
}
@article{TOIS23-PEPLER,
	title={Personalized Prompt Learning for Explainable Recommendation},
	author={Li, Lei and Zhang, Yongfeng and Chen, Li},
	journal={ACM Transactions on Information Systems (TOIS)},
	year={2023}
}
@inproceedings{ATT2Seq,
    title = "Learning to Generate Product Reviews from Attributes",
    author = "Dong, Li  and
      Huang, Shaohan  and
      Wei, Furu  and
      Lapata, Mirella  and
      Zhou, Ming  and
      Xu, Ke",
    editor = "Lapata, Mirella  and
      Blunsom, Phil  and
      Koller, Alexander",
    booktitle = "ACL",
    year = "2017",
    pages = "623--632"
}
@inproceedings{NRT,
author = {Li, Piji and Wang, Zihao and Ren, Zhaochun and Bing, Lidong and Lam, Wai},
title = {Neural Rating Regression with Abstractive Tips Generation for Recommendation},
year = {2017},
booktitle = {SIGIR},
pages = {345–354}
}
@inproceedings{PMF,
author = {Salakhutdinov, Ruslan and Mnih, Andriy},
title = {Probabilistic Matrix Factorization},
year = {2007},
isbn = {9781605603520},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Many existing approaches to collaborative filtering can neither handle very large datasets nor easily deal with users who have very few ratings. In this paper we present the Probabilistic Matrix Factorization (PMF) model which scales linearly with the number of observations and, more importantly, performs well on the large, sparse, and very imbalanced Netflix dataset. We further extend the PMF model to include an adaptive prior on the model parameters and show how the model capacity can be controlled automatically. Finally, we introduce a constrained version of the PMF model that is based on the assumption that users who have rated similar sets of movies are likely to have similar preferences. The resulting model is able to generalize considerably better for users with very few ratings. When the predictions of multiple PMF models are linearly combined with the predictions of Restricted Boltzmann Machines models, we achieve an error rate of 0.8861, that is nearly 7\% better than the score of Netflix's own system.},
booktitle = {NeurIPS},
pages = {1257–1264}
}
@inproceedings{SVD++,
author = {Koren, Yehuda},
title = {Factorization meets the neighborhood: a multifaceted collaborative filtering model},
year = {2008},
isbn = {9781605581934},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1401890.1401944},
doi = {10.1145/1401890.1401944},
abstract = {Recommender systems provide users with personalized suggestions for products or services. These systems often rely on Collaborating Filtering (CF), where past transactions are analyzed in order to establish connections between users and products. The two more successful approaches to CF are latent factor models, which directly profile both users and products, and neighborhood models, which analyze similarities between products or users. In this work we introduce some innovations to both approaches. The factor and neighborhood models can now be smoothly merged, thereby building a more accurate combined model. Further accuracy improvements are achieved by extending the models to exploit both explicit and implicit feedback by the users. The methods are tested on the Netflix data. Results are better than those previously published on that dataset. In addition, we suggest a new evaluation metric, which highlights the differences among methods, based on their performance at a top-K recommendation task.},
booktitle = {SIGKDD},
pages = {426–434}
}
@inproceedings{bleu,
    title = "{B}leu: a Method for Automatic Evaluation of Machine Translation",
    author = "Papineni, Kishore  and
      Roukos, Salim  and
      Ward, Todd  and
      Zhu, Wei-Jing",
    editor = "Isabelle, Pierre  and
      Charniak, Eugene  and
      Lin, Dekang",
    booktitle = "Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2002",
    address = "Philadelphia, Pennsylvania, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P02-1040",
    doi = "10.3115/1073083.1073135",
    pages = "311--318",
}
@inproceedings{rouge,
    title = "{ROUGE}: A Package for Automatic Evaluation of Summaries",
    author = "Lin, Chin-Yew",
    booktitle = "Text Summarization Branches Out",
    month = jul,
    year = "2004",
    address = "Barcelona, Spain",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W04-1013",
    pages = "74--81",
}
@inproceedings{nete,
author = {Li, Lei and Zhang, Yongfeng and Chen, Li},
title = {Generate Neural Template Explanations for Recommendation},
year = {2020},
isbn = {9781450368599},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3340531.3411992},
doi = {10.1145/3340531.3411992},
abstract = {Personalized recommender systems are important to assist user decision-making in the era of information overload. Meanwhile, explanations of the recommendations further help users to better understand the recommended items so as to make informed choices, which gives rise to the importance of explainable recommendation research. Textual sentence-based explanation has been an important form of explanations for recommender systems due to its advantage in communicating rich information to users. However, current approaches to generating sentence explanations are either limited to predefined sentence templates, which restricts the sentence expressiveness, or opt for free-style sentence generation, which makes it difficult for sentence quality control. In an attempt to benefit both sentence expressiveness and quality, we propose a Neural Template (NETE) explanation generation framework, which brings the best of both worlds by learning sentence templates from data and generating template-controlled sentences that comment about specific features. Experimental results on real-world datasets show that NETE consistently outperforms state-of-the-art explanation generation approaches in terms of sentence quality and expressiveness. Further analysis on case study also shows the advantages of NETE on generating diverse and controllable explanations.},
booktitle = {Proceedings of the 29th ACM International Conference on Information \& Knowledge Management},
pages = {755–764},
numpages = {10},
keywords = {recommender systems, neural template explanation, natural language generation, explainable recommendation},
location = {Virtual Event, Ireland},
series = {CIKM '20}
}
@article{hss,
  title={Generate natural language explanations for recommendation},
  author={Chen, Hanxiong and Chen, Xu and Shi, Shaoyun and Zhang, Yongfeng},
  journal={arXiv preprint arXiv:2101.03392},
  year={2021}
}
@inproceedings{GRU,
    title = "Learning Phrase Representations using {RNN} Encoder{--}Decoder for Statistical Machine Translation",
    author = {Cho, Kyunghyun  and
      van Merri{\"e}nboer, Bart  and
      Gulcehre, Caglar  and
      Bahdanau, Dzmitry  and
      Bougares, Fethi  and
      Schwenk, Holger  and
      Bengio, Yoshua},
    booktitle = "EMNLP",
    year = "2014",
    pages = "1724--1734"
}
@ARTICLE{lstm,
  author={Hochreiter, Sepp and Schmidhuber, Jürgen},
  journal={Neural Computation}, 
  title={Long Short-Term Memory}, 
  year={1997},
  volume={9},
  number={8},
  pages={1735-1780},
  keywords={},
  doi={10.1162/neco.1997.9.8.1735}}
@inproceedings{BPE,
    title = "Neural Machine Translation of Rare Words with Subword Units",
    author = "Sennrich, Rico  and
      Haddow, Barry  and
      Birch, Alexandra",
    editor = "Erk, Katrin  and
      Smith, Noah A.",
    booktitle = "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2016",
    address = "Berlin, Germany",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P16-1162",
    doi = "10.18653/v1/P16-1162",
    pages = "1715--1725",
}
@inproceedings{sentencepiece,
    title = "{S}entence{P}iece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing",
    author = "Kudo, Taku  and
      Richardson, John",
    editor = "Blanco, Eduardo  and
      Lu, Wei",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D18-2012",
    doi = "10.18653/v1/D18-2012",
    pages = "66--71",
    abstract = "This paper describes SentencePiece, a language-independent subword tokenizer and detokenizer designed for Neural-based text processing, including Neural Machine Translation. It provides open-source C++ and Python implementations for subword units. While existing subword segmentation tools assume that the input is pre-tokenized into word sequences, SentencePiece can train subword models directly from raw sentences, which allows us to make a purely end-to-end and language independent system. We perform a validation experiment of NMT on English-Japanese machine translation, and find that it is possible to achieve comparable accuracy to direct subword training from raw sentences. We also compare the performance of subword training and segmentation with various configurations. SentencePiece is available under the Apache 2 license at \url{https://github.com/google/sentencepiece}.",
}
@inproceedings{xavier,
  title={Understanding the difficulty of training deep feedforward neural networks},
  author={Xavier Glorot and Yoshua Bengio},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  year={2010},
  url={https://api.semanticscholar.org/CorpusID:5575601}
}
@inproceedings{lora,
title={Lo{RA}: Low-Rank Adaptation of Large Language Models},
author={Edward J Hu and Yelong Shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=nZeVKeeFYf9}
}
@Misc{peft,
  title =        {PEFT: State-of-the-art Parameter-Efficient Fine-Tuning methods},
  author =       {Sourab Mangrulkar and Sylvain Gugger and Lysandre Debut and Younes Belkada and Sayak Paul and Benjamin Bossan},
  howpublished = {\url{https://github.com/huggingface/peft}},
  year =         {2022}
}
@inproceedings{Adamw,
  title={Decoupled Weight Decay Regularization},
  author={Ilya Loshchilov and Frank Hutter},
  booktitle={International Conference on Learning Representations},
  year={2017},
  url={https://api.semanticscholar.org/CorpusID:53592270}
}

@inproceedings{ni-etal-2019-justifying,
    title = "Justifying Recommendations using Distantly-Labeled Reviews and Fine-Grained Aspects",
    author = "Ni, Jianmo  and
      Li, Jiacheng  and
      McAuley, Julian",
    editor = "Inui, Kentaro  and
      Jiang, Jing  and
      Ng, Vincent  and
      Wan, Xiaojun",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-1018",
    doi = "10.18653/v1/D19-1018",
    pages = "188--197",
    abstract = "Several recent works have considered the problem of generating reviews (or {`}tips{'}) as a form of explanation as to why a recommendation might match a customer{'}s interests. While promising, we demonstrate that existing approaches struggle (in terms of both quality and content) to generate justifications that are relevant to users{'} decision-making process. We seek to introduce new datasets and methods to address the recommendation justification task. In terms of data, we first propose an {`}extractive{'} approach to identify review segments which justify users{'} intentions; this approach is then used to distantly label massive review corpora and construct large-scale personalized recommendation justification datasets. In terms of generation, we are able to design two personalized generation models with this data: (1) a reference-based Seq2Seq model with aspect-planning which can generate justifications covering different aspects, and (2) an aspect-conditional masked language model which can generate diverse justifications based on templates extracted from justification histories. We conduct experiments on two real-world datasets which show that our model is capable of generating convincing and diverse justifications.",
}
@inproceedings{transformer,
author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, \L{}ukasz and Polosukhin, Illia},
title = {Attention is all you need},
year = {2017},
isbn = {9781510860964},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.0 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature.},
booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems},
pages = {6000–6010},
numpages = {11},
location = {Long Beach, California, USA},
series = {NIPS'17}
}

@inproceedings{bert,
    title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    author = "Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina",
    editor = "Burstein, Jill  and
      Doran, Christy  and
      Solorio, Thamar",
    booktitle = "NAACL",
    month = jun,
    year = "2019",
    pages = "4171--4186"
}
@inproceedings{gpt2,
  title={Language Models are Unsupervised Multitask Learners},
  author={Alec Radford and Jeff Wu and Rewon Child and David Luan and Dario Amodei and Ilya Sutskever},
  year={2019},
  url={https://api.semanticscholar.org/CorpusID:160025533}
}

@inproceedings{KG,
author = {Fu, Zuohui and Xian, Yikun and Gao, Ruoyuan and Zhao, Jieyu and Huang, Qiaoying and Ge, Yingqiang and Xu, Shuyuan and Geng, Shijie and Shah, Chirag and Zhang, Yongfeng and de Melo, Gerard},
title = {Fairness-Aware Explainable Recommendation over Knowledge Graphs},
year = {2020},
isbn = {9781450380164},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3397271.3401051},
doi = {10.1145/3397271.3401051},
abstract = {There has been growing attention on fairness considerations recently, especially in the context of intelligent decision making systems. For example, explainable recommendation systems may suffer from both explanation bias and performance disparity. We show that inactive users may be more susceptible to receiving unsatisfactory recommendations due to their insufficient training data, and that their recommendations may be biased by the training records of active users due to the nature of collaborative filtering, which leads to unfair treatment by the system. In this paper, we analyze different groups of users according to their level of activity, and find that bias exists in recommendation performance between different groups. Empirically, we find that such performance gap is caused by the disparity of data distribution, specifically the knowledge graph path distribution in this work. We propose a fairness constrained approach via heuristic re-ranking to mitigate this unfairness problem in the context of explainable recommendation over knowledge graphs. We experiment on several real-world datasets with state-of-the-art knowledge graph-based explainable recommendation algorithms. The promising results show that our algorithm is not only able to provide high-quality explainable recommendations, but also reduces the recommendation unfairness in several aspects.},
booktitle = {SIGIR},
pages = {69–78}
}

@inproceedings{image,
author = {Chen, Xu and Chen, Hanxiong and Xu, Hongteng and Zhang, Yongfeng and Cao, Yixin and Qin, Zheng and Zha, Hongyuan},
title = {Personalized Fashion Recommendation with Visual Explanations based on Multimodal Attention Network: Towards Visually Explainable Recommendation},
year = {2019},
booktitle = {SIGIR},
pages = {765–774}
}

@article{cloud,
  title={Visualization of Explanations in Recommender Systems},
  author={Mohammed Al-Taie and Seifedine Nimer Kadry},
  journal={Journal of Advanced Management Science},
  year={2014},
  volume={2},
  pages={140-144},
  url={https://api.semanticscholar.org/CorpusID:51944238}
}

@article{faithfulness&coherence,
  title={On Faithfulness and Coherence of Language Explanations for Recommendation Systems},
  author={Zhouhang Xie and Julian McAuley and Bodhisattwa Prasad Majumder},
  journal={ArXiv},
  year={2022},
  volume={abs/2209.05409},
  url={https://api.semanticscholar.org/CorpusID:252199696}
}

@inproceedings{distinct-n,
    title = "A Diversity-Promoting Objective Function for Neural Conversation Models",
    author = "Li, Jiwei  and
      Galley, Michel  and
      Brockett, Chris  and
      Gao, Jianfeng  and
      Dolan, Bill",
    editor = "Knight, Kevin  and
      Nenkova, Ani  and
      Rambow, Owen",
    booktitle = "Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2016",
    address = "San Diego, California",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N16-1014",
    doi = "10.18653/v1/N16-1014",
    pages = "110--119",
}
@inproceedings{
bertscore,
title={BERTScore: Evaluating Text Generation with BERT},
author={Tianyi Zhang* and Varsha Kishore* and Felix Wu* and Kilian Q. Weinberger and Yoav Artzi},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=SkeHuCVFDr}
}
@inproceedings{bartscore,
 author = {Yuan, Weizhe and Neubig, Graham and Liu, Pengfei},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan},
 pages = {27263--27277},
 publisher = {Curran Associates, Inc.},
 title = {BARTScore: Evaluating Generated Text as Text Generation},
 url = {https://proceedings.neurips.cc/paper_files/paper/2021/file/e4d2b6e6fdeca3e60e0f1a62fee3d9dd-Paper.pdf},
 volume = {34},
 year = {2021}
}
@inproceedings{Twitter2,
    title = "{T}ime{LM}s: Diachronic Language Models from {T}witter",
    author = "Loureiro, Daniel  and
      Barbieri, Francesco  and
      Neves, Leonardo  and
      Espinosa Anke, Luis  and
      Camacho-collados, Jose",
    booktitle = "ACL",
    year = "2022",
    pages = "251--260"
}
@article{Roberta,
  author    = {Yinhan Liu and
               Myle Ott and
               Naman Goyal and
               Jingfei Du and
               Mandar Joshi and
               Danqi Chen and
               Omer Levy and
               Mike Lewis and
               Luke Zettlemoyer and
               Veselin Stoyanov},
  title     = {RoBERTa: {A} Robustly Optimized {BERT} Pretraining Approach},
  journal   = {CoRR},
  volume    = {abs/1907.11692},
  year      = {2019},
  url       = {http://arxiv.org/abs/1907.11692},
  archivePrefix = {arXiv},
  eprint    = {1907.11692},
  timestamp = {Thu, 01 Aug 2019 08:59:33 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1907-11692.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{llama,
  title={LLaMA: Open and Efficient Foundation Language Models},
  author={Hugo Touvron and Thibaut Lavril and Gautier Izacard and Xavier Martinet and Marie-Anne Lachaux and Timoth{\'e}e Lacroix and Baptiste Rozi{\`e}re and Naman Goyal and Eric Hambro and Faisal Azhar and Aurelien Rodriguez and Armand Joulin and Edouard Grave and Guillaume Lample},
  journal={ArXiv},
  year={2023},
  volume={abs/2302.13971},
  url={https://api.semanticscholar.org/CorpusID:257219404}
}


@misc {sentiment,
	author       = { {NLP Town} },
	title        = { bert-base-multilingual-uncased-sentiment (Revision edd66ab) },
	year         = 2023,
	url          = { https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment },
	doi          = { 10.57967/hf/1515 },
	publisher    = { Hugging Face }
}

@article{survey,
author = {Zhang, Yongfeng and Chen, Xu},
title = {Explainable Recommendation: A Survey and New Perspectives},
year = {2020},
issue_date = {Mar 2020},
publisher = {Now Publishers Inc.},
address = {Hanover, MA, USA},
volume = {14},
number = {1},
issn = {1554-0669},
url = {https://doi.org/10.1561/1500000066},
doi = {10.1561/1500000066},
abstract = {Explainable recommendation attempts to develop models that generate not only high-quality recommendations but also intuitive explanations. The explanations may either be post-hoc or directly come from an explainable model (also called interpretable or transparent model in some contexts). Explainable recommendation tries to address the problem of why: by providing explanations to users or system designers, it helps humans to understand why certain items are recommended by the algorithm, where the human can either be users or system designers. Explainable recommendation helpsendation systems. It also facilitates system design to improve the transparency, persuasiveness, effectiveness, trustworthiness, and satisfaction of recommers for better system debugging. In recent years, a large number of explainable recommendation approaches – especially model-based methods – have been proposed and applied in real-world systems.In this survey, we provide a comprehensive review for the explainable recommendation research. We first highlight the position of explainable recommendation in recommender system research by categorizing recommendation problems into the 5W, i.e., what, when, who, where, and why. We then conduct a comprehensive survey of explainable recommendation on three perspectives: 1) We provide a chronological research timeline of explainable recommendation, including user study approaches in the early years and more recent model-based approaches. 2) We provide a two-dimensional taxonomy to classify existing explainable recommendation research: one dimension is the information source (or display style) of the explanations, and the other dimension is the algorithmic mechanism to generate explainable recommendations. 3) We summarize how explainable recommendation applies to different recommendation tasks, such as product recommendation, social recommendation, and POI recommendation.We also devote a section to discuss the explanation perspectives in broader IR and AI/ML research. We end the survey by discussing potential future directions to promote the explainable recommendation research area and beyond.},
journal = {Found. Trends Inf. Retr.},
month = {mar},
pages = {1–101},
numpages = {101}
}

@Inbook{Tintarev2015,
author="Tintarev, Nava
and Masthoff, Judith",
editor="Ricci, Francesco
and Rokach, Lior
and Shapira, Bracha",
title="Explaining Recommendations: Design and Evaluation",
bookTitle="Recommender Systems Handbook",
year="2015",
publisher="Springer US",
address="Boston, MA",
pages="353--382",
abstract="This chapter gives an overview of the area of explanations in recommender systems. We approach the literature from the angle of evaluation: that is, we are interested in what makes an explanation ``good''. The chapter starts by describing how explanations can be affected by how recommendations are presented, and the role the interaction with the recommender system plays w.r.t. explanations. Next, we introduce a number of explanation styles, and how they are related to the underlying algorithms. We identify seven benefits that explanations may contribute to a recommender system, and relate them to criteria used in evaluations of explanations in existing recommender systems. We conclude the chapter with outstanding research questions and future work, including current recommender systems topics such as social recommendations and serendipity. Examples of explanations in existing systems are mentioned throughout.",
isbn="978-1-4899-7637-6",
doi="10.1007/978-1-4899-7637-6_10",
url="https://doi.org/10.1007/978-1-4899-7637-6_10"
}

@inproceedings{ni-etal-2017-estimating,
    title = "Estimating Reactions and Recommending Products with Generative Models of Reviews",
    author = "Ni, Jianmo  and
      Lipton, Zachary C.  and
      Vikram, Sharad  and
      McAuley, Julian",
    editor = "Kondrak, Greg  and
      Watanabe, Taro",
    booktitle = "IJCNLP",
    month = nov,
    year = "2017",
    pages = "783--791"
}

@inproceedings{DualLearning,
author = {Sun, Peijie and Wu, Le and Zhang, Kun and Fu, Yanjie and Hong, Richang and Wang, Meng},
title = {Dual Learning for Explainable Recommendation: Towards Unifying User Preference Prediction and Review Generation},
year = {2020},
booktitle = {WWW},
pages = {837–847}
}

@inproceedings{cheng-etal-2023-explainable,
    title = "Explainable Recommendation with Personalized Review Retrieval and Aspect Learning",
    author = "Cheng, Hao  and
      Wang, Shuo  and
      Lu, Wensheng  and
      Zhang, Wei  and
      Zhou, Mingyang  and
      Lu, Kezhong  and
      Liao, Hao",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "ACL",
    year = "2023",
    pages = "51--64"
}

@article{labelsmoothing,
  title={Rethinking the Inception Architecture for Computer Vision},
  author={Christian Szegedy and Vincent Vanhoucke and Sergey Ioffe and Jonathon Shlens and Zbigniew Wojna},
  journal={CVPR},
  year={2015},
  pages={2818-2826}
}

@inbook{labelsmoothingsurvey,
author = {M\"{u}ller, Rafael and Kornblith, Simon and Hinton, Geoffrey},
title = {When does label smoothing help?},
year = {2019},
booktitle = {NeurIPS},
articleno = {422}
}

@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@inproceedings{Radford2019LanguageMA,
  title={Language Models are Unsupervised Multitask Learners},
  author={Alec Radford and Jeff Wu and Rewon Child and David Luan and Dario Amodei and Ilya Sutskever},
  year={2019},
  url={https://api.semanticscholar.org/CorpusID:160025533}
}

@article{zhang2019deep,
  title={Deep learning based recommender system: A survey and new perspectives},
  author={Zhang, Shuai and Yao, Lina and Sun, Aixin and Tay, Yi},
  journal={ACM Computing Surveys},
  volume={52},
  number={1},
  pages={1--38},
  year={2019}
}

@inproceedings{ZhangYWW22,
  author       = {Wei Zhang and
                  Junbing Yan and
                  Zhuo Wang and
                  Jianyong Wang},
  title        = {Neuro-Symbolic Interpretable Collaborative Filtering for Attribute-based
                  Recommendation},
  booktitle    = {{WWW}},
  pages        = {3229--3238},
  year         = {2022},
}

@article{ZhangC20,
  author       = {Yongfeng Zhang and
                  Xu Chen},
  title        = {Explainable Recommendation: {A} Survey and New Perspectives},
  journal      = {Found. Trends Inf. Retr.},
  pages        = {1--101},
  year         = {2020},
}

@article{hu2021knowledgeable,
  title={Knowledgeable prompt-tuning: Incorporating knowledge into prompt verbalizer for text classification},
  author={Hu, Shengding and Ding, Ning and Wang, Huadong and Liu, Zhiyuan and Wang, Jingang and Li, Juanzi and Wu, Wei and Sun, Maosong},
  journal={arXiv preprint arXiv:2108.02035},
  year={2021}
}


@inbook{labelSmoothing1,
author = {M\"{u}ller, Rafael and Kornblith, Simon and Hinton, Geoffrey},
title = {When does label smoothing help?},
year = {2019},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {The generalization and learning speed of a multi-class neural network can often be significantly improved by using soft targets that are a weighted average of the hard targets and the uniform distribution over labels. Smoothing the labels in this way prevents the network from becoming over-confident and label smoothing has been used in many state-of-the-art models, including image classification, language translation and speech recognition. Despite its widespread use, label smoothing is still poorly understood. Here we show empirically that in addition to improving generalization, label smoothing improves model calibration which can significantly improve beam-search. However, we also observe that if a teacher network is trained with label smoothing, knowledge distillation into a student network is much less effective. To explain these observations, we visualize how label smoothing changes the representations learned by the penultimate layer of the network. We show that label smoothing encourages the representations of training examples from the same class to group in tight clusters. This results in loss of information in the logits about resemblances between instances of different classes, which is necessary for distillation, but does not hurt generalization or calibration of the model's predictions.},
booktitle = {Proceedings of the 33rd International Conference on Neural Information Processing Systems},
articleno = {422},
numpages = {10}
}
@inproceedings{10.5555/3666122.3666237,
author = {Sun, Zhiqing and Shen, Yikang and Zhou, Qinhong and Zhang, Hongxin and Chen, Zhenfang and Cox, David and Yang, Yiming and Gan, Chuang},
title = {Principle-driven self-alignment of language models from scratch with minimal human supervision},
year = {2024},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Recent AI-assistant agents, such as ChatGPT, predominantly rely on supervised fine-tuning (SFT) with human annotations and reinforcement learning from human feedback (RLHF) to align the output of large language models (LLMs) with human intentions, ensuring they are helpful, ethical, and reliable. However, this dependence can significantly constrain the true potential of AI-assistant agents due to the high cost of obtaining human supervision and the related issues on quality, reliability, diversity, self-consistency, and undesirable biases. To address these challenges, we propose a novel approach called SELF-ALIGN, which combines principle-driven reasoning and the generative power of LLMs for the self-alignment of the AI agents with minimal human supervision.Applying SELF-ALIGN to the LLaMA-65b base language model, we develop an AI assistant named Dromedary. With fewer than 300 lines of human annotations (including < 200 seed prompts, 16 generic principles, and 5 exemplars for in-context learning), Dromedary significantly surpasses the performance of several state-of-the-art AI systems, including Text-Davinci-003 and Alpaca, on benchmark datasets with various settings. We have open-sourced the code, LoRA weights of Dromedary, and our synthetic training data to encourage further research into aligning LLM-based AI agents with enhanced supervision efficiency, reduced biases, and improved controllability.},
booktitle = {Proceedings of the 37th International Conference on Neural Information Processing Systems},
articleno = {115},
numpages = {55},
location = {New Orleans, LA, USA},
series = {NIPS '23}
}

@inproceedings{NEURIPS2023_ac662d74,
 author = {Zhou, Chunting and Liu, Pengfei and Xu, Puxin and Iyer, Srinivasan and Sun, Jiao and Mao, Yuning and Ma, Xuezhe and Efrat, Avia and Yu, Ping and YU, LILI and Zhang, Susan and Ghosh, Gargi and Lewis, Mike and Zettlemoyer, Luke and Levy, Omer},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {A. Oh and T. Naumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
 pages = {55006--55021},
 publisher = {Curran Associates, Inc.},
 title = {LIMA: Less Is More for Alignment},
 url = {https://proceedings.neurips.cc/paper_files/paper/2023/file/ac662d74829e4407ce1d126477f4a03a-Paper-Conference.pdf},
 volume = {36},
 year = {2023}
}
@misc{vicuna2023,
    title = {Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90\%* ChatGPT Quality},
    url = {https://lmsys.org/blog/2023-03-30-vicuna/},
    author = {Chiang, Wei-Lin and Li, Zhuohan and Lin, Zi and Sheng, Ying and Wu, Zhanghao and Zhang, Hao and Zheng, Lianmin and Zhuang, Siyuan and Zhuang, Yonghao and Gonzalez, Joseph E. and Stoica, Ion and Xing, Eric P.},
    month = {March},
    year = {2023}
}
@inproceedings{SIGIR14-Sentires,
	title={Do users rate or review? Boost phrase-level sentiment labeling with review-level sentiment classification},
	author={Zhang, Yongfeng and Zhang, Haochen and Zhang, Min and Liu, Yiqun and Ma, Shaoping},
	booktitle={SIGIR},
	year={2014}
}
@inproceedings{DeepCoNN,
  title={Joint deep modeling of users and items using reviews for recommendation},
  author={Zheng, Lei and Noroozi, Vahid and Yu, Philip S},
  booktitle={Proceedings of the tenth ACM international conference on web search and data mining},
  pages={425--434},
  year={2017}
}
@inproceedings{NARRE,
  title={Neural attentional rating regression with review-level explanations},
  author={Chen, Chong and Zhang, Min and Liu, Yiqun and Ma, Shaoping},
  booktitle={Proceedings of the 2018 world wide web conference},
  pages={1583--1592},
  year={2018}
}
@inproceedings{co-attentive,
  title={Co-attentive multi-task learning for explainable recommendation.},
  author={Chen, Zhongxia and Wang, Xiting and Xie, Xing and Wu, Tong and Bu, Guoqing and Wang, Yining and Chen, Enhong},
  booktitle={IJCAI},
  volume={2019},
  pages={2137--2143},
  year={2019}
}
@inproceedings{li2020generate,
  title={Generate neural template explanations for recommendation},
  author={Li, Lei and Zhang, Yongfeng and Chen, Li},
  booktitle={Proceedings of the 29th ACM International Conference on Information \& Knowledge Management},
  pages={755--764},
  year={2020}
}
@inproceedings{yang2021explanation,
  title={Explanation as a Defense of Recommendation},
  author={Yang, Aobo and Wang, Nan and Deng, Hongbo and Wang, Hongning},
  booktitle={Proceedings of the 14th ACM International Conference on Web Search and Data Mining},
  pages={1029--1037},
  year={2021}
}
@article{zhang2023triple,
  title={Triple Dual Learning for Opinion-based Explainable Recommendation},
  author={Zhang, Yuting and Sun, Ying and Zhuang, Fuzhen and Zhu, Yongchun and An, Zhulin and Xu, Yongjun},
  journal={ACM Transactions on Information Systems},
  volume={42},
  number={3},
  pages={1--27},
  year={2023},
  publisher={ACM New York, NY}
}
@misc{Sentires,
  author={Li, Lei and Chen, Li and Zhang, Yongfeng and Zhang, Haochen and Zhang, Min and Liu, Yiqun and Ma, Shaoping},
  year={2020},
  title={Sentires},
  howpublished = {\url{https://github.com/lileipisces/Sentires-Guide}}
}