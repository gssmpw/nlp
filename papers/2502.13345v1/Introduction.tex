\begin{figure}[t]
\centering
\includegraphics[width=\columnwidth]{pic_v5.pdf} % 
\caption{Watermark framework comparison with existing  solutions.}
\label{fig1}
\end{figure}

\section{Introduction}
%近年来，扩散模型取得了显著进展，极大地提升了图像生成任务的质量。诸如Stable Diffusion和DALLE-2等模型展示了能够生成广泛创意效果的能力，涵盖了艺术作品和现实世界的真实描绘。还推动了诸如ControlNet和Instruct-Pix2Pix等图像编辑工具的发展，深刻影响了公众创作、绘画预览、美术设计等领域。
Substantial progress in latent diffusion models (LDMs) \cite{croitoru2023diffusion} have significantly enhanced the quality of image generation, which presents observable abilities in producing a wide scope of creative visuals, e.g., artistic works and realistic depictions. 
% However, the diffusion models for synthesizing photorealistic content are encountering threats from being exploited by untrustworthy users, causing deepfake \cite{barrett2023identifying} and infringement of copyright \cite{gowal2023identifying}. 
To safeguard the copyright of generative models \cite{gowal2023identifying} and prevent their misuse \cite{barrett2023identifying}, watermarking is one avenue for detecting generated content and tracing its source. Recently, there is a compelling trend for  model producers  to distribute LDMs to numberous model users by model sharing \cite{donahue2021model}, disclosure \cite{azcoitia2022survey}, and trading \cite{pei2023data}. Since a large amount of model users are granted with model architecture access and fine-tuning permission in these model distribution scenarios, effective watermark injection and robust watermark verification becomes more challenging compared with local model usage. 

In order to support applications in  model distribution scenarios, LDM watermarks need to accommodate serveral key constrains. (1) Since model networks and parameters will be distributed for personalized usage, it is possible for model users to bypass the  watermark injection by model modifications. Therefore, security mechanism is indispensable to avoid watermark evading. (2) When the model is distributed to massive users, the watermark has to guarantee low injection time cost while spanning distinctive information for a large amount of user verification. (3) Due to the higher model access permission and larger user scale in model distribution scenarios, untrustworthy users pose a greater threat of model theft and leakage, making it essential for watermarking methods to ensure robustness against diverse adversaries. 


%In order to support user-personalized operations and further explore the application value of diffusion models, model distributions, such as model sharing \cite{donahue2021model}, disclosure \cite{azcoitia2022survey}, and trading \cite{pei2023data}, are important ways for fine-tuning on private data and domain-specific applications.
% for protecting the copyright of diffusion models \cite{zhao2023recipe}. %, e.g., Stable Diffusion \cite{rombach2022high} and DALLE-2 \cite{ramesh2022hierarchical}.
%The technical advancement in image editing tools (e.g., ControlNet \cite{zhang2023adding} and Instruct-Pix2Pix \cite{brooks2023instructpix2pix}) also has profoundly influenced various fields, such as painting previews and artistic design.
%In recent years, substantial progress in diffusion models has significantly enhanced the quality of image generation tasks. 
%Models such as Stable Diffusion \cite{rombach2022high} and DALLE-2 \cite{ramesh2022hierarchical} have demonstrated the ability to produce a wide range of creative visuals, covering artistic works and realistic depictions. 
%They have also propelled the development of image editing tools such as ControlNet \cite{zhang2023adding} and Instruct-Pix2Pix \cite{brooks2023instructpix2pix}, profoundly influencing fields like painting previews and artistic design.
% In order to further improve the performance of diffusion models, \yj{Not the only reason.} model distributions, such as model sharing \yj{refs}, disclosure\yj{refs}, and trading\yj{refs}, are important ways for fine-tuning on private data and domain-specific applications.  

%Model distribution scenarios exhibit the following characteristics. First, model architecture and weights will be distributed to users for local deployment and usage. Second, the amount of users is often very large. For example, the open-source model Stable Diffusion \cite{rombach2022high} has been downloaded over a million times.  Third, due to the higher model access permissions granted to users in model distribution, coupled with the large scale of the user base, there are various potential methods for unauthorized users to exploit and leak the model, thus significantly complicating copyright protection.

% In order to support user-personalized operations and further explore the application value of diffusion models, model distributions, such as model sharing \cite{donahue2021model}, disclosure \cite{azcoitia2022survey}, and trading \cite{pei2023data}, are important ways for fine-tuning on private data and domain-specific applications.
% Model distribution, including model sharing \cite{donahue2021model}, disclosure \cite{azcoitia2022survey}, and trading \cite{pei2023data}, plays a crucial role in supporting user-personalized operations and further exploring the application value of diffusion models, serving as important methods for fine-tuning on private data and domain-specific applications.

% However, the diffusion models for synthesizing photorealistic content are encountering threats from being exploited by untrustworthy users, causing numerous offenses, such as deepfakes and online spams \cite{barrett2023identifying}. 
% For instance, Google passively announced their image watermark solution called SynthID, in order to deal with adversarial issues on social media \cite{gowal2023identifying}. 



% Watermarking is deemed to be a technical alternative for protecting the copyright of diffusion models \cite{zhao2023recipe}.
% In the scenario of model distribution, high-quality diffusion models can be considered as intellectual property, as it generally require  meticulously designed deep neural network architecture, large-scale high-quality datasets, and substantial computational resources. 
% A few vital issues of ideal watermarking approaches need to be addressed before utilized for model distribution, covering watermark flexibility, security, and robustness. 

% \yj{Summarize the first two paragraphs in one paragraph to introduce (1) the background of LDM watermarking, (2) the model distribution scenarios (3) and the importance of LDM watermarking in distribution scenarios.}

%Model watermarking for LDM has to accommodate serveral key constrains for application in the distribution scenarios. (1) Security mechanism to avoid evading the watermark. Since users have control over the model parameters and structure, additional security mechanism is required to ensure that users cannot bypass the embedding of the watermark.  (2) Distinctive watermark information with low injection cost. Given the massive scale of users in model distribution scenarios, sufficient information should be ensured to match users while maintaining an efficient watermark embedding mechanism. (3) Quite diverse adversaries. Due to the higher model permissions and larger user scale in model distribution scenarios, untrustworthy users pose a greater potential threat of model theft and leakage, making it essential for watermarking methods to ensure sufficient robustness against diverse adversaries.

% To be noticed, explaining why the constraint existed first and then describing the constraint.

A traditional watermarking solution is post-processing watermark that embeds watermarks after image generation (Figure \ref{fig1}(a)). However, untrustworthy users can remove post-hoc watermark trivially. %The open-source models, e.g., Stable Diffusion \cite{rombach2022high} exemplifies this issue, as removal of a watermark can be as straightforward as commenting out a single line of code. 
%Existing watermarking methods can be divided into two types: post-processing watermarks and in-processing watermarks. Post-processing \cite{cox2007digital,zhang2019robust} watermarks embed watermarks after image generation. However, untrustworthy users can remove post-hoc watermark trivially. The open-source models, e.g., Stable Diffusion \cite{rombach2022high} exemplifies this issue, as removal of a watermark can be as straightforward as commenting out a single line of code.  
% which are model-agnostic but can introduce human-visible artifacts, compromising image quality. 
On the other hand, in-processing watermarks inject messages into the image generation process, which contain three category solutions based on modification ways. Whole model modifications \cite{zhao2023recipe,feng2024aqualora} embed watermarks by training the entire generative models (Figure \ref{fig1}(b)), which require substantial training resources and thus inefficient in terms of model distribution senarios. Partial model modifications \cite{fernandez2023stable,xiong2023flexible} merely fine-tune the decoder of the LDMs (Figure \ref{fig1}(c)). However, these methods are vulnerable to multiple attacks \cite{an2024benchmarking} such as reconstructive attack \cite{zhao2023invisible} and adaptive adversarial sample attack \cite{jiang2023evading}. Random seed modifications \cite{wen2024tree,yang2024gaussian,ci2025ringid} 
%which are referred to as semantic watermarks, 
inject watermarks into the initial latent variable of LDMs which are time-efficient without model fine-tuning and robust against diverse attacks. But in model distribution scenarios, the untrustworthy user can easily change the initial latent vector to circumvent watermark injection.
% (low security and robustness)


% First of all, it is a challenge to support model watermarking with low injection cost and sufficient model watermark information in various model distribution scenarios for large amount of model users. 
% In general, the quality and quantity of watermark embedding will cause varying degrees of impact on the model performance. 
% Thus, finding out a solution to embed flexible watermarks in the limited space capacity, e.g., using multi-bit watermarks, is one of the challenges in dealing with heterogeneous model distribution issues.  \yj{The above two sentances are confusing.}
% % First of all, finding out a solution to embed flexible watermarks in the limited space capacity, e.g., using multi-bit watermarks, is one of the challenges in dealing with heterogeneous model distribution issues. 
% % Second, threats also exist during the usage of model watermarking, such as unexpected disclosure and malicious removal. 
% Second, a primary purpose of model watermarking is to trace usage of the model, including the generated content. 
% % In most situations, due to the space limitation, watermarks are embedded in a plain-text manner to guarantee essential information, which weakens the usability of watermarks. 
% In Machine Learning as a Service (MLaaS) scenarios, watermarks are often added to generated the images through post-processing \cite{cox2007digital} or training-free watermarking (see Figure \ref{fig1}(a)) \cite{wen2024tree}. However, in the model distribution scenarios for diffusion models, untrustworthy users can remove post-hoc or initial latent variable watermarking trivially. 
% The open-source models, e.g., Stable Diffusion \cite{rombach2022high} exemplifies this issue, as removal of a watermark can be as straightforward as commenting out a single line of code.
% To prevent untrustworthy users from evading the watermark embedding process, existing works have embedded watermarks within model components by fine-tuning (see Figure \ref{fig1}(b)), such as Stable Signature \cite{fernandez2023stable} and FSwatermark \cite{xiong2023flexible}. But this kind of watermarks are vulnerable to multiple attacks \cite{an2024benchmarking}.
% Therefore, when considering the model a digital asset, the threat of model theft and tampering rises a higher-level requirement on the security. 
% %In the model distribution scenario for latent diffusion models, untrustworthy users can remove post-hoc watermarking trivially. 
% %The open-source nature of models like Stable Diffusion \cite{rombach2022high} exemplifies this issue, as the removal of a watermark can be as straightforward as commenting out a single line of code. 
% %To prevent untrustworthy users from evading the watermark embedding process, existing research such as Stable Signature \cite{fernandez2023stable} and FSwatermark \cite{xiong2023flexible} has embedded watermarks within model components.
% Finally, robustness is a great concern when considering quite diverse adversaries in the model distribution scenarios. 
% Recent works \cite{an2024benchmarking} have showed that existing schemes fail in withstanding reconstructive attacks \cite{zhao2023invisible} and adaptive adversarial sample attacks \cite{jiang2023evading}.
% Therefore, finding out a watermarking solution to ensuring stealthy transfer-ability while considering threats from adversaries has an urgent demand.  \yj{Divide this paragraph into two: one for constrains and the other for related works.}

% In order to solve the issues above, in this paper we propose a distribution scenario-oriented semantic watermarking of diffusion model  (see Figure 1(c)), namely Watermarked Latent Sampling from Distribution (DistriMark), for secure and unpredictable watermark distribution. \yj{Confusing} The approach transforms multi-bit watermark into pseudo-random latent variables, which ensures that the distributed model with an allocated fixed watermark can embed distinct watermark latent variables when using the model each time. Meanwhile, our scheme also guarantees the uniqueness of watermark verification, embedding distinct watermarks for different users, and makes the watermark embedding sufficiently random and difficult to detect. Considering the security of watermarks, we aim to ensure the watermark embedding cannot be removed in distribution scenarios so that we introduce a lightweight association security mechanism called Latent-VAE Skip-Binder, which is a VAE-based fine-tuning strategy for associating the watermark with the diffusion model. This fine-tuning strategy not only makes watermarked latent variables a prerequisite for model usage, but also avoids a variety of potential threats from malicious users, which guarantees the robustness of the watermark. 

In this work as shown in Figure \ref{fig1}(d), we extend the application of LDM watermarking to model distribution scenarios and propose a secure and efficient watermarking method, named as DistriMark. Considering the watermark injection efficiency, DistriMark is based on the random seed modification schema without any model fine-tuning. To avoid model user bypassing watermark injection, we propose a watermark-network controller module as a security mechanism, which establishes binding association between the VAE network in LDMs and the watermarked initial latent variable. In this way, LDMs can generate expected content only when the watermark is mandatory injected. To reduce the time cost of training the watermark-network controller module, we decouple the watermark injection and the security mechanism, ensuring that fine-tuning VAE only accomplishes the security mechanism without the burden of learning watermark patterns. Furthermore, we propose watermark generation module to transform the watermark into a watermark-specific distribution and obtain a watermarked latent variable through sampling strategy. For watermark verification, the  latent variable obtained by diffusion inversion is compared to the watermark distribution instead of a fixed watermarked variable. 
%Without fine-tuning diffusion model, we use adversarial samples to fine-tune watermark decoder. By implementing this approach, our scheme is able to fix the error of the diffusion inversion, while further improving the robustness of watermarking with adversarial samples. 
This watermark generation and verification strategies not only increases the security of plaintext watermarks, but also makes up the errors caused by diffusion inversion and enhance the robustness against various watermark attacks. 


%First, considering the security concerns related to bypassing the embedding of the watermark, we propose Watermark-Network Controller. The core concept behind this approach is to establish a connection between the model and the watermarked variable, leveraging the controller to enforce the mandatory embedding of the watermark whenever the model is utilized. Second, considering the efficiency issues caused by a large number of users in the model distribution scenario, we decoupled the watermark embedding and security mechanisms, ensuring that fine-tuning the VAE only requires implementing the security mechanism without simultaneously learning the watermark embedding pattern. We proposed a secure watermark distribution meth. The watermark encoder outputs a watermark-specific distribution, and a watermarked latent variable is obtained through sampling. For watermark detection, the watermarked latent variable is obtained through diffusion inversion, and then it is detected whether it belongs to the watermarked distribution. 
% This distribution mode avoids the input of user plaintext. 
%During detection, it is confirmed whether the latent variable belongs to the watermarked distribution. This watermark extraction mode can effectively reduce the error of diffusion inversion, and this verification mode is more robust against various image attacks. Third, considering the various attack methods faced in model distribution, we further propose an adversarial training strategy for watermark decoders. Without fine-tuning diffusion model, we use adversarial samples to fine-tune watermark decoder. By implementing this approach, our scheme is able to fix the error of the diffusion inversion, while further improving the robustness of watermarking with adversarial samples. 

%考虑到模型分发场景中大规模用户造成的效率问题，我们解耦了水印嵌入和安全机制，保证对VAE微调只需要实现安全机制而不需同时学习水印嵌入模式。我们提出了一种安全水印分发方法。通过水印编码器输出水印特定分布并采样获得带水印的隐变量，水印检测通过扩散反演获得带水印的隐变量并检测是否属于带水印的分布。这种分发模式首先避免了用户明文的输入，其次检测时将确认隐变量是否属于带水印的分布，这种水印提取模式能有效减少扩散反演的误差，并且这种验证模式在应对各类图像攻击时更鲁棒。


% The approach transforms multi-bit watermark into pseudo-random latent variables, which ensures that the distributed model with an allocated fixed watermark can embed distinct watermark latent variables when using the model each time. Meanwhile, our scheme also guarantees the uniqueness of watermark verification, embedding distinct watermarks for different users, and makes the watermark embedding sufficiently random and difficult to detect. Considering the security of watermarks, we aim to ensure the watermark embedding cannot be removed in distribution scenarios so that we introduce a lightweight association security mechanism called Latent-VAE Skip-Binder, which is a VAE-based fine-tuning strategy for associating the watermark with the diffusion model. This fine-tuning strategy not only makes watermarked latent variables a prerequisite for model usage, but also avoids a variety of potential threats from malicious users, which guarantees the robustness of the watermark. 

% Moreover, compared with fine-tuning-based watermarking approaches, even though the proposed semantic watermarking method is more robust against a few threats, e.g., model attacks, it may encounter issues of diffusion inversion errors during the verification process, which weakens the accuracy of watermark verification. 
% In order to address the diffusion inversion error issue, we further propose an adversarial training strategy for watermark decoders.
% By implementing this approach, our scheme is able to fix the error of the diffusion inversion, while further improving the robustness of watermarking with adversarial samples. \yj{Reorgnize the above two paragraphs to highlight the main technique novolty targeting on  `security' and `efficiency'.}

% {\color{blue}
% In order to solve the issues above, in this paper we propose a distribution scenario-oriented semantic watermarking of diffusion model. 
% We develop a watermark embedding scheme that transfers multi-bit watermark into pseudo-random latent vector, in order to address the flexibility issue in distribution scenarios. 
% The propose scheme could ensure the model distributing fixed watermark to embed distinct watermark latent vector. 
% Meanwhile, our scheme also guarantees the uniqueness of watermark verification, embedding distinct watermarks for different users, and makes the watermark embedding sufficiently random and difficult to detect. 
% Considering the usability of watermarks, we aim to ensure the watermark embedding cannot be removed in distribution scenarios so that a VAE-based fine-tuning watermark model lightweight association scheme is developed, which employs skip connections to bind the variational autoencoder with watermarked latent variables.
% This fine-tuning scheme not only makes watermarked latent vector a prerequisite for model usage, but also avoids a variety of potential threats from malicious users, e.g., model fine-tuning attacks, which guarantees the robustness of the watermark.

% Moreover, compared with fine-tuning-based watermarks, even though the proposed semantic watermarked latent vector is more robust against a few threats, e.g., model attacks, it may encounter issues of diffusion inversion errors during the verification process, which weakens the accuracy of watermark verification. 
% In order to address the diffusion inversion error issue, we further propose an adversarial training strategy for watermark decoders.
% Without fine-tuning diffusion model, we use adversarial samples to fine-tune watermark decoder. 
% By implementing this approach, our scheme is able to fix the error of the diffusion inversion, while further improving the robustness of watermarking with adversarial samples. 
% }


%下一段介绍模型方法
% 为解决上述问题，本文提出一种面向分发场景的扩散模型的语义水印。 为解决水印在分发场景下的灵活性，我们提出一种将多比特水印转换为伪随机隐向量（latent vector）的水印嵌入方法，方法能够使分发固定水印的模型每次嵌入水印的latent vector不同，同时能够保证水印验证的唯一性，实现为不同用户嵌入不同水印的同时使水印具备不易被发现的随机性。为进一步达到水印在分发场景下不易去除的可用性，我们提出基于VAE微调的水印-模型轻量级关联方法， which employs skip connections to bind the variational autoencoder with watermarked latent variables, 这种微调方法不仅保证模型使用者不能脱离watermarked latent vector正常使用模型，还相比现有微调方法，避免了模型使用者通过模型微调等攻击方式降低水印鲁棒性的影响。与基于finetuning 的水印相比，虽然本文提出的在latent vector中嵌入语义水印的方式在对抗图像攻击、模型攻击等情况下鲁棒性更强，但语义水印在验证过程中存在扩散反演误差，降低水印验证的准确率。为提升水印验证过程的准确率，本文进一步提出对水印解码器的对抗训练策略，在不微调扩散模型的前提下，采用对抗样本对水印解码器进行微调，在修复水印扩散反演的误差同时还进一步提升水印在对抗样本下的鲁棒性。




 %Among them, malicious content or copyright infringement and other behaviors generated by AIGC require corresponding traceability technology. At the same time, as digital assets, models also face problems such as theft and malicious modification.

%然而,扩散模型生成真实描绘的能力可能会被不可信的用户滥用，从而导致深度伪造和在线垃圾邮件的激增。这在社交媒体上已经是一个问题，并导致谷歌等公司宣布他们的图像水印，例如SynthID。另一方面，

% However, the implementation of synthesizing photorealistic contents is encountering threats from being exploited by untrustworthy users, causing numerous offenses, such as deepfakes and online spams \cite{barrett2023identifying}. 
% For instance, Google passively announced their image watermark solution, SynthID, in order to deal with adversarial issues on social media \cite{gowal2023identifying}. 
% Moreover, watermarking is a technical alternative for protecting the copyright of diffusion models \cite{zhao2023recipe}.
% In the scenario of model trading, high-quality diffusion models can be considered intellectual property, as it generally require  meticulously designed deep neural network architectures, large-scale high-quality datasets, and substantial computational resources. 


%However, the capacity for synthesizing photorealistic content may be exploited by untrustworthy users, leading to a surge in deepfakes and online spam. 
%It has become an issue on social media \cite{barrett2023identifying}, leading companies like Google to announce their image watermark, such as SynthID \cite{gowal2023identifying}. 
%On the other hand, high-quality diffusion models requires meticulously designed deep neural network architectures, large-scale high-quality datasets, and substantial computational resources. 
%It should be considered intellectual property. 
%Watermarking can be used to protect the copyright of diffusion models.

%在扩散模型分发场景中，敌手可以轻易地删除后生成水印。开源的 Stable Diffusion就是一个很好的例子，因为删除水印相当于注释掉源代码中的一行。为避免敌手规避水印嵌入过程，已有研究(Stable Signature、FSwatermark)将水印嵌入模型组件中，然而，近期研究已有表明当前SOTA无法抵御重建式水印攻击[A]和自适应对抗样本攻击[B]。


%In the model distribution scenario for latent diffusion models, untrustworthy users can remove post-hoc watermarking trivially. The open-source nature of models like Stable Diffusion \cite{rombach2022high} exemplifies this issue, as the removal of a watermark can be as straightforward as commenting out a single line of code. To prevent untrustworthy users from evading the watermark embedding process, existing research such as Stable Signature \cite{fernandez2023stable} and FSwatermark \cite{xiong2023flexible} has embedded watermarks within model components. %However, recent studies have shown that state-of-the-art methods are unable to withstand reconstructive attacks \cite{zhao2023invisible} and adaptive adversarial sample attacks \cite{jiang2023evading}.

%为了解决上述问题并实现鲁棒的水印嵌入和高质量的图像,我们提出了一种在模型分发场景下的多比特语义水印。具体来说该方法通过训练编码器-解码器模型，建立了初始潜变量和水印信息的统一表示。语义水印通过编码器嵌入到潜空间中，并微妙地影响扩散模型的采样过程。通过扩散反演和消息解码器，可以从带水印的图像中恢复消息。为防止用户在图像生成过程中规避水印嵌入，该方法的安全机制包括快速微调VAE-解码器，其中使用跳跃连接将变分自编码器与带水印的潜变量绑定。这种方法有几个优点，已有研究表明本方法基于的语义水印鲁棒性对比过去后处理水印有明显鲁棒性优势。而且它不需要对图像进行后处理，这使得水印在计算上更轻巧。提出的安全机制可以避免用户逃避水印嵌入过程，并帮助模型提供商监控用户是否负责任地使用。
% To address the aforementioned issues and achieve robust watermarking and high-quality images, we propose a multi-bit semantic watermarking scheme for model distribution scenarios. 
% Specifically, the method establishes a unified representation of the initial latent variables as well as the messages through training an encoder-decoder model. 
% The semantic watermark is embedded into latent space through encoder and subtly influences the sampling process of latent diffusion models. 
% Messages are restored from watermarked images by diffusion inversion and message-decoder. 
% To prevent users from evading watermark embedding during image generation, the security mechanism involves a rapid fine-tuning of the VAE-Decoder, which employs skip connections to bind the variational autoencoder with watermarked latent variables. 
% Comparing to traditional post-processing watermarks, semantic watermarking has been demonstrated to have a higher-level capability in robustness \cite{wen2024tree,zhang2024robust,jiang2023evading}.
% It also reduces the computation cost due to the elimination of the needs for image post-processing \cite{yu2020responsible,lin2024cyclegan}. 
% Model producers deploy the model to distinct model users with a unique watermark, so that the proposed security mechanism monitors whether the users use the model in a responsible manner. 
%There are several advantages to this approach. 
%Existing research \cite{wen2024tree,zhang2024robust,jiang2023evading} indicates that the semantic watermarking exhibits significant robustness compared to traditional post-processing watermarks. 
%Moreover, it eliminates the need for post-processing of images, making the watermark computationally lighter \cite{yu2020responsible,lin2024cyclegan}. 
%Model producers could deploy their models to different model users with a unique watermark, and monitor that they are used in a responsible manner through the proposed security mechanism.

%我们所提出的方法在模型分发场景的应用如图所示，模型生产者(model producer)在训练好扩散模型和水印组件后，通过微调变分自编码器将消息编码器(Message Encoder)输出的隐变量与模型组件绑定。模型生产者向模型使用者分发Message Encoder、U-net、VAE-Decoder以提供生成式模型服务。




% The method we propose for model distribution scenarios is depicted in Figure \ref{fig1}. 
% After training latent diffusion models and the watermark components, the model producer fine-tunes the VAE-Decoder to bind the latent variables, which are embedded with the message of the specific model user, with the model components. 
% Then, the model producer distributes the message encoder, U-Net and VAE-Decoder to model users to provide generative model services. 
% When suspicious malicious images generated by models or pirated copyrighted images appear on art platforms, news media or other sharing platforms, model producers can trace illegal usage or copyright infringement involving untrustworthy users by extracting watermark information embedded in the generated images.


\begin{figure*}[t]
\centering
\includegraphics[width=2\columnwidth]{2.pdf} % 
\caption{Framework of the proposed DistriMark watermarking scheme for Latent Diffusion Model.}
\label{fig2}
\end{figure*}


The main contributions are summarized as follows:
(1) We propose new security mechanism to prevent watermark leakage and watermark escape in the model distribution scenarios by pseudo-random latent variable transformation and VAE-based fine-tuning strategy. We consider watermark randomness and watermark-model association as two constraints for enhancing watermarking security, which sheds new light on the real-world application of diffusion model watermarking.
(2) We propose a novel model distribution scenario-oriented watermarking schema for LDMs. By injecting multi-bit watermarks into the initial latent variables and fixing the verification errors via watermark distribution verification and adversarial training strategy, our schema achieves both robustness and flexibility compared with existing fine-tuning and random seed-based watermarks.
(3) DistriMark shows superior performance on effectiveness and robustness compared with existing six baselines over ten image processing attacks, challenging adaptive adversarial sample attacks and reconstructive attacks. DistriMark is more secure against watermark escape and leakage compared with existing random seed modification watermarks in the distribution scenarios.


%(1) We propose a novel watermark distribution scheme, Watermarked Latent Sampling from Distribution (DistriMark).
% (1) We propose a novel multi-bit semantic watermark network for latent diffusion models in the model distribution scenario. 
% Our scheme has been proved that it can defend the reconstructive attacks and adaptive black-box adversarial sample attacks.
%The method is capable of withstanding the reconstructive attacks \cite{zhao2023invisible} and adaptive black-box adversarial sample attacks \cite{jiang2023evading}.
%(2) We first propose Latent-VAE Skip-Binder, a model lightweight association security mechanism for the security of watermark embedding. 
%(3) Our experiment evaluation has completed comparisons between our scheme and state-of-the-art watermarking techniques, which demonstrates that the proposed scheme has merits in security, efficiency, and accuracy. 
