\documentclass{article}

% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2024


% Note: For the preprint, we modified neurips_2024.sty to remove "Preprint. Under review.", per a paranoid interpretation of NeurIPS call for papers  (https://neurips.cc/Conferences/2024/CallForPapers) and arXiv instructions (https://trevorcampbell.me/html/arxiv.html).
\usepackage[preprint]{neurips_2024}

% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
%     \usepackage[preprint]{neurips_2024}


% to compile a camera-ready version, add the [final] option, e.g.:
%     \usepackage[final]{neurips_2024}


% to avoid loading the natbib package, add option nonatbib:
%    \usepackage[nonatbib]{neurips_2024}


\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors
\usepackage{colortbl}       % table cell colors
\usepackage{array}          % breaking cell titles to multiple rows

% Author added packages:
\usepackage{orcidlink}
\usepackage{amsmath}
\usepackage{tikz}
\usetikzlibrary{shadows.blur}
\usetikzlibrary{arrows.meta}
\usetikzlibrary{shapes.geometric, positioning, fit}
\usepackage{multirow}
\usepackage{multicol}
\usepackage{siunitx}
\sisetup{
    separate-uncertainty = true,      % Enables the "value ± error" format
    round-mode = uncertainty,       % Rounds numbers to a specified number of figures
    round-precision = 2,        % Sets the precision to 3 significant figures
    table-align-uncertainty = true
}
\usepackage{pifont}         % For check and cross symbols
\usepackage{graphicx}

% Author added defs, tikzstyles, saveboxes, etc.:
\def\gridstep{0.5}
\definecolor{beaublue}{rgb}{0.74, 0.83, 0.9}
\definecolor{paleyellow}{RGB}{255, 255, 210}
\definecolor{palegreen}{RGB}{210, 255, 210}
\newcommand{\yesmark}{\textcolor{black}{\ding{51}}}    % Black checkmark
\newcommand{\nomark}{\textcolor{black}{\ding{55}}}     % Gray cross
\newcommand{\cmark}{\textcolor{blue}{\ding{51}}}    % Green checkmark
\newcommand{\xmark}{\textcolor{red}{\ding{55}}}     % Red cross
\newcommand{\dmark}{{$-$}}   % Minus
\newcommand{\confmark}{\textcolor{lightgray}{\rule{1.3ex}{1.3ex}}} % Light gray solid square
\newcommand{\meanmark}{{\rule[0.5ex]{0.8em}{0.8pt}}} % Thick, long black dash
\newcommand{\barconfmark}{{\vrule height 0.5em width 0.8pt depth 0pt}} % Thick, short vertical black dash
\tikzstyle{finely dashed}=[dash pattern=on 1.5pt off 1.5pt]

\newsavebox{\bluepixel}
\sbox{\bluepixel}{\begin{tikzpicture}\draw[beaublue!75!black, fill=beaublue] rectangle (2mm, 2mm);\end{tikzpicture}}

\newsavebox{\yellowpixel}
\sbox{\yellowpixel}{\begin{tikzpicture}\draw[fill=paleyellow] rectangle (2mm, 2mm);\end{tikzpicture}}

\newsavebox{\greenpixel}
\sbox{\greenpixel}{\begin{tikzpicture}\draw[fill=palegreen,finely dashed] rectangle (2mm, 2mm);\end{tikzpicture}}

\title{Per-channel autoregressive linear prediction padding in tiled CNN processing of 2D spatial data}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.

\author{%
  Olli~Niemitalo\orcidlink{0000-0002-3467-8341}\\
  HAMK Häme University of Applied Sciences\\
  Hämeenlinna, Finland\\
  \texttt{Olli.Niemitalo@hamk.fi}\\
  \And
  Otto~Rosenberg\orcidlink{0009-0006-4742-1605}\\
  HAMK Häme University of Applied Sciences\\
  Hämeenlinna, Finland\\
  \texttt{Otto.Rosenberg@hamk.fi}\\
  \And
  Nathaniel~Narra\orcidlink{0000-0003-1618-5444}\\
  HAMK Häme University of Applied Sciences\\
  Hämeenlinna, Finland\\
  \texttt{Nathaniel.Narra@hamk.fi}\\
  \And
  Olli~Koskela\orcidlink{0000-0002-3424-9969}\\
  HAMK Häme University of Applied Sciences\\
  Hämeenlinna, Finland\\
  \texttt{Olli.Koskela@hamk.fi}\\
  \And
  Iivari~Kunttu\orcidlink{0000-0002-7460-6422}\\
  HAMK Häme University of Applied Sciences\\
  Hämeenlinna, Finland\\
  \texttt{Iivari.Kunttu@hamk.fi}\\
}


\begin{document}

\maketitle

\begin{abstract}
We present linear prediction as a differentiable padding method. For each channel, a stochastic autoregressive linear model is fitted to the padding input by minimizing its noise terms in the least-squares sense. The padding is formed from the expected values of the autoregressive model given the known pixels. We trained the convolutional RVSR super-resolution model from scratch on satellite image data, using different padding methods. Linear prediction padding slightly reduced the mean square super-resolution error compared to zero and replication padding, with a moderate increase in time cost. Linear prediction padding better approximated satellite image data and RVSR feature map data. With zero padding, RVSR appeared to use more of its capacity to compensate for the high approximation error. Cropping the network output by a few pixels reduced the super-resolution error and the effect of the choice of padding method on the error, favoring output cropping with the faster replication and zero padding methods, for the studied workload.\end{abstract}

\section{Introduction}

\begin{figure}[!h]
    \centering
    \includegraphics[width=1.0\linewidth]{fig_lp6x7.pdf}
    \caption{Satellite images padded using our linear prediction padding method (variant \texttt{lp6x7}).}
    \label{fig:lp6x7}
\end{figure}

Geospatial rasters and other extensive spatial data can be processed in tiles (patches) to work around memory limitations. The results are seamless if all whole-pixel shifts of the tiling grid result in the same stitched results. A convolutional neural network (CNN) consisting of valid convolutions and pointwise operations is equivariant to whole-pixel shifts. In such \textit{shift equivariant} CNN-based processing, each input tile must cover the receptive fields of the output pixels, \textit{i.e.} input tiles must be overlapped. This wastefully repeats computations. In deep CNNs, the receptive fields may be thousands of pixels wide (\citealt{araujo2019computing}), exacerbating the problem.

\newcommand{\picneighborhood}[5]{
\begin{tikzpicture}
\foreach \x/\y/\nodelabel/\nodesubscript/\nodecolor/\nodeoption in {#1} {
    \draw[scale=\gridstep, line width=0.5, fill=\nodecolor, \nodeoption] (\x, \y) rectangle +(1, 1);
    \draw[scale=\gridstep, shift={(0.5,0.28)}] (\x,\y) node[anchor=base] {\nodelabel};
}
\draw[scale=\gridstep, line width=1.5pt] {#2};
\draw[scale=\gridstep, line width=0, draw=none] {#3}; % invisible bounding box
\draw[scale=\gridstep, shift={{#4}}] (0.5, 0.5) node[anchor=base] {#5};
\end{tikzpicture}
}

\newcommand{\picneighborhoodgrid}[8]{
\foreach \x/\y/\xcount/\ycount/\nodecolor/\nodeoption/\shade in {#1} {
    \ifnum\shade=1
        \filldraw[rounded corners,draw=none,fill=none,blur shadow={shadow opacity=10,shadow blur steps=4,shadow xshift=0pt,shadow yshift=0pt},shift={(\x*#6, \y*#6)}] (-0.0625, -0.0625) rectangle +(\xcount*#6+0.125,\ycount*#6+0.125);
    \fi
}
\foreach \x/\y/\xcount/\ycount/\nodecolor/\nodeoption/\shade in {#1} {
    \draw[scale={#6},step=1.0,fill=\nodecolor,draw=none,shift={(\x, \y)}] rectangle (\xcount,\ycount);
    \draw[scale={#6},step=1.0,line width=#7,fill=none,shift={(\x, \y)},line cap=round,\nodeoption] (0, 0) grid (\xcount,\ycount);
}
\draw[scale={#6}, line width={#8}] {#2};
\draw[scale={#6}, line width=0, draw=none] {#3}; % invisible bounding box
\draw[scale={#6}, shift={{#4}}] (0.5, 0.5) node[anchor=base] {#5};
}

\begin{figure}[!h]
\centering
\begin{tikzpicture}
\begin{scope}[scale=1.5]
\picneighborhoodgrid{%
{0/0/9/9/white/white!75!black/1},% data
%{6/6/3/3/beaublue/beaublue!75!black/0},% kernel
%{6/0/3/3/beaublue/beaublue!75!black/0},% kernel
%{0/0/3/3/beaublue/beaublue!75!black/0},% kernel
{0/6/3/3/beaublue/beaublue!75!black/0}% kernel
}
{(0, 0)--(9, 0)--(9, 9)--(0, 9)--cycle}% black line
{}% invisible bounding box
{(4, 3.75)}{Input}% text
{0.25}{0.5}{1}%scale and linewidths
\draw[scale=0.25,step=1.0,fill=none,dashed,shift={(1, 1)}] rectangle (7,7);
\begin{scope}[shift={(12.5*0.25, 1*0.25)}]
\picneighborhoodgrid{%
{0/0/7/7/white/white!75!black/1},% data
{0/6/1/1/beaublue/beaublue!75!black/0}% kernel
}
{(0, 0)--(7, 0)--(7, 7)--(0, 7)--cycle}% black line
{}% invisible bounding box
{(3, 2.75)}{Output}% text
{0.25}{0.5}{1}%scale and linewidths
\end{scope}
\draw[ultra thick,arrows = {-Stealth[inset=0pt, angle=90:8pt]}] (9*0.25, 4.5*0.25) -- (12.5*0.25, 4.5*0.25);
\draw[draw=beaublue!80!black] (0.75, 2.25) -- (3.375, 2);
\draw[draw=beaublue!80!black] (0.75, 1.5) -- (3.375, 1.75);
\draw[draw=beaublue!80!black] (0, 2.25) -- (3.125, 2);
\draw[draw=beaublue!80!black] (0, 1.5) -- (3.125, 1.75);
\node[anchor=north] at (2.625, 1.125) {\begin{tabular}{c}Valid\\convo-\\lution\end{tabular}};
\end{scope}
\end{tikzpicture}
\caption{Valid convolution with a $3{\times3}$ kernel with origin in the middle erodes data spatially by a one-pixel-thick layer at each image edge. The receptive field of a single output pixel (\usebox{\bluepixel}) is illustrated.}
\label{fig:validConvSpatialReduction}
\end{figure}

Spatial reduction (see Fig.~\ref{fig:validConvSpatialReduction}) in deep CNNs is commonly compensated for by padding the input of each spatial convolution, with zeros in the case of the typically used \textit{zero padding} (\texttt{zero} for brevity) or with the value of the nearest input pixel in \textit{replication padding} (\texttt{repl}). In the less used polynomial \textit{extrapolation padding} (\texttt{extr}$N$), a Lagrange polynomial of a degree $N-1$ is fitted to the $N$ nearest input pixels from the same row or column, and the padding is sampled from the extrapolated polynomial. \texttt{extr0} is equivalent to \texttt{zero} and \texttt{extr1} to \texttt{repl}.

An ideal padding method would exactly predict the spatial data outside the padding input view. This is not possible to do for data coming from an effectively random process, such as natural data or a CNN feature map derived from it. Using padding increases processing error towards tile edges (\citealt{huang2018tiling}) and will generally break CNN shift equivariance. Center-cropping the CNN output reduces the error (\citealt{huang2018tiling}) and thus indirectly improves shift equivariance. The strength of the receptive fields of output neurons typically decay super-exponentially with distance to their center (\citealt{luo2016understanding}), meaning that an output center crop less than the radius of the theoretical receptive field could reduce the processing error close to that of a valid-convolution CNN.

In this work we introduce \textit{linear prediction padding} (abbreviated \texttt{lp}, see Fig.~\ref{fig:lp6x7}) and evaluate the performance of tiled CNN super-resolution employing padding methods \texttt{lp}, \texttt{zero}, \texttt{repl}, and 
\texttt{extr}.

\section{Linear prediction padding}
Linear prediction is a method for recursively predicting data using nearby known or already predicted data as input (for an introduction, see \citealt{makhoul1975linear} for the 1D case and \citealt{weinlich2022compression} for the 2D case, both very approachable texts). Linear prediction is closely related to stochastic autoregressive (AR) processes. In the 2D case, we can model single-channel image or feature map data $I$, assumed real-valued, by a zero-mean stationary process $\hat I$:
\begin{equation}
\hat I_{(y,x) + h_0} = \sum_{i=1}^{P} a_i \hat I_{(y,x) + h_i}  + \varepsilon_{(y, x) + h_0},
\label{eq:arProcess}
\end{equation}
where $(y, x)$ are integer spatial coordinates, $a_i$ are coefficients that parameterize the process, $\varepsilon$ is zero-mean independent and identically distributed (IID) noise, and the \textit{extended neighborhood} $h$ is a list of 2D coordinate offsets (relative to a shared origin), first the pixel of interest $\hat I_{(y,x)+h_0}$, followed by its \textit{neighborhood} $\hat I_{(y,x)+h_{1\ldots P}}$ in any order. Each pixel depends linearly on $P$ neighbors (see Fig.~\ref{fig:neighborhoods}). Our approach to linear prediction padding is to least-squares (LS) fit the AR model (Eq.~\ref{eq:arProcess}) to actual image data $I$ and to compute the padding as conditional expectancies assuming that the data obeys the model, $\hat I = I$.

\begin{figure}[!h]
\centering
\begin{tikzpicture}
\picneighborhoodgrid{%
{0/0/1/1/palegreen/dashed/1},% predicted
{0/1/1/1/paleyellow//1}% predictor
}
{}% black line
{{(0, -1.5)--(0, 0)}}% invisible bounding box
{(0, -1.5)}{$1{\times}1$}%label
{\gridstep*0.75}{0.5}{1}%scale and linewidths
\end{tikzpicture}
\begin{tikzpicture}
\picneighborhoodgrid{%
{0/0/1/1/palegreen/dashed/1},% predicted
{0/1/1/2/paleyellow//1}% predictor
}
{}% black line
{{(0, -1.5)--(0, 0)}}% invisible bounding box
{(0, -1.5)}{$2{\times}1$}%
{\gridstep*0.75}{0.5}{1}%scale and linewidths
\end{tikzpicture}
\begin{tikzpicture}
\picneighborhoodgrid{%
{0/0/1/1/palegreen/dashed/1},% predicted
{-1/1/3/2/paleyellow//1}% predictor
}
{}% black line
{{(0, -1.5)--(0, 0)}}% invisible bounding box
{(0, -1.5)}{$2{\times}3$}%
{\gridstep*0.75}{0.5}{1}%scale and linewidths
\end{tikzpicture}
\begin{tikzpicture}
\picneighborhoodgrid{%
{0/0/1/1/palegreen/dashed/1},% predicted
{-2/1/5/2/paleyellow//1}% predictor
}
{}% black line
{{(0, -1.5)--(0, 0)}}% invisible bounding box
{(0, -1.5)}{$2{\times}5$}%
{\gridstep*0.75}{0.5}{1}%scale and linewidths
\end{tikzpicture}
\begin{tikzpicture}
\picneighborhoodgrid{%
{0/0/1/1/palegreen/dashed/1},% predicted
{-1/1/3/3/paleyellow//1}% predictor
}
{}% black line
{{(0, -1.5)--(0, 0)}}% invisible bounding box
{(0, -1.5)}{$3{\times}3$}%
{\gridstep*0.75}{0.5}{1}%scale and linewidths
\end{tikzpicture}
\caption{Illustration of some rectangular 2D neighborhoods (with pixels \usebox{\yellowpixel}) next to the pixel of interest (\usebox{\greenpixel}), defining the linear dependency structure of a downwards causal AR model. The extended neighborhood $1{\times}1$ can be defined by $h = [(1, 0), (0, 0)]$ and $2{\times}1$ by $h = [(2, 0), (0, 0), (1, 0)]$.}
\label{fig:neighborhoods}
\end{figure}

The LS fit is obtained by minimizing the mean square prediction error (MSE), with residual noise as the error:
\begin{equation}
\begin{gathered}
\varepsilon_{(y, x) + h_0} = \sum_{i=1}^{P} a_i I_{(y,x) + h_i} - I_{(y,x) + h_0},\quad\text{MSE} = {\textstyle\frac{1}{|S|}}\hspace{-0.75em}\sum_{(y,x)\in S}\hspace{-0.75em}\Big(\sum_{i=1}^{P} a_i I_{(y,x) + h_i} - I_{(y,x) + h_0}\Big)^2,\\
S = \left\{(y,x)\,|\,(y,x) + h_i \in K\text{ for all } i\in[0, P]\right\}
\end{gathered}
\label{eq:mse}
\end{equation}
where $S$ is the set of coordinates that keeps all pixel accesses in the sums within the set of input image pixel coordinates $K$ (see the left side of Fig.~\ref{fig:cornerHandling}).

The noise, being zero-mean by definition, does not contribute to the AR process expected value:
\begin{equation}
\begin{split}
\operatorname{E}\big(\hat I_{(y,x) + h_0}\big)
= &\operatorname{E}\Bigg(\sum_{i=1}^{P} a_i \hat I_{(y,x) + h_i}  + \varepsilon_{(y, x) + h_0}\Bigg)
%= \sum_{i=1}^{P} \operatorname{E}\big(a_i \hat I_{(y,x) + h_i}\big) + \operatorname{E}\big(\varepsilon_{(y, x) + h_0}\big)\\
= \sum_{i=1}^{P} a_i \operatorname{E}\big(\hat I_{(y,x) + h_i}\big) + 0.
\label{eq:arProcessExpectedUnconditional}
\end{split}
\end{equation}
We can recursively calculate conditional expectances (the padding) further away from $K$ using both the known pixels (the input image) and any already calculated expectances (the nascent padding):
\begin{equation}
\begin{gathered}
\operatorname{E}\big(\hat I_{(y,x) + h_0}\,\big|\,\hat I_{(y, x)\in K}\big) = \sum_{i=1}^{P} a_i\begin{cases}
\hat I_{(y,x) + h_i}&\text{if\,}{\scriptstyle(y,x) + h_i}\in K,\\
\operatorname{E}\big(\hat I_{(y,x) + h_i}\,\big|\,\hat I_{(y, x)\in K}\big)&\text{otherwise}.
\end{cases}
\end{gathered}
\label{eq:arProcessReflectanceRecursion}
\end{equation}

\begin{figure}[!h]
\centering
\begin{tikzpicture}
\begin{scope}[scale=0.832]
\begin{scope}[shift={(3*0.375, 3*0.375)}]
\begin{scope}[rotate=0*90, shift={(-2, -2)}]
\picneighborhoodgrid{%
{0/0/16/16/white/lightgray/1},% data
{2/0/1/1/palegreen/finely dashed/0},% predicted
{0/1/5/4/paleyellow//0},% predictor
{13/0/1/1/palegreen/finely dashed/0},% predicted
{11/1/5/4/paleyellow//0},% predictor
{2/11/1/1/palegreen/finely dashed/0},% predicted
{0/12/5/4/paleyellow//0},% predictor
{13/11/1/1/palegreen/finely dashed/0},% predicted
{11/12/5/4/paleyellow//0}% predictor
}
{(0, 0)--(16, 0)--(16, 16)--(0, 16)--cycle}% black line
{}% invisible bounding box
{(0, -0)}{}% text
{0.25}{0.25}{0.5}%scale and linewidths
\end{scope}
\end{scope}
\end{scope}
\end{tikzpicture}
\hspace{1.3cm}
\begin{tikzpicture}
\picneighborhoodgrid{%
{-2/0/2/1/palegreen/dashed/1},% predicted
{-2/1/5/4/paleyellow//1}% predictor
}
{(-2, 5.25)--(-2, 1)--(3.25, 1)}% black line
{{(0, 0)--(0, -1.5)}}% invisible bounding box
{(3.75, 2)}{$\ldots$}%
{\gridstep*0.75}{0.5}{1}%scale and linewidths
\end{tikzpicture}
\begin{tikzpicture}
\picneighborhoodgrid{%
{0/0/1/1/palegreen/dashed/1},% predicted
{-2/1/5/4/paleyellow//1}% predictor
}
{(-2.25, 1)--(3.25, 1)}% black line
{{(0, 0)--(0, -1.5)}}% invisible bounding box
{(3.75, 2)}{$\ldots$}%
{\gridstep*0.75}{0.5}{1}%scale and linewidths
\end{tikzpicture}
\begin{tikzpicture}
\picneighborhoodgrid{%
{1/0/2/1/palegreen/dashed/1},% predicted
{-2/1/5/4/paleyellow//1}% predictor
}
{(-2.25, 1)--(3, 1)--(3, 5.25)}% black line
{{(0, 0)--(0, -1.5)}}% invisible bounding box
{(0, 0)}{}%
{\gridstep*0.75}{0.5}{1}%scale and linewidths
\end{tikzpicture}
\caption{Downwards linear prediction padding with a $4{\times}5$ neighborhood --- Left: predicted (\usebox{\greenpixel}) and neighborhood pixels (\usebox{\yellowpixel}) at the corners of the rectangular area of coordinates over which MSE is calculated during fitting. Right: corner handling prevents narrowing of the recursive prediction front.}
\label{fig:cornerHandling}
\end{figure}

We use rotated extended neighborhoods to pad in different directions, and adjust the extended neighborhoods (see the right side of Fig.~\ref{fig:cornerHandling}) when padding near the corners. We pad channels of multi-channel data separately. Before padding, we make the data zero-mean by mean subtraction, which we found necessary for numerically stable Cholesky solves of AR coefficients and to meet the assumption of a zero-mean AR process. We add the mean back after padding. Depending on the extended neighborhood shape, we use a method based on covariance or a method based on autocorrelation.

\subsection {Covariance method}
For one ($P=1$) and two-pixel ($P=2$) neighborhoods, the error to minimize can be expressed using the shorthand $r_{ij}$ for the means of products that are elements of a \textit{covariance matrix} $r$:
\begin{align}
&\begin{aligned}P{=}1:\quad\text{MSE} =& {\textstyle\frac{1}{|S|}}\hspace{-0.75em}\sum_{(y,x)\in S}\hspace{-0.75em}\big(a_1 I_{(y,x) + h_1} - I_{(y,x) + h_0} \big)^2
%=&{\textstyle\frac{1}{|S|}}\hspace{-0.75em}\sum_{(y,x)\in S}\hspace{-0.75em}\big(a_1^2 I_{(y,x) + h_1}^2 - 2 a_1 I_{(y,x) + h_0} I_{(y,x) + h_1} + I_{(y,x) + h_0}^2\big)\\
%=&a_1^2 {\textstyle\frac{1}{|S|}}\hspace{-0.75em}\sum_{(y,x)\in S}\hspace{-0.75em} I_{(y,x) + h_1}^2 - 2 a_1 {\textstyle\frac{1}{|S|}}\hspace{-0.75em}\sum_{(y,x)\in S}\hspace{-0.75em} I_{(y,x) + h_0} I_{(y,x) + h_1} + {\textstyle\frac{1}{|S|}}\hspace{-0.75em}\sum_{(y,x)\in S}\hspace{-0.75em}I_{(y,x) + h_0}^2\\
= a_1^2 r_{11} - 2 a_1 r_{01} + r_{00}\\
P{=}2:\quad\text{MSE} =& {\textstyle\frac{1}{|S|}}\hspace{-0.75em}\sum_{(y,x)\in S}\hspace{-0.75em}\big(a_1 I_{(y,x) + h_1} + a_2 I_{(y,x) + h_2} - I_{(y,x) + h_0}\big)^2\\
%=&{\textstyle\frac{1}{|S|}}\hspace{-0.75em}\sum_{(y,x)\in S}\hspace{-0.75em}\big(a_1^2 I_{(y,x) + h_1}^2 + 2 a_1 a_2 I_{(y,x) + h_1} I_{(y,x) + h_2} \\&- 2 a_1 I_{(y,x) + h_0} I_{(y,x) + h_1} + a_2^2 I_{(y,x) + h_2}^2 \\&- 2 a_2 I_{(y,x) + h_0} I_{(y,x) + h_2} + I_{(y,x)}^2\big)\\
=&\,a_1^2 r_{11} + 2 a_1 a_2 r_{12} - 2 a_1 r_{01} + a_2^2 r_{22} - 2 a_2 r_{02} + r_{00},
\end{aligned}\\
&\text{where } r_{ij} = {\textstyle\frac{1}{|S|}}\hspace{-0.75em}\sum_{(y,x)\in S}\hspace{-0.75em}{I_{(y,x) + h_i}I_{(y,x) + h_j}},\quad r_{ij} = r_{ji}.
\label{eq:shorthandCovariance}
\end{align}
The LS solutions can be found by solving what are known as the \textit{normal equations}:
\begin{equation}
\begin{aligned}
P{=}1:\quad&\hphantom{\Bigg\{}\tfrac{\partial\text{MSE}}{\partial a_1} = 2 a_1 r_{11} - 2 r_{01} = 0\quad&&\Rightarrow\quad \hphantom{\Bigg\{}a_1 = \tfrac{r_{01}}{r_{11}}\\
P{=}2:\quad&\begin{cases}   
\frac{\partial\text{MSE}}{\partial a_1} = 2 a_1 r_{11} + 2 a_2 r_{12} - 2 r_{01} = 0\\[3pt]
\frac{\partial\text{MSE}}{\partial a_2} = 2 a_1 r_{12} + 2 a_2 r_{22} - 2 r_{02} = 0
\end{cases}&&\Rightarrow\quad\begin{cases}
a_1 = \tfrac{r_{01} r_{22} - r_{02} r_{12}}{r_{11} r_{22} - r_{12}^2}\\[10pt]
a_2 = \tfrac{r_{02} r_{11} - r_{01} r_{12}}{r_{11} r_{22} - r_{12}^2}.
\end{cases}
\end{aligned}
\label{eq:findCoefDirect}
\end{equation}
In implementation, we used a safe version of the division operator and its derivatives that replaces infinities with zeros in results. For any $P$, the normal equations involve the covariance matrix $r$:
\begin{equation}
\left[
    \begin{array}{cccc}
      r_{11} & r_{12} & \ldots & r_{1P}\\
      r_{12} & r_{22} & \ldots & r_{2P}\\
      \vdots & \vdots & \ddots & \vdots\\
      r_{1P} & r_{2P} & \ldots & r_{PP}
    \end{array}
  \right] \left[
    \begin{array}{c}
      a_{1}\\
      a_{2}\\
      \vdots\\
      a_{P}
    \end{array}
  \right] = \left[
    \begin{array}{c}
      r_{01}\\
      r_{02}\\
      \vdots\\
      r_{0P}
    \end{array}
  \right].
  \label{eq:findCoefMatrix}
\end{equation}
The approach is known as the \textit{covariance method}. We implemented it only for the neighborhoods $1{\times}1$ (method \texttt{lp1x1cs} where \texttt{cs} stands for covariance, stabilized) and $2{\times}1$ (\texttt{lp2x1cs}), using Eq.~\ref{eq:findCoefDirect} and stabilization of the effectively 1D linear predictors by reciprocating the magnitude of each below-unity-magnitude root of the AR process characteristic polynomial of lag operator $B$ and by obtaining the coefficients from the expanded manipulated polynomial (see Appendix~\ref{ap:stabilization} for details):
\begin{equation}
1{\times}1:\quad 1 - a_1 B,\quad\quad 2{\times}1:\quad 1 - a_1 B - a_2 B^2.
\label{eq:characteristicPolynomials}
\end{equation}

\subsection{Autocorrelation method with Tukey window and zero padding}

For methods \texttt{lp2x1}, \texttt{lp2x3}, \texttt{lp2x5}, \texttt{lp3x3}, \texttt{lp4x5}, and \texttt{lp6x7}, named by the height${\times}$width of the neighborhood in vertical padding, we redefined $r_{ij}$ as normalized 
 $(N_y, N_x)$-periodic autocorrelation:
\begin{equation}
r_{ij} = \frac{R_{h_i - h_j}}{N_y N_x},\quad R_{(\Delta y, \Delta x)} = \sum_{y=0}^{N_y-1} \sum_{x=0}^{N_x-1} I_{(y, x)}I_{\big((y-\Delta y)\operatorname{mod}N_y, (x-\Delta x)\operatorname{mod}N_x\big)}.
\label{eq:autocorrelation}
\end{equation}
To reduce periodization artifacts, for use in Eq.~\ref{eq:autocorrelation}, we multiplied the image horizontally and vertically by a Tukey window with a constant segment length of 50\% and zero padded it sufficiently to prevent wraparound. For \texttt{lp2x5}, \texttt{lp3x3}, \texttt{lp4x5}, and \texttt{lp6x7} we accelerated calculation of $R$ using fast Fourier transforms (FFTs) taking advantage of the Wiener--Khinchin theorem, $R = \operatorname{IDFT2}\big(|\operatorname{DFT2}(I)|^2\big)$ for our purposes, where $\operatorname{DFT2}$ and $\operatorname{IDFT2}$ are the 2D discrete Fourier transform and its inverse.

\subsection{Implementation}

We implemented linear prediction padding in the JAX framework (\citealt{jax2018github}) and solved Eq.~\ref{eq:findCoefMatrix} using a differentiable Cholesky solver from Lineax (\citealt{lineax2023}), stabilizing solves by adding a small constant $10^{-7}$ to diagonal elements of the covariance matrix, \textit{i.e.} by ridge regression.

While not dictated by the theory, we constrained our implementation to rectangular neighborhoods (as in Fig.~\ref{fig:neighborhoods}) with the predicted pixel located adjacent to and centered on the neighborhood with the exception of corner padding (see Fig.~\ref{fig:cornerHandling}). Our implementation benefited from the capability of JAX to 1) \textit{scan} the recursion for paddings larger than a 1-pixel layer, 2) to \textit{vmap} (vectorizing map) for parallelization of the padding front and for calculations over axes of rectangular unions of extended neighborhoods including corner handling variants, and 3) to fuse convolution with covariance statistics collection. As far as the authors are aware, such automated fusing would not take place in PyTorch that at present only offers an optimized computational kernel for zero padding.

\section{Evaluation in RVSR super-resolution}
\label{se:superResolution}

\begin{figure}
\centering
\tikzset{
    io/.style={draw=none, line width=0, inner sep=0pt, outer sep=0pt},
    section/.style={draw=none, blur shadow={shadow opacity=0}},
    conv/.style={rectangle, draw, rounded corners, minimum width=1cm, minimum height=0.5cm, fill=yellow!30, rotate=90, blur shadow={shadow opacity=50,shadow blur steps=4,shadow xshift=0pt,shadow yshift=0pt}},
    bilinear/.style={rectangle, draw, rounded corners, minimum width=1cm, minimum height=0.5cm, fill=teal!10!white, blur shadow={shadow opacity=50,shadow blur steps=4,shadow xshift=0pt,shadow yshift=0pt}},
    repconv/.style={rectangle, draw, rounded corners, minimum width=1cm, minimum height=0.5cm, fill=gray!30, rotate=90, blur shadow={shadow opacity=50,shadow blur steps=4,shadow xshift=0pt,shadow yshift=0pt}},
    se/.style={rectangle, draw, rounded corners, minimum width=1cm, minimum height=0.5cm, fill=gray!20, rotate=90, blur shadow={shadow opacity=50,shadow blur steps=4,shadow xshift=0pt,shadow yshift=0pt}},
    gelu/.style={rectangle, draw, rounded corners, minimum width=1cm, minimum height=0.5cm, fill=orange!30, rotate=90, blur shadow={shadow opacity=50,shadow blur steps=4,shadow xshift=0pt,shadow yshift=0pt}},
    pixelshuffle/.style={rectangle, draw, rounded corners, minimum width=1cm, minimum height=0.5cm, fill=blue!15, rotate=90, blur shadow={shadow opacity=50,shadow blur steps=4,shadow xshift=0pt,shadow yshift=0pt}},
    sum/.style={circle, draw, minimum size=0.5cm, fill=white, rotate=90,inner sep=0pt, outer sep=0pt, blur shadow={shadow opacity=50,shadow blur steps=4,shadow xshift=0pt,shadow yshift=0pt}},
    padconv/.style={draw=green!70!black, thick},
    padbilinear/.style={draw=blue, thick},
    arrow/.style={-Latex, thick}
}

\begin{tikzpicture}[node distance=0.8cm]
    % RVSR label
    \node[io, overlay, anchor=west] (rvsr) at (0, 2.6) {RVSR:};

    % Layers
    \begin{scope}[general shadow/.style={}]
    \node[anchor=south, rotate=90] (input) at (0, 0) {Low res};
    \end{scope}
    \node[conv, node distance=0.9cm, below of = input] (conv3) {Conv-3};
    \node[bilinear] (bilinear1) at (4.5cm, 2cm) {Bilinear $4\times$ upscale};
    \node[repconv, node distance=1cm, below of = conv3] (repconv1) {RepConv};
    \node[conv, node distance=0.9cm, below of = repconv1] (conv1) {Conv-1};
    \node[gelu, node distance=0.55cm, below of = conv1] (gelu) {GELU};
    \node[conv, node distance=0.55cm, below of = gelu] (conv2) {Conv-1};
    \node[sum, below of = conv2] (sum1) {$+$};
    \node[sum, below of = sum1] (sum2) {$+$};
    \node[repconv, node distance=0.82cm, below of = sum2] (repconv2) {RepConv};
    \node[conv, node distance=0.59cm, below of = repconv2] (conv3x) {Conv-1};
    \node[pixelshuffle, node distance=0.55cm, below of = conv3x] (pixelshuffle) {PixelShuffle};
    \node[sum, below of = pixelshuffle] (sum3) {$+$};
    \node[io, right of = sum3, node distance=0.7cm, rotate=90] (output) {High res $4\times$};

    % Padding
    \draw[padconv] (node cs:name=conv3,anchor=north) ++(-1mm, -1mm) rectangle ++(2mm, 2mm);
    \draw[padbilinear] (node cs:name=bilinear1,anchor=west) ++(-1mm, -1mm) rectangle ++(2mm, 2mm);    
    % Connections
    \draw[arrow] (input) -- (conv3);
    \draw[arrow, rounded corners = 0.25cm] (input) -| (0.2cm, 2cm) -- (bilinear1.west);
    \draw[arrow, rounded corners = 0.25cm] (bilinear1.east) -| (sum3.east);
    \draw[arrow, rounded corners = 0.25cm] (conv3.south) -| ++(0.25cm, 1.5cm) -| (sum2.east);
    \draw[arrow] (conv3) -- (repconv1);
    \draw[arrow, rounded corners = 0.25cm] (repconv1.south) -| ++(0.25cm, 1cm) -| (sum1.east);
    \draw[draw, thick] (repconv1) -- (conv1);
    \draw[draw, thick] (conv1) -- (gelu);
    \draw[draw, thick] (gelu) -- (conv2);
    \draw[arrow] (conv2) -- (sum1);
    \draw[arrow] (sum1) -- (sum2);
    \draw[arrow] (sum2) -- (repconv2);
    \draw[draw, thick] (repconv2) -- (conv3x);
    \draw[draw, thick] (conv3x) -- (pixelshuffle);
    \draw[arrow] (pixelshuffle) -- (sum3);
    \draw[arrow] (sum3) -- (output);

    % Sections
    \draw[rounded corners = 0.25cm, dashed, gray] (1.3cm,-1.25cm) rectangle ++(3.5cm,2.5cm);
    \node[section] at (3.1cm,-1cm) {Repeat $\times8$% %RepViT
    };
    \node[section, anchor=west] at (4.9cm,-1cm) {%$\times8$
    }; 

    
\end{tikzpicture}%
\hspace{0.5cm}%
\begin{tikzpicture}[node distance=0.8cm]
    % Input
    \node[io] (input) at (0, 0) {};

    % RepConv label
    \node[io, overlay, anchor=east] (repconv) at (0, 1.25) {RepConv:};

    % Combiner
    \node[io, right of = input, node distance=0.55cm] (combiner) {};
    
    % Layers
    \node[conv, node distance=0.9cm, below of = combiner] (conv21) {Conv-1};
    \node[conv, node distance=0.55cm, below of = conv21] (conv22) {Conv-3};
    \node[conv, node distance=0.55cm, below of = conv22] (conv23) {Conv-1};
    \node[conv, node distance=1.35cm, left of = conv21] (conv11) {Conv-1};
    \node[conv, node distance=0.55cm, below of = conv11] (conv12) {Conv-3};
    \node[conv, node distance=0.55cm, below of = conv12] (conv13) {Conv-1};
    \node[conv, node distance=1cm, right of = conv22, rotate=-90] (conv3) {Conv-3};
    \node[conv, node distance=1cm, left of = conv12, rotate=-90] (conv4) {Conv-1};

    % Sum
    \node[sum, below of = conv23] (sum) {$+$};

    % Output
    \node[io, right of = sum, node distance=0.55cm] (output) {};

    % Connections and padding
    \draw[arrow, rounded corners = 0.25cm] (combiner) -| ++(0.25cm, -0.5cm) |- (conv11.north);
    \draw[arrow] (combiner) -- (conv21);
    \draw[arrow, rounded corners = 0.25cm] (combiner) -| ++(0.25cm, 0.5cm) |- (conv3.west);
    \draw[padconv] (node cs:name=combiner) ++(-1mm, -1mm) rectangle ++(2mm, 2mm);% Padding
    \draw[arrow] (input) -- (combiner);
    \draw[draw, thick] (conv11) -- (conv12);
    \draw[draw, thick] (conv12) -- (conv13);
    %\draw[arrow] (conv13) -- (sum);
    \draw[arrow, rounded corners = 0.25cm] (conv13.south) -| ++(0.25cm, 0.5cm) -- (sum.north west);
    \draw[draw, thick] (conv21) -- (conv22);
    \draw[draw, thick] (conv22) -- (conv23);
    \draw[arrow] (conv23) -- (sum);
    \draw[arrow, rounded corners = 0.25cm] (conv3.east) -| ++(0.25cm, -0.5cm) -- (sum.north east);
    \draw[arrow, rounded corners = 0.25cm] (input) -| ++(0.25cm, -1cm) |- (conv4.west);
    \draw[arrow, rounded corners = 0.25cm] (conv4.east) -- ++(0.25cm, 0cm) -| (sum.west);
    \draw[arrow, rounded corners = 0.25cm] (input) -| ++(0.25cm, 1.5cm) -| (sum.east);
    \draw[arrow] (sum) -- (output);
    
    % Sections
\end{tikzpicture}
\newsavebox{\padconviconbox}
\sbox{\padconviconbox}{\begin{tikzpicture}\draw[padconv] rectangle (2mm, 2mm);\end{tikzpicture}}
\newsavebox{\padbilineariconbox}
\sbox{\padbilineariconbox}{\begin{tikzpicture}\draw[padbilinear] rectangle (2mm, 2mm);\end{tikzpicture}}\caption{The convolutional RVSR super-resolution model. The spatial sizes of convolution kernels were $N\times N$ for Conv-$N$. Bilinear image upscaling methods in JAX and PyTorch implicitly replication pad their inputs. We padded upscale input explicitly (\usebox{\padbilineariconbox}) with the method configurable separately from padding of Conv inputs (\usebox{\padconviconbox}). The RepConv block was converted to a single Conv-3 for inference.}
\label{fig:rvsr}
\end{figure}

We reimplemented the convolutional RVSR $4\times$ super-resolution model (\citealt{rvsr_paper}) in JAX-based Equinox (\citealt{equinox}) with a fully configurable padding method (see Fig.~\ref{fig:rvsr})) and trained its 218~928 training-time parameters from scratch using MSE loss. For some experiments, to emulate network output center cropping, we omitted padding from the inputs of a number of the last conv layers and cropped the bilinear upscale. We define \textit{output crop} as the number of 4-pixels-thick \textit{shells} discarded in center cropping (see Fig.\ref{fig:outputCrop}). We used the same padding method in the convolutional and upscale paths, with the exception of \texttt{zero-repl} and \texttt{zero-zero} where the latter designator signifies the upscale padding method. The upscale output was cropped identically to output crop, rendering \texttt{zero-repl} and \texttt{zero-zero} equivalent (denoted \texttt{zero}) for output crop $\geq 1$.

We used a dataset of 10k $512{\times}512$ pixel Sentinel 2 Level-1C RGB images (\citealt{sentinel2_10k}). We linearly mapped reflectances 0 to 1 to values -1 to 1. We split the data to a training set of 9k images and a test set of 1k images. The mean over images and channels of the variance of the test set was 0.44 with RGB means -0.28, -0.31, and -0.22.
%0.043799866, -0.28047428 -0.30902568 -0.22211602
To assemble a training batch we randomly picked images without replacement from the set, randomly cropped each image to $200{\times}200$, created a low-resolution version by bilinearly downscaling with anti-aliasing to $50{\times}50$, and center cropped the images to remove edge effects resulting in $192{\times}192$ target images and $48{\times}48$ input images.

We used a batch size of 64 and the Adam optimizer (\citealt{kingma2014adam}) with $\varepsilon = 10^{-3}$ (increased to improve stability) and default $b_1 = 0.9$ and $b_2 = 0.999$, and learning rate linearly ramped from $5\times10^{-6}$ to 0.014 over steps 0 to 100 (warmup, tuned for a low failure rate without sacrificing learning rate much) and from 0.014 to 0 over steps 1M to 1.5M (cooldown). We repeated the training with up to 12 different random number generator seeds.

\definecolor{blanchedalmond}{rgb}{1.0, 0.92, 0.8}
\definecolor{aqua}{rgb}{0.0, 1.0, 1.0}
\begin{figure}[!h]
\centering
\tikzset{
    arrow/.style={-Latex, thick}
}
\begin{tikzpicture} %[anchor=south west,
\node[anchor=center,inner sep=0,minimum size=1.5in] (input) at (0,0) {\includegraphics[width=1.5in,height=1.5in,interpolate=false]{input.png}};
\node[node distance=1.9in, right of=input,anchor=center,inner sep=0,minimum size=1.5in] (output) {\includegraphics[width=1.5in,height=1.5in,interpolate=false]{output.png}};
\node[node distance=1.9in, right of=output,anchor=center,inner sep=0,minimum size=1.5in] (target) {\includegraphics[width=1.5in,height=1.5in,interpolate=false]{target.png}};
\node[text=white] at (input) {Input};
\node[text=white] at (output) {Output};
\node[text=white] at (target) {Target};
\node[text=black, anchor=north, xshift=0.2in, yshift=-3pt] at (input.east) {RVSR};
\foreach \i in {0,...,10} {
  \pgfmathsetmacro{\scale}{(24-\i)/48}
  \draw[draw={\ifnum\i=5 black\else gray\fi},scale=\scale] (output)+(-1.5in, -1.5in) rectangle ++(1.5in, 1.5in);
  \draw[draw={\ifnum\i=5 black\else gray\fi},scale=\scale] (target)+(-1.5in, -1.5in) rectangle ++(1.5in, 1.5in);
}
\node[text=white, inner xsep=1pt, inner ysep=0, anchor=south west] at (input.south west) {$48{\times}48$ pixels};
\node[text=white, inner sep=1pt, anchor=south west] at (output.south west) {$192{\times}192$};
\node[text=yellow, inner sep=1pt, anchor=south west,xshift=0.15625in,yshift=0.15625in] at (output.south west) {$152{\times}152$};
\node[text=yellow, inner sep=1pt, anchor=south west,xshift=0.3125in,yshift=0.3125in] at (output.south west) {$112{\times}112$};
\node[text=yellow, inner sep=1pt, anchor=south east] at (output.south east) {0};
\node[text=yellow, inner sep=1pt, anchor=south east,xshift=-0.15625in,yshift=0.15625in] at (output.south east) {5};
\node[text=yellow, inner sep=1pt, anchor=south east,xshift=-0.3125in,yshift=0.28in] at (output.south east) {\noindent\begin{tabular}{@{}r@{}}\strut Output crop:\\\strut 10\end{tabular}};
\node[text=white, inner sep=1pt, anchor=south west] at (target.south west) {$192{\times}192$};
\node (mse) [right=0.2in of output.east, anchor=center,inner sep=1pt, rotate=90] {MSE};
\draw[draw=blue!50!white] (-0.75in,0.75in) -- (1.4625in, 0.4375in);
\draw[draw=blue!50!white] (-0.09375in,0.75in) -- (1.49375in, 0.4375in);
\draw[draw=blue!50!white] (-0.75in,0.09375in) -- (1.4625in, 0.40625in);
\draw[draw=blue!50!white] (-0.09375in,0.09375in) -- (1.49375in, 0.40625in);
\draw[draw=blue!25!white] (input)+(-0.75in, 0.75in) rectangle ++(-0.09375in, 0.09375in);
\draw[draw=blue!25!white] (output)+(-0.4375in, 0.4375in) rectangle ++(-0.40625in, 0.40625in);
\node[text=blue!25!white, inner xsep=1pt, inner ysep=1pt, anchor=center, text width=0.5in, align=center, xshift=0.328125in,yshift=-0.328125in] at (input.north west) {Receptive field};
\draw[thick,arrows = {-Stealth[inset=0pt, angle=90:6pt]}] (input.east) -- (output.west);
\draw[thick,arrows = {-Stealth[inset=0pt, angle=90:6pt]}] (output.east)+(-0.15625in,0) -- (mse.north);
\draw[thick,arrows = {-Stealth[inset=0pt, angle=90:6pt]}] (target.west)+(0.15625in,0) -- (mse.south);
\end{tikzpicture}
\caption{Illustration of RVSR super-resolution output cropping in MSE calculation, showing output crop 5 as an example. At output crop 10, the theoretical receptive fields do not include any padding.}
\label{fig:outputCrop}
\end{figure}

For trained models, we also evaluated test MSE separately for shells \#0--10, including in shell \#10 also the rest of the shift-equivariantly processed output center. We report bootstrapped 95\% confidence intervals over seeds for mean MSE and mean relative MSE difference. Test loss was calculated using center-cropped dataset images during training and by cropping at each corner in final evaluation.

Each training run took $\sim$4 days on a single NVIDIA V100 32G GPU, $\sim$2.5 GPU years in total consuming $\sim$5~MWh of 100\% renewable energy. Development and testing consumed $\sim$15\% additional compute. We used a V100S 32G to evaluate final MSEs, and an RTX~4070 Ti 16G for maximum batch size binary search and GPU throughput measurement at maximum batch size.

\begin{table}
\centering
\sisetup{detect-all=true}
\begin{tabular}{p{0.17cm}p{1.4cm}p{0.17cm}S[round-mode=places,round-precision=0,table-column-width=0.6cm]S[round-mode=places,round-precision=0,table-column-width=0.6cm]S[round-mode=places,round-precision=0,table-column-width=0.6cm]S[round-mode=places,round-precision=0,table-column-width=0.6cm]S[table-format=3.1(2)]S[table-format=3.2(2)]S[table-format=3.2(1)]}
\toprule
{\rotatebox[origin=l]{90}{\parbox{3.0cm}{\raggedright Output crop}}} &
{\rotatebox[origin=l]{90}{\parbox{3.0cm}{\raggedright Conv and upscale padding method(s)}}} &
{\rotatebox[origin=l]{90}{\parbox{3.0cm}{\vspace{-\baselineskip}\raggedright FFT ($\mathcal{F}$) or direct (D) autocorrelation}}} &
{\rotatebox[origin=l]{90}{\parbox{3.0cm}{\raggedright Maximum training batch size (images) $\uparrow$}}} &
{\rotatebox[origin=l]{90}{\parbox{3.0cm}{\raggedright Training throughput (images/s) $\uparrow$}}} &
{\rotatebox[origin=l]{90}{\parbox{3.0cm}{\raggedright Maximum inference batch size (images) $\uparrow$}}} &
{\rotatebox[origin=l]{90}{\parbox{3.0cm}{\raggedright{Inference throughput ($10^{6}$ pixels/s) $\uparrow$}}}} &
{\rotatebox[origin=l]{90}{\parbox{3.0cm}{\raggedright{Mean test MSE ($10^{-6}$) $\downarrow$}}}} &
{\rotatebox[origin=l]{90}{\parbox{3.0cm}{\raggedright Mean test MSE diff to zero-repl (\%) $\downarrow$}}} &
{\rotatebox[origin=l]{90}{\parbox{3.0cm}{\raggedright Outermost shell mean test MSE diff to zero-repl (\%) $\downarrow$}}} \\
\midrule
\multirow[t]{14}{*}{0} & \texttt{extr1} & & \bfseries 266.0 & 480.452101 & 6741.000000 & 864.546377 & \color{lightgray} 544.959849214205 \pm 2.446456885979883 & \color{lightgray} -0.25339003874507615 \pm 0.3085123219642755 & \color{lightgray} 0.4326897857147092 \pm 0.24080167562037624 \\
 & \texttt{extr2} & & \bfseries 266.0 & 479.653907 & 6741.000000 & 759.081643 & \color{lightgray} 550.5411788209232 \pm 2.8581956942133355 & \color{lightgray} 0.7681481104344994 \pm 0.35332690262815375 & \color{lightgray} 5.671478425448297 \pm 0.5299081936383132 \\
 & \texttt{extr3} & & \bfseries 266.0 & 478.395050 & 6741.000000 & 758.053104 & 559.6470636790199 \pm 1.9191393992038104 & 2.3788932255014004 \pm 0.3891036495911877 & 11.975397300371379 \pm 0.396429509843367 \\
 & \texttt{lp1x1cs} & & 237.000000 & 463.995174 & 6741.000000 & 722.056184 & 543.3013911691281 \pm 3.2700520213693096 & -0.6411865971757609 \pm 0.38685698100893945 & -1.822784686819451 \pm 0.28310065342701174 \\
 & \texttt{lp2x1} & D & 190.000000 & 433.302572 & 6741.000000 & 498.230041 & 543.2122395126903 \pm 2.262502979762915 & -0.6346082537686986 \pm 0.2450940143535211 & -1.706658744523474 \pm 0.19080500536579792 \\
 & \texttt{lp2x1cs} & & 189.000000 & 442.154728 & 6741.000000 & 631.946863 & 542.9373805285942 \pm 2.896162065580021 & -0.6760418757364636 \pm 0.28024843540835725 & -1.8761920273275265 \pm 0.14119700322443807 \\
 & \texttt{lp2x3} & D & 187.000000 & 429.345265 & 6741.000000 & 479.813897 & 542.7761618003938 \pm 2.9609883029961637 & -0.7055746267948391 \pm 0.18712002538769454 & -1.895669271761099 \pm 0.17647128816500834 \\
 & \texttt{lp2x5} & $\mathcal{F}$ & 240.000000 & 453.086143 & 6020.000000 & 381.709125 & \bfseries 542.7006953055012 \pm 2.4852499516221043 & \bfseries -0.7191520946131198 \pm 0.16997620276872955 & \bfseries -1.9034024051500096 \pm 0.11293023373673505 \\
 & \texttt{lp3x3} & $\mathcal{F}$ & 241.000000 & 454.871281 & 6020.000000 & 393.782284 & 543.2120199951795 \pm 2.488181931441287 & -0.6504373010225484 \pm 0.24640787966793556 & -1.8907992662674253 \pm 0.11989544375661954 \\
 & \texttt{lp4x5} & $\mathcal{F}$ & 236.000000 & 447.054718 & 6020.000000 & 355.597599 & 543.2137853553018 \pm 3.4780494701765186 & -0.6255524324166255 \pm 0.3881038479250816 & -1.7733878418324447 \pm 0.1761102166377695 \\
 & \texttt{lp6x7} & $\mathcal{F}$ & 191.000000 & 432.219856 & 6020.000000 & 265.673784 & \color{lightgray} 543.6788944941698 \pm 1.7790228329556168 & \color{lightgray} -0.48778418776277727 \pm 0.2309893751564318 & \color{lightgray} -1.343000200541449 \pm 0.22616481293357427 \\
 & \texttt{repl} & & \bfseries 266.0 & \bfseries 481.03431888441503 & \bfseries 6880.0 & 870.245266 & 544.5671742345946 \pm 3.08969406533473 & -0.3870149278010444 \pm 0.29925055482660945 & 0.2792256236510945 \pm 0.1664539731084041 \\
 & \texttt{zero-repl} & & 263.000000 & 471.559648 & \bfseries 6880.0 & \bfseries 964.2265000884665 & 546.645091575677 \pm 1.9289681318043999 & 0.00 & 0.00 \\
 & \texttt{zero-zero} & & 263.000000 & 472.152709 & 6741.000000 & 960.137030 & 547.128090114226 \pm 1.8219101180508834 & 0.08854964708396536 \pm 0.25865578509211934 & 1.3201178562295632 \pm 0.1456064371012915 \\
\midrule
\multirow[t]{5}{*}{1} & \texttt{lp1x1cs} & & 238.000000 & 468.155412 & \bfseries 7314.0 & 695.149594 & 532.2005759348174 \pm 1.6496797300522077 & \bfseries -0.2696939261634468 \pm 0.291547789291931 & \bfseries -0.9298748095229364 \pm 0.15810570643741928 \\
 & \texttt{lp2x1cs} & & 191.000000 & 444.219350 & \bfseries 7314.0 & 608.214496 & \bfseries 531.9557897262416 \pm 1.7587412816786976 & -0.2677053436905746 \pm 0.16917642462399043 & -0.8840283634334349 \pm 0.19675246500067511 \\
 & \texttt{lp2x3} & D & 188.000000 & 436.314796 & \bfseries 7314.0 & 473.092142 & 532.4696238709893 \pm 2.344382484650474 & -0.22073637629368506 \pm 0.2626896030341265 & -0.8804640321716379 \pm 0.13006854160406478 \\
 & \texttt{repl} & & \bfseries 268.0 & 481.451226 & \bfseries 7314.0 & 808.182948 & 532.7624195651754 \pm 2.5745552310546285 & -0.1646218006201146 \pm 0.3084564187076404 & -0.06867039139297458 \pm 0.13055723012842718 \\
 & \texttt{zero} & & \bfseries 268.0 & \bfseries 482.78755118230595 & \bfseries 7314.0 & \bfseries 895.9946722262563 & 533.6467998433128 \pm 1.9924019943148892 & 0.00 & 0.00 \\
\midrule
\multirow[t]{3}{*}{5} & \texttt{lp2x3} & D & 257.000000 & 486.267107 & \bfseries 8403.0 & 465.035776 & 531.7565014509676 \pm 2.8474410144431728 & -0.04518253499897254 \pm 0.2979220891732665 & \bfseries -0.1595411758545141 \pm 0.14371132966073266 \\
 & \texttt{repl} & & \bfseries 325.0 & 517.986362 & \bfseries 8403.0 & 663.830190 & \bfseries 531.6577330576004 \pm 2.5375089750437025 & \bfseries -0.06370497782126715 \pm 0.2749219041620122 & -0.13746603348017772 \pm 0.17298366838585436 \\
 & \texttt{zero} & & \bfseries 325.0 & \bfseries 518.2520139161879 & \bfseries 8403.0 & \bfseries 706.1611640451468 & 531.99700282125 \pm 2.2361908199079132 & 0.00 & 0.00 \\
\bottomrule
\\
\end{tabular}
    \caption{RVSR evaluation results. 95\% convidence intervals are reported (gray means lack of data).}
    \label{tab:mainResultsTable}
\end{table}

\section{Results and discussion}

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{fig_loss_shells.pdf}
    \caption{Super-resolution mean test MSE for select models, calculated separately for shells of equivalent width of 1 input pixel (bounded by squares in Fig.~\ref{fig:outputCrop}). Error bars indicate 95\% confidence interval of the mean. Results for each output crop only include those seeds for which training was successful for every method listed. Pale-colored bars indicate exclusion of shells from training loss.}
    \label{fig:lossShellsBar}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=0.875\linewidth]{fig_scatterplot_presets_seeds.pdf}
    \caption{Super-resolution test MSE with mean (\meanmark) and the 95\% confidence interval of the mean (\confmark) across all successful training runs. For seed values, see Appendix~\ref{ap:seedTable}.}
    \label{fig:scatterplot}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{fig_test_loss_history.pdf}
    \caption{Super-resolution mean test loss during training for select padding methods, including for each output crop only those seeds that resulted in a successful training run for every method listed.}
    \label{fig:history}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=1.0\linewidth]{fig_time.pdf}
    \caption{95\% confidence interval of the mean super-resolution MSE of each model vs. training/inference throughput evaluated using maximum training/inference batch sizes. Except for the outermost shell mean test MSE, the results do not apply to other than the used $48{\times}48$ pixel input image size because of the difference in the ratio of output pixels influenced by padding.}
    \label{fig:mseVsThroughput}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.63\linewidth]{fig_layer_nmse.pdf}
    \caption{Test mean-over-seeds NMSE (MSE divided by data variance) of padding each convolution layer input (low-res input \#0 and feature maps \#1--9) and high-res network output (\#10) from a $28{\times}28$-pixel center crop to $30{\times}30$ pixels, in a trained RVSR network. Padding by mean would give $\text{NMSE}=1$. Sparsity differences (\citealt{aimar2018nullhop}) may contribute to predictability differences.}
    \label{fig:featureMapPaddingNMSE}
\end{figure}

For sample images padded using variants of \texttt{lp} and other methods, see Appendix~\ref{ap:paddingSamples}. In RVSR super-resolution training, we observed catastrophic Adam optimizer instability with some seed--method combinations (see Appendix~\ref{ap:seedTable}). We believe that this was a chaotic effect due to both a high learning rate and to numerical issues exemplified by differences between the equivalent \texttt{repl} and \texttt{extr1}, and not indicative of an inherent difference in training stability between the various padding methods. Overall training dynamics (Fig.~\ref{fig:history}) were similar between the padding methods, with the exception of lower early-training test MSE for \texttt{repl} and the \texttt{lp} methods, compared to a \texttt{zero-repl} baseline, when trained without output crop. The main evaluation results for trained models can be found in Table~\ref{tab:mainResultsTable}, and sample images and a visualization of the deviation from shift equivariance in Appendix~\ref{ap:samples}.

The different \texttt{lp} methods yielded very similar super-resolution test MSEs, bringing the light-weight \texttt{lp1x1cs} and \texttt{lp2x1cs} to the inference throughput--MSE Pareto front (see Fig.~\ref{fig:mseVsThroughput}) for each output crop 0 and 1. The \texttt{lp} methods that used FFT-accelerated autocorrelation reached larger batch sizes in training but were limited to smaller batch sizes in inference, in comparison to \texttt{lp} methods that calculated autocorrelation directly and used a similar neighborhood size.

For output crop 0, every tested \texttt{lp} method yielded a 0.20--0.9\% (at 95\% confidence) lower mean test MSE and 1.5--2.0\% lower outermost shell mean test MSE compared to the standard \texttt{zero-repl} baseline (see Tab.~\ref{tab:mainResultsTable}). For the other shells (see Fig.~\ref{fig:lossShellsBar}), \texttt{lp2x3} and \texttt{repl} were tied but consistently better than the baseline. Compared to the baseline, \texttt{repl} improved the test mean MSE by 0.1--0.7\% but, notably, was 0.1--0.5\% worse at the outermost shell. We hypothesize that the more clear edge signal and worse data approximation by \texttt{zero-repl}, compared to \texttt{repl}, enables and forces the network to use some of its capacity to improve shell \#0 performance at the cost of overall performance. As an approximator of the internal feature maps of a trained RVSR network (with GELU activation), \texttt{zero} has up to 40-fold larger error than \texttt{repl} and \texttt{lp2x3} (see Fig.~\ref{fig:featureMapPaddingNMSE}). The worse approximation by \texttt{zero} is illustrated by the up to 10-fold MSE error growth for shells not included in the training loss and outside the output crop (shaded gray in Fig.~\ref{fig:lossShellsBar}), compared to \texttt{repl} and \texttt{lp2x3}. Compared to explicit \texttt{zero}, the default implicit \texttt{repl} in bilinear upscale gave a lower outermost shell mean test MSE.

For output crop 1, the choice of padding method mattered less, with \texttt{lp2x3} improving upon the baseline at the two outermost shells. Models trained with output crop 5 saw no difference from the choice of padding method. Furthermore, the test MSEs have only relatively modest differences between output crops. At shells \#$\ge$5, all models perform similarly with the exception of the somewhat worse output crop 0 \texttt{zero-repl}. This might be because training with output crop doesn't free up sufficient capacity to decrease MSE in the remaining image area for \texttt{repl} and \texttt{lp2x3}.

For \texttt{extr}$N$ we found test MSE to increase with $N$, with \texttt{extr3} giving 11--12\% worse outermost shell mean MSE compared to baseline. In contrast, \citealt{diffconv_paper} found the equivalent of \texttt{extr3} (see GitHub issue \#2 in \citealt{diffconv_repo} for a numerical demonstration of equivalence) to give better results in a U-net super-resolution task than \texttt{zero} or \texttt{repl}, which we suspect was due to their use of blurred inputs (Gaussian blur of standard deviation $\sigma = 3$) that are better approximated by the higher-degree \texttt{extr3} method (see Appendix~\ref{ap:blurExtr}).

\section{Conclusions}

Using linear prediction padding (\texttt{lp}) instead of \texttt{zero} or replication padding (\texttt{repl}) improved slightly the quality of CNN-based super-resolution, in particular near image borders, at a moderate added time cost. Center-cropping the network output leveled the differences in output--target mean square error between padding methods. At output crop 5 the stitching artifacts due to deviation from shift equivariance were no longer visible.

Considering padding as autoregressive estimation of data and feature maps explains some of the differences between padding methods. However, the tested CNN architecture learned to compensate the elevated super-resolution error near the image edge to roughly the same magnitude for all the tested padding methods, including \texttt{zero} which has an exceptionally high estimation error. The slightly higher overall super-resolution error with \texttt{zero} supports the hypothesis that more network capacity is consumed by the compensation of the larger padding error.

Our results might not directly apply to other CNN architectures and tasks. Covariance statistics may suffer from the small sample problem with spatially tiny inputs such as encodings. Larger effective receptive fields may favor \texttt{lp}, whereas workloads with a higher level of spatial inhomogeneity, lower spatial correlations in network input or feature maps (in particular spatially whitened data), or higher nonlinearity in spatial dependencies would likely make \texttt{lp} less useful, favoring \texttt{zero} for its clear edge signaling. If using \texttt{lp} in CNN-based processing of images with \textit{framing}, for example photos of objects, any needed location information might need to come from another source than the padding. 

Our JAX \texttt{lp} padding implementation and source code for reproducing the results of this article are freely available (\citealt{rosenberg_2025_14871260}). Our \texttt{lp1x1cs} and \texttt{lp2x1cs} methods would be the most straightforward ones to port to other frameworks.

\section{Further work}

We have yet to explore 1) using a spatially weighted loss to level spatial differences in error, 2) using batch rather than image statistics for a larger statistical sample, 3) increasing the sample size by giving \texttt{lp} memory of past statistics, 4) learning rather than solving \texttt{lp} coefficients, 5) modeling dependencies between channels, 6) instead of ouput cropping, cross-fading adjacent output tiles and optimizing the cross-fade curves during training, 7) setting the padding method separately for each feature map based on its spatial autocorrelation, 8) accelerating solves by taking advantage of the covariance matrix structure, and 9) use of \texttt{lp} in other CNN architectures and training settings.

\section{Contributions and acknowledgements}

The article was written by Olli Niemitalo (who wrote the theory) and Otto Rosenberg, and reviewed by Nathaniel Narra and Iivari Kunttu. Implementations were written by Otto Rosenberg and Olli Niemitalo. The work was supervised by Olli Koskela and Iivari Kunttu. The work was supported by the Research Council of Finland funding decision 353076, Digital solutions to foster climate-smart agricultural transition (Digi4CSA). Model training was done on the CSC -- IT Center for Science, Finland supercomputer Puhti. The dataset used contains Copernicus Sentinel data 2015--2022.

\bibliographystyle{plainnat}
\bibliography{bibliography}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\appendix

\section{Stabilization of 1D covariance method linear prediction}\label{ap:stabilization}

For 1D linear prediction neighborhoods $1{\times}1$ (stabilized covariance method \texttt{lp1x1cs}) and $2{\times}1$ \texttt{lp2x1cs}), the padding procedure in one direction (Eq.~\ref{eq:arProcessReflectanceRecursion}) using already calculated coefficients $a_{1\ldots P}$ is equivalent to a discrete-time linear time-invariant (LTI) system having a causal recursion:
\begin{equation}
\begin{aligned}
1{\times}1:\,\, y[k] = a_1 y[k-1] + b_0 x[k],\quad\quad
2{\times}1:\,\, y[k] = a_1 y[k-1] + a_2 y[k-2]+ b_0 x[k],
\end{aligned}
\label{eq:lti}
\end{equation}
where $y[k]$ are known pixel values or padding pixels, $x[k]$ are input pixels with $x[k] = 0\text{ for all }k$ with an inconsequential input coefficient $b_0$. The corresponding transfer functions are:
\begin{equation}
\begin{array}{ll}
\begin{aligned}[t]
1{\times}1:\quad H(z) &= \frac{b_0}{1 - a_1 \,z^{-1}}\\&=\frac{b_0\,z}{z-p_0},\\
p_0 &= a_1
\end{aligned}&\quad\quad\begin{aligned}[t]2{\times}1:\quad H(z) &= \frac{b_0}{1 - a_1\,z^{-1} - a_2\,z^{-2}}\\&=\frac{b_0\,z^2}{(z-p_0)(z-p_1)},\\
p_0 &= \frac{a_1 + \sqrt{a_1^2 + 4\,a_2}}{2}\\
p_1 &= \frac{a_1 - \sqrt{a_1^2 + 4\,a_2}}{2},
\end{aligned}
\label{eq:transferFunctionLp1x2}
\end{array}
\end{equation}
where $b_0$ is an input scaling factor, $z^{-1}$ represents a delay of one sampling period, and $H(e^{i\omega})$, represents the frequency response of the system with $\omega$ the frequency in radians per sampling period, $e$ the natural number, and $i$ the imaginary unit.

The system is stable if all poles $p$ of the transfer function lie inside the complex $z$-plane unit circle. A stationary autoregressive process is stable. If the coefficients were found by solving normal equations with approximate covariances, then stability is not guaranteed. In practice, stability is needed to prevent blow-up of the padding output when padding recursively.

By reciprocating the $z$-plane radius of all poles that have radius $> 1$, the system can be made stable, or marginally stable in case any of the poles lie at radius 1 exactly. An unstable system has no well-defined frequency response, but we can still compute $H(e^{i\omega})$. The stabilization alters the phase of $H(e^{i\omega})$ but maintains its magnitude up to a constant scaling factor that is inconsequential with zero input, thus preserving the essential power-spectral characteristics of the autoregressive process. Magnitude scaling could be compensated for by setting $b'_0 = b_0\big(1 - \sum_{i=0}^{i<P} a'_i\big)/\big(1 - \sum_{i=0}^{i<P} a_i\big)$ where $'$ denotes updated variables. The choice of $b_0$ is inconsequential with constant zero input but would matter in \textit{generative} padding with $x$ a white noise \textit{innovation}.

For a $2{\times}1$ neighborhood, if what's under the square root in Eq.~\ref{eq:transferFunctionLp1x2} is negative, $a_1^2 + 4 a_2 < 0$, then the poles are complex and form a complex conjugate pair. Otherwise, both poles are real. The squared magnitudes of the complex conjugate pair of poles are equal, $|p_0|^2 = |p_1|^2 = -a_2$. The complex poles lie outside the unit circle only if $-a_2 > 1$, in which case the system can be stabilized by $a'_1 = -a_1/a_2$, $a'_2 = 1/a_1$. Real poles $p_0$ and $p_1$ can be found using Eq.~\ref{eq:transferFunctionLp1x2}, they can be reciprocated when necessary, and the modified coefficients can be extracted from the expanded form of the numerator polynomial as: $a'_1 = p'_0 + p'_1$ and $a'_2 = p'_0\,p'_1$.

The characteristic polynomial of the AR process is the denominator of the transfer function Eq.~\ref{eq:transferFunctionLp1x2} written with lag operator $B = z^{-1}$. With the characteristic polynomial the stability condition is that all roots are outside the unit circle. Stabilization via the characteristic polynomial would manipulate the coefficients identically to what was presented above.

\clearpage
\section{Sample padded images}
\label{ap:paddingSamples}

Fig.~\ref{fig:paddingSamples} shows sample padded images. For information about the image dataset, see section \ref{se:superResolution}.
\begin{figure}[!h]
    \centering
    \includegraphics[width=1.0\linewidth]{fig_padding_samples.pdf}
    \caption{Non-cherry-picked $48{\times}48$ pixel test set satellite images padded with $24$ pixels on each side, using different methods. The first row shows the ground truth (\textit{target}) image from which each padding input was center-cropped (see the \texttt{zero} row for the crop boundaries). The \texttt{lp} methods with larger neighborhood widths capture directional regularities with larger slopes off the padding direction. The \texttt{extr2} and \texttt{extr3} recursions are unstable. Color channels have been clipped to reflectance range 0--0.8.}
    \label{fig:paddingSamples}
\end{figure}

\clearpage
\section{Effect of blur on padding error}
\label{ap:blurExtr}

To simulate padding input data having an adjustable degree of blurriness or a rate of frequency spectral decay, we model Gaussian-blurred white-noise data by uniformly sampling a zero-mean Gaussian process $x$ of unit variance and with Gaussian covariance as function of lag $d$:
\begin{equation}
\text{Cov}(x[i], x[i+d]) = \kappa(d) = \exp \left(-\tfrac{d^2}{2\sigma^2} \right)\quad\text{for all integer }i,
\end{equation}
with $\sigma$ corresponding to the standard deviation of the Gaussian blur. A general linear right padding method approximates $x[0]$ from the $P$ nearest samples by $\hat x[0] = \sum_{i=1}^P a_i x[-i]$. We define the padding error $\varepsilon$ with the sign convention:
\begin{equation}
\varepsilon = \hat x[0] - x[0] = \sum_{i=0}^P a_i x[-i],\quad a_0 = -1,
\end{equation}
prepending $a_{1\ldots P}$ with $a_0 = -1$ for convenience. The normalized mean square of the zero-mean $\varepsilon$ is:
\begin{equation}
\begin{aligned}
\text{NMSE} = \frac{\operatorname{E}(\varepsilon^2)}{\text{Var}(x)} = \frac{\text{Var}(\varepsilon)}{1} &= \sum_{i=0}^P \sum_{j=0}^P \text{Cov}(a_i x[-i], a_j x[-j]) = \sum_{i=0}^P \sum_{j=0}^P a_i a_j \kappa(j-i)
\end{aligned}
\label{eq:nmseFromCov}
\end{equation}
We compare in Fig.~\ref{fig:errorVarVsBlurSigma} the MSE for the following 1D padding methods with some equivalencies:
\begin{equation}
\begin{array}{lll}
\text{Method(s)}&P&a_{0\ldots P}\\
\hline
\texttt{zero}, \texttt{extr0}&0&-1\\
\texttt{repl}, \texttt{extr1}&1&-1, 1\\
\texttt{extr2}&2&-1, 2, -1\\
\texttt{extr3}&3&-1, 3, -3, 1\\
\texttt{lp1x1cs}&1&-1, a_1\\
\texttt{lp2x1}, \texttt{lp2x1cs}&2&-1, a_1, a_2\\
\texttt{lp3x1}&3&-1, a_1, a_2, a_3\\
\end{array}
\end{equation}
with $a_{1\ldots P}$ for \texttt{lp1x1cs}, \texttt{lp2x1}, and \texttt{lp2x1cs} from Eq.~\ref{eq:findCoefDirect} and for \texttt{lp3x1} from solving Eq.~\ref{eq:findCoefMatrix} using Levinson recursion, with known autocorrelation-like covariances $r_{ij}=\kappa(j-i)$, corresponding to the limiting case of infinitely vast padding input providing covariance statistics matching the covariances of the Gaussian process.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.5\linewidth]{fig_data_blur.pdf}
    \caption{Theoretical padding NMSE as function of standard deviation $\sigma$ of Gaussian blur applied to white-noise data. Padding input is the blurred data normalized to unit variance. Increasing the order of the \texttt{extr} padding mode increases the error for low $\sigma$ and decreases it for high $\sigma$. Each \texttt{lp} method has been least-squares fit to the known signal model and thus attains the lowest possible MSE given the number of predictors. \texttt{zero} remains ideal for data with zero autocorrelation at non-zero lags.}
    \label{fig:errorVarVsBlurSigma}
\end{figure}

\clearpage
\section{Trained models}\label{ap:seedTable}

\begin{center}    
\begin{tabular}{llcccccccccccc}
\toprule
&&\multicolumn{12}{c}{seed / symbol}\\
\multirow{2}{*}{\shortstack[l]{output\\crop}}&\multirow{2}{*}{\shortstack[l]{padding\\method}}&0&1&2&3&4&5&6&7&8&9&10&11\\
&&
\includegraphics{s0.pdf}&
\includegraphics{s1.pdf}&
\includegraphics{s2.pdf}&
\includegraphics{s3.pdf}&
\includegraphics{s4.pdf}&
\includegraphics{s5.pdf}&
\includegraphics{s6.pdf}&
\includegraphics{s7.pdf}&
\includegraphics{s8.pdf}&
\includegraphics{s9.pdf}&
\includegraphics{s10.pdf}&
\includegraphics{s11.pdf}\\
\midrule
0 & \texttt{lp1x1cs} & \cmark & \cmark & \cmark & \xmark & \xmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark \\
& \texttt{lp2x1} & \cmark & \xmark & \cmark & \xmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark \\
& \texttt{lp2x1cs} & \cmark & \cmark & \cmark & \xmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark \\
& \texttt{lp2x3} & \cmark & \cmark & \cmark & \xmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark \\
& \texttt{lp2x5} & \cmark & \cmark & \cmark & \xmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark \\
& \texttt{lp3x3} & \cmark & \cmark & \cmark & \xmark & \cmark & \xmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark \\
& \texttt{lp4x5} & \cmark & \cmark & \cmark & \xmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark \\
&  \texttt{lp6x7} & \cmark & \cmark & \cmark & \dmark & \dmark & \dmark & \dmark & \dmark & \dmark & \dmark & \dmark & \dmark \\
& \texttt{zero-repl} & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark & \xmark & \xmark & \cmark & \cmark & \cmark \\
& \texttt{zero-zero} & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark & \xmark & \xmark & \cmark & \cmark & \cmark \\
& \texttt{repl} & \cmark & \xmark & \cmark & \xmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark \\
& \texttt{extr1} & \cmark & \cmark & \cmark & \dmark & \dmark & \dmark & \dmark & \dmark & \dmark & \dmark & \dmark & \dmark \\
& \texttt{extr2} & \cmark & \cmark & \cmark & \dmark & \dmark & \dmark & \dmark & \dmark & \dmark & \dmark & \dmark & \dmark \\
& \texttt{extr3} & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark \\
\midrule
1 & \texttt{lp1x1cs} & \cmark & \cmark & \xmark & \xmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark \\
& \texttt{lp2x1cs} & \cmark & \xmark & \xmark & \xmark & \cmark & \cmark & \xmark & \cmark & \cmark & \cmark & \cmark & \cmark \\
& \texttt{lp2x3} & \cmark & \cmark & \cmark & \xmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark \\
& \texttt{zero} & \xmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark \\
& \texttt{repl} & \cmark & \cmark & \xmark & \xmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark \\
\midrule
5 & \texttt{lp2x3} & \cmark & \cmark & \cmark & \xmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark \\
& \texttt{zero} & \cmark & \cmark & \xmark & \xmark & \cmark & \cmark & \cmark & \cmark & \cmark & \xmark & \cmark & \cmark \\
& \texttt{repl} & \cmark & \cmark & \xmark & \xmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark \\
\bottomrule
\end{tabular}
\end{center}
Super-resolution training was either successful (\cmark), failed (\xmark), or skipped (\dmark) for different combinations of padding methods and the random number generator seed. We report loss differences between models using only seeds that resulted in successful training for both of the compared models.

\section{Tiled processing samples and deviation from shift equivariance}\label{ap:samples}

Figs.~\ref{fig:samples_output_crop_0}--\ref{fig:samples_output_crop_5} show non-cherry-picked stitched tiled processing results from models trained with seed 10, using different output crops. Fig.~\ref{fig:samples_inputs_targets} show the corresponding inputs and targets from the test set.
Figs.~\ref{fig:shift_invariance_abs_deviation_output_crop_0}--\ref{fig:shift_invariance_abs_deviation_output_crop_5} visualize deviation from shift equivariance for the same images.

\begin{figure}[!h]
    \centering
    \includegraphics[width=1.0\linewidth]{fig_inputs_targets.pdf}
    \caption{The super-resolution inputs and targets from the test set, cropped to the same view as the sample results.}
    \label{fig:samples_inputs_targets}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=1.0\linewidth]{fig_stitched_output_crop_0.pdf}
    \caption{Stitched RVSR super-resolution results with output crop 0. Four output tiles, each as large as the images shown, were stitched together with a corner of the tiling grid at the center of each image. A cross-hair-shaped discontinuity artifact is formed due to deviation from shift equivariance. Black represents zero reflectance and white represents a reflectance of 0.8 on every channel.}
    \label{fig:samples_output_crop_0}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=1.0\linewidth]{fig_stitched_output_crop_1.pdf}
    \caption{Stitched RVSR super-resolution results with output crop 1. Visually, the discontinuity artifact is much weaker than with output crop 1 and is only visible on high-contrast edges not perpendicular to the tile boundary.}
    \label{fig:samples_output_crop_1}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=1.0\linewidth]{fig_stitched_output_crop_5.pdf}
    \caption{Stitched RVSR super-resolution results with output crop 5. No visible tiling artifacts.}
    \label{fig:samples_output_crop_5}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=1.0\linewidth]{fig_shift_invariance_abs_deviation_output_crop_0.pdf}
    \caption{RVSR super-resolution deviation from shift equivariance for output crop 0, calculated as the absolute value of the difference between a stitched tiled prediction and a prediction using only valid convolutions. Black represents no difference and white represents an absolute reflectance difference of 0.2 on every channel.}
    \label{fig:shift_invariance_abs_deviation_output_crop_0}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=1.0\linewidth]{fig_shift_invariance_abs_deviation_output_crop_1.pdf}
    \caption{RVSR super-resolution deviation from shift equivariance for output crop 1.}
    \label{fig:shift_invariance_abs_deviation_output_crop_1}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=1.0\linewidth]{fig_shift_invariance_abs_deviation_output_crop_5.pdf}
    \caption{RVSR super-resolution deviation from shift equivariance for output crop 5. \texttt{zero} displays elevated deviations compared to \texttt{lp2x3} and \texttt{repl}.}
    \label{fig:shift_invariance_abs_deviation_output_crop_5}
\end{figure}

\end{document}