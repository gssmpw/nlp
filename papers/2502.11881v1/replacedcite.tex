\section{Related Work}
\paragraph{Model-based Theory-of-Mind Reasoning}
Cognitive science research has shown that humans reason about other agents' minds by assuming their actions are rational and goal-directed ____. These processes have been formalized as Bayesian Theory of Mind ____, which models agents as rational actors that plan and act upon their beliefs and desires to achieve their goals. This probabilistic model can then be inverted via \textit{inverse planning}, inferring agents' mental states from their behavior ____, including via SMC methods ____. While \tracing is patterned on this model-based approach, we do not explicitly model rational agents, but instead use LLMs as \emph{implicit models} of agents' behavior, and as \emph{hypothesis generators} for agents' thoughts, enabling our method to be applied to open-ended inputs.

\paragraph{Theory-of-Mind Reasoning in LLMs}
Debates on whether LLMs are capable of ToM reasoning have sparked extensive controversy ____.
As a result, many benchmarks for evaluating ToM reasoning have been released ____ along with task complexity assessments ____.
While LLMs succeed on some tasks, analyses on these benchmarks show that they are not yet at the level of human ToM, with signs of overfitting ____ and overall poor capabilities ____.
To mitigate this, several inference-time methods have been introduced ____.
However, they rely on specific assumptions or few-shot examples, making them less scalable.
Recently, ____ showed search for generating ToM training data and ____ introduced a modular design for ToM hypothesis generation in multi-agent game scenarios.
In this work, we aim to minimize assumptions and introduce a flexible algorithm capable of generating traces of a target agent's mental states in open-ended text.


\paragraph{Inference-time Reasoning for LLMs} has emerged as a pivotal area of research, particularly in mathematics, coding, and puzzle solving.
Early work, such as Chain-of-Thought ____, demonstrated the benefits of generating intermediate reasoning steps, and was later augmented by approaches capable of exploring multiple reasoning paths ____, aggregation across reasoning chains ____, and problem decomposition ____.
Recently, reasoning models trained via reinforcement learning---o1 ____, R1 ____, and QwQ ____---have shown remarkable performance.
Most of these approaches leverage objectively verifiable answers to enable reinforcement and accurate selection among multiple reasoning paths.  However, such verification is challenging in social reasoning due to subjectivity and uncertainty. To handle uncertainty, recent methods perform probabilistic inference in LLMs via sequential Monte Carlo ____, but have not been used to infer and track mental states. In this work, we introduce a general SMC-like algorithm capable of operating effectively in the social domain while bypassing the need for objective verification.