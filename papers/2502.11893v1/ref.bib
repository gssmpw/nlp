@article{allen2020towards,
  title={Towards understanding ensemble, knowledge distillation and self-distillation in deep learning},
  author={Allen-Zhu, Zeyuan and Li, Yuanzhi},
  journal={arXiv preprint arXiv:2012.09816},
  year={2020}
}
@article{zou2023benefits,
  title={The benefits of mixup for feature learning},
  author={Zou, Difan and Cao, Yuan and Li, Yuanzhi and Gu, Quanquan},
  journal={arXiv preprint arXiv:2303.08433},
  year={2023}
}
@inproceedings{jelassi2022towards,
  title={Towards understanding how momentum improves generalization in deep learning},
  author={Jelassi, Samy and Li, Yuanzhi},
  booktitle={International Conference on Machine Learning},
  year={2022}
}
@inproceedings{cao2022benign,
  title={Benign overfitting in two-layer convolutional neural networks},
  author={Cao, Yuan and Chen, Zixiang and Belkin, Misha and Gu, Quanquan},
  booktitle={Advances in neural information processing systems},
  year={2022}
}

@inproceedings{feldman2020neural,
  title={What neural networks memorize and why: Discovering the long tail via influence estimation},
  author={Feldman, Vitaly and Zhang, Chiyuan},
  booktitle={Advances in Neural Information Processing Systems},
  year={2020}
}
@inproceedings{feldman2020does,
  title={Does learning require memorization? a short tale about a long tail},
  author={Feldman, Vitaly},
  booktitle={ACM SIGACT Symposium on Theory of Computing},
  year={2020}
}
@article{hartley2022measuring,
  title={Measuring unintended memorisation of unique private features in neural networks},
  author={Hartley, John and Tsaftaris, Sotirios A},
  journal={arXiv preprint arXiv:2202.08099},
  year={2022}
}
@inproceedings{cheng2022memorize,
  title={Memorize to generalize: on the necessity of interpolation in high dimensional linear regression},
  author={Cheng, Chen and Duchi, John and Kuditipudi, Rohith},
  booktitle={Conference on Learning Theory},
  year={2022}
}
@inproceedings{kou2023benign,
  title={Benign Overfitting in Two-layer ReLU Convolutional Neural Networks},
  author={Kou, Yiwen and Chen, Zixiang and Chen, Yuanzhou and Gu, Quanquan},
  booktitle={International Conference on Machine Learning},
  year={2023}
}
@article{garg2023memorization,
  title={Memorization through the lens of curvature of loss function around samples},
  author={Garg, Isha and Roy, Kaushik},
  journal={arXiv preprint arXiv:2307.05831},
  year={2023}
}
@inproceedings{wang2024memorization,
  title={Memorization in self-supervised learning improves downstream generalization},
  author={Wang, Wenhao and Kaleem, Muhammad Ahmad and Dziedzic, Adam and Backes, Michael and Papernot, Nicolas and Boenisch, Franziska},
  booktitle={International Conference on Learning Representations},
  year={2024}
}
@inproceedings{brown2021memorization,
  title={When is memorization of irrelevant training data necessary for high-accuracy learning?},
  author={Brown, Gavin and Bun, Mark and Feldman, Vitaly and Smith, Adam and Talwar, Kunal},
  booktitle={ACM SIGACT symposium on theory of computing},
  year={2021}
}
@inproceedings{frei2022benign,
  title={Benign overfitting without linearity: Neural network classifiers trained by gradient descent for noisy linear data},
  author={Frei, Spencer and Chatterji, Niladri S and Bartlett, Peter},
  booktitle={Conference on Learning Theory},
  year={2022}
}
@inproceedings{jacot2018neural,
  title={Neural tangent kernel: Convergence and generalization in neural networks},
  author={Jacot, Arthur and Gabriel, Franck and Hongler, Cl{\'e}ment},
  booktitle={Advances in neural information processing systems},
  year={2018}
}
@article{du2018gradient,
  title={Gradient descent provably optimizes over-parameterized neural networks},
  author={Du, Simon S and Zhai, Xiyu and Poczos, Barnabas and Singh, Aarti},
  journal={arXiv preprint arXiv:1810.02054},
  year={2018}
}
@inproceedings{allen2019convergence,
  title={A convergence theory for deep learning via over-parameterization},
  author={Allen-Zhu, Zeyuan and Li, Yuanzhi and Song, Zhao},
  booktitle={International conference on machine learning},
  year={2019}
}
@inproceedings{shen2022data,
  title={Data augmentation as feature manipulation},
  author={Shen, Ruoqi and Bubeck, S{\'e}bastien and Gunasekar, Suriya},
  booktitle={International conference on machine learning},
  year={2022}
}
@inproceedings{sagawa2020investigation,
  title={An investigation of why overparameterization exacerbates spurious correlations},
  author={Sagawa, Shiori and Raghunathan, Aditi and Koh, Pang Wei and Liang, Percy},
  booktitle={International Conference on Machine Learning},
  year={2020}
}
@article{lecun1998gradient,
  title={Gradient-based learning applied to document recognition},
  author={LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick},
  journal={Proceedings of the IEEE},
  year={1998}
}
@article{krizhevsky2009learning,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and Hinton, Geoffrey and others},
  year={2009},
  publisher={Toronto, ON, Canada}
}
@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={IEEE conference on computer vision and pattern recognition},
  year={2016}
}
@book{vershynin2018high,
  title={High-dimensional probability: An introduction with applications in data science},
  author={Vershynin, Roman},
  year={2018}
}
@book{hastie2009elements,
  title={The elements of statistical learning: data mining, inference, and prediction},
  author={Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome H and Friedman, Jerome H},
  year={2009},
  publisher={Springer}
}