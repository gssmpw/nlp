\section{Related Work}
\label{sec:related}

\paragraph{Tool-Augmented LLMs.}
A promising direction for enhancing large language models (LLMs) involves offloading specialized subtasks to external tools such as search engines ____, web browsers ____, calculators ____, translation systems ____, or Python interpreters ____. Broadly, these methods either rely on large-scale fine-tuning or human supervision to teach LLMs how to invoke tools ____ or use few-shot prompts for single tools in narrowly defined tasks ____. In contrast, \model is a \emph{training-free} framework that integrates diverse tools through standardized \emph{tool cards} and employs a planner-executor paradigm to manage multi-step reasoning. Because new tools can be introduced without re-training, \model offers a more \emph{extensible} and \emph{modular} approach to tool usage. 

\paragraph{LLM Agents.} A growing body of work leverages LLMs as autonomous agents that make decisions and invoke tools in multi-step workflows. Some agents use closed-source models with hand-engineered prompts ____, while others fine-tune LLMs on curated data that learn when and how to call tools ____. These frameworks often face limitations. For example, although specialized agent frameworks achieve strong performance in particular domains (e.g., chemistry ____, vision ____, materials science ____, or medical imaging ____), they typically lack generality across diverse tasks. Additionally, some systems are constrained by narrow capabilities with static planning ____ and multi-step reasoning ____. Recently, general-purpose agent platforms such as \autogen ____, \gptplugin ____, and \langchain ____ have emerged, but they have seen less emphasis on complex reasoning and rigorous benchmarking across diverse downstream tasks. In contrast, \model combines the flexibility of such platforms with a dedicated planner and executor to handle multi-step decision-making. 


\paragraph{Complex Task Reasoning.}
When faced with multi-step problems, a common strategy is to break down a question into simpler sub-questions and solve them step by step. Early work approached decomposition with unsupervised or weakly supervised models ____, and more recent research has explored prompting techniques for step-by-step reasoning, including Chain-of-Thought ____, Least-to-Most ____, ReAct ____, Pearl ____, Forest-of-Thought ____, and rStar-Math____. While these methods significantly improve LLMsâ€™ single-model reasoning capabilities, they primarily rely on the latent capacity of an LLM without external validation or targeted tool usage. In contrast, \model systematically combines multi-step decomposition (via an iterative planner) with specialized tools (encapsulated by \emph{tool cards}) and an executor for reliable, context-aware function calling. This design makes it easy to incorporate domain-specific functionalities and check intermediate steps with external modules, thus improving both correctness and versatility in tackling challenging tasks.