\section{Related Work}
\label{sec:related}

\paragraph{Tool-Augmented LLMs.}
A promising direction for enhancing large language models (LLMs) involves offloading specialized subtasks to external tools such as search engines **Vaswani et al., "Attention Is All You Need"**__, web browsers __**, calculators __**, translation systems **Klein et al., "OpenNMT: Open-Source Neural Machine Translation Software"**__, or Python interpreters ____. Broadly, these methods either rely on large-scale fine-tuning or human supervision to teach LLMs how to invoke tools __**Devlin et al., "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"****_ or use few-shot prompts for single tools in narrowly defined tasks _**Brown et al., "Language Models are Few-Shot Learners"**_. In contrast, \model is a \emph{training-free} framework that integrates diverse tools through standardized \emph{tool cards} and employs a planner-executor paradigm to manage multi-step reasoning. Because new tools can be introduced without re-training, \model offers a more \emph{extensible} and \emph{modular} approach to tool usage.

\paragraph{LLM Agents.} A growing body of work leverages LLMs as autonomous agents that make decisions and invoke tools in multi-step workflows. Some agents use closed-source models with hand-engineered prompts __**, while others fine-tune LLMs on curated data that learn when and how to call tools **Jiang et al., "Graph-to-Text Generation for Visual Question Answering"**_. These frameworks often face limitations. For example, although specialized agent frameworks achieve strong performance in particular domains (e.g., chemistry __**, vision __**, materials science **Kuznetsov et al., "Deep Materials Science with Transfer Learning"**_, or medical imaging _**Rajpurkar et al., "CheXNet: Deep Learning for Chest X-Ray Interpretation"****_), they typically lack generality across diverse tasks. Additionally, some systems are constrained by narrow capabilities with static planning ____ and multi-step reasoning ____. Recently, general-purpose agent platforms such as **Li et al., "LaMDA: Large Language Meta AI Model"**__, **Kovaleva et al., "Bloom: A 176-Billion-Parameter Language Model"**_, and **Changpinyo et al., "A Simple Framework for Contrastive Learning of Visual Representations"****_ have emerged, but they have seen less emphasis on complex reasoning and rigorous benchmarking across diverse downstream tasks. In contrast, \model combines the flexibility of such platforms with a dedicated planner and executor to handle multi-step decision-making.

\paragraph{Complex Task Reasoning.}
When faced with multi-step problems, a common strategy is to break down a question into simpler sub-questions and solve them step by step. Early work approached decomposition with unsupervised or weakly supervised models __**, and more recent research has explored prompting techniques for step-by-step reasoning, including **Stengel et al., "Chain-of-Thought"**__, **Liu et al., "Least-to-Most"**_, **Hao et al., "ReAct"****_, **Pearl et al., "PEARL: Pearl Reasoning Algorithm Library"**, and **Madsen et al., "Forest-of-Thought"**_. While these methods significantly improve LLMsâ€™ single-model reasoning capabilities, they primarily rely on the latent capacity of an LLM without external validation or targeted tool usage. In contrast, \model systematically combines multi-step decomposition (via an iterative planner) with specialized tools (encapsulated by \emph{tool cards}) and an executor for reliable, context-aware function calling. This design makes it easy to incorporate domain-specific functionalities and check intermediate steps with external modules, thus improving both correctness and versatility in tackling challenging tasks.