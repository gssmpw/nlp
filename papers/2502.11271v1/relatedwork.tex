\section{Related Work}
\label{sec:related}

\paragraph{Tool-Augmented LLMs.}
A promising direction for enhancing large language models (LLMs) involves offloading specialized subtasks to external tools such as search engines \citep{komeili-etal-2022-internet, thoppilan2022lamda, lazaridou2022internet, shuster2022blenderbot, yao2022react}, web browsers \citep{nakano2021webgpt}, calculators \citep{cobbe2021training, thoppilan2022lamda}, translation systems \citep{thoppilan2022lamda}, or Python interpreters \citep{gao2023pal}. Broadly, these methods either rely on large-scale fine-tuning or human supervision to teach LLMs how to invoke tools \citep{schick2023toolformer, komeili-etal-2022-internet, nakano2021webgpt, thoppilan2022lamda} or use few-shot prompts for single tools in narrowly defined tasks \citep{yao2022react, lazaridou2022internet, gao2023pal}. In contrast, \model is a \emph{training-free} framework that integrates diverse tools through standardized \emph{tool cards} and employs a planner-executor paradigm to manage multi-step reasoning. Because new tools can be introduced without re-training, \model offers a more \emph{extensible} and \emph{modular} approach to tool usage. 

\paragraph{LLM Agents.} A growing body of work leverages LLMs as autonomous agents that make decisions and invoke tools in multi-step workflows. Some agents use closed-source models with hand-engineered prompts \citep{chen2023llava, wang2024mobile}, while others fine-tune LLMs on curated data that learn when and how to call tools \cite{liu2023llava, tao2023webwise, zhang2024toolbehonest}. These frameworks often face limitations. For example, although specialized agent frameworks achieve strong performance in particular domains (e.g., chemistry \citep{bran2023chemcrow}, vision \citep{li2024mmedagent, hu2024visual}, materials science \citep{kang2024chatmof}, or medical imaging \citep{schmidgall2024agentclinic}), they typically lack generality across diverse tasks. Additionally, some systems are constrained by narrow capabilities with static planning ~\cite{lu2023chameleon} and multi-step reasoning \citep{hu2024visual}. Recently, general-purpose agent platforms such as \autogen \citep{autogen}, \gptplugin \citep{gpt4oplugin}, and \langchain \citep{langchain} have emerged, but they have seen less emphasis on complex reasoning and rigorous benchmarking across diverse downstream tasks. In contrast, \model combines the flexibility of such platforms with a dedicated planner and executor to handle multi-step decision-making. 


\paragraph{Complex Task Reasoning.}
When faced with multi-step problems, a common strategy is to break down a question into simpler sub-questions and solve them step by step. Early work approached decomposition with unsupervised or weakly supervised models \citep{perez2020unsupervised, khot2022decomposed}, and more recent research has explored prompting techniques for step-by-step reasoning, including Chain-of-Thought \citep{wei2022chain}, Least-to-Most \citep{zhou2022least}, ReAct \citep{yao2022react}, Pearl \citep{sun2023pearl}, Forest-of-Thought \citep{bi2024forest}, and rStar-Math\citep{guan2025rstar}. While these methods significantly improve LLMsâ€™ single-model reasoning capabilities, they primarily rely on the latent capacity of an LLM without external validation or targeted tool usage. In contrast, \model systematically combines multi-step decomposition (via an iterative planner) with specialized tools (encapsulated by \emph{tool cards}) and an executor for reliable, context-aware function calling. This design makes it easy to incorporate domain-specific functionalities and check intermediate steps with external modules, thus improving both correctness and versatility in tackling challenging tasks.