\begin{table}[t]
    \centering
    \caption{Percentage accuracy for task recognition (TR), step recognition (SR), and step forecasting (SF) within the COIN and CrossTask datasets across different pre-training methods. All methods were pre-trained on the same subset of 30k videos. Best performances are in \textbf{bold} while runner-ups are \underline{underlined}.}
    \begin{tabular}{c c c c|c c c|c c c}
        \multirow{2}{*}{Method} & Pre-Training & Task & Step & \multicolumn{3}{|c|}{COIN} & \multicolumn{3}{|c}{CrossTask} \\
        & Architecture & Loss & Loss & SF & SR & TR & SF & SR & TR \\
        \hline
        MIL-NCE & - & & & 36.87 & 38.73 & 78.30 & 58.07 & 57.70 & 89.43 \\
        Paprika & MLP & \yes & \yes & \underline{42.54} & 45.57 & 84.40 & 59.49 & 60.01 & 93.90 \\
        \hline
        LwDS (SC) & \multirow{4}{*}{Transformer} & & \yes & 37.05 & 43.42 & 81.02 & 59.49 & 59.84 & 92.07 \\
        LwDS (DM) & & & \yes & 40.60 & \underline{48.41} & 85.39 & 61.04 & 61.31 & 94.31 \\
        VideoTF (SC) & & & \yes & 37.74 & 42.05 & 84.12 & 57.95 & 57.58 & 94.11 \\
        VideoTF (DM) & & & \yes & 37.35 & 38.08 & 84.87 & 59.28 & 60.06 & \textbf{94.92} \\
        \hline
        \multirow{2}{*}{\model{} (Ours)} & \multirow{2}{*}{Transformer} & \yes & & 42.31 & 46.78 & \underline{86.70} & \textbf{62.18} & \underline{62.20} & 94.72 \\
        & & \yes & \yes & \textbf{42.68} & \textbf{49.89} & \textbf{87.42} & \underline{62.00} & \textbf{62.62} & \textbf{94.92} \\
    \end{tabular}
    \label{tab:baselines}
\end{table}