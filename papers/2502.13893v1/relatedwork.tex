\section{Related Work}
While some researchers have been using image-based insect identification and some researchers have been using acoustic data for person identification \cite{dibbo2022phone, cheung2020continuous}, respiratory disease monitoring \cite{vhaduri2019towards, dibbo2021effect}, sleep health monitoring \cite{vhaduri2020nocturnal, vhaduri2018impact, chen2020estimating}, mental health and well-being management \cite{kim2020understanding, vhaduri2021deriving, vhaduri2021predicting}, insect identification from acoustic data did not receive much attention in the past. Recently, the classification of insect species using audio signals has gained increasing attention due to its potential in ecological monitoring and pest management. Previous studies have explored various methodologies for feature extraction, machine learning models, and dataset preparation to achieve accurate classification.

Acoustic signal analysis has been a core area of focus. Unique sounds produced by insects, such as chirps or stridulations, are distinct identifiers for species. Traditional approaches often use Mel Frequency Cepstral Coefficients (MFCCs) to represent these sounds. However, recent studies have highlighted the limitations of MFCCs for high-frequency insect signals, leading to the exploration of alternative techniques such as Linear Frequency Cepstral Coefficients (LFCCs) and adaptive waveform-based methods like LEAF. A notable example demonstrated the effectiveness of fusing MFCCs and LFCCs, achieving classification accuracy of up to 98.07\% for over 300 species \cite{acoustic_insect_mfcc_lfcc,adaptive_insect_classification}.

Deep learning has also contributed significantly to bioacoustics. Techniques such as Convolutional Neural Networks (CNNs) and EfficientNet have shown promise in extracting both spectral and temporal features. The Dual-Frequency and Spectral Fusion Module (DFSM), in particular, enhances accuracy by capturing intricate insect sound characteristics. These methods are vital for processing large datasets and overcoming challenges like noise and overlapping signals \cite{adaptive_insect_classification,dfsm_insect_classification}.

Traditional machine learning models, such as Random Forest and Support Vector Machines (SVM), continue to play an essential role in small-scale datasets or scenarios requiring explainable models. These models often rely on handcrafted features such as MFCCs and STFT-based spectrograms, which effectively capture key characteristics of insect sounds \cite{dfsm_insect_classification,ml_insect_bioacoustics}.

The availability of diverse and annotated datasets has been pivotal in advancing this field. Studies have emphasized the importance of high-quality datasets, such as the curated collections of insect sounds from orthopteran species and bioacoustic datasets like ESC-50. These datasets provide critical resources for training and validating models in real-world applications, ranging from biodiversity studies to agricultural pest control \cite{acoustic_insect_mfcc_lfcc,ml_insect_bioacoustics,framework_insect_sound_analysis}.

While significant progress has been made in the field of audio-based insect classification, many existing methods focus on either limited species or lack the integration of diverse feature extraction techniques and machine learning models. Our work aims to bridge these gaps by combining Mel Frequency Cepstral Coefficients (MFCCs), and advanced models such as XGBoost and Random Forest. By leveraging these techniques, our approach seeks to capture subtle acoustic variations and improve classification accuracy. This work has the potential to enhance automated insect monitoring systems, contributing to more efficient ecological monitoring, biodiversity assessment, and pest management strategies.