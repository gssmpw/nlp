\section{Related work}
Guiding generative models with intermediate steps has been widely explored to enhance coherence, interpretability, and task performance. Existing approaches can be categorized into explicit human-readable intermediate steps, and structured weakly supervised intermediate steps.

\paragraph{Human readable intermediate steps}
Plan-and-Write **Li et al., "Storytelling with Joint Plot Planning"** introduces storyline-based planning, where a model first generates a structured sequence of key events before expanding them into a full story, improving coherence and creativity. %In summarization, 
**Vig et al., "Improving Abstractive Summarization by Revisiting Content Planning"**, ____ employ content planning, explicitly modelling aspect and sentiment distributions to guide summary generation, thereby enhancing readability and informativeness.

Similarly, **Saeidi et al., "Question Decomposition Meaning Representations (QDMR) for Text-to-SQL Parsing"** propose Question Decomposition Meaning Representations (QDMR), which break down complex questions into sequences of reasoning steps. These decompositions serve as an explicit intermediate representation, improving interpretability and guiding Text-to-SQL parsing by systematically mapping natural language queries to SQL.
**Bajgar et al., "Story Generation with a Sequence-to-Sequence-to-Sequence Model (SEQ³)"**  introduce a sequence-to-sequence-to-sequence model (SEQ³), where the intermediate step is a compressed version of the input sentence, explicitly represented in natural language. 


% Other works rely on latent representations, where intermediate steps remain internal to the model rather than explicitly interpretable. ____ ____ introduce reversible latent structures to improve compositional generalization, but these representations do not correspond to explicit human-understandable reasoning steps. 




\paragraph{Structured intermediate steps}
Some models introduce structured but weakly supervised intermediate steps, where the intermediate representations are partially interpretable but not explicitly labelled during training. **Andreas et al., "Neural Semantic Parsing"** generate predicate-argument structures, which serve as an intermediate step in semantic parsing. Unlike explicit intermediate representations, these structures are learned through optimization-based search rather than direct supervision.
Similarly, **Rajani et al., "Label Aligned Graphs (LAGr) for Compositional Generalization"** propose Label Aligned Graphs (LAGr), where models predict node and edge labels to construct structured meaning representations aligned with input text, improving systematic generalization in semantic parsing. These representations enhance compositional generalization but still depend on predefined structural mappings.
**Kampmann et al., "Intermediate Representations for Compositional Generalization"** introduce intermediate representations that transform meaning representations (e.g., SPARQL or SQL queries) into structured forms that improve compositional generalization while maintaining reversibility. 
While these methods balance interpretability and generalization, they still rely on task-specific constraints rather than fully flexible intermediate representations.

\paragraph{Reinforcement learning in NLP}
RL has also been applied in NLP to optimize model generation beyond traditional supervised learning for text summarization**Kumar et al., “Deep Reinforcement Learning for Text Summarization”**, dialogue generation **Li et al., "Adversarial Dialogue Generation"** and machine translation **Sutskever et al., "Sequence to Sequence Learning with Neural Networks"**. More recently, Reinforcement Learning from Human Feedback (RLHF) **Bartlett et al., "Reinforcement Learning from Human Feedback for Language Translation"** has been instrumental in aligning large-scale language models with human preferences, demonstrating the effectiveness of RL-based fine-tuning. While RL provides a strong optimization framework, it does not inherently generate structured intermediate representations, instead refining model behaviour through reward-based learning.


% While these methods show that intermediate steps improve performance, they either depend on predefined structured constraints or lack interpretability, making them less adaptable across tasks.

% More recently, researchers have explored self-supervised approaches to autonomously learn intermediate steps without human annotations. ____ ____ propose self-reinforcement learning, where models iteratively generate and refine synthetic intermediate data to improve performance. However, such approaches still depend on task-specific setups or external reward signals, constraining their generalizability.

%In contrast, our 
In this paper, we learn intermediate steps freely, without predefined formats, constraints, search procedures, external supervision, annotated datasets or task-specific designs.
Inspired by RL principles, our method integrates intermediate step/initial state generation and final output optimization into a unified framework. 
Our approach generalizes across tasks such as translation, summarization, and multi-choice question answering logical reasoning, and architectures, providing a flexible, scalable, and theoretically grounded solution for improving the quality of generation.


% Guiding generative models with intermediate steps, such as keywords, outlines, or reasoning chains, has been extensively studied across various domains to improve task performance, coherence, and interpretability. Early work, such as **Keller et al., "Controllable Text Generation"**, introduced controllable text generation by leveraging control codes to guide the generation process. These approaches demonstrated the utility of external guidance in producing coherent and contextually relevant outputs. Similarly, Plan-and-Write **Li et al., “Storytelling with Joint Plot Planning”** emphasized hierarchical planning in story generation by generating a sequence of keywords as an intermediate step before crafting the full narrative, enhancing both creativity and coherence.

% The use of intermediate steps extends beyond story generation. In summarization, **Vig et al., "Improving Abstractive Summarization by Revisiting Content Planning"** (____) proposed RL-based methods to optimize abstractive summaries by generating intermediate representations. These efforts showcased how intermediate structures could bridge input and output for more accurate and interpretable outputs. Similarly, ____ employed content planning for unsupervised opinion summarization, organizing key elements into structured summaries that maintain coherence and relevance.

% In reasoning tasks, the advent of COT prompting  **Kim et al., “COT: A Prompt-Based Reasoning Framework”** highlighted the importance of intermediate logical reasoning steps. While COT focuses on prompt-based reasoning, fine-tuning approaches such as ____ (____) demonstrated how incorporating intermediate steps during training improves model interpretability and task performance. These efforts underscore the general utility of intermediate steps but often rely on predefined formats and annotated datasets, which limit scalability.

% More recent works explore the autonomous generation of intermediate steps. For instance, self-reinforcement methods, such as ____ (____), allow models to iteratively generate and refine synthetic data or guiding contexts without requiring human intervention. These approaches align with RL principles, emphasizing iterative optimization to enhance performance. However, these methods still often depend on specific task setups or external rewards, constraining their generalizability.

% Several studies have explored intermediate representations in sequence-to-sequence learning, often relying on structured latent variables. ____ (2017) used an optimization-based search process, where the model generates a latent predicate-argument structure and iterates over possible representations to maximize final output accuracy. ____ (2021) enforced reversible intermediate representations in pre-trained models, ensuring compositional generalization but requiring explicitly defined mappings. ____ (2019) proposed a sequence-to-sequence-to-sequence autoencoder, where an intermediate compressed representation is learned for sentence compression using an explicit autoencoding objective.

% In contrast, our method learns intermediate steps freely, without predefined constraints, search procedures, or external supervision, making it more flexible and adaptable across tasks like summarization, translation, and reasoning.

% In contrast, we introduce a task-agnostic framework that enables models to generate and optimize intermediate steps, or the initial states without relying on predefined formats or external supervision. Inspired by RL principles, our method integrates intermediate step/initial state generation and final output optimization into a unified framework. Unlike prior work that depends on annotated datasets or task-specific designs, our approach generalizes across tasks such as translation, summarization, and multi-choice question answering for both reading comprehension and logical reasoning, and architectures, providing a flexible, scalable, and theoretically grounded solution for improving the quality of generation.
% both training and inference.