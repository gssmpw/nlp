\section{Related Work}
\vspace{-1em}
\textbf{Graph self-supervised methods.} Leveraging the inherent graph structure of molecules, many graph-based self-supervised methods have the potential to train molecular models that capture transferable knowledge. For example, ____ proposed graph context prediction and attribute masking methods to enhance molecular property prediction. GraphMAE ____ pre-trained molecular models using a generative decoder to reconstruct atomic and bond attributes. D-SLA ____ applied contrastive learning based on graph edit distance, improving predictions of molecular biochemical activities. Additionally, graph motifs—induced subgraphs that describe recurrence and significance—have increasingly been utilized to construct self-supervised learning frameworks for molecules ____, facilitating the learning of multi-scale molecular information. These pre-training methods primarily focus on graph characteristics, while neglecting the intrinsic quantum mechanisms within molecules. As a result, they are limited in their ability to predict molecular quantum mechanical properties. 

% However, despite their improvements in property prediction, these pre-training methods primarily focus on graph characteristics, such as geometric semantics and graph-level similarity, while neglecting the intrinsic quantum mechanisms within molecules. As a result, they are limited in their ability to predict molecular quantum mechanical properties. 

% In this work, we propose EMPP, which introduces physical priors into learning tasks, enabling GNN models to capture key quantum mechanical features.

\textbf{3D molecular representation.} Given the strong correlation between the quantum characteristics of molecules and their 3D structures, recent molecular models have increasingly focused on 3D representations ____. As a result, self-supervised techniques have also evolved to operate in 3D space. For instance, Unimols ____ masked atomic properties and restored them using 3D molecular models, while denoising methods ____ introduced a series of physics-informed pre-training paradigms. We provide a detailed discussion of these methods in Section \ref{sec:revisit} and highlight their main limitation: accurately defining the parameters of Gaussian mixture distributions can be challenging. In contrast, EMPP learns quantum mechanical features through a position prediction process, effectively bypassing the difficulties associated with denoising methods.
% across a broader chemical space, improving the model's generalization capability.


\textbf{Spherical harmonics projection.} High-degree spherical harmonic representations with grid projections ____ have demonstrated significant capabilities in spatial description. Building on this, Symphony ____ introduced a neighbor-based spatial position prediction method, developing a framework for molecular generation. While EMPP shares some technical similarities with Symphony, their distinct tasks (molecular generation versus self-supervised learning) lead to differing implementation priorities. Symphony prioritizes flexibility in position prediction to ensure the sampling of diverse molecules, whereas EMPP emphasizes accuracy and well-posed position prediction to facilitate learning of genuine physical interactions.



\vspace{-1em}