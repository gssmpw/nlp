[
  {
    "index": 0,
    "papers": [
      {
        "key": "dwork2012awareness",
        "author": "Cynthia Dwork and Moritz Hardt and Toniann Pitassi and Omer Reingold and Rich Zemel",
        "title": "Fairness Through Awareness"
      },
      {
        "key": "hardt2016eqopp",
        "author": "Moritz Hardt and Eric Price and Nathan Srebro",
        "title": "Equality of Opportunity in Supervised Learning"
      },
      {
        "key": "lipton2018treatmentdisparity",
        "author": "Zachary C. Lipton and Alexandra Chouldechova and Julian McAuley",
        "title": "Does mitigating ML's impact disparity require treatment disparity?"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "rottger2024safetyprompts",
        "author": "Paul R\u00f6ttger and Fabio Pernisi and Bertie Vidgen and Dirk Hovy",
        "title": "SafetyPrompts: a Systematic Review of Open Datasets for Evaluating and Improving Large Language Model Safety"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "gallegos2023llmsurvey",
        "author": "Isabel O. Gallegos and Ryan A. Rossi and Joe Barrow and Md Mehrab Tanjim and Sungchul Kim and Franck Dernoncourt and Tong Yu and Ruiyi Zhang and Nesreen K. Ahmed",
        "title": "Bias and Fairness in Large Language Models: A Survey"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "gupta2024calm",
        "author": "Vipul Gupta and Pranav Narayanan Venkit and Hugo Lauren\u00e7on and Shomir Wilson and Rebecca J. Passonneau",
        "title": "{CALM}: A Multi-task Benchmark for Comprehensive Assessment of Language Model Bias"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "smith2022holistic",
        "author": "Eric Michael Smith and Melissa Hall and Melanie Kambadur and Eleonora Presani and Adina Williams",
        "title": "\"I'm sorry to hear that\": Finding New Biases in Language Models with a Holistic Descriptor Dataset"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "liang2023helm",
        "author": "Percy Liang and Rishi Bommasani and Tony Lee and Dimitris Tsipras and Dilara Soylu and Michihiro Yasunaga and Yian Zhang and Deepak Narayanan and Yuhuai Wu and Ananya Kumar and Benjamin Newman and Binhang Yuan and Bobby Yan and Ce Zhang and Christian Cosgrove and Christopher D. Manning and Christopher R\u00e9 and Diana Acosta-Navas and Drew A. Hudson and Eric Zelikman and Esin Durmus and Faisal Ladhak and Frieda Rong and Hongyu Ren and Huaxiu Yao and Jue Wang and Keshav Santhanam and Laurel Orr and Lucia Zheng and Mert Yuksekgonul and Mirac Suzgun and Nathan Kim and Neel Guha and Niladri Chatterji and Omar Khattab and Peter Henderson and Qian Huang and Ryan Chi and Sang Michael Xie and Shibani Santurkar and Surya Ganguli and Tatsunori Hashimoto and Thomas Icard and Tianyi Zhang and Vishrav Chaudhary and William Wang and Xuechen Li and Yifan Mai and Yuhui Zhang and Yuta Koreeda",
        "title": "Holistic Evaluation of Language Models"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "dhamala2021bold",
        "author": "Jwala Dhamala and Tony Sun and Varun Kumar and Satyapriya Krishna and Yada Pruksachatkun and Kai-Wei Chang and Rahul Gupta",
        "title": "{BOLD}: Dataset and metrics for measuring biases in open-ended language generation"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "tamkin2023discrimeval",
        "author": "Alex Tamkin and Amanda Askell and Liane Lovitt and Esin Durmus and Nicholas Joseph and Shauna Kravec and Karina Nguyen and Jared Kaplan and Deep Ganguli",
        "title": "Evaluating and Mitigating Discrimination in Language Model Decisions"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "liang2023helm",
        "author": "Percy Liang and Rishi Bommasani and Tony Lee and Dimitris Tsipras and Dilara Soylu and Michihiro Yasunaga and Yian Zhang and Deepak Narayanan and Yuhuai Wu and Ananya Kumar and Benjamin Newman and Binhang Yuan and Bobby Yan and Ce Zhang and Christian Cosgrove and Christopher D. Manning and Christopher R\u00e9 and Diana Acosta-Navas and Drew A. Hudson and Eric Zelikman and Esin Durmus and Faisal Ladhak and Frieda Rong and Hongyu Ren and Huaxiu Yao and Jue Wang and Keshav Santhanam and Laurel Orr and Lucia Zheng and Mert Yuksekgonul and Mirac Suzgun and Nathan Kim and Neel Guha and Niladri Chatterji and Omar Khattab and Peter Henderson and Qian Huang and Ryan Chi and Sang Michael Xie and Shibani Santurkar and Surya Ganguli and Tatsunori Hashimoto and Thomas Icard and Tianyi Zhang and Vishrav Chaudhary and William Wang and Xuechen Li and Yifan Mai and Yuhui Zhang and Yuta Koreeda",
        "title": "Holistic Evaluation of Language Models"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "tamkin2023discrimeval",
        "author": "Alex Tamkin and Amanda Askell and Liane Lovitt and Esin Durmus and Nicholas Joseph and Shauna Kravec and Karina Nguyen and Jared Kaplan and Deep Ganguli",
        "title": "Evaluating and Mitigating Discrimination in Language Model Decisions"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "sheng2019babysitter",
        "author": "Emily Sheng and Kai-Wei Chang and Premkumar Natarajan and Nanyun Peng",
        "title": "The Woman Worked as a Babysitter: On Biases in Language Generation"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "huang2023trustgpt",
        "author": "Yue Huang and Qihui Zhang and Philip S. Y and Lichao Sun",
        "title": "{TrustGPT}: A Benchmark for Trustworthy and Responsible Large Language Models"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "huang2023trustgpt",
        "author": "Yue Huang and Qihui Zhang and Philip S. Y and Lichao Sun",
        "title": "{TrustGPT}: A Benchmark for Trustworthy and Responsible Large Language Models"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "kirk2021biasoutofbox",
        "author": "Hannah Kirk and Yennie Jun and Haider Iqbal and Elias Benussi and Filippo Volpin and Frederic A. Dreyer and Aleksandar Shtedritski and Yuki M. Asano",
        "title": "Bias Out-of-the-Box: An Empirical Analysis of Intersectional Occupational Biases in Popular Generative Language Models"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "ovalle2023fullywhoiam",
        "author": "Anaelia Ovalle and Palash Goyal and Jwala Dhamala and Zachary Jaggers and Kai-Wei Chang and Aram Galstyan and Richard Zemel and Rahul Gupta",
        "title": "\u201cI\u2019m fully who I am\u201d: Towards Centering Transgender and Non-Binary Voices to Measure Biases in Open Language Generation"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "blodgett2020bias",
        "author": "Su Lin Blodgett and Solon Barocas and Hal Daum\u00e9 III and Hanna Wallach",
        "title": "Language (Technology) is Power: A Critical Survey of \u201cBias\u201d in NLP"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "goldfarbtarrant2023mask",
        "author": "Seraphina Goldfarb-Tarrant and Eddie Ungless and Esma Balkir and Su Lin Blodgett",
        "title": "This Prompt is Measuring <MASK>: Evaluating Bias Evaluation in Language Models"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "blodgett2021salmon",
        "author": "Su Lin Blodgett and Gilsinia Lopez and Alexandra Olteanu and Robert Sim and Hanna Wallach",
        "title": "Stereotyping Norwegian Salmon: An Inventory of Pitfalls in Fairness Benchmark Datasets"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "watsondaniels2024colorblind",
        "author": "Jamelle Watson-Daniels",
        "title": "Algorithmic Fairness and Color-blind Racism: Navigating the Intersection"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "lucy2024onesize",
        "author": "Li Lucy and Su Lin Blodgett and Milad Shokouhi and Hanna Wallach and Alexandra Olteanu",
        "title": "\"One-Size-Fits-All\"? Examining Expectations around What Constitute \"Fair\" or \"Good\" NLG System Behaviors"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "kantharuban2024stereopersonal",
        "author": "Anjali Kantharuban and Jeremiah Milbauer and Emma Strubell and Graham Neubig",
        "title": "Stereotype or Personalization? User Identity Biases Chatbot Recommendations"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "sotnikova2021stereo",
        "author": "Anna Sotnikova and Yang Trista Cao and Hal Daum\u00e9 III and Rachel Rudinger",
        "title": "Analyzing Stereotypes in Generative Text Inference Tasks"
      }
    ]
  },
  {
    "index": 22,
    "papers": [
      {
        "key": "wan2024factualitytax",
        "author": "Yixin Wan and Di Wu and Haoran Wang and Kai-Wei Chang",
        "title": "The Factuality Tax of Diversity-Intervened Text-to-Image Generation: Benchmark and Fact-Augmented Intervention"
      }
    ]
  },
  {
    "index": 23,
    "papers": [
      {
        "key": "goldfarbtarrant2023mask",
        "author": "Seraphina Goldfarb-Tarrant and Eddie Ungless and Esma Balkir and Su Lin Blodgett",
        "title": "This Prompt is Measuring <MASK>: Evaluating Bias Evaluation in Language Models"
      }
    ]
  },
  {
    "index": 24,
    "papers": [
      {
        "key": "blodgett2021salmon",
        "author": "Su Lin Blodgett and Gilsinia Lopez and Alexandra Olteanu and Robert Sim and Hanna Wallach",
        "title": "Stereotyping Norwegian Salmon: An Inventory of Pitfalls in Fairness Benchmark Datasets"
      }
    ]
  }
]