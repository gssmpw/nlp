\revision{
\subsection{Loss Function}
\label{loss_function}
\ourmethod is trained by minimizing the binary cross entropy loss over positive and negative triplets.

For entity prediction, the loss function is:
$$\text{Loss} = -\log p(h, r, t) - \sum\limits_{i=1}^{n} \frac{1}{n} \log(1 - p(h_i^\prime, r, t_i^\prime))$$
where ($h, r, t$) is the positive triplet and ($h_i^\prime, r, t_i^\prime$) is a negative triplet by corrupting the head or the tail. $n$ is the number of negative triplets per positive triplet.

For relation prediction, the loss function is:
$$\text{Loss} = -\log p(h, r, t) - \sum\limits_{i=1}^{n} \frac{1}{n} \log(1 - p(h, r_i^\prime, t))$$
where ($h, r, t$) is the positive triplet and ($h, r_i^\prime, t$) is a negative triplet by corrupting the relation. $n$ is the number of negative triplets per positive triplet.
}

\subsection{Ablation Study}
We conducted multiple experiments to gain deeper insights into the pre-training quality of \ourmethod and to quantify the impact of the proposed adjacency matrix and the iterative updating scheme on its performance. \revision{We compare the performance of (1) \ourmethod, (2) \ourmethod without iterative updates, and (3) \ourmethod without iterative updates and without our relation graph (using the relation graph of ULTRA).} We can not do test \ourmethod w/o proposed relation graph and w/ iterative updates because \revision{iterative updates are impossible with the prior relation graphs since entities are not included as edges connecting relations in prior relation graphs and thus the message passing on prior relation graphs would not use the entity embeddings}. The data presented in Table \ref{ablation} clearly demonstrates that both the proposed relation graph and the iterative update scheme significantly enhance the prediction performance.

\begin{table*}[t]
\centering
\caption{Zero-shot entity prediction results of \ourmethod, \ourmethod without proposed relation graph and \ourmethod without iterative update scheme.}
\label{ablation}
\begin{tabular}{lcc}
\toprule
 & MRR & Hits@10 \\
 \midrule
\ourmethod w/o proposed relation graph and w/o iterative updates & 0.356  & 0.508  \\
\ourmethod w/ proposed relation graph and w/o iterative updates & 0.361 & 0.518 \\
\ourmethod & \textbf{0.390} & \textbf{0.548} \\
\bottomrule
\end{tabular}
\end{table*}

\subsection{Detailed Results}
\Cref{entity_app} shows an an overview of \ourmethod performance improvement compared with ULTRA. \Cref{tab:app_zero_shot_ent} shows detailed zero-shot entity prediction MRR and Hits@10.  \Cref{tab:app_fine_tune_ent} shows detailed fine-tuned entity prediction MRR and Hits@10. \Cref{tab:app_zero_shot_rel} shows detailed zero-shot relation prediction MRR and Hits@1.  \Cref{tab:app_fine_tune_rel} shows detailed fine-tuned relation prediction MRR and Hits@1. From these tables we can conclude \ourmethod outperforms the baseline model in both entity and relation prediction. 

\begin{table*}[t]
\centering
\caption{An overview of \ourmethod performance improvement compared with ULTRA.}
\label{entity_app}
\begin{tabular}{lrrrr}
\toprule
Task & \multicolumn{2}{c}{Entity} & \multicolumn{2}{c}{Relation}  \\
\midrule
Improvement & zero-shot & finetuned & zero-shot & finetuned\\
\midrule
-2\% and below & 4 & 3 & 8 & 12 \\
-2\% to 0\%& 9 & 19 & 2 & 3 \\
0\% to 2\% & 15 & 24 & 6 & 7 \\
2\% and above & 26 & 11 & 38 & 35 \\ \midrule
Total & 54 & 57 & 54 & 57 \\
\bottomrule
\end{tabular}
\end{table*}

\begin{table*}[t]
\centering
\caption{Zero-shot entity prediction MRR and Hits@10 over 57 KGs from distinct domains.}
\label{tab:app_zero_shot_ent}
\begin{tabular}{lccccc}
\toprule
Dataset & ULTRA MRR & \ourmethod MRR & ULTRA Hits@10 & \ourmethod Hits@10 \\
\midrule
CoDEx Small & \textbf{0.472} & \textbf{0.472} & 0.667 & \textbf{0.670} \\
CoDEx Large & \textbf{0.338} & 0.335 & \textbf{0.469} & \textbf{0.469} \\
NELL-995 & 0.406 & \textbf{0.472} & 0.543 & \textbf{0.629} \\
YAGO 310 & \textbf{0.451} & 0.409 & 0.615 & \textbf{0.627} \\
WDsinger & 0.382 & \textbf{0.511} & 0.498 & \textbf{0.609} \\
NELL23k & 0.239 & \textbf{0.290} & 0.408 & \textbf{0.497} \\
FB15k237\_10 & \textbf{0.248} & 0.246 & \textbf{0.398} & 0.393 \\
FB15k237\_20 & \textbf{0.272} & 0.269 & \textbf{0.436} & 0.430 \\
FB15k237\_50 & \textbf{0.324} & 0.321 & \textbf{0.526} & 0.521 \\
DBpedia100k & 0.398 & \textbf{0.426} & 0.576 & \textbf{0.603} \\
AristoV4 & \textbf{0.182} & 0.181 & 0.282 & \textbf{0.286} \\
ConceptNet100k & 0.082 & \textbf{0.193} & 0.162 & \textbf{0.345} \\
Hetionet & 0.257 & \textbf{0.279} & 0.379 & \textbf{0.420} \\
FB-100 & \textbf{0.449} & 0.436 & \textbf{0.642} & 0.635 \\
FB-75 & \textbf{0.403} & 0.401 & 0.604 & \textbf{0.611} \\
FB-50 & \textbf{0.338} & 0.334 & 0.543 & \textbf{0.547} \\
FB-25 & 0.388 & \textbf{0.393} & 0.640 & \textbf{0.650} \\
WK-100 & 0.164 & \textbf{0.188} & 0.286 & \textbf{0.299} \\
WK-75 & 0.365 & \textbf{0.368} & \textbf{0.537} & 0.513 \\
WK-50 & \textbf{0.166} & \textbf{0.166} & \textbf{0.324} & 0.313 \\
WK-25 & \textbf{0.316} & 0.305 & \textbf{0.532} & 0.496 \\
NL-100 & 0.471 & \textbf{0.486} & 0.651 & \textbf{0.676} \\
NL-75 & \textbf{0.368} & 0.351 & \textbf{0.547} & 0.525 \\
NL-50 & \textbf{0.407} & 0.404 & \textbf{0.570} & 0.548 \\
NL-25 & \textbf{0.395} & 0.377 & 0.569 & \textbf{0.589} \\
NL-0 & 0.342 & \textbf{0.385} & 0.523 & \textbf{0.549} \\
HM 1k & 0.059 & \textbf{0.072} & 0.092 & \textbf{0.128} \\
HM 3k & 0.037 & \textbf{0.069} & 0.077 & \textbf{0.119} \\
HM 5k & 0.034 & \textbf{0.062} & 0.071 & \textbf{0.110} \\
HM Indigo & \textbf{0.440} & 0.436 & \textbf{0.648} & 0.645 \\
MT1 tax & 0.224 & \textbf{0.358} & 0.305 & \textbf{0.452} \\
MT1 health & 0.298 & \textbf{0.376} & 0.374 & \textbf{0.457} \\
MT2 org & \textbf{0.095} & 0.091 & \textbf{0.159} & 0.156 \\
MT2 sci & 0.258 & \textbf{0.323} & 0.354 & \textbf{0.465} \\
MT3 art & 0.259 & \textbf{0.284} & 0.402 & \textbf{0.441} \\
MT3 infra & 0.619 & \textbf{0.655} & 0.755 & \textbf{0.797} \\
MT4 sci & 0.274 & \textbf{0.290} & 0.449 & \textbf{0.460} \\
MT4 health & 0.624 & \textbf{0.677} & 0.737 & \textbf{0.775} \\
Metafam & 0.238 & \textbf{0.341} & 0.644 & \textbf{0.815} \\
FBNELL & \textbf{0.485} & 0.473 & 0.652 & \textbf{0.660} \\
WN-v1 & 0.648 & \textbf{0.699} & 0.768 & \textbf{0.791} \\
WN-v2 & 0.663 & \textbf{0.678} & 0.765 & \textbf{0.781} \\
WN-v3 & 0.376 & \textbf{0.418} & 0.476 & \textbf{0.541} \\
WN-v4 & 0.611 & \textbf{0.648} & 0.705 & \textbf{0.723} \\
FB-v1 & 0.498 & \textbf{0.515} & 0.656 & \textbf{0.682} \\
FB-v2 & 0.512 & \textbf{0.525} & 0.700 & \textbf{0.730} \\
FB-v3 & 0.491 & \textbf{0.501} & 0.654 & \textbf{0.669} \\
FB-v4 & 0.486 & \textbf{0.493} & 0.677 & \textbf{0.687} \\
NL-v1 & 0.785 & \textbf{0.806} & \textbf{0.913} & 0.898 \\
NL-v2 & 0.526 & \textbf{0.569} & 0.707 & \textbf{0.768} \\
NL-v3 & 0.515 & \textbf{0.558} & 0.702 & \textbf{0.743} \\
NL-v4 & 0.479 & \textbf{0.538} & 0.712 & \textbf{0.765} \\
ILPC Small & 0.302 & \textbf{0.303} & 0.443 & \textbf{0.455} \\
ILPC Large & 0.290 & \textbf{0.307} & 0.424 & \textbf{0.428} \\
\bottomrule
\end{tabular}
\end{table*}

\begin{table*}[t]
\centering
\caption{Finetuned entity prediction MRR and Hits@10 over 57 KGs from distinct domains.}
\label{tab:app_fine_tune_ent}
\begin{tabular}{lccccc}
\toprule
Dataset & ULTRA MRR & \ourmethod MRR & ULTRA Hits@10 & \ourmethod Hits@10 \\
\midrule
WN18RR &0.480 \tiny{± 0.000} &\textbf{0.514} \tiny{± 0.003} &\textbf{0.614} \tiny{± 0.000} &0.611 \tiny{± 0.005} \\
FB15K237 &\textbf{0.368} \tiny{± 0.000} &0.366 \tiny{± 0.002} &\textbf{0.564} \tiny{± 0.000} &0.559 \tiny{± 0.002} \\
CoDEx Medium &\textbf{0.372} \tiny{± 0.000} &0.365 \tiny{± 0.001} &\textbf{0.525} \tiny{± 0.000} &0.521 \tiny{± 0.001} \\
CoDEx Small &\textbf{0.490} \tiny{± 0.003} &0.484 \tiny{± 0.001} &\textbf{0.686} \tiny{± 0.003} &0.676 \tiny{± 0.003} \\
CoDEx Large &0.343 \tiny{± 0.002} &\textbf{0.348} \tiny{± 0.002} &0.478 \tiny{± 0.002} &\textbf{0.481} \tiny{± 0.002} \\
NELL-995 &\textbf{0.509} \tiny{± 0.013} &0.506 \tiny{± 0.030} &\textbf{0.660} \tiny{± 0.006} &0.648 \tiny{± 0.016} \\
YAGO 310 &\textbf{0.557} \tiny{± 0.009} &0.541 \tiny{± 0.050} &\textbf{0.710} \tiny{± 0.003} &0.702 \tiny{± 0.021} \\
WDsinger &0.417 \tiny{± 0.002} &\textbf{0.502} \tiny{± 0.001} &0.526 \tiny{± 0.002} &\textbf{0.620} \tiny{± 0.001} \\
NELL23k &0.268 \tiny{± 0.001} &\textbf{0.306} \tiny{± 0.010} &0.450 \tiny{± 0.001} &\textbf{0.536} \tiny{± 0.007} \\
FB15k237\_10 &\textbf{0.254} \tiny{± 0.001} &0.253 \tiny{± 0.001} &\textbf{0.411} \tiny{± 0.001} &0.408 \tiny{± 0.002} \\
FB15k237\_20 &\textbf{0.274} \tiny{± 0.001} &0.273 \tiny{± 0.001} &\textbf{0.445} \tiny{± 0.002} &0.441 \tiny{± 0.001} \\
FB15k237\_50 &\textbf{0.325} \tiny{± 0.002} &0.322 \tiny{± 0.001} &\textbf{0.528} \tiny{± 0.002} &0.522 \tiny{± 0.002} \\
DBpedia100k &0.436 \tiny{± 0.008} &\textbf{0.457} \tiny{± 0.026} &0.603 \tiny{± 0.006} &\textbf{0.619} \tiny{± 0.012} \\
AristoV4 &0.343 \tiny{± 0.006} &\textbf{0.345} \tiny{± 0.009} &0.496 \tiny{± 0.004} & \textbf{0.499} \tiny{± 0.010} \\
ConceptNet100k &0.310 \tiny{± 0.004} &\textbf{0.340} \tiny{± 0.008} &0.529 \tiny{± 0.007} &\textbf{0.564} \tiny{± 0.001} \\
Hetionet &\textbf{0.399} \tiny{± 0.005} &0.394 \tiny{± 0.004} &\textbf{0.538} \tiny{± 0.004} &0.534 \tiny{± 0.005} \\
WN-v1 &0.685 \tiny{± 0.003} &\textbf{0.705} \tiny{± 0.007} &0.793 \tiny{± 0.003} &\textbf{0.798} \tiny{± 0.005} \\
WN-v2 &0.679 \tiny{± 0.002} &\textbf{0.682} \tiny{± 0.004} &0.779 \tiny{± 0.003} &\textbf{0.780} \tiny{± 0.002} \\
WN-v3 &0.411 \tiny{± 0.008} &\textbf{0.425} \tiny{± 0.010} &\textbf{0.546} \tiny{± 0.006} &0.543 \tiny{± 0.006} \\
WN-v4 &0.614 \tiny{± 0.003} &\textbf{0.650} \tiny{± 0.002} &0.720 \tiny{± 0.001} &\textbf{0.722} \tiny{± 0.002} \\
FB-v1 &0.509 \tiny{± 0.002} &\textbf{0.515} \tiny{± 0.000} &0.670 \tiny{± 0.004} &\textbf{0.682} \tiny{± 0.000} \\
FB-v2 &0.524 \tiny{± 0.003} &\textbf{0.525} \tiny{± 0.000} &0.710 \tiny{± 0.004} &\textbf{0.730} \tiny{± 0.000} \\
FB-v3 &\textbf{0.504} \tiny{± 0.001} &0.501 \tiny{± 0.000} &0.663 \tiny{± 0.003} &\textbf{0.669} \tiny{± 0.000} \\
FB-v4 &\textbf{0.496} \tiny{± 0.001} &0.493 \tiny{± 0.000} &0.684 \tiny{± 0.001} &\textbf{0.687}± \tiny{0.000} \\
NL-v1 &0.757 \tiny{± 0.021} &\textbf{0.804} \tiny{± 0.007} &0.878 \tiny{± 0.035} &\textbf{0.899} \tiny{± 0.001} \\
NL-v2 &\textbf{0.575} \tiny{± 0.004} &0.571 \tiny{± 0.003} &0.761 \tiny{± 0.007} &\textbf{0.764} \tiny{± 0.006} \\
NL-v3 &0.563 \tiny{± 0.004} &\textbf{0.571} \tiny{± 0.007} &0.755 \tiny{± 0.006} &\textbf{0.759} \tiny{± 0.006} \\
NL-v4 &0.469 \tiny{± 0.020} &\textbf{0.551} \tiny{± 0.001} &0.733 \tiny{± 0.011} &\textbf{0.772} \tiny{± 0.004} \\
ILPC Small &\textbf{0.303} \tiny{± 0.001} &\textbf{0.303} \tiny{± 0.001} &0.453 \tiny{± 0.002} &\textbf{0.455} \tiny{± 0.001} \\
ILPC Large &0.308 \tiny{± 0.002} &\textbf{0.310} \tiny{± 0.002} &\textbf{0.431} \tiny{± 0.001} &\textbf{0.431} \tiny{± 0.003} \\
HM 1k &0.042 \tiny{± 0.002} &\textbf{0.072} \tiny{± 0.000} &0.100 \tiny{ ± 0.007} &\textbf{0.128} \tiny{± 0.000} \\
HM 3k &0.030 \tiny{± 0.002} &\textbf{0.069} \tiny{± 0.000} &0.090 \tiny{ ± 0.003} &\textbf{0.119} \tiny{± 0.000} \\
HM 5k &0.025 \tiny{± 0.001} &\textbf{0.074} \tiny{± 0.021} &0.068 \tiny{ ± 0.003} &\textbf{0.118} \tiny{± 0.013} \\
HM Indigo &0.432 \tiny{± 0.001} &\textbf{0.436} \tiny{± 0.000} &0.639 \tiny{ ± 0.002} &\textbf{0.645} \tiny{± 0.000} \\
FB-100 &\textbf{0.444} \tiny{± 0.003} &0.436 \tiny{± 0.001} &\textbf{0.643} \tiny{± 0.004} &0.633 \tiny{± 0.003} \\
FB-75 &0.400 \tiny{± 0.003} &\textbf{0.401} \tiny{± 0.000} &0.598 \tiny{± 0.004} &\textbf{0.611} \tiny{± 0.000} \\
FB-50 &\textbf{0.334} \tiny{± 0.002} &\textbf{0.334} \tiny{± 0.000} &0.538 \tiny{± 0.004} &\textbf{0.547} \tiny{± 0.000} \\
FB-25 &0.383 \tiny{± 0.001} &\textbf{0.393} \tiny{± 0.000} &0.635 \tiny{± 0.002} &\textbf{0.650} \tiny{± 0.000} \\
WK-100 &0.168 \tiny{± 0.005} &\textbf{0.188} \tiny{± 0.000} &0.286 \tiny{± 0.003} &\textbf{0.299} \tiny{± 0.000} \\
WK-75 &\textbf{0.380} \tiny{± 0.001} &0.368 \tiny{± 0.000} &\textbf{0.530} \tiny{± 0.009} &0.513 \tiny{± 0.000} \\
WK-50 &0.140 \tiny{± 0.010} &\textbf{0.166} \tiny{± 0.000} &0.280 \tiny{± 0.012} &\textbf{0.313} \tiny{± 0.000} \\
WK-25 &\textbf{0.321} \tiny{± 0.003} &0.300 \tiny{± 0.009} &\textbf{0.535} \tiny{± 0.007} &0.493 \tiny{± 0.006} \\
NL-100 &0.458 \tiny{± 0.012} &\textbf{0.482} \tiny{± 0.002} &0.684 \tiny{± 0.011} &\textbf{0.691} \tiny{± 0.001} \\
NL-75 &\textbf{0.374} \tiny{± 0.007} &0.351 \tiny{± 0.000} &\textbf{0.570} \tiny{± 0.005} &0.525 \tiny{± 0.000} \\
NL-50 &\textbf{0.418} \tiny{± 0.005} &0.405 \tiny{± 0.002} &\textbf{0.595} \tiny{± 0.005} &0.555 \tiny{± 0.012} \\
NL-25 &\textbf{0.407} \tiny{± 0.009} &0.377 \tiny{± 0.000} &\textbf{0.596} \tiny{± 0.012} &0.589 \tiny{± 0.000} \\
NL-0 &0.329 \tiny{± 0.010} &\textbf{0.385} \tiny{± 0.000} &\textbf{0.551} \tiny{± 0.012} &0.549 \tiny{± 0.000} \\
MT1 tax &0.330 \tiny{± 0.046} &\textbf{0.397} \tiny{± 0.001} &0.459 \tiny{± 0.056} &\textbf{0.508} \tiny{± 0.002} \\
MT1 health &\textbf{0.380} \tiny{± 0.002} &0.376 \tiny{± 0.000} &\textbf{0.467} \tiny{± 0.006} &0.457 \tiny{± 0.000} \\
MT2 org &\textbf{0.104} \tiny{± 0.001} &0.098 \tiny{± 0.002} &\textbf{0.170} \tiny{± 0.001} &0.162 \tiny{± 0.002} \\
MT2 sci &0.311 \tiny{± 0.010} &\textbf{0.331} \tiny{± 0.012} &0.451 \tiny{± 0.042} &\textbf{0.526} \tiny{± 0.005} \\
MT3 art &\textbf{0.306} \tiny{± 0.003} &0.289 \tiny{± 0.004} &\textbf{0.473} \tiny{± 0.003} &0.441 \tiny{± 0.001} \\
MT3 infra &0.657 \tiny{± 0.008} &\textbf{0.672} \tiny{± 0.003} &0.807 \tiny{± 0.007} &\textbf{0.810} \tiny{± 0.002} \\
MT4 sci &0.303 \tiny{± 0.007} &\textbf{0.305} \tiny{± 0.003} &0.478 \tiny{± 0.003} &\textbf{0.482} \tiny{± 0.001} \\
MT4 health &\textbf{0.704} \tiny{± 0.002} &0.702 \tiny{± 0.002} &\textbf{0.785} \tiny{± 0.002} &\textbf{0.785} \tiny{± 0.002} \\
Metafam &\textbf{0.997} \tiny{± 0.003} &\textbf{0.997} \tiny{± 0.003} &\textbf{1.000} \tiny{± 0.000} &\textbf{1.000} \tiny{± 0.000} \\
FBNELL &\textbf{0.481} \tiny{± 0.004} &0.478 \tiny{± 0.004} &\textbf{0.661} \tiny{± 0.011} &0.655 \tiny{± 0.012} \\
\bottomrule
\end{tabular}
\end{table*}

\begin{table*}[t]
\centering
\caption{Zero-shot relation prediction MRR and Hits@1 over 57 KGs from distinct domains.}
\label{tab:app_zero_shot_rel}
\begin{tabular}{lcccc}
\toprule
Dataset & ULTRA MRR & \ourmethod MRR & ULTRA Hits@1 & \ourmethod Hits@1 \\
\midrule
CoDEx Small & 0.900 & \textbf{0.961} & 0.820 & \textbf{0.935} \\
CoDEx Large & 0.892 & \textbf{0.902} & 0.824 & \textbf{0.837} \\
NELL-995 & \textbf{0.583} & 0.578 & 0.437 & \textbf{0.457} \\
YAGO 310 & 0.646 & \textbf{0.783} & 0.403 & \textbf{0.598} \\
WDsinger & 0.668 & \textbf{0.720} & 0.546 & \textbf{0.621} \\
NELL23k & 0.669 & \textbf{0.756} & 0.548 & \textbf{0.657} \\
FB15k237\_10 & 0.688 & \textbf{0.795} & 0.550 & \textbf{0.711} \\
FB15k237\_20 & 0.695 & \textbf{0.834} & 0.558 & \textbf{0.758} \\
FB15k237\_50 & 0.717 & \textbf{0.876} & 0.591 & \textbf{0.812} \\
DBpedia100k & 0.650 & \textbf{0.717} & 0.509 & \textbf{0.582} \\
AristoV4 & 0.254 & \textbf{0.389} & 0.201 & \textbf{0.265} \\
ConceptNet100k & 0.181 & \textbf{0.650} & 0.083 & \textbf{0.469} \\
Hetionet & 0.634 & \textbf{0.809} & 0.524 & \textbf{0.707} \\
WN-v1 & \textbf{0.836} & 0.792 & \textbf{0.740} & 0.613 \\
WN-v2 & \textbf{0.853} & 0.764 & \textbf{0.790} & 0.572 \\
WN-v3 & 0.707 & \textbf{0.741} & \textbf{0.577} & 0.568 \\
WN-v4 & \textbf{0.860} & 0.764 & \textbf{0.803} & 0.570 \\
FB-v1 & 0.646 & \textbf{0.705} & 0.523 & \textbf{0.599} \\
FB-v2 & 0.695 & \textbf{0.713} & 0.570 & \textbf{0.590} \\
FB-v3 & 0.679 & \textbf{0.742} & 0.553 & \textbf{0.644} \\
FB-v4 & 0.638 & \textbf{0.766} & 0.488 & \textbf{0.665} \\
NL-v1 & 0.636 & \textbf{0.657} & 0.358 & \textbf{0.453} \\
NL-v2 & 0.742 & \textbf{0.780} & 0.652 & \textbf{0.696} \\
NL-v3 & 0.669 & \textbf{0.725} & 0.544 & \textbf{0.612} \\
NL-v4 & 0.606 & \textbf{0.794} & 0.489 & \textbf{0.691} \\
ILPC Small & 0.905 & \textbf{0.919} & 0.843 & \textbf{0.872} \\
ILPC Large & 0.875 & \textbf{0.894} & 0.799 & \textbf{0.829} \\
HM 1k & 0.626 & \textbf{0.663} & \textbf{0.447} & 0.414 \\
HM 3k & 0.592 & \textbf{0.664} & \textbf{0.439} & 0.418 \\
HM 5k & 0.605 & \textbf{0.672} & \textbf{0.452} & 0.428 \\
HM Indigo & 0.681 & \textbf{0.852} & 0.559 & \textbf{0.765} \\
FB-100 & 0.830 & \textbf{0.921} & 0.728 & \textbf{0.880} \\
FB-75 & 0.698 & \textbf{0.822} & 0.555 & \textbf{0.747} \\
FB-50 & 0.696 & \textbf{0.780} & 0.575 & \textbf{0.699} \\
FB-25 & 0.687 & \textbf{0.805} & 0.565 & \textbf{0.724} \\
WK-100 & 0.887 & \textbf{0.907} & 0.812 & \textbf{0.869} \\
WK-75 & 0.911 & \textbf{0.916} & 0.875 & \textbf{0.883} \\
WK-50 & 0.865 & \textbf{0.868} & 0.793 & \textbf{0.818} \\
WK-25 & 0.857 & \textbf{0.881} & 0.760 & \textbf{0.823} \\
NL-100 & 0.743 & \textbf{0.884} & 0.564 & \textbf{0.796} \\
NL-75 & \textbf{0.795} & 0.788 & 0.692 & \textbf{0.699} \\
NL-50 & 0.680 & \textbf{0.755} & 0.569 & \textbf{0.636} \\
NL-25 & 0.688 & \textbf{0.742} & 0.562 & \textbf{0.614} \\
NL-0 & 0.632 & \textbf{0.658} & 0.502 & \textbf{0.519} \\
MT1 tax & \textbf{0.985} & 0.975 & \textbf{0.976} & 0.958 \\
MT1 health & 0.721 & \textbf{0.973} & 0.561 & \textbf{0.949} \\
MT2 org & 0.974 & \textbf{0.986} & 0.951 & \textbf{0.973} \\
MT2 sci & \textbf{0.976} & 0.964 & \textbf{0.961} & 0.941 \\
MT3 art & 0.881 & \textbf{0.885} & 0.798 & \textbf{0.825} \\
MT3 infra & \textbf{0.962} & 0.940 & \textbf{0.935} & 0.905 \\
MT4 sci & 0.933 & \textbf{0.966} & 0.891 & \textbf{0.944} \\
MT4 health & 0.826 & \textbf{0.937} & 0.719 & \textbf{0.898} \\
Metafam & 0.124 & \textbf{0.291} & 0.000 & \textbf{0.011} \\
FBNELL & 0.700 & \textbf{0.726} & 0.564 & \textbf{0.605} \\
\bottomrule
\end{tabular}
\end{table*}

\begin{table*}[t]
\centering
\caption{Finetuned relation prediction MRR and Hits@1 over 57 KGs from distinct domains.}
\label{tab:app_fine_tune_rel}
\begin{tabular}{lccccc}
\toprule
Dataset & ULTRA MRR & \ourmethod MRR & ULTRA Hits@1 & \ourmethod Hits@1 \\
\midrule
WN18RR & \textbf{0.914} \tiny{± 0.004} & 0.783 \tiny{± 0.009} & \textbf{0.871} \tiny{± 0.001} & 0.634 \tiny{± 0.007} \\
FB15K237 & 0.795 \tiny{± 0.017} & \textbf{0.924} \tiny{± 0.005} & 0.709 \tiny{± 0.025} & \textbf{0.870} \tiny{± 0.024} \\
CoDEx Medium & 0.919 \tiny{± 0.032} & \textbf{0.931} \tiny{± 0.001} & 0.870 \tiny{± 0.048} & \textbf{0.886} \tiny{± 0.001} \\
CoDEx Small & 0.942 \tiny{± 0.007} & \textbf{0.964} \tiny{± 0.002} & 0.900 \tiny{± 0.014} & \textbf{0.943} \tiny{± 0.002} \\
CoDEx Large & 0.907 \tiny{± 0.000} & \textbf{0.908} \tiny{± 0.003} & \textbf{0.850} \tiny{± 0.000} & 0.845 \tiny{± 0.004} \\
NELL-995 & \textbf{0.630} \tiny{± 0.000} & 0.578 \tiny{± 0.000} & \textbf{0.513} \tiny{± 0.000} & 0.457 \tiny{± 0.000} \\
YAGO 310 & \textbf{0.930} \tiny{± 0.002} & 0.826 \tiny{± 0.000} & \textbf{0.891} \tiny{± 0.004} & 0.666 \tiny{± 0.000} \\
WDsinger & \textbf{0.730} \tiny{± 0.012} & 0.721 \tiny{± 0.004} & 0.603 \tiny{± 0.020} & \textbf{0.627} \tiny{± 0.007} \\
NELL23k & 0.688 \tiny{± 0.008} & \textbf{0.755} \tiny{± 0.004} & 0.571 \tiny{± 0.009} & \textbf{0.658} \tiny{± 0.005} \\
FB15k237\_10 & 0.688 \tiny{± 0.000} & \textbf{0.795} \tiny{± 0.000} & 0.550 \tiny{± 0.000} & \textbf{0.711} \tiny{± 0.000} \\
FB15k237\_20 & 0.695 \tiny{± 0.000} & \textbf{0.846} \tiny{± 0.011} & 0.558 \tiny{± 0.000} & \textbf{0.778} \tiny{± 0.017} \\
FB15k237\_50 & 0.728 \tiny{± 0.013} & \textbf{0.903} \tiny{± 0.003} & 0.618 \tiny{± 0.027} & \textbf{0.858} \tiny{± 0.006} \\
DBpedia100k & 0.650 \tiny{± 0.000} & \textbf{0.780} \tiny{± 0.003} & 0.509 \tiny{± 0.000} & \textbf{0.665} \tiny{± 0.006} \\
AristoV4 & 0.254 \tiny{± 0.000} & \textbf{0.498} \tiny{± 0.002} & 0.201 \tiny{± 0.000} & \textbf{0.381} \tiny{± 0.002} \\
ConceptNet100k & 0.612 \tiny{± 0.000} & \textbf{0.712} \tiny{± 0.005} & 0.488 \tiny{± 0.000} & \textbf{0.551} \tiny{± 0.003} \\
Hetionet & 0.737 \tiny{± 0.031} & \textbf{0.922} \tiny{± 0.002} & 0.646 \tiny{± 0.041} & \textbf{0.862} \tiny{± 0.005} \\
WN-v1 & \textbf{0.844} \tiny{± 0.021} & 0.776 \tiny{± 0.021} & \textbf{0.754} \tiny{± 0.029} & 0.591 \tiny{± 0.034} \\
WN-v2 & \textbf{0.834} \tiny{± 0.008} & 0.765 \tiny{± 0.009} & \textbf{0.766} \tiny{± 0.013} & 0.574 \tiny{± 0.015} \\
WN-v3 & 0.707 \tiny{± 0.000} & \textbf{0.756} \tiny{± 0.044} & 0.577 \tiny{± 0.000} & \textbf{0.594} \tiny{± 0.064} \\
WN-v4 & \textbf{0.861} \tiny{± 0.005} & 0.804 \tiny{± 0.013} & \textbf{0.795} \tiny{± 0.007} & 0.651 \tiny{± 0.026} \\
FB-v1 & 0.650 \tiny{± 0.008} & \textbf{0.705} \tiny{± 0.000} & 0.513 \tiny{± 0.014} & \textbf{0.599} \tiny{± 0.000} \\
FB-v2 & 0.675 \tiny{± 0.035} & \textbf{0.713} \tiny{± 0.000} & 0.547 \tiny{± 0.040} & \textbf{0.590} \tiny{± 0.000} \\
FB-v3 & 0.677 \tiny{± 0.007} & \textbf{0.742} \tiny{± 0.000} & 0.556 \tiny{± 0.006} & \textbf{0.644} \tiny{± 0.000} \\
FB-v4 & 0.690 \tiny{± 0.026} & \textbf{0.766} \tiny{± 0.000} & 0.560 \tiny{± 0.035} & \textbf{0.665} \tiny{± 0.000} \\
NL-v1 & \textbf{0.719} \tiny{± 0.061} & 0.590 \tiny{± 0.036} & \textbf{0.504} \tiny{± 0.113} & 0.341 \tiny{± 0.066} \\
NL-v2 & 0.668 \tiny{± 0.064} & \textbf{0.811} \tiny{± 0.000} & 0.549 \tiny{± 0.090} & \textbf{0.740} \tiny{± 0.000} \\
NL-v3 & 0.646 \tiny{± 0.014} & \textbf{0.757} \tiny{± 0.004} & 0.484 \tiny{± 0.022} & \textbf{0.643} \tiny{± 0.009} \\
NL-v4 & 0.570 \tiny{± 0.030} & \textbf{0.822} \tiny{± 0.011} & 0.412 \tiny{± 0.056} & \textbf{0.735} \tiny{± 0.011} \\
ILPC Small & \textbf{0.922} \tiny{± 0.001} & 0.919 \tiny{± 0.000} & \textbf{0.876} \tiny{± 0.001} & 0.872 \tiny{± 0.000} \\
ILPC Large & 0.875 \tiny{± 0.000} & \textbf{0.894} \tiny{± 0.000} & 0.799 \tiny{± 0.000} & \textbf{0.829} \tiny{± 0.000} \\
HM 1k & 0.626 \tiny{± 0.000} & \textbf{0.663} \tiny{± 0.000} & \textbf{0.447} \tiny{± 0.000} & 0.414 \tiny{± 0.000} \\
HM 3k & 0.592 \tiny{± 0.000} & \textbf{0.664} \tiny{± 0.000} & \textbf{0.439} \tiny{± 0.000} & 0.418 \tiny{± 0.000} \\
HM 5k & 0.605 \tiny{± 0.000} & \textbf{0.672} \tiny{± 0.000} & \textbf{0.452} \tiny{± 0.000} & 0.428 \tiny{± 0.000} \\
HM Indigo & 0.726 \tiny{± 0.005} & \textbf{0.835} \tiny{± 0.002} & 0.614 \tiny{± 0.004} & \textbf{0.746} \tiny{± 0.003} \\
FB-100 & 0.851 \tiny{± 0.006} & \textbf{0.921} \tiny{± 0.000} & 0.769 \tiny{± 0.016} & \textbf{0.880} \tiny{± 0.000} \\
FB-75 & 0.754 \tiny{± 0.020} & \textbf{0.822} \tiny{± 0.000} & 0.638 \tiny{± 0.032} & \textbf{0.747} \tiny{± 0.000} \\
FB-50 & 0.696 \tiny{± 0.000} & \textbf{0.780} \tiny{± 0.000} & 0.575 \tiny{± 0.000} & \textbf{0.699} \tiny{± 0.000} \\
FB-25 & 0.684 \tiny{± 0.021} & \textbf{0.805} \tiny{± 0.000} & 0.563 \tiny{± 0.024} & \textbf{0.724} \tiny{± 0.000} \\
WK-100 & \textbf{0.924} \tiny{± 0.003} & 0.916 \tiny{± 0.001} & 0.879 \tiny{± 0.002} & \textbf{0.885} \tiny{± 0.003} \\
WK-75 & 0.911 \tiny{± 0.000} & \textbf{0.937} \tiny{± 0.003} & 0.875 \tiny{± 0.000} & \textbf{0.910} \tiny{± 0.003} \\
WK-50 & 0.865 \tiny{± 0.000} & \textbf{0.881} \tiny{± 0.007} & 0.793 \tiny{± 0.000} & \textbf{0.840} \tiny{± 0.014} \\
WK-25 & 0.897 \tiny{± 0.002} & \textbf{0.905} \tiny{± 0.007} & 0.834 \tiny{± 0.005} & \textbf{0.860} \tiny{± 0.011} \\
NL-100 & 0.803 \tiny{± 0.008} & \textbf{0.885} \tiny{± 0.005} & 0.678 \tiny{± 0.012} & \textbf{0.793} \tiny{± 0.008} \\
NL-75 & \textbf{0.795} \tiny{± 0.000} & 0.790 \tiny{± 0.000} & 0.678 \tiny{± 0.000} & \textbf{0.671} \tiny{± 0.000} \\
NL-50 & \textbf{0.808} \tiny{± 0.000} & 0.774 \tiny{± 0.000} & 0.704 \tiny{± 0.000} & \textbf{0.683} \tiny{± 0.000} \\
NL-25 & \textbf{0.737} \tiny{± 0.000} & 0.709 \tiny{± 0.000} & 0.622 \tiny{± 0.000} & \textbf{0.606} \tiny{± 0.000} \\
NL-0 & 0.632 \tiny{± 0.000} & \textbf{0.655} \tiny{± 0.006} & 0.502 \tiny{± 0.000} & \textbf{0.518} \tiny{± 0.002} \\
MT1 tax & 0.990 \tiny{± 0.001} & \textbf{0.995} \tiny{± 0.001} & 0.984 \tiny{± 0.001} & \textbf{0.990} \tiny{± 0.001} \\
MT1 health & 0.929 \tiny{± 0.044} & \textbf{0.973} \tiny{± 0.000} & 0.867 \tiny{± 0.087} & \textbf{0.949} \tiny{± 0.000} \\
MT2 org & 0.981 \tiny{± 0.014} & \textbf{0.987} \tiny{± 0.001} & 0.963 \tiny{± 0.027} & \textbf{0.978} \tiny{±0.001} \\
MT2 sci & 0.977 \tiny{± 0.001} & \textbf{0.990} \tiny{± 0.001} & 0.961 \tiny{± 0.001} & \textbf{0.984} \tiny{± 0.002} \\
MT3 art & \textbf{0.907} \tiny{± 0.012} & 0.887 \tiny{± 0.003} & 0.851 \tiny{± 0.024} & \textbf{0.828} \tiny{± 0.005} \\
MT3 infra & 0.966 \tiny{± 0.003} & \textbf{0.970} \tiny{± 0.001} & 0.947 \tiny{± 0.006} & \textbf{0.952} \tiny{± 0.003} \\
MT4 sci & 0.954 \tiny{± 0.002} & \textbf{0.972} \tiny{± 0.001} & 0.929 \tiny{± 0.002} & \textbf{0.952} \tiny{± 0.001} \\
MT4 health & 0.951 \tiny{± 0.006} & \textbf{0.986} \tiny{± 0.001} & 0.919 \tiny{± 0.010} & \textbf{0.979} \tiny{± 0.002} \\
Metafam & \textbf{0.368} \tiny{± 0.029} & 0.265 \tiny{± 0.044} & \textbf{0.112} \tiny{± 0.036} & 0.024 \tiny{± 0.022} \\
FBNELL & 0.720 \tiny{± 0.013} & \textbf{0.766} \tiny{± 0.004} & 0.576 \tiny{± 0.020} & \textbf{0.639} \tiny{± 0.006} \\
\bottomrule
\end{tabular}
\label{table:relation_prediction}
\end{table*}