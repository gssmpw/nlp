\documentclass{article}
\usepackage{log_2024}						% for camera-ready version
% \usepackage[review]{log_2024}				% for anonymous submission to proceedings track
% \usepackage[review,eatrack]{log_2024}		% for anonymous submission to extended abstract track
% \usepackage[preprint]{log_2024}			% for preprint version
% \usepackage[eatrack]{log_2024}				% for accepted extended abstracts

\input{math_commands}

\usepackage{booktabs}						% professional-quality tables
\usepackage{multirow}						% tabular cells spanning multiple rows
\usepackage{amsfonts}						% blackboard math symbols
\usepackage{graphicx}						% figures
\usepackage{duckuments}						% sample images

% If you want to use natbib:
\usepackage[numbers,compress,sort]{natbib}	% for numerical citations
% \usepackage[sort,round]{natbib}			% for textual citations

% If you want to use bibLaTeX, uncomment below:
% \usepackage[
%      backend=biber,
%      style=numeric-comp,
%      backref=true,
%      natbib=true]{biblatex}
% \addbibresource{reference.bib}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage[backref=page]{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{multirow}
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors
\usepackage{xspace}
\usepackage{adjustbox}
%\usepackage
\usepackage{xcolor}
% \hypersetup{
%     colorlinks,
%     linkcolor={red!50!black},
%     citecolor={blue!50!black},
%     urlcolor={blue!80!black}
% }
\usepackage{wrapfig}


\usepackage{bbm}
\usepackage{CJKutf8}

%\input{math_commands}
\usepackage{cleveref}
%\usepackage{graphicx}
\usepackage{subcaption}

\usepackage{algpseudocode}
\usepackage{algorithm}

\newcommand{\ourmethod}{TRIX\xspace}


\title{TRIX: A More Expressive \revision{Model for Zero-shot\\ 
Domain Transfer in Knowledge Graphs}}

\author[Y. Zhang et al.]{%
Yucheng Zhang\\
Purdue University\\
\email{zhan4332@purdue.edu}\And
Beatrice Bevilacqua\\
Purdue University\\
\email{bbevilac@purdue.edu}\AND
Mikhail Galkin\\
Intel AI Lab\\
\email{mikhail.galkin@intel.com}\And
Bruno Ribeiro\\
Purdue University\\
\email{ribeirob@purdue.edu}
}

\begin{document}

\maketitle

\begin{abstract}
\revision{Fully inductive knowledge graph models can be trained on multiple domains and subsequently perform zero-shot knowledge graph completion (KGC) in new unseen domains.
This is an important capability towards the goal of having foundation models for knowledge graphs.}
  In this work, we introduce a more expressive and capable \revision{fully inductive model}, dubbed \ourmethod, which not only yields strictly more expressive triplet embeddings (head entity, relation, tail entity)  compared to state-of-the-art methods, but also introduces a new capability: directly handling both entity and relation prediction tasks in inductive settings. 
  Empirically, we show that \ourmethod outperforms the state-of-the-art fully inductive models in zero-shot entity and relation predictions in new domains, and outperforms large-context LLMs in out-of-domain predictions.
  % Empirically, we show that \ourmethod\ surpasses state-of-the-art \revision{fully inductive models}, with an average improvement of up to 7.4\% in hits@10 accuracy in zero-shot entity or relation prediction, as well as fine-tuning scenarios, across a diverse set of 57 datasets. Additionally, we conduct a comparison with large-context Large Language Models (LLMs) on zero-shot relation \revision{and entity} prediction tasks. Our results demonstrate that while LLMs achieve comparable performance to \ourmethod in-domain, their predictive capabilities degrade significantly out-of-domain (exhibiting high sensitivity to relation and entity permutations in the knowledge graph prompt), while \ourmethod maintains robust performance in these scenarios. This underscores the importance of further developing \revision{fully inductive models} to reason across domains. 
  The source code is available at \revision{\url{https://github.com/yuchengz99/TRIX}}.
\end{abstract}

\section{Introduction}
%\vspace{-5pt}
\input{sections/introduction}

%\vspace{-5pt}
\section{Related Work}
%\vspace{-5pt}
\input{sections/related_work}

%\vspace{-15pt}
\section{Preliminaries}\label{sec:preliminary}
%\vspace{-8pt}
\input{sections/preliminary}

\section{\ourmethod Framework}
%\vspace{-5pt}
\input{sections/proposed_method}

\section{Experiments}
%\vspace{-5pt}
\input{sections/experiment}


%\vspace{-5pt}
\section{Conclusion}
%\vspace{-5pt}
In this paper we considered the fully inductive link prediction task in KGs. We identified the open challenges in existing fully inductive models, and proposed \ourmethod, a novel architecture designed to improve expressiveness and support efficient relation prediction tasks. Through comprehensive experiments spanning 57 diverse KGs datasets, we demonstrate that increased expressiveness translates into better performance. Additionally, our experimental study sheds light on the limitations of LLMs in exploiting graph information in new domains for entity and relation prediction tasks.


% \vspace{-10pt}
% \paragraph{Limitations and Impact Statement.}
% Despite the promising results of \ourmethod in the inductive settings we consider, there are still aspects that can be refined in future research.
% For example, while \ourmethod aims to enhance expressivity compared to existing methods, there might still be scenarios where its representation power is limited, leading to challenges in capturing complex relationships.
% Furthermore, the relation adjacency matrix size introduces additional computational complexity during training, potentially requiring more resources and time compared to simpler models. Finally, while not designed for malicious intent, there is a possibility of \ourmethod being repurposed for activities like uncovering sensitive information, raising questions about data privacy and responsible AI use.
% For natbib users:

\newpage
\clearpage
\section*{Acknowledgments}
This work was funded in part by the National Science Foundation (NSF) awards, CCF-1918483, CAREER IIS-1943364 and CNS-2212160, Amazon Research Award, AnalytiXIN, and the Wabash Heartland Innovation Network (WHIN), Ford, NVidia, CISCO, and Amazon. Computing infrastructure was supported in part by CNS-1925001 (CloudBank). This work was supported in part by AMD under the AMD HPC Fund program. %Any opinions, findings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the sponsors.

\bibliographystyle{unsrtnat}
\bibliography{ref}
% For bibLaTeX users:
% \printbibliography

\newpage
\appendix
\section{Pseudo Codes of Iterative Embedding Updates}
\input{sections/appendix_codes}

\section{Expressive Power}\label{app:expressive-power}
\input{sections/appendix_proof}

\section{Computational Resources}\label{appx:compute}
We implemented \ourmethod using PyTorch~\citep{paszke2019pytorch} (offered under BSD-3 Clause license) and the PyTorch Geometric library~\citep{fey2019fast} (offered under MIT license) for efficient processing of graph-structured data. All experiments were conducted on NVIDIA RTX A5000,  NVIDIA RTX A6000, and NVIDIA GeForce RTX 4090 GPUs, and on the Google's Gemini API. For hyperparameter tuning and model selection, we used the Weights and Biases (wandb) library~\citep{wandb}.

\section{LLM Experiment Details}
\label{appx:LLMexp}
\input{sections/appendix_llm}

\section{Datasets}
\label{appx:datasets}
\input{sections/appendix_data}

\section{Detailed Experiment Results of Entity and Relation Prediction}
\label{appx:detailedresults}
\input{sections/appendix_experiment}

\end{document}
