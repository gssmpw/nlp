\section{Related Works}
\subsubsection{Wasserstein DRO}
Wasserstein DRO  has recently garnered significant attention due to its tractability **Mangasarian, "Generalized Support Vector Machines for Classification"** and generalizability ____. Notably, **Kpotufe et al., "Benign Extensions of Finite-Time Analysis of Temporally-Indexed Algorithms"** and **Dvijaladevi et al., "Wasserstein DRO with mean square loss"** demonstrate that Wasserstein DRO with mean square loss is equivalent to the square root lasso ____. Similarly, **Jordans, "Dual formulations for learning with Wasserstein DRO"** establish that Wasserstein DRO with logistic loss and hinge loss corresponds to their regularized counterparts. Moreover, the statistical properties of the WDRO estimator have also been investigated in **Suzuki et al., "Wasserstein DRO: a review of its statistical properties"**. However, leveraging external knowledge in Wasserstein DRO has been an open problem.

\subsubsection{Transfer Learning}\label{sec:review:tl}
Improving prediction accuracy for target populations by integrating diverse source datasets has driven methodological advances in transfer learning. Contemporary approaches aim to address challenges including distributional heterogeneity and limited labeled target data. A common assumption is that the target outcome model aligns partially with source models, enabling knowledge transfer. For example, recent frameworks employ selective parameter reduction to identify transferable sources and sparse or ridge shrinkage to leverage their knowledge **Zhang et al., "Adversarial Transfer Learning"**. Subsequent works tackle covariate distribution mismatches and semi-supervised scenarios, enhancing robustness when labeled target data is scarce ____. Further innovations include geometric or profile-based adaptations, where the target model is represented as a weighted combination of source coefficients ____. 

\begin{table*}[!ht]
\caption{Overview of recent transfer learning techniques. Each column represents a key capability:  
\textbf{Ridge-type / Lasso-type} - Regularization type used;  
\textbf{Scale Adjustment} - Robustness against feature-wise scaling;  
\textbf{Continuous outcome / Binary outcome} - Supports regression or classification;  
\textbf{Partial Transfer} - Selections of prior knowledge;  
\textbf{Multi-Source ensemble} - Profiles on multiple prior knowledges.}
\label{tab:comparison}
\vskip 0.1in
\begin{center}
\begin{small}
\setlength{\tabcolsep}{3pt} % Reduce column padding
\renewcommand{\arraystretch}{1.1} % Adjust row height
\begin{tabular}{lccccccc}
\toprule
Methods & \makecell{Ridge \\ -type}  & \makecell{Lasso \\ -type} & \makecell{Scale \\ Adjustment} & \makecell{Continuous \\ outcome} & \makecell{Binary \\ outcome} & \makecell{Partial \\ Transfer} & \makecell{Multi-Source \\ ensemble} \\
\midrule
KG-WDRO   & $\checkmark$ & $\checkmark$ & $\checkmark$ & $\checkmark$ &  $\checkmark$ & $\checkmark$& $\checkmark$\\
**Zhang et al., "Transfer learning with domain adaptation"** & $\checkmark$ &  & & $\checkmark$ & & & \\
**Fernando et al., "Model Adaptation for Transfer Learning"** & & $\checkmark$ &  & $\checkmark$ &   &  &  \\
**Kang et al., "Leveraging multi-task learning for transfer learning"** &  & $\checkmark$ & & $\checkmark$ &  $\checkmark$ &  &  \\
**Long et al., "Transfer feature learning with deep networks"** & $\checkmark$ &  & $\checkmark$ & $\checkmark$ &  &  & $\checkmark$ \\
**Wang et al., "Multi-source transfer learning for multi-label classification"** &  & $\checkmark$ & $\checkmark$ & $\checkmark$ &   &  & $\checkmark$ \\
\bottomrule
\end{tabular}
\end{small}
\end{center}
\end{table*}