
\section{Proofs}
The purpose of this appendix is to provide detailed proofs of the theoretical results presented in the main article. Appendix~\ref{proof:kernel} elaborates on the formula that characterizes the unique minimizer of the WeaKL empirical risks, while Appendix~\ref{sec:constraints} discusses the integration of linear constraints into the empirical risk framework.

\subsection{A useful lemma}
\begin{lemma}[Full rank]
    The matrix \[\tilde M = \frac{1}{n}\Big( \sum_{j=1}^n \mathbb \Phi_{t_j}^\ast \Lambda^\ast \Lambda\mathbb \Phi_{t_j}\Big) +  M^\ast M\] is invertible. Moreover, for all $\theta\in\mathbb C^{\dim \theta}$, $\theta^\star \tilde M \theta \geq \lambda_{\min}(\tilde M)\|\theta\|_2^2$, where $\lambda_{\min}(\tilde M)$ is the minimum eigenvalue of $\tilde M$.
    \label{lemma:full}
\end{lemma}
\begin{proof}
    First, we note that $\tilde M$ is a positive Hermitian square matrix. Hence, the spectral theorem guarantees that $\tilde M$ is diagonalizable in an orthogonal basis of $\mathbb C^{\dim(\theta)}$ with real eigenvalues. In particular, it admits a positive square root, and the min-max theorem states that $\theta^\ast \tilde M \theta = \|\tilde M^{1/2} \theta\|_2^2 \geq \lambda_{\min}(\tilde M^{1/2})^2\|\theta\|_2^2 = \lambda_{\min}(\tilde M)\|\theta\|_2^2$. This shows the second statement of the lemma.
    
    Next, for all $\theta \in \mathbb C^{\dim \theta}$, $\theta^\ast \tilde M \theta \geq \theta^\ast  M^\ast M \theta$.
    Since $M$ is full rank,  $\mathrm{rank}(M) = \dim(\theta)$. Therefore, $\tilde M \theta = 0 \Rightarrow \theta^\ast \tilde M \theta = 0 \Rightarrow \theta^\ast M^\ast M \theta = 0  \Rightarrow \|M\theta\|_2^2 = 0 \Rightarrow M\theta = 0 \Rightarrow \theta = 0$. Thus, $\tilde M$ is injective and, in turn, invertible.
\end{proof}


\subsection{Proof of Proposition~\ref{prop:emp_risk_min}}
\label{proof:kernel}
The function $L: \mathbb C^{\dim(\theta)} \to \mathbb R^+$ can be written as
\[L(\theta) = \frac{1}{n}\Big( \sum_{j=1}^n (\mathbb \Phi_{t_j}\theta- Y_{t_j})^\ast \Lambda^\ast \Lambda(\mathbb \Phi_{t_j}\theta- Y_{t_j})\Big)  + \theta^\ast M^\ast M\theta.\]
Recall that the matrices $\Lambda$ and $M$ are assumed to be injective. 
Observe that $L$ can be expanded as
\[L(\theta + \delta \theta) = L(\theta) + 2 \mathrm{Re}(\langle \tilde M\theta-\tilde Y, \delta \theta\rangle) + o(\|\delta \theta\|_2^2),\]
where $\tilde Y = \frac{1}{n} \sum_{j=1}^n \mathbb \Phi_{t_j}^\ast \Lambda^\ast \Lambda Y_{t_j}.$
This shows that $L$ is differentiable and that its differential at $\theta$ is the function $dL_\theta: \delta \theta \mapsto 2 \mathrm{Re}(\langle \tilde M\theta - \tilde Y, \delta \theta\rangle)$.
Thus, the critical points $\theta$ such that $dL_{\theta} = 0$ satisfy 
\[\forall\; \delta \theta \in \mathbb C^{\dim(\theta)}, \; \mathrm{Re}(\langle \tilde M\theta- \tilde Y, \delta \theta\rangle) = 0.\]
Taking $\delta \theta = \tilde M \theta- \tilde Y$ shows that $\|\tilde M\theta- \tilde Y\|_2^2 = 0$, i.e., $\tilde M\theta = \tilde Y$. From Lemma~\ref{lemma:full}, we deduce that $\theta = \tilde M^{-1} \tilde Y$, which is exactly the $\hat \theta_n$ in \eqref{eq:weakl}.

From Lemma~\ref{lemma:full}, we also deduce that, for all $\theta$ such that $\|\theta\|_2$ is large enough, one has $L(\theta) \geq \lambda_{\min}(\tilde M)\|\theta\|_2^2/2$. 
Since $L$ is continuous, it has at least one global minimum. Since the unique critical point of $L$ is $\hat \theta_n$, we conclude that $\hat \theta_n$ is the unique minimizer of $L$. 
\subsection{Orthogonal projection and linear constraints}
\label{sec:constraints}
\begin{lemma}[Orthogonal projection]
    \label{lem:ortho}
    Let $\ell_1, \ell_2 \in \mathbb N^\star$. Let $P$ be an injective $\ell_1 \times \ell_2$ matrix with coefficients in $\mathbb C$. Then
    $C = \mathrm{I}_{\ell_1} - P(P^\ast P)^{-1}P^\ast$ is the orthogonal projection on $\mathrm{Im}(P)^\perp$, where $\mathrm{Im}(P)$ is the image  of $P$ and $\mathrm{I}_{\ell_1}$ is the $\ell_1\times \ell_1$ identity matrix.
\end{lemma}
\begin{proof}
First, we show that $P^\ast P$ is an $\ell_2 \times \ell_2$ matrix of full rank. Indeed, for all $x\in \mathbb C^{\ell_2}$, one has $P^\ast P x = 0 \Rightarrow x^\ast P^\ast P x = 0 \Rightarrow \|Px\|_2^2 = 0$. Since $P$ is injective, we deduce that $\|Px\|_2^2 = 0 \Rightarrow x = 0$. This means that $\ker P^\ast P = \{0\}$, and so that $P^\ast P$ is full rank. Therefore, $(P^\ast P)^{-1}$ is well defined.

Next, let $C_1 = P(P^\ast P)^{-1}P^\ast$. Clearly, $C_1^2 = C_1$, i.e., $C_1$ is a projector. Since $C_1^\ast = C_1$, we deduce that $C_1$ is an orthogonal projector.
 In addition, since $C_1 = P\times ((P^\ast P)^{-1}P^\ast)$, $\mathrm{Im}(C_1) \subseteq \mathrm{Im}(P)$. Moreover, if $x \in \mathrm{Im}(P)$, there exists a vector $ z$ such that $x = Pz$, and $C_1x = P(P^\ast P)^{-1}P^\ast Pz = Pz =x$. Thus, $x \in \mathrm{Im}(C_1)$. This shows that $\mathrm{Im}(C_1) = \mathrm{Im}(P)$. We conclude that $C_1$ is the orthogonal projection on $\mathrm{Im}(P)$ and, in turn, that $C = \mathrm{I}_{\ell_1} - C_1$ is the orthogonal projection on $\mathrm{Im}(P)^\perp$.
\end{proof}

The following proposition shows that, given the exact prior knowledge $C\theta^\star = 0$, enforcing the linear constraint  $C\theta = 0$ almost surely improves the performance of WeaKL.
\begin{proposition}[Constrained estimators perform better.]
\label{prop:prop_lin}
    Assume that $Y_t = f_{\theta^\star}(X_t) + \varepsilon_t$ and that $\theta^\star$ satisfies the constraint $C\theta^\star = 0$, for some matrix $C$. (Note that we make no assumptions about the distribution of the time series $(X, \varepsilon)$.)
    Let $\Lambda$ and $M$ be injective matrices, and let $\lambda \geq 0$ be a hyperparameter. 
    Let $\hat \theta$ be the WeaKL given by \eqref{eq:weakl} and let $\hat \theta_C$ be the WeaKL obtained by replacing $M$ with $(\sqrt{\lambda}C^\top \mid M^\top)^\top$ in \eqref{eq:weakl}.
    Then, almost surely,
    \[\frac{1}{n}\sum_{j=1}^n\| f_{\theta^\star}(X_{t_j}) - f_{\hat \theta_C}(X_{t_j})\|_2^2 + \|M(\theta^\star- \hat \theta_C)\|_2^2\leq \frac{1}{n}\sum_{j=1}^n\| f_{\theta^\star}(X_{t_j}) - f_{\hat \theta}(X_{t_j})\|_2^2 + \|M(\theta^\star- \hat \theta)\|_2^2.\]
\end{proposition}
\begin{proof} Recall from \eqref{eq:weakl} that
\[
    \hat \theta = P^{-1} \sum_{j=1}^n \mathbb \Phi_{t_j}^\ast \Lambda^\ast \Lambda Y_{t_j} \quad \mbox{and} \quad 
     \hat \theta_C = \big(P+ \lambda n C^\ast C\big)^{-1} \sum_{j=1}^n \mathbb \Phi_{t_j}^\ast \Lambda^\ast \Lambda Y_{t_j},
     %\label{eq:estimators}
\]
where $P = ( \sum_{j=1}^n \mathbb \Phi_{t_j}^\ast \Lambda^\ast \Lambda\mathbb \Phi_{t_j}) + n M^\ast M$.
Since $C\theta^\star = 0$, we see that 
\begin{equation}
    \theta^\star = \big(P+ \lambda n C^\ast C\big)^{-1}P\theta^\star
    \label{eq:theta_star}.
\end{equation}
Subtracting \eqref{eq:theta_star} to, respectively, $\hat \theta$ and $\hat \theta_C$, we obtain
\[
     \theta^\star- \hat \theta = P^{-1/2} \Delta \quad \mbox{and}\quad 
    \theta^\star - \hat \theta_C = \big( P +\lambda n C^\ast C\big)^{-1} P^{1/2} \Delta,
\]
where \[\Delta = P^{-1/2}\Big(P\theta^\star- \sum_{j=1}^n \mathbb \Phi_{t_j}^\ast \Lambda^\ast \Lambda Y_{t_j}\Big).\] 
Moreover, according to the Loewner order \citep[see, e.g.,][Chapter~7.7]{Horn2012matrix}, we have that
$P^{-1/2}C^\ast C P^{-1/2} \geq 0$ and $(P^{-1/2}C^\ast C P^{-1/2})^2 \geq 0$. 
(Indeed, since $P$ is Hermitian, so is $P^{-1/2}C^\ast C P^{-1/2}$.)
Therefore, $(\mathrm{I} +\lambda n  P^{-1/2}C^\ast C P^{-1/2})^2 \geq \mathrm{I}$ and $( \mathrm{I} +\lambda n  P^{-1/2}C^\ast C P^{-1/2})^{-2} \leq \mathrm{I}$ \citep[see, e.g.,][Corollary~7.7.4]{Horn2012matrix}.
Consequently,
\[\|P^{1/2}(\theta^\star - \hat \theta_C)\|_2^2 = \Delta^\ast \big( \mathrm{I} +\lambda n  P^{-1/2}C^\ast C P^{-1/2}\big)^{-2} \Delta \leq \|\Delta\|_2^2 = \|P^{1/2}(\theta^\star - \hat \theta)\|_2^2.\]
Observing that $\|P^{1/2}(  \theta^\star-\hat \theta_C)\|_2^2 = \frac{1}{n}\sum_{j=1}^n\| f_{\theta^\star}(X_{t_j}) - f_{\hat \theta_C}(X_{t_j})\|_2^2 + \|M(\theta^\star- \hat \theta_C)\|_2^2$ and $\|P^{1/2}( \theta^\star- \hat \theta)\|_2^2 = \frac{1}{n}\sum_{j=1}^n\| f_{\theta^\star}(X_{t_j}) - f_{\hat \theta}(X_{t_j})\|_2^2 + \|M(\theta^\star- \hat \theta)\|_2^2$ concludes the proof.
\end{proof}
\begin{remark}
\label{rem:comment_prop_lin}
    Taking the limit $\lambda \to \infty$ in Proposition~\ref{prop:prop_lin} does not affect the result and corresponds to restricting the parameter space to $\ker(C)$, meaning that, in this case, $C \hat \theta_C = 0$.
    
Note also that the proposition is extremely general, as it holds almost surely without requiring any assumptions on either $X$ or $\varepsilon$.
Here, the error of $\hat \theta$ is measured by 
\[\frac{1}{n}\sum_{j=1}^n\| f_{\theta^\star}(X_{t_j}) - f_{ \hat \theta}(X_{t_j})\|_2^2 + \|M(\theta^\star- \hat \theta)\|_2^2,\]
which quantifies both the error of $\hat \theta$ at the points $X_{t_j}$ and in the $M$ norm.
Under additional assumptions on $X$ and $\varepsilon$, this discretized risk can be shown to converge to the $L^2$ error, $\mathbb E\| f_{\theta^\star}(X) - f_{ \hat \theta}(X)\|_2^2$, using Dudleyâ€™s theorem \citep[see, e.g., Theorem~5.2 in the Supplementary Material of][]{doumeche2023convergence}.

However, the rate of this convergence of $\hat \theta$ to $\theta^\star$ depends on the properties of $C$ and $M$, as well as the growth of $\dim(\theta)$ with $n$.
For instance, when the penalty matrix $M$ encodes a PDE prior, the analysis becomes particularly challenging and remains an open question in physics-informed machine learning.
Therefore, we leave the study of this convergence outside the scope of this article.
\end{remark}

\section{More WeaKL models}
\subsection{Forecast combinations}
\label{sec:combination}
To forecast a time series $Y$, different models can be used, each using different implementations and sets of explanatory variables. Let $p$ be the number of models and let $\hat{Y}^1_t, \ldots, \hat{Y}^p_t$ be the respective estimators of $Y_t$.
The goal is to determine the optimal weighting of these forecasts, based on their performance evaluated over the time points $t_1 \leq  \cdots \leq t_n$. 
Therefore, in this setting, $X_t = (t, \hat{Y}^1_t, \ldots, \hat{Y}^p_t)$, and the goal is to find the optimal function linking $X_t$ to $Y_t$.
Note that, to avoid overfitting, we assume that the forecasts $\hat{Y}^1_t, \ldots, \hat{Y}^p_t$ were trained on time steps before~$t_1$.
This approach is sometimes referred to as the online aggregation of experts \citep{Remlinger2023expert, Antoniadis2024Aggregation}. Such forecast combinations are widely recognized to significantly improve the performance of the final forecast \citep{timmermann2006handbook, vilmarest2022state,petropoulos2022forecasting, amara-ouali2024forecasting}, as they leverage the strengths of the individual predictors. 

Formally, this results in the model
\[f_\theta(X_t) = \sum_{\ell=1}^p (p^{-1}+ h_{\theta_\ell}(t) )\hat Y^\ell_{t},\]
where $h_{\theta_\ell}(t) = \langle \phi(t), \theta_\ell\rangle$, $\phi$ is the Fourier map $\phi(t) =(\exp(i k t/2))_{-m\leq k \leq m}^\top$, and $\theta_\ell \in \mathbb{C}^{2m+1}$.
The $p^{-1}$ term introduces a bias, ensuring that $h_{\theta_\ell} = 0$ corresponds to a uniform weighting of the forecasts $\hat Y^\ell$.
The function $f^\star$ is thus estimated by minimizing the loss
    \[L(\theta) = \frac{1}{n}\sum_{j=1}^n \Big|\Big(\sum_{\ell=1}^p (p^{-1}+ h_{\theta_\ell}(t_j) )\hat Y^\ell_{t_j}\Big) - Y_{t_j}\Big|^2  + \sum_{\ell=1}^{p} \lambda_\ell \|h_{\theta_\ell}\|_{H^s}^2,\]
    where $\lambda_\ell > 0$ are hyperparameters.
Again, a common choice for the smoothing parameter is to set $s = 2$. 
Let $\phi_1(X_t) = 
    (
    (\hat Y^\ell_{t}\exp(ik t/2))_{- m\leq k \leq  m})_{\ell=1}^p)^\top \in \mathbb C^{(2m+1)p}$.
The Fourier coefficients that minimize the empirical risk are given by
\[
\hat \theta  = ({\mathbb{\Phi}} ^\ast {\mathbb{\Phi}} + n M^\ast  M)^{-1}{\mathbb \Phi}^\ast   \mathbb W,
\]
where $\mathbb W = (W_{t_1}, \hdots, W_{t_n})^\top$ is such that $W_t = Y_t - p^{-1}\sum_{\ell=1}^p \hat Y^\ell_t$,
\[M = \begin{pmatrix}
        \sqrt{\lambda_1} D& 0  & 0\\
        0 & \ddots&  0\\
        0 & 0& \sqrt{\lambda_{d_1}} D
    \end{pmatrix},\]
and $D$ is the $(2m+1)\times (2m+1)$ diagonal matrix
$D =\mathrm{Diag}((\sqrt{1+k^{2s}})_{-m\leq k\leq m})$. 

\subsection{Differential constraints}
\label{sec:diff}
As discussed in the introduction, some time series obey physical laws and can be expressed as solutions of PDEs. Physics-informed kernel learning (PIKL) is a kernel-based method developed by \citet{doumÃ¨che2024physicsinformedkernellearning} to incorporate such PDEs as constraints. It can be regarded as a specific instance of the WeaKL framework proposed in this paper. In effect, given a bounded Lipschitz domain $\Omega$ and a linear differential operator $\mathscr D$, using the model $f_{ \theta}(x) = \langle \phi(x), \theta\rangle$, where $\phi(x) = (\exp(i  \langle x, k \rangle / 2) )_{\|k\|_\infty \leq m}$ is the Fourier map and $\theta$ represents the Fourier coefficients, the PIKL approach shows how to construct a matrix $M$ such that
\[
\int_\Omega \mathscr{D}(f_\theta, u)^2 \, du = \|M \theta\|_2^2.
\]
Thus, to incorporate the physical prior $\forall x \in \Omega,\; \mathscr D(f^\star, x) = 0$ into the learning process, the empirical risk takes the form
\[
L(\theta) = \frac{1}{n}\sum_{i=1}^n |f_\theta(X_{t_i}) - Y_{t_i}|^2 + \lambda \int_\Omega \mathscr{D}(f_\theta, u)^2 \, du =  \frac{1}{n}\sum_{i=1}^n |f_\theta(X_{t_i}) - Y_{t_i}|^2 + \|\sqrt{\lambda}M\theta\|_2^2,
\]
where $\lambda > 0 $ is a hyperparameter.
From \eqref{eq:weakl2} it follows that the minimizer of the empirical risk is
$\hat \theta = (\mathbb \Phi^\ast \mathbb \Phi+nM)^{-1} \mathbb\Phi^\ast \mathbb Y$. It is shown in \citet{doumeche2024physicsinformed} that, as $n \to \infty$, $f_{\hat{\theta}}$ converges to $f^\star$ under appropriate assumptions. Moreover, incorporating the differential constraint improves the learning process; in particular, $f_{\hat{\theta}}$ converges to $f^\star$ faster when $\lambda > 0$.

\section{A toy-example of hierarchical forecasting}
\label{sec:toy-example}
\paragraph{Setting.} We evaluate the performance of WeaKL on a simple but illustrative hierarchical forecasting task. In this simplified setting, we want to forecast two random variables, $Y_1$ and $Y_2$, defined as follows:
\[Y_1 = \langle X_1, \theta_1 \rangle + \varepsilon_1, \quad Y_2 = \langle X_2, \theta_2 \rangle - \varepsilon_1 + \varepsilon_2,
\]
where $X_1$, $X_2$, $\varepsilon_1$, and $\varepsilon_2$ are independent. The feature vectors are $X_1 \sim \mathcal{N}(0, \mathrm{I}_d)$ and $X_2 \sim \mathcal{N}(0, \mathrm{I}_d)$, with $d \in \mathbb N^\star$. The noise terms follow Gaussian distributions $\varepsilon_1 \sim \mathcal{N}(0, \sigma_1^2)$ and $\varepsilon_2 \sim \mathcal{N}(0, \sigma_2^2)$, with $\sigma_1, \sigma_2 > 0$.
Note that the independence assumption aims at simplifying the analysis in this toy-example by putting the emphasis on the impact of the hierarchical constraints rather than on the autocorrelation of the signal, though in practice this assumption is unrealistic for most time series. 
This is why we will develop a use case of hierarchical forecasting with real-world time series in Section~\ref{sec:tourism}.

What distinguishes this hierarchical prediction setting is the assumption that $\sigma_1 \geq \sigma_2$. 
Consequently, conditional on $X_1$ and $X_2$, the sum $Y_1 + Y_2= \langle  X_1, \theta_1 \rangle + \langle  X_2, \theta_2 \rangle + \varepsilon_2$ has a lower variance than either $Y_1$ or $Y_2$. 
We assume access to $n$ i.i.d.~copies $(X_{1,i}, X_{2,i}, Y_{1,i}, Y_{2,i})_{i=1}^n$ of the random variables $(X_1, X_2, Y_1, Y_2)$. 
The goal is to construct three estimators $\hat{Y}_1$, $\hat{Y}_2$, and $\hat{Y}_3$ of $Y_1$, $Y_2$, and $Y_3:=Y_1+Y_2$.

\paragraph{Benchmark.} We compare four techniques. The \textit{bottom-up (BU)} approach involves running two separate ordinary least squares (OLS) regressions that independently estimate $Y_1$ and $Y_2$ without using information about $Y_1 + Y_2$. Specifically,
\[
\hat{Y}_1^{\mathrm{BU}} = \langle X_1, \hat{\theta}_1^{\mathrm{BU}} \rangle, \quad \hat{Y}_2^{\mathrm{BU}} = \langle X_2, \hat{\theta}_2^{\mathrm{BU}} \rangle,
\]
where the OLS estimators are
\[
\hat{\theta}_1^{\mathrm{BU}} = (\mathbb{X}_1^\top \mathbb{X}_1)^{-1} \mathbb{X}_1^\top \mathbb{Y}_1, \quad \hat{\theta}_2^{\mathrm{BU}} = (\mathbb{X}_2^\top \mathbb{X}_2)^{-1} \mathbb{X}_2^\top \mathbb{Y}_2.
\]
Here, $\mathbb X_1 = (X_{1,1} \mid  \cdots \mid 
    X_{1,n})^\top$ and  $\mathbb X_2 = (X_{2,1}\mid \cdots \mid
    X_{2,n})^\top$ are $n \times d$ matrices, while  $\mathbb Y_1 = (Y_{1,1}, \hdots ,
    Y_{1,n})^\top$ and  $\mathbb Y_2 = (Y_{2,1}, \hdots ,
    Y_{2,n})^\top$ are vectors of $\mathbb R^n$.
To estimate $Y_3$, we simply set $\hat Y_3^{\mathrm{BU}}  = \hat Y_1^{\mathrm{BU}}  + \hat Y_2^{\mathrm{BU}} $.

The \textit{Reconciliation (Rec)} approach involves running three independent forecasts of $Y_1$, $Y_2$, and $Y_3$, followed by using the constraint that the updated estimator $\hat Y_3^{\mathrm{Rec}}$ should be the sum of $\hat Y_1^{\mathrm{Rec}}$ and $\hat Y_2^{\mathrm{Rec}}$ \citep{Wickramasuriya2019optimal}. To estimate $Y_3$, we run an OLS regression with 
$\mathbb X = (\mathbb X_1\mid  \mathbb X_2)$  and $\mathbb Y = \mathbb Y_1 +  \mathbb Y_2$. In this approach, 
\[
\begin{pmatrix}
    \hat Y_{3,t}^{\mathrm{Rec}}\\
    \hat Y_{1,t}^{\mathrm{Rec}}\\
    \hat Y_{2,t}^{\mathrm{Rec}}
\end{pmatrix} = S (S^T S)^{-1} S^T\begin{pmatrix}
    &\langle X_{t}, (\mathbb X^\top \mathbb X)^{-1}\mathbb X^\top \mathbb Y\rangle\\
    &\langle X_{1,t}, \hat \theta_1^{\mathrm{BU}}\rangle\\
    &\langle X_{2,t}, \hat \theta_2^{\mathrm{BU}}\rangle
\end{pmatrix},
\]
with $S = \begin{pmatrix}
    1 & 1 \\
    1 & 0 \\
    0 & 1
\end{pmatrix}$ and $X_t = (X_{1,t} \mid X_{2,t})$.

The \textit{Minimum Trace (MinT)} approach is an alternative update method that replaces the update matrix $S (S^\top S)^{-1} S^T$ with
$S (J-JWU(U^\top W U)^{-1}U^\top)$,
$J = \begin{pmatrix}
    0 & 1 & 0\\
    0 & 0 & 1 
\end{pmatrix}$,
$W$ the $3 \times 3$ covariance matrix of the prediction errors on the training data, and
$U = \begin{pmatrix}
    -1 &1 & 1
\end{pmatrix}^\top$ \citep{Wickramasuriya2019optimal}.
This approach extends the linear projection onto $\mathrm{Im}(S)$ and better accounts for correlations in the noise of the time series. 
Finally, we apply the WeaKL-BU estimator \eqref{eq:pikl-bu} with $M=0$, $\phi_1(x) = x$, $\phi_2(x) = x$, and $\Lambda = \mathrm{Diag}(1,1, \lambda)$, where $\lambda > 0$ is a hyperparameter that controls the penalty on the joint prediction $Y_{1} + Y_{2}$. 
It minimizes the empirical loss
\[
L(\theta_1, \theta_2) = \frac{1}{n}\sum_{i=1}^n |\langle X_{1,i}, \theta_1\rangle- Y_{1,i}|^2 + |\langle X_{2,i}, \theta_2\rangle-Y_{2,i}|^2 + \lambda |\langle X_{1,i}, \theta_1\rangle + \langle X_{1,i}, \theta_2\rangle- Y_{1,i}-Y_{2,i}|^2,
\]
In the experiments, we set $\lambda = \sigma_2^{-2}$ for simplicity, although it can be easily learned by cross-validation.
\begin{figure}
    \centering
    \includegraphics[width=0.4\linewidth]{hier_y1_20.png}
    \includegraphics[width=0.4\linewidth]{hier_y2_20.png}
    \includegraphics[width=0.4\linewidth]{hier_sum_20.png}
    \includegraphics[width=0.4\linewidth]{hier_tot_20.png}
    \caption{Hierarchical forecasting performance with $2d/n = 0.5$.}
    \label{fig:hier}
\end{figure}

\paragraph{Monte Carlo experiment.} To compare the performance of the different methods, we perform a Monte Carlo experiment. Since linear regression is invariant under multiplication by a constant, we set $\sigma_1=1$ without loss of generality. 
Since $\sigma_2 \leq \sigma_1$, we allow $\sigma_2$ to vary from $0$ to $1$. For each value of $\sigma_2$, we run $1000$ Monte Carlo simulations, where each simulation uses $n = 80$ training samples and $\ell = 20$ test samples. In each Monte Carlo run, we independently draw $\theta_1 \sim \mathcal N(0, I_d)$, $\theta_2 \sim \mathcal N(0, I_d)$, $X_{1,i} \sim \mathcal N(0, I_{ d})$, $X_{2,i} \sim \mathcal N(0, I_{d})$, $\varepsilon_{1,i} \sim \mathcal N(0, 1)$, and $\varepsilon_{2,i} \sim \mathcal N(0, \sigma_2^2)$, where $1 \leq i \leq n$. 
Note that, on the one hand, the $L^2$ error of an OLS regression on $Y_1 + Y_2$ is $\sigma_2^2 (1 + 2d/n)$, while on the other hand, the minimum possible $L^2$ error when fitting  $Y_1 + Y_2$ is $\sigma_2^2$.
Thus,  a large $2d/n$ is necessary to observe the benefits of hierarchical prediction. To achieve this, we set $d = 20$, resulting in $2d/n = 0.5$.

The models are trained on the $n$ training data points, and their performance is evaluated on the $\ell$ test data points using the mean squared error (MSE). Given any estimator $(\hat{Y}_1$, $\hat{Y}_2$, $\hat{Y}_3)$ of $(Y_1, Y_2, Y_1+Y_2)$, we compute the error $\ell^{-1}\sum_{j=1}^\ell| Y_{1, n+j}- \hat Y_{1, n+j}|^2$ on $Y_1$, the error $\ell^{-1}\sum_{j=1}^\ell| Y_{2, n+j}- \hat Y_{2, n+j}|^2$ on $Y_2$, and the error $\ell^{-1}\sum_{j=1}^\ell| Y_{1, n+j} + Y_{2, n+j}- \hat Y_{3, n+j}|^2$ on $Y_1 + Y_2$. 
The hierarchical error is defined as the sum of these three MSEs, which are visualized in Figure \ref{fig:hier}. 

\paragraph{Results.} Figure \ref{fig:hier} clearly shows that all hierarchical models (Rec, MinT, and WeaKL) outperform the naive bottom-up model for all four MSE metrics. Among them, our WeaKL consistently emerges as the best performing model, achieving superior results for all values of $\sigma_2$. Our WeaKL delivers gains ranging from $10\%$ to $50\%$ over the bottom-up model, solidifying its effectiveness in the benchmark.

The strong performance of WeaKL can be attributed to its approach, which goes beyond simply computing the best linear combination of linear experts to minimize the hierarchical loss, as reconciliation methods typically do. Instead, WeaKL directly optimizes the weights $\theta_1$ and $\theta_2$ to minimize the hierarchical loss.
Another way to interpret this is that when the initial forecasts are suboptimal, reconciliation methods aim to find a better combination of those forecasts, but do so without adjusting their underlying weights. In contrast, the WeaKL approach explicitly recalibrates these weights, resulting in a more accurate and adaptive hierarchical forecast.

\paragraph{Extension to the over-parameterized limit.} Another advantage of WeakL is that it also works for $d$ such that $2n \geq 2d \geq n$. 
In this context, the Rec and MinT algorithms cannot be computed because the OLS regression of $\mathbb Y$ on $\mathbb X$ is overparameterized ($2d$ features but only $n$ data points). 
To study the performance of the benchmark in the $n \simeq d$ limit, we repeated the same Monte Carlo experiment, but with $d = 38$, resulting in $d/n = 0.95$.
\begin{figure}
    \centering
    \includegraphics[width=0.4\linewidth]{hier_y1_38.png}
    \includegraphics[width=0.4\linewidth]{hier_y2_38.png}
    \includegraphics[width=0.4\linewidth]{hier_sum_38.png}
    \includegraphics[width=0.4\linewidth]{hier_tot_38.png}
    \caption{Hierarchical forecasting performance with $2d/n = 0.95$.}
    \label{fig:hier_2}
\end{figure}
The MSEs of the methods are shown in Figure~\ref{fig:hier_2}. These results further confirm the superiority of the WeaKL approach in the overparameterized regime. 
Note that such overparameterized situations are common in hierarchical forecasting.  
For example, forecasting an aggregate index-such as electricity demand, tourism, or food consumption-at the national level using city-level data across $d \gg 1$ cities (e.g., local temperatures) often leads to an overparameterized model.


\paragraph{Extension to non-linear regressions.} For simplicity, our experiments have focused on linear regressions. However, it is important to note that the hierarchical WeaKL can be applied to nonlinear regressions using exactly the same formulas. Specifically, in cases where $Y_1 = f_1(X_1) + \varepsilon_1$ and $Y_2 = f_2(X_2) - \varepsilon_1 + \varepsilon_2$, where $f_1$ and $f_2$ represent nonlinear functions, the WeaKL approach remains valid. This is because the connection to the linear case is straightforward: the WeaKL essentially performs a linear regression on the Fourier coefficients of $X_1$ and $X_2$, seamlessly extending its applicability to nonlinear settings.

\section{Experiments}
This appendix provides comprehensive details on the use cases discussed in the main text.
Appendix~\ref{sec:tuning} describes our hyperparameter tuning technique.
Appendix~\ref{sec:block-bootstrap} explains how we evaluate uncertainties.
Appendix~\ref{sec:half-hour} outlines our approach to handling sampling frequency in electricity demand forecasting applications.
Appendix~\ref{sec:case_study1} details the models used in Use case 1, while Appendix~\ref{sec:sobriety} focuses on Use case $2$, and Appendix~\ref{sec:hierarchical_details} covers the tourism demand forecasting use case.

\subsection{Hyperparameter tuning}
\label{sec:tuning}
\paragraph{Hyperparameter tuning of the additive WeaKL.} Consider a WeaKL additive model
\begin{align*}
    f_{\theta}(X_t) &=  \langle \phi_{1,1}(X_{1,t}), \theta_{1,1}\rangle + \cdots + \langle \phi_{1,d_1}(X_{d_1,t}), \theta_{1,d_1}\rangle,%,\\&    =  g_1(X_{1,t}) + \cdots + g_{d_1}(X_{d_1,t}),
\end{align*}
where the type (linear, nonlinear, or categorical) of the effects are specified. Thus, as detailed in Section~\ref{sec:shape},
\begin{itemize}
    \item[$(i)$] If the effect $\langle \phi_{1,\ell}(X_{\ell,t}), \theta_{1,j}\rangle$ is assumed to be linear, then $\phi_{1,j}(X_{\ell,t}) = X_{\ell,t}$,
    \item[$(ii)$] If the effect $\langle \phi_{1,\ell}(X_{\ell,t}), \theta_{1,\ell}\rangle$ is assumed to be  nonlinear, then $\phi_{1,\ell}$ is a Fourier map with $2m_\ell +1$ Fourier modes,
    \item[$(iii)$] If the effect $\langle \phi_{1,\ell}(X_{\ell,t}), \theta_{1,\ell}\rangle$ is assumed to be categorical with values in $E$, then $\phi_{1,\ell}$ is a Fourier map with $2\lfloor |E|/2\rfloor+1$ Fourier modes.
\end{itemize}
We let $\mathbf{m} = \{m_\ell\mid \hbox{the effect $\langle \phi_{1,\ell}(X_{\ell,t}), \theta_{1,\ell}\rangle$ is nonlinear}\}$ be the concatenation of the numbers of Fourier modes of the nonlinear effects.
The goal of hyperparameter tuning is to find the best set of hyperparameters $\lambda = (\lambda_1, \hdots, \lambda_{d_1})$ and 
$\mathbf{m}$ for the empirical risk \eqref{eq:weaklGAM} of the additive WeaKL.

To do so, we split the data into three sets: a training set, then a validation set, and finally a test set.
These three sets must be disjoint to avoid overfitting, and the test set is the dataset on which the final performance of the method will be evaluated.
The sets should be chosen so that the distribution of $(X,Y)$ on the validation set resembles as much as possible the distribution of $(X,Y)$ on the test set.

We consider a list of potential candidates for the optimal set of hyperparameters $(\lambda ,\mathbf{m})_{\mathrm{opt}}$. 
Since we have no prior knowledge about $(\lambda, \mathbf{m})$, we chose this list to be a grid of parameters. For each element $(\lambda, \mathbf{m})$ in the grid, we compute the minimizer $\hat \theta(\lambda, \mathbf{m})$ of the loss \eqref{eq:weaklGAM} over the training period. Then, given $\hat \theta(\lambda, \mathbf{m})$, we compute the mean squared error (MSE) of $f_{\hat \theta(\lambda, \mathbf{m})}$ over the validation period. This procedure is commonly referred to as grid search. The resulting estimate of the optimal hyperparameters $(\lambda, \mathbf{m})_{\mathrm{opt}}$ corresponds to the values of  $(\lambda, \mathbf{m})$ that minimize the MSE of  $f_{\hat \theta(\lambda, \mathbf{m})}$ over the validation period. The performance of the additive WeaKL is then assessed based on the performance of $f_{\hat \theta(\lambda, \mathbf{m})_{\mathrm{opt}}}$ on the test set.
\paragraph{Hyperparameter tuning of the online WeaKL.} Consider an online WeaKL
\begin{equation*}
    f_\theta(t, x_1, \hdots, x_{d_1}) = h_{\theta_0}(t)+ \sum_{\ell=1}^{d_1} (1+ h_{\theta_\ell}(t))  \hat g_\ell(x_\ell),
\end{equation*}
where the effects $\hat g_\ell$ are known, and the updates $h_{\theta_\ell}(t) = \langle \phi(t), \theta_\ell\rangle$ are such that $\phi$ is the Fourier map $\phi(t) =(\exp(i k t/2))_{-m_j\leq k \leq m_j}^\top$, with $m_j \in \mathbb N^\star$.
We let $\mathbf{m} = \{m_j\mid 0\leq j \leq d_1\}$ be the concatenation of the numbers of Fourier modes.
The goal of hyperparameter tuning is to find the best set of hyperparameters $\lambda = (\lambda_0, \hdots, \lambda_{d_1})$ and 
$\mathbf{m}$ for the empirical risk \eqref{eq:risk_online} of the online WeaKL.

To do so, we split the data into three sets: a training set, then a validation set, and finally a test set.
This three sets must be disjoint to avoid overfitting.
Moreover, the training set and the validation set must be disjoint from the data used to learn the effects $\hat g_\ell$.
The test set must be the set on which the final performance of the method will be evaluated. 
The sets should be chosen so that the distribution of $(X,Y)$ on the validation set resembles as much as possible the distribution of $(X,Y)$ on the test set.
Similarly to the hyperparameter tuning of the additive WeaKL, we then consider a list of potential candidates for the optimal hyperparameter $(\lambda ,\mathbf{m})_{\mathrm{opt}}$, which can be a grid.
Then, we compute the minimizer $\hat \theta(\lambda, \mathbf{m})$ of the loss \eqref{eq:risk_online} on the training period, and the resulting estimation of $(\lambda, \mathbf{m})_{\mathrm{opt}}$ is the set of hyperparameters $(\lambda, \mathbf{m})$ such that the MSE of $f_{\hat \theta(\lambda, \mathbf{m})}$ on the validation period is minimal.
The performance of the online WeaKL is thus measured by the performance of $f_{\hat \theta(\lambda, \mathbf{m})_{\mathrm{opt}}}$ on the test set.

\subsection{Block bootstrap methods}
\label{sec:block-bootstrap}
\paragraph{Evaluating uncertainties with block bootstrap.}
The purpose of this paragraph is to provide theoretical tools for evaluating the performance of time series estimators.
Formally, given a test period $\{t_1, \hdots, t_n\}$, a  target time series $(Y_{t_j})_{1\leq j \leq n}$, and an estimator $(\hat Y_{t_j})_{1\leq j \leq n}$ of $Y$, the goal is to construct confidence intervals that quantify how far $\mathrm{RMSE}_{n} = (n^{-1}\sum_{j=1}^n |\hat Y_{t_j} - Y_{t_j}|^2)^{1/2}$ deviates from its expectation 
$\mathrm{RMSE} = (\mathbb{E} |\hat Y_{t_1} - Y_{t_1}|^2)^{1/2}$, and  how far  $\mathrm{MAPE}_n = n^{-1}\sum_{j=1}^n |\hat Y_{t_j} - Y_{t_j}| |Y_{t_j}|^{-1}$ deviates from its expectation $\mathrm{MAPE} = \mathbb{E}( |\hat Y_{t_1} - Y_{t_1}| |Y_{t_1}|^{-1})$.
Here, we assume that $Y$ and $\hat{Y}$ are strongly stationary, meaning their distributions remain constant over time.
Constructing such confidence intervals is non-trivial because the observations $Y_{t_j}$ in the time series $Y$ are correlated, preventing the direct application of the central limit theorem.
The block bootstrap algorithm is specifically designed to address this challenge and is defined as follows.

Consider a sequence $Z_{t_1},Z_{t_2},\hdots,Z_{t_n}$ such that the quantity of interest can be expressed as $g(\mathbb{E}(Z_{t_1}))$, for some function $g$. 
This quantity is estimated by $g(\bar Z_n)$, where $\bar Z_n = n^{-1}\sum_{j=1}^n Z_{t_j}$ is the empirical mean of the sequence.
For example, $\mathrm{RMSE} = g(\mathbb E(Z_{t_1}))$ and $\mathrm{RMSE}_n = g(\bar Z_n)$ for $g(x) = x^{1/2}$ and $Z_{t_j}=(Y_{t_j}-\hat{Y_{t_j}})^2$, while $\mathrm{MAPE} = g(\mathbb E(Z_{t_1}))$ and  $\mathrm{MAPE}_n = g(\bar Z_n)$  for $g(x) = x$ and $Z_{t_j}=|\hat Y_{t_j} - Y_{t_j}| |Y_{t_j}|^{-1}$.
The goal of the block bootstrap algorithm is to estimate the distribution of $g(\bar Z_n)$.

Given a length $\ell \in \mathbb N^\star$ and a starting time $t_j$, we say that $(Z_{t_j}, \hdots, Z_{t_{j+\ell-1}})\in \mathbb R^\ell$ is a block of length $\ell$ starting at $t_j$. We draw  $b = \lfloor n/\ell\rfloor +1$ blocks of length $\ell$ uniformly from the sequence  $(Z_{t_1}, Z_{t_2}, \dots, Z_{t_n})$ and then concatenate these blocks to form the sequence $Z^\ast = (Z_1^\ast, Z_2^\ast, \dots, Z_{b\ell}^\ast)$.
Thus, $Z^\ast$ is a resampled version of $Z$  obtained with replacement.

For convenience, we consider only the first $n$ values of $Z^\ast$ and compute the bootstrap version of the empirical mean: $\bar{Z}^\ast_n=\frac{1}{n}\sum_{j=1}^nZ^\ast_j$. By repeatedly resampling the $b$ blocks and generating multiple instances of $\bar{Z}^\ast_n$, the resulting distribution of $\bar{Z}^\ast_n$  provides a reliable estimate of the distribution of $\bar{Z}_n$.
In particular, under general assumptions about the decay of the autocovariance function of $Z$, choosing $\ell = \lfloor n^{1/4} \rfloor$ leads to 
\[\sup_{x\in\mathbb{R}}|\mathbb{P}(T^{\ast}_n\leq x\mid Z_{t_1},\hdots,Z_{t_n})-\mathbb{P}(T_n\leq x)| = O_{n\to \infty}(n^{-3/4}),\]  where $T^{\ast}_n=\sqrt n(\bar{Z}^\ast_n-\mathbb{E}(\bar{Z}^\ast_n\mid Z_{t_1},\hdots,Z_{t_n}))$ and $T_n=\sqrt n(\bar{Z}_n-\mathbb{E}(Z_{t_1}))$ \citep[see, e.g.][Theorem 6.7]{lahiri2013resampling}.
Note that this convergence rate of $n^{-3/4}$ is actually quite fast, as even if the $Z_{t_j}$  were i.i.d., the empirical mean $\bar{Z}_n$  would only converge to a normal distribution at a rate of $n^{-1/2}$
(by the Berry-Esseen theorem). This implies that the block bootstrap method estimates the distribution of $\bar{Z}_n$ faster than $\bar{Z}_n$  itself converges to its Gaussian limit.

The choice of $\ell$ plays a crucial role in this method.
For instance, setting $\ell = 1$ leads to an underestimation of the variance of $\bar{Z}_n$  when the $Z_{t_j}$ are correlated \citep[see, e.g.][Corollary 2.1]{lahiri2013resampling}.
In addition, block resampling introduces a bias, as $Z_{t_n}$ belongs to only a single block and is therefore less likely to be resampled than  $Z_{t_{\lfloor n/2\rfloor}}$.
This explains why $\mathbb{E}(\bar{Z}^\ast_n \mid Z_{t_1}, \dots, Z_{t_n}) \neq \bar{Z}_n$.
To address both problems, \citet{politis1994stationary} introduced the stationary bootstrap, where the block length $\ell$ varies and follows a geometric distribution.

\paragraph{Comparing estimators with block bootstrap.}
Given two stationary estimators $\hat Y^1$ and $\hat Y^2$ of $Y$,  the goal is to develop a test of level $\alpha \in [0,1]$ for the hypothesis $H_0: \mathbb E|\hat Y^1_t-Y_t| = \mathbb E|\hat Y^2_t-Y_t|$. Using the previous paragraph, such a test could be implemented by estimating two confidence intervals $I_1$ and $I_2$ for $\mathbb E|\hat Y^1_t-Y_t|$ and $\mathbb E|\hat Y^2_t-Y_t|$ at level $\alpha/2$ using block bootstrap, and then rejecting $H_0$  if  $I_1 \cap I_2 = \emptyset$. However, this approach tends to be conservative, potentially reducing the power of the test when assessing whether one estimator is significantly better than the other.  

To create a more powerful test, \citet{Messner2020evaluation} and \citet{Farrokhabadi2022day} suggest relying on the MAE skill score, which is defined by \[\mathrm{Skill}=1-\frac{\mathrm{MAE_{1}}}{\mathrm{MAE_{2}}},\]
where $\mathrm{MAE_{1}}$ and $\mathrm{MAE_{2}}$ are the mean average errors of $\hat{Y}^{1}$ and $\hat{Y}^2$, respectively. 
Note that $\mathrm{Skill}= (\mathrm{MAE}_{2} - 
\mathrm{MAE_{1}})/\mathrm{MAE_{2}}$
is the relative distance between the two $\mathrm{MAE}$s. Thus, $\hat{Y}^{1}$ is significantly better than $\hat{Y}^2$ if $\mathrm{Skill}$ is significantly positive.
A confidence interval for $\mathrm{Skill}$ can be obtained  by block bootstrap.
Indeed, consider the time series $Z$ defined as $Z_{t_j}=(|\hat{Y}^{1}_{t_j}-Y^1_{t_j}|,|\hat{Y}^{2}_{t_j}-Y^2_{t_j}|)$, and let $g(x,y)=1-x/y$. We use the block bootstrap method over this sequence to estimate $g(\mathbb E(Z))$ by generating different samples of $\mathrm{MAE_{1}}$ and $\mathrm{MAE_{2}}$. In particular, in Appendix~\ref{sec:case_study1}, $\hat{Y}^{1}$ corresponds to WeakL, while $\hat{Y}^{2}$ is the estimator of the winning team of the IEEE competition.

\subsection{Half-hour frequency}
\label{sec:half-hour}

Short-term electricity demand forecasts are often estimated with a half-hour frequency, meaning that the objective is to predict electricity demand every $30$ minutes during the test period. This applies to both Use case 1 and Use case 2.
There are two common approaches to handling this frequency in forecasting models. One approach is to include the half-hour of the day as a feature in the models. The alternative, which yields better performance, is to train a separate model for each half-hour, resulting in $48$ distinct models. This superiority arises because the relationship between electricity demand and conventional features (such as temperature and calendar effects) varies significantly across different times of the day. For instance, electricity demand remains stable at night but fluctuates considerably during the day. This variability justifies treating the forecasting problem at each half-hour as an independent learning task, leading to $48$ separate models. Consequently, in both use cases, all models discussed in this paper---including WeaKL, as well as those from \citet{vilmarest2022state} and \citet{doumeche2023human}---are trained separately for each of the $48$ half-hours, using identical formulas and architectures. This results in $48$ distinct sets of model weights. 
For simplicity, and since the only consequence of this preprocessing step is to split the learning data into $48$ independent groups, this distinction is omitted from the equations.

\subsection{Precisions on the Use case 1 on the IEEE DataPort Competition on Day-Ahead Electricity Load Forecasting}
\label{sec:case_study1}
In this appendix, we provide additional details on the two WeaKLs used in the benchmark for Use case 1 of the IEEE DataPort Competition on Day-Ahead Electricity Load Forecasting. The first model is a direct adaptation of the GAM-Viking model from \citet{vilmarest2022state} into the WeaKL framework. The second model is a WeaKL where the effects are learned through hyperparameter tuning.
\paragraph{Direct translation of the GAM-Viking model into the WeaKL framework.} 


To build their model, \citet{vilmarest2022state} consider four primary models: an autoregressive model (AR), a linear regression model, a GAM, and a multi-layer perceptron (MLP). 
These models are initially trained on data from $18$ March $2017$ to $1$ January $2020$. 
Their weights are then updated using the Viking algorithm starting from $1$ March $2020$ \citep[][Table~3]{vilmarest2022state}. 
The parameters of the Viking algorithm were manually selected by the authors based on performance monitoring over the $2020$â€“$2021$ period \citep[][Figure7]{vilmarest2022state}. 
To further refine the forecasts, the model errors are corrected using an autoregressive model, which they called the intraday correction and implemented as a static Kalman filter. The final forecast is obtained by online aggregation of all models, meaning that the predictions from different models are combined in a linear combination that evolves over time. The weights of this aggregation are learned using the ML-Poly algorithm from the \texttt{opera} package \citep{gaillard2016opera}, trained over the period $1$ July $2020$ to $18$ January $2021$. 
The test period spans from $18$ January $2021$ to $17$ February $2021$. 
During this period, the aggregated model achieves a MAE of $10.9$~GW, while the Viking-updated GAM model alone yields an MAE of $12.7$~GW.

Here, to ensure a fair comparison between our WeaKL framework and the GAM-Viking model of \citet{vilmarest2022state}, we replace their GAM-Viking with our online WeaKL in their aggregation. Our additive WeaKL model is therefore a direct translation of their offline GAM formulation into the WeaKL framework. Specifically, we consider the additive WeaKL based on the features $X = (\mathrm{DoW}, \mathrm{FTemps95_{corr1}}, \mathrm{Load_1}, \mathrm{Load_7}, \mathrm{ToY}, t)$ corresponding to
\begin{equation*}
\begin{split} 
Y_t =& g_1^\star(\mathrm{DoW}_t)
   +g_2^\star(\mathrm{FTemps95_{corr1}}_t)
   + g_3^\star(\mathrm{Load_1}_t) +g_4^\star(\mathrm{Load_7}_t)+g_5^\star(\mathrm{ToY}_t)
      +g_6^\star(t) +\varepsilon_t,
\end{split}
\end{equation*}
where $g_1^\star$ is categorical with 7 values, $g_2^\star$ and $g_6^\star$  are linear,  $g_3^\star$, $g_4^\star$, and $g_5^\star$ are nonlinear.

$\mathrm{FTemps95_{corr1}}$ is a smoothed version of the temperature, while the other features remain the same as those used in Use case 2. The weights of the additive WeaKL model are determined using the hyperparameter selection technique described in Appendix~\ref{sec:tuning}. 
The training period spans from $18$ March $2017$ to $1$ November $2019$, while the validation period extends from $1$ November $2019$ to $1$ January $2020$. 
During this grid search, the performance of $250,047$ sets of hyperparameters $(\lambda, \mathbf m)\in \mathbb R^7\times \mathbb R^3$ is evaluated in less than a minute using a standard GPU (Nvidia L4 GPU, $24$~GB RAM, $30.3$ teraFLOPs for Float32). 
Notably, this optimization period exactly matches the training period of the primary models in \citet{vilmarest2022state}, ensuring a fair comparison between the two approaches.

Then, we run an online WeaKL, where the effects $\hat g_\ell$, $1\leq \ell \leq 7$, are inherited directly from the previously trained additive WeaKL. 
The weights of this online WeaKL are determined using the hyperparameter selection technique described in Appendix~\ref{sec:tuning}. 
The training period extends from $1$ February $2020$ to $18$ November $2020$, while the validation period extends from $18$ November $2020$ to $18$ January $2021$, immediately preceding the final test period to ensure optimal adaptation. During this grid search, we evaluate $625$ sets of hyperparameters $(\lambda, \mathbf m)\in \mathbb R^6\times \mathbb R^6$ in less than a minute using a standard GPU. 
Since $t$ is already included as a feature, the function  $h_0^\ast$ in Equation~\eqref{eq:model} is not required in this setting.

Finally, we evaluate the performance of our additive WeaKL (denoted as $\hbox{WeaKL}_{\mathrm{+}}$), our additive WeaKL followed by intraday correction ($\hbox{WeaKL}_{+,\mathrm{intra}}$), our online WeaKL ($\hbox{WeaKL}_{\mathrm{on}}$), our online WeaKL with intraday correction ($\hbox{WeaKL}_{\mathrm{on, intra}}$), and an aggregated model based on \citet{vilmarest2022state}, where the GAM and GAM-Viking models are replaced by our additive and online WeaKL models ($\hbox{WeaKL}_{\mathrm{agg}}$). The test period remains consistent with \citet{vilmarest2022state}, spanning from $18$ January $2021$ to $17$ February $2021$. Their performance results are presented in Table~\ref{tab:gam-vik} and compared to their corresponding translations within the GAM-Viking framework.
\begin{table}
    \centering
    \caption{Comparing GAM-Viking with its direct translation in the WeaKL framework on the final test period}
    \begin{tabular}{|c|ccccc|}
        \hline
        Model GAM &  $\hbox{GAM}_{\mathrm{+}}$ & $\hbox{GAM}_{+,\mathrm{intra}}$ & $\hbox{GAM}_{\mathrm{on}}$ & $\hbox{GAM}_{\mathrm{on, intra}}$ & $\hbox{GAM}_{\mathrm{agg}}$\\
        \hline
         MAE (GW) & 48.3 & 22.7 & 13.2 & 12.7 & 10.9\\
         \hline
         \hline
        Model WeaKL &  $\hbox{WeaKL}_{\mathrm{+}}$ & $\hbox{WeaKL}_{+,\mathrm{intra}}$ & $\hbox{WeaKL}_{\mathrm{on}}$ & $\hbox{WeaKL}_{\mathrm{on, intra}}$ & $\hbox{WeaKL}_{\mathrm{agg}}$\\
        \hline
         MAE (GW) & 58.0 & 23.4 & 11.2 & 11.3 & 10.5\\
         \hline
    \end{tabular}
    \label{tab:gam-vik}
\end{table}
Thus, $\hbox{GAM}_{\mathrm{+}}$ refers to the offline GAM, while $\hbox{GAM}_{+,\mathrm{intra}}$ corresponds to the offline GAM with an intraday correction. Similarly, $\hbox{GAM}_{\mathrm{on}}$ represents the GAM-Viking model, and $\hbox{GAM}_{\mathrm{on, intra}}$ denotes the GAM-Viking model with an intraday correction. Finally, $\hbox{GAM}_{\mathrm{agg}}$ corresponds to the final model proposed by \citet{vilmarest2022state}.

The performance $\hbox{GAM}_{\mathrm{+}}$, $\hbox{GAM}_{\mathrm{+, intra}}$, $\hbox{WeaKL}_{\mathrm{+}}$, and $\hbox{WeaKL}_{\mathrm{+, intra}}$ in Table~\ref{tab:gam-vik} alone is not very meaningful because the distribution of electricity demand differs between the training and test periods. To address this, Table~\ref{tab:gam-vik-norm} presents a comparison of the same algorithms, trained on the same period but evaluated on a test period spanning from $1$ January $2020$ to $1$ March $2020$. In this stationary period, WeaKL outperforms the GAMs.
\begin{table}
    \centering
    \caption{Comparing GAM with its direct translation in the WeaKL framework on a stationary test period.}
    \begin{tabular}{|c|cccc|}
        \hline
        Model &  $\hbox{GAM}_{\mathrm{+}}$ &  $\hbox{WeaKL}_{\mathrm{+}}$ & $\hbox{GAM}_{+,\mathrm{intra}}$ & $\hbox{WeaKL}_{+,\mathrm{intra}}$\\
        \hline
         MAE (GW) & 20.7 & 19.1 & 19.3 & 19.2\\
         \hline
    \end{tabular}
    \label{tab:gam-vik-norm}
\end{table}

Moreover, in Table~\ref{tab:gam-vik}, the online WeaKLs clearly outperform the GAM-Viking models, achieving a reduction in MAE of more than $10\%$.
As a result, replacing the GAM-Viking models in the aggregation leads to improved overall performance. Notably, the WeaKLs are direct translations of the GAM-Viking models, meaning that the performance gains are due solely to model optimization and not to any structural changes.

\paragraph{Pure WeaKL.}
In addition, we trained an additive WeaKL using a different set of variables than those in the GAM model, aiming to identify an optimal configuration. Specifically, we consider the additive WeaKL with 
\begin{align*}
    X= (&\mathrm{FcloudCover\_corr1},\mathrm{Load1D},\mathrm{Load1W},\mathrm{DayType},\mathrm{FTemperature\_corr1},\\  &\mathrm{FWindDirection}, \mathrm{FTemps95\_corr1},\mathrm{Toy},\mathrm{t}),
\end{align*} where 
\begin{itemize}
    \item[$(i)$] the effects of $\mathrm{FclouCover\_corr1}$, $\mathrm{Load1D}$, and $\mathrm{Load1W}$ are nonlinear,
    \item[$(ii)$] the effect of $\mathrm{DayType}$ is categorical with 7 values,
    \item[$(iii)$] the remaining effects are linear.
\end{itemize}
This model is trained using the hyperparameter tuning process detailed in Appendix~\ref{sec:tuning}, with the training period spanning from $18$ March $2017$ to $1$ January $2020$, and validation starting from $1$ October $2019$.
Next, we fit an online WeaKL model, with hyperparameters tuned using a training period from $1$ March $2020$ to $18$ November $2020$ and a validation period extending until $18$ January $2021$.

To verify that our pure WeaKL model achieves a significantly lower error than the best model from the IEEE competition, we estimate the $\mathrm{MAE}$ skill score by comparing our pure WeaKL to the model proposed by \citet{vilmarest2022state}. To achieve this, we follow the procedure detailed in Appendix~\ref{sec:block-bootstrap}, using block bootstrap with a block length of $\ell = 24$ and $3000$ resamples to estimate the distribution of the $\mathrm{MAE}$ skill score, $\mathrm{Skill}$. Here, $\hat{Y}^1$ represents the WeaKL, while $\hat{Y}^2$ corresponds to the estimator from \citet{vilmarest2022state}. To evaluate the performance difference, we estimate the standard deviation $\sigma_n$ of $\mathrm{Skill}_n$ and construct an asymptotic one-sided confidence interval for $\mathrm{Skill}$. Specifically, we define
$\mathrm{Skill}_n = 1 - (\sum_{j=1}^n |\hat Y^1_{t_j} - Y_{t_j}| )/(\sum_{j=1}^n |\hat Y^2_{t_j} - Y_{t_j}|)$
and consider the confidence interval $[\mathrm{Skill}_n - 1.28 \sigma_n, +\infty[$, which corresponds to a confidence level of $\alpha = 0.1$. The resulting interval, $[0.007, +\infty[$, indicates that the $\mathrm{Skill}$ score is positive with at least $90\%$ probability. Consequently, with at least $90\%$ probability, the WeaKL  chieves a lower $\mathrm{MAE}$ than the best model from the IEEE competition.

\subsection{Precision on the use Use case 2 on forecasting the French electricity load during the energy crisis}
\label{sec:sobriety}
This appendix provides detailed information on the additive WeaKL and the online WeaKL used in Use case 2, which focuses on forecasting the French electricity load during the energy crisis.
\paragraph{Additive WeaKL.} As detailed in the main text, the additive WeaKL is built using the following features:
\[X =(\mathrm{Load}_1, \mathrm{Load}_7, \mathrm{Temp}, \mathrm{Temp}_{950},  \mathrm{Temp}_{\mathrm{max 950}}, \mathrm{Temp}_{\mathrm{min 950}}, \mathrm{ToY},  \mathrm{DoW}, \mathrm{Holiday},t).
\]

The effects of $\mathrm{Load}_1$, $\mathrm{Load}_7$, and $t$ are modeled as linear. The effects of $\mathrm{Temp}$, $\mathrm{Temp}_{950}$,  $\mathrm{Temp}_{\mathrm{max 950}}$, $ \mathrm{Temp}_{\mathrm{min 950}}$, and $\mathrm{ToY}$ are modeled as nonlinear with $m=10$. The effects of $\mathrm{DoW}$ and $\mathrm{Holiday}$ are treated as categorical, with $|E| = 7$ and $|E| = 2$, respectively. The model weights are selected through hyperparameter tuning, as detailed in Appendix~\ref{sec:tuning}. The training period spans from $8$ January $2013$ to $1$ September $2021$, while the validation period covers $1$ September $2021$ to $1$ September $2022$. Notably, this is the exact same period used by \citet{doumeche2023human} to train the GAM. The objective of the hyperparameter tuning process is to determine the optimal values for $\lambda = (\lambda_1, \hdots, \lambda_{10}) \in (\mathbb R^+)^{10}$ and $\mathbf{m} = (m_3, m_4, m_5, m_6, m_7) \in (\mathbb N^\star)^5$ in \eqref{eq:weaklGAM}. As a result, the additive WeaKL model presented in Use case 2 is the outcome of this hyperparameter tuning process.

\paragraph{Online WeaKL.} Next, we train an online WeaKL to update the effects of the additive WeaKL. To achieve this, we apply the hyperparameter selection technique detailed in Appendix~\ref{sec:tuning}. The training period spans from $1$ February $2018$ to $1$ April $2020$, while the validation period extends from $1$ April $2020$ to $1$ June $2020$. These periods, although not directly contiguous to the test period, were specifically chosen because they overlap with the COVID-19 outbreaks. This is crucial, as it allows the model to learn from a nonstationary period. Moreover, since online models require daily updates, the online WeaKL is computationally more expensive than the additive WeaKL. The training period is set to two years and two months, striking a balance between computational efficiency and GPU memory usage. Using the parameters $(\lambda, \mathbf m)$ obtained from hyperparameter tuning, we then retrain the model in an online manner with data starting from $1$ July $2020$, ensuring that the rolling training period remains at two years and two months.

\paragraph{Error quantification.} Following the approach of \citet{doumeche2023human}, the standard deviations of the errors are estimated using stationary block bootstrap with a block length of $\ell = 48$ and 1000 resamples.

\paragraph{Model running times.} Below, we present the running times of various models in the experiment that includes holidays:
\begin{itemize}
\item  GAM: $20.3$ seconds. 
\item Static Kalman adaption: $1.7$ seconds.
\item Dynamic Kalman adaption: $48$ minutes, for an hyperparameter tuning of $10^4$ sets of hyperparameters \citep[see][II.A.2]{obst2021adaptive}.
\item Viking algorithm: $215$ seconds (in addition to training the Dynamic Kalman model).
\item Aggregation: $0.8$ seconds.
\item GAM boosting model: $6.6$ seconds.
\item Random forest model: $196$ seconds.
\item Random forest + bootstrap model: $34$ seconds.
\item Additive WeaKL: grid search of $1.6\times 10^5$ hyperparameters: $257$ seconds; training a single model: $2$ seconds.
\item Online WeaKL: grid search of $9.2\times 10^3$ hyperparameters: $114$ seconds; training a single model: $52$ seconds.
\end{itemize}
\subsection{Precisions on the use case on hierarchical forecasting of Australian domestic tourism with transfer learning}
\label{sec:hierarchical_details} The matrices $\Lambda$ for the WeaKL-BU, WeaKL-G, and WeaKL-T estimators are selected through hyperparameter tuning. Following the procedure detailed in Appendix~\ref{sec:tuning}, the dataset is divided into three subsets: training, validation, and test. The training set comprises the first $60\%$ of the data, the validation set the next $20\%$, and the test set the last $20\%$. 
The optimal matrix, $\Lambda_{\mathrm{opt}}$, is chosen from a set of candidates by identifying the estimator trained on the training set that achieves the lowest MSE on the validation set. The model is then retrained using both the training and validation sets with $\Lambda = \Lambda_{\mathrm{opt}}$, and its performance is evaluated on the test set. Given that $d_1 = 415 \times 24 = 19,920$, WeaKL involves matrices of size $d_1^2 \simeq 4\times 10^8$, requiring several gigabytes of RAM. Consequently, the grid search process is computationally expensive. For instance, in this experiment, the grid search over $1024$ hyperparameter sets for WeaKL-T takes approximately $45$ minutes.