
\section{Introduction}

\paragraph{Time series forecasting.} Time series data are used extensively in many contemporary applications, such as forecasting supply and demand, pricing, macroeconomic indicators, weather, air quality, traffic, migration, and epidemic trends %\citep{lim2021time,petropoulos2022forecasting}.
\citep{petropoulos2022forecasting}. 
However, regardless of the application domain, forecasting time series presents unique challenges due to inherent data characteristics such as observation correlations, non-stationarity, irregular sampling intervals, and missing values. These challenges limit the availability of relevant data and make it difficult for complex black-box or overparameterized learning architectures to perform effectively, even with rich historical data %\citep{zeng2023transformers, amara-ouali2024forecasting, campagne2024leveraging, Tayal2024}.
\citep{lim2021time}. 

\paragraph{Constraints in time series.} In this context, many modern frameworks incorporate physical constraints to improve the performance and interpretability of forecasting models. The strongest form of such constraints are typically derived from fundamental physical properties of the time series data and are represented by systems of differential equations. For example, weather forecasting often relies on solutions to the Navier-Stokes equations \citep[][]{schultz2021can}.
In addition to defining physical relationships, differential constraints can also serve as regularization mechanisms. For example, spatiotemporal regression on graphs can involve penalizing the spatial Laplacian of the regression function to enforce smoothness across spatial dimensions \citep[][]{jin2024spatio}.

However, time series rarely satisfy strict differential constraints, often adhering instead to more relaxed forms of constraints \citep[][]{coletta2023on}.
Perhaps the most successful example of such weak constraints are the generalized additive models \citep[GAMs,][]{hastie1986generalized}, which have been applied to time series forecasting in epidemiology \citep{wood2017generalized}, earth sciences \citep{augusting2009modeling}, and energy forecasting \citep{fasiolo2021fast}. 
GAMs model the target time series (or some parameters of its distribution) as a sum of nonlinear effects of the features, thereby constraining the shape of the regression function.
Another example of weak constraint appears in the context of spatiotemporal time series with hierarchical forecasting. Here, the goal is to combine regional forecasts into a global forecast by enforcing that the global forecast must be equal to the sum of the regional forecasts \citep{Wickramasuriya2019optimal}.
Although this may seem like a simple constraint, hierarchical forecasting is challenging because of a trade-off: using more granular regional data increases the available information, but also introduces more noise as compared to the aggregated total. Another common and powerful constraint in time series forecasting arises when combining multiple forecasts \citep{gaillard2014second}. 
This is done by creating a final forecast by weighting each of the initial forecasts, with the constraint that the sum of the weights must equal one.

\paragraph{PIML and time series.} Although  weak constraints have been studied individually and applied to real-world data, a unified and efficient approach is still lacking.
It is important here to mention physics-informed machine learning (PIML), which offers a promising way to integrate constraints into machine learning models. 
Based on the foundational work of \citet{raissi2019PINN}, PIML exploits the idea that constraints can be applied with neural networks and optimized by backpropagation, leading to the development of physics-informed neural networks (PINNs). 
PINNs have been successfully used to predict time series governed by partial differential equations (PDEs) in areas such as weather modeling \citep{kashinath2021physics}, and stiff chemical reactions \citep{ji2021stiff}. 
Weak constraints on the shape of the regression function have also been modeled with PINNs \citep[][]{daw2022lake}. 
However, PINNs often suffer from optimization instabilities and overfitting  \citep{doumeche2023convergence}.  
As a result, alternative methods have been developed for certain differential constraints that offer improved optimization properties over PINNs. For example, data assimilation techniques in weather forecasting have been shown to be consistent with the Navier-Stokes equations \citep{nickl2024on}. 
Moreover, \citet{doumeche2024physicsinformed} showed that forecasting with linear differential constraints can be formulated as a kernel method, yielding closed-form solutions to compute the exact empirical risk minimum. An additional advantage of this kernel modeling is that the learning algorithm can be executed on GPUs, leading to significant speedups compared to the gradient-descent-based optimization of PINNs \citep{doum√®che2024physicsinformedkernellearning}.

\paragraph{Contributions.}
In this paper, we present a principled approach to effectively integrate constraints into time series forecasting. Each constrained problem is reformulated as the minimization of an empirical risk consisting of two key components: a data-driven term and a regularization term that enforces the smoothness of the function and the desired physical constraints.
For nonlinear regression tasks, we rely on a Fourier expansion.
Our framework allows for efficient computation of the exact minimizer of the empirical risk, which is easily optimized on GPUs for scalability and performance.

In Section~\ref{sec:weak}, we introduce a unified mathematical framework that connects empirical risks constrained by various forms of physical information. Notably, we highlight the importance of distinguishing between two categories of constraints: shape constraints, which limit the set of admissible functions, and learning constraints, which introduce an initial bias during parameter optimization. In Section~\ref{sec:shape}, we explore shape constraints and illustrate their relevance using the example of electricity demand forecasting.
In Section~\ref{sec:weight}, we define learning constraints and show how they can be applied to tourism forecasting.
This common modeling framework for shape and learning constraints allows for efficient integration of multiple constraints, as illustrated by the WeaKL-T in Section~\ref{sec:weight}, which combines hierarchical forecasting with additive models and transfer learning. 
Each empirical risk can then be minimized on a GPU using linear algebra, ensuring scalability and computational efficiency. 
This direct computation guarantees that the proposed estimator exactly minimizes the empirical risk, preventing convergence to potential local minima---a common limitation of modern iterative and gradient descent methods used in PINNs.
Our method achieves significant performance improvements over state-of-the-art approaches. 
\if\jasa0
{
The code for the numerical experiments and implementation is publicly available at \url{https://github.com/NathanDoumeche/WeaKL}.
}\fi






\section{Incorporating constraints in time series forecasting}
\label{sec:weak}
Throughout the paper, we assume that $n$ observations $(X_{t_1}, Y_{t_1}), \ldots, (X_{t_n}, Y_{t_n})$ are drawn on $\mathbb{R}^{d_1} \times \mathbb{R}^{d_2}$. 
The indices $t_1, \ldots, t_n \in T$ correspond to the times at which an unknown stochastic process $(X,Y):=(X_t, Y_t)_{t \in T}$ is sampled.
Note that, all along the paper, the time steps need not be regularly sampled on the index set $T \subseteq \mathbb R$. 
We focus on supervised learning tasks that aim to estimate an unknown function $f^\star : \mathbb{R}^{d_1} \to \mathbb{R}^{d_2}$, under the assumption that $Y_t = f^\star(X_t) + \varepsilon_t$, where $\varepsilon$ is a random noise term. Without loss of generality, upon rescaling, we assume that $X_t:= (X_{1,t}, \hdots, X_{d_1,t}) \in [-\pi, \pi]^{d_1}$ and $-\pi \leq t_1 \leq  \cdots \leq  t_{n+1}\leq \pi$. The goal is to construct an estimator $\hat{f}$ for $f^\star$. 

A simple example to to keep in mind is when $Y$ is a stationary, regularly sampled time series with $t_j = j/n$, and the lagged value $X_j = Y_{t_{j-1}}$ serves as the only feature. In this specific case, where $d_1 = d_2$, the model simplifies to
$Y_t = f^\star(Y_{t-1/n})+\varepsilon_t$. Thus, the regression setting reduces to an autoregressive model. Of course, we will consider more complex models that go beyond this simple case.



\paragraph{Model parameterization.} We consider parameterized models of the form 
\begin{equation}
    f_{\theta}(X_t) = (f^1_{\theta}(X_t), \hdots, f^{d_2}_{\theta}(X_t)) =  (\langle \phi_1(X_t), \theta_1\rangle, \hdots, \langle \phi_{d_2}(X_t), \theta_{d_2}\rangle),
    \label{eq:model_def}
\end{equation} 
where each component  $f^\ell_\theta(X_t)$ is computed as the inner product of a feature map $\phi_\ell(X_t) \in \mathbb{C}^{D_\ell}$, with $D_\ell \in \mathbb N^\star$, and a vector $\theta_\ell \in \mathbb{C}^{D_\ell}$. 
%(with the possible extension $\theta_j \in \mathbb{C}^{D_j}$ if $\phi_j$ is complex-valued). 
The parameter vector $\theta \in \mathbb C^{D_1 + \cdots + D_{d_2}}$ of the model is defined as the concatenation of $\theta_1$, $\dots$, $\theta_{d_2}$. 
Note that $f_\theta$ is uniquely determined by $\theta$ and the maps~$\phi_\ell$.
To simplify the notation, we write $\dim(\theta) = D_1 + \cdots + D_{d_2}$. 

Our goal is to learn a parameter $\hat \theta \in \mathbb C^{\dim(\theta)}$ such that $\hat Y_t  = f_{\hat{\theta}}(X_t)$ is an estimator of the target $Y_t$.
Equivalently, $f_{\hat{\theta}}$ is an estimator of the target function $f^\star$. 
To this end, the core principle of our approach is to consider $\hat \theta$ to be a minimizer over $\mathbb C^{\dim(\theta)}$ of an empirical risk of the form
\begin{equation}
    L(\theta) = \frac{1}{n}\sum_{j=1}^n \|\Lambda(f_\theta(X_{t_j})-Y_{t_j})\|_2^2  + \|M\theta\|_2^2,
    \label{eq:risk}
\end{equation}
where $\Lambda$ and $M$ are complex-valued matrices with problem-dependent dimensions, which are not necessarily square. The matrix $M$ encodes a regularization penalty, which may include hyperparameters to be tuned through validation, as we will see in several examples.

\paragraph{Explicit formula for the empirical risk minimizer: WeaKL.}The following proposition shows how to compute the exact minimizer of \eqref{eq:risk}. 
(Throughout the document, $\ast$ denotes the conjugate transpose operation.)
\begin{proposition}[Empirical risk minimizer.] 
\label{prop:emp_risk_min}
Suppose both $M$ and $\Lambda$ are injective.
Then, there is a unique minimizer to \eqref{eq:risk}, which takes the form
\begin{equation}
    \hat \theta = \Big( \Big( \sum_{j=1}^n \mathbb \Phi_{t_j}^\ast \Lambda^\ast \Lambda\mathbb \Phi_{t_j}\Big) + n M^\ast M\Big)^{-1} \sum_{j=1}^n \mathbb \Phi_{t_j}^\ast \Lambda^\ast \Lambda Y_{t_j},
    \label{eq:weakl}
\end{equation}
where $\mathbb \Phi_t$ is the $d_2\times \dim(\theta)$ block-wise diagonal feature matrix at time $t$, defined by
\begin{equation}
\mathbb \Phi_t = \begin{pmatrix}
    \phi_1(X_{t})^\ast & 0& 0 \\
    0 & \ddots & 0 \\
    0 & 0 & \phi_{d_2}(X_{t})^\ast
\end{pmatrix}
\label{eq:feature_matrix}.
\end{equation}
\end{proposition}
This result, proven in Appendix~\ref{proof:kernel}, generalizes well-known results on kernel ridge regression \citep[see, e.g.,][Equation 10.17]{mehri2012foundations}. 
In the rest of the paper, we refer to the estimator $\hat \theta$ as the weak kernel learner (WeaKL). The strength of WeaKL lies in its exact computation via~\eqref{eq:weakl}. Unlike current implementations of GAMs and PINNs, WeaKL is free from optimization errors. Furthermore, since WeaKL relies solely on linear algebra, it can take advantage of GPU programming to accelerate the learning process. 
This efficiency enables effective hyperparameter optimization, as demonstrated in Section~\ref{sec:energy_crisis} through applications to electricity demand forecasting.

\paragraph{Algorithmic complexity.} The formula \eqref{eq:weakl} used in this article to minimize the empirical risk \eqref{eq:risk} can be implemented with a  complexity of $ O(\dim(\theta)^3 +  \dim(\theta)^2 n)$. 
Note that the dimensions $d_1$ and $d_2$ of the problem only impact the complexity of WeaKL through $\dim(\theta) = D_1 + \cdots + D_{d_2}$. 
By construction, $\dim(\theta) \geq d_2$, but the influence of $d_1$ is more subtle and depends on the chosen dimension $D_\ell$ of the maps $\phi_j: [-\pi, \pi]^{d_1}\to \mathbb{C}^{D_j}$. 
In particular, if all the maps have the same dimension, i.e., $D_\ell = D$, then $\dim(\theta) = Dd_2$.

Notably, this implementation runs in less than ten seconds on a standard GPU (e.g., an NVIDIA $L4$ with $24$ GB of RAM) when $\dim(\theta) \leq 10^3$ and $n \leq 10^5$. 
We believe that this framework is particularly well suited for time series, where data sampling is often costly, thus limiting both $n$ and $d_2$. Moreover, in many cases, the distribution of the target time series changes significantly over time, making only the most recent observations relevant for forecasting. This further limits the size of $n$. For example, in the Monash time series forecasting archive \citep{Godahewa2021Monash}, $19$ out of $30$ time series have $d_2 \leq 10^3$ and $n \leq 10^5$. 
However, there are relevant time series where either the dimension $d_2$ or the number of data points $n$ is large. 
In such cases, finding an exact minimizer of the empirical risk \eqref{eq:risk} becomes very computationally expensive. 
Efficient techniques have been developed to approximate the minimizer of \eqref{eq:risk} in these regimes \citep[see, e.g.,][]{meanti2020kernel}, but a detailed discussion of these methods is beyond the scope of this paper.

\paragraph{Some important examples.}
Let us illustrate the mechanism with two fundamental examples. Of course, the case where $\phi_\ell(x) = x$ and where $\Lambda$ and $M$ are identity matrices corresponds to the well-known ridge linear regression. 
On the other hand, a powerful example of a nonparametric regression map is the Fourier map, defined as $\phi_\ell(x) = (\exp(i \langle x, k \rangle / 2))_{\|k\|_\infty \leq m}^\top = (\exp(i \langle x, k \rangle / 2))_{-m\leq k_1, \hdots, k_{d_1} \leq m}^\top$, where the Fourier frequencies are truncated at $m \geq 0$. 
This map leverages the expressiveness of the Fourier basis to capture complex patterns in the data. Thus, for the $\ell$-th component of $f_{\theta}$, we consider the Fourier decomposition
\[
f^\ell_{ \theta}(x) =  \sum_{\|k\|_\infty \leq m}  \theta_{\ell,k} \exp(-i \langle x, k\rangle/2),
\]
which can approximate any function in $L^2([-\pi, \pi]^{d_1}, \mathbb{R})$ as $m \to \infty$. In this example, we have $\theta_{\ell}=(\theta_{\ell,k})_{\|k\|_\infty \leq m}^\top \in \mathbb C^{(2m+1)^d}$. 
Next, for $s \in \mathbb N^\star$, 
let $M$ be the $(2m+1)^{d_1}\times (2m+1)^{d_1}$ positive diagonal matrix such that
\[
\|M \theta_\ell\|_2^2  = \lambda \sum_{\|k\|_{\infty} \leq m} \theta_{\ell,k}^2 (1+\|k\|_2^{2s}),
\]
where $\lambda > 0$ is an hyperparameter.
Then, $\|M \theta_\ell\|_2$
is a Sobolev norm on the derivatives up to order $s$ of $f_{\theta_\ell}$.
When $\lambda = 1$, we will denote this norm by $\|f_{\theta}^\ell\|_{H^s}$. 
This approach regularizes the smoothness of $f_{\hat{\theta}}^{\ell}$, encouraging the recovery of smooth solutions. 
Moreover, choosing $\Lambda$ as the identity matrix and $\lambda = n^{-2s/(2s+d_1)}$ achieves the Sobolev minimax rate $\mathbb E(\|f_{\hat \theta}^\ell(X) -Y_\ell\|_2^2) = O(n^{-2s/(2s+d_1)})$ \citep{blanchard2020kernel}. 
This result justifies why the Fourier decomposition serves as an effective nonparametric mapping. 

These fundamental examples illustrate the richness of the approach, making it possible to incorporate constraints into models of chosen complexity, from very light models like linear regression, up to nonparametric models such as Fourier maps. 


\paragraph{Classification of the constraints.} In order to clarify our discussion as much as possible, we find it helpful, after a thorough analysis of the existing literature, to consider two families of constraints. This distinction arises from the need to address two fundamentally different aspects of the forecasting problem.
\begin{enumerate}
\item {\bf Shape constraints}, described in Section~\ref{sec:shape}, include additive models, online adaption after a break, and forecast combinations (detailed in Appendix~\ref{sec:combination}). In these models, prior information is incorporated by selecting custom maps $\phi_\ell$. The set of admissible models  $f_\theta$ is thus restricted by shaping the structure of the function space through this choice of maps. Here, the matrix $M$ serves only as a regularization term, while $\Lambda$ is the identity matrix.


\item {\bf Learning constraints}, described in Section~\ref{sec:weight}, include transfer learning, hierarchical forecasting, and differential constraints (detailed in Appendix~\ref{sec:diff}). In these models, prior information or constraints are incorporated through the matrices $M$ and $\Lambda$. The goal is to increase the efficiency of parameter learning by introducing additional regularization.
\end{enumerate}
It is worth noting, however, that certain specific shape constraints cannot be penalized by a kernel norm, such as those in isotonic regression. In the conclusion, we discuss possible extensions to account for such constraints.

\section{Shape constraints}
\label{sec:shape}
\subsection{Mathematical formulation}
In this section, we introduce relevant feature maps $\phi$ that incorporate prior knowledge about the shape of the function  $f^\star:[-\pi,\pi]^{d_1}\to \mathbb{C}^{d_2}$. To simplify the notation, we focus on the one-dimensional case where $d_2 = 1$ and $\Lambda = 1$. 
This simplification comes without loss of generality, since the feature maps developed in this section can be applied directly to \eqref{eq:model_def}.

As a result, the model reduces to $f_{\theta}(X_t) = \langle \phi_1(X_t), \theta_1 \rangle$, and \eqref{eq:weakl} simplifies to
\begin{equation}
    \hat \theta = ( \mathbb \Phi^\ast \mathbb \Phi + n M^\ast M)^{-1}  \mathbb \Phi^\ast \mathbb Y,
    \label{eq:weakl2}
\end{equation}
where $\mathbb Y = (Y_{t_1}, \hdots, Y_{t_n})^\top \in \mathbb R^n$ and the $n\times \dim(\theta)$ matrix $\mathbb \Phi$ takes the form 
\[ \mathbb \Phi = (\phi_1(X_{t_1})\mid \cdots \mid \phi_1(X_{t_n}))^\ast.
\]
Note that $\mathbb \Phi$ is the classical feature matrix, and that it is related to the matrix $\mathbb \Phi_t$ of \eqref{eq:feature_matrix} by $\mathbb \Phi^\ast \mathbb \Phi = \sum_{j=1}^n\mathbb \Phi_{t_j}^\ast \mathbb \Phi_{t_j} = \sum_{j=1}^n \phi_1(X_{t_j}) \phi_1(X_{t_j})^\ast$.

\paragraph{Additive model: Additive WeaKL.} The additive model constraint assumes that $f^\star(x_1, \hdots, x_{d_1}) = \sum_{\ell=1}^{d_1} g_\ell^\star(x_\ell)$, where $g_\ell^\star: \mathbb{R} \to \mathbb{R}$ are univariate functions. This constraint is widely used in data science, both in classical statistical models \citep{hastie1986generalized} and in modern neural network architectures \citep{agarwal2021neural}. Indeed, additive models are interpretable because the effect of each feature $x_\ell$ is captured by its corresponding function $g_\ell^\star$. In addition, univariate effects are easier to estimate than multivariate effects \citep{Ravikumar2009sparse}. These properties allow the development of efficient variable selection methods \citep[see, for example,][]{marra2011practical}, similar to those used in linear regression.

In our framework, the additivity constraint directly translates into the model as
\[
f_{\theta}(X_t) =  \langle \phi_{1}(X_{t}), \theta_{1}\rangle = \langle \phi_{1,1}(X_{1,t}), \theta_{1,1}\rangle + \cdots + \langle \phi_{1,d_1}(X_{d_1,t}), \theta_{1,d_1}\rangle,
\]
where $\phi_1$ is the concatenation of the maps $\phi_{1,\ell}$, and $\theta_1$ is the concatenation of the vectors  $\theta_{1,\ell}$. 
Note that the maps $\phi_{1,\ell}$ and the vectors $\theta_{1, \ell}$ can be multidimensional, depending on the model.
In this formulation, the effect of each feature is modeled by the function $g_\ell(x_\ell) = \langle \phi_{1,\ell}(x_\ell), \theta_{1,\ell}\rangle$, which can be either linear or nonlinear in $x_\ell$.
The empirical risk then takes the form
\begin{equation}
    L(\theta) = \frac{1}{n} \sum_{j=1}^n |f_\theta(X_{t_j}) - Y_{t_j}|^2 + \sum_{\ell=1}^{d_1}\lambda_\ell\|M_\ell\theta_{1,\ell}\|_2^2, \label{eq:weaklGAM}
\end{equation}
where $\lambda_\ell >0$ are hyperparameters and $M_\ell$ are regularization matrices.
There are three types of effects that can be taken into account:
\begin{itemize}
    \item[$(i)$] A linear effect is obtained by setting $\phi_{1,\ell}(x_\ell) = x_\ell \in \mathbb R$. 
    To regularize the parameter $\theta_{1, \ell}$, we set $M_\ell = 1$. This corresponds to a ridge penalty.
    \item[$(ii)$] A nonlinear effect can be modeled using the Fourier map $\phi_{1,\ell}(x_\ell) = (\exp(i  k x_\ell  / 2))_{-m\leq k \leq m}^\top$. 
    To regularize the parameter $\theta_{1, \ell}$, we set $M_\ell$ to be the $(2m+1)\times (2m+1)$ diagonal matrix defined by $M_\ell =\mathrm{Diag}((\sqrt{1+k^{2s}})_{-m\leq k\leq m})$, penalizing the Sobolev norm. 
    A common choice for the smoothing parameter $s$, as used in GAMs, is $s = 2$ \citep[see, e.g.,][]{wood2017generalizedbook}.
    \item[$(iii)$] If $x_\ell$ is a categorical feature, i.e., $x_\ell$ takes values in a finite set $E$, we can define a bijection $\psi: E \to \{1, \hdots, |E|\}$. The effect of $x_\ell$ can then be modeled as $g_\ell(x_\ell) = \langle \phi_{1,\ell}(x_\ell), \theta_1 \rangle$, where $\phi_\ell = \phi \circ \psi$ and $\phi$ is the Fourier map with $m = \lfloor |E|/2 \rfloor$. To regularize the parameter $\theta_{1, \ell}$, we set $M_\ell$ as the identity matrix, which corresponds to applying a ridge penalty.
\end{itemize}
Overall, similar to GAMs, WeaKL can be optimized to fit additive models with both linear and nonlinear effects. The parameter $\hat \theta$ of the WeaKL can then be computed using \eqref{eq:weakl2}
with 
\[M = \begin{pmatrix}
        \sqrt{\lambda_1} M_1& 0  & 0\\
        0 & \ddots&  0\\
        0 & 0& \sqrt{\lambda_{d_1}} M_{d_1}
    \end{pmatrix}.\]
To stress that this WeaKL results from the enforcement of additive constraints, we call it the \textit{additive WeaKL}.
Note that, contrary to GAMs where identifiability issues must be addressed \citep{wood2017generalizedbook}, WeaKL does not require further regularization, since $\hat \theta$ is the unique minimizer of the empirical risk~$L$. 
Note that the hyperparameters $\lambda_\ell$, along with the number $m$ of Fourier modes and the choice of feature maps  $\phi_\ell$, can be determined by model selection, as described in Appendix~\ref{sec:tuning}.

\paragraph{Online adaption after a break: Online WeaKL.}
For many time series, the dependence of $Y$ on $X$ can vary over time. For example, the behavior of $Y$ may change rapidly following extreme events, resulting in structural breaks. A notable example is the shift in electricity demand during the COVID-19 lockdowns, as illustrated in use case $1$. To provide a clear mathematical framework, we assume that the distribution of $(X, Y)$ follows an additive model that evolves smoothly over time. Formally, considering $(t, X_t)$ as a feature vector, we assume that
\begin{equation}
    f^\star(t, x_1, \hdots, x_{d_1}) = h_0^\star(t)+ \sum_{\ell=1}^{d_1} (1+ h_\ell^\star(t))  g_\ell^\star(x_\ell),
    \label{eq:model}
\end{equation}
where $g_\ell^\star$ and $h_\ell^\star$ are univariate functions. This model forms the core of the Kalman-Viking algorithm \citep{vilmarest2024viking}, which has demonstrated state-of-the-art performance in forecasting electricity demand and renewable energy production \citep{obst2021adaptive, vilmarest2022state, Vilamarest2024adaptive}. 

We assume that we have at hand estimators $\hat g_\ell$ of $g_\ell^\star$ that we want to update over time. For example, these estimators can be obtained by fitting an additive WeaKL model, initially assuming $h_\ell^\star = 0$. The functions $h_\ell^\star$ are then estimated by minimizing the empirical risk
\begin{equation}
    L(\theta) = \frac{1}{n}\sum_{j=1}^n \Big|h_{\theta_0}(t_j) + \sum_{\ell=1}^{d_1} (1+h_{\theta_\ell}(t_j)) \hat g_\ell(X_{\ell,t_j})-Y_{t_j}\Big|^2 + \sum_{0\leq \ell \leq d_1} \lambda_\ell\|h_{\theta_\ell}\|_{H^s}^2,
    \label{eq:risk_online}
\end{equation}
where $\lambda_\ell > 0$ are hyperparameters regularizing the smoothness of the functions $h_{\theta_\ell}$. Here, $h_{\theta}(t) = \langle \phi(t), \theta\rangle$, and $\phi$ is the Fourier map $\phi(t) =(\exp(i k t/2))_{-m\leq k \leq m}^\top$. The prior $h_{\theta_\ell} \simeq 0$ reflects the idea that the best a priori estimate of $Y$'s behavior follows the stable additive model. Defining $W_t = Y_t - \sum_{\ell=1}^{d_1}\hat g_\ell(X_{\ell,t})$, the empirical risk can be reformulated as
\begin{equation*}
    L(\theta) = \frac{1}{n}\sum_{j=1}^n |\langle \phi_1(t_j, X_{t_j}), \theta\rangle - W_{t_j}|^2 + \|M \theta\|_2^2,
\end{equation*}
where
$\phi_1(t, X_t) = 
    ((\exp(ik t/2))_{- m\leq k \leq  m},
    (\hat g_\ell(X_{\ell,t})\exp(ik t/2))_{- m\leq k \leq  m})_{\ell=1}^{d_1})^\top \in \mathbb C^{(2m+1)(d_1+1)}$,
\[M = \begin{pmatrix}
        \sqrt{\lambda_0} D& 0  & 0\\
        0 & \ddots&  0\\
        0 & 0& \sqrt{\lambda_{d_1}} D
    \end{pmatrix},\]
and $D$ is the $(2m+1)\times (2m+1)$ diagonal matrix
$D =\mathrm{Diag}((\sqrt{1+k^{2s}})_{-m\leq k\leq m})$.
From \eqref{eq:weakl2}, we deduce that the unique minimizer of the empirical loss $L$ is
\begin{equation}
    \hat \theta  = ({\mathbb{\Phi}} ^\ast {\mathbb{\Phi}} + n  M^\ast M)^{-1}{\mathbb \Phi}^\ast  \mathbb W,
    \label{eq:online}
\end{equation}
where  $\mathbb W = (W_{t_1}, \hdots, W_{t_n})^\top \in \mathbb R^n$. 

This formulation allows to forecast the time series $Y$ at the next time step, $t_{n+1}$, using
\begin{align*}
\hat Y_{t_{n+1}} &= f_{\hat \theta}(t_{n+1}, X_{t_{n+1}}) = \langle \phi_1(t_{n+1}, X_{t_{n+1}}), \hat \theta\rangle \\
&=   h_{\hat \theta_0}(t_{n+1}) + \sum_{\ell=1}^{d_1} (1+h_{\hat \theta_\ell}(t_{n+1})) \hat g_\ell(X_{\ell,t_{n+1}}).
\end{align*}
Since the model is continuously updated over time, this corresponds to an online learning setting.
To emphasize that Equation~\eqref{eq:online} arises from an online adaptation process, we refer to this model as the \textit{online WeaKL}.
Unlike the Viking algorithm of \citet{vilmarest2024viking}, which approximates the minimizer of the empirical risk through an iterative process, online WeaKL offers a closed-form solution and exploits GPU parallelization for significant speedups.
As shown in Section~\ref{sec:energy_crisis}, our approach leads to improved performance in electricity demand forecasting. 



\subsection{Application to electricity load forecasting}
\label{sec:energy_crisis}
In this subsection, we apply shape constraints to two use cases in electricity demand forecasting and demonstrate the effectiveness of our approach.
In these electricity demand forecasting problems, the focus is on short-term forecasting, with particular emphasis on the recent non-stationarities caused by the COVID-19 lockdowns and by the energy crisis.

\paragraph{Electricity load forecasting and non-stationarity.} Accurate demand forecasting is critical due to the costly nature of electricity storage, coupled with the need for supply to continuously match demand.  
Short-term load forecasting, especially for 24-hour horizons, is particularly valuable for making operational decisions in both the power industry and electricity markets.
Although the cost of forecasting errors is difficult to quantify, a $1\%$ reduction in error is estimated to save utilities several hundred thousand USD per gigawatt of peak demand \citep{hong2016probabilistic}. 
Recent events such as the COVID-19 shutdown have significantly affected electricity demand, highlighting the need for updated forecasting models  \citep{zarbakhsh2022human}.

\paragraph{Use case 1: Load forecasting during COVID.} In this first use case, we test the performance of our WeaKL on the IEEE DataPort Competition on Day-Ahead Electricity
Load Forecasting \citep{Farrokhabadi2022day}.
Here, the goal is to forecast the electricity demand of an unknown country during the period following the Covid-19 lockdown.
The winning model of this competition was the Viking model of Team~4 \citep{vilmarest2022state}, with a mean absolute error (MAE) of $10.9$ gigawatts (GW). For comparison, a direct translation of their model into the online WeaKL framework---using the same features and maintaining the same additive effects---results in an MAE of $10.5$ GW. In parallel, we also apply the online WeaKL methodology without relying on the variables selected by \citet{vilmarest2022state}. Instead, we determine the optimal hyperparameters $\lambda_\ell$ and select the feature maps $\phi_\ell$ through a hyperparameter tuning process (see Appendix~\ref{sec:tuning}). This leads to a different selected model with a MAE of $9.9$ GW (see Appendix~\ref{sec:case_study1} for a complete description of the models). 
Thus, the online WeaKL given by \eqref{eq:online} outperforms the state-of-the-art by $9\%$. 
As done in the IEEE competition \citep{Farrokhabadi2022day}, we assess the significance of this result by evaluating the MAE skill score using a block bootstrap approach (see Appendix~\ref{sec:case_study1}). 
It shows that the online WeaKL outperforms the winning model proposed by \citet{vilmarest2022state} with a probability above $90\%$.
The updated results of the competition are presented in Table~\ref{tab:ieee}. 
Note that a great variety of models were benchmarked in this competition, like Kalman filters (Team~4), autoregressive models (Teams~4 and 7), random forests (Teams~4 and 6), gradient boosting (Teams~6 and 36),  deep residual networks (Team~19), and averaging (Team~13).

\begin{table}[h]
\centering
\caption{Performance of the online WeaKL and of the top $10$ participants of the IEEE competiton. A specific bootstrap test shows that the WeaKL significantly outperform the winning team.}
\begin{tabular}{lccccccccccc}
\toprule
Team & WeaKL &  4 &   14 &   7 &   36 &   19 &   23 &   9 &   25 &   13 &   26 \\
\midrule
MAE (GW)  & \textbf{9.9} & 10.9 & 11.8 & 11.9 & 12.3 & 12.3 & 13.9 & 14.2 & 14.3 & 14.6 & 15.4\\
\bottomrule
\end{tabular}

\label{tab:ieee}
\end{table}

\paragraph{Use case 2: Load forecasting during the energy crisis.}
In this second use case, we evaluate the performance of our WeaKL within the open source benchmark framework proposed by \citet{doumeche2023human}. This benchmark provides a comprehensive evaluation of electricity demand forecasting models, incorporating the GAM boosting model of \cite{bentaieb2014a}, the GAM of \cite{obst2021adaptive}, the Kalman models of \cite{vilmarest2022state}, the time series random forests of \cite{gohery2023random}, and the Viking model of \cite{Vilamarest2024adaptive}. 
The goal here is to forecast the French electricity demand during the energy crisis in the winter of 2022-2023. Following the war in Ukraine and maintenance problems at nuclear power plants, electricity prices reached an all-time high at the end of the summer of 2022. In this context, French electricity demand decreased by $10\%$ compared to its historical trends \citep{doumeche2023human}. 
This significant shift in electricity demand can be interpreted as a structural break, which justifies the application of the online WeaKL given by \eqref{eq:online}.

In this benchmark, the models are trained from 8 January 2013 to 1 September 2022, and then evaluated from 1 September 2022 to 28 February 2023.
The dataset consists of temperature data from the French meteorological administration \citet{meteoFrance}, and electricity demand data from the French  transmission system operator \citet{rteData}, sampled with a half-hour resolution.  
This translates into the feature variable 
\[X =(\mathrm{Load}_1, \mathrm{Load}_7, \mathrm{Temp}, \mathrm{Temp}_{950},  \mathrm{Temp}_{\mathrm{max 950}}, \mathrm{Temp}_{\mathrm{min 950}}, \mathrm{ToY},  \mathrm{DoW}, \mathrm{Holiday},t),
\]
where $\mathrm{Load}_1$ and $\mathrm{Load}_7$ are the electricity demand lagged by one day and seven days, $\mathrm{Temp}$ is the temperature, and $\mathrm{Temp}_{950}$,  $\mathrm{Temp}_{\mathrm{max 950}}$, and $\mathrm{Temp}_{\mathrm{min 950}}$ are smoothed versions of $\mathrm{Temp}$. The time of year $\mathrm{ToY} \in \{1, \hdots, 365\}$ encodes the position within the year. 
The day of the week $\mathrm{DoW} \in \{1, \hdots, 7\}$ encodes the position within the week. 
In addition, $\mathrm{Holiday}$ is a boolean variable set to one during holidays, and $t$ is the timestamp. 
Here, the target $Y = \mathrm{Load}$ is the electricity demand, so $d_1 = 10$ and $d_2 = 1$.


We compare the performance of two of our WeaKLs against this benchmark.
First, our additive WeaKL is a direct translation of the GAM formula proposed by  \cite{obst2021adaptive} into the additive WeaKL framework given by \eqref{eq:weaklGAM}. Thus, $f_\theta(x) = \sum_{\ell=1}^{10} g_\ell(x_\ell)$, where:
\begin{itemize}
    \item the effects $g_1$, $g_2$, and $g_{10}$ of $\mathrm{Load}_1$, $\mathrm{Load}_7$, and $t$ are linear,
    \item the effects $g_3,\dots, g_7$ of $\mathrm{Temp}$, $\mathrm{Temp}_{950}$,  $\mathrm{Temp}_{\mathrm{max 950}}$, $ \mathrm{Temp}_{\mathrm{min 950}}$, and $\mathrm{ToY}$ are nonlinear with $m=10$,
    \item the effects $g_8$ and $g_9$ of   $\mathrm{DoW}$ and $\mathrm{Holiday}$ are categorical with $|E| = 7$ and $|E| = 2$.
\end{itemize}


\begin{wrapfigure}[\lenghtfig]{r}{0.4\textwidth}
    \centering 
    \vspace{-1em}
    \includegraphics[width=\linewidth, trim={0.4cm 0.3cm 0.2cm 0.9cm},clip]{temperature_effect.pdf}
    \vspace{-2em}
    \caption{Effect in MW of the temperature in the additive WeaKL.}
    \label{fig:WeaKL_effect}
 \end{wrapfigure}
\noindent The weights $\theta$ are learned using data from 2013 to 2021, while the optimal hyperparameters $\lambda_1, \dots, \lambda_{10}$ are tuned using a validation set covering the period from 2021 to 2022.
Once the additive WeaKL is learned, it becomes straightforward to interpret the impact of each feature on the model. For example, the effect $\hat g_3: \mathrm{Temp} \mapsto \langle\phi_{1,3}(\mathrm{Temp}), \hat \theta_{1, 3}\rangle $ of the rescaled temperature feature ($\mathrm{Temp} \in [-\pi, \pi]$) is illustrated in Figure~\ref{fig:WeaKL_effect}.


Second, our online WeaKL is the online adaptation of $f_\theta$  in response to a structural break, as described by \eqref{eq:online}.
The hyperparameters $\lambda_0, \dots, \lambda_{10}$ in \eqref{eq:risk_online} are chosen to minimize the error over a validation period from $1$ April $2020$ to $1$ June $2020$, corresponding to the first COVID-19 lockdown. Note that this validation period does not immediately precede the test period, which is uncommon in time series analysis. However, this choice ensures that the validation period contains a structural break, making it as similar as possible to the test period. Next, the functions $h_0, \dots, h_{10}$ in \eqref{eq:model} are trained on a period starting from $1$ July $2020$, and updated online. 

The results are summarized in Table~\ref{table_score_target_agg2}. The errors and their standard deviations are assessed by stationary block bootstrap (see Appendix~\ref{sec:block-bootstrap}). Since holidays are notoriously difficult to predict, performance is evaluated over the entire period (referred to as \textit{Including holidays}), and separately excluding holidays and the days immediately before and after (referred to as \textit{Excluding holidays}). 
Over both test periods, the additive WeaKL  significantly outperforms the GAM, while the online WeaKL outperforms the state-of-the-art by more than $10\%$ across all metrics.


Figure~\ref{fig:err_time_weaKL} shows the errors of the WeaKLs as a function of time during the test period, which includes holidays. 
During the sobriety period, electricity demand decreased, causing the additive WeaKL to overestimate demand, resulting in a negative bias. Interestingly, this bias is effectively corrected by the online WeaKL, which explains its strong performance. This shows that the online update of the effects effectively corrects biases caused by shifts in the data distribution.

Then, we compare the running time of the algorithms. 
Note that, during hyperparameter tuning, the GPU implementation of WeaKL makes it possible to train $1.6\times 10^5$ additive WeaKL over a period of eight years in less than five minutes on a single standard GPU (NVIDIA $L4$). 
As for the online WeaKL, the training is more computationally intensive because the model must be updated in an online fashion.
However, training $9.2 \times 10^3$ online WeaKLs over a period of two years takes less than two minutes.
This approach is faster than the Viking algorithm, which takes over $45$ minutes to evaluate the same number of parameter sets on the same dataset, even when using $10$ CPUs in parallel. A detailed comparison of the running times for all algorithms is provided in Appendix~\ref{sec:sobriety}.
\begin{table}[H]
\centering
\caption{Benchmark for load forecasting during the energy crisis}
\begin{tabular*}{\textwidth}{@{\extracolsep\fill}lcccc}
  \toprule
  & \multicolumn{2}{@{}c@{}}{ Including holidays} & \multicolumn{2}{@{}c@{}}{Excluding holidays} \\\cmidrule{2-3}\cmidrule{4-5}%
 & RMSE (GW)& MAPE (\%) &  RMSE (GW)& MAPE (\%)\\
  \midrule
  \textit{Statistical model} &&&&\\
  Persistence (1 day) & 4.0$\pm$0.2 & 5.5$\pm$0.3 & 4.0$\pm$0.2  & 5.0$\pm$0.3\\
  SARIMA  &  2.4$\pm$0.2   & 3.1$\pm$0.2 & 2.0$\pm$0.2  & 2.6$\pm$0.2\\
  GAM & 2.3$\pm$0.1 & 3.5$\pm$0.2   & 1.70$\pm$0.06 & 2.6$\pm$0.1 \\
  \midrule
    \textit{Data assimilation }\\
  Static Kalman & 2.1$\pm$0.1 & 3.1$\pm$0.2   &  1.43$\pm$0.05 & 2.20$\pm$0.08 \\
  Dynamic Kalman & 1.4$\pm$0.1 & 1.9$\pm$0.1   & 1.10$\pm$0.04 & 1.58$\pm$0.05  \\
    Viking & 1.5$\pm$0.1 & 1.8$\pm$0.1 &  0.98$\pm$0.04 & 1.33$\pm$0.04\\
    Aggregation & 1.4$\pm$0.1 & 1.8$\pm$0.1 & 0.96$\pm$0.04 & 1.36$\pm$0.04\\
    \midrule
    \textit{Machine learning}\\
    GAM boosting & 2.6$\pm$0.2 & 3.7$\pm$0.2 & 2.3$\pm$0.1 & 3.3$\pm$0.2 \\
    Random forests &  2.5$\pm   $0.2& 3.5$\pm$0.2& 2.1$\pm$0.1 & 3.0$\pm$0.1\\
    Random forests + bootstrap & 2.2$\pm$0.2 & 3.0$\pm$0.2 & 1.9$\pm$0.1 & 2.6$\pm$0.1\\
    \midrule
    \textit{WeaKLs}\\
    Additive WeaKL & 1.95$\pm$0.08 & 3.0 $\pm$0.1& 1.55$\pm$0.06 & 2.32$\pm$0.09  \\
    Online WeaKL &  \textbf{1.14$\pm$0.09}& \textbf{1.5$\pm$0.1}&  \textbf{0.87$\pm$0.04 }& \textbf{1.17$\pm$0.05} \\
   \bottomrule
\end{tabular*}
\label{table_score_target_agg2}
\end{table}
Both use cases demonstrate that WeaKL models are very powerful. Not only are they highly interpretable---thanks to their ability to fit into a common framework and produce simple formulas---but they are also competitive with state-of-the-art techniques in terms of both optimization efficiency (they can run on GPUs) and performance (measured by MAPE and RMSE).
\begin{figure}
    \centering
    \includegraphics[width=1\linewidth, trim={2.2cm 1.2cm 3cm 2.1cm},clip]{UseCase2_ForecastError.pdf}
    \caption{Error $Y_t - \hat Y_t$ in MW of the WeaKLs on the test period including holidays. Dots represent individual observations, while the bold curves indicate the one-week moving averages.}
    \label{fig:err_time_weaKL}
\end{figure}
\section{Learning constraints}
\label{sec:weight}
\subsection{Mathematical formulation}
Section~\ref{sec:shape} focused on imposing constraints on the shape of the regression function $f^\star$. In contrast, the goal of the present section is to impose constraints on the parameter $\theta$. 
We begin with a ge\-ne\-ral method to enforce linear constraints on $\theta$, and subsequently apply this framework to transfer learning, hierarchical forecasting, and differential constraints.

\paragraph{Linear constraints.}
Here, we assume that $f^\star$ satisfies a linear constraint.
By construction of $f_\theta$ in \eqref{eq:model_def}, such a linear constraint directly translates into a constraint on $\theta$.
For example, the linear constraint $f^{\star\,1}(X_t) = 2f^{\star\,2}(X_t)$ can be implemented by enforcing $\theta_1 = 2\theta_2$.
Thus, in the following, we assume a prior on $\theta$ in the form of a linear constraint. Formally, we want to enforce that $\theta \in \mathcal{S}$, where $\mathcal{S}$ is a known linear subspace of $\mathbb{C}^{\dim(\theta)}$.
Given an injective $\dim(\theta) \times \dim(\mathcal{S})$ matrix $P$ such that $\mathrm{Im}(P) = \mathcal{S}$, then, as shown in Lemma~\ref{lem:ortho}, $\|C\theta\|_2^2$ is the square of the Euclidean distance between $\theta$ and $\mathcal S$, where $C=\mathrm{I}_{\dim(\theta)} - P(P^\ast P)^{-1}P^\ast$.  In particular, $\|C\theta\|_2^2 = 0 $ is equivalent to $\theta \in \mathcal S$, and $\|C\theta\|_2^2 = \|\theta\|_2^2$ if $\theta \in \mathcal S^\perp$. From this observation, there are two ways to enforce $\theta \in \mathcal S$ in the empirical risk \eqref{eq:risk}.

On the one hand, suppose that $f^\star$ exactly satisfies the linear constraint.
This happens in particular when the constraint results from a physical law. 
For example, to build upon the use cases of Section~\ref{sec:energy_crisis}, assume that we want to forecast the electricity load of different regions of France, i.e., the target $Y \in \mathbb R^3$ is such that $Y_1$ is the load of southern France, $Y_2$ is the load of northern France, and $Y_3 = Y_1+Y_2$ is the national load. 
This prototypical example of hierarchical forecasting is presented in Section~\ref{sec:toy-example}, where we show how incorporating even a simple constraint can significantly improve the model's performance. In this example, we know that $f^\star$ satisfies the constraint $f^{\star\,3} = f^{\star\,1} + f^{\star\,2}$.
When dealing with such exact priors, a sound approach is to consider only parameters $\theta$ such that $C\theta = 0$, or equivalently, $\theta = P\theta'$. Letting $\Pi_\ell$ be the $D_\ell\times \dim(\theta)$ projection matrix such that $\theta_\ell = \Pi_\ell \theta$, we have $\langle \phi_\ell (X_t), \theta_\ell\rangle = \langle \phi_\ell (X_t), \Pi_\ell \theta\rangle  = \langle P^\ast \Pi_\ell^\ast \phi_\ell (X_t),  \theta'\rangle$. 
Thus, minimizing the empirical risk \eqref{eq:risk} over $\theta' \in \mathbb C^{\dim(\mathcal S)}$ simply requires changing $\phi_\ell$ to $P^\ast \Pi_\ell^\ast \phi_\ell$, which is equivalent to replacing $\mathbb{\Phi}_t$ with $\mathbb{\Phi}_t P$ in \eqref{eq:weakl}. 

On the other hand, suppose that the linear constraint serves as a good but inexact prior. 
For example, building on the last example, let $X_t$ be the average temperature in France at time $t$. We expect the loads $Y_1$ in southern France and $Y_2$ in northern France to behave similarly. 
In both regions, lower temperatures lead to increased heating usage (and thus higher loads), while higher temperatures result in increased cooling usage (also leading to higher loads). 
Therefore, $f^{\star\,1}$ and $f^{\star\,2}$ share the same shape, resulting in the prior $f^{\star\,1} \simeq f^{\star\,2}$. 
This prototypical example of transfer learning is explored in the following paragraphs. Such inexact constraints can be enforced by adding a penalty $\lambda \|C\theta\|_2^2$ in the empirical risk \eqref{eq:risk}, where $\lambda > 0$ is an hyperparameter. (Equivalently, this only consists in replacing $M$ with $(\sqrt{\lambda} C^\top \mid  M^\top)^\top$ in \eqref{eq:risk}.)
This ensures that $\|C\hat \theta\|_2^2$ is small, while allowing the model to learn functions that do not exactly satisfy the constraint. 

These approaches are statistically sound, since under the assumption that $Y_t = f_{\theta^\star}(X_t)+ \varepsilon_t$, where $\theta^\star \in \mathcal{S}$, both estimators have lower errors compared to unconstrained regression. This is true in the sense that, almost surely,
\[\frac{1}{n}\sum_{j=1}^n\| f_{\theta^\star}(X_{t_j}) - f_{\hat \theta_C}(X_{t_j})\|_2^2 + \|M(\theta^\star- \hat \theta_C)\|_2^2\leq \frac{1}{n}\sum_{j=1}^n\| f_{\theta^\star}(X_{t_j}) - f_{\hat \theta}(X_{t_j})\|_2^2 + \|M(\theta^\star- \hat \theta)\|_2^2,\]
where $\hat \theta$ is the unconstrained WeaKL and $\hat \theta_C$ is a WeaKL integrating the constraint $C\theta^\star \simeq 0$ (see Proposition~\ref{prop:prop_lin} and Remark~\ref{rem:comment_prop_lin}).

\paragraph{Transfer learning.} Transfer learning is a framework designed to exploit similarities between different prediction tasks when $d_2 >1$. The simplest case involves predicting multiple targets $Y_1, \hdots, Y_{d_2}$ with similar features $X_1, \hdots, X_{d_2}$.
For example, suppose we want to forecast the electricity demand of $d_2$ cities. Here, $Y_\ell$ is the electricity demand of the city $\ell$, while $X_\ell$ is the average temperature in city $\ell$.
The general function $f^\star$ estimating $(Y_1, \hdots, Y_{d_2})$ can be expressed as $f^\star(X) = f^\star(X_1, \hdots, X_{d_2}) = (f^{\star\,1}(X_1), \hdots, f^{\star\,d_2}(X_{d_2}))$. The transfer learning assumption is $f^{\star\,1} \simeq \cdots \simeq f^{\star\,d_2}$. 
Equivalently, this corresponds to the linear constraint $\theta \in \mathrm{Im}(P)$, where $P = (\mathrm{I}_{2m+1} \mid \cdots \mid \mathrm{I}_{2m+1})^\top$ is a $(2m+1)d_1\times (2m+1)$ matrix. 
Thus, one can apply the framework of the last paragraph on linear constraints as inexact prior using $P$.


\paragraph{Hierarchical forecasting.} Hierarchical forecasting involves predicting multiple time series that are linked by summation constraints. This approach was introduced by \citet{athanasopoulos2009hierarchical} to forecast Australian domestic tourism. Tourism can be analyzed at various geographic scales. 
For example, at time $t$, one could consider the total number $Y_{A,t}$ of tourists in Australia, and the number $Y_{S_i,t}$ of tourists in each of the seven Australian states $S_1,\hdots, S_7$. By definition, $Y_{A,t}$ is the sum of the $Y_{S_i, t}$, which leads to the exact summation constraint $Y_{A,t} = \sum_{i=1}^7 Y_{S_i, t}$. Furthermore, since each state $S_i$ is composed of $z_i$ zones $Z_{i,1}$, $\dots$, $Z_{i, z_i}$, an additional hierarchical level can be introduced. 
Note that the number of zones depends on the state, for a total of 27 zones.
This results in another set of summation constraints
$Y_{S_i, t} =  Y_{Z_{i,1}, t}+\cdots + Y_{Z_{i,z_i}, t}$. 
\begin{figure}
    \centering
    \includegraphics[width=0.7\linewidth, trim={0 3.5cm 0 0},clip]{Graph.pdf}
    \caption{Graph representing the hierarchy of Australian domestic tourism.}
    \label{fig:DAC}
\end{figure}
Overall, the complete set of summation constraints can be represented by a directed acyclic graph, as shown in Figure~\ref{fig:DAC}. 
Alternatively, these constraints can be expressed by a $35 \times 27$ summation matrix $S$ that connects the bottom-level series $Y_b= ( Y_{Z_{1,1}},\hdots, Y_{Z_{7,z_7}})^\top \in \mathbb R^{27}$ to all hierarchical nodes $Y = (Y_{Z_{1,1}},\dots, Y_{Z_{7,z_7}}, Y_{S_1}, \hdots, Y_{S_7}, Y_A)^\top \in \mathbb R^{35}$ through the relation $Y = S Y_b$.
Thus, by letting $\mathbb 1 = (1, \hdots, 1)^\top \in \mathbb{R}^{27}$, and defining $\mathbb 1^{(j)}\in \mathbb R^{27}$ by $\mathbb 1^{(j)}_i = \left\{\begin{array}{cc}
     1 &   \hbox{ if } \sum_{k=1}^{j-1} z_k \leq i \leq \sum_{k=1}^j z_k\\
     0 &   \hbox{ otherwise}
\end{array}\right.$,  we have that $S = (\mathrm{I}_{27} \mid \mathbb 1^{(1)} \mid \cdots \mid \mathbb 1^{(7)} \mid  \mathbb 1)^\top$. 
The goal of hierarchical forecasting is to take advantage of the summation constraints defined by $S$ to improve the predictions of the vector $Y$ representing all hierarchical nodes.

This context can be easily generalized to many time series forecasting tasks. Spatial summation constraints, which divide a geographic space into different subspaces, have been applied in areas such as electricity demand forecasting \citep{bregere2022online}, electric vehicle charging demand forecasting \citep{amara-ouali2024forecasting}, and tourism forecasting \citep{Wickramasuriya2019optimal}.
Summation constraints also arise in multi-horizon forecasting, where, for example, an annual forecast must equal the sum of the corresponding monthly forecasts \citep{kourentzes2019cross}.
Finally, they also appear when goods are categorized into different groups \citep{pennings2017integrated}.

There are two main approaches to hierarchical forecasting. The first, known as forecast reconciliation, attempts to improve an existing estimator $\hat{Y}$ of the hierarchical nodes $Y$ by multiplying $\hat{Y}$ by a so-called reconciliation matrix $P$, so that the new estimator $P \hat Y$ satisfies the summation constraints. 
Formally, it is required that $\mathrm{Im}(P) \subseteq \mathrm{Im}(S)$, where $S$ is the summation matrix. 
The goal is for $P\hat{Y}$ to have less error than $\hat{Y}$. 
The strengths of this approach are its low computational cost and its ability to seamlessly integrate with pre-existing forecasts. 
Various reconciliation matrices, such as the orthogonal projection $P = S(S^\top S)^{-1}S$ on $\mathrm{Im}(S)$ (see the paragraph above on linear constraints), have been shown to reduce forecasting errors and to even be optimal under certain assumptions 
\citep{Wickramasuriya2019optimal}. Another complementary approach is to incorporate the hierarchical structure of the problem directly into the training of the initial estimator $\hat{Y}$ 
\citep{rangapuram21end}.
While this method is more computationally intensive, it provides a more comprehensive solution than reconciliation methods because it uses the hierarchy not only to shape the regression function, but also to inform the learning of its parameters. In this paper, we build on this approach to design three new estimators, all of which are implemented in Section~\ref{sec:tourism}.

As for now, we denote by $\ell_1$ the total number of nodes and $\ell_2 \leq \ell_1$ the number of bottom nodes. Thus, $Y=(Y_{\ell})_{1\leq \ell \leq \ell_1}^\top$ represents the global vector of all nodes, while $Y_b=(Y_{\ell})_{1\leq \ell \leq \ell_2}^\top$ represents the vector of the bottom nodes.
The $\ell_1 \times \ell_2$ summation matrix $S$ is defined so that, for all time index~$t$, the summation identity $Y_t = S Y_{b,t}$ is satisfied. 

\paragraph{Estimator 1. Bottom-up approach: WeaKL-BU.} In the bottom-up approach, models are fitted only for the bottom-level series $Y_b$, resulting in a vector of estimators $\hat{Y}_b$. The remaining levels are then estimated by $\hat{Y} = S \hat{Y}_b$, where $S$ is the summation matrix. 

To achieve this, forecasts for each bottom node $1 \leq \ell \leq \ell_2$ are constructed using a set of explanatory variables $X_\ell \in \mathbb R^{d_\ell}$ specific to that node. Together, these explanatory variables $X_1, \hdots, X_{\ell_2}$ form the feature $X\in \mathbb R^{d_1+\dots +d_{\ell_2}}$. A straightforward choice of features are the lags of the target variable, i.e., $X_{\ell, t} = Y_{\ell, t-1}$, though many other choices are possible. Next, for each bottom node $1 \leq \ell \leq \ell_2$, we fit a parametric model $f_{\theta_\ell}(X_{\ell, t})$ to predict the series $Y_{\ell, t}$. 
Each function $f_{\theta_\ell}$ is parameterized by a mapping $\phi_\ell$ (e.g., a Fourier map or an additive model) and a coefficient vector $\theta_\ell$, such that
$f_{\theta_\ell}(X_{\ell,t}) = \langle \phi_\ell(X_{\ell,t}), \theta_\ell \rangle$.
Therefore, the model for the lower nodes $Y_{b, t}$ can be expressed as $\mathbb \Phi_t \theta$, where  $\theta = (\theta_1, \hdots, \theta_{\ell_2})^\top$ is the vector of all coefficients, and $\mathbb{\Phi}_t$ is the feature matrix at time $t$ defined in \eqref{eq:feature_matrix}. 
Overall, the model for all levels $Y_t = S Y_{b, t}$ is $S \mathbb{\Phi}_t \theta$, and the empirical risk corresponding to this problem is given by
\[L(\theta) = \frac{1}{n}\sum_{j=1}^n\|\Lambda( S\mathbb \Phi_{t_j} \theta - Y_{t_j})\|_2^2 + \|M\theta\|_2^2,\]
where $\Lambda$ is a $\ell_1\times \ell_1$ diagonal matrix with positive coefficients,  and $M$ is a penalty matrix that depends on the $\phi_\ell$ mappings, as in Section~\ref{sec:shape}. 

Since $\Lambda$ scales the relative importance of each node in the learning process, the choice of its coefficients plays a critical role in the performance of the estimator. 
In the experimental Section~\ref{sec:tourism}, $\Lambda$ will be learned through hyperparameter tuning. Typically, $\Lambda_{\ell, \ell}$ should be large when $\mathrm{Var}(Y_\ell | X_\ell)$ is low---that is, the more reliable $Y_\ell$ is as a target \citep{Wickramasuriya2019optimal}. From~\eqref{eq:feature_matrix}, we deduce that the minimizer $\hat \theta$ of the empirical risk is 
    \begin{equation}
    \label{eq:pikl-bu}
        \hat \theta = \Big(\Big(\sum_{j=1}^n \mathbb \Phi_{t_j}^\ast S^\ast\Lambda^\ast \Lambda S\mathbb \Phi_{t_j}\Big) + n M^\ast M\Big)^{-1} \sum_{j=1}^n \mathbb \Phi_{t_j}^\ast \Lambda^\ast \Lambda Y_{t_j}.
    \end{equation}
We call $\hat{\theta}$ the {\it WeaKL-BU}. Setting $\Lambda = \mathrm{I}_{\ell_1}$, i.e., the identity matrix, results in treating all hierarchical levels equally, which is the setup of \citet{rangapuram21end}. On the other hand, setting $\Lambda_{\ell, \ell} = 0$ for all $\ell \geq \ell_2$ leads to learning each bottom node independently, without using any information from the hierarchy. 
This is the traditional bottom-up approach.

\paragraph{Estimator 2. Global hierarchy-informed approach: WeaKL-G.} 
The context is similar to the bottom-up approach, but here models are fitted for all nodes $1 \leq \ell \leq \ell_1$, using local explanatory variables $X_\ell \in \mathbb{R}^{d_\ell}$, where $d_\ell \geq 1$. Thus, the model for $Y_{t}$ is given by $\mathbb \Phi_t \theta$, where $\theta = (\theta_1, \hdots, \theta_{\ell_1})^\top$ is the vector of coefficients and $\mathbb{\Phi}_t$ is the feature matrix at time $t$ defined in \eqref{eq:feature_matrix}.
To ensure that the hierarchy is respected, we introduce a penalty term:
\[
\|\Gamma(S\Pi_b\mathbb \Phi_t\theta-\mathbb \Phi_t\theta)\|_2^2  = \|\Gamma(S\Pi_b-\mathrm{I}_{\ell_1})\mathbb \Phi_t\theta\|_2^2,
\]
where $\Gamma$ is a positive diagonal matrix and $\Pi_b$ is the projection operator on the bottom level, defined as $\Pi_b \theta = (\theta_1, \hdots, \theta_{\ell_2})^\top$. As in the bottom-up case, $\Gamma$ encodes the level of trust assigned to each node. 
In Section~\ref{sec:tourism}, we learn $\Gamma$ through hyperparameter tuning. This results in the empirical risk
\[L(\theta) = \frac{1}{n}\sum_{j=1}^n\|\mathbb \Phi_{t_j} \theta - Y_{t_j}\|_2^2 + \frac{1}{n}\sum_{j=1}^n\|\Gamma(S\Pi_b-\mathrm{I}_{\ell_1})\mathbb \Phi_{t_j}\theta\|_2^2 + \|M\theta\|_2^2.\]
where $M$ is a penalty matrix that depends on the $\phi_\ell$ mappings, as in Section~\ref{sec:shape}.
This empirical risk is similar to the one proposed by \citet{Zheng2023coherent}, where a penalty term is used to enforce hierarchical coherence during the learning process.
From \eqref{eq:feature_matrix}, we deduce that the  minimizer is given by 
    \begin{equation}
    \label{eq:pikl-G}
        \hat \theta = \Big(\sum_{j=1}^n (\mathbb \Phi_{t_j}^\ast\mathbb \Phi_{t_j}+ \mathbb \Phi_{t_j}^\ast(\Pi_b^\ast S^\ast-\mathrm{I}_{\ell_1})\Gamma^\ast \Gamma(S\Pi_b-\mathrm{I}_{\ell_1})\mathbb \Phi_{t_j})+nM^\ast M\Big)^{-1} \sum_{j=1}^n \mathbb \Phi_{t_j}^\ast Y_t.
    \end{equation}
We refer to $\hat{\theta}$  as the {\it WeaKL-G}.
The fundamental difference between \eqref{eq:pikl-bu} and \eqref{eq:pikl-G} is that the WeaKL-BU estimator only learns parameters for the $\ell_2$ bottom nodes, whereas the WeaKL-G estimators learns parameters for all nodes. We emphasize that WeaKL-BU and WeaKL-G follow different approaches. While WeaKL-BU adjusts the lower-level nodes and then uses the summation matrix $S$ to estimate the higher levels, WeaKL-G relies directly on global information, which is subsequently penalized by $S$. In the next paragraph, we complement the WeaKL-BU estimator by adding transfer learning constraints.

\paragraph{Estimator 3. Hierarchy-informed transfer learning: WeaKL-T.} In many hierarchical forecasting applications, the targets $Y_{\ell}$ are of the same nature throughout the hierarchy. Consequently, we often expect them to be explained by similar explanatory variables $X_{\ell}$ and to have similar regression functions estimators $f_{\hat{\theta}_\ell}$ \citep[e.g.,][]{leprince2023hierarchical}. For this reason, we propose an algorithm that combines WeaKL-BU with transfer learning.

Therefore, we assume that there is a subset $J \subseteq \{1,
\hdots, \ell_2\}$ of similar nodes and weights $(\alpha_i)_{i\in J}$ such that we expect $\alpha_i f_{\hat \theta_{i}}(X_{i,t}) \simeq \alpha_j f_{\hat \theta_{j}}(X_{j,t})$ for $i, j \in J$. 
In particular, there is an integer $D$ such that $\theta_j \in \mathbb{C}^{D}$ for all $j\in J$.
Therefore, denoting by $\Pi_J$ the projection on $J$ such that $\Pi_J\theta = (\theta_j)_{j\in J}\in \mathbb C^{D|J|}$, this translates into the constraint that $\Pi_J \theta \in \mathrm{Im}(M_J)$ where $M_J = (\alpha_1 \mathrm{I}_{D}, \hdots, \alpha_{|J|} \mathrm{I}_{D})^\top$.
As explained in the paragraph on linear constraints, we enforce this inexact constraint by penalizing the empirical risk with the addition of the term $\|(\mathrm{I}_{D|J|}-P_J)\Pi_J\theta\|_2^2$, where $P_J = M_J(M_J^\ast M_J)^{-1}M_J^\ast$ is the orthogonal projection onto the image of $M_J $.
This leads to the empirical risk
\[L(\theta) = \frac{1}{n}\sum_{j=1}^n\|\Lambda( S\mathbb \Phi_{t_j} \theta - Y_{t_j})\|_2^2+\lambda \|(\mathrm{I}_{D|J|}-P_{J})\Pi_{J}\theta\|_2^2 + \|M\theta\|_2^2,\]
where $M$ is a penalty matrix that depends on the $\phi_\ell$ mappings, as in Section~\ref{sec:shape}.
We call {\it WeaKL-T} the minimizer $\hat \theta$ of $L$. It is given by
    \begin{equation}
    \label{eq:pikl-T}
        \hat \theta = \Big(\Big(\sum_{j=1}^n \mathbb \Phi_{t_j}^\ast S^\ast\Lambda^\ast \Lambda S\mathbb \Phi_{t_j}\Big)+  n\lambda \Pi_{J}^\ast(\mathrm{I}_{D|J|}-P_{J})\Pi_{J}+nM^\ast M\Big)^{-1} \sum_{j=1}^n \mathbb \Phi_{t_j}^\ast\Lambda^\ast \Lambda Y_{t_j}.
    \end{equation}


\subsection{Application to tourism forecasting}
\label{sec:tourism}
\paragraph{Hierarchical forecasting and tourism.} 


In this experiment, we aim to forecast Australian domestic tourism using the dataset from \citet{Wickramasuriya2019optimal}. The dataset includes monthly measures of Australian domestic tourism from January 1998 to December 2016, resulting in $n = 216$ data points. 
Each month, domestic tourism is measured at four spatial levels and one categorical level, forming a five-level hierarchy. At the top level, tourism is measured for Australia as a whole. 
It is then broken down spatially into $7$ states, $27$ zones, and $76$ regions. 
Then, for each of the $76$ regions, four categories of tourism are distinguished  according to the purpose of travel: holiday, visiting friends and
relatives (VFR), business, and other. This gives a total of five levels (Australia, states, zones, regions, and categories), with $\ell_2 = 76 \times 4 = 304$ bottom nodes, and $\ell_1 = 1 + 7 + 27 + 76 + \ell_2 = 415$ total nodes.


\paragraph{Benchmark.} The goal is to forecast Australian domestic tourism one month in advance. Models are trained on the first $80\%$ of the dataset and evaluated on the last $20\%$. 
Similar to \citet{Wickramasuriya2019optimal}, we only consider autoregressive models with lags from one month to two years.
This setting is particularly interesting because, although each time series can be reasonably fitted using the $216$ data points, the total number of targets $\ell_1$ exceeds $n$. Consequently, the higher levels cannot be naively learned from the lags of the bottom level time series through linear regression.

The bottom-up (BU) model involves running $304$ linear regressions $\hat Y^{\mathrm{BU}}_{\ell,t} = \sum_{j=1}^{24}a_{\ell, j}Y_{\ell,t-j}$ for $1\leq \ell \leq \ell_2$, where $Y_{\ell,t-j}$ is the lag of $Y_{\ell, t}$ by $j$ months. 
The final forecast is then computed as $\hat Y^{\mathrm{BU}}_{t} = S\hat Y^{\mathrm{BU}}_{\ell,t}$,  where $S$ is the summation matrix.  
The Independent (Indep) model involves running separate linear regressions for each target time series using its own lags. This results in $415$ linear regressions of the form $\hat Y^{\mathrm{Indep}}_{\ell,t} = \sum_{j=1}^{24}a_{\ell, j}Y_{\ell,t-j}$ for $1\leq \ell \leq \ell_1$. 
Rec-OLS is the estimator resulting from OLS adjustment of the Indep estimator, i.e., taking $P = S(S^\ast S)^{-1}S$ \citep{Wickramasuriya2019optimal}. 
MinT refers to the estimator derived from the minimum trace adjustment of the Indep estimator \citep[see MinT(shrinkage) in][]{Wickramasuriya2019optimal}.
PIKL-BU refers to the estimator \eqref{eq:pikl-bu}, where, for all $1\leq \ell \leq 304$, $X_{\ell,t} = (Y_{\ell, t-j})_{1\leq j \leq 24}$ and $\phi_\ell(x) = x$.
PIKL-G is the estimator \eqref{eq:pikl-G}, where, for all $1\leq \ell \leq 415$, $X_{\ell,t} = (Y_{\ell, t-j})_{1\leq j \leq 24}$ and $\phi_\ell(x) = x$. 
Finally, PIKL-T is the estimator \eqref{eq:pikl-T}, where $X_{\ell,t} = (Y_{\ell, t-j})_{1\leq j \leq 24}$ and $\phi_\ell(x) = x$. 
In the latter model, all the auto-regressive effects are penalized to enforce uniform weights, which means that $\alpha_\ell = 1$ and $J = \{1, \hdots, \ell_2\}$ in \eqref{eq:pikl-T}.
The hyperparameter tuning process to learn the matrix $\Lambda$ for the WeaKLs is detailed in Appendix~\ref{sec:hierarchical_details}.

\paragraph{Results.} Table~\ref{table_australia} shows the results of the experiment. The mean square errors (MSE) are computed for each hierarchical level and aggregated under {\it All levels}. 
Their standard deviations are estimated using block bootstrap with blocks of length $12$.
The models are categorized based on the features they utilize.
We observe that the WeaKL-type estimators consistently outperform all other competitors in every case. This highlights the advantage of incorporating constraints to enforce the hierarchical structure of the problem, leading to an improved learning process.


\begin{table}[H]
\centering
\caption{Benchmark in forecasting Australian domestic tourism} 
\begin{tabular}{lcccccc}
\toprule
 &  & &$\;$\hfill  MSE  & ($\times 10^6$) \hfill $\;$&   &  \\
 \cmidrule{2-7}%
 & Australia & States & Zones & Regions & Categories & All levels \\
\midrule
\textit{Bottom data} &&&&&&\\
BU & $5.3\!\pm\!0.5$ & $2.0\!\pm\!0.2$ & $1.37\!\pm\!0.05$ & $\mathbf{1.19\!\pm\!0.02}$ & $\mathbf{1.17\!\pm\!0.03}$ & $11.0\!\pm\!0.7$ \\
WeaKL-BU & $\mathbf{4.5\!\pm\!0.5}$ & $\mathbf{1.9\!\pm\!0.3}$ & $\mathbf{1.34\!\pm\!0.05}$ & $\mathbf{1.19\!\pm\!0.03}$ & $\mathbf{1.17\!\pm\!0.03}$ & $\mathbf{10.1\!\pm\!0.6}$ \\
\midrule
\textit{Own lags} &&&&&&\\
Indep & $3.6\!\pm\!0.6$ & $1.8\!\pm\!0.2$ & $1.42\!\pm\!0.05$ & $1.23\!\pm\!0.03$ & $1.17\!\pm\!0.03$ & $9.2\!\pm\!0.7$ \\
WeaKL-G & $\mathbf{3.6\!\pm\!0.5}$ & $\mathbf{1.8\!\pm\!0.2}$ & $\mathbf{1.37\!\pm\!0.05}$ & $\mathbf{1.18\!\pm\!0.03}$ & $\mathbf{1.15\!\pm\!0.03}$ & $\mathbf{9.0\!\pm\!0.7}$ \\
\midrule
\textit{All data} &&&&&&\\
Rec-OLS & $3.5\!\pm\!0.5$ & $1.8\!\pm\!0.2$ & $1.35\!\pm\!0.05$ & $1.18\!\pm\!0.02$ & $1.17\!\pm\!0.03$ & $8.9\!\pm\!0.7$ \\
MinT & $3.6\!\pm\!0.4$ & $1.7\!\pm\!0.1$ & $1.29\!\pm\!0.05$ & $\mathbf{1.15\!\pm\!0.03}$ & $1.17\!\pm\!0.03$ & $8.9\!\pm\!0.5$ \\
WeaKL-T & $\mathbf{3.1\!\pm\!0.3}$ & $\mathbf{1.7\!\pm\!0.1}$ & $\mathbf{1.27\!\pm\!0.05}$ & $\mathbf{1.15\!\pm\!0.02}$ & $\mathbf{1.12\!\pm\!0.03}$ & $\mathbf{8.3\!\pm\!0.4}$ \\
\bottomrule
\end{tabular}
\label{table_australia}
\end{table}

\section{Conclusion}

In this paper, we have shown how to design empirical risk functions that integrate common linear constraints in time series forecasting. For modeling purposes, we distinguish between shape constraints (such as additive models, online adaptation after a break, and forecast combinations) and learning constraints (including transfer learning, hierarchical forecasting, and differential constraints). 
These empirical risks can be efficiently minimized on a GPU, leading to the development of an optimized algorithm, which we call WeaKL. 
We have applied WeaKL to three real-world use cases---two in electricity demand forecasting and one in tourism forecasting---where it consistently outperforms current state-of-the-art methods, demonstrating its effectiveness in structured forecasting problems.

Future research could explore the integration of additional constraints into the WeaKL framework. For example, the current approach does not allow for forcing the regression function $f_\theta$ to be non-decreasing or convex. However, since any risk function $L$ of the form \eqref{eq:risk} is convex in $\theta$, the problem can be formulated as a linearly constrained quadratic program. While this generally increases the complexity of the optimization, it can also lead to efficient algorithms for certain constraints. In particular, when $d=1$, imposing a non-decreasing constraint on $f_\theta$ reduces the problem to isotonic regression, which has a computational complexity of $O(n)$ \citep{wright1980isotonic}.