\section{Related Work}
\label{sec:related}
\paragraph{Tensor Network Structure Search}
%
TN-SS has been explored in prior work from different aspects.
%
One branch of TN-SS focuses on optimizing rank assignments____.
%
These studies target specific tensor network topologies, proposing efficient algorithms to sample rank assignments and verifying whether the sampled ranks meets the error constraints.
%
Another branch concentrates on topology search while keeping the internal rank assignments fixed____.
%
More recent work address the complete TN-SS problem____, incorporating both topology and rank search.
%
Most of these methods adopt a sampling-based design, where they sample both the topology and rank assignments, and validate each candidate structure to check if it satisfies the desired error bound.
%
An alternative approach is introduced by ____ which avoids sampling.
%
Their method encodes both topology and rank search into a unified optimization problem, and employs the alternating direction method of multipliers (ADMM) to find a solution.
%
Our idea can be viewed as an variant of sampling-based methods.
%
However, our dedicated domain-specific language (DSL) for tensor network transformation, combined with the constraint-based sketch completion, effectively reduces the number of required samples and accelerates the search.
%
\paragraph{Low-Rank Tensor Decomposition}
%
Low-rank tensor decomposition has been studied for many different structures.
%
Tucker decomposition____ factorizes a high-order tensor into a core tensor with several low-rank tensors, one for each mode.
%
Tensor train decomposition____ expresses a high-order tensor as a linear multiplication of 3-order tensors.
%
Hierarchical Tucker decomposition____ generalizes tensor trains and tuckers to arbitrary trees, offering greater flexibility and compression potential.
%
Beyond tree-based structures, several prior work____ explores tensor decomposition for structures with cycles, such as tensor rings or tensor chains.
%
In contrast, our work focuses on searching for the optimal tree structure representation to compress the input data tensor.
%
Cyclic structures are currently outside our search space, and we plan to consider them in future work.
%
\begin{figure}[t]
    \centering
    \begin{minipage}{.4\linewidth}
    \centering
    \small
    \begin{align*}
        &\osplit(\{I_1\}, r_1);\\
        &\osplit(\{I_1, I_2\}, r_2);\\
        &\osplit(\{I_2\}, r_3);
    \end{align*}
    \end{minipage}
    %
    \hfill
    %
    \begin{minipage}{.55\linewidth}
    \centering
    \resizebox{.85\linewidth}{!}{
        \input{figs/tn_example}
    }
    \end{minipage}    
    \caption{An example transformation program (left) and the result tensor network (right).}
    \label{fig:example-program}
\end{figure}
\paragraph{Sketch-Based Program Synthesis}
%
Sketches have been widely used in the program synthesis community.
%
The idea of sketch generation and completion was first introduced by____ for bit-manipulation programs.
%
Since then, sketches have demonstrated their effectiveness in various domains such as stencil computations____, database programs____, Java programming____,  and regular expression synthesis____.
%
These methods share a common structure: a sketch generation phase followed by sketch completion, and the sketch completion phase uses constraints to encode syntactic and semantic requirements.
%
We adapt this framework to the TN-SS problem by encoding the error bound constraints as an integer programming problem and optimizing for network costs.
%
Additionally, we show that a smart prioritization strategy at the sketch level significantly reduces the number of required samples and enhances efficiency.