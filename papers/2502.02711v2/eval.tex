\section{Evaluation}\label{sec:eval}
%
In this section, we present the empirical evaluation results, which aim to answer the following research questions:
\begin{enumerate}[label=\textbf{(RQ\arabic*)},align=left,parsep=-1ex,topsep=0ex]
    \item Can our algorithm discover well-compressed structures for both synthetic and real data?
    \item How does the performance of our algorithm compare to prior work?
    \item How useful are output-directed splits and constraint-based sketch completion in accelerating the search?
\end{enumerate}

\paragraph{General Experiment Setup}
%
We run all the following experiments on a laptop with the Apple M3 Max CPU and 128 GB memory.
%
In the experiments, we collect the running time and the compression ratio, which is defined as $\size{\ten{T}}\slash{\size{\net{G}}} = {\size{\ten{T}}}\slash{\sum_{v\in \nodes}\size{v}}$.

\subsection{Comparison on Synthetic Data}\label{sec:eval:synthetic}
\paragraph{Experiment Setup}
%
We evaluate our algorithm on synthetic data by generating random tensors contracted from random tree structures.
%
This provides a basic test that our algorithm can identify structures with compression ratios equal to or better than the ground truth.
%
Following prior work~\cite{zheng2024svdinstn}, we generate order-4 tensors with dimensions $16 \times 18 \times 20 \times 22$ and order-5 tensors with dimensions $14 \times 16 \times 18 \times 20 \times 22$.
%
Internal ranks are randomly sampled between $2$ and $5$.
%
For each shape, we sample $50$ random structures with randomly assigned tensor values, and contract them into data tensors.

\paragraph{Result Analysis}
%
\cref{fig:eval:synthetic} compares the compression ratios of the ground truth structures and the structures discovered by our algorithm.
%
The results demonstrate that the compression ratio achieved by our algorithm is greater than or equal to the ground truth for every data point.
%
This answers RQ1 and confirms that the propose algorithm can identify the ground truth structures or, in some cases, discover better structures as the ground truth may not be optimal.

\subsection{Comparison on Real Data}\label{sec:eval:real}
%
\paragraph{Experiment Setup}
%
To evaluate the performance of our method on real-world data, we take the light field dataset from prior work~\cite{zheng2024svdinstn}, the BigEarthNet dataset~\cite{sumbul2019bigearthnet} of Sentinel-2 image patches, and the PDEBench dataset~\cite{PDEBench,PDEBench2022} of PDE parameters.
%
For the light field dataset, we follow the setup in prior work and take the bunny data with dimensions $40 \times 60 \times 3 \times 9 \times 9$.
%
For the BigEarthNet dataset, we randomly sample $30$ and $3000$ data points and stack them together to create tensors with dimensions $30 \times 12 \times 120 \times 120$ and $5 \times 20 \times 30 \times 12 \times 120 \times 120$ respectively.
%
For the PDEBench dataset, we take the data from the 3D compressible Navier-Stokes problem, randomly sample $10$ data points, and generate tensors with dimensions $10 \times 5 \times 21 \times 64 \times 64 \times 64$.
%
We compare our method in terms of search time and compression ratio against tensor trains, binary hierarchical tuckers, and three baselines:
%
\begin{enumerate*}[label=(\arabic*)]
    \item GreedyTN~\cite{hashemizadeh2020adaptive}: a greedy algorithm that gradually increases internal ranks until the desired accuracy is achieved;
    \item TnALE~\cite{Li_Zeng_Tao_Zhao_2022}: a sampling-based method that reduces sample size by local search;
    \item SVDinsTN~\cite{zheng2024svdinstn}: an optimization-based approach that encodes rank search as a tensor value search problem.
\end{enumerate*}
%
For our algorithm, we search sketches of up to $6$ splits and pick the topmost one for the actual tensor decomposition.
%
The timeout limit is 3 hours.
%
\begin{figure}
    \centering
    \includegraphics[width=.85\linewidth]{figs/random_parity.pdf}
    \caption{Compression results for random generated data.}
    \label{fig:eval:synthetic}
\end{figure}

\begin{figure*}[t]
    \centering
    
    \begin{minipage}{.245\linewidth}
    \includegraphics[width=\linewidth]{figs/bunny_010.pdf}
    \end{minipage}
    %
    \begin{minipage}{.245\linewidth}
    \includegraphics[width=\linewidth]{figs/stack_30_eps_010.pdf}
    \end{minipage}
    %
    \begin{minipage}{.245\linewidth}
    \includegraphics[width=\linewidth]{figs/stack_3000_eps_010.pdf}
    \end{minipage}
    %
    \begin{minipage}{.245\linewidth}
    \includegraphics[width=\linewidth]{figs/PDEBench_010.pdf}
    \end{minipage}
    
    \begin{minipage}{.245\textwidth}
    \includegraphics[width=\linewidth]{figs/bunny_001.pdf}
    \end{minipage}
    %
    \begin{minipage}{.245\linewidth}
    \includegraphics[width=\linewidth]{figs/stack_30_eps_001.pdf}
    \end{minipage}
    %
    \begin{minipage}{.245\linewidth}
    \includegraphics[width=\linewidth]{figs/stack_3000_eps_001.pdf}
    \end{minipage}
    %
    \begin{minipage}{.245\linewidth}
    \includegraphics[width=\linewidth]{figs/PDEBench_001.pdf}
    \end{minipage}
    \caption{Comparison of compression ratio vs time on real datasets. The datasets from left to right are light field data ($40 \times 60 \times 3 \times 9 \times 9$), BigEarthNet ($30 \times 12 \times 120 \times 120$), BigEarthNet ($5 \times 20 \times 30 \times 12 \times 120 \times 120$), and PDEBench ($10 \times 5 \times 21 \times 64 \times 64 \times 64$). The two rows corresponds to error bounds of $0.1$ and $0.01$ respectively.}
    \label{fig:eval:real}
    \vspace{20pt}
\end{figure*}

\paragraph{Result Analysis}
%
The experiment results on real data are shown in \cref{fig:eval:real}.
%
Compared to TT and HT, our algorithm finds more compressed network structures but requires only around an order of magnitude more time across all test datasets.
%
This is expected, as our approach explores arbitrary tree structures and allows reordering free indices, whereas TT and HT are limited to being two special cases in our broader search space.
%
When compared with prior work, our method achieves equal or better compression ratios, especially on large data tensors.
%
More importantly, our method is at least $10\times$ faster than baselines.
%
TnALE occasionally discovers structures with higher compression ratios because it can find structures with cycles, which is not in our search space.
%
However, its reliance on a large number of samples to achieve good compression ratio makes it extremely slow for all test cases. 
%
TnALE sometimes does not converge to the desired error bound within 3-hour timeout, and suffers from out-of-memory issues on large tensors.
%
TNGreedy and SVDinsTN exhibit similar performance as ours on smaller data tensors and larger error bounds, although they adopt two different strategies in search: TNGreedy gradually increases the ranks while SVDinsTN gradually decreases the ranks.
%
Neither method scales well when the size of data tensor grows, failing to produce results within the 3-hour timeout for BigEarthNet data with $\error = 0.01$ and other larger data tensors with both error bounds.
%
These results answer both RQ1 and RQ2 that our method performs better than baseline tools on both search time and compression ratio.
%
Our method avoids repeatedly attempting different rank assignments.
%
Instead, this task is delegated to constraint solvers, and we defer the actual data fitting until the final step, which reduces the number of expensive computations.

\subsection{Ablation Study}\label{sec:eval:ablation}
%

\paragraph{Input- vs Output-Directed Splits}
%
We evaluate the effectiveness of output-directed splits by replacing them with input-directed splits during sketch generation but keeping the constraint-based rank search algorithm.
%
The combination size of input-directed splits is limited to $5$.
%
We compare compression ratios and running time of the two settings on BigEarthNet data with dimensions $30\times 12 \times 120 \times 120$.
%
\cref{tab:ablation} shows that both methods achieve similar compression ratios, but output-directed splits runs significantly faster because using $\osplit$ results in only $63$ sketches whereas using $\isplit$ leads to $35727$ sketches.
\begin{table}[t]
    \small
    \centering
    \caption{Comparison of compression ratio (CR) and runtime (in seconds) on BigEarthNet $30\times 12 \times 120 \times 120$ data across different variants of our algorithm\footnotemark. The variants differ based on the type of splits used ($\osplit$ or $\isplit$) and the rank search method (constraint-based or equal error distribution). $\osplit$ + Constraint is ours. Results are shown for error bounds $\error=0.1$ and $\error=0.01$.}
    \label{tab:ablation}
    \begin{tabular}{cc|rr|rr}
        \toprule
        \multicolumn{2}{c|}{Variant} & \multicolumn{2}{c|}{$\error = 0.1$} & \multicolumn{2}{c}{$\error = 0.01$} \\
        \midrule
        Split & Rank & CR & Time & CR & Time \\
        \midrule
        $\osplit$ & Constraint & $156.45$ & $\mathbf{5.04}$ & $2.68$ & $\mathbf{8.06}$\\
        $\isplit$ & Constraint & $154.64$ & $1248.06$ & $2.66$ & $419.65$\\
        $\osplit$ & Equal & $147.51$ & $15.04$ & $2.62$ & $68.97$\\
        \bottomrule
    \end{tabular}
    \vspace{-20pt}
\end{table}

\paragraph{w/ vs w/o Constraint-Based Rank Search}
%
To evaluate the effectiveness of constraint-based rank search, we compare it against a variant that distributes the error budget equally between steps, which is the strategy adopted by HT and TT.
%
The results in \cref{tab:ablation} demonstrate that this variant not only achieves a lower compression ratio but is also slower than the constraint-solving approach.
%
Our constraint-based rank search method avoids performing actual data fitting for each sketch by using a constraint solver, which reduces computation time, especially for small error bounds.
\footnotetext{Ablation experiments on larger tensors did not produce results within $12$ hours and are therefore omitted.}

\subsection{Generalization Analysis}\label{sec:eval:general}
%
To understand whether the structure discovered by our algorithm generalizes to unseen data in the same dataset, we perform a generalization test.
%
\paragraph{Experiment Setup}
We divide the data samples in each dataset into batches of equal size.
%
For the first batch (the training batch), we perform both topology search and rank search using the proposed algorithm.
%
For the following ones (the test batches), we take the topology returned by the training batch, and only run the constraint-based rank search to assess how well this topology generalizes to unseen data from the same source.
%
In the BigEarthNet dataset, we divide the data into $89$ batches, each containing $3000$ samples and resulting in a tensor of shape $5 \times 20 \times 30 \times 12 \times 120 \times 120$.
%
In the PDEBench dataset, we divide the data into $60$ batches of $10$ samples each, producing tensors of shape $10 \times 5 \times 21 \times 64 \times 64 \times 64$.
%
We use $\error = 0.1$ for this experiment.
%

\begin{table}[t]
    \centering
    \small
    \caption{Performance of network search on the training batch, optimal discovered network on the test batches, and hierarchical Tuckers (HT) on the test batch with respect to compression ratios (CR) and time (in seconds).}\label{tab:generalization}
    \begin{tabular}{c|rr|rr}
        \toprule
        & \multicolumn{2}{c|}{BigEarthNet}  & \multicolumn{2}{c}{PDEBench} \\
        \cmidrule{2-5}
        & CR & Time & CR & Time\\
        \midrule
        Train & $157.12$ & $4591.64$  & $38.75$ & $2141.85$ \\
        Test &$148.98$ & $109.61$ & $38.58$ & $115.38$ \\
        HT  & $60.71$ & $190.98$ & $22.65$ & $95.21$ \\
        \bottomrule
    \end{tabular}
    \vspace{-20pt}
\end{table}

\paragraph{Result Analysis}
\cref{tab:generalization} presents the compression ratios and running time for the training batch and the averages of the test batches.
%
The results show that the compression ratios of the test batches are close to that of the training batch, which proves that the discovered topology generalizes well to unseen data.
%
Particularly, although the training batch requires thousands of seconds to find the optimal structure, it takes only about $110$ seconds on average to perform the decomposition for a single test batch.
%
This result reinforces the feasibility of running the training batch once to determine the optimal topology and reusing it for subsequent batches, which significantly reduces the overall computation time.