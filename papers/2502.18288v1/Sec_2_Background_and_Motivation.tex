\section{Background and Motivation} \label{sec:background}

This section introduces some necessary background about \zk and analyzes the issues that motivate this work. 







\subsection{{\zk}} \label{subsec:zk}
% todo 这里的参考文献

\begin{figure}[t]
    \centering
    \includegraphics[width=0.48\textwidth]{figures/ZK-SNARKs.png}
    \caption{The complete process of a \zk protocol.}
    \label{fig:zk-snarks}
    \vspace{10pt}
\end{figure}

Zero-knowledge proofs enable one party, the prover, to demonstrate the validity of a statement to another party, the verifier, without revealing any information about the statement.
\zk \cite{bitansky2013succinct, chiesa2020marlin} is one of the well-known Zero-Knowledge protocols, which has been widely adopted in various real-world applications. For example, the blockchains, especially cryptocurrency systems, employ it to validate transactions while keeping details confidential for privacy protection \cite{sasson2014zerocash,danezis2013pinocchio,filecoin2022,quorum2022,guo2024zkcross,kosba2016hawk,mina2022,qedit2017}.
Furthermore, {\zk} can enable off-chain execution and on-chain verification based on the succinct proofs, mitigating the on-chain transaction pressure \cite{xie2022zkbridge,mina2022,xu2024exploring}.
Beyond this, \zk is applied in verifiable outsource system\cite{wahby2014efficient,costello2015geppetto,delignat2016cinderella}, such as database outsourcing \cite{li2023zksql,zhang2017zero} and privacy-preserving machine learning \cite{liu2021zkcnn,chen2024zkml}, promising result correctness and data privacy.

 
 
In {\zk}, the computation logic is expressed by a \emph{circuit} as examplified in \cref{fig:ex_zk_circuit}, where each step of the computation is converted to a logical operation. To guarantee the circuit execution meets our expectation, some \emph{constraints}, i.e., a set of equations/inequations, are imposed on the inputs and outputs.  \Cref{fig:zk-snarks} shows a complete process of a \zk protocol:
%, which can be formally expressed as a three-tuple of polynomial time algorithms
\begin{itemize}[leftmargin=*]
    \item $Setup(1^\lambda,F)\to(pk_F,vk_F)$. This phase takes a predicate $F$ (i.e., ) as inputs and generates a proving key $pk_F$ and a verification key $vk_F$. The setup is performed once per circuit and can be reused for multiple proofs about $F$.
        
    \item $Prove(x,w,pk_F)\to\pi$. This phase generates a proof $\pi$ using the instance $x$, witness $w$, and proving key $pk_F$. The proof $\pi$ attests that $w$ satisfies $F$ with respect to $x$, without revealing any information about $w$.
    
    \item $Verify(x,\pi,vk_F)\to\{0,1\}$. This phase verifies whether proof $\pi$ is valid, for instance, $x$, using the verification key $vk_F$. It can efficiently check the proof without the need to recomput $F$.
\end{itemize}

Generally, the setup phase is a one-time operation, and the verify phase is performed on the verifier's side. Thus, the performance for them is not our concern. The prove phase, the focus of this work, commonly consumes tremendous computational resources. Particularly, the prove phase in \zk consists of two major components: \emph{witness generation} and \emph{proof computation}. 




\begin{figure}[t]
    \centering
    \includegraphics[width=0.44\textwidth]{figures/zk_example.pdf}
    \caption{An example of the \zk circuit. }
    \label{fig:ex_zk_circuit}
\end{figure}


 





\paragraph{Witness generation} Witness generation builds the necessary inputs required for proof computation, known as the witness $w$ satisfying the predicate $F$, against a given instance. 
%It prepares the foundational data required for the proof without revealing sensitive information. 
The intermediate values are computed during witness generation to satisfy the circuit's constraints. The circuit can be regarded as a layered graph, and the computation is processed layer-by-layer as depicted in \cref{fig:ex_zk_circuit}. Specifically, the nodes in each layer depend on the outputs from the previous layer. Within each layer, all nodes are completely independent, implying the parallel computation for nodes in the same layer. Thus, the parallelism potential of the witness generation phase is highly related to the circuit's structure.






 



% 这里NTT还是要说...因为现在NTT用的比FFT多,FFT算是ZKP刚提出来的时候的标配，NTT比它更新一点，现在更常用
\paragraph{Proof computation} Proof computation produces a succinct cryptographic proof from the witness based on the proving key and the circuit constraints. This phase involves several computationally intensive operations, including the polynomial (POLY) evaluation and the multi-scalar multiplication (MSM). During the POLY stage, the Fast Fourier Transform (FFT) or its variant, the Number Theoretic Transform (NTT), is applied to efficiently evaluate polynomials over a large number of points. The subsequent MSM stage combines multiple elliptic curve points with their corresponding scalar values. The MSM stage is particularly resource-intensive, often accounting for up to 70\% of the total proof generation time in CPU-based \zk implementations \cite{ma2023gzkp}.




%It is important to note that while proof computation depends on the completion of its corresponding witness generation, the witness generation and proof computation of separate tasks are entirely independent of one another.


\begin{figure*}[t]
%\vspace{10pt}
\centering
\includegraphics[width=\textwidth]{figures/overview.pdf}
\caption{System architecture and overall workflow of \system.}
\label{fig:overview}
\end{figure*}


\vspace{-10pt}

\subsection{Motivation}

Although \zk has made significant progress in various aspects, two challenges still hinder its applications for large-scale circuits. 




\paragraph{Inefficiencies in witness generation} 
Significant efforts, e.g., Gnark \cite{gnark}, have been dedicated to optimizing the proof computation phase, enhancing resource utilization, and accelerating proof generation. However, the witness generation phase that draws less attention has gradually become a bottleneck in the overall system efficiency. This is because the parallelism of witness generation directly inherits from the circuit structure, which is difficult to accelerate. As a result, the average resource utilization remains low even with highly optimized proof computation. This situation will escalate in scenarios where proof generation is continuously invoked, such as verifiable computation platforms handling concurrent user requests. Therefore, how to increase resource utilization becomes a critical issue for such platforms. 




%This imbalance between witness generation and proof computation leads to suboptimal CPU usage, which is detrimental in high-throughput environments. Particularly, in scenarios where a continuous stream of proofs needs to be generated, such as verifiable computation platforms handling concurrent user requests, the inefficiencies in witness generation become a critical issue.


% 按照上一次的讨论，在motivation里是把内存单独拿出来的，然后下面的逻辑就是1. zkp本身要内存很多；2. 这种内存大的问题会顺带影响到一些并行的优化，就是说本来跑一个就要很大内存了，跑多个更多了；这样能挂上pipeline，然后目前的intro里的逻辑是先说利用率->pipe,然后pipe->内存太大->partition
% 一种可能是把内存也作为一个单独的贡献，就是说，我们通过partition解决了内存问题，逻辑上来说没问题，实际情况是各个子电路的pk是要同时存在内存的，因为不可能只用一次都不用了，（尝试过持久化，读进来也很慢很慢，分钟级别），pk太大了，所有子电路的pk大小总和可以认为和原来的一个pk差不多，所以这部分内存没动，减少的是prove过程的内存，这个确实1/n，但这部分内存比pk小不少，大概是40G：20G，然后partition是动了那20G；可以看实验，实验是区分了total memory(包括pk)和Prove memory（不包括pk的），然后partition的实验里total memory不算堆叠pk，pipeline实验里算了堆叠pk；

\paragraph{Memory overhead} 
\zk circuits frequently comprise millions of constraints, leading to substantial memory requirements. This large memory footprint constrains the scalability of \zk systems and undermines the potential of parallel optimizations in proof generation. To address this, SPLIT \cite{qi2023split} introduced an approach that partitions circuits into smaller subcircuits and executes them sequentially. However, this method relies on manual circuit division, impractical in current in-production \zk circuits. As the size and complexity of the circuits increase, manual division is even prone to errors. Consequently, there is a pressing need for a general and automatic circuit partitioning algorithm specifically designed for single-machine environments.



%Manual partitioning is especially problematic in practice, as ZK-SNARK circuits are often deeply intertwined with application-specific logic, making it difficult to abstract and generalize the partitioning process. 



% Although ZK-SNARK proofs are succinct and efficient to verify, proof generation remains a significant challenge hindering large-scale adoption. To generate proofs, the prover executes numerous arithmetic operations over a large finite field, resulting in proof generation times that far exceed those required for verification. Despite the successful deployment of ZK-SNARKs in various domains, this computational complexity continues to impose substantial overhead. In response, considerable research efforts have been dedicated to optimizing ZK-SNARK proof generation by improving the speed and resource utilization of \textit{proof computation} through advancements in underlying algorithms or hardware accelerations\cite{chen2017big,dai2016cuhe,goey2021accelerating,kim2020accelerating, ma2023gzkp, zhang2021pipezk, ji2024accelerating,govindaraju2008high}. 

% However, these works have largely overlooked the bottlenecks in the \textit{witness generation} phase, which is equally critical to the overall proof generation process. Witness generation often suffers from limited parallelism due to the structure of the circuit, which directly impacts the system's overall resource utilization. Even with highly optimized proof computation, the system's performance may be severely constrained by the slower, less parallelizable witness generation phase. This imbalance between witness generation and proof computation leads to suboptimal CPU usage, which is detrimental in high-throughput environments. Therefore, in scenarios where a continuous stream of proofs needs to be generated, such as verifiable computation platforms handling concurrent user requests, the inefficiencies in witness generation become a critical issue.

% Another major concern in ZK-SNARK systems is memory usage, which has long been a critical bottleneck. ZK-SNARK circuits often contain tens or even hundreds of millions of constraints, resulting in immense memory requirements. This large memory footprint not only limits the scalability of ZK-SNARKs but also diminishes the effectiveness of various optimizations in proof generation, as memory limitations can constrain the ability to fully utilize parallelism. To address this issue, some works have adopted circuit partitioning approaches\cite{rosenberg2024hekaton,liu2024pianist, sang2023automating, qi2023split,costello2015geppetto}. However, these solutions either rely on tools like METIS\cite{karypis1998fast}, which are designed for distributed systems and are not suitable for single-machine environments, or opt for manually partitioning circuits at the code level rather than offering a generalized, automated partitioning method. Manual circuit partitioning is especially problematic because ZK-SNARK circuits are often tightly coupled with application-specific logic, making it difficult to abstract or generalize the partitioning process. As circuit size and complexity grow, manual partitioning becomes increasingly impractical and error-prone, introducing significant overhead in terms of both time and computational resources. As a result, there is a pressing need for a general-purpose, automated circuit partitioning algorithm that is specifically designed for single-machine environments.

