\section{Analysis}
\label{sec:analysis}

%Let us start by considering the entropy
%\begin{align}
%    \condent(\agen,\estn) = -\sum_{\mcn} p(\mcn\given\agen,\estn) \log_2 p(\mcn\given\agen,\estn)
%    \label{eq:cond_entropy_formula}
%\end{align}
%whose calculation requires the conditional distribution of the  source state given the current receiver estimate and the AoI value. 
To characterize the uncertainty at the receiver, we will resort to the auxiliary terminating Markov chain $Y_n$ reported in \figr\ref{fig:markovChains}b, with state-space $\mathcal Y = \{0,1,\mathsf d\}$. The chain transitions between the two upper states so long as the sink receives no message from the reference node, with $0$ and $1$ denoting the actual current source value. In turn, the process enters the absorbing state $\mathsf d$ as soon as an update refreshing the receiver estimate is delivered. 
%\begin{figure}
%    \centering
%    \includegraphics[width=.8\columnwidth]{./Figures/absorbing_MC.pdf}
%    \caption{Terminating Markov chain useful to characterize the distributions needed in the computation of the conditional entropy $\ent(\Mcn\given\Agen,\Estn)$. The chain transitions to the absorbing state $\mathsf d$ whenever an update from the reference node is received, refreshing the estimate. Conversely, the chain moves between states $0$ and $1$, describing the corresponding current reference source value, so long as no update message from the reference terminal arrives.}
%    \label{fig:absMC}
%\end{figure}
The one-step transition matrix for the process can be written as
\begin{align}
    \mathbf P = 
    \left(
        \begin{array}{cc|c}
            q_{00}  & q_{01} & q_{0\mathsf d}\\  
            q_{10}  & q_{11} & q_{1\mathsf d}\\[.3em]
            \hline
            0       & 0      & 1
        \end{array}
    \right)
     =
    \begin{pmatrix}
        \mathbf A & \mathbf a_{\mathsf d}\\
        \mathbf 0 & 1 \\
    \end{pmatrix}
\end{align}
where $\mathbf A$ is the $2\times 2$ matrix that captures transitions between $0$ and 1, and the $2\times 1$ vector $\mathbf a_{\mathsf d}$ contains the probability of being absorbed from each of the two states. In turn, the transition probabilities can be derived for the considered system model. For instance, focusing on state $0$, the chain will move to $1$ with probability $q_{01} = \qZO (1-\pTx_{01}\ps)$. Here, the first factor captures the fact that the source has to move to state $1$, whereas the second accounts for the lack of an update delivery from the terminal over the current slot (which would lead to absorption). Similarly, the chain remains in $0$ with probability \mbox{$q_{00}=(1-\qZO)(1-\pTx_{00}\ps)$}. Finally, if a message is successfully sent, the chain moves to $\mathsf d$, regardless of the state of the source, i.e., with overall probability $q_{0\mathsf d} = (\qZO\pTx_{01}+(1-\qZO)\pTx_{00})\ps$. The transitions from $1$ are immediately derived in the same manner and are not reported for the sake of compactness. 

The chain leads to a first result, captured in the following
\begin{prop} \label{prop1}The conditional probability of the reference source being in state \mcn\ given that its current AoI is \agen\ and the last received updated contained state \estn\ is 
    \begin{align}
        p(\mcn\given\agen,\estn) = \frac{ \mathbf e_{\estn}^{\mathsf T} \mathsf A^{\agen} \,\mathbf e_{\mcn}}{\mathbf e_{\estn}^{\mathsf T} \mathsf A^{\agen} \mathbf 1_2}
        \label{eq:pmfXnGivenDeltaXnHat}
    \end{align}
    where, for any $\estn$ and \mcn\ in  $\mathcal X$, $\mathbf e_{\estn}$ and $\mathbf e_{\mcn}$ are defined as \mbox{$\mathbf e_0 = [1,0]^{\mathsf T}$}; $\mathbf e_1 = [0,1]^{\mathsf T}$.
\end{prop}
%\begin{align}
%    p(\mcn\given\agen,\estn) = \frac{[\mathsf A^{\agen}]_{\estn,\mcn}}{[\mathsf A^{\agen}]_{\estn,0} + [\mathsf A^{\agen}]_{\estn,1}}
%    \label{eq:pmfXnGivenDeltaXnHat}
%\end{align}
\begin{proof}
We observe that, for the Markov chain of \figr\ref{fig:markovChains}b, the $\ell$-step transition probability from $i$ to $j$, with $i,j \in \{0,1\}$, provides the joint distribution of the source being in state $j$ and of not having delivered an update over the last $\ell \geq 1$ slots, given that its state $\ell$ slots ago was $i$. This corresponds to having an estimate $i$, content of the last received message, and a current AoI value $\ell$. By the definition of conditional probability, the sought distribution follows as
\begin{align}
    p(\mcn\given\agen,\estn) = \frac{q_{\estn \mcn}(\agen)}{p(\agen\given\estn)}.
\end{align}
The numerator is directly given by the \estn-row, \mcn-column element of the \agen-step transition matrix $\mathbf P^\agen$ of the chain. By the structure of $\mathbf P$, it is immediate to verify that this corresponds to $\mathbf e_{\estn}^{\mathsf T} \mathsf A^{\agen} \,\mathbf e_{\mcn}$. On the other hand, %the conditional probability of having AoI value $\agen$ given a last update of value $\estn$ 
$p(\agen\given\estn)$ can be derived as the probability of the chain not to transition to state $\mathsf d$ for \agen\ steps having started in \estn. This evaluates to $\sum\nolimits_{y\in\mathcal Y\setminus\{\mathsf d\}} q_{\estn y}(\agen) = q_{\estn 0}(\agen)  + q_{\estn 1}(\agen)$, where both addends are again obtained as elements of matrix $\mathbf A^{\agen}$.
\end{proof}
%where 
%\begin{align}
%    q_{\estn\mcn}(\agen) = \mathbf e_{\estn}^{\mathsf T} \,\mathbf P^{\agen} \,\mathbf e_{\mcn}.
%\end{align}
The result allows then to evaluate the performance at the receiver given the current conditions in terms of AoI and estimate, resorting to the definition in \eqref{eq:cond_ent}.
\begin{lemma}
    The receiver uncertainty on \Mcn, given \agen\ and \estn\ can be computed for any channel access strategy $\bm \lambda$ as
        \begin{align}
        \condent(\agen,\estn) = -\sum\nolimits_{\mcn} p(\mcn\given\agen,\estn) \log_2 p(\mcn\given\agen,\estn)
    \end{align}
    where $p(\mcn\given\agen,\estn)$ is obtained through \eqref{eq:pmfXnGivenDeltaXnHat}.
\end{lemma}

Let us now turn our attention to the derivation of the conditional entropy $\ent(\Mcn\given\Agen,\Estn)$ in \eqref{eq:ent_def}, which further requires the joint distribution of the current AoI and estimate available at the receiver at a general time slot $n$, i.e., $p(\agen,\estn) = p(\agen\given\estn) p(\estn)$. In the following, we streamline the steps for its computation through Prop. \ref{prop:condXn} and \ref{prop:statEst}. In turn, these results require a preliminary characterization of the inter-refresh time. Specifically, let us denote by \Irt\ the stochastic process describing the duration between two successive message receptions from the reference source, i.e., between two estimate updates at the sink. With this definition, we have:
\begin{prop}
Conditioned on the current estimate available at the receiver, the probability distribution of the process $W$ and its expected value are given by
\begin{align}
    p(\irt\given\estn) = \mathbf e_{\estn}^{\mathsf T} \mathbf A^{\irt-1} \, \mathbf a_{\mathsf d}
    \label{eq:condPMfW}
\end{align}
\begin{align}
    \mathbb E[\Irt \given \Estn=\estn] = \mathbf e_{\estn}^{\mathsf T} (\mathbf I_2 - \mathsf A)^{-1} \, \mathbf 1_2
    \label{eq:avgW}
\end{align}
where $\mathbf e_{\estn}$, $\estn\in\mathcal X$, is defined as in Prop.\ref{prop1}.
\end{prop}
\begin{proof}
    The results follows by observing that the distribution of \Irt, conditioned on the period being characterized by an estimate value $\hat{x}$ at the receiver, corresponds to the absorption time for the auxiliary chain in \figr\ref{fig:markovChains}b when starting from $\hat{x}$. Note indeed that, counting the steps to absorption starting from state $i\in\{0,1\}$ is equivalent to assuming reception of a message at time $0$ \--- stating that the reference source is in state $i$ \---, and thus starting a period over which the sink will keep $i$ as estimate. In turn, the distribution of the absorption time can be obtained using standard methods for Markov chains \cite{Kemeny76}, leading to the discrete phase-type distribution reported in \eqref{eq:condPMfW}, and the corresponding average absorption time in \eqref{eq:avgW}.        
\end{proof}

The proposition allows to derive the statistics of the current AoI value and the stationary distribution of the estimate.
\begin{prop}\label{prop:condXn}
    Conditioned on the estimate available at the receiver, the current AoI follows the probability distribution
    \begin{align}
        p(\agen\given\estn) = \frac{1}{\mathbf e_{\estn}^{\mathsf T} (\mathbf I_2 - \mathsf A)^{-1} \, \mathbf 1_2} \cdot \sum_{w>\agen} p(w\given \estn).
        \label{eq:condPMFAge_complete}
    \end{align}
    \begin{proof}
        For a generic time instant $n$, let us indicate as $\Irt(n)$ the duration of the estimate inter-refresh period $n$ falls into. The probability that $\Irt(n)$ lasts for $w$ slots follows as
        \begin{align}
        \mathsf P \!\left( \Irt(n)=\irt \given \Estn=\estn \right) = \frac{\irt \, p(\irt\given\estn)}{\sum\nolimits_\irt \irt \, p(\irt\given\estn)}
        \label{eq:condProbW}
        \end{align}
        capturing the fraction of time spent by the system in estimate inter-refresh periods of duration $\irt$. %Focus now on $p(\agen\given\estn)$, i.e., the probability of having an AoI value of \agen\ at a generic time instant $n$, conditioned on having at that time an estimate \estn. 
        Recalling the definition of \Irt, we observe that the AoI of the reference source is $0$ at the beginning of an inter-refresh period, and grows linearly over time, reaching the maximum value of $\Irt-1$ at the start of the last slot of the interval. Therefore, the probability for the receiver to have an AoI $\Agen=\agen$ at a generic time instant $n$ falling into an inter-refresh period of duration $\Irt(n)=\irt$ is simply $1/\irt$, $\forall$ $\agen\in\{0,\dots,\irt-1\}$. Leveraging this, the conditional PMF $p(\agen\given\estn)$ can be conveniently computed as
        \begin{align}
            \begin{split}
            \!\!\!\!\!p(\agen\given\estn) &\stackrel{(a)}{=} \sum\nolimits_{\irt > \agen} \frac{1}{\irt} \cdot \mathsf P\left(\Irt(n) = \irt \given \Estn=\estn\right)\!. %\\
                                %&\stackrel{(b)}{=} \sum_{\irt > \agen} \frac{p(\irt\given\estn)}{\mathbb E[\Irt \given \Estn=\estn]}.                        
            \end{split}
            \label{eq:condPMFAge}
        \end{align}
        Within \eqref{eq:condPMFAge}, $(a)$ follows from the law of total probability, observing that the AoI can reach a value $\agen$ only over an inter-refresh period of length at least $\agen+1$ slots, and using the uniform conditional probability for the AoI that was just derived. Plugging in \eqref{eq:condProbW} and recalling \eqref{eq:avgW} leads after simple steps to the proposition statement.
        %In turn, $(b)$ plugs into the expression the results in \eqref{eq:condProbW}. The proposition statement follows leaning on \eqref{eq:avgW}.                 
    \end{proof}
\end{prop}

\begin{prop}\label{prop:statEst}
    The stationary distribution of the receiver estimate for the reference source is given by    
    \begin{align}
        p(\estn) = \frac{\mathsf c_{\estn} \cdot \mathbb E[W \given \Estn=\estn]}{\mathsf c_{0} \cdot \mathbb E[W \given \Estn=0] + \mathsf c_{1} \cdot \mathbb E[W \given \Estn=1]}.
        \label{eq:pXn}
    \end{align}
    where 
    \begin{align}
        \mathsf c_0 = \frac{(\statZ (1-\qZO) \pTx_{00} + \statO \qOZ \pTx_{10})\ps}{\avgPTx \ps}, \quad  \mathsf c_1 = 1 - \mathsf c_0.
        \label{eq:c0}
    \end{align}
\end{prop}
\begin{proof}
    We start by observing that an inter-refresh period is characterized by having an estimate $\Estn=0$ with probability $\mathsf c_0$ reported in \eqref{eq:c0}. Here, the numerator captures the probability for the source to be in $0$ and to successfully deliver an update, i.e., $\statZ(1-\qZO)\pTx_{00}\ps$, or in $1$, transition to $0$ and inform the receiver, i.e., $\statO\qOZ\pTx_{10}\ps$. In turn, the denominator is a normalizing factor that accounts for the overall probability of delivering an update, i.e., initiating a new inter-refresh period. Similarly, the probability of having an inter-refresh interval with $\Estn=1$ is simply described by the auxiliary variable $\mathsf c_1 = 1-\mathsf c_0$. Leaning on this, the stationary distribution of $\Estn$ can be expressed as the fraction of time the receiver spends with such estimate value, obtaining the expression in \eqref{eq:pXn}.
\end{proof}

To conclude, the joint PMF $p(\agen,\estn)$ can be computed using \eqref{eq:condPMFAge_complete} and \eqref{eq:pXn}, eventually providing a complete analytical characterization of the conditional entropy $H(\Mcn\given\Agen,\Estn)$.

%To characterize this, we again resort to the auxiliary Markov process in \figr\ref{fig:abs_mc}, and  
%As a starting point, we observe that the chain can be used to capture the inter-refresh time of the estimate at the sink for the source of interest. Specifically, let us denote by \Irt\ the stochastic process describing the duration between two successive receptions of a message from the reference source, i.e., between two updates of the corresponding estimate at the sink. With this definition, the distribution of \Irt, conditioned on the period being characterized by an estimate value $\hat{x}$ at the receiver, is simply the absorption time for the chain when starting from $\hat{x}$.\footnote{Note indeed that counting the steps to absorption starting from state $i\in\{0,1\}$ is equivalent to assuming that at time $0$ a message is received, stating that the reference source is in such state, and thus starting a period over which the sink has an estimate $i$.} Accordingly, $p(\irt\given\estn)$ can be obtained using standard methods for Markov chains \cite{} as the discrete phase-type distribution
%\begin{align}
%    p(\irt\given\estn) = \mathbf e_{\estn}^{\mathsf T} \mathbf A^{\irt-1} \, \mathbf a_{\mathsf d}.
%\end{align}

