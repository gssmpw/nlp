\section{System Model}
\label{sec:sysModel}

We study a wireless network composed of \nodes\ terminals (nodes). Time is divided in slots, and each node monitors an independent discrete-time, two-state, Markov chain taking values in $\{0,1\}$. We denote by $\Mcni$, $n\in\mathbb N$, the chain observed by terminal $i$. 
%\begin{figure}
%    \centering
%    \includegraphics[width=.8\columnwidth]{./Figures/source_MC.pdf}
%    \caption{Discrete time Markov chain \mcn\ describing the evolution of one of the monitored sources.}
%    \label{fig:mc_source}
%\end{figure}
At the start of a slot, each process transitions between its states following the one-step probabilities reported in \figr\ref{fig:markovChains}a. For convenience, we introduce the \emph{asymmetry factor} $\asymm := \qZO/\qOZ$, capturing the ratio of the average time spent in state $1$ (i.e., $1/\qOZ$) with respect to state $0$ (i.e., $1/\qZO$). When $\asymm=1$, we speak of symmetric sources. The stationary distribution of the chain follows as $\statZ = \qOZ/(\qZO+\qOZ)$ and $\statO = 1-\statZ$.

Nodes share a wireless channel, and aim at reporting the state of the monitored sources to a common receiver (sink). Specifically, at the start of a slot, each terminal independently decides whether to transmit a packet, containing the current state of the Markov chain it observes. Accordingly, a slotted ALOHA protocol is implemented. No feedback is provided by the sink, and no retransmissions are performed by nodes. Following the well-established collision channel model \cite{Abramson77:PacketBroadcasting}, we assume that a slot over which two or more packets are sent (collision) does not allow retrieval of information at the sink, whereas successful decoding takes place whenever a single terminal transmits during a slot. 

In the remainder, we will focus on access schemes in which the transmission probability of a terminal is dictated by the previous and present state of the monitored process. We denote this quantity as $\pTx_{\mc_{n-1} \mcn}$, so that the access policy is fully specified by the vector $\pTxVec = [\pTx_{00},\pTx_{01},\pTx_{10},\pTx_{11}]$. We remark that, while $\pTxVec$ is the same for all nodes, the actual contention probability of each of them depends on the current evolution of its source. In view of this, the characterization of the number of terminals accessing the channel over a slot would require to jointly track all the Markov processes. Albeit conceptually viable, this approach soon becomes cumbersome as \nodes\ grows. We thus resort to an approximation, whose tightness is discussed in Sec.~\ref*{sec:results}, and model the success probability for a transmitted packet as
\begin{align}
    \ps := (1-\avgPTx)^{\nodes-1}
    \label{eq:ps}
\end{align}
where we have introduced the ancillary quantity \mbox{$\avgPTx := \statZ [ (1{-}\qZO) \pTx_{00} {+} \qZO \pTx_{01} ] + \statO [\qOZ \pTx_{10} {+} (1{-}\qOZ) \pTx_{11}]$}.
%\begin{align}
%    \avgPTx := \statZ [\, (1-\qZO) \pTx_{00} + \qZO \pTx_{01} \,] + \statO [\,\qOZ \pTx_{10} + (1-\qOZ) \pTx_{11}\,].
%\end{align}
In other words, we consider an i.i.d. behavior for all the $\nodes-1$ terminals other than the sender of interest, assuming that each of them transmits with probability \avgPTx. This, in turn, captures the average access probability for a node in stationary conditions. 


\begin{figure}    
    \subfloat[]{
        \includegraphics[width=.25\columnwidth]{./Figures/source_MC_vertical.pdf}}
    \hspace*{.1em}
    \subfloat[]{
        \includegraphics[width=.7\columnwidth]{./Figures/absorbing_MC.pdf}}
    \caption{(a) Markov chain \Mcn\ describing a monitored source; (b) terminating Markov chain $Y_n$ used to characterize $\ent(\Mcn\given\Agen,\Estn)$. The process enters the absorbing state $\mathsf d$ when an update from the reference node is received. Conversely, it moves between $0$ and $1$, describing the corresponding current source value, so long as no update message from the reference terminal arrives.}
    \label{fig:markovChains}
    \vspace{-1em}
\end{figure}

Within our system, the sink maintains an estimate $\Estn^{(i)}$ of the state of each monitored process. To this aim, we consider a simple solution, updating the estimate every time a message containing the current state of the source is received, and retaining the previous knowledge otherwise. Formally:
\begin{align}
    \!\!\!\!\Estn^{(i)} = 
    \begin{split}
    \begin{cases}
        \hspace*{.3em} \Mcni            \!\!\!& \text{ if node $i$ delivers message at slot $n$}\\[.3em]
        \hspace*{.3em} \Est_{n-1}^{(i)} \!\!\!& \text{ otherwise}
    \end{cases}
    \end{split}
    \label{eq:dh}
\end{align} 
with $\Estn^{(i)}\in\{0,1\}$. Without loss of generality, we will focus on the behavior of a reference source, and drop superscript $i$.
%\begin{remark}
%    \emph{We note that the presented approach requires no knowledge of network cardinality, employed access policy and source statistics. The estimator is only triggered upon successful decoding of a message, and can simply be run at the application layer, without the need for any other cross-layer information exchange (e.g., presence of a collided or idle slot). As such it may be of particular relevance for a large number of practical/already deployed IoT use cases.}
%\end{remark}
 
For the setting under study, we want to characterize the uncertainty of the sink on the state of the reference process. To this aim, we note that, at time $n$, a receiver implementing the estimator in \eqref{eq:dh} only has knowledge about (i) the last received update from the node of interest, i.e., \Estn, and (ii) the time elapsed since such message was retrieved. We denote the random process describing the latter as $\Agen \in \mathbb N_0$, and observe that \Agen\ corresponds the current AoI \cite{Yates20_Survey} at the sink. Indeed, each sent packet contains up to date information on the monitored source, %implementing a generate-at-will model, 
and $\Agen$ is exactly the difference between the current time and the time stamp of the last received message. We assume that, upon reception, \Agen\ is reset to $0$.

A natural measure of the sink uncertainty at time $n$, for a given AoI-estimate pair $(\agen,\estn)$, is thus given by the entropy
\begin{align}
    \mathsf h(\agen,\estn) := \ent( \Mcn \,|\, \Agen = \agen, \Estn = \estn).
    \label{eq:cond_ent}
\end{align}
An example of the time evolution of $\condent(\agen,\estn)$ is reported in \figr\ref{fig:timeline}. %In this case, $\nodes=50$ nodes were considered, implementing a transmission policy $\pTx_{\mc_{n-1} \mcn} = 1/ \nodes$, for any $(\mc_{n-1},\mcn)$ pair, and the source parameters were set as $\qZO=0.1$, $\qOZ=0.01$. 
The metric is reset to zero each time a message from the reference node is decoded. Instead, in the absence of updates, $\condent(\agen,\estn)$ tends to the stationary entropy of the source, $\mathsf H(X) = -\statZ \log_2 \statZ -\statO \log_2 \statO$. Finally, the peak shown in the plot denotes the higher uncertainty at the sink  experienced following reception of a message notifying of a source transition to the less likely state $0$. 

Leaning on this notation, we evaluate the average performance of the system in terms of the conditional entropy
\begin{align}
    \ent(\Mcn\,|\, \Agen,\Estn) = \sum_{\substack{\agen \in \mathbb N_0 \\ \estn \in \{0,1\} } } p(\agen,\estn)\, \condent(\agen,\estn).
    \label{eq:ent_def}
\end{align}
%with $\agen \in \mathbb N_0$, and $\estn \in \{0,1\}$.

\vspace{.5em}
\textbf{Remark.} \emph{The considered estimator is only updated upon successful decoding of a message from the source of interest, and can be run at the application layer, without the need for any other cross-layer information exchange (e.g., presence of a collided or idle slot). %As such it may be of particular relevance for a large number
    %of practical/already deployed IoT use cases.  
    In the remainder, we will provide a framework to understand, as protocol designers, how the medium contention shall be tuned  to minimize the average uncertainty $\ent(\Mcn\given \Agen,\Estn)$. On the other hand, as clarified in \secr\ref{sec:analysis}, knowledge of network cardinality, access parameters, and source statistics, allows an application to base control and decisions on its current uncertainty computed via \eqref{eq:cond_ent}.}
    %On the other hand, as clarified     in Sec. III, knowledge of network cardinality, access parameters, and source statistics suffice to compute (3), allowing an 
    %application with such knowledge to base control and decisions on its current uncertainty

    \begin{figure}
        \centering
        \includegraphics[width=.9\columnwidth]{./Figures/entropyTimeline_asymmetric.pdf}
        \caption{Example of time evolution of the entropy $\condent(\agen,\estn)$. In this case, $\qZO=0.1$, $\qOZ=0.01$, $\nodes=50$, $\pTx_{\mc_{n-1}\mcn} = 1/\nodes$, $\forall \, (\mc_{n-1},\mcn)$.}
        \vspace{-1em}
        \label{fig:timeline}
    \end{figure}