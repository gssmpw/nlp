\section*{Limitations}

\NewPara{Number of human experts:} We presented results from \totalevaluators experts (authors). The number wasn't larger due to cost and time constraints. While we found that the quality of feedback is high and believe that this number is reasonable, it could be larger for greater statistical significance. Our hit rate on responses to the email invitations was \hitresponse, so there may have been some bias in who responded and completed the evaluation. We will continue to obtain more expert evaluations, but given our constraints, it is unlikely to be larger than a few hundred experts. 

\NewPara{Variety of domains:} \name is designed to be domain-independent, but as of now, we have evaluated it only in the areas of CS and Aero. However, our development has had no domain-specific engineering, training, or prompting. 

\NewPara{PDF document constraints:} This paper PDF documents parsed with GROBID, excluding figures from question generation. While our system supports web-based documents and follows hyperlinks, this paper evaluates only PDFs.

%\NewPara{Preference expression by human experts.} A more robust evaluation method could involve pairwise expert preferences, where evaluators compare two questions—one from each method—across multiple trials. This may provide a stronger ranking mechanism than absolute scoring.

%A better approach to ranking questions by quality might have been to have the expert choose a preference between two questions, one from each method, and run such an evaluation over $n$ pairs of questions. 

\NewPara{Session-level evaluation:} We evaluate individual questions but not full quiz sessions. Assessing entire quizzes is critical for measuring concept coverage and learning outcomes but is challenging due to {\em evaluator fatigue}.

\NewPara{Incorporating human feedback:} \name currently does not use any human feedback for fine-tuning or reinforcement learning. Doing so could enhance its quality and potentially improve other methods like \Baseline, altering the relative performance results reported.

%\jc{We don't do any human feedback tuning to fine-tune/RLHF/etc. the model, which we should do for future work}

\NewPara{Question types:} This paper focuses on single-answer multiple-choice questions, though real-world tests use diverse formats, including multiple-correct-choice, true/false, fill-in-the-blank, and open-ended questions. Currently, \name generates high-quality conceptual questions (as shown by our results), but does not yet produce ones requiring logical or mathematical reasoning.

% \pk{@Hari, should we add option refinement here as well? }

%\kn{From ACL website: Authors are required to discuss the limitations of their work in a dedicated section titled “Limitations”. This section should be included at the end of the paper, before the references, and \textbf{it will not count toward the page limit.} This includes both, long and short papers. Papers without a limitations section will be \textbf{desk rejected.}}

\section*{Ethical Considerations}

Using LLMs to generate questions raises important ethical concerns regarding their responsible use in the training and education of people~\cite{MIT_law}. LLMs suffer from bias caused by their training data~\cite{bender2021dangers}, which can affect the quality and neutrality of the generated questions.

We conform to the ACL Code of Ethics~\cite{ACLCodeOfEthics}. Prior to our evaluation study, we obtained an IRB exemption. We have protected the privacy and anonymity of the evaluators by sharing only aggregate, anonymized statistics. The responses from our evaluators carry no risk of harm. Before participating, all evaluators reviewed a consent form and provided feedback through a secure platform (see~\autoref{subsec:appendix_human_eval_conduct} for details). We use the term ``expert'' to refer to an author of the evaluated documents, but this label does not imply any specific responsibilities or expectations on the evaluator. All evaluators took part voluntarily, without compensation.

We envision \name to help learners and educators by generating questions. It is not intended to replace human teachers. LLMs are prone to errors and hallucinations and may learn biased information from training data~\cite{MIT_law}. Therefore, an expert or educator needs to ensure that the questions and answers generated by \name are accurate and relevant to the material.  

Generating questions from research papers introduces potential concerns regarding intellectual property, copyright, and attribution. \name does not copy text directly from documents but synthesizes questions based on inferred key concepts. Users should acknowledge original sources when using \name, particularly in educational, research, and commercial settings.
