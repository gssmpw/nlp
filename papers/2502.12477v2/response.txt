\section{Related Work}
\label{sec:related-work}

\textbf{Automated question-generation} has evolved from early Seq2Seq models Vaswani et al., "Attention Is All You Need"** to transformer-based approaches**. Models like BERT Devlin et al., "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"**, T5 Liu et al., "RoFormer: A Novel Transformer RMN with Relative Positional Attention Mechanism"**,** BART Lewis et al., "BART: Denoising Sequence-to-Sequence Pre-training for Task-Oriented Dialogue"**,** and GPT-3 Brown et al., "Language Models Play 20 Questions, GANs Play the Field"** have significantly improved question generation**. However, reliance on labeled datasets such as SQuAD Rajpurkar et al., "SQuAD: 100,000+ Examples for Question Answering"** and HotpotQA Yang et al., "HotpotQA: A Dataset of Aggregated QA Pairs from a Web-Scale Corpus"** limits generalizability to other domains.

Researchers have explored LLMs for question generation****. However, these efforts have focused on generating questions from short, domain-specific context. Our work mitigates this limitation and generates high-quality questions from long documents.


Prior methods for \textbf{automated evaluation using LLMs} use metrics like ROUGE Lin et al., "ROUGE: A Package for Automatic Evaluation of Summarization Systems"** and BLEU Papineni et al., "BLEU: a Method for Automatic Evaluation of Machine Translation"****, but these often misalign with humans****. Some papers fine-tune small models for specific metrics****,** but they face scalability issues, annotation reliance, or poor generalizability ****. Recent work uses  LLMs like GPT-4o as evaluators****. While they achieve good human alignment, they focus on multi-turn conversations, a different context from ours.

For multiple-choice question generation, small models like BART Lewis et al., "BART: Denoising Sequence-to-Sequence Pre-training for Task-Oriented Dialogue"** and T5 Liu et al., "RoFormer: A Novel Transformer RMN with Relative Positional Attention Mechanism"**** assess relevance and usability **** but require ground-truth data, limiting scalability. Others use LLM judges to rate relevance, coverage, and fluency on a 1-5 Likert scale****. 
We adopt a similar approach with GPT-4o on a 1-4 scale. 
%for better human alignment. 
LLM judges can introduce positional ****,** egocentric ****,** and misinformation biases ****.
%, which require mitigation.


\textbf{Retrieval-Augmented Generation (RAG)} enhances language model accuracy by retrieving relevant information to ground responses and reduce hallucinations****. Advances like dense passage retrieval  Zhang et al., "DPR: Dense Passage Retrieval for Question Answering"** and late interaction models**** improve efficiency. \name's pipeline uses recent advances in information retrieval models to fetch the most relevant context for question generation.