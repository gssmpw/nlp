\subsection{Cost Analysis}
\label{appendix:scalability}

We define the \emph{cost} of the system as the total number of input and output tokens used to generate $N$ questions by $\text{Cost}(N)$, and we inspect how $\text{Cost}(N)$ grows as $N$ increases. \\


\NewPara{Cost when using the Entire Document}: Assume that in each question generation round, we use a \emph{question batch size} of $b$ -- i.e., LLM is prompted to generate $b$ questions. If the average number of input tokens is $D$ and the average number of output tokens per question is $q$, using the entire document to generate $N$ questions would result in {\small $\text{Cost}_{\text{Entire Document}}(N) = \frac{N}{b} D + N q$}. 
Note that this system has a running cost of processing the document proportional to $N$ (i.e., $\frac{N}{b} D$). \\


\NewPara{Cost when using a pre-processed text}: When using a preprocessed text This system has a fixed one-time cost for generating the summary denoted by $f(D)$. If the avg number tokens in the summary is denoted by $D_{s}$ and the batch size of $b_s$ is used, we have {\small $Cost_{\textit{Summary}}(N) = f(D) + \frac{N}{b_s} D_{s} + N q$}. Note that as $N$ grows, we have: 

\begin{small}
\begin{align}
    \lim_{N \rightarrow \infty} & \big( \text{Cost}_{\textit{Entire Document}}(N) 
    - \text{Cost}_{\textit{Summary}}(N) \big) \nonumber \\
    &= N \left(\frac{D}{b} - \frac{D_{s}}{b_s}\right)- f(D) \nonumber \\
    &= N \left(\frac{D}{b} - \frac{D_{s}}{b_s}\right) \nonumber \\
\label{eqn:scalability}
\end{align}
\end{small}

In words, if $\frac{D_{s}}{b_s} < \frac{D}{b}$, as the number of questions increases, the cost of the system using the entire document is much larger than the system using the summary -- the cost difference in \autoref{eqn:scalability} grows to infinity.
 
