[
  {
    "index": 0,
    "papers": [
      {
        "key": "thompson1933likelihood",
        "author": "Thompson, William R",
        "title": "On the likelihood that one unknown probability exceeds another in view of the evidence of two samples"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "Robbins1952SomeAO",
        "author": "Herbert E. Robbins",
        "title": "Some aspects of the sequential design of experiments"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "slivkins2019introduction",
        "author": "Aleksandrs Slivkins ",
        "title": "Introduction to Multi-Armed Bandits"
      },
      {
        "key": "Csa18",
        "author": "Tor Lattimore and Csaba Szepesv\\'ari",
        "title": "Bandit Algorithms"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "EvenDar2002PACBF",
        "author": "Even-Dar, Eyal and Mannor, Shie and Mansour, Yishay",
        "title": "{PAC} Bounds for Multi-armed Bandit and {M}arkov Decision Processes"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "bubeck2009pure",
        "author": "Bubeck, S{\\'e}bastien and Munos, R{\\'e}mi and Stoltz, Gilles",
        "title": "Pure exploration in multi-armed bandits problems"
      },
      {
        "key": "Audibert2010BestAI",
        "author": "Jean-Yves Audibert and S{\\'e}bastien Bubeck",
        "title": "Best Arm Identification in Multi-Armed Bandits"
      },
      {
        "key": "gabillon2012unified",
        "author": "Gabillon and Victor and Ghavamzadeh and Mohammad and Lazaric, Alessandro",
        "title": "{Best arm identification: A unified approach to fixed budget and fixed confidence}"
      },
      {
        "key": "karnin2013almost",
        "author": "Karnin, Zohar and Koren, Tomer and Somekh, Oren",
        "title": "Almost optimal exploration in multi-armed bandits"
      },
      {
        "key": "jamieson2014lil",
        "author": "Jamieson, Kevin and Malloy, Matthew and Nowak, Robert and Bubeck, S{\\'e}bastien",
        "title": "lil\u2019{UCB}: An optimal exploration algorithm for multi-armed bandits"
      },
      {
        "key": "kaufmann2016complexity",
        "author": "Kaufmann, Emilie and Capp{\\'e}, Olivier and Garivier, Aur{\\'e}lien",
        "title": "On the complexity of best-arm identification in multi-armed bandit models"
      },
      {
        "key": "garivier2016optimal",
        "author": "Garivier, Aur{\\'e}lien and Kaufmann, Emilie",
        "title": "Optimal best arm identification with fixed confidence"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "mannor2004sample",
        "author": "Mannor, Shie and Tsitsiklis, John N",
        "title": "The sample complexity of exploration in the multi-armed bandit problem"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "jamieson2014best",
        "author": "Jamieson, Kevin and Nowak, Robert",
        "title": "Best-arm identification algorithms for multi-armed bandits in the fixed confidence setting"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "yu2013sample",
        "author": "Yu, Jia Yuan and Nikolova, Evdokia",
        "title": "Sample Complexity of Risk-Averse Bandit-Arm Selection"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "tan2022survey",
        "author": "Tan, Vincent Y. F. and L.A., Prashanth and Jagannathan, Krishna",
        "title": "A Survey of Risk-Aware Multi-Armed Bandits"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "szorenyi2015qualitative",
        "author": "Szorenyi, Balazs and Busa-Fekete, Robert and Weng, Paul and H\u00fcllermeier, Eyke",
        "title": "Qualitative Multi-Armed Bandits: A Quantile-Based Approach"
      },
      {
        "key": "david2016pure",
        "author": "David, Yahel and Shimkin, Nahum",
        "title": "Pure exploration for max-quantile bandits"
      },
      {
        "key": "nikolakakis2021quantile",
        "author": "Nikolakakis, Konstantinos E and Kalogerias, Dionysios S and Sheffet, Or and Sarwate, Anand D",
        "title": "Quantile multi-armed bandits: Optimal best-arm identification and a differentially private scheme"
      },
      {
        "key": "howard2022sequential",
        "author": "Howard, Steven R and Ramdas, Aaditya",
        "title": "{Sequential estimation of quantiles with applications to A/B testing and best-arm identification}"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "nikolakakis2021quantile",
        "author": "Nikolakakis, Konstantinos E and Kalogerias, Dionysios S and Sheffet, Or and Sarwate, Anand D",
        "title": "Quantile multi-armed bandits: Optimal best-arm identification and a differentially private scheme"
      },
      {
        "key": "howard2022sequential",
        "author": "Howard, Steven R and Ramdas, Aaditya",
        "title": "{Sequential estimation of quantiles with applications to A/B testing and best-arm identification}"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "nikolakakis2021quantile",
        "author": "Nikolakakis, Konstantinos E and Kalogerias, Dionysios S and Sheffet, Or and Sarwate, Anand D",
        "title": "Quantile multi-armed bandits: Optimal best-arm identification and a differentially private scheme"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "nikolakakis2021quantile",
        "author": "Nikolakakis, Konstantinos E and Kalogerias, Dionysios S and Sheffet, Or and Sarwate, Anand D",
        "title": "Quantile multi-armed bandits: Optimal best-arm identification and a differentially private scheme"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "howard2022sequential",
        "author": "Howard, Steven R and Ramdas, Aaditya",
        "title": "{Sequential estimation of quantiles with applications to A/B testing and best-arm identification}"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "altschuler2019best",
        "author": "Altschuler, Jason and Brunel, Victor-Emmanuel and Malek, Alan",
        "title": "Best arm identification for contaminated bandits"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "nikolakakis2021quantile",
        "author": "Nikolakakis, Konstantinos E and Kalogerias, Dionysios S and Sheffet, Or and Sarwate, Anand D",
        "title": "Quantile multi-armed bandits: Optimal best-arm identification and a differentially private scheme"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "zhang2021quantile",
        "author": "Zhang, Mengyan and Ong, Cheng Soon",
        "title": "Quantile bandits for best arms identification"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "torossian2019mathcal",
        "author": "Torossian, L{\\'e}onard and Garivier, Aur{\\'e}lien and Picheny, Victor",
        "title": "$\\mathcal{X}$-Armed Bandits: Optimizing Quantiles, {CVaR} and Other Risks"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "amani2023distributed",
        "author": "Amani, Sanae and Lattimore, Tor and Gy\\\"{o}rgy, Andr\\'{a}s and Yang, Lin",
        "title": "Distributed Contextual Linear Bandits with Minimax Optimal Communication Cost"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "salgia2023distributed",
        "author": "Salgia, Sudeep and Zhao, Qing",
        "title": "Distributed Linear Bandits under Communication Constraints"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "vial2020one",
        "author": "Vial, Daniel and Shakkottai, Sanjay and Srikant, R",
        "title": "One-bit feedback is sufficient for upper confidence bound policies"
      },
      {
        "key": "hanna2022solving",
        "author": "Hanna, Osama A. and Yang, Lin and Fragouli, Christina",
        "title": "Solving Multi-Arm Bandit Using a Few Bits of Communication"
      },
      {
        "key": "mitra2023linear",
        "author": "Mitra, Aritra and Hassani, Hamed and Pappas, George J",
        "title": "Linear stochastic bandits over a bit-constrained channel"
      },
      {
        "key": "mayekar2023communication",
        "author": "Mayekar, Prathamesh and Scarlett, Jonathan and Tan, Vincent YF",
        "title": "{Communication-constrained bandits under additive Gaussian noise}"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "vial2020one",
        "author": "Vial, Daniel and Shakkottai, Sanjay and Srikant, R",
        "title": "One-bit feedback is sufficient for upper confidence bound policies"
      },
      {
        "key": "hanna2022solving",
        "author": "Hanna, Osama A. and Yang, Lin and Fragouli, Christina",
        "title": "Solving Multi-Arm Bandit Using a Few Bits of Communication"
      }
    ]
  },
  {
    "index": 22,
    "papers": [
      {
        "key": "hanna2022solving",
        "author": "Hanna, Osama A. and Yang, Lin and Fragouli, Christina",
        "title": "Solving Multi-Arm Bandit Using a Few Bits of Communication"
      }
    ]
  },
  {
    "index": 23,
    "papers": [
      {
        "key": "hillel2013distributed",
        "author": "Hillel, Eshcar and Karnin, Zohar and Koren, Tomer and Lempel, Ronny and Somekh, Oren",
        "title": "Distributed exploration in Multi-Armed Bandits"
      },
      {
        "key": "karnin2013almost",
        "author": "Karnin, Zohar and Koren, Tomer and Somekh, Oren",
        "title": "Almost optimal exploration in multi-armed bandits"
      },
      {
        "key": "tao2019collaborative",
        "author": "Tao, Chao and Zhang, Qin and Zhou, Yuan",
        "title": "Collaborative learning with limited interaction: Tight bounds for distributed exploration in multi-armed bandits"
      },
      {
        "key": "reda2022nearoptimal",
        "author": "Cl{\\'e}mence R{\\'e}da and Sattar Vakili and Emilie Kaufmann",
        "title": "Near-Optimal Collaborative Learning in Bandits"
      }
    ]
  }
]