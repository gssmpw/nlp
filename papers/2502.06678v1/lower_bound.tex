\section{Lower Bounds}
\label{sec: lower bound}

In this section, we provide two lower bounds on the number of arm pulls.  In Section~\ref{sec: lower bound unquantized}, we provide a near-matching worst-case lower bound 
$\Omega \big( \sum_{k\in\A} \Delta_k^{-2} \log(\delta^{-1})  \big)$
for instances with positive gap and $\epsilon$ is small enough such that $\A_{\epsilon}(\nu)= \{k^*\}$.
This lower bounds holds even in the absence of communication constraints.
 In Section~\ref{sec: log lambda epsilon dependence}, we address the $\log(\lambda/\epsilon)$ dependence in the upper bound by showing that $\Omega(\log(\lambda/\epsilon))$ arm pulls are needed for any $(\epsilon, \delta)$-reliable algorithm when 1-bit threshold queries are used; in particular, targeting $\epsilon = 0$ is infeasible without further assumptions.
 




\subsection{Lower Bound for the Unquantized Variant}
\label{sec: lower bound unquantized}
We present a worst-case lower bound on the expected number of arm pulls for the setup with no communication constraint.
The lower bound is based on a bad instance adapted from \cite[Theorem 4]{nikolakakis2021quantile}, which is for the quantile bandit problem of identifying the unique optimal arm $k^*$.
Specifically, for instances with satisfying arm set $\A_{\epsilon}(\nu) = \{k^*\}$,
the only correct output in both problem formulations is $k^*$.
By choosing $\epsilon$ to be sufficiently small, the hard instance in their problem formulation (which does not allow an $\epsilon$ relaxation) can be adapted to be a hard instance in our problem formulation.



\begin{theorem}[Worst-case lower bound]
\label{thm: lower bound unquantized}
Fix  $q, \delta \in (0, 1)$ and $\lambda \ge 1$.
There exists a quantile bandit instance~$\nu \in \cE$ with a unique best arm $k^*$ such that for any $\epsilon > 0$ satisfying
\begin{equation}
\label{eq: epsilon condition}
    \epsilon  \le
    \frac{1}{2} \big(Q_{k^*}(q) - \max \limits_{k \ne k^*} Q_k(q) \big)
\end{equation}
and any $(\epsilon, \delta)$-reliable algorithm,
 the number of arm pulls $\tau$ satisfies
\begin{equation}
\label{eq: lower bound unquantized}
\E[\tau]
\ge
\Omega \bigg(
\sum_{k=1}^K
 \frac{1}{\Delta_k^2}
    \log \left( \frac{1}{\delta} \right)
    \bigg),
\end{equation}
where $\Delta_{k}(\nu, \epsilon, q) \coloneqq \lim\limits_{c \to \infty} \Delta_{k}(\nu, \lambda, \epsilon, c, q)$ is the gap defined in Definition~\ref{def: our gap} with $c \to \infty$ (see~\eqref{eq: gap k infinite c} for the explicit form).
\end{theorem}

\begin{proof}
    See Appendix~\ref{sec: appendix unquantized lower bound}.
\end{proof}

The only difference in the upper bound~\eqref{eq: upper bound} and lower bound is that the lower bound only contains the log factor $\log(\delta^{-1})$ rather than the sum of three log factors, and so our upper bound matches the dependence on $\Delta_k$ of the lower bound to within a logarithmic factor.  We note that if $\delta \le \max(\Delta_k,\Delta)^{\Theta(1)}$ and $\delta \le \big( \frac{\epsilon}{c\lambda K} \big)^{\Theta(1)}$ then the sum of three log terms in \eqref{eq: upper bound} simplifies to $O\big( \log(\delta^{-1}) \big)$, so in this ``low error probability'' regime we in fact get matching scaling laws in the upper and lower bound.  


\subsection{$\Omega(\log(\lambda/\epsilon))$ Dependence Under Threshold Query Model}
\label{sec: log lambda epsilon dependence}
In this section, we show that $\Omega(\log(\lambda/\epsilon))$ arm pulls is needed for any $(\epsilon, \delta)$-reliable algorithm in the case that only threshold queries are allowed.
That is, the side information sent by the learner to the agent is always some threshold query of the form ``Is $r_{a_t, t} \le \gamma_t$?'', and the learner receives the 1-bit comparison feedback $\mathbf{1}(r_{a_t, t} \le \gamma_t)$.
This is a common 1-bit quantization method in practice and is also the one used in Algorithm~\ref{alg: main}, though it would also be of interest to determine whether using other 1-bit quantization methods can help.


\begin{theorem}[$\Omega(\log(\lambda/\epsilon))$ dependence]
\label{thm: log lambda/epsilon dependence}
Fix $\lambda \ge \epsilon > 0$, and $q \in (0, 1)$, and $\delta \in (0, 0.5)$.
Under the threshold query model, there exists a two-arm quantile bandit instance~$\nu$ with deterministic rewards such that any $(\epsilon, \delta)$-reliable algorithm requires $\Omega(\log(\lambda/ \epsilon))$ arm pulls.
\end{theorem}

\begin{proof}
    The idea is that if the two deterministic arms in $[0,\lambda]$ are separated by $2\epsilon$, then a binary search over $\Theta(\lambda/\epsilon)$ possible choices is needed just to locate them.  See Appendix~\ref{sec: appendix log lambda epsilon dependence} for the details.
\end{proof}

 While our upper and lower bounds match to within at most logarithmic factors under mild conditions, we leave it open as to 
(i)  whether the dependence on $\Delta_k$ can be improved in general (e.g., to doubly-logarithmic as in the ones in unquantized quantile BAI~\cite{nikolakakis2021quantile, howard2022sequential}, and (ii) whether there exist regimes in which the \emph{joint} dependence on the gaps and $(\lambda,\epsilon)$ can be improved.

