\section{Introduction}
The multi-armed bandit (MAB) is a well-studied decision-making framework due to its effectiveness in modelling a wide range of application domains such as online advertising, recommendation systems, clinical trials, and A/B testing.
Two common but distinct objectives in theoretical MAB studies are regret minimization and best arm identification (BAI), and this paper is focused on the latter. 
The goal of BAI is for the learner/decision-maker to efficiently identify the ``best'' arm (decision) from a set of arms, where the learning process occurs through ``pulling'' the arms and receiving some feedback about their rewards.

In the vanilla setting of BAI, the best arm is defined as the arm whose reward distribution has the highest mean, and the learner has access to direct observations of the rewards of the pulled arms. 
To tailor to certain practical applications, the best arm is sometimes defined using a different performance measure, and certain constraints are sometimes incorporated into the feedback/learning process.
Examples of this include (but are not limited to) the following:
\begin{itemize}[topsep=0pt, itemsep=0pt]
    \item[(i)] 
    in settings where the decision-making is risk-sensitive, using quantiles or value-at-risk as the performance measure may be more appropriate than using mean reward;

    \item[(ii)]
    in settings where the uplink communication from the sensor to the server (learner) is costly, the communication to the learner may be restricted, e.g., to send only a few bits rather than sending the exact reward.
\end{itemize}
In this paper, we consider a setup for BAI that features both of these aspects. Specifically, the communication to the learner is restricted to \textit{one bit} of feedback per arm pull, and the goal of the learner is to identify the arm with the highest $q$-quantile for some $q \in (0,1)$. The problem setup is described formally in Section~\ref{sec: setup}. The main contribution of this paper is an algorithm (Algorithm~\ref{alg: main}) for this problem whose upper bound on the sample complexity nearly matches the lower bound for the problem \textit{without} the communication constraint.  This complements an analogous study of highest mean BAI giving evidence that \emph{multiple bits per arm pull} need to be used \cite{hanna2022solving}, suggesting that the quantile-based objective may be easier to handle in highly quantized scenarios.  
The details of our results and contributions are given in Section~\ref{sec: contributions}. 
Before formally introducing the problem and stating our contributions, we outline some related work.


\input{related_work}

