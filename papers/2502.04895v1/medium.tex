\chapter{Medium Modeling via Generative Adversarial Networks} % Modeling PHY layer with Machine Learning techniques
\chaptermark{Medium Modeling with GANs}
%\thispagestyle{empty}
\label{sec:medium}
Channel modeling plays a crucial role in the development of reliable communication technologies. The performance of any communication system is strongly dependent on the physical and statistical properties of its communication medium. However, different infrastructures and application scenarios pose challenges such as extreme channel variability, including noise, interference, fading, and distortion, rendering the development of comprehensive mathematical bottom-up channel models impossible. 

In this chapter, we present a general purpose data-driven solution for modeling any communication medium. In particular, we use GANs to implicitly model the empirical channel statistical distribution obtained from real measurement campaigns. We propose a time-frequency strategy to model the noise and extend it to noise affecting multiple conductors. We also provide tips and tricks on how to properly train such complex NNs.

The results presented in this chapter are documented in \cite{RighiniLetizia2019,Letizia2019a}.


\section{Generative adversarial network based channel synthesis}
\sectionmark{GAN-based channel synthesis}
\label{sec:gan_ch_synthesis}
We define as synthetic channel model a phenomenological method that emulates the statistics of the communication channel. Such method does not include the medium physical knowledge to define the model but only the channel transfer functions (CTFs) distribution. Specifically, we shortly describe a tool that is able to generate synthetic data that follow the observed statistics, totally abstracting from the physical interpretation of the medium.

GANs (see Sec. \ref{sec:gans}) have already found some use and applications in communication theory for problems such as stochastic channel modeling and information encoding \cite{OsheaGAN} and for end-to-end system design where the channel effects on the input signals are modeled via conditional GANs \cite{Ye2018}. Nonetheless,
GANs have been mostly successfully applied on image synthesis. Images have two fundamental properties that make them suitable for GAN implementation: 
\begin{itemize}
\item CNNs enable an ad hoc learning scheme, reducing overfitting and mode-collapsing problems;
\item A qualitative assessment based on samples could be in principle enough since visual examination of samples by humans is one of the most common and intuitive ways to evaluate GANs.
\end{itemize} 
Less work has been carried out when generating structured non-images data. Indeed, problems like global convergence of the training and modeling high-dimensional complex distributions are still open questions. 
Among these problems, mode collapse is perhaps the most critical one. This is a well know issue of GAN architectures and it is characterized by a partial sampling of the data distribution. MGANs \cite{MGAN} are
a possible architecture to reduce the probability to run into this problem employing multiple generators instead of using a single one as in the original GAN (see Fig. \ref{fig:medium_MGAN}).

\begin{figure}[t]
  \centering
	\includegraphics[scale=0.3]{images/medium/MGAN.pdf}
	\caption{MGAN architecture to generate the new channel latent realizations.}
	\label{fig:medium_MGAN}
\end{figure}%

Complex channels such as the optical fiber or the power line ones demand precise characterization over different frequency bands, making vanilla GANs practically unusable for training synthetic models. In fact, CTFs are realizations of high-dimensional random processes for which no ad hoc architectures have been developed.

We thus propose a more general approach for generating synthetic channels, based on feature characterization and generation.

Let $\mathbf{x} \sim \mathcal{D}$ be the input data which we would like to learn the statistics $p_{X}(\mathbf{x})$. If an a-priori knowledge of the complexity of the distribution $p_{X}(\mathbf{x})$ is provided, the idea is to target a lower-dimensional distribution $p_{Z}(\mathbf{z})$. Suppose there exists a function $F: X\to Z$ which maps $\mathbf{x}$ into $\mathbf{z}$, then a deterministic relation between the two distributions exists, so that with the change of variable rule we obtain $p_{X}$ from $p_{Z}$ as follows
\begin{equation}
p_{X}(\mathbf{x}) = p_{Z}(F(\mathbf{x}))\cdot \biggl| \det \frac{\partial F(\mathbf{x})}{\partial \mathbf{x}}\biggr|.
\label{eq:medium_NICE}
\end{equation}
We propose to model only the distribution $p_{Z}(\mathbf{z})$ of the features $\mathbf{z}$ by identifying the transform function $F(\cdot)$ as the encoder block of an already trained AE (e.g. a probabilistic VAE). Then, after generating new features $\mathbf{z}_g$ with MGANs, the decoder block $G(\cdot)$ takes $\mathbf{z}_g$ as input and produces new samples $\mathbf{x}_g$. 
We forced the features space to be energy-constrained. To keep trace of this limit, a good approach is to add a regularization term in the cost function. In detail, the proposed cost function for the AE training is
\begin{equation}
\label{PowerAE}
\mathcal{L}_{\text{AE}} = \mathbb{E}_{\mathbf{x}\sim \mathcal{D}}[\delta(\mathbf{x},G(F(\mathbf{x})))+\lambda | \mathbf{A}\cdot F(\mathbf{x})+\mathbf{b}|^2_2],
\end{equation}
where $\delta$ is the cross entropy, $\mathbf{A}$ and $\mathbf{b}$ are constant parameters of a linear transformation, a weight matrix and a bias vector, respectively. A comparison between real and generated latent samples is offered in Fig. \ref{fig:medium_Features}. Architectural details are reported in Tab. \ref{tab:autoencoder_nn} and \ref{tab:gan_nn}.

\begin{figure}
  \centering
	\includegraphics[scale=0.6]{images/medium/PDF_features3_crop.pdf}
	\caption{Cumulative 1D-PDF of the extracted features from the AE and of the generated ones using MGANs.}
	\label{fig:medium_Features}
\end{figure}

\begin{table}
	\scriptsize % text dimension
	\centering
	\caption{AE architecture for channel feature generation.}
	\begin{tabular}{ p{5cm}|p{3cm}|p{3cm}} 
		\toprule
		Operation & Feature maps  		& Activation  \\
		\midrule
		\textbf{Encoder} & &\\
		Fully connected & 100 & eLU \\ 
		Dropout &0.5&  \\ 
		Fully connected &80& ReLU  \\ 
		Dropout &0.5&  \\ 
		Fully connected & 50 & ReLU  \\  \hline
		\textbf{Features} & &\\
		Fully connected & 25 & ReLU \\  \hline
		\textbf{Decoder} & 50	&   \\
		Dropout &0.5&   \\
		Fully connected & 80 & ReLU  \\  
		Dropout &0.5&   \\
		Fully connected & 100 & Tanh  \\ \hline
		Batch size &  \multicolumn{2}{c}{128}  \\ 
		Number of iterations &  \multicolumn{2}{c}{100000}  \\ 
		Learning rate &  \multicolumn{2}{c}{0.0002}   \\ 
		Regularization constant &  \multicolumn{2}{c}{$\lambda$ = 0.0002}  \\ 
		Optimizer &  \multicolumn{2}{c}{Adam ($\beta_1$ = 0.9, $\beta_2$ = 0.999)}  \\
		Weight matrix &  \multicolumn{2}{c}{$\mathbf{A}=\mathbb{I}$} \\
		Bias vector &  \multicolumn{2}{c}{$\mathbf{b}$ = -0.5} \\ \hline
		%\bottomrule	
	\end{tabular}
	
	\label{tab:autoencoder_nn}
	%\noindent\makebox[\linewidth]{\rule{0.85\paperwidth}{0.4pt}} %linea
\end{table}

\begin{table}
	\scriptsize % text dimension
	\centering
	\caption{MGAN architecture.}
	\begin{tabular}{ p{3cm}|p{1.5cm}|p{1.5cm}} 
		\toprule
		Operation & Feature maps  		& Activation  \\
		\midrule
		\textbf{Generators} & &  \\ 
		$G(\mathbf{y}):\mathbf{y} \sim \mathcal{U}(-1,1)$ & 16\\ 
		Dropout &0.5& \\ 
		Fully connected &32& ReLU \\ 
		Dropout &0.5&  \\ 
		Fully connected &45& ReLU \\ 
		Dropout &0.5&  \\ 
		Fully connected & 60 & ReLU \\  \hline
		\textbf{Common Generator $G_0$} & &  \\ 
		Fully connected & 70 & ReLU \\ 
		Fully connected & 30 & ReLU \\ 
		Fully connected & 25 & Sigmoid \\  \hline
		\textbf{Common Discriminator $D_0$} &&   \\ 
		Fully connected & 25 & Leaky ReLU  \\
		Dropout &0.5& \\
		Fully connected & 18 & Leaky ReLU \\  
		Dropout &0.5&  \\
		Fully connected & 16 & Leaky ReLU \\  \hline
		\textbf{Classifier} & &\\ 
		Fully connected & 3 & Softmax \\  \hline
		\textbf{Discriminator} & &  \\ 
		Fully connected & 1 & Sigmoid \\ \hline
		Number of generators & \multicolumn{2}{c}{3} \\
		Batch size & \multicolumn{2}{c}{128} \\
		Number of iterations & \multicolumn{2}{c}{150000} \\ 
		Leaky ReLU slope &  \multicolumn{2}{c}{0.2} \\ 
		Learning rate &  \multicolumn{2}{c}{0.0002}  \\ 
		Regularization constant &  \multicolumn{2}{c}{$\beta$ = 0.5} \\ 
		Optimizer &  \multicolumn{2}{c}{Adam ($\beta_1$ = 0.5, $\beta_2$ = 0.9999)}  \\ \hline
		%\bottomrule	
	\end{tabular}
	
	\label{tab:gan_nn}
\end{table}

To verify the goodness of the proposed methodology (schematically described in Algorithm \ref{AE&GAN}), consolidated metrics for real and generated data are compared in Ch. \ref{sec:plc}.

\begin{algorithm}[b]
\caption{AE \& GAN}\label{AE&GAN}
\begin{algorithmic}[1]
\BState Training VAE with input/output $\mathbf{x}$
\State \hspace{3mm}$\mathbf{z} \gets \text{encoder}(\mathbf{x})$
\State \hspace{3mm}Save decoder block
\BState Training MGAN with the original features $\mathbf{z}$ 
\State \hspace{3mm}Sample uniform $\mathbf{y}\sim \mathcal{U}(-1,1)$
\State \hspace{3mm}$\mathbf{z}_g \gets \text{generator}(\mathbf{y})$
\BState $\mathbf{x}_g \gets \text{decoder}(\mathbf{z}_g)$
\end{algorithmic}
\end{algorithm}

Notice that the proposed strategy is extremely similar with the most recent and successful text-to-image architectures such as the latent diffusion model Stable Diffusion \cite{SD2021}. In fact, instead of working directly in the complicated pixel domain, it is convenient to compresses the image $\mathbf{x}$ into a significantly smaller latent variable $\mathbf{z}$, rendering in this way the model faster and more efficient.

\section{Spectrograms generation for noise modeling}
\sectionmark{GAN-based noise synthesis}
\label{sec:medium_channelsynthesis}
Modeling and reproducing noise patterns play an important role in the development of enhanced communication algorithms. 
ML techniques can also be exploited to model complex noise distributions and synthetically reproduce unseen traces. 
Traditional methods, however, do not provide an ensemble characterization of the noise and its
time-variant nature, resulting in difficult parametrization. 
To overcome these limitations, a top-down modeling approach that exclusively depends on the measurements can be followed. Inspired by the SpecGAN method illustrated
in \cite{donahue2018adversarial}, we propose a versatile approach to generate noise in communications, which will be denoted also as synthetic noise. 

The core idea consists of transforming noise measurements into spectrograms which are used to train a DCGAN to generate new spectrograms with the same statistical distribution. Then, the Griffin-Lim algorithm \cite{GriffinLim} converts the synthesized spectrograms into new noise traces.

The scalability of the approach we illustrate in the following allows to incorporate the mutual dependence of multi-conductor noise traces and replicate them.
Finally, the presented method is evaluated through qualitative and quantitative metrics on power line noise measurements: the generated noise traces are perceived indistinguishable from the measured ones, and at the same time, their statistical properties are preserved as proven by the numerical results discussed in Ch. \ref{sec:plc}. 

\subsection{Spectrogram representation}
Time-variant signals are often represented through spectrograms. When dealing with the Fourier transform, time localization gets lost, therefore transforms such as the Short Time Fourier Transform (STFT) or wavelet transform can incorporate information about time localization, at expenses of a less precise frequency localization. The magnitude squared of the STFT is defined as the spectrogram and it gives information on how energy varies over time and frequency.
To analyze and generate noise traces, we divided the measured noise into several traces of length $N$ samples and for each vector we found its spectrogram representation. In particular, let $x(n)$ and $X_w(m,f)$ be the noise sequence and its STFT, respectively. Let $w(n)$ be the analysis window of length $L$, then from the definition of STFT
\begin{equation}
X_w(m,f)=\mathcal{F}[x_w(m,n)]=\sum_{n=0}^{N-1}{x_w(m,n)e^{-j2\pi f n}}
\end{equation}
with
\begin{equation}
x_w(m,n) = w(n-mH)\cdot x(n),
\end{equation}
the spectrogram has expression
\begin{equation}
S(m,f) = |X_w(m,f)|^2,
\end{equation}
where $m$ represents the index for the frame in time, $H$ the stride, and $f$ represents the index for the frequency bin. 

\begin{figure}
	\centering
	\includegraphics[scale=0.35]{images/medium/SpectrogramsMulti_noise_plc_graph_4.pdf}
	\caption{Block-spectrogram of randomly picked  multi-conductor generated (synthetic) and measured (real) noise traces.}
	\label{fig:medium_Block-Spectrogram}
\end{figure}


\subsection{DCGAN}
The statistics of the noise, i.e. spatial and time dependence, resides in the collected dataset. However, the spectrogram $S(m,f)$ offers a visual representation of the measured noise, consequentially  the statistical information is nicely transferred into images. In order to generate new noise with the same distribution of the observed one, new spectrograms $\hat{S}(m,f)$ need to be synthesized. For such purpose, 
we use the DCGAN architecture for image generation \cite{Radford2016}.

\subsection{Griffin-Lim algorithm}
The spectrogram offers an immediate visual representation of time-variant signals. Nevertheless, it only carries magnitude information losing the phase information of the original signal. Therefore, it is not possible to perfectly reconstruct the original samples $x(n)$ from the spectrogram $S(m,f)$ without using phase information. A way to approximate $x(n)$ is the Griffin-Lim algorithm (LSEE-MSTFT) proposed in \cite{GriffinLim}. The idea of LSEE-MSTFT is to iteratively build an estimate of $x(n)$ whose spectrogram converges (in norm $l_2$) to the given one $S(m,f)$. To do so, starting from an initial estimate $x^0(n)$, at each $i$-th step the STFT of the estimation has expression
\begin{equation}
\hat{X}_w^i(m,f)=\sqrt{S(m,f)}\cdot e^{j\angle X_w^i(m,f)}
\end{equation}
and the next estimate $x^{i+1}(n)$ reads as follows
\begin{equation}
x^{i+1}(n)=\frac{\sum_{m=0}^{L-1}{w(n-mH)\cdot \hat{x}_w^i(m,n)}}{\sum_{m=0}^{L-1}{w^2(n-mH)}}.
\end{equation}
By proceeding in such way, $x^{i+1}(n)$ converges to a discrete-time real signal whose spectrogram is $S(m,f)$. When the LSEE-MSTFT algorithm receives as input the generated spectrograms $\hat{S}(m,f)$, it outputs a vector $\hat{x}(n)=x^{i+1}(n)$ corresponding to a generated noise measurement.

\begin{algorithm}
	\caption{Generation of Multi-Conductor Noise}
	\label{alg:noise_gen}
	\begin{algorithmic}[1]
		\Inputs{$p$ multi-conductor noise measurements of $M$ conductors;}
		\Initialize{Parameters for the STFT, DCGAN, LSEE-MSTFT algorithm.}
		\For{$i=1$ to $p$}
		\For{$j=1$ to $M$}
		\State Compute the spectrogram $S_j^{(i)}(m,f)$;
		\EndFor

		\State Create the block-spectrogram $BS^{(i)}(m,f)$;
		\EndFor
		\State Train the DCGAN with the block-spectrogram dataset;
		\State Generate a set of $k$ new block-spectrograms $\hat{BS}(m,f)$;
		\For{$i=1$ to $k$}
		\State Extract the single generated spectrograms $\hat{S}_j^{(i)}(m,f)$;
		\For{$j=1$ to $M$}
		\State Generate the multi-conductor noise vector $\hat{x}^{(i)}_j(n)$ 
		\State using the LSEE-MSTFT algorithm;
		\EndFor
		\EndFor
	\end{algorithmic}
\end{algorithm}

\subsection{Multi-conductor noise generation}
Herein, we extend the methodology presented in the previous paragraph to learn and synthesize the multiple conductor noise statistics.

Let $x_j(n)$ be the synchronized noise measurements collected for $M$ conductors with $j=1,\dots,M$, and let $S_j(m,f)$ be the respective spectrogram. An interesting approach to generate the cross-statistical dependence between the noise in multi-conductors is to concatenate the $M$ spectrograms into a block-spectrogram image $BS(m,f)$, which contains the mutual time-frequency information. To generate new multi-conductor noise measurements, it is enough to generate new block-spectrogram images $\hat{BS}(m,f)$, using for example the DCGAN architecture when $M$ is small, or the Progressive and StyleGANs \cite{karras2018progressive, Karras2019} to deal with higher dimensions in number of samples and number of conductors. Each generated spectrogram $\hat{S}_j(m,f)$ inside $\hat{BS}(m,f)$ takes into account its own statistics but also the cross-statistics, thus the mutual dependence with the other spectrograms. The LSEE-MSTFT algorithm applied for each $\hat{S}_j(m,f)$ returns $M$ generated noise vectors $\hat{x}_j(n)$ with the desired statistics.
The steps aforementioned are summarized in the Alg.~\ref{alg:noise_gen} for multi-conductor noise generation. 

\subsection{Parameter details}
We consider and generate sequences of noise vectors (see Ch. \ref{sec:plc}) of length $N=1024$ samples, corresponding to $1.024$ ms of data when sampled at $f_s=1$ MHz. 
To compute the STFT we filtered the discrete-time signal $x(n)$ with the Blackman-Harris window $w(n)$ of length $L=65$. We choose a stride (hop) $H$ of $15$, resulting in around $75\%$ frame overlap, with $64$ frames and $65$ frequency bins, according to the formulas
\begin{align*}
\text{freq. bins} &= L \nonumber \\
\text{frames} &= 1+\left\lfloor\frac{N-L}{H}\right \rfloor 
\end{align*}
where $\lfloor \cdot \rfloor$ denotes the floor function. We trim the top Nyquist frequency from each STFT $X_w(m,f)$ in order to deal with spectrograms $S(m,f)$ of square dimension $64\times 64$. We replace the Nyquist bin during resynthesis with the mean of the dataset.
After taking the base $10$ logarithm of the spectrogram $S(m,f)$ to better align with human perception, we scaled it to be between $-1$ and $1$ to match the $\text{tanh}$ output non-linearity of the generator network and we kept trace of the de-normalization parameters.
Once the noise dataset has been converted into its image representation, we generated new spectrograms using the DCGAN. The training details for the DCGAN model are reported in Tab.~\ref{tab:DCGAN_parameters}. 
We stopped the training procedure when the statistical metrics of the generated noise, obtained with LSEE-MSTFT, were significative. The number of iteration steps in the estimation process of the LSEE-MSTFT was set to $16$.

We implemented the multi-conductor generation approach in the case of noise measured in $2$ conductors. For each synchronized noise trace the respective spectrogram was built and placed together in the block-spectrogram image of dimension $64\times 128$. We exploited the same DCGAN architecture with the only exception of a first layer with $4096\times 2$ neurons and the first feature maps of dimension $(8,8\times 2,64)$.

\begin{table}
	\centering
	\caption{DCGAN architecture for spectrogram generation.}
	\begin{tabular}{ p{5cm}|p{3cm}|p{3cm}} 
		\toprule
		Operation & Feature maps  		& Activation  \\
		\midrule
		\textbf{Generator $G$} &&   \\ 
		$G(\mathbf{y}):\mathbf{y} \sim \mathcal{U}(-1,1)$ & 100\\ 
		Fully connected & $4096$ & ReLU \\ 
		Reshape and upsampling & $(8,8,64)$ &  \\ 
		Convolution and BatchNorm & $64$ & ReLU \\ 
		Upsampling & &  \\ 
		Convolution and BatchNorm & $32$ & ReLU \\ 
		Upsampling & &  \\ 
		Convolution and BatchNorm & $16$ & ReLU \\ 
		Convolution & $3$ & Tanh \\  \hline
		
		\textbf{Discriminator $D$} & &  \\ 
		$D(\mathbf{x}):\mathbf{x} \sim p_x(\mathbf{x})$ & $(64,64,1)$ \\ 
		Convolution & $32$ & LeakyReLU \\ 
		Dropout & $0.25$ &  \\ 
		Convolution and BatchNorm & $64$ & LeakyReLU \\ 
		Dropout & $0.25$ &  \\ 
		Convolution and BatchNorm & $128$ & LeakyReLU \\ 
		Dropout & $0.25$ &  \\ 
		Convolution and BatchNorm & $256$ & LeakyReLU \\ 
		Dropout & $0.25$ &  \\ 
		Flatten and dense & $1$ & Sigmoid \\   \hline
		
		Batch size & \multicolumn{2}{c}{32} \\
		Number of iterations & \multicolumn{2}{c}{50000} \\ 
		Leaky ReLU slope &  \multicolumn{2}{c}{0.2} \\ 
		Learning rate &  \multicolumn{2}{c}{0.0002}  \\ 
		Optimizer &  \multicolumn{2}{c}{Adam ($\beta_1$ = 0.5, $\beta_2$ = 0.9999)}  \\ \hline
		%\bottomrule	
	\end{tabular}
	\label{tab:DCGAN_parameters}
\end{table}

\section{Further ideas and summary}
\sectionmark{StyleGAN-based medium synthesis}
\label{sec:stylegan_synthesis}
In principle, as we proposed to translate the set of measured channels into images, it is possible to adopt the StyleGAN architecture \cite{Karras2019} to significantly improve the channel generation process. Indeed, any CTF can be represented via a time-frequency decomposition: static channels will possess the same values across time, thus images divided into horizontal stripes. Time-variant channels, instead, are easily mapped into images where vertical portions represent a specific spectrum for a given time window (see Fig. \ref{fig:medium_timeinv} and \ref{fig:medium_timevar}).

\begin{figure}[t]
  \centering
	\includegraphics[scale=0.45]{images/medium/medium_timeinv.pdf}
 	\caption{Time-invariant transformation}
	\label{fig:medium_timeinv}
\end{figure}%
\begin{figure}[t]
  \centering
	\includegraphics[scale=0.45]{images/medium/medium_timevar.pdf}
 	\caption{Time-variant transformation}
	\label{fig:medium_timevar}
\end{figure}%

This chapter has proposed a methodology to model and generate the channel and noise in communication systems via DL techniques. The methodology has been segmented in three phases: a) a pre-processing part where the collected channel or noise traces are represented either as latent features or as in the time-frequency domain as spectrograms, respectively; b) a second generative phase in which GANs produce either new latent features or spectrograms with the same statistics of the original ones; c) a third last phase where either the generated features are decoded into channel samples or the spectrograms are converted to time-domain noise traces using the Griffin-Lim algorithm. 
The generation of multi-conductor noise has been presented as an extension of the single-conductor one using the concept of block-spectrogram, which takes into account the noise spatial cross-dependence.

