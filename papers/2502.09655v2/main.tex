%% LyX 2.3.0 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[english]{article}
\usepackage[T1]{fontenc}
\usepackage[latin9]{inputenc}
\usepackage{babel}
\usepackage{array}
\usepackage{float}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{cancel}
\usepackage{graphicx}
\PassOptionsToPackage{normalem}{ulem}
\usepackage{ulem}
\usepackage[unicode=true]
 {hyperref}

\makeatletter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LyX specific LaTeX commands.
%% Because html converters don't know tabularnewline
\providecommand{\tabularnewline}{\\}
\floatstyle{ruled}
\newfloat{algorithm}{tbp}{loa}
\providecommand{\algorithmname}{Algorithm}
\floatname{algorithm}{\protect\algorithmname}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% User specified LaTeX commands.
\PassOptionsToPackage{numbers, compress}{natbib}

\usepackage[preprint]{neurips_2024}

\PassOptionsToPackage{numbers, compress}{natbib}

\usepackage[unicode=true]{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor} 

\usepackage{microtype}
\usepackage{graphicx}
%\usepackage{subfigure}
\usepackage{mathtools}

\usepackage{xcolor}
\usepackage{soul}
\newcommand{\mathcolorbox}[2]{\colorbox{#1}{$\displaystyle #2$}}

\definecolor{red}{HTML}{FF0000}
\definecolor{lawngreen}{HTML}{7CFC00}
\definecolor{orange}{HTML}{FFA500}
\definecolor{peru}{HTML}{CD853F}
\definecolor{gray}{HTML}{808080}
\definecolor{lightgray}{RGB}{240,240,240}

\usepackage{algpseudocode}

\@ifundefined{showcaptionsetup}{}{%
 \PassOptionsToPackage{caption=false}{subfig}}
\usepackage{subfig}
\makeatother

\begin{document}
\renewcommand{\contentsname}{Table of Content for Appendix}

\title{Bidirectional Diffusion Bridge Models}

\author{\textbf{Duc Kieu, Kien Do, Toan Nguyen, Dang Nguyen, Thin Nguyen}\\
Applied Artificial Intelligence Institute (A2I2), Deakin University,
Australia\\
\emph{\{v.kieu, k.do, k.nguyen, d.nguyen, thin.nguyen\}@deakin.edu.au}}

\maketitle
\global\long\def\Expect{\mathbb{E}}
\global\long\def\Real{\mathbb{R}}
\global\long\def\Data{\mathcal{D}}
\global\long\def\Loss{\mathcal{L}}
\global\long\def\Normal{\mathcal{N}}
\global\long\def\softmax{\text{softmax}}
\global\long\def\ELBO{\text{ELBO}}
\global\long\def\argmin#1{\underset{#1}{\text{argmin}}}
\global\long\def\argmax#1{\underset{#1}{\text{argmax}}}
\global\long\def\diag{\text{diag}}

\begin{abstract}
\input{abstract.tex}
\end{abstract}
\addtocontents{toc}{\protect\setcounter{tocdepth}{-1}}

\section{Introduction}

\input{intro.tex}

\section{Preliminaries\label{sec:Preliminaries}}

\input{prelim.tex}

\section{Method}

\input{method.tex}

\section{Experiments}

\input{exp.tex}

\section{Related Work}

\input{relate.tex}

\section{Conclusion}

\input{discuss.tex}

\clearpage{}

\bibliographystyle{plain}
%\bibliography{reference}

\begin{thebibliography}{10}

\bibitem{albergo2023stochastic}
Michael~S Albergo, Nicholas~M Boffi, and Eric Vanden-Eijnden.
\newblock Stochastic interpolants: A unifying framework for flows and
  diffusions.
\newblock {\em arXiv preprint arXiv:2303.08797}, 2023.

\bibitem{batzolis2021conditional}
Georgios Batzolis, Jan Stanczuk, Carola-Bibiane Sch{\"o}nlieb, and Christian
  Etmann.
\newblock Conditional image generation with score-based diffusion models.
\newblock {\em arXiv preprint arXiv:2111.13606}, 2021.

\bibitem{bishop2006pattern}
C~Bishop.
\newblock Pattern recognition and machine learning.
\newblock {\em Springer google schola}, 2:531--537, 2006.

\bibitem{bortoli2021diffusion}
Valentin~De Bortoli, James Thornton, Jeremy Heng, and Arnaud Doucet.
\newblock Diffusion schr{\"{o}}dinger bridge with applications to score-based
  generative modeling.
\newblock In {\em {NeurIPS}}, pages 17695--17709, 2021.

\bibitem{chen2022likelihood}
Tianrong Chen, Guan{-}Horng Liu, and Evangelos~A. Theodorou.
\newblock Likelihood training of schr{\"{o}}dinger bridge using
  forward-backward sdes theory.
\newblock In {\em {ICLR}}, 2022.

\bibitem{choi2021ilvr}
Jooyoung Choi, Sungwon Kim, Yonghyun Jeong, Youngjune Gwon, and Sungroh Yoon.
\newblock {ILVR:} conditioning method for denoising diffusion probabilistic
  models.
\newblock In {\em {ICCV}}, pages 14347--14356, 2021.

\bibitem{dhariwal2021diffusion}
Prafulla Dhariwal and Alexander Nichol.
\newblock Diffusion models beat gans on image synthesis.
\newblock {\em {NeurIPS}}, 34:8780--8794, 2021.

\bibitem{do2024variational}
Kien Do, Duc Kieu, Toan Nguyen, Dang Nguyen, Hung Le, Dung Nguyen, and Thin
  Nguyen.
\newblock Variational flow models: Flowing in your style.
\newblock {\em arXiv preprint arXiv:2402.02977}, 2024.

\bibitem{doob1984classical}
Joseph~L Doob and JI~Doob.
\newblock {\em Classical potential theory and its probabilistic counterpart},
  volume 262.
\newblock Springer, 1984.

\bibitem{fortet1940resolution}
Robert Fortet.
\newblock R{\'e}solution d'un syst{\`e}me d'{\'e}quations de m.
  schr{\"o}dinger.
\newblock {\em Journal de Math{\'e}matiques Pures et Appliqu{\'e}es},
  19(1-4):83--105, 1940.

\bibitem{goodfellow2014generative}
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley,
  Sherjil Ozair, Aaron Courville, and Yoshua Bengio.
\newblock Generative adversarial nets.
\newblock {\em {NIPS}}, 27:2672--2680, 2014.

\bibitem{heusel2017gans}
Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp
  Hochreiter.
\newblock Gans trained by a two time-scale update rule converge to a local nash
  equilibrium.
\newblock {\em {NIPS}}, 30:6626--6637, 2017.

\bibitem{ho2020denoising}
Jonathan Ho, Ajay Jain, and Pieter Abbeel.
\newblock Denoising diffusion probabilistic models.
\newblock {\em {NeurIPS}}, 33:6840--6851, 2020.

\bibitem{ho2021classifier}
Jonathan Ho and Tim Salimans.
\newblock Classifier-free diffusion guidance.
\newblock In {\em NeurIPS 2021 Workshop on Deep Generative Models and
  Downstream Applications}, 2021.

\bibitem{hyvarinen2005estimation}
Aapo Hyv{\"a}rinen and Peter Dayan.
\newblock Estimation of non-normalized statistical models by score matching.
\newblock {\em Journal of Machine Learning Research}, 6(4), 2005.

\bibitem{pix2pix2017}
Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, and Alexei~A Efros.
\newblock Image-to-image translation with conditional adversarial networks.
\newblock {\em {CVPR}}, pages 1125--1134, 2017.

\bibitem{karush1961chapman}
Jack Karush.
\newblock On the chapman-kolmogorov equation.
\newblock {\em The Annals of Mathematical Statistics}, 32(4):1333--1337, 1961.

\bibitem{kim2024unpaired}
Beomsu Kim, Gihyun Kwon, Kwanyoung Kim, and Jong~Chul Ye.
\newblock Unpaired image-to-image translation via neural schr{\"o}dinger
  bridge.
\newblock In {\em {ICLR}}, 2024.

\bibitem{kingma2021variational}
Diederik Kingma, Tim Salimans, Ben Poole, and Jonathan Ho.
\newblock Variational diffusion models.
\newblock {\em {NeurIPS}}, 34:21696--21707, 2021.

\bibitem{KingmaB14}
Diederik~P. Kingma and Jimmy Ba.
\newblock Adam: {A} method for stochastic optimization.
\newblock In {\em {ICLR}}, 2015.

\bibitem{kingma2013auto}
Diederik~P Kingma and Max Welling.
\newblock Auto-encoding variational bayes.
\newblock {\em {ICLR}}, 2014.

\bibitem{lee2023minimizing}
Sangyun Lee, Beomsu Kim, and Jong~Chul Ye.
\newblock Minimizing trajectory curvature of ode-based generative models.
\newblock {\em {ICML}}, 202:18957--18973, 2023.

\bibitem{leonard2014survey}
Christian L{\'e}onard.
\newblock A survey of the schr{\"o}dinger problem and some of its connections
  with optimal transport.
\newblock {\em Discrete \& Continuous Dynamical Systems-A}, 34(4):1533--1574,
  2014.

\bibitem{LiX0L23}
Bo~Li, Kaitao Xue, Bin Liu, and Yu{-}Kun Lai.
\newblock {BBDM:} image-to-image translation with brownian bridge diffusion
  models.
\newblock In {\em {CVPR}}, pages 1952--1961, 2023.

\bibitem{lipman2022flow}
Yaron Lipman, Ricky~TQ Chen, Heli Ben-Hamu, Maximilian Nickel, and Matthew Le.
\newblock Flow matching for generative modeling.
\newblock In {\em {ICLR}}, 2022.

\bibitem{LiuCST22}
Guan{-}Horng Liu, Tianrong Chen, Oswin So, and Evangelos~A. Theodorou.
\newblock Deep generalized schr{\"{o}}dinger bridge.
\newblock In {\em {NeurIPS}}, 2022.

\bibitem{LiuVHTNA23}
Guan{-}Horng Liu, Arash Vahdat, De{-}An Huang, Evangelos~A. Theodorou, Weili
  Nie, and Anima Anandkumar.
\newblock I\({}^{\mbox{2}}\)sb: Image-to-image schr{\"{o}}dinger bridge.
\newblock In {\em {ICML}}, volume 202, pages 22042--22062, 2023.

\bibitem{liu2022rectified}
Qiang Liu.
\newblock Rectified flow: A marginal preserving approach to optimal transport.
\newblock {\em arXiv preprint arXiv:2209.14577}, 2022.

\bibitem{liu2022flow}
Xingchao Liu, Chengyue Gong, et~al.
\newblock Flow straight and fast: Learning to generate and transfer data with
  rectified flow.
\newblock In {\em {ICLR}}, 2022.

\bibitem{liu2022let}
Xingchao Liu, Lemeng Wu, Mao Ye, and Qiang Liu.
\newblock Let us build bridges: Understanding and extending diffusion
  generative models.
\newblock In {\em NeurIPS 2022 Workshop on Score-Based Methods}, 2022.

\bibitem{LiuW0l23}
Xingchao Liu, Lemeng Wu, Mao Ye, and Qiang Liu.
\newblock Learning diffusion bridges on constrained domains.
\newblock In {\em {ICLR}}, 2023.

\bibitem{pavon1991free}
Michele Pavon and Anton Wakolbinger.
\newblock On free energy, stochastic control, and schr{\"o}dinger processes.
\newblock In {\em Modeling, Estimation and Control of Systems with Uncertainty:
  Proceedings of a Conference held in Sopron, Hungary, September 1990}, pages
  334--348. Springer, 1991.

\bibitem{peluchetti2023diffusion}
Stefano Peluchetti.
\newblock Diffusion bridge mixture transports, schr{\"o}dinger bridge problems
  and generative modeling.
\newblock {\em Journal of Machine Learning Research}, 24(374):1--51, 2023.

\bibitem{rombach2022high}
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj{\"o}rn
  Ommer.
\newblock High-resolution image synthesis with latent diffusion models.
\newblock In {\em {CVPR}}, pages 10684--10695, 2022.

\bibitem{saharia2022palette}
Chitwan Saharia, William Chan, Huiwen Chang, Chris Lee, Jonathan Ho, Tim
  Salimans, David Fleet, and Mohammad Norouzi.
\newblock Palette: Image-to-image diffusion models.
\newblock In {\em {SIGGRAPH}}, pages 1--10, 2022.

\bibitem{salimans2016improved}
Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and
  Xi~Chen.
\newblock Improved techniques for training gans.
\newblock {\em {NeurIPS}}, 29:2226--2234, 2016.

\bibitem{sasaki2021unit}
Hiroshi Sasaki, Chris~G Willcocks, and Toby~P Breckon.
\newblock Unit-ddpm: Unpaired image translation with denoising diffusion
  probabilistic models.
\newblock {\em arXiv preprint arXiv:2104.05358}, 2021.

\bibitem{schrodinger1931umkehrung}
E.~Schr{\"o}dinger.
\newblock {\em {\"U}ber die Umkehrung der Naturgesetze}.
\newblock Sitzungsberichte der Preussischen Akademie der Wissenschaften.
  Physikalisch-mathematische Klasse. Verlag der Akademie der Wissenschaften in
  Kommission bei Walter De Gruyter u. Company, 1931.

\bibitem{shi2023diffusion}
Yuyang Shi, Valentin De~Bortoli, Andrew Campbell, and Arnaud Doucet.
\newblock Diffusion schr{\"o}dinger bridge matching.
\newblock In {\em Proceedings of the 37th International Conference on Neural
  Information Processing Systems}, pages 62183--62223, 2023.

\bibitem{sohl2015deep}
Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan, and Surya Ganguli.
\newblock Deep unsupervised learning using nonequilibrium thermodynamics.
\newblock In {\em {ICML}}, volume~37, pages 2256--2265, 2015.

\bibitem{SomnathPHM0B23}
Vignesh~Ram Somnath, Matteo Pariset, Ya{-}Ping Hsieh,
  Mar{\'{\i}}a~Rodr{\'{\i}}guez Mart{\'{\i}}nez, Andreas Krause, and Charlotte
  Bunne.
\newblock Aligned diffusion schr{\"{o}}dinger bridges.
\newblock In {\em {UAI}}, pages 1985--1995, 2023.

\bibitem{song2020denoising}
Jiaming Song, Chenlin Meng, and Stefano Ermon.
\newblock Denoising diffusion implicit models.
\newblock In {\em {ICLR}}, 2021.

\bibitem{song2019generative}
Yang Song and Stefano Ermon.
\newblock Generative modeling by estimating gradients of the data distribution.
\newblock {\em {NeurIPS}}, pages 11895--11907, 2019.

\bibitem{song2020score}
Yang Song, Jascha Sohl-Dickstein, Diederik~P Kingma, Abhishek Kumar, Stefano
  Ermon, and Ben Poole.
\newblock Score-based generative modeling through stochastic differential
  equations.
\newblock In {\em {ICLR}}, 2021.

\bibitem{su2023dual}
Xuan Su, Jiaming Song, Chenlin Meng, and Stefano Ermon.
\newblock Dual diffusion implicit bridges for image-to-image translation.
\newblock In {\em ICLR}, 2023.

\bibitem{tong2023improving}
Alexander Tong, Kilian Fatras, Nikolay Malkin, Guillaume Huguet, Yanlei Zhang,
  Jarrid Rector{-}Brooks, Guy Wolf, and Yoshua Bengio.
\newblock Improving and generalizing flow-based generative models with
  minibatch optimal transport.
\newblock {\em Trans. Mach. Learn. Res.}, 2024.

\bibitem{tong2023simulation}
Alexander Tong, Nikolay Malkin, Kilian Fatras, Lazar Atanackovic, Yanlei Zhang,
  Guillaume Huguet, Guy Wolf, and Yoshua Bengio.
\newblock Simulation-free schr$\backslash$" odinger bridges via score and flow
  matching.
\newblock {\em arXiv preprint arXiv:2307.03672}, 2023.

\bibitem{vargas2021solving}
Francisco Vargas, Pierre Thodoroff, Austen Lamacraft, and Neil Lawrence.
\newblock Solving schr{\"o}dinger bridges via maximum likelihood.
\newblock {\em Entropy}, 23(9):1134, 2021.

\bibitem{diode_dataset}
Igor Vasiljevic, Nick Kolkin, Shanyi Zhang, Ruotian Luo, Haochen Wang,
  Falcon~Z. Dai, Andrea~F. Daniele, Mohammadreza Mostajabi, Steven Basart,
  Matthew~R. Walter, and Gregory Shakhnarovich.
\newblock {DIODE}: {A} {D}ense {I}ndoor and {O}utdoor {DE}pth {D}ataset.
\newblock {\em arXiv preprint arXiv:1908.00463}, 2019.

\bibitem{wolleb2022swiss}
Julia Wolleb, Robin Sandk{\"u}hler, Florentin Bieder, and Philippe~C Cattin.
\newblock The swiss army knife for image-to-image translation: Multi-task
  diffusion models.
\newblock {\em arXiv preprint arXiv:2204.02641}, 2022.

\bibitem{zhang2018perceptual}
Richard Zhang, Phillip Isola, Alexei~A Efros, Eli Shechtman, and Oliver Wang.
\newblock The unreasonable effectiveness of deep features as a perceptual
  metric.
\newblock In {\em {CVPR}}, pages 586--595, 2018.

\bibitem{zhao2022egsde}
Min Zhao, Fan Bao, Chongxuan Li, and Jun Zhu.
\newblock Egsde: Unpaired image-to-image translation via energy-guided
  stochastic differential equations.
\newblock {\em Advances in Neural Information Processing Systems},
  35:3609--3623, 2022.

\bibitem{zhou2024denoising}
Linqi Zhou, Aaron Lou, Samar Khanna, and Stefano Ermon.
\newblock Denoising diffusion bridge models.
\newblock In {\em {ICLR}}, 2024.

\end{thebibliography}


\addtocontents{toc}{\protect\setcounter{tocdepth}{2}}

\clearpage{}


\appendix
\tableofcontents{}

\input{appdx.tex}
\end{document}
