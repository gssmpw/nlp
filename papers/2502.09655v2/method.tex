\noindent 
\begin{figure*}[t]
\begin{centering}
\includegraphics[width=0.8\textwidth]{asset/model}
\par\end{centering}
\caption{An illustration of \emph{Bidirectional Diffusion Bridge Models (BDBM)}.
Instead of learning two separate models $z_{\theta}\left(t,x_{t},x_{0}\right)$
and $z_{\phi}\left(s,x_{s},x_{T}\right)$ for the forward and backward
transitions, we learn a single model $z_{\varphi}\left(t,x_{t},\left(1-m\right)*x_{0},m*x_{T}\right)$
with a binary mask $m$ that enables transition in both directions.
Grey and white nodes denote initial and generated samples, respectively.}
\end{figure*}


\subsection{Chapman-Kolmogorov Equations for Bridges\label{subsec:Chapman-Kolmogorov-equations-for-bridges}}

In many real-world problems (e.g., paired/unpaired image translation),
the joint boundary distribution $p\left(y_{A},y_{B}\right)$ of samples
from two domains $A$, $B$ is given in advance rather than just either
$p\left(y_{A}\right)$ or $p\left(y_{B}\right)$, and we need to design
a stochastic process such that if we start from $y_{A}$ ($y_{B}$),
we should reach $y_{B}$ ($y_{A}$) with a predefined probability
$p\left(y_{B}|y_{A}\right)$ ($p\left(y_{A}|y_{B}\right)$). Such
stochastic processes are referred to as \emph{stochastic bridges}
or simply \emph{bridges }\cite{liu2022let,LiuW0l23,LiX0L23,zhou2024denoising}.
In this section, we will develop mathematical models for stochastic
bridges based on the CKEs for Markov processes in Section \ref{sec:Preliminaries}.

Without loss of generality, we associate two domains $A$, $B$ with
samples at time $0$, $T$, respectively. Let $\left\{ X_{t}\right\} $
be a stochastic process in which the initial distribution $p\left(x_{0}|y_{A}\right)$
is a Dirac distribution at $y_{A}$ (i.e., $p\left(x_{0}|y_{A}\right)=\delta_{y_{A}}$).
To conform to the notation used in prior works, we denotes $\hat{x}_{0}:=y_{A}$.
The symbol $^{\wedge}$ indicates that $\hat{x}_{0}$ is a specified
value rather than a random state like $x_{0}$\footnote{This allows us to write $p\left(x_{0}|\hat{x}_{0}\right)=\delta_{\hat{x}_{0}}=\delta_{y_{A}}$}.
For modeling simplicity, we assume that the process is a \emph{conditional
Markov process} described by the following CKE:
\begin{equation}
p\left(x_{v}|x_{t},\hat{x}_{0}\right)=\int p\left(x_{v}|x_{s},\text{\ensuremath{\hat{x}_{0}}}\right)p\left(x_{s}|x_{t},\text{\ensuremath{\hat{x}_{0}}}\right)dx_{s}\label{eq:bridge_CKE}
\end{equation}
where $t<s<v$. Interestingly, if we start this process from an arbitrary
time $t$ with the marginal distribution $p\left(x_{t}|\hat{x}_{0}\right)$,
we will always reach the same distribution at time $T>t$. To see
this, we represent $p\left(x_{T}|\hat{x}_{0}\right)$ using two different
starting times $t,s$ with $0\leq t<s<T$ as follows:
\begin{align}
 & p\left(x_{T}|\hat{x}_{0}\right)\nonumber \\
=\  & \int p\left(x_{T}|x_{s},\hat{x}_{0}\right)p\left(x_{s}|\hat{x}_{0}\right)dx_{s}\\
=\  & \int p\left(x_{T}|x_{s},\hat{x}_{0}\right)\left(\int p\left(x_{s}|x_{t},\hat{x}_{0}\right)p\left(x_{t}|\hat{x}_{0}\right)dx_{t}\right)dx_{s}\\
=\  & \int\underbrace{\left(\int p\left(x_{T}|x_{s},\hat{x}_{0}\right)p\left(x_{s}|x_{t},\hat{x}_{0}\right)dx_{s}\right)}_{p\left(x_{T}|x_{t},\hat{x}_{0}\right)}p\left(x_{t}|\hat{x}_{0}\right)dx_{t}\\
=\  & \int p\left(x_{T}|x_{t},\hat{x}_{0}\right)p\left(x_{t}|\hat{x}_{0}\right)dx_{t}
\end{align}
The intuition here is the associativity of the (functional) inner
product between $p\left(x_{T}|x_{s},\hat{x}_{0}\right)$, $p\left(x_{s}|x_{t},\hat{x}_{0}\right)$,
and $p\left(x_{t}|\hat{x}_{0}\right)$. Let us consider the problem
of learning the transition kernel $p_{\theta}\left(x_{s}|x_{t},\hat{x}_{0}\right)$
of the above process such that $p_{\theta}\left(x_{T}|\hat{x}_{0}\right)$
equals $p\left(y_{B}|y_{A}\right)$. Clearly, $p_{\theta}\left(x_{s}|x_{t},\hat{x}_{0}\right)$
should satisfy:
\begin{equation}
p\left(x_{T}|x_{t},\hat{x}_{0}\right)=\int p\left(x_{T}|x_{s},\hat{x}_{0}\right)p_{\theta}\left(x_{s}|x_{t},\hat{x}_{0}\right)dx_{s}\label{eq:bridge_CKE_not_learnable}
\end{equation}
for all $0\leq t<s$. However, Eq.~\ref{eq:bridge_CKE_not_learnable}
does not facilitate easy learning of $p_{\theta}\left(x_{s}|x_{t},\hat{x}_{0}\right)$
because determining the values of $p\left(x_{T}|x_{t},\hat{x}_{0}\right)$
and $p\left(x_{T}|x_{s},\hat{x}_{0}\right)$ can be challenging in
practice, which usually requires another parameterized model. Therefore,
we utilize the equivalent formula below:
\begin{equation}
q\left(x_{s}|\hat{x}_{T},\hat{x}_{0}\right)=\int p_{\theta}\left(x_{s}|x_{t},\hat{x}_{0}\right)q\left(x_{t}|\hat{x}_{T},\hat{x}_{0}\right)dx_{t}\label{eq:bridge_CKE_learnable}
\end{equation}
with $\hat{x}_{T}\sim p\left(y_{B}|y_{A}\right)$. The derivation
of Eq.~\ref{eq:bridge_CKE_learnable} is presented in Appdx.~\ref{subsec:Proof_Chapman-Kolmogorov-equations-for-bridges}.
Eq.~\ref{eq:bridge_CKE_learnable} implies that if we can construct
a \emph{double conditional Markov process} between $\hat{x}_{0}$
and $\hat{x}_{T}$ such that the marginal distribution at time $t$
is $q\left(x_{t}|\hat{x}_{T},\hat{x}_{0}\right)$ and the two boundary
distributions at times $0$ and $T$ are Dirac distributions at $\hat{x}_{0}$
and $\hat{x}_{T}$, respectively (i.e., $q\left(x_{0}|\hat{x}_{T},\hat{x}_{0}\right)=\delta_{\hat{x}_{0}}\left(x_{0}\right)$
and $q\left(x_{T}|\hat{x}_{T},\hat{x}_{0}\right)=\delta_{\hat{x}_{T}}\left(x_{T}\right)$),
then by learning $p_{\theta}\left(x_{s}|x_{t},\hat{x}_{0}\right)$
to match the transition probability $q\left(x_{s}|x_{t},\hat{x}_{T},\hat{x}_{0}\right)$
of this process, $p_{\theta}\left(x_{s}|x_{t},\hat{x}_{0}\right)$
will serve as the transition probability of a bridge starting from
$\hat{x}_{0}$ and ending at $\hat{x}_{T}$ with $p\left(\hat{x}_{T}|\hat{x}_{0}\right)=p\left(y_{B}|y_{A}\right)$.
There are various ways to align $p_{\theta}\left(x_{s}|x_{t},\hat{x}_{0}\right)$
with $q\left(x_{s}|x_{t},\hat{x}_{T},\hat{x}_{0}\right)$ and the
loss below is commonly used due to its link to variational inference
\cite{ho2020denoising,LiX0L23}:
\begin{equation}
\Loss=\Expect_{t,s,\hat{x}_{0},\hat{x}_{T}}\left[D_{\text{KL}}\left(q\left(x_{s}|x_{t},\hat{x}_{T},\hat{x}_{0}\right)\|p_{\theta}\left(x_{s}|x_{t},\hat{x}_{0}\right)\right)\right]\label{eq:loss_bridge_1}
\end{equation}
where $t\sim\mathcal{U}\left(0,T-\Delta t\right)$, $s=t+\Delta t$,
$\hat{x}_{0}\sim p\left(y_{A}\right)$, $\hat{x}_{T}\sim p\left(y_{B}|y_{A}\right)$.

In practice, we often choose $q\left(x_{t}|\hat{x}_{T},\hat{x}_{0}\right)$
and $q\left(x_{s}|\hat{x}_{T},\hat{x}_{0}\right)$ to be Gaussian
distributions, which results in $q\left(x_{s}|x_{t},\hat{x}_{T},\hat{x}_{0}\right)$
being a Gaussian. Therefore, if $p_{\theta}\left(x_{s}|x_{t},\hat{x}_{0}\right)$
is also modeled as a Gaussian distribution, then Eq.~\ref{eq:loss_bridge_1}
can be expressed in closed-form. Details about this will be presented
in Section~\ref{subsec:Generalized-Diffusion-Bridge-Models}. In
Appdx.~\ref{subsec:Connection-between-the-CKE-framework}, we provide
the connection of this framework to variational inference, score matching,
and Doob's $h$-transform.

\subsection{Generalized Diffusion Bridge Models\label{subsec:Generalized-Diffusion-Bridge-Models}}

To simplify our notation, from this section onward, we will use $x_{0}$,
$x_{T}$ in place of $\hat{x}_{0}$, $\hat{x}_{T}$ in the conditional
distributions $q\left(x_{t}|\hat{x}_{0},\hat{x}_{T}\right)$ and $q\left(x_{s}|x_{t},\hat{x}_{0},\hat{x}_{T}\right)$
with a note that they should be interpreted as specified values rather
than random states. As discussed in Section~\ref{subsec:Chapman-Kolmogorov-equations-for-bridges},
$q\left(x_{t}|x_{0},x_{T}\right)$ should be chosen as a Gaussian
distribution with zero variance at $t\in\left\{ 0,T\right\} $ to
facilitate learning the transition kernel. A general formula of $q\left(x_{t}|x_{0},x_{T}\right)$
is $q\left(x_{t}|x_{0},x_{T}\right)=\Normal\left(\alpha_{t}x_{0}+\beta_{t}x_{T},\sigma_{t}^{2}\mathrm{I}\right)$
where $\alpha_{t},\beta_{t},\sigma_{t}$ are continuously differentiable
functions of $t\in\left[0,T\right]$ satisfying $\alpha_{0}=\beta_{T}=1$
and $\alpha_{T}=\beta_{0}=\sigma_{0}=\sigma_{T}=0$. According to
this formula, $x_{t}\sim q\left(x_{t}|x_{0},x_{T}\right)$ can be
computed as follows:
\begin{equation}
x_{t}=\alpha_{t}x_{0}+\beta_{t}x_{T}+\sigma_{t}z\label{eq:ref_bridge_xt_decomp}
\end{equation}
with $z\sim\Normal\left(0,\mathrm{I}\right)$. Similarly, we have
$q\left(x_{s}|x_{0},x_{T}\right)=\Normal\left(\alpha_{s}x_{0}+\beta_{s}x_{T},\sigma_{s}^{2}\mathrm{I}\right)$.
This means $q\left(x_{s}|x_{t},x_{0},x_{T}\right)$ has the form $\Normal\left(x_{s}\big|\mu\left(s,t,x_{t},x_{0},x_{T}\right),\delta_{s,t}^{2}\mathrm{I}\right)$
where:
\begin{align}
 & \mu\left(s,t,x_{t},x_{0},x_{T}\right)\nonumber \\
=\  & \alpha_{s}x_{0}+\beta_{s}x_{T}+\sqrt{\sigma_{s}^{2}-\delta_{s,t}^{2}}\frac{\left(x_{t}-\alpha_{t}x_{0}-\beta_{t}x_{T}\right)}{\sigma_{t}}\label{eq:ref_forward_mean_1}\\
=\  & \frac{\beta_{s}}{\beta_{t}}x_{t}+\left(\alpha_{s}-\alpha_{t}\frac{\beta_{s}}{\beta_{t}}\right)x_{0}+\left(\sqrt{\sigma_{s}^{2}-\delta_{s,t}^{2}}-\sigma_{t}\frac{\beta_{s}}{\beta_{t}}\right)z\label{eq:ref_forward_mean_2}
\end{align}
and $\delta_{s,t}$ can vary arbitrarily within the (half-)interval
$[0,\sigma_{s})$. Eq.~\ref{eq:ref_forward_mean_2} is derived from
Eq.~\ref{eq:ref_forward_mean_1} by setting $x_{T}=\frac{1}{\beta_{t}}\left(x_{t}-\alpha_{t}x_{0}-\sigma_{t}z\right)$
according to Eq.~\ref{eq:ref_bridge_xt_decomp}.

To match $p_{\theta}\left(x_{s}|x_{t},x_{0}\right)$ with $q\left(x_{s}|x_{t},x_{0},x_{T}\right)$
($t<s$), we should be able to infer $x_{T}$ from $x_{t}$, $x_{0}$
in $p_{\theta}\left(x_{s}|x_{t},x_{0}\right)$. A straightforward
approach is to formulate $p_{\theta}\left(x_{s}|x_{t},x_{0}\right)$
as $\Normal\left(x_{s}\big|\mu_{\theta}\left(s,t,x_{t},x_{0}\right),\delta_{s,t}^{2}\mathrm{I}\right)$
and reparameterize $\mu_{\theta}\left(s,t,x_{t},x_{0}\right)$ to
match with $\mu\left(s,t,x_{t},x_{0},x_{T}\right)$, where $x_{T}$
replaced by its approximation $x_{T,\theta}\left(t,x_{t},x_{0}\right)$
in Eq.~\ref{eq:ref_forward_mean_1} (or $z$ replaced by $z_{\theta}\left(t,x_{t},x_{0}\right)$
in Eq.~\ref{eq:ref_forward_mean_2}). When $z_{\theta}\left(t,x_{t},x_{0}\right)$
is modeled, we regard $x_{T,\theta}\left(t,x_{t},x_{0}\right)$ as
$\frac{1}{\beta_{t}}\left(x_{t}-\alpha_{t}x_{0}-\sigma_{t}z_{\theta}\left(t,x_{t},x_{0}\right)\right)$,
and the loss in Eq.~\ref{eq:loss_bridge_1} simplifies to:
\begin{equation}
\Loss=\Expect_{t,x_{0},x_{T},z,x_{t}}\left[w_{t}\left\Vert z_{\theta}\left(t,x_{t},x_{0}\right)-z\right\Vert _{2}^{2}\right]\label{eq:loss_bridge_2}
\end{equation}
where $t\sim\mathcal{U}\left(0,T\right)$, $x_{0}\sim p\left(y_{A}\right)$,
$x_{T}\sim p\left(y_{B}|y_{A}\right)$, $z\sim\Normal\left(0,\mathrm{I}\right)$,
and $x_{t}=\alpha_{t}x_{0}+\beta_{t}x_{T}+\sigma_{t}z$. $w_{t}$
is set to 1 in our work. This loss is a weighted version of the score
matching loss for bridges \cite{zhou2024denoising}. Once $z_{\theta}$
has been learned, it will approximate $-\sigma_{t}\nabla\log p\left(x_{t}|x_{0}\right)$,
and $x_{T,\theta}$ derived from $z_{\theta}$ approximates $\Expect_{p\left(x_{T}|x_{t},x_{0}\right)}\left[x_{T}\right]$
due to Tweedie's formula for bridges (Appdx\@.~\ref{subsec:Tweedie's-formula-for-bridges}).

\begin{table*}
\begin{centering}
\begin{tabular}{cccccccccc}
\toprule 
\multirow{2}{*}{Model} & \multicolumn{3}{c}{Edges$\rightarrow$Shoes$\times64$} & \multicolumn{3}{c}{Edges$\rightarrow$Handbags$\times64$} & \multicolumn{3}{c}{Normal$\rightarrow$Outdoor$\times256$}\tabularnewline
\cmidrule{2-10} 
 & FID $\downarrow$ & IS $\uparrow$ & LPIPS $\downarrow$ & FID $\downarrow$ & IS $\uparrow$ & LPIPS $\downarrow$ & FID $\downarrow$ & IS $\uparrow$ & LPIPS $\downarrow$\tabularnewline
\midrule
\midrule 
BBDM & 2.11 & 3.23 & \uline{0.05} & 6.38 & 3.71 & 0.19 & 8.79 & 5.48 & 0.29\tabularnewline
\midrule 
$\text{I}^{2}\text{SB}$ & 2.14 & \textbf{3.41} & 0.06 & 6.05 & \uline{3.73} & 0.17 & \uline{5.48} & 5.71 & 0.37\tabularnewline
\midrule 
DDBM & 6.42 & 3.26 & 0.12 & 3.89 & 3.58 & 0.23 & 6.16 & 5.74 & 0.35\tabularnewline
\midrule
\midrule 
BDBM-1 (ours) & \uline{1.78} & \uline{3.28} & 0.07 & \uline{3.83} & 3.71 & \uline{0.11} & 7.17 & \textbf{5.97} & \textbf{0.11}\tabularnewline
\midrule 
BDBM (ours) & \textbf{1.06} & \uline{3.28} & \textbf{0.02} & \textbf{3.06} & \textbf{3.74} & \textbf{0.08} & \textbf{4.67} & \uline{5.91} & \uline{0.16}\tabularnewline
\bottomrule
\end{tabular}
\par\end{centering}
\caption{Quantitative comparison between BDBM and unidirectional bridge models
on translation tasks from sketch/normal maps to color images. The
best results are highlighted in bold, while the second-best results
are underlined.\label{tab:main_result_1}}
\end{table*}


\subsection{Bidirectional Diffusion Bridge Models\label{subsec:Bidirectional-Diffusion-Bridge-Models}}

Leaning $p_{\theta}\left(x_{s}|x_{t},x_{0}\right)$ with $t<s$ in
Section~\ref{subsec:Generalized-Diffusion-Bridge-Models} leads to
a bridge that maps samples at time $0$ (domain $A$) to those at
time $T$ (domain $B$). Unfortunately, we cannot travel in the reverse
direction (i.e., generate $x_{0}$ from $x_{T}$) with this bridge.
It is because the reverse transition kernel derived from $p_{\theta}\left(x_{s}|x_{t},x_{0}\right)$
requires the knowledge of $x_{0}$, which is not available if starting
from time $T$. A straightforward solution to this problem is constructing
another bridge with $x_{T}$ as the source by learning $p_{\phi}\left(x_{t}|x_{s},x_{T}\right)$
($t<s$). This results in two separate models for forward and backward
travels, which doubles the resources for training and deployment.
To overcome this limitation, we propose a novel Bidirectional Diffusion
Bridge Model (BDBM) that enables bidirectional travel while requiring
the training of only a single network. In our model, $p_{\theta}\left(x_{s}|x_{t},x_{0}\right)$
and $p_{\phi}\left(x_{t}|x_{s},x_{T}\right)$ are transition kernels
operating in opposite directions along the same bridge that connects
$x_{0}$ and $x_{T}$. Due to the interchangeability between $x_{t}$
and $x_{s}$ in Eq.~\ref{eq:bridge_CKE_learnable}, it follows that
if $p_{\theta}\left(x_{s}|x_{t},x_{0}\right)$ approximates $q\left(x_{s}|x_{t},x_{0},x_{T}\right)$,
then $p_{\phi}\left(x_{t}|x_{s},x_{T}\right)$ should approximate
$q\left(x_{t}|x_{s},x_{0},x_{T}\right)$, which is derived from $q\left(x_{s}|x_{t},x_{0},x_{T}\right)$
via the Bayes' rule:
\begin{equation}
q\left(x_{t}|x_{s},x_{0},x_{T}\right)=q\left(x_{s}|x_{t},x_{0},x_{T}\right)\frac{q\left(x_{t}|x_{0},x_{T}\right)}{q\left(x_{s}|x_{0},x_{T}\right)}\label{eq:Bayes_rule_bridge}
\end{equation}
Since $q\left(x_{t}|x_{0},x_{T}\right)$, $q\left(x_{s}|x_{0},x_{T}\right)$,
and $q\left(x_{s}|x_{t},x_{0},x_{T}\right)$ are Gaussian distributions
specified in Eqs.~\ref{eq:ref_bridge_xt_decomp}, \ref{eq:ref_forward_mean_1},
$q\left(x_{t}|x_{s},x_{0},x_{T}\right)$ is also a Gaussian distribution
of the form $\Normal\left(x_{t}\Big|\tilde{\mu}\left(t,s,x_{s},x_{0},x_{T}\right),\frac{\delta_{s,t}^{2}\sigma_{t}^{2}}{\sigma_{s}^{2}}\mathrm{I}\right)$
with $\tilde{\mu}\left(t,s,x_{s},x_{0},x_{T}\right)$ given by:
\begin{align}
 & \tilde{\mu}\left(t,s,x_{s},x_{0},x_{T}\right)\nonumber \\
=\  & \alpha_{t}x_{0}+\beta_{t}x_{T}+\sigma_{t}\sqrt{\sigma_{s}^{2}-\delta_{s,t}^{2}}\frac{\left(x_{s}-\alpha_{s}x_{0}-\beta_{s}x_{T}\right)}{\sigma_{s}^{2}}\label{eq:ref_backward_mean_1}\\
=\  & \frac{\alpha_{t}}{\alpha_{s}}x_{s}+\left(\beta_{t}-\beta_{s}\frac{\alpha_{t}}{\alpha_{s}}\right)x_{T}+\left(\frac{\sigma_{t}\sqrt{\sigma_{s}^{2}-\delta_{s,t}^{2}}}{\sigma_{s}}-\sigma_{s}\frac{\alpha_{t}}{\alpha_{s}}\right)z'\label{eq:ref_backward_mean_2}
\end{align}
where Eq.~\ref{eq:ref_backward_mean_2} is derived from Eq.~\ref{eq:ref_backward_mean_1}
by setting $x_{0}=\frac{1}{\alpha_{s}}\left(x_{s}-\beta_{s}x_{T}-\sigma_{s}z'\right)$.
We can align $p_{\phi}\left(x_{t}|x_{s},x_{T}\right)$ with $q\left(x_{t}|x_{s},x_{0},x_{T}\right)$
by reparameterizing the mean $\tilde{\mu}_{\phi}\left(t,s,x_{s},x_{T}\right)$
of $p_{\phi}\left(x_{t}|x_{s},x_{T}\right)$ such that it has the
same formula as $\tilde{\mu}\left(t,s,x_{s},x_{0},x_{T}\right)$ in
Eq.~\ref{eq:ref_backward_mean_1} but with $x_{0}$ replaced by $x_{0,\phi}\left(s,x_{s},x_{T}\right)$
(or $z'$ replaced by $z_{\phi}\left(s,x_{s},x_{T}\right)$ in Eq.~\ref{eq:ref_backward_mean_2}). 

In the case where $p_{\theta}\left(x_{s}|x_{t},x_{0}\right)$ and
$p_{\phi}\left(x_{t}|x_{s},x_{T}\right)$ are modeled via $z_{\theta}\left(t,x_{t},x_{0}\right)$
and $z_{\phi}\left(s,x_{s},x_{T}\right)$, respectively, it is possible
to use a single network $z_{\varphi}$ instead of two separate networks
$z_{\theta}$ and $z_{\phi}$ because they both represent the same
noise variable $z\sim\Normal\left(0,\mathrm{I}\right)$ (given $t=s$).
To deal with the problem that the forward transition depends on $x_{0}$
while the backward transition depends on $x_{T}$, we feed both $x_{0}$
and $x_{T}$ as inputs to $z_{\varphi}$ and mask one of them using
a mask $m$ associated with the transition direction. This results
in the model $z_{\varphi}\left(t,x_{t},\left(1-m\right)*x_{0},m*x_{T}\right)$
where $m=0$ (1) if we move forward from 0 to $T$ (backward from
$T$ to 0). We learn $z_{\varphi}$ by minimizing the following loss:
\begin{align}
\Loss_{\text{BDBM}}= & \Expect_{t,x_{0},x_{T},z,x_{t},m}\left[w_{t}\left\Vert z_{\varphi}\left(t,x_{t},\left(1-m\right)*x_{0},m*x_{T}\right)-z\right\Vert _{2}^{2}\right]\label{eq:loss_BDBM}
\end{align}
where $x_{0}$, $x_{T}$, $t$, $z$, $x_{t}$ are sampled in the
same way as in Eq.~\ref{eq:loss_bridge_2}, and the mask $m$ is
sampled from the Bernoulli distribution with $p\left(m=1\right)=0.5$.

On the other hand, when $x_{T,\theta}\left(t,x_{t},x_{0}\right)$
and $x_{0,\phi}\left(s,x_{s},x_{T}\right)$ serve as the parameterized
models for $p_{\theta}\left(x_{s}|x_{t},x_{0}\right)$ and $p_{\phi}\left(x_{t}|x_{s},x_{T}\right)$,
respectively, we propose to use a unified model to predict $x_{0}+x_{T}$.
We denote this model as $s_{\varphi}\left(t,x_{t},\left(1-m\right)*x_{0},m*x_{T}\right)$
and learn it with the loss:
\begin{align}
\Loss_{\text{BDBM}}^{(2)} & =\Expect_{t,x_{0},x_{T},z,x_{t},m}\Big[w_{t}\big\| s_{\varphi}\left(t,x_{t},\left(1-m\right)*x_{0},m*x_{T}\right)-\left(x_{0}+x_{T}\right)\big\|_{2}^{2}\Big]\label{eq:loss_BDBM_2}
\end{align}
When traveling from 0 to $T$ (from $T$ to 0), we set $m$ to $0$
(1) and use $s_{\varphi}\left(t,x_{t},x_{0},0\right)-x_{0}$ ($s_{\varphi}\left(s,x_{s},0,x_{T}\right)-x_{T}$)
to mimic $x_{T,\theta}\left(t,x_{t},x_{0}\right)$ ($x_{0,\phi}\left(s,x_{s},x_{T}\right)$).
We can also train $s_{\varphi}$ to predict $x_{0}+x_{T}$. In Appdx.~\ref{subsec:Training-and-sampling_alg},
we provide detailed training and sampling algorithms for BDBM. We
also discuss several important variants of BDBM in Appdx.~\ref{subsec:Special-cases-of-BDBM}.
