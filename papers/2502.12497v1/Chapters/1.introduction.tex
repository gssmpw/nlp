\section{Introduction}
Large Language Models (LLMs) have ushered in a new era of artificial intelligence (AI), redefining what is possible in domains such as natural language understanding~\cite{daye2024llmcodeunderstanding,lu2024visionunderstanding,zhao2024llmsurvey}, text generation~\cite{zhao2024llmsurvey,roberto2023generativeai}, software engineering~\cite{hou2024llm4se,jin2024agents4se,wang2024agentsinse}, and autonomous systems~\cite{wu2023autogen,wang2024ala}. These models, built on billions of parameters and trained on extensive datasets, have demonstrated superhuman capabilities in tasks like mathematical reasoning~\cite{janice2024mathematical}, video generation~\cite{maaz2024videochatgpt}, and code generation~\cite{priyan2022codegeneration}. Since the release of ChatGPT~\cite{chatgpt}, the field has seen an explosion of both commercial and open-source LLMs, with applications expanding across industries, including education, healthcare, and finance. As LLMs continue to integrate into real-world systems, their development and deployment processes have become increasingly complex and dependent on a variety of components, giving rise to the concept of the LLM Supply Chain~\cite{wang2024llmsc}.

\noindent \textbf{LLM Supply Chain.} The LLM supply chain, as defined in previous studies~\cite{wang2024llmsc,hu2024llmsc,huang2024llmsc}, refers to the interconnected ecosystem of components, stakeholders, and dependencies involved in the lifecycle of LLMs. Unlike traditional software systems, the LLM supply chain incorporates novel elements such as massive datasets, development toolchains, pre-trained models, and specialized deployment environments. For instance, building an LLM-driven application may involve reusing an open-source model, integrating third-party libraries, and orchestrating workflows with plugins. Each stage introduces dependencies on external components, such as data providers, model repositories, or software frameworks, which collectively form the supply chain.

\noindent \textbf{Research Gaps.} The growing reliance on the supply chain in developing and deploying LLMs introduces a new dimension of challenges, particularly in terms of security. However, most existing security research has primarily focused on content safety aspects, including adversarial attacks~\cite{liu2024adversary,andy2023universal}, jailbreaks~\cite{shen2024dan,xu2024jailbreak}, and backdoor attacks~\cite{li2024backdoorllm,zhao2025surveybackdoor}, which exploit vulnerabilities in the models themselves to manipulate outputs or bypass safety mechanisms. While these studies have provided valuable insights into specific content-related vulnerabilities, they largely overlook the security properties of the underlying system software ecosystem.  
Furthermore, despite some emerging efforts to address vulnerabilities in LLM software systems~\cite{zhao2024malhug,zhu2025tensorflow,liu2024llmrce,pedro2025prompt2sql}, these efforts remain fragmented and limited in scope, lacking a comprehensive and systematic understanding of vulnerabilities across the entire LLM ecosystem. For instance, it remains unclear which components are most prone to vulnerabilities, and what root causes underlie these issues. The effectiveness of existing detection techniques in addressing the unique challenges of LLM systems remains uncertain. Without a systematic analysis of these aspects, securing the increasingly complex LLM ecosystem remains a significant challenge.

\noindent \textbf{Our Work.} In this paper, we fill this gap by providing a systematization of knowledge of vulnerabilities in the LLM supply chain. Specifically, we collect and analyze 529 vulnerabilities reported between January 2023 and October 2024, spanning 75 prominent LLM projects. These projects encompass 13 key lifecycle stages of the LLM ecosystem, including data indexing, vector storage, model training, LLMOps, model serving, retrieval-augmented generation (RAG), orchestration, and front-end UI frameworks \& applications. We systematically investigate these vulnerabilities and provide a detailed root cause taxonomy comprising 4 categories and 11 subcategories, offering a deeper understanding of the distinct vulnerability patterns in LLM systems. Additionally, we examine the fix patterns and effectiveness of the 300 vulnerabilities with available patches, investigating issues like patch side effects and recurring vulnerabilities. To summarize, we make the following contributions:
\begin{itemize}[leftmargin=10pt]
    \item \textbf{Systematic Study.} We conduct the first systematic study of vulnerabilities in the LLM supply chain, analyzing 529 vulnerabilities reported across 75 prominent LLM projects. These vulnerabilities span 13 key lifecycle stages of the LLM ecosystem, ranging from upstream processes to downstream components.
    \item \textbf{Root Cause Taxonomy.} We develop a detailed root cause taxonomy comprising 4 categories and 11 subcategories. By systematically mapping these vulnerabilities to their root causes, we provide actionable insights for developers and researchers to better understand, predict, and mitigate vulnerabilities in LLM systems.
    \item \textbf{Fix Pattern Investigation.} We analyze 300 vulnerabilities with available patches, studying the effectiveness of these fixes, and cases of recurring vulnerabilities. Our investigation uncovers common pitfalls in patch implementation, such as incomplete fixes, unintended side effects, and recurring vulnerabilities due to inadequate testing.
\end{itemize}

\noindent \textbf{Key Findings.}
Our study reveals that vulnerabilities in the LLM supply chain are mainly concentrated in the application layer (50.3\%) and model layer (42.7\%), collectively accounting for 93\% of all identified issues, with most vulnerabilities arising from Python (50.1\%) and JavaScript (23.2\%) ecosystems. Improper resource control throughout the lifetime is the most prevalent root cause (45.7\%), driven by the complexity of managing memory, files, and network connections in LLM workloads, followed by improper neutralization (25.1\%), where improper handling of generative outputs highlights the risks associated with prompt injection and unsanitized model-generated content. While 300 vulnerabilities (56.7\%) had available fixes, the ineffectiveness of 8\% of these patches led to the recurrence of 34 vulnerabilities. These findings underscore the systemic challenges in addressing vulnerabilities in the LLM supply chain and highlight the need for comprehensive strategies to secure this evolving ecosystem.