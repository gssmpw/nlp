\section{RQ1: Distribution}
To comprehensively analyze the distribution of vulnerabilities in LLM systems, we first examined how vulnerabilities are distributed across the lifecycle stages of affected components in the LLM ecosystem. Following this, we categorized these vulnerabilities using Common Weakness Enumeration (CWE) classifications to understand their underlying characteristics. Below, we elaborate on these two dimensions in detail.

\subsection{Lifecycle Stages of Affected Components}
To understand the characteristics and lifecycle distribution of vulnerabilities in LLM systems, we analyzed 529 CVEs collected from diverse components across the LLM supply chain. These vulnerabilities were categorized into three layers—data, model, and application—corresponding to key stages in the LLM lifecycle. Below, we provide a detailed breakdown of the CVEs associated with each stage.

\noindent \textbf{Overall Distribution.}
As shown in \autoref{tab:lifecycle_components_desc}, vulnerabilities are unevenly distributed across lifecycle stages, with the application layer accounting for 266 CVEs (50.3\%), the model layer 226 CVEs (42.7\%), and the data layer 37 CVEs (7.0\%). This distribution indicates that vulnerabilities tend to concentrate in layers where LLM systems directly interact with external inputs (application layer) or handle complex operational workflows (model layer).

\begin{table}[t]
\centering
\caption{Lifecycle Distribution of CVEs by Layer.}
\label{tab:lifecycle_components_desc}
\begin{tabular}{llr}
\toprule
\textbf{Layer}         & \textbf{Lifecycle Stage}               & \textbf{CVEs (\%)} \\ 
\midrule
\multirow{3}{*}{\textbf{Data}} 
                       & Data Index                            & 21 / 4.0\%        \\ 
                       & Vector Database                      & 8 / 1.5\%         \\ 
                       & Data Pipeline                        & 8 / 1.5\%         \\ 
\midrule
\multirow{5}{*}{\textbf{Model}} 
                       & Logging \& LLMOps                     & 124 / 23.4\%      \\ 
                       & Training Framework                   & 67 / 12.7\%       \\ 
                       & Model Serving                        & 21 / 4.0\%        \\ 
                       & Model Quantization                   & 7 / 1.3\%         \\ 
                       & Model Inference                      & 7 / 1.3\%         \\ 
\midrule
\multirow{5}{*}{\textbf{Application}} 
                       & App/Front-end                        & 210 / 39.7\%      \\ 
                       & Orchestration Framework              & 33 / 6.2\%        \\ 
                       & LLM Gateway                          & 10 / 1.9\%        \\ 
                       & RAG                                  & 9 / 1.7\%         \\ 
                       & Plugins/External Tools               & 4 / 0.8\%         \\ 
\midrule
\textbf{Total}         &                                       & \textbf{529} \\ 
\bottomrule
\end{tabular}
\end{table}

\noindent \textbf{Data Layer (37 CVEs, 4.0\%).}
The data layer, responsible for managing and processing data, accounted for 37 CVEs (7.0\%). This layer includes components such as data indexing systems (21 CVEs, 4.0\%), vector databases (8 CVEs, 1.5\%), and data pipelines (8 CVEs, 1.5\%). Vulnerabilities in data indexing systems can lead to issues such as poisoned datasets or data corruption, which can propagate downstream. Similarly, vector databases face risks of unauthorized access, potentially exposing sensitive embeddings used in RAG.

\noindent \textbf{Model Layer (226 CVEs, 42.7\%).} The model layer, encompassing processes such as training, optimization, serving, and inference, exhibited 226 CVEs (42.7\%), making it the second-most affected layer. Among these, logging and LLMOps frameworks were particularly vulnerable, with 124 CVEs (23.4\%). These weaknesses not only compromise the integrity of the LLM workflows but also expose the broader system to potential attacks, including unauthorized access and code execution. Training frameworks accounted for 67 CVEs (12.7\%) and were primarily affected by memory-related vulnerabilities in operators and handling of model files. Model serving systems exhibited 21 CVEs (4.0\%), where exploitation could disrupt real-time inference, degrade model availability, or allow attackers to exfiltrate sensitive data. Overall, these vulnerabilities in the model layer can have cascading effects on LLM systems and, in some cases, directly impact the victim’s infrastructure.

\noindent \textbf{Application Layer (266 CVEs, 50.3\%).} The application layer was the most affected, with 266 CVEs (50.3\%), underscoring its critical role in connecting LLM systems to external environments and users. Front-end frameworks and applications were particularly vulnerable, with 210 CVEs (39.7\%), due to their exposure to user inputs and interaction interfaces. Orchestration frameworks accounted for 33 CVEs (6.2\%), highlighting potential risks in workflow automation and LLM integration. Additional components, such as LLM gateways (10 CVEs, 1.9\%), RAG systems (9 CVEs, 1.7\%), and plugins or external tools (4 CVEs, 0.8\%), also presented security challenges, particularly in their roles as intermediaries or extensions of LLM functionalities.

\begin{tcolorbox}
    \textbf{Findings.} The majority of vulnerabilities (50.3\%) are concentrated in the application layer, while other lifecycle stages like LLMOps and training also exhibit significant security risks.
\end{tcolorbox}

\subsection{Ecosystem Distribution}
To better understand the distribution of vulnerabilities across different programming ecosystems, we categorized the 529 CVEs based on the primary programming languages or technologies used in the affected repositories. This analysis sheds light on the ecosystems most affected by vulnerabilities and highlights key areas requiring security improvements. The results are summarized in \autoref{tab:ecosystem_components_desc}.

\begin{table}[t]
\centering
\caption{Ecosystem Distribution of CVEs by Project.}
\label{tab:ecosystem_components_desc}
\begin{tabular}{llc}
\toprule
\textbf{Ecosystem}      & \textbf{Project}                            & \textbf{CVEs} \\
\midrule
\multirow{7}{*}{\textbf{Python}} & mlflow/mlflow                               & 44            \\
                         & GaiZhenbiao/ChuanhuChatGPT                  & 22            \\
                         & mindsdb/mindsdb                              & 20            \\
                         & gradio-app/gradio                          & 13            \\
                         & parisneo/lollms                            & 12            \\
                         & stitionai/devika                           & 12            \\
                         & others ($\le 10$)                              & 132           \\
\midrule
\multirow{5}{*}{\textbf{JavaScript}} 
                         & mintplex-labs/anything-llm                 & 49            \\
                         & lunary-ai/lunary                           & 44            \\
                         & FlowiseAI/Flowise
                         & 8        \\
                         & open-webui/open-webui                      & 7             \\
                         & others ($\le 5$)                           & 15            \\
\midrule
\multirow{3}{*}{\textbf{C++}}        & paddlepaddle/paddle                        & 41            \\
                             & ggerganov/llama.cpp                        & 5             \\
                             & tensorflow/serving                         & 1             \\
\midrule
\multirow{4}{*}{\textbf{Java}}      & h2oai/h2o-3                                & 13            \\
                             & pytorch/serve                              & 4             \\
                             & vertaai/modeldb                            & 2             \\
                             & deepjavalibrary/djl                        & 2             \\
\midrule
\multirow{2}{*}{\textbf{Go}}                         & mudler/localai                             & 10            \\
                             & ollama/ollama                              & 8             \\
\midrule
\multirow{1}{*}{\textbf{Others}}         & /                                    & 54             \\
\midrule
\textbf{Total}             &                                            & \textbf{529}  \\
\bottomrule
\end{tabular}
\end{table}




\noindent \textbf{Python Ecosystem.}  
The Python ecosystem emerged as the most affected, contributing 265 CVEs (50.1\% of the total). This prominence reflects Python's centrality in the development of LLM frameworks and tools, with many popular projects such as \texttt{mlflow/mlflow} (44 CVEs), \texttt{GaiZhenbiao/ChuanhuChatGPT} (22 CVEs), and \texttt{mindsdb/mindsdb} (20 CVEs) leveraging Python to manage workflows, fine-tune models, and enable inference processes.  The high number of CVEs is driven not only by Python’s extensive adoption across these domains but also by vulnerabilities linked to unsafe model file formats in frameworks such as PyTorch and TensorFlow~\cite{zhao2024malhug,zhu2025tensorflow}.

\noindent \textbf{JavaScript and TypeScript Ecosystems.}  
The JavaScript and TypeScript ecosystems collectively accounted for 123 CVEs, representing 23.2\% of the total vulnerabilities. JavaScript-based projects, such as \texttt{mintplex-labs/anything-llm} (49 CVEs) and \texttt{open-webui/open-webui} (7 CVEs), contributed 57 CVEs (10.8\%), while TypeScript tools like \texttt{lunary-ai/lunary} (44 CVEs) and \texttt{FlowiseAI/Flowise} (8 CVEs) added another 66 CVEs (12.5\%). These ecosystems are heavily utilized for implementing front-end UI frameworks and workflow orchestration tools, which serve as critical components for facilitating user interactions with LLM systems. The high number of vulnerabilities reflects the inherently user-facing nature of these projects, where insecure API management, inadequate input validation, and improper access controls can pose significant security risks. 

\noindent \textbf{C++/Java/Go Ecosystem.} 
The C++, Java, and Go ecosystems collectively contributed 86 CVEs (16.3\%), highlighting their importance in performance-critical and backend components of LLM systems. C++ accounted for 47 CVEs, with notable examples including \texttt{paddlepaddle/paddle} (41 CVEs) and \texttt{ggerganov/llama.cpp} (5 CVEs). Java contributed 21 CVEs, with projects like \texttt{h2oai/h2o-3} (13 CVEs) and \texttt{pytorch/serve} (4 CVEs). The Go ecosystem added 18 CVEs, primarily from repositories such as \texttt{mudler/LocalAI} (10 CVEs) and \texttt{ollama/ollama} (8 CVEs). These languages are extensively used for model serving, orchestration, and computational tasks, where vulnerabilities like memory corruption, resource exhaustion, or unauthorized access can disrupt LLM workflows. 

\begin{tcolorbox}
    \textbf{Findings.} The majority of vulnerabilities in the LLM ecosystem are concentrated in Python and JavaScript projects, collectively accounting for 73.3\% of CVEs. 
\end{tcolorbox}