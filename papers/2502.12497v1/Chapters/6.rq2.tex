\section{RQ2: Root Cause}
To analyze the vulnerabilities impacting the LLM ecosystem, we categorized the 529 CVEs based on their Common Weakness Enumeration (CWE) identifiers. These CWEs represent the root causes of vulnerabilities and provide critical insights into the most frequent weaknesses. By understanding these root causes, developers can prioritize mitigation efforts and strengthen the security of LLM systems.

\begin{table*}[t]
\centering
\caption{Classification of LLM Vulnerabilities by the Root Cause. R1: Improper Control of a Resource Through its Lifetime, R2: Improper Neutralization, R3: Improper Access Control, R4: Computational and Exception Handling Errors.}
\fontsize{9.5}{13}\selectfont
\label{tab:cwe_distribution}
\begin{tabular}{c|llc|c}
\hline
\textbf{Root Cause} & \textbf{Class} & \textbf{CWE Info} & \textbf{Count} & \textbf{Total (\%)} \\
\hline
\multirow{13}{*}{\textbf{R1}} 
& \multirow{5}{*}{Path Traversal} & CWE-22 & 43 & \multirow{13}{*}{242 / 45.7\%} \\
&  & CWE-29 & 40 & \\
&  & CWE-23 & 33 & \\
&  & CWE-36 & 9 & \\
&  & CWE-39 & 5 & \\
\cline{2-4}
& \multirow{4}{*}{Externally Controlled Reference to a Resource in Another Sphere} 
& CWE-918 & 25 & \\
&  & CWE-942 & 8 & \\
&  & CWE-73 & 7 & \\
&  & CWE-601 & 5 & \\
\cline{2-4}
& Improper Control of Dynamically-Managed Code Resources & CWE-502 & 27 & \\
\cline{2-4}
& \multirow{2}{*}{Uncontrolled Resource Consumption} 
& CWE-754 & 9 & \\
&  & CWE-770 & 9 & \\
\cline{2-4}
& \multirow{1}{*}{Incorrect Access of Indexable Resource (Range Error)} 
& CWE-125 & 6 & \\
\hline
\multirow{6}{*}{\textbf{R2}} 
& \multirow{6}{*}{Injection} 
& CWE-79 & 33 & \multirow{6}{*}{133 / 25.1\%} \\
&  & CWE-94 & 29 & \\
&  & CWE-1426 & 28 & \\
&  & CWE-78 & 26 & \\
&  & CWE-89 & 11 & \\
&  & CWE-1336 & 6 & \\
\hline
\multirow{5}{*}{\textbf{R3}} 
& \multirow{1}{*}{Improper Privilege Management} 
& CWE-266 & 29 & \multirow{5}{*}{65 / 12.3\%} \\
\cline{2-4}
& \multirow{3}{*}{Improper Authorization} 
& CWE-639 & 15 & \\
&  & CWE-862 & 11 & \\
&  & CWE-863 & 6 & \\
\cline{2-4}
& \multirow{1}{*}{Origin Validation Error} 
& CWE-352 & 15 & \\
\hline
\multirow{2}{*}{\textbf{R4}} 
& Incorrect Calculation & CWE-369 & 8 & \multirow{2}{*}{14 / 2.6\%} \\
& Improper Check or Handling of Exceptional Conditions & CWE-476 & 6 & \\
\hline
\multirow{1}{*}{\textbf{Others}} 
& / & / & 80 & 15.1\% \\
\hline
\textbf{Total} & / & / & \textbf{529} & 100\% \\
\hline
\end{tabular}
\end{table*}

\noindent \textbf{Overview of the Root Cause Taxonomy.}
The vulnerabilities identified in the LLM ecosystem are grouped into four primary categories, as shown in \autoref{tab:cwe_distribution}, each reflecting distinct systemic weaknesses. The most prevalent category, \textbf{R1}: Improper control of a resource through its lifetime (242, 45.7\%), encompasses issues such as path traversal, externally controlled references to resources, and improper management of dynamically allocated code. 
\textbf{R2}: Improper neutralization (133, 25.1\%) includes vulnerabilities arising from untrusted inputs, such as command injection, cross-site scripting, and improper output encoding. 
\textbf{R3}: Improper access control (65, 12.3\%) reflects deficiencies in authorization, privilege management, and authentication mechanisms.
Finally, \textbf{R4}: Computational and exception handling errors (14, 2.6\%) represent logical flaws in calculations and inadequate handling of runtime exceptions. 
In addition to these primary categories, 75 vulnerabilities (14.2\%) are classified as Others, representing CWEs that individually contribute fewer than five instances. 

\noindent \textbf{R1: Improper Control of a Resource through Its Lifetime.} 
Improper control of a resource through its lifetime refers to the inability to maintain proper control over resources during their creation, usage, and release phases. In LLM systems, the complexity and scale of computational resources, such as memory, files, and network connections, make resource management even more critical. These resources must be carefully allocated, utilized, and deallocated to ensure system stability and security. Among the identified vulnerabilities related to improper resource control, the diversity of resource types and operations often creates challenges for developers, leading to errors that can be exploited by attackers. Based on our analysis, we have identified the following subsets of vulnerabilities under this root cause:

\begin{figure}[t]
    \centering
    \includegraphics[width=0.95\linewidth]{Figures/cve-2023-48299.jpg}
    \caption{Example of CVE-2023-48299.}
    \label{fig:cve-2023-48299}
\end{figure}

\begin{itemize}[leftmargin=10pt]
    \item \textbf{Path Traversal.} Path traversal vulnerabilities are a critical subset of issues within the category of improper control of a resource through its lifetime, accounting for 130 CVEs. These vulnerabilities stem from insufficient control over file path resources during their creation, manipulation, or validation phases. When user-supplied file paths are not properly sanitized, attackers can exploit this weakness to access files and directories outside the intended operational boundaries, compromising system integrity and confidentiality. A representative example is \texttt{CVE-2023-48299}\footnote{https://github.com/advisories/GHSA-m2mj-pr4f-h9jp}~(as illustrated in \autoref{fig:cve-2023-48299}), a ZipSlip vulnerability discovered in \texttt{TorchServe}, a widely used model-serving framework. This vulnerability allowed attackers to upload malicious archive files via the model and workflow management API. These archives contained carefully crafted file paths designed to escape the designated extraction directory, enabling attackers to write files to arbitrary locations on the filesystem within the permissions of the TorchServe process. Exploiting this flaw, malicious actors could embed harmful code in public or open-source models, posing significant risks to machines running TorchServe.

    \item \textbf{Externally Controlled Reference to a Resource in Another Sphere.} Externally controlled reference to a resource in another sphere is a notable subset within the category of improper control of a resource through its lifetime, accounting for 45 CVEs. These vulnerabilities occur when an application allows unvalidated or improperly sanitized external inputs to dictate the location or identity of resources accessed by the system. This can lead to unauthorized access, data leakage, or unintended interactions with external systems. CWE-918, commonly referred to as Server-Side Request Forgery (SSRF), is a prominent example of this type of vulnerability. For instance, in \texttt{CVE-2023-43654}\footnote{https://github.com/advisories/GHSA-8fxr-qfr9-p34w}, an SSRF vulnerability was identified as part of the ShellTorch~\cite{shelltorch} exploit chain targeting \texttt{TorchServe}. In this case, TorchServe's model management API allowed the registration of model workflow archives from remote URLs without proper validation. The default configuration accepted any URL, failing to restrict access to trusted domains. This SSRF allows arbitrary file writes to the model store folder, enabling attackers to upload malicious models to be executed by the server.

    \item \textbf{Improper Control of Dynamically-Managed Code Resources.} Improper control of dynamically-managed code resources is a critical subset within the category of improper control of a resource through its lifetime, accounting for 27 CVEs. This class of vulnerabilities often arises from the insecure deserialization of untrusted data, particularly in scenarios involving pre-trained models or datasets and distributed training frameworks. In these cases, attackers can exploit deserialization mechanisms to execute arbitrary code, compromise system integrity, and manipulate workflows.
    A representative example is \texttt{CVE-2024-3568}\footnote{https://huntr.com/bounties/b3c36992-5264-4d7f-9906-a996efafba8f}, which exposes a deserialization vulnerability in Hugging Face’s \texttt{Transformers} library. Specifically, the vulnerability resides in the \texttt{load\_repo\_checkpoint} function of the \texttt{TFPreTrainedModel} class. Attackers could craft malicious serialized payloads in files, such as \texttt{.pickle}, that are subsequently loaded during model checkpointing. This attack vector allowed adversaries to execute arbitrary commands, demonstrating how unsafe model loading practices can open critical security gaps. In the context of LLMs, models are inherently executable code~\cite{zhao2024malhug,zhu2025tensorflow}; thus, unvalidated deserialization of models or datasets poses severe risks.
    Another notable instance, \texttt{CVE-2024-7804}\footnote{https://huntr.com/bounties/0e870eeb-f924-4054-8fac-d926b1fb7259}, was identified in \texttt{PyTorch}'s distributed remote procedure call (RPC) framework. Here, deserialization vulnerabilities occur during RPC calls, where Python objects are serialized and transmitted between nodes in a distributed training environment. The deserialization process used Python's \texttt{pickle} module without sufficient validation, enabling attackers to inject malicious serialized objects into RPC requests. These malicious objects could then execute arbitrary code on the master node, granting full control over the training environment. Such exploits not only jeopardize the confidentiality and integrity of sensitive training data but also potentially compromise the entire infrastructure supporting the distributed workflow.

\end{itemize}

\begin{tcolorbox}
    \textbf{Findings.} Improper control of resources through their lifetime accounts for 45.7\% of all identified CVEs, making it the most prevalent root cause. The scale and complexity of managing resources such as memory, files, and network connections in the LLM ecosystem amplify these vulnerabilities.
\end{tcolorbox}



\noindent \textbf{R2: Improper Neutralization.} 
Improper neutralization represents a significant root cause of vulnerabilities in LLM-based systems. Traditionally, in web services, vulnerabilities often arise from insufficient validation or sanitization of user-provided inputs received from remote sources. However, in the LLM ecosystem, the challenge extends further to include the neutralization of the model’s own outputs (CWE-1426). Treating these outputs as inherently trustworthy in downstream processes introduces critical risks, as attackers can manipulate the model’s behavior through prompt engineering or adversarial inputs. Unlike traditional input sanitization scenarios, LLM outputs are diverse in format and complexity, encompassing natural language, executable code, or database queries. Without robust validation mechanisms, downstream components interacting with these outputs are exposed to injection attacks. Based on our analysis, we identified the following vulnerabilities caused by prompt injection.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.95\linewidth]{Figures/CVE-2023-39662.jpg}
    \caption{Illustration of CVE-2023-39662. Prompt Injection Leading to RCE in \texttt{llama\_index}.}
    \label{fig:cve-2023-39662}
\end{figure}

\begin{itemize}[leftmargin=10pt]
    \item \textbf{Prompt Injection Leading to SQL Injection.}  
    Prompt injection can result in SQL injection when model-generated outputs are directly integrated into database queries without sanitization. For instance, \texttt{CVE-2024-8309}\footnote{https://huntr.com/bounties/8f4ad910-7fdc-4089-8f0a-b5df5f32e7c5} demonstrates a prompt injection vulnerability in the \texttt{GraphCypherQAChain} class of the \texttt{LangChain} library. This vulnerability allows attackers to manipulate generative model outputs to inject arbitrary Cypher queries into a Neo4j database. Without proper validation, the system executes these malicious queries, enabling attackers to perform unauthorized actions such as data exfiltration, modification, or deletion. In this case, prompt injection escalated into a full-scale SQL injection, compromising the integrity and security of the database.

    \item \textbf{Prompt Injection Leads to Code Injection and Arbitrary Code Execution.}  
    When LLM-generated outputs are used to produce executable code, such as Python scripts, prompt injection can lead to code injection vulnerabilities. Attackers can craft prompts designed to inject malicious code, which is then executed by the system. This can result in arbitrary code execution, allowing attackers to gain unauthorized access, escalate privileges, or compromise the entire system. For example, \texttt{CVE-2023-39662}\footnote{https://github.com/run-llama/llama\_index/issues/7054} demonstrates how prompt injection can lead to remote code execution (RCE) in \texttt{llama\_index} (as shown in \autoref{fig:cve-2023-39662}). In this case, the vulnerability arises from the unsafe use of the \texttt{exec} function to execute Python code generated by the model. The lack of proper validation and sandboxing of the LLM-generated code allows attackers to inject malicious instructions through crafted prompts. When deployed as part of an application backend, such as a web app or Slackbot, this vulnerability exposes the server to remote exploitation. An attacker can execute arbitrary commands on the server, leading to data breaches, privilege escalation, and complete server compromise. 
    
    \item \textbf{Prompt Injection Leads to Cross-Site Scripting (XSS).}  
    Prompt injection can also result in XSS when model-generated outputs are rendered into web pages without proper sanitization or escaping of special characters. This vulnerability arises when LLM systems directly output user-controlled or manipulated content into a browser context, allowing attackers to inject malicious JavaScript code. For example, \texttt{CVE-2024-1602}\footnote{https://huntr.com/bounties/59be0d5a-f18e-4418-8f29-72320269a097} demonstrates how prompt injection can lead to XSS in the \texttt{LoLLMs-WebUI} application. In this case, the model output is not adequately sanitized, enabling attackers to inject JavaScript code through specially crafted payloads. If the malicious payload is processed and displayed in a web interface without escaping, the JavaScript code is executed within the victim's browser context. Unlike traditional XSS attacks, this variant relies on the uncontrolled propagation of harmful outputs generated by the LLM, stemming directly from the prompt injection, highlighting the unique security challenges in LLM-backed systems.
\end{itemize}

\begin{tcolorbox}
\textbf{Findings.} Improper neutralization accounts for 25.1\% of all identified CVEs. Notably, 28 CVEs (CWE-1426, 21.1\% of injection vulnerabilities) are directly linked to untrusted model outputs, underscoring the risks posed by prompt injection and the improper handling of generative model outputs in downstream processes.
\end{tcolorbox}

\noindent \textbf{R3: Improper Access Control.}  
Improper access control arises when a system fails to enforce or implement restrictions on what actions, operations, or resources users can access based on their privileges or roles. In LLM-based systems, these vulnerabilities are particularly prevalent in front-end UIs, application frameworks, and LLMOps platforms. Many frameworks assume that users will deploy their services in secure, local environments. However, in practice, a significant number of users deploy these services in open network environments without implementing adequate access controls, such as in ShadowRay~\cite{shadowray}. 
In addition to the risks associated with front-end applications, LLMOps platforms introduce unique challenges due to their multi-role environments. These platforms often involve multiple stakeholders, such as administrators, developers, and end-users, who require varying levels of access to resources and functionality. When role-based access control (RBAC) mechanisms are insufficiently granular, users may inadvertently be granted excessive permissions, leading to privilege escalation. 
Based on our analysis, the following subsets of vulnerabilities fall under this root cause.

\begin{itemize}[leftmargin=10pt]  
    \item \textbf{Improper Privilege Management.} Improper privilege management occurs when a system assigns excessive or inappropriate privileges to users or processes, allowing them to perform actions beyond their intended level of access. This can result from misconfigurations, flawed privilege allocation logic, or insufficient checks during role assignment. 
    For instance, \texttt{CVE-2024-1741}\footnote{https://huntr.com/bounties/671bd040-1cc5-4227-8182-5904e9c5ed3b} highlights a critical privilege management flaw in the \texttt{lunary-ai/lunary} framework. In this vulnerability, users removed from an organization could still perform privileged operations, such as reading, creating, editing, or deleting prompt templates associated with the organization, by reusing their old authorization tokens. Despite being removed as members, affected users could exploit this issue by intercepting and replaying HTTP requests (e.g., \texttt{PATCH}, \texttt{GET}, \texttt{POST}, \texttt{DELETE}) with their previously captured authorization tokens.  
    
    \item \textbf{Improper Authorization.} Improper authorization occurs when a system fails to enforce or implement appropriate access control rules, allowing unauthorized users to perform restricted actions. This can arise from either missing authorization checks or incorrectly implemented authorization logic. For example, \texttt{CVE-2024-5389}\footnote{https://huntr.com/bounties/3ca5309f-5615-4d5b-8043-968af220d7a2} demonstrates an insecure direct object reference (IDOR) vulnerability in the \texttt{lunary-ai/lunary} framework. This issue allows a user from one organization to create, edit, or delete prompts in datasets belonging to other organizations. By intercepting and manipulating requests, such as \texttt{PATCH /v1/datasets/variations/\{id\}}, an attacker can bypass organizational boundaries by altering or omitting parameters like \texttt{projectId}.
    The exploitation of such vulnerabilities can severely impact system integrity by allowing attackers to overwrite legitimate prompts, remove critical resources, and tamper with experiment results. 

    \item \textbf{Origin Validation Error.} Origin validation errors occur when a system fails to adequately validate the source of a request, allowing attackers to impersonate legitimate users or perform unauthorized actions. This class of vulnerabilities typically arises in web-based applications that lack proper protection mechanisms, such as Cross-Site Request Forgery (CSRF) tokens or strict origin headers. 
    For instance, \texttt{CVE-2024-24593}\footnote{https://github.com/advisories/GHSA-w6j5-fp4m-crpf} demonstrates a critical CSRF vulnerability in the \texttt{ClearML} server, a platform widely used for managing LLM experiments and workflows. The vulnerability affects all API and web server components, allowing an attacker to exploit a lack of CSRF protection to impersonate legitimate users. By crafting a malicious web page, an attacker can trick a victim into visiting the page, which triggers API requests from the victim's browser using their credentials. This vulnerability enables attackers to perform unauthorized actions, such as changing data and settings, accessing confidential workspaces, or adding themselves to sensitive projects.
\end{itemize}

\begin{tcolorbox}  
    \textbf{Findings.}  
    Improper access control, accounting for 12.3\% of CVEs, emphasizing the need for stricter access control mechanisms in open and multi-role environments.
\end{tcolorbox}
    
\noindent \textbf{R4: Computational and Exception Handling Errors.}  
Computational and exception handling errors account for 2.6\% of all identified CVEs. These vulnerabilities arise when systems fail to properly manage computational logic or handle exceptions, leading to issues such as invalid memory access, infinite loops, resource exhaustion, and incorrect outputs. While many of these issues have historically existed in traditional deep learning frameworks, they persist and manifest uniquely in the LLM supply chain due to the complexity and scale of workloads. These vulnerabilities are not limited to training frameworks but also extend to other components, such as vector databases.

\begin{itemize}[leftmargin=10pt] 
    \item \textbf{Improper Resource Initialization and Validation.}  
    Failure to properly initialize or validate computational resources, such as memory buffers, data structures, or input parameters, can lead to severe consequences. For instance, \texttt{CVE-2024-2367}\footnote{https://huntr.com/bounties/d7605a64-fd6d-4ca1-ba72-cc7e667ef81a} highlights a vulnerability in the \texttt{GatherTreeKernel} function of \texttt{PaddlePaddle}. This issue occurs when tensors are processed without validating negative values in the parent tensor, resulting in a heap-buffer-overflow. Such vulnerabilities can cause data corruption, program crashes, or unauthorized access, undermining the integrity and reliability of LLM systems.
    
    \item \textbf{Uncontrolled Resource Release.} Improper resource management, particularly during deallocation or release, is another major concern in LLM workloads. For instance, \texttt{CVE-2023-37365}\footnote{https://github.com/advisories/GHSA-xwc8-rf6m-xr86} highlights a double-free vulnerability in \texttt{hnswlib}, a widely used vector database for semantic search and similarity calculations. This issue arises when the \texttt{init\_index} function is configured with excessively large parameters, resulting in improperly deallocated memory. The vulnerability leads to heap corruption, program crashes, or resource conflicts, particularly in shared or high-demand environments. 
\end{itemize}

\begin{tcolorbox}  
    \textbf{Findings.} Computational and exception handling errors, while accounting for only 2.6\% of CVEs, highlight critical vulnerabilities that span multiple components of the LLM supply chain, including training frameworks and vector databases. 
\end{tcolorbox}

% \item \textbf{Improper Resource Initialization and Validation.} Failure to properly initialize or validate resources during their creation phase is a common issue in LLM systems. This includes insufficient validation of input data, file paths, or configuration parameters, which can lead to unexpected behavior or security breaches. For example, CVE-2024-2367\footnote{https://huntr.com/bounties/d7605a64-fd6d-4ca1-ba72-cc7e667ef81a} demonstrates a typical case of improper resource initialization and validation in the \texttt{GatherTreeKernel} function of PaddlePaddle. Specifically, the \texttt{GatherTreeKernel} function processes tensors without checking for negative values in the parent tensor, leading to invalid memory access. When the tensor passed to the function contains negative values, the lack of validation triggers a heap-buffer-overflow, resulting in data corruption, unauthorized access, or unexpected behavior in LLM systems.

% \begin{figure}
%     \centering
%     \includegraphics[width=0.95\linewidth]{Figures/CVE-2024-2367.jpg}
%     \caption{Example of CVE-2024-2367 for Resource Validation.}
%     \label{fig:cve-2024-2367}
% \end{figure}

% \item \textbf{Incorrect Resource Usage and Release.} Resource misuse and improper deallocation are critical issues in LLM systems, often involving memory buffers, file handles, or network connections. For example, CVE-2024-0088\footnote{https://huntr.com/bounties/e8bfc644-48db-4a38-b212-8ad3ce73521f} in the Triton Inference Server highlights the dangers of incorrect resource usage and release during inference requests. In this case, the Triton server improperly uses the shared memory region when calculating the output address for inference results. By specifying an invalid offset in the inference request (e.g., \texttt{-0x20}), the server computes an address outside the allocated shared memory region, resulting in illegal memory access and program crashes. Another example is CVE-2023-37365\footnote{https://github.com/advisories/GHSA-xwc8-rf6m-xr86}, a double-free vulnerability in the \texttt{hnswlib} library~(Vector Database). This issue occurs in the \texttt{init\_index} function when the M parameter is set to a large integer. Improper deallocation of memory leads to a double-free condition, which corrupts the heap and results in program crashes. More broadly, such uncontrolled resource release and usage can also lead to memory leaks, resource exhaustion, or conflicts in scenarios where multiple models or users share resources, ultimately compromising system integrity and reducing availability.

% \noindent \textbf{Root Cause 6: Insufficient Control Flow Management.}  
% Insufficient control flow management occurs when a system fails to properly handle the execution flow of processes, leading to unintended behavior such as infinite loops, uncontrolled recursion, or race conditions. These vulnerabilities can degrade system performance, cause resource exhaustion, or result in incorrect or unexpected outputs. Below, we detail three critical subcategories related to insufficient control flow management:

% \begin{itemize}[leftmargin=10pt] 

% \item \textbf{Loop with Unreachable Exit Condition.} An infinite loop occurs when a loop’s exit condition is unreachable or improperly implemented, causing the program to continue execution indefinitely. In LLM-based systems, this can happen when the model processes complex or malformed inputs that inadvertently lead to unending iterations. For example, a poorly designed algorithm for processing user prompts or generating outputs might fail to detect termination conditions, resulting in excessive resource consumption and potential denial of service (DoS). 

% \item \textbf{Uncontrolled Recursion.} Uncontrolled recursion occurs when a recursive function is invoked without an effective mechanism to limit its depth or prevent excessive calls, leading to stack overflow or resource exhaustion. In LLM-powered systems, this can happen if recursive calls are dynamically generated based on user input or model outputs without proper safeguards. For instance, an LLM might recursively process nested structures in user prompts or data, eventually overwhelming system resources. 

% \item \textbf{Time-of-check Time-of-use (TOCTOU) Race Condition.} TOCTOU race conditions occur when a system performs a check (e.g., for permissions or resource availability) and subsequently acts on the result, but the resource's state changes in the time between the check and the operation. In LLM-based systems, this can be exploited in scenarios where file operations, resource locks, or shared data are dynamically managed. For example, an attacker might manipulate a file or resource after it has passed a security check but before it is accessed or modified, leading to unauthorized actions or data corruption. 
% \end{itemize}

% \begin{tcolorbox}  
% \textbf{Findings.}  
% Insufficient control flow management encompasses vulnerabilities such as infinite loops, uncontrolled recursion, and TOCTOU race conditions, all of which can severely impact the stability, security, and performance of LLM-based systems. 
% \end{tcolorbox}