\section{Background}
Integrating LLMs into real-world systems demands a robust and interconnected technical stack, driving the creation of a diverse ecosystem of tools and frameworks to support their lifecycle. This section provides an overview of the LLM lifecycle and technical stack, highlighting their complexity and the associated security challenges.

% \subsection{LLM Lifecycle and Tech Stack}
\noindent \textbf{LLM Lifecycle and Tech Stack.} The lifecycle of LLMs involves multiple interconnected stages, each supported by specialized tools and frameworks, forming a complex and comprehensive technical stack. These stages include data collection and preprocessing, model training, optimization, deployment, and post-deployment monitoring. Each stage is crucial for the integration of LLMs into real-world systems, and together they ensure the models are effective and scalable. However, as the stack is highly interconnected, vulnerabilities introduced at any stage—whether during data handling, model training, or deployment—can compromise the overall integrity and performance of the LLM system. \autoref{fig:stack} illustrates the general architecture of the LLM tech stack, which consists of three primary layers:
\begin{figure}[t]
    \centering
    \includegraphics[width=0.95\linewidth]{Figures/stack.pdf}
    \caption{LLM Lifecycle and Tech Stack.}
    \label{fig:stack}
\end{figure}

\noindent \textbf{[A] Data Layer.} The data layer serves as the foundation of the LLM lifecycle, responsible for managing the collection, transformation, storage, and retrieval of large datasets. This layer handles the initial steps of the data pipeline, beginning with transforming raw data into vector representations using embedding models. Tools like SentenceTransformers~\cite{sentence-transformers} are employed to create high-quality embeddings that convert textual data into vector formats suitable for downstream processes. The embedded data is then indexed and stored in systems that facilitate efficient and scalable retrieval, such as vector databases like FAISS~\cite{faiss} and Qdrant~\cite{qdrant}, which facilitates rapid access to relevant data for tasks such as Retrieval-Augmented Generation (RAG) or LLM caching. 
    
\noindent \textbf{[B] Model Layer.} The model layer is essential for the core development, optimization, and deployment of LLMs, providing the necessary tools and frameworks to enhance model performance. Frameworks like Hugging Face’s Transformers~\cite{transformers} facilitate the implementation and fine-tuning of pre-trained models. Supporting techniques such as model quantization and model merging help optimize the model’s size and computational efficiency. LLM operations (LLMOps), such as lunary~\cite{lunary}, are also integrated into this layer, enabling continuous monitoring and refinement of the model's performance throughout its lifecycle, from the initial development phase to deployment.
Once the model is prepared, it is served and utilized through model serving and inference processes. Frameworks such as Triton Inference Server~\cite{triton-inference-server} or Ollama~\cite{ollama} provide the necessary infrastructure to deploy models into production environments, enabling real-time predictions via API endpoints. The inference process then utilizes these models to generate outputs for various tasks, such as text generation or question answering, based on user queries or system requests.
    
\noindent \textbf{[C] Application Layer.} The application layer is responsible for connecting trained LLMs to real-world systems and users, enabling seamless integration and deployment. This layer focuses primarily on orchestration frameworks that automate workflows and manage the interactions between different components. Orchestration tools like LangChain~\cite{langchain} and AutoGPT~\cite{AutoGPT} enable autonomous decision-making and process automation by chaining LLM calls together.
Supporting tools are essential for extending the LLM’s capabilities. For example, LiteLLM~\cite{litellm} acts as an LLM gateway, serving as a proxy that provides a unified interface for calling multiple models in a consistent format. GPTCache~\cite{gptcache} provides caching services to optimize performance and reduce latency, ensuring faster responses during inference. Tools like Haystack~\cite{haystack} support retrieval-augmented generation (RAG), enhancing the LLM's ability to respond to complex queries by retrieving relevant information from external data sources. Additionally, function-calling frameworks like Composio~\cite{composio} can be integrated to enhance agent capabilities, allowing for dynamic interactions with external APIs and systems.
As many LLM systems interact directly with users, front-end frameworks are also a critical part of this layer. Platforms like Anything-LLM~\cite{anythingllm} and LocalAI~\cite{localai} provide interfaces for users to interact with LLMs, enabling easy access to LLM functionalities through user-friendly interfaces. 

% \subsection{LLM Infrastructure Vulnerabilities}
% As the adoption of LLMs continues to grow, the complexity and interconnected nature of their supporting infrastructure have significantly expanded the potential attack surface for adversaries. The LLM ecosystem consists of various components, including third-party libraries, deployment platforms, and orchestration frameworks, all of which introduce unique vulnerabilities. These vulnerabilities, if exploited, can undermine the security of the entire system—affecting aspects such as data integrity, model performance, and user privacy.

% Each layer of the LLM tech stack introduces its own set of challenges. For example, in the Data Layer, vulnerabilities related to data preprocessing, such as improper data sanitization or malicious data injection, can lead to poisoned training data or biased embeddings that degrade model performance or generate biased outputs. Moreover, vulnerabilities in data indexing and retrieval processes, especially in vector databases like FAISS~\cite{faiss} and Qdrant~\cite{qdrant}, can expose sensitive information or enable unauthorized access to stored data~\cite{vecdbvul}, impacting the overall integrity of the LLM system.

% In the Model Layer, vulnerabilities often arise from the tools and techniques used for model development and optimization. Issues such as insecure model merging, unsafe handling of training data, or flaws in quantization processes could lead to compromised models, performance degradation, or adversarial attacks. LLM operations (LLMOps) integrated into this layer—such as tools for monitoring and adjusting model performance—may also introduce risks if improperly configured or managed, enabling potential misuse or unintentional bias during the deployment phase.

% Finally, in the Application Layer, security risks often stem from the orchestration and deployment frameworks that facilitate communication between the LLM and external systems. Vulnerabilities in API endpoints, poor authentication mechanisms, or improper access control can expose the system to attacks such as unauthorized access, denial-of-service attacks, or even the injection of malicious inputs. Frameworks like LangChain~\cite{langchain}, AutoGPT~\cite{AutoGPT}, and LiteLLM~\cite{litellm}, while providing powerful capabilities for automation and model integration, can be vulnerable if not properly secured. Additionally, front-end frameworks like Anything-LLM~\cite{anythingllm} and LocalAI~\cite{localai} that facilitate user interactions also pose risks if they fail to implement adequate input validation and authentication.

% The increasingly complex LLM ecosystem highlights the need for comprehensive security practices at every stage of development and deployment. Vulnerabilities introduced at any layer can cascade and result in substantial security breaches, affecting the performance, reliability, and safety of LLM systems. 