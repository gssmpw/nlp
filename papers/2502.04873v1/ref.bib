@inproceedings{murali2021same,
  title={Same object, different grasps: Data and semantic knowledge for task-oriented grasping},
  author={Murali, Adithyavairavan and Liu, Weiyu and Marino, Kenneth and Chernova, Sonia and Gupta, Abhinav},
  booktitle={Conference on robot learning},
  pages={1540--1557},
  year={2021},
  organization={PMLR}
}
@article{fang2023anygrasp,
  title={Anygrasp: Robust and efficient grasp perception in spatial and temporal domains},
  author={Fang, Hao-Shu and Wang, Chenxi and Fang, Hongjie and Gou, Minghao and Liu, Jirong and Yan, Hengxu and Liu, Wenhai and Xie, Yichen and Lu, Cewu},
  journal={IEEE Transactions on Robotics},
  year={2023},
  publisher={IEEE}
}
@inproceedings{sundermeyer2021contact,
  title={Contact-graspnet: Efficient 6-dof grasp generation in cluttered scenes},
  author={Sundermeyer, Martin and Mousavian, Arsalan and Triebel, Rudolph and Fox, Dieter},
  booktitle={2021 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={13438--13444},
  year={2021},
  organization={IEEE}
}
@article{mahler2017dex,
  title={Dex-net 2.0: Deep learning to plan robust grasps with synthetic point clouds and analytic grasp metrics},
  author={Mahler, Jeffrey and Liang, Jacky and Niyaz, Sherdil and Laskey, Michael and Doan, Richard and Liu, Xinyu and Ojea, Juan Aparicio and Goldberg, Ken},
  journal={arXiv preprint arXiv:1703.09312},
  year={2017}
}
@article{calli2015ycb,
  title={The YCB object and model set: Towards common benchmarks for manipulation research},
  author={Calli, Berk and Singh, Aaron and Bruce, Aaron and Walsman, Alex and Konolige, Kurt and Srinivasa, Siddhartha S and Abbeel, Pieter and Dollar, Aaron M},
  journal={2015 International Conference on Advanced Robotics (ICAR)},
  pages={510--517},
  year={2015},
  organization={IEEE}
}
@article{borja2014googlescan,
  title={Google Object Scans: High-Quality 3D Meshes for Robotics and Vision Research},
  author={Borja, Kelvin and Bai, Yawei and Smith, Travis and Liu, Eric and Krainin, Michael and Hanrahan, Pat and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1407.1550},
  year={2014}
}

@inproceedings{mousavian20196,
  title={6-dof graspnet: Variational grasp generation for object manipulation},
  author={Mousavian, Arsalan and Eppner, Clemens and Fox, Dieter},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={2901--2910},
  year={2019}
}
@article{yang2023dawn,
  title={The dawn of lmms: Preliminary explorations with gpt-4v (ision)},
  author={Yang, Zhengyuan and Li, Linjie and Lin, Kevin and Wang, Jianfeng and Lin, Chung-Ching and Liu, Zicheng and Wang, Lijuan},
  journal={arXiv preprint arXiv:2309.17421},
  volume={9},
  number={1},
  pages={1},
  year={2023}
}
@article{li2023m,
  title={M$^3$ IT: A Large-Scale Dataset towards Multi-Modal Multilingual Instruction Tuning},
  author={Li, Lei and Yin, Yuwei and Li, Shicheng and Chen, Liang and Wang, Peiyi and Ren, Shuhuai and Li, Mukai and Yang, Yazheng and Xu, Jingjing and Sun, Xu and others},
  journal={arXiv preprint arXiv:2306.04387},
  year={2023}
}
@article{taunyazov2023grace,
  title={GRaCE: Optimizing Grasps to Satisfy Ranked Criteria in Complex Scenario},
  author={Taunyazov, Tasbolat and Lin, Kelvin and Soh, Harold},
  journal={arXiv preprint arXiv:2309.08887},
  year={2023}
}
@article{barad2023graspldm,
  title={GraspLDM: Generative 6-DoF Grasp Synthesis using Latent Diffusion Models},
  author={Barad, Kuldeep R and Orsula, Andrej and Richard, Antoine and Dentler, Jan and Olivares-Mendez, Miguel and Martinez, Carol},
  journal={arXiv preprint arXiv:2312.11243},
  year={2023}
}
@article{chang2024text2grasp,
  title={Text2Grasp: Grasp synthesis by text prompts of object grasping parts},
  author={Chang, Xiaoyun and Sun, Yi},
  journal={arXiv preprint arXiv:2404.15189},
  year={2024}
}
@inproceedings{tang2023task,
  title={Task-oriented grasp prediction with visual-language inputs},
  author={Tang, Chao and Huang, Dehao and Meng, Lingxiao and Liu, Weiyu and Zhang, Hong},
  booktitle={2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={4881--4888},
  year={2023},
  organization={IEEE}
}
@article{li2024semgrasp,
  title={Semgrasp: Semantic grasp generation via language aligned discretization},
  author={Li, Kailin and Wang, Jingbo and Yang, Lixin and Lu, Cewu and Dai, Bo},
  journal={arXiv preprint arXiv:2404.03590},
  year={2024}
}
@article{jang2017end,
  title={End-to-end learning of semantic grasping},
  author={Jang, Eric and Vijayanarasimhan, Sudheendra and Pastor, Peter and Ibarz, Julian and Levine, Sergey},
  journal={arXiv preprint arXiv:1707.01932},
  year={2017}
}
@inproceedings{urain2023se,
  title={Se (3)-diffusionfields: Learning smooth cost functions for joint grasp and motion optimization through diffusion},
  author={Urain, Julen and Funk, Niklas and Peters, Jan and Chalvatzaki, Georgia},
  booktitle={2023 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={5923--5930},
  year={2023},
  organization={IEEE}
}
@inproceedings{gu2023maniskill2,
  title={ManiSkill2: A Unified Benchmark for Generalizable Manipulation Skills},
  author={Gu, Jiayuan and Xiang, Fanbo and Li, Xuanlin and Ling, Zhan and Liu, Xiqiang and Mu, Tongzhou and Tang, Yihe and Tao, Stone and Wei, Xinyue and Yao, Yunchao and Yuan, Xiaodi and Xie, Pengwei and Huang, Zhiao and Chen, Rui and Su, Hao},
  booktitle={International Conference on Learning Representations},
  year={2023}
}
@article{liu2024moka,
  title={Moka: Open-vocabulary robotic manipulation through mark-based visual prompting},
  author={Liu, Fangchen and Fang, Kuan and Abbeel, Pieter and Levine, Sergey},
  journal={arXiv preprint arXiv:2403.03174},
  year={2024}
}
@article{wu2024helpful,
  title={Helpful DoggyBot: Open-World Object Fetching using Legged Robots and Vision-Language Models},
  author={Wu, Qi and Fu, Zipeng and Cheng, Xuxin and Wang, Xiaolong and Finn, Chelsea},
  journal={arXiv preprint arXiv:2410.00231},
  year={2024}
}
@article{weerakoon2024behav,
  title={BehAV: Behavioral Rule Guided Autonomy Using VLMs for Robot Navigation in Outdoor Scenes},
  author={Weerakoon, Kasun and Elnoor, Mohamed and Seneviratne, Gershom and Rajagopal, Vignesh and Arul, Senthil Hariharan and Liang, Jing and Jaffar, Mohamed Khalid M and Manocha, Dinesh},
  journal={arXiv preprint arXiv:2409.16484},
  year={2024}
}
@article{hu2023look,
  title={Look before you leap: Unveiling the power of gpt-4v in robotic vision-language planning},
  author={Hu, Yingdong and Lin, Fanqi and Zhang, Tong and Yi, Li and Gao, Yang},
  journal={arXiv preprint arXiv:2311.17842},
  year={2023}
}
@article{kim2024openvla,
  title={OpenVLA: An Open-Source Vision-Language-Action Model},
  author={Kim, Moo Jin and Pertsch, Karl and Karamcheti, Siddharth and Xiao, Ted and Balakrishna, Ashwin and Nair, Suraj and Rafailov, Rafael and Foster, Ethan and Lam, Grace and Sanketi, Pannag and others},
  journal={arXiv preprint arXiv:2406.09246},
  year={2024}
}
@article{team2024octo,
  title={Octo: An open-source generalist robot policy},
  author={Team, Octo Model and Ghosh, Dibya and Walke, Homer and Pertsch, Karl and Black, Kevin and Mees, Oier and Dasari, Sudeep and Hejna, Joey and Kreiman, Tobias and Xu, Charles and others},
  journal={arXiv preprint arXiv:2405.12213},
  year={2024}
}
@article{brohan2023rt,
  title={Rt-2: Vision-language-action models transfer web knowledge to robotic control},
  author={Brohan, Anthony and Brown, Noah and Carbajal, Justice and Chebotar, Yevgen and Chen, Xi and Choromanski, Krzysztof and Ding, Tianli and Driess, Danny and Dubey, Avinava and Finn, Chelsea and others},
  journal={arXiv preprint arXiv:2307.15818},
  year={2023}
}
@article{ramakrishnan2024does,
  title={Does Spatial Cognition Emerge in Frontier Models?},
  author={Ramakrishnan, Santhosh Kumar and Wijmans, Erik and Kraehenbuehl, Philipp and Koltun, Vladlen},
  journal={arXiv preprint arXiv:2410.06468},
  year={2024}
}
@article{nasiriany2024pivot,
  title={Pivot: Iterative visual prompting elicits actionable knowledge for vlms},
  author={Nasiriany, Soroush and Xia, Fei and Yu, Wenhao and Xiao, Ted and Liang, Jacky and Dasgupta, Ishita and Xie, Annie and Driess, Danny and Wahid, Ayzaan and Xu, Zhuo and others},
  journal={arXiv preprint arXiv:2402.07872},
  year={2024}
}
@inproceedings{minderer2022simple,
  title={Simple open-vocabulary object detection},
  author={Minderer, Matthias and Gritsenko, Alexey and Stone, Austin and Neumann, Maxim and Weissenborn, Dirk and Dosovitskiy, Alexey and Mahendran, Aravindh and Arnab, Anurag and Dehghani, Mostafa and Shen, Zhuoran and others},
  booktitle={European Conference on Computer Vision},
  pages={728--755},
  year={2022},
  organization={Springer}
}
@article{Qwen2VL,
  title={Qwen2-VL: Enhancing Vision-Language Model's Perception of the World at Any Resolution},
  author={Wang, Peng and Bai, Shuai and Tan, Sinan and Wang, Shijie and Fan, Zhihao and Bai, Jinze and Chen, Keqin and Liu, Xuejing and Wang, Jialin and Ge, Wenbin and Fan, Yang and Dang, Kai and Du, Mengfei and Ren, Xuancheng and Men, Rui and Liu, Dayiheng and Zhou, Chang and Zhou, Jingren and Lin, Junyang},
  journal={arXiv preprint arXiv:2409.12191},
  year={2024}
}
@article{deitke2024molmo,
  title={Molmo and pixmo: Open weights and open data for state-of-the-art multimodal models},
  author={Deitke, Matt and Clark, Christopher and Lee, Sangho and Tripathi, Rohun and Yang, Yue and Park, Jae Sung and Salehi, Mohammadreza and Muennighoff, Niklas and Lo, Kyle and Soldaini, Luca and others},
  journal={arXiv preprint arXiv:2409.17146},
  year={2024}
}
@article{zhang2022dino,
  title={Dino: Detr with improved denoising anchor boxes for end-to-end object detection},
  author={Zhang, Hao and Li, Feng and Liu, Shilong and Zhang, Lei and Su, Hang and Zhu, Jun and Ni, Lionel M and Shum, Heung-Yeung},
  journal={arXiv preprint arXiv:2203.03605},
  year={2022}
}
@misc{trimesh,
  title={{Trimesh}: A Python library for loading and using triangular meshes},
  author={Dawson-Haggerty, Michael},
  year={2019},
  howpublished={\url{https://github.com/mikedh/trimesh}}
}
@misc{mplib,
  title={{MPlib}: A Lightweight Motion Planning Library},
  author={Liu, Minghua and Gu, Jiayuan and Guo, Kolin and Lin, Xinsong},
  year={2021},
  howpublished={\url{https://github.com/haosulab/mplib}}
}
