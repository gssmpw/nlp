[
  {
    "index": 0,
    "papers": [
      {
        "key": "mousavian20196",
        "author": "Mousavian, Arsalan and Eppner, Clemens and Fox, Dieter",
        "title": "6-dof graspnet: Variational grasp generation for object manipulation"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "urain2023se",
        "author": "Urain, Julen and Funk, Niklas and Peters, Jan and Chalvatzaki, Georgia",
        "title": "Se (3)-diffusionfields: Learning smooth cost functions for joint grasp and motion optimization through diffusion"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "sundermeyer2021contact",
        "author": "Sundermeyer, Martin and Mousavian, Arsalan and Triebel, Rudolph and Fox, Dieter",
        "title": "Contact-graspnet: Efficient 6-dof grasp generation in cluttered scenes"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "fang2023anygrasp",
        "author": "Fang, Hao-Shu and Wang, Chenxi and Fang, Hongjie and Gou, Minghao and Liu, Jirong and Yan, Hengxu and Liu, Wenhai and Xie, Yichen and Lu, Cewu",
        "title": "Anygrasp: Robust and efficient grasp perception in spatial and temporal domains"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "murali2021same",
        "author": "Murali, Adithyavairavan and Liu, Weiyu and Marino, Kenneth and Chernova, Sonia and Gupta, Abhinav",
        "title": "Same object, different grasps: Data and semantic knowledge for task-oriented grasping"
      },
      {
        "key": "jang2017end",
        "author": "Jang, Eric and Vijayanarasimhan, Sudheendra and Pastor, Peter and Ibarz, Julian and Levine, Sergey",
        "title": "End-to-end learning of semantic grasping"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "tang2023task",
        "author": "Tang, Chao and Huang, Dehao and Meng, Lingxiao and Liu, Weiyu and Zhang, Hong",
        "title": "Task-oriented grasp prediction with visual-language inputs"
      },
      {
        "key": "li2024semgrasp",
        "author": "Li, Kailin and Wang, Jingbo and Yang, Lixin and Lu, Cewu and Dai, Bo",
        "title": "Semgrasp: Semantic grasp generation via language aligned discretization"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "chang2024text2grasp",
        "author": "Chang, Xiaoyun and Sun, Yi",
        "title": "Text2Grasp: Grasp synthesis by text prompts of object grasping parts"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "taunyazov2023grace",
        "author": "Taunyazov, Tasbolat and Lin, Kelvin and Soh, Harold",
        "title": "GRaCE: Optimizing Grasps to Satisfy Ranked Criteria in Complex Scenario"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "liu2024moka",
        "author": "Liu, Fangchen and Fang, Kuan and Abbeel, Pieter and Levine, Sergey",
        "title": "Moka: Open-vocabulary robotic manipulation through mark-based visual prompting"
      },
      {
        "key": "team2024octo",
        "author": "Team, Octo Model and Ghosh, Dibya and Walke, Homer and Pertsch, Karl and Black, Kevin and Mees, Oier and Dasari, Sudeep and Hejna, Joey and Kreiman, Tobias and Xu, Charles and others",
        "title": "Octo: An open-source generalist robot policy"
      },
      {
        "key": "brohan2023rt",
        "author": "Brohan, Anthony and Brown, Noah and Carbajal, Justice and Chebotar, Yevgen and Chen, Xi and Choromanski, Krzysztof and Ding, Tianli and Driess, Danny and Dubey, Avinava and Finn, Chelsea and others",
        "title": "Rt-2: Vision-language-action models transfer web knowledge to robotic control"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "weerakoon2024behav",
        "author": "Weerakoon, Kasun and Elnoor, Mohamed and Seneviratne, Gershom and Rajagopal, Vignesh and Arul, Senthil Hariharan and Liang, Jing and Jaffar, Mohamed Khalid M and Manocha, Dinesh",
        "title": "BehAV: Behavioral Rule Guided Autonomy Using VLMs for Robot Navigation in Outdoor Scenes"
      },
      {
        "key": "nasiriany2024pivot",
        "author": "Nasiriany, Soroush and Xia, Fei and Yu, Wenhao and Xiao, Ted and Liang, Jacky and Dasgupta, Ishita and Xie, Annie and Driess, Danny and Wahid, Ayzaan and Xu, Zhuo and others",
        "title": "Pivot: Iterative visual prompting elicits actionable knowledge for vlms"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "liu2024moka",
        "author": "Liu, Fangchen and Fang, Kuan and Abbeel, Pieter and Levine, Sergey",
        "title": "Moka: Open-vocabulary robotic manipulation through mark-based visual prompting"
      },
      {
        "key": "wu2024helpful",
        "author": "Wu, Qi and Fu, Zipeng and Cheng, Xuxin and Wang, Xiaolong and Finn, Chelsea",
        "title": "Helpful DoggyBot: Open-World Object Fetching using Legged Robots and Vision-Language Models"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "ramakrishnan2024does",
        "author": "Ramakrishnan, Santhosh Kumar and Wijmans, Erik and Kraehenbuehl, Philipp and Koltun, Vladlen",
        "title": "Does Spatial Cognition Emerge in Frontier Models?"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "liu2024moka",
        "author": "Liu, Fangchen and Fang, Kuan and Abbeel, Pieter and Levine, Sergey",
        "title": "Moka: Open-vocabulary robotic manipulation through mark-based visual prompting"
      }
    ]
  }
]