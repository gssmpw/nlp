%%%%%%%% ICML 2025 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2025} with \usepackage[nohyperref]{icml2025} above.
\usepackage{hyperref}


% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
\usepackage[preprint]{icml2025}

% If accepted, instead use the following line for the camera-ready submission:
% \usepackage[accepted]{icml2025}

% \usepackage{natbib}
% \bibliographystyle{abbrvnat}
% \setcitestyle{authoryear,open={(},close={)}} %Citation-related commands
% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\crefname{theorem}{theorem}{theorems}
\Crefname{Theorem}{Theorem}{Theorems}

\newtheorem{proposition}[theorem]{Proposition}
\crefname{proposition}{proposition}{propositions}
\Crefname{Proposition}{Proposition}{Propositions}

\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\crefname{corollary}{corollary}{corollaries}
\Crefname{Corollary}{Corollary}{Corollaries}

\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\crefname{definition}{definition}{definitions}
\Crefname{Definition}{Definition}{Definitions}

\newtheorem{assumption}[theorem]{Assumption}
\Crefname{assumption}{Assumption}{Assumptions}
\crefname{assumption}{assumption}{assumptions}

\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}
\crefname{remark}{remark}{remarks}
\Crefname{Remark}{Remark}{Remarks}


% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
\usepackage[disable,textsize=tiny]{todonotes}
%\usepackage[textsize=tiny]{todonotes}

\input{header2}
\input{def}
% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{DP guarantees of MCMC algorithms}

\begin{document}

\twocolumn[
\icmltitle{Differential privacy guarantees of Markov chain Monte Carlo algorithms}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2025
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
% \icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Andrea Bertazzi}{yyy}
\icmlauthor{Tim Johnston}{comp}
\icmlauthor{Gareth O. Roberts}{sch}
\icmlauthor{Alain Durmus}{yyy}
%\icmlauthor{}{sch}
%\icmlauthor{}{sch}
\end{icmlauthorlist}

\icmlaffiliation{yyy}{\'Ecole polytechnique, Institut Polytechnique de Paris, France}
\icmlaffiliation{comp}{Université Paris Dauphine - PSL, France}
\icmlaffiliation{sch}{University of Warwick, UK}

\icmlcorrespondingauthor{Andrea Bertazzi}{andrea.bertazzi@polytechnique.edu}


% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Differential privacy, MCMC algorithms}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
% \printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.

\begin{abstract}
This paper aims to provide differential privacy (DP) guarantees for Markov chain Monte Carlo (MCMC) algorithms. In a first part, we establish DP guarantees on samples output by MCMC algorithms as well as Monte Carlo estimators associated with these methods under assumptions on the convergence properties of the underlying Markov chain. In particular, our results highlight the critical condition of ensuring the target distribution is differentially private itself. In a second part, we specialise our analysis to the unadjusted Langevin algorithm and stochastic gradient Langevin dynamics and establish guarantees on their (Rényi) DP. To this end, we develop a novel methodology based on Girsanov's theorem combined with a perturbation trick to obtain bounds for an unbounded domain and in a non-convex setting. We establish: (i) uniform in $n$ privacy guarantees when the state of the chain after $n$ iterations is released, (ii) bounds on the privacy of the entire chain trajectory. These findings provide concrete guidelines for privacy-preserving MCMC.
\end{abstract}



\section{Introduction}
The framework of differential privacy (DP) \citep{dwork2006differential,Dwork_2006} has become the standard approach for designing statistical and machine learning algorithms with quantitative guarantees on the information that their output reveals about the data. In particular, the DP guarantees of Bayesian statistical methods have already been investigated in various works, typically focusing on the DP analysis of samples drawn from the posterior distribution associated with the data and problem at hand \citep{wang2015privacy,dimitrakakis_2016,geumlek2017renyi,hu2025privacyguaranteesposteriorsampling}. In practice,  Markov chain Monte Carlo (MCMC) algorithms are required to produce approximate samples from the posterior, and for this reason their DP guarantees have also been the object of extensive research \citep{heikkila2019differentially,yildirim2019exact,li2019connecting,chourasia2021differential,altschuler2022privacy,zhang2023dp}. 

Several works obtain DP of the one-step transitions of the MCMC algorithm by injecting extra noise in various ways, e.g. in the acceptance-rejection step of Metropolis-Hastings-type algorithms \citep{heikkila2019differentially,yildirim2019exact}, or leveraging the additional randomness already introduced by subsampling strategies \citep{wang2015privacy,bierkens2022federated}, optionally together with clipping of the gradient that drives the moves of the chain \citep{29314d8a28074bd7a58ae560f691f253,10.1145/2976749.2978318}. Many iterations of the MCMC chain are required to approach the posterior distribution, and the typical strategy to obtain guarantees on the DP of the algorithm after some number $n$ of iterations is to use composition bounds \citep{10.1145/2976749.2978318, pmlr-v97-wang19c, 10.1109/FOCS.2014.56}. However, the privacy implied using composition bounds for Markov chains naturally decays with the number of steps \citep{pmlr-v37-kairouz15} and as a consequence the injected noise must scale with the number of iterations in order to obtain uniform privacy bounds for the final draw. 
This limitation was recently addressed by e.g.,\citet{chourasia2021differential} and \citet{altschuler2022privacy}, who obtained uniform in time bounds on the (Rényi) DP of gradient descent-type algorithms. However, these results are limited to the strongly convex case or have bad dependence on the step-size and diameter of the state space.

% This issue was addressed by \citet{chourasia2021differential}, who used a PDE approach to bound the Rényi differential privacy \citep{Mironov_2017} of a noisy gradient descent algorithm uniformly in time. However, the approach of \citet{chourasia2021differential} depends on the log-Sobolev constant of the law of the algorithm, hence bounds could only be obtained in the strongly convex case. \citet{altschuler2022privacy} proposed an alternative approach yielding uniform-in-time bounds for stochastic gradient descent, but with a dependence on the inverse of the step size and the diameter of the state space that leads to poor privacy guarantees in the high-accuracy regime.


\paragraph{Contributions of this work}
In this paper we study the differential privacy of MCMC algorithms. The paper is divided in two parts.

In the first part (\Cref{sec:convergence_and_DP}) we consider general MCMC algorithms and establish a clear connection between the DP guarantees of the posterior distribution and of a corresponding MCMC algorithm. In particular, we find that the DP of the posterior is the crucial starting point to perform Bayesian inference. This fact is supported by \Cref{prop:tvdistance_lowerbound}, which shows that if the posterior has weaker DP guarantees than the MCMC algorithm, the law of the MCMC chain after $n$ iterations is far from the posterior in total variation distance.
This result emphasises the importance of starting with a differentially private model, a property that has been mostly neglected in the literature. The other results presented in \Cref{sec:convergence_and_DP} (\Cref{prop:geomerg_to_DP,prop:ergodic_average_mainresult}) assume DP of the posterior and use it to show $(\varepsilon,\delta)$-DP for the MCMC algorithm when we either release the $n$-th state of the chain or a (noisy) Monte Carlo estimator. These bounds are tight when the algorithm is close to equilibrium. 

In \Cref{sec:chara_difssuion}, we introduce a novel approach to establish $(\varepsilon,\delta)$-DP and Rényi-DP of the full path of an MCMC algorithm, or also only of its state after $n$ iterations, in a non-convex setting. Our approach, presented in \Cref{sec:approach_RadonNikodym}, is based on obtaining high probability bounds of the Radon-Nikodym derivative of the law of the output obtained for two different, adjacent datasets. In \Cref{subsec: DP of SDEs} we illustrate how this strategy can be applied to the case of MCMC algorithms based on diffusions, where we rely on Girsanov's theorem to express the Radon-Nikodym derivative. Our strategy of proof allows to obtain bounds for the entire trajectory of a variety of stochastic algorithms, significantly improving on known composition bounds. In particular, we show that the entire trajectory up to the $n$-th iteration is $(\varepsilon,\delta)$-DP, where $\varepsilon$ is $O(n+\sqrt{n\log(1/\delta)})$ and $\delta>0$ is constant, and also $(\alpha, \varepsilon)$-Rényi-DP with $\varepsilon=O(\alpha n)$ for $\alpha>0$ constant. Thanks to a careful perturbation technique, we are also able to apply our approach to the case where only the final state after $n$ iterations is released, and not the entire path. In this case, we obtain uniform in time guarantees both for DP and Rényi-DP.
We then specialise our analysis to two classical MCMC algorithms based on the Langevin diffusion: the unadjusted Langevin algorithm and its stochastic gradient variant (see \Cref{sec: privacy of stoch alg}). Leveraging our approach, we address the open problem of obtaining uniform in time DP guarantees in a non-convex setting. 

% To summarise, our main contributions are the following two observations:
% \begin{itemize}
%     \item rather than looking at the one-step privacy of an MCMC method and then applying a composition bound, it makes more sense to analyse the privacy of the target measure and prove that the MCMC method is close to it. In fact, as the number of steps goes to infinity the privacy of the MCMC method converges to the privacy of the target.
%     \item for MCMC methods based on diffusions, a particular thorough analysis of privacy (using Girsanov's theorem) can be given provided. In particular we show that for the entire trajectory the $(\varepsilon,\delta)$-DP grows like $\varepsilon=O(\sqrt{n})$ for $\delta>0$ constant, and that the $(\alpha, \varepsilon)$-Rényi DP grows with $\varepsilon=O(n)$ for $\varepsilon>0$ constant. This improves significantly on known composition bounds. Furthmore, using a particular `pertubation' trick to analyse the privacy of the final draw. Using these techniques we are able to obtain uniform in time privacy bounds in Rényi and $(\varepsilon, \delta)$-DP in a non-convex setting, which to the best of our knowledge has not yet been achieved in the literature
% \end{itemize}

% The results in Sections \ref{sec:preliminaries} and \ref{sec:convergence_and_DP} provide very general methods for ensuring the $(\varepsilon, \delta)$-privacy of MCMC algorithms when they are close to equilibrium. The bounds in Sections \ref{sec: Privacy of Diffusions} and \ref{sec: privacy of stoch alg} are uniform in time and distinguish the privacy of the entire chain from the final draw, however the setting is limited to algorithms with Gaussian transition kernels in a particular regime.

% We note that distinguishing the privacy of an entire MCMC chain with the privacy of the final draw has not been emphasised previously in the literature. However we believe this is an important thing to clarify, since one expects very different results for these two classifications. Furthermore in application (such as federated learning) it is not always realistic that an adversary would only be aware of the final step of an MCMC method.
%Our main result for the latter point can be informally stated as follows
%\begin{theorem}[Privacy of Non-Convex MCMC Diffusions - Informal]
 %   Under a suitable non-convex `convexity outside of a ball' condition, one has that MCMC based on diffusions, like ULA and SGD, are private in a manner that doesn't degenerate with the smallness of the stepsize or the number of steps. Furthermore, the privacy of the entire trajectory up to step $n$ is private in a manner which only depends on $n\gamma$, where $\gamma>0$ is the stepsize.
%\end{theorem}




\section{Preliminaries}\label{sec:preliminaries}
In Bayesian statistics, the primary object of interest is the posterior distribution of the parameter $\theta \in \rmE$ given an observed dataset $\dataset \in \mathcal{S}$. The posterior distribution, denoted as $\pi_\dataset$, is of the form 
\begin{equation}\label{eq:posterior}
    \pi_\dataset(\msb) =\left.  \int_{\msb} L_\dataset(\theta)\eta(\dd \theta) \middle/ {Z_\dataset}\right. \eqsp, \quad \msb \in \mathcal{B}(\rmE) \eqsp,
\end{equation}
where $(\rmE,\mcbb(\rmE))$ is a Borel space,  $L_\dataset(\theta)$ is the likelihood associated with $\dataset$, $\eta$ is a prior distribution for the parameter, and $Z_\dataset = \int_\rmE L_\dataset(\theta)\eta(\dd \theta) $.
In order to make practical use of the Bayesian framework, it is then essential to have access to key statistics of the posterior distribution, such as its moments. MCMC algorithms aim to solve this task relying on a Markov chain, $(\Xdatan)_{n\geq 1}$, which has law that converges to $\pi_\dataset$ asymptotically in the number of iterations $n$. Throughout the paper, we shall denote the transition kernel of the Markov chain as $P_\dataset:\rmE\times\mathcal{B}(\rmE) \to  [0,1 ]$, where this means $\Xdatan \sim P_\dataset(\Xdata_{n-1},\cdot)$ and also that $\Xdatan \sim P^n_\dataset(\Xdata_{0},\cdot)$, where $X^\dataset_{0}$ is the initial state of the chain. In particular, MCMC algorithms can be used to estimate expectations $\pidata(f):=\int_\rmE f(\theta) \pidata(\dd \theta)$, for some statistics $f : \rmE \to \rset$ thanks to associated  Monte Carlo averages  $ \frac1N \sum_{n=1}^N f(\Xdatan) $, in the sense that $ \lim_{N\to\infty}\frac1N \sum_{n=1}^N f(\Xdatan) =\pidata(f)$ \cite{robert2004monte}. There can be several possible outputs of an MCMC algorithm, such as the state of the chain at time $n$, $\Xdatan$,  the entire path up to time $n$, $(\Xdata_1,\dots,\Xdatan)$), or also the Monte Carlo estimator $\frac1N\sum_{n=1}^N f(\Xdatan)$. In either case, we can think of our MCMC methods as a randomised algorithm $\A(\dataset)$, that is a random function of the dataset.
We refer to \citet{rob_ros_mcmc_survey} for an introduction to the main concepts required to obtain (asymptotically) valid MCMC algorithms.

We refer to as randomized algorithm any function $\dataset  \mapsto \A(\dataset)$, such that $\A(\dataset)$ is a  random variable on a probability space $(\Omega, \mathbb{P},\mathcal{F})$.
The framework of differential privacy \citep{dwork2006differential} compares the output of a randomised algorithm obtained giving two adjacent datasets as input. 
Various notions of adjacency between datasets can be introduced, where the most popular considers adjacent any two datasets that differ in only one entry.
% typically requiring that $\rho(\dataset,\dataset')\leq 1$ for a chosen (pseudo) metric $\rho$, e.g. the Hamming distance $\rho(\dataset,\dataset')=\sum_{i=1}^n \1_{x_i\neq x'_i}$, where $\dataset = \{ x_i\}_{i=1}^n$ and $ \dataset' = \{  x_i'\}_{i=1}^n$. In the following, we say two datasets $\dataset,\dataset'$ are adjacent to indicate that $\rho(\dataset,\dataset')\leq 1$ but we do not specify the choice of metric.
Below we state the definition of differential privacy.
\begin{definition}\label{def:DP}
    A randomised algorithm $\A$ is $(\varepsilon,\delta)$-differentially private, for $\varepsilon,\delta \geq 0$, if for any measurable set $\msb\in\mathcal{B}(\rmE)$
    \begin{equation}\label{eq:DP}
        \mathbb{P}(\A(\dataset) \in \msb) \leq e^{\varepsilon} \,\mathbb{P}(\A(\dataset')\in \msb )+ \delta,
    \end{equation}
    for any pair of adjacent datasets $\dataset,\dataset'\in\mathcal{S}$.
    %, i.e. the cardinal of the symmetric differences between $\dataset$ and $\dataset'$ is at most two. In words, they differ in at most one instance.
\end{definition}
% Note that the statement \eqref{eq:DP} does not account for the the randomness of the dataset, but only of the additional randomness of the algorithm $\A.$

Following \Cref{def:DP}, we say that a posterior distribution is $(\varepsilon,\delta)$-differentially private when, for all measurable sets $\msb$, it holds that
\begin{equation}\label{eq:DP_posterior}
   \pi_\dataset(\msb )\leq e^{\varepsilon}\,\pi_{\dataset'}(\msb) + \delta ,
\end{equation}
for all adjacent datasets $\dataset,\dataset'.$
This is interpreted as a privacy guarantee of an i.i.d. sample from the posterior.
%In general, off-the-shelf Bayesian models can satisfy Equation \eqref{eq:DP_posterior} for suitable choices of $\rho$ and of the prior distribution $\eta$. An analysis of this is given in \citet{dimitrakakis_2016}, who define $\pi$ to be $(\varepsilon,\delta)$-differentially private under $\rho$ when 
%\begin{equation}
%    \pi(\msb\rvert \dataset) \leq e^{\varepsilon \rho(\dataset,\dataset')}\,\pi(\msb\rvert \dataset') + \delta\rho(\dataset,\dataset'). \label{eq:DP_posterior_rho}
%\end{equation}
%Clearly \eqref{eq:DP_posterior_rho} implies \eqref{eq:DP_posterior} with the same $\varepsilon$ and $\delta.$
% \begin{definition}
%     A randomised algorithm $\A$ is $(\varepsilon,\delta)$-differentially private under a pseudo-metric $\rho$ if for any measurable set $\msb$
%     \begin{equation}
%         \mathbb{P}(\A(\dataset) \in \msb\rvert \dataset) \leq e^{\varepsilon \rho(\dataset,\dataset')} \,\mathbb{P}(\A(\tilde \dataset)\in \msb\rvert \tilde \dataset) + \delta\rho(\dataset,\dataset').
%     \end{equation}
% \end{definition}
% Then, we shall say that a posterior distribution $\pi$ is $(\varepsilon,\delta)$-differentially private under $\rho$ when 
% \begin{equation}\label{eq:DP_posterior_rho}
%     \pi(\msb\rvert \dataset) \leq e^{\varepsilon \rho(\dataset,\dataset')}\,\pi(\msb\rvert \tilde \dataset) + \delta\rho(\dataset,\dataset')
% \end{equation}
% which is interpreted as a privacy guarantee of an i.i.d. sample from $\pi(\cdot\rvert \dataset)$, i.e. the randomised algorithm is $\A(\dataset)=\theta$ for $\theta \sim \pi(\cdot\rvert \dataset)$. 



A related notion of privacy that we consider in this article is that of \emph{Rényi differential privacy} \citep{Mironov_2017}. In order to introduce the Rényi-DP we first need to define the Rényi divergence. For $\alpha>1$ and two probability distributions, $P$ and $Q$, for which their Radon-Nikodym derivative is well defined, their Rényi divergence is 
\begin{equation}\label{eq:Rényi_divergence}
    \renyi_\alpha(P\rVert Q) := \frac{1}{\alpha-1} \log \PE_{Q} \left[ \left(\frac{\dd P}{\dd Q}\right)^\alpha\right]. 
\end{equation}
% A randomised algorithm $\A$ is said to be Rényi-differentially private when the Rényi-divergence between the law corresponding to two adjacent datasets, $\dataset,\dataset'$, is bounded. In the next definition, we denote the law of $\A(\dataset)$ as $P_{\A(\dataset)}$.
We then have the following definition.
\begin{definition}
    A randomised algorithm $\A$ is $(\alpha,\varepsilon)$-Rényi differentially private , $\varepsilon \geq 0$ and $\alpha >1$, if for all adjacent sets $\dataset,\dataset'$ it holds that $\renyi_\alpha(P_{\A(\dataset)}\rVert P_{\A(\dataset')})\leq \varepsilon.$
    % \begin{equation}
    %     \renyi_\alpha(P_{\A(\dataset)}\rVert P_{\A(\dataset')})\leq \varepsilon.
    % \end{equation}
\end{definition}
% When $\alpha\to 1$, the Rényi divergence converges to the KL divergence, that is
% \begin{equation}
%     \renyi_1(P\rVert Q) = \PE_{P} \left[ \log \frac{\dd P}{\dd Q}\right].
% \end{equation}
When $\alpha \to \infty$ we recover $(\varepsilon,0)$-DP.
Notice also that a $(\alpha,\varepsilon)$-Rényi-differentially private algorithm is also $(\varepsilon - \frac1{\alpha-1}\log \delta,\delta)$-differentially private for any $\delta\in(0,1)$ (see  Proposition 3 in \citet{Mironov_2017}). Similarly to \eqref{eq:DP_posterior}, we say a posterior distribution is $(\alpha,\varepsilon)$-Rényi-differentially private when $\renyi_\alpha(\pi_\dataset,\pi_{\dataset'})\leq \varepsilon$ for all adjacent datasets $\dataset,\dataset'$.

\section{From convergence to differential privacy}\label{sec:convergence_and_DP}

This section establishes the connection between the DP of an MCMC algorithm and its convergence to the posterior distribution. 

\subsection{Differential privacy of a Markov chain after $n$ steps}
Here we are interested in the following question: \emph{what is the relation between  the differential privacy of the $n$-th state of an MCMC algorithm, the differential privacy of the target distribution, and the total variation  distance between them?}

In order to address the question above, we consider the randomised algorithm $\A_s(\dataset) = X_n^\dataset$, where $(X_k^\dataset)_{k\in\nset}$ is a Markov chain with transition kernel $P_\dataset$ and that is initialised from a probability distribution $\nu_\dataset.$ The law of $X_n^\dataset$ is denoted as $\nu_\dataset P_\dataset^n(\cdot) := \int \nu_\dataset(\dd x) P_\dataset^n(x,\cdot)$.
If $\tvnorm{\cdot}$ denotes the total variation distance (see \Cref{def:tvdistance}), for two probability distributions $\mu_\dataset$, $\nu_\dataset$ that satisfy $\lVert \mu_\dataset - \nu_\dataset\rVert_{\TV} \leq \beta$, we have that $(\varepsilon,\delta)$-DP of $\mu_\dataset$ implies $(\varepsilon,\delta + \beta(e^\varepsilon+1))$-DP of $\mu_\dataset$ (see \Cref{prop:tv_distance_DP} in \Cref{sec:proof_prop_TV} for the proof of this result).
In the case of MCMC algorithms, the law of $\A(\dataset)$ depends on the number of iterations $n,$ and so will its total variation distance to $\pi_\dataset.$ Nevertheless, also in our case we can apply \Cref{prop:tv_distance_DP} to address the question above.
In this sense we make the following assumption, which requires a bound on the total variation distance that is uniform over datasets and decreasing in the number of iterations.

% \alain{think about the dependence on the data
% one idea is to make results from \url{https://arxiv.org/pdf/1909.00966} quantitative not to pay the price of the data size in the constants
% }
\begin{assumption}[Data-uniform convergence of the Markov chain]\label{ass:convergence_markovchain}
    Consider a family of transition kernels $\{P_\dataset:\rmE\times\mathcal{B}(\rmE)\to[0,1]:\, \dataset \in \mathcal{S}\}$ and a family of initial distributions  $\{ \nu_\dataset: \dataset\in\mathcal{S}\}$. 
    There exist a positive, decreasing function $\msr$ such that $\lim_{m\to\infty}\msr(m)=\underline r \geq 0$, and a constant $\zeta <\infty$ such that for all $\dataset \in \mathcal{S}$ and all $n\in\N$
    \begin{equation}\label{eq:uniform_convergence_chain}
        \lVert \nu_\dataset P^n_\dataset - \pi_\dataset\rVert_{\TV} \leq \zeta  \, \msr(n)\eqsp.
        % \lVert \nu_\dataset P^n(\cdot\rvert \dataset) - \pi(\cdot\rvert \dataset) \rVert_{V_\dataset} \leq C \rho^n \lVert \nu_\dataset(\cdot) - \pi(\cdot\rvert \dataset) \rVert_{V_\dataset}
    \end{equation}
    % where $\nu_\dataset P_\dataset^n(\cdot) = \int \nu_\dataset(\dd x) P_\dataset^n(x,\cdot)$ is the law after $n$ steps of the Markov chain with initial condition $\nu_\dataset$ and transition kernel $P_\dataset$. 
\end{assumption}

In particular, \Cref{ass:convergence_markovchain} requires that $\zeta$ and $\msr$ are independent of the dataset. The function $\msr$ is typically such that either $\lim_{m\to\infty} \msr(m) =\underline r = 0$, that is the when case the MCMC algorithm is asymptotically exact, or $\underline r > 0$, that is the case when the MCMC algorithm is biased, for instance as a result of using an unadjusted discretisation scheme of a continuous time process.
Under this assumption, we can obtain the following relations between the DP guarantees of $\A_s(\dataset)$ and $\pi_\dataset$.
\begin{proposition}\label{prop:geomerg_to_DP}
    % Suppose $\pi$ is $(\varepsilon,\delta)$-DP in the sense of \eqref{eq:DP_posterior} and 
    Consider the randomised algorithm $\A_s(\dataset) \sim \nu_\dataset P_\dataset^n$ and suppose \Cref{ass:convergence_markovchain} is verified. The following statements hold:
    \begin{enumerate}[wide,label=(\roman*)]
        \item If $\pi$ is $(\varepsilon,\delta)$-differentially private, then $\A_s(\dataset)$ is $(\varepsilon, \delta+\kappa \msr(n))$-differentially private with $\kappa = \zeta (e^\varepsilon+1).$
        \item If $\A_s(\dataset)$ is $(\varepsilon,\delta)$-differentially private for any $n$\,, then $\pi$ is $(\varepsilon,\delta+(1+e^{\varepsilon})\zeta \underline r)$-differentially private.
    \end{enumerate}
\end{proposition}
\begin{proof}
    The first statement is obtained applying \Cref{prop:tv_distance_DP}.
    The second statement follows applying \Cref{prop:tv_distance_DP} to obtain that $\pi_\dataset$ is $(\varepsilon,\delta + (1+e^{\varepsilon})\zeta  \, \msr(n))$-differentially private, then taking the limit as $n\to \infty$.
\end{proof}
The first statement is similar to Proposition 3 in \citet{wang2015privacy}. We note also that the second statement in \Cref{prop:geomerg_to_DP} is still valid when the convergence bound \eqref{eq:uniform_convergence_chain} is not data-uniform.

The following result is a simple consequence of the second statement in \Cref{prop:geomerg_to_DP}.
\begin{corollary}\label{cor:negativeresult_DP}
    Consider the randomised algorithm $\A_s(\dataset) \sim \nu_\dataset P_\dataset^n$ and suppose \Cref{ass:convergence_markovchain} is verified. Let $\varepsilon \geq 0$, $\delta\in [0,1)$, and $\delta'=\delta+(1+e^{\varepsilon})\zeta  \underline r$.
    If $\pi$ is not $(\varepsilon,\delta')$-differentially private, then there exists $n\in\N$ such that  $\A_s(\dataset)$ is \underline{not} $(\varepsilon,\delta)$-differentially private.
\end{corollary}
\begin{proof}
    The result holds by contradiction using the second statement in \Cref{prop:geomerg_to_DP}.
\end{proof}
\Cref{cor:negativeresult_DP} highlights the importance of starting with a differentially private posterior distribution. Indeed, any MCMC algorithm that is asymptotically exact, i.e. such that $\underline r = 0$, will fail to be $(\varepsilon,\delta)$-differentially private for some $n$ when the posterior itself is not $(\varepsilon,\delta)$-differentially private.


Finally, we obtain a lower bound for $\lVert \nu_\dataset P_\dataset^n - \pi_\dataset\rVert_{\TV}$ when $P_{\dataset}^n$ is $(\varepsilon,\delta_n)$-differentially private, while the target distribution is not $(\varepsilon,\delta)$-differentially private for some $\delta > \delta_n$. The result below shows that $P^n_\dataset$ can be very far from $\pi_\dataset$ (in TV distance) when $\delta$ is larger than $\delta_n$.
\begin{proposition}\label{prop:tvdistance_lowerbound}
    Let $\{P^n_\dataset:\dataset\in\mathcal{S}\}$ be a family of Markov kernels  and $\{\nu_\dataset:\dataset\in\mathcal{S}\}$ a family of initial distribution such that for any $n\geq 1$, the randomised algorithm $\A(\dataset) \sim \nu_{\dataset} P_{\dataset}^n$ is $(\varepsilon,\delta_n)$-differentially private, and let $\{\pi_\dataset:\dataset\in\mathcal{S}\}$ be a family of probability distributions that is \underline{not} $(\varepsilon,\delta)$-differentially private, where $\delta > \delta_n$. 
    Then, there exists a dataset $\dataset \in\mathcal{S}$ such that
    \begin{equation}\label{eq:LB_TV}
        \lVert \nu_{\dataset} P_\dataset^n - \pi_\dataset\rVert_{\TV} > \frac{e^{-\varepsilon}}{1+e^{-\varepsilon}} (\delta-\delta_n)\,.
    \end{equation}
    % Then, for every $\zeta\in(0,\delta - \delta_n)$ there exists a dataset $\dataset \in\mathcal{S}$ such that
    % \begin{equation}\label{eq:LB_TV}
    %     \lVert P_\dataset^n - \pi_\dataset\rVert_{\TV} > \min\{\zeta,e^{-\varepsilon}(\delta-\delta_n-\zeta)\} \,.
    % \end{equation}
\end{proposition}
\begin{proof}
    The statement follows by an application of \Cref{prop:tvdistance_lowerbound_general} in \Cref{sec:tvdistance_lowerbound}.
\end{proof}
The statement of \Cref{prop:tvdistance_lowerbound_general} in \Cref{sec:tvdistance_lowerbound} gives more insight than the statement above. Indeed, it shows that, for any pair of adjacent datasets $\dataset,\dataset'$ for which there exists a measurable set $\msb$ such that $\pi_\dataset(\msb) > e^\varepsilon \pi_{\dataset'}(\msb) + \delta$, \eqref{eq:LB_TV} holds for either $\dataset$ or $\dataset'$. This means that the $n$-th state of the MCMC algorithm can be far from the posterior distribution for numerous datasets.
In practice, a posterior distribution $\pi$ can violate $(\varepsilon,\delta)$-DP even for large $\varepsilon$ and $\delta$ unless it is carefully designed \citep{dimitrakakis_2016}. Hence, \Cref{prop:tvdistance_lowerbound} shows that it is essential to design $\pi$ carefully. 


\subsection{Differential privacy of Monte Carlo estimators}

We are now concerned with the task of releasing an estimate of an expectation $\pi_\dataset(f) :=\int_{\rmE} f(x) \pi_\dataset(\dd x)$ obtained running an MCMC algorithm for $N$ iterations. Specifically, 
we are given $f:\mathbb{R}^d\to \mathbb{R}$ and we simulate a Markov chain $X^\dataset$ with transition kernel $P_\dataset$ to obtain the ergodic average $\frac{1}{N} \sum_{n=1}^N f(X_n^\dataset)$. 
Similarly to the previous section, our strategy to obtain a DP guarantee will be based on an assumption that requires the ergodic average to be close to the truth, i.e. $\pi_\dataset(f)$. Moreover, it will also be necessary to add noise to the ergodic average since for large $N$ it converges to the true expectation of the observable, $\pi_\dataset(f),$ and hence an adversary could distinguish between two adjacent datasets based on the observed ergodic average.
To protect against an adversary we then consider the randomised algorithm
\begin{equation}\label{eq:ergodic_avg+noise}
    \A(\dataset) = \frac{1}{N} \sum_{n=1}^N f(X_n^\dataset) + L_\eta,
\end{equation}
where $L_\eta$ is a random variable that is independent of the chain $X^\dataset$ and should satisfy the following assumption.
\begin{assumption}\label{ass:privacy_noise}
    For any measurable set $\msb$, and any $a,b\in\mathbb{R}$ such that $\lvert a-b\rvert\leq \eta$, for $\eta >0$, there exist $(\varepsilon,\delta)$ such that
    \begin{equation}
        \mathbb{P}(a+L_\eta\in \msb) \leq e^{\varepsilon} \, \mathbb{P}(b+L_\eta\in \msb) + \delta.
    \end{equation}
\end{assumption}
This condition essentially requires that adding $L_\eta$ makes the release of scalars that are close to each other differentially private. A typical choice is to draw $L_\eta$ from the Laplacian distribution with scale parameter $\eta / \varepsilon$, which satisfies \Cref{ass:privacy_noise} with parameters $(\varepsilon,0)$ \citep{Dwork_2006}. 

In order to take advantage of \Cref{ass:privacy_noise}, we shall require that the ergodic averages corresponding to two Markov chains for two adjacent datasets $\dataset,\dataset'$ are $\eta$-close with high probability. 
Without such property, an adversary would be able to distinguish between two adjacent datasets based on the observed Monte Carlo estimator.
We formalise this requirement in the next assumption. 
\begin{assumption}\label{ass:closeness_chains}  
    Let $\{P^n_\dataset:\dataset\in\mathcal{S}\}$ be a family of Markov kernels  and $\{\nu_\dataset:\dataset\in\mathcal{S}\}$ a family of initial distributions and let $N\in\N$.
    There exist $\eta <\infty,$ $\tilde\delta\in(0,1)$ that are independent of $\dataset,\dataset'$, such that for any adjacent datasets $\dataset$ and $\dataset'$
    \begin{equation}\label{eq:closeness_chains}
        \mathbb{P}\left( \left\lvert \frac{1}{N} \sum_{n=1}^N f(X_n^\dataset)-\frac{1}{N} \sum_{n=1}^N f(X_n^{\dataset'}) \right\rvert \leq \eta \right) \geq 1-\tilde\delta\eqsp,
    \end{equation}
    for some joint processes $(\Xdatan,X^{\dataset'}_n)_{n=1}^N$ such that  $(\Xdatan)_{n=1}^N$ and $(X^{\dataset'}_n)_{n=1}^N$ are two Markov chains respectively with transition kernels $P_\dataset$ and $P_{\dataset'}$, and initial distributions $\nu_\dataset, \nu_{\dataset'}$.
\end{assumption}
Note that in  \Cref{ass:closeness_chains}, we do not suppose that $\Xdatan$ and $X^{\dataset'}_n$ are independent and  we can consider any coupling between $\nu_{\dataset}P_{\dataset}^n$ and $\nu_{\dataset'}P_{\dataset'}^n$.

In order to obtain a guarantee on the DP of $\A$, we shall assume that $L_\eta$ satisfies \Cref{ass:privacy_noise} with $\eta$ as given by \Cref{ass:closeness_chains}.
Notice that the variance of the noise injected in the output to achieve a fixed level of DP $\varepsilon$ increases with $\eta$. In particular, in the case of Laplacian noise we find 
$$\textnormal{Var}(\A(\dataset)) = \textnormal{Var}\left(\frac{1}{N} \sum_{n=1}^N f(X_n^\dataset)\right) + \frac{\eta}{\varepsilon_\eta}\eqsp.$$
Therefore, the variance of the injected noise scales linearly with $\eta$.

We are now ready to state our result, that is obtained applying a more general argument that holds for any algorithm of the type $\A(\dataset) = g_\dataset + L_\eta$, where $g_\dataset$ is a random function that depends on $\dataset$ (see \Cref{prop:dp_generalalgo_closehighprob} in \Cref{sec:general_result_ergoaverage}). 
\begin{proposition}\label{prop:erg_avg_general}
    % Let $\A$ be the randomised mechanism defined in \eqref{eq:ergodic_avg+noise} and s
    Suppose \Cref{ass:closeness_chains} holds for some $\eta$ and $\tilde\delta$, and that $L_\eta$ satisfies \Cref{ass:privacy_noise} with the same $\eta$. Then the randomised mechanism $\A$, defined in \eqref{eq:ergodic_avg+noise}, is $(\varepsilon,\delta+\tilde\delta)$-differentially private.
\end{proposition}
\begin{proof}
    The result follows applying \Cref{prop:dp_generalalgo_closehighprob}.
\end{proof}



Verifying \Cref{ass:closeness_chains} directly would require ad-hoc arguments. Therefore we now introduce two conditions that are sufficient to ensure that \Cref{ass:closeness_chains} holds. We start with a high-probability, non-asymptotic bound on the convergence of the ergodic average to the true value, $\pi_\dataset(f).$ 
\begin{assumption}\label{ass:nonasymptotic_convergence_MCavg}
    Let $\{P^n_\dataset:\dataset\in\mathcal{S}\}$ be a family of Markov kernels  and $\{\nu_\dataset:\dataset\in\mathcal{S}\}$ a family of initial distributions and    let $N\in\N$. Denote by $(\Xdatan)_{n=1}^N$ a Markov chain with transition kernel $P_\dataset$ for any $\dataset\in\mcs$. Assume that 
    there exist $\tilde\delta\in(0,1)$ and $C<\infty$ such that for any $\dataset \in \mcs$
    \begin{equation}\label{eq:nonasymptotic_convergence_MCavg}
        \PP \left(\left\lvert \frac{1}{N} \sum_{n=1}^N f(X_n^\dataset)-\pi_\dataset(f)\right\rvert \leq C \right) \geq  1-\tilde\delta.
    \end{equation}
\end{assumption}

This assumption can be typically verified using some mixing properties of the family of Markov kernels $\{P^n_\dataset:\dataset\in\mathcal{S}\}$, that should be uniform over $\dataset \in \mcs$ as stated in \Cref{ass:convergence_markovchain}; see e.g. \citet{paulin2015concentration,durmus2023rosenthal} and the reference therein.

Then, we require that the absolute value of the difference between $\pi_\dataset(f)$ and  $\pi_{\dataset'}(f)$ is bounded by a constant for any adjacent datasets $\dataset,\dataset'$. This ensures that the output $\A$ localises around similar values and thus can be private.  
\begin{assumption}\label{ass:posterior_expectations}
    There exists $\gamma_f<\infty$ such that
    \begin{equation}
        \lvert \pi_\dataset(f) - \pi_{\dataset'}(f) \rvert \leq \gamma_f,
    \end{equation}
    for any adjacent datasets $\dataset,\dataset'\in\mathcal{S}.$
\end{assumption}
We now state our main result of the section.
\begin{proposition}\label{prop:ergodic_average_mainresult}
    Suppose \Cref{ass:nonasymptotic_convergence_MCavg,ass:posterior_expectations} hold for some $C,\tilde \delta, \gamma_f$. Suppose also that $L_\eta$ satisfies \Cref{ass:privacy_noise} for $\eta =  2C  + \gamma_f$.
    Then the randomised mechanism $\A$ defined in \eqref{eq:ergodic_avg+noise} is $(\varepsilon,\delta+ 2\tilde\delta -\tilde\delta^2)$-differentially private.
\end{proposition}
\begin{proof}
The proof is based on showing that \Cref{ass:closeness_chains} holds under our assumptions. The details can be found in \Cref{sec:ergodic_average_mainresult}.
\end{proof}



\section{Characterising the Privacy of Diffusions}\label{sec: Privacy of Diffusions}
\label{sec:chara_difssuion}
In this section we describe our novel proof strategy to obtain DP guarantees of MCMC algorithms.

\subsection{Differential Privacy with Radon-Nikodym Derivatives}\label{sec:approach_RadonNikodym}
We shall start describing our approach considering an abstract randomised algorithm $\A (\dataset):\Omega\to \mathcal{X}$ on a probability space $(\Omega,\mcf,\PP)$, that should be interpreted as the output of an MCMC algorithm such as its $n$-th state or its full path up to the the $n$-th state. The distribution of $\A(\dataset)$ for any $\dataset\in\mcs$, denoted as $P_{\A(\dataset)}$, is defined for any measurable set $\msb\subset \mathcal{X}$ as $$P_{\A(\dataset)}^{\PP}(\msb) = \PP(\A(\dataset)\in \msb) \eqsp.$$
Our strategy to obtain DP of the mechanism $\mathcal{A}$ is based on a change of measure argument.
In particular, for every pair of adjacent datasets $\dataset, \dataset'\in \mathcal{S}$ we shall find a probability measure $\mathbb{Q}$ on $(\Omega, \mathcal{F})$ such that the law of $\mathcal{A}(\dataset)$ under $\mathbb{Q}$ is equal to the law of $\mathcal{A}(\dataset')$ under $\mathbb{P}$. This is to say,
\begin{equation}\label{eq: change of measure defn}
P_{\A(\dataset)}^{\PP} = P_{\A(\dataset')}^{\QQ} \eqsp.
    %\footnote{Here $\A(\dataset')^{-1}(\msb=\{\omega \in \Omega :\, \mathcal{A}(\dataset)^{-1}(\omega)\in \msb\}.$}
\end{equation}
Note that $\QQ$ depends on $\dataset,\dataset'$, but to avoid overloading the notation, we keep this dependence implicit.
When  $\mathbb{P}$ and $\mathbb{Q}$ are mutually absolutely continuous, we can define the Radon-Nikodym (RN) derivative $\frac{\dd \mathbb{Q}}{\dd \mathbb{P}}:\Omega\to\mathbb{R}$, together with its inverse $\frac{\dd \mathbb{P}}{\dd \mathbb{Q}}$. That is to say, for every random variable $Z:\Omega\to\mathcal{X}$ one has
\begin{equation}\label{eq: int wrt Q identity}
    \PE_{\mathbb{Q}}[Z]=\PE\biggr[Z\frac{\dd\mathbb{Q}}{\dd \mathbb{P}}\biggr] \eqsp,
\end{equation}
where $\PE_{\mathbb{Q}}$ denotes integration on $\Omega$ with respect to $\mathbb{Q}$, while $\PE$ denotes integration with respect to $\PP$. Since $\frac{\dd\mathbb{Q}}{\dd\mathbb{P}}$ is a mapping from the probability space, we can treat it as a random variable taking values in $\mathbb{R}$.

Now that we have set the framework, we can show how to obtain DP of $\A$ bounding the RN derivative with high probability.
\begin{lemma}\label{lem: epsilon delta privacy}
    Let $\mathcal{A}$ be a random mechanism and suppose for every two adjacent datasets there exists a measure $\mathbb{Q}$ such that \eqref{eq: change of measure defn} holds. Suppose furthermore for every such $\mathbb{Q}$ the Radon-Nikodym derivative, $\frac{\dd\mathbb{P}}{\dd\mathbb{Q}}$, is well defined, and also that
    \begin{equation}
        \PP \biggr(\frac{\dd \mathbb{P}}{\dd \mathbb{Q}}>e^\varepsilon\biggr)\leq \delta.
    \end{equation}
  Then, $\mathcal{A}$ is $(\varepsilon, \delta)$-differentially private.
  \end{lemma}
\begin{proof}
The proof follows by splitting the expectation of the relevant indicator function into regions where $\frac{\dd \mathbb{P}}{\dd \mathbb{Q}}$ is large and small. Full details can be found in Appendix \ref{subsec: proof of epsilon delta}.
\end{proof}
%We observe that the choice of $\mathbb{Q}$ is in general \textbf{not} unique, and choosing $\mathbb{Q}$ badly can lead to ineffective bounds. 

In the next section, we will rely on \Cref{lem: epsilon delta privacy} to obtain DP guarantees for diffusion-based MCMC algorithms, where the RN derivative can be obtained by Girsanov's theorem.
The following lemma is essentially a version of the data processing inequality.

\begin{lemma}\label{lem: data processing}
   Let $\mathcal{A}$ be a random mechanism and consider two constants $\alpha>1, \varepsilon >0$. Suppose for every $\dataset,\dataset'\in \mathcal{S}$ there exists a measure $\mathbb{Q}$ such that \eqref{eq: change of measure defn} holds. Suppose in addition that the Radon-Nikodym derivative $\frac{\dd \mathbb{P}}{\dd \mathbb{Q}}$ is well defined and
   \begin{equation}\label{eq: Rényi by expectation}
 \mathbb{E}\biggr [\biggr ( \frac{\dd \mathbb{P}}{\dd \mathbb{Q}}\biggr)^{\alpha-1}\biggr]\leq e^{(\alpha-1)\varepsilon}.
\end{equation}
   Then, $\mathcal{A}$ is $(\alpha, \varepsilon)$-Rényi differentially private.
\end{lemma}
\begin{proof}
The proof can be found in Appendix \ref{subsec: proof of data processing}.
\end{proof}
\begin{remark}
    For all results in this paper, bounds in $(\varepsilon, \delta)$-DP can be achieved by converting a Rényi-DP bound, as mentioned in \Cref{sec:preliminaries}. However, we presented \Cref{lem: epsilon delta privacy,lem: data processing} separately since \Cref{lem: data processing} applies more generally, and in particular does not require control of the tails of $\dd\mathbb{P}/\dd\mathbb{Q}$.
\end{remark}

% Observe that if the Radon-Nikodym derivative $\frac{d\mathbb{Q}}{d\mathbb{P}}$ is also well defined (so $\mathbb{P}$ and $\mathbb{Q}$ are absolutely continuous with respect to one another) one has that 
% \begin{equation}
%     \frac{d\mathbb{Q}}{d\mathbb{P}}=\biggr (\frac{d\mathbb{P}}{d\mathbb{Q}}\biggr)^{-1},
% \end{equation}
% and therefore by \eqref{eq: int wrt Q identity} one has 
% This is how we shall bound the Rényi divergence of $\mathbb{P}$ and $\mathbb{Q}$ in the following section. 

\subsection{Differential privacy of stochastic differential equations}\label{subsec: DP of SDEs}
In this section we shall consider the DP of random mechanisms $\A$ that involve the solution of a stochastic differential equation (SDE). We are particularly interested in two distinct random mechanisms generated by \eqref{eq: generic diffusion}: the single time evaluation $\mathcal{A}_s(\dataset)=X^{\dataset}_T $ taking values in $\mathbb{R}^d$, and also the whole path $\mathcal{A}_p(\dataset)=(X^{\dataset}_T)_{t\in [0,T]} $ taking values in $C([0,T],\mathbb{R}^d)$, that is the space of continuous functions on $[0,T]$ taking values in $\mathbb{R}^d$.

The general SDE we study is
\begin{align}\label{eq: generic diffusion}
    &\dd X^{\dataset}_t = f_\dataset(X^D_{\kappa(t)},\eta_{\kappa(t)})\dd t+\sqrt{2/\beta} \,\dd W_t, %\\
    % &X^\dataset_0=x_0\in \mathbb{R}^d.
\end{align}
with initial condition $X^\dataset_0=x_0\in \mathbb{R}^d.$
Here $W_t$ is Brownian motion, $f_\dataset:\mathbb{R}^d\times \mathcal{X}\to\mathbb{R}^d$ is a measurable function, $\kappa:[0,\infty)\to[0,\infty)$ is a function satisfying $\kappa(t)\leq t$, $(\eta_t)_{t\geq 0}$ is a stochastic process independent of $(W_t)_{t\geq 0}$ taking values in some space $\mathcal{X}$, and $\beta>0$ is an inverse temperature parameter that scales the noise. 
The function $\kappa$ allows us to consider discrete time approximations obtained e.g. applying the Euler scheme to a continuous time SDE. For instance, the choice $\kappa(t):=\gamma\lfloor t/\gamma\rfloor$ corresponds to the backwards projection onto the grid $\{n\gamma\}_{n\in\N}$. In this case one has that $X^\dataset_{n\gamma}$ is equal in law to the Markov chain $(x^\dataset_n)_{n\in\N}$
\begin{equation}
  x^\dataset_{n+1}=  x^\dataset_{n}+\gamma f_\dataset(x^\dataset_n,\eta_{n\gamma})+\sqrt{2\gamma/\beta}\,z_{n+1}\eqsp,
\end{equation}
and $(z_n)_{n\geq 1}$ is a sequence of independent standard normal random variables.
The process $(\eta_t)_{t\geq 0}$ allows us to consider additional sources of randomness, for instance the random mini-batches that give the stochastic gradient in the noisy SGD algorithm. 

\begin{remark}
    We assume that \eqref{eq: generic diffusion} has a unique strong solution. This holds when $\kappa$ is a projection onto a grid, and also when $\kappa(t)=t$ under weak conditions \citep{ZHANG20051805}.
\end{remark}

%In Sections ... below we shall choose $f=-\nabla U_{\dataset}(x)$ so as to sample from $\pi\sim e^{-U_\dataset(x)}$ via the unadjusted Langevin algorithm, and subsequently $f(x,\cdot,\dataset)=-\sum_{i\in \eta_{\kappa(t)}}\nabla l(x,d_i)$ for the SGD algorithm (where $\dataset=(d_1,...,d_n)$).

Now that we have set the framework, we are ready to give our result on the privacy of the entire trajectory of $X^\dataset$ up to a time $T>0$.
\begin{proposition}[Privacy of the path]\label{prop: dp of whole traj}
Consider the family of processes \eqref{eq: generic diffusion}. Suppose there exists $c>0$ such that for every adjacent datasets $\dataset,\dataset' \in \mathcal{S}$ and $x\in \mathbb{R}^d, \eta\in \mathcal{X}$ one has
\begin{equation}\label{eq: assumed discrep}
    \lvert f_\dataset(x,\eta)-f_{\dataset'}(x,\eta)\rvert\leq c \eqsp.
\end{equation}
Then for $\delta>0, \alpha\geq 1$ one has that the algorithm $\mathcal{A}_p(\dataset)=(X^{\dataset}_T)_{t\in [0,T]}$ is $(\varepsilon_\delta, \delta)$-differentially private and $(\alpha, \varepsilon_\alpha)$-Rényi differentially private for
\begin{equation}
    \varepsilon_\delta=C_1(T)/4+\sqrt{C_1(T)\log(1/\delta)},\;\;
    \varepsilon_\alpha=\alpha C_1(T) /4\eqsp,
\end{equation}
and $C_1(T)=c^2\beta T$.
\end{proposition}
\begin{proof}
    Fixing adjacent datasets $\dataset,\dataset' \in \mathcal{S}$, we use Girsanov's theorem to define a measure $\mathbb{Q}$ under which $(X^{\dataset'}_t)_{t\in [0,T]}$ is equal in distribution to $(X^{\dataset}_t)_{t\in [0,T]}$ under $\mathbb{P}$. Using bounds on the assumed discrepancy between the drifts \eqref{eq: assumed discrep}, we may control the RN derivative $\dd \mathbb{P}/\dd \mathbb{Q}$ in such a way as to obtain the result applying \Cref{lem: epsilon delta privacy,lem: data processing}. Full details are presented in \Cref{subsubsec: proof of privacy of path}.
\end{proof}


In the following result, we demonstrate that our proof strategy can be used to give privacy bounds for $\A_s(\dataset)$ that are uniform in $T>0$. We remark that the condition \eqref{eq: closeness condition} can be satisfied in non-convex settings, which to the best of our knowledge have not been addressed thus far in the literature.

\begin{proposition}[Privacy of the final value]\label{prop: pertubation trick}\label{prop: dp of final value}
Let $T>0$ and assume there exist constants $L,C,c>0$ such that for every adjacent datasets $\dataset, \dataset'\in \mathcal{S}$ one has
\begin{equation}\label{eq: drift assump}
    \lvert f_\dataset(x,s)-f_{\dataset'}(y,s)\rvert \leq L\lvert x-y\rvert+c\eqsp,
\end{equation}
and $(X_t^\dataset)_{t \in\ccint{0,T}}$ and $(X_t^{\dataset'})_{t \in\ccint{0,T}}$ are solutions of \eqref{eq: generic diffusion} with drifts $f_{\dataset}$ and $f_{\dataset'}$ respectively, driven by the same Brownian motion $(W_t){_t\geq 0}$, such that almost surely it holds that
\begin{equation}\label{eq: closeness condition}
   \sup_{t\in [0,T]} \lvert X^{\dataset}_t-X^{\dataset'}_t\rvert\leq C\eqsp.
\end{equation}
Then for $\delta>0, \alpha\geq 1$ one has that $\mathcal{A}_s(\dataset)=X^{\dataset}_T $ is $(\varepsilon_\delta, \delta)$-private and $(\alpha, \varepsilon_\alpha)$-Rényi private for
\begin{equation}
    \varepsilon_\delta=C_2/4+\sqrt{C_2\log(1/\delta)},\;\;
    \varepsilon_\alpha=\alpha C_2/4,
\end{equation}
where $C_2=\beta(C(L+1)+c)^2$.
\end{proposition}
\begin{proof}
    We fix a pair of adjacent datasets $\dataset,\dataset'\in \mathcal{S}$ and $T>0$, and define an auxiliary process $(Z_t)_{t\in [0,T]}$ satisfying
\begin{equation}
    Z_t=X^{\dataset}_t \; \text{for} \; t\in [0,T-1] ,\;\;\;\;\;\;Z_T=X^{\dataset'}_T.
\end{equation}
In particular, $Z_t$ is given by perturbing the dynamics of $X^{\dataset}_T$ on $t\in [T-1,T]$ in such a way that it approaches $X^{\dataset'}_T$. By the assumption that $X_t^\dataset$ and $X_t^{\dataset'}$ are almost surely close, one may define this perturbation in such a way that it is almost surely bounded. Therefore via Girsanov's theorem we can find a measure $\mathbb{Q}$ satisfying the assumptions of \Cref{lem: epsilon delta privacy,lem: data processing}. Full details are presented in \Cref{subsubsec: proof of dp of final value}.
\end{proof}


\section{Privacy of Langevin-based algorithms in the non-convex setting}\label{sec: privacy of stoch alg}
In this section we obtain (Rényi)-DP for both the trajectory and the final value of two Langevin-based MCMC algorithms: ULA and noisy SGD.
All bounds in this section are derived from \Cref{prop: dp of whole traj,prop: dp of final value}. 

\subsection{Sampling from Bayesian posteriors with ULA}
Consider a posterior distribution with density with respect to the Lebesgue measure on $\rset^d$ of the form
\begin{equation}\label{eq: Bayes post}
\pi_\dataset(x) \propto e^{-U_\dataset(x)},
\end{equation}
for $U_\dataset:\mathbb{R}^d\to\mathbb{R}$. We can approximately sample from $\pi_\dataset$ with ULA, that is the Markov chain
     \begin{align}\label{eq: ULA}
        x^\dataset_{n+1}= x^\dataset_n-\gamma\nabla U_\dataset(x^\dataset_n)+\sqrt{2\gamma}\, z_{n+1},
    \end{align}
    with initial condition $x^\dataset_0=x_0\in \mathbb{R}^d,$ and where $(z_n)_{n\geq 1}$ is a sequence of i.i.d. standard Gaussians on $\mathbb{R}^d$, and $\gamma>0$ is the step size. 
    ULA arises as the Euler discretisation of the overdamped Langevin diffusion and has been shown to be successful for sampling from Bayesian posteriors under a range of assumptions \citep{NIPS1992_f29c21d4, 0b5e028f-1a33-3fed-ae08-229fd5443c3f, articleula}.
    % ULA is essentially the Euler-Maruyama discretisation of the continuous time dynamics
    %  \begin{align}
    %         \dd X^{\dataset}_T&=-\nabla U_\dataset(X^{\dataset}_T)\dd t+\sqrt{2}\dd W_t,
    %     \end{align}
    % which is known to have invariant measure $\pi_\dataset$ under weak conditions. It has been shown to be successful for sampling from Bayesian posteriors under a range of assumptions \citep{NIPS1992_f29c21d4, 0b5e028f-1a33-3fed-ae08-229fd5443c3f, articleula}. 
    We shall consider the privacy of both the final draw $x^\dataset_n\in \mathbb{R}^d$, and of the entire chain $(x^\dataset_1,...,x^\dataset_n)\in \mathbb{R}^{dn}$, under a non-convex assumption on $U_\dataset$. The particular assumption we place upon the posterior in the following theorem is close to the convexity outside of a ball condition considered in \citet{efae5be7-f11b-336b-9773-33eaf5b19d54} and \citet{pmlr-v151-erdogdu22a}.
    \alain{clash of notation for $\mu$ and $c$ to be replaced by $c_V$ and $\mathtt{m}$}
    \begin{assumption}\label{ass:ULA_finalstate}
        Consider a posterior distribution \eqref{eq: Bayes post} and suppose for every dataset $\dataset\in \mathcal{S}$ one may write $ U_\dataset=V_\dataset+K$,
    where $V_\dataset,K:\mathbb{R}^d\to\mathbb{R}$ are  continuously differentiable functions. In addition suppose that there exists a constant $c>0$ such that 
   %\begin{equation}
 $\sup_{x\in\rset^d}  \lvert \nabla V_\dataset(x)\rvert \leq c.$
   %\end{equation}
   Furthermore, $\nabla K$ is $L$-Lipschitz, that is 
   $$\lvert \nabla K(x)-\nabla K(y)\rvert \leq L\lvert x-y\rvert,$$
   for all $x,y \in \mathbb{R}^d$,
   and also strongly convex, that is there exists $\mu>0$ such that for all $x,y \in \mathbb{R}^d$.
    \begin{equation}\label{eq: mon assumption K}
        \langle \nabla K(x)-\nabla K(y),x-y\rangle \geq \mu\Vert x-y\Vert^2.
    \end{equation}
    \end{assumption}
 \begin{theorem}\label{thm: Bayesian ULA}
 Suppose \Cref{ass:ULA_finalstate} holds and let $\A_s(\dataset) = x_n^\dataset$ be the $n$-th state of the ULA targeting $\pi_\dataset$ with step-size $\gamma \in (0,2\mu/L^2)$. Then, for $\delta>0$ and $\alpha\geq 1$, $\A_s(\dataset)$ is $(\varepsilon_\delta, \delta)$-differentially private and $(\alpha, \varepsilon_\alpha)$-Rényi differentially private for
\begin{equation}
    \varepsilon_\delta=C_3/4+\sqrt{C_3\log(1/\delta)},\;\;
    \varepsilon_\alpha=\alpha C_3/4,
\end{equation}
    where $C_3=c^2 (\frac{2(L+1)}{ \mu-\gamma L^2/2}+1)^2$.
 % Consider \eqref{eq: Bayes post}, and suppose for every pair of adjacent datasets $\dataset,\dataset' \in \mathcal{S}$ one may write\andrea{where is the data dependence here? Should it be $V_\dataset$?}
 %       \begin{equation}
 %       U_\dataset=V+K,\;\;\; U_{\dataset'}=V'+K 
 %  \end{equation}
 % for once continuously differentiable functions $V,V',K:\mathbb{R}^d\to\mathbb{R}$. Assume of $V, V',$ that there exists a constant $c>0$ such that 
 %   \begin{equation}
 %   \lvert \nabla V(\cdot)\rvert ,\;\lvert \nabla V'(\cdot)\rvert \leq c.
 %   \end{equation}
 %   Furthermore, assume $\nabla K$ is $L$-Lipschitz, that is 
 %   $$\lvert \nabla K(x)-\nabla K(y)\rvert \leq L\lvert x-y\rvert$$
 %   for all $x,y \in \mathbb{R}^d$,
 %   % \footnote{i.e. for all $x,y \in \mathbb{R}^d$ one has $$\lvert \nabla K(x)-\nabla K(y)\rvert \leq L\lvert x-y\rvert.$$} 
 %   and strongly convex, that is there exists $\mu>0$ such that 
 %    \begin{equation}\label{eq: mon assumption K}
 %        \langle \nabla K(x)-\nabla K(y),x-y\rangle \geq \mu\Vert x-y\Vert^2.
 %    \end{equation}
%    Then if one applies the ULA algorithm \eqref{eq: ULA} targeting $\pi_\dataset$ for step-size $\gamma \in (0,2\mu/L^2)$, one has that for $\delta>0, \alpha\geq 1$ the final draw $\A_s(\dataset) = x_n^\dataset$ is $(\varepsilon_\delta, \delta)$-differentially private and $(\alpha, \varepsilon_\alpha)$-Rényi differentially private for
% \begin{equation}
%     \varepsilon_\delta=C_3/4+\sqrt{C_3\log(1/\delta)},\;\;
%     \varepsilon_\alpha=\alpha C_3/4,
% \end{equation}
%     where $C_3=c^2 (\frac{2(L+1)}{ \mu-\gamma L^2/2}+1)^2$.
    \end{theorem}
    \begin{proof}
    The proof here uses Proposition \ref{prop: pertubation trick}. One considers a continuous time interpolation of the ULA algorithm \eqref{eq: ULA}, at which point it just suffices to show that the closeness condition \eqref{eq: closeness condition} holds for the continuous time interpolation. Full details are given in Appendix \ref{subsubsec: proof of ula}.
    \end{proof}

%The following Theorem allows us to bound the privacy of (single draws) from a wide variety of Bayesian posteriors that are not uniformly log-concave.
%\begin{theorem}
%\label{thm: Bayesian true density}
%    Consider a Bayesian posterior $\pi(\cdot\vert D) \sim e^{-U_D}$ for $U_D:\mathbb{R}^d\to\mathbb{R}$ once continuous differentiable, such that  one may write
 %        \begin{equation}
  %      U_D=V_D+K.
%    \end{equation}
%   and there exists a constant $c>0$ such that for all datasets $D$ one has 
 %   \begin{equation}
 %   \lvert \nabla V_D(\cdot)\rvert \leq c.
 %   \end{equation}
 %   Furthermore we assume $\nabla K$ is $L$-Lipschitz\footnote{i.e. for all $x,y \in \mathbb{R}^d$ one has $$\lvert \nabla K(x)-\nabla K(y)\rvert \leq L\lvert x-y\rvert.$$} and strongly convex, that is there exists $\mu>0$ such that 
  %  \begin{equation}\label{eq: mon assumption K}
   %     \langle \nabla K(x)-\nabla K(y),x-y\rangle \geq \mu\Vert x-y\Vert^2.
  %  \end{equation}

%    Then for $\delta>0, \alpha\geq 1$ one has that the true posterior is $(\varepsilon_\delta, \delta)$-private and $(\alpha, \varepsilon_\alpha)$-Rényi private for
%\begin{equation}
%    \varepsilon_\delta=C_3\sqrt{\log(1/\delta)},\;\;\;\;
%    \varepsilon_\alpha=\alpha C_3^2/2,
%\end{equation}
%where $C_3=c (\frac{2(L+1)}{ \mu}+1)$.
 %   \end{theorem}
  %  \begin{proof}
%    It is well known that one can construct an SDE (the overdamped Langevin dynamics) that has invariant measure $\pi(\cdot\vert D)$, such that under weak conditions the law of the solution to the SDE will converge to this SDE. Specifically one considers 
       
%where $X^D_0$ is independent of $(W_t)_{t\geq 0}$, so that using the assumptions it is possible to show for every adjacent $D,D'$
%\begin{equation}
%  \limsup_{s\to \infty}\lvert X^D_s-X^{D'}_s \rvert\leq \frac{2c}{\mu} .
%\end{equation}    
%The result then follows from Proposition \ref{prop: dp of final value}. Full details are in Appendix \ref{subsubsec: proof of bayesian density}.
 %   \end{proof}
    
  %  Now we may easily apply these techniques to show the privacy of the Unadjusted Langevin Algorithm (ULA) applied to sample from the posterior of $\pi$, that is the process
%     \begin{equation}\label{eq: ULA}
    %    x^D_{n+1}:=x^\dataset_n-\gamma\nabla U_D(x^\dataset_n)+\sqrt{2\gamma}z_{n+1}, \;\;\;x^D_0=x_0\in \mathbb{R}^d,
%    \end{equation}
 %   where $(z_n)_{n\geq 1}$ is a sequence of iid standard Gaussians on $\mathbb{R}^d$ and $\gamma>0$ is the stepsize. Note that ULA is simply the Euler scheme discretisation (of stepsize $\gamma>0$) of the overdamped Langevin dynamics \eqref{eq: unadjusted Langevin SDE}.
   

    
    Note that the above bound does \emph{not} depend on the number of steps. Furthermore, since recent analysis like \cite{pmlr-v178-chewi22a} suggests that ULA recovers the true posterior in Rényi divergence as $\gamma\to 0$ and $n\to \infty$, taking the limit as $\gamma\to 0$ in Theorem \ref{thm: Bayesian ULA} suggests that true posterior is differentially private with $C_3>0$ replaced with $C_4=c (\frac{2(L+1)}{ \mu}+1)$.
    
    Now we consider the privacy of the entire chain under slightly different assumptions.
    \alain{$c$ should be $c_U$}
    \begin{assumption}\label{ass:ULA_path}
        There exists a constant $c>0$ such that the posterior $ \pi_\dataset$ in \eqref{eq: Bayes post}  satisfies for any adjacent datasets $\dataset,\dataset' \in \mathcal{S}$ and all $x\in \mathbb{R}^d$
   \begin{equation}
       \lvert \nabla U_\dataset(x)-\nabla U_{\dataset'}(x)\rvert \leq c\eqsp.
   \end{equation}
    \end{assumption}
    Note that the following result places no requirement on the step size, but it does depend on the number of steps. 
    \begin{theorem}\label{thm: ULA full path}
    Suppose \Cref{ass:ULA_path} holds and let $\A_p(\dataset) =(x^\dataset_1,\dots,x^\dataset_n)$ be the path of ULA up to state $n\in\N$.
   % Suppose there exists a constant $c>0$ such that the posterior $ \pi_\dataset\sim e^{-U_\dataset}$ satisfies for any adjacent datasets $\dataset,\dataset' \in \mathcal{S}$ and all $x\in \mathbb{R}^d$
   % \begin{equation}
   %     \lvert \nabla U_\dataset(x)-\nabla U_{\dataset'}(x)\rvert \leq c.
   % \end{equation}
   % Let $\delta>0, \alpha\geq 1$.
    Then, for $\delta>0, \alpha\geq 1$, the algorithm $\A_p(\dataset)$ is $(\varepsilon_\delta, \delta)$-differentially private and $(\alpha, \varepsilon_\alpha)$-Rényi differentially private for
\begin{equation}
    \varepsilon_\delta=C_5(n)/4+\sqrt{C_5(n)\log(1/\delta)},\;\;
    \varepsilon_\alpha=\alpha C_5(n)/4\eqsp,
\end{equation}
    where $C_5(n)=n\gamma c^2$.
\end{theorem}
\begin{proof}
    We use the continuous time interpolation of \eqref{eq: ULA}, along with \Cref{prop: dp of whole traj}. Then since $(x^\dataset_1,...,x^\dataset_n)$ is equal in law to a mapping from $(X^{\dataset}_T)_{t\in [0,n\gamma]}$, the result follows from the data processing inequality (see Theorem 9 in \citet{6832827}).
\end{proof}
%\subsubsection{Example: Gaussian Likelihood With Non Log-Convex Prior}
%Let us consider a simple $1$-dimensional Bayesian model with Gaussian likelihood $p(x\vert \theta)\sim \mathcal{N}(\theta, \sigma^2)$, a prior $p(\theta)$ given by a non log-convex distribution (for instance bimodel) with bounded log-gradient, and bounded data. Here we use the standard Hamming distance to classify adjacent datasets. Specifically, if $p(\theta)\sim e^{-f(\theta)}$ for continuously differentiable $f:\mathbb{R}\to\mathbb{R}$ satisfying $\lvert \nabla f(\cdot)\rvert\leq c_1$, and $\dataset=(x_1,...,x_n)$ satisfies $\lvert x_i\rvert \leq c_2$ uniformly over all datasets, one has that the posterior distribution
%\begin{equation}
%\pi_\dataset(\theta)\sim \exp(-\sum_{i=1}^n(x_i-\theta)^2/\sigma^2)p(\theta),
%\end{equation}
%satisfies Theorem \ref{thm: convex sgd} for
%\begin{equation}
%    K(\theta)=\theta^2/\sigma^2+\sum_{i=2}^n(x_i-\theta)^2/\sigma^2,
%\end{equation}
%and 
%\begin{equation}
%    V(\theta)=-2x_1\theta/\sigma^2+f(\theta),
%    \end{equation}
%    \begin{equation}
 %   V'(\theta)=-2x_1'\theta/\sigma^2+f(\theta),
%\end{equation}
%so that $c=c_1+2c_2/\sigma^2$ and $\mu,L=2n/\sigma^2$. Furthermore, this setting satisfies Theorem \ref{thm: ULA full path} for $c=2c_2/\sigma^2$.

%One could choose $f$ for example as
%\begin{equation}
%    f(\theta)= \begin{cases}
%L(\theta+l_1)(\theta+l_2)(\theta+l_3)(\theta+l_4),\;\;\;\; \theta\in (-s,s)\\
%f(-s)+s\nabla f(-s)+\nabla f(-s)\theta, \;\;\theta\leq -s\\
%f(s)-s\nabla f(s)+\nabla f(s)\theta,\;\;\;\; \theta \geq s,
%\end{cases}
%\end{equation}
%where $L,s>0$ and $-s<l_1<...<l_4<s$ are parameters.

%One notes the boundedness assumption on the data is not an artifact of our proof, since in such a model data that is too large will always lead to a privacy violation. The assumption that data is bounded could be lifted by using the `metric privacy' definition given in \cite{JMLR:v18:15-257}, which allows for weaker privacy bounds when the data is further apart. 

\subsection{Noisy stochastic gradient descent}
In this section we study the DP of a stochastic-gradient variant of the ULA. This algorithm is essentially a noisy version of the stochastic gradient descent and can be used to minimise the loss function
\begin{equation}\label{eq: loss}
    \mathcal{L}_\dataset(x):=\frac{1}{m}\sum_{i=1}^m \ell(x, d_i)\eqsp,
\end{equation}
where we assumed the dataset is of the form $\dataset=\{d_1,...,d_m\}$.
The algorithm we consider is driven by the following Markov chain:
\begin{align}\label{eq: SGD}
        x^\dataset_{n+1}\!=x^\dataset_n- \frac{\gamma}{s} \!\!\sum_{i\in A_{n+1}}\!\!\! \nabla _x \ell(x^\dataset_n, d_i)+\!\sqrt{2\gamma/\beta} z_{n+1}\eqsp,
\end{align}
where $\ell:\mathbb{R}^d\times \mathcal{X}\to\mathbb{R}$, $(A_n)_{n\geq 1}$ is a sequence of independent random variables uniformly distributed on subsets of $\{1,...,m\}$ of size $s\leq m$, the step size is $\gamma>0$, and $(z_n)_{n\geq 1}$ is a sequence of i.i.d. standard Gaussians on $\mathbb{R}^d$, independent of $(A_n)_{n\geq 1}$. Here $\ell(x,d_i)$ is interpreted as the loss incurred for datum $d_i$. We remark that the algorithm \eqref{eq: SGD} is known in the MCMC literature as stochastic gradient Langevin dynamics \citep{welling2011bayesian}. 

% In this section we consider the task of optimising a loss function of the form
% \begin{equation}\label{eq: loss}
%     \mathcal{L}(\theta,\dataset):=\frac{1}{m}\sum_{i=1}^ml(\theta, x_i),
% \end{equation}
% where the dataset $\dataset=(x_1,...,x_m)$ takes values in a set $\mathcal{S}:=\mathcal{X}^m$ and $l:\mathbb{R}^d\times \mathcal{X}\to\mathbb{R}$ are functions. Now we give privacy bounds for both the entire chain and the final draw that hold in a non-convex setting. For each choice $\dataset\in \mathcal{X}^m$ of data we consider the Markov chain
% \begin{align}\label{eq: SGD}
%         x^\dataset_{n+1}=x_n- &\frac{\gamma}{s}\sum_{i\in A_{n+1}}\nabla _x l(x^\dataset_n, x_i)+\sqrt{2\gamma/\beta}z_{n+1},
% \end{align}
% with initial condition $x^\dataset_0=\theta_0\in \mathbb{R}^d,$ and where $(A_n)_{n\geq 1}$ is a sequence of independent random variables uniformly distributed on subsets of $\{1,...,m\}$ of size $s\leq m$, the step size is $\gamma>0$, and $(z_n)_{n\geq 1}$ is a sequence of i.i.d. standard Gaussians on $\mathbb{R}^d$, independent of $(A_n)_{n\geq 1}$.

In order to prove DP of the algorithm, we shall work under the following assumption on the loss function.
\begin{assumption}\label{ass:noisySGD_final}
    Consider the loss function \eqref{eq: loss}, where
    \begin{equation}
        \ell(x, d) = v(x,d)+k(x)\eqsp,
    \end{equation}
    for functions $v:\mathbb{R}^d\times \mathcal{S}\to\mathbb{R}$ and $k:\R^d \to \mathbb{R}$ that are once continuously differentiable. Furthermore, $\nabla k$ is $L$-Lipschitz and for $c,\mu>0$ one has $ \lvert \nabla_x v(x,d)\rvert \leq c$ for any $x\in\R^d$ and any datum $d$,
    as well as 
    \begin{equation}
        \langle \nabla k(x)-\nabla k(y),x -y\rangle\geq \mu \lVert x-y\rVert^2\eqsp.
    \end{equation}
\end{assumption}
We then have the following result.
\begin{theorem}\label{thm: non-convex sgd}
    % Consider the loss function \eqref{eq: loss}, and suppose for each $x\in \mathcal{X}$ one has that 
    % \begin{equation}
    %     l(\theta, x)=v(\theta,x)+k(\theta),
    % \end{equation}
    % for functions $v,k:\mathbb{R}^d\times \dataset\to\mathbb{R}$ that are once continuously differentiable such that $\nabla k$ is $L$-Lipschitz and for $c,\mu>0$ one has
    % \begin{equation}
    %     \lvert \nabla_x v(\theta, x)\rvert \leq C,
    % \end{equation}
    % and 
    % \begin{equation}
    %     \langle \nabla k(\theta_1)-\nabla k(\theta_2),\theta_1-\theta_2\rangle\geq \mu \Vert \theta_1-\theta_2\Vert^2.
    % \end{equation}
    Suppose \Cref{ass:noisySGD_final} holds and consider the algorithm $\A_s(\dataset) = x_n^\dataset$ described in \eqref{eq: SGD} with $\gamma\in (0,2\mu/L^2)$ and stochastic gradient of size $s\leq m$. Then, for $\delta>0$ and $\alpha\geq 1$, one has that $\A_s$ is $(\varepsilon_\delta, \delta)$-differentially private and $(\alpha, \varepsilon_\alpha)$-Rényi differentially private for
\begin{equation}
    \varepsilon_\delta=C_6/4+\sqrt{C_6\log(1/\delta)},\;\;\;\;
    \varepsilon_\alpha=\alpha C_6/4\eqsp,
\end{equation}
    where $C_6=c^2\beta(\frac{2(L+1)}{ \mu-\gamma L^2/2}+1)^2$.
\end{theorem}
\begin{proof}
    The proof here is similar to the proof of \Cref{thm: Bayesian ULA}, with minor alterations due to the stochastic gradient and the inverse temperature parameter $\beta>0$. Full details are given in Appendix \ref{subsubsec: proof of sgd non-convex}.
\end{proof}

\Cref{thm: non-convex sgd} is only a minor refinement of Theorem \ref{thm: Bayesian ULA}, and in particular the privacy guarantee does not improve with the size $m$ of the dataset. However, in the strongly convex case where each $\nabla v$ is constant, the following theorem (similar to Theorem 2 in \citet{chourasia2021differential}) shows that privacy does increase with $s\leq m$.
\begin{theorem}\label{thm: convex sgd}
    Consider the setting of Theorem \ref{thm: non-convex sgd}, but suppose that for any datum $d\in \dataset$ with $\dataset\in\mathcal{S}$ one has that $\nabla _x v(x,d)$ is constant in $x\in \mathbb{R}^d$. Then, for $\delta>0$ and $\alpha\geq 1$, one has that $\A_s$ is $(\varepsilon_\delta, \delta)$-differentially private and $(\alpha, \varepsilon_\alpha)$-Rényi differentially private for
\begin{equation}
    \varepsilon_\delta=C_7+\sqrt{C_7\log(1/\delta)},\;\;\;\;
    \varepsilon_\alpha=\alpha C_7/4\eqsp,
\end{equation}
    where $C_7=\frac{c^2\beta}{s^2} (\frac{2(L+1)}{ \mu-\gamma L^2/2}+1)^2$.
\end{theorem}
\begin{proof}
    The proof can be found in Appendix \ref{subsubsec: proof of sgd convex}.
\end{proof}

It is an open problem as to how $m$ and $s$ affect the privacy of the noisy SGD algorithm in the setting of \Cref{thm: non-convex sgd}. However, the following result on the path of noisy SGD improves with the size $s\leq m$ of the stochastic gradient.
\begin{theorem}\label{thm: path of SGD}
   Consider the loss function \eqref{eq: loss}, and suppose there exists $c>0$ such that for every $\dataset,\dataset' \in \mathcal{S}$ and $d\in \dataset, d'\in \dataset'$ one has that 
    \begin{equation}
        \lvert \nabla_x \ell(x, d)-\nabla_x \ell(x,d')\rvert \leq c.
    \end{equation}
    Then, for $\delta>0$ and $\alpha\geq 1$, the algorithm $\A_p(\dataset) = (x_1^\dataset,\dots,x_n^\dataset)$ shown in \eqref{eq: SGD} is $(\varepsilon_\delta, \delta)$-differentially private and $(\alpha, \varepsilon_\alpha)$-Rényi differentially private for
\begin{equation}
    \varepsilon_\delta=C_8+\sqrt{C_8\log(1/\delta)},\;\;\;\;
    \varepsilon_\alpha=\alpha C_8/4\eqsp,
\end{equation}
    where $C_8(n)=\frac{\beta c^2}{ s^2}n\gamma $.
\end{theorem}
\begin{proof}
    The proof is very similar to the proof of \Cref{thm: ULA full path}. Full details are given in \Cref{subsubsec: proof of sgd path}.
\end{proof}
The results of \citet{ryffel:hal-03547726} and \citet{10.5555/3600270.3600321} suggest that one may obtain superior bounds by fully exploiting the randomness of the stochastic gradient. However, for simplicity we do not consider this in the current work.

\subsection{Commentary on Bounds Presented}
We have studied two kinds of dimension-independent privacy guarantees: for the entire trajectory of an MCMC chain, and for the final draw. In the former case, we improved on known composition bounds. In particular, our $(\varepsilon,\delta)$-DP bounds in \Cref{thm: Bayesian ULA,thm: non-convex sgd} feature uniform values of $\delta>0$, and $\varepsilon=O(n+\sqrt{n\log(1/\delta)})$ dependence on the number of steps $n$, whilst the advanced composition bounds presented in \citet{pmlr-v37-kairouz15} achieve $\varepsilon=O(n+\sqrt{n\log(e+(\varepsilon \sqrt{n}/\delta))})$. This essentially matches bounds presented in \citet{chourasia2021differential}.
On the other hand, our bounds for the privacy of the final draw in \Cref{thm: Bayesian ULA,thm: non-convex sgd} are uniform in time in a non-convex setting on an unbounded space, which answers the open problem of question Question 1.1 in \citet{altschuler2022privacy}. Also, unlike the results of \citet{altschuler2022privacy}, our bounds do not depend on the size of the state space (which is unbounded), and do not blow up as the step-size goes to $0$. In this sense, we therefore generalise the results of \citet{chourasia2021differential} to a non-convex setting. Indeed, our results match \citet{chourasia2021differential} in the strongly convex regime. 

\section{Conclusions}
We have presented a variety of results on the differential privacy of MCMC algorithms. Our results clarify the importance of choosing a Bayesian posterior distribution that has good DP guarantees, or else an MCMC algorithm cannot be expected to both private and close to convergence. Our results imply that it is crucial to design the MCMC algorithm together with the Bayesian model, in order to allow an end-to-end private inference.
We have also discussed a novel approach to prove DP based on bounding the Radon-Nikodym derivative of the algorithm. This strategy allowed us to obtain new non-convex results that extend the known privacy properties of Langevin-based MCMC algorithm. We expect that a more careful analysis could allow extensions of our results to more general assumptions on the posterior distribution.
Our approach can be applied to very general randomised algorithms and not only to those considered in this article. We leave extensions to more complex settings such as Bayesian federated learning for future work.


% Acknowledgements should only appear in the accepted version.
\section*{Acknowledgements}
All authors acknowledge funding by the European Union (ERC-2022-SyG, 101071601). Views and opinions expressed are however those of the authors only and do not necessarily reflect those of the European Union or the European Research Council Executive Agency. Neither the European Union nor the granting authority can be held responsible for them.
Gareth O. Roberts has been supported by the UKRI grant EP/Y014650/1 as part of the ERC Synergy project OCEAN,  EPSRC grants Bayes for Health (R018561), CoSInES (R034710), PINCODE (EP/X028119/1), ProbAI (EP/Y028783/1) and EP/V009478/1.

We thank Mengchu Li and Shenggang Hu for the useful discussions.

\section*{Impact Statement}

This paper presents work whose goal is to advance the field of 
Machine Learning. There are many potential societal consequences 
of our work, none which we feel must be specifically highlighted here.

\bibliography{bibliography}
\bibliographystyle{icml2025}

\newpage
\appendix
\onecolumn

\section{Proofs and general results for \Cref{sec:convergence_and_DP}}

In this section we give proofs and general statements relative to \Cref{sec:convergence_and_DP}. These rely on the following definition.

\begin{definition}\label{def:tvdistance}
    Let $\mu$ and $\nu$ be two probability distributions on $(\rmE,\mcbb(\rmE))$. Their total variation (TV) distance is 
    \begin{equation}
        \tvnorm{\mu - \nu} := \sup_{\msb\in\mcbb(\rmE)} \lvert \mu(\msb) - \nu(\msb)\rvert.
    \end{equation}
\end{definition}

\subsection{Auxiliary result for \Cref{prop:geomerg_to_DP}}\label{sec:proof_prop_TV}
The following result is analogous to Proposition 12 in \citet{NIPS2016_a7aeed74}.
\begin{proposition}\label{prop:tv_distance_DP}
    Let $\{\mu_\dataset:\dataset\in\mathcal S\}$ and $\{\nu_\dataset:\dataset\in\mathcal S\}$ that satisfy $\lVert \mu_\dataset - \nu_\dataset\rVert_{\TV} \leq \beta$ for any $\dataset\in\mathcal{S}$. If $\mu$ is $(\varepsilon,\delta)$-differentially private, then $\nu$ is $(\varepsilon,\delta + \beta(e^\varepsilon+1))$-differentially private.
\end{proposition}
\begin{proof}
    Let $\dataset,\dataset' \in \mathcal{S}$ denote two adjacent datasets and $\msb$ be a measurable set. First, we observe that under our assumption and by the definition of the total variation distance we have $\lvert\mu_\dataset (\msb)- \nu_\dataset (\msb) \rvert \leq \beta.$
    This implies following inequalities for any $\dataset$:
    \begin{align}
        \mu_\dataset (\msb )  & \leq  \nu_\dataset(\msb) +  \beta, \label{eq:fromTV_1} \\
        \nu_\dataset(\msb) & \leq \mu_\dataset (\msb) +  \beta. \label{eq:fromTV_2}
    \end{align}
   Using these inequalities as well as the $(\varepsilon,\delta)$-DP of $\mu$, we find that
    \begin{align}
        \nu_\dataset (\msb ) &\leq \mu_\dataset(\msb) + \beta\\
        & \leq e^\varepsilon \mu_{\dataset'}(\msb) + \delta + \beta \\
        & \leq e^\varepsilon \left(\nu_{\dataset'}(\msb) + \beta  \right) + \delta + \beta,
    \end{align}
    which concludes the proof.
\end{proof}

\subsection{General result for \Cref{prop:tvdistance_lowerbound}}\label{sec:tvdistance_lowerbound}
\begin{proposition}\label{prop:tvdistance_lowerbound_general}
    Let $\{\mu_\dataset:\dataset\in\mathcal S\}$ and $\{\nu_\dataset:\dataset\in\mathcal S\}$ be two families of probability distributions.  Assume $\{\nu_\dataset:\dataset\in\mathcal S\}$ is $(\varepsilon,\delta_\nu)$-differentially private and $\{\mu_\dataset:\dataset\in\mathcal S\}$ is \underline{not} $(\varepsilon,\delta_\mu)$-DP for $\delta_\mu>\delta_\nu$, i.e. there exists at least one pair of adjacent datasets $\dataset,\dataset'\in\mathcal{S}$ for which there is a measurable set $\msb$ such that
    \begin{equation}\label{eq:munotDP}
        \mu_{\dataset'}(\msb) > e^{\varepsilon}\mu_\dataset(\msb)  + \delta_\mu\eqsp.
    \end{equation} 
    Define the set of pairs of adjacent datasets for which \eqref{eq:munotDP} holds:
    \begin{equation}
        \overline{\mathcal{S}} := \{(\dataset,\dataset')\in\mathcal{S}\times\mathcal{S}: \dataset,\dataset' \text{ are adjacent and there exists  }\msb \text{ such that }\eqref{eq:munotDP} \text{ holds}\}.
    \end{equation}
    Then, for any pair $(\dataset,\dataset') \in \overline{\mathcal{S}}$ there exists $\tilde\dataset\in(\dataset,\dataset')$ such that
    \begin{equation}
        \lVert \nu_{\tilde\dataset} - \mu_{\tilde\dataset} \rVert_{\TV}  > \frac{e^{-\varepsilon}}{1+e^{-\varepsilon}} (\delta_\mu-\delta_\nu) \eqsp.
    \end{equation}
\end{proposition}
\begin{proof}
    We take any two adjacent datasets $(\dataset,\dataset')\in\overline{\mathcal{S}}$. Notice that \eqref{eq:munotDP} implies that
    \begin{align}
            \mu_\dataset(\msb) &< e^{-\varepsilon} \mu_{\dataset'}(\msb) - e^{-\varepsilon}\delta_\mu\eqsp. 
    \end{align}
    Moreover, $(\varepsilon,\delta_\nu)$-DP of $\nu$ means that
    \begin{align}
        \nu_\dataset(\msb) & \geq e^{-\varepsilon} \nu_{\dataset'}(\msb) - e^{-\varepsilon}\delta_\nu\eqsp.
    \end{align}
    Using both inequalities we find
    \begin{align}
        \mu_\dataset(\msb) - \nu_\dataset(\msb) & \leq - (e^{-\varepsilon}\delta_\mu - e^{-\varepsilon}\delta_\nu) + e^{-\varepsilon} \mu_{\dataset'}(\msb) - e^{-\varepsilon} \nu_{\dataset'}(\msb) \\
        & \leq -  (e^{-\varepsilon}\delta_\mu - e^{-\varepsilon}\delta_\nu) + e^{-\varepsilon} (\mu_{\dataset'}(\msb) - \nu_{\dataset'}(\msb))\eqsp.
    \end{align}
    Suppose now that $\lVert \mu_{\dataset'} - \nu_{\dataset'}\rVert_\TV \leq \zeta$ for some constant $0<\zeta < \delta_\mu -\delta_\nu$. This implies that $\mu_{\dataset'}(\msb) - \nu_{\dataset'}(\msb) \leq \zeta$.
    Therefore, we find
    \begin{align}
        \mu_\dataset(\msb) - \nu_\dataset(\msb)  < - e^{-\varepsilon}(\delta_\mu -\delta_\nu - \zeta)\eqsp.
    \end{align}
    Since the right hand side is negative by construction, taking the absolute value we find
    \begin{equation}
         \lvert \mu_\dataset(\msb) - \nu_\dataset(\msb) \rvert  \geq e^{-\varepsilon}(\delta_\mu -\delta_\nu - \zeta)\eqsp.
    \end{equation}
    By the definition of TV distance we find
    \begin{equation}
        \lVert \mu_\dataset - \nu_\dataset\rVert_{\TV} \geq  \lvert \mu_\dataset(\msb) - \nu_\dataset(\msb) \rvert > e^{-\varepsilon}(\delta_\mu -\delta_\nu - \zeta)\eqsp.
    \end{equation}
    This shows that there always exists a dataset $\tilde \dataset \in \{\dataset,\dataset'\}$ such that
    \begin{equation}
        \lVert \mu_{\tilde \dataset } - \nu_{\tilde \dataset } \rVert_{\TV} > \min\{\zeta,e^{-\varepsilon} \left(\delta_\mu - \delta_\nu - \zeta\right) \}\eqsp.
    \end{equation}
    Optimising the bound for $\zeta \in (0,\delta_\mu-\delta_\nu)$ we find $\zeta^* = \frac{e^{-\varepsilon}}{1+e^{-\varepsilon}} (\delta_\mu-\delta_\nu),$ which satisfies the equation $\zeta^* = e^{-\varepsilon} (\delta_\mu - \delta_\nu - \zeta^*).$
\end{proof}


\subsection{General result for \Cref{prop:erg_avg_general}}\label{sec:general_result_ergoaverage}
Consider the randomised algorithm
\begin{equation}\label{eq:algo_ergoavg_general}
    \A(\dataset) = g_\dataset + L,
\end{equation}
where $g_\dataset$ is a random variable that depends on the dataset, and $L$ satisfies \Cref{ass:privacy_noise} and is independent of $g_\dataset$.
We make the following assumptions, which is the general version of \Cref{ass:closeness_chains}.
\begin{assumption}\label{ass:closeness_chains_general}  
    Let $\dataset,\dataset'\in \mathcal{S}$ denote two adjacent datasets.
    There exist $\eta>0,\delta<1$ that are independent of $\dataset,\dataset'$ such that
    \begin{equation}\label{eq:closeness_chains}
        \mathbb{P}\left( \left\lvert g_\dataset - g_{\dataset'} \right\rvert \leq \eta \right) \geq 1-\tilde\delta\eqsp.
    \end{equation}
    % uniformly over all adjacent datasets $\dataset,\dataset'.$
\end{assumption}
\Cref{ass:privacy_noise} and \Cref{ass:closeness_chains_general} are enough to obtain the following guarantee on the differential privacy of the randomised algorithm \eqref{eq:algo_ergoavg_general}.
\begin{proposition}\label{prop:dp_generalalgo_closehighprob}
    Let $\A$ be the randomised mechanism defined in \eqref{eq:algo_ergoavg_general}, where $L$ is independent of $g_\dataset$ for any $\dataset\in\mathcal{S}.$ Suppose \Cref{ass:closeness_chains_general} holds, as well as \Cref{ass:privacy_noise} for $\eta$ as in \Cref{ass:closeness_chains_general}. Then $\A$ is $(\varepsilon,\tilde\delta+\delta)$-differentially private.
\end{proposition}
\begin{proof} 
    Let $\msb$ be any measurable set. We find
    \begin{align}\label{eq:proof_ergoaverage_general}
        \mathbb{P} \left( \A(\dataset)\in \msb\right) &=\mathbb{P} \left( \A(\dataset)\in\msb, \left\lvert g_\dataset - g_{\dataset'} \right\rvert\leq \eta \right)  + \mathbb{P} \left( \A(\dataset)\in\msb, \left\lvert g_\dataset - g_{\dataset'} \right\rvert > \eta \right).
    \end{align}
    The first term on the right hand side of \eqref{eq:proof_ergoaverage_general} can be bounded using \Cref{ass:privacy_noise}. Indeed, \Cref{ass:privacy_noise} can be used since we are on the event $\left\lvert g_\dataset - g_{\dataset'} \right\rvert\leq \eta$ and because $L$ and $g_{\dataset},g_{\dataset'}$ are independent. Following this reasoning, we find
    \begin{align}
        \mathbb{P} \left( g_\dataset + L\in\msb, \left\lvert g_\dataset - g_{\dataset'} \right\rvert\leq \eta \right)  &\leq e^{\varepsilon} \mathbb{P} \left( g_{\dataset'} + L\in\msb, \left\lvert g_\dataset - g_{\dataset'} \right\rvert\leq \eta \right) + \delta \\
        & \leq e^{\varepsilon} \PP(\A(\dataset')\in \msb)+ \delta.
    \end{align}
    In the last inequality we simply discarded the event $\{\left\lvert g_\dataset - g_{\dataset'} \right\rvert\leq \eta\}.$
    Applying \Cref{ass:closeness_chains_general} we can bound the second term in \eqref{eq:proof_ergoaverage_general} as follows:
    \begin{equation}
        \mathbb{P} \left( \A(\dataset)\in\msb, \left\lvert g_\dataset - g_{\dataset'} \right\rvert > \eta \right)  \, \leq \, \mathbb{P} \left(\left\lvert g_\dataset - g_{\dataset'} \right\rvert > \eta \right) \, \leq \, \tilde\delta.
    \end{equation}
    We have obtained the result.
\end{proof}

\subsection{Proof of \Cref{prop:ergodic_average_mainresult}}\label{sec:ergodic_average_mainresult}
Let $\dataset,\dataset'\in \mathcal{S}$ be two adjacent datasets.
We introduce a joint process $(\Xdatan,X^{\dataset'}_n)_{n=1}^N$ such that  $(\Xdatan)_{n=1}^N$ and $(X^{\dataset'}_n)_{n=1}^N$ are two independent Markov chains respectively with transition kernels $P_\dataset$ and $P_{\dataset'}$, and initial distributions $\nu_\dataset, \nu_{\dataset'}$.
We now define two sets, $\msb_1$ and $\msb_2$, that represent respectively \Cref{ass:nonasymptotic_convergence_MCavg} and \Cref{ass:closeness_chains}:
    \begin{align}
        \msb_1 &  := \left\{ \left\lvert \frac{1}{N} \sum_{n=1}^N f(X_n^{\tilde \dataset})-\pi_{\tilde \dataset}(f)\right\rvert \leq C_{\tilde\delta,N}, \text{ for } \tilde \dataset = \dataset,\dataset' \right\}
    \end{align}
    and 
    \begin{align}
        \msb_2:=\left\{ \left\lvert \frac{1}{N} \sum_{n=1}^N f(X_n^\dataset)-\frac{1}{N} \sum_{n=1}^N f(X_n^{\dataset'}) \right\rvert \leq 2C_{\tilde\delta,N} + \gamma_f \right\}.
    \end{align}
    Now notice that $\msb_1\subset\msb_2$ under our assumptions, and hence $\PP(\msb_2) \geq \PP(\msb_1)$. Indeed, an application of \Cref{ass:posterior_expectations} gives
    \begin{align}
        \left\lvert \frac{1}{N} \sum_{n=1}^N f(X_n^\dataset)-\frac{1}{N} \sum_{n=1}^N f(X_n^{\dataset'}) \right\rvert & \leq \left\lvert \frac{1}{N} \sum_{n=1}^N f(X_n^\dataset)- \pi_{\dataset}(f)\right\rvert  + \left\lvert \pi_{\dataset}(f)-\pi_{\dataset'}(f) \right\rvert  + \left\lvert \frac{1}{N} \sum_{n=1}^N f(X_n^{\dataset'})- \pi_{\dataset'}(f)\right\rvert  \\
        & \leq 2C_{\tilde\delta,N} + \gamma_f\,.
    \end{align}
    Then, notice that, since the two chains are independent, we find 
    \begin{align}
        \PP(\msb_1) & = \PP\left( \left\lvert \frac{1}{N} \sum_{n=1}^N f(X_n^{\dataset})-\pi_{\dataset}(f)\right\rvert \leq C_{\delta,N} \right)  \PP\left( \left\lvert \frac{1}{N} \sum_{n=1}^N f(X_n^{\dataset'})-\pi_{\dataset'}(f)\right\rvert \leq C_{\tilde\delta,N} \right).
    \end{align}
    Hence, by \Cref{ass:nonasymptotic_convergence_MCavg} 
    \[\PP(\msb_1) \geq (1-\tilde\delta)^2 = 1 - (2\tilde\delta - \tilde\delta^2).\]
    Therefore, we have obtained $\PP(\msb_2) \geq  1 - (2\tilde\delta - \tilde\delta^2).$ The result then follows by \Cref{prop:dp_generalalgo_closehighprob}.
    
\section{Proofs and auxiliary results for \Cref{sec: Privacy of Diffusions}}

\subsection{Proof of Lemma \ref{lem: epsilon delta privacy}}\label{subsec: proof of epsilon delta}
Consider a measurable set $\msb  \subset \mathcal{X}$ and denote $X = \A(\dataset)$, $Y=\A(\dataset')$. Let us introduce the set where the Radon-Nikodym derivative is larger than a constant $e^\varepsilon$ as
\begin{equation}
    \msk_\varepsilon \coloneqq \left\{\omega:\frac{\dd \PP}{\dd \mathbb{Q}} (\omega) > e^{\varepsilon} \right\}.
\end{equation}
Then we can decompose $\PP(X\in \msb)$ as
\begin{align}
    \PP(X\in \msb) & = \PE[\1_{X\in \msb} \1_{\msk_\varepsilon}] + \PE[\1_{X\in \msb} \1_{\msk_\varepsilon^c}].
\end{align}

Hence, since by assumption we can control the Radon-Nikodym derivative with high probability, in the sense that $\PP\left(\msk_\varepsilon \right) \leq \delta$,
we find that 
\begin{equation}
    \PE[\1_{X\in \msb} \1_{\msk_\varepsilon}] \leq \delta.
\end{equation}
On the other hand, we have
\begin{align}
    \PE[\1_{X\in \msb} \1_{\msk_\varepsilon^c}] = \PE_{\mathbb{Q}}\left[\1_{X\in \msb}\1_{\msk_\varepsilon^c} \times \frac{\dd \PP}{\dd \mathbb{Q}} \right] \leq e^\varepsilon \PE_{\mathbb{Q}}\left[\1_{X\in\msb}\right]  = e^\varepsilon \PP(Y\in \msb),
    \end{align}
as required.


\subsection{Proof of \Cref{lem: data processing}}\label{subsec: proof of data processing}
By the data processing inequality (Theorem 9, \cite{6832827}) one has
\begin{equation}
        \renyi_\alpha(P^{\mathbb{P}}_{\mathcal{A}(D)}\Vert P^{\mathbb{P}}_{\mathcal{A}(D')})=\renyi_\alpha(P^{\mathbb{P}}_{\mathcal{A}(D)}\Vert P^{\mathbb{Q}}_{\mathcal{A}(D)})\leq \renyi_\alpha(\mathbb{P}\Vert \mathbb{Q}).
    \end{equation}
    The result then follows by the definition of Rényi DP in \eqref{eq:Rényi_divergence} since
    \begin{equation}
        \PE_{\mathbb{Q}}\biggr[\biggr (\frac{\dd \mathbb{P}}{\dd \mathbb{Q}}\biggr)^\alpha\biggr]=\PE\biggr[\biggr (\frac{\dd \mathbb{P}}{\dd \mathbb{Q}}\biggr)^{\alpha-1}\biggr].
    \end{equation}
    \subsection{Girsanov's theorem for SDEs}
Here we apply Girsanov's theorem to obtain the Radon-Nikodym derivative of the law of two SDEs with different drifts. The precise formulation we choose here is chosen so as to be able to apply the result to the diffusion \eqref{eq: generic diffusion} featured in \Cref{subsec: DP of SDEs}. We shall assume Novikov's condition \eqref{eq:Novikov_condition}. 
\begin{lemma}\label{lemma:girsanov_sde}
    Consider two processes $X_t^i$ for $i=1,2$ on a filtered probability space $(\Omega, \mathcal{F},(\mathcal{F}_t)_{t\geq 0}, \mathbb{P})$ that solve the SDEs
    \begin{equation}
 \dd X^1_t=g(X^1_{\kappa(t)},\eta_{\kappa(t)})\dd t+\sqrt{2/\beta}\dd W_t,
    \end{equation}
    \begin{equation}
\dd X^2_t=g(X^2_{\kappa(t)},\eta_{\kappa(t)})\dd t+u_t\dd t+\sqrt{2/\beta}\dd W_t.
    \end{equation}
    where $X^1_0,X^2_0=x_0\in \mathbb{R}^d$, $(W_t)_{t\geq 0}$ is a standard Brownian motion, $g:\mathbb{R}^d\to\mathbb{R}^d$ is a function, $\kappa:[0,\infty)\to[0,\infty)$ satisfies $\kappa(t)\leq t$, $(\eta_t)_{t\geq 0}$ is a stochastic process independent of $(W_t)_{t\geq 0}$ and $u_t$ is a $\mathcal{F}_t$-adapted process. Let the SDE given for each $i=1,2$ have a unique strong solution, and suppose for $T>0$ that
    \begin{equation}\label{eq:Novikov_condition}
        \PE\left[\exp\left( \frac{1}{2} \int_0^T \lvert u_t \rvert^2 \, \dd t \right)\right] <\infty.
    \end{equation}
    Then there exists a measure $\mathbb{Q}$ such that the random variable $(X^1_t)_{t\in [0,T]}$ on the probability space $(\Omega, \mathcal{F},(\mathcal{F}_t)_{t\geq 0}, \mathbb{Q})$ is equal in law to $(X^2_t)_{t\in [0,T]}$ on the probability space $(\Omega, \mathcal{F},(\mathcal{F}_t)_{t\geq 0}, \mathbb{P})$, and furthermore
  \begin{equation}\label{eq: Radon-Nikodym}
\frac{\dd\mathbb{Q}}{\dd\mathbb{P}}= \exp\biggr(\sqrt{\frac{\beta}{2}}\int^T_0 \langle u_s , \dd W_s\rangle-\frac{\beta}{4}\int^T_0\lvert u_s \rvert^2 \dd s\biggr).
    \end{equation}
\end{lemma}
\begin{proof}
For $t\geq 0$ let us define the new process
\begin{equation}
    \widetilde{W}_t:=\sqrt{\frac{\beta}{2}}\int^t_0u_s\dd s+W_t,
\end{equation}
We may now use Girsanov's theorem to find a measure $\mathbb{Q}$ such that $(\widetilde{W}_t)_{t\in [0,T]}$ is a Brownian motion under $\mathbb{Q}$. Particularly, under \eqref{eq:Novikov_condition} one has by Corollary 5.13, Section 3.5 of \citet{karatzas1991brownian} that
        \begin{equation}
          \exp\biggr(\sqrt{\frac{\beta}{2}}\int^t_0 \langle  u_s  , \dd W_s\rangle -\frac{\beta}{4}\int^t_0\lvert u_s \rvert^2 \dd s\biggr),
        \end{equation}
is a $(\mathcal{F}_t)_{t\geq 0}$-martingale under $\mathbb{P}$, so by Girsanov's theorem, i.e. Theorem 5.1, Section 3.5 of \citet{karatzas1991brownian}, one has that $(\widetilde{W}_t)_{t\in [0,T]}$ is a Brownian motion under $\mathbb{Q}$ given by \eqref{eq: Radon-Nikodym}. Then since one may write
    \begin{equation}\label{eq: new X^1 expression}
    \dd X^1_t=g(X^1_{\kappa(t)},\eta_{\kappa(t)})\dd t+\sqrt{2/\beta}\dd \widetilde{W}_t,\;\;\;X^1_0=x_0\in \mathbb{R}^d,
    \end{equation}
    and since both SDEs have unique strong solution one sees that $(X^1_t)_{t\in [0,T]}$ defined on the probability space $(\Omega, \mathcal{F},(\mathcal{F}_t)_{t\geq 0}, \mathbb{Q})$ must be equal in law to $(X^2_t)_{t\in [0,T]}$ defined on $(\Omega, \mathcal{F},(\mathcal{F}_t)_{t\geq 0}, \mathbb{P})$.
    
    %We can reason assuming $$B_t =\frac{1}{\sqrt 2} (X_t-X_0 -\int_0^t f_1(X_s)\dd s )$$ is a standard BM under $\PP^1$. We wish to find the measure $\PP^2$ such that the process $$\tilde B_t =\frac{1}{\sqrt 2} (X_t-X_0 -\int_0^t f_2(X_s)\dd s )$$ is a standard BM under $\PP^2$. By Girsanov's theorem, we obtain that this holds when such measure has RN derivative with respect to $\PP^1$ given by $$\exp\left(\int_0^t \langle b(X^1_s), \dd B_s \rangle - \frac12\int_0^t \lVert b(X^1_s)\rVert^2\dd t\right)$$ 
    %for $b(x) = \frac{1}{\sqrt 2}(f_2(x)-f_1(x)).$ 
    %Hence this gives \eqref{eq:RN_SDE}. 
\end{proof}


%\begin{corollary}\label{cor:KL_SDE}
%    Under the conditions of \Cref{lemma:girsanov_sde}, it holds that 
%    \begin{equation}\label{eq:KL_diffusions}
 %       \renyi_1(\PP^1_T,\PP^2_T) = \PE \left[ \frac{1}{4}  \int_0^T \lVert f_{2}(X_t^1) - f_{1}(X_t^1) \rVert^2 \dd t\right].
%    \end{equation}
%\end{corollary}
%\begin{proof}
%By \eqref{eq:RN_SDE} we find
 %   \begin{align}
%       \renyi_1(\PP^1_T,\PP^2_T) & =  \PE_{\PP_T^1}\left[ \log \frac{\dd \PP_T^1}{\dd \PP_T^2}\right] \\
%        & = \PE_{\PP_T^1} \left[ \frac{1}{\sqrt 2}\int_0^T \langle f_1(X_t) - f_2(X_t) ,\dd B^2_t\rangle - \frac{1}{4}  \int_0^T \lVert f_1(X_t) - f_2(X_t) \rVert^2 \dd t \right].
%    \end{align}
%By Girsanov's theorem $B^2_t = B_t^1 - \frac{1}{\sqrt 2}\int_0^t (f_1(X_s) - f_2(X_s))\dd s$. Then notice that the integral $\int_0^T \langle f_1(X_t) - f_2(X_t) ,\dd B^1_t\rangle$ is a $\PP^1_T$-martingale and hence has expectation zero. Hence we obtain \eqref{eq:KL_diffusions}.
%\end{proof}


    \subsection{Bounds on Stochastic Integrals}
In this section we present two well known bounds for exponentials of stochastic integrals.
\begin{lemma}\label{lem: stoch int exp}
 Let $u_t$ be a $(\mathcal{F}_t)_{t\geq 0}$-measurable process such that for some $T,K>0$ one has $\sup_{t\in [0,T]}\lvert u_t\rvert \leq K$. Then
\begin{equation}
        \PE\biggr[\exp\biggr(\int^T_0 \langle u_s, \dd W_s \rangle \biggr)\biggr]\leq e^{TK^2/2}.
    \end{equation}
    \end{lemma}
    \begin{proof}
        Since we have that $\lvert u_t\rvert \leq K$ almost surely, one sees that for every $t\geq 0$
        \begin{equation}
            \PE\biggr[\exp\biggr(\frac{1}{2}\int^t_0\lvert u_s\rvert^2 \dd s\biggr)\biggr]<\infty.
        \end{equation}
        Therefore by Corollary 5.13, Section 3.5 of \citet{karatzas1991brownian} one has that
        \begin{equation}
            \exp\biggr(\int^t_0 \langle u_s, \dd W_s\rangle-\frac{1}{2}\int^t_0\lvert u_s\rvert^2 \dd s\biggr),
        \end{equation}
        is a martingale. Then using the assumed bound $\lvert u_t\rvert \leq K$ again one has
\begin{equation}
            \PE\biggr [\exp\biggr(\int^T_0 \langle u_s, \dd W_s\rangle-TK^2/2\biggr)\biggr]\leq \PE\biggr[\exp\biggr(\int^T_0 \langle u_s, \dd W_s\rangle-\frac{1}{2}\int^T_0\lvert u_s\rvert^2 \dd s\biggr)\biggr]=1,
        \end{equation}
        at which point the result follows.
    \end{proof}
    \begin{lemma}\label{lem: stoch int tail bdds}
        For $u_t$ as in \Cref{lem: stoch int exp}, one has for any $a>0$
        \begin{equation}
            \PP\biggr (\int^T_0 \langle u_s, \dd W_s\rangle >a\biggr )\leq \exp \left(-\frac{a^2}{2TK^2}\right).
        \end{equation}
    \end{lemma}
    \begin{proof}
        Let $\upsilon>0$ and $a\in\R$. By Markov's inequality
        \begin{equation}
        \PP\biggr (\int^T_0 \langle u_s, \dd W_s\rangle>a\biggr )=\PP\biggr (\exp\biggr(\upsilon\int^T_0 \langle u_s, \dd W_s\rangle \biggr)>e^{a\upsilon}\biggr )\leq e^{-a\upsilon}\PE\biggr[\exp\biggr(\upsilon\int^T_0 \langle u_s, \dd W_s\rangle \biggr)\biggr],
    \end{equation}
    so that applying \Cref{lem: stoch int exp} one has
    \begin{equation}
        \PP\biggr (\int^T_0 \langle u_s, \dd W_s\rangle >a\biggr )\leq e^{-a\upsilon+T\upsilon^2K^2/2}.
    \end{equation}
    The result follows by minimising $\upsilon$.
    \end{proof}

%\begin{lemma}
%    For $\frac{d\mathbb{Q}}{d\mathbb{P}}$ as given in \eqref{eq: RN der from Girsanov}, under the assumptions $\lvert u_t\rvert \leq K$ from Lemma \ref{lemma:girsanov_sde} one has that the inverse $\frac{d\mathbb{P}}{d\mathbb{Q}}$ is well defined and furthermore for every $\alpha >1$ and $\delta>0$ one has
%\end{lemma}

\subsection{Proof of Proposition \ref{prop: dp of whole traj}}\label{subsubsec: proof of privacy of path}
Let us fix adjacent datasets $\dataset,\dataset'\in \mathcal{S}$. Then by the assumptions and the version of Girsanov's theorem presented in \Cref{lemma:girsanov_sde}, one sees that there exists a measure $\mathbb{Q}$ under which $(X^\dataset_t)_{t\in [0,T]}$ is equal in law to $(X^{\dataset'}_t)_{t\in [0,T]}$ under $\mathbb{P}$, that is
\begin{equation}
    P^{\mathbb{Q}}_{(X^\dataset_t)_{t\in [0,T]}}=P^{\mathbb{P}}_{(X^{\dataset'}_t)_{t\in [0,T]}},
\end{equation}
and furthermore
    \begin{equation}\label{eq: RN der from Girsanov}
        \frac{\dd \mathbb{Q}}{\dd \mathbb{P}}=\exp\biggr(\sqrt{\frac{\beta}{2}}\int^T_0 \langle  h(X^\dataset_{\kappa(t)},\eta_{\kappa(t)}), \dd W_t\rangle -\frac{\beta}{4}\int^T_0 \lvert h(X^\dataset_{\kappa(t)},\eta_{\kappa(t)})\rvert ^2 \dd t\biggr),
    \end{equation}
    for
    \begin{equation}
h(x,\eta):=f(x,\eta,\dataset)-f(x,\eta, \dataset').
    \end{equation}
    Then, \Cref{lem: epsilon delta privacy,lem: data processing} give that DP and Rényi-DP can be obtained by controlling respectively the tails and the moments of $\frac{\dd \mathbb{P}}{\dd \mathbb{Q}}$.

    Let us first focus on the DP bound. For any $\delta>0$, let  $\varepsilon_\delta:=Tc^2\beta/4+c\sqrt{\beta T\log(1/\delta)}$.
    Since $\lvert h\rvert\leq c$ by assumption, one has
    \begin{align}
        \PP\biggr (\frac{\dd \mathbb{P}}{\dd \mathbb{Q}}>e^{\varepsilon_\delta}\biggr)&\leq \PP\biggr(\exp\biggr(-\sqrt{\frac{\beta}{2}}\int^T_0 \langle h(X^\dataset_{\kappa(t)},\eta_{\kappa(t)}), \dd W_t\rangle \biggr)> \exp\biggr(\varepsilon_\delta-\frac{\beta}{4}\int^T_0 \lvert h(X^\dataset_{\kappa(t)},\eta_{\kappa(t)})\rvert ^2 \dd t) \biggr)\biggr)\\
       & \leq \PP \biggr(\exp\biggr(-\sqrt{\frac{\beta}{2}}\int^T_0 \langle h(X^\dataset_{\kappa(t)},\eta_{\kappa(t)}), \dd W_t\rangle \biggr)> \exp\left(\varepsilon_\delta-\frac\beta4 Tc^2\right) \biggr)\\
       & = \PP \biggr( \int^T_0 \langle -\sqrt{\frac{\beta}{2}} h(X^\dataset_{\kappa(t)},\eta_{\kappa(t)}), \dd W_t\rangle >  c\sqrt{\beta T\log(1/\delta)} \biggr)
    \end{align}
    Now, applying \Cref{lem: stoch int tail bdds} for $u_t = -\sqrt{\frac{\beta}{2}} h(X^\dataset_{\kappa(t)},\eta_{\kappa(t)})$, which under our assumptions satisfies $\lvert u_t\rvert \leq c \sqrt{\frac{\beta}{2}},$ we find 
    \begin{align}
        \PP\biggr (\frac{\dd \mathbb{P}}{\dd \mathbb{Q}}>e^{\varepsilon_\delta}\biggr)&\leq \delta.
    \end{align}
    Finally, \Cref{lem: epsilon delta privacy} gives the wanted $(\varepsilon, \delta)$-DP bound. 
    
    Now we derive the bound on the Rényi-DP for $\alpha>1$. \Cref{lem: data processing} shows that it is sufficient to bound
    \begin{align}
        \PE\biggr [ \biggr(\frac{\dd \mathbb{P}}{\dd \mathbb{Q}}\biggr)^{\alpha-1}\biggr]&=\PE\biggr[\exp\biggr(\frac{\beta(\alpha-1)}{4}\int^T_0 \lvert h(X^\dataset_{\kappa(t)},\eta_{\kappa(t)})\rvert ^2 \dd t-(\alpha-1)\sqrt{\frac{\beta}{2}}\int^T_0 \langle  h(X^\dataset_{\kappa(t)},\eta_{\kappa(t)}), \dd W_t\rangle \biggr)\biggr].
    \end{align}
    We can bound the first term using that $\lvert h(X^\dataset_{\kappa(t)},\eta_{\kappa(t)})\rvert  \leq c$, while the second term can be dealt applying \Cref{lem: stoch int exp} for $u_t = (1-\alpha)(\beta/2)^{1/2}h(X^\dataset_{\kappa(t)},\eta_{\kappa(t)})$. This gives
    \begin{align}
        \PE\biggr [ \biggr(\frac{\dd \mathbb{P}}{\dd \mathbb{Q}}\biggr)^{\alpha-1}\biggr]
        &\leq \exp\biggr(\frac{\beta(\alpha-1)}{4}Tc^2\biggr)\PE\biggr[\exp\biggr(\int^T_0 \langle  (1-\alpha)\sqrt{\frac{\beta}{2}} h(X^\dataset_{\kappa(t)},\eta_{\kappa(t)}), \dd W_t\rangle \biggr)\biggr]\\
        &\leq \exp\left(\frac{\beta}4 Tc^2\alpha(\alpha-1) \right).
    \end{align}
    By \Cref{lem: data processing} this implies Rényi-DP with $\varepsilon = \frac{\beta}4 Tc^2\alpha.$
  % Taking the $\alpha\to 1$ limit then provides the result for KL-privacy, i.e. $\alpha=1$.


\subsection{Proof of \Cref{prop: dp of final value}}\label{subsubsec: proof of dp of final value}
Let us assume $T\geq 1$, noting that the result holds by Proposition \ref{prop: dp of whole traj} for $T\leq 1$. Let us fix adjacent datasets $\dataset, \dataset'\in \mathcal{S}$ and let us define the process $(Z_t)_{t\in [0,T]}$ by
\begin{equation}
    \dd Z_t=f_\dataset(Z_{\kappa(t)}, \eta_{\kappa(t)})\dd t+u_t\dd t+\sqrt{2/\beta}\dd W_t,\;\;\;Z_0=x_0\in \mathbb{R}^d,
\end{equation}
where $u_t$ is supported on $t\in [T-1,T]$ and in particular
\begin{equation}
    u_t:=[ f_{\dataset'}(X^{\dataset'}_{\kappa(t)},\eta_{\kappa(t)})-f_\dataset(Z_{\kappa(t)}, \eta_{\kappa(t)}) -(Z_{T-1}-X^{\dataset'}_{T-1})]\1_{t\in [T-1,T]}.
\end{equation}
Then, for $t\in [T-1,T]$ one has
\begin{align}
    Z_t-X^{\dataset'}_t&=Z_{T-1}-X^{\dataset'}_{T-1}+\int^t_{T-1}\left(f_\dataset(Z_{\kappa(s)}, \eta_{\kappa(s)})+u_s-f_{\dataset'}(X^{\dataset'}_{\kappa(s)},\eta_{\kappa(s)}) \right)\dd s\\
    &=Z_{T-1}-X^{\dataset'}_{T-1}-\int^t_{T-1}(Z_{T-1}-X^{\dataset'}_{T-1})\dd s\\
    & = (T-t) \left( Z_{T-1}-X^{\dataset'}_{T-1}\right),
\end{align}
and hence $Z_T=X^{\dataset'}_T$ almost surely. Furthermore, since \eqref{eq: generic diffusion} has a unique strong solution for each dataset one has that $Z_t=X^{\dataset}_t$ for $t\in [0,T-1]$ almost surely. Therefore by assumption one has for $t\in [0,T-1]$ that
\begin{equation}
\lvert Z_t-X^{\dataset'}_t\rvert=\lvert X^\dataset_t-X^{\dataset'}_t\rvert\leq C.
\end{equation}
Furthermore note that, for $t\in [T-1,T]$,
\begin{align}
    \lvert Z_t-X^{\dataset'}_t\rvert &= (T-t)\lvert X^{\dataset}_{T-1}-X^{\dataset'}_{T-1}\rvert \\
    & \leq \lvert X^{\dataset}_{T-1}-X^{\dataset'}_{T-1}\rvert\\
    & \leq C.
\end{align}
Hence, for $t\in [0,T]$ one has
\begin{equation}
\lvert Z_{\kappa(t)}-X^{\dataset'}_{\kappa(t)}\rvert \leq C.
\end{equation}
Using \eqref{eq: drift assump} one may therefore bound
\begin{equation}
    \lvert u_t\rvert\leq L\lvert X^{\dataset'}_{\kappa(t)} - Z_{\kappa(t)}\rvert  + c + C \leq C(L+1)+c.
\end{equation}
Now observe that by \Cref{lemma:girsanov_sde}, under the measure $\mathbb{Q}$ given as
\begin{equation}
    \dd \mathbb{Q}=\exp\biggr (\sqrt{\frac{\beta}{2}}\int^T_{T-1} \langle u_t,\dd W_t\rangle -\frac{\beta }{4}\int^T_{T-1} \lvert u_t\rvert^2\dd t\biggr )\dd \mathbb{P},
\end{equation}
one has that 
\begin{equation}\label{eq: equivilence of measures}
    P^{\mathbb{Q}}_{(Z_t)_{t\in [0,T]}}=P^{\mathbb{P}}_{(X^{\dataset}_t)_{t\in [0,T]}}.
\end{equation}
Moreover, since $Z_T=X^{\dataset'}_T$ almost surely, by \eqref{eq: equivilence of measures} one has that
\begin{equation}
P^{\mathbb{Q}}_{X^{\dataset'}_T}=P^{\mathbb{Q}}_{Z_T}=P^{\mathbb{P}}_{X^{\dataset}_T}.
\end{equation}
Now, we wish to apply \Cref{lem: epsilon delta privacy,lem: data processing} to obtain the wanted guarantees respectively on the DP and Rényi-DP of our randomised algorithm.  For any $\delta>0$ and $\alpha>1$, let us set $\varepsilon_\delta=C_2/4+\sqrt{C_2\log(1/\delta)}$ and $\varepsilon_\alpha=\alpha C_2/4$, where $C_2=\beta(C(L+1)+c)^2$.
Proceeding as in the proof of \Cref{prop: dp of whole traj} one may show that
\begin{equation}
    \PP\biggr (\frac{\dd \mathbb{P}}{ \dd \mathbb{Q}}\geq \varepsilon_\delta\biggr)\leq \delta, \qquad
    \renyi_\alpha(\mathbb{P}\vert \mathbb{Q})\leq \varepsilon_\alpha,
\end{equation}
which is sufficient to apply \Cref{lem: epsilon delta privacy,lem: data processing}.
% Then since $Z_T=X^{\dataset'}_T$ almost surely, by \eqref{eq: equivilence of measures} one has that
% \begin{equation}
% P^{\mathbb{Q}}_{X^{\dataset'}_T}=P^{\mathbb{Q}}_{Z_T}=P^{\mathbb{P}}_{X^{\dataset}_T}.
% \end{equation}
% As a result one may apply Lemmas \ref{lem: epsilon delta privacy} and \ref{lem: data processing} to conclude.
%\subsection{Proof of Theorem ...}\label{subsubsec: proof of bayesian density}

% Let us consider the overdamped Langevin dynamics 
  %      \begin{equation}\label{eq: unadjusted Langevin SDE}
 %           dX^{\dataset}_T=-\nabla U_\dataset(X^{\dataset}_T)dt+\sqrt{2}dW_t,\;\;\;\mathcal{L}(X^\dataset_0)=\pi_\dataset,
 %       \end{equation}
 %  where $X^\dataset_0$ are independent for each data $\dataset$, and additionally independent of the driving noise $(W_t)_{t\geq 0}$ that is the same for each data $\dataset$. Therefore by the invariance of $\pi_\dataset$ via our assumptions, one has that $\mathcal{L}(X^{\dataset}_T)=\pi_\dataset$ for every data $\dataset$ and $t\geq 0$. Now let us use Proposition \ref{prop: dp of final value} to show privacy. In particular let us show that the condition \eqref{eq: closeness condition} is satisfied for a new diffusion defined as \eqref{eq: unadjusted Langevin SDE} for $t\in [T,2T]$ and sufficiently large $T>0$. Let $\dataset,\dataset'$ be adjacent datasets. Then using Ito's formula one calculates
%\begin{equation}
%    e^{2\mu T}\lvert X^{\dataset}_T-X^{\dataset'}_T\rvert ^2=\lvert X^\dataset_0-X^{\dataset'}_0\rvert ^2+\int^T_0  2e^{2\mu s}(\mu\lvert X^\dataset_s-X^{\dataset'}_s\rvert^2-\langle \nabla U_\dataset(X^\dataset_s)-\nabla U_{\dataset'}(X^{\dataset'}_s), X^\dataset_s-X^{\dataset'}_s\rangle ds.
%\end{equation}
 %       Applying the assumptions one then sees that
%\begin{equation}
%    e^{2\mu T}\lvert X^{\dataset}_T-X^{\dataset'}_T\rvert ^2\leq \lvert X^\dataset_0-X^{\dataset'}_0\rvert ^2+\int^T_0  4ce^{2\mu s} \lvert X^\dataset_s-X^{\dataset'}_s\rvert ds,
%\end{equation}        
%so that taking supremum insider the integral and evaluating the integral of the exponential function one may bound as
%\begin{equation}
%    e^{2\mu T}\lvert X^{\dataset}_T-X^{\dataset'}_T\rvert ^2\leq \lvert X^\dataset_0-X^{\dataset'}_0\rvert ^2+\frac{2c}{\mu}e^{2\mu T} \sup_{u\in [0,T]}\lvert X^\dataset_u-X^{\dataset'}_u \rvert ,
%\end{equation}        
%and so
%\begin{equation}
%   \lvert X^{\dataset}_T-X^{\dataset'}_T\rvert ^2\leq  e^{-2\mu T}\lvert X^\dataset_0-X^{\dataset'}_0\rvert ^2+\frac{2c}{\mu}\sup_{u\in [0,t]}\lvert X^\dataset_u-X^{\dataset'}_u \rvert .
%\end{equation}    
%Then since the RHS is increasing in $t>0$, one may take supremum on the LHS and divide through to obtain
%\begin{equation}
%   \sup_{u\in [0,T]}\lvert X^\dataset_u-X^{\dataset'}_u \rvert\leq \frac{2c}{\mu} .
%\end{equation}   
%Therefore, by Proposition \ref{prop: pertubation trick} one sees that $X^{\dataset}_T$ is $(\varepsilon_\delta, \delta)$-private and $(\alpha, \varepsilon_\alpha)$-Rényi private as given in the Theorem statement. To see that this transfers to the true posterior note that ...


\section{Proofs for \Cref{sec: privacy of stoch alg}}

\subsection{Proof of \Cref{thm: Bayesian ULA}}\label{subsubsec: proof of ula}
Let us fix adjacent datasets $\dataset,\dataset'\in \mathcal{S}$ and consider two versions $(x^\dataset_n)_{n\geq 1}$ and $(x^{\dataset'}_n)_{n\geq 1}$ of the ULA algorithm \eqref{eq: ULA} targeting $\pi_\dataset$ and $\pi_{\dataset'}$ respectively. Let $(x^\dataset_n)_{n\geq 1}$ and $(x^{\dataset'}_n)_{n\geq 1}$ be driven by the same sequence $(z_n)_{n\geq 1}$ of iid standard Gaussians. Let us define
\begin{equation}
    e_n:=x^\dataset_n-x^{\dataset'}_n,
\end{equation}
so that by the strong monotonicity and $L$-Lipschitz assumption on $\nabla K$ one has
\begin{equation}
    \lvert e_n-\gamma \nabla K(x^\dataset_n)-\gamma \nabla K(x^{\dataset'}_n)\rvert^2\leq (1-2\gamma \mu+\gamma^2L^2)\lvert e_n\rvert^2.
\end{equation}
Now let us show
\begin{equation}\label{eq: bound for closeness ULA}
    0\leq 1-2\gamma \mu+\gamma^2L^2\leq 1.
\end{equation}
For the lower bound one can show by standard calculus that the minimum value attained for $\gamma>0$ in the above expression is $1-\mu^2/L^2$. To see that this is greater than $0$, note that by the monotonicity assumption \eqref{eq: mon assumption K}, applying Cauchy-Schwarz one must have
\begin{equation}
    \lvert \nabla K(x)-\nabla K(y)\rvert\geq \mu \lvert x-y\rvert,
\end{equation}
and therefore one must have $L\geq\mu$. The upper bound in \eqref{eq: bound for closeness ULA} follows simply by the assumption $\gamma \in (0,2\mu/L^2)$. Then since $\sqrt{1-x}\leq 1-x/2$ for $x\in [0,1]$, one may conclude
\begin{equation}
    \lvert e_n-\gamma \nabla K(x^\dataset_n)-\gamma \nabla K(x^{\dataset'}_n)\rvert \leq (1-\gamma \mu+\gamma^2L^2/2)\lvert e_n\rvert.
\end{equation}
By the assumption that that $\lvert \nabla V\rvert, \lvert \nabla V'\rvert \leq c$, one therefore has that\alain{for the future, see more assumption on $\nabla V^{\dataset}$, in fact we can deal with less restricted assumption using reflexion coupling! !-)}
\begin{align}
    \lvert e_{n+1}\rvert &\leq \lvert e_n-\gamma \nabla K(x^\dataset_n)-\gamma \nabla K(x^{\dataset'}_n)\rvert+\lvert \gamma \nabla V^{\dataset}(x^\dataset_n)-\gamma \nabla V^{\dataset'}(x^{\dataset'}_n)\rvert \nonumber \\
    &\leq (1-\gamma \mu+\gamma^2L^2/2)\lvert e_n\rvert+2\gamma c.
\end{align}
Iterating this bound from $n=0$ (since $e_0=0$) one obtains for all $n\geq 1$ that
\begin{equation}\label{eq: closeness bound ULA}
    \lvert e_n\rvert \leq \frac{2c}{ \mu-\gamma L^2/2}.
\end{equation}
Now let us consider the following interpolation of the ULA algorithm. Let us define $\kappa_\gamma:[0,\infty)\to[0,\infty)$ by $\kappa_\gamma(t):=\gamma\lfloor t/\gamma\rfloor$, that is, the projection backwards onto $\{0,\gamma, 2\gamma, ...\}$. Then consider the continuous time process 
    \begin{equation}
            \dd X^{\dataset}_t=-\nabla U_\dataset(X^\dataset_{\kappa_\gamma(t)})\dd t+\sqrt{2}\dd W_t,\;\;\;X^\dataset_0=x_0\in \mathbb{R}^d,
        \end{equation}
        and likewise for $\dataset'$. It is easy to verify that since the coefficients of the drift are fixed in-between the time-discretisation grid $\{0,\gamma, 2\gamma, ...\}$, one has that the law of $X^\dataset_{n\gamma}$ is equal to the law of $(x^\dataset_n)$, and likewise for $\dataset'$. Furthermore, since $X^{\dataset}_T$ and $X^{\dataset'}_t$ are driven by the same Brownian motion, one may apply \eqref{eq: closeness bound ULA} to conclude that
        \begin{equation}
        \sup_{t\geq 0}\;\lvert X^\dataset_{\kappa_\gamma(t)}-X^{\dataset'}_{\kappa_\gamma(t)}\rvert \leq \frac{2c}{ \mu-\gamma L^2/2}.
        \end{equation}
        So as to satisfy the assumptions of Proposition \ref{prop: dp of final value} we need to extend this bound from grid points $\kappa_\gamma(t)$ to the whole of $t\geq 0$. To see this note that 
        \begin{equation}\label{eq: between grid points}
          X^{\dataset}_t-X^{\dataset'}_t=X^\dataset_{\kappa_\gamma(t)}-X^{\dataset'}_{\kappa_\gamma(t)}-(t-\kappa_\gamma(t))[\nabla U_\dataset(X^\dataset_{\kappa_\gamma(t)})-\nabla U_{\dataset'}(X^{\dataset'}_{\kappa_\gamma(t)})],
        \end{equation}
        and furthermore for arbitrary $x,y \in \mathbb{R}^d$ and $t>0$, if one defines
\begin{equation}
    f(t):=\lvert x +yt\rvert^2= \lvert x \rvert^2+2t\langle a,y \rangle+t^2\lvert y\rvert^2,
\end{equation}
then since $f''>0$ the function $f$ cannot have a local maximum anywhere. Therefore $$\sup_{t\in [a,b]}f(t)\leq \max\{f(a), f(b)\}.$$ Applying this principle to \eqref{eq: between grid points} one sees that
\begin{equation}
        \sup_{t\geq 0}\; \lvert X^{\dataset}_t-X^{\dataset'}_t\rvert \leq \frac{2c}{ \mu-\gamma L^2/2}.
        \end{equation}
        Therefore one sees that the assumptions of Proposition \ref{prop: dp of final value} are satisfied for $L,c>0$ as in the Proposition, and $C=\frac{2c}{ \mu-\gamma L^2/2}$, and the result therefore follows by choosing $T=n\gamma$

\subsection{Proof of \Cref{thm: non-convex sgd}}\label{subsubsec: proof of sgd non-convex}
As in the proof of Theorem \ref{thm: Bayesian ULA}, for adjacent data $\dataset=(d_1,...,d_m),\dataset'=(d_1',...,d_m')$ we show that $x^\dataset_n$ and $x^{\dataset'}_n$ are almost surely close. The strategy here is essentially the same. Letting $e_n:=x^\dataset_n-x^{\dataset'}_n$ as before, one has
\begin{align}
    \Bigg \lvert e_n-\frac{\gamma}{s}\sum_{i\in A_{n+1}} (\nabla  k(x^\dataset_n)-\nabla k(x^{\dataset'}_n))\Bigg\rvert^2 & =\lvert e_n\rvert^2-2\frac{\gamma}{s}\sum_{i\in A_{n+1}}\langle e_n, \nabla k(x^\dataset_n)-\nabla k(x^{\dataset'}_n)\rangle\nonumber \\
    & \quad +\biggr \lvert \frac{\gamma}{s}\sum_{i\in A_{n+1}} (\nabla  k(x^\dataset_n)-\nabla k(x^{\dataset'}_n))\biggr \rvert^2,
\end{align}
so that since by the Lipschitz assumption and the fact $A_{n+1}\subset\{1,2,...,m\}$ is of size $s$, one obtains
\begin{equation}
\biggr \lvert \frac{\gamma}{s}\sum_{i\in A_{n+1}} (\nabla  k(x^\dataset_n)-\nabla k(x^{\dataset'}_n))\biggr \rvert\leq \gamma L\lvert e_n\rvert.
\end{equation}
Then applying the convexity assumption one obtains
\begin{align}\label{eq: convex calc SGD}
    \lvert e_n-\frac{\gamma}{s}\sum_{i\in A_{n+1}} (\nabla  k(x^\dataset_n)-&\nabla k(x^{\dataset'}_n))\rvert^2\leq (1-2\mu +L^2\gamma^2)\lvert e_n\rvert^2,
\end{align}
so that since as before one has $0\leq 1-2\mu +L^2\gamma^2\leq 1$, one may square root to see that
\begin{align}\label{eq: SGD calculation}
    \lvert e_{n+1}\rvert=\lvert e_n-\frac{\gamma}{s}\sum_{i\in A_{n+1}} (\nabla  k(x^\dataset_n)-\nabla k(x^{\dataset'}_n))\rvert^2+\frac{\gamma}{s}\sum_{i\in A_{n+1}}\lvert \nabla_x v(x^\dataset_n,d_i)-\nabla_x v(x^{\dataset'}_n,d_i')\rvert,
\end{align}
so that using the assumption $\lvert \nabla_x v (\cdot,\cdot)\rvert \leq c$ one sees that the bound \eqref{eq: closeness bound ULA} from before also holds in this setting.

Now let us find a continuous time interpolation of the SGD process \eqref{eq: SGD}. For the stochastic gradient we consider the process $(\eta_t)_{t\geq 0}$ given for $n\in \mathbb{N}$ and $t\in (n\gamma, (n+1)\gamma)$ as $\eta_t=A_{n+1}$, where $(A_n)_{n\geq 1}$ is the sequence of i.i.d. random variables uniformly distributed on subsets of size $s\leq m$ of $\{1,2,...,m\}$. Then for every data $\dataset=(x_1,...,x_m)$ one may define the process $(Y^\dataset_t)_{t\geq 0}$ as the solution to the SDE
\begin{equation}\label{eq: SGD cont}
\dd Y^\dataset_t=-\frac{1}{s}\sum_{i\in \eta_t}\nabla _x \ell(Y^\dataset_{\kappa_\gamma(t)}, d_i)\dd t+\sqrt{2/\beta}\dd W_t,
    \end{equation}
    where $\kappa_\gamma$ is the backwards projection to $\{0,\gamma, 2\gamma,...\}$ as in the proof of Theorem \ref{thm: Bayesian ULA}. Then it is easy to verify that the law of $Y^\dataset_{n\gamma}$ is equal to the law of $x^\dataset_n$, at which point one can use the strategy from the proof of Theorem \ref{thm: Bayesian ULA} to obtain that
\begin{equation}
           \sup_{t\geq 0} \lvert Y^\dataset_t-Y^{\dataset'}_t \rvert \leq \frac{2c}{ \mu-\gamma L^2/2},
        \end{equation}
        at which point as before the result follows from \Cref{prop: dp of final value}, paying attention to the value of $\beta>0$ assumed in the definition \eqref{eq: SGD} of the SGD algorithm.
\subsection{Proof of \Cref{thm: convex sgd}}\label{subsubsec: proof of sgd convex}
Here we modify slightly proof of Theorem \ref{thm: non-convex sgd} previously. Specifically, note that if $\dataset=(d_1,...,d_m)$ and $\dataset'=(d_1',...,d_m')$ are adjacent then only one of their entries is different, that is there exists $i\in\{1,2,...,m\}$ such that $d_i\not=d_i'$, however for $j\in \{1,2,...,m\}$ such that $j\not =i$ one has $d_j=d_j'$. Therefore, since we have assumed $v_\theta(\cdot,d)$ to be constant for every $d\in \dataset$, one may bound
\begin{align}
\frac{\gamma}{s}\sum_{i\in A_{n+1}}\lvert \nabla_x v(x^\dataset_n,d_i)-\nabla_x v(x^{\dataset'}_n,d_i')\rvert\leq \frac{2c\gamma}{s},
\end{align}
and therefore using \eqref{eq: convex calc SGD} and \eqref{eq: SGD calculation} one has that
\begin{align}
    \lvert e_{n+1}\rvert\leq (1-\gamma \mu+\gamma^2L^2/2)\lvert e_n\rvert+\frac{2c\gamma}{s},
\end{align}
and as a result
\begin{equation}
    \sup_{n\geq 1}  \lvert e_n\rvert\leq  \frac{2c}{s(\gamma L^2/2-\mu)}.
\end{equation}
Then extending this bound to the continuous interpolation \eqref{eq: SGD cont} as in the proofs of \Cref{thm: Bayesian ULA,thm: non-convex sgd}, and applying \Cref{prop: dp of final value} as before, the result follows.
\subsection{Proof of Theorem \ref{thm: path of SGD}}\label{subsubsec: proof of sgd path}
The proof here is very simple: note that the assumptions imply that for every pair of adjacent datasets $ \dataset,\dataset'$ and $x \in \mathbb{R}^d$, since $A_{n+1}$ is a subset of size $s\leq m$ of $\{1,2,...,m\}$, one has $\dataset =(d_1,...,d_m)$, $\dataset' =(d_1',...,d_m')$ that differ in only one element, so
\begin{equation}
    \left\lvert \frac{1}{s}\sum_{i\in \eta_t}\nabla _x \ell(x, d_i)-\frac{1}{s}\sum_{i\in \eta_t}\nabla _x \ell(x, d'_i) \right\rvert \leq c/s.
\end{equation}
Therefore one may apply \Cref{prop: dp of whole traj} to \eqref{eq: SGD cont}, and then since the law of $(Y^\dataset_0,Y^\dataset_\gamma, ...Y^\dataset_{n\gamma})$ is equal to the law of $(x^\dataset_0,...,x^\dataset_n)$ and $(Y^\dataset_0,Y^\dataset_\gamma, ...Y^\dataset_{n\gamma})$ is equal to a mapping from $(Y_t)_{t\in[0,n\gamma]}$, the result follows from the data processing inequality (see Theorem 9 in \citet{6832827}).






\end{document}


% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was created
% by Iain Murray in 2018, and modified by Alexandre Bouchard in
% 2019 and 2021 and by Csaba Szepesvari, Gang Niu and Sivan Sabato in 2022.
% Modified again in 2023 and 2024 by Sivan Sabato and Jonathan Scarlett.
% Previous contributors include Dan Roy, Lise Getoor and Tobias
% Scheffer, which was slightly modified from the 2010 version by
% Thorsten Joachims & Johannes Fuernkranz, slightly modified from the
% 2009 version by Kiri Wagstaff and Sam Roweis's 2008 version, which is
% slightly modified from Prasad Tadepalli's 2007 version which is a
% lightly changed version of the previous year's version by Andrew
% Moore, which was in turn edited from those of Kristian Kersting and
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.
