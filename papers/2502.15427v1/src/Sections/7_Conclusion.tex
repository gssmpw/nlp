In this work, we performed a wide benchmarking of guardrails  over a large number of datasets. We show that many defences can have large performance differences depending on the attack style considered, highlighting that evaluating over many different categories of attacks is essential for accurately determining guardrail performance. Furthermore, guardrails can vary significantly in both memory footprint, computational cost, and extensibility to new attack vectors. Increasing the computation by an order of magnitude to defend against jailbreaks may thus not be a feasible solution in relation to far more lightweight approaches that have been relatively under-explored, and able to satisfy practical deployment constraints. A principal limitation of this work is that we were required to sub-sample our final evaluation data due to the high computation cost of several defences, and the range of datasets being evaluated.

\section{Acknowledgment}

We are grateful to IBM Watson Natural Language Processing team. Additionally, we would like to specifically recognize Manish Nagireddy, Aliza Heching, Yang Zhao, Bhatta Bhattacharjee, Neelima Reddy Gade, Ravi Chamarthy, Upasana Bhattacharya, Manish Bhide, Elizabeth Daly, Michael Hind, Ian Molloy, J.R. Rao, Sriram Raghavan for their support.