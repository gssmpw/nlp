
\documentclass{article} % For LaTeX2e
\usepackage{iclr2025_conference,times}

% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{math_commands.tex}

\usepackage{hyperref}
\usepackage{url}



\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{multirow}
%\usepackage{graphics}
\usepackage{booktabs} 

% \usepackage{algorithm}
% \usepackage{algorithmic}
\usepackage{xcolor}
\usepackage[linesnumbered,ruled,vlined]{algorithm2e}
\makeatletter
\newcommand{\algorithmfootnote}[2][\footnotesize]{%
  \let\old@algocf@finish\@algocf@finish% Store algorithm finish macro
  \def\@algocf@finish{\old@algocf@finish% Update finish macro to insert "footnote"
    \leavevmode\rlap{\begin{minipage}{\linewidth}
    #1#2
    \end{minipage}}%
  }%
}

%\newtheorem{proposition}[theorem]{Proposition}
%\newtheorem{proposition}{Proposition}[theorem]
\newtheorem{theorem}{Theorem}
%\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{proposition}[theorem]{Proposition}

\usepackage{color}


\title{Fast Direct: Query-Efficient  Online Black-box Guidance  for Diffusion-model Target Generation}

% Authors must not appear in the submitted version. They should be hidden
% as long as the \iclrfinalcopy macro remains commented out below.
% Non-anonymous submissions will be rejected without review.

% \author{Antiquus S.~Hippocampus, Natalia Cerebro \& Amelie P. Amygdale \thanks{ Use footnote for providing further information
% about author (webpage, alternative address)---\emph{not} for acknowledging
% funding agencies.  Funding acknowledgements go at the end of the paper.} \\
% Department of Computer Science\\
% Cranberry-Lemon University\\
% Pittsburgh, PA 15213, USA \\
% \texttt{\{hippo,brain,jen\}@cs.cranberry-lemon.edu} \\
% \And
% Ji Q. Ren \& Yevgeny LeNet \\
% Department of Computational Neuroscience \\
% University of the Witwatersrand \\
% Joburg, South Africa \\
% \texttt{\{robot,net\}@wits.ac.za} \\
% \AND
% Coauthor \\
% Affiliation \\
% Address \\
% \texttt{email}
% }

\author{
Kim Yong Tan \textsuperscript{\rm 1}~~
Yueming Lyu \textsuperscript{\rm 2,3}\thanks{\vspace{-20pt}Corresponding author}~~
Ivor Tsang\textsuperscript{\rm 1,2,3}~~
Yew-Soon Ong\textsuperscript{\rm 1,2,3} \\
\\
\textsuperscript{\rm 1}College of Computing and Data Science, Nanyang Technological University, Singapore\\
\textsuperscript{\rm 2}Centre for Frontier AI Research, Agency for Science, Technology and Research, Singapore\\
\textsuperscript{\rm 3}Institute of High Performance Computing,  Agency for Science, Technology and Research, Singapore\\
\\
{\tt \{KIMYONG001,ASYSOng\}@ntu.edu.sg}\\
{\tt \{Lyu\_Yueming,Ivor\_Tsang\}@cfar.a-star.edu.sg}
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors' names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\iclrfinalcopy % Uncomment for camera-ready version, but NOT for submission.
\begin{document}

\maketitle
\vspace{-10pt}
\begin{abstract}

Guided diffusion-model generation is a promising direction for customizing the generation process of a pre-trained diffusion model to address specific downstream tasks. Existing guided diffusion models either rely on training the guidance model with pre-collected datasets or require the objective functions to be differentiable. However, for most real-world tasks, offline datasets are often unavailable, and their objective functions are often not differentiable, such as image generation with human preferences, molecular generation for drug discovery, and material design. Thus, we need an \textbf{online} algorithm capable of collecting data during runtime and supporting a \textbf{black-box} objective function. Moreover, the \textbf{query efficiency} of the algorithm is also critical because the objective evaluation of the query is often expensive in real-world scenarios. In this work, we propose a novel and simple algorithm, \textbf{Fast Direct}, for query-efficient online black-box target generation. Our Fast Direct builds a pseudo-target on the data manifold to update the noise sequence of the diffusion model with a universal direction, which is promising to perform query-efficient guided generation. Extensive experiments on twelve high-resolution ($\small {1024 \times 1024}$) image target generation tasks and six 3D-molecule target generation tasks show $\textbf{6}\times$ up to $\textbf{10}\times$ query efficiency improvement and $\textbf{11}\times$ up to $\textbf{44}\times$ query efficiency improvement, respectively. Our implementation is publicly available at: \url{https://github.com/kimyong95/guide-stable-diffusion/tree/fast-direct}
\end{abstract}

% Our technique employs a simple update rule to update the noise sequence of the diffusion model in a universal direction in the data manifold, which is essential to perform guided generation efficiently. Moreover, our method benefits from closed-form updates of nonparametric methods (e.g., Gaussian Process), which do not require additional training of the surrogate model.  Empirically, extensive real-world experiments on 12 target (prompt) image generation tasks and six molecular target generation tasks show the significant query-efficiency improvement of our QOBG method compared with baselines. 

\section{Introduction}

Diffusion models have become the state-of-the-art generative model for image synthesis \citep{ho2020denoising, nichol2021improved, dhariwal2021diffusion} and video synthesis \citep{ho2022video}, etc. Its remarkable success is due to its powerful capability in modeling complex multi-mode high-dimensional data distributions. 

%The key idea of diffusion models is to train a deep neural network to transform a simple prior distribution (often isotropic Gaussian) into the data distribution by iteratively applying a de-noising operation. 

% introduce diffusion targeted generation, review existing methods.
One promising direction for utilizing the generative power of diffusion models is through target generation, which allows users to customize the generation process to meet specific downstream objectives, effectively extending the models' capabilities beyond synthesis problems to engineering optimization and science discovery problems, such as image generation with human preferences, drug discovery \citep{corso2022diffdock,guan20233d} and material design \citep{vlassis2023denoising,giannone2023aligning}.  

The pre-trained diffusion models often struggle to generate desired samples for these applications, especially when the target data lies outside the training data distribution.  
Therefore, the target generation often involves model fine-tuning or guidance techniques. \cite{krishnamoorthy2023diffusion} proposes to train the diffusion model with re-weighted training loss, while \cite{clark2023directly,black2023training,fan2024reinforcement,yang2024using} advocates for fine-tuning the parameters of the pre-trained model. As opposed to training-time approaches, \cite{bansal2023universal} introduces an inference-time approach, which replaces the classifier in classifier guidance \citep{dhariwal2021diffusion} with a differentiable objective function to achieve the downstream target. However, the requirement of the differentiable objective limits its practical usage for real applications with black-box feedback.

% Identify a specific problem in targeted generation that has not been solved, and describe the importance of this problem.
Most real-world applications of target generation involve evaluating \textbf{black-box objectives} in an \textbf{online} manner. For example, image generation with human preferences requires human users to evaluate the generated images; drug design requires real-world experiments to evaluate the generated molecules. These applications typically require several iterative query-feedback cycles with a black-box objective to achieve satisfactory target generation. As objective evaluations are often expensive, it becomes crucial to develop \textbf{query-efficient} algorithms to minimize the cost of these evaluations.

%Additionally, these real-world objective evaluations are non-differentiable, so the algorithm needs to support the \textbf{black-box objective} function.

%However, the existing works are not suitable to address the   \textbf{online black-box guidance}  tasks. 

Although the \textbf{online black-box} target generation tasks are important, the existing works are not suitable to address this task. \cite{bansal2023universal,krishnamoorthy2023diffusion,lu2023contrastive} require training an offline guidance model with pre-collected data, while \cite{bansal2023universal,clark2023directly,prabhudesai2023aligning,he2023manifold} require the objective function to be differentiable. Most recently, \cite{black2023training,fan2024reinforcement,yang2024using} can be employed for online black-box target generation, but they require online updates of the huge number of parameters, which is both time-consuming and not query-efficient.

% explains the algorithm

%{\color{red}==================================== Below Need Revision}

% To address the \textbf{query-efficient} requirement challenge of online black-box target generation, we propose a novel algorithm, \textbf{Fast Direct}. 

% Our \textbf{Fast Direct} method builds a pseudo-target on the data manifold to guide the pre-trained diffusion model for black-box target generation.    

% In this work,  we propose a novel guided noise sequence optimization (GNSO) technique to guide the diffusion model sampling process towards a given target.  Our GNSO  updates the noise sequence in a universal direction on the data manifold. This technique enables fast adaptation from any initial generation towards the given input target, which not only forms a simple and efficient backbone for designing black-box target generation algorithms but also provides a basic tool for other downstream tasks. Our GNSO cannot directly handle black-box target generation tasks. Based on our GNSO technique, we further propose a novel algorithm, \textbf{Fast Direct}, to address the \textbf{query-efficient} requirement challenge of online black-box target generation.  Our \textbf{Fast Direct} method builds a pseudo-target on the data manifold as the input of our GNSO to guide the pre-trained diffusion model for black-box target generation at inference time.   
%\textbf{Fast Direct} employs non-parametric methods to update the pseudo-target with black-box query feedback in an online manner. %The updated pseudo-target can then serve as input for our GNSO to guide the pre-trained diffusion model to generate target data queries efficiently.   


%To address the \textbf{query-efficient} requirement challenge of online black-box target generation, we propose a simple and novel algorithm,  \textbf{Fast Direct}. 

In Section~\ref{TargetGuidanceQ1}, we first propose a novel guided noise sequence optimization (GNSO) technique to guide the diffusion model sampling process towards a given target. GNSO updates the noise sequence in a \textit{universal direction} on the data manifold. Our GNSO is \textbf{efficient}: it enables fast adaptation (with around only 50 steps) from any initial generation towards the given input target. Moreover, GNSO is \textbf{robust}: empirically, even if the input target image is noisy, it can still generate a clear image semantically similar to the target image. The GNSO itself cannot directly handle black-box target generation tasks, but it provides a backbone for further designing black-box algorithms. 

In Section~\ref{section:fact_direct}, based on our GNSO technique, we further propose a novel algorithm, \textbf{Fast Direct}, to tackle the \textbf{online black-box} target generation tasks in a \textbf{query-efficient} manner. Fast Direct builds a pseudo-target on the data manifold as the input for our GNSO, to guide the diffusion model at inference time. Notably, our Fast Direct is easy to implement and supports any stochastic diffusion scheduler. Moreover, our Fast Direct provides a very flexible framework for extension. Any designs of update methods for the pseudo-target can serve as a plug-in for our Fast Direct.

In Section~\ref{section:experiments}, we evaluate our {Fast Direct} algorithm on the real-world applications:   high-resolution ($1024 \times 1024$)   image target generation tasks and 3D-molecule target generation tasks.  For image tasks,  we employ the black-box API of the modern Large Language Model (LLM),  Gemini~1.5, as the black-box objective, which is much more practical compared with the synthetic toy score function used in the literature. Extensive experiments on twelve image target generation tasks and six 3D-molecule target generation tasks show significant query efficiency improvement:  \textbf{6}-times up to \textbf{10}-times query efficiency improvement on image tasks and \textbf{11}-times up to \textbf{44}-times query efficiency improvement on 3D-molecule tasks, compared with baselines. Additionally, we evaluate Fast Direct on compressibility, incompressibility, and atheistic quality tasks, demonstrating its generalization ability on the unseen prompts. Our contributions are summarized as follows:
\vspace{0pt}
\begin{itemize}[topsep=0pt,leftmargin=*, labelindent=10pt,itemsep=0pt]
\item We propose a novel guided noise sequence optimization (GNSO) technique to guide the diffusion model sampling process toward a given target in an efficient and robust manner.
\item Based on GNSO, we further propose a novel algorithm, Fast Direct, to address online black-box target generation tasks in a query-efficient manner.
\item Fast Direct achieves significant query efficiency improvement in real-world applications: high-resolution image target generation tasks and 3D-molecule target generation tasks. Additionally, we demonstrate its generalization capability for unseen prompts.
\end{itemize}

% For 3D-molecule target generation tasks,   we employ Vina score as the black-box objective, which is more practical and challenging compared with the logP score used in the literature. 

% {\color{red}
% Our method guided the sampling process of the diffusion model at inference time by moving along the gradient direction on the data manifold.  To be specific, we employ the Gaussian process with shift-invariant kernels as the surrogate.  The GP model enables us to compute the surrogate prediction in a closed form.  Moreover, we show that the gradient of the GP with shift-invariant kernels lies in a manifold spanned by data, 
% which is important to guide diffusion target generation while avoiding degenerating generation quality. 
% }


% At the high level, we extend classifier guidance by replacing the classifier model with a surrogate objective model which incrementally learns the objective value during runtime. During inference, the sampling trajectory is guided by this surrogate model to achieve optimal objective value. In section [3], we first study different guidance directions and empirically show that our proposed \textbf{last-sample gradient guidance} can achieve the near-optimal objective. Next, we investigate different types of surrogate object models and conclude that \textbf{non-parametric model} significantly outperforms deep neural networks when data is limited. Lastly, leveraging these two techniques, we present our complete algorithm QOBG.

% % explains results
% We demonstrate our algorithm in the targeted image generation task. We use SDXL as the backbone text-to-image model, and we notice several prompts where the pre-trained model is unable to generate successful images. We utilize modern chat agents such as ChatGPT 4 and Gemini 1.5 as the objective function to evaluate how well the generated images align with the given prompts. We show that our algorithm can guide the diffusion model to successfully generate the desired images with as few as 10 batch objective queries. This is significantly more query-efficient than existing methods that require hundreds of queries.

% % summary
% Our contributions are twofold:
% \begin{itemize}
% 	\item We introduce QOBG, an online guidance algorithm for targeted generation with black-box objectives using diffusion models. Unlike existing methods that rely on computationally expensive fine-tuning, the guidance approach offers greater flexibility and efficiency, and it can be used in conjunction with the fine-tuning method. To our knowledge, this is the first exploration of \textbf{online guidance} in this context.
% 	\item We empirically demonstrate that our algorithm is significantly more \textbf{query-efficient} than existing fine-tuning methods.
% \end{itemize}

\section{Related Works}
%In this section, we briefly review two main approaches for target generation.
\subsection{Guided Generation}
Diffusion guided generation (also called inference-time guidance) refers to the technique to guide the sampling trajectory of the pre-trained diffusion to generate target data \citep{10081412,chen2024overview}. The key advantage of this approach is that it does not require updating the model parameters, which is computationally expensive, especially for large models.

\cite{dhariwal2021diffusion} proposed classifier guidance. However, it requires a guidance model trained on noisy images with different noise scales, which is generally not readily available and often requires training from scratch for each domain. \cite{chung2022diffusion,bansal2023universal,he2023manifold} extend the classifier guidance by using a differentiable objective function defined only for clean data. Instead of using noisy images, the predicted clean images at each sampling step are used as the input for the guidance objective function. In this way, the guidance process can operate on the clean image space. While the predicted clean image is naturally imperfect, empirically it still provides informative feedback to guide image generation \citep{bansal2023universal}.

However, this approximation can harm image quality. \cite{bansal2023universal} proposed universal guidance that comprises backward guidance followed by a self-recurrence step to preserve image quality. On the other hand, \cite{he2023manifold} leverages the differentiability of a well-trained auto-encoder to project the image to the data manifold and thus preserve image quality during the guidance process. Instead of guiding the sampling trajectory, \cite{karunratanakul2024optimizing,eyring2024reno} treat the diffusion process as a black-box and only optimize the initial (prior) noise.

While the aforementioned approaches assume a differentiable objective function, \cite{lu2023contrastive} tackles black-box objective $f$ by learning a differentiable proxy neural network $h$ to match their gradients, i.e., $\nabla f \approx \nabla h$. \cite{li2024derivative} eliminates the need for a differentiable proxy model by employing importance sampling weighted by the objective values during the sampling process. Most recently, DNO~\citep{tang2024tuning} proposes optimizing the diffusion noise sequence by using ZO-SGD~\citep{nesterov2017random} to tackle the black-box objective function. However, it runs at the instance level; namely, each run only produces one image.

%To the best of our knowledge, how to develop inference-time guidance methods for online guidance with black-box objective functions remains an open problem. Existing approaches are either offline or assume differentiable objective functions. 

\subsection{Diffusion-model Fine-tuning}
Diffusion-model fine-tuning refers to the technique that updating the pre-trained diffusion-model parameters to improve its performance on a specific use case. In this section, we review the fine-tuning methods that support online learning of the black-box objective function.

\cite{black2023training,fan2024reinforcement} formulate the diffusion fine-tuning problem as a reinforcement learning (RL) problem within Markov Decision Processes (MDPs), and propose an iterative algorithm to fine-tune the diffusion model by using Proximal Policy Optimization (PPO) \citep{schulman2017equivalence,uehara2024understanding} loss function. \cite{fan2024reinforcement} integrates the PPO with a KL regularization to prevent the fine-tuned model from deviating too much from the pre-trained model. 

On the other hand, \cite{yang2024using} does not require an absolute objective value; instead, it uses the relative reward on a pair of samples by integrating DPO (Direct Preference Optimization) \citep{rafailov2024direct}, a technique for fine-tuning large language models, into the diffusion model.

Fine-tuning the diffusion model requires a large amount of GPU memory. Existing work mitigates memory consumption by using the LoRA technique (Low-Rank Adaptation) \citep{hu2021lora} and only fine-tunes parameters of the attention blocks in UNet. We categorize the related works based on whether they support the online and black-box objective tasks in Appendix \ref{appendix_related_works} Table \ref{tab:related_works}.

\section{Methods}

In this section, we first present a novel inference-time guidance generation method by guided noise sequence optimization.  Based on this method,  we further present our query-efficient online black-box guidance algorithm, Fast Direct,  to address online black-box guidance tasks.  


\subsection{Noise Sequence Optimization with Target Guidance}\label{TargetGuidanceQ1}

%\setlength{\textfloatsep}{0pt}
\begin{algorithm}[ht]
  \DontPrintSemicolon
  \caption{Guided Noise Sequence Optimization}
  \algorithmfootnote{
	Line 4 - Line 6: Call diffusion-model sampler to generate data $\boldsymbol{x}_K$. \\
  	Line 7 - Line 9: Update the noise $\boldsymbol{\epsilon}_k$ by moving along direction $\boldsymbol{x}^* - \boldsymbol{x}_K$. 
  }
  \label{QOBGwithTarget}

  \KwIn{Stepsize $\alpha$, target data $\boldsymbol{x}^*$, number of diffusion sampling steps $K$, pre-trained diffusion sampler $\mathcal{S}_\theta$, number of iterations $T$.}
  \KwOut{Generated target $\boldsymbol{x}_K$.}

  Take i.i.d. noise $\{\boldsymbol{\epsilon}_0, \cdots, \boldsymbol{\epsilon}_K\} \sim \mathcal{N}(\boldsymbol{0}, \boldsymbol{I})$\;
  Compute the norm of noise $\epsilon_k^{\text{norm}} = \|\boldsymbol{\epsilon}_k\|$ for $k \in \{0,\cdots,K \}$.\;
  
  \For{$t \gets 1$ \KwTo $T$}{
    $\boldsymbol{x}_0 \gets \boldsymbol{\epsilon}_0$\;
    \For{$k \gets 1$ \KwTo $K$}{
      $\boldsymbol{x}_k \gets \mathcal{S}_\theta(\boldsymbol{x}_{k-1}, \boldsymbol{\epsilon}_k)$\;
    }
    \For{$k \gets 0$ \KwTo $K$}{
      $\hat{\boldsymbol{\epsilon}}_k \gets \boldsymbol{\epsilon}_k + \alpha (\boldsymbol{x}^* - \boldsymbol{x}_K)$\;
      $\boldsymbol{\epsilon}_k \gets \frac{\hat{\boldsymbol{\epsilon}}_k}{\|\hat{\boldsymbol{\epsilon}}_k\|} \epsilon_k^{\text{norm}}$\;
    }
  }
\end{algorithm}


\begin{figure}[ht]
  \centering
  \vspace{-10pt}
  \includegraphics[width=0.85\linewidth]{./figures/demo-1.jpeg}
  \vspace{-5pt}
  \captionsetup{belowskip=0pt}
  \caption{Demonstration of guided generation for a given target by Algorithm~\ref{QOBGwithTarget}. Column 2 (Update Direction) indicates the update term of Algorithm \ref{QOBGwithTarget}, Line 8. Rows 1 to 3 analyze how different update directions can affect the generated images. Rows 4 and 5 show that by using the update direction of $\boldsymbol{x}^*-\boldsymbol{x}_K$, the diffusion model can generate visually satisfying images even when the target image is noisy. The noisy target image ($\boldsymbol{x}^*$) of the row 4 is obtained by clean image added with noise $\mathcal{N}(\boldsymbol{0},\boldsymbol{I})$, and row 5 is added with noise $\mathcal{N}(\boldsymbol{0},9 \times \boldsymbol{I})$.}
  \label{fig:algo1_demo}
  \vspace{-15pt}
\end{figure}


%Given a pre-trained diffusion model,
 Take i.i.d. Gaussian samples $\{ \boldsymbol{\epsilon}_0,\cdots,\boldsymbol{\epsilon}_K \} \sim \mathcal{N}(\boldsymbol{0},\boldsymbol{I})$, for $k \in \{1,\cdots,K\}$,  the inference process of the diffusion model can be formulated as follows:
\begin{align}
    \boldsymbol{x}_{k}  = \mathcal{S}_\theta(\boldsymbol{x}_{k-1}, \boldsymbol{\epsilon}_k),
\end{align}
where $\mathcal{S}_\theta(\cdot,\cdot)$ denotes the diffusion model sampler that depends on the concrete SDE solver used,   $\boldsymbol{x}_0= \boldsymbol{\epsilon}_0$ is a Gaussian sample, and $\boldsymbol{x}_K$ denotes the generated data. 


\textit{Question 1: Given an input target $\boldsymbol{x}^*$, can we guide a pre-trained diffusion model at inference time to generate the target data efficiently and robustly?}

To answer this question, we need to develop an algorithm to address two challenges simultaneously: (1) Guidance Efficiency:  the algorithm can generate the target data $\boldsymbol{x}^*$ by using only a few guidance update steps. (2) Robust to noisy target:  given a noisy target (e.g., a noise-perturbed image), the algorithm can generate meaningful target data (e.g., a clear image).

 We propose a novel guided noise sequence optimization method to address the above two challenges, which is presented in Algorithm~\ref{QOBGwithTarget}. Our method optimizes the noise sequence by updating the noise along the direction on the data manifold. 
Specifically, Algorithm~\ref{QOBGwithTarget} consists of two procedures: a data generation procedure and a noise update procedure.  In the data generation procedure, 
Line 4 - Line 6 in Algorithm~\ref{QOBGwithTarget} employ current noise sequence $\{ \boldsymbol{\epsilon}_0,\cdots,\boldsymbol{\epsilon}_K \}$
to generate a data $\boldsymbol{x}_K$.  In the noise update procedure, Lines 7 - 9 in Algorithm~\ref{QOBGwithTarget}, we update each noise $\boldsymbol{\epsilon}_k$
by moving along a universal  direction $ \boldsymbol{x}^* - \boldsymbol{x}_K$. Then, Algorithm~\ref{QOBGwithTarget} continues to employ the updated noise to generate a new data $\boldsymbol{x}_K$.     By looping the data generation procedure and noise update procedure, Algorithm~\ref{QOBGwithTarget} can generate a clear and meaningful target. 

 The  direction $ \boldsymbol{x}^* - \boldsymbol{x}_K$ point from the current generation data $\boldsymbol{x}_K$ to the target $\boldsymbol{x}^*$. Intuitively, moving in this direction will shift the diffusion sampling trajectory toward the target. 
We highlight the advantage of updating noise with the \textit{universal direction} $ \boldsymbol{x}^* - \boldsymbol{x}_K$ compared with direction $ \boldsymbol{x}^* - \boldsymbol{x}_k$  as the following remark. 

% and will guide the generation process to fast converge to the target. 

\textbf{Remark:} In our Algorithm~\ref{QOBGwithTarget}, we guided the noise update by moving along a universal direction $\boldsymbol{x}^*-\boldsymbol{x}_K$.  This direction lies in the data manifold, which alleviates the quality degeneration of the generated data.  We employ the direction $\boldsymbol{x}^*-\boldsymbol{x}_K$ instead of the direction $\boldsymbol{x}^*-\boldsymbol{x}_k$ because the internal $\boldsymbol{x}_k$ during inference sampling process may be far away from the data manifold (e.g., the $\boldsymbol{x}_k$  can be a very noisy and distorted image), which may degenerate the quality.  

%In contrast,  direction $\boldsymbol{x}^*-\boldsymbol{x}_k$ involves the internal results $\boldsymbol{x}_k$  of diffusion sampling process, which 



We empirically evaluate Algorithm~\ref{QOBGwithTarget} with different update directions: $\vec{d} = \boldsymbol{x}^*-\boldsymbol{x}_K$ and $\vec{d} = \boldsymbol{x}^*-\boldsymbol{x}_k$. Additionally, we consider the approximation $\boldsymbol{x}_K \approx \hat{\boldsymbol{x}}_k$\footnote{The $\hat{\boldsymbol{x}}_k$ is the "predicted clean image" at step $k$, see the Eq.12 of DDIM~\citep{song2020denoising}. Note that it is undefined for the initial step, so we simply set $\hat{\boldsymbol{x}}_0 \coloneqq \hat{\boldsymbol{x}}_1$.\vspace{-15pt}}. Lastly, we set the noisy target to test the robustness. We use the stable-diffusion model as the pre-trained model. The stepsize $\alpha$ is set to $\alpha=2 \times 10^{-3}$. 
% The empirical generation results are shown in Figure~\ref{fig:algo1_demo} as a demonstration. In Figure~\ref{fig:algo1_demo}, we list the generated image every 10 iterations on the right-hand side of the "Update Direction".
We present the generated images every 10 iterations for each case in Figure~\ref{fig:algo1_demo}.

From Figure~\ref{fig:algo1_demo}, we can observe that Algorithm~\ref{QOBGwithTarget} (with update direction $\boldsymbol{x}^*-\boldsymbol{x}_K$) can successfully guide the diffusion process towards the target image, while  $\boldsymbol{x}^*-\boldsymbol{x}_k$ leads to a degenerated image. The approximation $\boldsymbol{x}^*-\hat{\boldsymbol{x}}_K$ can achieve comparable target image but not as accurate as $\boldsymbol{x}^*-\boldsymbol{x}_K$.




% We show the guided generation of  Algorithm~\ref{QOBGwithTarget} on clean target and noisy target in Figure~\ref{fig:algo1_demo}. {\color{red} To do: Add Discussion about demo experiments}

Interestingly, even the input target $\boldsymbol{x}^*$ is perturbed by noise and lies out of the data manifold, Algorithm~\ref{QOBGwithTarget} will 
generate a pseudo-data on data manifold that is similar to the noisy target $\boldsymbol{x}^*$ but with much higher quality compared with the input noisy target.  This property is important for designing black-box guidance methods because the update direction is an approximation or estimation of the true gradient of the black-box objective. 

Moreover, we present the updating direction $\boldsymbol{x}^*-\boldsymbol{x}_{K'}$ for $K' \in \{K, K/2, K/4, K/8\}$ in Appendix~\ref{appendix:universal_direction}. We observe that the generated image quality decreases as the $\boldsymbol{x}_{K'}$ becomes noisier.

% \begin{algorithm}[t]
%   \caption{Guided Noise Sequence Optimization}
%   \label{QOBGwithTarget}
% \begin{algorithmic}[1]
%     \STATE {\bf Input:}  stepsize $\alpha$, target data $\boldsymbol{x}^*$,  number of diffusion sampling step $K$,  pre-trained  diffusion sampler $\mathcal{S}_\theta$.  Number of iterations $T$. 
% 	%\STATE Initialization: $\mathcal{D}=\{\}$.
	
% 	\STATE Take i.i.d. noise $\{ \boldsymbol{\epsilon}_0,\cdots,\boldsymbol{\epsilon}_K \} \sim \mathcal{N}(\boldsymbol{0},\boldsymbol{I})$. 

%    \STATE Compute the norm of noise $\{ \|\boldsymbol{\epsilon}_0 \|,\cdots,\|\boldsymbol{\epsilon}_K \| \}$. 
		
% 		\FOR{$t=1,\cdots ,T$}
%                \STATE /* Comment: Line 6- Line 9 call diffusion-model sampler to generate data $\boldsymbol{x}_K$  */ 
% 			\STATE $\boldsymbol{x}_0 \leftarrow \boldsymbol{\epsilon}_0$   
% 			\FOR{$k=1,\cdots ,K$}  
% 			\STATE $\boldsymbol{x}_k \leftarrow \mathcal{S}_\theta(\boldsymbol{x}_{k-1}, \boldsymbol{\epsilon}_k)$ 
% 			\ENDFOR

%                 \STATE /* Comment: Line 11- Line 14 update the noise  by moving along direction $\boldsymbol{x}^* - \boldsymbol{x}_K$  */ 
% 			\FOR{$k=0,\cdots ,K$}
% 			\STATE $\hat{\boldsymbol{\epsilon}}_k \leftarrow \boldsymbol{\epsilon}_k + \alpha (\boldsymbol{x}^* - \boldsymbol{x}_K) $
% 			% \STATE $\epsilon_k \leftarrow \text{Proj}_{\mathbb{S}^{d-1}(\|\epsilon_k \|) }(\hat{\epsilon}_k)$
%             \STATE $\boldsymbol{\epsilon}_k \leftarrow  \frac{\hat{\boldsymbol{\epsilon}}_k}{\|\hat{\boldsymbol{\epsilon}}_k \|} \|\boldsymbol{\epsilon}_k \| $
% 			\ENDFOR
% 		\ENDFOR

%     \STATE   Return target generation  $\boldsymbol{x}_K$ and noise sequence $\{ \boldsymbol{\epsilon}_0,\cdots,\boldsymbol{\epsilon}_K \}$
	

%  % \ENDWHILE
% \end{algorithmic}
% \end{algorithm}



\subsection{query-efficient online black-box guidance}\label{section:fact_direct}


In section~\ref{TargetGuidanceQ1}, we address the diffusion guidance sampling with a given optimal target input. However, in reality, we often only have access to the black-box objective function $f(\boldsymbol{x})$, where the optimal target data $\boldsymbol{x}^* = \arg \min f(\boldsymbol{x})$ is unknown. In this section, we further investigate the diffusion guidance sampling with only black-box objective feedback. For this task, it is natural to ask the following question.

\textit{Question 2:  Can we guide a pre-trained diffusion model at inference time to generate target data with only black-box objective feedback in a query-efficient online manner?}

To answer this question, we need to address two challenges: (1) the Black-box challenge and (2) the Online guidance challenge.  
The black-box challenge means that we cannot access the gradient of the objective. The online guidance challenge means we don't have a prior dataset to train a surrogate (classifier) for guidance; we can only access the black-box objective through query feedback online. Usually, the query evaluation is expensive. Thus, query efficiency is critical. 

We start addressing the above two challenges based on our target guidance generation  Algorithm~\ref{QOBGwithTarget}. 
Although Algorithm~\ref{QOBGwithTarget} itself cannot handle black-box guidance tasks because it needs input a target $\boldsymbol{x}^*$, it provides a basis for us to design query-efficient online black-box guidance methods. 
To be specific, Algorithm~\ref{QOBGwithTarget} enables us to generate a target even updating with a noisy direction $ \boldsymbol{x}^* - \boldsymbol{x}_K$. This property is important for black-box guidance tasks because we can use a noisy estimation of the gradient of the black-box objective to guide the generation. 

 The key idea is to set a pseudo target $\hat{\boldsymbol{x}}^*$ to guide the generation process based on our Algorithm~\ref{QOBGwithTarget}.  We present our Fast Direct method as in Algorithm~\ref{FastDirect}.   In Algorithm~\ref{FastDirect}, we call Algorithm~\ref{QOBGwithTarget} inside the for-loop w.r.t. the number of batch queries $t$. The only difference compared with Alg.~\ref{QOBGwithTarget} is that we set a pseudo target $\hat{\boldsymbol{x}}^*$ in Line 10 of Algorithm~\ref{FastDirect} instead of a given fixed target $\boldsymbol{x}^*$.  

\vspace{-0pt}
\setlength{\textfloatsep}{0pt}
\begin{algorithm}[ht]
  \DontPrintSemicolon
  
  \caption{Fast Direct}
  \label{FastDirect}
  
  \KwIn{Max number of batch queries $N$, batch size $B$, step-size $\alpha$, number of diffusion sampling steps $K$, pre-trained diffusion sampler $\mathcal{S}_\theta$.}
  \KwOut{Set of optimized samples $\{ x^1_K, \cdots, x^B_K \}$, pseudo target model that learns from dataset $\mathcal{D}$.}
  Initialize $\mathcal{D} \gets \{\}$\;
  \For{$i \gets 1$ \KwTo $N$}{
  \SetKwBlock{DoParallel}{do parallel for $B$ instances}{end}
  
  \DoParallel{
  
    Take i.i.d. noise $\{\boldsymbol{\epsilon}_0, \cdots, \boldsymbol{\epsilon}_K\} \sim \mathcal{N}(\boldsymbol{0}, \boldsymbol{I})$.\;
    Compute the norm of noise $\epsilon_k^{\text{norm}} = \|\boldsymbol{\epsilon}_k\|$ for $k \in \{0,\cdots,K \}$.\;

    \For{$t \gets 1$ \KwTo $i$}{
      $\boldsymbol{x}_0 \gets \boldsymbol{\epsilon}_0$\;
      \For{$k \gets 1$ \KwTo $K$}{
        $\boldsymbol{x}_k \gets \mathcal{S}_\theta(\boldsymbol{x}_{k-1}, \boldsymbol{\epsilon}_k)$\;
      }
      Set a pseudo target $\hat{\boldsymbol{x}}^*$ by the pseudo target model with input $\boldsymbol{x}_K$.\;
      \For{$k \gets 0$ \KwTo $K$}{
        $\hat{\boldsymbol{\epsilon}}_k \gets \boldsymbol{\epsilon}_k + \alpha(\hat{\boldsymbol{x}}^* - \boldsymbol{x}_K)$\;
        $\boldsymbol{\epsilon}_k \gets \frac{\hat{\boldsymbol{\epsilon}}_k}{\|\hat{\boldsymbol{\epsilon}}_k\|} \epsilon_k^{\text{norm}}$\;
      }
    }
    Query black-box objective score $y \gets f(\boldsymbol{x}_K)$.\;
    Increment dataset $\mathcal{D} \gets \mathcal{D} \cup \{(\boldsymbol{x}_K, y)\}$.\;
    }
    Update pseudo target model with dataset $\mathcal{D}$.\;
  }
\end{algorithm}
\vspace{-5pt}


The choice of models for updating the pseudo target $\hat{\boldsymbol{x}}^*$ in Algorithm~\ref{FastDirect} is flexible, which supports various black-box target generation method designs based on our Fast Direct algorithm framework. 
In this work,  we set the pseudo target $\hat{\boldsymbol{x}}^*$ through nonparametric methods without additional training.  Specifically, we employ two methods for setting the pseudo target $\hat{\boldsymbol{x}}^*$, namely, Gaussian process (GP) update and historical optimal update. 

\textbf{Set pseudo target $\hat{\boldsymbol{x}}^*$ by GP update:}
For the GP update case, we set the pseudo target $\hat{\boldsymbol{x}}^*$ as the one gradient step update using the gradient of the posterior mean prediction of the GP surrogate model as follows:
\begin{align}\label{TargetGP}
    \hat{\boldsymbol{x}}^* = \boldsymbol{x}_K - \nabla \hat{f}(\boldsymbol{x}_K; \boldsymbol{X}^{n})
\end{align}
where $\boldsymbol{x}_K$ denotes the generated data in Algorithm~\ref{FastDirect}  and  $\hat{f}(\boldsymbol{x}_K; \boldsymbol{X}^{n} )$ denotes the  posterior prediction of the GP surrogate model~\citep{seeger2004gaussian} evaluated  at $\boldsymbol{x}_K$, which has closed-form as below:
%By employing Algorithm~\ref{QOBGwithTarget}, we use one-step updated generation as the noisy target for input of  Algorithm~\ref{QOBGwithTarget}. 
\begin{align}
 \hat{f}(\boldsymbol{x}_K; \boldsymbol{X}^{n}) =  \boldsymbol{k}(\boldsymbol{x}_K,\boldsymbol{X}^n)^\top \big(\mathcal{K}(\boldsymbol{X}^n,\boldsymbol{X}^n)+ \lambda \boldsymbol{I}\big)^{-1} \boldsymbol{y} 
\end{align}
where $\boldsymbol{X}^n= [\boldsymbol{x}^1,\cdots,\boldsymbol{x}^n]$ and $\boldsymbol{y}= [y^1,\cdots,y^n]$ denotes the collected data and its corresponding score value in the historical set $\mathcal{D}$ in Algorithm~\ref{FastDirect}, respectively.  When the historical set $\mathcal{D}$ is empty, we simply set the gradient $ \nabla \hat{f}(\boldsymbol{x}_K; \varnothing )  =0$.

In this work, we employ shift-invariant kernels that can be rewritten in the form as $k(\boldsymbol{z}_1,\boldsymbol{z}_2) = g(\|\boldsymbol{z}_1-\boldsymbol{z}_2 \|_2) $, e.g., Gaussian kernel and Mat\'ern kernel.  We show that the gradient of the GP surrogate when employing these shift-invariant kernels lies on the low-dimensional data manifold. We present this property in Proposition~\ref{proposition1}. Detailed proof of Proposition~\ref{proposition1} can be found in Appendix~\ref{Proofproposition1}.    This property enables us to generate meaningful data on the data manifold instead of degenerated data, which is important for high-dimensional diffusion-model target generation problems, e.g., high-resolution ($1024 \times 1024$) target image generation tasks.  

\begin{proposition}\label{proposition1}
Given prior data $\boldsymbol{X}^n= [\boldsymbol{x}^1,\cdots,\boldsymbol{x}^n]$ and its corresponding score $\boldsymbol{y}= [y^1,\cdots,y^n]$,  let $ \hat{f}(\boldsymbol{x}; \boldsymbol{X}^n)$ denotes the posterior mean  of the GP model. For  shift-invariant kernels  $k(\boldsymbol{z}_1,\boldsymbol{z}_2) = g(\|\boldsymbol{z}_1-\boldsymbol{z}_2 \|_2) $,  $\nabla \hat{f}(\boldsymbol{x}; \boldsymbol{X}^n)$ lies on a subspace  spanned by $[\boldsymbol{x},\boldsymbol{x}^1,\cdots,\boldsymbol{x}^n]$, where $\boldsymbol{x}^i$ denotes the $i^{th}$ data sample in $\boldsymbol{X}^n$. 
\end{proposition}



\textbf{Remark:} When setting the pseudo target $\hat{\boldsymbol{x}}^*$ as Eq.(\ref{TargetGP}),  we know the pseudo target $\hat{\boldsymbol{x}}^*$ lies on the  low-dimensional subspace spanned by data according to  Proposition~\ref{proposition1}. Usually, the gradient descent update in Eq.(\ref{TargetGP}) will lead to a new pseudo target $\hat{\boldsymbol{x}}^*$ with a lower score.  In addition, based on the empirical observation from Algorithm~\ref{QOBGwithTarget}, we know that even the pseudo target $\hat{\boldsymbol{x}}^*$ is noisy, Algorithm~\ref{QOBGwithTarget} can still generate similar data that is meaningful and lies on the data manifold. These two properties enable Algorithm~\ref{FastDirect} to generate data with lower and lower scores along the data manifold. 

%\textbf{Remark:} The gradient of the GP surrogate with shift-invariant kernel lies on the data manifold spanned by $[\boldsymbol{x},\boldsymbol{x}_1,\cdots,\boldsymbol{x}_n]$. 


\textbf{Set pseudo target $\hat{\boldsymbol{x}}^*$ by historical optimal update:} For the historical optimal update case,  we set pseudo target $\hat{\boldsymbol{x}}^*$ as the empirical  optimal point from the historical dataset $\mathcal{D}$ in Algorithm~\ref{FastDirect} as:
\begin{align}\label{historicalOpt}
    \hat{\boldsymbol{x}}^* = \argmin _{\boldsymbol{x}\in \mathcal{D}} f(\boldsymbol{x}).
\end{align}
Set pseudo target $\hat{\boldsymbol{x}}^*$ as Eq.(\ref{historicalOpt}) is an empirical approximation of the optimal target $\boldsymbol{x}^* = \argmin _{\boldsymbol{x}\in \mathcal{X}} f(\boldsymbol{x})$.  In Algorithm~\ref{FastDirect}, at each iteration w.r.t. the batch query  $i$,  we employ the generated data that achieves the current best score as the pseudo target $\hat{\boldsymbol{x}}^*$ to guide the generation process. Intuitively, given this pseudo target $\hat{\boldsymbol{x}}^*$,  Algorithm~\ref{FastDirect} will generate a batch of data that is similar to $\hat{\boldsymbol{x}}^*$ on the low-dimensional data manifold, which is promising to further improve the score. By iteratively repeating this procedure, the generated data progressively achieves lower objective scores.

% \begin{algorithm}[t]
%   \caption{Fast Direct}
%   \label{FastDirect}
% \begin{algorithmic}[1]
%     \STATE {\bf Input:} Max number of batch  queries $T$, batch size $N$, step-size $\alpha$,  number of diffusion sampling step $K$,  pre-trained  diffusion sampler $\mathcal{S}_\theta$
%     %non-parametric model $g(\cdot;\mathcal{D})$ paramaterized on dataset $\mathcal{D}$.
% 	 \STATE Initialization: $\mathcal{D}=\{\}$.
%   %\STATE Initialization: $X=\{\}$.
% 	\FOR{$t=1,\cdots ,T$}

% 	\STATE Take i.i.d. noise $\{ \boldsymbol{\epsilon}_0,\cdots,\boldsymbol{\epsilon}_K \} \sim \mathcal{N}(\boldsymbol{0},\boldsymbol{I})$. 

%    \STATE Compute the norm of noise $\{ \|\boldsymbol{\epsilon}_0 \|,\cdots,\|\boldsymbol{\epsilon}_K \| \}$. 
		
% 		\FOR{$i=1,\cdots ,t$}
%          %      \STATE /* Comment: Line 6- Line 9 call diffusion-model sampler to generate data $\boldsymbol{x}_K$  */ 
% 			\STATE $\boldsymbol{x}_0 \leftarrow \boldsymbol{\epsilon}_0$   
% 			\FOR{$k=1,\cdots ,K$}  
% 			\STATE $\boldsymbol{x}_k \leftarrow \mathcal{S}_\theta(\boldsymbol{x}_{k-1}, \boldsymbol{\epsilon}_k)$ 
% 			\ENDFOR
%           %  \STATE  Set $\hat{\boldsymbol{x}}^* \leftarrow \boldsymbol{x}_K -  \nabla g(\boldsymbol{x}_K;\mathcal{D})  $
%    %          \STATE  Set $\hat{\boldsymbol{x}}^* \leftarrow \boldsymbol{x}_K $
%    %          \FOR{$j=1,\cdots ,m$}  
% 			% \STATE  Set $\hat{\boldsymbol{x}}^* \leftarrow \hat{\boldsymbol{x}}^* - \beta \nabla g(\hat{\boldsymbol{x}}^*;\mathcal{D})  $
% 			% \ENDFOR
%         \STATE Set a pseudo target  $\hat{\boldsymbol{x}}^*$ by a nonparametric method.  
%            %     \STATE /* Comment: Line 11- Line 14 update the noise  by moving along direction $\hat{\boldsymbol{x}}^* - \boldsymbol{x}_K$  */ 
% 			\FOR{$k=0,\cdots ,K$}
% 			\STATE $\hat{\boldsymbol{\epsilon}}_k \leftarrow \boldsymbol{\epsilon}_k + \alpha ( \hat{\boldsymbol{x}}^* - \boldsymbol{x}_K) $
% 			% \STATE $\epsilon_k \leftarrow \text{Proj}_{\mathbb{S}^{d-1}(\|\epsilon_k \|) }(\hat{\epsilon}_k)$
%             \STATE $\boldsymbol{\epsilon}_k \leftarrow  \frac{\hat{\boldsymbol{\epsilon}}_k}{\|\hat{\boldsymbol{\epsilon}}_k \|} \|\boldsymbol{\epsilon}_k \| $
% 			\ENDFOR
% 		\ENDFOR
 
	
% 		\STATE Query black-box objective score $y=f(\boldsymbol{x}_K)$
% 		\STATE Increment dataset $\mathcal{D} \leftarrow \mathcal{D} \cup \{ (\boldsymbol{x}_K,y) \}$ 
%  % \STATE Update the surrogate model $g(\cdot,\mathcal{D})$ with $\mathcal{D}$.
% 	\ENDFOR

%  % \ENDWHILE
% \end{algorithmic}
% \end{algorithm}



% \begin{algorithm}[ht]
%   \caption{QOBG}
%   \label{algo}
% \begin{algorithmic}[1]
%     \STATE {\bf Input:} Max number of batch  queries $T$, batch size $N$, learning rate $\alpha$, objective function $f$, number of diffusion sampling step $K$,  pre-trained  diffusion sampler $\mathcal{S}_\theta$, non-parametric model $g(\cdot;\mathcal{D})$ paramaterized on dataset $\mathcal{D}$.
% 	\STATE Initialization: $\mathcal{D}=\{\}$.
% 	\FOR{$t=1,\cdots ,T$}
% 	\STATE Take i.i.d. noise $\{ \epsilon_0,\cdots,\epsilon_K \} \sim \mathcal{N}(\boldsymbol{0},\boldsymbol{I})$
		
% 		\FOR{$l=1,\cdots ,t$}
% 			\STATE $x_0 = \epsilon_0$
		
% 			\FOR{$k=1,\cdots ,K$}
% 			\STATE $x_k = \mathcal{S}_\theta(x_{k-1}, \epsilon_k)$
% 			\ENDFOR
		
% 			\FOR{$k=0,\cdots ,K$}
% 			\STATE $\hat{\epsilon}_k \leftarrow \epsilon_k - \alpha \nabla g(x_K;\mathcal{D})$
% 		%	\STATE $\epsilon_k \leftarrow \text{proj}(\hat{\epsilon}_k)$
%           \STATE $\epsilon_k \leftarrow  \frac{\hat{\epsilon}_k}{\|\hat{\epsilon}_k \|} \|\epsilon_k \| $
% 			\ENDFOR
% 		\ENDFOR
% 		\STATE Evaluate black-box objective at queries $y=f(x_K)$
% 		\STATE Increment dataset $\mathcal{D} \leftarrow \mathcal{D} \cup \{ (x_K,y) \}$
% 	\ENDFOR

%  % \ENDWHILE
% \end{algorithmic}
% \end{algorithm}


\section{Experiments}
\label{section:experiments}

In this section, we evaluate our algorithm in two domains, images and molecules, and compare it against four baseline methods:  DDPO~\citep{black2023training},  DPOK~\citep{fan2024reinforcement}, D3PO~\citep{yang2024using}, and DNO~\citep{tang2024tuning}. Moreover, we further evaluate our algorithm in compressibility, incompressibility, and aesthetic quality tasks in Appendix~\ref{appendix:sr_experiment}.

\subsection{Image Black-box Target Generation Task}
\label{section:image_experiment}

% introduce task
\textbf{Problem: Prompt Alignment}. We consider the image-prompt alignment problem. While the current state-of-the-art image generative models excel at generating highly realistic images, they sometimes struggle to faithfully generate images that are accurately aligned with the input prompts, especially those complex prompts involving rare object combinations, object counting, or specific object positioning.

% introduce generative model
\textbf{Pre-trained Model: SDXL-Lightning}. We use the SDXL \citep{podell2023sdxl} diffusion model as the backbone text-to-image model. It can generate a 1024$\times$1024 high-resolution realistic image. In our experiment, we use the distilled version, SDXL-Lightning \citep{lin2024sdxl}, for its high sampling efficiency, which can generate images with comparable quality with just $K=8$ steps. We use the official implementation \footnote{\url{https://huggingface.co/ByteDance/SDXL-Lightning}}

% introduce objective function
\textbf{Objective Function: Gemini 1.5}. We leverage Gemini 1.5 \citep{reid2024gemini}, an advanced multi-modal LLM service, as our black-box objective function to evaluate the alignment between input prompts and generated images. To avoid confusion, the term \textit{query} refers to the input to Gemini, while \textit{prompt} refers to the text used for image generation.

The query to Gemini 1.5 consists of the generated images with the question like: "Does the prompt \texttt{\$prompt} accurately describe the image? Rate from 1 to 5". We state the complete query in Appendix \ref{appendix_experiment}. 

Because it is a closed-source paid service, we limit the number of batch queries in our experiments, referred to as the \textit{batch query budget}. We use the Gemini 1.5 Flash model (code: \texttt{gemini-1.5-flash-001}) for its cost-efficiency, and set the temperature to $0$ for experiment consistency and reproducibility. For conciseness, we call it simply \textit{Gemini} in the following section. 


% introduce guidance algorithm
\textbf{Experiment Procedure}. We identify 12 prompts that the pre-trained model SDXL-Lighning struggles to generate, and refer to these as the 12 tasks in our experiment, where the goal is to generate images that are accurately aligned with the input prompts. We compare our Fast Direct algorithm against each baseline method, and each experiment is constrained with a $50$ batch query budget.

We perform inference-time guidance using Fast Direct (Algorithm~\ref{FastDirect}) to maximize the Gemini rating. We use the GP model in Eq. \ref{TargetGP} for the pseudo-target, and set the kernel as a Gaussian kernel, and we follow \citep{hvarfner2024vanilla} to set the lengthscale as $\lambda=\sqrt{d}$, where $\small d=4\times128\times128$ is the latent dimensionality of SDXL. We use $N=50$ iterations to utilize the $50$ batch query budget, and set the batch size as $B=32$ and step size as $\alpha=80$. We use the \texttt{EularDescreteScheduler}~\citep{karras2022elucidating} sampler as suggested by the SDXL-Lightning implementation~\citep{lin2024sdxl}, and the \texttt{DDIMScheduler}~\citep{song2020denoising} (DDIM) sampler for a fair comparison with the baselines.

For all baseline methods, we perform $50$ iterations, each iteration utilizes one batch query for updating. We set the batch size to $32$, and leave the rest of the hyperparameters as default. We state more details for baselines in the Appendix~\ref{appendix:baseline_details}. Note that for DNO, in which each experiment trial can only produce one image, we run 16 independent experiment trials and report the average results\footnote{Note that DNO spent $16 \times 50=800$ batch queries for each task.}.

% result
\textbf{Experiment Results}. We present the results for the "deer-elephant" \footnote{The complete prompt is: \texttt{A yellow reindeer and a blue elephant.}\label{main_prompt}\vspace{-10pt}} task in this section and defer the results for the other 11 tasks to Appendix \ref{appendix_images} due to space constraints.
We compare the images generated by our method with those generated by the baseline methods at each $10$ batch query intervals in Fig. \ref{fig:algo2_demo}.
We can observe that our algorithm successfully satisfies the visual objectives for both samplers within the 50 batch query budget, while the baseline methods fall short within the same budget. Similar phenomena are observed for the other 11 tasks in Appendix \ref{appendix_images}. We grant baseline methods with extra batch query budget, and we observed that DDPO and DPOK almost achieve the visual objectives, whereas D3PO and DNO remain unsuccessful in this particular task.

We collect the 32 randomly generated images using our algorithm (by utilizing a $50$ batch query budget) and present them in Fig. \ref{fig:all_images}. We can observe that most images well satisfy the visual objective. Similar phenomena are observed on the other 11 tasks as shown in Appendix \ref{appendix_images}.

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.85\linewidth]{figures/compare-baseline/compare-all-images-0.jpeg}
%  \captionsetup{belowskip=0pt}
  \caption{The generated images over each number of batch queries on the prompt "deer-eleplant" \footref{main_prompt}, extra batch query budget (until 500) is given to the baseline methods for demonstration.}
  \label{fig:algo2_demo}
  \vspace{0pt}
\end{figure}

\begin{figure}[ht]
    \vspace{0pt}
    \centering
    \includegraphics[width=0.8\textwidth]{figures/ours-final/0.jpeg}
%    \captionsetup{belowskip=0pt}
    \caption{The 32 randomly generated images for the prompt "deer-eleplant" \footref{main_prompt} guided by Fast Direct (w/ EDM) by utilizing 50 batch query budget.}
    \label{fig:all_images}
    \vspace{0pt}
\end{figure}

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/figure-image.jpeg}
    \captionsetup{belowskip=0pt}
    \caption{The average Gemini rating (from 1 to 5, higher is better) of the generated images over each number of batch queries on the 12 different tasks (the prompts abbreviation shown in bracket, see the complete prompts in Appendix \ref{tab:all_prompts}).}
    \label{fig:images_score}
    \vspace{0pt}
\end{figure}

For the quantitative results, we report the average objective values over each batch query across the 12 tasks in Fig. \ref{fig:images_score}. For DNO, which only produces one image each experiment, we average the results from 16 independent experiments. We observe that the Fast Direct achieves nearly a full score within the 50 batch query budget in all tasks, which is significantly higher than the baseline methods. Moreover, we observe that Fast Direct achieve a similar score for both samplers, suggesting it is invariant to the sampler. We further perform an ablation study in Appendix~\ref{appendix_ablation}, and show that Fast Direct is insensitive to the hyper-parameters: step size $\alpha$ and batch size $B$.

We further employ tasks 1 to 3 and assign an extra batch query budget of $200$ to the baseline methods. We report the \textit{accumulated objective values}, which represent the best objective values achieved up to each number of batch queries, in Appendix Fig. \ref{fig:images_score_accum}. We observe that our algorithm, utilizing only 50 batch query budget, consistently outperforms all baseline methods even when they are assigned with expanded batch query budget of 200.

To quantify this advantage, in Table \ref{tab:speedup}, we identify the minimum number of batch query budget (denoted as $N^*$) our algorithm requires to surpass each baseline method with their $200$ batch query budget. We further calculate ours \textit{batch-query-efficiency gain} compared to baselines as $\frac{200}{N^*}$ and report (in the bracket) in Table \ref{tab:speedup}. We can observe that our algorithm is at least 667\% and up to 1000\% more batch-query-efficient than the baseline methods.




\begin{table}[ht]
\caption{The minimum number of batch query budget (denoted as $N^*$) for Fast Direct (ours) to outperform each baseline (when each baseline is granted with $200$ batch query budget) on images and molecules tasks. The values in brackets show the batch-query-efficiency gain ($\frac{200}{N^*}$) of Fast Direct (ours) over the baselines.}
\centering
\vspace{-5pt}
\resizebox{.6\textwidth}{!}{
    \begin{tabular}{p{2.5cm}|c|c|c}
    \hline
     & \multicolumn{3}{c}{\makecell{Minimum number of batch queries ($N^*$) for \\ \textbf{Fast Direct} to outperform each baselines:}} \\
     & \textbf{DDPO} & \textbf{DPOK} & \textbf{D3PO} \\ \hline
    
    \multicolumn{4}{l}{\textbf{Image Tasks}} \\
    Task 1     & 15 (13.34$\times$) & 15 (13.34$\times$) & 10 (20.00$\times$) \\ 
    Task 2     & 8 (25.00$\times$)  & 8 (25.00$\times$)  & 4 (50.00$\times$)   \\ 
    Task 3     & 37 (5.41$\times$)  & 46 (4.34$\times$)  & 16 (12.50$\times$)  \\ \hline
    Average    & 20 (10.00$\times$) & 23 (8.70 $\times$) & 30 (6.67$\times$)   \\ \hline
    \multicolumn{4}{l}{} \\ [-5pt]
    \multicolumn{4}{l}{\textbf{Molecules Tasks}} \\
    Task 1  & 6 (33.33$\times$) & 5 (40.00$\times$) & 25 (8.00$\times$)  \\
    Task 2     & 9 (22.22$\times$)  & 4 (50.00$\times$)  & 11 (18.18$\times$)   \\ \hline
    Average    & 7.5 (26.67$\times$) & 4.5 (44.44$\times$) & 18 (11.11$\times$)   \\ \hline
    \end{tabular}
}
\label{tab:speedup}
\end{table}

\vspace{0pt}
\subsection{Molecule Black-box Target Generation Task}
\vspace{0pt}

\textbf{Problem: Drug Discovery}. We consider the drug discovery problem. One of the key problems is to find drug molecules that have a strong binding affinity with the target protein receptor. The binding affinity quantifies the strength of the interaction between two biomolecules, so a stronger binding affinity indicates a higher drug efficacy.

A traditional approach to this problem requires human-designed molecules, which are highly time-consuming. Recent advancements in AI pose a great potential to speed up this process by generating molecules using advanced generative models such as diffusion models. Although the current pre-trained molecule models, such as TargetDiff, are capable of generating relatively realistic molecules, they cannot generate molecules with the user's desired high binding affinity.

\textbf{Pre-trained Model: TargetDiff}. We use TargetDiff \citep{guan20233d} as the backbone molecules generative model. It is pre-trained on the CrossDocked2020 dataset \citep{francoeur2020three}, and can generate realistic 3D molecular structures conditioned on the given protein receptor. For sampling efficiency, we use the \texttt{DDIMScheduler} sampler with $K = 200$ sampling steps as we find that it can generate comparable results. During the generation process, we fix the atom type according to the dataset reference and only
allow the atom position to be varied. We use the official implementation \footnote{\url{https://github.com/guanjq/targetdiff}} in our experiment.

\textbf{Objective Function: Molecules Binding Affinity.} Measurement of the binding affinity requires a real-world experiment, which is highly expensive \citep{david2020molecular}. In our experiment, we leverage the Vina score (kcal/mol) calculated by the AutoDock Vina simulation software \citep{eberhardt2021autodock} to estimate the binding affinity. A lower (more negative) Vina score indicates a stronger estimated binding affinity. Therefore, our objective is to minimize the Vina score.

\textbf{Experiment Procedure.} We conduct experiments on 6 tasks, where the goal of each task is to optimize the Vina score on the protein receptors of ID from 1 to 6, respectively. Similar to image tasks, each algorithm is constrained to 50 batch query budget.

We perform inference-time guidance using our Algorithm \ref{FastDirect} to minimize the Vina score. We use the historical optimal in Eq. \ref{historicalOpt} for the pseudo-target. We use $N=50$ iterations to utilize the $50$ batch query budget, and set the batch size as $B=32$, and the step size as $\alpha=10^{-2}$. We then conduct experiments on the baseline methods for $50$ fine-tuning iterations. For DDPO and DPOK, the batch size is set as the same $32$; while D3PO requires binary rewards, so we double the batch size as $64$ \footnote{However, unlike image tasks where Gemini can evaluate rewards for two images in a single query, the Vina simulation lacks this capability, requiring 64 individual queries for a batch of size 64.}. We keep the hyperparameters as default for all baseline methods.

\textbf{Experiment Results}. We report the average Vina score (recall, lower is better) for each batch of queries across 6 tasks in Fig. \ref{fig:mol_score}. We observe that our algorithm consistently achieves much lower Vina score compared to the baseline methods across all tasks. Similar to the images task, we grant extra batch query budget of 200 to the baselines for tasks 1 and 2, and report the \textit{accumulated objective values} in Appendix Fig~\ref{fig:mol_score_accum}, and list the \textit{batch-query-efficiency gain} in Table~\ref{tab:speedup}. We observe that our algorithm is at least 1111\% and up to 4444\% more batch-query-efficient compared to the baseline methods.

% \begin{table}[ht]
% \centering
% \caption{The minimum number of batch query budget (denoted as $N^*$) for our algorithm to outperform each baseline (when the baselines are given a $200$ batch query budget). The bracket shows the
% speedup factor of Fast Direct over each baseline.}
% \begin{tabular}{|l|c|c|c|}
% \hline
%            & \makecell{$N^*$ for Fast Direct \\ to outperform DDPO} & 
%              \makecell{$N^*$ for Fast Direct \\ to outperform DPOK} &
%              \makecell{$N^*$ for Fast Direct \\ to outperform D3PO}  \\ \hline
% Task 1     & 6 (33.33$\times$) & 5 (40.00$\times$) & 25 (8.00$\times$)  \\ \hline
% Task 2     & 9 (22.22$\times$)  & 4 (50.00$\times$)  & 11 (18.18$\times$)   \\ \hline
% Average    & 7.5 (26.67$\times$) & 4.5 (44.44$\times$) & 18 (11.11$\times$)   \\ \hline
% \end{tabular}

% \label{tab:mol_speedup}
% \end{table}

\section{Conclusion}

In this work, we proposed \textbf{Fast Direct} for diffusion model target generation, which effectively addresses the challenges of limited batch query budgets and black-box objective functions, demonstrating its potential for various applications, including image generation and drug discovery. Fast Direct is highly practical, as it is easy to implement, supports any type of SDE solver, and has only one hyper-parameter to tune (step size $\alpha$).
Our algorithm is based on the surprising empirical observation that the \textit{universal update direction} (i.e., $\boldsymbol{x}^*-\boldsymbol{x}_K$ in Algorithm \ref{QOBGwithTarget}) can efficiently guide the diffusion trajectory toward the target, even when the target $\boldsymbol{x}^*$ is extremely noisy. This phenomenon suggests an intriguing robustness in the diffusion inference process. Future research could investigate its underlying theoretical principles.

\subsubsection*{Acknowledgments}
This research is supported by the National Research Foundation, Singapore and Infocomm Media Development Authority under its Trust Tech Funding Initiative, the Center for Frontier Artificial Intelligence Research Center, Institute of High Performance Computing, A*Star, and the College of Computing and Data Science at Nanyang Technological University. Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not reflect the views of National Research Foundation, Singapore and Infocomm Media Development Authority. Yueming Lyu is supported by
Career Development Fund (CDF) of the Agency for Science, Technology and Research (A*STAR) (No: C243512014 and No: C233312007).

\bibliography{iclr2025_conference}
\bibliographystyle{iclr2025_conference}

\newpage

\appendix

\section{More Experiments: Compressibility, Incompressibility, and Aesthetic Quality}

\label{appendix:sr_experiment}

\textbf{Problem.} We follow DDPO~\citep{black2023training} to evaluate our algorithm on the three black-box optimization tasks for images: compressibility, incompressibility, and aesthetic quality.

\textbf{Objective Function.} For compressibility, we aimed to minimize the compressed JPEG size (MB) of the generated images. For incompressibility, it's simply the inverse. For aesthetic quality, the aesthetic score is evaluated by the pre-trained LAION aesthetics predictor~\citep{schuhmann2022laion}, which is trained on human ratings of the images' aesthetic quality, and we aimed to maximize the aesthetic score.

\textbf{Experiment Procedure.} For each task, we uniformly sample from the 45 common animals (as proposed by DDPO~\citep{black2023training}) as input prompts and optimize the objective using Fast Direct in Algorithm~\ref{FastDirect}. The prompt for each instance within a batch is sampled randomly and independently. We set $N=50$ batch query budget for compressibility and incompressibility, and $N=100$ for aesthetic quality. We use the same pre-trained model, hyper-parameters, and GP settings as in Section~\ref{section:image_experiment}. The 45 common animal prompts used in the experiment are as follows: \\
\begin{center}
\begin{tabular}{c|c|c|c|c|c|c|c|c}
cat     & dog      & horse    & monkey    & rabbit    & zebra    & spider   & bird      & sheep     \\
deer    & cow      & goat     & lion      & tiger     & bear     & raccoon  & fox       & wolf      \\
lizard  & beetle   & ant      & butterfly & fish      & shark    & whale    & dolphin   & squirrel  \\
mouse   & rat      & snake    & turtle    & frog      & chicken  & duck     & goose     & bee       \\
pig     & turkey   & fly      & llama     & camel     & bat      & gorilla  & hedgehog  & kangaroo  \\
\end{tabular}
\end{center}

For DNO, each experimental trial generates only a single image, and the objective score is highly dependent on the specific prompt. To ensure a more accurate evaluation, we run $45$ independent experiment trials using each prompt and report the average results. Consequently, DNO requires $45 \times$ more batch queries per task compared to other methods.

\textbf{Experiment Result.} We present the objective scores for each task in the left column of Fig.~\ref{fig:sr_score} and provide the generated images for the three tasks in the supplementary materials. For compressibility and incompressibility, we observe that Fast Direct achieves significantly better scores than the baselines. For aesthetic quality, Fast Direct with the EDM sampler achieves significantly better scores than with DDIM, likely due to EDM being a more advanced sampler, capable of generating higher-quality images. DNO achieves comparable scores; however, note that each experiment optimizes and generates only a single image.


\begin{figure}[ht!]
  \centering
  \includegraphics[width=1\linewidth]{figures/figure-sr.jpeg}
  \caption{Left column: The average objective score of the generated images over each number of batch queries on the 3 black-box optimization tasks, the images are generated using the 45 common animals that were used in DDPO~\citep{tang2024tuning} as the input prompts. Right column: The objective score of the images generated by \textbf{unseen prompts}, which demonstrates the generalization capability. Note that DNO is not applicable to this task.}
  \label{fig:sr_score}
\end{figure}


\textbf{Generalization Ability.}
We follow DDPO to evaluate generalization ability. For Fast Direct, we freeze the learned GP model to generate 16 unseen images using distinct unseen animal prompts. Specifically, in this phase, Lines 17 and 18 are removed from Algorithm~\ref{FastDirect}, and our algorithm does not access the objective function. For DDPO, DPOK, and D3PO, the fine-tuned models are frozen to generate images with the 16 unseen animal prompts. DNO is not applicable to the generalization experiment, as it performs per-image optimization and lacks generalization ability. For the unseen prompts, since DDPO didn't publish the unseen prompts, we created our own as follows:
\begin{center}
\begin{tabular}{c|c|c|c|c|c|c|c}
elephant  & eagle     & pigeon    & hippo     & hamster   & otter     & panda    & reindeer   \\
owl       & penguin   & flamingo  & seal      & koala     & giraffe   & parrot   & cheetah    \\
\end{tabular}
\end{center}

In Fig.\ref{fig:sr_images}, we present the images generated using the unseen prompt "hippo" by each algorithm across the three tasks. The remaining 15 prompts for the three tasks are provided in the supplementary material. A similar phenomenon is observed for all 15 other unseen prompts across the three tasks. For quantitative evaluation, we report the objective values for the unseen prompts in the right column of Fig.\ref{fig:sr_score}. We can observe that Fast Direct with the GP model has generalization ability to unseen prompts.

% We observe that Fast Direct can visually achieve the objective in all tasks. This result is non-trivial, as the GP model does not contain any images of a "hippo" and is not aware of the specific image prompt. From an optimization perspective, converging to any of the 45 "aesthetic animals" stored in the GP model could yield a high objective value. Therefore, regularization is typically required to prevent the diffusion trajectory from deviating too far. Interestingly, vanilla Fast Direct, without any special prompt-related regularization, remains visually faithful to the unseen input prompt instead of blindly optimizing the objective. 


\begin{figure}[h]
    \centering
    \subfigure[\scriptsize{Compressibility}]{
        \includegraphics[width=0.8\textwidth]{figures/compare-baseline/compare-all-images-12.jpeg}}
   \subfigure[\scriptsize{Incompressibility}]{
        \includegraphics[width=0.8\textwidth]{figures/compare-baseline/compare-all-images-13.jpeg}
        }
   \subfigure[\scriptsize{Aesthetic Quality}]{
        \includegraphics[width=0.8\textwidth]{figures/compare-baseline/compare-all-images-14.jpeg}
        }
    \caption{The generated images using the unseen prompt "hippo" in the aesthetic quality task, extra batch query budgets (until 500) are given to the baseline methods for demonstration.}
    \label{fig:sr_images}
\end{figure}


\begin{figure}[h]
    \centering
    \subfigure[\scriptsize{Pre-trained}]{
        \includegraphics[width=0.48\textwidth]{figures/ours-init/12-val.jpeg}}
   \subfigure[\scriptsize{Compressibility}]{
        \includegraphics[width=0.48\textwidth]{figures/ours-final/12-val.jpeg}
        }
   \subfigure[\scriptsize{Incompressibility}]{
        \includegraphics[width=0.48\textwidth]{figures/ours-final/13-val.jpeg}
        }
   \subfigure[\scriptsize{Aesthetic Quality}]{
        \includegraphics[width=0.48\textwidth]{figures/ours-final/14-val.jpeg}
        }
    \caption{The generated images using the 16 unseen prompts. Top left is the image generated by the pre-trained model, the rest are the Fast Direct generated images in the corresponding tasks.}
    \label{fig:sr_16_images}
\end{figure}


\clearpage
\newpage 
\section{Ablation Study}
\label{appendix_ablation}

%We perform an ablation study to investigate whether our algorithm is sensitive to the hyperparameters. 

We perform an ablation study on the target image generation  Task-1.
For step size analysis, we fix the batch size as $32$, then perform experiment with different step size $\alpha = \{ 20,40,80,160,320 \}$; for batch size analysis, we fix the step size as $80$, then perform experiment with different batch size $B = \{ 4,8,16,32,64 \}$. Additionally, we report the run time for different batch sizes. We report the result in Fig.~\ref{fig:ablation}.

We can observe that the performance steadily increases for any step size and any batch size, which suggests that our algorithm is not sensitive to the hyperparameter settings. The run time scales linearly with the batch size. In our target image generation experiments in Section~\ref{section:image_experiment}, as the batch size is set as $32$, each experiment takes approximately $6.4$ hours to process $32$ images in parallel.

\begin{figure}[h]
    \centering
    \includegraphics[width=1\linewidth]{figures/ablation.jpeg}
  	\caption{Left: Gemini rating for different step size settings. Middle: Gemini rating for different batch size settings. Right: Run time (hours) for different batch size settings.}
    \label{fig:ablation}
\end{figure}


\section{Analysis of Universal Direction}
\label{appendix:universal_direction}

In Fig.~\ref{fig:ablation_demo_1_k}, we demonstrate Algorithm~\ref{QOBGwithTarget} with update direction $\vec{d} = \boldsymbol{x}^*-\boldsymbol{x}_{K'}$ for $K' \in \{ K, K/2, K/4, K/8 \}$. It shows that the generated image quality decreases as the  $K'$ decreases. This is because as $K'$ decreases, the $\boldsymbol{x}_{K'}$ becomes noisier and may move further away from the data manifold.

\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/demo-1-ablation.jpeg}
    \caption{The update direction $\vec{d} = \boldsymbol{x}^*-\boldsymbol{x}_{K'}$ for $K' \in \{ K, K/2, K/4, K/8 \}$, the generated images quality decrease as the $\boldsymbol{x}_{K'}$ being more more noisy.}
    \label{fig:ablation_demo_1_k}
\end{figure}

\section{Baselines Details}
\label{appendix:baseline_details}

For DDPO, DPOK, and D3PO, we fine-tune the model to maximize the Gemini rating. We fine-tune the model with $50$ epochs; each epoch utilizes one batch query for model updating. For DDPO and DPOK, we set the batch size to $32$; for D3PO, it requires a relative reward, so we doubled the batch size to $64$.\footnote{For D3PO, to evaluate $64$ images only requires $32$ queries calls, see Appendix \ref{appendix_experiment}.} As these RL-based methods require closed-form expression of the logarithm probabilities, we follow their official implementation to use the \texttt{DDIMScheduler} \citep{song2020denoising} sampler.

For DNO, we optimize the noise sequence w.r.t the Gemini rating. Recall that the Gemini is a black-box, so we use the non-differentiable mode, with the number of samples for gradient approximation set as $32$, and optimize for $50$ iterations; each iteration utilizes one batch query for updating. However, each experiment of DNO only produces one image, where the score is highly dependent on the initial prior. Thus, for a more accurate evaluation, we run 16 independent experiments to generate 16 images and report the average results. Note that this requires $16 \times 50=800$ batch queries for each task, which is $16$ times compared with our Fast Direct and other baselines. 

\section{Proof of Proposition~\ref{proposition1}}
\label{Proofproposition1}


\begin{proof}
   Let $\boldsymbol{\alpha}= \big(\mathcal{K}(\boldsymbol{X}^n,\boldsymbol{X}^n)+ \lambda \boldsymbol{I}\big)^{-1} \boldsymbol{y} =[\alpha_1,\cdots,\alpha_n]^\top $, for GP with a shift-invariant kernel that can be rewritten as  $k(\boldsymbol{z}_1,\boldsymbol{z}_2)= g(\|\boldsymbol{z}_1-\boldsymbol{z}_2 \|_2)$, the gradient of the GP prediction is 
\begin{align}
    \nabla\hat{f}(\boldsymbol{x}; \boldsymbol{X}^n) & = \nabla \boldsymbol{k}(\boldsymbol{x},\boldsymbol{X}^n)^\top \boldsymbol{\alpha} \\
    & = \sum_{i=1}^n \alpha_i \nabla {k}(\boldsymbol{x}, \boldsymbol{x}^i)  \\
    & = \sum_{i=1}^n  \frac{\alpha_i}{\|\boldsymbol{x}-\boldsymbol{x}^i \|}  g'( \|\boldsymbol{x}-\boldsymbol{x}^i \|_2 )  ( \boldsymbol{x}-\boldsymbol{x}^i ) \\
    & = \sum_{i=1}^n c_i(\boldsymbol{x}) ( \boldsymbol{x}-\boldsymbol{x}^i ) \label{LinearCom}
\end{align}
where $\boldsymbol{x}^i$ denotes the $i^{th}$ sample in $\boldsymbol{X}^n= [\boldsymbol{x}^1,\cdots,\boldsymbol{x}^n]$, and $c_i(\boldsymbol{x})= \frac{\alpha_i}{\|\boldsymbol{x}-\boldsymbol{x}^i \|}  g'( \|\boldsymbol{x}-\boldsymbol{x}^i \|_2 ) $, and $g'(\cdot)$ denotes the derivative of $g(\cdot)$.  

From Eq.(\ref{LinearCom}), we can see that the gradient $\nabla\hat{f}(\boldsymbol{x}; \boldsymbol{X}^n)$ is a weighted sum of $\boldsymbol{x} - \boldsymbol{x}^i$ for $i \in \{1,\cdots,n\}$. Thus, we know $\nabla\hat{f}(\boldsymbol{x}; \boldsymbol{X}^n)$ lies on a  subspace spanned by $[\boldsymbol{x},\boldsymbol{x}^1,\cdots,\boldsymbol{x}^n]$

\end{proof}

\section{Overview of Related Works}
\label{appendix_related_works}

We present the summary of related works according to their category and supported problem scenarios in Table \ref{tab:related_works}.

\begin{table}[!ht]
\centering
\captionsetup{aboveskip=0pt}
\caption{Overview of existing approaches.}
\resizebox{.75\textwidth}{!}{
\begin{tabular}{|l|l|c|c|}
\hline
Algorithm Category & Algorithm & Online & Black-box \\ \hline
\multirow{3}{*}{\makecell[l]{Training / \\ Fine-tune}} &
    DRaFT \citep{clark2023directly} & 
        \cmark & \xmark \\ \cline{2-4} &
    \makecell[l]{
        DDOM \citep{krishnamoorthy2023diffusion}, \\
        RCGDM \citep{yuan2024reward}, \\
        DPO \citep{wallace2024diffusion}
    } & \xmark & \cmark \\ \cline{2-4} &
    \makecell[l]{
        DDPO \citep{black2023training}, \\
        DPOK \citep{fan2024reinforcement}, \\
        D3PO \citep{yang2024using}
    } & \cmark & \cmark
    \\ \hline
\multirow{3}{*}{\makecell[l]{Inference-time\\Guidance}} & 
    \makecell[l]{
        LGD \citep{song2023loss}, \\
        MPGD \citep{he2023manifold}, \\
        DNO (2024a) \citep{karunratanakul2024optimizing}, \\
        ReNO \citep{eyring2024reno}
    } & \cmark    & \xmark \\ \cline{2-4}  &
    CEP \citep{lu2023contrastive} & 
        \xmark     & \cmark \\ \cline{2-4} &
    \makecell[l]{
    DNO~\citep{tang2024tuning},	 \\
    CASBO~\citep{lyu2024covariance}, \\
    	\textbf{Fast Direct} (ours) 
    } & \cmark & \cmark \\ 
    \hline
\end{tabular}
}
\label{tab:related_works}
\end{table}

\section{Experiment Details}
\label{appendix_experiment}

We use the following query question for the Gemini:
\begin{quote}
\small
    \texttt{Does the prompt \underline{\$prompt} accurately describe the image?\\
    Rate from 1 (inaccurate) to 5 (accurate).\\
    Answer in the format: Score=(score), Reason=(reason).}
\normalsize
\end{quote}
where the \texttt{\underline{\$prompt}} is substituted by the input prompt used for image generation. We extract the integer score as the objective value.

The D3PO takes relative reward, so we specially crafted for its selective query question:
\begin{quote}
\small
    \texttt{Given this two images, which image is better aligned with the prompt \underline{\$prompt}? \\
    Answer in the format: Choice=(1/2), Reason=(reason).}
\normalsize
\end{quote}
where we extract the choice (1/2) as the selections.

The Gemini 1.5 Flash can faithfully respond with the correct format to ensure our experiment is consistent.

\section{Molecules Generation Experiment Results}
We report the average Vina score in the molecules generation task in Fig.~\ref{fig:mol_score}.

\begin{figure}[ht]
    \centering
    \includegraphics[width=1.0\textwidth]{figures/figure-mol.jpeg}
    \captionsetup{belowskip=-0pt}
    \caption{The Vina score (lower is better) of the generated molecules for each number of batch queries on the six protein receptors.}
    \label{fig:mol_score}
    \vspace{0pt}
\end{figure}

\section{More Experiment Results}
\label{appendix_experiment_result}
We report the accumulated objective values over the number of batch queries for the images task in Fig. \ref{fig:images_score_accum}, and for the molecules task in Fig. \ref{fig:mol_score_accum}.

\begin{figure}[ht]
    \centering
    \includegraphics[width=\textwidth]{figures/figure-image-accum.jpeg}
    \caption{The accumulated Gemini rating (from 1 to 5, higher is better) over the number of batch queries. The accumulated plot displays the maximum Gemini rating achieved for each number of batch queries.}
    \label{fig:images_score_accum}
\end{figure}

\begin{figure}[ht]
    \centering
    \includegraphics[width=\textwidth]{figures/figure-mol-accum.jpeg}
    \caption{The accumulated Vina score (lower is better) over the number of batch queries. The accumulated plot displays the minimum Vina score achieved up to each number of batch queries.}
    \label{fig:mol_score_accum}
\end{figure}


\section{More Generated Images by Fast Direct for Image-Prompt Alignment Task}
\label{appendix_images}

Table \ref{tab:all_prompts} shows the list the complete prompts used for each task in our image generation experiment. From Fig. \ref{fig:demo_baseline_1} to Fig. \ref{fig:demo_baseline_11}, we present the generated images of each algorithm over each number of batch queries for prompts 2 to 12. From Fig. \ref{fig:demo_32_1} to Fig. \ref{fig:demo_32_11}, we showcase the 32 randomly generated by the pre-trained model, followed by the resultant images guided by the Fast Direct for prompts 2 to 12.

\begin{table}[h]
\caption{Target Image Generation Tasks}
\begin{tabular}{p{0.08\textwidth}|p{0.21\textwidth}|p{0.67\textwidth}}
 \toprule
Task ID & Abbreviated Prompt & Complete Prompt    \\ \hline                                                                           
1       & deer-elephant      & A yellow reindeer and a blue elephant.                                                                                     \\ \hline
2       & traffic-light      & A traffic light with yellow at top, green at middle, and red at bottom.                                                    \\ \hline
3       & apple              & Seven red apples arranged in a circle.                                                                                     \\ \hline
4       & cyber-dog          & A natural fluffy dog talking to a cybertic dog.                                                                            \\ \hline
5       & puppy-nose         & Side view of a puppy lying on floor, one butterfly stopping on its nose.                                                   \\ \hline
6       & robot-plant        & A cute cybernetic robot plants a tree in the forest.                                                                       \\ \hline
7       & ocean              & A helicopter floating under the ocean.                                                                                     \\ \hline
8       & sand-glass         & A transparent glass filled with a mixture of water and sand, with one feather floating inside.                             \\ \hline
9       & penguin            & A photo realistic photo showing a penguin standing on a very small floating ice, with a tree is on fire in the background. \\ \hline
10      & basket             & Exactly one orange in a basket of apples.                                                                                  \\ \hline
11      & ice-cube           & A glass of water with exactly one ice cube.                                                                                \\ \hline
12      & cat-butterfly      & A cat with butterfly wings.                                                                                                \\ \hline
\end{tabular}
\label{tab:all_prompts}
\end{table}


\begin{figure}[h]
  \centering
  \includegraphics[width=0.8\linewidth]{figures/compare-baseline/compare-all-images-1.jpeg}
  \caption{The generated images over each number of batch queries on the prompt "traffic-light", extra batch query budgets (until 500) are given to the baseline methods for demonstration.}
  \label{fig:demo_baseline_1}
\end{figure}


\begin{figure}[h]
  \centering
  \includegraphics[width=0.8\linewidth]{figures/compare-baseline/compare-all-images-2.jpeg}
  \caption{The generated images over each number of batch queries on the prompt "apple", extra batch query budgets (until 500) are given to the baseline methods for demonstration.}
  \label{fig:demo_baseline_2}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=0.7\linewidth]{figures/compare-baseline/compare-all-images-3.jpeg}
  \caption{The generated images over each number of batch queries on the prompt "cyber-dog" for each algorithm.}
  \label{fig:demo_baseline_3}
\end{figure}


\begin{figure}[h]
  \centering
  \includegraphics[width=0.7\linewidth]{figures/compare-baseline/compare-all-images-4.jpeg}
  \caption{The generated images over each number of batch queries on the prompt "puppy-nose" for each algorithm.}
  \label{fig:demo_baseline_4}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=0.7\linewidth]{figures/compare-baseline/compare-all-images-5.jpeg}
  \caption{The generated images over each number of batch queries on the prompt "robot-plant" for each algorithm.}
  \label{fig:demo_baseline_5}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=0.7\linewidth]{figures/compare-baseline/compare-all-images-6.jpeg}
  \caption{The generated images over each number of batch queries on the prompt "ocean" for each algorithm.}
  \label{fig:demo_baseline_6}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=0.7\linewidth]{figures/compare-baseline/compare-all-images-7.jpeg}
  \caption{The generated images over each number of batch queries on the prompt "sand-glass" for each algorithm.}
  \label{fig:demo_baseline_7}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=0.7\linewidth]{figures/compare-baseline/compare-all-images-8.jpeg}
  \caption{The generated images over each number of batch queries on the prompt "penguin" for each algorithm.}
  \label{fig:demo_baseline_8}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=0.7\linewidth]{figures/compare-baseline/compare-all-images-9.jpeg}
  \caption{The generated images over each number of batch queries on the prompt "basket" for each algorithm.}
  \label{fig:demo_baseline_9}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=0.7\linewidth]{figures/compare-baseline/compare-all-images-10.jpeg}
  \caption{The generated images over each number of batch queries on the prompt "ice-cube" for each algorithm.}
  \label{fig:demo_baseline_10}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=0.7\linewidth]{figures/compare-baseline/compare-all-images-11.jpeg}
  \caption{The generated images over each number of batch queries on the prompt "cat-butterfly" for each algorithm.}
  \label{fig:demo_baseline_11}
\end{figure}

\begin{figure}[h]
    \centering
    \subfigure[\scriptsize{Pre-trained}]{
        \includegraphics[width=1\textwidth]{./figures/ours-init/1.jpeg}}
   \subfigure[\scriptsize{Fast Direct}]{
        \includegraphics[width=1\textwidth]{./figures/ours-final/1.jpeg}
        }
    \caption{The 32 randomly generated images for the prompt "traffic-light" guided by Fast Direct by utilizing 50 batch query budget.}
    \label{fig:demo_32_1}
\end{figure}

\begin{figure}[h]
    \centering
    \subfigure[\scriptsize{Pre-trained}]{
        \includegraphics[width=1\textwidth]{./figures/ours-init/2.jpeg}}
   \subfigure[\scriptsize{Fast Direct}]{
        \includegraphics[width=1\textwidth]{./figures/ours-final/2.jpeg}
        }
    \caption{The 32 randomly generated images for the prompt "apple" guided by Fast Direct by utilizing 50 batch query budget.}
    \label{fig:demo_32_2}
\end{figure}

\begin{figure}[h]
    \centering
    \subfigure[\scriptsize{Pre-trained}]{
        \includegraphics[width=1\textwidth]{./figures/ours-init/3.jpeg}}
   \subfigure[\scriptsize{Fast Direct}]{
        \includegraphics[width=1\textwidth]{./figures/ours-final/3.jpeg}
        }
    \caption{The 32 randomly generated images for the prompt "cyber-dog" guided by Fast Direct by utilizing 50 batch query budget.}
    \label{fig:demo_32_3}
\end{figure}

\begin{figure}[h]
    \centering
    \subfigure[\scriptsize{Pre-trained}]{
        \includegraphics[width=1\textwidth]{./figures/ours-init/4.jpeg}}
   \subfigure[\scriptsize{Fast Direct}]{
        \includegraphics[width=1\textwidth]{./figures/ours-final/4.jpeg}
        }
    \caption{The 32 randomly generated images for the prompt "puppy-nose" guided by Fast Direct by utilizing 50 batch query budget.}
    \label{fig:demo_32_4}
\end{figure}

\begin{figure}[h]
    \centering
    \subfigure[\scriptsize{Pre-trained}]{
        \includegraphics[width=1\textwidth]{./figures/ours-init/5.jpeg}}
   \subfigure[\scriptsize{Fast Direct}]{
        \includegraphics[width=1\textwidth]{./figures/ours-final/5.jpeg}
        }
    \caption{The 32 randomly generated images for the prompt "robot-plant" guided by Fast Direct by utilizing 50 batch query budget.}
    \label{fig:demo_32_5}
\end{figure}

\begin{figure}[h]
    \centering
    \subfigure[\scriptsize{Pre-trained}]{
        \includegraphics[width=1\textwidth]{./figures/ours-init/6.jpeg}}
   \subfigure[\scriptsize{Fast Direct}]{
        \includegraphics[width=1\textwidth]{./figures/ours-final/6.jpeg}
        }
    \caption{The 32 randomly generated images for the prompt "ocean" guided by Fast Direct by utilizing 50 batch query budget.}
    \label{fig:demo_32_6}
\end{figure}

\begin{figure}[h]
    \centering
    \subfigure[\scriptsize{Pre-trained}]{
        \includegraphics[width=1\textwidth]{./figures/ours-init/7.jpeg}}
   \subfigure[\scriptsize{Fast Direct}]{
        \includegraphics[width=1\textwidth]{./figures/ours-final/7.jpeg}
        }
    \caption{The 32 randomly generated images for the prompt "sand-glass" guided by Fast Direct by utilizing 50 batch query budget.}
    \label{fig:demo_32_7}
\end{figure}

\begin{figure}[h]
    \centering
    \subfigure[\scriptsize{Pre-trained}]{
        \includegraphics[width=1\textwidth]{./figures/ours-init/8.jpeg}}
   \subfigure[\scriptsize{Fast Direct}]{
        \includegraphics[width=1\textwidth]{./figures/ours-final/8.jpeg}
        }
    \caption{The 32 randomly generated images for the prompt "penguin" guided by Fast Direct by utilizing 50 batch query budget.}
    \label{fig:demo_32_8}
\end{figure}

\begin{figure}[h]
    \centering
    \subfigure[\scriptsize{Pre-trained}]{
        \includegraphics[width=1\textwidth]{./figures/ours-init/9.jpeg}}
   \subfigure[\scriptsize{Fast Direct}]{
        \includegraphics[width=1\textwidth]{./figures/ours-final/9.jpeg}
        }
    \caption{The 32 randomly generated images for the prompt "basket" guided by Fast Direct by utilizing 50 batch query budget.}
    \label{fig:demo_32_9}
\end{figure}

\begin{figure}[h]
    \centering
    \subfigure[\scriptsize{Pre-trained}]{
        \includegraphics[width=1\textwidth]{./figures/ours-init/10.jpeg}}
   \subfigure[\scriptsize{Fast Direct}]{
        \includegraphics[width=1\textwidth]{./figures/ours-final/10.jpeg}
        }
    \caption{The 32 randomly generated images for the prompt "ice-cube" guided by Fast Direct by utilizing 50 batch query budget.}
    \label{fig:demo_32_10}
\end{figure}

\begin{figure}[h]
    \centering
    \subfigure[\scriptsize{Pre-trained}]{
        \includegraphics[width=1\textwidth]{./figures/ours-init/11.jpeg}}
   \subfigure[\scriptsize{Fast Direct}]{
        \includegraphics[width=1\textwidth]{./figures/ours-final/11.jpeg}
        }
    \caption{The 32 randomly generated images for the prompt "cat-butterfly" guided by Fast Direct by utilizing 50 batch query budget.}
    \label{fig:demo_32_11}
\end{figure}


\end{document}
