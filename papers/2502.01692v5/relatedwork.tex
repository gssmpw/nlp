\section{Related Works}
%In this section, we briefly review two main approaches for target generation.
\subsection{Guided Generation}
Diffusion guided generation (also called inference-time guidance) refers to the technique to guide the sampling trajectory of the pre-trained diffusion to generate target data \citep{10081412,chen2024overview}. The key advantage of this approach is that it does not require updating the model parameters, which is computationally expensive, especially for large models.

\cite{dhariwal2021diffusion} proposed classifier guidance. However, it requires a guidance model trained on noisy images with different noise scales, which is generally not readily available and often requires training from scratch for each domain. \cite{chung2022diffusion,bansal2023universal,he2023manifold} extend the classifier guidance by using a differentiable objective function defined only for clean data. Instead of using noisy images, the predicted clean images at each sampling step are used as the input for the guidance objective function. In this way, the guidance process can operate on the clean image space. While the predicted clean image is naturally imperfect, empirically it still provides informative feedback to guide image generation \citep{bansal2023universal}.

However, this approximation can harm image quality. \cite{bansal2023universal} proposed universal guidance that comprises backward guidance followed by a self-recurrence step to preserve image quality. On the other hand, \cite{he2023manifold} leverages the differentiability of a well-trained auto-encoder to project the image to the data manifold and thus preserve image quality during the guidance process. Instead of guiding the sampling trajectory, \cite{karunratanakul2024optimizing,eyring2024reno} treat the diffusion process as a black-box and only optimize the initial (prior) noise.

While the aforementioned approaches assume a differentiable objective function, \cite{lu2023contrastive} tackles black-box objective $f$ by learning a differentiable proxy neural network $h$ to match their gradients, i.e., $\nabla f \approx \nabla h$. \cite{li2024derivative} eliminates the need for a differentiable proxy model by employing importance sampling weighted by the objective values during the sampling process. Most recently, DNO~\citep{tang2024tuning} proposes optimizing the diffusion noise sequence by using ZO-SGD~\citep{nesterov2017random} to tackle the black-box objective function. However, it runs at the instance level; namely, each run only produces one image.

%To the best of our knowledge, how to develop inference-time guidance methods for online guidance with black-box objective functions remains an open problem. Existing approaches are either offline or assume differentiable objective functions. 

\subsection{Diffusion-model Fine-tuning}
Diffusion-model fine-tuning refers to the technique that updating the pre-trained diffusion-model parameters to improve its performance on a specific use case. In this section, we review the fine-tuning methods that support online learning of the black-box objective function.

\cite{black2023training,fan2024reinforcement} formulate the diffusion fine-tuning problem as a reinforcement learning (RL) problem within Markov Decision Processes (MDPs), and propose an iterative algorithm to fine-tune the diffusion model by using Proximal Policy Optimization (PPO) \citep{schulman2017equivalence,uehara2024understanding} loss function. \cite{fan2024reinforcement} integrates the PPO with a KL regularization to prevent the fine-tuned model from deviating too much from the pre-trained model. 

On the other hand, \cite{yang2024using} does not require an absolute objective value; instead, it uses the relative reward on a pair of samples by integrating DPO (Direct Preference Optimization) \citep{rafailov2024direct}, a technique for fine-tuning large language models, into the diffusion model.

Fine-tuning the diffusion model requires a large amount of GPU memory. Existing work mitigates memory consumption by using the LoRA technique (Low-Rank Adaptation) \citep{hu2021lora} and only fine-tunes parameters of the attention blocks in UNet. We categorize the related works based on whether they support the online and black-box objective tasks in Appendix \ref{appendix_related_works} Table \ref{tab:related_works}.