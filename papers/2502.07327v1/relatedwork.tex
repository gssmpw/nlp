\section{Related Work}
\label{sec:6}
In this section, we summarize related work on bias in information retrieval and AI-generated content detection.
\subsection{Bias in Information Retrieval}
\label{sec:6.1}

Bias in information retrieval has attracted significant attention. \cite{mowshowitz2002assessing} first introduced the concept of bias, defining it, analyzing its sources, and proposing methods for evaluating bias, such as comparing search engine performance. Later studies focused on real-time methods for measuring bias in web search engines~\cite{mowshowitz2005measuring}. Research has since progressed in three main areas: analyzing bias sources in specific domains, exploring methods for assessing and mitigating bias, and investigating retrieval bias induced by AIGC-generated content.

% Research on assessing and mitigating bias has revealed a significant negative correlation between retrieval bias and performance~\cite{wilkie2014retrievability}. Subsequent studies addressed fairness across various systems and proposed mitigation strategies~\cite{yao2017new, yang2017measuring, geyik2019fairness}. Efforts to quantify bias in search engines, social networks, and recommendation services, along with fairness in collaborative filtering systems, were also explored~\cite{pitoura2018measuring}. Additional work focused on tackling fairness challenges in search and information retrieval systems~\cite{gao2021addressing, gao2021toward}.

Regarding methods for assessing and mitigating bias, research has explored the relationship between retrieval bias and performance, revealing a significant negative correlation~\cite{wilkie2014retrievability}. Later studies expanded on fairness in various systems and proposed mitigation strategies~\cite{yao2017new, yang2017measuring, geyik2019fairness}. Fairness in collaborative filtering recommendation systems and ranked outputs are examined, with efforts to quantify bias in search engines, social networks, and recommendation services~\cite{pitoura2018measuring}. Other studies concentrated on addressing fairness challenges in search and retrieval systems~\cite{gao2021addressing, gao2021toward}.

The rise of AIGC has introduced new challenges in retrieval bias. Research has explored the bias introduced by large language models (LLMs) in retrieval systems, revealing that neural retrieval models tend to prioritize AIGC-generated documents, a phenomenon known as source bias~\cite{dai2023llms}. Studies also show that objects in images generated by large vision-language models (LVLMs) exhibit more hallucination features compared to natural images~\cite{gao2024aigcs}. Additionally, it has been highlighted that synthetic images can introduce biases, with strategies proposed to mitigate these effects~\cite{xu2024invisible}. While prior research has not addressed source bias in video generation, this work validates its existence, identifies its origins in visual and temporal factors, and proposes solutions to mitigate the bias.

\subsection{AI-generated Content Detection}

% In recent years, researchers have extensively studied detecting AI-generated content. Existing methods for detecting AI-generated text can be broadly categorized into three approaches: Watermarking methods, which embed identifiable markers into AI-generated content to verify its origin~\cite{topkara2006hiding,ueoka2021frustratingly,gu2022watermarking,liu2023private,liu2024adaptive}; statistical methods, which use metrics like entropy to distinguish AI-generated text from human-written text~\cite{vasilatos2023howkgpt,mitchell2023detectgpt,su2023detectllm}; and supervised learning methods, which train deep classifiers to differentiate between AI-generated and human-written content.

Current methods for detecting AI-generated images are primarily classified into two categories: GAN-based detection methods, which focus on identifying artifacts unique to GAN-generated images~\cite{wang2020cnn,liu2020global}, and generalizable detection methods for diffusion models, which aim to identify a broader range of AI-generated images~\cite{ma2023exposing,luo2024lare,wu2023generalizable,epstein2023online,wang2023dire,corvi2023detection}. In contrast, the detection of AI-generated videos remains relatively underexplored. Existing methods include a motion discrepancy-based approach to distinguish AI-generated fake videos from real ones~\cite{fei2021exposing}, the use of a 3D convolutional network to analyze appearance, motion, and geometry for video differentiation~\cite{chang2024matters}, and H.264 re-compression to detect synthetic videos~\cite{Vahdati_2024_CVPR}. This work demonstrates that AI-generated videos contain additional visual and temporal information embedded by video generation models, which can be exploited to detect such videos. Furthermore, these studies indirectly support the existence of this additional information, as identified in our research.