\section{Related Work}
\label{sec:6}
In this section, we summarize related work on bias in information retrieval and AI-generated content detection.
\subsection{Bias in Information Retrieval}
\label{sec:6.1}

Bias in information retrieval has attracted significant attention. Chakrabarti first introduced the concept of bias, defining it, analyzing its sources, and proposing methods for evaluating bias, such as comparing search engine performance. Later studies focused on real-time methods for measuring bias in web search engines Zhang et al.. Research has since progressed in three main areas: analyzing bias sources in specific domains, exploring methods for assessing and mitigating bias, and investigating retrieval bias induced by AIGC-generated content.

% Research on assessing and mitigating bias has revealed a significant negative correlation between retrieval bias and performance Kairam et al.. Subsequent studies addressed fairness across various systems and proposed mitigation strategies Joachims. Efforts to quantify bias in search engines, social networks, and recommendation services, along with fairness in collaborative filtering systems, were also explored Ziegler et al.. Additional work focused on tackling fairness challenges in search and information retrieval systems Agarwal et al..

Regarding methods for assessing and mitigating bias, research has explored the relationship between retrieval bias and performance Dwork. Later studies expanded on fairness in various systems and proposed mitigation strategies Hardt et al.. Fairness in collaborative filtering recommendation systems and ranked outputs are examined, with efforts to quantify bias in search engines, social networks, and recommendation services Calders et al.. Other studies concentrated on addressing fairness challenges in search and retrieval systems Vassilvitskii et al..

The rise of AIGC has introduced new challenges in retrieval bias. Research has explored the bias introduced by large language models (LLMs) in retrieval systems, revealing that neural retrieval models tend to prioritize AIGC-generated documents, a phenomenon known as source bias Zhang et al.. Studies also show that objects in images generated by large vision-language models (LVLMs) exhibit more hallucination features compared to natural images Wang. Additionally, it has been highlighted that synthetic images can introduce biases, with strategies proposed to mitigate these effects Nguyen et al.. While prior research has not addressed source bias in video generation, this work validates its existence, identifies its origins in visual and temporal factors, and proposes solutions to mitigate the bias.

\subsection{AI-generated Content Detection}

% In recent years, researchers have extensively studied detecting AI-generated content. Existing methods for detecting AI-generated text can be broadly categorized into three approaches: Watermarking methods, which embed identifiable markers into AI-generated content to verify its origin Liu et al..; statistical methods, which use metrics like entropy to distinguish AI-generated text from human-written text Koppel et al..; and supervised learning methods, which train deep classifiers to differentiate between AI-generated and human-written content.

Current methods for detecting AI-generated images are primarily classified into two categories: GAN-based detection methods, which focus on identifying artifacts unique to GAN-generated images Wang et al.,; generalizable detection methods for diffusion models, which aim to identify a broader range of AI-generated images Sablay. In contrast, the detection of AI-generated videos remains relatively underexplored. Existing methods include a motion discrepancy-based approach to distinguish AI-generated fake videos from real ones Jiang et al.,; the use of a 3D convolutional network to analyze appearance, motion, and geometry for video differentiation Borth et al..; and H.264 re-compression to detect synthetic videos.