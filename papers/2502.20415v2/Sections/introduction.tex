\section{Introduction}
Computers and their performance improvement have historically relied on two pillars: Moore's law~\cite{schaller_moores_1997} and Dennard's scaling~\cite{bohr200730}. The former was formulated by Gordon Moore in the 1960s and states that the number of transistors per unit area double every 24 months, primarily due to improvements in lithography techniques. The latter was introduced by Richard Dennard, who found that as transistors grow smaller, the energy consumption reduces, resulting in constant power density. These two observations worked in tandem, allowing us to build more complex high-performing computers (Moore's law) without them consuming needlessly large amounts of energy (Dennard's scaling).
Unfortunately, Dennard's scaling ended in 2004-2005~\cite{dennard2018perspective}, and we are currently witnessing the slow-down of Moore's law~\cite{schaller_moores_1997} as well as the emergence of Dark Silicon~\cite{esmaeilzadeh2011dark} without any in-place replacement technology at hand~\cite{shalf2020future}. Instead, researchers and industry are looking for alternative ways of computing in hope of continuing the trend in computer performance we have seen so far. These technologies are collectively called \textit{post-Moore technologies}~\cite{leiserson2020there,shalf2020future} and include quantum computers~\cite{gyongyosi2019survey}, adiabatic reversible logic~\cite{bommi2018survey}, and analog computing~\cite{maclennan2007review}. Two post-Moore technologies, however, are perhaps the most salient alternatives: Neuromorphic--~\cite{schuman2017survey} and Reconfigurable--computing~\cite{podobas2020survey,kuon_fpga_2008}.

Introduced in the 1980s by Carver Mead, neuromorphic systems~\cite{mead1990neuromorphic} are computers built to replicate -- to various extent -- the impressive computing capabilities of the biological brain. Initially designed to replicate brain circuitry using analog electronic components, neuromorphic systems today are implemented in different technologies, ranging from digitally synchronous (e.g., Intel Loihi~\cite{davies2018loihi} or IBM TrueNorth~\cite{akopyan2015truenorth}), mixed analog/digital (e.g., BrainDrop~\cite{neckar2018braindrop}), fully analog (e.g. \cite{indiveri2011neuromorphic}), to even memristor- or photonics-based systems~\cite{li2018review,shastri2021photonics}. Regardless of how they are implemented, they share two fundamental traits: \textbf{(i) }they communicate through discrete events called spikes and \textbf{(ii)} they are programmed in a non-imperative way, generally by encoding the problem to be solved through a spiking neural network (SNN)~\cite{maass1997networks}. Solving a problem using a neuromorphic system, often results in a significantly more energy-efficient solution in several application domains~\cite{davies_advancing_2021} as opposed to a traditional von Neumann system~\cite{nikhil1989can}. A large number of functionalities of neuromorphic systems are driven by discoveries and innovation in neuroscience (e.g.,  Spike-Timing Dependent Plasticity (STDP)~\cite{song2000competitive}, Bayesian Confidence Propagation Neural Network (BCPNN)~\cite{ravichandran2024unsupervised}, or Eligibility Propagation (E-prop)~\cite{bellec_solution_2020}), which has motivated many researchers to abandon non-reconfigurable and expensive application-specific integrated circuits (ASICs) and leverage the reconfigurable Field-Programmable Gate Arrays (FPGAs) to keep up with the fast pace of neuroscientific research. FPGAs~\cite{gandhare2019survey} are a group of reconfigurable devices allowing for implementing a variety of digital circuits without the need for fabricating a bespoke ASIC. Initially designed to prototype ASICs prior to tape-out, nowadays the FPGAs are used in a plethora of different fields from low-volume electronics~\cite{andina2017fpgas}, through space exploration~\cite{jacobs2012reconfigurable}, to large data centers~\cite{weerasinghe2015enabling}. A hardware designer can program an FPGA to act as a central processing unit (CPU)~\cite{calderon2005soft}, a Graphics Processing Unit (GPU)~\cite{andryc2013flexgrip}, or a neuromorphic device. FPGAs have shown a lot of promise in accelerating neuromorphic workloads, resulting in significant performance gains over CPU- and GPU-based solutions~\cite{podobas2017designing,ju_fpga_2020}, with examples of even outperforming ASIC-based neuromorphic systems (e.g., for brain simulation~\cite{lindqvist2024fast}).

This paper presents the outcome of a systematic review of neuromorphic hardware architectures integrated using FPGAs. We included majority of the literature on the subject starting from 1998, discarded unrelated works based on their abstract and/or topic, read a total of 129 papers in detail, which we then summarized and classified according to the extended taxonomy we propose. Furthermore, we identified and collected performance metrics across the surveyed literature and condensed this information in the form of trends and observations on the direction of development of the field. Finally, we conclude the survey with a discussion on future opportunities.

\input{Sections/introduction/introduction_motivation}

\input{Sections/introduction/introduction_method}