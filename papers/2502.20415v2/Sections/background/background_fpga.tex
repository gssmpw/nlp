\subsection{Field-Programmable Gate Arrays}
\begin{wrapfigure}[16]{h}{0.5\textwidth}
  \centering
    \vspace{-10pt}
    \includegraphics[width=0.8\linewidth]{Figs/fpga_arch.png}
    \caption{Abstract view of an FPGA, showing reconfigurable logic (blue), DSP-blocks (green), BRAM (red), and hardened memory controller and processor blocks. Illustration based on~\cite{kuon_fpga_2008}.}
    \label{fig:fpga_arch}
  \Description{Diagrams representing the Taxonomy classes' main features.}
\end{wrapfigure}
Field-Programmable Gate Arrays (FPGAs)\cite{kuon_fpga_2008} belong to a family of reconfigurable architectures, whose underlying silicon can be reprogrammed to yield different functionality. Historically used to prototype ASICs before tape-out, nowadays the FPGAs are used in various different fields from low-volume electronics, through embedded systems and telecommunications to high-performance computing (HPC)\cite{podobas2017evaluating, zohouri2016evaluating}. Performance of the FPGA-based systems can generally be better than that of the systems based on CPUs or GPUs but worse than that of custom ASICs. Another strength of using FPGAs is that they can be iteratively tailored to the needs of the application without the cost of developing a new ASIC every time. To put this matter into perspective, an FPGA capable of executing tens of billions of floating-point operations per second (tens of TFLOPs) can reach the price of thousands of dollars, while creating a similarly capable ASIC is between two and three orders of magnitude more expensive.
Fundamentally, every FPGA consists of a number of \textit{logic blocks} (also called \textit{configurable logic blocks} or \textit{logic elements}), a system of programmable interconnects (called \textit{fabric}) that routes signals between the logic blocks and input/output (I/O) blocks for communication with external devices. Logic blocks are usually made up of a look-up table (LUT) that stores predefined list of logic outputs for any combination of logic input vectors and standard logic circuitry, such as multiplexers, full adders and flip-flops. The content of these LUTs can be programmed, and by connecting several LUTs together, we can achieve any digital functionality. Originally, FPGAs comprised only the aforementioned logic blocks and fabric, but it was soon realized that certain digital circuits (e.g., multipliers) consumed much of the FPGA's logic resources. Thus, dedicated (called hardened) functionality was added to the subsequent iterations of the FPGA chips, e.g., bespoke on-chip memory called block random access memory (BRAM), digital signal processing (DSP) blocks (which, in some FPGAs, include floating-point units) and many others (phased locked loops, PCIe controllers, etc.). Figure~\ref{fig:fpga_arch} shows a view of an FPGA.

There are multiple ways to program FPGAs. The most well-known way that also gives the best results -- but also the one with the steepest learning curve -- is to design logic at the register transfer level (RTL) using hardware description languages (HDLs) such as VHDL or Verilog. Another approach, which has become increasingly popular lately, is to write the intended functionality using programming languages such as C or C++ and let the compilers automatically transform the code into hardware. This is called High-Level Synthesis (HLS)\cite{nane2015survey} and allows engineers and researchers without background in electrical engineering or computer science to work with FPGAs.


% Field-Programmable Gate Arrays (FPGAs)\cite{kuon_fpga_2008} belong to a family of reconfigurable architectures, whose underlying silicon can be reprogrammed to yield different functionality. Historically used to prototype ASICs before tape-out, nowadays the FPGAs are used in various different fields from low-volume electronics, through embedded systems and telecommunications to high-performance computing (HPC)\cite{podobas2017evaluating, zohouri2016evaluating}. Performance of the FPGA-based systems is generally better than that of the systems based on CPUs or GPUs but worse than that of custom ASICs. Another strength of using FPGAs is that they can be iteratively tailored to the needs of the application without the cost of developing a new ASIC every time. To put this matter into perspective, an FPGA capable of executing tens of billions of floating-point operations per second (tens of TFLOPs) can reach the price of thousands of dollars, while creating a similarly capable ASIC is between two and three orders of magnitude more expensive.

% Fundamentally, an FPGA comprises many small static random access memory (SRAM) cells that act as look-up tables (LUTs). The content of these LUTs can be programmed, and by connecting several LUTs, we can achieve nearly any digital functionality. Originally, FPGAs had only LUTs and a reprogrammable interconnect. However, it was soon realized that some digital circuits (e.g., multipliers) consumed much of the FPGA's logic. Thus, more dedicated (called hardened) functionality was added to the subsequent iterations of the FPGA chips, e.g., bespoke on-chip memory called block RAM (BRAM), digital signal processing (DSP) blocks (which, in some FPGAs, include floating-point operations) and many others (phased locked loops, PCIe controllers, etc.). Figure~\ref{fig:fpga_arch} shows an abstract view of an FPGA.

% There are multiple ways to program FPGAs. The most well-known and performance way -- but also the one with the steepest learning curve -- is to design logic at the register transfer level (RTL) using languages such as VHDL or Verilog. Another approach, which has become increasingly popular lately, is to write the intended functionality using high-level programming languages such as C or C++ and let compilers automatically transform the code into hardware. This is called High-Level Synthesis\cite{nane2015survey} and allows engineers and researchers without background in electrical engineering or computer science to work with FPGAs.