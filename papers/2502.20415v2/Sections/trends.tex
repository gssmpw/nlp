\section{Trends, Tendencies, and Discussion}
\label{sec:trends}
% Mixing the results with the thoughts. Should save up space.
% General numbers
% \begin{wrapfigure}[14]{h}{0.5\textwidth}
%   \centering
%     \vspace{-20pt}
%     \includegraphics[width=\linewidth]{Figs/graphpad_synapses_vs_neurons.pdf}
%     \caption{Neurons and synapses of the surveyed architectures.}
%     \label{fig:graphpad_synapses_vs_neurons}
% \end{wrapfigure}
\begin{figure}[h]
  \centering
    \begin{subfigure}{.4\textwidth}
    \centering
    \includegraphics[width=\linewidth]{Figs/graphpad_imps_per_year.pdf}
    \caption{Class population structure through years.}
    \label{fig:trends_large_imps}
    \end{subfigure}%
    \begin{subfigure}{.4\textwidth}
    \centering
    \includegraphics[width=\linewidth]{Figs/graphpad_models_per_year.pdf}
    \caption{Share of different neuron models through years.}
    \label{fig:trends_large_models}
    \end{subfigure}
    \medskip
    \begin{subfigure}{.4\textwidth}
    \centering
    \includegraphics[width=\linewidth]{Figs/graphpad_synapses_vs_neurons.pdf}
    \caption{Complexity of the implemented architectures.}
    \label{fig:trends_large_synapses}
    \end{subfigure}%
    \begin{subfigure}{.4\textwidth}
    \centering
    \includegraphics[width=0.9\linewidth]{Figs/graphpad_use_case.pdf}
    \caption{Share of use cases for the surveyed architectures.}
    \label{fig:trends_use_case}
    \end{subfigure}
    % \begin{subfigure}{.45\textwidth}
    % \centering
    % \includegraphics[width=\linewidth]{Figs/graphpad_prediction_logic.pdf}
    % \caption{Predicted LC number required to implement $10^{11}$ of neurons on an FPGA by Class.}
    % \label{fig:graphpad_use_case}
    % \end{subfigure}
    \caption{Diagrams with various properties of the classified NMAs.}
    \label{fig:trends_large}
  \Description{Diagrams with the observed trends.}
\end{figure}
We surveyed 129 papers describing NMAs that provided enough information for us to apply the Taxonomy rules and derive further metrics. Additional 27 papers consisted of non-NMA structures and NMA-related research, as described in Section \ref{sec:overview_non_nma}. Around 86.78\% of architecture featured a parallel architecture, with 30.58\% being fully parallel. Some form of online learning was featured in 31.4\% of implementations, which is a rather small number - most likely due to the lack of agreement on how to realize brain-like learning in hardware efficiently.
% Taxonomy related
As Figure \ref{fig:trends_large_imps} suggests, the NMAs on FPGAs have been gaining popularity throughout the years, with the most implementations presented around the year 2021. We can see that the three most populous classes are Class 2 (38), Class 4 (22) and Class 6 (17). This is unsurprising as the collocated memory and computation is the easiest Trait to include, and thus we can see them appearing often. Class 7 consists of only 10 examples, but they can also be seen throughout the years, showing interest in implementing \textit{fully neuromorphic} systems.
% SNN-related
% \begin{wrapfigure}[12]{h}{0.5\textwidth}
%   \centering
%     \vspace{-10pt}
%     \includegraphics[width=\linewidth]{Figs/graphpad_use_case.pdf}
%     \caption{Share of different use cases for the surveyed architectures.}
%     \label{fig:graphpad_use_case}
% \end{wrapfigure}
Close to 53.5\% of the NMAs realized up to and including 1000 neurons. This can be due to the classification tasks being the most popular use case -- 40\% of NMAs according to the Figure \ref{fig:trends_use_case} -- and those do not require large networks. The target benchmarks should be thus reconsidered and new ones should be introduced to test more complex NMAs. Moreover, 28\% of architectures target neuroscience, reinforcing the close connection between biological and spiking neural networks. 
% \begin{wrapfigure}[14]{h}{0.5\textwidth}
%   \centering
%     \vspace{-10pt}
%     \includegraphics[width=\linewidth]{Figs/graphpad_sntr_year.pdf}
%     \caption{Ratio of Synapses to Neurons in surveyed architectures.}
%     \label{fig:graphpad_sntr_year}
% \end{wrapfigure}
The most popular neuron model is LIF (47.29\%), followed by IZH (18.6\%), IF (14.7\%) and HH (9.3\%) - the rest of the models were utilized in around 10\% of the architectures. As LIF neurons are the simplest to implement, IZH give similar spiking behaviors with reduced complexity to the complete and HH neurons are popular for neuroscientific experiments - those results are not surprising.
\begin{wrapfigure}[14]{r}{0.5\textwidth}
  \centering
    \vspace{-25pt}
    \includegraphics[width=\linewidth]{Figs/graphpad_prediction_logic.pdf}
    \caption{Predicted LB number required to implement $10^{11}$ of neurons on an FPGA by Class. }
    \label{fig:prediction_logic}
\end{wrapfigure}
The hardware constraints were a crucial factor when selecting the appropriate neuron model and not many researchers decided to implement the complex HH model. The most popular topology is FF-FC (33.3\%), then SCNN (12.4\%), A2A (10.9\%), biology-related "fixed" topologies (8.5\%), WTA (7\%) and LSMs (2.3\%) - other topologies were usually special cases with a single representative. Once again, the influence of the use case in topology choice is rather apparent.
% Platform-related
Interestingly, a majority of NMAs (86\%) were implemented on Xilinx/AMD devices, which may suggest that FPGA-based NMAs development is dependent on a single manufacturer when it comes for creating larger and faster implementations. Moreover, nearly 77\% of the architectures utilized at most 50\% of the available resources, regardless of the platform size and manufacturer, and there were only five examples of systems clocked at above 200 MHz, which suggests that even today the FPGAs are not utilized to their full potential in the field of NMA development.
Figure \ref{fig:prediction_logic} shows the trend of available logic resources on FPGAs, based on the size of the AMD/Xilinx Virtex FPGA device family\footnote{The newest devices from AMD - Versal - are discarded as they are not \textit{pure} FPGAs, but rather System-On-a-Chip devices with relatively small FPGA fabric (as a percentage of the entire chip).} (black dots) through the years and required logic resources for implementing $10^{11}$ neurons -- the estimated size of the human brain -- on a single chip for the most promising architectures from every Class. We can see that, if we discard the impact of embedded memory size and improvements in on-chip communication and assume this trend to hold, Classes 0 and 3 can be expected to achieve human-brain scale around the year 2035 as they require the least amount of on-chip logic resources and scale the best in single-chip implementations. The rest need more time -- Classes 1, 2, 4, 6 and 7 would achieve the goal after 2055 and Class 5 (prediction is rather vague here, because it is based on a system that used multiple FPGAs -- BiCoSS) would achieve it after 2045. They would benefit more from adding more chips, as it is already being done\cite{kudithipudi2025neuromorphic}. However, considering that IEEE suggests in their International Roadmap for Devices and Systems (IRDS) from 2022 that Moore's Law will be upheld for additional 10-15 years\cite{https://doi.org/10.60627/c13z-v363}, only Classes 0 and 3 seem likely to achieve the aforementioned goal in the predicted years.
% \begin{wrapfigure}[13]{h}{0.5\textwidth}
%   \centering
%     \vspace{-20pt}
%     \includegraphics[width=\linewidth]{Figs/graphpad_models_per_year.pdf}
%     \caption{Share of different neuron models through years.}
%     \label{fig:graphpad_models_per_year}
% \end{wrapfigure}
% \begin{wrapfigure}[14]{h}{0.5\textwidth}
%   \centering
%     \vspace{-20pt}
%     \includegraphics[width=\linewidth]{Figs/graphpad_imps_per_year.pdf}
%     \caption{Class population structure through years.}
%     \label{fig:graphpad_imps_per_year}
% \end{wrapfigure}