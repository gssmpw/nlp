\section{Details in Literature Analysis of Prompting Behavior in Frontier LLMs}
\label{appendix:details_in_meta_analysis}

\subsection{Which Categories  Benefit from CoT?}

To replicate the Chain-of-Thought (CoT) improvements over standard direct prompting, as demonstrated by \citet{sprague2024cot}, we adopt their category schemas, which include entailment, text classification, generation, knowledge, contextQA, multihopQA, commonsense reasoning, logical reasoning, spatial reasoning, and math. 
While these categories provide a fine-grained definition of traditional NLP tasks, they lack generalizability in encompassing the broader capabilities of modern LLMs, such as multimodality, safety, and tool use. 
The complete version of Fig.~\ref{fig:cot_improvement_verification} is presented below in Fig.~\ref{fig:cot_improvement_verification_full}.


Extracting records for this type of analysis is challenging due to the strict criteria for sample selection. 
While \citet{sprague2024cot}'s dataset contains a larger overall sample size, as it is not limited to a single model and \datasetname~is not specifically oriented to replicating their study. 
For the overlapping model (GPT-4), their dataset includes 168 instances, whereas ours contains 553. This demonstrates the scalability of our pipeline.

\begin{figure}[t!]
    \centering  
    \includegraphics[width=1.0\columnwidth]{figures/figure_literature_analysis_cot_sprague_replica}
    \caption{Full version of box plots showing performance improvements with CoT compared to standard prompting, categorized according to \citet{sprague2024cot} for a fine-grained investigation in various reasoning tasks.}
    \label{fig:cot_improvement_verification_full}
\end{figure}


% \begin{table*}[ht]
% \centering
% \small
% \renewcommand{\arraystretch}{1.3}
% \begin{tabular}{l|c|cc}
% \toprule
% \multirow{2}{*}{\textbf{Category}} & \multirow{2}{*}{\textbf{Mean $\Delta$}} & \multicolumn{2}{c}{\textbf{One-Sided Bootstrap}} \\
% & & p-value & Significant \\
% \midrule
% Math & 14.61 & 0.0000 & Yes \\
% Symbolic and algorithmic & 8.85 & 0.0002 & Yes \\
% Spatial and temporal reasoning & 3.03 & 0.0166 & No \\
% Logical reasoning & 2.39 & 0.0084 & No \\
% Commonsense reasoning & 5.41 & 0.0450 & No  \\
% Multi-hop QA & 2.05 & 0.0000 & Yes \\
% Context-aware QA & 2.45 & 0.0014 & Yes \\
% Encyclopedic knowledge & 2.18 & 0.0076 & No \\
% Generation & 4.24 & 0.0280 & No \\
% Text classification & 1.01 & 0.4464 & No \\
% Entailment & 0.81 & 0.2070 & No  \\
% \bottomrule
% \end{tabular}
% \caption{Statistical test results across different categories for replicating the study from \citet{sprague2024cot}. Mean $\Delta$ represents the average of improvement when using CoT over standard prompting, and significance is determined at $p=0.00227$ applying a Bonferroni correction.}
% \label{tab:statistical-tests}
% \vspace{-.3cm}
% \end{table*}


% \begin{table*}[ht]  
% \centering  
% \small  
% \renewcommand{\arraystretch}{1.3}  
% \begin{tabular}{l|c|cc|c|cc}  
% \toprule  
% \multirow{2}{*}{\textbf{Category}} & \multicolumn{3}{c|}{\textbf{Original Results}} & \multicolumn{3}{c}{\textbf{Filtered Results}} \\  
% & Mean $\Delta$ & p-value & Significant & Mean $\Delta$ & p-value & Significant \\  
% \midrule  
% Math & 14.61 & 0.0000 & Yes & 13.53 & 0.0000 & Yes \\  
% Symbolic and algorithmic & 8.85 & 0.0002 & Yes & 9.13 & 0.0000 & Yes \\  
% Spatial and temporal reasoning & 3.03 & 0.0166 & No & 2.07 & 0.0056 & No \\  
% Logical reasoning & 2.39 & 0.0084 & No & 1.18 & 0.3776 & No \\  
% Commonsense reasoning & 5.41 & 0.0450 & No & 5.61 & 0.0748 & No \\  
% Multi-hop QA & 2.05 & 0.0000 & Yes & 1.21 & 0.0064 & No \\  
% Context-aware QA & 2.45 & 0.0014 & Yes & 0.28 & 0.7060 & No \\  
% Encyclopedic knowledge & 2.18 & 0.0076 & No & 3.31 & 0.0138 & No \\  
% Generation & 4.24 & 0.0280 & No & 1.92 & 0.3920 & No \\  
% Text classification & 1.01 & 0.4464 & No & 0.27 & 0.8644 & No \\  
% Entailment & 0.81 & 0.2070 & No & 0.93 & 0.1666 & No \\  
% \bottomrule  
% \end{tabular}  
% \caption{Statistical test results across different categories for replicating the study from \citet{sprague2024cot}. \textbf{Original Results} refers to the results from Table 7 from the submission (without filtering any papers). \textbf{Filtered Results} refer to the results from the filtered papers that are published in top conferences. Mean $\Delta$ represents the average of improvement when using CoT over standard prompting, and significance is determined at $p=0.00227$ after applying a Bonferroni correction.}  
% \vspace{-.3cm}  
% \end{table*}  


\begin{table*}[t]  
\centering  
\resizebox{0.63\textwidth}{!}{  
  \begin{tabular}{l|ccc|ccc}  
  \toprule  
  \textbf{CoT Reasoning} & \multicolumn{3}{c|}{\textbf{Original Results}} & \multicolumn{3}{c}{\textbf{Filtered Results}} \\  
  & \textbf{Median} & \textbf{Q1} & \textbf{Q3} & \textbf{Median} & \textbf{Q1} & \textbf{Q3} \\  
  \toprule  
  $\Delta$ (Few-shot, Zero-shot) & 3.0 & 0.4 & 9.2 & 5.0 & 2.3 & 10.4 \\  
  $\Delta$ (More-shot, Less-shot) & 3.1 & 0.4 & 9.0 & 5.0 & 2.3 & 10.7 \\  
  \bottomrule  
  \end{tabular}  
}  
\caption{Statistical distribution of performance improvements when using varying levels of demonstrations in CoT prompting. \textbf{Original Results} refers to the results from Table 5 from the submission (without filtering any papers). \textbf{Filtered Results} refer to the results from the filtered papers that are published in top conferences. $\Delta$(A, B) refers to the performance improvement of A over B, Q1 and Q3 represent the first and third quartiles, respectively.}  
\label{tab:cot-vs-zero-shot-cot-subset}
\end{table*}  

\begin{table*}[t]  
\centering  
\resizebox{0.65\textwidth}{!}{  
  \begin{tabular}{l|ccc|ccc}  
  \toprule  
  \textbf{$\Delta$ (CoT, Direct Prompting)} & \multicolumn{3}{c|}{\textbf{Original Results}} & \multicolumn{3}{c}{\textbf{Filtered Results}} \\  
  & \textbf{Median} & \textbf{Q1} & \textbf{Q3} & \textbf{Median} & \textbf{Q1} & \textbf{Q3} \\  
  \toprule  
  Few-shot & 0.9 & -1.2 & 3.7 & 1.3 & 0.0 & 3.0 \\  
  Zero-shot & 1.3 & -0.4 & 4.7 & 1.3 & 0.0 & 3.6 \\  
  \bottomrule  
  \end{tabular}  
}  
\caption{Statistical distribution of performance improvements for CoT compared to direct prompting given different levels of demonstrations. \textbf{Original Results} refers to the results from Table 6 from the submission (without filtering any papers). \textbf{Filtered Results} refer to the results from the filtered papers that are published in top conferences. }  
\label{tab:cot-vs-standard-subset}  
\end{table*}  


\begin{figure}[t!]
    \centering
    \includegraphics[width=0.9\columnwidth]{figures/figure_literature_analysis_more_shot_vs_less_shot.pdf}
    \caption{Box plot distributions showcasing performance enhancements using more in-context examples compared to less in-context examples setup, categorized by skill sets in \cref{subsection:core_skills}. 
     Grey dots represent individual deltas, while sky pink dots show the mean delta aggregated for each paper. A pink star indicates the mean delta for each category.}
    \label{fig:icl_improvement_more_vs_less}
\end{figure}

\subsection{Which Categories Benefit from ICL?}

We visualize the distribution of in-context examples, comparing cases with more versus fewer demonstrations, in Fig.~\ref{fig:icl_improvement_more_vs_less}. 
The results show that the overall median and distribution are similar to those in Fig.~\ref{fig:icl_improvement}, suggesting that the presence of demonstrations is more crucial than their quantity.

\subsection{How Do Trends in Peer-Reviewed Papers Compare to Those in arXiv Publications?}

We reanalyzed the joint behavior findings from \cref{subsection:joint_behavior} using only peer-reviewed papers published in journals or conferences.
Table~\ref{tab:cot-vs-zero-shot-cot-subset} and Table~\ref{tab:cot-vs-standard-subset} present these results.
The filtered data confirms our original finding regarding the interaction between CoT and ICL: CoT with demonstrations (ICL) consistently outperforms CoT without demonstrations. Additionally, CoT's improvement over standard prompting remains consistent regardless of demonstration count (zero-shot or few-shot).