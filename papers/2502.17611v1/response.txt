\section{Related Work}
\label{sec:related}

% papers that propose methods to reduce hallucinations in LLMs
% Two parts: social bias evaluation, RAG. But the intersection is null.
% Cite the only other RAG-bias paper (in related work) and tell it is contemporary and how it differs from ours, or highlight similar findings 

\paragraph{Social Biases in LLMs:}
\acp{LLM} are typically trained on extensive text collections sourced from the internet, which often contains various types of social biases that are then mirrored in the models' behaviour **Bolukbasi et al., "Man is to Computer Programmer as Woman is to Homemaker"**. 
These biases can be assessed through two primary methods: intrinsic and extrinsic **Deepti Ghosh et al., "Understanding Social Biases in NLI Systems"**, **Nicolai Diederich, "A Survey on Methods for Handling Linguistic Bias in NLP Systems"** evaluation.
Intrinsic measures focus on biases within word embeddings or model predictions **Bolukbasi et al., "Man is to Computer Programmer as Woman is to Homemaker"**, while extrinsic measures analyse biases in outputs from downstream tasks such as \ac{NLI} or question answering **Sap et al., "Social Biases in Language Models Out of the Box"**.
%\ac{RAG} can be seen as a downstream application of \acp{LLM}, and we use \ac{BBQ}, a QA-based extrinsic evaluation benchmark in this paper.

\paragraph{RAG and Social Biases:}
Although social biases of \acp{LLM} have been studied extensively for various downstream applications, the effect of \ac{RAG} on \ac{NLG} has been less frequently explored.
**Bolukbasi et al., "Man is to Computer Programmer as Woman is to Homemaker"** proposed a three-level threat model and studied the sensitivity of \ac{RAG} to the external datasets used for the retrieval.
They found  that the fairness of a \ac{RAG} system can get easily compromised due to the social biases in the datasets used.
Unlike their approach which uses a limited set of contexts from the \ac{BBQ} dataset, our work incorporates a broader range of documents from diverse datasets, enhancing the generalisability of our findings.

**Sheng et al., "Mitigating Social Bias in Retrieval Augmented Generation"** explored fairness within \ac{RAG} systems by examining disparities in retrieval performance between protected and non-protected groups, using data from FairRanking Track **FairRanking, "Protected Attributes for Evaluation"** that focuses on protected attributes like binary gender (i.e. female vs. males) and geographic origin (i.e. non-Europeans vs. Europeans).
%Specifically, ____ created subsets for evaluating fairness in binary gender (i.e. females as the protected group and males the non-protected group) and location (i.e. non-Europeans as the protected group and Europeans as the non-protected group).
%They also considered socio-economic status (i.e. poor as the protected group and rich as the non-protected group) using the \ac{BBQ} dataset.
This study primarily addressed fairness, defined as equitable retrieval performance, whereas our study extends the evaluation to social biases in multilingual contexts, providing a deeper understanding of bias dynamics in \ac{RAG} beyond just fairness.

%Note that the focus of ____ is on fairness, which is defined as the difference of information retrieval performance between the protected vs. non-protected groups.
%In contrast, we evaluate social biases in \ac{RAG}, while the accuracy of the retrieval system is a secondary criteria guaranteeing the reliability of the evaluation.
%Moreover, ____ and ____ both evaluated social biases only for English, whereas we conduct a multilingual evaluation.

\begin{figure*}[t!]
    \centering
    \includegraphics[height=50mm]{figures/outline.png}
    \caption{Overview of our RAG social bias evaluation protocol. 
    Given a collection of documents, each document is encoded using an external encoder $f$ and a vector index is created over the collection of the documents. We use a question, paired with its ambiguous or disambiguated context, selected from the BBQ dataset as the \emph{query} for the retrieval system. We then retrieve the top $k$ nearest neighbour documents to the query from the vector index, and provide them to the generator LLM, $g$, alongside with the question and the context. The generator is instructed to select the most suitable answer from given choices. }
    \label{fig:RAG}
\end{figure*}