\section{Related Work}
\label{sec:related}

% papers that propose methods to reduce hallucinations in LLMs
% Two parts: social bias evaluation, RAG. But the intersection is null.
% Cite the only other RAG-bias paper (in related work) and tell it is contemporary and how it differs from ours, or highlight similar findings 

\paragraph{Social Biases in LLMs:}
\acp{LLM} are typically trained on extensive text collections sourced from the internet, which often contains various types of social biases that are then mirrored in the models' behaviour~\cite{Penedo:2024}. 
These biases can be assessed through two primary methods: intrinsic and extrinsic~\cite{goldfarb-tarrant-etal-2021-intrinsic,cao-etal-2022-intrinsic} evaluation.
Intrinsic measures focus on biases within word embeddings or model predictions~\cite{caliskan-et-al-weat,nangia-etal-2020-crows,nadeem-etal-2021-stereoset,kaneko-etal-2022-debiasing}, while extrinsic measures analyse biases in outputs from downstream tasks such as \ac{NLI} or question answering~\cite{webster-2020-sts,De-Arteaga-biasbios}.
%\ac{RAG} can be seen as a downstream application of \acp{LLM}, and we use \ac{BBQ}, a QA-based extrinsic evaluation benchmark in this paper.

\paragraph{RAG and Social Biases:}
Although social biases of \acp{LLM} have been studied extensively for various downstream applications, the effect of \ac{RAG} on \ac{NLG} has been less frequently explored.
\citet{Hu:2021} proposed a three-level threat model and studied the sensitivity of \ac{RAG} to the external datasets used for the retrieval.
They found  that the fairness of a \ac{RAG} system can get easily compromised due to the social biases in the datasets used.
Unlike their approach which uses a limited set of contexts from the \ac{BBQ} dataset, our work incorporates a broader range of documents from diverse datasets, enhancing the generalisability of our findings.

\citet{wu-etal-2025-rag} explored fairness within \ac{RAG} systems by examining disparities in retrieval performance between protected and non-protected groups, using data from FairRanking Track~\citep{Ekstrand:2023} that focuses on protected attributes like binary gender (i.e. female vs. males) and geographic origin (i.e. non-Europeans vs. Europeans).
%Specifically, \citet{wu-etal-2025-rag} created subsets for evaluating fairness in binary gender (i.e. females as the protected group and males the non-protected group) and location (i.e. non-Europeans as the protected group and Europeans as the non-protected group).
%They also considered socio-economic status (i.e. poor as the protected group and rich as the non-protected group) using the \ac{BBQ} dataset.
This study primarily addressed fairness, defined as equitable retrieval performance, whereas our study extends the evaluation to social biases in multilingual contexts, providing a deeper understanding of bias dynamics in \ac{RAG} beyond just fairness.

%Note that the focus of \citet{wu-etal-2025-rag} is on fairness, which is defined as the difference of information retrieval performance between the protected vs. non-protected groups.
%In contrast, we evaluate social biases in \ac{RAG}, while the accuracy of the retrieval system is a secondary criteria guaranteeing the reliability of the evaluation.
%Moreover, \citet{wu-etal-2025-rag} and \citet{Hu:2021} both evaluated social biases only for English, whereas we conduct a multilingual evaluation.

\begin{figure*}[t!]
    \centering
    \includegraphics[height=50mm]{figures/outline.png}
    \caption{Overview of our RAG social bias evaluation protocol. 
    Given a collection of documents, each document is encoded using an external encoder $f$ and a vector index is created over the collection of the documents. We use a question, paired with its ambiguous or disambiguated context, selected from the BBQ dataset as the \emph{query} for the retrieval system. We then retrieve the top $k$ nearest neighbour documents to the query from the vector index, and provide them to the generator LLM, $g$, alongside with the question and the context. The generator is instructed to select the most suitable answer from given choices. }
    \label{fig:RAG}
\end{figure*}