Before formally presenting our work and the main results, we start with an informal, example-driven prologue. This will help illustrate the intuitive ideas behind the key constructs we are about to introduce.

\paragraph{History Expressions}
Usually, a function, whether local or remote, has a signature of the following form:
\begin{equation}
    f: \tau_1 \longrightarrow \tau_2
\end{equation}
Where $\tau_1$ represents the type of the formal parameters of $f$, while $\tau_2$ is the return type. When we refer to \emph{local} functions, we naturally have access to the function’s body, allowing us to directly infer its type. However, if $f$ is a \emph{remote} service, the body is immaterial and the type cannot be inferred by us. Instead, it is provided by the (API's) provider, and we assume that the information about the function’s type given by the provider is reliable and trusted.

Our goal here is to incorporate additional information about a function (or, more generally, an expression) that are related to how the resources within it are used.
The added information will be statically encoded as a History Expression denoted by $H$. 
The type associated with a function, as shown below,
\begin{equation}
    f: \tau_1 \overset{H}{\longrightarrow} \tau_2
\end{equation}
includes $H$, which is referred to as the latent effect of the function. In other words, we are working within a type and effect system \cite{types-effects-general,static3-types-effects}.

History Expressions were originally introduced in \cite{history} to handle the secure orchestration of properties of functional services and to manage secure resource usage. Our formulation of History Expressions differs from the original version presented in \cite{history}, as we incorporate the use of type qualifiers within them. Type qualifiers are first-order logic formulas that provide an abstract description of the values associated with a type. The concept of type qualifiers in History Expressions is derived from the notion of Refinement Types \cite{refinement}, which typically allow a type qualifier to be paired with a basic type (such as $int$, $bool$, $int\;list$, etc.) to convey additional information about the type's values. Coverage Types \cite{coverage} offer a specific instance of Refinement Types. Note that the introduction of type qualifiers enables more compact representations of histories. Furthermore, because History Expressions capture the effects of a function's behaviour on its resources, it is essential to link these effects on resources with the values returned by the function (the return type).

We have already pointed out that History Expressions provide an over-approximation of the actual behaviour of a function with respect to resources. Therefore, the introduction of type qualifiers allows for a more refined, lower over-approximation, enabling a more precise "skimming" or selection of specific values within a type to be considered.

\paragraph{Coverage Types} 
Coverage Types \cite{coverage} are built on the foundation of Refinement Types \cite{refinement}, which enable the creation of custom types by associating qualifiers with base types. These qualifiers provide an over-approximation of the values that an expression, linked to the type, may return.
Coverage Types were introduced to address the challenges of Property-Based Testing (PBT), where suitable auxiliary functions, known as input test generators, are used to generate input cases that satisfy specific properties (usually constraints on the program's inputs). 

The output of these generators is then fed as input into the program undergoing PBT. In a testing scenario, it is desirable to cover as many input cases as possible, including edge cases and rare scenarios. A key requirement is the ability to statically verify the completeness of an input test generator: it must not only produce correct input cases but also potentially \emph{all} relevant cases.

Rather than focusing on proving the correctness of a program, Coverage Types shift the emphasis towards proving the completeness of the generator functions in relation to the data they handle. Coverage Types achieve this by employing an under-approximation approach. The type associated with an expression provides a guarantee about the values it returns. Specifically, it ensures that all values satisfying the predicate associated with the type will be generated in at least one execution of the expression. It is important to note that the predicate does not necessarily represent all values returned by each execution. However, we are guaranteed that all values satisfying the predicate are covered, in line with the principles of under-approximation logic \cite{IL1}.

Here, we introduce \emph{Extended Coverage Types}, which are characterized by the inclusion of two type qualifiers. The first qualifier corresponds to the standard Coverage Type, while the second provides additional information that specifies \emph{exactly} the values returned by the expression: both \emph{all and only} those values. This extension stems from the need to incorporate \emph{correctness} in resource usage, which is tracked through History Expressions. From a technical standpoint, Extended Coverage Types involves handling under-approximation within an otherwise over-approximated type.

Our goal is to statically verify the correct usage of resources through a type that directly corresponds to a History Expression. In a type system that follows the idea of over-approximation for the return type, this would pose no issues; it would simply require pairing the return type with the behavioural type.

\begin{wrapfigure}{r}{0.4\textwidth}
    \centering
    \begin{lstlisting}
match bool_gen () with
| 0 -> 'a'
| 1 -> 'b'
    \end{lstlisting}
    \caption{}
    \label{fig:exmp2}
\end{wrapfigure}

In Coverage Types, however, the type represents the guarantee of coverage for certain values, while other values may exist along paths that were disregarded during the typing process. For example, consider the example in Figure \ref{fig:exmp2}, the \verb|patter-matching| can be typed by the Coverage Type:

\begin{equation}
    \under{v: char \;|\; v = \text{'a'}}
\end{equation}

The issue arises from excluding the path where the expression reduces to $b$. If this value is later used in an action or an external function call recorded in a History Expression, the correctness property of the type system would be compromised. This is because the expected history would no longer provide a valid over-approximation.

We address this issue by introducing a new Coverage Type, enhanced with a qualifier that ensures not only completeness (coverage) but also correctness. While this might seem like a significant change that could disrupt the type system and its denotations, this is not the case. The only rule affected is the one governing the subtyping relationship, as that is where paths are discarded.

To keep consistency, in this new type—referred to as the \textbf{Extended Coverage Type} (ECT), the second qualifier in the sub-typing rule must remain semantically identical. As we will demonstrate, if an expression is typed according to the type system rules of $\lambda^{\textbf{TG}}$ \cite{coverage} without applying the sub-typing rule, the type qualifier will precisely represent the values returned at runtime.

For instance, the \emph{ECT} associated with the expression of the previous example is:

\begin{equation}
    \under{v: char \;|\; v = \text{'a'} \;|\; v = \text{'a'} \;\lor\; v = \text{'b'}}
\end{equation}

\vspace{0pt}
\begin{wrapfigure}{l}{0.60\textwidth}
    \begin{lstlisting}
let f = ?\typeact{new}$_{file}$? ()
in
let _ = ?\typeact{open}? f
in
let rec g (n: int) (f: ?\typekw{file}?) : int list =
    if n < 0 then [] else (
        if bool_gen () then [] else (
            let x = int_range (0, n)
            in
            let _ = ?\typeact{write}? f x
            in
            x :: (g (x - 1) f)
        )
    )
in
g 10 f
    \end{lstlisting}
    \caption{Code that creates and opens a new file, and writes in a series of randomly generated numbers between 0 and 10 including extremes.}
    \label{fig:exmp1}
\end{wrapfigure}

We now consider a more expressive example. The code in Figure \ref{fig:exmp1} uses OCaml-like syntax and begins by creating and opening a new file. After that, a recursive function, \verb|g|, is defined. This function takes two parameters: an integer \verb|n| and a file \verb|f|, and writes to the file the number generated by the primitive \verb|int_range|. The \verb|int_range| function accepts a pair of numbers and randomly generates, following a uniform probability distribution, a number between the two given values. The generated number is then concatenated with the results of subsequent recursive calls, until either \verb|n| becomes less than \verb|0|, or early termination occurs via the \verb|bool_gen| primitive, which randomly generates a boolean value.This block of code produces \emph{all} lists in descending order without repeated elements, using numbers between \verb|0| and \verb|10|.

To ensure completeness in generation, early termination is essential; otherwise, lists that satisfy the criteria, such as \verb|[10]| and \verb|[7, 5]|, would never be generated. Finally, the function is applied to \verb|10| and the newly created file.

The return type will obviously be a \verb|int list| type. What we are now interested in is determining the program's behaviour with respect to resource usage. The History Expression, the latent effect, that our type system will be able to associate with the code on the left is as follows:

\begin{equation}
    \begin{gathered}
        new_{file}(X) \cdot open(X) \cdot \\
        \cdot \mu G\bluet{(}n{:}(int{:}v \geq 0), \;f{:}(file{:}\top_{file})\bluet{)}\oranget{(}\epsilon + write(v = f, \; v \geq 0 \;\land\; v \leq n) \cdot \\
        \cdot G\bluet{(}n{:}(\exists x. x \geq 0 \;\land\; v \leq n \;\land\; v = x - 1), \;f{:}(v = f)\bluet{)}\oranget{)} \cdot G(v = 10, \;v = X)
    \end{gathered}
\end{equation}

The effect described above is an over-approximation of the behaviour of the code in Figure 
\ref{fig:exmp1}. First, a file is created and associated with an arbitrary identifier, $X$. Then, the file is opened, and the latent effect of the recursive function \verb|g| is defined. This is achieved using recursion (via the $\mu$ construct), allowing us to express the following:

\begin{enumerate}
    \item The identifier $G$ to be used for recursive calls.
    \item The list of parameters that the function takes as input, with associated types.
    \item The latent effect of the recursive function includes the possibility of either terminating the recursion through the special empty action $\epsilon$, or writing the generated number $x$ to the file $f$. Since $x$ can be any number between $0$ and $n$, we achieve an over-approximation by incorporating the qualifier associated with the variable $x$ into the \verb|write| action. The recursive call, $G$, takes the same file and $x - 1$ as parameters. Because the exact value of $x$ is unknown, the qualifier has the role of representing all the possible values that can be obtained, meaning all values that satisfy the predicate.
\end{enumerate}

As expected, the application of the recursive function $G$ takes place at the end of the history, since the $\mu$ primitive defines a recursive function but does not apply it. The appearance of the identifier $G$ with its associated parameters, upon which the function is invoked, marks the starting point for the unfolding of the recursion.

The Coverage Type associated with the previous code fragment in Figure \ref{fig:exmp1} is as follows:
\begin{equation}
    \begin{gathered}
        \under{v: int\;list \;|\; \forall u, mem(v, u) \Longrightarrow 0 \leq u \leq 10 \;\land\; dec\_sorted(v) \;\land\; \\
        \neg(\exists w, \forall u, mem(v, u) \Longleftrightarrow mem(w, u) \;\land\; shorter(w, v))}
    \end{gathered}
\end{equation}

We now comment on the Coverage Type above. Following \cite{coverage}, type qualifiers are enriched with \emph{method predicates} such as $mem$, $dec\_sorted$ and $shorter$, namely certain \emph{uninterpreted functions} of which we only know the name and arity. The predicate $mem(v, u)$ returns \verb|true| if the element $u$ belongs to the data structure $v$; $dec\_sorted$ checks whether the structure is ordered in the descending direction; whereas $shorter$ returns \verb|true| if the length in terms of elements of the first structure is less than the second.

Intuitively, all values that satisfy the predicate are returned by the program. In fact, it is clear that any list meeting the constraints outlined below will certainly be generated in at least one execution of the code in Figure \ref{fig:exmp1}:
\begin{enumerate}
    \item All items in the list are between 0 and 10;
    \item The list must be ordered in descending order;
    \item There must not exist a list $w$ that contains exactly the same elements as the list in question but is shorter in length. If such a list exists, it would mean that the current list contains at least one duplicate. However, as previously mentioned, the code does not generate lists with repeated elements.
\end{enumerate}

A main issue with Coverage Types, however, is their under-approximation flavour. This allows certain paths that are actually reachable to be dropped, precisely because they are defined as an under-approximation of the values returned by the program.

For instance, the code in Figure \ref{fig:exmp1} can also be associated with the Coverage Types:
\begin{equation}
    \begin{gathered}
        \under{v: int\;list \;|\; \forall u, mem(v, u) \Longrightarrow u = 5 \;\lor\; v = 9 \;\land\; dec\_sorted(v) \;\land\; \\
        \neg(\exists w, \forall u, mem(v, u) \Longleftrightarrow mem(w, u) \;\land\; shorter(w, v))}
    \end{gathered}
\end{equation}
\begin{equation}
    \begin{gathered}
        \under{v: int\;list \;|\; \forall u, mem(v, u) \Longrightarrow 0 \leq u \leq 7 \;\land\; dec\_sorted(v) \;\land\; \\
        \neg(\exists w, \forall u, mem(v, u) \Longleftrightarrow mem(w, u) \;\land\; shorter(w, v))}
    \end{gathered}
\end{equation}
Note that the lists satisfying the predicate of the first type above are only \verb|[]|, \verb|[5]|, \verb|[9]| and \verb|[9, 5]|. These lists are guaranteed to be generated in at least one execution of the code, and therefore, the type provides a correct under-approximation of the program's behaviour. Indeed, according to the structural properties of Coverage Types \cite{coverage}, the following subtype relation applies:
\begin{equation}
    \begin{gathered}
        \under{v: int\;list \;|\; \forall u, mem(v, u) \Longrightarrow 0 \leq u \leq 10 \;\land\; dec\_sorted(v) \;\land\; \\
        \neg(\exists w, \forall u, mem(v, u) \Longleftrightarrow mem(w, u) \;\land\; shorter(w, v))} \\
        <: \\
        \under{v: int\;list \;|\; \forall u, mem(v, u) \Longrightarrow u = 5 \;\lor\; v = 9 \;\land\; dec\_sorted(v) \;\land\; \\
        \neg(\exists w, \forall u, mem(v, u) \Longleftrightarrow mem(w, u) \;\land\; shorter(w, v))}
    \end{gathered}
\end{equation}
However, if we delete paths that are nevertheless valid, the linkage with the over-approximation provided by the effect, is no longer valid! This is why we introduce Extended Coverage Types which essentially adds an additional qualifier where no path has been dropped, and this qualifier will be used to bind variables within History Expressions.