\section{Related Work}
The recent rise in MARL popularity has fragmented community standards and tools, with the frequent introduction of new libraries such as \cite{rutherford2024jaxmarl, hu2022marllib, liang2018rllib, pettingzoo}. Among the most popular are PyMARL \cite{smac} and EPyMARL \cite{papoudakis2021benchmarking}, both of which have played a crucial role in driving the influx of cooperative MARL algorithms. However, these libraries have somewhat overlooked the integration of fully cooperative MARL environments, pushing researchers to focus on specific benchmarks, such as SMAC \cite{smac, smac2} and GRF \cite{grf}, raising concerns about the reliability and generalizability of the proposed algorithms \cite{protocol}. Despite recent efforts \cite{papoudakis2021benchmarking, yu2020benchmarking, bettini2024benchmarl, hu2022marllib} aiming to provide a comprehensive understanding of standard cooperative MARL algorithms through benchmarking, the evaluation of fully cooperative MARL still lacks systematic diversity and reliability.