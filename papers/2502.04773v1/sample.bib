@book{Lam94,
  author = {Leslie Lamport},
  title = {{\LaTeX}: A Document Preparation System},
  publisher = {Addison-Wesley},
  address = {Reading, MA},
  edition = {2nd},
  year = {1994}
}



@inproceedings{liang2018rllib,
  title={RLlib: Abstractions for distributed reinforcement learning},
  author={Liang, Eric and Liaw, Richard and Nishihara, Robert and Moritz, Philipp and Fox, Roy and Goldberg, Ken and Gonzalez, Joseph and Jordan, Michael and Stoica, Ion},
  booktitle={International conference on machine learning},
  pages={3053--3062},
  year={2018},
  organization={PMLR}
}

@article{pettingzoo,
  title={Pettingzoo: Gym for multi-agent reinforcement learning},
  author={Terry, Jordan and Black, Benjamin and Grammel, Nathaniel and Jayakumar, Mario and Hari, Ananth and Sullivan, Ryan and Santos, Luis S and Dieffendahl, Clemens and Horsch, Caroline and Perez-Vicente, Rodrigo and others},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={15032--15043},
  year={2021}
}

@inproceedings{rutherford2024jaxmarl,
  title={JaxMARL: Multi-Agent RL Environments and Algorithms in JAX},
  author={Rutherford, Alexander and Ellis, Benjamin and Gallici, Matteo and Cook, Jonathan and Lupu, Andrei and Ingvarsson, Gar{\dh}ar and Willi, Timon and Khan, Akbir and Schroeder de Witt, Christian and Souly, Alexandra and others},
  booktitle={Proceedings of the 23rd International Conference on Autonomous Agents and Multiagent Systems},
  pages={2444--2446},
  year={2024}
}

@article{facmac,
  title={Facmac: Factored multi-agent centralised policy gradients},
  author={Peng, Bei and Rashid, Tabish and Schroeder de Witt, Christian and Kamienny, Pierre-Alexandre and Torr, Philip and B{\"o}hmer, Wendelin and Whiteson, Shimon},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={12208--12221},
  year={2021}
}

@inproceedings{zheng2018magent,
  title={Magent: A many-agent reinforcement learning platform for artificial collective intelligence},
  author={Zheng, Lianmin and Yang, Jiacheng and Cai, Han and Zhou, Ming and Zhang, Weinan and Wang, Jun and Yu, Yong},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={32},
  number={1},
  year={2018}
}

@book{marl_book,
  title={Multi-agent reinforcement learning: Foundations and modern approaches},
  author={Albrecht, Stefano V and Christianos, Filippos and Sch{\"a}fer, Lukas},
  year={2024},
  publisher={MIT Press}
}

@article{hu2022marllib,
  title={Marllib: Extending rllib for multi-agent reinforcement learning},
  author={Hu, Siyi and Zhong, Yifan and Gao, Minquan and Wang, Weixun and Dong, Hao and Li, Zhihui and Liang, Xiaodan and Yang, Yaodong and Chang, Xiaojun},
  year={2022}
}

@article{bettini2024benchmarl,
  title={Benchmarl: Benchmarking multi-agent reinforcement learning},
  author={Bettini, Matteo and Prorok, Amanda and Moens, Vincent},
  journal={Journal of Machine Learning Research},
  volume={25},
  number={217},
  pages={1--10},
  year={2024}
}

@article{gupta2023cammarl,
  title={CAMMARL: Conformal Action Modeling in Multi Agent Reinforcement Learning},
  author={Gupta, Nikunj and Nath, Somjit and Kahou, Samira Ebrahimi},
  journal={arXiv preprint arXiv:2306.11128},
  year={2023}
}

@article{ai_albrecht_edinburgh,
  title={Deep reinforcement learning for multi-agent interaction},
  author={Ahmed, Ibrahim H and Brewitt, Cillian and Carlucho, Ignacio and Christianos, Filippos and Dunion, Mhairi and Fosong, Elliot and Garcin, Samuel and Guo, Shangmin and Gyevnar, Balint and McInroe, Trevor and others},
  journal={Ai Communications},
  volume={35},
  number={4},
  pages={357--368},
  year={2022},
  publisher={IOS Press}
}

@article{overcooked,
  title={On the utility of learning about humans for human-ai coordination},
  author={Carroll, Micah and Shah, Rohin and Ho, Mark K and Griffiths, Tom and Seshia, Sanjit and Abbeel, Pieter and Dragan, Anca},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@inproceedings{rahman2022adversar,
  title={Adversar: Adversarial search and rescue via multi-agent reinforcement learning},
  author={Rahman, Aowabin and Bhattacharya, Arnab and Ramachandran, Thiagarajan and Mukherjee, Sayak and Sharma, Himanshu and Fujimoto, Ted and Chatterjee, Samrat},
  booktitle={2022 IEEE International Symposium on Technologies for Homeland Security (HST)},
  pages={1--7},
  year={2022},
  organization={IEEE}
}

@article{cds,
  title={Celebrating diversity in shared multi-agent reinforcement learning},
  author={Li, Chenghao and Wang, Tonghan and Wu, Chengjie and Zhao, Qianchuan and Yang, Jun and Zhang, Chongjie},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={3991--4002},
  year={2021}
}

@article{qplex,
  title={Qplex: Duplex dueling multi-agent q-learning},
  author={Wang, Jianhao and Ren, Zhizhou and Liu, Terry and Yu, Yang and Zhang, Chongjie},
  journal={arXiv preprint arXiv:2008.01062},
  year={2020}
}

@article{qmix,
  title={Monotonic value function factorisation for deep multi-agent reinforcement learning},
  author={Rashid, Tabish and Samvelyan, Mikayel and De Witt, Christian Schroeder and Farquhar, Gregory and Foerster, Jakob and Whiteson, Shimon},
  journal={Journal of Machine Learning Research},
  volume={21},
  number={178},
  pages={1--51},
  year={2020}
}

@inproceedings{burgard2000collaborative,
  title={Collaborative multi-robot exploration},
  author={Burgard, Wolfram and Moors, Mark and Fox, Dieter and Simmons, Reid and Thrun, Sebastian},
  booktitle={Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No. 00CH37065)},
  volume={1},
  pages={476--481},
  year={2000},
  organization={IEEE},
  publisher={IEEE}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@article{smac2,
  title={Smacv2: An improved benchmark for cooperative multi-agent reinforcement learning},
  author={Ellis, Benjamin and Cook, Jonathan and Moalla, Skander and Samvelyan, Mikayel and Sun, Mingfei and Mahajan, Anuj and Foerster, Jakob and Whiteson, Shimon},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{smac,
  title={The starcraft multi-agent challenge},
  author={Samvelyan, Mikayel and Rashid, Tabish and De Witt, Christian Schroeder and Farquhar, Gregory and Nardelli, Nantas and Rudner, Tim GJ and Hung, Chia-Man and Torr, Philip HS and Foerster, Jakob and Whiteson, Shimon},
  journal={arXiv preprint arXiv:1902.04043},
  year={2019}
}

@inproceedings{grf,
  title={Google research football: A novel reinforcement learning environment},
  author={Kurach, Karol and Raichuk, Anton and Sta{\'n}czyk, Piotr and Zaj{\k{a}}c, Micha{\l} and Bachem, Olivier and Espeholt, Lasse and Riquelme, Carlos and Vincent, Damien and Michalski, Marcin and Bousquet, Olivier and others},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={34},
  number={04},
  pages={4501--4510},
  year={2020}
}

@inproceedings{ddqn,
  title={Deep reinforcement learning with double q-learning},
  author={Van Hasselt, Hado and Guez, Arthur and Silver, David},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={30},
  number={1},
  year={2016}
}

@article{mnih2013playing,
  title={Playing atari with deep reinforcement learning},
  author={Mnih, Volodymyr},
  journal={arXiv preprint arXiv:1312.5602},
  year={2013}
}

@article{clip_in_rl,
  title={Can pre-trained text-to-image models generate visual goals for reinforcement learning?},
  author={Gao, Jialu and Hu, Kaizhe and Xu, Guowei and Xu, Huazhe},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{happo,
  title={Trust region policy optimisation in multi-agent reinforcement learning},
  author={Kuba, Jakub Grudzien and Chen, Ruiqing and Wen, Muning and Wen, Ying and Sun, Fanglei and Wang, Jun and Yang, Yaodong},
  journal={arXiv preprint arXiv:2109.11251},
  year={2021}
}

@article{emc,
  title={Episodic multi-agent reinforcement learning with curiosity-driven exploration},
  author={Zheng, Lulu and Chen, Jiarui and Wang, Jianhao and He, Jiamin and Hu, Yujing and Chen, Yingfeng and Fan, Changjie and Gao, Yang and Zhang, Chongjie},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={3757--3769},
  year={2021}
}

@article{mat,
  title={Multi-agent reinforcement learning is a sequence modeling problem},
  author={Wen, Muning and Kuba, Jakub and Lin, Runji and Zhang, Weinan and Wen, Ying and Wang, Jun and Yang, Yaodong},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={16509--16521},
  year={2022}
}

@inproceedings{eoi,
  title={The emergence of individuality},
  author={Jiang, Jiechuan and Lu, Zongqing},
  booktitle={International Conference on Machine Learning},
  pages={4992--5001},
  year={2021},
  organization={PMLR}
}

@inproceedings{maser,
  title={Maser: Multi-agent reinforcement learning with subgoals generated from experience replay buffer},
  author={Jeon, Jeewon and Kim, Woojun and Jung, Whiyoung and Sung, Youngchul},
  booktitle={International Conference on Machine Learning},
  pages={10041--10052},
  year={2022},
  organization={PMLR}
}

@article{mappo,
  title={The surprising effectiveness of ppo in cooperative multi-agent games},
  author={Yu, Chao and Velu, Akash and Vinitsky, Eugene and Gao, Jiaxuan and Wang, Yu and Bayen, Alexandre and Wu, Yi},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={24611--24624},
  year={2022}
}

@inproceedings{coma,
  title={Counterfactual multi-agent policy gradients},
  author={Foerster, Jakob and Farquhar, Gregory and Afouras, Triantafyllos and Nardelli, Nantas and Whiteson, Shimon},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={32},
  number={1},
  year={2018}
}

@inproceedings{shah2021rrl,
  title={RRL: Resnet as representation for Reinforcement Learning},
  author={Shah, Rutav M and Kumar, Vikash},
  booktitle={International Conference on Machine Learning},
  pages={9465--9476},
  year={2021},
  organization={PMLR}
}

@inproceedings{wang2020roma,
  title={ROMA: multi-agent reinforcement learning with emergent roles},
  author={Wang, Tonghan and Dong, Heng and Lesser, Victor and Zhang, Chongjie},
  booktitle={Proceedings of the 37th International Conference on Machine Learning},
  pages={9876--9886},
  year={2020}
}

@article{protocol,
  title={Towards a standardised performance evaluation protocol for cooperative marl},
  author={Gorsane, Rihab and Mahjoub, Omayma and de Kock, Ruan John and Dubb, Roland and Singh, Siddarth and Pretorius, Arnu},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={5510--5521},
  year={2022}
}

@article{yu2020benchmarking,
  title={Benchmarking multi-agent deep reinforcement learning algorithms},
  author={Yu, Chao and Velu, Akash and Vinitsky, Eugene and Wang, Yu and Bayen, Alexandre and Wu, Yi},
  year={2020}
}

@article{mpe2,
  title={Multi-agent actor-critic for mixed cooperative-competitive environments},
  author={Lowe, Ryan and Wu, Yi I and Tamar, Aviv and Harb, Jean and Pieter Abbeel, OpenAI and Mordatch, Igor},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{yang2024hierarchical,
  title={Hierarchical multi-agent skill discovery},
  author={Yang, Mingyu and Yang, Yaodong and Lu, Zhenbo and Zhou, Wengang and Li, Houqiang},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{nekoei2023dealing,
  title={Dealing with non-stationarity in decentralized cooperative multi-agent deep reinforcement learning via multi-timescale learning},
  author={Nekoei, Hadi and Badrinaaraayanan, Akilesh and Sinha, Amit and Amini, Mohammad and Rajendran, Janarthanan and Mahajan, Aditya and Chandar, Sarath},
  booktitle={Conference on Lifelong Learning Agents},
  pages={376--398},
  year={2023},
  organization={PMLR}
}

@inproceedings{christianos2021scaling,
  title={Scaling multi-agent reinforcement learning with selective parameter sharing},
  author={Christianos, Filippos and Papoudakis, Georgios and Rahman, Muhammad A and Albrecht, Stefano V},
  booktitle={International Conference on Machine Learning},
  pages={1989--1998},
  year={2021},
  organization={PMLR}
}

@article{zhong2024heterogeneous,
  title={Heterogeneous-agent reinforcement learning},
  author={Zhong, Yifan and Kuba, Jakub Grudzien and Feng, Xidong and Hu, Siyi and Ji, Jiaming and Yang, Yaodong},
  journal={Journal of Machine Learning Research},
  volume={25},
  number={1-67},
  pages={1},
  year={2024}
}

@article{ruan2022gcs_yalidu,
  title={GCS: Graph-based coordination strategy for multi-agent reinforcement learning},
  author={Ruan, Jingqing and Du, Yali and Xiong, Xuantang and Xing, Dengpeng and Li, Xiyun and Meng, Linghui and Zhang, Haifeng and Wang, Jun and Xu, Bo},
  journal={arXiv preprint arXiv:2201.06257},
  year={2022}
}

@article{guan2022efficient_masia,
  title={Efficient multi-agent communication via self-supervised information aggregation},
  author={Guan, Cong and Chen, Feng and Yuan, Lei and Wang, Chenghe and Yin, Hao and Zhang, Zongzhang and Yu, Yang},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={1020--1033},
  year={2022}
}

@article{atm2022transformer,
  title={Transformer-based working memory for multiagent reinforcement learning with action parsing},
  author={Yang, Yaodong and Chen, Guangyong and Wang, Weixun and Hao, Xiaotian and Hao, Jianye and Heng, Pheng-Ann},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={34874--34886},
  year={2022}
}

@article{hong2024learning,
  title={Learning to influence human behavior with offline reinforcement learning},
  author={Hong, Joey and Levine, Sergey and Dragan, Anca},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{fosong2024learning,
  title={Learning Complex Teamwork Tasks using a Given Sub-task Decomposition},
  author={Fosong, Elliot and Rahman, Arrasy and Carlucho, Ignacio and Albrecht, Stefano V},
  booktitle={Proceedings of the 23rd International Conference on Autonomous Agents and Multiagent Systems},
  pages={598--606},
  year={2024}
}

@article{chen2024generative,
  title={Generative modelling of stochastic actions with arbitrary constraints in reinforcement learning},
  author={Chen, Changyu and Karunasena, Ramesha and Nguyen, Thanh and Sinha, Arunesh and Varakantham, Pradeep},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{siu2021dynamic,
  title={Dynamic coordination graph for cooperative multi-agent reinforcement learning},
  author={Siu, Chapman and Traish, Jason and Da Xu, Richard Yi},
  booktitle={Asian Conference on Machine Learning},
  pages={438--453},
  year={2021},
  organization={PMLR}
}

@article{terry2020multiplayer,
  title={Multiplayer support for the arcade learning environment},
  author={Terry, Justin K and Black, Benjamin and Santos, Luis},
  journal={arXiv preprint arXiv:2009.09341},
  year={2020}
}

@article{terry2020revisiting,
  title={Revisiting parameter sharing in multi-agent deep reinforcement learning},
  author={Terry, Justin K and Grammel, Nathaniel and Son, Sanghyun and Black, Benjamin and Agrawal, Aakriti},
  journal={arXiv preprint arXiv:2005.13625},
  year={2020}
}

@inproceedings{kontogiannis2023inherently,
  title={Inherently Interpretable Deep Reinforcement Learning Through Online Mimicking},
  author={Kontogiannis, Andreas and Vouros, George A},
  booktitle={International Workshop on Explainable, Transparent Autonomous Agents and Multi-Agent Systems},
  pages={160--179},
  year={2023},
  organization={Springer}
}

@article{supply_chain,
  title={Case-based reinforcement learning for dynamic inventory control in a multi-agent supply-chain system},
  author={Jiang, Chengzhi and Sheng, Zhaohan},
  journal={Expert Systems with Applications},
  volume={36},
  number={3},
  pages={6520--6526},
  year={2009},
  publisher={Elsevier}
}

@inproceedings{logistics,
  title={A Cooperative Multi-Agent Reinforcement Learning Framework for Resource Balancing in Complex Logistics Network},
  author={Li, Xihan and Zhang, Jia and Bian, Jiang and Tong, Yunhai and Liu, Tie-Yan},
  booktitle={Proceedings of the 18th International Conference on Autonomous Agents and MultiAgent Systems},
  pages={980--988},
  year={2019}
}

@article{schaul2015prioritized,
  title={Prioritized Experience Replay},
  author={Schaul, Tom},
  journal={arXiv preprint arXiv:1511.05952},
  year={2015}
}

@inproceedings{xiao2020learning,
  title={Learning multi-robot decentralized macro-action-based policies via a centralized q-net},
  author={Xiao, Yuchen and Hoffman, Joshua and Xia, Tian and Amato, Christopher},
  booktitle={2020 IEEE International conference on robotics and automation (ICRA)},
  pages={10695--10701},
  year={2020},
  organization={IEEE}
}

@article{xiao2022asynchronous,
  title={Asynchronous actor-critic for multi-agent reinforcement learning},
  author={Xiao, Yuchen and Tan, Weihao and Amato, Christopher},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={4385--4400},
  year={2022}
}

@inproceedings{xiao2020macro,
  title={Macro-action-based deep multi-agent reinforcement learning},
  author={Xiao, Yuchen and Hoffman, Joshua and Amato, Christopher},
  booktitle={Conference on Robot Learning},
  pages={1146--1161},
  year={2020},
  organization={PMLR}
}

@inproceedings{seuken2007,
author = {Seuken, Sven and Zilberstein, Shlomo},
title = {Improved memory-bounded dynamic programming for decentralized POMDPs},
year = {2007},
isbn = {0974903930},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Memory-Bounded Dynamic Programming (MBDP) has proved extremely effective in solving decentralized POMDPs with large horizons. We generalize the algorithm and improve its scalability by reducing the complexity with respect to the number of observations from exponential to polynomial. We derive error bounds on solution quality with respect to this new approximation and analyze the convergence behavior. To evaluate the effectiveness of the improvements, we introduce a new, larger benchmark problem. Experimental results show that despite the high complexity of decentralized POMDPs, scalable solution techniques such as MBDP perform surprisingly well.},
booktitle = {Proceedings of the Twenty-Third Conference on Uncertainty in Artificial Intelligence},
pages = {344–351},
numpages = {8},
location = {Vancouver, BC, Canada},
series = {UAI'07}
}

@inproceedings{omidshafiei2017deep,
  title={Deep decentralized multi-task multi-agent reinforcement learning under partial observability},
  author={Omidshafiei, Shayegan and Pazis, Jason and Amato, Christopher and How, Jonathan P and Vian, John},
  booktitle={International Conference on Machine Learning},
  pages={2681--2690},
  year={2017},
  organization={PMLR}
}

@book{oliehoek2016concise,
  title={A concise introduction to decentralized POMDPs},
  author={Oliehoek, Frans A and Amato, Christopher and others},
  volume={1},
  year={2016},
  publisher={Springer}
}

@inproceedings{mpe,
  title={Emergence of grounded compositional language in multi-agent populations},
  author={Mordatch, Igor and Abbeel, Pieter},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={32},
  number={1},
  year={2018}
}

@inproceedings{lbf,
    author = {Albrecht, Stefano V. and Stone, Peter},
    title = {Reasoning about Hypothetical Agent Behaviours and their Parameters},
    year = {2017},
    publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
    address = {Richland, SC},
    booktitle = {Proceedings of the 16th Conference on Autonomous Agents and MultiAgent Systems},
    pages = {547–555},
    numpages = {9},
    keywords = {ad hoc teamwork, agent types, parameter learning},
    location = {S\~{a}o Paulo, Brazil},
    series = {AAMAS '17}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@article{sun2024decision,
  title={Decision-Making With Speculative Opponent Models},
  author={Sun, Jing and Chen, Shuo and Zhang, Cong and Ma, Yining and Zhang, Jie},
  journal={IEEE Transactions on Neural Networks and Learning Systems},
  year={2024},
  publisher={IEEE}
}

@inproceedings{jeon2022maser,
  title={Maser: Multi-agent reinforcement learning with subgoals generated from experience replay buffer},
  author={Jeon, Jeewon and Kim, Woojun and Jung, Whiyoung and Sung, Youngchul},
  booktitle={International Conference on Machine Learning},
  pages={10041--10052},
  year={2022},
  organization={PMLR}
}

@article{zheng2021episodic,
  title={Episodic multi-agent reinforcement learning with curiosity-driven exploration},
  author={Zheng, Lulu and Chen, Jiarui and Wang, Jianhao and He, Jiamin and Hu, Yujing and Chen, Yingfeng and Fan, Changjie and Gao, Yang and Zhang, Chongjie},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={3757--3769},
  year={2021}
}

@inproceedings{liu2021coach,
  title={Coach-player multi-agent reinforcement learning for dynamic team composition},
  author={Liu, Bo and Liu, Qiang and Stone, Peter and Garg, Animesh and Zhu, Yuke and Anandkumar, Anima},
  booktitle={International Conference on Machine Learning},
  pages={6860--6870},
  year={2021},
  organization={PMLR}
}

@article{yang2022transformer,
  title={Transformer-based working memory for multiagent reinforcement learning with action parsing},
  author={Yang, Yaodong and Chen, Guangyong and Wang, Weixun and Hao, Xiaotian and Hao, Jianye and Heng, Pheng-Ann},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={34874--34886},
  year={2022}
}

@misc{slimsam,
      title={SlimSAM: 0.1\% Data Makes Segment Anything Slim}, 
      author={Zigeng Chen and Gongfan Fang and Xinyin Ma and Xinchao Wang},
      year={2024},
      eprint={2312.05284},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2312.05284}, 
}

@article{sam,
  title={Segment Anything},
  author={Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Alexander and Gustafson, Laura and Xiao, Tsung-Yi and White, Curtis and Berg, Alexander C and Lo, Wan-Yen and Doll{\'a}r, Piotr and Girshick, Ross},
  journal={arXiv preprint arXiv:2304.02643},
  year={2023}
}

@InProceedings{xiao_corl_2019,
    author = "Xiao, Yuchen and Hoffman, Joshua and Amato, Christopher",
    title = "Macro-Action-Based Deep Multi-Agent Reinforcement Learning",
    booktitle = "3rd Annual Conference on Robot Learning",
    year = "2019"
}

@misc{pressureplate_github,
  author       = {Trevor McInroe, Filippos Christianos},
  title        = {Github pressureplate},
  howpublished = {\url{https://github.com/uoe-agents/pressureplate/tree/main}},
  note         = {Pressureplate GitHub repository}
}

#### LBF env references
@inproceedings{papoudakis2021benchmarking,
   title={Benchmarking Multi-Agent Deep Reinforcement Learning Algorithms in Cooperative Tasks},
   author={Georgios Papoudakis and Filippos Christianos and Lukas Schäfer and Stefano V. Albrecht},
   booktitle = {Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks (NeurIPS)},
   year={2021},
   openreview = {https://openreview.net/forum?id=cIrPX-Sn5n},
}

@inproceedings{christianos2020shared,
  title={Shared Experience Actor-Critic for Multi-Agent Reinforcement Learning},
  author={Christianos, Filippos and Schäfer, Lukas and Albrecht, Stefano V},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  year={2020}
}

@misc{lbf_github,
  author       = {Filippos Christianos, Lukas Schäfer},
  title        = {Github LBF},
  howpublished = {\url{https://github.com/semitable/lb-foraging/tree/master}},
  note         = {LBF GitHub repository}
}
@misc{1606.01540,
  Author = {Greg Brockman and Vicki Cheung and Ludwig Pettersson and Jonas Schneider and John Schulman and Jie Tang and Wojciech Zaremba},
  Title = {OpenAI Gym},
  Year = {2016},
  Eprint = {arXiv:1606.01540},
}

######
###### overcooked env refrences

@misc{overcooked_github,
  author       = {Center for Human-Compatible AI GIthub contributors},
  title        = {Github Overcooked},
  howpublished = {\url{https://github.com/HumanCompatibleAI/overcooked_ai}},
  note         = {Overcooked GitHub repository}
}

@article{bellemare2013arcade,
  title={The arcade learning environment: An evaluation platform for general agents},
  author={Bellemare, Marc G and Naddaf, Yavar and Veness, Joel and Bowling, Michael},
  journal={Journal of Artificial Intelligence Research},
  volume={47},
  pages={253--279},
  year={2013}
} = {The Knowledge Engineering Review},
  volume = {10},
  number = {2},
  pages = {115--152},
  year = {1995}
}

@article{GrKr96,
  title = {Collaborative Plans for Complex Group Action},
  author = {Grosz, Barbara J. and Kraus, Sarit},
  journal = {Artificial Intelligence},
  volume = {86},
  number = {2},
  pages = {269--357},
  year = {1996}
}

@Techreport{Har78,
  author =       "David Harel",
  year =         "1978",
  title =        "Logics of programs: axiomatics and descriptive power",
  institution =  "Massachusetts Institute of Technology",
  type =         "MIT Research Lab Technical Report",
  number =       "TR-200",
  address =      "Cambridge, MA",
  month =        "",
  note =         ""
}

@Phdthesis{Cla85,
  author =       "Kenneth L. Clarkson",
  year =         "1985",
  title =        "Algorithms for Closest-Point Problems (Computational Geometry)",
  school =       "Stanford University",
  address =      "Palo Alto, CA",
  note =         "UMI Order Number: AAT 8506171",
  type =         "",
  month =        ""
}

@misc{Oba08,
  author        = "Barack Obama",
  year          = "2008",
  title         = "A More Perfect Union",
  howpublished  = "Video",
  day           = "5",
  url           = "http://video.google.com/videoplay?docid=6528042696351994555",
  month         = mar,
  lastaccessed  = "March 21, 2008",
  note          =  ""
}

@misc{Sci09,
  author =       "Joseph Scientist",
  year =         "2009",
  title =        "The fountain of youth",
  note =         "Patent No. 12345, Filed July 1st., 2008, Issued Aug. 9th., 2009",
  url =          "",
  howpublished = "",
  month =        aug,
  lastaccessed = ""
}

@ArtifactDataset{AnMC13,
 author    =  {Sam Anzaroot and Andrew McCallum},
 title     =  {{UMass} Citation Field Extraction Dataset},
 year      = 2013,
 organization = {University of Massachusetts},
 url       =
    {http://www.iesl.cs.umass.edu/data/data-umasscitationfield},
 lastaccessed = {May 27, 2019}
}

@inproceedings{Hag1993,
title        = {Maintaining Discrete Probability Distributions Optimally},
author       = {Hagerup, Torben and Mehlhorn, Kurt and Munro, J. Ian},
booktitle    = {Proceedings of the 20th International Colloquium on Automata, Languages and Programming},
series       = {Lecture Notes in Computer Science},
volume       = {700},
pages        = {253--264},
year         = {1993},
publisher    = {Springer-Verlag},
address      = {Berlin}
}

@Book{Knu97,
  author =       "Donald E. Knuth",
  title =        "The Art of Computer Programming, Vol. 1: Fundamental Algorithms",
  publisher =    "Addison Wesley",
  year =         "1997",
  address =      "Reading, Massachusetts",
  edition =      "3rd",
  editor =       "",
  volume =       "",
  number =       "",
  series =       "",
  month =        "",
  note =         ""
}

@MASTERSTHESIS{Ani03,
author = {David A. Anisi},
title = {Optimal Motion Control of a Ground Vehicle},
school = {Royal Institute of Technology (KTH), Stockholm, Sweden},
intitution = {FOI-R-0961-SE, Swedish Defence Research Agency (FOI)},
year = {2003},
}
