@article{DePellegrin_Petrick_2024, title={Planning Domain Simulation: An Interactive System for Plan Visualisation}, volume={34}, url={https://ojs.aaai.org/index.php/ICAPS/article/view/31469}, DOI={10.1609/icaps.v34i1.31469}, abstractNote={Representing and manipulating domain knowledge is essential for developing systems that can visualize plans. This paper presents a novel plan visualisation system called Planning Domain Simulation (PDSim) that employs knowledge representation and manipulation techniques to support the plan visualization process. PDSim can use PDDL or the Unified Planning Library’s Python representation as the underlying language for modelling planning problems and provides an interface for users to manipulate this representation through interaction with the Unity game engine and a set of planners. The system’s features include visualising plan components, and their relationships, identifying plan conflicts, and examples applied to real-world problems.
The benefits and limitations of PDSim are also discussed, highlighting future research directions in the area.}, number={1}, journal={Proceedings of the International Conference on Automated Planning and Scheduling}, author={De Pellegrin, Emanuele and Petrick, Ronald P. A.}, year={2024}, month={May}, pages={133-141} }

@book{baier2008principles,
  title={Principles of model checking},
  author={Baier, Christel and Katoen, Joost-Pieter},
  year={2008},
  publisher={MIT press}
}

@inproceedings{bender2021dangers,
  title={On the dangers of stochastic parrots: Can language models be too big?},
  author={Bender, Emily M and Gebru, Timnit and McMillan-Major, Angelina and Shmitchell, Shmargaret},
  booktitle={Proceedings of the 2021 ACM conference on fairness, accountability, and transparency},
  pages={610--623},
  year={2021}
}

@inproceedings{bhatt2021uncertainty,
  title={Uncertainty as a form of transparency: Measuring, communicating, and using uncertainty},
  author={Bhatt, Umang and Antor{\'a}n, Javier and Zhang, Yunfeng and Liao, Q Vera and Sattigeri, Prasanna and Fogliato, Riccardo and Melan{\c{c}}on, Gabrielle and Krishnan, Ranganath and Stanley, Jason and Tickoo, Omesh and others},
  booktitle={Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society},
  pages={401--413},
  year={2021}
}

@inproceedings{bhattacharjee2024towards,
  title={Towards llm-guided causal explainability for black-box text classifiers},
  author={Bhattacharjee, Amrita and Moraffah, Raha and Garland, Joshua and Liu, Huan},
  booktitle={AAAI 2024 Workshop on Responsible Language Models, Vancouver, BC, Canada},
  year={2024}
}

@article{chan2023chateval,
  title={Chateval: Towards better llm-based evaluators through multi-agent debate},
  author={Chan, Chi-Min and Chen, Weize and Su, Yusheng and Yu, Jianxuan and Xue, Wei and Zhang, Shanghang and Fu, Jie and Liu, Zhiyuan},
  journal={arXiv preprint arXiv:2308.07201},
  year={2023}
}

@article{chen2023teaching,
  title={Teaching large language models to self-debug},
  author={Chen, Xinyun and Lin, Maxwell and Sch{\"a}rli, Nathanael and Zhou, Denny},
  journal={arXiv preprint arXiv:2304.05128},
  year={2023}
}

@article{chen2024can,
  title={Can We Rely on LLM Agents to Draft Long-Horizon Plans? Let's Take TravelPlanner as an Example},
  author={Chen, Yanan and Pesaranghader, Ali and Sadhu, Tanmana and Yi, Dong Hoon},
  journal={arXiv preprint arXiv:2408.06318},
  year={2024}
}

@inproceedings{desmond2024evalullm,
  title={EvaluLLM: LLM assisted evaluation of generative outputs},
  author={Desmond, Michael and Ashktorab, Zahra and Pan, Qian and Dugan, Casey and Johnson, James M},
  booktitle={Companion Proceedings of the 29th International Conference on Intelligent User Interfaces},
  pages={30--32},
  year={2024}
}

@inproceedings{dixon2014fridge,
  title={“The fridge door is open”--Temporal Verification of a Robotic Assistant’s Behaviours},
  author={Dixon, Clare and Webster, Matt and Saunders, Joe and Fisher, Michael and Dautenhahn, Kerstin},
  booktitle={Advances in Autonomous Robotics Systems: 15th Annual Conference, TAROS 2014, Birmingham, UK, September 1-3, 2014. Proceedings 15},
  pages={97--108},
  year={2014},
  organization={Springer}
}

@book{ebbinghaus1994mathematical,
  title={Mathematical logic},
  author={Ebbinghaus, Heinz-Dieter and Flum, J{\"o}rg and Thomas, Wolfgang and Ferebee, Ann S},
  volume={2},
  year={1994},
  publisher={Springer}
}

@article{fakhoury2024llm,
  title={LLM-based Test-driven Interactive Code Generation: User Study and Empirical Evaluation},
  author={Fakhoury, Sarah and Naik, Aaditya and Sakkas, Georgios and Chakraborty, Saikat and Lahiri, Shuvendu K},
  journal={arXiv preprint arXiv:2404.10100},
  year={2024}
}

@article{fox2003pddl2,
  title={PDDL2. 1: An Extension to PDDL for Expressing Temporal Planning Domains},
  author={Fox, Maria and Long, Derek},
  journal={Journal of Artificial Intelligence Research},
  volume={20},
  pages={61--124},
  year={2003},
  url={https://doi.org/10.1613/jair.1129},
  doi={10.1613/jair.1129}
}

@book{ghallab2016automated,
  title={Automated Planning and Acting},
  author={Ghallab, Malik and Nau, Dana and Traverso, Paolo},
  year={2016},
  publisher={Cambridge University Press},
  address={Cambridge, England}
}

@misc{gundawar2024robustplanningllmmoduloframework,
      title={Robust Planning with LLM-Modulo Framework: Case Study in Travel Planning}, 
      author={Atharva Gundawar and Mudit Verma and Lin Guan and Karthik Valmeekam and Siddhant Bhambri and Subbarao Kambhampati},
      year={2024},
      eprint={2405.20625},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2405.20625}, 
}

@inproceedings{hassan2024llm,
  title={Llm-guided formal verification coupled with mutation testing},
  author={Hassan, Muhammad and Ahmadi-Pour, Sallar and Qayyum, Khushboo and Jha, Chandan Kumar and Drechsler, Rolf},
  booktitle={2024 Design, Automation \& Test in Europe Conference \& Exhibition (DATE)},
  pages={1--2},
  year={2024},
  organization={IEEE}
}

@article{helmert2009concise,
  title={Concise finite-domain representations for PDDL planning tasks},
  author={Helmert, Malte},
  journal={Artificial Intelligence},
  volume={173},
  number={5-6},
  pages={503--535},
  year={2009},
  publisher={Elsevier}
}

@article{huang2023can,
  title={Can large language models explain themselves? a study of llm-generated self-explanations},
  author={Huang, Shiyuan and Mamidanna, Siddarth and Jangam, Shreedhar and Zhou, Yilun and Gilpin, Leilani H},
  journal={arXiv preprint arXiv:2310.11207},
  year={2023}
}

@article{huang2024empirical,
  title={An empirical study of llm-as-a-judge for llm evaluation: Fine-tuned judge models are task-specific classifiers},
  author={Huang, Hui and Qu, Yingqi and Liu, Jing and Yang, Muyun and Zhao, Tiejun},
  journal={arXiv preprint arXiv:2403.02839},
  year={2024}
}

@inproceedings{hurnaus2010programming,
  title={Programming assistance based on contracts and modular verification in the automation domain},
  author={Hurnaus, Dominik and Pr{\"a}hofer, Herbert},
  booktitle={Proceedings of the 2010 ACM Symposium on Applied Computing},
  pages={2544--2551},
  year={2010}
}

@article{ji2023survey,
  title={Survey of hallucination in natural language generation},
  author={Ji, Ziwei and Lee, Nayeon and Frieske, Rita and Yu, Tiezheng and Su, Dan and Xu, Yan and Ishii, Etsuko and Bang, Ye Jin and Madotto, Andrea and Fung, Pascale},
  journal={ACM Computing Surveys},
  volume={55},
  number={12},
  pages={1--38},
  year={2023},
  publisher={ACM New York, NY}
}

@article{ji2024testing,
  title={Testing and Understanding Erroneous Planning in LLM Agents through Synthesized User Inputs},
  author={Ji, Zhenlan and Wu, Daoyuan and Ma, Pingchuan and Li, Zongjie and Wang, Shuai},
  journal={arXiv preprint arXiv:2404.17833},
  year={2024}
}

@inproceedings{jiang2023graphologue,
  title={Graphologue: Exploring large language model responses with interactive diagrams},
  author={Jiang, Peiling and Rayan, Jude and Dow, Steven P and Xia, Haijun},
  booktitle={Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
  pages={1--20},
  year={2023}
}

@article{kambhampati2024llms,
  title={LLMs can't plan, but can help planning in LLM-modulo frameworks},
  author={Kambhampati, Subbarao and Valmeekam, Karthik and Guan, Lin and Verma, Mudit and Stechly, Kaya and Bhambri, Siddhant and Saldyt, Lucas and Murthy, Anil},
  journal={arXiv preprint arXiv:2402.01817},
  year={2024}
}

@article{kapellosaiplan4eu,
  title={AIPlan4EU: Planning and Scheduling for Space Applications},
  author={Kapellos, K and Micheli, A and Valentini, A}
}

@inproceedings{khurana2024and,
  title={Why and when llm-based assistants can go wrong: Investigating the effectiveness of prompt-based interactions for software help-seeking},
  author={Khurana, Anjali and Subramonyam, Hariharan and Chilana, Parmit K},
  booktitle={Proceedings of the 29th International Conference on Intelligent User Interfaces},
  pages={288--303},
  year={2024}
}

@article{kim2024understanding,
  title={Understanding Large-Language Model (LLM)-powered Human-Robot Interaction},
  author={Kim, Callie Y and Lee, Christine P and Mutlu, Bilge},
  journal={arXiv preprint arXiv:2401.03217},
  year={2024}
}

@article{koga2023exploring,
  title={Exploring the pitfalls of large language models: Inconsistency and inaccuracy in answering pathology board examination-style questions},
  author={Koga, Shunsuke},
  journal={medRxiv},
  pages={2023--08},
  year={2023},
  publisher={Cold Spring Harbor Laboratory Press}
}

@article{koo2023benchmarking,
  title={Benchmarking cognitive biases in large language models as evaluators},
  author={Koo, Ryan and Lee, Minhwa and Raheja, Vipul and Park, Jong Inn and Kim, Zae Myung and Kang, Dongyeop},
  journal={arXiv preprint arXiv:2309.17012},
  year={2023}
}

@article{krishna2024post,
  title={Post hoc explanations of language models can improve language models},
  author={Krishna, Satyapriya and Ma, Jiaqi and Slack, Dylan and Ghandeharioun, Asma and Singh, Sameer and Lakkaraju, Himabindu},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{lee2023benefits,
  title={Benefits, limits, and risks of GPT-4 as an AI chatbot for medicine},
  author={Lee, Peter and Bubeck, Sebastien and Petro, Joseph},
  journal={New England Journal of Medicine},
  volume={388},
  number={13},
  pages={1233--1239},
  year={2023},
  publisher={Mass Medical Soc}
}

@article{li2022explanations,
  title={Explanations from large language models make small reasoners better},
  author={Li, Shiyang and Chen, Jianshu and Shen, Yelong and Chen, Zhiyu and Zhang, Xinlu and Li, Zekun and Wang, Hong and Qian, Jing and Peng, Baolin and Mao, Yi and others},
  journal={arXiv preprint arXiv:2210.06726},
  year={2022}
}

@inproceedings{li2023making,
  title={Making language models better reasoners with step-aware verifier},
  author={Li, Yifei and Lin, Zeqi and Zhang, Shizhuo and Fu, Qiang and Chen, Bei and Lou, Jian-Guang and Chen, Weizhu},
  booktitle={Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={5315--5333},
  year={2023}
}

@article{liang2024improving,
  title={Improving llm reasoning through scaling inference computation with collaborative verification},
  author={Liang, Zhenwen and Liu, Ye and Niu, Tong and Zhang, Xiangliang and Zhou, Yingbo and Yavuz, Semih},
  journal={arXiv preprint arXiv:2410.05318},
  year={2024}
}

@inproceedings{liu2023grounding,
  title={Grounding complex natural language commands for temporal tasks in unseen environments},
  author={Liu, Jason Xinyu and Yang, Ziyi and Idrees, Ifrah and Liang, Sam and Schornstein, Benjamin and Tellex, Stefanie and Shah, Ankit},
  booktitle={Conference on Robot Learning},
  pages={1084--1110},
  year={2023},
  organization={PMLR}
}

@article{liu2024exploring,
  title={Exploring and evaluating hallucinations in llm-powered code generation},
  author={Liu, Fang and Liu, Yang and Shi, Lin and Huang, Houkun and Wang, Ruifeng and Yang, Zhen and Zhang, Li and Li, Zhongqi and Ma, Yuchi},
  journal={arXiv preprint arXiv:2404.00971},
  year={2024}
}

@inproceedings{liu2024speak,
  title={Speak From Heart: An Emotion-Guided LLM-Based Multimodal Method for Emotional Dialogue Generation},
  author={Liu, Chenxiao and Xie, Zheyong and Zhao, Sirui and Zhou, Jin and Xu, Tong and Li, Minglei and Chen, Enhong},
  booktitle={Proceedings of the 2024 International Conference on Multimedia Retrieval},
  pages={533--542},
  year={2024}
}

@inproceedings{liu2024we,
  title={" We Need Structured Output": Towards User-centered Constraints on Large Language Model Output},
  author={Liu, Michael Xieyang and Liu, Frederick and Fiannaca, Alexander J and Koo, Terry and Dixon, Lucas and Terry, Michael and Cai, Carrie J},
  booktitle={Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
  pages={1--9},
  year={2024}
}

@inproceedings{louie2020novice,
  title={Novice-AI music co-creation via AI-steering tools for deep generative models},
  author={Louie, Ryan and Coenen, Andy and Huang, Cheng Zhi and Terry, Michael and Cai, Carrie J},
  booktitle={Proceedings of the 2020 CHI conference on human factors in computing systems},
  pages={1--13},
  year={2020}
}

@inproceedings{lu2023plug,
 author = {Lu, Pan and Peng, Baolin and Cheng, Hao and Galley, Michel and Chang, Kai-Wei and Wu, Ying Nian and Zhu, Song-Chun and Gao, Jianfeng},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {A. Oh and T. Naumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
 pages = {43447--43478},
 publisher = {Curran Associates, Inc.},
 title = {Chameleon: Plug-and-Play Compositional Reasoning with Large Language Models},
 url = {https://proceedings.neurips.cc/paper_files/paper/2023/file/871ed095b734818cfba48db6aeb25a62-Paper-Conference.pdf},
 volume = {36},
 year = {2023}
}

@inproceedings{ma2024beyond,
  title={Beyond chatbots: Explorellm for structured thoughts and personalized model responses},
  author={Ma, Xiao and Mishra, Swaroop and Liu, Ariel and Su, Sophie Ying and Chen, Jilin and Kulkarni, Chinmay and Cheng, Heng-Tze and Le, Quoc and Chi, Ed},
  booktitle={Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
  pages={1--12},
  year={2024}
}

@article{marasovic2021few,
  title={Few-shot self-rationalization with natural language prompts},
  author={Marasovi{\'c}, Ana and Beltagy, Iz and Downey, Doug and Peters, Matthew E},
  journal={arXiv preprint arXiv:2111.08284},
  year={2021}
}

@inproceedings{mathews2019explainable,
  title={Explainable artificial intelligence applications in NLP, biomedical, and malware classification: a literature review},
  author={Mathews, Sherin Mary},
  booktitle={Intelligent Computing: Proceedings of the 2019 Computing Conference, Volume 2},
  pages={1269--1292},
  year={2019},
  organization={Springer}
}

@article{maynez2020faithfulness,
  title={On faithfulness and factuality in abstractive summarization},
  author={Maynez, Joshua and Narayan, Shashi and Bohnet, Bernd and McDonald, Ryan},
  journal={arXiv preprint arXiv:2005.00661},
  year={2020}
}

@article{minaee2024large,
  title={Large language models: A survey},
  author={Minaee, Shervin and Mikolov, Tomas and Nikzad, Narjes and Chenaghlu, Meysam and Socher, Richard and Amatriain, Xavier and Gao, Jianfeng},
  journal={arXiv preprint arXiv:2402.06196},
  year={2024}
}

@article{mirchandani2023large,
  title={Large language models as general pattern machines},
  author={Mirchandani, Suvir and Xia, Fei and Florence, Pete and Ichter, Brian and Driess, Danny and Arenas, Montserrat Gonzalez and Rao, Kanishka and Sadigh, Dorsa and Zeng, Andy},
  journal={arXiv preprint arXiv:2307.04721},
  year={2023}
}

@article{mostajabdaveh2024optimization,
  title={Optimization modeling and verification from problem specifications using a multi-agent multi-stage LLM framework},
  author={Mostajabdaveh, Mahdi and Yu, Timothy T and Ramamonjison, Rindranirina and Carenini, Giuseppe and Zhou, Zirui and Zhang, Yong},
  journal={INFOR: Information Systems and Operational Research},
  pages={1--19},
  year={2024},
  publisher={Taylor \& Francis}
}

@article{nau2021gtpyhop,
  title={GTPyhop: A hierarchical goal+ task planner implemented in Python},
  author={Nau, Dana and Bansod, Yash and Patra, Sunandita and Roberts, Mark and Li, Ruoxi},
  journal={HPlan 2021},
  pages={21}
}

@inproceedings{ni2023lever,
  title={Lever: Learning to verify language-to-code generation with execution},
  author={Ni, Ansong and Iyer, Srini and Radev, Dragomir and Stoyanov, Veselin and Yih, Wen-tau and Wang, Sida and Lin, Xi Victoria},
  booktitle={International Conference on Machine Learning},
  pages={26106--26128},
  year={2023},
  organization={PMLR}
}

@article{park2024offsetbias,
  title={Offsetbias: Leveraging debiased data for tuning evaluators},
  author={Park, Junsoo and Jwa, Seungyeon and Ren, Meiying and Kim, Daeyoung and Choi, Sanghyuk},
  journal={arXiv preprint arXiv:2407.06551},
  year={2024}
}

@inproceedings{peer2004pddl,
  title={A PDDL based tool for automatic web service composition},
  author={Peer, Joachim},
  booktitle={International Workshop on Principles and Practice of Semantic Web Reasoning},
  pages={149--163},
  year={2004},
  organization={Springer}
}

@InProceedings{pmlr-v235-kambhampati24a,
  title = 	 {Position: {LLM}s Can’t Plan, But Can Help Planning in {LLM}-Modulo Frameworks},
  author =       {Kambhampati, Subbarao and Valmeekam, Karthik and Guan, Lin and Verma, Mudit and Stechly, Kaya and Bhambri, Siddhant and Saldyt, Lucas Paul and B Murthy, Anil},
  booktitle = 	 {Proceedings of the 41st International Conference on Machine Learning},
  pages = 	 {22895--22907},
  year = 	 {2024},
  editor = 	 {Salakhutdinov, Ruslan and Kolter, Zico and Heller, Katherine and Weller, Adrian and Oliver, Nuria and Scarlett, Jonathan and Berkenkamp, Felix},
  volume = 	 {235},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {21--27 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://raw.githubusercontent.com/mlresearch/v235/main/assets/kambhampati24a/kambhampati24a.pdf},
  url = 	 {https://proceedings.mlr.press/v235/kambhampati24a.html},
  abstract = 	 {We argue that auto-regressive LLMs cannot, by themselves, do planning or self-verification (which is after all a form of reasoning), and shed some light on the reasons for misunderstandings in the literature. We will also argue that LLMs should be viewed as universal approximate knowledge sources that have much more meaningful roles to play in planning/reasoning tasks beyond simple front-end/back-end format translators. We present a vision of LLM-Modulo Frameworks that combine the strengths of LLMs with external model-based verifiers in a tighter bi-directional interaction regime. We will show how the models driving the external verifiers themselves can be acquired with the help of LLMs. We will also argue that rather than simply pipelining LLMs and symbolic components, this LLM-Modulo Framework provides a better neuro-symbolic approach that offers tighter integration between LLMs and symbolic components, and allows extending the scope of model-based planning/reasoning regimes towards more flexible knowledge, problem and preference specifications.}
}

@inproceedings{porfirio2018authoring,
  title={Authoring and verifying human-robot interactions},
  author={Porfirio, David and Saupp{\'e}, Allison and Albarghouthi, Aws and Mutlu, Bilge},
  booktitle={Proceedings of the 31st annual acm symposium on user interface software and technology},
  pages={75--86},
  year={2018}
}

@inproceedings{porfirio2020transforming,
  title={Transforming robot programs based on social context},
  author={Porfirio, David and Saupp{\'e}, Allison and Albarghouthi, Aws and Mutlu, Bilge},
  booktitle={Proceedings of the 2020 CHI conference on human factors in computing systems},
  pages={1--12},
  year={2020}
}

@inproceedings{porfirio2024polaris,
author = {Porfirio, David and Roberts, Mark and Hiatt, Laura M.},
title = {Goal-Oriented End-User Programming of Robots},
year = {2024},
isbn = {9798400703225},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3610977.3634974},
doi = {10.1145/3610977.3634974},
abstract = {End-user programming (EUP) tools must balance user control with the robot's ability to plan and act autonomously. Many existing task-oriented EUP tools enforce a specific level of control, e.g., by requiring that users hand-craft detailed sequences of actions, rather than offering users the flexibility to choose the level of task detail they wish to express. We thereby created a novel EUP system, Polaris, that in contrast to most existing EUP tools, uses goal predicates as the fundamental building block of programs. Users can thereby express high-level robot objectives or lower-level checkpoints at their choosing, while an off-the-shelf task planner fills in any remaining program detail. To ensure that goal-specified programs adhere to user expectations of robot behavior, Polaris is equipped with a Plan Visualizer that exposes the planner's output to the user before runtime. In what follows, we describe our design of Polaris and its evaluation with 32 human participants. Our results support the Plan Visualizer's ability to help users craft higher-quality programs. Furthermore, there are strong associations between user perception of the robot and Plan Visualizer usage, and evidence that robot familiarity has a key role in shaping user experience.},
booktitle = {Proceedings of the 2024 ACM/IEEE International Conference on Human-Robot Interaction},
pages = {582–591},
numpages = {10},
keywords = {end-user programming, human-robot interaction, task planning},
location = {Boulder, CO, USA},
series = {HRI '24}
}

@article{rawte2023survey,
  title={A survey of hallucination in large foundation models},
  author={Rawte, Vipula and Sheth, Amit and Das, Amitava},
  journal={arXiv preprint arXiv:2309.05922},
  year={2023}
}

@inproceedings{sallam2023chatgpt,
  title={ChatGPT utility in healthcare education, research, and practice: systematic review on the promising perspectives and valid concerns},
  author={Sallam, Malik},
  booktitle={Healthcare},
  volume={11},
  number={6},
  pages={887},
  year={2023},
  organization={MDPI}
}

@article{sarkar2022like,
  title={What is it like to program with artificial intelligence?},
  author={Sarkar, Advait and Gordon, Andrew D and Negreanu, Carina and Poelitz, Christian and Ragavan, Sruti Srinivasa and Zorn, Ben},
  journal={arXiv preprint arXiv:2208.06213},
  year={2022}
}

@inproceedings{sauer2022structure,
  title={Structure synthesis for extended robot state automata},
  author={Sauer, Lukas and Henrich, Dominik},
  booktitle={International Conference on Robotics in Alpe-Adria Danube Region},
  pages={71--79},
  year={2022},
  organization={Springer}
}

@article{schellaert2023your,
  title={Your prompt is my command: on assessing the human-centred generality of multimodal models},
  author={Schellaert, Wout and Mart{\'\i}nez-Plumed, Fernando and Vold, Karina and Burden, John and Casares, Pablo AM and Loe, Bao Sheng and Reichart, Roi and Korhonen, Anna and Hern{\'a}ndez-Orallo, Jos{\'e} and others},
  journal={Journal of Artificial Intelligence Research},
  volume={77},
  pages={377--394},
  year={2023}
}

@inproceedings{schoen2020authr,
  title={Authr: A task authoring environment for human-robot teams},
  author={Schoen, Andrew and Henrichs, Curt and Strohkirch, Mathias and Mutlu, Bilge},
  booktitle={Proceedings of the 33rd annual acm symposium on user interface software and technology},
  pages={1194--1208},
  year={2020}
}

@article{shah2013knowledge,
  title={Knowledge engineering tools in planning: State-of-the-art and future challenges},
  author={Shah, M and Chrpa, Luk{\'a}s and Jimoh, Falilat and Kitchin, D and McCluskey, T and Parkinson, Simon and Vallati, Mauro},
  journal={Knowledge engineering for planning and scheduling},
  volume={53},
  pages={53},
  year={2013}
}

@inproceedings{shankar2024validates,
  title={Who validates the validators? aligning llm-assisted evaluation of llm outputs with human preferences},
  author={Shankar, Shreya and Zamfirescu-Pereira, JD and Hartmann, Bj{\"o}rn and Parameswaran, Aditya and Arawjo, Ian},
  booktitle={Proceedings of the 37th Annual ACM Symposium on User Interface Software and Technology},
  pages={1--14},
  year={2024}
}

@article{silverLLM2024, 
  title={Generalized Planning in PDDL Domains with Pretrained Large Language Models}, volume={38}, url={https://ojs.aaai.org/index.php/AAAI/article/view/30006}, DOI={10.1609/aaai.v38i18.30006}, abstractNote={Recent work has considered whether large language models (LLMs) can function as planners: given a task, generate a plan. We investigate whether LLMs can serve as generalized planners: given a domain and training tasks, generate a program that efficiently produces plans for other tasks in the domain. In particular, we consider PDDL domains and use GPT-4 to synthesize Python programs. We also consider (1) Chain-of-Thought (CoT) summarization, where the LLM is prompted to summarize the domain and propose a strategy in words before synthesizing the program; and (2) automated debugging, where the program is validated with respect to the training tasks, and in case of errors, the LLM is re-prompted with four types of feedback. We evaluate this approach in seven PDDL domains and compare it to four ablations and four baselines. Overall, we find that GPT-4 is a surprisingly powerful generalized planner. We also conclude that automated debugging is very important, that CoT summarization has non-uniform impact, that GPT-4 is far superior to GPT-3.5, and that just two training tasks are often sufficient for strong generalization.}, number={18}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Silver, Tom and Dan, Soham and Srinivas, Kavitha and Tenenbaum, Joshua B. and Kaelbling, Leslie and Katz, Michael}, year={2024}, month={Mar.}, pages={20256-20264} }

@article{son2024llm,
  title={Llm-as-a-judge \& reward model: What they can and cannot do},
  author={Son, Guijin and Ko, Hyunwoo and Lee, Hoyoung and Kim, Yewon and Hong, Seunghyeok},
  journal={arXiv preprint arXiv:2409.11239},
  year={2024}
}

@INPROCEEDINGS{songLLMPlan2023,
  author={Song, Chan Hee and Sadler, Brian M. and Wu, Jiaman and Chao, Wei-Lun and Washington, Clayton and Su, Yu},
  booktitle={2023 IEEE/CVF International Conference on Computer Vision (ICCV)}, 
  title={LLM-Planner: Few-Shot Grounded Planning for Embodied Agents with Large Language Models}, 
  year={2023},
  volume={},
  number={},
  pages={2986-2997},
  keywords={Computer vision;Costs;Grounding;Annotations;Computational modeling;Natural languages;Training data},
  doi={10.1109/ICCV51070.2023.00280}}

@inproceedings{subramonyam2024bridging,
  title={Bridging the Gulf of Envisioning: Cognitive Challenges in Prompt Based Interactions with LLMs},
  author={Subramonyam, Hari and Pea, Roy and Pondoc, Christopher and Agrawala, Maneesh and Seifert, Colleen},
  booktitle={Proceedings of the CHI Conference on Human Factors in Computing Systems},
  pages={1--19},
  year={2024}
}

@inproceedings{suh2023sensecape,
  title={Sensecape: Enabling multilevel exploration and sensemaking with large language models},
  author={Suh, Sangho and Min, Bryan and Palani, Srishti and Xia, Haijun},
  booktitle={Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
  pages={1--18},
  year={2023}
}

@inproceedings{sun2022investigating,
  title={Investigating explainability of generative AI for code through scenario-based design},
  author={Sun, Jiao and Liao, Q Vera and Muller, Michael and Agarwal, Mayank and Houde, Stephanie and Talamadupula, Kartik and Weisz, Justin D},
  booktitle={Proceedings of the 27th International Conference on Intelligent User Interfaces},
  pages={212--228},
  year={2022}
}

@inproceedings{tankelevitch2024metacognitive,
  title={The metacognitive demands and opportunities of generative AI},
  author={Tankelevitch, Lev and Kewenig, Viktor and Simkute, Auste and Scott, Ava Elizabeth and Sarkar, Advait and Sellen, Abigail and Rintel, Sean},
  booktitle={Proceedings of the CHI Conference on Human Factors in Computing Systems},
  pages={1--24},
  year={2024}
}

@article{teufelberger2024llm,
  title={LLM-for-X: Application-agnostic Integration of Large Language Models to Support Personal Writing Workflows},
  author={Teufelberger, Lukas and Liu, Xintong and Li, Zhipeng and Moebus, Max and Holz, Christian},
  journal={arXiv preprint arXiv:2407.21593},
  year={2024}
}

@article{turpin2024language,
  title={Language models don't always say what they think: unfaithful explanations in chain-of-thought prompting},
  author={Turpin, Miles and Michael, Julian and Perez, Ethan and Bowman, Samuel},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{valmeekam2022large,
  title={Large language models still can't plan (a benchmark for LLMs on planning and reasoning about change)},
  author={Valmeekam, Karthik and Olmo, Alberto and Sreedharan, Sarath and Kambhampati, Subbarao},
  booktitle={NeurIPS 2022 Foundation Models for Decision Making Workshop},
  year={2022}
}

@article{valmeekam2023planning,
  title={On the planning abilities of large language models-a critical investigation},
  author={Valmeekam, Karthik and Marquez, Matthew and Sreedharan, Sarath and Kambhampati, Subbarao},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={75993--76005},
  year={2023}
}

@article{vasconcelos2023generation,
  title={Generation probabilities are not enough: Exploring the effectiveness of uncertainty highlighting in AI-powered code completions},
  author={Vasconcelos, Helena and Bansal, Gagan and Fourney, Adam and Liao, Q Vera and Vaughan, Jennifer Wortman},
  journal={arXiv preprint arXiv:2302.07248},
  year={2023}
}

@article{wang2023large,
  title={Large language models are not fair evaluators},
  author={Wang, Peiyi and Li, Lei and Chen, Liang and Cai, Zefan and Zhu, Dawei and Lin, Binghuai and Cao, Yunbo and Liu, Qi and Liu, Tianyu and Sui, Zhifang},
  journal={arXiv preprint arXiv:2305.17926},
  year={2023}
}

@inproceedings{wang2024LLM,
author = {Wang, Xinru and Kim, Hannah and Rahman, Sajjadur and Mitra, Kushan and Miao, Zhengjie},
title = {Human-LLM Collaborative Annotation Through Effective Verification of LLM Labels},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3641960},
doi = {10.1145/3613904.3641960},
abstract = {Large language models (LLMs) have shown remarkable performance across various natural language processing (NLP) tasks, indicating their significant potential as data annotators. Although LLM-generated annotations are more cost-effective and efficient to obtain, they are often erroneous for complex or domain-specific tasks and may introduce bias when compared to human annotations. Therefore, instead of completely replacing human annotators with LLMs, we need to leverage the strengths of both LLMs and humans to ensure the accuracy and reliability of annotations. This paper presents a multi-step human-LLM collaborative approach where (1) LLMs generate labels and provide explanations, (2) a verifier assesses the quality of LLM-generated labels, and (3) human annotators re-annotate a subset of labels with lower verification scores. To facilitate human-LLM collaboration, we make use of LLM’s ability to rationalize its decisions. LLM-generated explanations can provide additional information to the verifier model as well as help humans better understand LLM labels. We demonstrate that our verifier is able to identify potentially incorrect LLM labels for human re-annotation. Furthermore, we investigate the impact of presenting LLM labels and explanations on human re-annotation through crowdsourced studies.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {303},
numpages = {21},
keywords = {Human-LLM collaborative annotation, LLM annotation, NLP, self-rationalization, text annotation},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{wang2024human,
  title={Human-LLM collaborative annotation through effective verification of LLM labels},
  author={Wang, Xinru and Kim, Hannah and Rahman, Sajjadur and Mitra, Kushan and Miao, Zhengjie},
  booktitle={Proceedings of the CHI Conference on Human Factors in Computing Systems},
  pages={1--21},
  year={2024}
}

@article{wiegreffe2021reframing,
  title={Reframing human-AI collaboration for generating free-text explanations},
  author={Wiegreffe, Sarah and Hessel, Jack and Swayamdipta, Swabha and Riedl, Mark and Choi, Yejin},
  journal={arXiv preprint arXiv:2112.08674},
  year={2021}
}

@inproceedings{wu2024mathchat,
  title={MathChat: Converse to Tackle Challenging Math Problems with LLM Agents},
  author={Wu, Yiran and Jia, Feiran and Zhang, Shaokun and Li, Hangyu and Zhu, Erkang and Wang, Yue and Lee, Yin Tat and Peng, Richard and Wu, Qingyun and Wang, Chi},
  booktitle={ICLR 2024 Workshop on Large Language Model (LLM) Agents},
  year={2024}
}

@inproceedings{xiao2024human,
  title={Human-Centered Evaluation and Auditing of Language Models},
  author={Xiao, Ziang and Deng, Wesley Hanwen and Lam, Michelle S and Eslami, Motahhare and Kim, Juho and Lee, Mina and Liao, Q Vera},
  booktitle={Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
  pages={1--6},
  year={2024}
}

@article{xie2024travelplanner,
  title={Travelplanner: A benchmark for real-world planning with language agents},
  author={Xie, Jian and Zhang, Kai and Chen, Jiangjie and Zhu, Tinghui and Lou, Renze and Tian, Yuandong and Xiao, Yanghua and Su, Yu},
  journal={arXiv preprint arXiv:2402.01622},
  year={2024}
}

@article{yang2024harnessing,
  title={Harnessing the power of llms in practice: A survey on chatgpt and beyond},
  author={Yang, Jingfeng and Jin, Hongye and Tang, Ruixiang and Han, Xiaotian and Feng, Qizhang and Jiang, Haoming and Zhong, Shaochen and Yin, Bing and Hu, Xia},
  journal={ACM Transactions on Knowledge Discovery from Data},
  volume={18},
  number={6},
  pages={1--32},
  year={2024},
  publisher={ACM New York, NY}
}

@inproceedings{yang2024plug,
  title={Plug in the safety chip: Enforcing constraints for llm-driven robot agents},
  author={Yang, Ziyi and Raman, Shreyas S and Shah, Ankit and Tellex, Stefanie},
  booktitle={2024 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={14435--14442},
  year={2024},
  organization={IEEE}
}

@article{yao2023llm,
  title={Llm lies: Hallucinations are not bugs, but features as adversarial examples},
  author={Yao, Jia-Yu and Ning, Kun-Peng and Liu, Zhen-Hui and Ning, Mu-Nan and Liu, Yu-Yang and Yuan, Li},
  journal={arXiv preprint arXiv:2310.01469},
  year={2023}
}

@inproceedings{zamfirescu2023johnny,
  title={Why Johnny can’t prompt: how non-AI experts try (and fail) to design LLM prompts},
  author={Zamfirescu-Pereira, JD and Wong, Richmond Y and Hartmann, Bjoern and Yang, Qian},
  booktitle={Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
  pages={1--21},
  year={2023}
}

@inproceedings{zhang2023visar,
  title={Visar: A human-ai argumentative writing assistant with visual programming and rapid draft prototyping},
  author={Zhang, Zheng and Gao, Jie and Dhaliwal, Ranjodh Singh and Li, Toby Jia-Jun},
  booktitle={Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
  pages={1--30},
  year={2023}
}

@article{zhang2023wider,
  title={Wider and deeper llm networks are fairer llm evaluators},
  author={Zhang, Xinghua and Yu, Bowen and Yu, Haiyang and Lv, Yangyu and Liu, Tingwen and Huang, Fei and Xu, Hongbo and Li, Yongbin},
  journal={arXiv preprint arXiv:2308.01862},
  year={2023}
}

@article{zhang2024cfbench,
  title={Cfbench: A comprehensive constraints-following benchmark for llms},
  author={Zhang, Tao and Shen, Yanjun and Luo, Wenjing and Zhang, Yan and Liang, Hao and Yang, Fan and Lin, Mingan and Qiao, Yujing and Chen, Weipeng and Cui, Bin and others},
  journal={arXiv preprint arXiv:2408.01122},
  year={2024}
}

@inproceedings{zhang2025mathverse,
  title={Mathverse: Does your multi-modal llm truly see the diagrams in visual math problems?},
  author={Zhang, Renrui and Jiang, Dongzhi and Zhang, Yichi and Lin, Haokun and Guo, Ziyu and Qiu, Pengshuo and Zhou, Aojun and Lu, Pan and Chang, Kai-Wei and Qiao, Yu and others},
  booktitle={European Conference on Computer Vision},
  pages={169--186},
  year={2025},
  organization={Springer}
}

@article{zhao2023survey,
  title={A survey of large language models},
  author={Zhao, Wayne Xin and Zhou, Kun and Li, Junyi and Tang, Tianyi and Wang, Xiaolei and Hou, Yupeng and Min, Yingqian and Zhang, Beichen and Zhang, Junjie and Dong, Zican and others},
  journal={arXiv preprint arXiv:2303.18223},
  year={2023}
}

@article{zhao2024explainability,
  title={Explainability for large language models: A survey},
  author={Zhao, Haiyan and Chen, Hanjie and Yang, Fan and Liu, Ninghao and Deng, Huiqi and Cai, Hengyi and Wang, Shuaiqiang and Yin, Dawei and Du, Mengnan},
  journal={ACM Transactions on Intelligent Systems and Technology},
  volume={15},
  number={2},
  pages={1--38},
  year={2024},
  publisher={ACM New York, NY}
}

@article{zheng2024judging,
  title={Judging llm-as-a-judge with mt-bench and chatbot arena},
  author={Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

