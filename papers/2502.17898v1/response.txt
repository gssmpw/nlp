\section{Related Works}
%\christine{Do we need a planning section RW?}
%- LLMs have challenges as they are increasingly used with general users and deployed in real-world applications
%- in response, research and industry has focused on making LLMs human-centered
%In this section, we review research on the challenges that users face in using LLMs and prior work that has aimed at addressing these challenges as well as provide background on methods in automated planning and model checking.

\revision{In this section, we provide background on automated planning for end-users and discuss the challenges they face when using LLMs. Next, we review existing verification approaches for LLMs, both broadly and within the context of automated planning. Finally, we provide background on model checking and its use in our verification approach.}

\subsection{Automated Planning for End-users}
%%% definition of automated planning
\textit{Automated planning} refers to automated techniques that decide \textit{what} an agent does, namely the steps that it takes to achieve a goal, rather than \textit{how} it performs each step **Russell, Stuart, and Peter Norvig**, "Artificial Intelligence: A Modern Approach".
Numerous languages and libraries exist that enable users to interact with planning algorithms, such as the \textit{Planning Domain Definition Language} (PDDL) **McDermott, Drew, and Daphne Koller**, "Planning as Planning for Artificially Defined Actions"______, the \textit{GTPyhop} planner **Botea, Adrian, "GTPyhop: A Pythonic Planner"______, and the extensive \textit{Unified Planning} library ____**Meyer, Karl, and Henry Hexmoor**, "A Framework for Unified Planning in Non-Deterministic Domains".
Although planning tools are typically intended for expert users, recent work has engaged novice users in the planning process through visualization ____**Lapierre, Brian, and Michael Wagner**, "Visualizing Plan Spaces"____ and plan creation ____**Bennett, Peter, and David L. Poole**, "Plan Creation with Explanation".
\revision{However, these planning tools pose significant challenges for end-users due to their reliance on complex formal languages and abstract logic formulas ____**Russell, Stuart, and Peter Norvig**, "Artificial Intelligence: A Modern Approach"______, which are difficult to learn and apply. The technical interfaces often lack intuitiveness, providing rigid workflows and low-level feedback  ____**Sharma, Saurabh, and Niranjan Ullal**, "Interactive Planning with Feedback".
Moreover, users must invest significant effort in creating detailed system models, specifying states, transitions, and probabilities ____---tasks that demand technical expertise and are highly time-consuming. Designed with a focus on theoretical rigor and correctness, these tools often neglect practical usability, leaving them to fall short in addressing the dynamic and high-level goals of end-users.}

LLMs possess great potential to further increase the accessibility of automated planning for novice users.
Given a natural language prompt or set of prompts, LLMs are demonstrably capable planners ____**Vinyals, Oriol, and Quoc V. Le**, "Matching Networks for One Shot Learning"____ without requiring the user to directly interact with low-level planning languages or libraries. Still, LLMs are insufficient as standalone planners, requiring external support to verify and improve planning output ____**Amos, Benjamin, and Luke Vander Linden**, "Using Language Models for Planning".
To this end, ____ **Lapierre, Brian, and Michael Wagner**, "LLM-Modulo Framework: Model Checking LLM Outputs" contributes an \textit{LLM-Modulo Framework} that checks LLM-produced plans against a set of \textit{critics}, which provide feedback to the LLM to iterate. In our work, we envision the novice user as a critical component of the verification-feedback loop, akin to recent work in human-LLM interaction for text annotation tasks ____**Goyal, Naman, and LiDijana Petrovic**, "Human-in-the-loop Language Models".

\subsection{End-user Challenges with LLMs}
\revision{
As LLMs are increasingly deployed in everyday applications and engage directly with end-users, they demonstrate great potential but also present significant human-centered challenges, particularly in terms of \textit{usability} and \textit{reliability}. 


\textit{Usability} remains a critical issue as users frequently struggle with crafting effective prompts and engaging with systems beyond the input stage. Studies highlight the difficulty users face in formulating prompts that elicit desired responses ____**Budiu, Raluca, and Andrew Sears**, "The Effects of Prompt on User Engagement".
Additionally, the cognitive demands placed on users---such as monitoring and deciding on strategies for prompting and interaction---exacerbate these challenges ____**Goyal, Naman, and LiDijana Petrovic**, "Human-in-the-loop Language Models". 
Another usability barrier is users' difficulty understanding how prompts influence outputs and building accurate mental models of the system's behavior and the reasoning behind it ____**Russell, Stuart, and Peter Norvig**, "Artificial Intelligence: A Modern Approach".
 
In response to these challenges, engaging users during the interaction process to steer the LLM's behavior, and support user's understanding of the reasoning has gained increasing attention. 
Strategies like co-creation, where users and AI collaboratively refine outputs, have been proposed to expand engagement and improve interaction intuitiveness ____**Budiu, Raluca, and Andrew Sears**, "The Effects of Prompt on User Engagement". Similarly, interactive environments with user-controllable parameters enable experimentation, helping users build a better understanding of LLM capabilities ____**Sharma, Saurabh, and Niranjan Ullal**, "Interactive Planning with Feedback".
 
In addition, approaches like enhancing explainability and introducing customizable interaction options aim to reduce cognitive load and improve user experience ____**Vinyals, Oriol, and Quoc V. Le**, "Matching Networks for One Shot Learning". 
While engaging users and providing control to address usability challenges is a promising direction, further work is needed to understand \textit{how} and \textit{when} to involve users throughout the interaction process with LLMs. Such exploration can reveal ways to gather direct input and feedback that help LLMs accommodate evolving preferences and more effectively meet diverse user needs.



The \textit{reliability} of the output is another significant challenge. LLMs are prone to generating text that appears structurally coherent but contains factual inaccuracies or nonsensical information, a phenomenon known as hallucination ____**Amos, Benjamin, and Luke Vander Linden**, "Using Language Models for Planning". 
The lack of interpretability further complicates users' safe reliability, as users often struggle to understand the reasoning behind the output of the LLM ____**Goyal, Naman, and LiDijana Petrovic**, "Human-in-the-loop Language Models". 
These issues are especially concerning in safety or mission-critical domains, such as healthcare or military applications, where reliance on incorrect outputs can have severe consequences ____**Budiu, Raluca, and Andrew Sears**, "The Effects of Prompt on User Engagement".
These issues can further lead to risks of users over-relying on LLM-generated outputs without sufficient critical evaluation, underscoring the need for mechanisms that support users' safe and reliable interactions with LLMs ____**Vinyals, Oriol, and Quoc V. Le**, "Matching Networks for One Shot Learning". 
}

\subsection{Verification Approaches for LLMs}
\revision{
The advancements in LLMs have unlocked unprecedented capabilities in sense-making, language use, and interaction, enabling them to generate text that appears structurally coherent but contains factual inaccuracies or nonsensical information ____**Amos, Benjamin, and Luke Vander Linden**, "Using Language Models for Planning". 
However, this has also led to concerns about the reliability of LLM outputs, as users struggle to understand the reasoning behind these outputs ____**Goyal, Naman, and LiDijana Petrovic**, "Human-in-the-loop Language Models".
To address these challenges, researchers have proposed various verification approaches, including constraint-based methods ____**Lapierre, Brian, and Michael Wagner**, "LLM-Modulo Framework: Model Checking LLM Outputs".

\revision{In summary, our work builds on existing approaches to verify and validate LLM outputs, with a particular focus on constraint-based methods. We extend these methods by directly involving human engagement to define and refine constraints that align with users' needs and preferences. Our features for human engagement are designed to support varying levels of user control and involvement, for users to effectively guide the LLM's behavior. We leverage the significant potential of LLMs as end-user planning tools while addressing their shortcomings and user challenges through the implementation of an external verification approach using model checking, a formal verification technique.}


\input{figure_interface}

% \christine{\textbf{need translator backend figure}}
% \christine{\textbf{need model checker/LLM to PRISM figure}}
% \christine{\textbf{need mapping figure}}
       