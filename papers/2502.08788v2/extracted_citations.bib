@article{chen2024IoA,
  publtype={informal},
  author={Weize Chen and Ziming You and Ran Li and Yitong Guan and Chen Qian and Chenyang Zhao and Cheng Yang and Ruobing Xie and Zhiyuan Liu and Maosong Sun},
  title={Internet of Agents: Weaving a Web of Heterogeneous Agents for Collaborative Intelligence},
  year={2024},
  cdate={1704067200000},
  journal={CoRR},
  volume={abs/2407.07061},
  url={https://doi.org/10.48550/arXiv.2407.07061}
}

@inproceedings{chen2024comm,
  title={CoMM: Collaborative Multi-Agent, Multi-Reasoning-Path Prompting for Complex Problem Solving},
  author={Chen, Pei and Zhang, Shuai and Han, Boran},
  booktitle={Findings of the Association for Computational Linguistics: NAACL 2024},
  pages={1720--1738},
  year={2024}
}

@inproceedings{chen2024reconcile,
    title = "{R}e{C}oncile: Round-Table Conference Improves Reasoning via Consensus among Diverse {LLM}s",
    author = "Chen, Justin  and
      Saha, Swarnadeep  and
      Bansal, Mohit",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.381",
    doi = "10.18653/v1/2024.acl-long.381",
    pages = "7066--7085",
    abstract = "Large Language Models (LLMs) still struggle with natural language reasoning tasks. Motivated by the society of minds (Minsky, 1988), we propose ReConcile, a multi-model multi-agent framework designed as a round table conference among diverse LLM agents. ReConcile enhances collaborative reasoning between LLM agents via multiple rounds of discussion, learning to convince other agents to improve their answers, and employing a confidence-weighted voting mechanism that leads to a better consensus. In each round, ReConcile initiates discussion between agents via a {`}discussion prompt{'} that consists of (a) grouped answers and explanations generated by each agent in the previous round, (b) their confidence scores, and (c) demonstrations of answer-rectifying human explanations, used for convincing other agents. Experiments on seven benchmarks demonstrate that ReConcile significantly improves LLMs{'} reasoning {--} both individually and as a team {--} surpassing prior single-agent and multi-agent baselines by up to 11.4{\%} and even outperforming GPT-4 on three datasets. ReConcile also flexibly incorporates different combinations of agents, including API-based, open-source, and domain-specific models, leading to an 8{\%} improvement on MATH. Finally, we analyze the individual components of ReConcile, demonstrating that the diversity originating from different models is critical to its superior performance.",
}

@inproceedings{duimproving,
  title={Improving Factuality and Reasoning in Language Models through Multiagent Debate},
  author={Du, Yilun and Li, Shuang and Torralba, Antonio and Tenenbaum, Joshua B and Mordatch, Igor},
  booktitle={Forty-first International Conference on Machine Learning},
  year="2023"
}

@inproceedings{khan2024debating,
  author={Akbir Khan and John Hughes and Dan Valentine and Laura Ruis and Kshitij Sachan and Ansh Radhakrishnan and Edward Grefenstette and Samuel R. Bowman and Tim Rockt√§schel and Ethan Perez},
  title={Debating with More Persuasive LLMs Leads to More Truthful Answers},
  year={2024},
  cdate={1704067200000},
  url={https://openreview.net/forum?id=iLCZtl7FTa},
  booktitle={ICML}
}

@inproceedings{li2024Sparse,
    title = "Improving Multi-Agent Debate with Sparse Communication Topology",
    author = "Li, Yunxuan  and
      Du, Yibing  and
      Zhang, Jiageng  and
      Hou, Le  and
      Grabowski, Peter  and
      Li, Yeqing  and
      Ie, Eugene",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2024",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-emnlp.427",
    doi = "10.18653/v1/2024.findings-emnlp.427",
    pages = "7281--7294",
    abstract = "Multi-agent debate has proven effective in improving large language models quality for reasoning and factuality tasks. While various role-playing strategies in multi-agent debates have been explored, in terms of the communication among agents, existing approaches adopt a brute force algorithm {--} each agent can communicate with all other agents. In this paper, we systematically investigate the effect of communication connectivity in multi-agent systems. Our experiments on GPT and Mistral models reveal that multi-agent debates leveraging sparse communication topology can achieve comparable or superior performance while significantly reducing computational costs. Furthermore, we extend the multi-agent debate framework to multi-modal reasoning and alignment labeling tasks, showcasing its broad applicability and effectiveness. Our findings underscore the importance of communication connectivity on enhancing the efficiency and effectiveness of the {``}society of minds{''} approach.",
}

@inproceedings{liang2023encouraging,
    title = "Encouraging Divergent Thinking in Large Language Models through Multi-Agent Debate",
    author = "Liang, Tian  and
      He, Zhiwei  and
      Jiao, Wenxiang  and
      Wang, Xing  and
      Wang, Yan  and
      Wang, Rui  and
      Yang, Yujiu  and
      Shi, Shuming  and
      Tu, Zhaopeng",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.emnlp-main.992/",
    doi = "10.18653/v1/2024.emnlp-main.992",
    pages = "17889--17904",
}

@article{pham2023let,
  title={Let models speak ciphers: Multiagent debate through embeddings},
  author={Pham, Chau and Liu, Boyi and Yang, Yingxiang and Chen, Zhengyu and Liu, Tianyi and Yuan, Jianbo and Plummer, Bryan A and Wang, Zhaoran and Yang, Hongxia},
  journal={arXiv preprint arXiv:2310.06272},
  year={2023}
}

@article{qian2024scaling,
  title={Scaling Large-Language-Model-based Multi-Agent Collaboration},
  author={Qian, Chen and Xie, Zihao and Wang, Yifei and Liu, Wei and Dang, Yufan and Du, Zhuoyun and Chen, Weize and Yang, Cheng and Liu, Zhiyuan and Sun, Maosong},
  journal={arXiv preprint arXiv:2406.07155},
  year={2024}
}

@inproceedings{smit2023we,
  title={Should we be going MAD? A Look at Multi-Agent Debate Strategies for LLMs},
  author={Smit, Andries Petrus and Grinsztajn, Nathan and Duckworth, Paul and Barrett, Thomas D and Pretorius, Arnu},
  booktitle={Forty-first International Conference on Machine Learning},
  year=2024
}

@article{wang2024rethinking,
  title={Rethinking the Bounds of LLM Reasoning: Are Multi-Agent Discussions the Key?},
  author={Wang, Qineng and Wang, Zihao and Su, Ying and Tong, Hanghang and Song, Yangqiu},
  journal={arXiv preprint arXiv:2402.18272},
  year={2024}
}

@inproceedings{xiong-FORD,
    title = "Examining Inter-Consistency of Large Language Models Collaboration: An In-depth Analysis via Debate",
    author = "Xiong, Kai  and
      Ding, Xiao  and
      Cao, Yixin  and
      Liu, Ting  and
      Qin, Bing",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-emnlp.508",
    doi = "10.18653/v1/2023.findings-emnlp.508",
    pages = "7572--7590",
    abstract = "Large Language Models (LLMs) have shown impressive capabilities in various applications, but they still face various inconsistency issues. Existing works primarily focus on the inconsistency issues within a single LLM, while we complementarily explore the inter-consistency among multiple LLMs for collaboration. To examine whether LLMs can collaborate effectively to achieve a consensus for a shared goal, we focus on commonsense reasoning, and introduce a formal debate framework (FORD) to conduct a three-stage debate among LLMs with real-world scenarios alignment: fair debate, mismatched debate, and roundtable debate. Through extensive experiments on various datasets, LLMs can effectively collaborate to reach a consensus despite noticeable inter-inconsistencies, but imbalances in their abilities can lead to domination by superior LLMs. Leveraging a more advanced LLM like GPT-4 as an authoritative judge can boost collaboration performance. Our work contributes to understanding the inter-consistency among LLMs and lays the foundation for developing future collaboration methods. Codes and data are available at https://github.com/Waste-Wood/FORD.",
}

@inproceedings{yin2023exchange,
  title={Exchange-of-Thought: Enhancing Large Language Model Capabilities through Cross-Model Communication},
  author={Yin, Zhangyue and Sun, Qiushi and Chang, Cheng and Guo, Qipeng and Dai, Junqi and Huang, Xuanjing and Qiu, Xipeng},
  booktitle={The 2023 Conference on Empirical Methods in Natural Language Processing},
  year={2023}
}

@inproceedings{zhang2023exploring,
title={Exploring Collaboration Mechanisms for {LLM} Agents: A Social Psychology View},
author={Jintian Zhang and Xin Xu and Ningyu Zhang and Ruibo Liu and Bryan Hooi and Shumin Deng},
booktitle={ICLR 2024 Workshop on Large Language Model (LLM) Agents},
year={2024},
url={https://openreview.net/forum?id=7hjIA8xAOD}
}

