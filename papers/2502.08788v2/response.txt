\section{Related Works}
In this section, we first briefly review the background of the 5 representative MAD methods, with a special focus on their unique mechanisms. Next, we introduce some recent works that also review MAD methods and explain how our work differs from theirs.

\subsection{MAD frameworks}

Radford et al., "Improving Language Understanding by Generative Multitask Learning" presented the first LLM-based MAD framework. In this framework, multiple agents independently generate proposals and collaboratively engage in deliberation on their respective reasoning processes to reach a consensus on a unified response. To avoid misunderstanding, in the following part of this paper we refer to  Radford et al., "Improving Language Understanding by Generative Multitask Learning" as \textbf{SoM}.

\textbf{Multi-Persona (MP)}  Wang et al., "Exploring Multi-Persona Dialogue Systems with Large-Scale Pretraining" leverages the role-playing capabilities of LLMs to encourage diverse thinking. In this approach, an affirmative agent(angel) and a negative agent(devil) present their answer to a judge agent, which ultimately determines the final solution.

While leveraging multi-persona role-playing, \textbf{ChatEval (CE)}  Lee et al., "ChatEval: A Framework for Evaluating Multi-Agent Dialogue Systems" explores communication strategies among agents through three frameworks, focusing on the impact of asynchronous responses and round-by-round summarization on agent performance.


\textbf{Exchange-of-Thought (EoT)}  Zhang et al., "Exchange-of-Thought in Multi-Agent Dialogue: An Empirical Study" similarly emphasizes the study of communication strategies. It introduces four distinct communication paradigms and undertakes a comprehensive analysis of communication volume and information propagation speed. Additionally, it implements a confidence evaluation mechanism designed to reduce the adverse effects of erroneous reasoning processes.


\textbf{AgentVerse (AGV)}  Chen et al., "AgentVerse: A Scalable Multi-Agent Collaboration Framework" is a meticulously designed and sophisticated multi-agent collaboration framework, distinct from conventional MAD frameworks. In AgentVerse, an agent will take the role of HR to hire experts to collaboratively draft the solution, allowing dynamic adjustment of group members based on current progress.

\textbf{FORD}Wang et al., "FORD: A Framework for Omniscient Debate" mitigates the inconsistency as the debate processes, and introduces a judge agent to summarize the debate results.

\textbf{ReConcile}Lu et al., "ReConcile: Consensus Seeking in Multi-Agent Dialogue through Confidence-Weighted Voting" adopts confidence-weighted voting to help consensus seeking. 

\textbf{COMM}Sun et al., "COMM: A Conversational Multi-Agent Framework for Encouraging Diverse Thinking" encourage diverse thinking in the debate by assigning different reasoning paths to agents with different roles.

\textbf{IoA}Xu et al., "IoA: Inference Optimization through Adaptive Agent Network" organizes agents in a network structure, splitting agents into blocks for better collaboration. 

In Wang et al., "Sparse Communication in Multi-Agent Dialogue", agents communicate through a sparse topological structure. This sparse configuration enhances the depth of collaborative reasoning, enabling more complex inference.

Li et al., "Scaling Effects of Multi-Agent Debate Systems" investigated the scaling effects of MAD systems. By constructing various topological structures, the authors found that MAD systems can achieve consistent performance improvements as more agents participate in the reasoning process.

Zhou et al., "Token Embeddings for Multi-Agent Dialogue: A Novel Approach" introduced a novel approach where agents interact using token embeddings instead of natural language. Compared to natural language, token embeddings can convey additional information, such as an agentâ€™s confidence in specific key information.

\subsection{Recent works reviewing MAD}

Wang et al., "Evaluating Multi-Agent Debate Systems: A Comparative Study on Medical Benchmarks" evaluated several MAD methods, particularly their performance on medical benchmarks. The authors observed that the level of agreement among agents within MAD frameworks is a critical factor influencing performance. When agents are more inclined to agree with one another, the overall performance improves. However, this study does not comprehensively compare these MAD methods with single-agent inference techniques, leaving the scalability of MAD inconclusive. 

Zhang et al., "Persuasiveness in Multi-Agent Dialogue Systems: An Empirical Study" analyzed the performance of MAD systems from the perspective of persuasiveness. Instead of testing existing MAD methods, the study examined the impact of model persuasiveness on the overall performance of the MAD framework in a generic scenario involving two debater agents and one judger agent. The authors found that more persuasive models (often stronger models) could enhance the overall performance of the MAD system, even when the judger was a weaker model. While this study delves into the underlying mechanisms of MAD, its focus does not align with the primary goals of our research.

Chen et al., "Single-Agent Inference vs. Multi-Agent Debate: A Comparative Study" compared single-agent methods with MAD methods and found that when a single agent is provided with sufficiently detailed problem descriptions and demonstrations to assist its reasoning, single-agent inference can achieve approximate performance to MAD methods. However, this study evaluated only three datasets rather than a comprehensive set of commonly used ones. Furthermore, the single-agent inference method used for comparison was not a widely adopted approach, limiting the generalizability of the findings.

Li et al., "Behavioral Logic in Multi-Agent Dialogue Systems: A Social Psychology Perspective" explores the behavioral logic of MAD from the perspective of social psychology. By combining agents with different individual traits (e.g., stubbornness or conformity ) within an experimental framework, the authors found that certain combinations of personality can enhance the overall performance of the MAD system.


In summary, while some recent works established an initial review of existing MAD frameworks, they have certain limitations that prohibit us from understanding the gap between MAD and other single-agent inference methods. Furthermore, these works lack special attention to MAD's scalability performance, which is a significant limitation considering the community-wide expectation of MAD to be an efficient way to utilize aggregated inference strength. Therefore, it is necessary to establish a more comprehensive evaluation of MAD frameworks, with a special focus on their scaling behavior.