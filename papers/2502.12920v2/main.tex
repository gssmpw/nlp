%%%%%%%% ICML 2025 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass[table]{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
%\usepackage{subfigure}
\usepackage{booktabs} % for professional tables
\usepackage{multirow} % Required for multirow cells
\usepackage{subcaption}

\usepackage{bm}
\usepackage{pifont}
\usepackage{placeins}

\newcommand{\cmark}{ \color{lessbrightgreen} \ding{51}}%
\newcommand{\xmark}{ \color{brightred} \ding{55}}%


% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2025} with \usepackage[nohyperref]{icml2025} above.
\usepackage{hyperref}


% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
% \usepackage{icml2025}

% If accepted, instead use the following line for the camera-ready submission:
\usepackage[accepted]{icml2025}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

%\usepackage{ulem}


% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

%\usepackage[table]{xcolor}
\usepackage{xstring} % For string comparisons

% Define colors
\definecolor{lessbrightgreen}{rgb}{0.0, 0.5, 0.0}
\definecolor{brightred}{rgb}{1.0, 0.0, 0.0}
\definecolor{darkgreen}{rgb}{0.0, 0.5, 0.0}
\definecolor{violet}{rgb}{0.4, 0.0, 0.7}
%\definecolor{magenta}{rgb}{0.4, 0.0, 0.7}

\newcommand\Tau{\mathrm{T}}

\newcommand{\raj}[1]{{\color{blue}(Raj): #1}}
\newcommand{\artjom}[1]{{\color{red}(Artjom): #1}}

% Command to color numbers based on their sign
\newcommand{\colornumber}[1]{%
    \IfBeginWith{#1}{-}{\textcolor{lessbrightgreen}{#1}}{\textcolor{brightred}{#1}}%
}



% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}


% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Lightweight Online Adaption of Time Series Foundation Model Forecasts}

\begin{document}

\twocolumn[
\icmltitle{Lightweight Online Adaption for Time Series Foundation Model Forecasts}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2025
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Thomas L.~Lee}{equal,sch,intern}
\icmlauthor{William Toner}{equal,comp}
\icmlauthor{Rajkarn Singh}{comp}
\icmlauthor{Artjom Joosem}{comp}
\icmlauthor{Martin Asenov}{comp}
\end{icmlauthorlist}


\icmlaffiliation{intern}{Work done while an intern at Huawei}
\icmlaffiliation{comp}{Huawei SIR Lab, Edinburgh Research Centre, UK}
\icmlaffiliation{sch}{School of Informatics, University of Edinburgh, UK}

\icmlcorrespondingauthor{Thomas L.~Lee}{T.L.Lee-1@sms.ed.ac.uk}
\icmlcorrespondingauthor{William Toner}{william.toner2@huawei.com}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Machine Learning, ICML, Time Series, Foundation Models, Deep Learning}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

%\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
\printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.

\begin{abstract}
Foundation models (FMs) have emerged as a promising approach for time series forecasting. While effective, FMs typically remain fixed during deployment due to the high computational costs of learning them online. 
Consequently, deployed FMs fail to adapt their forecasts to current data characteristics, despite the availability of online feedback from newly arriving data. This raises the question of whether FM performance can be enhanced by the \textit{efficient} usage of this feedback. We propose \textit{AdapTS} to answer this question. 

\textit{AdapTS} is a lightweight mechanism for the online adaption of FM forecasts in response to online feedback.
%AdapTS dynamically adjusts the forecasts of an FM to the evolving data distributions during deployment.
AdapTS consists of two parts: \textbf{a)} the \textit{AdapTS-Forecaster} which is used to learn the current data distribution; and \textbf{b)} the \textit{AdapTS-Weighter} which is used to combine the forecasts of the FM and the AdapTS-Forecaster. We evaluate the performance of AdapTS in conjunction with several recent FMs across a suite of standard time series datasets. In \emph{all} of our experiments we find that using AdapTS improves performance. This work demonstrates how efficient usage of online feedback can be used to improve FM forecasts.
\end{abstract}

\begin{figure}[!t]
    \centering
    \includegraphics[width=\columnwidth]{Images/overview.pdf}  % Adjust width to 80% of text width
    \caption{\textbf{Exploitation of online information for forecast adaption in deployment:} Time series foundation models (FMs) are typically seen as fixed when deployed. We propose a method, \textit{AdapTS}, to efficiently improve their forecasts online by leveraging the feedback available in realistic deployment scenarios. AdapTS consists of two components: the \textit{AdapTS-Forecaster}, a lightweight forecaster, learnt online; and the \textit{AdapTS-Weighter} a dynamic method to adapt the FM forecasts by combining it with the AdapTS-Forecaster's forecasts.}
    \label{fig:method_summary}
    \vspace{4mm}
\end{figure}
\section{Introduction}\label{sec:intro}
Over the last decade there has been rapid development in machine learning models for time series forecasting \citep{darlow2023foldformer, lim2021time, nietime2022}. This has prompted practitioners in fields requiring accurate forecasting to adopt and deploy increasingly advanced models to remain competitive. Although these deep models perform well, training them can be prohibitive, requiring substantial computational resources, machine learning expertise, and ample data \citep{mercier2021evaluating}. These practical hurdles have spurred interest in foundation models (FMs) for time series forecasting \citep{miller2024survey, Ansari2024Chronos}, which diverge from the standard paradigm of training on a specific dataset. Instead, FMs are trained across multiple large datasets \citep{Woo2024moirai}, enabling them to generalise to new, unseen time series and deliver strong \textit{zero-shot} forecasting performance \citep{Ansari2024Chronos, rasul2023lag}. This avoids retraining a new model for each task, allowing FMs to be used out-of-the-box even with no available training data, ML expertise, or computational resources.

While effective, time series FMs remain fixed during deployment, making them non-adaptive to shifts in the underlying distribution. In time series deployment scenarios however, new data arrives continuously, providing feedback on forecast accuracy and changes in the underlying behaviour of the time series \citep{zhang2024addressing}.
This raises the possibility of using online feedback to enhance FM performance.
This poses a challenge however, as computational efficiency is a critical requirement for any online adaptation mechanism to be practical in real-world time series settings \citep{joosen2024serverless}. Potential naive approaches to online adaption, such as regular retraining or continual finetuning on available data, are at present prohibitively expensive---as demonstrated in Section~\ref{sec:comp_cost} and \citet{verwimp2023continual}. Currently, there is \textit{no general, efficient method for leveraging online feedback in time series FMs at deployment.}

In this work, we propose \textbf{\textit{AdapTS}}, an efficient approach for online \textbf{Adap}tion for \textbf{T}ime \textbf{S}eries FMs at deployment. 
AdapTS does not alter the parameters of an FM, which remain fixed during deployment, instead adapting the \emph{forecasts} output by the FM. In effect, we take a non-online FM and turn it into an efficient online model, FM\textit{+AdapTS} (see Figure~\ref{fig:method_summary}). This approach is lightweight, running on a single CPU, making implementation cheap. Importantly, AdapTS can be used \emph{out-of-the-box}---i.e., without human supervision---to enhance the performance of any FM. 

AdapTS consists of two components: the \textit{AdapTS-Forecaster}, a lightweight forecast model which is trained online, and the \textit{AdapTS-Weighter} which combines the forecasts of the FM and the AdapTS-Forecaster using an online weighting policy. To ensure that AdapTS is computationally efficient we design a complex linear model to use as the AdapTS-forecaster, exploiting the Woodbury matrix identity to fit it efficiently online. 
%Using a linear model does not come at the cost of performance as for time series, unlike other domains where FMs are used, linear models are still competitive \cite{nietime2022}. 
To construct the AdapTS-weighter we build upon exponential weighting, an approach with a longstanding pedigree in the online learning community \cite{cesa2006prediction}. We construct a weighter made out of a fast adapting component to extract local information and a slow component to extract global information. This allows the weighter to quickly adapt to distribution shift. We experimentally demonstrate consistent performance improvements when using AdapTS, across multiple state-of-the-art foundation models and across the standard time-series benchmark datasets. 

Our work consists of three main contributions:
\begin{enumerate}
\itemsep0em 
    \item We propose \textit{AdapTS}, an efficient way to exploit the online feedback available in the deployment stage of a time series foundation model to improve performance. 
    \item Design a lightweight linear forecaster applied in the Fourier domain---the \emph{AdapTS-Forecaster}---which can be efficiently fit online via the Woodbury matrix identity.\looseness=-1
    \item Design a dynamic weighter---the \emph{AdapTS-Weighter}---to combine the AdapTS-Forecaster and FM forecasts. This is constructed out of fast and slow components to quickly adapt the weighting to shifting data distributions.\looseness=-1
\end{enumerate}

\section{Related Work}
\label{sec:related_work}
Currently, the main paradigm to construct (zero-shot) time series FMs is to collect a large pretraining set of time series data and then use it to learn an LLM-like transformer model \citep{rasul2023lag,chen2024visionts,liang2024foundation}. For example, \textit{Chronos} \citep{Ansari2024Chronos}, \textit{Moirai} \citep{Woo2024moirai} and \textit{TimesFM} \citep{Das2024TimesFM} are all time series FMs which are trained on large curated pretraining sets of time series, consisting of billions of training points, and whose backbones consist of LLM-based transformer architectures---such as Chronos, which uses the T5 architecture \citep{roberts2019exploring}. Also, recently there have been new time series FMs which have gone against this trend by not using LLM architectures as their backbones. For instance, \textit{TTM} \citep{Ekambaram2024Tiny} uses the TSMixer architecture \cite{ekambaram2023tsmixer} as its backbone, which is specific to time series, resulting in a much smaller model size when compared to methods using LLM backbones. While, \textit{VisionTS} \citep{chen2024visionts} uses a masked autoencoder \citep{he2022masked} as its backbone and does not use time series data for pretraining, instead using images from the ImageNet dataset.

A major focus of this work is the exploitation of online feedback available at the deployment stage of a time series forecaster. The idea of leveraging online feedback in deployment to improve performance of an ML system has a long history \citep{hoi2021online, polikar2001learn++, bottou2003large}. Currently, this concept falls within the domain of continual or lifelong learning for deep learning methods \citep{de2021continual, wang2024comprehensive}. Some of these works, for instance, investigate how to update a model online given the newly available data, which is either from the same distribution or from a shifting distribution \citep{aljundi2019task, lee2024chunking}. Importantly, much of the research on continual learning has focused on vision or text tasks \citep{qu2021recent, wu2024continual}, with comparatively little attention given to the time series domain \citep{besnard2024continual}. The studies that have explored continual learning for time series forecasting concentrate on methods for updating the weights of deep learning models \citep{ao2023continual, pham2022learning, zhang2024addressing}. This has two problems in the context of time series: \textbf{a)} updating the weights of a deep learning model, especially of the size of a FM, at the frequency often required for time series data and with the resources usually available (e.g. CPUs) can often make such methods infeasible to use in practice \cite{diao2024forecasting, Ekambaram2024Tiny}. And \textbf{b)} online updating of deep models suffers from the problems of catastrophic forgetting and plasticity loss \citep{kirkpatrick2017overcoming, dohare2023maintaining, de2021continual}. Solutions to this currently require retraining on large amounts of historic data and complex, model-specific learning routines \citep{yang2024recent}. This is in contrast to the focus of our work, which looks at the efficient online adaption of FM forecasts, so that it can be widely used in the real world.

\section{Preliminaries}\label{sec:preliminaries}
\subsection{Rolling Window Forecasting}
When deploying a time series forecast model in practice, new data becomes available over time. To model this realistic scenario, practitioners typically adopt a \emph{rolling window} approach in which the time series is processed one time step at a time \citep{nietime2022}. At each time step, a \emph{context} window containing the previous $L$ time-series values is constructed, from which the model produces a forecast for the next $H$ steps. $H$ is referred to as the \emph{forecast horizon}. By progressing through the time series step-by-step, previous model forecasts can be evaluated against the actual ground truth values that subsequently occur, called the \emph{target}.

Observing data in a rolling manner permits the usage of new data to improve the underlying time series forecaster. Specifically, by tracking the seriesâ€™ evolution and receiving real-time feedback on forecast accuracy, the model can be refined as the new data arrives. 

In this work we look at the rolling window setting, where the parameters of AdapTS are altered every $M$ time steps using online feedback; a process we refer to as \emph{updating}. We keep track of each time AdapTS is updated by using a counter referred to as the \emph{update step} which we denote by $\tau$, to differentiate it from our notation for time step $t$. For every $M$ time steps $t\mapsto t+M$, there is a single update step $\tau\mapsto \tau+1$. 

\subsection{Notation}\label{sec:notation} 
We list the notation used in this paper below. For notational simplicity, \textit{here and in Section~\ref{sec:methodology}, we only describe the univariate case.} This is when each value in the time series is a scalar. This simplification is without loss of generality, as AdapTS forecasts each dimension of the time series, called \emph{channels}, separately---i.e. it is channel independent.  
\begin{itemize}
\itemsep0em 
    \item $L$: Context length (number of time steps in the input sequence).
    \item $H$: Forecast horizon (number of future time steps to predict).
    \item $c$: Number of channels (distinct time series).   
    \item $\bm{x}$: Context window, $\bm{x} \in \mathbb{R}^{L}$.
    \item $M$: The number of time steps between subsequent updating of AdapTS. 
    \item $t$: Current time step.
    \item $\tau$: Update Step, number of times forecaster has been updated using online feedback. Given by $\lfloor \frac{t}{M}\rfloor$.
    \item $\bm{y}, \bm{\hat{y}}$: Target and forecast respectively, $\bm{y}, \bm{\hat{y}} \in \mathbb{R}^{H}$.
    \item $X,Y$: \emph{Design} matrices containing all observed context and target vectors respectively up to the current time step. $\tilde{X},\tilde{Y}$ Fourier domain representations of the design matrices. 
\end{itemize}

\section{AdapTS: Online Adaption of Forecasts}
\label{sec:methodology}
We propose a method for the online \textbf{Adap}tion for \textbf{T}ime \textbf{S}eries (\textbf{\textit{AdapTS}}), to improve the performance of time series FMs during deployment. \textbf{\textit{AdapTS}} is a lightweight approach consisting of two parts:
\begin{enumerate}
\itemsep0em 
    \item The \textit{AdapTS-Forecaster}: a lightweight forecast model, trained online on the most recently observed time series data. 
    \item The \textit{AdapTS-Weighter}: an online weighting mechanism which adjusts the forecasts of the FM by combining it with the forecasts of the AdapTS-Forecaster.
\end{enumerate}
We display the components of AdapTS in Figure~\ref{fig:method_schematic} and describe them in turn below. 

\subsection{AdapTS-Forecaster}
\begin{figure*}[!t]
        \centering
        \includegraphics[width=\textwidth]{Images/overview_detailed.pdf}
        \caption{\textbf{Forecast construction for FM+\textit{AdapTS}:} The left side of the figure shows how AdapTS adjusts the forecast of the FM. This is achieved by combining the FM forecast with the forecasts of the online (Woodbury) updated AdapTS-Forecaster using a weighted average. The weights $w_\tau$ in the weighted average are determined by the AdapTS-Weighter based on previous performance of the FM and AdapTS-Forecaster. The schematic in the blue box to the right, zooms into the components of the AdapTS-Weighter: the fast, slow and merge weighters. Where the fast weighter gives a weighting based on recent performance; the slow weighter gives a weighting based on performance across the whole history. The merge weighter is used to combine the weights given by the fast and slow weighters. Each weighter uses exponential weighting to construct their weights; the difference being the losses used as input. While the slow weigher can be seen as using all previous losses to compute its weight, we note that only the last $B$ losses need to stored by AdapTS.}
        \label{fig:method_schematic}
\end{figure*}
The AdapTS-Forecaster is a linear forecast model used to provide forecasts based on the data seen online from the time series. We use a linear forecaster for three reasons: \textbf{a)} they have good performance in time series forecasting \citep{zeng2023transformers}; \textbf{b)} as required by our setting, they can be efficiently updated online; and \textbf{c)} online updating of linear models does not suffer from the same problems of catastrophic forgetting as the online updating neural networks \citep{de2021continual}. Additionally, when updating and using the AdapTS-Forecaster we transform the time series into the Fourier domain. This is to allow for more efficient updating by discarding high frequency features. In the rest of this section we denote the parameters of the AdapTS-Forecaster as a complex $L\times H$ weight matrix $W$.

At each update step, we refit the AdapTS-Forecaster using the most recent $M$ time steps from the time series. We fit by minimising the mean squared error loss. This means that the AdapTS-Forecaster can be fit in closed-form, avoiding the need for gradient-based optimisation \citep{toneranalysis}. Specifically, letting $\tilde{X},\tilde{Y}$ denote Fourier domain representations of all the seen dataset contexts and targets, the ($\text{L}_2$-regularised) Ordinary Least-Squares (OLS) solution for the complex weight matrix of the AdapTS-Forecaster is
\begin{align}\label{eqn:ols}
   W \coloneq (\tilde{X}^*\tilde{X} + \lambda I)^{-1}\tilde{X}^*\tilde{Y},
\end{align}
where $\lambda$ is the regularisation coefficient and $^*$ denotes the conjugate transpose.

To update the AdapTS-Forecaster, a naive implementation would be to store the matrices $\tilde{X}^T\tilde{X}$ and $\tilde{X}^*\tilde{Y}$, incrementally updating them each update step. These matrices can be used to update the weight matrix by using Equation~\ref{eqn:ols}, requiring the recomputation of the inverse $(\tilde{X}^T\tilde{X} + \lambda I)^{-1}$ at each update step. This approach would be computationally costly. \textbf{We speed up model fitting substantially in two ways}:
\begin{enumerate}
    \item Removing high frequencies.
    \item Using the Woodbury matrix identity \citep{woodbury1950inverting}.
\end{enumerate}

%By Fitting a linear regression model in the Fourier Domain is equivalent to fitting in the time-domain since the Discrete Fourier Transform (DFT) is an isometry (sorry will :( )
\textbf{1) Removing High Frequencies} \; By fitting the AdapTS-Forecaster in Fourier space we have a convenient mechanism for dimensionality reduction of the context and target vectors via the removal of high frequency components \citep{xu2024fits}. Specifically, given some $\alpha\in [0,1]$ and the Fourier domain representation of a context (or target) vector, we retain the lowest $\alpha$ proportion of frequencies, discarding the rest. This filtering technique, similar to the one considered by \citet{xu2024fits} (as discussed in Appendix~\ref{sec:fits_compare}), reduces the dimensionality of the weight vector being learned from $L\times H$ to $(\alpha L\times \alpha H)$, greatly speeding up the fitting, with minimal impact on performance as demonstrated in our ablations. 

\textbf{2) The Woodbury Matrix Identity} \; is a method for efficiently recomputing the inverse of a matrix after a low-rank update \citep{woodbury1950inverting}. We apply this in our setting to enable efficient recomputation of $(\tilde{X}^T\tilde{X} + \lambda I)^{-1}$ upon receiving new data. Specifically, letting
\begin{align*}
    A^{-1} \coloneq (\tilde{X}^*\tilde{X}+ \lambda I)^{-1}
\end{align*}
and letting $\tilde{X}_M$ denote the design matrix containing the $M$ most recently observed data features, the Woodbury update is defined as
\begin{align*}
A^{-1} &\mapsto A^{-1} - B,
\end{align*}
where
\begin{align*}
   B &\coloneq A^{-1}{\tilde{X}}_M^*(I + \tilde{X}_MA^{-1}{\tilde{X}}_M^*)^{-1}{\tilde{X}}_MA^{-1}.
\end{align*}
This expression can be computed efficiently if model refitting occurs regularly so that $M<L$. This is because rather than inverting a large matrix of dimension $L\times L$ (as in Equation~\ref{eqn:ols}), we invert a smaller matrix of dimension $M\times M$.     

\subsection{AdapTS-Weighter}
The \textit{AdapTS-Weighter} combines the forecasts of the FM and the AdapTS-Forecaster; adapting the FM's forecast by incorporating the knowledge learnt online by the AdapTS-Forecaster. We combine the forecasts by taking a weighted average of them. Denoting the forecasts of the FM and the AdapTS-Forecaster at time step $t$ by $\hat{\bm{y}}_{t,FM}$ and $\hat{\bm{y}}_{t,AF}$, respectively, the combined forecast is given by
\begin{align}\label{eqn:weight_combine}
    \bm{\hat{y}}_{t, AdapTS} = w_{\tau} \bm{\hat{y}}_{t, FM} + (1-w_{\tau}) \bm{\hat{y}}_{t, AF}.   
\end{align}
The weight $w_{\tau} \in [0, 1]$ is adjusted online by the AdapTS-Weighter to reflect the changes in the relative performance between the FM's and AdapTS-Forecaster's forecasts. We use a weighted average to combine forecasts because the general idea has been shown theoretically to improve performance (e.g., Theorem~\ref{thm:exp_weighter}). We also note that the simpler approach of using an unweighted average ($w_{\tau} = 0.5$) leads to poor performance, as demonstrated in Appendix~\ref{Appen:weighterAblate}. 

The basic building block of the AdapTS-Weighter is exponential weighting which is a celebrated method from the online learning community \citep{cesa2006prediction, Rakhlin2008Online} and can be used to weight forecasts. However, the standard way to perform exponential weighting has the drawback of being quite slow to adapt to changes in the relative performance differences between the forecasters. To be more adaptive we are inspired by Complementary Learning System theory \citep{mcclelland1995there, kumaran2016learning, ba2016using} to use a combination of a slow exponential weighter, which learns weights based on the \textit{whole} history, and a fast weighter, which only uses the \textit{recent} history. Below, we first describe exponential weighting in general and then the fast and slow weighers used by AdapTS-Weighter to produce $w_{\tau}$.

%\newpage
\textbf{Exponential Weighting} \; is a method for combining $K$ forecasters by computing a weighted average of their forecasts, where the weights are learned online based on the past losses of each forecaster. We describe first the general case, where for $K$ forecasters $\omega_{\tau, k}$ denotes the weight for the $k$\textsuperscript{th} forecaster at update step $\tau$. The weights are updated at update step $\tau$ by the learning rule: 
\begin{align*}
    {\omega}_{\tau,k} = \frac{\omega_{\tau-1, k} e^{-\eta \text{Loss}_{\tau, k}}}{\sum_{k'=1}^{K} \omega_{ \tau-1, k'} e^{-\eta \text{Loss}_{\tau,k'}}},
\end{align*}
where $\text{Loss}_{\tau, k}$ denotes the loss incurred by the $k$\textsuperscript{th} forecaster on update step $\tau$, $\eta$ denotes a predefined learning rate and where we assume $\omega_{0,k} = 1$ for all $k$. 
%In practice, $\text{Loss}_{\tau, k}$ is the average MASE \citep{hyndman2006another} over the last $M$ time steps, MASE being the loss used for evaluation in our experiments.
By recursively expanding the update rule it is possible to give a closed form solution to the weights learnt at update step $\tau$,
\begin{align*}
        \omega_{\tau, k} = \frac{e^{-\eta \sum_{\tau'=1}^{\tau} \text{Loss}_{\tau',k}}}{\sum_{k'=1}^{K} e^{-\eta \sum_{\tau'=1}^{\tau} \text{Loss}_{\tau',k'}}}.
\end{align*}
Hence the weights learnt by exponential weighting is a softmax of the cumulative losses incurred so far by the forecasters. This update rule has two desirable properties: \textbf{a)} the worse a forecaster performs the smaller its weight, and \textbf{b)} the weighter is affected less and less by individual updates as time progresses. Additionally, there is a well known theoretical result which bounds the cumulative loss when using exponential weighting; theoretically motivating its use:
\begin{theorem} 
\label{thm:exp_weighter}
    \cite{cesa2006prediction, Rakhlin2008Online} Given a convex loss function, define the loss of the weighted-average forecaster at some update step $\tau$ as $\text{\emph{Loss}}_{\tau, weighted}$ and define regret at time $\Tau$ as 
    \begin{align*}
        R_T = \sum_{\tau'=1}^{\Tau} \text{\emph{Loss}}_{\tau', weighted} - \min_{k \in \{1, \ldots, K\}} \sum_{\tau'=1}^{\Tau} \text{\emph{Loss}}_{\tau', k}.
    \end{align*}
    Then for a maximum incurred loss of $L_{\max}$ and a learning rate of $\eta = \frac{1}{L_{\max}}\sqrt{\frac{8 \text{\emph{ln}} K}{\Tau}}$ we have that
    \begin{align*}
        R_T \leq L_{\max}\sqrt{\frac{\Tau}{2} \text{\emph{ln}} K}.
    \end{align*}
\end{theorem}

\textbf{Slow and Fast Weighters} \; While exponential weighting is an effective approach it has the drawback that it does not quickly adapt to distribution shift \citep{jadbabaie2015online, cesa2012new, zhao2020dynamic}. This is because the losses incurred over the most recent time steps are given the same importance as those in the far past when constructing the weights. Hence, it takes several update steps for there to be enough losses from a new data distribution to outweigh older losses to correctly adjust the weights. To remedy this drawback we look at using a combination of two weighters (as shown in Figure~\ref{fig:method_schematic}): \textbf{a)} a \textbf{slow} weighter which is an exponential weighter, between the FM and AdapTS-Forecaster. The update for \emph{the slow weight for the FM forecast} $w^{slow}_{\tau}$ at update step $\tau$ is
\begin{align*}
        w^{slow}_{\tau} = \frac{w^{slow}_{\tau-1} e^{-\eta \text{Loss}_{\tau, 1}}}{ w^{slow}_{ \tau-1} e^{-\eta \text{Loss}_{\tau,1}} + (1-w^{slow}_{ \tau-1}) e^{-\eta \text{Loss}_{\tau,2}}}.
\end{align*}
\textbf{b)} A \textbf{fast} weighter, identical to the slow weighter but only using losses from the last $B$ update steps. \emph{The fast weight for the FM forecast  $w^{fast}_{\tau}$} at update step $\tau$ is
\begin{align*}
        w^{fast}_{\tau} = \frac{e^{-\eta \sum_{\tau'=\tau-B}^{\tau} \text{Loss}_{\tau',1}}}{\sum_{k'=1}^{2} e^{-\eta \sum_{\tau'=\tau-B}^{\tau} \text{Loss}_{\tau',k'}}}.
\end{align*}
By only using the last $B$ updates for the fast weighter we aim to make it more adaptive than the slow weighter to the current relative performance difference between the FM and AdapTS-Forecaster. Additionally, note that in our setting we always have $K=2$, this means we effectively have a single weight for each weighter where, for instance, \emph{the slow weight for the AdapTS-Forecaster is} $1-w^{slow}_{\tau}$.

% \raj{for better clarity, it is worth emphasizing that we are making two predictions here, separately with slow and fast weighters, and then compute the respective losses. Also, mention that the inference is made only once for FM and one for AdapTS and not additional computations are performed}

\textbf{Merging Fast and Slow Weights} \; The final part of the AdapTS-Weighter is a mechanism for synthesising a single weight $w_{\tau}$ from the fast and slow weights ($w^{fast}_{\tau}, w_{\tau}^{slow}$ respectively). $w_{\tau}$ is used for combining the forecasts of the FM and AdapTS-Forecaster as in Equation~\ref{eqn:weight_combine}. We use an exponential weighter, the \textbf{merge} weighter, to produce this final weight. Specifically, we record the losses $\text{Loss}_{\tau, f}$ obtained when combining the FM and AdapTS-Forecaster using the fast weight (i.e. setting $w_{\tau} \coloneq w_{\tau}^{fast}$) and the losses $\text{Loss}_{\tau, s}$ obtained when using slow weight ($w_{\tau} \coloneq w_{\tau}^{slow}$). We then use exponential weighting to fit a weight $\beta_{\tau}^{merge}$:
\begin{align*}
    \beta^{merge}_{\tau} = \frac{\beta^{merge}_{\tau-1} e^{-\eta \text{Loss}_{\tau, f}}}{\beta^{merge}_{\tau-1} e^{-\eta \text{Loss}_{\tau, f}}+ (1-\beta^{merge}_{\tau-1}) e^{-\eta \text{Loss}_{\tau, s}}}.
\end{align*}
This \emph{merge} weight is then used to combine the fast and slow weights via
\begin{align*}
    w_{\tau} = \beta^{merge}_{\tau}w^{fast}_{\tau} + (1-\beta^{merge}_{\tau})w^{slow}_{\tau},
\end{align*} 
to generate the final weight given in Equation~\ref{eqn:weight_combine}. An algorithmic description of the AdapTS-Weighter is given in Appendix~\ref{Appen:weighterAlgo}.

%\newpage
\begin{table*}[t!]
\setlength\tabcolsep{0.7pt}
\centering
\caption{\textbf{MASE of time series foundation models with and without using \textit{AdapTS}:} A lower MASE is better and we present results for each dataset over multiple forecast horizon lengths denoted as $H$ in the table. The results show that by using \textit{AdapTS} we improve performance across all datasets and forecast lengths tested.}
\label{table:results_main}
\begin{tabular}{@{}c@{\hskip 1mm}c@{\hskip 1mm}|@{\hskip 1mm}cccccccccc@{}}
\toprule
\addlinespace
 & \multicolumn{1}{c}{} & \multicolumn{10}{c}{Time Series FMs} \\
\cmidrule(l){3-12}
\multirow{2}{*}{Dataset} &  \multirow{2}{*}{$H$} &  \multicolumn{1}{c}{\multirow{2}{*}{\textbf{TTM}}} & & \multirow{2}{*}{\textbf{TimesFM}} &  &  \multirow{2}{*}{\textbf{VisionTS}} &  &  \multirow{2}{*}{\textbf{Chronos}} &  &  \multirow{2}{*}{\textbf{Moirai}} &  \\ 
&    &  & +\textit{AdapTS}($\downarrow$) &  & +\textit{AdapTS}($\downarrow$) &   & +\textit{AdapTS}($\downarrow$) &   & +\textit{AdapTS}($\downarrow$) &   & +\textit{AdapTS}($\downarrow$) \\
\midrule
\multirow{3}{*}{ETTh1} & 30 & 0.930 & \colornumber{-0.019} & 0.913 & \colornumber{-0.022} & 0.967 & \colornumber{-0.063} & 0.936 & \colornumber{-0.047} & 1.010 & \colornumber{-0.089} \\ 
& 96  & 1.081 & \colornumber{-0.014} & 1.107 & \colornumber{-0.049} & 1.084 & \colornumber{-0.028} & 1.120 & \colornumber{-0.063} & 1.168 & \colornumber{-0.086} \\
& 336  & 1.286 & \colornumber{-0.006} & 1.350 & \colornumber{-0.062} & 1.306 & \colornumber{-0.022} & 1.361 & \colornumber{-0.074} & 1.417 & \colornumber{-0.101} \\
\addlinespace
\multirow{3}{*}{ETTh2} & 30  & 1.472 & \colornumber{-0.018} & 1.470 & \colornumber{-0.024} & 1.542 & \colornumber{-0.071} & 1.455 & \colornumber{-0.021} & 1.536 & \colornumber{-0.058} \\
& 96  & 2.786 & \colornumber{-0.016} & 2.799 & \colornumber{-0.040} & 2.787 & \colornumber{-0.029} & 2.801 & \colornumber{-0.047} & 2.863 & \colornumber{-0.062} \\
& 336 & 6.802 & \colornumber{-0.011} & 6.816 & \colornumber{-0.040} & 6.763 & \colornumber{-0.008} & 6.850 & \colornumber{-0.092} & 6.913 & \colornumber{-0.105} \\
\addlinespace
\multirow{3}{*}{ETTm1} & 30  & 0.802 & \colornumber{-0.048} & 0.833 & \colornumber{-0.079} & 1.021 & \colornumber{-0.252} & 0.891 & \colornumber{-0.139} & 1.078 & \colornumber{-0.311} \\
& 96  & 0.973 & \colornumber{-0.053} & 1.016 & \colornumber{-0.097} & 1.050 & \colornumber{-0.130} & 1.164 & \colornumber{-0.243} & 1.239 & \colornumber{-0.310} \\
& 336  & 1.205 & \colornumber{-0.063} & 1.276 & \colornumber{-0.131} & 1.216 & \colornumber{-0.077} & 1.489 & \colornumber{-0.341} & 1.479 & \colornumber{-0.327} \\
\addlinespace
\multirow{3}{*}{ETTm2} & 30  & 0.799 & \colornumber{-0.036} & 0.814 & \colornumber{-0.057} & 1.040 & \colornumber{-0.251} & 0.843 & \colornumber{-0.085} & 0.946 & \colornumber{-0.164} \\
& 96  & 0.991 & \colornumber{-0.038} & 1.029 & \colornumber{-0.077} & 1.088 & \colornumber{-0.124} & 1.107 & \colornumber{-0.150} & 1.151 & \colornumber{-0.180} \\
& 336 & 1.320 & \colornumber{-0.040} & 1.429 & \colornumber{-0.128} & 1.351 & \colornumber{-0.072} & 1.478 & \colornumber{-0.193} & 1.522 & \colornumber{-0.219} \\
\addlinespace
\multirow{3}{*}{\begin{tabular}{c} US \\ Weather \\ \end{tabular}} & 30 & 0.893 & \colornumber{-0.036} & 0.868 & \colornumber{-0.041} & 1.027 & \colornumber{-0.172} & 0.939 & \colornumber{-0.091} & 0.896 & \colornumber{-0.068} \\
& 96  & 1.123 & \colornumber{-0.040} & 1.164 & \colornumber{-0.102} & 1.155 & \colornumber{-0.085} & 1.204 & \colornumber{-0.121} & 1.143 & \colornumber{-0.088} \\
& 336  & 1.296 & \colornumber{-0.044} & 1.364 & \colornumber{-0.123} & 1.286 & \colornumber{-0.048} & 1.423 & \colornumber{-0.163} & 1.334 & \colornumber{-0.111} \\
\addlinespace
\multirow{3}{*}{Weather} & 30  & 0.887 & \colornumber{-0.033} & 0.798 & \colornumber{-0.020} & 1.342 & \colornumber{-0.449} & 1.077 & \colornumber{-0.230} & 1.161 & \colornumber{-0.261} \\
& 96  & 1.205 & \colornumber{-0.043} & 1.269 & \colornumber{-0.220} & 1.436 & \colornumber{-0.253} & 1.697 & \colornumber{-0.538} & 1.720 & \colornumber{-0.503} \\
& 336  & 1.576 & \colornumber{-0.040} & 3.084 & \colornumber{-1.591} & 1.691 & \colornumber{-0.140} & 2.099 & \colornumber{-0.571} & 2.073 & \colornumber{-0.494} \\
\addlinespace
\multirow{3}{*}{Solar} & 30  & 1.091 & \colornumber{-0.031} & 1.097 & \colornumber{-0.058} & 1.004 & \colornumber{-0.020} & 0.984 & \colornumber{-0.030} & 1.222 & \colornumber{-0.132} \\
& 96  & 1.129 & \colornumber{-0.031} & 1.201 & \colornumber{-0.097} & 1.079 & \colornumber{-0.021} & 1.080 & \colornumber{-0.046} & 1.308 & \colornumber{-0.164} \\
& 336  & 1.166 & \colornumber{-0.033} & 1.248 & \colornumber{-0.100} & 1.236 & \colornumber{-0.087} & 1.107 & \colornumber{-0.028} & 1.292 & \colornumber{-0.119} \\
\addlinespace
\multirow{3}{*}{ECL} & 30  & 1.003 & \colornumber{-0.086} & --- & --- & 0.982 & \colornumber{-0.107} & 0.874 & \colornumber{-0.034} & 1.225 & \colornumber{-0.288} \\
& 96  & 1.106 & \colornumber{-0.094} & --- & --- & 1.090 & \colornumber{-0.104} & 1.015 & \colornumber{-0.054} & 1.303 & \colornumber{-0.275} \\
& 336  & 1.279 & \colornumber{-0.086} & --- & --- & 1.368 & \colornumber{-0.177} & 1.236 & \colornumber{-0.079} & 1.476 & \colornumber{-0.264} \\
\addlinespace
\multirow{3}{*}{Traffic} & 30  & 0.887 & \colornumber{-0.067} & --- & --- & 0.962 & \colornumber{-0.140} & 0.659 & \colornumber{-0.015} & 0.770 & \colornumber{-0.029} \\
& 96  & 0.920 & \colornumber{-0.077} & --- & --- & 0.943 & \colornumber{-0.112} & 0.746 & \colornumber{-0.033} & 0.752 & \colornumber{-0.017} \\ 
& 336  & 0.965 & \colornumber{-0.084} & --- & --- & 1.012 & \colornumber{-0.127} & 0.923 & \colornumber{-0.100} & 0.801 & \colornumber{-0.019} \\
\addlinespace
\bottomrule
%\vspace{1mm}
\end{tabular}
\end{table*}
\section{Experiments}
\label{sec:experiments}
\subsection{Experimental Setup}
%\textbf{Setting} \; 
To evaluate the performance of AdapTS we simulate how it would perform in a deployment scenario. Specifically, we adopt the rolling window setting described in Section~\ref{sec:preliminaries}, moving through the time series and producing forecasts one time step at a time. We update AdapTS every $M=200$ time steps using the online feedback provided by the newest $200$ data points. 

\textbf{Foundation Models (FMs)} \; Our experiments explore using AdapTS in combination with several of the most recent and well know (zero-shot) FMs for time series: Chronos (tiny) \citep{Ansari2024Chronos}, TTM (revision 2) \citep{Ekambaram2024Tiny}, TimesFM \citep{Das2024TimesFM}, Moirai (small) \citep{Woo2024moirai} and VisionTS \citep{chen2024visionts}. We compare the performance of each FM with and without using AdapTS. 

\textbf{Datasets} \; The datasets we evaluate on are ETTh1, ETTh2, ETTm1, ETTm2, Weather, Traffic, ECL, Solar and US Weather (given in \citet{zhou2021informer, wu2021autoformer, liu2022pyraformer, darlow2024dam}). These are standard datasets used widely in time series work \cite{Ekambaram2024Tiny} and importantly, none of the FMs used these datasets for pretraining. This is with the exception of TimesFM which uses Traffic and ECL for training, hence we do not report results for it for those two datasets. Furthermore, we look at these datasets for three different prediction horizons: $T=30, 96, 336$, which were chosen to be comparable to previous work \citep{Woo2024moirai, Ekambaram2024Tiny}. Throughout all experiments we use a context length of $L=520$, which is a standard context length for the FMs used in our experiments \citep{Ansari2024Chronos}. Additional details about our experiments, including additional hyperparameter settings, are given in Appendix~\ref{Appen:ExpDetails}.      

%\artjom{So does this mean that a value of 1 means that the model has the same performance as a naive seasonal forecaster? MASE<1 means better than naive seasonal, MASE>1 means worse than naive seasonal? It is worth giving an explanation of meaningful ranges here if applicable} 

\textbf{Metrics} \; We evaluate our results using Mean Absolute Scaled Error (MASE) \citep{hyndman2006another}. This is defined for a given forecast $\bm{\hat{y}}$, context $\bm{x}$ and target $\bm{y}$ as
\begin{align*}
    \text{MASE}(\bm{\hat{y}}, \bm{y}, \bm{x}) = \frac{L-S}{T} \frac{\sum_{i=1}^{T} |\hat{y}_i - y_i|}{\sum_{i=1}^{H-S}|x_i-x_{i+S}|}
\end{align*}
where $S$ represents the seasonality. MASE measures the absolute error between the forecast and target, normalised by the error of a naive seasonal forecaster on the context. This allows for comparisons across time series with varying scales over time. This is important in the rolling window setting, as it is unrealistic to assume that each channel is scaled to unit variance.

We also report results using the Root Mean Squared Scaled Error (RMSSE) in Appendix~\ref{Appen:RMSSE}. This metric is defined similarly to MASE but uses RMSE instead of MAE \citep{hyndman2006another}. The conclusions drawn from both metrics are the same.

\subsection{Main Results}
Table~\ref{table:results_main} presents the results of our experiments applying AdapTS to FMs, showing that AdapTS improves performance in all cases. The table displays the MASEs of each FM and the difference in MASE when using the FM with AdapTS (the \emph{+AdapTS} columns). For the difference, a negative number means that FM\textit{+AdapTS} performs better than using the FM on its own, which we colour \emph{green}. % \textcolor{darkgreen}{green}. 
As shown by the table we improve the performance in all cases as we have green numbers for all FMs across all of the datasets looked at. In some cases the improvement is quite large. For instance, by using AdapTS to adapt the forecasts of VisionTS we get an average improvement of over $10\%$. These results illustrate that efficiently and effectively exploiting the online feedback in the rolling window setting allows AdapTS to improve the forecasts of FMs.

\subsection{Computational Cost} \label{sec:comp_cost}
A core characteristic of AdapTS is that it is computationally inexpensive. For example, when deploying on two CPUs, AdapTS adds only an additional $0.38$ seconds per update relative to employing the FM without online adaption. This speed is crucial since, during deployment, online updating must occur faster than new data arrives. To contextualise the speed of AdapTS, we compare it to the only efficient (online) finetuning method, to the best of our knowledge, proposed for time series FMs given by \citet{Ekambaram2024Tiny}. Unlike AdapTS this approach is specific to the TTM FM. We find that \textbf{AdapTS is $\bm{2506}$x faster than online finetuning TTM}---as demonstrated in Appendix~\ref{Appen:finetune}. The greater computational expense of online finetuning TTM renders it infeasible in many deployment scenarios with restricted computational resources. Notably, AdapTS also outperforms this more computationally expensive approach, achieving an average $5.89\%$ gain in predictive performance on the ETT datasets. 
\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{Images/ensemble_weights_during_training.pdf}
    \caption{\textbf{AdapTS weight ($w_{\tau}$) over time for the Chronos FM for each channel of the ETTh1 dataset:} Each line in the plot shows the AdapTS weight for a channel. A weight of $1$ means that the AdapTS-Forecaster has no contribution to the final forecast, similarly, a weight of $0$ means that the FM is not contributing to the final forecast. The plot shows that for $5$ out of $7$ channels the FM weights gradually decrease; this reflects the fact that as the AdapTS-Forecaster observes more data its performance improves and it is upweighted by the AdapTS-Weighter. Occasionally, the weights adapt quickly to changes in the underlying time series, for example the purple channel shows a rapid weighting change between steps $8,000$-$10,000$ (shaded in cream). }
    \label{fig:ensemble_weights}
    %\vspace{-1mm}
\end{figure}
\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{Images/mae_comparison6.pdf}
    \caption{\textbf{MASEs of the Moirai FM, Moirai\textit{+AdapTS} and AdapTS-Forecaster over time on a snippet from channel 6 of the ETTh1 dataset:} The plot shows during certain intervals (shaded in cream) Moirai outperforms the AdapTS-Forecaster, on other occasions the reverse is true (shaded in light blue). While the AdapTS-Weighter ensures that the performance of the combined forecast (the green dashed line) generally outperforms either individual forecast. This demonstrates a reason for why using AdapTS improves performance, where the gain in using it is given by the green shaded region.}
    \label{fig:nice_figure}
    \vspace{-1mm}
\end{figure}

\subsection{Why Does AdapTS Improve Performance?}
While Table~\ref{table:results_main} demonstrates that AdapTS improves the performance of FMs, it is important to analyse why this is the case. We believe that AdapTS provides a benefit in two main ways: \textbf{a)} the AdapTS-Weighter can identify shifts in data distribution, ensuring that the combined forecast is well suited to the current features of the time series. \textbf{b)} By leveraging online feedback the AdapTS-Forecaster fits to the specific dynamic features of the time series, enabling the combined forecast to more accurately model these features. We evidence both points below. 

The AdapTS-Weighter makes AdapTS sensitive to the changing data distribution of the time series. This is achieved by the AdapTS-Weighter quickly adjusting the weighting between the AdapTS-Forecaster and FM when distribution shifts occur. An example of the weights adjusting to a shift in distribution is shown in Figure~\ref{fig:ensemble_weights}, which depicts the evolution of the FM weights ($w_{\tau}$) for Chronos on ETTh1. Specifically, the weight given to the FM for the purple channel rapidly increases in the cream shaded region. Additionally, in Figure~\ref{fig:nice_figure} we plot a moving average of the MASEs over time of the Moirai FM, the AdapTS-Forecaster and the combined Moirai\textit{+AdapTS} during a snippet of the ETTh1 dataset. The Figure shows how the AdapTS-Weighter dynamically weights the forecasts of the AdapTS-forecaster and the FM based on their performance on the local data distribution. This allows AdapTS to generally generate forecasts which are superior to either forecaster individually. Notably, Figure~\ref{fig:nice_figure} also shows that utilising the AdapTS usually provides a benefit regardless of whether, for the current data distribution, the FM outperforms the AdapTS-Forecaster (cream shaded regions) or vice versa (light-blue shaded regions). This all provides evidence to the fact that AdapTS both adjusts to shifts in the data distribution and by doing so increases the accuracy of forecasts. 

Figure~\ref{fig:ensemble_weights} also shows that for most channels, the FM weight tends to decrease over time. This phenomenon suggests that as the AdapTS-Forecaster observes more dataset-specific data it generally becomes better fitted to the given time series and is consequently up-weighted. This has the follow-on effect that the FM's forecast can be increasingly adapted to the characteristics of the time series it has been deployed on. An additional discussion of how the AdapTS-Forecaster identifies time series specific features to improve performance is presented in Appendix~\ref{sec:dataset_specific}. We also remark that, there are some channels in Figure~\ref{fig:ensemble_weights} where the FM consistently has a larger weight than the AdapTS-Forecaster (e.g. the brown line) and hence is performing better. This justifies the decision to make AdapTS channel-independent, as if were not, it would not be able to weight these channels differently from the others. 

\subsection{Ablations}
\label{sec:ablations}
To analyse the respective contribution of different parts of AdapTS we perform several ablations: \textbf{a)} in Appendix~\ref{Appen:weighterAblate} we look at the respective performance of the two main components of the AdapTS-Weighter, the fast and slow weighters. We find that using both leads to a gain compared to using either individually. \textbf{b)} In Appendices~\ref{sec:speed_ablation},~\ref{sec:freqprop_performance_ablation} we ablate the AdapTS-Forecaster. Demonstrating that filtering high frequencies and using the Woodbury matrix identity leads to significant speed up. We find that, as expected, discarding more frequency components leads to a drop in performance. However, when the proportion of frequencies removed is small $\approx 10\text{-}20\%$, this drop is negligible. \textbf{c)} In Appendix~\ref{sec:update_steps_ablation} we analyse the role of the updating frequency $M$. We observe that by updating AdapTS more frequently one may improve its forecasting performance albeit at the cost of compute performance. 

\section{Conclusions}\label{sec:conc}
In this work we look at how to efficiently improve the forecasts of a deployed time series foundation model (FM). We propose \textit{AdapTS}, a method which exploits the fact in deployment there is online feedback on previous forecasts as new data arrives. AdapTS leverages this feedback in two ways: \textbf{a)} to train a lightweight linear forecaster (AdapTS-Forecaster) on the newly arriving data to learn the up-to-date data distribution; and \textbf{b)} to adapt the FMs forecasts by combining them with the forecasts generated by the AdapTS-Forecaster using a learnt weighting mechanism---the AdapTS-Weighter. We demonstrate experimentally that by using \textit{AdapTS} we improve performance consistently across all datasets and FMs looked at. This indicates that exploiting the online feedback given in deployment is an effective way to boost the performance of FMs. Crucially, this online adaption of forecasts is achieved in a FM-agnostic manner and with a small enough overhead (e.g., see Section~\ref{sec:comp_cost}) that it can be widely used in the real world.

% \section*{Impact Statement}
% This paper looks at the general area of time series forecasting. While there are many potential societal consequences of work in time series forecasting, due to the general scope of our work we do not feel there are any specific societal consequences to note here.

\FloatBarrier

% In the unusual situation where you want a paper to appear in the
% references without citing it in the main text, use \nocite

\bibliography{references}
\bibliographystyle{icml2025}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix
\onecolumn

% You can have as much text here as you want. The main body must be at most $8$ pages long.
% For the final version, one more page can be added.
% If you want, you can use an appendix like this one.  

\section{Additional Methodological Details for AdapTS}
\subsection{Implementation Details of the AdapTS-Forecaster}
\textbf{Initialisation} \; Initially there is no data to fit AdapTS-Forecaster since we assume that we are deploying zero-shot without access to a training dataset. Consequently, we are required to wait a small amount of time before the AdapTS-Forecaster can first be fit to data. To handle this period we initialise the linear model to the naive seasonal forecaster. 
%Mention the annealing using weights alpha = (N+batch_size)/(N+2*batch_size) with alpha = 1 after N=1000

\textbf{Instance Norm} \; The AdapTS-Forecaster utilises a variant of instance norm at inference time. Given a context vector $\bm{x}$ and a target vector $\bm{y}$, and a forecast model $f$, this involves normalising $\bm{x}$ by its mean $\mu(\bm{x})$ applying a model $f$ on the normalised $\bm{x}'$, and adding this mean back onto the prediction $\hat{y}$. Formally;
\begin{align*}
    \bm{x}' &= \bm{x} - \mu(\bm{x} ), \\
    \hat{\bm{y}} &= f(\bm{x}'), \\
    \hat{\bm{y}}_{\text{out}} &= \hat{\bm{y}} + \mu(\bm{x} ).
\end{align*}

\subsubsection{Numerical Issues and Resolutions}
The naive approach for handling the repeated refitting of the AdapTS-Forecaster is to store $X^TX$ and $X^TY$. As one observes new contexts and targets these quantities can be updated via;
\begin{align*}
    X^TX \mapsto X^TX + X_{M}^TX_{M},\\
    X^TY \mapsto X^TY + X_{M}^TY_{M}.
\end{align*}
After which one may recompute $(X^TX + \lambda I)^{-1}X^TY$ to produce the updated weight matrix. While this approach is effective and requires only the storage of $L\times L$ and $L\times H$ matrices, one must take care that the cumulative sums $X^TX, X^TY$ don't grow too large. For example, in the context of serverless computing practitioners are often interested in predicting function requests. The number of these requests can sometimes be in the millions per hour \citep{joosen2023does, diao2024forecasting}. Consequently, in this setting, over the course of a year the values of $X^TX$ will grow to be in the order of $10^{17}$. Using, say, 32-bit float the large growth in the magnitude of the elements of $X^TX$ can result in a loss of numerical precision. To address this issue we adopt a subtly different approach, instead storing $\frac{X^TX}{N}, \frac{X^TY}{N}$ where $N$ is the number of data instances which have been observed thus far. This ensures that the magnitude of the values in these matrices remains approximately constant. Specifically, given $M$ new data instances $X_{M},Y_{M}$ one updates $\frac{X^TX}{N}$ in the following way:
 \begin{align*}
    \frac{X^TX}{N} \mapsto \frac{N}{N+M}\left(\frac{X^TX}{N}\right) + \frac{X_{M}^TX_{M}}{N+M}.
\end{align*}
The update is similar for $\frac{X^TY}{N}$.

We then observe that 
\begin{align*}
    (X^TX + \lambda I)^{-1}X^TY = \left(\frac{X^TX}{N} + \frac{\lambda }{N}I \right)^{-1}\frac{X^TY}{N}
\end{align*}
Thus we can compute the OLS solution using the scaled quantities $\frac{X^TX}{N}$ and $\frac{X^TY}{N}$ annealing the regularisation parameter $\lambda$ by scaling by $\frac{1}{N}$ as we see more data. \\

\textbf{Data Scaling} \; Typically, when training deep models on time series, practitioners adopt the approach of normalising the data. The standard approach is to compute the mean and the standard deviation of each series on some training set and then scale so that the data is zero mean and unit variance \citep{nietime2022}. The validation and test data are scaled using these same parameters derived from the training set. This technique handles the radically different scales between different time series, and mirrors data standardisation practices in other areas of machine learning such as computer vision. In an online setting however we assume that there is no training dataset from which these metrics can be computed. Thus we cannot adopt this approach. We resolve this by computing a running standard deviation for each channel which are updated online as more data is observed using Welford's online algorithm \citep{welford1962note}. These values are used to scale the data before fitting the linear model. Note that, at inference time, no data scaling is needed before applying the linear model since $\alpha A\left(\frac{\bm{x}}{\alpha}\right) = A\bm{x}$ for any $\alpha$. 

\subsubsection{How Does The AdapTS-Forecaster Differ From FITS?}\label{sec:fits_compare}
Our AdapTS-Forecaster architecture is inspired by the FITS linear forecast model; an effective lightweight approach for time series forecasting \citep{xu2024fits}. FITS applies the Real Fourier Transform (RFT) to a context vector, removes high frequency components using a low-pass filter (LPF) and then takes the inverse RFT to map back into the time domain. This structure is similar to that of the AdapTS-Forecaster, however there are some important differences between our AdapTS-Forecaster and FITS, some of which we summarise below:
\begin{enumerate}
    \item \textbf{Model Fitting:} While FITS is fit using gradient descent, AdapTS uses a closed-form solution to find the complex weight matrix. 
    \item \textbf{Model Output:} FITS outputs a forecast of the target and a reconstruction of the context vector, whereas AdapTS only generates a target.
 \item \textbf{Loss Function:} FITS is trained to minimise both the reconstruction error and forecast error where we only consider forecast error.
\item \textbf{Target Compression:}  FITS uses a low-pass filter to compress the context vector. AdapTS applies an LPF to the context and target.
\item \textbf{Online Learning:} Our method is designed for online learning whereas FITS considers exclusively the non-online setting. 
\end{enumerate}

\textbf{Relation To Standard Linear Regression} \;  When FITS does not use a LPF and the context length exceeds the prediction horizon length, it is known that it is equivalent to ordinary least-squares linear regression \citep{toneranalysis}. Similarly, in the case where our model applies no compression to the target or the context it will also be equivalent to ordinary least-squares linear regression. 

\subsection{AdapTS-Weighter Algorithms} \label{Appen:weighterAlgo}
We present here the two algorithms which form the AdapTS-Weighter. Algorithm~\ref{alg:AdapTS-Weighter-Predict}, shows how AdapTS-Weighter adapts the FM forecast by combining it with the AdapTS-Forecaster forecast using a weighted average. While Algorithm~\ref{alg:AdapTS-Weighter-Update} shows how the AdapTS-Weighter uses exponential weighting to update the weights of the fast, slow and merge weighters which construct the weights $w_{\tau}$ used to combine the FM and AdapTS-Forecaster forecasts. 
\begin{algorithm}[h]
   \caption{AdapTS-Weighter Combined Forecasts at Update Step $\tau$}
   \label{alg:AdapTS-Weighter-Predict}
\begin{algorithmic}
   \STATE {\bfseries Input:} $\bm{\hat{y}}_{t, FM}$ and $\bm{\hat{y}}_{t, AF}$, which are the forecasts of the FM and AdapTS-Forecaster for time $t$, respectively, and let the last update step be update step $\tau$
   \STATE 
   \STATE Compute weight:
   \STATE $w_{\tau} = \beta^{merge}_{\tau}w^{fast}_{\tau} + (1-\beta^{merge}_{\tau})w^{slow}_{\tau}$
   \STATE
   \STATE Compute and return AdapTS' forecasts:
   \STATE {\bfseries Return} $w_{\tau} \bm{\hat{y}}_{t, FM} + (1-w_{\tau}) \bm{\hat{y}}_{t, AF}$
\end{algorithmic}
\end{algorithm}
\begin{algorithm}[h]
   \caption{AdapTS-Weighter Update at Update Step $\tau$}
   \label{alg:AdapTS-Weighter-Update}
\begin{algorithmic}
   \STATE {\bfseries Input:} $\widehat{Y}_{\tau, FM}$ and $\widehat{Y}_{\tau, AF}$; the $M$ rolling forecasts of the FM and AdapTS-Forecaster for update step $\tau$, respectively; and, $X_{\tau}$, $Y_{\tau}$ the true values for the contexts and forecasts of update step $\tau$, respectively
   \STATE
   \STATE Compute losses for update step $\tau$ (we use average MASE over the last $M$ time steps for the loss function):
   \STATE $\text{Loss}_{\tau,1} = \text{Compute\_Average\_MASE}(\hat{Y}_{\tau, FM}, Y_{\tau}, X_{\tau})$
   \STATE $\text{Loss}_{\tau,2} = \text{Compute\_Average\_MASE}(\hat{Y}_{\tau, AF}, Y_{\tau}, X_{\tau})$
   \STATE $\text{Loss}_{{\tau}, s} = \text{Compute\_Average\_MASE}(w^{slow}_{{\tau}-1}\hat{Y}_{FM}+(1-w^{slow}_{{\tau}-1})\hat{Y}_{{\tau}, AF}, Y_{\tau}, X_{\tau})$
   \STATE $\text{Loss}_{{\tau}, f} = \text{Compute\_Average\_MASE}(w^{fast}_{{\tau}-1}\hat{Y}_{FM}+(1-w^{fast}_{{\tau}-1})\hat{Y}_{{\tau}, AF}, Y_{\tau}, X_{\tau})$
   \STATE
   \STATE Update slow weighter:
   \STATE $w^{slow}_{\tau} = \frac{w^{slow}_{\tau-1} e^{-\eta \text{Loss}_{\tau, 1}}}{ w^{slow}_{ \tau-1} e^{-\eta \text{Loss}_{\tau,1}} + (1-w^{slow}_{ \tau-1}) e^{-\eta \text{Loss}_{\tau,2}}}$
   \STATE
   \STATE Update fast weighter:
   \STATE $w^{fast}_{\tau} = \frac{e^{-\eta \sum_{\tau'=\tau-B}^{\tau} \text{Loss}_{\tau', 1}}}{\sum_{j=1}^{2} e^{-\eta \sum_{\tau'=\tau-B}^{\tau} \text{Loss}_{\tau', j}}}$
   \STATE
   \STATE Update merge weighter:
   \STATE $ \beta^{merge}_{\tau} = \frac{\beta^{merge}_{\tau-1} e^{-\eta \text{Loss}_{\tau, f}}}{\beta^{merge}_{\tau-1} e^{-\eta \text{Loss}_{\tau, f}}+ (1-\beta^{merge}_{\tau-1}) e^{-\eta \text{Loss}_{\tau, s}}}$ 
\end{algorithmic}
\end{algorithm}

\FloatBarrier


\section{Hyperparameters and Additional Experiment Details}
\label{Appen:ExpDetails}
There are a few additional details to mention about our experiments. First, there are the hyperparameter values used for AdapTS. These are chosen \textit{a priori} and are the same across all of our experiments. This is due to the fact in the rolling window setting it is not possible to fix hyperparameters before evaluating/deploying the forecaster. For the AdapTS-Forecaster the parameter values are $\lambda=20$ and $\alpha=0.9$. For the AdapTS-Weighter the hyperparameters are $\eta = 0.5$ for all weighters and $B=5$ update steps. Second, at the start of deployment the AdapTS-Forecaster has insufficient data to give accurate forecasts therefore we have a warm-up period of 5 update steps where it is not used in the combined forecast. Last, in Table~\ref{tab:DatasetStats} we present the seasonalities used to calculate the MASE and RMSSE scores for each dataset along with some general dataset statistics---number of channels and time steps.   
\begin{table}[h]
\centering
\caption{\textbf{Dataset statistics and the seasonalities used for each dataset in the computation of MASE}}
\label{tab:DatasetStats}
\begin{tabular}{c|ccc}
\toprule
\multirow{2}{*}{\textbf{Dataset}} & \multirow{2}{*}{\textbf{Seasonality}} & \multirow{2}{*}{\textbf{\#Channels}} & \multirow{2}{*}{\textbf{\#Time Steps}} \\
\\ 
\midrule
\addlinespace
ETTh1 & 24 & 7 & 17420 \\
ETTh2 & 24 & 7 & 17420 \\
ETTm1 & 96 & 7 & 69680 \\
ETTm2 & 96 & 7 & 69680 \\
US Weather & 24 & 12 & 35064 \\
Weather & 144 & 21 & 52696 \\
Solar & 24 & 88 & 12840 \\
ECL & 24 & 321 & 26304 \\
Traffic & 24 & 862 & 17544\\
\addlinespace
\bottomrule
\end{tabular}
\end{table}

\textbf{Details of FMs} \; For each of the FMs looked at, we have aimed to use the same configurations as in the original works. However, there are some necessary changes we needed to make. First, both TTM and TimesFM are trained using a context length of $512$ and so in our experiments we remove the first $8$ values of each $520$-long context before giving it to TTM or TimesFM. Also, the currently released models for TTM only predict to a maximum horizon length of $96$. Hence to forecast with TTM using a horizon length of $336$ we auto-regressively feed-in the constructed forecast back into TTM to generate longer forecasts. This is the same technique as done in the paper proposing TTM \citep{Ekambaram2024Tiny}. 

\section{Additional Experimental Results}
\subsection{Comparison of AdapTS to Continual Finetuning} \label{Appen:finetune}
An alternative method to AdapTS for using online feedback in the rolling window setting is finetuning the FM at each update step. As explained in Section~\ref{sec:related_work} this has three main problems: \textbf{a)} there is no default model-agnostic way to repeatedly finetune time series FMs; \textbf{b)} continually finetuning FMs lead to problems found in continual learning like catastrophic forgetting which are hard to deal with \cite{de2021continual, lee2024approximate}; and \textbf{c)} finetuning large FMs is computationally expensive and so cannot be done in many real world deployment settings \citep{Ekambaram2024Tiny}. These reasons are why we do not compare the efficient, model-agnostic and unforgetting AdapTS to finetuning in the main text. However, it is still useful to see how well AdapTS compares to finetuning approaches. 

To look at the performance of finetuning in the rolling window setting we perform an experiment where we finetune TTM at each update step. We use TTM as it is the only time series FM which we know of that proposes an efficient finetuning scheme but we note that this scheme is specific to TTM and cannot be used for other FMs, unlike AdapTS \citep{Ekambaram2024Tiny}. To address the continual learning problems encountered by incrementally finetuning TTM at each update step, we finetune using experience replay, a well known and well performing continual learning method \citep{ostapenko2022continual, chaudhry2019tiny, wang2024comprehensive}. More specifically, we set $M=200$ as in our main experiments, maintain a memory buffer of $400$ previously-seen instances---uniformly sampled from seen instances---and allow the method to see the last $400$ time series instances. Then we finetune using TTMs scheme where the data in the memory buffer and the first $200$ of the last $400$ time series instances as training data and the last $200$ being used as validation data for early stopping. We run the experiment on 2 Intel(R) Xeon(R) Platinum 8168 CPUs, to model a realistic deployment scenario, and measure both the MASE forecasting performance and the mean time taken to perform an update step for finetuning TTM and for AdapTS. The results of the experiment for ETTh1 with a forecast horizon of $96$ are presented in Table~\ref{tab:finetuning}. The table shows that using AdapTS improves both forecasting accuracy and computational efficiency. For example, AdapTS has a $5.89\%$ better forecasting performance and is 2506x faster. This means that while finetuning may not be able to be used in a real-world deployment setting due to computational expense \citep{joosen2023does, diao2024forecasting}, AdapTS very likely can be as it incurs only a very small computational overhead.                       
\begin{table*}[t]
\centering
\caption{\textbf{Computational and forecasting performance of using AdapTS with TTM compared to incrementally finetuning TTM (TTM-Finetune):} In the table we present the average results for all the ETT datasets over the forecast horizons of $\{30, 96, 336\}$. The results show that using AdapTS improves both the forecasting performance and computational efficiency when compared to finetuning.}
\label{tab:finetuning}
\begin{tabular}{@{}c|cc@{}}
\toprule
\multirow{2}{*}{Method} & \multirow{2}{*}{Seconds-Per-Update (CPU)} & \multirow{2}{*}{MASE} \\ 
& & \\
\midrule
\textbf{TTM-Finetune} & 911.52 & 1.746 \\
\textbf{TTM+\textit{AdapTS}} & 0.38 & 1.673 \\
\midrule
Avg. \textit{AdapTS} improvement &  \textbf{2506x} ($\uparrow$) & \textbf{5.89\%} ($\uparrow$) \\
\addlinespace
\bottomrule
\end{tabular}
\end{table*}

\subsection{Comparison of AdapTS to a Single Finetuning Step}
\begin{table*}[t]
%\setlength\tabcolsep{0.7pt}
\centering
\caption{\textbf{MASE results of finetuning TTM once on the ETT datasets (\textit{TTM-Single-Finetune}):} For each dataset and forecast horizon, we finetune TTM on the first $2000$ time steps and the use it to forecast the rest of the time series. We compare this method to (zero-shot) TTM and when using TTM with AdapTS (TTM\textit{+AdapTS}). Furthermore, in the \emph{TTM+AdapTS best?} column we write a tick if TTM\textit{+AdapTS} performs the best or equal best and a cross if it does not. The table shows that finetuning TTM once damages its performance, as this performs worse than TTM without finetuning.}
\label{table:one_finetune}
\begin{tabular}{@{}cc|cccc@{}}
\toprule
\addlinespace
\multirow{2}{*}{Dataset} &  \multirow{2}{*}{$H$}  &  \multirow{2}{*}{\textbf{TTM}} & \multirow{2}{*}{\textbf{TTM-Single-Finetune}} & \multirow{2}{*}{\textbf{{TTM\textit{+AdapTS}}}} & \multirow{2}{*}{\textit{TTM+AdapTS best?}} \\ 
& & \\
\midrule
\multirow{3}{*}{ETTh1} & 30 & 0.930 & 0.965 & 0.911 & \cmark \\ 
& 96 & 1.081 & 1.172 & 1.067 & \cmark \\
& 336  & 1.286 & 1.537 & 1.280 & \cmark \\
\addlinespace
\multirow{3}{*}{ETTh2} & 30 & 1.472 & 1.579 & 1.455 & \cmark  \\
& 96  & 2.786 & 2.927 & 2.770 & \cmark \\
& 336  & 6.802 & 7.044 & 6.791 & \cmark  \\
\addlinespace
\multirow{3}{*}{ETTm1} & 30 & 0.802 & 0.856 & 0.753 & \cmark  \\
& 96  & 0.973 & 1.055 & 0.919 & \cmark  \\
& 336  & 1.205 & 1.346 & 1.143 & \cmark\\
\addlinespace
\multirow{3}{*}{ETTm2} & 30  & 0.799 & 0.885 & 0.763 & \cmark \\
& 96 & 0.991 & 1.116 & 0.953 & \cmark \\
& 336  & 1.320 & 1.564 & 1.279 & \cmark \\
\addlinespace
\bottomrule
\end{tabular}
\end{table*}
In the previous section we explored how well AdapTS compared to finetuning TTM at every update step. In this section we explore how well it compares to finetuning TTM once, a commonly explored setup in previous work \cite{Ekambaram2024Tiny, Ansari2024Chronos}. More specifically, we use TTM zero-shot for $2000$ time steps and then use the data seen to finetune TTM. For the ETTh datasets this corresponds to finetuning on $\approx10\%$ of the data. We use the same method as in Appendix~\ref{Appen:finetune} to perform the finetuning with the newest $400$ data points used for validation and the rest for training. After this we use the finetuned TTM to forecast the rest of the time series. The results of these experiments for the ETT datasets are presented in Table~\ref{table:one_finetune}. The table shows that by only finetuning once we perform worse than using TTM zero-shot and additionally worse than using TTM with AdapTS. This indicates that while a single finetuning step might help to improve forecasts in the short term, in the long term it can damage TTMs ability to generalise to the changing data distribution of the time series. Therefore, these results suggest the need for online updating to improve forecasts of FMs at deployment.    

\newpage
\subsection{AdapTS Performance versus Update Frequency}
\label{sec:update_steps_ablation}
\begin{figure*}[b]
    \centering
    \begin{minipage}{0.50\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Images/update_ablation_freq_etth2_final.pdf}
     \end{minipage}\hfill
    \begin{minipage}{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Images/update_ablation_freq_ettm1_final.pdf}
    \end{minipage}
    \caption{\textbf{AdapTS performance as a function of the update frequency used during online evaluation, indicating that more frequent updating boosts performance:} The left figure shows results for the ETTh2 dataset, while the right figure shows results for the ETTm1 dataset.}
    \label{fig:retraining_ablation}
\end{figure*}
In our experiments we refit the AdapTS-Forecaster every $M=200$ time steps. This number is fixed across our experiments and has not been tuned. In this section we look at how performance is impacted by varying this update parameter. Figure~\ref{fig:retraining_ablation} plots the MASE of our approach as we increase the update frequency of AdapTS. The results shown are for the ETTh2 (right) and ETTm1 (left) datasets for the TTM FM (the FM attaining the best results on this dataset). These graphs demonstrate how more regular updating generally improves performance of our approach. This supports our core hypothesis that for time series it is crucial to utilise the most up-to-date data. 

\subsection{AdapTS-Forecaster Computational Efficiency Ablation}
\label{sec:speed_ablation}
When training online in real-time is it vital that model fitting be fast and computationally low-cost. This necessity motivates our decision to use a linear model which can be fit in closed-form for the AdapTS-Forecaster. Additionally, as outlined in Section~\ref{sec:methodology}, we take advantage of two ways to speed up our method:  \textbf{1)} we use the Woodbury matrix identity and \textbf{2)} we discard high frequency components when fitting the AdapTS-Forecaster. In this section we evaluate how these techniques impact the amount fitting time on a CPU. This ablation complements Section~\ref{sec:freqprop_performance_ablation} which explores how  removing high frequencies impacts the performance of AdapTS, demonstrating that the decline in performance is slight. Thus together this section and Section~\ref{sec:freqprop_performance_ablation} validate our decision to remove high frequencies to improve speed.

\subsubsection{Impact of \% of Discarded Frequencies on Execution Speed}
\label{Appen:freqSpeed}
\begin{figure*}[t]
    \centering
    \begin{minipage}[t]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Images/speed_ablation__etth1_perbatch.pdf} 
        \caption{\textbf{The impact on time taken for fitting and inference as a function of percentage of frequencies discarded by AdapTS:} We measure the time AdapTS takes for fitting and inference on a batch size of 200 as the percentage of discarded frequency components increases. As more frequencies are discarded, the total time decreases. Fitting and inference are performed using two CPU cores. Due to the presence of noise, the curve is not perfectly monotonic, as might be expected.}
        \label{fig:freq_speedablation_etth1}
    \end{minipage}
    \hfill
    \begin{minipage}[t]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Images/updatespeed_ablation__etth1_final.pdf} 
        \caption{\textbf{The impact of retraining frequency on AdapTS fitting+inference speed:} We plot the total time taken for fitting and inference in AdapTS as we vary the number of times the model is refitted during evaluation on the ETTh1 dataset with a horizon of 336. We compare the performance of the Woodbury update rule (blue) with the more basic OLS (`linear') approach. No frequency components are removed in this experiment. As retraining becomes more frequent, the benefit of using the Woodbury identity increases; when retraining occurs 84 times, the speed-up is approximately 25\% over the naive `linear' implementation. Minor fluctuations in the curve reflect the noise inherent in measuring computation speed.}
        \label{fig:retraining_speedablation_etth1}
    \end{minipage}
\end{figure*}
As detailed in Section~\ref{sec:methodology} the AdapTS includes a feature allowing the model to discard a percentage of the high frequencies of the context and targets when fitting in order to improve inference and fitting time. In this section we explore how varying the percentage of high frequencies which are discarded impacts the total execution time for fitting and inference. Specifically, we vary the proportion of frequencies discarded in steps of $5\%$ and record the time taken by AdapTS, for fitting and inference on a single data batch of size 200. For these experiments we do not use the Woodbury identity to investigate the role of frequencies on execution time in isolation. To ensure consistent resource allocation, we bound the execution to two CPU cores. This allowed us to isolate the computation to specific cores, mitigating potential variability caused by the operating systemâ€™s task scheduler. 

Figure~\ref{fig:freq_speedablation_etth1} shows the results of these experiments, plotting fitting + inference time against percentage of discarded frequencies. The plot suggest that execution speed improves by discrding a higher proportion of frequency components. For example, discarding 40\% of components results in a 25\% speed-up compared to using 100\% of the components.

\subsubsection{Speed-Up from the Woodbury Matrix Identity}
\label{Appen:woodSpeed}
The AdapTS-Forecaster, detailed in Section~\ref{sec:methodology}, uses the Woodbury matrix identity. In this section we record how this design decision impacts the time taken for fitting and inference of AdapTS. We vary the number of times that we refit the AdapTS-Forecaster during evaluation on the ETTh1 dataset and record the total time taken to fit and predict using the AdapTS model. We repeat twice, once using the Woodbury identity and once not using the identity which we call \emph{linear}. All fitting and prediction occurs on 2 CPUs. For these experiments we do not throw away any high frequency components so that we can study the impact of the woodbury identity in isolation. We use a prediction horizon of $336$. The results of these experiments are plotted in Figure~\ref{fig:retraining_speedablation_etth1}, where we plot the number of retrains on the x-axis aginst total time in the y-axis. `Woodbury' is plotted in blue and `linear' in red.   

\newpage
By inspection of Figure~\ref{fig:retraining_speedablation_etth1} we see that, when one retrains rarely, it is preferable \textit{not} to use the Woodbury update rule. This is because the Woodbury update rule is suited for low-rank updates and when refitting occurs infrequently, the rank of the update matches the rank of the matrix being updated. However, when retraining occurs regularly the Woodbury grants a speed-up over the naive implementation. Moreover, the gain increases as the regularity of retraining increases. In our main experiments we refit every 200 times steps. For the ETTh1 dataset this corresponds to refitting the AdapTS-Forecaster 84 times. At this retraining frequency the Woodbury matrix identity grants a roughly $25\%$ speed-up. The graph features certain bumps which reflect the noise inherent in measuring execution time. Both graphs show a bump at 50 retrains. On the ETTh1 dataset 50 retrains corresponds to retraining every 336 time steps, this value is equal to the prediction horizon length. Consequently, as the number of retrains increases from 49 to 50 prediction length exceeds the batch size for the first time impacting the speed of the matrix computations and explaining the apparent discontinuity. 
%mention the discontuionty at 50 retrains?


\subsection{AdapTS Performance as Function of $\%$ High-Frequencies Discarded}\label{sec:freqprop_performance_ablation} 
The AdapTS-Forecaster removes high frequencies from the context and target to reduce dimensionality, thereby speeding-up model fitting and inference. In Figure~\ref{fig:freqprop_performance_ablation} we look at how performance is impacted  by this design choice. We plot the performance on the y-axis and the percentage of frequency components which are discarded on the x-axis.
%$0\%$ therefore corresponds to a standard linear regression model applied in the Fourier Domain. 
The plot shows the Weather dataset on the left-hand side and the ETTm1 dataset on the right, both using a forecast horizon of 96 and a TTM base forecaster. The performance of the TTM FM without online adaption is given by the horizontal black dashed line. We observe that even only 5\% of frequencies are retained our approach still outperforms the FM. While removing high frequencies results in a drop in performance, removing only $10\text{-}20\%$ of frequencies has a negligible impact on method performance. Taking into account the meaningful speed-up observed in the ablations in Section~\ref{sec:speed_ablation} validates this decision to drop high frequency components. 
\begin{figure*}[t]
    \centering
    \begin{minipage}{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Images/freqprop_ablation_weather_final.pdf}
    \end{minipage}\hfill
    \begin{minipage}{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Images/freqprop_ablation_ettm1_final.pdf}
    \end{minipage}
    \caption{\textbf{AdapTS performance as a function of the percentage of high-frequency components discarded before model fitting:} We plot the MASE of FM+AdapTS as the percentage of high-frequency components removed by the AdapTS-Forecaster increases, for both the Weather dataset (left plot) and the ETTm1 dataset (right plot). The foundation model (FM) used is TTM. The MASE of the FM (black dashed line) is shown for comparison. As more frequencies are discarded, performance begins to decline; however, initially, this decline is minor (for the ETTm1 dataset, removing $20\%$ of frequency components results in only a $\sim 0.001$ increase in MASE). While further removal of high-frequency components leads to greater performance degradation, even when only $5\%$ of the high-frequency components are retained, our approach still outperforms the FM.}
    \label{fig:freqprop_performance_ablation}
\end{figure*}

%Note: You are using ETTh2 and TTM and this is update-steps 200. I think writing this caption and putting in all the relevant details still needs work.

\FloatBarrier

\subsection{AdapTS-Weighter Ablation} \label{Appen:weighterAblate}
The AdapTS-Weighter consists of a combination two separate weighers---fast and slow---therefore it is useful to understand the respective contribution of these two parts. To perform this ablation we ran experiments where we only used the slow weighter (\textit{AdapTS-SlowWeighter}) or fast weighter (\textit{AdapTS-FastWeighter}) on their own. The results of these experiments are recorded in Table~\ref{table:weighter_ablation}, where we show for each dataset and prediction horizon, the average MASE across adapting the FMs used in our main experiments (TTM, TimesFM, VisionTS, Chronos, Moirai). The table shows, by the green ticks, that using the full AdapTS-Weighter is better or equal to only using the fast or slow weighter. Additionally, we find that for all but the largest time series ECL and Traffic, using only the fast weighter gets around the same performance as using the full AdapTS-Weighter. While for ECL and Traffic, using the full AdapTS-Weighter gives a gain compared to either using just the slow or fast weighter. This shows that the way we combine the fast and slow weighter means that we can mainly use the fast weighter for the simpler datasets; while we can use a combination of the slow and fast weighter for the more complex data sets to increase performance.

In Table~\ref{table:weighter_ablation} we also show the results of using an unweighted mean to combine the forecasts of the FM and AdapTS-Forecaster (\emph{AdapTS-Unweighted}). More formally, this is when we set $w_{\tau} = 0.5$ for all update steps $\tau$. The results in Table~\ref{table:weighter_ablation} show that using a unweighted mean leads to poor performance in most cases and that it is never better or equivalent to using the AdapTS-Weighter in our experiments. Hence, this provides evidence that using a weighted mean to combine forecasts is a good design decision.     
\begin{table*}[h]
\setlength\tabcolsep{4.7pt}
\centering
\caption{\textbf{Results of ablation where we compare using the full AdapTS-Weighter (\textit{AdapTS}) with when using only its slow weighter component (\textit{AdapTS-SlowWeighter}), fast weighter component (\textit{AdapTS-FastWeighter}) or using an unweighted mean (\textit{AdapTS-Unweighted}):} We present for each data set and prediction horizon the average MASE across adapting the FMs used in our main experiments (TTM, TimesFM, VisionTS, Chronos, Moirai). We also show in the column `\textit{AdapTS best?}' a tick if AdapTS performs the best or equal best and a cross if it does not. The table shows that using the full AdapTS-Weighter is better than using either of its components independently and that using a unweighted mean performs poorly.}
\label{table:weighter_ablation}
\begin{tabular}{@{}cc|ccccc@{}}
\toprule
\addlinespace
 & \multicolumn{1}{c}{} & \multicolumn{4}{c}{Average MASE over adapting different FMs ($\downarrow$)} \\
\cmidrule(l){3-6}
\multirow{2}{*}{Dataset} &  \multirow{2}{*}{$H$}  &  \multirow{2}{*}{\textbf{\textit{AdapTS}}} & \multirow{2}{*}{\textbf{\textit{AdapTS-SlowWeighter}}} & \multirow{2}{*}{\textbf{\textit{AdapTS-FastWeighter}}} & \multirow{2}{*}{\textbf{\textit{AdapTS-Unweighted}}} & \multirow{2}{*}{\textit{AdapTS best?}} \\ 
& & \\
\midrule
\multirow{3}{*}{ETTh1} & 30 & $0.903_{\pm 0.028}$	& $0.905_{\pm 0.026}$	& $0.903_{\pm 0.028}$ & $0.909_{\pm 0.03}$ & \cmark \\
& 96 & $1.064_{\pm 0.022}$	& $1.066_{\pm 0.020}$	& $1.066_{\pm 0.020}$ & $1.070_{\pm 0.023}$ & \cmark \\
& 336 & $1.291_{\pm 0.029}$	& $1.292_{\pm 0.027}$	& $1.291_{\pm 0.029}$ & $1.296_{\pm 0.030}$ & \cmark \\
\addlinespace
\multirow{3}{*}{ETTh2} & 30 & $1.457_{\pm 0.035}$	& $1.459_{\pm 0.033}$ & $1.457_{\pm 0.035}$	& $1.462_{\pm 0.031}$ & \cmark \\
& 96 & $2.769_{\pm 0.038}$	& $2.773_{\pm 0.038}$	& $2.769_{\pm 0.038}$ & $2.772_{\pm 0.024}$ & \cmark \\
& 336 & $6.778_{\pm 0.045}$	& $6.783_{\pm 0.043}$	& $6.778_{\pm 0.044}$ & $6.779_{\pm 0.039}$ & \cmark \\
\addlinespace
\multirow{3}{*}{ETTm1} & 30 & $0.759_{\pm 0.016}$	& $0.763_{\pm 0.011}$	& $0.759_{\pm 0.016}$ & $0.795_{\pm 0.084}$ & \cmark \\
& 96 & $0.922_{\pm 0.008}$	& $0.926_{\pm 0.005}$	& $0.921_{\pm 0.009}$ & $0.959_{\pm 0.074}$ & \cmark \\
& 336 & $1.146_{\pm 0.010}$	& $1.146_{\pm 0.006}$	& $1.145_{\pm 0.010}$  & $1.190_{\pm 0.092}$ & \cmark \\
\addlinespace
\multirow{3}{*}{ETTm2} & 30 & $0.770_{\pm 0.029}$	& $0.779_{\pm 0.026}$	& $0.770_{\pm 0.029}$ & $0.799_{\pm 0.075}$ & \cmark \\
& 96 & $0.959_{\pm 0.017}$	& $0.970_{\pm 0.019}$	& $0.959_{\pm 0.017}$ & $0.984_{\pm 0.044}$ & \cmark \\
& 336 & $1.289_{\pm 0.024}$	& $1.295_{\pm 0.018}$	& $1.289_{\pm 0.024}$ & $1.315_{\pm 0.056}$ & \cmark \\
\addlinespace
\multirow{3}{*}{\begin{tabular}{c} US \\ Weather \\ \end{tabular}} & 30 & $0.843_{\pm 0.029}$	& $0.844_{\pm 0.027}$	& $0.843_{\pm 0.029}$ & $0.865_{\pm 0.051}$ & \cmark \\
& 96 & $1.070_{\pm 0.025}$	& $1.071_{\pm 0.026}$	& $1.070_{\pm 0.025}$ & $1.090_{\pm 0.016}$ & \cmark \\
& 336 & $1.243_{\pm 0.028}$	& $1.243_{\pm 0.029}$	& $1.243_{\pm 0.028}$ & $1.263_{\pm 0.031}$& \cmark \\
\addlinespace
\multirow{3}{*}{Weather} & 30 & $0.854_{\pm 0.098}$	& $0.858_{\pm 0.086}$	& $0.854_{\pm 0.098}$ & $0.925_{\pm 0.188}$ & \cmark \\
& 96 & $1.154_{\pm 0.126}$	& $1.157_{\pm 0.114}$	& $1.154_{\pm 0.126}$ & $1.267_{\pm 0.192}$ & \cmark \\
& 336 & $1.537_{\pm 0.063}$	& $1.542_{\pm 0.047}$	& $1.537_{\pm 0.064}$ & $1.763_{\pm 0.549}$ & \cmark \\
\addlinespace
\multirow{3}{*}{Solar} & 30 & $1.025_{\pm 0.112}$	& $1.027_{\pm 0.106}$	& $1.025_{\pm 0.112}$ & $1.026_{\pm 0.100}$ & \cmark \\
& 96 & $1.088_{\pm 0.085}$	& $1.088_{\pm 0.081}$	& $1.088_{\pm 0.085}$ & $1.089_{\pm 0.088}$ & \cmark \\
& 336 & $1.137_{\pm 0.070}$	& $1.137_{\pm 0.069}$	& $1.137_{\pm 0.070}$ & $1.138_{\pm 0.066}$& \cmark \\
\addlinespace
\multirow{3}{*}{ECL} & 30 & $0.892_{\pm 0.087}$	& $0.895_{\pm 0.078}$	& $0.903_{\pm 0.100}$ & $0.923_{\pm 0.127}$ & \cmark \\
& 96 & $0.997_{\pm 0.059}$	& $0.998_{\pm 0.050}$	& $1.008_{\pm 0.076}$ & $1.027_{\pm 0.105}$ & \cmark \\
& 336 & $1.188_{\pm 0.046}$	& $1.190_{\pm 0.039}$	& $1.200_{\pm 0.067}$  & $1.220_{\pm 0.086}$ & \cmark \\
\addlinespace
\multirow{3}{*}{Traffic} & 30 & $0.757_{\pm 0.168}$	& $0.763_{\pm 0.161}$	& $0.764_{\pm 0.165}$ & $0.787_{\pm 0.148}$& \cmark \\
& 96 & $0.781_{\pm 0.133}$	& $0.787_{\pm 0.120}$	& $0.788_{\pm 0.137}$ & $0.813_{\pm 0.131}$ & \cmark \\
& 336 & $0.843_{\pm 0.099}$	& $0.845_{\pm 0.093}$	& $0.849_{\pm 0.107}$ & $0.871_{\pm 0.107}$ & \cmark \\
\addlinespace
\bottomrule
\end{tabular}
\end{table*}

\FloatBarrier

\subsection{Analysis of the Performance of AdapTS-Forecaster Compared to FMs}
\begin{table*}[t!]
%\setlength\tabcolsep{2pt}
%\begin{adjustwidth}{-2.7cm}{-1cm}
\centering
\caption{\textbf{MASE of the AdapTS-Forecaster, TTM and when adapting TTM with AdapTS (TTM+\textit{AdapTS}):} The results show that AdapTS-Forecaster, which is trained online on each dataset, and TTM, performing zero-shot forecasting, perform similarly. TTM sometimes performs better than AdapTS-Forecaster and othertimes not. Additionally, TTM+\textit{AdapTS} improves upon both TTM and using AdapTS-Forecaster on its own for all datasets and forecast horizon lengths.}
\label{tab:adapts_forecaster_comparison}
\begin{tabular}{@{}cc|ccc@{}}
\toprule
\multirow{2}{*}{Dataset} & \multirow{2}{*}{$H$} & \multirow{2}{*}{\textbf{AdapTS-Forecaster}} & \multirow{2}{*}{\textbf{TTM}} & \multirow{2}{*}{\textbf{TTM+\textit{AdapTS}}} \\ 
& & & \\
\midrule
\multirow{3}{*}{ETTh1} & 30 & 0.946 & 0.930 & 0.911 \\ 
& 96 & 1.113 & 1.081 & 1.067 \\
& 336 & 1.335 & 1.286 & 1.280 \\
\addlinespace
\multirow{3}{*}{ETTh2} & 30 & 1.503 & 1.472 & 1.455  \\
& 96 & 2.819 & 2.786 & 2.770  \\
& 336 & 6.822 & 6.802 & 6.791   \\
\addlinespace
\multirow{3}{*}{ETTm1} & 30 & 0.769 & 0.802 & 0.753   \\
& 96 & 0.931 & 0.973 & 0.919  \\
& 336 & 1.150 & 1.205 & 1.143 \\
\addlinespace
\multirow{3}{*}{ETTm2} & 30 & 0.793 & 0.799 & 0.763  \\
& 96 & 0.981 & 0.991 & 0.953  \\
& 336 & 1.300 & 1.320 & 1.279  \\
\addlinespace
\multirow{3}{*}{\begin{tabular}{c} US \\ Weather \\ \end{tabular}} & 30 & 0.877 & 0.893 & 0.857  \\
& 96 & 1.096 & 1.123 & 1.083  \\
& 336 & 1.262 & 1.296 & 1.252  \\
\addlinespace
\multirow{3}{*}{Weather} & 30 & 0.907 & 0.887 & 0.855  \\
& 96 & 1.205 & 1.205 & 1.162  \\
& 336 & 1.568 & 1.576 & 1.536  \\
\addlinespace
\multirow{3}{*}{Solar} & 30 & 1.084 & 1.091 & 1.060  \\
& 96 & 1.124 & 1.129 & 1.098  \\
& 336 & 1.172 & 1.166 & 1.134  \\
\addlinespace
\multirow{3}{*}{ECL} & 30 & 0.930 & 1.003 & 0.917  \\
& 96 & 1.021 & 1.106 & 1.012  \\
& 336 & 1.205 & 1.279 & 1.193  \\
\addlinespace
\multirow{3}{*}{Traffic} & 30 & 0.871 & 0.887 & 0.820  \\
& 96 & 0.888 & 0.920 & 0.843  \\ 
& 336 & 0.922 & 0.965 & 0.881  \\
\addlinespace
\bottomrule
\end{tabular}
%\end{adjustwidth}
\end{table*}
To understand the impact of learning from the up-to-date feedback given in the rolling window setting, we present here the performance of using the AdapTS-Forecaster on it own. We compare this against using (zero-shot) TTM, the best performing FM in our experiments, and when using AdapTS with TTM (TTM\textit{+AdapTS}). The results are displayed in Table~\ref{tab:adapts_forecaster_comparison}, from which we can draw three main conclusions: \textbf{a)} for some datasets using TTM zero-shot performs better than learning from the given dataset online using AdapTS-Forecaster (e.g. ETTh1 and ETTh2); \textbf{b)} for other datasets by learning online on the given dataset AdapTS-Forecaster performs better than using TTM (e.g. ECL and Traffic); and \textbf{c)} using AdapTS-Forecaster to adapt the forecasts of TTM (TTM\textit{+AdapTS}) always improves performance against using either separately. While using summary MASEs is informative, it is also useful to look at how the relative performance between the AdapTS-Forecaster and FMs changes over time. We can look at Figure~\ref{fig:ensemble_weights} to do this, as it displays the weight $w_{\tau}$ used to weight between the AdapTS-Forecaster and the Chronos at each update step $\tau$ for ETTh1. The figure shows that for most channels that at the start Chronos is preferred and performs better than the AdapTS-Forecaster. But, as the AdapTS-Forecaster sees more data and therefore learns the specific time series characteristics it gradually performs better and therefore is weighted more heavily. This all shows that, as expected, using the up-to-date feedback in the rolling window setting (i.e. deployment stage), means we can learn a dataset specific forecaster (AdapTS-Forecaster) which steadily improves in performance over time to be comparable to the FM. Therefore, it can be used to adapt the FMs forecasts to be more dataset specific, to improve performance, which our results experimentally validate (e.g., see Appendix~\ref{sec:dataset_specific}).

%\newpage
\FloatBarrier
\subsection{RMSSE results}
\label{Appen:RMSSE}
\begin{table*}[h!]
\setlength\tabcolsep{0.7pt}
\centering
\caption{\textbf{RMSSE of time series foundation models with and without using AdapTS:} A lower RMSSE is better and we present results for each dataset over multiple forecast horizon lengths denoted as `$H$' in the table. The results show that by using \textit{AdapTS} we improve RMSSE scores across all datasets and forecast lengths tested, as when evaluating with MASE.}
\label{table:rmsse_results}
\begin{tabular}{@{}c@{\hskip 1mm}c@{\hskip 1mm}|@{\hskip 1mm}cccccccccc@{}}
\toprule
\addlinespace
 & \multicolumn{1}{c}{} & \multicolumn{10}{c}{Time Series FMs} \\
\cmidrule(l){3-12}
\multirow{2}{*}{Dataset} &  \multirow{2}{*}{$H$} &  \multicolumn{1}{c}{\multirow{2}{*}{\textbf{TTM}}} & & \multirow{2}{*}{\textbf{TimesFM}} &  &  \multirow{2}{*}{\textbf{VisionTS}} &  &  \multirow{2}{*}{\textbf{Chronos}} &  &  \multirow{2}{*}{\textbf{Moirai}} &  \\ 
& &  & +\textit{AdapTS}($\downarrow$) &  & +\textit{AdapTS}($\downarrow$) &   & +\textit{AdapTS}($\downarrow$) &   & +\textit{AdapTS}($\downarrow$) &   & +\textit{AdapTS}($\downarrow$) \\
\midrule
\multirow{3}{*}{ETTh1} & 30  & 0.806 & \colornumber{-0.016} & 0.805 & \colornumber{-0.023} & 0.864 & \colornumber{-0.068} & 0.840 & \colornumber{-0.052} & 0.877 & \colornumber{-0.076} \\
& 96  & 0.954 & \colornumber{-0.012} & 0.994 & \colornumber{-0.049} & 0.975 & \colornumber{-0.031} & 1.017 & \colornumber{-0.068} & 1.032 & \colornumber{-0.074} \\
& 336  & 1.149 & \colornumber{-0.005} & 1.215 & \colornumber{-0.058} & 1.176 & \colornumber{-0.024} & 1.231 & \colornumber{-0.072} & 1.259 & \colornumber{-0.085} \\
\addlinespace
\multirow{3}{*}{ETTh2} & 30  & 0.838 & \colornumber{-0.015} & 0.842 & \colornumber{-0.021} & 0.911 & \colornumber{-0.072} & 0.868 & \colornumber{-0.034} & 0.896 & \colornumber{-0.056} \\
& 96  & 1.149 & \colornumber{-0.012} & 1.178 & \colornumber{-0.037} & 1.166 & \colornumber{-0.029} & 1.209 & \colornumber{-0.054} & 1.219 & \colornumber{-0.060} \\
& 336  & 1.807 & \colornumber{-0.010} & 1.832 & \colornumber{-0.036} & 1.802 & \colornumber{-0.015} & 1.897 & \colornumber{-0.086} & 1.900 & \colornumber{-0.084} \\
\addlinespace
\multirow{3}{*}{ETTm1} & 30  & 0.680 & \colornumber{-0.039} & 0.710 & \colornumber{-0.067} & 0.860 & \colornumber{-0.208} & 0.763 & \colornumber{-0.122} & 0.905 & \colornumber{-0.253} \\
& 96  & 0.865 & \colornumber{-0.046} & 0.910 & \colornumber{-0.088} & 0.963 & \colornumber{-0.139} & 1.040 & \colornumber{-0.216} & 1.093 & \colornumber{-0.265} \\
& 336  & 1.077 & \colornumber{-0.052} & 1.135 & \colornumber{-0.106} & 1.108 & \colornumber{-0.080} & 1.321 & \colornumber{-0.287} & 1.316 & \colornumber{-0.282} \\
\addlinespace
\multirow{3}{*}{ETTm2} & 30  & 0.668 & \colornumber{-0.032} & 0.693 & \colornumber{-0.055} & 0.868 & \colornumber{-0.213} & 0.742 & \colornumber{-0.097} & 0.805 & \colornumber{-0.154} \\
& 96  & 0.847 & \colornumber{-0.034} & 0.892 & \colornumber{-0.075} & 0.955 & \colornumber{-0.129} & 0.981 & \colornumber{-0.156} & 1.001 & \colornumber{-0.173} \\
& 336  & 1.123 & \colornumber{-0.036} & 1.187 & \colornumber{-0.094} & 1.163 & \colornumber{-0.073} & 1.285 & \colornumber{-0.186} & 1.299 & \colornumber{-0.198} \\
\addlinespace
\multirow{3}{*}{\begin{tabular}{c} US \\ Weather \\ \end{tabular}} & 30  & 0.744 & \colornumber{-0.030} & 0.746 & \colornumber{-0.038} & 0.875 & \colornumber{-0.149} & 0.803 & \colornumber{-0.088} & 0.779 & \colornumber{-0.067} \\
& 96  & 0.971 & \colornumber{-0.032} & 1.035 & \colornumber{-0.092} & 1.015 & \colornumber{-0.072} & 1.063 & \colornumber{-0.115} & 1.030 & \colornumber{-0.087} \\
& 336  & 1.148 & \colornumber{-0.033} & 1.230 & \colornumber{-0.108} & 1.159 & \colornumber{-0.043} & 1.278 & \colornumber{-0.149} & 1.232 & \colornumber{-0.108} \\
\addlinespace
\multirow{3}{*}{Weather} & 30 & 0.580 & \colornumber{-0.028} & 0.521 & \colornumber{-0.017} & 0.941 & \colornumber{-0.359} & 0.724 & \colornumber{-0.167} & 0.753 & \colornumber{-0.184} \\
& 96  & 0.987 & \colornumber{-0.035} & 0.888 & \colornumber{-0.034} & 1.203 & \colornumber{-0.223} & 1.363 & \colornumber{-0.402} & 1.337 & \colornumber{-0.365} \\
& 336  & 1.643 & \colornumber{-0.031} & 1.767 & \colornumber{-0.214} & 1.761 &\colornumber{-0.131} & 2.061 & \colornumber{-0.439} & 2.001 & \colornumber{-0.369} \\
\addlinespace
\multirow{3}{*}{Solar} & 30  & 0.790 & \colornumber{-0.005} & 0.831 & \colornumber{-0.043} & 0.836 & \colornumber{-0.045} & 0.846 & \colornumber{-0.065} & 0.922 & \colornumber{-0.104} \\
& 96  & 0.866 & \colornumber{-0.006} & 0.957 & \colornumber{-0.079} & 0.919 & \colornumber{-0.045} & 0.997 & \colornumber{-0.106} & 1.031 & \colornumber{-0.131} \\
& 336  & 0.903 & \colornumber{-0.005} & 1.000 & \colornumber{-0.077} & 0.973 & \colornumber{-0.057} & 1.033 & \colornumber{-0.091} & 1.046 & \colornumber{-0.109} \\
\addlinespace
\multirow{3}{*}{ECL} & 30  & 0.846 & \colornumber{-0.066} & --- & --- & 0.863 & \colornumber{-0.102} & 0.781 & \colornumber{-0.040} & 1.049 & \colornumber{-0.250} \\
& 96  & 0.956 & \colornumber{-0.070} & --- & --- & 0.964 & \colornumber{-0.092} & 0.929 & \colornumber{-0.063} & 1.135 & \colornumber{-0.235} \\
& 336  & 1.115 & \colornumber{-0.062} & --- & --- & 1.191 & \colornumber{-0.138} & 1.130 & \colornumber{-0.085} & 1.285 & \colornumber{-0.214} \\
\addlinespace
\multirow{3}{*}{Traffic} & 30 & 0.709 & \colornumber{-0.051} & --- & --- & 0.793 & \colornumber{-0.128} & 0.587 & \colornumber{-0.027} & 0.630 & \colornumber{-0.026} \\
& 96 & 0.783 & \colornumber{-0.057} & --- & --- & 0.811 & \colornumber{-0.090} & 0.723 & \colornumber{-0.052} & 0.678 & \colornumber{-0.020} \\
& 336 & 0.843 & \colornumber{-0.057} & --- & --- & 0.876 & \colornumber{-0.090} & 0.895 & \colornumber{-0.115} & 0.754 & \colornumber{-0.021} \\
\addlinespace
\bottomrule
\end{tabular}
\end{table*}

\newpage
\subsection{The AdapTS-Forecaster Learns Dataset-Specific Features}\label{sec:dataset_specific}
While FMs are designed to produce good forecasts out-of-the-box, avoiding a dataset-specific training routine can mean that such models are not optimally tuned to the given data distribution. In contrast, the AdapTS-Forecaster is fit to data drawn from the specific time series. This allows it to pick up on dataset-specific features than the FM may miss. This way combining the forecasts of the FM with those of the AdapTS-Forecaster can boost performance. Two concrete examples of this are given in this section. 

Figure~\ref{fig:spike2} shows forecasts on the Traffic dataset (channel 620) made by TTM (left, orange) and AdapTS-Forecaster (right, blue). We see that while the forecasts of TTM are good, capturing daily periodicity, it does not model the decrease in traffic which occurs during the weekend (regions shaded in blue). By contrast, the AdapTS-Forecaster is able to identify and predict this decrease in traffic.

Figure~\ref{fig:spike} shows forecasts on two cloud time series \citep{joosen2024serverless} made by TTM (orange) and TTM+AdapTS (blue) compared against the ground truth (red). We see that while the forecasts of TTM are fairly accurate it does not anticipate spikes which occur periodically in either of the datasets. However, the AdapTS-Forecaster, which is fit on drawn from these dataset, is able to insert the missing spikes boosting overall performance.

\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{Images/spike2.pdf}
    \caption{\textbf{TTM (left) and AdapTS-Forecaster (right) forecasts on the Traffic dataset:} The TTM forecast (right figure, orange) is good, picking up on the daily periodicity in traffic levels. However, TTM fails to model the weekly periodicity; specifically the decline in traffic occurring at the weekend (see the blue shaded regions). Conversely, the AdapTS-Forecaster, which is fit to the dataset, predicts this decline in weekend traffic numbers.  }
    \label{fig:spike2}
\end{figure}

%\begin{figure*}[t]
%    \centering
%    \begin{minipage}{0.49\textwidth}
%        \centering
%        \includegraphics[width=\textwidth]{Manuscript/Images/spike.pdf}
%    \end{minipage}\hfill
%    \begin{minipage}{0.49\textwidth}
%        \centering
%        \includegraphics[width=\textwidth]{Manuscript/Images/spike3.pdf}
%    \end{minipage}
%    \caption{\textbf{TTM and TTM+AdapTS forecasts on two time series from the Huawei %Cloud dataset.} In both figures, the TTM forecast (orange) is accurate but omits the %large spikes which occurs around time step $7100$ on the left figure and around step %$7170$ on the right figure. This is despite the regularity of these spikes making %them seemingly easy to predict. In contrast, AdapTS predicts these spikes well so %that TTM+AdapTS (blue) generates a superior forecast to TTM by itself. }
%    \label{fig:spike}
%\end{figure*}

\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{Images/cloud_spike_bigger.pdf}
    \caption{\textbf{TTM and TTM+AdapTS forecasts on two cloud time series:} In both figures, the TTM forecast (orange) is accurate but omits the large spikes which occurs around time step $7100$ on the left figure and around step $7170$ on the right figure. This is despite the regularity of these spikes making them seemingly easy to predict. In contrast, AdapTS predicts these spikes well so that TTM+AdapTS (blue) generates a superior forecast to TTM by itself. }
    \label{fig:spike}
\end{figure}

%\newpage
\subsection{A Note on the Performance Ordering of FMs When Using or Not Using AdapTS}
It is interesting to see how the relative performance of FM change when using AdapTS to adjust their forecasts online. The results in Table~\ref{table:results_main} show that in our experiments TTM is generally the best performing FM without AdapTS. But, when using AdapTS the best performing FM is less clear: the performance of each of the FMs becomes more similar and the best model varies across dataset and prediction length. This suggests that in realistic settings where it is possible to use AdapTS to exploit online feedback to improve forecasts, the performance improvement in newer FMs is less stark than in the zero-shot setting. This adds qualifications to the suggested progress made in time series forecasting by successive generations of FMs.  
\end{document}


% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was created
% by Iain Murray in 2018, and modified by Alexandre Bouchard in
% 2019 and 2021 and by Csaba Szepesvari, Gang Niu and Sivan Sabato in 2022.
% Modified again in 2023 and 2024 by Sivan Sabato and Jonathan Scarlett.
% Previous contributors include Dan Roy, Lise Getoor and Tobias
% Scheffer, which was slightly modified from the 2010 version by
% Thorsten Joachims & Johannes Fuernkranz, slightly modified from the
% 2009 version by Kiri Wagstaff and Sam Roweis's 2008 version, which is
% slightly modified from Prasad Tadepalli's 2007 version which is a
% lightly changed version of the previous year's version by Andrew
% Moore, which was in turn edited from those of Kristian Kersting and
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.
