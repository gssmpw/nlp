%File: anonymous-submission-latex-2025.tex
\documentclass{article} % DO NOT CHANGE THIS
% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2025} with \usepackage[nohyperref]{icml2025} above.
\usepackage{hyperref}


% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
\usepackage[arxiv]{icml2025}

\usepackage{newfloat}
\usepackage{listings}

% \usepackage{bibentry}
% \usepackage{amsmath}
% % \usepackage{algpseudocode}
% \usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

% \usepackage{hyperref}
\usepackage{multirow}
\usepackage{enumitem}
\usepackage{bm,bbm}
\usepackage{todonotes}

\newcommand{\minimize}[1]{\underset{{#1}}{\text{minimize}}}
\newcommand{\ra}[1]{\renewcommand{\arraystretch}{#1}}
\DeclareMathOperator*{\argmin}{argmin}
\DeclareMathOperator*{\EE}{\mathbb{E}}


\usepackage{xcolor}
\usepackage{soul}
\definecolor{BlueViolet}{RGB}{138,43,226}



%\newcommand{\bcol}[1]{\textcolor{BlueViolet}{#1}}
\newcommand{\bcol}[1]{\emph{#1}}
\newcommand{\nando}[1]{\textcolor{purple}{$^{\sl NF:}$ #1}}
\newcommand{\ste}[1]{\textcolor{blue}{$^{\sl SZ:}$ #1}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}


\begin{document}


\twocolumn[
\icmltitle{Training-Free Constrained Generation With Stable Diffusion Models}


\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Stefano Zampini}{equal,yyy,zzz}
\icmlauthor{Jacob Christopher}{equal,uva}
\icmlauthor{Luca Oneto}{zzz}
\icmlauthor{Davide Anguita}{zzz}
\icmlauthor{Ferdinando Fioretto}{uva}
\end{icmlauthorlist}

\icmlaffiliation{yyy}{Polytechnic of Turin, Turin, Italy}
\icmlaffiliation{uva}{University of Virginia, Charlottesville, Virginia, USA}
\icmlaffiliation{zzz}{University of Genoa, Genoa, Italy}

\icmlcorrespondingauthor{Stefano Zampini}{stefano.zampini@polito.it}
\icmlcorrespondingauthor{Jacob Christopher}{csk4sr@virginia.edu}
\icmlcorrespondingauthor{Ferdinando Fioretto}{fioretto@virginia.edu}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Machine Learning, ICML}

\vskip 0.3in
]

\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution

% \title{Enabling Constrained Generation for Stable Diffusion Models}
% \author{
% Stefano Zampini \textsuperscript{\rm 1, \rm 3},
% Jacob Christopher \textsuperscript{\rm 2},
% Luca Oneto \textsuperscript{\rm 3},
% Davide Anguita \textsuperscript{\rm 3},
% Ferdinando Fioretto \textsuperscript{\rm 2}
% }

% \affiliations {
%     % Affiliations
%     \textsuperscript{\rm 1}Polytechnic of Turin\\
%     \textsuperscript{\rm 2}University of Virginia\\
%     \textsuperscript{\rm 3}University of Genoa\\
%     stefano.zampini@polito.it, csk4sr@virginia.edu, fioretto@virginia.edu
% }



\begin{abstract}
Stable diffusion models represent the state-of-the-art in data synthesis across diverse domains and hold transformative potential for applications in science and engineering, e.g., by facilitating the discovery of novel solutions and simulating systems that are computationally intractable to model explicitly.
However, their current utility in these fields is severely limited by an inability to enforce strict adherence to physical laws and domain-specific constraints. Without this grounding, the deployment of such models in critical applications, ranging from material science to safety-critical systems, remains impractical.
This paper addresses this fundamental limitation by proposing a novel approach to integrate stable diffusion models with constrained optimization frameworks, enabling them to generate outputs that satisfy stringent physical and functional requirements. 
We demonstrate the effectiveness of this approach through material science experiments requiring adherence to precise morphometric properties, inverse design problems involving the generation of stress-strain responses using video generation with a simulator in the loop, and safety settings where outputs must avoid copyright infringement. 
\end{abstract}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Diffusion models have emerged as powerful generative tools, synthesizing structured content from random noise through sequential denoising processes \cite{sohl2015deep, ho2020denoising}. Their flexibility and efficacy have driven significant advancements across diverse domains, including engineering \cite{wang2023diffusebot, zhong2023guided}, automation \cite{carvalho2023motion, janner2022planning}, chemistry \cite{anand2022protein, hoogeboom2022equivariant}, and medical analysis \cite{cao2024high, chung2022score}. The advent of stable diffusion models has further extended these capabilities, enabling efficient handling of high-dimensional data and more complex distributions \cite{rombach2022highresolutionimagesynthesislatent}. This scalability makes stable diffusion models particularly promising for applications in science and engineering, where data is highly complex and fidelity is paramount.

Despite their success in generating coherent content, diffusion models face a critical limitation when applied to domains that require outputs to adhere to strict criteria. In scientific and engineering contexts, generated data must go beyond merely resembling real-world examples; it must rigorously comply with predefined specifications, such as physical laws, first principles, safety standards, or design constraints. When these criteria are not met, the outputs may become unreliable, unsuitable for practical use, or even hazardous, undermining trust in the model's applicability. %These stringent requirements pose a significant challenge, as 
However, conventional diffusion models lack the mechanisms necessary to guarantee such compliance. {\em Bridging this gap is crucial for realizing the potential of diffusion models in high-stakes scientific applications where adherence to constraints is not merely desirable but imperative.}

Recent research has reported varying success in augmenting these models with (often specialized classes of) constraints, providing adherence to desired properties in selected domains \cite{frerix2020homogeneous,liu2024mirror,fishman2023diffusion, fishman2024metropolis,christopher2024constrained}.
Many of these methods, however, are restricted to simple constraint sets or sets that can be easily approximated, such as a simplex, L2-ball, or polytope, making them unable to handle more complex requirements that are necessary for the applications of interest in this work. %\citet{christopher2024constrained} provide support for arbitrary constraint sets by extending the sampling algorithm to use a projected gradient approach.
Additionally, all of these previously proposed techniques are designed for standard diffusion models and operate directly in the original data space, and thus are incompatible with stable diffusion models, which operate on latent representations. 
% However, none of these works have provided support for stable diffusion models.
Indeed, these methods are contingent on the ability to impose constraints directly during the diffusion reverse process \cite{frerix2020homogeneous,christopher2024constrained} and in some cases the forward process \cite{liu2024mirror,fishman2023diffusion,fishman2024metropolis} which cannot be extended within the latent representation used by stable diffusion models. 
This incompatibility limits their applicability to high-dimensional, real-world scenarios common in the application of interest of this work. 

This paper addresses this challenge by introducing a novel, gradient-based framework that enforces constraints directly on the latent representations of stable diffusion models during the reverse diffusion process. Our approach employs a primal-dual method to enforce these constraints, emulating a dual ascent process through a proximal Langevin dynamics term. For the first time, this enables stable diffusion models to generate outputs that strictly adhere to arbitrary constraint sets while preserving their coherence to the original data distribution. Our method is empirically validated, demonstrating state-of-the-art performance in constrained generation tasks, including synthesis of materials with precise morphometric properties, inverse design of meta-materials targeting exact stress-strain curves using a simulator in the loop, and content generation complying with copyright constraints.


\textbf{Contributions.}
This paper provides several contributions: 
\begin{enumerate}[leftmargin=*, parsep=0pt, itemsep=0pt, topsep=0pt]
\item It introduces a novel paradigm for {\it training-free constraint imposition} on stable diffusion models, for the first time allowing for strict adherence to arbitrary constraint sets with state-of-the-art stable diffusion models.
\item It demonstrates a new approach for {\it incorporating complex non-differentiable simulators into the sampling process} for direct constraint enforcement.
\item It provides a rigorous evaluation on settings motivated by real-world scientific and practical use cases, reporting state-of-the-art results as assessed by qualitative metrics {\em while also providing constraint satisfaction}.
\item It provides guarantees for convex constraints, which are common in applications for many scientific domains (see Appendix \ref{appendix:theory}).
% \item \nando{needs to be improved - expanded}
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \section{Related Work}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% \textbf{Constrained Optimization for Diffusion Sampling} Prior work by \cite{christopher2024constrained} frames the diffusion model sampling process as a constrained optimization problem. While this approach guarantees constraint satisfaction and is applicable to a diverse set of domains, it cannot directly cope with latent representations present in stable diffusion models. This challenge is primarily posed by the inability to represent constraints directly in the latent space. This work similarly models the reverse process as a constrained optimization problem, but adapts the constraint imposition to operate upon the latent throughout the sampling procedure.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Preliminaries}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% We begin by introducing diffusion models and the notation that will be used throughout this paper. In Section \ref{subsec:ddpm} we discuss Diffusion Denoising Probabilistic Models (DDPM) and subsequently explain their connection to stable diffusion models (Section \ref{subsec:stable}).


\textbf{Diffusion Denoising Probabilistic Models.}
\label{subsec:ddpm}
Diffusion-based generative models \cite{sohl2015deep, ho2020denoising} represent the data distribution by constructing a Markov chain $\{\bm{x}_t\}_{t=0}^T$, where $\bm{x}_0$ denotes the original data sample. This framework defines a Gaussian diffusion process such that $p(\bm{x}_0) = \int p(\bm{x}_T) \prod_{t=1}^T p(\bm{x}_{t-1} \vert \bm{x}_t) \, d\bm{x}_{1:T}$.

In the \textit{forward process}, data is progressively perturbed by adding Gaussian noise at each timestep $t$, following a predefined noise schedule. As $t$ approaches $T$, the distribution of $\bm{x}_T$ approximates a standard Gaussian.

A neural network denoiser, $\epsilon_\theta(\bm{x}_t, t)$, is trained to predict the added noise $\epsilon \sim \mathcal{N}(\bm{0}, \bm{I})$ at each timestep $t$. The training objective minimizes the mean squared error between the true noise and the network's prediction:
\[
\min_\theta 
\EE_{t \sim [1,T],\; \bm{x}_0,\; \epsilon \sim \mathcal{N}(\bm{0}, \bm{I})}
\left[ \left\| 
\epsilon - \epsilon_\theta( \bm{x}_t, t ) 
\right\|_2^2 \right].
\]
In the \textit{reverse process}, the trained denoiser $\epsilon_\theta(\bm{x}_t, t)$ is used to iteratively reconstruct data samples from the noise distribution $p(\bm{x}_T)$. At each step $t$, the denoiser approximates the reverse transition $p(\bm{x}_{t-1} \vert \bm{x}_t)$, effectively reversing the diffusion process to generate high-quality data samples. This phase is also called \emph{sampling}.


% Diffusion-based generative models \cite{sohl2015deep, ho2020denoising} represent the data distribution, whose samples are denoted as $\bm{x}_0$, by expanding it into a Markov chain $\{\bm{x}_t\}_{t=1}^T$. This approach defines a Gaussian diffusion process expressed as $p(\bm{x}_0) = \int p(\bm{x}_T) \prod_{t=1}^T p(\bm{x}_{t-1} \vert \bm{x}_t) \, d \bm{x}_{1:T}$.

% In the \textit{forward process}, the data undergoes incremental perturbations by adding Gaussian noise, gradually transforming it towards a standard Gaussian distribution. The transition kernel governing this process is given by $q(\bm{x}_t \vert \bm{x}_{t-1}) = \mathcal{N}(\bm{x}_t; \sqrt{1 - \beta_t} \bm{x}_{t-1}, \beta_t \bm{I})$, where each $\beta_t \in (0, 1)$ constitutes the noise schedule $\{\beta_t\}_{t=1}^T$. This schedule is designed so that the terminal distribution $p(\bm{x}_T)$ approximates a Gaussian distribution.

% At each time step $t$, the variable $\bm{x}_t$ can be analytically described by
% \[
% \chi_t(\bm{x}_0, \epsilon) = \sqrt{{\alpha}_t} \bm{x}_0 + \sqrt{1 - {\alpha}_t} \epsilon,
% \]
% where $\epsilon \sim \mathcal{N}(\bm{0}, \bm{I})$ represents the noise term, and ${\alpha}_t = \prod_{i=1}^t (1 - \beta_i)$. This formulation facilitates the training of a neural network denoiser $\epsilon_\theta(\bm{x}_t, t)$, which learns to predict the noise component at each step, thereby implicitly modeling the underlying data distribution.

% The denoiser is trained by minimizing the discrepancy between the actual noise $\epsilon$ and its prediction $\epsilon_\theta(\bm{x}_t, t)$ using the loss function:
% \begin{equation}
%     \min_\theta 
%     \EE_{t \sim [1,T],\; \bm{x}_0,\; \epsilon \sim \mathcal{N}(\bm{0}, \bm{I})}
%     \left[ \left\| 
%     \epsilon - \epsilon_\theta( \bm{x}_t, t ) 
%     \right\|_2^2 \right].
% \end{equation}

% In the \textit{reverse process}, the trained denoiser $\epsilon_\theta(\bm{x}_t, t)$ is employed to iteratively transform samples from the noise distribution $p(\bm{x}_T)$ back into realistic data samples from $p(\bm{x}_0)$. At each step $t$, the denoiser approximates the reverse transition $p(\bm{x}_{t-1} \vert \bm{x}_t)$, effectively reversing the diffusion process and enabling the generation of high-quality data samples.

% \nando{let's rewrite and condense this -- remove notation never used for example of the scheduler. }

\textbf{Stable Diffusion.}
%\label{subsec:stable}
Stable diffusion models \cite{rombach2022high,podell2023sdxl} extend DDPMs by applying the diffusion process in a low-dimensional latent space rather than directly on the space of the training data.
An encoder-decoder architecture is used, where the encoder $\mathcal{E}$ maps the high-dimensional image data to a latent space, denoted $\mathbf{z}_t$, and the decoder $\mathcal{D}$ reconstructs the image from the latent space after the diffusion model has operated on it.
\begin{equation}
    \min_\theta 
    \EE_{t \sim [1,T],\; \mathbf{z}_t \sim \mathcal{E}(\bm{x}), \epsilon \sim \mathcal{N}(\bm{0}, \bm{I})}
    \left[ \left\| 
    \epsilon - \epsilon_\theta( \mathbf{z}_t, t ) 
    \right\|_2^2 \right].
\end{equation}
% \nando{This now comes out of nowhere}
The loss remains consistent with standard DDPM, with the caveat that the stable diffusion model is trained to denoise over the latent space as opposed to the image space. Notice, however, that training the denoiser does not directly interact with the decoder, as the denoiser’s loss is defined over the latent space and does not connect to the finalized samples. This consideration is relevant to the design choice taken by this paper in the proposed solution, discussed in Section \ref{sec:space_correction}. %since constraints violations cannot be directly backpropagated with respect 
After iterative denoising, the final sample can be obtained by decoding $\mathbf{z}_0$ with $\mathcal{D}$.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Projected Langevin Dynamics}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Integrating constrained optimization techniques with sampling algorithms has been pivotal in endowing generative process with scientific and engineering principles. 
Particularly when sampling over convex constraint sets, proximal methods have been proposed to ensure convergence of Langevin dynamics algorithms to feasible distributions. \citet{brosse2017sampling} provide theoretical motivation for the inclusion of proximal operators in Langevin Monte Carlo sampling algorithms, proving specific convergence bounds.

Diffusion models directly use a variant of Langevin Monte Carlo sampling, Stochastic Gradient Langevin Dynamics (SGLD), for their denoising process. This sampling procedure provides a non-deterministic version of natural gradient descent by incorporating additional noise in the optimization procedure via Lagevin dynamics \cite{welling2011bayesian}. Provided this understanding, \citet{christopher2024constrained} frame the sampling procedure as a constrained optimization problem, given the constraint set $\mathbf{C}$:
\begin{subequations}
    \label{eq:pdm}
    \begin{align}
        \label{eq:constrained-diffusion}
        \minimize{\bm{x}_{T}, \ldots, \bm{x}_1} &\;
        \sum_{t = T, \ldots, 1}- \log q(\bm{x}_{t}|\bm{x}_0) \\
        \label{eq:constrained-diffusion-constr}
        \textrm{s.t.:}  &\quad \mathbf{g}(\bm{x}_t) = 0
    \end{align}
\end{subequations}
where $\mathbf{g}$ is a differentiable vector-valued function which evaluates to zero when the constraints are satisfied and otherwise measures the distance of $\bm{x}$ from constraint set $\mathbf{C}$. 

Note that this sampling process converges to an ``almost-minimizer'' of the function within $d^2/(\sigma^{1/4}\lambda^*)\log(1/\epsilon)$ where $\sigma^2$ is the variance schedule, $\lambda^*$ is the uniform spectral gap of Langevin diffusion, and $d$ is the problem dimensions, as proven by \citet{welling2011bayesian}. Furthermore, \citet{xu2018global} demonstrate that these results generally extend to nonconvex settings, further justifying this derivation.







% \citet{christopher2024constrained} apply proximal Langevin dynamics to diffusion models using this formalization of the reverse diffusion process. Specifically, they using projection operator, $\mathcal{P}_{\mathbf{C}}$, which is a specific class of proximal operators.
% The proposed method, Projected Diffusion Models, converges to a feasible subdistribution of the learned data by enforcing constraints throughout the reverse process. A projection operator, $\mathcal{P}_{\mathbf{C}}$, is generally defined in constrained optimization contexts as
% \begin{equation}
%     \label{eq:projection}
%     \mathcal{P}_{\mathbf{C}}(\bm{x}_t) = \argmin_{\bm{y}_t \in \mathbf{C}} ||\bm{y}_t - \bm{x}_t||_{2}^2, 
% \end{equation}
% computing the nearest feasible point to $\bm{x}$ by minimizing the distance function $||\bm{y}_t - \bm{x}_t||_{2}^2$.

Operationally, enforcing constraints during the 
sampling can be obtained by modifying the update step as:
\begin{equation}
    \label{eq:projected-update}
    \bm{x}_{t}^{i+1} = \mathcal{P}_{\mathbf{C}} \left(\bm{x}_{t}^{i} + \gamma_t \nabla_{\bm{x}_{t}^{i}} \log q(\bm{x}_{t}|\bm{x}_0) + \sqrt{2\gamma_t}\bm{\epsilon}\right)
\end{equation}
where the projection operator $\mathcal{P}_{\mathbf{C}}(\bm{x}) = \argmin_{\bm{y} \in \mathbf{C}} \|\bm{y} - \bm{x}\|_{2}^2$ returns the nearest feasible sample. By incorporating the projection operator during each step of the reverse diffusion process, Projected Diffusion Models ensure that generated samples remain within the constraint set throughout the reverse process, resulting in convergence to a feasible subdistribution of the learned data.

While existing methods have been shown to be applicable when diffusion models operate across the image space, such approaches cannot be directly adapted to the context of stable diffusion as $\mathbf{C}$ cannot be directly represented in the latent space where the reverse process occurs. While prior work has attempted to impose select criteria on latent representations, these methods rely on learning-based approaches that struggle in out-of-distribution settings \cite{engel2017latent}, making them unsuitable for scenarios requiring strict constraint adherence. This limitation likely explains their inapplicability in the engineering and scientific applications explored by \cite{christopher2024constrained,fishman2023diffusion,fishman2024metropolis}. 

The next section proposes a novel adaptation of constrained Langevin dynamics algorithms to enforce constraints directly in the latent space of stable diffusion models to overcome these challenges.





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Latent Space Correction}
\label{sec:space_correction}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Applying constraint-guided corrections directly in the latent space is challenging because the learned latent representation does not correspond to explicit image features, making it difficult to represent and enforce constraints defined in the image space. The key insight for addressing this challenge lies in recognizing that while constraints cannot be directly represented in the latent space, their satisfaction can still be evaluated at any point in the diffusion process. Indeed, the decoder $\mathcal{D}$ acts as a differentiable function of the latent which transforms the latent to the image space, where constraints can be directly quantified. Hence, with a differentiable constraint function or surrogate, its gradient can be leveraged to iteratively adjust the latent representation at any step of the diffusion process, ensuring constraint adherence.


\subsection{Proximal Langevin Dynamics}
% First, we extend the projected Langevin dynamics algorithm to {\it Proximal Langevin Dynamics}. Although projections may be highly effective when they can be directly imposed, in many settings, including the stable diffusion sampling process, this computation is intractable. \hl{Proximal operators generalize projection by allowing the incorporation of more complex constraint functions, thereby enabling the efficient handling of complex constraints within the Langevin dynamics framework.}
First, we generalize the projected Langevin dynamics algorithm into {\it Proximal Langevin Dynamics} to handle a wider range of constraints. Although direct projections work well when constraints can be explicitly stated, they become limited for more complex or implicit constraints. Proximal operators overcome this limitation by generalizing projections to accommodate a broader class of constraint functions, making them suitable for efficiently handling complex constraints within the Langevin dynamics framework.
% \nando{What is the connection here between "this computation is intractable" and Proximal operates [..]? }
\begin{equation}
    \label{eq:proximal-update}
    \mathbf{z}_{t}^{i+1} = \text{prox}_{\lambda \mathbf{g}(\mathbf{z_t})} \left(\mathbf{z}_{t}^{i} + \gamma_t \nabla_{\mathbf{z}_{t}^{i}} \log q(\mathbf{z}_{t}|\mathbf{z}_0) + \sqrt{2\gamma_t}\bm{\epsilon}\right),
\end{equation}
Henceforth, we will use $\mathbf{z}_{t}$ to replace $\bm{x}_{t}$ when defining the diffusion process, referring specifically to the latent representation for a stable diffusion model.
Here, the proximal operator balances maintaining similarity to the updated sample and adhering to the constraint function $\mathbf{g}$ as weighted by hyperparmeter $\lambda$. The operator is defined as: 
\begin{equation}
    \label{eq:proximal-operator}
    \text{prox}_{{\lambda \mathbf{g}(\mathbf{z_t})}} = \arg\min_{\bm{y}} \,\bigl\{ \mathbf{g}(\bm{y}) + \tfrac{1}{2\lambda}\|\bm{y} - \mathbf{z_t}\|_2^2 \bigr\}.
\end{equation}
This operation is equivalent to a projection %, which is a specific class of proximal operators, 
when $\mathbf{g}$ acts as an indicator function that evaluates to infinity if $\bm{y}$ violates the constraints and zero otherwise.


% Additionally, and importantly, even if the constraint evaluation function is not directly differentiable, if a correction can be computed, the gradient with respect to the distance function between the original and projected sample can be used as a differentiable surrogate to correct the latent. The paper explores these details as follows.

\subsection{Constraining the Sampling Process}
To extend Equation (\ref{eq:pdm}) to impose meaningful constraints throughout the stable diffusion sampling process, we redefine the input of the constraint function to take a mapping from the current sample $\mathbf{z}_t$ to a corresponding sample in the image space $\bm{x}_t$. Expressly, this transformation can be conducted via the decoder, given that $\bm{x}_t = \mathcal{D}(\mathbf{z}_t)$. Hence, our sampling optimization becomes:
\begin{subequations}
\begin{align}
    \label{eq:constrained-diffusion-g}
    \minimize{\mathbf{z}_{T}, \ldots, \mathbf{z}_1} &\;
    \sum_{t = T, \ldots, 1}- \log q(\mathbf{z}_{t}|\mathbf{z}_0) \\
    \label{eq:constrained-diffusion-constr-g}
    \textrm{s.t.:}  &\quad \mathbf{g}(\mathcal{D}(\mathbf{z}_t)) = 0,
\end{align}
\end{subequations}
where ${\cal D}$ maps the latent representation $\mathbf{z}_t$ into its original dimensions and \( \mathbf{g} := \inf_{\bm{y} \in \mathbf{C}}\|\bm{y} - \bm{x}_t  \|\).
% \nando{why g is teh defined as $||$ of C? -- this does not capture the constraint violation if we want to capture that notion, which needs to be specified by class of constraints.}
Hence, at each iteration of the diffusion process, our goal is to restore feasibility with respect to $\mathbf{g}$. 
As the constraint function can only be meaningfully represented in the image space, we instead rely on a Lagrangian dual approach to impose constraints on the latent.
Lagrangian dual methods are particularly effective here because they convert the constrained problem into an unconstrained one, which can be solved using standard gradient-based techniques. Hence, we bypass the need to explicitly correct the latent and can incorporate the feasibility restoration step within a gradient-based framework.
% gradient descent to optimize with respect to this constraint function.

% \nando{Rather than saying gradient descent, can we introduce the Lagrangian dual process here - or mention we use a primal dual inspired method? }

Importantly, the gradients of this function can be computed with regard to the latent by decoding the latent representation, allowing for evaluation of the constraint function in the image space.
Subsequently, a Lagrangian relaxation of a projection onto the feasible set can be computed by iteratively backpropogating through the frozen decoder layers.


The computational graph is constructed to facilitate corrections to the latent representation $\mathbf{z}_t$ by incorporating the constraint function into the optimization process. Gradients of the constraint function are backpropagated through the computational graph, defined as:
\begin{equation}
    \mathbf{z}_t \leftarrow \mathcal{D}(\mathbf{z}_t) = \bm{x}_t \leftarrow \mathbf{g}(\bm{x}_t) = \inf_{\bm{y} \in \mathbf{C}}\|\bm{y} - \bm{x}_t  \|
\end{equation}
Note that gradients flow from the constraint evaluation in the image space back to the latent representation $\mathbf{z}_t$, thus enabling updates to $\mathbf{z}_t$ that reduce constraint violations iteratively. % and bring it closer to satisfying the desired conditions. 
Crucially, these gradients enable us to restore feasibility in the image space while imposing these constraints directly on the latent representation.




% \begin{algorithm}[t]
% \caption{Sampler with Constraint Correction}
% \begin{algorithmic}[1]
% \Require $\text{tolerance}$: violation tolerance, $\text{lr}$: learning rate
% \Function{$\mathbf{g}$}{$\bm{x}_t$}
%     \State $\text{violation} = \mathbf{C}( \bm{x}_t )$
%     \State \Return $\text{violation}$
% \EndFunction

% % \Function{$\mathbf{g}$}{$\bm{x}_t$}
% %     \State \textellipsis \Comment{Define the constraint violation computation}
% % \EndFunction

% \For{$t \gets T$ to $0$}
%     \State \textellipsis \Comment{General sampling algorithm}

%     \While{\Call{$\mathbf{g}$}{$\mathcal{D}(\mathbf{z}_t)$} $\geq$ $\text{tolerance}$}
%         \State $loss \gets$ \Call{$\mathbf{g}$}{$\mathcal{D}(\mathbf{z}_t)$}
%         \State $g \gets \nabla_{\mathbf{z}_t} (\mathbf{z}_t, loss)$
%         \State $\mathbf{z}_t \gets \mathbf{z}_t - (g \times \text{lr})$
%     \EndWhile

% \EndFor

% \State \Return \Call{$\mathcal{D}$}{$\mathbf{z}_0$}
% \end{algorithmic}
% \label{algorithm:pseudocode}
% \end{algorithm}

\begin{algorithm}[tb]
    \caption{Sampler with Constraint Correction}
    \label{alg:sampler}
    \begin{algorithmic}[1]
    \STATE \textbf{Input:} $\epsilon$ (violation tolerance), $\text{lr}$ (learning rate)
    \STATE \textbf{Define} $\mathbf{prox}(\bm{x}_t^i)$:
        \STATE \quad $\text{violation} \gets \mathbf{g}(\bm{x}_t^i)$
        \STATE \quad $\text{distance} \gets \tfrac{1}{2\lambda}\|\bm{x}_t^i - \bm{x}_t^0\|_2^2$
        \STATE \quad \textbf{return} $\text{violation} + \text{distance}$
    \FOR{$t = T, \ldots, 0$}
        \STATE \(\dots\) \COMMENT{General sampling steps (omitted).}
        \STATE $i = 0$
        \WHILE{$\mathbf{prox}(\mathcal{D}(\mathbf{z}_t^i)) \ge \epsilon$}
            \STATE $g \gets \nabla_{\mathbf{z}_t^i} \mathbf{prox}(\mathcal{D}(\mathbf{z}_t^i))$
            \STATE $\mathbf{z}_t^{i+1} \gets \mathbf{z}_t^i - (g \times \text{lr})$
            \STATE $i = i + 1$
        \ENDWHILE
    \ENDFOR
    \STATE \textbf{return} $\mathcal{D}\bigl(\mathbf{z}_0\bigr)$
    \end{algorithmic}
    \label{algorithm:pseudocode}
\end{algorithm}



\subsection{Training-Free Correction Algorithm}

We are now ready to introduce the proposed training-free algorithm to impose constraints on $\mathbf{z}_t$ leveraging the constructed computational graph. The algorithm can be broken into an outer minimizer, which iteratively corrects $\mathbf{z}_t$, and an inner minimizer, which provides the necessary gradients for the outer minimizer.

\textbf{Outer minimizer.}
Provided the constraint set cannot be directly represented in the latent space, the proximal operator (Equation \ref{eq:proximal-operator}) must be adjusted to evaluate the constraint function of the decoded latent. 
% \textcolor{purple}{Similarly a projection cannot be computed directly on the latent (without relaxations?) so we define a distance function in the image space...}
Consequentially, we use:
\begin{equation}
\small
    \label{eq:proximal-operator-dist}
    \text{prox}_{{\lambda \mathbf{g}(\mathbf{z_t})}} = \arg\min_{\bm{y}} \,\bigl\{ \mathbf{g}(\mathcal{D}(\bm{y})) + \tfrac{1}{2\lambda}\|\mathcal{D}(\bm{y}) - \mathcal{D}(\mathbf{z_t})\|_2^2 \bigr\}.
\end{equation}
% noting that $\mathbf{g}$ remains an indicator function, effectively enforcing feasibility. 
Algorithm \ref{algorithm:pseudocode} provides a pseudo-code of applying this proximal operator (lines 9-13) within the stable diffusion sampling process. 
This follows a series of iterative updates,
\begin{equation}
    \mathbf{{z}}_t^{i+1} = \mathbf{z}_t^{i} - \nabla_{\mathbf{z}_t^{i}}  \text{prox}_{{\lambda \mathbf{g}(\mathbf{z_t^i})}}(\mathcal{D}(\mathbf{z}_t^i)),
\end{equation}
converging when the sample $\mathbf{z}_t^i$ reaches the constraint set.
Convergence is ensured under general smoothness properties of the latent space, provided that the constraint set is convex, as described in Appendix \ref{appendix:theory}.
We will subsequently refer to this corrected latent as $\hat{\mathbf{z}}_t$.
% \nando{are these convergence guaranteed? Any kind of restriction on the constraint class that should be considered here?}


% Algorithm \ref{algorithm:pseudocode} provides a pseudo-code implementation of our proposed approach to demonstrate how this method can be directly integrated into the stable diffusion sampling process. 
% Following each sampling update step, a gradient-based correction is applied to the sample to restore feasibility. The constraint function is iteratively evaluated to provide gradient updates to the latent variable $\mathbf{z}_t$ until it has been returned to the feasible region. 

\textbf{Inner minimizer.}
% \textcolor{purple}{Here, I think we only need to explain that the output of $\mathbf{g}$ is a distance metric from $\mathbf{z}_t^{i}$ to $\mathbf{\hat{z}}_t$.}
At each iteration of the outer minimizer, the objective of the proximal operator is evaluated to obtain a gradient.
% Although this proximal operator can be relaxed to satisfy problem-specific criteria (see Section \ref{subsec:copyright} \nando{expand briefly to anticipate in one line what we do in this section}), it is generally desirable to maintain $\mathbf{g}$ as an indicator function to establish strong constraint enforcement.
At this point, a projection operator \(\mathcal{P}_\mathbf{C}\) can be formulated in the image space, mapping the point $\bm{x}_t$ to the nearest point satisfying the constraints; the projection will be equivalent to Equation \ref{eq:proximal-operator-dist} if $\mathbf{g}$ is as an indicator function, allowing us to differentiate the objective of $\mathcal{P}_\mathbf{C}(\bm{x}_t)$.
Notably, this derivation captures both the constraint violation term, $\mathbf{g}(\mathcal{D}(\mathbf{z}_t))$, and the distance term, $\tfrac{1}{2\lambda}\|\mathcal{D}(\bm{y}) - \mathcal{D}(\mathbf{z_t})\|_2^2$, within the prescribed tolerance, resulting in the solution to Equation \ref{eq:proximal-operator-dist} at the end of the outer minimization.

In other cases, a projection may not be directly computable,
such as when the constraints are evaluated by an external simulator (as in Section \ref{subsec:metamaterials}) or when the constraints are too general to represent in closed-form (as in Section \ref{subsec:copyright}),
% \nando{(make examples here: for instance, [...])}, 
and in these cases, it is necessary to approximate this objective to Equation \ref{eq:proximal-operator-dist} using other approaches. 
In these cases where $\mathbf{g}$ is non-differentiable, it may be necessary to either use heuristic-based methods to approximate this projection {\it or} employ a surrogate model to approximate $\mathbf{g}$.
We discuss this further in Section \ref{sec:surrogate_constraints} and empirically validate such approaches in the subsequent section.

{\it Importantly, this corrective step cannot be generally equated to a projection of the latent.} 
We justify this deviation from the use of projections with the following rationale:
Because the nearest feasible point in the image space may not coincide with the nearest feasible point in the latent space, a projection in the image space, where we evaluate constraint adherence, may provide a different solution than a projection in the latent space without latent space smoothness assumptions \cite{guo2024smooth}.
Hence, precise projection operations can be vastly more costly than the corrective steps employed, especially provided the added complexity of differentiating through the decoder. 
% This computational overhead reduces the practicality of solving this directly. 

% Importantly, this approach does not require directly differentiating the constraint function itself, as the distance function of \(\mathcal{P}_C\) ensures that optimization remains viable.




% \begin{enumerate}
%     \item \textcolor{purple}{Mat-Sci: return $\|\bm{x}_t - \mathcal{P}_\mathbf{C}(\bm{x}_t)\|$; distance metric in the image space (matches Eq 10)}
%     \item \textcolor{purple}{Copy: return $\|PCA_{\mathcal{C}_\theta}(\bm{x}_t | y) - PCA_{\mathcal{C}_\theta}(\bm{x}_t)\|$; this one confuses me the most... }
%     \item \textcolor{purple}{Str-Str: return $\|\bm{x}_t - \hat{\bm{x}}_t\|$; distance metric in the image space (matches a relaxed approximation of Eq 10 -- eventually finds a feasible point, but perhaps the solution doesn't perfectly satisfy wrt the second term)}
% \end{enumerate}



% \textbf{Comparison to Other Methods.} 
Previous research has demonstrated that gradient-based corrections can reliably guide parametric models toward feasible solutions \cite{donti2021dc3}. Building on these findings, we propose a correction step that yields comparable convergence to the constraint set.
Importantly, our method applies these corrections exclusively in a {\it training-free} manner, as opposed to existing approaches which enforce these corrections during both training and inference.

In Appendix \cite{app:comparison} we also offer an in-depth view of the differences of this approach with respect to classifier guidance. 

% \nando{I would not have an emphasized separate paragraph to elucidate this. I would just say that gradient-based corrections have been used in differentiable optimization models to ensure that parametric optimizers converge to feasible solutions [DC3], albeit these methods typically require enforcing such corrections at both training and inference time while we operate exclusively at sampling time.}


\iffalse
Practically, the optimization resembles a variant of the Frank-Wolfe method, as the Euclidean projection is approximated by the minimization over $\mathbf{g}$.
The convergence criteria, however, differs in that traditional Frank-Wolfe methods assess convergence by the L2 distance over the latent space \(||\bm{y}_t - \mathbf{z}_t||_{2}^2\), whereas here we use the L2 distance over the image space \(||\mathcal{D}(\bm{y}_t) - \mathcal{D}(\mathbf{z}_t)||_{2}^2\).
% \fi
Importantly, {\it this corrective step cannot be directly equated to a projection of the latent} as the nearest feasible point in the image space will not necessarily be the nearest feasible point in the latent. Hence, we will subsequently refer to the corrected latent as $\hat{\mathbf{z}_t}$.
% For cases where $\mathcal{L}_{\textit{violation}}$ is differentiable, line 12 can be substituted to use this loss directly.
\fi

% \textbf{Non-differentiable constraint functions}  
% In cases where the constraint function \(\mathbf{g}\) is not directly differentiable, it is still possible to construct a surrogate function using the distance function of a projection. Specifically, a projection operator \(\mathcal{P}_C\) can be formulated in the image space, mapping the point $\bm{x}_t$ to the nearest point satisfying the constraints, can serve as the foundation for this surrogate. By leveraging the properties of \(\mathcal{P}_C\), a distance-based measure can be used to quantify how far a given point is from satisfying the constraint. Importantly, this approach does not require directly differentiating the constraint function itself, as the distance function of \(\mathcal{P}_C\) ensures that optimization remains viable. This approach is used effectively for the constraint correction in Section \ref{subsec:microstruct}, where we impose hard constraints on morphometric properties for microstructure inverse-design.
% \nando{describe the experiments to put things in context and anticipate the broader impacts of these methods}






\section{Surrogate Constraints}
\label{sec:surrogate_constraints}
% \nando{What do you think about calling these proxy-constraints or surrogate constraints rather than classifier-based constraints? I would prefer this notation and modify the text below accordingly}

% \todo{Expound on what we do for the copyright experiment. Also, add some description of how this differs from guidance schemes.}

% \color{blue}
% SZ: look at https://arxiv.org/abs/2105.05233 for classifier-guided diffusion
% \nando{HAve an intro for this section -- many desirable properties cannot be directly expressed as mathematical expressions, but can be estimated via surrogate models (e.g., PDEs, simulations, etc.). In particular we deal with the case in which these surrogates are expressable using neural network classifiers.}

% \ste{Direct mathematical representation of many desirable properties is often not feasible. To estimate these properties, surrogate models like simulations, partial differential equations (PDEs), and others are employed. Specifically, we address cases where the fulfillment of these properties is formulated via a neural network.
% We propose a classifier-based projected diffusion method that uses an external neural network to enforce class-specific constraints through targeted sample adjustments at select steps. The classifier guides the generation by projecting the sample $x_t$ onto another point in the sample space $x\text{'}_t$ that satisfies certain target constraints.
% Note that this approach is fundamentally ...}

While in the previous section we discuss how to endow mathematical properties within stable diffusion, many desirable properties cannot be directly expressed as explicit mathematical expressions. Particularly when dealing with physical simulators, heuristic-based analytics, and partial differential equations, it becomes often necessary to estimate these constraints with surrogate models. To this end, we propose a proxy constraint correction that leverages an external differentiable module to enforce constraints. 

These surrogate constraints introduce the ability to impose soft constraints that would otherwise be intractable. Specifically, we replace $\mathbf{g}(\bm{x}_t)$, the constraint evaluation function used in the optimization process, with either 
{\bf (1)} the constraint violation predicted directly by a proxy model or
{\bf (2)} a constraint violation function dependent on the surrogate model (e.g., a distance function between the target properties and the surrogate model's predictions for these properties in $\bm{x}_t$).
This allows the surrogate to directly evaluate and guide the sample’s adherence to the desired constraints at each step. Apart from this substitution, the overall algorithm remains identical to Algorithm 1. Through iterative corrections, the model {\sl converges} to a corrected sample $\hat{\mathbf{z}_t}$ that satisfies the target constraints to the extent permitted by the surrogate's predictive accuracy.
% , while preserving the generative structure of the diffusion process.





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Experiments}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The performance of our method is evaluated on domain-specific tasks, highlighting its applicability to diverse domains. Supplementary results are provided in Appendix~\ref{appendix:additional_results}


\textbf{Baselines.} Performance is benchmarked against: 
\begin{enumerate}[leftmargin=*, parsep=2pt, itemsep=2pt, topsep=0pt]
% \item {\bf Image Space Correction:} We implement a naive approach which converts the latent representation to the image space, projects the image, and then passes the feasible image through the encoder layer to return to the latent space.
\item {\bf Projected Diffusion Models (PDM):} We leverage a standard DDPM model denoising over the image space. Following \cite{christopher2024constrained}, we project at each denoising step to restore feasibility.
% \item {\bf Post-Processing Conditional Model:} Utilizing the same stable diffusion model as our method, we project only at the final step after decoding the latent.
\item {\bf Conditional Diffusion Model (Cond):} We apply a stable diffusion text-to-image framework, in order to condition the image generation using a specific prompt that embeds the target level of porosity. 
\end{enumerate}
% Computing a projection directly at each iteration of the diffusion reverse process is not possible, as the constraints cannot be meaningfully represented in the latent space.




\subsection{Microstructure Generation}
\label{subsec:microstruct}

Microstructure imaging data is critical in material science domains for discovering structure-property linkages.
However, the availability of this data is limited on account of prohibitive costs to obtain high-resolution images of these microstructures.
In this experiment, we task the model with generating samples subject to a constraint on the porosity levels of the output microstructures.
Specifically, the goal is to generate new microstructures with specified, and often previously unobserved, porosity levels from a limited dataset of microstructure materials. 

For this experiment we obtain the dataset used by \cite{christopher2024constrained}. Notably, there are two significant obstacles to using this dataset: {\it data sparsity} and {\it absence of feasible samples}. To address the former limitation, we subsample the original microstructure images to generate the dataset using $64 \times 64$ images patches that have been upscaled to $1024 \times 1024$. To the latter point, while the dataset contains many samples that fall within lower porosity ranges, it is much more sparse at higher porosities. Hence, when constraining the porosity in these cases, it is often the case that no feasible samples exist at a given porosity level.

\textbf{Inner minimizer.}
To model the proximal operator for our proposed method, we use a projection operator in the image space and optimize with respect to this objective.
Let $\bm{x^{i,j}}$ be the pixel value for row $i$ and column $j$, where $\bm{x^{i,j}} \in [-1, 1]$ for all values of $i$ and $j$. The porosity is then,
\[
    \textit{porosity} = \sum^n_{i=1} \sum^m_{j=1} \mathbbm{1}{\left( \bm{x^{i,j}} < 0 \right)},
\]
where $\mathbbm{1}(\cdot)$ is the indicator function, which evaluates to 1 if the condition inside holds and 0 otherwise.
We can then construct a projection using a top-k algorithm to return,
\begin{subequations}
\begin{align*}
    \mathcal{P}_\mathbf{C}(\bm{x}) = \argmin_{y^{i,j}} \sum_{i,j} \|y^{i,j} - \bm{x^{i,j}} \| \\
    \text{s.t. } \quad y^{i,j} \in [-1, 1], \quad \sum^n_{i=1} \sum^m_{j=1} \mathbbm{1}\left( \bm{y^{i,j}} < 0\right) = K
\end{align*}
\end{subequations}
where $K$ is the number of pixels that should be ``porous''.
Importantly, since the above program is convex, our model provides a certificate on the satisfaction of such constraints in the generated materials. We refer the interested reader to Appendix \ref{appendix:theory} for additional discussion.


\textbf{Results.}
%\todo{Here we should discuss the results, point to some figures, etc.}
A sample of the results of our experiments is presented in Figure~\ref{fig:microstructure-images}. Analyzing these results, we compare our constrained stable diffusion model with the baselines to evaluate performance across various metrics.

% The Image Space Correction method, which involves re-encoding the image into the latent space after correcting it during various denoising steps, did not produce high-quality images and significantly deviated the denoising process outside the training set distribution. This deviation is reflected by both higher FID scores and poorer empirical metrics when compared to the dataset.

% Similarly, the Learned Latent Corrector, where a network is trained to project a latent vector toward a new state ensuring constraint satisfaction, led to results that fell outside the microstructure distribution. The generated images lacked quality and did not capture the essential features of the dataset, rendering this method ineffective for this application.


Compared to the {\it Projected Diffusion Model (PDM)}, latent diffusion approaches show a significant improvement. Latent diffusion models enable higher-quality and higher-resolution images. The previous state-of-the-art PDM, which operates without latent diffusion, had an \bcol{FID more than twice as high as the models incorporating latent diffusion}. This highlights the benefits of our method in producing images that are both high-quality and adhere closely to the data distribution.

The {\it Conditional Diffusion Model}, utilizing text-to-image conditioning, demonstrated excellent adherence to the training set distribution, achieving an average FID of 10.8. However, conditioning via text prompts proved unsuitable for enforcing the porosity constraints. \bcol{On average, only 31.6$\%$ of the samples had a porosity error less than 10\%,} indicating that this method \bcol{lacks reliability in constraint satisfaction} despite its ability to match the training distribution.

% The {\it Post-Processing Corrector} framework performs unconstrained latent denoising and then modifies the final output via projection to enforce the constraints. While it guarantees satisfaction of the porosity constraint and performs well relative to the FID metric, {\bf it exhibited low microstructure realism}. 
% As shown in Figure~\ref{fig:microstructure-micrometry}, the images produced by the post-processing model exhibit a void diameter distribution significantly deviating from that of the training set, resulting in unrealistic images. This discrepancy is particularly pronounced at high porosity levels, where post-processing generates voids that are much larger than those observed in reality. 
% This behavior occurs as the samples at the end of the unconstrained denoising are often far from the target porosity. In such cases, {\bf the post-processing projection distorts the pores, leading to unrealistic pore sizes.}
% Similar results are obtained when analyzing the aspect ratio and orientation of the voids.


In contrast, our {\it Latent Constrained Model} exhibits the most optimal characteristics. \bcol{The proposed method satisfies the porosity constraints exactly, achieves an excellent FID scores, and provides the highest level of microstructure realism as assessed by the heuristic-based analysis}. This indicates that our approach effectively balances constraint satisfaction with high-quality image generation. {\it This is a significant advantage over existing baselines, as the method ensures both high-quality image generation and precise adherence to the physical constraints.}

% In conclusion, despite the higher computational expense, our constrained stable diffusion model proves to be the most effective method for generating microstructure images with strict porosity constraints. It offers significant advantages over existing baselines, ensuring both high-quality image generation and precise adherence to physical properties such as inclusion shape and size.

\begin{figure}[t!]
\begin{minipage}{0.5\textwidth}
\ra{0.25}
\setlength{\tabcolsep}{1pt}
\centering
\begin{tabular}{c cccc}
  \toprule
  \multirow{2}{*}{\footnotesize{Ground}} & \multirow{2}{*}{\footnotesize{P(\%)~~}} 
  & \multicolumn{3}{c}{\footnotesize{\bf Generative Methods}}\\[2pt]
   & &  \footnotesize{\sl Cond} &  \footnotesize{\sl PDM} & \footnotesize{\sl Latent (Ours)} \\
    \midrule
    % \includegraphics[width=0.18\columnwidth]{images/Microstructure/ground_p0.1.png} &
    % \raisebox{2\height}{\footnotesize{\sl {10~~}}} &
    % \includegraphics[width=.18\columnwidth]{images/Microstructure/cond_p0.1.png} &
    % % \includegraphics[width=.16\columnwidth]{images/Microstructure/post_proc_p0.1.png} &
    % \includegraphics[width=.18\columnwidth]{images/Microstructure/pdm_p0.1.png} &
    % \includegraphics[width=.18\columnwidth]{images/Microstructure/latent_cons_last3_p0.1.png} \\

    \includegraphics[width=0.19\columnwidth]{images/Microstructure/ground_p0.3.png} &
    \raisebox{2\height}{\footnotesize{\sl {30~~}}} &
    \includegraphics[width=.19\columnwidth]{images/Microstructure/cond_p0.3.png} &
    % \includegraphics[width=.16\columnwidth]{images/Microstructure/post_proc_p0.3.png} &
    \includegraphics[width=.19\columnwidth]{images/Microstructure/pdm_p0.3.png} &
    \includegraphics[width=.19\columnwidth]{images/Microstructure/latent_cons_last3_p0.3.png} \\

    \includegraphics[width=0.19\columnwidth]{images/Microstructure/ground_p0.5.png} &
    \raisebox{2\height}{\footnotesize{\sl {50~~}}} &
    \includegraphics[width=.19\columnwidth]{images/Microstructure/cond_p0.5.png} &
    % \includegraphics[width=.16\columnwidth]{images/Microstructure/post_proc_p0.5.png} &
    \includegraphics[width=.19\columnwidth]{images/Microstructure/pdm_p0.5.png} &
    \includegraphics[width=.19\columnwidth]{images/Microstructure/latent_cons_last3_p0.5.png} \\[2pt]
    \midrule
    \multicolumn{2}{l}{{\bf \footnotesize{FID scores:}}} & {\bf \scriptsize{10.8 $\!\pm\!$ 0.9}} & \scriptsize{30.7 $\!\pm\!$ 6.8} & \scriptsize{13.5 $\!\pm\!$ 3.1}\\ \\
    \multicolumn{2}{l}{{\bf \footnotesize{P error $>$ 10\%:}}} & \scriptsize{68.4$\%$ $\!\pm\!$ 12.4} & {\bf \scriptsize{0$\%$ $\!\pm\!$ 0}} & {\bf \scriptsize{0$\%$ $\!\pm\!$ 0}}\\
    \bottomrule
\end{tabular}
\caption{Comparison of model performance in terms of FID score and constraint satisfaction (percentage of samples that does not satisfy the target porosity with a margin of 10$\%$).}
\label{fig:microstructure-images}
\end{minipage}
\end{figure}

% \nando{Can we zoom in the region of interest (0 - 0.3) of Figure 2? }
% \ste{Figure updated}

\begin{figure}[t!]
\begin{minipage}{0.5\textwidth}
\ra{0.25}
\setlength{\tabcolsep}{1pt}
\centering
\begin{tabular}{c|c}
  \toprule
   \multicolumn{2}{c}{\footnotesize{\bf Voids diameter distribution}}\\[2pt]
   \midrule
    \footnotesize{\sl {P = 30\%~~}}  & 
    \footnotesize{\sl {P = 50\%~~}}\\
    \includegraphics[width=.425\columnwidth]{images/Microstructure/d_void_0.3.png} &
    \includegraphics[width=.425\columnwidth]{images/Microstructure/d_void_0.5.png}\\
    \midrule
    \multicolumn{2}{c}{\bf \footnotesize{MSE w.r.t. Ground}} \\ 
    \midrule
    [2pt] \footnotesize{Cond: 1.58} & \footnotesize{Cond: 0.31} \\
    [2pt] \footnotesize{\bf Ours: 0.47} & \footnotesize{\bf Ours: 0.12} \\ 
    \bottomrule
\end{tabular}
% \begin{tabular}{lc|c}
%     \multirow{2}{*}{\rotatebox{90}{\bf \footnotesize{MSE}}}
%      & [2pt] \footnotesize{Cond: 1.58} & \footnotesize{Cond: 0.31} \\ 
%      & [2pt] \footnotesize{Ours: 0.47} & \footnotesize{Ours: 0.12} \\ 
% \end{tabular}
\caption{Distribution of void diameters in the training set (Ground) and in data generated by Conditional diffusion model and Latent Constrained Diffusion models.}
\label{fig:microstructure-micrometry}
\end{minipage}
\end{figure}
 
% \subsection{Metamaterial Inverse-Design}
% \label{subsec:phys-inform}
% \todo{Here we should described the experiment, discuss the results, etc. (if this is completed prior to CVPR)}





\subsection{Metamaterial Inverse Design}
\label{subsec:metamaterials}
% \textcolor{purple}{General description of the problem setting...}
Now, we demonstrate the efficacy of our method for inverse-design of mechanical metamaterials with specific nonlinear stress-strain behaviors. 
Achieving desired mechanical responses necessitates precise control over factors such as buckling, contact interactions, and large-strain deformations, which are inherently nonlinear and sensitive to small variations in design parameters. Traditional design approaches often rely on iterative trial-and-error methods, which can be time-consuming and may not guarantee optimal solutions.

Specifically, our task is to generate mechanical metamaterials that closely match a target stress-strain response.
We obtain a dataset of periodic stochastic cellular structures subjected to large-strain compression from \citet{bastek2023inverse}. This dataset includes full-field data capturing complex phenomena such as buckling and contact interactions. 
Because the problem is invariant with respect to length scale, the geometric variables can be treated as dimensionless. The stress is expressed in megapascals (MPa).

Exact constraint evaluation requires the use of {\it an external, non-differentiable simulator} $\phi$.
To compute the ground truth results for the stress-strain response, we employ Abaqus \cite{borgesson1996abaqus}, using this simulator both for our correction steps and for validation of the accuracy of the generations.



\iffalse
To integrate the non-differentiable simulator into the inner minimizer, we leverage a particle swarm optimization (PSO) algorithm to approximate the projection operator.
PSO operates by initializing a swarm of particles (candidate solutions) that explore the search space. Each particle adjusts its position based on its own experience and the experience of neighboring particles, converging towards optimal solutions over iterations.
By utilizing PSO, we approximate the projection operator without requiring gradient information, making it suitable for scenarios where traditional gradient-based methods are inapplicable due to non-differentiability.
When we have converged to the approximation of the projection, the outer minimizer can optimize with respect to the distance function between $\mathbf{z}_t$ and $\mathbf{\hat{z}}_t$.
\fi
\textbf{Inner minimizer.}
To incorporate the non-differentiable simulator into the inner minimization process, we employ a {\it differentiable perturbed optimizer (DPO)} to approximate the projection operator \cite{berthet2020learning, mandi2024decision}. 
% This approach enables the seamless integration of non-differentiable components into differentiable frameworks, facilitating end-to-end optimization.
DPO operates by introducing controlled perturbations to the optimization variables and subsequently smoothing the objective function. This process involves adding random local perturbations to the input parameters, evaluating the simulator's output, and applying a smoothing function to approximate gradients.
By doing so, we can compute approximate gradients of the non-differentiable simulator, using a continuously differentiable Monte Carlo estimate,
\begin{equation*}
    \mathbf{\bar{\phi}_\epsilon}(\bm{x}_t) = \frac{1}{M} \sum^M_{m=1} \mathbf{\phi}\left(\bm{x}_t + \epsilon\eta^{(m)}\right)
\end{equation*}
where $\phi$ is our external simulator, $\mathbf{\phi}(\bm{x}_t+\epsilon\eta)$ is a sample drawn from the Monte Carlo estimated distribution $\mathbf{\bar{\phi}_\epsilon}(\bm{x}_t)$, $M$ is the number of perturbed samples generated for the estimate (we set $M = 10$), and $\epsilon$ scales the perturbations. We then differentiate with respect to this Monte Carlo estimate to formulate the loss:
\begin{equation*}
    \nabla_{\bm{x}_t} \mathcal{L} \left(\mathbf{\phi}\left(\bm{x}_t\right)\right) = -\left(\bar{\mathbf{\phi}}_\epsilon\left( \bm{x}_t\right) - \textit{target} \right)
\end{equation*}

By utilizing this method, we estimate the projection operator using the solution provided by the Monte Carlo estimate, making it suitable for scenarios where traditional gradient-based methods are inapplicable due to non-differentiability. 
Once we have converged to the approximation of the projection, the outer minimizer can optimize with respect to the distance function between $\mathbf{z}_t$ and $\mathbf{\hat{z}}_t$.


\textbf{Results.}
% \textcolor{purple}{Summary of results...}
We illustrate the DPO process for our \textit{Latent Constrained Model} in Figure~\ref{fig:metamaterial-images}.
Firstly, note that our method facilitates the reduction of error tolerance in our projection to arbitrarily low levels.
By performing additional iterations of the DPO, we can progressively refine the projection operator's approximation, thereby enhancing its accuracy. 
Moreover, the integration of the simulator into the optimization loop enables the model to extrapolate and generalize beyond the confines of the existing dataset. We highlight this unique feature in Figure~\ref{fig:metamaterial-extrap-ex}.

Practically, one can select an error tolerance and compute budget for tailored for the specific application. Each iteration of the DPO necessitates approximately 30 seconds of computational time. Given our prescribed error tolerance, convergence is achieved within five iterations, culminating in a total computational duration of approximately 2.5 minutes per optimization run. 
Additionally, note that $\phi$ has not been optimized for runtime, operating exclusively on CPU cores.

Due to the complexity of the stress-strain response constraints in this problem, other constraint-aware methods (i.e. Projected Diffusion Models) are inapplicable, and, hence, our analysis focuses on the performance of \textit{Conditional Diffusion Model} baselines. 
We compare to
{\bf (1)} an unconstrained stable diffusion model identical to the one used for our method and
{\bf (2)} state-of-the-art method proposed by \citet{bastek2023inverse}, which operates in the video space. 
% \ste{We have also a prompt-conditional model as a baseline. See Fig 7} 
While our approach optimizes samples to arbitrary levels of precision, we observe that these baselines exhibit high error bounds relative to the target stress-strain curves that are unable to be further optimized. 
As shown in Table~\ref{tab:metamaterial-results}, with five DPO steps \bcol{our method provides a {\bf 4.6x improvement} over the state-of-the-art model by \citet{bastek2023inverse} and a {\bf 5.1x improvement} over the conditional stable diffusion model} in MSE between the predicted structure stress-strain response and the target response.
{\it These results empirically demonstrate the efficacy of our approach for inverse-design problems, as we greatly surpass the performance of conditional models in generating samples that adhere to the target properties.}

% \renewcommand{\arraystretch}{1.5}
\begin{table}[t!]
\begin{minipage}{0.5\textwidth}
\ra{0.25}
\setlength{\tabcolsep}{10pt}
\noindent\fboxsep=0pt
\noindent\fboxrule=0.26pt
\centering
% \resizebox{\textwidth}{!}{
\begin{tabular}{l @{\hspace{.2cm}} cccc}
    \toprule
    \footnotesize{Model} &
    \footnotesize{MSE $[\downarrow]$} & 
    \footnotesize{\sl \shortstack{Fraction of physically \\ invalid shapes $[\downarrow]$}} \\
    \midrule
    \footnotesize{\sl \shortstack{\small Cond}} & 
    \footnotesize{7.1 $\!\pm\!$ 4.5} & \footnotesize{55$\%$} \\
    \midrule
    \footnotesize{\sl \shortstack{\small \citeauthor{bastek2023inverse}}} &
    \footnotesize{6.4 $\!\pm\!$ 4.6} & \footnotesize{20$\%$} \\
    \midrule
    \footnotesize{\sl \shortstack{\small Latent (Ours)}} & {\bf \footnotesize{1.4 $\!\pm\!$ 0.6}} & {\bf \footnotesize{5$\%$}} \\
    \bottomrule
\end{tabular}
% }
\caption{Comparison of MSE with respect to the target stress-strain response and rejection rate of shapes deemed physically inconsistent.}
\label{tab:metamaterial-results}
\end{minipage}
\end{table}

% \begin{itemize}
% \item we can reduce tolerance of error arbitrarily. 
% \item we can extrapolate and generalize because we work with a simulator in the loop we can reach curves that did not exist in the dataset. 
% \item Abaqus -- [30 sec.] x 5 iterations
% \end{itemize}








\iffalse
\begin{figure}[t!]
\begin{minipage}{0.5\textwidth}
\ra{0.25}
\setlength{\tabcolsep}{1pt}
\noindent\fboxsep=0pt
\noindent\fboxrule=0.26pt
\centering
\begin{tabular}{c ccccc}
    \toprule
    \footnotesize{Original} & 
    \footnotesize{Step 0} &
    \footnotesize{Step 1} & 
    \footnotesize{Step 2} & 
    \footnotesize{Step 3} & 
    \footnotesize{Step 4} \\
    
    \midrule
    \fbox{\includegraphics[width=0.12\columnwidth]{images/Metamaterials/original.png}} &
    \fbox{\includegraphics[width=0.12\columnwidth]{images/Metamaterials/0.png}} & \fbox{\includegraphics[width=.12\columnwidth]{images/Metamaterials/1.png}} &
    \fbox{\includegraphics[width=.12\columnwidth]{images/Metamaterials/2.png}} &
    \fbox{\includegraphics[width=.12\columnwidth]{images/Metamaterials/3.png}} &
    \fbox{\includegraphics[width=.12\columnwidth]{images/Metamaterials/4.png}} \\
    \midrule
    
    \includegraphics[width=0.12\columnwidth]{images/Metamaterials/orig_0.png} &
    \includegraphics[width=0.12\columnwidth]{images/Metamaterials/step0_0.png} &    \includegraphics[width=.12\columnwidth]{images/Metamaterials/step1_0.png} &
    \includegraphics[width=.12\columnwidth]{images/Metamaterials/step2_0.png} &
    \includegraphics[width=.12\columnwidth]{images/Metamaterials/step3_0.png} &
    \includegraphics[width=.12\columnwidth]{images/Metamaterials/step4_0.png} \\

    \includegraphics[width=0.12\columnwidth]{images/Metamaterials/orig_1.png} &
    \includegraphics[width=0.12\columnwidth]{images/Metamaterials/step0_1.png} &    \includegraphics[width=.12\columnwidth]{images/Metamaterials/step1_1.png} &
    \includegraphics[width=.12\columnwidth]{images/Metamaterials/step2_1.png} &
    \includegraphics[width=.12\columnwidth]{images/Metamaterials/step3_1.png} &
    \includegraphics[width=.12\columnwidth]{images/Metamaterials/step4_1.png} \\
    
    \includegraphics[width=0.12\columnwidth]{images/Metamaterials/orig_6.png} &
    \includegraphics[width=0.12\columnwidth]{images/Metamaterials/step0_5.png} &    \includegraphics[width=.12\columnwidth]{images/Metamaterials/step1_5.png} &
    \includegraphics[width=.12\columnwidth]{images/Metamaterials/step2_5.png} &
    \includegraphics[width=.12\columnwidth]{images/Metamaterials/step3_5.png} &
    \includegraphics[width=.12\columnwidth]{images/Metamaterials/step4_5.png} \\
    
    \includegraphics[width=0.12\columnwidth]{images/Metamaterials/orig_10.png} &
    \includegraphics[width=0.12\columnwidth]{images/Metamaterials/step0_10.png} &    \includegraphics[width=.12\columnwidth]{images/Metamaterials/step1_10.png} &
    \includegraphics[width=.12\columnwidth]{images/Metamaterials/step2_10.png} &
    \includegraphics[width=.12\columnwidth]{images/Metamaterials/step3_10.png} &
    \includegraphics[width=.12\columnwidth]{images/Metamaterials/step4_10.png} \\
    
    \midrule   
    \includegraphics[width=0.14\columnwidth]{images/Metamaterials/orig_curve.png} &
    \includegraphics[width=0.14\columnwidth]{images/Metamaterials/step_0_curve.png} &    \includegraphics[width=.14\columnwidth]{images/Metamaterials/step_1_curve.png} &
    \includegraphics[width=.14\columnwidth]{images/Metamaterials/step_2_curve.png} &
    \includegraphics[width=.14\columnwidth]{images/Metamaterials/step_3_curve.png} &
    \includegraphics[width=.14\columnwidth]{images/Metamaterials/step_4_curve.png} \\ [2pt]
    \midrule
    {\bf \footnotesize{MSE:}} & \scriptsize{} & \scriptsize{} & \scriptsize{} & \scriptsize{} & \scriptsize{}\\ 
    \bottomrule
\end{tabular}
\caption{Several successive steps of Particle Swarm Optimization are shown. At each stage, a swarm of perturbed shapes is generated, each undergoing structural analysis with Abaqus, which provides the corresponding stress-strain curve. The perturbation that produces the curve closest to the target is then selected, and a new perturbation-structural analysis-selection cycle begins, continuing until convergence is achieved. The convergence tolerance can be tightened as desired, provided it is compatible with the available computational cost.}
\label{fig:microstructure-images}
\end{minipage}
\end{figure}
\fi

\begin{figure}[t!]
\begin{minipage}{0.5\textwidth}
\ra{0.25}
\setlength{\tabcolsep}{1pt}
\noindent\fboxsep=0pt
\noindent\fboxrule=0.26pt
\centering
\begin{tabular}{c ccc}
    \toprule
    \footnotesize{Original} & 
    \footnotesize{Step 0} &
    \footnotesize{Step 2} & 
    \footnotesize{Step 4} \\
    
    \midrule
    \fbox{\includegraphics[width=0.16\columnwidth]{images/Metamaterials/original.png}} &
    \fbox{\includegraphics[width=.16\columnwidth]{images/Metamaterials/0.png}} &
    \fbox{\includegraphics[width=.16\columnwidth]{images/Metamaterials/2.png}} &
    \fbox{\includegraphics[width=.16\columnwidth]{images/Metamaterials/4.png}} \\
    \midrule
    \multicolumn{4}{c}
    {\bf \footnotesize{Structural analysis}} \\
    
    \includegraphics[width=0.18\columnwidth]{images/Metamaterials/orig_0.png} &
    \includegraphics[width=.18\columnwidth]{images/Metamaterials/step0_0.png} &
    \includegraphics[width=.18\columnwidth]{images/Metamaterials/step2_0.png} &
    \includegraphics[width=.18\columnwidth]{images/Metamaterials/step4_0.png} \\

    \includegraphics[width=0.18\columnwidth]{images/Metamaterials/orig_1.png} &
    \includegraphics[width=.18\columnwidth]{images/Metamaterials/step0_1.png} &
    \includegraphics[width=.18\columnwidth]{images/Metamaterials/step2_1.png} &
    \includegraphics[width=.18\columnwidth]{images/Metamaterials/step4_1.png} \\
    
    \includegraphics[width=0.18\columnwidth]{images/Metamaterials/orig_5.png} &
    \includegraphics[width=.18\columnwidth]{images/Metamaterials/step0_5.png} &
    \includegraphics[width=.18\columnwidth]{images/Metamaterials/step2_5.png} &
    \includegraphics[width=.18\columnwidth]{images/Metamaterials/step4_5.png} \\
    
    \includegraphics[width=0.18\columnwidth]{images/Metamaterials/orig_10.png} &
    \includegraphics[width=.18\columnwidth]{images/Metamaterials/step0_10.png} &
    \includegraphics[width=.18\columnwidth]{images/Metamaterials/step2_10.png} &
    \includegraphics[width=.18\columnwidth]{images/Metamaterials/step4_10.png} \\
    
    \midrule      
    \multicolumn{4}{c}{\bf \footnotesize{Stress-strain curves}} \\[2pt]
    \includegraphics[width=0.22\columnwidth]{images/Metamaterials/orig_curve.png} &
    \includegraphics[width=.22\columnwidth]{images/Metamaterials/step_0_curve.png} &
    \includegraphics[width=.22\columnwidth]{images/Metamaterials/step_2_curve.png} &
    \includegraphics[width=.22\columnwidth]{images/Metamaterials/step_4_curve.png} \\ 
    \multicolumn{4}{c}{\includegraphics[width=.6\columnwidth]{images/Metamaterials/curves_legend.png}} \\[2pt]
    \midrule
    \multicolumn{4}{c}
    {\bf \footnotesize{MSE} $[\downarrow]$} \\[2pt] \footnotesize{179.5} & \footnotesize{175.6} & \footnotesize{12.5} & \footnotesize{1.2}\\ 
    \bottomrule
\end{tabular}
\caption{Several successive steps of DPO are shown. At each stage, $M$ perturbed shapes are generated, each undergoing structural analysis with $\phi$, which provides the corresponding stress-strain curve. 
% The perturbation that produces the curve closest to the target is then selected, and a new perturbation-structural analysis-selection cycle begins, continuing until convergence is achieved. The convergence tolerance can be tightened as desired, provided it is compatible with the available computational cost.
}
\label{fig:metamaterial-images}
\end{minipage}
\end{figure}

\iffalse
\begin{figure}[t!]
\begin{minipage}{0.5\textwidth}
\ra{0.25}
\setlength{\tabcolsep}{1pt}
\noindent\fboxsep=0pt
\noindent\fboxrule=0.26pt
\centering
\begin{tabular}{ccc ccc}
    \toprule
    \multicolumn{3}{c}
    {\bf \footnotesize{Interpolation}} &
    \multicolumn{3}{c}
    {\bf \footnotesize{Extrapolation}} \\[2pt]
    \multicolumn{3}{c}{\includegraphics[width=0.2\columnwidth]{images/Metamaterials/int.png}} &
    \multicolumn{3}{c}{\includegraphics[width=0.2\columnwidth]{images/Metamaterials/ext.png}} \\
    \midrule
    \footnotesize{Shape} & 
    \footnotesize{Stress curve} &
    \footnotesize{MSE} &
    \footnotesize{Shape} & 
    \footnotesize{Stress curve} &
    \footnotesize{MSE} \\
    
    \midrule
    \fbox{\includegraphics[width=0.112\columnwidth]{images/Metamaterials/4.png}} &
    \fbox{\includegraphics[width=0.18\columnwidth]{images/Metamaterials/Int_proj.png}} &
    \raisebox{2\height}{\footnotesize{\sl {1.3~~}}} &  
    \fbox{\includegraphics[width=.112\columnwidth]{images/Metamaterials/Projected_extrap.png}} &   \fbox{\includegraphics[width=.18\columnwidth]{images/Metamaterials/Ext_proj.png}} &
    \raisebox{2\height}{\footnotesize{\sl {78.3~~}}} \\
    \fbox{\includegraphics[width=0.112\columnwidth]{images/Metamaterials/Conditional_interp.png}} &
    \fbox{\includegraphics[width=0.18\columnwidth]{images/Metamaterials/Int_cond.png}} &
    \raisebox{2\height}{\footnotesize{\sl {7.0~~}}} &    \fbox{\includegraphics[width=.112\columnwidth]{images/Metamaterials/Conditional_extrap.png}} &
    \fbox{\includegraphics[width=.18\columnwidth]{images/Metamaterials/Ext_cond.png}} &
    \raisebox{2\height}{\footnotesize{\sl {127.3~~}}} \\
    \fbox{\includegraphics[width=0.112\columnwidth]{images/Metamaterials/Nature_interp.png}} &
    \fbox{\includegraphics[width=0.18\columnwidth]{images/Metamaterials/Int_nat.png}} &
    \raisebox{2\height}{\footnotesize{\sl {9.2~~}}} &    \fbox{\includegraphics[width=.112\columnwidth]{images/Metamaterials/Nature_extrap.png}}
    &    \fbox{\includegraphics[width=.18\columnwidth]{images/Metamaterials/Ext_nat.png}} &
    \raisebox{2\height}{\footnotesize{\sl {99.6~~}}} \\
    \bottomrule
\end{tabular}
\caption{The figure illustrates the performance of different models in interpolation (i.e., when the target curve falls within the stress range covered by the training set) and in extrapolation (i.e., when the target is outside this range). In addition to the proposed model, a conditional Stable Diffusion model and a conditional Video Stable Diffusion model \cite{bastek2023inverse} are shown. The proposed model allows for arbitrarily small tolerance settings and outperforms the baselines in both tests.}
\label{fig:metamaterial-extrap}
\end{minipage}
\end{figure}
\fi





\begin{figure*}[t!]
\begin{minipage}{0.65\textwidth}
\ra{0.25}
\setlength{\tabcolsep}{1pt}
\centering
\begin{tabular}{c cccc}
  \toprule
   \multicolumn{5}{c}{\footnotesize{\bf Denoising process}}\\[2pt]
     & \footnotesize{\sl 25 $\%$} & \footnotesize{\sl 50 $\%$} & \footnotesize{\sl 75 $\%$} & \footnotesize{\sl 100 $\%$} \\
    \midrule
    \raisebox{2.5\height}{\footnotesize{\sl Cond }} & \includegraphics[width=.16\columnwidth]{images/Copyright/copyright_step_6_orig.png} &
    \includegraphics[width=.16\columnwidth]{images/Copyright/copyright_step_12_orig.png} &
    \includegraphics[width=.16\columnwidth]{images/Copyright/copyright_step_18_orig.png} &
    \includegraphics[width=.16\columnwidth]{images/Copyright/copyright_step_24_orig.png} \\ 

    \raisebox{2.5\height}{\footnotesize{\sl Latent (Ours) }} & \includegraphics[width=.16\columnwidth]{images/Copyright/copyright_step_6_proj.png} &
    \includegraphics[width=.16\columnwidth]{images/Copyright/copyright_step_12_proj.png} &
    \includegraphics[width=.16\columnwidth]{images/Copyright/copyright_step_18_proj.png} &
    \includegraphics[width=.16\columnwidth]{images/Copyright/copyright_step_24_proj.png} \\
    \bottomrule
\end{tabular}
\label{fig:copyright-denoising}
\end{minipage}
\begin{minipage}{0.35\textwidth}
\vspace{0pt}\hspace{-30pt}
\includegraphics[width=1.1\textwidth]{images/Copyright/projection.png}
\end{minipage}
\caption{{\bf Left:} Comparison between denoising process of the original and corrected images. {\bf Right:} Representation of the correction process in the PCA-2 space. The sample, initially closer to the `Mickey Mouse' cluster is corrected toward the `Jerry' cluster while retaining the background and other aesthetic components of the image as much as possible.}
\label{fig:copyright-projection}
\end{figure*}

\subsection{Copyright-Safe Generation}
\label{subsec:copyright}
Next, we explore the applicability of the proposed method for satisfying surrogate constraints. 
An important challenge for safe deployment of generative models is mitigating the risk of generating outputs which closely resemble copyrighted material. 
For this setting, a pretrained proxy model is fine-tuned to determine whether the generation infringes upon existing copyrighted material. This model has been calibrated so that the output logits can be directly used to evaluate the likelihood that the samples resemble existing protected material. Hence, by minimizing this surrogate constraint function, we directly minimize the likelihood that the output image includes copyrighted material.

To implement this, we define a permissible threshold for the likelihood function captured by the classifier. A balanced dataset of 8,000 images is constructed to fine-tune the classifier and diffusion models. Here, we use cartoon mouse characters `Jerry,' from {\it Tom and Jerry}, and copyright-protected character `Mickey Mouse'. When fine-tuning the diffusion model, we do not discriminate between these two characters, but the classifier is tuned to identify `Mickey Mouse' as a copyrighted example.



% An initial attempt tried to project the noisy samples toward feasible samples by minimizing the difference between the target probability and the predicted one. However, this method did not prove to be effective. We noticed that increasing the number of dimensions considered yielded better results.

\textbf{Inner minimizer.}
Our correction step begins by performing Principal Component Analysis (PCA) on the 512 features input to the last layer and selecting the two principal components. 
This analysis yields two well-defined clusters corresponding to the class labels.
Provided this, we formulate a correction by iteratively driving the noisy samples toward the centroid of the target cluster, as illustrated in Figure~\ref{fig:copyright-projection} (right).
During the early stages of the denoising process, if the classifier assigns a high probability to the sample being `Mickey Mouse,' we correct the sample toward the `Jerry' cluster in the feature space. Specifically, we iteratively adjust the sample until its distance from the `Jerry' cluster falls below a predefined threshold. This correction is achieved by minimizing the distance between the sample's feature representation and the centroid of the `Jerry' cluster, effectively guiding the generation process away from the copyrighted class label.

After this correction, the denoising process is allowed to evolve naturally without further intervention. This method ensures that the generated images are guided away from resembling copyrighted material while still allowing the model to produce high-quality outputs. By selectively modifying the generated content during the initial stages of denoising, we can effectively prevent the model from producing images that infringe on copyrights without significantly affecting the overall image quality.


\textbf{Results.}
Figure~\ref{fig:copyright-projection} (right) illustrates the correction path that occurs during the initial stages of denoising. Once the correction is completed, the denoising process proceeds freely, as shown in Figure~\ref{fig:copyright-projection} (left), where we compare the evolution of the original sample and that of the corrected sample.

We implement a \textit{Conditional Diffusion Model} baselines using and unconstrained stable diffusion model identical to the one used for our method. {\it The conditional baseline generates the protected cartoon character (Mickey Mouse) {\bf 33\% of the time}, despite conditioning it against these generations.}

Conversely, our \textit{Latent Constrained Model} only generates the protected cartoon character {\bf 10\% of the time}, aligning with the expected bounds of the classifier's predictive accuracy.
Our method has proven to be highly effective because it \bcol{preserves the generative capabilities of the model while imposing the defined constraints.} Notably, the difference between the original image and the corrected one primarily affects the areas near the figure that violate the constraint, while the rest of the image remains largely unchanged. The FID scores of the generated images, increasing only slightly from 61.2 to 65.1, remain largely unaltered by the gradient-based correction. {\it This demonstrates that our approach can selectively modify generated content to avoid copyrighted material without compromising overall image quality.}


\section{Related Work}

\textbf{Conditional diffusion guidance.}
Conditional diffusion models have emerged as a powerful tool to guide generative models toward specific tasks. Classifier-based \cite{dhariwal2021diffusion} and classifier-free \cite{ho2022classifier} conditioning methods have been employed to frame higher-level constraints for inverse design problems \cite{chung2022diffusion, chung2022score, wang2023diffusebot, bastek2023inverse} and physically grounding generations \cite{carvalho2023motion, carvalho2024motion, yuan2023physdiff}.
\citeauthor{rombach2022high} extended conditional guidance to stable diffusion models via class-conditioning, allowing similar guidance schemes to be applied for latent generation. 
However, while conditioning based approaches can effectively capture class-level specifications, they are largely ineffective when lower-level properties need to be satisfied (as demonstrated in Section \ref{subsec:microstruct}).


\textbf{Training-free diffusion guidance.}
Similar to classifier-based conditioning, training-free guidance approaches leverage an external classifier to guide generations to satisfy specific constraints.
Juxtaposed to classifier-based conditioning, and the method proposed in this paper, training-free guidance leverages {\it off-the-shelf} classifiers which have been trained exclusively on clean data. Several approaches have been proposed which incorporate slight variations of training-free guidance to improve constraint adherence \cite{yu2023freedom, mo2024freecontrol, he2023manifold, bansal2023universal}.
\citeauthor{ye2024tfg} compose a unified view of these methods, detailing search strategies to optimize the implementation of this paradigm.
\citeauthor{huang2024constrained} improve constraint adherence by introducing a ``trust schedule'' that increases the strength of the guidance as the reverse process progresses but remain unable to exactly satisfy the constraint set, even within the statistical bounds of the employed classifier. Importantly, training-free guidance approaches suffer from two significant shortcomings. First, this paradigm exhibits worse performance than classifier-based guidance as the off-the-shelf classifiers provide inaccurate gradients at higher noise levels. Second, like classifier-based guidance, these guidance schemes are ineffective in satisfying lower-level constraints




\textbf{Post-processing optimization.}
When strict constraints are required, diffusion outputs are frequently used as initial guesses for a subsequent constrained optimization procedure. This approach has been shown to be particularly advantageous in non-convex scenarios where the initial starting point strongly influences convergence to a feasible solution \cite{power2023sampling}. Other methods incorporate optimization objectives directly into the diffusion training process, essentially framing the post-processing optimization steps as an extension of the generative model \cite{giannone2023aligning, maze2023diffusion}. However, these methods rely on a succinctly formulated objective and therefore often remain effective only for niche problems—such as constrained trajectory optimization—limiting their applicability to a wider set of generative tasks. Furthermore, post-processing steps are agnostic to the original data distribution, and, hence, the constraint correction steps often results in divergence from this distribution altogether. This has been empirically demonstrated in previous studies on constrained diffusion model generation \cite{christopher2024constrained}.

\textbf{Hard constraints for generative models.}  
\citet{frerix2020homogeneous} proposed an approach to impose hard constraints on autoencoder outputs by scaling the generated data so that feasibility is enforced, but this solution is limited to simple linear constraints. \citet{liu2024mirror} introduced “mirror mappings” to handle constraints, though their method applies solely to familiar convex constraint sets. Given the complex constraints examined in this paper, neither of these strategies was suitable for our experiments. Alternatively, \citet{fishman2023diffusion, fishman2024metropolis} extended the classes of constraints that can be handled, but their approach is demonstrated only for trivial predictive tasks with MLPs where constraints can be represented as convex polytopes. This confines their method to constraints approximated by simple geometric shapes, such as L2-balls, simplices, or polytopes. \citeauthor{christopher2024constrained} generalizes constrained diffusion models to arbitrary constraint sets, but, like the other methods for hard constraint imposition discussed, their work is not extended to stable diffusion models.




\section{Conclusion}
This paper provides the first work integrating constrained optimization into the sampling process of stable diffusion models.
This intersection enables the generation of outputs that both resemble the training distribution and adhere to task-specific constraints. 
By leveraging differentiable constraint evaluation functions within a constrained optimization framework, the proposed method ensures the feasibility of generated samples while maintaining high-quality synthesis. Experimental results in material science and safety-critical domains highlight the model's ability to meet strict property requirements and mitigate risks, such as copyright infringement. 
This approach paves the way for broader and more responsible applications of diffusion models in domains where strict adherence to constraints is paramount.

\newpage
% \section*{Impact Statement}
% This paper presents work whose goal is to advance the field of 
% Machine Learning. There are many potential societal consequences 
% of our work, none which we feel must be specifically highlighted here.

\section*{Acknowledgments}
This research is partially supported by NSF grants 2334936, 2334448, and NSF CAREER Award 2401285. 
% Fioretto is also supported by an Amazon Research Award and a Google Research Scholar Award. 
The authors acknowledge Research Computing at the University of Virginia for providing computational resources that have contributed to the results reported within this paper. 
The views and conclusions of this work are those of the authors only.


\section*{Contributions}
FF and JC conceived the idea and developed the initial methods. SZ and JC implemented the algorithms, contributed to discussions, and refined the research direction. SZ conducted the experiments and analysis, while JC contributed to theoretical development and additional experiments. FF provided overall guidance and coordination. JC, FF, and SZ co-wrote the paper. LO and DA funded SZ’s visit to FF’s lab.

\bibliography{aaai}
\bibliographystyle{icml2025}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix
\onecolumn


\iffalse
\section{Future Work and Limitation}


\textbf{Classifier-based constraints.}
Section \ref{subsec:copyright} motivates the use of classifier-based constraints for stable diffusion models. While we illustrate one potential use case of this approach, we hold that this can generalize to arbitrary properties that can be captured using a classifier. 
We defer more rigorous comparison to classifier guidance \cite{ho2020denoising} and classifier-free guidance \cite{ho2022classifier} for future work.

\textbf{Stable video generation.}
While there many exciting applications for using this approach for scientific and safety-critical domains when generating data in the image space, many more applications will be enabled by extending this work to video diffusion models. While we compare to video diffusion baselines in Section \ref{subsec:metamaterials}, our training-free correction algorithm is only applied to stable image diffusion models. The introduction of temporal constraints over video frames holds significant potential that we plan to investigate in subsequent studies.


\textbf{Integration of external simulators.}
This paper motivates future study of embedding non-differentiable simulators within generative process. \citet{yuan2023physdiff} previously proposed the inclusion of physics-based simulators to augment diffusion generations, but in their case, differentiability was not considered as their simulation used a reinforcement-learning environment to directly return a modified version of the noisy sample $\bm{x}_t$. More often, external simulators are used to provide a measure of constraint satisfaction rather than to transform a sample. The techniques explored in this paper provide a vastly more general framework for incorporating these black-box simulators as a differentiable components of the sampling process and, hence, opens the door for the integration of increasingly complex constraints. Further use cases will be explored in consecutive works.
\fi 


\section{Extended Results}
\label{appendix:additional_results}

In this section, we include additional results and figures from our experimental evaluation.


\subsection{Microstructure Generation}

\begin{figure}[h]
\begin{minipage}{\textwidth}
\ra{0.25}
\setlength{\tabcolsep}{1pt}
\centering
\begin{tabular}{c ccccc}
  \toprule
  \multirow{2}{*}{\normalsize{Ground}} & \multirow{2}{*}{\normalsize{P(\%)~~}} 
  & \multicolumn{3}{c}{\normalsize{\bf Generative Methods}}\\[2pt]
   & &  \normalsize{\sl Cond} & \normalsize{\sl PDM} & \normalsize{\sl Latent (Ours)} \\
    \midrule
    \includegraphics[width=0.21\linewidth]{images/Microstructure/ground_p0.1.png} &
    \raisebox{2\height}{\footnotesize{\sl {10~~}}} &
    \includegraphics[width=.21\linewidth]{images/Microstructure/cond_p0.1.png} &
    % \includegraphics[width=.16\linewidth]{images/Microstructure/post_proc_p0.1.png} &
    \includegraphics[width=.21\linewidth]{images/Microstructure/pdm_p0.1.png} &
    \includegraphics[width=.21\linewidth]{images/Microstructure/latent_cons_last3_p0.1.png} \\

    \includegraphics[width=0.21\linewidth]{images/Microstructure/ground_p0.3.png} &
    \raisebox{2\height}{\footnotesize{\sl {30~~}}} &
    \includegraphics[width=.21\linewidth]{images/Microstructure/cond_p0.3.png} &
    % \includegraphics[width=.16\linewidth]{images/Microstructure/post_proc_p0.3.png} &
    \includegraphics[width=.21\linewidth]{images/Microstructure/pdm_p0.3.png} &
    \includegraphics[width=.21\linewidth]{images/Microstructure/latent_cons_last3_p0.3.png} \\

    \includegraphics[width=0.21\linewidth]{images/Microstructure/ground_p0.5.png} &
    \raisebox{2\height}{\footnotesize{\sl {50~~}}} &
    \includegraphics[width=.21\linewidth]{images/Microstructure/cond_p0.5.png} &
    % \includegraphics[width=.16\linewidth]{images/Microstructure/post_proc_p0.5.png} &
    \includegraphics[width=.21\linewidth]{images/Microstructure/pdm_p0.5.png} &
    \includegraphics[width=.21\linewidth]{images/Microstructure/latent_cons_last3_p0.5.png} \\[2pt]
    \midrule
    \multicolumn{2}{l}{{\bf \large{FID scores:}}} & \normalsize{10.8 $\!\pm\!$ 0.9} & \normalsize{30.7 $\!\pm\!$ 6.8} & \normalsize{13.5 $\!\pm\!$ 3.1}\\ \\
    \multicolumn{2}{l}{{\bf \large{P error $>$ 10\%:}}} & \normalsize{68.4$\%$ $\!\pm\!$ 12.4} & \normalsize{0$\%$ $\!\pm\!$ 0} & \normalsize{0$\%$ $\!\pm\!$ 0}\\
    \bottomrule
\end{tabular}
\caption{Extended version of Figure~\ref{fig:microstructure-images}}
\label{fig:microstructure-images-ex}
\end{minipage}
\end{figure}

\textbf{Additional baselines.} To supplement the evaluation presented in paper, we also implemented the following baselines:
\begin{enumerate}[leftmargin=*, parsep=2pt, itemsep=2pt, topsep=0pt]
\item {\bf Image Space Correction:} We implement a naive approach which converts the latent representation to the image space, projects the image, and then passes the feasible image through the encoder layer to return to the latent space.
\item {\bf Learned Latent Corrector:} Adapting the implementation by \cite{engel2017latent} for diffusion models, we train a network to restore feasibility prior to the decoding step. 
\end{enumerate}


The {\it Image Space Correction} method, which involves re-encoding the image into the latent space after correcting it during various denoising steps, and the {\it Learned Latent Corrector} method, where a network is trained to project a latent vector toward a new state ensuring constraint satisfaction, both failed to produce viable samples. {\bf Both baselines deviated significantly from the training set distribution,} resulting in high FID scores and generated images that lacked quality, failing to capture essential features of the dataset. Due to the inability of these methods to produce viable samples, we do not include them in Figure~\ref{fig:microstructure-images}.

\newpage
\subsection{Metamaterial Inverse Design}

\iffalse
\begin{figure}[h!]
\centering
\begin{minipage}{\textwidth}
\ra{0.25}
\setlength{\tabcolsep}{1pt}
\noindent\fboxsep=0pt
\noindent\fboxrule=0.26pt
\centering
\begin{tabular}{c ccc}
    \toprule
    \footnotesize{Original} & 
    \footnotesize{Step 0} &
    \footnotesize{Step 2} & 
    \footnotesize{Step 4} \\
    
    \midrule
    \fbox{\includegraphics[width=0.16\linewidth]{images/Metamaterials/original.png}} &
    \fbox{\includegraphics[width=.16\linewidth]{images/Metamaterials/0.png}} &
    \fbox{\includegraphics[width=.16\linewidth]{images/Metamaterials/2.png}} &
    \fbox{\includegraphics[width=.16\linewidth]{images/Metamaterials/4.png}} \\
    \midrule
    \multicolumn{4}{c}
    {\bf \footnotesize{Structural analysis}} \\[2pt]
    \includegraphics[width=0.18\linewidth]{images/Metamaterials/orig_0.png} &
    \includegraphics[width=.18\linewidth]{images/Metamaterials/step0_0.png} &
    \includegraphics[width=.18\linewidth]{images/Metamaterials/step2_0.png} &
    \includegraphics[width=.18\linewidth]{images/Metamaterials/step4_0.png} \\

    \includegraphics[width=0.18\linewidth]{images/Metamaterials/orig_1.png} &
    \includegraphics[width=.18\linewidth]{images/Metamaterials/step0_1.png} &
    \includegraphics[width=.18\linewidth]{images/Metamaterials/step2_1.png} &
    \includegraphics[width=.18\linewidth]{images/Metamaterials/step4_1.png} \\
    
    \includegraphics[width=0.18\linewidth]{images/Metamaterials/orig_5.png} &
    \includegraphics[width=.18\linewidth]{images/Metamaterials/step0_5.png} &
    \includegraphics[width=.18\linewidth]{images/Metamaterials/step2_5.png} &
    \includegraphics[width=.18\linewidth]{images/Metamaterials/step4_5.png} \\
    
    \includegraphics[width=0.18\linewidth]{images/Metamaterials/orig_10.png} &
    \includegraphics[width=.18\linewidth]{images/Metamaterials/step0_10.png} &
    \includegraphics[width=.18\linewidth]{images/Metamaterials/step2_10.png} &
    \includegraphics[width=.18\linewidth]{images/Metamaterials/step4_10.png} \\
    
    \midrule   
    \multicolumn{4}{c}
    {\bf \footnotesize{Stress-strain curves}} \\[2pt]
    \includegraphics[width=0.22\linewidth]{images/Metamaterials/orig_curve.png} &
    \includegraphics[width=.22\linewidth]{images/Metamaterials/step_0_curve.png} &
    \includegraphics[width=.22\linewidth]{images/Metamaterials/step_2_curve.png} &
    \includegraphics[width=.22\linewidth]{images/Metamaterials/step_4_curve.png} \\ [2pt]
    \multicolumn{4}{c}{\includegraphics[width=.5\columnwidth]{images/Metamaterials/curves_legend.png}} \\[2pt]
    \midrule
    \multicolumn{4}{c}
    {\bf \large{MSE}} \\[2pt] \normalsize{179.5} & \normalsize{175.6} & \normalsize{12.5} & \normalsize{1.2}\\ 
    \bottomrule
\end{tabular}
\caption{Extended version of Figure~\ref{fig:metamaterial-images}}
\label{fig:metamaterial-images-ex}
\end{minipage}
\end{figure}
\fi


\begin{figure}[h!]
\begin{minipage}{\textwidth}
\ra{0.25}
\setlength{\tabcolsep}{1pt}
\noindent\fboxsep=0pt
\noindent\fboxrule=0.26pt
\centering
\begin{tabular}{c @{\hspace{.2cm}} ccc@{\hspace{.7cm}}ccc}
    \toprule
     &
    \multicolumn{3}{c}
    {\bf \footnotesize{Interpolation}} &
    \multicolumn{3}{c}
    {\bf \footnotesize{Extrapolation}} \\[2pt]
     & \multicolumn{3}{c}{\includegraphics[width=0.25\linewidth]{images/Metamaterials/int.png}} &
    \multicolumn{3}{c}{\includegraphics[width=0.25\linewidth]{images/Metamaterials/ext.png}} \\
    \midrule
    \footnotesize{Model} &
    \footnotesize{Shape} & 
    \footnotesize{Stress curve} &
    \footnotesize{MSE} &
    \footnotesize{Shape} & 
    \footnotesize{Stress curve} &
    \footnotesize{MSE} \\
    
    \midrule
    
    \raisebox{3ex}[0pt][0pt]{\footnotesize{\sl \shortstack{Cond \\ (Stable Image)}}} & \fbox{\includegraphics[width=0.112\linewidth]{images/Metamaterials/Conditional_interp.png}} &
    \fbox{\includegraphics[width=0.18\linewidth]{images/Metamaterials/Int_cond.png}} &
    \raisebox{3.5\height}{\footnotesize{\sl {7.0~~}}} &    \fbox{\includegraphics[width=.112\linewidth]{images/Metamaterials/Conditional_extrap.png}} &
    \fbox{\includegraphics[width=.18\linewidth]{images/Metamaterials/Ext_cond.png}} &
    \raisebox{3.5\height}{\footnotesize{\sl {127.3~~}}} \\
    
    \raisebox{3ex}[0pt][0pt]{\footnotesize{\sl \shortstack{Cond \\ (Video Diffusion) \\ \citeauthor{bastek2023inverse}}}} & \fbox{\includegraphics[width=0.112\linewidth]{images/Metamaterials/Nature_interp.png}} &
    \fbox{\includegraphics[width=0.18\linewidth]{images/Metamaterials/Int_nat.png}} &
    \raisebox{3.5\height}{\footnotesize{\sl {9.2~~}}} &    \fbox{\includegraphics[width=.112\linewidth]{images/Metamaterials/Nature_extrap.png}}
    &    \fbox{\includegraphics[width=.18\linewidth]{images/Metamaterials/Ext_nat.png}} &
    \raisebox{3.5\height}{\footnotesize{\sl {99.6~~}}} \\

    \raisebox{3.5ex}[0pt][0pt]{\footnotesize{\sl \shortstack{Latent \\ (Ours)}}} & \fbox{\includegraphics[width=0.112\linewidth]{images/Metamaterials/4.png}} &
    \fbox{\includegraphics[width=0.18\linewidth]{images/Metamaterials/Int_proj.png}} &
    \raisebox{3.5\height}{\footnotesize{\sl {1.2~~}}} &  
    \fbox{\includegraphics[width=.112\linewidth]{images/Metamaterials/Projected_extrap.png}} &   \fbox{\includegraphics[width=.18\linewidth]{images/Metamaterials/Ext_proj.png}} &
    \raisebox{3.5\height}{\footnotesize{\sl {78.3~~}}} \\
    
    \bottomrule
\end{tabular}

\caption{}
\label{fig:metamaterial-extrap-ex}
\end{minipage}
\end{figure}

Figure~\ref{fig:metamaterial-extrap-ex} illustrates the performance of different models in interpolation (i.e., when the target curve falls within the stress range covered by the training set) and in extrapolation (i.e., when the target is outside this range). In addition to the proposed model, a Conditional Stable Diffusion model and a Conditional Video Diffusion model \cite{bastek2023inverse} are shown. The proposed model allows for arbitrarily small tolerance settings and outperforms the baselines in both tests.



\subsection{Copyright-Safe Generation}

\textbf{Surrogate implementation.}
We begin by fine-tuning a classifier capable of predicting membership to one of two classes: `Mickey Mouse' or `Jerry'. 
The architecture of the classifier consists of a ResNet50 backbone, which is followed by two fully connected layers. These layers serve to progressively reduce the dimensionality of the feature map, first from 2048 to 512 and then from 512 to a single scalar feature, which represents the output of the classifier. A Sigmoid activation function is then applied to this final feature to estimate the probability that the input sample belongs to either the 'Mickey Mouse' or 'Jerry' class. This process ensures that the model outputs a value between 0 and 1, indicating the likelihood of each class membership. The classifier was evaluated on a held-out test set and demonstrated a strong performance, achieving an accuracy greater than 87\%, which showcases its effectiveness in distinguishing between the two classes.



\section{Theoretical Analysis}
\label{appendix:theory}

In this section, we present a theoretical analysis of the proposed method, focusing on the satisfaction of hard constraints and the convergence properties associated with both hard constraints and surrogate constraints introduced in this paper.

\begin{theorem}
    \textbf{Convex Constraint Guarantees:} The proposed method provides feasibility guarantees for convex constraint.
\end{theorem}

First, note that when a projection (or approximation thereof) can be constructed in the image space, strict guarantees can be provided on the feasibility of the {\it final outputs} of the stable diffusion model. 
% Similar to post-processing methods, a 
A final projection can be applied after decoding $\mathbf{z}_0$, and, as this operator is applied directly in the image space, constraint satisfaction is ensured if the projection is onto a convex set.
% as proven by \citeauthor{christopher2024constrained} 
{\bf These guarantees hold for our experiments with hard constraints (Sections \ref{subsec:microstruct} and \ref{subsec:metamaterials}). }


\iffalse
\subsection{Hard Constraints Convergence}
As aforementioned, the proposed method effectively guarantees constraint satisfaction in the {\it final} generated outputs. Since this guarantee stems from the final projection, one may conjecture that post-processing is sufficient for synthesizing the high quality results reported in this paper. Yet, empirically we demonstrate that our continuous corrections throughout sampling result in improved sample synthesis. Next, we will provide theoretical rationale for the improvement over post-processing methods.

\begin{assumption}
    \label{assumption:smooth}
    \textbf{Latent Space Smoothness:} For any timestep \( t \) and for any small perturbation \( \Delta \mathbf{z}_t \) applied to the latent variable \( \mathbf{z}_t \), the resulting change in the output image \( \Delta \bm{x}_t \) satisfies
    \[
    \frac{\| \Delta \bm{x}_t \|}{\| \Delta \mathbf{z}_t \|} \approx \beta
    \]
    where \( \| \cdot \| \) denotes the norm (e.g., Euclidean norm) of the vector, and \( \beta \) is a constant that does not depend on \( t \) or \( \bm{x}_t \).
\end{assumption}

This assumption implies that the magnitude of changes in the decoded image \( \bm{x}_t \) is proportional to the magnitude of perturbations in the latent variable \( \mathbf{z}_t \), with the proportionality constant \( \beta \) remaining consistent across different timesteps and latent variables.
While Assumption~\ref{assumption:smooth} may initially appear restrictive, {\it Smooth Diffusion} has previously been proposed to provide this property of \textit{latent space smoothness} \cite{guo2024smooth}.


Assumption~\ref{assumption:smooth} results in theoretical equivalencies between this approach and \citet{christopher2024constrained}, resulting in two important implications. First, the projection employed in the image space is equivalent to a projection in the latent space given that $\beta \times \|\mathbf{\hat{z}_t} - \mathbf{z}_t\| \approx \|\mathcal{P}_{\mathbf{C}}(\bm{x}_t) - \bm{x}_t\|$.
Hence, this distance minimization in the image space results in distance minimization in the latent space. 

Second, building upon the latent space smoothness assumption, we can analyze the convergence behavior of our method during the sampling process. This analysis demonstrates that our approach ensures convergence towards the constraint set throughout sampling, differentiating it from post-processing methods.


\begin{definition}
The operator \( \mathcal{U} \) defines a single update step for the sampling process:
\begin{equation}
    \label{eq:update-def}
    \mathcal{U}(\mathbf{z}_{t}) = \mathbf{z}_{t} + \gamma_t \mathbf{s}_{\theta}(\mathbf{z}_{t}, t) + \sqrt{2\gamma_t}\bm{\epsilon}
\end{equation}
where \( \mathbf{z}_t^{i} \) represents the latent variable at time step \( t \) and iteration \( i \), \( \gamma_t \) is the step size, \( \mathbf{s}_{\theta} \) is the score function parameterized by \( \theta \), and \( \bm{\epsilon} \) denotes Gaussian noise.
\end{definition}


There exists a maximum timestep \( \bar{T} \) such that:

\begin{equation}
    \label{eq:grad-size}
    \exists \bar{T} \; \text{s.t.} \; \left\| \mathbf{z}_{\bar{T}} + \gamma_t \nabla_{\mathbf{z}_{\bar{T}}} \log p(\mathbf{z}_{\bar{T}}|\mathbf{z}_0) \right\|_2 \leq \left\| \rho_t \right\|_2
\end{equation}

where \( \rho_t \) represents the closest point to the global optimum achievable via a single gradient step from any point in the constraint set \( \mathbf{C} \).

\begin{theorem}
\label{theorem:converges}
(Extended from \citet{christopher2024constrained}) Let the distance error be defined as:
\begin{equation}
    \label{eq:projection-error}
    \text{Error}(\mathbf{z}, \mathbf{C}) = \|\mathbf{z} - \mathbf{\hat{z}}\|^2_2
\end{equation}
Assuming \( \log p(\mathbf{z}_t) \) is convex and that the latent space smoothness assumption holds, for any \( t \leq \bar{T} \),
\begin{equation}
    \label{eq:theorem-1}
    \mathbb{E} \left[ \text{Error}(\mathcal{U}(\mathbf{z}_{t}), \mathbf{C}) \right] \geq \mathbb{E} \left[ \text{Error}(\mathcal{U}(\mathbf{\hat{z}}_{t}), \mathbf{C}) \right]
\end{equation}
\end{theorem}

This theorem indicates that {\bf incorporating gradient-based correction steps throughout sampling ensures that the samples generated during the diffusion process remain closer to the constraint set compared to samples generated without such corrections.} As the step size \( \gamma_t \) decreases over time, the projection error diminishes, {\bf leading the samples to converge towards the feasible subspace defined by the constraint set \( \mathbf{C} \).}

By integrating continuous corrections during sampling and leveraging the latent space smoothness assumption, our method ensures that the generated samples not only satisfy the hard constraints in the final outputs but also adhere to these constraints throughout the diffusion process, resulting in higher-quality synthesized results. 



\subsection{Surrogate Constraints Convergence}

While the previous parts of this section focus on hard constraint imposition, similar analysis can be derived for surrogate constraints, with the caveat that these will be limited to `statistical guarantees' due to the inclusion of a surrogate model.  


\begin{assumption}
    \label{assumption:surrogate-smoothness}
    \textbf{Surrogate Model Smoothness:} The surrogate model \( \phi \) defining the constraint is Lipschitz continuous in the latent space, i.e., there exists a constant \( L > 0 \) such that for any \( \mathbf{z}, \mathbf{z}' \in \mathbb{R}^d \),
    \[
    |\phi(\mathbf{z}) - \phi(\mathbf{z}')| \leq L \|\mathbf{z} - \mathbf{z}'\|_2.
    \]
\end{assumption}

This assumption ensures that small perturbations in the latent space lead to bounded changes in the surrogate constraint value, making it feasible to iteratively correct the latent variable during the diffusion process.
{\it Furthermore, provided this assumption, we can extends Theorem~\ref{theorem:converges} to encompass surrogate constraints.}


% \begin{definition}
% The surrogate constraint operator \( \mathcal{S} \) maps a latent variable \( \mathbf{z}_t \) to its corrected form based on the surrogate model:
% \begin{equation}
%     \label{eq:surrogate-update}
%     \mathcal{S}(\mathbf{z}_t) = \mathbf{z}_t - \eta_t \nabla_{\mathbf{z}_t} \phi(\mathbf{z}_t),
% \end{equation}
% where \( \eta_t \) is the step size for the surrogate correction.
% \end{definition}



While hard constraints offer strict guarantees of feasibility, surrogate constraints provide statistical guarantees due to their data-driven nature. {\bf The convergence analysis indicates that, under the smoothness assumption, the sampling process guided by surrogate constraints will, in expectation, produce samples that increasingly satisfy the desired properties encoded by the proxy model.} 

\fi
% $\mathbf{\hat{z}}_{T-1}$

% In summary, the smoothness of the surrogate model allows us to extend the convergence guarantees from hard constraints to surrogate constraints. Although the guarantees are statistical rather than absolute, they provide a robust foundation for ensuring that the generated samples adhere to the desired constraints throughout the diffusion process.




% \begin{enumerate}
%     \item When using hard constraints (i.e. microstructures): 
%     \begin{enumerate}
%         \item We cannot guarantee convergence (as $D$ is not convex)
%         \item Convex set guarantees? (We have to assume convergence)
%     \end{enumerate}
%     \item When using soft constraints (i.e. stress-strain, copyright generation):
%     \begin{enumerate}
%         \item We cannot guarantee convergence (as $D$ and $p(y \mid \bm{x}_t)$ are not convex)
%         \item Statistical guarantees? (We have to assume convergence)
%     \end{enumerate}
    
% \end{enumerate}



\section{Comparison to Classifier Guidance}
\label{app:comparison}

The proposed approach and classifier-guided diffusion \cite{dhariwal2021diffusion} rely on an external predictive model to direct the generation process. However, the two methods fundamentally differ in how the methods apply the model’s gradient. Classifier-guided diffusion encourages similarity to feasible training samples, offering implicit guidance. In contrast, our approach provides {\it statistical guarantees as to constraint satisfaction within the confidence levels of the classifier,} providing a more direct and targeted mechanism for integrating constraints into the generative process.
% \nando{These guanratees need to be discussed in a theoretical section!}

\textbf{Classifier-based guidance.} Applies Bayesian principles to direct generation toward a target class 
$y$, based on the decomposition:
\begin{equation}
\small
\nabla_{\bm{x}_t} \log p(\bm{x}_t \mid y) = \nabla_{\bm{x}_t} \log p(\bm{x}_t) + \nabla_{\bm{x}_t} \log p(y \mid \bm{x}_t)
\end{equation}
This conditional generation incorporates a classifier $p(y \mid \bm{x}_t)$ into the sampling process. During generation, the model updates the noisy sample $\bm{x}_t$ by combining the standard denoising step with the classifier’s gradient:
\begin{equation}
    \small
    x_{t+1} = x_t + \epsilon \nabla_{x_t} \log p(x_t) + \sqrt{2 \epsilon}  + w \nabla_{x_t} \log p(y \mid x_t)
\end{equation}
Here, the classifier’s gradient $w \nabla_{x_t} \log p(y \mid \bm{x}_t)$ guides the denoising toward samples likely belonging to class $y$, with $w$ controlling the guidance strength.


\textbf{Training-free guidance.} 
Extends the principles of classifier-based guidance by leveraging pretrained, ``off-the-shelf'' classifiers to steer the generation process without requiring additional training. 
As with classifier-based guidance, the conditional generation incorporates a classifier $p(y \mid \bm{x}_t)$ into the sampling process. However, rather than training a custom classifier tailored to the diffusion model, this approach directly uses existing models to compute the guidance term.
By decoupling the classifier from the diffusion model training, training-free guidance achieves flexibility and reusability, making it a practical choice for tasks where suitable pretrained classifiers are available.



\textbf{Surrogate constraint corrections.} Introduce a structured method to enforce class-specific constraints by adjusting samples at specific diffusion steps. In this approach, a surrogate model modifies the sample $\mathbf{z}_t$ to $\hat{\mathbf{z}}_t$ to meet the target constraints. 
These corrections can be introduced either at the beginning of the diffusion process, setting a strong initial alignment to the target class and then allowing the model to evolve naturally, or at designated points within the denoising sequence to enforce the constraints more explicitly at each selected step. 
In contrast, while classifier-based guidance and training-free guidance continuously integrate classifier gradients to steer generation toward the target class, surrogate constraint corrections offer discrete, targeted adjustments throughout the reverse diffusion process. This makes surrogate constraints particularly effective when strict adherence to certain class-specific conditions is necessary at particular stages of the generation process.
% \nando{This last sentence doesn't mean much... Can we discuss well the difference between these two methods?}



\end{document}
