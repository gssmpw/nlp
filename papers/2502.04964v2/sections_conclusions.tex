% !TEX root = ../main.tex

\section{Conclusion}
  We presented \texttt{CoCoA}, a unified approach that integrates \textbf{Co}nfidence and \textbf{Co}nsistency for uncertainty quantification in LLMs. By combining token-level confidence scores with semantic similarity between multiple sampled outputs, CoCoA offers a more holistic view of uncertainty than either approach alone. In extensive evaluations on question answering, summarization, and translation, our approach outperformed existing baselines and state-of-the-art UQ methods. Moreover, \texttt{CoCoA}'s flexible design allows easy adaptation to a variety of tasks and settings. 
  
  Moving forward, several directions are open for further exploration. These include incorporating more adaptive sampling strategies that efficiently capture the model output space, refining semantic similarity functions for domain-specific tasks, and improving calibration techniques to strengthen the confidence metrics of the model.
