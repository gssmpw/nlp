% !TEX root = ../main.tex

  \begin{figure*}[t!]
    \centering
    \includegraphics[width=\linewidth]{img_final_diagram.pdf}
    \caption{Illustration of the method: the LLM generates a response, evaluates the similarity to alternatives, computes the uncertainty, and combines the uncertainty score with the similarity measures. High similarity to alternatives reduces the uncertainty, while low similarity keeps it high.}
    \label{fig:method}
  \end{figure*}


\section{Background}
  In this section, we introduce key concepts related to uncertainty quantification for LLMs, outline existing methods, discuss their limitations, and highlight the motivation for our approach.

  First and foremost, it is important to establish the concept of an \textit{uncertainty function}. Let $\yv = f(\xv)$ denote the output of an LLM given an input sequence $\xv$. The model defines a probabilistic output distribution $p(\yv \mid \xv)$, from which outputs can be sampled. An \textit{uncertainty function} \( U \) is a mapping that quantifies the level of uncertainty $u$ associated with the output of a model \( \yv \), conditioned on the input sequence \( \xv \), which we denote as
  \begin{equation}
    u = U(\yv \mid \xv).
  \end{equation}
  %
  With this notion in mind, we now discuss existing methods for uncertainty quantification, outline their limitations, and describe how our approach addresses them.

\subsection{Single-Sequence Information-Based Methods}
  Information-based methods rely on a single sample from the LLM and estimate the uncertainty of the generated sequence by aggregating the uncertainty scores of individual tokens. One of the simplest techniques of this kind is
  \textit{Maximum Sequence Probability (MSP)}: 
  \begin{equation}
    u_{\text{MSP}} = - \log p\bigl(\yv \mid \xv\bigr).
  \end{equation}
  %
  Several other measures fall into this category, including \textit{Perplexity} and \textit{Mean Token Entropy}~\citep{fomicheva-etal-2020-unsupervised}; see Appendix~\ref{suppl:confidence} for details. While using only a single sample makes them computationally efficient, these techniques face three major challenges:
  \begin{enumerate}
    \item First, LLMs provide us with the probability of a specific answer, even though the same meaning could often be expressed in multiple ways. Therefore, to obtain a proper probability for the meaning of an answer, we need to marginalize over its various possible rephrasings. However, this is not feasible if we generate only a single sample. 

    \item Second, answers of LLMs in general have very low probabilities due to the size of the vocabulary and the length of the generated sequences. Therefore, their estimates by LLM are not very reliable in general.

    \item Third, these methods do not provide information about the flatness or the variability of the answer distribution. 
  \end{enumerate}
  

\subsection{Consistency-Based Methods}
  The aforementioned issues lead to the development of consistency-based methods based on repetitive sampling from the LLM.
  Consider that we have sampled a set of outputs \( \bigl\{\yv^{(i)}\bigr\}_{i=1}^M\), where \({\yv^{(i)} \sim p(\yv \mid \xv)}\). 
  Consistency-based uncertainty quantification methods rely only on the diversity of answers \(\yv^{(i)}\) sampled from the LLM. The idea is that if the model outputs similar answers for the same prompt over and over again, it is confident in its predictions; otherwise, it is uncertain. These techniques do not require knowledge about the probability distribution of the tokens and can be applied in the black-box setting, when only the generated tokens are available. This case is quite common when LLMs are deployed as a service and are accessible through a limited API.
  
  Formally, given $M$ samples from the model, consistency-based methods compute a similarity matrix \(G\), where each element \(g_{ij}\) represents some form of similarity between the sampled outputs \(\yv^{(i)}\) and \(\yv^{(j)}\): 
  \begin{equation}
    g\bigl(\yv^{(i)}, \yv^{(j)}\bigr) \in [0, 1].
  \end{equation}
  %
  The value \(g\bigl(\yv^{(i)}, \yv^{(j)}\bigr) = 1\) indicates the complete equivalence between \(\yv^{(i)}\) and \(\yv^{(j)}\), and \(g\bigl(\yv^{(i)}, \yv^{(j)}\bigr) = 0\) indicates that there is no similarity. 
  
  Similarity could be computed in various ways. For example, {\it Lexical Similarity}~\citep{fomicheva-etal-2020-unsupervised} is the surface form similarity, which calculates the overlap of words or phrases in the generations. More advanced techniques propose various methods for taking into account the semantic similarity of the generated answers by hard or soft clustering~\citep{lin2023generating}. For example, the \textit{Degree Matrix} approach considers a similarity matrix $G$, which is computed using a model for Natural Language Inference (NLI), which predicts the probabilities of entailment, ${p}_{\mathrm{entail}}(\yv, \yv')$, and contradiction, ${p}_{\mathrm{contra}}(\yv, \yv')$, between pairs of sentences $\yv$ and $\yv'$. The similarity between two sequences is then defined as either $g_{\mathrm{entail}}(\yv, \yv') = {p}_{\mathrm{entail}}(\yv, \yv') \quad \text{or} \quad g_{\mathrm{contra}}(\yv, \yv') = 1 - {p}_{\mathrm{contra}}(\yv, \yv')$. \citet{lin2023generating} proposes to compute an averaged similarity matrix as  $g_{ij} = \bigl(g\bigl(\yv^{(i)}, \yv^{(j)}\bigr) + g\bigl(\yv^{(j)}, \yv^{(i)}\bigr)\bigr)/2$. The diagonal matrix $D$ is then defined with elements  $D_{ii} = \sum_{j = 1}^M g_{ij}$. The uncertainty from this soft clustering of meanings can then be defined as follows:
  \begin{equation}
    U_{\mathrm{DegMat}} = 1 - \frac{\mathrm{trace}(D)}{M^2}. 
  \end{equation}
  %
  The advantage of these techniques is that by generating multiple samples and analyzing their semantic similarity, they can obtain empirical probabilities for \textit{meanings} instead of individual answers. The main drawback is that they discard the useful information that comes from the probability distribution represented by the LLM, including estimates of probabilities of specific answers. 


\subsection{Information-Based Methods with Repeated Sampling}
  The natural idea is to somehow benefit from having multiple samples from the model while using important information contained in the output probabilities estimated by an LLM. Below, we examine several approaches that have sought to achieve this.

\paragraph{Averaging uncertainties.}
  The uncertainty scores can be aggregated using simple Monte Carlo averaging:
  \begin{equation}
    u_{\text{MC}} = \frac{1}{M} \sum_{i=1}^M u_i.
  \label{eq:mc_uncertainty}
  \end{equation}
  %
  For the case when using the MSP uncertainty measure, i.e., when $u_i = -\log p\bigl(\yv^{(i)} \mid \xv\bigr)$, we obtain $u_{\text{MC}} = -\frac{1}{M} \sum_{i=1}^M \log p\bigl(\yv^{(i)} \mid \xv\bigr)$. The other notable example is the Monte Carlo Sequence Entropy~\citep{kuhn2023semantic}.

  While simple averaging represents a natural way to aggregate uncertainties, it has certain issues related to the nature of LLMs. First of all, in the vast majority of applications, an LLM-based system should produce a single output $\yv_*$ for an input query. When we consider $u_{\text{MC}}$, we essentially perform averaging of uncertainties of different sequences, thus somewhat assessing the uncertainty related to the entire generative distribution $p(\yv \mid \xv)$ for the input $\xv$, but not for a particular generated sequence $\yv_*$. This averaged uncertainty might not be adequate for this particular sequence and, remarkably, often performs worse than the uncertainty $u_* = U(\yv_* \mid \xv)$, which is related solely to the output $\yv_*$.
  Moreover, although intuitive, this na\"{i}ve aggregation method assumes that all outputs contribute equally to the final uncertainty estimate, regardless of their semantic relationships. This can lead to inconsistencies when semantically equivalent outputs have varying uncertainty scores or when outputs with low similarity are treated as equally important. 


\paragraph{Semantically weighted averaging.}
  The basic idea of aggregation approaches like Semantic Entropy~\cite{kuhn2023semantic} or SAR~\cite{duan-etal-2024-shifting} is to perform a weighted averaging of output probabilities and give more weight to sequences semantically similar to the response shown to a user. All recently proposed techniques, such as SAR and Semantic Entropy, can be unified into a semantically-aware Generalized Monte Carlo uncertainty estimate, defined as
  \begin{equation}
    u_{\text{GMCU}} = \frac{1}{M}\sum_{i = 1}^M h \Biggl(\sum_{j = 1}^M g_{ij} \, p_j\Biggr).
  \label{eq:gmcu}
  \end{equation}
  %
  Here, the inner summation aggregates sequence probabilities \(p_j\) weighted by their semantic similarity to the \(i\)-th output, and the outer summation averages these contributions across all samples. The function $h(\cdot)$ provides an additional layer of flexibility, transforming the reweighted uncertainty scores, making the method a generalized framework for uncertainty quantification. Existing methods, such as Semantic Entropy and SAR, can be considered as special cases of this more comprehensive approach, where the functions \(h\) and \( g \) are chosen appropriately.

  Unfortunately, methods that fall under GMCU, while offering benefits, also inherit the aforementioned issues from both categories of methods:
  \begin{enumerate}
    \item The term \(\sum_{j = 1}^M g_{ij} \, p_j\) aims to average the probabilities of semantically similar sequences to obtain more robust estimate of the probability. However, due to the extreme instability of the LLM probabilities, as shown in Figure~\ref{fig:inconsistent_probability}, the aggregated probabilities often perform worse than non-aggregated baselines.

    \item The outer summation in~\eqref{eq:gmcu}, similarly to the case of simple Monte Carlo averaging~\eqref{eq:mc_uncertainty}, often fails to outperform the uncertainty $u_* = U(\yv_* \mid \xv)$ of a single generated sequence $\yv_*$.
  \end{enumerate}

  Let us note that all uncertainty functions discussed so far have the following properties: 
  \begin{itemize}
    \item \textbf{Non-Negativity.} The uncertainty function produces nonnegative values, that is, \(U(\yv) \geq 0\) for all \(\yv\).
    
    \item \textbf{Monotonicity.} Higher values of the uncertainty function \(U\) indicate higher uncertainty, i.e.,~if output \(\yv^{(1)}\) is considered more uncertain than output \(\yv^{(2)}\), then \(U\bigl(\yv^{(1)}\bigr) \geq U\bigl(\yv^{(2)}\bigr)\).
  \end{itemize}
  %
  These properties become important to perform the kind of synthesis of confidence and consistency we propose in the following section.

\section{CoCoA: Bridging Confidence and Consistency for Better Uncertainty Quantification}
  We start by summarizing the benefits and drawbacks of various uncertainty quantification approaches discussed above:
  \begin{enumerate}
    \item Both information-based and (semantic) consistency-based methods provide grounded and useful uncertainty quantification measures.

    \item Output probabilities $p(\yv^{(j)} \mid \xv), \, j = 1, \dots, M$ might have substantially different values for semantically equivalent outputs, which questions the usefulness of (weighted) averaging these probabilities for uncertainty quantification.

    \item For various methods based on the aggregation over multiple samples, the result might be suboptimal due to the noise related to the averaging over all generated outputs. Focusing solely on a particular output sequence and its relation to other generated outputs might be beneficial.
  \end{enumerate}
  %
  In what follows, we present a family of UQ \textit{\underline{Co}nfidence and \underline{Co}nsistency-based \underline{A}pproaches} (\texttt{CoCoA}), offering a new way to merge information- and consistency-based measures for uncertainty quantification in LLMs.

  Let us consider an actual output sequence $\yv_*$ and a set of sampled sequences $\yv^{(i)}, \, i = 1, \dots, M$. Here, $\yv_*$ might be one of the sequences $\yv^{(i)}$ or might be generated separately. In what follows, we will consider several possible cases, including $\yv_*$ being a random sequence from a set $\{\yv^{(i)}\}$, $\yv_*$ being a sequence from a set $\{\yv^{(i)}\}$ having the highest probability, and, finally, $\yv_*$ being a sequence found via the beam search procedure.

  First, consider an information-based uncertainty score of the output $\yv_*$:
  \begin{equation}
    u_*^{\text{info}} = U^{\text{info}}(\yv_* \mid \xv),
  \end{equation}
  where $U^{\text{info}}$ might be MSP, perplexity, mean token entropy, or another uncertainty measure related solely to the generated sequence $\yv_*$. 

  We quantify the consistency-based uncertainty via a direct measurement of the semantic similarity of generated sequence $\yv_*$ to sampled sequences:
  \begin{equation}
    u_*^{\text{cons}} = \frac{1}{M} \sum_{i = 1}^M (1 - g_{*i}),
    \label{eq:ave_dissim}
  \end{equation}
  where $g_{*i} = g\bigl(\yv_*, \yv^{(i)}\bigr)$. This formulation satisfies the desired properties of the uncertainty function -- that is their values are nonnegative and their values increase with increased inconsistency (decreasing value of $g_{*i}$). In our ablation study, we will show that such an uncertainty measure reliably outperforms consistency-based measures that aggregate the pairwise similarities of all the samples (see Appendix~\ref{sec:sum_cocoa}).

  Finally, we need to aggregate $u_*^{\text{info}}$ and $u_*^{\text{cons}}$ into a single uncertainty measure. We propose to aggregate them in a multiplicative way:
  \begin{equation}
    u_*^{\texttt{CoCoA}} = u_*^{\text{info}} \cdot u_*^{\text{cons}}
  \label{eq:cocoa}
  \end{equation}
  %
  This formulation preserves the non-negativity and the monotonicity properties while integrating both global (semantic) and local (model-specific) uncertainty signals. It ensures that uncertainty is amplified for sequences that are both intrinsically uncertain (high \(u_*^{\text{info}}\)) and semantically inconsistent with the dataset (high \(u_*^{\text{cons}}\)), while keeping it low for the opposite scenario (see Figure~\ref{fig:method}).

  Although the choice of the multiplicative aggregation function \texttt{CoCoA} is heuristic, it provides a practical and effective way to combine information- and consistency-based uncertainty signals in LLMs. In our ablation study, we also compare the multiplicative formulation in~\eqref{eq:cocoa} to a simpler additive variant, \(u_*^{\text{info}} + u_*^{\text{cons}}\) (see Appendix~\ref{sec:sum_cocoa}). Empirically, the multiplicative combination is better at capturing the joint impact of both information-based and consistency-based uncertainty, yielding more reliable estimation across all tasks.


  % \textcolor{red}{The text below is currently not used.}
  %   Given the semantic similarity function \( g(\cdot, \cdot) \), we calculate pairwise similarity scores for all $M$ sampled outputs $\{\yv_1, \dots, \yv_M\}$. The result is a similarity matrix $G$ of size $M \times M$, where each element $g_{ij}$ represents the semantic similarity between $\yv^{(i)}$ and $\yv^{(j)}$. This matrix serves as the foundation for incorporating semantic relationships into the uncertainty enrichment process.

  % $g_{ij}$ = g\bigl(\yv^{(i)}, \yv^{(j)}\bigr)

  % Assymetric/

  % \subsection{Generalized Monte-Carlo Uncertainty}
  %   Accurately quantifying uncertainty in large language models (LLMs) requires an approach that not only accounts for the probabilistic nature of the model's output distribution $p_{\thetav}(\yv \mid \xv)$ but also reflects the semantic relationships among the generated outputs. Traditional Monte Carlo methods estimate uncertainty by uniformly aggregating scores across multiple outputs, treating all samples as equally informative. However, this approach fails to consider the underlying structure of the sampled outputs. For example, when the majority of sampled outputs are semantically similar, while one is a clear outlier, the aggregation process should assign greater weight to the consistent outputs to ensure the uncertainty estimate accurately reflects the predominant patterns in the model's predictions. A robust uncertainty estimation method should assign higher uncertainty to semantically incoherent or nonsensical outputs and lower uncertainty to outputs that are consistent and meaningful.

  %   To address this issue, we propose a Generalized Monte-Carlo Uncertainty (GMCU) method that takes semantic similarity into account when aggregating uncertainty scores. Instead of treating all outputs as equally important, GMCU assigns more weight to outputs that are semantically divergent, ensuring that the final uncertainty score reflects both the diversity of the predictions and their underlying meanings. 

  % % To address this limitation, we propose an enriched uncertainty estimation method that aggregates uncertainty scores across multiple sampled outputs, using semantic relationships between them. The key idea is to sample multiple outputs from \( p_{\thetav}(\yv \mid \xv) \) and compute an aggregated uncertainty score that accounts for their semantic equivalence.

  % % We propose a way to enrich this estimate $u$ by sampling the output distribution of an LLM repeatedly and aggregating uncertainty scores of each of the samples, with respect to their semantic equivalence. More precisely, given $M$ samples from the model and a semantic equivalence function $g_{ij} = g\bigl(\yv^{(i)}, \yv^{(j)}\bigr) \in [0,1]$, that produces similarity score between two samples $\yv^{(i)}, \yv^{(j)}$, we build a semantically-aware Monte-Carlo estimate like this:

  % Any uncertainty metric $u$ can be enriched by sampling the output distribution of a large language model (LLM) multiple times and aggregating the uncertainty scores of the sampled outputs while accounting for their semantic relationships. Specifically, given $M$ samples from the model, compute a similarity matrix \( G \), where each element \( g_{ij} \) represents the semantic similarity between the sampled outputs \( \yv^{(i)} \) and \( \yv^{(j)} \), formally defined as \( g_{ij} = g\bigl(\yv^{(i)}, \yv^{(j)}\bigr)\). Using this similarity matrix, the semantically-aware Generalized Monte Carlo uncertainty estimate is defined as:
  % \begin{equation}
  %   u_{GMCU} = \frac{1}{M}\sum_{i = 1}^M h \Biggl(\sum_{j = 1}^M g_{ij} u_j\Biggr),
  % \end{equation}
  % %
  % Here, the inner summation aggregates uncertainty scores \( u_j \) weighted by their semantic similarity to the \( i \)-th output, and the outer summation averages these contributions across all samples. The function $h(\cdot)$ provides an additional layer of flexibility, transforming the reweighted uncertainty scores, making the method a generalized framework for uncertainty estimation. Existing methods, such as Semantic Entropy, can be considered as specific cases of this more comprehensive approach, where \( h(\cdot) \) and \( g(\cdot, \cdot) \) are chosen appropriately to match their definitions.

  % This formulation ensures that the final uncertainty estimate reflects both the probabilistic variability of the model's outputs and their semantic coherence, as captured by the similarity matrix \( G \).

  %For a specific sequence \(i\), its uncertainty can be viewed as a measure of the model's inconsistency with itself - i.e. how similar is this specific sequence relative to other possible generations? 

  % This diversity-based metric thus captures the model's self-inconsistency for a given sequence in the context of the sample. These two formulations focus on two potential aspects of consistency:
  % \begin{enumerate}
  %   \item The first formulation, \( u_i^{\text{diversity}} = \frac{1}{M-1} \sum_{j \neq i} (1 - g_{ij}) \), rewards consistent outputs by bringing the value closer to 0 as the model becomes more consistent with itself and reaches 0 when all samples are identical.
  %   % % \item The second formulation, \( U_i^{\text{diversity}} = \frac{n-1}{\sum_{j \neq i} G_{ij}} \), penalizes inconsistency more strongly, with the score increasing dramatically as inconsistency grows. In the extreme case where the outputs are entirely inconsistent (i.e., all pairwise similarities \( G_{ij} = 0 \) for \( j \neq i \)), the denominator becomes zero, making the score undefined. To address this edge case, a small positive constant \( \epsilon = 10^{-10} \) is added to the denominator, ensuring numerical stability:
  %   % \[
  %   % U_i^{\text{diversity}} = \frac{n-1}{\sum_{j \neq i} G_{ij} + \epsilon}.
  %   % \]
  % \end{enumerate}

% \subsection{Alternative approach to why it looks like this}
%   \begin{itemize}
%     \item Sample scores in the LLM output are noisy and inconsistent, which is why one-sample estimates of MCSE and MCNSE often outperform full-sample ones. (MP $>$ MCSE, PPL $>$ MCNSE, see some of the results in the tables).
%     \item Semantically-enriched full-sample methods (SE, SAR) mitigate this to a certain degree by adding semantic consistency into consideration.
%     \item We suggest a one-sample approach to estimating semantically-weighted Monte-Carlo entropy of LLM output. Consider the following estimate:
%     \[
%       U_{SW-MCSE} = -\frac{1}{M}\sum_{i = 1}^M \biggl[\log p_i\sum_{j = 1}^M (1 - g_{ij})\biggr].
%     \]
%     %
%     We suggest using one-sample version of this estimate, centered at the most probable sample:
%     \[
%       U_{ours} = -\log p_{i}\sum_{j = 1}^M (1 - g_{ij}),
%     \]
%     \[
%       i = \argmax_i(p_i).
%     \]
%   \end{itemize}

 
% \subsection{Semantic Entropy}
%   \begin{equation}
%     u_{SE} = - \frac{1}{M}\sum_{i = 1}^M \log \Biggl(\sum_{j = 1}^M g_{ij} p_j\Biggr),
%   \end{equation}

% \subsection{SAR}
%   \begin{equation}
%     u_{SAR} = - \frac{1}{M}\sum_{i = 1}^M \log \left(\tilde{p}_i 
%     + \frac{\sum_{j = 1, j \neq i}^M g_{ij} \tilde{p}_j}{t}\right),
%   \end{equation}

% \subsection{MP/PPLGSU}
%   \begin{equation}
%     u_{GSU} = \frac{1}{M}\sum_{i = 1}^M \left(\frac{\sum_{j = 1}^M g_{ij}(-\log\tilde{p}_j)}{\sum_{j = 1}^M g_{ij}}\right),
%   \end{equation}

% \subsection{MP/PPLGSUexp}
%   \begin{equation}
%     u_{GSU} = \frac{1}{M}\sum_{i = 1}^M \left(\frac{\sum_{j = 1}^M g_{ij}(-\tilde{p}_j)}{\sum_{j = 1}^M g_{ij}}\right),
%   \end{equation}

% \subsection{MTEGSU}
%   \begin{equation}
%     u_{GSU} = \frac{1}{M}\sum_{i = 1}^M \left(\frac{\sum_{j = 1}^M g_{ij} u_{MTE}}{\sum_{j = 1}^M g_{ij}}\right),
%   \end{equation}

% \subsection{Semantic Average MP/PPL}
%   \begin{equation}
%     u_{SA} = \frac{\sum_{j = 1}^M g_{0j}(-\log\tilde{p}_j)}{\sum_{j = 1}^M g_{0j}},
%   \end{equation}

% \subsection{Semantic Average MP/PPLexp}
%   \begin{equation}
%     u_{SA} =\frac{\sum_{j = 1}^M g_{0j}(-\tilde{p}_j)}{\sum_{j = 1}^M g_{0j}},
% \end{equation}

% \subsection{Semantic Average MTE}
% \begin{equation}
%     u_{SA} = \frac{\sum_{j = 1}^M g_{0j} u_{MTE}}{\sum_{j = 1}^M g_{0j}},
%   \end{equation}

% \subsection{EnrichedAveSimilarity}
%   Average similarity of a sample j to other model outputs can be defined as: 
%   \begin{equation}
%     \text{Average Similarity}_j = \frac{\sum_{j \neq i} g_{ji}}{M - 1},
%   \end{equation}

%   For each sample j in ${s_1, \dots, s_n}$ and it's corresponding single-sequence metrics ${u_1, \dots, u_n}$
%   \begin{equation}
%     u^{enriched}_{j} = u_j \cdot \frac{1}{\text{Average Similarity}_j}
%   \end{equation}

% This setup explicitly punishes inconsistency in answer.
%   Problem - values from 0 to +infinity. 

% \subsection{EnrichedAveDissimilarity}
%   Average dissimilarity of a sample j to other model outputs can be defined as: 
%   \begin{equation}
%     \text{Average Dissimilarity}_j = \frac{\sum_{j \neq i} (1-g_{ji})}{M - 1},
%   \end{equation}

%   For each sample j in ${s_1, \dots, s_n}$ and it's corresponding single-sequence metrics ${u_1, \dots, u_n}$
%   \begin{equation}
%     u^{enriched}_{j} = u_j \cdot \textit{Average Dissimilarity}_j
%   \end{equation}

%   Values from 0 to 1. This setup rewards consistency. 

% First, suppose we have a distance (or dissimilarity) function 
% \begin{equation}
%     D(\mathbf{y}, \mathbf{y}') \in [0, 1]  
% \end{equation}
  
% defined between two model outputs \(\mathbf{y}\) and \(\mathbf{y}'\). We consider the 
% distribution \(p_{\theta}(\mathbf{y}\mid \mathbf{x})\) of outputs produced by a large language model (LLM). 
% The \emph{expected dissimilarity} between a fixed output \(\mathbf{y}_j\) and a random draw \(\mathbf{y}'\) 
% from that distribution is:

% \begin{equation}
%   \mathbb{E}
%   \bigl[D(\mathbf{y}_j, \mathbf{y}')\bigr]
%   \;=\;
%   \int 
%     D\bigl(\mathbf{y}_j, \mathbf{y}'\bigr)\, 
%     p_{\theta}\bigl(\mathbf{y}'\!\mid\!\mathbf{x}\bigr)\,
%   d \mathbf{y}'
% \end{equation}

% Since we typically cannot compute this integral in closed form, we approximate it 
% via Monte Carlo sampling. Specifically, we draw \(\mathbf{y}_1, \ldots, \mathbf{y}_M\) 
% i.i.d.\ from \(p_{\theta}(\mathbf{y}\mid \mathbf{x})\). Then, for each sampled output \(\mathbf{y}_j\), 
% we estimate its expected distance to a fresh random draw by the average distance 
% to the other samples:

% \begin{equation}
%   \mathbb{E}
%   \bigl[D(\mathbf{y}_j, \mathbf{y}')\bigr]
%   \;\approx\;
%   \frac{1}{M-1}
%   \sum_{\substack{i \neq j}}^{M}
%   D\bigl(\mathbf{y}_j, \mathbf{y}_i\bigr).
% \end{equation}
