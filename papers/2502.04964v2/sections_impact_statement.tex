% !TEX root = ../main.tex

\vspace{-2mm}
\section*{Impact Statement}
As large language models (LLMs) are increasingly integrated into everyday applications, ensuring the robustness of their outputs is essential, particularly in high-stakes domains such as healthcare and the legal sector. In addition to flagging low-quality responses, clear confidence estimates can help reduce overreliance on automated systems and foster safer, more responsible LLM usage. Here, we introduced \texttt{CoCoA}, a new framework that enhances uncertainty quantification in LLMs. While \texttt{CoCoA} improves reliability, its use requires careful domain adaptation to align with specific task requirements.
