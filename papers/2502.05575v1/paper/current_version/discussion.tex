\section{Discussion}
\label{sec:discussion}
\karima{In the previous section, we presented the results of an extensive evaluation of twelve state-of-the-art graph-based vector search methods. Table~\ref{tab:comp} summarizes the evaluation across key criteria: % for both search and indexing. 
for search, we assess efficiency, accuracy, and the number of tunable parameters; 
for indexing, we evaluate efficiency at high recall, memory footprint, and parameter tuning complexity. }

\karima{The best-performing methods, HNSW, VAMANA, and ELPIS, have the best search performance and index efficiency. However, ELPIS requires an extra parameter during both indexing (leaf size) and search (nprobes), whereas VAMANA requires an extra parameter to tune during indexing (alpha). NSG and SSG exhibit efficient query performance, but their indexing capability is hindered because of their base graph EFANNA, which similarly to KGraph, is tedious to tune and suffers from high indexing time and footprint. Both SPTAG (BKT) and NGT show satisfactory performance during search; however, they do not scale well to large datasets and require more tuning compared to the best methods. The assessment of HCNNG is based on the optimized parlayNN implementation which has shown competitive performance on large-scale datasets.} 

We now summarize the key insights and pinpoint promising research directions.

\begin{table}[tb]
\begin{minipage}{0.9\textwidth}
\hspace{4cm}
$\checkmark$ Good \quad
$\sim$ Medium \quad
$\times$ Bad
\end{minipage} \\[2pt]
\captionsetup{justification=centering}
\resizebox{0.8\columnwidth}{!}{
\begin{tabular}{lccc|ccc}
\toprule
\textbf{Method} & \multicolumn{3}{c|}{\textbf{Query Answering}} & \multicolumn{3}{c}{\textbf{Index Building}} \\
                & \textbf{Efficiency} & \textbf{Accuracy} & \textbf{Tuning} & \textbf{Efficiency} & \textbf{Footprint} & \textbf{Tuning} \\
\midrule
HNSW     & $\checkmark$ & $\checkmark$ & $\checkmark$ & $\checkmark$ & $\checkmark$ & $\checkmark$ \\
ELPIS    & $\checkmark$ & $\checkmark$ & $\sim$       & $\checkmark$ & $\checkmark$ & $\sim$ \\
VAMANA   & $\checkmark$ & $\checkmark$ & $\checkmark$ & $\checkmark$ & $\checkmark$ & $\sim$ \\
NSG      & $\checkmark$ & $\checkmark$ & $\checkmark$ & $\sim$       & $\sim$       & $\sim$ \\
SSG      & $\checkmark$ & $\checkmark$ & $\checkmark$ & $\sim$       & $\sim$       & $\sim$ \\
EFANNA   & $\times$     & $\sim$       & $\times$     & $\times$     & $\times$     & $\times$ \\
KGRAPH   & $\times$     & $\times$     & $\times$     & $\times$     & $\times$     & $\times$ \\
DPG      & $\times$     & $\sim$       & $\sim$       & $\sim$       & $\sim$       & $\sim$ \\
SPTAG    & $\sim$       & $\checkmark$ & $\times$     & $\times$     & $\checkmark$ & $\times$ \\
HCNNG    & $\checkmark$ & $\checkmark$ & $\checkmark$ & $\checkmark$ & $\checkmark$ & $\sim$ \\
LSHAPG   & $\times$     & $\sim$       & $\times$     & $\sim$       & $\checkmark$ & $\checkmark$ \\
NGT      & $\sim$       & $\sim$       & $\times$     & $\times$     & $\checkmark$ & $\times$ \\
SPTAG    & $\sim$       & $\sim$       & $\sim$       & $\times$     & $\checkmark$ & $\times$ \\
\bottomrule
\end{tabular}
}
\centering
\caption{\karima{Comparative Analysis}}
   \vspace*{-0.2cm}

\label{tab:comp}
\end{table}

\noindent{\bf Unexpected Results.} Our results lead to interesting observations that warrant further study. 
%\begin{itemize}
    %\item   

\noindent
\textit{(1) Stacked NSW:} while hierarchical layers of NSW graphs have shown promise in improving search performance on billion-scale datasets (Figure~\ref{fig:ss:search}), our experiments demonstrate that a simpler approach like K-random sampling can achieve better results on smaller and medium-sized datasets. 
%\textit{(2) Impact of SS on graph indexing:}  even though the difference between the two best SS strategies, SN and KS, is not significant on small datasets, it was surprising to observe that this difference can grow much larger during indexing (Table~\ref{tab:ss:idx}). 

\noindent
\textit{(2) Scalability of Graph Approaches:} while all graph-based vector search methods can efficiently build indexes on small datasets, most approaches face significant scalability challenges. 
Some methods (SPTAG, NGT, NSG, and SSG) demonstrate
impressive search performance on 1M and 25GB datasets (Figs. ~\ref{fig:elpis:query:performance:1M:sift:10NN}, ~\ref{fig:elpis:query:performance:1M:deep:10NN}, ~\ref{fig:elpis:query:performance:25GB:seismic:10NN},~\ref{fig:elpis:query:performance:25GB:deep:10NN}, and ~\ref{fig:elpis:query:performance:25GB:sald:10NN}) but their index construction could not scale to 100GB and billion-scale datasets. An important research direction is to improve the indexing scalability for these methods either by adopting summarization techniques during index construction or by using a scalable data structure to construct the base graph (i.e IVFPQ~\cite{faiss} to find the neighbors of nodes during insertion). 

\noindent
\textit{(3) DC-based approach for hard datasets and workloads:} an interesting finding was the superior performance of DC-based approaches compared to other methods like HNSW, NSG, and Vamana on challenging datasets/workloads such as Seismic, RandPow0, RandPow50 and Deep hard query workload for 1M and 25GB dataset sizes. We believe the DC strategy helps in this context because the graphs are built on clustered subsets of data, which facilitates beam search in retrieving more accurate nearest neighbors (NN), as opposed to running the search on the entire dataset, which results in lower accuracy (Figures~\ref{fig:elpis:query:performance:1M:seismic:10NN}, \ref{fig:elpis:query:performance:25GB:seismic:10NN}, \ref{fig:query:performance:25GB:rand:pow1:10NN}, and~\ref{fig:query:performance:25GB:rand:pow50:10NN}).
\karima{The optimized implementations from~\cite{parlayann} exhibit faster query times during search, but the gap narrows down with high recall. 
%A reason for this may be that the impact of efficient data structures employed in~\cite{parlayann} {\bf be specific. what types of structures?} diminishes as the cost of distance calculations becomes the bottleneck.} \tp{do we need to explain this? it won't be easy did the reviewers ask? if not, let's forget it} \karima{the reviewers did not ask}
}

\noindent{\bf Neighborhood Diversification.} Adopting an ND strategy to sparsify the graph \textit{always} leads to better search performance, particularly as the dataset size grows
%This is evident when comparing the performance of ND-based approaches to NP-based approaches like EFANNA and KGraph 
(Figures \ref{fig:elpis:query:performance:1M:seismic:10NN}, \ref{fig:elpis:query:performance:25GB:seismic:10NN}). 
%The importance of ND increases with the dataset size, as the search performance of both EFANNA and KGraph deteriorates further on 25GB datasets. 
%Notably, among ND approaches, our experiments show that RND and MOND provide the most search efficiency (Figure \ref{fig:ND:search:real}). Nevertheless, we firmly believe there is significant room for improvement in this direction, also further theoretical studies are necessary to understand how neighborhood diversification can enhance the construction of efficient graph structures while maintaining good connectivity within the graph (proximity vs. sparsity).
Our experiments also show that RND and MOND lead to the best search performance overall (Figure \ref{fig:ND:search:real}). Nevertheless, we believe there is significant room for improvement in this direction. Besides, we argue that further theoretical studies are necessary to better understand the trade-offs between proximity and sparsity, and thus build graph structures 
 that are efficient during search and maintain good connectivity.

\noindent{\bf Seed Selection:} Our experiments demonstrate that the SS strategy plays a crucial role in enhancing not only search performance (Figure~\ref{fig:ss:search}) but also indexing efficiency (Table \ref{tab:ss:idx}). An important research direction is to develop novel, lightweight SS strategies. Such strategies could significantly improve the overall performance of graph-based vector search, both in terms of indexing and query-answering. Additionally, they could enhance the ability to handle out-of-distribution queries, particularly for large datasets where efficient seed selection becomes even more critical (Figures \ref{fig:ss:deep1b}, \ref{fig:ss:sift1b}).

%\textit{(2) Impact of SS on graph indexing:}  even though the difference between the two best SS strategies, SN and KS, is not significant on small datasets, it was surprising to observe that this difference can grow much larger during indexing (Table~\ref{tab:ss:idx}). 

\noindent{\bf Data-Adaptive Techniques.} Our experiments evaluate the performance of various graph-building paradigms within our taxonomy (SS, NP, II, ND, and DC). While NP-based methods perform the worst overall and are the least scalable, there is no clear winner across all dataset sizes and query workloads. \textit{(1) Scalability:} II-based approaches have superior efficiency during indexing and higher scalability in both querying and indexing.
\textit{(2) Query Answering:} ND-based methods have the best query performance overall. 
%less challenging datasets (\karima{refer to figures +H explain what is meant by less challenging: RC, LID}). 
Meanwhile, DC-based approaches are superior on challenging datasets (High LID\&Low RC, Fig. \ref{fig:datacomp}) and hard query workloads \karima{(Fig. \ref{fig:elpis:query:performance:1B:t2i:10NN},
\ref{fig:elpis:query:performance:1M:seismic:10NN}, 
\ref{fig:elpis:query:performance:25GB:seismic:10NN}, 
\ref{fig:search:query:performance:25GB:hard},
\ref{fig:query:performance:25GB:rand:pow50:10NN},
\ref{fig:query:performance:25GB:rand:pow1:10NN})}. 
A promising research direction would be to develop techniques that adapt to dataset characteristics such as dataset size, dimensionality, RC and LID to excel both in indexing and query answering across a variety of query workloads and dataset sizes.

\noindent{\bf Hybrid Design.}  Most recent methods use a mix of paradigms. HNSW leverages II to scale index construction to large datasets and ND to support efficient query answering. ELPIS incorporates a DC-based strategy during both index building and search to further enhance the scalability of HNSW across varying dataset difficulty levels. Interestingly, Vamana, relying only on the ND paradigm, achieves good search performance and scalability, however its indexing time is prohibitive. 
A promising research direction is building hybrid approaches that combine the key strengths of different techniques, particularly II, ND and DC. Besides, devising novel base graphs, clustering and summarization techniques tailored for DC-based methods can further improve their performance.

\karima{\noindent{\bf Optimized Libraries.}  
Our experiments with the parlayNN library~\cite{parlayann} (Fig. \ref{fig:optimized_impl}) indicate the importance of such work. 
For instance, the parlayNN HCNNG\_Opt implementation was scalable to 1B datasets, whereas the non-optimized version could not scale beyond 25GB. 
%We believe that 
Other methods could benefit from such optimizations to scale to large datasets, and further efforts are needed by the community to adopt and support libraries such as parlayNN.}
 

\karima{\noindent{\bf Recommendations.}
Our study demonstrates varying performance trends across datasets of different sizes, query workloads of different hardness and desired recall values. Figure~\ref{fig:recgann} provides recommendations for methods based on these criteria.  For small to medium-sized datasets (25GB and below), HNSW, NSG, and its improved version, SSG, consistently demonstrate excellent performance on easier datasets (Fig.\ref{fig:elpis:query:performance:1M:deep:10NN}, \ref{fig:elpis:query:performance:1M:sift:10NN}, \ref{fig:elpis:query:performance:1M:imagenet:10NN}, \ref{fig:elpis:query:performance:1M:gist:10NN}). On harder datasets, DC-based methods like SPTAG, ELPIS, and HCNNG prove more efficient (Figs. \ref{fig:elpis:query:performance:1M:seismic:10NN} \ref{fig:elpis:query:performance:25GB:seismic:10NN}, \ref{fig:elpis:query:performance:1M:sald:10NN}, \ref{fig:elpis:query:performance:25GB:sald:10NN}, \ref{fig:search:query:performance:25GB:hard:1p}, \ref{fig:search:query:performance:25GB:hard:10p}). 
On large datasets (100GB and above), HNSW and ELPIS consistently rank as top choices (Figs.\ref{fig:elpis:query:performance:100GB}, \ref{fig:elpis:query:performance:1B}). 
%For NSG, SPTAG, and HCNNG, scalability becomes a challenge. %This highlights the need for more efficient public implementations of these methods, such as ParlayANN, which we also recommend for efficient implementations of HNSW, VAMANA, and HCNNG.
}

\begin{figure}[tb]
  \captionsetup{justification=centering}
    \includegraphics[width=0.55\columnwidth]{../img-png/figures/recgann.png}
    \vspace*{-0.2cm}
    \caption{\karima{Recommendations (Indexing + 10K queries)} }
   \vspace*{-0.2cm}
    \label{fig:recgann}
\end{figure}
%\ilias{\url{https://docs.google.com/presentation/d/1tA3viMqyWiFN2162Uq68qnPEYuFjRhcXQA02amMTFCs/edit?usp=sharing}}}
    

\begin{comment}
\ilias{Key Conclusions:
\begin{enumerate}
    \item \textbf{Neighborhood Diversification:}
    \begin{enumerate}[i.]
        \item Sparsifying the graph through different ND techniques leads to better performance of various dataset scales, with RND and MOND providing most efficiency (Figure \ref{fig:ND:search:real}).
        \item Further theoretical studies are also necessary to understand how neighborhood diversification can enhance the construction of efficient graph structures, while maintaining good connectivity within the graph (proximity vs. sparsity).
    \end{enumerate}

    \item \textbf{Seed Selection:}
    \begin{enumerate}[i.]
        \item The choice of seed selection strategies can improve not only the search (Figure \ref{fig:ss:search}) but also the indexing performance (Figure \ref{fig:ss:idx}).
        \item Sophisticated lightweight structures such as SN proposed by HNSW lead to the best performance on large scale (1B), while a simple yet efficient method such as K random sampling gives the best performance on small and medium scale (25GB \& 100GB) (Figure \ref{fig:ss:search}).
        \item Designing better strategies and lightweight structures for SS to efficiently represent dataset distribution and provide superior search seeds can enhance graph-based approaches in both search and indexing, particularly since top-performing methods are ND-based. This also improves graph performance in handling out-of-distribution queries.
    \end{enumerate}

    \item \textbf{Benchmark:}
\begin{enumerate}[i.]
    \item II-based approaches show the best scalability where only HNSW, ELPIS, and Vamana could scale to a 1B dataset, with ELPIS having the smallest indexing time and footprint (Figures \ref{fig:elpis:idx:time}; \ref{fig:elpis:idx:footprint:memory}).
    \item ND-based approaches provide the best overall search performance. Approaches such as NSSG, HNSW, and NSG give top performance on 1M datasets (Figure \ref{fig:elpis:query:performance:1M}). 
    \item On hard datasets and queries, DC based approaches shows the best performance (Figures \ref{fig:elpis:query:performance:1M:seismic:10NN});\ref{fig:elpis:query:performance:25GB:seismic:10NN}; \ref{fig:search:query:performance:25GB:hard} 
    \item On large scale dataset, ELPIS delivers the best performance (Figures \ref{fig:elpis:query:performance:25GB};\ref{fig:elpis:query:performance:100GB}; \ref{fig:elpis:query:performance:1B}).

\end{enumerate}
    
\end{enumerate}
}
\end{comment}