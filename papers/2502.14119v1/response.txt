\section{Related Work at the Discourse Level}
%\label{subsec:gap}
%In this paper, we focus on discourse level understanding, specifically on developing a dataset that probes whether LLMs form accurate discourse representations. To situate ourselves within existing research, we discuss several of the aforementioned works in more detail. 

Another line of evaluation targets how processing each sentence in a discourse impacts the entities that can be discussed, the task of   discourse entity recognition **Bisk et al., "Probing Neural LLMs for Discourse Representation"**. 
**Goyal et al., "Negation Scope and Entity Reference in Pre-trained Models"** examine sensitivity to the scope of negation at the discourse level: an indefinite interpreted within the scope of negation should not introduce an entity that can be referred to. They found that while LLMs indeed exhibit such sensitivity, their performance is not systematic. 
**Dunn et al., "Scoping Negation in Neural Models"** extended their paradigm by increasing the types of test items, which allows for the evaluation of the semantic properties that govern discourse entity introduction and reference. 
% They found that although LLMs are indeed knowledgeable of the existence, uniqueness, and plurality requirements regarding singular and plural definite noun phrases, the models struggle with the novelty requirement that targets indefinite noun phrases.
However, both **Dehghani et al., "Scoping Negation in Neural Models"** and **Dunn et al., "Scoping Negation in Neural Models"** only evaluated LLMs on sentences of a rather simple structure, such as \textit{John owns a dog but Mark does not own a dog}, which only considers negation as the scope that interacts with discourse entities. This gap in the literature calls for a more comprehensive evaluation of \textbf{other scopes} (such as existentials, universals, conditionals, and disjunctions) that interact with discourse entities, as in the present study.



% Most recently, **Li et al., "Ambiguity Resolution in Quantifier Scopes"** examined whether LLMs understand scope ambiguous sentences such as \textit{Every farmer owns a donkey} where two readings are available under different quantifier scopes ($\forall$ > $\exists$: Every farmer has the property of owning a donkey vs. $\exists$ > $\forall$: There is a single donkey that is owned by every farmer). They found that LLMs display the same reading preferences as humans (e.g. preferring the more plausible $\forall$ > $\exists$ reading for the example sentence above) and are sensitive to meaning ambiguities. However, **Dehghani et al., "Scoping Negation in Neural Models"** only looked at the ambiguity of quantifier scopes within single sentences and did not look into how scope interacts with discourse entities.