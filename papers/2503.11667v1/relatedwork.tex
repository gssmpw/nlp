\section{Related Work}
\label{sec:related-work}
The original Logit Lens concept demonstrated that meaningful token predictions could be extracted from intermediate transformer layers \cite{nostalgebraist2020interpreting}. Subsequent improvements introduced the Tuned Lens \cite{belrose2023elicitinglatentpredictionstransformers}, which applies learned transformations to intermediate activations for clearer interpretation. Parallel work developed complementary techniques like Patchscopes \cite{ghandeharioun2024patchscopesunifyingframeworkinspecting} and gradient projection methods \cite{katz2024backwardlensprojectinglanguage}, creating a rich ecosystem of transformer analysis tools.\\
\\
Recent applications have revealed fundamental insights about LLM internals. Wu\cite{wu2024semantichubhypothesislanguage} used Logit Lens to identify cross-lingual semantic hubs, while Jia\cite{jaturong2025an} employed it to study prediction refinement dynamics. Safety researchers \cite{ashkan2024mechanistic} and alignment investigators \cite{bhalla2025unifyinginterpretabilitycontrolevaluation} have leveraged these techniques to localize critical model behaviors. However, all such studies remain constrained by the limited model support of existing implementations.