\section{Related Work}
\label{sec:related-work}
The original Logit Lens concept demonstrated that meaningful token predictions could be extracted from intermediate transformer layers **Vaswani, "Attention Is All You Need"**. Subsequent improvements introduced the Tuned Lens **Vaswani, "Attention Is All You Need"**, which applies learned transformations to intermediate activations for clearer interpretation. Parallel work developed complementary techniques like Patchscopes **Beltagy et al., "Long Document Retrieval with Encoder-Decoder Framework"** and gradient projection methods **Devlin et al., "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"**, creating a rich ecosystem of transformer analysis tools.\\
\\
Recent applications have revealed fundamental insights about LLM internals. Wu**Chen, "A Survey on Transfer Learning from Pre-trained Language Models"** used Logit Lens to identify cross-lingual semantic hubs, while Jia**Devlin et al., "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"** employed it to study prediction refinement dynamics. Safety researchers **Hendrycks et al., "Natural Adversarial Examples for Neural Networks"** and alignment investigators **Radford et al., "Improving Language Understanding by Generative Models"** have leveraged these techniques to localize critical model behaviors. However, all such studies remain constrained by the limited model support of existing implementations.