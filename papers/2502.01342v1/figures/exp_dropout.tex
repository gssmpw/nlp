

\begin{figure*}[ht!]
    \centering
    \includegraphics[width=0.3\textwidth]{figures/sources/mainnet_pls_acc.pdf}
    \includegraphics[width=0.3\textwidth]{figures/sources/subnet_pls_acc.pdf}
    \includegraphics[width=0.3\textwidth]{figures/sources/warm_start_dropout.pdf}
    \caption{\textbf{Left.} Random label MNIST experiment using an 8-layer MLP. Higher dropout probabilities result in significant trainability loss. 
    \textbf{Middle.} Accuracy of the subnetworks trained on random target. Each subnetworks are sampled from original network after each epoch. Subnetworks of the Dropout also experience trainability loss. \textbf{Right.} Warm-start scenario of Resnet-18 model with CIFAR100 dataset. Dropout improves generalization performance; however, the reduction in accuracy compared to the cold-start scenario is nearly identical to that of the vanilla model.}
    \label{exp_dropout}
\end{figure*}

