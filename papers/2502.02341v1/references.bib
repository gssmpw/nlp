@article{balakrishnan2019voxelmorph,
  title={VoxelMorph: A Learning Framework for Deformable Medical Image Registration},
  author={Guha Balakrishnan and Amy Zhao and Mert Rory Sabuncu and John V. Guttag and Adrian V. Dalca},
  journal={IEEE Transactions on Medical Imaging},
  year={2018},
  volume={38},
  pages={1788-1800},
  url={https://api.semanticscholar.org/CorpusID:52281312}
}

@inproceedings{kim2024data,
  title={Data-Efficient Unsupervised Interpolation Without Any Intermediate Frame for 4D Medical Images},
  author={Kim, JungEun and Yoon, Hangyul and Park, Geondo and Kim, Kyungsu and Yang, Eunho},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={11353--11364},
  year={2024}
}

@article{doersch2015unsupervised,
  title={Unsupervised Visual Representation Learning by Context Prediction},
  author={Carl Doersch and Abhinav Kumar Gupta and Alexei A. Efros},
  journal={2015 IEEE International Conference on Computer Vision (ICCV)},
  year={2015},
  pages={1422-1430},
  url={https://api.semanticscholar.org/CorpusID:9062671}
}

@article{gidaris2018unsupervised,
  title={Unsupervised representation learning by predicting image rotations},
  author={Gidaris, Spyros and Singh, Praveer and Komodakis, Nikos},
  journal={arXiv preprint arXiv:1803.07728},
  year={2018}
}

@inproceedings{chen2020simple,
  title={A simple framework for contrastive learning of visual representations},
  author={Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey},
  booktitle={International conference on machine learning},
  pages={1597--1607},
  year={2020},
  organization={PMLR}
}

@inproceedings{sun2020test,
  title={Test-time training with self-supervision for generalization under distribution shifts},
  author={Sun, Yu and Wang, Xiaolong and Liu, Zhuang and Miller, John and Efros, Alexei and Hardt, Moritz},
  booktitle={International conference on machine learning},
  pages={9229--9248},
  year={2020},
  organization={PMLR}
}

@article{Guo2020ASV,
  title={A Spatiotemporal Volumetric Interpolation Network for 4D Dynamic Medical Image},
  author={Yuyu Guo and Lei Bi and Euijoon Ahn and David Dagan Feng and Qian Wang and Jinman Kim},
  journal={2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2020},
  pages={4725-4734},
  url={https://api.semanticscholar.org/CorpusID:211572601}
}

@article{Wei2023MPVF4M,
  title={MPVF: 4D Medical Image Inpainting by Multi-Pyramid Voxel Flows},
  author={Tzu-Ti Wei and Chin-Ting Kuo and Yu-Chee Tseng and Jen-Jee Chen},
  journal={IEEE Journal of Biomedical and Health Informatics},
  year={2023},
  volume={27},
  pages={5872-5882},
  url={https://api.semanticscholar.org/CorpusID:262147608}
}

@article{CHEN2022102615,
title = {TransMorph: Transformer for unsupervised medical image registration},
journal = {Medical Image Analysis},
volume = {82},
pages = {102615},
year = {2022},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2022.102615},
url = {https://www.sciencedirect.com/science/article/pii/S1361841522002432},
author = {Junyu Chen and Eric C. Frey and Yufan He and William P. Segars and Ye Li and Yong Du},
keywords = {Image registration, Deep learning, Vision transformer, Computerized phantom},
abstract = {In the last decade, convolutional neural networks (ConvNets) have been a major focus of research in medical image analysis. However, the performances of ConvNets may be limited by a lack of explicit consideration of the long-range spatial relationships in an image. Recently, Vision Transformer architectures have been proposed to address the shortcomings of ConvNets and have produced state-of-the-art performances in many medical imaging applications. Transformers may be a strong candidate for image registration because their substantially larger receptive field enables a more precise comprehension of the spatial correspondence between moving and fixed images. Here, we present TransMorph, a hybrid Transformer-ConvNet model for volumetric medical image registration. This paper also presents diffeomorphic and Bayesian variants of TransMorph: the diffeomorphic variants ensure the topology-preserving deformations, and the Bayesian variant produces a well-calibrated registration uncertainty estimate. We extensively validated the proposed models using 3D medical images from three applications: inter-patient and atlas-to-patient brain MRI registration and phantom-to-CT registration. The proposed models are evaluated in comparison to a variety of existing registration methods and Transformer architectures. Qualitative and quantitative results demonstrate that the proposed Transformer-based model leads to a substantial performance improvement over the baseline methods, confirming the effectiveness of Transformers for medical image registration.}
}

@misc{jia2023fouriernetleveragingbandlimitedrepresentation,
      title={Fourier-Net+: Leveraging Band-Limited Representation for Efficient 3D Medical Image Registration}, 
      author={Xi Jia and Alexander Thorley and Alberto Gomez and Wenqi Lu and Dipak Kotecha and Jinming Duan},
      year={2023},
      eprint={2307.02997},
      archivePrefix={arXiv},
      primaryClass={eess.IV},
      url={https://arxiv.org/abs/2307.02997}, 
}

@article{JOSHI2023102917,
title = {R2Net: Efficient and flexible diffeomorphic image registration using Lipschitz continuous residual networks},
journal = {Medical Image Analysis},
volume = {89},
pages = {102917},
year = {2023},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2023.102917},
url = {https://www.sciencedirect.com/science/article/pii/S1361841523001779},
author = {Ankita Joshi and Yi Hong},
keywords = {Unsupervised diffeomorphic image registration, Deep residual networks, Lipschitz continuity, Stationary and non-stationary velocity fields, Multi-scale registration},
abstract = {Classical diffeomorphic image registration methods, while being accurate, face the challenges of high computational costs. Deep learning based approaches provide a fast alternative to address these issues; however, most existing deep solutions either lose the good property of diffeomorphism or have limited flexibility to capture large deformations, under the assumption that deformations are driven by stationary velocity fields (SVFs). Also, the adopted squaring and scaling technique for integrating SVFs is time- and memory-consuming, hindering deep methods from handling large image volumes. In this paper, we present an unsupervised diffeomorphic image registration framework, which uses deep residual networks (ResNets) as numerical approximations of the underlying continuous diffeomorphic setting governed by ordinary differential equations, which is parameterized by either SVFs or time-varying (non-stationary) velocity fields. This flexible parameterization in our Residual Registration Network (R2Net) not only provides the modelâ€™s ability to capture large deformation but also reduces the time and memory cost when integrating velocity fields for deformation generation. Also, we introduce a Lipschitz continuity constraint into the ResNet block to help achieve diffeomorphic deformations. To enhance the ability of our model for handling images with large volume sizes, we employ a hierarchical extension with a multi-phase learning strategy to solve the image registration task in a coarse-to-fine fashion. We demonstrate our models on four 3D image registration tasks with a wide range of anatomies, including brain MRIs, cine cardiac MRIs, and lung CT scans. Compared to classical methods SyN and diffeomorphic VoxelMorph, our models achieve comparable or better registration accuracy with much smoother deformations. Our source code is available online at https://github.com/ankitajoshi15/R2Net.}
}

@article{Kim2022DiffusionDM,
  title={Diffusion Deformable Model for 4D Temporal Medical Image Generation},
  author={Boah Kim and Jong-Chul Ye},
  journal={ArXiv},
  year={2022},
  volume={abs/2206.13295},
  url={https://api.semanticscholar.org/CorpusID:250072903}
}

@InProceedings{pmlr-v172-wolterink22a,
  title = 	 {Implicit Neural Representations for Deformable Image Registration},
  author =       {Wolterink, Jelmer M and Zwienenberg, Jesse C and Brune, Christoph},
  booktitle = 	 {Proceedings of The 5th International Conference on Medical Imaging with Deep Learning},
  pages = 	 {1349--1359},
  year = 	 {2022},
  editor = 	 {Konukoglu, Ender and Menze, Bjoern and Venkataraman, Archana and Baumgartner, Christian and Dou, Qi and Albarqouni, Shadi},
  volume = 	 {172},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--08 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v172/wolterink22a/wolterink22a.pdf},
  url = 	 {https://proceedings.mlr.press/v172/wolterink22a.html},
  abstract = 	 {Deformable medical image registration has in past years been revolutionized by the use of convolutional neural networks. These methods surpass conventional image registration techniques in speed but not in accuracy. Here, we present an alternative approach to leveraging neural networks for image registration. Instead of using a convolutional neural network to predict the transformation between images, we optimize a multi-layer perceptron to represent this transformation function. Using recent insights from differentiable rendering, we show how such an implicit deformable image registration (IDIR) model can be naturally combined with regularization terms based on standard automatic differentiation techniques. We demonstrate the effectiveness of this model on 4D chest CT registration in the DIR-LAB data set and find that a three-layer multi-layer perceptron with periodic activation functions outperforms all published deep learning-based results on this problem, without any folding and without the need for training data. The model is implemented using standard deep learning libraries and flexible enough to be extended to include different losses, regularizers, and optimization schemes.}
}

@article{Costanzino2024TestTT,
  title={Test Time Training for Industrial Anomaly Segmentation},
  author={Alex Costanzino and Pierluigi Zama Ramirez and Mirko Del Moro and Agostino Aiezzo and Giuseppe Lisanti and Samuele Salti and Luigi Di Stefano},
  journal={2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)},
  year={2024},
  pages={3910-3920},
  url={https://api.semanticscholar.org/CorpusID:268987537}
}

@inproceedings{
bertrand2023testtime,
title={Test-time Training for Matching-based Video Object Segmentation},
author={Juliette Bertrand and Giorgos Kordopatis-Zilos and Yannis Kalantidis and Giorgos Tolias},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
year={2023},
url={https://openreview.net/forum?id=9QsdPQlWiE}
}

@article{sun2019unsupervised,
  title={Unsupervised domain adaptation through self-supervision},
  author={Sun, Yu and Tzeng, Eric and Darrell, Trevor and Efros, Alexei A},
  journal={arXiv preprint arXiv:1909.11825},
  year={2019}
}

@article{gandelsman2022test,
  title={Test-time training with masked autoencoders},
  author={Gandelsman, Yossi and Sun, Yu and Chen, Xinlei and Efros, Alexei},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={29374--29385},
  year={2022}
}

@inproceedings{he2022masked,
  title={Masked autoencoders are scalable vision learners},
  author={He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={16000--16009},
  year={2022}
}

@article{liang2024comprehensive,
  title={A comprehensive survey on test-time adaptation under distribution shifts},
  author={Liang, Jian and He, Ran and Tan, Tieniu},
  journal={International Journal of Computer Vision},
  pages={1--34},
  year={2024},
  publisher={Springer}
}

@inproceedings{noroozi2016unsupervised,
  title={Unsupervised learning of visual representations by solving jigsaw puzzles},
  author={Noroozi, Mehdi and Favaro, Paolo},
  booktitle={European conference on computer vision},
  pages={69--84},
  year={2016},
  organization={Springer}
}

@article{chen2019self,
  title={Self-supervised learning for medical image analysis using image context restoration},
  author={Chen, Liang and Bentley, Paul and Mori, Kensaku and Misawa, Kazunari and Fujiwara, Michitaka and Rueckert, Daniel},
  journal={Medical image analysis},
  volume={58},
  pages={101539},
  year={2019},
  publisher={Elsevier}
}

@inproceedings{taleb2021multimodal,
  title={Multimodal self-supervised learning for medical image analysis},
  author={Taleb, Aiham and Lippert, Christoph and Klein, Tassilo and Nabi, Moin},
  booktitle={International conference on information processing in medical imaging},
  pages={661--673},
  year={2021},
  organization={Springer}
}