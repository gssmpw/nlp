\section{Conclusion}
% In this work, we begin by revisiting existing token reduction methods that rely on attention scores to identify important tokens. We observe that this paradigm is fraught with limitations. Methods based on this paradigm, such as SparseVLM and FastV, underperform even compared to random retention of visual tokens on certain benchmarks. Visual analysis further reveals a noticeable bias in the selection of important tokens when relying on attention scores. Moreover, the involvement of attention scores in token reduction prevents these methods from being fully compatible with Flash Attention.
% To address these issues, we propose a novel, train-free, plug-and-play token reduction method called DART, which is seamlessly compatible with Flash Attention. Our approach is grounded in the concept of token redundancy. We conduct extensive evaluations across multiple benchmarks, encompassing both image-understanding and video-understanding tasks. We compare DART with state-of-the-art methods under the same reduction ratio and latency conditions, demonstrating its superior performance.
% \textcolor{red}{todo...}
% % 实验表明DART...

% In this work, we revisit existing token reduction methods that rely on attention scores to identify important tokens and uncover significant limitations. Methods such as SparseVLM and FastV, based on this paradigm, underperform even compared to random token retention on certain benchmarks. Visual analysis further reveals a noticeable bias in token selection when using attention scores. Additionally, the reliance on attention scores hinders compatibility with Flash Attention.
% To address these issues, we propose \textbf{\algname}, a train-free, plug-and-play token reduction method fully compatible with Flash Attention, based on the concept of token duplication.
% \algname has been extensively evaluated across multiple benchmarks for image and video understanding tasks. Under identical reduction ratios and latency conditions (See Figure~\ref{fig:latency_vs_performance}, Table~\ref{tab:main}, \ref{tab:qwen2vl}, and \ref{tab:minicpm}), \algname demonstrates superior performance compared to existing state-of-the-art methods.

% In this work, we revisit existing token reduction methods that rely on attention scores to identify important tokens and uncover significant limitations. Methods such as SparseVLM and FastV, based on this paradigm, underperform even compared to random token retention on certain benchmarks and have a noticeable bias in token selection. Additionally, the reliance on attention scores hinders compatibility with Flash Attention.
% To address these issues, we propose \textbf{\algname}, a train-free, plug-and-play token reduction method fully compatible with Flash Attention, based on token duplication.
% \algname has been extensively evaluated across multiple benchmarks for image and video understanding tasks. Under identical reduction ratios and latency conditions (See Figure~\ref{fig:latency_vs_performance}, Table~\ref{tab:main}, \ref{tab:qwen2vl}, and \ref{tab:minicpm}), \algname demonstrates superior performance compared to existing state-of-the-art methods.


% ---------- insightful version ---------------
% The pursuit of efficient token reduction in multimodal large language models (MLLMs) has traditionally focused on token ``importance'', typically gauged by attention scores. 
% However, we identify several limitations in these approaches: they overlook the dynamic nature of token importance during pruning, exhibit position bias in attention scores, and demonstrate incompatibility with Flash Attention.
% This study challenges this conventional paradigm by uncovering a crucial, yet neglected perspective: token duplication. 
% Based on this, we develop \textbf{\algname}, a training-free and plug-and-play token reduction method that achieves a better trade-off between performance and latency (Tab.~\ref{tab:main},~\ref{tab:qwen2vl},~\ref{tab:minicpm},~\ref{tab:efficiency} and Fig.~\ref{fig:latency_vs_performance}). 
% In our in-depth exploration, we made some remarkable findings: There may exist multiple sets of ``important'' tokens, as several distinct groups of retained visual tokens with an overlap of less than 50\% can still achieve competitive performance (\secref{pivot_token_selection}).
% Furthermore, token pruning may be able to mitigate hallucinations (\secref{sec:Layer_and_num}).
% These observations highlight the limitations of importance-based methods, revealing token pruning's potential to reduce hallucinations and provide insights for optimizing accuracy and efficiency in MLLMs.

The pursuit of efficient token reduction in MLLMs has traditionally centered on token ``importance'' often measured by attention scores, sometimes suffering from worse performance than random token pruning.
%However, these approaches face notable limitations: they neglect the dynamic nature of token importance during pruning, exhibit position biases in attention scores, and are incompatible with Flash Attention. 
This study introduces \algname, which focuses on the duplication of tokens, aiming to remove the tokens that are similar to others, leading to a superior balance between performance and latency in 13 benchmarks and 5 MLLMs (Tab.~\ref{tab:main},~\ref{tab:efficiency},~\ref{tab:qwen2vl},~\ref{tab:minicpm}, and Fig.~\ref{fig:latency_vs_performance}). 
Our exploration yields surprising insights: multiple distinct sets of retained tokens, sharing less than 50\% overlap, can deliver comparable and good performance (\secref{pivot_token_selection}). Additionally, token pruning shows potential to mitigate hallucinations (\secref{sec:Layer_and_num}). These observations highlight the limitations of importance-based methods and may offer valuable insights into the influence of vision tokens in MLLMs.

%revealing token pruning's potential to reduce hallucinations and provide insights for optimizing accuracy and efficiency in MLLMs.
