\section{Concluding Remarks}

\label{Conclusion}

In this paper, we proposed a vision-language approach to detect content rating violations in Google Play Store. Our model includes multiple trained encoders capturing features related to app creative styles, content, text descriptions and their relationships using a cross-attention module. We trained our model using a large dataset from Google Play Store focusing on gaming apps. Our method outperformed the state-of-the-art CLIP model, even when fine-tuned on the same dataset. We achieved 5.9\% and 5.8\% relative improvements in accuracy compared to CLIP and fine-tuned CLIP, respectively. Even though our method doesn't achieve perfect accuracy, apps that deviate from the predicted rating (i.e., potential malpractices or disguises) can serve as a shortlist for e-safety regulators and app market operators, thereby reducing manual effort. By leveraging static information such as images and text, we can quickly identify apps for further inspection. Beyond these two categories, we also identified unverifiable apps that have been assigned higher content ratings, yet even human reviewers could not justify these ratings based on the app creatives and descriptions alone. While there is no legal requirement for an app’s creatives to explicitly reflect its content rating, we emphasize the importance of ensuring alignment between content descriptors and app creatives/descriptions. This transparency will help users to make informed decisions.


We applied our model in the wild and found that our model can detect content rating malpractices in practice. We could identify 71 ($\sim$17\% of what we verified) of such examples.
Some notable examples include gambling apps such as \emph{Liar's Dice VIP} being categorised as G and \emph{Drug Mafia 3d Weed} being categorised as PG. In addition to that, within our test set, 16.86\% of the apps we identified as violating content policies are no longer available in Google Play Store due to potential banning, further justifying the effectiveness of our method. As an artefact, we also found another interesting behaviour related to app content ratings in the Google Play Store characterised as \emph{potentially disguises}. These apps have a correct content rating. However, their look and feel appear to target a general audience. For example, an app with a cartoonish theme but mature content may inadvertently attract children, for whom the content could be disturbing. We identified 32 such instances. Finally, we conducted an extended evaluation on 2,172 `teacher approved' apps and identified nine apps with possible content rating malpractices. 


One limitation of our work is the reliance on top apps having reliable content ratings and representative app creatives. While several comparable works have used similar ideas in domains such as spam app detection~\cite{seneviratne2015early}, counterfeit detection~\cite{karunanayake2020multi}, this approach may introduce noise into the CLIP fine-tuning process. One way to mitigate this limitation is through human annotation, though this can be costly. Another approach is to match apps between the Google Play Store and Apple App Store using a method such as ~\cite{steinbock2024comparing}, leveraging Apple's content ratings, which typically undergo manual verification. However, Google and Apple use different content rating scales, which may introduce inconsistencies.

Additionally, incorporating other app metadata—such as user comments, data safety declarations, and dynamic app behaviors—could enhance the framework’s robustness against unverifiable apps. However, this approach is more resource- and time-intensive than analyzing text descriptions and app creatives. As a result, it could serve as a secondary classifier after identifying potential content rating violations at scale using our proposed method.
