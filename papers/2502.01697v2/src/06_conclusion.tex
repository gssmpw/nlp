\section{Conclusion}

\subsection{Key Contributions}

In summary, in this work we quantitatively investigated the quality and diversity of various synthetic data generation methods. Through this investigation, we find that base models are generally more diverse than instruct-tuned models while instruct-tuned models produce higher quality output than base models, validating hypotheses in the research community. These insights motivate the design of a better system to generate synthetic data, \Sys{}.

Through extensive experiments, we validate the importance of each step in \Sys{} and demonstrate its ability to preserve base model diversity while enhancing output quality. Moreover, by fine-tuning on \Sys{}-generated data for various domains, we underscore \Sys{}â€™s practical utility, consistently outperforming existing synthetic data generation methods on downstream tasks such as GSM8K and LiveCodeBench, in addition to RAFT, for which we set a new SOTA. 

\subsection{Future Work}

There are a lot of exciting directions for future work. For one, \Sys{} is not necessarily the only way to elicit diversity in the synthetic data generation process. We were able to achieve all of our results with essentially basic prompting, leading us to believe there is room for even more improvement if one was to, for example, fine-tune the refiner specifically for this use case or use stronger refiner models. Introducing additional stages to \Sys{} could also lead to improvements (e.g., additional refinement steps). Beyond multi-stage systems, the design space for diversity is vast -- in one direction, training instruct-tuned models with different objective functions that encourage entropy is another area of exploration.

Furthermore, the implications of a lack of high-quality, diverse generations from LLMs go beyond just synthetic data. For example, much of the work in inference time compute relies on models being able to generate sufficiently different possible trajectories and using these diverse trajectories (exploration) with a feedback signal to improve reasoning capabilities \cite{zhang2024accessing, zelikman2022starbootstrappingreasoningreasoning}, yet only a few methods look explicitly at generator diversity \cite{wang2024planning}.

Lastly, the same \Sys{} method demonstrated in this paper for synthetic training data can also be used with no modifications to generate synthetic evaluation sets, which are especially valuable in so many real-world domains with low-data availability.
