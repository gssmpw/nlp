\section{Related Work}
\label{related_work}

\paragraph{Synthetic Data.} Synthetic data is commonly used to train state of the art models like Llama 3.3 \cite{llama2024llama}, Qwen 2.5 \cite{qwen2025qwen25technicalreport}, Nemotron 4 \cite{nvidia2024nemotron4340btechnicalreport}, and o3-mini \cite{guan2025deliberativealignmentreasoningenables}. However, prior work has shown its usage poses risks such as model collapse, where iterative training on low-diversity data shifts the generation distribution toward a high-probability mean, degrading both performance and diversity \cite{Shumailov2024, shimabucoro2024llmseellmdo, guo2023curious}. Recent work has pointed towards diversity in training data improving downstream performance, though doesn't consider the quality of the data in tandem \cite{chen2024diversitysyntheticdataimpact}. In contrast, the \Sys{} pipeline is designed with both of these objectives in mind, producing diverse high-quality data to support model training.

\paragraph{Generation Methods.} Current methods to improve LLM generation diversity include prompting, sampling, and multi-stage generation.

Prompting methods leverage instruction-following by requesting distinct responses in single calls or varying prompts (e.g., assigning distinct `personalities' or randomizing few-shot examples) \cite{zhang-etal-2024-improving-diversity, naik2023diversity, frohling2024personas, chen2024diversitysyntheticdataimpact, li2022making}. However, compared to \Sys{}, these methods depend on pre-existing data or curated prompts, limiting scalability.

Sampling methods like temperature scaling and nucleus sampling \cite{Holtzman2020} are widely used, but often prioritize token-level randomness over semantic diversity. Indeed, methods such as logit suppression \cite{chung2023increasing} can enhance diversity but may require significant manual refinement to maintain quality.

Multi-Stage generation methods vary in approach. SimpleStrat \cite{wong2024simplestratdiversifyinglanguagemodel} explicitly generates strata of the solution space and then conditions responses on each, effective for short-answer responses (often a single word or phrase), though limiting applicability to broader synthetic data generation. More complex frameworks require extensive human setup or curation to seed the diversity with topics, making them less scalable \cite{lambert2024self, li2024syntheticdataalmostscratch, li2023textbooksneediiphi15}. In contrast, \Sys{}, is a practical two-step pipeline that we show works generally with minimal human involvement.

Prior work has studied differences in base and instruct models in calibration \cite{openai2024gpt4technicalreport} and agentic environments \cite{li2024predictingvsactingtradeoff}, though no work to our knowledge has leveraged base models for synthetic data generation.

\paragraph{Evaluating Synthetic Data.} Synthetic data utility is typically assessed by downstream performance, though to motivate better systems, we additionally study diversity and entry-wise quality.

Token-level metrics like self-BLEU \cite{zhu2018texygen} are common, though embedding-based approaches (e.g., BERTScore \cite{zhang2019bertscore}, Sentence-BERT \cite{reimers2019sentence}) better capture semantic diversity rather than token diversity, which is our primary focus.

Lastly, while dataset-wide quality is often measured via downstream performance, assessing individual synthetic samples remains underexplored. In \cref{motivation}, we introduce an entry-wise quality measure to evaluate sample realism, ensuring robust synthetic data generation.
