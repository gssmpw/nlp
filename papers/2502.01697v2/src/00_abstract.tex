\begin{abstract}
As the demand for high-quality data in model training grows, researchers and developers are increasingly generating synthetic data to tune and train LLMs.
A common assumption about synthetic data is that sampling from instruct-tuned models is sufficient; however, these models struggle to produce diverse outputsâ€”a key requirement for generalization. Despite various prompting methods, in this work we show that achieving meaningful diversity from instruct-tuned models remains challenging.
In contrast, we find base models without post-training exhibit greater diversity, but are less capable at instruction following and hence of lower quality.
Leveraging this insight, we propose \textbf{Base-Refine} (\Sys), a synthetic data generation method that combines the diversity of base models with the quality of instruct-tuned models through a two-stage process.
With minimal few-shot examples and curation, \Sys{} generates diverse and high-quality datasets, improving downstream task performance.
We show that fine-tuning with as few as 1,000 \Sys{}-generated samples can reach performance comparable to the best similarly sized models on LiveCodeBench tasks. 
Furthermore, fine-tuning with \Sys{}-generated data achieves a 101\% improvement over instruct-only data on GSM8K and a 18.4\% improvement over SOTA methods on RAFT.
\end{abstract}

\input{src/figures/abstract}
