\section{Evaluation}
\label{results}

We evaluate \Sys{} for diversity, data quality, and downstream utility on the same domains and against the same baseline methods presented in \cref{motivation}. We implement \Sys{} with Llama-3.1-70B-Base in the base generation stage and Llama-3.1-70B-Instruct in the refinement stage, and perform additional experiments with the Llama 3.1 8B family and with Llama 3.1 8/70B as the base model and GPT-4o as the refiner \cite{llama2024llama, openai2024hello}.

We follow generally the same sampling temperatures as in \cref{motivation}. However, for Enron and Newsgroups, we instead sample from Llama-3.1-8B-Instruct at temperature $0.7$ in order to maintain coherence in generations. We always sample the refine model at a temperature of $0.7$.

For evaluation of downstream utility for the generative tasks, we LoRA \cite{hu2021lora} fine-tune Llama-3.1-8B-Instruct for 4 epochs using the generated data, except for GSM8K where Llama-3.2-1B-Instruct \cite{llama2024llama} is fine-tuned instead due to high baseline performance of the 8B model. Other fine-tuning hyperparameters are in \cref{appendix_hyperparameters}. The fine-tuned models are evaluated on a static $n=100$ test set for HotpotQA and PubMedQA, a static $n=500$ test set for GSM8K, and the full $n=442$ test set for LCB TOP. In this section, we will focus only on the generative tasks; the downstream evaluation process for classification tasks is presented in \cref{appendix_class_train} and detailed results for all domains can be found in \cref{appendix_core}.

\input{src/figures/bare_v_base_diversity}

\paragraph{\Sys{} Quality \& Diversity.} We begin by looking at the quality/diversity trends of \Sys{} when compared with previous methods. From the histograms plotted in \cref{results-bare-diversity}, we can see that \Sys{} effectively does not change the similarity distribution of generated data when compared to the base model at all -- it is able to successfully retain the diversity of base generations. Detailed results with average embedding similarity scores can be found in \cref{appendix_core}.

\input{src/figures/bare_v_base_quality}

Simultaneously though, looking at \cref{ir-lift-plot}, we can see that while retaining diversity, \Sys{} leads to a monotonic increase in the IR for every domain - suggesting that it is able to lift the quality of the generations to be on par or in some cases even surpass directly sampling from an instruct model. Combined, this indicates that \Sys{} is capable of leveraging the diversity of base models and quality of instruct-tuned models in its end generations.

\input{src/figures/bare_prompting_accuracy}
\input{src/figures/bare_accuracy}

\paragraph{Fine-tuned Model Accuracy.} We now show the utility of \Sys{} datasets as a whole. In \cref{results-all-ft-accuracy}, we demonstrate the accuracy of a model fine-tuned on the datasets generated using different methods. Almost uniformly, \Sys{} leads to greater improvements in downstream model quality than generating from either Base or Instruct models, and across all domains \Sys{}-based data leads to the highest fine-tuned model accuracy.

Impressively, in \cref{prompt-main}, beyond just base and instruct sampling, we show that enhancing GPT-4o with \Sys{} using only a small base model like Llama-3.1-8B-Base produces \textbf{monotonically better} fine-tuning data than all prompting methods discussed in \cref{qd-investigation-results} that use only GPT-4o. These clear results showcase \Sys{}'s ability to out-perform the existing methods for high-quality, diverse data generation.

Focusing on the RAFT domains, \Sys{} improves upon the standard SOTA pipeline for fine-tuning LLMs for RAG by up to 18.4\%, as seen with the 8B family on HotpotQA (standard RAFT is implemented in our Instruct generation results). \Sys{} with both model families also outperforms existing RAFT pipelines on PubMedQA. While \Sys{} with the Llama 3.1 70B family does not improve upon RAFT for HotpotQA, switching out the Llama-3.1-70B-Instruct refiner for GPT-4o does lead to an improvement (\cref{appendix_core}).

On GSM8K, \Sys{} is the only method that provides useful training data. The un-trained model performance was 21.8\%, and fine-tuning on \Sys{} generated data achieves accuracies of 24.9\% and 32.8\% with the Llama 8B and 70B families, respectively. Accuracy when training with data generated by single model methods either decreased accuracy or had little difference. In fact, training on data generated by Llama-3.1-70B-Instruct led to an accuracy of just 17.8\%, which \Sys{} with Llama-3.1-70B-Base refined by GPT-4o outperforms by 101\% (35.8\% accuracy).

On LCB TOP, fine-tuning a Llama-3.1-8B-Instruct model on 1000 examples generated by \Sys{} using the Llama 3.1 8B model family for just 4 epochs resulted in performance of 28.1\% accuracy, comparable to the current top models of similar size on the LCB leaderboard: DeepSeekCoder 6.7B Instruct \cite{guo2024deepseek} at 32.7\% and Magicoder$\mathcal{S}$ DS 6.7B \cite{wei2024magicoder} at 32.4\%. While both these models perform slightly better, they used orders of magnitude more data and trained for longer than us.

Similar to HotpotQA, on LCB TOP, \Sys{} with the Llama 3.1 70B family shows less of an improvement than the 70B-instruct-only data generation method. Again, using GPT-4o as a refiner instead of Llama-3.1-70B-Instruct gives stronger results. This suggests that with the right refiner choice, \Sys{} consistently provides gains. We show detailed results of refining with GPT-4o in all domains in \cref{appendix_core}, emphasizing \Sys{}'s consistently strong data generation capabilities.

We also find that temperature ablations do not meaningfully affect the utility of instruct-tuned model generations, especially when compared to gains using \Sys{}. For details, see \cref{appendix_temp}.

\paragraph{Instruct-Instruct Ablation.} A possible challenge is that the gains in performance are due to a multi-step pipeline rather than combining a base and instruct-tuned model. To demonstrate the importance of using a base model in \Sys{}, we performed an ablation where an instruct-tuned model's generations are refined by an instruct-tuned model on the GSM8K task. The accuracy on the test set after switching Llama-3.1-70B-Base to Instruct in the first step drops from $29.8\%$ to $25.4\%$. This trend held when GPT-4o was the refiner as well, with a drop from $35.8\%$ to $30.8\%$. At the same time, the pattern of little change in the average pairwise similarity before and after refinement remains, indicating that diversity must be introduced in the first stage. Having earlier established that base models are most effective at diversity, we conclude that the use of base models is a necessary component of \Sys{}. Detailed results from this ablation are in \cref{appendix_refine}.
