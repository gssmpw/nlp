\section{Related Works}
\textbf{In-Context Learning.} Since its introduction by Devlin, "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding", ICL in LM has been studied extensively in various directions. For example, Liang et al., "Language Models as Zero-Shot Learners" analyzed the role of prompts in improving the ICL performance. Theoretical analysis of how LMs perform ICL has been proposed by Gu et al., "A Comprehensive Survey on In-Context Learning for Natural Language Processing". These works study the internal mechanism -- either with regularized linear regression or gradient descent -- of the transformer architecture, which is the workhorse behind most current state-of-the-art LMs. 

\textbf{Language model intervention.} Intervening on the hidden states of transformer-based LMs, or activations editing, has recently emerged as an efficient method for controllable text generation. Contrasting to weights editing, activations editing refers to modifying the output of attention heads on one or several layer(s) of the transformer architecture, ultimately steering the generated text to desirable outcomes. Initially proposed to perform text style transfer, this method has been extended to improve the performance of few shots / zero shots of ICL, such as in Zhang et al., "Activations Editing for Few-Shot Text Style Transfer". Our work follows this direction but improved upon them by using only a fewer number of prompt inputs. As such, the aforementioned works, most notably by Liu et al., "Towards Efficient In-Context Learning: A Survey", are directly related to our work.