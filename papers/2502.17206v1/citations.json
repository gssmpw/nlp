[
  {
    "index": 0,
    "papers": [
      {
        "key": "bahdanau2014neural",
        "author": "Bahdanau, Dzmitry",
        "title": "Neural machine translation by jointly learning to align and translate"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "vaswani2017attention",
        "author": "Vaswani, A",
        "title": "Attention is all you need"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "wu2021fastformer",
        "author": "Wu, Chuhan and Wu, Fangzhao and Qi, Tao and Huang, Yongfeng and Xie, Xing",
        "title": "Fastformer: Additive attention can be all you need"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "shaker2023swiftformer",
        "author": "Shaker, Abdelrahman and Maaz, Muhammad and Rasheed, Hanoona and Khan, Salman and Yang, Ming-Hsuan and Khan, Fahad Shahbaz",
        "title": "Swiftformer: Efficient additive attention for transformer-based real-time mobile vision applications"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "zhang2024cas",
        "author": "Zhang, Tianfang and Li, Lei and Zhou, Yang and Liu, Wentao and Qian, Chen and Ji, Xiangyang",
        "title": "Cas-vit: Convolutional additive self-attention vision transformers for efficient mobile applications"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "wang2020linformer",
        "author": "Wang, Sinong and Li, Belinda Z and Khabsa, Madian and Fang, Han and Ma, Hao",
        "title": "Linformer: Self-attention with linear complexity"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "mahmood2024enhanced",
        "author": "Mahmood, Kaleel and Huang, Shaoyi",
        "title": "Enhanced Computationally Efficient Long LoRA Inspired Perceiver Architectures for Auto-Regressive Language Modeling"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "su2024roformer",
        "author": "Su, Jianlin and Ahmed, Murtadha and Lu, Yu and Pan, Shengfeng and Bo, Wen and Liu, Yunfeng",
        "title": "Roformer: Enhanced transformer with rotary position embedding"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "liu2021pay",
        "author": "Liu, Hanxiao and Dai, Zihang and So, David and Le, Quoc V",
        "title": "Pay attention to mlps"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "halacheva2024expanding",
        "author": "Halacheva, Anna-Maria and Nayyeri, Mojtaba and Staab, Steffen",
        "title": "Expanding Expressivity in Transformer Models with M{\\\"o}bius Attention"
      }
    ]
  }
]