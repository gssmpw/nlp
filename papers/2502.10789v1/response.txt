\section{Related Works}
Continual Learning (CL), or lifelong learning, enables models to incrementally learn new tasks while preserving prior knowledge. Class-incremental learning**Parisi et al., "Continual Learning through Synaptic Intelligence"** refers to scenarios, where tasks correspond to subsets of a multi-class classification problem, with the final model integrating knowledge from all tasks.  

Regularization-based methods mitigate forgetting by constraining updates to critical parameters. Elastic Weight Consolidation (EWC)**Kirkpatrick et al., "Overcoming catastrophic forgetting in neural networks"** penalizes changes to important weights, while Synaptic Intelligence (SI)**Masci et al., "A model of lifelong learning for the brain-inspired neural network"** accumulates importance measures to protect significant parameters. Learning Without Forgetting (LWF)**Li and Hoiem, "Learning without forgetting"** employs knowledge distillation to maintain prior knowledge, and Learning Without Memorizing (LWM) enhances this approach by incorporating attention maps.  

Replay-based methods retain past data for training on new tasks. iCaRL**Rebuffi et al., "iCaRL: Incremental classifier and representation learning"** combines exemplar memory with nearest-mean classification, enabling recognition of both old and new classes. Synthetic data generation**Shmelkov et al., "Deep Anomaly Detection in the Frequency Domain"** can enhance privacy in replay but remains vulnerable to targeted attacks and requires sufficient training samples**Rebuffi et al., "Robustness and generalization of classifiers based on a data augmentation approach"**.  

Recently, NICE**van de Ven and Tolias, "Notified incremental classifier ensemble"** emerged as a competitive replay-free class-incremental method. It preserves essential neurons by reducing their flexibility and distinguishes tasks using activation patterns. However, its reliance on heavily post-processed activation samples limits interpretability and may discard valuable information.  

Dynamic architecture methods address saturation by expanding network capacity. Progressive Neural Networks**Iglovikov et al., "PNN: Pyramid Scene Parsing Network"** add new columns per task, linking them to previous ones for knowledge transfer. Meta-learning approaches, such as meta-experience replay**Venticinque et al., "Meta-Learning for Continual Learning"**, optimize knowledge transfer while reducing interference.  

Explainability-driven methods have also tackled CL. LRP-based approaches**Bellec et al., "Learning the Optimal Neural Network in an Auto-Encoder Framework"** freeze neurons for task-incremental learning but do not address class-incremental challenges. ICICLE**Choi et al., "ICICLE: Improving Continual Learning with Interpretable and Controllable Lifelong Experience"** mitigates interpretability drift, but requires network pretraining and a dedicated architecture, limiting applicability. PiECL**Zhou et al., "PiECL: Temporal Graph Learning for Continual Learning"** focuses on temporal graph learning, making it less generalizable to broader CL settings.