\section{Introduction}

A strong trend in recent years has been towards \emph{federated} computations~\cite{Kairouz2021advances} in which algorithms are run on a distributed dataset rather than by collecting data and performing the computation in a centralized manner.
This trend is motivated by the wish to protect individuals' data, as well as organizations' wish steer clear of liability issues stemming from collecting and handling private data.
The leading approach to federated computations with \emph{formal} privacy guarantees is to use differential privacy~\cite{dwork2006calibrating} which limits the amount of information that can be inferred about a given user's input by selecting the output from a suitable probability distribution defined by the inputs.
A particularly simple and appealing setup is \emph{local differential privacy} (LDP), in which each user individually sends the output of a differentially private algorithm to a central ``analyzer'', who in turn uses all the user outputs to approximate a function of the inputs.
Though LDP is not the only approach to federated computations with differential privacy, it has been influential. 
For example, LDP has been used in industrial deployments of differential privacy~\cite{cormode2018privacy,Erlingsson2014rappor,apple2017differential}, and there is a rich theory showing both upper and lower bounds on the privacy-utility trade-offs that are possible under LDP.
When giving privacy guarantees under LDP it is common to consider \emph{pure} differential privacy since it is known that any non-adaptive protocol satisfying approximate differential privacy can be converted into an equivalent one satisfying pure differential privacy~\cite{bun2019heavy}.
An interesting aspect of LDP algorithms is that they can be used as building blocks of more sophisticated algorithms offering better privacy utility trade-offs (with stronger trust assumptions), for example in the~\emph{shuffle model}~\cite{bittau2017prochlo, cheu2018distributed,erlingsson2019amplification}.

{\bf Quantile estimation.}
In this paper we study the problem of \emph{quantile estimation} under local differential privacy constraints: In quantile estimation, we are given a dataset $X$ consisting of $n$ datapoints $x_1,\dots,x_n \in [B]:=\{1,\dots,\ab\}$, where $\ab$ is an integer parameter\footnote{As we will see, even with the weaker privacy guarantee of central DP, it is provably impossible to obtain meaningful error guarantees in the continuous setting, where user data is from e.g., $[0,1]$. However, in~\cref{sec:continuous}, we will discuss how our algorithms can be brought to work in the continuous setting as well only requiring mild assumptions on the distribution of the input data.}. 
%
Given this dataset, we define the empirical CDF $F_X:[B]\to [0,1]$ by 
\begin{equation}
\label{eq: empirical cdf}
F_X(i)=\frac{1}{n}|\{j\in [n]\mid x_j\leq i\}|,
\end{equation}
that is, $F_X(i)$ is the fraction of elements in the dataset that are smaller than or equal to $i$.
Given $q\in (0,1)$ we would ideally like to output an approximate $q$th quantile of the dataset, that is, a value $m\in [B]$ such that $F_X(m)$ is approximately equal to $q$.
%
Such a value $m$ may not always exist, for example if all $x_i$ are equal. Instead, we measure the approximation guarantee in terms of a parameter $\alpha \in (0,1)$ and we are happy to report a value $m$ such that  $q$ is contained in the interval $[F_X(m)-\alpha,F_X(m+1)+\alpha]$.


{\bf Adaptive Local Differential Privacy.}
In this paper we consider LDP algorithms that work in rounds, making \emph{adaptive} choices of what information should be released in each round.
An adaptive LDP protocol involves $n$ users indexed by $i=1,\dots,n$, with user $i$ holding a data item $x_i$, and an \emph{aggregator} that coordinates the protocol.
In round $t$ the aggregator \emph{queries} a set $I_t\subseteq \{1,\dots,n\}$ of one or more users, asking them to run a differentially private mechanism $\mathcal{M}_t$ on their data.
The output of $\mathcal{M}_t(x_i)$ is then sent to the aggregator for each $i\in I_t$.
Protocols in this model can be adaptive in the sense that the choice of mechanism $\mathcal{M}_t$ can depend on the results of mechanisms in rounds $1,\dots,t-1$.
We consider \emph{sequentially adaptive} protocols in which the query sets $I_1, I_2,\dots$ are disjoint, such that the privacy guarantee for each user is simply determined by the privacy guarantee of the mechanism that was used for the LDP report on their data (if any).
%
In contrast \emph{non-adaptive} LDP protocols can be run in a single round. The private mechanism $\mathcal{M}_t$ is predetermined and does not depend on the outputs of $\mathcal{M}_1,\dots, \mathcal{M}_{t-1}$. It is often the case that all $\mathcal{M}_t$ are the same. 
Adaptive mechanisms often offer much improved utility/privacy tradeoffs compared to their non-adaptive counterparts but they are harder to coordinate and thus less desirable from a practical perspective.

%
%



%



%

%

%

For quantile estimation, each user $i$ holds the datapoint $x_i\in[B]$ and our goal is to estimate a quantile, with error described as above, such that $\calM_t$ satisfies LDP.
It is not hard to see that an algorithm for estimating the median, that is $q=1/2$, can be used to estimate any quantile of the dataset with only a constant factor increase of the approximation guarantee.
This is because we can reduce the general case to the median by introducing $n$ additional, virtual users holding data, $(1-q)n$ users each holding the value $1$ and $qn$ users holding the value $\ab$ (see Lemma \ref{appendix: padding argument}).
%
%
Thus, for our algorithm we focus on estimating the median. We refer to this problem with desired accuracy $\alpha$ and LDP privacy parameter $\eps$ as $\texttt{LDPemp-median}(\{x_i\}_{i=1}^n, \alpha, \epsilon)$ (see Section~\ref{sec:preliminaries} for the formal definition). 
%
We derive a sequentially adaptive algorithm with the following guarantee:

\begin{theorem}\label{thm:main-emp}
For all $\alpha \in (0,\frac{1}{4})$, and $\eps\in(0,1)$, there exists a sequentially adaptive $\eps$-LDP protocol solving \texttt{LDPemp-median}$(\{x_i\}_{i=1}^n,\alpha,\eps)$ with probability at least $1-\frac{1}{\ab}$ for any dataset with $n\geq c\frac{\log \ab}{\eps^2\alpha^2}$ for a universal constant $c$.
\end{theorem}

%
The algorithm queries one user at a time (so each $|I_t| = 1$) and proceeds for $n$ rounds. In terms of communication and run time, our algorithm is efficient: each user communicates just $1$ bit to the server, and each round has update time $O(\log B)$. %
In addition, we show that the error of our protocol is \emph{optimal} up to constant factors under (sequentially-adaptive) LDP:

\begin{theorem}\label{thm:main-lower}
Suppose that $B$ is sufficiently large, $\alpha \leq \frac{1}{2}$, and $\epsilon < 1$. Any sequentially adaptive LDP protocol solving %
\texttt{LDPemp-median}$(\{x_i\}_{i=1}^n,\alpha,\eps)$ with probability at least $3/4$ for any dataset of size $n \geq n_0$ must have $n_0=\Omega\left(\frac{\log \ab}{\eps^2\alpha^2}\right)$.
\end{theorem}
\emph{Remark:} The above theorem is stated for the median, but as we will see, the same lower bound holds for estimating any quantile $q\in (2\alpha,1-2\alpha)$. 
Note that for $q\leq \alpha$ or $q\geq 1-\alpha$, there is a trivial protocol that outputs either $1$ or $B$. 
Combined with the above observation for reducing a general quantile to the median, our results therefore show that $\Theta(\frac{\log B}{\eps^2\alpha^2})$ is essentially the correct bound for quantile estimation under sequentially-adaptive LDP in the high privacy regime. 

 \paragraph{Non-Adaptive Protocols.}
%
\cref{thm:main-emp,thm:main-lower} settle the optimal privacy/utility tradeoffs for adaptive LDP protocols in the high privacy regime. 
As we will discuss in Section~\ref{sec:prior-work}, all non-adaptive mechanisms that we are aware of require a $\text{polylog}(\ab)$ factor more users to solve \texttt{LDPemp-median}, which can be significant as $B$ is typically a large parameter such as $2^{32}$. 
Our privacy/utility tradeoff in the adaptive case is therefore much better than for known non-adaptive protocols, but as discussed non-adaptive protocols more practical appealing. A natural question is thus if the gap is inherent. We settle this question in the positive essentially showing that~\emph{any} non-adaptive protocol must incur an additional logarithmic factor in $B$ in the number of users required for a desired accuracy. Thus, non-adaptivity, while practically desirable, comes at a significant price in utility. Our result is as follows.
\begin{theorem}\label{thm:intro-lower-non-interactive}
    Suppose $\ab$ is sufficiently large, $B^{-\Omega(1)} \leq \acc \leq c $ for a universal constant $c$, and $\priv \leq \frac{1}{\log(1/\acc)}$.
    Suppose that there exists a non-adaptive $\priv$-LDP algorithm solving \texttt{LDPemp-median}$(\{x_i\}_{i=1}^n, \acc, \priv)$ with probability at least $\frac{3}{4}$ for any dataset of size $n \geq n_0$. 
    Then $n_0 = \Omega\left(\frac{\log^2(\ab)}{\acc^2\priv^2 \log(1/\acc)^4}\right)$. 
\end{theorem}
In particular, when $\eps,\alpha=\Theta(1)$, the number of users must be $\Omega(\log^2 B)$ whereas our previous theorems show that $O(\log B)$ suffices for adaptive protocols. The authors believe that the high logarithmic dependence on $1/\alpha$ is an artifact of the proof.




%



%
%
%
%
%

%
%
%
%

%
%

%




\paragraph{The Shuffle Model}

Shuffle differential privacy (shuffle-DP)~\cite{bittau2017prochlo,Cheu19DDPS} captures the idea that using a random permutation to shuffle a large enough set of somewhat private user messages, thus making their origins indistinguishable, boosts the privacy guarantee for each user. 
More precisely, in shuffle-DP, each user applies a LDP protocol to their data and then sends the output to a trusted \emph{shuffler} whose only task is to randomly permute the users data before forwarding it to a central data curator.
The privacy boost achieved from shuffling was analysed in~\cite{feldman21shuffle} (see~\cref{theorem: amplification by shuffling}).
To gain the privacy boost, the batch of users shuffled can not be too small. This
%
makes it fundamentally incompatible with highly adaptive protocols having $n$ rounds of adaptivity, and each batch of size one. To bypass this, we consider protocols which run in a bounded number of rounds, shuffling the users queried in each round, simultaneously obtaining both the benefits of adaptivity and the boosted privacy from shuffling.

%

%
We refer to the problem of estimating the median of $n$ users within accuracy $\alpha$ using $r$ adaptive rounds of shuffling under $(\eps,\delta)$-DP as $\texttt{shuffle-emp-median}(\{x_i\}_{i=1}^n,\alpha,\eps,\delta,r)$ (see~\cref{sec:preliminaries} for a formal definition).
We provide a protocol for this problem with $r=\log_2\ab$ and $n=(\log B)\cdot\widetilde{O}\left(\frac{1}{\eps^2}+\frac{1}{\alpha^2}\right)$.
\begin{theorem}
\label{thm:main-shuffle}
    Let $r=\log_2 B$ and $\eps,\alpha<1$. There exists a protocol for \texttt{shuffle-emp-median}$(\{x_i\}_{i=1}^n,\alpha,\eps,\delta,r)$ with success probability $1-\failp$ in the sequentially interactive model, provided that
    \[
    n=O\left( \left(\frac{1}{\acc^2} +\frac{1}{\priv^2}\right)\log\ab\sqrt{\log(1/\privdelta)\log\frac{\log\ab}{\failp}} \right).
    \]
    The protocol queries shuffled batches of $n/\log_2(\ab)$ users. 
\end{theorem}


We believe that the framework of combining shuffling with rounds of adaptivity might be of interest for many other problems. On the one hand, we could use a non-adaptive protocol with shuffling, getting better dependence on $\eps$ and $\acc$, but this would incur additional logarithmic factors in $\ab$. On the other hand, we could use a sequentially adaptive algorithm like in~\cref{thm:main-emp}, but then we lose the benefits of shuffling since each batch has size $1$.~\cref{thm:main-shuffle} demonstrates that protocols having several adaptive rounds using shuffling of each batch, can provide the best of both worlds.

%



%
%
%
%
%
%
%
%
%


%
%
%

\textbf{Experiments} In Section~\ref{sec:experiments}, we demonstrate that the algorithm in Theorem~\ref{thm:main-emp} performs favorably compared to known non-adaptive mechanisms as well as a more naive noisy binary search mechanism. 


\subsection{Related Work}\label{sec:prior-work}

\paragraph{Differential Privacy} Differential privacy is considered the gold standard in private data analysis due to its rigorous guarantees, e.g., immunity to side information, and other useful properties \cite{dwork2006calibrating, dwork2014algorithmic}. 
A number of mechanisms exist for releasing medians and general quantiles for centralized DP. First, one may instantiate mechanisms based on local sensitivity~\cite{nissim2007smooth, dwork2009differential, asi2020near}, since quantiles often have low local sensitivity for many datasets. More recently, specialized mechanisms for medians \cite{ tzamos2020optimal, drechsler2022nonparametric,aliakbarpour2023differentially} and quantiles \cite{wilson2019differentially, gillenwater2021differentially, alabi2022bounded} have been proposed to obtain even lower error but they require certain mild assumptions on the distribution of the data points.
%
The case where data points can be arbitrary from some discrete domain $[B]$, like for us, has been well studied in the central setting. The sequence of works,~\cite{BeimelNS16twotologstar,Bun2015logstar,Kaplan2020closinggap} gradually reduced the number of users needed for accuracy $\alpha$ to $\tilde O(\frac{1}{\eps}\log^{1.5} (1/\delta)\cdot (\log^*B)^{1.5})
)$ for $(\eps,\delta)$-privacy. This almost matches the the $\Omega(\log^*(B))$ lower bound from~\cite{AlonLMM19}. A corollary of this lower bound is that even with central DP, no algorithm can achieve $o(1)$ quantile error in the continuous setting regardless of how many users there are.
%
\paragraph{Local Differential Privacy} There is increasing interest in local differential privacy (LDP), where the central aggregator is not trusted, and each user applies a DP mechanism to their data before broadcasting it. LDP mechanisms for many problems and accompanying lower bounds were shown in \cite{duchi2013local}. A ubiquitous LDP protocol that we will utilize is \emph{randomized response} (See~\cref{def: binary rr}), where answers to a binary query are flipped with probability $\frac{1}{1+e^\varepsilon} \approx \frac{1}{2}-\epsilon$. For the median problem, an LDP algorithm was found in \cite{duchi2018minimax} under a different loss function, the difference between the estimate and the median in the \emph{data domain}. This loss function is subject to strong lower bounds (a linear dependence on the domain size). %
The most relevant work to our setting is the so-called \emph{hierarchical mechanism}~\cite{kulkarni2019answering}.
%

\paragraph{Hierarchical mechanism} 
%
The hierarchical mechanism uses the $b$-adic decomposition of the interval $[0,\ab]$ (which is a $b$-ary tree of depth $\Theta(\log_b(\ab))$ whose nodes at level $\ell$ correspond to intervals of length $\frac{\ab}{b^\ell}$). Each participant uniformly selects a level $\ell$ at random and employs standard frequency LDP oracles \cite{bassily2015local,wang2017locally} to disclose which node at level $\ell$ their data belongs to. The central aggregator may then combine the frequency oracles at each level to answer any range query. 
%
%
A particular use of range queries with relative error $\alpha$ is for constructing an $\alpha$-approximate CDF of the data set, which in turn can be used to approximate every quantile within error $\alpha$. Unfortunately, dividing the user data among levels worsens the dependence on $\log(\ab)$. In Appendix~\ref{app:hierarchical-mech}, we demonstrate that the hierarchical mechanism can be used to solve \texttt{LDPemp-median} with $n =O(\frac{\log^3 \ab}{\epsilon^2 \alpha^2})$ users. %
%
In terms of the polynomial dependence on $\log B$, there is still a multiplicative $\log B$ gap between this upper bound and the lower bound of~\cref{thm:intro-lower-non-interactive} which would be very interesting to close.

\paragraph{Shuffle Differential Privacy}
The central model of DP requires that data be collected non-privately by the curator, which
results in extremely accurate protocols. %
On the other hand, in the local model users do not trust anyone, and the response to any query must be privatized before it is broadcast by the user. In shuffle-DP, each user applies a LDP protocol to their data and then sends the output to a trusted \emph{shuffler} whose only task is to randomly permute the users data before forwarding it to a central data curator. This places shuffling as a middle ground between these two models in terms of both trust and accuracy. 

%
Understanding the separation between the local, shuffle, and central models of privacy, and therefore the trade-offs between trust and accuracy, is of both theoretical, and practical interest. For a survey of such separations, see~\cite{cheu2021differential}. 

\paragraph{Noisy binary search and threshold queries} Consider an algorithm that sequentially picks a \textit{threshold query} $m\in[\ab]$, then samples a user from the database $X$ and receives the bit $y=[x\leq m]$. Since $\Pr[y = 1] = F_X(m)$, finding an integer $m$ such that $F_X(m) \approx q$ reduces to the \textit{noisy binary search} problem. This search over a CDF with \textit{threshold query} sample access, exactly mirrors searching over a monotonically increase sequence of coins. Noisy binary search was introduced by~\cite{karp2007noisy} with a tight bound of $\Theta(\log(\ab)/\acc^2)$, later improved by constant factors by \cite{gretta2023sharp}, which holds for the non-private median when samples are accessed via threshold queries in the statistical setting. 

%

%
%
%
%

%
%

%


\paragraph{Structure of the Paper}
In~\cref{sec:preliminaries}, we introduce necessary preliminaries for our theoretical analyses. In~\cref{sec:tech-contributions}, we provide an overview of our main ideas and technical contributions.~\cref{sec:proof-of-main-adaptive-up} is dedicated to proving~\cref{thm:main-emp}. In~\cref{sec:lower-bound}, we prove the lower bounds of~\cref{thm:main-lower,thm:intro-lower-non-interactive}. In~\cref{sec:naive-shuffle}, we provide the proof of~\cref{thm:main-shuffle}. Finally, in~\cref{sec:experiments} we present our experimental results.
