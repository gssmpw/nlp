\section{Experiments}
\label{app: experiments}
\input{pseudocodes/DPBayeSS}

All experiments were carried out using an Intel
Xeon Processor W-2245 (8 cores, 3.9GHz), 128GB RAM, Ubuntu 20.04.3, and Python 3.11. We considered the \emph{success rate} for an error $\alpha$
\begin{equation*}
    \text{success rate} := \text{Pr}\left[F_X(\tilde{m})<\frac{1}{2}+\alpha \wedge F_X(\tilde{m}+1)>\frac{1}{2}-\alpha\right],
\end{equation*}
where $F_X$ is the CDF of the sensitive dataset and $\tilde{m}$ is the median released by the algorithm, and the absolute quantile error
\begin{equation*}
    \text{error} := |F_{X}(\tilde{m})-F_{X}(m)|,
\end{equation*}
as the main metrics for our evaluation.
Each algorithm was executed 200 times to compute the empirical cumulative distribution of the absolute quantile error. As error we opted for the standard deviation of the sample average success rate, calculated as:
\begin{equation*}
    \sigma = \sqrt{\frac{\tilde{p}(1-\tilde{p})}{200}} \qquad \text{where }\quad \tilde{p} = \frac{1}{200}\sum_{i=1}^{200} \left[F_X(\tilde{m}_i)<\frac{1}{2}+\alpha \wedge F_X(\tilde{m}_i+1)>\frac{1}{2}-\alpha\right]
\end{equation*}

\paragraph{Data Generation} The income dataset was generated using a Pareto distribution $p(x) \sim \frac{1}{x^{\gamma+1}}$, a well studied distribution to model income data \cite{arnold2014pareto}. We generate $n = \{2500, 5000, 7500\}$ positive integers by sampling from the continuous Pareto distribution with shape $\gamma = 1.5$ and multiplicative factor  $2000$, and then rounding them. For different coin domains $[\ab]$ we clip the dataset to get integer values in $[\ab]$. To compare \texttt{DpBayeSS} and \texttt{DpNaiveNBS} across various coin domains $[\ab]$ for a fixed privacy budget, we generated $n=2500$ integers by sampling from a uniform distribution over a random interval within $[\ab]$. This approach avoids having the median around $\ab/2$, which would make the problem too straightforward.

\paragraph{Implementation Details} 
These mechanisms are run over the entire dataset, meaning that each user is sample once.
\begin{itemize}
\item\texttt{DpNaiveNBS} is a standard differentially private implementation of noisy binary search introduced in \cite{karp2007noisy}, where each coin flip is privatized using randomized response with $\varepsilon$ privacy budget, which we call $\texttt{RR}_{\varepsilon}$. 
It searches the coin with probability closest to $\frac{1}{2}$ using standard binary search. To estimate a coin probability it  samples without replacement batches of size $b=\lfloor \frac{n}{\lceil \log_2\ab\rceil }\rfloor$, then it redistributes the remaining samples $n-\lceil\log_2\ab\rceil b$ by adding one sample to each batch starting from the first one. 
Due to randomize response, any empirical probability $p_{c} = \frac{1}{b}\sum_{x \in \text{batch}} \texttt{RR}_{\varepsilon}\big([x \leq c]\big)$ is unbiased $\Tilde{p}_c = \frac{e^{\varepsilon}+1}{e^{\varepsilon}-1}(p_{c}-\frac{1}{e^{\varepsilon}+1})$ before confronting it with $\frac{1}{2}$. 

\item\texttt{DpBayeSS} is a implementation of Algorithm 3 in \cite{gretta2023sharp}, with some minor changes ($\gamma$ is set to $1/13$ in line 11 of Algorithm 3),  where each coin flip is privatized using randomized response. The algorithm runs at most two \texttt{DpBayesLearn} (a differentially private implementation of Algorithm \ref{alg: BayesLearn} where each coin flip is privatized using randomized response) and further makes use of \texttt{DpNaiveNBS} on the remaining coins to get the one with head probability closest to $\frac{1}{2}$. The sample budget $n$ is split to $M_{B_1}$, $M_{B_2}$ for the two \texttt{DpBayesLearn} and $M_{S}$ for the \texttt{DpNaiveNBS}. The split satisfies the following ratios suggested in \cite{gretta2023sharp} $\frac{M_{B_1}}{M_{B_2}} = \frac{\log B}{\log \log B}$, $\frac{M_{B_1}}{M_{S}} = \log B$, and $\frac{M_{B_2}}{M_{S}} = \log\log B$. 

\texttt{BayesLearn} is designed to take $\alpha$ as an input for updating the weights during the Bayesian learning step (see Algorithm \ref{alg: BayesLearn}), hence it assumes a sufficiently large number of users. To reverse this approach so using $n$ as input, we empirically determine the minimum value of $\alpha$ achievable by the algorithm.
For \texttt{DpBayesLearn} and  $\varepsilon<1$ we showed that to get an error $\alpha$ we need to solve for an error $\tilde{\alpha} = \frac{\alpha\varepsilon}{8}$. 
For a fixed $n$, the error cannot be smaller than $\alpha \geq 8c \frac{\sqrt{\log B}}{\varepsilon\sqrt{n}}$ for some constant $c>0$, therefore 
we have that $\tilde{\alpha} \geq c\sqrt{\frac{\log B}{n}}$. 
We analyze different values of $c$ in the hyper-parameter selection section in order to get a value of $c$ such that the algorithm, run with $\tilde{\alpha} = c\sqrt{\frac{\log B}{n}}$, gives better results. For completeness and full reproducibility we provide a pseudocode of our implementation in Algorithm~\ref{alg: DPBayeSS}

\item\texttt{Hierarchical Mechanism} is built according to \cite{kulkarni2019answering}. Essentially, we constructed a tree with branching factor equal to 4 and at each level we store the 4-adic decomposition of $[B]$. For example, if $B = 4^9$ at the first level of the tree, composed by four nodes, is stored $\{[1,\dots, 4^{8}], [4^{8}+1, \dots, 2\cdot 4^{8}], [2\cdot 4^{8}+1, \dots, 3\cdot 4^8], [3\cdot 4^{8}+1, \dots, 4^9]\}$, while on the leaves are stored all the possible singletons. Each user selects a random level of the tree and reports its position using \emph{unary encoding}\cite{wang2017locally, cormode2021frequency}. For this LDP protocol we used the public library at the following GitHub repository\footnote{\url{https://github.com/Samuel-Maddock/pure-LDP}}. After filling the tree, we computed the whole cumulative distribution and released the coin with closest value to $\frac{1}{2}$.
\end{itemize}
\begin{figure*}[t]
    \centering
    
    \begin{subfigure}[t]{\textwidth}
        \centering
        \begin{minipage}{0.48\textwidth}
            \centering
            \includegraphics[width=1\linewidth]{figures/find_alpha/success_vs_constant_N_2500_Bexp_9.pdf}
            \subcaption*{Success rate vs. constant $c$}
        \end{minipage}%
        \hspace{0.02\textwidth}
        \begin{minipage}{0.48\textwidth}
            \centering
            \includegraphics[width=1\linewidth]{figures/find_alpha/abs_errors_cdf_N_2500_Bexp_9.pdf}
            \subcaption*{Cumulative distribution of absolute error}
        \end{minipage}
        \caption{Experiments for $n=2500$ and $\ab = 4^9$}
    \end{subfigure}
    
    \vspace{1em} %
    
    \begin{subfigure}[t]{\textwidth}
        \centering
        \begin{minipage}{0.48\textwidth}
            \centering
            \includegraphics[width=1\linewidth]{figures/find_alpha/success_vs_constant_N_5000_Bexp_8.pdf}
            \subcaption*{Success rate vs. constant $c$}
        \end{minipage}%
        \hspace{0.02\textwidth}
        \begin{minipage}{0.48\textwidth}
            \centering
            \includegraphics[width=1\linewidth]{figures/find_alpha/abs_errors_cdf_N_5000_Bexp_8.pdf}
            \subcaption*{Cumulative distribution of absolute error}
        \end{minipage}
        \caption{Experiments for $n=5000$ and $\ab = 4^8$}
    \end{subfigure}

    \caption{\small Experiments to estimate the best constant $c$ to compute $\alpha_{\text{update}}=c\sqrt{\frac{\log \ab}{n}}$.}
    \label{fig: find-alpha}
\end{figure*}
\newpage
\subsection{Hyper-parameter selection}\label{sec:hyper-parameter}
To determine the optimal parameter for updating \texttt{DpBayesLearn} given a fixed number of users $n$, coins $B$, and varying privacy budgets $\varepsilon \in \{0.5, 1, 1.5\}$, we conducted experiments using \texttt{DpBayeSS} with different update parameters $\alpha_{\text{update}} = c \sqrt{\frac{\log B}{n}}$. These experiments were performed on two distinct datasets generated by sampling from a Pareto distribution, the outcomes are illustrated in \autoref{fig: find-alpha}. By analyzing different $\alpha_{\text{test}}$ values and the error distribution across various privacy budgets, we observed that the algorithm performs poorly at $c=0.1$. However, within the range $c \in [0.3, 0.7]$, the performance stabilizes, and accuracy decreases for $c > 0.7$. Therefore, an effective range for the parameter $c$ is $[0.3, 0.7]$. Based on this analysis, we chose to use $c = 0.6$. We note that our analysis is tailored to the high-privacy regime; however, in practice, this constant also yields a well-performing algorithm for $\varepsilon < 5$.
\newpage
\subsection{Comparison analysis} \label{sec: comprehensive analysis}
\begin{figure*}[t]
    \centering
    
    \begin{subfigure}[t]{\textwidth}
        \centering
        \begin{minipage}{0.48\textwidth}
            \centering
            \includegraphics[width=1\linewidth]{figures/uniform_data/success_rate_vs_B_N_2500_eps_0.5.png}
            \subcaption*{Success rate vs. coin domain size $B$}
        \end{minipage}%
        \hspace{0.02\textwidth}
        \begin{minipage}{0.48\textwidth}
            \centering
            \includegraphics[width=1\linewidth]{figures/uniform_data/abs_cdf_N_2500_eps_0.5.png}
            \subcaption*{Cumulative distribution of absolute error}
        \end{minipage}
        \caption{Experiments for $n=2500$ and $\varepsilon = 0.5$}
    \end{subfigure}
    
    \vspace{1em} %
    
    \begin{subfigure}[t]{\textwidth}
        \centering
        \begin{minipage}{0.48\textwidth}
            \centering
            \includegraphics[width=1\linewidth]{figures/uniform_data/success_rate_vs_B_N_2500_eps_1.0.png}
            \subcaption*{Success rate vs. coin domain size $B$}
        \end{minipage}%
        \hspace{0.02\textwidth}
        \begin{minipage}{0.48\textwidth}
            \centering
            \includegraphics[width=1\linewidth]{figures/uniform_data/abs_cdf_N_2500_eps_1.0.png}
            \subcaption*{Cumulative distribution of absolute error}
        \end{minipage}
        \caption{Experiments for $n=2500$ and $\varepsilon = 1$}
    \end{subfigure}

    \caption{\small Experiments run over a dataset obtained by sampling $n$ random integers over a random subset of $[B]$.}
    \label{fig: different B}
\end{figure*}
In \autoref{fig: comparison} we run the three algorithms two Pareto like dataset with $n=\{2500, 7500\}$ and $B = \{4^9, 4^8\}$ with various privacy budgets $\varepsilon \in [0.1, 5]$. We observed how the adaptive mechanisms \texttt{DpBayeSS} and \texttt{DpNaiveNBS} outperform a non adaptive mechanism such as \texttt{Hierarchical Mechanism}. This superior performance is not surprising as the former algorithms are tailored specifically for median estimation. In contrast, \texttt{Hierarchical Mechanism} constructs a differential private data structure capable of answering any range queries with an error of $\text{polylog}(B)$. From our results it is clear the \texttt{DpBayeSS} is more likely to return a coin with low quantile error than \texttt{DpNaiveNBS}, both for $\varepsilon < 1$ and $\varepsilon > 1$. This result aligns with the findings in \cite{gretta2023sharp}, where the authors conducted experiments demonstrating that \texttt{BayeSS} can achieve the same error rate as \texttt{NaiveNBS} (algorithms without randomized response) using fewer coin flips and, consequently, fewer user samples.

We conducted further experiments to evaluate the behavior of \texttt{DpBayeSS} and \texttt{DpNaiveNBS} for different coin domains $[B]$. The dataset is obtained by sampling $n=2500$ integers uniformly from a random interval in $[B]$, for any $B \in \{10^3, 10^4, 10^5, 10^6\}$. The main results are listed in \autoref{fig: different B} for two different privacy budget $\varepsilon\in \{0.5, 1\}$. We observed that \texttt{DpBayeSS} is more stable than \texttt{DpNaiveNBS} for different coin domains, and offers good utility for realistic privacy budget and error (e.g. for $\alpha_{\text{test}} = 0.05$, $\varepsilon=1$, and $n=2500$, \texttt{DpBayeSS} returns a $\alpha_{\text{test}}$-good median with probability higher than $0.8$).

\newpage
\begin{figure*}[h]
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=0.80\linewidth]{figures/comparison/large_success_rate_N_10000000_B_exp_8.png}
        \subcaption*{Success rate vs. privacy budget $\varepsilon$}
\end{minipage}%
    \hspace{0.02\textwidth}
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=0.80 \linewidth]{figures/comparison/abs_cdf_N_10000000_B_exp_8.png}
        \subcaption*{Cumulative distribution of absolute error}
    \end{minipage}
    \caption{Experiments for $n=10^7$ and $B = 4^8$, with $\delta = 10^{-8}$ for shuffle DP}
    \label{fig: comparison large}
\end{figure*}
\subsection{Noisy Binary Search with Shuffling} 
When the number of users $n$ is sufficiently large, noisy binary search with shuffling, as described in Section \ref{sec:naive-shuffle}, can be implemented. The implementation mirrors that of \texttt{DpNaiveNBS},  but the privacy budget $\varepsilon_{\texttt{RR}}$ for randomizing the coin flip is determined as $\varepsilon_{\texttt{RR}} = \log\left(\frac{\varepsilon^2}{80 \log(4/\delta)} \left(\left\lfloor \frac{n}{\lceil \log_2\ab\rceil }\right\rfloor+1\right)\right)$ to achieve $(\varepsilon,\delta)$-differential privacy (DP) under shuffling, as established in \autoref{lemma: amplification by shuffling}.  Since $\varepsilon_{\texttt{RR}} \geq 0$ is required, the user population $n$ must be sufficiently large to enable this amplification technique. In particular, for $\delta =10^{-8}$, $\varepsilon\in \{0.1, 0.5, 1\}$, and $B =4^8$, it is necessary to have $n$ greater than $2.5\cdot 10^{7}, 7.8\cdot 10^4$ and $1.3\cdot 10^{4}$, respectively, making a direct comparison with the previous experiments impossible.

We generated a Pareto-like dataset (as described in the Data Generation section) with $n = 10^7$ and conducted experiments using $\delta = 10^{-8}$ and various privacy budgets $\varepsilon \in [0.1, 5]$. Due to limited computational resources and the non optimal implementation of \texttt{DpBayesSS} and \texttt{Hierarchical Mechanism}, we restricted our comparison to \texttt{DpNaiveNBS} and its variant implemented with privacy amplification through shuffling. The results are shown in \autoref{fig: comparison large}. For small privacy budgets, shuffling-based amplification provides higher utility, whereas for $\varepsilon > 3$, the performance of the algorithms converges and becomes comparable.




\begin{figure*}[t!]
    \centering
    
    \begin{subfigure}[t]{\textwidth}
        \centering
        \begin{minipage}{0.48\textwidth}
            \centering
            \includegraphics[width=0.80\linewidth]{figures/comparison/large_success_rate_N_2500_B_exp_9.png}
            \subcaption*{Success rate vs. privacy budget $\varepsilon$}
    \end{minipage}%
        \hspace{0.02\textwidth}
        \begin{minipage}{0.48\textwidth}
            \centering
            \includegraphics[width=0.80 \linewidth]{figures/comparison/abs_cdf_N_2500_B_exp_9.png}
            \subcaption*{Cumulative distribution of absolute error}
        \end{minipage}
        \caption{Experiments for $n=2500$ and $B = 4^9$}
    \end{subfigure}
    
    \begin{subfigure}[t]{\textwidth}
        \centering
        \begin{minipage}{0.48\textwidth}
            \centering
            \includegraphics[width=0.80\linewidth]{figures/comparison/large_success_rate_N_7500_B_exp_8.png}
            \subcaption*{Success rate vs. privacy budget $\varepsilon$}
        \end{minipage}%
        \hspace{0.02\textwidth}
        \begin{minipage}{0.48\textwidth}
            \centering
            \includegraphics[width=0.80 \linewidth]{figures/comparison/abs_cdf_N_7500_B_exp_8.png}
            \subcaption*{Cumulative distribution of absolute error}
        \end{minipage}
    \caption{Experiments for $n=7500$ and $B = 4^8$}
    \end{subfigure}
    \caption{Comparison analysis.}
    \label{fig: comparison}
\end{figure*}