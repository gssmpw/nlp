\section{Proof of Theorem \ref{thm:NBS-changing-probabilities}}
\label{app: proof theorem 3.1} 
\input{pseudocodes/small_pseuodocode_main} 
The goal of this section is to prove Theorem~\ref{thm:NBS-changing-probabilities}. We first define the adversarial setting.
\begin{definition}
\label{def:adversarial}
Let $0<\alpha<1$ and $\ab$ a positive integer. Let $p_0,\dots,p_\ab\in [0,1]$ be unknowns with $0=p_0\leq\cdots \leq p_\ab= 1$. In \emph{\texttt{AdvMonotonicNBS}$(\tau, \alpha, c)$}, for $c>0$, our goal is to identify an $(\tau,\alpha(1+c))$-good coin (defined in \autoref{eq:good-coin}).
To do so, we may iteratively pick indices $i\in \ab$. Then an adversary selects a probability $\tilde p_i$ such that $| {\tilde{p}}_i - p_i|\leq c\alpha$, and we observe the outcome of a coin flip with heads probability $\tilde p_i$.
\end{definition}
We show that the \texttt{BayeSS} algorithm (\texttt{BayeSS} abbreviates \emph{Bayesian Screening Search}) from \cite{gretta2023sharp}(Algorithm 3) solves the \texttt{AdvMonotonicNBS}$(\tau, \alpha, c)$ problem returning the a $(\tau,\alpha(1+c))$-good coin with high probability in $\ab$ using
%
$O(\frac{\tau(1-\tau)\log \ab}{\alpha^2})$ 
 coin flips. We actually prove a stronger theorem which immediately implies~\cref{thm:NBS-changing-probabilities}.

\begin{theorem}\label{thm:GP-generalization}
Suppose that $c\leq 1$ and $\alpha \leq \frac{1}{2}\min\{\tau, 1-\tau\}$. There exists an algorithm~\cite{gretta2023sharp} for \emph{\texttt{AdvMonotonicNBS}$(\tau, \alpha, c)$} which uses 
%
$\tfrac{1}{C_{\tau, \alpha}}(\log \ab + O(\log^{2/3}\ab\,\log^{1/3}\frac{1}{\failp}+\log\frac{1}{\failp}))$ 
coin flips\footnote{Namely, $C_{\tau, \alpha}$ is the information capacity of the Binary Asymmetric Channel (BAC) with crossover probabilities $\{\tau + \alpha, \tau - \alpha\}$. Concretely, $C_{\tau, \alpha}=\max_q H((1-q)(\tau-\alpha) + q(\tau+\alpha))-(1-q)H(\tau-\alpha)-qH(\tau+\alpha)$ with $H$ being the binary entropy function, and $C_{\tau,\alpha} = \Theta(\tfrac{\alpha^2}{\tau(1-\tau)})$ for $\alpha \leq \frac{1}{2}\min(\tau, 1-\tau)$.}
%
and returns a $(\tau,\alpha(1+c))$-good coin with probability at least $1-\failp$.
\end{theorem}

Note that Theorem~\ref{thm:NBS-changing-probabilities} follows directly from Theorem~\ref{thm:GP-generalization} by setting $\tau=1/2$ and $\failp=\ab^{-\lambda}$ for any constant $\lambda$. With this, the proof of Theorem~\ref{thm:main-emp} is complete.

 Before we delve into the proof of Theorem~\ref{thm:GP-generalization}, let us first describe the idea behind \texttt{BayeSS}, described shortly in Algorithm \ref{alg: bayeSS}.
 %
 %
 At a high level \texttt{BayeSS} proceeds in two steps allocating a portion of the coin flips for each step. The first step is a Bayes learner algorithm, called  \texttt{BayesLearn}.
 %
 It starts by assigning a uniform prior $w(I_i)$ to each coin interval $I_i=[i, i+1]$ for any $i \in [\ab-1]$, then takes the $\tau$-quantile interval under the posterior $w(I_i)$, selects a coin from this interval, flips it, and updates each $w(I_i)$ according to the result of the coin flip and the error $\alpha$. This procedure is repeated iteratively.
 The sampled intervals are collected in a multiset $L$, with the guarantee that, after \( O\big(\tfrac{(1+\gamma)\log B}{C_{\tau, \alpha}}\big) \) coin flips, a $\gamma$-fraction of intervals in  $L$  contains a $(\tau, \alpha)$-good coin with high probability in  $\ab$  (referred to as good intervals). In the second step, this property is used to narrow the set of possible coins to $O(1/\gamma)$, ensuring that it contains at least one $(\tau, \alpha)$-good coin. Each coin in the candidate set can be individually tested, up to error $\alpha$, with high probability using $O(\tfrac{1}{\gamma\alpha^2}\log(\tfrac{\ab}{\gamma}))$ coin flips.

It is easy to see that in the adversarial setting, the coins can be tested up to error $\alpha(1+c)$ in the second step. 
%
Our main challenge in proving Theorem~\ref{thm:GP-generalization}, is analyzing the first part of the algorithm, \texttt{BayesLearn}, in the adversarial setting. 
%
%
%
%
%
The authors in \cite{gretta2023sharp} used a stopping time argument to analyze \texttt{BayesLearn}. They defined a potential function $\Phi$, with an initial negative value, constructed so that a positive potential implies finding at least a $\gamma$ fraction of good intervals. The stochastic process describing the evolution of the potential $\{\Phi_{i}\}_{i=1,\dots}$ is then modeled with a submartingale that can be used to bound, using Azuma's inequality, the probability that the process crosses zero after a sufficient number of iterations. We prove that we can use the same argument for the case of adversarial probabilities if we allow the potential to catch approximate good intervals, namely intervals containing $(\tau, \alpha(1+c))$-good coin.

\paragraph{New potential} Let $\{\ell,\dots,r\}$ be the set of $(\tau,\alpha(1+c))$-good intervals. Let $a$ be the maximum $i \in [\ab-1]$ such that $p^1_i\leq \tau$. Let $L$ be the list of intervals visited in \texttt{BayesLearn}. We define the potential function as 
\begin{equation*}
\label{eq: new potential}
    \Phi(w, L) := \log_2 w(a) + 12 C_{\tau, \alpha}(|\{x\in L : x \in [\ell,r]\}|-\gamma|L|),
\end{equation*}
where $w(a)$ is the Bayesian posterior weight associated to the best interval $a$ and $C_{\tau, \alpha}$ is a concrete function of $\tau$ and $\alpha$.
Notice that a positive potential implies $|\{x\in L | x \in [\ell,r]\}| >\gamma |L|$, hence indicating the presence of a $\gamma$ fraction $(\tau, \alpha(1+c))$-good intervals in $L$. The following Lemma generalises Lemma 7 of \cite{gretta2023sharp} and allows the construction of a submartingale.
\input{pseudocodes/bayes_learn}
\begin{lemma}[Adaptation of Lemma 7 in \cite{gretta2023sharp} for adversarial probabilities]
    \label{lemma: increase in expectation of the potential}
    For $c\leq 1$ and $\alpha \leq \frac{1}{2}\min\{\tau, 1-\tau\}$, the expected variation of the potential is 
    \begin{equation}
        \E[\Phi_{t+1}-\Phi_{t}|y_{1}, \dots, y_t] \geq (1-12\gamma)C_{\tau, \alpha},
    \end{equation}
    where $(y_1, \dots, y_t)$ are the results of the coin toss up to $t+1$-th sample, and $C_{\tau, \alpha} = \Theta\left(\frac{\tau(1-\tau)}{\alpha^2}\right)$.
\end{lemma}
\begin{proof}
The proof for the adversarial setting, which allows an adversary to alter the head coin probability at each iteration up to $c\alpha$, while preserving their order, closely resembles the proof of Lemma 7 in \cite{gretta2023sharp}, which addresses the case of fixed coin probabilities. We will go through the steps of the proof highlighting the main differences. An implementation of \texttt{BayesLearn} for empirical quantile estimation, where each user is used at most once, can be found in Algorithm \ref{alg: BayesLearn}.
%


Let's define the capacity of the $(\tau, \alpha)$-BAC (Binary Asymmetric Channel) as
\begin{align*}
    C_{\tau, \alpha} &= \max_{q} H((1-q)(\tau-\alpha)+q(\tau+\alpha)) -(1-q)H(\tau-\alpha)-qH(\tau+\alpha), \\
    q&=\arg \max_x H((1-x)(\tau-\alpha)+x(\tau+\alpha)) -(1-x)H(\tau-\alpha)-xH(\tau+\alpha),
\end{align*}
where $H(p)$ is the binary entropy. Let's define the multiplicative Bayes weights $d_{x,y}:\{0,1\}\times \{0,1\}\rightarrow \R$, they indicates the multiplicative effect of a flip resulting $x$ (1=Heads, 0=Tails) on the density of an interval on side $y$ (1=Right, 0=Left) of the flipped coin.
\begin{align*}
    d_{0,0} &= \dfrac{1-\tau-\alpha}{1-\tau-(2q-1)\alpha}\\
    d_{0,1} &= \dfrac{1-\tau+\alpha}{1-\tau-(2q-1)\alpha}\\
    d_{1,0} &= \dfrac{\tau +\alpha}{\tau+(2q-1)\alpha}\\
    d_{1,1} &= \dfrac{\tau-\alpha}{\tau+(2q-1)\alpha}.
\end{align*}
We will mainly use the results from Lemma 9 in \cite{gretta2023sharp} that states that
\begin{gather}
    C_{\tau, \alpha} = (\tau + \alpha)\log_2 d_{1,0} + (1-\tau-\alpha)\log_2 d_{0,0} \label{eq: lemma A.1 [1]},\\
    C_{\tau, \alpha} = (\tau -\alpha)\log_2 d_{1,1} + (1-\tau+\alpha)\log_2 d_{0,1} \label{eq: lemma A.1 [2]},
\end{gather}
with the fact that $d_{1,0} \geq d_{0,0}$ and $d_{1,1}\leq d_{0,1}$. Recall the potential function: let $\{\ell,\dots,r\}$ be the set of $(\tau,\alpha(1+c))$-good intervals. Let $a$ be the maximum $i \in [B-1]$ such that $p^1_i\leq \tau$. Let $L$ be the list of intervals visited in \texttt{BayesLearn}. 
%
%

Let $j_t$ be the interval chosen at $t$-th round, and let $c_t$ be the index of the coin flipped. Let $p^t_{c_t} = p^t$ (we will discard the coin subscript) the probability of the selected coin at time $t$. We split the potential in two addend
\begin{gather}
    \label{eq: set}
    12 C_{\tau, \alpha}(|\{x\in L | x \in [\ell,r]\}|-\gamma|L|)\\
    \label{eq: log weight}
    \log_2 w(a)
\end{gather}
The main difference with the proof in \cite{gretta2023sharp} is that a good coin is defined on the initial probabilities $\{p^1_i\}_{i=1, \dots, B}$, but at the $t$-th iteration we only have access to coin with probability $\{p^t_i\}_{i=1,\dots,B}$. However, they are concentrated around $\alpha$, so $|p^t-p^1|\leq c\alpha$ for $c\leq 1$.

{\bf Bad queries:} Consider $j_t \notin [\ell, r]$. If $j_t>r$, then $p^1\geq \tau + (1+c)\alpha$. As we have that $|p^t-p^1|\leq c\alpha$ we also have $p^t \geq p^1-c\alpha \geq \tau+(1+c)\alpha-c\alpha=\tau+\alpha$. The expected change in the weights is
\begin{equation*}
    \E[\log_2 w_{t+1}(a)- \log_2 w_{t}(a)] = p^t \log_2 d_{1,0} + (1-p^t)\log_2 d_{0,0}\geq C_{\tau, \alpha}.
\end{equation*}
Where the last inequality comes from the fact that the expression is minimized as $p^{t}=\tau+\alpha$, and \autoref{eq: lemma A.1 [1]}. Consider now $j_t<L$, then $p^1\leq \tau-(1+c)\alpha$, which means $p^t \leq p^1+c\alpha \leq \tau-(1+c)\alpha + c\alpha = \tau-\alpha$, then 
\begin{equation*}
    \E[\log_2 w_{t+1}(a)- \log_2 w_{t}(a)] = p^t \log_2 d_{1,1} + (1-p^t)\log_2 d_{0,1}\geq C_{\tau, \alpha},
\end{equation*}
where we reach the minimum $C_{\tau, \alpha}$ when $p^t=\tau-\alpha$, due to \autoref{eq: lemma A.1 [2]}. As $j_t \notin [\ell,r]$ the change in \autoref{eq: set} is $-\gamma \cdot 12 C_{\tau,\alpha}$. Therefore, on bad queries the expected change in $\Phi$ is at least $(1-12\gamma)C_{\tau, \alpha}$.

{\bf Good Queries:} Let's consider the expected change in \autoref{eq: log weight} when $j_t \in [\ell, r]$. Consider the case where $j_t \neq a$, then the expected change is either
\begin{align*}
    &p^t \log_2 d_{1,0} +(1-p^t) \log_2 d_{0,0} \quad  \text{if}  \quad \text{$a$ is on the left of $j_t$, so $p^{0}\geq \tau \Rightarrow p^t \geq \tau-c\alpha$}\\
    &p^t \log_2 d_{1,1} +(1-p^t) \log_2 d_{0,1} \quad  \text{if} \quad  \text{$a$ is on the right of $j_t$, so $p^{0}\leq \tau \Rightarrow p^t \leq \tau+c\alpha\qquad$}
\end{align*}
The first expression is increasing in $p^t$ while the second is decreasing, therefore the expected change is at least
\begin{equation}\label{eq: min for good queries}
    \min\left\{(\tau-c\alpha) \log_2 d_{1,0} +(1-\tau+c\alpha) \log_2 d_{0,0}\,;\,(\tau+c\alpha) \log_2 d_{1,1} +(1-\tau-c\alpha) \log_2 d_{0,1}\right\}
\end{equation}
Let's consider the first argument of the previous expression
\begin{align*}
    (\tau-c\alpha) \log_2 d_{1,0} +(1-\tau+c\alpha) \log_2 d_{0,0} &=(\tau+\alpha) \log_2 d_{1,0} +(1-\tau-\alpha) \log_2 d_{0,0}-\alpha(1+c)(\log_2 d_{1,0}-\log_2 d_{0,0})\\
    &= C_{\tau, \alpha} -\alpha(1+c)\underbrace{(\log_2 d_{1,0}-\log_2 d_{0,0})}_{\geq 0} \quad \tag{as  $d_{1,0}\geq d_{0,0}$}\\
    &\geq C_{\tau, \alpha}-2\alpha (\log_2 d_{1,0}-\log_2 d_{0,0}) \quad \tag{as  $c\leq 1$}\\
    & \geq C_{\tau, \alpha}-2(6\log 2)C_{\tau, \alpha}\\
    & \geq -11 C_{\tau, \alpha},
\end{align*}
where in the first inequality we used the fact that $c\leq 1 \Rightarrow (1+c)\alpha\leq 2\alpha$, while in the second inequality we used Lemma 10 and Lemma 13 in \cite{gretta2023sharp}, valid for $\alpha \leq \frac{1}{2}\min(\tau, 1-\tau)$.
Analogously, for the second argument of \autoref{eq: min for good queries} we get
\begin{align*}
    (\tau + c\alpha)\log_2 d_{1,1} + (1-\tau-c\alpha)\log_2 d_{0,1} &=(\tau -\alpha)\log_2 d_{1,1} + (1-\tau+\alpha)\log_2 d_{0,1} -(1+c)\alpha\underbrace{(\log_2 d_{0,1}-\log_2 d_{1,1})}_{\geq 0}\\
    &\geq -11 C_{\tau, \alpha},
\end{align*}
where the inequality follows by an analogous computation.
Therefore, the change of the weights when $j_t \neq a$ is in expectation at least $-11 C_{\tau,\alpha}$ when $c\in [0,1]$ and $\alpha \leq \frac{1}{2}\min(\tau, 1-\tau)$.
Let's consider now the case where $j_{t} = a$, the expected change is
\begin{equation}
\label{eq: lemma general k}
    p^t\log_2(d_{1,0}k+d_{1,1}(1-k))+(1-p^t)\log_2(d_{0,0}k+d_{0,1}(1-k)),
\end{equation}
for some $k\in [0,1]$. We have two cases: $k\leq q$ or $k>q$. When $k\leq q$ the coin flipped is $a$ then $p^1\leq \tau$ and so $p^{t}\leq \tau+c\alpha$, in \cite{gretta2023sharp} it was shown that in this case \autoref{eq: lemma general k} is decreasing in $p^t$, then the minimum is 
\begin{equation}
\label{eq: min 1}
    (\tau+c\alpha)\log_2(d_{1,0}k+d_{1,1}(1-k))+(1-\tau-c\alpha)\log_2(d_{0,0}k+d_{0,1}(1-k)) 
\qquad \text{if } k\leq q.
\end{equation}
Conversely, when $k>q$ the coin flipped is $a+1$ and then $p^1\geq \tau$ so $p^t\geq \tau-c\alpha$. In this case the expression \eqref{eq: lemma general k} is increasing in $p^t$ so the minimum is
\begin{equation}
\label{eq: min 2}
    (\tau-c\alpha)\log_2(d_{1,0}k+d_{1,1}(1-k))+(1-\tau+c\alpha)\log_2(d_{0,0}k+d_{0,1}(1-k)) 
\qquad \text{if } k> q.
\end{equation}
In \cite{gretta2023sharp} the authors demonstrated that the minimum are obtained when $k\in \{0,1\}$. Therefore, for $k=1> q$ we have \autoref{eq: min 2} while for $k=0< q$ we have instead \autoref{eq: min 1}, which means that the minimum is
\begin{equation*}
    \min\left\{(\tau-c\alpha) \log_2 d_{1,0} +(1-\tau+c\alpha) \log_2 d_{0,0}\,;(\tau+c\alpha) \log_2 d_{1,1} +(1-\tau-c\alpha) \log_2 d_{0,1}\right\},
\end{equation*}
which is at least $-11 C_{\tau, \alpha}$ as demonstrated for the case $j_t \neq a$.
To conclude, the expected change in \autoref{eq: set} is at least $12 C_{\tau, \alpha}(1-\gamma)$, then the overall expected change for the potential is at least $12 C_{\tau, \alpha}(1-\gamma)-11C_{\tau, \alpha} = (1-12 \gamma)C_{\tau, \alpha}$, cocnluding the proof.
\end{proof}


The previous Lemma is the building block for the analysis of \texttt{BayesLearn}, as it allows the construction of a submartingale $\{Y_{t}\}_{t=1,\dots}$ with $Y_{t+1} = \Phi_{t+1}-gt$, for $g=(1-12\gamma)C_{\tau, \alpha}$,
%
that can be used to bound the probability to have a $\gamma$ fraction of good intervals, hence a positive potential. The analysis then follows directly from \cite{gretta2023sharp} with the distinction that the algorithm now with high probability in $\ab$ returns a $(\tau,\alpha(1+c))$-good coin, so proving Theorem \ref{thm:GP-generalization}. Since the proof is identical (see Lemma 6 and Theorem 1 of~\cite{gretta2023sharp}), we omit it. 
However, in order to make this paper self-contained, we will show a simple proof of Theorem~\ref{thm:NBS-changing-probabilities} (which is much less general than Theorem~\ref{thm:GP-generalization}). We restate the theorem here.
\begin{theorem}
Let $0<\alpha\leq \frac{1}{4}$ and suppose $c\leq 1$
There exists an algorithm for \texttt{AdvMonotonicNBS}$(1/2, \alpha, c)$ which uses $O\left(\tfrac{\log B}{\alpha^2}\right)$ coin flips and returns an $(1/2,\alpha(1+c))$-good with high probability in $B$.
\end{theorem}
\begin{proof}
Let $\Phi$ be the potential function in Lemma~\ref{lemma: increase in expectation of the potential} in the case $\tau=1/2$.
Given Lemma \ref{lemma: increase in expectation of the potential}, by choosing $g=(1-12\gamma)C_{1/2, \alpha}$ equal to the lower bound of the lemma, we have that $\{Y_{t}\}_{t=1,\dots}$, for $Y_{t+1} = \Phi_{t+1}-gt$
%
, is a submartingale as
%
%
%
\begin{equation*}
    \E[Y_{t+1}|y_1,\dots,y_t] = \E[\Phi_{t+1}|y_1,\dots, y_t]-gt = \underbrace{\E[\Phi_{t+1}-\Phi_t|y_1,\dots, y_t]}_{\geq g}-g +Y_{t}\geq Y_t
\end{equation*}
%
The difference of the martingale sequence $|Y_{t+1}-Y_t|$ is
\begin{equation*}
    |Y_{t+1}-Y_{t}|\leq |\log_2 w_{t+1}(a)-\log_{2}w_t(a)|+12 C_{1/2,\alpha}+g\leq  |\log_2 w_{t+1}(a)-\log_{2}w_t(a)|+O(\alpha^2),
\end{equation*}
by triangle inequality and $C_{1/2, \alpha}=\Theta(\alpha^2)$ for $\alpha\in (0,1/4)$ due to Lemma 10 \cite{gretta2023sharp}. The remaining term is 
$|\log w_{t+1}(a)-\log w_t(a)|\leq \max\{\log d_{1,0}, \log d_{0,1}\}\leq O(\alpha)$ for Lemma 13 \cite{gretta2023sharp}, thus $|Y_{t+1}-Y_t|\leq O(\alpha)$. We can use Azuma's inequality to bound the probability of having a negative potential 
\begin{align*}
    \Pr[\Phi_{t+1}\leq 0] &= \Pr[\Phi_{t+1}-gt-\Phi_1\leq -gt -\Phi_1]\\
    &=\Pr[Y_{t+1}-Y_0\leq -gt -\Phi_1]\\
    &\leq \exp\bigg(-\dfrac{(gt+\Phi_1)^2}{t\cdot O(\alpha^2)}\bigg)\quad \text{for } gt\geq -\Phi_1.
\end{align*}
Note that $\Phi_1=-\log(B-1)$. Therefore, picking $T=O\left(\frac{\log B}{g}\right)$ sufficiently large, we get that $\frac{(gT+\Phi_1)^2}{T\cdot O(\alpha^2)}\geq \lambda\log B$ for any desired constant $\lambda>0$. Thus,
\[
\Pr[\Phi_{T+1}\leq 0]\leq B^{-\lambda}.
\]
On the other hand, note that if $\Phi_{T+1}> 0$, then
\[
 0<\frac{\Phi_{T+1}}{12C_{1/2, \alpha}} \leq (|\{x\in L : x \in [\ell,r]\}|-\gamma|L|),
\]
and so, a $\gamma$ fraction of the intervals in $L$ are $(1/2,\alpha(1+c))$-good. Now we can order the intervals in $L$ in sorted order according to their indices $i$ of the corresponding coins. By picking a subset $S$ of every $(1/\gamma)$th of them, we are ensured that one of them will be good (conditional on the high probability event $\Phi_{T+1}> 0$). For each interval in $S$, we can test whether it is $(1/2,\alpha(1+c))$-good with high probability using $O(\frac{\log B}{\alpha^2})$ coin flips of each of the coins at its endpoints. Therefore, we successfully determine an $(1/2,\alpha(1+c))$-good coin with high probability in $B$. If we pick $\gamma=1/13$, the total number of coins flipped is 
\[
T+|S|O\bigg(\frac{\log B}{\alpha^2}\bigg)= O\bigg(\frac{\log B}{g}\bigg)+O\bigg(\frac{\log B}{\alpha^2}\bigg)=O\bigg(\frac{\log B}{\alpha^2}\bigg),
\]
where the final bound uses that $g=(1-12\gamma)C_{1/2, \alpha}=\frac{1}{13}C_{1/2, \alpha}=\Theta(\alpha^2)$. This completes the proof.
%
%
%
   %
%
%
%
 %
  %
%
%
%
  %
%
%
\end{proof}