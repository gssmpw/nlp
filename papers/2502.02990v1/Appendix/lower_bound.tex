\section{Lower Bounds}\label{sec:lower-bound}
In this section, we give the proof of our lower bounds: Theorem~\ref{thm:main-lower} for adaptive mechanisms, and Theorem~\ref{thm:intro-lower-non-interactive} for non-adaptive mechanisms. Since an algorithm for the median problem implies an algorithm for a general quantile by inserting dummy elements, we will correspondingly show a lower bound for the general quantile problem, demonstrating that all quantiles (not too close to the minimum or maximum) are as hard as the median. We use the notation \texttt{LDPstat-quantile} and \texttt{LDPemp-quantile} with the additional parameter $q$ to describe the corresponding generalizations.

\subsection{Adaptive Mechanisms}

In the statistical setting, our building block will be the lower bound framework in~\cite{duchi2013local}, which turns the estimation problem into a distinguishing problems. In our setting, it means that if a mechanism attains low error on the quantile problem, then it is good at distinguishing distributions with different $q$th quantiles from each other, even from a ``hard'' family of distributions. Our hard family of distributions will be close in statistical distance, but still have different $q$th quantiles:
    \[
        P_\beta(i) = \begin{cases}
        q - 2\alpha & i = 1 \\
        4\alpha & i = \beta \\
        1-q-2\alpha & i = \ab,
    \end{cases}
    \]
for $\beta \in \{2, \ldots, \ab-2\}$. If $\beta$ is chosen uniformly at random, then our LDP distinguishing mechanism will be able to deliver $\log(\ab)$ bits of information (measured with the mutual information), by Fano's inequality. However, there is an upper bound on the amount of mutual information possible with an LDP protocol, as first established in~\cite{duchi2013local}. This gives us the following bound:

\begin{theorem}\label{thm:stat-lb-adapt}
    Let $\ab \geq 4$, $\alpha < \frac{1}{2}$, $\epsilon < 1$, and $q\in (2\alpha, 1-2\alpha)$. Suppose there is a sequentially interactive $\epsilon$-LDP algorithm that  for any distribution $\mathcal{D}$ solves \texttt{LDPstat-quantile}$(\mathcal{D},n,\alpha,\eps,q)$ with probability at least $\frac{1}{2}$ . Then 
    \[
        n \geq \Omega\left( \frac{\log B}{ \eps^2\alpha^2}\right).
    \]
\end{theorem}

\begin{proof}
    Let $\mathcal{M}=(\mathcal{M}_1,\dots, \mathcal{M}_n)$ be a sequentially interactive $\eps$-LDP protocol which solves \texttt{LDPstat-quantile}$(\mathcal{D},n,\alpha,\eps,q)$ with probability $\geq 1/2$, i.e., for a distribution $\mathcal{D}$ and $n$ samples $x_1,\dots,x_n$ from $\mathcal{D}$, it outputs an estimate $\tilde m=\mathcal{M}(x_1,\dots, x_n)$ which is an $\alpha$-approximation to the true median of $\mathcal{D}$ with probability at least $1/2$.
    Consider the following collection of distributions $\{P_\beta\}_{\beta \in [B]}$ indexed by a parameter $\beta\in \{1,\dots,B-1\}$, with probability mass functions defined by
    \[
        P_\beta(i) = \begin{cases}
        q - 2\alpha & i = 0 \\
        4\alpha & i = \beta \\
        1-q-2\alpha & i = B-1.
    \end{cases}
    \]

    Let ${\beta^*}$ be uniformly at random from $\{1,\dots,B-1\}$, and generate $n$ samples $x_1, \ldots, x_n$ from $P_{\beta^*}$. Let $y_i=\mathcal{M}_i(x_i,y_1,\dots,y_{i-1})$ be the $\eps$-differentially private output of user $i$ generated in the manner of in the manner of~\eqref{eq:sequential-interaction}. Finally, let $\tm_{\beta^*}=\mathcal{F}(y_1,\dots, y_n)$ be the estimated median output by our protocol. By Fano's inequality,
    \begin{align*}
        I({\beta^*} ; y_1, \ldots, y_n) &\geq H({\beta^*}) - H(\textbf{1}[\tm_{\beta^*} = {\beta^*}]) +\\
        &\quad - \Pr[\tm_{\beta^*} \neq  {\beta^*}] \log_2(B - 1) \\
        &\geq \log_2(B) - 1 - \frac{1}{2} \log(B-1) \\
        &\geq \frac{1}{4} \log_2(B),
    \end{align*}
    where $I$ denotes the mutual information and $H$ denotes the binary entropy.
    
    However, using the fact that our mechanism is $\eps$-LDP, we can use the \emph{upper bound} from~\cite{duchi2013local} on the mutual information between $\{y_1,\dots, y_n\}$ and ${\beta^*}$. According to their bound (see the calculations following Corollary 1 of~\cite{duchi2013local}) for all $\epsilon < 1$, we have 
    \[
    I({\beta^*}; y_1, \ldots, y_n) \leq 4(e^\epsilon-1)^2  \frac{n}{B^2} \sum_{\beta, \beta' \in [B]} \|P_\beta- P_{\beta'}\|_{TV}^2.
    \]
    %
         %
        %
            %
        %
   %
   Note that the total variation distance between $P_\beta$ and $P_{\beta'}$ for $P_\beta\neq \beta'$ is $4\alpha$. It follows that, 
   \[
   I({\beta^*}; y_1, \ldots, y_n) \leq 256 \eps^2n\alpha^2.
   \]
    Combining inequalities, we see that $\log(B) \leq 1024 \epsilon^2 \alpha^2 n$ which implies that $n =\Omega( \frac{\log B}{ \eps^2\alpha^2})$, as desired.
\end{proof}

To adapt this to the empirical setting, observe that any algorithm for the empirical problem can be used to solve the statistical problem by sampling, and then applying the empirical algorithm.
\begin{theorem}\label{thm:emp-lb-adapt}
    Let $\ab \geq 4,\acc<\frac{1}{2}$, and $q \in (2\alpha, 1-2\alpha)$. If $\priv \leq \min \{ 1, \frac{1}{64} \sqrt{\log \ab} \}$, then any sequentially interactive $\epsilon$-LDP algorithm that solves \texttt{LDPemp-quantile}$(\{x_i\}_{i=1}^n,\alpha,\eps,q)$ with probability $\frac{3}{4}$ requires $n \geq \Omega(\frac{\log B}{\priv^2 \acc^2})$. 
\end{theorem}

\begin{proof}
    We will first show any algorithm $\calM$ which solves $\texttt{LDPemp-quantile}(\{x_i\}_{i=1}^n, \alpha, \epsilon, q)$ with probability $\frac{3}{4}$ can be used to solve $\texttt{LDPstat-quantile}(\calD, n, 2\alpha, \epsilon, q)$ with probability $\frac{1}{2}$. The algorithm will simply apply $\calM$ to the sampled dataset $\{x_1, \ldots, x_n\}_{i=1}^n$ from $\calD$. Using Hoeffding's bound, together with the fact that $n \geq \frac{2}{\alpha^2}$, the $q$th quantile $x_{(q)}$ of the sampled dataset will have quantile error at most $\alpha$ from the true $q$th quantile of $\calD$ with probability at least $\frac{3}{4}$. Thus, the correctness guarantee of $\calM$ carries over, with success probability at least $\frac{1}{2}$ by the union bound.

    Using the above reduction, we are able to show a lower bound of $n \geq \Omega(\frac{\log \ab}{\priv^2 \acc^2})$ so long as these $\frac{\log(B)}{1024 \priv^2 \acc^2} \geq \frac{4}{\alpha^2}$ is satisfied.
    
\end{proof}

Theorem~\ref{thm:main-lower} follows directly from Theorem~\ref{thm:emp-lb-adapt}. These lower bounds establish that our algorithm in Theorem~\ref{thm:main-emp} is tight in the $\epsilon = O(1)$ regime.

\subsection{Non-Adaptive Mechanisms}
In order to prove non-adaptive lower bound of~\cref{thm:intro-lower-non-interactive}, we will apply a lower bound for learning a cumulative distribution function from~\cite{edmondsNU20}. The CDF learning problem is defined as follows:



\begin{definition}
    Given a dataset $X = \{x_1, \ldots, x_n\} \subseteq [B]$, let $F_X(t)$ denote its c.d.f. (given by $F_X(t) = \frac{1}{n} \sum_{i=1}^n \textbf{1}[x_i \leq \tau]$.
    In the $\texttt{LDPemp-cdf}(\{x_i\}_{i=1}^n, \alpha, \epsilon)$ problem, the task is to output a function $\tilde{F}$ under $\epsilon$-LDP which approximates the c.d.f. up to error alpha at all points; i.e. 
    \[
        \E[\|\tilde{F} - F_X\|_\infty] \leq \alpha.
    \]
\end{definition}
Observe the above definition considers the expected error, which different from applying Definitions~\ref{def:med-emp} or~\ref{def:med-stat} with constant probability of failure. We change to expectation because it is the setting considered by~\cite{edmondsNU20}, but may easily convert between the two types of guarantees (since the maximum c.d.f. error is $1$, we only need failure probability of $\alpha$ to obtain a bound on the expectation).

A lower bound on $n$ for learning a c.d.f. was shown in~\cite{edmondsNU20} for $\epsilon < 1$:

\begin{theorem}\label{thm:emp-lb-cdf} (Theorem 23 in~\cite{edmondsNU20})
    There exists a constant $C$ such that,
    for all $\alpha$ sufficiently small, and all $\epsilon < 1$ and $B$ satisfying $\frac{\log^2(B)}{ \epsilon^2\alpha^2 \log(1/\alpha)^2} \geq \frac{C \log (2B)}{\alpha^2} + \frac{C}{\epsilon^2 \alpha^2}$ any $\epsilon$-LDP algorithm which solves $\texttt{LDPemp-cdf}(\{x_i\}_{i=1}^n, \alpha, \epsilon)$ requires 
    \[
        n \geq \Omega\left(\frac{\log^2(B)}{\epsilon^2 \alpha^2 \log(1/\alpha)^2}\right).
    \]
\end{theorem}

In particular, it is sufficient to satisfy Theorem~\ref{thm:emp-lb-cdf} when $\alpha \geq B^{-\Omega(1)}$ and $\epsilon \leq \frac{\sqrt{\log B}}{\log(1/\alpha)}$, which is a mild assumptions as $\alpha, \epsilon$ are constants typically significantly less than $B$. 

To apply this theorem, we prove a reduction from \texttt{LDPemp-quantile} for constant $q$ to \texttt{LDPemp-cdf}. The c.d.f. may be solved to accuracy $\alpha$ by computing the $\alpha, 2\alpha, \ldots, 1-\alpha$ quantiles. With correct padding, we may use our \texttt{LDPemp-quantile} algorithm to answer any of these quantiles. To answer all $\frac{1}{\alpha}$ quantiles, our reduction uses non-adaptivity in a crucial way: it is only necessary to collect responses once, add in the proper amount of responses for padded elements, and then post-process them into a response. By boosting the accuracy of the quantile with $\log(\frac{1}{\alpha})$ runs, each quantile estimate will have success probability at least $1-\alpha^2$. We may then apply a union bound to obtain a bound on the expected error on all quantiles (giving the desired c.d.f. error).

\begin{lemma}\label{lem:reduct}
    Suppose there is a non-adaptive algorithm solving $\texttt{LDPemp-quantile}(\{x_i\}_{i=1}^{n}, \alpha, \epsilon, q)$ with probability $\frac{3}{4}$, for all datasets of size $n \geq n_0$. Then, there is a non-adaptive algorithm solving $\texttt{LDPemp-cdf}(\{x_i\}_{i=1}^{n}, \alpha (1 + \frac{1}{q}), 2\epsilon \log(\frac{1}{\alpha}))$  with probability $\frac{3}{4}$ for any datasets of size $n \geq n_0$ . 
\end{lemma}

\begin{proof}
    WLOG, we may assume that $q \leq \frac{1}{2}$.
    Suppose we are given a dataset $\{x_1\}_{i=1}^n$. We will first show how to estimate any quantile $q'$ with success probability at least $\frac{3}{4}$ and error $\frac{\alpha}{q}$. We may do this by adding padded elements to the dataset. Specifically, if $q < q'$, then adding $\frac{q' - q}{q}n$ padded $B$s to the dataset will ensure that the $q$th quantile will match the $q'$th quantile of the original dataset. If  $q' < q$, then adding $\frac{q - q'}{1-q}n$ padded $1$s to the dataset will ensure the $q$th quantile will match the $q'$th quantile of the original dataset.
    Observe that quantile error of $\alpha$ in the padded dataset corresponds to quantile error $\frac{\alpha}{q}$ in the original dataset.


    Next, observe that computing the quantiles $\{\alpha, 2\alpha, \ldots, 1-\alpha\}$ with error $\alpha$ gives a $2\alpha$ c.d.f. estimation. We will simulate running the above procedure on all $\frac{1}{\alpha}$ quantiles by collecting the responses $r_1 = \calM_1(x_1), \ldots, r_n = \calM_n(x_n)$, and then $r_i^0 = \calM_i(1), r_i^1 = \calM_i(B)$ for $n+1 \leq i \leq n + \frac{n}{q}$. By picking the correct padded elements, we may post-process the response to obtain an estimate of any $q'$th quantile with error at most $\frac{\alpha}{q}$. This crucially uses the fact that the $\calM$ are non-interactive, as any state shared between the $\calM_i$ could not be simulated for all runs at once.

    Each of the above estimated quantiles has error $\frac{\alpha}{q}$ with probability at least $\frac{3}{4}$. We may boost the success probability by running the above procedure independently $2 \log(\frac{1}{\alpha})$ times and taking the \emph{median} quantile estimate; by Chernoff's bound, we are guaranteed that each quantile estimate is at most $\frac{\alpha}{q}$ from the true $q'$ quantile with probability $1-\alpha^2$. By the union bound all quantile estimates will have error $\frac{\alpha}{q}$ with success probability at least $1-\alpha$, and the expected c.d.f. error is at most $\alpha + (1-\alpha)\frac{\alpha}{q} \leq \alpha (1 + \frac{1}{q})$. Finally, the privacy parameter is $2\epsilon \log (\frac{1}{\alpha})$ by simple composition.
\end{proof}


Theorem~\ref{thm:emp-lb-cdf} and Lemma~\ref{lem:reduct} together give us a lower bound on the median error under LDP:

\begin{theorem}\label{thm:lb-non-adapt}
    For any constant $q \in (0.1, 0.9)$, any $\alpha$ sufficiently small, $\epsilon < \frac{1}{\log(1/\alpha)}$, and $B$ such that $\alpha \geq B^{-\Omega(1)}$ and $\epsilon \leq \frac{\sqrt{\log B}}{\log(1/\alpha)^2}$, any $\priv$-LDP algorithm which solves $\texttt{LDPquantile-emp}(\{x_i\}_{i=1}^n, \acc, \priv, q)$ with probability at least $\frac{3}{4}$ requires 
    \[
        n \geq \Omega\left(\frac{\log^2(\ab)}{\priv^2 \acc^2 \log(1/\acc)^4}\right).
    \]
\end{theorem}
Theorem~\ref{thm:intro-lower-non-interactive} follows directly from this result.