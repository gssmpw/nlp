\section{Experiments}\label{sec:experiments}

\begin{figure}[t]
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=1\linewidth]{figures/main/success_and_cdf_N_2500_B_exp_9.png}
        \subcaption{\small Pareto like data with $n=2500$ and $\ab=4^9$}
        \label{sub: 1}
    \end{minipage}%
    \hspace{0.02\textwidth}
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=1 \linewidth]{figures/main/main_2500_eps_1.0.png}
        \subcaption{\small Uniform data with $n=2500$ and $\varepsilon=1$}
        \label{sub: 2}
    \end{minipage}
    \caption{Plots \ref{sub: 1} compare the three algorithms on the Pareto-like dataset: the left plot shows the success rate for $\alpha_{\text{test}}= 0.04$ across $\varepsilon\in[0.1, 5]$, and the right plot shows the c.d.f. of the absolute error for $\varepsilon = 0.57$. Plots \ref{sub: 2} compare \texttt{DpBayeSS} and \texttt{DpNaiveNBS} on a uniform dataset with $\varepsilon=1$: the left plot shows the success rate for different coin domains $\ab$ for $\alpha_{\text{test}}=0.04$, and the right plot shows the c.d.f. of the absolute error for $\ab=10^6$. The error bars on the left plots are standard deviation, computed as the sample average over $200$ trials. The decrease in accuracy observed in \cref{sub: 2} at $B = 10^5$ is likely attributable to a random generation of a more challenging dataset.
    }
    \label{fig: main results}
\end{figure}

We compared three mechanisms for median estimation in the empirical setting: \texttt{DpNaiveNBS} (binary search with randomized response), \texttt{Hierarchical Mechanism} from \cite{kulkarni2019answering}, which serves as the state of the art for non-adaptive protocols, and our sequentially adaptive algorithm, \texttt{DpBayeSS}, introduced in Theorem~\ref{thm:main-emp} (\cref{alg: DPBayeSS} in \cref{app: experiments} illustrates the pseudocode). Further details of the implementation, extensive experimental analysis, and experimental results for our algorithm in the shuffle model appear in \cref{app: experiments}. Experiments were conducted on data generated from two distributions: a Pareto distribution over $[B]$, often used to model quantities like income and population~\cite{arnold2014pareto}, and a uniform distribution over a random interval $[l,r]$ with $1 \leq l \leq r \leq \ab$, ensuring that the position of the median is not straightforward.

We evaluated the mechanisms using two metrics: the \emph{success rate}, 
%
computed as the fraction of times a $(\frac{1}{2}, \alpha_{\text{test}})$-good coin is returned with $\alpha_{\text{test}}=0.04$, and the \emph{absolute quantile error}, $|F_X(\Tilde{m}) - F_X(m)|$, where $\Tilde{m}$ is the returned median. We run each algorithm $200$ times and computed the standard deviation of the success rate as the sample average of a Bernoulli random variable.
%

In \autoref{sub: 1}, we plot the success rate of the three privacy mechanisms for a fixed $B=4^9$, and $n = 2500$, with $\epsilon$ varying from $0.1$ to $5$, for the synthetic Pareto-like dataset. We also plot the cumulative distribution of the absolute quantile error, showing the distribution of the quantile error over $200$ trials, for $\epsilon = 0.57$. These parameter settings are typical values encountered in real applications; we test many more parameter values in \autoref{app: experiments} with similar results. 
%
The plots illustrate that \texttt{DpBayeSS} always achieves far higher success rate than the other two mechanisms, and is statistically significant as the confidence intervals are far from overlapping. Correspondingly, the c.d.f. of the absolute quantile error shows this value is much lower for \texttt{DpBayeSS}. Also, we observe that the number of users is insufficient to obtain a meaningful median using the \texttt{Hierarchical Mechanism}, which aligns with our theoretical predictions.

In \autoref{sub: 2}, we plot the succes rate of \texttt{DpBayeSS} and \texttt{DpNaiveNBS} with a fixed privacy budget $\varepsilon=1$ over varying domain sizes $\ab$ from $10^3$ to $10^6$ using the uniform distribution data set with $2500$ users. We also plot the c.d.f. of absolute quantile error for a large domain of $B = 10^6$. We observe again that \texttt{DpBayeSS} achieves superior performance in all the values of $\ab$ tested. Due to implementation constraints, \texttt{Hierarchical Mechanism} was not tested on this dataset, but results in \autoref{sub: 1} indicate its error is generally higher than binary search-based methods. Our code is freely available \footnote{\url{https://github.com/NynsenFaber/Quantile_estimation_with_adaptive_LDP}}.





