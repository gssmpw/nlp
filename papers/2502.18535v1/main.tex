%\documentclass[journal,12pt,onecolumn,draftclsnofoot]{IEEEtran}
\documentclass[journal]{IEEEtran}

\input{packageSetup}
\usepackage{wasysym}
%\usepackage{diagbox}
%\usepackage{geometry}
%\usepackage{array}
\usepackage{caption}
\usepackage{subfigure}
%\usepackage{lipsum}
%\usepackage{booktabs}
%\renewcommand{\arraystretch}{1.5}
%\usepackage{makecell}

\usepackage{booktabs} % 用于绘制三线表
\usepackage{graphicx} % 用于调整表格宽度
\usepackage{amssymb} % 用于使用 \checkmark

% \usepackage{multirow}
% \usepackage{makecell}



\begin{document}


\title{A Survey of Zero-Knowledge Proof Based Verifiable Machine Learning}

\author{Zhizhi Peng, Taotao Wang, Chonghe Zhao, Guofu Liao, Zibin Lin, \\ Yifeng Liu,  Bin Cao, Long Shi, Qing Yang, and Shengli Zhang% <-this % stops a space

\thanks{Z. Peng, T. Wang, C. Zhao, Y. Liu, Q. Yang, and S. Zhang are with the College of Electronics and Information Engineering, Shenzhen University, Shenzhen, Guangdong Province, China, e-mails: {p1878575@163.com}, {ttwang@szu.edu.cn}, {zhaochonghe\_szu@163.com}, {13539213368@163.com}, {yang.qing@szu.edu.cn},  {zsl@szu.edu.cn}.

B. Cao is with the State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, China, e-mail: caobin@bupt.edu.cn.

L. Shi is with the School of Electronic and Optical Engineering, Nanjing University of Science and Technology, Nanjing 210094, China, e-mail: slong1007@gmail.com.

%S.~Liew is with Department of Information Engineering, The Chinese Univeristy of Hong Kong, Hong Kong SAR, China, e-mail: soung@ie.edu.hk.
}% 


}

\maketitle

\begin{abstract}
As machine learning technologies advance rapidly across various domains, concerns over data privacy and model security have grown significantly. These challenges are particularly pronounced when models are trained and deployed on cloud platforms or third-party servers due to the computational resource limitations of users' end devices. In response, zero-knowledge proof (ZKP) technology has emerged as a promising solution, enabling effective validation of model performance and authenticity in both training and inference processes without disclosing sensitive data. Thus, ZKP ensures the verifiability and security of machine learning models, making it a valuable tool for privacy-preserving AI. Although some research has explored the verifiable machine learning solutions that exploit ZKP, a comprehensive survey and summary of these efforts remain absent. This survey paper aims to bridge this gap by reviewing and analyzing all the existing Zero-Knowledge Machine Learning (ZKML) research from June 2017 to December 2024. We begin by introducing the concept of ZKML and outlining its ZKP algorithmic setups under three key categories: verifiable training, verifiable inference, and verifiable testing. Next, we provide a comprehensive categorization of existing ZKML research within these categories and analyze the works in detail. Furthermore, we explore the implementation challenges faced in this field and discuss the improvement works to address these obstacles. Additionally, we highlight several commercial applications of ZKML technology. Finally, we propose promising directions for future advancements in this domain.
\end{abstract}

\begin{IEEEkeywords}
Zero-knowledge Proof, Machine Learning, Verifiability, Model Security, Data Privacy.
\end{IEEEkeywords}

\markboth{A Survey of Zero-Knowledge Proof Based Verifiable Machine Learning, Feb. 2025}{}
\linenumbers

\section{Introduction}\label{s:intro}
\IEEEPARstart{T}{he} rapid advancement of artificial intelligence (AI) technologies, epitomized by machine learning (ML), has brought significant transformations to various aspects of human life. Recently, the emergence of generative AI models based on large models has introduced new opportunities in fields such as design and art, software development, publishing, and even finance. However, as model capabilities increase, the demand for computational power in machine learning grows exponentially, necessitating larger datasets and more extensive computational clusters for parallel training. AI business products like ChatGPT \cite{wu2023brief} and Midjourney \cite{borji2022generated} present impressive performance, relying not only on sophisticated machine learning models and efficient algorithms but also on substantial investments in data and computational resources for model training.

Due to limitations in computational and data resources, ordinary users such as individuals, small and medium-sized institutions often cannot train ML models locally or even perform inference using trained models. To address this, ML service providers (for example, large companies like Google, Amazon, Alibaba, etc.) offer rental services for ML models, computational resources, and storage space, enabling customers to easily execute ML tasks and integrate them into their applications. For example, ML clients, i.e., individuals, small and medium-sized institutions, utilize Machine Learning as a Service (MLaaS) \cite{ribeiro2015mlaas} engines to outsource complex ML models (such as  deep neural networks ) training and inference tasks, and performing inferences with trained ML models; the ML service provider receive data from ML clients to execute the ML tasks. 

However, the above paradigm raises significant concerns regarding trust and data privacy between ML clients and ML service providers. On one hand, clients are particularly vulnerable due to the sensitive nature of their data, as evidenced by frequent and severe data breaches. Notable examples include the 2022 data breach involving the digital booking and scheduling platform FlexBooker, which resulted in the compromise of personal information for approximately 3.2 million users. Similarly, the theft of a database hosted on Alibaba Cloud exposed the personal information of 1 billion Chinese citizens, along with billions of police records, highlighting the alarming scale and impact of such incidents. Additionally, other issues include ML service providers using underperforming models for inferences while fabricating seemingly flawless results to their clients. As a consequence, clients are often unwilling to provide data containing private information to ML service providers. On the other hand, ML service providers are concerned about their machine learning models being stolen or maliciously compromised. For instance, attackers disguise themselves as clients to implant ``backdoors'' into the ML service providers' models, causing it to perform well on normal samples but make specific erroneous inferences on inputs with particular backdoor triggers \cite{wang2019security}. Another scenario is that the ML service providers are using a model trained on the wrong data, or using a poorly performing model to make predictions and faking a seemingly perfect result to deceive the client. In summary, due to the trust and data privacy concerns between clients and machine learning service providers, there is a need for privacy-preserving solutions that allow the encrypted data of clients to be used in machine learning tasks while preventing attacks and fraudulent activities on the models of ML service providers, serving trust assurances \cite{al2019privacy}.

Recently, it has been demonstrated that the technique of zero-knowledge proofs (ZKP) can effectively address the aforementioned issues. Consequently, ZKP has been proposed as a solution to implement a verifiable machine learning framework, known as zero-knowledge machine learning (ZKML). ZKP is a type of cryptographic technique that allows one party to prove the truth of a statement to another party without revealing any information beyond the statement itself \cite{de1992zero}. They have the potential to effectively solve the privacy protection and tissues of data and models in MLaaS, as well as the trustworthiness of model computation results. Within the framework of ZKML, the correctness of data and the correctness of model parameters or execution results can be considered as a "statement" that the ZKP is used to prove. For example, in a ZKP-based training task of verifiable machine learning, the client needs to prove to the ML service provider that the training data provided by the client is indeed correct; conversely, the ML service provider needs to prove to the client that the model parameters (or inference results) are indeed obtained by training (or performing inference) on the dataset received from the client. ZKP allows the two parties to trust the statements without learning the details of task executions. 

Fig. \ref{f1} illustrates one of ZKML setups for executing inference tasks in ZKML. In this ZKML setup, the machine learning service provider acts as the prover in the ZKP algorithm, and the client acts as the verifier. The function \( F(\ast) \) represents the relationship the ZKP algorithm wants to prove. The input data for the ZKP algorithm is divided into public input (known to both the prover and verifier) and the private witness (known only to the prover). To execute this ZKML setup, a client first sends their data \( x \)  to the ML service provider as the data input to the ML model; and then the ML service provider supplies the model parameters $w$ together with the data \( x \) to completes the  machine learning inference task by computing the model inference result \( r = W(x, w) \), where \( W(\ast) \) denotes the model inference computation; after that, the machine learning service provider runs the proving function of ZKP to generate a zero-knowledge proof \( \pi \) for that the relationship \( F(x, r, w) = W(x, w) - r = 0 \) is hold, where \( (x, r) \) are set as the public input of the ZKP algorithm and \( w \) is set to as the private witness of the ZKP algorithm; finally, the client runs the verifying function of ZKP to verify the proof \( \pi \) and accepts the inference result \( r \) if the proof \( \pi \) is verified successfully. Through this ZKML setup, the client can trust that the inference result \( r = W(x, w) \) provided by the ML service provider is indeed obtained by executing the machine learning model on their provided data \( x \), even though they do not learn the specific model parameters \( w \) and the exact inference computation process of \( W(\ast) \). In this way, a form of ``trustworthy'' machine learning is achieved via the verifiability of ZKP.

\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{pic1.png}
    \caption{An illustrating setup of ZKML Framework.}
    \label{f1}
\vspace{-10pt}
\end{figure}

Thanks to the growing interest in privacy-preserving and trust ML technologies and the advancements in zero-knowledge proof techniques, there are now numerous works on ZKML, and new proposals continue to emerge. ZKML is a novel verifiable ML framework at the intersection of machine learning and cryptography, characterized by a diverse and complex research landscape. Therefore, systematically reviewing its development trajectory and summarizing current progress is crucial for advancing future research. Currently, there are limited survey studies on ZKML research works and no comprehensive coverage about the latest research up to now, lacking depth understanding about the relationship between research works. The existing survey works about ZKML are \cite{moduluslabs2023cost,sathe2023state,xing2023zero}, and we summarized them as follows. In \cite{moduluslabs2023cost}, Modulus Lab conducted inductive and comparative studies on the verifiability of machine learning inference task based on ZKP, confirming the feasibility of ZKP in verifiable machine learning. Using multilayer perceptrons (MLP) as the benchmark machine learning model, they compared the performances of six different ZKP systems, including Groth16, Gemini, Winterfell, Halo2, Plonky2, and zkCNN \cite{liu2021zkcnn}, in terms of proof time and memory consumption during machine learning inferences. Additionally, through comprehensive experimental validation, this work explained the impact of different ZKP systems on the efficiency of machine learning verifiable inference works. However, their analysis of how ZKML works enhance efficiency is relatively limited (all the works mentioned in \cite{moduluslabs2023cost} are also included for investigations in this survey). Sathe \emph{et al.} \cite{sathe2023state} introduced and analyzed ZKML works up to 2023, providing detailed descriptions of zkCNN \cite{liu2021zkcnn}, ezDPS \cite{wang2022ezdps}, Xing \cite{xing2023block}, and Mystique \cite{weng2021mystique}. However, this survey covers fewer works and does not provide a comparative investigation of the existing works; the authors of \cite{sathe2023state}, individually described the specific contents of the four works mentioned, failing to comprehensively present the latest developments and directions in the field. Recently, Xing \emph{et al.} \cite{xing2023zero} provided a comprehensive survey of ZKML, including definitions, properties, and challenges. This survey covered all relevant ZKML works up to June 2023. The existing works discussed in this survey were divided into two application categories and further classified based on technical characteristics, providing researchers with a more comprehensive reference.

To bridge the gap and enhance existing reviews and surveys on ZKML, we conducted a comprehensive investigation summarizing ZKML works from June 2017 to December 2024. The main contributions of this survey paper are as follows:
\begin{itemize}
    \item \textbf{Systematic Investigation of ZKML Research}: This paper offers a structured examination of ZKML works, organizing, classifying, and summarizing nearly all significant contributions from June 2017 to December 2024, encompassing a total of 27 notable studies.
    
    \item \textbf{Categorization and Discussion of Technical Improvements}: We categorize the technical improvement works that aim to address the implementation challenges of ZKML research into two primary dimensions (\emph{i.e.}, improving the generality and efficiency of ZKML) and outline the evolutionary process of these advancements.
    
    \item \textbf{Introduction of Commercial Applications}: Moving beyond academic contexts, this paper explores commercial applications of ZKML, demonstrating its relevance and potential impact in industry.
    
    \item \textbf{Future Directions and Technical Challenges}: By analyzing the current state of ZKML research and identifying key technical challenges, this paper proposes potential avenues for future development, offering guidance and inspiration for subsequent researchers.
\end{itemize}

The remainder of the paper is organized as follows: Section II introduces the background of machine learning and zero-knowledge proofs, along with three categories of verifiable machine learning. Section III presents existing research works for verifiable machine learning based on zero-knowledge proofs and their development process. Section IV discusses commercial applications of ZKML. Section V not only summarizes the paper, but also proposes future directions for ZKML development. Table \ref{tab1} lists the main abbreviations used in the paper and their definitions.

\begin{table}[t]
    \centering
    \renewcommand{\arraystretch}{1.3} % 增大行距，值越大行距越大
    \setlength{\tabcolsep}{10pt} % 增大列距，值越大列间距越大
    \caption{ Abbreviations Table}

    \begin{tabular}{l l}
        \hline
        \textbf{Abbreviations} & \textbf{Full Name} \\ \hline
        AI & Artificial Intelligence \\
        ML & Machine Learning \\
        MLaaS & Machine Learning as a Service \\
        ZKP & Zero-Knowledge Proof \\
        zk-SNARK & Zero-Knowledge Succinct \\
        &Non-interactive Argument of Knowledge \\
        R1CS & rank-1 constraint system \\
        MLP & Multilayer Perceptron \\
        SVM & Support Vector Machine \\
        CRS & Common Reference String \\
        ROM & random oracle model \\
        DP & Differential Privacy \\
        FL & Federated Learning \\
        TEE & Trusted Execution Environment \\
        SMC & Secure Multiparty Computation \\
        NN & Neural Network \\
        LogR & Logistic Regression \\
        LR & Linear Regression \\
        DWT & Discrete Wavelet Transformation \\
        PCA & principal components analysis \\
        DT & Decision Tree \\
        CNN & Convolutional neural network \\
        LLM & Large language model \\
        QAP & Quadratic Arithmetic Problem \\
        QPP & Quadratic Polynomial Problem \\
        QMP & Quadratic Matrix Problem \\
        \hline\\
    \end{tabular}
    \label{tab1}
\vspace{-15pt}
\end{table}






\section{Background}\label{s:bg}

This section starts by providing the technical background of machine learning and zero-knowledge proofs. It then delves into the details of verifiable machine learning and concludes with a comparison of the strengths and limitations of zero-knowledge proofs relative to other security techniques in the context of verifiable machine learning.

\subsection{Machine Learning}\label{ss:2a}



Machine Learning (ML) \cite{jordan2015machine}, a subfield of AI, enables the development of models from diverse types of data, such as numerical values, textual content, images, and user interactions. These ML models are applied to tasks like pattern recognition, problem-solving, and making predictions \cite{janiesch2021machine}. ML encompasses various approaches, including supervised learning, unsupervised learning, reinforcement learning, and more. In this survey, we primarily focus on supervised learning, as it is the most common form of ML and serves as the foundation for the most of existing zero-knowledge-based verifiable machine learning research.



% Machine Learning (ML) \cite{jordan2015machine}, a subfield of Artificial Intelligence (AI) \cite{hamet2017artificial}, is a powerful computational data analysis technique. It automatically creates analytical models by utilizing various types of data (such as numerical data, text content, user interactions, and visual data), enabling computers to learn from data and perform inference, classification, and decision-making based on it \cite{janiesch2021machine}. Although machine learning has been widely applied and rapidly developed across various fields, data privacy and machine learning security issues remain significant challenges. On the one hand, model training relies on large amounts of data, some of which are generated and collected from people's daily lives, inevitably involving privacy leakage issues. For example, ChatGPT uses a dataset of approximately 570GB for training, much of which originates from users who are often unaware that their personal data is used to train AI models. While most data are not privacy-sensitive, some sensitive or private data are inevitably mixed into the model. On the other hand, machine learning models may inadvertently leak sensitive information. For instance, attackers can gain insights into training data by analyzing the model's output, potentially compromising data privacy \cite{benos2021machine}. The security of machine learning models and the trustworthiness of computational tasks also face severe challenges. Attackers can influence the model training process by tampering with training data or adding malicious data, ultimately reducing accuracy during the inference phase \cite{liu2021machine}. During the inference phase, attackers can cause model misinferences by adding carefully crafted small perturbations to the test data, known as adversarial example attacks \cite{khalid2018security}. Therefore, effectively protecting user data privacy and ensuring machine learning security is crucial.

% To clearly explain how zero-knowledge proofs can be applied to machine learning in the following sections, a brief introduction to the working mechanisms of machine learning and several classic models is provided.

% \noindent\textbf{Working Mechanism}: The working mechanism of machine learning primarily includes the following steps \cite{mahesh2020machine}:

% \begin{itemize}

%     \item Data Collection: Gather a large amount of data, including both input and output data.
%     \item Data Preprocessing: Perform preprocessing tasks such as cleaning, organizing, and standardizing the collected data to ensure its accuracy and consistency.
%     \item Feature Extraction: Extract features relevant to the problem from the data for use by machine learning algorithms.
%     \item Model Training: Train the model using the processed feature data and corresponding label data. This involves continuously adjusting model parameters to better fit the data.
%     \item Model Evaluation: Evaluate the model's accuracy and stability using a test dataset.
%     \item Model Optimization: Optimize the model based on the evaluation results to improve its performance and generalization ability.
% \end{itemize}

% \noindent\textbf{Classic Models}: Machine learning is an artificial intelligence technique that enables computer systems to learn and improve from experience by using algorithms and models. Machine learning models can be broadly categorized into supervised learning \cite{muhammad2015supervised} and unsupervised learning \cite{novakovic2017evaluation}.



In supervised learning, the goal is to train a model that can capture the mapping $g(\cdot)$ from inputs \(X\) (also referred to as data features) to outputs \(Y\) (also known as labels), expressed as $Y=g(X)$. We denote a ML model by $f_\theta(\cdot)$, where $\theta$ represents the parameters of the model. The model is trained using a training algorithm and a dataset \(D_{train}=\{(X_1, Y_1), (X_2, Y_2), \ldots, (X_n, Y_n)\}\), where each pair \((X_i, Y_i)\) represents an input and its corresponding output label. In the training process, the parameters of the model are optimized by minimizing the total loss over the training dataset,  formalized as: \(\theta  = \arg \mathop {\min }\limits_{\theta '} \sum\nolimits_{\left( {{Y_i},{X_i}} \right) \in {D_{train}}} {l\left( {{Y_i},{f_{\theta '}}\left( {{X_i}} \right)} \right)} \), where \({l\left( {\cdot,\cdot} \right)}\) denotes the chosen loss function. Once the model \( f_\theta(\cdot) \) is trained, it can be used to infer the output label \( Y' \) for new input data \( X \) that were not part of the training dataset, expressed as \( Y' = f_\theta(X) \). The goal is for the learned model \( f_\theta(\cdot) \) to approximate the true mapping \( g(\cdot) \) as closely as possible, ensuring that the predicted output label \( Y' \) closely matches the true label \( Y \).


Various models are used to represent the mapping between input data features and output labels, including linear regression, decision trees, support vector machines, and deep neural networks. Each model has distinct characteristics and is suited to specific scenarios. Given the popularity and effectiveness of deep neural networks in modern applications, as well as the fact that nearly all existing work on ZKML focuses on deep neural networks, we adopt them as the default ML model in this survey unless otherwise specified. Consequently, the model parameters refer to the weights of the connections between the neuron units across the layers of the deep neural network.



% \begin{figure}[!t]
%     \centering
%     \includegraphics[width=\linewidth]{pic2.png}
%     \caption{Supervised learning paradigm.}
%     \label{f2}
% \vspace{-13pt}
% \end{figure}

% For unsupervised learning \cite{hahne2008unsupervised}, it is a technique that seeks patterns and structures in unlabeled data, discovering hidden structures and relationships through techniques such as clustering, dimensionality reduction, and association rules. Currently, due to the lack of explicit labels and the undefined nature of verification tasks in unsupervised learning, constructing corresponding ZKP is more complex and difficult to define. Therefore, the models in ZKML are mostly supervised learning models.

% Classic machine learning models include linear regression, decision trees, support vector machines (SVM), neural networks, and convolutional neural networks. These models have different characteristics and applicable scenarios, as detailed below:
% \noindent

% \begin{itemize}
%     \item For linear regression, it is suitable for situations where there is a linear relationship between variables \cite{maulud2020review}. The core lies in two points: i) analyzing the relationship between independent and dependent variables, and ii) using various optimization methods to train model parameters. This can be done directly using gradient descent algorithms or indirectly by transforming it into a dual problem.
%     \item For decision trees, they are applicable to classification and regression problems. They rely on a tree structure of decision rules to classify and infer data. By training on data, the model adjusts its structure and parameters, ultimately generating decision paths based on decision rules at the nodes to make decisions \cite{myles2004introduction}.
%     \item For SVM, it is suitable for classification and regression problems by finding an optimal hyperplane to separate data of different categories, thereby achieving classification tasks. In cases where data is linearly inseparable, nonlinear mapping algorithms are used to transform samples from a low-dimensional input space into a linearly separable high-dimensional feature space. These mapping algorithms make it possible to use linear algorithms to perform linear analysis on the nonlinear features of samples in the high-dimensional feature space \cite{pradhan2012support}.
%     \item For neural networks, they process information by simulating the connections between neurons in the human brain \cite{jain1996artificial}, suitable for handling complex and nonlinear pattern recognition problems. Specifically, a neural network is a network structure composed of hierarchically arranged neurons, where each neuron typically follows the form \( Y = WX + b \). Here, \( Y \) represents the output of the neuron, \( W \) is the weight matrix containing all the weights connecting the inputs and the neuron, \( X \) is the input vector containing all input features, and \( b \) is a constant bias term. This structure makes matrix and vector multiplication the main operations in neural networks. Additionally, to enable neurons to learn and capture nonlinear relationships in data, activation functions are introduced. Common nonlinear activation functions include the ReLU function, Softmax function, and Sigmoid function \cite{sharma2017activation}.
%     \item For convolutional neural networks, they primarily focus on two-dimensional data structures and are well-suited for processing images and spatial data. Compared to conventional neural networks, a key feature of convolutional neural networks is the introduction of convolution operations, allowing them to establish connections within local regions and reduce the number of parameters \cite{li2021survey}.
% \end{itemize}


\subsection{Zero-Knowledge Proof}\label{ss:2b}
Zero-knowledge proof (ZKP) is a cryptographic technique that proves a statement's validity without revealing any private information about the statement. There are several types of zero-knowledge proof systems \cite{canetti2000resettable}, for example, zero-knowledge succinct non-interactive argument of knowledge (zk-SNARK) \cite{sasson2014zerocash}, zero-knowledge scalable transparent argument of knowledge (zk-STARK) \cite{ben2019scalable}, and others. 


%Among them, zero-knowledge succinct non-interactive argument of knowledge (zk-SNARK) is considered to be the most practical. We present a simplified model of zk-SNARK here. We refer the readers to \cite{sasson2014zerocash} for the formal and complete model of zk-SNARK.

The computation of a ZKP system is usually represented by an arithmetic circuit that consists of the basic arithmetic operations of addition, subtraction, multiplication, and division.\footnote{Actually, the ZKP systems of zk-SNARK are always associated with arithmetic circuit representations; zk-STARK can theoretically support arithmetic circuit representations, but it typically uses the more efficient arithmetic intermediate representation (AIR) \cite{ben2018scalable} to construct ZKP systems.} An \(\mathbb{F}\)-arithmetic circuit is a circuit in which all inputs and all outputs are elements in a field \(\mathbb{F}\). Consider an \(\mathbb{F}\)-arithmetic circuit \(C\) that has an input \(x \in \mathbb{F}^n\), an auxiliary input \(W \in \mathbb{F}^h\) called a witness, and an output \(C(x,W) \in \mathbb{F}^l\), where \(n, h, l\) are the dimensions of the input, auxiliary input, and output, respectively. The arithmetic circuit satisfiability problem of the \(\mathbb{F}\)-arithmetic circuit \(C\) is captured by the relation: $\mathcal{R}_C = \{(x,W) \in \mathbb{F}^n \times \mathbb{F}^h : C(x,W) = 0^l\}$ and its expression is \(\mathcal{L}_C = \{x \in \mathbb{F}^n: \exists W \in \mathbb{F}^h \text{ s.t. } C(x,W) = 0^l\}\). A ZKP system consists of three algorithmic components \cite{sasson2014zerocash}:

\begin{itemize}
    \item[$\blacksquare$] $(PK, VK) \leftarrow KEYGEN(1^\lambda, C)$ is the key generation algorithm that generates the proving key $PK$ and the verification key $VK$ by using a predefined security parameter $\lambda$ and an arithmetic circuit representation $C$.
    \item[$\blacksquare$] $\pi \leftarrow PROVE(PK, x, W)$ is the proof generation algorithm that generates a proof $\pi$ based on the proving key $PK$, the input $x$ and the witness $W$.
    \item[$\blacksquare$] $1/0 \leftarrow VERIFY(VK, x, \pi)$ is the proof verification algorithm that outputs a decision to accept or reject $\pi$ using $VK$, $x$ and $\pi$ as the input.
\end{itemize}
The proving key PK and the verification key VK generated by the KEYGEN algorithm are treated as the public parameters. The PROVE algorithm is executed by the prover, and the VERIFY algorithm is executed by the verifier. Witness W is the secret owned by the prover that they do not want to reveal to others and yet wants to prove that they know the secret.

Different ZKP systems are computationally suited to different types of arithmetic circuits, each with distinct characteristics. As a result, various ZKP systems excel in different application domains. For instance, zk-SNARKs are particularly effective at handling arithmetic circuits represented in the Rank-1 Constraint System (R1CS) form; whereas ZKP systems based on sum-check \cite{lund1992algebraic} and GKR \cite{thaler2015note} protocols are more suitable for dealing with arithmetic circuits that exhibit a layered structure. This layered structure of arithmetic circuits is particularly relevant in the context of deep neural network models in machine learning, which typically possess a layered structure. Consequently, many ZKML works targeting deep neural networks leverage sum-check and GKR protocols for enhanced efficiency and performance.

In general, the following two technical advantages of ZKP systems are useful for verifiable machine learning and thus are exploited by ZKML. The VERIFY algorithm can be executed significantly faster than the PROVE algorithm. The VERIFY algorithm does not require access to the private witness. The first advantage enables machine learning clients to save computational resources compared to performing all computations themselves. The second advantage ensures that sensitive information remains protected throughout the entire machine learning process, preventing any disclosure.


%zk-SNARK has the following technical advantages \cite{sun2021survey}. First, the generated proof has a size of just several bytes, the proof can be verified in a short running time, and the PROVE algorithm can be executed in polynomial time (the succinct property). Second, the prover and verifier do not need to communicate synchronously with each other to perform the challenge and response phases; the generated proof is sent to a verifier and can be verified offline (the non-interactive property). In this work, we use zk-SNARK algorithms to implement our scheme.

%In practice, most zero-knowledge proof works for verifiable machine learning are non-interactive, with the Sumcheck protocol and GKR protocol playing significant roles. Particularly in verifying complex computations, the GKR protocol provides a framework for verifying circuit computations, while the Sumcheck protocol is a core tool for handling polynomial computation verification. These protocols are often used to construct zero-knowledge proof works related to verifiable machine learning.

%The Sumcheck protocol \cite{lund1992algebraic} is an interactive proof protocol used to solve the summation problem of a multivariate polynomial \(f : \mathbb{F}^t \rightarrow \mathbb{F} : \sum_{b_1, b_2, ..., b_t \in \{0,1\}} f(b_1, b_2, ..., b_t)\). Direct summation requires \(2^t\) computations based on the combinations of \(b_i\). To efficiently prove the computation process of the polynomial to the verifier \(V\), the prover \(P\) can generate a proof of size \(O(d\ell)\), where \(d\) is the degree of the polynomial \(f\). In the Sumcheck protocol, to allow the verifier \(V\) to evaluate the polynomial at two challenge points, the prover \(P\) ultimately needs to expose the polynomial, which makes it not zero-knowledge. However, Wahby \emph{et al.} \cite{wahby2018doubly} applied zero-knowledge polynomial commitments to hide the polynomial and achieve zero-knowledge properties. Additionally, the interactive challenge process can be replaced by the Fiat-Shamir transformation, making the Sumcheck protocol a non-interactive zero-knowledge proof protocol.

%The GKR protocol \cite{thaler2015note} is also an interactive protocol and an application of the Sumcheck protocol. Its purpose is to allow the prover \(P\) to convince the verifier \(V\) to accept that the output of an arithmetic circuit \(C\) computed over a finite field on some input \(X\) is \(y : C(x) = y\). The core idea of this protocol is to decompose the verification process of the circuit computation results layer by layer: starting from the output layer, when verifying the computation output of a certain layer, it is assumed that the output result of the previous layer is correct. Through this protocol, the verifier \(V\) can verify, with knowledge of the arithmetic circuit \(C\) and input \(X\), with a lower time complexity than directly computing the circuit's output.

\subsection{Verifiable machine learning}\label{ss:2c}
As machine learning continues to address increasingly complex problems, the size and complexity of the models employed have grown significantly. Larger neural networks require more parameters, which in turn leads to higher costs. These costs stem from the need for extensive datasets and substantial computational resources. As a result, high-cost machine learning computations are often accessible only to large institutions. Within the framework of MLaaS, these institutions, acting as ML service providers, perform ML tasks such as model training or inference and subsequently share the results with their clients. 

In this context, it becomes crucial for ML service providers to prove that the shared results were derived from genuine computations rather than being fabricated. This necessity has given rise to the concept of verifiable machine learning. Verifiable machine learning encompasses three primary categories:  \emph{Verifiable Training}, \emph{Verifiable Testing}, and \emph{Verifiable Inference}, as outlined below:




\begin{itemize}
    \item {\bf \emph{Verifiable Training}} ensures the quality of data, the consistency of training algorithms, and the integrity of model parameters throughout the training process. In practice, many individuals and small companies lack the necessary infrastructure to train the machine learning models they require. To address this gap, ML service providers on MLaaS platforms offer model training services, allowing these individuals and small businesses---who act as their ML clients---to outsource their training tasks to the providers on these platforms. In such a setup, the ML service provider undertakes the training process based on the client's specified configuration details, including accuracy thresholds, the number of epochs, and the network architecture. Once the training is complete, the ML service provider provides the company with the trained model in exchange for a fee. However, this arrangement introduces the need for the individuals and small companies to verify that the ML service provider performed the training task faithfully---strictly adhering to the predefined requirements---and that the returned model is genuinely the result of the stated training process.

    \item  {\bf \emph{Verifiable Testing}} involves proving the true performance of a model, ensuring that its claimed performance accurately reflects its generalization ability rather than being limited to its training data. For instance, in verifiable testing on an MLaaS platform, an ML client uploads the target machine learning model along with some test data and specifies the evaluation metrics to be used, such as accuracy or F1 score. The ML service provider then performs the testing as required and generates a detailed test report. To guarantee the authenticity of this process, some encryption techniques and third-party verification tools must be employed to ensure the following: the test data remains unaltered throughout the testing process; the testing adheres strictly to the predefined configuration; and the final testing results accurately reflect the model's true performance.

    \item  {\bf  \emph{Verifiable Inference}} ensures that the claimed inference results are indeed the outputs generated by the specified machine learning model using the provided input data and following the predetermined inference process. For example, an ML client can upload the input data and the designated model to an ML service provider who performs the inference task while preserving the confidentiality of both the data and the model. To maintain authenticity and data privacy, cryptographic techniques like ZKP can be used. These techniques verify the correctness of the inference process and the integrity of the data without revealing sensitive details. The inference results returned by the ML service provider can then be verified to ensure they have not been tampered with and accurately reflect the model's capabilities. This approach allows ML clients to safely and reliably utilize external ML inference services. 
\end{itemize}


\begin{table*}[ht]
\centering
\renewcommand{\arraystretch}{1.5} % Adjust row height
\setlength{\tabcolsep}{7pt} % Adjust column spacing
\caption{Comparison of Security Techniques in Verifiable Machine Learning}

\begin{center}
\begin{tabular}{p{0.22\linewidth} p{0.32\linewidth} p{0.36\linewidth}}
\hline
\textbf{Security Techniques} & \textbf{Advantages in Verifiable Machine Learning} & \textbf{Limitations Compared to ZKP} \\ \hline
DP \cite{dwork2006differential} & Protects training data from inference attacks by introducing statistical noise & The added noise reduces dataset utility, impacting model accuracy and usability \\ 
HE \cite{yi2014homomorphic} & Enables computations on encrypted data, ensuring data privacy & High computational and storage overheads limit scalability and efficiency \\ 
FL \cite{konevcny2016federated} & Allows collaborative training without data sharing, protecting privacy and reducing overall computational costs & Vulnerable to malicious participants providing false data, which can compromise the model \\ 
TEE \cite{sabt2015trusted} & Isolates sensitive computations in a secure environment with integrity and confidentiality guarantees & Unsuitable for tasks requiring extensive computational resources \\ 
SMC \cite{zhao2019secure} & Achieves high computational accuracy without leaking participants' private data; supports general-purpose computations & Computational delay does not scale linearly with the number of participants, affecting efficiency \\ 
\hline
\end{tabular}
\end{center}
\label{tab2}
\end{table*}



\subsection{Comparison of Security Techniques in Verifiable Machine Learning}\label{ss:2d}


Several security techniques, such as Differential Privacy (DP), Homomorphic Encryption (HE), Federated Learning (FL), Trusted Execution Environments (TEE), and Secure Multiparty Computation (SMC), can provide verifiable computation and privacy protection in machine learning to a certain degree. However, when these security techniques are applied to verifiable machine learning, they exhibit certain limitations compared to ZKP. The comparative analysis is presented in Table \ref{tab2} and detailed as follows. 


DP is a highly regarded and rigorous security technique for privacy protection. Initially proposed by Dwork in 2006 \cite{dwork2006differential}, DP operates by adding random noise to query results, ensuring that the presence or absence of any individual in the dataset does not significantly alter the outcome. This approach safeguards individual data privacy. When applied to ML models, DP can protect training data against model inversion attacks. Consequently, numerous studies have explored integrating DP into ML models \cite{dwork2008differential}. However, compared to ZKP, the introduction of random noise can compromise dataset accuracy, potentially affecting both model utility and precision.


HE \cite{yi2014homomorphic} is an encryption technique that enables computations to be performed directly on encrypted data (ciphertexts). The results remain encrypted, and once decrypted, they match the outcomes of the same computations performed on plaintexts. This capability is often referred to as "computable yet invisible" data. HE is categorized into Fully Homomorphic Encryption (FHE) and Partially Homomorphic Encryption (PHE). FHE supports arbitrary computations on ciphertexts, whereas PHE allows only specific operations, such as addition, multiplication, or a limited combination of both. While HE ensures data privacy while maintaining data computability, it faces significant performance challenges, including high computational and storage overhead, especially when compared to ZKP.

FL is a distributed machine learning framework introduced by Google in 2016 \cite{konevcny2016federated,rieke2020future}. It enables collaborative model training while preserving data privacy and ensuring regulatory compliance, thereby enhancing AI model performance. FL addresses the limitations of single-feature data during the training phase and safeguards private data against leakage. Additionally, its distributed architecture reduces overall computational costs. However, FL has a significant vulnerability: it cannot prevent participants from submitting false or malicious data, which can irreparably compromise the final trained model.


TEE \cite{sabt2015trusted} is a secure, independent processing environment with computation and storage capabilities, designed to provide robust security and integrity protection. It utilizes isolated memory to store private data and perform computations, ensuring that only authorized interfaces can access the data. Hardware-based TEE technology is highly efficient and capable of supporting multi-level, complex algorithm logic implementations. However, its reliance on underlying hardware architecture makes it less suitable for tasks requiring high network bandwidth or significant computational resources.

SMC \cite{zhao2019secure} is a cryptographic technique that enables multiple parties to collaboratively achieve computational goals while ensuring that private data remains confidential, except for the computed results and any information inferable from them. SMC offers high computational accuracy and supports programmable, general-purpose computations. Nevertheless, as the number of participants increases, it becomes increasingly difficult to design computational schemes that ensure computation latency scales linearly, posing challenges for large-scale applications.







\section{Research of ZKML} \label{s:3}

In this section, we begin by introducing verifiable machine learning in the context of zero-knowledge proofs, referred to as ZKML. Next, we categorize and analyze the existing research efforts in ZKML. Finally, we discuss the key challenges faced in the development of ZKML, as well as the potential solutions proposed to address these challenges.


\subsection{Introduction of ZKML}\label{ss:3a}
In ZKML, there are two key participants: the ML service provider, acting as the prover in the ZKP system ($P$), and the ML client, serving as the verifier in the ZKP system ($V$). Due to $V$'s limited computational resources or lack of access to the necessary data, it delegates machine learning tasks---including training and inference---to $P$. As a result, the majority of computations in the machine learning workflow are performed by $P$. Meanwhile, $V$ focuses solely on verifying the correctness of the results and the processes used to produce them, ensuring both accuracy and integrity.



Depending on the specific tasks and privacy protection requirements, the prover $P$ and the verifier $V$ may hold different datasets, models, and objectives. Since both parties operate in a trustless environment, $P$ might act dishonestly---for example, by using incorrect data during training or fabricating seemingly valid results---which could severely compromise the learning task's outcome. To address these issues, ZKML is introduced as a means to ensure transparency and trustworthiness in the computational process.


The typical workflow of ZKML is illustrated in Fig.~\ref{f3}. First, the prover $P$ and the verifier $V$ agree on the machine learning task $T$ (i.e., to specify the used model and performance metric, etc.) and input data $D$. The verifier $V$ generates and sends a commitment $c$ to the prover $P$ to confirm the integrity of the committed input data $D$. After verifying the commitment, the prover $P$ generates the proving and verification keys. Subsequently, the prover $P$ executes the machine learning task to obtain the result $r$ while simultaneously using a proving mechanism to generate a proof $\pi$. Finally, the verifier $V$ evaluates the result $r$ and the proof $\pi$ to determine whether the prover $P$ has correctly executed the machine learning task $T$. If the verification of $\pi$ is successful, the verifier $V$ concludes that the prover $P$ has honestly performed the task $T$ based on the input data $D$, producing the correct result $r$. Otherwise, the verifier $V$ rejects the result.


\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{pic3.png}
    %\includegraphics[width=\linewidth]{pic3.eps}
    \caption{The typical workflow of ZKML.}
    \label{f3}
    % \vspace{-13pt}
\end{figure}


In a ZKP system, the statement to be proven (e.g., verifying that a computation was performed correctly or that a secret satisfies certain conditions) is encoded as a computation. This computation is typically represented as an arithmetic circuit, which processes public inputs and private witnesses through a sequence of arithmetic operations to generate an output. In this paper, we exploits conceptual diagrams to  depict the designs of the arithmetic circuits for the three categories of ZKML. These diagrams highlight three primary components: circuit input, circuit logic, and circuit output. The configuration of these components---circuit input, circuit logic, and circuit output---varies across the three categories of ZKP-based verifiable machine learning, as described below.


\subsubsection{\bf ZKP based Verifiable Training} Fig.~\ref{f5} presents the conceptual diagram of the arithmetic circuits used in ZKP-based verifiable training. Below, we detail the components of this diagram. 

\begin{itemize}


\item {Circuit Input}: The inputs to the circuit in ZKP-based verifiable training include both private witness and public input. The private witness encompasses the training data, the labels of the training data. The public input consists of the hash of the training data, the hash of the training data labels, the threshold of the model training loss and the proving key necessary to generate zero-knowledge proofs.\footnote{The hashes used in the inputs serve as commitments to the corresponding data. Alternatively, other cryptographic commitment schemes compatible with ZKP can also be utilized.}

\item {Circuit Logic}: The circuit executes several essential computational tasks to enable verifiable training. First, it computes the hashes of the training data and their corresponding labels that given in the private witness, then compares these computed hashes with those provided in the public input. If the hashes match, the computation proceeds; otherwise, it terminates. Next, the circuit generates model inference outputs using the training data as inputs to the model. It then calculates the training loss by comparing the inferred outputs with the true labels of the training data. This training loss is evaluated against a predetermined threshold. If the loss exceeds the threshold, the circuit computes gradients and updates the model parameters accordingly; otherwise, the training process halts. Throughout this process, all computations are integrated with the proving key to produce a zero-knowledge proof, ensuring the integrity and confidentiality of the entire computation process.

\item {Circuit Output}: The output includes the hash of the updated model parameters after training and the generated zero-knowledge proof. 

\end{itemize}

This circuit design enables the verification of each step in the training process according to the defined algorithms and procedures, without revealing sensitive information such as the training data and the trained model parameters. Consequently, it ensures the transparency and trustworthiness of the training process while preserving data and model privacy. 



\begin{figure*}[!t]
    \centering
    \includegraphics[width=0.75\linewidth]{fig5.png}
    %\includegraphics[width=\linewidth]{pic5.eps}
    \caption{Conceptual diagram of the arithmetic circuits used in ZKP-based verifiable training.}
    \label{f5}
\end{figure*}


\subsubsection{\bf ZKP based Verifiable Testing} Fig.~\ref{f6} presents the conceptual diagram of the arithmetic circuits used in ZKP-based verifiable testing. Below, we detail the components of this diagram. 



\begin{itemize}


\item {Circuit Input}: Within the input to the circuit, the private witness includes the model parameters; the public input consists of the the testing data and their corresponding labels, the hash of the model parameters, the threshold of the model testing performance and the proving key necessary to generate zero-knowledge proofs.

\item {Circuit Logic}: The circuit performs several key computational tasks for verifiable testing. First, it computes the hash of the model parameters, then compares the computed hash with the hash provided in the public input. If the hashes match, the computation proceeds; otherwise, it terminates. After that, it computes the model inference outputs using the testing data as the inputs to the model with the model parameters. Next, it calculates the model testing performance by comparing the inferred outputs with the true labels of the testing data. This computed model testing performance is then evaluated against a predetermined performance threshold. If the performance exceeds the threshold, a zero-knowledge proof for this result is generated using the proving key.

\item {Circuit Output}: The output includes the testing performance of the model and the generated zero-knowledge proof. 


\end{itemize}

This circuit design of ZKP-based verifiable testing ensures that
the model testing performance is within a certain range, meanwhile the privacy of the model parameters is protected. 



\begin{figure*}[!t]
    \centering
    \includegraphics[width=0.75\linewidth]{fig6.png}
    \caption{Conceptual diagram of the arithmetic circuits used in ZKP-based verifiable testing.}
    \label{f6}
\end{figure*}




\subsubsection{\bf ZKP-based Verifiable Inference} Fig.~\ref{f7} presents the conceptual diagram of the arithmetic circuits used in ZKP-based verifiable inference. Below, we detail the components of this diagram.

\begin{itemize}

\item {Circuit Input}: The inputs to the circuit in ZKP-based verifiable inference include both private witness and public input. The private witness comprises the model parameters. The public input includes the hash of the model parameters, the data used for model inference, and the proof key required for generating the zero-knowledge proof.

\item {Circuit Logic}: The circuit performs several critical computational tasks for verifiable inference. It first computes the hash of the model parameters, then compares the computed hash with the hash provided in the public input. If the hashes match, the computation proceeds; otherwise, it terminates. Then, it computes the inferred outputs by applying the model parameters to the input data. Simultaneously, the proof key is utilized to generate a zero-knowledge proof of the correctness of the inference computation. 

\item {Circuit Output}: The output consists of the inference results for the input data and the generated zero-knowledge proof. 

\end{itemize}

This circuit design ensures that the inference process adheres to the defined algorithms and procedures, allowing for verification of correctness without exposing sensitive information (i.e., the model parameters). Consequently, it upholds the privacy of the model parameters  while maintaining the integrity and trustworthiness of the inference results.

\begin{figure*}[t]
    \centering
    \includegraphics[width=0.75\linewidth]{fig7.png}
    \caption{Conceptual diagram of the arithmetic circuits used in ZKP-based verifiable inference.}
    \label{f7}
\end{figure*}





Based on the  conceptual diagrams of the arithmetic circuits, we can intuitively illustrate how the objectives of the three categories of ZKML are achieved using ZKP. In the following part of this section, we classify existing ZKML studies into these three categories and analyze them individually.











\subsection{Discussion of Existing ZKML Studies} \label{ss:3b}

Since its inception in 2017, research in ZKML has progressed rapidly, with a significant body of work emerging by 2024. Fig.~\ref{f4} presents a timeline of representative studies, highlighting the advancements and evolution in this field. These studies can be categorized into the three primary categories of verifiable machine learning (i.e., verifiable training, verifiable testing, and verifiable inference) based on the stages of the machine learning process and their verification objectives. The detailed classifications and corresponding research outcomes are summarized in Table~\ref{tab3}. In the following, we examine the works of each category in depth, analyzing the design principles, implementation methodologies, and application scenarios of various approaches. This discussion aims to shed light on how these methods enhance the security and trustworthiness of machine learning tasks. 









\subsubsection{\bf ZKP based Verifiable Training} \label{sss:3a}


In 2021, Zhao \emph{et al.} proposed VeriML \cite{zhao2021veriml}, whose core idea is to make the training process retrievable to achieve verifiability in machine learning training. VeriML pre-stores the inputs and outputs of several iterations during the training process and commits to them, allowing the prover to retrieve specified iterations upon the verifier's request and generate proofs of their computational processes. VeriML supports six typical machine learning models, including linear regression, logistic regression, neural networks, SVM, K-Means, and decision trees. Also, VeriML's computational and communication costs are justified through numerous experiments. Experimental results demonstrate that the communication overhead of VeriML is related to the number of iterations and the number of data samples, and the computational overhead of VeriML is dominated by the batch size of data samples and increases linearly with the batch size.

Zhang \emph{et al.} introduced Hydra \cite{zhang2021hydra}, a verifiable training protocol for neural networks built upon the GKR protocol. This system is specifically tailored for neural networks and builds upon the SafetyNets method---the first verifiable inference approach leveraging ZKP, which will be discussed later. In particular, Hydra uses SafetyNets to represent a neural network as an arithmetic circuit. To achieve verifiable training, Hydra introduces a subcircuit protocol and a  interactive quantization algorithm. The execution process of Hydra's subcircuit protocol can be summarized as follows: First, the large and deep circuit representing a neural network is partitioned into multiple smaller sub-circuits by depth. The prover then applies the GKR protocol to generate proofs for each sub-circuit. Once a proof for a sub-circuit is generated, it is immediately transmitted to the verifier for verification. Finally, all proofs corresponding to the sub-circuits are aggregated into a single final proof for the entire circuit, which is sent to the verifier for verification. This pipelined approach enables the proof-and-verification process to begin as soon as sub-circuits are uploaded, eliminating the need to process the entire circuit at once. By overlapping proof generation and verification, Hydra significantly enhances verification efficiency. Hydra's interactive quantization algorithm begins by rounding the weights of the bottom layers of the neural network, freezing these quantized layers, and retraining the network. This process is then repeated layer by layer, progressively moving upward, until all layers have been quantized. This interactive quantization algorithm is executed for the each part of the neural network corresponding to each sub-circuit in the pipelined proof-and-verification process. 



\begin{figure*}[!t]
    \centering
    \includegraphics[width=0.75\linewidth]{timeline2.pdf}
    %\includegraphics[width=\linewidth]{pic4.eps}
    \caption{A timeline of representative existing ZKML studies.}
    \label{f4}
\end{figure*}

Huang \emph{et al.} proposed zkMLaaS \cite{huang2022zkmlaas}, a framework that employs a two-round challenge-response protocol and random sampling of model weights to generate proofs. This approach reduces the time cost of proof generation while ensuring the verifiable integrity of the training process. Prior to executing the challenge-response protocol, an honest third party (or the ML client) generates a key pair (PK,VK), distributing PK to the ML service provider (the prover) and VK to the ML client (the verifier). In the first round of the challenge-response protocol, the ML service provider submits commitments for all intermediate weights updated during each training iteration and data sampling epoch to the ML client. In the second round, the ML client randomly selects a subset of the intermediate weights, and the ML service provider is required to generate corresponding proofs for them. The zkMLaaS framework leverages zk-SNARKs and commitment schemes to ensure security. The binding property of the commitment scheme guarantees that the ML service provider cannot produce two different sets of weights corresponding to the same commitment. Furthermore, since the public key is generated by the client or a trusted third party, the service provider is restricted to generating proofs only for the circuits specified by the client. This ensures that the intermediate weights are derived solely from the correct model and data.



zkDL \cite{sun2023zkdl} is an efficient ZKML system designed for the verifiable training of deep neural networks. To address the non-arithmetic nature of ReLU activation functions in neural networks, zkDL introduces the zkReLU protocol, which facilitates proving computations involving ReLU. The zkReLU protocol leverages auxiliary inputs to transform the nonlinear computations of ReLU into an equivalent linear form, enabling efficient handling of forward and backward propagations through ReLU. To ensure the validity of these auxiliary inputs, zkReLU employs the Pedersen commitment scheme and incorporates an anchoring mechanism that links the arithmetic operations within each layer to the auxiliary inputs. This design not only preserves the tensor structure inherent in deep neural networks but also significantly reduces computational redundancy by reusing verified commitments. For circuit design in the training of deep neural networks, zkDL proposes FAC4DNN (Flat Arithmetic Circuit for Deep Neural Networks), which parallelizes the traditionally sequential execution of neural network layers and training iterations. This approach effectively flattens the circuit, reducing its depth by a factor of $O(N)$, where $N$ is the product of the neural network depth and the number of training iterations. zkDL implements a three-step parallel proof process for FAC4DNN: (1) parallel execution of the GKR protocol for each layer, (2) parallel proof of inter-layer arithmetic relationships, and (3) parallel verification of auxiliary inputs. This design ensures that the proof size grows only by $O(\log L)$, where $L$ is the product of the neural network depth. Compared to traditional sequential proof generation, zkReLU's parallel proof generation offers significant time efficiency. It shows in \cite{sun2023zkdl} that the proof generation of zkDL for the entire forward and backward propagation of the neural network training process to be completed within tens of seconds for neural networks with 10 millions parameters.



Grag \emph{et al.} \cite{garg2023experimenting} proposed the concept of Zero-Knowledge Proof of Training (zkPoT), aiming to strike a balance between proof size and computation time. zkPoT is a novel and efficient zero-knowledge proof generation framework that combines two types of zero-knowledge proof techniques: arithmetic and non-arithmetic operations. By carefully integrating these techniques, zkPoT seeks to overcome the limitations of existing methods, ensuring that the proof size grows linearly with the number of the data in the dataset but remains independent of the number of data features. Moreover, this framework does not require the entire computation process to be stored in main memory (RAM) during proof generation, as it can load data from auxiliary memory when needed. Consequently, this approach imposes no fundamental memory limitations on the model size or dataset during training, making it more compatible with machine learning training tasks.

\begin{table*}[t]
    \caption{Classification of Existing ZKML Approaches}
    \centering
    \begin{tabular}{l c l c c c}
        \hline
        \textbf{Research Works} & \textbf{Time} & \textbf{Application} & \textbf{Verifiable Training} & \textbf{Verifiable Testing} & \textbf{Verifiable Inferring} \\ 
        \hline
        SafetyNets\cite{ghodsi2017safetynets} & 2017.6 & DNN & $\circ$ & $\circ$  & $\bullet$  \\ \hline
        Drynx\cite{froelicher2020drynx} & 2020.3 & Regression models & $\circ$ & $\circ$ & $\bullet$  \\ \hline
        ZKDT\cite{zhang2020zero} & 2020.10 & DT & $\circ$ & $\bullet$ & $\circ$  \\ \hline
        vCNN\cite{lee2024vcnn} & 2020.12 & CNN & $\circ$ & $\circ$ & $\bullet$  \\ \hline
        ZEN\cite{feng2021zen} & 2021.5 & NN &  $\circ$   & $\bullet$  & $\circ$ \\ \hline
        Mystique\cite{weng2021mystique} & 2021.8 & NN & $\circ$ & $\circ$ & $\bullet$  \\ \hline
        VeriML\cite{zhao2021veriml} & 2021.10 & Six models & $\bullet$  & $\circ$ & $\circ$\\ \hline
        zkCNN\cite{liu2021zkcnn} & 2021.11 & CNN & $\circ$ & $\bullet$ & $\circ$  \\ \hline
        Hydra\cite{zhang2021hydra} & 2021.12 & NN & $\bullet$  & $\circ$  & $\circ$ \\ \hline
        Kang\cite{kang2022scaling} & 2022.10 & MobileNet v2 & $\circ$ & $\circ$ & $\bullet$  \\ \hline
        Singh\cite{singh2022zero} & 2022.10 & DT & $\circ$ & $\circ$ & $\bullet$ \\ \hline
        zkMLaaS\cite{huang2022zkmlaas} & 2022.12 & ML & $\bullet$  & $\circ$ & $\circ$  \\ \hline
        ezDPS\cite{wang2022ezdps} & 2022.12 & ML Pipeline & $\circ$ & $\circ$ & $\bullet$ \\ \hline
        pvCNN\cite{weng2023pvcnn} & 2023.3 & CNN & $\circ$  & $\bullet$  & $\circ$  \\ \hline
        Fan\cite{fan2023validating} & 2023.5 & CNN & $\circ$    & $\circ$  & $\bullet$  \\ \hline
        ZKDL\cite{sun2023zkdl} & 2023.7 & DNN & $\bullet$ & $\circ$   &  $\circ$    \\ \hline
        ZKPoT\cite{garg2023experimenting} & 2023.9 & LogR & $\bullet$  & $\circ$   &  $\circ$  \\ \hline
        South\cite{ganescu2024trust} & 2024.2 & ML & $\circ$    & $\circ$  & $\bullet$  \\ \hline
        Lookup arguments\cite{campanelli2024lookup} & 2024.4 & DT & $\circ$   &  $\bullet$  &  $\circ$   \\ \hline
        ZKML\cite{chen2024zkml} & 2024.4 & ML & $\circ$    & $\circ$   & $\bullet$ \\ \hline
        zkLLM\cite{sun2024zkllm} & 2024.4 & LLM & $\circ$    & $\circ$ & $\bullet$  \\ \hline
        Lu\cite{lu2024efficient} & 2024.5 & NN & $\circ$    & $\circ$   & $\bullet$  \\ \hline
        SpaGKR\cite{li2024sparsity} & 2024.6 & ML & $\circ$     & $\circ$ & $\bullet$   \\ \hline
        Kaizen\cite{abbaszadeh2024zero} & 2024.7 & DNN & $\bullet$  & $\circ$   & $\circ$   \\ \hline
        Hao\cite{hao2024scalable} & 2024.8 & ML & $\circ$   &  $\circ$ & $\bullet$ \\ \hline
        Artemis \cite{lycklama2024artemis}    & 2024.9 & ML & $\circ$  & $\bullet$ &  $\circ$  \\ \hline
        Zhan \cite{zhan2024validating}   & 2024.11 & CNN & $\circ$  & $\circ$  &  $\bullet$  \\ \hline
    \end{tabular}%
    \label{tab3}
\end{table*}



Since the zkPoT framework developed by Garg \emph{et al.} \cite{garg2023experimenting} only supports basic machine learning algorithms, such as logistic regression, and does not extend to deep neural networks, Kasra \emph{et al.} \cite{abbaszadeh2024zero} proposed an efficient and concise zkPoT technique designed specifically for training DNN models using multiple small-batch gradient descent algorithms. Their work focuses on two key components: an optimized proof system for gradient descent iterations and a framework for efficient recursive proof composition across multiple iterations. First, Kasra \emph{et al.} introduced an optimized GKR-style proof system (based on the sumcheck protocol) tailored for the gradient descent algorithm, enabling the verification of the correctness of computations in each iteration. Next, they developed a method to combine multiple proofs into a single, smaller proof, which can verify the correctness of results across multiple iterations, thereby achieving conciseness. Additionally, the authors proposed a general framework that integrates multiple proofs with polynomial commitments to produce a compact proof and commitment, significantly enhancing the efficiency of both proof generation and verification.

\subsubsection{\bf ZKP based Verifiable Testing}\label{sss:3b}



In 2020, Zhang \emph{et al.} proposed a ZKML protocol for verifiable inference and accuracy testing of decision trees, named zkDT \cite{zhang2020zero}. zkDT enables the owner of a decision tree model to convince others of the model's inference results on data samples or its accuracy on public datasets, all without revealing any information about the model itself. The protocol leverages the Aurora protocol \cite{ben2019aurora} as the ZKP backend due to Aurora's fast proving time, which is a desirable feature for large decision trees. zkDT significantly improves the efficiency of proving time by transforming the computation of decision tree inference into a circuit of size $O(d + h)$, where $d$ is the length of the inference path on the tree, and $h$ is the number of data features. Notably, many testing data samples share common nodes on the decision tree. To exploit this, zkDT optimizes the proof and verification process for decision tree accuracy testing by validating all the nodes of the inference paths across all testing data in a single step, rather than validating the inference path of each sample individually. The implementation of zkDT demonstrates its practicality. For a decision tree with 23 levels and 1029 nodes, and a test dataset consisting of 5000 data samples with 54 features each, zkDT takes 250 seconds to generate a proof of size 287 KB for accuracy testing, and 15.6 seconds for verification.


Campanelli \emph{et al.} \cite{campanelli2024lookup} proposed a novel lookup argument and demonstrated how it can significantly improve upon the zkDT framework introduced in \cite{zhang2020zero}. Lookup arguments allow one to prove that the elements of a committed vector originate from a larger committed table. This enables innovative approaches to reduce the prover complexity of general-purpose zk-SNARKs, particularly for implementing ``non-arithmetic operations'' such as range checks, XOR, and AND more efficiently. The authors make several key advancements in lookup arguments: (1) They extend vector lookups to matrix lookups, allowing proof that a committed matrix is a submatrix of a committed table.
(2) They introduce a concept that ensures the privacy of both the sub-vector/sub-matrix and the table. (3) They propose new zero-knowledge lookup arguments, namely cq+, zkcq+, and cq++, which are more efficient than the recent work by Eagen, Fiore, and Gabizon, referred to as cq \cite{eagen2022cq}. Furthermore, they present an application of fully zero-knowledge matrix lookup arguments to zkDT. Using matrix lookup arguments, one can commit to a decision tree by encoding it as a matrix, and to prove correct evaluation, the prover commits to the single row corresponding to the correct leaf. They can then prove, using the matrix lookup argument, that the committed row is indeed a leaf of the committed decision tree. Once the relevant row is isolated, the prover can then demonstrate that the input vector satisfies all the constraints outlined by that row. For statements involving multiple input vectors, rather than committing to a single row, the prover can commit to a matrix whose rows correspond to the entries of the leaves reached by the evaluations. Thanks to the efficiency of the matrix lookup argument, the prover's time complexity remains independent of the size of the decision tree.


pvCNN \cite{weng2023pvcnn} is a framework designed for the verifiable testing of convolutional neural networks (CNNs), developed by integrating fully homomorphic encryption, zk-SNARKs, and collaborative inference. The implementation of pvCNN can be summarized in three key steps. (1) pvCNN constructs a Quadratic Matrix Programs (QMP) based arithmetic circuit, which significantly reduces the number of multiplication gates required for convolution operations. This reduction minimizes the circuit size and enhances proof efficiency. Within this circuit, each multiplication gate represents the two-dimensional convolution operation between multiple filters and input data in a batch-processing manner. This design enables pvCNN to achieve zk-SNARK proof aggregation, allowing for the batch verification of multiple proofs. (2) pvCNN aggregates multiple proofs corresponding to test data provided by different testers for the same CNN model into a single proof. The validity of the aggregated proof guarantees the correctness of the original individual proofs, thereby improving verification efficiency. (3) The CNN model is divided into two parts: a private part, retained locally by the model developer, and a public part, outsourced to an external server. The private part processes test data encrypted via homomorphic encryption, as provided by the tester, and transmits its output to the public part to complete subsequent computations for CNN testing. This partitioning mechanism ensures privacy protection while enabling efficient inference verification. Through these steps, the pvCNN framework achieves efficient verification of neural network inference results from multiple testers while preserving data privacy. Experimental results demonstrate that, for high-dimensional matrix multiplication, pvCNN achieves a proof generation time that is approximately 13.9 times faster and a setup time that is 17.6 times faster than existing zk-SNARKs based on Quadratic Arithmetic Programs (QAP). Moreover, pvCNN overcomes the limitations of QAP-based zk-SNARKs in handling a bounded number of multiplication operations.


Feng \emph{et al.}  \cite{feng2021zen} proposed the first optimizing compiler for verifiable neural networks using zero-knowledge proofs, named ZEN. ZEN consists of two schemes: ZENacc and ZENinfer. ZENacc proves the accuracy of a committed neural network model, while ZENinfer proves a specific inference result. Together, these schemes ensure both the privacy of user data and the confidentiality of neural network models. To address the computational costs associated with zk-SNARKs, ZEN introduces two optimization algorithms. First, ZEN incorporates a novel neural quantization algorithm that applies two R1CS-friendly optimizations: sign-bit grouping and remainder-based verification. These optimizations enhance the efficiency of converting a floating-point neural network into a fully quantized model expressed in R1CS. As a result, compared to state-of-the-art quantization schemes, ZEN achieves up to 73.9x savings in R1CS constraints for convolution kernels and up to 8.4x reduction for fully connected kernels, all without incurring any additional accuracy loss. Second, ZEN introduces a Single Instruction Multiple Data (SIMD) style optimization, known as stranded encoding. This method optimally encodes multiple low-precision integers (8-bit) with a single finite field element (typically 254-bit). Feng et al. also developed an open-source toolchain that takes a floating-point PyTorch model and converts it into ZEN schemes with all of the aforementioned optimizations. Their evaluation demonstrates that, without any accuracy loss, ZEN provides savings in the number of constraints ranging from 5.43x to 22.19x, with an average reduction of 15.35x, when compared to a vanilla implementation of neural network models in zk-SNARKs.


%Feng \emph{et al.}  proposed ZEN \cite{feng2021zen}, the first optimized compiler capable of generating efficient verifiable zero-knowledge neural network execution works. ZEN uses the Groth16 scheme\cite{angel2022efficient} implemented through the arkworks library in zero-knowledge proofs, which can compile floating-point PyTorch models into R1CS constraints. ZEN has two important components: R1CS-friendly quantization and R1CS constraint encoding. The quantization algorithm converts floating-point neural networks into fully quantized models to be expressed in R1CS. Based on these optimization methods,  ZEN can reduce R1CS constraints by 5.43-22.19 times compared to the ordinary implementation of neural network models in zk-SNARK, without any additional accuracy loss.

Liu \textit{et al.}~\cite{liu2021zkcnn} proposed a scheme for Convolutional Neural Networks (CNNs), called zkCNN, which enables the verification of a model's inference for a given input data without revealing the model's parameters. This scheme can also be generalized to prove the model's accuracy on a public dataset while ensuring that the model's parameters remain private. zkCNN incorporates a new sumcheck protocol for two-dimensional convolutions, achieving a prover time of $O(n^2)$ for two input matrices of sizes $n \times n$ and $w \times w$. This is even faster than computing the result directly, making it asymptotically optimal. The proof size is $O(\log n)$. A key component of this protocol is an efficient sumcheck for the Fast Fourier Transform (FFT), which requires only $O(N)$ time to generate the proof for a vector of size $N$, offering a better asymptotic complexity than the conventional $O(N \log N)$ needed for FFT computation. Building upon this, the authors further propose a protocol that achieves a sublinear verifier time of $O(\log^2 n)$ with a proof size of $O(\log^2 n)$. Additionally, they design an interactive proof using the Generalized Knowledge Representation protocol for CNN predictions, including verification of the convolutional layers, ReLU activation functions, and max pooling operations. They introduce generalized addition and multiplication gates, which allow operations with fan-in greater than two, enabling inner products to be implemented with a single sumcheck. By extending these gates to accept inputs from any layer, they avoid additional prover time. For CNN convolutional layers, they optimize the sumcheck protocol by reducing the prover time for the inverse FFT (IFFT) by a factor corresponding to the number of input channels. They also design an efficient circuit gadget that combines the computation of the ReLU activation and max pooling functions, requiring only a single bit-decomposition per number. The proposed scheme supports large CNNs like VGG16, which has 15 million parameters and 16 layers, significantly improving the proof generation time to 88.3 seconds---1264 times faster than existing schemes. The proof size is 341 kilobytes, and the verifier time is only 59.3 milliseconds. Furthermore, the scheme can scale to prove the accuracy of the same CNN on 20 images.



Recent advancements in ZKML often underestimate the substantial overhead involved in verifying the necessary commitments to both the model and the data. This challenge becomes particularly pronounced in scenarios such as verifiable testing, where executing the model on larger datasets is required. To address this gap, Ycklama \emph{et al.} \cite{lycklama2024artemis} proposed a novel approach for constructing efficient Commit-and-Prove SNARKs (CP-SNARKs) that minimizes the computational burden within the SNARK and extends the underlying proof system in a highly efficient manner. Specifically, they introduce two new CP-SNARK constructions---Apollo and Artemis---that effectively address the emerging challenge of commitment verification in zkML pipelines. Apollo operates on KZG commitments and requires white-box use of the underlying proof system, while Artemis is compatible with any homomorphic polynomial commitment and utilizes only black-box access to the proof system. Apollo simplifies the construction process by eliminating the need for shifting proofs, drastically reducing the number of linking proof instances. This optimization allows Apollo to achieve a 7.3x improvement in prover time compared to Lunar \cite{ campanelli2021lunar}. For instance, when performing an inference proof for MobileNet \cite{ sandler2018mobilenetv2}, Lunar requires 20 shifting and 20 linking proofs, whereas Apollo requires just one linking proof. However, Apollo inherits the trusted setup requirement from Lunar. In contrast, Artemis requires only black-box use of the underlying SNARK and supports any homomorphic polynomial commitment, enabling it to work with modern proof systems such as Halo2 with IPA-based commitments, which do not require a trusted setup. The paper also presents the first implementation of Lunar's CP-SNARK, alongside the implementations of the Apollo and Artemis constructions, all of which are made publicly available as open-source software. The evaluation demonstrates that Apollo and Artemis significantly outperform existing approaches across a range of ML models, improving the state of the art by an order of magnitude. Additionally, the evaluation shows that Artemis, when used without a trusted setup, achieves performance that is effectively the same as Apollo (and Artemis) with a trusted setup.


\subsubsection{\bf ZKP based Verifiable Inference}\label{sss:3c}


The earliest scheme for verifiable inference based on ZKP is SafetyNets \cite{ghodsi2017safetynets}, proposed in 2017. This approach enables verifiable inference of deep neural networks on untrusted cloud servers. Noting  that the hierarchical structure of the GKR protocol aligns almost perfectly with the architecture of multi-layer neural networks, SafetyNets combines the GKR protocol with an interactive proof protocol for matrix multiplication \cite{cormode2011verifying}, achieving end-to-end verifiability while significantly reducing bandwidth costs. To address the challenge of nonlinear computations in neural networks, which cannot be easily represented in arithmetic circuits and handled by the proof protocol, SafetyNets restricts its support to specific quadratic activation functions and sum pooling operations. However, this limitation reduces the generality of the technique. Although SafetyNets does not provide zero-knowledge properties, privacy is not a concern in this context, as both the input and the model are supplied by the verifier.

In 2020, Froelicher \emph{et al.} \cite{froelicher2020drynx} proposed a decentralized ZKML system named Drynx that combines interactive protocols, homomorphic encryption, zero-knowledge proofs, and differential privacy technologies, enabling privacy-preserving statistical queries (inferences) and training and evaluation of logistic regression models on distributed datasets. The Drynx system consists of four main components: the querier (Q), data providers (DPs), computation nodes (CNs), and verification nodes (VNs). Within the system's interaction protocol, Q initiates a query request, after which the DPs encrypt their raw data using homomorphic encryption techniques and transmit the encrypted responses to the CNs. The CNs aggregate and process the received encrypted data collectively, generating both the query results and corresponding zero-knowledge proofs to ensure the correctness of the computation process. The VNs are responsible for verifying the correctness of the computations. Through this interaction protocol, Drynx effectively guarantees the transparency and verifiability of query execution. Even under a strong adversarial model with malicious entities, the system ensures the correctness of the computation results. Drynx employs Camenisch-Stadler ZKP \cite{camenisch1997proof} to verify the computational integrity of CNs, and Camenisch-Chaabouni ZKP \cite{chaabouni2007efficient} to validate the range of input data, ensuring that the data provided by DPs falls within legitimate bounds. CNs generate zero-knowledge proofs upon completing calculations, while VNs collectively verify these proofs to ensure the accuracy of computational results, with verification results stored on the blockchain to achieve computational process auditability. Additionally, the Drynx system implements differential privacy protection based on the Collective Differential Privacy (CDP) protocol introduced in Unlynx \cite{froelicher2017unlynx}, effectively protecting individual privacy by adding noise to query results.


vCNN \cite{lee2024vcnn} is a verifiable inference framework specifically designed to accelerate the proof process for convolutional neural networks (CNNs). In CNNs, the output of a convolutional operation is represented as a sum of products: $y_i = \sum\nolimits_{j = 1}^{l - 0} {a_j \cdot x_{l - 1 - j}}$, where \(y_i\) is the \(i\)-th convolutional output, \(\left( x_i, \cdots, x_{i+l-1} \right)\) is the \(i\)-th input data vector of length \(l\), and \(\left( a_0, \cdots, a_{n-1} \right)\) is the convolutional kernel vector of length \(n\). The number of multiplications involved in a convolutional operation is \(O(ln)\), which is often computationally expensive. Consequently, traditional zk-SNARKs incur significant proving time when verifying these multiplications. To address this challenge, vCNN introduces a novel approach to reduce the cost of proving CNN convolutional operations by transforming the sum of products into a product of sums: $\left( \sum\nolimits_{i = 1}^{n + l - 2} y_i \right) = \left( \sum\nolimits_{i = 0}^{n - 1} x_i \right) \left( \sum\nolimits_{i = 0}^{l - 1} a_i \right)$. However, this transformation introduces a potential issue: multiple different values of \(y_i^\prime \neq y_i\) can satisfy the above equality if \(\sum\nolimits_{i = 1}^{n + l - 2} y_i^\prime = \sum\nolimits_{i = 1}^{n + l - 2} y_i\). To prevent such ambiguities, an indeterminate variable \(Z\) is introduced, ensuring that the following equality holds for all \(Z\): $\left( \sum\nolimits_{i = 1}^{n + l - 2} y_i Z^i \right) = \left( \sum\nolimits_{i = 0}^{n - 1} x_i Z^i \right) \left( \sum\nolimits_{i = 0}^{l - 1} a_i Z^i \right)$. This equality corresponds to a polynomial multiplication: $y(Z) = x(Z) \cdot a(Z)$, where \(y(Z)\), \(x(Z)\), and \(a(Z)\) are polynomials. The verifiability of this transformation can be encoded using quadratic polynomial programs (QPPs) \cite{kosba2014trueset}, reducing the proving cost from \(O(ln)\) to \(O(n + l)\) when \(n\) and \(l\) take practical values. This reduction in complexity enables vCNN to significantly improve the proving time for CNN inference compared to traditional zk-SNARKs based on quadratic arithmetic programs (QAPs) \cite{burkard1984quadratic}. Experimental results demonstrate the effectiveness of vCNN. On the simple MNIST dataset, vCNN improves proof performance by a factor of 20. For the more complex VGG16 model \cite{simonyan2014very}, it achieves an improvement of 18,000 times.


Due to the lack of efficient ZKP protocols capable of verifying the inference results produced by the complex computations of neural networks, Weng \emph{et al.} \cite{weng2021mystique} proposed Mystique. This system is built upon the subfield vector oblivious linear evaluation (sVOLE) \cite{yang2021quicksilver} interactive proof protocol. The work introduces three main contributions. (1) Mystique provides a set of efficient ZKP building blocks tailored for implementing inference in large-scale neural networks. These building blocks enable developers to construct ZKML systems with ease, abstracting away the complexities of the underlying cryptographic logic. (2) Three optimized ZKP protocols are proposed to address various challenges: (i) A novel protocol for efficient conversion between arithmetic and Boolean values, which enhances performance by adapting the circuit to specific computational requirements; (ii) A protocol for efficient conversion between public commitments and private authenticated values, facilitating the seamless integration of publicly committed values into ZKP systems; (iii) A protocol for efficient conversion between fixed-point and floating-point numbers, resolving the inconsistency between floating-point representations used in machine learning algorithms and fixed-point representations used in cryptographic computations. (3) Mystique introduces an optimized zero-knowledge proof protocol for matrix multiplication, achieving sublinear private multiplications relative to the size of the matrix. This significantly improves computational efficiency for matrix-related operations in ZKP systems.


Singh \emph{et al.} proposed a zero-knowledge verifiable scheme for a distributed AI pipeline, which includes a privacy-preserving verification protocol for the inference using decision trees \cite{singh2022zero}. The distributed AI pipeline assigns different stages of the process---such as data collection, model training, and model inference---to independent participants, including data owners, model owners, and model users. However, previous approaches faced significant inefficiencies in handling memory within the circuit. To overcome this limitation, the authors introduced an improved protocol for the privacy-preserving verifiable inference using decision trees. By eliminating the need for expensive one-time hash operations on the tree structure, the size of the verification circuit was reduced by up to tenfold. Additionally, the protocol leverages read-only memory access to further optimize performance, significantly reducing the number of multiplication gates required per prediction. Experimental results demonstrate that, compared to zkDT---a similar scheme designed for the verification of decision tree inference---the proposed protocol achieves substantial improvements in efficiency, with its circuit size being only $25\%$ to $40\%$ of zkDT.

In December 2022, Wang \emph{et al.} proposed ezDPS \cite{wang2022ezdps}, an efficient machine learning inference pipeline (MLIP) designed to process data across multiple stages at the ML service provider's end. The pipeline enables the service provider, who supplies the ML model, to compute the final inference result for the client, who provides the input data, while safeguarding the private model parameters at each stage. After committing to its private model, the ezDPS MLIP operates through three key processing stages: (i) utilizing discrete wavelet transform (DWT) for initial data transformation; (ii) applying principal component analysis (PCA) to reduce dimensionality and extract essential features; (iii) performing classification using support vector machines (SVM). The framework employs Hyrax \cite{wahby2018doubly} as the underlying polynomial commitment scheme and Spartan \cite{setty2020spartan} as the backend zero-knowledge proof (ZKP) protocol to verify computations across these stages. Furthermore, ezDPS introduces the concept of zero-knowledge proof of accuracy (zkPoA), which allows the ML service provider to prove the accuracy of the committed model on public datasets without revealing the model parameters. However, a notable limitation of this approach is its inability to preserve client data privacy. Specifically, clients must send their input data in plaintext to the ezDPS platform for computation, potentially exposing sensitive information. 


Kang \emph{et al.} \cite{kang2022scaling} leveraged the Halo2 ZKP scheme \cite{halo2book} to construct a zk-SNARK arithmetic circuit capable of supporting the MobileNet v2 model \cite{sandler2018mobilenetv2}. In contrast to prior works that primarily targeted small-scale datasets (e.g., MNIST or CIFAR-10) with simpler models, this study demonstrates that zk-SNARKs can effectively handle real-world, large-scale neural network models. Specifically, it supports MobileNet v2, a model trained and evaluated on the large-scale ImageNet dataset---a widely used computer vision benchmark comprising over 1 million high-resolution images across 1,000 categories. This work primarily addresses the computational overhead of verifying division operations in the circuit, which is a significant bottleneck in zk-SNARK-based deep learning inference. To tackle this, the authors proposed two key optimizations based on the Plonkish arithmetization framework \cite{gabizon2019plonk} in the Halo2 scheme. (1) For linear operations, including convolutional layers, residual connection layers, and fully connected layers, the authors designed two custom gates to efficiently encode division operations. The first gate performs an addition of multiple inputs, while the second gate computes the dot product of inputs and weights, incorporating the division by a fixed scaling factor. These gates avoid the need for complex floating-point arithmetic by leveraging fixed-point approximations, significantly reducing the number of constraints required for division. (2) For nonlinear operations such as ReLU and softmax, the authors utilized lookup arguments to efficiently represent division. Specifically, the division operation is precomputed for a range of possible input values, and the results are stored in a lookup table. During proof generation, the circuit enforces that the computed division results match the precomputed values in the table, thereby reducing the computational cost associated with division. Additionally, the authors ensured the privacy of the model's inputs and weights by incorporating hash commitments. This allows the model provider to prove the correctness of inference without revealing sensitive model parameters or input data. The proposed zk-SNARK scheme achieves high accuracy on ImageNet-scale models while maintaining relatively low verification time. For example, the proof verification time for MobileNet v2 with 79.2\% accuracy on ImageNet is approximately 10.27 seconds on commodity hardware. Furthermore, the proof size is significantly smaller compared to prior methods. Specifically, the proof size is reduced to 5,952 bytes, which is orders of magnitude smaller than methods based on secure multi-party computation (MPC), which typically require tens to hundreds of gigabytes for proof representation.


Fan \emph{et al.} proposed a zero-knowledge verification scheme to ensure the integrity of CNN inference, with a focus on balancing the confidentiality of certain CNN model parameters and verifying the correctness of the inference process in machine learning as a service (MLaaS) scenarios \cite{fan2023validating}. In this scheme, the authors developed a computational logic extraction algorithm capable of accurately translating the computational logic of convolutional layers, fully connected layers, pooling layers, and activation layers into corresponding simple arithmetic expressions. These expressions are subsequently used to construct proof circuits for each layer of the model within the zk-SNARK framework. Based on this design, the prover performs the computations involved in the CNN model's inference process and generates zero-knowledge proofs using the constructed proof circuits. The verifier then validates the integrity of the inference process by checking the proofs for each layer of the model. Although this scheme increases the number of multiplications and additions, resulting in a more complex R1CS for circuit construction, experimental results show that both the computational and storage overheads remain within acceptable limits. This demonstrates the practicality of the proposed approach for real-world applications.


Ganescu \emph{et al.} \cite{ganescu2024trust} proposed a novel ZKML scheme, named  snarkGPT, to address the challenge of securely executing Generative AI models via remote cloud APIs for all users, without exposing sensitive model information. Since transformers serve as the foundational architecture for many Generative AI models, snarkGPT is specifically designed to prove the execution of transformer-based models. Using a fixed version of the EZKL framework (commit  8f122bf1), Ganescu \emph{et al.} implement the snarkGPT protocol based on Halo2, with a particular focus on the nanoGPT model \cite{karpathy2023nanogpt}. The performance of their implementation is evaluated in terms of time and memory costs associated with proof generation, particularly for the prover, who is responsible for generating the zk-SNARK proof. Experimental results show that proof generation time increases nonlinearly with both embedding size and layer count. Additionally, the study examines the impact of circuit matrix size on proof generation time and memory consumption, revealing that larger matrix sizes lead to significant increases in both. Specifically, when the logarithmic size of the circuit matrix grows from 14 to 18, runtime improves slightly, but as the size reaches 24 and 25, there is a sharp increase in both runtime and memory costs. Notably, memory usage escalates dramatically, reaching 148 GB for a logarithmic matrix size of 25. The research also explores the relationship between model architecture, the number of parameters, and the number of constraints generated in zk-SNARK proofs. Experiments highlight a stark contrast in the constraint-to-parameter ratio between nanoGPT and other models, such as the Modulus Labs MLP model. For nanoGPT, this ratio ranges from approximately 58x to 85x, whereas the MLP model exhibits a significantly lower ratio. By comparing constraint generation across different models, the study uncovers substantial differences in zk-SNARK proof generation between Transformer architectures (like nanoGPT) and other types of neural networks, such as Convolutional Neural Networks. These findings suggest that zk-SNARK proof generation time and memory costs are influenced not only by the number of model parameters but also by factors such as architectural design and the choice of proof system.


Handling large-scale machine learning models requires substantial memory and computational resources, which has historically constrained previous ZKML schemes to relatively small-scale models. To overcome this limitation, Chen \emph{et al.} proposed a novel system capable of generating zero-knowledge proofs for the inference of larger-scale machine learning models, including contemporary vision models and a lightweight version of GPT-2 \cite{chen2024zkml}. This system addresses the challenge of proving large-scale models by compiling models built in TensorFlow into circuits within the Halo2 proof system. The core contribution lies in the introduction of an optimized compiler, which features efficient constraint gadgets for fundamental operations and an advanced optimizer to determine the optimal layout for these gadgets. This innovation dramatically improves the compilation perfoHrmance, achieving up to 24\(\times\) speedups for implementing the same operations in zk-SNARK circuits. In comparison to prior works, the combination of the optimized compiler and the Halo2 framework enables the system to support a broader range of models while delivering significant improvements in proof generation speed, verification time, and proof size. This advancement represents a major step forward in making zero-knowledge proofs practical for large-scale machine learning applications.

zkLLM \cite{sun2024zkllm} is a solution for verifiable inference of large language models (LLMs) based on the transformer architecture, aiming to verify the authenticity of LLM inference  outputs without disclosing the model parameters. Its implementation can be summarized into the following two key components. (1) {\bf tlookup}: The paper proposed the tlookup protocol to address the high computational complexity and memory overhead associated with non-arithmetic tensor operations (such as activation functions) in ZKP. The tlookup protocol pre-constructs a lookup table that stores the mapping between activation function inputs and outputs. This approach eliminates the need to directly compute complex nonlinear functions during the proof process. Instead, it enables rapid verification of input-output pairs through table lookup, thereby significantly reducing computational complexity. Additionally, tlookup introduces a random linear combination technique to compress input and output values, reducing the amount of data that needs to be transmitted and processed during proof generation. To further enhance efficiency, the tlookup protocol fully leverages modern hardware capabilities (e.g., GPUs) by designing a verification process that supports parallel computation. In this process, the kernel functions for table lookup and random linear combination are parallelized, greatly reducing the time required for inference proof generation. (2) {\bf zkAttn}: Building upon tlookup, the paper further introduced the zkAttn protocol, which provides an efficient zero-knowledge proof process for the attention mechanism in LLMs. The core computations of the attention mechanism include matrix multiplication and the Softmax function. These operations typically incur high computational costs and storage overhead in zero-knowledge proofs. zkAttn introduces specific optimization methods, such as exploiting the shift invariance of the Softmax function and applying simplified and piecewise linear approximations to the input-output pairs of the Softmax function. These strategies significantly reduce the complexity of proof generation. Through these designs, even the most complex attention mechanism layers in LLMs can be efficiently subjected to zero-knowledge verification. Through these two components, zkLLM provides a fully parallelized scheme based on CUDA technology for verifying the correctness of large language model inference results without exposing the model's private parameters. Experimental results demonstrate that zkLLM exhibits efficient performance on large language models with up to 13 billion parameters (such as OPT and LLaMa-2). Specifically, zkLLM's proof generation time is under 15 minutes, and verification time requires only a few seconds, significantly enhancing verification efficiency. Furthermore, the scheme keeps GPU memory consumption within 23.1 GB, making it compatible with common GPU hardware environments. In terms of numerical accuracy, zkLLM performs well, achieving performance close to the original model and ensuring the correctness of inference results.

ZKML \cite{chen2024zkml} is a compiler specifically designed to optimize zero-knowledge proofs for machine learning models. Its core functionality involves converting TensorFlow models into Halo2 zero-knowledge proof circuits, enabling efficient verification of complex machine learning inference processes. The system architecture comprises two critical modules: low-level gadgets and a Circuit Layout Optimizer. First, the low-level gadgets serve as fundamental components of ZKML, providing efficient constraint representations for common machine learning operations such as dot products, Softmax, and nonlinear activation functions (e.g., ReLU, GELU). These constraints enable the implementation of these operations within zero-knowledge proof circuits with minimal computational overhead and storage requirements, thereby supporting diverse model architectures including GPT-2, Twitter models, ResNet-18, and VGG-16. Second, the Circuit Layout Optimizer automatically selects optimal circuit configurations through circuit simulation and cost estimation. This intelligent optimization module adapts circuit structures based on hardware resources and model characteristics, effectively reducing computational redundancy and significantly improving proof efficiency. Through these dual mechanisms, ZKML demonstrates remarkable performance improvements and flexibility in supporting zero-knowledge proofs for large-scale machine learning model inference. Experimental evaluations on multiple models (including GPT-2, Diffusion Models, Twitter models, ResNet-18, and VGG-16) reveal compelling results: For GPT-2, proof generation requires approximately 3,652 seconds with verification completed in 18.7 seconds and a compact proof size of 28 KB. ResNet-18 achieves proof generation in 52.9 seconds, verification in 12 milliseconds, and a proof size of 15.3 KB. Comparative analysis with existing zero-knowledge proof systems (zkCNN \cite{liu2021zkcnn} and vCNN \cite{lee2024vcnn}) demonstrates ZKML's superior performance, achieving up to 24-fold improvement in proof generation time, 5x reduction in verification time, and 22x compression in proof size. Notably, on the CIFAR-10 dataset, ZKML reduces proof generation time by 31 hours compared to conventional approaches. Furthermore, the system maintains exceptional model accuracy with negligible impact (within 0.01\%), significantly outperforming traditional quantization methods that typically incur 0.1\% accuracy degradation, thereby achieving an optimal balance between efficiency and precision.

Lu \emph{et al.} \cite{lu2024efficient} proposed an efficient and scalable ZKP framework aimed at optimizing the generation of verifiable inference proofs for neural networks. By integrating the Vector Oblivious Linear Evaluation (VOLE) \cite{schoppmann2019distributed} technology, range proofs, and lookup proofs, this framework significantly improves the proof efficiency of non-linear layers and can be extended to more types of neural networks. The framework not only supports CNNs, such as ResNet-101 and VGG-11, but also Transformer networks like GPT-2, supporting Transformer networks with up to 117 million parameters. The specific details of the framework proposed in  \cite{lu2024efficient} are as follows. (1) To tackle the issue of high computational overhead in the non-linear layers of neural networks, the framework transforms complex non-linear relationships into two core proof forms: Range Proofs and Exponent Proofs. This approach significantly reduces the large number of constraints that traditional methods need to handle. Range Proofs are used to verify whether input values fall within a specific range, while Exponent Proofs deal with complex relationships involving exponential operations, effectively reducing computational complexity. Simultaneously, based on VOLE technology, the framework designs two improved methods: a Range Proof module and a Lookup Proof. These methods not only efficiently perform range verification but also rapidly complete data lookup and mapping operations, greatly enhancing the efficiency and scalability of proof generation. (2) The paper adopts a modular design approach, endowing the framework with high flexibility and scalability. Through this modular method, the framework can incrementally combine basic operational units (such as addition, multiplication, and range verification) to extend support to the inference verification of entire neural networks. Specifically, the framework optimizes CNNs and Transformer networks, enabling efficient proof and verification of the inference processes and results of these common models. Additionally, this modular design provides the possibility for the framework to extend to other types of neural networks (such as Recurrent Neural Networks or Graph Neural Networks), allowing it to maintain efficiency and generality across different application scenarios. Through these two key steps, the paper provides an efficient and scalable neural network verification scheme while ensuring data privacy protection. Experimental results demonstrate significant performance improvements in non-linear layer proofs and overall neural network verification. In the proofs of non-linear layers (such as ReLU, Softmax, GELU, and Normalization), compared to Mystique (a scheme based on bit decomposition), the proof generation time achieved up to a 477.2x speedup, and the computational and communication costs were also significantly better than existing schemes. In the neural network inference proof process, significant optimizations were achieved for Convolutional Neural Networks (such as VGG-11, ResNet-50, and ResNet-101). For example, the proof generation time for ResNet-101 was only 6.65 seconds, an acceleration of 41.4 times compared to traditional methods; for Transformer Neural Networks (such as GPT-2), the proof generation time was 287.1 seconds, a 35.7x improvement over ZKML \cite{sun2024zkllm}. Furthermore, the framework is compatible with high-precision quantized neural networks, achieving inference accuracy close to the original model. For instance, the accuracy of ResNet-101 on the CIFAR-10 dataset decreased by only 0.04\% , fully demonstrating its efficiency and reliability.


%While zkLLM is a GPU-accelerated solution customized for transformer-based neural networks \cite{sun2024zkllm}, Lu \emph{et al.}  propose a complementary framework designed to provide an efficient and scalable zero-knowledge proof system for various types of neural networks on CPUs \cite{lu2024efficient}. This framework offers three key contributions: (1) The framework leverages VOLE \cite{schoppmann2019distributed} as the proving backend, enabling it to handle large-scale computations with minimal memory consumption. (2) To address the challenges of proving nonlinear layers, the authors introduce methods based on range proofs and lookup table proofs. These methods replace the complex approach of decomposing inputs and outputs of nonlinear operations into Boolean circuits, significantly reducing the number of constraints required for proving nonlinear layers and thereby improving proof efficiency. (3) The framework adopts a modular architecture, making it easily extensible to support a wider variety of neural network architectures.

%Together, zkLLM \cite{sun2024zkllm} and the CPU-based framework of \cite{lu2024efficient} represent significant advancements in zero-knowledge proof systems, addressing the computational and scalability challenges of verifying neural network inference across diverse platforms and architectures.


Hao \emph{et al.}  \cite{hao2024scalable} conducted an in-depth study on improving the efficiency of ZKP for non-linear functions in ML models. They proposed the use of the table lookup technique and digital decomposition to address the computational cost issues in verifying non-linear functions. Their specific contributions are as follows. (1) {\bf Table Lookup Technique}: This is one of the core innovations of the paper, aiming to efficiently verify the correctness of non-linear functions through the use of lookup tables. Specifically, complex non-linear functions (such as exponentials, divisions, etc.) are transformed into lookup table problems by storing valid input-output mappings in a lookup table. The prover needs only to prove that the input-output pair exists in the lookup table to complete the function verification. This method avoids the traditional verification approach based on Boolean circuits, eliminating the need to convert arithmetic values into Boolean values, thereby significantly reducing computational complexity. (2) {\bf Digital Decomposition}: However, directly storing lookup tables of all possible input-output pairs leads to excessively large sizes, especially when the input bit-length is large, causing the size of the lookup table to grow exponentially. To solve the problem of lookup table size explosion, the paper proposes digital decomposition. Large bit-length inputs cause storage requirements and computational costs of lookup tables to increase sharply; therefore, the paper decomposes large bit-length inputs into several smaller numbers (e.g., 5 to 12 bits), effectively reducing the size of the lookup table. For example, an input~$x$ can be decomposed as $x = x_{k-1} \parallel \ldots \parallel x_0$, where each decomposed number~$x_i$ has a smaller bit length. This approach allows the lookup table to store mappings of small numbers for verification. Through digital decomposition, the paper supports the verification of large bit-length inputs with less storage overhead and computational cost while maintaining the correctness and completeness of the verification results. Through these two key steps, the authors successfully implemented zero-knowledge proofs for common non-linear functions such as ReLU, Sigmoid, GELU, Softmax, Maxpooling, and normalization. Compared to existing solutions (e.g., Mystique~\cite{weng2021mystique}), this research achieved significant performance improvements, with runtime reduced by $50\times$ to $179\times$, and communication costs decreased by $1.2\times$ to $4.8\times$. In applicability verification, the framework demonstrated outstanding efficiency advantages in mainstream machine learning tasks (such as inference verification of CNNs and LLMs), especially showing significant performance improvements when handling common functions like ReLU and Softmax. For example, on the ReLU function, runtime was reduced by approximately $100\times$; on the Softmax function, runtime was reduced by approximately $179\times$; and on the GELU function, runtime was reduced by approximately $77\times$ to $86\times$.

%Hao proposed a systematic zero-knowledge proof framework to handle nonlinear mathematical functions in machine learning \cite{hao2024scalable}. It uses a lookup table approach to solve the computation problem of nonlinear functions. The key challenge of this approach is that lookup tables cannot be directly applied to nonlinear functions in machine learning because the tables become too large and inefficient. To solve this problem, the work introduces several important building blocks, including digit decomposition, comparison, and truncation, which can efficiently use lookup tables and ensure the correctness of the proof. Extensive experimental evaluations show that compared to Mystique \cite{weng2021mystique}, this work achieves a 50-179 times improvement in runtime.

%The paper \cite{li2024sparsity} explores a special category of models called Ternary Networks, whose parameters take values from {-1, 0, 1}, a special category of ZK-friendly ML models. To exploit the natural sparsity in Ternary Networks, the authors propose the SpaGKR protocol and the SpaGKR-LS protocol. SpaGKR is a sparsity-aware general GKR protocol for handling general layer structures where weights may be sparse. This protocol can incorporate various sparsity-aware sumchecks as subroutines; SpaGKR-LS is an asymptotically optimal sparsity-aware GKR protocol for linear layers, with proof time linear only in the number of non-zero entries of the model parameters.


% The main contribution of work ~\cite{li2024sparsity} focuses on enhancing the efficiency and practicality of ZKML, especially when dealing with large-scale machine learning models. The paper is the first to explicitly investigate the application of \emph{ternary networks}---a special class of machine learning models---in the context of ZKML. Ternary networks employ extreme quantization by restricting all weights to ${-1, 0, 1}$, which not only significantly improves computational efficiency but also makes the models more suitable for the ZKML framework while maintaining high performance. The study demonstrates that such extreme quantization does not significantly reduce model capacity or accuracy. Moreover, ternary networks convert field multiplication into sparse field addition, markedly enhancing the efficiency of ZKML. Through theoretical analysis, the paper points out that under mild assumptions, this transformation can improve the efficiency of the proof protocol by a factor of $45$. This work proposed the \emph{SpaGKR} framework, a general framework for ZKML specifically designed to exploit the sparsity in model parameters to enhance proof efficiency. SpaGKR modifies the gate definitions in the traditional GKR protocol to reflect the sparsity of the parameters. \emph{SpaSum} is a key component within the SpaGKR framework, specifically designed to handle the products and sums between sparse vectors. By leveraging sparsity, SpaSum can significantly reduce the prover's computational burden. During the proof process, SpaSum reduces the proof time complexity from $O\left( (p_{i+1} + 1) \cdot N_{i+1}^o \right)$ to $O\left( (p_{i+1} + 1) \cdot N_{i+1}^{\emptyset} \right)$, where $N_{i+1}^{\emptyset}$ represents the number of nonzero elements.  For linear layers, SpaGKR is further refined into the \emph{SpaGKR-LS} protocol, which achieves asymptotically optimal proof time---that is, the proof time depends only on the number of nonzero elements in the model parameters. SpaGKR-LS significantly improves proof efficiency by invoking the sumcheck process only once. 


Work~\cite{li2024sparsity} introduced a ZKP-based verifiable inference framework for deep learning models, aiming to enhance the efficiency and practicality of ZKML while addressing privacy and security concerns in current MLaaS systems. The framework achieves significant improvements in proof efficiency and storage overhead by incorporating sparsity-aware protocols and ternary networks. Its implementation involves the following key steps: (1) Optimized Protocol for Sparse Linear Layers (SpaGKR-LS): The paper proposes an optimized protocol, SpaGKR-LS, specifically designed for the linear layers of neural networks. This protocol achieves proof time that scales linearly with the number of non-zero parameters, significantly reducing computational complexity through techniques such as mode pruning and quantization. By leveraging the sparsity of linear layers, the protocol enables more efficient proofs for sparse networks. (2) Quantization with Ternary Networks: The framework quantizes the model using ternary networks, where parameters are restricted to \{-1, 0, 1\}. This design eliminates multiplication operations and, by combining sparsity and low-bit-width characteristics, further enhances proof efficiency. The ternary network's inherent sparsity and simplified arithmetic operations reduce computational overhead, making the proof process more efficient. (3) Modular Framework Design: A modular framework is proposed, compatible with existing ZKML methods based on GKR (Sumcheck Protocol). This modular design allows seamless integration with sparsity-aware protocols, such as the Lasso protocol \cite{setty2024unlocking} or the SpaGKR protocol proposed in this work. The flexibility of the modular approach enables efficient verification and adaptability to different use cases. Through these three steps, the proposed framework not only overcomes the efficiency bottlenecks of traditional ZKML methods in handling sparsity and quantized models but also significantly enhances the flexibility and scalability of the framework through its modular design. Experimental results demonstrate the effectiveness of the framework. For sparse linear layers, SpaGKR-LS achieves a 45x speedup in proof time compared to traditional ZKML methods that ignore sparsity. For ternary networks, proof time is further reduced by approximately 5x. Additionally, the framework achieves substantial improvements in verification time and storage efficiency, showcasing its practicality and effectiveness for large-scale deep learning models.

The work of~\cite{zhan2024validating} proposes a ZKP-based verifiable inference scheme for deep learning models, aiming to address data leakage and service fraud issues prevalent in current MLaaS platforms. By ensuring the integrity of ML inference processes and results, as well as the privacy and security of ML model parameters, the scheme enhances trust in MLaaS. The proposed scheme integrates non-interactive ZKP with blockchain technology to ensure model integrity verification while protecting sensitive information about model parameters. Its implementation can be divided into three key steps: (1) R1CS Circuit Design for Neural Network Modules: Each module of the neural network---such as convolution, normalization, activation, and pooling layers---is designed as a R1CS circuit to precisely describe and verify its computational logic. To optimize the circuit complexity, several innovations are introduced in the module designs: In the \emph{convolutional layers}, \emph{depthwise separable convolutions} are employed instead of traditional convolutions, significantly reducing computational complexity; for the \emph{activation functions}, minimal polynomial methods are used to approximate complex activation functions (e.g., Swish), avoiding the complexity associated with floating-point operations; in the \emph{pooling layers}, \emph{adaptive average pooling} circuits are designed to ensure the circuits can flexibly adapt to different input and output sizes. These optimizations enable the computational logic of each module to be transformed into simple polynomial constraints, significantly reducing the generation time and storage requirements of zk-SNARK proof files. (2) Serial Hash Circuit Connection (SHCC) Algorithm: To address the high complexity introduced by interactions and integrity verification between modules in the modular design of large neural networks, the paper proposes the SHCC algorithm. The large-scale deep learning model is divided into multiple modules, with hash connections ensuring integrity between modules. Specifically, the SHCC algorithm adopts a layer-by-layer hashing method, where each module's output hash value is generated from the current module's computation result and the previous module's hash value, forming a serial hash chain. If the output of any module is tampered with, subsequent module verification will fail due to hash mismatches, thereby ensuring the integrity and security of the entire network. Through these steps, the proposed framework not only ensures the integrity verification of deep learning models but also enhances computational and storage efficiency while guaranteeing privacy protection. Experimental results demonstrate significant optimizations in verification time and storage overhead. Specifically, the verification time is reduced by $54.6\%$. In terms of storage overhead, the transformed R1CS circuits are more concise, reducing the storage requirements of proof files (such as R1CS files, ZKEY files, and WASM files) by $58.1\%$. Notably, the proof files generated using the Groth16 protocol have a fixed size of $4$KB. In the Ethereum environment, verification of proof files is achieved through smart contracts. The verification process is divided into three modules: \emph{input module}, \emph{backbone module}, and \emph{output module}, with proof files generated off-chain separately and verification executed through on-chain smart contracts. Experimental results confirm the feasibility of the scheme through the deployment and execution of smart contracts. Gas consumption tests demonstrate that the verification process is efficient and cost-controllable; for example, the execution cost of the backbone module is 397,434 Gas, and the verification cost is 222,424 Gas.


Additionally, the research efforts in zkDT \cite{zhang2020zero}, ZEN \cite{feng2021zen}, zkCNN \cite{liu2021zkcnn}, and Lookup arguments \cite{campanelli2024lookup} also contribute to and support ZKP-based verifiable inference. These works have been introduced earlier in this section and will not be revisited in this part discussing verifiable inference. 


\subsection{Improvements in ZKML Implementations}\label{ss:3c}

Most machine learning  algorithms are inherently complex and computationally expensive, making their implementation with existing ZKP solutions highly challenging. This complexity often renders direct proof generation and verification infeasible for many practical applications. Specifically, there are two primary challenges in implementing ZKML:

\begin{itemize}
    \item \emph{Generality Limitations}: Most machine learning tasks rely on floating-point computations and nonlinear operations. However, ZKP, as a cryptographic technique, operates on linear arithmetic over finite fields. Floating-point and nonlinear operations in ML cannot be directly translated into the arithmetic circuit representations required by ZKP over finite fields. As a result, ZKP algorithms must be specifically tailored to handle the floating-point computations and nonlinearities of different ML models. For example, the ReLU activation function, $f(x)=max(x,0)$ used in neural networks, though computationally simple in conventional ML implementations requires specialized adaptations in ZKML implementations. ReLU inherently requires inequality comparisons ($x>0$) and conditional branching, which cannot be natively executed in finite field arithmetic. To circumvent this, ReLU can be expressed as $x\cdot \mathbb{I}(x{\geq}0)$ by introducing auxiliary binary variables for the indicator function $\mathbb{I}$ (as proposed in \cite{sun2023zkdl}). Alternatively, ReLU can be approximated using polynomial functions. Moreover, these ReLU-specific adaptations fail to generalize to other activation functions. This demonstrates how ZKML systems sacrifice generality for functionality---each unique nonlinear operation demands custom constraint system design, precision-robustness tradeoff analysis, and specialized optimization passes. 
    
    
    %in deep neural networks, nonlinear activation functions such as ReLU, Sigmoid, or Tanh are widely used. These operations cannot be directly represented in ZKP-friendly arithmetic circuits and must instead be approximated using piecewise linear functions or low-degree polynomials. However, the choice of approximation often depends on the specific activation function and the model being used. For instance, implementing ReLU may involve a custom circuit that checks whether a value is greater than zero, while Sigmoid or Tanh requires more complex polynomial approximations, which increase the circuit size and computational complexity. These model-specific adaptations significantly limit the generality of ZKML frameworks, as each neural network architecture or activation function may require a unique circuit design and optimization strategy.
    
    
    \item \emph{Efficiency Barriers}: Modern machine learning models, such as deep neural networks, typically involve a large number of parameters, resulting in massive arithmetic circuit representations. Consequently, the proof generation and verification processes in ZKP can become prohibitively time-consuming. For instance, Groth16, one of the most widely used zk-SNARK protocols, has a proof generation complexity of \(O(|C|E)\), where \(|C|\) denotes the size of the arithmetic circuit (directly proportional to the computational workload), and \(E\) represents the cost of group exponentiation. To prove the inference using a deep neutral network model like VGG16 that has 138 million parameters, the value of  \(|C|\) and \(E\) can be calculated as follows. Each convolutional layer requires round 5,000 multiplication gates per parameter due to weight-input multiplications and activation function approximations; total circuit size reaches $|C| \approx 7.2 \times 10^{11}$ gates (720 billion gates); Groth16 proof generation requires 2 group exponentiations per multiplication gate, leading to  $E=1.44 \times 10^{12}$ exponentiations. For a VGG16-sized circuit using BN254 elliptic curve (254-bit base field): the evaluation key size is $|C|\times 3\times 64~ /10^{12} =(720 \times 10^9 \times 192)/ 10^{12} = 138.24$  TB; the verification key size is $(|C|+2)3.64~ /10^{12} =(720 \times 10^9 \times 192)/ 10^{12} = 46.08$ TB; the proof generation time is over 30 years on a 256-core AWS c6i.32xlarge instance. This demands an extraordinary amount of memory and computational resources. Thus, efficiently generating proofs for ML computations remains a significant challenge.
    
\end{itemize}


In the following, we explore how existing research efforts tackle the challenges of improving the generality and efficiency of ZKML implementations. These efforts are categorized into three main areas: enhancing generalization, improving efficiency, and addressing other aspects across various types of ZKML, as summarized in Fig.~\ref{tab}.





% \begin{table*}[t]
% \setlength{\tabcolsep}{2pt} % 调整列间距
% \centering
% \small 
% \begin{center}
% \begin{tabular}{|c|c|c|c|c|}
% \hline
% \multirow{3}{*}{\shortstack{\textbf{Categories}\\\textbf{of ZKML}}} & \multirow{3}{*}{\shortstack{\textbf{Verifiable}\\\textbf{Training}}} & \multirow{3}{*}{\shortstack{\textbf{Verifiable}\\\textbf{Testing}}}& \multicolumn{2}{c|}{\textbf{Verifiable Inferring}} \\ \cline{4-5} 

%  &  & & \textbf{Public input,} & \textbf{Private input,} \\
% & & &\textbf{ private model} &\textbf{ private model} \\ \hline

% \multirow{6}{*}{\shortstack{\textbf{Generali}\\\textbf{-zability}}}
%  & VeriML\cite{zhao2021veriml} & ZEN\cite{feng2021zen} & SafetyNets\cite{ghodsi2017safetynets}  & Mystique\cite{weng2021mystique} \\ \cline{2-5} 
%  & zkMLaaS\cite{huang2022zkmlaas} & zkCNN\cite{liu2021zkcnn} & ZEN\cite{feng2021zen} & Kang\cite{kang2022scaling}  \\ \cline{2-5} 
%  & ZKDL\cite{sun2023zkdl} & Kang\cite{kang2022scaling} & zkCNN\cite{liu2021zkcnn} & \\ \cline{2-5} 
%  & zkPoT\cite{garg2023experimenting} & South\cite{ganescu2024trust} & ZKML\cite{chen2024zkml} & \\ \cline{2-5} 
%  &  Kaizen\cite{abbaszadeh2024zero}&  & South\cite{ganescu2024trust} & \\ \cline{2-5} 
%  &  &  & Lu\cite{lu2024efficient} & \\ \cline{2-5} 
%  &  &  & SpaGKR\cite{li2024sparsity} & \\ \hline
% \multirow{10}{*}{\textbf{Efficiency}} 
%  & VeriML\cite{zhao2021veriml} & ZKDT\cite{zhang2020zero} & SafetyNets\cite{ghodsi2017safetynets}  & vCNN\cite{lee2024vcnn}  \\ \cline{2-5} 
%  & zkMLaaS\cite{huang2022zkmlaas} &  \multirow{2}{*}{\shortstack{Lookup\\arguments\cite{campanelli2024lookup}}} & Hydra\cite{zhang2021hydra} & pvCNN\cite{weng2023pvcnn} \\ \cline{2-2} \cline{4-5}  
%  & Hydra\cite{zhang2021hydra} &  & ZKDT\cite{zhang2020zero} & \\ \cline{2-5} 
%  &  &  & zkCNN\cite{liu2021zkcnn} & \\ \cline{2-5} 
%  &  &  & Singh\cite{singh2022zero} & \\ \cline{2-5} 
%  &  &  & ezDPS\cite{wang2022ezdps}  & \\ \cline{2-5} 
%  &  &  & Fan \cite{fan2023validating} & \\ \cline{2-5} 
%  &  &  & zkLLM\cite{sun2024zkllm} & \\ \cline{2-5} 
%  &  &  & Lu\cite{lu2024efficient} & \\ \cline{2-5} 
%  &  &  & \shortstack{Lookup\\arguments\cite{campanelli2024lookup}} & \\ \cline{2-5} 
%  &  &  & Hao\cite{hao2024scalable} & \\ \hline
% \textbf{Others} & Drynx\cite{ghodsi2017safetynets} &  &  & \\ \hline
% \end{tabular}
% \end{center}
% \caption{Categories of ZKML}
% \label{tab4}
% \end{table*}




\subsubsection{Improvement of Generality}\label{sss:3a}
To bridge the gap between floating-point machine learning operations and finite-field ZKP primitives, the key lies in converting decimals into integers through quantization functions that minimize precision loss while maintaining model performance. This process also involves determining the optimal number of variable bits. On one hand, the range of integers representable by a fixed number of bits is inherently limited, potentially causing overflow issues when decimals mapped by the quantization function exceed this range. On the other hand, the computation involving these converted integers must retain as many significant bits as possible to reduce the impact of diminished computational precision on overall model accuracy.


To ensure accuracy, in SafetyNets \cite{ghodsi2017safetynets}, all decimal weights and input data must be within \([- (p - 1)/2, (p - 1)/2]\). The floating-point parameters \(W_i'\) and \(b_i'\) obtained from training are multiplied by a constant \(\beta > 1\) and rounded to convert them into integers, \emph{i.e.}, \(W_i = \lceil \beta W_i' \rceil\), with the same method applied to inputs using a scaling factor \(\alpha\), \emph{i.e.}, \(x = \lceil \alpha x' \rceil\). To ensure isotropic scaling of all values in the network, set \(b_i = \lceil \alpha z^{l-1} \beta (z^{l-1}+1) b_i' \rceil\). This method achieves an integer computation process. In VeriML \cite{zhao2021veriml}, each input is restricted to at most \(l\) decimal places by multiplying the input by \(2^l\) to convert it to an integer, applying appropriate scaling factors in the equations. zkCNN \cite{liu2021zkcnn} adopts the quantization technique proposed by Jacob \emph{et al.} \cite{Jacob_2018_CVPR} to encode floating-point numbers as integers. This quantization scheme is an affine mapping from integer \(q\) to real number \(a\). Specifically, \(a = L(q - Z)\), where the quantization parameter \(L\) is a real number called the quantization scale, and \(Z\) is an integer called the quantization zero point. Using quantization, each value of data samples and model parameters is represented as a Q-bit integer \(q\), allowing addition and multiplication of two real numbers with the same scale to naturally represent integer addition and multiplication. Kang \cite{kang2022scaling} employs quantized DNNs to avoid the costly overhead of floating-point arithmetic, representing weights and other floating-point parameters as 8-bit integers, similar to the method in zkCNN. This quantization scheme is an affine mapping from integer \(W_{\text{quant}}\) to real number \(W, w = (W_{\text{quant}} - z) \cdot (a/b)\), where \(W_{\text{quant}}\) and \(z\) are 8-bit integer weights and zero point, and \(a/b\) represents fixed-point approximation. Choosing lower precision values for \(a\) and \(b\) leads to slight accuracy degradation, but significantly improves proof and verification performance. However, the aforementioned methods are only applicable to problems within specific ZKP systems and lack generality. The above methods are only applicable to problems within specific zero-knowledge proof systems. Next, existing research solutions that effectively address generality issues will be introduced, which can be used directly or indirectly in arithmetic processing in the future.

\begin{figure*}[t]
    \centering
    \includegraphics[width=\linewidth]{improvements.pdf}
    \caption{The categorization of ZKML works based on improvements in generality, efficiency, and other aspects.}
    \label{tab}
%\vspace{-15pt}
\end{figure*}

To further address the issue of generality, enabling future direct or indirect use in arithmetic processing, Weng \emph{et al.} proposed the Mystique system \cite{weng2021mystique}, which allows efficient conversion between arithmetic and Boolean values, between public commitments and private authenticated values, and between fixed-point and floating-point numbers. The authors also design an efficient zero-knowledge proof for matrix multiplication, making the number of private multiplications required sublinear in matrix size. Notably, this system has been integrated into the privacy-preserving framework Rosetta\cite{chen2020rosetta} based on TensorFlow\cite{abadi2016tensorflow}, meaning developers can directly call this system and ignore the cryptographic details involved. ZEN \cite{feng2021zen} proposed a new quantization algorithm that avoids floating-point zero-knowledge proofs, including two R1CS-friendly optimizations: sign bit grouping and remainder-based verification. Compared to existing quantization works, ZEN saves 73.9 times R1CS on convolution kernels and 8.4 times R1CS on fully connected kernels without causing additional accuracy loss. Additionally, ZEN can convert a floating-point PyTorch model into an arithmetic circuit over a finite field. Kang \emph{et al.} \cite{kang2022scaling}  used the zero-knowledge proof scheme Halo2 to customize an ImageNet-scale zk-SNARK circuit for the MobileNet v2 model. To address the high verification cost of division operations in the circuit, two custom gates were designed for linear layers to represent division. For nonlinear layers, lookup parameters were used to reduce the representation cost of division. Three protocols based on this scheme were also proposed for verifying model accuracy, prediction results, and search term-predicate matching. Compared to other works (including ZEN \cite{feng2021zen}, vCNN \cite{lee2024vcnn}, pvCNN \cite{weng2023pvcnn}, zkCNN \cite{liu2021zkcnn}), this scheme improves proof time on MobileNet by at least ten times.

The above works focus on addressing the challenges of quantization techniques for floating-point operations in zero-knowledge proof systems, providing solutions to bridge the gap between machine learning computations and finite-field arithmetic. However, an additional challenge arises when adapting widely used machine learning models, particularly neural networks, to these systems. While operations such as matrix multiplication and convolution in neural networks can be effectively represented using basic addition and multiplication, most activation functions are inherently nonlinear and cannot be directly expressed within arithmetic circuits.

Currently, methods for handling activation functions in neural networks include: SafetyNets \cite{ghodsi2017safetynets}, VeriML \cite{zhao2021veriml}, zkMLaaS \cite{huang2022zkmlaas}, zkCNN \cite{liu2021zkcnn}, and zkDL \cite{sun2023zkdl}. For SafetyNets \cite{ghodsi2017safetynets}, it uses a quadratic activation function. This directly avoids complex computations but may impact network performance due to poor activation functions. For VeriML \cite{zhao2021veriml}, it uses Remez approximation to approximate the sigmoid function and quadratic functions to approximate the ReLU function, thereby addressing the issue caused by the poor activation in SafetyNets. For zkMLaaS, it utilizes the method proposed by Sav \emph{et al.} \cite{chen2020rosetta} to minimize the least squares error when approximating activation functions. However, this method also leads to performance degradation due to approximation. For zkCNN \cite{liu2021zkcnn}, it uses a bit decomposition method to directly compute the ReLU function in segments. Fan constructs an operation matrix where the input of the ReLU activation layer is Hadamard-multiplied with the operation matrix to obtain the output of the ReLU layer. This method has minimal impact on model performance but introduces additional computation and design overhead. For zkDL \cite{sun2023zkdl}, it further proposes a zero-knowledge proof protocol optimized for ReLU activation functions, the zkReLU protocol, which introduces auxiliary inputs to verify the forward and backward propagation processes involving ReLU, retains the tensor structure of deep learning, and combines zero-knowledge inner product proofs with the GKR protocol designed for optimized arithmetic circuits, achieving significant improvements in proof generation speed and size reduction.

\subsubsection{Improvement of Efficiency}\label{sss:3b}
Recent advancements in ZKP systems for machine learning have focused on improving efficiency and scalability through innovative algorithmic designs and circuit optimizations. These techniques aim to bridge the gap between the computational complexity of machine learning models and the constraints of ZKP frameworks by leveraging methods such as matrix representations, efficient arithmetic circuit constructions, and tailored proof strategies. Key ideas include transforming complex operations like convolutions and nonlinear activation functions into simpler arithmetic forms, optimizing proof generation with probabilistic algorithms, and modularizing model components to streamline verification. Additionally, techniques like random sampling, table lookups, and specialized commitment schemes have been introduced to reduce proof costs and enhance scalability. These foundational ideas set the stage for the following research efforts, which tackle specific challenges in validating neural networks, decision trees, and other machine learning models within ZKP systems.


In SafetyNets \cite{ghodsi2017safetynets}, the GKR protocol is designed based on matrix multiplication equations to achieve efficient verification of neural network computations. Unfortunately, for activation functions and pooling layers, SafetyNets \cite{ghodsi2017safetynets} can only support specific quadratic activation functions and sum pooling, making it relatively impractical. To address this issue, Liu \emph{et al.} proposed zkCNN \cite{liu2021zkcnn}, a zero-knowledge proof scheme for convolutional neural networks based on the GKR protocol, which improves the efficiency of zero-knowledge proofs by optimizing the proof cost of convolution computations in convolutional neural network models. Specifically, zkCNN \cite{liu2021zkcnn} designs a new GKR protocol for verifying fast Fourier transform (FFT) computations and constructs a protocol for two-dimensional convolutions based on FFT, achieving an additional proof time complexity of \(O(n^2)\), faster than the convolution computation itself. In terms of performance, zkCNN is 11.2 times and 213 times faster than vCNN and ZEN on LeNet, respectively. Meanwhile, Fan \cite{fan2023validating}  \emph{et al.} also focused on convolution computation, converting the computation into simple arithmetic expressions in matrix form. For convolution layers, the im2col method is used to represent 3D convolutions as 2D matrices, thus converting convolution computation into equivalent matrix multiplication. Pooling layers also use the im2col method to reduce 3D data to 2D representations. Activation functions ReLU and Softmax are also expressed in the form of matrix multiplication. ReLU is represented as the input matrix multiplied by a matrix with elements 0 or 1, while Softmax is represented as the output matrix multiplied by a vector of exponentials. Additionally, all matrix computations in convolutional neural networks can be optimized using Freivalds' algorithm \cite{freivalds1977probabilistic}, significantly improving the efficiency of setup and proof generation.


Zhan \cite{zhan2024validating} leverages depthwise separable convolutions, Hesamifard's approximate activation function scheme \cite{hesamifard2019deep}, and adaptive average pooling based on specified output sizes to transform convolutional layers, normalization layers, activation layers, and pooling layers into simplified linear arithmetic expressions, while optimizing them according to circuit-specific characteristics. The overall network structure of the large language model is modularized into three components: the head, the backbone, and the tail. To manage the connections between these components, a hash function is introduced, ensuring efficient and seamless integration.


Theoretically, compared to works like SafetyNets \cite{ghodsi2017safetynets} and VeriML \cite{zhao2021veriml}, vCNN \cite{lee2024vcnn} makes certain improvements in the proof of convolution computation. vCNN \cite{lee2024vcnn} extends the original zk-SNARKs scheme based on quadratic arithmetic programs (QAPs) to zk-SNARKs based on quadratic polynomial programs (QPPs) by leveraging the properties of convolution computation. vCNN \cite{lee2024vcnn} uses polynomial expressions of vectors to make the proof of convolution computation more adaptable and efficient. For pooling and activation layers, vCNN \cite{lee2024vcnn} retains the QAP-based zk-SNARK and generates continuity proofs connecting adjacent layers through Committed Proof SNARK (CP-SNARK). Thus, QAP and QPP-based zk-SNARKs prove the correctness of intra-layer computation, while CP-SNARK proves the continuity of each layer's computation, ultimately proving the correctness of the entire convolutional neural network computation.

Inspired by vCNN \cite{lee2024vcnn}, Weng \emph{et al.} further proposed pvCNN \cite{weng2023pvcnn}, a framework for verifiable convolutional neural networks. They proposed a zk-SNARKs scheme based on quadratic matrix programs (QMP) on top of the QPP method in vCNN. pvCNN \cite{weng2023pvcnn} extends the representation capability of wires in the circuit from arrays to matrices and reduces the number of multiplication gates in convolution operations, thus reducing the circuit size and improving efficiency. Additionally, because neural networks are layered, multiple proofs for different inputs of the same CNN layer can be merged into one proof. In terms of performance, this scheme is theoretically compared with SafetyNets\cite{ghodsi2017safetynets}, zkCNN \cite{liu2021zkcnn}, and vCNN \cite{lee2024vcnn}, showing significant improvement in proof time over the aforementioned works. Experimental results also indicate that QMP-based zk-SNARKs are more efficient in convolution operations than QAP-based methods.

zkLLM \cite{sun2024zkllm}  introduces tlookup, which allows parallel lookup of parameters in non-arithmetic tensor operations in deep learning, providing a solution without asymptotic overhead. Lu \cite{lu2024efficient} discards bit decomposition in generating proofs for nonlinear layers, instead converting nonlinear relationships in neural networks into range and exponential relationships, completing the proof of nonlinear layers through range proofs and lookup proofs, achieving about two orders of magnitude reduction. Hao \cite{hao2024scalable} uses table lookup for ZK proofs of nonlinear functions, addressing the challenge of large tables by decomposing inputs with large bit lengths into a fixed number of smaller numbers to obtain smaller tables, and designs modules for number decomposition, comparison, and truncation to effectively utilize table lookup. Compared to Mystique \cite{weng2021mystique}, the protocol achieves a 50 to 179 times improvement in runtime for widely used nonlinear functions in machine learning, such as ReLU, sigmoid, and GELU.

For decision tree models, to verify the output, the prover must first commit to the decision tree and then prove the validity of the verification path to the verifier. However, converting each comparison on the verification path into an arithmetic circuit is very costly. To address this issue, ZKDT \cite{sun2023zkdl} reduces the cost of proof generation by inserting designed sibling nodes on the verification path. Singh  \emph{et al.} proposed a zero-knowledge verifiable scheme for distributed AI pipelines, including a privacy-preserving verification scheme for decision tree inference \cite{singh2022zero}. The distributed AI pipeline assigns different steps of data collection, model training, and model prediction to independent participants, such as data owners, model owners, and model users. Compared to ZKDT \cite{sun2023zkdl}, this scheme avoids costly hash operations by changing the representation and commitment of decision trees. Moreover, by improving access methods in arithmetic circuits, it reduces the access cost of different operations in prediction path verification, further reducing the number of multiplication gates in arithmetic circuits. For decision tree inference tasks, the circuit complexity generated by this scheme is ten times more efficient than zkDT \cite{sun2023zkdl}. Lookup arguments \cite{campanelli2024lookup} encode decision trees as a matrix, and by committing to this matrix encoding, the decision tree is committed. Due to the efficiency characteristics of matrix lookup parameters, the prover's time complexity is independent of the decision tree size, improving proof time by nearly an order of magnitude and verification time by two orders compared to ZKDT.

The goal of improving proof efficiency by optimizing algorithm structure is to reasonably partition the algorithm and apply appropriate proof strategies to proportionally enhance proof efficiency. For example, verifying only a portion of the rounds during the training process can reduce the number of proofs generated. Since the same process is iterated multiple times during training, VeriML chooses to use a few rounds of the training process as a challenge for verification, thereby reducing proof costs. By pre-storing inputs and outputs of some iterations during training and committing to them, the prover can retrieve specified iterations and generate proofs of their computation process as required by the verifier. Some small optimizations are proposed for the six machine learning models supported by VeriML to improve proof efficiency. Additionally, VeriML uses an on-chain protocol to protect the confidentiality of trained models for fair transactions.

Hydra \cite{zhang2021hydra} uses the GKR protocol to compute sub-circuits split from the original circuit. Through a polynomial commitment scheme, Hydra simplifies the proof process. Meanwhile, since sub-circuits are independent of each other, they can be generated and verified in parallel, improving efficiency. Additionally, a bottom-up quantization algorithm is proposed to reduce the impact of integration on accuracy. Compared to SafetyNets, the Hydra protocol improves efficiency on neural networks by four times.

Lycklama \cite{lycklama2024artemis} also addresses the challenges in commitment schemes, proposing two novel methods, Apollo and Artemis, to mitigate the significant overhead associated with committing to models and data. Apollo streamlines the construction process by minimally adapting the arithmetization of the witness within the SNARK framework, whereas Artemis is designed to support any homomorphic polynomial commitment scheme. For the VGG model, this work achieves a substantial reduction in the overhead of commitment checks, lowering it from 11.5x to 1.2x.


zkMLaaS \cite{huang2022zkmlaas} focuses on addressing the issue of input data volume and adopts the idea of random sampling. By randomly selecting and challenging committed epochs and iteration numbers, proof costs are proportionally reduced, similar to VeriML. Regarding convolution operations in CNNs, the optimization idea is similar to the method proposed by Fan  \emph{et al. }\cite{fan2023validating}. The im2col algorithm is applied to convert convolutions into matrix multiplications, and Freivalds' algorithm is further used to reduce the overhead of matrix multiplication. Compared to directly using zk-SNARKs, zkMLaaS saves approximately 273 times the proof overhead.


\section{Commercial Applications of ZKML}\label{s:4}

Currently, some projects and companies have already begun using ZKML technology to protect the privacy and security of data for machine learning. This section introduces several companies and projects that have explored and implemented ZKML in practice.

EZKL \cite{cryptoeprint:2020:352} is a library and command line tool for doing inference for deep learning models using zk-SNARK. With EZKL, we first define a neural network model in Pytorch or TensorFlow, and then export the model as an ONNX file with some sample inputs in a JSON file, and finally apply EZKL to these files to generate a zk-SNARK circuit. With the latest round of performance improvements, EZKL can prove a MNIST-sized model in about 2 seconds and takes up 700MB of memory. So far, EZKL has been used as infrastructure in several hackathon projects, showing significant early adoption.

Coda \cite{bonneau2020coda} was the first cryptocurrency protocol with a clean blockchain. Current cryptocurrencies such as Bitcoin and Ether store hundreds of gigabytes of data, which will only grow larger over time. For Coda, however, no matter how much usage grows, the stored data always remains the same size, around 20 KB. By utilizing recursive zk-SNARK, Coda block producers can quickly share proofs of the correct blockchain state across the network and easily update the proofs as new transactions occur. This breakthrough application of zero-knowledge proofs enables Coda to provide scalability for thousands of transactions per second, millions of users, and years of transaction history without sacrificing security.

The DeFiChain\cite{DeFiChain} platform uses ZKML technology to validate the accuracy of AI models used for fraud detection and credit risk assessment without revealing any user data. DeFiChain uses zk-SNARKs to generate cryptographic proofs that their AI models produce accurate risk assessments. This process can be done without revealing the inner workings of the model, such as coefficients in logistic regression or decision trees in random forests, and assuring users that the model is working properly.

Modulus Labs\cite{ModulusXYZ} demonstrated ZKML use cases with RockyBot (an on-chain trading bot) and Leela vs. the World (a chess game). In particular, RockyBot is the world's first fully on-chain AI trading bot, which brilliantly uses AI/ML for asset management. rockyBot uses the zk-SNARKs technique to demonstrate that the bot's trading decisions agree with the predictions of trained Recurrent Neural Networks (RNN) and Long Short-Term Memory (LSTM) models. In the Leela vs. the World game, everyone can play against a verified on-chain instance of the Leela chess engine. The team has also written a paper \cite{moduluslabs2023cost} that benchmarks the speed and efficiency of various proving systems with different model sizes.

Giza \cite{Giza} is a protocol that allows AI models to be deployed on-chain using a completely trustless approach. The technology stack used by Giza consists of the following four: 1) the ONNX format for representing machine learning models, 2) the Giza Transpiler for converting these models into the Cairo program format, 3) ONNX Cairo Runtime for executing the models in a verifiable and deterministic way, and 4) Giza Model smart contracts for deploying and executing models on the chain.

ZKaptcha \cite{zkaptcha} focuses on the problem of bots in web3 to provide CAPTCHA services for smart contracts. The current implementation of the project allows end users to generate proof that it is a human operation by completing a CAPTCHA. The CAPTCHA is validated by an on-chain validator and accessed through a smart contract. Currently, ZKaptcha relies primarily only on ZKP, but there are plans to implement ZKML in the future, similar to existing web2 CAPTCHA services. These services can analyze behaviors such as mouse movements to determine if a user is human, rather than a bot.

\section{Future Directions of ZKML}\label{s:5}

With the rapid development of ZKML technology, the future research and application directions present a broad prospect. Combining the current research status and technical challenges of ZKML, we conclude the following possible development directions:

\begin{itemize}
    \item \textbf{Improve computational efficiency and scalability:} Although existing ZKML frameworks have been able to handle simple machine learning models, computational efficiency and scalability are still key bottlenecks when dealing with large-scale deep neural networks, multimodal models, and generative models. Future research should focus on optimizing zero-knowledge proof protocols to support efficient proof generation and verification for large-scale computational tasks. For example, novel recursive proof systems, optimized arithmetic circuit designs, and the development of specific ZK protocols suitable for deep learning can be explored. This will pave the way for large-scale deployment of ZKML in real-world applications.
    
    \item \textbf{Optimize generalization and practicality:} Multiple hurdles still need to be crossed to move ZKML technology from theoretical research to practical applications. Future research can be devoted to developing more practical ZKML tools and platforms, lowering the threshold of development and application, and making it widely used in various industries. For example, finance, healthcare, cryptocurrency, supply chain and other fields have a high demand for data privacy and security, and ZKML has a broad application prospect in these fields. Further research on how to integrate ZKML technology into existing machine learning frameworks to enhance its operability in industry is key to advancing this field.
    
    \item \textbf{Support for diverse and complex machine learning models:} As machine learning models continue to become more complex, ZKML needs to extend the range of models it supports, especially emerging machine learning paradigms such as multimodal models, generative models, and self-supervised learning models. Future research could explore how to efficiently verify the correctness of these complex models in a zero-knowledge proof framework. For example, developing special proof techniques for generative models or zero-knowledge proof works for multimodal fusion. In addition, self-supervised and unsupervised learning models with complex loss functions and iterative and diverse optimization processes need to be better supported in ZKML.
    
    \item \textbf{Enhance privacy protection and security:} Privacy protection is one of the core goals of ZKML, and future research needs to further enhance the privacy protection of models and data while ensuring the security of the models. Currently, most of the research focuses on privacy protection in the inference phase, and future research should also focus on privacy protection in the training phase as well as comprehensive protection of the entire machine learning pipeline. For example, research can be conducted on how to verify the correctness of the model training process while maintaining model privacy, or combine techniques such as homomorphic encryption and multi-party secure computation to enhance the security of models and data. In addition, the defense capability of the model against adversarial attacks should be strengthened by detecting adversarial samples through zero-knowledge proof techniques to ensure that the model maintains stable and trustworthy performance in the face of malicious attacks, thus enhancing the overall security of the model while protecting privacy.
\end{itemize}

\section{Conclusions}\label{s:6}
This survey comprehensively investigates existing ZKML works. First, we introduce the backgrounds on machine learning and zero-knowledge proofs, followed by an exploration of zero-knowledge proof-based verifiable machine learning (ZKML). We place special emphasis on the unique advantages of zero-knowledge proof techniques over other cryptographic methods in terms of protecting privacy and verifying the computational correctness of machine learning. Subsequently, we categorize ZKML works according to the different stages of the machine learning process and the associated verification goals, while reviewing the current state of the art in research. We also discuss several commercial applications of ZKML. Finally, we propose future directions for the development of ZKML, with a particular focus on enhancing computational efficiency and scalability, optimizing performance, expanding application ranges, and improving privacy protection and security. These discussions and analyses of ZKML provide valuable insights and guidance for both academia and industry.

% References
\bibliographystyle{IEEEtran}
\bibliography{ref.bib}



\end{document}
