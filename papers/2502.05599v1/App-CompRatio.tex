\section{Proof of Lemma \ref{lem:order}}
\begin{proof}
Without loss of generality, let all $\frac{ \sfv_k}{r_k}$ be distinct.
  Let the statement be false, and in particular in the optimal solution $\bq$ there exists a $k'$ (in order) for which $q_{k'} < 1$  but $q_{k'+1} > 0$. We will contradict to the optimality of $\bq$ by creating a new solution with larger objective function while satisfying the constraint. Consider a new solution ${\hat \bq}$ where we keep all 
  $q_k$'s the same other than $q_{k'}$ and $q_{k'+1}$ which are changed to ${\hat q}_{k'} = q_{k'}+q_{k'+1} \frac{r_{k'+1}}{r_{k'}}$ and ${\hat q}_{k'+1}=0$. Clearly, ${\hat \bq}$ satisfies the constraint. However, the change in objective function value (going from $\bq$ to $\hat \bq$) is 
  $$q_{k'+1}r_{k'+1} \left( \frac{\sfv_{k'}}{r_{k'}} - \frac{\sfv_{k'+1}}{r_{k'+1}}\right) >0,$$ since $\frac{\sfv_{k'}}{r_{k'}} > \frac{\sfv_{k'+1}}{r_{k'+1}}$ by definition.
  Thus, $\bq$ cannot be optimal.
\end{proof}

\section{Proof of Theorem \ref{proof:learn1}}
\begin{proof}
Since all the parameters of $\cP_{\text{light}}$ are expected values of i.i.d. random variables that are estimated using sample mean estimator $\frac{1}{n}\sum_{i=1}^n X_i$, from Chernoff bound, we have 
$ \bbP\left( \left | \frac{1}{n}\sum_{i=1}^n X_i - \bbE\{X_1\} \right | > \epsilon\right) \le \exp^{ -(2n \epsilon^2)}$.
Thus, we get that dedicating $T/2$ slots for learning, the probability that any of parameters of $\cP_{\text{light}}$ deviate from their means by more than $O(\log(1/\delta)/\sqrt{T})$ is at most $K \delta$ (union bound).

Once the learning is complete at the end of the $T/2^{th}$ slot, \textsf{Learn-Alg} employs the optimal solution (Lemma \ref{lem:order}) assuming all the parameters 
of $\cP_{\text{light}}$ are known exactly. However, since the parameters of $\cP_{\text{light}}$ are learnt, there is always a residual error, and hence we appeal next to the sensitivity analysis \cite{boyd2004convex} of LPs, which deals with the effect of perturbation of parameters/constraints on the optimal LP solution.
From [Section 5.6.3 \cite{boyd2004convex}], for LPs (where strong duality holds, which is true in our case since \eqref{eq:optprob} is feasible and bounded), choosing $\delta = 1/T$, we get that  the solution obtained by \textsf{Learn-Alg} satisfies
  $$\frac{ \bbE\left\{\ \sum_{t=T/2+1}^T v_t x_t(b^\cA_t)\right\} }{ \bbE\left\{\ \sum_{t=T/2+1}^T v_t x_t(b^\opt_t)\right\} }\ge (1-O(K\log(1/\delta)/\sqrt{T})) ,$$ 
  since when random variables are well estimated within an error of $O(\log(1/\delta)/\sqrt{T})$, the value accrued by algorithm \textsf{Learn-Alg} is within $(1-O(K\log(1/\delta)/\sqrt{T}))$ fraction of that of $\opt$, while otherwise, 
 the value accrued by algorithm \textsf{Learn-Alg} is at least $0$.
% can be $O(1)$ while that of $\opt$ can be $O(T/2)$ in $T/2$ slots.
  
  Since the input is i.i.d., $\bbE\left\{\ \sum_{t=1}^T v_t x_t(b^\opt_t)\right\} = 2 \bbE\left\{\ \sum_{t=T/2+1}^T v_t x_t(b^\opt_t)\right\}.$
  Thus, we get that $\text{c.r.}_{\text{\textsf{Learn-Alg}}} \ge 1/2 -(1-O(K\log(1/\delta)/\sqrt{T}))$.
  Recall that until slot $T/2$, $b_t=v_t$, thus \textsf{Learn-Alg} satisfies the ROSC until slot $T/2$ following Section \ref{sec:warmup}.
  Moreover, for $t>T/2$, the solution output by \textsf{Learn-Alg}  satisfies the ROSC with probability $1-(1-O(K\log(1/\delta)/\sqrt{T}))$. 
\end{proof}