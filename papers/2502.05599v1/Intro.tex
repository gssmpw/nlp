\section{Introduction}
In this paper, we consider the {\it auto-bidding} problem, an important example of online optimization under time varying constraints, that is relevant for many resource allocation settings, especially for online advertising. 
With auto-bidding, in each time slot $t$, an auction is conducted, where 
an ad-query defined by a three-tuple, {\it value} $v_t$, {\it allocation function} $x_t(.)$ and {\it payment function} $p_t(.)$ is generated that is independent and identically distributed (i.i.d.) with some unknown distribution. 
Allocation function $x_t(b_t)$ is essentially the probability of winning the auction in slot $t$ depending on the bid value $b_t$. 
Corresponding to the allocation function is the expected payment $p_t$ that the bidder has to pay if allocation function is non-zero for the submitted bid. Both the allocation and payment functions are assumed to be monotonic. 
% and is required to be {\it truthful}, i.e., satisfies \eqref{eq:myersontruthfulcond}. E.g. the second-price auction is truthful.

In each slot, a single auto-bidder gets to see only the value  and is asked to bid, while the allocation and payment functions remains {\bf hidden}. 
Once the bid is submitted, the bidder receives the outcome of the auction: the hidden allocation function and the required payment. The realized value for the bidder in a slot is the product of the {\it value} and the {\it allocation function} evaluated at the submitted bid for that slot. 
Because of financial considerations, a typical return-on-spend  constraint (ROSC) is imposed that requires that the {\it total expected realized value summed across all slots} should be at least as much as the {\it total expected payment made across all slots}. 

The optimization problem is to maximize the total expected realized value summed across all slots subject to the ROSC. The problem is {\it online}, since at any time slot an online algorithm can only use the revealed value of that slot, and all the past information. Regret
$\cR_\cA(T)$ quantifies the performance of any online algorithm $\cA$, defined as the expected difference between the total realized value of an optimal offline algorithm $\opt$ and  $\cA$, over a time horizon of $T$ slots.

Auto-bidding is the dominant model in online advertising \cite{balseiro2019learning, aggarwal2019autobidding, babaioff2020non, golrezaei2021auction, deng2021towards, balseiro2021robust, balseiro2021landscape}, where auto-bidders are deployed on behalf of advertisers to win ad-slots on webpages.
Once a user arrives on a webpage, the effective value of showing an ad to that user is some fixed basic value (intrinsic to the user) multiplied by the probability of an advertiser winning that auction depending on its bid, and the associated payment rule that is required to be truthful for maintaining 
incentive compatibility.

\vspace{-0.1in}
\subsection{Prior Work}
Single learner auto-bidding problem has been considered quite extensively in literature, but one allowance that is almost universally made is accepting some violation of the ROSC. For example, in \cite{Feng}, an algorithm with $\cR(T) = O(\sqrt{T})$ is proposed but it violates the ROSC by an amount  $O(\sqrt{T\log T})$. Prior to this, \cite{castiglioni2022unifying} derived an algorithm with $\cR(T) =O(T^{3/4})$ together with $O(T^{3/4})$ ROSC violation. For a slightly different objective function of $(v_t-s_t)$ at time $t$, where $s_t$ is the second largest bid at time $t$ from other bidders, and both $v_t,s_t$ are generated i.i.d., \cite{golrezaei2021bidding} derives a threshold based algorithm with $\cR(T) = O(T^{2/3})$ and satisfies the ROSC. In addition to ROSC, additional constraint on total payment made 
has also been considered in \cite{Feng, castiglioni2022unifying, golrezaei2021bidding}. 
Related to auto-bidding problem is the online allocation problem \cite{balseiro2020dual}, that only has budget constraints and no ROSC.
%where requests arrive sequentially during a finite horizon
%and, for each request, a decision maker needs to
%choose an action that consumes a certain amount
%of resources and generates revenue. The revenue
%function and resource consumption of each request are drawn i.i.d. with an independently and at random
% unknown distribution. The objective is to maximize
%cumulative revenues subject to a constraint on the
%total consumption of resources.


More complicated auto-bidding models \cite{borgs2007dynamics, golrezaei2021auction, chen2023complexity, lucier2024autobidders} 
have also been studied where multiple agents compete directly, however, always following a second-price auction, for which $O(\sqrt{T})$ regret and ROSC satisfaction with high probability are known. 


\vspace{-0.1in}
\subsection{Related Problems} 
In constrained online convex optimization (COCO), on each round, the online policy first chooses an action, and then the adversary reveals a convex cost function and multiple convex constraints. Since constraints are revealed after the action has been chosen, no policy can satisfy the constraints exactly, and hence
in addition to regret, cumulative constraint violation (CCV) is a relevant performance metric. COCO has been studied with both 
 stochastic \cite{mannor2009online, mahdavi2013stochastic, yu2017online, badanidiyuru2018bandits} as well as worst case input \cite{yu2016low, guo2022online, sinha2024optimalalgorithmsonlineconvex}, where simultaneous regret and CCV bounds are derived.
%$x_t \in \mathcal{X}$ 
% and then the adversary chooses a convex cost function $f_t: \mathcal{X} \to \mathbb{R}$ and $k$ constraints of the form $g_{t,i}(x) \leq 0, \ i=1,\dots,k$ where $g_{t,i}: \mathcal{X} \to \mathbb{R}$ is a convex function. Since $g_{t, i}$'s are revealed after the action $x_t$ is chosen, any online policy need not necessarily take feasible actions, and the obvious metric of interest in addition to the regret ($ \max_{f_t, x^\star} \textrm{Regret}_T(x^\star) \equiv \sum_{t=1}^T f_t(x_t) - \sum_{t=1}^T f_t(x^\star)$, is the total cumulative constraint violation (CCV) $\mathbb{V}(T)$ defined as $\mathbb{V}(T) = \max_{i, i=1,\dots, k} \sum_{t=1}^T \max(g_{t,i}(x_t),0)$.  
 %The best known results for COCO with worst case input are simultaneous $O(\sqrt{T})$ regret and $O(\sqrt{T})$ CCV with a matching lower bound \cite{sinha2024optimalalgorithmsonlineconvex}. 
Compared to COCO, with auto-bidding,  value $v_t$ is revealed before action is taken and the input is i.i.d.
 
 Other related models of online optimization with constraints have also been studied, e.g. \cite{agrawal2014fast}, where at each slot a discrete set of vectors are revealed, and an algorithm has to choose one of them with the goal of minimizing a (pre-specified) loss function evaluated at the average of the chosen vectors, subject to the average of the chosen vectors to lie in a (pre-specified) convex region. Similar to COCO, simultaneous regret and constraint violation bounds are derived in \cite{agrawal2014fast}.
 
{\bf Knapsack Problem:} The auto-bidding problem is closely related to an interesting variant (unstudied as far as we know) of the usual online knapsack problem \cite{vaze2023online}, where on an item's arrival, only its value is revealed 
but the size (it occupies) is hidden. An algorithm is allowed to advertise the maximum size it is willing to accept knowing the value, and if the size is at most the advertised size, the item is accepted.
If the input is worst-case, it is not difficult to see that for this variant of the knapsack problem, the competitive ratio of any online algorithm is unbounded. Thus, the auto-bidding problem's special structure and the i.i.d. input makes it amenable for non-trivial analysis. Knapsack problem with unknown but fixed capacities has been studied \cite{disser2017packing}, but not under  above constraints. 

{\bf Resource Allocation:} The single auto-bidder problem is essentially a resource allocation problem,
where a decision maker needs to
choose an action that consumes a certain amount
of resources and generates utility/revenue. The revenue
function and resource consumption of each request are drawn i.i.d. from an unknown distribution. 
The objective is to maximize
cumulative revenue subject to some constraint on the total consumption of resources. 
Thus, the considered problem is relevant for very general settings that include 
inventory management for hotels and airlines with limited resources \cite{talluri1998analysis}, buying energy/power under 
i.i.d. demand and pricing \cite{yang2019online}, etc.

\vspace{-.2in}
\subsection{Our Contributions}
In this paper, we consider the single auto-bidding problem with i.i.d. input, where in contrast to prior work that allowed ROSC 
violation, the main object of interest  is the characterization of achievable regret under strict ROSC satisfaction. Towards that end, our contributions are as follows.
\begin{itemize}
\item We show a {\bf major negative result} that the regret of any online algorithm that strictly satisfies the ROSC is $\Omega(T)$. Thus imposing strict ROSC satisfaction makes 
all online algorithms `weak' for auto-bidding, and to {\bf get sub-linear regret, ROSC has to be violated}. What is the best simultaneous regret and ROSC violation that any online algorithm can achieve remains an open question. $O(\sqrt{T})$ regret and $O(\sqrt{T \log T})$ are currently the best known simultaneously achievable regret and ROSC violation bound \cite{Feng}.
\item For the case of repeated identical auction when value ($v_t$) revealed in each slot is a constant, we show that the sum of the regret and the ROSC 
violation for any online algorithm is $\Omega(\sqrt{T})$. This implies that  the regret of any online algorithm that strictly satisfies the ROSC is $\Omega(\sqrt{T})$.
\item We show that the best known algorithm \cite{Feng} for the considered auto-bidding problem which violates the ROSC by at most $O(\sqrt{T\log T})$ has regret $\Omega(\sqrt{T})$ even for repeated identical auction. Thus the $O(\sqrt{T})$ regret bound of \cite{Feng} is tight.

\item For the repeated identical auction when value ($v_t$) revealed in each slot is a constant, we propose a simple algorithm that satisfies the ROSC on a sample path basis and show that its regret is at most $O(\sqrt{T \log T})$ for a specific class of allocation and payment functions under some mild assumptions. As far as we know, this is first such result.

%is an important object of future work. 
\item Since achieving sub-linear regret is not possible for auto-bidding when $v_t\ne v_{t'}$,  
we consider the metric of competitive ratio and propose an algorithm with competitive ratio close to $1/2$.
\end{itemize}


