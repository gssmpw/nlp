@misc{akyürek2023rl4f,
      title={RL4F: Generating Natural Language Feedback with Reinforcement Learning for Repairing Model Outputs}, 
      author={Afra Feyza Akyürek and Ekin Akyürek and Aman Madaan and Ashwin Kalyan and Peter Clark and Derry Wijaya and Niket Tandon},
      year={2023},
      eprint={2305.08844},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{bianchisafety,
  title={Safety-Tuned LLaMAs: Lessons From Improving the Safety of Large Language Models that Follow Instructions},
  author={Bianchi, Federico and Suzgun, Mirac and Attanasio, Giuseppe and Rottger, Paul and Jurafsky, Dan and Hashimoto, Tatsunori and Zou, James},
  booktitle={The Twelfth International Conference on Learning Representations},
  year=2024
}

@article{bommasani2021opportunities,
  title={On the opportunities and risks of foundation models},
  author={Bommasani, Rishi and Hudson, Drew A and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and others},
  journal={arXiv preprint arXiv:2108.07258},
  year={2021}
}

@inproceedings{chengaining,
  title={Gaining Wisdom from Setbacks: Aligning Large Language Models via Mistake Analysis},
  author={Chen, Kai and Wang, Chunwei and Yang, Kuo and Han, Jianhua and Lanqing, HONG and Mi, Fei and Xu, Hang and Liu, Zhengying and Huang, Wenyong and Li, Zhenguo and others},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024}
}

@article{kopf2024openassistant,
  title={Openassistant conversations-democratizing large language model alignment},
  author={K{\"o}pf, Andreas and Kilcher, Yannic and von R{\"u}tte, Dimitri and Anagnostidis, Sotiris and Tam, Zhi Rui and Stevens, Keith and Barhoum, Abdullah and Nguyen, Duc and Stanley, Oliver and Nagyfi, Rich{\'a}rd and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{nozawa2021understanding,
  title={Understanding negative samples in instance discriminative self-supervised representation learning},
  author={Nozawa, Kento and Sato, Issei},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={5784--5797},
  year={2021}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@inproceedings{qi2024fine,
  title={Fine-tuning Aligned Language Models Compromises Safety, Even When Users Do Not Intend To!},
  author={Qi, Xiangyu and Zeng, Yi and Xie, Tinghao and Chen, Pin-Yu and Jia, Ruoxi and Mittal, Prateek and Henderson, Peter},
  booktitle={International Conference on Learning Representations},
  year={2024}
}

@article{stiennon2020learning,
  title={Learning to summarize with human feedback},
  author={Stiennon, Nisan and Ouyang, Long and Wu, Jeffrey and Ziegler, Daniel and Lowe, Ryan and Voss, Chelsea and Radford, Alec and Amodei, Dario and Christiano, Paul F},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={3008--3021},
  year={2020}
}

@article{sun2024principle,
  title={Principle-driven self-alignment of language models from scratch with minimal human supervision},
  author={Sun, Zhiqing and Shen, Yikang and Zhou, Qinhong and Zhang, Hongxin and Chen, Zhenfang and Cox, David and Yang, Yiming and Gan, Chuang},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{tian2020makes,
  title={What makes for good views for contrastive learning?},
  author={Tian, Yonglong and Sun, Chen and Poole, Ben and Krishnan, Dilip and Schmid, Cordelia and Isola, Phillip},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={6827--6839},
  year={2020}
}

@inproceedings{wan2023poisoning,
  title={Poisoning language models during instruction tuning},
  author={Wan, Alexander and Wallace, Eric and Shen, Sheng and Klein, Dan},
  booktitle={International Conference on Machine Learning},
  pages={35413--35425},
  year={2023},
  organization={PMLR}
}

@article{wang2022self,
  title={Self-instruct: Aligning language models with self-generated instructions},
  author={Wang, Yizhong and Kordi, Yeganeh and Mishra, Swaroop and Liu, Alisa and Smith, Noah A and Khashabi, Daniel and Hajishirzi, Hannaneh},
  journal={Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={13484--13508},
  year={2023}
}

@article{wang2024learning,
  title={Learning From Failure: Integrating Negative Examples when Fine-tuning Large Language Models as Agents},
  author={Wang, R and Li, H and Han, X and others},
  journal={arXiv preprint arXiv:2402.11651},
  year={2024}
}

@inproceedings{welleck2020neural,
  title={NEURAL TEXT DEGENERATION WITH UNLIKELIHOOD TRAINING},
  author={Welleck, Sean and Kulikov, Ilia and Roller, Stephen and Dinan, Emily and Cho, Kyunghyun and Weston, Jason},
  booktitle={8th International Conference on Learning Representations, ICLR 2020},
  year={2020}
}

@article{wu2024fine,
  title={Fine-grained human feedback gives better rewards for language model training},
  author={Wu, Zeqiu and Hu, Yushi and Shi, Weijia and Dziri, Nouha and Suhr, Alane and Ammanabrolu, Prithviraj and Smith, Noah A and Ostendorf, Mari and Hajishirzi, Hannaneh},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{zhao2023survey,
  title={A survey of large language models},
  author={Zhao, Wayne Xin and Zhou, Kun and Li, Junyi and Tang, Tianyi and Wang, Xiaolei and Hou, Yupeng and Min, Yingqian and Zhang, Beichen and Zhang, Junjie and Dong, Zican and others},
  journal={arXiv preprint arXiv:2303.18223},
  year={2023}
}

