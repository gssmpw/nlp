@inproceedings{GeneticAlgorithmsSharing1987,
    title = {Genetic Algorithms with Sharing for Multimodal Function Optimization},
    booktitle = {Genetic Algorithms and their Applications: Proceedings of the Second International Conference on Genetic Algorithms},
    author = {Goldberg, David E. and Richardson, Jon},
    year = {1987},
    pages = {41--49}
}

@inproceedings{alps,
    author = {Hornby, Gregory S.},
    title = {ALPS: the age-layered population structure for reducing the problem of premature convergence},
    year = {2006},
    isbn = {1595931864},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/1143997.1144142},
    doi = {10.1145/1143997.1144142},
    abstract = {To reduce the problem of premature convergence we define a new method for measuring an individual's age and propose the Age-Layered Population Structure (ALPS). This new measure of age measures how long the genetic material has been evolving in the population: offspring start with an age of 1 plus the age of their oldest parent instead of starting with an age of 0 as with traditional measures of age. ALPS differs from a typical evolutionary algorithm (EA) by segregating individuals into different age-layers by their age and by regularly introducing new, randomly generated individuals in the youngest layer. The introduction of randomly generated individuals at regular intervals results in an EA that is never completely converged and is always exploring new parts of the fitness landscape. By using age to restrict competition and breeding, younger individuals are able to develop without being dominated by older ones. Analysis of the search behavior of ALPS finds that the offspring of individuals that are randomly generated mid-way through a run are able to move the population out of mediocre local-optima to better parts of the fitness landscape. In comparison against a traditional EA, a multi-start EA and two other EAs with diversity maintenance schemes we find that ALPS produces significantly better designs with a higher reliability than the other EAs.},
    booktitle = {Proceedings of the 8th Annual Conference on Genetic and Evolutionary Computation},
    pages = {815–822},
    numpages = {8},
    keywords = {age, computer-automated design, evolutionary algorithms, open-ended design, premature convergence},
    location = {Seattle, Washington, USA},
    series = {GECCO '06}
}

@inproceedings{boldi2024solving,
  title={Solving Deceptive Problems Without Explicit Diversity Maintenance},
  author={Boldi, Ryan and Ding, Li and Spector, Lee},
  booktitle={Proceedings of the Genetic and Evolutionary Computation Conference Companion},
  pages={171--174},
  year={2024}
}

@article{csc,
  author={Grillotti, Luca and Cully, Antoine},
  journal={IEEE Transactions on Evolutionary Computation}, 
  title={Unsupervised Behavior Discovery With Quality-Diversity Optimization}, 
  year={2022},
  volume={26},
  number={6},
  pages={1539-1552},
  keywords={Containers;Robots;Magnetosphere;Ion radiation effects;Robot sensing systems;Task analysis;Optimization;Behavioral diversity;optimization methods;quality-diversity (QD) optimization;robotics;unsupervised learning},
  doi={10.1109/TEVC.2022.3159855},
}

@inproceedings{cully_AutonomousSkillDiscovery_2019,
	address = {New York, NY, USA},
	series = {{GECCO} '19},
	title = {Autonomous skill discovery with quality-diversity and unsupervised descriptors},
	isbn = {978-1-4503-6111-8},
	url = {https://doi.org/10.1145/3321707.3321804},
	doi = {10.1145/3321707.3321804},
	abstract = {Quality-Diversity optimization is a new family of optimization algorithms that, instead of searching for a single optimal solution to solving a task, searches for a large collection of solutions that all solve the task in a different way. This approach is particularly promising for learning behavioral repertoires in robotics, as such a diversity of behaviors enables robots to be more versatile and resilient. However, these algorithms require the user to manually define behavioral descriptors, which is used to determine whether two solutions are different or similar. The choice of a behavioral descriptor is crucial, as it completely changes the solution types that the algorithm derives. In this paper, we introduce a new method to automatically define this descriptor by combining Quality-Diversity algorithms with unsupervised dimensionality reduction algorithms. This approach enables robots to autonomously discover the range of their capabilities while interacting with their environment. The results from two experimental scenarios demonstrate that robot can autonomously discover a large range of possible behaviors, without any prior knowledge about their morphology and environment. Furthermore, these behaviors are deemed to be similar to hand-crafted solutions that uses domain knowledge and significantly more diverse than when using existing unsupervised methods.},
	urldate = {2025-01-07},
	booktitle = {Proceedings of the {Genetic} and {Evolutionary} {Computation} {Conference}},
	publisher = {Association for Computing Machinery},
	author = {Cully, Antoine},
	month = jul,
	year = {2019},
	pages = {81--89},
}

@article{deb2002fast,
    title={A fast and elitist multiobjective genetic algorithm: NSGA-II},
    author={Deb, Kalyanmoy and Pratap, Amrit and Agarwal, Sameer and Meyarivan, TAMT},
    journal={IEEE transactions on evolutionary computation},
    volume={6},
    number={2},
    pages={182--197},
    year={2002},
    publisher={IEEE}
}

@inproceedings{helmuth2016effects,
    title={Effects of lexicase and tournament selection on diversity recovery and maintenance},
    author={Helmuth, Thomas and McPhee, Nicholas Freitag and Spector, Lee},
    booktitle={Proceedings of the 2016 on Genetic and Evolutionary Computation Conference Companion},
    pages={983--990},
    year={2016}
}

@article{helmuth_solving_2015,
	title = {Solving {Uncompromising} {Problems} {With} {Lexicase} {Selection}},
	volume = {19},
	issn = {1089-778X, 1089-778X, 1941-0026},
	url = {http://ieeexplore.ieee.org/document/6920034/},
	doi = {10.1109/TEVC.2014.2362729},
	abstract = {We describe a broad class of problems, called “uncompromising problems,” characterized by the requirement that solutions must perform optimally on each of many test cases. Many of the problems that have long motivated genetic programming research, including the automation of many traditional programming tasks, are uncompromising. We describe and analyze the recently proposed “lexicase” parent selection algorition and show that it can facilitate the solution of uncompromising problems by genetic programming. Unlike most traditional parent selection techniques, lexicase selection does not base selection on a ﬁtness value that is aggregated over all test cases; rather, it considers test cases one at a time in random order. We present results comparing lexicase selection to more traditional parent selection methods, including standard tournament selection and implicit ﬁtness sharing, on four uncompromising problems: ﬁnding terms in ﬁnite algebras, designing digital multipliers, counting words in ﬁles, and performing symbolic regression of the factorial function. We provide evidence that lexicase selection maintains higher levels of population diversity than other selection methods, which may partially explain its utility as a parent selection algorithm in the context of uncompromising problems.},
	language = {en},
	number = {5},
	urldate = {2023-08-24},
	journal = {IEEE Transactions on Evolutionary Computation},
	author = {Helmuth, Thomas and Spector, Lee and Matheson, James},
	month = oct,
	year = {2015},
	pages = {630--643},
}

@article{hfc,
    author = {Hu, Jianjun and Goodman, Erik and Seo, Kisung and Fan, Zhun and Rosenberg, Rondal},
    title = {The Hierarchical Fair Competition (HFC) Framework for Sustainable Evolutionary Algorithms},
    year = {2005},
    issue_date = {June 2005},
    publisher = {MIT Press},
    address = {Cambridge, MA, USA},
    volume = {13},
    number = {2},
    issn = {1063-6560},
    url = {https://doi.org/10.1162/1063656054088530},
    doi = {10.1162/1063656054088530},
    abstract = {Many current Evolutionary Algorithms (EAs) suffer from a tendency to converge prematurely or stagnate without progress for complex problems. This may be due to the loss of or failure to discover certain valuable genetic material or the loss of the capability to discover new genetic material before convergence has limited the algorithm's ability to search widely. In this paper, the Hierarchical Fair Competition (HFC) model, including several variants, is proposed as a generic framework for sustainable evolutionary search by transforming the convergent nature of the current EA framework into a non-convergent search process. That is, the structure of HFC does not allow the convergence of the population to the vicinity of any set of optimal or locally optimal solutions. The sustainable search capability of HFC is achieved by ensuring a continuous supply and the incorporation of genetic material in a hierarchical manner, and by culturing and maintaining, but continually renewing, populations of individuals of intermediate fitness levels. HFC employs an assembly-line structure in which subpopulations are hierarchically organized into different fitness levels, reducing the selection pressure within each subpopulation while maintaining the global selection pressure to help ensure the exploitation of the good genetic material found. Three EAs based on the HFC principle are tested - two on the even-10-parity genetic programming benchmark problem and a real-world analog circuit synthesis problem, and another on the HIFF genetic algorithm (GA) benchmark problem. The significant gain in robustness, scalability and efficiency by HFC, with little additional computing effort, and its tolerance of small population sizes, demonstrates its effectiveness on these problems and shows promise of its potential for improving other existing EAs for difficult problems. A paradigm shift from that of most EAs is proposed: rather than trying to escape from local optima or delay convergence at a local optimum, HFC allows the emergence of new optima continually in a bottom-up manner, maintaining low local selection pressure at all fitness levels, while fostering exploitation of high-fitness individuals through promotion to higher levels.},
    journal = {Evol. Comput.},
    month = jun,
    pages = {241–277},
    numpages = {37}
}

@article{lehman_AbandoningObjectivesEvolution_2011,
	title = {Abandoning {Objectives}: {Evolution} {Through} the {Search} for {Novelty} {Alone}},
	volume = {19},
	issn = {1063-6560, 1530-9304},
	shorttitle = {Abandoning {Objectives}},
	url = {https://direct.mit.edu/evco/article/19/2/189-223/1365},
	doi = {10.1162/EVCO_a_00025},
	abstract = {In evolutionary computation, the ﬁtness function normally measures progress towards an objective in the search space, effectively acting as an objective function. Through deception, such objective functions may actually prevent the objective from being reached. While methods exist to mitigate deception, they leave the underlying pathology untreated: Objective functions themselves may actively misdirect search towards dead ends. This paper proposes an approach to circumventing deception that also yields a new perspective on open-ended evolution: Instead of either explicitly seeking an objective or modeling natural evolution to capture open-endedness, the idea is to simply search for behavioral novelty. Even in an objective-based problem, such novelty search ignores the objective. Because many points in the search space collapse to a single behavior, the search for novelty is often feasible. Furthermore, because there are only so many simple behaviors, the search for novelty leads to increasing complexity. By decoupling open-ended search from artiﬁcial life worlds, the search for novelty is applicable to real world problems. Counterintuitively, in the maze navigation and biped walking tasks in this paper, novelty search signiﬁcantly outperforms objective-based search, suggesting the strange conclusion that some problems are best solved by methods that ignore the objective. The main lesson is the inherent limitation of the objective-based paradigm and the unexploited opportunity to guide search through other means.},
	language = {en},
	number = {2},
	urldate = {2025-01-09},
	journal = {Evolutionary Computation},
	author = {Lehman, Joel and Stanley, Kenneth O.},
	month = jun,
	year = {2011},
	pages = {189--223},
}

@inproceedings{lehman_EvolvingDiversityVirtual_2011,
	address = {New York, NY, USA},
	series = {{GECCO} '11},
	title = {Evolving a diversity of virtual creatures through novelty search and local competition},
	isbn = {978-1-4503-0557-0},
	url = {https://doi.org/10.1145/2001576.2001606},
	doi = {10.1145/2001576.2001606},
	abstract = {An ambitious challenge in artificial life is to craft an evolutionary process that discovers a wide diversity of well-adapted virtual creatures within a single run. Unlike in nature, evolving creatures in virtual worlds tend to converge to a single morphology because selection therein greedily rewards the morphology that is easiest to exploit. However, novelty search, a technique that explicitly rewards diverging, can potentially mitigate such convergence. Thus in this paper an existing creature evolution platform is extended with multi-objective search that balances drives for both novelty and performance. However, there are different ways to combine performance-driven search and novelty search. The suggested approach is to provide evolution with both a novelty objective that encourages diverse morphologies and a local competition objective that rewards individuals outperforming those most similar in morphology. The results in an experiment evolving locomoting virtual creatures show that novelty search with local competition discovers more functional morphological diversity within a single run than models with global competition, which are more predisposed to converge. The conclusions are that novelty search with local competition may complement recent advances in evolving virtual creatures and may in general be a principled approach to combining novelty search with pressure to achieve.},
	urldate = {2025-01-09},
	booktitle = {Proceedings of the 13th annual conference on {Genetic} and evolutionary computation},
	publisher = {Association for Computing Machinery},
	author = {Lehman, Joel and Stanley, Kenneth O.},
	month = jul,
	year = {2011},
	pages = {211--218},
}

@misc{mouret_IlluminatingSearchSpaces_2015,
	title = {Illuminating search spaces by mapping elites},
	url = {http://arxiv.org/abs/1504.04909},
	doi = {10.48550/arXiv.1504.04909},
	abstract = {Many fields use search algorithms, which automatically explore a search space to find high-performing solutions: chemists search through the space of molecules to discover new drugs; engineers search for stronger, cheaper, safer designs, scientists search for models that best explain data, etc. The goal of search algorithms has traditionally been to return the single highest-performing solution in a search space. Here we describe a new, fundamentally different type of algorithm that is more useful because it provides a holistic view of how high-performing solutions are distributed throughout a search space. It creates a map of high-performing solutions at each point in a space defined by dimensions of variation that a user gets to choose. This Multi-dimensional Archive of Phenotypic Elites (MAP-Elites) algorithm illuminates search spaces, allowing researchers to understand how interesting attributes of solutions combine to affect performance, either positively or, equally of interest, negatively. For example, a drug company may wish to understand how performance changes as the size of molecules and their cost-to-produce vary. MAP-Elites produces a large diversity of high-performing, yet qualitatively different solutions, which can be more helpful than a single, high-performing solution. Interestingly, because MAP-Elites explores more of the search space, it also tends to find a better overall solution than state-of-the-art search algorithms. We demonstrate the benefits of this new algorithm in three different problem domains ranging from producing modular neural networks to designing simulated and real soft robots. Because MAP- Elites (1) illuminates the relationship between performance and dimensions of interest in solutions, (2) returns a set of high-performing, yet diverse solutions, and (3) improves finding a single, best solution, it will advance science and engineering.},
	urldate = {2025-01-09},
	publisher = {arXiv},
	author = {Mouret, Jean-Baptiste and Clune, Jeff},
	month = apr,
	year = {2015},
	note = {arXiv:1504.04909 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Neural and Evolutionary Computing, Computer Science - Robotics, Quantitative Biology - Populations and Evolution},
}

@article{pugh_QualityDiversityNew_2016,
	title = {Quality {Diversity}: {A} {New} {Frontier} for {Evolutionary} {Computation}},
	volume = {3},
	issn = {2296-9144},
	shorttitle = {Quality {Diversity}},
	url = {https://www.frontiersin.org/journals/robotics-and-ai/articles/10.3389/frobt.2016.00040/full},
	doi = {10.3389/frobt.2016.00040},
	abstract = {{\textless}p{\textgreater}While evolutionary computation and evolutionary robotics take inspiration from nature, they have long focused mainly on problems of performance optimization. Yet, evolution in nature can be interpreted as more nuanced than a process of simple optimization. In particular, natural evolution is a divergent search that optimizes locally within each niche as it simultaneously diversifies. This tendency to discover both quality and diversity at the same time differs from many of the conventional algorithms of machine learning, and also thereby suggests a different foundation for inferring the approach of greatest potential for evolutionary algorithms. In fact, several recent evolutionary algorithms called {\textless}italic{\textgreater}quality diversity (QD) algorithms{\textless}/italic{\textgreater} (e.g., novelty search with local competition and MAP-Elites) have drawn inspiration from this more nuanced view, aiming to fill a space of possibilities with the best possible example of each type of achievable behavior. The result is a new class of algorithms that return an archive of diverse, high-quality behaviors in a single run. The aim in this paper is to study the application of QD algorithms in challenging environments (in particular complex mazes) to establish their best practices for ambitious domains in the future. In addition to providing insight into cases when QD succeeds and fails, a new approach is investigated that hybridizes multiple views of behaviors (called {\textless}italic{\textgreater}behavior characterizations{\textless}/italic{\textgreater}) in the same run, which succeeds in overcoming some of the challenges associated with searching for QD with respect to a behavior characterization that is not necessarily sufficient for generating both quality and diversity at the same time.{\textless}/p{\textgreater}},
	language = {English},
	urldate = {2025-01-06},
	journal = {Frontiers in Robotics and AI},
	author = {Pugh, Justin K. and Soros, Lisa B. and Stanley, Kenneth O.},
	month = jul,
	year = {2016},
	note = {Publisher: Frontiers},
	keywords = {behavior characterization, Behavioral diversity, Evolutionary computation, neuroevolution, non-objective search, novelty search, quality diversity},
}

@article{qd_framework,
  author={Cully, Antoine and Demiris, Yiannis},
  journal={IEEE Transactions on Evolutionary Computation}, 
  title={Quality and Diversity Optimization: A Unifying Modular Framework}, 
  year={2018},
  volume={22},
  number={2},
  pages={245-259},
  keywords={Optimization;Legged locomotion;Sociology;Statistics;Algorithm design and analysis;Evolutionary computation;Behavioral diversity;collection of solutions;novelty search;optimization methods;quality-diversity (QD)},
  doi={10.1109/TEVC.2017.2704781},
}

@inproceedings{vassiliades_ComparisonIlluminationAlgorithms_2017,
	address = {Berlin Germany},
	title = {A comparison of illumination algorithms in unbounded spaces},
	isbn = {978-1-4503-4939-0},
	url = {https://dl.acm.org/doi/10.1145/3067695.3082531},
	doi = {10.1145/3067695.3082531},
	abstract = {Illumination algorithms are a new class of evolutionary algorithms capable of producing large archives of diverse and high-performing solutions. Examples of such algorithms include Novelty Search with Local Competition (NSLC), the Multi-dimensional Archive of Phenotypic Elites (MAP-Elites) and the newly introduced Centroidal Voronoi Tessellation (CVT) MAP-Elites. While NSLC can be used in unbounded behavioral spaces, MAP-Elites and CVTMAP-Elites require the user to manually specify the bounds. In this study, we introduce variants of these algorithms that expand their bounds based on the discovered solutions. In addition, we introduce a novel algorithm called “Cluster-Elites” that can adapt its bounds to non-convex spaces. We compare all algorithms in a maze navigation problem and illustrate that Cluster-Elites and the expansive variants of MAP-Elites and CVT-MAP-Elites have comparable or be er performance than NSLC, MAP-Elites and CVT-MAP-Elites.},
	language = {en},
	urldate = {2025-01-09},
	booktitle = {Proceedings of the {Genetic} and {Evolutionary} {Computation} {Conference} {Companion}},
	publisher = {ACM},
	author = {Vassiliades, Vassilis and Chatzilygeroudis, Konstantinos and Mouret, Jean-Baptiste},
	month = jul,
	year = {2017},
	pages = {1578--1581},
}

@article{vassiliades_UsingCentroidalVoronoi_2018,
    title = {Using {Centroidal} {Voronoi} {Tessellations} to {Scale} {Up} the {Multidimensional} {Archive} of {Phenotypic} {Elites} {Algorithm}},
    volume = {22},
    issn = {1941-0026},
    url = {https://ieeexplore.ieee.org/document/8000667},
    doi = {10.1109/TEVC.2017.2735550},
    abstract = {The recently introduced multidimensional archive of phenotypic elites (MAP-Elites) is an evolutionary algorithm capable of producing a large archive of diverse, high-performing solutions in a single run. It works by discretizing a continuous feature space into unique regions according to the desired discretization per dimension. While simple, this algorithm has a main drawback: it cannot scale to high-dimensional feature spaces since the number of regions increase exponentially with the number of dimensions. In this paper, we address this limitation by introducing a simple extension of MAP-Elites that has a constant, predefined number of regions irrespective of the dimensionality of the feature space. Our main insight is that methods from computational geometry could partition a high-dimensional space into well-spread geometric regions. In particular, our algorithm uses a centroidal Voronoi tessellation (CVT) to divide the feature space into a desired number of regions; it then places every generated individual in its closest region, replacing a less fit one if the region is already occupied. We demonstrate the effectiveness of the new “CVT-MAP-Elites” algorithm in high-dimensional feature spaces through comparisons against MAP-Elites in maze navigation and hexapod locomotion tasks.},
    number = {4},
    urldate = {2025-01-13},
    journal = {IEEE Transactions on Evolutionary Computation},
    author = {Vassiliades, Vassilis and Chatzilygeroudis, Konstantinos and Mouret, Jean-Baptiste},
    month = aug,
    year = {2018},
    note = {Conference Name: IEEE Transactions on Evolutionary Computation},
    keywords = {Behavioral diversity, centroidal Voronoi tessellation (CVT), Clustering algorithms, Evolutionary computation, illumination algorithms, Legged locomotion, Lighting, multidimensional archive of phenotypic elites (MAP-Elites), Optimization, Partitioning algorithms, quality diversity (QD)},
    pages = {623--630},
}

