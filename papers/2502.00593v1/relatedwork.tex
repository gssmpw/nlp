\section{Related Work}
\label{sec:related-work}
\subsection{Local Competition in Genetic Algorithms}
%
Evolution's ability to generate diverse, well-adapted species has inspired numerous approaches in evolutionary computation to maintain population diversity. Early techniques focused on preventing premature convergence through mechanisms like fitness sharing~\citep{GeneticAlgorithmsSharing1987}, which enforces competition between similar solutions to encourage exploration of distant parts of the search space. \citet{alps} introduced the age-layered population structure where individuals compete only with others of similar genetic age, while \citet{hfc} introduced hierarchical fair competition to restrict competition to occur between solutions of similar fitness levels.

Several multi-objective and elitist algorithms promote diversity implicitly through their selection mechanisms as a natural consequence of search, rather than through an explicit diversity preservation mechanism. For example, NSGA-II~\citep{deb2002fast} maintains diversity through non-dominated sorting and crowding distance mechanisms, without needing a predefined behavior descriptor. Lexicase selection~\citep{helmuth_solving_2015}, which filters down individuals based on their performance on a large number of objectives that are considered in a random order, similarly maintains high levels of diversity~\citep{helmuth2016effects,boldi2024solving}.

A radical departure from these approaches came with Novelty Search~\citep{lehman_AbandoningObjectivesEvolution_2011}, which completely abandons the objective function and instead rewards solutions solely for being behaviorally different from their predecessors. By introducing the concept of behavioral distance as a fundamental measure for competition, Novelty Search laid crucial groundwork for new forms of local competition that would later be integrated with objective-based optimization in Quality-Diversity algorithms. 

\subsection{Quality-Diversity}
%
Quality-Diversity algorithms address the challenge of discovering diverse, high-performing solutions through local competition mechanisms~\citep{pugh_QualityDiversityNew_2016}. MAP-Elites~\citep{mouret_IlluminatingSearchSpaces_2015} formalizes this through a grid-based architecture where solutions compete only within their behavioral cell, maintaining the highest-performing individual in each niche. To enhance scalability in high-dimensional behavior spaces, Centroidal Voronoi Tessellations~\citep{vassiliades_UsingCentroidalVoronoi_2018} adaptively partition the space into well-distributed regions. While these approaches prove effective, particularly in robotics applications, they rely on predefined bounds and potentially arbitrary discretization of the behavior space.

Unstructured archives offer an alternative approach to local competition. Novelty Search with Local Competition~\citep{lehman_EvolvingDiversityVirtual_2011} and AURORA~\citep{cully_AutonomousSkillDiscovery_2019,qd_framework} make solutions compete only against their behavioral neighbors through a distance-threshold mechanism. While these methods eliminate the need for predefined cells, they introduce new challenges through fixed distance parameters that require careful tuning and often need complex adaptation mechanisms like container size control~\citep{csc}. Cluster-Elites~\citep{vassiliades_ComparisonIlluminationAlgorithms_2017} attempts to address these limitations by dynamically spreading centroids across the actual shape of the discovered solutions rather than within a predefined hyperrectangle, allowing it to better adapt to non-convex behavioral spaces.

Our method, \ours{}, introduces a novel approach to local competition that rewards solutions that either outperform their neighbors or find unique behaviors compared to better-performing solutions. Rather than using spatial partitioning or distance thresholds, \ours{} creates an emergent competition structure based on relative solution performance and proximity. This approach naturally adapts to the distribution of solutions without requiring predefined bounds or parameters, making it particularly effective for domains with unknown or complex behavioral spaces.