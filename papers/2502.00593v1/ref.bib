
@article{grillotti2022unsupervisedqd,
  title={Unsupervised behavior discovery with quality-diversity optimization},
  author={Grillotti, Luca and Cully, Antoine},
  journal={IEEE Transactions on Evolutionary Computation},
  volume={26},
  number={6},
  pages={1539--1552},
  year={2022},
  publisher={IEEE}
}

@inproceedings{cully2013brevolution,
  title={Behavioral repertoire learning in robotics},
  author={Cully, Antoine and Mouret, Jean-Baptiste},
  booktitle={Proceedings of the 15th annual conference on Genetic and evolutionary computation},
  pages={175--182},
  year={2013}
}

@inproceedings{boldi2024solving,
  title={Solving Deceptive Problems Without Explicit Diversity Maintenance},
  author={Boldi, Ryan and Ding, Li and Spector, Lee},
  booktitle={Proceedings of the Genetic and Evolutionary Computation Conference Companion},
  pages={171--174},
  year={2024}
}

@article{flageat2023UQD,
  title={Uncertain quality-diversity: evaluation methodology and new methods for quality-diversity in uncertain domains},
  author={Flageat, Manon and Cully, Antoine},
  journal={IEEE Transactions on Evolutionary Computation},
  year={2023},
  publisher={IEEE}
}

@inproceedings{janmohamed2023MOMEPGX,
author = {Janmohamed, Hannah and Pierrot, Thomas and Cully, Antoine},
title = {Improving the Data Efficiency of Multi-Objective Quality-Diversity through Gradient Assistance and Crowding Exploration},
year = {2023},
isbn = {9798400701191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583131.3590470},
doi = {10.1145/3583131.3590470},
abstract = {Quality-Diversity (QD) algorithms have recently gained traction as optimisation methods due to their effectiveness at escaping local optima and capability of generating wide-ranging and high-performing solutions. Recently, Multi-Objective MAP-Elites (MOME) extended the QD paradigm to the multi-objective setting by maintaining a Pareto front in each cell of a MAP-ELITES grid. mome achieved a global performance that competed with NSGA-II and SPEA2, two well-established multi-objective evolutionary algorithms, while also acquiring a diverse repertoire of solutions. However, MOME is limited by non-directed genetic search mechanisms which struggle in high-dimensional search spaces. In this work, we present Multi-Objective MAP-Elites with Policy-Gradient Assistance and Crowding-based Exploration (MOME-PGX): a new QD algorithm that extends MOME to improve its data efficiency and performance. MOME-PGX uses gradient-based optimisation to efficiently drive solutions towards higher performance. It also introduces crowding-based mechanisms to create an improved exploration strategy and to encourage greater uniformity across Pareto fronts. We evaluate MOME-PGX in four simulated robot locomotion tasks and demonstrate that it converges faster and to a higher performance than all other baselines. We show that MOME-PGX is between 4.3 and 42 times more data-efficient than MOME and doubles the performance of MOME, NSGA-II and SPEA2 in challenging environments.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
pages = {165–173},
numpages = {9},
keywords = {quality-diversity, multi-objective optimisation, MAP-elites, neuroevolution},
location = {Lisbon, Portugal},
series = {GECCO '23}
}

@inproceedings{pierrot2022MOQD,
  title={Multi-objective quality diversity optimization},
  author={Pierrot, Thomas and Richard, Guillaume and Beguir, Karim and Cully, Antoine},
  booktitle={Proceedings of the Genetic and Evolutionary Computation Conference},
  pages={139--147},
  year={2022}
}

@book{greatness,
author = {Stanley, Kenneth O. and Lehman, Joel},
title = {Why Greatness Cannot Be Planned: The Myth of the Objective},
year = {2015},
isbn = {3319155237},
publisher = {Springer Publishing Company, Incorporated},
abstract = {Why does modern life revolve around objectives? From how science is funded, to improving how children are educated -- and nearly everything in-between -- our society has become obsessed with a seductive illusion: that greatness results from doggedly measuring improvement in the relentless pursuit of an ambitious goal. In Why Greatness Cannot Be Planned, Stanley and Lehman begin with a surprising scientific discovery in artificial intelligence that leads ultimately to the conclusion that the objective obsession has gone too far. They make the case that great achievement can't be bottled up into mechanical metrics; that innovation is not driven by narrowly focused heroic effort; and that we would be wiser (and the outcomes better) if instead we whole-heartedly embraced serendipitous discovery and playful creativity. Controversial at its heart, yet refreshingly provocative, this book challenges readers to consider life without a destination and discovery without a compass.}
}

@article{neat,
title={Evolving Neural Networks Through Augmenting Topologies},
author={Kenneth O. Stanley and Risto Miikkulainen},
volume={10},
journal={Evolutionary Computation},
number={2},
pages={99-127},
url="http://nn.cs.utexas.edu/?stanley:ec02",
year={2002}
}

@article{pugh_QualityDiversityNew_2016,
	title = {Quality {Diversity}: {A} {New} {Frontier} for {Evolutionary} {Computation}},
	volume = {3},
	issn = {2296-9144},
	shorttitle = {Quality {Diversity}},
	url = {https://www.frontiersin.org/journals/robotics-and-ai/articles/10.3389/frobt.2016.00040/full},
	doi = {10.3389/frobt.2016.00040},
	abstract = {{\textless}p{\textgreater}While evolutionary computation and evolutionary robotics take inspiration from nature, they have long focused mainly on problems of performance optimization. Yet, evolution in nature can be interpreted as more nuanced than a process of simple optimization. In particular, natural evolution is a divergent search that optimizes locally within each niche as it simultaneously diversifies. This tendency to discover both quality and diversity at the same time differs from many of the conventional algorithms of machine learning, and also thereby suggests a different foundation for inferring the approach of greatest potential for evolutionary algorithms. In fact, several recent evolutionary algorithms called {\textless}italic{\textgreater}quality diversity (QD) algorithms{\textless}/italic{\textgreater} (e.g., novelty search with local competition and MAP-Elites) have drawn inspiration from this more nuanced view, aiming to fill a space of possibilities with the best possible example of each type of achievable behavior. The result is a new class of algorithms that return an archive of diverse, high-quality behaviors in a single run. The aim in this paper is to study the application of QD algorithms in challenging environments (in particular complex mazes) to establish their best practices for ambitious domains in the future. In addition to providing insight into cases when QD succeeds and fails, a new approach is investigated that hybridizes multiple views of behaviors (called {\textless}italic{\textgreater}behavior characterizations{\textless}/italic{\textgreater}) in the same run, which succeeds in overcoming some of the challenges associated with searching for QD with respect to a behavior characterization that is not necessarily sufficient for generating both quality and diversity at the same time.{\textless}/p{\textgreater}},
	language = {English},
	urldate = {2025-01-06},
	journal = {Frontiers in Robotics and AI},
	author = {Pugh, Justin K. and Soros, Lisa B. and Stanley, Kenneth O.},
	month = jul,
	year = {2016},
	note = {Publisher: Frontiers},
	keywords = {behavior characterization, Behavioral diversity, Evolutionary computation, neuroevolution, non-objective search, novelty search, quality diversity},
}

@inproceedings{faldor_ArtificialOpenEndedEvolution_2024,
	title = {Toward {Artificial} {Open}-{Ended} {Evolution} within {Lenia} using {Quality}-{Diversity}},
	url = {https://dx.doi.org/10.1162/isal_a_00827},
	doi = {10.1162/isal_a_00827},
	abstract = {Abstract. From the formation of snowflakes to the evolution of diverse life forms, emergence is ubiquitous in our universe. In the quest to understand how complexity can arise from simple rules, abstract computational models, such as cellular automata, have been developed to study self-organization. However, the discovery of self-organizing patterns in artificial systems is challenging and has largely relied on manual or semi-automatic search in the past. In this paper, we show that Quality-Diversity, a family of Evolutionary Algorithms, is an effective framework for the automatic discovery of diverse self-organizing patterns in complex systems. Quality-Diversity algorithms aim to evolve a large population of diverse individuals, each adapted to its ecological niche. Combined with Lenia, a family of continuous cellular automata, we demonstrate that our method is able to evolve a diverse population of lifelike self-organizing autonomous patterns. Our framework, called Leniabreeder, can leverage both manually defined diversity criteria to guide the search toward interesting areas, as well as unsupervised measures of diversity to broaden the scope of discoverable patterns. We demonstrate both qualitatively and quantitatively that Leniabreeder offers a powerful solution for discovering self-organizing patterns. The effectiveness of unsupervised Quality-Diversity methods combined with the rich landscape of Lenia exhibits a sustained generation of diversity and complexity characteristic of biological evolution. We provide empirical evidence that suggests unbounded diversity and argue that Leniabreeder is a step toward replicating open-ended evolution in silico.},
	language = {en},
	urldate = {2025-01-06},
	publisher = {MIT Press},
	author = {Faldor, Maxence and Cully, Antoine},
	month = jul,
	year = {2024},
}

@article{lehman_AbandoningObjectivesEvolution_2011,
	title = {Abandoning {Objectives}: {Evolution} {Through} the {Search} for {Novelty} {Alone}},
	volume = {19},
	issn = {1063-6560, 1530-9304},
	shorttitle = {Abandoning {Objectives}},
	url = {https://direct.mit.edu/evco/article/19/2/189-223/1365},
	doi = {10.1162/EVCO_a_00025},
	abstract = {In evolutionary computation, the ﬁtness function normally measures progress towards an objective in the search space, effectively acting as an objective function. Through deception, such objective functions may actually prevent the objective from being reached. While methods exist to mitigate deception, they leave the underlying pathology untreated: Objective functions themselves may actively misdirect search towards dead ends. This paper proposes an approach to circumventing deception that also yields a new perspective on open-ended evolution: Instead of either explicitly seeking an objective or modeling natural evolution to capture open-endedness, the idea is to simply search for behavioral novelty. Even in an objective-based problem, such novelty search ignores the objective. Because many points in the search space collapse to a single behavior, the search for novelty is often feasible. Furthermore, because there are only so many simple behaviors, the search for novelty leads to increasing complexity. By decoupling open-ended search from artiﬁcial life worlds, the search for novelty is applicable to real world problems. Counterintuitively, in the maze navigation and biped walking tasks in this paper, novelty search signiﬁcantly outperforms objective-based search, suggesting the strange conclusion that some problems are best solved by methods that ignore the objective. The main lesson is the inherent limitation of the objective-based paradigm and the unexploited opportunity to guide search through other means.},
	language = {en},
	number = {2},
	urldate = {2025-01-09},
	journal = {Evolutionary Computation},
	author = {Lehman, Joel and Stanley, Kenneth O.},
	month = jun,
	year = {2011},
	pages = {189--223},
}

@inproceedings{lehman_EvolvingDiversityVirtual_2011,
	address = {New York, NY, USA},
	series = {{GECCO} '11},
	title = {Evolving a diversity of virtual creatures through novelty search and local competition},
	isbn = {978-1-4503-0557-0},
	url = {https://doi.org/10.1145/2001576.2001606},
	doi = {10.1145/2001576.2001606},
	abstract = {An ambitious challenge in artificial life is to craft an evolutionary process that discovers a wide diversity of well-adapted virtual creatures within a single run. Unlike in nature, evolving creatures in virtual worlds tend to converge to a single morphology because selection therein greedily rewards the morphology that is easiest to exploit. However, novelty search, a technique that explicitly rewards diverging, can potentially mitigate such convergence. Thus in this paper an existing creature evolution platform is extended with multi-objective search that balances drives for both novelty and performance. However, there are different ways to combine performance-driven search and novelty search. The suggested approach is to provide evolution with both a novelty objective that encourages diverse morphologies and a local competition objective that rewards individuals outperforming those most similar in morphology. The results in an experiment evolving locomoting virtual creatures show that novelty search with local competition discovers more functional morphological diversity within a single run than models with global competition, which are more predisposed to converge. The conclusions are that novelty search with local competition may complement recent advances in evolving virtual creatures and may in general be a principled approach to combining novelty search with pressure to achieve.},
	urldate = {2025-01-09},
	booktitle = {Proceedings of the 13th annual conference on {Genetic} and evolutionary computation},
	publisher = {Association for Computing Machinery},
	author = {Lehman, Joel and Stanley, Kenneth O.},
	month = jul,
	year = {2011},
	pages = {211--218},
}

@misc{mouret_IlluminatingSearchSpaces_2015,
	title = {Illuminating search spaces by mapping elites},
	url = {http://arxiv.org/abs/1504.04909},
	doi = {10.48550/arXiv.1504.04909},
	abstract = {Many fields use search algorithms, which automatically explore a search space to find high-performing solutions: chemists search through the space of molecules to discover new drugs; engineers search for stronger, cheaper, safer designs, scientists search for models that best explain data, etc. The goal of search algorithms has traditionally been to return the single highest-performing solution in a search space. Here we describe a new, fundamentally different type of algorithm that is more useful because it provides a holistic view of how high-performing solutions are distributed throughout a search space. It creates a map of high-performing solutions at each point in a space defined by dimensions of variation that a user gets to choose. This Multi-dimensional Archive of Phenotypic Elites (MAP-Elites) algorithm illuminates search spaces, allowing researchers to understand how interesting attributes of solutions combine to affect performance, either positively or, equally of interest, negatively. For example, a drug company may wish to understand how performance changes as the size of molecules and their cost-to-produce vary. MAP-Elites produces a large diversity of high-performing, yet qualitatively different solutions, which can be more helpful than a single, high-performing solution. Interestingly, because MAP-Elites explores more of the search space, it also tends to find a better overall solution than state-of-the-art search algorithms. We demonstrate the benefits of this new algorithm in three different problem domains ranging from producing modular neural networks to designing simulated and real soft robots. Because MAP- Elites (1) illuminates the relationship between performance and dimensions of interest in solutions, (2) returns a set of high-performing, yet diverse solutions, and (3) improves finding a single, best solution, it will advance science and engineering.},
	urldate = {2025-01-09},
	publisher = {arXiv},
	author = {Mouret, Jean-Baptiste and Clune, Jeff},
	month = apr,
	year = {2015},
	note = {arXiv:1504.04909 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Neural and Evolutionary Computing, Computer Science - Robotics, Quantitative Biology - Populations and Evolution},
}

@misc{fontaine_MappingHearthstoneDeck_2019,
	title = {Mapping {Hearthstone} {Deck} {Spaces} through {MAP}-{Elites} with {Sliding} {Boundaries}},
	url = {http://arxiv.org/abs/1904.10656},
	doi = {10.48550/arXiv.1904.10656},
	abstract = {Quality diversity (QD) algorithms such as MAP-Elites have emerged as a powerful alternative to traditional single-objective optimization methods. They were initially applied to evolutionary robotics problems such as locomotion and maze navigation, but have yet to see widespread application. We argue that these algorithms are perfectly suited to the rich domain of video games, which contains many relevant problems with a multitude of successful strategies and often also multiple dimensions along which solutions can vary. This paper introduces a novel modification of the MAP-Elites algorithm called MAP-Elites with Sliding Boundaries (MESB) and applies it to the design and rebalancing of Hearthstone, a popular collectible card game chosen for its number of multidimensional behavior features relevant to particular styles of play. To avoid overpopulating cells with conflated behaviors, MESB slides the boundaries of cells based on the distribution of evolved individuals. Experiments in this paper demonstrate the performance of MESB in Hearthstone. Results suggest MESB finds diverse ways of playing the game well along the selected behavioral dimensions. Further analysis of the evolved strategies reveals common patterns that recur across behavioral dimensions and explores how MESB can help rebalance the game.},
	urldate = {2025-01-09},
	publisher = {arXiv},
	author = {Fontaine, Matthew C. and Lee, Scott and Soros, L. B. and Silva, Fernando De Mesentier and Togelius, Julian and Hoover, Amy K.},
	month = apr,
	year = {2019},
	note = {arXiv:1904.10656 [cs]},
	keywords = {Computer Science - Neural and Evolutionary Computing},
}

@inproceedings{vassiliades_ComparisonIlluminationAlgorithms_2017,
	address = {Berlin Germany},
	title = {A comparison of illumination algorithms in unbounded spaces},
	isbn = {978-1-4503-4939-0},
	url = {https://dl.acm.org/doi/10.1145/3067695.3082531},
	doi = {10.1145/3067695.3082531},
	abstract = {Illumination algorithms are a new class of evolutionary algorithms capable of producing large archives of diverse and high-performing solutions. Examples of such algorithms include Novelty Search with Local Competition (NSLC), the Multi-dimensional Archive of Phenotypic Elites (MAP-Elites) and the newly introduced Centroidal Voronoi Tessellation (CVT) MAP-Elites. While NSLC can be used in unbounded behavioral spaces, MAP-Elites and CVTMAP-Elites require the user to manually specify the bounds. In this study, we introduce variants of these algorithms that expand their bounds based on the discovered solutions. In addition, we introduce a novel algorithm called “Cluster-Elites” that can adapt its bounds to non-convex spaces. We compare all algorithms in a maze navigation problem and illustrate that Cluster-Elites and the expansive variants of MAP-Elites and CVT-MAP-Elites have comparable or be er performance than NSLC, MAP-Elites and CVT-MAP-Elites.},
	language = {en},
	urldate = {2025-01-09},
	booktitle = {Proceedings of the {Genetic} and {Evolutionary} {Computation} {Conference} {Companion}},
	publisher = {ACM},
	author = {Vassiliades, Vassilis and Chatzilygeroudis, Konstantinos and Mouret, Jean-Baptiste},
	month = jul,
	year = {2017},
	pages = {1578--1581},
}

@software{brax2021github,
    author = {C. Daniel Freeman and Erik Frey and Anton Raichuk and Sertan Girgin and Igor Mordatch and Olivier Bachem},
    title = {Brax - A Differentiable Physics Engine for Large Scale Rigid Body Simulation},
    url = {http://github.com/google/brax},
    version = {0.12.1},
    year = {2021},
}

@article{jamil_LiteratureSurveyBenchmark_2013,
	title = {A {Literature} {Survey} of {Benchmark} {Functions} {For} {Global} {Optimization} {Problems}},
	volume = {4},
	doi = {10.1504/IJMMNO.2013.055204},
	abstract = {Test functions are important to validate and compare the performance of optimization algorithms. There have been many test or benchmark functions reported in the literature; however, there is no standard list or set of benchmark functions. Ideally, test functions should have diverse properties so that can be truly useful to test new algorithms in an unbiased way. For this purpose, we have reviewed and compiled a rich set of 175 benchmark functions for unconstrained optimization problems with diverse properties in terms of modality, separability, and valley landscape. This is by far the most complete set of functions so far in the literature, and tt can be expected this complete set of functions can be used for validation of new optimization in the future.},
	journal = {Int. J. of Mathematical Modelling and Numerical Optimisation},
	author = {Jamil, Momin and Yang, Xin-She},
	month = aug,
	year = {2013},
	file = {jamil_2013_a_literature_survey_of_benchmark_functions_for_global_optimization_problems.pdf:/Users/mf1022/Library/CloudStorage/OneDrive-ImperialCollegeLondon/Zotero/Jamil/jamil_2013_a_literature_survey_of_benchmark_functions_for_global_optimization_problems2.pdf:application/pdf},
}

@inproceedings{cully_AutonomousSkillDiscovery_2019,
	address = {New York, NY, USA},
	series = {{GECCO} '19},
	title = {Autonomous skill discovery with quality-diversity and unsupervised descriptors},
	isbn = {978-1-4503-6111-8},
	url = {https://doi.org/10.1145/3321707.3321804},
	doi = {10.1145/3321707.3321804},
	abstract = {Quality-Diversity optimization is a new family of optimization algorithms that, instead of searching for a single optimal solution to solving a task, searches for a large collection of solutions that all solve the task in a different way. This approach is particularly promising for learning behavioral repertoires in robotics, as such a diversity of behaviors enables robots to be more versatile and resilient. However, these algorithms require the user to manually define behavioral descriptors, which is used to determine whether two solutions are different or similar. The choice of a behavioral descriptor is crucial, as it completely changes the solution types that the algorithm derives. In this paper, we introduce a new method to automatically define this descriptor by combining Quality-Diversity algorithms with unsupervised dimensionality reduction algorithms. This approach enables robots to autonomously discover the range of their capabilities while interacting with their environment. The results from two experimental scenarios demonstrate that robot can autonomously discover a large range of possible behaviors, without any prior knowledge about their morphology and environment. Furthermore, these behaviors are deemed to be similar to hand-crafted solutions that uses domain knowledge and significantly more diverse than when using existing unsupervised methods.},
	urldate = {2025-01-07},
	booktitle = {Proceedings of the {Genetic} and {Evolutionary} {Computation} {Conference}},
	publisher = {Association for Computing Machinery},
	author = {Cully, Antoine},
	month = jul,
	year = {2019},
	pages = {81--89},
}

@article{vassiliades_UsingCentroidalVoronoi_2018,
    title = {Using {Centroidal} {Voronoi} {Tessellations} to {Scale} {Up} the {Multidimensional} {Archive} of {Phenotypic} {Elites} {Algorithm}},
    volume = {22},
    issn = {1941-0026},
    url = {https://ieeexplore.ieee.org/document/8000667},
    doi = {10.1109/TEVC.2017.2735550},
    abstract = {The recently introduced multidimensional archive of phenotypic elites (MAP-Elites) is an evolutionary algorithm capable of producing a large archive of diverse, high-performing solutions in a single run. It works by discretizing a continuous feature space into unique regions according to the desired discretization per dimension. While simple, this algorithm has a main drawback: it cannot scale to high-dimensional feature spaces since the number of regions increase exponentially with the number of dimensions. In this paper, we address this limitation by introducing a simple extension of MAP-Elites that has a constant, predefined number of regions irrespective of the dimensionality of the feature space. Our main insight is that methods from computational geometry could partition a high-dimensional space into well-spread geometric regions. In particular, our algorithm uses a centroidal Voronoi tessellation (CVT) to divide the feature space into a desired number of regions; it then places every generated individual in its closest region, replacing a less fit one if the region is already occupied. We demonstrate the effectiveness of the new “CVT-MAP-Elites” algorithm in high-dimensional feature spaces through comparisons against MAP-Elites in maze navigation and hexapod locomotion tasks.},
    number = {4},
    urldate = {2025-01-13},
    journal = {IEEE Transactions on Evolutionary Computation},
    author = {Vassiliades, Vassilis and Chatzilygeroudis, Konstantinos and Mouret, Jean-Baptiste},
    month = aug,
    year = {2018},
    note = {Conference Name: IEEE Transactions on Evolutionary Computation},
    keywords = {Behavioral diversity, centroidal Voronoi tessellation (CVT), Clustering algorithms, Evolutionary computation, illumination algorithms, Legged locomotion, Lighting, multidimensional archive of phenotypic elites (MAP-Elites), Optimization, Partitioning algorithms, quality diversity (QD)},
    pages = {623--630},
}

@article{ga,
    ISSN = {00368733, 19467087},
    URL = {http://www.jstor.org/stable/24939139},
    author = {John H. Holland},
    journal = {Scientific American},
    number = {1},
    pages = {66--73},
    publisher = {Scientific American, a division of Nature America, Inc.},
    title = {Genetic Algorithms},
    urldate = {2025-01-12},
    volume = {267},
    year = {1992}
}

@book{rechenberg_EvolutionsstrategieOptimierungTechnischer_1973,
    address = {Stuttgart-Bad Cannstadt},
    series = {Problemata},
    title = {Evolutionsstrategie: {Optimierung} technischer {Systeme} nach {Prinzipien} der biologischen {Evolution}},
    isbn = {978-3-7728-0373-4 978-3-7728-0374-1},
    shorttitle = {Evolutionsstrategie},
    language = {de},
    number = {15},
    publisher = {Frommann-Holzboog},
    author = {Rechenberg, Ingo and Eigen, Manfred},
    year = {1973},
}



@article{helmuth_solving_2015,
	title = {Solving {Uncompromising} {Problems} {With} {Lexicase} {Selection}},
	volume = {19},
	issn = {1089-778X, 1089-778X, 1941-0026},
	url = {http://ieeexplore.ieee.org/document/6920034/},
	doi = {10.1109/TEVC.2014.2362729},
	abstract = {We describe a broad class of problems, called “uncompromising problems,” characterized by the requirement that solutions must perform optimally on each of many test cases. Many of the problems that have long motivated genetic programming research, including the automation of many traditional programming tasks, are uncompromising. We describe and analyze the recently proposed “lexicase” parent selection algorition and show that it can facilitate the solution of uncompromising problems by genetic programming. Unlike most traditional parent selection techniques, lexicase selection does not base selection on a ﬁtness value that is aggregated over all test cases; rather, it considers test cases one at a time in random order. We present results comparing lexicase selection to more traditional parent selection methods, including standard tournament selection and implicit ﬁtness sharing, on four uncompromising problems: ﬁnding terms in ﬁnite algebras, designing digital multipliers, counting words in ﬁles, and performing symbolic regression of the factorial function. We provide evidence that lexicase selection maintains higher levels of population diversity than other selection methods, which may partially explain its utility as a parent selection algorithm in the context of uncompromising problems.},
	language = {en},
	number = {5},
	urldate = {2023-08-24},
	journal = {IEEE Transactions on Evolutionary Computation},
	author = {Helmuth, Thomas and Spector, Lee and Matheson, James},
	month = oct,
	year = {2015},
	pages = {630--643},
}

@inproceedings{jundt2019comparing,
    title={Comparing and combining lexicase selection and novelty search},
    author={Jundt, Lia and Helmuth, Thomas},
    booktitle={Proceedings of the Genetic and Evolutionary Computation Conference},
    pages={1047--1055},
    year={2019}
}

@inproceedings{helmuth2016effects,
    title={Effects of lexicase and tournament selection on diversity recovery and maintenance},
    author={Helmuth, Thomas and McPhee, Nicholas Freitag and Spector, Lee},
    booktitle={Proceedings of the 2016 on Genetic and Evolutionary Computation Conference Companion},
    pages={983--990},
    year={2016}
}


@article{deb2002fast,
    title={A fast and elitist multiobjective genetic algorithm: NSGA-II},
    author={Deb, Kalyanmoy and Pratap, Amrit and Agarwal, Sameer and Meyarivan, TAMT},
    journal={IEEE transactions on evolutionary computation},
    volume={6},
    number={2},
    pages={182--197},
    year={2002},
    publisher={IEEE}
}

@article{bader2011hype,
    title={HypE: An algorithm for fast hypervolume-based many-objective optimization},
    author={Bader, Johannes and Zitzler, Eckart},
    journal={Evolutionary computation},
    volume={19},
    number={1},
    pages={45--76},
    year={2011},
    publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@inproceedings{knowles2001reducing,
    title={Reducing local optima in single-objective problems by multi-objectivization},
    author={Knowles, Joshua D and Watson, Richard A and Corne, David W},
    booktitle={International conference on evolutionary multi-criterion optimization},
    pages={269--283},
    year={2001},
    organization={Springer}
}

@article{Deb2002AFA,
  title={A fast and elitist multiobjective genetic algorithm: NSGA-II},
  author={Kalyanmoy Deb and Samir Agrawal and Amrit Pratap and T. Meyarivan},
  journal={IEEE Trans. Evol. Comput.},
  year={2002},
  volume={6},
  pages={182-197},
  url={https://api.semanticscholar.org/CorpusID:9914171}
}

@incollection{spector2024particularity,
    title={Particularity},
    author={Spector, Lee and Ding, Li and Boldi, Ryan},
    booktitle={Genetic Programming Theory and Practice XX},
    pages={159--176},
    year={2024},
    publisher={Springer}
}

@inproceedings{grillotti23Kheperax,
    author = {Grillotti, Luca and Cully, Antoine},
    title = {Kheperax: a Lightweight JAX-based Robot Control Environment for Benchmarking Quality-Diversity Algorithms},
    year = {2023},
    isbn = {9798400701207},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3583133.3596387},
    doi = {10.1145/3583133.3596387},
    abstract = {This work introduces a new lightweight and massively parallelizable implementation of a Quality-Diversity (QD) task: the libfastsim maze. This QD task involves finding a collection of neural network controllers navigating a robot to diverse positions in a maze. The proposed implementation, called Kheperax, can be used as a benchmark task for standard QD algorithms, but also for Model-based, Unsupervised and Uncertain QD algorithms. It can automatically run and parallelize parameter evaluations on hardware accelerators, such as Graphical Processing Units (GPUs). When evaluating large batches of parameters, Kheperax is at least 4 times faster than the original libfastsim implementation. The source code is available online1.},
    booktitle = {Proceedings of the Companion Conference on Genetic and Evolutionary Computation},
    pages = {2163–2165},
    numpages = {3},
    keywords = {quality-diversity, neuroevolution},
    location = {Lisbon, Portugal},
    series = {GECCO '23 Companion}
}

@book{darwin,
    title={On the Origin of Species by Means of Natural Selection, or the Preservation of Favoured Races in the Struggle for Life},
    author={Darwin, Charles},
    year={1859},
    publisher={John Murray},
    address={London},
    edition={1},
}

@inproceedings{GeneticAlgorithmsSharing1987,
    title = {Genetic Algorithms with Sharing for Multimodal Function Optimization},
    booktitle = {Genetic Algorithms and their Applications: Proceedings of the Second International Conference on Genetic Algorithms},
    author = {Goldberg, David E. and Richardson, Jon},
    year = {1987},
    pages = {41--49}
}

@inproceedings{alps,
    author = {Hornby, Gregory S.},
    title = {ALPS: the age-layered population structure for reducing the problem of premature convergence},
    year = {2006},
    isbn = {1595931864},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/1143997.1144142},
    doi = {10.1145/1143997.1144142},
    abstract = {To reduce the problem of premature convergence we define a new method for measuring an individual's age and propose the Age-Layered Population Structure (ALPS). This new measure of age measures how long the genetic material has been evolving in the population: offspring start with an age of 1 plus the age of their oldest parent instead of starting with an age of 0 as with traditional measures of age. ALPS differs from a typical evolutionary algorithm (EA) by segregating individuals into different age-layers by their age and by regularly introducing new, randomly generated individuals in the youngest layer. The introduction of randomly generated individuals at regular intervals results in an EA that is never completely converged and is always exploring new parts of the fitness landscape. By using age to restrict competition and breeding, younger individuals are able to develop without being dominated by older ones. Analysis of the search behavior of ALPS finds that the offspring of individuals that are randomly generated mid-way through a run are able to move the population out of mediocre local-optima to better parts of the fitness landscape. In comparison against a traditional EA, a multi-start EA and two other EAs with diversity maintenance schemes we find that ALPS produces significantly better designs with a higher reliability than the other EAs.},
    booktitle = {Proceedings of the 8th Annual Conference on Genetic and Evolutionary Computation},
    pages = {815–822},
    numpages = {8},
    keywords = {age, computer-automated design, evolutionary algorithms, open-ended design, premature convergence},
    location = {Seattle, Washington, USA},
    series = {GECCO '06}
}

@article{hfc,
    author = {Hu, Jianjun and Goodman, Erik and Seo, Kisung and Fan, Zhun and Rosenberg, Rondal},
    title = {The Hierarchical Fair Competition (HFC) Framework for Sustainable Evolutionary Algorithms},
    year = {2005},
    issue_date = {June 2005},
    publisher = {MIT Press},
    address = {Cambridge, MA, USA},
    volume = {13},
    number = {2},
    issn = {1063-6560},
    url = {https://doi.org/10.1162/1063656054088530},
    doi = {10.1162/1063656054088530},
    abstract = {Many current Evolutionary Algorithms (EAs) suffer from a tendency to converge prematurely or stagnate without progress for complex problems. This may be due to the loss of or failure to discover certain valuable genetic material or the loss of the capability to discover new genetic material before convergence has limited the algorithm's ability to search widely. In this paper, the Hierarchical Fair Competition (HFC) model, including several variants, is proposed as a generic framework for sustainable evolutionary search by transforming the convergent nature of the current EA framework into a non-convergent search process. That is, the structure of HFC does not allow the convergence of the population to the vicinity of any set of optimal or locally optimal solutions. The sustainable search capability of HFC is achieved by ensuring a continuous supply and the incorporation of genetic material in a hierarchical manner, and by culturing and maintaining, but continually renewing, populations of individuals of intermediate fitness levels. HFC employs an assembly-line structure in which subpopulations are hierarchically organized into different fitness levels, reducing the selection pressure within each subpopulation while maintaining the global selection pressure to help ensure the exploitation of the good genetic material found. Three EAs based on the HFC principle are tested - two on the even-10-parity genetic programming benchmark problem and a real-world analog circuit synthesis problem, and another on the HIFF genetic algorithm (GA) benchmark problem. The significant gain in robustness, scalability and efficiency by HFC, with little additional computing effort, and its tolerance of small population sizes, demonstrates its effectiveness on these problems and shows promise of its potential for improving other existing EAs for difficult problems. A paradigm shift from that of most EAs is proposed: rather than trying to escape from local optima or delay convergence at a local optimum, HFC allows the emergence of new optima continually in a bottom-up manner, maintaining low local selection pressure at all fitness levels, while fostering exploitation of high-fitness individuals through promotion to higher levels.},
    journal = {Evol. Comput.},
    month = jun,
    pages = {241–277},
    numpages = {37}
}

@article{fitnessUniform,
    author = {Hutter, M. and Legg, S.},
    title = {Fitness uniform optimization},
    year = {2006},
    issue_date = {October 2006},
    publisher = {IEEE Press},
    volume = {10},
    number = {5},
    issn = {1089-778X},
    url = {https://doi.org/10.1109/TEVC.2005.863127},
    doi = {10.1109/TEVC.2005.863127},
    abstract = {In evolutionary algorithms, the fitness of a population increases with time by mutating and recombining individuals and by a biased selection of fitter individuals. The right selection pressure is critical in ensuring sufficient optimization progress on the one hand and in preserving genetic diversity to be able to escape from local optima on the other hand. Motivated by a universal similarity relation on the individuals, we propose a new selection scheme, which is uniform in the fitness values. It generates selection pressure toward sparsely populated fitness regions, not necessarily toward higher fitness, as is the case for all other selection schemes. We show analytically on a simple example that the new selection scheme can be much more effective than standard selection schemes. We also propose a new deletion scheme which achieves a similar result via deletion and show how such a scheme preserves genetic diversity more effectively than standard approaches. We compare the performance of the new schemes to tournament selection and random deletion on an artificial deceptive problem and a range of NP hard problems: traveling salesman, set covering, and satisfiability},
    journal = {Trans. Evol. Comp},
    month = oct,
    pages = {568–589},
    numpages = {22},
    keywords = {Fitness tree model, fitness uniform deletion scheme, fitness uniform selection scheme, local optima, preserve diversity, satisfiability, set covering, traveling salesman}
}

@phdthesis{mahfoud_NichingMethodsMultimodal_1995,
    title = {Niching Methods for Genetic Algorithms},
    author = {Mahfoud, Samir W.},
    year = {1995},
    school = {University of Illinois at Urbana-Champaign},
    address = {Urbana}
}

@software{jax,
  author = {James Bradbury and Roy Frostig and Peter Hawkins and Matthew James Johnson and Chris Leary and Dougal Maclaurin and George Necula and Adam Paszke and Jake Vander{P}las and Skye Wanderman-{M}ilne and Qiao Zhang},
  title = {{JAX}: composable transformations of {P}ython+{N}um{P}y programs},
  url = {http://github.com/jax-ml/jax},
  version = {0.3.13},
  year = {2018},
}

@article{qdax,
	title = {{QDax}: a library for quality-diversity and population-based algorithms with hardware acceleration},
	volume = {25},
	url = {http://jmlr.org/papers/v25/23-1027.html},
	number = {108},
	journal = {Journal of Machine Learning Research},
	author = {Chalumeau, Felix and Lim, Bryan and Boige, Raphaël and Allard, Maxime and Grillotti, Luca and Flageat, Manon and Macé, Valentin and Richard, Guillaume and Flajolet, Arthur and Pierrot, Thomas and Cully, Antoine},
	year = {2024},
	pages = {1--16},
}

@article{qd_framework,
  author={Cully, Antoine and Demiris, Yiannis},
  journal={IEEE Transactions on Evolutionary Computation}, 
  title={Quality and Diversity Optimization: A Unifying Modular Framework}, 
  year={2018},
  volume={22},
  number={2},
  pages={245-259},
  keywords={Optimization;Legged locomotion;Sociology;Statistics;Algorithm design and analysis;Evolutionary computation;Behavioral diversity;collection of solutions;novelty search;optimization methods;quality-diversity (QD)},
  doi={10.1109/TEVC.2017.2704781},
}

@article{csc,
  author={Grillotti, Luca and Cully, Antoine},
  journal={IEEE Transactions on Evolutionary Computation}, 
  title={Unsupervised Behavior Discovery With Quality-Diversity Optimization}, 
  year={2022},
  volume={26},
  number={6},
  pages={1539-1552},
  keywords={Containers;Robots;Magnetosphere;Ion radiation effects;Robot sensing systems;Task analysis;Optimization;Behavioral diversity;optimization methods;quality-diversity (QD) optimization;robotics;unsupervised learning},
  doi={10.1109/TEVC.2022.3159855},
}

@article{faldor_SynergizingQualityDiversityDescriptorConditioned_2024,
    author = {Faldor, Maxence and Chalumeau, F\'{e}lix and Flageat, Manon and Cully, Antoine},
    title = {Synergizing Quality-Diversity with Descriptor-Conditioned Reinforcement Learning},
    year = {2024},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3696426},
    doi = {10.1145/3696426},
    abstract = {A hallmark of intelligence is the ability to exhibit a wide range of effective behaviors. Inspired by this principle, Quality-Diversity algorithms, such as, are evolutionary methods designed to generate a set of diverse and high-fitness solutions. However, as a genetic algorithm, relies on random mutations, which can become inefficient in high-dimensional search spaces, thus limiting its scalability to more complex domains, such as learning to control agents directly from high-dimensional inputs. To address this limitation, advanced methods like and have been developed, which combine actor-critic techniques from Reinforcement Learning with, significantly enhancing the performance and efficiency of Quality-Diversity algorithms in complex, high-dimensional tasks. While these methods have successfully leveraged the trained critic to guide more effective mutations, the potential of the trained actor remains underutilized in improving both the quality and diversity of the evolved population. In this work, we introduce, an extension of that utilizes the descriptor-conditioned actor as a generative model to produce diverse solutions, which are then injected into the offspring batch at each generation. Additionally, we present an empirical analysis of the fitness and descriptor reproducibility of the solutions discovered by each algorithm. Finally, we present a second empirical analysis shedding light on the synergies between the different variations operators and explaining the performance improvement from to.},
    journal = {ACM Trans. Evol. Learn. Optim.},
    month = sep,
    keywords = {Quality-Diversity, Reinforcement Learning, Neuroevolution, MAP-Elites, Policy Gradient}
}

@inproceedings{faldor_MAPElitesDescriptorConditionedGradients_2023,
	address = {New York, NY, USA},
	series = {{GECCO} '23},
	title = {{MAP}-{Elites} with {Descriptor}-{Conditioned} {Gradients} and {Archive} {Distillation} into a {Single} {Policy}},
	isbn = {9798400701191},
	url = {https://dl.acm.org/doi/10.1145/3583131.3590503},
	doi = {10.1145/3583131.3590503},
	abstract = {Quality-Diversity algorithms, such as MAP-Elites, are a branch of Evolutionary Computation generating collections of diverse and high-performing solutions, that have been successfully applied to a variety of domains and particularly in evolutionary robotics. However, MAP-Elites performs a divergent search based on random mutations originating from Genetic Algorithms, and thus, is limited to evolving populations of low-dimensional solutions. PGA-MAP-Elites overcomes this limitation by integrating a gradient-based variation operator inspired by Deep Reinforcement Learning which enables the evolution of large neural networks. Although high-performingin many environments, PGA-MAP-Elites fails on several tasks where the convergent search of the gradient-based operator does not direct mutations towards archive-improving solutions. In this work, we present two contributions: (1) we enhance the Policy Gradient variation operator with a descriptor-conditioned critic that improves the archive across the entire descriptor space, (2) we exploit the actor-critic training to learn a descriptor-conditioned policy at no additional cost, distilling the knowledge of the archive into one single versatile policy that can execute the entire range of behaviors contained in the archive. Our algorithm, DCG-MAP-Elites improves the QD score over PGA-MAP-Elites by 82\% on average, on a set of challenging locomotion tasks.},
	urldate = {2025-01-07},
	booktitle = {Proceedings of the {Genetic} and {Evolutionary} {Computation} {Conference}},
	publisher = {Association for Computing Machinery},
	author = {Faldor, Maxence and Chalumeau, Félix and Flageat, Manon and Cully, Antoine},
	month = jul,
	year = {2023},
	pages = {138--146},
}

@inproceedings{cqd,
    address = {Massachusetts, Boston},
    title = {A discretization-free metric for assessing quality diversity algorithms},
    isbn = {978-1-4503-9268-6},
    url = {https://doi.org/10.1145/3520304.3534018},
    doi = {10.1145/3520304.3534018},
    language = {en-GB},
    urldate = {2025-01-29},
    booktitle = {{GECCO} '22: {Proceedings} of the {Genetic} and {Evolutionary} {Computation} {Conference} {Companion}},
    publisher = {ACM},
    author = {Kent, Paul and Branke, Juergen and Gaier, Adam and Mouret, Jean-Baptiste},
    month = jul,
    year = {2022},
    pages = {2131--2135},
}
