\section{Background} \label{sec:background}

\subsection{Diffusion Models}
Consider data distribution $\pdata$ on support $\mcx$, and let the stochastic process $(\bfX_t)_{t=0}^T$ be given by the following dynamics; known as the forward process:
    \begin{equation}
          \label{eq:forward}
            \rmd \bfX_t = f(t)\bfX_t \rmd t + g(t) \rmd \bfB_t  ,\quad \bfX_0 \sim p_0\defeq\pdata,
        \end{equation}
        with Brownian motion, $(\bfB_t)_{t \in \ccint{0,T}}$, drift
        $f: \rset \to \rset$ and scale $g: \rset \to \rset$ applied coordinate wise and let $p_t$ denotes the marginal density of $\bfX_t$.

    Diffusion models \citep{song2020denoising, song2021scorebased, ho2020denoising} generate new samples by simulating from the stochastic process \eqref{eq:time_reversed} with density denoted $q^\lambda_{0:T}$, initialization $\tilde{\bfX}_0 \sim p_T$ and $\tilde{\bfB}_t$ denotes another Brownian motion, independent to the forward process. 
    \begin{equation}\small 
      \label{eq:time_reversed}
      \rmd \tilde{\bfX}_t = \left[-f(t) + g^2(t) \tfrac{1+\lambda^2}{2}\nabla \log p_{T-t}(\tilde{\bfX}_t) \right] \rmd t + \lambda g(t)
      \rmd \tilde{\bfB}_t.
    \end{equation}
    Parameter $\lambda>0$ controls the degree of stochasticity
    within $q^\lambda_{0:T}$ \citep{diffnormflow, zhang2022fast}. In particular, for $\lambda=1$, $p_{0:T}=q^1_{0:T}$, hence $q^1_{0:T}$ corresponds to the time-reversal of \eqref{eq:forward} \citep{haussmann1986time,anderson1965iterative}. Setting $\lambda=0$, results in the probability flow ODE \citep{song2021scorebased}. The marginal distributions of \eqref{eq:time_reversed} match those of \eqref{eq:forward}, i.e. $q^\lambda_t = p_t$, for all $t$ and all $\lambda\geq 0$, hence \eqref{eq:time_reversed} generates the data distribution $q^\lambda_0=p_0=\pdata$.
    
    
    \textbf{Training.} The score term, $\nabla \log p_{t}(\bfX_t)$, is generally intractable but can be expressed as the solution to a regression problem on the conditional score, then approximated by training a parameterized function $s^*_\theta$. This is known as denoising score-matching (DSM) \citep{song2019generative, vincent2011connection}:
    \begin{align*} 
         s^*_\theta =\arg\min_{s_\theta} \mathbb{E}_{p_{0,t}}[\|s_\theta(\bfX_{t},t) - \nabla_{x_{t}} \log p_{t|0}(\bfX_{t}|\bfX_{0})\|^2].
    \end{align*}
     Given the drift function in \eqref{eq:forward} is typically chosen to be linear in state $\bfX_t$ and applied coordinate-wise, then the forward process may be sampled in closed form using $\bfX_t|x_0 = \alpha_t x_0 + \sigma_t\epsilon$, $\epsilon\sim \mcn(\mathbf{0}, \Ibb)$, for some time-indexed coefficients $\alpha_t, \sigma_t \in \mathbb{R}^+$, \citep{sarkka2019applied, song2021scorebased}. The conditional score $\nabla_{x_{t}} \log p_{t|0}(\bfX_{t}|\bfX_{0})$ is therefore tractable. Alternatively, based on Tweedie's formula \citep{efron_tweedie, Robbins1956AnEB}: $
    \nabla \log p_t(x_t) = \sigma_t^{-2}(\alpha_t \mathbb{E}_{X_0|x_t}[\bfX_0 |x_t] - x_t)$; one may approximate the expected denoiser $\mathbb{E}_{\bfX_0|x_t}[\bfX_0 |x_t]$ via regression as in \eqref{eq:denoise_loss}:
    \begin{align} \label{eq:denoise_loss}
         D^*_\theta =\arg\min_{D_\theta} \mathbb{E}_{p_{0,t}}[\|D_\theta(\bfX_{t},t) - \bfX_{0}\|^2].
    \end{align}
    \textbf{Conditional Generation}.
    Conditional generation is typically achieved via a conditional score, which can either be trained by DSM or decomposed into a unconditional and guidance term. The unconditional score can be pre-trained via DSM and the guidance term $\nabla \log p(y \mid x_t)$ , which can be approximated in many ways such as via some classifier \citep{dhariwal2021diffusion}; classifier on a denoised state \citep{chungdiffusion} or simply trained via denoising \citep{ho2022classifier, denker2024deft}:
    \begin{equation}
        \nabla \log p_t(x_t \mid  y) =  \nabla \log p_t(x_t) + \omega \nabla \log p_t(y \mid x_t).
    \end{equation}
    Here $\omega \geq 1$ heuristically adjusts guidance strength, similar to temperature controlled sampling.  Classifier-free guidance is the most commonly used training approach, estimating the guidance term by $\nabla \log p(y \mid x_t)=\nabla \log p(x_t \mid y) - \nabla \log p_t(x_t)$, where each individual term is trained via conditional DSM. 

\subsection{Energy Based Models}\label{sec:ebm}
Energy-based models (EBMs) \citep{lecun2006tutorial} approximate density $\pdata \approx p_\theta:= Z^{-1}e^{-E_\theta}$ using $\theta$ parameterized potential $E_\theta(x)$, for normalising constant $Z$. The seminal work of~\citet{teh2003energy}, later improved by~\citet{du2021improved}, introduced contrastive training of EBM by taking gradient steps on $-\expect_{x\sim p_0}[E_{\theta}(x)]+\expect_{x\sim p_\theta}[E_{\theta}(x)]$. Sampling $p_\theta$ typically entails expensive MCMC methods however.  

\textbf{Diffusion models as a sequence of energy based models}.
Given the idealised score, $\nabla \log p_t$, is a gradient one could avoid MCMC and use denoising score matching to learn a sequence of energy functions $(E_\theta(\cdot,t))_t$ such that $-\nabla_{x_t} E_\theta(x_t,t) \approx \nabla \log p_t(x_t)$, i.e. $s_\theta(x_t,t):=-\nabla_{x_t} E_\theta(x_t,t)$, henceforth referred to as an energy-parameterisation. This is in contrast to the usual diffuson model parameterisation where score or denoiser is approximated directly with a neural network $s_\theta(x_t,t) \approx \nabla \log p_t(x_t)$. Energy parameterized diffusion models were first shown to be possible for image datasets in \cite{salimans2021should} by careful choice of architecture, yet thus far remains noticeably inferior to unconstrained diffusion models.

\subsection{Sequential Monte Carlo} 
Before delving into our method, we briefly recap Sequential Monte Carlo (SMC)  \citep{doucet2001sequential, chopin2020introduction} for later use in \Cref{sec:comp_cont}. SMC entails propagating $K$ particles initially sampled from some distribution $M_0$ through a sequence of proposal, importance weighting, and resampling steps. The resampling steps are crucial to ensuring computation is focused on promising particles, and to avoiding weight degeneracy. A simplified algorithm is presented in \Cref{alg:gen_smc}, any resampling approaches could be used, in practice we use adaptive resampling \citep{del2011adaptive} with the systematic resampler \citep[Chapter 4]{chopin2020introduction}.

SMC enables an approximate change of measure through the Feynman Kac model (FKM) framework \citep{chopin2020introduction, del2004feynman}. A FKM consists of an initial distribution $M_0$; some time indexed Markov transition kernels $(M_t)_t$, which we can sample from; and non-negative potential functions $(G_t)_t$, $G_0: \mathcal{X} \rightarrow \mathbb{R}^+$, $G_t: \mathcal{X}^2 \rightarrow \mathbb{R}^+$. 
\begin{align}
    &M(\mathrm{d}x_{0:T}) = M_0(\mathrm{d}x_0)\prod_{t=1}^{T}M_t(\mathrm{d}x_t|x_{t-1}) \label{eq:proposal_measure} \\ \vspace{-0.1cm}
    &Q(\mathrm{d}x_{0:T}) \propto G_0(x_0)\prod_{t=1}^{T}G_t(x_t,x_{t-1})M(\mathrm{d}x_{0:T}) \label{eq:fk_measure} 
\end{align}
The use of potentials permits a change of measure from the proposal from Markov process \eqref{eq:proposal_measure} to the FKM distribution \eqref{eq:fk_measure}, where \eqref{eq:fk_measure} can be approximately simulated with SMC or particle filtering as in \Cref{alg:gen_smc}.
{\small
\begin{algorithm}
        \caption{Generative SMC}
        \label{alg:gen_smc}
        \setlength{\parindent}{0pt}
        \begin{algorithmic}
            \State{Sample $\bfX_{0}^{k}\stackrel{\text{i.i.d.}}{\sim} M_0$ ~for $k \in [K]$}
           \State{Weight $\omega_1^{k}=G_0(\bfX^{k}_0)$~for $k \in [K]$}
        \For{$t=1,...,T$}
            \State{Normalize weights $w^{k}_{t-1}\propto \omega^{k}_{t-1}$, $\sum_{k=1}^K  w^{k}_{t-1}=1$}
            \State{Resample $\tilde{\bfX}^{k}_{t-1}\sim \sum_{k=1}^K  w^{k}_{t-1} \delta_{\bfX^{k}_{t-1}}$ ~for $k \in [K]$}
                \State{Proposal $\bfX_{t}^{k}\sim M(\cdot|\tilde{\bfX}^{k}_{t-1})$  ~for $k \in [K]$}
                \State{Weight $\omega^{k}_t= G(\bfX_{t}^{k},\tilde{\bfX}^{k}_{t-1})$}
        \EndFor
        \State{{\bfseries Return:} samples $(\bfX_{T}^{k})_k$}
        \end{algorithmic}
        \end{algorithm}
        }






