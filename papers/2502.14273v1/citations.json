[
  {
    "index": 0,
    "papers": [
      {
        "key": "openai2024gpt4",
        "author": "{OpenAI}",
        "title": "GPT-4 Technical Report"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "dubey2024llama",
        "author": "Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and others",
        "title": "The llama 3 herd of models"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "liu2024improved",
        "author": "Liu, Haotian and Li, Chunyuan and Li, Yuheng and Lee, Yong Jae",
        "title": "Improved baselines with visual instruction tuning"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "chen2023minigptv2",
        "author": "Chen, Jun and Zhu, Deyao and Shen, Xiaoqian and Li, Xiang and Liu, Zechun and Zhang, Pengchuan and Krishnamoorthi, Raghuraman and Chandra, Vikas and Xiong, Yunyang and Elhoseiny, Mohamed",
        "title": "MiniGPT-v2: Large Language Model as a Unified Interface for Vision-Language Multi-Task Learning"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "zang2024contextual",
        "author": "Zang, Yuhang and Li, Wei and Han, Jun and Zhou, Kaiyang and Loy, Chen Change",
        "title": "Contextual object detection with multimodal large language models"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "tang2024chain",
        "author": "Tang, Lv and Jiang, Peng-Tao and Shen, Zhi-Hao and Zhang, Hao and Chen, Jin-Wei and Li, Bo",
        "title": "Chain of visual perception: Harnessing multimodal large language models for zero-shot camouflaged object detection"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "zhu2024multi",
        "author": "Zhu, Jian and Wang, Hanli and Shi, Miaojing",
        "title": "Multi-modal large language model enhanced pseudo 3d perception framework for visual commonsense reasoning"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "tan2021efficientnetv2",
        "author": "Tan, Mingxing and Le, Quoc",
        "title": "Efficientnetv2: Smaller models and faster training"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "gehrig2022high",
        "author": "Gehrig, Daniel and Scaramuzza, Davide",
        "title": "Are high-resolution event cameras really needed?"
      },
      {
        "key": "son20174",
        "author": "Son, Bongki and Suh, Yunjae and Kim, Sungho and Jung, Heejae and Kim, Jun-Seok and Shin, Changwoo and Park, Keunju and Lee, Kyoobin and Park, Jinman and Woo, Jooyeon and others",
        "title": "4.1 A 640$\\times$ 480 dynamic vision sensor with a 9$\\mu$m pixel and 300Meps address-event representation"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "zheng2024eventdance",
        "author": "Zheng, Xu and Wang, Lin",
        "title": "EventDance: Unsupervised Source-free Cross-modal Adaptation for Event-based Object Recognition"
      },
      {
        "key": "su2023event",
        "author": "Su, Menghao and Yang, Panpan and Jiang, Runhao and Yan, Rui",
        "title": "Event-based object recognition using feature fusion and spiking neural networks"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "wu2023eventclip",
        "author": "Wu, Ziyi and Liu, Xudong and Gilitschenski, Igor",
        "title": "Eventclip: Adapting clip for event-based object recognition"
      },
      {
        "key": "zhou2023clip",
        "author": "Zhou, Jiazhou and Zheng, Xu and Lyu, Yuanhuiyi and Wang, Lin",
        "title": "E-clip: Towards label-efficient event-based open-world understanding by clip"
      },
      {
        "key": "zhou2024eventbind",
        "author": "Zhou, Jiazhou and Zheng, Xu and Lyu, Yuanhuiyi and Wang, Lin",
        "title": "Eventbind: Learning a unified representation to bind them all for event-based open-world understanding"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "wu2023eventclip",
        "author": "Wu, Ziyi and Liu, Xudong and Gilitschenski, Igor",
        "title": "Eventclip: Adapting clip for event-based object recognition"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "zhou2024eventbind",
        "author": "Zhou, Jiazhou and Zheng, Xu and Lyu, Yuanhuiyi and Wang, Lin",
        "title": "Eventbind: Learning a unified representation to bind them all for event-based open-world understanding"
      },
      {
        "key": "gehrig2024low",
        "author": "Gehrig, Daniel and Scaramuzza, Davide",
        "title": "Low-latency automotive vision with event cameras"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "yu2024can",
        "author": "Yu, Zongyou and Qu, Qiang and Chen, Xiaoming and Wang, Chen",
        "title": "Can Large Language Models Grasp Event Signals? Exploring Pure Zero-Shot Event-based Recognition"
      }
    ]
  }
]