\section{Related Work}
\subsection{LLM Agent}
An agent refers to an entity capable of perceiving its environment and taking action to achieve its goals. AI agents are increasingly seen as a promising direction toward achieving Artificial General Intelligence (AGI) \citep{durante2024agent}. Agents leverage the capabilities of Large Language Models (LLMs) to perform various tasks. In the construction of LLM agents, two of the most crucial aspects are (1) the architecture and (2) the method of acquiring capabilities. The architecture of LLM agents consists of four parts: Profile (primarily involving character background, written as prompts), Memory (including environmental and contextual information), Planning (allowing the agent to rationally execute according to a plan), and Action (transforming the agent's decisions into reasonable outputs)\citep{wang2024survey}. The method of acquiring capabilities is mainly divided into whether fine-tuning is performed. ReAct \citep{yao2022react} proposed a framework that combines reasoning and action, utilizing prompt engineering for task decomposition. Later, AutoGPT \citep{yang2023auto} introduced memory mechanisms and tool invocation capabilities, supporting multi-step task execution. HuggingGPT \citep{shen2024hugginggpt} coordinated multimodal models through LLMs, validating the potential of LLMs as the control hub. In multi-agent systems, early research borrowed from traditional multi-agent system architecture designs, proposing two mainstream frameworks: hierarchical (e.g., MetaGPT \citep{hong2023metagpt}) and decentralized (e.g., AutoGen \citep{wu2023autogen}). To enhance collaboration efficiency, researchers have explored various interaction paradigms, such as role-playing (CAMEL \citep{li2023camel} promotes task decomposition through predefined role divisions), debate negotiation (e.g., the debate decision-making framework MAD \citep{liang2024encouragingdivergentthinkinglarge}), and knowledge sharing (AgentVerse \citep{chen2023agentverse} uses dynamic memory banks to achieve experience transfer).

\subsection{LLM-assisted Psychology}
The powerful capabilities of LLMs in natural language processing and simulating interpersonal interactions have provided opportunities to assist in mental health. LLMs can play a role in various areas such as medical diagnosis, expansion of mental health resources, and therapy \citep{hua2024large}. In diagnosis, LLMs are widely used for screening and diagnosing mental health issues, including depression, anxiety, and post-traumatic stress disorder (PTSD). In mental health resource development, LLMs address the scarcity of mental health data by generating synthetic data (e.g., simulated counseling dialogues) or expanding existing clinical questionnaires. In psychological therapy, the application of LLMs offers new possibilities for improving mental health services. By increasing accessibility, providing personalized treatment plans, and reducing treatment costs, LLMs have the potential to enhance mental health care. SMILE utilizes ChatGPT to convert single-turn long conversations into multi-turn dialogues for the development of specialized dialogue systems for mental health support \citep{qiu2023smile}. SoulChat constructs the SoulChatCorpus dataset based on psychological consultation questions and answers, fine-tuning it to significantly enhance LLMs' abilities to provide empathy, listening, and comfort when offering emotional support \citep{chen2023soulchat}. MindChat is trained on one million high-quality multi-turn mental health conversation data to communicate in a more empathetic and guiding manner with users \citep{MindChat}.