\section{Introduction}

Combinatorial optimization (CO) lies at the core of numerous scientific and engineering studies, encompassing applications in network design, resource allocation, healthcare, and supply chain~\citep{du1998handbook, hoffman2000combinatorial, zhong2021preface}. Combinatorial optimization usually involves selecting an optimal solution from a discrete but often exponentially large set of candidates. 
Many are NP-hard (meaning that if $P \neq NP$ then there is no polynomial-time algorithm for solving them in the general cases~\citep{papadimitriou1998combinatorial}). This makes it challenging to design algorithms with provable guarantees, but in practice solvers can find reasonable quality solutions (e.g., \gurobi~\citep{gurobi}). 
%have demonstrated remarkable empirical success across diverse problem domains, offering practical solutions even for intractable problem sizes.
%computationally challenging. %Despite the broad applications, 
%Many combinatorial optimization problems are NP-hard, 


Recent advances in artificial intelligence (AI) and GPU computing have motivated use of AI-inspired approaches, e.g., Graph Neural Networs (GNNs) and reinforcement learning,  to learn problem-specific strategies for NP-hard optimization problems such as MIS~\citep{li2018combinatorial, ahn2020learning} and TSP~\citep{kool2018attention, zhang2021solving}. AI models can also be trained to predict search directions or refine heuristic rules~\citep{li2018combinatorial, d2020learning}. These algorithms utilize advanced GPUs and often require shorter inference compared to CPU-based algorithms. Additionally, AI-inspired methods avoid the need to design heuristics for specific problems, allowing generalization to new instances and problems~\citep{bengio2021machine, cappart2023combinatorial}.


%As computational resources continue to grow, AI-inspired combinatorial optimization offers an exciting paradigm shift to tackle hard combinatorial problems. 
%{\sc list here some notable papers and  summarize claims in some of them}




%e remarkable progress in AI-inspired combinatorial optimization, 
%{\sc have there been studies about the most recent AI-inspired methods or not? If not, then say that more clearly. Otherwise the reader has no idea why our paper is novel or important}

Despite the claimed benefits of AI-inspired methods, a few years ago~\citet{angelini2023modern} showed that a Graph Neural Network based MIS algorithm~\citep{schuetz2022combinatorial} failed to surpass greedy algorithms.
\citet{boether_dltreesearch_2022} showed that AI-inspired approaches fail to provide superior search directions compared to traditional heuristics in tree search algorithms for MIS. \citet{gamarnik2023barriers} suggests that GNN has theoretical limits which may become obstacles for GNN-based MIS algorithms. %(In addition, AI-inspired algorithms may require significant training time and GPU memory, which makes it unfair to compare directly with CPU algorithms in efficiency.)

However, in recent years many new AI-inspired CO algorithms, utilizing a variety of techniques, such as diffusion models~\citep{sun2023difusco, sanokowskidiffusion}, GPU-accelerated sampling~\citep{sun2023revisiting}, and direct optimization~\citep{alkhouri2024dataless} have been developed and claimed to significant improve over the previous ones. Furthermore, GFlowNets~\cite{bengio2021flow}, which have been proposed as general-purpose tools for tasks like scientific discovery and reinforcement learning~\cite{bengio2023gflownet}, has also been used to solve CO problems~\citep{zhang2023let}. Since combinatorial optimization is an arena where humans have hand-designed algorithms for many decades, the following question is of great scientific interest:
%It is not clear whether these algorithms have overcome previous obstacles and outperform classical heurstics. Which raises the question:
\begin{quote}
    \centering
    \emph{Do AI-inspired algorithms perform better than classical heuristics for \\combinatorial optimization?}
\end{quote}

%\textcolor{blue}{But there has been no systematic study of these newer methods. Furthermore, 
%There is an important scientific motivation to study this issue, since Thus it seems worthwhile to check how they compare to human-designed algorithms in a well-studied setting.

%\vspace{-1mm}
\subsection{Our contributions}

We explore the question in the context of 
%the realm of the 
\texttt{Maximum Independent Set} (MIS) problem: given a graph, aiming to find the largest subset of nodes with no edges present between any node pair.
%The problem is NP-hard, and thus unlikely to have efficient algorithms that solve all instances. 
The simplicity of the problem attracted design of many heuristics to tackle the problem~\citep{andrade2012fast, lamm2015graph}. In recent works, MIS is also a main target in efforts that design AI-inspired approaches such as non-convex optimization~\citep{schuetz2022combinatorial, alkhouri2024dataless}, reinforcement learning~\citep{ahn2020learning, zhang2023let}, and diffusion models~\citep{sun2023difusco, sanokowskidiffusion}. 

%Thus MIS is a good problem for  systematically comparing classical algorithms  and AI-inspired methods. %Although MIS was shown to be NP-hard, that result speaks primarily to the difficulty of the problem on worst-case graphs.
%Random graph families are often used in evaluating MIS algorithms, which we also use. They can be easily generated and definitely a fair arena for AI-inspired methods, since the input is drawn from a  fixed and easily understood distribution. 

%\haoyu{need to discuss why we test these algorithms, the newest for each ``category''}
For classical heuristics, we test degree-based greedy (\deggreedy, pick a node with smallest degree at each step), and the state-of-the-art MIS solver \kamis~\citep{lamm2017finding, dahlum2016accelerating, hespe2019scalable}.
%, which is a nontrivial implementation of a local-search algorithm. 
For AI-inspired algorithms, we test the newest algorithms from each ``category'' according to the techniques they use, including sampling algorithm \isco~\citep{sun2023revisiting}, non-convex optimization algorithm \pcqo~\citep{alkhouri2024dataless}, reinforcement-learning related algorithms \lwd~\citep{ahn2020learning} and  \gflownets~\citep{zhang2023let} (based on GFlowNets~\citep{bengio2021flow}) and diffusion models \difusco~\citep{sun2023difusco} and \diffuco~\citep{sanokowskidiffusion}.

Testing on different graph types with different sizes and densities leads to the following empirical finding (\Cref{sec:exp-results}).

%\textcolor{blue}{We benchmark different heuristics, from random greedy (\rangreedy, randomly pick a feasible node into the independent set and repeat) and degree-based greedy (\deggreedy, pick a node with smallest degree at each step and repeat) to the state-of-the-art MIS solver \kamis~\citep{lamm2017finding, dahlum2016accelerating}, with non-convex optimization algorithm \pcqo~\citep{alkhouri2024dataless}, reinforcement learning related algorithm \gflownets~\citep{zhang2023let}, and diffusion models \difusco~\citep{sun2023difusco}/\diffuco~\citep{sanokowskidiffusion}. }

\underline{\textbf{Finding 1}:} \emph{Current AI-inspired algorithms for MIS still don't outperform the best heuristic \kamis, which runs on a single thread in a CPU, while AI-inspired methods often require significant computational resources.}

\underline{\textbf{Finding 2}:} \emph{As the graph becomes larger or denser, \kamis  exhibits a notable superiority to AI-inspired algorithms.}

\underline{\textbf{Finding 3}:} \emph{The simplest degree-based greedy algorithm (\deggreedy) serves as a very strong baseline. Some AI-inspired algorithms perform similarly to or worse than \deggreedy, especially for larger and denser graphs.}

%We discuss our experimental findings in 
\Cref{sec:ablations} presents ablation studies to understand why some AI-inspired methods fail to improve over the simplest \deggreedy method. We introduce a new mode of analysis, \emph{serialization}, that transforms the solution of any algorithm into a sequential list of choices leading to the final independent set. We compare sequential order with the one produced by \deggreedy (\Cref{sec:comp-gflownets,sec:comp-other-algs}). We find that the reinforcement learning related algorithm \gflownets, based on GFlowNets, behaves similarly to \deggreedy. We also found several qualitative characteristics that appear to distinguish  algorithms that perform significantly better than \deggreedy from those that perform similarly or even worse than \deggreedy. We also explore whether AI-inspired method can improve their solution quality via a post-processing step using local search~(\Cref{sec:add-local-search}), but find that they still fail to outperform \kamis after some improvements. In \Cref{sec:refute-conjecture}, we discuss an additional result that may be of interest for MIS experts: on random graphs,   \kamis has a level of performance on MIS  that appears to contradict a well-known conjecture about polynomial-time algorithms~\cite{coja2015independent}.