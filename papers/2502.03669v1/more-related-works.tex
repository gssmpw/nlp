\section{More Related Works}\label{sec:more-related-works}

\paragraph{More on theoretical results for MIS}
For random ER graphs with number of nodes $n$ and average degree $d$, the upper bound of MIS size is $\frac{2n\ln d}{d}$ for asymptotically large $n$ and $d$.~\citep{coja2015independent}.
\citet{grimmett1975colouring} proves that the simplest \rangreedy can achieve half-optimal at $\frac{n \ln d}{d}$ on random ER graphs. Despite that, there is no known existing polynomial algorithm which can reach MIS size of $(1+\eps)\frac{n \ln d}{d}$ for any constant $\eps$ for asymptotically large $n$ and $d$.~\citep{coja2015independent}. \citet{coja2015independent} also suggests that the reason is likely independent sets of size larger than $(1+\eps)\frac{n \ln d}{d}$ forms an intricately ragged landscape, where local algorithms will stuck. \citet{gamarnik2014limits, rahman2017local} proves that for local algorithms (which is defined to only use information from a constant neighborhood of a node to decide whether the node is in the independent set) are at most half optimal for independent set on random $d$-regular graphs. \citet{gamarnik2014limits} suggests this is due to a property of the MIS problem, which they denote as the \emph{Overlap Gap Property} (OGP)~\citep{gamarnik2021overlap}. \citet{gamarnik2023barriers} suggests that graph neural networks (GNNs) are also a type of local algorithms and thus being limited by OGP. While most AI-inspired MIS algorithms use GNN, the proof only applies to algorithms use GNNs as the only component to find solutions like~\citep{schuetz2022combinatorial}, so it may not apply directly to more complicated algorithms like those tested in our paper. Yet, it may still suggests a reason why GNN-based algorithms (including most AI-inspired algorithms) cannot outperform classical heuristics like \kamis.

In addition, \citet{barbier2013hard} provides a conjectured tighter upper bound than $\frac{2n\ln d}{d}$ for $d$-regular graphs using the hard-core model in physics. \citet{ding2016maximum} proves a similar tighter upper bound for $d$-regular graphs. \citet{wormald2003analysis} gives average-case performance for \deggreedy on $d$-regular graphs.


\paragraph{More on classical heuristics}
Over the past few decades, significant progress has been made in tackling NP-hard combinatorial optimization (CO) problems by developing approximation algorithms and heuristic methods. Approximation algorithms provide provable guarantees on solution quality and have led to groundbreaking results for classical problems, such as the Maximum Independent Set (MIS), Traveling Salesperson Problem (TSP), and Maximum Cut~\citep{boppana1992approximating, laporte1992traveling, goemans1995improved}.

As we mentioned in \Cref{sec:related-works}, there are various existing heuristics for MIS. For exmaple, reduction techniques reduce the graph into smaller instances. \citet{akiba2016branch} and \citet{xiao2013confining} have shown a variety of reduction techniques which work well for MIS problem. \citet{butenko2002finding, bourgeois2012fast} uses reduction techniques to develop efficient exact algorithms for MIS. Local search improves an existing independent set by removing a small number of nodes and insert other eligible nodes. \citet{andrade2012fast} gives an efficient local search algorithm for MIS and has been used as a subprocess for several MIS solvers. Evolutionary algorithms combine several existing solutions into a new solution. Examples include \citet{back1994evolutionary, borisovsky2003experimental, lamm2015graph}. \kamis~\citep{lamm2017finding, dahlum2016accelerating} was developed based on many of these techniques above.

In addition, the MIS problem can also be relaxed into semi-definite programming (SDP), which leads to several approximation algorithms \citep{halperin2002improved, bansal2014approximating}.

\paragraph{More on AI methods for combinatorial optimization} 
In addition to \cref{sec:related-works}, we note that \citet{sun2022annealed, sanokowski2023variational, sanokowskidiffusion} use annealing techniques. \citet{sun2023difusco} was developed based on \citet{qiu2022dimes}, and \citet{sanokowskidiffusion} was based on \citet{sanokowski2023variational}. \citet{sanokowskidiffusion} can also be considered as an extension of \citet{karalias2020erdos}.


Besides MIS, Maximum Cut, and TSP, people also considered to use AI-Inspired methods for other combinatorial optimization problems, including Vehicle Routing Problems (including TSP)~\citep{kool2018attention, chen2019learning, delarue2020reinforcement, li2021deep, zheng2021combining, ye2024deepaco}, Job Scheduling Problems~\citep{lin2019smart, baer2019multi, zhang2020learning, ye2024deepaco}, Boolean Satisfiability (SAT)~\citep{amizadeh2019learning, you2019g2sat, kurin2020can, li2022nsnet, li2023hardsatgen}, and Casual Discovery~\citep{zheng2018dags, zhu2020causal, sanchez2022diffusion}.
