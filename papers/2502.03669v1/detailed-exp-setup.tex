\section{Detailed Experiment Setup}\label{sec:detail-exp-setup}
\subsection{Algorithm Pseudo-code for degree-based serialization}
Please refer to \Cref{alg:serialization} for the pseudo-code for degree-based serialization, mentioned in \Cref{sec:comp-other-algs}.

\begin{algorithm}[!h]
\caption{Degree-based solution serialization}
\label{alg:serialization}
\begin{algorithmic}[1]
\REQUIRE{The graph $\gG(\gV,\gE)$, the independent set $\gI$}
    \STATE // Maintain the copy
    \STATE $\gG'\leftarrow\gG,\gI'\leftarrow\gI$ 
    \STATE // Initialize empty ordered list
    \STATE $\gL = []$ 
    \WHILE{$\gI'\neq\phi$}
        \STATE pick $v\in \gI'$ with smallest degree in $\gG'$, break ties randomly
        \STATE $\gL\leftarrow \gL \cup \{v\}$
        \STATE Delete $\{v\}\cup \texttt{Neighbors}(v)$ from $\gG'$, delete $v$ from $\gI'$
    \ENDWHILE
    \RETURN Ordered list $\gL$
\end{algorithmic}
\end{algorithm}

\subsection{Datasets}
For synthetic graphs, we test $8$ graphs for each parameter $(n,d)$ or $(n,m)$. We test on $100$ graphs for real-world datasets. For learning-based algorithms, we use $4000$ training graphs generated using the same parameter (in case of random graphs) or drawn $4000$ graphs from the same real-world dataset.
\paragraph{Erd\H{o}s-Reny\'i (ER) graph}
ER graphs~\citep{erdos59a} have 2 parameters: the number of nodes $n$ and the average degree $d$. For graphs with given $(n,d)$ We generate them by choosing $M = \frac{nd}{2}$ edges uniformly at random between $n$ nodes. This is the Erd\H{o}s-Reny\'i's $G(n,M)$ model.

There is also $G(n,p)$ model for ER graphs, which is also used widely. They behave similarly for many graph properties to $G(n,M)$ models when $M = {n\choose 2} p$ and we expect the emipirical results for MIS problems will also be very similar.

For the main experiments, we use ER graphs with $n = \{100, 300, 1000, 3000, 10000\}, d = \{10, 30, 100, 300, 1000, 3000\}$ with $d < n$ as shown in \cref{tab:res-ba}. We also test on larger graphs with $n = \{30000, 1\times 10^5, 3\times 10^5, 1\times 10^6, 3 \times 10^6\}$ as shown in \cref{tab:res-er-larger-graph}. Due to computational and time limits, we could only obtain results from classical CPU-based algorithms for these large graph, and only sparse graphs for very large $n \geq 1\times 10^6$.

\paragraph{Barab\'asiâ€“Albert (BA) graph}
BA graphs~\citep{albert2002statistical} also have 2 parameters: the number of nodes $n$ and the generation parameter $m$, with $n > m$. For a given $(n,m)$, the generation process initializes with $m$ nodes, and then add 1 node at each step. When adding a new node, $m$ neighbors of the new node are sampled from the existing nodes, with the probability of the current degree of the nodes. The average degree of BA graph with given $(n,m)$ can be computed as $d = 2m - \frac{m}{n}-\frac{m^2}{n} \approx 2m$.

For the main experiments, similar to ER graphs, we also use $n = \{100, 300, 1000, 3000, 10000\}$. Since the average degree $d \approx 2m$, we use $m=\{5, 15, 50, 150, 500, 1500\}$ with $2m < n$.

\paragraph{Real-world graphs}
Since we need at least $4100$ graphs to train and test our algorithms and the graphs should not be too small, it is difficult to find such datasets. Fortunately, \citet{Morris+2020} provides a website \url{www.graphlearning.io} which includes many graph datasets prepared by them or collected from other works. Although most of the datasets are still too small or having too small graphs, we are able to find 2 datasets: REDDIT-MULTI-5K and COLLA, both from \citet{yanardag2015deep}. REDDIT-MULTI-5K has $4999$ graphs with average nodes $508.52$ and average edges $594.87$, so the graphs are generally very sparse. COLLA has $5000$ graphs with average nodes $74.49$ and $2457.78$, so they are denser but smaller graphs.

We were not able to find real-world datasets with enough size of more larger and denser graphs, which are generally more difficult for MIS algorithms. The dataset DIMACS used in \citet{boether_dltreesearch_2022} contains such graphs but they only have $37$ graphs which is not enough for training.

\subsection{Hardware configurations}
The CPU we use is either Intel Xeon Processor E5-2680 v4 @ 2.40GHz or Intel Xeon Silver 4214 Processor @ 2.20GHz. The GPU we use is Nvidia Tesla A100 80GB when we refer to time limit or time cost. For small graphs when the GPU memory limit and time limit is not reached, we also use Nvidia RTX A6000 48GB and Nvidia RTX 2080Ti 11GB.

\subsection{Classical CPU-based algorithms}
\paragraph{\rangreedy and \deggreedy}
\deggreedy(Degree-based Greedy) is as follows: Starting from an empty set. Select a node with the lowest degree of the graph (if there exists several nodes of the lowest degree, we pick one uniformly at random) and add it to the set. Then remove the node and all its neighbors from the graph. 

\rangreedy(Random Greedy) is as follows: Starting from an empty set. Select a node from the graph uniformly at random and add it into the set. Then remove the node and all its neighbors from the graph. The only difference between it and \deggreedy is that the choice of node is completely random.

They are both non-backtracking algorithms.

We did not include results of \rangreedy in the main paper because its performance is significantly lower than all other algorithms. It can be considered as a baseline and has theoretical significance, since it has provable guarantee for random graphs~\citep{grimmett1975colouring}.

In order to match the best-of-20 sampling we used for the learning-based-algorithms, we also ran \deggreedy for $20$ times and report the best results in the main experiments ($n \leq 10000$).

We wrote the script in Python and ran it on a single CPU thread for each graph with a time limit of 24hrs, but it actually run less than 1hr on smaller graphs like $n \leq 3000$. We gave 32GB memory for graphs with $n\leq 10000$ and 64GB memory for larger graphs. Since there are much more efficient implementations like C++, the efficiency of the greedy algorithms is not very relevant. 

\paragraph{\kamis (\onlinemis and \redumis)}
\kamis(Karlsruhe Maximum Independent Sets)~\citep{lamm2017finding} (\url{https://karlsruhemis.github.io/}) is the state-of-art heuristic solver for MIS and has been used as a baseline in many previous works. It provides 2 algorithms for the MIS problem: \redumis~\citep{lamm2017finding} and \onlinemis~\citep{dahlum2016accelerating}.

We can provide a time-limit for both algorithm. \onlinemis will use up the time given while \redumis will end on its own when it finds appropriate. In general, \redumis provides better results when given enough time, where \onlinemis is faster to reach a solution of reasonable quality for large and dense graphs.

We ran both algorithm on a single CPU thread for each graph with a time limit of 24hrs, because our benchmark focus on performance instead of efficiency. For relatively small graphs ($n\leq 3000$), \redumis often require less than 1hr and at most $1.25$hrs, and  \onlinemis can also provide answer with the same quality when giving 1hr time limit.  We gave 32GB memory for graphs with $n\leq 10000$ and 64GB memory for larger graphs. 

\subsection{GPU-accelerated non-learning algorithms}
\paragraph{\isco}
\isco(improved Sampling for Combinatorial Optimization)~\citep{sun2023revisiting}  is a GPU-accelerated sampling-based method. It does not require learning. According to \citep{sun2023revisiting}, the main benefit is that it can process a large batch of graphs in parallel thus improve efficiency. While processing a small number of graphs like in our case (8 test graphs), it still requires significant time, often longer than \redumis. 

We use the code from the codebase of DISCS~\citep{goshvadi2024discs}, which is a follow-up paper for \isco, as \isco did not provide the codebase. We use 1 80GB $A100$ GPU to run \isco with all test graphs together. The time limit is 96hrs, and the actual time it requires is shorter. It fail to run graphs of size $(n=3000,1000)$, $(n=10000, d=100)$, and larger because they require larger than 80GB memory. The code does not support multi-GPU.

\paragraph{\pcqo}
\pcqo(Parallelized
 Clique-Informed Quadratic Optimization)~\citep{alkhouri2024dataless} is a GPU-accelerated gradient-based optimization algorithm, which directly optimize on the quadratic loss function of the MIS problem. The loss function for a graph $G=(V,E)$ and solution vector $\vx$ is \begin{equation}
    f(\vx) \coloneqq -\sum_{v\in V} \vx_v + \gamma\sum_{(u,v)\in E} \vx_v \vx_u - \gamma' \sum_{(u,v)\in E'} \vx_v \vx_u,
\end{equation}
where $E'$ is the edge set of the complement graph $G'$. $\gamma$ and $\gamma'$ are hyperparameters and there are many other hyperparameters including learning rate, momentum, etc.

This algorithm is sensitive to hyperparameters and the default hyperparameters lead to bad solution quality for most of our dataset. Therefore, unlike in other algorithms where we use the default setting, we perform a hyperparameter tunining. We also did not find a good set of hyperparameters for all ER graphs or all BA graphs, so we do a grid search of hyperparameters for each dataset (i.e. for each $(n,d)$ pair in ER graphs and each $(n,m)$ pair in BA graphs).

Although \citet{alkhouri2024dataless} reported that using the third term in the loss function (i.e. nonzero $\gamma'$) can lead to better answers comparing to only using 2-term loss function (set $\gamma'=0$), we found that a nonzero $\gamma'$ makes the algorithm more sensitive to hyperparameters and difficult to perform hyperparameter tuning for our benchmark with many datasets. Therefore, we only use $2$-term loss function by setting $\gamma'=0$.

In the grid search for hyperparameters, we use learning rate $0.001$ (default), momentum $\{0.5, 0.9\}$, $\gamma \in \{4, 20, 100, 500, 2500\}$, and report the results obtained from the best hyperparameters. However, for $n \geq 30000$, the grid search within this domain does not provide solution with reasonable size (worse than \rangreedy), so we do not report results for larger graphs. Despite that, there may exist a better set of hyperparamters which could make this algorithm perform well on larger graphs.

We use 1 80GB $A100$ GPU for all test graphs together with a time limit of 96hrs. It is able to run all experiments from $n\leq 10000$, and often requires shorter time compared to \isco and \kamis.

\subsection{Learning-based algorithms}
We use $4000$ training graphs for each datasets to train our models. Without otherwise noted, all the training are in-distribution, with respect to a single set of parameters (i.e. $(n,d)$ for ER graphs, $(n,m)$ for BA graphs) for synthetic graphs.

\paragraph{\lwd}
\lwd(Learning what to Defer)~\citep{ahn2020learning} is a reinforcement learning based algorithm which requires training data to learn the policy. It models the MIS problem as a Markov Decision Process (MDP), where in each step it selects some (possibly $0$, $1$, or multiple) nodes to add into the independent set. It is a non-backtracking algorithm as the added nodes are never taken out. \citet{boether_dltreesearch_2022} also included this algorithm in their benchmark.

We use the code from \citet{boether_dltreesearch_2022} since it provides better functionality than the original codebase. We use the default setting provided by \citet{boether_dltreesearch_2022} in their MIS Benchmark codebase (\url{https://github.com/MaxiBoether/mis-benchmark-framework}), but change the number of samples to $20$ (default is $10$) for test sampling, in order to match the best-of-20 sampling in our benchmark.

We use 1 80GB $A100$ GPU to train for each datasets and test with the same GPU. The training time limit is set to 96hrs. The default number of training steps (number of updates to the policy) is $20000$. Since \lwd stores checkpoints throughout the process, we still report the test results based on the newest checkpoints for unfinished experiments if we have the checkpoints which reports meaningful results (better than half of the results reported by \deggreedy). Those results are indicated by $*$ in the tables. The number of steps taken by those datasets with unfinished experiments is in \cref{tab:lwd-steps}.
\input{tables/lwd-steps}

\paragraph{\gflownets}
\gflownets(Let the Flows Tell)~\citep{zhang2023let} similar to \lwd, also model the MIS problem as a MDP and non-backtracking. The difference is that it only choose $1$ node at each step, making it more similar to \deggreedy. The node chosen at each step is chosen by a GFlowNet~\citep{bengio2021flow}, which is trained by in-distribution training data.

We use the default setting provide by \cite{zhang2023let} for training with $20$ epochs. By default setting, it has best-of-20 sampling and report the best solution found.

We use 1 80GB $A100$ GPU to train for each datasets and test with the same GPU. The training time limit is set to 96hrs. It completes training for all graphs with $n\leq 3000$, but larger graphs require larger GPU memory. The code does not support multi-GPU.

\paragraph{\difusco}
\difusco(Diffusion Solvers
 for Combinatorial Optimization)~\citep{sun2023difusco} trains a diffusion model using supervised learning to produce a solution for the MIS. The diffusion model provides an entire solution so it is a one-shot algorithm.

The training data is $4000$ graphs for each dataset (1 set of parameter for synthetic graphs). All training is in-distribution. The training data is labelled by \redumis with time limit of 1hr. For graphs we used for training ($n\leq 3000$), \redumis gives the same performance compared to a time limit of 24hrs. 

We use the default setting in \citep{sun2023difusco} except that we use $50$ diffusion steps throughout training and testing, and $20$ samples for testing to be aligned with best-of-20 sampling in other methods. We train the model for $50$ epochs (default) for each dataset.

We use 1 80GB $A100$ GPU to train for each datasets and test with the same GPU. The training time limit is set to 96hrs. The code does not support multi-GPU. We report results where the training can be completed.

Although \citet{sun2023difusco} suggested that \difusco has some generalization ability. We found the performance degrade significantly for out-of-distribution trained models (specifically trained on smaller graphs with the same average degree but test on larger graphs), we did not report the results of larger graphs where the in-distribution training cannot finish.

\paragraph{\diffuco}
\diffuco(Diffusion for Unsupervised Combinatorial Optimization)~\citep{sanokowskidiffusion} is also a diffusion model based algorithm but unlike \difusco it uses unsupervised learning. The diffusion model is trained to sample the solution of low energy state. It also provides an entire solution and is also a one-shot algorithm.

We use the default setting in \citet{sanokowskidiffusion} for RB-large MIS task (in their Appendix C.5). During testing, we use conditional expectation with $20$ samples to align with best-of-20 sampling in other algorithms. The code supports multi-GPU. We use 4 80GB $A100$ GPU to train for each datasets with time limit 96hrs.

The training time is significantly longer than other learning-based algorithms for the same dataset and it can only complete training up to ER graphs with $(n=1000, d=100)$ and BA graph with $(n=1000, d=50)$. According to \citet{sanokowskidiffusion} it has reasonable generalization ability, and we also found that the performance drop is relatively small if we test larger graphs using models trained with smaller graphs with similar average degree. Therefore, we also report test results using out-of-distribution trained model. The parameters of those datasets and the datasets used to train corresponding models are reported in \cref{tab:diffuco-train}. Those results are labelled using $\dag$ in tables.
\input{tables/diffuco-train}

\subsection{Local search}
\label{sec:local_search}
Local search is a method to improve a given independent set. It can be used as a post-processing technique, or be used as sub-procedures in more complicated algorithms like \kamis. \citet{andrade2012fast} provides an efficient local search algorithm. Part of it is to find $2$-improvement, which is the part used as sub-procedure in \kamis~\citep{lamm2017finding, dahlum2016accelerating}.

The local search algorithm for $2$-improvement for a given independent set $I$ is as follows. This algorithm process every vertex $x \in I$ in turn. First, it temporarily removes $x$ from $I$, creating a new set $S$. We call a vertex a free vertex of $S$ if there is no edge between it and any vertex in $S$. If $S$ has less than two free vertices, stop: there is no 2-improvement involving $x$. Otherwise, for each neighbor $v$ of $x$ that is a free vertex for $S$, insert $v$ into $S$ and check if the new set ($S'$) has a free vertex $w$. If it does, inserting $w$ leads to a $2$-improvement; if it does not, remove $v$ from $S'$ (thus restoring $S$) and process the next neighbor of $x$. If no improvement is found, reinsert $x$ into $S$ to turn it back to $I$. Every vertex is scanned $O(1)$ times in this algorithm so it can find a $2$-improvement (if there exists) in $O(m)$ time according to \citet{andrade2012fast}.

We implemented this algorithm in Python and use it as a post-processing for the solutions produced by the algorithm we test.

