\section{More Experiment Results}\label{sec:more-exp}
In this section, we show more experiment results. \Cref{sec:more-exp-larger-graph} shows more experiment results on much larger graphs, where the AI-inspired methods cannot handle. \Cref{sec:more-exp-serialization} show the serialization results on more graphs. \Cref{sec:comparison-lwd} show a more detailed results between \lwd and \deggreedy, which applies degree-based serialization as a subprocedure. \Cref{sec:more-exp-ls} shows the full results when adding local search as a post-processing procedure. Finally, \Cref{sec:more-exp-ratio} discusses more results on the ratio of the solution found by different algorithms to $\frac{n\ln d}{d}$ on ER graphs, which relates to the theoretical conjecture mentioned in \Cref{sec:refute-conjecture}.

\subsection{Larger graphs}\label{sec:more-exp-larger-graph}
\Cref{tab:res-er-larger-graph} reports our results for large ER graphs not reported in \cref{tab:res-er}. Within our computation limits as described in \cref{sec:detail-exp-setup}, we can only obtain results for classical heuristic algorithms (\rangreedy, \deggreedy, \onlinemis, \redumis).
\input{tables/res-er-larger-graph}

\subsection{Serialization}\label{sec:more-exp-serialization}
\Cref{fig:serial-er,fig:serial-ba} shows the percentage to choose the smallest possible degree node on different part of the serialization across various algorithms for all ER graphs and all BA graphs with nodes $n\leq 3000$, respectively. The serialization process is discussed in \cref{sec:comp-other-algs}. Missing bars are algorithms which we do not get results due to computational limit, same as in \cref{tab:res-er,tab:res-ba}.
\input{figs/serialization_ER_full}
\input{figs/serialization_BA_full}

These results reinforced our observations in \cref{sec:comp-other-algs}. First, the percentage for \deggreedy and \gflownets are generally high. \deggreedy reaches $100\%$ for all parts in some graphs, which is the theoretically achievable percentage since \deggreedy actually picks the lowest degree node in the remaining graph and this sequence will give a serialization with percentage $100\%$ for all parts. In those cases, \gflownets also have percentage close to $100\%$ for all $3$ parts.

Second, for those algorithms with good performance, namely \onlinemis, \redumis, \isco, and \lwd, the bar plot shows similar characteristics. The percentage for the 1st third is generally low, while the 2nd third is high, and the 3rd third is higher and close to $100\%$. This characteristics are observed in most settings accross various parameters $(n,d)$/$(n,m)$ for both ER and BA graphs. The exception is only very sparse BA graphs.

Moreover, newly from these plots across various parameters, we also observe that given same $n$, \deggreedy and \gflownets tend to have lower percentage for sparse graphs (smaller $d$ or $m$) and higher percentage for denser graphs (larger $d$ or $m$) across all $3$ parts. On the other hand, \onlinemis, \redumis, \isco, and \lwd tend to have the percentage of 1st 1/3 decreases, while the percentage of the 2nd and 3rd 1/3 increases, when the density of graph increases ($d$ or $m$ increases for same $n$). This shows another qualitative difference between the algorithms similar to \deggreedy (\deggreedy and \gflownets) and the good-performing algorithms (\onlinemis, \redumis, \isco, and \lwd).

We also note that BA graphs $(n=300, m=50)$, $(n=1000, m=150)$, and $(n=3000, m=500)$ are outliers. Most algorithms have percentage close to $100\%$ for all parts. This is because these graphs are rather different from other BA graphs. They have an easily found large MIS, which is the $m$ nodes initially in the graph at the start of the BA generation process.~\citep{albert2002statistical}. From \cref{tab:res-ba}, we can see many algorithms can find these MIS and report a MIS size of $m$ for these graphs. This suggests that for this special type of BA graphs, our serialization analysis can observe different characteristics from other BA graphs.

\subsection{Comparison between \deggreedy and \lwd}
\label{sec:comparison-lwd}
\lwd, similar to \gflownets, is also a non-backtracking MDP based algorithm which picks nodes sequentially. The main difference is that instead of picking $1$ node at a step like \deggreedy and \gflownets, it picks some nodes at a step, which can be $0$ or $1$ or multiple nodes. In that case, it does not have a \emph{natural serialization} like \gflownets (discussed in \cref{sec:comp-gflownets}). However, since it still have steps and we still know some nodes are chosen before others, we can perform a serialization within each step. We call this \emph{pseudo-natural serialization}.

The procedure of our pseudo-natural serialization is as follows. Consider a step $t$ of \lwd, let the independent set before the step be $\gI_{t-1}$. Similar to \cref{alg:serialization}, we build a residual graph $\gG'$ which removes the nodes in $\gI_{t-1}$ and their neighbors from $\gG$. Then, \lwd chose a set of nodes $\gS_t$ to add to the independent set. We then perform the serialization for the set $\gS_t$ (replace $\gI'$ by $\gS$ in \cref{alg:serialization}) and get a ordered list $\gL_t$.  $\gL_t$ is the ordered list for a step. We then concatenate all the ordered lists  $\gL_t$'s for all the steps in order to get a full ordered list $\gL$. For this serialization, we do not repeat it as in \cref{alg:serialization}.

Similar to \cref{sec:comp-gflownets}, we plot a heatmap \cref{fig:toprank-lwd} across various parameters for ER and BA graphs on the average percentage of the nodes being the smallest degree node in the residual graph. In addition to that, similar to \cref{sec:comp-other-algs}, we divide the ordered list $\gL$ into $3$ equal parts to compute the average percentage of the nodes being the smallest degree node seperately.
\input{figs/lwd_segment_heatmaps}

The heatmaps for overall percentages suggest that \lwd is not very similar to \deggreedy like \gflownets. From the heatmaps for different 1/3 parts, we can see the percentage increases from the 1st 1/3 to the 3rd 1/3 for all the datasets (different parameters of the synthetic graphs). This aligns with our ``counterfactual" serialization results for \lwd in \cref{sec:comp-other-algs}, where we also observe the percentage increases clearly from 1st 1/3 to 3rd 1/3. This shows that our serialization method in \cref{sec:comp-other-algs} can reflect the pattern correctly.

The percentages here in the heatmap is smaller than the percentages for ``counterfactual" serialization in the bar graphs in \cref{sec:comp-other-algs}. This is likely due to the fact that in the ``counterfactual" serialization we repeat the serialization process for $100$ times and report the highest percentages we get, while here we only do serialization once for each step.

\subsection{Local search}\label{sec:more-exp-ls}

\input{tables/res-ls-full}

\Cref{tab:res-ls-full} shows the full results after incorporating $2$-improvement local search from the ARW local search algorithm~\citep{andrade2012fast} as a post-processing step, which is discussed in \cref{sec:add-local-search}.

\subsection{More results on the ratio}\label{sec:more-exp-ratio}
In addition to what we show in \cref{sec:refute-conjecture}, \Cref{fig:er_heatmap} shows the ratio of MIS size to $\frac{n\ln d}{d}$ for ER graphs with number of nodes $n$ and average degree $d$ across more algorithms. We can see that \redumis, \onlinemis, and \isco has consitently high ratios more than $1.2$. \rangreedy stays around $1.0$ for all $(n,d)$. Other algorithms, including \deggreedy, all have higher ratios for sparser graphs, but lower ratios (close to $1$) for denser graphs.
\input{figs/fig_gnm_heatmap}
