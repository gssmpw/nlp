%%%%%%%% ICML 2025 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2025} with \usepackage[nohyperref]{icml2025} above.
\usepackage{hyperref}


% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
\usepackage[accepted]{icml2025}

% If accepted, instead use the following line for the camera-ready submission:
%\usepackage[accepted]{icml2025}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{example}[theorem]{Example} % added
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
\usepackage[disable,textsize=tiny]{todonotes}
%\usepackage[textsize=tiny]{todonotes}

% Custom math commands
\input{math_commands}

% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Properties of Wasserstein Gradient Flows for the Sliced-Wasserstein Distance}

\begin{document}

\twocolumn[
\icmltitle{Properties of Wasserstein Gradient Flows for the Sliced-Wasserstein Distance}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2025
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
%\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Christophe Vauthier}{lmo}
\icmlauthor{Quentin Mérigot}{lmo,ens}
\icmlauthor{Anna Korba}{ensae}
\end{icmlauthorlist}

\icmlaffiliation{lmo}{Université Paris-Saclay, CNRS, Laboratoire de mathématiques d’Orsay, 91405, Orsay, France}
\icmlaffiliation{ensae}{Centre de recherche en économie et statistique, ENSAE, Palaiseau, France}
\icmlaffiliation{ens}{DMA, École normale supérieure, Université PSL, CNRS, 75005 Paris, France}
\icmlcorrespondingauthor{Christophe Vauthier}{first1.last1@xxx.edu}
\icmlcorrespondingauthor{Quentin Mérigot}{first2.last2@www.uk}
\icmlcorrespondingauthor{Anna Korba}{first2.last2@www.uk}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Machine Learning, ICML}

\vskip 0.3in]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.


%\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
%\printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.

\footnotetext[1]{Université Paris-Saclay, CNRS, Laboratoire de mathématiques d’Orsay, 91405, Orsay, France}
\footnotetext[2]{DMA, École normale supérieure, Université PSL, CNRS, 75005 Paris, France}
\footnotetext[3]{Centre de recherche en économie et statistique, ENSAE, Palaiseau, France}
\begin{abstract}
In this paper, we investigate the properties of the Sliced Wasserstein Distance (SW) when employed as an objective functional. The SW metric has gained significant interest in the optimal transport and machine learning literature, due to its ability to capture intricate geometric properties of probability distributions while remaining  computationally tractable, making it a valuable tool for various applications, including generative modeling and domain adaptation. Our study aims to provide a rigorous analysis of the critical points arising from the optimization of the SW objective. By computing explicit perturbations, we establish that stable critical points of SW cannot concentrate on segments. This stability analysis is crucial for understanding the behaviour of optimization algorithms for models trained using the SW objective. Furthermore, we investigate the properties of the SW objective, shedding light on the existence and convergence behavior of critical points. We illustrate our theoretical results through numerical experiments.
\end{abstract}

\section{Introduction}

An important problem in statistical learning is to approximate an intractable target probability measure $\rho$ on $\R^d$ with a probability measure supported on a finite set of points. Such problems arise in various contexts, such as sampling from Bayesian posterior distributions \citep{blei2017variational,wibisono2018sampling}, generative modeling \citep{bond2021deep} and training neural networks \citep{chizat2018global, mei2018mean}. Recently, a popular framework to address such tasks has been to consider gradient flows, i.e., optimization dynamics
on the space of measures, to minimize 
%One possible approach to address this problem is to minimize 
an objective functional of the form $\cF(\mu) := \mathcal{D}(\mu|\rho)$, where $\mathcal{D}$ is a discrepancy (e.g. a distance, or a divergence) between measures. Starting from an initial probability distribution $\mu_0$, Wasserstein gradient flows $(\mu_t)_{t>0}$ are curves of steepest descent with respect to the Wasserstein-2 ($\W_2$) metric of the objective $\cF$, in $\cP_2(\R^d)$ the space of probability distributions over $\R^d$ with finite second moment. In practice, they can be simulated by considering an initial distribution that is a discrete measure uniformly supported on a set of particles. 
%by following a suitable discretization of the Wasserstein-gradient flow of $\cF$.  which in our case will be uniformly supported over a finite set of particles, and to construct
The particle positions then evolve according to a system of ODEs, which often corresponds to the gradient flow of a functional $F: (\R^d)^N \to \R$, where $d$ is the dimension of the space and $N$ the number of particles. Then, a practical scheme is derived by discretizing in time this flow, e.g. with gradient descent. 
Many divergences or distances can be considered as the discrepancy $\mathcal{D}$, each offering different tradeoffs between attractive geometrical properties and computational burden of the associated training dynamics. Generally the objective function is chosen so that the dynamic is tractable given the available information on $\rho$.  When the density of $\rho$ is known up to a normalization constant, as often the case in Bayesian inference, standard choices include the Kullback-Leibler divergence~\citep{salim2020wasserstein}, Kernel Stein Discrepancy~\citep{fisher2021measure,korba2021kernel} or Fisher Divergences~\citep{cai2024batch}. On the other hand, when samples of the target distribution are available, Integral Probability Metrics (IPM) %~\citep{li2017mmd} 
or Optimal Transport distances %~\citep{arjovsky2017wasserstein}
are preferred
, since they are well-defined for discrete measures. For instance in generative modeling, while original Generative Adversarial Networks are known to optimize a Jensen-Shannon divergence to the distribution of the samples~\citep{goodfellow2020generative} and can be understood via the perspective of Wasserstein flows~\citep{yi2023monoflow}, 
a wide range of these metrics have been used for the training of GANs, e.g. Wasserstein-1~\citep{arjovsky2017wasserstein}, Sinkhorn divergences~\citep{genevay2018learning}, Maximum Mean Discrepancies~\citep{li2017mmd} or novel metrics interpolating between IPM and f-divergences~\citep{birrell2022f}. Alternatively, recent work directly tackled generative modeling tasks through simulating Wasserstein gradient flows of such discrepancies, e.g. Sliced-Wasserstein distances~\citep{liutkus2019sliced,dai2020sliced,du2023nonparametric}, Energy distances~\citep{hertrich2024generative}, f-divergences~\citep{fan2022,choi2024scalable}. For all these methods, the choice of the discrepancy objective is crucial for their empirical success. \ak{les gans c'est plutôt paramétrique $\theta\mapsto F(\mu_{\theta},\rho)$; est-ce qu'on rajoute une remarque à ce sujet dans le papier?}



For instance, Wasserstein distances themselves seem to be suitable objectives, in the sense that they preserve the geometry of probability distributions, e.g. when computing barycenters \citep{rabin2012wasserstein}. %,solomon2015convolutional
%However these distances are not closed-form, and optimizing them through gradient descent involves running a rather expensive optimization subroutine at each step \citep{altschuler2021wasserstein,altschuler2022wasserstein,chambolle2022accelerated}.
However, for discrete measures, such distances are known to suffer from a large computational cost and poor statistical efficiency~\citep{peyre2019computational}. 
To alleviate this issue,  several alternatives to the Wasserstein distance were proposed. %For instance, the Sinkhorn divergence \citep{ramdas2017wasserstein} %, genevay2018learning,chizat2020faster is a popular proxy based on entropic optimal transport regularisation \citep{cuturi2013sinkhorn . 
Among these, the Sliced-Wasserstein distance (SW) \citep{bonneel2015sliced} 
is 
a computationally attractive proxy. It involves averages of Wasserstein distances in dimension 1 (each of which can be computed in closed-form) with respect to an infinite number of directions. 
It has gained popularity in machine learning applications, such as computing barycenters of distributions \citep{bonneel2015sliced}, variational inference \citep{yi2023sliced} or recently generative modeling \citep{kolouri2018sliced,liutkus2019sliced,dai2020sliced,du2023nonparametric}. While its statistical and computational properties have been studied extensively in the literature \citep{nadjahi2020,manole2022minimax,nietert2022statistical}, the behavior  of its optimization dynamics remain largely unknown. In this paper, we consider the objective functional $\cF$ to be a SW distance to a fixed measure $\rho$. We consider its Wasserstein gradient flow as well as its discrete-time and space counterpart as an optimization scheme pushing particles from a source $\mu$ to approximate the target $\rho$. As this latter optimization problem is non-convex, it is natural to study the critical points that may be encountered during minimization. Our main objective is not only to understand the discretized problem, but also its continuous time and space analog, which motivates us to propose a notion of critical point for the continuous functional $\cF$ that is compatible with the critical points for the discretized problem. 

We note at this point that there exists many natural notions of critical points for a functional $\cG$ defined on the space of probability measures over $\R^d$. A measure $\mu$ is called a critical point of $\cG$ if for any curve $(\mu_t)_{t\in [0,1]}$ in the space of measures such that $\mu_0 = \mu$ belonging to a certain family of allowed perturbations, one has
\begin{equation} \label{eq:ags_possible_critical_point2}
    \left.\frac{d}{d t} \cG(\mu_t)\right|_{t=0^+} = 0.
\end{equation}
Our aim at this point is not to discuss the differentiability assumptions on $\cG$, and we will therefore remain at a formal\ak{an informal?} level. Depending on the set of allowed perturbations, we will recover several  distinct and arguably interesting notions of critical points:
\begin{itemize}
    \item We will call $\mu$ an \emph{Eulerian critical point} if it satisfies \eqref{eq:ags_possible_critical_point2} for all perturbations of $\mu$ of the form $\mu_t = (1-t)\mu + t\nu$ for $\nu\in\cP_2(\R^d)$. This coincides with the standard notion of critical point on the ``flat" space $\cP_2(\R^d)$ (i.e., not equipped with $\W_2$). Such critical points are not meaningful when considering Wasserstein gradient flows.
    \item We will call $\mu$ a \emph{Wasserstein critical point} if it satisfies \eqref{eq:ags_possible_critical_point2} for all $\W_2$-geodesics emanating from $\mu$. If $\mu$ is a probability density, we know from Brenier's theorem that geodesics are all
    curves of the form $\mu_t = ((1-t) \Id + tT)_{\#} \mu$ with $T$ the gradient of a convex function. 
    \item Finally, we will call $\mu$ a \emph{Lagrangian critical point} if it satisfies \eqref{eq:ags_possible_critical_point2} for all curves of the form $\mu_t = (\Id + t\xi)_\# \mu$ for any vector field $\xi\in L^2(\mu,\R^d)$\ak{rajouter def de L2?}.
\end{itemize}
We now discuss the case where $\cG = \cG_\rho := \frac{1}{2}\W_2^2(\cdot,\rho)$ is the squared Wasserstein distance to a probability density $\rho$ to fix ideas. First, we note that the only Eulerian critical point of this functional is $\rho$, a non-obvious fact, which  follows from strong convexity of this $\cG_\rho$ \citep[Proposition 7.19]{santambrogio2015optimal}. Second, if $\mu \neq \rho$ and if $(\mu_t)_{t\in[0,1]}$ is the $\W_2$-geodesic between $\mu$ and $\rho$, one can verify that $\cG_\rho(\mu_t) \leq \cG_\rho(\mu) - c t$ for some $c>0$, thus implying that $\mu$ is not critical. Therefore, the only Wasserstein critical point of $\cG_\rho$ is, again, $\mu = \rho$. 
It is clear from the definition that every Wasserstein critical point is a Lagrangian critical point. \ak{pas méga clair non?}The converse holds when $\mu$ is absolutely continuous, because one can take $\xi = T-\Id$, but not in general.
As explained in \cite{Mrigot2021NonasymptoticCB} and studied in detail in \citep[Chapter 4]{sarrazin:tel-03585897}, the functional $\cG_\rho$ admits \emph{many} Lagrangian critical points. First and foremost, any local or global minimizer of $X = (x_1,\hdots,x_N) \in (\R^d)^N \mapsto \cG_\rho(\frac{1}{N}\sum_i\delta_{x_i})$ induces a Lagrangian critical point $\mu_X = \frac{1}{N}\sum_i \delta_{x_i}$ (showing the practical relevance of this notion), but moreover any $\W_2$-limit of Lagrangian critical points are Lagrangian critical. This notion of critical point translates a difficulty that comes from the discretization, but that persists in the continuous limit.

\paragraph{Contributions and outline.} 
%Our aim in this article is to understand the Lagrangian critical points when one replaces the standard Wasserstein distances by its sliced-Wasserstein counterpart. 
%In particular, our ultimate goal would be to provide an answer to the following question
Regarding the theoretical guarantees of optimization schemes applied to SW, a natural question is
the following: given a sequence of discrete measures $(\mu_N)$ supported on $N$ atoms, and constructed using a first-order algorithm applied on a SW objective, can we expect this sequence to converge to the target measure $\rho$ as $N\to \infty$? This question is difficult because of the non-convexity of the discretized SW objective. 
 However, we could hope that the non-convexity becomes milder as $N\to+\infty$, in the spirit of \cite{chizat2018global,Mrigot2021NonasymptoticCB}. 


Our paper is a first step towards %this objective 
answering this question and is organized as follows. In \Cref{sec:background}, we introduce the necessary background on optimal transport and Sliced-Wassertein distances. In \Cref{section:sw_discrete}, we discuss properties of gradient descent of the functional $\cF$ over discrete measures and of its critical points, showing in particular that trajectories of  gradient descent avoid the non-differentiability locus of $F$. In \Cref{sec:general_properties}, we give an explicit characterization of Lagrangian critical points of the SW objective $\cF = \frac{1}{2} \SW_2^2(\cdot,\rho)$ for general measures\ak{general $\mu$ and/or $\rho$?}, and we prove %in \Cref{th:weak_convergence_crit_points}
that our notion of critical points passes to weak limits under mild assumptions. This implies  that the limit of discrete critical points (e.g., obtained numerically), is a Lagrangian critical point. 
In \Cref{sec:lower_dim_crit_points} we construct explicit examples of Lagrangian critical points of $\cF$ supported on lower-dimensional subsets of $\R^d$. This shows in particular that there exists "bad" Lagrangian critical points points of the SW objective which are distinct from the target $\rho$. %This could in principle be a problem when using the SW objective as a way to approximate $\rho$ by discrete measures. 
A natural question is then whether these "bad" Lagrangian critical points 
%which include a lower-dimensional part,
can actually occur as the limit of discrete measures obtained by an optimization algorithm. Since we expect that gradient descent will converge to stable critical points \cite{lee2019firstOrderMethods}, it is tempting to rule out these bad critical points by showing that they are unstable. We establish in \Cref{sec:lower_dim_crit_points} that any Lagrangian critical point that contains a segment must be unstable. Since our proof relies on delicate explicit computations, the extension to more general lower dimensional critical points is left as future work. 
%, we prove the instability of a family of critical points that contain a lower-dimensional part (a segment). This suggests that such critical points would not be obtained as limits of stable critical points of the discretized energy (since gradient descent typically converges to stable critical points).
Finally \Cref{sec:experiments} presents illustrations of our theoretical results on numerical experiments. 

\section{Background}\label{sec:background}

\paragraph{Measures and optimal transport} 
We first give some background on optimal transport distances. We denote $\cP(\R^d)$ the set of probability measures on $\R^d$ and $\cP_p(\Rsp^d)$ the set of probability measures with finite $p$th moment ($p\geq 1$). The $d$-dimensional Lebesgue and $k$-dimensional Hausdorff measures are denoted respectively by $\cL^d$ and $\cH^k$. For us, a probability density $\rho$ on $\R^d$ is a probability measure which is absolutely continuous with respect to the Lebesgue measure; we will often use the same notation for $\rho$ and its density. Given a measurable map $T$ from $\Rsp^d$ to itself and $\mu\in \cP(\X)$, $T_{\#}\mu$ denotes the pushforward measure of $\mu$ by $T$.
The Wasserstein distance of order $p$ between any probability measures $\mu, \nu$ in $\cP_p(\R^d)$ is defined as %
%\begin{equation}
%\label{eq:def_wass}
\begin{equation}
    \W_p^p(\mu, \nu) = \inf_{\pi \in \Pi(\mu, \nu)} \int_{\R^d \times \R^d} \| x - y \|^p \rmd\pi(x,y),
\end{equation}
%\end{equation}
where $\|\cdot\|$ denotes the Euclidean norm, and $\Pi(\mu, \nu)$ is the set of probability measures on $\R^d \times \R^d$ with marginals $\mu$ and $\nu$.
%  The space of $\ell$ continuously differentiable functions on $\X$ is $C^{\ell}(\X)$, and the space of smooth functions with compact support is $C_c^{\infty}(\X)$. 

%\paragraph{Univariate distributions.} 
\paragraph{1D optimal transport} Consider probability measures $\mu, \nu \in \cP_p(\R)$, and let $F_\mu^{-1}$ and $F_\nu^{-1}$ be their quantile functions, i.e. $F_\mu^{-1}(t) = \inf \{ s \in \R\mid F_\mu(s)\geq t\}$ where $F_\mu$ is the cdf.
%of $\mu$ and $\nu$ respectively\footnote{Recall $F_{\mu}(t)=\mu((-\infty,t])$ and $F_{\mu}^{-1}(t)=\inf\left\{ s, \; F_{\mu}(s) \geq t\right\}$.}. 
By \citep[Theorem 3.1.2.(a)]{rachev1998mass}, the 1D Wasserstein distance is the $L^p$ distance between the quantile functions, 
\begin{equation} \label{eq:wass_1d}
    \W_p^p(\mu, \nu) = \int_{0}^1 |F_\mu^{-1}(t) - F_\nu^{-1}(t)|^p \rmd t  .
\end{equation}
If $X=(x_1,\hdots,x_N) \subseteq \Rsp^N$ is a finite set in $\R$,  $\mu_X = \frac1N \sum_i \delta_{x_i}$ is the associated empirical measure, and  $\sigma_X$ is a permutation such that $i \mapsto x_{\sigma_X(i)}$ is non-decreasing, Equation \eqref{eq:wass_1d} becomes more explicit:
%$\mu = \frac{1}{N} \sum_{i=1}^N \delta_{x_i}$ and $\nu = \frac{1}{N} \sum_{i=1}^N \delta_{y_i}$ are empirical measures, with $x_1,\hdots,x_N, y_1,\hdots,y_N \in \R$, \eqref{eq:wass_1d} can be computed explicitely, denoting $\sigma_X$ a permutation which makes $i\mapsto x_{\sigma(i)}$ non-decreasing and defining $\sigma_Y$ similarly:
\begin{equation} \label{eq:wass_1d_disc}
\W_p^p(\mu_X, \mu_Y) = \frac{1}{N} \sum_{i=1}^N | x_{\sigma_X(i)} - y_{\sigma_Y(i)} |^p,
\end{equation}
showing the complexity of  1D optimal transport is the same as sorting, i.e. $O(N\log N)$. 
However, in dimension higher than one, there is no explicit expression for $\W_p^p(\mu, \nu)$ and despite the progress made in the last decade, the computational cost remains superlinear in the number of atoms \citep{peyre2019computational}. 

\paragraph{Sliced-Wasserstein distance} The Sliced-Wass\-erstein (SW) distance \citep{rabin2012wasserstein} defines an alternative metric by leveraging the computational efficiency of $\W_p^p$ for univariate  distributions.  For $\theta \in \bS^d$, $P_{\theta} : \R^d \to \R$ denotes the linear form $x \mapsto \sca{\theta}{x}$. Then, the SW distance of order $p$ between $\mu, \nu \in \cP_p(\R^d)$ is
\begin{equation} \label{eq:def_sw}
  \SW_p^{p}(\mu, \nu) = \int_{\bS^{d-1}} \W_p^p(P_{\theta\#} \mu, P_{\theta\#} \nu) d\theta,
\end{equation}
where $\bS^{d-1}$ is the $(d -1)$-dimensional unit sphere and $d\theta$ is the uniform distribution on $\bS^{d-1}$. Since $P_{\theta\sharp} \mu$, $P_{\theta\sharp}\nu$ are univariate distributions, the Wasserstein distances in \eqref{eq:def_sw} are conveniently computed using \eqref{eq:wass_1d}. The sliced-Wasserstein distance $\SW_p$ is always smaller than the original Wasserstein distance \citep[Proposition 5.1.3]{bonnotte2013unidimensional}, and is even bi-Hölder equivalent to this distance on the subset $\Prob(B(0,R)) \subseteq \Prob_p(\R^d)$. The computational and statistical aspects of sliced-Wasserstein distances are by now well studied, we refer to \citep{nadjahi2020} and references therein.
%bonneel2015sliced

%In practice, the integral 
%in \eqref{eq:def_sw} is approximated with a standard Monte Carlo method. 
%Computing %$\SW_{p,L}^{p}$
%the latter %Monte Carlo 
%approximation of the SW distance  
%between two empirical distributions then amounts to projecting sets of $n$ observations in $\R^d$ along $L$ directions, and sorting the projected data. The resulting computational complexity is $\mathcal{O}(Ldn + Ln\log n)$, which is more efficient than $\W_p^p$ in general. 
%This complexity means that the Monte Carlo estimate is
%more expensive when $d$, $n$ and $L$ increase,
%and it is often unclear how $L$ should be chosen in 
%order to control the approximation error;
%see \citep[Theorem 6]{nadjahi2020}. 
\section{Discrete Sliced-Wasserstein distance dynamics}\label{section:sw_discrete}
Before investigating the convergence of the gradient flow of Sliced-Wasserstein distance to its critical points and the characterization of the latter, we first study in this section the optimization of the Sliced-Wasserstein distance in practice, where the optimized (source) measure is discrete. Our first subsection studies the differentiability properties of the Sliced-Wasserstein objective when the first argument is a discrete measure, while the second provides a descent lemma for this objective. Finally, we show quantitatively that for a suitable stepsize, gradient descent does not collapse particles and is thus defined for all times. 
%In this section we will fix %$p \geq 1$ and 
%$N > 0$.

%\subsection{Differentiability of the Sliced-Wasserstein functional} \label{section:discrete_differentiability}
\paragraph{Differentiability of the SW functional.} 
 We consider a target probability density $\rho \in \cP_p(\R^d)$, and we define the function
\begin{equation}\label{eq:FN}
 F : X=(X_1,...,X_N) \in (\R^d)^N \mapsto \frac{1}{p} \SW_p^p(\mu_X, \rho),
\end{equation}
where $\mu_X = \frac{1}{N} \sum_{i=1}^N \delta_{X_i}$ is the uniform empirical measure associated to the set of points $X$. As $\rho$ has finite $p$-moment, $F(X) < +\infty$ for every point cloud $X$. As seen in \Cref{sec:background}, SW distance involves sorting the projections of $X$ over directions. However, the sorting operation, seen as a function of $\R^N$ to $\R^N$, is piecewise linear and non-differentiable when two of the coordinates agree. We may therefore expect our functional $F$ to be non-differentiable at any point cloud $X$ which belongs to the  generalized diagonal $\Delta_N := \{(X_1,...,X_N) \in (\R^d)^N \mid \exists i \neq j, X_i = X_j \}$. The next proposition shows differentiability of $F$ on the complement of this generalized diagonal. 

As usual, we denote $\mathfrak{S}_N$ the group of permutations of $\{1,...,N\}$. We will use the notation 
$V_{\theta,i}$ for the $i$-th Power cell associated to $P_{\theta\#}\rho$, i.e. 
\begin{equation}
    V_{\theta,i} = F_{P_{\theta\#}\rho}^{-1}\left(\left[\frac{i}{N},\frac{i+1}{N}\right]\right).
\end{equation}
Moreover, given a point cloud $X = (X_1,\hdots,X_N) \in (\R^d)^N$, we denote $\sigma_{X,\theta} \in \mathfrak{S}_N$ a permutation such that the map $i \in \{1,\hdots,N\} \mapsto \sca{X_{\sigma_{X,\theta}(i)}}{\theta}$ is non-decreasing.
\begin{proposition} 
    \label{prop:discrete_gradient}
    If $p \geq 2$ is an integer, then $F$ is differentiable at any point cloud $X = (X_1,\hdots,X_N) \in (\R^d)^N$ which does not belong to the generalized diagonal $\Delta_N$. The gradient of $F$ with respect to the $i$-th vector $X_i$ is then %given by 
    \begin{align}
        \nabla_{X_i} F(X) &= \int_{\bS^{d-1}} \int_{V_{\theta,\sigma_{X,\theta}^{-1}(i)}} \sgn(\sca{X_i}{\theta} - x) \notag \\
        & \quad \times |\sca{X_i}{\theta} - x|^{p-1}\theta dP_{\theta\#}\rho(x) d\theta,
    \end{align}
    In the particular case where $p = 2$, this expression can be further simplified by introducing the barycenters of the Power cells  $V_{\theta,i}$, i.e. $b_{\theta,i} = N\int_{V_{\theta,i}} xdP_{\theta\#}\rho(x)$:% we have that
    \begin{equation}
        \nabla_{X_i} F(X) = \frac{1}{N} \left(\frac{1}{d} X_i - \int_{\bS^{d-1}} b_{\theta,\sigma_{X,\theta}^{-1}(i)}\theta d\theta\right).\label{eq:sw2_critical_point}
    \end{equation}
\end{proposition}
The proof of \Cref{prop:discrete_gradient} is deferred to  \Cref{sec:proof_of_discrete_gradient}. This proposition is valid in the semi-discrete setting, where the source measure is finitely supported and $\rho$ has a density, while similar results in the literature tackle different settings, e.g. fully-discrete~\citep{tanguy2023discrete_sw_losses} or where both measures are densities~\citep{manole2022minimax}. %This result cannot be proven by simply applying dominated convergence, as the set on which the integrand is differentiable varies with $\theta$. Instead, we must decompose the integral on two %different
%domains, one on a set $\Theta_\epsilon = \{\theta \in \bS^{d-1} \;|\; \exists i \neq j, |\sca{X_i-X_j}{\theta}| \leq \epsilon \}$ and the other on $\bS^{d-1} \setminus \Theta_\epsilon$ for any $\epsilon>0$, and work on these separately to show the differentiability of $F$ at $X$.


\paragraph{Descent lemma.}  %\label{section:dsct_lemma} In this subsection we will keep the same notations as above. 
While our previous result provides a general formula for gradients of SW distances of order $p\ge2 $, we  focus on the particular case $p = 2$ where the computations are the most simple. We then have the following result for the gradient descent on $F$, 

\begin{proposition} \label{prop:descent_lemma}
    For every $X \in (\R^d)^N \setminus \Delta_N$ and every $\lambda > 0$, denoting $Y := X - \lambda \nabla F(X)$, we have 
    \begin{equation} \label{eq:dsct_lma1}
        F(Y) - F(X) \leq -\lambda \left(1 - \frac{\lambda}{2Nd}\right) \|\nabla F(X)\|^2
    \end{equation}
\end{proposition}
The proof of \Cref{prop:descent_lemma} is provided in \Cref{sec:proof_descent_lemma} and relies on the semiconcavity of $F$. This proposition implies that if $X$ is not a critical point of $F$ and if the step-size $\lambda$ belongs to $(0,2Nd)$, one gradient descent step from $X$ strictly decreases the value of $F$. In particular, the  r.h.s. of the inequality \eqref{eq:dsct_lma1} is minimal for a step-size $\lambda = Nd$, and we may expect the convergence speed of the gradient descent to be the fastest for step sizes around this value. 
Considering the expression of $\nabla F(X)$ given by \eqref{eq:sw2_critical_point}, one iteration of the gradient descent with such a step writes:
\begin{equation}\label{eq:gd_step_sw}
X_i^{k+1} \leftarrow X_i^k - Nd \nabla_i F(X^k) = d\int_{\bS^{d-1}} b_{\theta,\sigma_{X^k,\theta}^{-1}(i)}\theta d\theta. 
\end{equation}
Interestingly, choosing a step of $Nd$ for the $\SW^2_2$ objective is reminiscent of the results obtained by \citep{Mrigot2021NonasymptoticCB}. They study a  variant of Lloyd's algorithm, which optimizes $X \mapsto \Wass^2_2(\mu_X,\rho)$ by assigning to $X^{k+1}$ the barycenters of the Power cells  (also referred to as Laguerre cells) associated to $X^k$, and which was proven, under certain conditions, to approximate $\rho$ closely after a single step (see Theorem 3 and Corollary 4 in \citep{Mrigot2021NonasymptoticCB}).
%A consequence of the descent lemma 

Another consequence of \Cref{prop:descent_lemma} is that the sum of squared gradients of $F$ at $X^k$ is bounded. Indeed, for $\lambda = Nd$, we have 
\begin{equation}
    \|\nabla F(X^k) \|^2 \leq \frac{2}{Nd} (F(X^k) - F(X^{k+1})),
\end{equation}
which implies that any converging subsequence of $(X^k)$ converges to a critical point $X^*$ of the energy. The convergence of the whole sequence $(X^k)$ to a critical point is open in general. It can be proven if one assumes that that the energy level $F^{-1}(F(X^*))$ only contains a finite number of critical points, as in 
 \citep[Appendix]{bourne2020laguerre}, but this hypothesis cannot be checked in practice.  \cite{portales2024} prove  convergence of the whole sequence of iterates of  Lloyd-type algorithms in several settings, but they acknowledge that their techniques do not extend to the case of  $\cF = \frac{1}{2} \SW^2_2(\cdot,\rho)$ when $\rho$ is a probability density.


%\textcolor{red}{Citer ce papier: \url{https://arxiv.org/pdf/2405.20744} qui montre la convergence des iterees de Lloyd dans le cas Wasserstein mais pas sliced-Wasserstein}

\paragraph{Well-behavedness of gradient descent} In the gradient descent scheme described above, it is a priori possible that the iterates will get close to the generalized diagonal $\Delta_N$. This is a problem, as $F$ is only known to be differentiable on $(\R^d)^N \setminus \Delta_N$. The following property ensures that, if the densities of the projections of $\rho$ are bounded, the iterates will remain  away from $\Delta_N$.

\begin{proposition} \label{prop:descent_well_behaved}
    Assume that there exists $\beta > 0$ such that for every $\theta \in \bS^{d-1}$, the density of $\rho_\theta$ if bounded from above by $\beta$. Then, there exists $C = C(d)$ such that for every $X \in (\R^d)^N$ and for every $\lambda > 0$, defining $Y := X - \lambda \nabla F(X)$, we have for every $i \neq j$,
    \begin{itemize}
        \item If $\|X_i - X_j\| < \frac{dC}{N\beta}$, then $\|Y_i - Y_j\| >  \|X_i - X_j\|$
        \item If $\lambda \in (0,Nd/2)$, then $Y \notin \Delta_N$
    \end{itemize}
    Furthermore, if $X$ is a critical point of $F$, then %for every $i \neq j$,
    \begin{equation}
        \min_{i\neq j} \|X_i - X_j\| \geq \frac{dC}{N\beta}
    \end{equation}
\end{proposition}

The proof of Proposition \ref{prop:descent_well_behaved} is provided in \Cref{sec:proof_descent_well_behaved}. The proof strategy we use also implies that the continuous flow $\dot{X} = - \nabla F(X)$ is defined for all times when initialized from a point cloud $X(0)$ not in $\Delta_N$, as discussed in the same appendix.

%Therefore, provided the gradient goes to zero, any limit point of the gradient descent will be a critical point \textcolor{purple}{under the assumption that there are only finitely many Laguerre diagrams
%with the same energy $F$ \citep[Section 1]{bourne2020laguerre}. }\ak{maybe we state more explicitly that we make this assumption?}
%\qm{We should say more clearly that 1) any converging subsequence of the gradient descent converges to a critical point and 2) we don't know whether the whole sequence converge, but that in the case of $W_2$ Bourne et al were able to show such a convergence under a technical assumption (which we do not need to state precisely)} 
%\qm{\url{https://arxiv.org/pdf/1912.07188} Section 1}
\section{Characterization of critical points}\label{sec:general_properties}

%In the latter section we studied the convergence of the discrete-time gradient flow to critical points of the finite-dimensional SW objective $F$.
The goal of this this section is to derive a rigorous characterization of Lagrangian critical points of the SW objective $\cF = \frac{1}{2}\SW_2^2(\cdot,\rho)$, assuming that the target probability density $\rho$ is in $\mathcal{P}_2(\R^d)$.

\subsection{Barycentric characterization}
As  in the introduction, we first define Lagrangian critical points using derivatives of $\cF$ along  perturbations of the measure.
\begin{definition} \label{def:lag-crit}
A measure $\mu \in \cP_2(\R^d)$ is a \emph{Lagrangian critical point} for $\SW_2^2(\cdot,\rho)$ if for any vector field $\xi \in L^2(\mu,\R^d)$
\begin{equation}
    \left.\frac{d}{dt}  \SW_2^2((\Id + t\xi)_{\#} \mu,\rho)\right|_{t=0^+} = 0. \label{eq:crit_point_requirement} 
\end{equation} 
\end{definition}
The right derivative is always well-defined thanks to \Cref{prop:sw2_diff}(a), as a convex function always has left and right directional derivatives. % This definition is designed so that  a point cloud $X \in \R^{dN}\setminus \Delta_N$ is critical for $F$ if and only if the  measure $\mu_X$ is a Lagrangian critical point for $\cF$ if and only if $X$ is a critical point of $F$. 

As \Cref{def:lag-crit} is difficult to verify in practice, we will now define a second notion of Lagrangian criticality, which we will prove to be equivalent to the first under mild assumptions on $\mu$, and which will be very similar in spirit to the concept of Lagrangian critical measures for the standard Wasserstein distance developed in \cite{sarrazin:tel-03585897}.

We assume that $\mu \in \cP_2(\R^d)$ is fixed, and for every direction $\theta$, we denote $\gamma_\theta$ the optimal transport plan between $ \mu_\theta = P_{\theta\#}\mu$ and $\rho_\theta= P_{\theta\#}\rho$. We note that since the \emph{target measure} $\rho_\theta$ is absolutely continuous, Brenier's theorem implies that this plan is unique and can be written as $\gamma_\theta = (T_\theta,\Id)_\#\rho_\theta$ where $T_\theta$ is the  transport map $T_\theta$ from $\rho_\theta$ to $\mu_\theta$. We finally consider the barycentric projection $\bar{\gamma}_\theta$ of this transport plan  \citep[Definition 5.4.2]{ambrosio2005gradient}, which we can define using conditional expectations:
\begin{equation}
    \bar{\gamma}_\theta : \R\to \R, \; u \mapsto \mathbb{E}_{(U,V) \sim \gamma_\theta}[V\,|\,U = u].
\end{equation}
We are now ready to state our second definition of Lagrangian critical points.
\begin{definition} \label{def:strong-lag-crit}
    A measure $\mu \in \cP_2(\R^d)$ is a \textit{barycentric Lagrangian critical point} for $\SW^2_2(\cdot,\rho)$ if $v_\mu = 0$ $\mu$-a.e., where $v_\mu$ is the vector field defined by 
    \begin{equation} \label{eq:v_mu_definition}
        v_\mu : x \mapsto \frac{1}{d} x - \int_{\bS^{d-1}} \bar{\gamma}_\theta(\sca{x}{\theta}) \theta d\theta.
    \end{equation}
\end{definition}
Note that this integral is well-defined by the selection result \citep[Corollary 5.22]{villani2008OldNew}. Our two notions of Lagrangian critical points are compatible with the notion of critical points of the discretized problem defined in the previous section, as stated in the following Proposition. %, indeed :

\begin{proposition} \label{prop:compatibility_with_discrete_case}
    Let $X \in (\R^d)^N \setminus \Delta_N$, then $\nabla F(X) = 0$ if and only if $\mu_X$ is a Lagrangian critical point for $\SW^2_2(\cdot,\rho)$ if and only if $\mu_X$ is a barycentric Lagrangian critical point for $\SW^2_2(\cdot,\rho)$.
\end{proposition}
The proof of \Cref{prop:compatibility_with_discrete_case} is deferred to \Cref{sec:proof_compatibility_with_discrete_case}. 
A natural (non trivial) follow-up question is then whether the limit of a sequence of discrete critical points $\mu_N = \frac 1N \sum_{i=1}^N \delta_{X_i}$ (e.g. obtained numerically) is also a critical point (as defined either in \Cref{def:lag-crit} or in \Cref{def:strong-lag-crit}). The following theorem provides an answer to this question.

\begin{theorem}[Limits of critical points are critical] \label{th:weak_convergence_crit_points}
    Assume that $\rho \in \cP(\Omega)$ with $\Omega \subseteq \R^d$ compact. If a sequence $(\mu_N)_{N\geq 1}$ of barycentric Lagrangian critical points for $\SW^2_2(\cdot,\rho)$  converges  weakly to an atomles measure $\mu$,  %such that for every continuous $\xi : \Omega \mapsto \R^d$, $t \to \SW^2_2((\Id+t\xi)_\#\mu,\rho)$ is differentiable at $t=0$, 
    then $\mu$ is barycentric Lagrangian critical for $\SW^2_2(\cdot,\rho)$.
\end{theorem}
%\ak{say that the fact that Def 4.1 translates into the condition barycentric is convenient when considering weak limits of sequences of measures?}
%The previous theorem in particular applies to discrete sequences $\mu_n=\sum_{i=1}^N \delta_{X_i}$ critical points that can be find in practice when minimizing a SW objective as explained in the previous section; and even if this sequence if converging to a limit $\mu$ with a density, the latter is still a critical point. 
%Note that by \Cref{prop:sw2_diff}(c), the assumption on $\mu$ is satisfied whenever $\mu$ is without atoms. 

The proof of \Cref{th:weak_convergence_crit_points} can be found in \Cref{sec:th_weak_convergence_crit_points}. Crucially, 
it relies on the study of the intricate relationship between the two definitions of Langrangian critical points we have defined. This study is detailed in the next section.
%Finding more general convergence results, with less conditions on $\mu$, may constitute an avenue for future research.
%This definition coincides with \Cref{def:lag-crit} when the measure $\mu$ is the uniform measure over a point cloud $X \in \R^{d\times N} \setminus \Delta_N$. 
%Indeed, in this case, one easily checks that $\bar{\gamma}_\theta(\sca{X_i}{\theta})$ is the $\rho_\theta$-barycenter of the Power cell $T_\theta^{-1}(\sca{X_i}{\theta})$, and \Cref{eq:sw2_lg_critical_point} coincides with $\nabla F(X) = 0$. 

\subsection{Technical tools for \Cref{th:weak_convergence_crit_points}}

We have already shown in \Cref{prop:compatibility_with_discrete_case} that the two notions of critical agree for discrete measures. Here, we discuss why \Cref{def:strong-lag-crit} is also natural \blue{in a more general setting, such as those of Wasserstein gradient flows.} 
\blue{Indeed, by \citep[Section 5.7.1]{bonnotte2013unidimensional}, the absolutely continuous stationary points $\mu$ of the gradient flow dynamics of $\cF$ are characterized by 
\begin{equation} \label{eq:wgf_density_stationary_cond}
    \int_{\bS^{d-1}} \varphi'_\theta(\sca{x}{\theta})\theta d\theta = 0, \quad \mu-\hbox{a.e. } x \in \R^d
\end{equation}
where $\varphi_{\theta}$ is the Kantorovitch potential from $\mu_{\theta}=P_{\theta\#}\mu$ to $\rho_{\theta} = P_{\theta\#}\rho$ for the cost $c(s,t) = \frac 12 (s-t)^2$. But since we have $\varphi'_\theta = \Id - T_\theta^{-1}$ \citep[Section 1.3.1]{santambrogio2015optimal}, and $\bar{\gamma}_\theta = T^{-1}_\theta$ (as $\mu_\theta$ is absolutely continuous), we see that \eqref{eq:wgf_density_stationary_cond} rewrites as
$v_\mu = 0$ $\mu$-ae, and thus an absolutely continuous measure $\mu$ is a stationary point of the Wasserstein gradient flow of $\cF$ iff it is a barycentric Lagrangian critical point. Furthermore, \citep[Lemma 5.7.2]{bonnotte2013unidimensional} immediately rewrites as
\begin{proposition} (Bonnotte)
If $\mu,\rho \in \cP(B(0,R))$ are absolutely continuous and both have a strictly positive density on $B(0,R)$, then $\mu = \rho$ if and only if it is barycentric Lagrangian critical for $\SW^2_2(\cdot,\rho)$
\end{proposition}}
\mayberemove{\Cref{def:strong-lag-crit} is also (formally) consistent with what we would expect a critical point of a Wasserstein gradient flow of $\cF$ to satisfy. Indeed, the vector field ruling the gradient flow dynamics of $\cF$ can be written as  the gradient of the first variation of $\mathcal{F}$ whenever this first derivative exists  \citep[Section 8.2]{santambrogio2015optimal}. By \citep[Proposition 5.1.6]{bonnotte2013unidimensional} the first variation of $\cF$ at $\mu$ is given by
\begin{equation}
    \frac{\delta\cF(\mu)}{\delta\mu} : x \in \R^d \mapsto \int_{\bS^{d-1}} \varphi_\theta(P_\theta(x)) d\theta \in \R,
\end{equation}
where $\varphi_{\theta}$ is the Kantorovitch potential from $\mu_{\theta}=P_{\theta\#}\mu$ to $\rho_{\theta} = P_{\theta\#}\rho$ for the cost $c(s,t) = \frac 12 (s-t)^2$. Assume now that $\mu$ is absolutely continuous. Then $\varphi'_\theta = \Id - T_\theta$ \citep[Section 1.3.1]{santambrogio2015optimal}, and differentiating, we have by the chain rule:
\begin{equation}
    \nabla\frac{\delta\cF(\mu)}{\delta\mu}(x) = \frac{x}{d} - \int_{\bS^{d-1}} T_\theta(\sca{x}{\theta}) \theta d\theta. \label{eq:wass_gradient}
\end{equation}
Hence we see from \eqref{eq:wass_gradient} that an absolutely continuous $\mu$ is a barycentric Lagrangian critical point for $\SW^2_2(\cdot,\rho)$ if and only if $\nabla\frac{\delta\cF(\mu)}{\delta\mu} = 0$ $\mu$-almost everywhere.} Now, we will see that \Cref{def:strong-lag-crit} and \ref{def:lag-crit} coincide if $\mu,\rho$ are compactly supported and $\mu$ is without atoms. %if $\mu$ has absolutely continuous projections on lines according to the following definition.
%\begin{definition}\label{def:abso_continuous_proj}
    %A measure $\mu \in \cP(\R^d)$ will be said to \textit{have absolutely continuous projections on lines} if $\mu_\theta$ is absolutely continous for almost every unit vector $\theta$. %(In the following, for the sake of brievity, we may omit "on lines").
%\end{definition}
%This is a much more general assumption than absolute continuity. For example, it covers many measures that are supported on lower dimensional manifolds, such as $\cH^k_{|\Sigma}$ where $\Sigma$ is a $k$-simplex of $\R^d$ ($k\geq 1$), or countable averages of such measures. Yet, it is strong enough to recover the characterization of critical points as \eqref{eq:crit_point_requirement}, as shown in the following results. 
For $\mu \in \cP(\R^d)$, we denote $\Vert \cdot \Vert_{L^2(\mu)}$ and $\ps{\cdot,\cdot}_{L^2(\mu)}$ the norm and the inner product on $L^2(\mu,\R^d)$.

\begin{proposition}
    \label{prop:sw2_diff}
    Let $\mu \in \cP_2(\R^d)$, then :
    \setlist{nolistsep}
    \begin{enumerate}[noitemsep,label=(\alph*)]
        \item The function $F_\mu : L^2(\mu,\R^d) \mapsto \R$ defined as follows is convex:
        \begin{equation}
            F_\mu : \xi \mapsto \frac{1}{d} \|\xi\|^2_{L^2(\mu)} - \SW^2_2((\Id+\xi)_\#\mu,\rho)
        \end{equation}
        \item The vector field $v_\mu$ belongs to $L^2(\mu,\R^d)$. Furthermore, $-2v_\mu$ belongs to the subdifferential of $F_\mu$ at $0$, that is, for every $\xi \in L^2(\mu,\R^d)$,
        \begin{equation} \label{eq:v_mu_subdiff_F_mu}
            F_\mu(0) - 2\sca{v_\mu}{\xi}_{L^2(\mu)} \leq F_\mu(\xi)
        \end{equation}
        \item If $\mu$ and $\rho$ have compact support and $\mu$ is without atoms, then for every vector field $\xi \in L^2(\mu,\R^d)$, the function $\varphi(t) = \SW^2_2((\Id+t\xi)_\#\mu,\rho)$ is differentiable at $t=0$, with
        \begin{equation}
            \varphi'(0) = 2\sca{v_\mu}{\xi}_{L^2(\mu)} 
        \end{equation}
    \end{enumerate}
\end{proposition}

\begin{corollary}
    \label{cor:sw2_crit_point_char}
    If $\mu$ is a Lagrangian critical point for $\SW^2_2(\cdot,\rho)$, then it is also a barycentric Lagrangian critical points for $\SW^2_2(\cdot,\rho)$. If furthermore $\mu$ and $\rho$ have compact support and $\mu$ is without atoms, then the converse statement is also true.
\end{corollary}
The proof of  \Cref{prop:sw2_diff} and \Cref{cor:sw2_crit_point_char}  can be found in \Cref{sec:proof_sw2_diff} and \Cref{sec:proof_sw2_crit_point_char} respectively.
%The latter result shows that our notion of Lagrangian critical points satisfies the requirement \eqref{eq:crit_point_requirement} that we stated at the beginning of this section. Note also that when $t \mapsto \SW^2_2(\mu^t,\rho)$ is twice differentiable at $t = 0$, the inequality stated in Proposition \ref{prop:sw2_diff} gives an upper bound on its second derivative. In \Cref{cor:sw2_crit_point_char}, we only need the assumption that $\mu$ has absolutely continuous projections to ensure the existence of the derivative at $t=0$ of $\SW^2_2(\mu^t,\rho)$. However, any measure $\mu$ such that $\SW^2_2(\mu_t,\rho)$ is differentiable at $t = 0$ for any perturbation $\xi$ will also satisfy the corollary. 
\Cref{prop:sw2_diff}(c) extends the result \citep[5.1.7. Proposition]{bonnotte2013unidimensional} on the differentiability of SW. In particular, Bonnote's results holds under the strong assumption that $\mu$ is absolutely continuous, whereas \Cref{prop:sw2_diff} makes the much milder assumption that $\mu$ is atomless. 

\section{Lower-dimensional critical points: existence and instability}
\label{sec:lower_dim_crit_points}

\subsection{Leveraging symmetry to find critical points}

Now that we have characterized Lagrangian critical points, it is natural to ask ourselves whether there can exist such Lagrangian critical measures $\mu$ different than the target distribution $\rho$. A good way to construct such critical points is to look for measures that are supported on a symmetry axis of a  well-chosen measure $\rho$. Our next result provides several examples.

\begin{proposition} \label{prop:ex_symmetric_crit_points}
    The following are barycentric Lagrangian critical points :
    \begin{enumerate}[leftmargin=*, topsep=0pt, parsep=0pt,label=(\alph*)]
    %,itemsep=0pt
        \item In dimension $d = 2$, the measure $\mu = \frac{\pi}{8} \cH^1_{|[-\frac{4}{\pi},\frac{4}{\pi}]}$
        is a barycentric Lagrangian critical point for the measure $\rho$ with density $\rho(x) = \frac{1}{2\pi} \frac{1}{\sqrt{1-|x|^2}} \bOne_{B(0,1)}(x)$, which we will hereafter call the (two-dimensional) \textit{sliced-uniform measure}.
        \item  In dimension $d > 1$, the measure $\mu$ defined by $\mu := (\Id,0_{d-1})_{\#}\mu_0$ with $\mu_0 = \cN(0,\alpha_d^2)$ is a barycentric Lagrangian critical point for the standard Gaussian $\rho = \cN(0,I_d)$, where $\alpha_d$ is defined by $\alpha_d = d\int_{\bS^{d-1}} |\sca{\theta}{e_1}|^{3/2} d\theta$ and $(e_1,...,e_d)$ is the canonical basis of $\R^d$. %\[ \alpha_d = d\int_{\bS^{d-1}} |\sca{\theta}{e_1}|^{3/2} d\theta \]
    \end{enumerate}
\end{proposition}

We refer to  $\rho$ in \Cref{prop:ex_symmetric_crit_points}(a) as the sliced-uniform measure, as \mayberemove{it has the convenient property that \todo{Supprimer ?}}for every $\theta \in \Sph^{d-1}$, its projection $P_{\theta\#}\rho$ is the normalized restriction of the Lebesgue measure to $[-1,1]$. \Cref{prop:ex_symmetric_crit_points}(a) provides an example of  target measure $\rho$ on a disk in $d=2$ that is symmetric with respect to any line, and which admits in this case a critical point supported on a segment, hence of strictly lower dimension.  \Cref{prop:ex_symmetric_crit_points}(b) provides a similar result for isotropic Gaussians. The proof of \Cref{prop:ex_symmetric_crit_points} is deferred to \Cref{sec:prop_ex_symmetric_crit_points}. \mayberemove{It constructs the points using the following general method, which ensures they are Lagrangian critical: we consider a measure $\mu_\alpha$ supported on $\R e_1$ and parametrized by $\alpha \in \R$ (for example $\mu_\alpha = \frac{1}{2\alpha} \cH^1_{|[-\alpha,\alpha]}$ or $\mu_\alpha = (\Id,0_{d-1})_\#\cN(0,\alpha^2)$). We then rewrite the condition for barycentric Lagrangian criticality $v_{\mu_\alpha} = 0$ into an equation of the form $x e_1 = f(\alpha) x e_1$ $\mu$-a.e. $x$, and we solve $f(\alpha) = 1$. Here the symmetry of the problem helps us simplify the criticality condition into a scalar equation.\todo{Supprimer pour gagner de la place ?} } %\ak{super !}

We now discuss more informally about why we expect to find critical points of this type.  Assume that there exists a subspace $H$ of $\R^d$ such that the target $\rho$ is symmetric with respect to $H$, i.e. $S_{H\#}\rho = \rho$ where $S_H$ is the reflection at $H$. Then, if $\spt(\mu) \subseteq  H$, then for every $\theta \in \bS^{d-1}$, we have $\rho_{S_H(\theta)} = \rho_\theta$ and $\mu_{S_H(\theta)} = \mu_\theta$, thus $T_\theta = T_{S_H(\theta)}$. Thus, for every $x \in \spt(\mu) \subseteq H$, we have by straightforward computations \footnote{$v_\mu(x) = \frac{x}{d} - \int \frac{T_\theta(\sca{\theta}{x})\theta + T_{S_H(\theta)}(\sca{S_H(\theta)}{x})S_H(\theta)}{2} d\theta 
    = \frac{x}{d} - \int T_\theta(\sca{\theta}{x})\frac{\theta + S_H(\theta)}{2} d\theta \hbox{ as } x \in H $.}:
\begin{equation}
    v_\mu(x) = \frac{x}{d} - \int_{\bS^{d-1}} T_\theta(\sca{\theta}{x})P_H(\theta) d\theta \in H,
\end{equation}
where $P_H$ is the projection on $H$. This means that both the iterates of the gradient descent $\mu \leftarrow (\Id+\tau v_\mu)_\#\mu$ %and the trajectory of the gradient flow 
will remain supported on $H$. %the discretized Wasserstein gradient flow %$\mu \leftarrow \mu - \lambda \nabla \cdot (\nabla (\frac{\delta \cF(\mu)}{\delta \mu})\mu_t)$ 
%will stay in the space of measures supported on $H$. Furthermore, for the continuous Wasserstein flow \eqref{eq:wgf} %$\partial_t \mu_t = \nabla \cdot (\nabla (\frac{\delta \cF(\mu)}{\delta \mu})\mu_t)$
%, under suitable regularity conditions on $\nabla \frac{\delta \cF(\mu)}{\delta \mu}$, the continuous flow should also stay on measures supported on $H$, see \citep[Prop 10]{korba2021kernel}.
Therefore, taking the limit of the trajectory as $t\to +\infty$ should be a critical point of $\cF$, still supported on $H$.

\begin{figure*}[ht]
    \vskip 0.2in
    \begin{center}
        \centerline{\includegraphics[width=\textwidth]{fig_instability.png}}
        \caption{Instability of measures containing an horizontal segment. On the top line are plotted the value $\SW^2_2(\mu^t, \rho)$ for different measures $\mu$, $\rho$ and perturbations $\xi$. On the bottom line are depictions of the different $\mu$ (black points), $\rho$ (approximated by the blue points) and $\xi$ (red arrows). Columns (a) and (b): $\mu$ is a point cloud of $N = 100$ points uniformly distributed on the segment $[-4/\pi,4/\pi] \times \{0\}$, $\xi$ alternates between $e_2$ and $-e_2$, and $\rho$ is the normal (a) and sliced-uniform distribution (see \Cref{prop:ex_symmetric_crit_points}) (b). Column (c): Same $\mu$ and $\xi$, and this time $\rho$ is the uniform measure on the shell $C(0,1,2)$. Column (d) : $\rho$ is again the shell, and $\mu$ is a point cloud with a "dumbbell-like" shape, whose central segment is perturbed similarly as in (a),(b),(c).}
        \label{fig:1}
    \end{center}
    \vskip -0.2in
\end{figure*}

\subsection{Some explicit unstable critical points} \label{section:unstable_points}

Previously, we highlighted critical points that are supported on a subset of $\R^d$, for a target distribution that is full-dimensional. This is problematic because our gradient algorithm may be stuck at these critical points, which are typically at a high level in the energy landscape. We now investigate their stability, as gradient descent is unlikely to get stuck at unstable critical points, with the aim of showing that such points do not appear in practice.

We will focus on a particular case of unstable behavior. We will restrict ourselves to the case $d = 2$, and we will show that when the target measure $\rho$ is absolutely continuous, measures $\mu$ that contain a part supported on a segment are not stable for $\SW^2_2$ when perturbed in a certain way. 

\begin{proposition} \label{prop:examples_unstable}
    Let $\rho \in \cP_2(\R^2)$ be an absolutely continuous measure, such that the densities of its projections $\rho_\theta$ are uniformly bounded from above by $b > 0$. Let $\mu \in \cP_2(\R^2)$ be any measure such that there exists a segment $S \subseteq \R^2$ and $a > 0$ such that $a\cH^1_{|S} \leq \mu$. Then, if $\mu^t$ is the perturbation
    \begin{equation}
        \mu^t := \frac{1}{2} (\tau_{-t\vec{n}\#}\mu + \tau_{t\vec{n}\#}\mu)
    \end{equation}
    where $\tau_{\vec{a}}$ is the translation by $\vec{a} \in \R^2$ and $\vec{n} \in \bS^1$ is orthogonal to $S$, then the perturbation $\mu_t$ is unstable for $\SW^2_2(\cdot, \rho)$: that is, for any $C > 0$, there exists a neighborhood $(-\varepsilon,\varepsilon)$ of $t=0$ in which
    \begin{equation}
        \SW^2_2(\mu^t, \rho) \leq \SW^2_2(\mu, \rho) - Ct^2.
    \end{equation}
\end{proposition}

\begin{figure*}[ht]
    \vskip 0.2in % J'ai repris le code de l'exemple pour les figures
    \begin{center}
        \centerline{\includegraphics[width=\linewidth]{fig_gd_2.png}}
        \caption{Gradient descent of $\SW^2_2$. On a point cloud of $N = 1000$ points for different choices of step-size and $\rho$. Left : convergence speed of gradient descent, where $\rho$ is the normal distribution, for different step-sizes (given in multiples of $N$ in the legend). Center left : Initial point cloud (in green), sampled uniformly in $[-1,1]^2$, and final point cloud (in red) after $200$ iterations with step-size $\lambda=2N$. Center right and right : same as respectively the left and center left images, but with $\rho$ the sliced-uniform measure (see \Cref{prop:ex_symmetric_crit_points}).}
         \label{fig:2main}
    \end{center}
   % \vskip -0.2in
\end{figure*}

The proof of \Cref{prop:examples_unstable} is deferred to \Cref{sec:proof_examples_unstable}. Our \Cref{prop:examples_unstable} proves that critical points as described therein, are highly unstable. Indeed, we do not have a Taylor expansion $\SW^2_2(\mu^t, \rho) = \SW^2_2(\mu, \rho) + at + \frac{1}{2} b t^2 + o(t^2)$ with $a = 0$ and $b < 0$. Instead, the inequality $\SW^2_2(\mu^t, \rho) \leq \SW^2_2(\mu, \rho) - Ct^2$ is true for \textit{any} $C > 0$ provided that $t$ is close enough to $0$. In particular, this implies that $\SW^2_2(\mu^t, \rho)$ is not twice differentiable at $t = 0$. Hence, while the SW flow may exhibit critical points that are not global minimizers, they may be unstable in general. Our result proves this in the case where the target contains a segment.


On the other hand, the perturbation $\mu^t$ used in Proposition \ref{prop:examples_unstable} is not of the form $(\Id+t\xi)_\#\mu$, and thus does not fit in our previously defined framework of Lagrangian critical points. However, this result suggests that by approximating $\mu^t$ using a suitable alternating vector field $\xi$, we can find $\xi$ such that $\SW^2_2((\Id+t\xi)_\#\mu, \rho)$ will also have a local maximum at $t = 0$.

Note that the proof of \Cref{prop:examples_unstable} makes heavy use of the properties of the segment, among which that the existence of a relatively simple closed form of the quantile functions of the projections are available. In general, it is difficult to describe how the quantile functions of the projections behave when considering general measures and perturbations.

\section{Experiments}\label{sec:experiments}

This section presents the results of our experiments, designed to examine the extent to which the theoretical findings from the previous sections hold in practice. 
%In order to investigate to what extent the theoretical results in the previous sections translate to practice, we conducted some experiments, the results of which are reported in this section. 
In the experiments, $F(X)$ is approximated by taking the average of 1D Wasserstein distances over $L = 100$ directions, and by approximating $\rho$ with a point cloud $Y$ containing $M = 10000$ points. Our code will be made public. 

\paragraph{Instability of critical points.} \label{paragraph:instability_experiments}
First, we considered a point cloud $X = (X_1,...,X_N)$ with $X_i = -\frac{4}{\pi} + \frac{8}{\pi}\frac{i-1}{N-1}$, with $N = 100$, that approximates the measure $\mu = \frac{\pi}{8} \cH^1_{|[-\frac{4}{\pi},\frac{4}{\pi}]}$ that was studied in \Cref{sec:lower_dim_crit_points}. We considered a perturbation $\xi$ that alternates between $e_2$ and $-e_2$ and we plotted $t \mapsto F(X + t\xi) = \SW^2_2(\mu_X^t, \rho)$ in Figure \ref{fig:1} for different choices of $\rho$. We see that the numerical results are consistent with our theoretical findings: indeed, we have a local maximum for all three considered target measures. Furthermore, when $X$ is a point cloud with a more complex shape but which includes an horizontal segment, we still observe an instability by perturbing the segment and leaving the other points of the point cloud unchanged. Moreover, while the perturbation considered in \Cref{prop:examples_unstable} is not induced by a vector field $\xi$, those in these experiments are, and they do exhibit an instability. This suggests that, if we approximate the perturbation in \Cref{prop:examples_unstable} closely enough with a vector field that alternates between $\vec{n}$ and $-\vec{n}$, we could obtain a unstable perturbation of the form $(\Id+t\xi)_\#\mu$, which would fit in our framework of Lagrangian critical points.

\paragraph{Gradient descent.}
We also investigated the convergence speed of the gradient descent for $\SW^2_2$ for different choices of step sizes, as shown in Figure~\ref{fig:2main}. We observe that choosing step sizes close to $\lambda = dN$ (here $d=2$), as %conjectured
justified 
in \Cref{section:sw_discrete} does indeed yield a important decrease of the loss at the first few iterations, while lower step sizes result in slower convergence of the descent, and step sizes larger than $2dN$ (the threshold above which \Cref{prop:descent_lemma} stops applying) result in divergence of the descent.

\section{Discussion.}
\mayberemove{In this work, we have studied critical points of Sliced-Wasserstein distances objectives with respect to a probability density $\rho$. We highlight the subtleties and relevance of Lagrangian critical points in the space of measures. We also 
prove rigorously the instability of a family of measures that are not absolutely continuous (\Cref{prop:examples_unstable}), and illustrate this behaviour numerically.\todo{Est-ce qu'on enlève ça ? C'est une répétition de ce qu'on avait déjà dit dans la section Contributions and outline}\ak{moi je le remettrai}
}
In this work, we have studied critical points of SW objectives with respect to a probability density $\rho$,  by leveraging the notion of Lagrangian critical points in the space of measures. We provided a detailed analysis of the critical points of a flow associated with a non-convex objective distance, in contrast with most of the literature that primarily deals with convex ones or that uses functional inequalities.   
%We highlight the subtleties and relevance of Lagrangian critical points in the space of measures. We also prove rigorously the instability of a family of measures that are not absolutely continuous (\Cref{prop:examples_unstable}), and illustrate this behaviour numerically.
However, many important open questions about critical points of SW remain. %, and we want to emphasize three of them
First, is it possible to prove that any Wasserstein or Lagrangian critical point $\mu$ of $\cF = \frac12 \SW^2_2(\cdot,\rho)$ which is absolutely continuous must be equal to $\rho$ ? Theorem 4.1 in \citep{cozzi2024long} gives a (very) partial answer to this question: it implies in particular that if $\rho$ is a standard Gaussian and if $\mu$ has finite entropy, then $\mu=\rho$. Second, can we get a better understanding of stable critical points? There exists finitely supported stable critical points (e.g. the global minimizers of the discretized energy) and we have shown in \Cref{prop:examples_unstable} that stable critical points cannot contain a segment. More generally, one could hope to show that any stable critical point $\mu$ of $\cF$ which is atomless must be equal to $\rho$.
Third, we note that there exists other proxies of the Wasserstein-p distances based on 1-dimensional projections, such as Max-sliced Wasserstein \cite{deshpande2019max}, SW distances with respect to other probability measures on the unit sphere \cite{nguyen2024energy,rowland2019orthogonal,mahey2024fast}. Extending our study to these variants of SW is the topic of future research. \ak{and to mmd with smooth kernels with is known to be non convex ? (arbel2019)}
%proposed to leverage 1-d projections to obtain (non-optimal) couplings between distributions in the original space and get upper proxies for the Wasserstein distance. 

\section{Acknowledgements}
The authors acknowledge the support of the Agence nationale de la recherche, through the PEPR PDE-AI project (ANR-23-PEIA-0004) and the AI4IDF funding from the DIM (Domaine de recherche et d'innovation majeure, Île de France). 

\bibliography{biblio}
\bibliographystyle{icml2025}

\newpage

\appendix

\input{appendix}

\end{document}
