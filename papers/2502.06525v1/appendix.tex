\onecolumn

\section{Proofs}

\subsection{Proof of \texorpdfstring{\Cref{prop:discrete_gradient}}{}}
\label{sec:proof_of_discrete_gradient}

First, consider a probability density $\rho \in \cP_p(\R)$, with cumulative distribution function $F_\rho : \R \mapsto [0;1]$. 
%We consider the function \[ G : X=(x_1,...,x_N) \in \R^N \mapsto \frac{1}{p} \W_p^p(\mu_X, \rho) \]with 
Let $\mu_X = \frac{1}{N} 
\sum_{i=1}^N \delta_{x_i}$ the uniform empirical measure associated to $X=(x_1,...,x_N) \in \R^N$. For every $i \in \{1,...,N\}$, we define $V_i = F_\rho^{-1}([\frac{i-1}{N};\frac{i}{N}])$ the $i$-th Power cell associated to $\rho$. Then the properties of one-dimensional optimal transport imply that, for every $X = (x_1,...,x_N) \in \R^N$ with $x_{\sigma(1)} \leq ... \leq x_{\sigma(N)}$, $\sigma \in \mathfrak{S}_N$, we have 
\begin{equation}
    G(X):=\frac{1}{p} \W_p^p(\mu_X, \rho) = \frac{1}{p} \sum_{i=1}^N \int_{V_i} |x_{\sigma(i)} - x|^p d\rho(x) = \frac{1}{p} \sum_{i=1}^N \int_{V_{\sigma^{-1}(i)}} |x_i - x|^p d\rho(x).
\end{equation}
We can then easily see that when $p > 1$, $G$ is $C^1$ on the complement of the generalized diagonal $\Delta_N = \{(x_1,...,x_N) \in \R^N \mid \exists i \neq j, x_i = x_j \}$, and its partial derivatives are given by 
\begin{equation}
    \partial_i G (x_1,...,x_N) = \int_{V_{\sigma^{-1}(i)}} \sgn(x_i - x)|x_i - x|^{p-1} d\rho(x),
\end{equation}
where $\sigma \in \mathfrak{S}_N$ is such that $x_{\sigma(1)} < ... < x_{\sigma(N)}$. In the particular case where $p = 2$, the partial derivatives take the simpler form 
\begin{equation}
   \partial_i G (x_1,...,x_N) = \int_{V_{\sigma^{-1}(i)}} (x_i - x)d\rho(x) = \frac{1}{N} (x_i - b_{\sigma^{-1}(i)}) 
\end{equation}
with $b_i = N\int_{V_i} xd\rho(x)$ the barycenter of the $i$-th Power cell $V_i$. \\
With these considerations on one-dimensional measures in mind, we can now move on to prove \Cref{prop:discrete_gradient}. For this, we will need the following lemma.

\begin{lemma}
    \label{lm:lemma_1}
    If $p \geq 2$, $\rho \in \cP_p(\R)$ is a probability density and $X = (x_1,...,x_N) \in \Delta_N$ with $x_{\sigma(1)} < ... < x_{\sigma(N)}$, $\sigma \in \mathfrak{S}_N$, and $H = (h_1,...,h_N) \in \R^N$ is a perturbation such that $X+H$ has the same ordering $\sigma$ as $X$, then writing $R_1 G(X,H) = G(X+H) - G(X) - \sca{\nabla G(X)}{H}$ we have
    \begin{equation}
        |R_1 G(X,H)| \leq (p-1) \sum_{i=1}^N |h_i|^2\left(\sum_{k=0}^{p-2} \binom{p-2}{k} |h_i|^{p-2-k} \int |x_i - x|^k d\rho(x) \right)
    \end{equation}
    (this is a finite quantity since $\rho$ has finite order $p$ moments).
\end{lemma}

\begin{proof}
    Consider the function $f(x) = |x|^p$. Since $p \geq 2$, we see that $f$ is $C^2$ and that $f'(x) = px|x|^{p-2}$, $f"(x) = p(p-1)|x|^{p-2}$. As a consequence, applying Taylor's theorem, for every $x,h \in \R$,
    \begin{align}
        f(x+h) - f(x) - f'(x)h &= \int_{x}^{x+h} f"(t)(x-t)dt \\
        |f(x+h) - f(x) - f'(x)h| &\leq \int_{x}^{x+h} |f"(t)(x-t)|dt \\
            &\leq \int_{x}^{x+h} p(p-1) \max(|x|,|x+h|)^{p-2}|h|dt \\
            &\leq p(p-1) |h|^2 (|x|+|h|)^{p-2} \\
    \end{align}
    Therefore, since $X+H$ and $X$ have the same ordering $\sigma$, 
    \begin{align}
        R_1 G(X,H)
            &= \frac{1}{p} \sum_{i=1}^N \int_{V_{\sigma^{-1}(i)}} (|x_i + h_i - x|^p - |x_i - x|^p - p\sgn(x_i - x)|x_i - x|^{p-1}) d\rho(x) \\
        |R_1 G(X,H)| 
            &\leq \frac{1}{p}\sum_{i=1}^N \int_{V_{\sigma^{-1}(i)}} p(p-1) |h_i|^2 (|x_i - x|+|h_i|)^{p-2} d\rho(x) \\
            &\leq (p-1) \sum_{i=1}^N |h_i|^2 \int (|x_i - x|+|h_i|)^{p-2} d\rho(x) \\
            &\leq (p-1) \sum_{i=1}^N |h_i|^2\left(\sum_{k=0}^{p-2} \binom{p-2}{k} |h_i|^{p-2-k} \int |x_i - x|^k d\rho(x) \right)
    \end{align}
\end{proof}

Now we can prove \Cref{prop:discrete_gradient}.
\begin{proof} [Proof (\Cref{prop:discrete_gradient})]
    First, let's introduce the following definitions : for every $\epsilon > 0$ let 
    \begin{equation}
        \Theta_\epsilon := \{ \theta \in \Sph^{d-1} \mid \exists i \neq j, |\sca{X_i-X_j}{\theta}| \leq \epsilon \}
    \end{equation}
    and for every $\theta \in \Sph^{d-1}$ define the function $G_\theta : X \in \R^N \mapsto \frac{1}{p} \Wass_p^p(\mu_X,P_{\theta\#}\rho)$
    For every point cloud $X \in (\R^d)^N$ and every $\theta \in \Sph^{d-1}$, let $\sigma_{\theta,X} \in \mathfrak{S}_N$ be a (not necessarily unique) permutation such that $\sca{X_{\sigma_{\theta,X}(1)}}{\theta} \leq ... \leq \sca{X_{\sigma_{\theta,X}(N)}}{\theta}$, and let 
    \begin{equation}
        \tilde{\nabla}_{X_i}F(X) := \int_{\bS^{d-1}} \int_{V_{\theta,\sigma_{\theta,X}^{-1}(i)}} \sgn(\sca{X_i}{\theta} - x)|\sca{X_i}{\theta} - x|^{p-1}\theta dP_{\theta\#}\rho(x) d\theta
    \end{equation}
    We want to prove that if $X \notin \Delta_N$, $F$ is differentiable at $X$ and $\nabla F(X) = \tilde{\nabla}F(X)$.

    Let $\epsilon > 0$ be fixed. We see that if $\|H\| \leq \epsilon$, then for every $\theta \notin \Theta_{2\epsilon}$, $\sigma_{\theta,X+H} = \sigma_{\theta,X}$. Furthermore we know that there exists $C_0 = C_0(X) > 0$ such that
    \begin{equation}
        \Haus^{d-1}(\Theta_\epsilon) \leq C_0\epsilon
    \end{equation}

    We now consider a perturbation $H$ such that $\|H\| \leq \epsilon/2$. We have
    \begin{equation}
        F(X+H) - F(X) - \sca{\tilde{\nabla}F(X)}{H} = A(H) + B(H) + C(H)
    \end{equation}
    with
    \begin{align}
        A(H) &= \int_{\Theta_{\epsilon}^c} (G_\theta(P_\theta(X+H)) - G_\theta(P_\theta(X)) - \sca{P_\theta(H)}{\nabla G_\theta(P_\theta(X))}) d\theta \\
        B(H) &= \int_{\Theta_{\epsilon}} (G_\theta(P_\theta(X+H)) - G_\theta(P_\theta(X))) d\theta \\
        C(H) &= - \int_{\Theta_{\epsilon}} \sca{P_\theta(H)}{\nabla G_\theta(P_\theta(X))} d\theta
    \end{align}
    When $\theta \in \Theta_\epsilon^c$, we have $\sigma_{\theta,X+H} = \sigma_{\theta,X}$ and we can apply lemma \ref{lm:lemma_1} to $G_\theta$ and we have that 
    \begin{equation}
        \left| G_\theta(P_\theta(X+H)) - G_\theta(P_\theta(X)) - \sca{P_\theta(H)}{\nabla G_\theta(P_\theta(X))} \right| \leq C \|H\|^2
    \end{equation}
    with a constant $C$ that is uniform on $\theta$ and depends only on $X$, $\rho$, $\epsilon$ and $p$ (indeed, the moments of $P_{\theta\#}\rho$ are bounded by those of $\rho$). Therefore we deduce that
    \begin{equation}
        A(H) = o(\|H\|)
    \end{equation}
    Now, notice that 
    \begin{align}
        |\partial_i G_\theta(P_\theta(X))| 
            &\leq \int_{V_{\theta,\sigma_{\theta,X}^{-1}(i)}} |\sca{X_i}{\theta} - x|^{p-1} dP_{\theta\#}\rho(x) \\
        \sum_{i=1}^N | \partial_i G_\theta(P_\theta(X)) | 
            &\leq \sum_{i=1}^N \int_{V_{\theta,\sigma_{\theta,X}^{-1}(i)}} |\sca{X_i}{\theta} - x|^{p-1} dP_{\theta\#}\rho(x) \\
            &\leq \Wass_{p-1}^{p-1}(\mu_{P_\theta(X)},P_{\theta\#}\rho) \leq \Wass_{p-1}^{p-1}(\mu_X,\rho) \\
    \end{align}
    therefore we deduce that
    \begin{equation}
        |C(H)| \leq C_0\epsilon\|H\|\Wass_{p-1}^{p-1}(\mu_X,\rho)
    \end{equation}

    Finally, for a generic $\theta$, using the shorthand notations $W_p(X) = W_p(\mu_{P_\theta(X)},P_{\theta\#}\rho)$ and $W_p(Y,X) = W_p(\mu_{P_\theta(X)},\mu_{P_\theta(Y)})$, we have
    \begin{align}
        |G_\theta(P_\theta(X+H)) - G_\theta(P_\theta(X))|
            &= |W_p(X+H)^p - W_p(X)^p| \\
            &= |W_p(X+H) - W_p(X)| \sum_{i=0}^{p-1} W_p(X+H)^{p-1-i} W_p(X)^i \\
            &\leq  W_p(X+H,X) \sum_{i=0}^{p-1} (W_p(X)+W_p(X,X+H))^{p-1-i} W_p(X)^i
    \end{align}
    because $\Wass_p$ is a distance and satisfies the triangle inequality. Since $W_p(X+H,X) \leq \|H\| \leq \epsilon$ and $W_p(X) \leq \Wass(\mu_X,\rho)$, we have
    \begin{equation}
        |G_\theta(P_\theta(X+H)) - G_\theta(P_\theta(X))| \leq C\|H\|
    \end{equation}
    with a constant $C$ which is uniform in $\theta$ and depends only on $p$, $\epsilon$ and $\Wass(\mu_X,\rho)$.
    Therefore 
    \begin{equation}
        |B(H)| \leq C_0C\epsilon\|H\|
    \end{equation}
    
    Thus, we have proven that 
    \begin{equation}
        F(X+H) - F(X) - \sca{\tilde{\nabla}F(X)}{H} = o(\|H\|)
    \end{equation}
    which is the desired result.
\end{proof}

As a side note, remark that $F$ is actually twice differentiable almost everywhere, as a consequence of the following semi-concavity property for $F$ :

\begin{proposition}
    $F$ is $\frac{1}{Nd}$-semiconcave (i.e. $F - \frac{1}{2Nd}\|\cdot\|^2$ is concave).
\end{proposition}

\begin{proof}
    Indeed, $ F(X) - \frac{1}{2Nd}\|X\|^2 = \int_{\bS^{d-1}} \frac{1}{2} \W^2_2(\mu_{P_\theta(X)},P_{\theta\#}\rho) - \frac{1}{2N} \|P_\theta(X)\|^2 d\theta $ for every $X \in \R^{d \times N}$, and we use the fact that the projection $P_\theta$ is linear and that $Y \in \R^N \mapsto \W_2^2(Y,\tilde{\rho})$ is $\frac{1}{N}$-semiconcave (see for example Proposition 1, \citep{Mrigot2021NonasymptoticCB})
\end{proof}

\subsection{Proof of \texorpdfstring{\Cref{prop:descent_lemma}}{}} \label{sec:proof_descent_lemma}

To prove the descent lemma \Cref{prop:descent_lemma}, we first need to prove that $F$ is smooth.

\begin{proposition} \label{prop:l_smoothness}
    For every $X,Y \in \R^{d \times N} \setminus \Delta_N$, we have 
    \begin{equation}\label{eq:l_smoothness}
        F(Y) \leq F(X) + \sca{\nabla F(X)}{Y-X}  + \frac{1}{2Nd} \|X-Y\|^2
    \end{equation}
\end{proposition}

\begin{proof}
    First, let $\theta \in \bS^{d-1}$ be fixed. Let $\sigma \in \mathfrak{S}_N$ be such that $\sca{X_{\sigma_\theta(1)}}{\theta} \leq ... \leq \sca{X_{\sigma_\theta(N)}}{\theta}$. Then, since the map which sends $V_{\theta,i}$ to $\sca{Y_{\sigma_\theta(i)}}{\theta}$ is a (not necessarily optimal) transport map from $\rho_\theta$ to $\mu_{P_\theta(Y)}$, we have
    \begin{align}
        \W_2^2(\mu_{P_\theta(Y)}, \rho_\theta) \leq& \sum_{i=1}^N \int_{V_{\theta,\sigma_\theta^{-1}(i)}} |\sca{Y_i}{\theta} - x|^2 d\rho_\theta(x) \\
            \leq& \sum_{i=1}^N \int_{V_{\theta,\sigma_\theta^{-1}(i)}} |\sca{Y_i}{\theta} - \sca{X_i}{\theta} + \sca{X_i}{\theta} - x|^2 d\rho_\theta(x) \\
            \leq& \frac{1}{N} \sum_{i=1}^N \sca{Y_i-X_i}{\theta}^2 + \sum_{i=1}^N \int_{V_{\theta,\sigma_\theta^{-1}(i)}} 2\sca{Y_i-X_i}{\theta}(\sca{X_i}{\theta}  - x) d\rho_\theta(x) \\
            &+ \W_2^2(\mu_{P_\theta(X)}, \rho_\theta) \\
            \leq& \frac{1}{N} \sum_{i=1}^N \sca{Y_i-X_i}{\theta}^2 + \sum_{i=1}^N \frac{2}{N} \sca{Y_i-X_i}{\theta}(\sca{X_i}{\theta}  - b_{\theta,i}) \\
            &+ \W_2^2(\mu_{P_\theta(X)}, \rho_\theta)
    \end{align}
    Integrating over the sphere we have 
    \begin{align}
        \SW_2^2(\mu_Y, \rho) \leq& \frac{1}{N} \sum_{i=1}^N \int_{\bS^{d-1}} \sca{Y_i-X_i}{\theta}^2 d\theta + \frac{2}{N} \sum_{i=1}^N \int_{\bS^{d-1}} \sca{Y_i-X_i}{\theta} (\sca{X_i}{\theta}  - b_{\theta,i})d\theta \\
            &+ \SW_2^2(\mu_X, \rho) \\
         \leq& \frac{1}{Nd} \sum_{i=1}^N \|Y_i-X_i\|^2  + \sum_{i=1}^N \left\langle Y_i-X_i \mid \frac{2}{N} \int_{\bS^{d-1}} (\sca{X_i}{\theta}  - b_{\theta,i})\theta d\theta \right\rangle \\
         &+ \SW_2^2(\mu_X, \rho)
    \end{align}
    In the RHS of the last inequality, we recognize the expression of the gradient of $F$ which we recall is $\nabla_{X_i} F = \frac{1}{N} \int_{\bS^{d-1}} (\sca{X_i}{\theta} - b_{\theta,i})\theta d\theta$. Therefore, substituting it gives the intended result
    \begin{equation}
        F(Y) \leq \frac{1}{2Nd} \|X-Y\|^2 + \sca{Y-X}{\nabla F(X)}  + F(X).  \qedhere 
    \end{equation}
\end{proof}

Now, we can prove \Cref{prop:descent_lemma}.  
    Equation \eqref{eq:dsct_lma1} is obtained directly from \Cref{eq:l_smoothness} by taking $Y := X - \lambda \nabla F(X)$. %To get equation \eqref{eq:dsct_lma2}, we observe that \begin{equation}       \inf F - F(X)\leq F(X - \lambda \nabla F(X)) - F(X) \leq -\lambda \left(1 - \frac{\lambda}{2Nd}\right) \|\nabla F(X)\|^2      \end{equation}and, taking $\lambda = Nd$, we obtain \eqref{eq:dsct_lma2}.

\subsection{Proof of \texorpdfstring{\Cref{prop:descent_well_behaved}}{}} \label{sec:proof_descent_well_behaved}

We will first need to prove the following lemmas :

\begin{lemma} \label{lemma:barycenter_bound_distance}
    Let $\rho \in \cP([a,b])$ be an absolutely continuous probability measure, with density (which we will also denote $\rho$) bounded from above by $\beta > 0$. Then the barycenter $x_0 = \int_a^b x d\rho(x)$ of $\rho$ satisfies $|x_0 - a|, |x_0 - b| \geq \frac{1}{2\beta}$.
\end{lemma}

\begin{proof}
    Since $\rho \leq \beta$, integrating $\rho$ on $[a,b]$, we note that $\frac{1}{\beta} \leq b-a$. Let $\rho_0 \in \cP([a,b])$ be the probability with density $\beta$ on $[a,a+1/\beta]$ and $0$ on $[a+1/\beta,b]$. Its cumulative distribution function is thus
    \begin{equation}
         F_{\rho_0}(x) = \begin{cases}
        \beta(x-a) & \hbox{ if } x \in [a,a+1/\beta] \\
        1 & \hbox{ if } x \geq a+\frac{1}{\beta}
        \end{cases}
    \end{equation}
    and, since $\rho \leq \beta$, we have $F_{\rho} \leq F_{\rho_0}$ on $[a,b]$. Thus, the quantile functions of $\rho,\rho_0$ satisfy $F_{\rho}^{-1} \geq F^{-1}_{\rho_0}$ (this follows directly from their definition), and we have
    \begin{align}
        x_0 - a &= \int_a^b (x-a) d\rho(x) = \int_0^1 (F^{-1}_{\rho}(x) - a)dx \\
        &\geq \int_0^1 (F^{-1}_{\rho_0}(x)-a) dx = \int_a^b (x-a) d\rho_0(x) = \int_a^{a+\frac{1}{\beta}} \beta (x-a) dx = \frac{1}{2\beta}
    \end{align}
    where we used the fact that $\mu = F^{-1}_{\mu\#}\cL^1_{[0,1]}$ for any probability measure $\mu$ on the real line (see \citep[Proposition 2.2]{santambrogio2015optimal}). Similarly, we can show that $b - x_0 \geq \frac{1}{2\beta}$
\end{proof}

\begin{lemma} \label{lemma:gradient_diff_bound}
    Assume that there exists $\beta > 0$ bounding from above the density of $\rho_\theta$ for every $\theta \in \bS^{d-1}$. Then there exists $C = C(d)$ such that, for every $X \in (\R^d)^N \setminus \Delta_N$, we have for every $i \neq j$,
    \begin{equation} \label{eq:lemma_grad_diff_bound}
        N\sca{\nabla_{X_i}F(X) - \nabla_{X_j}F(X)}{X_i - X_j} \leq \frac{1}{d} \|X_i - X_j\|^2 - \frac{C}{N\beta}\|X_i - X_j\|
    \end{equation}
\end{lemma}

\begin{proof}
    Using the notations of \Cref{prop:discrete_gradient} and \Cref{eq:sw2_critical_point}, we have
    \begin{equation}
        N\sca{\nabla_{X_i}F(X) - \nabla_{X_j}F(X)}{X_i - X_j} = \frac{1}{d} \|X_i - X_j\|^2 - \int_{\bS^{d-1}} (b_{\theta,\sigma^{-1}_{X,\theta}(i)} - b_{\theta,\sigma^{-1}_{X,\theta}(j)})\sca{\theta}{X_i - X_j} d\theta
    \end{equation}
    By symmetry, we have in fact
    \begin{equation} \label{eq:appendix_l183}
        N\sca{\nabla_{X_i}F(X) - \nabla_{X_j}F(X)}{X_i - X_j} = \frac{1}{d} \|X_i - X_j\|^2 - 2\int_{\{\sca{\theta}{X_i - X_j} > 0\}} (b_{\theta,\sigma^{-1}_{X,\theta}(i)} - b_{\theta,\sigma^{-1}_{X,\theta}(j)})\sca{\theta}{X_i - X_j} d\theta
    \end{equation}
    Indeed, for every $\theta \in \bS^{d-1}$, we can check that we have $\sigma_{X,-\theta}^{-1}(k) = N + 1 - \sigma_{X,\theta}^{-1}(k)$ and $b_{-\theta,k} = b_{\theta,N+1-k}$ for every $k = 1,\ldots,N$. However, if $\theta \in \bS^{d-1}$ is such that $\sca{\theta}{X_i - X_j} > 0$, then we have $\sigma^{-1}_{X,\theta}(i) > \sigma^{-1}_{X,\theta}(j)$, and thus
    \begin{equation}
        b_{\theta,\sigma^{-1}_{X,\theta}(i)} - b_{\theta,\sigma^{-1}_{X,\theta}(j)} \geq \frac{1}{N \beta}
    \end{equation}
    Indeed, for every $k = 1,\ldots,N$, the distance separating the barycenter $b_{\theta,k}$ from the boundary of its corresponding Power cell $V_{\theta,k}$ is at least $\frac{1}{2\beta N}$, which we see by applying \Cref{lemma:barycenter_bound_distance} to the probability measure $N \rho_{\theta|V_{\theta,k}}$. In particular, since $\sca{\theta}{X_i - X_j}$ is also positive, we have
    \begin{equation}
        \sca{\theta}{X_i - X_j}(b_{\theta,\sigma^{-1}_{X,\theta}(i)} - b_{\theta,\sigma^{-1}_{X,\theta}(j)}) \geq \frac{1}{N \beta}\sca{\theta}{X_i - X_j}
    \end{equation}
    Injecting this into \Cref{eq:appendix_l183}, we obtain the inequality
    \begin{align}
        N\sca{\nabla_{X_i}F(X) - \nabla_{X_j}F(X)}{X_i - X_j} &\leq \frac{1}{d} \|X_i - X_j\|^2 - 2\int_{\{\sca{\theta}{X_i - X_j} > 0\}} \frac{1}{N \beta}\sca{\theta}{X_i - X_j} d\theta \\
        &\leq \frac{1}{d} \|X_i - X_j\|^2 - \frac{2}{N\beta}\|X_i - X_j\|\int_{\{\sca{\theta}{\theta_0} > 0\}} \sca{\theta}{\theta_0} d\theta \\
        &\leq \frac{1}{d} \|X_i - X_j\|^2 - \frac{C}{N\beta}\|X_i - X_j\|
    \end{align}
    where $\theta_0 := \frac{X_i - X_j}{\|X_i - X_j\|}$, and where $C := 2\int_{\{\sca{\theta}{\theta_0} > 0} \sca{\theta}{\theta_0} d\theta > 0$. Note that, by symmetry, $C$ does not depend on $\theta_0 \in \bS^{d-1}$ and depends only on $d$. This proves the lemma.
\end{proof}

We can now prove the proposition.

\begin{proof}[Proof (\Cref{prop:descent_well_behaved})]
    If $i \neq j$, then we have
    \begin{align}
        \|Y_i - Y_j\|^2 &= \|(X_i - X_j) - \lambda (\nabla_{X_i} F(X) - \nabla_{X_j} F(X)) \|^2 \\
        &= \|X_i - X_j\|^2 - 2\lambda \sca{\nabla_{X_i} F(X) - \nabla_{X_j} F(X)}{X_i - X_j} + \lambda^2 \|\nabla_{X_i} F(X) - \nabla_{X_j} F(X)\|^2 \\
        &\geq \|X_i - X_j\|^2 - 2\lambda \sca{\nabla_{X_i} F(X) - \nabla_{X_j} F(X)}{X_i - X_j} \\
        &\geq \|X_i - X_j\|^2 - 2\frac{\lambda}{N} \left(\frac{1}{d} \|X_i - X_j\|^2 - \frac{C}{N\beta}\|X_i - X_j\|\right) 
    \end{align}
    where we used \Cref{lemma:gradient_diff_bound} in the last line. Thus, we have proved
    \begin{equation}
        \|Y_i - Y_j\|^2 \geq \|X_i - X_j\|^2 + 2\frac{\lambda}{N} \|X_i - X_j\| \left(\frac{C}{N\beta} - \frac{1}{d}\|X_i - X_j\|\right) \label{eq:grad_descent_iterates_distances}
    \end{equation}
    Now :
    \begin{itemize}
        \item If $\|X_i - X_j\| \leq \frac{dC}{N\beta}$, we have directly $\|Y_i - Y_j\| > \|X_i - X_j\|$ from \Cref{eq:grad_descent_iterates_distances}.
        \item If $\lambda \in (0,Nd/2)$, then we have from \Cref{eq:grad_descent_iterates_distances},
        \begin{align}
            \|Y_i - Y_j\|^2 &\geq \|X_i - X_j\|^2 - 2\frac{\lambda}{N} \left(\frac{1}{d} \|X_i - X_j\|^2 - \frac{C}{N\beta}\|X_i - X_j\|\right) \\
            &\geq \|X_i - X_j\|^2 - 2\frac{\lambda}{dN} \|X_i - X_j\|^2 = \left(1 - \frac{2\lambda}{dN}\right) \|X_i - X_j\|^2 > 0
        \end{align}
        \item If $X$ is a critical point, we have $\nabla F(X) = 0$ and thus $Y = X$. Therefore, \Cref{eq:grad_descent_iterates_distances} yields
        \begin{equation}
            0 \geq 2\frac{\lambda}{N} \|X_i - X_j\| \left(\frac{C}{N\beta} - \frac{1}{d} \|X_i - X_j\|\right)
        \end{equation}
        which implies
        \begin{equation}
            \frac{1}{d} \|X_i - X_j\| \geq \frac{C}{N\beta}
        \end{equation}
    \end{itemize}
\end{proof}

As a side note, observe that if we consider the continuous time gradient flow
\begin{equation}
    \begin{cases}
    X(t = 0) = X_0 & \hbox{ with } X_0 \in (\R^d)^N \setminus \Delta_N \\
    \dot{X}(t) = -\nabla F(X(t)) & \hbox{ for } t > 0
\end{cases}
\end{equation}
then \Cref{lemma:gradient_diff_bound} implies that for every $t > 0$ at which the flow is well-defined, for every $i \neq j$,
\begin{align}
    \frac{d}{dt} \|X_i - X_j\|^2 &= -\sca{\nabla_{X_i} F(X) - \nabla_{X_j} F(X)}{X_i - X_j} \\
    &\geq -\frac{1}{Nd} \|X_i - X_j\|^2 + \frac{C}{N^2\beta}\|X_i - X_j\| \\
    &\geq \frac{\|X_i - X_j\|}{N} \left(\frac{C}{N\beta} - \frac{1}{d}\|X_i - X_j\| \right)
\end{align}
and in particular
\begin{equation} \frac{d}{dt} \|X_i - X_j\|^2 > 0 \end{equation}
whenever $\|X_i - X_j\| \leq \frac{dC}{N\beta}$. This implies that :
\begin{itemize}
    \item If $\|X_i - X_j\| \geq \frac{dC}{N\beta}$ at $t = 0$, then this inequality must stay true at every $t > 0$.
    \item If $\|X_i - X_j\| \leq \frac{dC}{N\beta}$ at $t = 0$, then $\|X_i - X_j\|$ increases until it is greater or equal than $\frac{dC}{N\beta}$, and does not become lower than this threshold afterwards.
\end{itemize}
Thus, we see that the continuous time gradient flow is also well-behaved, in that it will tend to stay far away from the generalized diagonal $\Delta_N$.

\subsection{Proof of \texorpdfstring{\Cref{prop:compatibility_with_discrete_case}}{}} \label{sec:proof_compatibility_with_discrete_case}

First, it will be helpful to introduce the following family of transport plans between the projected measures : for a given $\theta \in \bS^{d-1}$, we disintegrate $\mu$ and $\rho$ with respect to $P_\theta$ to get families of probabilities $(\mu_{\theta,u})_{u\in \R}$ and $(\rho_{\theta,v})_{v\in \R}$ such that $\spt (\mu_{\theta,u}) \subseteq P_\theta^{-1}(u)$, $\spt (\rho_{\theta,v}) \subseteq P_\theta^{-v}(s)$ and for every test function $\varphi \in C^0(\Omega)$, $\int \varphi(x) d\mu(x) = \int \int \varphi(x) d\mu_{\theta,u}(x) d\mu_\theta(u)$ and $\int \varphi(y) d\rho(y) = \int \int \varphi(y) d\rho_{\theta,v}(y) d\rho_\theta(v)$. We then define $\hat{\gamma}_\theta$ as the probability measure whose integral over a test function $\varphi(x,y) \in C^0(\Omega \times \Omega)$ is

\[ \int \varphi(x,y) d\hat{\gamma}_\theta(x,y) = \int \int \int \varphi(x,y) d\mu_{\theta,u}(x)d\rho_{\theta,v}(y) d\gamma_\theta(u,v). \]

We can see then that $\hat{\gamma}_\theta$ is a transport plan (not necessarily optimal) between $\mu$ and $\nu$ and that $(P_\theta,P_\theta)_\#\hat{\gamma}_\theta = \gamma_\theta$ (in other words, $\hat{\gamma}_\theta$ is optimal for the cost function $x,y \mapsto \sca{y-x}{\theta}^2$). We also disintegrate $\gamma_\theta$ with respect to the first variable, giving a family of probabilities $(\gamma_{\theta,u})_{u \in \R}$ such that $\spt (\gamma_{\theta,u}) \subseteq \{u\} \times \R \simeq \R$ (in other words, for every test function $\varphi \in C^0(\R \times \R)$, $\int \varphi(u,v) d\gamma_\theta(u,v) = \int \int \varphi(u,v) d\gamma_{\theta,u}(v) d\mu_\theta(u)$). Notice that these give an alternative definition of $\bar{\gamma}_\theta$ : indeed $\bar{\gamma}_\theta(u) = \int v d\gamma_{\theta,u}(v)$.

We can now proceed to the proof of \Cref{prop:compatibility_with_discrete_case}.

\begin{proof}[Proof (\Cref{prop:compatibility_with_discrete_case})]
    First, if $\xi \in L^2(\mu_X,\R^d)$, then, defining $H \in (\R^d)^N$ by $H_i := \xi(X_i)$ for every $i = 1,\ldots,N$, we have for every $t > 0$ (small enough so that $X + tH \notin \Delta_N$),
    \begin{equation} F(X + tH) = \frac 12 \SW^2_2(\mu_{X+tH}, \rho) = \frac 12 \SW^2_2((\Id+t\xi)_\#\mu_X,\rho) \end{equation}
    from which we deduce, by taking the right derivative at $t = 0$,
    \begin{equation} \sca{\nabla F(X)}{H} = \left. \frac{d}{dt} \SW^2_2((\Id+t\xi)_\#\mu,\rho) \right|_{t=0^+} \end{equation}
    In particular, we immediately see from \Cref{def:lag-crit} that $\nabla F(X) = 0$ if and only if $\mu_X$ is a Lagrangian critical point. \newline

    Second, the condition $v_{\mu_X} = 0$ $\mu_X$-a.e. from \Cref{def:strong-lag-crit} writes as
    \begin{equation} \label{eq:appendix_l259}
        \frac{1}{d} X_i - \int_{\bS^{d-1}} \bar{\gamma}_\theta(\sca{X_i}{\theta}) \theta d\theta = 0, \quad i \in \{1,\ldots,N\}
    \end{equation}
    Fix $\theta \in \bS^{d-1}$ such that the $\sca{X_1}{\theta},\ldots,\sca{X_N}{\theta}$ are distinct. Using the notations from \Cref{section:sw_discrete}, we know that $\gamma_\theta = (T_\theta,\Id)_\#\rho_\theta$ where $T_\theta$ is the optimal transport map from $\rho_\theta$ to $\mu_\theta$, which sends for every $i=1,\ldots,N$ the Power cell $V_{\theta,i}$ to $\sca{X_{\sigma_{X,\theta}(i)}}{\theta}$. Thus, for every test function $\varphi \in C^0(\R \times \R)$, we have
    \begin{align}
        \int_{\R \times \R} \varphi(u,v) d\gamma_\theta(u,v) &= \sum_{i=1}^N \int_{\R \times V_{\theta,\sigma^{-1}_{X,\theta}(i)}} \varphi(u,v) d\gamma_\theta(u,v) \\ 
        &= \sum_{i=1}^N \int_{\R \times V_{\theta,\sigma^{-1}_{X,\theta}(i)}} \varphi(\sca{X_i}{\theta},v) d\gamma_\theta(u,v) \\ 
        &= \sum_{i=1}^N \int_{V_{\theta,\sigma^{-1}_{X,\theta}(i)}} \varphi(\sca{X_i}{\theta},v) d\rho_\theta(v)
    \end{align}
    and since we also have
    \begin{align}
        \int_{\R \times \R} \varphi(u,v) d\gamma_\theta(u,v) &= \int_\R \int_\R \varphi(u,v) d\gamma_{\theta,u}(v) d\mu_\theta(u) \\
        &= \frac 1N \sum_{i=1}^N \int_{\R} \varphi(\sca{X_i}{\theta},v) d\gamma_{\theta,\sca{X_i}{\theta}}(v)
    \end{align}
    we deduce that $\gamma_{\theta,\sca{X_i}{\theta}} = N\rho_{|V_{\theta,\sigma^{-1}_{X,\theta}(i)}}$ for every $i$. Thus, we have for every $i$
    \begin{equation} \bar{\gamma}_\theta(\sca{X_i}{\theta}) = \int_\R v d\gamma_{\theta,\sca{\theta}{X_i}}(v) = N\int_{V_{\theta,\sigma^{-1}_{X,\theta}(i)}} vd\rho_\theta(v) = b_{\theta,\sigma_{X,\theta}^{-1}(i)} \end{equation}
    and, using \eqref{eq:sw2_critical_point}, \eqref{eq:appendix_l259} rewrites as
    \begin{equation} N\nabla_{X_i} F(X) = 0, \quad i \in \{1,\ldots,N\} \end{equation}
    Thus, $\nabla F(X) = 0$ iff $\mu_X$ is a barycentric Lagrangian critical point.
\end{proof}

\subsection{Proof of \texorpdfstring{\Cref{prop:sw2_diff}}{}} \label{sec:proof_sw2_diff}

First, we prove \Cref{prop:sw2_diff}(a). Let $\xi_0,\xi_1 \in L^2(\mu,\R^d)$, we denote $S^t = \Id + (1-t)\xi_0 + t\xi_1$ and $\mu^t = S^t_{\#}\mu$. For any fixed $t\in [0,1]$,  $\gamma := ((P_\theta,P_\theta) \circ (S_0,S_1))_\#\mu$ is a transport plan between $\mu^0_\theta$ and $\mu^1_\theta$ such that 
\begin{equation} \mu^t_\theta = ((1-t)\pi_1 + t\pi_2)_{\#} \gamma.\end{equation}
where $\pi_i$ is the projection on the $i$-th coordinate. Furthermore, by Proposition 7.3.1 of \cite{ambrosio2005gradient}, there exists a plan $\eta \in \cP(\R \times \R \times \R)$ such that $(\pi_1,\pi_2)_\#\eta = \gamma$ and $((1-t)\pi_1+t\pi_2,\pi_3)_\#\eta$ is an optimal transport plan between $\mu^t_\theta$ and $\rho_\theta$. Then, according to Theorem 7.3.2 of \cite{ambrosio2005gradient}, asserting the semi-concavity of the squared Wasserstein distance, we have
\begin{equation} \label{eq:appendix_l295}
    \W_2^2(\mu^t_\theta,\rho^\theta) \geq (1-t)\W_2^2(\mu^0_\theta,\rho_\theta) + t\W_2^2(\mu^0_\theta,\rho_\theta) - t(1-t)\W_{\eta}^2(\mu^0_\theta,\mu^1_\theta),
\end{equation}
where $W_\eta$ is defined in (7.3.2) of \cite{ambrosio2005gradient} by
\begin{equation} \label{eq:appendix_l297}
    W^2_\eta(((1-t)\pi_1 + t\pi_2)_\#\eta,\pi_{k\#}\eta) := \int_{\R \times \R \times \R} |(1-t)x_i + tx_j - x_k|^2 d\eta(x_i,x_j,x_k)
\end{equation}
for every $i,j,k \in \{1,2,3\}$ and $t \in [0,1]$. In this case, we have
\begin{align}
    \W_{\eta}^2(\mu^0_\theta,\mu^1_\theta) &= \int_{\R^3} (x_1 - x_2)^2 d\eta(x_1,x_2,x_3) = \int_{\R^2} (x-y)^2 d\gamma(x,y) \\
    &= \int_{\R^2} \sca{x - y}{\theta}^2 d(S_0,S_1)_{\#}\mu(x,y) = \int \sca{\xi_0(x) - \xi_1(x)}{\theta}^2 d\mu(x)
\end{align}
(we take $i=0,j=2,k=1$ and $t=0$ in \eqref{eq:appendix_l297}). Integrating the inequality \eqref{eq:appendix_l295} over $\theta \in \bS^{d-1}$, we get 
\begin{align}
    \SW_2^2(\mu^t,\rho) 
    &\geq (1-t)\SW_2^2(\mu^0,\rho) + t \SW_2^2(\mu^1,\rho) -  t(1-t)\int \int_{\bS^{d-1}}\sca{\xi_1(x) - \xi_0(x)}{\theta}^2  d\theta d\mu(x) \\
    &\geq (1-t)\SW_2^2(\mu^0,\rho) + t \SW_2^2(\mu^1,\rho) -  \frac{1}{d} t(1-t)\|\xi_1 - \xi_0\|^2_{L^2(\mu)}
\end{align}
This rewrites as
\begin{equation} F_\mu((1-t)\xi_0 + t\xi_1) \leq (1-t) F_\mu(\xi_0) + t F_\mu(\xi_1) \end{equation}
which proves the convexity of $F_\mu$. \newline

Now, we prove \Cref{prop:sw2_diff}(b). First, we show that $v_\mu \in L^2(\mu,\R^d)$. This is the case because $\Id \in L^2(\mu,\R^d)$ as $\mu \in \cP_2(\R^d)$, and
\begin{align}
    \int_{\R^d}\left|\int_{\bS^{d-1}}\bar{\gamma}_\theta(\sca{x}{\theta})\theta d\theta\right|^2 d\theta d\mu(x) &\leq \int_{\R^d} \int_{\bS^{d-1}} \bar{\gamma}^2_\theta(\sca{x}{\theta}) d\theta d\mu(x) \\
    &\leq \int_{\R^d} \int_{\bS^{d-1}} \int_\R v^2 d\gamma_{\theta,\sca{x}{\theta}}(v) d\theta d\mu(x) \\
    &\leq \int_{\bS^{d-1}} \int_{\R^d} \int_\R v^2 d\gamma_{\theta,\sca{x}{\theta}}(v) d\mu(x) d\theta \\
    &\leq \int_{\bS^{d-1}} \int_{\R} \int_\R v^2 d\gamma_{\theta,u}(v) d\mu_\theta(u) d\theta \\
    &\leq \int_{\bS^{d-1}} \int_{\R^2} v^2 d\gamma_{\theta}(u,v) d\theta \\
    &\leq \int_{\bS^{d-1}} \int_\R v^2 d\rho_\theta(v) d\theta \\
    &\leq \int_{\bS^{d-1}} \int_{\R^d} \sca{y}{\theta}^2 d\rho(y) d\theta = \frac{1}{d} \int_{\R^d} \|y\|^2 d\rho(y) < \infty
\end{align}
where we used Jensen's inequality in the first lines, and $\rho \in \cP_2(\R^d)$. This proves that $v_\mu$ is in $L^2(\mu,\R^d)$. \newline

Fix now $\xi \in L^2(\mu,\R^d)$. Denote $S_\xi = \Id + \xi$ and $\mu^\xi = S_{\xi\#} \mu$, then for every $\theta \in \bS^{d-1}$, the plan $\hat{\gamma}_\theta^\xi := (S_\xi,\Id)_\#\hat{\gamma}_\theta$ is a transport plan between $\mu^\xi$ and $\rho$, such that $(P_\theta,P_\theta)_{\#}\hat{\gamma}_\theta^\xi \in \Pi(\mu^\xi_\theta,\rho_\theta)$ is not necessarily optimal. Then, we have
\begin{align}
    \W^2_2(\mu_\theta^\xi,\rho_\theta) &\leq \int_{(\R^d)^2} \sca{x - y}{\theta}^2 d\hat{\gamma}_\theta^\xi(x,y) \notag \\
    &\leq \int_{(\R^d)^2} \sca{S_\xi(x) - y}{\theta}^2 d\hat{\gamma}_\theta(x,y) \notag \\
    &\leq \int_{(\R^d)^2} \sca{x + \xi(x) - y}{\theta}^2 d\hat{\gamma}_\theta(x,y) \notag \\
    &\leq \int_{(\R^d)^2} \sca{x - y}{\theta}^2 d\hat{\gamma}_\theta(x,y) + 2\int_{(\R^d)^2} \sca{x-y}{\theta}\sca{\theta}{\xi(x)} d\hat{\gamma}_\theta(x,y) + \int_{(\R^d)^2} \sca{\xi(x)}{\theta}^2 d\hat{\gamma}_\theta(x,y) \notag \\
    &\leq \W_2^2(\mu_\theta,\rho_\theta) + 2\int_{(\R^d)^2} \sca{x-y}{\theta}\sca{\theta}{\xi(x)} d\hat{\gamma}_\theta(x,y) + \int_{\R^d} \sca{\xi(x)}{\theta}^2 d\mu(x) \label{eq:appendix_l334}
\end{align}
The second term in the right hand side of the last inequality is
\begin{align}
    \int_{(\R^d)^2} \sca{x-y}{\theta}\sca{\theta}{\xi(x)}d\hat{\gamma}_\theta(x,y) 
    &= \int (u-v) \int \sca{\theta}{\xi(x)} d\mu_{\theta,u}(x) d\gamma_\theta(u,v) \notag \\
    &= \int \int \int (u-v)\sca{\theta}{\xi(x)} d\mu_{\theta,u}(x) d\gamma_{\theta,u}(v) d\mu_\theta(u) \notag \\
    &= \int \int \int (u-v)\sca{\theta}{\xi(x)} d\gamma_{\theta,u}(v) d\mu_{\theta,u}(x) d\mu_\theta(u) \notag \\
    &= \int_{\R^d} \sca{\theta}{\xi(x)} \int (\sca{x}{\theta} - v)  d\gamma_{\theta,\sca{x}{\theta}}(v) d\mu(x) \notag \\
    &= \int_{\R^d} \sca{\theta}{\xi(x)} (\sca{x}{\theta} - \bar{\gamma}_\theta(\sca{x}{\theta})) d\mu(x) \label{eq:appendix_l343}
\end{align}
Therefore, integrating \eqref{eq:appendix_l334} using \eqref{eq:appendix_l343}, we get
\begin{equation} \label{eq:appendix_l346}
    \SW^2_2(\mu^\xi,\rho) \leq \SW^2_2(\mu,\rho) + 2\int_{\bS^{d-1}} \int_{\R^d} (\sca{x}{\theta} - \bar{\gamma}_\theta(\sca{x}{\theta})) \sca{\theta}{\xi(x)} d\mu(x) d\theta + \frac{1}{d} \|\xi\|^2_{L^2(\mu)}
\end{equation}
but since
\begin{align}
    \int_{\bS^{d-1}} \int_{\R^d} (\sca{x}{\theta} - \bar{\gamma}_\theta(\sca{x}{\theta})) \sca{\theta}{\xi(x)} d\mu(x) d\theta &= \int_{\R^d} \sca{\xi(x)}{\int_{\bS^{d-1}} (\sca{x}{\theta} - \bar{\gamma}_\theta(\sca{x}{\theta}))\theta d\theta} d\mu(x) \\
    &= \int_{\R^d} \sca{\xi(x)}{\frac{1}{d} x - \int_{\bS^{d-1}} \bar{\gamma}_\theta(\sca{x}{\theta})\theta d\theta} d\mu(x) \\
    &= \sca{\xi}{v_\mu}_{L^2(\mu)}
\end{align}
equation \eqref{eq:appendix_l346} rewrites as
\begin{equation} \label{eq:appendix_l356}
    \SW^2_2(\mu^\xi,\rho) \leq \SW^2_2(\mu,\rho) + 2\sca{v_\mu}{\xi}_{L^2(\mu)} + \frac 1d \|\xi\|^2_{L^2(\mu)}
\end{equation}
that is
\begin{equation} F_\mu(0) - 2\sca{v_\mu}{\xi}_{L^2(\mu)} \leq F_\mu(\xi) \end{equation}
and this finishes proving \Cref{prop:sw2_diff}(b). \newline

Finally, we prove \Cref{prop:sw2_diff}(c). Assume that $\mu, \rho$ are supported in some compact set $\Omega \subseteq \R^d$ and that $\mu$ is without atoms. Let $\xi \in L^2(\mu,\R)$ be fixed and define $\varphi(t) := \SW^2_2(\mu^t,\rho)$ where $\mu^t = (\Id+t\xi)_\#\mu$. Equation \eqref{eq:appendix_l356} applied to the vector field $t\xi$ gives
\begin{equation} \varphi(t) \leq \varphi(0) + 2t\sca{v_\mu}{\xi}_{L^2(\mu)} + \frac 1d t^2\|\xi\|^2_{L^2(\mu)} \end{equation}
Therefore, we immediately have the inequalities
\begin{equation} \limsup_{t \mapsto 0^+} \frac{1}{t} (\varphi(t) - \varphi(0)) \leq 2\sca{\xi}{v_\mu}_{L^2(\mu)} \end{equation}
\begin{equation} \liminf_{t \mapsto 0^-} \frac{1}{t} (\varphi(t) - \varphi(0)) \geq 2\sca{\xi}{v_\mu}_{L^2(\mu)} \end{equation}

Let's derive the other inequalities : let $(\varphi_\theta, \psi_\theta)$ be a pair of c-concave Kantorovich potentials for $(\mu_\theta,\rho_\theta)$ (for the cost $c(u,v) = (u-v)^2$). For every $t > 0$, we then have 
\begin{align}
    \frac{1}{t} (\Wass^2_2(\mu^t_\theta,\rho_\theta) - \Wass^2_2(\mu_\theta,\rho_\theta)) 
    &\geq \frac{1}{t} \int_{\R^2} \varphi_\theta(u) (d\mu^t_\theta(u) - d\mu_\theta(u)) \\
    &\geq \frac{1}{t} \left( \int_{\R^d} \varphi_\theta(\sca{x + t\xi(x)}{\theta}) - \varphi_\theta(\sca{x}{\theta}) d\mu(x) \right) 
\end{align}
By c-concavity, $\varphi_\theta$ is Lipschitz on $P_\theta(\Omega)$ (it has the same modulus of continuity as $c$ - note that we use here the fact that $\mu$ and $\rho$ have compact support). Thus, $t \mapsto \frac{1}{t}(\varphi_\theta(\sca{x + t\xi(x)}{\theta}) - \varphi_\theta(\sca{x}{\theta}))$ is bounded from below by $-L|\sca{\xi(x)}{\theta}|$, which is integrable as $\xi \in L^2(\mu,\R^d)$, where $L$ is the Lipschitz constant of $\varphi_\theta$, which depends only on $\mathrm{diam}(\Omega)$. Since in the $L^2$ case $c$-concavity means that $\frac{1}{2}|\cdot|^2 - \varphi_\theta$ is convex and lsc, $\varphi_\theta$ has at every point right and left derivatives $\varphi_\theta^+$ and $\varphi_\theta^-$ ; therefore, applying Fatou's lemma and integrating on $\bS^{d-1}$,
\begin{align}
    \liminf_{t \mapsto 0^+} \frac{1}{t} (\Wass^2_2(\mu^t_\theta,\rho_\theta) - \Wass^2_2(\mu_\theta,\rho_\theta)) 
    &\geq \int_{\bS^{d-1}} \int_{\R^d} \varphi^{\sgn(\sca{\xi(x)}{\theta})}_\theta(\sca{x}{\theta})\sca{\xi(x)}{\theta} d\mu(x) d\theta 
\end{align}
However, since $\mu$ is without atoms, by \Cref{prop:atomless_is_wap}, for almost every $\theta \in\bS^{d-1}$, $\mu_\theta$ is without atoms, and for %\footnote{\textcolor{red}{c'est pas $\mu_\theta$ presque tout u? à noter: la différentiabilité $\mu_\theta$-presque partout de $\phi_\theta$ est vraie dès que $\mu_\theta$ n'a pas d'atome: dans ce cas, on sait que le plan de transport est induit par une application, cf Chapitre 2 de Filippo. On pourrait peut-être remplacer l'hypothèses "with absolutely continuous projections" par "with atomless projections"}} 
$\mu_\theta$-almost every $u$, $\varphi_\theta$ is differentiable at $u$ with $\varphi'_\theta(u) = \varphi_\theta^+(u) = \varphi_\theta^-(u)$\footnote{Since $\frac{x^2}{2} - \varphi_\theta$ is convex, it is differentiable almost everywhere, with a nondecreasing differential. Furthermore its set of nondifferentiability is at most countable, so it has zero $\mu_\theta$-measure as $\mu_\theta$ is without atoms.}. Furthermore, we have $\varphi'_\theta(u) = 2(u - T^{-1}_\theta(u))$ (the factor 2 comes from the fact that we used the cost $(u-v)^2$ instead of $\frac{1}{2}(u-v)^2$) and $\bar{\gamma}_\theta = T^{-1}_\theta$ (as $\gamma_\theta = (\Id,T^{-1}_\theta)_\#\mu_\theta$), and therefore
\begin{align}
    \int_{\R^d} \varphi'_\theta(\sca{x}{\theta})\sca{\xi(x)}{\theta} d\mu(x)) &= 2\int_{\R^d} (\sca{x}{\theta} - T^{-1}_\theta(\sca{x}{\theta})) \sca{\xi(x)}{\theta} d\mu(x) \\
    &= 2\int_{\R^d} (\sca{x}{\theta} - \bar{\gamma}_\theta(\sca{x}{\theta})) \sca{\xi(x)}{\theta} d\mu(x)
\end{align}
so
\begin{equation} \liminf_{t \mapsto 0^+} \frac{1}{t} (\Wass^2_2(\mu^t_\theta,\rho_\theta) - \Wass^2_2(\mu_\theta,\rho_\theta)) \geq 2\int_{\bS^{d-1}} \int_{\R^d} (\sca{x}{\theta} - \bar{\gamma}_\theta(\sca{x}{\theta})) \sca{\xi(x)}{\theta} d\mu(x) d\theta \end{equation}
Integrating this latter inequality, we obtain 
\begin{equation} \liminf_{t \mapsto 0^+} \frac{1}{t} (\varphi(t) - \varphi(0)) \geq 2\sca{\xi}{v_\mu}_{L^2(\mu)} \end{equation}
Using a similar argument, we show that
\begin{equation} \limsup_{t \mapsto 0^-} \frac{1}{t} (\varphi(t) - \varphi(0)) \leq 2\sca{\xi}{v_\mu}_{L^2(\mu)} \end{equation}
This proves that $\varphi$ is differentiable at $t = 0$, with
\begin{equation} \varphi'(0) = 2\sca{\mu}{\xi}_{L^2(\mu)}\end{equation}
This finishes the proof. \qed

\subsection{Proof of \texorpdfstring{\Cref{cor:sw2_crit_point_char}}{}} \label{sec:proof_sw2_crit_point_char}

First, if $\mu$ is a Lagrangian critical point for $\SW^2_2(\cdot,\rho)$, then for every $\xi \in L^2(\mu,\R^d)$, it satisfies \eqref{eq:crit_point_requirement} :
\begin{equation}
    \left.\frac{d}{dt}  \SW_2^2((\Id + t\xi)_{\#} \mu,\rho)\right|_{t=0^+} = 0
\end{equation}
But applying \Cref{prop:sw2_diff}(b) to the vector field $t\xi$, we have for every $t > 0$
\begin{equation}
    \SW_2^2((\Id + t\xi)_{\#} \mu,\rho) \leq \SW_2^2(\mu,\rho) + 2t\sca{v_\mu}{\xi}_{L^2(\mu)} + \frac{1}{d}t^2\|\xi\|^2_{L^2(\mu)}
\end{equation}
Combined with the previous equation, this yields
\begin{equation}
    0 = \left.\frac{d}{dt}  \SW_2^2((\Id + t\xi)_{\#} \mu,\rho)\right|_{t=0^+} \leq 2\sca{v_\mu}{\xi}_{L^2(\mu)} 
\end{equation}
Therefore, we have $\sca{v_\mu}{\xi}_{L^2(\mu)} \geq 0$ for every $\xi \in L^2(\mu,\R^d)$, and this implies $v_\mu = 0$ in $L^2(\mu,\R^d)$. Thus, $\mu$ is a barycentric Lagrangian critical point. \newline

Now, assume that $\mu,\rho$ are compactly supported, and that $\mu$ is without atoms. Then, by proposition \ref{prop:sw2_diff}(c), for every $\xi \in L^2(\mu,\R^d)$, we have
\begin{equation} \left.\frac{d}{dt}  \SW_2^2((\Id + t\xi)_{\#} \mu,\rho)\right|_{t=0^+} = 2\sca{v_\mu}{\xi}_{L^2(\mu)} \end{equation}
Therefore $\mu$ satisfies \Cref{def:lag-crit} if and only if $\sca{v_\mu}{\xi}_{L^2(\mu)} = 0$ for every $\xi \in L^2(\mu,\R^d)$, which is equivalent to $v_\mu = 0$ $\mu$-a.e.. Thus $\mu$ is Lagrangian critical if and only if it is barycentric Lagrangian critical. \qed

\subsection{Projections of measures without atoms}

In this subsection, we prove an useful lemma on measures without atoms. If $\mu$ is a measure on $\R^d$, we say that $\mu$ is \textit{with atomless projections}, which we abbreviate WAP, if its projection $\mu_\theta$ is without atoms for almost every $\theta \in \bS^{d-1}$. It is straightforward that if $\mu$ is WAP, then it is without atoms. It turns out that for finite measures, the converse is also true :

\begin{proposition} \label{prop:atomless_is_wap}
    Let $\mu$ be a finite measure on $\R^d$, then $\mu$ is atomless if and only if it is WAP.
\end{proposition}

\begin{proof}
    We have already seen that if $\mu$ has atoms, then it can't be WAP. \newline
    Now, for every $k \in \{0,\ldots,d-1\}$, let $AG_k(\R^d)$ be the $k$-th affine Grassmannian of $\R^d$, that is the set of affine subspaces of $\R^d$ of dimension $k$, and for every $k \in \{0,\ldots,d-1\}$ and measure $\mu$ on $\R^d$, we note
    \begin{equation}
        A_{k,\mu} = \{V \in AG_k(\R^d) \setcond \mu(V) > 0 \}
    \end{equation}
    (in particular, $A_{0,\mu}$ is the set of atoms of $\mu$). Let $\mu$ be a fixed finite measure on $\R^d$ without atoms. We construct by induction a sequence of finite measures $\mu_0 = \mu, \mu_1, \ldots, \mu_{d-1}$ such that for every $k$, $AG_{k,\mu_k} = \emptyset$, and if $k > 0$, then $\mu_k \hbox{ is WAP} \Rightarrow \mu_{k-1} \hbox{ is WAP}$. Our first term $\mu_0 = \mu$ satisfies by assumption $A_{0,\mu_0} = \emptyset$. Now assume that we have built $\mu_0,\ldots,\mu_{k-1}$. \newline
    If $V_1,\ldots,V_l \in A_{k,\mu_{k-1}}$ are distinct, then
    \begin{equation} \mu_{k-1}(V_1 \cup \ldots \cup V_l) = \sum_{i=1}^l \mu_{k-1}(V_i) \end{equation}
    as the intersection of any subset of these has null $\mu_{k-1}$-measure since $A_{k-1,\mu_{k-1}} = \emptyset$. In particular, the family $(\mu_{k-1}(V))_{V \in A_{k,\mu_{k-1}}}$ is summable, with sum $\leq 1$, and $A_{k,\mu_{k-1}}$ is at most countable. Define
    \begin{equation} \mu_k := \mu_{k-1} - \mu_{k-1| \bigcup A_{k,\mu_{k-1}}} \end{equation}
    Then, by construction, $A_{k,\mu_k} = \emptyset$. Now, let $\theta \in \bS^{d-1}$ be such that $(\mu_{k-1})_\theta$ has an atom : there exists $u \in \R$ such that $(\mu_{k-1})_\theta(\{u\}) > 0$. Assume that $(\mu_k)_\theta(\{u\}) = 0$, then this implies that there exists $V \in A_{k,\mu_{k-1}}$ such that $(\mu_{k-1|V})_\theta(\{u\}) > 0$, that is $\mu_{k-1}(V \cap P_\theta^{-1}(u)) > 0$. Since $A_{k-1,\mu_{k-1}} = \emptyset$, this implies that $V \cap P_\theta^{-1}(u)$ is an affine subspace of dimension $k$, that is $V \subseteq P_\theta^{-1}(u)$, and $\theta \in V^\perp$. This argument thus proves
    \begin{equation}
         \{\theta \in \bS^{d-1} \setcond (\mu_{k-1})_\theta \hbox{ has an atom} \} \subseteq \{\theta \in \bS^{d-1} \setcond (\mu_k)_\theta \hbox{ has an atom} \} \cup \{ \theta \in \bS^{d-1} \setcond \exists V \in A_{k,\mu_{k-1}}, \theta \in V^\perp \}
    \end{equation}
    Since the second term in the RHS is of null measure (as an at most countable union of sets of null measures), this inclusion implies that if $\mu_k$ is WAP, then $\mu_{k-1}$ is also WAP. This finishes our induction. \newline
    Now, we have built our sequence $\mu_0,\ldots,\mu_{d-1}$. But $A_{d-1,\mu_{d-1}} = \emptyset$ implies that $\mu_{d-1}$ is WAP (and that in fact $(\mu_{d-1})_\theta$ is without atoms for \textit{every} $\theta$). Thus, all the measures of the sequence are WAP, and in particular $\mu_0 = \mu$ is WAP.
\end{proof}

\subsection{Proof of \texorpdfstring{\Cref{th:weak_convergence_crit_points}}{}} \label{sec:th_weak_convergence_crit_points}

First, up to extending $\Omega$, we may assume that the $\mu_n, \mu$ are supported in $\Omega$. Indeed, if $R > 0$ is such that $\Omega \subseteq B(0,R)$, then if $x \in \spt(\mu_n)$ is such that $v_{\mu_n}(x) = 0$, we have
\begin{equation}
    0 = v_{\mu_n}(x) = \frac 1d x - \int_{\bS^{d-1}} \bar{\gamma}_{n,\theta}(\sca{x}{\theta}) \theta d\theta
\end{equation}
where for every $\theta \in \bS^{d-1}$, $\gamma_{n,\theta}$ is the optimal transport plan between $\mu_{n,\theta}$ and $\rho_\theta$, so that
\begin{equation}
    |x| \leq d \left|\int_{\bS^{d-1}} \bar{\gamma}_\theta(\sca{x}{\theta}) \theta d\theta\right| \leq d \int_{\bS^{d-1}} |\bar{\gamma}_\theta(\sca{x}{\theta})| d\theta \leq dR
\end{equation}
This $v_{\mu_n} = 0$ $\mu_n$-almost everywhere, this implies that $\mu_n$ is supported in $\Omega' = B(0,dR)$, and so is $\mu$. \newline

Consider $\xi : \Omega \mapsto \R^d$ a continuous vector field. For every $n$ and $t \in \R$, applying \Cref{prop:sw2_diff}(b) to $t\xi$, we have
\begin{align}
    \SW^2_2((\Id+t\xi)_\#\mu_n,\rho) &\leq \SW^2_2(\mu_n, \rho) + 2t\sca{v_{\mu_n}}{\xi}_{L^2(\mu_n)} + \frac 1d t^2 \|\xi\|^2_{L^2(\mu_n)} \\
    &\leq \SW^2_2(\mu_n,\rho) + \frac 1d t^2 \|\xi\|^2_{L^2(\mu_n)}
\end{align}
since $v_{\mu_n} = 0$. Letting $n \rightarrow \infty$, we thus find
\begin{equation}
    \SW_2^2((\Id+t\xi)_\#\mu, \rho) \leq \SW^2_2(\mu,\rho) + \frac 1d t^2 \|\xi\|^2_{L^2(\mu)}
\end{equation}
(Recall that $\SW_2 \leq \W_2$ and that on compact spaces, weak convergence coincide with convergence in the $\W_2$ topology).for the $\SW$ terms to converge, we actually need convergence in the $\W_2$ topology. But since $\mu$ is without atoms, by \Cref{prop:sw2_diff}(c), $t \mapsto \SW^2_2((\Id+t\xi)_\#\mu,\rho)$ is differentiable at 0, and this inequality implies
\begin{equation} \label{eq:appendix_l455}
    \frac{d}{dt}_{|t=0} \SW^2_2((\Id+t\xi)_\#\mu, \rho) = 0
\end{equation}
But again \Cref{prop:sw2_diff}(b) implies that for every $t \in \R$,
\begin{equation}
    \SW^2_2((\Id+t\xi)_\#\mu,\rho) \leq \SW^2_2(\mu, \rho) + 2t\sca{v_{\mu}}{\xi}_{L^2(\mu)} + \frac 1d t^2 \|\xi\|^2_{L^2(\mu)}
\end{equation}
so we also have
\begin{equation} \label{eq:appendix_l463}
    \frac{d}{dt}_{|t=0} \SW^2_2((\Id+t\xi)_\#\mu, \rho) = 2\sca{v_\mu}{\xi}_{L^2(\mu)}
\end{equation}
Thus, by \eqref{eq:appendix_l455} and \eqref{eq:appendix_l463}, we have $\sca{v_\mu}{\xi}_{L^2(\mu)} = 0$ for every continuous vector field $\xi : \Omega \mapsto \R^d$. In particular, this implies $v_\mu = 0$ in $L^2(\mu,\R^d)$, and $\mu$ is indeed a barycentric Lagrangian critical point for $\SW^2_2(\cdot,\rho)$. This finishes the proof. \qed

\subsection{Proof of \texorpdfstring{\Cref{prop:ex_symmetric_crit_points}}{}}  \label{sec:prop_ex_symmetric_crit_points}

First, let $\mu = \frac{\pi}{8} \cH_{|[-\frac{4}{\pi},\frac{4}{\pi}]}$ and let $\rho$ be the sliced-uniform measure, of which we recall the definition below.

\begin{definition} \label{def:sliced_uniform}   
    The probability measure $\rho \in \cP(\R^2)$ supported on the unit open ball $B(0,1)$ of the plane with the density $f(x) = \frac{1}{2\pi} \frac{1}{\sqrt{1 - |x|^2}}$ is such that in every direction $\theta \in \Sph^{d-1}$, its projection $P_{\theta\#}\rho$ is the normalized restriction of the Lebesgue measure to $[-1;1]$. We'll call $\rho$ the (two-dimensional) \textit{sliced-uniform measure} on $[-1;1]$.
\end{definition}

As explained in \Cref{def:sliced_uniform}, each projection $P_{\theta\#}\rho$ is the normalized restriction of the Lebesgue measure to $[-1,1]$. Indeed, the density of $P_{e1\#}\rho$ at $x \in [-1;1]$ is given by
\begin{equation}
     P_{e1\#}\rho(x) = \frac{1}{2\pi} \int_{-\sqrt{1-x^2}}^{\sqrt{1-x^2}} \frac{1}{\sqrt{1 - x^2 - y^2}} dy
    = \frac{1}{2\pi} \int_{-1}^1 \frac{1}{\sqrt{1-t^2}} dt = \frac{1}{2\pi} \int_{-\frac{\pi}{2}}^{\frac{\pi}{2}} d\theta = \frac{1}{2}
\end{equation}
with the changes of variables $y = \sqrt{1-x^2}$, $t = \sin \theta$. By symmetry, the same result holds for all $\theta$. 

Then, identifying $\bS^1 \simeq (-\pi,\pi] \simeq [0,2\pi)$, we have for every direction $\theta$, $\rho_\theta = \frac{1}{2} \cL^1_{[-1,1]}$, and when $\theta \neq \pm \frac{\pi}{2}$, we have $\mu_\theta = \frac{\pi}{8|c_\theta|} \cL^1_{[-\frac{4|c_\theta|}{\pi}, \frac{4|c_\theta|}{\pi}]}$, with the notation $c_\theta = \cos(\theta)$ and $s_\theta = \sin(\theta)$ (in the vertical direction, $\mu_{\pm\frac{\pi}{2}} = \delta_0$). The optimal transport map from $\rho_\theta$ to $\mu_\theta$ is then $T_\theta(x) = \frac{4}{\pi}|c_\theta|x$. If $x = (x_1,0) = x_1 e1 \in \spt(\mu) = [-1,1] \times \{0\}$, where $(e_1,e_2)$ is the canonical basis of $\R^2$, we have (noting $\vec{\theta} = (c_\theta, s_\theta)^T$),

\begin{align}
     d\int_{-\pi}^{\pi} T^{-1}_\theta(\sca{x}{\vec{\theta}}) \vec{\theta} \frac{d\theta}{2\pi}
     &= 2\int_{-\pi}^{\pi} T^{-1}_\theta(x_1 c_\theta) \left( \begin{array}{c} c_\theta \\ s_\theta\end{array} \right) \frac{d\theta}{2\pi} \\
     &= \frac{\pi}{2} x_1 \int_{-\pi}^{\pi} \frac{c_\theta}{|c_\theta|} \left( \begin{array}{c} c_\theta \\ s_\theta\end{array} \right) \frac{d\theta}{2\pi} \\
     &= \frac{1}{4} x_1 \int_{-\pi}^{\pi} |c_\theta| d\theta e_1
\end{align}
(We see that the integral on the second coordinate cancels by antisymmetry). Since 
\begin{equation}
    \frac{1}{4} \int_{-\pi}^{\pi} |c_\theta| d\theta = \frac{1}{2} \int_0^\pi |c_\theta| d\theta = \int_0^{\pi/2} c_\theta d\theta = 1
\end{equation}
we thus have
\begin{equation} x_1 e_1 = d\int_{-\pi}^{\pi} T^{-1}_\theta(\sca{x}{\vec{\theta}}) \vec{\theta} \frac{d\theta}{2\pi} \end{equation}
that is $v_\mu(x) = 0$. This proves that $\mu$ satisfies \Cref{def:strong-lag-crit} and is therefore a barycentric Lagrangian critical point for $\SW^2_2(\cdot,\rho)$. \\

Now, we consider the case where $d > 1$, $\rho = \cN(0,I_d)$ and $\mu = (Id,0_{d-1})_\# \cN(0,\alpha_d^2)$ with $\alpha_d = d\int_{\bS^{d-1}} |\sca{\theta}{e_1}|^{3/2} d\theta$. For every $\theta \in \bS^{d-1}$, we have $\rho_\theta = \cN(0,1)$. Noting $(e_1,...,e_d)$ the canonical basis of $\R^d$, when $\sca{\theta}{e_1} \neq 0$, we have $\mu_\theta = P_{\theta\#}\mu = \cN(0,(\alpha_d|\sca{\theta}{e_1}|)^2)$, and when $\sca{\theta}{e_1} = 0$, $\mu_\theta = \delta_0$. Therefore, the optimal transport map from $\rho_\theta$ to $\mu_\theta$ is given by $T_\theta : x \mapsto \alpha_d|\sca{\theta}{e_1}|x$. Let $x = x_1 e_1 \in \spt \mu = \R \times \{0\}^{d-1}$, then we have
\begin{align}
    d \int_{\bS^{d-1}} T_\theta^{-1}(\sca{x}{\theta}) \theta d\theta 
        &= d \int_{\bS^{d-1}} T_\theta^{-1}(x_1\sca{\theta}{e_1}) \theta d\theta \\
        &= d x_1 \int_{\bS^{d-1}} \frac{\sca{\theta}{e_1}}{\alpha_d|\sca{\theta}{e_1}|} \theta d\theta \\
\end{align}
By symmetry we see that the components of this integral along $e_2,...,e_d$ are zero, and thus
\begin{align}
    d \int_{\bS^{d-1}} T_\theta^{-1}(\sca{x}{\theta}) \theta d\theta 
        &= d x_1 \int_{\bS^{d-1}} \frac{\sca{\theta}{e_1}^2}{\alpha_d|\sca{\theta}{e_1}|} d\theta e_1 \\
        &= x_1 \frac{1}{\alpha_d} d\int_{\bS^{d-1}}|\sca{\theta}{e_1}|^{3/2} d\theta e_1 \\
        &= x_1 e_1 \hbox{ by definition of } \alpha_d
\end{align}
This proves that $\mu$ satisfies \Cref{def:strong-lag-crit} and is therefore a barycentric Lagrangian critical point for $\SW^2_2(\cdot,\rho)$. \qed

\subsection{Proof of \texorpdfstring{\Cref{prop:examples_unstable}}{}} \label{sec:proof_examples_unstable}

\begin{proof}[Sketch of proof]
    Up to translating, rotating, and rescaling, we may decompose $\mu$ as $\mu = (1-\lambda)\mu_0 + \lambda \mu_1$ where $\mu_1 = \frac{1}{2}\cH^1_{|[-1,1]\times\{0\}}$. For every $\theta \in \bS^1$, let $\hat{\gamma}_\theta \in \Pi(\mu,\rho)$ be such that $(P_\theta,P_\theta)_\#\hat{\gamma}_\theta$ is optimal between $\mu_\theta$ and $\rho_\theta$. Then we can decompose $\hat{\gamma}_\theta$ and $\rho$ into 
    \begin{equation}\hat{\gamma}_\theta = (1-\lambda)\hat{\gamma}_{\theta,0} + \lambda \hat{\gamma}_{\theta,1}\end{equation} 
    and 
    \begin{equation}\rho = (1-\lambda)\rho_{\theta,0} + \lambda \rho_{\theta,1},\end{equation}
    where $\hat{\gamma}_{\theta,i}$ couples $\mu_i$ and $\rho_{\theta,i} \in \cP_2(\R^d)$. Denoting $\rho_{\theta,i,\theta}$ the projection of $\rho_{\theta,i}$ on  $\theta$ for $i=0,1$, these decompositions verify 
    \begin{equation}\SW^2_2(\mu^t, \rho) \leq (1-\lambda) \int_{\bS^1} \W^2_2(\mu_{0,\theta}^t, \rho_{\theta,0,\theta}) d\theta + \lambda \int_{\bS^1} \W^2_2(\mu_{1,\theta}^t, \rho_{\theta,1,\theta}) d\theta,\end{equation}
    with equality at $t = 0$. We bound separately the two terms of the right hand side. The first term can be easily bounded by 
    \begin{equation}(1-\lambda) \int_{\bS^1} \W^2_2(\mu_{0,\theta}, \rho_{\theta,0,\theta}) d\theta + O(t^2).\end{equation}
    All that is left is then to show that the second term can be bounded for any $C > 0$, on a neighborhood of $t = 0$, by 
    \begin{equation}\int_{\bS^{d-1}} \W^2_2(\mu_{1,\theta}, \rho_{\theta,1,\theta}) d\theta - Ct^2.\end{equation} 
    We obtain such a bound by writing $\W^2_2(\mu^t_{1,\theta}, \rho_{\theta,1,\theta})=\|F^{-1}_{\mu^t_{1,\theta}} - F^{-1}_{\rho_{\theta,1,\theta}}\|^2_{L^2([0,1])}$, and by making use of an explicit expression of $F^{-1}_{\mu^t_{1,\theta}}$ and of its symmetry to compute a Taylor expansion of 
    \begin{equation}\int_{\bS^{d-1}} \W^2_2(\mu^t_{1,\theta}, \rho_{\theta,1,\theta}) d\theta\end{equation} 
    and bound it from above in the desired way. 
\end{proof}

    Up to translating, rotating and rescaling, we may assume that $S = [-1,1] \times \{0,0\}$ and $\vec{n} = e_2$. Since $a \cH^1_{|S} \leq \mu$, we write
    \begin{equation} \mu = (1-\lambda) \mu_0 + \lambda \mu_1 \end{equation}
    where $\lambda \in [0,1]$ and $\mu_0,\mu_1$ are probability measures such that $\mu_1 = \frac{1}{2} \cH^1_{|[-1,1] \times \{0\}}$ and $\lambda = 2a$. For every $\theta \in \bS^1$, let $\hat{\gamma}_\theta \in \Pi(\mu,\rho)$ be such that $(P_\theta,P_\theta)_\#\hat{\gamma}_\theta$ is an optimal transport plan between $\mu_\theta$ and $\rho_\theta$. We can disintegrate $\hat{\gamma}_\theta$ with respect to $\mu$, thus writing $d\hat{\gamma}_\theta(x,y) = d\hat{\gamma}_\theta(y|x) d\mu(x)$, and we define two probability measures $\rho_{\theta,0}, \rho_{\theta,1} \in \cP_2(\R^2)$ by
    
    \begin{equation} \int \varphi(y) \rho_{\theta,i}(y) := \int \int \varphi(y) d\hat{\gamma}_\theta(y|x) d\mu_i(x), \;\; i \in \{0,1\}, \varphi \in C_b(\R^2) \end{equation}
    
    and two transport plans $\hat{\gamma}_{\theta,i} \in \Pi(\mu_i, \rho_{\theta,i})$ by $d\hat{\gamma}_{\theta,i}(x,y) = d\hat{\gamma}_\theta(y|x) d\mu_i(x)$. By \citep[Theorem 4.6]{villani2008OldNew}, the $(P_\theta,P_\theta)_\#\hat{\gamma}_{\theta,i}$ are actually optimal between their margins. In fact, we have
    \begin{equation} \W^2_2(\mu^t_\theta, \rho_\theta) \leq (1-\lambda) \W^2_2(\mu^t_{0,\theta},\rho_{\theta,0,\theta}) + \lambda \W^2_2(\mu^t_{1,\theta}, \rho_{\theta,1,\theta}) \end{equation}

    where $\nu^t := \frac{1}{2} (\tau_{te_2\#}\nu + \tau_{-te_2\#}\nu)$ for any measure $\nu$, with equality at $t = 0$. We will establish bounds separately on $\W^2_2(\mu^t_{0,\theta},\rho_{\theta,0,\theta})$ and $\W^2_2(\mu^t_{1,\theta},\rho_{\theta,0,\theta})$. First, we notice that 

    \begin{equation}
        \label{eq:proof_eq_l138}
        \int_{\bS^1} \W^2_2(\mu^t_{0,\theta},\rho_{\theta,0,\theta})d\theta \leq \int_{\bS^1} \W^2_2(\mu_{0,\theta},\rho_{\theta,0,\theta})d\theta + \frac{1}{d} t^2
    \end{equation} 

    Indeed, if we consider the transport plan $\hat{\gamma}_{\theta,0}^t \in \Pi(\mu_0^t, \rho_{\theta,0})$ defined by
    \begin{equation} \hat{\gamma}_{\theta,0}^t := \frac{1}{2} ((\tau_{te_2},Id)_\#\hat{\gamma}_{\theta,0} + (\tau_{-te_2},Id)_\#\hat{\gamma}_{\theta,0}) \end{equation}
    we have 

    \begin{align}
        \W^2_2(\mu^t_{0,\theta},\rho_{\theta,0,\theta})d\theta 
        &\leq \int \sca{x-y}{\theta}^2 d\hat{\gamma}_{\theta,0}^t(x,y) \\
        &\leq \int \frac{1}{2}(\sca{x+te_2-y}{\theta}^2 + \sca{x-te_2-y}{\theta}^2) d\hat{\gamma}_{\theta,0}(x,y) \\
        &\leq \int \sca{x-y}{\theta}^2 + t^2\sca{e_2}{\theta}^2) d\hat{\gamma}_{\theta,0}(x,y) \\
        &\leq \W^2_2(\mu_{0,\theta},\rho_{\theta,0,\theta})d\theta + t^2\sca{e_2}{\theta}^2
    \end{align}
    and by integrating on the sphere we get \eqref{eq:proof_eq_l138}.

    Now, all we need to prove is that for every $C > 0$, there exists a neighborhood of $t = 0$ in which

    \begin{equation} \int_{\bS^1} \W^2_2(\mu^t_{1,\theta},\rho_{\theta,1,\theta})d\theta \leq \int_{\bS^1} \W^2_2(\mu_{1,\theta},\rho_{\theta,1,\theta})d\theta - C t^2 \end{equation}
    By summing it with \eqref{eq:proof_eq_l138}, we obtain the proposition's statement. To derive this bound, we look at the quantile functions : for every $\theta \in \bS^1$, we have

    \begin{align}
        \W^2_2(\mu^t_{1,\theta},\rho_{\theta,1,\theta})d\theta 
        &= \|F^{-1}_{\mu^t_{1,\theta}} - F^{-1}_{\rho_{\theta,1,\theta}}\|^2_{L^2([0,1])} \\
        &= \|F^{-1}_{\mu^t_{1,\theta}} - F^{-1}_{\mu_{1,\theta}} + F^{-1}_{\mu_{1,\theta}} - F^{-1}_{\rho_{\theta,1,\theta}}\|^2_{L^2([0,1])} \\
        &= \|F^{-1}_{\mu^t_{1,\theta}} - F^{-1}_{\mu_{1,\theta}}\|^2_{L^2([0,1])} + 2\sca{F^{-1}_{\mu^t_{1,\theta}} - F^{-1}_{\mu_{1,\theta}}}{F^{-1}_{\mu_{1,\theta}} - F^{-1}_{\rho_{\theta,1,\theta}}}_{L^2([0,1])} \\
        &\quad + \| F^{-1}_{\mu_{1,\theta}} - F^{-1}_{\rho_{\theta,1,\theta}}\|^2_{L^2([0,1])} \\
        &= W^2_2(\mu^t_{1,\theta},\mu_{1,\theta}) + W^2_2(\mu_{1,\theta},\rho_{\theta,1,\theta}) + 2\sca{F^{-1}_{\mu^t_{1,\theta}} - F^{-1}_{\mu_{1,\theta}}}{F^{-1}_{\mu_{1,\theta}} - F^{-1}_{\rho_{\theta,1,\theta}}}_{L^2([0,1])}
    \end{align}
    We easily see that $W^2_2(\mu^t_{1,\theta},\mu_{1,\theta}) \leq W_2^2(\mu^t_1,\mu_1) \leq t^2$. Therefore, we simply need to show that for every $C > 0$, there exists a neighborhood of $t = 0$ such that 
    \begin{equation}
        \label{eq:proof_l169}
        \int_{\bS^1}\sca{F^{-1}_{\mu^t_{1,\theta}} - F^{-1}_{\mu_{1,\theta}}}{F^{-1}_{\mu_{1,\theta}} - F^{-1}_{\rho_{\theta,1,\theta}}}_{L^2([0,1])}d\theta \leq -Ct^2
    \end{equation}

    Since $\mu_1 = \frac{1}{2} \cH^1_{|[-1,1]\times\{0\}}$, we have, for every $t$, 
    \begin{equation} \mu_1^t = \frac{1}{4} (\cH^1_{|[-1,1]\times\{-t\}} + \cH^1_{|[-1,1]\times\{t\}})\end{equation}
    
    Now let $\theta \in \bS^1 \setminus \{\pm \frac{\pi}{2}\}$ (we make again the identification $\bS^1 \simeq \R/2\pi\mathbb{Z}$). The projections of $\mu^t_1$ and $\mu_1$ on $\R\theta$ are 
    
    \begin{equation} \mu^t_{1,\theta} = \frac{1}{4|c_\theta|} (\lambda_{A^-_{\theta,t}} + \lambda_{A^+_{\theta,t}}), \quad A^\pm_{\theta,t} = [\pm |ts_\theta| - |c_\theta|, \pm |ts_\theta| + |c_\theta|] \end{equation}
    and 
    \begin{equation} \mu_{1,\theta} = \frac{1}{2c_\theta} \lambda_{A_\theta}, \quad A_\theta = [-|c_\theta|,|c_\theta|]\end{equation}
    Therefore the quantile function of $\mu_{1,\theta}$ is simply
    \begin{equation}
        \label{eq:quantile_segment_theta}
        F^{-1}_{\mu_{1,\theta}}(x) = -|c_\theta| + 2|c_\theta|x, \quad x \in [0,1]
    \end{equation}
    In the following, since for any $\theta$ and any measures $\nu_1,\nu_2 \in \cP(\R^2)$, $W^2_2(\nu_{1,\theta+\pi},\nu_{2,\theta+\pi}) = W_2^2(\nu_{1,\theta},\nu_{2,\theta})$, we can restrict ourselves to $\theta \in (-\frac{\pi}{2},\frac{\pi}{2})$. To compute the quantile function of $\mu^t_{1,\theta}$, we then need to consider two cases.
    \begin{itemize}
        \item First, when $|\theta| \in [0,\arctan(1/|t|)]$,  the two segments $A^\pm_{\theta,t}$ overlap. Their union can then be decomposed into three segments where the density of $\mu_{1,\theta}^t$ is constant :
        \begin{align} 
        B_- \cup B_0 \cup B_+ &= [-|c_\theta| - |t s_\theta|, -|c_\theta| + |t s_\theta|] \\
        &\cup [-|c_\theta| + |t s_\theta|, |c_\theta| - |t s_\theta|] \\
        &\cup [|c_\theta| - |t s_\theta|, |c_\theta| + |t s_\theta|]
        \end{align}
        On $B_\pm$, the density is $\frac{1}{4|c_\theta|}$ while on $B_0$, it is $\frac{1}{2|c_\theta|}$. One can check that the quantile function of $\mu^t_{1,\theta}$ and $\mu_\theta$ is then (using the shorthand notation $t_\theta = \tan(\theta)$)
        \begin{equation} F^{-1}_{\mu^t_{1,\theta}}(x) = 
        \begin{cases} 
        -|c_\theta| - |t s_\theta| + 4 |c_\theta| x 
        & \hbox{ for } x\in \left[0, \frac{|t|}{2}|t_\theta|\right]\\
        -|c_\theta| + |t s_\theta| + 2 |c_\theta|\left(x -  \frac{|t|}{2}|t_\theta|\right)
        & \hbox{ for } x\in \left[\frac{|t|}{2}|t_\theta|, 1-\frac{|t|}{2}|t_\theta|\right]\\
        |c_\theta| - |t s_\theta| + 4|c_\theta|\left(x - 1 + \frac{|t|}{2}|t_\theta|\right)
        & \hbox{ for } x\in \left[1-\frac{|t|}{2}|t_\theta|, 1\right]\\
        \end{cases} \end{equation}
        \item Second, when $\theta \in (\arctan(1/|t|), \pi/2)$, the two segments $A^\pm_{\theta,t}$ do not overlap, in which case the quantile function of $\mu^t_{1,\theta}$ is 
        \begin{equation} F^{-1}_{\mu^t_{1,\theta}}(x) = 
        \begin{cases} 
        -|c_\theta| - |t s_\theta| + 4 |c_\theta| x 
        & \hbox{ for } x\in \left[0, \frac{1}{2}\right]\\
        -|c_\theta| + |t s_\theta| + 4|c_\theta|\left(x - \frac{1}{2}\right)
        & \hbox{ for } x\in \left(\frac{1}{2},1\right]\\
        \end{cases} \end{equation}
    \end{itemize}
    Denoting $m_{t,\theta} = \frac{1}{2} \min(1, |tt_\theta|)$, we can actually condense the two previous expressions of $F^{-1}_{\mu^t_{1,\theta}}$ into a single one valid for every $\theta \in (-\pi/2,\pi/2)$ : 
    \begin{equation}
        \label{eq:quantile_segment_t_theta}
        F^{-1}_{\mu^t_{1,\theta}}(x) = 
        \begin{cases} 
        -|c_\theta| - |t s_\theta| + 4 |c_\theta| x 
        & \hbox{ for } x\in [0, m_{t,\theta}]\\
        -|c_\theta| + 2|c_\theta|x
        & \hbox{ for } x\in (m_{t,\theta}, 1-m_{t,\theta}] \\
        -|c_\theta| + |t s_\theta| + 4|c_\theta|\left(x - \frac{1}{2}\right)
        & \hbox{ for } x\in (1-m_{t,\theta}, 1]\\
        \end{cases}
    \end{equation}
    We see in particular that
    \begin{itemize}
        \item $F^{-1}_{\mu^t_{1,\theta}}(x) = F^{-1}_{\mu_{1,\theta}}(x)$ for every $x \in (m_{t,\theta}, 1-m_{t,\theta}]$
        \item For every $t \in \R$ and $x \in [0,1]$, $F^{-1}_{\mu^t_{1,\theta}}(1-x) = 1 - F^{-1}_{\mu^t_{1,\theta}}(x)$ (in fact, we only needed to use the symmetry of $\mu^t_{1,\theta}$ to see this)
    \end{itemize}
    Therefore, we have
    \begin{multline}
        \sca{F^{-1}_{\mu^t_{1,\theta}} - F^{-1}_{\mu_{1,\theta}}}{F^{-1}_{\mu_{1,\theta}} - F^{-1}_{\rho_{\theta,1,\theta}}}_{L^2([0,1])} 
        = \int_0^1 (F^{-1}_{\mu^t_{1,\theta}}(x) - F^{-1}_{\mu_{1,\theta}}(x))(F^{-1}_{\mu_{1,\theta}}(x) - F^{-1}_{\rho_{\theta,1,\theta}}(x))dx \\
        = \int_0^{m_{t,\theta}} (F^{-1}_{\mu^t_{1,\theta}}(x) - F^{-1}_{\mu_{1,\theta}}(x))(F^{-1}_{\mu_{1,\theta}}(x) - F^{-1}_{\rho_{\theta,1,\theta}}(x))dx \notag \\ 
        \quad + \int_{1-m_{t,\theta}}^1 (F^{-1}_{\mu^t_{1,\theta}}(x) - F^{-1}_{\mu_{1,\theta}}(x))(F^{-1}_{\mu_{1,\theta}}(x) - F^{-1}_{\rho_{\theta,1,\theta}}(x))dx \\
        = \int_0^{m_{t,\theta}} (F^{-1}_{\mu^t_{1,\theta}}(x) - F^{-1}_{\mu_{1,\theta}}(x))(F^{-1}_{\mu_{1,\theta}}(x) - F^{-1}_{\rho_{\theta,1,\theta}}(x))dx \notag \\ 
        \quad + \int_0^{m_{t,\theta}} (F^{-1}_{\mu^t_{1,\theta}}(1-x) - F^{-1}_{\mu_{1,\theta}}(1-x))(F^{-1}_{\mu_{1,\theta}}(1-x) - F^{-1}_{\rho_{\theta,1,\theta}}(1-x))dx \\
        = \int_0^{m_{t,\theta}} (F^{-1}_{\mu^t_{1,\theta}}(x) - F^{-1}_{\mu_{1,\theta}}(x))(F^{-1}_{\mu_{1,\theta}}(x) - F^{-1}_{\rho_{\theta,1,\theta}}(x) - (F^{-1}_{\mu_{1,\theta}}(1-x) - F^{-1}_{\rho_{\theta,1,\theta}}(1-x)))dx
    \end{multline}
    We have 
    \begin{equation} F^{-1}_{\mu^t_{1,\theta}}(x) - F^{-1}_{\mu_{1,\theta}}(x) = 2|c_\theta|x - |ts_\theta| = 2|c_\theta|(x - \frac{1}{2}|t_\theta|)\end{equation}
    \begin{equation} F^{-1}_{\mu_{1,\theta}}(x) - F^{-1}_{\mu_{1,\theta}}(1-x) = -|c_\theta| + 2|c_\theta|x - (-|c_\theta| + 2|c_\theta|(1-x)) = 4|c_\theta|(x - \frac{1}{2}) \end{equation}
    for $x \in [0, m_{t,\theta}]$. If for $x \in [0,1] \setminus \{\frac{1}{2}\}$ we note 
    \begin{equation} G_\theta(x) := \frac{F^{-1}_{\rho_{\theta,1,\theta}}(x) - F^{-1}_{\rho_{\theta,1,\theta}}(1-x)}{x - \frac{1}{2}}\end{equation} we have
    \begin{equation} \sca{F^{-1}_{\mu^t_{1,\theta}} - F^{-1}_{\mu_{1,\theta}}}{F^{-1}_{\mu_{1,\theta}} - F^{-1}_{\rho_{\theta,1,\theta}}}_{L^2([0,1])} = \int_0^{m_{t,\theta}} (x - \frac{1}{2})(4|c_\theta| - G_\theta(x))2|c_\theta|(x - \frac{1}{2}|tt_\theta|) dx \end{equation}
        
    However, our hypothesis that for every $\theta$ the density of $\rho_\theta$ is bounded from above by $b > 0$ allows us to derive a lower bound for $G_\theta$. Indeed, since $\rho = (1-\lambda)\rho_{\theta,0} + \lambda \rho_{\theta,1}$, we have $\rho_{\theta,1} \leq \frac{1}{\lambda} \rho$ and thus $\rho_{\theta,1,\theta} \leq \tilde{b}$ with $\tilde{b} = \frac{b}{\lambda}$. Then, using the shorthand notations $F_\theta = F_{\rho_{\theta,1,\theta}}$ and $F^{-1}_\theta = F^{-1}_{\rho_{\theta,1,\theta}}$, for almost every $x \in [0,1]$,
    \begin{equation} F^{-1}_\theta(F_\theta(x)) = x\end{equation}
    
    Let $x = \alpha + h$ with $h > 0$. Since 
    \begin{equation}F_\theta(x) = F_\theta(\alpha) + \rho_{\theta,1,\theta}((\alpha,\alpha+h]) \leq F_\theta(\alpha) + \tilde{b}h \end{equation}
    we have
    \begin{equation} \alpha + h = F^{-1}_\theta(F_\theta(\alpha + h)) \leq F^{-1}_\theta(F_\theta(\alpha) + \tilde{b}h)\end{equation}
    Similarly, if $x = \alpha - h$ with $h > 0$, we have
    \begin{equation}F_\theta(x) = F_\theta(\alpha) - \rho_{\theta,1,\theta}((\alpha-h,\alpha]) \geq F_\theta(\alpha) - \tilde{b}h \end{equation}
    thus
    \begin{equation} \alpha - h = F^{-1}_\theta(F_\theta(\alpha - h)) \geq F^{-1}_\theta(F_\theta(\alpha) - \tilde{b}h)\end{equation}
    and thus we have
    \begin{equation} -2h \geq F^{-1}_\theta(F_\theta(\alpha) - \tilde{b}h) - F^{-1}_\theta(F_\theta(\alpha) + \tilde{b}h)\end{equation}
    
    Now, pick $\alpha$ such that $F_\theta(\alpha) = \frac{1}{2}$. Let $x \in [0,1/2]$, and let $h > 0$ be such that $x = \frac{1}{2} - \tilde{b}h$. Then, substituting the value of $x$ in the previous equation, we get
    \begin{equation} F^{-1}_\theta(x) - F^{-1}_\theta(1-x) \leq -2h = -\frac{2}{\tilde{b}}(\frac{1}{2} - x)\end{equation}
    \begin{equation} G_\theta(x) \geq \frac{2}{\tilde{b}} > 0\end{equation}
    for almost every $x \in [0,1/2]$. Thus, since by definition of $m_{t,\theta}$, $(x - \frac{1}{2})(x - \frac{1}{2}|tt_\theta|) \geq 0$ for $x \in [0, m_{t,\theta}]$, this means that for every $\theta \in (-\pi/2,\pi/2)$,
    \begin{equation}
         \label{eq:proof_l269} \sca{F^{-1}_{\mu^t_{1,\theta}} - F^{-1}_{\mu_{1,\theta}}}{F^{-1}_{\mu_{1,\theta}} - F^{-1}_{\rho_{\theta,1,\theta}}}_{L^2([0,1])} 
        \leq 2|c_\theta|(4|c_\theta|-\frac{2}{\tilde{b}}) \int_0^{m_{t,\theta}} (x - \frac{1}{2})(x - \frac{1}{2}|tt_\theta|) dx
    \end{equation}
    Let's compute the integral on the right-hand side  :
    \begin{align}
        \int_0^{m_{t,\theta}} (x - \frac{1}{2})(x - \frac{1}{2}|tt_\theta|) dx
        &= \int_0^{m_{t,\theta}} x^2 - \frac{1}{2} (1+|tt_\theta|)x + \frac{1}{4} |tt_\theta| dx \\
        &= \frac{m_{t,\theta}^3}{3} - \frac{1}{4} (1 + |tt_\theta|)m_{t,\theta}^2 + \frac{1}{4} |tt_\theta| m_{t,\theta}
    \end{align}
    If $|\theta| \leq \arctan(1/|t|)$, then $m_{t,\theta} = \frac{1}{2} |tt_\theta|$ and 
    \begin{align}
        \int_0^{m_{t,\theta}} (x - \frac{1}{2})(x - \frac{1}{2}|tt_\theta|) dx
        &= \frac{|tt_\theta|^3}{24} - \frac{1}{16} (1 + |tt_\theta|)|tt_\theta|^2 + \frac{1}{8} |tt_\theta|^2 \\
        &= \frac{|tt_\theta|^2}{16} - \frac{|tt_\theta|^3}{48} \\
        &= \frac{1}{16}|tt_\theta|^2(1 - \frac{1}{3}|tt_\theta|)
    \end{align}
    and in fact, since $|tt_\theta| \leq 1$ when $|\theta| \leq \arctan(1/|t|)$, we have
    \begin{equation} \label{eq:proof_285}
        \int_0^{m_{t,\theta}} (x - \frac{1}{2})(x - \frac{1}{2}|tt_\theta|) dx = \frac{1}{16}|tt_\theta|^2(1 - \frac{1}{3}|tt_\theta|) \geq \frac{1}{24} |tt_\theta|^2 > 0
    \end{equation}
    Let $\theta_1 \in (0,\pi/2)$ be such that $4c_{\theta_1} - \frac{2}{\tilde{b}} \leq -\frac{1}{\tilde{b}}$ and let $t$ be small enough so that $\alpha_t := \arctan(1/|t|) > \theta_1$. Then :
    \begin{itemize}
        \item If $|\theta| \in (\alpha_t,\pi/2)$, then we can simply bound \eqref{eq:proof_l269} from above by 0
        \begin{equation} \sca{F^{-1}_{\mu^t_{1,\theta}} - F^{-1}_{\mu_{1,\theta}}}{F^{-1}_{\mu_{1,\theta}} - F^{-1}_{\rho_{\theta,1,\theta}}}_{L^2([0,1])} 
        \leq 0 \end{equation}
         as $4|c_{\theta}| - \frac{2}{\tilde{b}} < 0$ and the integral is positive. Thus
        \begin{equation}
            \label{eq:proof_l294} \int_{[-\pi/2,-\alpha_t] \cup [\alpha_t,\pi/2]}\sca{F^{-1}_{\mu^t_{1,\theta}} - F^{-1}_{\mu_{1,\theta}}}{F^{-1}_{\mu_{1,\theta}} - F^{-1}_{\rho_{\theta,1,\theta}}}_{L^2([0,1])} d\theta
        \leq 0 
        \end{equation}
         \item If $|\theta| \in [0,\theta_1)$ then, combining \eqref{eq:proof_l269} and \eqref{eq:proof_285} we have
         \begin{align}
            \sca{F^{-1}_{\mu^t_{1,\theta}} - F^{-1}_{\mu_{1,\theta}}}{F^{-1}_{\mu_{1,\theta}} - F^{-1}_{\rho_{\theta,1,\theta}}}_{L^2([0,1])} 
            &\leq 2|c_\theta|(4|c_\theta|-\frac{2}{\tilde{b}}) \int_0^{m_{t,\theta}} (x - \frac{1}{2})(x - \frac{1}{2}|tt_\theta|) dx \\
            &\leq 2|c_\theta|(4|c_\theta|-\frac{2}{\tilde{b}}) \frac{1}{16}|tt_\theta|^2(1 - \frac{1}{3}|tt_\theta|) \\
            &\leq \frac{1}{4} (2 + \frac{1}{\tilde{b}}) t^2 t_{\theta_1}^2 (1 + \frac{1}{3} |tt_{\theta_1}|)
        \end{align}
        Therefore, we conclude that there exists some constant $C_0 > 0$ such that 
        \begin{equation}
            \label{eq:proof_l304} \int_{[-\alpha_t,-\theta_1] \cup [\theta_1,\alpha_t]}\sca{F^{-1}_{\mu^t_{1,\theta}} - F^{-1}_{\mu_{1,\theta}}}{F^{-1}_{\mu_{1,\theta}} - F^{-1}_{\rho_{\theta,1,\theta}}}_{L^2([0,1])} d\theta \leq C_0 t^2 + o(t^2) 
        \end{equation}
        \item Finally, if $|\theta| \in [\theta_1, \alpha_t]$ then, again combining \eqref{eq:proof_l269} and \eqref{eq:proof_285}, we have
        \begin{align} 
            \sca{F^{-1}_{\mu^t_{1,\theta}} - F^{-1}_{\mu_{1,\theta}}}{F^{-1}_{\mu_{1,\theta}} - F^{-1}_{\rho_{\theta,1,\theta}}}_{L^2([0,1])} 
            &\leq 2|c_\theta|(4|c_\theta|-\frac{2}{\tilde{b}}) \int_0^{m_{t,\theta}} (x - \frac{1}{2})(x - \frac{1}{2}|tt_\theta|) dx \\
            &\leq 2|c_\theta|(4|c_\theta|-\frac{2}{\tilde{b}}) \frac{1}{16}|tt_\theta|^2(1 - \frac{1}{3}|tt_\theta|) \\
            &\leq -\frac{1}{12\tilde{b}} |c_\theta| |tt_\theta|^2 \\
            &\leq -\frac{1}{12\tilde{b}} t^2 \frac{|s_\theta^2|}{|c_\theta|} \leq -\frac{|s_{\theta_1}|^2}{12\tilde{b}} t^2 \frac{1}{|c_\theta|}
        \end{align}
        However, the integral $\int_{\theta_1}^{\alpha_t} \frac{d\theta}{|c_\theta|}$ diverges to infinity when $t \mapsto 0$. Indeed, using the development 
        \begin{equation} \alpha_t := \arctan(1/|t|) = \frac{\pi}{2} - \arctan(|t|) = \frac{\pi}{2} - |t| + o(t^2) \end{equation}
        we have
        \begin{align} 
           \int_{\theta_1}^{\theta_t} \frac{d\theta}{|c_\theta|} &= \int_{\sin(\theta_1)}^{\sin(\alpha_t)} \frac{du}{1 - u^2} \\
           &= \frac{1}{2} [ \ln(1+u) - \ln(1-u) ]^{\sin(\alpha_t)}_{\sin(\theta_1)} \\
           &= \frac{1}{2} (\ln(1+\sin(\alpha_t)) - \ln(1-\sin(\alpha_t))) + C \\
           &= \frac{1}{2} \left(\ln\left(1+\sin\left(\frac{\pi}{2} - |t| + o(t^2)\right)\right) - \ln\left(1-\sin\left(\frac{\pi}{2} - |t| + o(t^2)\right)\right)\right) + C \\
           &= \frac{1}{2} (\ln(1+\cos(|t| + o(t^2))) - \ln(1-\cos(|t| + o(t^2)))) + C \\
           &= \frac{1}{2} (\ln(1+\cos(|t| + o(t^2))) - \ln(1-\cos(|t| + o(t^2)))) + C \\
           &= \frac{1}{2}\left(\ln\left(2 - \frac{1}{2}t^2 + o(t^2)\right) - \ln\left(\frac{1}{2}t^2 + o(t^2)\right)\right) + C\\
           &= \frac{1}{2}(\ln(2) + o(1) - 2\ln(t) + \ln(2) + o(1)) + C \\
           &= -\ln(t) + C + o(1) \xrightarrow[t \to 0]{} +\infty
        \end{align}
        Therefore, for any $C > 0$, there exists a neighborhood of $t = 0$ in which,
        \begin{equation}
             \label{eq:proof_l328} \int_{[-\alpha_t,-\theta_1]\cup[\theta_1,\alpha_t]} \sca{F^{-1}_{\mu^t_{1,\theta}} - F^{-1}_{\mu_{1,\theta}}}{F^{-1}_{\mu_{1,\theta}} - F^{-1}_{\rho_{\theta,1,\theta}}}_{L^2([0,1])} d\theta 
            \leq -Ct^2 
        \end{equation}
    \end{itemize}
    Thus, we can prove \eqref{eq:proof_l169} by bounding the integral of $\sca{F^{-1}_{\mu^t_{1,\theta}} - F^{-1}_{\mu_{1,\theta}}}{F^{-1}_{\mu_{1,\theta}} - F^{-1}_{\rho_{\theta,1,\theta}}}$ on $(-\pi/2,\pi/2)$ separately on the three regions $(-\pi/2,-\alpha_t]\cup[\alpha_t,\pi/2)$, $[-\theta_1,\theta_1]$ and $[-\alpha_t,-\theta_1]\cup[\theta_1,\alpha_t]$ using \eqref{eq:proof_l304}, \eqref{eq:proof_l294} and \eqref{eq:proof_l328}, taking in \eqref{eq:proof_l328} a constant $C > 0$ big enough to compensate the constant $C_0$ in \eqref{eq:proof_l304}. This concludes the proof. \qed

\section{Stability and numerical approximation} \label{section:numerical_approx}

In this section, we will discuss briefly the regularity properties of (practical) Monte Carlo approximations of the SW objective and what they entail for applying our theoretical understanding of $F$ to practical applications involving $F_L$. 
The discussion will be similar to the one found in \citep{tanguy2023discrete_sw_losses}, although they focus on the discrete setting, where $\rho$ is also a point cloud, whereas we focus on the semi-discrete one.

In practice, the Sliced-Wasserstein distance objective \eqref{eq:FN} discussed in \Cref{section:sw_discrete} is usually computed through a Monte Carlo estimator to approximate the integral. In the semi-discrete setting, this amounts to approximating the function $F(X)$ discussed in \Cref{section:sw_discrete} with the function $ F_L = \frac{1}{2L} \sum_{l=1}^L \W^2_2(\mu_{P_{\theta_l}(X)}, \rho_{\theta_l})$, where $\theta_1,...,\theta_L \in \bS^{d-1}$ are chosen directions. The latter may vary: for example, they may be uniformly sampled on $\bS^{d-1}$ at every step of a stochastic gradient descent (or some other optimization algorithm), or fixed once and for all.
 
In fact, the local behavior of $F_L$ is quite different from that of $F$, and exhibits a cell structure. Indeed, for every $\bm{\sigma} \in \mathfrak{S}_n^L$, let $\cC_{\bm{\sigma}} = \{X \in (\R^d)^N \;|\; \forall l \in \{1,...,L\}, \sigma_{\theta_l,X} \hbox{ is uniquely defined and is } \bm{\sigma}_l \}$. Then, for every $X \in \cC_{\bm{\sigma}}$, we have 
\begin{equation}F_L(X)  = \frac{1}{2L} \sum_{l=1}^L \sum_{i=1}^N \int_{V_{\theta_l,i}} |\sca{X_{\bm{\sigma}_l(i)}}{\theta_l} - x|^2 d\rho_{\theta_l}(x)\end{equation} 
which simplifies to 
\begin{equation}F_L(X) = q_{\bm{\sigma}}(X) + C_0\end{equation} 
with the quadratic function 
\begin{equation}q_{\bm{\sigma}}(X) = \frac{1}{2NL} \sum_{l=1}^L \sum_{i=1}^N |\sca{X_{\bm{\sigma}_l(i)}}{\theta_l} - b_{\theta_l,i}|^2\end{equation} 
and the constant 
\begin{equation}C_0 = \frac{1}{2L} \sum_{l=1}^L \sum_{i=1}^N \int_{V_{\theta_l,i}} |x - b_{\theta_l,i}|^2 d\rho_{\theta_l}(x)\end{equation}
In fact, $\cC_{\bm{\sigma}}$ can also be written as $\cC_{\bm{\sigma}} = \{X \in (\R^d)^N \;|\; \forall \bm{\sigma'} \in \mathfrak{S}_N^L, q_{\bm{\sigma'}}(X) > q_{\bm{\sigma}}(X) \}$, from which we can deduce that $\cC_{\bm{\sigma}}$ is an open polyhedral cone, obtained as the intersection of $L(N!-1)$ half-open planes. Furthermore, $F_L$ is actually the infimum of the $C_0 + q_{\bm{\sigma}}$: 
\begin{equation}F_L(X) = \inf_{\bm{\sigma} \in \mathfrak{S}_N^L} q_{\bm{\sigma}}(X) + C_0\end{equation}

As a consequence of these considerations, inside every cell $\cC_{\bm{\sigma}}$, $F_L$ will be $C^\infty$ as it is equal to a quadratic function, and its gradient and Hessian at $X \in \cC_{\bm{\sigma}}$ are respectively 
\begin{equation} \nabla_{X_i} F_L(X) = \frac{1}{NL} \sum_{l=1}^L (\sca{X_i}{\theta_l} - b_{\theta_l, \bm{\sigma}^{-1}_l(i)}) \theta_l\end{equation} 
and 
\begin{equation}\nabla_{X_i} \nabla_{X_j} F_L (X) = \frac{1}{NL} \delta_{ij} \sum_{l=1}^L \theta_l \theta_l^T \geq 0\end{equation}
Thus, $F_L$ is convex inside every cell $\cC_{\bm{\sigma}}$. In fact, we know by \citep[Theorem 2]{tanguy2023reconstructing} that when $L > d$, for almost every family $\theta_1,...,\theta_L \in \bS^{d-1}$, $\bigcap_{l=1}^L (\R\theta_i)^\perp = \{0\}$ and $\frac{1}{L} \sum_{l=1}^L \theta_l \theta_l^T$ is definite positive, which makes $F_L$ strictly convex inside every cell. In these conditions, any critical point contained in a cell will be a local minimum. \\

This is of significance when optimizing $F_L$. Indeed, even if it were possible to derive theoretical guarantees that high energy critical points of $F$ are unstable, a numerical scheme optimizing $F_L$ could end up converging to a high energy critical point of $F_L$ because of its local convexity. Consequently, on must be chose a number of directions $L$ and of points $N$ large enough to make sure the size of the cells $C_{\bm{\sigma}}$ is small enough to prevent this behavior. 

\begin{figure*}[t]
    \vskip 0.2in
    \begin{center}
        \centerline{\includegraphics[width=\textwidth]{fig_small_L.png}}
        \caption{Behavior of $F_L$ for different sets of test directions. Depicts the value of $F_L(X+t\xi)$, where $X$ is a point cloud of $N = 100$ points uniformly distributed on the segment $[-4/\pi,4/\pi] \times \{0\}$, $\xi$ alternates between $e_2$ and $-e_2$, and $\rho$ is the sliced-uniform distribution. Each column corresponds to a different number $L \in \{10,20,40,100\}$ of fixed test directions ; on the top line $e_2$ is included in the test directions while on the bottom line it is excluded}
    \end{center}
    \label{fig:2}
    \vskip -0.2in
\end{figure*}

\paragraph{Experiments} In another experiment, based on the discussion of Section \ref{section:numerical_approx}, we considered again the point cloud $X = (X_1,...,X_N)$ with $X_i = -\frac{4}{\pi} + \frac{8}{\pi}\frac{i-1}{N-1}$, with $N = 100$, the perturbation $\xi$ that alternates between $e_2$ and $-e_2$, and we plotted the estimator $t \mapsto F_L(X+t\xi)$ in Figure \ref{fig:2}, where $\rho$ is the sliced-uniform measure, for different sets of test directions $\{\theta_1,...,\theta_L\}$. We tested different values of $L$, and, for each of these values, we considered two cases :

\begin{itemize}
    \item one set of test directions $\{\theta_1,...,\theta_L\}$ including $e_2$, with $\theta_i = \frac{\pi}{2} + \frac{2\pi(i-1)}{L}$ for $i \in \{1,...,L\}$
    \item one set of test directions $\{\theta_1,...,\theta_L\}$ excluding $e_2$, with $\theta_i = \frac{\pi}{2} + \frac{\pi}{L} + \frac{2\pi(i-1)}{L}$ for $i \in \{1,...,L\}$ 
\end{itemize}
We observe that, as expected from the discussion in Section \ref{section:numerical_approx}, when the test directions exclude $e_2$ (so that the points of $X$ have distinct projections for every test direction), the estimator $t \mapsto F_L(X+t\xi)$ is locally smooth, and we distinctively see its cell structure for the smaller values of $L$. On the other hand, when the test directions include $e_2$, we see that the estimator is not smooth at $t = 0$. This again conforms to what we theoretically expect, as 

\begin{equation}\W^2_2(\mu_{X,e_2}, \rho_{e_2}) = \W^2_2(\frac{1}{2} (\delta_{-|t|} + \delta_{|t|}, \frac{1}{2} \cL^1_{|[-1,1]}) = \int_0^1 (|t| - x)^2 dx = \frac{1}{3} - |t| + t^2 \end{equation}
