\section{Introduction}
\label{sec:intro}
Object detection has been a challenging yet fundamental task in computer vision for the last decade. Close-up settings such as MS COCO~\cite{lin2014microsoft} have shown impressive performance with successful real-world applications. However, with the development of imaging systems and new application requirements like UAVs, detecting objects in high-resolution wide (HRW) shots with square-kilometer scenes and gigapixel-level resolutions have drawn increasing attention~\cite{chen2022towards,fan2022speed,han2021align,li2022oriented,najibi2019autofocus,pan2020dynamic,yang2022scrdet++,zhang2019cad,wang2024group,lin2023realgraph,ma2024visual,lin2024gigatraj}. 

\begin{figure}[!]
\centering
	% \begin{center}
		\includegraphics[width=1\linewidth]{pic/AP_curve.pdf}
	% \end{center}
        \vspace{-20pt}
	\caption{\textbf{Performance comparison in terms of object size on the PANDA dataset~\cite{wang2020panda}.} The horizontal axis indicates object sizes (the area of bounding boxes) on a logarithmic scale. The vertical axis shows detection accuracy per size. Both YOLOv8~\cite{yolov8} and DINO~\cite{zhang2022dino} underperform in handling extreme scale variations, especially for small and large objects. The proposed method performs well, achieving new state-of-the-art detection accuracy. 
    }
    \vspace{-12pt}
	\label{fig:sparse_challege}	
\end{figure}


Detecting objects in HRW shots using close-up detectors is not effective due to several unique characteristics of HRW shots, as found in PANDA~\cite{wang2020panda} and DOTA~\cite{xia2018dota}, compared to close-up shots like MS COCO. The most significant challenge is the sparse information in HRW shots, where objects often cover less than 5\% of the image. This makes it difficult for detectors to extract key features from a sea of background noise, resulting in false positives within the background and false negatives within the object areas during training and testing. 
%
The second challenge is the varying scales of objects in HRW shots, with changes up to 100 times. Detectors relying on fixed settings of the receptive field and anchors cannot adapt to these extreme scales, as shown in \cref{fig:sparse_challege}. For instance, YOLOv8~\cite{yolov8} underperforms in detecting small objects. While DINO~\cite{zhang2022dino} shows marginal improvement, it still falls short in adapting to such exaggerated scale changes, resulting in subpar detection of larger objects (\cref{fig:bad_case}). 
%
Additionally, the typical two-stage downsampling schemes~\cite{najibi2019autofocus, chen2022towards, fan2022speed, li2020density} miss more small objects. The slicing strategy~\cite{akyon2022sahi} can result in incomplete boxes when using NMS to merge prediction boxes, as shown in \cref{fig:challenge}. Therefore, it is imperative to bridge the gap between object detection in close-up and HRW shots.


Motivated by recent advanced techniques~\cite{meng2022adavit,rao2021dynamicvit, wang2022efficient,yang2022querydet, wang2021pnp, song2021dynamic} to enhance object detection accuracy, we present a novel detector for HRW shots that employs a sparse Vision Transformer, called SparseFormer.
%
SparseFormer uses attentive tokens selectively to concentrate on regions of an image where objects are sparsely distributed, facilitating the extraction of fine-grained features. 
To achieve this, it learns a ScoreNet to assess the importance of regions. By examining the variance of importance scores of all regions, our SparseFormer prioritizes regions that capture rich fine-grained details. In this way, it can focus on complex image regions rather than less significant ones (e.g., smooth content from the background). 
%
Concurrently, it divides each HRW shot into non-overlapping windows to extract coarse-grained features. 
Sharing a similar spirit with the receptive field strategy of the original Vision Transformer~\cite{dosovitskiy2020image}, our proposed SparseFormer combines coarse and fine-grained features, achieving much higher efficiency than Swin Transformer~\cite{liu2021swin}. This greatly helps to handle large scale variations and detect both large and small objects accurately. %, making it highly effective in images with significant scale differences.


We further present two innovative techniques to improve detection accuracy against huge scale changes. 
%
First, we observe that conventional NMS refers to confidence scores only to merge detection results, leading to incomplete bounding boxes on oversized objects. To address this, we propose a novel Cross-slice NMS scheme (C-NMS) that favors large bounding boxes with high confidence scores. The proposed C-NMS scheme greatly improves the detection accuracy of oversized objects. 
%
Second, we use a multi-scale strategy to extract coarse-grained and fine-grained features. The multi-scale strategy enlarges the receptive field, enhancing the detection accuracy on both large and small objects. 
%
In summary, the main contributions of this work are as follows:


\begin{itemize}
\item
We propose a novel sparse Vision Transformer based detector to handle huge scale changes in HRW images. 
\item
We further use cross-window NMS and multi-scale schemes to improve detection on large and small objects.
\item 
We extensively validate our method on two large-scale HRW-shot benchmarks, PANDA and DOTA-v1.0. Our method advances state-of-the-art performance by large margins. 
\end{itemize}

