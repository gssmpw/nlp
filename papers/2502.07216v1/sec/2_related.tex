\section{Related Work}
\noindent\textbf{Close-up shot detection models.}
%
The majority of common object detection datasets, such as PASCAL VOC~\cite{everingham2010pascal} and MS COCO~\cite{lin2014microsoft}, collect high-resolution images with close-up shots, which has greatly contributed to the development of object detection. Based on the detection head, the literature can be broadly categorized into two types: one-stage detectors and two-stage detectors. The primary objective of the two-stage object detection is accuracy, and it frames the detection as a ``coarse-to-fine" process~\cite{girshick2014rich, girshick2015fast, ren2015faster, he2017mask, cai2018cascade}. On the other hand, one-stage detectors have an edge in terms of speed, such as YOLO~\cite{redmon2016you}. Subsequent works have attempted to make improvements such as more anchors, better architecture, and richer training techniques~\cite{redmon2018yolov3, yolox2021, liu2016ssd}. To sum up, the current detectors exhibit great speed and accuracy in close-up shots.

\vspace{2mm}\noindent\textbf{High-resolution wide shot detection models.}
%
The introduction of imaging systems led to the development of a new benchmark for gigapixel-level detection with HRW shots called PANDA~\cite{wang2020panda}. This benchmark has recently gained a lot of attention. Previous works on gigapixel-level detection focus on achieving lower latency through patch selection or arrangement~\cite{najibi2019autofocus,fan2022speed,chen2022towards,li2024saccadedet,li2024saccademot}. However, they are unable to solve the unique challenges faced in HRW shots. Some works use sparse policies on patches~\cite{rao2021dynamicvit}, self-attention heads~\cite{meng2022adavit}, and transformer blocks~\cite{meng2022adavit} for image classification. PnP-DETR~\cite{wang2021pnp} exploits a poll and pool sampler to extract image features from the backbone and feed the sparse tokens to the attention encoder. This approach shows to be effective for object detection, panoptic segmentation, and image recognition. However, the sparse sampling on the backbone has not been adequately studied yet. 
%
DGE~\cite{song2021dynamic} is a plugin for vision transformers, but it is not flexible enough to be extended to ConvNet-based models or use arbitrary-size images as input. Therefore, how to design a flexible and model-agnostic architecture for object detection in HRW shots remains underexplored.

\begin{figure}[!]
\centering
	% \begin{center}
	\includegraphics[width=1\linewidth]{pic/bad_case.pdf}
	% \end{center}
        \vspace{-17pt}
	\caption{\textbf{Featured detection example on PANDA.} 
    The state-of-the-art detectors, YOLOv8~\cite{yolov8} (\textcolor{blue}{blue}) and DINO~\cite{zhang2022dino} (\textcolor{green}{green}), relying on fixed settings of the receptive field and anchors yield incomplete bounding boxes on a large bus and miss detections on a small car. 
 }
    \vspace{-12pt}
	\label{fig:bad_case}	
\end{figure}



\vspace{2mm}\noindent\textbf{Transformer backbones.}
Transformers have been successful in natural language processing (NLP), and their potential for vision tasks has gained considerable attention. One such example is the Vision Transformer (ViT)~\cite{dosovitskiy2020image}, which uses a pure Transformer model for image classification and has shown promising results. However, ViT's computational costs for processing high-resolution images are impractical. Several methods have been attempted to reduce ViT model costs, including window-based attention~\cite{liu2021swin}, downsampling in self-attention~\cite{wang2021pyramid, wu2021cvt}, and low-rank projection attention~\cite{xiong2021nystromformer}. 
Other works use sparse policies on patches~\citep{rao2021dynamicvit}, self-attention heads~\citep{meng2022adavit}, and transformer blocks~\citep{meng2022adavit} for image classification.
Unfortunately, these methods suffer from significant accuracy drops when detecting objects in high-resolution wide shots.
