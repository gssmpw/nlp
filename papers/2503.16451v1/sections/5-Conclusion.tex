\section{Conclusion}
In this paper, we propose a novel framework Think-Then-React (TTR) to address the action-to-reaction motion generation problem. First, we propose a unified motion encoder that tokenizes a person's starting location and following poses separately. Then we design motion and text related tasks to pre-train a large language model backbone to understand and generate both language and motion. We also fine-tune the model to think what the input action means and what an appropriate reaction is, and then generate reaction motions.
Experimental results show that our proposed TTR method outperforms all baselines in all metrics except for diversity. Our proposed thinking phase and all pre-training tasks contribute to the best performance. We find that although our proposed unified motion encoder enable leveraging single-person data in pre-training, it brings limited benefit due to the little overlapped poses between single-person motion and multi-person interaction.
In the future, we plan to explore more effective method for single-person and multi-person dataset.