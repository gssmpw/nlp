\section{Related Work}
\subsection{Generative Adversarial Networks}
Generative adversarial networks (GANs) ____ have been effectively applied to synthesize various forms of synthetic data ____. In the context of tabular data, CTGAN is a GAN-based model specifically designed for tabular data generation ____. A considerable body of literature has demonstrated the fidelity and utility of data generated with CTGAN, across several applications and disciplines ____. However, like other GAN-based approaches, CTGAN requires access to RWD, which presents privacy concerns. Overfitting and memorization of training data increases susceptibility to privacy attacks and data leak ____. This vulnerability is particularly of concern when GANs are trained on RWD with smaller sample sizes ____. GAN-based models also require some degree of technical expertise to generate high-quality synthetic data (e.g., GAN architecture, optimization, fine-tuning), which poses additional limitations to the accessibility of this approach. 
\subsection{Variational Autoencoders}
Variational autoencoders (VAEs) are another class of deep generative models used to synthesize synthetic data ____. Several VAEs have demonstrated applicability toward tabular data generation, including TVAE ____, which was presented alongside CTGAN. Like GAN-based approaches, VAEs require access to RWD and technical expertise.
\subsection{Large Language Models}
LLMs are another form of generative artificial intelligence, which have been applied to synthetic data generation. This primarily includes text-based data, including synthetic interview transcripts ____ and medical records ____. Some approaches to LLM-based tabular data synthesis have also emerged, including GReaT ____ and TabuLa ____. However, current LLM-based frameworks require access to RWD, pre-training, and/or fine-tuning. More recently, preliminary evidence has demonstrated the potential for zero-shot generation of synthetic tabular data with the LLM, GPT-4o ____. Without access to RWD, GPT-4o was capable of generating tabular data with high fidelity to clinical RWD by using plain-language prompts which described the desired statistical properties. Notably, this initial evidence has demonstrated the preservation of relationships between parameters, synthesis of new and interrelated features, amplification of sample sizes, and the utility of LLM-generated data toward training ML models. However, it remains unclear whether observed fidelity would scale to further interactions between parameters and how performance would compare to GAN-based frameworks with further benchmarking metrics. The potential for tabular data generation without requiring technical expertise and access to RWD in a zero-shot setting warrants further investigation.