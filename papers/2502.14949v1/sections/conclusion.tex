\section{Conclusion}

We introduce a comprehensive benchmark for Arabic OCR that fills the gap in standardized evaluation frameworks for Arabic document processing. Our dataset of 8,809 samples across nine major domains is the most diverse collection assembled for OCR evaluation, incorporating handwritten, scanned, synthetic, and scene text, as well as complex tables, charts, and end-to-end pdf-to-markdown. This framework extends beyond simple text recognition to include structural document analysis and enables systematic assessment of OCR performance across various fonts, styles, and layouts.

% By standardizing evaluation, our work lays the foundation for future Arabic OCR and document analysis research. We anticipate that our benchmark will drive the development of more robust OCR models, improvements in dataset creation, and the adoption of advanced deep learning techniques tailored for Arabic script recognition. Ultimately, our work aims to bridge the performance gap between Arabic and English OCR, advancing multilingual document analysis.