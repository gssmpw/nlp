@inproceedings{staar2018corpus,
  title={Corpus conversion service: A machine learning platform to ingest documents at scale},
  author={Staar, Peter WJ and Dolfi, Michele and Auer, Christoph and Bekas, Costas},
  booktitle={Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
  pages={774--782},
  year={2018}
}
@article{hashmi2021castabdetectors,
  title={Castabdetectors: Cascade network for table detection in document images with recursive feature pyramid and switchable atrous convolution},
  author={Hashmi, Khurram Azeem and Pagani, Alain and Liwicki, Marcus and Stricker, Didier and Afzal, Muhammad Zeshan},
  journal={Journal of Imaging},
  volume={7},
  number={10},
  pages={214},
  year={2021},
  publisher={MDPI}
}
%icdar 2013
@inproceedings{gobel2013icdar,
  title={ICDAR 2013 table competition},
  author={G{\"o}bel, Max and Hassan, Tamir and Oro, Ermelinda and Orsi, Giorgio},
  booktitle={2013 12th international conference on document analysis and recognition},
  pages={1449--1453},
  year={2013},
  organization={IEEE}
}
@inproceedings{gao2019icdar,
  title={ICDAR 2019 competition on table detection and recognition (cTDaR)},
  author={Gao, Liangcai and Huang, Yilun and D{\'e}jean, Herv{\'e} and Meunier, Jean-Luc and Yan, Qinqin and Fang, Yu and Kleber, Florian and Lang, Eva},
  booktitle={2019 International Conference on Document Analysis and Recognition (ICDAR)},
  pages={1510--1515},
  year={2019},
  organization={IEEE}
}
@inproceedings{kayal2021icdar,
  title={ICDAR 2021 competition on scientific table image recognition to LaTeX},
  author={Kayal, Pratik and Anand, Mrinal and Desai, Harsh and Singh, Mayank},
  booktitle={Document Analysis and Recognition--ICDAR 2021: 16th International Conference, Lausanne, Switzerland, September 5--10, 2021, Proceedings, Part IV 16},
  pages={754--766},
  year={2021},
  organization={Springer}
}
% TEDS metric: Tables eval for HTML
@article{zhong2019image,
  title={Image-based table recognition: data, model, and evaluation. CoRR abs/1911.10683},
  author={Zhong, X and ShafieiBavani, E and Jimeno-Yepes, A},
  journal={arXiv preprint arXiv:1911.10683},
  year={2019}
}
@inproceedings{zheng2021global,
  title={Global table extractor (gte): A framework for joint table identification and cell structure recognition using visual context},
  author={Zheng, Xinyi and Burdick, Douglas and Popa, Lucian and Zhong, Xu and Wang, Nancy Xin Ru},
  booktitle={Proceedings of the IEEE/CVF winter conference on applications of computer vision},
  pages={697--706},
  year={2021}
}
@inproceedings{long2021parsing,
  title={Parsing table structures in the wild},
  author={Long, Rujiao and Wang, Wen and Xue, Nan and Gao, Feiyu and Yang, Zhibo and Wang, Yongpan and Xia, Gui-Song},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={944--952},
  year={2021}
}
@inproceedings{li2021gfte,
  title={GFTE: graph-based financial table extraction},
  author={Li, Yiren and Huang, Zheng and Yan, Junchi and Zhou, Yi and Ye, Fan and Liu, Xianhui},
  booktitle={Pattern Recognition. ICPR International Workshops and Challenges: Virtual Event, January 10--15, 2021, Proceedings, Part II},
  pages={644--658},
  year={2021},
  organization={Springer}
}
@article{li2019tablebank,
  title={Tablebank: A benchmark dataset for table detection and recognition},
  author={Li, Minghao and Cui, Lei and Huang, Shaohan and Wei, Furu and Zhou, Ming and Li, Zhoujun},
  journal={arXiv preprint arXiv:1903.01949},
  year={2019}
}

@inproceedings{lysak2023optimized,
  title={Optimized Table Tokenization for Table Structure Recognition},
  author={Lysak, Maksym and Nassar, Ahmed and Livathinos, Nikolaos and Auer, Christoph and Staar, Peter},
  booktitle={International Conference on Document Analysis and Recognition},
  pages={37--50},
  year={2023},
  organization={Springer}
}

% WordScape
@article{weber2023wordscape,
  title={WordScape: a Pipeline to extract multilingual, visually rich Documents with Layout Annotations from Web Crawl Data},
  author={Weber, Maurice and Siebenschuh, Carlo and Butler, Rory and Alexandrov, Anton and Thanner, Valdemar and Tsolakis, Georgios and Jabbar, Haris and Foster, Ian and Li, Bo and Stevens, Rick and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={26048--26068},
  year={2023}
}

% PubLayNet
@inproceedings{zhong2019publaynet,
  title={Publaynet: largest dataset ever for document layout analysis},
  author={Zhong, Xu and Tang, Jianbin and Yepes, Antonio Jimeno},
  booktitle={2019 International conference on document analysis and recognition (ICDAR)},
  pages={1015--1022},
  year={2019},
  organization={IEEE}
}

%
@inproceedings{livathinos2021robust,
  title={Robust pdf document conversion using recurrent neural networks},
  author={Livathinos, Nikolaos and Berrospi, Cesar and Lysak, Maksym and Kuropiatnyk, Viktor and Nassar, Ahmed and Carvalho, Andre and Dolfi, Michele and Auer, Christoph and Dinkla, Kasper and Staar, Peter},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  pages={15137--15145},
  year={2021}
}

% Tablenet
@inproceedings{paliwal2019tablenet,
  title={Tablenet: Deep learning model for end-to-end table detection and tabular data extraction from scanned document images},
  author={Paliwal, Shubham Singh and Vishwanath, D and Rahul, Rohit and Sharma, Monika and Vig, Lovekesh},
  booktitle={2019 International Conference on Document Analysis and Recognition (ICDAR)},
  pages={128--133},
  year={2019},
  organization={IEEE}
}

@inproceedings{prasad2020cascadetabnet,
  title={CascadeTabNet: An approach for end to end table detection and structure recognition from image-based documents},
  author={Prasad, Devashish and Gadpal, Ayan and Kapadni, Kshitij and Visave, Manish and Sultanpure, Kavita},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition workshops},
  pages={572--573},
  year={2020}
}
@inproceedings{schreiber2017deepdesrt,
  title={Deepdesrt: Deep learning for detection and structure recognition of tables in document images},
  author={Schreiber, Sebastian and Agne, Stefan and Wolf, Ivo and Dengel, Andreas and Ahmed, Sheraz},
  booktitle={2017 14th IAPR international conference on document analysis and recognition (ICDAR)},
  volume={1},
  pages={1162--1167},
  year={2017},
  organization={IEEE}
}

%tableformer
@inproceedings{nassar2022tableformer,
  title={Tableformer: Table structure understanding with transformers},
  author={Nassar, Ahmed and Livathinos, Nikolaos and Lysak, Maksym and Staar, Peter},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={4614--4623},
  year={2022}
}

%camelbench
@article{ghaboura2024camel,
  title={CAMEL-Bench: A Comprehensive Arabic LMM Benchmark},
  author={Ghaboura, Sara and Heakl, Ahmed and Thawakar, Omkar and Alharthi, Ali and Riahi, Ines and Saif, Abduljalil and Laaksonen, Jorma and Khan, Fahad S and Khan, Salman and Anwer, Rao M},
  journal={arXiv preprint arXiv:2410.18976},
  year={2024}
}
% LAraBench
@article{abdelali2023larabench,
  title={LAraBench: Benchmarking Arabic AI with Large Language Models},
  author={Abdelali, Ahmed and Mubarak, Hamdy and Chowdhury, Shammur Absar and Hasanain, Maram and Mousi, Basel and Boughorbel, Sabri and Kheir, Yassine El and Izham, Daniel and Dalvi, Fahim and Hawasly, Majd and others},
  journal={arXiv preprint arXiv:2305.14982},
  year={2023}
}

% OSACT
@inproceedings{mubarak2022overview,
  title={Overview of OSACT5 shared task on arabic offensive language and hate speech detection},
  author={Mubarak, Hamdy and Al-Khalifa, Hend and Al-Thubaity, AbdulMohsen},
  booktitle={Proceedinsg of the 5th Workshop on Open-Source Arabic Corpora and Processing Tools with Shared Tasks on Qur'an QA and Fine-Grained Hate Speech Detection},
  pages={162--166},
  year={2022}
}

%Tashkeela
@article{zerrouki2017tashkeela,
  title={Tashkeela: Novel corpus of Arabic vocalized texts, data for auto-diacritization systems},
  author={Zerrouki, Taha and Balla, Amar},
  journal={Data in brief},
  volume={11},
  pages={147},
  year={2017}
}

%MADAR
@inproceedings{bouamor2018madar,
  title={The MADAR Arabic dialect corpus and lexicon},
  author={Bouamor, Houda and Habash, Nizar and Salameh, Mohammad and Zaghouani, Wajdi and Rambow, Owen and Abdulrahim, Dana and Obeid, Ossama and Khalifa, Salam and Eryani, Fadhl and Erdmann, Alexander and others},
  booktitle={Proceedings of the eleventh international conference on language resources and evaluation (LREC 2018)},
  year={2018}
}

% Arabench
@inproceedings{sajjad2020arabench,
  title={Arabench: Benchmarking dialectal arabic-english machine translation},
  author={Sajjad, Hassan and Abdelali, Ahmed and Durrani, Nadir and Dalvi, Fahim},
  booktitle={Proceedings of the 28th International Conference on Computational Linguistics},
  pages={5094--5107},
  year={2020}
}

% APTI
@inproceedings{slimane2009new,
  title={A new arabic printed text image database and evaluation protocols},
  author={Slimane, Fouad and Ingold, Rolf and Kanoun, Slim and Alimi, Adel M and Hennebert, Jean},
  booktitle={2009 10th international conference on document analysis and recognition},
  pages={946--950},
  year={2009},
  organization={IEEE}
}

% IFN/ENIT
@inproceedings{pechwitz2002ifn,
  title={IFN/ENIT-database of handwritten Arabic words},
  author={Pechwitz, Mario and Maddouri, S Snoussi and M{\"a}rgner, Volker and Ellouze, Noureddine and Amiri, Hamid and others},
  booktitle={Proc. of CIFED},
  volume={2},
  pages={127--136},
  year={2002},
  organization={Citeseer}
}

%khatt
@article{mahmoud2014khatt,
  title={KHATT: An open Arabic offline handwritten text database},
  author={Mahmoud, Sabri A and Ahmad, Irfan and Al-Khatib, Wasfi G and Alshayeb, Mohammad and Parvez, Mohammad Tanvir and M{\"a}rgner, Volker and Fink, Gernot A},
  journal={Pattern Recognition},
  volume={47},
  number={3},
  pages={1096--1112},
  year={2014},
  publisher={Elsevier}
}

%CORU
@article{abdallah2024coru,
  title={CORU: Comprehensive Post-OCR Parsing and Receipt Understanding Dataset},
  author={Abdallah, Abdelrahman and Abdalla, Mahmoud and Kasem, Mahmoud SalahEldin and Mahmoud, Mohamed and Abdelhalim, Ibrahim and Elkasaby, Mohamed and ElBendary, Yasser and Jatowt, Adam},
  journal={arXiv preprint arXiv:2406.04493},
  year={2024}
}

%Hindawi
@misc{elfilali2023hindawi,
  title = {Hindawi Books Dataset},
  author = {Elfilali, Ali},
  year = {2023},
  howpublished = {\url{https://huggingface.co/datasets/Ali-C137/Hindawi-Books-dataset}},
  note = {Dataset}
}

% PATD
@inproceedings{bouressace2019printed,
  title={Printed Arabic text database for automatic recognition systems},
  author={Bouressace, Hassina and Csirik, Janos},
  booktitle={Proceedings of the 2019 5th International Conference on Computer and Technology Applications},
  pages={107--111},
  year={2019}
}

% ADAB
@misc{adab2019bench,
    title = {ADAB database},
    doi = {10.21227/wpf8-dk19},
    url = {https://dx.doi.org/10.21227/wpf8-dk19},
    author = {Boubaker, Houcine and Elbaati, Abdelkarim and Tagougui, Najiba and El Abed, Haikal and Kherallah, Monji and Märgner, Volker and Alimi, Adel M.},
    publisher = {IEEE Dataport},
    year = {2021} 
}

%online-khatt
@article{mahmoud2018online,
  title={Online-khatt: an open-vocabulary database for Arabic online-text processing},
  author={Mahmoud, Sabri A and Luqman, Hamzah and Al-Helali, Baligh M and BinMakhashen, Galal and Parvez, Mohammad Tanvir},
  journal={The Open Cybernetics \& Systemics Journal},
  volume={12},
  number={1},
  year={2018}
}
% HistoryAr
@inproceedings{pantke2014historical,
  title={An historical handwritten arabic dataset for segmentation-free word spotting-hadara80p},
  author={Pantke, Werner and Dennhardt, Martin and Fecker, Daniel and M{\"a}rgner, Volker and Fingscheidt, Tim},
  booktitle={2014 14th International Conference on Frontiers in Handwriting Recognition},
  pages={15--20},
  year={2014},
  organization={IEEE}
}
% EvArEST
@article{hassan2021arabicEvArEST,
  title={Arabic scene text recognition in the deep learning era: Analysis on a novel dataset},
  author={Hassan, Heba and El-Mahdy, Ahmed and Hussein, Mohamed E},
  journal={IEEE Access},
  volume={9},
  pages={107046--107058},
  year={2021},
  publisher={IEEE}
}
%isi-ppt
@inproceedings{wu2017iccv,
    author = {Yue Wu and Prem Natarajan},
    booktitle = {International Conference on Computer Vision},
    title = {Self-organized Text Detection with Minimal Post-processing via Border Learning},
    year = {2017}
}
%muharaf
@article{saeed2024muharaf,
  title={Muharaf: Manuscripts of Handwritten Arabic Dataset for Cursive Text Recognition},
  author={Saeed, M. and Chan, A. and Mijar, A. and Moukarzel, J.},
  journal={arXiv preprint arXiv:2406.09630},
  year={2024}
}
%DocSynth-300K
@article{zhao2024doclayout,
  title={Doclayout-yolo: Enhancing document layout analysis through diverse synthetic data and global-to-local adaptive perception},
  author={Zhao, Z. and Kang, H. and Wang, B. and He, C.},
  journal={arXiv preprint arXiv:2410.12628},
  year={2024}
}
% BADAM
@inproceedings{badam2024benjamin,
author = {Kiessling, Benjamin and Ezra, Daniel St\"{o}kl Ben and Miller, Matthew Thomas},
title = {BADAM: A Public Dataset for Baseline Detection in Arabic-script Manuscripts},
year = {2019},
isbn = {9781450376686},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3352631.3352648},
doi = {10.1145/3352631.3352648},
booktitle = {Proceedings of the 5th International Workshop on Historical Document Imaging and Processing},
pages = {13–18},
numpages = {6}
}

% be_arabic_9k
@article{elanwar2021be_arabic_9k,
  title={Extracting text from scanned Arabic books: a large-scale benchmark dataset and a fine-tuned Faster-R-CNN model},
  author={Elanwar, R. and Qin, W. and Betke, M. and Wijaya, D.},
  journal={International Journal on Document Analysis and Recognition (IJDAR)},
  year={2021},
  publisher={Springer}
}

% m6doc
@inproceedings{cheng2023m6doc,
  title={M6doc: A large-scale multi-format, multi-type, multi-layout, multi-language, multi-annotation category dataset for modern document layout analysis},
  author={Cheng, H. and Zhang, P. and Wu, S. and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2023}
}

%DocLayNet
@article{doclaynet2022,
  title = {DocLayNet: A Large Human-Annotated Dataset for Document-Layout Analysis},  
  doi = {10.1145/3534678.353904},
  url = {https://arxiv.org/abs/2206.01062},
  author = {Pfitzmann, Birgit and Auer, Christoph and Dolfi, Michele and Nassar, Ahmed S and Staar, Peter W J},
  journal = {arXiv preprint arXiv:2206.01062},
  year = {2022}
}

%docbank
@article{li2020docbank,
  title={DocBank: A benchmark dataset for document layout analysis},
  author={Li, Minghao and Xu, Yiheng and Cui, Leyang and Huang, Shaohan and Wei, Furu and Li, Zhoujun},
  journal={arXiv preprint arXiv:2006.01038},
  year={2020}
}

%ccocr
@article{yang2024cc,
  title={CC-OCR: A Comprehensive and Challenging OCR Benchmark for Evaluating Large Multimodal Models in Literacy},
  author={Yang, Zhibo and Tang, Jun and Li, Zhaohai and Wang, Pengfei and Wan, Jianqiang and Zhong, Humen and Liu, Xuejing and Yang, Mingkun and Wang, Peng and Liu, Yuliang and others},
  journal={arXiv preprint arXiv:2412.02210},
  year={2024}
}
%AIN
@article{heakl2025ain,
  title={AIN: The Arabic INclusive Large Multimodal Model},
  author={Heakl, Ahmed and Ghaboura, Sara and Thawkar, Omkar and Khan, Fahad Shahbaz and Cholakkal, Hisham and Anwer, Rao Muhammad and Khan, Salman},
  journal={arXiv preprint arXiv:2502.00094},
  year={2025}
}

%peacock
@article{alwajih2024peacock,
  title={Peacock: A Family of Arabic Multimodal Large Language Models and Benchmarks},
  author={Alwajih, Fakhraddin and Nagoudi, El Moatez Billah and Bhatia, Gagan and Mohamed, Abdelrahman and Abdul-Mageed, Muhammad},
  journal={arXiv preprint arXiv:2403.01031},
  year={2024}
}

%GPT-4O
@article{hurst2024gpt,
  title={Gpt-4o system card},
  author={Hurst, Aaron and Lerer, Adam and Goucher, Adam P and Perelman, Adam and Ramesh, Aditya and Clark, Aidan and Ostrow, AJ and Welihinda, Akila and Hayes, Alan and Radford, Alec and others},
  journal={arXiv preprint arXiv:2410.21276},
  year={2024}
}
%GPT-4
@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

%Claude 3.5 Sonnet
@article{anthropic2024claude,
  title={Claude 3.5 sonnet model card addendum},
  author={Anthropic, AI},
  journal={Claude-3.5 Model Card},
  volume={3},
  number={6},
  year={2024}
}
%surya
@misc{paruchuri2024surya,
    author = {Paruchuri, Vik},
    title = {Surya: Accurate line-by-line text detection and recognition in complex documents},
    year = {2024},
    publisher = {GitHub},
    journal = {GitHub repository},
    howpublished = {\url{https://github.com/VikParuchuri/surya}}
}
%marker
@misc{paruchuri2024marker,
    author = {Paruchuri, Vik},
    title = {Marker: Convert PDF to markdown and other formats},
    year = {2024},
    publisher = {GitHub},
    journal = {GitHub repository},
    howpublished = {\url{https://github.com/VikParuchuri/marker}}
}
% docling
@article{auer2024docling,
  title={Docling Technical Report},
  author={Auer, Christoph and Lysak, Maksym and Nassar, Ahmed and Dolfi, Michele and Livathinos, Nikolaos and Vagenas, Panos and Ramis, Cesar Berrospi and Omenetti, Matteo and Lindlbauer, Fabian and Dinkla, Kasper and others},
  journal={arXiv preprint arXiv:2408.09869},
  year={2024}
}
%ppocr
%paddleocr
@article{du2020paddleocr,
  title={Pp-ocr: A practical ultra lightweight ocr system},
  author={Du, Yuning and Li, Chenxia and Guo, Ruoyu and Yin, Xiaoting and Liu, Weiwei and Zhou, Jun and Bai, Yifan and Yu, Zilin and Yang, Yehua and Dang, Qingqing and others},
  journal={arXiv preprint arXiv:2009.09941},
  year={2020}
}
@article{du2021paddleocr,
  title={Pp-ocrv2: Bag of tricks for ultra lightweight ocr system},
  author={Du, Yuning and Li, Chenxia and Guo, Ruoyu and Cui, Cheng and Liu, Weiwei and Zhou, Jun and Lu, Bin and Yang, Yehua and Liu, Qiwen and Hu, Xiaoguang and others},
  journal={arXiv preprint arXiv:2109.03144},
  year={2021}
}
@article{li2022paddleocr,
  title={PP-OCRv3: More attempts for the improvement of ultra lightweight OCR system},
  author={Li, Chenxia and Liu, Weiwei and Guo, Ruoyu and Yin, Xiaoting and Jiang, Kaitao and Du, Yongkun and Du, Yuning and Zhu, Lingfeng and Lai, Baohua and Hu, Xiaoguang and others},
  journal={arXiv preprint arXiv:2206.03001},
  year={2022}
}

%mineru
@article{wang2024mineru,
  title={Mineru: An open-source solution for precise document content extraction},
  author={Wang, Bin and Xu, Chao and Zhao, Xiaomeng and Ouyang, Linke and Wu, Fan and Zhao, Zhiyuan and Xu, Rui and Liu, Kaiwen and Qu, Yuan and Shang, Fukai and others},
  journal={arXiv preprint arXiv:2409.18839},
  year={2024}
}
%tesseract
@inproceedings{smith2007overviewtesseract,
  title={An overview of the Tesseract OCR engine},
  author={Smith, Ray},
  booktitle={Ninth international conference on document analysis and recognition (ICDAR 2007)},
  volume={2},
  pages={629--633},
  year={2007},
  organization={IEEE}
}

%easy ocr
@misc{easyocr,
  author       = {JaidedAI},
  title        = {EasyOCR: Ready-to-use Optical Character Recognition with Multi-language Support},
  year         = {2020},
  howpublished = {\url{https://github.com/JaidedAI/EasyOCR}},
  note         = {Accessed: 2025-02-14}
}

%got:general ocr theory
@article{wei2024general,
  title={General ocr theory: Towards ocr-2.0 via a unified end-to-end model},
  author={Wei, Haoran and Liu, Chenglong and Chen, Jinyue and Wang, Jia and Kong, Lingyu and Xu, Yanming and Ge, Zheng and Zhao, Liang and Sun, Jianjian and Peng, Yuang and others},
journal={arXiv preprint arXiv:2409.01704},
  year={2024}
}

%ocrbench v2
@article{fu2024ocrbench,
  title={OCRBench v2: An Improved Benchmark for Evaluating Large Multimodal Models on Visual Text Localization and Reasoning},
  author={Fu, Ling and Yang, Biao and Kuang, Zhebin and Song, Jiajun and Li, Yuzhe and Zhu, Linghao and Luo, Qidi and Wang, Xinyu and Lu, Hao and Huang, Mingxin and others},
  journal={arXiv preprint arXiv:2501.00321},
  year={2024}
}
@article{Liu2024ocrbench,
    title={OCRBench: on the hidden mystery of OCR in large multimodal models},
    volume={67},
    ISSN={1869-1919},
    url={http://dx.doi.org/10.1007/s11432-024-4235-6},
    DOI={10.1007/s11432-024-4235-6},
    number={12},
    journal={Science China Information Sciences},
    publisher={Springer Science and Business Media LLC},
    author={Liu, Yuliang and Li, Zhang and Huang, Mingxin and Yang, Biao and Yu, Wenwen and Li, Chunyuan and Yin, Xu-Cheng and Liu, Cheng-Lin and Jin, Lianwen and Bai, Xiang},
    year={2024},
    month=dec 
}
%review paper arabic ocr
@article{alghyaline2023arabic,
  title={Arabic Optical Character Recognition: A Review.},
  author={Alghyaline, Salah},
  journal={CMES-Computer Modeling in Engineering \& Sciences},
  volume={135},
  number={3},
  year={2023}
}
@article{bhatia2024qalam,
  title={Qalam: A Multimodal LLM for Arabic Optical Character and Handwriting Recognition},
  author={Bhatia, Gagan and Nagoudi, El Moatez Billah and Alwajih, Fakhraddin and Abdul-Mageed, Muhammad},
  journal={arXiv preprint arXiv:2407.13559},
  year={2024}
}

@inproceedings{waly2024arabic,
  title={Arabic Handwritten Document OCR Solution with Binarization and Adaptive Scale Fusion Detection},
  author={Waly, Alhossien and Tarek, Bassant and Feteha, Ali and Yehia, Rewan and Amr, Gasser and Fares, Ahmed},
  booktitle={2024 6th Novel Intelligent and Leading Emerging Sciences Conference (NILES)},
  pages={316--319},
  year={2024},
  organization={IEEE}
}
@inproceedings{shen2021layoutparser,
  title={Layoutparser: A unified toolkit for deep learning based document image analysis},
  author={Shen, Zejiang and Zhang, Ruochen and Dell, Melissa and Lee, Benjamin Charles Germain and Carlson, Jacob and Li, Weining},
  booktitle={Document Analysis and Recognition--ICDAR 2021: 16th International Conference, Lausanne, Switzerland, September 5--10, 2021, Proceedings, Part I 16},
  pages={131--146},
  year={2021},
  organization={Springer}
}
%BCE-Arabic-v1
@inproceedings{saad2016bce,
  title={BCE-Arabic-v1 dataset: Towards interpreting Arabic document images for people with visual impairments},
  author={Saad, Rana SM and Elanwar, Randa I and Kader, NS Abdel and Mashali, Samia and Betke, Margrit},
  booktitle={Proceedings of the 9th ACM International Conference on PErvasive Technologies Related to Assistive Environments},
  pages={1--8},
  year={2016}
}

@article{deitke2024molmo,
  title={Molmo and pixmo: Open weights and open data for state-of-the-art multimodal models},
  author={Deitke, Matt and Clark, Christopher and Lee, Sangho and Tripathi, Rohun and Yang, Yue and Park, Jae Sung and Salehi, Mohammadreza and Muennighoff, Niklas and Lo, Kyle and Soldaini, Luca and others},
  journal={arXiv preprint arXiv:2409.17146},
  year={2024}
}

@misc{muhtaseb2010pats,
   author = {El-Muhtaseb, Husni A.},
   title = {PATS-A01 - An Arabic Text Database},
   year = {2010},
   institution = {King Fahd University of Petroleum and Minerals},
   howpublished = {\url{https://faculty.kfupm.edu.sa/ics/muhtaseb/ArabicOCR/PATS-A01.htm}},
   note = {Database for Arabic Text Recognition Research}
}

%gemini
@article{team2024gemini,
  title={Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context},
  author={Georgiev, Petko and Lei, Ving Ian and Burnell, Ryan and Bai, Libin and Gulati, Anmol and Tanzer, Garrett and Vincent, Damien and Pan, Zhufeng and Wang, Shibo and others},
  journal={arXiv preprint arXiv:2403.05530},
  year={2024}
}

@misc{google2025gemini,
  author       = "{Google DeepMind}",
  title        = "{Gemini Model Updates - February 2025}",
  year         = 2025,
  url          = "https://blog.google/technology/google-deepmind/gemini-model-updates-february-2025/",
  note         = "Accessed: 2025-02-14"
}
%Charts metric: Structuring Chart-oriented Representation Metric (SCRM)
@article{xia2024chartx,
  title={Chartx \& chartvlm: A versatile benchmark and foundation model for complicated chart reasoning},
  author={Xia, Renqiu and Zhang, Bo and Ye, Hancheng and Yan, Xiangchao and Liu, Qi and Zhou, Hongbin and Chen, Zijun and Dou, Min and Shi, Botian and Yan, Junchi and others},
  journal={arXiv preprint arXiv:2402.12185},
  year={2024}
}

@misc{Llama3.2,
    title = {Llama 3.2: Revolutionizing Edge AI and Vision with Open, Customizable Models},
    url = {https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/},
    author = {Meta AI},
    month = {September},
    year = {2024}
}
%llama3
@article{dubey2024llama,
  title={The llama 3 herd of models},
  author={Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and others},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}

%deepseek vl2
@article{wu2024deepseekvl2,
  title={Deepseek-vl2: Mixture-of-experts vision-language models for advanced multimodal understanding},
  author={Wu, Zhiyu and Chen, Xiaokang and Pan, Zizheng and Liu, Xingchao and Liu, Wen and Dai, Damai and Gao, Huazuo and Ma, Yiyang and Wu, Chengyue and Wang, Bingxuan and others},
  journal={arXiv preprint arXiv:2412.10302},
  year={2024}
}
%internvl2.5
@article{chen2024expanding,
  title={Expanding performance boundaries of open-source multimodal models with model, data, and test-time scaling},
  author={Chen, Zhe and Wang, Weiyun and Cao, Yue and Liu, Yangzhou and Gao, Zhangwei and Cui, Erfei and Zhu, Jinguo and Ye, Shenglong and Tian, Hao and Liu, Zhaoyang and others},
  journal={arXiv preprint arXiv:2412.05271},
  year={2024}
}

%qwen2.5vl
@misc{Qwen2.5-VL,
    title = {Qwen2.5-VL},
    url = {https://qwenlm.github.io/blog/qwen2.5-vl/},
    author = {Qwen Team},
    month = {January},
    year = {2025}
}
%qwen 2 vl
@article{wang2024qwen2,
  title={Qwen2-vl: Enhancing vision-language model's perception of the world at any resolution},
  author={Wang, Peng and Bai, Shuai and Tan, Sinan and Wang, Shijie and Fan, Zhihao and Bai, Jinze and Chen, Keqin and Liu, Xuejing and Wang, Jialin and Ge, Wenbin and others},
  journal={arXiv preprint arXiv:2409.12191},
  year={2024}
}

%pdf extract kit
%wang2024mineru
@misc{zhao2024doclayoutyoloenhancingdocumentlayout,
      title={DocLayout-YOLO: Enhancing Document Layout Analysis through Diverse Synthetic Data and Global-to-Local Adaptive Perception}, 
      author={Zhiyuan Zhao and Hengrui Kang and Bin Wang and Conghui He},
      year={2024},
      eprint={2410.12628},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2410.12628}
}

@misc{wang2024unimernet,
      title={UniMERNet: A Universal Network for Real-World Mathematical Expression Recognition}, 
      author={Bin Wang and Zhuangcheng Gu and Chao Xu and Bo Zhang and Botian Shi and Conghui He},
      year={2024},
      eprint={2404.15254},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{he2024opendatalab,
  title={Opendatalab: Empowering general artificial intelligence with open datasets},
  author={He, Conghui and Li, Wei and Jin, Zhenjiang and Xu, Chao and Wang, Bin and Lin, Dahua},
  journal={arXiv preprint arXiv:2407.13773},
  year={2024}
}
@article{xia2023structchart,
  title={Structchart: Perception, structuring, reasoning for visual chart understanding},
  author={Xia, Renqiu and Zhang, Bo and Peng, Haoyang and Ye, Hancheng and Yan, Xiangchao and Ye, Peng and Shi, Botian and Qiao, Yu and Yan, Junchi},
  journal={arXiv preprint arXiv:2309.11268},
  year={2023}
}

%rtdetr
@article{zhao2023detrs,
  title={Detrs beat YOLOs on real-time object detection. arXiv e-prints},
  author={Zhao, Y and Lv, W and Xu, S and Wei, J and Wang, G and Dang, Q and Liu, Y and Chen, J},
  journal={arXiv preprint arXiv:2304.08069},
  year={2023}
}
%chrf
@inproceedings{popovic2015chrf,
  title={chrF: character n-gram F-score for automatic MT evaluation},
  author={Popovi{\'c}, Maja},
  booktitle={Proceedings of the tenth workshop on statistical machine translation},
  pages={392--395},
  year={2015}
}
%TEDS
@inproceedings{zhong2020image,
  title={Image-based table recognition: data, model, and evaluation},
  author={Zhong, Xu and ShafieiBavani, Elaheh and Jimeno Yepes, Antonio},
  booktitle={European conference on computer vision},
  pages={564--580},
  year={2020},
  organization={Springer}
}

%Timg2table
@misc{img2table,
  author       = {Xavier Cattan},
  title        = {img2table: Extract tables from images and scanned PDFs},
  year         = {2021},
  howpublished = {\url{https://github.com/xavctn/img2table}},
  note         = {Accessed: 2025-02-14}
}
%mtvqa
@misc{tang2024mtvqa,
      title={MTVQA: Benchmarking Multilingual Text-Centric Visual Question Answering}, 
      author={Jingqun Tang and Qi Liu and Yongjie Ye and Jinghui Lu and Shu Wei and Chunhui Lin and Wanqing Li and Mohamad Fitri Faiz Bin Mahmood and Hao Feng and Zhen Zhao and Yanjie Wang and Yuliang Liu and Hao Liu and Xiang Bai and Can Huang},
      year={2024},
      eprint={2405.11985},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
#exam-v
@article{das2024exams,
  title={EXAMS-V: A Multi-Discipline Multilingual Multimodal Exam Benchmark for Evaluating Vision Language Models},
  author={Das, Rocktim Jyoti and Hristov, Simeon Emilov and Li, Haonan and Dimitrov, Dimitar Iliyanov and Koychev, Ivan and Nakov, Preslav},
  journal={arXiv preprint arXiv:2403.10378},
  year={2024}
}