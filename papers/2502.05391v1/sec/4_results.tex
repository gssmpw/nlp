\vspace{-0.2cm}
\section{Experiments: Fast Style-Preserving Guided Generation and Editing}
\label{sec:results} 
\vspace{-0.1cm}

To understand the effect of guidance and inversion of iGCT, we first introduce our baselines, then, present a series of experiments on CIFAR-10 \cite{article} and ImageNet64 \cite{chrabaszcz2017downsampledvariantimagenetalternative} across various guidance scales \(w\) for image generation (Sec. \ref{sec:guidance}) and class-based editing (Sec. \ref{sec:image-editing}). Our analysis mainly focuses on CIFAR-10 compared against CFG and few-step distillation methods as baselines. For training and implementation details on iGCT, please see Appendix \ref{appendix:bs-config}.


\noindent{\bf Baselines.} We compare iGCT with two key baselines: EDM \cite{karras2022elucidating} and CD \cite{song2023consistency}, both widely adopted frameworks for DMs and CMs respectively. The goal is to evaluate iGCT’s performance against multi-step classifier-free guidance (CFG) in DMs, as well as few-step guided CMs. Prior to our work, guidance in consistency models was exclusively achieved through consistency distillation from pretrained DMs, as demonstrated by guided-CD and iCD \cite{luo2023latent,starodubcev2024invertible}. As of writing this paper, iGCT is the first framework to incorporate guidance directly into consistency training, eliminating the need for distillation. Given this, EDM and guided-CD serve as our primary baselines for evaluating guidance performance on CIFAR-10 \cite{article}. Additionally, we conduct image editing experiments using EDM as a baseline by leveraging its invertibility and guidance capabilities. 

We also present results on ImageNet64 \cite{chrabaszcz2017downsampledvariantimagenetalternative}, using EDM as the primary baseline. Due to resource constraints, we exclude guided-CD from this comparison, as distilling a DM model for guided-CD would require approximately twice the computational cost of iGCT from our CIFAR-10 experiments (see Table \ref{table:compute_resources}). This estimate is based on implementing guided-CD following the best configurations outlined in \cite{song2023consistency} and \cite{luo2023latent}. For iGCT, we adopt a smaller ADM architecture \cite{dhariwal2021diffusionmodelsbeatgans}, reducing the width dimensions compared to the default EDM. This adjustment allows us to lower the burden in training iGCT in 190 GPU days on A100 clusters. Additional details about the reimplementation of guided baselines, including CFG-EDM and guided-CD, can be found in Appendix \ref{appendix:bs-config}.


\vspace{-0.3cm}
\subsection{Guidance}
\label{sec:guidance}
\vspace{-0.15cm}

\begin{figure}[t!]  
    \centering
    \begin{subfigure}[b]{0.44\textwidth}
    \includegraphics[width=\textwidth]{fig/results_fid_vs_w.png} 
        \vspace{-1.4em}
        \caption{FID(50k) on different \(w\) scales.}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.45\textwidth}
    \includegraphics[width=\textwidth]{fig/results_precision_recall.png} 
        \vspace{-1.4em}
        \caption{Precision/Recall(50k) on different \(w\) scales.}
    \end{subfigure}
    \vspace{-1em}
    \caption{Adjusting the \(w\) scale for iGCT \textbf{consistently enhances precision}, in contrast to CFG, which experiences declines in both quality and diversity beyond a certain threshold. }
    \vspace{-1.5em}
    \label{fig:results_fid_prec_rec}
\end{figure}

\begin{table}[t]
\centering
\caption{Comparison of guided methods using DMs, distillation models, and iGCT, with the \textcolor{blue}{\textbf{best}} score highlighted in blue. iGCT achieves the best precision and FID under high guidance, e.g., w=7, w=13, while also maintaining a strong recall score, showing its ability to stably tradeoff quality and diversity. }
\label{tab:results_metrics}
\vspace{-0.2cm}
\begin{subtable}{0.49\textwidth}
\centering
\caption{CIFAR-10}
\renewcommand{\arraystretch}{0.2}
\resizebox{0.9\textwidth}{!}{
\begin{tabular}{@{}llcc@{}}
    \midrule
    W Scale & Methods & NFE$\downarrow$ & \makecell[l]{FID$\downarrow$ / Precision$\uparrow$ / Recall$\uparrow$} \\
    \midrule
    \multirow{4}{*}{\makecell[l]{w=1}} & \makecell[l]{CFG-EDM \cite{karras2022elucidating}} & 18 & \textcolor{blue}{\textbf{1.9}} / 0.66 / \textcolor{blue}{\textbf{0.64}} \\
    & \makecell[l]{Guided-CD \cite{song2023consistency}} & 1 & 7.1 / \textcolor{blue}{\textbf{0.74}} / 0.47 \\
    & & 2 & 3.9 / 0.71 / 0.53 \\ 
    & \makecell[l]{iGCT (ours)} & 1 & 4.1 / 0.69 / 0.57 \\
    & & 2 & 3.8 / 0.69 / 0.59 \\ 
    \midrule
    \multirow{4}{*}{\makecell[l]{w=7}} & \makecell[l]{CFG-EDM} & 18 & 23.8 / 0.63 / 0.27 \\
    & \makecell[l]{Guided-CD} & 1 & 21.5 / \textcolor{blue}{\textbf{0.79}} / 0.14 \\
    & & 2 & 21.3 / 0.76 / 0.20 \\ 
    & \makecell[l]{iGCT} & 1 & 10.1 / 0.77 / 0.38 \\
    & & 2 & \textcolor{blue}{\textbf{9.2}} / 0.76 / \textcolor{blue}{\textbf{0.42}} \\ 
    \midrule
    \multirow{4}{*}{\makecell[l]{w=13}} & \makecell[l]{CFG-EDM} & 18 & 32.6 / 0.47 / 0.13 \\
    & \makecell[l]{Guided-CD} & 1 & 33.0 / 0.74 / 0.05 \\
    & & 2 & 32.5 / 0.72 / 0.10 \\ 
    & \makecell[l]{iGCT} & 1 & {14.0} / \textcolor{blue}{\textbf{0.80}} / 0.28 \\
    & & 2 & \textcolor{blue}{\textbf{12.6}} / 0.78 / \textcolor{blue}{\textbf{0.35}} \\ 
    \bottomrule
\end{tabular}
}
\end{subtable}%
\vspace{0.1cm}
\begin{subtable}{0.49\textwidth}
\centering
\caption{ImageNet64}
\renewcommand{\arraystretch}{0.2}
\resizebox{0.9\textwidth}{!}{
\begin{tabular}{@{}llcc@{}}
    \midrule
    W Scale & Methods & NFE$\downarrow$ & \makecell[l]{FID$\downarrow$ / Precision$\uparrow$ / Recall$\uparrow$} \\
    \midrule
    \multirow{4}{*}{\makecell[l]{w=1}} & \makecell[l]{CFG-EDM \cite{karras2022elucidating}} & 18 & \textcolor{blue}{\textbf{3.38}} / \textcolor{blue}{\textbf{0.66}} / \textcolor{blue}{\textbf{0.64}} \\
    & \makecell[l]{iGCT} & 1 & 13.16 / 0.46 / 0.40 \\
    & & 2 & 11.67 / 0.43 / 0.47 \\ 
    \midrule
    \multirow{4}{*}{\makecell[l]{w=7}} & \makecell[l]{CFG-EDM} & 18 & 29.19 / \textcolor{blue}{\textbf{0.63}} / 0.27 \\
    & \makecell[l]{iGCT} & 1 & 15.45 / 0.54 / 0.22 \\
    & & 2 & \textcolor{blue}{\textbf{11.18}} / 0.50 / \textcolor{blue}{\textbf{0.29}} \\ 
    \midrule
    \multirow{4}{*}{\makecell[l]{w=13}} & \makecell[l]{CFG-EDM} & 18 & 29.03 / 0.47 / 0.13 \\
    & \makecell[l]{iGCT} & 1 & 20.78 / \textcolor{blue}{\textbf{0.60}} / 0.14 \\
    & & 2 & \textcolor{blue}{\textbf{13.37}} / 0.54 / \textcolor{blue}{\textbf{0.23}} \\ 
    \bottomrule
\end{tabular}
}
\end{subtable}
\vspace{-2.5em}
\end{table}

We evaluate iGCT using FID, precision and recall \cite{kynkäänniemi2019improvedprecisionrecallmetric} on CIFAR-10 and ImageNet64 across various guidance scales \(w\). All three metrics are computed by comparing 50k generated samples with 50k dataset samples. These metrics provide a consistent basis for evaluating a model's performance on quality and diversity. Fig. \ref{fig:results_guidance} compares guidance methods based on CFG and iGCT. When \(w>1\), both CFG-based methods and iGCT exhibit a trade-off between diversity and quality, with increased unification in background tone and color compared to \(w=1\), i.e., unguided conditional generation. Notably, CFG tends to produce high-contrast colors at higher guidance levels, while iGCT maintains a consistent style. Consequently, iGCT achieves lower FID compared to CD and EDM under high guidance. Adjusting the \(w\) scale for iGCT also consistently enhances precision, while CFG shows declines in both quality and diversity beyond a certain threshold. We plot the FID and precision/recall tradeoff on CIFAR-10 in Fig. \ref{fig:results_fid_prec_rec} and provide additional metric results for both CIFAR-10 and ImageNet64 in Table \ref{tab:results_metrics}.

\vspace{-0.15cm}
\subsection{Inversion-based Image Editing}
\vspace{-0.15cm}
\label{sec:image-editing}
To validate iGCT’s effectiveness in image editing, we conduct inversion-based editing experiments on CIFAR-10 and ImageNet64. We compare class-based editing results across various guidance scales \(w\) on the inversed noise latent. We train a CFG-EDM as baseline that infers the noise latent of a source image with DDIM inversion \cite{mokady2023null} without fine-tuning. The edited image is then generated conditionally on a target class. To perform image editing with iGCT, the noiser predicts the noise latent of a source image, then generates the edited image conditioned on the target class. Our baseline EDM requires 18 NFEs for both inversion and generation, whereas iGCT computes the noise latent in a single step, highlighting its potential for real-time image editing.

For CIFAR-10, we perform cross-class editing by transforming a source image into each target class. With LPIPS, edits are evaluated by measuring \textit{how much feature is preserved from the source}. With CLIP, we measure \textit{the edit's alignment} with the target prompt \textit{"a photo of a \(\{target\_class\_name\}\)"}. We average LPIPS and CLIP scores across edits for each \(w\) and plot the metrics for both iGCT and the baseline in 2D, illustrating the effects of guidance strength in image editing (Fig. \ref{fig:results_editing}). While EDM achieves a higher CLIP score, it alters the style of the original dataset and deviates from the source image. This shift makes the edited result less relevant to the original content, not to mention its cost in inversion and generation. iGCT presents strong potential for fast inversion-based editing by aligning source semantics well and achieving rapid edits in a single step.

With 1,000 classes in ImageNet64, we evaluate cross-class editing within 6 predefined subgroups: automobiles, bears, cats, dogs, vegetables, and wild herbivores from the validation set. For image-editing within each subgroup, we chose 5 distinct classes, e.g., black bear is a class in the bears subgroup, and 50 images per class. Results are shown in Fig. \ref{fig:results_im64_image_editing}, where LPIPS and CLIP scores are plotted on different \(w\) for the editing tasks. Similar to findings on CIFAR-10, CFG drastically alters the style and semantics of the source image under high guidance. In contrast, iGCT aligns essential features with both the source and target classes.

\begin{figure}[t!]  
    \centering
    \begin{subfigure}[b]{0.475\textwidth}
    \includegraphics[width=\textwidth]{fig/results_cross_class.png} 
        \vspace{-1em}
        \caption{Cross-class image editing on CIFAR-10}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.45\textwidth}
    \includegraphics[width=\textwidth]{fig/results_clip_lpips.png} 
        \vspace{-1em}
        \caption{CLIP/LPIPS on different \(w\) scales.}
    \end{subfigure}
    \vspace{-1.1em}
    \caption{iGCT presents strong potential for real-time image editing using CMs. Compared to DM-based methods, iGCT \textbf{aligns source semantics well} and achieves \textbf{rapid edits requiring only a single step.}}
    \label{fig:results_editing}
\vspace{-0.5cm}
\end{figure}

\begin{figure}[t!]  
    \centering
    \begin{subfigure}[b]{0.39\textwidth}
    \includegraphics[width=\textwidth]{fig/results_editing_cat.png} 
        \vspace{-1em}
        \caption{Subgroup: ``cats", CFG-EDM vs iGCT.}
    \end{subfigure}
    
    \begin{subfigure}[b]{0.39\textwidth}
    \includegraphics[width=\textwidth]{fig/results_im64_cats_clip_lpips.png} 
        \vspace{-1em}
        \caption{Subgroup: ``cats", CLIP/LPIPS on w scales.}
    \end{subfigure}
    
    \begin{subfigure}[b]{0.39\textwidth}
    \includegraphics[width=\textwidth]{fig/results_editing_bear.png} 
        \vspace{-1em}
        \caption{Subgroup:``bears", CFG-EDM vs iGCT.}
    \end{subfigure}
    
    \begin{subfigure}[b]{0.39\textwidth}
    \includegraphics[width=\textwidth]{fig/results_im64_bears_clip_lpips.png} 
        \vspace{-1em}
        \caption{Subgroup: ``bears", CLIP/LPIPS on w scales.}
    \end{subfigure}
    \vspace{-1.1em}
    \caption{Comparison of image editing on ImageNet64 subgroups: "cats" and "bears". iGCT requires only 1 step, and aligns more features from the source compared to EDM. }
    \vspace{-1.3em}
    \label{fig:results_im64_image_editing}
\end{figure}



