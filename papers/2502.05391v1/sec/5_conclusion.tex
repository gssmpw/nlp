\vspace{-0.3cm}
\section{Conclusion and Limitation}
\vspace{-0.1cm}

Our proposed iGCT reduces color saturation and artifacts at high guidance levels, offering a data-driven solution for guided image generation in CMs without relying on DMs. We also introduce a novel \textit{noiser} component for efficient image-to-noise mapping, that also enhances the alignment between edited and source images in image editing compared to naive DDIM.

However, iGCT faces several limitations that warrant further exploration. The performance on ImageNet64, for instance, falls short of existing approaches. Additionally, the theory for guided consistency training remains intuitive and informal. Establishing a theoretical mathematical formulation would help clarify why it outperforms alternatives like CFG. Addressing these areas in future work would solidify the method's contributions and open new research directions in this domain. 

\label{sec:conclusion}
