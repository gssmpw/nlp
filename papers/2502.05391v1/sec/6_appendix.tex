\clearpage
\renewcommand{\thefigure}{A\arabic{figure}}
\renewcommand{\thetable}{A\arabic{table}}
\renewcommand{\theequation}{A\arabic{equation}}
\setcounter{figure}{0}
\setcounter{table}{0}
\setcounter{equation}{0}

Our Appendix is organized as follows. First, we present the pseudocode for the key components of iGCT. We also include the proof for unit variance and boundary conditions in preconditioning iGCT's noiser. Next, we detail the training setups for our CIFAR-10 and ImageNet64 experiments. Additionally, we provide ablation studies on using guided synthesized images as data augmentation in image classification. Finally, we present more uncurated results comparing iGCT and CFG-EDM on inversion, editing and guidance, thoroughly of iGCT.

\vspace{-0.2cm}
\label{appendix:iGCT}
\section{Pseudocode for iGCT}
\vspace{-0.2cm}

iGCT is trained under a continuous-time scheduler similar to the one proposed by ECT \cite{ect}. Our noise sampling function follows a lognormal distribution, \(p(t) = \textit{LogNormal}(P_\textit{mean}, P_\textit{std})\), with \(P_\textit{mean}=-1.1\) and \( P_\textit{std}=2.0\). At training, the sampled noise is clamped at \(t_\text{min} = 0.002\) and \(t_\text{max} = 80.0\). Step function \(\Delta t (t)=\frac{t}{2^{\left\lfloor k/d \right\rfloor}}n(t)\), is used to compute the step size from the sampled noise \(t\), with \(k,d\) being the current training iteration and the number of iterations for halfing \(\Delta t\), and \(n(t) = 1 + 8 \sigma(-t)\) is a sigmoid adjusting function. 

In Guided Consistency Training, the guidance mask function determines whether the sampled noise \( t \) should be supervised for guidance training. With probability \( q(t) \in [0,1] \), the update is directed towards the target sample \( \boldsymbol{x}_0^{\text{tar}} \); otherwise, no guidance is applied. In practice, \( q(t) \) is higher in noisier regions and zero in low-noise regions, 
\begin{equation}
    q(t) = 0.9 \cdot \left( \text{clamp} \left( \frac{t - t_{\text{low}}}{t_{\text{high}} - t_{\text{low}}}, 0, 1 \right) \right)^2,
\end{equation}
where \( t_{\text{low}} = 11.0 \) and \( t_{\text{high}} = 14.3 \). For the range of guidance strength, we set \(w_\text{min} = 1\) and \(w_\text{max} = 15\). Guidance strengths are sampled uniformly at training, with \(w_\text{min} = 1\) means no guidance applied. 


\begin{algorithm}
\caption{Guided Consistency Training}
\label{alg:GCT}
\begin{algorithmic}[1]  % Adds line numbers
\setlength{\baselineskip}{0.9\baselineskip} % Adjust line spacing
\INPUT Dataset $\mathcal{D}$, weighting function $\lambda(t)$, noise sampling function $p(t)$, noise range $[t_\text{min}, t_\text{max}]$, step function $\Delta t(t)$, guidance mask function $q(t)$, guidance range $[w_\text{min}, w_\text{max}]$, denoiser $D_\theta$
\STATE \rule{0.96\textwidth}{0.45pt} 
\STATE Sample $(\boldsymbol{x}_0^{\text{src}}, c^{\text{src}}), (\boldsymbol{x}_0^{\text{tar}}, c^{\text{tar}}) \sim \mathcal{D}$ 
\STATE Sample noise $\boldsymbol{z} \sim \mathcal{N}(\boldsymbol{0},\mathbf{I})$, time step $t \sim p(t)$, and guidance weight $w \sim \mathcal{U}(w_\text{min}, w_\text{max})$
\STATE Clamp $t \leftarrow \text{clamp}(t,t_\text{min}, t_\text{max})$
\STATE Compute noisy sample: $\boldsymbol{x}_t = \boldsymbol{x}_0^{\text{src}} + t\boldsymbol{z}$
\STATE Sample $\rho \sim \mathcal{U}(0,1)$  
\vspace{0.3em}
\IF{$\rho > q(t)$}
    \STATE Compute step as normal CT: $\boldsymbol{x}_r = \boldsymbol{x}_t - \Delta t(t) \boldsymbol{z}$
    \STATE Set target class: $c \leftarrow c^{\text{src}}$
\ELSE
    \STATE Compute guided noise: $\boldsymbol{z}^* = (\boldsymbol{x}_t - \boldsymbol{x}_0^{\text{tar}}) / t$
    \STATE Compute guided step: $\boldsymbol{x}_r = \boldsymbol{x}_t - \Delta t(t) [w \boldsymbol{z}^* + (1-w)\boldsymbol{z}]$
    \STATE Set target class: $c \leftarrow c^{\text{tar}}$
\ENDIF
\vspace{0.3em} % Reduces extra vertical space before the loss line
\STATE Compute loss: 
\[
\mathcal{L}_\text{gct} = \lambda(t) \, d(D_{\theta}(\boldsymbol{x}_t, t, c, w), D_{{\theta}^-}(\boldsymbol{x}_r, r, c, w))
\]
\STATE Return $\mathcal{L}_\text{gct}$ 
\end{algorithmic}
\end{algorithm}



A \textit{noiser} trained under \textit{Inverse Consistency Training} maps an image to its latent noise in a single step. In contrast, DDIM Inversion requires multiple steps with a diffusion model to accurately produce an image's latent representation. Since the boundary signal is reversed, spreading from \( t_\text{max} \) down to \( t_\text{min} \), we design the importance weighting function \( \lambda'(t) \) to emphasize higher noise regions, defined as:
\begin{equation}
    \lambda'(t) = \frac{\Delta t (t)}{t_\text{max}},
\end{equation}
where the step size \( \Delta t (t) \) is proportional to the sampled noise level \(t\), and \( t_\text{max} \) is a constant that normalizes the scale of the inversion loss. The noise sampling function \( p(t) \) and the step function \( \Delta t (t) \) used in computing both \(\mathcal{L}_\text{gct}\) and \(\mathcal{L}_\text{ict}\) are the same.



\begin{algorithm}
\caption{Inverse Consistency Training}
\label{alg:iCT}
\begin{algorithmic}[1]  % Adds line numbers
\setlength{\baselineskip}{0.9\baselineskip} % Adjust line spacing
\INPUT Dataset $\mathcal{D}$, weighting function $\lambda'(t)$, noise sampling function $p(t)$, noise range $[t_\text{min}, t_\text{max}]$, step function $\Delta t(t)$, noiser $N_\varphi$
\STATE \rule{0.96\textwidth}{0.45pt} 
\STATE Sample $\boldsymbol{x}_0, c \sim \mathcal{D}$ 
\STATE Sample noise $\boldsymbol{z} \sim \mathcal{N}(\boldsymbol{0},\mathbf{I})$, time step $t \sim p(t)$
\STATE Clamp $t \leftarrow \text{clamp}(t,t_\text{min}, t_\text{max})$
\STATE Compute noisy sample: $\boldsymbol{x}_t = \boldsymbol{x}_0 + t\boldsymbol{z}$
\STATE Compute cleaner sample: $\boldsymbol{x}_r = \boldsymbol{x}_t - \Delta t(t) \boldsymbol{z}$
\vspace{0.3em} 
\STATE Compute loss: 
\[
\mathcal{L}_\text{ict} = \lambda'(t) \, d(N_{\varphi}(\boldsymbol{x}_r, r, c), D_{{\varphi}^-}(\boldsymbol{x}_t, t, c))
\]
\STATE Return $\mathcal{L}_\text{ict}$ 
\end{algorithmic}
\end{algorithm}

Together, iGCT jointly optimizes the two consistency objectives \(\mathcal{L}_\text{gct}, \mathcal{L}_\text{ict}\), and aligns the noiser and denoiser via a reconstruction loss, \(\mathcal{L}_\text{recon}\). To improve training efficiency, \(\mathcal{L}_\text{recon}\) is computed every \(i_\text{skip}\), reducing the computational cost of back-propagation through both the weights of the \textit{denoiser} \(\theta\) and the \textit{noiser} \(\varphi\). Alg. \ref{alg:iGCT} provides an overview of iGCT. 

\begin{algorithm}
\caption{iGCT}
\label{alg:iGCT}
\begin{algorithmic}[1]  % Adds line numbers
\setlength{\baselineskip}{0.9\baselineskip} % Adjust line spacing
\INPUT Dataset $\mathcal{D}$, learning rate $\eta$, weighting functions $\lambda'(t), \lambda(t), \lambda_{\text{recon}}$, noise sampling function $p(t)$, noise range $[t_\text{min}, t_\text{max}]$, step function $\Delta t(t)$, guidance mask function $q(t)$, guidance range $[w_\text{min}, w_\text{max}]$, reconstruction skip iters $i_\text{skip}$, models $N_\varphi, D_\theta$
\STATE \rule{0.9\textwidth}{0.45pt}  % Horizontal line to separate input from main algorithm
\STATE \textbf{Init:} $\theta, \varphi$, $\text{Iters} = 0$
\REPEAT
\STATE Do guided consistency training 
\[
\mathcal{L}_\text{gct}(\theta;\mathcal{D},\lambda(t),p(t),t_\text{min},t_\text{max},\Delta t(t),q(t),w_\text{min},w_\text{max})
\]
\STATE Do inverse consistency training
\[
\mathcal{L}_\text{ict}(\varphi;\mathcal{D},\lambda'(t),p(t),t_\text{min},t_\text{max},\Delta t(t))
\]
\IF{$(\text{Iters} \ \% \ i_\text{skip}) == 0$}
\STATE Compute reconstruction loss
\[
\mathcal{L}_\text{recon} = d(D_{\theta}(N_{\varphi}(\boldsymbol{x}_0,t_\text{min},c),t_\text{max},c,0), \boldsymbol{x}_0)
\]
\ELSE
\STATE \[
\mathcal{L}_\text{recon} = 0
\]
\ENDIF
\STATE Compute total loss: 
\[
\mathcal{L} = \mathcal{L}_\text{gct} + \mathcal{L}_\text{ict} + \lambda_{\text{recon}}\mathcal{L}_\text{recon}
\]
\STATE $\theta \leftarrow \theta - \eta \nabla_{\theta} \mathcal{L}, \ \varphi \leftarrow \varphi - \eta \nabla_{\varphi} \mathcal{L}$
\STATE $\text{Iters} = \text{Iters} + 1$
\UNTIL{$\Delta t \rightarrow dt$}
\end{algorithmic}
\end{algorithm}



\vspace{-0.3cm}
\section{Preconditioning for Noiser}
\label{appendix:unit-variance}
\vspace{-0.1cm}

We define 
\begin{equation}
    N_{\varphi}(\boldsymbol{x}_t, t, c) = c_\text{skip}(t) \, \boldsymbol{x}_t + c_\text{out}(t) \, F_{\varphi}(c_\text{in}(t) \, \boldsymbol{x}_t, t, c),
\end{equation}
where \( c_\text{in}(t) = \frac{1}{\sqrt{t^2 + \sigma_\text{data}^2}} \), \( c_\text{skip}(t) = 1 \), and \( c_\text{out}(t) = t_\text{max} - t \). This setup naturally serves as a boundary condition. Specifically:

\begin{itemize}
    \item When \( t = 0 \),
    \begin{equation}
        c_\text{out}(0) = t_\text{max} \gg c_\text{skip}(0) = 1,
    \end{equation}
    emphasizing that the model's noise prediction dominates the residual information given a relatively clean sample.

    \item When \( t = t_\text{max} \),
    \begin{equation}
        N_{\varphi}(\boldsymbol{x}_{t_\text{max}}, t_\text{max}, c) = \boldsymbol{x}_{t_\text{max}},
    \end{equation}
    satisfying the condition that \( N_{\varphi} \) outputs \( \boldsymbol{x}_{t_\text{max}} \) at the maximum time step.
\end{itemize}



We show that these preconditions ensure unit variance for the modelâ€™s input and target. First, \(\text{Var}_{\boldsymbol{x}_0, z}[\boldsymbol{x}_t] = \sigma_\text{data}^2 + t^2\), so setting \( c_\text{in}(t) = \frac{1}{\sqrt{\sigma_\text{data}^2 + t^2}} \) normalizes the input variance to 1. Second, we require the training target to have unit variance. Given the noise target for \( N_{\varphi} \) is \(\boldsymbol{x}_{t_\text{max}} = \boldsymbol{x}_0 + t_\text{max} z\), by moving of terms, the effective target for \( F_{\varphi} \) can be written as,
\begin{equation}
    \frac{\boldsymbol{x}_{t_\text{max}} - c_\text{skip}(t)\boldsymbol{x}_{t}}{c_\text{out}(t)}
\end{equation}
When \(c_\text{skip}(t) = 1\), \(c_\text{out}(t) = t_\text{max} - t \), we verify that target is unit variance,
\begin{align}
    &\text{Var}_{\boldsymbol{x}_0, \boldsymbol{z}} \left[ \frac{\boldsymbol{x}_{t_\text{max}} - c_\text{skip}(t) \, \boldsymbol{x}_{t}}{c_\text{out}(t)} \right] \\ \notag
    = \ &\text{Var}_{\boldsymbol{x}_0, \boldsymbol{z}} \left[ \frac{\boldsymbol{x}_0 + t_\text{max} \, \boldsymbol{z} - (\boldsymbol{x}_0 + t \, \boldsymbol{z})}{t_\text{max} - t} \right] \notag \\
    = \ &\text{Var}_{\boldsymbol{x}_0, \boldsymbol{z}} \left[ \frac{(t_\text{max} - t) \, \boldsymbol{z}}{t_\text{max} - t} \right] \notag \\
    = \ &\text{Var}_{\boldsymbol{x}_0, \boldsymbol{z}}[\boldsymbol{z}] \notag \\
    = \ &1. \notag
\end{align}

\vspace{-0.3cm}
\section{Baselines \& Training Details}
\label{appendix:bs-config}
\vspace{-0.1cm}

\begin{figure}[t!]  
    \centering
    \begin{subfigure}[b]{0.33\textwidth}
    \includegraphics[width=\textwidth]{fig/appendix/guidance_embed.pdf} 
        \caption{Guidance embedding.}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.33\textwidth}
    \includegraphics[width=\textwidth]{fig/appendix/adm_arch.pdf} 
        \caption{NCSN++ architecture.}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.33\textwidth}
    \includegraphics[width=\textwidth]{fig/appendix/ncsnpp_arch.pdf} 
        \caption{ADM architecture.}
    \end{subfigure}
    \hfill
    \caption{Design of guidance embedding, and conditioning under different network architectures.}
    \vspace{-1em}
    \label{fig:guidance_conditioning}
\end{figure}

For our diffusion model baseline, we follow \textit{EDM}'s official repository (\href{https://github.com/NVlabs/edm}{https://github.com/NVlabs/edm}) instructions for training and set \textit{label\_dropout} to 0.1 to optimize a CFG (classifier-free guided) DM. We will use this DM as the teacher model for our consistency model baseline via consistency distillation. 

The consistency model baseline \textit{Guided CD} is trained with a discrete-time schedule. We set the discretization steps \( N = 18 \) and use a Heun ODE solver to predict update directions based on the CFG EDM, as in \cite{song2023consistency}. Following \cite{luo2023latent}, we modify the model's architecture and iGCT's denoiser to accept guidance strength \(w\) by adding an extra linear layer. See the detailed architecture design for guidance conditioning of consistency model in Fig. \ref{fig:guidance_conditioning}. A range of guidance scales \(w \in [1,15]\) is uniformly sampled at training. Following \cite{song2023improved}, we replace LPIPS by Pseudo-Huber loss, with \(c=0.03 \) determining the breadth of the smoothing section between L1 and L2. See Table \ref{tab:training_configs} for a summary of the training configurations for our baseline models.


\begin{table}[t!]
\centering
\renewcommand{\arraystretch}{1.3} % Adjust vertical spacing
\small % Reduce text size
\caption{Summary of training configurations for baseline models.}
\begin{tabular}{lccc}
\toprule
\multirow{2}{*}{} & \multicolumn{2}{c}{\textbf{CIFAR-10}} & \textbf{ImageNet64}  \\
                  & EDM & Guided-CD & EDM \\
\midrule
\multicolumn{4}{l}{\textbf{\small Arch. config.}} \\
\hline
model arch.        & NCSN++ & NCSN++ & ADM     \\
channels mult.     & 2,2,2  & 2,2,2  & 1,2,3,4 \\
UNet size          & 56.4M  & 56.4M  & 295.9M  \\
\midrule
\multicolumn{4}{l}{\textbf{\small Training config.}} \\
\hline
lr             & 1e-3  & 4e-4  & 2e-4 \\
batch          & 512   & 512   & 4096 \\
dropout        & 0.13  & 0     & 0.1 \\
label dropout  & 0.1   & (n.a.) & 0.1 \\
loss           & L2    & Huber & L2    \\
training iterations & 390k  & 800k  & 800K \\
\bottomrule
\end{tabular}
\label{tab:training_configs}
\end{table}


\begin{table}[t!]
\centering
\renewcommand{\arraystretch}{1.3} % Adjust vertical spacing
\small % Reduce text size
\caption{Summary of training configurations for iGCT.}
\begin{tabular}{lcc}
\toprule
\multirow{2}{*}{} & \textbf{CIFAR-10} & \textbf{ImageNet64}  \\
                  & iGCT & iGCT \\
\midrule
\multicolumn{3}{l}{\textbf{\small Arch. config.}} \\
\hline
model arch.        & NCSN++ & ADM \\
channels mult.     & 2,2,2  & 1,2,2,3 \\
UNet size          & 56.4M  & 182.4M \\ 
Total size         & 112.9M & 364.8M \\ 
\midrule
\multicolumn{3}{l}{\textbf{\small Training config.}} \\
\hline
lr              & 1e-4 & 1e-4 \\
batch           & 1024 & 1024 \\
dropout            & 0.2 & 0.3 \\
loss               & Huber   & Huber \\
\(c\)                  & 0.03    &  0.06 \\
\(d\)                  & 40k     &  40k \\
\( P_\textit{mean} \) & -1.1 &  -1.1 \\
\( P_\textit{std} \) &  2.0  &  2.0  \\
\( \lambda_{\text{recon}} \) & 2e-5 & \parbox[t]{3.5cm}{\centering 2e-5, (\(\leq\) 180k)\\ 4e-5, (\(\leq\) 200k)\\ 6e-5, (\(\leq\) 260k) } \\  
\( i_{\text{skip}} \)        & 10 &  10 \\  
training iterations & 360k &  260k \\
\bottomrule
\end{tabular}
\label{tab:igct_training_configs}
\end{table}  

\begin{figure*}[t] 
    \centering
    \includegraphics[width=1.0\textwidth]{fig/appendix/inversion_collapse.pdf} 
    \caption{Inversion collapse observed during training on ImageNet64. The left image shows the input data. The middle image depicts the inversion collapse that occurred at iteration 220k, where leakage of signals in the noise latent can be visualized. The right image shows the inversion results at iteration 220k after appropriately increasing $\lambda_{\text{recon}}$ to 6e-5. The inversion images are generated by scaling the model's outputs by $1/80$, i.e., $ 1/t_\text{max}$, then clipping the values to the range [-3, 3] before denormalizing them to the range [0, 255]. }
    \vspace{-1.5em}
    \label{fig:inversion_collpase}
\end{figure*}

iGCT is trained with a continuous-time scheduler inspired by ECT \cite{ect}. To rigorously assess its independence from diffusion-based models, iGCT is trained from scratch rather than fine-tuned from a pre-trained diffusion model. Consequently, the training curriculum begins with an initial diffusion training stage, followed by consistency training with the step size halved every \(d\) iterations. In practice, we adopt the same noise sampling distribution \(p(t)\), same step function \(\Delta t (t) \), and same distance metric \( d(\cdot, \cdot) \) for both guided consistency training and inverse consistency training. 

For CIFAR-10, iGCT adopts the same UNet architecture as the baseline models. However, the overall model size is doubled, as iGCT comprises two UNets: one for the denoiser and one for the noiser. The Pseudo-Huber loss is employed as the distance metric, with a constant parameter \( c = 0.03 \). Consistency training is organized into nine stages, each comprising 400k iterations with the step size halved from the last stage. We found that training remains stable when the reconstruction weight \( \lambda_{\text{recon}} \) is fixed at \( 2 \times 10^{-5} \) throughout the entire training process.
 
For ImageNet64, iGCT employs a reduced ADM architecture \cite{dhariwal2021diffusionmodelsbeatgans} with smaller channel sizes to address computational constraints. A higher dropout rate and Pseudo-Huber loss with \( c = 0.06 \) is used, following prior works \cite{ect,song2023improved}. During our experiments, we observed that training on ImageNet64 is sensitive to the reconstruction weight. Keeping \(\lambda_{\text{recon}}\) fixed throughout training leads to inversion collapse, with significant signal leaked to the latent noise (see Fig. \ref{fig:inversion_collpase}). We found that increasing \(\lambda_{\text{recon}}\) to \( 4 \times 10^{-5} \) at iteration 1800 and to \( 6 \times 10^{-5} \) at iteration 2000 effectively stabilizes training and prevents collapse. This suggests that the reconstruction loss serves as a regularizer for iGCT. Additionally, we observed diminishing returns when training exceeded 240k iterations, leading us to stop at 260k iterations for our experiments. These findings indicate that alternative training strategies, such as framing iGCT as a multi-task learning problem \cite{kendall2018multi,liu2019loss}, and conducting a more sophisticated analysis of loss weighting, may be necessary to enhance stability and improve convergence. See Table \ref{tab:igct_training_configs} for a summary of the training configurations for iGCT.



\begin{table}[t]
\caption{Comparison of GPU hours across the methods used in our experiments on CIFAR-10.}
\centering
\begin{tabular}{|l|c|}
\hline
\textbf{Methods} & \textbf{A100 (40G) GPU hours} \\ \hline
CFG-EDM \cite{karras2022elucidating} & 312 \\ \hline
Guided-CD \cite{song2023consistency} & 3968 \\ \hline
iGCT (ours) & 2032 \\ \hline
\end{tabular}
\label{table:compute_resources}
\end{table}



\begin{figure*}[t!]  
    \centering
    \begin{subfigure}[b]{0.33\textwidth}
    \includegraphics[width=\textwidth]{fig/cls_exp_w1.png} 
        \caption{Accuracy on various ratios of augmented data, guidance scale w=1.}
    \end{subfigure}
    \begin{subfigure}[b]{0.33\textwidth}
    \includegraphics[width=\textwidth]{fig/cls_exp_w3.png} 
        \caption{Accuracy on various ratios of augmented data, guidance scale w=3.}
    \end{subfigure}
    \begin{subfigure}[b]{0.33\textwidth}
    \includegraphics[width=\textwidth]{fig/cls_exp_w5.png} 
        \caption{Accuracy on various ratios of augmented data, guidance scale w=5.}
    \end{subfigure}
    \begin{subfigure}[b]{0.33\textwidth}
    \includegraphics[width=\textwidth]{fig/cls_exp_w7.png} 
        \caption{Accuracy on various ratios of augmented data, guidance scale w=7.}
    \end{subfigure}
    \begin{subfigure}[b]{0.33\textwidth}
    \includegraphics[width=\textwidth]{fig/cls_exp_w9.png} 
        \caption{Accuracy on various ratios of augmented data, guidance scale w=9.}
    \end{subfigure}
    \caption{Comparison of synthesized methods, CFG-EDM vs iGCT, used for data augmentation in image classification. iGCT consistently improves accuracy. Conversely, augmentation data synthesized from CFG-EDM offers only limited gains.}
    \vspace{-1.5em}
    \label{fig:cls_results}
\end{figure*}


\vspace{-0.1cm}
\section{Application: Data Augmentation Under Different Guidance}
\vspace{-0.2cm}

In this section, we show the effectiveness of data augmentation with diffusion-based models, CFG-EDM and iGCT, across varying guidance scales for image classification on CIFAR-10 \cite{article}. High quality data augmentation has been shown to enhance classification performance \cite{yang2023imagedataaugmentationdeep}. Under high guidance, augmentation data generated from iGCT consistently improves accuracy. Conversely, augmentation data synthesized from CFG-EDM offers only limited gains. We describe the ratios of real to synthesized data, the classifier architecture, and the training setup in the following. 

\noindent{\bf Training Details.} We conduct classification experiments trained on six different mixtures of augmented data synthesized by iGCT and CFG-EDM: \(0\%\), \(20\%\), \(40\%\), \(80\%\), and \(100\%\). The ratio represents \(\textit{synthesized data} / \textit{real data}\). For example, \(0\%\) indicates that the training and validation sets contain only 50k of real samples from CIFAR-10, and \(20\%\) includes 50k real \textit{and} 10k synthesized samples. In terms of guidance scales, we choose \(w=1,3,5,7,9\) to synthesize the augmented data using iGCT and CFG-EDM. 
The augmented dataset is split 80/20 for training and validation. For testing, the model is evaluated on the CIFAR-10 test set with 10k samples and ground truth labels. 

The standard ResNet-18 \cite{he2015deepresiduallearningimage} is used to train on all different augmented datasets. All models are trained for 250 epochs, with batch size 64, using an Adam optimizer \cite{kingma2017adammethodstochasticoptimization}. For each augmentation dataset, we train the model six times under different seeds and report the average classification accuracy.

\noindent{\bf Results.} The classifier's accuracy, trained on augmented data synthesized by CFG-EDM and iGCT, is shown in Fig. \ref{fig:cls_results}. With \(w=1\) (no guidance), both iGCT and CFG-EDM provide comparable performance boosts. As guidance scale increases, iGCT shows more significant improvements than CFG-EDM. At high guidance and augmentation ratios, performance drops, but this effect occurs later for iGCT (e.g., at \(100\%\) augmentation and \(w=9\)), while CFG-EDM stops improving accuracy at \(w=7\). This experiment highlights the importance of high-quality data under high guidance, with iGCT outperforming CFG-EDM in data quality.

\section{Uncurated Results}
In this section, we present additional qualitative results to highlight the performance of our proposed iGCT method compared to the multi-step EDM baseline. These visualizations include both inversion and guidance tasks across the CIFAR-10 and ImageNet64 datasets. The results demonstrate iGCT's ability to maintain competitive quality with significantly fewer steps and minimal artifacts, showcasing the effectiveness of our approach.

\subsection{Inversion Results}
We provide additional visualization of the latent noise on both CIFAR-10 and ImageNet64 datasets. Fig. \ref{fig:CIFAR-10_inversion_reconstruction} and Fig. \ref{fig:im64_inversion_reconstruction} compare our 1-step iGCT with the multi-step EDM on inversion and reconstruction.  

\subsection{Editing Results}
In this section, we dump more uncurated editing results on ImageNet64's subgroups mentioned in Sec. \ref{sec:image-editing}. Fig. \ref{fig:im64_edit_1}--\ref{fig:im64_edit_4} illustrate a comparison between our 1-step iGCT and the multi-step EDM approach.

\subsection{Guidance Results}
In Section \ref{sec:guidance}, we demonstrated that iGCT provides a guidance solution without introducing the high-contrast artifacts commonly observed in CFG-based methods. Here, we present additional uncurated results on CIFAR-10 and ImageNet64. For CIFAR-10, iGCT achieves competitive performance compared to the baseline diffusion model, which requires multiple steps for generation. See Figs. \ref{fig:CIFAR-10_guided_1}--\ref{fig:CIFAR-10_guided_10}. For ImageNet64, although the visual quality of iGCT's generated images falls slightly short of expectations, this can be attributed to the smaller UNet architecture usedâ€”only 61\% of the baseline model sizeâ€”and the need for a more robust training curriculum to prevent collapse, as discussed in Section \ref{appendix:bs-config}. Nonetheless, even at higher guidance levels, iGCT maintains style consistency, whereas CFG-based methods continue to suffer from pronounced high-contrast artifacts. See Figs. \ref{fig:im64_guided_1}--\ref{fig:im64_guided_4}.


\begin{figure*}[t]
    \centering
    \begin{subfigure}{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{fig/appendix/recon_c10_data.png}
        \caption{CIFAR-10: Original data}
    \end{subfigure}
    \begin{subfigure}{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{fig/appendix/recon_im64_data.png}
        \caption{ImageNet64: Original data}
    \end{subfigure}

    \begin{subfigure}{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{fig/appendix/inv_c10_edm.png}
    \end{subfigure}
    \begin{subfigure}{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{fig/appendix/inv_im64_edm.png}
    \end{subfigure}

    \begin{subfigure}{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{fig/appendix/recon_c10_edm.png}
        \caption{CIFAR-10: Inversion + reconstruction, EDM (18 NFE)}
    \end{subfigure}
    \begin{subfigure}{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{fig/appendix/recon_im64_edm.png}
        \caption{ImageNet64: Inversion + reconstruction, EDM (18 NFE)}
    \end{subfigure}

    \begin{subfigure}{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{fig/appendix/inv_c10_igct.png}
    \end{subfigure}
    \begin{subfigure}{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{fig/appendix/inv_im64_igct.png}
    \end{subfigure}

    \begin{subfigure}{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{fig/appendix/recon_c10_igct.png}
        \caption{CIFAR-10: Inversion + reconstruction, iGCT (1 NFE)}
    \end{subfigure}
    \begin{subfigure}{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{fig/appendix/recon_im64_igct.png}
        \caption{ImageNet64: Inversion + reconstruction, iGCT (1 NFE)}
    \end{subfigure}

    \caption{Comparison of inversion and reconstruction for CIFAR-10 (left) and ImageNet64 (right).}
    \label{fig:comparison_CIFAR-10_imagenet64}
\end{figure*}




\begin{figure*}[t]
    \centering

    % Left column: corgi -> golden retriever
    \begin{minipage}{0.48\textwidth}
        \centering
        \begin{subfigure}{0.48\textwidth}
            \includegraphics[width=\linewidth]{fig/appendix_edit_igct/src_corgi.png}
            \caption{Original: "corgi"}
        \end{subfigure}

        \begin{subfigure}{0.48\textwidth}
            \includegraphics[width=\linewidth]{fig/appendix_edit_edm/w=0_src_corgi_tar_golden_retriever.png}
            \caption{EDM (18 NFE), w=1}
        \end{subfigure}
        \begin{subfigure}{0.48\textwidth}
            \includegraphics[width=\linewidth]{fig/appendix_edit_edm/w=6_src_corgi_tar_golden_retriever.png}
            \caption{EDM (18 NFE), w=7}
        \end{subfigure}
        \begin{subfigure}{0.48\textwidth}
            \includegraphics[width=\linewidth]{fig/appendix_edit_igct/w=6_src_corgi_tar_golden_retriever.png}
            \caption{iGCT (1 NFE), w=7}
        \end{subfigure}
        \begin{subfigure}{0.48\textwidth}
            \includegraphics[width=\linewidth]{fig/appendix_edit_igct/w=0_src_corgi_tar_golden_retriever.png}
            \caption{iGCT (1 NFE), w=1}
        \end{subfigure}

        \caption{ImageNet64: "corgi" $\rightarrow$ "golden retriever"}
        \label{fig:im64_edit_1}
    \end{minipage}
    \hfill
    % Right column: zebra -> horse
    \begin{minipage}{0.48\textwidth}
        \centering
        \begin{subfigure}{0.48\textwidth}
            \includegraphics[width=\linewidth]{fig/appendix_edit_igct/src_zebra.png}
            \caption{Original: "zebra"}
        \end{subfigure}

        \begin{subfigure}{0.48\textwidth}
            \includegraphics[width=\linewidth]{fig/appendix_edit_edm/w=0_src_zebra_tar_horse.png}
            \caption{EDM (18 NFE), w=1}
        \end{subfigure}
        \begin{subfigure}{0.48\textwidth}
            \includegraphics[width=\linewidth]{fig/appendix_edit_edm/w=6_src_zebra_tar_horse.png}
            \caption{EDM (18 NFE), w=7}
        \end{subfigure}
        \begin{subfigure}{0.48\textwidth}
            \includegraphics[width=\linewidth]{fig/appendix_edit_igct/w=0_src_zebra_tar_horse.png}
            \caption{iGCT (1 NFE), w=1}
        \end{subfigure}
        \begin{subfigure}{0.48\textwidth}
            \includegraphics[width=\linewidth]{fig/appendix_edit_igct/w=6_src_zebra_tar_horse.png}
            \caption{iGCT (1 NFE), w=7}
        \end{subfigure}

        \caption{ImageNet64: "zebra" $\rightarrow$ "horse"}
        \label{fig:im64_edit_2}
    \end{minipage}

\end{figure*}

\begin{figure*}[t]
    \centering

    % Left column: broccoli -> cauliflower
    \begin{minipage}{0.48\textwidth}
        \centering
        \begin{subfigure}{0.48\textwidth}
            \includegraphics[width=\linewidth]{fig/appendix_edit_igct/src_broccoli.png}
            \caption{Original: "broccoli"}
        \end{subfigure}

        \begin{subfigure}{0.48\textwidth}
            \includegraphics[width=\linewidth]{fig/appendix_edit_edm/w=0_src_broccoli_tar_cauliflower.png}
            \caption{EDM (18 NFE), w=1}
        \end{subfigure}
        \begin{subfigure}{0.48\textwidth}
            \includegraphics[width=\linewidth]{fig/appendix_edit_edm/w=6_src_broccoli_tar_cauliflower.png}
            \caption{EDM (18 NFE), w=7}
        \end{subfigure}
        \begin{subfigure}{0.48\textwidth}
            \includegraphics[width=\linewidth]{fig/appendix_edit_igct/w=0_src_broccoli_tar_cauliflower.png}
            \caption{iGCT (1 NFE), w=1}
        \end{subfigure}
        \begin{subfigure}{0.48\textwidth}
            \includegraphics[width=\linewidth]{fig/appendix_edit_igct/w=6_src_broccoli_tar_cauliflower.png}
            \caption{iGCT (1 NFE), w=7}
        \end{subfigure}

        \caption{ImageNet64: "broccoli" $\rightarrow$ "cauliflower"}
        \label{fig:im64_edit_3}
    \end{minipage}
    \hfill
    % Right column: jaguar -> tiger
    \begin{minipage}{0.48\textwidth}
        \centering
        \begin{subfigure}{0.48\textwidth}
            \includegraphics[width=\linewidth]{fig/appendix_edit_igct/src_jaguar.png}
            \caption{Original: "jaguar"}
        \end{subfigure}

        \begin{subfigure}{0.48\textwidth}
            \includegraphics[width=\linewidth]{fig/appendix_edit_edm/w=0_src_jaguar_tar_tiger.png}
            \caption{EDM (18 NFE), w=1}
        \end{subfigure}
        \begin{subfigure}{0.48\textwidth}
            \includegraphics[width=\linewidth]{fig/appendix_edit_edm/w=6_src_jaguar_tar_tiger.png}
            \caption{EDM (18 NFE), w=7}
        \end{subfigure}
        \begin{subfigure}{0.48\textwidth}
            \includegraphics[width=\linewidth]{fig/appendix_edit_igct/w=0_src_jaguar_tar_tiger.png}
            \caption{iGCT (1 NFE), w=1}
        \end{subfigure}
        \begin{subfigure}{0.48\textwidth}
            \includegraphics[width=\linewidth]{fig/appendix_edit_igct/w=6_src_jaguar_tar_tiger.png}
            \caption{iGCT (1 NFE), w=7}
        \end{subfigure}

        \caption{ImageNet64: "jaguar" $\rightarrow$ "tiger"}
        \label{fig:im64_edit_4}
    \end{minipage}

\end{figure*}






\begin{figure*}[b]
    \centering
    % First image
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_edm/0_0.0_middle_4x4_grid.png}
        \caption{CFG-EDM (18 NFE), w=1.0}
    \end{subfigure}
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_edm/0_6.0_middle_4x4_grid.png}
        \caption{CFG-EDM (18 NFE), w=7.0}
    \end{subfigure}
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_edm/0_12.0_middle_4x4_grid.png}
        \caption{CFG-EDM (18 NFE), w=13.0}
    \end{subfigure}
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_igct/0_0.0_middle_4x4_grid.png}
        \caption{iGCT (1 NFE), w=1.0}
    \end{subfigure}
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_igct/0_6.0_middle_4x4_grid.png}
        \caption{iGCT (1 NFE), w=7.0}
    \end{subfigure}
    % Third image
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_igct/0_12.0_middle_4x4_grid.png}
        \caption{iGCT (1 NFE), w=13.0}
    \end{subfigure}
    \caption{CIFAR-10 "airplane"}
    \label{fig:CIFAR-10_guided_1}
\end{figure*}
\begin{figure*}[t]
    \centering
    % First image
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_edm/1_0.0_middle_4x4_grid.png}
        \caption{CFG-EDM (18 NFE), w=1.0}
    \end{subfigure}
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_edm/1_6.0_middle_4x4_grid.png}
        \caption{CFG-EDM (18 NFE), w=7.0}
    \end{subfigure}
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_edm/1_12.0_middle_4x4_grid.png}
        \caption{CFG-EDM (18 NFE), w=13.0}
    \end{subfigure}
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_igct/1_0.0_middle_4x4_grid.png}
        \caption{iGCT (1 NFE), w=1.0}
    \end{subfigure}
    % Second image
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_igct/1_6.0_middle_4x4_grid.png}
        \caption{iGCT (1 NFE), w=7.0}
    \end{subfigure}
    % Third image
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_igct/1_12.0_middle_4x4_grid.png}
        \caption{iGCT (1 NFE), w=13.0}
    \end{subfigure}
    \caption{CIFAR-10 "car"}
    \label{fig:CIFAR-10_guided_2}
\end{figure*}
\begin{figure*}[t]
    \centering
    % First image
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_edm/2_0.0_middle_4x4_grid.png}
        \caption{CFG-EDM (18 NFE), w=1.0}
    \end{subfigure}
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_edm/2_6.0_middle_4x4_grid.png}
        \caption{CFG-EDM (18 NFE), w=7.0}
    \end{subfigure}
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_edm/2_12.0_middle_4x4_grid.png}
        \caption{CFG-EDM (18 NFE), w=13.0}
    \end{subfigure}
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_igct/2_0.0_middle_4x4_grid.png}
        \caption{iGCT (1 NFE), w=1.0}
    \end{subfigure}
    % Second image
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_igct/2_6.0_middle_4x4_grid.png}
        \caption{iGCT (1 NFE), w=7.0}
    \end{subfigure}
    % Third image
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_igct/2_12.0_middle_4x4_grid.png}
        \caption{iGCT (1 NFE), w=13.0}
    \end{subfigure}
    \caption{CIFAR-10 "bird"}
    \label{fig:CIFAR-10_guided_3}
\end{figure*}
\begin{figure*}[t]
    \centering
    % First image
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_edm/3_0.0_middle_4x4_grid.png}
        \caption{CFG-EDM (18 NFE), w=1.0}
    \end{subfigure}
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_edm/3_6.0_middle_4x4_grid.png}
        \caption{CFG-EDM (18 NFE), w=7.0}
    \end{subfigure}
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_edm/3_12.0_middle_4x4_grid.png}
        \caption{CFG-EDM (18 NFE), w=13.0}
    \end{subfigure}
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_igct/3_0.0_middle_4x4_grid.png}
        \caption{iGCT (1 NFE), w=1.0}
    \end{subfigure}
    % Second image
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_igct/3_6.0_middle_4x4_grid.png}
        \caption{iGCT (1 NFE), w=7.0}
    \end{subfigure}
    % Third image
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_igct/3_12.0_middle_4x4_grid.png}
        \caption{iGCT (1 NFE), w=13.0}
    \end{subfigure}
    \caption{CIFAR-10 "cat"}
    \label{fig:CIFAR-10_guided_4}
\end{figure*}
\begin{figure*}[t]
    \centering
    % First image
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_edm/4_0.0_middle_4x4_grid.png}
        \caption{CFG-EDM (18 NFE), w=1.0}
    \end{subfigure}
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_edm/4_6.0_middle_4x4_grid.png}
        \caption{CFG-EDM (18 NFE), w=7.0}
    \end{subfigure}
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_edm/4_12.0_middle_4x4_grid.png}
        \caption{CFG-EDM (18 NFE), w=13.0}
    \end{subfigure}
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_igct/4_0.0_middle_4x4_grid.png}
        \caption{iGCT (1 NFE), w=1.0}
    \end{subfigure}
    % Second image
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_igct/4_6.0_middle_4x4_grid.png}
        \caption{iGCT (1 NFE), w=7.0}
    \end{subfigure}
    % Third image
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_igct/4_12.0_middle_4x4_grid.png}
        \caption{iGCT (1 NFE), w=13.0}
    \end{subfigure}
    \caption{CIFAR-10 "deer"}
    \label{fig:CIFAR-10_guided_5}
\end{figure*}
\begin{figure*}[t]
    \centering
    % First image
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_edm/5_0.0_middle_4x4_grid.png}
        \caption{CFG-EDM (18 NFE), w=1.0}
    \end{subfigure}
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_edm/5_6.0_middle_4x4_grid.png}
        \caption{CFG-EDM (18 NFE), w=7.0}
    \end{subfigure}
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_edm/5_12.0_middle_4x4_grid.png}
        \caption{CFG-EDM (18 NFE), w=13.0}
    \end{subfigure}
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_igct/5_0.0_middle_4x4_grid.png}
        \caption{iGCT (1 NFE), w=1.0}
    \end{subfigure}
    % Second image
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_igct/5_6.0_middle_4x4_grid.png}
        \caption{iGCT (1 NFE), w=7.0}
    \end{subfigure}
    % Third image
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_igct/5_12.0_middle_4x4_grid.png}
        \caption{iGCT (1 NFE), w=13.0}
    \end{subfigure}
    \caption{CIFAR-10 "dog"}
    \label{fig:CIFAR-10_guided_6}
\end{figure*}
\begin{figure*}[t]
    \centering
    % First image
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_edm/6_0.0_middle_4x4_grid.png}
        \caption{CFG-EDM (18 NFE), w=1.0}
    \end{subfigure}
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_edm/6_6.0_middle_4x4_grid.png}
        \caption{CFG-EDM (18 NFE), w=7.0}
    \end{subfigure}
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_edm/6_12.0_middle_4x4_grid.png}
        \caption{CFG-EDM (18 NFE), w=13.0}
    \end{subfigure}
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_igct/6_0.0_middle_4x4_grid.png}
        \caption{iGCT (1 NFE), w=1.0}
    \end{subfigure}
    % Second image
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_igct/6_6.0_middle_4x4_grid.png}
        \caption{iGCT (1 NFE), w=7.0}
    \end{subfigure}
    % Third image
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_igct/6_12.0_middle_4x4_grid.png}
        \caption{iGCT (1 NFE), w=13.0}
    \end{subfigure}
    \caption{CIFAR-10 "frog"}
    \label{fig:CIFAR-10_guided_7}
\end{figure*}
\begin{figure*}[t]
    \centering
    % First image
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_edm/7_0.0_middle_4x4_grid.png}
        \caption{CFG-EDM (18 NFE), w=1.0}
    \end{subfigure}
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_edm/7_6.0_middle_4x4_grid.png}
        \caption{CFG-EDM (18 NFE), w=7.0}
    \end{subfigure}
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_edm/7_12.0_middle_4x4_grid.png}
        \caption{CFG-EDM (18 NFE), w=13.0}
    \end{subfigure}
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_igct/7_0.0_middle_4x4_grid.png}
        \caption{iGCT (1 NFE), w=1.0}
    \end{subfigure}
    % Second image
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_igct/7_6.0_middle_4x4_grid.png}
        \caption{iGCT (1 NFE), w=7.0}
    \end{subfigure}
    % Third image
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_igct/7_12.0_middle_4x4_grid.png}
        \caption{iGCT (1 NFE), w=13.0}
    \end{subfigure}
    \caption{CIFAR-10 "horse"}
    \label{fig:CIFAR-10_guided_8}
\end{figure*}
\begin{figure*}[t]
    \centering
    % First image
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_edm/8_0.0_middle_4x4_grid.png}
        \caption{CFG-EDM (18 NFE), w=1.0}
    \end{subfigure}
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_edm/8_6.0_middle_4x4_grid.png}
        \caption{CFG-EDM (18 NFE), w=7.0}
    \end{subfigure}
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_edm/8_12.0_middle_4x4_grid.png}
        \caption{CFG-EDM (18 NFE), w=13.0}
    \end{subfigure}
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_igct/8_0.0_middle_4x4_grid.png}
        \caption{iGCT (1 NFE), w=1.0}
    \end{subfigure}
    % Second image
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_igct/8_6.0_middle_4x4_grid.png}
        \caption{iGCT (1 NFE), w=7.0}
    \end{subfigure}
    % Third image
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_igct/8_12.0_middle_4x4_grid.png}
        \caption{iGCT (1 NFE), w=13.0}
    \end{subfigure}
    \caption{CIFAR-10 "ship"}
    \label{fig:CIFAR-10_guided_9}
\end{figure*}
\begin{figure*}[t]
    \centering
    % First image
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_edm/9_0.0_middle_4x4_grid.png}
        \caption{CFG-EDM (18 NFE), w=1.0}
    \end{subfigure}
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_edm/9_6.0_middle_4x4_grid.png}
        \caption{CFG-EDM (18 NFE), w=7.0}
    \end{subfigure}
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_edm/9_12.0_middle_4x4_grid.png}
        \caption{CFG-EDM (18 NFE), w=13.0}
    \end{subfigure}
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_igct/9_0.0_middle_4x4_grid.png}
        \caption{iGCT (1 NFE), w=1.0}
    \end{subfigure}
    % Second image
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_igct/9_6.0_middle_4x4_grid.png}
        \caption{iGCT (1 NFE), w=7.0}
    \end{subfigure}
    % Third image
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_igct/9_12.0_middle_4x4_grid.png}
        \caption{iGCT (1 NFE), w=13.0}
    \end{subfigure}
    \caption{CIFAR-10 "truck"}
    \label{fig:CIFAR-10_guided_10}
\end{figure*}


\begin{figure*}[b]
    \centering
    % First image
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_im64_edm/edm_class_291_w=0.0.png}
        \caption{CFG-EDM (18 NFE), w=1.0}
    \end{subfigure}
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_im64_edm/edm_class_291_w=6.0.png}
        \caption{CFG-EDM (18 NFE), w=7.0}
    \end{subfigure}
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_im64_edm/edm_class_291_w=12.0.png}
        \caption{CFG-EDM (18 NFE), w=13.0}
    \end{subfigure}
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_im64_igct/class_291_w=0.0.png}
        \caption{iGCT (2 NFE), w=1.0}
    \end{subfigure}
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_im64_igct/class_291_w=6.0.png}
        \caption{iGCT (2 NFE), w=7.0}
    \end{subfigure}
    % Third image
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_im64_igct/class_291_w=12.0.png}
        \caption{iGCT (2 NFE), w=13.0}
    \end{subfigure}
    \caption{ImageNet64 "lion"}
    \label{fig:im64_guided_1}
\end{figure*}



\begin{figure*}[b]
    \centering
    % First image
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_im64_edm/edm_class_292_w=0.0.png}
        \caption{CFG-EDM (18 NFE), w=1.0}
    \end{subfigure}
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_im64_edm/edm_class_292_w=6.0.png}
        \caption{CFG-EDM (18 NFE), w=7.0}
    \end{subfigure}
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_im64_edm/edm_class_292_w=12.0.png}
        \caption{CFG-EDM (18 NFE), w=13.0}
    \end{subfigure}
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_im64_igct/class_292_w=0.0.png}
        \caption{iGCT (2 NFE), w=1.0}
    \end{subfigure}
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_im64_igct/class_292_w=6.0.png}
        \caption{iGCT (2 NFE), w=7.0}
    \end{subfigure}
    % Third image
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_im64_igct/class_292_w=12.0.png}
        \caption{iGCT (2 NFE), w=13.0}
    \end{subfigure}
    \caption{ImageNet64 "tiger"}
    \label{fig:im64_guided_2}
\end{figure*}


\begin{figure*}[b]
    \centering
    % First image
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_im64_edm/edm_class_28_w=0.0.png}
        \caption{CFG-EDM (18 NFE), w=1.0}
    \end{subfigure}
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_im64_edm/edm_class_28_w=6.0.png}
        \caption{CFG-EDM (18 NFE), w=7.0}
    \end{subfigure}
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_im64_edm/edm_class_28_w=12.0.png}
        \caption{CFG-EDM (18 NFE), w=13.0}
    \end{subfigure}
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_im64_igct/class_28_w=0.0.png}
        \caption{iGCT (2 NFE), w=1.0}
    \end{subfigure}
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_im64_igct/class_28_w=6.0.png}
        \caption{iGCT (2 NFE), w=7.0}
    \end{subfigure}
    % Third image
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_im64_igct/class_28_w=12.0.png}
        \caption{iGCT (2 NFE), w=13.0}
    \end{subfigure}
    \caption{ImageNet64 "salamander"}
    \label{fig:im64_guided_3}
\end{figure*}


\begin{figure*}[b]
    \centering
    % First image
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_im64_edm/edm_class_407_w=0.0.png}
        \caption{CFG-EDM (18 NFE), w=1.0}
    \end{subfigure}
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_im64_edm/edm_class_407_w=6.0.png}
        \caption{CFG-EDM (18 NFE), w=7.0}
    \end{subfigure}
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_im64_edm/edm_class_407_w=12.0.png}
        \caption{CFG-EDM (18 NFE), w=13.0}
    \end{subfigure}
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_im64_igct/class_407_w=0.0.png}
        \caption{iGCT (2 NFE), w=1.0}
    \end{subfigure}
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_im64_igct/class_407_w=6.0.png}
        \caption{iGCT (2 NFE), w=7.0}
    \end{subfigure}
    % Third image
    \begin{subfigure}{0.25\textwidth}
        \includegraphics[width=\linewidth]{fig/appendix_im64_igct/class_407_w=12.0.png}
        \caption{iGCT (2 NFE), w=13.0}
    \end{subfigure}
    \caption{ImageNet64 "ambulance"}
    \label{fig:im64_guided_4}
\end{figure*}