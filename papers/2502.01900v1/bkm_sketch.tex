\section{Analysis of the Linearity Test}\label{sec:bkm_sketch}

In this section, we shall state and prove a generalized version of Theorem~\ref{thm:bkm23}.
The proof follows the work of Bhangale, Khot and Minzer~\cite{BKM23b}, and hence we only give a rough outline (skipping many of the technical points), pointing out the places where the proof differs from the above work.
We start with the following definition:

\begin{definition}\label{defn:cont_BLR}
	Let $k\geq 3,p\in (0,1)$, and let $\nu\in \mc D(p,k)$ be a distribution.
	We say that $\nu$ \emph{contains BLR}, if there exists some $\tilde{b}\in \set{0,1},\ \tilde{z}\in \set{0,1}^{k-3}$, such that 
	\[ \set{(x_1,\ x_2,\ x_1\oplus x_2\oplus \tilde{b},\ \tilde{z}) : x_1,x_2\in \set{0,1}}\subseteq \supp(\nu)\subseteq \set{0,1}^k. \]	
	Furthermore, for technical reasons, we shall also require that \[\textnormal{span}_{\mathbb{F}_2}(\supp(\nu)) = \set{x\in \set{0,1}^k : \sum_{i=1}^k x_i = 0\modt} .\]
\end{definition}

Observe that any $\nu$ with full even-weight support contains BLR (with $\tilde{b}=0$, and $\tilde{z}$ the all-zeros vector).
With this, we state the following generalization of Theorem~\ref{thm:bkm23}:

\begin{theorem}\label{thm:bkm23_in_section}
	Let $k\geq 3$ be a positive integer, and let $p\in (0,1),\ \epsilon \in (0,1]$ be constants, and let $\nu \in \mc D(p,k)$ be a distribution containing BLR (see Definition~\ref{defn:cont_BLR}).
	Then, there exists constants $\delta>0,\ d\in \N$ (possibly depending on $k, p, \epsilon, \nu$), such that for every large enough $n\in \N$, the following is true:
	
	Let $f:\set{0,1}^n\to[-1,1]$ be a function such that \[ \abs{\E_{(X_1,\dots,X_k)\sim \nu^{\otimes n}} \sqbrac{\prod_{i=1}^k f(X_i)} }\geq \eps.\]
	Then, there exists a set $S\subseteq [n]$, and a polynomial $g:\set{0,1}^n\to \R$ of degree at most $d$ and with 2-norm $\E_{X\sim \mu_p^{\otimes n} }\sqbrac{g(X)^2}\leq 1$, such that
	\[ \abs {\E_{X\sim \mu_p^{\otimes n}}\sqbrac{f(X)\cdot \chi_S(X)\cdot g(X)}} \geq \delta .\]
	
	Moreover, if the distribution $\nu$ has some pairwise independent coordinate, then we may assume $g\equiv 1$; that is, $f$ correlates with a linear function $\chi_S$.
\end{theorem}

The remainder of this section is devoted to the proof of the above theorem.
Let $k\geq 3$ be an integer, and let $\ p\in (0,1),\ \epsilon \in (0,1]$ be constants, and let $\nu \in \mc D(p,k)$ be a distribution containing BLR (see Definition~\ref{defn:cont_BLR}).
Also, let $f:\set{0,1}^n\to[-1,1]$ be a function such that

\begin{equation}\label{eqn:test_pass}
	\abs{\E_{X=(X_1,\dots,X_k)\sim \nu^{\otimes n}} \sqbrac{\prod_{i=1}^k f(X_i)} }\geq \eps.
\end{equation}

\subsection*{Step 1: Large Fourier Coefficient under Random Restriction.}\label{sec:large_fcurr}
We note that the proof of this step is where we differ from~\cite{BKM23b}.

Since the distribution $\nu\in \mc D(p,k)$ contains BLR, we can write $\nu = (1-\beta)\cdot \nu' + \beta\cdot \mu$, for some small constant $0<\beta<\frac{1}{2}\min\set{p,1-p}$, some distribution $\nu'$ over $\set{0,1}^k$, and with $\mu$ the uniform distribution over $\set{(x_1,x_2,x_1\oplus x_2\oplus \tilde{b},\tilde{z}) : x_1,x_2\in \set{0,1}}$, where $\tilde{b},\tilde{z}$ are as in Definition~\ref{defn:cont_BLR}.
Using this, we can describe choosing $X \sim \nu^{\otimes n}$ as the following two step process. First choose a set $I\subseteq [n]$, denoted $I\sim_{1-\beta} [n]$, by choosing $i\in I$ with probability $1-\beta$, independently for each $i\in [n]$.
Then, choose $Z\sim \nu'^{\otimes I}$ and $Y\sim \mu^{\bar{I}}$, and set $X = (Y,Z)$.

With the above, we can prove that the function $f$ satisfies the property of having a large fourier coefficient under random restrictions; the reader is referred to~\cite{Don14} for an introduction to Fourier analysis over the hypercube.

\begin{lemma}\label{lemma:lfcurr}
	With $\delta = \epsilon/2$, it holds that
	\[ \Pr_{I\sim_{1-\beta}[n],\ Z\sim \nu'^{\otimes I}}\sqbrac{\exists S\subseteq [n]\setminus I:\ \abs{\widehat{f_{I\to Z_1}}(S)}\geq \delta\ } \geq \delta.\]
	Here, $f_{I\to Z_1}$ refers to the restriction of the function $f$, with the variables in $I$ \emph{set to} $Z_1$.
\end{lemma}	
\begin{proof}
	By Equation~\ref{eqn:test_pass}, we have
	\begin{align*}
		\epsilon &\leq \abs{\ \E_{X=(X_1,\dots,X_k)\sim \nu^{\otimes n}} \sqbrac{\prod_{i=1}^k f(X_i)}\ }
		\\&= \abs{\ \E_{I\sim_{1-\beta}[n],\ Z\sim \nu'^{\otimes I}}\E_{Y\sim \mu^{\otimes \bar{I}}} \sqbrac{\prod_{i=1}^k f_{I\to Z_i}(Y_i)}\ }
		\\&\leq \E_{I\sim_{1-\beta}[n],\ Z\sim \nu'^{\otimes I}}\abs{\ \E_{Y\sim \mu^{\otimes \bar{I}}} \sqbrac{\prod_{i=1}^k f_{I\to Z_i}(Y_i)}\ }		
	\end{align*}
	Observe that in the above expression, the random variables $Y_4,\dots,Y_k$ are constants (determined by $\tilde{z}$).
	Now, using a (classical) Fourier analytic argument to analyze the BLR linearity test over the uniform distribution (see Chapter 1 of~\cite{Don14}), we get
	\begin{align*}
		\epsilon &\leq \E_{I\sim_{1-\beta}[n],\ Z\sim \nu'^{\otimes I}}\abs{\ \E_{Y\sim \mu^{\otimes \bar{I}}} \sqbrac{\prod_{i=1}^3 f_{I\to Z_i}(Y_i)}\ }		
%		\\&= \E_{I\sim_{1-\beta}[n],\ Z\sim \nu'^{\otimes I}}\abs{\ \E_{Y_1,Y_2\sim \set{0,1}^{\otimes \bar{I}}} \sqbrac{ f_{I\to Z_1}(Y_1)\cdot f_{I\to Z_2}(Y_2)\cdot f_{I\to Z_3}(Y_1\oplus Y_2\oplus \tilde{b}^{\bar{I}}) }\ }
		\\&= \E_{I\sim_{1-\beta}[n],\ Z\sim \nu'^{\otimes I}}\abs{\ \sum_{S\subseteq \bar{I}} \widehat{f_{I\to Z_1}}(S)\cdot \widehat{f_{I\to Z_2}}(S)\cdot \widehat{f_{I\to Z_3}}(S)\cdot (-1)^{\tilde{b}\cdot \abs{S}} \ }
		\\&\leq \E_{I\sim_{1-\beta}[n],\ Z\sim \nu'^{\otimes I}} \sqbrac{\max_{S\subseteq \bar{I}}\abs{\widehat{f_{I\to Z_1}}(S)}}
		\\&\leq \Pr_{I\sim_{1-\beta}[n],\ Z\sim \nu'^{\otimes I}}\sqbrac{\exists S\subseteq \bar{I}:\ \abs{\widehat{f_{I\to Z_1}}(S)}\geq \epsilon/2}  + \epsilon/2.
		\qedhere
	\end{align*}
\end{proof}	

\subsection*{Step 2: Direct Product Test}
Using Theorem 1.1 in~\cite{BKM23b}, by Lemma~\ref{lemma:lfcurr} we get the existence of constants $d\in \N, \delta'>0$, a set $S\subseteq [n]$, and a polynomial $g:\set{0,1}^n\to \R$ of degree at most $d$, and with 2-norm $\E_{X\sim \mu_p^{\otimes n} }\sqbrac{g(X)^2}\leq 1$, such that \[ \abs {\E_{X\sim \mu_p^{\otimes n}}\sqbrac{f(X)\cdot \chi_S(X)\cdot g(X)}} \geq \delta' .\]
	
This proves the first part of Theorem~\ref{thm:bkm23}.
It remains to show that if $\nu$ has some pairwise independent coordinate, it is possible to remove the function $g$ in the above expression.
	
\subsection*{Step 3: List Decoding.} This step follows Section 4.2 and Section 4.3 in~\cite{BKM23b}.

Using an iterative list-decoding process, we can find a constant $r\in \N$, and functions $\chi_{S_1}, \dots, \chi_{S_r}$, and constant degree polynomials $g_1,\dots, g_r,$ such that it is possible to ``replace" $f$ by $\sum_{i\in [r]}\chi_{S_i}\cdot g_i$ in Equation~\ref{eqn:test_pass} (and lose at most some constant factor in $\epsilon$).
Now, this implies that for some constant $\epsilon'>0$, and some indices $j_1,\dots,j_k\in [r]$, we have  
\begin{equation}\label{eqn:after_list}
	\abs{\E_{(X_1,\dots,X_k)\sim \nu^{\otimes n}} \sqbrac{\prod_{i=1}^k \chi_{S_{j_i}}(X_i) g_{j_i}(X_i) } }\geq \epsilon'.
\end{equation}
We remark that for the next step, some extra structure on $S_{j_i}$'s is needed, and ensuring that it holds requires the condition on $\textnormal{span}_{\F_2}(\supp(\nu))$ in Definition~\ref{defn:cont_BLR}.
	
\subsection*{Step 4: Invariance Principle Argument.}
This step follows Section 4.4, Section 4.5, and Section 4.6 in~\cite{BKM23b}. 

Assume, for the sake of contradiction, that $f$ is not correlated well with any $\chi_S$; that is, $\E_{X\sim \mu_p^{\otimes n}} \sqbrac{f(X)\cdot \chi_S(X)} \leq o_n(1)$ for each $S\subseteq [n]$.
Using this, it can be shown, roughly, that for each $i\in [k]$, the expectation $\E_{X\sim \mu_p^{\otimes n}}\sqbrac{\chi_{S_{j_i}}(X) g_{j_i}(X)} \leq o_n(1)$; note that for this conclusion to hold, we might have to modify $S_{j_i}$'s and $g_{j_i}$'s, however it is possible to do so while maintaining Equation~\ref{eqn:after_list}.

Now, by an invariance principle argument~\cite{MOO10, Mos10, Mos20}, very roughly, it is possible to replace the expectation in Equation~\ref{eqn:after_list} over $(X_1,\dots,X_k)\sim \nu^{\otimes n}$, by an expectation over $(Z_1,\dots,Z_k) \sim \mc N(0,\Sigma)^{\otimes n}$, where $\Sigma\in \R^{k\times k}$ is the (normalized) covariance matrix of $\nu$.
Finally, we use that some coordinate $X_{i^*}$ is pairwise independent of each $X_i$, for $i\not=i^*$.
Since the Gaussian distribution is determined by its covariance matrix, this implies that $Z_{i^*}$ is mutually independent of $(Z_i)_{i\not=i^*}$.
We have
\begin{align*}
	\epsilon' &\leq \abs{\E_{X=(X_1,\dots,X_k)\sim \nu^{\otimes n}} \sqbrac{\prod_{i=1}^k \chi_{S_{j_i}}(X_i) g_{j_i}(X_i) } }
	\\ &\approx  \abs{\E_{Z=(Z_1,\dots,Z_k)\sim \mc N(0,\Sigma)^{\otimes n}} \sqbrac{\prod_{i=1}^k \chi_{S_{j_i}}(Z_i) g_{j_i}(Z_i) } }
	\\&\approx \abs{\ \E_{Z_{i^*}\sim \mc N(0,1)^{\otimes n}} \sqbrac{ \chi_{S_{j_{i^*}}}(Z_{i^*}) g_{j_{i^*}}(Z_{i^*})} }\cdot  \abs{\ \E_{Z} \sqbrac{\prod_{i\in [k], i\not=i^*} \chi_{S_{j_i}}(Z_i) g_{j_i}(Z_i) } }
	\\&\approx \abs{\ \E_{X_{i^*}\sim \mu_p^{\otimes n}} \sqbrac{ \chi_{S_{j_{i^*}}}(X_{i^*}) g_{j_{i^*}}(X_{i^*})} }\cdot  \abs{\ \E_{Z} \sqbrac{\prod_{i\in [k], i\not=i^*} \chi_{S_{j_i}}(Z_i) g_{j_i}(Z_i) } }
	\\ &\leq o_n(1),
\end{align*}
which is a contradiction.
\qed
