\section{Linearity Testing Requires Pairwise Independence}\label{sec:lin_test_failure}

In this section, we prove Theorem~\ref{thm:intro_main}, which is restated below.

\begin{theorem}\label{thm:counter_eg}
	Let $k\in \N,\ p\in (0,1)$, and let $\nu \in \mc D(p,k)$ be a distribution having no pairwise independent coordinate (see Definition~\ref{defn:distr_class}).
	Then, there exists a constant $\alpha>0$, such that for every large enough $n\in \N$, there exists a function $f:\set{0,1}^n \to [-1,1]$ such that 
	\begin{enumerate}
		\item $\abs{\E_{X\sim \nu^{\otimes n}} \sqbrac{\prod_{i=1}^k f(X_i)} }\geq \alpha.$
		\item For every $S\subseteq [n]$, it holds that $ \abs{\E_{X\sim \mu_p^{\otimes n}}\sqbrac{f(X)\chi_S(X)}} \leq o_n(1)$.
	\end{enumerate}
	
	Moreover, if the distribution $\nu$ is such that $\eta:= \max_{i,j\in [k], i\not= j} \Pr_{X\sim \nu}\sqbrac{X_i=X_j} < 1$ (that is, no two coordinates are almost surely equal), the above holds for a function $f$ with range $\set{-1,1}$.
\end{theorem}

The remainder of this section is devoted to the proof of Theorem~\ref{thm:counter_eg}.
In Section~\ref{sec:counter_eg_1}, we prove the first part of the theorem, dealing with functions with range $[-1,1]$.
Then, in Section~\ref{sec:counter_eg_2}, we show how to round to functions with range $\set{-1,1}$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Function with Range $[-1,1]$}\label{sec:counter_eg_1}

Let $k\in \N,\ p\in (0,1),$ and let $\nu \in \mc D(p,k)$ be a distribution having no pairwise independent coordinate.
Let $\Sigma \in \R^{k\times k}$ be the (normalized) covariance matrix corresponding to the distribution $\nu$, given by, $\Sigma_{i,j} = \E_{X\sim \nu}\sqbrac{\frac{ \brac{X_i-p}\cdot \brac{X_j-p}}{p-p^2}}$.
Observe that the matrix $\Sigma$ satisfies the conditions of Proposition~\ref{prop:gaussian_counter_eg}, and hence there exists a function $h:\R\to [-1,1]$ such that
\begin{enumerate}
	\item $\E_{Z\sim \mc N(0,1)}\sqbrac{h(Z)} = 0$
	\item The function $H:\R^k\to [-1,1]$ given by $H(x) = \prod_{i\in [k]}h\brac{x_i}$ is such that \[\alpha :=  \frac{1}{2}\cdot \abs{\E_{Z\sim \mc N(0, \Sigma)} \sqbrac{H(Z)}} > 0 .\]
	\item The function $h$ is $K$-Lipschitz for some $K>0$; in particular, both $h$ and $H$ are bounded continuous functions.
\end{enumerate}

Consider any large $n\in \N$.
We define $f:\set{0,1}^n \to [-1,1]$ by 
\[f(x) = h\brac{\frac{1}{\sqrt{n}}\cdot \sum_{j=1}^n \frac{x\up{j}-p}{\sqrt{p-p^2}}},\]
The function $f$ satisfies the two properties in the theorem statement, as follows:

\begin{itemize}
	\item Let $X \sim \nu^{\otimes n}$, and let $Y = (Y_1,\dots, Y_k)$ be a $\set{0,1}^k$-valued random vector, defined as $Y_i=\frac{1}{\sqrt{n}}\cdot \sum_{j=1}^n \frac{X_i\up{j}-p}{\sqrt{p-p^2}}$.
	 
	Let $F:\set{0,1}^{kn}\to [-1,1]$ be given by $F(x) = \prod_{i\in [k]}f\brac{x_i}$.
	Since $H$ is continuous and bounded, we have by the Multivariate CLT (Theorem~\ref{thm:multi_clt}) that
	\[ \abs{\ \E\sqbrac{F(X)} - \E_{Z \sim \mc N(0, \Sigma)} \sqbrac{H(Z)}\ } = \abs{\ \E\sqbrac{{H(Y)}} - \E_{Z \sim \mc N(0, \Sigma)} \sqbrac{H(Z)}\ } \leq o_n(1).\]
	Hence, for large $n$, we get $\abs{\E_{X\sim \nu^{\otimes n}} \sqbrac{\prod_{i=1}^k f(X_i)} }\geq 2\alpha-o_n(1)\geq \alpha$, as desired.
	
	
	\item Consider any subset $S\subseteq [n]$, and let $T\subseteq S$ be any subset of size $\abs{T}=\min\set{\lfloor n^{1/4}\rfloor, \abs{S}}$. Let $\tilde{f}:\set{0,1}^n\to [-1,1]$ be defined by $\tilde{f}(X) = h\brac{\frac{1}{\sqrt{n-\abs{T}}}\cdot \sum_{j\in [n]\setminus T} \frac{x\up{j}-p}{\sqrt{p-p^2}} }$; note that this function only depends on the coordinates of $x$ outside the set $T$. Further, for each $x\in \set{0,1}^n$, by the Lipschitz bound on $h$, we get
	\begin{align*}
		\abs{f(x)-\tilde{f}(x)} &\leq K\cdot  \abs{\frac{1}{\sqrt{n}}\cdot \sum_{j=1}^n \frac{x\up{j}-p}{\sqrt{p-p^2}} - \frac{1}{\sqrt{n-\abs{T}}}\cdot \sum_{j\in [n]\setminus T} \frac{x\up{j}-p}{\sqrt{p-p^2}}}
		\\&\leq \frac{K}{\sqrt{p-p^2}}\cdot\brac{\frac{\abs{T}}{\sqrt{n}}+ \brac{n-\abs{T}}\cdot \abs{\frac{1}{\sqrt{n-\abs{T}}} - \frac{1}{\sqrt{n}}}}
		\\&\leq \frac{K}{\sqrt{p-p^2}}\cdot\brac{\frac{\abs{T}}{\sqrt{n}}+ \frac{n-\abs{T}}{\sqrt{n}}\cdot \frac{\abs{T}}{n}}
		\\&\leq \frac{K}{\sqrt{p-p^2}}\cdot\frac{2\abs{T}}{\sqrt{n}} = o_n(1),
	\end{align*}
	where we used that $(1-t)^{-1/2} \leq 1+t$ for each $t\in [0,1/2]$.
 
	Now, for $X\sim \mu_p^{\otimes n}$, we have
	\begin{align*}
		\abs{\ \E_X\sqbrac{f(X)\cdot \chi_S(X)}\ } &\leq \abs{\ \E_X\sqbrac{\tilde{f}(X)\cdot \chi_S(X)}\ } + o_n(1)
		\\&= \abs{\ \E_X\sqbrac{\tilde{f}(X)\cdot \chi_{S\setminus T}(X)}\cdot \E_X\sqbrac{ \chi_{T}(X)}\ } + o_n(1)
		\\&= \abs{\ \E_X\sqbrac{\tilde{f}(X)\cdot \chi_{S\setminus T}(X)}\ }\cdot \abs{1-2p}^{\abs{T}} + o_n(1).
	\end{align*}
	If $\abs{S} \geq \lfloor n^{1/4} \rfloor$, then $\abs{1-2p}^{\abs{T}} = o_n(1)$.
	Otherwise, we have that $S=T$, and by the Central Limit Theorem (see Theorem~\ref{thm:multi_clt}) , the first term in the above product equals
	\[ \abs{\ \E_X\sqbrac{\tilde{f}(X)}\ } = \abs{\ \E_X\sqbrac{\tilde{f}(X)} - \E_{Z\sim \mc N(0,1)}\sqbrac{h(Z)}\ } = o_n(1). \pushQED{\qed}\qedhere\popQED \]	
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Rounding to a Function with Range $\set{-1,1}$}\label{sec:counter_eg_2}

Now, we shall prove the second part of Theorem~\ref{thm:counter_eg}.

Let $k\in \N,\ p\in (0,1),$ and let $\nu \in \mc D(p,k)$ be a distribution having no pairwise independent coordinate.
Further suppose that the distribution $\nu$ is such that \[\eta := \max_{i,j\in [k], i\not= j} \Pr_{X\sim \nu}\sqbrac{X_i=X_j} < 1.\]
Let $\alpha>0$ be as obtained in Section~\ref{sec:counter_eg_1}.
Consider any large $n\in \N$, and let $f:\set{0,1}^n\to [-1,1]$ be the function obtained in Section~\ref{sec:counter_eg_1}.

Let $g:\set{0,1}^n \to \set{-1,1}$ be a random function, defined as $g(x) = \begin{cases} 1, & w.p.\  \frac{1+f(x)}{2} \\ -1, & w.p.\  \frac{1-f(x)}{2} \end{cases}$, independently for each $x\in \set{0,1}^n$.
Observe that this satisfies $\E_{g}\sqbrac{g(x)} = f(x)$ for each $x\in \set{0,1}^n$.
We will show that the function $g$ satisfies the two desired properties with probability $1-o_n(1)$, and hence by the probabilistic method, this guarantees the existence of a non-random $g$ as desired.
This is done as follows:
\begin{enumerate}
	\item Let $F,G:\set{0,1}^{kn}\to [-1,1]$ be defined as $F(x) = \prod_{i\in [k]}f\brac{x_i}$ and $G(x) = \prod_{i\in [k]}g\brac{x_i}$.
		Let $X,Y \sim \nu^{\otimes n}$ be independent (of each other and of $g$) and let $E$ be the event that $X_1, \dots, X_k, Y_1, \dots, Y_k$ are all distinct.
		Then, by a union bound, we have that $\Pr\sqbrac{\bar E} \leq 2\cdot \binom{k}{2} \cdot \eta^n + k^2\cdot \brac{p^2+\brac{1-p}^2}^n = o_n(1)$, and hence
		\begin{align*}
			\abs{\ \E_{g} \E_{X\sim \nu^{\otimes n}}\sqbrac{G(X)}-\E_{X\sim \nu^{\otimes n}}\sqbrac{F(X)}\ } 
			&\leq \Pr\sqbrac{\bar E} + \abs{\  \E_{g}\E_{X,Y}\sqbrac{G(X)\cdot \ind_{E}}-\E_{X}\sqbrac{F(X)}\ }
			\\&\leq \Pr\sqbrac{\bar E} + \abs{\ \E_{X,Y}\sqbrac{F(X)\cdot \ind_{E}}-\E_{X}\sqbrac{F(X)}\ } 
			\\&\leq 2\Pr\sqbrac{\bar E} = o_n(1).
		\end{align*}
		Similarly, we have
		\begin{align*}
			\abs{\ \E_{g} \sqbrac{\E_{X}\sqbrac{G(X)}}^2-\sqbrac{\E_{X}\sqbrac{F(X)}}^2\ } &= \abs{\ \E_{g} \E_{X,Y}\sqbrac{G(X)\cdot G(Y)}-\E_{X,Y}\sqbrac{F(X)\cdot F(Y)}\ } \\&\leq 2\Pr\sqbrac{\bar E} = o_n(1).
		\end{align*}
		
		Letting $\beta = \abs{\E_{X}\sqbrac{F(X)}} \geq \alpha$, we get 
		$ \Var_g\sqbrac{\E_{X}\sqbrac{G(X)}} \leq \beta^2+o_n(1) - \brac{\beta-o_n(1)}^2 = o_n(1)$.
		Hence, by Chebyshev's inequality (Fact~\ref{fact:chebyshev}), we have $\abs{\E_{X}\sqbrac{G(X)}} \geq \frac{\alpha}{2}$ with probability $1-o_n(1)$.
		
	\item Fix $S \subseteq [n]$. Let $X\sim \mu_p^{\otimes n}$, and let $W = \E_{X}\sqbrac{\chi_S(X)\cdot g(X)} = \sum_{x\in \set{0,1}^n}\Pr\sqbrac{X=x} \cdot \chi_S(x)\cdot g(x)$. Observe that $W$ is a sum of $2^n$ independent and bounded random variables, and such that $\E_g[W] = \E_{X}\sqbrac{\chi_S(X)\cdot f(X)}$. For $q = \max\set{p,1-p}<1$, it holds that $\sum_x (2\Pr[X=x])^2 \leq 4q^n\cdot \sum_x\Pr[X=x] = 4q^n$, and by Hoeffding's inequality (Fact~\ref{fact:hoeffding}), we have for each $t>0$ that
	\[ \Pr\sqbrac{ \abs{W-\E[W]}\geq t} \leq 2\cdot \exp\brac{-\frac{2t^2}{4q^n}}. \]
	Let $t=q^{n/4}$.
	Then, with probability at least $1-o_n(2^{-n})$, it holds that $\abs{W} = \abs{\E_{X}\sqbrac{\chi_S(X)\cdot g(X)}} \leq \abs{\E_{X}\sqbrac{\chi_S(X)\cdot f(X)}}+q^{n/4} = o_n(1).$
	
	Now, a union bound over $S\subseteq[n]$ shows that with probability $1-o_n(1)$, the above holds for every $S\subseteq [n]$.
	\qed
\end{enumerate}
