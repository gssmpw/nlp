\section{Introduction}

A function $f:\set{0,1}^n\to \set{-1,1}$ is said to be linear over $\F_2$\footnote{by identifying the range $\F_2$ with $\set{-1,1}$, under the map $b\to (-1)^b$}, if there exists a set $S\subseteq [n]$, such that $f(x) = \prod_{i\in S} \brac{-1}^{x_i}$; this function is denoted by $\chi_S$.
The classical linearity testing problem, asks, given query access\footnote{the algorithm is allowed to ask/query the value of $f(x)$ at any $x\in \set{0,1}^n$} to a function $f:\set{0,1}^n\to \set{-1,1}$, to distinguish between the following two cases\footnote{the algorithm is allowed to answer arbitrarily for functions $f$ which violate both the conditions}:
\begin{enumerate}
	\item $f$ is a linear function.
	\item $f$ is far from being linear; that is, for every linear function $\chi_S$, the functions $f$ and $\chi_S$ disagree on many points.
\end{enumerate}

Linearity testing was first studied by Blum, Luby, and Rubinfeld, who gave a very simple 3-query test for this problem~\cite{BLR93}.
This test, known as the BLR test, proceeds in the following manner: Sample $x, y \sim \set{0,1}^n$ uniformly and independently; query $f$ at $x, y,$ and $x\oplus y$, and accept if and only if $f(x\oplus y)=f(x)\cdot f(y)$.
Observe that this test accepts all linear functions with probability 1.
Blum, Luby and Rubinfeld proved that any function $f$ passing this test with high probability ($1-\delta$, for some small $\delta>0$), must agree with some linear function $\chi_S$ on most (at least $1-O(\delta)$ fraction of) points in $\set{0,1}^n$.
This result, with the acceptance/agreement probability close to 1, is known as the 99\%-regime of the test.

It was shown later~\cite{BCHKS96, KLX10} that the above result extends to the 1\% regime as well; more precisely, for every $\delta\in [0,1]$, and $f:\set{0,1}^n\to \set{-1,1}$ such that 
\[\E_{x,y\sim\set{0,1}^n}\sqbrac{f(x)\cdot f(y)\cdot f(x\oplus y)} \geq \delta,\]
there exists $S\subseteq [n]$ such that $\E_{x\sim \set{0,1}^n}\sqbrac{f(x)\cdot\chi_S(x)} \geq \delta$. 

The above test is of fundamental importance in theoretical computer science, and has several applications; for example, it is one of the ingredients in the proof of the celebrated PCP theorem~\cite{FGLSS96, AS98, ALMSS98}.
Furthermore, the analysis of the BLR test by Bellare et al.~\cite{BCHKS96} is one of the early uses of Fourier analysis over the boolean hypercube, an area which now plays a crucial role in many diverse subfields of mathematics and computer science, like complexity theory, harness of approximation, learning theory, coding theory, social choice theory, etc.~\cite{Don14}.

In this work, we are interested in the problem of linearity testing over the $p$-biased hypercube.
For $p\in (0,1)$, we denote by $\mu_p$ the $p$-biased distribution on $\set{0,1}$, which assigns probability $p$ to 1, and $1-p$ to 0.
The $p$-biased hypercube refers the set $\set{0,1}^n$, with the $n$-fold product measure $\mu_p^{\otimes n}$.
Linearity testing, in this $p$-biased setting, asks to distinguish between linear functions, and functions which are far (with respect to the $p$-biased measure) from being linear.

The 99\% regime of this problem is well-understood~\cite{KS09, DFH19}, and a simple 4-query test works in this case (see Example~\ref{eg:dfh19_test} below).
The question for the 1\% regime turns out to be significantly more challenging for any $p\not= 1/2$, and was wide open until a recent work of Bhangale, Khot and Minzer~\cite{BKM23b} made significant progress.
In particular, for every $p\in \brac{\frac{1}{3}, \frac{2}{3}}$, they give a 4-query test that works in the 1\% regime.

Building upon the work of Bhangale, Khot and Minzer, we consider a very general class of tests, where, very roughly, some $k$ queries $x_1,\dots, x_k \in \set{0,1}^n$, satisfying $\sum_{i\in [k]}x_i = 0 \modt$ are chosen, and the test accepts $f:\set{0,1}^n\to \set{-1,1}$ if $\prod_{i\in [k]} f(x_i) = 1$.
We shall require the following definitions:

\begin{definition}\label{defn:distr_class} (Class of Distributions)
	For $k\in \N,\ p\in (0,1)$, we define $\mc D(p,k)$ to be the class of all distributions $\nu$ on $\set{0,1}^k$ having $\mu_p$ as the marginal distribution on each coordinate $i\in [k]$, and such that $\supp(\nu)\subseteq \set{x\in \set{0,1}^k: \sum_{i=1}^kx_i = 0 \modt}$. 
	We say that such a distribution $\nu$ has \emph{full even-weight support}, if the above inclusion is an equality.
		
	For a distribution $\nu \in \mc D(p,k)$, we say that $i\in [k]$ is a \emph{pairwise independent coordinate}, if for each $j\in [k], j\not= i$, it holds that $\E_{X\sim \nu}\sqbrac{X_i\cdot X_j} = p^2$.
	We say that $\nu$ is \emph{pairwise independent}, if all its coordinates are pairwise independent.
\end{definition} 

\begin{definition}\label{defn:lin_test} (Class of Linearity Tests)
	For a distribution $\nu \in \mc D(p,k)$, we define a corresponding linearity test, denoted by $\Lin(\nu)$, as follows.
	Given query access to a function $f:\set{0,1}^n\to \set{-1,1}$:
	Sample\footnote{here, by $x = (x_1,\dots, x_k) \sim \nu^{\otimes n}$, we mean that for each $j\in [n]$, sample $(x_1\up{j},\dots, x_k\up{j})\sim \nu$ independently (also see Section~\ref{sec:prelims} for notation).} $x = (x_1,\dots, x_k) \sim \nu^{\otimes n}$, and accept if and only if $f(x_1)\cdot f(x_2)\cdots f(x_k) =1$.
\end{definition}

Note that every linear function passes such a test with probability 1\footnote{When $k$ is even, affine functions of the form $\pm \chi_S$ also pass the test with probability 1. In this work, we shall ignore the distinction between these functions and linear functions.}.
More strongly, each query in $\nu^{\otimes n}$ having marginal distribution $\mu_p^{\otimes n}$ ensures that functions that are close to linear (with respect to $p$-biased measure) are also accepted with high probability; in the property testing literature, such tests are called tolerant.
Furthermore, this is a very general class of linearity tests, containing many of the mentioned previously tests, as demonstrated by the following examples:

\begin{example}
	The BLR test uses $\nu$ to be uniform over ${\set{x\in \set{0,1}^3 : x_1+x_2+x_3 = 0 \modt}}$.
\end{example}
\begin{example}\label{eg:dfh19_test}
	The 4-query $p$-biased test of~\cite{DFH19} (for the 99\% regime) uses a distribution $\nu$ over $\set{0,1}^4$ of the following form:
	With probability $p_0$, set all coordinates to 0; with probability $p_1$, set all coordinates to 1; and with probability $1-p_0-p_1$, sample uniformly from the set $\set{x\in \set{0,1}^4 : x_1+x_2+x_3+x_4 = 0 \modt}$.
	Note that each coordinate has bias $p_1 + \frac{1}{2}\brac{1-p_0-p_1}$, and $p_0,p_1$ are chosen so that this equals $p$.
\end{example}

In this work, we analyze the precise conditions under which tests in Defintion~\ref{defn:lin_test} work for linearity testing, in the 1\% regime.
Our main result (proven in Section~\ref{sec:putting_together}) is the following:
\begin{theorem}\label{thm:intro_querybias_main_thm}
	Let $p\in (0,1)$.
	\begin{enumerate}
		\item For every integer $k > 1 + \frac{1}{\min\set{p,1-p}}$, there exists a distribution $\nu\in \mc D(p,k)$, such that the test $\Lin(\nu)$ is a $k$-query linearity test over the $p$-biased hypercube, for the 1\% regime.
		
		That is, for every $\eps>0$, there exists a $\delta>0$, such that for every large $n\in \N$, and every function $f:\set{0,1}^n\to [-1,1]$ satisfying\[ \abs{\E_{(X_1,\dots,X_k)\sim \nu^{\otimes n}} \sqbrac{\prod_{i\in [k]} f(X_i)} }\geq \eps,\]
		there exists a set $S\subseteq [n]$, such that $ \abs {\E_{X\sim \mu_p^{\otimes n}}\sqbrac{f(X)\cdot \chi_S(X)}} \geq \delta.$
		
		\item The above point also holds for all integers $k\geq 3$ with $p=\frac{1}{k-1}$, and for all even integers $k\geq 4$ with $p = 1-\frac{1}{k-1}$.
		
		\item Conversely, for every positive integer $k < 1+\frac{1}{\min\set{p,1-p}}$, and every distribution $\nu\in \mc D(p,k)$, the test $\Lin(\nu)$ fails in the 1\% regime.
		
		That is, there exists a constant $\alpha>0$, such that for every large $n\in \N$, there exists a function $f:\set{0,1}^n\to \set{-1,1}$ satisfying \[ \abs{\E_{(X_1,\dots,X_k)\sim \nu^{\otimes n}} \sqbrac{\prod_{i\in [k]} f(X_i)} }\geq \alpha,\]
		and such that for every $S\subseteq [n]$, it holds that $ \abs {\E_{X\sim \mu_p^{\otimes n}}\sqbrac{f(X)\cdot \chi_S(X)}} \leq o_n(1)$.
	\end{enumerate}
\end{theorem}

\begin{remark}\label{remark:corner_case_intro}
	Note that the above theorem does not discuss the case when $k\geq 5$ is an odd integer, and $p = 1-\frac{1}{k-1}$.
	This case is very interesting and is discussed in more detail in Section~\ref{sec:corner_case}.
	Informally speaking, the test corresponding to the ``natural" distribution $\nu \in \mc D(p,k)$, in this case, ensures correlation with a character of $\Z/(k-1)\Z$, and not a linear function $\chi_S$ (that is, a character of $\Z/2\Z$).
	In Section~\ref{sec:corner_case}, we also present an alternative test to get around this.
\end{remark}

Next, we shall describe the main technical results we prove along the way to prove Theorem~\ref{thm:intro_querybias_main_thm}.
We start by stating (a generalized version of) the main linearity testing result of Bhangale, Khot and Minzer~\cite{BKM23b}:

\begin{theorem}\label{thm:bkm23}
	(General version proved later as Theorem~\ref{thm:bkm23_in_section})
	Let $k\geq 3$ be a positive integer, and let $p\in (0,1),\ \epsilon \in (0,1]$ be constants, and let $\nu \in \mc D(p,k)$ be a distribution with full even-weight support (see Definition~\ref{defn:distr_class}).
	Then, there exists constants $\delta>0,\ d\in \N$ (possibly depending on $k, p, \epsilon, \nu$), such that for every large enough $n\in \N$, the following is true:
	
	Let $f:\set{0,1}^n\to[-1,1]$ be a function such that \[ \abs{\E_{(X_1,\dots,X_k)\sim \nu^{\otimes n}} \sqbrac{\prod_{i=1}^k f(X_i)} }\geq \eps.\]
	Then, there exists a set $S\subseteq [n]$, and a polynomial $g:\set{0,1}^n\to \R$ of degree at most $d$ and with 2-norm $\E_{X\sim \mu_p^{\otimes n} }\sqbrac{g(X)^2}\leq 1$, such that
	\[ \abs {\E_{X\sim \mu_p^{\otimes n}}\sqbrac{f(X)\cdot \chi_S(X)\cdot g(X)}} \geq \delta .\]
	
	Moreover, if the distribution $\nu$ has some pairwise independent coordinate, then we may assume $g\equiv 1$; that is, $f$ correlates with a linear function $\chi_S$.
\end{theorem}

We remark that Bhangale, Khot and Minzer only consider the case $k=4$, and only show $g\equiv 1$ in the case that all coordinates of $\nu$ are pairwise independent.
However, their proofs extend to the more general setting of Theorem~\ref{thm:bkm23}; we give an outline of this proof in Section~\ref{sec:bkm_sketch}.
Furthermore, we note that we are able to analyze the linearity test for a class of distributions which is much larger than the class of full even-weight support distributions; these distributions, in some sense, \emph{contain the BLR test}, and are formally defined in Section~\ref{sec:bkm_sketch}.

In the above work, the authors ask whether the conclusion $g\equiv 1$ can be obtained without assumption that $\nu$ has a pairwise independent coordinate.
We show this is not possible, and in fact the assumption that $\nu$ has a pairwise independent coordinate is necessary.

\begin{theorem}\label{thm:intro_main} (Restated and proved later as Theorem~\ref{thm:counter_eg})
	Let $k\in \N,\ p\in (0,1)$, and let $\nu \in \mc D(p,k)$ be a distribution having no pairwise independent coordinate (see Definition~\ref{defn:distr_class}).
	
	Then, there exists a constant $\alpha>0$, such that for every large enough $n\in \N$, there exists a function $f:\set{0,1}^n \to [-1,1]$ such that 
	\begin{enumerate}
		\item $\abs{\E_{X\sim \nu^{\otimes n}} \sqbrac{\prod_{i=1}^k f(X_i)} }\geq \alpha.$
		\item For every $S\subseteq [n]$, it holds that $ \abs{\E_{X\sim \mu_p^{\otimes n}}\sqbrac{f(X)\cdot \chi_S(X)}} \leq o_n(1)$.
	\end{enumerate}
	
	Moreover, if the distribution $\nu$ is such that $\eta:= \max_{i,j\in [k], i\not= j} \Pr_{X\sim \nu}\sqbrac{X_i=X_j} < 1$ (that is, no two coordinates are almost surely equal), the above holds for a function $f$ with range $\set{-1,1}$.
\end{theorem}

\begin{remark}
\hfill
\begin{enumerate}
	\item The assumption $\eta < 1$ in the second part of the Theorem~\ref{thm:intro_main} is necessary.
	For example, if the $i$\textsuperscript{th} and $j$\textsuperscript{th} coordinates of $\nu$ are equal, then, for functions $f$ with range $\set{-1,1}$, the terms $f(X_i)$ and $f(X_j)$ cancel out in the product $\E_{X\sim \nu^{\otimes n}} \sqbrac{\prod_{i=1}^k f(X_i)}$.
	In particular, the test is equivalent to the $(k-2)$-query test with coordinates $i,j$ removed from $\nu$, and this new distribution may possibly satisfy the conditions of Theorem~\ref{thm:bkm23}.
	\item The function $f$ we construct in Theorem~\ref{thm:intro_main}  does not correlate well with any linear function, although, as possibly required by Theorem~\ref{thm:bkm23}, it does correlate well with some constant degree function.
	\item The above theorem, answers in the \emph{negative} a question of~\cite{BKM23b}, who ask if \[\abs{\E_{(X,Y,Z,W)\sim \nu^{\otimes n}}\sqbrac{g_1(X)\cdot g_2(Y)\cdot g_3(Z)\cdot g_4(W)}} = o_n(1)\] for distributions $\nu\in \mc D(p,4)$ with full even-weight support, and $g_1,\dots,g_4:\set{0,1}^n\to \R$ bounded, noise stable, and resilient functions.
	\item It is an easy check that the distribution $\nu$ from Example~\ref{eg:dfh19_test} cannot have a pairwise independent coordinate, unless $p=1/2$. This shows that for $p\not=\frac{1}{2}$, simple tests that work in the 99\% regime fail to work in the 1\% regime.
	\item Recall that every $\nu\in\mc D(p,k)$ satisfies $\sum_i X_i=0 \modt$ almost surely, for $X\sim \nu$. We never use this in the proof of the above theorem, and the conclusion holds without it.
\end{enumerate}
\end{remark}

Very roughly speaking, in the proof of the above theorem we first construct a counter-example function in Gaussian space which ``passes the test" with decent probability, while having zero expectation; this function is then converted to a boolean function using the Central Limit Theorem and a rounding procedure.
Along the way, we prove a simple characterization for a random vector to have an independent coordinate, which we believe to be of independent interest, and is stated as follows:

\begin{proposition} (Restated formally and proved later as Proposition~\ref{prop:gaussian_counter_eg})
	Let $X=(X_1,\dots,X_k)$ be a $k$-dimensional multivariate Gaussian random vector, such that for each $i\in [k]$, the marginal is $X_i\sim \mc N(0,1)$.
	Then, the following are equivalent:
	\begin{enumerate}
		\item For every ``nice" function $f:\R\to \R$ satisfying $\E_{Z\sim \mc N(0,1)}\sqbrac{f(Z)}=0$, it holds that $\E\sqbrac{f(X_1)\cdot f(X_2)\cdots f(X_k)}=0$.
		\item There exists $i\in [k]$ such that $X_i$ is independent of $(X_1,\dots,X_{i-1}, X_{i+1}, \dots, X_k)$.
	\end{enumerate}
\end{proposition}

Finally, to use the above theorems (Theorem~\ref{thm:bkm23} and Theorem~\ref{thm:intro_main}), we analyze the tradeoff between the number of queries $k$ and the bias $p$, such that a distribution $\nu\in \mc D(p,k)$ with some pairwise independent coordinate exists.
In particular, we prove the following (restated and proved later as Proposition~\ref{prop:query_bias_lb} and Proposition~\ref{prop:query_bias_ub}): 

\begin{proposition}\label{prop:intro_bias_query_tradeoff}
	Let $k\in \N,\ p\in (0,1)$.
	Then, there exists a distribution $\nu \in \mc D(p,k)$ with some pairwise independent coordinate if and only if  $k \geq 1 + \frac{1}{\min\set{p,1-p}}$.
\end{proposition}

We note that the above generalizes the parameter setting for both the BLR test, corresponding to $p=\frac{1}{2},\ k=3$, and the case of $p\in \brac{\frac{1}{3},\frac{2}{3}},\ k=4$ considered in~\cite{BKM23b}.

\subsection{Related work}

The problem of linearity testing has been extensively studied, starting with the work of Blum, Luby and Rubinfeld~\cite{BLR93}, who gave a test for the uniform distribution, in the 99\% regime.
The analysis of their test was later extended to the 1\% regime~\cite{BCHKS96, KLX10}.
Tests for linearity have been also been studied in the low-randomness regime, and in the setting of non-abelian groups~\cite{BSVW03,BCLR08,SW06}.

For the $p$-biased case, in the 99\% regime, Halevy and Kushilevitz~\cite{HK07} gave a 3-query linearity test, that only uses random samples from the $p$-biased distribution!
However, the test is not tolerant, makes queries that are not distributed according to $\mu_p^{\otimes n}$, and hence may reject functions that are very close to linear (with respect to the $p$-biased measure).
Tolerant testers were analyzed later~\cite{KS09, DFH19}.
More strongly, the work of Dinur, Filmus and Harsha~\cite{DFH19} gives $2^d$-query tolerant tester for $p$-biased testing of degree $d$ functions over $\F_2$, a problem which has been well studied over the uniform distribution~\cite{AKKLR05, BKSSZ10}.

As a part of their work on approximability of satisfiable constraint satisfaction problems~\cite{BKM22, BKM23a, BKM23b, BKM24a, BKM24b}, Bhangale, Khot and Minzer study the $p$-biased version of linearity testing, in the 1\% regime.
As mentioned before, they give a 4-query test for $p\in \brac{\frac{1}{3},\frac{2}{3}}$. 

David, Dinur, Goldberg, Kindler and Shinkar~\cite{DDGKS17} study linearity testing on the $k$-slice (vectors of hamming-weight $k$), denoted by $L_{k,n}$, of the $n$-dimensional boolean hypercube, for even integers $k$. 
They show that if $f:\set{0,1}^n\to \set{-1,1}$ is such that $f(x\oplus y) = f(x)f(y)$ with probability $1-\epsilon$ over $x,y,x\oplus y$ (conditioned on all lying in $L_{k,n}$), then $f$ agrees with a linear function on $1-\delta$ fraction of $L_{k,n}$, where $\delta = \delta(\epsilon)\to 0$ as $\epsilon \to 0$.
In a recent work, Kalai, Lifshitz, Minzer and Ziegler~\cite{KLMZ24} prove a similar result for the $n/2$-slice, in the 1\% regime.

\subsection{Organization of the paper}

We start by presenting some preliminaries in Section~\ref{sec:prelims}.
In Section~\ref{sec:gaussian_variant}, we prove a variant of Theorem~\ref{thm:intro_main} over the Gaussian distribution, which then is used in Section~\ref{sec:lin_test_failure} to prove Theorem~\ref{thm:intro_main}.
In Section~\ref{sec:query_bias}, we analyze the tradeoff between the bias $p$ and the number of queries $k$, for the existence of a valid linearity test.
Combining all results, we prove Theorem~\ref{thm:intro_querybias_main_thm} in Section~\ref{sec:putting_together}.
In Section~\ref{sec:bkm_sketch}, we outline of the proof of Theorem~\ref{thm:bkm23}.
