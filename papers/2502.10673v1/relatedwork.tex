\section{Background and Related Work}
\vspace{-0.2em}
\subsection{Retrieval Augmented Generation}
\vspace{-0.3em}
RAG \cite{karpukhin2020dense, xiong2020approximate, lewis2020retrieval} integrates information retrieval with natural language generation to enhance the quality and relevance of generated responses \cite{gao2023retrieval}. 


In general, a RAG system involves three key components: the retriever $\mathcal{R}$, the generator $\mathcal{M}_0$, and a knowledge database $\mathcal{D}_{\mathsf{base}}$. Given a user query $q$, the retriever maps the input and documents in the knowledge database into embeddings within the same space. It then searches the knowledge database to retrieve $K$ most relevant documents, $\{d_1,...d_K\}=\mathcal{R}(q, \mathcal{D}_{\mathsf{base}})$, based on the distance metric like cosine-similarity. In the generation phase, the generator produces the response given the query and the retrieved documents, i.e., $y=\mathcal{M}_0(d_1,...,d_K,q)$.

\vspace{-0.5em}

\subsection{LLMs Watermarking} 
\vspace{-0.5em}
LLM watermarking embeds watermark into the text throughout the entire generation process \cite{li2024statistical, he2024universally, li2024robust, zhao2024sok, zhao2024permute, fu2024gumbelsoft, giboulot2024watermax, wu2023dipmark, he2025dist}. This is typically achieved by either perturbing the logits of the LLM \cite{liu2024adaptive, kirchenbauer2023watermark, zhao2023provable} or manipulating the sampling process \cite{kuditipudi2023robust, christ2024undetectable}. 

In particular, robustness is a critical property of LLM watermarking, enabling the detection of watermarks even after significant text modifications. For the DMI-RAG task, a robust watermark is essential to ensure its persistence from the watermarked document to the response of the RAG system. Therefore, among all existing LLM watermarking methods, we adopt the watermarking by \citet{zhao2023provable} in our framework, due to its simplicity and provable robustness. 


\vspace{-0.5em}

\subsection{Dataset Membership Inference for RAG} 
\vspace{-0.5em}
\textbf{Data Membership Attack.} Data membership attack for RAG \cite{liu2024mask} aims to determine whether a specific data instance is included in the knowledge dataset used by the RA-LLMs. \citet{li2024seeing} introduces a gray-box approach that computes a membership score by combining the similarity between generated text and a data member with the perplexity of the generated text. \citet{anderson2024my} propose a method that uses a specially designed prompt to black-box ask whether a dataset member appears in the context and deduces the membership status based on the model's answer.

\textbf{Backdoor Attack.} For dataset membership inference in RAG, the dataset owner can proactively perform specific operations on the original dataset to systematically accumulate strong evidence of unauthorized usage. Backdoor attack \cite{chaudhari2024phantom, cheng2024trojanrag, chen2024agentpoison} is an approach used to identify unauthorized usage by embedding triggers in the dataset. These triggers cause RA-LLMs to produce specified abnormal responses when queried with certain inputs. \citet{zou2024poisonedrag} propose injecting malicious texts into the dataset to manipulate RA-LLMs into generating a predetermined incorrect answer for a specific question. In some aspects, our method shares similarities with a backdoor. However, unlike existing backdoor attacks, which compromise the functionality or performance of the original dataset, our approach is specifically designed to avoid such issues.

% , making it more suitable for the dataset protection task.

\textbf{Dataset Membership Inference.} 
Dataset Membership Inference for protection can be achieved through proactive watermark embedding.
\citet{wei2024proving} propose inserting a random sequence repeatedly into the dataset and then computing the loss of the suspicious LLM on this sampled sequence to determine the dataset's presence. Most recently, \citet{jovanovic2024ward} proposes to use a watermarked LLM to paraphrase each document in the IP-protected dataset and detect the watermark in the responses of RA-LLM. In this paper, we embed \emph{invisible} watermarks into a small number of carefully designed canaries and insert them into the IP-protected dataset. Our approach preserves the original dataset untouched while achieving high detectability.



\begin{figure*}[!ht]
    \centering
    \includegraphics[width=1\linewidth]{fig/synthesis_workflow.pdf}
    \vspace{-2.5em}
    \caption{Workflow of our canary dataset synthesis algorithm. The process begins by randomly sampling a document from the IP dataset to serve as a reference. Next, key attributes are extracted from the reference document. Using these attributes, the descriptions and relationships between synthetic entities are created. Finally, the algorithm outputs the synthetic text and a corresponding query question.}
    %\byh{It seems that the article in 4 is not directly related to $C$ and $E$?}
    % \lyp{(4) is a summary of (3), and (3) is the detail description of entities in (2)}
    % \vspace{-0.6cm}
    \vspace{-0.9em}
    \label{fig:synthesis_workflow}
    \vspace{-0.5em}
\end{figure*}

\vspace{-0.5em}