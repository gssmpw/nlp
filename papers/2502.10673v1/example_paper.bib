@article{wei2024proving,
  title={Proving membership in LLM pretraining data via data watermarks},
  author={Wei, Johnny Tian-Zheng and Wang, Ryan Yixiang and Jia, Robin},
  journal={arXiv preprint arXiv:2402.10892},
  year={2024}
}

@article{liu2024robustifying,
  title={Robustifying Safety-Aligned Large Language Models through Clean Data Curation},
  author={Liu, Xiaoqun and Liang, Jiacheng and Ye, Muchao and Xi, Zhaohan},
  journal={arXiv preprint arXiv:2405.19358},
  year={2024}
}

@article{jovanovic2024ward,
  title={Ward: Provable RAG Dataset Inference via LLM Watermarks},
  author={Jovanovi{\'c}, Nikola and Staab, Robin and Baader, Maximilian and Vechev, Martin},
  journal={arXiv preprint arXiv:2410.03537},
  year={2024}
}

@inproceedings{kirchenbauer2023watermark,
  title={A watermark for large language models},
  author={Kirchenbauer, John and Geiping, Jonas and Wen, Yuxin and Katz, Jonathan and Miers, Ian and Goldstein, Tom},
  booktitle={International Conference on Machine Learning},
  pages={17061--17084},
  year={2023},
  organization={PMLR}
}

@inproceedings{ajith2024downstream,
  title={Downstream Trade-offs of a Family of Text Watermarks},
  author={Ajith, Anirudh and Singh, Sameer and Pruthi, Danish},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2024},
  pages={14039--14053},
  year={2024}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{zhao2023provable,
  title={Provable robust watermarking for ai-generated text},
  author={Zhao, Xuandong and Ananth, Prabhanjan and Li, Lei and Wang, Yu-Xiang},
  journal={arXiv preprint arXiv:2306.17439},
  year={2023}
}

@article{izacard2021unsupervised,
  title={Unsupervised dense information retrieval with contrastive learning},
  author={Izacard, Gautier and Caron, Mathilde and Hosseini, Lucas and Riedel, Sebastian and Bojanowski, Piotr and Joulin, Armand and Grave, Edouard},
  journal={arXiv preprint arXiv:2112.09118},
  year={2021}
}

@article{ma2022specialization,
  title={Specialization in a knowledge economy},
  author={Ma, Yueyuan},
  journal={Available at SSRN},
  volume={4052990},
  year={2022}
}

@inproceedings{papineni2002bleu,
  title={Bleu: a method for automatic evaluation of machine translation},
  author={Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
  booktitle={Proceedings of the 40th annual meeting of the Association for Computational Linguistics},
  pages={311--318},
  year={2002}
}

@article{pillutla2021mauve,
  title={Mauve: Measuring the gap between neural text and human text using divergence frontiers},
  author={Pillutla, Krishna and Swayamdipta, Swabha and Zellers, Rowan and Thickstun, John and Welleck, Sean and Choi, Yejin and Harchaoui, Zaid},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={4816--4828},
  year={2021}
}

@inproceedings{wettig2024qurating,
   title={{QuRating}: Selecting High-Quality Data for Training Language Models},
   author={Wettig, Alexander and Gupta, Aatmik and Malik, Saumya and Chen, Danqi},
   booktitle={International Conference on Machine Learning (ICML)},
   year={2024}
}

@inproceedings{boteva2016full,
  title={A full-text learning to rank dataset for medical information retrieval},
  author={Boteva, Vera and Gholipour, Demian and Sokolov, Artem and Riezler, Stefan},
  booktitle={Advances in Information Retrieval: 38th European Conference on IR Research, ECIR 2016, Padua, Italy, March 20--23, 2016. Proceedings 38},
  pages={716--722},
  year={2016},
  organization={Springer}
}

@inproceedings{Dua2019DROP,
  author={Dheeru Dua and Yizhong Wang and Pradeep Dasigi and Gabriel Stanovsky and Sameer Singh and Matt Gardner},
  title={  {DROP}: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs},
  booktitle={Proc. of NAACL},
  year={2019}
}

@article{nguyen2016ms,
  title={Ms marco: A human-generated machine reading comprehension dataset},
  author={Nguyen, Tri and Rosenberg, Mir and Song, Xia and Gao, Jianfeng and Tiwary, Saurabh and Majumder, Rangan and Deng, Li},
  year={2016}
}

@article{karpukhin2020dense,
  title={Dense passage retrieval for open-domain question answering},
  author={Karpukhin, Vladimir and O{\u{g}}uz, Barlas and Min, Sewon and Lewis, Patrick and Wu, Ledell and Edunov, Sergey and Chen, Danqi and Yih, Wen-tau},
  journal={arXiv preprint arXiv:2004.04906},
  year={2020}
}

@article{xiong2020approximate,
  title={Approximate nearest neighbor negative contrastive learning for dense text retrieval},
  author={Xiong, Lee and Xiong, Chenyan and Li, Ye and Tang, Kwok-Fung and Liu, Jialin and Bennett, Paul and Ahmed, Junaid and Overwijk, Arnold},
  journal={arXiv preprint arXiv:2007.00808},
  year={2020}
}

@article{lewis2020retrieval,
  title={Retrieval-augmented generation for knowledge-intensive nlp tasks},
  author={Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and K{\"u}ttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rockt{\"a}schel, Tim and others},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={9459--9474},
  year={2020}
}

@article{he2024universally,
  title={Universally Optimal Watermarking Schemes for LLMs: from Theory to Practice},
  author={He, Haiyun and Liu, Yepeng and Wang, Ziqiao and Mao, Yongyi and Bu, Yuheng},
  journal={arXiv preprint arXiv:2410.02890},
  year={2024}
}

@article{liu2024adaptive,
  title={Adaptive text watermark for large language models},
  author={Liu, Yepeng and Bu, Yuheng},
  journal={arXiv preprint arXiv:2401.13927},
  year={2024}
}

@article{li2024statistical,
  title={A Statistical Framework of Watermarks for Large Language Models: Pivot, Detection Efficiency and Optimal Rules},
  author={Li, Xiang and Ruan, Feng and Wang, Huiyuan and Long, Qi and Su, Weijie J},
  journal={arXiv preprint arXiv:2404.01245},
  year={2024}
}

@article{li2024robust,
  title={Robust detection of watermarks for large language models under human edits},
  author={Li, Xiang and Ruan, Feng and Wang, Huiyuan and Long, Qi and Su, Weijie J},
  journal={arXiv preprint arXiv:2411.13868},
  year={2024}
}

@article{zhao2024sok,
  title={SoK: Watermarking for AI-Generated Content},
  author={Zhao, Xuandong and Gunn, Sam and Christ, Miranda and Fairoze, Jaiden and Fabrega, Andres and Carlini, Nicholas and Garg, Sanjam and Hong, Sanghyun and Nasr, Milad and Tramer, Florian and others},
  journal={arXiv preprint arXiv:2411.18479},
  year={2024}
}

@article{zhao2024permute,
  title={Permute-and-Flip: An optimally robust and watermarkable decoder for LLMs},
  author={Zhao, Xuandong and Li, Lei and Wang, Yu-Xiang},
  journal={arXiv preprint arXiv:2402.05864},
  year={2024}
}

@article{fu2024gumbelsoft,
  title={GumbelSoft: Diversified Language Model Watermarking via the GumbelMax-trick},
  author={Fu, Jiayi and Zhao, Xuandong and Yang, Ruihan and Zhang, Yuansen and Chen, Jiangjie and Xiao, Yanghua},
  journal={arXiv preprint arXiv:2402.12948},
  year={2024}
}

@article{kuditipudi2023robust,
  title={Robust distortion-free watermarks for language models},
  author={Kuditipudi, Rohith and Thickstun, John and Hashimoto, Tatsunori and Liang, Percy},
  journal={arXiv preprint arXiv:2307.15593},
  year={2023}
}

@inproceedings{christ2024undetectable,
  title={Undetectable watermarks for language models},
  author={Christ, Miranda and Gunn, Sam and Zamir, Or},
  booktitle={The Thirty Seventh Annual Conference on Learning Theory},
  pages={1125--1139},
  year={2024},
  organization={PMLR}
}

@article{giboulot2024watermax,
  title={WaterMax: breaking the LLM watermark detectability-robustness-quality trade-off},
  author={Giboulot, Eva and Furon, Teddy},
  journal={arXiv preprint arXiv:2403.04808},
  year={2024}
}

@article{oren2023proving,
  title={Proving test set contamination in black box language models},
  author={Oren, Yonatan and Meister, Nicole and Chatterji, Niladri and Ladhak, Faisal and Hashimoto, Tatsunori B},
  journal={arXiv preprint arXiv:2310.17623},
  year={2023}
}

@article{magar2022data,
  title={Data contamination: From memorization to exploitation},
  author={Magar, Inbal and Schwartz, Roy},
  journal={arXiv preprint arXiv:2203.08242},
  year={2022}
}

@article{meeus2024copyright,
  title={Copyright Traps for Large Language Models},
  author={Meeus, Matthieu and Shilov, Igor and Faysse, Manuel and de Montjoye, Yves-Alexandre},
  journal={arXiv preprint arXiv:2402.09363},
  year={2024}
}

@article{li2024seeing,
  title={Seeing is believing: Black-box membership inference attacks against retrieval augmented generation},
  author={Li, Yuying and Liu, Gaoyang and Yang, Yang and Wang, Chen},
  journal={arXiv e-prints},
  pages={arXiv--2406},
  year={2024}
}

@article{liu2024mask,
  title={Mask-based membership inference attacks for retrieval-augmented generation},
  author={Liu, Mingrui and Zhang, Sixiao and Long, Cheng},
  journal={arXiv preprint arXiv:2410.20142},
  year={2024}
}

@article{anderson2024my,
  title={Is My Data in Your Retrieval Database? Membership Inference Attacks Against Retrieval Augmented Generation},
  author={Anderson, Maya and Amit, Guy and Goldsteen, Abigail},
  journal={arXiv preprint arXiv:2405.20446},
  year={2024}
}

@article{chaudhari2024phantom,
  title={Phantom: General Trigger Attacks on Retrieval Augmented Language Generation},
  author={Chaudhari, Harsh and Severi, Giorgio and Abascal, John and Jagielski, Matthew and Choquette-Choo, Christopher A and Nasr, Milad and Nita-Rotaru, Cristina and Oprea, Alina},
  journal={arXiv preprint arXiv:2405.20485},
  year={2024}
}

@article{zou2024poisonedrag,
  title={Poisonedrag: Knowledge poisoning attacks to retrieval-augmented generation of large language models},
  author={Zou, Wei and Geng, Runpeng and Wang, Binghui and Jia, Jinyuan},
  journal={arXiv preprint arXiv:2402.07867},
  year={2024}
}

@inproceedings{hoogeveen2015cqadupstack,
  title={Cqadupstack: A benchmark data set for community question-answering research},
  author={Hoogeveen, Doris and Verspoor, Karin M and Baldwin, Timothy},
  booktitle={Proceedings of the 20th Australasian document computing symposium},
  pages={1--8},
  year={2015}
}

@article{yang2018hotpotqa,
  title={HotpotQA: A dataset for diverse, explainable multi-hop question answering},
  author={Yang, Zhilin and Qi, Peng and Zhang, Saizheng and Bengio, Yoshua and Cohen, William W and Salakhutdinov, Ruslan and Manning, Christopher D},
  journal={arXiv preprint arXiv:1809.09600},
  year={2018}
}

@article{gunn2024undetectable,
  title={An undetectable watermark for generative image models},
  author={Gunn, Sam and Zhao, Xuandong and Song, Dawn},
  journal={arXiv preprint arXiv:2410.07369},
  year={2024}
}


@article{kirchenbauer2023reliability,
  title={On the reliability of watermarks for large language models},
  author={Kirchenbauer, John and Geiping, Jonas and Wen, Yuxin and Shu, Manli and Saifullah, Khalid and Kong, Kezhi and Fernando, Kasun and Saha, Aniruddha and Goldblum, Micah and Goldstein, Tom},
  journal={arXiv preprint arXiv:2306.04634},
  year={2023}
}

@article{wu2023dipmark,
  title={Dipmark: A stealthy, efficient and resilient watermark for large language models},
  author={Wu, Yihan and Hu, Zhengmian and Zhang, Hongyang and Huang, Heng},
  journal={arXiv preprint arXiv:2310.07710},
  year={2023}
}

@inproceedings{borgeaud2022improving,
  title={Improving language models by retrieving from trillions of tokens},
  author={Borgeaud, Sebastian and Mensch, Arthur and Hoffmann, Jordan and Cai, Trevor and Rutherford, Eliza and Millican, Katie and Van Den Driessche, George Bm and Lespiau, Jean-Baptiste and Damoc, Bogdan and Clark, Aidan and others},
  booktitle={International conference on machine learning},
  pages={2206--2240},
  year={2022},
  organization={PMLR}
}


@inproceedings{khattab2020colbert,
  title={Colbert: Efficient and effective passage search via contextualized late interaction over bert},
  author={Khattab, Omar and Zaharia, Matei},
  booktitle={Proceedings of the 43rd International ACM SIGIR conference on research and development in Information Retrieval},
  pages={39--48},
  year={2020}
}

@article{he2025dist,
      title={Distributional Information Embedding: A Framework for Multi-bit Watermarking}, 
      author={Haiyun He and Yepeng Liu and Ziqiao Wang and Yongyi Mao and Yuheng Bu},
    journal={arXiv preprint arXiv:2501.16558},
    year={2025}
}

@article{sander2024radioactive,
  title={Watermarking Makes Language Models Radioactive},
  author={Sander, Tom and Fernandez, Pierre and Durmus, Alain and Douze, Matthijs and Furon, Teddy},
  journal={arXiv preprint arXiv:2402.14904},
  year={2024}
}

@article{gao2023retrieval,
  title={Retrieval-augmented generation for large language models: A survey},
  author={Gao, Yunfan and Xiong, Yun and Gao, Xinyu and Jia, Kangxiang and Pan, Jinliu and Bi, Yuxi and Dai, Yi and Sun, Jiawei and Wang, Haofen},
  journal={arXiv preprint arXiv:2312.10997},
  year={2023}
}

@article{cheng2024trojanrag,
  title={TrojanRAG: Retrieval-Augmented Generation Can Be Backdoor Driver in Large Language Models},
  author={Cheng, Pengzhou and Ding, Yidong and Ju, Tianjie and Wu, Zongru and Du, Wei and Yi, Ping and Zhang, Zhuosheng and Liu, Gongshen},
  journal={arXiv preprint arXiv:2405.13401},
  year={2024}
}

@article{chen2024agentpoison,
  title={Agentpoison: Red-teaming llm agents via poisoning memory or knowledge bases},
  author={Chen, Zhaorun and Xiang, Zhen and Xiao, Chaowei and Song, Dawn and Li, Bo},
  journal={arXiv preprint arXiv:2407.12784},
  year={2024}
}

@article{li2024fakenews,
  title={Large Language Model Agent for Fake News Detection},
  author={Li, Xinyi and Zhang, Yongfeng and Malthouse, Edward C},
  journal={arXiv preprint arXiv:2405.01593},
  year={2024}
}

@inproceedings{wang2024factcheck,
  title={Factcheck-bench: Fine-grained evaluation benchmark for automatic fact-checkers},
  author={Wang, Yuxia and Reddy, Revanth Gangi and Mujahid, Zain and Arora, Arnav and Rubashevskii, Aleksandr and Geng, Jiahui and Afzal, Osama Mohammed and Pan, Liangming and Borenstein, Nadav and Pillai, Aditya and others},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2024},
  pages={14199--14230},
  year={2024}
}