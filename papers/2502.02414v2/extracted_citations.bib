@inproceedings{Cao2021ChooseAT,
  title={Choose a Transformer: Fourier or Galerkin},
  author={Shuhao Cao},
  booktitle={NeurIPS},
  year={2021}
}

@article{Li2020NeuralOG,
  title={Neural Operator: Graph Kernel Network for Partial Differential Equations},
  author={Zong-Yi Li and Nikola B. Kovachki and Kamyar Azizzadenesheli and Burigede Liu and Kaushik Bhattacharya and Andrew Stuart and Anima Anandkumar},
  journal={arXiv preprint arXiv:2003.03485},
  year={2020}
}

@inproceedings{NIPS2017_3f5ee243,
 author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
 booktitle = {NeurIPS},
 pages = {},
 title = {Attention is All you Need},
 year = {2017}
}

@article{Wen2021UFNOA,
  title={U-FNO--An enhanced Fourier neural operator-based deep-learning model for multiphase flow},
  author={Wen, Gege and Li, Zongyi and Azizzadenesheli, Kamyar and Anandkumar, Anima and Benson, Sally M},
  journal={Advances in Water Resources},
  year={2022},
}

@inproceedings{anonymous2023factorized,
title={Factorized Fourier Neural Operators},
author={Alasdair Tran and Alexander Mathews and Lexing Xie and Cheng Soon Ong},
booktitle={ICLR},
year={2023}
}

@article{dao2022flashattention,
  title={Flashattention: Fast and memory-efficient exact attention with io-awareness},
  author={Dao, Tri and Fu, Dan and Ermon, Stefano and Rudra, Atri and R{\'e}, Christopher},
  journal={NeurIPS},
  year={2022}
}

@inproceedings{gao2019graph,
    title={Graph U-Nets},
    author={Gao, Hongyang and Ji, Shuiwang},
    booktitle={ICML},
    year={2019}
}

@article{hamilton2017inductive,
  title={Inductive representation learning on large graphs},
  author={Hamilton, Will and Ying, Zhitao and Leskovec, Jure},
  journal={NeurIPS},
  year={2017}
}

@article{hao2023gnot,
  title={GNOT: A General Neural Operator Transformer for Operator Learning},
  author={Hao, Zhongkai and Ying, Chengyang and Wang, Zhengyi and Su, Hang and Dong, Yinpeng and Liu, Songming and Cheng, Ze and Zhu, Jun and Song, Jian},
  journal={ICML},
  year={2023}
}

@article{huang2019gpipe,
  title={Gpipe: Efficient training of giant neural networks using pipeline parallelism},
  author={Huang, Yanping and Cheng, Youlong and Bapna, Ankur and Firat, Orhan and Chen, Dehao and Chen, Mia and Lee, HyoukJoong and Ngiam, Jiquan and Le, Quoc V and Wu, Yonghui and others},
  journal={NeurIPS},
  year={2019}
}

@inproceedings{instabilityGNN,
	address = {Cham},
	author = {Klabunde, Max and Lemmerich, Florian},
	booktitle = {Machine Learning and Knowledge Discovery in Databases},
	title = {On the Prediction Instability of Graph Neural Networks},
	year = {2023}
}

@article{jacobs2023deepspeed,
  title={Deepspeed ulysses: System optimizations for enabling training of extreme long sequence transformer models},
  author={Jacobs, Sam Ade and Tanaka, Masahiro and Zhang, Chengming and Zhang, Minjia and Song, Shuaiwen Leon and Rajbhandari, Samyam and He, Yuxiong},
  journal={arXiv preprint arXiv:2309.14509},
  year={2023}
}

@article{jmlr_operator,
  author  = {Nikola Kovachki and Zongyi Li and Burigede Liu and Kamyar Azizzadenesheli and Kaushik Bhattacharya and Andrew Stuart and Anima Anandkumar},
  title   = {Neural Operator: Learning Maps Between Function Spaces With Applications to PDEs},
  journal = {JMLR},
  year    = {2023},
}

@inproceedings{kitaev2020reformer,
    title       = {Reformer: The Efficient Transformer},
    author      = {Nikita Kitaev and Lukasz Kaiser and Anselm Levskaya},
    booktitle   = {ICLR},
    year        = {2020},
}

@article{li2020neural,
  title={Neural operator: Graph kernel network for partial differential equations},
  author={Li, Zongyi and Kovachki, Nikola and Azizzadenesheli, Kamyar and Liu, Burigede and Bhattacharya, Kaushik and Stuart, Andrew and Anandkumar, Anima},
  journal={arXiv preprint arXiv:2003.03485},
  year={2020}
}

@inproceedings{li2021fourier,
title={Fourier Neural Operator for Parametric Partial Differential Equations},
author={Zongyi Li and Nikola Borislavov Kovachki and Kamyar Azizzadenesheli and Burigede liu and Kaushik Bhattacharya and Andrew Stuart and Anima Anandkumar},
booktitle={ICLR},
year={2021}
}

@article{liu2023ring,
  title={Ring attention with blockwise transformers for near-infinite context},
  author={Liu, Hao and Zaharia, Matei and Abbeel, Pieter},
  journal={arXiv preprint arXiv:2310.01889},
  year={2023}
}

@article{morris2023geometric,
  title={Geometric instability of graph neural networks on large graphs},
  author={Morris, Emily and Shen, Haotian and Du, Weiling and Sajjad, Muhammad Hamza and Shi, Borun},
  journal={arXiv preprint arXiv:2308.10099},
  year={2023}
}

@article{performer,
  title={Rethinking Attention with Performers},
  author={Krzysztof Choromanski and Valerii Likhosherstov and David Dohan and Xingyou Song and Andreea Gane and Tam{\'a}s Sarl{\'o}s and Peter Hawkins and Jared Davis and Afroz Mohiuddin and Lukasz Kaiser and David Belanger and Lucy J. Colwell and Adrian Weller},
  journal={ICLR},
  year={2021},
}

@article{qin2022devil,
  title={The devil in linear transformer},
  author={Qin, Zhen and Han, Xiaodong and Sun, Weixuan and Li, Dongxu and Kong, Lingpeng and Barnes, Nick and Zhong, Yiran},
  journal={arXiv preprint arXiv:2210.10340},
  year={2022}
}

@article{rahman2022u,
  title={U-no: U-shaped neural operators},
  author={Rahman, Md Ashiqur and Ross, Zachary E and Azizzadenesheli, Kamyar},
  journal={TMLR},
  year={2023}
}

@inproceedings{ronneberger2015u,
  title={U-net: Convolutional networks for biomedical image segmentation},
  author={Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  booktitle={MICCAI},
  year={2015}
}

@article{shoeybi2019megatron,
  title={Megatron-lm: Training multi-billion parameter language models using model parallelism},
  author={Shoeybi, Mohammad and Patwary, Mostofa and Puri, Raul and LeGresley, Patrick and Casper, Jared and Catanzaro, Bryan},
  journal={arXiv preprint arXiv:1909.08053},
  year={2019}
}

@article{solanki2003finite,
  title={Finite element modeling of plasticity-induced crack closure with emphasis on geometry and mesh refinement effects},
  author={Solanki, Kiran and Daniewicz, SR and Newman Jr, JC},
  journal={Engineering Fracture Mechanics},
  year={2003},
  publisher={Elsevier}
}

@inproceedings{wang2024LNO,
  title={Latent Neural Operator for Solving Forward and Inverse PDE Problems},
  author={Tian Wang and Chuang Wang},
  booktitle={NeurIPS},
  year={2024}
}

@inproceedings{wu2023LSM,
  title={Solving High-Dimensional PDEs with Latent Spectral Models},
  author={Haixu Wu and Tengge Hu and Huakun Luo and Jianmin Wang and Mingsheng Long},
  booktitle={ICML},
  year={2023}
}

@inproceedings{wu2024Transolver,
  title={Transolver: A Fast Transformer Solver for PDEs on General Geometries},
  author={Haixu Wu and Huakun Luo and Haowen Wang and Jianmin Wang and Mingsheng Long},
  booktitle={ICML},
  year={2024}
}

@article{zhuang2023optimizing,
  title={On optimizing the communication of model parallelism},
  author={Zhuang, Yonghao and Zheng, Lianmin and Li, Zhuohan and Xing, Eric and Ho, Qirong and Gonzalez, Joseph and Stoica, Ion and Zhang, Hao and Zhao, Hexu},
  journal={Proceedings of Machine Learning and Systems},
  volume={5},
  year={2023}
}

