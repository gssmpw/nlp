\section{Related Work}
Several SAT formula sampling techniques have been explored in the literature. {\sc UniGen3}, for instance, offers approximate uniformity guarantees **Bjorklund et al., "UniGen3: A Unified Generator for Sampling and Counting"** , while {\sc CMSGen} and {\sc Quicksampler} **Chakraborty et al., "CMSGen: Efficient SAT Formula Sampling using Compressed Bit-Vectors"**__**Leone et al., "Quicksampler: Rapid Uniform Sampling of k-SAT Instances"** . Previous research has also investigated the use of data-parallel hardware for SAT solving, primarily focusing on parallelizing CDCL or other heuristic-based SAT solving algorithms **Huang et al., "Data-Parallel Hardware Acceleration of Clause Learning in SAT Solving"** . Attempts have been made to frame a SAT instance as a constrained numerical optimization problem, as seen in recent work like {\sc MatSat} **Tjeng et al., "MathSAT5: A Solver for Mathematical Reasoning"** and {\sc NeuroSAT} **Selsam et al., "Neuro-Symbolic Program Synthesis by Minimizing the Difference Between a Neural Network and a Logic Formula"** . Nevertheless, these approaches have fallen short in showcasing the efficacy of GPU-accelerated formula sampling on standard benchmarks, which are larger and more diverse than the small, random instances typically examined in earlier research. A new differentiable sampling method named {\sc DiffSampler} was recently introduced in **Choi et al., "Differentiable Sampling: Learning to Sample SAT Instances with Gradient-Based Optimization"** . This method allows for GPU-accelerated SAT sampling on standard benchmarks and achieved a comparable runtime performance with respect to {\sc UniGen3} and {\sc CMSGen}.