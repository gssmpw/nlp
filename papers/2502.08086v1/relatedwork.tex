\section{Related Work}
Several SAT formula sampling techniques have been explored in the literature. {\sc UniGen3}, for instance, offers approximate uniformity guarantees \cite{yash2022barbarik}, while {\sc CMSGen} and {\sc Quicksampler} \cite{dutra2018quicksampler} prioritize sampling efficiency. Previous research has also investigated the use of data-parallel hardware for SAT solving, primarily focusing on parallelizing CDCL or other heuristic-based SAT solving algorithms \cite{costa2013parallelization, osama2021sat}. Attempts have been made to frame a SAT instance as a constrained numerical optimization problem, as seen in recent work like {\sc MatSat} \cite{sato2021matsat} and {\sc NeuroSAT} \cite{amizadeh2018learning}. Nevertheless, these approaches have fallen short in showcasing the efficacy of GPU-accelerated formula sampling on standard benchmarks, which are larger and more diverse than the small, random instances typically examined in earlier research. A new differentiable sampling method named {\sc DiffSampler} was recently introduced in \cite{Ardakani2024diffsampler}. This method allows for GPU-accelerated SAT sampling on standard benchmarks and achieved a comparable runtime performance with respect to {\sc UniGen3} and {\sc CMSGen}.