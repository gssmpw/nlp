@article{Karamcheti2023LanguageDrivenRL,
  title={Language-Driven Representation Learning for Robotics},
  author={Siddharth Karamcheti and Suraj Nair and Annie S. Chen and Thomas Kollar and Chelsea Finn and Dorsa Sadigh and Percy Liang},
  journal={ArXiv},
  year={2023},
  volume={abs/2302.12766},
  url={https://api.semanticscholar.org/CorpusID:257205716}
}

@misc{ahn2022icanisay,
      title={Do As I Can, Not As I Say: Grounding Language in Robotic Affordances}, 
      author={Michael Ahn and Anthony Brohan and Noah Brown and Yevgen Chebotar and Omar Cortes and Byron David and Chelsea Finn and Chuyuan Fu and Keerthana Gopalakrishnan and Karol Hausman and Alex Herzog and Daniel Ho and Jasmine Hsu and Julian Ibarz and Brian Ichter and Alex Irpan and Eric Jang and Rosario Jauregui Ruano and Kyle Jeffrey and Sally Jesmonth and Nikhil J Joshi and Ryan Julian and Dmitry Kalashnikov and Yuheng Kuang and Kuang-Huei Lee and Sergey Levine and Yao Lu and Linda Luu and Carolina Parada and Peter Pastor and Jornell Quiambao and Kanishka Rao and Jarek Rettinghouse and Diego Reyes and Pierre Sermanet and Nicolas Sievers and Clayton Tan and Alexander Toshev and Vincent Vanhoucke and Fei Xia and Ted Xiao and Peng Xu and Sichun Xu and Mengyuan Yan and Andy Zeng},
      year={2022},
      eprint={2204.01691},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2204.01691}, 
}

@misc{belkhale2024minivla,
      title={MiniVLA: A Better VLA with a Smaller Footprint}, 
      author={Suneel Belkhale and Dorsa Sadigh},
      url={https://github.com/Stanford-ILIAD/openvla-mini},
      year={2024},
}

@article{black2024pi_0,
  title={pi0: A Vision-Language-Action Flow Model for General Robot Control},
  author={Black, Kevin and Brown, Noah and Driess, Danny and Esmail, Adnan and Equi, Michael and Finn, Chelsea and Fusai, Niccolo and Groom, Lachy and Hausman, Karol and Ichter, Brian and others},
  journal={arXiv preprint arXiv:2410.24164},
  year={2024}
}

@article{brohan2023rt,
  title={Rt-2: Vision-language-action models transfer web knowledge to robotic control},
  author={Brohan, Anthony and Brown, Noah and Carbajal, Justice and Chebotar, Yevgen and Chen, Xi and Choromanski, Krzysztof and Ding, Tianli and Driess, Danny and Dubey, Avinava and Finn, Chelsea and others},
  journal={arXiv preprint arXiv:2307.15818},
  year={2023}
}

@misc{covariant_ai_2024,
author = "Andrew Sohn et al.",
title = "Introducing RFM-1: Giving robots human-like reasoning capabilities",
url = "https://covariant.ai/insights/introducing-rfm-1-giving-robots-human-like-reasoning-capabilities/",
year = "2024",
}

@article{duan2024manipulate,
  title={Manipulate-anything: Automating real-world robots using vision-language models},
  author={Duan, Jiafei and Yuan, Wentao and Pumacay, Wilbert and Wang, Yi Ru and Ehsani, Kiana and Fox, Dieter and Krishna, Ranjay},
  journal={arXiv preprint arXiv:2406.18915},
  year={2024}
}

@article{durante2024interactive,
  title={An interactive agent foundation model},
  author={Durante, Zane and Sarkar, Bidipta and Gong, Ran and Taori, Rohan and Noda, Yusuke and Tang, Paul and Adeli, Ehsan and Lakshmikanth, Shrinidhi Kowshika and Schulman, Kevin and Milstein, Arnold and others},
  journal={arXiv preprint arXiv:2402.05929},
  year={2024}
}

@inproceedings{gadre2023cows,
  title={Cows on pasture: Baselines and benchmarks for language-driven zero-shot object navigation},
  author={Gadre, Samir Yitzhak and Wortsman, Mitchell and Ilharco, Gabriel and Schmidt, Ludwig and Song, Shuran},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={23171--23181},
  year={2023}
}

@misc{huang2022innermonologueembodiedreasoning,
      title={Inner Monologue: Embodied Reasoning through Planning with Language Models}, 
      author={Wenlong Huang and Fei Xia and Ted Xiao and Harris Chan and Jacky Liang and Pete Florence and Andy Zeng and Jonathan Tompson and Igor Mordatch and Yevgen Chebotar and Pierre Sermanet and Noah Brown and Tomas Jackson and Linda Luu and Sergey Levine and Karol Hausman and Brian Ichter},
      year={2022},
      eprint={2207.05608},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2207.05608}, 
}

@misc{huang2022languagemodelszeroshotplanners,
      title={Language Models as Zero-Shot Planners: Extracting Actionable Knowledge for Embodied Agents}, 
      author={Wenlong Huang and Pieter Abbeel and Deepak Pathak and Igor Mordatch},
      year={2022},
      eprint={2201.07207},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2201.07207}, 
}

@inproceedings{huang2023embodied,
  title={An Embodied Generalist Agent in 3D World},
  author={Huang, Jiangyong and Yong, Silong and Ma, Xiaojian and Linghu, Xiongkun and Li, Puhao and Wang, Yan and Li, Qing and Zhu, Song-Chun and Jia, Baoxiong and Huang, Siyuan},
  booktitle={Proceedings of the International Conference on Machine Learning (ICML)},
  year={2024}
}

@article{huang2023voxposer,
  title={Voxposer: Composable 3d value maps for robotic manipulation with language models},
  author={Huang, Wenlong and Wang, Chen and Zhang, Ruohan and Li, Yunzhu and Wu, Jiajun and Fei-Fei, Li},
  journal={arXiv preprint arXiv:2307.05973},
  year={2023}
}

@article{kim2024openvla,
  title={OpenVLA: An Open-Source Vision-Language-Action Model},
  author={Kim, Moo Jin and Pertsch, Karl and Karamcheti, Siddharth and Xiao, Ted and Balakrishna, Ashwin and Nair, Suraj and Rafailov, Rafael and Foster, Ethan and Lam, Grace and Sanketi, Pannag and others},
  journal={arXiv preprint arXiv:2406.09246},
  year={2024}
}

@article{li2023vision,
  title={Vision-language foundation models as effective robot imitators},
  author={Li, Xinghang and Liu, Minghuan and Zhang, Hanbo and Yu, Cunjun and Xu, Jie and Wu, Hongtao and Cheang, Chilam and Jing, Ya and Zhang, Weinan and Liu, Huaping and others},
  journal={arXiv preprint arXiv:2311.01378},
  year={2023}
}

@article{liu2024rdt,
  title={RDT-1B: a Diffusion Foundation Model for Bimanual Manipulation},
  author={Liu, Songming and Wu, Lingxuan and Li, Bangguo and Tan, Hengkai and Chen, Huayu and Wang, Zhengyi and Xu, Ke and Su, Hang and Zhu, Jun},
  journal={arXiv preprint arXiv:2410.07864},
  year={2024}
}

@article{ma2022vip,
  title={Vip: Towards universal visual reward and representation via value-implicit pre-training},
  author={Ma, Yecheng Jason and Sodhani, Shagun and Jayaraman, Dinesh and Bastani, Osbert and Kumar, Vikash and Zhang, Amy},
  journal={arXiv preprint arXiv:2210.00030},
  year={2022}
}

@inproceedings{ma2023liv,
  title={Liv: Language-image representations and rewards for robotic control},
  author={Ma, Yecheng Jason and Kumar, Vikash and Zhang, Amy and Bastani, Osbert and Jayaraman, Dinesh},
  booktitle={International Conference on Machine Learning},
  pages={23301--23320},
  year={2023},
  organization={PMLR}
}

@article{majumdar2023we,
  title={Where are we in the search for an artificial visual cortex for embodied intelligence?},
  author={Majumdar, Arjun and Yadav, Karmesh and Arnaud, Sergio and Ma, Jason and Chen, Claire and Silwal, Sneha and Jain, Aryan and Berges, Vincent-Pierre and Wu, Tingfan and Vakil, Jay and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={655--677},
  year={2023}
}

@inproceedings{nair2022r3m,
  title={R3m: A universal visual representation for robot manipulation},
  author={Nair, Suraj and Rajeswaran, Aravind and Kumar, Vikash and Finn, Chelsea and Gupta, Abhinav},
  booktitle={CoRL},
  year={2022}
}

@article{o2023open,
  title={Open x-embodiment: Robotic learning datasets and rt-x models},
  author={O'Neill, Abby and Rehman, Abdul and Gupta, Abhinav and Maddukuri, Abhiram and Gupta, Abhishek and Padalkar, Abhishek and Lee, Abraham and Pooley, Acorn and Gupta, Agrim and Mandlekar, Ajay and others},
  journal={arXiv preprint arXiv:2310.08864},
  year={2023}
}

@misc{pertsch2025fastefficientactiontokenization,
      title={FAST: Efficient Action Tokenization for Vision-Language-Action Models}, 
      author={Karl Pertsch and Kyle Stachowicz and Brian Ichter and Danny Driess and Suraj Nair and Quan Vuong and Oier Mees and Chelsea Finn and Sergey Levine},
      year={2025},
      eprint={2501.09747},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2501.09747}, 
}

@misc{singh2022progpromptgeneratingsituatedrobot,
      title={ProgPrompt: Generating Situated Robot Task Plans using Large Language Models}, 
      author={Ishika Singh and Valts Blukis and Arsalan Mousavian and Ankit Goyal and Danfei Xu and Jonathan Tremblay and Dieter Fox and Jesse Thomason and Animesh Garg},
      year={2022},
      eprint={2209.11302},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2209.11302}, 
}

@misc{song2023llmplannerfewshotgroundedplanning,
      title={LLM-Planner: Few-Shot Grounded Planning for Embodied Agents with Large Language Models}, 
      author={Chan Hee Song and Jiaman Wu and Clayton Washington and Brian M. Sadler and Wei-Lun Chao and Yu Su},
      year={2023},
      eprint={2212.04088},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2212.04088}, 
}

@article{stone2023open,
  title={Open-world object manipulation using pre-trained vision-language models},
  author={Stone, Austin and Xiao, Ted and Lu, Yao and Gopalakrishnan, Keerthana and Lee, Kuang-Huei and Vuong, Quan and Wohlhart, Paul and Kirmani, Sean and Zitkovich, Brianna and Xia, Fei and others},
  journal={arXiv preprint arXiv:2303.00905},
  year={2023}
}

@article{wayve_ai_2024,
author = "Wayve",
title = "LINGO-2: Driving with Natural Language",
url = "https://wayve.ai/thinking/lingo-2-driving-with-language/",
year = "2024"}

@article{wen2024tinyvla,
  title={TinyVLA: Towards Fast, Data-Efficient Vision-Language-Action Models for Robotic Manipulation},
  author={Wen, Junjie and Zhu, Yichen and Li, Jinming and Zhu, Minjie and Wu, Kun and Xu, Zhiyuan and Cheng, Ran and Shen, Chaomin and Peng, Yaxin and Feng, Feifei and others},
  journal={arXiv preprint arXiv:2409.12514},
  year={2024}
}

@article{zhen20243dvla,
  author = {Zhen, Haoyu and Qiu, Xiaowen and Chen, Peihao and Yang, Jincheng and Yan, Xin and Du, Yilun and Hong, Yining and Gan, Chuang},
  title = {3D-VLA: 3D Vision-Language-Action Generative World Model},
  journal = {arXiv preprint arXiv:2403.09631},
  year = {2024},
}

