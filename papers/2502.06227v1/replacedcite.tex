\section{Related work}
\label{section:related_work}

\subsection{Deep-learning-based point cloud semantic segmentation}

\subsubsection{Fully supervised methods}

Some of the first deep learning architectures for semantic segmentation of point clouds discretized the inputs by projecting the point cloud onto a plane from several perspectives and subsequently utilized 2D convolutional neural networks (CNNs) ____. Later, multiple works, such as SqueezeSeg and its successors, proposed using spherical projections to alleviate the problem of occlusions and defects present in multi-view projections ____.

Architectures such as SegCloud ____ and PointGrid ____ first voxelize the input clouds and then perform semantic segmentation with a 3D CNN. Since the cubical scaling of the memory footprint of 3D convolutions poses a significant limitation in terms of both voxel size and depth of the networks, ____ proposed using submanifold sparse convolutions (SSCs) for semantic segmentation of point clouds. SSCs significantly decreased the computational load in comparison to 3D CNNs, while simultaneously achieving state-of-the-art performance. ____ further generalized SSCs for generic input and output coordinates as well as arbitrary kernel shapes.

Besides voxelization, a variety of more complex discretization approaches that exploit the inherent sparsity of point clouds have been proposed. Examples include OctNet ____ and O-CNN ____, which both utilize novel octree structures, as well as SPLATNet ____ and LatticeNet ____, which opt for lattice-based data structures.

PointNet ____ was the first neural network capable of processing raw point clouds directly. However, PointNets inability to capture local geometric information hindered its performance in semantic segmentation tasks. To this end, the authors introduced an improved version, PointNet++, which utilized a hierarchical structure for extracting local features from small point neighborhoods  ____. ____ proposed RandLA-Net for efficient semantic segmentation of large-scale point clouds. The network achieved significant performance gains through an innovative use of random downsampling and a novel local feature aggregation module.

Several works have proposed pointwise convolutions as an alternative to applying CNNs to discretized point clouds. PointCNN ____ introduced the $\bm{\chi}$-convolution which leveraged spatially-local correlation from unstructured point cloud data, while KPConv ____ used a set of kernel points to determine where each convolution kernel weight is applied. On the other hand, since point clouds can easily be transformed into graph representations, graph convolutional neural networks (GCNN) have also been a popular approach for semantic segmentation. SPG ____ combined GCNNs with superpoint representations, while DGCNN ____ and SPH3D ____ both introduced novel graph convolutional operators designed specifically for point clouds.

More recently, following the success of transformer-based architectures in natural language processing and computer vision tasks, a number of works have proposed architectures adapted for semantic segmentation of point cloud data ____.

\subsubsection{Weakly supervised methods}

Manually generating ground truth labels for large amounts of data is extremely time-consuming, especially when it comes to data formats that are challenging to annotate, like 3D point clouds. Weakly supervised deep learning attempts to alleviate this problem by training models with a very limited amount of ground truth data.

Since manually generating semantic annotations for 2D images requires significantly less labeling than 3D point clouds, utilizing 2D ground truth labels for 3D deep learning is a form of weak supervision, which some works have explored ____. However, the more common strategy for weak supervision is using a limited amount of ground truth labels, such that only a small minority of all available data with annotations is used for training. In principle, training such a model would only require manually annotating a small subset of points. ____ were among the first to apply this form of weak supervision in the context of point cloud semantic segmentation. By combining a 4-part loss function with label propagation at the inference stage, their method achieved an accuracy comparable to that of supervised baselines with only 10\% of the labels. PSD ____ with its perturbed self-distillation framework achieved performance comparable to RandLA-Net using 1\% of available point annotations, while SQN ____ introduced a point feature query network which enabled back-propagating training signals from sparsely annotated points to a wider context, resulting in performance comparable to supervised baselines on multiple benchmark data sets using just 0.1\% of ground truth labels. Transformer architectures have also been adapted to weakly supervised point cloud semantic segmentation by ____. Contrastive scene contexts proposed a slightly different approach for training semantic segmentation networks in a weakly supervised manner by introducing an unsupervised contrastive pretraining phase ____.

In contrast to methods that only utilize a limited amount of labeled data for training, pseudo-label-based methods assign artificial labels for unlabeled data points. SSPC-Net ____ and HybridCR ____ both presented weakly supervised point cloud semantic segmentation frameworks based on pseudo-labels. The former utilized a combination of superpoints and dynamic label propagation, while the latter imposed a contrastive loss on pseudo-labels generated from backbone predictions. LESS ____ presented a novel strategy for generating sparsely annotated data, where the labels are divided into three separate categories during training sparse, weak, and propagated, each of which has a separate contrastive loss function.

\subsubsection{Unsupervised methods}

Research on unsupervised deep learning approaches for semantic segmentation of point clouds remains fairly limited. The few existing architectures all utilize some form of deep clustering, where extracted feature vectors are clustered and subsequently used as pseudo-labels, which are iteratively updated during training.

GrowSP ____ first oversegments the input point clouds into superpoints and subsequently constructs superpoint level feature representations based on pointwise feature vectors from a sparse convolutional neural network (SCNN) feature extractor. The features are then clustered with $k$-means to obtain pseudo-labels for training the network. U3DS$^{3}$ ____ and PointDC ____ both utilize a very similar framework based on oversegmented point clouds and a 3D CNN backbone. To improve feature robustness, U3DS$^{3}$ used two separate pathways in the feature extractor combined with a two-part loss function. On the other hand, PointDC utilizes cross-modal distillation (CMD), where the input point clouds are first converted into multi-view images and passed as input to a pretrained unsupervised 2D feature extractor. The 2D features are subsequently projected back into 3D and used as supervision for training the feature extractor network.

Perhaps unsurprisingly, the performance of 3D unsupervised approaches is far from state-of-the-art supervised and weakly supervised methods in terms of segmentation accuracy. However, models such as GrowSP and U3DS$^{3}$ both show great potential and achieve results that are comparable to early supervised architectures such as PointNet ____.

\subsection{Multispectral laser scanning}

Multispectral LiDAR represents the next generation of laser scanning and has been shown to be beneficial in various applications related to vegetation and object classification ____. MS representations provide a large number of spectral features, which have the potential to yield improvements in automatic classification and segmentation of point clouds ____. Forestry and ecology have been some of the most popular applications for utilizing multispectral data ____ and its feasibility has been demonstrated in a wide variety of tasks, including individual tree segmentation ____, tree species classification \cite[see e.g][]{yu2017single,budei2018identifying,lindeberg2021classification}, stem volume estimation ____, leaf--wood separation ____, forest environment classification ____, and structure and physiology measurements in forest ecosystems ____. Notably, ____, ____, and ____ all found that multispectral data improved the classification accuracy of individual tree species in boreal forests in comparison to monospectral data. Similarly, ____ and ____ both established that multispectral data significantly improved detection accuracy in individual tree segmentation.

Outside of forestry applications, multispectral data has been used for a wide variety of remote sensing tasks, including change detection ____, road mapping ____, and land cover classification ____, which appears to be the most popular application. Similarly to the case of tree species classification, several works have demonstrated that utilizing intensity information from multiple wavelengths improves the accuracy of land cover classifiers ____. More recent research efforts on land cover classification using multispectral data have focused on deep learning approaches ____, including weakly supervised methods ____. ____ proposed GroupSP, a fully unsupervised DL framework based on GrowSP designed for semantic segmentation of multispectral point clouds depicting urban environments.

\subsection{Leaf--wood separation}

\subsubsection{Unsupervised algorithms}

Traditional leaf--wood separation algorithms can broadly be divided into two classes, radiometry-based methods and methods based on point cloud geometry ____. Such algorithms are unsupervised, since neither approach requires any prior knowledge about the classes of individual points, rather, the classification is based on heuristic assumptions about the geometric or radiometric properties of wood points, as well as the general structure of trees.

____ and ____ both extracted wood points from TLS scans based on two fixed thresholds determined through careful data analysis. On the other hand, ____ extracted wood points from simulated full waveform LiDAR using a single intensity threshold, which was optimized by applying the density-based spatial clustering of applications with noise (DBSCAN) ____ algorithm to leaf-off point clouds. Similarly, ____ detected wood points from full waveform TLS scans with a single threshold based on the distribution of reflectance value and pulse width ratios. By merging point clouds from near-infrared and shortwave-infrared scanners, ____ demonstrated the potential for improving radiometry-based classification of wood and foliage points through the use of multispectral data. Radiometry-based methods have fallen out of favor in more recent research due to a few notable limitations, such as external factors influencing the optical properties that thresholding relies on ____ and differences in attributes of different scanners and tree species that limit the generalization of thresholds to other types of data ____.

Early geometry-based leaf--wood separation algorithms were generally designed for the purpose of 3D reconstruction of trees, rather than semantic segmentation. ____ separated wood points starting from predefined root points using Dijkstra's shortest path algorithm, while ____ extracted initial branch structure graphs with multi-root Dijkstraâ€™s algorithm. On the other hand, ____ proposed a local approach for constructing precision tree models from TLS scans where the wooden components are iteratively reconstructed from small connected surface patches. ____ clustered geometric descriptors of point clouds representing individual trees with a Gaussian mixture model (GMM) and subsequently manually classified the clusters into trunk, branches, and foliage.

____ presented one of the first geometry-based algorithms designed for leaf--wood separation from point clouds of individual trees. Their approach detects initial wood proposals using thresholds for fitted circles and lines, which is followed by Dijkstra's shortest path algorithm and range search. ____ proposed a leaf--wood separation method for entire forest scenes, where wood points are detected through dynamic segment merging of superpoints and linearity thresholding.

A significant number of geometric leaf--wood separation algorithms are based on modeling the point cloud as a graph. LeWoS ____ estimates the wood probability of connected components in the point cloud graph and subsequently applies regularization to form the final prediction. ____ later improved the method with additional geometric features and graph optimization after the initial wood probability estimation. On the other hand, GBS ____ performs leaf--wood separation on graph representations of point clouds depicting individual trees using a combination of shortest path analysis, multi-scale thresholding based on geometric descriptors, and region growing. The algorithm of ____ combines GMM clustering and graph-segmentation by utilizing four separate classification branches, which are then merged into a single class prediction for each point.

Outside of graph-based approaches, ____ classified wood and foliage using local point cloud curvature and connected components. ____ proposed a statistical approach, which first fits a GMM to a set of geometric point cloud descriptors and subsequently detects inflection points between the resulting centroids and utilizes them as flexible thresholds for discerning between leaf and wood points.

\subsubsection{Machine- and deep-learning-based approaches}

A wide variety of fully supervised machine- and deep-learning-based approaches have been proposed for leaf--wood separation. Supervised methods have two advantages over unsupervised algorithms: they tend to be more accurate ____ and generally require considerably less hyperparameter optimization. However, the obvious drawback of utilizing supervised learning is the requirement for manually generated pointwise ground truth labels. To the best of our knowledge, neither weakly supervised nor unsupervised learning has been applied to leaf--wood separation in any previous work.

____ introduced GAFPC for supervised leaf--wood separation, which combines GMMs with six consecutive filters designed to correct misclassified points and remove noise. ____ trained a support vector machine (SVM) to separate wood and foliage points in TLS scans of individual deciduous trees, achieving an overall accuracy of over 90\% for most species. To assess the feasibility of supervised machine learning for leaf--wood separation, ____ conducted a performance comparison between SVM, naive Bayes classifier, GMM, and random forest. Although a majority of the approaches reached an overall accuracy of at least 95\%, random forest proved the most accurate.

____ used a random forest classifier for separating leaf and wood points from dual-wavelength full waveform TLS point clouds, while ____ trained a random forest classifier for leaf--wood separation of RGB colorized TLS data with optimal geometric and radiometric features obtained using adaptive radius near-neighbor search. Similarly, ____ combined random forest classifiers with a novel multi-scale strategy, where geometric features are computed for several neighborhood sizes. ____ compared the leaf--wood separation accuracy of random forest and two gradient boosting methods using similar multi-scale features, with random forest yielding the best performance.

Point cloud CNNs have been one of the most popular approaches for DL-based semantic segmentation of forest data. One of the earliest works to apply deep learning to the task of leaf--wood separation utilized a 3D fully convolutional neural network for semantic segmentation of TLS forest point clouds, processing the inputs as $128\times128\times128$ blocks of uniform voxels ____. ____ proposed a pipeline for segmenting ALS forest data, where individual trees were first delineated from rasterized point clouds using Faster R-CNN ____ followed by semantic segmentation with a 3D CNN inspired by VoxNet ____. The performance of the pipeline was further improved in later work with the inclusion of LiDAR intensity as one of the input features for the semantic segmentation network ____. ____ introduced a slightly different approach, where TLS point clouds are first partitioned into geometrically consistent regions, after which under-represented geometric features are compensated with a novel feature balance module. Finally, the balanced data is used for training a PointCNN semantic segmentation network.

In addition to CNNs, both the standard PointNet++ architecture and modified variants have been applied for leaf--wood separation in multiple works. ____ and ____ both utilized a standard PointNet++ model for semantic segmentation of forest TLS point clouds, while ____ combined geometric leaf--wood separation algorithms with a modified PointNet++ and trained it with simulated TLS point clouds of individual trees. On the other hand, ____ proposed a sensor-agnostic semantic segmentation model based on a modified PointNet++ backbone trained on a diverse data set consisting of point clouds captured with various types of laser scanners.

____ presented a novel approach for semantic segmentation of MLS forest point clouds using raw (non-georeferenced) 2D laser scanner profiles as a series of 2D rasters, each of which contained the ranges, reflectances and echo deviations measured during a single scanner mirror rotation. Their U-Net-based 2D CNN achieved performance comparable with RandLA-Net at a speed sufficient for real-time applications.

While a majority of research efforts have been focused on data preprocessing and feature engineering, more novel semantic segmentation architectures for leaf--wood separation have also been proposed. LWSNet ____ augmented a standard 3D U-Net with local contextual feature enhancement via a rearrangement attention mechanism and residual connection optimization, while MDC-Net ____ introduced a novel multi-directional collaborative convolutional module designed for extracting discriminative features for leaf--wood separation and combined it with a multi-scale 3D CNN.

More recently, ____ proposed ForAINet for panoptic segmentation of forest point clouds. The architecture utilizes a 3D SCNN U-Net for feature extraction followed by three separate branches for semantic prediction, center offset prediction, and feature embedding.