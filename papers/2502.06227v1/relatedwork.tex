\section{Related work}
\label{section:related_work}

\subsection{Deep-learning-based point cloud semantic segmentation}

\subsubsection{Fully supervised methods}

Some of the first deep learning architectures for semantic segmentation of point clouds discretized the inputs by projecting the point cloud onto a plane from several perspectives and subsequently utilized 2D convolutional neural networks (CNNs) \citep{su2015multiview,boulch2018snapnet}. Later, multiple works, such as SqueezeSeg and its successors, proposed using spherical projections to alleviate the problem of occlusions and defects present in multi-view projections \citep{wu2018squeezeseg,wu2019squeezesegv2,milioto2019rangenet++,xu2020squeezesegv3}.

Architectures such as SegCloud \citep{tchapmi2017segcloud} and PointGrid \citep{le2018pointgrid} first voxelize the input clouds and then perform semantic segmentation with a 3D CNN. Since the cubical scaling of the memory footprint of 3D convolutions poses a significant limitation in terms of both voxel size and depth of the networks, \cite{graham20183d} proposed using submanifold sparse convolutions (SSCs) for semantic segmentation of point clouds. SSCs significantly decreased the computational load in comparison to 3D CNNs, while simultaneously achieving state-of-the-art performance. \cite{choy20194d} further generalized SSCs for generic input and output coordinates as well as arbitrary kernel shapes.

Besides voxelization, a variety of more complex discretization approaches that exploit the inherent sparsity of point clouds have been proposed. Examples include OctNet \citep{riegler2017octnet} and O-CNN \citep{wang2017ocnn}, which both utilize novel octree structures, as well as SPLATNet \citep{su2018splatnet} and LatticeNet \citep{rosu2019latticenet}, which opt for lattice-based data structures.

PointNet \citep{qi2017pointnet} was the first neural network capable of processing raw point clouds directly. However, PointNets inability to capture local geometric information hindered its performance in semantic segmentation tasks. To this end, the authors introduced an improved version, PointNet++, which utilized a hierarchical structure for extracting local features from small point neighborhoods  \citep{qi2017pointnet++}. \cite{hu2020randlanet} proposed RandLA-Net for efficient semantic segmentation of large-scale point clouds. The network achieved significant performance gains through an innovative use of random downsampling and a novel local feature aggregation module.

Several works have proposed pointwise convolutions as an alternative to applying CNNs to discretized point clouds. PointCNN \citep{li2018pointcnn} introduced the $\bm{\chi}$-convolution which leveraged spatially-local correlation from unstructured point cloud data, while KPConv \citep{thomas2019kpconv} used a set of kernel points to determine where each convolution kernel weight is applied. On the other hand, since point clouds can easily be transformed into graph representations, graph convolutional neural networks (GCNN) have also been a popular approach for semantic segmentation. SPG \citep{landrieu2018large} combined GCNNs with superpoint representations, while DGCNN \citep{wang2019dynamic} and SPH3D \citep{lei2021spherical} both introduced novel graph convolutional operators designed specifically for point clouds.

More recently, following the success of transformer-based architectures in natural language processing and computer vision tasks, a number of works have proposed architectures adapted for semantic segmentation of point cloud data \citep{guo2021pct,zhao2021point,wu2022point,wu2024point,robert2023efficient}.

\subsubsection{Weakly supervised methods}

Manually generating ground truth labels for large amounts of data is extremely time-consuming, especially when it comes to data formats that are challenging to annotate, like 3D point clouds. Weakly supervised deep learning attempts to alleviate this problem by training models with a very limited amount of ground truth data.

Since manually generating semantic annotations for 2D images requires significantly less labeling than 3D point clouds, utilizing 2D ground truth labels for 3D deep learning is a form of weak supervision, which some works have explored \citep{wang2019towards,kweon2022joint}. However, the more common strategy for weak supervision is using a limited amount of ground truth labels, such that only a small minority of all available data with annotations is used for training. In principle, training such a model would only require manually annotating a small subset of points. \cite{xu2020weakly} were among the first to apply this form of weak supervision in the context of point cloud semantic segmentation. By combining a 4-part loss function with label propagation at the inference stage, their method achieved an accuracy comparable to that of supervised baselines with only 10\% of the labels. PSD \citep{zhang2021perturbed} with its perturbed self-distillation framework achieved performance comparable to RandLA-Net using 1\% of available point annotations, while SQN \citep{hu2022sqn} introduced a point feature query network which enabled back-propagating training signals from sparsely annotated points to a wider context, resulting in performance comparable to supervised baselines on multiple benchmark data sets using just 0.1\% of ground truth labels. Transformer architectures have also been adapted to weakly supervised point cloud semantic segmentation by \cite{yang2022mil}. Contrastive scene contexts proposed a slightly different approach for training semantic segmentation networks in a weakly supervised manner by introducing an unsupervised contrastive pretraining phase \citep{hou2021exploring}.

In contrast to methods that only utilize a limited amount of labeled data for training, pseudo-label-based methods assign artificial labels for unlabeled data points. SSPC-Net \citep{chen2021sspcnet} and HybridCR \citep{li2022hybridcr} both presented weakly supervised point cloud semantic segmentation frameworks based on pseudo-labels. The former utilized a combination of superpoints and dynamic label propagation, while the latter imposed a contrastive loss on pseudo-labels generated from backbone predictions. LESS \citep{liu2022less} presented a novel strategy for generating sparsely annotated data, where the labels are divided into three separate categories during training sparse, weak, and propagated, each of which has a separate contrastive loss function.

\subsubsection{Unsupervised methods}

Research on unsupervised deep learning approaches for semantic segmentation of point clouds remains fairly limited. The few existing architectures all utilize some form of deep clustering, where extracted feature vectors are clustered and subsequently used as pseudo-labels, which are iteratively updated during training.

GrowSP \citep{zhang2023growsp} first oversegments the input point clouds into superpoints and subsequently constructs superpoint level feature representations based on pointwise feature vectors from a sparse convolutional neural network (SCNN) feature extractor. The features are then clustered with $k$-means to obtain pseudo-labels for training the network. U3DS$^{3}$ \citep{liu2024u3ds} and PointDC \citep{chen2023pointdc} both utilize a very similar framework based on oversegmented point clouds and a 3D CNN backbone. To improve feature robustness, U3DS$^{3}$ used two separate pathways in the feature extractor combined with a two-part loss function. On the other hand, PointDC utilizes cross-modal distillation (CMD), where the input point clouds are first converted into multi-view images and passed as input to a pretrained unsupervised 2D feature extractor. The 2D features are subsequently projected back into 3D and used as supervision for training the feature extractor network.

Perhaps unsurprisingly, the performance of 3D unsupervised approaches is far from state-of-the-art supervised and weakly supervised methods in terms of segmentation accuracy. However, models such as GrowSP and U3DS$^{3}$ both show great potential and achieve results that are comparable to early supervised architectures such as PointNet \citep{zhang2023growsp,liu2024u3ds}.

\subsection{Multispectral laser scanning}

Multispectral LiDAR represents the next generation of laser scanning and has been shown to be beneficial in various applications related to vegetation and object classification \citep{kaasalainen2007toward, kaasalainen2019multispectral}. MS representations provide a large number of spectral features, which have the potential to yield improvements in automatic classification and segmentation of point clouds \citep{kaasalainen2007toward}. Forestry and ecology have been some of the most popular applications for utilizing multispectral data \citep{takhtkesha2024multispectral} and its feasibility has been demonstrated in a wide variety of tasks, including individual tree segmentation \citep[see e.g.][]{dai2018new,huo2020individual}, tree species classification \cite[see e.g][]{yu2017single,budei2018identifying,lindeberg2021classification}, stem volume estimation \citep{axelsson2023use}, leaf--wood separation \citep{li2013separating,howe2015capabilities,li2018utilization}, forest environment classification \citep{hopkinson2016multisensor}, and structure and physiology measurements in forest ecosystems \citep{woodhouse2011multispectral}. Notably, \cite{yu2017single}, \cite{kukkonen2019multispectral}, and \cite{hakula2023individual} all found that multispectral data improved the classification accuracy of individual tree species in boreal forests in comparison to monospectral data. Similarly, \cite{dai2018new} and \cite{huo2020individual} both established that multispectral data significantly improved detection accuracy in individual tree segmentation.

Outside of forestry applications, multispectral data has been used for a wide variety of remote sensing tasks, including change detection \citep{matikainen2017object,matikainen2019toward}, road mapping \citep{karila2017feasibility}, and land cover classification \citep{wang2014airborne,wichmann2015evaluating,bakula2016testing,teo2017analysis}, which appears to be the most popular application. Similarly to the case of tree species classification, several works have demonstrated that utilizing intensity information from multiple wavelengths improves the accuracy of land cover classifiers \citep{wang2014airborne,matikainen2017object,teo2017analysis}. More recent research efforts on land cover classification using multispectral data have focused on deep learning approaches \citep{yu2020hybrid,pan2020landcover,wang2021multi,li2022agfpnet,zhang2022introducing}, including weakly supervised methods \citep{chen2024feature,takhtkeshha2024automatic}. \cite{oinonen2024unsupervised} proposed GroupSP, a fully unsupervised DL framework based on GrowSP designed for semantic segmentation of multispectral point clouds depicting urban environments.

\subsection{Leaf--wood separation}

\subsubsection{Unsupervised algorithms}

Traditional leaf--wood separation algorithms can broadly be divided into two classes, radiometry-based methods and methods based on point cloud geometry \citep{wang2020lewos}. Such algorithms are unsupervised, since neither approach requires any prior knowledge about the classes of individual points, rather, the classification is based on heuristic assumptions about the geometric or radiometric properties of wood points, as well as the general structure of trees.

\cite{cote2009structural} and \cite{beland2014seeing} both extracted wood points from TLS scans based on two fixed thresholds determined through careful data analysis. On the other hand, \cite{wu20133d} extracted wood points from simulated full waveform LiDAR using a single intensity threshold, which was optimized by applying the density-based spatial clustering of applications with noise (DBSCAN) \citep{ester1996density} algorithm to leaf-off point clouds. Similarly, \cite{yang2013three} detected wood points from full waveform TLS scans with a single threshold based on the distribution of reflectance value and pulse width ratios. By merging point clouds from near-infrared and shortwave-infrared scanners, \cite{li2013separating} demonstrated the potential for improving radiometry-based classification of wood and foliage points through the use of multispectral data. Radiometry-based methods have fallen out of favor in more recent research due to a few notable limitations, such as external factors influencing the optical properties that thresholding relies on \citep{wang2020lewos} and differences in attributes of different scanners and tree species that limit the generalization of thresholds to other types of data \citep{tao2015geometric}.

Early geometry-based leaf--wood separation algorithms were generally designed for the purpose of 3D reconstruction of trees, rather than semantic segmentation. \cite{xu2007knowledge} separated wood points starting from predefined root points using Dijkstra's shortest path algorithm, while \cite{livny2010automatic} extracted initial branch structure graphs with multi-root Dijkstra’s algorithm. On the other hand, \cite{raumonen2013fast} proposed a local approach for constructing precision tree models from TLS scans where the wooden components are iteratively reconstructed from small connected surface patches. \cite{belton2013processing} clustered geometric descriptors of point clouds representing individual trees with a Gaussian mixture model (GMM) and subsequently manually classified the clusters into trunk, branches, and foliage.

\cite{tao2015geometric} presented one of the first geometry-based algorithms designed for leaf--wood separation from point clouds of individual trees. Their approach detects initial wood proposals using thresholds for fitted circles and lines, which is followed by Dijkstra's shortest path algorithm and range search. \cite{wang2018separating} proposed a leaf--wood separation method for entire forest scenes, where wood points are detected through dynamic segment merging of superpoints and linearity thresholding.

A significant number of geometric leaf--wood separation algorithms are based on modeling the point cloud as a graph. LeWoS \citep{wang2020lewos} estimates the wood probability of connected components in the point cloud graph and subsequently applies regularization to form the final prediction. \cite{wang2020unsupervised} later improved the method with additional geometric features and graph optimization after the initial wood probability estimation. On the other hand, GBS \citep{tian2022graph} performs leaf--wood separation on graph representations of point clouds depicting individual trees using a combination of shortest path analysis, multi-scale thresholding based on geometric descriptors, and region growing. The algorithm of \cite{vicari2019leaf} combines GMM clustering and graph-segmentation by utilizing four separate classification branches, which are then merged into a single class prediction for each point.

Outside of graph-based approaches, \cite{wan2021novel} classified wood and foliage using local point cloud curvature and connected components. \cite{shcherbcheva2023unsupervised} proposed a statistical approach, which first fits a GMM to a set of geometric point cloud descriptors and subsequently detects inflection points between the resulting centroids and utilizes them as flexible thresholds for discerning between leaf and wood points.

\subsubsection{Machine- and deep-learning-based approaches}

A wide variety of fully supervised machine- and deep-learning-based approaches have been proposed for leaf--wood separation. Supervised methods have two advantages over unsupervised algorithms: they tend to be more accurate \citep[see e.g.][]{morel2020segmentation,jiang2023lwsnet} and generally require considerably less hyperparameter optimization. However, the obvious drawback of utilizing supervised learning is the requirement for manually generated pointwise ground truth labels. To the best of our knowledge, neither weakly supervised nor unsupervised learning has been applied to leaf--wood separation in any previous work.

\cite{ma2016improved} introduced GAFPC for supervised leaf--wood separation, which combines GMMs with six consecutive filters designed to correct misclassified points and remove noise. \cite{yun2016novel} trained a support vector machine (SVM) to separate wood and foliage points in TLS scans of individual deciduous trees, achieving an overall accuracy of over 90\% for most species. To assess the feasibility of supervised machine learning for leaf--wood separation, \cite{wang2017feasibility} conducted a performance comparison between SVM, naive Bayes classifier, GMM, and random forest. Although a majority of the approaches reached an overall accuracy of at least 95\%, random forest proved the most accurate.

\cite{li2018utilization} used a random forest classifier for separating leaf and wood points from dual-wavelength full waveform TLS point clouds, while \cite{zhu2018foliar} trained a random forest classifier for leaf--wood separation of RGB colorized TLS data with optimal geometric and radiometric features obtained using adaptive radius near-neighbor search. Similarly, \cite{zhou2019separating} combined random forest classifiers with a novel multi-scale strategy, where geometric features are computed for several neighborhood sizes. \cite{moorthy2020improved} compared the leaf--wood separation accuracy of random forest and two gradient boosting methods using similar multi-scale features, with random forest yielding the best performance.

Point cloud CNNs have been one of the most popular approaches for DL-based semantic segmentation of forest data. One of the earliest works to apply deep learning to the task of leaf--wood separation utilized a 3D fully convolutional neural network for semantic segmentation of TLS forest point clouds, processing the inputs as $128\times128\times128$ blocks of uniform voxels \citep{xi2018filtering}. \citet{windrim2019forest} proposed a pipeline for segmenting ALS forest data, where individual trees were first delineated from rasterized point clouds using Faster R-CNN \citep{ren2017faster} followed by semantic segmentation with a 3D CNN inspired by VoxNet \citep{maturana2015voxnet}. The performance of the pipeline was further improved in later work with the inclusion of LiDAR intensity as one of the input features for the semantic segmentation network \citep{windrim2020detection}. \cite{shen2022deep} introduced a slightly different approach, where TLS point clouds are first partitioned into geometrically consistent regions, after which under-represented geometric features are compensated with a novel feature balance module. Finally, the balanced data is used for training a PointCNN semantic segmentation network.

In addition to CNNs, both the standard PointNet++ architecture and modified variants have been applied for leaf--wood separation in multiple works. \cite{kim2023automated} and \cite{wielgosz2023point2tree} both utilized a standard PointNet++ model for semantic segmentation of forest TLS point clouds, while \citet{morel2020segmentation} combined geometric leaf--wood separation algorithms with a modified PointNet++ and trained it with simulated TLS point clouds of individual trees. On the other hand, \cite{krisanski2021sensor} proposed a sensor-agnostic semantic segmentation model based on a modified PointNet++ backbone trained on a diverse data set consisting of point clouds captured with various types of laser scanners.

\cite{kaijaluoto2022semantic} presented a novel approach for semantic segmentation of MLS forest point clouds using raw (non-georeferenced) 2D laser scanner profiles as a series of 2D rasters, each of which contained the ranges, reflectances and echo deviations measured during a single scanner mirror rotation. Their U-Net-based 2D CNN achieved performance comparable with RandLA-Net at a speed sufficient for real-time applications.

While a majority of research efforts have been focused on data preprocessing and feature engineering, more novel semantic segmentation architectures for leaf--wood separation have also been proposed. LWSNet \citep{jiang2023lwsnet} augmented a standard 3D U-Net with local contextual feature enhancement via a rearrangement attention mechanism and residual connection optimization, while MDC-Net \citep{dai2023mdcnet} introduced a novel multi-directional collaborative convolutional module designed for extracting discriminative features for leaf--wood separation and combined it with a multi-scale 3D CNN.

More recently, \cite{xiang2024automated} proposed ForAINet for panoptic segmentation of forest point clouds. The architecture utilizes a 3D SCNN U-Net for feature extraction followed by three separate branches for semantic prediction, center offset prediction, and feature embedding.