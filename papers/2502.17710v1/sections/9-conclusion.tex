\section{Conclusion}
We introduce \offHandsDataset, a novel dataset of 288 gesture-country pairs spanning 25 gestures and 85 countries, enabling systematic evaluation of AI systems' cultural awareness. Our assessment of T2I systems, LLMs, and VLMs reveals critical gaps: over-flagging of offensive content, poor utilization of scene descriptions, resorting to US-centric interpretation of universal concepts, and better awareness of US-offensive gestures than non-US ones. These findings highlight the need for cultural sensitivity in AI safety frameworks as these systems increasingly serve global audiences. 

\section{Limitations}
\label{sec:limitations}
Despite introducing the first dataset for evaluating non-verbal communication through gestures across different regions, there are certain limitations: 

\paragraph{Limited Gesture Coverage} 
\offHandsDataset includes 25 gestures but does not account for interpretations specific to sign languages, such as American Sign Language (ASL), nor does it comprehensively cover all gestures used globally. While this limits its scope for exhaustive cultural or non-verbal communication studies, the dataset provides a strong starting point for exploring cross-cultural interpretations of widely recognized gestures. Future work could address these gaps to improve applicability.

\paragraph{Focus on Offensive Gestures}
This study focuses exclusively on annotating cultural interpretations of offensive gestures. A broader analysis, such as examining the combinatorial meanings of all 25 gestures across 85 countries, is beyond the scope of this work.  By narrowing the focus to offensiveness, we create a resource tailored to the development of culturally sensitive AI systems, emphasizing safety in cross-cultural contexts.

\paragraph{Regional Groupings for Annotators}
Annotations are organized by UN geoscheme subregions, offering greater granularity than continental groupings but potentially obscuring important intra-country and cross-border cultural nuances. While cultural identity often transcends geographic boundaries, subregional groupings provide a practical starting point for many global applications, such as AI-driven marketing or policy-making, which are influenced by national or subregional considerations. Future work could explore finer-grained groupings to address these limitations.


\paragraph{Subjectivity of Offensiveness} 
Offensiveness is inherently subjective and shaped by individual worldviews, cultural exposure, and context. Although we collected five annotations per country-gesture pair, these perspectives might not capture the full diversity of interpretations. Given this subjectivity, we do not expect high annotator agreement \cite{ross2017measuring, schmidt2017survey} and use a threshold approach when determining offensiveness (\S\ref{sec:data:char}). Some individuals within a given country might not find a gesture offensive, but our focus is on inclusivity and safety. AI systems should prevent the generation of offensive or hateful content, especially when certain populations interpret it as harmful or exclusionary.


\paragraph{Temporal Limitations} Cultural interpretations of gestures evolve over time, influenced by historical, social, and technological factors. This dataset reflects a snapshot of current interpretations and may not account for emerging changes. Periodic updates will be necessary to maintain relevance in dynamic cultural landscapes. 


\paragraph{Limited Linguistic Scope}
All annotations were collected in English, which may limit the datasetâ€™s ability to capture cultural nuances tied to annotators' native languages. Cultural interpretations often rely on idiomatic or symbolic expressions that may not translate directly into English \cite{kabra2023multi}. Expanding to a multilingual annotation framework could enhance the richness and accuracy of future datasets. 


\section{Ethical Considerations}
This work advocates for culturally inclusive and context-aware safety in AI systems, considering these ethical factors: 
\paragraph{Risks in Annotation} Recent work has shown that exposure of potentially offensive content can be
harmful to the annotators \cite{roberts2016commercial}. To mitigate these risks, we restricted each annotator to only 5-7 annotations, offered fair compensation at \$15/hour, and obtained informed consent before participation. Only essential demographic information was collected, and our annotation study is also supervised by an Institutional Review Board (IRB). 

\paragraph{Harm Prevention and Intended Use} While documenting offensive content carries inherent risks, such as the potential for misuse or the misrepresentation of cultural practices, we are committed to minimizing these risks. We believe the benefits of improving AI systems' cultural awareness and safety outweigh the potential harms \cite{larimore2021reconsidering, ipsos2016attitudes}. The research is intended to contribute to the development of AI systems that are less likely to inadvertently cause cultural offense or misinterpretations. We explicitly do not endorse the use of the data for harmful purposes, including generating offensive content, exploiting cultural differences for malicious intents, or developing biased and discriminatory AI technologies. 

\section*{Acknowledgements}
We would like to thank Vijay Viswanathan, Shaily Bhatt, Adithya Pratapa, Simran Khanuja, Jocelyn Shen, Fernando Diaz, Yuning Mao, 
Sunipa Dev, Nouha Dziri, and members of Saplings lab for their insightful feedback on this work. This research was supported in part by the National Science Foundation under grant 2230466 and in part by DSO National Laboratories. 