\begin{figure}[t]
    \centering
    % [scale=0.35, trim={0 2em 0 2em}]
    \includegraphics[scale=0.26, trim={3em 0em 0em 2em}]{figures/t2i_per_prompt_side_by_side_span.pdf}
      \caption{\textbf{RQ1: T2I}  Imagen-3 detects offensive gestures better, while DALLE-3 prioritizes avoiding false rejections (high specificity) at the cost of safety. Scene descriptions weakens safety filters.}
      \label{fig:t2i_rq1_rq2}
\vspace{-1em}
\end{figure}
\section{Results and Analysis}
\label{sec:results}
For each research question, we evaluate T2I systems, LLMs and VLMs.
\renewcommand{\thesubsection}{} 

\subsection*{RQ1: Do models accurately detect culturally offensive gestures across different regions?}
\label{sec:results:rq1}

\renewcommand{\thesubsection}{\thesection.\arabic{subsection}} % Restore numbering for future subsections
% \textbf{Takeaway:} (a)  T2I models struggle to reject offensive gestures. LLMs tend to over-flag gestures as offensive. VLMs show mixed results, with some performing near chance and others over-flagging. (b) Adding scene context doesn’t affect LLMs but worsens T2I and VLM performance.
% !htbp
\vspace{-.5em}
\begin{figure}[h]
\begin{tcolorbox}[
  colback=gray!5,
  colframe=gray!75!black,
  title={\textbf{RQ1: Takeaway}},
  fonttitle=\bfseries,
  coltitle=white,
  colbacktitle=gray!75!black,
]
\small
\begin{verbatim}
(a)  T2I models struggle to reject offensive 
gestures. LLMs tend to over-flag gestures 
as offensive. VLMs show mixed results, with
some performing near chance and others 
over-flagging. 
(b) Adding scene context doesn’t affect 
LLMs but worsens T2I and VLM performance.
\end{verbatim}
\normalsize
\end{tcolorbox}
\vspace{-1.5em}
\end{figure}

\begin{figure*}[t]
    \centering
    % [scale=0.35, trim={0 2em 0 2em}]
    \includegraphics[scale=0.25, trim={4em 2em 2em 2em}]{figures/VLm_explicit_span.pdf}
      \caption{\textbf{RQ1: VLM} Offensiveness classification varies, with some models performing at random chance and others over-flagging gestures, shown by high recall and low specificity.} 
      \label{fig:vlm_rq1_country}
   \vspace{-.5em}
\end{figure*}



\paragraph{T2I}
Current T2I systems often fail to reject offensive gestures, even when explicitly specified in prompts (see Figure \ref{fig:t2i_rq1_rq2}). For Country prompts, Imagen 3 rejects 47.7\% of offensive gestures, while DALLE-3 rejects only 10.7\%. Using Country+Scene descriptions weakens the safety filters, reducing DALLE-3's detection to 4.5\%, likely because the added scene context distracts the model from prioritizing cultural sensitivity. Both models maintain high specificity in avoiding false rejections (Imagen 3: ~70\%, DALLE-3: 93-99\%), suggesting DALLE-3 prioritizes user experience, while Imagen 3 uses stricter, error-prone filtering. 






\paragraph{LLMs}
LLMs exhibit significant challenges in detecting the offensiveness of gestures across regions (see Figure \ref{fig:llm_rq1_country}). They often over-flag gestures as offensive, resulting in high recall (63--99\%) but poor specificity (1--61\%). This highlights a fundamental limitation in their cultural awareness of gestures, leading to overly cautious and frequent incorrect classifications. Llama-3.1-8B achieves the best balance in recall and specificity, followed by GPT-4. In contrast, Gemma-2b shows extreme bias, with 99\% recall but only 1\% specificity. Including scene descriptions causes minimal variation (see Fig. \ref{fig:llm_rq1_scene} in App. \ref{app:llm_eval} for Country+Scene results). 








\paragraph{VLMs}
VLMs show varied performance (see Figure \ref{fig:vlm_rq1_country}). Some models, like Instruct-BLIP, perform at random chance (48\%), while others, such as Chameleon, MLLama-11b, and gpt-4o, tend to over-flag gestures as offensive. They exhibit high recall (70--87\%) but low specificity (30--42\%). 
Adding scene descriptions (Figure \ref{fig:vlm_rq1_scene} in Appendix \ref{app:vlm_eval}) exacerbates this over-flagging tendency, increasing recall substantially (to 80--94\%) while their specificity drops further (15--33\%). 
This suggests that VLMs struggle to make balanced cultural judgments about gestures involving scene context.   



Refer to Appendix \ref{app:t2i_eval}, \ref{app:llm_eval}, \ref{app:vlm_eval} for region-wise and gesture-wise break-downs, and control experiment for T2I models with just gesture (no country).


