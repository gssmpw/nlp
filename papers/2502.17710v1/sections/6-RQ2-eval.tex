\subsection*{RQ2: Are models culturally competent when gestures are described by how they're used in US contexts?} 
\label{sec:results:rq2}
\renewcommand{\thesubsection}{\thesection.\arabic{subsection}} % Restore numbering for future subsections
% \textbf{Takeaway:} All models -- T2I, LLMs, and VLMs -- often fail to detect culturally offensive gestures when described using implicit meaning based on their US interpretations.
\vspace{-.5em}
\begin{figure}[h]
\begin{tcolorbox}[
  colback=gray!5,
  colframe=gray!75!black,
  title={\textbf{RQ2: Takeaway}},
  fonttitle=\bfseries,
  coltitle=white,
  colbacktitle=gray!75!black,
]
\small
\begin{verbatim}
All models–T2I, LLMs, and VLMs–often 
default to US-centric interpretations of
universal concepts (e.g., "good luck" → 
fingers crossed), overlooking the cultural
variation in gestures used to express them.
\end{verbatim}
\normalsize
\end{tcolorbox}
\vspace{-2em}
\end{figure}

\paragraph{T2I} When prompted with neutral descriptions based on US meanings (e.g., ``gesture showing good luck'' instead of ``crossed fingers''), DALLE-3 and Imagen 3 often generate images of gestures that are offensive in other cultures, yielding error rates of \textbf{84.1\%} and \textbf{60.5\%}, respectively. This indicates that T2I models primarily rely on US-based meanings and fail to adjust to cultural differences.

\paragraph{LLMs} LLMs frequently misinterpret gestures by suggesting ones offensive in target cultures when prompted with US-based descriptions (e.g., ``a playful gesture used with children''). Error rates range from 19.0\% (Gemma-2B) to 69.0\% (Llama3.1-8B), with Llama models performing worst (see Table \ref{tab:llm_implicit}). This highlights their bias toward US interpretations and lack of cultural awareness, even without explicit gesture names.

\begin{table}[h]
\centering
\small
\begin{tabular}{lr|lr}
\toprule
\textbf{Model} & \textbf{Error } & \textbf{Model} & \textbf{Error } \\
 & \textbf{Rate (\%)} & & \textbf{Rate (\%)} \\
\midrule
Qwen2.5-7B & 32.8 & gemma-7b & 22.4 \\
Qwen2.5-14B & 41.4 & Llama3.1-8B & \textcolor{red}{\textbf{69.0}} \\
Qwen2.5-72B & 20.7 & Llama3.1-70B & \textcolor{red}{\textbf{46.6}} \\
gemma-2b & 19.0 & gpt-4 & 36.2 \\
\bottomrule
\end{tabular}
\caption{Comparison of error rates in LLMs when recommending gestures based on their US interpretations.}

\label{tab:llm_implicit}
\vspace{-1em}
\end{table}

\paragraph{VLMs}  Most VLMs, including Instruct-BLIP, MLlama-11b, and gpt-4o, frequently suggest offensive gestures, with high error rates of 82.8--90.5\%. While Phi3-V and Paligemma perform somewhat better, they still produce errors 12.9\% and 15.5\% of the time. This reflects VLMs' reliance on US-based interpretations and poor cultural recognition.

\begin{table}[h]
\centering
\small

\begin{tabular}{lr|lr}
\toprule
\textbf{Model} & \textbf{Error} & \textbf{Model} & \textbf{Error} \\
 & \textbf{Rate (\%)} & & \textbf{Rate (\%)} \\
\midrule
instruct-blip & \textcolor{red}{\textbf{90.5}} & paligemma & 15.5 \\
llava-1.5 & \textcolor{red}{\textbf{83.6}} & chameleon & 47.4 \\
LLava-Next & \textcolor{red}{\textbf{82.8}} & MLlama-11b & \textcolor{red}{\textbf{90.5}}  \\
Phi3\_V & 12.9 & gpt-4o & \textcolor{red}{\textbf{82.8}} \\
\bottomrule
\end{tabular}
\label{tab:vllm_implicit}
\caption{Comparison of error rates in VLMs when recommending gestures based on their US interpretations.}
\vspace{-1em}
\end{table}


