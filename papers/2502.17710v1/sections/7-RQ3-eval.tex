\subsection*{RQ3: Do models exhibit US-centric biases when classifying the offensiveness of gestures across different cultural contexts?}
\label{sec:results:rq3}
\renewcommand{\thesubsection}{\thesection.\arabic{subsection}} % Restore numbering for future subsections
% \textbf{Takeaway:} All models--T2I, LLMs, and VLMs--exhibit US-centric biases, with higher accuracy in identifying offensive gestures in US contexts than in non-US ones.
\vspace{-.5em}
\begin{figure}[h]
\begin{tcolorbox}[
  colback=gray!5,
  colframe=gray!75!black,
  title={\textbf{RQ3: Takeaway}},
  fonttitle=\bfseries,
  coltitle=white,
  colbacktitle=gray!75!black,
]
\small
\begin{verbatim}
All models–T2I, LLMs, and VLMs–exhibit 
US-centric biases, with higher accuracy 
in identifying offensive gestures in 
US contexts than in non-US ones.
\end{verbatim}
\normalsize
\end{tcolorbox}
\vspace{-2em}
\end{figure}

\paragraph{Setup} For each gesture marked offensive in the US, we identify two non-US counterparts: one country where the gesture is also offensive, and another where it is acceptable. Similarly, for gestures not offensive in the US, we find non-US country counterparts where they are considered offensive. The non-US country for each gesture is informed by \offHandsDataset annotation scores, choosing countries where the gesture is either maximally offensive or maximally acceptable depending on the comparison. Ideally, models should have high accuracy in identifying offensive \text{and} non offensive gestures across \textit{both} US and non-US contexts. Results presented below are for the Country prompt. See Appendix \ref{app:rq3_countries} for non-US country details.


\begin{figure}[t]
    \centering
    \includegraphics[scale=0.25, trim={4em 0em 2em 2em}]{figures/t2i_us_non_us_accuracy.pdf}
      \caption{Accuracy comparison of DALLE-3 and Imagen 3 in identifying offensive gestures across US and non-US contexts. DALLE-3 struggles in non-US contexts while performing moderately in US contexts. Imagen 3 shows high accuracy overall but shows a performance drop in non-US-offensive gestures.} 
      \label{fig:t2i_rq3}

\end{figure}


\paragraph{T2I} Figure \ref{fig:t2i_rq3} reveals a US-centric bias in DALLE-3's recognition of offensive gestures, with low accuracy (8--16\%) for gestures offensive in non-US contexts and moderate accuracy (27--41\%) for those offensive in US contexts. It performs well with non-offensive gestures in both contexts. In contrast, Imagen 3 has 100\% accuracy for gestures offensive in both contexts but has lower accuracy with culture-specific offensive gestures—66--67\% for US-only and 25--33\% for non-US only. This highlights the models' limited ability to generalize across different cultural contexts.


\begin{figure}[t]
    \centering
    % [scale=0.35, trim={0 2em 0 2em}]
    \includegraphics[scale=0.23, trim={4em 0em 2em 4em}]{figures/llm_us_non_us_accuracy.pdf}

      \caption{Comparison of gesture offensiveness detection accuracy across US and non-US contexts. Llama-3.1-70B over-flags gestures as offensive, performing best when gestures are offensive in both contexts but struggling with detection of non-offensive gestures. GPT-4 shows more balanced performance but has a larger accuracy drop in non-US contexts.}
      \label{fig:llm_rq3}
      \vspace{-1em}
\end{figure}

\paragraph{LLM} We present the performance of two state-of-the-art LLMs (Figure \ref{fig:llm_rq3}) , Llama-3.1-70b and GPT-4.  Llama-3.1-70B shows strong performance in identifying offensive gestures in both US and non-US contexts (79--87\%), however it struggles in identifying gestures when not-offensive in both contexts. This is likely due to its tendency to over-flag gestures as offensive (as seen Figure \ref{fig:llm_rq1_country}).
GPT-4, on the other hand, has consistent performance in accurately identifying offensive and non-offensive gestures in US contexts, but relatively lower accuracy for non-US contexts. Hence, both models exhibit some US-centric biases. 


\begin{figure}[t]
    \centering
    % [scale=0.35, trim={0 2em 0 2em}]
    \includegraphics[scale=0.23, trim={4em 0em 2em 4em}]{figures/VLm_us_non_us_accuracy.pdf}
      \caption{Accuracy comparison of MLlama-11b and GPT-4o in identifying gesture offensiveness across US and non-US contexts. Both models achieve high accuracy when gestures are offensive in both contexts, but struggle when gestures are context-dependent—particularly when gestures are offensive in non-US contexts but not in the US.}
      \label{fig:vlm_rq3}
\vspace{-1em}
\end{figure}

\paragraph{VLMs} We present the performance of two state-of-the-art VLMs, MLlama-11b and gpt-4o, in Figure \ref{fig:vlm_rq3}. While both models achieve high accuracy (75–100\%) for gestures considered offensive in both contexts, they face challenges with culturally-dependent cases.  For gestures that are inoffensive in the US but offensive elsewhere, MLlama-11b shows moderate accuracy (43–48\%), whereas gpt-4o has widely varying results (30\% accuracy for US and 86.7\% for non-US contexts). This discrepancy may stem from the models' general tendency to over-flag gestures as offensive (as also seen in Figure \ref{fig:vlm_rq1_country}). 


