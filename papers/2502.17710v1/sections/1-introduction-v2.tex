\section{Introduction}
\begin{figure}[!t]
    \centering
    \includegraphics[trim=0em 11em 4em 2em, clip, scale=0.85]{figures/intro_fig.pdf}
    \caption{Interpretations of gestures varies dramatically across regions and cultures. ``Crossing your fingers'', while commonly used in the US to wish for good luck, can be considered deeply offensive to female audiences in parts of Vietnam. AI systems, such as T2I models, should be culturally competent and avoid generating visual elements that risk miscommunication or offense in specific cultural contexts.}  
    \label{fig:intro-fig}
    \vspace{-.5em}
\end{figure}


Gestures, along with body postures and facial expressions, are integral to non-verbal communication and play a critical role in conveying beliefs, emotions, and intentions \cite{efron1941gesture, knapp1978nonverbal, kendon1997gesture, burgoon2011nonverbal}. While non-verbal communication is universal, its interpretations significantly vary across cultures, often leading to misunderstandings \cite{kirch1979non, Matsumoto2012CulturalSA, matsumoto2016cultural}.\footnote{Misaligned gestures have caused significant misunderstandings. e.g., Richard Nixon's use of double ``OK'' sign in South America and George H.W. Bush's inward-facing ``V-sign'' in Australia were perceived as offensive gestures by local audiences \cite{nyt_nixon_1974, nyt_gestures_1996, chicago_gestures_1992}.}  For example, the gesture of ``crossing your fingers,'' viewed as symbol of good luck in the US, can be offensive in Vietnam, particularly to women (Figure \ref{fig:intro-fig}). 

With AI systems increasingly deployed \textit{globally} across various domains, understanding cultural nuances in gesture usage becomes crucial. Companies such as AdCreative.ai and QuickAds integrate AI into advertising to tailor promotional materials for different cultural contexts, while travel platforms like TripAdvisor\footnote{\url{https://www.tripadvisor.com/TripBuilder}, \url{https://usefulai.com/tools/ai-travel-assistants}} provide (often unverified) culturally specific recommendations, including local etiquette and customs. However, as these systems engage with diverse audiences, the risk of generating culturally offensive content poses challenges -- not only in terms of harm and exclusion but also in reputational damage and business liability \cite{wenzel2024designing, ryan2024unintended}.\footnote{Digital media companies like Disney have recognized the cultural impact of nonverbal communication by digitally removing offensive hand gestures from productions to prevent cultural insensitivity \cite{chicago_tribune}.}  





Despite these real-world risks, current AI safety efforts primarily target explicit threats such as violence and sexual content \cite{han2024wildguard, Deng2023HarnessingLT, Riccio2024ExploringTB}, with relatively less attention on cultural sensitivities. Large language models (LLMs) and vision-language models (VLMs) are increasingly studied for their knowledge of cultural norms and artifacts like food and clothing \cite{Yin2021BroadenTV, romero2024cvqa, rao2024normad}, while text-to-image (T2I) models have prioritized geographical diversity, realism, and faithfulness \cite{hall2023dig, hall2024towards, kannen2024beyond}. However, the extent to which these models handle cultural nuances in nonverbal communication largely remains unexplored. 






To bridge this critical gap, we study culturally contextualized safety guardrails of AI systems through the lens of \textit{emblematic or conventional gestures} -- gestures that convey a single distinct message, typically independent of speech, but whose meaning can vary across communities.\footnote{We use the terms gestures, emblems, emblematic gestures and conventional gestures interchangeably.}
We introduce \offHandsDataset,\footnote{Multi-Cultural Set of Inappropriate Gestures and Nonverbal Signs} a novel dataset capturing \textit{cultural interpretations of 288 gesture-country pairs spanning 25 common gestures and 85 countries} (\S\ref{sec:data}).  Annotators from respective regions provide insights on: (1) the gesture's regional level of offensiveness (from not offensive to hateful), (2) its cultural significance, and (3) situational factors such as social setting and audience that influence its interpretation within that region. This dataset serves as a test bed for evaluating and improving cultural safety of AI systems in real-world applications. 
% This dataset serves dual purposes: as a test bed for evaluating cultural grounding in AI systems, and as a practical resource for developing culturally aware applications in domains like global marketing, education, and cross-cultural communication. {didn't understand the difference between test set and practical resource? Isn't it a practical resource because its a test set? We can't use it in any other setting, for example, training right? --> make clear}


Using our \offHandsDataset dataset, we aim to answer the following research questions:
\begin{enumerate}[label=\textbf{RQ\arabic*:}, itemsep=0pt, topsep=1pt, leftmargin=3em]
  \item Can models (LLMs, VLMs) accurately detect and (for T2I systems) reject culturally offensive gestures? 

  \item Are models culturally competent when interpreting universal concepts described by their \textit{implicit} meanings in the US? (e.g., do they default to US-centric ``crossed fingers'' gesture when asked to ``show a gesture meaning good luck''?) 
  
  \item Do models exhibit US-centric biases in their detection of offensive gestures across US and non-US cultural contexts? 

  
\end{enumerate}


Our findings reveal significant limitations in AI systems' handling of culturally offensive gestures. 
For offensive gesture detection (\textbf{RQ1}; \S\ref{sec:results:rq1}), we find that T2I models largely fail to reject offensive content (e.g., DALLE-3 rejects only 10.7\%), while LLMs and VLMs tend to over-flag gestures as offensive (e.g., gpt-4o with 87\% recall, 42\% specificity).  When interpreting the implicit meanings of gestures (\textbf{RQ2}; \S\ref{sec:results:rq2}), all models frequently default to US-based interpretations, often suggesting inappropriate gestures (e.g., DALLE-3 misinterprets 84.1\% of cases, gpt-4o 82.8\%). For US-centric biases (\textbf{RQ3}; \S\ref{sec:results:rq3}), we find that all models exhibit a US-centric bias, showing higher accuracy in identifying offensive gestures within US contexts than in non-US contexts (e.g., Llama-3.2-11b-Vision: 65\% accuracy in US vs. 48.3\% in non-US contexts).



These findings, enabled by our broad-coverage and comprehensive \offHandsDataset, highlight the urgent need for more inclusive and context-aware AI systems to prevent harm and ensure equitable applicability. We release our dataset and code to foster research on cross-cultural safety and inclusivity.\footnote{\href{https://github.com/Akhila-Yerukola/culturally-offensive-gestures}{https://github.com/Akhila-Yerukola/culturally-offensive-gestures}}
% 



