\section{Related Work}
\label{sec:related-work}

\subsubsection{\textbf{Edge Video Analytics}} can be categorized into:
%\subsubsection{Centralized Architecture:}
\hfill

\textit{Centralized Architecture: } dictates that video data is collected from multiple sources and processed at a central location.
To reduce overhead, approaches like VideoStorm \cite{zhang2017videostorm, Jiang2018chameleon, Tan2020FastVA, Zhang2018awstream, Li2020reducto} exploit the resource-quality tradeoff by adjusting parameters such as encoding quality, frame rate, and resolution.
Another strategy \cite{Kang2017noscope,Zhang2015vigil} uses models of varying accuracy, reserving high-precision models for complex tasks while employing cheaper ones for simpler tasks.
Jellyfish \cite{nigade2022jellyfish} combines both methods and provides a dynamic programming algorithm to handle network variability.

%\subsubsection{Distributed Architecture:}
\textit{Distributed Architecture: } supports both device-server and device-device workload distributions.
While better suited to dynamic environments, it creates a larger search space, including the challenge of finding optimal \textit{split points} for workload partitioning.
DRLTO \cite{wang2022DRLTO} uses a fixed split and device-based analysis to optimize offloaded frames.
Rim \cite{hu2021rim} maximizes workload at one device to increase resource utilization while approaches like Distream \cite{Hung2018VideoEdge, liang2024splitstream, zeng2020distream} use stochastic methods to explore the search space.
EdgeVision \cite{gao2024edgevision} applies reinforcement learning to learn optimal configurations.

A common drawback of these systems is not fully utilizing an effective tool, \textit{dynamic batching}, to flexibly handle dynamic environments, as it expands the complex search space. Additionally, they fail to address the challenges posed by GPU execution of models, such as \textit{co-location interference}.

\subsubsection{\textbf{Inference Serving beyond the Edge}} serves a inference requests of various tasks at the Cloud \cite{shen2019nexus, Tan2021migserving, Choi2022Gpulet, Gujarati2020Clockwork, Zhang2023SHEPHERD, crankshaw2020inferline}.
These systems consider large GPU clusters where one can take several GPUs or a whole cluster to serve a high concentration of requests.
Although they do not address challenges at the Edge, such as resource constraints and dynamic environments (e.g. network), techniques such as \textit{dynamic batching} and GPU scheduling have inspired \systemname{}.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Conclusion %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%