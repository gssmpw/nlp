@inproceedings{Choi2022Gpulet,
author = {Seungbeom Choi and Sunho Lee and Yeonjae Kim and Jongse Park and Youngjin Kwon and Jaehyuk Huh},
title = {Serving Heterogeneous Machine Learning Models on {Multi-GPU} Servers with {Spatio-Temporal} Sharing},
booktitle = {2022 USENIX ATC},
year = {2022},
isbn = {978-1-939133-29-53},
pages = {199--216}
}

@inproceedings{Gujarati2020Clockwork,
author = {Arpan Gujarati and Reza Karimi and Safya Alzayat and Wei Hao and Antoine Kaufmann and Ymir Vigfusson and Jonathan Mace},
title = {Serving {DNNs} like Clockwork: Performance Predictability from the Bottom Up},
booktitle = {14th USENIX Symp. on Operating Systems Design and Implementation (OSDI 20)},
year = {2020},
isbn = {978-1-939133-19-9},
pages = {443--462}
}

@INPROCEEDINGS{Hung2018VideoEdge,
  author={Hung, Chien-Chun and Ananthanarayanan, Ganesh and Bodik, Peter and Golubchik, Leana and Yu, Minlan and Bahl, Paramvir and Philipose, Matthai},
  booktitle={2018 IEEE/ACM Symp. on Edge Computing (SEC)}, 
  title={VideoEdge: Processing Camera Streams using Hierarchical Clusters}, 
  year={2018},
  volume={},
  number={},
  pages={115-131},
  keywords={Cameras;Merging;Cloud computing;Streaming media;Organizations;Detectors;Bandwidth;video analytics;scheduling;distributed clusters},
}

@inproceedings{Jiang2018chameleon,
author = {Jiang, Junchen and Ananthanarayanan, Ganesh and Bodik, Peter and Sen, Siddhartha and Stoica, Ion},
booktitle = {Proc. of the 2018 Conf. of the ACM Special Interest Group on Data Communication},
doi = {10.1145/3230543.3230574},
isbn = {9781450355674},
mendeley-groups = {SoulSaver},
pages = {253--266},
publisher = {ACM},
title = {{Chameleon: scalable adaptation of video analytics}},
year = {2018}
}

@article{Kang2017noscope,
abstract = {Recent advances in computer vision---in the form of deep neural networks---have made it possible to query increasing volumes of video data with high accuracy. However, neural network inference is computationally expensive at scale: applying a state-of-the-art object detector in real time (i.e., 30+ frames per second) to a single video requires a $4000 GPU. In response, we present N o S cope , a system for querying videos that can reduce the cost of neural network video analysis by up to three orders of magnitude via inference-optimized model search. Given a target video, object to detect, and reference neural network, N o S cope automatically searches for and trains a sequence, or cascade, of models that preserves the accuracy of the reference network but is specialized to the target video and are therefore far less computationally expensive. N o S cope cascades two types of models: specialized models that forego the full generality of the reference model but faithfully mimic its behavior for the target video and object; and difference detectors that highlight temporal differences across frames. We show that the optimal cascade architecture differs across videos and objects, so N o S cope uses an efficient cost-based optimizer to search across models and cascades. With this approach, N o S cope achieves two to three order of magnitude speed-ups (265-15,500x real-time) on binary classification tasks over fixed-angle webcam and surveillance video while maintaining accuracy within 1--5% of state-of-the-art neural networks.},
author = {Kang, Daniel and Emmons, John and Abuzaid, Firas and Bailis, Peter and Zaharia, Matei},
doi = {10.14778/3137628.3137664},
issn = {2150-8097},
journal = {Proc. of the VLDB Endowment},
mendeley-groups = {SoulSaver},
number = {11},
pages = {1586--1597},
title = {{NoScope: optimizing neural network queries over video at scale}},
volume = {10},
year = {2017}
}

@inproceedings{Li2020reducto,
author = {Li, Yuanqi and Padmanabhan, Arthi and Zhao, Pengzhan and Wang, Yufei and Xu, Guoqing Harry and Netravali, Ravi},
booktitle = {Proc. of SIGCOMM},
doi = {10.1145/3387514.3405874},
isbn = {9781450379557},
mendeley-groups = {SoulSaver},
pages = {359--376},
publisher = {ACM},
title = {{Reducto: On-Camera Filtering for Resource-Efficient Real-Time Video Analytics}},
year = {2020}
}

@inproceedings{Tan2020FastVA,
  author = {T. Tan and G. Cao},
  title = {{FastVA: Deep Learning Video Analytics Through Edge Processing and NPU in Mobile}},
  booktitle = {IEEE Conf. on Computer Communications},
  year = {2020},
  pages = {1947--1956},
  keywords = {Computational modeling;Mobile handsets;Machine learning;Time factors;Mobile applications;Servers;Streaming media},
  publisher = {IEEE}
}

@article{Tan2021migserving,
abstract = {Multi-Instance GPU (MIG) is a new feature introduced by NVIDIA A100 GPUs that partitions one physical GPU into multiple GPU instances. With MIG, A100 can be the most cost-efficient GPU ever for serving Deep Neural Networks (DNNs). However, discovering the most efficient GPU partitions is challenging. The underlying problem is NP-hard; moreover, it is a new abstract problem, which we define as the Reconfigurable Machine Scheduling Problem (RMS). This paper studies serving DNNs with MIG, a new case of RMS. We further propose a solution, MIG-serving. MIG- serving is an algorithm pipeline that blends a variety of newly designed algorithms and customized classic algorithms, including a heuristic greedy algorithm, Genetic Algorithm (GA), and Monte Carlo Tree Search algorithm (MCTS). We implement MIG-serving on Kubernetes. Our experiments show that compared to using A100 as-is, MIG-serving can save up to 40% of GPUs while providing the same throughput.},
archivePrefix = {arXiv},
arxivId = {2109.11067},
author = {Tan, Cheng and Li, Zhichao and Zhang, Jian and Cao, Yu and Qi, Sikai and Liu, Zherui and Zhu, Yibo and Guo, Chuanxiong},
eprint = {2109.11067},
journal = {arXiv},
mendeley-groups = {SoulSaver},
title = {{Serving DNN Models with Multi-Instance GPUs: A Case of the Reconfigurable Machine Scheduling Problem}},
year = {2021}
}

@inproceedings{Zhang2015vigil,
author = {Zhang, Tan and Chowdhery, Aakanksha and Bahl, Paramvir (Victor) and Jamieson, Kyle and Banerjee, Suman},
booktitle = {Proc. of the 21st Annual Int. Conf. on Mobile Computing and Networking},
doi = {10.1145/2789168.2790123},
isbn = {9781450336192},
mendeley-groups = {SoulSaver},
pages = {426--438},
publisher = {ACM},
title = {{The Design and Implementation of a Wireless Video Surveillance System}},
year = {2015}
}

@inproceedings{Zhang2018awstream,
author = {Zhang, Ben and Jin, Xin and Ratnasamy, Sylvia and Wawrzynek, John and Lee, Edward A.},
booktitle = {Proc. of the 2018 Conf. of the ACM Special Interest Group on Data Communication},
doi = {10.1145/3230543.3230554},
isbn = {9781450355674},
mendeley-groups = {SoulSaver},
pages = {236--252},
publisher = {ACM},
title = {{AWStream: adaptive wide-area streaming analytics}},
year = {2018}
}

@inproceedings{Zhang2023SHEPHERD,
author = {Hong Zhang and Yupeng Tang and Anurag Khandelwal and Ion Stoica},
title = {{SHEPHERD}: Serving {DNNs} in the Wild},
booktitle = {20th USENIX Symp. on Networked Systems Design and Implementation},
year = {2023},
isbn = {978-1-939133-33-5},
pages = {787--808},
}

@inproceedings{crankshaw2020inferline,
  title={InferLine: latency-aware provisioning and scaling for prediction serving pipelines},
  author={Crankshaw, Daniel and Sela, Gur-Eyal and Mo, Xiangxi and Zumar, Corey and Stoica, Ion and Gonzalez, Joseph and Tumanov, Alexey},
  booktitle={Proc. of the 11th ACM Symp. on Cloud Computing},
  pages={477--491},
  year={2020}
}

@article{gao2024edgevision,
  title={EdgeVision: Towards Collaborative Video Analytics on Distributed Edges for Performance Maximization},
  author={Gao, Guanyu and Dong, Yuqi and Wang, Ran and others},
  journal={IEEE Transactions on Multimedia},
  year={2024}
}

@inproceedings{hu2021rim,
  title={Rim: Offloading inference to the edge},
  author={Hu, Yitao and Pang, Weiwu and Liu, Xiaochen and Ghosh, Rajrup and Ko, Bongjun and Lee, Wei-Han and Govindan, Ramesh},
  booktitle={Proc. of the Int. Conf. on Internet-of-Things Design and Implementation},
  pages={80--92},
  year={2021}
}

@article{liang2024splitstream,
  title={SplitStream: Distributed and workload-adaptive video analytics at the edge},
  author={Liang, Yu and Zhang, Sheng and Wu, Jie},
  journal={Journal of Network and Computer Applications},
  volume={225},
  pages={103866},
  year={2024},
  publisher={Elsevier}
}

@inproceedings{nigade2022jellyfish,
  title={Jellyfish: Timely inference serving for dynamic edge networks},
  author={Nigade, Vinod and Bauszat, Pablo and Bal, Henri and Wang, Lin},
  booktitle={2022 IEEE Real-Time Systems Symp. (RTSS)},
  pages={277--290},
  year={2022},
  organization={IEEE}
}

@inproceedings{shen2019nexus,
  title={Nexus: A GPU cluster engine for accelerating DNN-based video analysis},
  author={Shen, Haichen and Chen, Lequn and Jin, Yuchen and Zhao, Liangyu and Kong, Bingyu and Philipose, Matthai and Krishnamurthy, Arvind and Sundaram, Ravi},
  booktitle={Proc. of the 27th ACM Symp. on Operating Systems Principles},
  pages={322--337},
  year={2019}
}

@ARTICLE{wang2022DRLTO,
  author={Wang, Jin and Hu, Jia and Min, Geyong and Zhan, Wenhan and Zomaya, Albert Y. and Georgalas, Nektarios},
  journal={IEEE Transactions on Computers}, 
  title={Dependent Task Offloading for Edge Computing based on Deep Reinforcement Learning}, 
  year={2022},
  volume={71},
  number={10},
  pages={2449-2461},
  keywords={Task analysis;Neural networks;Wireless communication;Energy consumption;Training;Reinforcement learning;Solid modeling;Multi-access edge computing;task offloading;deep reinforcement learning;sequence to sequence neural networks}
}

@inproceedings{zeng2020distream,
  title={Distream: scaling live video analytics with workload-adaptive distributed edge intelligence},
  author={Zeng, Xiao and Fang, Biyi and Shen, Haichen and Zhang, Mi},
  booktitle={Proc. of the 18th SenSys Conf.},
  pages={409--421},
  year={2020}
}

@inproceedings{zhang2017videostorm,
author = {Haoyu Zhang and Ganesh Ananthanarayanan and Peter Bodik and Matthai Philipose and Paramvir Bahl and Michael J. Freedman},
title = {Live Video Analytics at Scale with Approximation and {Delay-Tolerance}},
booktitle = {14th USENIX Symp. on Networked Systems Design and Implementation},
year = {2017},
isbn = {978-1-931971-37-9},
pages = {377--392},
}

