\section{Experiment}
\subsection{Setup}

% % main experiment table
% \begin{table*}[h]

%     \vspace{-10pt}
%     \caption{Overall performance on product recommendation task.}
%     \vspace{-8pt}
%     \centering
%     \scalebox{1}{
%     \setlength{\tabcolsep}{1.5mm}
%     {\begin{tabular}{ccccccc|cccccc}
% \toprule
% \multirow{2.5}{*}{Method} 
%                        & \multicolumn{3}{c|}{@1}                                                 & \multicolumn{3}{c|}{@3}                            & \multicolumn{3}{c|}{@5}                                                                                          & \multicolumn{3}{c}{@10}                                                                                        \\ \cmidrule{2-13} 
%                        & MAP             & NDCG            & \multicolumn{1}{c|}{HR}        & MAP             & NDCG            & HR         & MAP                                 & NDCG                                & \multicolumn{1}{c|}{HR}         & MAP                                 & NDCG                               & HR                             \\ \midrule

% SASRec      & 0.0606 & 0.0606  & \multicolumn{1}{l|}{0.0606} & 0.0903 & 0.0876 & 0.1067 & 0.0903 & 0.0970 & \multicolumn{1}{l|}{0.1294} & 0.0903 & 0.1067 & 0.1589 \\
% Bert4Rec    & 0.0272 & 0.0272  & \multicolumn{1}{l|}{0.0272} & 0.0332 & 0.0351 & 0.0408 & 0.0339 & 0.0363 & \multicolumn{1}{l|}{0.0439} & 0.0348 & 0.0386 & 0.0507 \\ \midrule
% PURS                          & 0.0194                        & 0.0194          & \multicolumn{1}{l|}{0.0194}          & 0.0247          & 0.0267          & \multicolumn{1}{l|}{0.0323}          & 0.0273          & 0.0316          & \multicolumn{1}{l|}{0.0452}          & 0.0297          & 0.0377          & 0.0645          \\ 
% \midrule
% LLM4Seren        & 0.0683 & 0.0683  & \multicolumn{1}{l|}{0.0683} & 0.1162 & 0.1191 & 0.1893 & 0.1334 & 0.1485  & \multicolumn{1}{l|}{0.2820} & 0.1543 & 0.2047 & 0.4964 \\
% SerenPrompt & 0.0840 & 0.0840 & \multicolumn{1}{l|}{0.0840} & 0.1749 & 0.1904 & 0.3330 & 0.2186 & 0.2725 & \multicolumn{1}{l|}{\textbf{0.5722}} & 0.2454 & 0.3530 & \textbf{0.8705} \\ \midrule
% % SerenGPT-SFT         & 0.1771 & 0.1771  & \multicolumn{1}{l|}{0.1771} & 0.2198 & 0.2312 & 0.3315 & 0.2327 & 0.2529 & \multicolumn{1}{l|}{0.4148} & 0.2476 & 0.2866 & 0.5632 \\
% \textbf{SerenGPT}        & \textbf{0.2740} & \textbf{0.2740} & \multicolumn{1}{l|}{\textbf{0.2740}} & \textbf{0.3140} & \textbf{0.3231} & \textbf{0.4481} & \textbf{0.3262} & \textbf{0.3444} & \multicolumn{1}{l|}{0.5374} & \textbf{0.3365} & \textbf{0.3680} & 0.6487\\
%  \bottomrule
% \end{tabular}}
%     }


% \label{tab:overall}
% \vspace{0pt}
% \end{table*}

\begin{table*}[h]

    \vspace{-10pt}
    \caption{Offline performance on serendipity recommendation.  The best result is given in bold, while the second-best value is underlined. The symbol * indicates statistically significant improvement over the best baselines( t-test with $p < 0.05$).}
    \vspace{-8pt}
    \centering
    \scalebox{0.95}{
    \setlength{\tabcolsep}{1.5mm}
    {\begin{tabular}{ccccc|cccc|cccc}
\toprule
\multirow{2}{*}{Method} & \multicolumn{4}{c|}{MAP$_{seren}$} & \multicolumn{4}{c|}{NDCG$_{seren}$} & \multicolumn{4}{c}{HR$_{seren}$} \\
\cmidrule{2-13} 
 & @1 & @3 & @5 & @10 & @1 & @3 & @5 & @10 & @1 & @3 & @5 & @10 \\
 \midrule
SASRec & 0.0606 & 0.0810 & 0.0863 & 0.0903 & 0.0606 & 0.0876 & 0.0971 & 0.1067 & 0.0606 & 0.1067 & 0.1294 & 0.1590 \\
Bert4Rec & 0.0273 & 0.0332 & 0.0339 & 0.0348 & 0.0273 & 0.0352 & 0.0364 & 0.0386 & 0.0273 & 0.0409 & 0.0439 & 0.0507 \\
\midrule
PURS & 0.0194 & 0.0247 & 0.0273 & 0.0297 & 0.0194 & 0.0267 & 0.0316 & 0.0377 & 0.0194 & 0.0323 & 0.0452 & 0.0645 \\
SerenEnhance & \underline{0.1900} & \underline{0.1956} & 0.1965 & 0.1972 & \underline{0.1900} & \underline{0.1974} & 0.1993 & 0.2007 & \underline{0.1900} & 0.2029 & 0.2074 & 0.2120 \\
\midrule
LLM4Seren & 0.0683 & 0.1163 & 0.1335 & 0.1544 & 0.0683 & 0.1192 & 0.1485 & 0.2047 & 0.0683 & 0.1893 & 0.2820 & 0.4965 \\
SerenPrompt & 0.0840 & 0.1750 & \underline{0.2187} & \underline{0.2455} & 0.0840 & 0.1904 & \underline{0.2725} & \underline{0.3531} & 0.0840 & \underline{0.3331} & \textbf{0.5723} & \textbf{0.8706} \\
\midrule
\textbf{SerenGPT} & \textbf{0.2861*} & \textbf{0.3260*} & \textbf{0.3395*} & \textbf{0.3509*} & \textbf{0.2861*} & \textbf{0.3353*} & \textbf{0.3587*} & \textbf{0.3847*} & \textbf{0.2861*} & \textbf{0.4625*} & \underline{0.5556} & \underline{0.6760}\\
 \bottomrule
\end{tabular}}
}
\label{tab:overall}
\vspace{-10pt}
\end{table*}



% \subsubsection{Scenario} Our experiments are conducted on Taobao, a leading large-scale e-commerce platform, including serendipitous product recommendations in "Guess What You Like" of Taobao homepage, and serendipitous search query predictions in Main Search.
% \begin{itemize}
%     \item \textbf{Product Recommendation} aims to predict next serendipitous item based on a user's historical behaviors and profile. For offline experiments, we filter out 19, 141 serendipity samples, splitting them into training and testing sets at 9:1. Since most baselines require scoring candidate item, we follow~\cite{fu2024art} and randomly select 99 negative items for each positive item in the test set to form a candidate set.  As our model SerenGPT generates the next item's title, we employ a matching algorithm to calculate the similarity between the generated title and the candidate items' titles, producing a ranking based on the match scores. For online serving, w
%     \item \textbf{Search Query Prediction} aims to predict the next serendipitous search query based on the user's historical behavior and profile.  The definition of serendipity remains consistent with Definition 1. For offline experiments, we filter out 26, 672 serendipity samples.
% \end{itemize}

\subsubsection{Scenario} Our experiments are conducted on \textbf{Taobao}, a leading large-scale e-commerce platform with billions of users and items. Our scenario is the "\textbf{Guess What You Like}" column of the Taobao App homepage and we aim to predict the next serendipitous item based on a user's historical behaviors and profiles. For offline experiments, we filter out 19, 141 serendipity samples from this scenario according to Section~\ref{sec:data_gen}, splitting them into training and testing sets at 9:1. Since most serendipity baselines~\cite{fu2024art,tokutake2024can} require ranking a small set of candidate items, we follow~\cite{fu2024art} and randomly select 99 negative (non-serendipitous) items for each positive (serendipitous) item in test set to form a candidate item set. As our model SerenGPT is a generative model that generates the item's title, we employ a matching algorithm to calculate the similarity between the generated title and the candidate items' titles, producing a ranking based on the match scores. 
% The online serving is carried out according to the process in Section~\ref{sec:downstream}.

% \subsubsection{Secenario} Our experiments are conducted on Taobao, a leading large-scale e-commerce platform, and our scenario is "Guess What You Like" column of Taobao App homepage, with two tasks to enhance recommendation serendipity: 
% \begin{itemize}
%     \item \textbf{Item Prediction} aims to predict next serendipitous item based on a user's historical behaviors and profile. For offline experiments, we filter out 19, 141 serendipity samples, splitting them into training and testing sets at 9:1. Since most baselines require scoring candidate item, we follow~\cite{fu2024art} and randomly select 99 negative items for each positive item in the test set to form a candidate set.  As our model SerenGPT generates the next item's title, we employ a matching algorithm to calculate the similarity between the generated title and the candidate items' titles, producing a ranking based on the match scores. The online serving is carried out according to the process in Section~\ref{sec:downstream}.
%     \item \textbf{Search Query Prediction} aims to predict the next serendipitous search query based on the user's historical behavior and profile. Users' search queries can also contain rich serendipity information, such as new preferences and unmet needs in current recommendations. Therefore, we filter out search queries that lead to serendipitous clicks and train SerenGPT to predict these queries. In the online serving, the predicted search queries will enter the recall phase of serendipity channel just like the predicted items, ultimately generating recommendations. For offline experiments, we filter out 26, 672 serendipity queries and divide them into a training set and a test set in a 9:1 ratio, focusing on comparing the accuracy of predicted queries.
% \end{itemize}


% public dataset: SerenLens dataset~\cite{fu2023wisdom}

% - without profile, only train SerenGPT with DPO on serendipity samples + matching algorithm

% industrial dataset: Taobao (item + query)

% - profile + SerenGPT + matching algorithm
% \newline


% We first generate a candidate item set for each user (1 positive + 99 random negative items).  During evaluation, a simple matching algorithm will then be used to match the generated item from SerenGPT.

\subsubsection{Baselines}
For offline experiments, we follow~\cite{fu2024art} and adopt three categories of baselines: \textbf{sequential recommendation, deep learning-based and LLM-based serendipity recommendation models}. Due to the scarcity of serendipity data, we incorporate non-serendipity click data for several baselines. Sequential recommendation algorithms, including \textbf{SASRec}~\cite{kang2018self} and \textbf{BERT4Rec}~\cite{sun2019bert4rec}, are trained on both serendipity and non-serendipity data. Deep learning-based serendipity recommendation methods are mainly trained on serendipity data, but also rely on non-serendipity data for augmentation. In this category, we chose two SOTA baselines \textbf{SerenEnhance}~\cite{fu2023wisdom} and  \textbf{PURS}~\cite{li2020purs}. LLM-based serendipity recommenders are trained only on serendipity data. This is a relatively new area, and we identify two baselines, \ie, \textbf{LLM4Seren}~\cite{tokutake2024can} and \textbf{SerenPrompt}~\cite{fu2024art}. Our model, SerenGPT, is also trained solely on serendipity data. More details can be found in Appendix~\ref{app:baselines}.

 
% \subsubsection{Baselines}
% For \textit{item prediction}, we consider sequential recommendation models \eg, \textbf{SASRec}~\cite{kang2018self} and \textbf{BERT4Rec}~\cite{sun2019bert4rec}, deep learning-based serendipity models like \textbf{SerenEnhance}~\cite{fu2023wisdom} and  \textbf{PURS}~\cite{li2020purs}, and LLM-based serendipity models, \eg, \textbf{LLM4Seren}~\cite{tokutake2024can} and \textbf{SerenPrompt}~\cite{fu2024art}. Due to the scarcity of serendipity data, many baselines incorporate regular click data. Similarly, we enhance the sequential recommendation and deep learning-based serendipity baselines with additional click data samples. For the \textit{search query prediction} task, since prior serendipity models do not address this task, we design several LLM-based baselines, including zero-shot LLMs (\textbf{ZSLLM}) and LLMs supervised fine-tuned on search query data (\textbf{SFT}), as well as different variants of preference alignment, \eg, \textbf{DPO}~\cite{rafailov2024direct}, \textbf{KTO}~\cite{ethayarajh2024kto}, and \textbf{SimPO}~\cite{meng2024simpo}, with then same backbone LLM and prompt as SerenGPT. More details can be found in Appendix~\ref{app:baselines}.

\subsubsection{Metrics}\label{sec:metrics} For offline experiments, we follow~\cite{fu2023wisdom,fu2024art} and adopt HR$_{seren}$@K, NDCG$_{seren}$@K, and MAP$_{seren}$@K, where K=1,3,5,10. HR$_{seren}$@K denotes the proportion of serendipity items retrieved in the top-K position. NDCG$_{seren}$@K is derived from the ranking metric NDCG, which replaces relevant items with serendipitous items. Similarly, MAP$_{seren}$@K is also a serendipity-version of MAP. 

In online experiments, there are three types of metrics: serendipity, utility, and user engagement metrics. \textbf{Serendipity} metrics focus on serendipity-related items. Here, it is slightly different from Definition~\ref{def:serend}, requiring only that items' atomic category, brand, or seller should not have appeared in the user's valid exposures during the last 10 days with visits. Some key metrics include:  \textbf{PVR} (the percentage of finally exposed items that belong to serendipity-related items), the number of \textbf{Clicks}, and \textbf{Transaction Volume} (number of purchases) for serendipity-related items. For simplicity, we refer to them as \textbf{S-PVR}, \textbf{S-Click}, and \textbf{S-TV}. Generally, the higher these metrics are, the better the model performs regarding serendipity.

The \textbf{utility} metrics measure the effectiveness and revenue of RSs across all items, including serendipitous and non-serendipitous ones. Common metrics include \textbf{CTR} (Click-Through Rate) and total \textbf{TV} (Transaction Volume) across all items. These metrics indicate the impact of increasing serendipity on the platform's performance and revenue.  The primary indicator of \textbf{user engagement} here is \textbf{UV3}, which measures the number of users who scroll through more than 200 items. An increase in UV3 suggests that users find the recommendations engaging and remain interested for longer, indicating an improvement in user experience.

% \subsubsection{Metrics} For \textbf{item prediction}, we follow~\cite{fu2023wisdom,fu2024art} and adopt HR$_{seren}$@K, NDCG$_{seren}$@K, and MAP$_{seren}$@K, where K=1,5,10. HR$_{seren}$@K denotes the proportion of serendipity items retrieved in the top-K position. NDCG$_{seren}$@K is derived from the well-known ranking metric NDCG, which replaces relevant items with serendipitous items. Similarly, MAP$_{seren}$@K is also a serendipity-version of MAP. For \textbf{search query prediction} task, we use \textit{hit rate}, the proportion of test samples where the generated query matches the ground truth query. As different queries may have the same meaning, we train an LLM-based relevance model to determine whether two queries are semantically aligned (matched).

\subsubsection{Reproducibility} During the training of SerenGPT, we employ \textbf{Qwen2-0.5B-Instruct}~\footnote{\url{https://huggingface.co/Qwen/Qwen2-0.5B-Instruct}} as the backbone LLM and split the training data into SFT and IPO training data at 1:1. In the SFT phase, SerenGPT is fully fine-tuned on 8 A100 GPUs. In the IPO phase, SerenGPT undergoes LoRA~\cite{hu2021lora} fine-tuning on 8 L40S GPUs, with a LoRA rank of 8, LoRA alpha set to 16, and LoRA dropout set to 0. Both phases use AdamW as the optimizer, with a batch size of 16, a learning rate of 1e-5, and the epoch set to 1. Additionally, the weight $\alpha$ of SFT loss in Eq.~\eqref{eq:final_ipo} is 0.2. During the inference, we utilize vLLM for acceleration, with a temperature of 0.95 and a repetition penalty of 1.05. The LLM-based baselines utilize the same backbone LLM as SerenGPT and are trained on the same training data.

In \textbf{online deployment}, SerenGPT is trained offline and then deployed online following Section~\ref{sec:downstream} with the nearline cache updated every 24 hours. Once deployed, SerenGPT is fixed. Only retrieval and pre-ranking models in the serendipity channel are continuously trained and updated at low costs. In practice, Taobao hashes daily visitors into 100 buckets, each serving millions of users. Cognition profile generation relies on the fine-tuned Qwen-7B-Chat, with profile updates every 15 days. For all users in a bucket, generating profiles on H20 takes about 480 GPU hours, while generating recommendations with SerenGPT on L40S takes 2400 GPU hours. 
% Generating profiles for all users in a single bucket takes about 6 hours on 80 H20 GPUs. Generating recommendations for all users in a bucket using SerenGPT takes about 50 hours on 48 L40S GPUs.

% \subsubsection{Reproducibility} During the training of both item and search query prediction tasks, we employ \textbf{Qwen2-0.5B-Instruct}~\footnote{\url{https://huggingface.co/Qwen/Qwen2-0.5B-Instruct}} as the backbone LLM for SerenGPT and split the training data into SFT and IPO training data at 1:1. In the SFT phase, SerenGPT is fully fine-tuned on 8 A100 GPUs. In the IPO phase, SerenGPT undergoes LoRA fine-tuning on 8 L40S GPUs, with a LoRA rank of 8, LoRA alpha set to 16, and LoRA dropout set to 0. Both phases use AdamW as the optimizer, with a batch size of 16, a learning rate of 1e-5, and the epoch set to 1. Additionally, we incorporate the SFT loss function in the IPO training with a weight of 0.1. During the inference, we utilize vLLM for acceleration, with a temperature of 0.95 and a repetition penalty of 1.05.

\vspace{-5pt}
\subsection{Offline Experiments}
As SERAL is an online framework, the offline experiments focus on SERAL's core component, SerenGPT, while the online experiments in Section~\ref{sec:online} presents the overall performance of SERAL.
\subsubsection{Offline Performance}
The performance is presented in Table~\ref{tab:overall}. Several important observations can be inferred from the results. 

\textit{Firstly, our model, SerenGPT, significantly outperforms baselines, especially in ranking and head metrics.} For example, SerenGPT surpasses the strongest baseline, SerenPrompt, by 226\% in Hit@1 and 79.5\% in NDCG@3. However, in tail recall metrics like HR@10, SerenGPT performs worse than SerenPrompt. This is likely because SerenPrompt scores every item in the candidate set, whereas SerenGPT only generates a single predicted item and then uses a matching model to match items in the candidate set. When the generated item is in the candidate set, it is matched accurately, boosting head metrics like Hit@1. However, when the generated item is not in the candidate set, the performance heavily relies on the matching model, which may struggle to recall relevant items, leading to poorer tail metrics. We opt for the generative model over the scoring model due to the high inference latency of LLMs, making online scoring of multiple items inefficient. Their inference efficiency is compared in the Appendix~\ref{app:efficiency}.

\textit{Secondly, LLM-based serendipity models perform consistently well and exhibit strong data efficiency.} Even zero-shot LLM4Seren outperforms most deep learning-based models, and fine-tuned LLMs further enhance performance owing to LLMs' stronger understanding of serendipity. Given the scarcity of serendipity data, deep learning-based models often rely on non-serendipity data for augmentation. In contrast, LLM-based serendipity models, SerenPrompt and SerenGPT, achieve superior results with only a small set of serendipity data. This highlights LLM-based models' effectiveness and data efficiency, making them suited for serendipity recommendations.

% \subsubsection{Search Query Prediction} Since there was no existing serendipity model for the task of search query prediction, we compare several baselines that we designed, which are based on the SerenGPT structure with modifications to the preference alignment approaches. These can also be seen as ablations of SerenGPT. The final results are presented in Table~\ref{tab:overall_search}, from which we can see that the SerenGPT trained with IPO performs the best. This highlights the importance of preference alignment and choosing the right alignment method. Some alignment methods, such as DPO, perform worse than SFT, which may be due to overfitting, as discussed in Appendix~\ref{app:diversity}, leading to the generation of overly homogeneous items.

% \begin{table}[h]

%     \vspace{-8pt}
%     \caption{Performance on search query prediction task.}
%     % \caption{Overall performance on search query prediction task.  The best result is given in bold, while the second-best value is underlined. The symbol * indicates statistically significant improvement over the best baselines( t-test with $p < 0.05$).}
%     \vspace{-8pt}
%     \centering
%     \scalebox{0.95}{
%     \setlength{\tabcolsep}{1.5mm}
%     {\begin{tabular}{c|cccccc}
% \toprule
% Method & ZSLLM & SFT & DPO & SimPO & KTO & \textbf{IPO(ours)} \\
% \midrule
% hit rate &  & 0.3298 & 0.3191 & 0.3289 &  & \textbf{0.3485*} \\
%  \bottomrule
% \end{tabular}}
% }
% \label{tab:overall_search}
% \vspace{-8pt}
% \end{table}
\subsubsection{Ablation Study}
To investigate the effectiveness of each module, we design several variants of SerenGPT. First, we remove some key modules: \textbf{w/o CP} excludes cognitive profiling from the prompt. \textbf{w/o CDI-D} and \textbf{w/o CDI-P} remove the denoising and pairing components of CDI, respectively, and \textbf{w/o CDI} removes both. Note that generating enough preference pairs is challenging without CDI pair, so w/o CDI pair employs KTO training~\cite{ethayarajh2024kto} that doesn't require pairs. \textbf{w/o IPO} discards IPO training, retaining only SFT on a subset of the data. \textbf{w/ $\alpha=0$} sets the weight $\alpha$ of SFT loss in Eq.~\eqref{eq:final_ipo} to 0. Additionally, we replace IPO with SFT and DPO, resulting in \textbf{w/ SFT} and \textbf{w/ DPO} variants.
\begin{table}[h]

    \vspace{-5pt}
    \caption{Ablation study of SerenGPT. }
    \vspace{-8pt}
    \centering
    \scalebox{0.9}{
    \setlength{\tabcolsep}{1.5mm}
    {\begin{tabular}{ccc|cc|cc}
\toprule
 \multirow{2}{*}{Method} & \multicolumn{2}{c|}{MAP$_{seren}$} & \multicolumn{2}{c|}{NDCG$_{seren}$} & \multicolumn{2}{c}{HR$_{seren}$} \\
 \cmidrule{2-7}
 & @3 & @10 & @3 & @10 & @3 & @10 \\
 \midrule
w/o CP & 0.2933 & 0.3195 & 0.3031 & 0.3558 & 0.4148 & 0.6450 \\
w/o CDI & 0.2840 & 0.3066 & 0.2924 & 0.3377 & 0.4103 & 0.6101 \\
w/o CDI-D & 0.2998 & 0.3224 & 0.3086 & 0.3542 & 0.4307 & 0.6313 \\
w/o CDI-P & \underline{0.3223} & \underline{0.3397} & \underline{0.3303} & 0.3653 & 0.4534 & 0.6101 \\
w/o IPO & 0.2198 & 0.2476 & 0.2312 & 0.2866 & 0.3316 & 0.5632 \\
\midrule
w/ $\alpha=0$ & 0.2887 & 0.3134 & 0.2969 & 0.3460 & 0.4080 & 0.6291 \\
w/ SFT & 0.3117 & 0.3335 & 0.3216 & \underline{0.3663} & \textbf{0.4640} & \underline{0.6616} \\
w/ DPO & 0.2926 & 0.3144 & 0.3027 & 0.3459 & 0.4239 & 0.6192 \\
\midrule
\textbf{SerenGPT} & \textbf{0.3260} & \textbf{0.3509} & \textbf{0.3353} & \textbf{0.3847} & \underline{0.4625} & \textbf{0.6760}\\ 
\bottomrule
\end{tabular}}
    }

\label{tab:Ablation}
\vspace{-5pt}
\end{table}

% \begin{table}[h]

%     \vspace{-5pt}
%     \caption{Ablation study of SerenGPT. }
%     \vspace{-8pt}
%     \centering
%     \scalebox{0.88}{
%     \setlength{\tabcolsep}{1.5mm}
%     {\begin{tabular}{ccc|cc|cc}
% \toprule
%  \multirow{2}{*}{Method} & \multicolumn{2}{c|}{MAP$_{seren}$} & \multicolumn{2}{c|}{NDCG$_{seren}$} & \multicolumn{2}{c}{NDCG$_{seren}$} \\
%  \cmidrule{2-7}
%  & @1 & @5 & @1 & @5 & @1 & @5 \\
%  \midrule
% w/o CP & 0.2513 & 0.3065 & 0.2513 & 0.3262 & 0.2513 & 0.5042 \\
% w/o CDI & 0.2445 & 0.2960 & 0.2445 & 0.3141 & 0.2445 & 0.4996 \\
% w/o CDI denoise & 0.2619 & 0.3110 & 0.2619 & 0.3284 & 0.2619 & 0.5193 \\
% w/o CDI pair & \underline{0.2860} & \underline{0.3317} & \underline{0.2860} & \underline{0.3470} & \underline{0.2860} & 0.5299 \\
% w/o IPO & 0.1771 & 0.2327 & 0.1771 & 0.2530 & 0.1771 & 0.4148 \\
% \midrule
% w/ SFT & 0.2695 & 0.3224 & 0.2695 & 0.3409 & 0.2695 & \underline{0.5496} \\
% w/ DPO & 0.2513 & 0.3031 & 0.2513 & 0.3210 & 0.2513 & 0.5042 \\
% \midrule
% SerenGPT & \textbf{0.2861} & \textbf{0.3395} & \textbf{0.2861} & \textbf{0.3587} & \textbf{0.2861} & \textbf{0.5556}\\ 
% \bottomrule
% \end{tabular}}
%     }

% \label{tab:Ablation}
% \vspace{-5pt}
% \end{table}

Due to page limits, we present representative results in Table~\ref{tab:Ablation}, with a full table in Appendix~\ref{app:ablation}. Removing any component leads to performance degradation, demonstrating the importance of each module. Notably, removing IPO causes the largest drop, highlighting the critical role of preference alignment. The significant decline in w/o CDI further confirms that our data intervention measures effectively enhance data quality. Lastly, replacing IPO with DPO or SFT reduces performance and generates more homogeneous content, whereas IPO increases diversity, as validated in Appendix~\ref{app:diversity}.

\subsection{Online Experiment}\label{sec:online}
\subsubsection{Short-term Online A/B Test}\label{sec:short_ab}
To evaluate the online impact of SERAL, particularly SerenGPT, we conduct a \textbf{two-week A/B test} on "Guess What You Like" of Taobao. We compare two variants, \textbf{SERAL-SFT} and \textbf{SERAL-IPO}, utilizing SerenGPT trained with SFT and IPO, respectively, against the online serendipity-enhanced baseline in Table~\ref{tab:short_ab}. Notably, the online baseline already incorporates cognitive profiles and trending topics to enhance serendipity, as these features were developed and deployed earlier. Since S-PVR and CTR are percentages, we use \textbf{pt} for absolute difference. For example, SerenGPT-IPO's +5.7pt in S-PVR represents an increase from 18.33\% to 24.03\%, an absolute improvement of 5.7\%.
% \begin{table}[h]
%     \vspace{-8pt}
%     \caption{Online improvement on serendipity metrics.}
%     \vspace{-8pt}
%     \centering
%     \scalebox{1}{
%     \setlength{\tabcolsep}{2mm}
%     {\begin{tabular}{c|ccc}
% \toprule
% Model & PVR & Clicks & Transaction Volume \\
% \midrule
% SerenGPT-SFT & +6.4\% & +33.97\% & +29.89\% \\
% SerenGPT-IPO & +6.4\% & +34.41\% & +30.66\% \\
%  \bottomrule
% \end{tabular}}
% }
% \label{tab:short_ab_seren}
% \vspace{-8pt}
% \end{table}
% 
\begin{table}[h]
    \vspace{-4pt}
    \caption{Online improvement over serendipity baseline. Since S-PVR and CTR are percentages, we use percentage points (pt) for absolute improvement. \% denotes relative improvement.}
    \vspace{-5pt}
    \centering
    \scalebox{0.87}{
    \setlength{\tabcolsep}{1.5mm}
    {\begin{tabular}{c|cccccc}
\toprule
% Model & S-PVR & S-Click & S-TV & CTR & TV & UV3 \\
% \midrule
% SerenGPT-SFT & +6.4\% & +33.97\% & +29.89\% & -0.41\% & -0.69\% & +0.54\% \\
% SerenGPT-IPO & +6.4\% & +34.41\% & +30.66\% & -0.20\% & -0.79\% & +0.25\% \\
Model & S-PVR & S-Click & S-TV & CTR & TV & UV3 \\
\midrule
SERAL-SFT & +5.68pt & +26.12\% & +24.58\% & -0.02pt & -0.65\% & +0.48\% \\
SERAL-IPO & +5.70pt & +29.56\% & +27.60\% & -0.01pt & -0.71\% & +0.14\% \\
 \bottomrule
\end{tabular}}
}
\label{tab:short_ab}
\vspace{-5pt}
\end{table}

Both variants of SERAL show significant improvements in serendipity metrics, such as exposure ratio (S-PRV), clicks (S-Click), and transaction volume (S-TV) of serendipity-related items. This shows that SERAL increased the proportion of serendipitous items in recommendations, and these items successfully captured user interest (clicks and purchases). It also improves the user engagement metric UV3, indicating that users are more engaged. Its impact on overall utility metrics, such as CTR and total transaction volume (TV), is relatively minor. Besides, SERAL-IPO outperforms SERAL-SFT in serendipity metrics, while maintaining comparable utility performance. This demonstrates that IPO can deliver serendipitous and engaging recommendations.
% \begin{table}[h]
%     \vspace{-8pt}
%     \caption{Improvement on utility and user experience metrics.}
%     \vspace{-8pt}
%     \centering
%     \scalebox{1}{
%     \setlength{\tabcolsep}{2mm}
%     {\begin{tabular}{c|ccc}
% \toprule
% Model & CTR & Transaction Volume & UV3 \\
% \midrule
% SerenGPT-SFT & -0.02\% & -0.69\% & +0.54\% \\
% SerenGPT-IPO & -0.01\% & -0.79\% & +0.25\% \\
%  \bottomrule
% \end{tabular}}
% }
% \label{tab:short_ab_util}
% \vspace{-8pt}
% \end{table}
\begin{figure}
    \centering
    \vspace{-10pt}
    \includegraphics[trim={0.3cm 0
    0 0},clip,width=0.49\textwidth]{imgs/online_metrics_2.pdf}
    \vspace{-20pt}
    \caption{Long-term online impact of serendipity items.}
    \vspace{-10pt}
    \label{fig:long_ab}
\end{figure}
% \begin{figure}
%     \centering
%     % \vspace{-10pt}
%     \includegraphics[trim={0.3cm 0
%     0 0},clip,width=0.48\textwidth]{imgs/online_metrics.pdf}
%     \vspace{-20pt}
%     \caption{Long-term online impact of our SERAL.}
%     \vspace{-10pt}
%     \label{fig:long_ab}
% \end{figure}
\subsubsection{Long-term Online Impact of Serendipity Items}
Our proposed SERAL now serves the primary traffic in the "Guess What You Like" on Taobao. To investigate the long-term effects of serendipity items in large-scale RSs, we maintain a small traffic group without any serendipity enhancements as our baselines and compare it with SERAL for \textbf{four months}. Their daily performance and SERAL's average improvement are presented in Figure~\ref{fig:long_ab} and Table~\ref{tab:long_ab}. Note that, in Figure~\ref{fig:long_ab}, we apply min-max normalization to the y-axis of TV, CTR, and UV3 to protect sensitive data. For example, if the original data range is 1,000-5,000, it is scaled to 0-1. This only modifies the y-axis without altering trends and relative changes.
% More metrics are provided in Appendix~\ref{app:long_ab}.

\begin{table}[h]
    \vspace{-10pt}
    \caption{Online improvement over non-serendipity baseline. }
    \vspace{-8pt}
    \centering
    \scalebox{0.87}{
    \setlength{\tabcolsep}{1.5mm}
    {\begin{tabular}{c|cccccc}
\toprule
Model & S-PVR & S-Click & S-TV & CTR & TV & UV3 \\
\midrule
SERAL & +17.36pt & +819.9\% & +969.6\% & +0.05pt & +0.98\% & +3.04\% \\
 \bottomrule
\end{tabular}}
}
\label{tab:long_ab}
\vspace{-10pt}
\end{table}
% Firstly, serendipity model significantly increases the proportion of serendipitous items in recommendations. Over four months, the average \textbf{serendipity exposure ratio (S-PVR) rises from 3.35\% to 20.71\%} and serendipity-related clicks (S-Click) and transaction volumes (S-TV) also achieves substantial increase. Secondly, utility metrics (TV and CTR) for all items remain stable, with a slight increase of 0.98\% and 0.05pt. Lastly, there is a significant improvement in user engagement, with a \textbf{3.04\%} average increase in \textbf{UV3}. 
Compared to the baseline, our method has achieved a significant enhancement in serendipity items, reflected in S-PVR, S-Click, and S-TV. The increase of serendipitous items has bolstered the overall transaction volume (TV) and CTR by \textbf{0.98\%} and \textbf{0.05pt}, respectively. Moreover, it has also markedly improved user engagement, with a \textbf{3.04\%} average increase in \textbf{UV3}. This demonstrates that serendipity items help to break the filter bubble of homogeneous recommendations and effectively improve user engagement while also boosting CTR and revenue. The improvements here differ from those in Section~\ref{sec:short_ab} because various SERAL-related approaches are employed online, \eg, retrieval by SerenGPT and cognitive profiles. In contrast, Section~\ref{sec:short_ab} focuses solely on the impact of SerenGPT.

% Ablation exp table
% \begin{table*}[h]

%     \vspace{-10pt}
%     \caption{Ablation }
%     \vspace{-8pt}
%     \centering
%     \scalebox{1}{
%     \setlength{\tabcolsep}{1.5mm}
%     {\begin{tabular}{ccccccc|cccccc}
% \toprule
% \multirow{2.5}{*}{Method}&\multicolumn{3}{c|}{@1}&\multicolumn{3}{c|}{@3}&\multicolumn{3}{c|}{@5}&\multicolumn{3}{c}{@10}\\ \cmidrule{2-13}
% &MAP&NDCG&\multicolumn{1}{c|}{HR}&MAP&NDCG&HR&MAP&NDCG&\multicolumn{1}{c|}{HR}&MAP&NDCG&HR\\ \midrule

%  no\_user\_image &  0.2513 &  0.2513 &  \multicolumn{1}{c|}{0.2513} &  0.2933 & 0.3031 & 0.4148 & 0.3065 & 0.3262 & \multicolumn{1}{c|}{0.5042} & 0.3195 & 0.3558 & 0.6450 \\
% no\_revelance & 0.2619 & 0.2619 & \multicolumn{1}{c|}{0.2619} & 0.2998 & 0.3086 & 0.4307 & 0.3110 & 0.3284 & \multicolumn{1}{c|}{0.5193} & 0.3224 & 0.3542 & 0.6313 \\
% no\_CDI\_pair & 0.2869 & 0.2869 & \multicolumn{1}{c|}{0.2869} & 0.3223 & 0.3303 & 0.4534 & 0.3317 & 0.3470 & \multicolumn{1}{c|}{0.5299} & 0.3397 & 0.3653 & 0.6101 \\
% no\_CDI & 0.2445 & 0.2445 & \multicolumn{1}{c|}{0.2445} & 0.2840 & 0.2924 & 0.4103 & 0.2960 & 0.3141 & \multicolumn{1}{c|}{0.4996} & 0.3066 & 0.3377 & 0.6101 \\
% no\_ipo(sft) & 0.2695 & 0.2695 & \multicolumn{1}{c|}{0.2695} & 0.3117 & 0.3216 & 0.4640 & 0.3224 & 0.3409 & \multicolumn{1}{c|}{0.5496} & 0.3335 & 0.3663 & 0.6616 \\
% dpo & 0.2513 & 0.2513 & \multicolumn{1}{c|}{0.2513} & 0.2926 & 0.3027 & 0.4239 & 0.3031 & 0.3210 & \multicolumn{1}{c|}{0.5042} & 0.3144 & 0.3459 & 0.6192 \\
% \textbf{SerenGPT-IPO} & 0.2740 & 0.2740 & \multicolumn{1}{c|}{0.2740} & 0.3141 & 0.3231 & 0.4481 & 0.3263 & 0.3445 & \multicolumn{1}{c|}{0.5375} & 0.3366 & 0.3680 & 0.6488 \\ 

% \bottomrule
% \end{tabular}}
%     }

% \label{tab:Ablation}
% \vspace{-5pt}
% \end{table*}

\subsubsection{Nearline Cache} 
 This section explores the impact of nearline caching frequency in a \textbf{two-week online test}, with the frequency set to \textbf{6h}, \textbf{12h}, and \textbf{24h}. The performance on different types of metrics (S-PVR, S-Click, CTR, TV, and UV3) and resource usage (\textbf{QPS} and \textbf{E-QPS}) are shown in Figure~\ref{fig:cache}. Here, QPS refers to queries per second for invoking SerenGPT, with higher QPS indicating greater resource usage. E-QPS denotes failed requests, and a higher E-QPS indicates greater resource strain, making it more difficult to access resources and provide recommendations. To facilitate plotting and protect sensitive data, all metrics are normalized to 1 based on their maximum values. As shown in Figure~\ref{fig:cache}, a higher cache frequency leads to better serendipity (S-PVR, S-Click), but it also results in greater resource consumption (QPS). Higher frequencies may lead to resource congestion, blocking the recommendation process and significantly reducing effectiveness. The cache frequency has little impact on the user experience metric UV3 and only a small effect on utility. However, even with a 24-hour update frequency, the improvement in serendipity remains significant. Therefore, the caching frequency should be adjusted based on available resources to strike a balance between performance and efficiency.

% \begin{figure}
%     \centering
%     \vspace{-10pt}
%     \includegraphics[trim={0.3cm 0
%     0 0},clip,width=0.48\textwidth]{imgs/freq_exp.pdf}
%     \vspace{-20pt}
%     \caption{Online Performance of different caching frequency .}
%     \vspace{-10pt}
%     \label{fig:cache}
% \end{figure}

% \textit{add the figure and other observations when experiments are over}

% \subsubsection{Compatibility Analysis}

% \subsubsection{Case Study} profile+user history behaviors+ serendipity item

\begin{figure}[h]
    \centering
    \vspace{-5pt}
    \includegraphics[trim={0.3cm 0cm
    0 2cm},clip,width=0.48\textwidth]{imgs/freq_exp_1.pdf}
    \vspace{-25pt}
    \caption{Online Performance of different caching frequency.}
    \vspace{-15pt}
    \label{fig:cache}
\end{figure}



\section{Conclusion}
This work addresses the filter bubble problem in RSs by proposing  SERAL. It comprises three stages: Cognition Profile Generation to compress user behavior into multi-level profiles, SerenGPT Alignment to align LLM-based serendipity predictions with human preferences, and Nearline Adaptation for efficient industrial deployment. Online experiments show it improves serendipity PVR, clicks, and transactions by 5.7\%, 29.56\%, and 27.6\%, enhancing user experience without much impact on revenue. Fully deployed in Taobao’s "Guess What You Like" section, it shows LLMs' potential to break the filter bubble and elevate user satisfaction in RSs.