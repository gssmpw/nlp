\section{Related Work}
\subsection{Serendipity Recommendations}
% The concept of serendipity, how it solves filter bubbles, and its distinction with diversity and novelty (ref ~\cite{fu2024art})

Due to feedback loops, traditional RSs tend to recommend items similar to what users already know, leading to user boredom. To address this, serendipity is introduced in RSs, referring to unexpected yet appealing experiences~\cite{fu2023deep,ziarani2021serendipity,kotkov2016survey}. According to the Britannica Dictionary, serendipity is "luck that takes the form of finding valuable or pleasant things that are not looked for." Although there is no universally agreed-upon definition of recommendation serendipity, most research agrees that it should involve two central aspects: unexpectedness and relevance~\cite{fu2024art,fu2023deep,fu2023wisdom}, \ie, 
it should go beyond user expectations while also engaging their interest. 
% These two aspects help RSs break out of the filter bubble of homogeneous recommendations, ultimately offering unexpected yet appealing experiences for users. 
Besides, diversity and novelty are two concepts often associated with serendipity~\cite{fu2023deep,kotkov2016survey,kaminskas2016diversity}. They can introduce unfamiliar items to the user, offering a fresh experience (unexpectedness). However, these items may not attract users (non-relevance) and even cause dissatisfaction~\cite{kotkov2016survey}. Thus, serendipity is more challenging, necessitating unexpected recommendations still attract users' interests.

% DL-based~\cite{fu2023deep} and LLM-based~\cite{tokutake2024can,fu2024art} serendipity recommendation

Deep learning-based serendipity recommendation can be categorized into pre-processing, in-processing, and post-processing approaches~\cite{fu2023deep}. The pre-processing stage typically involves data pre-processing, \eg, engineering serendipity features~\cite{li2019haes,kim2019sequential}. 
% For instance, HAES~\cite{li2019haes} leverages the users’ demographic information and movies’ statistical information to calculate the elasticity to discover serendipitous movies. 
The in-processing approaches incorporate serendipity during model training and learn a serendipity representation~\cite{fu2023wisdom,li2020directional,li2020purs,zhang2021snpr,wang2023industrial}.
% For example, SerenEnhance~\cite{fu2023wisdom} learning the fine-grained facets of serendipity during training. 
Post-processing methods re-rank given relevance-oriented lists to generate serendipity-oriented recommendation lists~\cite{cheng2017learning,liu2023personalized}. 
% For instance, DCF~\cite{cheng2017learning} re-ranks candidate items to maximize diversity scores. 
In-processing is generally the most prevalent and effective. However, due to the scarcity of serendipity data, which often relies on user annotations, they must adopt smaller models and depend on biased data for augmentation. This may reinforce feedback loops, making bursting filter bubbles and identifying serendipity challenging.


Recently, LLMs have been applied to serendipity recommendations~\cite{fu2024art,tokutake2024can}. For example, in~\cite{tokutake2024can}, LLMs evaluate items' serendipity in a zero-shot manner. SerenPrompt~\cite{fu2024art} designs various prompts for LLMs to assess serendipity. These preliminary attempts show the promising potential of LLMs in serendipity recommendations. Still, several unresolved challenges remain, such as aligning LLMs with humans in serendipity and their deployment in industrial RSs.


\subsection{LLM-based Recommendations}
The past few years have witnessed a growing interest in LLM-based RSs~\cite{li2023large,zhu2023large,chen2023large,fan2023recommender,wu2023survey,liu2023pre,yu2023self,lin2023can}, which can be roughly classified into two categories: (1) LLMs as recommenders and (2) LLMs as components of traditional recommenders. The former is to adopt LLMs as recommenders to generate recommendations directly~\cite{xi2024memocrs,chatrec,xi2024play,lin2024rella,bao2023tallrec,zheng2024adapting,zhu2024collaborative,zheng2024harnessing,dong2024unsupervised,tan2024idgenrec,wu2024coral,kim2024large,wang2024eager,lin2024bridging}. Early attempts primarily utilize zero-shot LLMs~\cite{chatrec,xi2024memocrs}. 
% For instance, ChatRec~\cite{chatrec} and MemoCRS~\cite{xi2024memocrs} employ LLMs as recommender system interfaces for conversational multi-round recommendations. 
However, this falls behind SOTA recommendation models, so the focus of later work shifts to how to inject recommendation knowledge into LLMs, primarily through fine-tuning, such as TALLRec~\cite{bao2023tallrec} fine-tuned on LLaMA-7B~\cite{llama}. 
% ReLLa~\cite{lin2023rella} design retrieval-enhanced instruction tuning by adopting semantic user behavior retrieval as a data augmentation technique and finetunes Vicuna-13B.
The latter integrates knowledge from LLMs into conventional RSs to enhance the recommendation performance and meanwhile avoid the online inference latency issue of LLMs~\cite{xi2023towards,lyu2023llm,ren2024representation,xi2024efficient,xi2024decoding,liu2024once,ren2024enhancing,du2024disco,tian2024reland,wang2024can}. For example, KAR~\cite{xi2023towards} and RLMRec~\cite{ren2024representation} integrate open-world knowledge from LLMs into RSs. 
% Some researchers propose S\&R Multi-Domain Foundation model~\cite{gong2023unified}, which finetunes LLMs on recommendation and search data to extract domain invariant features for promoting performance in cold-start scenarios. 

% There are two categories: LLMs as recommenders and LLMs as feature enhancers. The latter is more suitable for deployment.

The latter is more deployable for industrial RSs when integrating RSs and LLMs~\cite{xi2023towards,zhang2024notellm,xi2024decoding,luo2024kellmrec}. The inference latency of LLMs is very high, and current industrial RSs cannot support the online inference of LLMs that the first approach requires. The latter only involves LLMs offline to generate features, which minimizes its impact on online inference latency. However, these deployable methods have only focused on improving recommendation accuracy and may struggle to adapt to data distribution changes. Therefore, we focus on serendipity recommendations and adopt nearline caching solutions to avoid LLMs' online inference while ensuring rapid updates to adapt to distribution changes.
% , efficiently integrating LLMs into industrial RSs. 
% To this end, our work follows the latter but shifts the focus to serendipitous recommendations, incorporating serendipitous items generated by LLMs with traditional RSs.