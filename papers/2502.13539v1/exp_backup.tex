\section{Experiment}
\subsection{Setup}

% % main experiment table
% \begin{table*}[h]

%     \vspace{-10pt}
%     \caption{Overall performance on product recommendation task.}
%     \vspace{-8pt}
%     \centering
%     \scalebox{1}{
%     \setlength{\tabcolsep}{1.5mm}
%     {\begin{tabular}{ccccccc|cccccc}
% \toprule
% \multirow{2.5}{*}{Method} 
%                        & \multicolumn{3}{c|}{@1}                                                 & \multicolumn{3}{c|}{@3}                            & \multicolumn{3}{c|}{@5}                                                                                          & \multicolumn{3}{c}{@10}                                                                                        \\ \cmidrule{2-13} 
%                        & MAP             & NDCG            & \multicolumn{1}{c|}{HR}        & MAP             & NDCG            & HR         & MAP                                 & NDCG                                & \multicolumn{1}{c|}{HR}         & MAP                                 & NDCG                               & HR                             \\ \midrule

% SASRec      & 0.0606 & 0.0606  & \multicolumn{1}{l|}{0.0606} & 0.0903 & 0.0876 & 0.1067 & 0.0903 & 0.0970 & \multicolumn{1}{l|}{0.1294} & 0.0903 & 0.1067 & 0.1589 \\
% Bert4Rec    & 0.0272 & 0.0272  & \multicolumn{1}{l|}{0.0272} & 0.0332 & 0.0351 & 0.0408 & 0.0339 & 0.0363 & \multicolumn{1}{l|}{0.0439} & 0.0348 & 0.0386 & 0.0507 \\ \midrule
% PURS                          & 0.0194                        & 0.0194          & \multicolumn{1}{l|}{0.0194}          & 0.0247          & 0.0267          & \multicolumn{1}{l|}{0.0323}          & 0.0273          & 0.0316          & \multicolumn{1}{l|}{0.0452}          & 0.0297          & 0.0377          & 0.0645          \\ 
% \midrule
% LLM4Seren        & 0.0683 & 0.0683  & \multicolumn{1}{l|}{0.0683} & 0.1162 & 0.1191 & 0.1893 & 0.1334 & 0.1485  & \multicolumn{1}{l|}{0.2820} & 0.1543 & 0.2047 & 0.4964 \\
% SerenPrompt & 0.0840 & 0.0840 & \multicolumn{1}{l|}{0.0840} & 0.1749 & 0.1904 & 0.3330 & 0.2186 & 0.2725 & \multicolumn{1}{l|}{\textbf{0.5722}} & 0.2454 & 0.3530 & \textbf{0.8705} \\ \midrule
% % SerenGPT-SFT         & 0.1771 & 0.1771  & \multicolumn{1}{l|}{0.1771} & 0.2198 & 0.2312 & 0.3315 & 0.2327 & 0.2529 & \multicolumn{1}{l|}{0.4148} & 0.2476 & 0.2866 & 0.5632 \\
% \textbf{SerenGPT}        & \textbf{0.2740} & \textbf{0.2740} & \multicolumn{1}{l|}{\textbf{0.2740}} & \textbf{0.3140} & \textbf{0.3231} & \textbf{0.4481} & \textbf{0.3262} & \textbf{0.3444} & \multicolumn{1}{l|}{0.5374} & \textbf{0.3365} & \textbf{0.3680} & 0.6487\\
%  \bottomrule
% \end{tabular}}
%     }


% \label{tab:overall}
% \vspace{0pt}
% \end{table*}

\begin{table*}[h]

    % \vspace{-10pt}
    \caption{Overall performance on product recommendation task.  The best result is given in bold, while the second-best value is underlined. The symbol * indicates statistically significant improvement over the best baselines( t-test with $p < 0.05$).}
    \vspace{-8pt}
    \centering
    \scalebox{1}{
    \setlength{\tabcolsep}{1.5mm}
    {\begin{tabular}{ccccc|cccc|cccc}
\toprule
\multirow{2}{*}{Method} & \multicolumn{4}{c|}{MAP$_{seren}$} & \multicolumn{4}{c|}{NDCG$_{seren}$} & \multicolumn{4}{c}{HR$_{seren}$} \\
\cmidrule{2-13} 
 & @1 & @3 & @5 & @10 & @1 & @3 & @5 & @10 & @1 & @3 & @5 & @10 \\
 \midrule
SASRec & 0.0606 & 0.0810 & 0.0863 & 0.0903 & 0.0606 & 0.0876 & 0.0971 & 0.1067 & 0.0606 & 0.1067 & 0.1294 & 0.1590 \\
Bert4Rec & 0.0273 & 0.0332 & 0.0339 & 0.0348 & 0.0273 & 0.0352 & 0.0364 & 0.0386 & 0.0273 & 0.0409 & 0.0439 & 0.0507 \\
\midrule
PURS & 0.0194 & 0.0247 & 0.0273 & 0.0297 & 0.0194 & 0.0267 & 0.0316 & 0.0377 & 0.0194 & 0.0323 & 0.0452 & 0.0645 \\
SerenEnhance & \underline{0.1900} & \underline{0.1956} & 0.1965 & 0.1972 & \underline{0.1900} & \underline{0.1974} & 0.1993 & 0.2007 & \underline{0.1900} & 0.2029 & 0.2074 & 0.2120 \\
\midrule
LLM4Seren & 0.0683 & 0.1163 & 0.1335 & 0.1544 & 0.0683 & 0.1192 & 0.1485 & 0.2047 & 0.0683 & 0.1893 & 0.2820 & 0.4965 \\
SerenPrompt & 0.0840 & 0.1750 & \underline{0.2187} & \underline{0.2455} & 0.0840 & 0.1904 & \underline{0.2725} & \underline{0.3531} & 0.0840 & \underline{0.3331} & \textbf{0.5723} & \textbf{0.8706} \\
\midrule
\textbf{SerenGPT} & \textbf{0.2861*} & \textbf{0.3260*} & \textbf{0.3395*} & \textbf{0.3509*} & \textbf{0.2861*} & \textbf{0.3353*} & \textbf{0.3587*} & \textbf{0.3847*} & \textbf{0.2861*} & \textbf{0.4625*} & \underline{0.5556} & \underline{0.6760}\\
 \bottomrule
\end{tabular}}
}
\label{tab:overall}
\vspace{0pt}
\end{table*}



% \subsubsection{Scenario} Our experiments are conducted on Taobao, a leading large-scale e-commerce platform, including serendipitous product recommendations in "Guess What You Like" of Taobao homepage, and serendipitous search query predictions in Main Search.
% \begin{itemize}
%     \item \textbf{Product Recommendation} aims to predict next serendipitous item based on a user's historical behaviors and profile. For offline experiments, we filter out 19, 141 serendipity samples, splitting them into training and testing sets at 9:1. Since most baselines require scoring candidate item, we follow~\cite{fu2024art} and randomly select 99 negative items for each positive item in the test set to form a candidate set.  As our model SerenGPT generates the next item's title, we employ a matching algorithm to calculate the similarity between the generated title and the candidate items' titles, producing a ranking based on the match scores. For online serving, w
%     \item \textbf{Search Query Prediction} aims to predict the next serendipitous search query based on the user's historical behavior and profile.  The definition of serendipity remains consistent with Definition 1. For offline experiments, we filter out 26, 672 serendipity samples.
% \end{itemize}

\subsubsection{Scenario} Our experiments are conducted on \textbf{Taobao}, a leading large-scale e-commerce platform, and our scenario is the "\textbf{Guess What You Like}" column of the Taobao App homepage. In this scenario, we aim to predict the next serendipitous item based on a user's historical behaviors and profile, thus enhancing its serendipity and user experiences. For offline experiments, we filter out 19, 141 serendipity samples from this scenario according to Section~\ref{sec:data_gen}, splitting them into training and testing sets at 9:1. Since most serendipitous recommendation methods~\cite{fu2024art,tokutake2024can} require ranking a small set of candidate items, we follow~\cite{fu2024art} and randomly select 99 negative (non-serendipitous) items for each positive (serendipitous) item in the test set to form a candidate item set. As our model SerenGPT is a generative model that generates the next serendipitous item's title, we employ a matching algorithm to calculate the similarity between the generated title and the candidate items' titles, producing a ranking based on the match scores. The online serving is carried out according to the process in Section~\ref{sec:downstream}.

% \subsubsection{Secenario} Our experiments are conducted on Taobao, a leading large-scale e-commerce platform, and our scenario is "Guess What You Like" column of Taobao App homepage, with two tasks to enhance recommendation serendipity: 
% \begin{itemize}
%     \item \textbf{Item Prediction} aims to predict next serendipitous item based on a user's historical behaviors and profile. For offline experiments, we filter out 19, 141 serendipity samples, splitting them into training and testing sets at 9:1. Since most baselines require scoring candidate item, we follow~\cite{fu2024art} and randomly select 99 negative items for each positive item in the test set to form a candidate set.  As our model SerenGPT generates the next item's title, we employ a matching algorithm to calculate the similarity between the generated title and the candidate items' titles, producing a ranking based on the match scores. The online serving is carried out according to the process in Section~\ref{sec:downstream}.
%     \item \textbf{Search Query Prediction} aims to predict the next serendipitous search query based on the user's historical behavior and profile. Users' search queries can also contain rich serendipity information, such as new preferences and unmet needs in current recommendations. Therefore, we filter out search queries that lead to serendipitous clicks and train SerenGPT to predict these queries. In the online serving, the predicted search queries will enter the recall phase of serendipity channel just like the predicted items, ultimately generating recommendations. For offline experiments, we filter out 26, 672 serendipity queries and divide them into a training set and a test set in a 9:1 ratio, focusing on comparing the accuracy of predicted queries.
% \end{itemize}


% public dataset: SerenLens dataset~\cite{fu2023wisdom}

% - without profile, only train SerenGPT with DPO on serendipity samples + matching algorithm

% industrial dataset: Taobao (item + query)

% - profile + SerenGPT + matching algorithm
% \newline


% We first generate a candidate item set for each user (1 positive + 99 random negative items).  During evaluation, a simple matching algorithm will then be used to match the generated item from SerenGPT.

\subsubsection{Baselines}
For offline experiments, we follow~\cite{fu2024art} and adopt three categories of baselines: \textbf{sequential recommendation, deep learning-based serendipity recommendation, and LLM-based serendipity recommendation algorithms}. Due to the scarcity of serendipity data, many baselines incorporate regular click data. Similarly, we also enhance them with additional click data samples. Sequential recommendation algorithms, including \textbf{SASRec}~\cite{kang2018self} and \textbf{BERT4Rec}~\cite{sun2019bert4rec}, are trained on both serendipity and non-serendipity data. Deep learning-based serendipity recommendation methods are mainly trained on serendipity data, but due to the limited amount of such data, they leverage additional non-serendipity data for augmentation. In this category, we chose two state-of-the-art baselines \textbf{SerenEnhance}~\cite{fu2023wisdom} and  \textbf{PURS}~\cite{li2020purs}. LLM-based serendipity recommendation approaches are trained only on serendipity data. This is a relatively new area, and we identify two baselines, \ie, \textbf{LLM4Seren}~\cite{tokutake2024can} and \textbf{SerenPrompt}~\cite{fu2024art}. Our model, SerenGPT, is also trained solely on serendipity data. More details can be found in Appendix~\ref{app:baselines}.

 
% \subsubsection{Baselines}
% For \textit{item prediction}, we consider sequential recommendation models \eg, \textbf{SASRec}~\cite{kang2018self} and \textbf{BERT4Rec}~\cite{sun2019bert4rec}, deep learning-based serendipity models like \textbf{SerenEnhance}~\cite{fu2023wisdom} and  \textbf{PURS}~\cite{li2020purs}, and LLM-based serendipity models, \eg, \textbf{LLM4Seren}~\cite{tokutake2024can} and \textbf{SerenPrompt}~\cite{fu2024art}. Due to the scarcity of serendipity data, many baselines incorporate regular click data. Similarly, we enhance the sequential recommendation and deep learning-based serendipity baselines with additional click data samples. For the \textit{search query prediction} task, since prior serendipity models do not address this task, we design several LLM-based baselines, including zero-shot LLMs (\textbf{ZSLLM}) and LLMs supervised fine-tuned on search query data (\textbf{SFT}), as well as different variants of preference alignment, \eg, \textbf{DPO}~\cite{rafailov2024direct}, \textbf{KTO}~\cite{ethayarajh2024kto}, and \textbf{SimPO}~\cite{meng2024simpo}, with then same backbone LLM and prompt as SerenGPT. More details can be found in Appendix~\ref{app:baselines}.

\subsubsection{Metrics}\label{sec:metrics} For offline experiments, we follow~\cite{fu2023wisdom,fu2024art} and adopt HR$_{seren}$@K, NDCG$_{seren}$@K, and MAP$_{seren}$@K, where K=1,3,5,10. HR$_{seren}$@K denotes the proportion of serendipity items retrieved in the top-K position. NDCG$_{seren}$@K is derived from the well-known ranking metric NDCG, which replaces relevant items with serendipitous items. Similarly, MAP$_{seren}$@K is also a serendipity-version of ranking metric MAP. 

In online experiments, the metrics are divided into three categories: serendipity, utility, and user engagement metrics. \textbf{Serendipity} metrics focus on serendipity-related items. Here, it is slightly different from Definition~\ref{def:serend}, requiring only that items' atomic category, brand, or seller should not have appeared in the user's valid exposures during the last 10 days with visits. Key metrics in this category include:  \textbf{PVR} (the percentage of finally exposed items that belong to serendipity-related items), the number of \textbf{Clicks}, and \textbf{Transaction Volume} (number of purchases) for serendipity-related items. For simplicity, we refer to these metrics as \textbf{S-PVR}, \textbf{S-Click}, and \textbf{S-TV}. Generally, the higher these metrics are, the better our recommendations perform regarding serendipity.

The \textbf{utility} metrics measure the effectiveness and revenue of RSs across all items, including serendipitous and non-serendipitous ones. Common metrics include \textbf{CTR} (Click-Through Rate) and total \textbf{TV} (Transaction Volume) across all items. These metrics indicate the impact of increasing serendipity on the platform's performance and revenue.  The primary indicator of \textbf{user engagement} here is \textbf{UV3}, which measures the number of users who scroll through more than 200 items. An increase in UV3 suggests that users find the recommendations engaging and remain interested for longer, indicating an improvement in user experience.

% \subsubsection{Metrics} For \textbf{item prediction}, we follow~\cite{fu2023wisdom,fu2024art} and adopt HR$_{seren}$@K, NDCG$_{seren}$@K, and MAP$_{seren}$@K, where K=1,5,10. HR$_{seren}$@K denotes the proportion of serendipity items retrieved in the top-K position. NDCG$_{seren}$@K is derived from the well-known ranking metric NDCG, which replaces relevant items with serendipitous items. Similarly, MAP$_{seren}$@K is also a serendipity-version of MAP. For \textbf{search query prediction} task, we use \textit{hit rate}, the proportion of test samples where the generated query matches the ground truth query. As different queries may have the same meaning, we train an LLM-based relevance model to determine whether two queries are semantically aligned (matched).

\subsubsection{Reproducibility} During the training of SerenGPT, we employ \textbf{Qwen2-0.5B-Instruct}~\footnote{\url{https://huggingface.co/Qwen/Qwen2-0.5B-Instruct}} as the backbone LLM and split the training data into SFT and IPO training data at 1:1. In the SFT phase, SerenGPT is fully fine-tuned on 8 A100 GPUs. In the IPO phase, SerenGPT undergoes LoRA fine-tuning on 8 L40S GPUs, with a LoRA rank of 8, LoRA alpha set to 16, and LoRA dropout set to 0. Both phases use AdamW as the optimizer, with a batch size of 16, a learning rate of 1e-5, and the epoch set to 1. Additionally, the weight $\alpha$ of SFT loss in Eq.~\eqref{eq:final_ipo} is 0.2. During the inference, we utilize vLLM for acceleration, with a temperature of 0.95 and a repetition penalty of 1.05. The LLM-based baselines utilize the same backbone LLM as SerenGPT and are trained on the same training data.

% \subsubsection{Reproducibility} During the training of both item and search query prediction tasks, we employ \textbf{Qwen2-0.5B-Instruct}~\footnote{\url{https://huggingface.co/Qwen/Qwen2-0.5B-Instruct}} as the backbone LLM for SerenGPT and split the training data into SFT and IPO training data at 1:1. In the SFT phase, SerenGPT is fully fine-tuned on 8 A100 GPUs. In the IPO phase, SerenGPT undergoes LoRA fine-tuning on 8 L40S GPUs, with a LoRA rank of 8, LoRA alpha set to 16, and LoRA dropout set to 0. Both phases use AdamW as the optimizer, with a batch size of 16, a learning rate of 1e-5, and the epoch set to 1. Additionally, we incorporate the SFT loss function in the IPO training with a weight of 0.1. During the inference, we utilize vLLM for acceleration, with a temperature of 0.95 and a repetition penalty of 1.05.


\subsection{Offline Performance}
The offline performance is presented in Table~\ref{tab:overall}. Several important observations can be inferred from the results. 

\textit{Firstly, our model, SerenGPT, significantly outperforms baselines, especially in ranking and head metrics.} For example, SerenGPT surpasses the strongest baseline, SerenPrompt, by 226\% in Hit@1 and 79.5\% in NDCG@3, demonstrating its ability to identify serendipity after preference alignment. However, in tail recall metrics like HR@10, SerenGPT performs worse than SerenPrompt. This is likely because SerenPrompt scores every item in the candidate set, whereas SerenGPT only generates a single predicted item and then uses a matching model to match items in the candidate set. When the generated item is in the candidate set, it is matched accurately, boosting head metrics like Hit@1. However, when the generated item is not in the candidate set, the performance heavily relies on the matching model, which may struggle to recall relevant items, leading to poorer tail metrics. We opt for the generative model over the scoring model due to the high inference latency of LLMs, making online scoring of multiple items inefficient. Their inference efficiency is compared in the Appendix~\ref{app:efficiency}.

\textit{Secondly, LLM-based serendipity models perform consistently well and exhibit strong data efficiency.} Even zero-shot LLM4Seren outperforms most deep learning-based models, and fine-tuned LLMs further enhance performance. This is likely due to LLMs' vast world knowledge and powerful reasoning capabilities, which bring a stronger understanding of serendipity. Given the scarcity of serendipity data, deep learning-based models often rely on non-serendipity click data for augmentation. In contrast, LLM-based serendipity models, SerenPrompt and SerenGPT, achieve superior results with only a small set of serendipity data without augmentation. This highlights LLM-based models' effectiveness and data efficiency, making them suited for serendipity recommendations.

% \subsubsection{Search Query Prediction} Since there was no existing serendipity model for the task of search query prediction, we compare several baselines that we designed, which are based on the SerenGPT structure with modifications to the preference alignment approaches. These can also be seen as ablations of SerenGPT. The final results are presented in Table~\ref{tab:overall_search}, from which we can see that the SerenGPT trained with IPO performs the best. This highlights the importance of preference alignment and choosing the right alignment method. Some alignment methods, such as DPO, perform worse than SFT, which may be due to overfitting, as discussed in Appendix~\ref{app:diversity}, leading to the generation of overly homogeneous items.

% \begin{table}[h]

%     \vspace{-8pt}
%     \caption{Performance on search query prediction task.}
%     % \caption{Overall performance on search query prediction task.  The best result is given in bold, while the second-best value is underlined. The symbol * indicates statistically significant improvement over the best baselines( t-test with $p < 0.05$).}
%     \vspace{-8pt}
%     \centering
%     \scalebox{0.95}{
%     \setlength{\tabcolsep}{1.5mm}
%     {\begin{tabular}{c|cccccc}
% \toprule
% Method & ZSLLM & SFT & DPO & SimPO & KTO & \textbf{IPO(ours)} \\
% \midrule
% hit rate &  & 0.3298 & 0.3191 & 0.3289 &  & \textbf{0.3485*} \\
%  \bottomrule
% \end{tabular}}
% }
% \label{tab:overall_search}
% \vspace{-8pt}
% \end{table}

\subsection{Online Performance}
\subsubsection{Online A/B Test}\label{sec:short_ab}
A two-week A/B test is conducted in the "Guess What You Like" column of Taobao. After SerenGPT is trained offline, it is deployed online following Section~\ref{sec:downstream} and remains fixed for two weeks, with low training and update costs. The recall and pre-ranking models in the serendipity channel are continuously trained and updated. The nearline cache update frequency is set to 24 hours. We compare two variants, SerenGPT-SFT and SerenGPT-IPO, with the online serendipity-enhanced baseline. Table~\ref{tab:short_ab} summarizes the average improvements of SerenGPT over baseline regarding serendipity, utility, and user engagement metrics. Since S-PVR and CTR are percentages, we use \textbf{pt} for absolute difference. For example, SerenGPT-IPO's +5.70pt in S-PVR means an increase from 18.33\% to 24.02\%, an improvement of 5.70\%.
% \begin{table}[h]
%     \vspace{-8pt}
%     \caption{Online improvement on serendipity metrics.}
%     \vspace{-8pt}
%     \centering
%     \scalebox{1}{
%     \setlength{\tabcolsep}{2mm}
%     {\begin{tabular}{c|ccc}
% \toprule
% Model & PVR & Clicks & Transaction Volume \\
% \midrule
% SerenGPT-SFT & +6.4\% & +33.97\% & +29.89\% \\
% SerenGPT-IPO & +6.4\% & +34.41\% & +30.66\% \\
%  \bottomrule
% \end{tabular}}
% }
% \label{tab:short_ab_seren}
% \vspace{-8pt}
% \end{table}
% 
\begin{table}[h]
    \vspace{-4pt}
    \caption{Online improvement of SerenGPT. Since S-PVR and CTR are percentages, we use percentage points (pt) for absolute improvements and relative improvement (\%) for others.}
    \vspace{-8pt}
    \centering
    \scalebox{0.87}{
    \setlength{\tabcolsep}{1.5mm}
    {\begin{tabular}{c|cccccc}
\toprule
% Model & S-PVR & S-Click & S-TV & CTR & TV & UV3 \\
% \midrule
% SerenGPT-SFT & +6.4\% & +33.97\% & +29.89\% & -0.41\% & -0.69\% & +0.54\% \\
% SerenGPT-IPO & +6.4\% & +34.41\% & +30.66\% & -0.20\% & -0.79\% & +0.25\% \\
Model & S-PVR & S-Click & S-TV & CTR & TV & UV3 \\
\midrule
SerenGPT-SFT & +5.68pt & +26.12\% & +24.58\% & -0.02pt & -0.65\% & +0.48\% \\
SerenGPT-IPO & +5.70pt & +29.56\% & +27.60\% & -0.01pt & -0.71\% & +0.14\% \\
 \bottomrule
\end{tabular}}
}
\label{tab:short_ab}
\vspace{-10pt}
\end{table}

Compared to the baseline, both variants of SerenGPT show significant improvements in serendipity metrics, such as S-PRV, S-Click, and transaction volume (S-TV). This indicates that SerenGPT effectively increases the proportion of serendipitous items in the final recommendations, resulting in more diverse recommendations. Moreover, these serendipitous items are not only displayed but also clicked on and purchased, demonstrating their ability to capture user interest. In addition, SerenGPT improves the user engagement metric UV3, indicating that users are more engaged. Its impact on overall utility metrics, such as CTR and total transaction volume (TV), is relatively minor. SerenGPT-IPO outperformed SerenGPT-SFT in serendipity, such as clicks and transactions, while maintaining comparable utility performance. This demonstrates that IPO can deliver serendipitous and engaging recommendations.
% \begin{table}[h]
%     \vspace{-8pt}
%     \caption{Improvement on utility and user experience metrics.}
%     \vspace{-8pt}
%     \centering
%     \scalebox{1}{
%     \setlength{\tabcolsep}{2mm}
%     {\begin{tabular}{c|ccc}
% \toprule
% Model & CTR & Transaction Volume & UV3 \\
% \midrule
% SerenGPT-SFT & -0.02\% & -0.69\% & +0.54\% \\
% SerenGPT-IPO & -0.01\% & -0.79\% & +0.25\% \\
%  \bottomrule
% \end{tabular}}
% }
% \label{tab:short_ab_util}
% \vspace{-8pt}
% \end{table}
\subsubsection{Long-term Impact of Serendipity}
Our serendipity model now serves the primary traffic in the "Guess What You Like" on Taobao, significantly improving both serendipity and user experience. To investigate the long-term effects of serendipity in large-scale industrial RSs, we maintain a small traffic group without any serendipity enhancements and evaluate the impact of serendipity for \textbf{four months}. Comparisons between the baseline (without any serendipity enhancements) and serendipity model on serendipity PVR (S-PVR), total transaction volume (TV), CTR, and UV3 are shown in Figure~\ref{fig:long_ab}. Note that we apply min-max normalization to the y-axis of TV, CTR, and UV3 to protect sensitive data. For example, if the original data range is 1,000-5,000, it is scaled to 0-1. This only modifies the y-axis without altering trends and relative changes.
% More metrics are provided in Appendix~\ref{app:long_ab}.
\begin{figure}
    \centering
    % \vspace{-10pt}
    \includegraphics[trim={0.3cm 0
    0 0},clip,width=0.48\textwidth]{imgs/online_metrics.pdf}
    \vspace{-20pt}
    \caption{Long-term impact of serendipity.}
    \vspace{-10pt}
    \label{fig:long_ab}
\end{figure}


Firstly, serendipity model significantly increases the proportion of serendipitous items in recommendations. Over four months, the average \textbf{serendipity PVR (S-PVR) rises from 3.35\% to 20.71\%}, with serendipity-related \textbf{clicks} and \textbf{transaction volumes} achieving substantial increases of \textbf{819.9\%} and \textbf{969.6\%}, respectively. Secondly, the total transaction volume (TV) for all items remains stable, with an average increase of \textbf{0.98\%}. Additionally, CTR increases by 0.05 percentage points. Lastly, there is a significant improvement in user engagement, as reflected by a \textbf{3.04\%} average increase in \textbf{UV3}. 

The above results demonstrate that enhancing serendipity breaks the filter bubble of homogeneous recommendation and effectively improves user engagement while also boosting CTR and revenue. It is worth noting that improvements here differ from those in Section~\ref{sec:short_ab} because multiple serendipity strategies are employed simultaneously online, contributing to larger improvements. In contrast, Section~\ref{sec:short_ab} focuses solely on the impact of SerenGPT.

\subsection{In-depth Analysis}

% Ablation exp table
% \begin{table*}[h]

%     \vspace{-10pt}
%     \caption{Ablation }
%     \vspace{-8pt}
%     \centering
%     \scalebox{1}{
%     \setlength{\tabcolsep}{1.5mm}
%     {\begin{tabular}{ccccccc|cccccc}
% \toprule
% \multirow{2.5}{*}{Method}&\multicolumn{3}{c|}{@1}&\multicolumn{3}{c|}{@3}&\multicolumn{3}{c|}{@5}&\multicolumn{3}{c}{@10}\\ \cmidrule{2-13}
% &MAP&NDCG&\multicolumn{1}{c|}{HR}&MAP&NDCG&HR&MAP&NDCG&\multicolumn{1}{c|}{HR}&MAP&NDCG&HR\\ \midrule

%  no\_user\_image &  0.2513 &  0.2513 &  \multicolumn{1}{c|}{0.2513} &  0.2933 & 0.3031 & 0.4148 & 0.3065 & 0.3262 & \multicolumn{1}{c|}{0.5042} & 0.3195 & 0.3558 & 0.6450 \\
% no\_revelance & 0.2619 & 0.2619 & \multicolumn{1}{c|}{0.2619} & 0.2998 & 0.3086 & 0.4307 & 0.3110 & 0.3284 & \multicolumn{1}{c|}{0.5193} & 0.3224 & 0.3542 & 0.6313 \\
% no\_CDI\_pair & 0.2869 & 0.2869 & \multicolumn{1}{c|}{0.2869} & 0.3223 & 0.3303 & 0.4534 & 0.3317 & 0.3470 & \multicolumn{1}{c|}{0.5299} & 0.3397 & 0.3653 & 0.6101 \\
% no\_CDI & 0.2445 & 0.2445 & \multicolumn{1}{c|}{0.2445} & 0.2840 & 0.2924 & 0.4103 & 0.2960 & 0.3141 & \multicolumn{1}{c|}{0.4996} & 0.3066 & 0.3377 & 0.6101 \\
% no\_ipo(sft) & 0.2695 & 0.2695 & \multicolumn{1}{c|}{0.2695} & 0.3117 & 0.3216 & 0.4640 & 0.3224 & 0.3409 & \multicolumn{1}{c|}{0.5496} & 0.3335 & 0.3663 & 0.6616 \\
% dpo & 0.2513 & 0.2513 & \multicolumn{1}{c|}{0.2513} & 0.2926 & 0.3027 & 0.4239 & 0.3031 & 0.3210 & \multicolumn{1}{c|}{0.5042} & 0.3144 & 0.3459 & 0.6192 \\
% \textbf{SerenGPT-IPO} & 0.2740 & 0.2740 & \multicolumn{1}{c|}{0.2740} & 0.3141 & 0.3231 & 0.4481 & 0.3263 & 0.3445 & \multicolumn{1}{c|}{0.5375} & 0.3366 & 0.3680 & 0.6488 \\ 

% \bottomrule
% \end{tabular}}
%     }

% \label{tab:Ablation}
% \vspace{-5pt}
% \end{table*}

\subsubsection{Ablation Study}
To investigate the effectiveness of each module, we design several variants of SerenGPT. First, we remove some key modules: \textbf{w/o CP} excludes cognitive profiling from the prompt. \textbf{w/o CDI-D} and \textbf{w/o CDI-P} remove the denoising and pairing components of CDI, respectively, and \textbf{w/o CDI} removes both. Note that generating enough preference pairs is challenging without CDI pair, so w/o CDI pair employs KTO training~\cite{ethayarajh2024kto} that doesn't require pairs. \textbf{w/o IPO} discards IPO training, retaining only SFT on a subset of the data. \textbf{w/ $\alpha=0$} sets the weight $\alpha$ of SFT loss in Eq.~\eqref{eq:final_ipo} to 0. Additionally, we replace IPO with SFT and DPO, resulting in \textbf{w/ SFT} and \textbf{w/ DPO} variants.
\begin{table}[h]

    \vspace{-5pt}
    \caption{Ablation study of SerenGPT. }
    \vspace{-8pt}
    \centering
    \scalebox{0.9}{
    \setlength{\tabcolsep}{1.5mm}
    {\begin{tabular}{ccc|cc|cc}
\toprule
 \multirow{2}{*}{Method} & \multicolumn{2}{c|}{MAP$_{seren}$} & \multicolumn{2}{c|}{NDCG$_{seren}$} & \multicolumn{2}{c}{HR$_{seren}$} \\
 \cmidrule{2-7}
 & @3 & @10 & @3 & @10 & @3 & @10 \\
 \midrule
w/o CP & 0.2933 & 0.3195 & 0.3031 & 0.3558 & 0.4148 & 0.6450 \\
w/o CDI & 0.2840 & 0.3066 & 0.2924 & 0.3377 & 0.4103 & 0.6101 \\
w/o CDI-D & 0.2998 & 0.3224 & 0.3086 & 0.3542 & 0.4307 & 0.6313 \\
w/o CDI-P & \underline{0.3223} & \underline{0.3397} & \underline{0.3303} & 0.3653 & 0.4534 & 0.6101 \\
w/o IPO & 0.2198 & 0.2476 & 0.2312 & 0.2866 & 0.3316 & 0.5632 \\
\midrule
w/ $\alpha=0$ & 0.2887 & 0.3134 & 0.2969 & 0.3460 & 0.4080 & 0.6291 \\
w/ SFT & 0.3117 & 0.3335 & 0.3216 & \underline{0.3663} & \textbf{0.4640} & \underline{0.6616} \\
w/ DPO & 0.2926 & 0.3144 & 0.3027 & 0.3459 & 0.4239 & 0.6192 \\
\midrule
\textbf{SerenGPT} & \textbf{0.3260} & \textbf{0.3509} & \textbf{0.3353} & \textbf{0.3847} & \underline{0.4625} & \textbf{0.6760}\\ 
\bottomrule
\end{tabular}}
    }

\label{tab:Ablation}
\vspace{-5pt}
\end{table}

% \begin{table}[h]

%     \vspace{-5pt}
%     \caption{Ablation study of SerenGPT. }
%     \vspace{-8pt}
%     \centering
%     \scalebox{0.88}{
%     \setlength{\tabcolsep}{1.5mm}
%     {\begin{tabular}{ccc|cc|cc}
% \toprule
%  \multirow{2}{*}{Method} & \multicolumn{2}{c|}{MAP$_{seren}$} & \multicolumn{2}{c|}{NDCG$_{seren}$} & \multicolumn{2}{c}{NDCG$_{seren}$} \\
%  \cmidrule{2-7}
%  & @1 & @5 & @1 & @5 & @1 & @5 \\
%  \midrule
% w/o CP & 0.2513 & 0.3065 & 0.2513 & 0.3262 & 0.2513 & 0.5042 \\
% w/o CDI & 0.2445 & 0.2960 & 0.2445 & 0.3141 & 0.2445 & 0.4996 \\
% w/o CDI denoise & 0.2619 & 0.3110 & 0.2619 & 0.3284 & 0.2619 & 0.5193 \\
% w/o CDI pair & \underline{0.2860} & \underline{0.3317} & \underline{0.2860} & \underline{0.3470} & \underline{0.2860} & 0.5299 \\
% w/o IPO & 0.1771 & 0.2327 & 0.1771 & 0.2530 & 0.1771 & 0.4148 \\
% \midrule
% w/ SFT & 0.2695 & 0.3224 & 0.2695 & 0.3409 & 0.2695 & \underline{0.5496} \\
% w/ DPO & 0.2513 & 0.3031 & 0.2513 & 0.3210 & 0.2513 & 0.5042 \\
% \midrule
% SerenGPT & \textbf{0.2861} & \textbf{0.3395} & \textbf{0.2861} & \textbf{0.3587} & \textbf{0.2861} & \textbf{0.5556}\\ 
% \bottomrule
% \end{tabular}}
%     }

% \label{tab:Ablation}
% \vspace{-5pt}
% \end{table}

Due to page limits, we present representative results in Table~\ref{tab:Ablation}, with a full table in Appendix~\ref{app:ablation}. Removing any component leads to performance degradation, demonstrating the importance of each module. Notably, removing IPO causes the largest drop, highlighting the critical role of preference alignment. The significant decline in w/o CDI further confirms that our data intervention measures effectively enhance data quality. Lastly, replacing IPO with DPO or SFT reduces performance and generates more homogeneous content, whereas IPO increases diversity, as validated in Appendix~\ref{app:diversity}.

\subsubsection{Nearline Cache} 
Nearline adaptation is a critical step for deploying LLMs online, so this section explores the impact of nearline caching frequency on model performance and resource consumption. During a two-week online test, the caching frequency is set to \textbf{6h}, \textbf{12h}, and \textbf{24h}, with performance on different types of metrics (S-PVR, S-Click, CTR, TV, and UV3) and resource usage (\textbf{QPS}) shown in Figure~\ref{fig:cache}. Here, QPS refers to queries per second, with higher QPS indicating more requests and greater resource usage. To facilitate plotting and protect sensitive data, all metrics are normalized to 1 based on their maximum values. As shown in Figure~\ref{fig:cache}, a higher cache frequency leads to better serendipity (S-PVR, S-Click), but it also results in greater resource consumption. The cache frequency has little impact on the user experience metric UV3 and only a small effect on utility. However, even with a 24-hour update frequency, the improvement in serendipity remains significant. Therefore, the caching frequency should be adjusted based on available resources to strike a balance between performance and efficiency.

\begin{figure}
    \centering
    \vspace{-10pt}
    \includegraphics[trim={0.3cm 0
    0 0},clip,width=0.48\textwidth]{imgs/freq_exp.pdf}
    \vspace{-20pt}
    \caption{Impact of the Nearline caching frequency .}
    \vspace{-10pt}
    \label{fig:cache}
\end{figure}


% \textit{add the figure and other observations when experiments are over}

% \subsubsection{Compatibility Analysis}

% \subsubsection{Case Study} profile+user history behaviors+ serendipity item


\section{Conclusion}
This work addresses the filter bubble problem in RSs by proposing  SERAL. It comprises three stages: Cognition Profile Generation to compress user behavior into multi-level profiles, SerenGPT Alignment to align LLM-based serendipity predictions with human preferences, and Nearline Adaptation for efficient industrial deployment. Online experiments show it improves serendipity PVR, clicks, and transactions by 5.7\%, 29.56\%, and 27.6\%, enhancing user experience without much impact on revenue. Fully deployed in Taobaoâ€™s "Guess What You Like" section, it shows LLMs' potential to break the filter bubble and elevate user satisfaction in RSs.