\vspace{-5pt}
\section{Introduction}

% Introduce filter bubble

% - cause: the feedback loop

% - harm: user boredom, decrease user satisfaction 

% - possible solution: Only increasing diversity and novelty can mitigate homogenization, but it may also introduce irrelevant content, harming the user experience. A more effective approach is serendipity recommendation, aiming to recommend items that provide users with unexpected yet appealing experiences. A serendipitous item should exceed users' expectations while still capturing their interest, encompassing factors like unexpectedness, novelty, diversity, and relevance.
% \newline

Nowadays, recommender systems (RSs) play an indispensable role in alleviating information overload and delivering personalized recommendations~\cite{fu2023deep,li2023breaking}. These systems predominantly rely on deep learning algorithms trained on users' historical interaction data and emphasize user preferences~\cite{zhou2018deep,xi2022multi,qin2020user}. However, due to the \textit{feedback loop} phenomenon, the content users encounter is largely determined by the system's prior recommendations, in turn narrowing down the training data that RSs can utilize. In other words, RSs are trained on data biased by its recommendations~\cite{li2023breaking,krauth2022breaking,mansoury2020feedback,chen2023bias}, as shown in Figure~\ref{fig:compare_intro} (a). The feedback loop, coupled with an over-specialization in user recent preferences, drives the system's recommendations and user behavior to converge around a narrow subset of homogeneous content, commonly called the \textit{filter bubble} effect~\cite{fu2023deep,aridor2020deconstructing,nguyen2014exploring}. As a result, RSs will persistently offer users familiar, homogeneous content, leading to user boredom and significantly diminishing user satisfaction~\cite{fu2023deep,niu2021luckyfind,niu2018adaptive}.

\begin{figure}
    \centering
    \vspace{-5pt}
    \includegraphics[trim={0.3cm 0.5cm
    0 0},clip,width=0.5\textwidth]{imgs/seren-intro-2.pdf}
    \vspace{-20pt}
    \caption{The comparison between (a) traditional recommender system and (b) our serendipity recommender system.}
    \vspace{-15pt}
    \label{fig:compare_intro}
\end{figure}

To address the challenges posed by the filter bubble, serendipity recommendation is advocated by many researchers, which aims to recommend items that provide users with unexpected yet appealing experiences~\cite{fu2023deep,ziarani2021serendipity,kotkov2016survey}. A serendipitous item should exceed users' expectations and counteract content homogenization while still capturing their interest,  which encompasses two key factors:  unexpectedness and relevance~\cite{fu2023deep,kotkov2024overview}. In recent years, serendipity recommendations have predominantly been driven by deep learning techniques~\cite{fu2023deep,fu2023wisdom,li2020directional,li2020purs,zhang2021snpr,wang2023industrial,cheng2017learning,liu2023personalized}, and have achieved promising results. However, due to the scarcity of serendipity data, which often relies on user surveys, they have to adopt smaller models and depend on biased recommendation data for augmentation. This may reinforce feedback loops, making it challenging to burst filter bubbles and accurately identify serendipitous items.


% To address the challenges posed by the filter bubble, serendipity recommendation is advocated by many researchers, which aims to recommend items that provide users with unexpected yet appealing experiences~\cite{fu2023deep,ziarani2021serendipity,kotkov2016survey}. A serendipitous item should exceed users' expectations and counteract content homogenization while still capturing their interest, encompassing factors like unexpectedness, novelty, diversity, and relevance~\cite{fu2023deep,kotkov2024overview}. In recent years, serendipity recommendations have predominantly been driven by deep learning techniques, and these methods can be classified into three categories: pre-processing, in-processing, and post-processing approaches~\cite{fu2023deep}. Pre-processing approaches typically involve data pre-preprocessing, such as engineering serendipity features~\cite{li2019haes,kim2019sequential}. In-processing algorithms capture serendipity during model training, aiming to learn serendipity representation based on users’ feedback~\cite{fu2023wisdom,li2020directional,li2020purs,zhang2021snpr,wang2023industrial}. Post-processing methods re-rank accuracy-oriented lists to generate serendipity-oriented recommendations~\cite{cheng2017learning,liu2023personalized}. Although these methods have achieved promising results, they rely on training data from within RSs and suffer from limited model capacity. This makes it challenging for them to overcome the feedback loop and accurately identify serendipitous items.

% DL-based Serendipity Recommendations~\cite{fu2023deep}

% - Categories: Pre-processing, in-processing, post-processing.

% - Issue: These methods rely on internal recommender system data, and the model's capacity remains limited.
% \newline

Recently, large language models (LLMs) 
have showcased remarkable proficiency in various domains, strikingly close to human-level performance~\cite{bubeck2023sparks,achiam2023gpt}. Notably, LLMs possess extensive world knowledge and exhibit remarkable comprehension and reasoning abilities. This enables them to incorporate external knowledge and intervention into RSs, break the feedback loop, and identify serendipitous items effectively, as shown in Figure~\ref{fig:compare_intro} (b). Moreover, LLM-based recommenders demonstrate sample efficiency and can attain superior performance with limited training data~\cite{lin2025large}. Preliminary work has attempted to apply LLMs to serendipity recommendations and achieve considerable results~\cite{tokutake2024can,fu2024art}, but they still suffer from the following issues, which limit their effectiveness and deployment.

% However, preliminary work~\cite{tokutake2024can,fu2024art} finds that while LLMs' performance is comparable to baselines, their serendipity assessments do not have a high agreement rate with humans. Therefore, we aim to improve LLMs' ability to recommend serendipitous items by addressing the issues below.

\textit{Firstly, serendipity judgments from LLMs are not aligned with human assessments.} Preliminary work leverages LLMs to evaluate item serendipity in a zero-shot manner and finds LLMs' judgments are not well-aligned with human assessments~\cite{tokutake2024can}. Serendipity relies heavily on personal context -- what feels serendipitous to one user may not to another~\cite{kotkov2024overview}. LLMs without fine-tuning do not develop a deep understanding of individual user preferences. Moreover, human perceptions of serendipity involve relevance and unexpectedness~\cite{fu2023deep}. Prompts may not be sufficient to guide LLMs toward accurately identifying the nuanced and subjective nature of serendipity because they offer limited control over how the model interprets unexpectedness and relevance, leading to misalignment with human expectations. Therefore, without dedicated alignment, LLMs may lack the tailored understanding of users and an accurate grasp of serendipity to align with human judgments.

\textit{Secondly, the length of user history that LLMs can utilize is limited, which poses a challenge in achieving a deep understanding of users.} SOTA recommendation models show that long user sequences are crucial for understanding user preferences~\cite{hou2024cross,si2024twin,feng2024context}. Similarly, serendipity recommendation relies on sufficient user history to identify serendipity, as it hinges on a nuanced understanding of an individual’s unique interests, surprises, and discoveries. However, LLMs struggle to comprehend long user behavior sequences, even when those sequences fall well within their context window~\cite{lin2024rella}. Studies exploring LLMs for serendipity also indicate their performance peaks with medium-length user sequences~\cite{tokutake2024can}. 
Given that user behavior histories in RSs are often considerably longer, even reaching 10,000~\cite{hou2024cross,si2024twin}, LLMs' inability to incorporate long sequences brings an insufficient understanding of the user’s nuanced preferences, obstructing them from identifying serendipitous items.

% \textit{Secondly, the length of user history that LLMs can utilize is limited, which poses a challenge in achieving a deep understanding of users.} Serendipity hinges on a nuanced grasp of an individual’s unique interests, surprises, and discoveries -- areas where LLMs fall short without sufficient personalized context or interactions. However, previous studies reveal that LLMs struggle to comprehend long user behavior sequences, even when those sequences fall well within their context window~\cite{lin2024rella}. Studies exploring LLMs for serendipity indicate their performance peaks with medium-length user sequences~\cite{tokutake2024can}.  Given that user behavior histories in RSs are often considerably longer, LLMs' inability to incorporate long sequences results in an insufficient understanding of the user’s nuanced preferences. Consequently, this limitation hinders their capacity to predict serendipitous items accurately.

\textit{Lastly, the current LLM-based serendipity recommendation poses challenges for online serving, making it difficult to address filter bubble issues in industrial RSs.} In existing approaches~\cite{tokutake2024can,fu2024art}, LLMs must assess each item's serendipity based on users' behavior sequences. However, industrial RSs handle vast numbers of users and items. Even if filtering down candidate items, its cost remains substantial. Furthermore, these methods necessitate high-latency online inference with LLMs, which fails to meet the latency requirements of industrial systems within hundreds of milliseconds~\cite{xi2023device}. Thus, deploying LLM-based serendipity recommendations efficiently and efficiently within industrial RSs remains a pivotal issue.


% - LLMs' serendipity judgments are not aligned with human assessments. 

% - The length of user history that LLMs can utilize is limited~\cite{tokutake2024can}. 

% - The current approach, which directly uses LLMs to assess an item's serendipity, poses challenges for online serving, making it difficult to solve filter bubble issues in industrial RSs.
% \newline

Therefore, we propose \underline{Se}rendipity \underline{R}ecommendations with \underline{A}ligned \underline{L}LMs (\textit{SERAL}). First, \textbf{Cognition Profile Generation} mimics human cognitive processes and compresses user information and long behavior sequences into concise, multi-level cognitive profiles, \eg, static, short-term, and long-term profiles. This prevents LLMs from handling long behavior sequences. Next, \textbf{SerenGPT Alignment} trains an LLM-based recommender, SerenGPT, to generate next serendipity items and aligns its serendipity judgments with human assessments through preference alignment algorithm IPO~\cite{azar2024general}. During the training data selection, we incorporate rich external information, including the open-world knowledge of LLMs and collaborative data intervention (CDI) between LLMs and humans, to break the feedback loop from biased RSs data. Lastly, in \textbf{Nearline Adaptation}, we design a nearline serendipity channel to produce and cache high-quality candidate items with SerenGPT. Then, cached candidates are incorporated into a traditional multi-stage recommendation pipeline (online personalized channel) at the ranking stage, avoiding the efficiency issues of LLMs in online serving. Our contributions can be summarized as follows:
\begin{itemize}
    \item We identify LLMs' advantages to detect serendipitous items and propose \textbf{SERAL}. To the best of our knowledge, this is the \textit{first work that utilizes and deploys LLMs for serendipity recommendation, addressing the filter bubble issue in industrial RSs}.
    % \item We devise three stages to enhance LLMs' ability to identify serendipity and feasibility to deployment, with \textbf{Congnition Profile Generation} to compress long user behaviors into multi-level cognitive profiles, \textbf{SerenGPT Alignment} to align the LLM-based serendipity recommender with human assessments via DPO, and \textbf{Nearline Adaptation} stage to incorporate SerenGPT into traditional multi-stage RSs efficiently.
    \item We devise three stages to enhance LLMs' ability to identify serendipity and feasibility to deployment, with Cognition Profile Generation to overcome LLMs' limitation in handling long sequences, SerenGPT Alignment to align LLMs with human serendipity judgments via IPO, and Nearline Adaptation stage to address deployment challenges.
    \item SERAL has been \textbf{fully deployed online} and improves serendipity exposure ratio (PVR), clicks, and transactions by 5.7\%, 29.56\%, and 27.6\%, without much impact on overall revenue. 
    \item Through \textbf{long-term online experiments}, we first validate that enhancing serendipity in large-scale RSs can notably improve user experience (3.04\% improvement in UV3) and even increase revenue (0.98\% increase in transaction volume).
\end{itemize}










