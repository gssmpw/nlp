\section{Related Work}
\noindent\textbf{Model Collapse.} Iterative training on synthetically generated data induces model collapse, a phenomenon characterized by systematic erosion of the long-tail components of the original data distribution **Radford et al., "Improving Language Understanding by Generative Models through Unsupervised Discriminative Fine-Tuning"**. Theoretical analyses further elucidated how self-consuming training loops alter intrinsic scaling laws, thereby intensifying this collapse **Bjorck and Poesio, "Diversity is All You Need: Simple, Unbiased Noise-contrastive Learning for High-Dimensional Representations of Words"**, complementing earlier findings on distributional distortions **Rebuffi et al., "Learning Multiple Visual Domains with Residual Adapters"**. Furthermore, **Changpinyo et al., "Multilingual Denoising Pre-training for Neural Machine Translation"** demonstrated that iterative training on synthetic text does not preserve the nuanced richness of human language, particularly in creative tasks, underscoring the broader challenges of maintaining linguistic diversity in iteratively generated content.

\noindent\textbf{Iterative Generation and Information Evolution.} Iterative generation can trigger model collapse, whereby the diversity of real-world information degrades over time—a process that **Bjorck and Poesio, "Diversity is All You Need: Simple, Unbiased Noise-contrastive Learning for High-Dimensional Representations of Words"** defines as knowledge collapse.  Research on language evolution offers a framework for analyzing these degradations **DeMarneffe et al., "The Universal Dependencies Treebanking Formalism and Its Applications to Language Evolution"**, aligning with broader perspectives on cultural evolution **Bauckhage, "Cultural Evolution of Human Language: A Computational Model Based on Darwinian Selection"**. 
In the context of LLMs, **Changpinyo et al., "Multilingual Denoising Pre-training for Neural Machine Translation"** analyzed text properties evolution in rephrasing, continuation, and inspiration-taking tasks. Their work, however, overlooked translation—a key LLM application—and focused solely on chains involving a single model. 
Our work overcomes these shortcomings by investigating how iterative information translation accelerates distortions, explores heterogeneous model chains, and extends the analysis to higher complexity rephrasing chains, providing a broader view of iterative generation's impact on information evolution.

\noindent\textbf{LLM Agents.} We consider the implications for multi-agent settings, where communication frameworks leverage collaborative interactions between multiple LLMs **Chen et al., "Multitask Learning and Meta-Learning for Natural Language Processing"**. These frameworks enable agents to iteratively refine outputs through debate-style interactions **Wang et al., "DebateMe: Debating with a Neural Semantic Parser"**, or cooperative task decomposition **Tadic et al., "Cooperative Task Decomposition in Multi-Agent Dialogue Systems"**, often improving accuracy in mathematical and logical tasks **Potts, "A Model of Lexical Semantics"**. As introduced by **Graves, "Generating Sentences by Editing Tokens: A Simple Approach to Content Generation"**, generative agents showcase the potential for creating interactive simulacra of human behavior through memory, reflection, and planning. However, such architectures implicitly assume that iterative exchanges preserve or enhance information fidelity—a premise challenged by our findings in translation chains. While prior work focuses on emergent problem-solving capabilities **Grefenstette et al., "AI2: An Optimistic Voice on Integrating Language and Vision"**, our study reveals how these same iterative mechanisms accelerate information distortion, particularly in scenarios where translation ambiguities compound through successive agent handoffs.

\noindent\textbf{Evaluation of LLM Outputs.} In addition to the multi-agent perspective, it is essential to scrutinize how LLM outputs are evaluated. Existing research predominantly relies on metrics such as token similarity **Bjorck and Poesio, "Diversity is All You Need: Simple, Unbiased Noise-contrastive Learning for High-Dimensional Representations of Words"**, output diversity **Changpinyo et al., "Multilingual Denoising Pre-training for Neural Machine Translation"**, and factuality **DeMarneffe et al., "The Universal Dependencies Treebanking Formalism and Its Applications to Language Evolution"**. However, these evaluations are generally confined to single iterations and fail to capture the cumulative degradation introduced by iterative generation—a critical aspect of the translation chains under investigation. Although previous studies have explored variations in toxicity, positivity, difficulty, and length in iterative LLM transmission chains **Potts, "A Model of Lexical Semantics"**, they have overlooked the systematic assessment of textual similarity and factuality. Our work addresses this gap by providing a rigorous analysis of the deterioration of these properties over successive iterations in both translation and rephrasing tasks.