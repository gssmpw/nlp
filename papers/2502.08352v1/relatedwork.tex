\section{Related Works}
\label{related_works}
In this section, we review traditional 3D reconstruction methods from satellite images relevant to our research and emerging methods that leverage volume rendering for reconstruction.

\subsection{3D Reconstruction Using Satellite Images}
Reconstructing 3D surface models from satellite images has been a longstanding challenge\cite{duan2016towards,facciolo2017automatic,zhao2021double,stucker2022resdepth,gao2023general}. Traditional reconstruction pipelines, mainly dominated by stereo matching, focus on pair-view reconstruction, consisting of four steps: stereo rectification, stereo matching, triangulation, and multi-view DSM fusion\cite{zhao2023review}. Stereo matching or disparity estimation is the process of finding the pixels in the different views that correspond to the same 3D point in the scene\cite{OROZCO2016121}. As a representative of global stereo matching (GSM), Kolmogorov and Zabih\cite{kolmogorov2001computing} introduced an energy minimization formulation of the correspondence problem with occlusions and a fast graph-cut-based approximation algorithm. However, GSM is not suitable for processing large-scale satellite images uniformly, which brings considerable computation burden. Semi-global stereo matching (SGM)\cite{hirschmuller2005accurate,hirschmuller2007stereo} uses an efficient one-dimensional path aggregation method to compute the minimum of the energy function, replacing the two-dimensional minimization algorithm used in GSM. Furthermore, the variations of SGM further improved accuracy and efficiency, such as MGM\cite{Facciolo2015MGMAS}, SGBM\cite{lastilla2019}. Ghuffar\cite{ghuffar2016satellite} applied the SGM to generate DSM from satellite image space and georeferenced voxel space avoiding stereo rectification and triangulation. Dumas \textit{et al.}\cite{dumas2022improving} combined semantic segmentation with SGM, using semantic guidance for pixels to stop matching paths at semantic boundaries, effectively optimizing the disparity transition between buildings and other areas. Yang \textit{et al.}\cite{yang2020novel} proposed semi-global and block matching, using adaptive block matching instead of the dense matching strategy. Barnes \textit{et al.}\cite{barnes2009patchmatch} proposed the PatchMatch method, which created a support window for every pixel in the reference image and used the slide window method to calculate the matching cost. He \textit{et al.}\cite{he2019learing} introduced a multi-support-patches extraction block to extract multispectral central-surround information. Bleyer \textit{et al.}\cite{bleyer2011patchmatch} improved the fronto-parallel window to slanted support window, which extended the matching accuracy to the sub-pixel level. Notably, S2P\cite{franchis2014pipeline,franchis2014refine,franchis2014rect} plays an important role in satellite image matching as a classical method. It approximated satellite images using a pinhole camera model, allowing the application of traditional reconstruction pipelines. Modern deep learning methods have brought stereo matching into a new stage. PSMNet\cite{chang2018pyramid} used spatial pyramid pooling and 3D CNN to aggregate context and regularize cost volume. Yang \textit{et al.}\cite{yang2019hsm} proposed a hierarchical stereo matching architecture to achieve high-res matching through a coarse-to-fine strategy. HMSM-Net\cite{he2022hmsmnet} utilized an end-to-end disparity learning model using low-level spatial features to guide the cost volume fusion of high-level features, and achieved good results in occluded and repeated areas. Sat-MVSF\cite{gao2023general} proposed a uniform framework for multi-view stereo (MVS) including pre-processing, an MVS network, and post-processing, which can generalize in different images.

Although traditional stereo matching reconstruction methods are well-established, they still involve complex workflows and require extensive manual intervention. Additionally, factors like lighting, style, and other image parameters continue to hinder the reconstruction quality of traditional approaches. These methods often rely on stereo image pairs to recover DSM and suffer from insufficient geometric accuracy. Multi-view information should be considered to achieve finer model representations.

\subsection{Neural Implicit Representations}
Neural implicit representations have garnered significant attention in recent years for 3D space representation and reconstruction\cite{mildenhall2021nerf}. The core idea of this approach is to use neural networks as continuous functions, embedding geometric and appearance information implicitly into a high-dimensional representation space. Compared to traditional discrete grid-based 3D representations, implicit representations can continuously describe scenes, offering fine details in higher resolution.

In novel view synthesis, NeRF\cite{mildenhall2021nerf} has demonstrated impressive results by introducing positional encoding, which maps three-dimensional space into the frequency domain, enhancing spatial representation capabilities. Mip-NeRF\cite{barron2021mipnerf} further employed integrated positional encoding and modelling the frequency domain projection of a spatial Gaussian distribution at the sampling positions through the view frustum that intersects the pixels. This enhancement increases the sensitivity to depth and minimises distortion. NeRF++\cite{kaizhang2020} models the scene as a unit sphere and applies inverted sphere parameterization to coordinates outside the unit sphere. NeRF-W\cite{martin2021nerfw} introduced feature vectors into the MLP to learn the colour styles of training images and incorporates weighting information, with a focus on learning static objects. URF\cite{rematas2022urban} introduced learnable scene exposure vectors and computes the final synthesized color based on affine transformations. To accelerate training, \cite{yu2022plenoxel,mueller2022instant,sun2022dvgo} introduces a voxel-grid hybrid structure to explicitly represent 3D information, and the features of sampled points are obtained through interpolation. However, the volumetric density in the radiance field cannot be perfectly aligned with the surface, making it challenging to accurately represent geometry.

In 3D reconstruction, surface rendering methods such as IDR\cite{yariv2020multiview} and DVR\cite{Niemeyer2019DifferentiableVR} define radiance directly on the surface and use implicit gradients for rendering. However, these approaches require input pixel-aligned masks. Volume rendering methods like \cite{Oechsle2021unisurf,yariv2021volsdf,wang2021neus}, directly using the photometric as supervision, can reconstruct accurate geometry. UNISURF\cite{Oechsle2021unisurf} derived surface positions of objects based on the zero-level set of SDF, generating realistic views by rendering colors and normals of points intersecting rays with the surface. VolSDF\cite{yariv2021volsdf} assumed maximum volumetric density at the surface, linking volumetric density and SDF values and using an approximation method for sampling. NeuS\cite{wang2021neus} addressed the offset issue in the conversion between volumetric density and SDF, proposing an unbiased transformation function that aligns volumetric density at its maximum with the surface. Sun \textit{et al.}\cite{Sun2022Neural3R} proposed a hybrid voxel representation and surface-guided sampling strategy, accurately reconstructing geometry by constraining the sampling range. NeuS2\cite{Wang2022NeuS2} combines NGP\cite{mueller2022instant} with NeuS to achieve geometric reconstruction of dynamic human bodies. Neuralangelo\cite{li2023neuralangelo} improves the issue of local interpolation grids lacking global smoothness by using numerical gradients to compute higher-order interpolation derivatives. Moreover, Voxurf\cite{wu2022voxurf} proposed a voxel-based 3D surface reconstruction method, acquiring a faster convergence speed than the pure MLP and hybrid representation methods.

There have already been some attempts to use satellite imagery as training input. S-NeRF\cite{kangle2021dsnerf} incorporated the direction of sunlight into the MLP, aiming to decompose surface albedo and ambient light to reconstruct the true color. Sat-NeRF\cite{mari2022sat} focused on the uncertainty of dynamic objects in the scene, reducing the view synthesis artifacts caused by these dynamic objects. EO-NeRF\cite{Mari_2023_eo} leveraged shadow information for geometric inference, ensuring that the shadows cast by buildings align with the scene's geometry. SUNDIAL\cite{behari2024sundial} precisely estimated lighting through secondary shadow ray transmission and introduced geometric regularization to optimize scene geometry jointly. During training, it simultaneously estimates the sun's direction to enhance the accuracy and robustness of decomposing the scene's physical properties. Sat-Mesh\cite{qu_sat-mesh_2023} leveraged photo consistency constraints to ensure that the textures in synthesized views are consistent with those at the same locations in the training images. This aids the model in learning accurate and plausible geometry. Sat-NGP\cite{billouard2024satngp} was the first to apply hash grids to satellite image reconstruction, but it was limited to novel view synthesis and DSM generation, unable to reconstruct complete surface models. Although the methods mentioned above consider lighting, the limited number and constrained angles of view make reconstructing complex scenes a significant challenge. By directly constraining the geometry, we can achieve better reconstruction results. Thus, we introduce new regularization terms to enhance the reconstruction result.
% 神经隐式表示近年来在三维空间的表示和重建中得到了广泛的关注。这种方法的核心思想是利用神经网络作为连续函数，将几何和外观信息隐式地嵌入到高维的表示空间中。与传统的基于离散网格的三维表示相比，隐式表示能够以连续的方式描述场景，从而具备更高的分辨率和更强的表达能力。
% 在新视图合成上，nerf展示了惊艳的结果，其引入的位置编码将三维空间编码入频率域，提高了空间表示能力。Mip-nerf将位置编码改进为集成位置编码，并建模穿过像素的视锥在采样位置的空间高斯分布的频率域投影，提高了nerf对于深度的敏感程度，不易造成失真。nerf++将场景视作单位球，对单位球外的坐标使用了inverted sphere parametrization。Nerf-W向MLP中引入了特征向量，学习训练图像的色彩风格，并加入权重信息，着重学习静态物体。URF引入了可学习的场景曝光向量，并根据仿射变换计算最终合成的颜色。为了加快训练速度，xxx引入体素网格混合结构显式地表示三维信息，并通过插值的方法获得采样点特征。但是辐射场中的体密度不能完全与表面对齐，难以准确表示几何。
% 在三维重建方面，使用表面渲染的方法例如IDR，DVR，直接在表面定义radiance，并使用隐式梯度进行渲染，但需要输入像素对齐的mask。体渲染的方法例如xxx，能够直接使用图像光度监督，获得精确的几何。UNISURF基于SDF值来推导物体的表面位置，通过渲染射线上与表面相交的点的颜色和法线方向，生成逼真视图。VolSDF假设表面出体密度最大，将体密度和SDF值链接起来，使用逼近的方式进行采样。NeuS针对体密度和SDF之间的转换存在偏移的问题，提出了无偏性转换函数，使体密度最大处和表面对齐。孙等人提出了一种混合体素表示和表面引导的采样策略，通过限定采样范围准确重建几何。NeuS2将ngp和neus结合起来实现了对于动态人体的几何重建。neuralangelo使用numerical gradients计算高阶插值导数，改善了局部插值网格确实全局平滑的问题。Voxurf提出了一个基于体素的重建框架，有更快的收敛速度。
% 使用卫星影像作为训练输入已经有一些尝试。S-NeRF向MLP中加入太阳光照方向，目的是分解地表反照率和环境光，重建真实地面颜色。Sat-NeRF关注场景中的动态物体的不确定性，减轻动态物体产生的视图合成伪影。EO-NeRF利用阴影信息进行几何推断，确保建筑物的阴影和场景的几何形状相匹配。SUNDIAL通过二次阴影射线传输精确估计光照，并引入几何正则项来联合优化场景几何，并在训练中同步估计太阳方向，以提高分解场景物理属性的准确性和鲁棒性。sat-mesh利用photo consistency约束合成视图纹理相较于训练图像中的相同位置具有一致性，有利于模型学习合理的几何。尽管上述方法都将光照纳入考虑，但囿于视角角度受限且数量少的问题，重建复杂场景仍是一个不小的挑战。我们可以通过对几何的直接约束来获得更好的重建效果，因此引入新的正则化项。