\section{RELATED WORK}
\label{related_work}
\textbf{Multi-behavior Recommendation.}
Multi-behavior recommendation methods aim to leverage the multiple behavior signals of users to alleviate the issue of data sparsity in target behavior. Early multi-behavior methods extend matrix factorization to accommodate multi-behavior data \cite{mf1,mf2,mf3}, such as CMF \cite{cmf}. Besides, some other methods use auxiliary behavioral signals to design new sampling strategies \cite{bprh,mc-bpr,bpr_resolve, vals}. But none of them exploits deep behavioral information.

With the rise of deep learning \cite{chengqing2023multi,liang2023knowledge,li2024dual,dang2023uniform}, deep neural networks (DNNs) and graph convolutional networks (GCNs) have been proven to be more suitable approaches for multi-behavior fusion, as they can delve deeper into the multiple information of different behaviors. 
DNN-based methods often heavily utilize neural networks to extract information from user-item interactions, and the information is embedded within the representations. For example, DIPN \cite{dipn} and MATN \cite{matn} capture the implicit relationship between behaviors through attention mechanism. NMTR \cite{nmtr} treats all behaviors as prediction targets and transfers prediction results between behaviors. However, most DNN-based models fail to capture high-order relationships, resulting in poor performance. 

In contrast, GCN-based models can learn higher-order relations between users and items, making them the most popular methods for multi-behavior recommendation currently. This type of method mainly learns behavioral information through graph convolution and considers capturing user behavior patterns by holistic modeling of multiple relationships between users and items. S-MBRec \cite{smbrec} models GCN for each behavior individually, focusing solely on the information of the current behavior without learning user patterns. MBGCN \cite{mbgcn}, CML \cite{CML} and CIGF \cite{cigf} further aggregate representations between behaviors through learnable parameters, with no constraints on user behavior patterns. Recent methods CRGCN \cite{crgcn} and MB-CGCN \cite{mbcgcn} take into account the hierarchical correlation between behaviors and employ cascading behavior network, and PKEF \cite{pkef} further considers the bias in cascading networks, but this cascading paradigm imposes overly strict constraints on user behavior patterns. BCIPM \cite{bipn} successively learns global behavior information and target behavior information, which only considers patterns before the target behavior. Therefore, existing methods do not adequately model user behavior patterns.

\textbf{MTL for Recommendation.}
Recent research works have extensively applied multi-task learning (MTL) \cite{stem,li2020improving,moe} methods to recommendation systems to leverage heterogeneous user information. The traditional multi-task learning method is the shared bottom \cite{sharebottom} structure, which shares the bottom network to learn representations and uses separate tower network to predict each task. While some multi-behavior approaches based on this structure \cite{ghcf,crgcn,mbgmn,CML} can achieve knowledge sharing between tasks, their effectiveness may be affected by task differences. To better jointly optimize the model, some methods have introduced attention-based gating mechanisms into MTL structures. For example, MOE \cite{moe} and MMOE \cite{mmoe} propose a multi-expert structure shared by all tasks, and utilize gating networks to obtain expert fusion weights for each task. PLE \cite{PLE} further divides experts into shared experts and task-specific experts. However, the above methods all share inputs between tasks, which can lead to negative information transfer due to gradient conflict. MESI in CIGF \cite{cigf} specifically decouples inputs between tasks, mitigating the negative impact of coupled gradients. PME in PKEF \cite{pkef} further introduces a projection mechanism during task fusion to eliminate harmful information. Nevertheless, none of these approaches fully alleviate the negative transfer problem caused by the aggregation of tasks with differing feature and label distributions from a structural perspective.

% (Illustrated in Section \ref{problem_gradient}). 
