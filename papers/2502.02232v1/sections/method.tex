\section{METHODOLOGY}
We devise a "Combinatorial Optimization Perspective based Framework" (COPF) for multi-behavior recommendation, which contains two parts: (1) Combinatorial Optimization Graph Convolution Network(COGCN); (2) Distributed Fitting Multi-Expert Network(DFME). Figure \ref{fig:framework} illustrates the overall architecture of the proposed framework.

\begin{figure*}[t]
	\centering
	\setlength{\belowcaptionskip}{-0.0cm}
	\setlength{\abovecaptionskip}{-0.0cm}
	\includegraphics[width=1.0\textwidth]{figures/main.pdf}
	\caption{Illustration of the proposed COPF framework, and we use three user behavior types as examples: view, cart, and buy. ($\oplus$) denotes the element-wise addition operation, $f(\cdot)$ represents the function to generate experts, and dotted lines represent stop gradient.}
	\label{fig:framework}
	\vspace{-4mm}
\end{figure*}

\subsection{Embedding Layer}
We first look up the low-dimensional dense embeddings for user $u$ and item $v$ from the embedding tables using their one-hot vectors, respectively. Specifically, the process for obtaining these embeddings can be formulated as follows:
\begin{equation}
\begin{aligned}
\mathbf{e}_{u}=\mathbf{E}_{u}^{T}\cdot\mathbf{ID}_{u} \in \mathbb{R}^{d}, \mathbf{e}_{v}=\mathbf{E}_{v}^{T}\cdot\mathbf{ID}_{v} \in \mathbb{R}^{d}
\end{aligned}
\vspace{-0.1mm}
\end{equation}
where $\mathbf{ID}_{u}$ and $\mathbf{ID}_{v}$ denotes the one-hot vectors of user $u$ and item $v$, $\mathbf{E}_u \in \mathbb{R}^{|\mathbf{U}| \times d}$ and $\mathbf{E}_v \in \mathbb{R}^{|\mathbf{V}| \times d}$ are the embedding tables for users and items, $|\mathbf{U}|$ and $|\mathbf{V}|$ are the total number of users and items, and $d$ is the embedding size.

\subsection{Combinatorial Optimization Graph Convolution Network}
The recent multi-behavior methods have aimed to deeply explore user behavior patterns to enhance model performance. However, they impose constraints on user behavior patterns that are either too strict or too slack during the fusion step, making it difficult for the model to accurately capture these patterns. 

To solve the above problem, we examine the multi-behavior fusion process from a combinatorial optimization perspective and propose the Combinatorial Optimization Graph Convolutional Network (COGCN). It imposes different degrees of constraints on behavior patterns at different stages of user behavior, so as to learn the optimal behavioral information.

\subsubsection{Definition of Constraints in Combinatorial Optimization.}
To better describe the constraints at different stages of behavior, we first introduce the following definitions:

% \mc{
% \textbf{Definition 1} (Permutation and Combination of User Behavior Patterns). Let's take predicting whether user $u_1$ will eventually engage in behavior $k_1$ with item $v_1$ as an example. During training, the Graph-based methods may capture the relationships between $u_1$ and $v_1$ at different levels and with multiple associations. For example, $u_1 \xrightarrow{cart} v_3 \xrightarrow{be \; favored \; by} u_{2} \xrightarrow{purchase} v_{1}$.
% In this series of correlations between $u_1$ and $v_1$, we have two types of elements involved, the nodes (user and item) and the edges (engagements) on the graph. The former can be determined by the adjacency interaction matrices which are the inputs of methods, while the permutation and combination of the latter are what we focus on. In this case, we formulate the sequence of engagements as $\{cart, favor, purchase\}$, which explicitly 



% For convenience, we denote $\{s_1, s_2, ... s_L\}$ as the unified combinatorial expression paradigm for user behavioral patterns. For each $s_i$, it represents the 
% }

% \textbf{Definition 1} (\textit{User Behavior Pattern}). User behavior patterns are defined as high-frequency behavior chains between users and all items on the platform, representing the user's personalized habits. Formally, for any user $u \in \mathbf{U}$, his/her user behavior pattern is: $u$→$\cdots$→[$b_1$]\&[$b_2$]\&$\ldots$\&[$b_K$]→$\cdots$→$\mathbf{V}$, where $b_i$ is the behavior $i$ and $K$ is the number of behavior types, [·] denotes optional but at least one is required here. To facilitate description, [$b_1$]\&[$b_2$]\&$\ldots$\&[$b_K$] is defined as \textbf{\textit{"pattern-point"}}. For example, for a user who habitually searches through the shopping cart to buy items but also directly buys items that they find appealing while viewing, his/her user behavior pattern is: $u$→\textit{view}\&\textit{cart}→\textit{buy}→$\mathbf{V}$.

\textbf{Definition 1} (\textit{User Behavior Pattern}). User behavior patterns are defined as high-frequency behavior chains between users and all items on the platform, representing the user's personalized habits. Formally, for any user $u \in \mathbf{U}$, his/her user behavior pattern is: $u$→$\cdots$→$b_k$→$\cdots$→$\mathbf{V}$, where $b_k$ is the behavior $k$ and $K$ is the number of behavior types. For example, for a user who directly buys items that they find appealing while viewing, his/her user behavior pattern is: $u$→\textit{view}→\textit{buy}→$\mathbf{V}$.

% \textbf{Definition 2} (\textit{Upstream and Downstream Pattern-point}). 
% For two pattern-points A and B, we define that if there exists a behavior in A that is the downstream behavior of all behaviors in B, then A is the downstream pattern-point of B. For example, consider the order of general principles of behavior \textit{view → cart → buy} in E-commerce, if A is \textit{view}\&\textit{cart}, and B is \textit{view}, then A is the downstream pattern-point of B.

\textbf{Definition 2} (\textit{Upstream and Downstream Behavior}). 
The order of behavior definition is often derived from the mainstream behavior habits of most users in the real world. For example, consider the combination \textit{view → cart → buy}. Upstream behavior refers to the behavior that precedes the current behavior. Similarly, downstream behavior refers to the behavior that follows the current behavior. In the example, \textit{view} is the upstream behavior of \textit{cart}, and \textit{buy} is the downstream behavior of \textit{cart}.

% \textbf{Definition 2} (\textit{Behavior Node}). A behavior node is defined as the detailed modeling of a certain behavior. In the multi-behavior methods, one type of behavior corresponds to one type of node. For example, for the behaviors \textit{view}, \textit{cart} and \textit{buy}, we have the behavior node set:\{\textit{view node}, \textit{cart node}, \textit{buy node}\}. For ease of description, we define the node types to be consistent with the corresponding behavior types $k \in \{1,2,...,K\}$.

% \textbf{Definition 3} (\textit{Behavior Node State}). Behavior node state is defined as the specific situation in which a node is currently located and can be clearly defined. Formally, the behavior node state here refers to the representations output by the current node.

It can be seen that for the number of behavior types $K$, the total number of possible user behavior patterns is $\sum_{i=1}^K\frac{K!}{(K-i)!}$. To restrict the solution space in the combinatorial optimization of multi-behavior recommendation systems, we impose constraints on user behavior patterns at three stages: pre-behavior, in-behavior, and post-behavior. The details are as follows.

\textbf{Definition 3} (\textit{Pre-behavior Constraint}). Many users interact with items in a predetermined order of behaviors. Therefore, the upstream behavior information of the current behavior is essential. Formally, for any behavior $k (k>1)$, 
The input of its encoder $\mathbf{s}_{input}^{k}$ is denoted as 
$\mathbf{s}_{input}^{k}=f(g(\sum_{k^{\prime}=1}^{k - 1}\mathbf{s}_{output}^{k^{\prime}},\mathbf{s}_{init}))$, where 
$\mathbf{s}_{init}$ is the initial input, and $\mathbf{s}_{output}^{k^{\prime}}$ is the information of the behavior $k^{\prime}$, which is actually the output of its encoder. $g(\cdot)$ is the aggregation function (e.g., summation) and $f(\cdot)$ is the transition function (e.g., matrix multiplication, graph convolution). In this way, we constrain the interaction between behaviors.

% \textbf{Definition 3} (\textit{Pre-behavior Constraints}). Many users interact with items in a predetermined order of behaviors. Therefore, the upstream behavior information of the current behavior is essential. According to definition 2, formally, for any pattern-point $k (k>1)$, 
% the behavior node state $\mathbf{s}_{node}^{k}$ is denoted as 
% $\mathbf{s}_{node}^{k}=f(g(\sum_{k^{\prime}=1}^{k - 1}\mathbf{s}_{node}^{k^{\prime}},\mathbf{s}_{init}))$, where 
% $\mathbf{s}_{init}$ is the initial state, $\mathbf{s}_{node}^{k^{\prime}}$ is the state of the behavior node $k^{\prime}$, $g(\cdot)$ is the aggregation function (e.g., summation) and $f(\cdot)$ is the 
% state transition function (e.g., matrix multiplication, graph convolution). In this way, we constraint the interaction between behavior nodes.

\textbf{Definition 4} (\textit{In-behavior Constraint}). In-behavior Constraints essentially pertain to the modeling of the current behavior (i.e., the 
transition function $f(\cdot)$). In order to capture more complex or implicit user behavior patterns (for example, a user alternates between \textit{view} and \textit{cart} before \textit{buy}), we similarly utilize GCN with heterogeneous relations \cite{mbgcn}.  Meanwhile, to prevent poor model generalization performance and overfitting problems caused by information leakage, we define that the current behavior node learning process cannot contain semantic information of downstream behaviors. Specifically, for the current behavior $k$, we have the output of its encoder:
\begin{equation}
\mathbf{s}_{output}^{k}=Agg(\mathbf{s}_{input}^{k},\{\mathbf{B}_{k^{\prime}}|\mathbf{B}_{k^{\prime}}\in \mathcal{B},1\leq k^{\prime}\leq k\})
\end{equation}
where $\mathbf{s}_{input}^{k} = g(\sum_{k^{\prime}=1}^{k - 1}\mathbf{s}_{output}^{k^{\prime}},\mathbf{s}_{init})$.

\textbf{Definition 5} (\textit{Post-behavior Constraint}). For each behavior, we design decoupled outputs to partition the solution space, modeling user behavior patterns that end with different behaviors. Through joint optimization, the model can achieve better performance. This is consistent with the perspective of our proposed DFME.

\subsubsection{Graph Convolution.}
\label{para_inter_enhance}
In the previous part, we outlined the specific constraints for different behavioral stages. As graph convolutional networks (GCNs) can efficiently utilize high-order connectivity between users and items, we use a GCN-based paradigm to model the multi-behavior information fusion in the combinatorial optimization perspective.

Given the adjacency matrices of different behaviors, we modify them to meet the requirements of graph convolution:
\begin{equation}
\mathbf{A}_{k}=\left(\begin{array}{cc}
0 & \mathbf{B}_{k} \\
\left(\mathbf{B}_{k}\right)^{T} & 0
\end{array}\right)
\end{equation}
where $\mathbf{A}_{k}$ is the adjacency matrix of behavior $k$ in the graph. For the same purpose, we obtain the embedding matrices for users and items, respectively:
\begin{equation}
\mathbf{E}_{u}=[\begin{array}{cc}\mathbf{e}_{u_{1}},\cdots,\mathbf{e}_{u_{|\mathrm{U}|}}\end{array}], 
\mathbf{E}_{v}=[\begin{array}{cc}\mathbf{e}_{v_{1}},\cdots,\mathbf{e}_{v_{|\mathrm{V}|}}\end{array}],
\end{equation}
we then capture the interaction information of behaviors through graph convolution. Inspired by \cite{lightgcn,mbgcn}, for behavior $k$, we have:
\begin{equation}
\label{mess_gcn}
\mathbf{E}^{k,l+1}=\sum_{k^{\prime}=1}^{k}(\mathbf{D}^{-1}\mathbf{A}_{k^{\prime}} + \mathbf{I})\mathbf{E}^{k,l}
\end{equation}
where $\mathbf{D}$ is the diagonal identity matrix, $\mathbf{I}$ denotes an identity matrix. $\mathbf{E}^{k,l} = \mathbf{E}_{u}^{k,l}||\mathbf{E}_{v}^{k,l}$, $(||)$ is the concatenate operation and $l$ denotes the $l$-th layer. the initial input of the model $\mathbf{E}^{1,0} = \mathbf{E}_{u}||\mathbf{E}_{v}$. We utilize the adjacency matrices of the current behavior and its upstream behavior for message propagation and aggregation on each layer $l$, thereby implementing the \textit{In-behavior Constraint}.

Further, in order to implement the \textit{Pre-behavior Constraint}, we define the hierarchical information transfer between behaviors as:
\begin{equation}
\mathbf{E}^{k+1,0}=\sum_{k^{\prime}=1}^{k}\mathbf{E}^{k^{\prime},L}+\mathbf{E}^{1,0}
\end{equation}
where $L$ denotes the total layers of GCN. Here, we combine the last layer representations of each upstream behavior representation with the initial representation as the input of the current behavior.

Follow the \textit{Post-behavior Constraint}, We independently output the representations of each behavior for subsequent multi-task learning. To be specific, we directly add the outputs of different layers to get relations of different orders. For the embeddings of user $u$ and item $v$ in 
$\mathbf{E}^{k,l}$($\mathbf{e}_u^{k,l}$ and $\mathbf{e}_v^{k,l}$), we have:
\begin{equation}
\mathbf{e}_u^{k,*} = \sum_{l=0}^{L}\mathbf{e}_u^{k,l}, \mathbf{e}_v^{k,*} = \sum_{l=0}^{L}\mathbf{e}_v^{k,l}
\end{equation}
where $L$ is the number of GCN layers. 
\subsection{Distributed Fitting Multi-Expert Network}
By employing COGCN in the multi-behavior fusion step, we have obtained representations for user $u$ and item $v$ under each behavior $k$. The subsequent task is to devise a proper structure for multi-behavior prediction. Many methods \cite{pkef,cigf,crgcn} have utilized MTL modules to fully leverage multi-behavior information to assist in predicting target behavior, which has demonstrated their effectiveness. However, these MTL methods exhibit insufficient exploration in their structural design, failing to account for the potential negative transfer effects caused by differences in feature and label distributions during the learning process. To handle the drawbacks of the existing MTL modules, we propose the Distributed Fitting Multi-Expert Network(DFME), which controls behavior interactions through both features and labels, thereby coordinating the relationships between tasks. The specific details are as follows.

\subsubsection{Generating of Behavior-specific Experts.}
As contrastive learning can alleviate distributional biases between different data sources, we utilize it to adaptively learn the distributional similarity between target behaviors and auxiliary behaviors before generating experts. Take the auxiliary behavior $k$ as an example, we have:
\begin{equation}
\mathcal{L}_{cl,U}^{K,k}=\frac{1}{|\mathbf{U}|}\sum_{u\in\mathbf{U}}-log\frac{\exp(\varphi(\mathbf{e}_u^{K,*},\mathbf{e}_u^{k,*})/\tau)}{\sum_{u^{\prime}\in\mathbf{U}}\exp(\varphi(\mathbf{e}_u^{K,*},\mathbf{e}_{u^{\prime}}^{k,*})/\tau)}
\end{equation}
where $\tau$ represents the temperature hyperparameter for the softmax function, and 
$\varphi(\cdot)$ is a function for calculating the similarity between two vectors(e.g., inner product) .The item side follows the same contrastive learning process. Thus, for behavior $k$, the final contrastive loss is $\mathcal{L}_{cl}^{K,k} =\mathcal{L}_{cl,U}^{K,k}+\mathcal{L}_{cl,V}^{K,k}$.

Then, we follow previous methods\cite{cigf} by using decoupled behavior representations to generate behavior-specific experts, thereby preventing gradient conflicts caused by coupled inputs:
\begin{equation}
\mathbf{e}^{k} = \mathbf{e}_u^{k,*} \circ \mathbf{e}_v^{k,*}
\end{equation}
where $(\circ)$ is the hadamard product operation. Since decoupled behavior representations are  utilized to generate experts, we can obtain a total of $k$ behavior-specific experts.

\subsubsection{Generating of Behavior-fitting Experts.}
To address the challenge of mitigating feature distribution bias, we also define a dedicated behavior-fitting expert for each task, whose outputs are used in the subsequent aggregation process. Specifically, for the current behavior $k$ and any other behavior $k^{\prime}$, it can be formulated as:
\begin{equation}
\left\{\begin{array}{c}
\begin{aligned}
\mathbf{e}_{u,in}^{k, k^{\prime}}&=(\alpha \mathbf{e}_u^{k,*}+\beta \mathbf{e}_u^{k^{\prime},*})/2\\
\mathbf{e}_{v,in}^{k, k^{\prime}}&=(\alpha \mathbf{e}_v^{k,*}+\beta \mathbf{e}_v^{k^{\prime},*})/2\\
\mathbf{e}_{in}^{k, k^{\prime}} &= \mathbf{e}_{u,in}^{k, k^{\prime}}||\mathbf{e}_{v,in}^{k, k^{\prime}}\\
\mathbf{e}_{out}^{k, k^{\prime}} &= Agg(\mathbf{e}_{in}^{k, k^{\prime}}, \mathbf{A}_{k^{\prime}})
\end{aligned}
\end{array}\right.
\end{equation}
where $\mathbf{e}_{out}^{k, k^{\prime}} = \mathbf{e}_{u,out}^{k, k^{\prime}}||\mathbf{e}_{v,out}^{k, k^{\prime}}$, $(||)$ is the concatenate operation, $\mathbf{e}_u^{k,*}$ and $\mathbf{e}_u^{k^{\prime},*}$ are the user representations of the $k$- and $k^{\prime}$-th behavior($k^{\prime} \neq k$) respectively, similarly for items. $\alpha, \beta$ are coefficients that control the scaling of behavioral representations, and $Agg(\cdot)$ is a graph convolution operator. In particular, the values of $\alpha$ and $\beta$ should be small to achieve the effect of fine-tuning the representation space. We use a graph convolutional network with the $k^{\prime}$-th behavior interaction matrix (i.e., $Agg(\cdot)$) to capture the effective information contained within the representation $\mathbf{e}_{in}^{k, k^{\prime}}$. Similar to Equation \ref{mess_gcn}, the graph convolutional operator is defined as follows:
\begin{equation}
\mathbf{E}^{k, k^{\prime}, l+1}=(\mathbf{D}^{-1}\mathbf{A}_{k^{\prime}} + \mathbf{I})(\mathbf{E}^{k,k^{\prime}, l}\circ\mathbf{R}^{k^{\prime},l}),\mathbf{R}^{k^{\prime},l}=\mathbf{W}^{l}\mathbf{R}^{k^{\prime},l - 1}
\end{equation}
where ($\circ$) is the hadamard product operation, $\mathbf{A}_{k^{\prime}}$ is the adjacency matrix of behavior $k^{\prime}$. $\mathbf{W}^{l}$ is the layer specific parameter shared with the layer of GCN. We use a hierarchically updated behavior embedding matrix $\mathbf{R}^{k^{\prime},l}$ for fully learning of the $k^{\prime}$-th behavior information, with its initial state is $\mathbf{R}^{k^{\prime},1}$.

As $\mathbf{e}_{out}^{k, k^{\prime}}$ contains the representation of users and items, we utilize the hadamard product operation to generate final experts, which is similar to behavior-specific experts:
\begin{equation}
\mathbf{e}^{k, k^{\prime}} = \mathbf{e}_{u,out}^{k, k^{\prime}} \circ \mathbf{e}_{v,out}^{k, k^{\prime}}
\end{equation}

\subsubsection{Aggregating of Experts.}
In order to mitigate the problem of negative transfer caused by distribution differences between features and labels, we improve the task aggregation mechanism in both forward and backward propagation. As we can see, behavior-aware graph convolution operation and representation scaling mechanism help us capture the effective components of other behaviors, which can be further utilized to alleviate the negative transfer caused by feature distribution differences in gated aggregation. To be specific, We define the gate for task $k$ as:
\begin{equation}
\mathbf{g}^k=Softmax(\mathbf{W}_g(\mathbf{e}_{u}^{k,*}||\mathbf{e}_{v}^{k,*})+\mathbf{b}_g)
\end{equation}
where $(||)$ is the concatenate operation, $\mathbf{W}_{g} \in \mathbb{R}^{K \times 2d}$ and $\mathbf{b}_{g} \in \mathbb{R}^{K \times 1}$ are feature transformation matrix and bias matrix, and $\mathbf{g}^{k} \in \mathbb{R}^{K \times 1}$ is the attention vector which are used as selector to calculate the weighted sum of all experts. We then take the refined representations $\mathbf{e}^{j, k} ( j \in \{1,2,...,K\} \cap j \neq k)$ of other behaviors and $\mathbf{e}^{k}$ as targets of aggregation by the $k$-th gate. In order to eliminate the negative impact caused by the distribution differences in labels between the auxiliary and target behaviours, we ensure that the parameters of the target task are not updated by the gradient updates from the auxiliary tasks, thus preventing interference from auxiliary behaviors. Formally, we have:
\begin{equation}
\mathbf{o}^{k}(j)=\left\{\begin{array}{c}
\begin{aligned}
& \mathbf{g}^{k}(j) \cdot \mathbf{e}^{k},& j& = k\\
& \mathbf{g}^{k}(j) \cdot \mathbf{e}^{j, k},& j&\neq k\\
& sg(\mathbf{g}^{k}(j) \cdot \mathbf{e}^{j, k}),& j&\neq k \,and\, j = K
\end{aligned}
\end{array}\right.
\end{equation}
where $\mathbf{g}^{k}(j)$ denotes the $j$-th element of vector $\mathbf{g}^{k}$. $sg(\cdot)$ is the stop gradient operation. The final prediction for task $k$ is calculated as:
\begin{equation}
\hat{o}_{uv}^{k} = h^{k}(\sum_{j=1}^{K} {\mathbf{o}^{k}(j)})
\end{equation}
where $h^{k}(\cdot)$ is the tower function. For simplicity, we use average operation as the tower function here. $\hat{o}_{uv}^{k}$ is the prediction score of whether user $u$ will have interaction with item $v$ under behavior $k$.

\subsection{Joint Optimization}
As we have obtained the final prediction $\hat{o}_{uv}^{k}$ for each behavior 
$k$, we leverage the Bayesian Personalized Ranking (BPR)\cite{bpr} loss to optimize the model:
\begin{equation}
\mathcal{L}_{bpr} = -\sum_{k=1}^{K}\sum_{(u,s,t)\in \mathcal{O}_k} \lambda_k * \textup{ln} \sigma(\hat{o}_{us}^{k} - \hat{o}_{ut}^{k})
\end{equation}
where $\mathcal{O}_k = \left\{(u,s,t)|(u,s)\in \mathcal{O}_k^{+}, (u,t) \in \mathcal{O}_k^{-} \right\}$ denotes the training dataset. $\mathcal{O}_k^+$ and $\mathcal{O}_k^-$ indicates the observed and unobserved user-item interactions under behavior $k$, respectively. $\lambda_k$ is the coefficient of behavior $k$, and $\sigma$ is the sigmoid function.

In all, the final loss can be formulated as:
\begin{equation}
    \mathcal{L}(\Theta) = \mathcal{L}_{bpr} + \gamma \sum_{k=1}^{K - 1}\mathcal{L}_{cl}^{K,k} + \mu ||\Theta||^2_2
\end{equation}
where $\gamma$ is the coefficient of cl loss, $\Theta$ represents set of all model parameters. $\mu$ is the $L_2$ regularization coefficient for $\Theta$.
% \subsection{Complexity Analysis}
% \label{complexity}
% \subsubsection{Time Complexity.}
% The time spent on COPF is mainly in the multi-behavior fusion step, and the computational complexity of COGCN is $\sum_{k=1}^{K}{O\left(L\cdot\left|\mathcal{E}_{k} \right| \cdot d\right)}$, where $\left|\mathcal{E}_{k} \right|$ represents the number of edges across all graphs in the set $\mathcal{E}_{k}$, $K$ is the behavior number, $L$ denotes the number of GNN layers of the $k$-th behavior, and $d$ denotes the embedding size. Since the computational complexity does not introduce parameters outside the GNN module, the time complexity of COPF is comparable to that of existing GNN-based methods.

% \subsubsection{Space Complexity.} 
% The learnable parameters in COPF mainly come from the embeddings of users and items, resulting in a space complexity of $O\left((|\mathbf{U}|+|\mathbf{V}|)d\right)$, which is similar to existing methods. Additionally, as the dense graphs $\mathcal{G}_{k}$ in the set $\mathcal{G}$ are pre-converted into sparse behavior-specified matrices, there is no need to pay additional space to store these graphs in the computational process. Overall, The memory usage of the model remains within a manageable range during training.
