\section{APPENDIX}
\subsection{Complexity Analysis}
\label{complexity}
\subsubsection{Time Complexity.}
The main time consumption of COPF lies in the graph convolution operations. The computational complexity of the both steps is $O\left(L\left|\mathcal{E} \right| d\right)$, where $\left|\mathcal{E} \right|$ represents the number of edges in the bipartite graph $\mathcal{G}$, $L$ denotes the number of GNN layers, and $d$ denotes the embedding size. Since the computational complexity does not introduce parameters outside the GNN module, the time complexity of COPF is comparable to that of existing GNN-based methods.

\subsubsection{Space Complexity.} 
The learnable parameters in COPF mainly come from the embeddings of users and items, resulting in a space complexity of $O\left((|\mathbf{U}|+|\mathbf{V}|)d\right)$, which is similar to existing methods. Additionally, as the dense graphs $\mathcal{G}_{k}$ ($k \in \{1,2,...,K\}$) required for graph convolution operation are pre-converted into sparse behavior-specified matrices, there is no need to pay additional space to store these graphs in the computational process. Overall, The memory usage of the model remains within a manageable range during training.


\subsection{Analysis of Data Distribution}


Figure \ref{fig:label_venn} shows the data distribution on the three datasets. 1/0 indicates the presence or absence of the corresponding type of behavior. For example, 1001 represents users who only have view and buy behaviors with items. As we can see, there are significant differences in the behavior distribution between datasets, and each dataset contains rich information about user behavior patterns that can be used for learning. For instance, the user behaviors in the Beibei dataset strictly follow the dependency requirements, so the \textbf{COPF-C} variant performs significantly better on Beibei than the other two datasets due to its cascade paradigm(shown in Table \ref{tab:ablation_key}). Moreover, the user behavior patterns are not explicitly available within most datasets since we do not know the specific timing of each user-item interaction. The process of learning user behavior is also implicit. This highlights the necessity of using a general framework(i.e., COGCN) to restrict the solution space by imposing constraints from the perspective of combinatorial optimization to efficiently capture user behavior patterns.

\begin{figure}[H]
	\centering
	\setlength{\belowcaptionskip}{0cm}
	\setlength{\abovecaptionskip}{0cm}
	\includegraphics[width=0.48\textwidth]{figures/venn.pdf}
	\caption{Data distribution of three datasets}
	\label{fig:label_venn}
	\vspace{-4mm}
\end{figure}

\subsection{Analysis of the Proposed DFME}
\subsubsection{The structure of transfer-based MTL}
\label{classical_mtl}

\begin{figure}[H]
	\centering
	\setlength{\belowcaptionskip}{0cm}
	\setlength{\abovecaptionskip}{0cm}
	\includegraphics[width=0.47\textwidth]{figures/mtl_structure.pdf}
	\caption{The structure of transfer-based MTL. Red line represents the forward propagation that affects the target task A, blue line denotes the backward propagation that affects the target task A, and yellow line represents the irrelevant process.}
	\label{fig:mtl_structure}
	\vspace{-4mm}
\end{figure}

\begin{figure*}[ht]
	\centering
	\setlength{\belowcaptionskip}{0cm}
	\setlength{\abovecaptionskip}{0cm}
	\includegraphics[width=\textwidth]{figures/engle.pdf}
	\caption{Refine with other behavior representions.}
	\label{fig:engle}
	\vspace{-4mm}
\end{figure*}

A basic transfer-based MTL network is shown in Figure \ref{fig:mtl_structure}. The task corresponding to the target behavior is designated as the target task (Task A), while other tasks are auxiliary tasks(Task B and other tasks). As we can see, there are four paths associated with these two tasks. For target task A, path 1 is the main path for this task, and path 4 becomes an irrelevant path due to the decoupling of task inputs \cite{pkef}. Paths 2 and 3 are information interaction paths resulting from the aggregation between tasks, which are the main correlations that DFME needs to coordinate. Specifically, path 2 affects the target task A at the feature level during forward propagation, and path 3 affects the target task A at the label level during backward propagation.

\subsubsection{Shortcomings of existing optimal MTL}
\label{shortcoming_pkef}
PKEF introduces a projection mechanism during aggregation to disentangle the shared and unique parts for other behavioral experts. The shared part is used for aggregation, while the unique part is used for auxiliary learning. While somewhat effective, this method has two main issues: \textbf{1)} For instance, with the behaviors "\textit{cart}" and "\textit{buy}", PKEF assumes that the shared part is the information related to both behaviors occurring together (e.g., \textit{cart \& buy}), while the unique part is information related to only a single behavior (e.g., \textit{only cart}), thus further sets an auxiliary loss for the unique part accordingly (e.g., labels for \textit{cart w/o buy}). In reality, "\textit{not buy}" is also valuable information for learning behavior \textit{buy}, which should exist in the shared part, and the unique part should be completely irrelevant information. This incorrect projection mechanism can compromise the effectiveness of the information during aggregation. Additionally, the projection mechanism ensures that the representation space of the auxiliary behavior remains consistent with that of the current behavior during aggregation. However, since the model is still in the training phase, the representation space for the target behavior is unstable and may be inaccurate. Enforcing such alignment could introduce detrimental information, which can potentially prevent the model from converging to the optimal distribution and adversely affect its generalization performance. \textbf{2)} PKEF overlooks the impact of gradient coupling during aggregation, where gradient updates from auxiliary tasks affect the target task. The above two problems may cause the model's inability to accurately fit the target behavior distribution, leading to negative transfer problem. 

\subsubsection{Method of the proposed DFME}
\label{method_dfme}
Our proposed MTL network, named DFME, coordinates the relationship between target and auxiliary tasks in two key aspects to control negative information transfer. Specifically, in forward propagation, contrastive learning between tasks is utilized to enable the target behavior to obtain effective information from the auxiliary behaviors, thereby reducing the distribution gap between the target and auxiliary behaviors when generating behavior-specific experts. Meanwhile, we spatially adapt the representation of the current behavior to fit the aggregation process by generating behavior-fitting experts for each task, thereby preventing interference among different task behaviors. As shown in Figure \ref{fig:engle}, for the current behavior $k$ and one of the other behaviors $k^{\prime}$, we fuse the representations of behavior $k$ and $k^{\prime}$ after multiplying them by small weight coefficients respectively. This yields a fitted representation that is appropriately sized and slightly different in direction from the representation of behavior $k^{\prime}$. We then obtain the final task output representation by capturing the effective information about behavior $k^{\prime}$ contained in this fitted representation through a graph convolutional network. Finally, we use behavior-specific expert for the current behavior and behavior-fitting experts for other behaviors during aggregation. In summary, the above steps can be outlined as follows: the effective information contained in the interaction between behaviors is used to refine the representation space of the current behavior while ensuring that the generalization performance of the model is not affected.

During backward propagation, for a transfer-based MTL using decoupled input ($\mathbf{e}_{u}^{k^{\prime}}$,$\mathbf{e}_{v}^{k^{\prime}}$) for each task $k^{\prime} \in \{1,2,...,K\}$ , the aggregation process of the auxiliary task $k$ is:
\begin{displaymath}
    \mathbf{o}^{k} = \sum_{k^{\prime}=1}^{K}\mathbf{g}^k(k^{\prime})\cdot\mathbf{e}^{k^{\prime}}
\end{displaymath}
where $\mathbf{e}^{k^{\prime}}$ is the output of the expert, $\mathbf{g}^k(k^{\prime})$ indicates the $k^{\prime}$-th element of the gating vector $\mathbf{g}^k$. Due to the introduction of behavior-fitting experts (i.e., $f_k(\cdot)$) in the forward propagation to refine the representation space for each behavior, the aggregation process can be further represented as:
\begin{displaymath}
    \mathbf{o}^k=\sum_{k^{\prime}=1,k^{\prime}\neq k}^K{\mathbf{g}^k(k^{\prime})\cdot\mathbf{e}^{k, k^{\prime}}}+\mathbf{g}^k(k)\cdot\mathbf{e}^{k}
\end{displaymath}
where $\mathbf{e}^{k, k^{\prime}}=f_k(\mathbf{e}_{u}^{k},\mathbf{e}_{v}^{k},\mathbf{e}_{u}^{k^{\prime}},\mathbf{e}_{v}^{k^{\prime}})$ denotes the output of the behavior-fitting expert. And the loss function for task $k$ can be defined as: 
\begin{displaymath}
\mathcal{L}_{k}=L(h^{k}(\mathbf{o}^{k})-\hat{o}_{uv}^{k})
\end{displaymath}
where $h^{k}(\cdot)$ is the tower function, $L(\cdot)$ denotes the loss function. Then we can obtain the gradient of the auxiliary task $k$ with respect to the behavior target behavior $t$ as follows: 
\begin{displaymath}
\begin{aligned}
{\frac{\partial \mathcal{L}_{k}}{\partial \mathbf{e}_{*}^t}}
&=\frac{\partial h^k(\mathbf{g}^k(t)\cdot \mathbf{e}^{k, t})}{\partial \mathbf{e}_{*}^t}*L^{\prime}(h^{k}(\mathbf{o}^k)-\hat{o}_{uv}^k) \\
&=\frac{\partial h^k(\mathbf{g}^k(t)\cdot f_k(\mathbf{e}_{u}^{k},\mathbf{e}_{v}^{k},\mathbf{e}_{u}^{t},\mathbf{e}_{v}^{t}))}{\partial \mathbf{e}_{*}^t}*L^{\prime}(h^{k}(\mathbf{o}^k)-\hat{o}_{uv}^k)
\end{aligned}
\end{displaymath}
where $\mathbf{e}_{*}^t \in \{\mathbf{e}_{u}^{t},\mathbf{e}_{v}^{t}\}$. It can be seen that the gradient update of the auxiliary task still affects the target behavior. Therefore, we stop the gradient updates from the auxiliary loss to the target behavior in order to alleviate the potential negative transfer caused by gradient coupling in the multi-behavior prediction step. 
