\section{EXPERIMENTS}
\label{experiments}

\begin{table}[t]
\setlength{\abovecaptionskip}{0cm}
\setlength{\belowcaptionskip}{0mm}
\caption{Statistics of evaluation datasets.}
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}{c|ccccc}
\toprule
Dataset & \#User & \#Item & \#Interaction & \#Target Interaction &  \#Interactive Behavior Type \\ \midrule
Beibei & 21,716 & 7,977 & $3.3 \times 10^6$ & 282,860 & \{View,Cart,Buy\} \\ 
Taobao & 15,449 & 11,953 & $1.2 \times 10^6$ & 92,180 & \{View,Cart,Buy\} \\
Tmall & 41,738 & 11,953 & $2.3 \times 10^6$ & 255,586 & \{View,Collect,Cart,Buy\} \\  \bottomrule

\end{tabular}
}
\vspace{-3mm}
\label{dataset}
\end{table}

\subsection{Experimental Setting}
\subsubsection{Parameter Settings}
Our proposed COPF is implemented in TensorFlow \cite{TensorFlow}. For a fair comparison, following PKEF \cite{pkef} and BCIPM \cite{bipn}, we set the embedding size to 64. We initialize the parameters using Xavier \cite{xavier}. The parameters are optimized by Adam \cite{adam}, while the learning rate is set to $10^{-3}$. We search the number of GCN layers in \{1,2,3,4\}. Moreover, we adjust the loss coefficients for each behavior in \{0,1/6,2/6,3/6,4/6,5/6,1\} and fix the sum of the coefficients for all actions as 1. The coefficient of contrastive loss $\gamma$ and $L_2$ regularization $\mu$ are set to 1 and 0.01, respectively. All experiments are run 5 times and average results are reported. For fairness, the parameter settings of the baseline are adjusted and searched by referring to the original work. Furthermore, we conduct parameter analysis experiments, which are shown in Section \ref{hyper}.

\subsubsection{Dataset Description}
We use three public datasets (Beibei, Taobao and Tmall) to validate the effectiveness of our proposed COPF model. The pre-processing of these datasets is consistent with the previous methods \cite{cigf,pkef}. Specifically, we eliminate duplicate user-item interactions through retaining the earliest one. The statistical information of these three datasets is summarized in Table \ref{dataset}. 

\subsubsection{Evaluation Metrics}
To evaluate the performance of COPF and baseline methods in top-k item recommendation, we use two metrics: Hit Ratio (\textit{HR@K}) and Normalized Discounted Cumulative Gain (\textit{NDCG@K}). In all our experiments, we set $K = 10$.


\subsubsection{Baseline Models}
To validate the effectiveness of COPF, we compared it with numerous baseline models in recent years, which can be divided into three categories: \textbf{(1) Single-behavior methods:} MF-BPR \cite{bpr}, NeuMF \cite{ncf} and LightGCN \cite{lightgcn}, \textbf{(2) Multi-behavior methods without MTL:} RGCN \cite{RGNN}, GNMR \cite{gnmr}, NMTR \cite{nmtr}, \\ MBGCN\footnote{https://github.com/tsinghua-fib-lab/MBGCN} \cite{mbgcn}, S-MBRec \cite{smbrec}, KMCLR \cite{kmclr} and MB-CGCN\footnote{https://github.com/SS-00-SS/MBCGCN} \cite{mbcgcn}, \textbf{(3) Multi-behavior methods with MTL:} CML \cite{CML}, CRGCN \cite{crgcn}, CIGF \cite{cigf}, PKEF \footnote{https://github.com/MC-CV/PKEF} \cite{pkef} and BCIPM\footnote{https://github.com/MingshiYan/BIPN} \cite{bipn}.


\begin{table}[t]
\setlength{\abovecaptionskip}{0cm}
\setlength{\belowcaptionskip}{0mm}
\caption{The overall performance comparison. Boldface denotes the highest score and underline indicates the results of the best baselines. $\star$ represents significance level $p$-value $<0.05$ of comparing COPF with the best baseline.}
    \centering
    \begin{threeparttable}
	\resizebox{\linewidth}{!}{
    \begin{tabular}{c|cccccc}
    \toprule
    \multirow{2}{*}{Model}&
    \multicolumn{2}{c}{Beibei}&\multicolumn{2}{c}{Taobao}&\multicolumn{2}{c}{Tmall}\cr
    \cmidrule(lr){2-3} \cmidrule(lr){4-5} \cmidrule(lr){6-7} 
    &HR&NDCG&HR&NDCG&HR&NDCG\cr
    \midrule
    MF-BPR&0.0191&0.0049&0.0076&0.0036&0.0230&0.0207\cr
    NeuMF&0.0232&0.0135&0.0236&0.0128&0.0124&0.0062\cr
    LightGCN&0.0391&0.0209&0.0411&0.0240&0.0393&0.0209\cr
    \hline
    RGCN&0.0363&0.0188&0.0215&0.0104&0.0316&0.0157\cr
    GNMR&0.0413&0.0221&0.0368&0.0216&0.0393&0.0193\cr
    NMTR&0.0429&0.0198&0.0282&0.0137&0.0536&0.0286\cr
    MBGCN&0.0470&0.0259&0.0509&0.0294&0.0549&0.0285\cr
    S-MBRec&0.0489&0.0253&0.0498&0.0269&0.0694&0.0362\cr
    KMCLR&0.0531&0.0263&0.1185&0.0659&0.0603&0.0310\cr
    MB-CGCN&0.0579&0.0381&0.1233&0.0677&0.0984&0.0558\cr
    \hline
    CML&0.0542&0.0268&0.1203&0.0661&0.0448&0.0227\cr
    CRGCN&0.0459&0.0324&0.0855&0.0439&0.0840&0.0442\cr
    CIGF&0.0809&0.0400&0.0897&0.0474&0.1150&0.0636\cr
    PKEF&\underline{0.1130}&\underline{0.0582}&\underline{0.1385}&\underline{0.0785}&0.1277&0.0721\cr
    BCIPM&0.0458&0.0221&0.1201&0.0656&\underline{0.1414}&\underline{0.0741}\cr
    \hline
    \textbf{COPF}&\textbf{0.1694}$^\star$&\textbf{0.0903}$^\star$&\textbf{0.1552}$^\star$&\textbf{0.0838}$^\star$&\textbf{0.1755}$^\star$&\textbf{0.0967}$^\star$\cr
    \hline
    Rel Impr.&49.91\%&55.15\%&12.06\%&6.75\%&24.12\%&30.50\%\cr
    \bottomrule
    \end{tabular}}
    \end{threeparttable}
    \vspace{-4mm}
    \label{comparisons_model}
\end{table}

\subsection{Performance Comparison}
\label{performance}
Table \ref{comparisons_model} shows the performance of methods on three datasets with respect to HR@10 and NDCG@10. 
We have the following findings:
\begin{itemize}

\item Our proposed COPF model achieves the best performance on all three datasets. Specifically, COPF improves the best baselines by \textbf{49.91$\%$}, \textbf{12.06$\%$}, and \textbf{ 24.12$\%$} in terms of HR ( \textbf{55.15$\%$}, \textbf{6.75$\%$}, and \textbf{30.50$\%$} in terms of NDCG) on Beibei, Taobao, and Tmall datasets, respectively. Due to the varying user behavior patterns across different datasets, the superior performance on all datasets further demonstrates the applicability and effectiveness of COPF for multi-behavior recommendation.

\item In single-behavior methods, LightGCN achieves better performance than MF-BPR and NeuMF, while in multi-behavior methods, MBGCN also outperforms NMTR. This demonstrates the advantage of GCNs in capturing high-order interactive information. Furthermore, most of the multi-behavior recommendation methods, such as MBGCN, perform better than single-behavior methods on all three datasets, which highlights the superiority of leveraging multi-behavior information for learning. Finally, the excellent performance of CML and KMCLR also illustrates the effectiveness of contrastive learning.

\item Although models vary in network structure, the multi-behavior methods with MTL generally perform better overall compared to those without MTL. For example, PKEF consistently outperforms all the multi-behavior methods without MTL. It is worth noting that KMCLR and MB-CGCN perform better among the multi-behavior methods without MTL. The possible reasons are that KMCLR enhances the original multi-behavioral information by introducing external knowledge graph information; Meanwhile, MB-CGCN reduces the solution space of the multi-behavior fusion problem through cascade constraints. Even though this constraint is overly strict, it still achieves relatively better results in the biased space.

\item MBGCN outperforms RGCN by considering the contribution of each behavior during behavior fusion. Compared to them, CIGF utilizes multi-task learning in the prediction process, which further improves the performance. However, they still lacked
proper constraints or imposed overly relaxed constraints on user behavior patterns. Recent approaches like CRGCN, MB-CGCN, and PKEF use cascading paradigm to constrain the learning of user behavior patterns; BCIPM further relaxes the constraints within the cascading paradigm and highlights the significance of the target behavior. As we can see, PKEF achieves second performance only to our model on Beibei and Taobao, while BCIPM does the same on Tmall. This indicates the necessity of considering user behavior pattern constraints from a combinatorial optimization perspective.
\end{itemize}

\subsection{Ablation Study}
\label{ablation_study}
\subsubsection{Impact of the Key Components}

\begin{table}[t]
    \setlength{\abovecaptionskip}{0cm}
    \setlength{\belowcaptionskip}{0mm}
    \caption{Performances of different COPF variants.}
    \centering
    \begin{threeparttable}
    \resizebox{\linewidth}{!}{
    \begin{tabular}{c|cccccc}
    \toprule
    \multirow{2}{*}{Model}&
    \multicolumn{2}{c}{Beibei}&\multicolumn{2}{c}{Taobao}&\multicolumn{2}{c}{Tmall}\cr
    \cmidrule(lr){2-3} \cmidrule(lr){4-5} \cmidrule(lr){6-7}
    &HR&NDCG&HR&NDCG&HR&NDCG\cr
    \midrule
    w/o COGCN &0.0601&0.0294&0.0801&0.0417&0.0783&0.0437\cr
    COPF-P &0.1282&0.0661&0.1041&0.0540&0.1201&0.0639\cr
    COPF-A &0.1649&0.0885&0.1389&0.0740&0.1592&0.0883\cr
    COPF-D &0.0333&0.0163&0.1052&0.0595&0.1064&0.0606\cr
    COPF-F &0.1285&0.0665&0.0996&0.0515&0.1167&0.0620\cr
    COPF-C &0.1514&0.0861&0.0913&0.0511&0.0785&0.0446\cr
    COPF-B &0.1622&0.0870&0.1531&0.0817&0.1714&0.0957\cr
    COPF-H &0.1199&0.0649&0.0841&0.0478&0.0809&0.0475\cr
    \hline
    w/o DFME &0.0821&0.0400&0.1120&0.0607&0.1146&0.0643\cr
    w/o con. &0.1154&0.0581&0.1476&0.0788&0.1425&0.0791\cr
    w/o for. &0.1649&0.0886&0.0471&0.0247&0.1391&0.0769\cr
    w/o back. &0.1676&0.0886&0.1446&0.0781&0.1601&0.0888\cr
    all sg. &0.1656&0.0888&0.1508&0.0809&0.1553&0.0866\cr
    w/o fit. &0.1182&0.0614&0.0827&0.0438&0.1346&0.0738\cr
    \hline
    \textbf{COPF}&\textbf{0.1694}&\textbf{0.0903}&\textbf{0.1552}&\textbf{0.0838}&\textbf{0.1755}&\textbf{0.0967}\cr
    \bottomrule
    \end{tabular}}
    \end{threeparttable}
    \vspace{-4mm}
    \label{tab:ablation_key}
\end{table}
To evaluate the effectiveness of sub-modules in our COPF framework, we conducted ablation experiments on COGCN and DFME respectively. For COGCN, we mainly consider the constraints of each stage. Specifically, we first define two strict constraints: (1) \textit{strict pre-behavior constraint}: Change the pre-behavior constraint to "only receive information about the most recent upstream behavior"; (2) \textit{strict in-behavior constraint}: Change the in-behavior constraint to "only learn the current behavior signal". Then we design the following variants: (1) \textbf{w/o COGCN}: Replace COGCN with multiple LightGCN.(2) \textbf{COPF-P}: Remove pre-behavior constraint.(3) \textbf{COPF-A}: Remove in-behavior constraint.(4) \textbf{COPF-D}: Remove post-behavior constraint(and no DFME either).(5) \textbf{COPF-F}: Remove pre-behavior and in-behavior constraints.(6) \textbf{COPF-C}:Use a strict cascading paradigm.(7) \textbf{COPF-B}: Use strict pre-behavior constraint instead. (8) \textbf{COPF-H}: Use strict in-behavior constraint instead. For DFME, we have: (1) \textbf{w/o DFME}: Replace DFME with the bilinear module.(2) \textbf{w/o con.}: Remove contrastive learning.(3) \textbf{w/o for.}: Remove improvement in forward propagation during aggregation.(4) \textbf{w/o back.}: Remove improvement in backward propagation during aggregation.(5) \textbf{all sg.}: Use simple stop-gradient strategy in backward propagation during aggregation.(6) \textbf{w/o fit.}: Remove improvements in both propagation during aggregation. The results in Table \ref{tab:ablation_key} lead to the following conclusions:
\begin{itemize}
\item Comparing the performance of COPF with other variants that modify constraints in COGCN (for fairness, \textbf{COPF-D} is compared with \textbf{w/o DFME}), we observe that removing or altering the constraints of any stage leads to varying degrees of performance degradation. Additionally, \textbf{w/o COGCN} achieves the worst performance on the three datasets compared to other variants. These demonstrate the effectiveness of addressing multi-behavior fusion from a combinatorial optimization perspective and validate the rationality of the constraints established at each stage of COGCN.
\item The performance of each variant modified for DFME is also affected to varying degrees, with the \textbf{w/o DFME} variant performing the worst. This demonstrates the rationality and effectiveness of our proposed DFME.

\end{itemize}


\subsubsection{Impact of the Aggregation Schemes}
\label{knowledge_fusion}
\begin{table}[t]
    \setlength{\abovecaptionskip}{0cm}
    \setlength{\belowcaptionskip}{0mm}
    \caption{Performances of different aggregation schemes.}
    \centering
    \begin{threeparttable}
    \resizebox{\linewidth}{!}{
    \begin{tabular}{c|cccccc}
    \toprule
    \multirow{2}{*}{Model}&
    \multicolumn{2}{c}{Beibei}&\multicolumn{2}{c}{Taobao}&\multicolumn{2}{c}{Tmall}\cr
    \cmidrule(lr){2-3} \cmidrule(lr){4-5} \cmidrule(lr){6-7}
    &HR&NDCG&HR&NDCG&HR&NDCG\cr
    \midrule
    No Aggregation &0.1103 & 0.0560 & 0.1143 & 0.0634 & 0.1165 & 0.0655 \cr
    Summation &0.1163 & 0.0605 & 0.0789 & 0.0410 & 0.1323 & 0.0732\cr
    Linear Trans.&0.0724 & 0.0342 & 0.1317 & 0.0712 & 0.1408 & 0.0771\cr
    Vanilla Fusion &0.1228 & 0.0637 & 0.1080 & 0.0589 & 0.1337 & 0.0749\cr
    Projection Fusion&0.1299 & 0.0672 & 0.1153 & 0.0611 & 0.1442 & 0.0791\cr
    \hline
    \textbf{COPF}&\textbf{0.1694}&\textbf{0.0903}&\textbf{0.1552}&\textbf{0.0838}&\textbf{0.1755}&\textbf{0.0967}\cr
    \bottomrule
    \end{tabular}}
    \end{threeparttable}
    \vspace{-4mm}
    \label{tab:ablation_fusion}
\end{table}

To further explore the optimal approach for coordinating tasks, we compare the proposed scheme with several other alternatives: (1) \textbf{No Aggregation}: No aggregation process between tasks. (2) \textbf{Summation}: Simply add the representation of different tasks. (3) \textbf{Linear Trans.}: Apply a linear transformation to transfer the task representation. (4)\textbf{Vanilla Fusion} \cite{pkef}: Utilize a variant of vanilla attention\cite{atrank}. (5) \textbf{Projection Fusion} \cite{dumn}: Explicitly extract the information through projection mechanism. It is worth noting that in order to directly compare the performance of the aggregation methods, all schemes have incorporated the contrastive learning between behaviors. As shown in Table \ref{tab:ablation_fusion}, We can observe that No Aggregation performs the worst overall among all the schemes, which fully demonstrates the importance of aggregation between tasks. Summation negatively impacts the distribution of representations, leading to relatively poor performance on the three datasets. Additionally, both Linear Trans. and Vanilla Fusion methods ignore the noise that may be introduced during aggregation, which can result in negative information transfer. Projection Fusion utilizes a projection mechanism, avoiding the introduction of harmful information while also mitigating the impact of distribution differences in representations. Finally, our proposed method demonstrates the best performance across all three datasets, highlighting the effectiveness of our scheme.


\subsubsection{Impact of the MTL module}
To further demonstrate the superiority of our proposed DFME in MTL, we compare it with some other MTL models: Shared Bottom \cite{sharebottom}, Bilinear \cite{ghcf}, MMOE \cite{mmoe}, PLE \cite{PLE}, MESI \cite{cigf} and PME \cite{pkef}. These MTL models are applied on top of COGCN for multi-behavior recommendation, which are named COGCN+SB, COGCN+MMOE, COGCN+PLE, COGCN+Bilinear, COGCN+MESI, and COGCN+PME respectively. In particular, We weight the $K$ separate representations generated by COGCN to meet the shared input requirement of the classical MTL models (i.e., Shared Bottom, MMOE, and PLE). The experimental results are presented in Table \ref{tab:ablation_mtl}. COGCN+SB achieves the poorest performance among all MTL models on all datasets. COGCN+MMOE and COGCN+PLE outperform COGCN+SB under the same conditions through gating mechanism, which demonstrates the necessity of task aggregation. COGCN+Bilinear shows better performance by using decoupled input and streamlined task prediction tower functions. COGCN+MESI further combines both decoupled inputs and task aggregation but performs worse than COGCN+Bilinear on Tmall dataset, which is possibly due to differences in feature distributions during aggregation. COGCN+PME further enforces alignment of task representation spaces during aggregation, significantly enhancing performance. Finally, our DFME consistently outperforms all other models on all datasets, verifying its effectiveness for MTL.


\begin{table}[t]
    \setlength{\abovecaptionskip}{0cm}
    \setlength{\belowcaptionskip}{0mm}
    \caption{Performances of different MTL module.}
    \centering
    \begin{threeparttable}
    \resizebox{\linewidth}{!}{
    \begin{tabular}{c|cccccc}
    \toprule
    \multirow{2}{*}{Model}&
    \multicolumn{2}{c}{Beibei}&\multicolumn{2}{c}{Taobao}&\multicolumn{2}{c}{Tmall}\cr
    \cmidrule(lr){2-3} \cmidrule(lr){4-5} \cmidrule(lr){6-7}
    &HR&NDCG&HR&NDCG&HR&NDCG\cr
    \midrule
    COGCN+SB & 0.0328 & 0.0159 & 0.0594 & 0.0305 & 0.0740 & 0.0403\cr
    COGCN+MMOE & 0.0557 & 0.0280 & 0.0610 & 0.0317 & 0.0838 & 0.0440\cr
    COGCN+PLE & 0.0546 & 0.0269 & 0.0649 & 0.0338 & 0.0801 & 0.0422\cr
    COGCN+Bilinear & 0.0629 & 0.0306 & 0.0986 & 0.0522 & 0.1559 & 0.0858\cr
    COGCN+MESI & 0.0885 & 0.0439 & 0.1039 & 0.0540 & 0.1487 & 0.0811\cr
    COGCN+PME & 0.1137 & 0.0572 & 0.1525 & 0.0800 & 0.1572 & 0.0862\cr
    \hline
    \textbf{COGCN+DFME}&\textbf{0.1694}&\textbf{0.0903}&\textbf{0.1552}&\textbf{0.0838}&\textbf{0.1755}&\textbf{0.0967}\cr
    \bottomrule
    \end{tabular}}
    \end{threeparttable}
    \vspace{-4mm}
    \label{tab:ablation_mtl}
\end{table}


\subsection{Compatibility Analysis}

\begin{table}[t]
    \setlength{\abovecaptionskip}{0cm}
    \setlength{\belowcaptionskip}{0mm}
    \caption{Compatibility performance of DFME with different models as backbones ("X+DFME" means using X to replace the COGCN in COPF).}
    \centering
    \begin{threeparttable}
    \resizebox{\linewidth}{!}{
    \begin{tabular}{c|cccccc}
    \toprule
    \multirow{2}{*}{Model}&
    \multicolumn{2}{c}{Beibei}&\multicolumn{2}{c}{Taobao}&\multicolumn{2}{c}{Tmall}\cr
    \cmidrule(lr){2-3} \cmidrule(lr){4-5} \cmidrule(lr){6-7}
    &HR&NDCG&HR&NDCG&HR&NDCG\cr
    \midrule
    LightGCN$_M$&0.0456&0.0224&0.0452&0.0246&0.0489&0.0297\cr
    LightGCN$_M$+DFME & \textbf{0.0928} & \textbf{0.0461} & \textbf{0.0928} & \textbf{0.0522} & \textbf{0.0865} & \textbf{0.0493}\cr
    \hline
    MB-CGCN&0.0579&0.0381&0.1233&0.0677&0.0984&0.0558\cr
    MB-CGCN+DFME & \textbf{0.1356} & \textbf{0.0747} & \textbf{0.1400} & \textbf{0.0764} & \textbf{0.1094} & \textbf{0.0585}\cr
    \Xhline{1px}
    CRGCN&0.0459&0.0324&0.0855&0.0439&0.0840&0.0442\cr
    CRGCN+DFME & \textbf{0.1253} & \textbf{0.0663} & \textbf{0.1322} & \textbf{0.0698} & \textbf{0.1308} & \textbf{0.0736}\cr
    \hline
    CIGF&0.0809&0.0400&0.0897&0.0474&0.1150&0.0636\cr
    CIGF+DFME & \textbf{0.0851} & \textbf{0.0435} & \textbf{0.1097} & \textbf{0.0600} & \textbf{0.1219} & \textbf{0.0704}\cr
    \hline
    PKEF&0.1130&0.0582&0.1385&0.0785&0.1277&0.0721\cr 
    PKEF+DFME & \textbf{0.1320} & \textbf{0.0701} & \textbf{0.1425} & \textbf{0.0794} & \textbf{0.1419} & \textbf{0.0810}\cr
    \bottomrule
    \end{tabular}}
    \end{threeparttable}
    \vspace{-3mm}
    \label{tab:compatible_mtl}
\end{table}

Our proposed DFME can serve as a general module applicable to most existing multi-behavior methods, and we validate this through a compatibility analysis. Specifically, we select some representative multi-behavior methods with MTL, like CRGCN, CIGF and PKEF, as well as multi-behavior methods without MTL, like LightGCN$_M$(LightGCN enhanced with the multi-behavioral graph) and MB-CGCN. Then, we replace their prediction modules with DFME, and compare them with the corresponding original models. The results are shown in Table \ref{tab:compatible_mtl}. As we can see, our proposed DFME improves the performance of all original models. The original LightGCN$_M$ and MB-CGCN benefit significantly from DFME due to their lack of MTL modules. Among multi-behavior methods with MTL, CRGCN exhibits more significant improvement. This is likely due to its original MTL module being relatively basic, which allows for greater compatibility. In contrast, CIGF and PKEF already have sizable MTL modules, resulting in a less pronounced improvement. Overall, the results fully demonstrate the wide compatibility and general applicability of our proposed DFME, which can be integrated into the multi-behavior methods to improve their performance. 

\subsection{Parameter Analysis}
\label{hyper}
\subsubsection{Impact of the number of layers}

\begin{figure}[t]
	\setlength{\belowcaptionskip}{0cm}
	\setlength{\abovecaptionskip}{0cm}
	\subfigure{
        \begin{minipage}[t]{0.47\linewidth}
        \centering
		\label{fig:coefficient_beibei} 
		\includegraphics[width=\textwidth]{figures/layer_hr.pdf}
        \end{minipage}}
	\subfigure{
        \begin{minipage}[t]{0.47\linewidth}
        \centering
		\label{fig:coefficient_taobao} 
		\includegraphics[width=\textwidth]{figures/layer_ndcg.pdf}
        \end{minipage}}
	\caption{Impact of GCN layers.}
        \vspace{-3mm}
	\label{fig:layer}
\end{figure}

We investigate the impact of high-order interaction information on model performance by varying the number of GCN layers within the range of \{1, 2, 3, 4\}. As shown in Figure \ref{fig:layer}, the optimal number of layers varies by dataset, which is determined by the relative amounts of noise and useful signals in the high-order information. However, when the number of layers exceeds three, performance significantly declines due to the over-smoothing problem of GCN.

\subsubsection{Impact of temperature hyperparameter}

\begin{figure}[t]
	\setlength{\belowcaptionskip}{0cm}
	\setlength{\abovecaptionskip}{0cm}
	\subfigure{
        \begin{minipage}[t]{0.47\linewidth}
        \centering
		\label{fig:layer_beibei} 
		\includegraphics[width=\textwidth]{figures/lhr.pdf}
        \end{minipage}}
	\subfigure{
        \begin{minipage}[t]{0.47\linewidth}
        \centering
		\label{fig:layer_taobao} 
		\includegraphics[width=\textwidth]{figures/temp.pdf}
        \end{minipage}}
	\caption{Impact of temperature hyperparameter.}
        \vspace{-3mm}
	\label{fig:temperature}
\end{figure}

We adjust the temperature hyperparameter in contrastive learning within the range of \{0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.8\} and plot the resulting curves (shown in Figure \ref{fig:temperature}). For all three datasets, excessively large temperature coefficients lead to poorer performance, which indicates that a large temperature value will reduce the ability to distinguish negative samples. Additionally, in the Taobao dataset, performance also declines when the temperature coefficient is too small (e.g., 0.1). This may be due to the imbalanced contribution of the samples.

\subsubsection{Impact of the scaling size}


\begin{figure}[t]
	\setlength{\belowcaptionskip}{0cm}
	\setlength{\abovecaptionskip}{0cm}
	\subfigure{
        \begin{minipage}[t]{0.47\linewidth}
        \centering
		\label{fig:scaling_hr} 
		\includegraphics[width=\textwidth]{figures/layer_hrindex.pdf}
        \end{minipage}}
	\subfigure{
        \begin{minipage}[t]{0.47\linewidth}
        \centering
		\label{fig:scaling_ndcg} 
		\includegraphics[width=\textwidth]{figures/layer_ndcgindex.pdf}
        \end{minipage}}
	\caption{Impact of the scaling size.}
        \vspace{-3mm}
	\label{fig:scaling}
\end{figure}

With $\beta$ fixed at 0.001, we investigate the impact of the scaling factor $\alpha$ on the forward propagation in multi-task learning. Figure \ref{fig:scaling} shows the results of our search in the range of \{0.1, 0.2, 0.4, 0.8\}. Across all datasets, COPF achieves the highest performance when the scaling factor is small (i.e., 0.1). Besides, the performance gradually decreases as the scaling factor increases, which is particularly evident in the Taobao dataset. These observations highlight the effectiveness of "fine-tuning" the representation space.
