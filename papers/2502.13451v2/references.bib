@article{McGeer01041990,
  author = {McGeer, Tad}, 
  title = {\href{http://ijr.sagepub.com/content/9/2/62.abstract}{Passive Dynamic Walking}}, 
  volume = {9}, 
  number = {2}, 
  pages = {62-82}, 
  year = {1990}, 
  doi = {10.1177/027836499000900206}, 
  URL = {http://ijr.sagepub.com/content/9/2/62.abstract}, 
  eprint = {http://ijr.sagepub.com/content/9/2/62.full.pdf+html}, 
  journal = {The International Journal of Robotics Research}
}




@article{kuang2024openfmnav,
  title={OpenFMNav: Towards Open-Set Zero-Shot Object Navigation via Vision-Language Foundation Models},
  author={Kuang, Yuxuan and Lin, Hai and Jiang, Meng},
  journal={arXiv preprint arXiv:2402.10670},
  year={2024}
}

@article{kalman1960new,
  title={A new approach to linear filtering and prediction problems},
  author={Kalman, R.E.},
  journal={Journal of Basic Engineering},
  volume={82},
  number={1},
  pages={35--45},
  year={1960},
  publisher={Citeseer}
}

@inproceedings{chen2019touchdown,
  title={Touchdown: Natural language navigation and spatial reasoning in visual street environments},
  author={Chen, Howard and Suhr, Alane and Misra, Dipendra and Snavely, Noah and Artzi, Yoav},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={12538--12547},
  year={2019}
}


@article{vasudevan2021talk2nav,
  title={Talk2nav: Long-range vision-and-language navigation with dual attention and spatial memory},
  author={Vasudevan, Arun Balajee and Dai, Dengxin and Van Gool, Luc},
  journal={International Journal of Computer Vision},
  pages={246--266},
  year={2021}
}

@inproceedings{zeng2021transporter,
  title={Transporter networks: Rearranging the visual world for robotic manipulation},
  author={Zeng, Andy and Florence, Pete and Tompson, Jonathan and Welker, Stefan and Chien, Jonathan and Attarian, Maria and Armstrong, Travis and Krasin, Ivan and Duong, Dan and Sindhwani, Vikas and others},
  booktitle={Conference on Robot Learning},
  pages={726--747},
  year={2021}
}

@inproceedings{ramakrishnan2022poni,
  title={Poni: Potential functions for objectgoal navigation with interaction-free learning},
  author={Ramakrishnan, Santhosh Kumar and Chaplot, Devendra Singh and Al-Halah, Ziad and Malik, Jitendra and Grauman, Kristen},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18890--18900},
  year={2022}
}
@article{chiang2023vicuna,
  title={Vicuna: An open-source chatbot impressing gpt-4 with 90\%* chatgpt quality},
  author={Chiang, Wei-Lin and Li, Zhuohan and Lin, Zi and Sheng, Ying and Wu, Zhanghao and Zhang, Hao and Zheng, Lianmin and Zhuang, Siyuan and Zhuang, Yonghao and Gonzalez, Joseph E and others},
  journal={See https://vicuna. lmsys. org (accessed 14 April 2023)},
  year={2023}
}



@article{zheng2023judging,
  title={Judging llm-as-a-judge with mt-bench and chatbot arena},
  author={Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric and others},
  journal={Advances in Neural Information Processing Systems},
  pages={46595--46623},
  year={2023}
}
@inproceedings{zhang20233d,
  title={3D-Aware Object Goal Navigation via Simultaneous Exploration and Identification},
  author={Zhang, Jiazhao and Dai, Liu and Meng, Fanpeng and Fan, Qingnan and Chen, Xuelin and Xu, Kai and Wang, He},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6672--6682},
  year={2023}
}
@article{sun2023eva,
  title={Eva-clip: Improved training techniques for clip at scale},
  author={Sun, Quan and Fang, Yuxin and Wu, Ledell and Wang, Xinlong and Cao, Yue},
  journal={arXiv preprint arXiv:2303.15389},
  year={2023}
}


@article{li2023llama,
  title={LLaMA-VID: An Image is Worth 2 Tokens in Large Language Models},
  author={Li, Yanwei and Wang, Chengyao and Jia, Jiaya},
  journal={arXiv preprint arXiv:2311.17043},
  year={2023}
}

@inproceedings{zhang2004extrinsic,
  title={Extrinsic calibration of a camera and laser range finder (improves camera calibration)},
  author={Zhang, Qilong and Pless, Robert},
  booktitle={2004 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  volume={3},
  pages={2301--2306},
  year={2004},
  organization={IEEE}
}

@article{sethian1999fast,
  title={Fast marching methods},
  author={Sethian, James A},
  journal={SIAM review},
  volume={41},
  number={2},
  pages={199--235},
  year={1999},
  publisher={SIAM}
}


@inproceedings{shah2023gnm,
  title={Gnm: A general navigation model to drive any robot},
  author={Shah, Dhruv and Sridhar, Ajay and Bhorkar, Arjun and Hirose, Noriaki and Levine, Sergey},
  booktitle={2023 IEEE International Conference on Robotics and Automation},
  pages={7226--7233},
  year={2023},
  organization={IEEE}
}

@inproceedings{liu2024volumetric,
  title={Volumetric Environment Representation for Vision-Language Navigation},
  author={Liu, Rui and Wang, Wenguan and Yang, Yi},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={16317--16328},
  year={2024}
}
@article{Zhang2024LanguageGuidedWM,
  title={Language-Guided World Models: A Model-Based Approach to AI Control},
  author={Alex Zhang and Khanh Nguyen and Jens Tuyls and Albert Lin and Karthik Narasimhan},
  journal={arXiv preprint arXiv:2402.01695},
  year={2024}
}
@article{bommasani2021opportunities,
  title={On the opportunities and risks of foundation models},
  author={Bommasani, Rishi and Hudson, Drew A and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and others},
  journal={arXiv preprint arXiv:2108.07258},
  year={2021}
}
@article{zhang2024vision,
  title={Vision-and-language navigation today and tomorrow: A survey in the era of foundation models},
  author={Zhang, Yue and Ma, Ziqiao and Li, Jialu and Qiao, Yanyuan and Wang, Zun and Chai, Joyce and Wu, Qi and Bansal, Mohit and Kordjamshidi, Parisa},
  journal={arXiv preprint arXiv:2407.07035},
  year={2024}
}
@article{long2024instructnav,
  title={InstructNav: Zero-shot System for Generic Instruction Navigation in Unexplored Environment},
  author={Long, Yuxing and Cai, Wenzhe and Wang, Hongcheng and Zhan, Guanqi and Dong, Hao},
  journal={arXiv preprint arXiv:2406.04882},
  year={2024}
}
@article{lin2024navcot,
  title={NavCoT: Boosting LLM-Based Vision-and-Language Navigation via Learning Disentangled Reasoning},
  author={Lin, Bingqian and Nie, Yunshuang and Wei, Ziming and Chen, Jiaqi and Ma, Shikui and Han, Jianhua and Xu, Hang and Chang, Xiaojun and Liang, Xiaodan},
  journal={arXiv preprint arXiv:2403.07376},
  year={2024}
}

@article{Wang2021GroundingLT,
  title={Grounding Language to Entities and Dynamics for Generalization in Reinforcement Learning},
  author={H. J. Austin Wang and Karthik Narasimhan},
  journal={arXiv preprint  arXiv:2101.07393},
  year={2021}
}



@inproceedings{macenski2020marathon,
  title={The marathon 2: A navigation system},
  author={Macenski, Steve and Mart{\'\i}n, Francisco and White, Ruffin and Clavero, Jonatan Gin{\'e}s},
  booktitle={2020 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  pages={2718--2725},
  year={2020},
  organization={IEEE}
}

@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(NeurIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})

@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(NeurIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})

% --------------------------------------------------------- VLN ------------------------------------------------- 

@inproceedings{anderson2018vision,
  title={Vision-and-language navigation: Interpreting visually-grounded navigation instructions in real environments},
  author={Anderson, Peter and Wu, Qi and Teney, Damien and Bruce, Jake and Johnson, Mark and S{\"u}nderhauf, Niko and Reid, Ian and Gould, Stephen and Van Den Hengel, Anton},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3674--3683},
  year={2018}
}


@inproceedings{krantz2020beyond,
  title={Beyond the nav-graph: Vision-and-language navigation in continuous environments},
  author={Krantz, Jacob and Wijmans, Erik and Majumdar, Arjun and Batra, Dhruv and Lee, Stefan},
  booktitle={European Conference on Computer Vision},
  pages={104--120},
  year={2020}
}

@inproceedings{qi2020reverie,
  title={Reverie: Remote embodied visual referring expression in real indoor environments},
  author={Qi, Yuankai and Wu, Qi and Anderson, Peter and Wang, Xin and Wang, William Yang and Shen, Chunhua and Hengel, Anton van den},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9982--9991},
  year={2020}
}

@article{he2021landmark,
  title={Landmark-RxR: Solving Vision-and-Language Navigation with Fine-Grained Alignment Supervision},
  author={He, Keji and Huang, Yan and Wu, Qi and Yang, Jianhua and An, Dong and Sima, Shuanglin and Wang, Liang},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={652--663},
  year={2021}
}

@inproceedings{shridhar2020alfred,
  title={Alfred: A benchmark for interpreting grounded instructions for everyday tasks},
  author={Shridhar, Mohit and Thomason, Jesse and Gordon, Daniel and Bisk, Yonatan and Han, Winson and Mottaghi, Roozbeh and Zettlemoyer, Luke and Fox, Dieter},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={10740--10749},
  year={2020}
}

@article{fried2018speaker,
  title={Speaker-follower models for vision-and-language navigation},
  author={Fried, Daniel and Hu, Ronghang and Cirik, Volkan and Rohrbach, Anna and Andreas, Jacob and Morency, Louis-Philippe and Berg-Kirkpatrick, Taylor and Saenko, Kate and Klein, Dan and Darrell, Trevor},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@inproceedings{koh2021pathdreamer,
  title={Pathdreamer: A world model for indoor navigation},
  author={Koh, Jing Yu and Lee, Honglak and Yang, Yinfei and Baldridge, Jason and Anderson, Peter},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={14738--14748},
  year={2021}
}

@inproceedings{wang2022less,
  title={Less is More: Generating Grounded Navigation Instructions from Landmarks},
  author={Wang, Su and Montgomery, Ceslee and Orbay, Jordi and Birodkar, Vighnesh and Faust, Aleksandra and Gur, Izzeddin and Jaques, Natasha and Waters, Austin and Baldridge, Jason and Anderson, Peter},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={15428--15438},
  year={2022}
}

@inproceedings{majumdar2020improving,
  title={Improving vision-and-language navigation with image-text pairs from the web},
  author={Majumdar, Arjun and Shrivastava, Ayush and Lee, Stefan and Anderson, Peter and Parikh, Devi and Batra, Dhruv},
  booktitle={European Conference on Computer Vision},
  pages={259--274},
  year={2020},
  organization={Springer}
}

@inproceedings{hao2020towards,
  title={Towards learning a generic agent for vision-and-language navigation via pre-training},
  author={Hao, Weituo and Li, Chunyuan and Li, Xiujun and Carin, Lawrence and Gao, Jianfeng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={13137--13146},
  year={2020}
}

@inproceedings{qi2021road,
  title={The road to know-where: An object-and-room informed sequential bert for indoor vision-language navigation},
  author={Qi, Yuankai and Pan, Zizheng and Hong, Yicong and Yang, Ming-Hsuan and van den Hengel, Anton and Wu, Qi},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1655--1664},
  year={2021}
}

@inproceedings{hong2021vln,
  title={\rvlnbert: A recurrent vision-and-language bert for navigation},
  author={Hong, Yicong and Wu, Qi and Qi, Yuankai and Rodriguez-Opazo, Cristian and Gould, Stephen},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={1643--1653},
  year={2021}
}

@article{moudgil2021soat,
  title={Soat: A scene-and object-aware transformer for vision-and-language navigation},
  author={Moudgil, Abhinav and Majumdar, Arjun and Agrawal, Harsh and Lee, Stefan and Batra, Dhruv},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={7357--7367},
  year={2021}
}

@inproceedings{guhur2021airbert,
  title={Airbert: In-domain pretraining for vision-and-language navigation},
  author={Guhur, Pierre-Louis and Tapaswi, Makarand and Chen, Shizhe and Laptev, Ivan and Schmid, Cordelia},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1634--1643},
  year={2021}
}

@inproceedings{qi2020object,
  title={Object-and-action aware model for visual language navigation},
  author={Qi, Yuankai and Pan, Zizheng and Zhang, Shengping and Hengel, Anton van den and Wu, Qi},
  booktitle={European Conference on Computer Vision},
  pages={303--317},
  year={2020}
}

@inproceedings{gao2021room,
  title={Room-and-object aware knowledge reasoning for remote embodied referring expression},
  author={Gao, Chen and Chen, Jinyu and Liu, Si and Wang, Luting and Zhang, Qiong and Wu, Qi},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3064--3073},
  year={2021}
}

@article{anderson2019chasing,
  title={Chasing ghosts: Instruction following as bayesian state tracking},
  author={Anderson, Peter and Shrivastava, Ayush and Parikh, Devi and Batra, Dhruv and Lee, Stefan},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{hong2020language,
  title={Language and visual entity relationship graph for agent navigation},
  author={Hong, Yicong and Rodriguez, Cristian and Qi, Yuankai and Wu, Qi and Gould, Stephen},
  journal={Advances in Neural Information Processing Systems},
  pages={7685--7696},
  year={2020}
}

@article{deng2020evolving,
  title={Evolving graphical planner: Contextual global planning for vision-and-language navigation},
  author={Deng, Zhiwei and Narasimhan, Karthik and Russakovsky, Olga},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={20660--20672},
  year={2020}
}

@inproceedings{zhu2020babywalk,
    title = "{B}aby{W}alk: Going Farther in Vision-and-Language Navigation by Taking Baby Steps",
    author = "Zhu, Wang and Hu, Hexiang and Chen, Jiacheng and Deng, Zhiwei and Jain, Vihan and Ie, Eugene and Sha, Fei",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    year = "2020",
    publisher = "Association for Computational Linguistics",
    pages = "2539--2556",
}

@article{hong2020sub,
  title={Sub-Instruction Aware Vision-and-Language Navigation},
  author={Hong, Yicong and Rodriguez-Opazo, Cristian and Wu, Qi and Gould, Stephen},
  journal={arXiv preprint arXiv:2004.02707},
  year={2020}
}

@article{li2022incorporating,
  title={Incorporating External Knowledge Reasoning for Vision-and-Language Navigation with Assistantâ€™s Help},
  author={Li, Xin and Zhang, Yu and Yuan, Weilin and Luo, Junren},
  journal={Applied Sciences},
  volume={12},
  number={14},
  pages={7053},
  year={2022},
  publisher={MDPI}
}

@InProceedings{VLN_LAD_2023,
    author    = {Li, Mingxiao and Wang, Zehao and Tuytelaars, Tinne and Moens, Marie-Francine},
    title     = {Layout-aware Dreamer for Embodied Referring Expression Grounding},
    booktitle = {AAAI},
    year      = {2023}
}

@inproceedings{chen2021topological,
  title={Topological planning with transformers for vision-and-language navigation},
  author={Chen, Kevin and Chen, Junshen K and Chuang, Jo and V{\'a}zquez, Marynel and Savarese, Silvio},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={11276--11286},
  year={2021}
}

@article{chen2021history,
  title={History aware multimodal transformer for vision-and-language navigation},
  author={Chen, Shizhe and Guhur, Pierre-Louis and Schmid, Cordelia and Laptev, Ivan},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={5834--5847},
  year={2021}
}

@article{ma2019self,
  title={Self-monitoring navigation agent via auxiliary progress estimation},
  author={Ma, Chih-Yao and Lu, Jiasen and Wu, Zuxuan and AlRegib, Ghassan and Kira, Zsolt and Socher, Richard and Xiong, Caiming},
  journal={arXiv preprint arXiv:1901.03035},
  year={2019}
}

@inproceedings{zhu2020vision,
  title={Vision-language navigation with self-supervised auxiliary reasoning tasks},
  author={Zhu, Fengda and Zhu, Yi and Chang, Xiaojun and Liang, Xiaodan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10012--10022},
  year={2020}
}

@inproceedings{wang2018look,
  title={Look before you leap: Bridging model-free and model-based reinforcement learning for planned-ahead vision-and-language navigation},
  author={Wang, Xin and Xiong, Wenhan and Wang, Hongmin and Wang, William Yang},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={37--53},
  year={2018}
}

@inproceedings{wang2019reinforced,
  title={Reinforced cross-modal matching and self-supervised imitation learning for vision-language navigation},
  author={Wang, Xin and Huang, Qiuyuan and Celikyilmaz, Asli and Gao, Jianfeng and Shen, Dinghan and Wang, Yuan-Fang and Wang, William Yang and Zhang, Lei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6629--6638},
  year={2019}
}

@inproceedings{wang2020active,
  title={Active visual information gathering for vision-language navigation},
  author={Wang, Hanqing and Wang, Wenguan and Shu, Tianmin and Liang, Wei and Shen, Jianbing},
  booktitle={European Conference on Computer Vision},
  pages={307--322},
  year={2020},
  organization={Springer}
}

@inproceedings{krantz2021waypoint,
  title={Waypoint models for instruction-guided navigation in continuous environments},
  author={Krantz, Jacob and Gokaslan, Aaron and Batra, Dhruv and Lee, Stefan and Maksymets, Oleksandr},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={15162--15171},
  year={2021}
}

@inproceedings{an2021neighbor,
  title={Neighbor-view enhanced model for vision and language navigation},
  author={An, Dong and Qi, Yuankai and Huang, Yan and Wu, Qi and Wang, Liang and Tan, Tieniu},
  booktitle={Proceedings of the 29th ACM International Conference on Multimedia},
  pages={5101--5109},
  year={2021}
}

@inproceedings{tan2019learning,
  title={Learning to Navigate Unseen Environments: Back Translation with Environmental Dropout},
  author={Tan, Hao and Yu, Licheng and Bansal, Mohit},
  booktitle={Proceedings of NAACL-HLT},
  pages={2610--2621},
  year={2019}
}

@inproceedings{qiao2022hop,
  title={HOP: History-and-Order Aware Pre-training for Vision-and-Language Navigation},
  author={Qiao, Yanyuan and Qi, Yuankai and Hong, Yicong and Yu, Zheng and Wang, Peng and Wu, Qi},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={15418--15427},
  year={2022}
}

@inproceedings{zhu2021multimodal,
  title={Multimodal Text Style Transfer for Outdoor Vision-and-Language Navigation},
  author={Zhu, Wanrong and Wang, Xin and Fu, Tsu-Jui and Yan, An and Narayana, Pradyumna and Sone, Kazoo and Basu, Sugato and Wang, William Yang},
  booktitle={EACL},
  year={2021}
}

@inproceedings{liu2021vision,
  title={Vision-language navigation with random environmental mixup},
  author={Liu, Chong and Zhu, Fengda and Chang, Xiaojun and Liang, Xiaodan and Ge, Zongyuan and Shen, Yi-Dong},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1644--1654},
  year={2021}
}

@inproceedings{li2022envedit,
  title={EnvEdit: Environment Editing for Vision-and-Language Navigation},
  author={Li, Jialu and Tan, Hao and Bansal, Mohit},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={15407--15417},
  year={2022}
}

@inproceedings{chen2022think,
  title={Think Global, Act Local: Dual-scale Graph Transformer for Vision-and-Language Navigation},
  author={Chen, Shizhe and Guhur, Pierre-Louis and Tapaswi, Makarand and Schmid, Cordelia and Laptev, Ivan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={16537--16547},
  year={2022}
}

@inproceedings{wang2021structured,
  title={Structured scene memory for vision-language navigation},
  author={Wang, Hanqing and Wang, Wenguan and Liang, Wei and Xiong, Caiming and Shen, Jianbing},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8455--8464},
  year={2021}
}

@inproceedings{georgakis2022cross,
  title={Cross-modal Map Learning for Vision and Language Navigation},
  author={Georgakis, Georgios and Schmeckpeper, Karl and Wanchoo, Karan and Dan, Soham and Miltsakaki, Eleni and Roth, Dan and Daniilidis, Kostas},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={15460--15470},
  year={2022}
}

@inproceedings{zhao2022target,
  title={Target-Driven Structured Transformer Planner for Vision-Language Navigation},
  author={Zhao, Yusheng and Chen, Jinyu and Gao, Chen and Wang, Wenguan and Yang, Lirong and Ren, Haibing and Xia, Huaxia and Liu, Si},
  booktitle={Proceedings of the 30th ACM International Conference on Multimedia},
  pages={4194--4203},
  year={2022}
}

@inproceedings{chen2022reinforced,
  title={Reinforced Structured State-Evolution for Vision-Language Navigation},
  author={Chen, Jinyu and Gao, Chen and Meng, Erli and Zhang, Qiong and Liu, Si},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={15450--15459},
  year={2022}
}

@inproceedings{lin2021scene,
  title={Scene-intuitive agent for remote embodied visual grounding},
  author={Lin, Xiangru and Li, Guanbin and Yu, Yizhou},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={7036--7045},
  year={2021}
}

@inproceedings{li2022clear,
  title={CLEAR: Improving Vision-Language Navigation with Cross-Lingual, Environment-Agnostic Representations},
  author={Li, Jialu and Tan, Hao and Bansal, Mohit},
  booktitle={Findings of the Association for Computational Linguistics: NAACL 2022},
  pages={633--649},
  year={2022}
}

@inproceedings{hong2022bridging,
  title={Bridging the Gap Between Learning in Discrete and Continuous Environments for Vision-and-Language Navigation},
  author={Hong, Yicong and Wang, Zun and Wu, Qi and Gould, Stephen},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={15439--15449},
  year={2022}
}



@inproceedings{wu2022cross,
  title={Cross-modal Semantic Alignment Pre-training for Vision-and-Language Navigation},
  author={Wu, Siying and Fu, Xueyang and Wu, Feng and Zha, Zheng-Jun},
  booktitle={Proceedings of the ACM International Conference on Multimedia},
  pages={4233--4241},
  year={2022}
}

@inproceedings{gu2022vision,
  title={Vision-and-Language Navigation: A Survey of Tasks, Methods, and Future Directions},
  author={Gu, Jing and Stefani, Eliana and Wu, Qi and Thomason, Jesse and Wang, Xin},
  booktitle={Proceedings of the Annual Meeting of the Association for Computational Linguistics},
  pages={7606--7623},
  year={2022}
}

@article{parvaneh2020counterfactual,
  title={Counterfactual vision-and-language navigation: Unravelling the unseen},
  author={Parvaneh, Amin and Abbasnejad, Ehsan and Teney, Damien and Shi, Javen Qinfeng and van den Hengel, Anton},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={5296--5307},
  year={2020}
}

@inproceedings{fu2020counterfactual,
  title={Counterfactual vision-and-language navigation via adversarial path sampler},
  author={Fu, Tsu-Jui and Wang, Xin Eric and Peterson, Matthew F and Grafton, Scott T and Eckstein, Miguel P and Wang, William Yang},
  booktitle={European Conference on Computer Vision},
  pages={71--86},
  year={2020},
  organization={Springer}
}

@inproceedings{wang2020environment,
  title={Environment-agnostic multitask learning for natural language grounded navigation},
  author={Wang, Xin Eric and Jain, Vihan and Ie, Eugene and Wang, William Yang and Kozareva, Zornitsa and Ravi, Sujith},
  booktitle={European Conference on Computer Vision},
  pages={413--430},
  year={2020},
  organization={Springer}
}

@inproceedings{Zhu2022diagnosing,
  title={Diagnosing Vision-and-Language Navigation: What Really Matters},
  author={Wanrong Zhu and Yuankai Qi and P. Narayana and Kazoo Sone and Sugato Basu and Xin Eric Wang and Qi Wu and Miguel P. Eckstein and William Yang Wang},
  booktitle={NAACL},
  year={2022}
}

@inproceedings{pashevich2021episodic,
  title={Episodic transformer for vision-and-language navigation},
  author={Pashevich, Alexander and Schmid, Cordelia and Sun, Chen},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={15942--15952},
  year={2021}
}

@inproceedings{wang2022counterfactual,
  title={Counterfactual Cycle-Consistent Learning for Instruction Following and Generation in Vision-Language Navigation},
  author={Wang, Hanqing and Liang, Wei and Shen, Jianbing and Van Gool, Luc and Wang, Wenguan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={15471--15481},
  year={2022}
}

@inproceedings{zhang2022lovis,
  title={LOViS: Learning Orientation and Visual Signals for Vision and Language Navigation},
  author={Zhang, Yue and Kordjamshidi, Parisa},
  booktitle={Proceedings of the 29th International Conference on Computational Linguistics},
  pages={5745--5754},
  year={2022}
}

@inproceedings{hu2019you,
  title={Are You Looking? Grounding to Multiple Modalities in Vision-and-Language Navigation},
  author={Hu, Ronghang and Fried, Daniel and Rohrbach, Anna and Klein, Dan and Darrell, Trevor and Saenko, Kate},
  booktitle={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  pages={6551--6557},
  year={2019}
}

% --------------------------------------------------------- Mapping --------------------------------------------------------

@article{fuentes2015visual,
  title={Visual simultaneous localization and mapping: a survey},
  author={Fuentes-Pacheco, Jorge and Ruiz-Ascencio, Jos{\'e} and Rend{\'o}n-Mancha, Juan Manuel},
  journal={Artificial intelligence review},
  volume={43},
  number={1},
  pages={55--81},
  year={2015},
  publisher={Springer}
}

@inproceedings{henriques2018mapnet,
  title={Mapnet: An allocentric spatial memory for mapping environments},
  author={Henriques, Joao F and Vedaldi, Andrea},
  booktitle={proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={8476--8484},
  year={2018}
}

@inproceedings{cartillier2021semantic,
  title={Semantic mapnet: Building allocentric semantic maps and representations from egocentric views},
  author={Cartillier, Vincent and Ren, Zhile and Jain, Neha and Lee, Stefan and Essa, Irfan and Batra, Dhruv},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={2},
  pages={964--972},
  year={2021}
}

@inproceedings{chaplot2019learning,
  title={Learning To Explore Using Active Neural SLAM},
  author={Chaplot, Devendra Singh and Gandhi, Dhiraj and Gupta, Saurabh and Gupta, Abhinav and Salakhutdinov, Ruslan},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@article{chaplot2020object,
  title={Object goal navigation using goal-oriented semantic exploration},
  author={Chaplot, Devendra Singh and Gandhi, Dhiraj Prakashchand and Gupta, Abhinav and Salakhutdinov, Russ R},
  journal={Advances in Neural Information Processing Systems},
  pages={4247--4258},
  year={2020}
}

@inproceedings{chaplot2020neural,
  title={Neural topological slam for visual navigation},
  author={Chaplot, Devendra Singh and Salakhutdinov, Ruslan and Gupta, Abhinav and Gupta, Saurabh},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={12875--12884},
  year={2020}
}

@article{galindo2008robot,
  title={Robot task planning using semantic maps},
  author={Galindo, Cipriano and Fern{\'a}ndez-Madrigal, Juan-Antonio and Gonz{\'a}lez, Javier and Saffiotti, Alessandro},
  journal={Robotics and autonomous systems},
  volume={56},
  number={11},
  pages={955--966},
  year={2008},
  publisher={Elsevier}
}

@inproceedings{irshad2021sasra,
  title={Sasra: Semantically-aware spatio-temporal reasoning agent for vision-and-language navigation in continuous environments},
  author={Irshad, Muhammad Zubair and Mithun, Niluthpol Chowdhury and Seymour, Zachary and Chiu, Han-Pang and Samarasekera, Supun and Kumar, Rakesh},
  booktitle={2022 26th International Conference on Pattern Recognition},
  pages={4065--4071},
  year={2022}
}
@article{wani2020multion,
  title={Multion: Benchmarking semantic map memory using multi-object navigation},
  author={Wani, Saim and Patel, Shivansh and Jain, Unnat and Chang, Angel and Savva, Manolis},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={9700--9712},
  year={2020}
}

@inproceedings{min2021film,
  title={FILM: Following Instructions in Language with Modular Methods},
  author={Min, So Yeon and Chaplot, Devendra Singh and Ravikumar, Pradeep Kumar and Bisk, Yonatan and Salakhutdinov, Ruslan},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@article{blanco2008toward,
  title={Toward a unified Bayesian approach to hybrid metric--topological SLAM},
  author={Blanco, Jose-Luis and Fern{\'a}ndez-Madrigal, Juan-Antonio and Gonzalez, Javier},
  journal={IEEE Transactions on Robotics},
  volume={24},
  number={2},
  pages={259--270},
  year={2008},
  publisher={IEEE}
}

@inproceedings{konolige2011navigation,
  title={Navigation in hybrid metric-topological maps},
  author={Konolige, Kurt and Marder-Eppstein, Eitan and Marthi, Bhaskara},
  booktitle={2011 IEEE International Conference on Robotics and Automation},
  pages={3041--3047},
  year={2011},
  organization={IEEE}
}

@inproceedings{gomez2020hybrid,
  title={Hybrid topological and 3d dense mapping through autonomous exploration for large indoor environments},
  author={Gomez, Clara and Fehr, Marius and Millane, Alex and Hernandez, Alejandra C and Nieto, Juan and Barber, Ramon and Siegwart, Roland},
  booktitle={2020 IEEE International Conference on Robotics and Automation},
  pages={9673--9679},
  year={2020},
  organization={IEEE}
}

@inproceedings{niijima2020city,
  title={City-scale grid-topological hybrid maps for autonomous mobile robot navigation in urban area},
  author={Niijima, Shun and Umeyama, Ryusuke and Sasaki, Yoko and Mizoguchi, Hiroshi},
  booktitle={2020 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  pages={2065--2071},
  year={2020},
  organization={IEEE}
}

@inproceedings{an2023bevbert,
  title={Bevbert: Multimodal map pre-training for language-guided navigation},
  author={An, Dong and Qi, Yuankai and Li, Yangguang and Huang, Yan and Wang, Liang and Tan, Tieniu and Shao, Jing},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={2737--2748},
  year={2023}
}

% --------------------------------------------------------- Pretraining --------------------------------------------------------

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International Conference on Machine Learning},
  pages={8748--8763},
  year={2021}
}

@inproceedings{li2021supervision,
  title={Supervision Exists Everywhere: A Data Efficient Contrastive Language-Image Pre-training Paradigm},
  author={Li, Yangguang and Liang, Feng and Zhao, Lichen and Cui, Yufeng and Ouyang, Wanli and Shao, Jing and Yu, Fengwei and Yan, Junjie},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@inproceedings{shen2021much,
  title={How Much Can CLIP Benefit Vision-and-Language Tasks?},
  author={Shen, Sheng and Li, Liunian Harold and Tan, Hao and Bansal, Mohit and Rohrbach, Anna and Chang, Kai-Wei and Yao, Zhewei and Keutzer, Kurt},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@article{lu2019vilbert,
  title={Vilbert: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks},
  author={Lu, Jiasen and Batra, Dhruv and Parikh, Devi and Lee, Stefan},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@inproceedings{tan2019lxmert,
  title={LXMERT: Learning Cross-Modality Encoder Representations from Transformers},
  author={Tan, Hao and Bansal, Mohit},
  booktitle={Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing},
  pages={5100--5111},
  year={2019}
}

@inproceedings{li2020oscar,
  title={Oscar: Object-semantics aligned pre-training for vision-language tasks},
  author={Li, Xiujun and Yin, Xi and Li, Chunyuan and Zhang, Pengchuan and Hu, Xiaowei and Zhang, Lei and Wang, Lijuan and Hu, Houdong and Dong, Li and Wei, Furu and others},
  booktitle={European Conference on Computer Vision},
  pages={121--137},
  year={2020},
  organization={Springer}
}

@inproceedings{zhang2021vinvl,
  title={Vinvl: Revisiting visual representations in vision-language models},
  author={Zhang, Pengchuan and Li, Xiujun and Hu, Xiaowei and Yang, Jianwei and Zhang, Lei and Wang, Lijuan and Choi, Yejin and Gao, Jianfeng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5579--5588},
  year={2021}
}

@inproceedings{jiang2020defense,
  title={In defense of grid features for visual question answering},
  author={Jiang, Huaizu and Misra, Ishan and Rohrbach, Marcus and Learned-Miller, Erik and Chen, Xinlei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10267--10276},
  year={2020}
}

@article{huang2020pixel,
  title={Pixel-bert: Aligning image pixels with text by deep multi-modal transformers},
  author={Huang, Zhicheng and Zeng, Zhaoyang and Liu, Bei and Fu, Dongmei and Fu, Jianlong},
  journal={arXiv preprint arXiv:2004.00849},
  year={2020}
}

@inproceedings{kim2021vilt,
  title={Vilt: Vision-and-language transformer without convolution or region supervision},
  author={Kim, Wonjae and Son, Bokyung and Kim, Ildoo},
  booktitle={International Conference on Machine Learning},
  pages={5583--5594},
  year={2021}
}

@article{zeng2021multi,
  title={Multi-Grained Vision Language Pre-Training: Aligning Texts with Visual Concepts},
  author={Zeng, Yan and Zhang, Xinsong and Li, Hang},
  journal={arXiv preprint arXiv:2111.08276},
  year={2021}
}

@inproceedings{huang2021seeing,
  title={Seeing out of the box: End-to-end pre-training for vision-language representation learning},
  author={Huang, Zhicheng and Zeng, Zhaoyang and Huang, Yupan and Liu, Bei and Fu, Dongmei and Fu, Jianlong},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={12976--12985},
  year={2021}
}

@inproceedings{lin2014microsoft,
  title={Microsoft coco: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={European conference on computer vision},
  pages={740--755},
  year={2014},
  organization={Springer}
}

@article{krishna2017visual,
  title={Visual genome: Connecting language and vision using crowdsourced dense image annotations},
  author={Krishna, Ranjay and Zhu, Yuke and Groth, Oliver and Johnson, Justin and Hata, Kenji and Kravitz, Joshua and Chen, Stephanie and Kalantidis, Yannis and Li, Li-Jia and Shamma, David A and others},
  journal={International journal of computer vision},
  volume={123},
  number={1},
  pages={32--73},
  year={2017},
  publisher={Springer}
}

@inproceedings{anderson2018bottom,
  title={Bottom-up and top-down attention for image captioning and visual question answering},
  author={Anderson, Peter and He, Xiaodong and Buehler, Chris and Teney, Damien and Johnson, Mark and Gould, Stephen and Zhang, Lei},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={6077--6086},
  year={2018}
}

@article{ren2015faster,
  title={Faster r-cnn: Towards real-time object detection with region proposal networks},
  author={Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}

% --------------------------------------------------------- autonomous driving ----------------------------------------------------------------



% --------------------------------------------------------- others ----------------------------------------------------------------

@inproceedings{chang2017matterport3d,
  title={Matterport3D: Learning from RGB-D Data in Indoor Environments},
  author={Chang, Angel and Dai, Angela and Funkhouser, Thomas and Halber, Maciej and Niebner, Matthias and Savva, Manolis and Song, Shuran and Zeng, Andy and Zhang, Yinda},
  booktitle={International Conference on 3D Vision},
  pages={667--676},
  year={2017}
}

@article{anderson2018evaluation,
  title={On evaluation of embodied navigation agents},
  author={Anderson, Peter and Chang, Angel and Chaplot, Devendra Singh and Dosovitskiy, Alexey and Gupta, Saurabh and Koltun, Vladlen and Kosecka, Jana and Malik, Jitendra and Mottaghi, Roozbeh and Savva, Manolis and others},
  journal={arXiv preprint arXiv:1807.06757},
  year={2018}
}

@article{ilharco2019general,
  title={General evaluation for instruction conditioned navigation using dynamic time warping},
  author={Ilharco, Gabriel and Jain, Vihan and Ku, Alexander and Ie, Eugene and Baldridge, Jason},
  journal={arXiv preprint arXiv:1907.05446},
  year={2019}
}

@inproceedings{dosovitskiy2020image,
  title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@inproceedings{deng2009imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={2009 IEEE conference on computer vision and pattern recognition},
  pages={248--255},
  year={2009},
  organization={Ieee}
}

@article{liu2019roberta,
  title={Roberta: A robustly optimized bert pretraining approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1907.11692},
  year={2019}
}

@inproceedings{zhao2021surprising,
  title={The surprising effectiveness of visual odometry techniques for embodied pointgoal navigation},
  author={Zhao, Xiaoming and Agrawal, Harsh and Batra, Dhruv and Schwing, Alexander G},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={16127--16136},
  year={2021}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{kenton2019bert,
  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Kenton, Jacob Devlin Ming-Wei Chang and Toutanova, Lee Kristina},
  booktitle={Proceedings of NAACL-HLT},
  pages={4171--4186},
  year={2019}
}

@article{arevalo2017gated,
  title={Gated Multimodal Units for Information Fusion},
  author={Arevalo, John and Solorio, Thamar and Montes-y-G{\'o}mez, Manuel and Gonz{\'a}lez, Fabio A},
  year={2017}
}

@article{jiang2018rednet,
  title={Rednet: Residual encoder-decoder network for indoor rgb-d semantic segmentation},
  author={Jiang, Jindong and Zheng, Lunan and Luo, Fei and Zhang, Zhijun},
  journal={arXiv preprint arXiv:1806.01054},
  year={2018}
}

@article{koh2022simple,
  title={Simple and Effective Synthesis of Indoor 3D Scenes},
  author={Koh, Jing Yu and Agrawal, Harsh and Batra, Dhruv and Tucker, Richard and Waters, Austin and Lee, Honglak and Yang, Yinfei and Baldridge, Jason and Anderson, Peter}
}

@inproceedings{philion2020lift,
  title={Lift, splat, shoot: Encoding images from arbitrary camera rigs by implicitly unprojecting to 3d},
  author={Philion, Jonah and Fidler, Sanja},
  booktitle={European Conference on Computer Vision},
  pages={194--210},
  year={2020},
  organization={Springer}
}

@inproceedings{schulter2018learning,
  title={Learning to look around objects for top-view representations of outdoor scenes},
  author={Schulter, Samuel and Zhai, Menghua and Jacobs, Nathan and Chandraker, Manmohan},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={787--802},
  year={2018}
}

@article{li2022bevformer,
  title={BEVFormer: Learning Bird's-Eye-View Representation from Multi-Camera Images via Spatiotemporal Transformers},
  author={Li, Zhiqi and Wang, Wenhai and Li, Hongyang and Xie, Enze and Sima, Chonghao and Lu, Tong and Yu, Qiao and Dai, Jifeng},
  journal={arXiv preprint arXiv:2203.17270},
  year={2022}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@article{chaplot2021seal,
  title={SEAL: Self-supervised embodied active learning using exploration and 3d consistency},
  author={Chaplot, Devendra Singh and Dalal, Murtaza and Gupta, Saurabh and Malik, Jitendra and Salakhutdinov, Russ R},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={13086--13098},
  year={2021}
}

@inproceedings{YLan2010pooling,
  author    = {YLan Boureau and
               Jean Ponce and
               Yann LeCun},
  title     = {A Theoretical Analysis of Feature Pooling in Visual Recognition},
  booktitle = {Proceedings of the 27th International Conference on Machine Learning
               (ICML-10), June 21-24, 2010, Haifa, Israel},
  pages     = {111--118},
  year      = {2010},
}

@inproceedings{savva2019habitat,
  title={Habitat: A platform for embodied ai research},
  author={Savva, Manolis and Kadian, Abhishek and Maksymets, Oleksandr and Zhao, Yili and Wijmans, Erik and Jain, Bhavana and Straub, Julian and Liu, Jia and Koltun, Vladlen and Malik, Jitendra and others},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={9339--9347},
  year={2019}
}

@inproceedings{kwon2021visual,
  title={Visual graph memory with unsupervised representation for visual navigation},
  author={Kwon, Obin and Kim, Nuri and Choi, Yunho and Yoo, Hwiyeon and Park, Jeongho and Oh, Songhwai},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={15890--15899},
  year={2021}
}

@inproceedings{loshchilov2018decoupled,
  title={Decoupled Weight Decay Regularization},
  author={Loshchilov, Ilya and Hutter, Frank},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@article{yao2022react,
  title={React: Synergizing reasoning and acting in language models},
  author={Yao, Shunyu and Zhao, Jeffrey and Yu, Dian and Du, Nan and Shafran, Izhak and Narasimhan, Karthik and Cao, Yuan},
  journal={arXiv preprint arXiv:2210.03629},
  year={2022}
}

@book{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}

@inproceedings{parisotto2020stabilizing,
  title={Stabilizing transformers for reinforcement learning},
  author={Parisotto, Emilio and Song, Francis and Rae, Jack and Pascanu, Razvan and Gulcehre, Caglar and Jayakumar, Siddhant and Jaderberg, Max and Kaufman, Raphael Lopez and Clark, Aidan and Noury, Seb and others},
  booktitle={International conference on machine learning},
  pages={7487--7498},
  year={2020}
}

@inproceedings{ross2011reduction,
  title={A reduction of imitation learning and structured prediction to no-regret online learning},
  author={Ross, St{\'e}phane and Gordon, Geoffrey and Bagnell, Drew},
  booktitle={Proceedings of the fourteenth international conference on artificial intelligence and statistics},
  pages={627--635},
  year={2011},
  organization={JMLR Workshop and Conference Proceedings}
}

@article{li2019robust,
  title={Robust navigation with language pretraining and stochastic sampling},
  author={Li, Xiujun and Li, Chunyuan and Xia, Qiaolin and Bisk, Yonatan and Celikyilmaz, Asli and Gao, Jianfeng and Smith, Noah and Choi, Yejin},
  journal={arXiv preprint arXiv:1909.02244},
  year={2019}
}

@article{bengio2015scheduled,
  title={Scheduled sampling for sequence prediction with recurrent neural networks},
  author={Bengio, Samy and Vinyals, Oriol and Jaitly, Navdeep and Shazeer, Noam},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}

%-------------------------------------------------ZSON--------------------------------------------------

@article{Kadian2019AreWM,
  title={Are We Making Real Progress in Simulated Environments? Measuring the Sim2Real Gap in Embodied Visual Navigation},
  author={Abhishek Kadian and Joanne Truong and Aaron Gokaslan and Alexander Clegg and Erik Wijmans and Stefan Lee and Manolis Savva and S. Chernova and Dhruv Batra},
  journal={arXiv},
  year={2019},
}

@article{Zhu2020ZeroSD,
  title={Zero Shot Detection},
  author={Pengkai Zhu and Hanxiao Wang and Venkatesh Saligrama},
  journal={IEEE Transactions on Circuits and Systems for Video Technology},
  year={2020},
}

@article{wortsman2021robust,
  title={Robust fine-tuning of zero-shot models},
  author={Wortsman, Mitchell and Ilharco, Gabriel and Li, Mike and Kim, Jong Wook and Hajishirzi, Hannaneh and Farhadi, Ali and Namkoong, Hongseok and Schmidt, Ludwig},
  journal={arXiv preprint arXiv:2109.01903},
  year={2021}
}

@article{habitat19iccv,
  title     =     {Habitat: {A} {P}latform for {E}mbodied {AI} {R}esearch},
  author    =     {Manolis Savva and Abhishek Kadian and Oleksandr Maksymets and Yili Zhao and Erik Wijmans and Bhavana Jain and Julian Straub and Jia Liu and Vladlen Koltun and Jitendra Malik and Devi Parikh and Dhruv Batra},
  journal =     {ICCV},
  year      =     {2019}
}

@article{Deitke2020RoboTHOR,
  title={RoboTHOR: An Open Simulation-to-Real Embodied AI Platform},
  author={Matt Deitke and Winson Han and Alvaro Herrasti and Aniruddha Kembhavi and Eric Kolve and Roozbeh Mottaghi and Jordi Salvador and Dustin Schwenk and Eli VanderBilt and Matthew Wallingford and Luca Weihs and Mark Yatskar and Ali Farhadi},
  journal={CVPR},
  year={2020},
}

@article{Khandelwal2021Simple,
  title={Simple but Effective: CLIP Embeddings for Embodied AI},
  author={Apoorv Khandelwal and Luca Weihs and Roozbeh Mottaghi and Aniruddha Kembhavi},
  journal={arXiv},
  year={2021},
}

@article{majumdar2022zson,
  title={Zson: Zero-shot object-goal navigation using multimodal goal embeddings},
  author={Majumdar, Arjun and Aggarwal, Gunjan and Devnani, Bhavika and Hoffman, Judy and Batra, Dhruv},
  journal={arXiv preprint arXiv:2206.12403},
  year={2022}
}

@article {gadre2022cow,
	title={CLIP on Wheels: Open-Vocabulary Models are (Almost) Zero-Shot Object Navigators},
	author={Gadre, Samir Yitzhak and Wortsman, Mitchell and Ilharco, Gabriel and Schmidt, Ludwig and Song, Shuran},
	journal={arXiv},
	year={2022}
}

@InProceedings{zero_experience,
    author    = {Al-Halah, Ziad and Ramakrishnan, Santhosh Kumar and Grauman, Kristen},
    title     = {Zero Experience Required: Plug \& Play Modular Transfer Learning for Semantic Visual Navigation},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2022},
    pages     = {17031-17041}
}

@article{gadre2022cows,
  title={CoWs on Pasture: Baselines and benchmarks for language-driven zero-shot object navigation},
  author={Gadre, SY and Wortsman, M and Ilharco, G and Schmidt, L and Song, S},
  journal={arXiv preprint arXiv:2203.10421},
  year={2022}
}

@inproceedings{selvaraju2017grad,
  title={Grad-cam: Visual explanations from deep networks via gradient-based localization},
  author={Selvaraju, Ramprasaath R and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={618--626},
  year={2017}
}

@inproceedings{yamauchi1997frontier,
  title={A frontier-based approach for autonomous exploration},
  author={Yamauchi, Brian},
  booktitle={Proceedings 1997 IEEE International Symposium on Computational Intelligence in Robotics and Automation CIRA'97.'Towards New Computational Principles for Robotics and Automation'},
  pages={146--151},
  year={1997},
  organization={IEEE}
}

@article{dorbala2022clip,
  title={CLIP-Nav: Using CLIP for Zero-Shot Vision-and-Language Navigation},
  author={Dorbala, Vishnu Sashank and Sigurdsson, Gunnar and Piramuthu, Robinson and Thomason, Jesse and Sukhatme, Gaurav S},
  journal={arXiv preprint arXiv:2211.16649},
  year={2022}
}

@inproceedings{shah2023lm,
  title={Lm-nav: Robotic navigation with large pre-trained models of language, vision, and action},
  author={Shah, Dhruv and Osi{\'n}ski, B{\l}a{\.z}ej and Levine, Sergey and others},
  booktitle={Conference on Robot Learning},
  pages={492--504},
  year={2023}
}

@article{huang2022visual,
  title={Visual Language Maps for Robot Navigation},
  author={Huang, Chenguang and Mees, Oier and Zeng, Andy and Burgard, Wolfram},
  journal={arXiv preprint arXiv:2210.05714},
  year={2022}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{vemprala2023chatgpt,
  title={Chatgpt for robotics: Design principles and model abilities},
  author={Vemprala, Sai and Bonatti, Rogerio and Bucker, Arthur and Kapoor, Ashish},
  journal={2023},
  year={2023}
}

@article{bubeck2023sparks,
  title={Sparks of artificial general intelligence: Early experiments with gpt-4},
  author={Bubeck, S{\'e}bastien and Chandrasekaran, Varun and Eldan, Ronen and Gehrke, Johannes and Horvitz, Eric and Kamar, Ece and Lee, Peter and Lee, Yin Tat and Li, Yuanzhi and Lundberg, Scott and others},
  journal={arXiv preprint arXiv:2303.12712},
  year={2023}
}

@article{zhou2023esc,
  title={ESC: Exploration with Soft Commonsense Constraints for Zero-shot Object Navigation},
  author={Zhou, Kaiwen and Zheng, Kaizhi and Pryor, Connor and Shen, Yilin and Jin, Hongxia and Getoor, Lise and Wang, Xin Eric},
  journal={arXiv preprint arXiv:2301.13166},
  year={2023}
}

@article{dorbala2023can,
  title={Can an Embodied Agent Find Your" Cat-shaped Mug"? LLM-Based Zero-Shot Object Navigation},
  author={Dorbala, Vishnu Sashank and Mullen Jr, James F and Manocha, Dinesh},
  journal={arXiv preprint arXiv:2303.03480},
  year={2023}
}

%--------------------------------------------LLMs----------------------------------

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{touvron2023llama,
  title={Llama: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}

@article{chowdhery2022palm,
  title={Palm: Scaling language modeling with pathways},
  author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
  journal={arXiv preprint arXiv:2204.02311},
  year={2022}
}

@article{zhang2022opt,
  title={Opt: Open pre-trained transformer language models},
  author={Zhang, Susan and Roller, Stephen and Goyal, Naman and Artetxe, Mikel and Chen, Moya and Chen, Shuohui and Dewan, Christopher and Diab, Mona and Li, Xian and Lin, Xi Victoria and others},
  journal={arXiv preprint arXiv:2205.01068},
  year={2022}
}

@article{wei2021finetuned,
  title={Finetuned language models are zero-shot learners},
  author={Wei, Jason and Bosma, Maarten and Zhao, Vincent Y and Guu, Kelvin and Yu, Adams Wei and Lester, Brian and Du, Nan and Dai, Andrew M and Le, Quoc V},
  journal={arXiv preprint arXiv:2109.01652},
  year={2021}
}

@misc{openai2023gpt4,
      title={GPT-4 Technical Report}, 
      author={OpenAI},
      year={2023},
      eprint={2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{vicuna2023,
    title = {Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90\%* ChatGPT Quality},
    url = {https://lmsys.org/blog/2023-03-30-vicuna/},
    author = {Chiang, Wei-Lin and Li, Zhuohan and Lin, Zi and Sheng, Ying and Wu, Zhanghao and Zhang, Hao and Zheng, Lianmin and Zhuang, Siyuan and Zhuang, Yonghao and Gonzalez, Joseph E. and Stoica, Ion and Xing, Eric P.},
    month = {March},
    year = {2023}
}

@article{scao2022language,
  title={What Language Model to Train if You Have One Million GPU Hours?},
  author={Scao, Teven Le and Wang, Thomas and Hesslow, Daniel and Saulnier, Lucile and Bekman, Stas and Bari, M Saiful and Bideman, Stella and Elsahar, Hady and Muennighoff, Niklas and Phang, Jason and others},
  journal={arXiv preprint arXiv:2210.15424},
  year={2022}
}

@article{wu2023visual,
  title={Visual chatgpt: Talking, drawing and editing with visual foundation models},
  author={Wu, Chenfei and Yin, Shengming and Qi, Weizhen and Wang, Xiaodong and Tang, Zecheng and Duan, Nan},
  journal={arXiv preprint arXiv:2303.04671},
  year={2023}
}

@article{schick2023toolformer,
  title={Toolformer: Language models can teach themselves to use tools},
  author={Schick, Timo and Dwivedi-Yu, Jane and Dess{\`\i}, Roberto and Raileanu, Roberta and Lomeli, Maria and Zettlemoyer, Luke and Cancedda, Nicola and Scialom, Thomas},
  journal={arXiv preprint arXiv:2302.04761},
  year={2023}
}

@article{peng2023check,
  title={Check your facts and try again: Improving large language models with external knowledge and automated feedback},
  author={Peng, Baolin and Galley, Michel and He, Pengcheng and Cheng, Hao and Xie, Yujia and Hu, Yu and Huang, Qiuyuan and Liden, Lars and Yu, Zhou and Chen, Weizhu and others},
  journal={arXiv preprint arXiv:2302.12813},
  year={2023}
}



@article{karpas2022mrkl,
  title={MRKL Systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning},
  author={Karpas, Ehud and Abend, Omri and Belinkov, Yonatan and Lenz, Barak and Lieber, Opher and Ratner, Nir and Shoham, Yoav and Bata, Hofit and Levine, Yoav and Leyton-Brown, Kevin and others},
  journal={arXiv preprint arXiv:2205.00445},
  year={2022}
}

@misc{shen2023hugginggpt,
      title={HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace}, 
      author={Yongliang Shen and Kaitao Song and Xu Tan and Dongsheng Li and Weiming Lu and Yueting Zhuang},
      year={2023},
      eprint={2303.17580},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{saycan2022arxiv,
    title={Do As I Can and Not As I Say: Grounding Language in Robotic Affordances},
    author={Michael Ahn and Anthony Brohan and Noah Brown and Yevgen Chebotar and Omar Cortes and Byron David and Chelsea Finn and Chuyuan Fu and Keerthana Gopalakrishnan and Karol Hausman and Alex Herzog and Daniel Ho and Jasmine Hsu and Julian Ibarz and Brian Ichter and Alex Irpan and Eric Jang and Rosario Jauregui Ruano and Kyle Jeffrey and Sally Jesmonth and Nikhil Joshi and Ryan Julian and Dmitry Kalashnikov and Yuheng Kuang and Kuang-Huei Lee and Sergey Levine and Yao Lu and Linda Luu and Carolina Parada and Peter Pastor and Jornell Quiambao and Kanishka Rao and Jarek Rettinghouse and Diego Reyes and Pierre Sermanet and Nicolas Sievers and Clayton Tan and Alexander Toshev and Vincent Vanhoucke and Fei Xia and Ted Xiao and Peng Xu and Sichun Xu and Mengyuan Yan and Andy Zeng},
    booktitle={arXiv preprint arXiv:2204.01691},
    year={2022}
}

@article{driess2023palm,
  title={Palm-e: An embodied multimodal language model},
  author={Driess, Danny and Xia, Fei and Sajjadi, Mehdi SM and Lynch, Corey and Chowdhery, Aakanksha and Ichter, Brian and Wahid, Ayzaan and Tompson, Jonathan and Vuong, Quan and Yu, Tianhe and others},
  journal={arXiv preprint arXiv:2303.03378},
  year={2023}
}

@article{wei2022emergent,
  title={Emergent abilities of large language models},
  author={Wei, Jason and Tay, Yi and Bommasani, Rishi and Raffel, Colin and Zoph, Barret and Borgeaud, Sebastian and Yogatama, Dani and Bosma, Maarten and Zhou, Denny and Metzler, Donald and others},
  journal={arXiv preprint arXiv:2206.07682},
  year={2022}
}

@article{li2023blip,
  title={Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models},
  author={Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven},
  journal={arXiv preprint arXiv:2301.12597},
  year={2023}
}

@inproceedings{girshick2015fast,
  title={Fast r-cnn},
  author={Girshick, Ross},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={1440--1448},
  year={2015}
}

@misc{zhu2023chatgpt,
      title={ChatGPT Asks, BLIP-2 Answers: Automatic Questioning Towards Enriched Visual Descriptions}, 
      author={Deyao Zhu and Jun Chen and Kilichbek Haydarov and Xiaoqian Shen and Wenxuan Zhang and Mohamed Elhoseiny},
      year={2023},
      eprint={2303.06594},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{li2022grounded,
  title={Grounded language-image pre-training},
  author={Li, Liunian Harold and Zhang, Pengchuan and Zhang, Haotian and Yang, Jianwei and Li, Chunyuan and Zhong, Yiwu and Wang, Lijuan and Yuan, Lu and Zhang, Lei and Hwang, Jenq-Neng and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10965--10975},
  year={2022}
}


@article{kamath2022marval,
  title={A New Path: Scaling Vision-and-Language Navigation with Synthetic Instructions and Imitation Learning},
  author={Kamath, Aishwarya and Anderson, Peter and Wang, Su and Koh, Jing Yu and Ku, Alexander and Waters, Austin and Yang, Yinfei and Baldridge, Jason and Parekh, Zarana},
  journal={arXiv preprint arXiv:2210.03112},
  year={2022}
}

@article{an2024etpnav,
  title={Etpnav: Evolving topological planning for vision-language navigation in continuous environments},
  author={An, Dong and Wang, Hanqing and Wang, Wenguan and Wang, Zun and Huang, Yan and He, Keji and Wang, Liang},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2024},
  publisher={IEEE}
}

@inproceedings{chen2022hm3dlearning,
  title={Learning from unlabeled 3d environments for vision-and-language navigation},
  author={Chen, Shizhe and Guhur, Pierre-Louis and Tapaswi, Makarand and Schmid, Cordelia and Laptev, Ivan},
  booktitle={European Conference on Computer Vision},
  pages={638--655},
  year={2022},
  organization={Springer}
}


@article{wang2022internvideo,
  title={InternVideo: General Video Foundation Models via Generative and Discriminative Learning},
  author={Wang, Yi and Li, Kunchang and Li, Yizhuo and He, Yinan and Huang, Bingkun and Zhao, Zhiyu and Zhang, Hongjie and Xu, Jilan and Liu, Yi and Wang, Zun and Xing, Sen and Chen, Guo and Pan, Junting and Yu, Jiashuo and Wang, Yali and Wang, Limin and Qiao, Yu},
  journal={arXiv preprint arXiv:2212.03191},
  year={2022}
}

@inproceedings{ramakrishnan2021hm3d,
  title={Habitat-Matterport 3D Dataset (HM3D): 1000 Large-scale 3D Environments for Embodied AI},
  author={Ramakrishnan, Santhosh Kumar and Gokaslan, Aaron and Wijmans, Erik and Maksymets, Oleksandr and Clegg, Alexander and Turner, John M and Undersander, Eric and Galuba, Wojciech and Westbury, Andrew and Chang, Angel X and others},
  booktitle={Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2)},
  year={2021}
}

@inproceedings{li2023vlnsig,
  title     = {Improving Vision-and-Language Navigation by Generating Future-View Image Semantics},
  author    = {Jialu Li, Mohit Bansal},
  booktitle = {CVPR},
  year      = {2023}
}

@inproceedings{wijmans2020ddppo,
  title = {{DD-PPO}: {L}earning Near-Perfect PointGoal Navigators from 2.5 Billion Frames},
  author =  {Erik Wijmans and Abhishek Kadian and Ari Morcos and Stefan Lee and Irfan Essa and Devi Parikh and Manolis Savva and Dhruv Batra},
  booktitle = {International Conference on Learning Representations (ICLR)},
  year =    {2020}
}
@article{deitke2022procthor,
  title={ProcTHOR: Large-Scale Embodied AI Using Procedural Generation},
  author={Deitke, Matt and VanderBilt, Eli and Herrasti, Alvaro and Weihs, Luca and Salvador, Jordi and Ehsani, Kiana and Han, Winson and Kolve, Eric and Farhadi, Ali and Kembhavi, Aniruddha and others},
  journal={arXiv preprint arXiv:2206.06994},
  year={2022}
}

@inproceedings{ramrakhya2022habweb,
  title={Habitat-Web: Learning Embodied Object-Search Strategies from Human Demonstrations at Scale},
  author={Ramrakhya, Ram and Undersander, Eric and Batra, Dhruv and Das, Abhishek},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5173--5183},
  year={2022}
}

@InProceedings{hong2020recurrent,
    author    = {Hong, Yicong and Wu, Qi and Qi, Yuankai and Rodriguez-Opazo, Cristian and Gould, Stephen},
    title     = {A Recurrent Vision-and-Language BERT for Navigation},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
    year      = {2021},
    pages     = {1643-1653}
}

@inproceedings{wang2020environment,
  title={Environment-agnostic multitask learning for natural language grounded navigation},
  author={Wang, Xin Eric and Jain, Vihan and Ie, Eugene and Wang, William Yang and Kozareva, Zornitsa and Ravi, Sujith},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part XXIV 16},
  pages={413--430},
  year={2020},
  organization={Springer}
}
@article{raychaudhuri2021law,
  title={Language-aligned waypoint (law) supervision for vision-and-language navigation in continuous environments},
  author={Raychaudhuri, Sonia and Wani, Saim and Patel, Shivansh and Jain, Unnat and Chang, Angel X},
  journal={arXiv preprint arXiv:2109.15207},
  year={2021}
}
@inproceedings{lin2022multimodal,
  title={Multimodal transformer with variable-length memory for vision-and-language navigation},
  author={Lin, Chuang and Jiang, Yi and Cai, Jianfei and Qu, Lizhen and Haffari, Gholamreza and Yuan, Zehuan},
  booktitle={Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part XXXVI},
  pages={380--397},
  year={2022},
  organization={Springer}
}

@article{shah2022lmnav,
  title={Lm-nav: Robotic navigation with large pre-trained models of language, vision, and action},
  author={Shah, Dhruv and Osinski, Blazej and Ichter, Brian and Levine, Sergey},
  journal={arXiv preprint arXiv:2207.04429},
  year={2022}
}

@article{zhangdiagnosing,
  title={Diagnosing the environment bias in vision-and-language navigation},
  author={Zhang, Yubo and Tan, Hao and Bansal, Mohit},
  journal={IJCAI},
  year={2020}
}


@inproceedings{krantz_vlnce_2020,
  title={Beyond the Nav-Graph: Vision and Language Navigation in Continuous Environments},
  author={Jacob Krantz and Erik Wijmans and Arjun Majundar and Dhruv Batra and Stefan Lee},
  booktitle={European Conference on Computer Vision},
  year={2020}
 }


@inproceedings{ku2020room,
  title={Room-Across-Room: Multilingual Vision-and-Language Navigation with Dense Spatiotemporal Grounding},
  author={Ku, Alexander and Anderson, Peter and Patel, Roma and Ie, Eugene and Baldridge, Jason},
  booktitle={Proceedings of the Conference on Empirical Methods in Natural Language Processing},
  pages={4392--4412},
  year={2020}
}

@inproceedings{tan2019envdrop,
  title={Learning to Navigate Unseen Environments: Back Translation with Environmental Dropout},
  author={Tan, Hao and Yu, Licheng and Bansal, Mohit},
  booktitle={Proceedings of NAACL-HLT},
  pages={2610--2621},
  year={2019}
}

@inproceedings{li2022envedit,
  title={EnvEdit: Environment Editing for Vision-and-Language Navigation},
  author={Li, Jialu and Tan, Hao and Bansal, Mohit},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={15407--15417},
  year={2022}
}

@inproceedings{shen2021benefit,
  title={How Much Can CLIP Benefit Vision-and-Language Tasks?},
  author={Shen, Sheng and Li, Liunian Harold and Tan, Hao and Bansal, Mohit and Rohrbach, Anna and Chang, Kai-Wei and Yao, Zhewei and Keutzer, Kurt},
  booktitle={International Conference on Learning Representations},
  year={2021}
}


@inproceedings{krantz2022sim,
  title={Sim-2-Sim Transfer for Vision-and-Language Navigation in Continuous Environments},
  author={Krantz, Jacob and Lee, Stefan},
  booktitle={European Conference on Computer Vision},
  pages={588--603},
  year={2022}
}


@article{dou2022foam,
  title={FOAM: A Follower-aware Speaker Model For Vision-and-Language Navigation},
  author={Dou, Zi-Yi and Peng, Nanyun},
  journal={arXiv preprint arXiv:2206.04294},
  year={2022}
}

@article{wu2021improvedspeaker,
  title={Improved speaker and navigator for vision-and-language navigation},
  author={Wu, Zongkai and Liu, Zihan and Wang, Ting and Wang, Donglin},
  journal={IEEE MultiMedia},
  volume={28},
  number={4},
  pages={55--63},
  year={2021},
  publisher={IEEE}
}


@inproceedings{wang2022less,
  title={Less is More: Generating Grounded Navigation Instructions from Landmarks},
  author={Wang, Su and Montgomery, Ceslee and Orbay, Jordi and Birodkar, Vighnesh and Faust, Aleksandra and Gur, Izzeddin and Jaques, Natasha and Waters, Austin and Baldridge, Jason and Anderson, Peter},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={15428--15438},
  year={2022}
}

@inproceedings{anderson2020sim,
  title={Sim-to-real transfer for vision-and-language navigation},
  author={Anderson, Peter and Shrivastava, Ayush and Truong, Joanne and Majumdar, Arjun and Parikh, Devi and Batra, Dhruv and Lee, Stefan},
  booktitle={Conference on Robot Learning},
  pages={671--681},
  year={2021}
}


@inproceedings{chen2022duet,
  title={Think Global, Act Local: Dual-scale Graph Transformer for Vision-and-Language Navigation},
  author={Chen, Shizhe and Guhur, Pierre-Louis and Tapaswi, Makarand and Schmid, Cordelia and Laptev, Ivan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={16537--16547},
  year={2022}
}


@inproceedings{xia2018gibson,
  title={Gibson env: Real-world perception for embodied agents},
  author={Xia, Fei and Zamir, Amir R and He, Zhiyang and Sax, Alexander and Malik, Jitendra and Savarese, Silvio},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={9068--9079},
  year={2018}
}


@inproceedings{anderson2020rxr,
  title={Room-Across-Room: Multilingual Vision-and-Language Navigation with Dense Spatiotemporal Grounding},
  author={Ku, Alexander and Anderson, Peter and Patel, Roma and Ie, Eugene and Baldridge, Jason},
  booktitle={Proceedings of the Conference on Empirical Methods in Natural Language Processing},
  pages={4392--4412},
  year={2020}
}


@inproceedings{jain2019stay,
  title={Stay on the Path: Instruction Fidelity in Vision-and-Language Navigation},
  author={Jain, Vihan and Magalhaes, Gabriel and Ku, Alexander and Vaswani, Ashish and Ie, Eugene and Baldridge, Jason},
  booktitle={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  pages={1862--1872},
  year={2019}
}

@inproceedings{thomason2020cvdn,
  title={Vision-and-dialog navigation},
  author={Thomason, Jesse and Murray, Michael and Cakmak, Maya and Zettlemoyer, Luke},
  booktitle={Conference on Robot Learning},
  pages={394--406},
  year={2020}
}

@article{zhao2021comodgan,
  title={Large scale image completion via co-modulated generative adversarial networks},
  author={Zhao, Shengyu and Cui, Jonathan and Sheng, Yilun and Dong, Yue and Liang, Xiao and Chang, Eric I and Xu, Yan},
  journal={arXiv preprint arXiv:2103.10428},
  year={2021}
}


@inproceedings{zhu2021scoa,
  title={Self-motivated communication agent for real-world vision-dialog navigation},
  author={Zhu, Yi and Weng, Yue and Zhu, Fengda and Liang, Xiaodan and Ye, Qixiang and Lu, Yutong and Jiao, Jianbin},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1594--1603},
  year={2021}
}

@inproceedings{jain2021mural,
  title={MURAL: Multimodal, multitask representations across languages},
  author={Jain, Aashi and Guo, Mandy and Srinivasan, Krishna and Chen, Ting and Kudugunta, Sneha and Jia, Chao and Yang, Yinfei and Baldridge, Jason},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2021},
  pages={3449--3463},
  year={2021}
}

@article{koh2022simple,
  title={Simple and Effective Synthesis of Indoor 3D Scenes},
  author={Koh, Jing Yu and Agrawal, Harsh and Batra, Dhruv and Tucker, Richard and Waters, Austin and Lee, Honglak and Yang, Yinfei and Baldridge, Jason and Anderson, Peter},
  journal={arXiv preprint arXiv:2204.02960},
  year={2022}
}

@article{chen2021hamt,
  title={History aware multimodal transformer for vision-and-language navigation},
  author={Chen, Shizhe and Guhur, Pierre-Louis and Schmid, Cordelia and Laptev, Ivan},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={5834--5847},
  year={2021}
}

@article{an20221st,
  title={1st Place Solutions for RxR-Habitat Vision-and-Language Navigation Competition},
  author={An, Dong and Wang, Zun and Li, Yangguang and Wang, Yi and Hong, Yicong and Huang, Yan and Wang, Liang and Shao, Jing},
  journal={arXiv preprint arXiv:2206.11610},
  year={2022}
}

@article{qin2021ensemble,
  title={Explore the Potential Performance of Vision-and-Language Navigation Model: a Snapshot Ensemble Method},
  author={Qin, Wenda and Misu, Teruhisa and Wijaya, Derry},
  journal={arXiv preprint arXiv:2111.14267},
  year={2021}
}

@article{xie2022beam,
  title={Vision--Language Navigation With Beam-Constrained Global Normalization},
  author={Xie, Liang and Zhang, Meishan and Li, You and Qin, Wei and Yan, Ye and Yin, Erwei},
  journal={IEEE Transactions on Neural Networks and Learning Systems},
  year={2022},
  publisher={IEEE}
}

@inproceedings{zhu2020vision,
  title={Vision-language navigation with self-supervised auxiliary reasoning tasks},
  author={Zhu, Fengda and Zhu, Yi and Chang, Xiaojun and Liang, Xiaodan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10012--10022},
  year={2020}
}

@article{anderson2019chasing,
  title={Chasing ghosts: Instruction following as bayesian state tracking},
  author={Anderson, Peter and Shrivastava, Ayush and Parikh, Devi and Batra, Dhruv and Lee, Stefan},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@inproceedings{wang2020active,
  title={Active visual information gathering for vision-language navigation},
  author={Wang, Hanqing and Wang, Wenguan and Shu, Tianmin and Liang, Wei and Shen, Jianbing},
  booktitle={European Conference on Computer Vision},
  pages={307--322},
  year={2020},
  organization={Springer}
}

@misc{armeni20193d,
      title={3D Scene Graph: A Structure for Unified Semantics, 3D Space, and Camera}, 
      author={Iro Armeni and Zhi-Yang He and JunYoung Gwak and Amir R. Zamir and Martin Fischer and Jitendra Malik and Silvio Savarese},
      year={2019},
      eprint={1910.02527},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{liu2021envmixup,
  title={Vision-language navigation with random environmental mixup},
  author={Liu, Chong and Zhu, Fengda and Chang, Xiaojun and Liang, Xiaodan and Ge, Zongyuan and Shen, Yi-Dong},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1644--1654},
  year={2021}
}


@article{hong2020graph,
  title={Language and Visual Entity Relationship Graph for Agent Navigation},
  author={Hong, Yicong and Rodriguez, Cristian and Qi, Yuankai and Wu, Qi and Gould, Stephen},
  journal={Advances in Neural Information Processing Systems},
  pages={7685--7696},
  year={2020}
}


@article{qiao2023hop+,
  title={HOP+: History-enhanced and Order-aware Pre-training for Vision-and-Language Navigation},
  author={Qiao, Yanyuan and Qi, Yuankai and Hong, Yicong and Yu, Zheng and Wang, Peng and Wu, Qi},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2023},
  publisher={IEEE}
}

@inproceedings{qi2021road,
  title={The road to know-where: An object-and-room informed sequential bert for indoor vision-language navigation},
  author={Qi, Yuankai and Pan, Zizheng and Hong, Yicong and Yang, Ming-Hsuan and van den Hengel, Anton and Wu, Qi},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1655--1664},
  year={2021}
}


@inproceedings{hao2020prevalent,
  title={Towards learning a generic agent for vision-and-language navigation via pre-training},
  author={Hao, Weituo and Li, Chunyuan and Li, Xiujun and Carin, Lawrence and Gao, Jianfeng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={13137--13146},
  year={2020}
}

@inproceedings{chen2022sevol,
  title={Reinforced Structured State-Evolution for Vision-Language Navigation},
  author={Chen, Jinyu and Gao, Chen and Meng, Erli and Zhang, Qiong and Liu, Si},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={15450--15459},
  year={2022}
}

@article{de2018talk,
  title={Talk the walk: Navigating new york city through grounded dialogue},
  author={De Vries, Harm and Shuster, Kurt and Batra, Dhruv and Parikh, Devi and Weston, Jason and Kiela, Douwe},
  journal={arXiv preprint arXiv:1807.03367},
  year={2018}
}

@inproceedings{padmakumar2022teach,
  title={Teach: Task-driven embodied agents that chat},
  author={Padmakumar, Aishwarya and Thomason, Jesse and Shrivastava, Ayush and Lange, Patrick and Narayan-Chen, Anjali and Gella, Spandana and Piramuthu, Robinson and Tur, Gokhan and Hakkani-Tur, Dilek},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={36},
  pages={2017--2025},
  year={2022}
}

@inproceedings{zhu2021soon,
  title={SOON: Scenario Oriented Object Navigation with Graph-based Exploration},
  author={Zhu, Fengda and Liang, Xiwen and Zhu, Yi and Yu, Qizhi and Chang, Xiaojun and Liang, Xiaodan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={12689--12699},
  year={2021}
}

@article{krantz2022iterative,
  title={Iterative Vision-and-Language Navigation},
  author={Krantz, Jacob and Banerjee, Shurjo and Zhu, Wang and Corso, Jason and Anderson, Peter and Lee, Stefan and Thomason, Jesse},
  journal={arXiv preprint arXiv:2210.03087},
  year={2022}
}

@inproceedings{dorbala2022clip_nav_vln,
  title={CLIP-Nav: Using CLIP for Zero-Shot Vision-and-Language Navigation},
  author={Dorbala, Vishnu Sashank and Sigurdsson, Gunnar A and Thomason, Jesse and Piramuthu, Robinson and Sukhatme, Gaurav S},
  booktitle={Workshop on Language and Robotics at CoRL 2022},
  year={2022}
}

@inproceedings{radford2021clip,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International Conference on Machine Learning},
  pages={8748--8763},
  year={2021}
}

@article{deng2020evolving,
  title={Evolving graphical planner: Contextual global planning for vision-and-language navigation},
  author={Deng, Zhiwei and Narasimhan, Karthik and Russakovsky, Olga},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={20660--20672},
  year={2020}
}

@inproceedings{ke2019tactical,
  title={Tactical rewind: Self-correction via backtracking in vision-and-language navigation},
  author={Ke, Liyiming and Li, Xiujun and Bisk, Yonatan and Holtzman, Ari and Gan, Zhe and Liu, Jingjing and Gao, Jianfeng and Choi, Yejin and Srinivasa, Siddhartha},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={6741--6749},
  year={2019}
}


@article{homerobot,
  title = {HomeRobot: Open Vocabulary Mobile Manipulation},
  author = {Yenamandra, Sriram and Ramachandran, Arun and Yadav, Karmesh and Wang, Austin and
            Khanna, Mukul and Gervet, Theophile and Yang, Tsung-Yen and Jain, Vidhi and Clegg,
	    Alexander William and Turner, John and Kira, Zsolt and Savva, Manolis and Chang,
	    Angel and Chaplot, Devendra Singh and Batra, Dhruv and Mottaghi, Roozbeh and Bisk,
	    Yonatan and Paxton, Chris},
  year = {2023},
}

@article{padalkar2023open,
  title={Open x-embodiment: Robotic learning datasets and rt-x models},
  author={Padalkar, Abhishek and Pooley, Acorn and Jain, Ajinkya and Bewley, Alex and Herzog, Alex and Irpan, Alex and Khazatsky, Alexander and Rai, Anant and Singh, Anikait and Brohan, Anthony and others},
  journal={arXiv preprint arXiv:2310.08864},
  year={2023}
}

@article{zhang2021rosefusion,
  title={ROSEFusion: random optimization for online dense reconstruction under fast camera motion},
  author={Zhang, Jiazhao and Zhu, Chenyang and Zheng, Lintao and Xu, Kai},
  journal={ACM Transactions on Graphics (TOG)},
  volume={40},
  number={4},
  pages={1--17},
  year={2021},
  publisher={ACM New York, NY, USA}
}


@article{zhang2022asro,
  title={ASRO-DIO: Active subspace random optimization based depth inertial odometry},
  author={Zhang, Jiazhao and Tang, Yijie and Wang, He and Xu, Kai},
  journal={IEEE Transactions on Robotics},
  volume={39},
  number={2},
  pages={1496--1508},
  year={2022},
  publisher={IEEE}
}

@article{liu2023efficient,
  title={Efficient and consistent bundle adjustment on lidar point clouds},
  author={Liu, Zheng and Liu, Xiyuan and Zhang, Fu},
  journal={IEEE Transactions on Robotics},
  year={2023},
  publisher={IEEE}
}

@article{zhang2023gamma,
  title={GAMMA: Graspability-Aware Mobile MAnipulation Policy Learning based on Online Grasping Pose Fusion},
  author={Zhang, Jiazhao and Gireesh, Nandiraju and Wang, Jilong and Fang, Xiaomeng and Xu, Chaoyi and Chen, Weiguang and Dai, Liu and Wang, He},
  journal={arXiv preprint arXiv:2309.15459},
  year={2023}
}



@article{dong2023survey,
  title={A survey on long text modeling with transformers},
  author={Dong, Zican and Tang, Tianyi and Li, Lunyi and Zhao, Wayne Xin},
  journal={arXiv preprint arXiv:2302.14502},
  year={2023}
}


@article{mees2022calvin,
  title={Calvin: A benchmark for language-conditioned policy learning for long-horizon robot manipulation tasks},
  author={Mees, Oier and Hermann, Lukas and Rosete-Beas, Erick and Burgard, Wolfram},
  journal={IEEE Robotics and Automation Letters},
  volume={7},
  number={3},
  pages={7327--7334},
  year={2022},
  publisher={IEEE}
}

@article{li2023vision,
  title={Vision-language foundation models as effective robot imitators},
  author={Li, Xinghang and Liu, Minghuan and Zhang, Hanbo and Yu, Cunjun and Xu, Jie and Wu, Hongtao and Cheang, Chilam and Jing, Ya and Zhang, Weinan and Liu, Huaping and others},
  journal={arXiv preprint arXiv:2311.01378},
  year={2023}
}


@article{wu2023unleashing,
  title={Unleashing Large-Scale Video Generative Pre-training for Visual Robot Manipulation},
  author={Wu, Hongtao and Jing, Ya and Cheang, Chilam and Chen, Guangzeng and Xu, Jiafeng and Li, Xinghang and Liu, Minghuan and Li, Hang and Kong, Tao},
  journal={arXiv preprint arXiv:2312.13139},
  year={2023}
}

@article{wang2023prompt,
  title={Prompt a robot to walk with large language models},
  author={Wang, Yen-Jen and Zhang, Bike and Chen, Jianyu and Sreenath, Koushil},
  journal={arXiv preprint arXiv:2309.09969},
  year={2023}
}


@inproceedings{ALFRED20,
  title ={{ALFRED: A Benchmark for Interpreting Grounded
           Instructions for Everyday Tasks}},
  author={Mohit Shridhar and Jesse Thomason and Daniel Gordon and Yonatan Bisk and
          Winson Han and Roozbeh Mottaghi and Luke Zettlemoyer and Dieter Fox},
  booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year = {2020},
}


@article{wang2023internvid,
title={InternVid: A Large-scale Video-Text Dataset for Multimodal Understanding and Generation},
author={Wang, Yi and He, Yinan and Li, Yizhuo and Li, Kunchang and Yu, Jiashuo and Ma, Xin and Chen, Xinyuan and Wang, Yaohui and Luo, Ping and Liu, Ziwei and Wang, Yali and Wang, Limin and Qiao, Yu},
journal={arXiv preprint arXiv:2307.06942},
year={2023}
}

@article{batra2020rearrangement,
  title={Rearrangement: A challenge for embodied ai},
  author={Batra, Dhruv and Chang, Angel X and Chernova, Sonia and Davison, Andrew J and Deng, Jia and Koltun, Vladlen and Levine, Sergey and Malik, Jitendra and Mordatch, Igor and Mottaghi, Roozbeh and others},
  journal={arXiv preprint arXiv:2011.01975},
  year={2020}
}

@article{zhao2023learning,
  title={Learning fine-grained bimanual manipulation with low-cost hardware},
  author={Zhao, Tony Z and Kumar, Vikash and Levine, Sergey and Finn, Chelsea},
  journal={arXiv preprint arXiv:2304.13705},
  year={2023}
}


@inproceedings{ehsani2021manipulathor,
  title={Manipulathor: A framework for visual object manipulation},
  author={Ehsani, Kiana and Han, Winson and Herrasti, Alvaro and VanderBilt, Eli and Weihs, Luca and Kolve, Eric and Kembhavi, Aniruddha and Mottaghi, Roozbeh},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={4497--4506},
  year={2021}
}

@inproceedings{habitat2020sim2real,
  title     =     {Are {W}e {M}aking {R}eal {P}rogress in {S}imulated {E}nvironments? {M}easuring the {S}im2{R}eal {G}ap in {E}mbodied {V}isual {N}avigation},
  author    =     {{Abhishek Kadian} and {Joanne Truong} and Aaron Gokaslan and Alexander Clegg and Erik Wijmans and Stefan Lee and Manolis Savva and Sonia Chernova and Dhruv Batra},
  booktitle =     {arXiv:1912.06321},
  year      =     {2019}
}

@inproceedings{batra2020objectnav,
  title     =     {Object{N}av {R}evisited: {O}n {E}valuation of {E}mbodied {A}gents {N}avigating to {O}bjects},
  author    =     {Dhruv Batra and Aaron Gokaslan and Aniruddha Kembhavi and Oleksandr Maksymets and Roozbeh Mottaghi and Manolis Savva and Alexander Toshev and Erik Wijmans},
  booktitle =     {arXiv:2006.13171},
  year      =     {2020}
}

@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in Neural Information Processing Systems},
  pages={24824--24837},
  year={2022}
}


@InProceedings{macenski2020marathon2,
author = {Macenski, Steven and Martin, Francisco and White, Ruffin and GinÃ©s Clavero, Jonatan},
title = {The Marathon 2: A Navigation System},
booktitle = {2020 IEEE/RSJ International Conference on Intelligent Robots and Systems},
year = {2020}
}


@inproceedings{anderson2021sim,
  title={Sim-to-real transfer for vision-and-language navigation},
  author={Anderson, Peter and Shrivastava, Ayush and Truong, Joanne and Majumdar, Arjun and Parikh, Devi and Batra, Dhruv and Lee, Stefan},
  booktitle={Conference on Robot Learning},
  pages={671--681},
  year={2021}
}

@article{mezghani2021imagenav,
  title={Memory-augmented reinforcement learning for image-goal navigation},
  author={Mezghani, Lina and Sukhbaatar, Sainbayar and Lavril, Thibaut and Maksymets, Oleksandr and Batra, Dhruv and Bojanowski, Piotr and Alahari, Karteek},
  journal={arXiv preprint arXiv:2101.05181},
  year={2021}
}

@article{zhao2021large,
  title={Large scale image completion via co-modulated generative adversarial networks},
  author={Zhao, Shengyu and Cui, Jonathan and Sheng, Yilun and Dong, Yue and Liang, Xiao and Chang, Eric I and Xu, Yan},
  journal={arXiv preprint arXiv:2103.10428},
  year={2021}
}

@article{radford2019gpt2,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@inproceedings{ross2011dagger,
  title={A reduction of imitation learning and structured prediction to no-regret online learning},
  author={Ross, St{\'e}phane and Gordon, Geoffrey and Bagnell, Drew},
  booktitle={Proceedings of the international conference on artificial intelligence and statistics},
  pages={627--635},
  year={2011}
}

@article{lamb2016professor,
  title={Professor forcing: A new algorithm for training recurrent networks},
  author={Lamb, Alex M and ALIAS PARTH GOYAL, Anirudh Goyal and Zhang, Ying and Zhang, Saizheng and Courville, Aaron C and Bengio, Yoshua},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

@inproceedings{lin2021sia,
  title={Scene-intuitive agent for remote embodied visual grounding},
  author={Lin, Xiangru and Li, Guanbin and Yu, Yizhou},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={7036--7045},
  year={2021}
}

@article{dosovitskiy2020vit,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}


@article{anderson2018spl,
  title={On evaluation of embodied navigation agents},
  author={Anderson, Peter and Chang, Angel and Chaplot, Devendra Singh and Dosovitskiy, Alexey and Gupta, Saurabh and Koltun, Vladlen and Kosecka, Jana and Malik, Jitendra and Mottaghi, Roozbeh and Savva, Manolis and others},
  journal={arXiv preprint arXiv:1807.06757},
  year={2018}
}

@article{ilharco2019ndtw,
  title={General evaluation for instruction conditioned navigation using dynamic time warping},
  author={Ilharco, Gabriel and Jain, Vihan and Ku, Alexander and Ie, Eugene and Baldridge, Jason},
  journal={arXiv preprint arXiv:1907.05446},
  year={2019}
}

@inproceedings{deng2009imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={2009 IEEE conference on computer vision and pattern recognition},
  pages={248--255},
  year={2009},
  organization={Ieee}
}

@inproceedings{lin2021scene,
  title={Scene-intuitive agent for remote embodied visual grounding},
  author={Lin, Xiangru and Li, Guanbin and Yu, Yizhou},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={7036--7045},
  year={2021}
}

@article{magassouba2021crossmap,
  title={CrossMap transformer: A crossmodal masked path transformer using double back-translation for vision-and-language navigation},
  author={Magassouba, Aly and Sugiura, Komei and Kawai, Hisashi},
  journal={IEEE Robotics and Automation Letters},
  volume={6},
  number={4},
  pages={6258--6265},
  year={2021},
  publisher={IEEE}
}

@inproceedings{kim2021ndh,
  title={Ndh-full: Learning and evaluating navigational agents on full-length dialogue},
  author={Kim, Hyounghun and Li, Jialu and Bansal, Mohit},
  booktitle={Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  year={2021}
}


@article{chen2022weakly,
  title={Weakly-supervised multi-granularity map learning for vision-and-language navigation},
  author={Chen, Peihao and Ji, Dongyu and Lin, Kunyang and Zeng, Runhao and Li, Thomas and Tan, Mingkui and Gan, Chuang},
  journal={Advances in Neural Information Processing Systems},
  pages={38149--38161},
  year={2022}
}
@article{zhou2023navgpt,
  title={NavGPT: Explicit Reasoning in Vision-and-Language Navigation with Large Language Models},
  author={Zhou, Gengze and Hong, Yicong and Wu, Qi},
  journal={arXiv preprint arXiv:2305.16986},
  year={2023}
}
@inproceedings{zhou2024navgpt,
  title={Navgpt: Explicit reasoning in vision-and-language navigation with large language models},
  author={Zhou, Gengze and Hong, Yicong and Wu, Qi},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  pages={7641--7649},
  year={2024}
}
@inproceedings{hong2023ego2map,
  title={Learning Navigational Visual Representations with Semantic Map Supervision}, 
  author={Hong, Yicong and Zhou, Yang and Zhang, Ruiyi and Dernoncourt, Franck and Bui, Trung and Gould, Stephen and Tan, Hao},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={3055--3067},
  year={2023}
}

@inproceedings{papineni2002bleu,
  title={Bleu: a method for automatic evaluation of machine translation},
  author={Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
  booktitle={Proceedings of the 40th annual meeting of the Association for Computational Linguistics},
  pages={311--318},
  year={2002}
}
@inproceedings{yu2023l3mvn,
  title={L3mvn: Leveraging large language models for visual target navigation},
  author={Yu, Bangguo and Kasaei, Hamidreza and Cao, Ming},
  booktitle={IEEE/RSJ International Conference on Intelligent Robots and Systems},
  pages={3554--3560},
  year={2023}
}
@article{chen2024mapgpt,
  title={MapGPT: Map-Guided Prompting for Unified Vision-and-Language Navigation},
  author={Chen, Jiaqi and Lin, Bingqian and Xu, Ran and Chai, Zhenhua and Liang, Xiaodan and Wong, Kwan-Yee K},
  journal={arXiv preprint arXiv:2401.07314},
  year={2024}
}


@inproceedings{long2024discuss,
  title={Discuss before moving: Visual language navigation via multi-expert discussions},
  author={Long, Yuxing and Li, Xiaoqi and Cai, Wenzhe and Dong, Hao},
  booktitle={IEEE International Conference on Robotics and Automation},
  pages={17380--17387},
  year={2024}
}
@article{lin2023development,
  title={The Development of LLMs for Embodied Navigation},
  author={Lin, Jinzhou and Gao, Han and Xu, Rongtao and Wang, Changwei and Guo, Li and Xu, Shibiao},
  journal={arXiv preprint arXiv:2311.00530},
  year={2023}
}
@article{radford2018improving,
  title={Improving language understanding by generative pre-training},
  author={Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya and others},
  year={2018},
  publisher={OpenAI}
}
@article{qwen2,
  title={Qwen2 Technical Report},
  year={2024}
}


@article{li2024llava,
  title={Llava-onevision: Easy visual task transfer},
  author={Li, Bo and Zhang, Yuanhan and Guo, Dong and Zhang, Renrui and Li, Feng and Zhang, Hao and Zhang, Kaichen and Zhang, Peiyuan and Li, Yanwei and Liu, Ziwei and others},
  journal={arXiv preprint arXiv:2408.03326},
  year={2024}
}
@article{wang2024qwen2,
  title={Qwen2-vl: Enhancing vision-language model's perception of the world at any resolution},
  author={Wang, Peng and Bai, Shuai and Tan, Sinan and Wang, Shijie and Fan, Zhihao and Bai, Jinze and Chen, Keqin and Liu, Xuejing and Wang, Jialin and Ge, Wenbin and others},
  journal={arXiv preprint arXiv:2409.12191},
  year={2024}
}


@inproceedings{zhai2023sigmoid,
  title={Sigmoid loss for language image pre-training},
  author={Zhai, Xiaohua and Mustafa, Basil and Kolesnikov, Alexander and Beyer, Lucas},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={11975--11986},
  year={2023}
}
@article{schumann2023velma,
  title={Velma: Verbalization embodiment of llm agents for vision and language navigation in street view},
  author={Schumann, Raphael and Zhu, Wanrong and Feng, Weixi and Fu, Tsu-Jui and Riezler, Stefan and Wang, William Yang},
  journal={arXiv preprint arXiv:2307.06082},
  year={2023}
}
@inproceedings{song2023llm,
  title={Llm-planner: Few-shot grounded planning for embodied agents with large language models},
  author={Song, Chan Hee and Wu, Jiaman and Washington, Clayton and Sadler, Brian M and Chao, Wei-Lun and Su, Yu},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={2998--3009},
  year={2023}
}
@article{dai2023instructblip,
  title={Instructblip: Towards general-purpose vision-language models with instruction tuning.},
  author={Dai, W and Li, J and Li, D and Tiong, AMH and Zhao, J and Wang, W and Li, B and Fung, P and Hoi, S},
  journal={arXiv preprint arXiv:2305.06500},
  volume={2},
  year={2023}
}

@article{claude,
  title={Instructblip: Towards general-purpose vision-language models with instruction tuning.},
  author={Anthropic},
  journal={https://www.anthropic.com/news/claude-3-5-sonnet},
  year={2024}
}
@article{cui2021toward,
  title={Toward next-generation learned robot manipulation},
  author={Cui, Jinda and Trinkle, Jeff},
  journal={Science robotics},
  volume={6},
  number={54},
  pages={eabd9461},
  year={2021},
  publisher={American Association for the Advancement of Science}
}
@inproceedings{shridhar2022cliport,
  title={Cliport: What and where pathways for robotic manipulation},
  author={Shridhar, Mohit and Manuelli, Lucas and Fox, Dieter},
  booktitle={Conference on Robot Learning},
  pages={894--906},
  year={2022}
}

@misc{Jocher_Ultralytics_YOLO_2023,
  author = {Jocher, Glenn and Qiu, Jing and Chaurasia, Ayush},
  license = {AGPL-3.0},
  title = {{Ultralytics YOLO}},
  url = {https://github.com/ultralytics/ultralytics},
  version = {8.0.0},
  year = {2023}
}
@article{suomalainen2022survey,
  title={A survey of robot manipulation in contact},
  author={Suomalainen, Markku and Karayiannidis, Yiannis and Kyrki, Ville},
  journal={Robotics and Autonomous Systems},
  volume={156},
  pages={104224},
  year={2022},
  publisher={Elsevier}
}

@inproceedings{huang2023inner,
  title={Inner Monologue: Embodied Reasoning through Planning with Language Models},
  author={Huang, Wenlong and Xia, Fei and Xiao, Ted and Chan, Harris and Liang, Jacky and Florence, Pete and Zeng, Andy and Tompson, Jonathan and Mordatch, Igor and Chebotar, Yevgen and others},
  booktitle={Conference on Robot Learning},
  pages={1769--1782},
  year={2023}
}

@article{pan2023langnav,
  title={Langnav: Language as a perceptual representation for navigation},
  author={Pan, Bowen and Panda, Rameswar and Jin, SouYoung and Feris, Rogerio and Oliva, Aude and Isola, Phillip and Kim, Yoon},
  journal={arXiv preprint arXiv:2310.07889},
  year={2023}
}

@article{mobile_sam,
  title={Faster Segment Anything: Towards Lightweight SAM for Mobile Applications},
  author={Zhang, Chaoning and Han, Dongshen and Qiao, Yu and Kim, Jung Uk and Bae, Sung-Ho and Lee, Seungkyu and Hong, Choong Seon},
  journal={arXiv preprint arXiv:2306.14289},
  year={2023}
}

@inproceedings{cheng2021mask2former,
  title={Masked-attention Mask Transformer for Universal Image Segmentation},
  author={Bowen Cheng and Ishan Misra and Alexander G. Schwing and Alexander Kirillov and Rohit Girdhar},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year={2022}
}
@inproceedings{zheng2024towards,
  title={Towards learning a generalist model for embodied navigation},
  author={Zheng, Duo and Huang, Shijia and Zhao, Lin and Zhong, Yiwu and Wang, Liwei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={13624--13634},
  year={2024}
}
@article{wu2024voronav,
  title={Voronav: Voronoi-based zero-shot object navigation with large language model},
  author={Wu, Pengying and Mu, Yao and Wu, Bingxian and Hou, Yi and Ma, Ji and Zhang, Shanghang and Liu, Chang},
  journal={arXiv preprint arXiv:2401.02695},
  year={2024}
}
@article{zhang2024trihelper,
  title={TriHelper: Zero-Shot Object Navigation with Dynamic Assistance},
  author={Zhang, Lingfeng and Zhang, Qiang and Wang, Hao and Xiao, Erjia and Jiang, Zixuan and Chen, Honglei and Xu, Renjing},
  journal={arXiv preprint arXiv:2403.15223},
  year={2024}
}
@article{zhang2024multi,
  title={Multi-Floor Zero-Shot Object Navigation Policy},
  author={Zhang, Lingfeng and Wang, Hao and Xiao, Erjia and Zhang, Xinyao and Zhang, Qiang and Jiang, Zixuan and Xu, Renjing},
  journal={arXiv preprint arXiv:2409.10906},
  year={2024}
}
@inproceedings{yokoyama2024vlfm,
  title={Vlfm: Vision-language frontier maps for zero-shot semantic navigation},
  author={Yokoyama, Naoki and Ha, Sehoon and Batra, Dhruv and Wang, Jiuguang and Bucher, Bernadette},
  booktitle={IEEE International Conference on Robotics and Automation},
  pages={42--48},
  year={2024}
}
@article{zhan2024mc,
  title={MC-GPT: Empowering Vision-and-Language Navigation with Memory Map and Reasoning Chains},
  author={Zhan, Zhaohuan and Yu, Lisha and Yu, Sijie and Tan, Guang},
  journal={arXiv preprint arXiv:2405.10620},
  year={2024}
}
@inproceedings{chen2020uniter,
  title={Uniter: Universal image-text representation learning},
  author={Chen, Yen-Chun and Li, Linjie and Yu, Licheng and El Kholy, Ahmed and Ahmed, Faisal and Gan, Zhe and Cheng, Yu and Liu, Jingjing},
  booktitle={European conference on computer vision},
  pages={104--120},
  year={2020}
}

@article{li2019visualbert,
  title={Visualbert: A simple and performant baseline for vision and language},
  author={Li, Liunian Harold and Yatskar, Mark and Yin, Da and Hsieh, Cho-Jui and Chang, Kai-Wei},
  journal={arXiv preprint arXiv:1908.03557},
  year={2019}
}

@article{su2019vl,
  title={Vl-bert: Pre-training of generic visual-linguistic representations},
  author={Su, Weijie and Zhu, Xizhou and Cao, Yue and Li, Bin and Lu, Lewei and Wei, Furu and Dai, Jifeng},
  journal={arXiv preprint arXiv:1908.08530},
  year={2019}
}

@inproceedings{wang2023scaling,
  title={Scaling data generation in vision-and-language navigation},
  author={Wang, Zun and Li, Jialu and Hong, Yicong and Wang, Yi and Wu, Qi and Bansal, Mohit and Gould, Stephen and Tan, Hao and Qiao, Yu},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={12009--12020},
  year={2023}
}

@article{xu2023vision,
  title={Vision and Language Navigation in the Real World via Online Visual Language Mapping},
  author={Xu, Chengguang and Nguyen, Hieu T and Amato, Christopher and Wong, Lawson LS},
  journal={arXiv preprint arXiv:2310.10822},
  year={2023}
}

@article{zeng2023kefa,
  title={Kefa: A Knowledge Enhanced and Fine-grained Aligned Speaker for Navigation Instruction Generation},
  author={Zeng, Haitian and Wang, Xiaohan and Wang, Wenguan and Yang, Yi},
  journal={arXiv preprint arXiv:2307.13368},
  year={2023}
}

@article{wang2024pasts,
  title={PASTS: Progress-aware spatio-temporal transformer speaker for vision-and-language navigation},
  author={Wang, Liuyi and Liu, Chengju and He, Zongtao and Li, Shu and Yan, Qingqing and Chen, Huiyi and Chen, Qijun},
  journal={Engineering Applications of Artificial Intelligence},
  volume={128},
  pages={107487},
  year={2024},
  publisher={Elsevier}
}

@article{li2023panogen,
  title={PanoGen: Text-Conditioned Panoramic Environment Generation for Vision-and-Language Navigation},
  author={Li, Jialu and Bansal, Mohit},
  journal={arXiv preprint arXiv:2305.19195},
  year={2023}
}


@article{chen20232,
  title={Action-Aware Zero-Shot Robot Navigation by Exploiting Vision-and-Language Ability of Foundation Models},
  author={Chen, Peihao and Sun, Xinyu and Zhi, Hongyan and Zeng, Runhao and Li, Thomas H and Liu, Gaowen and Tan, Mingkui and Gan, Chuang},
  journal={arXiv preprint arXiv:2308.07997},
  year={2023}
}

@article{liang2023mo,
  title={MO-VLN: A Multi-Task Benchmark for Open-set Zero-Shot Vision-and-Language Navigation},
  author={Liang, Xiwen and Ma, Liang and Guo, Shanshan and Han, Jianhua and Xu, Hang and Ma, Shikui and Liang, Xiaodan},
  journal={arXiv preprint arXiv:2306.10322},
  year={2023}
}

@inproceedings{wang2023gridmm,
  title={Gridmm: Grid memory map for vision-and-language navigation},
  author={Wang, Zihan and Li, Xiangyang and Yang, Jiahao and Liu, Yeqi and Jiang, Shuqiang},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={15625--15636},
  year={2023}
}
@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@article{sun2023generative,
  title={Generative pretraining in multimodality},
  author={Sun, Quan and Yu, Qiying and Cui, Yufeng and Zhang, Fan and Zhang, Xiaosong and Wang, Yueze and Gao, Hongcheng and Liu, Jingjing and Huang, Tiejun and Wang, Xinlong},
  journal={arXiv preprint arXiv:2307.05222},
  year={2023}
}
@article{yang2023dawn,
  title={The dawn of lmms: Preliminary explorations with gpt-4v (Vision)},
  author={Yang, Zhengyuan and Li, Linjie and Lin, Kevin and Wang, Jianfeng and Lin, Chung-Ching and Liu, Zicheng and Wang, Lijuan},
  journal={arXiv preprint arXiv:2309.17421},
  volume={9},
  number={1},
  pages={1},
  year={2023}
}
@article{liu2023improved,
  title={Improved baselines with visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Li, Yuheng and Lee, Yong Jae},
  journal={arXiv preprint arXiv:2310.03744},
  year={2023}
}


@article{liu2024visual,
  title={Visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
  journal={Advances in neural information processing systems},
  volume={36},
  year={2024}
}



@article{hu2023look,
  title={Look before you leap: Unveiling the power of gpt-4v in robotic vision-language planning},
  author={Hu, Yingdong and Lin, Fanqi and Zhang, Tong and Yi, Li and Gao, Yang},
  journal={arXiv preprint arXiv:2311.17842},
  year={2023}
}

@article{brohan2023rt,
  title={Rt-2: Vision-language-action models transfer web knowledge to robotic control},
  author={Brohan, Anthony and Brown, Noah and Carbajal, Justice and Chebotar, Yevgen and Chen, Xi and Choromanski, Krzysztof and Ding, Tianli and Driess, Danny and Dubey, Avinava and Finn, Chelsea and others},
  journal={arXiv preprint arXiv:2307.15818},
  year={2023}
}
@inproceedings{rombach2022high,
  title={High-resolution image synthesis with latent diffusion models},
  author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={10684--10695},
  year={2022}
}
@article{blattmann2023stable,
  title={Stable video diffusion: Scaling latent video diffusion models to large datasets},
  author={Blattmann, Andreas and Dockhorn, Tim and Kulal, Sumith and Mendelevitch, Daniel and Kilian, Maciej and Lorenz, Dominik and Levi, Yam and English, Zion and Voleti, Vikram and Letts, Adam and others},
  journal={arXiv preprint arXiv:2311.15127},
  year={2023}
}
@inproceedings{zhang2023adding,
  title={Adding conditional control to text-to-image diffusion models},
  author={Zhang, Lvmin and Rao, Anyi and Agrawala, Maneesh},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={3836--3847},
  year={2023}
}
@inproceedings{fu2024drive,
  title={Drive like a human: Rethinking autonomous driving with large language models},
  author={Fu, Daocheng and Li, Xin and Wen, Licheng and Dou, Min and Cai, Pinlong and Shi, Botian and Qiao, Yu},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={910--919},
  year={2024}
}

@inproceedings{qiao2023march,
  title={March in chat: Interactive prompting for remote embodied referring expression},
  author={Qiao, Yanyuan and Qi, Yuankai and Yu, Zheng and Liu, Jing and Wu, Qi},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={15758--15767},
  year={2023}
}

@inproceedings{ross2011reduction,
  title={A reduction of imitation learning and structured prediction to no-regret online learning},
  author={Ross, St{\'e}phane and Gordon, Geoffrey and Bagnell, Drew},
  booktitle={Proceedings of the fourteenth international conference on artificial intelligence and statistics},
  pages={627--635},
  year={2011},
  organization={JMLR Workshop and Conference Proceedings}
}

@article{kearns1991extending,
  title={Extending regular expressions with context operators and parse extraction},
  author={Kearns, Steven M},
  journal={Software: Practice and Experience},
  volume={21},
  number={8},
  pages={787--804},
  year={1991},
  publisher={Wiley Online Library}
}
@article{park2023visual,
  title={Visual language navigation: A survey and open challenges},
  author={Park, Sang-Min and Kim, Young-Gab},
  journal={Artificial Intelligence Review},
  pages={365--427},
  year={2023}
}
@article{tsai2023multimodal,
  title={Multimodal large language model for visual navigation},
  author={Tsai, Yao-Hung Hubert and Dhar, Vansh and Li, Jialu and Zhang, Bowen and Zhang, Jian},
  journal={arXiv preprint arXiv:2310.08669},
  year={2023}
}
@inproceedings{krantz2023iterative,
  title={Iterative vision-and-language navigation},
  author={Krantz, Jacob and Banerjee, Shurjo and Zhu, Wang and Corso, Jason and Anderson, Peter and Lee, Stefan and Thomason, Jesse},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={14921--14930},
  year={2023}
}
@inproceedings{kamath2023new,
  title={A New Path: Scaling Vision-and-Language Navigation with Synthetic Instructions and Imitation Learning},
  author={Kamath, Aishwarya and Anderson, Peter and Wang, Su and Koh, Jing Yu and Ku, Alexander and Waters, Austin and Yang, Yinfei and Baldridge, Jason and Parekh, Zarana},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10813--10823},
  year={2023}
}

@inproceedings{shah2021ving,
  title={Ving: Learning open-world navigation with visual goals},
  author={Shah, Dhruv and Eysenbach, Benjamin and Kahn, Gregory and Rhinehart, Nicholas and Levine, Sergey},
  booktitle={2021 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={13215--13222},
  year={2021},
  organization={IEEE}
}

@inproceedings{gadre2023cows,
  title={Cows on pasture: Baselines and benchmarks for language-driven zero-shot object navigation},
  author={Gadre, Samir Yitzhak and Wortsman, Mitchell and Ilharco, Gabriel and Schmidt, Ludwig and Song, Shuran},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={23171--23181},
  year={2023}
}
@article{yenamandra2023homerobot,
  title={Homerobot: Open-vocabulary mobile manipulation},
  author={Yenamandra, Sriram and Ramachandran, Arun and Yadav, Karmesh and Wang, Austin and Khanna, Mukul and Gervet, Theophile and Yang, Tsung-Yen and Jain, Vidhi and Clegg, Alexander William and Turner, John and others},
  journal={arXiv preprint arXiv:2306.11565},
  year={2023}
}
@article{li2024long,
  title={Long-context LLMs Struggle with Long In-context Learning},
  author={Li, Tianle and Zhang, Ge and Do, Quy Duc and Yue, Xiang and Chen, Wenhu},
  journal={arXiv preprint arXiv:2404.02060},
  year={2024}
}

@inproceedings{zhang2024navid,
  title={Navid: Video-based vlm plans the next step for vision-and-language navigation},
  author={Zhang, Jiazhao and Wang, Kunyu and Xu, Rongtao and Zhou, Gengze and Hong, Yicong and Fang, Xiaomeng and Wu, Qi and Zhang, Zhizheng and Wang, He},
  booktitle = {Proceedings of Robotics: Science and Systems},
  year={2024}
}
@INPROCEEDINGS{Zhang-RSS-24, 
    AUTHOR    = {Jiazhao Zhang AND Kunyu Wang AND Rongtao Xu AND Gengze Zhou AND Yicong Hong AND Xiaomeng Fang AND Qi Wu AND Zhizheng Zhang AND He Wang}, 
    TITLE     = {{NaVid: Video-based VLM Plans the Next Step for Vision-and-Language Navigation}}, 
    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, 
    YEAR      = {2024}, 
    ADDRESS   = {Delft, Netherlands}, 
    MONTH     = {July}, 
    DOI       = {10.15607/RSS.2024.XX.079} 
}
@inproceedings{wang2023dreamwalker,
  title={Dreamwalker: Mental planning for continuous vision-language navigation},
  author={Wang, Hanqing and Liang, Wei and Van Gool, Luc and Wang, Wenguan},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={10873--10883},
  year={2023}
}
@inproceedings{wang2024lookahead,
  title={Lookahead Exploration with Neural Radiance Representation for Continuous Vision-Language Navigation},
  author={Wang, Zihan and Li, Xiangyang and Yang, Jiahao and Liu, Yeqi and Hu, Junjie and Jiang, Ming and Jiang, Shuqiang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={13753--13762},
  year={2024}
}




@article{chen2024affordances,
  title={Affordances-Oriented Planning using Foundation Models for Continuous Vision-Language Navigation},
  author={Chen, Jiaqi and Lin, Bingqian and Liu, Xinmin and Ma, Lin and Liang, Xiaodan and Wong, Kwan-Yee K},
  journal={arXiv preprint arXiv:2407.05890},
  year={2024}
}