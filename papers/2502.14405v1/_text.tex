% ======================================================================================
\section{Introduction}
Audio effects are central for engineers and musicians to shape the timbre, dynamics, and spatialisation of sound~\cite{wilmering2020history}.
% For some instruments (e.g., electric guitar) the processing signal chain can often be viewed as part of the artist’s creative expression \cite{case2010recording}.
% Entire musical genres and styles are frequently defined and identified by the type of audio effects adopted \cite{blair2015southern, williams2012tubby}; and renowned musicians commonly rely on specific combinations of instruments and effects to achieve a unique sound \cite{prown2003gear}.
For some instruments (e.g., electric guitar) the processing chain is part of the artist’s creative expression \cite{case2010recording} 
and music genres and styles are also defined by the type of effects adopted 
\cite{blair2015southern, williams2012tubby}
; with renowned musicians adopting specific combinations to achieve a unique sound \cite{prown2003gear}.
% Therefore, research related to audio effects, especially since the development and success of deep learning \citep{bengio2017deep} and differentiable digital signal processing \citep{engel2020ddsp} techniques, is a very active field \citep{comunita19afxresearch}, with many avenues of investigation open.
Therefore, research related to audio effects, especially with the success of deep learning 
\citep{bengio2017deep} 
and differentiable digital signal processing (DDSP) \citep{engel2020ddsp}, is a very active field \citep{comunita19afxresearch}, with many avenues of investigation open, like:
audio effects classification and identification 
\citep{
comunita2021guitar, 
hinrichs2022classification}, 
% hinrichs2022convolutional, 
% guo2023automatic, 
% hinrichs2024blind, 
% take2024audio}
settings or coefficients estimation and extraction 
\citep{
kuznetsov2020differentiable, 
nercessian2020neural, 
colonel2022direct}, 
% mitcheltree2023modulation, 
% bargum2023differentiable, 
% yu2024differentiable}
modeling 
\citep{
martinez2021deep, 
wright2023adversarial}, 
% carson2023differentiable, 
% chen2024improving, 
% simionato2024comparative, 
% yeh2024ddsp
% and removal 
% \citep{
% zavivska2020survey, 
% gaultier2021sparsity, 
% tanaka2022applade, 
% imort2022distortion, 
% rice2023general}
processing graph estimation 
\citep{
lee2023blind, 
lee2024searching} 
and style transfer 
\citep{
steinmetz2022style, 
% koo2023music, 
vanka2024diff, 
steinmetz2024st}, 
automatic mixing 
\citep{
steinmetz2021automatic, 
martinez2022automatic}
% koo2022end, 
% koszewski2023automatic, 
% sai2023adoption} 
or reverse engineering of a mix 
\citep{
% colonel2021reverse, 
colonel2022reverse, 
colone2023reverse}. 
% colonel2023music}.

% By far the most active, especially due to the interest in recreating digital emulations of vintage and/or expensive analog devices, is the field of audio effects modeling - also referred to as virtual analog - with methods often categorized into white-, gray- and black-box approaches (see Section \ref{sec:background}); 
% and, when adopting techniques that support gradient backpropagation, referred to as differentiable white-, gray- and black-box approaches.
One of the most active, driven by interest in emulating vintage or costly analog devices, is audio effects modeling (virtual analog), often categorized into white-, gray-, and black-box approaches (see Sec.~\ref{sec:background});
and, when using techniques that support gradient backpropagation, referred to as differentiable white-, gray- and black-box.
% With the possibility of using data (e.g., audio recordings or measurements) for gradient descent and automatically learn a model, differentiable methods have become a common approach, and great effort is going into developing architectures that not only can accurately capture an audio effect behavior - and possibly do it in a computationally efficient way - but that are expressive enough to model a wide variety of effect categories and devices.
Differentiable methods, leveraging data for gradient descent, are widely used to learn audio effect models. 
Efforts focus on developing architectures that are both accurate and computationally efficient while being expressive enough to model diverse effect categories and devices.
% Out of the three macro categories of audio effects: linear (e.g., equalization and reverb), nonlinear (e.g., distortion and compression) and modulation (e.g., phaser and flanger); nonlinear effects are the ones that received most of the attention of the research community, with architectures proposed mainly for black-box and gray-box methods (see Secs.~\ref{sec:back-diff-black-box} and \ref{sec:back-diff-gray-box}).

Of the three macro categories of audio effects - linear (e.g., EQ, reverb), nonlinear (e.g., distortion, compression), and modulation (e.g., phaser, flanger) - nonlinear effects have received the most attention, with architectures mainly proposed for black- and gray-box methods (see Secs.~\ref{sec:back-diff-black-box} and \ref{sec:back-diff-gray-box}).
% Although many models have been proposed for nonlinear audio effects modeling, most of the works focus on a single effect category among, e.g., guitar amplifiers, overdrive, distortion, fuzz or dynamic range compressors; and evaluated against previous art on a single or a limited number of devices.
Most nonlinear audio effects models focus on a single category (e.g., guitar amplifiers, distortion, compressors) and are evaluated on a single or limited set of devices.
% Meaning that, even with all the effort, there is not a clear state of the art yet that can indicate the best performing approach, especially when aiming at developing architectures capable of reliably model all types of nonlinear effects and across a wide range of devices.
Despite the effort, there is no clear state of the art yet that identifies the best-performing approach, particularly for developing architectures that can reliably model all types of nonlinear effects across a wide range of devices.
% Also, in all previous literature, training and evaluation are conducted on data recorded from the same sources (e.g. a specific electric guitar or bass) and very similar content, playing techniques and style, not allowing to reach a reliable conclusion about the generalization capabilities of a trained model.
Also, all previous works train and evaluate on data recorded from the same sources (e.g. a specific electric guitar or bass) and very similar content, playing techniques and style, not allowing to reach a reliable conclusion about the generalization capabilities of a trained model.
In most cases, training and testing data is normalized without verifying the input dynamic range, not ensuring trained models to be accurate across signal levels.

% Therefore, to address these and other limitations (see Secs. \ref{sec:tonetwist} and \ref{sec:training}) in previous work, to draw an accurate picture of the state of the art, and to identify avenues for further research we conduct an extensive set of experiments (see Sec. \ref{sec:experiments}).
Therefore, to overcome these limitations, assess the state of the art, and identify research directions, we conduct extensive experiments.
In doing so, our work contributes mainly in the following ways:
\begin{itemize}
    \item Evaluate and compare differentiable black-box and gray-box approaches for modeling nonlinear audio effects like guitar amplifiers, overdrive, distortion, fuzz, and compression (Sec.~\ref{sec:experiments}).
    \item Introduce time-varying gray-box models and propose models for compressor/limiter, distortion and fuzz effects (Sec.~\ref{sec:gb-models}).
    % \item Propose computationally efficient time-varying conditioning mechanisms for black-box architectures and compare against established ones (Sec.~\ref{sec:cond-bb-models}).
    \item Publish a large dataset of dry-input/wet-output pairs for audio effects research that is also the first open to community contributions (Sec.~\ref{sec:tonetwist}).
    % \item Publish code for an audio effects modeling framework to experiment with and compare existing architectures, as well as advance the state of the art by introducing novel ones (Sec.~\ref{sec:framework}).
    \item Evaluate the models on a variety of metrics (Sec.~\ref{sec:obj_eval}) and conduct extensive subjective evaluation (Sec.~\ref{sec:subj_eval}).
\end{itemize}

The remainder of the paper is organized as follows. 
% In Section~\ref{sec:background} we draw the landscape of non-differentiable and differentiable white-, gray- and black-box approaches to audio effects modeling. 
In Section~\ref{sec:background}, we outline non-differentiable and differentiable white-, gray-, and black-box approaches to audio effects modeling.
% Section~\ref{sec:framework} introduces the NablAFx audio effects modeling framework, while 
Sections~\ref{sec:bb-models} and \ref{sec:gb-models} describe the black- and gray-box architectures included in our experiments, while the ToneTwist AFx dataset is described in \ref{sec:tonetwist}. 
Experiments and results are illustrated and discussed in Sections \ref{sec:experiments} and \ref{sec:results}, and objective and subjective evaluations are presented in \ref{sec:eval}. 
We conclude the manuscript in \ref{sec:conclusion}.

% ======================================================================================
% \clearpage
\section{Background}
\label{sec:background}
% ======================================
\subsection{Nonlinear Audio Effects Modeling}
\label{sec:back-nnlinafx-modeling}

% For many decades scientists and engineers have been interested in methods and technologies to formalize and digitally recreate harmonic and non-harmonic distortion \citep{schaefer1970electronic, suen1970derivation, le1979digital, roads1979tutorial} for musical applications.
% For decades, scientists and engineers have explored methods to digitally recreate harmonic and non-harmonic distortion for musical applications 
% \citep{
% schaefer1970electronic, 
% % suen1970derivation, 
% le1979digital, 
% roads1979tutorial}.
% And since the 90s companies like Yamaha Corp \citep{doidic1998tube, kuroki1998digital}, Softube AB \citep{gustaffsson2012system} or Kemper Amps \citep{kemper2014musical} have filed patents with this purpose and that are at the base of products still on the market nowadays\footnote{\url{https://www.kemper-amps.com/}}\footnote{\url{https://www.softube.com/}}.
% Since the '90s, companies like Yamaha Corp 
% \citep{
% % doidic1998tube, 
% kuroki1998digital}, 
% Softube AB \citep{gustaffsson2012system}, 
% and Kemper Amps \citep{kemper2014musical} have filed patents that form the basis of products still on the market today\footnote{\url{https://www.kemper-amps.com/}}\footnote{\url{https://www.softube.com/}}.

% The first example of thorough investigation of the potential of nonlinear distortion for musical applications is the 1979 work of Le Brun on waveshaping \citep{le1979digital} and the following tutorial by Roads \citep{roads1979tutorial}.
The first thorough investigation of nonlinear distortion for musical applications is Le Brun's 1979 work on waveshaping \citep{le1979digital} and Roads' subsequent tutorial \citep{roads1979tutorial}.
% And in the following decades numerous techniques were added with the main purpose of digitally simulating or emulating nonlinear analog circuits and devices. 
In the following decades, numerous techniques were developed to digitally simulate or emulate nonlinear analog circuits and devices.
This is why we now have approaches based on: 
solving or approximating the equations describing a system's behavior, 
% \citep{
% % suen1970derivation, 
% yeh2007simulation, 
% macak2010real}
% wilczek2022virtual}
% dynamic convolution, 
% \citep{kemp1999analysis}, 
wave digital filters, 
% \citep{fettweis1986wave}, 
state-space modeling, 
% \citep{
% yeh2009digital, 
% holters2015generalized, 
% bennett2022state}
% port-hamiltonian mechanics, 
% \citep{van2006port}
Volterra series 
% \citep{schattschneider1999discrete} 
or Wiener-Hammerstein models, 
% \citep{
% schoukens2017identification, 
% schoukens2019nonlinear}
just to name a few.
And, with the advancement of machine learning, neural networks based modeling 
% \citep{martinez2021deep} 
and differentiable DSP 
% \citep{hayes2024review} 
have been added to the state of the art.

% Depending on the degree of prior knowledge applied to model a target device, the existing approaches for audio effects modeling can be divided into three categories: white-, gray- and black-box.
% And, if the implementation supports gradients backpropagation, we then talk of differentiable white-, gray- and black-box approaches.
Audio effects modeling approaches can be categorized into white-, gray-, and black-box, based on the degree of prior knowledge applied, and further classified as differentiable if they support gradient backpropagation.
% In the following sections we draw a picture of previous art for nonlinear audio effects modeling and describe the different emulation paradigms and techniques.
The following sections review previous work on nonlinear audio effects modeling and describe emulation paradigms and techniques.

% ======================================
\subsection{White-box Modeling}
\label{sec:back-white-box}

% White-box modeling is based on the complete knowledge of the system, uses ordinary/partial differential equations to describe its behavior and adopts numerical methods to solve them in the continuous or discrete domain.
White-box modeling relies on full system knowledge, using differential equations to describe its behavior and numerical methods to solve them in the continuous or discrete domain. 
% Since they reproduce all the important characteristics of a target device, such models can achieve very good results and are preferable when the sound of a specific analog device is to be replicated with high accuracy.
These models provide accurate results, making them ideal for replicating specific analog devices.
Although, they can be time-consuming to develop, require exact knowledge of the equations describing nonlinear elements and access to the circuit schematic, and can result in substantial computational load.

Simple systems can be modeled manually by solving the equations 
\citep{
yeh2007simulation, 
d2014generalized, 
esqueda2017virtuallockhart}; 
but, for more complex cases, there exist general-purpose frameworks like: 
state-space models 
\citep{mavcak2012real, holters2015generalized, yeh2009automated}, 
wave digital filters 
\citep{
werner2015wave, 
% werner2018modeling, 
% dunkel2016fender, 
% cauduro2011real, 
de2009virtual, 
d2012new}, 
port-hamiltonian systems 
\citep{falaize2016passive}.

In practice, solving \textbf{equations} have mostly been applied to a small subset of single nonlinear processing blocks like: 
vacuum tube 
\citep{
sapp1999simulation, 
karjalainen2006virtual, 
% santagata2007non, 
% cardarilli2009improved, 
dempwolf2011physically} 
or transistor stages 
\citep{d2019fast}, 
diode clippers 
\citep{
yeh2007simulation, 
% macaksimulation, 
% macak2009nonlinear, 
germain2015design, 
% schuck2019simple, 
d2019fast}, 
transformers 
\citep{macak2011nonlinear}, 
moog ladder filter 
\citep{
d2013improved, 
d2014generalizedI, 
d2014generalizedII} 
or the Buchla 259 wavefolder 
\citep{esqueda2017virtualbuchla}.
But there are also examples of literature modeling complete devices with this method 
\citep{
% overton2006digital, 
yeh2007simplified, 
macak2013guitar}. 
% koper2020taming}.

% The most studied framework for white-box modeling are \textbf{wave digital filters} (WDF), a method that emulates analog circuits based on the theory of traveling waves (scattering theory) and uses wave variables instead of standard circuit variables (i.e., voltage and current) to represent the behavior of circuit elements. WDFs are designed to preserve key properties of analog circuits such as passivity and energy conservation, making them stable and robust for digital implementation
The most studied white-box modeling framework is \textbf{wave digital filters} (WDF), which emulates analog circuits using traveling wave (scattering) theory and wave variables (instead of voltages and currents), preserving properties like passivity and energy conservation for stable, robust digital implementation.
\footnote{\url{https://ccrma.stanford.edu/~dtyeh/papers/wdftutorial.pdf}}
\citep{fettweis1986wave}.

Beside single nonlinear blocks like: 
vacuum tube 
\citep{
karjalainen2006wave, 
yeh2008simulating, 
% yeh2009digital, 
% pakarinen2009enhanced, 
d2012wave}
% d2012new}
or transistor stages 
\citep{
yeh2008simulating, 
yeh2009digital, 
% bernardini2015modeling, 
% bernardini2016modeling, 
% olsen2016resolving, 
bogason2018modeling}, 
% bernardini2020wave}
diode clippers 
\citep{
% petrausch2004wave, 
yeh2008numerical, 
yeh2008simulating, 
% yeh2009digital, 
% paiva2012emulation, 
% schwerdtfeger2014multidimensional, 
werner2015improved, 
% werner2015general, 
% bernardini2016dynamic, 
% bernardini2016modeling, 
% olsen2016resolving, 
% werner2015resolving, 
bernardini2017biparametric}, 
% werner2017generalizing}
opamps 
\citep{
yeh2009digital, 
% werner2016wave, 
bogason2017modeling}, 
nonlinear filters 
\citep{
werner2015resolving, 
bogason2018modeling} 
and transformers 
\citep{
pakarinen2009wave}; 
% cauduro2011real}
we also find examples of WDFs applied to complete devices like: 
overdrive and distortion pedals 
\citep{
yeh2009digital, 
bernardini2020wave},
amplifiers 
\citep{
pakarinen2009wave, 
de2009virtual}, 
% dunkel2016fender, 
% zhang2018real}
limiters 
\citep{raffensperger2012toward}.

Similar observations are valid for \textbf{state-space methods}, which represent an electronic circuit as a system of first-order differential equations, describing the circuit in terms of state variables, inputs, and outputs. 
% This method uses matrix algebra to model the relationships between circuit components, allowing for efficient digital simulation of complex analog systems.
Using matrix algebra to model components relationships, this method enables efficient digital simulation of complex analog systems.
Methods developed for the simulation of state-space systems include the K-method 
\citep{
% borin2000elimination, 
yeh2006discretization, 
yeh2009digital}
the Nodal K-method (or NK-method) and the Discrete K-method (or DK-method or Nodal DK-method) 
\citep{
yeh2009digital, 
yeh2009automated}. 
% yeh2011automated
% }.

Examples of state-space methods applied to single nonlinear blocks include: 
vacuum tubes, 
% \citep{
% yeh2008simulating, 
% yeh2009digital, 
% cohen2009simulation, 
% cohen2010measures, 
% yeh2011automated}
transistors, 
% \citep{
% yeh2008simulating, 
% yeh2009digital, 
% yeh2011automated},
% holmes2019guitar}
diode clippers 
% \citep{
% yeh2008simulating, 
% yeh2009digital, 
% yeh2009automated} 
% holters2015generalized, 
% holmes2015improving}
and opamps
\citep{
yeh2008simulating, 
yeh2009digital, 
yeh2009automated}, 
% \citep{yeh2009digital}
or transformers 
\citep{holters2016circuit}.
But also find examples of emulation of complete devices like: 
overdrive and distortion 
\citep{
yeh2009digital, 
holmes2015improving}, 
% holmes2016physical, 
% holmes2017comparison, 
% holmes2019guitar}
fuzz 
\citep{
holmes2017comparison, 
% holmes2019guitar, 
bennett2022state},
compression 
\citep{kroning2011analysis},
or amplifiers 
\citep{
cohen2010real, 
% cohen2010measures, 
macak2012simulation}.

% \textbf{Port-Hamiltonian} approaches digitally emulate analog circuits based on the principles of Hamiltonian mechanics, focusing on the conservation of energy within a system 
% \citep{van2006port}.
\textbf{Port-Hamiltonian} approaches emulate analog circuits using Hamiltonian mechanics, focusing on energy conservation \citep{van2006port}.
% The only example of such approach applied to nonlinear audio effects is limited to single transistor stages and diode clippers 
The only application of this approach to nonlinear audio effects is limited to single transistor stages and diode clippers.
\citep{falaize2016passive}.\\

% ======================================
\subsection{Black-box Modeling}
\label{sec:back-black-box}

% In black-box approaches, minimal knowledge of the system is required and modeling mostly relies on input-output measurements.
Black-box approaches require minimal system knowledge, and mostly rely on input-output data; simplifying the process to collecting adequate data.
% A major advantage is that they simplify the process to collecting adequate data. 
However, such models often lack interpretability and might entail time-consuming optimizations.
The main non-differentiable black-box methods are based on Volterra series and dynamic convolution.

\textbf{Volterra series} represent a nonlinear system as an infinite series of integral operators, analogous to a Taylor series expansion but in the context of systems and signals. 
The output is given by a sum of convolutions of the input signal with a series of kernels (functions), and the modeling procedure mainly involves extracting such kernels from input-output measurements.
Although it has been applied to a range of nonlinear blocks 
\citep{
helie2006use, 
yeh2008numerical} 
% helie2009volterra, 
% agerkvist2010volterra}
and effects 
\citep{
carini2015legendre, 
tronchin2013emulation, 
% tronchin2015further, 
schmitz2017hammerstein, 
orcioni2017multivariance, 
% orcioni2018identificationI, 
% orcioni2018identificationII, 
carini2019nonlinear}
% , it is shown to only be sufficiently accurate for weakly nonlinear systems, making it not applicable to most nonlinear audio effects.
, this method is sufficiently accurate only for weakly nonlinear systems, making it not applicable to most nonlinear audio effects.

% The same can be said for \textbf{dynamic convolution} 
% \citep{
% kemp1999analysis, 
% primavera2012approximation}
% , where the impulse response or processing kernels of a system are varied as a function of the present and/or past input amplitudes to model non-linear or hysteretic behaviors of a system.
The same applies to \textbf{dynamic convolution}
\citep{
kemp1999analysis, 
primavera2012approximation}
, which adjusts impulse responses or processing kernels based the present/past input amplitude to model nonlinear or hysteretic behavior.

% ======================================
\subsection{Gray-box Modeling}
\label{sec:back-gray-box}

Gray-box approaches combine a partial theoretical structure with data - typically input/output measurements - to complete the model.
% Grey-box models have the advantage of greatly reducing the prior knowledge necessary to model a device while maintaining a degree of interpretability, thanks to the block-oriented approach.
They reduce prior knowledge requirements while maintaining interpretability through a block-oriented approach; although, the specific structure, measurements and optimization procedures, are critical to achieve a good approximation.

% For nonlinear effects like amplifiers, overdrive, distortion and fuzz, the baseline approach is to define a model as an interconnection of linear filters and static nonlinearities, such as: Hammerstein models (static nonlinearity followed by linear filter), Wiener models (linear filter followed by static nonlinearity) or Wiener-Hammerstein models (static nonlinearity in between two linear filters).
For nonlinear effects like amplifiers and distortion, models are typically defined as an interconnection of linear filters and static nonlinearities, such as: Hammerstein models (static nonlinearity followed by linear filter), Wiener models (linear filter followed by static nonlinearity) or Wiener-Hammerstein models (static nonlinearity in between two linear filters).
Although, for greater accuracy \textbf{Wiener-Hammerstein models} have often been extended to include: 
non-static nonlinearities (i.e., hysteresis and memory) 
\citep{
eichas2015block, 
eichas2016black, 
eichas2018gray},
or a cascade of pre- and power-amp models 
\citep{
kemper2014musical, 
eichas2017block}.
There exist more complex arrangements made of cascaded and parallel blocks (see \citep{schoukens2019nonlinear} for more examples) and, for nonlinear effects, 
parallel polynomial 
\citep{
novak2009nonlinear, 
% novak2010analysis, 
cauduro2012reduced} 
% germain2012uniform} 
and Chebyshev 
\citep{
novak2010chebyshev, 
bank2011computationally} 
Hammerstein models have also been adopted.

To model dynamic range compression, all proposed methods 
\citep{
ramos2011block, 
eichas2016modeling} 
% mccormack2017fft} 
are based on the block-oriented architecture described in 
\citep{zolzer2002dafx} 
and analyzed in details in 
\citep{giannoulis2012digital}.

% ======================================
\subsection{Differentiable White-box Modeling}
\label{sec:back-diff-white-box}

With the recent rise of machine learning the research community started applying neural networks and DDSP to white-, gray- and black-box modeling.
% In \citep{parker2019modelling}, the authors adopt a multi-layer perceptron (MLP) in the context of a state-space model, which they call state trajectory network. 
% The network uses both the input signal and an internal state to predict the output. 
In \citep{parker2019modelling}, the authors use a multi-layer perceptron (MLP) as a state-space model, called a state trajectory network, which predicts the output based on the input signal and an internal state.
Since state-space models are based on circuit variables, when applying the method to a first-order and a second-order diode clipper the authors adopt input and internal voltages as training signals to predict output voltage.
This approach is then extended in \citep{peussa2021exposure} using a gated recurrent unit (GRU).\\
% In \citep{esqueda2021differentiable} the authors introduce the concept of differentiable white-box virtual analog modeling, with the idea of using backpropagation to optimize the components' values in an analog circuit. The method is applied to find the resistors' and capacitors' values that best approximate the frequency response of an RC filter and a tone-stack.
In \citep{esqueda2021differentiable}, the authors introduce differentiable white-box virtual analog modeling, using backpropagation to optimize component values in analog circuits, applied to find optimal resistor and capacitor values that approximate the frequency response of an RC filter and tone-stack.\\
The idea of learning ordinary differential equations using differentiable methods is applied in \cite{wilczek2022virtual} to learn the governing equations of diode clippers.\\
% Another recent work \citep{parker2022physical} uses recurrent neural networks with fast convolutional layers to model partial-differential equations governed systems. Specifically, they use the proposed approach to investigate: lossy dispersive string, 2D wave equation and tension modulated string.
In \citep{parker2022physical}, the authors use recurrent neural networks with fast convolutional layers to model partial-differential equation governed systems, applying it to lossy dispersive string, 2D wave equation, and tension-modulated string.\\
% Analogously to \citep{parker2019modelling} for state-space models, in \citep{chowdhury2022emulating} the concept of differentiable wave digital filters is introduced, where an MLP is used to learn the relation between input and output wave variables for a diode clipper.
Analogously to \citep{parker2019modelling} for state-space models, \citep{chowdhury2022emulating} introduces differentiable wave digital filters, using an MLP to learn the input-output relationship of wave variables in a diode clipper.

% ======================================
\subsection{Differentiable Black-box Modeling}
\label{sec:back-diff-black-box}

% Black-box modeling is by far the most common paradigm adopted for differentiable audio effects modeling, and it has been applied to most linear, non-linear and modulation effects; although with different degrees of success.
Black-box modeling is the most common approach for differentiable audio effects, and it has been applied to most linear, non-linear, and modulation effects, although with varying success.

The first example of neural networks adoption for a modeling task is \citep{mendoza2005emulating}, where the author uses an \textbf{MLP} to model overdrive.
Following this, recurrent networks were proposed for guitar amplifiers modeling, with \textbf{echo state machines} \citep{holzmann2009reservoir} and \textbf{NARX} networks \citep{covert2013vacuum} being adopted due to their easier and more stable training with respect to early LSTMs.
Although, once the training issues were overcome, recurrent networks like \textbf{LSTMs} \citep{zhang2018vacuum, schmitz2018nonlinear} have become a common approach, with different nonlinear effects, architectures and conditioning methods being further studied in 
\citep{wright2019real, wright2020real, wright2020perceptual, chowdhury2020comparison, simionato2022deep, simionato2024comparative, yeh2024hyper}.

In \citep{schmitz2019objective}, an \textbf{hybrid CNN and LSTM} architecture is explored for guitar amps emulation, while \citep{ramirez2019modeling} is the first example of \textbf{Encoder/Decoder} (ED) architecture applied to nonlinear effects, although limited by a low sampling rate (16~kHz) and non-causal implementation.
Improvements on this ED architecture were further explored in \citep{ramirez2019general, martinez2020deep} and applied to dynamic range compression among other effects.

\textbf{CNN} architectures took longer to be explored as a modeling approach. 
In the first examples 
\citep{damskagg2019real, damskagg2019deep} 
the authors used a non-autoregressive WaveNet 
\citep{rethage2018wavenet}, also known as a gated convolutional network (GCN), which is a special case of temporal convolutional network (TCN) \citep{bai2018empirical} that uses gated activations. 
These works focused on guitar amplifiers, overdrive, and distortion effects, and achieved results equal or better than recurrent networks in a subjective test \citep{wright2020real}.
TCNs have been proposed for compressor modeling in \citep{steinmetz2022efficient}, while GCNs have been extended with temporal feature-wise linear modulation (TFiLM) \citep{birnbaum2019temporal} in \citep{comunita2023modelling} to model time-varying nonlinear effects like fuzz and compressor, and shown in both cases to outperform recurrent networks and standard GCNs.

ED-based architectures have also been further explored in the time \citep{simionato2023fully} and spectrogram \citep{hawley2019profiling, mitchell2020exploring} domain for compressor modeling.
More recently, with the success of \textbf{state-space models} 
\citep{gu2021combining, gu2021efficiently, gu2023mamba} 
in general time series modeling tasks, the application to effects modeling like compressor and overdrive were also explored 
\citep{yin2024modeling, simionato2024comparative, simionato2024modeling}.
It is also worth noticing how LSTMs and GCNs have also been adopted for patents on differentiable nonlinear audio effects modeling for commercial products \citep{borquez2022neural} (Neural DSP Technologies).

% ======================================
\subsection{Differentiable Gray-box Modeling}
\label{sec:back-diff-gray-box}

With the development of DDSP \citep{hayes2024review}, it has become possible and also desirable to explore differentiable gray-box approaches to audio effects modeling. 
The main advantages being the reduced number of parameters and higher computational efficiency w.r.t. neural networks as well as the higher degree of interpretability.
% Similarly to non-differentiable methods, there is a limited number of studies on block-based differentiable modeling with all proposed architectures implementing or extending W-H models for nonlinear effects like guitar amps, overdrive, distortion and fuzz, or implementing differentiable versions of the compressor model proposed in \citep{zolzer2002dafx}.

Few studies explore block-based differentiable modeling, with most extending W-H models for nonlinear effects (guitar amps, overdrive, distortion, fuzz) 
\citep{
kuznetsov2020differentiable, 
nercessian2021lightweight, 
colonel2022reverse, 
miklanek2023neural, 
yeh2024ddsp} 
or implementing a differentiable version
\citep{
lee2024searching, 
yu2024differentiable, 
colonel2022approximating, 
wright2022grey} 
of previously suggested implementations of feed-forward digital compressors 
\cite{zolzer2002dafx, giannoulis2012digital}.

% The first example inspired to \textbf{W-H models} is presented in \citep{matsunaga2018digital} and tested on overdrive emulation.
The first \textbf{W-H model}-inspired approach \citep{matsunaga2018digital} tests overdrive emulation, with input and output convolutional layers used to learn FIR filters and LSTM layers used to learn a nonlinearity.
A similar approach \citep{taylor2020latent} implements guitar amps emulation as a series of six learnable Wiener models (i.e., linear filters followed by nonlinearity). 
Here the filters are implemented as fixed band-pass, while the scaling factor for each band component is learned, and the nonlinear block is set to a soft-sign. 
Tested on several amplifiers, it allows to implement \textit{hybrid models} by interpolating coefficients from different amps.

\textbf{DDSP} for gray-box modeling is first explored in \citep{kuznetsov2020differentiable}, where differentiable linear time-invariant filters and a nonlinearity form a W-H model that emulates the Boss DS-1 distortion pedal.
LTI filters are implemented either as FIRs with 128 taps or second-order IIRs (biquads), while an MLP is used as a memoryless nonlinearity.\\
For their model of the Boss MT-2 distortion pedal, Nercessian et al. \citep{nercessian2021lightweight} adopt a cascade of 40 hyperconditioned filtering stages, each made of biquad, gain and $\tanh$ nonlinearity.
Hyperconditioning \citep{ha2022hypernetworks, serra2019blow} involves using neural networks to adjust the internal coefficients or weights of a differentiable block, such as a neural network or DDSP block. 
In this case, a parametric model is obtained by conditioning, through affine transformations, biquad coefficients and gain.
Therefore, the controllers we use in our work (see Sec.\ref{sec:gb-dist}) are a form of hyperconditioning. 
Though interpretable, the long sequence of nonlinear filters doesn't closely match the actual circuit or is easily observable.\\
Also Colonel et al. \citep{colonel2022reverse} explore differentiable W-H models with a focus on proposing several parametric nonlinearities: harmonic sum of $\tanh$ functions, power sum of $\tanh$ functions, Fourier series and Legendre polynomials.
LTI filters are implemented as differentiable 20-band FIR graphic EQs. 
While good results are achieved, the model is limited to single input-output pairs (overfitting to one example) and is non-parametric.\\
In \citep{miklanek2023neural}, Miklanek et al. proposed a hybrid differentiable guitar amplifier model, combining black-box and gray-box approaches. The pre- and power amplifiers are modeled using recurrent and fully connected layers, while a differentiable parametric tone-stack model, with a known processing function, is placed between them.\\
A recent guitar amplifier model in \citep{yeh2024ddsp} features a detailed, differentiable parametric processor for each stage of a typical amplifier's analog circuit. 
This includes several W-H stages for the pre-amplifier, a tone-stack \citep{miklanek2023neural}, a custom AB push-pull power amplifier model, and a custom output transformer model. 
Despite its advanced design, the best-performing gray-box arrangement significantly underperforms compared to a single-layer recurrent network, with more trainable parameters (10.1k vs. 8k), resembling a black-box model in size.


% In \citep{nercessian2021lightweight}, authors implement differentiable biquad filters and cascade them with tanh nonlinearities to model a guitar distortion pedal; however, the use of 40 blocks reduces the interpretability typical of gray-box methods.\\


% \textbf{DDSP} for gray-box modeling is first explored in \citep{kuznetsov2020differentiable}, where differentiable IIR filters together with an MLP are used as a W-H model to emulate the Boss DS-1 distortion pedal.
% The model is made of an MLP memoryless nonlinearity between differentiable linear time-invariant filters, either FIRs with 128 taps or second-order IIRs (biquads).\\

% In \citep{kuznetsov2020differentiable}, Kuznetsov et al. adopt a differentiable W-H model to emulate the Boss DS-1 distortion pedal. 
% The model is made of an MLP memoryless nonlinearity between differentiable linear time-invariant filters, either FIRs with 128 taps or second-order IIRs (biquads).\\


% More recently \citep{miklanek2023neural} a differentiable implementation of tone-stack typical of guitar amps have been proposed and adopted in between two small black-box models - LSTM- and GRU-based - to capture complete guitar amplifiers (i.e., preamp, tone controls, power amp). 
% Recently, \citep{miklanek2023neural} proposed a differentiable tone-stack for guitar amps which, placed between two small black-box models - LSTM- and GRU-based - was used to capture complete guitar amplifiers (i.e., preamp, tone controls, power amp). 
% Although this is considered a block-oriented approach, using black-box models makes it a sort of hybrid between black- and gray-box modeling.
% Though block-oriented, the use of black-box models makes it a hybrid of black- and gray-box modeling.\\
% A more detailed guitar amp model was proposed in \citep{yeh2024ddsp}, again dividing the structure into preamp, tone-stack and power amp. 
% Even with a structure more faithful to the typical circuit schematic, the added complexity makes this model comparable to some black-box ones for number of parameters while achieving lower accuracy.
% Despite being more faithful to the typical circuit schematic, its complexity matches some black-box models for parameters count, while achieving lower accuracy.



% While many approaches have been proposed to model dynamic range compression with differentiable black-box models 
% \citep{
% ramirez2019general, 
% hawley2019profiling, 
% steinmetz2022efficient, 
% simionato2022deep,
% comunita2023modelling, 
% % simionato2023fully,
% % fasciani2024conditioning,
% % simionato2024comparative,
% % simionato2024modeling,
% yeh2024hyper}
% , there are fewer studies that adopt a gray-box paradigm 
% \citep{
% % lee2024searching, 
% yu2024differentiable, 
% colonel2022approximating, 
% wright2022grey} 
% and are all based on two previously suggested implementations of feed-forward digital compressors 
% \cite{zolzer2002dafx, giannoulis2012digital}.


% In \citep{kuznetsov2020differentiable}, Kuznetsov et al. adopt a differentiable W-H model to emulate the Boss DS-1 distortion pedal. 
% The model is made of an MLP memoryless nonlinearity between differentiable linear time-invariant filters, either FIRs with 128 taps or second-order IIRs (biquads).\\
% 
% Also Colonel et al. \citep{colonel2022reverse} explore differentiable W-H models with a focus on proposing several parametric nonlinearities: harmonic sum of $\tanh$ functions, power sum of $\tanh$ functions, Fourier series and Legendre polynomials.
% LTI filters are implemented as differentiable 20-band FIR graphic EQs. 
% While good results are achieved, the model is limited to single input-output pairs (overfitting to one example) and is non-parametric.\\
% In \citep{miklanek2023neural}, Miklanek et al. proposed a hybrid differentiable guitar amplifier model, combining black-box and gray-box approaches. The pre- and power amplifiers are modeled using recurrent and fully connected layers, while a differentiable parametric tone-stack model, with a known processing function, is placed between them.\\
% A recent guitar amplifier model in \citep{yeh2024ddsp} features a detailed, differentiable parametric processor for each stage of a typical amplifier's analog circuit. 
% This includes several W-H stages for the pre-amplifier, a tone-stack \citep{miklanek2023neural}, a custom AB push-pull power amplifier model, and a custom output transformer model. 
% Despite its advanced design, the best-performing gray-box arrangement significantly underperforms compared to a single-layer recurrent network, with more trainable parameters (10.1k vs. 8k), resembling a black-box model in size.

% ======================================
\subsection{State of the art}
\label{sec:back-sota}

As we have seen in the previous sections there is a vast literature on nonlinear audio effects modeling detailing a large number of approaches and paradigms, which include both differentiable and non-differentiable implementations.
Generally speaking, the vast majority of the effort for non-differentiable methods is focused on white-box models, where the goal is to achieve a very accurate emulation of a specific device and - thanks to the access to and understanding of the circuit schematic - deterministic methods are still favorable and the best performing, assuming flexibility of a model is not a requirement and development time is not a concern.

Non-differentiable gray-box approaches have also been widely studied, especially for nonlinear effects like amps, overdrive and distortion, thanks to the theoretical basis guaranteed by W-H models. These are also used in commercial products, although they have never been thoroughly evaluated in subjective tests; it is therefore difficult to know whether they can compete with white-box methods in terms of accuracy.

Non-differentiable black-box methods have also been studied, but the literature does not highlight the potential to achieve sufficient emulation accuracy while still being difficult to optimize.

The opposite can be said for differentiable methods, where thanks to the wide development of neural networks, black-box approaches have become the most studied and achieved state-of-the-art performance while differentiable white-box methods have not yet developed and need to be further explored to understand their performance potential.

Similarly to gray-box methods, the differentiable counterpart has been proved to be useful and worth exploring further even if, at the moment of writing, cannot achieve state-of-the-art emulation accuracy and have not been thoroughly evaluated in subjective tests.

% ======================================================================================
\section{Methodology}
In the following sections we outline the key aspects of our work to establish a state of the art for differentiable black- and gray-box modeling. 
For consistency, ease of comparison, and to encourage future developments we rely on the \textbf{NablAFx}\footnote{\url{https://github.com/mcomunita/nablafx}}\citep{comunità2025nablafxframeworkdifferentiableblackbox} audio effects modeling framework.
We describe black- (Sec.~\ref{sec:bb-models}) and gray-box (Sec.~\ref{sec:gb-models}) architectures included in our experiments and introduce \textbf{ToneTwist AFx} (Sec.~\ref{sec:tonetwist}) - a novel dataset for audio effects research.

% ======================================
\subsection{Differentiable Black-box Models}
\label{sec:bb-models}
All architectures considered in our experiments are described in detail in \citep{comunità2025nablafxframeworkdifferentiableblackbox}; specifically, we include: LSTM-based recurrent networks, temporal convolution networks (TCN) \citep{lea2016temporal}, gated convolution networks (GCN) \cite{rethage2018wavenet} and structured state-space sequence models (S4) \citep{gu2021efficiently} with diagonal matrices \citep{gupta2022diagonal}.
Single LSTM layer architectures have been widely adopted for nonlinear (overdrive, distortion, guitar amps) \citep{wright2019real, wright2020real} and nonlinear time-varying (fuzz, compressor) \citep{steinmetz2022efficient, comunita2023modelling} effects.
Shown to outperform recurrent networks on various tasks, TCNs have also been adopted to model nonlinear time-varying effects, such as compressors \citep{steinmetz2022efficient}, while GCNs were proposed in \citep{
damskagg2019deep, 
damskagg2019real, 
wright2020real} 
for nonlinear (guitar amp, overdrive, distortion) and in \citep{comunita2023modelling} for nonlinear time-varying effects (compressor, fuzz).
More recently, S4 architectures were adopted for compressor modeling in \citep{yin2024modeling, simionato2024modeling}.
Since these architectures have each been applied to some but not all types of nonlinear effects, preventing clear conclusions on the state of the art, we include all of them in our experiments.

% ======================================
\subsection{Differentiable Gray-box Models}
\label{sec:gb-models}
As described in \citep{comunità2025nablafxframeworkdifferentiableblackbox}, we define a gray-box model as a sequence of differentiable processors, each with an associated controller which generates the control parameters that dictate the processor's exact behavior.
We propose gray-box architectures for dynamic range compression (Sec.\ref{sec:gb-comp}), distortion and fuzz (Sec.\ref{sec:gb-dist}).

% ======================================
\subsubsection{Model for Compressor/Limiter}
\label{sec:gb-comp}

While many approaches have been proposed to model dynamic range compression with differentiable black-box models 
\citep{
ramirez2019general, 
hawley2019profiling, 
steinmetz2022efficient, 
simionato2022deep,
comunita2023modelling, 
% simionato2023fully,
% fasciani2024conditioning,
% simionato2024comparative,
% simionato2024modeling,
yeh2024hyper}
, there are fewer studies that adopt a gray-box paradigm 
\citep{
% lee2024searching, 
yu2024differentiable, 
colonel2022approximating, 
wright2022grey} 
and are all based on two previously suggested implementations of feed-forward digital compressors 
\cite{zolzer2002dafx, giannoulis2012digital}.

% In this work we propose a very simple architecture that takes advantage of the idea of dynamic controller \citep{nablafx} to implicitly learn the compression curve as a function of the input signal and the attack/release time constants. 
Here we propose a simple architecture leveraging dynamic controllers \citep{comunità2025nablafxframeworkdifferentiableblackbox} to implicitly learn the compression curve as a function of input signal and attack/release time constants.
The model - shown in Fig. \ref{fig:gb-comp_gb-dist} with input $x_{n}$, output $y_{n}$ and controls $c$ - is composed of: Static Parametric EQ, Dynamic Gain, Static Parametric EQ, Static Gain. 
The first Parametric EQ captures the overall frequency response of a device while the Dynamic Gain models the compression curve.
The second Parametric EQ shapes the output timbre after nonlinear gain, and the output Gain is necessary to match the target level (make-up gain).
The same model can be made parametric by replacing all static/dynamic controllers with their conditional counterparts.
The dynamic controller works at the default block size of 128 samples, equivalent to 2.66ms at 48kHz sampling rate. 
To obtain a higher temporal resolution, and more accurate modeling, one could use a smaller block size and implement interpolation methods for smoother control sequences.

In Fig. \ref{fig:gb-comp-dist_example-response} we show examples of the frequency/time response learned by the proposed model when trained on a compressor (Flamma AnalogComp) and a limiter (UA 6176 Vintage Channel Strip - 1176LN Limiter). 
% In the first example the input and output EQs show different frequency response while in the second we notice that an almost perfectly symmetrical response is learned. 
In the first example, input and output EQs differ, while in the second, a nearly symmetrical response is learned.
% We also notice how the proposed dynamic Gain block successfully captures the different behaviors, with the compressor showing a slower attack than the limiter and a faster release. 
We notice how the Dynamic Gain successfully captures different behaviors, with the compressor having slower attack and faster release than the limiter; also the exponential time constants - typical of analog compressors - appear to be correctly captured.
% Also the exponential attack/release time constants - typical of analog dynamic range compressors - seems to be correctly captured.

\begin{figure*}[t]
    \begin{minipage}[b]{\textwidth}
        \centering
        \includegraphics[width=.75\textwidth]{FIGURES/GB-COMP.pdf}
        \\\textbf{(a)} Gray-box model for compressor/limiter
        \label{fig:gb-comp}
    \end{minipage}%
    \vspace{5mm}
    \begin{minipage}[b]{1\textwidth}
        \centering
        \includegraphics[width=\textwidth]{FIGURES/GB-DIST+FUZZ.pdf}
        \\\textbf{(b)} Gray-box model for amp/overdrive/distortion/fuzz
        \label{fig:gb-dist}
    \end{minipage}
    \caption{Proposed gray-box architectures}
    \label{fig:gb-comp_gb-dist}
\end{figure*}

% ======================================
\subsubsection{Model for Amplifier, Overdrive, Distortion and Fuzz}
\label{sec:gb-dist}

Similar to compression, there is also a wealth of literature on differentiable black-box models for: 
amplifiers,
\citep{
covert2013vacuum, 
zhang2018vacuum, 
schmitz2018real, 
schmitz2018nonlinear, 
schmitz2019objective, 
damskagg2019deep, 
wright2019real, 
wright2020real, 
wright2023adversarial} 
% chen2024improving}, 
overdrive 
\citep{
mendoza2005emulating, 
ramirez2019modeling, 
damskagg2019real, 
wright2020real, 
chowdhury2020comparison, 
fasciani2024conditioning, 
yeh2024hyper, 
simionato2024comparative}, 
distortion 
\citep{
ramirez2019modeling, 
damskagg2019real, 
wright2019real, 
wright2020real, 
yoshimoto2020deep, 
yoshimoto2021wavenet} 
% chen2024improving} 
and fuzz 
\citep{comunita2023modelling}. 
Recently, there has been exploration into applying a gray-box paradigm to this task 
\citep{
kuznetsov2020differentiable, 
nercessian2021lightweight, 
colonel2022reverse, 
miklanek2023neural, 
yeh2024ddsp}, 
as it offers desirable characteristics such as fewer trainable parameters, greater interpretability, and reduced training data requirements.

% In \citep{kuznetsov2020differentiable}, Kuznetsov et al. adopt a differentiable W-H model to emulate the Boss DS-1 distortion pedal. 
% The model is made of an MLP memoryless nonlinearity between differentiable linear time-invariant filters, either FIRs with 128 taps or second-order IIRs (biquads).\\
% For their model of the Boss MT-2 distortion pedal, Nercessian et al. \citep{nercessian2021lightweight} adopt a cascade of 40 hyperconditioned filtering stages, each made of biquad, gain and $\tanh$ nonlinearity.
% Hyperconditioning \citep{ha2022hypernetworks, serra2019blow} involves using neural networks to adjust the internal coefficients or weights of a differentiable block, such as a neural network or DDSP block. 
% In this case, a parametric model is obtained by conditioning, through affine transformations, biquad coefficients and gain.
% Therefore, the controllers we use in our work are a form of hyperconditioning. 
% Though interpretable, the long sequence of nonlinear filters doesn't closely match the actual circuit or is easily observable.\\
% Also Colonel et al. \citep{colonel2022reverse} explore differentiable W-H models with a focus on proposing several parametric nonlinearities: harmonic sum of $\tanh$ functions, power sum of $\tanh$ functions, Fourier series and Legendre polynomials.
% LTI filters are implemented as differentiable 20-band FIR graphic EQs. 
% While good results are achieved, the model is limited to single input-output pairs (overfitting to one example) and is non-parametric.\\
% In \citep{miklanek2023neural}, Miklanek et al. proposed a hybrid differentiable guitar amplifier model, combining black-box and gray-box approaches. The pre- and power amplifiers are modeled using recurrent and fully connected layers, while a differentiable parametric tone-stack model, with a known processing function, is placed between them.\\
% A recent guitar amplifier model in \citep{yeh2024ddsp} features a detailed, differentiable parametric processor for each stage of a typical amplifier's analog circuit. 
% This includes several W-H stages for the pre-amplifier, a tone-stack \citep{miklanek2023neural}, a custom AB push-pull power amplifier model, and a custom output transformer model. 
% Despite its advanced design, the best-performing gray-box arrangement significantly underperforms compared to a single-layer recurrent network, with more trainable parameters (10.1k vs. 8k), resembling a black-box model in size.

In this work, we extend previous gray-box approaches based on the W-H model. 
Fig.~\ref{fig:gb-comp_gb-dist} illustrates our comprehensive architecture for emulating amplifiers, overdrive, distortion, and - when using dynamic controllers - fuzz effects.
We use two Parametric EQs \citep{comunità2025nablafxframeworkdifferentiableblackbox} for pre- and post-emphasis filtering around a Nonlinearity, which can be memoryless or not. 
Gain stages control distortion and output amplitude, while an Offset stage before the nonlinearity models asymmetrical clipping. 
A fixed offset suffices for amplifiers, overdrive, and distortion, while a dynamic controller is needed for fuzz effects to capture hysteresis (i.e., dynamic bias shift) and the characteristic timbre during note attack and release.
Conditional controllers can turn the model into a parametric one.
Fig.~\ref{fig:gb-comp-dist_example-response} shows examples of learned dynamic offsets from fuzz effects models, with the first having a longer attack and much longer release time constants than the second.

\begin{figure*}[t]
    \begin{minipage}[b]{.31\textwidth}
        \centering
        \includegraphics[height=3.7cm]{FIGURES/Example_GB-COMP-Flamma_Response_1.png}
        \\\textbf{(1a)} Parametric EQ
        \label{fig:ex_eqblock_response}
    \end{minipage}
    \begin{minipage}[b]{.36\textwidth}
        \centering
        \includegraphics[height=3.7cm]{FIGURES/Example_GB-COMP-Flamma_Response_2.png}
        \\\textbf{(1b)} Dynamic Gain
        \label{fig:ex_nonlinblock_response}
    \end{minipage}
    \begin{minipage}[b]{.32\textwidth}
        \centering
        \includegraphics[height=3.7cm]{FIGURES/Example_GB-COMP-Flamma_Response_3.png}
        \\\textbf{(1c)} Parametric EQ
        \label{fig:ex_dcblock_response}
    \end{minipage}\\
    
    \begin{minipage}[b]{.31\textwidth}
        \centering
        \includegraphics[height=3.7cm]{FIGURES/Example_GB-COMP-UA_Response_1.png}
        \\\textbf{(2a)} Parametric EQ
        \label{fig:ex_eqblock_response}
    \end{minipage}
    \begin{minipage}[b]{.36\textwidth}
        \centering
        \includegraphics[height=3.7cm]{FIGURES/Example_GB-COMP-UA_Response_2.png}
        \\\textbf{(2b)} Dynamic Gain
        \label{fig:ex_nonlinblock_response}
    \end{minipage}
    \begin{minipage}[b]{.32\textwidth}
        \centering
        \includegraphics[height=3.7cm]{FIGURES/Example_GB-COMP-UA_Response_3.png}
        \\\textbf{(2c)} Parametric EQ
        \label{fig:ex_dcblock_response}
    \end{minipage}\\

    \begin{minipage}[b]{.50\textwidth}
        \centering
        \includegraphics[height=3.7cm]{FIGURES/Example_GB-FUZZ-Custom_Response_1.png}
        \\\textbf{(3a)} Dynamic Offset
        \label{fig:ex_offblock_response_1}
    \end{minipage}
    \begin{minipage}[b]{.50\textwidth}
        \centering
        \includegraphics[height=3.7cm]{FIGURES/Example_GB-FUZZ-HBFuzzyLogic_Response_1.png}
        \\\textbf{(4a)} Dynamic Offset
        \label{fig:ex_offblock_response_2}
    \end{minipage}
    % \caption{Examples of Dynamic Offset}
    \caption{Examples of response for gray-box models of (1) Flamma Compressor, (2) UA 6176 - 1176LN Limiter, (3) Custom Dynamic Fuzz, (4) Harley Benton Fuzzy Logic.}
    \label{fig:gb-comp-dist_example-response}
\end{figure*}

% ======================================
% \clearpage
\subsection{ToneTwist AFx Dataset}
\label{sec:tonetwist}

In order to establish the state of the art in audio effects modeling across various effect types, we required access to dry-input/wet-output data from multiple devices; and, since modeling mainly focuses on physical units, data needed to be from analog devices.
For a realistic scenario, data needed to include a variety of sources, content and playing techniques, to test generalization capabilities beyond the ones used for training.
Furthermore, to run extensive experiments efficiently, we needed consistently organized data to avoid custom preprocessing and dataset code for each device.

Although there are publicly available datasets for audio effects modeling \citep{stein2010automatic, comunita2021guitar, pedroza2022egfxset}, these were deemed unsuitable for our work for several reasons.
The IDMT-SMT-Audio-Effects\footnote{\url{https://www.idmt.fraunhofer.de/en/publications/datasets/audio\_effects.html}} \citep{stein2010automatic} dataset focuses on detection and classification tasks, it is limited to single notes and chords from two electric guitars and two electric basses, and it only includes digital effects covering 10 linear, non-linear, and modulation effects.
Similarly, GUITAR-FX-DIST \citep{comunita2021guitar}, which focuses on classification and parameter estimation,  
includes single notes and chords from two guitars and only features digital emulations of 14 distortion effects.
% , with multiple control settings per unit.
While EGFxSet\footnote{\url{https://egfxset.github.io/}} \citep{pedroza2022egfxset} includes recordings from 12 physical units, equally split between analog and digital, it only features single notes from one electric guitar; and, despite being intended for audio effects modeling, it is unsuitable due to high background noise and other artifacts.

For the reasons above, we introduce the ToneTwist AFx dataset\footnote{\url{https://github.com/mcomunita/tonetwist-afx-dataset}} (Table~\ref{tab:dataset}), the largest collection (40 devices at the time of writing) of dry/wet signal pairs from nonlinear audio effects.
Beside being the first thoroughly documented audio effects dataset, it is also open to contributions from the wider community.
While data is hosted on Zenodo\footnote{\url{https://zenodo.org/}} for long-term availability, 
% with separate records for each effect, detailed documentation, and links to dry source audio; 
our repository organizes download links, provides retrieval scripts, basic training code, and contribution guidelines, facilitating new submissions and fostering discussion.

ToneTwist AFx is organized into four categories: analog, analog parametric, digital, and digital parametric, with \textit{parametric} referring to entries sampled with control settings granularity sufficient for parametric modeling.
It features dry-input signals from seven sources, including a variety of guitars, basses, and test signals like chirps and white noise.
% Preprocessing, recording, and data organization are well-documented. 
The test set features different content and instruments from the training/validation set, ensuring a realistic evaluation of the generalization capabilities of trained models.

Recording was carried out with a Focusrite Scarlett Solo audio interface, featuring a low-noise pre-amplifier (±0.06 dB, 20Hz-20kHz). 
Synchronization between dry-input and wet-output was achieved by adding two impulses at the start and end of each file and then manually shifting each wet-output file of the same number of samples to account for interface latency.
Devices delays were assumed negligible.
We also ensure a high input dynamic range by applying a uniformly distributed gain ([-20dB, 0dB]) to the dry-input every 5 seconds. 

% We introduce the ToneTwist AFx dataset\footnote{\url{https://github.com/mcomunita/tonetwist-afx-dataset}} (Table~\ref{tab:dataset}), the largest collection of dry/wet signal pairs for nonlinear audio effects; it also covers other effect types and is designed to be easily extended.

% ToneTwist AFx is the first thoroughly documented dataset open to contributions from the wider community. 
% It serves as a platform for researchers and practitioners to share data and discuss improvements. While most recordings currently come from the primary author, it also includes data from other researchers and public sources, aiming to compile existing work and encourage future expansions.

% The dataset was developed to ensure:
% \begin{itemize}
%     \item Completeness: consolidating contributions and recognizing collective research efforts.
%     \item Accessibility: hosted on Zenodo\footnote{\url{https://zenodo.org/}} for long-term availability.
%     \item Consistency: verified, pre-processed, and reorganized external data for immediate usability.
% \end{itemize}
% and is divided into two main components:
% \begin{itemize}
%     \item Data: publicly available with separate records for each effect, detailed documentation (e.g., settings, preprocessing steps), and links to dry source audio.
%     \item Repository: organizes download links, provides retrieval scripts, basic training code, and contribution guidelines, facilitating new submissions and fostering discussions.
% \end{itemize}

% The ToneTwist AFx dataset is organized into four categories: analog, analog parametric, digital, and digital parametric, with \textit{parametric} referring to entries sampled with control settings granularity sufficient for parametric modeling.
% It uses dry input signals from seven sources, including a variety of guitars, basses, and test signals like chirps and white noise. 
% Preprocessing, recording, and data organization are well-documented. 
% The test set features different content and instruments from the training/validation set, ensuring a realistic evaluation on audio effects models generalization capabilities.

% Recording was carried out with a Focusrite Scarlett Solo audio interface, featuring a low-noise pre-amplifier (±0.06 dB, 20Hz-20kHz). 
% Synchronization between dry input and wet output was achieved by adding two impulses at the start and end of each file and then manually shifting each wet output file of the same number of samples to account for interface latency.
% Devices delays were assumed negligible.

% Aside from ours, three other publicly available datasets for audio effects research exist, though all have limitations for audio effects modeling:
% \begin{itemize}
%     \item IDMT-SMT-Audio-Effects\footnote{\url{https://www.idmt.fraunhofer.de/en/publications/datasets/audio\_effects.html}} \citep{stein2010automatic}: focused mainly on detection and classification tasks, it is limited to recordings of single notes and chords using two electric guitars and two electric basses. It only includes digital effects - without specifying the plugins used - with a single control setting per effect, covering 10 linear, non-linear, and modulation effects.
%     \item GUITAR-FX-DIST \citep{comunita2021guitar}: focused on classification and parameter estimation, this dataset includes recordings of single notes and chords from two guitars. It features digital emulations of overdrive, distortion, and fuzz effects, with multiple control settings per unit, covering 14 distortion effects in total. 
%     \item EGFxSet\footnote{\href{https://egfxset.github.io/}{https://egfxset.github.io/}} \citep{pedroza2022egfxset}: a diverse dataset with recordings from 12 physical units, equally split between analog and digital, featuring single notes from a single electric guitar. Despite being intended for audio effects modeling, it is unsuitable due to high background noise and other artifacts.
% \end{itemize}

% At the time of writing, the ToneTwist AFx dataset primarily focuses on nonlinear effects, with plans to expand as external data and community contributions are added.

\input{TABLES/dataset}

% ======================================
% \subsection{Evaluation}
% \label{sec:eval}

% ======================================
% \subsubsection{Objective Evaluation}
% \label{sec:obj_eval}
% Loss, FAD and other metrics
% - correlation between loss and metrics\\
% - FAD with ST-ITO encoder\\
% - average loss across architectures to draw a general conclusion

% ======================================
% \subsubsection{Subjective Evaluation}
% \label{sec:subj_eval}
% Describe listening test design:\\
% - Mushra test\\
% - 8 samples (lstm, tcn, tcn-tf, gcn, gcn-tf, s4, s4-tf, gb) + reference for each page\\
% - 16 effects\\
% - k samples per effects\\
% - each listener 10 pages out of the 16 * k possible

% Results:\\
% - box plots\\
% - scatter plot loss vs ratings or FAD vs ratings

% ======================================================================================
% \clearpage
\section{Experiments}
\label{sec:experiments}
In this section we give an overview and description of all the architectures, models configurations, and data used for our experiments.
% Since among the goals of this work is to help establish a state-of-the-art for audio effects modeling while identifying future directions of investigation, we made an effort to include a wide range of experiments and experiments configurations to achieve a clear picture of the research landscape.
To help establish the state of the art in audio effects modeling and identify future research directions, we included a wide range of experiments and configurations.

\input{TABLES/models}
\input{TABLES/models-param}

% ======================================
\subsection{Overview of Models Configurations}
\label{sec:models_config}
% Table \ref{tab:models} shows a complete list of of all the models, hyperparameters values and computational complexity\footnote{\url{https://github.com/MrYxJ/calculate-flops.pytorch}} included in our experiments.
% To reduce the problem to a tractable one, we limit number of models for each architecture while still considering a broad range of sizes and computational complexity.
Table \ref{tab:models} lists all models, hyperparameter values, and computational complexity\footnote{\url{https://github.com/MrYxJ/calculate-flops.pytorch}} used in our experiments on non-parametric modeling, where we balance tractability by limiting the number of models per architecture while covering a broad range of sizes and complexities.

% Table \ref{tab:models} shows all the black- and gray-box models included in our experiments on non-parametric modeling. 
As described in Sec.\ref{sec:bb-models}, we include the four most common neural networks types for black-box modeling: LSTM, TCN, GCN and S4; as well as the gray-box models proposed in Sec.\ref{sec:gb-models}: GB-COMP for compressor/limiter, GB-DIST for amplifier/overdrive/distortion and GB-FUZZ for fuzz.
% For LSTM architectures, the only parameter to choose is the number of channels. 
% As adopted in previous works \cite{wright2020real, steinmetz2022efficient, comunita2023modelling}, sensible choices for \textit{small} and \textit{large} models are 32 and 96 channels respectively (LSTM-32/LSTM-96).
For LSTM architectures, the only parameter to choose is the number of channels, with 32 and 96 channels being sensible choices for \textit{small} and \textit{large} models (LSTM-32/LSTM-96), as adopted in previous works \cite{wright2020real, steinmetz2022efficient, comunita2023modelling}.\\
% For TCN and GCN architectures we define models having a combination of \textit{short}, \textit{medium} and \textit{long} receptive fields - i.e., 45, 250 and 2500~ms at 48~kHz as indicated in the models' names - and a \textit{small} or \textit{large} (S/L in the models' names) number of blocks - i.e., 5/6 or 10/11. 
For TCN and GCN models, we consider variants with \textit{short}, \textit{medium}, and \textit{long} receptive fields (45, 250 and 2500~ms at 48kHz), with \textit{small} (5/6 blocks) or \textit{large} (10/11 blocks) configurations (S/L in model names).
We keep the number of channels constant and equal to 16.
We also include variants without and with TFiLM (TF in the models' names) to evaluate whether time-varying conditioning - shown to be able to capture long-range dependencies \citep{comunita2023modelling} typical of compressors and fuzz effects - is beneficial across architectures. 
For TFiLM layers we always adopt a block size - i.e., downsampling/maxpooling factor - of 128, which was shown to be optimal in \citep{comunita2023modelling}.
% , and one could expect a similar shift in performance when choosing smaller of larger block sizes. 
% The number of channels for TCN and GCN architectures is kept constant and equal to 16.
% As can be noticed in the table, for each receptive field length, we keep comparable number of parameters - and hence FLOP/s and MAC/s - between \textit{small} and \textit{large} number of layers, with the idea that the fundamental difference between the two is how many nonlinear activations the model can rely on to achieve a good approximation of the effect being modeled.
As shown in the table, for each receptive field, \textit{small} and \textit{large} models have comparable parameters, FLOP/s, and MAC/s, with the idea that the main difference is in the number of processing stages and not in the networks expressivity itself.
% Obviously, when including TFiLM, which adds a conditioning layer to each block of the main network, it is not possible to keep similar number of parameters for different number of block, although given the relatively small number of channels (16) and the low sample rate at which TFiLM layers work, the pairs of models remain comparable in terms of computational complexity.
With TFiLM adding a conditioning layer per block, matching parameter counts across block variations isn't feasible, but due to the small channel count (16) and low TFiLM sample rate, model pairs remain computationally comparable.\\
For S4 architectures we define \textit{small} and \textit{large} models (S/L in the name) based on the number of blocks and state dimension, with values chosen based on the experiments reported in the original publication \citep{gu2021efficiently}.
For S4 models as well we introduce TFiLM conditioned variants and keep the number of channels constant and equal to 16.\\
While for the GB-COMP architecture we only investigate one configuration, for GB-DIST and GB-FUZZ models we test two, based on the type of nonlinearity adopted: Static MLP Nonlinearity or Static Rational Nonlinearity (MLP/RNL in the name).
The MLP itself accounts for most of the computational complexity of GB-DIST and GB-FUZZ models.\\

For experiments on parametric modeling (Table~\ref{tab:models-param}) we take a subset of the configurations in Table~\ref{tab:models} and we pair them with the various conditioning mechanisms described in \citep{comunità2025nablafxframeworkdifferentiableblackbox}.
% Specifically, for LSTM architectures we consider concatenation (C in the name) as the baseline method; we then also experiment with time-varying concatenation (TVC in the name), which contributes to a limited amount to the computational complexity.
For LSTM models, we use concatenation (C) as the baseline and also test time-varying concatenation (TVC), which adds minimal computational cost.
% Of the two types of convolutional backbones we only select the TCN architecture and, of the different models we only select those with \textit{short} receptive field (45ms); this because networks with short receptive fields will need to rely more heavily on the expressivity of the different conditioning methods and their ability to capture long-range dependencies, hence better highlighting performance differences.
For convolutional backbones, we select only TCNs and models with a \textit{short} (45ms) receptive field, as these rely more on conditioning methods to capture long-range dependencies, highlighting performance differences.
We consider FiLM conditioning (F in the name) to be the baseline method and experiment with TFiLM, TTFiLM (TTF in the name) and TVFiLM (TVF in the name). 
We do the same for S4 architectures.
% It is clear from Table \ref{tab:models-param} how both TTFiLM and TVFiLM achieve the goal of introducing time-dependent conditioning like TFiLM with a number of parameters and computational efficiency comparable to the baseline FiLM method. 
% In fact, both proposed methods have small impact in terms of number of parameters, FLOP/s and MAC/s.
Table~\ref{tab:models-param} shows that both TTFiLM and TVFiLM introduce time-dependent conditioning with parameter and computational efficiency similar to the baseline FiLM method, having minimal impact on parameters, FLOP/s, and MAC/s.
For gray-box models, we add parametric control using differentiable controllers from \citep{comunità2025nablafxframeworkdifferentiableblackbox} and replace static/dynamic controllers with conditional ones (C in the model name).
Although they increase the number of parameters, the impact of conditional controllers on the computational complexity is minimal due to the small size of the MLPs and LSTMs in their implementation.

% Beside achieving a good understanding of the state-of-the-art, goal of our experiments is also to identify an architecture capable of modeling a broad range of effect types and devices consistently, without the need to choose different architectures or different configurations depending on the device being modeled, the broader goal being to define a universal audio effects modeling architecture.
Beside a good understanding of the state-of-the-art, our experiments aim to identify architectures that can model a wide range of effects and devices consistently, without requiring different configurations, with the broader goal of defining a universal audio effects modeling architecture.
% We also recognize that, if time and resources allowed, one could use model pruning [cite] or hyperparameters optimization to identify the smallest possible size for each effect, but that would require many hours or days for each audio effect.
% Alternatively, once identified an architecture/configuration capable of covering a broad range of devices, one could rely on model distillation [cite] to reduce the model size and increase efficiency. 
% But again, this would require extra experimentation and specific training sessions for each effect.
While we recognize that model pruning \citep{sudholt2022pruning} or hyperparameter optimization could identify the smallest model size for each effect, this would require extensive time and resources. 
Alternatively, model distillation \citep{hinton2015distillingknowledgeneuralnetwork} could reduce size and increase efficiency after identifying a suitable architecture, but this also requires additional experimentation and training.

% ======================================
\subsection{Overview of Audio Effects Configurations}
% Table \ref{tab:effects_configs} shows all the audio effects and effects settings included in our study. 
% For experiments on non-parametric modeling we select four devices for each audio effect category: compressor/limiter, overdrive, distortion and fuzz, for a total of sixteen devices, twelve of which use data that was recorded by ourselves for the ToneTwist AFX dataset (see Sec. \ref{sec:tonetwist}).
Table~\ref{tab:effects_configs} lists all the audio effects and settings in our study. For non-parametric modeling, we select four devices per effect category (compressor/limiter, overdrive, distortion, fuzz), totaling sixteen devices, twelve of which are from our ToneTwist AFX dataset (see Sec.~\ref{sec:tonetwist}).

% The choice of settings for each device is such that for each category the devices will present a variety of behaviors while also making sure for the modeling task to be as challenging as possible.
Settings for each device are chosen to ensure a variety of behaviors within each category, while maximizing the challenge for the modeling task.
% When modeling dynamic range compression, we select configurations with fast attach, slow release and high compression ratio, so that the model will need to capture both the very fast transients during the attack, the long-range dependencies during the release, and the nonlinear behavior due to the compression.
% For overdrive, we always select \textit{high} gain settings to have as complex of a spectrum as possible, with various tone/equalization values.
For compression, we select fast attack, slow release, and high compression ratio settings to capture fast transients, long-range dependencies, and nonlinear behaviors. 
For overdrive, we choose high gain settings with varying tone/equalization for a complex spectrum.
% For distortion, we choose both \textit{medium} and \textit{high} gain settings, while for fuzz effects, which are designed for high gain and distortion, we select \textit{medium} gain settings so that the dynamic behavior typical of such devices is perceivable and not hidden underneath extremely high distortion levels.
For distortion, we select both \textit{medium} and \textit{high} gain settings, while for fuzz effects, which are inherently \textit{high} gain, we opt for \textit{medium} gain settings to ensure the dynamic behavior is noticeable and not concealed by excessive distortion.
% It is also important to underline how the settings' values across effect type and device are only relatively correlated with the edge behaviors we are trying to capture during the modeling task - since they do not reflect specific unit of measure or internal parameters values - therefore, can only be considered as a rough description of the effect behavior and timbral characteristics.
It is important to note that the settings values across effect types and devices are only vaguely correlated with the behaviors we are modeling, as they don't correspond to specific units or internal parameters, serving only as a general description of the effect's behavior and timbral traits.

% In the same table we also include effects and settings for experiments on parametric modeling: a vacuum tubes guitar amplifier and a digital emulation of a germanium transistors fuzz effect.
The table also includes effects and settings for parametric modeling experiments: a vacuum tube guitar amplifier and a digital germanium transistor fuzz emulation.
% Beside experimenting with parametric modeling and study different conditioning methods, data from the two devices can also help evaluate performance when testing on unseen controls configurations and unseen sources. 
% In fact, for the Marshall JVM410H guitar amp, train, validation and test content is from the same sources - i.e., specific guitar and bass devices - but different control settings; while, for the Multidrive Pedal Pro F-Fuzz fuzz pedal, control settings between train, validation and test are the same while the sources and content are different - i.e., unseen guitar and bass playing unseen content.
In addition to parametric modeling and conditioning methods, data from these two devices help evaluate performance on unseen control configurations and sources. 
For the Marshall JVM410H, training, validation, and testing use the same sources but different control settings. 
For the Multidrive Pedal Pro F-Fuzz, control settings are the same across sets, but sources and content differ, featuring unseen guitar and bass performances.

\input{TABLES/effects_configurations}

% ======================================
\subsection{Training}
\label{sec:training}

\input{TABLES/training}

% In all previous literature on audio effects modeling there has always been the assumption that training different architectures and models configurations under one training scheme - in terms of loss function, learning rate, learning rate scheduler, loss weights etc. - is a fair approach to compare the performance and reach reliable conclusions about the state of the art. 
All previous audio effects modeling studies have always assumed that training different architectures and model configurations under the same training scheme - i.e., loss functions and loss weights, learning rate and rate scheduler etc. - allows fair performance comparisons and reliable state-of-the-art conclusions.
This has been the case also for works that compared vastly different architectures like black-box and gray-box ones 
\citep{yeh2024ddsp, miklanek2023neural, wright2022grey}.
% Although, in our preliminary experiments we were able to assess that one can reach vastly different loss values when training the same architecture under different training schemes, making it not possible to really compare different architectures and model configurations without choosing the appropriate training-related hyperparameters for each architecture. 
Although, in preliminary experiments we were able to assess that training an architecture under different schemes can yield vastly different loss values, and even more so when different architectures are involved.
This highlights the need to choose appropriate training-related hyperparameters for each model to enable meaningful comparisons between architectures and configurations.

% In this section we describe and discuss our preliminary experiments targeted at identifying appropriate hyperparameters and training configurations for each type of architecture involved in our experiments: LSTM, TCN, GNC, S4, GB.
This section discusses preliminary experiments to identify optimal hyperparameters and training configurations for LSTM, TCN, GNC, S4, and GB architectures, and the resulting training schemes are shown in Table~\ref{tab:training}.
% As a starting point, based on previous literature on effects modeling [cite some papers] and more generally on sound synthesis [cite] and audio processing [cite] tasks, we assumed a combination of $L1$ and multiresolution spectrogram (MR-STFT) to be the most reliable and perceptually relevant loss function to choose.
Based on prior work on effects modeling \cite{steinmetz2022efficient, comunita2023modelling}, sound synthesis \cite{engel2019ddsp}, and audio processing \citep{yamamoto2020parallel}, we assumed an $L1$ + MR-STFT loss as the most reliable and perceptually relevant choice, and opted for specific combinations of loss weights, which we report in Table~\ref{tab:training}.
Having a 10:1 ratio between $L1$ and MR-STFT loss makes the two terms about equal in absolute numeric values, giving them the same importance.
Conversely, having a 1:1 ratio equals to give the spectrogram loss greater importance.
To compare experiments with different loss weights, we report results by scaling the loss terms accordingly.
This means that, while backpropagation is influenced by the weight values, the results in Section~\ref{sec:results} are independent of the specific choice, allowing for comparison across experiments.

% The learning rate (LR) for each architecture was selected by training on one audio effect (Custom Dynamic Fuzz) and comparing results for $\text{LR}=[0.1,0.01,0.005,0.001,0.0005]$.
We chose the learning rate (LR) for each architecture by training on one audio effect (Custom Dynamic Fuzz) and comparing results for $\text{LR}=[0.1,0.01,0.005,0.001,0.0005]$.
For gray-box models we also tested $LR=1$, since higher learning rates seemed to work better. 
% During such experiments we also concluded that it was essential to implement a learning rate multiplier for each block in a gray-box signal chain since more complex blocks (e.g., Static MLP Nonlinearity and Static FIR Filter) required a lower LR than simpler ones (e.g., Parametric EQ, Static Rational Nonlinearity).
We also found it essential to use a learning rate multiplier for each block in the gray-box signal chain, as more complex blocks (e.g., Static MLP Nonlinearity, Static FIR Filter) needed a lower LR than simpler ones (e.g., Parametric EQ, Static Rational Nonlinearity).
% This allowed us to significantly improve gray-box losses and reach a much better local optimum in terms of perceptual similarity with the target.
This significantly improved gray-box losses and led to better local optima in terms of perceptual similarity with the target.
% We also conducted preliminary experiments to select the best activation function and, after testing $tanh$, parametric ReLU and Rational activations, we could not identify a clear winner, and therefore proceeded by selecting the $tanh$, being the least computationally expensive one.
Furthermore, we conducted experiments to choose activation functions and, after testing $tanh$, parametric ReLU and rational activations \citep{delfosse2020rationals}, no clear winner emerged, and proceeded selecting $tanh$, being the least computationally expensive one.
% One of the main challenges highlighted during this experimental phase was the instability in training LSTM models - regardless of LR, LR scheduler, gradient clipping algorithm and clipping value, loss weights, training samples length and the use of truncated backpropagation through time (TBPTT) or not - with many cases of \textit{NaN} loss failures. 

A major challenge during this phase was the instability in training LSTM models, resulting in frequent \textit{NaN} loss failures despite adjustments to: LR, gradient clipping, loss weights, training samples length, and the use of truncated backpropagation through time (TBPTT) \citep{comunità2025nablafxframeworkdifferentiableblackbox}.
A suboptimal solution was to select the training scheme reported in Table~\ref{tab:training}. 
% While this does not guarantee to have no \textit{NaN} loss failures, it allows in most cases to reach a suitable local optimum by simply training each model on a wider range of hyperparameters.
% For TBPTT we update the gradients every 4800 samples (100~ms at 48~kHz) and set the maximum number of training steps to equal the number of training epochs for models trained without TBPTT.
While this does not prevent \textit{NaN} loss failures, it helps to reach a suitable local optimum by training each model with a broader range of hyperparameters. 
For TBPTT, gradients are updated every 4800 samples (100 ms at 48 kHz), and the max training steps match the epochs used for models without TBPTT.
All other architectures revealed to be much more stable - with no \textit{NaN} loss cases - while still benefiting from training on a variety of LRs to achieve optimal results.
For all architectures we opt to reduce LR by half when there are no improvements in total validation loss for 20 epochs.
To prevent overfitting, we also use early stopping of 50 epochs.

Examples that highlight differences in performance as a function of LR are shown in Figure~\ref{fig:example_loss_variance}, with training sessions that might not reach a good local optimum (\ref{fig:example_loss_variance}a) or exhibit scaled-loss differences of up to 30\%-40\% (\ref{fig:example_loss_variance}b and \ref{fig:example_loss_variance}c).

\begin{figure*}[t]
    \begin{minipage}[b]{.32\textwidth}
        \centering
        \includegraphics[width=.9\textwidth]{FIGURES/ExampleLoss_HB-Plexicon_LSTM-32_loss-norm-val-tot.png}
        \\\textbf{(a)} LSTM trained on\\Harley Benton Plexicon
        \label{fig:ex_loss_lstm}
    \end{minipage}
    \begin{minipage}[b]{.32\textwidth}
        \centering
        \includegraphics[width=.9\textwidth]{FIGURES/ExampleLoss_HB-Rodent_bb_S4_loss-norm-val-tot.png}
        \\\textbf{(b)} S4 trained on\\Harley Benton Rodent
        \label{fig:ex_loss_s4}
    \end{minipage}
    \begin{minipage}[b]{.32\textwidth}
        \centering
        \includegraphics[width=.9\textwidth]{FIGURES/ExampleLoss_HB-FuzzyLogic_gb_GB-FUZZ-RNL_loss_norm-val-tot.png}
        \\\textbf{(c)} GB-FUZZ trained on\\Harley Benton Fuzzy Logic
        \label{fig:ex_loss_gb}
    \end{minipage}
    \caption{Validation scaled-loss for different learning rates reveals training discrepancies and unreliability of previous literature comparing architectures and model configurations using a single training scheme.}
    \label{fig:example_loss_variance}
\end{figure*}

% ======================================================================================
% \clearpage
\section{Results}
\label{sec:results}

% ======================================
\subsection{Results for Non-parametric Models}
\label{sec:results_overall}
% In Figure \ref{fig:bp_loss} we plot the total loss for the different architectures trained on the sixteen effects included in our study (see Sec.~\ref{tab:effects_configs}), showing box plots for the overall results (\ref{fig:bp_loss_overall}) and for each effect category separately (\ref{fig:bp_loss_comp}-\ref{fig:bp_loss_fuzz}).
% Overall, S4 models with TFiLM conditioning perform the best.
Figure~\ref{fig:bp_loss} shows the total loss for architectures trained on sixteen effects (see Sec.~\ref{tab:effects_configs}), with box plots for overall results (\ref{fig:bp_loss}a) and each effect category (\ref{fig:bp_loss}b-e).

Overall, S4 models with TFiLM conditioning perform the best.
Also, TFiLM improves median performance across architectures and reduces the variance, demonstrating how time-varying conditioning enhances expressivity, regardless of the backbone.
% We can also notice how, while GCN achieves lower loss compared to TCN, when using TFiLM conditioning the two convolutional backbones achieve very similar results, making the added computational complexity of GCN-TF models difficult to justify, and highlighting how it might be better to focus on designing an efficient and effective time-varying conditioning method.
Although GCN achieves lower loss than TCN, TFiLM conditioning results in similar performance for both, making the added complexity of GCN-TF hard to justify and emphasizing how efficient and effective time-varying conditioning could be focus of further research.
% Results also show that gray-box models do not yet achieve a median performance comparable with black-box models, although they can perform better than black-box models in some cases and also show smaller variance than LSTMs.
Gray-box models show higher median loss than black-box ones but can outperform them in some cases, and also exhibit smaller variance than LSTMs.
% LSTMs are shown to be the least reliable models demonstrating the greatest variance across architectures and therefore, making it not suited to model a wide range of effect types and devices.
Having the greatest variance across architectures, LSTMs are shown to be the least reliable, which makes them unsuitable for modeling a wide range of effect types and devices.

% Breaking down performance by effect type we notice how S4 models perform best in each category, with TFiLM conditioning not always significantly improving the loss when compared to standard S4 models, but never hindering performance either.
Breaking down performance by effect type, S4 models perform best in each category, with TFiLM conditioning generally improving or maintaining performance without hindering it.
It therefore seems that S4 models with a form of time-dependent conditioning are the best candidate to develop high performing architectures across a wide range of effect types and implementations.
% In convolutional architectures, TFiLM is shown to be helpful for every effect category although to a varying extent, and especially beneficial for distortion and fuzz effects, which are complex effects to model combining both high levels of distortion and in some cases complex time-dependent behaviors. 

In convolutional architectures, TFiLM is shown to be helpful for every effect category although to a varying extent, particularly benefiting distortion and fuzz effects with their complex timbre and time-dependent behaviors.
% This is also demonstrated by looking at the average loss and standard deviation included at the end of in Table \ref{tab:results_overall}, with distortion and fuzz the most challenging effects to model among the types included in our study.
This is reflected in the average loss and standard deviation in Table~\ref{tab:results_overall}, where distortion and fuzz are the most challenging effects to model.
Beside compressors, LSTM is confirmed to be the least reliable architecture in each category, with far greater variance than any other architecture and performing on par or worse than gray-box models.

Looking in further details at the results in Table~\ref{tab:results_overall} where we gather mean ($\mu$) and standard deviation ($\sigma$) of the total loss for each device type and overall, we notice how S4 with TFiLM conditioning (S4-TF-L-16) performed the best, with TFiLM giving only a marginal improvement w.r.t. base S4 models of the same \textit{size}.
% Standard S4 and GCN-TF are the second and third best respectively in terms of average. While TCN-TF are the best when it comes to standard deviation across effect types.
Standard S4 and GCN-TF rank second and third in average loss, while TCN-TF has the lowest standard deviation across effect types.
% Again, TFiLM conditioning is always beneficial in terms of loss, especially for convolutional backbones, where beside improving performance at each receptive field and model size, allows for smaller models (with fewer layers) to equal models with a greater number of layers, reducing the importance of both, long receptive field and number of nonlinear activations, to capture complex timbres and long-range dependencies.
TFiLM conditioning consistently improves loss, especially for convolutional backbones, enhancing performance at each receptive field and model size, while enabling smaller models to match the performance of larger ones, reducing the reliance on receptive field length and nonlinear activations to capture complex timbres and long-range dependencies.
Overall, TCN-TF models perform well in terms of mean loss and are among the best in terms of standard deviation, which makes them a good choice to model diverse effects.
Once more, looking at each model size and receptive field length, the performance improvement of GCN and GCN-TF w.r.t. TCN and TCN-TF models does not seem to justify the increase in parameters and computational cost.
Also worth noticing is that rational nonlinearities are useful for gray-box models, allowing to match performance while greatly reducing the computational complexity of MLP-based models, regardless of the effect and across architectures (i.e., GB-DIST and GB-FUZZ).

\begin{figure*}[t]
    \begin{minipage}[b]{1\textwidth}
        \centering
        \includegraphics[height=5cm]{FIGURES/Boxplot_TotLoss-vs-Arch_Overall.pdf}
        \\\textbf{(a)} Overall
        \label{fig:bp_loss_overall}
    \end{minipage}\\\\
    \begin{minipage}[b]{.245\textwidth}
        \centering
        \includegraphics[height=4.0cm]{FIGURES/Boxplot_TotLoss-vs-Arch_Comp.pdf}
        \\\textbf{(b)} Compressor/Limiter
        \label{fig:bp_loss_comp}
    \end{minipage}
    \begin{minipage}[b]{.245\textwidth}
        \centering
        \includegraphics[height=4.0cm]{FIGURES/Boxplot_TotLoss-vs-Arch_Od.pdf}
        \\\textbf{(c)} Overdrive
        \label{fig:bp_loss_od}
    \end{minipage}
    \begin{minipage}[b]{.245\textwidth}
        \centering
        \includegraphics[height=4.0cm]{FIGURES/Boxplot_TotLoss-vs-Arch_Dist.pdf}
        \\\textbf{(d)} Distortion
        \label{fig:bp_loss_dist}
    \end{minipage}
    \begin{minipage}[b]{.245\textwidth}
        \centering
        \includegraphics[height=4.0cm]{FIGURES/Boxplot_TotLoss-vs-Arch_Fuzz.pdf}
        \\\textbf{(e)} Fuzz
        \label{fig:bp_loss_fuzz}
    \end{minipage}
    \caption{Total loss for different architectures: overall and for each effect type}
    \label{fig:bp_loss}
\end{figure*}

\input{TABLES/results_overall}

\input{TABLES/results_param_overall}

% ======================================
\subsection{Results for Parametric Models}
\label{sec:results_parametric_models}

Table~\ref{tab:results_overall_param} shows the losses for parametric models trained on Marshall JVM410H guitar amplifier and Multidrive Pedal Pro F-Fuzz digital emulation of Fuzz Face guitar pedal.
% We report both validation and test loss to understand the models performance change when tested on unseen controls configurations - as in the guitar amp case - or when tested on unseen sources and content - as in the fuzz guitar pedal case.
We report both validation and test loss to assess model performance when tested on unseen controls configurations (i.e., guitar amp) or unseen sources and content (i.e., fuzz pedal).
S4 models are the best performing on the guitar amp, with LSTM models and TCN with time-varying conditioning performing only marginally worse.
For the fuzz effect pedal emulation, LSTMs are the best performing, with S4 models with time-varying conditioning (S4-TF-L-16 and S4-TVF-L-16) being only slightly worse.

While TVCond (TVC) conditioning is not useful to improve LSTM performance on the Marshall amp, it is beneficial to achieve among best performance with a smaller LSTM model.
For TCN models, TFiLM (TF) conditioning is the most effective for both guitar amp and fuzz pedal cases, regardless of the number of layers in the model.
We also notice how the baseline FiLM (F) conditioning is the worst mechanism for all but one case when applied to either TCN or S4 models.
Looking at S4 models, the proposed TTFiLM (TTF) and TVFiLM (TVF) conditioning allow performance on par or better than TFiLM (TF) regardless of model size.
Also, TVF allows small models to achieve performance comparable to bigger ones.
For TCN models, it is less clear whether there is an advantage in using TTF or TVF w.r.t. TF beside computational complexity.

% Generally speaking, it is not clear which conditioning mechanism is best; 
To recap, TFiLM seems to be the best across architectures, with TVFiLM better than TTFiLM when reducing the computational complexity.
A study on a wider variety of effects would allow to better asses whether TVF and TTF can compete with TF conditioning.

\begin{figure*}[ht!]
    \begin{center}
    \begin{minipage}[b]{.32\textwidth}
        \centering
        \includegraphics[height=4.5cm]{FIGURES/Boxplot_MSE-vs-Arch_Overall.pdf}
        \\\textbf{(a)} MSE
        \label{fig:ex_loss_lstm}
    \end{minipage}
    \begin{minipage}[b]{.32\textwidth}
        \centering
        \includegraphics[height=4.5cm]{FIGURES/Boxplot_ESR-vs-Arch_Overall.pdf}
        \\\textbf{(b)} ESR
        \label{fig:ex_loss_s4}
    \end{minipage}
    \begin{minipage}[b]{.32\textwidth}
        \centering
        \includegraphics[height=4.5cm]{FIGURES/Boxplot_MAPE-vs-Arch_Overall.pdf}
        \\\textbf{(c)} MAPE
        \label{fig:ex_loss_s4}
    \end{minipage}
    \caption{Metrics for different architectures for all effect types}
    \label{fig:metrics_boxplots}
    \end{center}
\end{figure*}

\begin{figure*}[ht!]
    \centering
    \begin{minipage}[b]{.45\textwidth}
        \centering
        \includegraphics[height=4.8cm]{FIGURES/Boxplot_FADvggish-vs-Arch_Overall.pdf}
        \\\textbf{(a)} VGGish
        \label{fig:ex_loss_lstm}
    \end{minipage}
    \begin{minipage}[b]{.45\textwidth}
        \centering
        \includegraphics[height=4.8cm]{FIGURES/Boxplot_FADpann-vs-Arch_Overall.pdf}
        \\\textbf{(b)} PANN
        \label{fig:ex_loss_s4}
    \end{minipage}
    
    \begin{minipage}[b]{.45\textwidth}
        \centering
        \includegraphics[height=4.8cm]{FIGURES/Boxplot_FADclap-vs-Arch_Overall.pdf}
        \\\textbf{(c)} CLAP
        \label{fig:ex_loss_s4}
    \end{minipage}
    \begin{minipage}[b]{.45\textwidth}
        \centering
        \includegraphics[height=4.8cm]{FIGURES/Boxplot_FADafxrep-vs-Arch_Overall.pdf}
        \\\textbf{(d)} AFx-Rep
        \label{fig:ex_loss_s4}
    \end{minipage}
    \caption{FAD for different architectures for all effect types}
    \label{fig:metrics_boxplots_fad}
\end{figure*}

% ======================================================================================
% \clearpage
\section{Evaluation}
\label{sec:eval}

% ======================================
\subsection{Objective Evaluation}
\label{sec:obj_eval}
% \input{TABLES/metrics_comp_od}
% \input{TABLES/metrics_dist_fuzz}
% \input{TABLES/metrics_overall}

To extend the objective evaluation beyond loss values we use most of the metrics available from the NablAFx framework \citep{comunità2025nablafxframeworkdifferentiableblackbox}, these include both signal-based metrics (i.e., MSE, ESR, MAPE) as well as latent representation-based ones (i.e., FAD). 
FAD is computed using three widely adopted representations (i.e., VGGish, PANN and CLAP) as well as a recently proposed audio production style representation (AFx-Rep) \cite{steinmetz2024st}.
We compute these metrics for several reasons beside broadening the analysis: to investigate which ones might be most suited for modeling tasks, to investigate correlation between objective metrics and subjective ratings (see Sec.~\ref{sec:subj_eval}), to encourage further research on audio effects related representations and evaluation methods.

When using objective metrics - which we plot in Fig.~\ref{fig:metrics_boxplots} and \ref{fig:metrics_boxplots_fad} on a log scale to highlight differences - the picture is similar to the results discussed in previous sections.
S4 and S4-TF architectures show the best performance across effect type, regardless of the metric used.
Once again, temporal conditioning (TFiLM), is helpful in improving performance - noticeable from the reduction in median as well as standard deviation values - regardless of the architecture's backbone (TCN, GCN or S4).
LSTM architectures are shown again to have a high performance variance, making them not reliable when modeling a wide range of devices.
While gray-box models again achieve results that are not on par with black-box ones, therefore requiring further exploration.

\subsection{Efficiency}
\label{sec:efficiency}

\begin{figure*}[t]
    \begin{minipage}[b]{.33\textwidth}
        \centering
        \includegraphics[width=\textwidth]{FIGURES/Plot_RTF-vs-FrameSize_1.pdf}
        \\\textbf{(a)}
    \end{minipage}
    \begin{minipage}[b]{.33\textwidth}
        \centering
        \includegraphics[width=\textwidth]{FIGURES/Plot_RTF-vs-FrameSize_2.pdf}
        \\\textbf{(b)}
    \end{minipage}
    \begin{minipage}[b]{.33\textwidth}
        \centering
        \includegraphics[width=\textwidth]{FIGURES/Plot_RTF-vs-FrameSize_3.pdf}
        \\\textbf{(c)}
    \end{minipage}
    \caption{Real-time factor vs. Frame size for some of the models included in the experiments}
    \label{fig:rtf_vs_frame}
\end{figure*}

We investigated the run-time of the proposed models and conditioning methods in a frame-based implementation to mimic a standard digital audio effect implementation. 
The real-time factor (RTF) is defined as:
\begin{equation}
    \text{RTF}:=\frac{F}{T \cdot f_{s}}
\end{equation}
where $F$ is the frame size in samples and $T$ is the time in seconds to process them at sampling rate $f_{s}$. 
We measure the RTF at power of 2 frame sizes, $F \in 32, 64, ..., 16384$, on a 2019 MacBook Pro with an Intel Core i5 @ 1.4 GHz.

Results for non-parametric models are shown in Fig.~\ref{fig:rtf_vs_frame}a and \ref{fig:rtf_vs_frame}b and for parametric ones in Fig.~\ref{fig:rtf_vs_frame}c.
We show only a limited number of configurations for clarity.
In a block-based formulation, TCN models require a buffer of past samples such that we pass an input of $F + r - 1$ samples, where $F$ is the number of output samples and $r$ is the receptive field in samples.

LSTMs achieve real-time operation at every frame size, but the RTF remains constant over a certain size due to the inability to parallelize computations along the temporal dimension.
The RTF for TCN, GCN (not shown) and GB models, is instead proportional to the frame size.
For convolutional backbones, whether the models achieve real-time operation at a sufficiently small frame size is strongly related to the receptive field and the number of blocks.
Interestingly, S4 models show a behavior in between recurrent and convolutional networks, where the RTF is proportional to frame size for small sizes and flattens out for large sizes.
Although best performing, S4 models require appropriate choice of number of blocks and state dimension to allow real-time operation, in fact, our larger model does not achieve $\text{RTF}> 1$.
In our implementation, all proposed gray-box models (of which we only show GB-FUZZ-MLP) show very similar RTF, proportional to frame size.

Fig.~\ref{fig:rtf_vs_frame}b compares TCN models with and without TFiLM conditioning, with temporal feature-wise modulation consistently reducing the RTF at every model and frame size.
Also, in Fig.~\ref{fig:rtf_vs_frame}c we compare different conditioning methods (FiLM, TFiLM, TTFiLM, TVFiLM) for parametric TCN models, and include a non-parametric model (TCN-45-S-16) for reference.
We notice how, even if computationally as efficient as models with FiLM and TVFiLM, TTFiLM conditioning is the worst in terms of RTF, while TVFiLM achieves real-time performance between FiLM and TFiLM, introducing time-varying conditioning at a low computational cost. 

Our results represent a worse-case scenario, since optimized C++ implementations may achieve a speedup compared to the PyTorch models used in our analysis \citep{wright2019real}.

% ======================================
\subsection{Subjective Evaluation}
\label{sec:subj_eval}

\begin{figure*}[t]
    \begin{minipage}{1\textwidth}
        \centering
        \includegraphics[height=5cm]{FIGURES/Boxplot_ListTestRatings-vs-Arch_Overall_FiltBefore_Best+Listening+Experience+Familiar_350rat.pdf}
        \\\textbf{(a)} Overall
        % \label{fig:bp_loss_overall}
    \end{minipage}\\\\
    
    \begin{minipage}{.255\textwidth}
        \centering
        \includegraphics[height=4.1cm]{FIGURES/Boxplot_ListTestRatings-vs-Arch_Comp_FilteBefore_Best+Listening+Experience+Familiar_100rat.pdf}
        \\\textbf{(b)} Compressor/Limiter
        % \label{fig:bp_loss_comp}
    \end{minipage}
    \begin{minipage}{.23\textwidth}
        \centering
        \includegraphics[height=4.1cm, trim=31 0 0 0, clip]{FIGURES/Boxplot_ListTestRatings-vs-Arch_Od_FilterBefore_Best+Listening+Experience+Familiar_100rat.pdf}
        \\\textbf{(c)} Overdrive
        % \label{fig:bp_loss_od}
    \end{minipage}
    \begin{minipage}{.23\textwidth}
        \centering
        \includegraphics[height=4.1cm, trim=31 0 0 0, clip]{FIGURES/Boxplot_ListTestRatings-vs-Arch_Dist_FilterBefore_Best+Listening+Experience+Familiar_90rat.pdf}
        \\\textbf{(d)} Distortion
        % \label{fig:bp_loss_dist}
    \end{minipage}
    \begin{minipage}{.23\textwidth}
        \centering
        \includegraphics[height=4.1cm, trim=31 0 0 0, clip]{FIGURES/Boxplot_ListTestRatings-vs-Arch_Fuzz_FilterBefore_Best+Listening+Experience+Familiar_90rat.pdf}
        \\\textbf{(e)} Fuzz
        % \label{fig:bp_loss_fuzz}
    \end{minipage}
    \caption{Subjective ratings for different architectures: overall and for each effect type}
    \label{fig:list_test}
\end{figure*}

To evaluate the perceptual differences among architectures, we conducted a MUSHRA listening test. 
Each trial presented participants with processed audio from all architectures under evaluation (LSTM, TCN, TCN-TF, GCN, GCN-TF, S4, and S4-TF) alongside a reference signal (wet-output) and an anchor (dry-input). 
We selected 12 effects (3 per type) out of the 16 we trained on.
For each effect, we curated three distinct sound examples designed to highlight model performance. 
These included a bass riff with a high input level and clear attacks to emphasize timbral and temporal characteristics, a guitar sample at similarly high input levels with pronounced attacks to further assess these aspects, and a second guitar sample with a very low input level and steady picking. 
This last example was chosen to evaluate the models’ ability to faithfully capture devices across extreme input dynamics. 

For each architecture we selected the best-performing model in terms of total test loss.
% Additionally, for each architecture, we selected both the best- and worst-performing model configurations based on prior objective evaluations. 
% This approach was intended to maximize the perceptual differences across trials, as selecting only high-performing models often resulted in minimal or imperceptible differences. 
% By including worst-performing models, we aimed to broaden the rating scale and derive more meaningful perceptual insights.
The listening test consisted of a total of 68 possible questions, with each participant randomly assigned seven to maintain a manageable test duration. 
A total of 27 participants were recruited, and a rigorous screening process was implemented. 
Participants were assessed on prior experience with listening tests, musical training or production experience, and familiarity with the specific effects being evaluated (compressors, overdrive/distortion, and fuzz). 
Further filtering was applied to ensure test reliability, participants who did not rate the reference sample at 80 or higher in more than one out of their seven trials were excluded from the final analysis. After applying these screening criteria, we obtained 350 valid ratings in total, averaging 35 per architecture and approximately 8.75 ratings per effect type.
Our strict participant selection strategy was intentional, prioritizing fewer but highly skilled listeners. 
This approach significantly reduced rating variance, leading to a more reliable subjective evaluation of model performance.

We show the overall results in Fig.~\ref{fig:list_test} together with ratings broken down by effect category.
In general, subjective ratings confirm the results obtained during the training process, with S4 architectures performing best, followed by convolutional backbones, gray-box models and LSTMs.
TFiLM conditioning allows to increase median accuracy and lower variance, improving modeling reliability across effects types and devices.
With respect to objective metrics, gray-box models are on average rated higher than LSTMs, but with high variance, which might entail the potential to match black-box approaches while requiring careful architecture design for different effect types.
Once again, LSTMs are confirmed to be unreliable as modeling architectures on a wide range of devices.

If we break down ratings by effect type we notice that in the majority of cases TFiLM helps to improve performance, in particular for convolutional backbones trained on overdrive, distortion and fuzz.
Proposed gray-box models perform, on average, well on compression and fairly on overdrive, while less so on distortion and fuzz.
Also, GCNs are not consistently better than TCNs, which confirms that the added complexity of GCNs is in general not necessary for good performance.
S4 models remain the most consistent, with median ratings at or above 80 in all but one case.

\subsection{Correlation}
\label{sc:correlation}

We further extend our analysis calculating the Spearman correlation between objective metrics and subjective ratings (Table~\ref{tab:corr_metrics-fad-ratings}).
Out of the signal-based metrics, MR-STFT shows the highest correlation with human ratings, supporting the assumption that it is a suitable term to include in the loss function.
MAPE and L1 are the second and third most correlated metrics, again supporting the idea that including a time-domain loss term is meaningful for modeling tasks.
Considering effects type, MR-STFT is the most relevant for high-distortion effects, while MAPE and L1 are the most correlated with subjective ratings for overdrive and compression respectively, although in the latter case, absolute correlation values are very low or not significant ($p > 0.05$), showing no single metric to be well suited for training.
We conclude that using frequency-domain in conjunction with time-domain losses seems to be a sensible choice for a wide variety of cases, but that improvements are possible, especially for compression modeling.

Observing latent representation-based metrics instead, VGGish and AFx-Rep vectors are overall the most correlated with subjective ratings.
Looking at specific effect types, none of the representations seem to be suited for compression and overdrive models evaluation, while CLAP and VGGish are, respectively, highly correlated with distortion and fuzz effects.

% \subsection{Performance}

% We conclude our analysis by summing up the overall objective and subjective performance of each architecture in Fig.\ref{fig:ratings-vs-rtf}, where we show median subjective ratings vs. mean real-time factor across models configurations (computed for frame size of 512 samples). 
% We also represent computational complexity making the markers equal to:
% \begin{equation}
%     S = \beta \cdot \frac{P + F + M}{N}
% \end{equation}
% i.e., the size ($S$) is proportional ($\beta$) to the mean sum of number of parameters (P), FLOP/s (F) and MAC/s (M).
% This shows how S4 architectures seem be the most suited to model a wide range of effects categories and devices accurately, with low computational complexity, while allowing real-time performance, assuming an appropriate model configurations as shown in Sec.\ref{sec:efficiency}.

% Also, compressors models are all rated very high, which highlights several issues in our opinion: compressors are very difficult to evaluate in subjective tests since they require highly skilled and experienced listeners to detect differences, or they actually are not that difficult to emulate, making them not suitable to evaluate modeling architectures, although they have many times been considered as the reference effect to test modeling performance \citep{steinmetz2022efficient, simionato2024modeling, yin2024modeling, hawley2019profiling}, or if trained appropriately and with settings specific for each architecture each architecture can achieve high performance.
% It is also interesting to notice the discrepancies in subjective ratings obtained in previous literature when training the same models on the same data \citep{steinmetz2022efficient, simionato2024modeling, yin2024modeling}. There seem to be open questions on whether differences are related to the training schemes or the listening test procedures.

\input{TABLES/correlation_subj-eval-vs-metrics-and-fad}

% ======================================================================================
% \clearpage
% \section{Discussion}
% \label{sec:discussion}

% ======================================================================================
\section{Conclusions and Future Work}
\label{sec:conclusion}
% In this work, we presented extensive experiments into establishing the state of the art for differentiable black-box and gray-box approaches for nonlinear audio effects modeling.
% Our experiments comprised state-of-the-art neural network architectures, we also proposed differentiable DSP-based gray-box architectures and introduced ToneTwist AFx, a large dataset of dry-input/wet-output pairs for audio effects research\\
In this work, we conducted extensive experiments to establish the state of the art in differentiable black-box and gray-box approaches for nonlinear audio effects modeling.
Our study explored task-specific neural network architectures, proposed differentiable DSP-based gray-box models, and presented ToneTwist AFx, a large dataset of dry-input/wet-output pairs for audio effects research.

We described the challenges of training and comparing different approaches, and demonstrated how careful consideration of the training scheme is essential to ensure fair comparisons and draw reliable conclusions.\\
Thanks to our extensive objective and subjective evaluations we concluded that state-space models are the most suited to model a wide range of devices, with TCN and GCN architectures also achieving very good results.
We found LSTM-based recurrent networks to be unreliable across devices and DDSP-based models not yet on par with neural networks.
Time-varying conditioning like TFiLM was proven beneficial, across convolutional and state-space backbones, to improve median and variance in objective metrics and subjective ratings.
% - we also showed that a form of time-varying conditioning like TFiLM is beneficial, across convolutional or state-space backbones, to increase median and reduce variance in objective metrics and subjective ratings.
% Furthermore, the study of correlation between subjective ratings and signal-based metrics highlighted how a loss function based on time-domain (L1/MAPE) and spectral-domain (MR-STFT) is the most sensible choice for a wide range of cases, but that there is potential for improvement in terms of signal-based and latent representation-based metrics for models evaluation.
Our analysis of the correlation between subjective ratings and signal-based metrics showed that a loss function combining time-domain (L1/MAPE) and spectral-domain (MR-STFT) is generally effective. 
However, there is room for improvement in signal-based and latent representation-based metrics for model evaluation.

Given these results, future work might focus on any of the following aspect:
\begin{itemize}
    \item Identify perceptually relevant signal-based and latent representation-based metrics for audio effects modeling. This would enable optimized training schemes for each architecture while ensuring objective model comparisons.
    \item Enhance gray-box models to achieve modeling accuracy on par with black-box approaches.
    \item Further study parametric modeling and conditioning methods across a wide range of effects, especially focusing on efficient implementations.
    \item Improve the implementation of gray-box processors and controllers to speed-up processing and increase overall efficiency.
    \item Investigate universal audio effects modeling architectures that can encompass all effect categories, including linear, nonlinear, and modulation effects.
    \item Integrate hyperparameter optimization, along with model pruning or distillation, to achieve high-performance and efficient models.
\end{itemize}
% Identify signal-based or latent representation-based metrics that are perceptually relevant for audio effects modeling tasks. This would allow to train architectures with optimal training schemes for each architecture while comparing models objectively.
% - improve gray-box models to achieve modeling accuracy comparable to black-box ones\\
% - further study parametric modeling and conditioning methods across a wide range of effects, especially focusing on efficient implementations.
% - improve processors and controllers implementation toward faster processing
% - explore universal audio effects modeling architectures, i.e., models capable of covering all categories of effects, linear, nonlinear and modulation.
% - incorporate hyperparameters optimization and model pruning or distillation for high performance and efficient models.

\section{Acknowledgments}
Funded by UKRI and EPSRC as part of the “UKRI CDT in Artificial Intelligence and Music”, under grant EP/S022694/1.