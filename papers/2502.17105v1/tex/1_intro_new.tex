% \vspace{-5pt}
\section{Introduction}
\label{sec:intro}

\input{figs/overview/overview}

\input{figs/benchmark_vis/benchmark_vis}

The rapid advancement of AI image generation technologies has brought significant achievements but also growing social concern, as these technologies are increasingly misused for the creation of fake news, malicious defamation, and other forms of digital deception. 
In response, AI-generated image detection is receiving more attention.
There is a wide variety of generative models, along with commercial models with unknown internal architectures.
This highlights the need for a generalized detector capable of distinguishing between real and fake images, regardless of the generative model structure.

In this context, early research focused on identifying the characteristic fingerprints of generated images.
Recent work, NPR\cite{tan2024rethinking} shows that pixel-level features, induced by the upsampling layers commonly found in current generative models, can serve as cues for detection.
However, there are clear practical limitations to relying on low-level fingerprints. 
First, the approach is vulnerable to simple image degradations, such as JPEG compression or blurring, which are common in real-world online environments\cite{wang2020cnn}.
Additionally, the model may become biased toward the specific \emph{fakeness} seen at training in cases where generalization to novel generators is not sufficiently considered\cite{ojha2023towards, zhu2023gendet}.
For instance, a detector trained on GAN-generated images may learn the characteristics of GANs as the fake features, while mistakenly perceiving images generated by diffusion models as real.
This bias limits the detector's generalizability across different types of generative models.

To tackle these limitations, UnivFD\cite{ojha2023towards} utilizes a robust, pre-trained image encoder.
This image embedding is task-agnostic, enabling it to capture high-level semantic information from images.
However, we found that UnivFD exhibits a bias towards the observed content in the training images, learning another specific \textit{fakeness}.
\cref{fig:overview} shows that UnivFD misclassifies most GAN-generated images of a novel class (StyleGAN-\textit{bedroom}) as \textit{real}.
The \textit{bedroom} class is absent from the training set, which may lead the detector to mistakenly classify most images as real, demonstrating the detector's reliance on seen content during training.

We propose a novel technique called \textbf{PatchShuffle}, which is the core of our fake image detection model, \textbf{SFLD} (pronounced ``shuffled'').
PatchShuffle divides the image into non-overlapping patches and randomly shuffles them.
This procedure disrupts the high-level semantic structure of the image while preserving low-level textural information. 
This allows the detection model to better focus on both context and texture.
SFLD utilizes an ensemble of classifiers at multiple levels of PatchShuffle, leveraging hierarchical information across various patch sizes.
This approach ensures that the model leverages both the semantic and textural aspects of the image to improve fake image detection.
The results demonstrate that SFLD achieves superior performance with enhanced robustness and better generalization.

Furthermore, we observe that previous benchmarks have three limitations:
\textbf{(1) low image quality.}
The previous benchmarks contain a significant portion of low-quality images that lag behind the capabilities of current generative models.
As a result, the practical usefulness of these benchmarks is significantly reduced.
\textbf{(2) lack of content preservation.}
Some subsets---particularly foundation generative models---lack access to the training data used for the checkpoints.
Consequently, the content of the generated and real images often differs significantly, making it difficult to determine whether a detector focuses on real/fake discriminative features or other irrelevant features. 
\textbf{(3) limited class diversity.}
Existing benchmarks primarily focus on expanding the variety of generative models without considering the generated class diversity and scalability among generative models.
As shown in \cref{fig:overview}, this makes it difficult to identify detection bias towards certain classes, as well as hard to represent the in-the-wild performance of the detector due to limited class diversity.

To address these challenges, we propose a new benchmark generation methodology and corresponding benchmark, \textbf{TwinSynths}.
It consists of synthetic images that are visually near-identical to paired real images for practical and fair evaluations.
TwinSynths constructs image pairs that preserve both quality and content while retaining the architectural characteristics of each generative model.
Also, TwinSynths enables flexible class expansion by generating synthetic images tailored to the real image. 
Using this benchmark, we evaluate the performance of our proposed SFLD method as well as existing detection models.

Our main contributions are summarized as follows: 
\begin{itemize}[leftmargin=*]
    \setlength\itemsep{0.0em}
    \item We propose SFLD, a novel AI-generated image detection method that integrates semantic and texture artifacts on generated images, achieving state-of-the-art performance.
    \item We propose a new approach on benchmarks and the subset of generated images that can ensure the quality and content of generated images.
    \item We validate our method through extensive experiments and analysis that support our hypothesis.
\end{itemize}
