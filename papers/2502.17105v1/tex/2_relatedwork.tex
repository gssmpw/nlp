\section{Related works}
\label{sec:related-works}

\textbf{AI-generated image detection on specific image generation models} 
Research on distinguishing between synthetic and real images using deep learning models has increased with the development of image generation models. 

Early works were focused on finding the fingerprints in images generated with GANs, which were targeted at high-performing image generation models.
Two major approaches were the use of statistics from the image domain \cite{mccloskey2018detecting, nataraj2019detecting} and the training of CNN-based classifiers.
In particular, in the case of using CNNs, there are two main approaches: focusing on the image domain \cite{mo2018fake, yu2019attributing, tariq2019gan} or the frequency domain \cite{marra2019gans, valle2018tequilagan, Frank}.
Specifically, GAN-generated images have been found to exhibit sharp periodic artifacts in this frequency domain, leading to a variety of applications\cite{ricker2024detectiondiffusionmodeldeepfakes, corvi2023detection, Frank}.

Recently, generative models took a big leap forward with the advent of diffusion models, which called for fake image detection methods that are able to respond to diffusion models.
However, some studies show that existing models trained to detect conventional GANs often fail in images from diffusion models.
For example, periodic artifacts that were clearly visible in GAN were rarely found in diffusion models\cite{ricker2024detectiondiffusionmodeldeepfakes, corvi2023detection}. 
In response, new detection methods optimized for diffusion models have emerged, for example, approaches that use diffusion models to reconstruct test images and evaluate them based on how well they are reconstructed\cite{Wang_2023_ICCV, luo2024lare, zhang2023diffusion}.

\textbf{Generalization of AI-generated image detection}
Recently, the community has shifted its focus towards general AI-generated image detectors that are not specific to GAN or diffusion. In particular, the development of commercially deployed generated models that do not reveal the model structure has increased the demand for such a universal detector.

Apart from existing attempts to learn a specialized feature extractor that simply classifies real/fake in a binary manner, Ojha \etal\cite{ojha2023towards} used the features extracted from a strong vision-language pre-trained encoder that is not trained on a particular AI-generated image. Zhu \etal\cite{zhu2023gendet} combined anomaly detection methods to increase the discrepancy between real and fake image features. 

Furthermore, several studies have concentrated on analyzing pixel-level traces on images inevitably left by the image generators. 
Tan \etal\cite{tan2024rethinking} exploited the artifacts that arise from up-sampling operations, based on the fact that most popular generator architectures include up-sampling operations. 
Chai \etal\cite{chai2020makes} tried to restrict the receptive field to emphasize local texture artifacts.

We design a simple yet powerful general AI-generated image detector that utilizes the feature space of the large pre-trained Vision Language Model.
We apply image reformation to capture not only global semantic artifacts but local texture artifacts from the input images, ensuring detection performance and generalizability on unseen generators.
