\begin{figure*}[t]
  \centering
  \includegraphics[width=\linewidth]{fig/forward_nbg_2.pdf}
   \caption{In a standard MLLM generation process, the model directly outputs an response based on the input image and query. However, an MLLM equipped with Visual Perception Tokens can first generate special tokens that trigger additional perception processes before responding. If the MLLM outputs a Region Selection Token, the original image is cropped and reprocessed through the visual encoder. The MLLM then bases its answer on two sets of visual embeddings: the first set contains the global embeddings from the original image, and the second set contains the local embeddings from the cropped image. If the MLLM outputs a DINO Feature Token, the DINO features of the image are used to supplement the original CLIP-based features. Additionally, besides the DINO features, the hidden state of the DINO Feature Token is also input to the projector as a condition to control which features are ultimately passed to the language model.}
   \label{fig:forward}
\end{figure*}
