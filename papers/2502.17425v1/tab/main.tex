\begin{table*}[t]
    \centering
    \resizebox{\linewidth}{!}{%
\begin{tabular}{lcccccc|c}
\toprule
\multicolumn{1}{c}{}                        &                                  & \multicolumn{3}{c|}{Visual Reasoning}                                                         & \multicolumn{2}{c|}{General VQA}                                             & Fine-Grained VQA          \\ \cmidrule(l){3-8} 
\multicolumn{1}{c}{\multirow{-2}{*}{Model}} & \multirow{-2}{*}{Max Resolution} & GQA            & OpenImage      & \multicolumn{1}{c|}{VSR}                                    & LLaVA Instruction Tuning                                    & Flickr*        & CUB Birds                 \\ \midrule
Qwen2-VL-2B                                 & 224                              & 0.448          & 0.413          & \multicolumn{1}{c|}{0.561}                                  & 0.655                                                       & 0.521          & 0.621                     \\
Qwen2-VL-7B                                 & 224                              & 0.464          & 0.442          & \multicolumn{1}{c|}{0.632}                                  & 0.703                                                       & 0.524          & 0.697                     \\
\rowcolor{fullgreen!20} 
Qwen2-VL-2B-VPT (DINO)                      & 224                              & \textbf{0.606} & \textbf{0.842} & \multicolumn{1}{c|}{\cellcolor{fullgreen!20}\textbf{0.657}} & \textbf{0.705}                                              & \textbf{0.558} & \textbf{0.892}            \\ \midrule
Qwen2-VL-2B                                 & 512                              & 0.487          & 0.418          & \multicolumn{1}{c|}{0.580}                                  & 0.728                                                       & 0.557          & 0.652                     \\
Qwen2-VL-7B                                 & 512                              & 0.569          & 0.456          & \multicolumn{1}{c|}{0.641}                                  & 0.780                                                       & 0.636 & 0.687                     \\
\rowcolor{fullgreen!20} 
Qwen2-VL-2B-VPT (DINO)                      & 512                              & 0.625 & 0.872 & \multicolumn{1}{c|}{\cellcolor{fullgreen!20}0.738} & 0.797                                              & 0.663          & 0.898            \\ 
\rowcolor{fullgreen!20} 
Qwen2-VL-2B-VPT (DINO, Free Choice)         & 512                              & \textbf{0.635} & 0.874 & \multicolumn{1}{c|}{\cellcolor{fullgreen!20}0.733} & 0.802                                              & 0.705          & 0.911            \\ 
\rowcolor{fullgreen!20} 
Qwen2-VL-2B-VPT (CLIP)                      & 512                              & 0.621 & 0.872 & \multicolumn{1}{c|}{\cellcolor{fullgreen!20}0.746} & 0.791                                              & 0.660          & 0.913            \\ 
\rowcolor{fullgreen!20} 
Qwen2-VL-2B-VPT (SAM)                       & 512                              & 0.617 & 0.876 & \multicolumn{1}{c|}{\cellcolor{fullgreen!20}0.746} & 0.796                                              & 0.657          & 0.905            \\ 
\rowcolor{fullred!20} 
Qwen2-VL-7B-VPT (CLIP)                      & 512                              & 0.633 & \textbf{0.878} & \multicolumn{1}{c|}{\cellcolor{fullred!20}\textbf{0.790}} & \textbf{0.831}                                              & \textbf{0.680}          & \textbf{0.921}            \\ \bottomrule\toprule
                                            &                                  & \multicolumn{4}{c|}{Text/OCR Related VQA}                                                                                                                   & Hallucination  &                           \\ \cmidrule(lr){3-7}
\multicolumn{1}{c}{\multirow{-2}{*}{Model}}                    & \multirow{-2}{*}{Max Resolution} & DocVQA         & TextVQA        & TextCaps                                                    & \multicolumn{1}{c|}{DUDE*}                                  & POPE*          & \multirow{-2}{*}{Average} \\ \midrule
Qwen2-VL-2B                                 & 224                              & 0.051          & 0.383          & 0.390                                                       & \multicolumn{1}{c|}{0.063}                                  & 0.821          & 0.448                     \\
Qwen2-VL-7B                                 & 224                              & 0.063          & 0.421          & 0.431                                                       & \multicolumn{1}{c|}{0.095}                                  & 0.827          & 0.482                     \\
\rowcolor{fullgreen!20} 
Qwen2-VL-2B-VPT (DINO)                      & 224                              & \textbf{0.125} & \textbf{0.537} & \textbf{0.466}                                              & \multicolumn{1}{c|}{\cellcolor{fullgreen!20}\textbf{0.103}} & \textbf{0.843} & \textbf{0.576}            \\ \midrule
Qwen2-VL-2B                                 & 512                              & 0.301          & 0.765          & 0.710                                                       & \multicolumn{1}{c|}{0.253}                                  & 0.847          & 0.572                     \\
Qwen2-VL-7B                                 & 512                              & 0.360          & 0.816 & 0.732                                              & \multicolumn{1}{c|}{0.322}                                  & 0.866          & 0.624                     \\
\rowcolor{fullgreen!20} 
Qwen2-VL-2B-VPT (DINO)                      & 512                              & 0.573 & 0.860          & 0.766                                                       & \multicolumn{1}{c|}{\cellcolor{fullgreen!20}0.430} & 0.893 & 0.738            \\ 
\rowcolor{fullgreen!20} 
Qwen2-VL-2B-VPT (DINO, Free Choice)         & 512                              & 0.576 & 0.861          & 0.758                                                       & \multicolumn{1}{c|}{\cellcolor{fullgreen!20}0.438} & 0.950 & 0.749            \\ 
\rowcolor{fullgreen!20} 
Qwen2-VL-2B-VPT (CLIP)                      & 512                              & 0.567 & 0.856          & 0.770                                                       & \multicolumn{1}{c|}{\cellcolor{fullgreen!20}0.433} & 0.887 & 0.738            \\ 
\rowcolor{fullgreen!20} 
Qwen2-VL-2B-VPT (SAM)                       & 512                              & 0.558 & 0.858          & 0.750                                                       & \multicolumn{1}{c|}{\cellcolor{fullgreen!20}0.431} & 0.894 & 0.735            \\ 
\rowcolor{fullred!20} 
Qwen2-VL-7B-VPT (CLIP)                      & 512                              & \textbf{0.658} & \textbf{0.906}          & \textbf{0.788}                                                       & \multicolumn{1}{c|}{\cellcolor{fullred!20}\textbf{0.532}} & \textbf{0.903} & \textbf{0.773}            \\ \bottomrule
\end{tabular}%
    }
    \caption{Performance comparison of MLLMs with and without Visual Perception Tokens. Datasets marked with ``*'' are not used in the training process. The best performance is highlighted in \textbf{bold}. A 2B model with Visual Perception Tokens can even outperform the 7B model without Visual Perception Tokens.}
    \label{tab:main}
\end{table*}