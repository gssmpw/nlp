
\begin{table*}[htbp]
    \centering
    \begin{tabular}{c|c|ccccc|ccccc}
        \toprule
        \multirow{2}{*}{Data} &\multirow{2}{*}{Method} & \multicolumn{5}{c|}{\textbf{Alpaca-52k}} & \multicolumn{5}{c}{\textbf{WizardLM\_evol\_instruct-70k}} \\ \cline{3-12}
        & & \tiny{MMLU} & \tiny{Winogrande} & \tiny{Truthfulqa} & \tiny{ARC} & \tiny{Gsm8k} & \tiny{MMLU} & \tiny{Winogrande} & \tiny{Truthfulqa} & \tiny{ARC} & \tiny{Gsm8k} \\ \cline{1-12}
        All & NA & 53.33 & 71.98 & 34.88 & 51.37 & 13.87  & 55.01  & 74.59 & 39.05 & 53.58 & 27.90 \\ \cline{1-12}
        \multirow{6}{*}{1k} 
        &\#INSTAG & 53.59 & 70.64 & 33.41 & 48.81 & 15.09 & 53.72 & 71.82 & 35.99 & 50.77 & 21.76 \\ 
        &Longest-instruction & 53.29 & 70.13 & 33.61 & 48.92 & 21.23 & 54.97 & 73.09 & 37.58 & 50.77 & 24.03 \\  
        & Longest-response  & 53.16 & 74.59 & 35.37 & 52.22 & 21.38 & 54.81 & 74.82 & 38.07 & 52.47 & 26.61 \\ 
        & Repr Filter &  53.81 & 73.48 & 35.13  & 50.77 & 11.75 & 50.95 & 74.03 & 36.60 & 47.70 & 24.26 \\  \cline{2-12}
        &\textbf{\one} & 54.49 & 74.19 & 33.17 & 51.71 & 18.27 & 54.88 & 74.59 & 38.43 & 55.80 & 25.25 \\ \cline{2-12}
        & \textbf{\two}  & 54.09 & 73.40 & 33.28 & 52.82 & 21.30 & 54.47 & 73.24 & 37.94 & 51.02 & 26.23 \\ 
        \midrule
        \multirow{6}{*}{3k}
        &\#INSTAG & 52.78 & 69.38 & 33.66 & 48.21 & 13.57 & 55.19 & 73.32 & 39.17 & 48.89 & 22.44 \\ 
        &Longest-instruction & 55.21 & 72.93 & 33.29 & 50.68 & 16.60 & 55.31 & 73.72 & 40.15 & 51.71 & 23.88 \\  
        & Longest-response  & 53.26 & 70.80 & 32.56 & 49.49 & 20.70 & 54.05 & 74.74 & 37.94 & 51.11 & 21.91 \\          
        & Repr Filter & 54.11 & 70.72 & 33.66  & 49.06 & 13.57 & 55.21 & 75.06 & 38.68 & 50.60 & 21.68 \\  \cline{2-12}
        &\textbf{\one} & 54.17 & 71.43 & 33.05 & 78.83 & 15.16 & 55.05 & 74.43 & 37.45 & 53.84 & 22.35 \\ \cline{2-12}
        & \textbf{\two}  & 54.39 & 70.56 & 32.93 & 52.47 & 11.90 & 55.38 & 74.19 & 36.35 & 53.41 & 24.41 \\ 
        \midrule
        \multirow{6}{*}{5k}
        &\#INSTAG & 50.19 & 69.23 & 29.87 & 47.01 & 13.04 & 55.13 & 74.03 & 38.80 & 78.24 & 22.74 \\ 
        &Longest-instruction & 52.39 & 70.96 & 29.50 & 50.43 & 13.34 & 55.04 & 74.27 & 38.31 & 81.86 & 23.81 \\  
        & Longest-response  & 51.09 & 71.02 & 32.24 & 49.87 & 12.59 & 54.73 & 74.66 & 37.33 & 53.24 & 20.47 \\  
        & Repr Filter & 54.51 & 73.95 & 34.52  & 54.01 & 16.60 & 55.80 & 75.53 & 37.70 & 52.99  & 25.25 \\  \cline{2-12}
        &\textbf{\one} & 51.65 & 70.32 & 32.44 & 48.63 & 11.37 & 55.23 & 73.95 & 37.70 & 51.79 & 23.20 \\ \cline{2-12}
        & \textbf{\two}  & 52.22 & 71.59 & 31.21 & 49.66 & 11.60 & 54.52 & 73.64 & 38.19 & 53.16 & 23.81 \\ 
        \bottomrule
    \end{tabular}
    \caption{Comparison of different models fine-tuned from Llama-2-13b using 1k, 3k and 5k data selected from Alpaca and WizardLM\_evol\_instruct\_70k datasets. '-' represents not appliable.}\label{tab: benchmark}
\end{table*}

 

