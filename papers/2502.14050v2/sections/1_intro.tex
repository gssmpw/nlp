\section{Introduction}
Scaling large language models (LLMs) has been shown to significantly enhance performance \citep{kaplan2020scaling, achiam2023gpt}, augmented by alignment \citep{bai2022constitutional, rafailov2024direct, schulman2017proximal} to make LLMs follow human instructions. Instruction fine-tuning (IFT) \citep{weifinetuned, longpre2023flan, sanhmultitask, ouyang2022training} has become an essential step in adapting LLMs to perform effectively across diverse tasks, and it is believed that the data quality and diversity are the most important factors during IFT.
%, and it is believed that the data quality and diversity are the true 'secrets' to for companies like OpenAI to lead the race. 
Recently, there is a growing interest on data-centric AI.
For example, innovations in data engineering enable scaling to vast contexts, extending the modelâ€™s capacity to handle extensive data sequences \citep{fudata}. Alpaca \citep{taori2023stanford} can elicit Llama's instruction-following by distilling $52$k instruction conversations from ChatGPT \citep{chatgpt2023}.
Importance resampling for selection has been developed to optimize data relevance \citep{xie2023data}. 


Although it is well acknowledged that the critical to effective instruction tuning is the training data's quantity \citep{ding2023enhancing}, quality \citep{chenalpagasus}, diversity \citep{bukharin2023data}, and complexity \citep{wang2023self}, as also highlighted by recent industrial technical reports, such as Llama-3 \citep{dubey2024llama} and QWen-2 \citep{yang2024qwen2},
it is still a mystery of how to accurately measure those features in data.
Generally, ensuring data quantity and quality are easier to achieve with either human feedback \citep{ouyang2022training} or automated AI feedback \citep{lee2023rlaif}.
However, evaluating data diversity and complexity are challenging. For instance, a recent call \citep{zhao2024position} urge a quantifiable approach to dataset diversity to ensure that claims of diversity are substantiated and meaningful: "\textbf{Measure Dataset Diversity, Don't Just Claim It}". 


Previous work has proved the effectiveness of small data quantity for achieving either general instruction following \citep{chen2023maybe, zhou2024lima}, or task-oriented abilities \citep{xialess}. \cite{zhang2024instruction} shows some preliminarily results to claim that instruction diversity drives generalization to unseen scenarios through symbolic tasks. And \cite{liumakes} perform controlled studies to measure data across
three dimensions: complexity, quality, and diversity (measured by cosine similarity of sentence representation). Besides, data pruning based on concept complexity has been shown effective in both pre-training \citep{abbaseffective} and post-training \citep{lu2023instag}.
However, many previous text diversity metrics \citep{shaib2024standardizing} are not adopted due to their intrinsic limitations. Therefore, there is still a lack of reliable diversity measure toward more efficient, effective, and targeted data selection in the instruction tuning landscape. And it is also unclear about the underlying mechanism such as what contributes to an accurate data diversity measure. 
Recently, SAEs \citep{cunningham2023sparse} has emerged as a powerful tool for interpreting the activated features in language models. The sparsity of the atomic monosemanticity guarantees the features are highly independent and 
accurate. Inspired by this advance, we first train an SAE and then \textbf{propose a new approach to use the activated features from SAE to measure data diversity}. 
Depending on the number of selected data, we then proposed two algorithms for effective data selection. The first one is greedy sampling using features from SAE for limited data (\textbf{SAE-GreedSelect}) and the second one is similarity-based sampling using features from SAE for scaling up the data selection (\textbf{SAE-SimScale}). We conduct comprehensive experiments on the widely used Alpaca \citep{taori2023alpaca} and WizardLM\_evol\_instruct\_70k \citep{xu2023wizardlm} datasets and our approach witnesses significant superiority over several previous results such as \textit{\#InsTag} \citep{lu2023instag}, \textit{Longest} \citep{zhaolong} and Repr Filter \citep{liumakes} across various models and data scale. 
Our approach also explains why some previous methods work by looking at the extracted features in the selected data.

In summary, we propose a novel method to use SAEs for diversity measure, and design new algorithms for diversity-driven data selection, contributing to more effective and interpretable instruction tuning.
