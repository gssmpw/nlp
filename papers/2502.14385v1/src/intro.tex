
\section{Introduction}

In an era, where Language Models (LMs) form the foundation of numerous tools and systems, a significant concern arises: how can we ensure these tools are equally beneficial to all communities? One major hurdle in this direction is \emph{inclusiveness}, particularly when it comes to scarce language varieties and the lack of models that take into account the diversity of dialects and culturally significant nuances of a given language~\cite{CostaJussa2018}. 
For example, while Portuguese is not considered a low-resource language, most of the content available is in Brazilian Portuguese. 
This is due to the Brazilian population representing more than 70\% of all native Portuguese speakers\footnote{Statistic derived from Wikipedia \url{https://en.wikipedia.org/wiki/Portuguese_language#Lusophone_countries}}. 
Consequently, a LM or a translation system trained on a Portuguese corpus is inclined to produce text containing phrases and grammatical structures of Brazilian Portuguese.  
As a result, countries like Portugal and Mozambique, which use different varieties of Portuguese, could find themselves at a disadvantage, particularly in deploying LM-based systems in critical areas such as healthcare and judiciary, where the grammar and lexicons of the language are of great importance~\cite{Scherre2016, Kato2016, Brito2016}.


One solution would be to create LMs specific to a certain language variety. However, this presents its own set of challenges for training and evaluation~\cite{ArmengolEstape2021,Rodrigues2023}. 
Training a LM, be it from scratch or fine-tuning,  requires a large, carefully curated corpus for training and several benchmarks for evaluation~\cite{Albalak2024}, which are either nonexistent or contaminated by the dominant language varieties. 
Another way to overcome these challenges is to create machine translation (MT) models dedicated to a specific language variety~\cite{Zbib2012, Sennrich2016, Riley2023}. 
With a sufficiently powerful MT model for the low-resource variety, we can take the first step toward resource creation and inclusion of these languages.
Such models can be used to translate training and evaluation benchmarks, which are predominantly in English, to the low-resource variety. 
Additionally, they can serve as an off-the-shelf intermediary between widely-used LMs and systems in low-resource settings or even be used to artificially generate data in the desired language variety. 


In this paper, we present a novel methodology for developing a neural machine translation (NMT) model tailored to low-resource language varieties, where manually annotated data is scarce or unavailable. Our approach leverages a retro-translation technique: we first gather texts in the low-resource language variety and translate them into a resource-rich language. This newly created parallel corpus is then used to fine-tune a pre-trained language model. We validate our methodology using European Portuguese as a case study, though the same steps can be applied to other languages with similar challenges. As part of this work, we have created and publicly released a meticulously curated parallel corpus for European Portuguese, comprising 1,719,002 documents -- the largest of its kind to date. We evaluate our model against existing open and close source translation systems for Portuguese, as well as zero-shot language models, demonstrating the effectiveness of our approach. Finally, to ensure our translations remain true to the intended language variety, we use a language variety classification model to quantify if the texts produced by our translation model are effectively European Portuguese. 

In summary, our contributions are the following:

\begin{enumerate}

  \item We propose a methodology to create a parallel corpus for a low-resource language variety using an on-the-shelf translation model. 
  To this end, we provide the community with the largest translation dataset for European Portuguese and English, named PTradutor.
  
  \item We provide the first  open-source translation models from English to European Portuguese which  outperform the generic Portuguese open-source translation systems and close the gap to state-of-the-art close-source translations systems for European Portuguese.
  
  \item We offer a comprehensive evaluation of our models, emphasizing not only translation quality but also linguistic alignment to the desired language variety.

\end{enumerate}

The remainder of this manuscript is organized as follows: Section~\ref{sec:ptradutor} offers a comprehensive overview of the development of our corpus, PTradutor, which serves as the foundation for training our models. Sections~\ref{sec:exp_setup} and \ref{sec:eval} describe the experimental setup and present the results of our experiments, respectively. In Section~\ref{sec:related_work}, we position our research within the context of existing approaches. Finally, Section~\ref{sec:conculsion} summarizes our findings and suggests directions for future research.
