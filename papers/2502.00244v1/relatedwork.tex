\section{Related Work}
In this section, we review prior on content review work to set the context for the use of psychological measures to study reviewer mental health. We then summarize the psychological risks of this work to establish the circumstances where such measures are used. We then summarize the differences between clinical and psychological measures of mental health. Finally, we outline the stakeholders, including designers, corporate managers, and labor unions, who stand to benefit from access to reliable measurement.

\subsection{Content review work}
This paper broadly focuses on the psychological experience of ``content review work,'' in which a human is repeatedly exposed to potentially harmful material and is expected to classify it without the ability to directly intervene or interact in the situation that generated the material. This material could be presented in various media (text, audio, visual, tactile). It could include graphic content, suicide notes, illegal material involving children, misinformation, evidence of war crimes, or other information broadly considered so harmful or risky that it needs to be proactively and urgently classified. We chose the term to describe a specific experience within a wider set of practices that have been called content labeling \cite{morrow2022emerging}, human computation \cite{law_human_2011}, commercial content moderation \cite{roberts_behind_2019}, volunteer moderation \cite{matias_civic_2019}, open source intelligence \cite{fiorella_how_2022}, digital humanitarian response \cite{dubberley_making_2015}, social media reporting \cite{dubberley_finally_2020}, microwork, ghost work \cite{gray_ghost_2019}, and digital crisis response \cite{branson_when_2021}. This general definition offers a bridge to the psychological literature while also highlighting key distinctions between content reviewing and other activities with trauma risks, such as nursing or law enforcement. In this section, we briefly summarize the evolving role of content review work in digital technologies and outline the distinct characteristics of this work that shape the psychological experience of workers.

\subsubsection{How Content Review Work Is Structured}
Scholarship on content review work has outlined multiple layers of relationships and institutions that structure the psychological experience of content reviewers: the user experience, interaction, forms of labor, and response to rapidly changing demand.

At its most basic level, content reviewing work is a \textit{user experience}. A system of bureaucracy and technology compiles materials for review, organizes those materials into a sequence of tasks, and then presents the worker with materials to make judgments on \cite{gray_ghost_2019}. Designers of these systems can control many aspects of the user experience, including the structure of tasks, the rate of tasks, the stimuli presented to workers (blurred or not for example), the rate of exposure, worker agency over task selection, whether tasks are individual or collective, and whether reviewers learn the outcomes of their judgments \cite{steiger_psychological_2021}. The type of content moderators encounter varies in severity, from benign content that was mistakenly flagged to the most extreme material. \cite{steiger_psychological_2021, yang2024perceptions}.

Content review work also varies in the degree to which reviewers \textit{interact} with the situations that they are making judgments about. In systems where content reviewing is one part of a wider set of community leadership and facilitation, people who do review work also have direct contact in real-time with the people and situations they are reviewing \cite{li_all_2022, postigo_emerging_2003, matias_civic_2019}, contact that is associated with differences in well-being \cite{bulat_psychology_2024}. Yet many content reviewers are distanced physically and culturally and separated in time from the situations they review, unable to contact people or intervene in the lives of people who likely do not know the reviewers exist \cite{roberts_behind_2019, gray_ghost_2019}. In situations where content reviewers evaluate the safety and reliability of AI systems, there may be no real situation for intervention at all, and reviewers may be unaware that they are interacting with generated materials \cite{zhang_human_2024}.

The work of content reviewers is structured through widely varying \textit{labor systems} that determine the workload, incentives, penalties, and general working conditions of reviewers. Some workers are employed as trust and safety professionals with salaries, retirement funds, and other corporate benefits \cite{roberts_behind_2019}. Others are volunteers or entry-level staff at journalism and civil society organizations \cite{dubberley_making_2015}. Yet others are prison laborers \cite{lehtiniemi_prisoners_2022, kaun_prison_2020}. While frontline content reviewers are the people exposed to the greatest quantities of extreme content, many other staff are also exposed in their everyday work, including engineers, product designers, and policy teams \cite{tspa2024content}. Many content reviewers work as precarious contractors in high-pressure work environments for companies that are sub-contracted by other firms, often in countries with low minimum wages and few labor protections \cite{buni2016secret, roberts2017social, chen2014laborers}. These working conditions are defined by a competing circle of regulators (who demand content moderation), multiple layers of subcontractors (who sell content reviewing services), and review requesters who are often global corporations seeking to scale digital technologies or mitigate technology harms \cite{gillespie2019custodians}.

Finally, content reviewing offers time-sensitive responses to \textit{rapidly changing demand} shaped by cultural markets, geopolitics, and business competition. Across fields, these dynamics create urgency for large volumes of work at unpredictable times under precarious working conditions: daily quotas ranging from 100 to 1,000 items depending on the platform and type of content \cite{bbc2022moderators,mcintyre_behind_2022,bureau2023dating}. For example, on one platform, moderators must review 900 videos a day with only 15 seconds per video \cite{mcintyre_behind_2022}. While dating app moderators are expected to evaluate a profile every 100 seconds \cite{bureau2023dating}. Moderators for another social media platform are expected to process a ticket every 55 seconds, which leads to between 500 and 1,000 reviews per shift \cite{guardian2024african}. The start or end of a war, natural disaster, or policy change can quickly increase demand for people with no prior experience in content reviewing or lead some reviewers to lose their positions. Similarly, competition between firms for data and AI model validation can create escalating boom and bust cycles for content reviewing labor \cite{ganguli_red_2022}.

\subsection{The psychological risks of content review work}
According to news reports, lawsuits, ethnographic investigations, and some survey research, content reviewers experience similar mental health harms as other helping professionals \cite{spence_content_2024}. Yet some elements of the role, including the pace of material and dissociation from the situation, are less common. In this section, we review the psychological risks to content reviewers through the lens of research on these other professions.

Research with front-line professionals such as first responders has shown that being exposed to other people's traumatic experiences can lead to post-traumatic stress disorder (PTSD) \cite{obuobi-donkor2022,spence_psychological_2023}. This disorder can develop after being exposed to actual or threatened death, serious injury, or sexual violence, either by experiencing or witnessing the event directly or through repeated or extreme exposure to distressing details of the traumatic event(s). It is characterized by intrusion (unwanted, involuntary thoughts), avoidance (avoiding triggering situations or any discussion of the symptoms), negative emotions (such as fear, blame, guilt, shame), and hyper-arousal (irritability, becoming overly watchful of surroundings, difficulty sleeping) \cite{apa2013,spence_psychological_2023}.

People working in helping professions such as social work or therapy can also experience conditions such as secondary traumatic stress (STS), vicarious trauma (VT), and burnout due to their exposure to others' trauma \cite{craig2010,greinacher2019,lee2018,spence_psychological_2023}. These conditions are sometimes called the ``cost of caring'' and are related to the stress experienced in response to another person's distress \cite{figley1995,spence_psychological_2023}. STS shares symptoms with PTSD, such as intrusive thoughts, hyperarousal, and hypervigilance. The harms of VT can grow substantially across a person's lifespan because it changes a person's self-image and view of the world to be less trustful, more fearful, more vulnerable, and cynical \cite{foley2021,krause2009,spence_psychological_2023}. Similarly, burnout is characterized by emotional exhaustion, cynicism, and decreased feelings of accomplishment \cite{brady2017,omalley2019,spence_psychological_2023}.

Researchers have observed similar symptoms across professions that are not traditionally considered front-line staff. For instance, journalists exposed to traumatic events while dealing with distressing content such as child abuse, child cruelty, war, and aviation accidents tend to experience higher levels of PTSD and internalize guilty thoughts \cite{browne2012,spence_psychological_2023}. Professionals who help refugees, asylum seekers, and displaced people also experience adverse mental health effects. These can include Secondary Traumatic Stress (STS) and Vicarious Trauma Stress (VTS) \cite{ebren2022}. A recent study of fifteen research projects showed that forty-five percent of professionals and volunteers working with forcibly displaced people experienced secondary traumatic stress--including intrusive re-experiences of the stories they had heard from refugees \cite{roberts2021,ebren2022}.

Content reviewers, such as caring professionals, journalists, or humanitarian workers, also experience traumatic encounters indirectly. They are often required to view depictions of child sexual abuse, violence, cruelty, humiliation, and discrimination for extended periods \cite{steiger_psychological_2021,spence_psychological_2023}. As a result, they report experiencing anxiety, depression, nightmares, fatigue, and panic attacks, which also impact their relationships and physical health \cite{roberts_behind_2019,newton2019,newton2020b,spence_psychological_2023}. Academic research has highlighted that content reviewers experience high-stress levels, fatigue, insomnia, anxiety, low mood, increased apathy, guilt, and intrusive images as part of their everyday work \cite{dosono2019,lo2018,cook_awe_2022,benjelloun2020,spence_psychological_2023}. Content reviewers may not initially notice this effect, which can be gradual and cumulative, making it challenging for individuals to recognize any changes in themselves or others \cite{krause2009,ledingham2019,spence_psychological_2023}. When content reviewers provided examples of how they were affected, they mentioned experiencing intrusive thoughts and images related to CSAM, often triggered by children and their own sexual behavior \cite{spence_psychological_2023}. Some also talked about avoiding children and experiencing cognitive and emotional effects such as hyper-vigilance around children, anger, increased distrust of others, and symptoms of hyper-arousal, including sleep disturbances and bodily sensations of anxiety \cite{spence_psychological_2023}. 

The psychological consequences of chronic job-related stress or exposure to traumatic content at work can be severe and long-lasting \cite{vasconcelos2021,spence_psychological_2023}. Like people in similar professions, content reviewers have described developing a darker, more cynical view of the world and other people \cite{omalley2019,spence_psychological_2023}. These views may persist even after they leave their job \cite{omalley2019, spence_psychological_2023}. Younger workers tend to experience greater distress after trauma, more symptoms, and higher levels of burnout \cite{acierno2006,adams2006,brady2017,spence_psychological_2023}. Many content reviewers are relatively young, potentially making them more vulnerable to psychological harm while also having more of their lives to bear the consequences.

Researchers have also found that working with hate speech is linked to intrusive thoughts and hyper-vigilance \cite{jereza2022,spence_psychological_2023}. This type of content is the most common content that moderators have to review on social media platforms \cite{facebook2022a,twitter2021,spence_psychological_2023}. Researchers hypothesize that if hate speech is associated with violent or graphic content, moderators' worldviews may be altered, possibly aligning with what they are exposed to \cite{jereza2022,spence_psychological_2023}.

Further research is necessary to determine the prevalence of these harms among content reviewers, whether they vary on the basis of the content that they review, and what can be done to manage these harms \cite{jereza2022,spence_psychological_2023}. To answer these questions, we need larger-scale quantitative and longitudinal studies to measure potential effects and their long-term consequences, quantify potential impacts, and explore possible factors that increase content reviewer resilience \cite{burns2008,samsha2014,spence_psychological_2023}â€”issues that have been explored qualitatively in CSCW and HCI scholarship, e.g., \cite{dosono2019,finholt_psychology_1998,fox_patchwork_2023,cook_awe_2022}.

\subsection{Clinical and Research Uses for Psychological Measures of Workers}
Clinical and occupational psychologists make important scientific, occupational, and legal distinctions between different kinds of psychological measures. Notably, measures for individual diagnoses (clinical use) differ from those designed to shed light on a work environment or occupation (research use). For clinical psychologists, a reliable measure is a narrow diagnostic tool to inform interventions that could improve their health as well as provide reliable information to employers, insurers, and courts. For research-oriented occupational psychologists, a reliable measure will reveal new understandings about people, their environments, and the nature of their occupations.

Psychological surveys used for clinical purposes are designed to inform diagnoses of conditions that might include mental illness or some other psychological harm, whether or not a workplace experience has caused the damage. A reliable measure will help clinicians decide whether to classify people's experiences with a recognized mental health condition, whether it is short-term and reversible or not. Professional medical and psychiatric organizations, such as the American Psychiatric Association (APA), the World Health Organization (WHO), and the National Institute for Occupational Safety and Health (NIOSH) maintain consensus systems for carrying out these diagnoses, which are recognized by medical professionals, insurers, and courts \cite{who_icd11,apa2013,tetrick2023handbook}. For example, clinical psychologists have added Secondary Trauma as an extension of Post-Traumatic Stress Disorder (PTSD) in the DSM-5, which is used to diagnose mental health \cite{hydon2015preventing,apa2013}.

Many other psychological measures of workers are focused on supporting scientific discoveries about people and their environments rather than supporting clinical diagnoses. For example, the Maslach Burnout Inventory (MBI) was originally developed to understand organizational stress and job-person fit rather than diagnose a medical condition independent of someone's job \cite{MaslachJackson1981,kahn1992stress}. Similarly, measures such as the Copenhagen Burnout Inventory (CBI) seek to measure a person's capacity and ability to manage their mental resources during or outside work periods \cite{kristensen2005copenhagen}. By studying people's psychological experience of work in context, researchers hope to understand the psychology of work better, compare different professions, and offer insights into the effects of different management approaches.

Psychologists insist that research-focused psychological measures should not be used for clinical purposes, which they have not been designed for \cite{tetrick2023handbook}. First, using the wrong measure for the wrong purpose could generate misleading findings if the instrument is measuring something that is not a clinical outcome. Second, non-clinical measures are not designed to support binary decisions about whether someone has a condition or not. So-called diagnoses based on non-clinical measures can be prone to error, especially when people without clinical training make arbitrary decisions about the threshold for diagnosis. Using clinical measures for non-clinical purposes can also cause difficulties for scientists when they lack the statistical properties needed to estimate correlation or causation across groups.

Decisions about what to measure have practical consequences for the people and organizations being measured. Since clinical measures are used to make claims about the health and competence of individuals, people may resist diagnosis due to potential stigma and workplace consequences. This diagnosis avoidance could lead to biased estimates in research studies. Mismeasurement can also lead to misunderstandings of worker conditions. For example, studies that prioritize clinical diagnoses alone may fail to observe workplace conditions that are important factors in a person's experience. Conversely, research-focused measures that incorporate more information about the workplace can sometimes fail to observe important health diagnoses \cite{tetrick2023handbook}.

Because clinical and research measures have different functions and prioritize different things, we differentiate between them in our systematic review. 

\subsection{Applying Psychological Measurements in CSCW}
Psychological measurement has played a central role in the fields of human-computer interaction and computer-supported cooperative work \cite{card_psychology_1986, olson_research_1997, finholt_psychology_1998,norman_design_2013, kiesler_social_1984}. In many cases, designers and organizations can develop bespoke surveys in user experience design \cite{ozok_survey_2007}. Yet high-stakes situations such as mental health rely on scientifically-validated measures.

Researchers in human-computer interaction have called for greater consideration of trauma in the design of technologies, making reference to the work of people who review harmful content for social media platforms \cite{scott_trauma-informed_2023} and artificial intelligence training systems \cite{zhang_human_2024}. Because the design of systems that structure human labor necessarily involves conflicting needs and aims \cite{gregory_scandinavian_2003} with different evidentiary requirements, no single measure of mental health will serve all purposes. In this section, we summarize the different parties who need to measure content reviewers' mental health and their sometimes conflicting use cases for clinical and psychological measures.

Content reviewing labor is structured in a complex supply chain of organizations with conflicting interests around worker mental health \cite{roberts_behind_2019}. This complexity is reflected in the scholarship within social computing, where researchers sometimes operationalize mental health as an independent variable that predicts productivity and retention for unpaid workers \cite{schopke-gonzalez_why_2022}, sometimes describe it as an occupational risk \cite{spence_content_2024}, and other times describe it as a social justice concern \cite{steiger_psychological_2021}. In public talks, trust and safety professionals at large platforms have also described mental health measurement as a tool for supply chain transparency as they evaluate the constellation of contractors and sub-contractors who provide this labor \cite{gilbert_what_2022}. 

\textbf{Content Reviewers}
Many content reviewers may not realize they are experiencing mental health issues, as such problems can manifest gradually \cite{Te-Brake2008} and reviewers may become accustomed to feelings of anxiety, stress, and unhappiness at work and view these emotions as common \cite{Te-Brake2008, capel_longitudinal_1991, spence_psychological_2023}. Ignoring early warning signs can exacerbate negative mental states, leading to illnesses, burnout, and other health problems. Such burnout can also negatively impact job performance, relationships, and home life \cite{shirom_discriminant_2003,spence_psychological_2023}. Self-assessment could help workers prioritize their well-being and observe early signs of discomfort \cite{spence_psychological_2023}. With feedback on their symptoms, workers could make informed assessments of how their work affects them, seek care, and request changes to their work arrangements \cite{steiger_psychological_2021,spence_psychological_2023,roberts__2023}. 


\textbf{Organizations that rely on content reviewing}
Since content reviewing work implicates many organizations across a labor supply chain of for-profit, non-profit, and public-interest organizations, these organizations have many potential uses for mental health measurement, some of them conflicting. Within organizations, measurements are relevant to three groups: managers, clients, and organizations that work with volunteer content reviewers.

\textit{Managers and designers} need to be able to identify working conditions that are especially harmful to whole groups of workers, whether those working conditions are the design of a software workflow, the design of an office building, or the management culture of a unit. They also need to be able to evaluate the effectiveness of interventions designed to improve workplace conditions \cite{steiger_psychological_2021}. \text{Clients of organizations} that provide content reviewing labor need to be able to assess the well-being of subcontractors well enough to manage liability and ensure compliance with mental health best practices, sometimes across countries and cultures. Clinical psychologists have reported that some companies have retained them to manage compliance and liability through supply chain transparency, though none of this work has been made public \cite{gilbert_what_2022}. Organizations that work with \textit{volunteer reviewers,} such as humanitarian groups, Wikipedia, or social media platforms, face distinct challenges to sustain levels of volunteering or support people whose trauma may make it difficult for them to step away from content reviewing \cite{mcmillen_wikipedia_2016}. Commercial platforms that rely on volunteer moderation also face this challenge, with the added constraint that too much support for unpaid volunteers might expose them to legal liability if courts determine that moderators should be compensated \cite{postigo_emerging_2003, terranova_free_2012, matias_civic_2019}.

\textbf{Labor Organizers}
Measurements of content reviewer mental health can also be powerful tools for labor organizers. Consider, for example, the publicly stated goals of the Safe Content Advocacy Network (SCAN), led by the Kenyan moderator and organizer Daniel Motaung. This organization seeks to advocate for better working conditions for moderators- an advocacy goal that reliable mental health measures could inform \cite{safe_content_advocacy_network}. These Kenyan workers, alongside content reviewers in Columbia, have now successfully unionized \cite{perrigo_150_2023, mcintyre_teleperformance_2023}. If labor organizers can use mental health measures to show the impacts of employer working conditions, wages, and benefit programs, their advocacy might be placed on a more substantial empirical basis.

\textbf{Social Scientists}
In parallel with the pragmatic interests of tech firms, moderators, and other stakeholders, improved measurements of mental health could also contribute more general discoveries to the fields of psychology and design. Digital communications systems have created a new class of psychological experience for humankind - processing highly disturbing material at an unprecedented scale and speed. Efforts to understand the psychological process created by these design decisions could help us better understand the nature of trauma more generally. Furthermore, attempts to transfer and validate clinical psychology measurements from other fields into content moderation could add clarity to the generalizability and limitations of the standard trauma measures we consider in this review. In parallel, computer scientists have recently developed frameworks for trauma-informed computing design \cite{dellet.altraumainformed}. The lessons we learn about the psychological impacts of moderation could have broader implications for trauma-informed computing, well beyond just content moderation.