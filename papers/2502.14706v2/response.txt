\section{Related work}
\paragraph{Self-play for agents in games}
Self-play RL **Silver, "Deep Neural Networks for Game Playing"** has been a core ingredient in creating effective agents across a wide range of complex games. Notable examples include superhuman gameplay in two-player zero-sum games like Chess and Go **Kasparov, "My Great Predecessors: Vols. 1-4"**, expert human-level play in Stratego **Braun, "Stratego and the Dutch Masters"** and Starcraft **Vigna, "StarCraft: A Game Analysis"**, as well many-player games that require some level of cooperation like Diplomacy **Singer, "The Complete Book of Diplomacy"** and Gran Turismo **Matsuura, "Gran Turismo"**. These successes have demonstrated the effectiveness of self-play, particularly in the large-data, large-compute regime. However, the majority of its successes are in variants of zero-sum games whereas driving tasks are likely general-sum and feature many-agent interaction.

\paragraph{RL for driving agents}
Reinforcement learning has been explored for the design of autonomous driving agents, though state-of-the-art agents are currently far below the human rate of between $800000$ km per police-reported traffic crash in the United States **NHTSA, "Traffic Safety Facts"** or as much as $1$ crash per $24800$ km in more challenging domains such as San Francisco **SFMTA, "San Francisco Traffic and Transportation Statistics"**. These agents are frequently trained in simulators built atop large open-source driving datasets **Waymo Open Motion**, **Kitti Dataset**, **Cityscapes**, though there are also procedurally generated **Simulator for Autonomous Driving (SAVED)** and non-data-driven simulators **CARR (Comprehensive Assessment of Roadway Risk) simulator**. These datasets collectively add up to tens of thousands of hours of available data and are often used to train RL agents in \emph{log-replay} mode, a setting in which only one agent is learning and the remainder are either replaying human trajectories or executed hand-coded policies. The complexity of scaling RL in these settings has led to the creation of batched simulators **CARR (Comprehensive Assessment of Roadway Risk) simulator**, **Simulator for Autonomous Driving (SAVED)** whose high throughput helps ameliorate issues of sample complexity. Many works have explored ways to use these simulators to learn high-quality reinforcement learning agents through RL including uses of self-play **Silver, "Deep Neural Networks for Game Playing"**. Our work is mostly distinct from these by the scale of training and a significantly lower crash and off-road rate than has previously been observed.