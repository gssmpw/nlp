\documentclass{article}

\usepackage{arxiv}
\input{head}


\title{Qini Curve Estimation Under \\Clustered Network Interference}

\author{
  Rickard K.A. Karlsson$^{*}$ \\Delft University of Technology \\ r.k.a.karlsson@tudelft.nl 
  \And 
  Bram van den Akker$^{*}$ \\ Booking.com \\ bram.vandenakker@booking.com 
  \And 
  Felipe Moraes \\ Booking.com \\ felipe.moraes@booking.com 
  \And 
  Hugo M. Proença \\ Booking.com \\ hugo.proenca@booking.com 
  \And 
  Jesse H. Krijthe \\ Delft University of Technology \\ j.h.krijthe@tudelft.nl
}

\begin{document}

\maketitle

\begingroup
\renewcommand\thefootnote{\textasteriskcentered}
\footnotetext{Equal contribution.}
\endgroup

\begin{abstract}
    Qini curves are a widely used tool for assessing treatment policies under allocation constraints as they visualize the incremental gain of a new treatment policy versus the cost of its implementation. Standard Qini curve estimation assumes no interference between units: that is, that treating one unit does not influence the outcome of any other unit. In many real-life applications such as public policy or marketing, however, the presence of interference is common. Ignoring interference in these scenarios can lead to systematically biased Qini curves that over- or under-estimate a treatment policy's cost-effectiveness.  In this paper, we address the problem of Qini curve estimation under clustered network interference, where interfering units form independent clusters. We propose a formal description of the problem setting with an experimental study design under which we can account for clustered network interference. Within this framework, we introduce three different estimation strategies suited for different conditions. Moreover, we introduce a marketplace simulator that emulates clustered network interference in a typical e-commerce setting. From both theoretical and empirical insights, we provide recommendations in choosing the best estimation strategy by identifying an inherent bias-variance trade-off among the estimation strategies. 
\end{abstract}

\section{Introduction} 

% General background on treatment effect heterogeneity
Understanding treatment effect heterogeneity --the variation in individual responses to the same treatment within a population-- is central in shaping individualized treatment policies across various domains, including personalized medicine~\citep{kravitz2004evidence}, uplift modeling in marketing and e-commerce~\citep{goldenberg2020free}, and targeted subgroup interventions in public policy~\citep{brand2011impact}. In these scenarios, the same questions recurs: \textit{Who should we treat?} Sometimes, it is sufficient to identify individuals who respond positively to a treatment. However, when treatments involve monetary or practical costs, the challenge is to devise a cost-effective policy that targets those who benefit the most from the treatment while staying within a given budget for treatment allocation.

% Introduce Qini curves
First introduced by~\citet{radcliffe2007using} in the marketing literature, Qini curves have become a widely used method for evaluating the cost-effectiveness of treatment policies. A Qini curve plots the incremental gain by treating units prioritized by a given treatment rule under varying allocation budgets. By comparing the Qini curves of different prioritization rules, practitioners can determine which rule most effectively identifies who responds well to treatment. However, reliable estimation of Qini curves depends on some key assumptions being met, one of which is the Stable Unit Treatment Value Assumption~\citep{rubin1980randomization}. This assumption implies that there is no treatment interference, meaning that treating one unit has no influence on the outcome of any other unit. 

% Explain why interference is a problem and point out research gap
Interference arises in a variety of contexts, from peer effects in social networks~\citep{manski2013identification,ogburn2020causal} to cannibalization effects on marketplace platforms ~\citep{holtz2024reducing}. One of the most common settings is so-called \textit{clustered network interference} where interference only happens within, rather than between, clusters. While there exists an extensive body of literature on estimating treatment effects under clustered network interference, e.g.~\citet{sobel2006randomized,hudgens2008toward}, little attention has been given to the problem of estimating Qini curves in this setting. As we demonstrate in Figure~\ref{fig:example}, traditional methods for estimating Qini curves become significantly biased when interference is present. Since biased Qini curves lead to incorrect assessments of the cost-effectiveness of treatment  policies, this is an important yet unaddressed problem. Consequently, the central question we aim to answer in this paper is: \textit{How can we accurately estimate Qini curves under clustered network interference?}

\paragraph{Contributions} To address our research question, we first present a formal description of the problem and describe the experimental study design and necessary identification conditions for estimating Qini curves under clustered network interference. Next, we propose three different estimation strategies based on different modeling assumptions, highlighting their respective benefits and drawbacks from a bias-variance perspective. We then empirically compare our proposed methods with a traditional approach for Qini curve estimation using a simulated dataset designed to mimic a marketplace with interference in the form of cannibalization among different vendors. Finally, based on our findings, we provide practical recommendations on how to estimate Qini curves in settings with clustered network interference. 

\begin{figure}[t]
    \centering
    \includegraphics[width=0.45\linewidth]{figures/qini_curves-normalize_True-20250126_171100-20250127_172025-20250128_214409-20250129_104511-softmax_exp_decay-Figure1.pdf}
    \caption{An illustrative experiment with Qini curve estimation under clustered network interference. The black dashed line represents the true underlying Qini curve, while the solid lines depict two estimation approaches: one based on a traditional method that assumes no interference, and the other representing a proposed strategy in this paper that adjusts for interference using inverse probability weighting.  More details on the simulation used to generate this figure can be found in Appendix~\ref{app:experiments}.}
    \label{fig:example}
\end{figure}

\section{Related works}


The task of estimating treatment effects becomes considerably more complex in the presence of interference. Hence, despite early influential works in causal inference such as~\citet{rubin1974estimating}, only recently has a large body of literature emerged to tackle scenarios with interference. One of the most commonly studied settings is clustered network interference, where treatment units form independent clusters~\citep{sobel2006randomized,hudgens2008toward,tchetgen2012causal}, a condition also known as partial interference. Interference also naturally arises in network data, where some units are related to other units by being neighbors in e.g. a social network~\citep{ugander2013graph,eckles2017design}. In some cases, an experimental study design can be constructed in a way to detect and reduce bias from interference, for instance, through a two-stage randomization design~\citep{hudgens2008toward} or by stratified randomization across different blocks~\citep{bajari2021multiple}. Previous works have covered specific tasks under interference such as heterogeneous treatment effect estimation~\citep{zhao2024learning} or policy evaluation/learning~\citep{zhang2023individualized}. To our knowledge, there is no prior work on the problem of estimating Qini curves in the presence of interference.

Evaluating treatment prioritization rules using Qini curves in settings without interference has gained more attention in recent years~\citep{radcliffe2007using,rossler2022bridging,bokelmann2024improving}. The development of estimations procedures with better statistical inference guarantees has enabled the use of Qini curves in this context~\citep{yadlowsky2024evaluating}. While none of these works consider interference, \citet{sverdrup2024qini} considers the related problem of estimating Qini curves for combinatorial multi-armed treatments. There is an inherent connection between combinatorial treatment problems and clustered network interference, as the treatment assignment of units within a single cluster can be seen as a combinatorial treatment decision. This connection also underscores the challenge of estimating Qini curves under clustered network interference: as cluster size grows the combinatorial space of possible treatments expands exponentially, leading to a corresponding increase in interactions among units within the cluster. To address this challenge, we propose estimation strategies designed to more accurately estimate Qini curves, even as the cluster size grows.


\section{Data structure \& assumptions}

\paragraph{Notation}
We assume access to observations from a distribution $P$. We have clusters $i=1,\dots, N$ and each cluster contains the units $j=1,\dots, M_i$. A unit can be referred to by the tuple $(i,j)$. For each cluster $i$, we observe pre-treatment covariates $X_{i}$ in $\mathcal{X}\subseteq \mathbb{R}^{d_x}$. For each unit, we observe pre-treatment covariates $Z_{ij}$ in $\mathcal{Z}\subseteq\mathbb{R}^{d_z}$, a binary treatment $W_{ij}\in\{0,1\}$, and an outcome of interest $Y_{ij}$ in $\mathcal{Y}\subseteq \mathbb{R}$. The outcome may be binary or continuous. In addition, we also observe a non-negative cost of treatment $C_{ij}$ in $\mathcal{C}\subseteq[0,\infty)$. The cost $C_{ij}$ depends on both the treatment and outcome, and specifically we assume there to be no cost $C_{ij}=0$ when no treatment is given $W_{ij}=0$.
We consider cluster-level outcomes and costs which we define as ${Y}_i=\sum_{j=1}^{M_i}Y_{ij}$ and ${C}_i=\sum_{j=1}^{M_i}C_{ij}$. We also define the cluster-level treatment which is a binary
vector $\mathbf{W}_i=[W_{i1}, W_{i2}, \dots, W_{iM_i}] \in \{0,1\}^{M_i}$. At last, random variables are denoted by capital letters, while their instantiated values use lowercase. Probability densities are represented as $f(\cdot)$. 

\paragraph{Clustered network interference} In the setting of clustered network interference, we assume observations can be divided in independent clusters. Treating one unit belonging to cluster $i$ may influence the outcomes of other units from that same cluster. However, treating units from a different cluster $i'$ will not influence the outcomes of the units in cluster $i$. To define causal effects in this setting, we posit potential (counterfactual) outcomes $Y_{ij}(\mathbf{w})$ corresponding to the outcomes we would observe for an unit$(i,j)$ if the treatment vector $\mathbf{W}_i$ would be set to  $\mathbf{w}$~\citep{tchetgen2012causal}. Analogously, we define the counterfactual cost $C_{ij}(\mathbf{w})$ if $\mathbf{W}_i$ would be set to $\mathbf{w}$. 

\paragraph{Study design}
Throughout this paper, we consider an experimental study design where the unit-level treatments $W_{ij}$ are independently and randomly assigned. The treatment probability is determined by $e_w(x) = \Pr(W=w\mid X=x)$ which is known and the same for all units within a given cluster. Following standard convention,  we refer to this probability as the propensity score~\citep{rosenbaum1983central}.  We assume the following conditions are fulfilled by our experimental study design.
\begin{assumption}\label{asmp:identification_conditions}\textit{Consistency:} if $\mathbf{W}_i = \mathbf{w}$ then $Y_{ij}(\mathbf{W}_i) = Y_{ij}$ and $C_{ij}(\mathbf{w})=C_{ij}$, for all units $(i,j)$ and treatments $\mathbf{w} \in \{0,1\}^{M_i}$. \textit{Conditional exchangeability:} for each treatment $\mathbf{w} \in \{0,1\}^{M_i}$, $\left(Y_{ij}(\mathbf{w}), C_{ij}(\mathbf{w})\right) \indep \mathbf{W}_i \mid X_i$. \textit{Positivity:} for each treatment $\mathbf{w}\in \{0,1\}^{M_i}$, if $f(x) \neq 0$ then $\Pr(\mathbf{W}_i = \mathbf{w} \mid X_i = x) > 0$.
\end{assumption}

\textit{Consistency} is met when the intervention is unambiguously defined, meaning that no undisclosed variants of the treatment exist. \textit{Conditional exchangeability} corresponds assuming no unmeasured confounding; specifically, the characteristics captured by cluster-level covariates are sufficient to control for any confounding between treatment assignment and outcome/cost. \textit{Positivity} necessitates that all clusters have a non-zero probability of receiving any of combination of available treatments among its units. In the context of our experimental study design, we emphasize that conditional exchangeability and positivity can be guaranteed by (conditional) randomization.




\section{Assessing treatment policies using Qini curves under clustered network interference}
We are interested in assessing treatment policies based on some treatment prioritization rule $S : \mathcal{X} \times \mathcal{Z} \rightarrow \mathbb{R}$ that attempts to rank all units across the clusters based on who responds best to the treatment. A larger $S(X_{i}, Z_{ij})$ should here be interpreted as that the unit $j$ in cluster $i$ is expected to have a larger treatment effect. Given a treatment prioritization rule $S$ and a fixed treatment threshold $R\in\mathbb{R}$, we will evaluate decisions by treatment policies defined as 
\begin{equation*}
    \pi_{S,R}(x,z) = \begin{cases}
        1, &  S(x,z) \geq R \\
        0, & S(x,z) < R 
    \end{cases}~.
\end{equation*}
Importantly, throughout this paper, we will assume that all treatment prioritization rules are derived independently of the data we will use to evaluate them on. For instance, $S$ could be the estimated model of the conditional average treatment effect, see e.g.~\citet{kunzel2019metalearners}, trained on a separate dataset or a formal prioritization rule developed by experts using domain knowledge. To simplify notation, we will omit the subscripts in $\pi_{S,R}$ when possible and simply write $\pi$ to denote a policy.

\subsection{Definition of the Qini curve}
A common approach to assess how well a treatment prioritization rule identifies those who best respond to a treatment is by using Qini curves~\citep{radcliffe2007using,sverdrup2024qini}. We denote the decisions made by the policy $\pi$ on an evaluation dataset as $\pi_{ij}=\pi(X_{i}, Z_{ij})\in\{0,1\}$ for unit $(i,j)$ and $\boldsymbol{\pi}_{i}=[\pi(X_{i}, Z_{i1}), \dots, \pi(X_{i}, Z_{iM_i})]\in\{0,1\}^{M_i}$ for the collective treatment decision on cluster $i$.
Then, we first define the policy value in terms of average cluster-level outcomes under decisions made by the policy $\pi$, 
\begin{equation*}
    V(\pi) = \E\left[\sum_{j=1}^{M_i} Y_{ij}\left(\boldsymbol{\pi}_i\right) \right]~,
\end{equation*}
and the policy cost of applying $\pi$ as
\begin{equation*}
    C(\pi) =\E\left[\sum_{j=1}^{M_i}  C_{ij}\left(\boldsymbol{\pi}_i\right) \right]~.
\end{equation*}
The expectations are taken with respect to the distribution of all possible clusters.

Let $R_B$ denote the threshold such that $C(\pi_{S,R_B})=B$, then we can define the Qini curve for a treatment prioritization rule $S$ as follows:
\begin{equation} \label{eq:qini_curve}
Q_{S}(B) = V(\pi_{S,R_B}) - V(\pi_0), \;\; B\in[0, B_{\text{max}}]
\end{equation}
where $\pi_0\equiv0$ is a reference policy that treats none and $B_{\text{max}}>0$ is the maximal allowed cost under consideration. 

The above definition is more general than the one by \citet{radcliffe2007using}, who assumes uniform cost across all units. In their approach, $Q_S(B)$ on the y-axis against the fraction of treated units on the x-axis. The definition presented here can be applied to this case by plotting $B/B_{\text{max}}$ on the x-axis, where $B_{\text{max}}$ represents the total cost of treating all units. We refer to this as the uniform cost case. 

To understand how interference introduces challenges in the estimation of Qini curves, consider a scenario where two units from the same cluster fall on opposite sides of the threshold $R$ --one above (indicating it should be treated) and one below (indicating it should not). Normally, these units would be considered independent, but in the presence of interference, spillover effects may occur between them. If these effects are not accounted for, we might over- or underestimate the policy value and cost which also affects the Qini curve estimation.

For the remainder of this paper, we will demonstrate how to address this issue and provide a methodology for estimating Qini curves that appropriately accounts for interference within a clustered network setting. However, before we discuss estimation, we also establish a necessary identifiability result that allows for estimation.

\subsection{Identifiability of policy value and policy cost}

To estimate $Q_{S}(B)$ in~\eqref{eq:qini_curve}, $V(\pi)$ and $C(\pi)$ must be identifiable from the observed data. We note that under assumption~\ref*{asmp:identification_conditions}, these can be identified from the data collected in our randomized design. More specifically, recall that $Y_i  =\sum_{j=1}^{M_i} Y_{ij}$ and $C_i =\sum_{j=1}^{M_i} C_{ij}$, then we define
\begin{align*}
    \phi(\pi) &= \frac{1}{N} \sum_{i=1}^N \E[Y_{i} \mid \mathbf{W}=\boldsymbol{\pi}_i, X_{i}]~,\\
    \psi(\pi) &= \frac{1}{N} \sum_{i=1}^N \E[C_{i} \mid \mathbf{W}=\boldsymbol{\pi}_i, X_{i}]~,
\end{align*}
for which we can show that the policy value and policy cost are identifiable from the observed data (see Appendix~~\ref{app:identification} for the proof).
\begin{theorem}~\label{thm:identification}
    Under assumption~\ref{asmp:identification_conditions}, we have that $V(\pi)=\E[\phi(\pi)]$ and $C(\pi)=\E[\psi(\pi)]$.
\end{theorem}

\begin{algorithm}[t]
\caption{Qini curve estimation}
\label{alg:qini_curve_estimation}

\begin{algorithmic}[1] % The number in [1] controls the line numbering.
\REQUIRE Dataset $D=\{X_i, \{Z_{ij}, W_{ij}, Y_{ij}, C_{ij}\}_{j=1}^{M_i}\}_{i=1}^N$; treatment prioritization rule $S$; number of percentiles $K$; max budget $B_{\text{max}}$; estimators $\widehat{\phi}$ and $\widehat{\psi}$; Boolean flag indicating if cost is uniform
\STATE Set $\widehat{V}_0 = \widehat{\phi}(\pi_0\equiv 0)$ and $(\widehat{B}_0, \widehat{Q}_0)=(0,0)$
\STATE Let $S_{\text{sorted}}(i)$ be the score for the $i$th unit when sorted by $S$ in descending order
\FOR{$k\in [1,\dots, K]$}
    \STATE Set $R_B = S_{\text{sorted}}(i_k)$ where $i_k=\text{round}(\frac{k}{K} \cdot |D|$) and $|D|$ is the total number of units
    \IF{cost is uniform}
        \STATE Set $\widehat{B}_k = \frac{k}{K}\cdot B_{\text{max}}$
    \ELSE
        \STATE Set $\widehat{B}_k= \widehat{\psi}(\pi_{S,R_B})$
    \ENDIF
    \STATE Set $\widehat{Q}_k = \widehat{\phi}(\pi_{S,R_B}) - \widehat{V}_0$
\ENDFOR
\STATE \textbf{return} $\{\widehat{B}_k,\widehat{Q}_k\}_{k=0}^{K}$

\end{algorithmic}
\end{algorithm}

With the established identification results, we can now propose a general procedure for Qini curve estimation in our experimental study design. In practice, to estimate the Qini curve for a treatment prioritization rule $S$, one typically estimates the policy value and cost over a range of pre-specified thresholds $R$. For the uniform cost case, it is sufficient to only estimate the policy value. So far we assume ranking according to $S$ leads to no ties, but if there are ties one could add tiebreakers depending on their application, e.g., a small amount of random noise. 

The full procedure is shown in Algorithm~\ref{alg:qini_curve_estimation}. To implement this algorithm, we need strategies for estimating $\phi(\pi)$ and $\psi(\pi)$, which will be the focus of the coming section.


\section{Estimation strategies}\label{sec:estimators}

In this section we consider multiple strategies for Qini curve estimation.  In particular, we will focus on weighting estimators that use the propensity score. Since we assumed the propensity score to be known in our design, we avoid the need to model any other nuisance parameters. Throughout this section, due to the similarity of $\phi(\pi)$ and $\psi(\pi)$, we only present strategies for estimating $\phi(\pi)$ which analogously can be applied for estimating $\psi(\pi)$ as well.

\subsection{Cluster-level inverse probability weighting}
The simplest estimator for $\phi(\pi)$ in our setting is
\begin{equation*} \label{eq:ipw_estimator}
    \IPW(\pi) = \frac{1}{N} \sum_{i=1}^{N} \frac{\mathbf{1}\left(\mathbf{W}_i=\boldsymbol{\pi}_i \right)}{\prod_{j=1}^{M_i} e_{\pi_{ij}}\left(X_i\right)} Y_i
\end{equation*}
where $\mathbf{1}(\cdot)$ denotes the indicator function. This estimator is a natural extension of the traditional inverse probability weighting (IPW) estimator~\citep{robins1994estimation} to settings with clustered network interference, see e.g. ~\citet{tchetgen2012causal}. For this reason, we will refer to $\IPW(\pi)$ as the standard IPW estimator.  Although we can show that $\IPW(\pi)$ is an unbiased estimator under assumption~\ref*{asmp:identification_conditions}, its efficiency is poor which becomes evident from inspecting its sampling variance,
\begin{equation*}
    \begin{aligned}
        \V(\IPW(\pi)) &= \frac{1}{N^2} \sum_{i=1}^{N} \left\{ \E\left[ \omega(X_i) \left[Y_i(\boldsymbol{\pi}_i)\right]^2   \right] + \V\left( Y_{i}(\boldsymbol{\pi}_i) \right) \right\} \\
        \omega(X_i)  & = \left[\prod_{j=1}^{M_i} \left(\frac{e_{1}(X_i) e_{0}(X_i)}{e_{\pi_{ij}}\left(X_i\right)^2 } + 1 \right) - 1 \right]
    \end{aligned}
\end{equation*}
We derive the unbiasedness and variance of the standard IPW estimator in Appendix~\ref{app:derivation_IPW}. 

Since $e_{1}(X_i)\neq 0$ and $e_{0}(X_i)\neq 0$ due to assumption~\ref{asmp:identification_conditions}, the factor $\omega(X_i)$ increases exponentially with the cluster size $M_i$.  Consequently, its variance scales exponentially with the cluster size $M_i$ which makes it prohibitively difficult to use the standard IPW estimator for Qini curve estimation in scenarios where the cluster size $M_i$ is large. 

For this reason, we explore other weighting estimators that introduce additional conditions on the structure of the underlying interference. It is important to emphasize here that these additional conditions are not required for identification of the policy value $V(\pi)$, but invoked for more efficient estimation. As we will see, in the cases where these additional conditions do not hold, their respective estimators may introduce additional biases. This results in an inherent bias-variance trade-off for estimating Qini curves in the presence of interference.

\subsection{Interference under a fractional exposure mapping}
One strategy to deal with interference is by defining exposure mappings~\citep{aronow2017estimating}. An exposure mapping is a function $d_{ij} : \{0,1\}^{M_i} \rightarrow \mathcal{D}$ between all possible treatment configurations for unit $(i,j)$ and a representation (or, embedding) of the treatment configurations. In essence, we want to map similar treatment configurations to the same ``effective treatment''~\citep{manski2013identification}. If the space $\mathcal{D}$ has smaller cardinality than the original space $\{0,1\}^{M_i}$, which has cardinality $2^{M_i}$, we have the possibility for more efficient estimation.  Any exposure mapping, however, must fulfill the following~condition.

\begin{assumption}\label{asmp:fractional}
    The potential outcomes of a unit $(i,j)$ can be grouped by $d_{ij}$, meaning that $d_{ij}(\mathbf{w})=d_{ij}(\mathbf{w}')$ implies $Y_{ij}(\mathbf{w})=Y_{ij}(\mathbf{w}')$ for all $\mathbf{w}, \mathbf{w}'\in \{0,1\}^{M_i}$.
\end{assumption}


Here, we consider Qini curve estimation using one of the most common ways to define an exposure map. Namely, assuming that the potential outcome $Y_{ij}(\mathbf{w})$ for a unit $(i,j)$ is only a function of both its own treatment status $W_{ij}$ and the fraction of treated units within the same cluster~\citep{ugander2013graph,bajari2021multiple}.  This corresponds to the exposure mapping $d_{ij}(\mathbf{W}_i) = [W_{ij},  \overline{W}_i]$ where $\overline{W}_{i}=M_i^{-1}\sum_{j=1}^{M_i}W_{ij}$. 

Denoting the fraction of treated in cluster $i$ by policy $\pi$ as $\overline{\pi}_i=M_i^{-1}\sum_{j=1}^{M_i}\pi_{ij} $, we define the fractional IPW estimator as follows:
\begin{equation*} \label{eq:fracIPW}
    \fracIPW(\pi) = \frac{1}{N} \sum_{i=1}^{N} \sum_{j=1}^{M_i} \frac{\mathbf{1}\left(W_{ij} = \pi_{ij}, \overline{W}_{i} = \overline{\pi}_{i} \right)}{q_{ij}(\boldsymbol{\pi}_i, X_i)} Y_{ij}
\end{equation*}
where $q_{ij}(\boldsymbol{\pi}_i, X_i)=\Pr(W_{ij}=\pi_{ij}, \overline{W}_i=\overline{\pi}_i \mid X_i)$. As we show in Appendix~\ref{app:weight_fracIPW}, the probability $q_{ij}(\boldsymbol{\pi}_i, X_i)$ can be expressed in terms of the known propensity score.

The fractional IPW estimator $\fracIPW$ is an unbiased estimator for the policy value $V(\pi)$ under assumptions~\ref{asmp:identification_conditions} and~\ref{asmp:fractional} (see Appendix~\ref{app:proof_fracIPW} for the proof). Compared to the standard IPW estimator, its variance scales more favorably with the cluster size $M_i$ because the fractional exposure mapping reduces the cardinality of the treatment space from $2^{M_i}$ to $2 (M_i+1)$ per cluster. This reduction makes estimation more feasible in settings with large clusters.

However, this does not imply that the variance of $\fracIPW$ grows linearly with $M_i$. The estimator remains inversely proportional to the probability $q_{ij}(\boldsymbol{\pi}_i, X_i)$. As $M_i$ increases, the number of possible treatment fractions grows, making it less likely to observe a specific fraction. Consequently, $q_{ij}(\boldsymbol{\pi}_i, X_i)$ approaches zero as $M_i$ increases, which amplifies the variance, though at a slower rate than the standard IPW estimator.

\subsection{Interference under $\beta$-additive model}
Next, we consider another strategy that can reduce variance compared to the standard IPW estimator. Specifically, we use the following polynomial model to describe the interference, as proposed by \citet{zhang2023individualized}.
\begin{assumption}\label{asmp:additivity}
    The potential outcome model satisfies $\E[Y_{ij}(\mathbf{W}_i) \mid X_i] = \mathbf{g}_j(X_i)^\top \gamma(\mathbf{W}_i)$ where $\mathbf{g}_j(X_i) = [g_j^{(0)}, \dots, g_j^{(m)}]^\top$ is an unknown vector of functions $g_j^{(\cdot)} : \mathcal{X} \rightarrow \mathbb{R}$ that may vary across units in the same cluster. Furthermore, we have the an augmented treatment vector $\gamma(\mathbf{W}_i) = \big[ 1, \mathbf{W}_{i}, \mathbf{W}_{i}^{(2)}, \dots, \mathbf{W}_{i}^{(\beta)} \big]^\top$
    with $\mathbf{W}_{i}^{(k)}=\big\{ \prod_{m=1}^{k} W_{ij_m} \;\big|\; j_1 < \dots < j_k \big\}$ that contains interactions up to the order of $\beta$ between treatment of different units in the same cluster. Here, $\beta$ is upper bounded by the largest possible $M_i$.
\end{assumption}
This assumption states that each unit's conditional mean potential outcome is a linear function of the augmented treatment vector $\gamma(\mathbf{W}_i)$, which includes interaction terms up to order $\beta$ between treatments within the same cluster. For this reason, we refer to the above assumption as the $\beta$-additive assumption.

Denoting $\mathcal{I}_i^{\beta}$ as the power set of $\{1, \dots, M_i\}$ with cardinality at most $\beta$, we define the $\beta$-additive IPW estimator
\begin{equation*}
     \betaIPW(\pi; \beta) = \frac{1}{N} \sum_{i=1}^N \left[ \sum_{\mathcal{U}\in\mathcal{I}_i^{\beta}} \prod_{j\in\mathcal{U}} \left( \frac{\mathbf{1}(W_{ij}=\pi_{ij})}{e_{\pi_{ij}}(X_i)} - 1\right)\right] Y_i ~.
\end{equation*}
To use the estimator $\betaIPW(\pi; \beta)$, we must specify $\beta$. When this parameter is chosen to satisfy assumption~\ref{asmp:additivity} alongside assumption~\ref{asmp:identification_conditions}, \citet{zhang2023individualized} proved that $\betaIPW$ is an unbiased estimator for the policy value $V(\pi)$. 

The choice of $\beta$ dictates the strength of the $\beta$-additive assumption, which becomes less restrictive as $\beta$ increases. Setting $\beta=\max_i M_i$ imposes no additional constraints on the interference structure since, in this case, we have that $\betaIPW=\IPW$~\citep{zhang2023individualized}. Thus, from a practical point of view, the greatest variance reduction can be achieved by using a smaller $\beta$. 

To highlight the best variance reduction we can possibly achieve with the $\beta$-IPW estimator, we consider the special case of $\addIPW(\pi)=\betaIPW(\pi; \beta=1)$, which we refer to as the additive IPW estimator because there are no interactions between multiple treatments within the same cluster. For the additive IPW estimator, we can prove that its variance will scale quadratically with the cluster size, that is, $\V\left(\addIPW\right) \propto \max_i M_i^2$ (see Appendix~\ref{app:variance_addIPW} for proof). This is a notable improvement over the exponential scaling of the standard IPW estimator.


\subsection{Selecting the best estimation strategy: considerations from a bias-variance perspective}

We have three possible estimators to use: the standard IPW estimator, the fractional IPW estimator, and the $\beta$-IPW estimator. While the standard IPW estimator will suffer from high variance when cluster sizes $M_i$ increase, the other two estimators alleviate this issue under specific conditions on the interference. However, this variance reduction may come at the cost of bias if those conditions are violated. Effectively navigating this bias-variance trade-off will be important. Overemphasizing variance reduction may lead to misleading policy evaluations, while prioritizing unbiasedness may produce unstable estimates.

In the next section,  we empirically examine which estimation strategy performs best across different settings to provide insights on the bias-variance trade-offs.

\section{Experiments} \label{sec:experiments}

% Goal of simulation
We aim to evaluate the performance of our proposed strategies for estimating Qini curves under clustered network interference. To balance realistic structures of interference with the benefits of synthetic data, we designed a simulator that mimics a marketplace, common in e-commerce or marketing, where interference arises through cannibalization among product items sold by different vendors.
We present our simulator as a framework that can be reused for future research on the topic of interference. We provide all code for reproducing our simulations in the Github repository \href{https://github.com/bookingcom/uplift-interference-simulator}{github.com/bookingcom/uplift-interference-simulator}.

In our experiments, we compare five strategies for estimating Qini curves. First, we implement a naive strategy that ignores all interference, which we refer to as the naive estimator  (more details are provided in Appendix~\ref{app:estimation_no_interference}). Next, we implement the estimators discussed in this paper: the standard IPW estimator, the fractional IPW estimator and the $\beta$-IPW estimator with $\beta=1$ (additive IPW) or $\beta=2$.

\paragraph{Evaluation criteria} Our experiments focus on two key aspects of using Qini curves for decision-making. The first aspect is calibration: how accurately the estimates $\{\widehat{Q}_k\}_{k=0}^K$ reflect the ground truth values $\{Q_k\}_{k=0}^K$. We assess this using bias $K^{-1}\sum_{k=1}^K\E[\widehat{Q}_k - Q_k]$, variance $K^{-1}\sum_{k=1}^K\V(\widehat{Q}_k)$, and mean squared error $K^{-1}\sum_{k=1}^K\E[(\widehat{Q}_k - Q_k)^2]$. The second aspect is discrimination: the ability to determine which policy is better. For this, we rank policies based on the estimated area under the Qini curve (higher is better) and use Kendall rank correlation to measure how well each estimator ranks policies compared to the ground truth ranking. By default, we evaluate all methods on a noise-perturbed version of the optimal treatment prioritization rule, which uses oracle knowledge of the data-generating process, to simulate a policy between optimal and random. To simplify evaluation, we perform experiments in the uniform cost case. 

\subsection{Simulating an e-commerce marketplace with clustered network interference}
\label{sec:simulator}
In this section, we describe a data-generating process where clusters correspond to potential buyers searching for some item, while treatment units are the items shown. In this marketplace, the treatment of an item could correspond to e.g. discounts or promotions, and the outcome is whether the item was purchased by the buyer. Treatment effects manifest as an incremental change in the probability of a purchase to occur due to the treatment. Each buyer can make at most one purchase, causing cannibalization as treatments may shift purchases between items rather than increasing total purchases.

To construct the dataset, we first sample the covariates and treatment. Next, to introduce heterogeneous treatment effects, we compute an item attractiveness score matrix $\mathbf{A}$, where each element $A_{ij}\in[0,1]$ represents buyer  $i$'s interest in purchasing item $(i,j)$. The elements in $\mathbf{A}$ depend on the covariates and assigned treatment. Details on this sampling and computation are provided in Appendix~\ref{app:simulation_details}. For simplicity, we assume all buyers observe the same number of items, denoted by $M$.

Next, we sample the outcome $Y_{ij}$, which indicates if item $(i,j)$ is purchased, in two steps. First, we sample the binary outcome $Y_i$ for buyer $i$. If a purchase occurs for $i$, we sample which item the buyer purchased. We sample $Y_i$ according to the Bernoulli probability $\eta(\mathbf{A}_i) = P(Y_i=1\mid\mathbf{A}_i)$. The structure of the interference in this dataset is largely determined by the choice of $\eta$.

We consider three alternatives for $\eta$. The simplest is $\eta_{\text{max}}(\mathbf{A}_i) = \max_{j} A_{ij}$ where only the most attractive item contributes the probability of a purchase by buyer $i$. We refer to $\eta_{\text{max}}$ as the max function. Next, we consider the product function $\eta_{\text{product}}(\mathbf{A}_i) = 1 - \prod_{j=1}^{M} (1-A_{ij})$. This function assumes that items contribute independently to a purchase such that $P(Y_i=1)=1-P(Y_i=0)=1-\prod_{j=1}^MP(Y_{ij}=0)$. Lastly, the third function is inspired by position bias, commonly found in ranking systems used in e-commerce platforms \citep{joachims2005accurately}. We refer to this as the exponential decay function, defined as $\eta_{\text{exp-decay}}(\mathbf{A}_i) = \sum_{j=1}^{M} (\frac{1}{2})^{\text{rank}(A_{ij})}A_{ij}$, where $\text{rank}(\cdot)$ returns the rank of the attractiveness scores for buyer $i$ in descending order. Each successive item contributes half as much as the preceding one to the probability of a purchase by buyer $i$.

For the final step, if we sample $(Y_i=1)$, we determine which item $(i,j)$ is purchased. This is done by sampling according to the probabilities given by the softmax function $P(Y_{ij}=1\mid Y_i=1, \mathbf{A}_i )=\frac{e^{A_{ij}}}{\sum_{j=1}^{M} e^{A_{ij}}}$. 


\subsection{How does interference affect the estimation error?}
In the first experiment, we evaluated all estimation strategies under different interference structures by varying $\eta$ as described in the previous subsection. In addition, we fixed the number of buyers (i.e., clusters) while varying the number of items $M$ (i.e., units) as the spillover effects due to interference largely is expected to depend on the cluster size; when the cluster size equals one, there is no interference. 

We compared the bias and mean squared error (MSE) of each estimation strategy, as shown in Figure~\ref{fig:compare_dgp}. Starting with the bias, we observed that the naive estimator is significantly biased for all interference structures. The bias, which increased with number of items, was generally smaller for the fractional IPW and $\beta$-IPW estimators with $\beta=2$. Meanwhile, the standard IPW estimator appeared unbiased in all cases. In all cases, the $\beta$-IPW estimator with $\beta=2$ is observed to have lower bias than the variant with $\beta=1$ and, in some cases, for larger number of items (e.g., more than 10) the variant with $\beta=1$ had a similar or larger absolute bias as the naive estimator. 

By examining the Qini curves for a fixed number of items $M=11$, as in Figure~\ref{fig:qini_curve_qualitative}, we can obtain a qualitative assessment of the bias of each estimation strategy. Most notably, the naive estimator and $\beta$-IPW estimator with $\beta=1$ outputs significantly different Qini curves despite having a similar absolute bias. For the naive estimator, the Qini curves are biased for the higher percentages of treated, whereas the bias of the $\beta$-IPW estimator is more uniformly biased.

Lastly, in terms of MSE, the standard IPW and fractional IPW estimators performed worst, with MSE increasing exponentially with cluster size. In contrast, the $\beta$-IPW estimators performed the best.  In particular, for the product function, $\beta=1$ yielded the best MSE. The naive estimator performed the worst for small item counts but its increase in MSE appeared to slow down for larger number of items.

\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{figures/Bias_Meansquarederror-n_items-normalize_True-20250128_214348-20250128_094648-20250129_104524.pdf}
    \caption{Comparison of bias and mean squared error for each strategy under different interference structures. We let $N=100.000$ and $M=11$. Averages and standard errors are reported over 150 repetitions.}
    \label{fig:compare_dgp}
\end{figure}
\begin{figure}[t]
        \centering
    \includegraphics[width=\linewidth]{figures/qini_curves-normalize_True-20250128_214348-20250128_094648-20250129_104524-softmax_exp_decay-Figure1False.pdf}
    \caption{Qini curves of each estimation strategy with $N=100.000$ and $M=11$ using with the exponential decay function $\eta_{\text{exp-decay}}$. The average Qini curve and standard error are reported over 150 repetitions. The dashed black line corresponds to the true underlying Qini~curve.}
    \label{fig:qini_curve_qualitative}
\end{figure}


\subsection{Which estimation strategy is most efficient?}
In the next experiment, we evaluated the efficiency of each estimation strategy by reporting the variance as we varied the number the buyers $N$ (i.e., clusters) or items $M$ (i.e., units). While varying one, the other was kept fixed to $N=20.000$ and $K=11$. We present results only using $\eta_{\text{exp-decay}}$ as we observed no difference when changing this~function.

The results indicate that the most efficient estimators, ranked from lowest to highest variance, are: naive, $\beta$-IPW $(\beta=1)$, $\beta$-IPW $(\beta=2)$, fractional IPW, and standard IPW. The variance of the standard IPW and fractional IPW estimators appeared to increase exponentially with the number of buyers $K$, whereas the others scaled sub-exponentially. Full results are provided in Figure~\ref{fig:variance_scaling} in the appendix.

\subsection{How well can we rank policies under clustered network interference?}
In the final experiment, we evaluated each estimation strategy’s ability to rank policies based on the estimated area under the Qini curve. To do so, we degraded the optimal treatment prioritization rule by adding progressively larger noise, generating seven policies with decreasing performance. This experiment was repeated 200 times  with $N=20.000$ and $K=11$ for each $\eta$,  and we report the average Kendall rank correlation coefficient between each strategy’s ranking and the ground truth ranking.

The results, presented in Table~\ref{tab:kendall_tau_rank_correlation} in the appendix, show that $\beta$-IPW with $\beta=1$ performed best overall, achieving a correct ranking in all cases (rank correlation coefficient = 1). However, the other estimators also attained similar or only slightly lower rank correlations, except in the case of $\eta_{\text{product}}$ where the naive estimator, standard IPW, and fractional IPW had rank correlations between 0.80 and 0.85.

\section{Discussion}

Our findings indicate that, while clustered network interference can cause severe bias in Qini curve estimates, it is possible to get accurate estimates using different estimation strategies that take interference into account. However, the best estimation strategy will depend on several application-specific factors, including cluster size, the number of observations, and prior beliefs about interference and the intended use of the Qini curve.

For small cluster sizes (e.g., fewer than 5), the choice of estimation strategy had a limited impact on estimation error, as IPW, fractional IPW, and $\beta$-IPW all performed comparably in terms of bias and mean squared error. For larger cluster sizes, however, we observed a trade-off between using an unbiased, high-variance estimator and a possibly biased, low-variance estimator. For unbiased estimation, the standard IPW estimator is preferred as it relies only on the weakest conditions regarding the interference, though it requires a large number of observations to be reliable. When data is limited, unbiased estimation might still be feasible if strong domain expertise about the interference structure can justify the use of either the fractional IPW or the $\beta$-IPW estimator. However, if some bias is tolerated, then our results suggest that $\beta$-IPW is a strong choice, as it has the lowest variance among strategies that account for interference. Increasing $\beta$ seems to reduce bias at the cost of introducing more variance; a possibly interesting research direction is to investigate how to data-adaptively tune $\beta$ for this bias-variance trade-off by e.g. fitting a polynomial model based on the $\beta$-additive assumption.

The acceptable level of bias depends on the decision-making context. For model selection --i.e., discriminating between good and bad policies-- we observed the $\beta$-IPW estimator performing best. Interestingly, the naive estimator that ignores interference also ranked policies correctly in some cases, suggesting that interference-related bias may have a limited effect on this type of decision-making. However, if the goal is to determine a suitable threshold for a treatment prioritization rule, a well-calibrated Qini curve becomes more critical, making an estimator with low bias~preferable.

An additional consideration, which was not explored in this study, is estimating Qini curves under clustered network interference from observational data when the propensity score is unknown. One could replace the known propensity score with the estimated propensity score in all estimators that we discussed, potentially introducing other forms of biases. These may arise from model misspecification, which could be mitigated with doubly-robust estimators \citep{liu2019doubly}, or from unmeasured confounders, which could be addressed through sensitivity analysis \citep{vanderweele2015interference} to establish bounds under varying degrees of confounding. Future research should investigate these strategies in the context of Qini curve~estimation.

\section{Conclusion}
We have introduced a framework for estimating Qini curves in experimental study designs with clustered network interference, along with multiple estimation strategies. Our results demonstrate that properly accounting for interference leads to more accurate Qini curve estimation, though the best estimation strategy depends on the specific context. To guide practitioners, we provide practical recommendations based on both theoretical insights and empirical findings, helping them better assess the cost-effectiveness of treatment policies in complex settings with interference.

\section*{Acknowledgments} 
This work was primarily conducted during an internship of RKAK at Booking.com. We appreciate the feedback from discussions by colleagues and would like to thank Mathijs de Jong, Ilir Maçi, Alina Solovjova, and Antonio Castelli for their feedback which has greatly improved the quality of our work.


\bibliographystyle{abbrvnat}
\bibliography{references}


\newpage
\appendix

\section{Proofs and derivations}

\subsection{Proof of Theorem~\ref{thm:identification}} \label{app:identification}

\begin{proof}
    Under assumption~\ref{asmp:identification_conditions}, we can show that $\E[\phi(\pi)]=V(\pi)$ by rewriting the expectation as follows,
    \begin{align*}
        \E[\phi(\pi)] & = \E\left[\frac{1}{N} \sum_{i=1}^N \E[Y_{i} \mid \mathbf{W}=\boldsymbol{\pi}_i, X_{i}] \right] \\
        & = \frac{1}{N} N \E\left[\E\left[Y_{i} \mid \mathbf{W}=\boldsymbol{\pi}_i, X_{i}\right] \right] \\
        & = \E\left[\E\left[ \sum_{j=1}^{M_i}Y_{ij}(\boldsymbol{\pi}_i) \mid \mathbf{W}=\boldsymbol{\pi}_i, X_{i}\right] \right] \\
        & = \E\left[\E\left[ \sum_{j=1}^{M_i}  Y_{ij}(\boldsymbol{\pi}_i) \mid X_{i} \right] \right] \\
        & = \E\left[ \sum_{j=1}^{M_i}  Y_{ij}(\boldsymbol{\pi}_i)  \right] 
    \end{align*}
    where the second equality follows from linearity of expectations, the third equality from that we defined $Y_i=\sum_{j=1}^{M_i}Y_{ij}$ and then $Y_{ij}=Y_{ij}(\boldsymbol{\pi}_i)$ due to consistency in assumption~\ref{asmp:identification_conditions}, and finally the fourth equality from conditional exchangeability $Y_{ij}(\boldsymbol{\pi}_i)\indep \mathbf{W}_i\mid X_i$ in assumption~\ref{asmp:identification_conditions}.  We can prove analogously using the same arguments that $\E[\psi(\pi)]=C(\pi)$.
\end{proof}



\subsection{Proof of unbiasedness and variance for IPW estimator}
\label{app:derivation_IPW}

\begin{proof}

    The unbiasedness of $\IPW(\pi)$ follows from the same arguments as deriving the inverse probability weighting estimator in settings with no interference~\citep{hernan2020causal}. 
    We can show that
    \begin{align*}
        \E\left[\IPW(\pi)\right] & =  \E\left[\frac{1}{N}\sum_{i=1}^{N}\frac{\mathbf{1}\left(\mathbf{W}_i=\boldsymbol{\pi}_i \right)}{\prod_{j=1}^{M_i} e_{\pi_{ij}}\left(X_i\right)} Y_i\right] \\
        & = \E\left[\frac{1}{N} \sum_{i=1}^{N}\frac{\mathbf{1}(\mathbf{W}_i =\boldsymbol{\pi}_i)}{\Pr(\mathbf{W}_i =\boldsymbol{\pi}_i \mid X_i)} Y_i\right] \\ 
        & = \E\left[\frac{1}{N} \sum_{i=1}^{N} \E\left[\frac{\mathbf{1}(\mathbf{W}_i =\boldsymbol{\pi}_i)}{\Pr(\mathbf{W}_i =\boldsymbol{\pi}_i \mid X_i)} Y_i\mid X_i \right]\right] \\
        & = \E\left[\frac{1}{N} \sum_{i=1}^{N} \E\left[ Y_i\mid \mathbf{W}_i=\boldsymbol{\pi}_i, X_i \right]\right] \\
        & = \E\left[\phi(\pi)\right]
    \end{align*}
    The second equality follows from the independent treatment assignments where
    \begin{equation*}
        \Pr(\mathbf{W}_i =\boldsymbol{\pi}_i \mid X_i)=\prod_{j=1}^{M_i} \Pr(W_{ij}=\pi_{ij}\mid X_i) = \prod_{j=1}^{M_i} e_{\pi_{ij}}\left(X_i\right),
    \end{equation*}
    The unbiasedness of $\IPW(\pi)$ then follows from $\E\left[\phi(\pi)\right]=\V(\pi)$ according to lemma~\ref{thm:identification}. 
        
    Next, we derive the expression for $\V\left(\IPW(\pi)\right)$. Due to independence of clusters, we first note that
    \begin{align*}
        \V\left(\IPW(\pi)\right) = \V\left(\frac{1}{N}\sum_{i=1}^{N}\frac{\mathbf{1}\left(\mathbf{W}_i=\boldsymbol{\pi}_i \right)}{\prod_{j=1}^{M_i} e_{\pi_{ij}}\left(X_i\right)} Y_i \right) = \frac{1}{N^2} \sum_{i=1}^N \V\left( \frac{\mathbf{1}\left(\mathbf{W}_i=\boldsymbol{\pi}_i \right)}{\prod_{j=1}^{M_i} e_{\pi_{ij}}\left(X_i\right)} Y_i \right)~.
    \end{align*}
    By using the law of total variance, we can rewrite 
    \begin{align*}
        \V\left( \frac{\mathbf{1}\left(\mathbf{W}_i=\boldsymbol{\pi}_i \right)}{\prod_{j=1}^{M_i} e_{\pi_{ij}}\left(X_i\right)} Y_i \right) = \E\left[\underbrace{\V\left( \frac{\mathbf{1}\left(\mathbf{W}_i=\boldsymbol{\pi}_i \right)}{\prod_{j=1}^{M_i} e_{\pi_{ij}}\left(X_i\right)} Y_i \mid Y_i(\boldsymbol{\pi}_i), X_i \right)}_{(a)} \right] + \V\left(\underbrace{\E\left[\frac{\mathbf{1}\left(\mathbf{W}_i=\boldsymbol{\pi}_i \right)}{\prod_{j=1}^{M_i} e_{\pi_{ij}}\left(X_i\right)} Y_i \mid Y_i(\boldsymbol{\pi}_i), X_i \right]}_{(b)} \right)~.
    \end{align*}
    Inspecting $(b)$ first, we note that
    \begin{align*}
    (b) & =\E\left[\frac{\mathbf{1}\left(\mathbf{W}_i=\boldsymbol{\pi}_i \right)}{\prod_{j=1}^{M_i} e_{\pi_{ij}}\left(X_i\right)} Y_i(\boldsymbol{\pi}_i) \mid Y_i(\boldsymbol{\pi}_i), X_i \right] \\
    & = Y_i(\boldsymbol{\pi}_i) \E\left[\frac{\mathbf{1}\left(\mathbf{W}_i=\boldsymbol{\pi}_i \right)}{\prod_{j=1}^{M_i} e_{\pi_{ij}}\left(X_i\right)} \mid Y_i(\boldsymbol{\pi}_i), X_i \right] \\
    & = Y_i(\boldsymbol{\pi}_i)~.
    \end{align*}
    where it follows from conditional exchangeability in assumption~\ref{asmp:identification_conditions} that $\E\left[\frac{\mathbf{1}\left(\mathbf{W}_i=\boldsymbol{\pi}_i \right)}{\prod_{j=1}^{M_i} e_{\pi_{ij}}\left(X_i\right)} \mid Y_i(\boldsymbol{\pi}_i), X_i \right]=\E\left[\frac{\mathbf{1}\left(\mathbf{W}_i=\boldsymbol{\pi}_i \right)}{\prod_{j=1}^{M_i} e_{\pi_{ij}}\left(X_i\right)} \mid X_i \right]=1$.

    Similarly, we can show that
    \begin{align*}
        (a) & = \V\left( \frac{\mathbf{1}\left(\mathbf{W}_i=\boldsymbol{\pi}_i \right)}{\prod_{j=1}^{M_i} e_{\pi_{ij}}\left(X_i\right)} Y_i(\boldsymbol{\pi}_i) \mid Y_i(\boldsymbol{\pi}_i), X_i \right) \\ 
        & = \left[\frac{Y_i(\boldsymbol{\pi}_i)}{ \prod_{j=1}^{M_i} e_{\pi_{ij}}\left(X_i\right) }\right]^2 \V\left( \mathbf{1}(\mathbf{W}_i=\boldsymbol{\pi}_i) \mid Y_i(\boldsymbol{\pi}_i), X_i \right) \\
        & = \left[\frac{Y_i(\boldsymbol{\pi}_i)}{ \prod_{j=1}^{M_i} e_{\pi_{ij}}\left(X_i\right) }\right]^2 \V\left( \mathbf{1}(\mathbf{W}_i=\boldsymbol{\pi}_i) \mid X_i \right)
    \end{align*}
    where the last equality follows from conditional exchangeability again. Next, using that treatment assignments are independent, we can further rewrite
    \begin{align*}
        \V\left( \mathbf{1}(\mathbf{W}_i=\boldsymbol{\pi}_i) \mid X_i \right) & =  \V\left( \prod_{j=1}^{M_i} \mathbf{1}(W_{ij}=\pi_{ij}) \mid X_i \right) \\
        &= \prod_{j=1}^{M_i}\left\{ \V\left( \mathbf{1}(W_{ij}=\pi_{ij}) \mid X_i\right) + \E\left[ \mathbf{1}(W_{ij}=\pi_{ij}) \mid X_i\right]^2 \right\} - \prod_{j=1}^{M_i} \E\left[\mathbf{1}(W_{ij}=\pi_{ij}) \mid X_i\right]^2 \\
        & = \prod_{j=1}^{M_i} \left\{e_{1}(X_i) e_{0}(X_i) + e_{\pi_{ij}}(X_i)^2 \right\} - \prod_{j=1}^{M_i} e_{\pi_{ij}}(X_i)^2 
    \end{align*}
    Plugging the above expression back into $(a)$, we get
    \begin{align*}
        (a) &= \left[\frac{Y_i(\boldsymbol{\pi}_i)}{ \prod_{j=1}^{M_i} e_{\pi_{ij}}\left(X_i\right) }\right]^2 \left[ \prod_{j=1}^{M_i} \left\{e_{1}(X_i) e_{0}(X_i) + e_{\pi_{ij}}(X_i)^2 \right\} - \prod_{j=1}^{M_i} e_{\pi_{ij}}(X_i)^2  \right] \\
        & = \left[Y_i(\boldsymbol{\pi}_i)\right]^2 \left[\prod_{j=1}^{M_i} \left\{\frac{e_{1}(X_i) e_{0}(X_i)}{e_{\pi_{ij}}\left(X_i\right)^2 } + 1 \right\} - 1 \right]
    \end{align*}
    At last, plugging our expression of $(a)$ and $(b)$ back into where we started, we obtain the final expression for the variance of the standard IPW estimator,
    \begin{equation*}
        \V\left(\IPW(\pi)\right) = \frac{1}{N^2} \sum_{i=1}^{M_i} \left\{ \E\left[ \left[Y_i(\boldsymbol{\pi}_i)\right]^2 \left[\prod_{j=1}^{M_i} \left(\frac{e_{1}(X_i) e_{0}(X_i)}{e_{\pi_{ij}}\left(X_i\right)^2 } + 1 \right) - 1 \right]  \right] + \V\left( Y_{i}(\boldsymbol{\pi}_i) \right) \right\}
    \end{equation*}
\end{proof}

\subsection{Expressing $q_{ij}$ in terms of the propensity score} \label{app:weight_fracIPW}
We have 
\begin{align*}
    q_{ij}(\boldsymbol{\pi}_i, X_i) & = \Pr(W_{ij}=\pi_{ij}, \overline{W}_i=\overline{\pi}_i \mid X_i) \\
    & = \Pr(W_{ij}=\pi_{ij} \mid \overline{W}_i=\overline{\pi}_i X_i) \Pr(\overline{W}_i=\overline{\pi}_i \mid X_i)~.
\end{align*}
As the propensity score $e_{w}(X_i)=\Pr(W_{ij}=w\mid X_i)$ is the same for every $j=1,\dots, M_i$, we have that all units in a cluster have the same probability of being treated. Therefore, once conditioning on the fraction $\overline{W}_i$ of treated in a cluster, the fraction equals to the probability that a unit has been treated in that cluster. We can thus write
\begin{equation*}
    \Pr(W_{ij}=\pi_{ij} \mid \overline{W}_i=\overline{\pi}_i X_i) = \pi_{ij}\cdot \overline{\pi}_i + (1-\pi_{ij})\cdot (1-\overline{\pi}_i)~.
\end{equation*}
Next, for the second probability $\Pr(\overline{W}_i=\overline{\pi}_i \mid X_i)$, we note that $\overline{W}_i = M_i^{-1} \sum_{j=1}^{M_i} W_{ij}$ can be seen a Binomial random variables scaled by $M_i^{-1}$. This means $M_i^{-1}\sum_{j=1}^{M_i} W_{ij} \sim \text{B}(M_i, e_{1}(X_i))$ and thus we have
\begin{equation*}
    \Pr(\overline{W}_i=\overline{\pi}_i \mid X_i) = \binom{M_i}{\overline{\pi}_i \cdot M_i} [e_1(X_i)]^{\overline{\pi}_i \cdot M_i} [1-e_1(X_i)]^{(1-\boldsymbol{\pi}_i)\cdot M_i}~.
\end{equation*}
Combining both expressions from above, we get
\begin{align*}
q_{ij}(\pi_{i}, X_i) =\left[\pi_{ij}\cdot \overline{\pi}_i + (1-\pi_{ij})\cdot (1-\overline{\pi}_i)\right] \times \binom{M_i}{\overline{\pi}_i \cdot M_i} [e_1(X_i)]^{\overline{\pi}_i \cdot M_i} [e_0(X_i)]^{(1-\overline{\pi}_i)\cdot M_i}~.
\end{align*}

\subsection{Proof of unbiasedness of fractional IPW estimator}
\label{app:proof_fracIPW}
\begin{proof}
    We can show that
    \begin{align*}
        \E\left[\fracIPW\right]& =\E\left[\frac{1}{N}\sum_{i=1}^N\sum_{j=1}^{M_i} \frac{1(W_{ij}=\pi_{ij}, \overline{W}_i=\overline{\pi}_i)}{q_{ij}(\boldsymbol{\pi}_i, X_i)}Y_{ij} \right]  \\
        & = \frac{1}{N}\sum_{i=1}^N \E\left[ \E\left[ \sum_{j=1}^{M_i} \frac{1(W_{ij}=\pi_{ij}, \overline{W}_i=\overline{\pi}_i)}{q_{ij}(\boldsymbol{\pi}_i, X_i)}Y_{ij} \mid X_i \right] \right]\\
        & = \frac{1}{N}\sum_{i=1}^N \E\left[ \E\left[ \sum_{j=1}^{M_i} Y_{ij} \mid d_{ij}(\mathbf{W}_i) = [\pi_{ij}, \overline{\pi}_i], X_i \right] \right] \\
        & = \frac{1}{N}\sum_{i=1}^N \E\left[ \E\left[ \sum_{j=1}^{M_i} Y_{ij}(\mathbf{W}_i) \mid d_{ij}(\mathbf{W}_i) = [\pi_{ij}, \overline{\pi}_i], X_i \right] \right] \\
        & = \frac{1}{N}\sum_{i=1}^N \E\left[ \E\left[ \sum_{j=1}^{M_i} Y_{ij}(\mathbf{W}_i) \mid X_i \right] \right] \\
        & = \frac{1}{N}\sum_{i=1}^N \E\left[ \sum_{j=1}^{M_i} Y_{ij}(\mathbf{W}_i)  \right] \\
        & = \frac{1}{N}\sum_{i=1}^N V(\pi) = V(\pi)
    \end{align*}
    where the second equality follows from linearity of expectations and law of iterated expectations, the fourth equality follows consistency in assumption~\ref{asmp:identification_conditions} and that the exposure mapping fulfills  assumption~\ref{asmp:fractional}, and finally the fifth equality from conditional exchangeability in assumption~\ref{asmp:identification_conditions} because $Y_{ij}(\mathbf{w}) \indep \mathbf{W_i} \mid X_i \Rightarrow Y_{ij}(\mathbf{w}) \indep d(\mathbf{W_i}) \mid X_i$ for all $\mathbf{w}\in\{0,1\}^{M_i}$.
\end{proof}


\subsection{Variance of additive IPW estimator} \label{app:variance_addIPW}

We have defined $\addIPW(\pi) = \betaIPW(\pi;\beta=1)$ which has a simpler form
\begin{align*}
    \addIPW(\pi) = \frac{1}{N}\sum_{i=1}^N \left\{ \sum_{j=1}^{M_i} \frac{\mathbf{1}(W_{ij}=\pi_{ij})}{e_1(X_i)} - (M_i -1) \right\} Y_i~.
\end{align*}
As clusters are independent, we can write $\V\left(\addIPW \right) = \frac{1}{N^2}\sum_{i=1}^N \V\left(\left\{ \sum_{j=1}^{M_i} \frac{\mathbf{1}(W_{ij}=\pi_{ij})}{e_1(X_i)} - (M_i -1) \right\} Y_i \right)$ where the variance terms inside the sum can be decomposed as
\begin{align*}
    \underbrace{\E\left[\left(\left\{ \sum_{j=1}^{M_i} \frac{\mathbf{1}(W_{ij}=\pi_{ij})}{e_1(X_i)} - (M_i -1) \right\} Y_i\right)^2\right]}_{(a)} - \underbrace{\E\left[\left\{ \sum_{j=1}^{M_i} \frac{\mathbf{1}(W_{ij}=\pi_{ij})}{e_1(X_i)} - (M_i -1) \right\} Y_i\right]^2 }_{(b)}~.
\end{align*}
When $\addIPW$ is an unbiased estimator, we have that $(b)=V(\pi)^2$. For $(a)$, we note that the sum $\sum_{j=1}^{M_i} \frac{\mathbf{1}(W_{ij}=\pi_{ij})}{e_1(X_i)}$ is linear with respect to $M_i$.  Thus, inspecting the full expression for the variance,
\begin{equation*}
    \V\left(\addIPW\right) = \frac{1}{N^2} \sum_{i=1}^N\left(\E\left[\left\{ \sum_{j=1}^{M_i} \frac{\mathbf{1}(W_{ij}=\pi_{ij})}{e_1(X_i)} - (M_i -1) \right\}^2 Y_i^2 \right]\right) - V(\pi)^2~,
\end{equation*}
we can see that the variance will scale quadratically with $M_i$.


\section{Estimating Qini curves in settings with no interference} \label{app:estimation_no_interference}
We assume the following statement which is equivalent to assuming no interference.
\begin{assumption}\label{asmp:no_interference}
    We assume that $Y_{ij}(\mathbf{w})=Y_{ij}(\mathbf{w}')$ if and only if $w_{ij}=w_{ij}'$ for all $\mathbf{w}, \mathbf{w}'\in \{0,1\}^{M_i}$.
\end{assumption}
Note that the above assumption is a special case of assumption~\ref{asmp:fractional} with the exposure mapping $d_{ij}(\mathbf{W}_i)=W_{ij}$.

We consider the simplest approach in the absence of interference for estimating Qini curves between any units. Consider the estimators based on inverse probability weighting,
\begin{align*}
    \widehat{\phi}^{\text{no-interference}}(\pi) = \frac{1}{N} \sum_{i=1}^N \sum_{i=1}^{M_i} \frac{\mathbf{1}(W_{ij}=\pi_{ij})}{e_{\pi_{ij}}(X_i)} Y_{ij} \;\;\text{and}\;\;
    \widehat{\psi}^{\text{no-interference}}(\pi) = \frac{1}{N} \sum_{i=1}^N \sum_{i=1}^{M_i} \frac{\mathbf{1}(W_{ij}=\pi_{ij})}{e_{\pi_{ij}}(X_i)} C_{ij}~.
\end{align*}
We can show that under assumption~\ref{asmp:identification_conditions} and~\ref{asmp:no_interference}, the above estimators are unbiased estimators for the policy value $V(\pi)$ and $C(\pi)$, respectively. Namely, we can show this with the same proof as in Appendix~\ref{app:proof_fracIPW}, but replacing $d_{ij}(\mathbf{W_i})=[W_{ij}, \overline{W}_i]$ with $d_{ij}(\mathbf{W_i})=W_{ij}$.


\section{Experimental details} \label{app:experiments}


\subsection{Simulating marketplace dataset} \label{app:simulation_details}

We sample the covariates and treatment as follows: For each buyer $i=1,\dots,N$, we sample covariates $X_i\sim \text{U}([0,1]^{12})$. Then, for each item $j=1,\dots, M$ we sample covariates $Z_{ij}\sim \text{U}([0,1]^{11})$ and we randomize the treatment assignment by sampling $W_{ij}\sim \text{Bern}(0.5)$. Here, $M$ is the same for all buyers.  Since we consider the uniform cost case, we need not sample cost of treatment since they are assumed to be the same each for item.

Next, to introduce heterogeneous treatment effects, we compute an item attractiveness score matrix $\mathbf{A}$ where element $A_{ij}$ relates buyer $i$'s interest in purchasing item $j$. This matrix depends on both the covariates and treatment as follows $A_{ij}=\delta_{ij}\cdot(A_{ij}^{(0)} + W_{ij} \cdot A_{ij}^{(1)})$, where $A_{ij}^{(w)}=X_i^\top \Omega_w Z_{ij}$ with $\Omega_w \sim \text{U}([0,1]^{12\times 11})$ for $w\in\{0,1\}$. The variable $d_{ij}\sim\text{Bern}(0.5)$ randomly masks some elements in $A_{ij}^{(1)}$ to zero; this emulates that some items will not respond at all to a treatment. Here,  $A_{ij}$ typically lies in the range $[0,1]$, but if necessary we clip it to this range so that we later could interpret it as a probability. 

\subsection{Details on experiment shown in Figure~1} 

We simulate a dataset with $N=20.000$ buyers (i.e., clusters) and $K=3$ items (i.e., units)  per buyer with the exponential decay function. We estimate the Qini curve for a fixed treatment prioritization rule using the naive estimator and the IPW estimator. This was repeated 200 times and we plotted the average Qini curve.

\subsection{Additional experimental results} \label{app:additional_results}

In this section, we include additional experimental results, see Figure~\ref{fig:variance_scaling} and Table~\ref{tab:kendall_tau_rank_correlation} to support our conclusions in Section~\ref{sec:experiments} in the main paper.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.7\linewidth]{figures/variance-normalize_True-20250126_171100-20250127_172025-20250128_214409-20250129_104511.pdf}
    \caption{Comparing variance of each estimation strategy as we vary the number the buyers $N$ (i.e., clusters) or items $M$ (i.e., units) with $\eta_{\text{exp-decay}}$. While varying one, the other is kept fixed to either $N=20.000$ or $K=11$. The variance is reported over 200 repetitions.}
    \label{fig:variance_scaling}
\end{figure}

\begin{table}[ht]
    \centering
    \caption{Comparison of ability to rank policies by each estimation strategy. We used $N=20.000$ number of buyers (i.e., clusters) and $K=11$ items (i.e., units) per buyer. We report the average Kendall rank correlation with respect to the ground truth ranking over 200 repetitions. Higher is better, where 1 corresponds to a perfect rank correlation.}
    \label{tab:kendall_tau_rank_correlation}
    \begin{tabular}{lrrr}
        \toprule
         & Max & Product & Exponential decay \\
        Estimation strategy &  &  &  \\
        \midrule
        Naive (ignore interference) & 1.000 & 0.808 & 1.000 \\
        Standard IPW & 0.928 & 0.845 & 0.945 \\
        Fractional IPW & 0.991 & 0.806 & 0.995 \\
        $\beta$-IPW ($\beta=1$) & 1.000 & 1.000 & 1.000 \\
        $\beta$-IPW ($\beta=2$) & 1.000 & 0.995 & 1.000 \\
        \bottomrule
    \end{tabular}
\end{table}





\end{document}
