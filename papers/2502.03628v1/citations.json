[
  {
    "index": 0,
    "papers": [
      {
        "key": "bai2024hallucination",
        "author": "Bai, Zechen and Wang, Pichao and Xiao, Tianjun and He, Tong and Han, Zongbo and Zhang, Zheng and Shou, Mike Zheng",
        "title": "Hallucination of multimodal large language models: A survey"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "tong2024eyes",
        "author": "Tong, Shengbang and Liu, Zhuang and Zhai, Yuexiang and Ma, Yi and LeCun, Yann and Xie, Saining",
        "title": "Eyes wide shut? exploring the visual shortcomings of multimodal llms"
      },
      {
        "key": "liu2024llavanext",
        "author": "Liu, Haotian and Li, Chunyuan and Li, Yuheng and Li, Bo and Zhang, Yuanhan and Shen, Sheng and Lee, Yong Jae",
        "title": "LLaVA-NeXT: Improved reasoning, OCR, and world knowledge"
      },
      {
        "key": "shi2024eagle",
        "author": "Shi, Min and Liu, Fuxiao and Wang, Shihao and Liao, Shijia and Radhakrishnan, Subhashree and Huang, De-An and Yin, Hongxu and Sapra, Karan and Yacoob, Yaser and Shi, Humphrey and others",
        "title": "Eagle: Exploring the design space for multimodal llms with mixture of encoders"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "li-etal-2023-evaluating",
        "author": "Li, Yifan  and\nDu, Yifan  and\nZhou, Kun  and\nWang, Jinpeng  and\nZhao, Xin  and\nWen, Ji-Rong",
        "title": "Evaluating Object Hallucination in Large Vision-Language Models"
      },
      {
        "key": "zhou2023analyzing",
        "author": "Zhou, Yiyang and Cui, Chenhang and Yoon, Jaehong and Zhang, Linjun and Deng, Zhun and Finn, Chelsea and Bansal, Mohit and Yao, Huaxiu",
        "title": "Analyzing and mitigating object hallucination in large vision-language models"
      },
      {
        "key": "vcd",
        "author": "Leng, Sicong and Zhang, Hang and Chen, Guanzheng and Li, Xin and Lu, Shijian and Miao, Chunyan and Bing, Lidong",
        "title": "Mitigating object hallucinations in large vision-language models through visual contrastive decoding"
      },
      {
        "key": "opera",
        "author": "Huang, Qidong and Dong, Xiaoyi and Zhang, Pan and Wang, Bin and He, Conghui and Wang, Jiaqi and Lin, Dahua and Zhang, Weiming and Yu, Nenghai",
        "title": "Opera: Alleviating hallucination in multi-modal large language models via over-trust penalty and retrospection-allocation"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "liu2023mitigating",
        "author": "Liu, Fuxiao and Lin, Kevin and Li, Linjie and Wang, Jianfeng and Yacoob, Yaser and Wang, Lijuan",
        "title": "Mitigating hallucination in large multi-modal models via robust instruction tuning"
      },
      {
        "key": "yu2024hallucidoctor",
        "author": "Yu, Qifan and Li, Juncheng and Wei, Longhui and Pang, Liang and Ye, Wentao and Qin, Bosheng and Tang, Siliang and Tian, Qi and Zhuang, Yueting",
        "title": "Hallucidoctor: Mitigating hallucinatory toxicity in visual instruction data"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "yue2024less",
        "author": "Yue, Zihao and Zhang, Liang and Jin, Qin",
        "title": "Less is more: Mitigating multimodal hallucination from an eos decision perspective"
      },
      {
        "key": "jiang2024hallucination",
        "author": "Jiang, Chaoya and Xu, Haiyang and Dong, Mengfan and Chen, Jiaxing and Ye, Wei and Yan, Ming and Ye, Qinghao and Zhang, Ji and Huang, Fei and Zhang, Shikun",
        "title": "Hallucination augmented contrastive learning for multimodal large language model"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "yin2023woodpecker",
        "author": "Yin, Shukang and Fu, Chaoyou and Zhao, Sirui and Xu, Tong and Wang, Hao and Sui, Dianbo and Shen, Yunhang and Li, Ke and Sun, Xing and Chen, Enhong",
        "title": "Woodpecker: Hallucination correction for multimodal large language models"
      },
      {
        "key": "zhou2023analyzing",
        "author": "Zhou, Yiyang and Cui, Chenhang and Yoon, Jaehong and Zhang, Linjun and Deng, Zhun and Finn, Chelsea and Bansal, Mohit and Yao, Huaxiu",
        "title": "Analyzing and mitigating object hallucination in large vision-language models"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "chen2024halc",
        "author": "Chen, Zhaorun and Zhao, Zhuokai and Luo, Hongyin and Yao, Huaxiu and Li, Bo and Zhou, Jiawei",
        "title": "Halc: Object hallucination reduction via adaptive focal-contrast decoding"
      },
      {
        "key": "sun2023aligning",
        "author": "Sun, Zhiqing and Shen, Sheng and Cao, Shengcao and Liu, Haotian and Li, Chunyuan and Shen, Yikang and Gan, Chuang and Gui, Liang-Yan and Wang, Yu-Xiong and Yang, Yiming and others",
        "title": "Aligning large multimodal models with factually augmented rlhf"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "vcd",
        "author": "Leng, Sicong and Zhang, Hang and Chen, Guanzheng and Li, Xin and Lu, Shijian and Miao, Chunyan and Bing, Lidong",
        "title": "Mitigating object hallucinations in large vision-language models through visual contrastive decoding"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "pai",
        "author": "Liu, Shi and Zheng, Kecheng and Chen, Wei",
        "title": "Paying more attention to image: A training-free method for alleviating hallucination in lvlms"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "pai",
        "author": "Liu, Shi and Zheng, Kecheng and Chen, Wei",
        "title": "Paying more attention to image: A training-free method for alleviating hallucination in lvlms"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "li2022contrastive",
        "author": "Li, Xiang Lisa and Holtzman, Ari and Fried, Daniel and Liang, Percy and Eisner, Jason and Hashimoto, Tatsunori and Zettlemoyer, Luke and Lewis, Mike",
        "title": "Contrastive decoding: Open-ended text generation as optimization"
      },
      {
        "key": "shi2023trusting",
        "author": "Shi, Weijia and Han, Xiaochuang and Lewis, Mike and Tsvetkov, Yulia and Zettlemoyer, Luke and Yih, Scott Wen-tau",
        "title": "Trusting your evidence: Hallucinate less with context-aware decoding"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "vcd",
        "author": "Leng, Sicong and Zhang, Hang and Chen, Guanzheng and Li, Xin and Lu, Shijian and Miao, Chunyan and Bing, Lidong",
        "title": "Mitigating object hallucinations in large vision-language models through visual contrastive decoding"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "dola",
        "author": "Yung-Sung Chuang and Yujia Xie and Hongyin Luo and Yoon Kim and James R. Glass and Pengcheng He",
        "title": "DoLa: Decoding by Contrasting Layers Improves Factuality in Large Language Models"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "favero2024multi",
        "author": "Favero, Alessandro and Zancato, Luca and Trager, Matthew and Choudhary, Siddharth and Perera, Pramuditha and Achille, Alessandro and Swaminathan, Ashwin and Soatto, Stefano",
        "title": "Multi-modal hallucination control by visual information grounding"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "woo2024don",
        "author": "Woo, Sangmin and Kim, Donguk and Jang, Jaehyuk and Choi, Yubin and Kim, Changick",
        "title": "Don't Miss the Forest for the Trees: Attentional Vision Calibration for Large Vision Language Models"
      }
    ]
  }
]