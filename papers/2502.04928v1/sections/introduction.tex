\section{Introduction}
Optimization problems are ubiquitous in industrial applications. Reducing costs, increasing efficiency and streamlining production are areas of research for our industries. In particular, resource and production allocation problems are widely used to address these topics. In an industry setting they are usually very complicated  and involve a large number of variables. Many of such production problems can be modeled as some variant of the knapsack problems, which is a well-studied combinatorial problem in the literature \cite{10.5555/98124}. The problem consists in assigning a number of objects to a number of knapsacks. Each object has a value and a weight and each knapsack has a maximum weight it can carry. The assignment must be done in such a way as to maximize the value carried by the knapsacks while respecting their capacities and assigning every object to a knapsack. In this paper, we are concerned with problems of this type.

As production processes grow in complexity, new optimization paradigms are needed. Quantum computing is a promising avenue for development new optimization algorithms. One class of algorithms that are proposed are quantum approximate optimization algorithms (QAOA) \cite{farhi2014quantum}. Currently there are claims in the literature for improved scaling performance with QAOA  and its variants \cite{doi:10.1126/sciadv.adm6761}, \cite{montanaro2024quantumspeedupssolvingnearsymmetric} but so far no robust practical advantage over classical methods has been shown. 
Grover's algorithm \cite{Grover_1996} is another method that is proposed to give a scaling advantage for larger optimization problems, however this is also the subject of discussion \cite{PhysRevX.14.041029}.   

In the noisy intermediate-scale quantum (NISQ) era of quantum computing \cite{preskill2018}, the quantum hardware is not ready to deal with problems of even moderate sizes. Nonetheless, quantum mechanics has aided in development of several fully classical algorithms, which are popularly known as quantum-inspired algorithms. Such algorithms are, for example, applied to fluid dynamics simulations \cite{Gourianov2022} and signal processing \cite{PRXQuantum.4.040318}.

In the classical realm, evolutionary strategies are popular gradient-free optimization methods. They rely on heuristic assumptions of the about the correlations among possible solutions of the optimization problem. An example of this is the CMA-ES heuristic \cite{hansen2019pycma}, which models the correlations of perspective solutions as Gaussian via their covariance matrix. This is an example where a Gaussian generative model, in which its mean and covariance are updated after every iteration, is used to generate candidate solutions for an optimization problem. 

Recently, a new type of heuristic algorithm has been proposed for black-box optimization: the generative-enhanced optimization algorithm (GEO) \cite{Alcazar2024, batsheva2023}. The idea is to train a generative model which learns the correlations and the structure among the optimization variables so that it is possible to generate or sample new possible solutions which may lead to lower costs of the underlying optimization problem. The generative model used can be classical, e.g., a variational autoencoder (VAE) \cite{cinelli2021variational}, a generative adversarial network (GAN) \cite{goodfellow_generative_2014}, or quantum, e.g., a variational quantum circuit (VQC) \cite{vqa}. However, quantum generative models will suffer from the same scalability issues approaches as QAOA when implemented in current quantum hardware.

An interesting instance of quantum-inspired methods is the tensor network (TN) model because it provides a tunable description of systems from classical to fully quantum models. In fact, they are commonly used in many-body physics to approximate ground states \cite{Or√∫s2019}. Recently, TNs have also found applications outside of describing many-body states. For example, TNs can be used to hierarchically discretize or parametrize a function which solves a partial differential equation relevant for fluid dynamics applications \cite{Gourianov2022}. Moreover, TN architectures have been used in machine learning as classifiers for images \cite{Guala2023} and to compress classical data \cite{jobst2023efficient} for usage in quantum computers. Due to their versatility, TNs are even used to compress large language models (LLMs) \cite{tomut2024compactifai}. 

Along these lines, \cite{PhysRevX.8.031012} has proposed TNs as generators for generative models capable of learning the popular MNIST dataset. Training of such models can be done by adapting well-known density matrix renormalization group (DMRG) techniques \cite{RevModPhys.77.259}. Sampling can be done efficiently via perfect sampling techniques \cite{PhysRevB.85.165146}. Moreover, symmetric TN (STN) models enable the incorporation of equality \cite{lopezpiqueres2023symmetric} and inequality \cite{lopezpiqueres2024constrainingtensornetworks} constraints via defining certain well-understood symmetries \cite{PhysRevB.83.115125}, which reduce the size of the sample space. There is vast literature and experience when dealing with TNs, see \cite{ORUS2014117} for an in-depth introduction. 

In this work, following \cite{Alcazar2024, lopezpiqueres2023symmetric}, we implement and benchmark a GEO method with TN- and STN- based generators for a generalized knapsack problem.  The STN model is used in the binary encoding of the problem to enforce all equality constraints while all inequality constraints are dealt with by similar methods described in \cite{banner2023quantuminspiredoptimizationindustrial}. The TN model is used to test an integer encoding of the optimization problem in which the equality constraints are explicitly fulfilled.  The motivation of this work is to explore the potential of GEO  using  both a TN and STN algorithm on a optimization problem which has more industry relevant constraints than the optimization problem considered in \cite{Alcazar2024, lopezpiqueres2023symmetric}.  Furthermore, this work explicitly outlines the encoding logic of the method, thus providing a reference for future practitioners.

The remainder of the paper is organized as follows: in section \ref{sec:geo}, we introduce the basics of GEO. In section \ref{sec:mps}, we briefly describe TNs, followed by a brief description on how to use STNs to encode equality constraints in section \ref{sec:symmetric_mps}. In section \ref{sec:knapsack}, we formulate the knapsack problem, followed by an introduction of the training and sampling algorithms needed to implement GEO in sections \ref{sec:dmrg} and \ref{sec:perfect_sampling}. We finish the section describing the benchmark experiments we will conduct in section \ref{sec:experiment_design}. We conclude the paper showing and discussing the results of our benchmarks in sections \ref{sec:results} and \ref{sec:conclusion}.