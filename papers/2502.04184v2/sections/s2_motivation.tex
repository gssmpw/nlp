\section{Motivation}
\label{sec:motivation}


\begin{figure*}[ht!] % Figure 2
\centerline{\includegraphics[width=0.8\textwidth]{images/full_workflow.pdf}}
    \caption{LLM-based error-driven notebook executability analysis and restoration workflow.}
    \label{fig:main_workflow}
    % \vspace{-4ex}
\end{figure*}


This section presents two case studies demonstrating that seemingly non-executable notebooks can potentially be restored with minor reconfiguration, and pathologically non-executable notebooks still offer valuable partially executable code. 


\subsection{Case Study 1: Restoring Complete Executability}
\label{case_study_1}

    The notebook {\small{\texttt{random\_forest\_algorithm.ipynb}}} \cite{girlscript2024} implements the random forest classifier algorithm. This notebook is hosted by the GirlScript Foundation's GitHub open-source repository ``Winter of Contributing" with 881 stars. It consists of 24 code cells. When this notebook is executed as is, it results in a ``FileNotFound" error in cell 2, attempting to read input file {\small{\texttt{Social\_Network\_Ads.csv}}}. This input file is accessible in the original author's environment, suggesting that the author intended this notebook to be executable before uploading it to GitHub. However, this input file is neither included in the repository nor available in the adopter's environment. Prior studies \cite{Pimentel2019, Pimentel2021} would classify this notebook as non-executable. This classification is analogous to considering ``{\small{\texttt{javac}}}" non-executable if no input {\small{\texttt{.java}}} file is provided. This notebook aims to demonstrate the logical steps required to create a classifier. Our observation is that for such a notebook, improving executability can help serve the notebook's purpose, which can be done by generating a synthetic input file. To do so, we package the notebook's code, Python error description, and the notebook's documentation into a prompt and query Llama-3 to generate an input file with a correct relative path to the notebook with synthetic content. This synthetically generated input file results in full executability of all 24 cells, i.e., improving the executability of the previously non-executable notebook by over 95\% as illustrated in Figure \ref{fig:cs1-full-exec}. This is a prime example of how non-executability is often over-classified when the input file is not provided but may be available locally to the original author. 
    

\subsection{Case Study 2: Improving Partial Executability}
\label{case_study_2}

    The notebook {\small{\texttt{DinosaurusIsland--Character level language model final-v3.ipynb}}} from GitHub repository ``deep-learning-coursera" \cite{gemaatienza} is demonstrating a deep learning tutorial. It has 129 stars and a total of 14 code cells. When executed in linear order, the notebook first encounters a ``ModuleNotFound" error in cell 1 due to the absence of module {\small{\texttt{utils}}}. We resolve this error by installing the required module. A follow-up execution raises a ``NameError" in cell 6 due to the undefined function {\small{\texttt{softmax()}}}. After reviewing the notebook, we noted that the markdown cell claimed the function was provided, but it is missing. The original notebook shows a valid output, meaning the author successfully executed it. This is a common case where program states are shared between different executions, even if the corresponding code is moved or deleted. Even if the notebook is executed end-to-end before pushing on GitHub, the error would not have surfaced as the function definition is still present in the current Python kernel. However, such program states are not shared with the notebook itself, resulting in a ``NameError" in a new Python Kernel. 
    
    Our analysis indicates that defining the undefined name with an appropriate implementation could significantly improve the notebook's executability. Therefore, we prompt Llama-3 with the error report and the code cells to generate a definition for this function and insert a new code cell containing the definition right before its usage. This LLM-generated code cell requires a module import for {\small{\texttt{tensorflow}}}. Again, we were able to install it in the environment. These simple addition and module installations improve the original notebook's executability by 7 cells until it encounters ``AttributeError" at cell 8. This is a tutorial notebook, and the first half illustrates valuable deep-learning knowledge in sequence models. Thus, partial executability offers added value.


