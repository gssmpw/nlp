@inproceedings{abernethy2008competing,
  title={Competing in the Dark: An Efficient Algorithm for Bandit Linear Optimization.},
  author={Abernethy, Jacob D and Hazan, Elad and Rakhlin, Alexander},
  booktitle={COLT},
  pages={263--274},
  year={2008},
  organization={Citeseer}
}

@inproceedings{bubeck2012towards,
  title={Towards minimax policies for online linear optimization with bandit feedback},
  author={Bubeck, S{\'e}bastien and Cesa-Bianchi, Nicolo and Kakade, Sham M},
  booktitle={Conference on Learning Theory},
  pages={41--1},
  year={2012},
  organization={JMLR Workshop and Conference Proceedings}
}

@article{cassel2024near,
  title={Near-optimal regret in linear MDPs with aggregate bandit feedback},
  author={Cassel, Asaf and Luo, Haipeng and Rosenberg, Aviv and Sotnikov, Dmitry},
  journal={arXiv preprint arXiv:2405.07637},
  year={2024}
}

@article{cesa2012combinatorial,
  title={Combinatorial bandits},
  author={Cesa-Bianchi, Nicolo and Lugosi, G{\'a}bor},
  journal={Journal of Computer and System Sciences},
  volume={78},
  number={5},
  pages={1404--1422},
  year={2012},
  publisher={Elsevier}
}

@article{chatterji2021theory,
  title={On the theory of reinforcement learning with once-per-episode feedback},
  author={Chatterji, Niladri and Pacchiano, Aldo and Bartlett, Peter and Jordan, Michael},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={3401--3412},
  year={2021}
}

@inproceedings{chen2022human,
  title={Human-in-the-loop: Provably efficient preference-based reinforcement learning with general function approximation},
  author={Chen, Xiaoyu and Zhong, Han and Yang, Zhuoran and Wang, Zhaoran and Wang, Liwei},
  booktitle={International Conference on Machine Learning},
  pages={3773--3793},
  year={2022},
  organization={PMLR}
}

@inproceedings{cohen2021online,
  title={Online markov decision processes with aggregate bandit feedback},
  author={Cohen, Alon and Kaplan, Haim and Koren, Tomer and Mansour, Yishay},
  booktitle={Conference on Learning Theory},
  pages={1301--1329},
  year={2021},
  organization={PMLR}
}

@article{dani2007price,
  title={The price of bandit information for online optimization},
  author={Dani, Varsha and Kakade, Sham M and Hayes, Thomas},
  journal={Advances in Neural Information Processing Systems},
  volume={20},
  year={2007}
}

@inproceedings{efroni2021reinforcement,
  title={Reinforcement learning with trajectory feedback},
  author={Efroni, Yonathan and Merlis, Nadav and Mannor, Shie},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={35},
  number={8},
  pages={7288--7295},
  year={2021}
}

@article{even2009online,
    title={Online Markov decision processes},
    author={Even-Dar, Eyal and Kakade, Sham M and Mansour, Yishay},
    journal={Mathematics of Operations Research},
    volume={34},
    number={3},
    pages={726--736},
    year={2009},
}

@article{hazan2016volumetric,
  title={Volumetric spanners: an efficient exploration basis for learning},
  author={Hazan, Elad and Karnin, Zohar},
  journal={Journal of Machine Learning Research},
  year={2016}
}

@article{jaksch2010near,
  title={Near-optimal Regret Bounds for Reinforcement Learning.},
  author={Jaksch, Thomas and Ortner, Ronald and Auer, Peter},
  journal={Journal of Machine Learning Research},
  volume={11},
  number={4},
  year={2010}
}

@inproceedings{jin2018q,
    title={Is q-learning provably efficient?},
    author={Jin, Chi and Allen-Zhu, Zeyuan and Bubeck, Sebastien and Jordan, Michael I},
    booktitle={Advances in Neural Information Processing Systems},
    pages={4863--4873},
    year={2018}
}

@inproceedings{jin2019learning,
  title={Learning adversarial markov decision processes with bandit feedback and unknown transition},
  author={Jin, Chi and Jin, Tiancheng and Luo, Haipeng and Sra, Suvrit and Yu, Tiancheng},
  booktitle={International Conference on Machine Learning},
  pages={4860--4869},
  year={2020},
  organization={PMLR}
}

@book{lattimore2020bandit,
  title={Bandit algorithms},
  author={Lattimore, Tor and Szepesv{\'a}ri, Csaba},
  year={2020},
  publisher={Cambridge University Press}
}

@article{luo2021policy,
  title={Policy optimization in adversarial mdps: Improved exploration via dilated bonuses},
  author={Luo, Haipeng and Wei, Chen-Yu and Lee, Chung-Wei},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@inproceedings{rosenberg2019bandit,
    title={Online Stochastic Shortest Path with Bandit Feedback and Unknown Transition Function},
    author={Rosenberg, Aviv and Mansour, Yishay},
    booktitle={Advances in Neural Information Processing Systems},
    pages={2209--2218},
    year={2019}
}

@inproceedings{rosenberg2019online,
  title={Online convex optimization in adversarial markov decision processes},
  author={Rosenberg, Aviv and Mansour, Yishay},
  booktitle={International Conference on Machine Learning},
  pages={5478--5486},
  year={2019},
  organization={PMLR}
}

@inproceedings{saha2023dueling,
  title={Dueling rl: Reinforcement learning with trajectory preferences},
  author={Saha, Aadirupa and Pacchiano, Aldo and Lee, Jonathan},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={6263--6289},
  year={2023},
  organization={PMLR}
}

@inproceedings{shani2020optimistic,
  title={Optimistic policy optimization with bandit feedback},
  author={Shani, Lior and Efroni, Yonathan and Rosenberg, Aviv and Mannor, Shie},
  booktitle={International Conference on Machine Learning},
  pages={8604--8613},
  year={2020},
  organization={PMLR}
}

@article{wu2023making,
  title={Making rl with preference-based feedback efficient via randomization},
  author={Wu, Runzhe and Sun, Wen},
  journal={arXiv preprint arXiv:2310.14554},
  year={2023}
}

@inproceedings{zimin2013online,
    title={Online learning in episodic Markovian decision processes by relative entropy policy search},
    author={Alexander Zimin and Gergely Neu},
    booktitle={Advances in Neural Information Processing Systems 26: 27th Annual Conference on Neural Information Processing Systems 2013.},
    year={2013},
}

