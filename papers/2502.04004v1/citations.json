[
  {
    "index": 0,
    "papers": [
      {
        "key": "efroni2021reinforcement",
        "author": "Efroni, Yonathan and Merlis, Nadav and Mannor, Shie",
        "title": "Reinforcement learning with trajectory feedback"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "cassel2024near",
        "author": "Cassel, Asaf and Luo, Haipeng and Rosenberg, Aviv and Sotnikov, Dmitry",
        "title": "Near-optimal regret in linear MDPs with aggregate bandit feedback"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "lattimore2020bandit",
        "author": "Lattimore, Tor and Szepesv{\\'a}ri, Csaba",
        "title": "Bandit algorithms"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "dani2007price",
        "author": "Dani, Varsha and Kakade, Sham M and Hayes, Thomas",
        "title": "The price of bandit information for online optimization"
      },
      {
        "key": "cesa2012combinatorial",
        "author": "Cesa-Bianchi, Nicolo and Lugosi, G{\\'a}bor",
        "title": "Combinatorial bandits"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "bubeck2012towards",
        "author": "Bubeck, S{\\'e}bastien and Cesa-Bianchi, Nicolo and Kakade, Sham M",
        "title": "Towards minimax policies for online linear optimization with bandit feedback"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "hazan2016volumetric",
        "author": "Hazan, Elad and Karnin, Zohar",
        "title": "Volumetric spanners: an efficient exploration basis for learning"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "cohen2021online",
        "author": "Cohen, Alon and Kaplan, Haim and Koren, Tomer and Mansour, Yishay",
        "title": "Online markov decision processes with aggregate bandit feedback"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "abernethy2008competing",
        "author": "Abernethy, Jacob D and Hazan, Elad and Rakhlin, Alexander",
        "title": "Competing in the Dark: An Efficient Algorithm for Bandit Linear Optimization."
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "jaksch2010near",
        "author": "Jaksch, Thomas and Ortner, Ronald and Auer, Peter",
        "title": "Near-optimal Regret Bounds for Reinforcement Learning."
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "zimin2013online",
        "author": "Alexander Zimin and Gergely Neu",
        "title": "Online learning in episodic Markovian decision processes by relative entropy policy search"
      },
      {
        "key": "rosenberg2019bandit",
        "author": "Rosenberg, Aviv and Mansour, Yishay",
        "title": "Online Stochastic Shortest Path with Bandit Feedback and Unknown Transition Function"
      },
      {
        "key": "rosenberg2019online",
        "author": "Rosenberg, Aviv and Mansour, Yishay",
        "title": "Online convex optimization in adversarial markov decision processes"
      },
      {
        "key": "jin2019learning",
        "author": "Jin, Chi and Jin, Tiancheng and Luo, Haipeng and Sra, Suvrit and Yu, Tiancheng",
        "title": "Learning adversarial markov decision processes with bandit feedback and unknown transition"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "even2009online",
        "author": "Even-Dar, Eyal and Kakade, Sham M and Mansour, Yishay",
        "title": "Online Markov decision processes"
      },
      {
        "key": "shani2020optimistic",
        "author": "Shani, Lior and Efroni, Yonathan and Rosenberg, Aviv and Mannor, Shie",
        "title": "Optimistic policy optimization with bandit feedback"
      },
      {
        "key": "luo2021policy",
        "author": "Luo, Haipeng and Wei, Chen-Yu and Lee, Chung-Wei",
        "title": "Policy optimization in adversarial mdps: Improved exploration via dilated bonuses"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "zimin2013online",
        "author": "Alexander Zimin and Gergely Neu",
        "title": "Online learning in episodic Markovian decision processes by relative entropy policy search"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "jin2019learning",
        "author": "Jin, Chi and Jin, Tiancheng and Luo, Haipeng and Sra, Suvrit and Yu, Tiancheng",
        "title": "Learning adversarial markov decision processes with bandit feedback and unknown transition"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "jin2018q",
        "author": "Jin, Chi and Allen-Zhu, Zeyuan and Bubeck, Sebastien and Jordan, Michael I",
        "title": "Is q-learning provably efficient?"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "luo2021policy",
        "author": "Luo, Haipeng and Wei, Chen-Yu and Lee, Chung-Wei",
        "title": "Policy optimization in adversarial mdps: Improved exploration via dilated bonuses"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "jin2019learning",
        "author": "Jin, Chi and Jin, Tiancheng and Luo, Haipeng and Sra, Suvrit and Yu, Tiancheng",
        "title": "Learning adversarial markov decision processes with bandit feedback and unknown transition"
      },
      {
        "key": "luo2021policy",
        "author": "Luo, Haipeng and Wei, Chen-Yu and Lee, Chung-Wei",
        "title": "Policy optimization in adversarial mdps: Improved exploration via dilated bonuses"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "luo2021policy",
        "author": "Luo, Haipeng and Wei, Chen-Yu and Lee, Chung-Wei",
        "title": "Policy optimization in adversarial mdps: Improved exploration via dilated bonuses"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "chatterji2021theory",
        "author": "Chatterji, Niladri and Pacchiano, Aldo and Bartlett, Peter and Jordan, Michael",
        "title": "On the theory of reinforcement learning with once-per-episode feedback"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "saha2023dueling",
        "author": "Saha, Aadirupa and Pacchiano, Aldo and Lee, Jonathan",
        "title": "Dueling rl: Reinforcement learning with trajectory preferences"
      },
      {
        "key": "chen2022human",
        "author": "Chen, Xiaoyu and Zhong, Han and Yang, Zhuoran and Wang, Zhaoran and Wang, Liwei",
        "title": "Human-in-the-loop: Provably efficient preference-based reinforcement learning with general function approximation"
      },
      {
        "key": "wu2023making",
        "author": "Wu, Runzhe and Sun, Wen",
        "title": "Making rl with preference-based feedback efficient via randomization"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "efroni2021reinforcement",
        "author": "Efroni, Yonathan and Merlis, Nadav and Mannor, Shie",
        "title": "Reinforcement learning with trajectory feedback"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "cassel2024near",
        "author": "Cassel, Asaf and Luo, Haipeng and Rosenberg, Aviv and Sotnikov, Dmitry",
        "title": "Near-optimal regret in linear MDPs with aggregate bandit feedback"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "cohen2021online",
        "author": "Cohen, Alon and Kaplan, Haim and Koren, Tomer and Mansour, Yishay",
        "title": "Online markov decision processes with aggregate bandit feedback"
      }
    ]
  }
]