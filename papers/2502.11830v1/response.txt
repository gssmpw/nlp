\section{Related Work}
\label{sec:related}
Text classification, the task of classifying a given text into a pre-defined list of categories, is a well-studied problem. From bag-of-words features to the current state-of-the-art LLMs, numerous approaches have been explored in the past. Access to large amounts of human labeled data has traditionally played a significant role in improving text classifiers, and NLP research in the past two decades addressed this issue by looking at different solutions to learn from little or no labeled data.

\paragraph{Zero-shot Pre-LLM Approaches: }Some of the earlier classification approaches relied on using only label names to build "data less" text classifier **Agirrezabal, "Classifying without a labeled corpus"** and embedding the texts and labels in a shared space **Kessler, "Embedding words and their meanings"**. **Boscheini, "Zero-shot text classification as textual entailment"** proposed to formulate zero-shot text classification as a textual entailment problem, although **Farahmand, "Limitations of textual entailment for zero-shot classification"** point to the limitations of this approach in terms of variability across datasets and reliance on spurious lexical patterns. Another practical approach for zero-shot classification is cross-lingual transfer i.e., train a classification model in one or more languages, and use it as a zero-shot classifier on the target language **Kumar, "Cross-lingual transfer for zero-shot text classification"**. Except **Kumar**, who studied sentiment and hate speech classification tasks, all the research has  focused primarily on English datasets. 

\paragraph{Few-shot fine-tuning: } Approaches that can learn from a small amount of ($<20$ samples per category) labeled examples have also been explored in the recent years **Mao, "Learning from few examples"**. SetFit **Mansoury, "SetFit: a supervised contrastive learning approach"** introduced an approach based on supervised contrastive learning, transforming a language model into a topic encoder using only a few examples per label, and demonstrated effectiveness with datasets where the number of categories are low (under 5). FastFit **Liu, "FastFit: scaling to many classes"** proposed an approach that scales to many classes (50--150) effectively, and showed its usefulness with English datasets. Out of these only SetFit evaluated with a few non-English datasets. %We consider FastFit, and compare its performance with the recent zero-shot LLMs and other approaches in this paper. 

\paragraph{Zero-shot Classification with LLMs: }With the arrival of Large Language Models, some recent approaches explored proprietary models like GPT3.5 and GPT4 for zero-shot or few-shot in-context learning for text classification across several datasets **Brown, "GPT-3.5 and GPT-4"**. Extending this line of work, open LLMs were studied in the context of intent classification **Zhang, "Intent classification with open LLMs"** and computational social science **Bender, "Computational social science with open LLMs"**. However, comparing such zero-shot approaches with few-shot and full-data  based fine-tuning, **Hamborg, "Comparison between zero-shot and few-shot approaches"** show that smaller, fine-tuned classifiers outperform zero-shot approaches. Whether supervised fine-tuning of LLMs offers any benefit is an unexplored question. Surprisingly, except **Hamborg**, all these experiments have been focused only on English datasets so far. We expand this strand of work to 7 other languages, and provide more detailed comparisons across different LLMs. 

\paragraph{Synthetic Data: } One approach to address the labeled data problem is to augment existing data by creating new data by applying text transformations such as replacing synonyms, paraphrasing, back translation etc. **Bastian, "Survey of synthetic data generation techniques"** presents a detailed survey of such data augmentation techniques for text classification. An extension of this idea is to directly synthesize the labeled data using generative language models **Mansoury, "Generative language models for synthetic data"**. In the recent past, Large Language Model based synthetic data generation is increasingly observed across different NLP tasks **Bender, "Large Language Models and synthetic data"**. GPT4 has been used for English **Brown, "GPT-3.5 and GPT-4 for text classification"** and code-mixed **Zhang, "Code-mixed text classification with GPT-4"** synthetic data generation for text classification with mixed results. We extend this line of work by covering more languages and exploring multiple LLMs as sources for synthetic data instead of relying on one, and extending to handle datasets with a larger label set. 

Overall, we address several gaps in existing research by comparing zero-shot classification, few-shot fine-tuning, synthetic data based classification, and classification with full data together, and also study how the comparison works out once we go beyond English. In this process, we also present a comparison between different open and closed recent LLMs.