\section{Introduction}

Music, as a powerful expression of cultural identity, is deeply embedded in traditions~\cite{10.1093/mq/79.2.281, chung2006digital}. Recent advancements in AI, powered by deep learning models~\cite{c:24,c:23,c:22}, have led to significant improvements in automatic music generation technologies. This progress has led to several music generation playgrounds such as Jukebox~\cite{c:25}, Suno\footnote{https://suno.com/}, and Udio\footnote{https://www.udio.com/} offering users the ability to generate music according to their specifications. However, these models often reflect biases, particularly towards Western musical traditions~\cite{10.1093/pnasnexus/pgae346, c:23}, in their training data. 

This lack of diversity in datasets, as outlined by~\citet{c:23, melechovsky-etal-2024-mustango, c:25}, is also evident in the disparate performance of the music generation models across genres. More specifically, the models tend to rely on Western tonal and rhythmic structures when generating music for non-Western genres, such as Indian or Middle Eastern music. The situation is comparable to the lack of cultural and linguistic diversity~\cite{c:27, bender-2018, bender2021dangers} in NLP research.

%challenge has been recognized in NLP, where the focus on linguistic inclusivity was initially limited. Since then, researchers have increasingly emphasized the importance of multilinguality , highlighting the importance of lingual diversity which has led to advancement in linguistic inclusivity in NLP.

In order to quantify the severity of this problem in music generation research landscape, we conduct a comprehensive analysis of existing music datasets and music generation papers, which reveals a stark disparity in the representation of non-Western music. Particularly noteworthy is the scarcity of non-Western music data, with merely 5.7\% of the total hours of the available datasets. This finding highlights the need for more diverse musical datasets and methods to adapt state-of-the-art models to low-resource genres. 

However, it remains unclear whether cross-genre music adaptation, similar to cross-lingual adaptation, can be effectively achieved using lightweight computational techniques such as parameter-efficient fine-tuning (PEFT) \cite{houlsby2019parameter}. In this paper, we explore this question by adapting two open-source models, MusicGen~\cite{c:23} and Mustango~\cite{melechovsky-etal-2024-mustango} for two low-resource non-Western genres - \textit{Hindustani Classical}~\footnote{Hindustani Classical music is a traditional system of music that emphasizes melodic development based on ragas (melodic frameworks) and talas (rhythmic cycles).} music of India and \textit{Makamat}~\footnote{Makam, in traditional Arabic music, is a melodic mode system defining pitches, patterns, and improvisation, central to Arabian art music, with 72 heptatonic scales} music of the Middle East.

%a technique involving lightweight, trainable modules that allow for parameter efficient fine-tuning of large pre-trained models. 
% This approach offers several advantages:

% \begin{itemize}
% \setlength{\parskip}{0pt}
%     \item It allows for efficient integration of cultural music knowledge without the need for full model retraining.
%     \item It provides a flexible framework for incorporating diverse musical traditions into existing models.
%     \item It potentially enhances the model's ability to capture and reproduce culture-specific musical elements.
% \end{itemize}

\begin{figure*}[!ht]
\centering
\includegraphics[width=\textwidth]{graphs/dataset_infographic_v7.png}
\caption{%
The bottom left piechart shows the global distribution of genre. Each piechart in the map shows the distribution of genres in different regions with the size of each piechart being proportional to their contribution to the data corpus.
}
\label{fig:dataset_infographic}
\end{figure*}

We hypothesize that explicit fine-tuning with a small number of additional parameters (less than 1\% of the pre-trained model) as adapters~\cite{bapna2019simple}, will lead to a far better performance for the under-represented music style. We conduct a series of experiments comparing the performance of baseline models and our adapter-enhanced models on objective metrics. For human evaluations, each model is tested using our novel evaluation framework roughly based on Bloom’s Taxonomy \cite{armstrong2010}: \textbf{Recall, Analysis}, and \textbf{Creativity} evaluate a model’s audio generation. Recall reproduces trained entities, Analysis forms new combinations of them, and Creativity blends different entities across genres in novel, unseen ways. Evaluations are conducted in a play-arena style, ranking models based on their adherence to the text prompt in terms of \textit{rhythm}, \textit{instrument}, \textit{melody} and \textit{creativity}. Mustango shows improvement when finetuned on Hindustani Classical music by 8\% and MusicGen shows improvement by 4\% on Turkish Makam in ELO ratings from their respective baselines. 

Our results show that while PEFT techniques are effective in improving the overall quality of generated music for the under-represented genre over the baseline models, not all models are adaptable to all genres. This implies that the various design choices made in the architecture, and the training datasets and recipes for the base model are crucial determinants of the adaptability of a model to certain musical genres. 


The contributions of this paper are threefold:

\begin{enumerate}
\setlength{\parskip}{0pt}
    \item We provide a detailed analysis of the current state of musical datasets, highlighting the under-representation of non-Western music.
    \item We present the first application of parameter-efficient training with adapters for cultural adaptation of under-represented genres in music generation models. 
    \item We introduce a novel arena-style evaluation framework based on Bloom's Taxonomy to assess the text to music generation capabilities of models using a play-arena style, ranking models on on their adherence to the text prompt on \textit{rhythm}, \textit{instrument}, \textit{melody} and \textit{creativity}.
    \item We demonstrate that while adapting base models to different genres is possible, it is a non-trivial challenge.
\end{enumerate}
The rest of the paper is organized as follows: In Section \ref{disparity_research}, we discuss global disparities in music representation, followed by Section \ref{experimental_setup}, which details our approach to adapting genres. Section \ref{result} presents our evaluation methodology and the results obtained from our analysis. We conclude our findings in Section \ref{conclusion}.