\begin{table*}[h]
\centering
\renewcommand{\arraystretch}{2} 
\resizebox{2\columnwidth}{!}{%
%\rotatebox{90}{
\begin{tabular}{l|ccc|ccc|ccc|ccc}
\toprule
\textbf{Model} & \multicolumn{6}{c|}{\textbf{Clinical Note-taking}} & \multicolumn{6}{c}{\textbf{Open-ended Medical Questions}} \\
 & \multicolumn{3}{c|}{\textbf{ACI Bench}} & \multicolumn{3}{c|}{\textbf{MTS Dialog}} & \multicolumn{3}{c|}{\textbf{MedDialog Raw}} & \multicolumn{3}{c}{\textbf{MediQA2019}} \\
 & \textbf{Bits per Byte $\downarrow$} & \textbf{Byte Perplexity $\downarrow$} & \textbf{Word Perplexity $\downarrow$} & \textbf{Bits per Byte $\downarrow$} & \textbf{Byte Perplexity $\downarrow$} & \textbf{Word Perplexity $\downarrow$} & \textbf{Bits per Byte $\downarrow$} & \textbf{Byte Perplexity $\downarrow$} & \textbf{Word Perplexity $\downarrow$} & \textbf{Bits per Byte $\downarrow$} & \textbf{Byte Perplexity $\downarrow$} & \textbf{Word Perplexity $\downarrow$} \\
\midrule 
BioMistral-MedMNX & 0.601 & 1.517 & 13.894 & 1.059 & 2.083 & 132.827 & 1.043 & 2.060 & 74.760 & 0.416 & 1.335 & 6.044 \\
JSL-MedLlama-3-8B-v2.0 & 0.703 & 1.628 & 21.725 & 1.099 & 2.143 & 160.188 & 1.179 & 2.265 & 131.509 & 0.517 & 1.431 & 9.312 \\
Llama3-Med42-8B & 0.485 & 1.399 & 8.357 & 1.060 & 2.085 & 133.416 & 1.069 & 2.097 & 83.115 & 0.405 & 1.324 & 5.754 \\
Meta-Llama-3.1-70B-Instruct & - & - & - & 0.984 & 1.978 & 93.943 & 0.993 & 1.991 & 60.907 & 0.245 & 1.185 & 2.886 \\
Meta-Llama-3.1-8B-Instruct & 0.612 & 1.529 & 14.618 & 1.074 & 2.105 & 142.211 & 1.060 & 2.085 & 80.124 & 0.430 & 1.347 & 6.407 \\
Mistral-7B-Instruct-v0.3 & 0.596 & 1.512 & 13.628 & 1.053 & 2.074 & 129.076 & 1.073 & 2.104 & 84.603 & 0.420 & 1.338 & 6.145 \\
Mixtral-8x7B-Instruct-v0.1 & 0.566 & 1.481 & 11.933 & 1.046 & 2.064 & 125.070 & 1.028 & 2.039 & 70.258 & 0.300 & 1.232 & 3.662 \\
Phi-3-medium-4k-instruct & 0.642 & 1.560 & 16.600 & 0.971 & 1.960 & 88.447 & 1.068 & 2.097 & 82.957 & 0.410 & 1.329 & 5.884 \\
Phi-3-mini-4k-instruct & 0.599 & 1.514 & 13.754 & 0.972 & 1.962 & 89.163 & 1.082 & 2.117 & 87.936 & 0.444 & 1.360 & 6.796 \\
%Qwen2-72B-Instruct & - & - & - & 0.954 & 1.938 & 82.027 & 0.938 & 1.916 & 48.395 & 0.350 & 1.274 & 4.533 \\
Qwen2-7B-Instruct & 0.619 & 1.535 & 15.009 & 1.063 & 2.089 & 135.111 & 1.044 & 2.063 & 75.218 & 0.447 & 1.363 & 6.895 \\
Yi-1.5-34B-Chat & 0.728 & 1.657 & 24.270 & 1.099 & 2.143 & 160.265 & 1.101 & 2.145 & 95.042 & 0.485 & 1.399 & 8.112 \\
Yi-1.5-9B-Chat & 0.711 & 1.636 & 22.456 & 1.180 & 2.265 & 232.073 & 1.123 & 2.178 & 104.205 & 0.532 & 1.446 & 9.968 \\
%gemma-2-27b-it & - &- & -& -& -&- & - & - & - & -& -&-\\
%gemma-2-9b-it & - & - & - & - &  - & & 3.647 & 12.528 & 3563621.691 & 3.400& 10.555 & - \\

\bottomrule
\end{tabular}%
}
%}
\caption{Perplexity results for Open-ended Medical Questions.}
\end{table*}