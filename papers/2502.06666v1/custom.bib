% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").

@article{huang2024comprehensive,
  title={A Comprehensive Survey on Evaluating Large Language Model Applications in the Medical Industry},
  author={Huang, Yining and Tang, Keke and Chen, Meilian},
  journal={arXiv preprint arXiv:2404.15777},
  year={2024}
}

@article{lee2024mechanistic,
  title={A mechanistic understanding of alignment algorithms: A case study on dpo and toxicity},
  author={Lee, Andrew and Bai, Xiaoyan and Pres, Itamar and Wattenberg, Martin and Kummerfeld, Jonathan K and Mihalcea, Rada},
  journal={arXiv preprint arXiv:2401.01967},
  year={2024}
}


@article{vilares2019head,
  title={HEAD-QA: A healthcare dataset for complex reasoning},
  author={Vilares, David and G{\'o}mez-Rodr{\'\i}guez, Carlos},
  journal={arXiv preprint arXiv:1906.04701},
  year={2019}
}



@article{alzahrani2024benchmarks,
  title={When benchmarks are targets: {R}evealing the sensitivity of large language model leaderboards},
  author={Alzahrani, Norah and Alyahya, Hisham Abdullah and Alnumay, Yazeed and Alrashed, Sultan and Alsubaie, Shaykhah and Almushaykeh, Yusef and Mirza, Faisal and Alotaibi, Nouf and Altwairesh, Nora and Alowisheq, Areeb and others},
  journal={arXiv preprint arXiv:2402.01781},
  year={2024}
}




@inproceedings{chiang2024chatbot,
  title={Chatbot {A}rena: {A}n {O}pen {P}latform for {E}valuating {LLM}s by {H}uman {P}reference},
  author={Chiang, Wei-Lin and Zheng, Lianmin and Sheng, Ying and Angelopoulos, Anastasios Nikolas and Li, Tianle and Li, Dacheng and Zhu, Banghua and Zhang, Hao and Jordan, Michael and Gonzalez, Joseph E and others},
  booktitle={Forty-first International Conference on Machine Learning},
  year={2024}
}



@article{ravaut2024much,
  title={How Much are LLMs Contaminated? A Comprehensive Survey and the LLMSanitize Library},
  author={Mathieu Ravaut  et al.},
  journal={arXiv preprint arXiv:2404.00699},
  year={2024}
}

@article{yang2023rethinking,
  title={Rethinking benchmark and contamination for language models with rephrased samples},
  author={Shuo Yang et al.}, 
  journal={arXiv preprint arXiv:2311.04850},
  year={2023}
}

@article{zhou2023don,
  title={Don't Make Your LLM an Evaluation Benchmark Cheater},
  author={Kun Zhou et al.}, 
  journal={arXiv preprint arXiv:2311.01964},
  year={2023}
}


@article{han2023medalpaca,
  title={MedAlpaca--an open-source collection of medical conversational AI models and training data},
  author={Tianyu Han et al.}, 
  journal={arXiv preprint arXiv:2304.08247},
  year={2023}
}


@article{pezeshkpour2023large,
  title={Large language models sensitivity to the order of options in multiple-choice questions},
  author={Pezeshkpour, Pouya and Hruschka, Estevam},
  journal={arXiv preprint arXiv:2308.11483},
  year={2023}
}


@inproceedings{zheng2023large,
  title={Large language models are not robust multiple choice selectors},
  author={Zheng, Chujie and Zhou, Hao and Meng, Fandong and Zhou, Jie and Huang, Minlie},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2023}
}


@article{he2023survey,
  title={A survey of Large Language Models for Healthcare: from data, technology, and applications to accountability and ethics},
  author={He, Kai and Mao, Rui and Lin, Qika and Ruan, Yucheng and Lan, Xiang and Feng, Mengling and Cambria, Erik},
  journal={Information Fusion},
  pages={102963},
  year={2025},
  publisher={Elsevier}
}


@misc{eriksen2023use,
  title={Use of GPT-4 to diagnose complex clinical cases},
  author={Eriksen, Alexander V and M{\"o}ller, S{\"o}ren and Ryg, Jesper},
  journal={NEJM AI},
  volume={1},
  number={1},
  pages={AIp2300031},
  year={2023},
  publisher={Massachusetts Medical Society}
}


@article{nastasi2023does,
  title={Does ChatGPT provide appropriate and equitable medical advice?: A vignette-based, clinical evaluation across care contexts},
  author={Anthony J Nastasi et al.}, 
  journal={MedRxiv},
  pages={2023--02},
  year={2023},
  publisher={Cold Spring Harbor Laboratory Press}
}


@article{singhal2023towards,
  title={Towards expert-level medical question answering with large language models},
  author={Karan Singhal et al.},
  journal={arXiv preprint arXiv:2305.09617},
  year={2023}
}


@article{umapathi2023med,
  title={Med-halt: Medical domain hallucination test for large language models},
  author={Umapathi, Logesh Kumar and Pal, Ankit and Sankarasubbu, Malaikannan},
  journal={arXiv preprint arXiv:2307.15343},
  year={2023}
}

@article{ahmad2023creating,
  title={Creating trustworthy llms: Dealing with hallucinations in healthcare ai},
  author={Ahmad, Muhammad Aurangzeb and Yaramis, Ilker and Roy, Taposh Dutta},
  journal={arXiv preprint arXiv:2311.01463},
  year={2023}
}


@article{wu2024well,
  title={How well do LLMs cite relevant medical references? An evaluation framework and analyses},
  author={Kevin Wu et al.}, 
  journal={arXiv preprint arXiv:2402.02008},
  year={2024}
}

@article{nastasi2023does,
  title={Does ChatGPT provide appropriate and equitable medical advice?: A vignette-based, clinical evaluation across care contexts},
  author={Anthony J Nastasi et al.}, 
  journal={MedRxiv},
  pages={2023--02},
  year={2023},
  publisher={Cold Spring Harbor Laboratory Press}
}


@article{gilbert2023large,
  title={Large language model AI chatbots require approval as medical devices},
  author={Stephen Gilbert et al.},
  journal={Nature Medicine},
  volume={29},
  number={10},
  pages={2396--2398},
  year={2023},
  publisher={Nature Publishing Group US New York}
}

@inproceedings{gottlieb2023safely,
  title={How to safely integrate large language models into health care},
  author={Gottlieb, Scott and Silvis, Lauren},
  booktitle={JAMA Health Forum},
  volume={4},
  number={9},
  pages={e233909--e233909},
  year={2023},
  organization={American Medical Association}
}

@article{bedi2024systematic,
  title={A Systematic Review of Testing and Evaluation of Healthcare Applications of Large Language Models (LLMs)},
  author={Bedi, Suhana and Liu, Yutong and Orr-Ewing, Lucy and Dash, Dev and Koyejo, Sanmi and Callahan, Alison and Fries, Jason A and Wornow, Michael and Swaminathan, Akshay and Lehmann, Lisa Soleymani and others},
  journal={medRxiv},
  pages={2024--04},
  year={2024},
  publisher={Cold Spring Harbor Laboratory Press}
}


@inproceedings{jin2019pubmedqa,
  title={Pub{M}ed{QA}: {A} {D}ataset for {B}iomedical {R}esearch {Q}uestion {A}nswering},
  author={Qiao Jin et al.},
  booktitle={Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
  pages={2567--2577},
  year={2019}
}

@article{jin2020disease,
  title={What Disease does this Patient Have? A Large-scale Open Domain Question Answering Dataset from Medical Exams},
  author={Di Jin et al.},
  journal={arXiv preprint arXiv:2009.13081},
  year={2020}
}

@InProceedings{pmlr-v174-pal22a,
  title = 	 {MedMCQA: A Large-scale Multi-Subject Multi-Choice Dataset for Medical domain Question Answering},
  author =       {Ankit Pal et al.},
  booktitle = 	 {Proceedings of the Conference on Health, Inference, and Learning},
  pages = 	 {248--260},
  year = 	 {2022},
  editor = 	 {Flores, Gerardo and Chen, George H and Pollard, Tom and Ho, Joyce C and Naumann, Tristan},
  volume = 	 {174},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {07--08 Apr},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v174/pal22a/pal22a.pdf},
  url = 	 {https://proceedings.mlr.press/v174/pal22a.html},
  abstract = 	 {This paper introduces MedMCQA, a new large-scale, Multiple-Choice Question Answering (MCQA) dataset designed to address real-world medical entrance exam questions. More than 194k high-quality AIIMS & NEET PG entrance exam MCQs covering 2.4k healthcare topics and 21 medical subjects are collected with an average token length of 12.77 and high topical diversity. Each sample contains a question, correct answer(s), and other options which requires a deeper language understanding as it tests the 10+ reasoning abilities of a model across a wide range of medical subjects & topics. A detailed explanation of the solution, along with the above information, is provided in this study.}
}

@inproceedings{hendrycks2020measuring,
  title={Measuring {M}assive {M}ultitask {L}anguage {U}nderstanding},
  author={Dan Hendrycks et al.}, 
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@inproceedings{zeng2020meddialog,
  title={MedDialog: Large-scale medical dialogue datasets},
  author={Zeng, Guangtao and Yang, Wenmian and Ju, Zeqian and Yang, Yue and Wang, Sicheng and Zhang, Ruisi and Zhou, Meng and Zeng, Jiaqi and Dong, Xiangyu and Zhang, Ruoyu and others},
  booktitle={Proceedings of the 2020 conference on empirical methods in natural language processing (EMNLP)},
  pages={9241--9250},
  year={2020}
}


@inproceedings{mts-dialog,
  title     = {An Empirical Study of Clinical Note Generation from Doctor-Patient Encounters},
    author = "Ben Abacha, Asma  and
      Yim, Wen-wai  and
      Fan, Yadan  and
      Lin, Thomas",
    booktitle = "Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics",
    month = may,
    year = "2023",
    address = "Dubrovnik, Croatia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.eacl-main.168",
    pages = "2291--2302"
}

@article{aci-bench,
  author = {Wen{-}wai Yim and
                Yujuan Fu and
                Asma {Ben Abacha} and
                Neal Snider and Thomas Lin and Meliha Yetisgen},
  title = {ACI-BENCH: a Novel Ambient Clinical Intelligence Dataset for Benchmarking Automatic Visit Note Generation},
  journal = {Nature Scientific Data},
  year = {2023}, 
  volume = {10},
  url = {https://www.nature.com/articles/s41597-023-02487-3}
}


@article{johnson2016mimic,
  title={MIMIC-III, a freely accessible critical care database},
  author={Johnson, Alistair EW and Pollard, Tom J and Shen, Lu and Lehman, Li-wei H and Feng, Mengling and Ghassemi, Mohammad and Moody, Benjamin and Szolovits, Peter and Anthony Celi, Leo and Mark, Roger G},
  journal={Scientific data},
  volume={3},
  number={1},
  pages={1--9},
  year={2016},
  publisher={Nature Publishing Group}
}



@inproceedings{losch2018european,
  title={European language resource coordination: Collecting language resources for public sector multilingual information management},
  author={L{\"o}sch, Andrea and Mapelli, Val{\'e}rie and Piperidis, Stelios and Vasi{\c{l}}jevs, Andrejs and Smal, Lilli and Declerck, Thierry and Schnur, Eileen and Choukri, Khalid and van Genabith, Josef},
  booktitle={Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018)},
  year={2018}
}

@article{luo2022biored,
  title={BioRED: a rich biomedical relation extraction dataset},
  author={Luo, Ling and Lai, Po-Ting and Wei, Chih-Hsuan and Arighi, Cecilia N and Lu, Zhiyong},
  journal={Briefings in Bioinformatics},
  volume={23},
  number={5},
  pages={bbac282},
  year={2022},
  publisher={Oxford University Press}
}

@article{rajpurkar2018know,
  title={Know what you don't know: Unanswerable questions for SQuAD},
  author={Rajpurkar, Pranav and Jia, Robin and Liang, Percy},
  journal={arXiv preprint arXiv:1806.03822},
  year={2018}
}

@inproceedings{10.1145/3582768.3582795,
author = {Schopf, Tim and Braun, Daniel and Matthes, Florian},
title = {Evaluating Unsupervised Text Classification: Zero-Shot and Similarity-Based Approaches},
year = {2023},
isbn = {9781450397629},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3582768.3582795},
doi = {10.1145/3582768.3582795},
abstract = {Text classification of unseen classes is a challenging Natural Language Processing task and is mainly attempted using two different types of approaches. Similarity-based approaches attempt to classify instances based on similarities between text document representations and class description representations. Zero-shot text classification approaches aim to generalize knowledge gained from a training task by assigning appropriate labels of unknown classes to text documents. Although existing studies have already investigated individual approaches to these categories, the experiments in literature do not provide a consistent comparison. This paper addresses this gap by conducting a systematic evaluation of different similarity-based and zero-shot approaches for text classification of unseen classes. Different state-of-the-art approaches are benchmarked on four text classification datasets, including a new dataset from the medical domain. Additionally, novel SimCSE [7] and SBERT-based [26] baselines are proposed, as other baselines used in existing work yield weak classification results and are easily outperformed. Finally, the novel similarity-based Lbl2TransformerVec approach is presented, which outperforms previous state-of-the-art approaches in unsupervised text classification. Our experiments show that similarity-based approaches significantly outperform zero-shot approaches in most cases. Additionally, using SimCSE or SBERT embeddings instead of simpler text representations increases similarity-based classification results even further.},
booktitle = {Proceedings of the 2022 6th International Conference on Natural Language Processing and Information Retrieval},
pages = {6–15},
numpages = {10},
keywords = {Zero-shot Text Classification, Natural Language Processing, Unsupervised Text Classification},
location = {Bangkok, Thailand},
series = {NLPIR '22}
}


@inproceedings{MEDIQA2019,
  author    = {Asma {Ben Abacha} and Chaitanya Shivade and Dina Demner{-}Fushman},
  title     = {Overview of the MEDIQA 2019 Shared Task on Textual Inference, Question Entailment and Question Answering},
  booktitle = {ACL-BioNLP 2019},
  year      = {2019}
}

@article{christophe2024med42,
  title={Med42-v2: A suite of clinical llms},
  author={Christophe, Cl{\'e}ment and Kanithi, Praveen K and Raha, Tathagata and Khan, Shadab and Pimentel, Marco AF},
  journal={arXiv preprint arXiv:2408.06142},
  year={2024}
}


@article{llama3modelcard,
    title={Llama 3 Model Card},
    author={AI@Meta},
    year={2024},
    url = {https://github.com/meta-llama/llama3blob/main/MODEL_CARD.md}
}

@article{qwen2,
  title={Qwen2 technical report},
  author={Yang, An and Yang, Baosong and Hui, Binyuan and Zheng, Bo and Yu, Bowen and Zhou, Chang and Li, Chengpeng and Li, Chengyuan and Liu, Dayiheng and Huang, Fei and others},
  journal={arXiv preprint arXiv:2407.10671},
  year={2024}
}



@article{young2024yi,
  title={Yi: Open foundation models by 01. ai},
  author={Young, Alex and Chen, Bei and Li, Chao and Huang, Chengen and Zhang, Ge and Zhang, Guanwei and Li, Heng and Zhu, Jiangcheng and Chen, Jianqun and Chang, Jing and others},
  journal={arXiv preprint arXiv:2403.04652},
  year={2024}
}


@article{gemma_2024,
    title={Gemma},
    url={https://www.kaggle.com/m/3301},
    DOI={10.34740/KAGGLE/M/3301},
    publisher={Kaggle},
    author={Gemma Team},
    year={2024}
}

@article{shoham2024medconceptsqa,
  title={MedConceptsQA--Open Source Medical Concepts QA Benchmark},
  author={Shoham, Ofir Ben and Rappoport, Nadav},
  journal={arXiv preprint arXiv:2405.07348},
  year={2024}
}



@article{dada2024clue,
  title={CLUE: A Clinical Language Understanding Evaluation for LLMs},
  author={Dada, Amin and Bauer, Marie and Contreras, Amanda Butler and Kora{\c{s}}, Osman Alperen and Seibold, Constantin Marc and Smith, Kaleb E and Kleesiek, Jens},
  journal={arXiv preprint arXiv:2404.04067},
  year={2024}
}

@article{kanithi2024medic,
  title={MEDIC: Towards a Comprehensive Framework for Evaluating LLMs in Clinical Applications},
  author={Kanithi, Praveen K and Christophe, Cl{\'e}ment and Pimentel, Marco AF and Raha, Tathagata and Saadi, Nada and Javed, Hamza and Maslenkova, Svetlana and Hayat, Nasir and Rajan, Ronnie and Khan, Shadab},
  journal={arXiv preprint arXiv:2409.07314},
  year={2024}
}


@misc{ivison2023camels,
      title={Camels in a Changing Climate: Enhancing LM Adaptation with Tulu 2}, 
      author={Hamish Ivison and Yizhong Wang and Valentina Pyatkin and Nathan Lambert and Matthew Peters and Pradeep Dasigi and Joel Jang and David Wadden and Noah A. Smith and Iz Beltagy and Hannaneh Hajishirzi},
      year={2023},
      eprint={2311.10702},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{Athene2024,
    title = {Athene-70B: Redefining the Boundaries of Post-Training for Open Models},
    url = {https://nexusflow.ai/blogs/athene},
    author = {Frick, Evan and Jin, Peter and Li, Tianle and Ganesan, Karthik and Zhang, Jian and Jiao, Jiantao and Zhu, Banghua},    
    month = {July},
    year = {2024}
}

@article{hager2024evaluation,
  title={Evaluation and mitigation of the limitations of large language models in clinical decision-making},
  author={Hager, Paul and Jungmann, Friederike and Holland, Robbie and Bhagat, Kunal and Hubrecht, Inga and Knauer, Manuel and Vielhauer, Jakob and Makowski, Marcus and Braren, Rickmer and Kaissis, Georgios and others},
  journal={Nature medicine},
  volume={30},
  number={9},
  pages={2613--2622},
  year={2024},
  publisher={Nature Publishing Group US New York}
}


@article{zhou2023survey,
  title={A survey of large language models in medicine: Progress, application, and challenge},
  author={Zhou, Hongjian and Gu, Boyang and Zou, Xinyu and Li, Yiru and Chen, Sam S and Zhou, Peilin and Liu, Junling and Hua, Yining and Mao, Chengfeng and Wu, Xian and others},
  journal={arXiv preprint arXiv:2311.05112},
  year={2023}
}


@inproceedings{fleming2024medalign,
  title={Medalign: A clinician-generated dataset for instruction following with electronic medical records},
  author={Fleming, Scott L and Lozano, Alejandro and Haberkorn, William J and Jindal, Jenelle A and Reis, Eduardo and Thapa, Rahul and Blankemeier, Louis and Genkins, Julian Z and Steinberg, Ethan and Nayak, Ashwin and others},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={20},
  pages={22021--22030},
  year={2024}
}

@inproceedings{nimah2023nlg,
  title={NLG Evaluation Metrics Beyond Correlation Analysis: An Empirical Metric Preference Checklist},
  author={Nimah, Iftitahu and Fang, Meng and Menkovski, Vlado and Pechenizkiy, Mykola},
  booktitle={Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={1240--1266},
  year={2023}
}


@article{chen2023large,
  title={Large language models in biomedical natural language processing: benchmarks, baselines, and recommendations},
  author={Chen, Qingyu and Du, Jingcheng and Hu, Yan and Keloth, Vipina Kuttichi and Peng, Xueqing and Raja, Kalpana and Zhang, Rui and Lu, Zhiyong and Xu, Hua},
  journal={arXiv preprint arXiv:2305.16326},
  year={2023}
}


@article{kim2024prometheus,
  title={Prometheus 2: An open source language model specialized in evaluating other language models},
  author={Kim, Seungone and Suk, Juyoung and Longpre, Shayne and Lin, Bill Yuchen and Shin, Jamin and Welleck, Sean and Neubig, Graham and Lee, Moontae and Lee, Kyungjae and Seo, Minjoon},
  journal={arXiv preprint arXiv:2405.01535},
  year={2024}
}


@article{jeong2024olaph,
  title={OLAPH: Improving Factuality in Biomedical Long-form Question Answering},
  author={Jeong, Minbyul and Hwang, Hyeon and Yoon, Chanwoong and Lee, Taewhoo and Kang, Jaewoo},
  journal={arXiv preprint arXiv:2405.12701},
  year={2024}
}


@article{vijayakumar2016diverse,
  title={Diverse beam search: Decoding diverse solutions from neural sequence models},
  author={Vijayakumar, Ashwin K and Cogswell, Michael and Selvaraju, Ramprasath R and Sun, Qing and Lee, Stefan and Crandall, David and Batra, Dhruv},
  journal={arXiv preprint arXiv:1610.02424},
  year={2016}
}

@inproceedings{kwon2023efficient,
  title={Efficient memory management for large language model serving with pagedattention},
  author={Kwon, Woosuk and Li, Zhuohan and Zhuang, Siyuan and Sheng, Ying and Zheng, Lianmin and Yu, Cody Hao and Gonzalez, Joseph and Zhang, Hao and Stoica, Ion},
  booktitle={Proceedings of the 29th Symposium on Operating Systems Principles},
  pages={611--626},
  year={2023}
}

@article{wang2024chain,
  title={Chain-of-thought reasoning without prompting},
  author={Wang, Xuezhi and Zhou, Denny},
  journal={arXiv preprint arXiv:2402.10200},
  year={2024}
}

@article{suzgun2022challenging,
  title={Challenging big-bench tasks and whether chain-of-thought can solve them},
  author={Suzgun, Mirac and Scales, Nathan and Sch{\"a}rli, Nathanael and Gehrmann, Sebastian and Tay, Yi and Chung, Hyung Won and Chowdhery, Aakanksha and Le, Quoc V and Chi, Ed H and Zhou, Denny and others},
  journal={arXiv preprint arXiv:2210.09261},
  year={2022}
}

@inproceedings{wang2023towards,
  title={Towards Understanding Chain-of-Thought Prompting: An Empirical Study of What Matters},
  author={Wang, Boshi and Min, Sewon and Deng, Xiang and Shen, Jiaming and Wu, You and Zettlemoyer, Luke and Sun, Huan},
  booktitle={The 61st Annual Meeting Of The Association For Computational Linguistics},
  year={2023}
}

@article{li2024can,
  title={Can multiple-choice questions really be useful in detecting the abilities of LLMs?},
  author={Li, Wangyue and Li, Liangzhi and Xiang, Tong and Liu, Xiao and Deng, Wei and Garcia, Noa},
  journal={arXiv preprint arXiv:2403.17752},
  year={2024}
}

@inproceedings{kamalloo2023evaluating,
  title={Evaluating Open-Domain Question Answering in the Era of Large Language Models},
  author={Kamalloo, Ehsan and Dziri, Nouha and Clarke, Charles and Rafiei, Davood},
  booktitle={Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={5591--5606},
  year={2023}
}