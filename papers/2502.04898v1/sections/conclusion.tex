\section{Conclusion}
\label{sec:conclusion}
We have presented ARTInp, a novel framework for inpainting and translating CBCT images into synthetic CT images, consisting of two networks: a completion network that fills the gaps in CBCT images and a translation network that generates synthetic CT images from the inpainted CBCT images. 
We designed ARTInp to enhance the application of CBCT images in the ART workflow, particularly in complex treatments such as TMLI, where the target area spans on the whole body of the patient and an analysis over a large volume is crucial.

To evaluate the potential of ARTInp, we trained it on a dataset of paired CBCT and CT images made available for the SynthRad 2023 challenge \cite{Thummerer2023}.
In particular, the completion network was trained to inpaint CBCT images with artificial gaps, while the translation network was trained to generate synthetic CT images from paired CBCT images.
At inference time, the completion network was used to inpaint the CBCT images with artificial gaps, which were then fed to the translation network to generate the synthetic CT images, which were compared to the original CT images.
The performance of ARTInp is promising, with an MAE\% below 2.5\% and a PSNR around 27dB, suggesting that the quality of the synthetic CT images generated is similar to the one achieved by models with similar target tasks in the literature~\cite{edmund_review_2017}, but no other works presented the full pipeline, including the inpainting. 
In particular, when CBCT images are inpainted before generating the synthetic CT images, the final performance is only slightly degraded, showing that the inpainting process is effective.
Nevertheless, the SSIM values are below 0.8, and a qualitative analysis of the generated images shows the presence of artifacts and distortions such as blurriness and noise, limiting so far the possibility to apply the framework in clinical processes. 
Overall, the results suggest that ARTInp has the potential to enhance CBCT-based workflows in radiotherapy and is worth further investigation.

Future work will focus on investigating additional training strategies, such as training both networks together, as well as using more complex architectures, such as 3D networks and diffusion models~\cite{Wolleb2022}, to improve the quality of the generated images. 
Moreover, we plan to evaluate the performance of ARTInp on a specific clinical setting, such as TMLI, to assess its potential for enhancing the ART workflow in radiotherapy.
