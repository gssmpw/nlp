\section{Related works}
\label{sec:related}
Synthetic image generation has been a popular research topic since the surge of DL for computer vision tasks in recent years; in the medical field, solutions to generate synthetic CTs are typically based on Generative Adversarial Networks (GANs) or diffusion models \cite{Zhou2023, Wolleb2022}.
Domain transfer and modality generation are two of the most studied tasks, as the necessity for different imaging modalities for the same patient is often considered the optimal approach to correctly define several clinical situations, particularly in RT. 
Among existing works targeting image-to-image translation, MedGAN is one of the first end-to-end approaches \cite{Armanious2018} fully employing DL models successfully; it combines the adversarial loss of GANs with non-adversarial losses to build a framework that allows for PET to CT translation and noisy Magnetic Resonance (MR) refinement in a supervised scenario; from the same authors \cite{armanious2019}, an approach based on cycle consistent GANs (CycleGAN) \cite{zhu2017unpaired} is proposed to tackle a similar problem in an unsupervised setting, which is the most common in the medical field, as it is rather challenging to find paired data for different imaging modalities. 
In \cite{Wolterink2017}, an adapted version of CycleGAN was fed slices from the sagittal plane of different brain MRI modalities, stacked, to generate sCT; in \cite{Jin2019}, a double consistency cycle leads the networks to learn the generation of synthetic MR from CT comparing the synthetic ones with both paired and unpaired images in the discriminator's input; this forces the network to generate a synthetic image which is consistent with both modalities; more recently, another iteration featuring a multi-modal approach to CycleGAN can be found in \cite{Crespi2024}, where multiple branches are added to the generator to develop a multi-modal approach to sCT from MRI acquired with the Dixon method. 
Among works targeting specifically sCT from CBCT, in \cite{Maspero2020}, a CycleGAN approach is used to generate synthetic images that allow for dose calculation from only CBCT through the generation of sCT, focusing on the treatment planning; in \cite{Gao2021} the authors aimed at generating sCT from low-dose CBCT using pix2pix\cite{isola2017image} on paired sets of images and attention-guided GAN\cite{Tang2019} in a CycleGAN setting for the unpaired sets, validating the system with a similar attention to dose calculation; \cite{Deng2023} tried to improve the CycleGAN approach modifying the architecture with an auxiliary chain containing a diversity branch block; \cite{Liu2020} focus on CBCT-based adaptive planning, tackling the sCT generation with CycleGAN modified with self-attention blocks included in the generator; \cite{Gao2023} aims at eliminating streaking artifacts from CBCT to generate once again a sCT on which dose calculation is possible, proposing SARN, a novel architecture, in cascade with CycleGAN and attention-gated CycleGAN; 
in \cite{Fu2024} sCT generation with diffusion models is explored with an energy diffusion model whose de-noising process is performed with a ResUNet with attention blocks and an energy-guided function that retains modality-independent features from the images.

Several efforts can be found in the literature with the objective of inpainting medical images for different purposes. 
In \cite{Pedrosa2025}, an Anatomically-guided Contextual Attention inpainting Network (AnaCAttNet) is guided by anatomical structures to transform pathological tissue of the lungs into healthy tissue.
\cite{Xie2022} proposed a GAN, GatedConv, to inpaint a metal artefact in MRI of the dental implant patients. 
In \cite{Kim2024}, the focus is on inpainting parts of tissues excluded in the field of view of CT acquisition with Globally and Locally Consistent Image Completion (GLIC)\cite{glcic}, obtaining promising results on structural similarity index measure (SSIM). 
An approach based on diffusion models is shown in \cite{durrer2024denoisingdiffusionmodelsinpainting}, with denoising diffusion probabilistic models (DDPM) for the task of transforming tumorous brain tissue in MRI scans into healthy brain tissue. 
To our knowledge, no works have been tackling the inpainting and the sCT generation together. 
