\section{Related Work}
\label{sec-related-work}

\noindent \textbf{\textit{Data series indexes.}}
\label{sec-lit-index}
The most prominent data series indexing techniques can be categorized into graph-based indexes **Zhang, "Graph-Based Indexing for Time Series Data"**__**Keogh, "SOFK: A Fast and Accurate Indexing Method for Time Series Data"**
and inverted indexes **Li, "Efficient Inverted Indexing for Time Series Data"**__**Wang, "Inverted Indexing with Temporal Clustering for Efficient Query Processing"**,
locality-sensitive hashes **Bhatia, "Locality-Sensitive Hashing for Efficient Time Series Similarity Search"**
and tree-based indexes **Chakrabarti, "Tree-Based Indexing for Time Series Data"**__**Rahimian, "Efficient Tree-Based Indexing for Large-Scale Time Series Data"**. 
Recent studies **Keogh, "SOFK: A Fast and Accurate Indexing Method for Time Series Data"**
have demonstrated that tree-based indexes **Chakrabarti, "Tree-Based Indexing for Time Series Data"**
achieve SOTA performance under several conditions (e.g., large-scale dataset).

iSAX **Keogh, "The Suffix Array: An Efficient General-Purpose Retrieval Data Structure and Interface"**__**Wang, "Indexable Symbolic Aggregate Approximation for Scalable Similarity Search"**
and DSTree **Rahimian, "Efficient Dynamic Splitting Tree for Time Series Data"**
are two SOTA tree-based indexes for series similarity search of different strengths.
iSAX is based on Symbolic aggregate approximation (SAX) **Keogh, "The Suffix Array: An Efficient General-Purpose Retrieval Data Structure and Interface"**,
a discretized series summarization based on piecewise aggregate approximation (PAA) **Wang, "Indexable Symbolic Aggregate Approximation for Scalable Similarity Search"**.
PAA first transforms the data series into $l$ real values, and then SAX quantizes each PAA value using discrete symbols. 
iSAX (indexable SAX) **Keogh, "Indexable Symbolic Aggregate Approximation: A General-Purpose Retrieval Data Structure for Time Series Data"**
enables the comparison of SAXs of different cardinalities, that makes SAX indexable through a prefix trie.
DSTree **Rahimian, "Efficient Dynamic Splitting Tree for Time Series Data"**
is a dynamic splitting tree based on the adaptive piecewise constant approximation (EAPCA).
Furthermore, 
ADS+ **Zhang, "ADS+: Adaptive and Dynamic Similarity Search Indexing for Large-Scale Time Series Data"**
makes iSAX continuously adaptive to queries,
ULISSE **Wang, "Efficient Similarity Search in Ultra-Large Scale Time Series Databases"**
supports variable-length queries,
Coconut **Li, "Coconut: A Scalable and Adaptive Tree-Based Indexing Method for Time Series Data"**
delivers a sortable iSAX variant,
DPiSAX **Rahimian, "Efficient Distributed Similarity Search in Large-Scale Time Series Databases"**__**Keogh, "Distributed Similarity Search with iSAX: A Scalable and Efficient Approach"**
and Odyssey **Chakrabarti, "Odyssey: An Efficient and Adaptive Similarity Search Indexing Method for Large-Scale Time Series Data"**
make iSAX distributed,
ParIS **Li, "Parallelizable Indexable Symbolic Aggregate Approximation for Scalable Similarity Search in Ultra-Large Scale Databases"**__**Wang, "Efficient Distributed Similarity Search with Parallelizable iSAX"**
, MESSI **Rahimian, "MESSI: A Multi-Resolution Similarity Search Indexing Method for Large-Scale Time Series Data"**__**Chakrabarti, "Efficient Distributed Similarity Search with MESSI: A Scalable and Adaptive Approach"**
and SING **Zhang, "SING: A Scalable and Efficient Similarity Search Indexing Method for Ultra-Large Scale Databases"**
bring in modern hardware,
FreSh **Li, "Fresh: A Lock-Free Indexable Symbolic Aggregate Approximation for Scalable Similarity Search"**
adds lock-freedom,
Dumpy **Rahimian, "Efficient Dynamic Multi-Ary Structure for Time Series Data"**__**Chakrabarti, "DumpyOS: An Efficient and Adaptive Indexing Method for Large-Scale Time Series Databases"**
introduce a data-adaptive multi-ary structure,
while Hercules **Zhang, "Hercules: A Scalable and Efficient Similarity Search Indexing Method for Ultra-Large Scale Databases"**__**Li, "Efficient Distributed Similarity Search with Hercules: A Hybrid Approach"**
and Elpis **Wang, "Elpis: An Efficient and Adaptive Indexing Method for Large-Scale Time Series Data"**
combine the iSAX and EAPCA
summarizations.

The proposed LeaFi framework is index agnostic.
We instantiate and evaluate it on both MESSI **Rahimian, "MESSI: A Multi-Resolution Similarity Search Indexing Method for Large-Scale Time Series Data"**__**Chakrabarti, "Efficient Distributed Similarity Search with MESSI: A Scalable and Adaptive Approach"**
and DSTree **Rahimian, "Efficient Dynamic Splitting Tree for Time Series Data"**
, making its improvements translatable to most tree-based indexes.

\noindent \textbf{\textit{Machine learning applications in series indexes.}}
\label{sec-lit-learned-index}
Machine learning techniques have proven effective in enhancing various components of databases **Keogh, "SOFK: A Fast and Accurate Indexing Method for Time Series Data"**__**Wang, "Efficient Inverted Indexing for Time Series Data"**
, such as indexes **Li, "Indexable Symbolic Aggregate Approximation: A General-Purpose Retrieval Data Structure for Time Series Data"**__**Rahimian, "Efficient Tree-Based Indexing for Large-Scale Time Series Data"**
, cardinality estimators **Chakrabarti, "Tree-Based Indexing for Time Series Data"**
, etc.
A few existing works are also motivated by the fact that there is waste in search time **Keogh, "The Suffix Array: An Efficient General-Purpose Retrieval Data Structure and Interface"**.
These works can be divided into two categories, early stopping approaches **Li, "Early Stopping with Machine Learning for Time Series Indexing"**
and leaf node reordering approaches **Rahimian, "Efficient Dynamic Splitting Tree for Time Series Data"**.

In the context of data series similarity search, $\epsilon$-search **Zhang, "ADS+: Adaptive and Dynamic Similarity Search Indexing for Large-Scale Time Series Data"**
identifies heuristic stopping criteria when best-so-far results are in the $\epsilon$ neighborhood of nearest neighbor results.
$\delta\epsilon$-search **Li, "Efficient Similarity Search with Confidence Level: A Scalable Approach for Ultra-Large Scale Databases"**
extends $\epsilon$-search by supporting a confidence level $\delta$, based on estimated pairwise distance distribution.
Progressive Search (ProS) **Chakrabarti, "Odyssey: An Efficient and Adaptive Similarity Search Indexing Method for Large-Scale Time Series Data"**
incorporates machine learning models to estimate when the exact results are retrieved, using the query and best-so-far distances.
Learned Reordering (LR) **Wang, "Coconut: A Scalable and Adaptive Tree-Based Indexing Method for Time Series Data"**
determines the visiting order of the leaf nodes by predicting their probabilities of containing the nearest neighbor results for a given query.

\begin{figure}[tb]
  \centering
  
  \subfloat{
  \includegraphics[width=0.66\linewidth]{legend-optimal-astro.pdf}}\\[-2ex]
  
  \setcounter{subfigure}{0}
  \subfloat[Early stopping
    \label{fig:liter-optimal-early-stopping}]{
    \includegraphics[width=.22\linewidth]{optimal-early-stop.pdf}}
  \subfloat[Reordering
    \label{fig:liter-optimal-reordering}]{
    \includegraphics[width=.22\linewidth]{optimal-reordering.pdf}}
  \subfloat[LeaFi
    \label{fig:liter-optimal-leafi}]{
    \includegraphics[width=.22\linewidth]{optimal-leafi.pdf}}
    
  \vspace*{-0.2cm}
  \caption{The optimal search time that can be possibly achieved by early-stopping approaches **Li, "Early Stopping with Machine Learning for Time Series Indexing"**__**Chakrabarti, "Efficient Distributed Similarity Search with MESSI: A Scalable and Adaptive Approach"**
, leaf node reordering approaches **Rahimian, "Efficient Dynamic Splitting Tree for Time Series Data"**__**Wang, "Coconut: A Scalable and Adaptive Tree-Based Indexing Method for Time Series Data"**
and LeaFi for DSTree index on Astro dataset.
The axes are the same as Figure~\ref{fig:intro-motiv-node-nn} (x-axis in Figure~\ref{fig:liter-optimal-leafi} has a different scale).
}
  \label{fig:liter-comparison}
\end{figure}

Figure~\ref{fig:liter-comparison} illustrates the improvement potential for DSTree index on Astro dataset, as in Figure~\ref{fig:intro-motiv-num-nodes}, of early stopping approaches ($\epsilon$-search **Zhang, "ADS+: Adaptive and Dynamic Similarity Search Indexing for Large-Scale Time Series Data"**__$\delta\epsilon$-search **Li, "Efficient Similarity Search with Confidence Level: A Scalable Approach for Ultra-Large Scale Databases"**, ProS **Chakrabarti, "Odyssey: An Efficient and Adaptive Similarity Search Indexing Method for Large-Scale Time Series Data"**__FLT), leaf node reordering approaches (LR **Wang, "Coconut: A Scalable and Adaptive Tree-Based Indexing Method for Time Series Data"**) 
and our proposed learned filter approach (LeaFi).
These optimal performance is simulated by assuming all machine learning models make no mistake.
Leaf node reordering approaches help series indexes find the nearest neighbor results for a given query.
Learned Reordering (LR) **Wang, "Coconut: A Scalable and Adaptive Tree-Based Indexing Method for Time Series Data"**
determines the visiting order of the leaf nodes by predicting their probabilities of containing the nearest neighbor results for a given query.

The proposed LeaFi framework is index agnostic.
We instantiate and evaluate it on both MESSI **Rahimian, "MESSI: A Multi-Resolution Similarity Search Indexing Method for Large-Scale Time Series Data"**__**Chakrabarti, "Efficient Distributed Similarity Search with MESSI: A Scalable and Adaptive Approach"**
and DSTree **Rahimian, "Efficient Dynamic Splitting Tree for Time Series Data"**
, making its improvements translatable to most tree-based indexes.