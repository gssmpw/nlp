\section{Related Work}
\label{sec-related-work}

\noindent \textbf{\textit{Data series indexes.}}
\label{sec-lit-index}
The most prominent data series indexing techniques can be categorized into graph-based indexes____, 
quantization____ and inverted indexes____, 
locality-sensitive hashes____,
and tree-based indexes____. 
Recent studies____ have demonstrated that tree-based indexes____ achieve SOTA performance under several conditions (e.g., large-scale dataset).

iSAX____ and DSTree____ are two SOTA tree-based indexes for series similarity search of different strengths____.
iSAX is based on Symbolic aggregate approximation (SAX)____, a discretized series summarization based on piecewise aggregate approximation (PAA)____.
PAA first transforms the data series into $l$ real values, and then SAX quantizes each PAA value using discrete symbols. 
iSAX (indexable SAX)____ enables the comparison of SAXs of different cardinalities, that makes SAX indexable through a prefix trie____. 
DSTree____ is a dynamic splitting tree based on the adaptive piecewise constant approximation (EAPCA).
Furthermore, 
ADS+____ makes iSAX continuously adaptive to queries, 
ULISSE____ supports variable-length queries, 
Coconut____ delivers a sortable iSAX variant, 
DPiSAX____ and Odyssey____ make iSAX distributed, 
ParIS____, MESSI____ and SING____ bring in modern hardware, FreSh____ adds lock-freedom, 
Dumpy____ and DumpyOS____ introduce a data-adaptive multi-ary structure, 
while Hercules____ and Elpis____ combine the iSAX and EAPCA____ summarizations.

The proposed LeaFi framework is index agnostic.
We instantiate and evaluate it on both MESSI____ and DSTree____, making its improvements translatable to most tree-based indexes.

\noindent \textbf{\textit{Machine learning applications in series indexes.}}
\label{sec-lit-learned-index}
Machine learning techniques have proven effective in enhancing various components of databases____, such as indexes____, cardinality estimators____, etc.
A few existing works are also motivated by the fact that there is waste in search time____. 
These works can be divided into two categories, early stopping approaches____ and leaf node reordering approaches____.

In the context of data series similarity search, $\epsilon$-search identifies heuristic stopping criteria when best-so-far results are in the $\epsilon$ neighborhood of nearest neighbor results____.
$\delta\epsilon$-search extends $\epsilon$-search by supporting a confidence level $\delta$, based on estimated pairwise distance distribution____.
Progressive Search (ProS) incorporates machine learning models to estimate when the exact results are retrieved, using the query and best-so-far distances____.
Learned Reordering (LR) determines the visiting order of the leaf nodes by predicting their probabilities of containing the nearest neighbor results for a given query____.

\begin{figure}[tb]
  \centering
  
  \subfloat{
  \includegraphics[width=0.66\linewidth]{legend-optimal-astro.pdf}}\\[-2ex]
  
  \setcounter{subfigure}{0}
  \subfloat[Early stopping
    \label{fig:liter-optimal-early-stopping}]{
    \includegraphics[width=.22\linewidth]{optimal-early-stop.pdf}}
  \subfloat[Reordering
    \label{fig:liter-optimal-reordering}]{
    \includegraphics[width=.22\linewidth]{optimal-reordering.pdf}}
  \subfloat[LeaFi
    \label{fig:liter-optimal-leafi}]{
    \includegraphics[width=.22\linewidth]{optimal-leafi.pdf}}
    
  \vspace*{-0.2cm}
  \caption{The optimal search time that can be possibly achieved by early-stopping approaches____, leaf node reordering approaches____ and LeaFi for DSTree index on Astro dataset.
  The axes are the same as Figure~\ref{fig:intro-motiv-node-nn} (x-axis in Figure~\ref{fig:liter-optimal-leafi} has a different scale).
  }
  \label{fig:liter-comparison}
\end{figure}

Figure~\ref{fig:liter-comparison} illustrates the improvement potential for DSTree index on Astro dataset, as in Figure~\ref{fig:intro-motiv-num-nodes}, of early stopping approaches ($\epsilon$-search, $\delta\epsilon$-search, ProS and FLT), leaf node reordering approaches (LR), and our proposed learned filter approach (LeaFi).
These optimal performance is simulated by assuming all machine learning models make no mistake.
Leaf node reordering approaches help series indexes find the nearest neighbor results in the first node being visited and employ the tightest best-so-far distance.
However, as shown in Figure~\ref{fig:intro-motiv-node-nn}, a tight best-so-far distance provide marginal help in pruning more leaf nodes - most of the summarization-based lower bounds are still smaller than that. 
Early stopping approaches can terminate search right after the nearest neighbor results are retrieved, but it cannot reduce the search time before the retrieval. 

On the other hand, LeaFi helps series indexes to search only those leaf nodes that can update the best-so-far distances, as the tightest lower bounds are employed in pruning decision, hence attaining a significant and consistent improvement potential.
Moreover, as trained using the node-wise distance information instead of index-wise leaf node searching information, LeaFi can be efficiently trained using 2k examples (0.002\% of the collection), compared to 100k to 1m examples (0.1\% of the collection) in the literature____.
As far as we are aware, LeaFi represents the first framework that incorporates learned filters in data series indexes and provides substantial improvement in pruning ratio and search time.

FAISS Learned Termination (FLT) is an early-termination technique proposed for vector similarity search using kNN graphs____.
Its stopping criterion is predicted by a nontrivial expert-crafted feature set, which cannot be directly applied to tree-based series indexes, and, in contrast to LeaFi, it does not offer a mechanism to set search quality targets.



\noindent \textbf{\textit{Conformal regressions.}}
\label{sec-lit-conformal}
Conformal regression is a statistical approach that enhances existing regression methods by providing predictive intervals with a guarantee on their coverage probability____. 
It involves fitting a regression model to a dataset and then generating predictions that include an interval which, with a specified level of confidence (e.g., 95\%), is expected to cover the true target values. 
This process relies on the computation of nonconformity scores that measure how unusual new observations are compared to training data____.

However, the direct application of existing conformal regression techniques cannot help LeaFi support the user-requested search quality.
This is because the conformal prediction intervals are derived independently for each model, whereas achieving an expected target of a LeaFi-enhanced search result, e.g., 99\% recall, requires tuning all learned filters collaboratively at the same time.
Hence, in LeaFi, we further design our auto-tuning approach based on the conformal regression framework.
To the best of our knowledge, LeaFi demonstrates the first effort to introduce conformal regression techniques into the domain of learned indexes.