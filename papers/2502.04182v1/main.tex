\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts

\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{tikz}
\usepackage{subfig}
\usepackage{booktabs}
\usepackage{textcomp}
\usepackage{hyperref}
\usepackage{balance}
\usepackage{url}

\newtheorem{definition}{Definition}

\def\checkmark{\tikz\fill[scale=0.4](0,.35) -- (.25,0) -- (1,.7) -- (.25,.15) -- cycle;} 

\usepackage{xspace}
\def\scheme{\textsc{FFG}\xspace}



\begin{document}

\title{\Large Fast In-Spectrum Graph Watermarks}

\author{\IEEEauthorblockN{Jade Garcia Bourrée}
\IEEEauthorblockA{\textit{Univ Rennes, Inria, CNRS, Irisa}\\
Rennes, France
}
\and
\IEEEauthorblockN{Anne-Marie Kermarrec}
\IEEEauthorblockA{\textit{EPFL}\\
Lausanne, Switzerland
}
\and
\IEEEauthorblockN{Erwan Le Merrer}
\IEEEauthorblockA{\textit{Univ Rennes, Inria, CNRS, Irisa}\\
Rennes, France
}
\and
\IEEEauthorblockN{Othmane Safsafi}
\IEEEauthorblockA{\textit{EPFL}\\
Lausanne, Switzerland
}
}

\date{}

\maketitle

\begin{abstract}\small\baselineskip=9pt
We address the problem of \textit{watermarking} graph objects, which consists in hiding information within them, to prove their origin. The two existing methods to watermark graphs use subgraph matching or graph isomorphism techniques, which are known to be intractable for large graphs.

To reduce the operational complexity, we propose \scheme, a new graph watermarking scheme adapted from an image watermarking scheme, since graphs and images can be represented as matrices. 
We analyze and compare \scheme, 
whose novelty lies in embedding the watermark in the Fourier transform of the adjacency matrix of a graph. Our technique enjoys a much lower complexity than that of related works (i.e. in $\mathcal{O}\left(N^2 \log N\right)$), while performing better or at least as well as the two state-of-the-art methods. 
\end{abstract}

\maketitle

\section{Introduction}
\textit{Watermarking} is the art of hiding information within a digital object. Watermarking has proven to be efficient in embedding robust information in complex data~\cite{hartung1999multimedia, kumar2020recent}. Despite the explosion in the use of graph-structured data in various scientific fields~\cite{bonifati2022special,das2014tale,de2014r2g,cudre2011graph}, the research of \textit{graph watermarking} --- especially for unweighted graphs --- is still in its early stages~\cite{isc,COSN}.

Creating graphs requires extensive data collection and pre-processing, making them highly valuable assets. Graphs emerge from a wide range of applications, including webs of trust in blockchains, circles in social networks, and co-purchasing networks in e-commerce platforms. The creators of these graphs often seek recognition, similar to the practices encouraged by Creative Commons licences. Watermarking schemes can satisfy this demand by embedding provenance information as a digital signature that can be extracted later to prove ownership.

Despite its potential, the watermarking of graph objects remains uncommon. None of the popular online platforms that share graph representations~\cite{snapnets, konect, nr} currently propose watermarked graphs.
This is mainly due to the limited number of existing techniques that are too computationally expensive.
These techniques rely on intensive graph-related operations, such as subgraph matching and isomorphism~\cite{isc,COSN}.

In this paper, we introduce a competitive watermarking scheme inspired by image watermarking techniques~\cite{TIP}.
By treating adjacency matrices of graphs analogously to pixel matrices in images, we propose to leverage complexity-reduced computational operations for watermarking graph adjacency matrices. An overview of methods for watermarking graph-related objects is provided in the appendix~\ref{sec:related}.\\
\textbf{Contributions.} Our contributions are as follows.

1) We introduce a novel analytical framework that applies an image processing scheme directly to the adjacency matrices of graphs, with the aim of using operations faster than the NP-complete related complexities of the related works \cite{isc, COSN}.

2) The main technical challenge in applying an image watermarking technique in a graph context is related to the binary nature of an edge's presence in an adjacency matrix, as opposed to real numbers in an image matrix. This forces binarization. Our formal analysis studies the necessary binarization of the watermark to verify that it effectively leads to a unique watermark in the graph (i.e. without collision with another watermark insertion), setting the stage for the subsequent practical applications.

3) Finally, we perform a head-to-head comparison of \scheme with the related work in the graph domain (schemes by Zhao \textit{et al.}~\cite{COSN} and Eppstein \textit{et al.}~\cite{isc}). We conclude that \scheme performs at least as well as its competitors, with the advantage of being much faster.

\section{Goals and Threat Model}
\label{sec:goals}
 The following section describes watermarking schemes and the goals of such methods.
 
\subsection{Watermarking Graphs: Threat Model}

A graph watermarking scheme is a set of functions (\texttt{Keygen}, \texttt{Embed}, \texttt{Extract}), applied to a graph~\cite{isc}. With \texttt{Keygen}, the owner of a graph generates a secret key.
This key is embedded into her graph $G$ with the \texttt{Embed} operation. It produces a modified graph $G_W$ and a watermark $W$ (which is related to the difference between the original and the watermarked graph).
The graph's owner can prove her ownership of a suspected shared graph $G^*$ with the watermark $W$ using the \texttt{Extract} function. \texttt{Extract} returns a success if $G^*$ is watermarked with $W$. Otherwise, either 1) $G^*$ was not watermarked with $W$ and the considered watermarking scheme (or not watermarked at all), or 2) an attacker who wanted to prevent extraction has modified $G^*$ enough to prevent \texttt{Extract} from succeeding.

\subsection{Design Goals for Watermarking Schemes}
\label{ss:goals}

The goals of a watermarking scheme are as follows~\cite{COSN}: 
\paragraph*{(Goal 1) Low distortion}
The watermark embedding with \texttt{Embed} must have a low impact on the original graph to preserve the intrinsic value of that graph.

\paragraph*{(Goal 2) Watermark uniqueness}
The \texttt{Embed} function must be injective. In other words, a graph watermarked independently with two different keys should not produce two identical graphs.

\paragraph*{(Goal 3) False positives and negatives}
A good watermarking scheme must minimize false positives without generating too many false negatives. 

\paragraph*{(Goal 4) Robustness to modifications}
A robust watermarking scheme must be resistant to modifications (i.e. attacks) performed on the watermarked graph. More specifically, a key extraction (\texttt{Extract}) must work with a high probability, despite attacks.\\

Other goals such as undetectability and distortion effect are defined and studied in Appendix \ref{a:add-exp}. These are additional goals we set with respect to the state-of-the-art watermarking methods.

\section{\scheme: Cox \textit{et al.} Scheme for Graphs}
\label{sec:algo}

This work considers undirected and unweighted graphs, in order to compete with state-of-the-art schemes~\cite{isc,COSN} described in Section~\ref{ss:Zhao-Eppstein}.
Since the goal is to exploit watermarking schemes originally designed for images, we assume that we can label the input graph arbitrarily, so that a deterministic mapping of its vertices in the adjacency matrix can be performed~\cite{fekete2015reorder,hahsler2011dissimilarity}. This assumption is realistic in many cases where vertices are naturally labeled and it is consistent with the fact that for images, pixels have a deterministic position in their matrix representation.

\subsection{Framework Rationale}
Notations introduced hereafter are also summed up in Table~\ref{notations} and Figure~\ref{fig:schema} (Appendix~\ref{s:notations}).

The number of vertices of a graph $G=(V,E)$ is $N = |V|$.
The adjacency matrix $A$ of $G$ is a square matrix of dimension $N$x$N$. In an unweighted graph $G$, the adjacency matrix is binary: it contains only $0$s and $1$s. There is a $1$ in $A[i,j]$ if the edge $(i,j)$ exists, otherwise $0$. 
This matrix is then treated as an image. $A$ can be watermarked with any watermarking scheme from the image domain that uses on a Fourier transform as its base operation~\cite{TIP,joseph1998ruanaidh,pereira1999template,8918869,riaz2008invisible,soni2013image}. In this context, we use the Cox \textit{et al.} scheme~\cite{TIP} as it is a pioneering work. From this scheme we obtain a matrix $A'$, containing a watermark. $A'$ has the salient property of being composed of real numbers (rather than of binary values, such as in $A$). $A'$ is also no longer symmetric. 

Therefore, our framework includes additional steps to transform $A'$ back into an undirected and unweighted graph. Part of our challenge is to analyze the consequences of these steps.
More specifically, the required binarization is the thresholding of all values in $A'$ by the average of $A$. This real value is denoted $av(A)$. Each element is set to $0$ if its modulus is less than the average of the original adjacency matrix $A$, otherwise $1$.

Our framework yields a proper graph representation through its new adjacency matrix $A_W$. From this matrix, the resulting graph can be shared at will by the owner of the graph. \\

\par Next, we describe the original scheme of Cox \textit{et al.} for watermarking images, before detailing its adaptation to graphs in our framework.

\subsection{Watermarking Images with the Cox \textit{et al.} Scheme}
In~\cite{TIP}, the watermark is a sequence of a fixed number of random reals chosen from a Gaussian distribution.
The authors compute the Fourier transform of the original image and insert the watermark into the largest low-frequency coefficients of the transformed matrix. They propose three ways to insert the watermark into the highest magnitude coefficients, including a simple additive method.

For a given image (possibly modified), a watermark is extracted in the spectral domain and compared with the original watermark. A similarity score is computed, which decides whether this image is watermarked or not.

\subsection{The \scheme Scheme for Watermarking Graphs}

We now propose \scheme as an adaptation of the Cox \textit{et al.} scheme to be applicable to unweighted graphs.
We first present the three functions \texttt{Keygen}, \texttt{Embed} and \texttt{Extract}. The pseudocode is given in Algorithm~\ref{algo}.  We then discuss the main differences with the original Cox \textit{et al.} scheme.

\begin{algorithm}
\caption{\scheme scheme}
\begin{algorithmic}[1]
    {\small
    \Function{Keygen}{$m, \sigma$}
    \State $\omega = \left [ \mathcal{G}(0,\sigma^2), \ldots , \mathcal{G}(0,\sigma^2) \right ]$ \Comment{\scriptsize of length $m$}
    \State \textbf{Return} $\omega$
    \EndFunction
    \Function{Embed}{$ A, \omega$}
        \State $m = |\omega|$
        \State $th = av(A)$ \Comment{\scriptsize real number}
        \State FT(A) = Fourier transform of $A$
        \State $\chi = \texttt{argsort}(|FT(A)|)[0:m]$ \Comment{\scriptsize \texttt{argsort} returns the indices that would sort its argument}
        \State $\mathcal{W} [i, j] = \left . \begin{matrix}
                \omega [n] \text{ if there exists } n \leq m, \; \chi[n] = (i,j)\\ %  \text{else } 0
                \end{matrix}\right.$
        \State $A' = A + FT^{-1}(\mathcal{W})$
        \State $A_W [i, j] = \left \{ \begin{matrix}
               1 \text{ if } |A'[i,j]|>th\\ 
               \text{else } 0
               \end{matrix}\right.$ 
               \Comment{\scriptsize binarization}
        \State \textbf{Return} $A_W$
    \EndFunction
    \Function{Extract}{$A$, $A^*, \omega, \theta$}
        \State $A_W = ...$ \Comment{\scriptsize generated as in \texttt{Embed}}
        \State $W^* = FT(A - A^*)$
        \State $W = FT(A - A_W)$
        \State $s = \left\|W^* - W \right\|_2$
        \State \textbf{Return} $s \leq \theta*\left\| W \right\|_2$ \Comment{\scriptsize True: watermark retrieved}
    \EndFunction 
}
\end{algorithmic}
\label{algo}
\end{algorithm}

\paragraph*{Key generation}
\texttt{Keygen}$(m, \sigma)$ generates a key as a Gaussian vector of $m$ values with standard deviation $\sigma$. This step is identical to that of Cox \textit{et al.}.

\paragraph*{Watermark embedding} The graph owner wants to embed a key $\omega$ generated with the function \texttt{Keygen} into her graph $G$ thanks to its adjacency matrix $A$. First, the sequence $\chi = \{(i_1, j_1), \dots, (i_m, j_m)\}$ is computed as the sequence of the first $m$ indices that would sort the modulus of the Fourier coefficients of $A$. The sequence $\chi$ is used to compute the intermediate watermark $\mathcal{W}$ of the graph owner in the Fourier spectrum. $\mathcal{W}$  is the matrix representation of the key where each element $\omega[n]$ is at position $\chi[n] = (i_n, j_n)$.
Then, the Fourier inverse of the intermediate watermark  $\mathcal{W}$  is added to the adjacency matrix $A$ to obtain a real matrix $A'$. The algorithm continues with binarization and symmetrization to obtain $A_W$. The watermark $W$ is defined as the difference of all coefficients of the Fourier transform of $A$ and $A_W$:
$ W = FT(A) - FT(A_W).$

\paragraph*{Watermark extraction}
The suspected watermark $W^*$ is compared to the original watermark $W$ using the $2$-norm of their difference. If the difference between $W^*$ and $W$ is less than a threshold, the extraction is hypothetically successful.

\paragraph*{The specificity of \scheme}
The first difference between the original scheme of Cox \textit{et al.}~\cite{TIP} and \scheme is that the watermark key cannot be chosen arbitrarily, but instead depends on the binarization operation. What is left after binarization depends on the chosen length $m$ and the standard deviation $\sigma$ of the elements in that key. Recommendations in Cox \textit{et al.}~\cite{TIP} are no longer valid due to this binarization step. Section~\ref{ss:distorsion} discusses how to properly obtain a key.

The second specificity is also due to the binarization step. This step causes the key to be spread over the entire transformed matrix. As a consequence: $\mathcal{W} \neq W.$
Thus, the watermark is defined over all matrix coefficients and not only over the ones specified by $\chi$.
The function \texttt{Extract} is applied to the watermark $W$ resulting from the binarization after embedding $\omega$ with the Cox \textit{et al.} scheme, and \textbf{not} applied directly to the key $\omega$ in the coefficients specified by $\chi$.
Given the key $\omega$, the watermark $W$ can be derived by the embedding function or by calling \texttt{Extract} before comparing to $W^*$.

\subsection{Scheme complexity vs related works}\label{ss:complexity} The main advantage in applying an image watermarking technique in a graph context is the time complexity of the watermarking scheme, which uses vertex labels to have a consistent mapping in the adjacency matrix. The function \texttt{Keygen} is  executed in constant time in $m$ operations where $m$ is the length of the desired key as in Cox \textit{et al.} In \texttt{Embed}, the worst-case time complexity of the Fourier operations (l.7 and l.10) and the sorting operation to compute $\chi$ (l.8) are linearithmic in the number of coefficients of their inputs. That is to say, their complexities are $\mathcal{O}\left( N^2 \log N\right)$ since they are applied to matrices of dimension $N$x$N$. The time complexity of all other operations in \texttt{Embed} are at most linear in the number of coefficients of their inputs. That is to say, the worst-case time complexity of \texttt{Embed} is $\mathcal{O}\left( N^2 \log N\right)$. The function \texttt{Extract} uses the same operations as in the function \texttt{Embed}, with the addition of computing the $2$ norm of the difference between two matrices of dimension $N$x$N$, which is linear in the size of the object. The worst-case time complexity of \texttt{Extract} is thus also $\mathcal{O}\left( N^2 \log N\right)$.

For comparison, the scheme from Zhao \textit{et al.} leverages the NP-complete subgraph matching routine. They argue that the computational complexity is lower on graphs with a "very high level of node heterogeneity" in terms of degrees, without providing a complexity analysis for this claim (see \cite{COSN}, Section 4); the problem still remains NP-complete in the general case.
While Eppstein \textit{et al.} \cite{isc} prove the correctness of their scheme for Erdős-Rényi and power-law graph families, they do not provide a bounded complexity analysis for these, and thus also remain in the NP-complete complexity class due to the subgraph isomorphism routine.
All three schemes are compared in terms of their practical execution times in Section~\ref{sss:timings}.

\section{Experiments: Compliance to Design Goals}
\label{sec:experiments}

This section presents the results of an extensive experimental study of \scheme.
It is organized to shed light on the practical compliance of \scheme to the design goals detailed in Section~\ref{ss:goals}.

\subsection{Experimental Setup}

Experiments are performed using Python 3. Reported timings are obtained from execution on a server equipped with Intel Xeon E5-2630 v3 CPUs, running at 2.40GHz.

\paragraph*{Graph generative models}
For experiments that require the variation of a graph property, graph generators from the Python package NetworkX~\cite{hagberg2008exploring} are used. These are well-known graph models, that have been used to model various real-world graphs: Erdős-Rényi (hereafter referred to as ER), Barabási-Albert (BA), or Watts-Stroggats (WS) models.

\paragraph*{Large and real graphs}
Experiments with \scheme are also performed on eight real-world large graphs with different edge densities, obtained from the SNAP repository~\cite{snapnets} (e.g. Pokec) and the NetworkRepository~\cite{nr} (e.g. Flickr). These graphs have different structures, which makes them interesting to study.

\paragraph*{Evaluation metrics} The properties and information to preserve are highly context-dependent, depending on the intended use of a graph.  It is impractical to cover all possible scenarios. Due to its generality and widespread use in the state-of-the-art~\cite{isc,COSN}, we consider the graph \textit{edit distance}, as a metric to quantify the degradation of a graph after these attacks:

\paragraph*{Definition.} The graph \textit{edit distance} (denoted ED) is the percentage of edges that distinguish two graphs. In the sequel, the distance is measured relative to the original graph.


For instance, if the $embed$ function flips $200$ edges from a graph $G$ containing $2,000$ edges, then the distance based on the fraction of edges between $G'$ and $G$ is $10\%$ edges. 
We emphasize that the ED can be greater than $100$\% because we can add edges and not just remove them. In fact, one can flip at most $N(N-1)/2$ edges from the input graph.

\subsection{Adaptations from the Theoretical Scheme}\label{ss:exp}
\subsubsection{\scheme Scalability}
\label{ss:scalability}

To increase the scalability of their schemes when applied to large graphs, both related works~\cite{isc,COSN} filter out the input graph to operate on a smaller set of vertices. Inspired by the Cox \textit{et al.} scheme~\cite{TIP} \scheme also performs a dimensionality reduction. This step is described in detail in the Appendix~\ref{a:reduction}.

We empirically evaluate the scalability of \scheme by increasing the size of the input graph from $N=10^3$ to $10^7$. To maintain a similar graph structure as the size increases, a BA graph generator is used. Its attachment parameter is set to $3$ (i.e. each new vertex attaches to $3$ existing vertices according to preferential attachment). The length of the key is arbitrarily always the same ($m = 200$) because all the graphs have the same attachment parameter (see Section \ref{ss:distorsion}).

The measured timings are as follows. For embedding: $0.20,~18,~20,$ $46$ and $358$ seconds for BA with sizes $1k,~10k,~100k,~1M$ and $10M$ respectively. For extraction, and the same graph sizes: $0.13,~15,~16,~17$ and $20$ seconds. The execution time of the key generation is almost constant at $0.8$ milliseconds.
These observations are fully consistent with the timing complexity analysis, and therefore confirm that our \scheme is tractable for large graphs.

\subsubsection{Resilience to Attacks and the Similarity Threshold}\label{sss:theta}
As in the original Cox \textit{et al.} scheme and in the related work~\cite{COSN} and~\cite{isc} for graphs, there is a \textit{threshold} parameter $\theta$ driving the success of the extraction function in Algorithm~\ref{algo}. The following paragraphs deal with this parameter $\theta$.
\paragraph*{The ideal case: the watermarked graph is never attacked.} We demonstrate that if attacks on $G_W$ are not considered, $\theta = 0$ can be set with the guarantee that the watermark of the graph's owner will always be extracted. That is, considering unattacked watermarked graphs, no false negatives can occur.

\par \textit{Proof.} A false negative occurs if \texttt{Extract} returns a failure even though the tested graph was indeed watermarked with a given watermark. In particular, the extraction will fail only if the following condition is not satisfied:
    $\left\|W^* - W \right\|_2 \leq \theta*\left\| W \right\|_2,$
where $W^*$ and $W$ are computed according to Algorithm~\ref{algo}, and while the tested graph $G^*$ \textbf{is} the watermarked graph $G_W$, that has not been attacked. Thanks to the deterministic mapping of vertices to adjacency matrices, $A^* = A_W$. Since the Fourier transform is linear, the condition $\left\|W^* - W \right\|_2 \leq \theta*\left\| W \right\|_2,$ becomes: $0 \leq \theta*\left\| W \right\|_2$, which always holds since $\theta \geq 0$. Thus if $\theta = 0$, no false negatives can occur with the \scheme scheme.

\paragraph*{A realistic case where the watermarked graph is attacked} In a real scenario, after the owner of a graph shares her watermarked graph, it can be modified. A false negative occurs when \texttt{Extract} returns a failure, despite the tested graph was indeed watermarked with the owner's watermark.
In this case, $\theta > 0$ defines the similarity above which the graph's owner considers the extracted watermark to be close enough to the original one, despite modifications.

We set $\theta$ to tolerate $10$\% edge flips, which is clearly a conservatively high value (according to related work~\cite{isc,COSN}, as and it will be illustrated in Section \ref{ss:distorsion}). Consequently, no false negatives can occur with less than $10$\% edge flips.
The effect of $\theta$ on false positives is studied in Section~\ref{ss:FPFN}.

\subsection{(Goal 1) Low Distortion}\label{ss:distorsion}
We now experiment with the distortion caused by embedding the watermark in a given graph. We study it theoretically in Appendix~\ref{s:theory}.

\paragraph*{Practical guidelines for low distortion}\label{p:fixed_params}
From Section~\ref{ss:goals}, low distortion is targeted for the watermark embedding. According to related work~\cite{isc,COSN}, the ED of large graphs must be at most $10^{-2}$\% edges. We now give a method to automatically set the parameters suitable for watermarking with such a minimal distortion. 

Figure~\ref{fig:existence} illustrates the link between $\sigma$ and $m$ for our three generative graph models, and a small distortion of $0.005\%$ edges.

Key lengths used in~\cite{isc} depend on \textit{densities} (being defined as the number of edges over the number of vertices) \cite{melancon2006just}, while those of~\cite{COSN} depend on the number of vertices. We set the key length $m$ of \scheme as the key length used in~\cite{isc} because the experiment in Section~\ref{exp:unique} shows that \scheme is also related to densities.

Once the key length $m$ is set as in~\cite{isc}, it is always possible to find a value of $\sigma$ to watermark the graph while achieving the distortion goal. Experiments have shown that for any graph $G$ and for any fixed key length $m \in [\![1, N_0*(N_0-1)/2]\!] $, there exists a value $\sigma_{max}$ to watermark the graph with a strictly positive edit distance. An automated way to set $\sigma$ under the small ED constraint is to use a dichotomous search in $[\![1, \sigma_{max}]\!]$. As shown in Appendix~\ref{a:reduction}, the proposed guidelines do not affect the scalability of \scheme.

\begin{figure}[t!]
\centerline{\includegraphics[width=0.9\linewidth]{pics/picswithoutFont3/666_0_A1.pdf}}
\caption{The relation between $m$ and $\sigma$ to watermark graphs with an ED $\in ]0,0.005[$ \% of edges, for the three graph models.}
\label{fig:existence}
\end{figure}

\begin{table}[ht!]
 \begin{center}
 \begin{tabular}{|c|c|c|c| }
 \hline
  Graph & $m$ & $\sigma$ & Watermarking ED\\
  \hline
  BA & $210$ & $1,750$ & $3.10^{-8}$\\
  Flickr & $3,250$ & $32,000$ & $2.10^{-8}$\\
  Pokec & $170$ & $7,000$ & $5.10^{-9} $\\
  \hline
 \end{tabular}
 \end{center}
 \caption{Parameters and resulting distortion (ED).}
 \label{keysetting}
 \end{table}


The three large and real graphs are watermarked using this method, leading to the parameters in Table~\ref{keysetting}. Note that the values of $m$ differ significantly between graphs, depending on their inner topological properties. The resulting EDs are effectively kept well below the target of $10^{-2}$\%.
Goal 1 is thus achieved.

Further experiments on the impact of \scheme on graphs are studied in Appendix~\ref{a:add-exp}.

\subsection{(Goal 2) Uniqueness of Watermarks}
\label{exp:unique}

To assess the uniqueness property resulting from \scheme, two keys $\omega_1$ and $\omega_2$ are generated with the same parameters ($m$ and $\sigma$) found by the automatic dichotomous procedure. There is a lack of uniqueness if the two keys result in the same watermark (i.e. if $\omega_1 \neq \omega_2$ and $G_{W_1}=G_{W_2}$).

We experiment with uniqueness for the three graph models and various graph densities in Figure~\ref{fig:uniqueness}. 
There are some collisions for the lowest densities, beyond $2$. 
This is not an issue per se, as these graphs are rare or atypical: a density less than $2$ means that a graph has, or is close to having, disconnected components.
Above this threshold, there is no collision; this is the expected setup, since collected graphs generally have high densities (\textit{e.g.,} from 12 to 36 in web crawls \cite{melancon2006just}, or without density limit for graphs studied in node classification, where edges are even removed to reduce the density before processing~\cite{li2022graph}). Goal 2 is thus validated for practical setups.

\begin{figure}[ht]
\centerline{\includegraphics[width=0.9\linewidth]{pics/667_None_S1_m.pdf}}
\caption{Success rate ($y$-axis) in inserting a unique watermark in three graph models, for 1M vertices graph models and different densities on the $x$-axis.
}
\label{fig:uniqueness}
\end{figure}

\subsection{(Goal 3) Low False Positives and Negatives}\label{ss:FPFN}
We now study the effect of $\theta$ on false positives.

Let $G_W$ be the watermarked graph of $G$ with the key $\omega$, and $G^*$ be any other graph \textbf{not} watermarked with $\omega$. Recall that Algorithm \ref{algo} with $G^*$ results in a false positive if the extraction of $W$ in $G^*$ succeeds.

\begin{figure}[ht]
\centerline{\includegraphics[width=0.7\linewidth]{pics/2179_E3_m.pdf}}
\caption{The impact of $\theta$ on extraction false positives (BA graphs).}
\label{fig:choiceT}
\end{figure}


The goal of the following experiment is to determine the value of $\theta$ for which false positives occur when attempting an extraction on non-watermarked graphs. Ten BA graphs are generated with density $\frac{|E|}{|V|} = 5$ (according to the uniqueness experiment in Figure~\ref{fig:uniqueness}). For each of them, we first inserted a key $\omega$; then we re-generated five more graphs with the same generative parameters, and tried to extract $\omega$ from them. Extractions are performed for different values of $\theta$. Figure~\ref{fig:choiceT} shows that as long as $\theta$ is less than or equal to $5$, there are no false positives. Then, values of $\theta$ above $6$ introduce some. Thus, $\theta = 1.4$ is consistent with the $2$-norm of the watermark to tolerate $10$\% edge flips for a graph of density $5$ in BA models. Goal 3 is then achievable by parameterization.

In the remaining experiments, $\theta$ is set to tolerate $10$\% edge flips since no false positives or false negatives occur in this setup.

\subsection{(Goal 4) Robustness to Attacks}

\subsubsection{Intensity and Impact of the Attack}
\label{ss:impact}
In order to assess a plausible intensity of an attack that a graph can sustain without losing its utility, we show in Figure~\ref{fig:spearman} a simple function performed on the three first graphs of Table \ref{expres}: the ranking of the top-$1000$ nodes according to the \textit{degree centrality}~\cite{das2018study}.
The figure plots the changes in this ranking of the most central nodes, according to the classic Spearman metric~\cite{diaconis1977spearman}. It measures the correlation between two rankings of the top nodes (on the original graph and on the attacked version). 
The correlation drops dramatically as the attack increases, with even the low value of $1\%$ of edges flipped. 
Thus, it appears that this random attack disrupts the connectivity of the central nodes, clearly questioning the usefulness of the resulting graph.
In this context, $10\%$ of flipped edges is an extreme attack that appears to remove the utility of the graph, and can thus be considered a very conservative upper bound.

\begin{figure}[h!]
\centerline{\includegraphics[width=.8\linewidth]{pics/0_16_A6_.pdf}}
\caption{The effect of an edge flipping attack on three real graphs, regarding the degree centrality of the top-1000 most central nodes. The $\%$ of edges flips appears on the $x$-axis, while the Spearman correlation of the top-1000 ranking appears on the $y$-axis.}
\label{fig:spearman}
\end{figure}


\subsubsection{Robustness}
The performance of \scheme is reported on real large graphs in Table~\ref{expres}.

The key lengths are similar to those used in Eppstein \textit{et al.}~\cite{isc} and standard deviations are set to target watermarks that cause little distortion. Despite their various densities, all of them were watermarked with indeed small distortions (EDs of $10^{-6}$ at the very least, most often at $10^{-8}$, and even as low as $10^{-10}$ for the graph "inf-belgium-osm"). 

\begin{table*}[ht]
\begin{center}
\scalebox{.8}{
\begin{tabular}{|c|c|c|c|c|c|c|c| }
 \hline
 Graphs & $|V|$ & $\frac{|E|}{|V|}$ &$m$ & $\sigma$ & ED & $\theta$ & $Suitability$\\
 \hline
 inf-belgium-osm & 1.4M & 1.1 & 54 & 250 & $3.10^{-10}$ & 0.6 & \checkmark\\
 soc-YouTube-ASU & 1.1M & 2.6 & 200 & 12,000 & $1.1.10^{-8}$ & 2 & \checkmark\\
 hollywood-2009 & 1.1M & 52.7 & 162 & 224,000 & $1.6.10^{-8}$ & 205 & \checkmark\\
 rgg-n-2-20-s0 & 1M & 6.6 & 119 & 1,624 & $3.8.10^{-8}$ & 10.2 & \checkmark\\
 kron-g500-logn20 & 1M & 42.6 & 71128 & 16,000 & $3.5.10^{-8}$ & 374 & \checkmark\\
 scale21-ef16-adj & 1.2 M & 51 & 44,743 & 12,000 & $1.7.10^{-8}$ & 233 & \checkmark\\
 roadNet-PA & 1.1M & 1.4 & 48 & 184 & $6.10^{-6}$ & 0.6 & \checkmark\\
 delaunay-n20 & 1M & 3.0 & 63 & 61 & $4.3.10^{-8}$ & 6.2 & \checkmark\\
 \hline
\end{tabular}
}
\end{center}
\caption{Experiment settings and results for \scheme, on real large graphs. }
\label{expres}
\end{table*}

We now subject these graphs to attacks and observe the resilience of \scheme.
The last column $Suitability$ shows that the extractions are successful despite the attack. 
We also note that additional tests have shown that all watermarks can as well be extracted even under an attack that flips $100$\% edges, for a value of $\theta$ set to be resistant to only $10$ \% edge flips. This underscores the robustness of \scheme, and the reach of Goal 4.

This experimental section confirms both the applicability of \scheme to real graphs, the low distortion of the scheme on these graph structures, and its resilience to significant attack strengths.



\subsubsection{Densities and the Resulting Threshold}
The last experiment for \scheme is to test its robustness to different graph densities, for the three graph models. We take the three graph generators (BA, WS, ER) and vary the density $\frac{|E|}{N}$ of graphs to $5$, $30$ and $50$. $5$ is a low density which respects the uniqueness condition, $30$ and $50$ are medium and high densities according to~\cite{melancon2006just} and the graphs taken from SNAP~\cite{snapnets}. For each generator and each density, we set $\theta$ to be resistant to $x$\% edge flips ($x$-axis). This resilience is observed on $3$ runs per point on Figure~\ref{fig:Tdensitymodel}, where $\theta$ is set by a dichotomous search for the effective resilience to the attack.

\begin{figure}[h!]
\centerline{\includegraphics[width=\linewidth]{pics/picswithoutFont3/4931_2408_7055_8367_23_6320_3668_8728_8992_1153_8624_8358_2577_None_grid.pdf}}
\caption{The choice of $\theta$ in \scheme to be resistant to $x$\% edge flips depending on the density and the type of  graph model.}
\label{fig:Tdensitymodel}
\end{figure}

Figure~\ref{fig:Tdensitymodel} shows that the resulting threshold $\theta$ depends primarily on the type of graph. For BA or WS graphs, a setting $\theta = 1$ is sufficient for \scheme to be resistant to attacks with up to $10\%$ edge flips ($x$-axis), regardless of the density of the original graph.
Density is the most relevant parameter when watermarking ER graphs, where $\theta$ can vary from $0.3$ to $5$ to be resistant to attacks of up to 10\% edge flips.

\section{A Comparative Benchmark}
\label{sec:benchmark}
Finally, we perform a head-to-head comparative benchmark of \scheme with the two state-of-the-art approaches~\cite{COSN} (Zhao) and~\cite{isc} (Eppstein), both in terms of running time and resilience to attacks.

\subsection{Related work}\label{ss:Zhao-Eppstein}

\paragraph*{The scheme by Zhao \textit{et al.}~\cite{COSN}} There are four steps in the graph embedding function of Zhao \textit{et al.}~\cite{COSN}.
First, they generate a random seed based on cryptographic keys. Then, they generate a random watermark graph (Erdős-Rényi) using the seed and match it with a subgraph of $G$. The subgraph selection is based on the structure of the vertices (i.e. their neighborhoods). Finally, the embedding is performed by an XOR operation between the subgraph and the random watermark graph.
For the extraction, they regenerate the watermark graph and the subgraph like in the embedding process. After that, they identify in the potential $G^*$ which vertices are candidates to match the subgraph (again using the vertex structure). Finally, they extract the watermark using a recursive algorithm.
Since the code was not provided by the authors, we implemented it in Python 3. We note that our execution results are consistent with those presented by the authors in their experimental section (Figure 2b in \cite{COSN}). We set $\theta=0.95$ and $B=25$, for an acceptable execution time.

\paragraph*{The scheme by Eppstein \textit{et al.} ~\cite{isc}} The scheme of Eppstein \textit{et al.}\cite{isc} consists of the same three functions \texttt{Keygen,} \texttt{Embed} and \texttt{Extract} as the \scheme scheme. In the scheme of Eppstein \textit{et al.}, private keys generated by the \texttt{Keygen} function are sets of vertex pairs in a graph containing as many vertices as in the graph to be watermarked. There are three main steps in the embedding function. The first step is ordering and labeling the vertices of the graph, considering degrees and using bit vectors. The vertices are divided into three categories: high, medium, and low degree vertices. Then, each edge contained in the private key is randomly flipped according to the probability of its statistical existence in the graph. The function \texttt{Extract} uses graph isomorphism to identify the watermarked graph. Unlike \scheme and Zhao~\cite{COSN}, this method identifies a graph between multiple (simultaneously created) watermark copies, not just a single watermark graph with a given key. The selected copy is the closest copy considering the Hamming distance.

\subsection{Execution Timings}
\label{sss:timings}

We first benchmark the runtime of the \texttt{Embed} and \texttt{Extract} functions of the competing watermarking schemes. The keys are generated according to the recommendations in each paper; their timings are not displayed, as they are all very fast.
Scalability improvements suggested by each paper have been implemented. 
\begin{figure}[h!]%
    \centering
    \subfloat[Execution timings\label{fig:timings}]{{\includegraphics[width=0.49\textwidth]{pics/fig6a_E6_all.pdf} }}%
    \qquad
    \subfloat[Robustness\label{fig:edgesflips}]{{\includegraphics[width=0.49\textwidth]{pics/picswithoutFont3/123_None_A1.pdf} }}%
    \caption{Benchmark comparison between \scheme, Eppstein~\cite{isc}, and Zhao~\cite{COSN}. (a) Timing ($y$-axis) of the \texttt{Embed} and \texttt{Extract} functions for the three competing schemes, depending on the BA graph size $N$ ($x$-axis). Executions taking less than the timeout (fixed at 25 minutes) are kept and plotted. (b) Robustness of the three schemes ($y$-axis) facing attacks: the normalized number of successful extractions, facing increasing edge flips (measured by edit distance on the $x$-axis as ratio of edges) on three large graphs.
        }
    \label{fig:example}%
\end{figure}

In Figure~\ref{fig:timings}, timings are measured in seconds as a function of the number of vertices $N$ in an increasing size BA graph (from $1k$ to $10M$ vertices, with an attachment parameter of $3$).
We set a timeout of $25$ minutes for the experiments (dotted gray horizontal line), so that all scheme executions --each running on a single core-- are discarded if they exceed this threshold.
For small and medium-sized graphs ($N \leq 10^5$), the embedding function of Zhao \textit{et al.} is the most efficient method, while its extraction takes the longest. For medium and large graphs (more than $10^5$ vertices), the \scheme scheme outperforms the state-of-the-art. Without exceeding the timeout, \scheme can watermark graphs with $10$ times more vertices than the scheme of Eppstein \textit{et al.} and up to $100$ times more vertices than the scheme of Zhao \textit{et al.}\\
Note that extractions are performed on a non-attacked $G_W$, which is the most favorable scenario for the schemes of Eppstein \textit{et al.} and Zhao \textit{et al.}: their extractions are longer when applied to attacked graphs, because the approximate subgraph matching is harder (while the matrix representation in \scheme makes it time-invariant to attacks). 
The extractions of Zhao \textit{et al.} and Eppstein \textit{et al.} are linear in the number of vertices, while \scheme is almost constant after $10k$ vertices.

Even though Zhao \textit{et al.} and Eppstein \textit{et al.} also perform dimensionality reduction, they use approximate subgraph isomorphism in the extraction, which is computationally expensive, if not intractable (NP-complete) for increasingly large graphs. \scheme relies on vertex labels (in parallel with images) to avoid such a tedious operation and then works significantly faster.



\subsection{Robustness to the Edge Flip Attack}
\label{ss:zhao}
In Table~\ref{expres}, we observed that \scheme is resistant to $100$\% edge flips on real graphs. (Recall that $100\%$ is relative to the number of edges in the original graph, which here means that $|E|$ edges were flipped among the $N(N-1)/2$ possible flips.)
Since Zhao and Eppstein schemes can at best achieve this resilience, we now test the watermark extractions of the three schemes, despite attacks on three watermarked graphs.

Figure~\ref{fig:edgesflips} shows the results for the three large graphs.
The success rate is shown on the $y$-axis. The $x$-axis shows the number of edges flipped, measured by the ED. Each experience is run three times (the standard deviation is zero, as there is no variation in the results across all the performed executions).

We observe that \scheme performs better than the scheme of Zhao \textit{et al.} for the three graphs. The scheme of Zhao \textit{et al.} fails before $10$\% edges are flipped, while \scheme handles flips equivalent to $100\%$ edges. 
\scheme also beats the Eppstein scheme, except on the Flickr graph where Eppstein survives $1000\%$ of flips.

We conclude that \scheme is at least as robust --except on one configuration--, if not better, against random edge flips than its two competitors. Overall, the high robustness of \scheme (resilience $\geq100\%$ of flipped edges, see Table~\ref{expres} and Figure~\ref{fig:example}b) makes it practical even in scenarios with extreme attack strengths.

\section{Conclusion}
\label{Conclusion}

Large and real graphs are valuable assets that can be tracked for provenance using watermarking techniques. This paper bridges the gap between the image processing and the graph domains. While previous state-of-the-art schemes
relied on standard graph manipulations,
we have shown that knowledge and techniques from the multimedia community can be ported to the graph domain, yielding significant complexity improvements. This is achieved by studying the transitions between a graph and its real-valued image-like representation, and vice versa. 
Our method \scheme shows strong performance on several metrics, including low false positives and negatives.

For future work, our framework can be extended with other binarization methods, such as the optimized thresholding method proposed by Otsu~\cite{Otsu}. This may lead to even smaller watermarks,
which is crucial for minimizing distortions in the watermarked graph. Another promising direction is to adapt recent image watermarking schemes to our framework. 

\bibliographystyle{plain}
\bibliography{references}

\newpage

\input{appendix}

\end{document}