% !TEX root = paper.tex
\section{Introduction}

% Problem of interest: motivate

Let $A$ be any weighted set of $n$ elements. Each element in $A$ is associated with a weight using the function $w:A\rightarrow [0,\infty)$. Given an input parameter $t>0$, the problem of estimating the $t$-th moment of $A$, expressed as $S_t=\sum_{a\in A} w(a)^t$, is called the {\it moment estimation} problem\footnote{The $t$-th moment of $A$ is also defined as $S_t=1/n \cdot \sum_{a\in A} w(a)^t$. We follow $S_t=\sum_{a\in A} w(a)^t$ for simplicity of calculations \cite{ERS2019}.}. In this work we study the moment estimation problem in a model in which we don't have direct access to the weights of the elements in $A$, instead we get indirect access to the weights using samples from an oracle. Our objective is to obtain a good approximation of the $t$th moment $S_t$ of $A$ while making a small number of queries to the oracle. 

% motivate sublinear

Estimation tasks on very large datasets are often performed using samples from the dataset. One common objective in these settings is to compute an approximate answer using only a small number of samples. Sublinear algorithms are algorithms that access only a tiny portion of the data (sublinear in the input size) and compute an approximate answer. For many problems of interest, uniform sampling-based algorithms require a lot of samples, and hence might not be very useful in designing sublinear algorithms where as weighted sampling-based algorithms often give better performance guarantees. This is the case, for example, for the sum estimation problem. Uniform sampling-based approaches require $\Omega(n)$ samples for the sum estimation problem in the worst-case where as weighted sampling-based algorithms require only $O(\sqrt{n}/\eps)$ samples \cite{MPX2007,BT2022}. This, however, uses the assumption of access to a stronger query oracle that returns samples according to a weighted distribution. In applications where access to such a stronger query oracle is available, one might use the above algorithms with better performance guarantees. One such use case is the parameter estimation problems on graphs where one is given access to a random edge sampling oracle. Details about using weighted sampling for graph parameter estimation problems and other application areas can be found in \cite{MPX2007,ABGPRY2018,BT2022}.

% problem definition
In this work we study the sample complexity of estimators for the moment estimation problem assuming access to a proportional sampling oracle on the set $A$. Proportional sampling on set $A$ returns an element $a\in A$ with probability proportional to $w(a)$. Let $W=\sum_{a\in A} w(a)$. Using proportional sampling an element $a\in A$ is chosen with probability $w(a)/W$. Next, we formally define the moment estimation problem that we study in this work.

\begin{defn}$((\eps,\delta)-\text{Moment Estimation})$ Given sample access to a set $A$ of $n$ weighted elements and input parameters $\eps,\delta\in (0,1)$, $t>0$, design an algorithm $ALG$ that returns $ALG(A,t,\eps,\delta)$ such that $$\Pr[(1-\eps)S_t\leq ALG(A,t,\eps,\delta)\leq (1+\eps)S_t]\geq 1-\delta$$ \end{defn}

% known results, different settings

The moment estimation problem is one of the fundamental problems with a number of variants that are studied in the literature of sublinear algorithms. For $t=1$, this is the {\it sum estimation} problem. Motwani~\etal~\cite{MPX2007} initiated the study of designing sublinear algorithms for the sum estimation problem assuming access to a proportional sampling oracle. Recently, Beretta and T{\v{e}}tek \cite{BT2022} have improved the sample complexity of the sum estimation problem to $O(\sqrt{n}/\eps)$ using proportional sampling. Estimating frequency moments in streams is one of the most well-studied problems in the streaming literature \cite{AMS1999}. Moment estimation is also well studied in the distributed communication models \cite{JW2023}. This problem can also be thought of as the vector norm estimation problem where the weights correspond to the entries of a vector. When the set of elements corresponds to the set of vertices in a graph and the weights correspond to the degrees of the vertices in the graph, this problem is known as the {\it degree distribution moment estimation} problem. For $t=1$, this is the edge estimation problem in graphs for which Feige \cite{F2006} and Goldreich and Ron \cite{GR2008} designed sublinear algorithms. For the related degree distribution moment estimation problem in graphs, the authors in \cite{ERS2018,ERS2019,GRS2011} designed sublinear time algorithms in the sparse graph model in which one is allowed to make uniform vertex, degree and neighbour queries. Aliakbarpour~\etal~\cite{ABGPRY2018} designed a sublinear algorithm for estimating $\sum_{a\in A} {w(a)\choose t}$ using $O(\frac{n^{1-1/t}\ln 1/\delta}{\eps^2})$ queries in the sparse graph model with additional access to a random edge oracle, where $w(a)$ denotes the degree of vertex $a$. Various applications of the moment estimation problem including its variants are discussed in \cite{ERS2018,ABGPRY2018,BT2022}.

A number of recent works \cite{AN2022,TT2022,G2017} highlighted the importance of designing sublinear algorithms with optimal dependence not only on $n$ but also on $\eps$ and $\delta$. Beretta and T{\v{e}}tek have improved the sample complexity of the sum estimation problem from $\tilde{O}(\sqrt{n}/\eps^{7/2})$ proportional samples in Motwani~\etal~\cite{MPX2007} to $\Theta(\sqrt{n}/\eps)$ proportional samples \cite{BT2022}. Assadi and Nguyen designed a sublinear algorithm to estimate $h$-index with optimal sample complexity dependence on all input parameters \cite{AN2022}. Despite a lot of work on sublinear algorithms for the moment estimation problem, we don't have a complete understanding of the sample complexity of the moment estimation problem using weighted sampling. One of the primary motivations of this work is to make progress in our understanding of the moment estimation problem in sublinear models. Next, we discuss the main results of this work.

%There has been recent interest in obtaining a tight bound considering all input parameters. We have shown that our bound is tight with respect to all the input parameters $n,\eps,\delta$. 

\subsection{Our contributions}

%\begin{thm}(Upper bound result) There exists an algorithm $ALG$ that given proportional sampling access to the weights of the elements of a set $A$ and a parameter $t\geq 2$, $\eps,\delta\in (0,1)$, provides an $(\eps,\delta)$-estimate of $S_t$ using $O(\frac{n^{1-1/t}\log 1/\delta}{\eps^2})$ samples. \end{thm}

%We note that our upper bound holds for any $t>1$. However, since we use the sum estimation algorithm of Beretta and T{\v{e}}tek \cite{BT2022} as a subroutine in out algorithm, this step additionally requires $O(\sqrt{n}/{\eps})$ proportional samples. For any $t>1$, our algorithm has sample complexity $O(\frac{\sqrt{n}\log 1/\delta}{\eps}+\frac{n^{1-1/t}\log 1/\delta}{\eps^2})$. For $t\geq 2$, this becomes $O(\frac{n^{1-1/t}\log 1/\delta}{\eps^2})$.
\subsubsection{Moment estimation using proportional sampling} 

Our results for the $(\eps,\delta)$-moment estimation problem using proportional sampling for $t>1$ are as follows. 

\begin{thm} There exists an algorithm $ALG$ that given proportional sampling access to the weights of the elements of a set $A$ and parameters $t>1$, $\eps,\delta\in (0,1)$, provides an $(\eps,\delta)$-estimate of $S_t$ using $O((\frac{\sqrt{n}}{\eps}+\frac{n^{1-1/t}}{\eps^2}) \ln\frac{1}{\delta})$ samples. \end{thm}

For $t\geq 2$, the sample complexity of our algorithm is $O(\frac{n^{1-1/t}\ln\frac{1}{\delta}}{\eps^2})$. Our next result shows that this bound is tight.

\begin{thm} For any $\eps,\delta\in (0,1)$ and $t>1$, any randomized algorithm that computes an $(\eps,\delta)$-estimate of $S_t$ requires $\Omega(\frac{n^{1-1/t}\ln\frac{1}{\delta}}{\eps^2})$ proportional samples. \end{thm}

For $0<t<1$, we show the following. We design an $(\eps,\delta)$-estimator for $S_t$ when $t>1/2$.

\begin{thm} There exists an algorithm $ALG$ that given proportional sampling access to the weights of the elements of a set $A$ and parameters $1/2<t<1$, $\eps,\delta \in (0,1)$, provides an $(\eps,\delta)$-estimate of $S_t$ using $O((\frac{\sqrt{n}}{\eps}+\frac{n^{\frac{1}{t}-1}}{\eps^2})\ln \frac{1}{\delta})$ samples. \end{thm}

We show that when $t\leq 1/2$, no sublinear algorithms exist for this problem. More specifically, we show the following.

\begin{thm} For any $\eps>0$ and $t\leq 1/2$, any randomized algorithm that computes an $(\eps,1/3)$-estimate of $S_t$ requires $\Omega(n)$ proportional samples. \end{thm}


\paragraph*{Significance of our results and comparisons with known results} 
\begin{itemize}

	\item {\bf Case $t>1$}: Eden~\etal~\cite{ERS2018,ERS2019} designed sublinear algorithms for the degree distribution moment estimation problem in the sparse graph model assuming access to uniform vertex, degree and neighbour queries. Aliakbarpour~\etal~\cite{ABGPRY2018} improved the sample complexity bound for this problem assuming additional access to a random edge oracle. Aliakbarpour~\etal~observed that estimating the number of $t$-stars in a graph can be seen as a variant of the moment estimation problem. Let $w(a)$ denote the degree of vertex $a\in A$. Then, $\sum_{a \in A}\binom {w(a)}t$ counts the number of $t$-stars in the graph. The authors designed sublinear algorithms for this problem assuming access to a random edge sampling oracle in the sparse graph model. To the best of our knowledge, this problem of estimating $\sum_{a\in A} {w(a)\choose t}$ of Aliakbarpour~\etal~seems to be the most closely related problem to ours. In our setting, the result of Aliakbarpour~\etal~gives a sublinear-time algorithm for moment estimation using $O(\frac{n^{1-1/t}\ln 1/\delta}{\eps^2})$ proportional samples.\footnote{The authors stated their bound as $O(n^{1-1/t}/\eps^3)$ for constant success probability, but we believe using \cite{BT2022}, it can be improved to $O(n^{1-1/t}/\eps^2)$.} They also proved a $\Omega(n^{1-1/t})$ sample complexity lower bound for this problem. In the following we discuss the key differences of our results with theirs.

\begin{enumerate}
	\item Upper bound for moment estimation: We note that for $t>1$ our upper bound matches with that of Aliakbarpour~\etal~\cite{ABGPRY2018} and the algorithmic ideas and the analysis of these works are similar. We do not claim much technical novelty for our upper bound. However, we point out that our setup is strictly more general than that of Aliakbarpour~\etal~and their result can be recovered in our setup. We also note that our algorithm uses only proportional samples where as the algorithm of Aliakbarpour~\etal~uses queries in the sparse graph model with additional access to random edge samples. Since it is known that using uniform edge samples one can sample vertices with probabilities proportional to their degrees, it appears that access to proportional samples enables one to design sublinear algorithms for the moment estimation problem.
	\item Lower bound for moment estimation: Aliakbarpour~\etal~gave a $\Omega(n^{1-1/t})$ lower bound for this problem. We show an improved lower bound of $\Omega(\frac{n^{1-1/t}\ln\frac{1}{\delta}}{\eps^2})$ for $t>1$. For $t\geq 2$, this settles the sample complexity of $\Theta(\frac{n^{1-1/t}\ln\frac{1}{\delta}}{\eps^2})$ for the moment estimation problem with optimal dependence on all input parameters $n,\eps,\delta$.
\end{enumerate}

	\item {\bf Case $t<1$}: Moment estimation for $0<t<1$ is a well motivated problem with a number of applications \cite{JW2023}. However, to the best of our knowledge, no sublinear algorithms were known for the moment estimation problem when $t<1$. The moment estimation algorithms of Eden~\etal~\cite{ERS2018,ERS2019} and Aliakbarpour~\etal~\cite{ABGPRY2018} work only for $t\geq 1$. We design the first sublinear algorithm for the moment estimation problem for $t>1/2$. We also show that for $t\leq 1/2$, no sublinear algorithms exist for this problem. 
\end{itemize}

\subsubsection{Characterization of Sample Complexity}
%We introduce a {\it moment-density} parameter of the input that governs the sample complexity of the moment estimation problem using proportional sampling and derive almost tight bounds on the sample complexity with respect to this parameter.

The moment estimation problem using proportional sampling requires $\Omega(\frac{n^{1-1/t}\ln\frac{1}{\delta}}{\eps^2})$ samples in the worst case. We study the moment estimation problem in a beyond worst-case analysis paradigm and identify a parameter of the input that characterizes the sample complexity of the problem using proportional sampling. For the degree distribution moment estimation problem in graphs, Eden~\etal~\cite{ERS2019} identified the {\it arboricity} of a graph as the relevant parameter and obtained sample complexity bounds in terms of the arboricity of the graph.

We introduce a new \textit{moment-density} parameter $\rho$ of the input that characterizes the sample complexity for the moment estimation problem. For $W=\sum_{a\in A} w(a)$ and $S_t=\sum_{a\in A} w(a)^t$, we define the parameter $\rho$ as $$\rho=\max_{L\subseteq A} \frac{\frac{\sum_{a\in L} w(a)^t}{\sum_{a\in L} w(a)}}{\frac{\sum_{a\in A} w(a)^t}{\sum_{a\in A} w(a)}}=\max_{L\subseteq A} \frac{\sum_{a\in L} w(a)^t}{\sum_{a\in L} w(a)} \cdot \frac{W}{S_t}$$ 

The motivation for writing the moment-density parameter $\rho$ in the above form is as follows. The key idea behind the lower bound instances for the moment estimation problem using proportional sampling (described in Section \ref{sec:lower-proportional}) is to assign large weights on only a few input elements such that these elements are not easily detected using proportional sampling but the $t$th power of their weights dominate the moment value of the instance. This is why proportional sampling requires a lot of samples on these kind of instances. Now, if we were allowed to sample elements of $A$ with probabilities proportional to their $t$th power of the weights, then the complexity of the moment estimation problem becomes the same as the complexity of the sum estimation problem using proportional sampling. But, when we sample using proportional sampling, there might be some elements with slightly larger weights having outsized influence in the moment value of the instance. The moment-density parameter $\rho$ is defined such that its value will be large on those instances. For any subset $L\subseteq A$, let $\rho_L$ denote the ratio of the fractional contribution of the elements in $L$ to the moment value and the probability that an element in $L$ is going to be sampled using proportional sampling. We have $\rho=\max_{L\subseteq A} \rho_L$. Alternatively, $\rho$ captures the maximum contribution of any subset $L$ to the $t$-th moment $S_t$ relative to the sum of the weights of elements in $L$. For scaling we divide it by $S_t/W$.

We show an upper bound for $(\eps,\delta)$-estimate of the moment using proportional sampling where we write the sample complexity in terms of $\eps,\delta$ and $\rho$.

\begin{thm} There exists an algorithm $ALG$ that given proportional sampling access to the weights of the elements in a set $A$ with moment-density parameter $\rho$ and parameters $\eps,\delta\in (0,1), t>1$, provides an $(\eps,\delta)$-estimate of $S_t$ using $O((\sqrt{n}/\eps+\frac{\rho}{\eps^2})\ln 1/\delta)$ samples. \end{thm}

Next, we show an almost tight lower bound on the sample complexity for the moment estimation problem on instances with moment-density parameter $\rho$ in terms of $\rho,\eps,\delta$.

\begin{thm} For any $\eps,\delta\in (0,1)$ and $t>1$, any randomized algorithm for $(\eps,\delta)$-estimate of $S_t$ on an instance with moment-density parameter $\rho$ requires $\Omega(\frac{\rho \ln 1/\delta}{\eps })$ proportional samples. \end{thm}


\subsubsection{Moment Estimation using Hybrid Sampling}

Proportional sampling-based algorithms for the moment estimation problem require $\Omega(\frac{n^{1-1/t}\ln1/\delta}{\eps^2})$ samples for $t>1$ in the worst case. One natural idea to design algorithms with improved sample complexity bounds is to give more power to the algorithm designer in the form of access to a stronger query oracle. In this section we explore whether additional access to a uniform sampling oracle allows one to design an algorithm with improved sample complexity for this problem. The hybrid sampling framework allows one to use both proportional and uniform samples. This study is motivated by the fact that, for the sum estimation problem, Motwani~\etal~\cite{MPX2007} and Beretta and T{\v{e}}tek \cite{BT2022} exploited access to a hybrid sampling oracle to design algorithms that make $\tilde{O}(n^{1/3}/\eps^{9/2})$ and $O(n^{1/3}/\eps^{4/3})$ samples, respectively. This is in contrast to the $\Theta(\sqrt{n}/\eps)$ sample complexity bound for the sum estimation problem using only proportional samples. In this work we explore whether hybrid sampling might give us better sample complexity bounds for the moment estimation problem. We prove a lower bound result showing that no improved algorithm with better sample complexity bounds exists for the moment estimation problem using hybrid sampling. We state the result next and prove it in Section \ref{sec:lower-hybrid}.

\begin{thm}(Lower bound using hybrid sampling) For any $\eps,\delta \in (0,1)$ and $t>1$, any algorithm having access to a hybrid sampling oracle requires at least $\Omega(\frac{n^{1-1/t}\ln 1/\delta}{\eps^2})$ samples to compute an $(\eps,\delta)$-estimate for $S_t$. \end{thm}


\subsection{Techniques} The main idea behind the upper bound is fairly standard and we describe it as follows. Suppose we obtain a sample $a\in A$ of weight $w(a)$ using proportional sampling. Let us set $X=w(a)^t$. Then, $\EE[X]=\sum_{a\in A} w(a)^t p_a$, where $p_a=\frac{w(a)}{W}$ denotes the probability of sampling the element $a$ and $W=\sum_{a\in A} w(a)$. Suppose we know $p_a$ for each $a\in A$, then $X=w(a)^t/p_a$ would give us an unbiased estimator of $S_t$. However, we don't know $W$ and hence don't know about these probabilities $p_a$. Our crucial observation here is to use the sum estimation algorithm in Beretta and T{\v{e}}tek \cite{BT2022} to obtain an $(\eps_1,\delta/2)$ estimate $\wt{W}$ of $W$, and use this in turn to obtain estimates $\tilde{p}_a$ for $p_a$. Our estimator built in this manner would not be an unbiased estimator of $S_t$ but we can reduce the bias of the estimator considerably by choosing an appropriate $\eps_1$. For our algorithmic results, we use $\eps_1=\eps/2$. We use similar techniques for designing algorithms in related settings. For the lower bound we use Yao's minimax lemma to construct families of instances that cannot be distinguished using a small number of proportional samples. A number of lower bound results were known for variants of the moment estimation problem \cite{GRS2011,ERS2018,ABGPRY2018}. Our lower bound constructions are motivated from these lower bound constructions. Unlike the earlier lower bounds though, our lower bounds have optimal dependence in $n,\eps,\delta$. 

\subsection{Related Works} Motwani~\etal~\cite{MPX2007} initiated the study of the sum estimation problem using access to a proportional sampling oracle and designed the first sublinear algorithm for this problem that uses $\tilde{O}(\sqrt{n})$ queries. They also designed sublinear algorithms in the hybrid sampling framework using $\tilde{O}(n^{1/3})$ queries. Beretta and T{\v{e}}tek \cite{BT2022} have recently improved these results; they prove $\Theta(\frac{\sqrt{n}}{\eps})$ sample complexity bound using proportional sampling and in the hybrid sampling setting gives almost tight sample complexity bound of $O(n^{1/3}/\eps^{4/3})$. Variants of these problems are also studied in the graph parameter estimation literature, where the elements of the set correspond to the vertices of a graph and the weights correspond to the degrees of the vertices and we are given query access to the graph. The sum estimation problem in this context becomes the {\it edge estimation} problem and moment estimation is known as the degree distribution moment estimation problem. Eden~\etal~\cite{ERS2018,ERS2019} studied the {\it degree distribution moment estimation} problem in the graph query model and designed sublinear algorithms with improved sample complexity bounds. Aliakbarpour~\etal~\cite{ABGPRY2018} studied the estimation of the number of $t$-stars in a graph and showed this problem to be closely related to the moment estimation problem. Moment estimation problem is also studied in streaming and distributed communication models \cite{AMS1999,JW2023}.

%\subsection{Organization} We describe the algorithm for moment estimation using proportional sampling in Section \ref{sec:moments} and prove the lower bound in Section \ref{sec:lower-proportional}. For $0<t<1$, the upper and lower bounds on the sample complexity for moment estimation are analyzed in Section \ref{sec:small-t}. The moment-density parameter and the characterization of sample complexity in terms of this parameter is given in Section \ref{sec:characterize}. The lower bound on sample complexity using hybrid sampling is described in Section \ref{sec:lower-hybrid}.

\section{Preliminaries} We use the following well known facts in the analysis.

\begin{fact}\label{fact:norms} For any vector $x\in \C^n$, and for any $0<r<p$, we have $||x||_p\leq ||x||_r\leq n^{(1/r-1/p)} ||x||_p$. \end{fact}

\begin{lem}(Chernoff bound \cite{MU2017})\label{lem:chernoff} Let $Z_1,Z_2,\ldots,Z_v$ be independent and identically distributed Bernoulli random variables. Let $Z=\sum_{i=1}^v Z_i$. Then, $\Pr[Z\leq(1-\gamma) \EE[Z]]\leq e^{-1/2 \cdot \gamma^2 \cdot \EE[Z]}$. \end{lem}

