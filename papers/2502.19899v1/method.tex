%Our work applies the framework for AI-assisted instruction of motor control tasks proposed by \cite{srivastava2022teaching} to performance driving, which consists of three steps: (i) unsupervised skill discovery across expert demonstrations to identify different skill sequences relevant to the task, (ii) a student modeling step to identify what skill the student should next learn, and (iii) a teaching intervention step, where a student is provided targeted instruction (e.g. ``drills''). Other works have considered \megha{cite the fencing paper, language feedback paper} 

%Unfortunately, there are two key challenges that arise when applying \cite{srivastava2022teaching}'s framework to specialized domains like performance racing. First, unsupervised skill discovery methods may return skills that are uninterpretable to humans, and unaligned with possible teaching interventions. For example, most shared autonomy features in vehicles provide assistance for steering, braking, and throttle. In order to leverage these for automated instruction, it is important that ...

%highlighting two key challenges with their method that occur when scaling to complex domains such as performance racing:  (i) interpretable skill discovery that aligns with potential teaching interventions, and (ii) strong student modeling algined with ZPD.    

%skills = steering, throttle, braking (make note that could be more specialized

%Let us consider a set of target skills $Z=(z_1, z_2, ..., z_j)$ we are able to provide instruction for. This can include complex skills, such as drifting, or simple general general skills like controlling braking, throttle, and steering, as we do in our work. We also define a set of metrics $\mathcal{M}=(m_1, m_2, ..., m_k)$, with which we can evaluate a student, such as speed, similarity to an expert, and smoothness in driving. Let $\phi: \mathcal{Z}, \mathcal{T} \rightarrow \mathbb{R}$ be a function that defines how important a skill $z_{1,j}$ was for a particular step $t_i$ in the student's trajectory. Let $\psi: \mathcal{S}, \mathcal{T_{S}}, \mathcal{T_{E}}, \mathcal{M} \rightarrow \mathbb{R}$ be a function that evaluates a particular step $t_i$ in the student's trajectory with a given metric $m$.

\begin{figure*} 
\centerline{\includegraphics[width=0.8\textwidth]{figures/zcoach.pdf}}
\caption{Overview of \texttt{Z-COACH}, which consists of three stages: (1) an interpretable skill discovery stage to identify task-relevant skills to guide coaching, (2) student modeling, which leverages shared autonomy to identify how a driver's behavior changes with assistance in order to choose skills within their ``zone of proximal development'', and (3) skill-targeted coaching, which leverages a different form of shared autonomy that forces drivers to control and practice a specific skill. Note that shared autonomy is leveraged twice by \texttt{Z-COACH}: for student modeling and for coaching.}
\label{fig:zcoach}
\end{figure*}

We now formalize our approach to leveraging shared autonomy for proximal teaching, where our goal is to select optimal coaching interventions that can help guide a student towards optimal behavior for a given task $g$ (e.g. driving). Let us treat $g$ as a standard Markov decision process (MDP) $<\mathcal{S}, \mathcal{A}, f, \mathcal{R}, T>$ with finite horizon $T$, reward function $\mathcal{R}: \mathcal{S} \times \mathcal{A} \rightarrow \mathbb{R}$ 
over state $\mathcal{S}$ and action $\mathcal{A}$ spaces, and a deterministic transition function $f_g: \mathcal{S} \times \mathcal{A} \rightarrow \mathcal{S}$ that maps a state and action pair $s_t, a_t$ at time step $t$ to a new state $s_{t+1}$. We can then define a trajectory $\tau$ as a sequence of state and action pairs $\{s_1,a_1, \dots, s_T,a_T\}$, and can collect trajectories from the student's policy ($\pi_{student}:\mathcal{S} \rightarrow \mathcal{A}$). 

Next, let $\mathcal{Z}_g$ represent the set of task-specific skills (e.g. soft braking), and $\mathcal{C}_g$ be the set of possible coaching interventions. These can include verbal feedback, haptic guidance, or, as in our work, different shared autonomy controls, and one can consider the function $\phi:\mathcal{Z}_g \rightarrow \mathcal{C}_g$ that outputs a specific coaching intervention $c=\phi(z)$ that targets a specific skill $z \in \mathcal{Z}_g$. We therefore seek to learn a useful teaching policy $\pi_{coach}:\mathcal{S},\Pi  \rightarrow \mathcal{C}_g$ that takes a student's current state $s$ and policy $\pi_{student} \sim \Pi$, and selects an intervention $c$ that guides $\pi_{student}$ towards an optimal policy $\pi*$. 

Our primary challenge lies with modeling the transition function $f_{student}:\mathcal{S}, \Pi, \mathcal{C} \rightarrow \Pi$ (i.e., how the coaching  intervention $c$ will modify the student's behavior).  Prior works have tackled this by making assumptions such as modeling student learning over time as a Wiener process, and selecting the coaching intervention $c$ that leads to the biggest increase in proficiency \citep{yu2023coach, ekanadham2017tskirt}. In contrast, we propose leveraging shared autonomy to directly observe how a student's current behavior is affected by assistance. The change in performance can inform which skills $z \in \mathcal{Z}_g$ are most within the student's ``zone of proximal development''  in real-time, allowing us to provide an effective intervention $c=\phi(z)$.

Figure \ref{fig:zcoach} provides an overview of \texttt{Z-COACH}, highlighting how we leverage shared autonomy for both student modeling and coaching. \texttt{Z-COACH} requires three components, which we formalize in more detail below:
\begin{itemize}
    \item Section \ref{sec:sa}: A shared autonomy paradigm that produces a policy $\pi
    _{SA}$ given the student's policy $\pi_{student}$. 
    \item Section \ref{sec:skill}: A set of  interpretable task skills $\mathcal{Z}_g$. 
    \item Section \ref{sec:zpd}: A model \textsf{zpd} which estimates how well each skill $z$ is within the student's ``zone of proximal development'', given $\mathcal{Z}_g$ and $\pi_{SA}$. 
\end{itemize}


\subsection{Shared Autonomy Design} \label{sec:sa}
We consider the simplest form of shared control, where the actions from both the human student ($\pi_{student}$) and an intelligent agent ($\pi_{agent}$) are merged, which in driving has been shown to improve overall performance in safety-critical situations \citep{wang2020review}. Concretely, given an observed state $s$, the output action of the policy $\pi_{SA}$ is:
\begin{equation}\label{eq:sa}
    \pi_{SA}(s) = \alpha * \pi_{agent}(s) + (1 - \alpha) * \pi_{student}(s)
\end{equation}

The term $\alpha$ controls the strength of the autonomy, and is action-specific (e.g. separate $\alpha$ for steering input and brake input in driving) Finally, the autonomous agent $\pi_{agent}$ can come from any source, including planning, reinforcement learning or imitation-learning on expert demonstrations. In our work, we use a PID controller and path planner based on expert trajectories, which we describe in more detail in Section \ref{sec:study}.


\subsection{Interpretable Skill Discovery}
\label{sec:skill}
Recall our goal to model students and design coaching interventions with respect to a set of skills $\mathcal{Z}_g$. Most works in the literature consider hand-crafted skills, and are therefore limited to environments where it is easy to manually evaluate skill performance from a student trajectory $\tau_{student}$, which is tricky for motor control tasks. To address this, \cite{srivastava2022motor} recently proposed using CompILE, an unsupervised skill discovery algorithm, which learns the latent skill set $\mathcal{Z}_g$ from expert trajectories $\tau_{expert} \sim \pi_{expert}$ \cite{kipf2019compile}. Concretely, CompILE jointly trains an encoder $q_\phi$ and decoder $p_\theta$ to segment a trajectory into $M$ segments (marked by boundaries $b$), and represent each segment with latent skill $z \in \mathcal{Z}_g$ that minimizes the following reconstruction loss (black only):

\begin{equation}\label{eq:compile}
    \mathcal{L} = - \mathbb{E}_{q_\theta(b, z|a, s)}\sum_i^M[Pr[\text{seg}_i] * \text{log}p_\theta(a\color{blue}, \psi(s)\color{black}|s, z_i)]
\end{equation}

The output of CompILE can therefore be viewed as a list of $M$ segments, as well as a probability distribution across all skills $z \in \mathcal{Z}_g$ such that $p_{z,i}$ is the likelihood $\text{seg}_i \in M$ expresses skill $z$.
Unfortunately, such a method lacks interpretability, and segments with similar latent skill representations CompILE may not appear similar to humans, making it difficult to map task skills to effective and meaningful coaching interventions ($\phi : \mathcal{Z}_g \rightarrow \mathcal{C}_g)$. We therefore propose using weak supervision by forcing latent skills $z$ to also represent semantically-meaningful auxiliary information (\color{blue}blue \color{black} in Equation \ref{eq:compile}) about the current state. In both Section \ref{results:skills} and Figure \ref{fig:method}, we show how a small amount of language feedback on student driving trajectories helps steer CompILE towards learning more human-interpretable skills $\mathcal{Z}_g$, while retaining the flexibility of not requiring manual evaluation from an expert.
\subsection{Zone of Proximal Development Estimation} \label{sec:zpd}
Finally, we formalize how to use a given shared autonomy policy $\pi_{SA}$ and task skills $\mathcal{Z}_g$ to estimate the student's Zone of Proximal Development.  Recall that our key idea is that  improvement in performance between $\pi_{SA}$ and $\pi_{student}$, with respect to skills $z \in \mathcal{Z}_g$, highlights which skills are most likely to be immediately ``learnable'' for the student.  If we define a function $\mathsf{align}$ that finds the closest (by location) part of a trajectory $\tau$ to a given skill segment $\text{seg}_i \in M$, then we can define: 


\begin{multline}\label{eq:zpd}
    \mathsf{zpd}(z) = \sum_{i=0}^{M}p_{z,i}*(\mathsf{score}(\mathsf{align}(\tau_{SA}, \text{seg}_i)) \\ -\mathsf{score}(\mathsf{align}(\tau_{student}, \text{seg}_i)))
\end{multline}

The $\mathsf{score}$ function can be any task-dependent performance metric, such as speed, smoothness, or similiarity to a reference expert trajectory $\tau_{expert}$. Intuitively, $\mathsf{zpd}(z)$ re-weights the difference between a student's performance with and without assistance for a given segment by the relevance of skill $z$. Then, one could define $\phi(z)$ using these weights, such as choosing the intervention $c \in \mathcal{C}_g$ that best targets the skill $\mathsf{argmax}_z\mathsf{zpd}(z)$. Thus, by explicitly incorporating full information about the student's trajectory with assistance $\tau_{SA}$, we can more precisely consider whether a student's difficulty with skill $z$ can be addressed via coaching at the current point of the student's learning. 

