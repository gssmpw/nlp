\section{Ethics considerations}
\label{sec:ethics}

This study utilized publicly available datasets~\cite{shi-etal-2022-selective, pii}, some of which included identifiable information such as personal details. However, third-party organizations pre-processed and validated the datasets to ensure that no real individualsâ€™ data were present, thus mitigating potential privacy concerns.

This project received ethical clearance from the Ethical Review Board of the affiliated institution on October 21, 2024 (Approval No. 24-09-4), with no ethical concerns raised.


\section{Open science}
\label{sec:openscience}
This work promotes transparency and reproducibility in research on privacy and utility in large language models (LLMs). To enable further investigation, we will release:
\begin{itemize}
    \item[1.] Code and Framework: The implementation of our proposed privacy measurement framework, which distinguishes between sensitive and non-sensitive tokens, along with scripts for privacy leakage analysis and utility-efficiency evaluation.
    \item[2.] Datasets and Preprocessing information: Links to publicly available datasets used in this study, along with preprocessing scripts to ensure reproducibility. Sensitive data were excluded or anonymized to comply with ethical standards.
    \item [3.] Evaluation Pipeline: An open-source pipeline for assessing privacy leakage and the trade-offs between privacy, utility, and efficiency in LLMs. 
\end{itemize}

These resources aim to support reproducibility and further research into privacy-aware, efficient LLM development.