\section{Quantifying Privacy and Utility}
\label{sec:quantifying_privacy_utility}
In this section, we introduce the distinction between sensitive and non-sensitive entities when quantifying privacy and utility of an LLM. We conduct case studies to compare our quantification with existing measures. Finally, we demonstrate how the privacy threat is unintentionally exaggerated in existing methods due to the lack of distinction between sensitive and non-sensitive entities.

\subsection{Rethinking Privacy and Utility}

Existing studies at the intersection of privacy and natural language processing \cite{zhao-etal-2022-provably,shi-etal-2022-selective,li2022large,yu2022differentially} seek to enhance privacy while maintaining model utility. Utility is generally assessed based on model performance, such as loss, accuracy, or perplexity \textit{across the entire test dataset}. Privacy is evaluated in terms of performance measures on the \textit{entire training dataset} or theoretical guarantees in differential privacy (DP).


Natural language text may contain both sensitive and non-sensitive words, referred to as entities. For example, sensitive entities include names, addresses, phone numbers, order IDs, and other personally identifiable information. In contrast, non-sensitive entities generally involve semantic and/or syntactic completions following predictable patterns in language generation tasks. Informally, sensitive entities are drawn from a large search space (e.g., \textit{a random sequence of digits}), resulting in high entropy and low predictability. In contrast, non-sensitive entities are more restricted in their occurrences (e.g., \textit{a subject is typically followed by a verb}), leading to low entropy and high predictability. 
Several studies \cite{biderman2024emergent, shi-etal-2022-selective, zhao-etal-2022-provably} distinguish between sensitive and non-sensitive entities in their proposed privacy leakage mitigation methods. However, the distinction is not leveraged in the \textit{quantification of privacy and utility}, which is essential for a granular evaluation as discussed next.

\noindent
\textbf{Quantification of privacy and utility.} In this work, we quantify privacy and utility by accounting for sensitive and non-sensitive entities. Considering a training dataset and a test dataset in a general LLM training pipeline, we quantify \textbf{privacy} as the \textit{recollection of sensitive entities in the training data} and \textbf{utility} as the \textit{prediction of non-sensitive entities in the test data}. Our motivation for the quantification is two-fold: (1) privacy of a model is generally related to training data, while utility is the model's performance on the test data. (2) when quantifying privacy, we deliberately disregard non-sensitive entities, since they are more predictable and not sensitive to a specific person or entity. Similarly, in quantifying utility, we ignore sensitive entities in the test data, since the sensitive entities are rare (and possibly unseen during training), whereas predicting non-sensitive entities indicates the general language understanding ability of LLMs. Next, we provide two pieces of evidence supporting why the distinction is important.

\subsection{Why do we distinguish between sensitive and non-sensitive entities?}
\label{sec:sens_non_sens_distinction}

In this section, we present evidence supporting the importance of distinguishing between sensitive and non-sensitive entities in natural language text while quantifying privacy and utility of an LLM. 

\begin{figure}[t!]
    \centering
        \begin{subfigure}{.48\linewidth}
       \includegraphics[scale=0.25]{figures-paper/section2/train-privacy-customersim--pythia-gpt4.pdf}
        \caption{Privacy measure in Pythia}
        \label{fig:pyt_priv}
    \end{subfigure}
    \hfil
    \begin{subfigure}{.48\linewidth}
        \includegraphics[scale=0.25]{figures-paper/section2/test-utility-customersim--pythia-gpt4.pdf}
        \caption{Utility measure in Pythia}
        \label{fig:pyt_util}
    \end{subfigure}
    
    \begin{subfigure}{.48\linewidth}
       \includegraphics[scale=0.25]{figures-paper/section2/train-privacy-customersim--gemma-gpt4.pdf}
        \caption{Privacy measure in Gemma}
        \label{fig:gemma_priv}
    \end{subfigure}
    \hfil
    \begin{subfigure}{.48\linewidth}
        \includegraphics[scale=0.25]{figures-paper/section2/test-utility-customersim--gemma-gpt4.pdf}
        \caption{Utility measure in Gemma}
        \label{fig:gemma_util}
    \end{subfigure}


    \begin{subfigure}{.48\linewidth}
       \includegraphics[scale=0.25]{figures-paper/section2/train-privacy-customersim--llama2-gpt4.pdf}
        \caption{Privacy measure in Llama2}
        \label{fig:llama_priv}
    \end{subfigure}
    \hfil
    \begin{subfigure}{.48\linewidth}
        \includegraphics[scale=0.25]{figures-paper/section2/test-utility-customersim--llama2-gpt4.pdf}
        \caption{Utility measure in Llama2}
        \label{fig:llama_util}
    \end{subfigure}
    
    \caption{
    Our measures offer a more precise assessment of privacy and utility when fine-tuning LLMs by distinguishing between sensitive and non-sensitive tokens, revealing higher privacy (higher loss) for sensitive tokens and better utility (lower loss) for non-sensitive tokens compared to traditional measures that overlook this sensitivity-based distinction.
    }
    \label{fig:FFT_All}
\end{figure}


\paragraph{\textbf{I. Analyzing privacy and utility while fine-tuning an LLM
}}
%: existing vs.\ our measures}} 
%\tr{provide the intuition}
In order to align with LLM terminology, hereafter, we use tokens to denote entities. Fine-tuning involves iterating an LLM on a specific dataset containing both sensitive and non-sensitive tokens. 
We illustrate how our measure of privacy and utility compares to existing measure in a typical fine-tuning scenario, highlighting a key difference: our approach distinguishes between sensitive and non-sensitive tokens, whereas the existing measure does not.

\textbf{Results.} In Figure~\ref{fig:FFT_All}, we demonstrate measures of privacy (left column) and utility (right column) while fine-tuning three LLM models on Customersim dataset \cite{shi-etal-2022-selective} (experimental details
are provided at the end of this section). In particular, we show training loss on the left column and test loss on the right column. Importantly, we separately compute the loss for both sensitive and non-sensitive tokens in both training and test datasets. Intuitively, a higher loss denotes more privacy and less utility.


\textbf{Privacy is overestimated in the existing measure.} In Figure~\ref{fig:pyt_priv}, we compute privacy using our measure, as well as the existing one. The existing measure of privacy considers \textit{all tokens in the training data}, where low training loss denotes less privacy, while our measure considers \textit{only the sensitive tokens in the training data}. Using our measure, a notable disparity emerges: \textit{sensitive tokens exhibit significantly higher loss than non-sensitive ones}, particularly in the initial training epochs, as sensitive tokens are less predictable. This eventually indicates that the loss over all tokens (existing measure) would be much lower initially than the loss over only sensitive tokens (our measure), thus overestimating privacy threats much earlier. 
%by unintentionally accounting for non-sensitive tokens having little to no privacy threat. 
Similar trends are observed for other models in Figures \ref{fig:gemma_priv} and \ref{fig:llama_priv}.


\textbf{Utility is underestimated in the existing measure.}
In Figure \ref{fig:pyt_util}, we compute utility using our measure and the prevailing one. The existing utility measure is related to the test loss of all tokens, where lower test loss indicates better utility. We can observe that our measure that considers the test loss on only non-sensitive tokens provides better utility than the existing measure. Similar trends are observed for other models in Figures \ref{fig:gemma_util} and \ref{fig:llama_util}. 
%In our measure, we only consider the test loss of non-sensitive tokens, which is even lower than the test loss of all tokens. 
Existing measure would lead to better utility at earlier epochs compared to our measure
%Using our measure, better utility (lower test loss) comes at later epochs compared to existing measures 
i.e. one would select checkpoints at epochs $4$, $2$ and $2$ using existing measures for Pythia, Gemma and Llama2 respectively and at epochs $5$, $6$, and $6$ using our measure. Thus, utility is underestimated in the existing measure. Figure \ref{fig:app_FFT_All_log} in Appendix \ref{appendix:sens_non_sens_distinction} shows the change more distinctly in log-scale. For the same fine-tuning scenario, our measure certifies better utility than the existing measure, which unintentionally considers the loss of sensitive tokens that are rare. The key to our findings is how we annotate sensitive and non-sensitive tokens in real-world datasets. Next, we expand our experimental details leading to our results.


\begin{table}[t!]
\scriptsize
\centering
\caption{Example of samples from datasets with sensitive tokens highlighted.}
\label{tab:snippets}
\begin{tabular}{|ll|}
\hline
\multicolumn{2}{|c|}{\textbf{CustomerSim}}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \\ \hline
\multicolumn{1}{|l|}{\begin{tabular}[c]{@{}l@{}}SYS: Hello, I am the customer \\ support bot. What can \\ I do for you?\\ USR: Hello robot. I ordered a pot \\ several days ago but I can't track it.\\ SYS: Could you verify your full name?\\ USR: \hl{Patrick Schug}\\ SYS: Verify your order number please.\\ USR: It's \hl{843-58572-7002}.\\ SYS: You can track your package \\ with your tracking number \\, which is \hl{AGZIM5T6KL}. \\ Are you happy about my answer?\\ USR: All good. See you.\\ SYS: Have a nice day! Bye.\end{tabular}}                                                                                                                                                                                                                                                                              & \begin{tabular}[c]{@{}l@{}}SYS: Hello, I am the customer \\ support bot. What can \\ I do for you?\\ USR: Hi. Where is my package?\\ SYS: Could you verify \\ your full name?\\ USR: I am \hl{Catherine Pena}.\\ SYS: Verify your phone number.\\ USR: You can reach me at \\ \hl{547.302.3744}.\\ SYS: The tracking number is \\ \hl{VVTPHDB6VK}. \\ Anything else?\\ USR: All good.\end{tabular}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \\ \hline
\multicolumn{2}{|c|}{\textbf{SynBio}}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \\ \hline
\multicolumn{1}{|l|}{\begin{tabular}[c]{@{}l@{}}My name is \hl{Alexander Tanaka}, and I'm a \\ saleswoman with a year of experience. I \\ recently completed a project that \\ involved developing and implementing \\ a new sales strategy  for \\ my company. I started by analyzing our \\ current sales data to identify areas where \\ we could improve...
\end{tabular}} & \begin{tabular}[c]{@{}l@{}}My name is \hl{Phillip Martinez}, and \\ I would like to share some aspects \\ of my life's journey with \\ you. I have had the pleasure of  \\ living in various places throughout \\ my life,  but I currently reside \\ at \hl{4537 Tanglewood Trail}\\
... you can reach me via email at \\ \hl{phillip-martinez@outlook.com}\\ or by phone at \hl{+86 19144 1648}.\end{tabular} \\ \hline
\end{tabular}
\end{table}


\noindent
\textbf{Experimental setup and methodology.} We perform our analysis on two datasets: CustomerSim~\cite{shi-etal-2022-selective}, a simulated dialog dataset for conversation generation and SynBio (originally called PII)~\cite{pii}, an LLM generated dataset representing student biographies containing personal identifiable information. Table \ref{tab:snippets} shows some excerpts from the datasets. We use three open-source models during evaluation: Pythia 1B \cite{biderman2023pythia}, Gemma 2B\cite{team2024gemma}, and Llama2 7B \cite{touvron2023llama}.


We leverage two tools for annotating sensitive information in a given text: Presidio~\cite{MsPresidio}, which helps in identification of private entities in text, and GPT-4 \cite{achiam2023gpt}, which is provided with a particular prompt for returning the annotated portions. An example of such a prompt for annotating samples is provided in Appendix~\ref{appendix:example-priv-annotatation}.


We run two surveys, each among 40 Prolific\footnote{\url{https://www.prolific.com}} users, to gauge the usefulness of the two tools.
We provide the details of the survey in Appendix~\ref{appendix:human-survey-priv-annotatations}.
Figure~\ref{fig:survey_results} shows the results on the CustomerSim dataset which depicts that 75\% participants found GPT4's annotations to be accurate while Presidio annotations were mostly mixed or under-annotated.
\textit{Hence, throughout the rest of the paper we show our results using GPT-4 annotations}, and those using Presidio annotations are shown in Appendix~\ref{appendix:exploring-tradeoffs}.


To summarize, the degree of difference in computing privacy and utility using our measure and the existing one depends on the ratio of sensitive to non-sensitive tokens. A higher ratio would result in a higher difference in the measure, and vice versa. Considering the distinction between sensitive and non-sensitive tokens, we show that the existing measure can both exaggerate privacy threats and underestimate the utility in LLMs. 
In this context, we re-examine a prior study~\cite{biderman2024emergent} to better support our claim that reported privacy threats are exaggerated.

\begin{figure}[!h]
    \centering
     \includegraphics[scale=0.28]{figures-paper/section3/plot1_multiplechoice_customersim.pdf}
    \caption{
    % GPT-4 demonstrates higher accuracy than Presidio for identifying privacy-sensitive information, as rated by human annotators.
    GPT-4 shows higher annotation accuracy, with 75\% of participants rating its annotations to be accurate while Presidio annotations were mostly mixed or under-annotated.
    }
    \label{fig:survey_results}
\end{figure}

\begin{table}[]
\caption{
Examples of memorized sequences from \cite{biderman2024emergent}, often containing predictable and non-sensitive patterns, like mathematical series and licensing text.
}
\label{tab:memseq}
\scriptsize
\centering
\scalebox{0.9}{
\begin{tabular}{p{0.5\columnwidth}|p{0.5\columnwidth}}
    % \multicolumn{2}{c}{\textbf{Memorized Sequence}} \\
    % \hline
    Prompt  & Generation \\
    \toprule
264. 
  265. 
  266. 
  267. 
  268. 
  269. 
  270. 
  271. & 272. 
  273. 
  274. 
  275. 
  276. 
  277. 
  278. 
  279. \\
  \midrule
active.disabled:focus,
.datepicker table tr td.active.disabled:hover:focus,
.datepicker table tr td.active:active, & .datepicker table tr td.active:hover:active,
.datepicker table tr td.active.disabled:active,
.datepicker table tr td \\
\midrule
$\langle$rel=``Chapter" href=``Char.html"$\rangle$$ \langle$link title=``Clflags" rel=``Chapter" href=``Clflags.html"$\rangle$ $\langle$ & link title=``Complex" rel=``Chapter" href=``Complex.html"$\rangle$ $ \langle$link title=``Condition" rel=``Chapter" href=``Condition.html"$\rangle$ \\

\midrule
    amp amp amp amp amp amp amp amp  amp amp amp amp amp amp amp amp & amp amp amp amp amp amp amp amp amp  amp amp amp amp amp amp amp  \\

\midrule
	.word 0
	.word 0
	.word 0
	.word 0
	.word 0
	.word 0 & .word 0
	.word 0
	.word 0
	.word 0
	.word 0
	.word 0
	.word \\
  \bottomrule
\end{tabular}}
\end{table}




 
\paragraph{\textbf{II. Examining memorized sequences from \cite{biderman2024emergent}:}}
We consider a case study to analyze the reported memorized strings by~\cite{biderman2024emergent}, %which are marked as possible privacy threats of the LLM.
Our goal is to examine whether the memorized strings contain sensitive information or mere syntactic and semantic patterns.

\textbf{Experimental setup.} The authors in \cite{biderman2024emergent} considered the task of predicting whether a model memorizes specific training data points from the Pile dataset~\cite{gao2020pile}, which is used to train base LLM models. Among published memorized strings, we randomly choose $5,000$ strings from the \textit{pythia-1b-dup} split~\cite{biderman2024emergent}. A representative list of memorized strings is in Table~\ref{tab:memseq}, where the strings often follow syntactic and semantic patterns, such as completion of mathematical series, code snippets, licensing agreements, etc. Therefore, \textit{our hypothesis is that most of the memorized strings contain a great amount of non-sensitive and highly predictable tokens.} To validate our hypothesis, we query for the source of memorized strings with respect to the training dataset, Pile, which aggregates data from multiple sources such as Pile-Cc, OpenWebText, ArXiv, etc. We leverage GPT-4 model to accomplish our task -- given a memorized string, we ask for the source of the string from the list of Pile sections. The prompt template for GPT-4 is the following.

\noindent
%\begin{quote}
\begin{mdframed}[backgroundcolor=lavender, linewidth=0pt]
\small
\textit{You are provided with the following text: \{\textcolor{blue}{memorized--sequence}\}.\newline
Which section of the Pile dataset does the text belong to? Choose from the list below. You can select 1 or 2 options separated by a comma. Please respond with only the option number.\newline
a. Pile-CC
b. PubMed Central
c. Books3 \\
d. OpenWebText2
e. ArXiv
f. GitHub
g. FreeLaw \\
h. Stack Exchange
i. USPTO Backgrounds \\
j. PubMed Abstracts
k. Gutenberg (PG-19) \\
l. OpenSubtitles
m. Wikipedia (en) \\
n. DM Mathematics
o. Ubuntu IRC \\
p. BookCorpus2
q. EuroParl 
r. HackerNews \\
s. YoutubeSubtitles 
t. PhilPapers \\
u. NIH ExPorter
v. Enron Emails}
\end{mdframed}
%\end{quote}

\begin{figure}[!h]
    \centering
        \subfloat{
       \includegraphics[scale=0.22]{figures-paper/section2/the_pile_dataset_pie_chart.pdf}
        }
        \subfloat{
       \includegraphics[scale=0.22]{figures-paper/section2/predicted_pile_sections_random_5000_gpt-4_v2_avg_pie_chart.pdf}
        }
    \caption{
    Memorized sequences are predominantly sourced from GitHub and ArXiv, despite these sections being mid-range in the original Pile dataset, suggesting that memorized content is largely non-sensitive and may pose a lower privacy risk than previously assumed.
    }
    \label{fig:pile-data}
\end{figure}
 %\vspace{-15pt}


\textbf{Results.} In Figure~\ref{fig:pile-data}, we present two pie charts illustrating the distributions across $22$ distinct sections or data sources within the Pile dataset. The left chart represents the original content distribution of sections within the Pile dataset, while the right chart depicts the distribution of sources of memorized sequences as predicted by GPT-4. 

In the right chart in Figure~\ref{fig:pile-data}, the memorized strings are predicted mostly from GitHub, followed by ArXiv, while the rest of the sources are largely under-represented. Herein, both GitHub and ArXiv are relatively in the middle range in terms of contents in the original dataset in the top chart.  However, analyzing the typical data in these sections, GitHub appears as a source of structured format code with repeated predictable patterns, which is commonly tagged as non-sensitive data. Similarly, the Pile dataset includes {\LaTeX} files uploaded to ArXiv, since {\LaTeX} is a common typesetting language for scientific research papers~\cite{gao2020pile}. As such, highly memorized strings in the Pile dataset are non-sensitive in nature.


\textbf{Validating GPT-4 predictions.} GPT-4 predictions may be erroneous. Hence, we conduct a verification test to evaluate the accuracy of GPT-4's predictions. For this assessment, we sample $200$ random strings from each of the 22 sections of the Pile dataset \cite{gao2020pile}, and prompt GPT-4 to predict the source of the strings. Unlike the previous experiment, \textit{the ground-truth of string source is known in this validation experiment}. Figure~\ref{fig:pile-data-verify} illustrates the accuracy for each section, indicating that $50\%$ of the sections exhibit an accuracy rate of at least $90\%$ with $4.5\%$ being the base accuracy of a random predictor.
Furthermore, GPT-4 predicts the correct source on an average of $78\%$ strings across all $22$ sections of the Pile dataset. In addition, misclassified strings are often assigned to sections of a similar category, e.g., \textit{NIH Explorer misclassified as PubMed Central} (more details in Appendix~\ref{appendix:validating-gpt4-preds}). \textit{Therefore, the GPT-4 predictions can be considered as reliable.}

\begin{figure}[!t]
    \centering
        \includegraphics[scale=0.35]{figures-paper/section2/the_pile_dataset_200_sample_per_section_bar_chart.pdf}
    \caption{
    GPT-4 achieves an average accuracy of 78\% in predicting the source of memorized strings across Pile dataset sections,
    % , with half of the sections reaching at least 90\% accuracy, 
    reinforcing the reliability of GPT-4 and supporting our position that privacy concerns in prior work are overestimated without distinguishing token sensitivity.
    }
    \label{fig:pile-data-verify}
\end{figure}

\begin{figure}[!t]
    \centering
    % \begin{subfigure}{.8\linewidth}
    %    \includegraphics[width=\linewidth,height=4cm]{figures/plot_q1.pdf}
    % \end{subfigure}
    % \begin{subfigure}{.9\linewidth}
       \includegraphics[scale=0.3]{figures-paper/section3/plot2_q1.pdf}
    % \end{subfigure}
    
    \caption{
    Most participants classified the memorized sequences detected by~\cite{biderman2024emergent} as non-sensitive, with fewer than 10\% marking them as privacy-sensitive, indicating that the perceived privacy risk of these strings is generally low.
    }
    \label{fig:human-survey-mem-txt}
\end{figure}


Finally, we conduct a human survey on Prolific to evaluate the extent of sensitive information present in  randomly chosen $100$ memorized strings from \cite{biderman2024emergent}. 
The survey results are summarized in Figure~\ref{fig:human-survey-mem-txt}. The majority of participants classified memorized strings as non-sensitive, while  $< 10\%$ participants disagree and mark the strings as containing privacy-sensitive information.
%Figure~\ref{fig:human-survey-mem-txt} shows the responses by question, illustrating a consistent trend across individual sequences. 
\textit{Therefore, most crowdsourced participants do not perceive the sampled stings as containing privacy-sensitive content.} 
%Overall, the data reveal a strong tendency for non-sensitivity classification across the memorized sequences tested.
Further details on the setup and results are provided in Appendix~\ref{appendix:human-survey-priv-mem-txt}. Thus, by distinguishing between sensitive and non-sensitive entities, we demonstrate a deeper understanding of actual privacy threat.