@misc{riebesell2024matbenchdiscoveryframework,
      title={Matbench Discovery -- A framework to evaluate machine learning crystal stability predictions}, 
      author={Janosh Riebesell and Rhys E. A. Goodall and Philipp Benner and Yuan Chiang and Bowen Deng and Gerbrand Ceder and Mark Asta and Alpha A. Lee and Anubhav Jain and Kristin A. Persson},
      year={2024},
      eprint={2308.14920},
      archivePrefix={arXiv},
      primaryClass={cond-mat.mtrl-sci},
      noURL={https://arxiv.org/abs/2308.14920}, 
}

@inproceedings{austin_structured_2021,
  title = {Structured {{Denoising Diffusion Models}} in {{Discrete State-Spaces}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Austin, Jacob and Johnson, Daniel D. and Ho, Jonathan and Tarlow, Daniel and van den Berg, Rianne},
  year = {2021},
  month = nov
}

@article{goodall_rapid_2022,
author = {Rhys E. A. Goodall  and Abhijith S. Parackal  and Felix A. Faber  and Rickard Armiento  and Alpha A. Lee },
title = {Rapid discovery of stable materials by coordinate-free coarse graining},
journal = {Science Advances},
volume = {8},
number = {30},
pages = {eabn4117},
year = {2022},
doi = {10.1126/sciadv.abn4117},
noURL = {https://www.science.org/doi/abs/10.1126/sciadv.abn4117},
eprint = {https://www.science.org/doi/pdf/10.1126/sciadv.abn4117},
abstract = {A fundamental challenge in materials science pertains to elucidating the relationship between stoichiometry, stability, structure, and property. Recent advances have shown that machine learning can be used to learn such relationships, allowing the stability and functional properties of materials to be accurately predicted. However, most of these approaches use atomic coordinates as input and are thus bottlenecked by crystal structure identification when investigating previously unidentified materials. Our approach solves this bottleneck by coarse-graining the infinite search space of atomic coordinates into a combinatorially enumerable search space. The key idea is to use Wyckoff representations, coordinate-free sets of symmetry-related positions in a crystal, as the input to a machine learning model. Our model demonstrates exceptionally high precision in finding unknown theoretically stable materials, identifying 1569 materials that lie below the known convex hull of previously calculated materials from just 5675 ab initio calculations. Our approach opens up fundamental advances in computational materials discovery. Coordinate-free machine learning models enable the efficient prediction of unknown stable materials.}
}

@inproceedings{gruver_protein_2023,
  title = {Protein {{Design}} with {{Guided Discrete Diffusion}}},
  booktitle = {Thirty-Seventh {{Conference}} on {{Neural Information Processing Systems}}},
  author = {Gruver, Nate and Stanton, Samuel Don and Frey, Nathan C. and Rudner, Tim G. J. and Hotzel, Isidro and {Lafrance-Vanasse}, Julien and Rajpal, Arvind and Cho, Kyunghyun and Wilson, Andrew Gordon},
  year = {2023},
  month = nov,
  urldate = {2024-01-08},
  abstract = {A popular approach to protein design is to combine a generative model with a discriminative model for conditional sampling. The generative model samples plausible sequences while the discriminative model guides a search for sequences with high fitness. Given its broad success in conditional sampling, classifier-guided diffusion modeling is a promising foundation for protein design, leading many to develop guided diffusion models for structure with inverse folding to recover sequences. In this work, we propose diffusioN Optimized Sampling (NOS), a guidance method for discrete diffusion models that follows gradients in the hidden states of the denoising network. NOS makes it possible to perform design directly in sequence space, circumventing significant limitations of structure-based methods, including scarce data and challenging inverse design. Moreover, we use NOS to generalize LaMBO, a Bayesian optimization procedure for sequence design that facilitates multiple objectives and edit-based constraints. The resulting method, LaMBO-2, enables discrete diffusions and stronger performance with limited edits through a novel application of saliency maps. We apply LaMBO-2 to a real-world protein design task, optimizing antibodies for higher expression yield and binding affinity to several therapeutic targets under locality and developability constraints, attaining a 99{\textbackslash}\% expression rate and 40{\textbackslash}\% binding rate in exploratory in vitro experiments.}
}

@inproceedings{vignac_digress_2022,
  title = {{{DiGress}}: {{Discrete Denoising}} Diffusion for Graph Generation},
  shorttitle = {{{DiGress}}},
  booktitle = {The {{Eleventh International Conference}} on {{Learning Representations}}},
  author = {Vignac, Clement and Krawczuk, Igor and Siraudin, Antoine and Wang, Bohan and Cevher, Volkan and Frossard, Pascal},
  year = {2022},
  month = sep,
  urldate = {2024-01-09},
  abstract = {This work introduces DiGress, a discrete denoising diffusion model for generating graphs with categorical node and edge attributes. Our model utilizes a discrete diffusion process that progressively edits graphs with noise, through the process of adding or removing edges and changing the categories. A graph transformer network is trained to revert this process, simplifying the problem of distribution learning over graphs into a sequence of node and edge classification tasks. We further improve sample quality by introducing a Markovian noise model that preserves the marginal distribution of node and edge types during diffusion, and by incorporating auxiliary graph-theoretic features. A procedure for conditioning the generation on graph-level features is also proposed. DiGress achieves state-of-the-art performance on molecular and non-molecular datasets, with up to 3x validity improvement on a planar graph dataset. It is also the first model to scale to the large GuacaMol dataset containing 1.3M drug-like molecules without the use of molecule-specific representations.}
}


@article{bronstein_geometric_2021,
	title = {Geometric {Deep} {Learning}: {Grids}, {Groups}, {Graphs}, {Geodesics}, and {Gauges}},
	shorttitle = {Geometric {Deep} {Learning}},
	noURL = {http://arxiv.org/abs/2104.13478},
	abstract = {The last decade has witnessed an experimental revolution in data science and machine learning, epitomised by deep learning methods. Indeed, many high-dimensional learning tasks previously thought to be beyond reach -- such as computer vision, playing Go, or protein folding -- are in fact feasible with appropriate computational scale. Remarkably, the essence of deep learning is built from two simple algorithmic principles: first, the notion of representation or feature learning, whereby adapted, often hierarchical, features capture the appropriate notion of regularity for each task, and second, learning by local gradient-descent type methods, typically implemented as backpropagation. While learning generic functions in high dimensions is a cursed estimation problem, most tasks of interest are not generic, and come with essential pre-defined regularities arising from the underlying low-dimensionality and structure of the physical world. This text is concerned with exposing these regularities through unified geometric principles that can be applied throughout a wide spectrum of applications. Such a 'geometric unification' endeavour, in the spirit of Felix Klein's Erlangen Program, serves a dual purpose: on one hand, it provides a common mathematical framework to study the most successful neural network architectures, such as CNNs, RNNs, GNNs, and Transformers. On the other hand, it gives a constructive procedure to incorporate prior physical knowledge into neural architectures and provide principled way to build future architectures yet to be invented.},
	urldate = {2022-01-18},
	journal = {arXiv:2104.13478 [cs, stat]},
	author = {Bronstein, Michael M. and Bruna, Joan and Cohen, Taco and Veličković, Petar},
	month = may,
	year = {2021},
	note = {arXiv: 2104.13478},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Computational Geometry},
	annote = {Comment: 156 pages. Work in progress -- comments welcome!},
}


@inproceedings{gilmer_neural_2017,
	title = {Neural {Message} {Passing} for {Quantum} {Chemistry}},
	noURL = {http://proceedings.mlr.press/v70/gilmer17a.html},
	abstract = {Supervised learning on molecules has incredible potential to be useful in chemistry, drug discovery, and materials science. Luckily, several promising and closely related neural network models inva...},
	language = {en},
	urldate = {2021-01-13},
	booktitle = {International {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Gilmer, Justin and Schoenholz, Samuel S. and Riley, Patrick F. and Vinyals, Oriol and Dahl, George E.},
	month = jul,
	year = {2017},
	note = {ISSN: 2640-3498},
	pages = {1263--1272},
}


@article{vaswani_attention_2017,
	title = {Attention is {All} you {Need}},
	volume = {30},
	noURL = {https://papers.nips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html},
	language = {en},
	urldate = {2021-06-18},
	journal = {Advances in Neural Information Processing Systems},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, \L{}ukasz and Polosukhin, Illia},
	year = {2017},
}

@inproceedings{
xie2022crystal,
title={Crystal Diffusion Variational Autoencoder for Periodic Material Generation},
author={Tian Xie and Xiang Fu and Octavian-Eugen Ganea and Regina Barzilay and Tommi S. Jaakkola},
booktitle={International Conference on Learning Representations},
year={2022},
noURL={https://openreview.net/forum?id=03RLpj-tc_}
}

@inproceedings{heusel_gans_2017,
 author = {Heusel, Martin and Ramsauer, Hubert and Unterthiner, Thomas and Nessler, Bernhard and Hochreiter, Sepp},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium},
 noURL = {https://proceedings.neurips.cc/paper_files/paper/2017/file/8a1d694707eb0fefe65871369074926d-Paper.pdf},
 volume = {30},
 year = {2017}
}

@article{preuer_frechet_2018,
author = {Preuer, Kristina and Renz, Philipp and Unterthiner, Thomas and Hochreiter, Sepp and Klambauer, G{\"u}nter},
title = {Fréchet ChemNet Distance: A Metric for Generative Models for Molecules in Drug Discovery},
journal = {Journal of Chemical Information and Modeling},
volume = {58},
number = {9},
pages = {1736-1741},
year = {2018},
doi = {10.1021/acs.jcim.8b00234},
note = {PMID: 30118593},
noURL = {https://doi.org/10.1021/acs.jcim.8b00234},
eprint = {https://doi.org/10.1021/acs.jcim.8b00234}
}

@inproceedings{
stark2024dirichlet,
title={Dirichlet Flow Matching with Applications to {DNA} Sequence Design},
author={Hannes Stark and Bowen Jing and Chenyu Wang and Gabriele Corso and Bonnie Berger and Regina Barzilay and Tommi Jaakkola},
booktitle={Forty-first International Conference on Machine Learning},
year={2024},
noURL={https://openreview.net/forum?id=syXFAVqx85}
}

@inproceedings{song_score-based_2021,
  title = {Score-{{Based Generative Modeling}} through {{Stochastic Differential Equations}}},
  booktitle = {International {{Conference}} on {{Learning Representations}}},
  author = {Song, Yang and {Sohl-Dickstein}, Jascha and Kingma, Diederik P. and Kumar, Abhishek and Ermon, Stefano and Poole, Ben},
  year = {2021},
  urldate = {2024-01-25},
  abstract = {Creating noise from data is easy; creating data from noise is generative modeling. We present a stochastic differential equation (SDE) that smoothly transforms a complex data distribution to a known prior distribution by slowly injecting noise, and a corresponding reverse-time SDE that transforms the prior distribution back into the data distribution by slowly removing the noise. Crucially, the reverse-time SDE depends only on the time-dependent gradient field (a.k.a., score) of the perturbed data distribution. By leveraging advances in score-based generative modeling, we can accurately estimate these scores with neural networks, and use numerical SDE solvers to generate samples. We show that this framework encapsulates previous approaches in score-based generative modeling and diffusion probabilistic modeling, allowing for new sampling procedures and new modeling capabilities. In particular, we introduce a predictor-corrector framework to correct errors in the evolution of the discretized reverse-time SDE. We also derive an equivalent neural ODE that samples from the same distribution as the SDE, but additionally enables exact likelihood computation, and improved sampling efficiency. In addition, we provide a new way to solve inverse problems with score-based models, as demonstrated with experiments on class-conditional generation, image inpainting, and colorization. Combined with multiple architectural improvements, we achieve record-breaking performance for unconditional image generation on CIFAR-10 with an Inception score of 9.89 and FID of 2.20, a competitive likelihood of 2.99 bits/dim, and demonstrate high fidelity generation of \$1024{\textbackslash}times 1024\$ images for the first time from a score-based generative model.},
  langid = {english},
}

@inproceedings{ho_denoising_2020-2,
  title = {Denoising {{Diffusion Probabilistic Models}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  year = {2020},
  volume = {33},
  pages = {6840--6851},
  publisher = {Curran Associates, Inc.},
  urldate = {2024-11-21},
  abstract = {We present high quality image synthesis results using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. Our best results are obtained by training on a weighted variational bound designed according to a novel connection between diffusion probabilistic models and denoising score matching with Langevin dynamics, and our models naturally admit a progressive lossy decompression scheme that can be interpreted as a generalization of autoregressive decoding. On the unconditional CIFAR10 dataset, we obtain an Inception score of 9.46 and a state-of-the-art FID score of 3.17. On 256x256 LSUN, we obtain sample quality similar to ProgressiveGAN.},
}

@inproceedings{sohl-dickstein_deep_2015,
  title = {Deep {{Unsupervised Learning}} Using {{Nonequilibrium Thermodynamics}}},
  booktitle = {Proceedings of the 32nd {{International Conference}} on {{Machine Learning}}},
  author = {{Sohl-Dickstein}, Jascha and Weiss, Eric and Maheswaranathan, Niru and Ganguli, Surya},
  year = {2015},
  month = jun,
  pages = {2256--2265},
  publisher = {PMLR},
  issn = {1938-7228},
  urldate = {2024-01-25},
  abstract = {A central problem in machine learning involves modeling complex data-sets using highly flexible families of probability distributions in which learning, sampling, inference, and evaluation are still analytically or computationally tractable. Here, we develop an approach that simultaneously achieves both flexibility and tractability. The essential idea, inspired by non-equilibrium statistical physics, is to systematically and slowly destroy structure in a data distribution through an iterative forward diffusion process. We then learn a reverse diffusion process that restores structure in data, yielding a highly flexible and tractable generative model of the data. This approach allows us to rapidly learn, sample from, and evaluate probabilities in deep generative models with thousands of layers or time steps, as well as to compute conditional and posterior probabilities under the learned model. We additionally release an open source reference implementation of the algorithm.},
  langid = {english},
}

@article{park_has_2024,
	title = {Has generative artificial intelligence solved inverse materials design?},
	volume = {7},
	issn = {2590-2385},
	noURL = {https://www.sciencedirect.com/science/article/pii/S259023852400242X},
	doi = {10.1016/j.matt.2024.05.017},
	abstract = {The directed design and discovery of compounds with pre-determined properties is a long-standing challenge in materials research. We provide a perspective on progress toward achieving this goal using generative models for chemical compositions and crystal structures based on a set of powerful statistical techniques drawn from the artificial intelligence community. We introduce the central concepts underpinning generative models of crystalline materials. Coverage is provided of early implementations for inorganic crystals based on generative adversarial networks and variational autoencoders through to ongoing progress involving autoregressive and diffusion models. The influence of the choice of chemical representation and the generative architecture is discussed, along with metrics for quantifying the quality of the hypothetical compounds produced. While further developments are required to enable realistic predictions drawn from richer structure and property datasets, generative artificial intelligence is already proving to be complementary to traditional materials design strategies.},
	number = {7},
	urldate = {2025-01-16},
	journal = {Matter},
	author = {Park, Hyunsoo and Li, Zhenzhu and Walsh, Aron},
	month = jul,
	year = {2024},
	pages = {2355--2367},
}

@inproceedings{jiao_space_2024,
  title = {Space {{Group Constrained Crystal Generation}}},
  booktitle = {The {{Twelfth International Conference}} on {{Learning Representations}}},
  author = {Jiao, Rui and Huang, Wenbing and Liu, Yu and Zhao, Deli and Liu, Yang},
  year = {2024},
  urldate = {2025-01-16},
  abstract = {Crystals are the foundation of numerous scientific and industrial applications. While various learning-based approaches have been proposed for crystal generation, existing methods neglect the spacegroup constraint which is crucial in describing the geometry of crystals and closely relevant to many desirable properties. However, considering spacegroup constraint is challenging owing to its diverse and nontrivial forms. In this paper, we reduce the spacegroup constraint into an equivalent formulation that is more tractable to be handcrafted into the generation process. In particular, we translate the spacegroup constraint into two cases: the basis constraint of the invariant exponential space of the lattice matrix and the Wyckoff position constraint of the fractional coordinates. Upon the derived constraints, we then propose DiffCSP++, a novel diffusion model that has enhanced a previous work DiffCSP by further taking spacegroup constraint into account. Experiments on several popular datasets verify the benefit of the involvement of the spacegroup constraint, and show that our DiffCSP++ achieves the best or comparable performance on crystal structure prediction and ab initio crystal generation.},
  langid = {english}
}


@inproceedings{levy_symmcd_2024,
  title = {{{SymmCD}}: {{Symmetry-Preserving Crystal Generation}} with {{Diffusion Models}}},
  shorttitle = {{{SymmCD}}},
  booktitle = {{{AI}} for {{Accelerated Materials Design}} - {{NeurIPS}} 2024},
  author = {Levy, Daniel and Panigrahi, Siba Smarak and Kaba, S{\'e}kou-Oumar and Zhu, Qiang and Galkin, Mikhail and Miret, Santiago and Ravanbakhsh, Siamak},
  year = {2024},
  month = nov,
  urldate = {2025-01-16},
  abstract = {Generating novel crystalline materials has the potential to lead to advancements in fields such as electronics, energy storage, and catalysis. The defining characteristic of crystals is their symmetry, which plays a central role in determining their physical properties. However, existing crystal generation methods either fail to generate materials that display the symmetries of real-world crystals, or simply replicate the symmetry information from examples in a database. To address this limitation, we propose SymmCD, a novel diffusion-based generative model that explicitly incorporates crystallographic symmetry into the generative process. We decompose crystals into two components and learn their joint distribution through diffusion: 1) the asymmetric unit, the smallest subset of the crystal which can generate the whole crystal through symmetry transformations, and; 2) the symmetry transformations needed to be applied to each atom in the asymmetric unit. We also use a novel and interpretable representation for these transformations, enabling generalization across different crystallographic symmetry groups. We showcase the competitive performance of SymmCD on a subset of the Materials Project, obtaining diverse and valid crystals with realistic symmetries and predicted properties.},
  langid = {english}
}


@inproceedings{jiao_crystal_2023,
  title = {Crystal {{Structure Prediction}} by {{Joint Equivariant Diffusion}}},
  booktitle = {Thirty-Seventh {{Conference}} on {{Neural Information Processing Systems}}},
  author = {Jiao, Rui and Huang, Wenbing and Lin, Peijia and Han, Jiaqi and Chen, Pin and Lu, Yutong and Liu, Yang},
  year = {2023},
  month = nov,
  urldate = {2025-01-16},
  abstract = {Crystal Structure Prediction (CSP) is crucial in various scientific disciplines. While CSP can be addressed by employing currently-prevailing generative models (**e.g.** diffusion models), this task encounters unique challenges owing to the symmetric geometry of crystal structures---the invariance of translation, rotation, and periodicity. To incorporate the above symmetries, this paper proposes DiffCSP, a novel diffusion model to learn the structure distribution from stable crystals. To be specific, DiffCSP jointly generates the lattice and atom coordinates for each crystal by employing a periodic-E(3)-equivariant denoising model, to better model the crystal geometry. Notably, different from related equivariant generative approaches, DiffCSP leverages fractional coordinates other than Cartesian coordinates to represent crystals, remarkably promoting the diffusion and the generation process of atom positions. Extensive experiments verify that our DiffCSP remarkably outperforms existing CSP methods, with a much lower computation cost in contrast to DFT-based methods. Moreover, the superiority of DiffCSP is still observed when it is extended for ab initio crystal generation.},
  langid = {english}
}



@article{mattergenNature,
	title = {A generative model for inorganic materials design},
	copyright = {2025 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {1476-4687},
	noURL = {https://www.nature.com/articles/s41586-025-08628-5},
	doi = {10.1038/s41586-025-08628-5},
	abstract = {The design of functional materials with desired properties is essential in driving technological advances in areas like energy storage, catalysis, and carbon capture1–3. Generative models provide a new paradigm for materials design by directly generating novel materials given desired property constraints, but current methods have low success rate in proposing stable crystals or can only satisfy a limited set of property constraints 4−11. Here, we present MatterGen, a model that generates stable, diverse inorganic materials across the periodic table and can further be fine-tuned to steer the generation towards a broad range of property constraints. Compared to prior generative models 4,12, structures produced by MatterGen are more than twice as likely to be novel and stable, and more than 10 times closer to the local energy minimum. After fine-tuning, MatterGen successfully generates stable, novel materials with desired chemistry, symmetry, as well as mechanical, electronic and magnetic properties. As a proof of concept, we synthesize one of the generated structures and measure its property value to be within 20 \% of our target. We believe that the quality of generated materials and the breadth of MatterGen’s capabilities represent a major advancement towards creating a foundational generative model for materials design.},
	language = {en},
	urldate = {2025-01-21},
	journal = {Nature},
	author = {Zeni, Claudio and Pinsler, Robert and Zügner, Daniel and Fowler, Andrew and Horton, Matthew and Fu, Xiang and Wang, Zilong and Shysheya, Aliaksandra and Crabbé, Jonathan and Ueda, Shoko and Sordillo, Roberto and Sun, Lixin and Smith, Jake and Nguyen, Bichlien and Schulz, Hannes and Lewis, Sarah and Huang, Chin-Wei and Lu, Ziheng and Zhou, Yichi and Yang, Han and Hao, Hongxia and Li, Jielan and Yang, Chunlei and Li, Wenjie and Tomioka, Ryota and Xie, Tian},
	month = jan,
	year = {2025},
	note = {Publisher: Nature Publishing Group},
	keywords = {Computer science, Theory and computation},
	pages = {1--3},
}

@misc{mattergenArxiv,
	title = {{MatterGen}: a generative model for inorganic materials design},
	shorttitle = {{MatterGen}},
	noURL = {http://arxiv.org/abs/2312.03687},
	doi = {10.48550/arXiv.2312.03687},
	abstract = {The design of functional materials with desired properties is essential in driving technological advances in areas like energy storage, catalysis, and carbon capture. Generative models provide a new paradigm for materials design by directly generating entirely novel materials given desired property constraints. Despite recent progress, current generative models have low success rate in proposing stable crystals, or can only satisfy a very limited set of property constraints. Here, we present MatterGen, a model that generates stable, diverse inorganic materials across the periodic table and can further be fine-tuned to steer the generation towards a broad range of property constraints. To enable this, we introduce a new diffusion-based generative process that produces crystalline structures by gradually refining atom types, coordinates, and the periodic lattice. We further introduce adapter modules to enable fine-tuning towards any given property constraints with a labeled dataset. Compared to prior generative models, structures produced by MatterGen are more than twice as likely to be novel and stable, and more than 15 times closer to the local energy minimum. After fine-tuning, MatterGen successfully generates stable, novel materials with desired chemistry, symmetry, as well as mechanical, electronic and magnetic properties. Finally, we demonstrate multi-property materials design capabilities by proposing structures that have both high magnetic density and a chemical composition with low supply-chain risk. We believe that the quality of generated materials and the breadth of MatterGen's capabilities represent a major advancement towards creating a universal generative model for materials design.},
	urldate = {2025-01-21},
	publisher = {arXiv},
	author = {Zeni, Claudio and Pinsler, Robert and Zügner, Daniel and Fowler, Andrew and Horton, Matthew and Fu, Xiang and Shysheya, Sasha and Crabbé, Jonathan and Sun, Lixin and Smith, Jake and Nguyen, Bichlien and Schulz, Hannes and Lewis, Sarah and Huang, Chin-Wei and Lu, Ziheng and Zhou, Yichi and Yang, Han and Hao, Hongxia and Li, Jielan and Tomioka, Ryota and Xie, Tian},
	month = jan,
	year = {2024},
	note = {arXiv:2312.03687 [cond-mat]},
	keywords = {Computer Science - Artificial Intelligence, Condensed Matter - Materials Science},
	annote = {Comment: 13 pages main text, 35 pages supplementary information},
}




@article{cheetham_artificial_2024,
	title = {Artificial {Intelligence} {Driving} {Materials} {Discovery}? {Perspective} on the {Article}: {Scaling} {Deep} {Learning} for {Materials} {Discovery}},
	volume = {36},
	issn = {0897-4756},
	shorttitle = {Artificial {Intelligence} {Driving} {Materials} {Discovery}?},
	noURL = {https://doi.org/10.1021/acs.chemmater.4c00643},
	doi = {10.1021/acs.chemmater.4c00643},
	abstract = {The discovery of new crystalline inorganic compounds─novel compositions of matter within known structure types, or even compounds with completely new crystal structures─constitutes an important goal of solid-state and materials chemistry. Some fractions of new compounds can eventually lead to new structural and functional materials that enhance the efficiency of existing technologies or even enable completely new technologies. Materials researchers eagerly welcome new approaches to the discovery of new compounds, especially those that offer the promise of accelerated success. The recent report from a group of scientists at Google who employ a combination of existing data sets, high-throughput density functional theory calculations of structural stability, and the tools of artificial intelligence and machine learning (AI/ML) to propose new compounds is an exciting advance. We examine the claims of this work here, unfortunately finding scant evidence for compounds that fulfill the trifecta of novelty, credibility, and utility. While the methods adopted in this work appear to hold promise, there is clearly a great need to incorporate domain expertise in materials synthesis and crystallography.},
	number = {8},
	urldate = {2025-01-21},
	journal = {Chemistry of Materials},
	author = {Cheetham, Anthony K. and Seshadri, Ram},
	month = apr,
	year = {2024},
	note = {Publisher: American Chemical Society},
	pages = {3490--3495},
}

@article{merchant_scaling_2023,
	title = {Scaling deep learning for materials discovery},
	volume = {624},
	copyright = {2023 The Author(s)},
	issn = {1476-4687},
	noURL = {https://www.nature.com/articles/s41586-023-06735-9},
	doi = {10.1038/s41586-023-06735-9},
	abstract = {Novel functional materials enable fundamental breakthroughs across technological applications from clean energy to information processing1–11. From microchips to batteries and photovoltaics, discovery of inorganic crystals has been bottlenecked by expensive trial-and-error approaches. Concurrently, deep-learning models for language, vision and biology have showcased emergent predictive capabilities with increasing data and computation12–14. Here we show that graph networks trained at scale can reach unprecedented levels of generalization, improving the efficiency of materials discovery by an order of magnitude. Building on 48,000 stable crystals identified in continuing studies15–17, improved efficiency enables the discovery of 2.2 million structures below the current convex hull, many of which escaped previous human chemical intuition. Our work represents an order-of-magnitude expansion in stable materials known to humanity. Stable discoveries that are on the final convex hull will be made available to screen for technological applications, as we demonstrate for layered materials and solid-electrolyte candidates. Of the stable structures, 736 have already been independently experimentally realized. The scale and diversity of hundreds of millions of first-principles calculations also unlock modelling capabilities for downstream applications, leading in particular to highly accurate and robust learned interatomic potentials that can be used in condensed-phase molecular-dynamics simulations and high-fidelity zero-shot prediction of ionic conductivity.},
	language = {en},
	number = {7990},
	urldate = {2025-01-21},
	journal = {Nature},
	author = {Merchant, Amil and Batzner, Simon and Schoenholz, Samuel S. and Aykol, Muratahan and Cheon, Gowoon and Cubuk, Ekin Dogus},
	month = dec,
	year = {2023},
	note = {Publisher: Nature Publishing Group},
	keywords = {Computer science, Scaling laws},
	pages = {80--85},
}


@article{wbmDataset,
	title = {Predicting stable crystalline compounds using chemical similarity},
	volume = {7},
	copyright = {2021 The Author(s)},
	issn = {2057-3960},
	noURL = {https://www.nature.com/articles/s41524-020-00481-6},
	doi = {10.1038/s41524-020-00481-6},
	abstract = {We propose an efficient high-throughput scheme for the discovery of stable crystalline phases. Our approach is based on the transmutation of known compounds, through the substitution of atoms in the crystal structure with chemically similar ones. The concept of similarity is defined quantitatively using a measure of chemical replaceability, extracted by data-mining experimental databases. In this way we build 189,981 possible crystal phases, including 18,479 that are on the convex hull of stability. The resulting success rate of 9.72\% is at least one order of magnitude better than the usual success rate of systematic high-throughput calculations for a specific family of materials, and comparable with speed-up factors of machine learning filtering procedures. As a characterization of the set of 18,479 stable compounds, we calculate their electronic band gaps, magnetic moments, and hardness. Our approach, that can be used as a filter on top of any high-throughput scheme, enables us to efficiently extract stable compounds from tremendously large initial sets, without any initial assumption on their crystal structures or chemical compositions.},
	language = {en},
	number = {1},
	urldate = {2025-01-21},
	journal = {npj Computational Materials},
	author = {Wang, Hai-Chen and Botti, Silvana and Marques, Miguel A. L.},
	month = jan,
	year = {2021},
	note = {Publisher: Nature Publishing Group},
	keywords = {Computational methods, Electronic properties and materials},
	pages = {1--9},
}


@misc{ramachandran_searching_2017,
	title = {Searching for {Activation} {Functions}},
	noURL = {http://arxiv.org/abs/1710.05941},
	doi = {10.48550/arXiv.1710.05941},
	abstract = {The choice of activation functions in deep networks has a significant effect on the training dynamics and task performance. Currently, the most successful and widely-used activation function is the Rectified Linear Unit (ReLU). Although various hand-designed alternatives to ReLU have been proposed, none have managed to replace it due to inconsistent gains. In this work, we propose to leverage automatic search techniques to discover new activation functions. Using a combination of exhaustive and reinforcement learning-based search, we discover multiple novel activation functions. We verify the effectiveness of the searches by conducting an empirical evaluation with the best discovered activation function. Our experiments show that the best discovered activation function, \$f(x) = x {\textbackslash}cdot {\textbackslash}text\{sigmoid\}({\textbackslash}beta x)\$, which we name Swish, tends to work better than ReLU on deeper models across a number of challenging datasets. For example, simply replacing ReLUs with Swish units improves top-1 classification accuracy on ImageNet by 0.9{\textbackslash}\% for Mobile NASNet-A and 0.6{\textbackslash}\% for Inception-ResNet-v2. The simplicity of Swish and its similarity to ReLU make it easy for practitioners to replace ReLUs with Swish units in any neural network.},
	urldate = {2025-01-22},
	publisher = {arXiv},
	author = {Ramachandran, Prajit and Zoph, Barret and Le, Quoc V.},
	month = oct,
	year = {2017},
	note = {arXiv:1710.05941 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
	annote = {Comment: Updated version of "Swish: a Self-Gated Activation Function"},
	file = {Preprint PDF:C\:\\Users\\filek51\\Zotero\\storage\\8DZTFGC3\\Ramachandran m. fl. - 2017 - Searching for Activation Functions.pdf:application/pdf;Snapshot:C\:\\Users\\filek51\\Zotero\\storage\\WV3DDXUV\\1710.html:text/html},
}


@inproceedings{loshchilov_decoupled_2019,
  title = {Decoupled {{Weight Decay Regularization}}},
  booktitle = {International {{Conference}} on {{Learning Representations}}},
  author = {Loshchilov, Ilya and Hutter, Frank},
  year = {2019},
  urldate = {2025-01-22},
  abstract = {L\$\_2\$ regularization and weight decay regularization are equivalent for standard stochastic gradient descent (when rescaled by the learning rate), but as we demonstrate this is {\textbackslash}emph\{not\} the case for adaptive gradient algorithms, such as Adam. While common implementations of these algorithms employ L\$\_2\$ regularization (often calling it ``weight decay'' in what may be misleading due to the inequivalence we expose), we propose a simple modification to recover the original formulation of weight decay regularization by {\textbackslash}emph\{decoupling\} the weight decay from the optimization steps taken w.r.t. the loss function. We provide empirical evidence that our proposed modification (i) decouples the optimal choice of weight decay factor from the setting of the learning rate for both standard SGD and Adam and (ii) substantially improves Adam's generalization performance, allowing it to compete with SGD with momentum on image classification datasets (on which it was previously typically outperformed by the latter). Our proposed decoupled weight decay has already been adopted by many researchers, and the community has implemented it in TensorFlow and PyTorch; the complete source code for our experiments is available at {\textbackslash}url\{https://github.com/loshchil/AdamW-and-SGDW\}},
  langid = {english},
  file = {C:\Users\filek51\Zotero\storage\75C6CC3W\Loshchilov and Hutter - 2018 - Decoupled Weight Decay Regularization.pdf}
}



%% Oskar


@article{parackal_identifying_2024,
	title = {Identifying crystal structures beyond known prototypes from x-ray powder diffraction spectra},
	volume = {8},
	issn = {2475-9953},
	noURL = {https://link.aps.org/doi/10.1103/PhysRevMaterials.8.103801},
	doi = {10.1103/PhysRevMaterials.8.103801},
	abstract = {The large amount of powder diffraction data for which the corresponding crystal structures have not yet been identified suggests the existence of numerous undiscovered, physically relevant crystal structure prototypes. In this paper, we present a scheme to resolve powder diffraction data into crystal structures with precise atomic coordinates by screening the space of all possible atomic arrangements, i.e., structural prototypes, including those not previously observed, using a pre-trained machine learning (ML) model. This involves (i) enumerating all possible symmetry-confined ways in which a given composition can be accommodated in a given space group, (ii) ranking the element-assigned prototype representations using energies predicted using the Wyckoff representation regression  ML model [Goodall  , ], (iii) assigning and perturbing atoms along the degree of freedom allowed by the Wyckoff positions to match the experimental diffraction data, and (iv) validating the thermodynamic stability of the material using density-functional theory. An advantage of the presented method is that it does not rely on a database of previously observed prototypes and is, therefore capable of finding crystal structures with entirely new symmetric arrangements of atoms. We demonstrate the workflow on unidentified x-ray diffraction spectra from the ICDD database and identify a number of stable structures, where a majority turns out to be derivable from known prototypes. However, at least two are found not to be part of our prior structural data sets.
            
              
              
                
                  Published by the American Physical Society
                  2024},
	language = {en},
	number = {10},
	urldate = {2025-01-24},
	journal = {Physical Review Materials},
	author = {Parackal, Abhijith S. and Goodall, Rhys E. A. and Faber, Felix A. and Armiento, Rickard},
	month = oct,
	year = {2024},
	pages = {103801},
	file = {Parackal m. fl. - 2024 - Identifying crystal structures beyond known protot.pdf:/Users/oskarandersson/Zotero/storage/VAIB59DI/Parackal m. fl. - 2024 - Identifying crystal structures beyond known protot.pdf:application/pdf},
}


@article{mehl_aflow_2017,
	title = {The {AFLOW} {Library} of {Crystallographic} {Prototypes}: {Part} 1},
	volume = {136},
	issn = {09270256},
	shorttitle = {The {AFLOW} {Library} of {Crystallographic} {Prototypes}},
	noURL = {https://linkinghub.elsevier.com/retrieve/pii/S0927025617300241},
	doi = {10.1016/j.commatsci.2017.01.017},
	abstract = {An easily available resource of common crystal structures is essential for researchers, teachers, and students. For many years this was provided by the U.S. Naval Research Laboratory’s Crystal Lattice Structures web page, which contained nearly 300 crystal structures, including a majority of those which were given Strukturbericht designations. This article presents the updated version of the database, now including 288 standardized structures in 92 space groups. Similar to what was available on the web page before, we present a complete description of each structure, including the formulas for the primitive vectors, all of the basis vectors, and the AFLOW commands to generate the standardized cells. We also present a brief discussion of crystal systems, space groups, primitive and conventional lattices, Wyckoﬀ positions, Pearson symbols and Strukturbericht designations. The web version of this database is located at http://aﬂow.org/CrystalDatabase.},
	language = {en},
	urldate = {2025-01-24},
	journal = {Computational Materials Science},
	author = {Mehl, Michael J. and Hicks, David and Toher, Cormac and Levy, Ohad and Hanson, Robert M. and Hart, Gus and Curtarolo, Stefano},
	month = aug,
	year = {2017},
	pages = {S1--S828},
	file = {Mehl m. fl. - 2017 - The AFLOW Library of Crystallographic Prototypes .pdf:/Users/oskarandersson/Zotero/storage/7HS6H8DD/Mehl m. fl. - 2017 - The AFLOW Library of Crystallographic Prototypes .pdf:application/pdf},
}


@book{ITA2002,
  added-at = {2011-12-21T01:05:11.000+0100},
  address = {Dordrecht, Boston, London},
  author = {IUCr},
  bibnoURL = {https://www.bibsonomy.org/bibtex/2e82b4160d90d338889137b8010ea4670/fairybasslet},
  edition = {5. revised edition},
  interhash = {db6e6a27bf9c48109ba741163f831366},
  intrahash = {e82b4160d90d338889137b8010ea4670},
  keywords = {imported},
  publisher = {Kluwer Academic Publishers},
  series = {International Tables for Crystallography},
  timestamp = {2019-03-11T21:06:37.000+0100},
  title = {International Tables for Crystallography, Volume A: Space Group Symmetry},
  year = 2002
}

@misc{batatia2023foundation,
      title={A foundation model for atomistic materials chemistry},
      author={Ilyes Batatia and Philipp Benner and Yuan Chiang and Alin M. Elena and Dávid P. Kovács and Janosh Riebesell and Xavier R. Advincula and Mark Asta and William J. Baldwin and Noam Bernstein and Arghya Bhowmik and Samuel M. Blau and Vlad Cărare and James P. Darby and Sandip De and Flaviano Della Pia and Volker L. Deringer and Rokas Elijošius and Zakariya El-Machachi and Edvin Fako and Andrea C. Ferrari and Annalena Genreith-Schriever and Janine George and Rhys E. A. Goodall and Clare P. Grey and Shuang Han and Will Handley and Hendrik H. Heenen and Kersti Hermansson and Christian Holm and Jad Jaafar and Stephan Hofmann and Konstantin S. Jakob and Hyunwook Jung and Venkat Kapil and Aaron D. Kaplan and Nima Karimitari and Namu Kroupa and Jolla Kullgren and Matthew C. Kuner and Domantas Kuryla and Guoda Liepuoniute and Johannes T. Margraf and Ioan-Bogdan Magdău and Angelos Michaelides and J. Harry Moore and Aakash A. Naik and Samuel P. Niblett and Sam Walton Norwood and Niamh O'Neill and Christoph Ortner and Kristin A. Persson and Karsten Reuter and Andrew S. Rosen and Lars L. Schaaf and Christoph Schran and Eric Sivonxay and Tamás K. Stenczel and Viktor Svahn and Christopher Sutton and Cas van der Oord and Eszter Varga-Umbrich and Tejs Vegge and Martin Vondrák and Yangshuai Wang and William C. Witt and Fabian Zills and Gábor Csányi},
      year={2023},
      howpublished={arXiv:2401.00096},
      archivePrefix={arXiv},
      primaryClass={physics.chem-ph}
}


@article{jain_commentary_2013,
	title = {Commentary: {The} {Materials} {Project}: {A} materials genome approach to accelerating materials innovation},
	volume = {1},
	issn = {2166-532X},
	shorttitle = {Commentary},
	noURL = {https://pubs.aip.org/apm/article/1/1/011002/119685/Commentary-The-Materials-Project-A-materials},
	doi = {10.1063/1.4812323},
	abstract = {Accelerating the discovery of advanced materials is essential for human welfare and sustainable, clean energy. In this paper, we introduce the Materials Project (www.materialsproject.org), a core program of the Materials Genome Initiative that uses high-throughput computing to uncover the properties of all known inorganic materials. This open dataset can be accessed through multiple channels for both interactive exploration and data mining. The Materials Project also seeks to create open-source platforms for developing robust, sophisticated materials analyses. Future efforts will enable users to perform ‘‘rapid-prototyping’’ of new materials in silico, and provide researchers with new avenues for cost-effective, data-driven materials design.},
	language = {en},
	number = {1},
	urldate = {2025-01-28},
	journal = {APL Materials},
	author = {Jain, Anubhav and Ong, Shyue Ping and Hautier, Geoffroy and Chen, Wei and Richards, William Davidson and Dacek, Stephen and Cholia, Shreyas and Gunter, Dan and Skinner, David and Ceder, Gerbrand and Persson, Kristin A.},
	month = jul,
	year = {2013},
	pages = {011002},
	file = {Jain m. fl. - 2013 - Commentary The Materials Project A materials gen.pdf:/Users/oskarandersson/Zotero/storage/7S35HSLQ/Jain m. fl. - 2013 - Commentary The Materials Project A materials gen.pdf:application/pdf},
}

@article{pyxtal,
title = "PyXtal: A Python library for crystal structure generation and symmetry analysis",
journal = "Computer Physics Communications",
volume = "261",
pages = "107810",
year = "2021",
issn = "0010-4655",
doi = "https://doi.org/10.1016/j.cpc.2020.107810",
noURL = "http://www.sciencedirect.com/science/article/pii/S0010465520304057",
author = "Scott Fredericks and Kevin Parrish and Dean Sayre and Qiang Zhu",
}

@book{mullerSymmetryRelationshipsCrystal2013,
  title = {Symmetry Relationships between Crystal Structures: Applications of Crystallographic Group Theory in Crystal Chemistry},
  shorttitle = {Symmetry Relationships between Crystal Structures},
  author = {M{\"u}ller, Ulrich and Wondratschek, Hans and B{\"a}rnighausen, Hartmut},
  year = {2013},
  series = {{{IUCr}} Texts on Crystallography},
  number = {18},
  publisher = {Oxford university press},
  address = {Oxford},
  isbn = {978-0-19-966995-0},
  langid = {english},
  lccn = {548.81},
  file = {/home/abhijith/Zotero/storage/68VIZVLQ/grupy-struktury.pdf}
}
% == BibTeX quality report for mullerSymmetryRelationshipsCrystal2013:
% ? unused Library catalog ("BnF ISBN")


@article{bartel_critical_2020,
	title = {A critical examination of compound stability predictions from machine-learned formation energies},
	volume = {6},
	issn = {2057-3960},
	noURL = {https://www.nature.com/articles/s41524-020-00362-y},
	doi = {10.1038/s41524-020-00362-y},
	abstract = {Abstract
            Machine learning has emerged as a novel tool for the efficient prediction of material properties, and claims have been made that machine-learned models for the formation energy of compounds can approach the accuracy of Density Functional Theory (DFT). The models tested in this work include five recently published compositional models, a baseline model using stoichiometry alone, and a structural model. By testing seven machine learning models for formation energy on stability predictions using the Materials Project database of DFT calculations for 85,014 unique chemical compositions, we show that while formation energies can indeed be predicted well, all compositional models perform poorly on predicting the stability of compounds, making them considerably less useful than DFT for the discovery and design of new solids. Most critically, in sparse chemical spaces where few stoichiometries have stable compounds, only the structural model is capable of efficiently detecting which materials are stable. The nonincremental improvement of structural models compared with compositional models is noteworthy and encourages the use of structural models for materials discovery, with the constraint that for any new composition, the ground-state structure is not known a priori. This work demonstrates that accurate predictions of formation energy do not imply accurate predictions of stability, emphasizing the importance of assessing model performance on stability predictions, for which we provide a set of publicly available tests.},
	language = {en},
	number = {1},
	urldate = {2025-01-29},
	journal = {npj Computational Materials},
	author = {Bartel, Christopher J. and Trewartha, Amalie and Wang, Qi and Dunn, Alexander and Jain, Anubhav and Ceder, Gerbrand},
	month = jul,
	year = {2020},
	pages = {97},
	file = {Bartel m. fl. - 2020 - A critical examination of compound stability predi.pdf:/Users/oskarandersson/Zotero/storage/RTCGZ8UC/Bartel m. fl. - 2020 - A critical examination of compound stability predi.pdf:application/pdf},
}


% ---

@article{zhu_wycryst_2024,
	title = {{WyCryst}: {Wyckoff} inorganic crystal generator framework},
	volume = {7},
	issn = {2590-2385},
	shorttitle = {{WyCryst}},
	noURL = {https://www.sciencedirect.com/science/article/pii/S2590238524003059},
	doi = {10.1016/j.matt.2024.05.042},
	abstract = {Recent advancements in property-directed generative design of inorganic materials account for periodicity and global Euclidian symmetry through translations, rotations, and reflections; however, they do not account for symmetry constraints within allowed space groups. To address this, we introduce a generative design framework (WyCryst) composed of three components: (1) a Wyckoff position-based inorganic crystal representation, (2) a property-directed variational autoencoder (VAE) model, and (3) an automated density functional theory (DFT) workflow for structure refinement. Our framework selectively generates materials by encoding the Wyckoff representation for each space group. As validation, we reproduce a variety of existing materials, CaTiO3, CsPbI3, BaTiO3, and CuInS2, for both ground-state and polymorphic crystal structure predictions. We also generate several ternary materials not found in the training database, which are proven to retain their symmetry and are phononically stable using our automated DFT workflow. We believe our symmetry-aware WyCryst takes a vital step toward AI-driven inorganic materials discovery.},
	number = {10},
	urldate = {2025-01-25},
	journal = {Matter},
	author = {Zhu, Ruiming and Nong, Wei and Yamazaki, Shuya and Hippalgaonkar, Kedar},
	month = oct,
	year = {2024},
	keywords = {AI for materials, crystal structure prediction, crystal symmetry, thermodynamic stability, variational autoencoders, Wyckoff symmetry},
	pages = {3469--3488},
}


@inproceedings{hoogeboom_argmax_2021-1,
	title = {Argmax {Flows} and {Multinomial} {Diffusion}: {Learning} {Categorical} {Distributions}},
	volume = {34},
	shorttitle = {Argmax {Flows} and {Multinomial} {Diffusion}},
	noURL = {https://proceedings.neurips.cc/paper/2021/hash/67d96d458abdef21792e6d8e590244e7-Abstract.html},
	abstract = {Generative flows and diffusion models have been predominantly trained on ordinal data, for example natural images. This paper introduces two extensions of flows and diffusion for categorical data such as language or image segmentation: Argmax Flows and Multinomial Diffusion. Argmax Flows are defined by a composition of a continuous distribution (such as a normalizing flow), and an argmax function. To optimize this model, we learn a probabilistic inverse for the argmax that lifts the categorical data to a continuous space. Multinomial Diffusion gradually adds categorical noise in a diffusion process, for which the generative denoising process is learned. We demonstrate that our method outperforms existing dequantization approaches on text modelling and modelling on image segmentation maps in log-likelihood.},
	urldate = {2025-01-27},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Hoogeboom, Emiel and Nielsen, Didrik and Jaini, Priyank and Forré, Patrick and Welling, Max},
	year = {2021},
	pages = {12454--12465},
}

@inproceedings{lou_discrete_2024,
	title = {Discrete {Diffusion} {Modeling} by {Estimating} the {Ratios} of the {Data} {Distribution}},
	noURL = {https://proceedings.mlr.press/v235/lou24a.html},
	abstract = {Despite their groundbreaking performance for many generative modeling tasks, diffusion models have fallen short on discrete data domains such as natural language. Crucially, standard diffusion models rely on the well-established theory of score matching, but efforts to generalize this to discrete structures have not yielded the same empirical gains. In this work, we bridge this gap by proposing score entropy, a novel loss that naturally extends score matching to discrete spaces, integrates seamlessly to build discrete diffusion models, and significantly boosts performance. Experimentally, we test our Score Entropy Discrete Diffusion models (SEDD) on standard language modeling tasks. For comparable model sizes, SEDD beats existing language diffusion paradigms (reducing perplexity by 252525-757575\%) and is competitive with autoregressive models, in particular outperforming GPT-2. Furthermore, compared to autoregressive mdoels, SEDD generates faithful text without requiring distribution annealing techniques like temperature scaling (around 666-8×8×8{\textbackslash}times better generative perplexity than un-annealed GPT-2), can trade compute and quality (similar quality with 32×32×32{\textbackslash}times fewer network evaluations), and enables controllable infilling (matching nucleus sampling quality while enabling other strategies besides left to right prompting).},
	language = {en},
	urldate = {2025-01-27},
	booktitle = {Proceedings of the 41st {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Lou, Aaron and Meng, Chenlin and Ermon, Stefano},
	month = jul,
	year = {2024},
	note = {ISSN: 2640-3498},
	pages = {32819--32848},
}


@inproceedings{campbell_continuous_2022,
  title = {A {{Continuous Time Framework}} for {{Discrete Denoising Models}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Campbell, Andrew and Benton, Joe and Bortoli, Valentin De and Rainforth, Tom and Deligiannidis, George and Doucet, Arnaud},
  year = {2022},
  month = may,
  urldate = {2024-01-09},
  abstract = {We provide the first complete continuous time framework for denoising diffusion models of discrete data. This is achieved by formulating the forward noising process and corresponding reverse time generative process as Continuous Time Markov Chains (CTMCs). The model can be efficiently trained using a continuous time version of the ELBO. We simulate the high dimensional CTMC using techniques developed in chemical physics and exploit our continuous time framework to derive high performance samplers that we show can outperform discrete time methods for discrete data. The continuous time treatment also enables us to derive a novel theoretical result bounding the error between the generated sample distribution and the true data distribution.},
  langid = {english},
  file = {C:\Users\filek51\Zotero\storage\FA8JMA6N\Campbell et al. - 2022 - A Continuous Time Framework for Discrete Denoising.pdf}
}


@inproceedings{sun_score-based_2023,
  title = {Score-Based {{Continuous-time Discrete Diffusion Models}}},
  booktitle = {International {{Conference}} on {{Learning Representations}}},
  author = {Sun, Haoran and Yu, Lijun and Dai, Bo and Schuurmans, Dale and Dai, Hanjun},
  year = {2023},
  month = feb,
  urldate = {2023-02-02},
  abstract = {Score-based modeling through stochastic differential equations (SDEs) has provided a new perspective on diffusion models, and demonstrated superior performance on continuous data. However, the gradient of the log-likelihood function, {\textbackslash}ie, the score function, is not properly defined for discrete spaces. This makes it non-trivial to adapt SDE with score functions to categorical data. In this paper, we extend diffusion models to discrete variables by introducing a stochastic jump process where the reverse process denoises via a continuous-time Markov chain. This formulation admits an analytical simulation during backward sampling. To learn the reverse process, we extend score matching to general categorical data, and show that an unbiased estimator can be obtained via simple matching of the conditional marginal distributions. We demonstrate the effectiveness of the proposed method on a set of synthetic and real-world music and image benchmarks.},
  langid = {english},
  file = {C:\Users\filek51\Zotero\storage\9JZN5SBU\Sun et al. - 2023 - Score-based Continuous-time Discrete Diffusion Mod.pdf}
}


@article{Belsky2002,
  title = {New developments in the Inorganic Crystal Structure Database (ICSD): accessibility in support of materials research and design},
  volume = {58},
  ISSN = {0108-7681},
  noURL = {http://dx.doi.org/10.1107/S0108768102006948},
  DOI = {10.1107/s0108768102006948},
  number = {3},
  journal = {Acta Crystallographica Section B Structural Science},
  publisher = {International Union of Crystallography (IUCr)},
  author = {Belsky,  Alec and Hellenbrandt,  Mariette and Karen,  Vicky Lynn and Luksch,  Peter},
  year = {2002},
  month = may,
  pages = {364–369}
}

@article{ROTH1993,
  title = {ChemInform Abstract: Synthesis, Structure, and X‐Ray Absorption Spectra of LixNbO2 and NaxNbO2 (x $\leq$ 1)},
  volume = {24},
  ISSN = {1522-2667},
  noURL = {http://dx.doi.org/10.1002/chin.199342004},
  DOI = {10.1002/chin.199342004},
  number = {42},
  journal = {ChemInform},
  publisher = {Wiley},
  author = {Roth,  H.‐F. and Meyer,  G. and Hu,  Z. and Kaindl,  G.},
  year = {1993},
  month = oct,
  pages = {1369–-1373}
}

@article{Hadenfeldt1988,
  title = {Darstellung und Kristallstruktur der Calciumpnictidiodide Ca2Nl,  Ca2Pl und Ca2Asl},
  volume = {558},
  ISSN = {1521-3749},
  noURL = {http://dx.doi.org/10.1002/zaac.19885580104},
  DOI = {10.1002/zaac.19885580104},
  number = {1},
  journal = {Zeitschrift f\"{u}r anorganische und allgemeine Chemie},
  publisher = {Wiley},
  author = {Hadenfeldt,  C. and Herdej\"{u}rgen,  H.},
  year = {1988},
  month = mar,
  pages = {35--40}
}

@article{Ong2013,
  title = {Python Materials Genomics (pymatgen): A robust,  open-source python library for materials analysis},
  volume = {68},
  ISSN = {0927-0256},
  noURL = {http://dx.doi.org/10.1016/j.commatsci.2012.10.028},
  DOI = {10.1016/j.commatsci.2012.10.028},
  journal = {Computational Materials Science},
  publisher = {Elsevier BV},
  author = {Ong,  Shyue Ping and Richards,  William Davidson and Jain,  Anubhav and Hautier,  Geoffroy and Kocher,  Michael and Cholia,  Shreyas and Gunter,  Dan and Chevrier,  Vincent L. and Persson,  Kristin A. and Ceder,  Gerbrand},
  year = {2013},
  month = feb,
  pages = {314–319}
}

@article{armiento2020database,
  title={Database-driven high-throughput calculations and machine learning models for materials design},
  author={Armiento, Rickard},
  journal={Machine Learning Meets Quantum Physics},
  pages={377--395},
  year={2020},
  publisher={Springer}
}

@article{kresse1994ab,
  title={Ab initio molecular-dynamics simulation of the liquid-metal--amorphous-semiconductor transition in germanium},
  author={Kresse, Georg and Hafner, J{\"u}rgen},
  journal={Physical Review B},
  volume={49},
  number={20},
  pages={14251},
  year={1994},
  publisher={APS}
}

@article{jainFormationEnthalpiesMixing2011a,
  title = {Formation Enthalpies by Mixing {{GGA}} and {{GGA}} \$+\$ \${{U}}\$ Calculations},
  author = {Jain, Anubhav and Hautier, Geoffroy and Ong, Shyue Ping and Moore, Charles J. and Fischer, Christopher C. and Persson, Kristin A. and Ceder, Gerbrand},
  year = {2011},
  month = jul,
  journal = {Phys. Rev. B},
  volume = {84},
  number = {4},
  pages = {045115},
  doi = {10.1103/PhysRevB.84.045115},
  urldate = {2022-12-05},
  abstract = {Standard approximations to the density functional theory exchange-correlation functional have been extraordinary successful, but calculating formation enthalpies of reactions involving compounds with both localized and delocalized electronic states remains challenging. In this work we examine the shortcomings of the generalized gradient approximation (GGA) and GGA+U in accurately characterizing such difficult reactions. We then outline a methodology that mixes GGA and GGA+U total energies (using known binary formation data for calibration) to more accurately predict formation enthalpies. We demonstrate that for a test set of 49 ternary oxides, our methodology can reduce the mean absolute relative error in calculated formation enthalpies from approximately 7.7\textendash 21\% in GGA+U to under 2\%. As another example we show that neither GGA nor GGA+U alone accurately reproduces the Fe-P-O phase diagram; however, our mixed methodology successfully predicts all known phases as stable by naturally stitching together GGA and GGA+U results. As a final example we demonstrate how our technique can be applied to the calculation of the Li-conversion voltage of LiFeF3. Our results indicate that mixing energies of several functionals represents one avenue to improve the accuracy of total energy computations without affecting the cost of calculation.},
  file = {/home/abhijith/Zotero/storage/VKMABYK5/PhysRevB.84.html}
}

@article{perdew1996generalized,
  title={Generalized gradient approximation made simple},
  author={Perdew, John P and Burke, Kieron and Ernzerhof, Matthias},
  journal={Physical review letters},
  volume={77},
  number={18},
  pages={3865},
  year={1996},
  publisher={APS}
}
