\begin{algorithm}[tb]
   \caption{\ourmodel}
   \label{algo:wyckoffdiff}
   \hspace*{\algorithmicindent} \textbf{Note:} We use the notation $\xt = (\typet, \numt)$. In the for-loop over $k$, if $k$ is an unconstrained position, $\x_0^k$ consists of $N_a$ variables and $\MLP(\hidden_k)$ outputs $N_a$ different probability vectors (sampled independently)
\begin{algorithmic}
\STATE Sample $s \sim \ptrain(s)$
\STATE Sample $\xprior \sim \ptheta(\xprior | s)$
\COMMENT{Prior distribution, e.g., assign all variables to zeros}
\FOR{$t$ in $T\dots 1$}
\STATE Encode material as $\{\hidden_k\}_{k=1}^{|L(s)|} = \text{GNN}(s, \xt)$ 
\FOR{$k$ in $1:|L(s)|$}
\STATE $\ptheta(\x_0^k | \xt, s) = \text{Categorical}\left(\x_0^k;\rvp=\MLP(\hidden_k)\right)$
\STATE Compute $\ptheta(\xtprevk|\xt,s)$ according to \Cref{eq:d3pm_post}
\STATE Sample $\xtprevk \sim \ptheta(\xtprevk|\xt,s)$
\ENDFOR
\ENDFOR
\RETURN $s$, $\x_0$
\end{algorithmic}
\end{algorithm}
