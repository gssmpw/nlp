\section{Related Work}
\begin{table}[!b]
    \renewcommand{\arraystretch}{1.3}
    \caption{
        \normalfont
        Outline formats used in previous vector font studies.
        These representations are categorized into command sequences and point sequences.
        In the context of vector fonts, these correspond to PostScript outlines and TrueType outlines.
    }
    \label{tab:study_outline_format}
    \centering
    \begin{tabular}{ll}
        \hline
        \textbf{Study}                              & \textbf{Outline formats} \\
        \hline
        SVG-VAE ____                 & Subset of SVG Commands   \\
        Im2Vec ____               & Points                   \\
        DeepSVG ____           & Subset of SVG Commands   \\
        Aoki and Aizawa ____          & Subset of SVG Commands   \\
        IconShop ____              & Subset of SVG Commands   \\
        DeepVecFont ____      & Custom Drawing Commands  \\
        DeepVecFont-v2 ____ & Custom Drawing Commands  \\
        $T^3$ ____             & TrueType Points          \\
        Nagata et al. ____      & TrueType Points          \\
        \hline
    \end{tabular}
\end{table}

\begin{table*}[!b]
    \renewcommand{\arraystretch}{1.3}
    \caption{
        \normalfont
        Drawing commands used in vector font outlines.
        The commands \texttt{moveTo}, \texttt{lineTo}, and \texttt{closePath} are common to both PostScript and TrueType outlines.
        The command \texttt{qCurveTo} is used only in TrueType outlines, whereas \texttt{curveTo} is exclusive to PostScript outlines.
    }
    \label{tab:drawing_commands}
    \centering
    \begin{tabular}{>{\centering\arraybackslash}m{2cm}>{\centering\arraybackslash}m{3cm}m{6cm}>{\centering\arraybackslash}m{4cm}}
        \hline
        \textbf{Command}   & \textbf{Arguments}           & \textbf{Description}                                                                                    & \textbf{Visualization}                                 \\
        \hline
        \texttt{moveTo}    & \(x, y\)                     & Move the cursor to the end-point \((x, y)\) without drawing anything.                                   & \includegraphics[scale=1]{fig/affinity/move_to.pdf}    \\
        \hline
        \texttt{lineTo}    & \(x, y\)                     & Draw a line to the point \((x, y)\).                                                                    & \includegraphics[scale=1]{fig/affinity/line_to.pdf}    \\
        \hline
        \texttt{qCurveTo}  & \(x_1, y_1, x, y\)           & Draw a quadratic Bézier curve with control point \((x_1, y_1)\) and end-point \((x, y)\).               & \includegraphics[scale=1]{fig/affinity/q_curve_to.pdf} \\
        \hline
        \texttt{curveTo}   & \(x_1, y_1, x_2, y_2, x, y\) & Draw a cubic Bézier curve with control points \((x_1, y_1)\), \((x_2, y_2)\), and end-point \((x, y)\). & \includegraphics[scale=1]{fig/affinity/curve_to.pdf}   \\
        \hline
        \texttt{closePath} & \(\varnothing\)              & Close the path by moving the cursor back to the path’s starting position.                               & \includegraphics[scale=1]{fig/affinity/close_path.pdf} \\
        \hline
    \end{tabular}
\end{table*}

\subsection{Transformer}

Transformer ____ is a neural network architecture that has achieved remarkable success in the field of natural language processing (NLP).
By utilizing the attention mechanism, Transformer enables the processing of variable-length sequential data.

Originally proposed as an Encoder-Decoder model for translation tasks, Transformer has since evolved into models that use only the Encoder or the Decoder.
BERT ____ is a language model that utilizes only the Encoder of the Transformer.
By combining pre-training and fine-tuning, BERT has achieved state-of-the-art performance in tasks such as question answering and document classification.
BERT encodes the entire input sequence into a fixed-length vector using the classification token (CLS), which is added to the beginning of the input sequence.
The encoded CLS token is then used for classification tasks.

Transformer has also been successfully applied in the field of computer vision.
Vision Transformer (ViT) ____ processes images by dividing them into multiple patches and treating each patch as a token, enabling effective image analysis.

Since vector graphics are represented as variable-length sequential data, Transformer provides a suitable framework for deep learning of vector graphics.
Furthermore, vector graphics can be considered an intermediate data form between texts and images, as they are images constructed from variable-length sequences.
Therefore, vector graphics can leverage insights from both NLP and computer vision applications of Transformer.

\subsection{Deep Learning for Vector Font}

Vector graphics are represented as variable-length sequential data, making it challenging to handle them in deep learning research until recently.
SVG-VAE ____ is one of the earliest models to address vector graphics generation.
It generates vector graphics from bitmap images using Variational Autoencoder (VAE) ____, leveraging an embedding representation based on sequences of SVG commands.
However, its applications were limited to Latin font generation.

Im2Vec ____ also generates vector graphics from bitmap images but adopts an embedding representation similar to TrueType outlines, using sequences of points and their corresponding flags.
Unlike SVG-VAE, Im2Vec extends its applicability not only to Latin fonts but also to emojis and icons.

DeepSVG ____ is the first model that apply Transformers to vector graphics generation.
By combining a VAE ____ with a hierarchical Transformer architecture and feed-forward prediction, DeepSVG can successfully generate vector graphics.
It utilizes an embedding representation based on command sequences and conducts experiments on icons and Latin fonts.
DeepSVG has inspired several subsequent studies.
Aoki and Aizawa ____ extended DeepSVG by focusing on font generation and introducing AdaIN ____ and Chamfer Loss, which enabled successful generation of complex shapes like Kanji characters.
IconShop ____, another extended work, specializes in icon generation.
These studies maintain the same command-sequence-based embedding representation as DeepSVG.

DeepVecFont ____ is a model that utilizes both bitmap and vector modalities for font generation.
For generating vector graphics, it employs an LSTM-based approach ____.
DeepVecFont adopts an embedding representation based on sequences of drawing commands, with coordinates expressed in relative values.
DeepVecFont-v2 ____, an improved version of DeepVecFont, introduces several enhancements,
including replacing LSTM with Transformer, representing coordinates in absolute values, and incorporating additional information about the starting point of commands.

$T^3$ ____ is a model focused on vector font classification.
It successfully adapts the BERT model architecture to vector fonts, enabling tasks such as character recognition and font style classification directly from vector format data.
Nagata et al. ____ conducted research on contour completion for vector graphics.
Both studies adopt embedding representations based on TrueType outlines.

The studies discussed above adopt different outline representations.
Table~\ref{tab:study_outline_format} summarizes the outline formats used in previous vector font studies.
These outline representations can be broadly categorized into command sequences and point sequences.
In the context of vector fonts, these correspond to PostScript outlines, which use drawing commands, and TrueType outlines, which represent contours as a set of points with flags.

\begin{figure*}[!t]
    \centerline{\includegraphics{fig/affinity/tt_to_ps.pdf}}
    \caption{
        Process of converting a TrueType outline into a PostScript outline.
        This transformation involves multiple steps, including decomposing quadratic Bézier splines, restructuring point sequences into segments, and converting quadratic Bézier curves into cubic Bézier curves.
        Each stage is illustrated in the figure, showing how the outline evolves through the transformation.
    }
    \label{fig:tt_to_ps}
\end{figure*}