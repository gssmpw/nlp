% This should be a bit more explained while staying in 1-2 sentences , e.g. While physical computing has achieved remarkable successes in diverse fields from image and sound recognition, embodied intelligence in soft robots, differential equation solving and linear algebra. 
% Perhaps a description of what physical computing is would also help: Physical computing aims to leverage phenomena such as noise, symmetry, interference, parametric phenomena, topology, etc to direclty evaluate functions and implement algorithms.  It has achieved remarkable successes in A, B and C... [note that it is still only 2 sentences! ]
%The description of learning should also be clarified, like the realization of 'physical learning systems, physical computers that can autonomously adapt in response to feedback and examples, is still in its infancy.
Physical computing~\cite{jaeger2023toward}---computing based on novel and unconventional phenomena and information carriers, has achieved remarkable successes. Some examples are photonic image recognition~\cite{photonicImageRecognition, mcmahonReviewOptical} and equation solving~\cite{metasurfaceComputingPolman, metamaterialDifferentialEquation}; the use of thermal noise for matrix inversion~\cite{thermodynamicMatrixInversion}, to perform inference~\cite{thermodynamicBayesianInference} and to sample probability distributions~\cite{ logarithmicBayesianQuerlioz}; the application of condensed-matter ideas such as topology~\cite{computingWithTopology}, symmetry~\cite{learningWithSymmetry} and parametric phenomena~\cite{computingParametricEffects} for computing; and the use of mechanical information carriers for the realization of acoustic arithmetic operations~\cite{fleuryMetamaterials}, passive speech recognition~\cite{dubvcek2024sensor}, passive event counting~\cite{beamCounting}, and to embody intelligent responses in soft robots~\cite{roboticOctopusEmbodiedIntelligence}. In contrast, physical learning---the process by which a physical computer autonomously improves its performance at a task by updating its parameters according to feedback and examples---is still comparatively in its infancy. Remarkable steps have been taken with the discovery of learning rules \cite{PhysicalLearningReview, EP1, EP2, CLflow, HEB, Hebbian, anisetti2024frequency, anisetti2023learning}---that indicate how parameters should be updated to improve system performance in a given information processing task; and some of these learning rules have been demonstrated in table-top experiments \cite{labDem, labDem2, arinze2023learning}. However, a significant gap remains between learning rules---which are abstract parameter update equations, and physical systems---governed by a Hamiltonian, and its interaction with the environment in the form of fluctuations and dissipation. %These projects work towards the central goal of self-learning materials. To reach it, we must bridge the gap between learning rules---which are abstract parameter update equations---and the dynamics of actual physical systems, governed by a Hamiltonian that interacts with the environment through damping and fluctuations. To be able to learn through dynamic time evolution as opposed to ad-hoc algorithmic intervention, a system requires at least two different time scales---a short-term memory that stores the degrees of freedom used for the current computation (i.e., involved in determining the output corresponding to a specific input), and a long-term memory that stores the learned responses---analogous to the weights of a machine learning model. In addition, a learning system requires coupling between these time scales: the long-term memory must be updated when examples are presented, while the inference-time response must be conditional on the learned behavior. 

\begin{figure}[!]
\includegraphics[width = \columnwidth]{Fig1.pdf}
\caption{\label{fig:epsart} A multifield coherent Ising machine is a network of multi-modal resonators, represented by a tight-binding model consisting of a scalar field $\sigma$ interacting with a spinor field $\vec{\psi}$. At every site $i$, the model has three degrees of freedom $\psi_{x,i}$, $\psi_{y,i}$ and $\sigma_{i}$, coupled via the nonlinear terms $H_L$ and $H_I$. The field $\vec{\psi}$ corresponds to the computational degrees of freedom (neural activations). $\vec{\psi}$ is composed of two identical sub-systems $\psi_x$ and $\psi_y$ (mass-spring lattices). During training, the output degree of freedom of the sub-system $\psi_y$ is clamped to a target value ($\psi_x$ is left free). The modes $\sigma_i$ are parametrically pumped (dotted green line) into a bistable self-oscillation regime, modeled by a spin (up or down depending on the phase of oscillation). This results in an Ising-like system that provides a long-term memory and stores the learned weights. The nonlinear interaction term $H_I$ modulates the dynamics of the computational field $\vec{\psi}$ according to the weights $\sigma$ (resulting in strong springs between antiferromagnetically-aligned sites). The term $H_L$ causes the weights $\sigma$ to be updated in response to a difference (contrast) between the free ($\psi_x$) and clamped ($\psi_y$) computational sub-systems. In a material, the field $\vec{\psi}$ can be realized by mapping the two spin components to a pair of doubly-degenerate localized orbitals. }
\vspace{-10pt}
\end{figure}

In this letter, we introduce a material model---a tight-binding Hamiltonian---that learns autonomously from a set of examples (Fig.~\ref{fig:epsart}). The model harnesses thermal fluctuations to drive transitions between states, and uses symmetry-protected degeneracies to construct two copies of the system, as required by contrastive learning rules. The incorporation of degeneracy and noise as building blocks of a self-learning physical system illustrates how phenomena that are not traditionally used for computation---or that are even actively avoided---can be reclaimed in novel information processing paradigms. The proposed system, referred here as a \emph{multifield coherent Ising machine} (Fig.~\ref{fig:epsart}), consists of a network of multi-modal resonators. Every site has three modes $\sigma$, $\psi_x$ and $\psi_y$. One of the modes, termed the long-term memory, learning or spin mode $\sigma$, is parametrically pumped into a bi-stable regime, forming a synthetic spin system known as a \emph{coherent Ising machine} (CIM)~\cite{coherentIsingExperiment, PhysRevResearch.4.013149}. We use the bi-stability of the spin mode $\sigma$ to store learned responses over long time scales, with the spin texture playing the role of the weights in a machine learning model. In addition to the spin field $\sigma$, two degenerate resonator modes are used to construct a synthetic spinor field $\vec{\psi}=(\psi_x, \psi_y)$. These modes will become the computational or short-term memory degrees of freedom---holding intermediate results of computations (neural activations). Nonlinear interactions between the modes, encoded in a learning Hamiltonian $H_l$, will cause the short-term dynamics of $\vec{\psi}$ to be conditioned by the long-term memory $\sigma$---allowing the field $\sigma$ to parameterize the computation. $H_l$ will also cause the weights in $\sigma$ to be updated according to a learning rule. A CIM interacting with an additional spinor field $\vec{\psi}$ through a nonlinear term $H_l$ is described by a Langevin equation:

%Around the local resonance frequency, this system is equivalent to a flow network or resistor network, a model that can learn to approximate linear functions~\cite{labDem}, and can also be generalized to nonlinear problems~\cite{labDem2}. To realize two timescales, our lattice model consists of two interacting fields (Fig.~\ref{fig:epsart}), a scalar field $\sigma$, which will become the long-term memory,  To establish a long-term memory from a regular degree of freedom, we parametrically drive each site. Above a critical pumping strength, the sites self-oscillate with one of two stable possible phase states. By mapping the phase state to a spin value, the system encodes a spin configuration. The term \emph{multifield} refers to the fact that the CIM interacts with an additional field $\vec{\psi}$ that encodes the computational degrees of freedom. The modes at each lattice site are governed by the following Langevin equation:

\begin{align}
&\ddot{\vec{\psi}}_{i} + \frac{\omega_c}{Q_c}\dot{\vec{\psi}}_{i} + w_c^2\vec{\psi}_{i} + \nabla_{\vec{\psi}_i} H_l = \vec{\xi}_{\psi, i};\\
&\ddot{\sigma}_i + \frac{\omega_l}{Q_l}\dot{\sigma}_i + \omega_l^2(1 + \alpha\sin(2\omega_l t))\sigma_i + \epsilon\sigma_i^3 +\nabla_{\sigma_i} H_l \ 
= \xi_{\sigma, i}. \label{eqn:Ising}
\end{align}

Where $i$ is the site number. We set the frequency of the computational and learning degrees of freedom to $\omega_c^2=0.5$ and $\omega_l^2=1$ respectively. The corresponding quality factors are set to $Q_c=4000$ and $Q_l=40$, while the pumping strength is set to $\alpha_l=0.1$ and the Duffing coefficient is set to $\epsilon=0.005$. The terms $\xi$ correspond to uncorrelated (diagonal), Gaussian distributed thermal noise with an autocorrelation $\langle\xi_{l/c}(t_0)\xi_{l/c}(t_1)\rangle = \sqrt{2k_BTb_{c/l}}\delta(t_1-t_0)$. Interactions between degrees of freedom are captured by the learning potential $H_l=H_I+H_L$, where the local part $H_L$ couples the fields locally at every site of the lattice---updating the long-term memory according to the learning rule---and the interaction part $H_I$ couples each site with its nearest neighbors---ensuring that information is processed according to the weights stored in the $\sigma$ field. 

\begin{figure}[t!]
\includegraphics[width = \columnwidth]{Fig2.pdf}
\caption{\label{fig:flip} Single-site learning dynamics. \textbf{(a)} Parametric self-oscillation regions corresponding to the contrast $\psi_X-\psi_Y$ values of $0$ (red), $3$ (purple) and $5$ (brown). These contrasts are the left limit, dashed vertical line and right limit in panel (b). The red dot corresponds to the excitation parameters (frequency of $2\omega_l=2$ and amplitude of $\omega_l^2\alpha=0.1$) (b). \textbf{b} Probability of flip during a learning protocol as a function of the contrast $\psi_X-\psi_Y$ for $k_BT$ values of $0.001$ (blue), $0.05$ (orange) and $0.1$ (green). \textbf{c} Transient dynamics during a learning protocol of width $\Delta_T=300$. The top panel shows the interaction strength $\mu(t)$ during the protocol. The middle panel shows the energy in the Ising mode $\sigma$ (denoted $E_I$), corresponding to a contrast of $0$ (red), $3$ (purple) and $5$ (brown), with a temperature $k_BT=0.05$. The black curve corresponds to a contrast of $5$ but setting $K_BT=0.05$. The bottom panel shows the Rabi oscillations in the energy $E_X$ of the free ($\psi_x$) mode, and the energy $E_Y$ of the clamped ($\psi_y$) mode, during the learning pulse. \textbf{d} Probability of spin flip as a function of the contrast $\psi_x-\psi_y$, for learning potentials $\mu_m=\mu_{m,0}/n^2$ with $n=1$ (blue), $n=2$ (orange) and $n=3$ (green) [top] and of protocol durations $\Delta_t=50$ (blue), $\Delta_t=100$ (orange), and $\Delta_t=300$ (green) [bottom]. The dashed lines in the top panel shows the sigmoidal fit of Eq.~\ref{eqn:switchprobability}. Throughout the figure, $\mu_{m,0}=0.005$.} 
\vspace{-15pt}
\end{figure}


The learning Hamiltonian $H_l$ is designed by analogy to the contrastive learning rule~\cite{labDem}, which involves comparing two copies of a system. We refer to these copies as \emph{free} and \emph{clamped} sub-systems. Both copies are presented with an excitation (in this work, a harmonic force at the resonance frequency $\omega_c$ of the computational modes $\psi_{x/y}$), at one or several input sites. The amplitude of this force encodes the input values. The output is obtained by reading the amplitude of oscillation of an output site. During learning, the output site of the clamped sub-system is forced to take a specific vibration amplitude. Then, the parameters (springs) are updated proportionally to the difference between the clamped and free energies. Although it can be proven that contrastive learning approximates gradient descent, intuitively, the learning rule can be understood as the changing the model parameters until the free system behaves like the clamped one---thus learning to produce the desired output. 

The need for two system copies poses a practical challenge for implementing contrastive learning rules. In our realization, we address this by mapping each copy to a component of the spinor field $\vec{\psi}$, with $\psi_x$ and $\psi_y$ becoming the free and clamped copies respectively. Although our work concerns a tight-binding model, in an actual condensed matter system, the two identical copies of the system can be robustly realized by associating them with basis functions that transform under a two-dimensional irreducible representation of the system's symmetry group, mapping each copy $\psi_x$ and $\psi_y$ to an irreducible symmetry sector~\cite{peri2019axial}. In contrastive learning, springs are updated in response to a difference between forces in the clamped and free configurations. Here, we implement a variation of the learning rule where the long-term memory is updated (spins are flipped) in response to the clamped and free site oscillation amplitudes. Although our learning rule deviates significantly from traditional contrastive learning, as spins can only take discrete states and experience probabilistic updates, a similar intuition as with contrastive learning can be applied: spins will flip until the free copy---which does not have access to the target output---learns to naturally approximate the target values. This intuition will be validated numerically in the next sections.



%The interaction Hamiltonian $H_I$ realizes the local learning rule and inter-site interactions, and consists of local Cross-Kerr potentials $V$ coupling the Ising mode to the contrast mode $\psi_{X-Y} := \psi_X - \psi_Y$ at every site and Duffing interaction potentials $E_{ij}$ acting on the difference in modal displacements between neighboring sites:
%\begin{align}
% V &= \mu(t)\sigma^2\psi_{X-Y}^2; %\label{eq:local}\\
% E_{ij} &= \lambda(t)(\Delta\sigma_{ij} + %\Delta\psi_{ij})^4 \label{eq:inter}.
%\end{align}
%Both have time-dependent strengths, allowing them to be switched on and off. The full equations which we integrated in the simulations are provided in Appendix \ref{Appendix:EOM}. 




%Here, we address this by considering a multifield lattice model. The model consists of a scalar field $\sigma$, that will become the long-term memory, and a spinor field $\psi$, that will become the short-term memory.

%To bridge the gap between these formal learning rules and functioning neuromorphic computers, the next necessary steps are to $(1)$ come up with a Hamiltonian that induces dynamics according to a learning rule; and $(2)$ design a system that is governed by this Hamiltonian. In this paper we concern ourselves with the former. The key idea is to separate the timescale of the learning dynamics from that of the computations, allowing both to be realized by the same Hamiltonian.  

%However, they all rely on ad hoc implementation---either through an algorithmic layer in training simulations, or through external computations in physical realizations---rather than emerging naturally through the systemâ€™s dynamics. 

%The learning rule we focus on is called contrastive learning  \cite{CLcompar}. The name reflects the fact that the weights are updated in proportion to the difference between two states of system. In one state---called the clamped---the desired response to a given input is forced, while in the other---known as the free---only the input is applied. Over many iterations of the rule, the free state learns to mimic the example posed by the clamped one, ultimately adopting the required behavior. All in all, we face two main challenges in finding a suitable Hamiltonian: $(1)$ the need to compare two distinct states of the same system; and $(2)$ the need for two well-separated timescales. The first is specific to the chosen learning rule and various approaches have already been suggested, such as using two physical copies \cite{labDem}, exploiting additional degrees of freedom \cite{additonalDOF}, and using hybrid boundary conditions \cite{CLflow}. The second is common among most learning rules, and has not yet been addressed. %is that so?



%The basis for our self-learning system is a coherent Ising machine---a spin-like network of bi-stable parametric resonators that can solve combinatorial optimization problems. The weights of the model are stored in the spin configuration, which is created by parametrically driving a designated mode $\sigma$ into a bistable regime (see Appendix \ref{Appendix:PR}). To implement learning, we couple this mode to an additional spinor field $\vec{\psi}$. The method we propose is outlined in Fig. \ref{fig:epsart}. The two system copies needed for contrastive learning are realized by exploiting the spatial symmetry-breaking responsible for mode degeneracies to ensure that the super-positioned free $\vec{\psi_X}$ and clamped $\vec{\psi_Y}$ spinor fields are physically identical. The displacement in each of the modes is described by the following equations:


%\textcolor{red}{Instead of having a section with the 'exact equations of motion' I think it is a better idea to provide a complete picture there (it is not that long...) just make sure the Hamiltonian includes all terms This is an example on how to describe the interaction: (but you need to also describe the local potential). Note that you can explain what every term deos but you can levae for next sections the detailed description on how it is accomplished. like 'ther interaction term is responsible for making the interaction of teh compytational degrees of freedom dependent on the spin texture, while the local term  'the local term is responsible for flipping the spins when clamped and free disagree}
%The Hamiltonian consists of a local term $H_L$ and a neuron-neuron interaction term 
%The interaction potential consists of a set of eight nonlinear springs $V_I(i)=\sum_i{\alpha_id^4_{v_i-u_i'}}$ ($1 <= i <= 8$). Each spring acts on the difference $d^4_{v_i-u_i'}=v_i-u_i$ between a linear combination of degrees of freedom in the site $s$ and a linear combination of degrees of freedom in the site $s'$, i.e., $d_{v_i-u_i'}=v_i-u_i$, with $v_i=\xi_i^{(1)}\psi_x + \xi_i^{(2)}\psi_y + \xi_i^{(3)}\sigma$ and $u_i=\xi_i'^{(1)}\psi_x + \xi_i'^{(2)}\psi_y + \xi_i'^{(3)}'\sigma$. The linear combination coefficients $\xi$ and weights $\alpha$ can be found in Table~\ref{tab:coefficients}. Although this work corresponds to a tight-binding model, each potential term can be intuitively understood as a cubic spring connecting a point $x_i$ of drum $s$ with another point $y_i'$ of drum $s'$, where the placement of the spring connections~\cite{perturbativeMetamaterials} is selected in way that the tight-binding orbital functions $\phi_{\psi_x, \psi_y, \sigma}(x_i) = \xi_i^{(1)}, \xi_i^{(2)}, \xi_i^{(2)}$ and $\phi_{\psi_x, \psi_y, \sigma}(y_i) = \xi_i'^{(1)}, \xi_i'^{(2)}, \xi_i'^{(2)}$ . In an experimental setting, both the time-dependent stiffness required for parametric oscillation and the switchable couplings can be implemented using piezoelectric materials~\cite{villanuevaParametricPiezo},  electrostatic interactions~\cite{electrostaticModeCoupling} between electrodes placed at the coordinates $x_i$ and $y_i$, or using optomechanical forces~\cite{aspelmeyerIntroOptomechanics}.



%\textcolor{red}{There should also be an explanation that this is not quite contrastive learning, but more of a contrastive-inspired learning rule. The intuition for it is that bits will flip until clamped and free match. We do not have mathematical proof that this converges, but we can claim that we test it numerically. }

%In the following sections, we study their respective roles: the long-timescale learning dynamics induced by $V$ in section \ref{SysDesc}; and the short-term multi-neuron dynamics governed by $E_{ij}$ in section \ref{Master}. Finally, in section \ref{Results}, we demonstrate the model's capability to learn by testing it against the Iris flower classification benchmark. 
%\textcolor{red}{Before you describe the model inclduing equations, it would be interesting to briefly explain how it works in high-level: The spin texture provides a long-term memory that determines the conductivity, between pairs of aligned spins -- physically storing the weights of the 'neural net', while the clamped and free. You could move the equations and table I to this secit }