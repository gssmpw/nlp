\section{Related Work}
\noindent{\bf Structured Reasoning Frameworks for LLMs}
Recently, a variety of reasoning language models have emerged, including o1 by OpenAI~\cite{o1}, QwQ by Alibaba~\cite{qwq}, and R1 by DeepSeek~\cite{r1}, demonstrating substantial improvements in tackling complex tasks. These models leverage structured reasoning methods to enhance robustness and problem-solving capabilities.
The concept of Chain-of-Thought reasoning (CoT)~\cite{cot, 0shot-cot}, established a foundational approach to reasoning in LLMs. 
Building on this foundation, more sophisticated topologies have emerged, such as tree~\cite{tot, bot, propagation} and graph~\cite{got, got2, resprompt}, enabling LLMs to address increasingly intricate problems.

Other enhancements include self-consistency CoT~\cite{self-consistency}, which incorporates verification and reflection mechanisms to bolster reasoning reliability, and ReAct~\cite{react}, which integrates tool usage into the reasoning process, allowing LLMs to access external resources and knowledge. These innovations collectively expand the reasoning capabilities of LLMs across a diverse range of applications.



\noindent{\bf LLM Inference Latency Reduction}
Although structured reasoning greatly enhances LLMs' ability to solve complex questions, 
it significantly increases the token usage before arriving at a final answer.
This makes it challenging to apply in cost-sensitive and latency-sensitive scenarios~\cite{token_economy}.
Furthermore, the modelâ€™s lack of awareness regarding task complexity often leads to overthinking~\cite{over-thinking, over-reasoning} even on simple tasks, resulting in unnecessary resource consumption.

Techniques like streaming aim to reduce {\em perceived} latency by incrementally providing partial outputs as they are generated, rather than waiting for the entire output sequence. However, this approach cannot fully mitigate overall latency or computational cost, and it is often unsuitable for chain-of-thought reasoning, as intermediate steps are often not intended to be shown to end users.

\citet{skeleton_of_thought} proposes Skeleton-of-Thought (SoT), a method that first guides LLMs to generate a skeleton outline of the answer, followed by parallel decoding to reduce latency. While SoT helps lower latency, it does not reduce computational cost and is limited to questions that can be parallelized effectively. 
\citet{draft_n_verify} took a different approach, it first generates draft tokens at lower quality but higher speed through selective skipping of intermediate layers, and then validates the draft in a single forward pass.
Our approach, CoD, can be combined with these approaches to further reduce the latency. 
% Active prompting ...

\citet{latent-cot} proposes Coconut to train LLMs to perform reasoning in a continuous latent space rather than in the traditional natural language space using the final hidden state of the LLM to represent the reasoning process. 
%Coconut reduces the latency and cost, but the accuracy drops in complicated tasks such as GSM8k. 
While Coconut reduces latency and computational cost, it suffers from reduced accuracy in complex tasks, such as GSM8k. Additionally, it loses the interpretability of natural language reasoning and cannot be applied to black-box models like GPT and Claude.

The works closest to ours are Concise Thoughts (CCoT)~\cite{ccot} and token-budget-aware LLM reasoning (TALE)~\cite{budget}.
CCoT proposes using a fixed global token budget for reasoning steps. However, different tasks may require varying budgets to achieve the optimal balance between performance and cost. Moreover, LLMs may fail to adhere to an impractical budget, often generating far more tokens than intended~\cite{budget}.
\citet{budget} extends this idea by dynamically estimating a global token budget for different problems based on reasoning complexity. However, this approach requires an additional LLM call to estimate the budget, which increases latency. Furthermore, it assumes that the model can accurately predict the complexity of requests, limiting its applicability to more complex tasks where reflection, self-correction, or external knowledge retrieval may be necessary during the reasoning process. In contrast, our approach employs a per-step budget, allowing unlimited reasoning steps, which makes it more adaptable to various structured reasoning techniques.