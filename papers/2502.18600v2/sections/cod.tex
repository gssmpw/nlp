\section{Chain-of-Draft Prompting}
%The Chain-of-Thought (CoT) prompting strategy has demonstrated significant effectiveness across a wide range of tasks, particularly those requiring complex multi-step reasoning. By generating detailed reasoning steps, CoT allows LLMs to break down problems into smaller, more manageable components, ultimately improving accuracy and interpretability. However, LLMs often produce excessively lengthy reasoning steps, consuming a substantial number of tokens before arriving at a final answer. This verbosity poses a major challenge for real-time applications, where response latency is critical. Since the time required for an LLM to generate a response grows linearly with the number of output tokens, the adoption of CoT in latency-sensitive scenarios remains constrained.

The Chain-of-Thought (CoT) prompting strategy has demonstrated significant effectiveness across a wide range of tasks, particularly those requiring complex multi-step reasoning.
However, LLMs often produce excessively verbose reasoning steps, consuming a substantial number of tokens before arriving at a final answer.
In contrast, humans tend to adopt a more concise approach when solving complex problems involving multi-step reasoning, such as mathematical or logical puzzles. Rather than elaborating on every detail, humans typically jot down only the essential intermediate results — minimal drafts — to facilitate their thought processes. Inspired by this natural tendency, we propose a novel prompting strategy called Chain-of-Draft (CoD). This approach aims to reduce verbosity by limiting the number of words used in each reasoning step, focusing only on the essential calculations or transformations needed to progress.

\begin{comment}
\begin{figure}[h!]
\centering
\begin{promptbox}[Standard]
Q: Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12
lollipops. How many lollipops did Jason give to Denny?
\newline
A: 8
\end{promptbox}
\begin{promptbox}[Chain-of-Thought]
Q: Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12
lollipops. How many lollipops did Jason give to Denny?
\newline
A: Jason started with 20 lollipops. Then he had 12 after giving some to Denny.
So he gave Denny 20 - 12 = 8. \#\#\#\# 8
\end{promptbox}
\begin{promptbox}[Chain-of-Draft]
Q: Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12
lollipops. How many lollipops did Jason give to Denny?
\newline
A: 20 - x = 12; x = 20 - 12 = 8. \#\#\#\# 8
\end{promptbox}
\caption{Example input-output pairs for standard prompting, chain of thought, and chain of draft.}
\label{fig:cod_vs_cot}
\end{figure}
\end{comment}

To illustrate the difference between standard prompting, Chain-of-Thought prompting, and our proposed Chain-of-Draft prompting, consider the following simple arithmetic problem:

\noindent\textit{Q: Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops did Jason give to Denny?}

The response generated by a standard prompting approach directly outputs the answer, often without any reasoning. While correct, this lacks transparency in how the answer was derived, and requires the language model to run multi-step reasoning without any help from intermediate result, which often leads to hallucination.

\begin{center}
\begin{promptbox}[Standard]
Q: Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12
lollipops. How many lollipops did Jason give to Denny?
\newline
A: 8
\end{promptbox}
\end{center}


Chain-of-Thought prompting, on the other hand, provides a detailed reasoning process.
While this response is accurate and interpretable, it includes unnecessary details about Jason, Denny, and the lollipops, which are irrelevant to solving the mathematical problem. This verbosity inflates the token count and increases the response latency.

\begin{center}
\begin{promptbox}[Chain-of-Thought]
Q: Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12
lollipops. How many lollipops did Jason give to Denny?
\newline
A: Let's think through this step by step:

1. Initially, Jason had 20 lollipops. \newline
2. After giving some to Denny, Jason now has 12 lollipops. \newline
3. To find out how many lollipops Jason gave to Denny, we need to calculate the difference between the initial number of lollipops and the remaining number. \newline
4. We can set up a simple subtraction problem:
   Initial number of lollipops - Remaining number of lollipops = Lollipops given to Denny \newline
5. Putting in the numbers:
   20 - 12 = Lollipops given to Denny \newline
6. Solving the subtraction:
   20 - 12 = 8

Therefore, Jason gave 8 lollipops to Denny.

\#\#\#\#\newline
8 lollipops
\end{promptbox}
\end{center}

By contrast, Chain-of-Draft prompting condenses the reasoning process into minimal, abstract representations. Here, the reasoning is distilled into a concise equation, focusing solely on the essential mathematical operation required to arrive at the solution. By abstracting away irrelevant contextual details, CoD significantly reduces the token count while maintaining transparency and correctness.

\begin{center}
\begin{promptbox}[Chain-of-Draft]
Q: Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12
lollipops. How many lollipops did Jason give to Denny?
\newline
A: 20 - x = 12; x = 20 - 12 = 8. \#\#\#\# 8
\end{promptbox}
\end{center}









