\def\bwdM{\overleftarrow{Q}_{0:\zeta}}
\def\fwdM{\overrightarrow{P}_{0:\zeta}}
\def\argmin{\textrm{argmin}}

We first prove \cref{prop:conv_SFBD}, which we restate below:
\convSFBD*

To facilitate our discussions, let
\begin{itemize}
	\item $\bwdM^{\phiv_{k-1}}$: the path measure induced by the backward process \cref{eq:conv_SFBD:bwd}. In general, we use $\bwdM^{\phiv}$ to denote the path measure when the drift term is parameterized $\phiv$. 
	\item $\fwdM^{(k)}$: the path measure induced by the forward process \cref{eq:fwd_diff} with $p_0 = p_0^{(k)}$, defined in \cref{prop:conv_SFBD}. The density of its marginal distribution at time $t$ is denoted by $p_t^{(k)}$
	\item $\fwdM^*$: the path measure induced by the forward process \cref{eq:fwd_diff} with $p_0 = p_\text{data}$. 
\end{itemize}
We note that, according to \cref{alg:SFBD}, the marginal distribution of $\bwdM^{\phiv_{k-1}}$ at $t = 0$ has density $p_0^{(k)}$. 

The following lemma allows us to show that the training of the diffusion model can be seen as a process of minimizing the KL divergence of two path measures. 
\begin{lemma}[\citealt{PavonA1991}, \citealt{VargasTLL2021}]
\label{appx:lem:kl_two_path}
	Given two SDEs:
	\begin{align}
		\diff \xv_t = \fv_i(\xv_t, t) \diff t + g(t) \diff \wv_t,~~~\xv_0\sim p_0^{(i)}(\xv)~~~~ t \in [0,T]
	\end{align}
	for $i = 1, 2$. Let $P^{(i)}_{0:T}$, for $i = 1, 2$, be the path measure induced by them, respectively. Then we have,
	\begin{align}
		\KL{P^{(1)}_{0:T}}{P^{(2)}_{0:T}} = \KL{p_0^{(1)}}{p_0^{(2)}} \; + \; \Eb_{P^{(1)}_{0:T}}\Bigl[\int_0^T \frac{1}{2\,g(t)^2}\,\|\fv_1(\xv_t,t)-\fv_2(\xv_t,t)\|^2\,dt\Bigr]. 
	\end{align}
	In addition, the same result applies to a pair of backward SDEs as well, where $p_0^{(i)}$ is replaced with $p_T^{(i)}$. 
\end{lemma}
\begin{proof}
	By the disintegration theorem~(e.g., see \citealt[Appx B]{VargasTLL2021}), we have 
	 \begin{align}
	 	\KL{P_1}{P_2} = \KL{p_0^{(1)}}{p_0^{(2)}} \; + \; \Eb_{P^{(1)}_{0:T}}\left[\log \frac{\diff P^{(1)}_{0:T}(\cdot | \xv_0))}{\diff P^{(2)}_{0:T}(\cdot | \xv_0)} \right],
	 \end{align}
	 where $P^{(i)}_{0:T}(\cdot |\xv_0)$ is the conditioned path measure of $P^{(i)}_{0:T}$ given the initial point $\xv_0$. Then, applying the Girsanov theorem \citep{Kailath1971, Oksendal2003} on the second term yields the desired result. 
\end{proof}
By \cref{appx:lem:kl_two_path}, we can show that the Denoiser Update step in \cref{alg:SFBD} finds $\phiv_{k}$ minimizing $\KL{\fwdM^{(k)}}{\bwdM^{\phiv}}$. To see this, note that
\begin{align*}
	\phiv_{k} &= \underset{\phiv}{\argmin} ~ \KL{\fwdM^{(k)}}{\bwdM^{\phiv}} \\
	&= \underset{\phiv}{\argmin} ~ \KL{p_\zeta^{(k)}}{p_\zeta^*} \; + \; \Eb_{\fwdM^{(k)}}\Bigl[\int_0^\zeta \frac{g(t)^2}{2}\,\| \nabla \log p_t^{(k)}(\xv_t)- \sv_{\phiv}(\xv_t,t)\|^2\,dt\Bigr],\numberthis \label{appx:eq:min_KL_update_denoiser}
\end{align*}
where $p_t^{(k)}$ is the marginal distribution induced by the forward process \eqref{eq:fwd_diff} with the boundary condition $p^{(k)}_0$ at $t = 0$. Note that, we have applied \cref{appx:lem:kl_two_path} to the backward processes inducing $\fwdM^{(k)}$ and $\bwdM^{\phiv}$. Thus, the drift term of $\fwdM^{(k)}$ is not zero but $-g(t)^2 \, \nabla \log p_t^{(k)}(\xv_t)$ according to \cref{eq:anderson_bwd}. Since the first term of \cref{appx:eq:min_KL_update_denoiser} is a constant, the minimization results in 
\begin{align}
	\nabla \log p_t^{(k)} (\xv_t) = \sv_{{\phiv}_k}(\xv_t, t)\label{eq:appx:score_minimize_KL}
\end{align}
for all $\xv_t \in \Rb^d$ and $t \in (0,\zeta]$. In addition, we note that, the denoising loss in \cref{eq:denoiser_loss} is minimized when $\nabla \log p_t^{(k)} (\xv_t) = \sv_{\phiv}(\xv_t, t)$ for all $t > 0$; as a result, $\phiv_{k}$ minimizes $\KL{\fwdM^{(k)}}{\bwdM^{\phiv}}$ as claimed. 

Now, we are ready to prove \cref{prop:conv_SFBD}. 
\begin{proof}[Proof of \cref{prop:conv_SFBD}]


Applying \cref{appx:lem:kl_two_path} to the backward process 
\begin{align*}
	\KL{\fwdM^*}{\bwdM^{\phiv_{k-1}}} &= \underbrace{\KL{p^*_\zeta}{p^*_\zeta}}_{=0} + \Eb_{\fwdM^*}\left[\int_0^\zeta \tfrac{g(t)^2}{2} \|\nabla\log p_t^*(\xv_0) - \sv_{{\phiv}_{k-1}}(\xv_t, t) \|^2 \diff t \right]\\
	&= \Eb_{\fwdM^*}\left[\int_0^\zeta \tfrac{g(t)^2}{2} \|\nabla\log p_t^*(\xv_0) - \sv_{{\phiv}_{k-1}}(\xv_t, t) \|^2 \diff t\right] \numberthis \label{eq:conv_SFBD:proof:1}
\end{align*}

Likewise,
\begin{align*}
	\KL{\fwdM^*}{\fwdM^{(k)}} =~& \KL{p^*_\zeta}{p_\zeta^{(k)}} + \Eb_{\fwdM^*}\left[\int_0^\zeta \tfrac{g(t)^2}{2} \|\nabla \log q_t^*(\xv_t) - \nabla\log p^{(k)}_t(\xv_t) \|^2 \diff t\right] \\
	=~&\KL{p^*_\zeta}{p_\zeta^{(k)}} + \Eb_{\fwdM^*}\left[\int_0^\zeta \tfrac{g(t)^2}{2} \|\nabla \log q_t^*(\xv_t) - \sv_{{\phiv}_k}(\xv_t, t) \|^2 \diff t\right] \\
	\overset{\eqref{eq:conv_SFBD:proof:1}}{=}~& \KL{p^*_\zeta}{p_\zeta^{(k)}} + \KL{\fwdM^*}{\bwdM^{\phiv_{k}}} \numberthis\label{eq:conv_SFBD:proof:2}
\end{align*} 
where the second equality is due to the discussion on deriving \cref{eq:appx:score_minimize_KL}. 


\cref{appx:lem:kl_two_path} also implies that 
\begin{align}
	\KL{\fwdM^*}{\bwdM^{\phiv_{k-1}}} = \KL{p_\text{data}}{p_0^{(k)}} + \underbrace{\Eb_{\fwdM^*}\left[\int_0^\zeta \tfrac{1}{2} \|\bv^{(k-1)}(\xv_t, t) \|^2 \diff t \right]}_{:= \Bc_{k-1}}, \label{eq:conv_SFBD:proof:2_1}
\end{align}
where $\bv^{(k-1)}(\xv_t, t)$ is the drift of the forward process inducing $\bwdM^{\phiv_{k-1}}$.
In addition, 
\begin{align}
	\KL{\fwdM^*}{\fwdM^{(k)}} = \KL{p_\text{data}}{p_0^{(k)}} + \Eb_{\fwdM^*}\left[\int_0^\zeta \tfrac{1}{2} \|\zero - \zero \|^2 \diff t\right] = \KL{p_\text{data}}{p_0^{(k)}}. \label{eq:conv_SFBD:proof:3}
\end{align}
As a result, 
\begin{align*}
	\KL{p_\text{data}}{p_0^{(k)}}
	\overset{\eqref{eq:conv_SFBD:proof:3}}{=}& \KL{\fwdM^*}{\fwdM^{(k)}} 	
	\overset{\eqref{eq:conv_SFBD:proof:2}}{=} \KL{p^*_\zeta}{p_\zeta^{(k)}} + \KL{\fwdM^*}{\bwdM^{\phiv_{k}}} \\
	\geq & ~ \KL{\fwdM^*}{\bwdM^{\phiv_{k}}}
	\overset{\eqref{eq:conv_SFBD:proof:2_1}}{=} \KL{p_\text{data}}{p_0^{(k+1)}} + \Bc_k \\
	\geq & \KL{p_\text{data}}{p_0^{(k+1)}}
\end{align*}
which is \eqref{eq:conv_SFBD:monotone}. In addition, we have
\begin{align*}
	\KL{\fwdM^*}{\bwdM^{\phiv_{k-1}}} 
	&\overset{\eqref{eq:conv_SFBD:proof:2_1}}{=} \KL{p_\text{data}}{p_0^{(k)}} + \Bc_{k-1}
	\overset{\eqref{eq:conv_SFBD:proof:3}}{=} \KL{\fwdM^*}{\fwdM^{(k)}} + \Bc_{k-1} \\ 
	&\overset{\eqref{eq:conv_SFBD:proof:2}}{=} \KL{p^*_\zeta}{p_\zeta^{(k)}} + \KL{\fwdM^*}{\bwdM^{\phiv_{k}}}  + \Bc_{k-1} \\
	&= \KL{\fwdM^*}{\bwdM^{\phiv_{k}}}  + \big[\KL{p^*_\zeta}{p_\zeta^{(k)}} +  \Bc_{k-1}\big].                                                                                                                                               
\end{align*}	


As a result, applying this relationship recursively, we have
\begin{align}
	\KL{\fwdM^*}{\bwdM^{\phiv_{0}}} = \sum_{k = 1}^K \KL{p^*_\zeta}{p_\zeta^{(k)}} + \sum_{k=1}^{K} \Bc_{k-1} + \KL{\fwdM^*}{\bwdM^{\phiv_{K}}}. 
\end{align}
Since $\KL{\fwdM^*}{\bwdM^{\phiv_{0}}} = M_0$, we have
\begin{align}
	\sum_{k = 1}^K \KL{p_\text{data} * h}{p^{(k)} * h} = \sum_{k = 1}^K \KL{p^*_\zeta}{p_\zeta^{(k)}} \leq M_0,
\end{align}
for all $K \geq 1$. This further implies, 
\begin{align}
	\min_{k \in \{1, 2, \ldots, K\}}\KL{p_\text{data} * h}{p^{(k)} * h} \leq \frac{M_0}{K}. 
\end{align}


Applying \cref{prop:conv_identify}, we obtain,
\begin{align}
			\min_{k \in \{1, 2, \ldots, K\}} \left|\Phi_{p_\text{data}}(\uv) - \Phi_{p_0^{(k)}}(\uv)\right|\leq \exp \big(\frac{\sigma_\zeta^2}{2} \|\uv\|^2 \big) \sqrt{\frac{2 M_0}{K}}.
\end{align}
\end{proof}

We complete this section by showing the connection between our framework and the original consistency loss. 
\RELCONSSFBD*
\begin{proof}
	When $t = s$, denoising noise in \cref{eq:denoiser_loss} becomes	
	\begin{align*}
	 &\underset{p_0}{\Eb} \,  \underset{p_{s|0}}{\Eb} \left[\|D_{\phiv}(\xv_s, s) - \xv_0 \|^2 \right] = \Eb_{p_s} \Eb_{p_{0|s}}\big[ \|D_{\phiv}(\xv_s, s) - \xv_0 \|^2  \big] \\
	 =\, & \Eb_{p_s} \Eb_{p_{0|s}}\big[ \|D_{\phiv}(\xv_s, s) - \Eb_{p_{0|s}}[\xv_0] + \Eb_{p_{0|s}}[\xv_0] - \xv_0 \|^2  \big] \\
	 =\, & \Eb_{p_s} \Eb_{p_{0|s}}\big[\|D_{\phiv}(\xv_s, s) - \Eb_{p_{0|s}}[\xv_0]  \|^2 \big] + \underbrace{\Eb_{p_s} \Eb_{p_{0|s}}\big[\|\Eb_{p_{0|s}}[\xv_0]  - \xv_0\|^2 \big]}_{\text{Const.}}  \\
	 &\hspace{15em} + 2 \underbrace{\Eb_{p_s} \Eb_{p_{0|s}}\big[\inner{D_{\phiv}(\xv_s, s) - \Eb_{p_{0|s}}[\xv_0]}{\Eb_{p_{0|s}}[\xv_0] - \xv_0} \big]}_{=0} \\
	 =\, & \Eb_{p_s}\big[\|D_{\phiv}(\xv_s, s) - \Eb_{p_{0|s}}[\xv_0]  \|^2 \big] + \textrm{Const.} \\
	 =\, & \Eb_{p_s} \big[\|D_{\phiv}(\xv_s, s) - \Eb_{p_{0|s}}[D_{\phiv}(\xv_0, 0)]  \|^2 \big] + \textrm{Const.},
	 \end{align*}
	 which is the consistency loss in \cref{eq:consistency_loss} when $r = 0$. 
\end{proof}
 





