In this section, we introduce a novel method for solving the deconvolution problem that integrates seamlessly with the existing diffusion model framework. As our approach involves iteratively applying the forward diffusion process described in \cref{eq:fwd_diff}, followed by a backward step with an optimized drift, we refer to this method as Stochastic Forward-Backward Deconvolution (SFBD), as described in \cref{alg:SFBD}. 

The proposed algorithm begins with a small set of clean data, $\Dc_\text{clean}$, for pretraining, followed by iterative optimization using a large set of noisy samples. As demonstrated in \cref{sec:emp}, decent quality images can be achieved on datasets such as CIFAR-10 \citep{Krizhevsky2009} and CelebA \citep{LiuLWT2015} using as few as 50 clean images. During pretraining, the algorithm produces a neural network denoiser, $D_{{\phiv}_0}$, which serves as the initialization for the subsequent iterative optimization process. Specifically, the algorithm alternates between the following two steps: for $k = 1, 2, \ldots K$, 
\begin{enumerate}
	\item (Backward Sampling) This step can be intuitively seen as a denoising process for samples in $\Dc_\text{noisy}$ using the backward SDE \cref{eq:anderson_bwd}. In each iteration, we use the best estimation of the score function so far induced by $D_{{\phiv}_{k-1}}$ through \cref{eq:score_repara_in_denoiser}. 
	\item (Denoiser Update) Fine-tune denoiser $D_{{\phiv}_{k-1}}$ to obtain $D_{{\phiv}_k}$ by minimizing \cref{eq:denoiser_loss} with the denoised samples obtained in the previous step. 
\end{enumerate}
The following proposition shows that when $\Dc_\text{noisy}$ contains sufficiently many samples to characterize the true noisy distribution $p_{\rm data} \conv h$, when $K \rightarrow \infty$, the diffusion model implemented by denoiser $D_{{\phiv}_K}$ has the sample distribution converging to the true $p_\text{data}$. 

\begin{algorithm}[!t]
\DontPrintSemicolon
   \caption{Stochastic Forward–Backward Deconvolution. (Given sample set $\Dc$, $p_\Dc$ denotes the corresponding empirical distribution.)}
   \label{alg:SFBD}

    \KwIn{clean data: $\Dc_\text{clean} = \{\xv^{(i)}\}_{i=1}^M$, noisy data: $\Dc_\text{noisy} = \{\yv_\tau^{(i)}\}_{i=1}^N$, number of iterations: $K$.} 

    \tcp{Initialize Denoiser}
    
    $\phiv_0 \leftarrow$ Pretrain $D_{\phiv}$ using \cref{eq:denoiser_loss} with $p_0 = p_{\Dc_\text{clean}}$

    \For{$k = 1$ to $K$}{
        \tcp{Backward Sampling}
        
        $\Ec_k \leftarrow \{ \yv_0^{(i)} : \forall \yv_\tau^{(i)} \in \Dc_\text{noisy}$, solve backward SDE \cref{eq:anderson_bwd} from $\tau$ to $0$, starting from $\yv_\tau^{(i)}$, where the score function is estimated as $\frac{D_{\phiv_{k-1}}(\xv_t, t) - \xv_t}{\sigma_t^2} \}$
        
        \tcp{Denoiser Update}
        
        $\phiv_k \leftarrow$ Train $D_{\phiv}$ by minimizing \cref{eq:denoiser_loss} with $p_0 = p_{\Ec_k}$
    }

    \KwOut{Final denoiser $D_{{\phiv}_K}$}
\end{algorithm}


\begin{restatable}{proposition}{convSFBD}
\label{prop:conv_SFBD}
	Let $p^*_t$ be the density of $\xv_t$ obtained by solving the forward diffusion process \cref{eq:fwd_diff} with $\xv_0 \sim p_\text{data}$, where we have $p^*_\zeta = p_{\rm data} \conv h$. Consider a modified \cref{alg:SFBD}, where the empirical distribution $P_{\Dc_\text{noisy}}$ is replaced with the ground truth $p^*_\zeta$.  Correspondingly, $p_{{\Ec}_k}$ becomes $p_0^{(k)}$, the distribution of $\xv_0$ induced by solving:
	\begin{align}
		\diff \xv_t = - g(t)^2 \, \sv_{\phiv_{k-1}}(\xv_t, t) \diff t + g(t) \diff \bar\wv_t, ~\xv_\zeta \sim p^*_\zeta \label{eq:conv_SFBD:bwd}
	\end{align}
	from $\zeta$ to $0$, where $\sv_{\phiv_k}(\xv_t, t) = \frac{D_{\phiv_k}(\xv_t, t) - \xv_t}{\sigma_t^2}$, $g(t) = (\frac{\diff \sigma^2_t}{\diff t})^{\sfrac{1}{2}}$ and $D_{{\phiv}_k}$ is obtained by minimizing \eqref{eq:denoiser_loss} according to \cref{alg:SFBD}. Assume $D_{{\phiv}_k}$ reaches the optimal for all~$k$. Under mild assumptions, for $k \geq 0$, we have
	\begin{align}
		\KL{p_\text{data}}{p_0^{(k)}} \geq \KL{p_\text{data}}{p_0^{(k+1)}}. \label{eq:conv_SFBD:monotone}
	\end{align}
	In addition, for all $K \geq 1$ and $\uv \in \Rb^d$, we have
	\begin{align*}
			\min_{k = 1,\ldots K}\left|\Phi_{p_\text{data}}(\uv) - \Phi_{p_0^{(k)}}(\uv)\right|\leq \exp \big(\frac{\sigma_\zeta^2}{2} \|\uv\|^2 \big) \sqrt{\frac{2 M_0}{K}},
	\end{align*}	
	 where
	\begin{align*}
		M_0 = \tfrac{1}{2} \int_0^\zeta g(t)^2 \Eb_{p_{t}^*}\big\|\nabla \log p^*_t(\xv_t) - \sv_{\phiv_0}(\xv_t, t) \big\|^2 \diff t. 
	\end{align*}
\end{restatable}
\cref{prop:conv_SFBD} shows, after sufficiently many iterations of backward sampling and denoiser updates, the distribution of denoised samples generated by the backward sampling step converges to the true data distribution at a rate of $\Oc(1 / \sqrt{K})$. Consequently, after fine-tuning the denoiser on these denoised samples during the Denoiser Update step, the diffusion model is expected to generate samples that approximately follow the data distribution, solving the deconvolution problem. It is important to note that this result describes the convergence rate of SFBD under the assumption of an infinite number of noisy samples, which is distinct from the optimal sample efficiency rate discussed in \cref{sec:deconv}.

\textbf{The importance of pretraining.} \cref{prop:conv_SFBD} also highlights the critical role of pretraining, as it allows the algorithm to begin fine-tuning from a point much closer to the true data distribution. Specifically, effective pretraining ensures that $\sv_{\phiv_0}$ closely approximates the ground-truth score, leading to a smaller  $M_0$  in \cref{prop:conv_SFBD}. This, in turn, reduces the number of iterations  $K$  required for the diffusion model to generate high-quality samples.

\textbf{The practical limits of increasing $K$.}  While \cref{prop:conv_SFBD} suggests that increasing the number of iterations $K$ can continuously improve sample quality, practical limitations come into play. Sampling errors introduced during the backward sampling process, as well as imperfections in the denoiser updates, accumulate over time. These errors eventually offset the benefits of additional iterations, as demonstrated in \cref{sec:emp}. This observation further highlights the importance of pretraining to mitigate the impact of such errors and achieve high-quality samples with fewer iterations.

\textbf{Alternative methods for backward sampling.} While the backward sampling in \cref{alg:SFBD} is presented as a naive solution to the backward SDE in \cref{eq:anderson_bwd}, the algorithm is not limited to this approach. Any backward SDE and solver yielding the same marginal distribution as \cref{eq:anderson_bwd} can be employed. Alternatives include PF-ODE, the predictor-corrector sampler \citep{SongDCKKEP2021}, DEIS \citep{ZhangC2023}, and the $2^\text{nd}$ order Heun method used in EDM \citep{KarrasAAL22}. Compared to the Euler–Maruyama method, these approaches require fewer network evaluations and offer improved error control for imperfect score estimation and step discretization. As the algorithm generates $\Ec_k$ that contains samples closer to $p_\text{data}$ with increasing $k$, clean images used for pretraining can be incorporated into $\Ec_k$ to accelerate this process. In our empirical study, this technique is applied whenever clean samples and noisy samples (prior to corruption) originate from the same distribution.

\input{tables/model_performance_compare.tex}

\textbf{Relationship to the consistency loss.} SFBD can be seen as an algorithm that enforces the consistency constraint across all positive time steps and time zero. Specifically, we have
\begin{restatable}{proposition}{RELCONSSFBD}
\label{prop:rel_btw_cons_SFBD}
Assume that the denoising network $D_{\phiv}$ is implemented to satisfy $D_{\phiv}(\cdot, 0) = \textrm{Id}(\cdot)$. When $r = 0$, the consistency loss in \cref{eq:consistency_loss} is equivalent to the denoising noise in \cref{eq:denoiser_loss} for $t = s$. 
\end{restatable}
The requirement that $D_{\phiv}(\cdot, 0) = \textrm{Id}(\cdot)$ is both natural and intuitive, as $D_{\phiv}(\xv_0, 0)$ approximates $\Eb[\xv_0 | \xv_0] = \xv_0$. This fact is explicitly enforced in the design of the EDM framework \citep{KarrasAAL22}, which has been widely adopted in subsequent research.

A key distinction between SFBD and the original consistency loss implementation is that SFBD does not require sampling from $p_{r|s}$ or access to the ground-truth score function induced by the unknown data distribution $p_\text{data}$. This is because, in the original implementation, $p_0 = p_\text{data}$, whereas in SFBD,  $p_0 = p_0^{(k)}$, as defined in \cref{prop:conv_SFBD}, and is obtained iteratively through the backward sampling step. As $k$  increases,  $p_0^{(k)}$  converges to  $p_\text{data}$, ensuring that the same consistency constraints are eventually enforced. Consequently, SFBD bridges the gap between theoretical formulation and practical implementation that exists in the original consistency loss framework.

%\textbf{Relationship to IPF.} The forward and backpack-flavoured optimization method is also used in the iterative proportional fitting (IPF) method to find Schrodinger's Bridge (an entropy regularized optimal transport scheme) \citep{BortoliTHD2021}. In comparison to IPF, SFBD has a fixed forward diffusion process, whereas in IPF, the forward process will be updated according to the results in previous iterations. 




