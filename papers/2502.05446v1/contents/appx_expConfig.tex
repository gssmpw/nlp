\subsection{Model Architectures}
We implemented the proposed SFBD algorithm based on the following configurations throughout our empirical studies:
\begin{table}[h]
    \centering
    \caption{Experimental Configuration for CIFAR-10 and CelebA}
    \label{tab:experiment-config}
    \renewcommand{\arraystretch}{1.2} % Adjust row height for readability
    \setlength{\tabcolsep}{6pt} % Adjust column spacing
    \begin{tabular}{p{4cm} p{4.5cm} p{4.5cm}} 
        \toprule
        \textbf{Parameter} & \textbf{CIFAR-10} & \textbf{CelebA} \\
        \midrule
        \textbf{General} & & \\
        Batch Size & 512 & 256 \\
        Loss Function & \texttt{EDMLoss} \citep{KarrasAAL22} & \texttt{EDMLoss} \citep{KarrasAAL22} \\
        Sampling Method &  $2^\text{nd}$ order Heun method (EDM) \citep{KarrasAAL22} & $2^\text{nd}$ order Heun method (EDM) \citep{KarrasAAL22}  \\
        Sampling steps & 18 & 40 \\
        \midrule 
        \textbf{Network Configuration} & & \\
        Dropout & 0.13 & 0.05 \\
        Channel Multipliers & $\{2, 2, 2\}$ & $\{1, 2, 2, 2\}$ \\
        Model Channels & 128 & 128 \\
        Resample Filter & $\{1, 1\}$ & $\{1, 3, 3, 1\}$ \\
        Channel Mult Noise & 1 & 2 \\
        \midrule
        \textbf{Optimizer Configuration} & & \\
        Optimizer Class & \texttt{Adam} \citep{KingmaBa2014} & \texttt{Adam}  \citep{KingmaBa2014} \\
        Learning Rate & 0.001 & 0.0002 \\
        Epsilon & $1 \times 10^{-8}$ & $1 \times 10^{-8}$ \\
        Betas & (0.9, 0.999) & (0.9, 0.999) \\
        \bottomrule
  \end{tabular}
\end{table}


\subsection{Datasets}
All experiments on CIFAR-10 \citep{Krizhevsky2009} use only the training set, except for the one presented in \cref{fig:ablation_cifar10:pretrain}. For this specific test, we merge the training and test sets so that each class contains a total of 6,000 images. At iteration 0, the FID computation measures the distance between clean images of trucks and those from the classes on which the model is fine-tuned. For subsequent iterations, FID is calculated in the same manner as in other experiments. Specifically, the model first generates 50,000 images, and the FID is computed between the sampled images and the images from the fine-tuning classes. All experiments on CelebA \citep{LiuLWT2015} are performed on its training set.

