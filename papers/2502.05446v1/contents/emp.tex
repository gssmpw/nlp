
\input{figures/model_performance_compare_visual.tex}

\input{figures/ablation_cifar10.tex}
In this section, we demonstrate the effectiveness of the SFBD framework proposed in \cref{sec:SFBD}. Compared to other models trained on noisy datasets, SFBD consistently achieves superior performance across all benchmark settings. Additionally, we conduct ablation studies to validate our theoretical findings and offer practical insights for applying SFBD effectively.

\textbf{Datasets and evaluation metrics.} The experiments are conducted on the CIFAR-10 \citep{Krizhevsky2009} and CelebA \citep{LiuGL2022} datasets, with resolutions of  $32 \times 32$  and  $64 \times 64$, respectively. CIFAR-10 consists of 50,000 training images and 10,000 test images across 10 classes. CelebA, a dataset of human face images, includes a predefined split of 162,770 training images, 19,867 validation images, and 19,962 test images. For CelebA,  images were obtained using the preprocessing tool provided in the DDIM official repository  \citep{SongME2021}.

\begin{figure}[t]
	\centering
	\includegraphics[width=0.95\columnwidth]{figures/noise_level_visual2.pdf}
	\caption{Noisy images with different $\sigma_\zeta$.}
	\label{fig:noisy_img_var_sigma}
	\vspace{-1em}
\end{figure}


We evaluate image quality using the Frechet Inception Distance (FID), computed between the reference dataset and 50,000 images generated by the models. Generated samples for FID computation are presented in \cref{appx:sample_results}.


\textbf{Models and other configurations.} We implemented SFBD algorithms using the architectures proposed in EDM \citep{KarrasAAL22} as well as the optimizers and hyperparameter configurations therein. All models are implemented in an unconditional setting, and we also enabled the non-leaky augmentation technique \citep{KarrasAAL22} to alleviate the overfitting problem. For the backward sampling step in SFBD, we adopt the $2^\text{nd}$-order Heun method \citep{KarrasAAL22}. More information is provided in \cref{appx:expConfig}. 


\subsection{Performance Comparison}
We compare SFBD with several representative models designed for training on noisy images, as shown in \cref{tb:performance_compare}. SURE-Score \citep{AaliAKT2023} and EMDiffusion \citep{BaiWCS2024} are diffusion-based frameworks that utilize Stein’s unbiased risk estimate and the expectation-maximization (EM) method, respectively, to address general inverse problems. AmbientDiffusion \citep{DarasSDGDK2023} solves similar problems by modifying the denoising loss \eqref{eq:denoiser_loss}, requiring a denoiser to restore further corrupted samples. TweedieDiffusion \citep{DarasDD2024} implements the original consistency loss in \cref{eq:consistency_loss}.

Following the experimental setup of \citet{BaiWCS2024}, images are corrupted by adding independent Gaussian noise with a standard deviation of  $\sigma_\zeta = 0.2$  to each pixel after rescaling pixel values to $[-1, 1]$. For reference, we also include results for models trained on clean images ($\sigma_\zeta = 0$). In cases with pretraining, the models are initially trained on 50 clean images randomly sampled from the training datasets. For all results presented in this work, the same set of 50 sampled images is used.


As shown in \cref{tb:performance_compare}, SFBD produces images of significantly higher quality than all baselines, as further illustrated by the denoised images in \cref{fig:model_benchmark_visual} by evaluating the backward SDE starting from a noisy image in the training dataset. Notably, on CelebA, SFBD achieves performance comparable to DDIM, which is trained on clean images. \cref{tb:performance_compare} also shows that while TweedieDiffusion benefits from pretraining, its results remain inferior to SFBD. In fact, we observe that the original consistency loss  \eqref{eq:consistency_loss} provides limited performance improvement after pretraining; the FID begins to degrade shortly after the consistency loss is applied.
\begin{figure*}[t!]
	\centering
	\includegraphics[width=0.5\columnwidth]{figures/charts/var_config_celeba.png}~~~~
	\raisebox{-0.1em}{\includegraphics[width=1.4\columnwidth]{figures/celeba_deconv_iters2.pdf}}
	\caption{(Left) SFBD performance on CelebA under three configurations, with FID at iteration 0 for the pretrained model. (Right) Denoised samples generated by the backward SDE, starting from a noisy image in the training dataset. For cfg A, results are shown after each fine-tuning iteration, while cfg B and cfg C are shown at their minimum FID iterations.}
	\label{fig:var_config_celeba}
\end{figure*}

\subsection{Ablation Study}
\label{sec:exp:ablation}
In this section, we investigate how SFBD's performance varies with clean image ratios, noise levels, and pretraining on similar datasets. The results align with our discussion in \cref{sec:deconv} and \cref{sec:SFBD} and provide practical insights. Experiments are conducted on CIFAR-10, with the default $\sigma_\zeta = 0.59$. This noise level significantly alters the original images, aligning with our original motivation to address potential copyright concerns (see \cref{fig:noisy_img_var_sigma}). 

\textbf{Clean image ratio.} \cref{fig:ablation_cifar10:clean_ratio} shows the FID trajectories across fine-tuning iterations $k$ for different clean image ratios. With just 4\% clean images, SFBD achieves strong performance (FID: 6.31) and outperforms DDIM with 10\% clean images. While higher clean image ratios further improve performance, the gains diminish as a small amount of clean data already provides sufficient high-frequency features (e.g., edges and local details) to capture feature variations. Since these features are shared across images, additional clean data offers limited improvement.


These findings suggest that practitioners with limited clean datasets should focus on collecting more copyright-free data to enhance performance. Notably, when clean images are scarce, the marginal gains from additional fine-tuning iterations $k$ are greater than when more clean data is available. Therefore, in scenarios where acquiring clean data is challenging, increasing fine-tuning iterations can be an effective alternative to improve results.
\vspace{-0.3em}

\textbf{Noise level.} \cref{fig:ablation_cifar10:sigma} shows SFBD's sampling performance across fine-tuning iterations for different noise levels, using the values from $2^\text{nd}$ order Heun sampling in EDM \citep{KarrasAAL22}. The impact of noise on the original images is visualized in \cref{fig:noisy_img_var_sigma}. As shown in \cref{fig:ablation_cifar10:sigma}, increasing $\sigma_\zeta$ significantly degrades SFBD's performance. This is expected, as higher noise levels obscure more features in the original images. Furthermore, as suggested by \cref{thm:MISE_upper_bound}, higher $\sigma_\zeta$ demands substantially more noisy images, which cannot be compensated by pretraining on a small clean image set. Importantly, this performance drop is a mathematical limitation discussed in \cref{sec:deconv}, rather than an issue solvable by better deconvolution algorithms. In \cref{sec:exp:futher_discuss}, we show that slightly increasing pretraining clean image set can yield strong results, even at reasonably high noise levels on CelebA.

\textbf{Pretraining with clean images from similar datasets.} \cref{fig:ablation_cifar10:pretrain} evaluates SFBD's performance when fine-tuning on image sets from different classes, with the model initially pretrained on clean truck images. The results show that the closer the noisy dataset is to the truck dataset (as indicated by the FID at iter 0), the better the model performs after fine-tuning. This is expected, as similar datasets share common features that facilitate learning the target data distribution.
Interestingly, even when the pretraining dataset differs significantly from the noisy dataset, the model still outperforms the version without pretraining. This is because unrelated datasets often share fundamental features, such as edges and local structures.  \textit{Therefore, practitioners should always consider pretraining before fine-tuning on target noisy datasets, while more similar pretraining datasets yield better final sampling performance.}





\subsection{Further Discussions}

\label{sec:exp:futher_discuss}
\textbf{Additional results on CelebA.} \cref{fig:var_config_celeba} presents SFBD performance trajectories on CelebA under three configurations. While \cref{tb:performance_compare} reports results using configuration (cfg) C to align with benchmarks, this setup is impractical due to its low noise level, which fails to address copyright and privacy concerns. As illustrated in \cref{fig:var_config_celeba} (right), the low noise level allows human observers to identify individuals and recover image details, with model-denoised images nearly identical to the originals. To address this, we report results for cfgs A and B with $\sigma_\zeta = 1.38$, concealing most original image information. While pretraining on 50 clean images performs poorly, increasing the size to 1.5k (still $< 1\%$ of the training dataset) achieves impressive results. At iteration 3, the model reaches FID 5.91, outperforming DDIM trained on clean images. This supports our discussion in \cref{sec:exp:ablation}: collecting more clean data significantly boosts performance when the clean dataset is small.

\textbf{Features learned from noisy images.} As shown in \cref{fig:var_config_celeba}, when $\sigma_\zeta = 1.38$, almost all information from the original images is obscured, prompting the question: can the model learn from such noisy inputs, and how does this happen? In \cref{fig:var_config_celeba}, we plot the model’s denoised outputs in cfg A after each fine-tuning iteration. These outputs serve as samples for the next iteration, revealing what the model learns and adapts to in the process. For the first row, the pretrained model (iter 0) produces a face very different from the original, failing to recover features like a headband. This occurs because the clean dataset for pretraining lacks similar faces with headbands. Instead of random guesses, the model combines local features (e.g., face shapes, eyes) learned from the clean data with the global structure from the noisy images. This process combines previously learned features in new ways, helps the model better generalize, and gradually improves its ability to approximate the true distribution, as supported by \cref{prop:conv_SFBD}. Likewise, the model learns how to attach the glasses to the individual's face in the second row. 
