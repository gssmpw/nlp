In this section we recall diffusion models, the density deconvolution problem and the consistency constraints.% to address deconvolution.
\subsection{Diffusion Models}
Diffusion models generate data by progressively adding Gaussian noise to input data and then reversing this process through sequential denoising steps to sample from noise. Given distribution $p_0$ on $\Rb^d$, the forward perturbation is specified by a stochastic differential equation (SDE):
\begin{align}
	\diff \xv_t = g(t) \diff \wv_t, ~~\textrm{~ $t\in [0, T]$,} \label{eq:fwd_diff}
\end{align}
$\xv_0 \sim p_0$, $T$ is a fixed positive constant and $g(t)$ is a scalar function.  $\{\wv_t\}_{t\in [0,T]}$ is the standard Brownian motion. 

%$\xv_0 \sim p_\textrm{data}$ and $T$ is a fixed positive constant. $\xv_t f(t)$ and $g(t)$ are the drift and diffusion coefficients, where $f$ and $g$ are scaler functions.  $\{\wv_t\}_{t\in [0,T]}$ is the standard Brownian motion. 

%\cref{eq:fwd_diff} induces a transition kernel $p_t(\xv_t | \xv_s)$ for $0 \leq s \leq t \leq T$, which is Gaussian and its mean and covariance matrix can be computed in closed form \citep[Eqs 4.23 and 5.51]{SarkkaSolin2019}. In particular, for $s = 0$, we write 
%\begin{align}
%	p_t(\xv_t | \xv_0) = \Nc(\muv_t(\xv_0), \sigma_t^2 \Iv)
%\end{align}
%for all $t\in [0,T]$. As discussed by \citet{ZhangC2023}, in DDPM \citep{HoJA2020} and DDIM \citep{SongME2021}, $f(t) = \frac{1}{2} \frac{d \log \alpha_t}{d t} $ and  $g(t) = (-\frac{d \log \alpha_t}{d t})^{\sfrac{1}{2}}$ with  $\alpha_0 = 1$ and approaching to zero as $t \rightarrow T$. We can show $\muv_t(\xv_0) = \sqrt \alpha_t \xv_0$ and $\sigma_t^2 = 1 - \alpha_t$. Likewise, in the settings used by \citet{SongDCKKEP2021, KarrasAAL22}, we have $f(t) = 0$, $g(t) = (\frac{\diff \sigma^2_t}{\diff t})^{\sfrac{1}{2}}$ and $p_t(\xv_t | \xv_0) = \Nc(\xv_0, \sigma_t^2 \Iv)$. 


%\red{\cref{eq:fwd_diff} induces a transition kernel \( p_{t|s}(\xv_t | \xv_s) \) for \( 0 \leq s \leq t \leq T \), which is Gaussian, with its mean and covariance matrix computable in closed form \citep[Eqs. 4.23 and 5.51]{SarkkaSolin2019}.} Specifically, for \( s = 0 \), it can be expressed as  
%\begin{align}
%    p_{t|0}(\xv_t | \xv_0) = \Nc(\mu_t \, \xv_0, \sigma_t^2 \Iv),
%\end{align}  
%for all $ t \in [0, T] $. As discussed by \citet{ZhangC2023}, in the frameworks of DDPM \citep{HoJA2020} and DDIM \citep{SongME2021}, the functions $f(t) = \frac{1}{2} \frac{d \log \alpha_t}{d t} $ and  $g(t) = (-\frac{d \log \alpha_t}{d t})^{\sfrac{1}{2}}$ where \( \alpha_0 = 1 \) and $ \alpha_t $ approaches zero as $ t \to T $. Using these definitions, it can be shown that $ \mu_t = \sqrt{\alpha_t} $ and $ \sigma_t^2 = 1 - \alpha_t $.  In contrast, under the settings employed by \citet{SongDCKKEP2021, KarrasAAL22}, we have
%$f(t) = 0$, $g(t) = (\frac{\diff \sigma^2_t}{\diff t})^{\sfrac{1}{2}}$ and the transition kernel simplifies to $p_{t|0}(\xv_t | \xv_0) = \Nc(\xv_0, \sigma_t^2 \Iv)$.  


%\cref{eq:fwd_diff} induces a transition kernel  \citep{SongDCKKEP2021, KarrasAAL22}
\cref{eq:fwd_diff} induces a transition kernel $p_{t|s}(\xv_t | \xv_s)$ for $0 \leq s \leq t \leq T$, which is Gaussian and its mean and covariance matrix can be computed in closed form \citep[Eqs 4.23 and 5.51]{SarkkaSolin2019}. In particular, for $s = 0$, we write 
\begin{align}
    p_{t|0}(\xv_t | \xv_0) = \Nc(\xv_0, \sigma_t^2 \Iv),
\end{align}  
for all $ t \in [0, T] $, where we set $g(t) = (\frac{\diff \sigma^2_t}{\diff t})^{\sfrac{1}{2}}$. 
When $\sigma_T^2$ is very large, $\xv_T$ can be approximately regarded as a sample from $\Nc(\zero, \sigma_T^2 \Iv)$. Let $ p_t(\xv_t) = \int p_{t|0}(\xv_t \vert \xv_0) \, p_0(\xv_0) \, \mathrm{d} \xv_0 $ denote the marginal distribution of $\xv_t$, where we have $ p_T \approx \mathcal{N}(\mathbf{0}, \sigma_T^2 \mathbf{I}) $. \citet{anderson1982} showed that backward SDE
\begin{align}
	\diff \xv_t = - g(t)^2 \, \nabla \log p_t(\xv_t) \diff t + g(t) \diff \bar\wv_t, ~\xv_T \sim p_T \label{eq:anderson_bwd}
\end{align}
has a transition kernel that matches the posterior distribution of the forward process, $p_{s|t}(\xv_s | \xv_t) = \tfrac{p_{t|s}(\xv_t | \xv_s)  p_s(\xv_s)}{p_t(\xv_t)}$ for $s \leq t$ in $[0,T]$. Thus, the backward SDE preserves the same marginal distributions as the forward process. Here, $\bar{\wv}_t$ represents a standard Wiener process with time flowing backward from $T$ to $0$, while $\nabla \log p_t(\xv_t)$ denotes the score function of the distribution $p_t(\xv_t)$.  With a well-trained network $\sv_{\phiv}(\xv_t, t) \approx \nabla \log p_t(\xv_t)$, we substitute it into \cref{eq:anderson_bwd} and solve the SDE backward from $\tilde\xv_T \sim \Nc(\zero, \sigma_T^2 \Iv)$. The resulting $\tilde\xv_0$ then serves as an approximate sample of $p_0$.

To train $\sv_{\phiv}$ to estimate the score, let $\Tc$ be a predefined sampler of $t \in [0, T]$ and $w(t)$ be a weight function. The network $\sv_{\phiv}$ can be effectively trained via the conditional score-matching loss \citep{SongDCKKEP2021}:
\begin{align*}
	\Lc_s(\phiv) \hspace{-0.3em} = \hspace{-0.4em} \underset{t \sim \Tc}{\Eb}\, \underset{p_0}{\Eb} \,  \underset{p_{t|0}}{\Eb} \left[w(t) \|\sv_{\phiv}(\xv_t, t) - \nabla \log p_{t\vert 0}(\xv_t \vert \xv_0)\|^2 \right]  % \label{eq:score_matching_loss}
\end{align*}
Instead, we may first train a denoiser $D_{\phiv}(\xv, t)$ to estimate $\Eb[\xv_0 \vert \xv_t]$ by minimizing \citep{KarrasAAL22}
\begin{align}
	\Lc_d(\phiv) \hspace{-0.3em} = \hspace{-0.4em} \underset{t \sim \Tc}{\Eb}\, \underset{p_0}{\Eb} \,  \underset{p_{t|0}}{\Eb} \left[w(t) \|D_{\phiv}(\xv_t, t) - \xv_0 \|^2 \right] \label{eq:denoiser_loss}
\end{align}
then estimate 
\begin{align}
	\nabla \log p_t(\xv_t) = \frac{\Eb[\xv_0 \vert \xv_t] - \xv_t}{\sigma_t^2} \approx \frac{D_{\phiv}(\xv_t, t) - \xv_t}{\sigma_t^2}. \label{eq:score_repara_in_denoiser}
\end{align}

 


%gives the same marginal distribution $p_t$ as the forward one for all $t\in [0,T]$. 
%
%
%
%Here, 
%
%\citet{SongDCKKEP2021} proved that the solution $\tilde\xv_t$ of the ODE:
%\begin{align}
%	\diff \tilde \xv_t = \Big[-t~\nabla\log p_t(\tilde\xv_t)\Big] \diff t ~~~ \mbox{with $\tilde \xv_T \sim p_T(\tilde\xv_T)$} \label{eq:PF-ODE}
%\end{align} 
%
%
%In this paper, we adopt the same configuration as \citeauthor{SongDCS2023}'s, where $\muv(\xv,t) = 0$ and $\sigma(t) = \sqrt{2t}$. When $T$ is sufficiently large, $\xv_T$ can be approximately seen as a sample following $\Nc(\zero, T^2 \Iv)$. Let $p_t$ denote the distribution of $\xv_t$ (thus, $p_0= p_{\rm data}$ and $p_T \approx \Nc(\zero, T^2 \Iv)$). 
%
%
%
%\citet{SongDCKKEP2021} proved that the solution $\tilde\xv_t$ of the ODE:
%\begin{align}
%	\diff \tilde \xv_t = \Big[-t~\nabla\log p_t(\tilde\xv_t)\Big] \diff t ~~~ \mbox{with $\tilde \xv_T \sim p_T(\tilde\xv_T)$} \label{eq:PF-ODE}
%\end{align}
%is also distributed according to $p_t$, where the ODE in \eqref{eq:PF-ODE} is called the \textit{PF-ODE}. Here, $\nabla \log p_t(\xv_t)$ is the score function of $p_t(\xv_t)$ and can be empirically estimated by a neural network $\sv_{\phiv}(\xv_t, t)$ which is notably easy to train due to the stable training process. (Readers may refer to \cite{SongDCKKEP2021} for its training details.) With a well-trained $\sv_{\phiv}(\xv_t, t)$, we then can plug it into \eqref{eq:PF-ODE} and solve the PF-ODE backward starting from $\tilde\xv_T\sim \Nc(\zero, T^2 \Iv)$ and the resulting $\tilde \xv_0$ can be seen as an approximate sample of $p_{\rm data}$.

\subsection{Density Deconvolution Problems}
\label{sec:prel:deconv_prob}

Classical deconvolution problems arise in scenarios where data are corrupted due to significant measurement errors, and the goal is to estimate the underlying data distribution. Specifically, let the corrupted samples $\mathcal{Y} = \{\yv^{(i)}\}_{i=1}^{n}$ be generated by the process:
\begin{align}
	\yv^{(i)} = \xv^{(i)} + \epsilonv^{(i)}, \label{eq:gen_conv_samples}
\end{align}
where $\xv^{(i)}$ and $\epsilonv^{(i)}$ are independent random variables. Here, $\xv^{(i)}$ is drawn from an unknown distribution with density $p_{\rm data}$, and $\epsilonv^{(i)}$ is sampled from a \emph{known} error distribution with density $h$. It can be shown that the corrupted samples $\yv^{(i)}$ follow a distribution with density $p_{\rm data} \conv h$, where $\conv$ denotes the convolution operator. We provide more details in \cref{appx:intro:density_deconv}.


The objective of the (density) deconvolution problem is to estimate the density of $p_{\rm data}$ using the observed data $\mathcal{Y}$, which is sampled from the convoluted distribution $p_{\rm data} \conv h$. In essence, deconvolution reverses the density convolution process, hence the name of the problem.

To assess the quality of an estimator $\hat{p}(\cdot; \mathcal{Y})$ of $p_{\rm data}$ based on $\mathcal{Y}$, the mean integrated squared error (MISE) is commonly used. MISE is defined as:
\begin{align}
	\textrm{MISE}( \hat p, p_\textrm{data}) = \Eb_{\Yc} \int_{\Rb^d} \big|\,                                                            \hat p(\xv ; \Yc) - p_\textrm{data}(\xv) \, \big|^2 \diff \xv. \label{eq:def_MISE}
\end{align}
In this paper, we focus on a corruption process implemented via forward diffusion as described in \cref{eq:fwd_diff}. Consequently, unless otherwise stated, in the rest of this work, we assume the error distribution $h$ is Gaussian $\mathcal{N}(\mathbf{0}, \sigma_\zeta^2\mathbf{I})$ with a given and fixed $\zeta \in (0, T)$.

To see why we could identify an original distribution $p$ through $p \conv h$, let $\Phi_p(\uv) = \Eb_p[\exp(i \, \uv^\top \xv)]$ for $\uv \in \Rb^d$ be the characteristic function of $p$. Then,

\begin{restatable}{proposition}{PROPCONVINDENTIFY}
\label{prop:conv_identify}
	Let $p$ and $q$ be two distributions defined on $\Rb^d$. For all $\uv \in \Rb^d$, 
	\begin{align*}
			|\Phi_p(\uv)\hspace{-0.1em} -\hspace{-0.1em} \Phi_q(\uv)|\hspace{-0.15em}\leq\hspace{-0.15em} \exp\hspace{-0.1em}\big(\frac{\sigma_\zeta^2}{2} \|\uv\|^2 \big) \sqrt{2 \,D_{\mathrm{KL}}(p \conv h\|q\conv h)}.
	\end{align*}
\end{restatable}
(All proofs are deferred to the appendix.) This result shows if two distributions $p$ and $q$ are similar after being convoluted with $h$, they must have similar characteristic functions and thus similar distribution. In particular, when $p \conv h = q \conv h$, then $p = q$, the case also discussed in \citet[Thm 2]{WangZHCZ2023}. As a result, whenever we could find $q$ satisfying $p_\text{data} \conv h = q \conv h$, we can conclude $p_\text{data} = q$.   

\subsection{Deconvolution through the Consistency Constraints}
\label{prel:deconv_through_consist_const}
While \cref{prop:conv_identify} shows it is possible to train a generative model using noisy samples, it remains a difficult question of how to use noisy samples to train a diffusion model to generate clean samples \emph{effectively}.

The question was partially addressed by \citet{DarasDD2024} through the consistency property \citep{DarasDDD2023}. In particular, since we have access to the noisy samples $\xv_\zeta$ from $p_\text{data} \conv h$, we can use them to train a network $\sv_{\phiv}(\xv_t, t)$ to approximate $\nabla \log p_t(\xv_t)$ for $t > \zeta$ through a modified score matching loss, which is referred as ambient score matching (ASM), denoted by $\Lc_\text{ASM}({\phiv})$. In their implementation, $\sv_{\phiv}(\xv_t, t)$ is parameterized by $\frac{D_{\phiv}(\xv_t, t) - \xv_t}{\sigma_t^2}$, where $D_{\phiv}(\xv_t, t)$ is trained to approximate $\Eb[\xv_0 \vert \xv_t]$. 

In contrast, for $t \leq \zeta$, score-matching is no longer applicable. Instead, \citet{DarasDD2024} propose that $D_{\phiv}(\xv_t, t)$ should obey the consistency property: %of diffusion processes:
\begin{align}
	\Eb[\xv_0|\xv_s] =  {\Eb}_{p_{r\vert s}} \big[\Eb[\xv_0|\xv_r] \big], \text{ for $0 \leq r \leq s \leq T$}
\end{align} 
by jointly minimizing the \textit{consistency loss}:
\begin{align}
	\Lc_\text{con}({\phiv}, r, s) \hspace{-0.12em}=\hspace{-0.12em} \Eb_{p_s} \big\|D_{\phiv}(\xv_s, s) \hspace{-0.12em} - \hspace{-0.12em} \Eb_{p_{r|s} } [D_{\phiv}(\xv_r, r)]  \big\|^2 \hspace{-0.12em}, \label{eq:consistency_loss}
\end{align}
where $r$ and $s$ are sampled from predefined distributions. Sampling from $p_{r|s}$ is implemented by solving \cref{eq:anderson_bwd} backward from $\xv_s$, replacing the score function with the network-estimated one $D_{\phiv}$ via \cref{eq:score_repara_in_denoiser}. For sampling from $p_s$, we first sample $\xv_\tau$ for $\tau > s$ and $\tau > \zeta$, then sample from $p_{s|\tau}$ in a manner analogous to sampling from $p_{r|s}$. 

It can be shown that if $D_{\phiv}$ minimizes the consistency loss for all $r, s$ and perfectly learns the score function for $t > \zeta$, then $\frac{D_{\phiv}(\xv_t, t) - \xv_t}{\sigma_t^2}$ becomes an exact estimator of the score function for all $t \in [0, T]$. Consequently, the distribution $p_0 = p_\text{data}$ can be sampled by solving \cref{eq:anderson_bwd}.

\citet{DarasDD2024} demonstrated the effectiveness of this framework only in fine-tuning latent diffusion models, leaving its efficacy when training from scratch unreported. Moreover, as sampling from $p_{r|s}$ depends on the model’s approximation of the score (which is particularly challenging to estimate accurately for $t < \zeta$) rather than the ground truth, there remains a gap between the theoretical framework and its practical implementation. This gap limits the extent to which the algorithm’s effectiveness is supported by their theoretical results.



