@inproceedings{das2018embodied,
  title={Embodied question answering},
  author={Das, Abhishek and Datta, Samyak and Gkioxari, Georgia and Lee, Stefan and Parikh, Devi and Batra, Dhruv},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1--10},
  year={2018}
}

@inproceedings{wijmans2019embodied,
  title={Embodied question answering in photorealistic environments with point cloud perception},
  author={Wijmans, Erik and Datta, Samyak and Maksymets, Oleksandr and Das, Abhishek and Gkioxari, Georgia and Lee, Stefan and Essa, Irfan and Parikh, Devi and Batra, Dhruv},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6659--6668},
  year={2019}
}

@inproceedings{yu2019multi,
  title={Multi-target embodied question answering},
  author={Yu, Licheng and Chen, Xinlei and Gkioxari, Georgia and Bansal, Mohit and Berg, Tamara L and Batra, Dhruv},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6309--6318},
  year={2019}
}

@inproceedings{majumdar2024openeqa,
  title={Openeqa: Embodied question answering in the era of foundation models},
  author={Majumdar, Arjun and Ajay, Anurag and Zhang, Xiaohan and Putta, Pranav and Yenamandra, Sriram and Henaff, Mikael and Silwal, Sneha and Mcvay, Paul and Maksymets, Oleksandr and Arnaud, Sergio and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={16488--16498},
  year={2024}
}

@inproceedings{gordon2018iqa,
  title={Iqa: Visual question answering in interactive environments},
  author={Gordon, Daniel and Kembhavi, Aniruddha and Rastegari, Mohammad and Redmon, Joseph and Fox, Dieter and Farhadi, Ali},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4089--4098},
  year={2018}
}

@inproceedings{masqa3d,
  title={SQA3D: Situated Question Answering in 3D Scenes},
  author={Ma, Xiaojian and Yong, Silong and Zheng, Zilong and Li, Qing and Liang, Yitao and Zhu, Song-Chun and Huang, Siyuan},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2023}
}

@inproceedings{azuma2022scanqa,
  title={Scanqa: 3d question answering for spatial scene understanding},
  author={Azuma, Daichi and Miyanishi, Taiki and Kurita, Shuhei and Kawanabe, Motoaki},
  booktitle={proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={19129--19139},
  year={2022}
}

@inproceedings{ren2024explore,
  title={Explore until Confident: Efficient Exploration for Embodied Question Answering},
  author={Ren, Allen Z and Clark, Jaden and Dixit, Anushri and Itkina, Masha and Majumdar, Anirudha and Sadigh, Dorsa},
  booktitle={First Workshop on Vision-Language Models for Navigation and Manipulation at ICRA 2024},
  year={2024}
}

@article{sakamoto2024map,
  title={Map-based Modular Approach for Zero-shot Embodied Question Answering},
  author={Sakamoto, Koya and Azuma, Daichi and Miyanishi, Taiki and Kurita, Shuhei and Kawanabe, Motoaki},
  journal={arXiv preprint arXiv:2405.16559  }       ,
  year={2024}
}

@inproceedings{chandrasegaranhourvideo,
  title={HourVideo: 1-Hour Video-Language Understanding},
  author={Chandrasegaran, Keshigeyan and Gupta, Agrim and Hadzic, Lea M and Kota, Taran and He, Jimming and Eyzaguirre, Cristobal and Durante, Zane and Li, Manling and Wu, Jiajun and Fei-Fei, Li},
  booktitle={The Thirty-eight Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
  year={2024}
}

@article{anwar2024remembr,
  title={Remembr: Building and reasoning over long-horizon spatio-temporal memory for robot navigation},
  author={Anwar, Abrar and Welsh, John and Biswas, Joydeep and Pouya, Soha and Chang, Yan},
  journal={arXiv preprint arXiv:2409.13682    }      ,
  year={2024}
}

@article{tan2023knowledge,
  title={Knowledge-based embodied question answering},
  author={Tan, Sinan and Ge, Mengmeng and Guo, Di and Liu, Huaping and Sun, Fuchun},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={45},
  number={10},
  pages={11948--11960},
  year={2023},
  publisher={IEEE}
}

@article{gao2024embodiedcity,
  title={EmbodiedCity: A Benchmark Platform for Embodied Agent in Real-world City Environment},
  author={Gao, Chen and Zhao, Baining and Zhang, Weichen and Mao, Jinzhu and Zhang, Jun and Zheng, Zhiheng and Man, Fanhang and Fang, Jianjie and Zhou, Zile and Cui, Jinqiang and others},
  journal={arXiv preprint arXiv:2410.09604       }    ,
  year={2024}
}

@article{ishmam2024image,
  title={From image to language: A critical analysis of visual question answering (vqa) approaches, challenges, and opportunities},
  author={Ishmam, Md Farhan and Shovon, Md Sakib Hossain and Mridha, Muhammad Firoz and Dey, Nilanjan},
  journal={Information Fusion},
  pages={102270},
  year={2024},
  publisher={Elsevier}
}

@inproceedings{guo2023images,
  title={From images to textual prompts: Zero-shot visual question answering with frozen large language models},
  author={Guo, Jiaxian and Li, Junnan and Li, Dongxu and Tiong, Anthony Meng Huat and Li, Boyang and Tao, Dacheng and Hoi, Steven},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={10867--10877},
  year={2023}
}

@article{liu2024aligning,
  title={Aligning Cyber Space with Physical World: A Comprehensive Survey on Embodied AI},
  author={Liu, Yang and Chen, Weixing and Bai, Yongjie and Li, Guanbin and Gao, Wen and Lin, Liang},
  journal={CoRR},
  year={2024}
}

@article{wu2018building,
  title={Building generalizable agents with a realistic and rich 3d environment},
  author={Wu, Yi and Wu, Yuxin and Gkioxari, Georgia and Tian, Yuandong},
  journal={arXiv preprint arXiv:1801.02209      }  ,
  year={2018}
}

@inproceedings{dai2017scannet,
  title={Scannet: Richly-annotated 3d reconstructions of indoor scenes},
  author={Dai, Angela and Chang, Angel X and Savva, Manolis and Halber, Maciej and Funkhouser, Thomas and Nie{\ss}ner, Matthias},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={5828--5839},
  year={2017}
}

@article{lee2024citynav,
  title={CityNav: Language-Goal Aerial Navigation Dataset with Geographic Information},
  author={Lee, Jungdae and Miyanishi, Taiki and Kurita, Shuhei and Sakamoto, Koya and Azuma, Daichi and Matsuo, Yutaka and Inoue, Nakamasa},
  journal={arXiv preprint arXiv:2406.14240}      ,
  year={2024}
}

@inproceedings{liu2023aerialvln,
  title={Aerialvln: Vision-and-language navigation for uavs},
  author={Liu, Shubo and Zhang, Hongsheng and Qi, Yuankai and Wang, Peng and Zhang, Yanning and Wu, Qi},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={15384--15394},
  year={2023}
}

@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774}     ,
  year={2023}
}

@article{yang2024qwen2,
  title={Qwen2. 5 technical report},
  author={Yang, An and Yang, Baosong and Zhang, Beichen and Hui, Binyuan and Zheng, Bo and Yu, Bowen and Li, Chengyuan and Liu, Dayiheng and Huang, Fei and Wei, Haoran and others},
  journal={arXiv preprint arXiv:2412.15115}      ,
  year={2024}
}

@inproceedings{yinsgsg-nav,
  title={SG-Nav: Online 3D Scene Graph Prompting for LLM-based Zero-shot Object Navigation},
  author={Yin, Hang and Xu, Xiuwei and Wu, Zhenyu and Zhou, Jie and Lu, Jiwen},
  booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
  year={2025}
}

@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

@inproceedings{bousselham2024grounding,
  title={Grounding everything: Emerging localization properties in vision-language transformers},
  author={Bousselham, Walid and Petersen, Felix and Ferrari, Vittorio and Kuehne, Hilde},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3828--3837},
  year={2024}
}

@book{sanders2016introduction,
  title={An introduction to Unreal engine 4},
  author={Sanders, Andrew},
  year={2016},
  publisher={AK Peters/CRC Press}
}


@inproceedings{shah2018airsim,
  title={Airsim: High-fidelity visual and physical simulation for autonomous vehicles},
  author={Shah, Shital and Dey, Debadeepta and Lovett, Chris and Kapoor, Ashish},
  booktitle={Field and Service Robotics: Results of the 11th International Conference},
  pages={621--635},
  year={2018},
  organization={Springer}
}

@article{deng2024opengraph,
  title={OpenGraph: Open-Vocabulary Hierarchical 3D Graph Representation in Large-Scale Outdoor Environments},
  author={Deng, Yinan and Wang, Jiahui and Zhao, Jingyu and Tian, Xinyu and Chen, Guangyan and Yang, Yi and Yue, Yufeng},
  journal={arXiv preprint arXiv:2403.09412}   ,
  year={2024}
}

@article{duan2022survey,
  title={A survey of embodied ai: From simulators to research tasks},
  author={Duan, Jiafei and Yu, Samson and Tan, Hui Li and Zhu, Hongyuan and Tan, Cheston},
  journal={IEEE Transactions on Emerging Topics in Computational Intelligence},
  volume={6},
  number={2},
  pages={230--244},
  year={2022},
  publisher={IEEE}
}

@article{lu2019vilbert,
  title={Vilbert: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks},
  author={Lu, Jiasen and Batra, Dhruv and Parikh, Devi and Lee, Stefan},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{mu2024embodiedgpt,
  title={Embodiedgpt: Vision-language pre-training via embodied chain of thought},
  author={Mu, Yao and Zhang, Qinglong and Hu, Mengkang and Wang, Wenhai and Ding, Mingyu and Jin, Jun and Wang, Bin and Dai, Jifeng and Qiao, Yu and Luo, Ping},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{xiang2024language,
  title={Language models meet world models: Embodied experiences enhance language models},
  author={Xiang, Jiannan and Tao, Tianhua and Gu, Yi and Shu, Tianmin and Wang, Zirui and Yang, Zichao and Hu, Zhiting},
  journal={Advances in neural information processing systems},
  volume={36},
  year={2024}
}

@article{huang2024manipvqa,
  title={Manipvqa: Injecting robotic affordance and physically grounded information into multi-modal large language models},
  author={Huang, Siyuan and Ponomarenko, Iaroslav and Jiang, Zhengkai and Li, Xiaoqi and Hu, Xiaobin and Gao, Peng and Li, Hongsheng and Dong, Hao},
  journal={arXiv preprint arXiv:2403.11289}  ,
  year={2024}
}

@article{zeng2024perceive,
  title={Perceive, reflect, and plan: Designing llm agent for goal-directed city navigation without instructions},
  author={Zeng, Qingbin and Yang, Qinglong and Dong, Shunan and Du, Heming and Zheng, Liang and Xu, Fengli and Li, Yong},
  journal={arXiv preprint arXiv:2408.04168}  ,
  year={2024}
}

@article{liu2024navagent,
  title={NavAgent: Multi-scale Urban Street View Fusion For UAV Embodied Vision-and-Language Navigation},
  author={Liu, Youzhi and Yao, Fanglong and Yue, Yuanchang and Xu, Guangluan and Sun, Xian and Fu, Kun},
  journal={arXiv preprint arXiv:2411.08579}  ,
  year={2024}
}

@article{gao2023room,
  title={Room-object entity prompting and reasoning for embodied referring expression},
  author={Gao, Chen and Liu, Si and Chen, Jinyu and Wang, Luting and Wu, Qi and Li, Bo and Tian, Qi},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2023},
  publisher={IEEE}
}

@article{pena2023visual,
  title={A visual questioning answering approach to enhance robot localization in indoor environments},
  author={Pe{\~n}a-Narvaez, Juan Diego and Mart{\'\i}n, Francisco and Guerrero, Jos{\'e} Miguel and P{\'e}rez-Rodr{\'\i}guez, Rodrigo},
  journal={Frontiers in Neurorobotics},
  volume={17},
  pages={1290584},
  year={2023},
  publisher={Frontiers Media SA}
}

@article{kalinowska2023embodied,
  title={Embodied communication: How robots and people communicate through physical interaction},
  author={Kalinowska, Aleksandra and Pilarski, Patrick M and Murphey, Todd D},
  journal={Annual review of control, robotics, and autonomous systems},
  volume={6},
  number={1},
  pages={205--232},
  year={2023},
  publisher={Annual Reviews}
}

@inproceedings{yan2024urbanclip,
  title={Urbanclip: Learning text-enhanced urban region profiling with contrastive language-image pretraining from the web},
  author={Yan, Yibo and Wen, Haomin and Zhong, Siru and Chen, Wei and Chen, Haodong and Wen, Qingsong and Zimmermann, Roger and Liang, Yuxuan},
  booktitle={Proceedings of the ACM on Web Conference 2024},
  pages={4006--4017},
  year={2024}
}