% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
% Change to "preprint" to generate a non-anonymous version with page numbers.
\usepackage[preprint]{acl}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}
\usepackage{amssymb}
% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}

% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

\usepackage{graphicx} %
% \urlstyle{rm} %
% \def\UrlFont{\rm}  %
\usepackage{natbib}  %
\usepackage{caption} %
\usepackage{algorithm}
\usepackage{listings}
\usepackage{algorithmic}
\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage[outdir=./]{epstopdf}
\usepackage{enumitem}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{subfloat}
\usepackage{newfloat}
\usepackage{graphicx}
% \usepackage[countmax]{subfloat}
% \usepackage{svg} % svg
\usepackage[normalem]{ulem}
\usepackage{framed}
\usepackage{mdframed}
\usepackage{xcolor}
\usepackage{lipsum}
\usepackage{float}
\usepackage{hyperref}

\definecolor{shadecolor}{gray}{0.9}
\definecolor{LightBlue}{rgb}{0.68, 0.85, 0.90}
\definecolor{LightYellow}{rgb}{1, 1, 0.71}
\definecolor{LightPurple}{rgb}{0.8, 0.6, 1}

\DeclareMathOperator*{\argmax}{arg\,max}
\newlist{todolist}{itemize}{2}
\setlist[todolist]{label=$\square$}
\usepackage{pifont}
\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%
\newcommand{\done}{\rlap{$\square$}{\raisebox{2pt}{\large\hspace{1pt}\cmark}}\hspace{-2.5pt}}
\newcommand{\wontfix}{\rlap{$\square$}{\large\hspace{1pt}\xmark}}

\newcommand{\todo}[1]{{\color{green} \textbf{ZQ}. #1}}
\newcommand{\yong}[1]{{\color{red} \textbf{Yong}: #1}}
\newcommand{\gao}[1]{{\color{pink} \textbf{Gao}: #1}}
\newcommand{\chen}[1]{{\color{red} \textbf{Chen}: #1}}
\newcommand{\chenf}[1]{\footnote{+chen+:#1}}
\newcommand{\yongrevised}[1]{{\color{pink} \textbf{Yong}: #1}}
\newcommand{\req}[1]{\textcolor{black}{#1}}
\newcommand{\rev}[1]{#1}
\newcommand{\yantex}[1]{{\color{black} \textbf{Yan}: #1}}
\newcommand{\yanf}[1]{\footnote{+yanf+:#1}}
\newcommand{\reviewf}[1]{\footnote{\color{blue}+rev+:#1}}


\newtheorem{mdefinition}{Definition}

\newtheorem{problem}{Problem}
\newcommand{\para}[1]{{\vspace{4pt} \bf \noindent #1 \hspace{0pt}}}

\setlength{\belowcaptionskip}{-0.1cm} 

\usepackage{array}
\newcolumntype{L}[1]{>{\raggedright\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{C}[1]{>{\centering\let\newline  \\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{R}[1]{>{\raggedleft\let\newline \\\arraybackslash\hspace{0pt}}m{#1}}


\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}
}


% \copyrightyear{2023}
% \acmYear{2023}
% \setcopyright{acmlicensed}
% \acmConference[WWW '24] {The Web Conference}{May 13--17, 2024}{Singapore}
% \acmBooktitle{Proceedings of The Web Conference 2024 (WWW '24), May 13--17, 2024, Singapore}
% \acmPrice{15.00}
% \acmISBN{979-8-4007-0103-0/23/08}
% \acmDOI{10.1145/XXXXXX.XXXXXX}
% \acmDOI{10.1145/3580305.3599322}

% \settopmatter{printacmref=true}

% \linespread{0.97}


% \copyrightyear{2025}
% \acmYear{2025}
% \setcopyright{acmcopyright}\acmConference[ALC'25]{The 63rd Annual Meeting of the Association for Computational Linguistics}{July 27th to August 1st, 2025}{Vienna, Austria}
% \acmBooktitle{The 63rd Annual Meeting of the Association for Computational Linguistics, Vienna, Austria}

% \author{Anonymous ACL submission}

% \author{Yong Zhao, Kai Xu, Zhengqiu Zhu, Yue Hu, Zhiheng Zheng, Yingfeng Chen, Yatai Ji, Chen Gao, Yong Li, Jincai Huang\\
% National University of Defense Technology, Tsinghua University\\
% \texttt{linian21@mails.tsinghua.edu.cn, \{chgao96, liyong07, liaoqm\}@tsinghua.edu.cn}}


\author{
 \textbf{Yong Zhao\textsuperscript{*1}},
 \textbf{Kai Xu\textsuperscript{*1}},
 \textbf{Zhengqiu Zhu\textsuperscript{1}},
 \textbf{Yue Hu\textsuperscript{1}},
  \\
 \textbf{Zhiheng Zheng\textsuperscript{2}},
 \textbf{Yingfeng Chen\textsuperscript{2}},
 \textbf{Yatai Ji\textsuperscript{1}},
 \textbf{Chen Gao \textsuperscript{2}},
 \textbf{Yong Li\textsuperscript{2}},
 \textbf{Jincai Huang\textsuperscript{1}}
\\
 \textsuperscript{1}National University of Defense Technology,
 \textsuperscript{2}Tsinghua University, \\
 \textsuperscript{*}Equal contribution
 % \textsuperscript{$\dagger$}Corresponding authors
\\
% \texttt{\{zhaoyong15, xukai09, zhuzhengqiu12\}@nudt.edu.cn, chgao96@gmail.com}
% \texttt{zhuzhengqiu12@nudt.edu.cn, chgao96@gmail.com}
}


% \orcid{0000-0003-4689-2289}
% \affiliation{
%   \institution{Shenzhen International Graduate School, Tsinghua University}
%   \city{Shenzhen}
%   \country{China}
% }

% \author{Chen Gao}
% \authornote{Corresponding author (chgao96@gmail.com).}
% \author{Yong Li}
% \affiliation{%
%   \institution{Department of Electronic Engineering, Tsinghua University}
%   \city{Beijing}
%   \country{China}
% }
% \author{Qingmin Liao}
% \affiliation{
%   \institution{Shenzhen International Graduate School, Tsinghua University}
%   \city{Shenzhen}
%   \country{China}
% }
% \renewcommand{\shortauthors}{Wen, et. al.}
%\renewcommand{\shortauthors}{Efficient and Joint Hyperparameter and Architecture Search for Collaborative Filtering}
% \makeatletter
% \def\@copyrightspace{\relax}
% \makeatother
% \settopmatter{printacmref=false}
\title{
% CityEQA: Long-Horizon Embodied (Dynamic) Question Answering in City Space via A Hierarchical Planner-Manager-Actor Agent Framework
% CityEQA: A Hierarchical Planner-Manager-Actor LLM Agent on Long-Horizon Embodied Question Answering Benchmark in City Space
CityEQA: A Hierarchical LLM Agent on Embodied Question Answering Benchmark in City Space
}
% \title{CityEQA: Long-Horizon Embodied Question Answering in City Space via Hierarchical Planner-Manager-Actor Framework}
\begin{document}
\maketitle
\begin{abstract}
% Our approach leverages multimodal representations and spatial reasoning to ground linguistic instructions in real-world cityscapes. We propose a novel framework that encodes urban context, dynamic object interactions, and scene semantics into a unified representation for robust decision-making. Experiments demonstrate that our method outperforms existing state-of-the-art models in XX metrics, paving the way for more effective embodied perception intelligence applications in urban settings. But here is still a significant gap between the baseline model and human performance,
% Embodied Question Answering (EQA) poses a distinctive challenge, combining natural language processing, computer vision, and robotics. It demands that agents proactively explore complex environments to answer open-ended questions. While existing studies have predominantly focused on indoor scenarios, this paper introduces CityEQA, addressing the challenges of answering perception questions in city spaces, which entail significant environmental, action, and perception complexities. We propose a benchmark dataset, namely CityEQA-EC, generated through extensive human annotation, designed to evaluate agent performance in navigating and understanding intricate urban landscapes. Moreover, we also design a novel embodied agent baseline for this task, which enables efficient decision-making and long-horizon planning via a hierarchical Planner-Manager-Actor framework. Experimental results demonstrate the effectiveness of our proposed methods in enhancing the capabilities of agents in CityEQA tasks, paving the way for future advancements in city embodied intelligence. But here is still a significant gap between the baseline model and human performance.
Embodied Question Answering (EQA) has primarily focused on indoor environments, leaving the complexities of urban settings—spanning environment, action, and perception—largely unexplored. To bridge this gap, we introduce \textbf{CityEQA}, a new task where an embodied agent answers open-vocabulary questions through active exploration in dynamic city spaces. To support this task, we present \textbf{CityEQA-EC}, the first benchmark dataset featuring 1,412 human-annotated tasks across six categories, grounded in a realistic 3D urban simulator. Moreover, we propose \textbf{Planner-Manager-Actor (PMA)}, a novel agent tailored for CityEQA. PMA enables long-horizon planning and hierarchical task execution:  the Planner breaks down the question answering into sub-tasks, the Manager maintains an object-centric cognitive map for spatial reasoning during the process control, and the specialized Actors handle navigation, exploration, and collection sub-tasks. Experiments demonstrate that PMA achieves 60.7\% of human-level answering accuracy, significantly outperforming frontier-based baselines. While promising, the performance gap compared to humans highlights the need for enhanced visual reasoning in CityEQA. This work paves the way for future advancements in urban spatial intelligence. Dataset and code are available at \url{https://github.com/tsinghua-fib-lab/CityEQA.git}. 



\end{abstract}

% \keywords{Macroeconomic Simulation; Large Language Models; Agent-based Modeling}

% \maketitle



\input{1.intro}
\input{3.dataset}
\input{4.method}
\input{5.exp}
\input{2.related}


\section{Conclusion}\label{sec::conclusion}

This paper pioneers the exploration of EQA tasks in outdoor urban environments. First, we introduced CityEQA-EC, the inaugural open-ended benchmark for CityEQA, comprising 1,412 tasks divided into six distinct categories. Second, we proposed a novel agent model (the PMA), designed to tackle long-horizon tasks through hierarchical planning, sensing, and execution.  Experimental results validated the effectiveness of PMA, achieving 60.73\% accuracy relative to human performance and outperforming traditional methods such as the FBE Agent. Nevertheless, challenges remain, including efficiency discrepancies (24.44 vs. 9.31 mean time steps taken by humans) and limitations in visual thinking capabilities. Future research could focus on enhancing PMA with self-reflection and error-correction mechanisms to mitigate error accumulation that can arise in long-horizon tasks.

\clearpage

\section{Limitations}
The work primarily focuses on object-centric question-answering tasks, such as identifying specific objects (e.g., buildings, vehicles) within city spaces.  Further, while our approach is effective for tasks involving static physical entities, it overlooks the importance of social interactions and dynamic events, which are also critical in urban settings.  For instance, questions related to dynamic events (e.g., "Is there a traffic jam on Main Street?"), or environmental conditions (e.g., "Is the park crowded right now?") are not considered up to now. These types of questions require some different sets of reasoning capabilities, such as temporal reasoning, event detection, and social context understanding, which are not currently supported by the Planner-Manager-Actor (PMA) agent.  Future work should expand the scope of CityEQA to include these non-entity-based tasks, further extending PMA and enabling embodied agents to handle a broader range of urban spatial intelligence challenges.


% \paragraph{Simulation Environment Constraints} The reliance on a single simulated cityscape (EmbodiedCity) limits generalizability to diverse real-world urban layouts. Depth estimation errors and simplified spatial relationships (e.g., cardinal directions only) may introduce biases.

% \paragraph{Error Accumulation in Long-Horizon Tasks} PMA’s hierarchical structure risks compounding errors during multi-step navigation and exploration, particularly in cluttered or ambiguous environments.

% \paragraph{Visual Thinking in Collector}


\section{Ethics Statement}
In the data collection, we ensure there is no identifiable information about individuals (faces, license plates) or private properties.
Thus, there is no ethical concern.
% Agents operating in city spaces (e.g., drones) may inadvertently capture identifiable information about individuals (faces, license plates) or private properties during exploration. Strict protocols for real-time data anonymization, limited retention periods, and explicit opt-out mechanisms for sensitive areas (e.g., residential zones) must be implemented.

% \clearpage

\bibliographystyle{ACM-Reference-Format}
% \balance
% \bibliographystyle{plain}
\bibliography{bibliography}
% \nobalance

% \nobalance 
\clearpage

\input{6.appendix}


% \nobalance 

\end{document}
