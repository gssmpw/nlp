



















\newcommand{\supplementarytitle}{
    \twocolumn[
        \begin{center}
            \LARGE \textbf{DOEI: Dual Optimization of Embedding Information With Attention-Enhanced Class Activation Maps} \\
            \vspace{2em}
            \Large \textbf{- Supplementary Materials -}
            \vspace{4em}
        \end{center}
    ]
}


\supplementarytitle

\renewcommand{\thesection}{\arabic{section}}
\setcounter{section}{0}

\renewcommand{\thefigure}{\arabic{figure}}
\setcounter{figure}{0}

\renewcommand{\thetable}{\arabic{table}}
\setcounter{table}{0}


\section{Datasets and Evaluation protocol}

    We assess the effectiveness of the proposed method by evaluating its performance on the widely used datasets, PASCAL VOC 2012~\cite{everingham2010pascal} and MS COCO 2014~\cite{lin2014microsoft}. \textbf{PASCAL VOC} is divided into training (train), validation (val), and test sets, containing 1,464, 1,449, and 1,456 images, respectively, covering 20 target categories and one background category. To maintain consistency with the general protocol followed in previous studies~\cite{xu2022multi,cheng2023out}, we used the augmented training set containing 10,582 images to train the classification network. \textbf{MS COCO} includes 80 target categories and one background category, with approximately 82,000 training images and 40,000 validation images. Following~\cite{lee2021railroad}, we retained only images containing target classes and extracted the ground-truth labels from COCO stuff~\cite{caesar2018coco}.
    
    To ensure fair comparison of experimental results with previous studies~\cite{xu2022multi,cheng2023out}, we followed the same calculation  approach and used mean Intersection-over-Union (mIoU) as the evaluation metric, which is suitable for assessing the \(train\) and \(val\) sets of two datasets. For the PASCAL VOC \(test\) set, results are provided by the official online evaluation server.

    \begin{figure}[H]
    \centering
    \includegraphics[width=\columnwidth]{figures/IJCAI-fig5.pdf}  
    \caption{Impact of varying numbers of embedding optimization layers on the mIoU, FP, and FN of the final CAM.}
    \label{Figure 5}
    \end{figure}
    
\section{Parameter Analysis}

    \textbf{Hybrid Feature Alignment weight \( \alpha \).} To highlight the impact of weight values \( \alpha \) on experimental results, all other hyper-parameters were fixed to the configuration that produced the best CAM quality. As shown in Figure~\ref{Figure 5}(a), the graph illustrates the effect of varying weights on mIoU values. Additionally, to visually demonstrate the improvement brought by the hybrid feature alignment weight \( \alpha \), we performed a comparative heatmap visualization of the fusion strategy. 
    
    
    
    As shown in Figure~\ref{Figure 5}, panel (b) displays the heatmap visualizations of self-attention weights for a specific category, both without and with the introduction of hybrid feature alignment. Experimental results show that when the weight is set to 0.35, mIoU reaches its maximum value, improving by 0.7\% compared to the case without hybrid feature alignment. This demonstrates that the introduction of hybrid feature alignment module allows the model to effectively address the limitations of the ViT self-attention mechanism in capturing image features. The fused features offer a more comprehensive representation of information across various dimensional spaces in the image, thereby fully validating the effectiveness of the feature fusion strategy.
    
    \textbf{Selection of Embedding Optimization Layers.} To showcase the improvement in CAM generation from embedding optimization and identify the optimal number of embedding optimization layers, we optimized embeddings at different numbers of cascaded encoders and compared the resulting improvements in the target localization map quality. We use mIoU to measure the accuracy of CAM and introduce the false positive (FP) and false negative (FN) metrics to jointly assess the severity of over-activation and under-activation in the model. As shown in Figure~\ref{Figure 6}, we set different numbers \( K\) of embedding optimization layers across layers 1 to 12 (the transformer encoder in DeiT-S consists of 12 layers) and calculated the results separately for each configuration, where \( K\) refers to refers to the first \( K\) layers near the input end. The results indicate that embedding optimization at every layer most effectively suppresses over-activation or under-activation. In contrast, without embedding optimization, the FP and FN values are the highest, and the mIoU value is the lowest. This suggests that, with the help of the embedding optimization mechanism, the model can appropriately extend to the entire target area while suppressing extension to non-target regions.
    
    \begin{figure*}[t] 
    \centering
    \includegraphics[width=\textwidth, trim=0.1cm 0.1cm 0.1cm 0.1cm, clip]{figures/IJCAI-fig7.pdf}
    \caption{
    Visualization of the CAMs of input images generated by different methods. (a)(e) Input; (b)(f) Baseline; (c)(g) Dual Optimization of Embedding Information (DOEI); (d)(h) GT;
    }
    \label{Figure 7} 
    \end{figure*}

\section{Qualitative Analysis}

    Figure~\ref{Figure 7} illustrates a clear comparison of the results obtained by applying our proposed method versus those of the baseline model. On the PASCAL VOC dataset, the quality of class activation maps (CAMs) generated after optimizing with our information embedding technique is significantly superior to that of the original baseline model. Notably, even on large-scale and highly complex datasets such as MS COCO, our innovative method demonstrates outstanding and consistent performance. This is largely attributed to its ability to effectively extract, refine, and optimize the intrinsic knowledge learned by the model, enabling a more precise representation of the target features and progressively achieving enhanced overall performance.

    \begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{figures/IJCAI-fig6.pdf}  
    \caption{Impact of varying numbers of embedding optimization layers on the mIoU, FP, and FN of the final CAM.}
    \label{Figure 6}
    \end{figure}
    





