%Version 3 December 2023
% See section 11 of the User Manual for version history
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                                 %%
%% Please do not use \input{...} to include other tex files.       %%
%% Submit your LaTeX manuscript as one .tex document.              %%
%%                                                                 %%
%% All additional figures and files should be attached             %%
%% separately and not embedded in the \TeX\ document itself.       %%
%%                                                                 %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%\documentclass[referee,sn-basic]{sn-jnl}% referee option is meant for double line spacing

%%=======================================================%%
%% to print line numbers in the margin use lineno option %%
%%=======================================================%%

%%\documentclass[lineno,sn-basic]{sn-jnl}% Basic Springer Nature Reference Style/Chemistry Reference Style

%%======================================================%%
%% to compile with pdflatex/xelatex use pdflatex option %%
%%======================================================%%

%%\documentclass[pdflatex,sn-basic]{sn-jnl}% Basic Springer Nature Reference Style/Chemistry Reference Style


%%Note: the following reference styles support Namedate and Numbered referencing. By default the style follows the most common style. To switch between the options you can add or remove Numbered in the optional parenthesis. 
%%The option is available for: sn-basic.bst, sn-vancouver.bst, sn-chicago.bst%  
 
%%\documentclass[pdflatex,sn-nature]{sn-jnl}% Style for submissions to Nature Portfolio journals
%%\documentclass[pdflatex,sn-basic]{sn-jnl}% Basic Springer Nature Reference Style/Chemistry Reference Style
\documentclass[pdflatex,sn-mathphys-num]{sn-jnl}% Math and Physical Sciences Numbered Reference Style 
%%\documentclass[pdflatex,sn-mathphys-ay]{sn-jnl}% Math and Physical Sciences Author Year Reference Style
%%\documentclass[pdflatex,sn-aps]{sn-jnl}% American Physical Society (APS) Reference Style
%%\documentclass[pdflatex,sn-vancouver,Numbered]{sn-jnl}% Vancouver Reference Style
%%\documentclass[pdflatex,sn-apa]{sn-jnl}% APA Reference Style 
%%\documentclass[pdflatex,sn-chicago]{sn-jnl}% Chicago-based Humanities Reference Style

%%%% Standard Packages
%%<additional latex packages if required can be included here>

\usepackage{graphicx}%
\usepackage{multirow}%
\usepackage{amsmath,amssymb,amsfonts}%
\usepackage{amsthm}%
\usepackage{mathrsfs}%
\usepackage[title]{appendix}%
\usepackage{xcolor}%
\usepackage{textcomp}%
\usepackage{manyfoot}%
\usepackage{booktabs}%
\usepackage{algorithm}%
\usepackage{algorithmicx}%
\usepackage{algpseudocode}%
\usepackage{listings}%
%\usepackage{url}
%\usepackage{hyperref}
%%%%

% \usepackage{amssymb}
\usepackage{float}
% \usepackage{amsmath}
% \usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{subcaption}

%%%%%=============================================================================%%%%
%%%%  Remarks: This template is provided to aid authors with the preparation
%%%%  of original research articles intended for submission to journals published 
%%%%  by Springer Nature. The guidance has been prepared in partnership with 
%%%%  production teams to conform to Springer Nature technical requirements. 
%%%%  Editorial and presentation requirements differ among journal portfolios and 
%%%%  research disciplines. You may find sections in this template are irrelevant 
%%%%  to your work and are empowered to omit any such section if allowed by the 
%%%%  journal you intend to submit to. The submission guidelines and policies 
%%%%  of the journal take precedence. A detailed User Manual is available in the 
%%%%  template package for technical guidance.
%%%%%=============================================================================%%%%

%% as per the requirement new theorem styles can be included as shown below
\theoremstyle{thmstyleone}%
\newtheorem{theorem}{Theorem}%  meant for continuous numbers
%%\newtheorem{theorem}{Theorem}[section]% meant for sectionwise numbers
%% optional argument [theorem] produces theorem numbering sequence instead of independent numbers for Proposition
\newtheorem{proposition}[theorem]{Proposition}% 
%%\newtheorem{proposition}{Proposition}% to get separate numbers for theorem and proposition etc.

\theoremstyle{thmstyletwo}%
\newtheorem{example}{Example}%
\newtheorem{remark}{Remark}%

\theoremstyle{thmstylethree}%
\newtheorem{definition}{Definition}%

\raggedbottom
%%\unnumbered% uncomment this for unnumbered level heads

\begin{document}

\title[Complex Networks for Pattern-Based Data Classification]{Complex Networks for Pattern-Based Data Classification}

%%=============================================================%%
%% GivenName	-> \fnm{Joergen W.}
%% Particle	-> \spfx{van der} -> surname prefix
%% FamilyName	-> \sur{Ploeg}
%% Suffix	-> \sfx{IV}
%% \author*[1,2]{\fnm{Joergen W.} \spfx{van der} \sur{Ploeg} 
%%  \sfx{IV}}\email{iauthor@gmail.com}
%%=============================================================%%

\author[1]{\fnm{Josimar} \sur{Chire}}\email{jecs89@usp.br}

\author*[2]{\fnm{Khalid} \sur{Mahmood}}\email{khalid.mahmood@it.uu.se}


\author[3]{\fnm{Zhao} \sur{Liang}}\email{zhao@usp.br}


\affil*[1]{\orgdiv{Institute of Mathematics and Computer Science}, \orgname{University of São Paulo}, \orgaddress{\city{São Carlos}, \state{SP}, \country{Brazil}}}

\affil[2]{\orgdiv{Department of Information Technology}, \orgname{Uppsala University}, \orgaddress{\city{Uppsala}, \country{Sweden}}}

\affil[3]{\orgdiv{Department of Computing and Mathematics}, \orgname{University of Sao Paulo}, \orgaddress{\city{Ribeirão Preto}, \state{SP}, \country{Brazil}}}

%%==================================%%
%% Sample for unstructured abstract %%
%%==================================%%

\abstract{Data classification techniques partition the data or feature space into smaller sub-spaces, each corresponding to a specific class. To classify into subspaces, physical features e.g.,  distance and distributions are utilized. This approach is challenging for the characterization of complex patterns that are embedded in the dataset.  However, complex networks remain a powerful technique for capturing internal relationships and class structures, enabling High-Level Classification. Although several complex network-based classification techniques have been proposed, high-level classification by leveraging pattern formation to classify data has not been utilized. In this work, we present two network-based classification techniques utilizing unique measures derived from the Minimum Spanning Tree and Single Source Shortest Path. These network measures are evaluated from the data patterns represented by the inherent network constructed from each class. We have applied our proposed techniques to several data classification scenarios including synthetic and real-world datasets. Compared to the existing classic high-level and machine-learning classification techniques, we have observed promising numerical results for our proposed approaches. Furthermore, the proposed models demonstrate the following distinguished features in comparison to the previous high-level classification techniques: (1) A single network measure is introduced to characterize the data pattern, eliminating the need to determine weight parameters among network measures. Therefore, the model is largely simplified, while obtaining better classification results. (2) The metrics proposed are sensitive and used for classification with competitive results.
}

%%================================%%
%% Sample for structured abstract %%
%%================================%%

% \abstract{\textbf{Purpose:} The abstract serves both as a general introduction to the topic and as a brief, non-technical summary of the main results and their implications. The abstract must not include subheadings (unless expressly permitted in the journal's Instructions to Authors), equations or citations. As a guide the abstract should not exceed 200 words. Most journals do not set a hard limit however authors are advised to check the author instructions for the journal they are submitting to.
% 
% \textbf{Methods:} The abstract serves both as a general introduction to the topic and as a brief, non-technical summary of the main results and their implications. The abstract must not include subheadings (unless expressly permitted in the journal's Instructions to Authors), equations or citations. As a guide the abstract should not exceed 200 words. Most journals do not set a hard limit however authors are advised to check the author instructions for the journal they are submitting to.
% 
% \textbf{Results:} The abstract serves both as a general introduction to the topic and as a brief, non-technical summary of the main results and their implications. The abstract must not include subheadings (unless expressly permitted in the journal's Instructions to Authors), equations or citations. As a guide the abstract should not exceed 200 words. Most journals do not set a hard limit however authors are advised to check the author instructions for the journal they are submitting to.
% 
% \textbf{Conclusion:} The abstract serves both as a general introduction to the topic and as a brief, non-technical summary of the main results and their implications. The abstract must not include subheadings (unless expressly permitted in the journal's Instructions to Authors), equations or citations. As a guide the abstract should not exceed 200 words. Most journals do not set a hard limit however authors are advised to check the author instructions for the journal they are submitting to.}

\keywords{Complex Networks, \sep High-Level Classification, \sep Machine Learning, \sep Artificial Intelligence.}

%%\pacs[JEL Classification]{D8, H51}

%%\pacs[MSC Classification]{35A01, 65L10, 65L12, 65L20, 65L70}

\maketitle

\section{Introduction}

Data classification maps the training dataset to the corresponding desired output. This constructed map - called a classifier, is used to predict the output for the new input instances.  One of the primary challenges of data classification is the feature extraction. In the context of machine learning, the feature extraction is a process of transforming raw data into a set of measurable properties or characteristics.  This process involves selecting and/or creating new variables that encapsulate the essential information needed to perform a specific analysis or task. The process often reducing the dimensionality of the data while preserving its most important characteristics. The feature extraction process is challenging because good features primarily vary from one dataset to another. 

In recent years, deep learning techniques have often been used for feature extractions, which revolutionized the classification tasks for numerous application scenarios such as object detection \cite{Redmon2016}, \cite{Ren2015}, machine translation \cite{Luong2015, Wu2016}, and speech recognition \cite{Hinton2012}. Deep learning models are ideal for neural networks that represent hierarchical structures, where simpler patterns are combined and reused to form more complex patterns. The primary advantage is that they can extract suitable features from the original data in an automatic manner.  Further, classic deep learning models, such as Convolutional Neural Networks (CNN) \cite{Goodfellow2016} are often suitable for processing data having regular forms (e.g., images).  However, the high-level semantic features embedded in datasets are difficult to decompose using traditional deep-learning techniques. This types of task requires analyzing the input data as a whole to identify the relationships among data samples and, consequently, the formation of its global pattern. This situation emerges in many real-world applications, such as machine translation and medical image diagnosis. 

To leverage the pattern from the dataset, a class of deep neural networks, called Graph Neural Networks (GNNs) \cite{Ward2022, Zhang2018, Wu2019, Zhou2022} has garnered significant attention. GNNs process data represented as graphs where the global structure of the data is captured.  Although several initiatives \cite{Angelov2020, Bai2021, Ras2022, Belle2021} have been conducted, deep learning models including GNNs are still short of a mechanism to provide an effective outcome, which is particularly important for many real-world applications (e.g., medical diagnostics).


% The following text was paraphrased
%Data classification maps the input data to the corresponding desired output for a given training set. The constructed map - called a classifier, is used to predict new input instances. One of the primary challenges of data classification is the feature extraction. The primary reason is that good features vary from one dataset to another. In this type of application scenario, deep learning techniques have revolutionized classification tasks in recent years for application scenarios such as object detection \cite{Redmon2016, Ren2015}, machine translation \cite{Luong2015, Wu2016}, and speech recognition \cite{Hinton2012}. Deep learning models are suitable for neural networks to represent hierarchical structures where simpler patterns are composed and reused to form more complex patterns. The primary advantage is that they can extract suitable features from the original data in an automatic way. However, classic deep learning models, such as Convolutional Neural Networks (CNN) \cite{Goodfellow2016} are suitable for processing data with regular forms, such as images.  Furthermore, the high-level semantic features embedded in datasets are hardly decomposed utilizing deep learning techniques. This kind of task requires the analysis of input data as a whole to identify the relationship among data samples and, consequently, its global pattern formation. This situation appears in many real-world applications such as machine translation, and medical image diagnosis. In order to leverage this pattern from the dataset, a class of deep neural networks, called Graph Neural Networks (GNNs) \cite{Ward2022, Zhang2018, Wu2019, Zhou2022}, triggered much attention. GNNs process data represented as graphs where the global structure of the data is captured.  Although several initiatives \cite{Angelov2020, Bai2021, Ras2022, Belle2021} have been conducted, deep learning models including GNNs are still short of a mechanism to provide an effective outcome, which is particularly important for many real-world applications (e.g., medical diagnostics). 



In recent years, interest in complex networks (i.e., a large-scale graph with nontrivial connection patterns) has grown considerably \cite{Barabasi99, barabasi2016network, newman10, chiresaire2020new}. This rise in interest is due to the inherent advantages of representing data as networks, which allow for capturing spatial, topological, dynamical, and functional relationships within large datasets. As a result, complex networks provide an effective method for identifying data patterns by considering the local, intermediate, and global relationships among data samples. Promising results have already been achieved in this area \cite{silva2016}.

Another approach – called hybrid classification technique \cite{silva2012} that combines both low and high levels of learning, has been proposed. Low-level classification techniques capture the physical features (e.g., geometrical or statistical features) of the input data using traditional classification methods. In contrast, high-level classification techniques utilize the complex topological properties of networks constructed from the input data. This approach typically uses three network measures—average degree, clustering coefficient, and assortativity—to represent the pattern of each class network derived from the input data. The authors \cite{silva2015} has also introduced a network-based classification technique that uses the average lengths of the transition and the attractive cycle of the tourist walk initiated from each node to represent network patterns. Another network-based classification technique employing the community concept has been proposed for detecting stock market trends \cite{TiagoZhao2021}.




%the following text is paraphrased
%Recently interest in complex networks (large-scale graphs with nontrivial connection patterns) has grown considerably \cite{Barabasi99, barabasi2016network, newman10, chiresaire2020new}. This emergence is explained by the inherent advantages that the data representation as networks provides; allowing to capture of spatial, topological, dynamical, and functional relations present in the large datasets. Complex networks are, therefore, a suitable way to identify data patterns considering local, intermediate, and global relationships among data samples. Some encouraging results have already been obtained in this direction \cite{silva2016}.  Another approach involving hybrid classification technique that combines the low and high levels of learning was also proposed \cite{silva2012}. In the low level classification techniques, the physical features (e.g., geometrical or statistical features) of the input data are captured, which can be implemented by any traditional classification technique. In contrast, high-level classification techniques exploit the complex topological properties of the underlying network constructed from the input data. In this technique, three network measures (i.e., average degree, clustering coefficient, and assortativity) are used to represent the pattern of each class network constructed from the input data. Later, the authors \cite{silva2015} have presented a network-based classification technique using the average lengths of the transition and the attractive cycle of the tourist walk initiated from  each node to represent network patterns . A network-based classification technique applying the community concept has also been proposed for stock market trend detection \cite{TiagoZhao2021}.

The complex network-based classification approach proposed in these works present definite advantages, such as classification according to pattern formation of the data, the classification process, and interoperability. However, these works exhibit the following limitations: 
\begin{enumerate}
  %\item It requires working together with a traditional classification technique that forms a hybrid approach. This initiates an extra challenging task to determine the weights between the two classifiers in different cases of classification.
  \item These methods require collaboration with a traditional classification technique, creating a hybrid approach. It introduces the additional challenge of determining the weights between the two classifiers for different classification scenarios.

  
  %\item Several network measures of these types of works are used to characterize the data pattern represented by the constructed networks for each class. Similar to the previous issue, the weights among the measures required to be defined, which is not trivial.

 \item Several network measures are utilized to characterize the data patterns represented by the constructed networks for each class. As with the previous issue, defining the weights among these measures is non-trivial.

  
  %\item The classification process is performed by checking the conformance of the new data to the pattern of each class network. Since each time only one test data is inserted, the network measure variations before and after the insertion usually is small, which makes it difficult to check the conformance levels. 

  \item The classification process involves checking how well the new data conforms to the pattern of each class network. Since only one test data point is inserted at a time, the variations in network measures before and after the insertion are usually minimal, making it difficult to assess conformance levels.






\end{enumerate}

\subsection{Contributions}
To overcome the above-mentioned problems, we present two network-based classification techniques considering a unique measure extracted from the inherent pattern of the data represented as a graph. These two techniques: Minimum Spanning Tree (MST) \cite{MST} and Single Source Shortest Path (SSSP) \cite{SSSP}, are utilized to characterize the networks constructed for each class. These approaches eliminate the need to determine any weights in the new model, making the new measure highly sensitive to the addition of even a single data item. Our observations indicate that these techniques produce promising numerical results when compared to traditional and other high-level classification techniques.









%In this way, no weight in the new model is required to be determined and the new measure is more sensitive to the insertion of even only one data item. We have observed promising numerical results utilizing these techniques in comparison to classic and other high-level classification techniques. 
%check later
% In network-based classification process, we firstly need to construct a network from the each class of the training data. Several methods have been proposed, such as b-matching \cite{Jebara2009},  linear neighborhood \cite{Wang2008} and methods based on single linkage \cite{Cupertino2013}.
% However, all of them consider the data features having the same importance in the distance or similarity calculation. 
% This is usually not accurate. Therefore, we determined which proportion each feature or variable contributes to the final classification results. This can be performed by assigning a weight to each data variable (feature) - modeling into an optimization problem. In this work, we also present a smiplified method to optimized the network construction process, utilizing Genetic Algorithm (GA). 


In summary, the contributions of this work are as follows:

\begin{itemize}
  \item We have present network-based classification techniques utilizing Minimum Spanning Tree (MST) and Single Source Shortest Path (SSSP) by leveraging the data represented as a graph. While our earlier work \cite{paperjecs} has introduced the MST model, in this work we provided extensive experiments to bolster our novel approach. The improved SSSP approach on the other hand is entirely novel and has not been proposed earlier. The techniques are presented in Section \ref{methods}.
  
  \item We have provided the running time of the implementation of our proposal using MST and SSSP approach, in Section \ref{complexity}. We have shown in practice that the SSSP approach will run faster compared with MST. By performing experimental evaluation in Section \ref{analysis}, we have also verified our claim that SSSP provides better performance.


  % \item We have demonstrated that MST measure performs better compared to the classical assortativity and average clustering techniques by utilizing synthetic and traditional datasets (e.g., Iris[XX], Wine[XX]) (Section \ref{experiment}).

\item By utilizing synthetic and traditional datasets (e.g., Iris \cite{iris}, Wine \cite{wine}), we have demonstrated that both MST and SSSP provide comparable performance for the insertion of elements for both the same and different classes (Section \ref{experiment}).


 % SSSP and MST is comparable with synthetic and traditional datasets  f
  
  \item We have further compared our approaches to the traditional machine learning algorithms by utilizing three real-world application datasets \cite{penguin, pulsar, covid} in Section \ref{applicaiotn}. We have shown that both MST and SSSP measures provide comparable performance to the machine learning algorithms such as MLP \cite{MLP}, XGBoost \cite{XGBoost}, Gaussian Naive Bayes \cite{naive}, Multilayer Perceptron (MLP) \cite{MLP}, Decision Tree\cite{decision_tree},  Logistic Regression \cite{logistic_regression}, Gaussian Naive Bayes \cite{naive}, Gradient Boosting \cite{gradient_descent}, Bootstrap Aggregating  \cite{bagging}, and Xgboost \cite{XGBoost}, while leveraging the internal structure of the network.


 

  
\end{itemize}

\section{Methodologies} \label{methods}

% \begin{itemize}
%     \item Select keywords related to covid-19 pandemic
%     \item Build the Query and Collect Data
%     \item Pre-processing data
%     \item Visualization to support Analysis
% \end{itemize}

The training and classification process utilizes the Minimum Spanning Tree (MST) or Single Source Shortest Path (SSSP) as a network measure. The proposed approaches consist of the following steps,  which are further elaborated through Figure \ref{fig:proposal}:

\begin{figure*}[!hbpt]
\centerline{
\includegraphics[width=0.95\textwidth]{graphics/method.drawio.pdf}
}
\vspace*{6mm}
\caption{Proposed approaches}
\label{fig:proposal}
\end{figure*}


\begin{enumerate}
  \item In the training phase, a set of $K$ networks are constructed, each for one of the $K$ classes. This step is depicted in Fig. \ref{fig:proposal}a, where the \textit{Dataset} is classified into two \textit{classes} (i.e., class \textit{1} and \textit{2}).  
  \item For each network, a data sample is represented as a node, where the connection weight between a pair of nodes is determined by the Euclidean distance. The corresponding underlying network of the \textit{Dataset} (from Fig. \ref{fig:proposal}a) is presented in Fig. \ref{fig:proposal}b. Here, the classification marked by \textit{class 1} and \textit{class 2} corresponds to \textit{network1} and \textit{network2} respectively.
  \item The training and classification process utilized either MST or SSSP as network measures. The MST and SSSP are applied to the underlying networks of \ref{fig:proposal}b (\textit{e.g., network1}, \textit{network2}), and the corresponding connected networks (forms a tree) are shown in Fig. \ref{fig:proposal}c.
     \begin{itemize}
         \item \textbf{MST}: For each network, Minimum Spanning Tree is calculated to represent the pattern formation of the corresponding class of data. 
         \item \textbf{SSSP}: The Single Source Shortest Path algorithm requires a source to be present in the network. To select a candidate source,  we first calculate the centroid \cite{Centroid} for each network and utilize it as a source for SSSP algorithm. In this approach, we use SSSP measure (instead of MST) to represent the pattern formation.
     \end{itemize}
  \item In the classification phase, a \textit{testing sample} (shown in Fig. \ref{fig:proposal}d) is inserted into each of the $K$ networks (of Fig. \ref{fig:proposal}c). The chosen measure (either MST or SSSP) is calculated again by considering the insertion of this new \textit{testing sample}. This process is depicted in Fig. \ref{fig:proposal}e, where SSSP is chosen as an example the network metric. For \textit{network1}, the SSSP measure before inserting the \textit{test data} is \textit{SSSP\textsubscript{1}'}, while \textit{SSSP\textsubscript{1}"} is evaluated after the insertion.
  \item Finally, the \textit{testing sample} is classified into a class, where its insertion causes the smallest variation of the MST or SSSP measure. For example, if the relative variation of \textit{network1} (based on  \textit{SSSP\textsubscript{1}'} and \textit{SSSP\textsubscript{1}"}) is smaller than the variation of \textit{network2} (based on  \textit{SSSP\textsubscript{2}'} and \textit{SSSP\textsubscript{2}"}), the \textit{testing sample} will be classified as \textit{network1}. This classification process is further discussed in Section \ref{classification}.
\end{enumerate}


In these approaches, the \textit{testing sample} aligns with the pattern formation of its class. Notice that the \textit{testing sample} can be either close to or far from the training samples of the same class, as classification is based on pattern conformation. Therefore, in the proposed approaches, checking physical distance or distribution is not a criterion for classification.

It is important to note that all the steps (from 1 to 5) in the classification and training processes for both MST and SSSP are identical, with the only difference being the selection of either MST or SSSP algorithm as the network measure.

The technicalities of the proposed models are further described in the following subsections. 

%\subsection{Preparing dataset}

%The dataset can possess attributes with different scales. Therefore,  we first normalize the attribute values following the min-max equation \ref{eq:min_max}.

%and oversampling step can be used to balance dataset and have similar number of samples per class

%\begin{equation}
%    x' = \frac{x - min(x)}{max(x) - min(x)}
%\label{eq:min_max}
% \end{equation}

%As a result, all the attribute values are mapped into the interval $[-1, 1]$.

% (\textbf{Josimar, descreve exatamente as normalizações feitas nesta etapa}).

% \subsection{Building the Optimized Complex Networks}

% The dataset is split in two parts following classic training-testing process. In the present classification strategy, the training phase is noting but the network construction for each data class. Each data sample is a node and each pair of the nodes is connected with a weight inversely proportional to their Euclidean distance, forming a fully connected and weighted network. 

% After that, each constructed network is pruned by excluding the edges with the weight values lower than $\theta$*median of the weights to tune the structure up. %And after of several experiments, the proper values is $0.80$.

% %\subsection{Optimization of the Constructed Networks}

% The networks constructed so far consider all the attributes have the same importance for correct classification. Generally, this is not true. On the contrary, different attributes contribute in different levels or have different importance. Therefore, we propose to associate a weight for each feature of the training samples to characterize the level of importance or contribution to classification following an optimization approach described by Algorithm \ref{algo:algo2}. 

% \begin{algorithm}
% \caption{Optimal Network Construction Using Genetic Algorithms}
% \label{algo:algo2}
% \textbf{Building Complex Networks}
% \begin{itemize}
%     \item Consider a training dataset $X_c = \{\textbf{x}_1^{c}, \textbf{x}_2^{c}, ..., \textbf{x}_{n_c}^{c}\}$, where $n_c$ is the number of data samples in class $c$, $c = 1, 2, .., l$ is the class index and the number of classes is $l$. The $i$th data sample of class $c$ is a $m$-dimensional vector $\textbf{x}_i^c = [{x_i_1}^c, {x_i_2}^c, ..., {x_i_m}^c]^T$, where ${x_i_j}^c$ is the $j$th attribute of the $i$th data sample of class $c$. In order to make feature selection and, consequently, construct the optimal network for each class of the training set, we put a different weight to each feature of the data sample, i.e., $\textbf{x}_i^c = [w_1 {x_i_1}^c, w_2 {x_i_2}^c, ..., w_m {x_i_m}^c]^T$, where ${w_j}$ is the weight of the $j$th data element ${x_i_j}^c$. This step is similar to Alg. \ref{algo:algo1}, but considering a weight vector representing the relevance of the feature. In the previous algorithms, all the weight values are 1.
% \end{itemize}
% \textbf{Finding the relevance of features by Genetic Algorithm}
% \begin{itemize}
%     \item Divide the training set into two subsets, one continues be the training set $X_{training}$ and another is the validation set $X_{validation}$. 
%     \item Randomly generate $N$ weight vectors, $W = \{W_1, W_2, ..., W_N \}$, where each element of the weight vector $W_i$ is $w_j \in [0, 1]$. The set of weight vectors $W$ is the initial population of the Genetic Algorithm.  
%     \item Use each weight vector $W_i$ together with the feature vectors of the training set to construct a network for each class of the data using Alg. \ref{algo:algo1}. 
%     \item Perform the classification task on the validation set $X_{validation}$ using Alg. \ref{algo:algo1}. 
%     \item The fitness function is the classification accuracy of the high-level technique on the validation set $X_{validation}$. 
    
%     \textbf{WHILE} (stopping criteria not met)
%     \begin{itemize}
%     \item Randomly select parents for reproduction from the individuals (weight vectors), which lead to the highest classification accuracy.
%     \item Perform crossover to create offspring.
%     \item Apply mutation to some offspring.
%     \item Use each weight vector $W_i$ of the offspring together with the feature vectors of the training set to construct a network for each class of the data using Alg. \ref{algo:algo1}. 
%     \item Perform the classification task on the validation set $X_{validation}$ using Alg. \ref{algo:algo1}. 
%     \item Evaluate the fitness of the new offspring by simply calculating the classification accuracy on the validation set.
%     \item Select individuals for the next generation
%     \item Update the population with the selected individuals
%     \end{itemize}
%     \item After finish the iterations, pick the best individual (weight vector).
% \end{itemize}
% \end{algorithm}

% The search of the weights related to feature importance will be done using using Alg. \ref{algo:algo2}. According to PYGAD \cite{gad2021pygad} (python package with Genetic Algorithms), the following parameter values are used in our study: 

% \begin{itemize}
%     \item $number\_generation$: 50, $size\_population$: 20
%     \item $crossover\_rate$: 0.8, $mutation\_rate$: 0.2
% \end{itemize}


%The objective is to maximize the metric (accuracy) of the proposal.

%\begin{equation}
%max \quad F(x) = w_1 * feat_1 + w_2 * feat_2 + \ldots + w_n * feat_n
%\label{eq:fx}
%\end{equation}

%Then, Euclidean distance measures between two multidimensional points is used to generate the edges between nodes. In the optimization approach, we introduce a weight into the distance measure, see Eq. \ref{eq:ed1}. Also, the weight vector will be optimized by applying a well-know genetic algorithm \cite{Whitley2012}.

%see Eq. \ref{eq:ed}. This distance is used to calculate the weight of the edges when a Complex Network is created.

%\begin{equation}
%    d(x,y) = \sum_{i=0}^n \sqrt{ (x_i - y_i)^2 }
%\label{eq:ed}
%\end{equation}

% After the optimization process, we get the features' weight vector. Then, Euclidean distance measures between two multidimensional points is used to generate the edges between nodes:

% \begin{equation}
%     d(x,y) = \sum_{i=0}^n \sqrt{ w_i*(x_i - y_i)^2 }
% \label{eq:ed1}
% \end{equation}

%Therefore, following the statement about each variable or feature has a different level of relevance to the final classification task and considering Eq. \ref{eq:fx}. The optimization problem is to find these $w_i$ to maximize the performance, the accuracy. Finally, the searching of these weights is performed by applying the Genetic Algorithm. The Genetic Algorithm Optimization works in the following steps:

%\begin{itemize}
%\item Create a initial population of 10 individuals, considering dimensionality $n$.
%\item Fitness function is the accuracy of the individual.%, evaluating \ref{eq:ed}.
%\item Start generations until reach $T$ generations
%\item Crossover step is performed for exploration or global search.
%\item Mutation step for exploitation or local search
%\item After the $T$ generations the best individual is returned.
%\end{itemize}

%Therefore, after of the optimization using Genetic Algorithms can get $w_i$ to perform the classification using the proposal of complex networks.

% \textbf{Josimar, aqui você precisa descrever em detalhes o processo de otimização utilizando Algoritmo Genetico. Esse é uma contribuição do seu trabalho.}

% In this proposal, Genetic Algorithm was used to find these weights.

\subsection{Evaluation of the Network Structure}
High-level classification techniques can employ traditional complex network metrics, such as average degree, clustering coefficient, and assortativity, to characterize the data patterns of each class. During classification, only one test data item is added to the network, which is typically large. Consequently, this network measures reflect only minor and localized changes, making it challenging to assess the pattern conformity of the test data sample. Hence, a network-sensitive measure is needed. Therefore, we propose new network measures based on Minimum Spanning Tree (MST) or Single Source Shortest Path (SSSP).
%paraphrased above
%The high-level classification techniques can use traditional complex network metrics, i.e. average degree, clustering coefficient, assortativity, and others to represent the data pattern of each data class. In each classification, only one testing data item is inserted into the network and the network is usually large. Therefore, the above-mentioned network measures only present small and local changes, which makes it difficult to check the pattern conformation of the testing data sample. For this reason, a network-sensitive measure is desirable. Therefore, we propose the new network measures based on MST or SSSP. 


\subsubsection{Minimum Spaning Tree (MST)}
%An undirected graph $G = (V, E)$, where $V$ are the vertexes and $E$ are the edges which connect vertexes $(u,v)$ in $E$. There is an associated cost for each edge, w(u,v). The Minimum Spanning Tree (MST) is defined by a path that connects all the vertexes where the total weight is minimized, having no cycles \cite{cormenbook}.

An undirected graph $G = (V, E)$ consists of a set of vertices 
$V$ and edges $E$, where each edge  $(u,v) \in E$ connects two vertices, $u$ and $v$. Each edge has an associated weight 
$w(u,v)$. A Minimum Spanning Tree (MST) is a subset of the edges that connects all the vertices with the minimum total weight, without forming any cycles \cite{cormenbook}.


\begin{equation}
    w(G) = \sum_{(u,v) \in V} w(u,v)
\end{equation}

%The MST represents the shortest path to minimally join all the nodes and many edges of the original network do not present in MST. The MST metric not only can represent the structure of each class network but also present larger variations before and after the insertion of the testing sample.

The MST provides the shortest path to minimally connect all nodes. Many edges from the original graph may not appear in the MST. Additionally, the MST metric can capture the network structure of each class and demonstrate significant changes before and after introducing a test sample.

\subsubsection{Single Source Shortest Path (SSSP)}
An undirected (also directed) graph $G = (V, E)$, where $V$ are the vertexes. Two vertexes, $v_1$ and $v_2$ are connected by edge $E_{(1,2)}$  and there is a associated cost for each edge $w_{(1,2)}$. A particular vertex, $v_s$ is defined as a source vertex.

The shortest path from source $v_s$ to a destination vertext $v_d$ is the path $P_(s,d) = (v_1, v_2, ..., v_n)$, where $v1 = v_s$ and $v_n = v_d$ over all possible $n$, minimizes the sum:
\begin{equation}
    P_{s,d} = \sum_{(i,j) \in n, \;  i \neq j} w(u,v)
\end{equation}

In another words, the Single Source Shortest Path from the source vertex, $v_s$ to all the other vertex, where the sum, $w(G)$ of all the paths is minimized \cite{SSSP}.

Similar to MST, SSSP forms a tree if the graph is connected, where many edges of the original network are not present in SSSP.  For each network, we do not have a defined source node, therefore, we calculated the centroid \cite{Centroid} of the graph. This centroid was defined as a source node to calculate the SSSP for each network. Like MST metric, SSSP can not only represent the structure of each class network but is also utilized to calculate the variation before and after the insertion of the testing sample.

\subsection{Implementation and Running-time of the Network Measures} \label{complexity}
In the implementation of the Minimum Spanning Tree, we have utilized Kruskal's algorithm\cite{MST}. This greedy algorithm first sorts the edges of the graph and maintains a disjoint-set data structure \cite{disjoint} to detect the cycle. If the graph $G(V,E)$ has $E$ edges, the running time to sort the edges with a comparison sort is $O(E \log {}E)$. The implementation of disjoint-set data structure uses Inverse Ackermann Function \cite{Ackermann}, which typically grows very slowly and the running time is amortized constant (i.e. $O(1)$) for each operation. Since there can be total $E$ edges that need to be checked for cycle detection using disjoint-set data structures, the running time to maintain the data structure is $O(E)$. The running time for Kruskal's Algorithm is dominated by the sorting; therefore, the complexity of the overall algorithm is $O(E \log {}E)$.

The Implementation of the Single Source Shortest Path uses Dijkstra's algorithm \cite{SSSP}. In Dijkstra's algorithm, we have used min-priority queue data structure \cite{pq} for storing and querying partial solutions sorted by weight from the source. The running time depends upon the cost of maintaining the priority queue. For an undirected graph $G = (V, E)$, 
the priority queue in our implementation can hold a maximum of $V$ edges for each vertex. Therefore, the cost of both search and insert in the priority queue is at most $O(\log {}V)$. Since we need to perform insert/serach for at most $E$ edges, the overall running time of SSSP for our implementation is $O(E \log {}V)$.

Note that, the running time of MST is $O(E \log {}E)$, while for SSSP it is $O(E \log {}V)$. However, the $O(E \log {}E)$  running time of MST can be reduced to $O(E \log {} V^2)$ for a complete graph, which is $2  \cdot O( E \log {}V)$. As a result, the MST might run slower than SSSP in practice, even though the theoretical running time of both MST and SSSP is $O( E \log {}V)$.





\subsection{Classification} \label{classification}

% \textbf{Josimar, aqui precisa descrever como um testing sample é inserido em cada rede. Ou seja, descreve o critério de inserção}
%Once the network of each class is constructed, we calculate the suitable network measure to represent the pattern of each class. These quantities are denoted as $G_{before} (class_i)$, $i = 1, 2, ... M$, where $M$ is the number of classes.  

After constructing the network for each class, we compute an appropriate network measure to represent the pattern of each class. These values are labeled as $G_{before}(class_x)$, for $x = 1, 2, ... M$, where $M$ is the total number of classes.

%In the classification stage, we insert a testing sample into each class network. The insertion follows the next steps:
In the classification phase, a test sample is introduced into each class network through the following steps:

% An insertion to one Complex Network follows the next steps:
\begin{itemize}
    \item Retrieve the adjacency matrix of the complex network for each class.
    \item Calculate the distance between the inserted test sample and all existing samples in the class.
    \item Update the adjacency matrix to include the new sample.
\end{itemize}

%After insertion of a testing sample, the same network measure, $G_{after} (class_i)$, $i = 1, 2, ..., M$ is calculated and compared to the measure (MST or SSSP) of each network (each class) before the insertion, $G_{before} (class_i)$. Now, we have the impact of the insertion of the new sample to each class, given by,

After the test sample is inserted, the same network measure, $G_{after}(class_x)$, for $x = 1, 2, ..., M$, is computed and compared with the original measure ( MST or SSSP) before the insertion (denoted as $G_{before}(class_x)$) for each class of the network. This comparison shows the effect of adding the new sample to each class, represented as:
\begin{equation}
\begin{split}
\Delta G (class_x) = || G_{before} (class_x) - G_{after} (class_x) ||\,, \; \\
x = 1,2, ..., M.
\end{split}
\label{eq:network_perturbation}
\end{equation}

%Finally, the new sample is classified to class $j$, where 
Finally, the test sample is classified into the class $y$, where:


\begin{equation}
\Delta G (class_y) = min \{\Delta G (class_x) \}\,, \; x = 1,2, ..., M.
\label{eq:min_perturbation}
\end{equation}

%Specifically, we check the variation of the MST or SSSP metric $w(G)$ before and after the insertion of the testing sample to each class network. The classification is made by the pattern conformation rule, i.e., the testing sample will be classified to that class where it's insertion produces the smallest variation of the $w(G)$.


Specifically, the change in the MST or SSSP metric, $w(G)$, is observed before and after the test sample is added to each class network. The classification is based on the pattern-matching rule, meaning the test sample will be assigned to the class where its insertion results in the smallest change in $w(G)$.


%And additional step to improve the global performance is the optimization of the structure, explained in the next subsection.

\section{Experimental Evaluations  } \label{experiment}
In this section, we present the experimental results by applying the MST and SSSP techniques to the synthetic and real datasets.

\subsection{Sensitivity of Metric}

Our earlier work \cite{paperjecs} provides a baseline experiment using only MST to test the sensitivity of traditional metrics like clustering coefficient,  assortativity. It demonstrated that MST is sensitive to changes in the network structure.  In this work, the experiments are further extended to provide a comparable view of sensitivity for both MST and SSSP.  This will help us to understand how sensitive SSSP is to the change of the network structure compared to the MST and other measures.  

%Besides, was presented MST could be sensitive what we are looking.
In our experiments, we have utilized two datasets: (1) an artificial dataset using normal distribution and (2) iris \cite{iris} and wine \cite{wine} dataset. 

% Initially, an experiment is performed an comparative analysis on the sensitivity of traditional metrics together with the MST and SSSP  metric. Specifically, we will compare the clustering coefficient, the assortativity, and the proposed MST and SSSP metric. We used two datasets: (1) artificial dataset using  normal distribution and (2) iris and wine dataset. 

 

\subsubsection{Artificial dataset with normal distribution}

The samples are generated using the normal distribution, by utilizing the following Eq. \ref{normal_distribution}.

\begin{equation}
    f(x) = \frac{1}{\sigma \sqrt{2\pi}} \exp\left(-\frac{(x - \mu)^2}{2\sigma^2}\right)
\label{normal_distribution}
\end{equation}
where:
\begin{align*}
f(x) & \text{ is the probability density function.} \\
x & \text{ is the value of the random variable.} \\
\mu & \text{ is the mean of the distribution.} \\
\sigma & \text{ is the standard deviation of the distribution.}
\end{align*}

A generated dataset of two classes with normal distribution each is shown by Fig. \ref{fig:4_twoblobs}, and the parameter values are: 

\begin{itemize}
    \item First class: $\mu$ = [1,1], $\sigma$ = [0.5, 0.5]
    \item Second class: $\mu$ = [5,5], $\sigma$ = [0.4, 0.4]
\end{itemize}

\begin{figure}[H]
  \centerline{
  \includegraphics[width = 0.6\columnwidth]{graphics/artificial_dataset.pdf}
  }
\caption{Synthetic dataset following a Normal Distribution with two classes, 50 samples}
\label{fig:4_twoblobs}
\end{figure}

The result of the the insertion of 5 samples belonging to the same and different classes, is presented in Fig. \ref{fig:4_artdat_mst}. This provides insight into the performance of the proposal using MST (Fig. \ref{fig:mst-normal}) and SSSP (Fig. \ref{fig:sssp-normal}), indicating that sensitivity is required for future classification tasks.

\begin{figure}[ht]%\centering
\captionsetup{justification=centering}
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=\hsize]
        {graphics/comparison_mst_artificial_dataset.pdf}
        \caption{Boxplot of MST Distances for Insertion of Same/Different Elements}
        \label{fig:mst-normal}
    \end{subfigure}
\hfill%\hfil
    \begin{subfigure}{0.45\textwidth}
    \includegraphics[width=\hsize]
    {graphics/comparison_ssp_artificial_dataset.pdf}
        \caption{Boxplot of SSSP Distances for Insertion of Same/Different Elements}
    \label{fig:sssp-normal}
\end{subfigure}
    \caption{Sensitivity experiment for MST and SSSP using synthetic dataset generated with Normal Distribution}
    \label{fig:4_artdat_mst}
\end{figure}

% Later, the analysis aimed to investigate whether the assortativity and clustering coefficient of these networks change before and after the insertion of elements.
% Considering, we employed fully connected complex networks to represent the structural characteristics of each class. 

% Figure \ref{fig:4_traditionarl_metrics} provides a visual representation of the results obtained from the application of traditional measures to complex networks.

% \begin{figure}[h]
%   \centering
%   \includegraphics[width=0.8\columnwidth]{graphics/comparison_metrics1.pdf}
%   \caption{Results with Traditional Measures of Complex Networks}
%   \label{fig:4_traditionarl_metrics}
% \end{figure}

The findings from this analysis allow us to evaluate how sensitive network metrics are when new elements are introduced to the class structure.

%The observations from this analysis help us assess the sensitivity of network metrics when new elements are introduced into the class structure. %Specifically, we focus on assortativity and clustering coefficient metrics to gain insights into how class-specific insertions may impact the network structure and we notice no impact in the metrics.

\pagebreak
\subsection{Iris and Wine dataset} 

In this section, the experimental results of the sensitivity measures using the MST and SSSP metrics utilizing two real dataset are performed. The results of the Iris dataset \cite{iris} are depicted in Fig. \ref{fig:4_iris_mst}, while the Wine dataset \cite{wine} is depicted in Fig. \ref{fig:4_wine_mst}. Upon analyzing these results, it is evident that both MST (Fig. \ref{fig:mst-iris} and Fig. \ref{fig:mst-wine}) and SSSP (Fig. \ref{fig:sssp-iris} and Fig. \ref{fig:sssp-wine}) measures are highly sensitive to the insertion of a test sample into a class to which it does not belong. In this scenario, the variation in the MST and SSSP measures are moderately significant. Conversely, when a test sample is inserted into the class to which it belongs, the variation is consistently small.



\begin{figure}[ht]%\centering
\captionsetup{justification=centering}
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=\hsize]
        {graphics/comparison_mst_iris.pdf}
        \caption{Boxplot of MST Distances for Insertion of Same/Different Elements}
        \label{fig:mst-iris}
    \end{subfigure}
\hfill%\hfil
    \begin{subfigure}{0.45\textwidth}
    \includegraphics[width=\hsize]
    {graphics/comparison_ssp_iris.pdf}
        \caption{Boxplot of SSSP Distances for Insertion of Same/Different Elements}
    \label{fig:sssp-iris}
\end{subfigure}
    \caption{Sensitivity experiment for MST and SSSP using Iris Dataset}
    \label{fig:4_iris_mst}
\end{figure}



% \begin{figure}[H]
%   \centerline{
%   \includegraphics[width = 0.45\columnwidth]{graphics/comparison_mst_iris.pdf}
%   \includegraphics[width = 0.45\columnwidth]{graphics/comparison_mst_iris.pdf}
  
%   }
% \caption{Results of Iris Dataset}
% \label{fig:4_iris_mst}
% \end{figure}





\begin{figure}[ht]%\centering
\captionsetup{justification=centering}
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=\hsize]
        {graphics/comparison_mst_wine.pdf}
        \caption{Boxplot of MST Distances for Insertion of Same/Different Elements}
        \label{fig:mst-wine}
    \end{subfigure}
\hfill%\hfil
    \begin{subfigure}{0.45\textwidth}
    \includegraphics[width=\hsize]
    {graphics/comparison_ssp_wine.pdf}
        \caption{Boxplot of SSSP Distances for Insertion of Same/Different Elements}
    \label{fig:sssp-wine}
\end{subfigure}
    \caption{Sensitivity experiment for MST and SSSP using Wine Dataset}
    \label{fig:4_wine_mst}
\end{figure}


% \begin{figure}[h]
%   \centerline{
%   \includegraphics[width = 0.45\columnwidth]{graphics/comparison_mst_wine.pdf}
%   \includegraphics[width = 0.45\columnwidth]{graphics/comparison_ssp_wine.pdf}  }
% \caption{Results of Wine Dataset}
% \label{fig:4_wine_mst}
% \end{figure}

Due to its high sensitivity and efficiency, both MST and SSSP measures are used to perform all the classification tasks in this work.


%The result is similar for both MST and SSSP. Therefore, in this section, we have only discussed the results using MST metric. However, the performance of the experiment is faster for SSSP; therefore, we further provided the discussion of the performance differences between SSSP and MST in the next section (Section \ref{analysis}).

% The results are presented in Fig. \ref{fig:exp_analysis1}, \ref{fig:exp_analysis2}, \ref{fig:exp_analysis3}.

% % \textbf{Josimar, qual rede e qual configuração destas simulações?}

% The experiment used the dataset magic \cite{romano2021pmlb}, a sample of 100 per class were selected randomly to have an initial dataset to calculate the initial metric, from a full connect Complex Network. 
% After a sample of 200 per class were selected, and 66.66\% were used for the insertion step to evaluate the impact of adding element of same class or not. Then, the metrics were calculated and the boxplots presented to have the variance of the values. 

% Figure \ref{fig:exp_analysis1} presents the pattern variation results using clustering coefficient metric for both classes (class 0 and class 1). The boxplot shows the distribution of the data. It is possible to notice there is no change in value after insertion of one element into the network of its class and into the network of the other class. 

% %Change name from avg clustering to Clustering Coefficient
% % http://localhost:8888/notebooks/2021/phd/ideas/Exp2-Copy2.ipynb
% \begin{figure}[H]
%   \centerline{
%   \includegraphics[width = 1.0\columnwidth]{graphics/clustering_coefficient_metric.pdf}}
% \caption{Boxplot of results after insertion, metric - Clustering Coefficient. Here, y axis represents metric values and x axis identifies the stages of the experiment.}

% % \textbf{ Josimar, descreve em mais detalhes as legendas de todas as figuras.}
% \label{fig:exp_analysis1}
% \end{figure}

% A similar scenario is presented in Figure \ref{fig:exp_analysis2}, the distribution of the pattern variation results is presented in a boxplot and no change is observed if an element is inserted into its class or the other class.

% \begin{figure}[H]
%   \centerline{
%   \includegraphics[width = 1.0\columnwidth]{graphics/assortativity_metric.pdf}}
% \caption{Boxplot of results after insertion, metric - Assortativity. Here, y axis represents metric values and x axis identifies the stages of the experiment.}
% \label{fig:exp_analysis2}
% \end{figure}

% On the other hand, Figure \ref{fig:exp_analysis3} introduces the results of using MST metric $w(T)$. A remarkable difference of the pattern variation is presented in the insertion of one element into its class and the other class.  

% \begin{figure}[H]
%   \centerline{
%   \includegraphics[width = 1.0\columnwidth]{graphics/mst_metric.pdf}}
% \caption{Boxplot of results after insertion, metric - Minimum Spanning Tree. Here, y axis represents metric values and x axis identifies the stages of the experiment.}
% \label{fig:exp_analysis3}
% \end{figure}

% It is important to highlight the efficiency to represent changes in the constructed networks by $w(T)$. In the cases of applying clustering coefficient and assortativity, the variations in the same class or in the other classes are very small because the insertion of only one element just generates local changes. On the other hand, MST metric $w(T)$ can generate larger variation before and after the insertion of a testing element. This is because the MST metric is calculated from a largely reduced portion of the edges of the original network and, in this way, few changes in the MST can generate relatively large effect. 

% \subsection{Experiment with Artificial Dataset}
% \label{subsection:artdataset}

% An artificial dataset, which consists of several groups of data with different geometric size and forms, i.e. spirals, stars. Overlapping elements are also introduced to increase the classification challenge of the proposed algorithm. A visualization of the dataset is present in Fig. \ref{fig:data7}.
% The number of classes for this dataset is 7 and there 100 elements per class.

% % \textbf{Josimar, descreve em detalhes o tamanho de cada classe, quais são os dados de treinamento e quais são os dados de teste. Além disso, mostra redes construidas. medidas basedao em MST calculadas, etc. Ou seja, apresenta em figuras e dados passo a passo o processo de treinamento de classificação}

% % An artificial dataset is creating considering some figures, i.e. spirals, stars. Besides, an overlapping is present to present challenge to the algorithms for classification tasks, see Fig. \ref{fig:data7}. This dataset have 7 classes and 100 samples per class. And a cross validation witk k=10 is performed to analyze the results.

% \begin{figure}[H]
%   \centerline{
%   \includegraphics[width = 0.5\columnwidth]{graphics/data_7_classes.png}
%   }
% \caption{Visualization of the artificial dataset (7 classes) with different forms of objects. }
% \label{fig:data7}
% \end{figure}

% A comparison is performed with classical Machine Learning algorithm, i.e. Multilayer Perceptron, Decision Tree, Logistic Regression, Gaussian Naive Bayes, Gradient, bagging, and Xgboost. The experiment is performed using a cross validation with $K = 10$. Figure \ref{fig:results7} shows that the proposed technique outperforms the other algorithms when er check the minimum values of accuracy. Besides, the accuracy median is higher and the limits of the boxplot are better. These results show the proposed technique gets good performance. 

% % \textbf{Josimar, tem como comparar com Deep Learning?}

% \begin{figure}[H]
%   \centerline{
%   \includegraphics[width = 0.75\columnwidth]{graphics/join_pd7.png}
%   }
% \caption{Classification accuracy results. In these simulations, the proposed classification technique runs without the optimization mechanism.}
% \label{fig:results7}
% \end{figure}

% Following the approach to optimize the network construction, a grid search is performed. Figure \ref{fig:results7_} shows that, after adding optimization mechanism, the proposed technique again presents the better classification accuracy and, at the same time, much smaller standard deviation among different runs. This justifies that each attribute contributes to the classification in different levels. 

% \begin{figure}[H]
%   \centerline{
%   \includegraphics[width = 0.75\columnwidth]{graphics/join_pd7_opt.png}
%   }
% \caption{Classification accuracy results. In these simulations, the optimization mechanism is incorporated into the proposed classification technique.}
% \label{fig:results7_}
% \end{figure}


% \subsection{Experiment with Real Dataset}
% \label{subsection:datasets}

% Now we do simulations on some baseline artificial datasets. The chosen dataset are available in \cite{romano2021pmlb}. We select the following datasets: magic, satimage, sleep and phoneme and a brief description of the selected datasets is present in Tab. \ref{datasets}. 

% % \clearpage

% \begin{table}[!h]
% \centering
% \begin{tabular}{|c|c|c|c|}
% \hline
% \multicolumn{4}{|c|}{\textbf{Dataset PMLB}}                                                                                                         \\ \hline
% \textbf{Name} & \textbf{Samples Class}                                                                      & \textbf{Variables} & \textbf{Classes} \\ \hline
% magic         & 0: 12332, 1: 6688                                                                           & 10                 & 2                \\ \hline
% satimage      & \begin{tabular}[c]{@{}c@{}}1: 1533, 2: 703, 3: 1358,\\  4: 626, 5 707, 7: 1508\end{tabular} & 36                 & 7                \\ \hline
% sleep         & \begin{tabular}[c]{@{}c@{}}0: 21359,1: 9052,2: 52698,\\ 3: 10832,5: 11967\end{tabular}      & 13                 & 5                \\ \hline
% phoneme       & 0: 3818, 1: 586                                                                             & 5                  & 2                \\ \hline
% \end{tabular}     
% \caption{Dataset description.}
% \label{datasets}
% \end{table}

% After the experiments using a cross validation of k=10, the results are presented in Fig \ref{fig:results_}. The proposed technique without optimization is named $Proposal$ and with optimization is $PropOpt$.

% \begin{figure}[hbpt]
%   \centerline{
%   \includegraphics[width = 1.0\columnwidth]{graphics/results_.pdf}
%   }
% \caption{Classification accuracy results.}
% \label{fig:results_}
% \end{figure}

% The weights found by the optimization procedure for each dataset are presented in Figure \ref{fig:results_weights_ga}:
% % \begin{itemize}
% %     \item magic: 0.408, 0.872, 0.248, 0.899, 0.691, 0.913, 0.359, 0.0869, 0.783, 0.823
% %     \item satimage: 0.0998, 0.186, 0.566, 0.63, 0.517, 0.445, 0.155, 0.167, 0.394, 0.0776, 0.326, 0.532, 0.285, 0.816, 0.733, 0.232, 0.803, 0.821, 0.743, 0.682, 0.169, 0.422, 0.017, 0.906, 0.851, 0.269, 0.102, 0.511, 0.649, 0.657, 0.745, 0.0268, 0.586, 0.984, 0.668, 0.403
% %     \item sleep: 0.603, 0.614, 0.711, 0.107, 0.914, 0.965, 0.23, 0.578, 0.0801, 0.711, 0.0342, 0.244, 0.792
% %     \item phoneme: 0.47, 0.208, 0.381, 0.974, 0.0497
% % \end{itemize}

% \begin{figure}[H]
%   \centerline{
%   \includegraphics[width = 1.0\columnwidth]{graphics/factors_dataset.pdf}
%   }
% \caption{Weights results after Optimization}
% \label{fig:results_weights_ga}
% \end{figure}

% The weights can be values between zero and one, then values closer to zero mean less relevance and closer to one, otherwise. From the darkest color to the lightest one.

% %\subsection{Analysis of the results}

% The experimental results presented in this subsection show that the proposed gets the best values with satimage, phoneme datasets. Besides, the optimization approach can improve the results up to 10\%. But, with datasets: magic and sleep is in the last three last positions. In spite of these results, the optimization approach can improve them up to 10\%. 


\subsection{Performace Comparison between MST and SSSP} \label{analysis}
We have conducted 1000 experiments, considering three complex networks for both MST and SSSP measures. The execution times of the result are provided in Table \ref{results}. We have observed that the \textit{mean} execution time for MST is 2.891 milliseconds(ms) having a standard deviation of 0.633 ms (\textit{std. dev.} in the table). For SSSP, the \textit{mean} execution time is 1.131 ms, with a standard deviation of 0.449 ms. The minimum (\textit{min}), maximum (\textit{min}), and different percentiles (\textit{25\%, 50\%, \& 75\%}) are also provided in Table \ref{results}. 
 
\begin{table}[hbpt]
\caption{Performance comparison between MST and SSSP. \\ 
\label{results}}
\centering
\begin{tabular}{|r|c|c|}
\hline
              & \textbf{MST} & \textbf{SSSP} \\ 
              & \textit{time(ms)}     & \textit{time(ms)}    \\ \hline
\textbf{mean} & 2.891     & 1.131     \\ \hline
\textbf{std. dev. }  & 0.633     & 0.449     \\ \hline
\textbf{min}  & 2.314     & 0.819     \\ \hline
\textbf{max}  & 19.585     & 25.247     \\ \hline
\textbf{25\%} & 2.447     & 0.901     \\ \hline
\textbf{50\%} & 2.689     & 0.983     \\ \hline
\textbf{75\%} & 3.190     & 1.152     \\ \hline
\end{tabular}
\end{table}


The most important observation of these experiments is that the mean execution time for SSSP is approximately 2.5 times faster than the performance of MST. This significant performance difference is attributed to the different approaches of the implementation of the algorithms. Our implementation of MST uses Kruskal's algorithm, which sorts the entire network first, while SSSP uses Dijkstra's algorithm maintains a priority queue stroing the partial network. As a result, the sorting process in MST significantly impacts its overall execution time. As discuss in the Section \ref{complexity}, the actual running time of SSSP is $O( E \log {}V)$, while the running time of MST is $2  \cdot O( E \log {}V)$. Therefore, the experimental performance of 2.5 speed up of the SSSP compared with MST matches with running time of the implementations provided in Section \ref{complexity}.


\pagebreak
\section{Performance Evaluation of Real-world Applications} \label{applicaiotn}


This section provides the performance evaluations of our network-based classification techniques compared with the traditional machine learning algorithms by utilizing three real-world application datasets. We have compared both the MST and SSSP measures with machine learning algorithms such as  Multilayer Perceptron (MLP) \cite{MLP}, Decision Tree\cite{decision_tree},  Logistic Regression \cite{logistic_regression}, Gaussian Naive Bayes \cite{naive}, Gradient Boosting
  \cite{gradient_descent}, Bootstrap Aggregating (a.k.a Bagging) \cite{bagging}, and Xgboost \cite{XGBoost}. 

The datasets were drawn from the real-world applications utilizing the Penguine Classification dataset \cite{penguin}, Pulser Star Detection Classification dataset \cite{pulsar}, and the COVID-19 Computed Tomography (CT) scan classification dataset \cite{covid}. For the experiment, we have used a cross-validation of K=10.

\subsection{Penguin Classification}
%%Added

The Palmer Archipelago (Antarctica) Penguin Dataset \cite{penguin} was collected and made available by Dr. Kristen Gorman and the Palmer Station, Antarctica (a member of the Long Term Ecological Research Network). 
The dataset is widely used for ecological and biological research and includes detailed measurements and observations on three species of penguins: Adélie, Chinstrap, and Gentoo. The dataset consists of $344$ observations having $8$ variables. Each observation represents a single penguin, and the variables are described as follows:
\begin{table}[htbp]
\caption{Descriptions of the Penguin dataset.} \label{penguin}
\centering
\small
%\scriptsize
\begin{tabular}{|r|l|}
\hline
\textbf{\normalsize{Variable}} & \textbf{\normalsize{Description}} \\ \hline
\textbf{species} & The species of the penguin (\textit{Adelie}, \textit{Chinstrap}, or \textit{Gentoo}) \\  \hline
\textbf{island} & Location of the penguin (\textit{Biscoe}, \textit{Dream}, or \textit{Torgersen}) \\  \hline
\textbf{bill\_length\_mm} & The length of the penguin's bill in millimeters \\  \hline
\textbf{bill\_depth\_mm} & The depth of the penguin's bill in millimeters \\  \hline
\textbf{flipper\_length\_mm} & The length of the penguin's flipper in millimeters \\  \hline
\textbf{body\_mass\_g} & The body mass of the penguin in grams \\  \hline
\textbf{sex} & The sex of the penguin (\textit{male} or \textit{female}) \\  \hline
\textbf{year} & The year the observation was recorded (2007 or 2008) \\  \hline
\end{tabular}
\end{table}


% 
%https://www.kaggle.com/datasets/parulpandey/palmer-archipelago-antarctica-penguin-data
%https://www.kaggle.com/code/parulpandey/penguin-dataset-the-new-iris
We have classified the data for the three classes for each species using MST, SSSP, and different machine learning techniques. The results of the classifications using these approaches are depicted in Fig. \ref{fig:penguin}. 

\begin{figure}[hbpt]
  \centerline{
  \includegraphics[width = 1.0\columnwidth]{graphics/boxplot_penguins.pdf}
  }
\caption{Classification accuracy results of  Penguin dataset.}
\label{fig:penguin}
\end{figure}


From the result, it is evident that for all the algorithms the accuracy median is equal to or higher than 0.95; therefore, all algorithms perform well for the Penguin dataset. The accuracy median of SSSP provides comparable performance having a comparable standard deviation to the ML algorithms (e.g., Xgboost, Gaussian-NB), and MST approaches. Furthermore, the MST provides equivalent performance to traditional machine learning algorithms.





% \subsection{Pima Indians Diabetes Database}

% https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database

% \begin{figure}[hbpt]
%   \centerline{
%   \includegraphics[width = 1.0\columnwidth]{graphics/boxplot_diabetes.pdf}
%   }
% \caption{Experimental result of diabetes dataset.}
% \label{fig:dataset1}
% \end{figure}

\subsection{Pulsar Star Detection}
Pulsars are rotating neutron stars, characterized by intense magnetic fields, which are swiftly spinning to emit electromagnetic radiation in concentrated beams. These emissions are displayed as recurring pulses across different wavelengths. Identifying pulsars from large amounts of data has significant importance in the field of radio astronomy. The High Time Resolution Universe survey dataset, version 2 (HTRU2) \cite{pulsar}, consists of collection of pulsar candidate and non-pulsar candidate examples. The dataset was contributed to the University of California, Irvine's machine learning repository by Dr. Robert Lyon et al. of The University of Manchester. 

The dataset consists of 17,898 examples, including both pulsar and non-pulsar instances. The dataset consists of 9 features that can be classified as two classes: 

\begin{table}[htbp]
\caption{Descriptions of the Pulsar Dataset(HTRU2). \\\label{htru}}
\centering
\small
%\scriptsize
\begin{tabular}{|r|l|}
\hline
\textbf{\normalsize{Variable}} & \textbf{\normalsize{Description}} \\ \hline
\textbf{Mean Profile} & The mean of the integrated pulse profile \\  \hline
\textbf{Standard Deviation Profile} &  Standard deviation of integrated pulse profile \\  \hline
\textbf{Excess Kurtosis Profile} & Excess kurtosis of integrated pulse profile \\  \hline
\textbf{Skewness Profile} & The skewness of the integrated pulse profile. \\  \hline
\textbf{Mean Curve} & The mean of the DM-SNR curve. \\  \hline
\textbf{Standard Deviation Curve} & The standard deviation of the DM-SNR curve. \\  \hline
\textbf{Excess Kurtosis Curve} & The excess kurtosis of the DM-SNR curve. \\  \hline
\textbf{Skewness Curve} & The skewness of the DM-SNR curve. \\  \hline
\textbf{Class Label} & Variable indicating class of a pulsar. \\  \hline
\end{tabular}
\end{table}

\pagebreak


% \textbf{Features:}
% \begin{enumerate}
% \item \textbf{Mean Profile:} The mean of the integrated pulse profile.
% \item \textbf{Standard Deviation Profile:} The standard deviation of the integrated pulse profile.
% \item \textbf{Excess Kurtosis Profile:} The excess kurtosis of the integrated pulse profile.
% \item \textbf{Skewness Profile:} The skewness of the integrated pulse profile.
% \item \textbf{Mean Curve:} The mean of the DM-SNR curve.
% \item \textbf{Standard Deviation Curve:} The standard deviation of the DM-SNR curve.
% \item \textbf{Excess Kurtosis Curve:} The excess kurtosis of the DM-SNR curve.
% \item \textbf{Skewness Curve:} The skewness of the DM-SNR curve.
% \item \textbf{Class Label:} The target variable indicating whether the example is a pulsar (positive class) or not (negative class).
% \end{enumerate}


The dataset is commonly used for binary classification tasks to distinguish between pulsar and non-pulsar examples.  Novel algorithms from the fields of machine learning and astronomy utilize this dataset to evaluate its performance. The result of the classification of the HTRU2 dataset using MST, SSSP, and different machine learning techniques are depicted in Fig. \ref{fig:HTRU}. 



%Added

% https://archive.ics.uci.edu/dataset/372/htru2


\begin{figure}[hbpt]
  \centerline{
  \includegraphics[width = 1.0\columnwidth]{graphics/boxplot_htru2.pdf}
  }
\caption{Classification accuracy results of Pulsar Star Dataset(HTRU2).}
\label{fig:HTRU}
\end{figure}


From the result, it is evident that the accuracy median of all the algorithms has a accuracy median of 0.9 or higher except MST. While MST still has a good accuracy of 0.85, SSSP still performs better with a precison median of 0.9. Furthermore, SSSP provides comparable performance to other machine learning algorithms (e.g., Xgboost, Gaussian-NB).




%Considering the results presented in the graphic Fig. \ref{fig:HTRU}, it is possible to notice that median of SSP is doing well, better than MST approach and close to the other algorithms.


\subsection{Covid-19 Classification}

Medical imagine techniques such as Chest X-ray and computed tomography scan (CT-scan) are important methods for the diagnosis of pulmonary diseases such as COVID-19. While the results can be interpreted and classified by the medical personal to identify the diseases, automated classification problems can also be effectively utilized without human intervention. In this work, we have utilized real-world COVID-19 CT-Scan images \cite{covid} for the proposed network-based classification techniques to classify the diseases.

The dataset consists of  50 images for each class, which made the dataset balanced. For illustrative purposes, 16 samples for each positive and negative case are presented in Fig. \ref{fig:dataset1}.

\begin{figure}[hbpt]
  \centerline{
  \includegraphics[width = 1.0\columnwidth]{graphics/sample.png}
  }
\caption{Dataset samples of SARS-COV-2 Ct-Scan Dataset \cite{covid}.}
\label{fig:dataset1}
\end{figure}


Feature extraction is carried out using the Gray Level Co-occurrence Matrix (GLCM) to obtain image patterns \cite{Mall2019}, \cite{Singh2017}. A total of $40$ features based on GLCM are extracted, and two classes are considered.

%pagaphrased
%The feature extraction step is performed using GLCM (Gray Level Co-occurrence Matrix) to get patterns of the images \cite{Mall2019}, \cite{Singh2017}. A total of $40$ features based on the GLCM are extracted and two classes are considered.

The result of the classification of the dataset using MST, SSSP, and different machine learning techniques are depicted in Fig. \ref{fig:covid}. 

\begin{figure}[hbpt]
  \centerline{
  \includegraphics[width = 1.0\columnwidth]{graphics/boxplot_covid19.pdf}
  }
\caption{Classification accuracy results of Covid-19 dataset.}
\label{fig:covid}
\end{figure}

\pagebreak

%Figure 6 shows that the proposed technique outperforms the other algorithms when er check the minimum values of pre- cision. Besides, the precision median is higher and the limits of the boxplot are better. These results show the proposed technique gets good performance.


%the proposed technique again presents the better classification precision and, at the same time, much smaller standard deviation among different runs. This justifies that each attribute contributes to the classification in different levels.


It is evident from the result that the accuracy median of SSSP has a comparable performance with the machine learning algorithms (e.g., Xgboost, Gaussian-NB, etc). Similarly, the MST also demonstrates competitive performance compared to the machine learning algorithms.


%it is possible to notice that median of SSSP is doing well similar with the other machine learnging algorithms but the mininum is lower than the others.

% \subsection{Snoring Classification}

% Snoring is a breathing disorder during the stage of sleeping of the people. During, having a good quality of sleep is important to maintain health body. Therefore, snoring can interfere with the quality of sleep, who snores and who is next to the snorer and can create mental, physical problems.
% The dataset \cite{Khan2019} for this experiments is a set of 500 audio files of snoring and 500 of audio with no snoring.

% Feature extraction is performed using MFCC (Mel-Frequency Cepstral Coefficients), considering previous related works \cite{Sreeram2020}, \cite{Rahmandani2018}.  A total of 20 features are extracted and two classes are considered.

% The results are presented in Fig. \ref{fig:results2}. Again, the proposed technique get very good results with high classification accuracy.

% \begin{figure}[hbpt]
%   \centerline{
%   \includegraphics[width = 1.0\columnwidth]{graphics/boxplot_snoring.pdf}
%   }
% \caption{Signal classification accuracy results.}
% \label{fig:results2}
% \end{figure}

% Considering the results presented in the graphic Fig. \ref{fig:dataset1}, it is possible to notice that median of SSP is doing well, closely to Xgboost, Gaussian-NB and closely to MST approach.

\section{Conclusion}
In this work, we presented two distinct network-based classification techniques using the Minimum Spanning Tree (MST) and Single Source Shortest Path (SSSP). Both techniques describe the data patterns represented by the network constructed for each class. 

Performance evaluations using synthetic and empirical datasets demonstrate that incorporating MST and SSP measures provides higher sensitivity to the data pattern formation, leading to improved classification outcomes. 

We also provided the execution times of implementations of our approaches. Through complexity analysis and experimental evaluation, we confirmed that the SSSP method outperforms the MST approach in terms of performance. For some datasets, the accuracy of SSSP was also observed better compared to MST for accuracy; therefore, SSSP is demonstrated to be a more competitive algorithm than MST.

Finally, we applied the proposed techniques to datasets from three real-world application scenarios. The algorithms have demonstrated comparable performance with the contemporary machine learning classification algorithms having the enhanced features of capturing complex network attributes.

%In this work, we have presented two different network-based classification techniques using the Minimum Spanning Tree (MST) and Single Source Shortest Path (SSSP) measures to characterize the data pattern represented by the network constructed for each class. Furthermore, an optimization approach was introduced to construct suitable networks for the class from the training data. The performance evaluations demonstrate promising results compared to the synthetic and classical machine learning classification techniques. The introduction of both MST and SSP measures presents higher sensitivity to data pattern formation, which generated better classification results. The proposed optimization techniques can effectively improve classification accuracy as well as stability. Furthermore, we have applied the proposed network-based classification techniques to the dataset from three real-world application scenarios and demonstrated better performance compared to the contemporary machine learning classification algorithms.

\section{Future Works}
In future work, we plan to develop advanced classification techniques utilizing dynamic network measures based on the maximal flow of the underlying network. We believe that these dynamic measures can more accurately capture data patterns, leading to an improved classification result.

%paraphrased
%As a future work, we will develop high-level classification technique using dynamic network measures, such as the measure based on the maximal flow of the underlying network. We believe that the dynamic measure can better capture the data pattern, and consequently, produce better classification results. 

\section*{Acknowledgment}
The authors of this work would like to thank the Center for Artificial Intelligence (C4AI-USP) and the support from the São Paulo Research Foundation (FAPESP grant\# 2019/07665-4) and from the IBM Corporation. The authors also would like to thank the support from the China Branch of the BRICS Institute of Future Network.

The authors also want to mention Research4Tech, an Artificial Intelligence community of Latin American Researchers for promoting Science and collaboration in Latin American countries. %where the author's role as an integrator between Professionals, Researchers, and Technology communities is key to developing the Latin American region as a strong body.




\bibliography{sn-bibliography}
% common bib file
%% if required, the content of .bbl file can be included here once bbl is generated
%%\input sn-article.bbl


\end{document}
