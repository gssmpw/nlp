\section{Problem Formulation}\label{sec:formulation}

Most current benchmarks for language models involve choosing or generating a correct solution to a given problem. We now formalize inverse benchmarks, which test a model's ability to falsify incorrect solutions.

\subsection{Falsification by Providing Counterexamples} 
To falsify a \textit{claim} means to find \textit{a counterexample} that shows the claim is not always true.
\begin{itemize}[leftmargin=*] 
\item \textit{Claim}: A claim $\mathbb{C}$ has two parts: a set of conditions $\mathcal{H}$ and a proposition $\mathcal{P}$. The claim is true when: Given any input $x$ that meets the conditions ($\mathcal{H}(x)$ is true), then it must also make the proposition true ($\mathcal{P}(x)$ is true). We write this as $\mathcal{H}(x) \implies \mathcal{P}(x)$. 
\item \textit{Counterexample}: A counterexample to a claim $\mathbb{C}$ is an input $x^*$ that shows the claim is wrong. This means that $x^*$ follows all the rules ($\mathcal{H}(x^*)$ is true) but does not make the statement true ($\mathcal{P}(x^*)$ is false). 
\end{itemize}

\noindent \textbf{Task}. Given a claim $\mathbb{C}$ (which might be stated in natural language), the model must find a counterexample $x^*$. 

\subsection{Finding Counterexamples for Algorithms}
How to check whether a proposed counterexample $x^*$ truly invalidates the claim? This requires verifying: (i) The conditions $\mathcal{H}$ are met and, (ii) The claim $\mathcal{P}$ does not hold for the given input. As a first step, we focus on a setting where counterexamples can be automatically verified: algorithmic problem solving. Here, a solution is to be generated for a problem statement which specifies the computational task, input constraints and input-output formats, and example cases for reference. The conditions $\mathcal{H}$ and claim $\mathcal{P}$ are:
\begin{align*}
&\mathcal{H}: \textrm{The input format and constraints included in the given problem statement are satisfied.}\\ 
&\mathcal{P}: \textrm{The given code}~ \mathcal{A} ~ \textrm{solves the problem described in the statement.} \end{align*}
\noindent \textbf{Task}. The goal of the model is to find an input \( x^* \) where \( \mathcal{A} \) produces an incorrect output. A validator script verifies whether $x^*$ satisfies the input constraints $\mathcal{H}$. Then, the claim can be checked by comparing the output of \( \mathcal{A} \) to a ground-truth solution (\( \mathcal{A}^* \)), i.e., \( \mathcal{A}(x^*) \neq \mathcal{A}^*(x^*) \). 