
%% bare_jrnl.tex
%% V1.4b
%% 2015/08/26
%% by Michael Shell
%% see http://www.michaelshell.org/
%% for current contact information.
%%
%% This is a skeleton file demonstrating the use of IEEEtran.cls
%% (requires IEEEtran.cls version 1.8b or later) with an IEEE
%% journal paper.
%%
%% Support sites:
%% http://www.michaelshell.org/tex/ieeetran/
%% http://www.ctan.org/pkg/ieeetran
%% and
%% http://www.ieee.org/

%%*************************************************************************
%% Legal Notice:
%% This code is offered as-is without any warranty either expressed or
%% implied; without even the implied warranty of MERCHANTABILITY or
%% FITNESS FOR A PARTICULAR PURPOSE! 
%% User assumes all risk.
%% In no event shall the IEEE or any contributor to this code be liable for
%% any damages or losses, including, but not limited to, incidental,
%% consequential, or any other damages, resulting from the use or misuse
%% of any information contained here.
%%
%% All comments are the opinions of their respective authors and are not
%% necessarily endorsed by the IEEE.
%%
%% This work is distributed under the LaTeX Project Public License (LPPL)
%% ( http://www.latex-project.org/ ) version 1.3, and may be freely used,
%% distributed and modified. A copy of the LPPL, version 1.3, is included
%% in the base LaTeX documentation of all distributions of LaTeX released
%% 2003/12/01 or later.
%% Retain all contribution notices and credits.
%% ** Modified files should be clearly indicated as such, including  **
%% ** renaming them and changing author support contact information. **
%%*************************************************************************


% *** Authors should verify (and, if needed, correct) their LaTeX system  ***
% *** with the testflow diagnostic prior to trusting their LaTeX platform ***
% *** with production work. The IEEE's font choices and paper sizes can   ***
% *** trigger bugs that do not appear when using other class files.       ***                          ***
% The testflow support page is at:
% http://www.michaelshell.org/tex/testflow/



\documentclass[journal]{IEEEtran}
%
% If IEEEtran.cls has not been installed into the LaTeX system files,
% manually specify the path to it like:
% \documentclass[journal]{../sty/IEEEtran}
\IEEEoverridecommandlockouts                              % This command is only
                                                          % needed if you want to
                                                          % use the \thanks command
% See the \addtolength command later in the file to balance the column lengths
% on the last page of the document
\newtheorem{Example}{Example}
\newtheorem{Remark}{Remark}
\newtheorem{Corollary}{Corollary}
\newtheorem{Definition}{Definition}
\newtheorem{Problem}{Problem}
\newenvironment{Proof}{\noindent{\em Proof:\/}}{\hfill $\Box$\par}
\newtheorem{Theorem}{Theorem}
\newtheorem{Lemma}{Lemma}
\newtheorem{Conjecture}{Conjecture}
\newtheorem{Assumption}{Assumption}
\newtheorem{Condition}{Condition}
\newtheorem{Property}{Property}

\usepackage[ruled,linesnumbered]{algorithm2e}
\usepackage{verbatim}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{amsmath,bm}
\usepackage{amssymb}
%\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{cite}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{orcidlink}

\allowdisplaybreaks

\algdef{SE}[DOWHILE]{Do}{doWhile}{\algorithmicdo}[1]{\algorithmicwhile\ #1}%

\newenvironment{allowbreaks}
  {\mathactivatecomma
   \mathcode`\,=\string"8000
   \ignorespaces}
  {\ignorespacesafterend}

\newcommand{\mathactivatecomma}{%
  \begingroup\lccode`~=`\,
  \lowercase{\endgroup\edef~}{\mathchar\the\mathcode`\,\penalty0 }}

\algnewcommand{\Initialize}[1]{%
  \State \textbf{Initialize: $i \in \mathcal{V}$}
  \Statex \hspace*{\algorithmicindent}\parbox[t]{.8\linewidth}{\raggedright #1}
}

\algnewcommand{\Iteration}[1]{%
  \State \textbf{Iteration $(k\geq 0)$: $i \in \mathcal{V}$}
  \Statex \hspace*{\algorithmicindent}\parbox[t]{.8\linewidth}{\raggedright #1}
}

\algnewcommand{\Output}[1]{%
  \State \textbf{Output: $i \in \mathcal{V}$}
  \Statex \hspace*{\algorithmicindent}\parbox[t]{.8\linewidth}{\raggedright #1}
}




% Some very useful LaTeX packages include:
% (uncomment the ones you want to payload)


% *** MISC UTILITY PACKAGES ***
%
%\usepackage{ifpdf}
% Heiko Oberdiek's ifpdf.sty is very useful if you need conditional
% compilation based on whether the output is pdf or dvi.
% usage:
% \ifpdf
%   % pdf code
% \else
%   % dvi code
% \fi
% The latest version of ifpdf.sty can be obtained from:
% http://www.ctan.org/pkg/ifpdf
% Also, note that IEEEtran.cls V1.7 and later provides a builtin
% \ifCLASSINFOpdf conditional that works the same way.
% When switching from latex to pdflatex and vice-versa, the compiler may
% have to be run twice to clear warning/error messages.






% *** CITATION PACKAGES ***
%
%\usepackage{cite}
% cite.sty was written by Donald Arseneau
% V1.6 and later of IEEEtran pre-defines the format of the cite.sty package
% \cite{} output to follow that of the IEEE. payloading the cite package will
% result in citation numbers being automatically sorted and properly
% "compressed/ranged". e.g., [1], [9], [2], [7], [5], [6] without using
% cite.sty will become [1], [2], [5]--[7], [9] using cite.sty. cite.sty's
% \cite will automatically add leading space, if needed. Use cite.sty's
% noadjust option (cite.sty V3.8 and later) if you want to turn this off
% such as if a citation ever needs to be enclosed in parenthesis.
% cite.sty is already installed on most LaTeX systems. Be sure and use
% version 5.0 (2009-03-20) and later if using hyperref.sty.
% The latest version can be obtained at:
% http://www.ctan.org/pkg/cite
% The documentation is contained in the cite.sty file itself.






% *** GRAPHICS RELATED PACKAGES ***
%
\ifCLASSINFOpdf
  % \usepackage[pdftex]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../pdf/}{../jpeg/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
  % or other class option (dvipsone, dvipdf, if not using dvips). graphicx
  % will default to the driver specified in the system graphics.cfg if no
  % driver is specified.
  % \usepackage[dvips]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../eps/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.eps}
\fi
% graphicx was written by David Carlisle and Sebastian Rahtz. It is
% required if you want graphics, photos, etc. graphicx.sty is already
% installed on most LaTeX systems. The latest version and documentation
% can be obtained at: 
% http://www.ctan.org/pkg/graphicx
% Another good source of documentation is "Using Imported Graphics in
% LaTeX2e" by Keith Reckdahl which can be found at:
% http://www.ctan.org/pkg/epslatex
%
% latex, and pdflatex in dvi mode, support graphics in encapsulated
% postscript (.eps) format. pdflatex in pdf mode supports graphics
% in .pdf, .jpeg, .png and .mps (metapost) formats. Users should ensure
% that all non-photo figures use a vector format (.eps, .pdf, .mps) and
% not a bitmapped formats (.jpeg, .png). The IEEE frowns on bitmapped formats
% which can result in "jaggedy"/blurry rendering of lines and letters as
% well as large increases in file sizes.
%
% You can find documentation about the pdfTeX application at:
% http://www.tug.org/applications/pdftex





% *** MATH PACKAGES ***
%
%\usepackage{amsmath}
% A popular package from the American Mathematical Society that provides
% many useful and powerful commands for dealing with mathematics.
%
% Note that the amsmath package sets \interdisplaylinepenalty to 10000
% thus preventing page breaks from occurring within multiline equations. Use:
%\interdisplaylinepenalty=2500
% after payloading amsmath to restore such page breaks as IEEEtran.cls normally
% does. amsmath.sty is already installed on most LaTeX systems. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/pkg/amsmath





% *** SPECIALIZED LIST PACKAGES ***
%
%\usepackage{algorithmic}
% algorithmic.sty was written by Peter Williams and Rogerio Brito.
% This package provides an algorithmic environment fo describing algorithms.
% You can use the algorithmic environment in-text or within a figure
% environment to provide for a floating algorithm. Do NOT use the algorithm
% floating environment provided by algorithm.sty (by the same authors) or
% algorithm2e.sty (by Christophe Fiorio) as the IEEE does not use dedicated
% algorithm float types and packages that provide these will not provide
% correct IEEE style captions. The latest version and documentation of
% algorithmic.sty can be obtained at:
% http://www.ctan.org/pkg/algorithms
% Also of interest may be the (relatively newer and more customizable)
% algorithmicx.sty package by Szasz Janos:
% http://www.ctan.org/pkg/algorithmicx




% *** ALIGNMENT PACKAGES ***
%
%\usepackage{array}
% Frank Mittelbach's and David Carlisle's array.sty patches and improves
% the standard LaTeX2e array and tabular environments to provide better
% appearance and additional user controls. As the default LaTeX2e table
% generation code is lacking to the point of almost being broken with
% respect to the quality of the end results, all users are strongly
% advised to use an enhanced (at the very least that provided by array.sty)
% set of table tools. array.sty is already installed on most systems. The
% latest version and documentation can be obtained at:
% http://www.ctan.org/pkg/array


% IEEEtran contains the IEEEeqnarray family of commands that can be used to
% generate multiline equations as well as matrices, tables, etc., of high
% quality.




% *** SUBFIGURE PACKAGES ***
%\ifCLASSOPTIONcompsoc
%  \usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
%\else
%  \usepackage[caption=false,font=footnotesize]{subfig}
%\fi
% subfig.sty, written by Steven Douglas Cochran, is the modern replacement
% for subfigure.sty, the latter of which is no longer maintained and is
% incompatible with some LaTeX packages including fixltx2e. However,
% subfig.sty requires and automatically payloads Axel Sommerfeldt's caption.sty
% which will override IEEEtran.cls' handling of captions and this will result
% in non-IEEE style figure/table captions. To prevent this problem, be sure
% and invoke subfig.sty's "caption=false" package option (available since
% subfig.sty version 1.3, 2005/06/28) as this is will preserve IEEEtran.cls
% handling of captions.
% Note that the Computer Society format requires a larger sans serif font
% than the serif footnote size font used in traditional IEEE formatting
% and thus the need to invoke different subfig.sty package options depending
% on whether compsoc mode has been enabled.
%
% The latest version and documentation of subfig.sty can be obtained at:
% http://www.ctan.org/pkg/subfig




% *** FLOAT PACKAGES ***
%
%\usepackage{fixltx2e}
% fixltx2e, the successor to the earlier fix2col.sty, was written by
% Frank Mittelbach and David Carlisle. This package corrects a few problems
% in the LaTeX2e kernel, the most notable of which is that in current
% LaTeX2e releases, the ordering of single and double column floats is not
% guaranteed to be preserved. Thus, an unpatched LaTeX2e can allow a
% single column figure to be placed prior to an earlier double column
% figure.
% Be aware that LaTeX2e kernels dated 2015 and later have fixltx2e.sty's
% corrections already built into the system in which case a warning will
% be issued if an attempt is made to payload fixltx2e.sty as it is no longer
% needed.
% The latest version and documentation can be found at:
% http://www.ctan.org/pkg/fixltx2e


%\usepackage{stfloats}
% stfloats.sty was written by Sigitas Tolusis. This package gives LaTeX2e
% the ability to do double column floats at the bottom of the page as well
% as the top. (e.g., "\begin{figure*}[!b]" is not normally possible in
% LaTeX2e). It also provides a command:
%\fnbelowfloat
% to enable the placement of footnotes below bottom floats (the standard
% LaTeX2e kernel puts them above bottom floats). This is an invasive package
% which rewrites many portions of the LaTeX2e float routines. It may not work
% with other packages that modify the LaTeX2e float routines. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/pkg/stfloats
% Do not use the stfloats baselinefloat ability as the IEEE does not allow
% \baselineskip to stretch. Authors submitting work to the IEEE should note
% that the IEEE rarely uses double column equations and that authors should try
% to avoid such use. Do not be tempted to use the cuted.sty or midfloat.sty
% packages (also by Sigitas Tolusis) as the IEEE does not format its papers in
% such ways.
% Do not attempt to use stfloats with fixltx2e as they are incompatible.
% Instead, use Morten Hogholm'a dblfloatfix which combines the features
% of both fixltx2e and stfloats:
%
% \usepackage{dblfloatfix}
% The latest version can be found at:
% http://www.ctan.org/pkg/dblfloatfix




%\ifCLASSOPTIONcaptionsoff
%  \usepackage[nomarkers]{endfloat}
% \let\MYoriglatexcaption\caption
% \renewcommand{\caption}[2][\relax]{\MYoriglatexcaption[#2]{#2}}
%\fi
% endfloat.sty was written by James Darrell McCauley, Jeff Goldberg and 
% Axel Sommerfeldt. This package may be useful when used in conjunction with 
% IEEEtran.cls'  captionsoff option. Some IEEE journals/societies require that
% submissions have lists of figures/tables at the end of the paper and that
% figures/tables without any captions are placed on a page by themselves at
% the end of the document. If needed, the draftcls IEEEtran class option or
% \CLASSINPUTbaselinestretch interface can be used to increase the line
% spacing as well. Be sure and use the nomarkers option of endfloat to
% prevent endfloat from "marking" where the figures would have been placed
% in the text. The two hack lines of code above are a slight modification of
% that suggested by in the endfloat docs (section 8.4.1) to ensure that
% the full captions always appear in the list of figures/tables - even if
% the user used the short optional argument of \caption[]{}.
% IEEE papers do not typically make use of \caption[]'s optional argument,
% so this should not be an issue. A similar trick can be used to disable
% captions of packages such as subfig.sty that lack options to turn off
% the subcaptions:
% For subfig.sty:
% \let\MYorigsubfloat\subfloat
% \renewcommand{\subfloat}[2][\relax]{\MYorigsubfloat[]{#2}}
% However, the above trick will not work if both optional arguments of
% the \subfloat command are used. Furthermore, there needs to be a
% description of each subfigure *somewhere* and endfloat does not add
% subfigure captions to its list of figures. Thus, the best approach is to
% avoid the use of subfigure captions (many IEEE journals avoid them anyway)
% and instead reference/explain all the subfigures within the main caption.
% The latest version of endfloat.sty and its documentation can obtained at:
% http://www.ctan.org/pkg/endfloat
%
% The IEEEtran \ifCLASSOPTIONcaptionsoff conditional can also be used
% later in the document, say, to conditionally put the References on a 
% page by themselves.




% *** PDF, URL AND HYPERLINK PACKAGES ***
%
%\usepackage{url}
% url.sty was written by Donald Arseneau. It provides better support for
% handling and breaking URLs. url.sty is already installed on most LaTeX
% systems. The latest version and documentation can be obtained at:
% http://www.ctan.org/pkg/url
% Basically, \url{my_url_here}.




% *** Do not adjust lengths that control margins, column widths, etc. ***
% *** Do not use packages that alter fonts (such as pslatex).         ***
% There should be no need to do such things with IEEEtran.cls V1.6 and later.
% (Unless specifically asked to do so by the journal or conference you plan
% to submit to, of course. )


% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}


\begin{document}
%
% paper title
% Titles are generally capitalized except for words such as a, an, and, as,
% at, but, by, for, in, nor, of, on, or, the, to and up, which are usually
% not capitalized unless they are the first or last word of the title.
% Linebreaks \\ can be used within to get better formatting as desired.
% Do not put math or special symbols in the title.
% \title{A Distributed and Time-efficient Cooperative Transportation Scheme for Nonholonomic Mobile Robots with Scalable Constraints}
\title{Low-Complexity Cooperative Payload Transportation for Nonholonomic Mobile Robots Under Scalable Constraints}
%
%
% author names and IEEE memberships
% note positions of commas and nonbreaking spaces ( ~ ) LaTeX will not break
% a structure at a ~ so this keeps an author's name from being broken across
% two lines.
% use \thanks{} to gain access to the first footnote area
% a separate \thanks must be used for each paragraph as LaTeX2e's \thanks
% was not built to handle multiple paragraphs
%

\author{Renhe~Guan~\orcidlink{0000-0001-5961-4531}, Yuanzhe~Wang~\orcidlink{https://orcid.org/0000-0002-1683-4849}, Tao~Liu~\orcidlink{0000-0001-8068-8025}
        and~Yan~Wang~\orcidlink{0000-0002-8644-8791}
        %,~\IEEEmembership{Senior~Member,~IEEE}
        % <-this % stops a space
%\thanks{M. Shell was with the Department
%of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta,
%GA, 30332 USA e-mail: (see http://www.michaelshell.org/contact.html).}% <-this % stops a space
\thanks{R. Guan and Yan Wang are with the School of Mechanical Electrical Engineering and Automation, Harbin Institute of Technology Shenzhen, Shenzhen, China. (email: guanrenhe142@gmail.com; wang.yan@hit.edu.cn) (Corresponding author: Yan Wang.)% <-this % stops a space

Yuanzhe Wang is with School of Control Science and Engineering, Shandong University, Jinan, Shandong, China.

T. Liu is with the School of Automation and Intelligent Manufacturing, Southern University of Science and Technology, Shenzhen 518055, China. (email: liut6@sustech.edu.cn)}
}

% note the % following the last \IEEEmembership and also \thanks - 
% these prevent an unwanted space from occurring between the last author name
% and the end of the author line. i.e., if you had this:
% 
% \author{....lastname \thanks{...} \thanks{...} }
%                     ^------------^------------^----Do not want these spaces!
%
% a space would be appended to the last name and could cause every name on that
% line to be shifted left slightly. This is one of those "LaTeX things". For
% instance, "\textbf{A} \textbf{B}" will typeset as "A B" not "AB". To get
% "AB" then you have to do: "\textbf{A}\textbf{B}"
% \thanks is no different in this regard, so shield the last } of each \thanks
% that ends a line with a % and do not let a space in before the next \thanks.
% Spaces after \IEEEmembership other than the last one are OK (and needed) as
% you are supposed to have spaces between the names. For what it is worth,
% this is a minor point as most people would not even notice if the said evil
% space somehow managed to creep in.



% The paper headers
\markboth{IEEE Transactions on Industrial Cyber-Physical Systems}%
{Shell \MakeLowercase{\textit{et al.}}: Bare Demo of IEEEtran.cls for IEEE Journals}
% The only time the second header will appear is for the odd numbered pages
% after the title page when using the twoside option.
% 
% *** Note that you probably will NOT want to include the author's ***
% *** name in the headers of peer review papers.                   ***
% You can use \ifCLASSOPTIONpeerreview for conditional compilation here if
% you desire.




% If you want to put a publisher's ID mark on the page you can do it like
% this:
%\IEEEpubid{0000--0000/00\$00.00~\copyright~2015 IEEE}
% Remember, if you use this you must call \IEEEpubidadjcol in the second
% column for its text to clear the IEEEpubid mark.



% use for special paper notices
%\IEEEspecialpapernotice{(Invited Paper)}




% make the title area
\maketitle

% As a general rule, do not put math, special symbols or citations
% in the abstract or keywords.
\begin{abstract}
Cooperative transportation, a key aspect of logistics cyber-physical systems (CPS), is typically approached using distributed control and optimization-based methods. The distributed control methods consume less time, but poorly handle and extend to multiple constraints. Instead, optimization-based methods handle constraints effectively, but they are usually centralized, time-consuming and thus not easily scalable to numerous robots. To overcome drawbacks of both, we propose a novel cooperative transportation method for nonholonomic mobile robots by improving conventional formation control, which is distributed, has a low time-complexity and accommodates scalable constraints. The proposed control-based method is testified on a cable-suspended payload and divided into two parts, including robot trajectory generation and trajectory tracking. Unlike most time-consuming trajectory generation methods, ours can generate trajectories with only constant time-complexity, needless of global maps. As for trajectory tracking, our control-based method not only scales easily to multiple constraints as those optimization-based methods, but reduces their time-complexity from polynomial to linear. Simulations and experiments can verify the feasibility of our method.         
\end{abstract}

% Note that keywords are not normally used for peerreview papers.
\begin{IEEEkeywords}
Logistics cyber-physical system, distributed robot cooperative transportation, scalable constraints, time-efficient scheme  
\end{IEEEkeywords}
% For peer review papers, you can put extra information on the cover
% page as needed:
% \ifCLASSOPTIONpeerreview
% \begin{center} \bfseries EDICS Category: 3-BBND \end{center}
% \fi
%
% For peerreview papers, this IEEEtran command inserts a page break and
% creates the second title. It will be ignored for other modes.
\IEEEpeerreviewmaketitle
\section{Introduction}
\IEEEPARstart{R}{ecently}, logistics cyber-physical systems (CPS), particularly multi-robot cooperative transportation, have garnered increasing attention due to their advantages, such as cost reduction and enhanced productivity \cite{G.A.2009, B.L.2023, Y.L.2023, J.F.2011, W.Z.2016, P.G.2004, J.F.2008,W.W.2020,Z.W.2016, J.A.2015, J.A2.2015, D.K.2021, N.L.2020, B.E.2020, D.M.2011, F.A.2012, Y.C.2015}. In this scenario, robots are required to coordinately transport the payload from a starting place to the desired destination quickly. Typically, the robot formation is subject to numerous constraints in practical transportation, such as obstacle avoidance, inter-robot collision avoidance, velocity constraints, payload protection, nonholonomic kinematics, etc. So far, how to overcome as many constraints as possible in the shortest time has become an important issue in cooperative transportation problems. 

Most cooperative transportation algorithms are based on two frameworks, including distributed control \cite{J.F.2011, W.Z.2016, P.G.2004, J.F.2008,W.W.2020,Z.W.2016} and optimization \cite{J.A.2015, J.A2.2015, D.K.2021, N.L.2020, B.E.2020, D.M.2011, F.A.2012, Y.C.2015}. However, neither of both can accommodate scalable constraints with relatively low time-complexity. Specifically, distributed control methods \cite{J.F.2011, W.Z.2016, P.G.2004, J.F.2008,W.W.2020,Z.W.2016} scale better in the number of robots and consume less time, but do not scale easily to multiple constraints. The controllers in these papers are implemented by consuming at most linear time $O(n)$, where $n$ is the number of robots. For example, papers like \cite{W.Z.2016, Z.W.2016} adopt a pushing strategy to deliver the payload to its destination, requiring only constant time to estimate the velocity of the payload and implement the designed controller. Other papers including \cite{J.F.2011, P.G.2004, J.F.2008, W.W.2020} use a caging strategy, which requires the robot to receive velocity or position information from its neighboring robots for controller design, consuming time roughly linearly proportional to the number of robots. Besides, due to the low time consumption of controller implementation, these algorithms can easily be extended to numerous robots. For instance, authors in \cite{W.Z.2016, Z.W.2016} perform simulations with over 20 robots, while papers including \cite{J.F.2008} use 8 to 20 robots to complete transportation experiments in real time.

However, distributed control methods are weak in enforcing multiple constraints as mentioned in \cite{B.E.2020}. They are usually designed for holonomic robots with specific constraints and can not be extended to new constraints by simple modifications. Although some control methods, such as null-space approach \cite{G.A.2009}, can handle constraints in a hierarchy of priorities, they only accommodate a limited number and type of constraints, excluding velocity constraints. In contrast, optimization methods can overcome it. Papers like \cite{B.E.2020} model cooperative transportation as a multi-robot trajectory generation problem with multiple constraints and use optimization methods to solve it. Then, the transportation task is completed by robots tracking the generated trajectories. Such problem can also be solved by centralized mixed integer programming \cite{D.M.2011} and sequential convex programming \cite{F.A.2012, Y.C.2015}. However, these methods \cite{B.E.2020, D.M.2011, F.A.2012, Y.C.2015} require environment maps for global planning and consume much time, where the computation cost of \cite{F.A.2012} grows exponentially with the number of robots or constraints. Thus, they are incapable of working online and adapting to environments without prior maps.

To tackle it, some papers including \cite{J.A.2015, J.A2.2015, D.K.2021, N.L.2020} improve optimization methods to enable transportation systems to make decisions online.
Specifically, authors in \cite{J.A.2015, J.A2.2015} formulate the transportation problem as a convex optimization problem and solve it in a distributed fashion to speed up. However, these methods are still time-consuming, with each global trajectory update taking several seconds and local velocity update taking several hundred milliseconds for only three robots. In \cite{D.K.2021}, the transportation problem is solved using recently popular hierarchical
quadratic programming method (HQP) proposed by \cite{E.A.2014}. Nevertheless, HQP and similar cascade quadratic programming method in \cite{O.K.2011} are centralized, where the number of constraints and the time consumed increase polynomially with the number of robots. Furthermore, the decentralized leader-follower model predictive control method is applied to achieve cooperative transportation in \cite{N.L.2020}, where the control frequency is only 10Hz with only two robots. In general, although the time consumed by these algorithms may be acceptable in some specific cases, they are much worse than distributed control methods in terms of time-complexity.

To solve these problems, we design a cooperative transportation method for a cable-suspended payload using nonholonomic mobile robots by combining advantages of low time-complexity in distributed control with the ease of handling constraints in optimization. Our method is developed by improving the conventional distributed formation control, whose main contributions are summarized below. 
% , by combining advantages of low time complexity in distributed control with the ease of handling constraints in optimization. The whole method is proposed

\begin{itemize}
    \item Different from most transportation methods based on distributed control \cite{J.F.2011, W.Z.2016, P.G.2004, J.F.2008,W.W.2020,Z.W.2016}, our approach is easily extended to multiple constraints, through a designed multi-process control framework. Besides, velocity constraints and scalable constraints that are not addressed in null-space approach \cite{G.A.2009} are included.  
    % while retaining their advantages of low computation complexity. 
    \item Unlike most related optimization-based methods with the polynomial and exponential time-complexity \cite{J.A.2015, J.A2.2015, D.K.2021, N.L.2020, B.E.2020, D.M.2011, F.A.2012, Y.C.2015, E.A.2014, O.K.2011}, ours consumes only linear time-complexity in total with the number of robots and constraints.
    \item In contrast to those centralized offline methods relying on prior environment maps \cite{D.M.2011, F.A.2012}, ours is distributed and can react to environments without maps in real time.   
\end{itemize}

The remainder of this paper is structured as follows. Section \uppercase\expandafter{\romannumeral2} presents the constrained cooperative transportation problem and our proposed scheme, which includes trajectory generation and trajectory tracking using a leader-follower structure. Section \uppercase\expandafter{\romannumeral3} details the constant time-complexity trajectory generation methods for both the leader and followers. Section \uppercase\expandafter{\romannumeral4} discusses trajectory tracking, where followers maintain constraints with linear time-complexity. In Section \uppercase\expandafter{\romannumeral5}, numerical simulations and real experiments validate our methods. Finally, Section \uppercase\expandafter{\romannumeral6} concludes the paper.    


% formulates the discussed cooperative transportation problem and the corresponding constraints. To solve them, the navigation algorithm is first presented for the leader robot in Section \uppercase\expandafter{\romannumeral3}, so that it can guide the whole robot team to the destination safely without environment maps. Then, the expected trajectories for follower robots are generated based on relative localization results fused with data from rotating camera sensors and wheel odometry. Next, the trajectory tracking strategies for the follower robots in obstacle districts are developed, which can achieve obstacle avoidance, trajectory following and relative distance maintenance concurrently. In this way, the payload can be transported to the destination with these robots. In Section \uppercase\expandafter{\romannumeral4}, numerical simulation and real experiment are performed respectively, whose results verify the feasibility of our methods. Finally, Section \uppercase\expandafter{\romannumeral5} concludes the whole paper.


% \IEEEPARstart{R}{ecently}, there has been a rapidly growing interest in cooperative transportation, owing to its multiple benefits including reduced costs and increased productivity. In this scenario, robots are required to transport the payload from a starting place to the desired destination coordinately. To achieve it, a centralized cooperative transportation strategy is proposed for multiple mobile robots with omni-directional wheels in \cite{F.H.2019}. Several unmanned aerial vehicles (UAVs) with monocular vision and inertial sensing are applied in \cite{G.L.2017} to cooperatively accomplish transportation tasks.

% However, the majority of previous studies on cooperative transportation still encounter many problems in practical use, such as excessive reliance on UAVs without motion constraints \cite{G.L.2017, J.F.2011, M.G.2017, H.L.2018, H.K.2017} and mobile robots with omni-directional structure \cite{F.H.2019, J.A.2015, J.A2.2015}, ignorance of environment obstacles \cite{W.W.2020,F.H.2019,G.L.2017,J.F.2011,M.G.2017,J.C.2013} and maximum velocity constraints \cite{T.M.2016, E.S.2017, F.H.2019, G.H.2015, J.C.2013, G.L.2017, J.F.2011, M.G.2017, W.W.2020, H.L.2018, H.K.2017}, the need for pre-constructed maps \cite{D.K.2021} and global environment parameters obtained by pre-training \cite{H.L.2018, H.K.2017}, disregard for the limited FOV of cameras \cite{M.G.2017} and potential damages caused by improper robot relative positions \cite{G.L.2017, M.G.2017}, and dependence upon global localization systems \cite{J.A.2015, J.A2.2015, W.W.2020, H.K.2017, H.L.2018, G.H.2015, J.C.2013, E.S.2017}. These constraints, if not well overcome, will hinder the application of cooperative transportation algorithms in practice. 
% % If not well overcome, these constraints will lay detrimental impacts on transportation missions.

% The first constraint derives from the reliance on UAVs and omni-directional mobile robots, which have several drawbacks. Specifically, aerial robots such as UAVs have a relatively small payload capacity, resulting in their low transportation efficiency. Additionally, omni-directional mobile robots with customized wheels have a shorter service life and a higher price, severely limiting their practical uses. As a result, research into cooperative transportation based on nonholonomic mobile robots is required.

% However, it is very challenging to achieve cooperative transportation with nonholonomic robots under the above-mentioned constraints. As noted in \cite{S.Z.2018}, these constraints impose additional limitations on the direction and magnitude of robot velocity, making it more difficult to design. Specifically, the nonholonomic constraint requires the direction of robot velocity to coincide with its heading direction; velocity saturation requires the magnitude of robot velocity to be bounded and collision avoidance requires the direction of robot velocity away from nearby obstacles and other robots when approaching them. Besides, the payload is normally physically attached to robots in cooperative transportation methods based on grasping strategy, caging strategy and cable-based strategy as summarized in \cite{E.T.2018}. Consequently, robots should maintain appropriate relative distances to prevent the payload from being stretched or colliding with the ground, which is neglected by most related papers. Whereas, this imposes a new constraint on the direction and magnitude of robot velocity, which should be constantly adjusted to maintain the proper robot relative distances.             
% For multi-robot transportation missions, obstacle avoidance is also an important issue to research on. In real working environments, obstacles are almost ubiquitous, such as desks in the office, machines in the factory and racks in the warehouse. Undoubtedly, collisions will easily occur in these scenes under algorithms disregarding obstacle avoidance like \cite{W.W.2020}. Although some methods \cite{H.L.2018, H.K.2017} claim to prevent collisions with obstacles, they heavily depend on pre-constructed environment maps or global environment parameters for path planning attained by offline training, severely restricting their practical use. In fact, it is time-consuming and memory-intensive to create a new map or learn different parameters for each new environment, leading to demands on online cooperative transportation methods adpative to unknown obstacle environments. Similar problems are discussed in \cite{T.M.2016} using a dynamical system approach, but it is limited to two mobile robots and cannot be extended to multiple ones.

% Other constraints derive from sensing, including the absence of global localization systems and prior maps, and limited FOV of onboard cameras. Some papers including \cite{J.A.2015, J.A2.2015, W.W.2020, H.K.2017, H.L.2018, G.H.2015, J.C.2013, E.S.2017} utilize global localization systems like Vicon and OptiTrack to measure robot global positions and robot relative positions, with drawbacks such as a high cost and a limited available workspace. Although a few papers can avoid these systems, they depend on pre-constructed environment maps for global localization \cite{D.K.2021} or global environment parameters attained by offline training \cite{H.L.2018, H.K.2017} for path planning, severely restricting their practical use. It is time-consuming to create a new map or learn different environment parameters for each new environment, leading to demands on online cooperative transportation methods adaptive to unknown obstacle environments. Besides, some related papers use the global position and heading angle of robots to linearize the nonholonomic model of mobile robots based on the feedback linearization technique, which may be time-consuming and costly due to the reliance on global localization systems or prior maps as in \cite{D.K.2021}. Thus, it is essential to design a cooperative transportation method that relies only on local measurements from onboard sensors like cameras and laser scanners. Normally, the camera is mounted on the follower to detect the leader and measure their relative poses, while the laser scanner is used to detect nearby obstacles. Furthermore, it needs to be addressed that the camera FOV is usually limited, which can lead to discontinuous visual measurements.

% Another point to emphasize is the relative localization between robots, which is the prerequisite for multi-robot coordination. Some papers including \cite{E.S.2017} utilize the global localization systems like Vicon and magnetic positioning to measure robot relative poses, with drawbacks such as a high cost and a limited avialable workspace. Besides, vision sensor can be mounted at the robot to recognize and localize the neighboring robots, which becomes much more popular recently due to its affordable prices and abundant features. However, it suffers from a limited FOV and cannot provide continuous visual feedback of relative poses, resulting in low localization accuracy. To solve it, a servo motor is installed under the camera so that neighbor robots are tracked actively. Sometimes, visual measurements are affected due to accidents like image blurring and occlusion. Here, wheel odometry data from robots is utilized to generate an approximate estimation of relative localization, which can be fused to overcome possible loss of detection caused by accidents.

% Furthermore, requirements from the protection of tranportation system and robot velocity constraints should be satisfied. As summarized in \cite{E.T.2018}, the payload is normally physically attached to robots under cooperative transportation methods based on grasping strategy, caging strategy and cable-based strategy. Consequently, robots should maintain appropriate relative distances to prevent the payload from being stretched or colliding, which is neglected by most related works. Additionally, there exist upper bounds on robot velocities in practice due to limited motor rotating speed, so that the designed control laws should be restricted within the bounds or capable of working under actuator saturation. Nevertheless, these constraints are ignored by most of existing works.

% To overcome above constraints, a distributed cooperative transportation method is developed for the cable-suspended payload in unknown obstacle environments. The main contribution is summarized as follows.
% \begin{itemize}
%     \item Based on nonholonomic robots with relatively longer service lives and cheaper prices, the transportation system can work in obstacle environments without global localization systems and prior maps, saving time and money, as well as broadening the range of applications.
% % 	\item In the absence of global localization systems and prior maps of obstacles, the cable-suspended payload can be automatically transported to the desired destination by multiple nonholonomic mobile robots without collisions.
% 	\item A general framework is proposed for the transportation system based on a multi-objective control approach, so that multiple practical constraints that have not been fully considered before are addressed simultaneously, including obstacle avoidance, inter-robot collision avoidance, velocity saturation and protection of the payload.
% 	\item The camera limitations in angle and depth are addressed by the designed rotation device and the control framework, respectively. 
% % 	\item A new trajectory generation and multi-objective trajectory tracking strategy are designed for follower robots in obstacle environments, based on visual feedback from the rotating camera with limited FOV.
% % % 	\item A rotation platform is designed for the follower camera with limited FOV, so that continuous visual feedback from the leader is provided for relative localization. 
% % 	\item The relative distances between robots are maintained in proper ranges, preventing the payload from being stretched or colliding with the ground. 
% % 	\item The velocities of mobile robots are bounded by the defined maximum values.
% \end{itemize}

% The remaining part of this paper is summarized in the following. Section \uppercase\expandafter{\romannumeral2} formulates the discussed cooperative transportation problem and the corresponding constraints. To solve them, the navigation algorithm is first presented for the leader robot in Section \uppercase\expandafter{\romannumeral3}, so that it can guide the whole robot team to the destination safely without environment maps. Then, the expected trajectories for follower robots are generated based on relative localization results fused with data from rotating camera sensors and wheel odometry. Next, the trajectory tracking strategies for the follower robots in obstacle districts are developed, which can achieve obstacle avoidance, trajectory following and relative distance maintenance concurrently. In this way, the payload can be transported to the destination with these robots. In Section \uppercase\expandafter{\romannumeral4}, numerical simulation and real experiment are performed respectively, whose results verify the feasibility of our methods. Finally, Section \uppercase\expandafter{\romannumeral5} concludes the whole paper.              

\section{System and Scheme Overview}\label{sec:problem_formulation}
\subsection{Structure of Cooperative Transportation System}
In this paper, a team of nonholonomic mobile robots are applied to accomplish the cooperative transportation task. For each robot $i$, the kinematics model is represented as
\begin{equation} \label{eq1}
\dot{x}_i = v_i {\rm cos}\theta_i,\;
\dot{y}_i = v_i {\rm sin}\theta_i,\;
\dot{\theta}_i = \omega_i
\end{equation} 
where $\bm{p}_i=[x_i(t),y_i(t)]^T$ is the position, $\theta_i(t) \in (-\pi,\pi]$ is the heading angle of robot $i$ with respect to the global frame $G$. The linear velocity of robot $i$ is $v_i$ and the angular velocity is $\omega_i$, while the velocity vector is $\bm{u}_i=[v_i,\omega_i]^T$. Given that most commercialized mobile robots provide velocity inputs, we do not consider the robot dynamics. 

As in Fig \ref{Transport}, the payload is raised by mobile robots with cables attached to robots at one end and to the payload at the other. Assume that the cable on each robot is fixed at height $d$, the length of cable is $l$ and the goal position is $\bm{p}_g = [x_g,y_g]^T$. The robot in the formation needs to efficiently perform two tasks in a distributed manner, including $1)$ generating a reference trajectory to $\bm{p}_g$ and $2)$ overcoming various constraints during transportation.
\begin{figure}[htbp]
\vspace{-0.45cm}
\centering
\includegraphics[width=3.2in]{Drawing2-4.pdf}  
\caption{The cooperative transportation system in obstacle environments}
\label{Transport}
\vspace{-0.3cm}
\end{figure}  

For fast trajectory generation, it is better for robots to adopt a control framework rather than a time-consuming trajectory optimization framework. To further increase efficiency, the transportation system can operate in a leader-follower configuration, with one robot in the front as the leader $l$ and the other $n_r$ robots as followers. The leader is only responsible for guiding the whole formation to $\bm{p}_g$ safely, while followers follow the leader and preserve constraints with the leader and other followers. In this way, followers can save time in trajectory generation and focus on overcoming constraints.  


Here, all robots form the set $\mathcal{R}$, all followers form $\mathcal{F}$ and the neighboring set of $i$ is $\mathcal{N}_i=\mathcal{R}\backslash \{i\}$. Each follower is equipped with a cheap monocular limited filed-of-view (FOV) camera to detect the leader and a laser scanner to detect obstacles. Without loss of generality, the origin of the global frame $G$ is selected as the initial position of the leader $l$, whose forward direction coincides with $x$ axis. The position of leader is denoted by $\bm{p}_l$, the position of the $k^{\text{th}}\,(k\le n_r)$ follower is $\bm{p}_k$ and the relative position between robots $i$ and $j$ in $i$'s local frame is ${}^i\bm{p}_j$, where $i, j\in \mathcal{R}$. We consider the transportation is roughly completed when the leader arrives $\bm{p}_g$. 

\begin{figure}[htbp]
\vspace{-0.45cm}
\centering
\includegraphics[width=3.1in]{zzzzz.pdf}  
\caption{Top view and front view of the transportation system}
\label{TransportDetails}
\vspace{-0.2cm}
\end{figure} 

To make the force on robots uniform, we set the desired relative position between robots on a circle, called the formation circle, as in Fig. \ref{TransportDetails}. Besides, the polygon formed by suspension points on the payload is similar to the polygon formed by robots, whose circumscribed circle is named as the suspension circle. As for parameters, the radius of the suspension circle and the formation circle are denoted as $R_s$ and $R_f$ respectively, while the height of payload is $h_0$. 

%  Assume that the cable on each robot is fixed at height $d$, the length of cable is $l$, the relative position between robot $i$ and $j$ is named as ${}^i\bm{p}_j$, where $i, j\in \mathcal{R}$.

\subsection{Constraints of Transportation System}
There are many constraints to be preserved during transportation. In the following, we will present some representative constraints and show how to scale up new constraints. 
\subsubsection{Payload Protection Constraints}
The payload may be stretched or collide with the ground. Assume the distance from the lowest point of payload to the ground as $h_p$ and the minimum safety height of payload as $h_{\min}$. To avoid collisions with the ground, there exists
\begin{equation} \label{eq200}
h_p=d-h_0-\sqrt{l^2-(R_f-R_s)^2}\ge h_{\min} 
\end{equation}
if we ignore the oscillation of the payload.
% Also, the robots should maintain a safety distance from one another to avoid inter-robot collisions and the payload from colliding with the ground.

To prevent the payload from being stretched, $R_f$ should satisfy $R_f \le l+R_s$. Combing Equation (\ref{eq200}), we have 
\begin{align} \label{eq2}
\begin{array}{l}
R_{\min} \le R_f \le l+R_s\\
R_{\min}=\left\{\begin{array}{l}
R_s\,(k_0> l, \text{where}\; k_0 = d-h_0-h_{\min})\\
R_s+\sqrt{l^2-k_0^2}\;(k_0\le l)
\end{array}\right.
\end{array}
\end{align} 

Thus, the robot formation can be scaled between circles of radius $R_{\min}$ to $l+R_s$, where the maximum scale ratio is defined as $r_{+}=\frac{l+R_s}{R_f}$ and the minimum scale ratio is $r_{-}=\frac{R_{\min}}{R_f}$. To restrict the formation within this annulus district and avoid collisions, the relative distance $\Vert {}^i\boldsymbol{p}_{j} \Vert$ should satisfy the constraint in Equation (\ref{eq2a}), where $\Vert {}^i\boldsymbol{p}_j^d \Vert$ is the desired relative distance in the Cartesian coordinate system. In the following, $\Vert {}^i\boldsymbol{p}_j^d \Vert$ will be replaced by an approximation $\Vert {}^i\boldsymbol{c}_j^d \Vert$, which is the desired relative distance in the curvilinear coordinate system and defined later.
\subsubsection{Individual Collision Avoidance Constraints}
% \begin{equation} \label{eq31}
% \max \{\rho_c,r_{-}\Vert {}^i\boldsymbol{p}_{j}^d \Vert\} \le \Vert {}^i\boldsymbol{p}_{j} \Vert \le \min\{c_{\max},r_{+}\Vert {}^i\boldsymbol{p}_{j}^d \Vert\}   
% \end{equation}
% where $\rho_c$ is the minimum distance to avoid inter-robot collisions, $c_{\max}$ is the maximum range of camera, $\Vert {}^i\boldsymbol{p}_j^d \Vert$ is the desired relative distance in the Cartesian coordinate system.  Then, we can define the minimum value of $\Vert {}^i\boldsymbol{p}_j^d \Vert$ as ${}^i\rho_j^{-}=\max \{\rho_c,r_{-}\Vert {}^i\boldsymbol{c}_{j}^d \Vert\}$ and the maximum value as ${}^i\rho_j^{+}=\min\{c_{\max},r_{+}\Vert {}^i\boldsymbol{c}_{j}^d \Vert\}$.   

% Assume that the initial relative distances between robots are not far away from the expected ones, we can roughly protect the payload from colliding with the ground by setting the minimum relative distance $\rho_{\min}$ as $\max\{\rho_c,2\sqrt{l^2-k_0^2}\}$ when $k_0 \le l$ and $\Vert {}^i\boldsymbol{c}_j^d \Vert$ is equal to ${}^i\boldsymbol{c}_{\max}^d$. Otherwise, the pair of robots only need to avoid inter-robot collisions and keep $\rho_{c}$ away from each other.          
%\begin{Remark}
%The varibale $h_p$ is decided by the relative positions of all mobile robots, whose exact value is hard to determine. Fortunately, we can easily obtain a lower bound of $h_p$. When there exists $d-h_0-h_{\min}> l$, we have $h_p\ge d-\sqrt{l^2-(\frac{\min\{{}^i\bm{p}_j\}}{2})^2}-h_0$, where $\min\{{}^i\bm{p}_j\}$ is the distance of the closest robot pair. Otherwise, it is $0$. With the lower bound of $h_p$, the constraints of robot relative distance are simply attained by combining with $\rho_c$ and $c_{\max}$.  
%\end{Remark} 

Each robot $i$ should keep a safety distance $d_o$ from nearby obstacles for collision avoidance as in Equation (\ref{eq2b}),
where $\rho_{io}$ is the distance between robot $i$ and its nearest obstacle, and $\mathcal{O}_i(t)$ is the obstacle measurement of robot $i$ at time $t$. Similarly, robots $i$ and $j$ should maintain at least $\rho_c$ away from each other to avoid inter-robot collisions as in Equation (\ref{eq2c}). 

\subsubsection{System Collision Avoidance Constraints}
% Unlike individual obstacle avoidance, system collision avoidance usually requires the polygon consisted of the robot formation away from obstacles, not just the robot itself. As in Fig. \ref{Obstacle}, each edge in the formation polygon needs to be a safe distance $d_c^s$ away from obstacles
In addition to robots, the cables and payload in the system should also be prevented from obstacles. As Fig. \ref{Transport} shows, they are restricted in the polygon generated by adjacent robots. If each edge $L_{ij}$ between robot $i$ and $j$ in the polygon keeps a safety distance $d_l$ away from obstacles, the system would not be damaged, represented as in Equation (\ref{eq2d}). For robot $i$, it only needs to consider collision avoidance between its two adjacent edges and obstacles and the two related robots form the set $\mathcal{Q}_i$. For example, the set $\mathcal{Q}_3$ for Follower $3$ in Fig. \ref{TransportDetails} is $\mathcal{Q}_3=\{l,2\}$. 

Besides, the function ${dist}({}^i\boldsymbol{p}_o,L_{ij}) = \frac{{}^i\boldsymbol{p}_o^TG{}^i\boldsymbol{p}_j}{\Vert G{}^i\boldsymbol{p}_j \Vert}$ is the distance from the obstacle $\boldsymbol{p}_o$ to $L_{ij}$ when ${}^i\boldsymbol{p}_o \in D_{ij}$, where ${}^i\boldsymbol{p}_o$ is the coordinate of $\boldsymbol{p}_o$ in the frame of robot $i$, $D_{ij}=\left\{q \mid\left(q-\boldsymbol{p}_{i}\right)^{T}{}^{i} \boldsymbol{p}_{j}>0,\left(q-\boldsymbol{p}_{j}\right)^{T} {}^{i} \boldsymbol{p}_{j}<0\right\}$ and the matrix $G$ is 
% $[0,-1;1,0]$. 
$\left[ \begin{array}{ccc}
0 & -1\\
1& 0
\end{array}
\right ]$.
Furthermore, $\rho_{il}$ is the smaller one of two available distances of $i$ and $d_l$ is the safety distance.   
% Thus, if the connecting line segment $L_{ij}$ of any two robots $i$ and $j$ does not intersect any nearby obstacle, the system would not be damaged, represented as 
% \begin{equation} \label{eq4}
% \rho_{il} = \min_{\boldsymbol{p} \in \mathcal{O}_i(t);j\in \mathcal{N}_i} \text{dist}(\boldsymbol{p},L_{ij}) \ge d_l
% \end{equation} 
% where $\text{dist}(\boldsymbol{p},L)$ is the distance from the point $\boldsymbol{p}$ to the line segment $L$ defined later, $\rho_{il}$ is the minimum one among all available distances related to $i$ and $d_l$ is the safety distance. 
\subsubsection{Velocity Constraints}
Due to mechanical and electrical constraints, the velocities of robot $i$ are usually bounded as in Equation (\ref{eq2e}), where $\bar v$ and $\bar \omega$ are velocity bounds.
\subsubsection{Sensor Range Constraints}
In general, cameras have a measuring range $[0,c_{\max}]$. In order for cameras on robots to observe each other's positions successfully, the distances between robots should be within $c_{\max}$ as in Equation (\ref{eq2f}).
\subsubsection{Other Scalable Constraints}
In practice, there may be other constraints on robot $i$. These constraints are usually related to velocity and position of robots and can be expressed uniformly as in Equation (\ref{eq2g}), where $\delta_i^-$ and $\delta_i^+$ are the lower and upper bounds, $f_i$ and $g_i$ are constraint functions. If the constraint is unbounded on one side, then $\delta_i^-$ is set to $-\infty$ or $\delta_i^+$ to $+\infty$. When the constraint is an equation constraint, we set $\delta_i^-$ and $\delta_i^+$ very close to each other for approximation.  

Based on above discussion, all constraints for the system can be summarized as follows. 
\begin{subequations}
\begin{align}
&r_{-}\Vert {}^i\boldsymbol{p}_{j}^d \Vert \le \Vert {}^i\boldsymbol{p}_{j} \Vert \le r_{+}\Vert {}^i\boldsymbol{p}_{j}^d \Vert \;(i\in \mathcal{F},j\in \mathcal{N}_i)\label{eq2a}\\
&\rho_{io} = \min _{\boldsymbol{p}_o \in \mathcal{O}_i(t)}\| \boldsymbol{p}_o- \boldsymbol{p}_{i}\| \ge d_o\;(i\in \mathcal{R}) \label{eq2b}\\
&\Vert {}^i\boldsymbol{p}_{j} \Vert \ge \rho_c\;(i\in \mathcal{F},j\in \mathcal{N}_i) \label{eq2c}\\
&\rho_{il} = \min_{\boldsymbol{p}_o \in \mathcal{O}_i(t);j\in \mathcal{Q}_i} \text{dist}({}^i\boldsymbol{p}_o,L_{ij}) \ge d_l \label{eq2d}\;(i\in \mathcal{F})\\
&\vert v_i \vert \le \bar v,\;\vert \omega_i \vert \le \bar \omega \;(i\in \mathcal{R})\label{eq2e}\\
&\Vert {}^i\boldsymbol{p}_{j} \Vert \le c_{\max}\;(i\in \mathcal{F},j\in \mathcal{N}_i) \label{eq2f}\\
&\delta_i^{-} \le f_i(v_i,\omega_i)+g_i(\boldsymbol{p}_i,\boldsymbol{p}_j)\le \delta_i^{+}\;(i\in \mathcal{F},j\in \mathcal{N}_i) \label{eq2g}
\end{align}
\end{subequations}
where only constraints in Equation (\ref{eq2b}), (\ref{eq2e}) are relevant for the leader navigating to $\boldsymbol{p}_g$ and other constraints related to the leader can be preserved by corresponding followers.    
\begin{Remark}
Here, we omit the motion and force analysis of the payload for the following reasons. First, accurately measuring the forces on the payload is difficult without using expensive force sensors, as some ropes may not always be under tension. Second, the current conditions account for worst-case positional scenarios, ensuring the payloads safety, making further motion analysis less necessary.
\end{Remark}

\begin{figure*}[htbp]
\centering
\includegraphics[height=1.4in]{flowchart_new.drawio-1-1.png}  
\caption{Flowchart of transportation framework, where yellow boxes represent robot process and red boxes are judgment conditions}
\label{flowchart} 
\vspace{-0.7cm}
\end{figure*}
\subsection{Problem Description}
Given the assumption that obstacles are convex and there is sufficient space for the transportation system with above constraints to pass through, we obtain the following problem. 
% Each robot in the group is equipped with a laser scanner to detect nearby obstacles, a rotating camera to recognize the leader robot and a device for inter-robot communication.
\begin{Problem} \label{prob_1}
Consider a cooperative transportation system comprised of a cable-suspended payload and several nonholonomic mobile robots under above constraints. Given a final goal position $\boldsymbol{p}_g=[x_g,y_g]^T$, we should propose distributed control strategies to achieve  
\begin{enumerate}
\item The reference trajectories to $\boldsymbol{p}_g$ can be quickly generated for robots without relying on global maps and time-consuming trajectory optimization algorithms.
\item Robots can overcome scalable constraints while tracking reference trajectories, and the time consumed is only linearly related to the number of robots and constraints.
\end{enumerate}          
\end{Problem} 
\subsection{Main Structure of Proposed Scheme}
The main structure of our proposed approach to Problem \ref{prob_1} is shown in Fig. \ref{flowchart}. As shown, the leader robot first quickly generates a trajectory towards $\boldsymbol{p}_g$, and then followers generate their own reference trajectories based on the leader's. During transportation, it is mainly the follower who is responsible for overcoming system constraints. The states of followers are divided into constraint preservation process, transition process and normal tracking process. The majority of constraints can be preserved in constraint preservation process, named as intra-process constraints. However, there are a few constraints that exist at all times and need to be protected in all processes such as velocity constraints, named as inter-process constraints.
These algorithms and processes will be described in details in the following sections. 
\section{Cooperative Trajectory Generation}
In this section, the methods of generating reference trajectory for the leader and followers are presented. Unlike other methods, ours takes only a constant amount of time $O(1)$ to complete at each sampling instant without global maps.
\begin{figure}[htbp]
\vspace{-0.2cm}
\centering
\includegraphics[width=2.4in]{transport_1.pdf}  
\caption{The diagram of leader trajectory generation}
\label{leader_graph}
\vspace{-0.8cm}
\end{figure} 
% To solve Problem \ref{prob_1}, several strategies are proposed by the following steps. To begin, a navigation law is designed for the leader to create a path to the target $\boldsymbol{p}_g$, which is collision-free and can provide sufficient space for follower robots to navigate through. Then, a trajectory generation method is proposed for each follower robot to calculate its reference path based on measurements from the rotating camera and the wheel odometry. Finally, several bounded control laws are provided for follower robots to follow the generated reference path, while complying with constraints of obstacle avoidance and safety requirements of the transportation system.
\subsection{Leader Trajectory Generation}
The leader is responsible for guiding the system to $\boldsymbol{p}_g$ and selecting a path which is spacious enough for robots to pass through. To facilitate it, followers are preferably distributed evenly on either side of the leader. With obstacle data $\mathcal{O}_l$ from the laser scanner, the trajectory generation algorithm of the leader is proposed in Algorithm \ref{algorithm_1}. As in Fig. \ref{leader_graph}, the nearest obstacle point $\boldsymbol{p}^{*}_o=[{x}^{*}_o, {y}^{*}_o]^T$ is first calculated in the leader frame with $\mathcal{O}_l$. Then, we define the distance from the leader to $\boldsymbol{p}^{*}_o$ as $\rho_{lo}=\sqrt{({x}^{*}_o)^2+({y}^{*}_o)^2}$ and the relative angle as $\alpha_{lo}=\text{atan2}(y_o^*,x_o^*)$, while $\alpha_g$ is the relative angle to the goal $\boldsymbol{p}_g$, $atan2$ is the function to calculate the arctangent value, $F$ is a flag variable to record the sign of $\dot{\rho}_{lo}$. The sign function ${sgn}(x)$ is defined as $\frac{x}{\vert x \vert}$ when $x \neq 0$, and $0$ otherwise.  

When $\rho_{lo} > d_t$, the leader is far from obstacles. It moves forward and adjusts the heading angle towards $\boldsymbol{p}_g$. The threshold $d_t$ should be large enough to cover the passage of the whole system, e.g. $d_t>R_f$. If $\rho_{lo} \le d_t$, the leader makes decisions according to $F$. When $F>0$, the leader is heading away from obstacles and it should continue moving towards $\boldsymbol{p}_g$. If $F\le 0$, a turn is performed to steer the leader away from obstacles. Specifically, it turns in the positive direction when the nearest obstacle is on the left, and in the negative direction otherwise. The linear velocity of leader is designed as ${v}_l=\varphi(\rho_{lo})\frac{}{}\tilde{v}_l$, which decreases as $\rho_{lo}$, i.e.
\begin{align} \label{eq51}
\varphi(\rho_{lo})=\left\{\begin{array}{l}
1\;(\rho_{lo}\ge d_t);\;0\;(\rho_{lo}<d_{o})\\
\frac{\rho_{lo}-d_{o}}{d_t-d_{o}}\;(d_{o} \le \rho_{lo}< d_t)
\end{array}\right.
\end{align}  
where $\tilde{v}_l$ is a constant. When approaching obstacles, it is beneficial for the leader to slow down to avoid them.

\vspace{-0.3cm}
\begin{algorithm} \label{algorithm_1}
\caption{Leader Trajectory Generation}
%\KwIn{$\boldsymbol{p}_g$, $\Delta T$ and $\mathcal{O}_l$}
\KwOut{$v_l$, $\omega_l$}
Obtain the nearest obstacle $\boldsymbol{p}^{*}_o=\text{argmin}_{\boldsymbol{p}\in \mathcal{O}_l}(\rho_{lo})$ in the local frame of the leader\; 
Calculate obstacle distance $\rho_{lo}$ and relative angle $\alpha_{lo}$\;
$\alpha_g = \operatorname{atan2}(y_g-y_l,x_g-x_l)-\theta_l$\;
$F = \text{sgn}(\hat \rho_{lo}(t+\Delta T)-\rho_{lo}(t))$, $v_l = \varphi(\rho_{lo})\frac{}{}\tilde{v}_l$\;
\uIf{$\rho_{lo} > d_t$}
{
    $\omega_l = \tilde{\omega}_l \text{sgn}(\alpha_g)$\; 

}\uElseIf{$\rho_{lo} \le d_t$ and $F>0$}
{
    $\omega_l = \tilde{\omega}_l \text{sgn}(\alpha_g)$\;
}\uElseIf{$\rho_{lo} \le d_t$, $F\le 0$ and $\alpha_{lo}<0$}
{
    $\omega_l = \tilde{\omega}_l$\;
}\ElseIf{$\rho_{lo} \le d_t$, $F\le 0$ and $\alpha_{lo}\ge 0$}
{
    $\omega_l = -\tilde{\omega}_l$\;
}
\end{algorithm}
\vspace{-0.3cm}

To obtain $F$ at time $t$, the difference between the estimation $\hat \rho_{lo}(t+\Delta T)$ and $\rho_{lo}(t)$ is applied, where $\Delta T$ is the forward prediction time. Besides, $\hat \rho_{lo}(t+\Delta T)$ is
\begin{equation} \label{eq6}
\begin{array}{l}
\hat \rho_{lo}(t+\Delta T) = \min _{\boldsymbol{p} \in \mathcal{O}_l(t)}\| \boldsymbol{p}- \hat{\boldsymbol{p}}_l(t+\Delta T)\|\\
\hat{\boldsymbol{p}}_l(t+\Delta T) = \boldsymbol{p}_l(t) + \Delta T[{v}_l \cos\theta_l(t), v_l \sin\theta_l(t)]^T
\end{array}
\end{equation}
Also, leader velocities are required to satisfy constraints in Equation (\ref{eq2e}), which means $\tilde{v} \le \bar v$ and $\tilde{\omega} \le \bar \omega$. To ensure obstacle avoidance in Equation (\ref{eq2b}), parameters should satisfy $\frac{\tilde{v}}{\tilde{\omega}}<d_o<d_t-\frac{2\tilde{v}}{\tilde{\omega}}<d_r-\frac{2\tilde{v}}{\tilde{\omega}}$,
% \begin{equation} \label{eq7}
% \frac{\tilde{v}}{\tilde{\omega}}<d_o<d_t-\frac{2\tilde{v}}{\tilde{\omega}}<d_r-\frac{2\tilde{v}}{\tilde{\omega}}
% \end{equation} 
where $d_r$ is the sensing range of the laser scanner. With above parameters, the leader would advance to $\boldsymbol{p}_g$ automatically and keep the distance $d_t-\frac{2\tilde{v}}{\tilde{\omega}}$ away from obstacles. To leave enough space for followers, we can increase $d_t$, $\tilde{\omega}$ and decrease $\tilde{v}$. The proof is similar to Theorem 1 in \cite{A.S.2013}, provided for interested readers to refer to.
\subsection{Follower Trajectory Generation}          \label{trajectory_generation}
Here, the reference trajectories are generated for followers. The rigid formation based on Cartesian coordinates suffers from many limitations and even a square shape with four nonholonomic mobile robots can not be perfectly achieved. To solve it, we use curvilinear coordinates instead. As in Fig. \ref{Transport}, the relative position between robots $i$ and $j$ is described by ${}^is_j$ and ${}^iq_j$, where ${}^is_j$ is the displacement along the path of robot $i$, and ${}^iq_j$ is the offset in the sliding direction. Notice that ${}^i\boldsymbol{c}_j = [{}^is_j,{}^iq_j]^T$ is equal to ${}^i\boldsymbol{p}_j$ when robot $i$ moves forward without rotation. Define the desired value of ${}^i\boldsymbol{c}_j$ as ${}^i\boldsymbol{c}_j^d = [{}^is_j^d,{}^iq_j^d]^T$. We generate the reference trajectory for the follower $i$ based on ${}^l\boldsymbol{c}_i^d$ with the leader $l$ in Algorithm \ref{algorithm_2}.
\vspace{-0.3cm}
\begin{algorithm} \label{algorithm_2}
\caption{Trajectory Generation for Follower $i$}
%\KwIn{${}^l\boldsymbol{c}_i^d$, $v_l$, $\omega_l$, $\delta_c$}
%\KwOut{${}^jv_r$, ${}^j\omega_r$}
\If{$\vert \delta_{i} \vert > \delta_c$}
{
    Rotate its camera with $\omega_i^c = k_c(\delta_{i}-\delta_c \text{sgn}(\delta_{i}-\delta_{c}))$ to measure relative pose ${}^i\bm{m}_{l}$ to the leader\; 
}
% \ElseIf{$\delta_{i} \le -\delta_c$}
% {
%     $\omega_i^c = k_c(\delta_{i}+\delta_c)$\; 
% }
% Obtain the relative pose ${}^i\bm{m}_{l}=[{}^i\bm{p}_{l}^T,{}^i\theta_{l}]^T$ to the leader by fusing data from camera and odometry\;
% Extrapolate its global position $(\bm{p}_{i},\theta_i)$ based on ${}^i\bm{m}_{l}$ and $(\bm{p}_{l},\theta_{l})$ transmitted by the leader\;       
Receive part of leader trajectory $\mathcal{T}_l(t)$ from the leader\;
Calculate its desired position $O_i^d(t)$ in the leader frame, which is $({}^is_j^d,{}^iq_j^d)$ away from the leader on $\mathcal{T}_l(t)$ in curvilinear coordinate systems\;  
Transform $O_i^d$ from the leader frame to the local frame of follower $i$ based on ${}^i\bm{m}_{l}$\;
Obtain its reference velocity $({}^iv_r(t),{}^i\omega_r(t))$ according to Equation (\ref{eq8})\; 
%\For{$j\in \mathcal{N}_i$}{
%Predict ${}^j\hat{\bm{m}}_l$ with $v_i$, $\omega_i$ from odoemtry and $v_j$, $\omega_j$ from data transmission\;
%Update ${}^j\tilde{\bm{m}}_l$ based on camera measurements\; 
%%\tcp{Update the weight}
%\uIf{$\vert \varphi_{ij}^m \vert \le \phi_c$ and $b_{i}^j > b_{\min}$}
%{
%    $b_{i}^j = b_{i}^j -k_c\Delta T$\;  
%
%}\uElseIf{$\vert \varphi_{ij}^m \vert \le \phi_c$ and $b_{i}^j \le b_{\min}$}
%{
%    $b_{i}^j = b_{\min}$\;
%}\uElseIf{$\vert \varphi_{ij}^m \vert > \phi_c$ and $b_{i}^j \le b_{\max}$}
%{
%    $b_{i}^j = b_{i}^j + k_c\Delta T$\;
%}\Else
%{$b_{i}^j = b_{\max}$\;
%}
%}
\end{algorithm}
\vspace{-0.3cm}

To obtain continuous relative pose measurements ${}^i\bm{m}_{l}=[{}^i\bm{p}_{l}^T,{}^i\theta_{l}]^T$ to the leader, the limited-FOV camera on follower $i$ actively tracks the leader via a rotating motor below, where the leader is detected by AprilTag in \cite{J.W.2016}. When the absolute value of relative angle $\delta_i$ between the camera and the leader exceeds the threshold $\delta_c$, the camera rotates at $\omega_i^c$ to track the leader and maintain it in FOV.
% First, the camera on follower $i$ actively tracks the leader $l$ to obtain continuous relative pose measurements ${}^i\bm{m}_{l}$ to $l$ with the rotating motor below, where the leader is detected by AprilTag markers \cite{J.W.2016}. 
% Sometimes, the leader may be lost due to image blurring or occlusion, where strategies based on visual servo do not work. To solve it and improve accuracy, the relative pose ${}^i\bm{m}_{l}$ is obtained by fusing the camera measurements and odometry with EKF filter.   
% To begin, the follower $i$ selects a target robot $a_i$ for visual tracking in order to attain continuous relative pose measurements ${}^i\bm{m}_{a_i}=[{}^i\bm{p}_{a_i}^T,{}^i\theta_{a_i}]^T$ with $a_i$. 
% Here, the visual feedback is fused with odometry information by EKF to avoid sudden loss.  Sometimes, the target robot $a_i$ may be lost due to image blurring or occlusion, where strategies based on visual servoing do not work. When it happens, the camera is rotated towards the robot $b$ with the minimum relative angle and selects $b$ as the new target $a_i$. With ${}^i\bm{m}_{a_i}$ and $(\bm{p}_{a_{i}},\theta_{a_{i}})$ from $a_i$, the robot $i$ can localize itself.   
%To localize robot $j$ in the global coordinate frame generated by the leader $l$, the pose estimation $(\bm{p}_{a_{j}},\theta_{a_{j}})$ is required to be transmitted by $a_j$. By this way, each follower robot $j$ can obtain relative pose ${}^j\bm{m}_l(t)=[{}^j\bm{p}_l^T(t),{}^j\theta_l(t)]^T$ to the leader and localize itself. 
Then, the leader transmits part of its trajectory $\mathcal{T}_l(t)$ to all followers, where $\mathcal{T}_l(t)$ records historical poses and velocities of the leader. Specifically, $\mathcal{T}_l(t)$ is defined as $\mathcal{T}_l(t)=(\bm{g}_l(t_{-k}),\bm{g}_l(t_{-k+1}),...,\bm{g}_l(t_{-1}),\bm{g}_l(t))$, where $\bm{g}_l(t)=[\bm{p}_l(t), \theta_l(t), v_l(t),\omega_l(t)]^T$ is recorded in the leader frame, $t_p$ represents $p^{\text{th}}$ sampling instant and $k$ is the buffer length. To reduce the amount of communication, we can decrease the buffer length $k$ as much as possible. Besides, data are transmitted only when leader velocities change, because the leader poses can be inferred from the constant leader velocities when they are unchanged.  

Next, as Fig. \ref{Transport} shows, the follower $i$ calculates the position of $O_L^i$ in its own frame with $\mathcal{T}_l(t)$, which is ${}^ls_i^d$ away from the current position of the leader $O_L$ along the leader's path. The time instant $t_a$ when the leader arrives at $O_L^i$ is estimated by $t_a = \text{argmin}_t\{\text{dist}(O_L^i, \bm{p}_l(t))\}$. Next, construct the coordinate system at $O_L^i$ with the forward tangent line of the leader's path as the $x$ axis. The desired position $O_i^d$ for the follower $i$ is ${}^lq_i^d$ away from $O_L^i$ on the $y$ axis and the desired heading angle $\theta_i^d$ is parallel to the $x$ axis. After obtaining $O_i^d$, the follower $i$ transforms $O_i^d$ to its own local frame based on ${}^i\bm{m}_{l}$.

% Besides, the position of $O_i^d$ in the global coordinate frame is $O_i^d(t)=[x_i^d(t),y_i^d(t)]$.            

The reference velocities ${}^iv_r(t)$ and ${}^i\omega_r(t)$ of the follower $i$ are generated with leader velocities  $(v_l(t_a),\omega_l(t_a))$ at $t_a$ as 
\begin{equation} \label{eq8}
{}^iv_r(t)=v_l(t_a)-\omega_l(t_a){}^lq_i^d,\;{}^i\omega_r(t)=\omega_l(t_a)
\end{equation}
where ${}^iv_r(t)$ is the sum of the leader velocity $v_l(t_a)$ and the additional velocity ${}^l\omega_i(t_a){}^lq_i^d$ caused by leader rotation, and ${}^i\omega_r(t)$ remains the same as the leader to maintain consistency.
% \begin{figure*}[htbp]
% \centering
% \includegraphics[height=1.4in]{flowchart_new.drawio.pdf}  
% \caption{Flowchart of transportation framework, where yellow boxes represent robot process and red boxes are judgment conditions}
% \label{flowchart} 
% \end{figure*}
\subsection{Complexity Analysis}
When the leader executes Algorithm \ref{algorithm_1}, the most time-consuming operation is the calculation of $\rho_{lo}(t)$ and $\hat \rho_{lo}(t+\Delta T)$, which requires traversing all points in $\mathcal{O}_l(t)$ and takes the time related to the number of points $y$ in $\mathcal{O}_l(t)$. The remaining parts are elementary operations, so the leader performs about $2y$ steps to complete Algorithm \ref{algorithm_1}. In fact, $y$ is a constant, so the leader only consumes a constant time $O(1)$. For each follower $i$, the most time-consuming operation is the calculation of $O_i^d$ and $t_a$, which requires traversing the received leader trajectory, and the steps performed are related to the buffer length $k$. Since $k$ is an adjustable constant, the time taken by the follower is also a constant $O(1)$. 

In contrast, integer programming based multi-robot trajectory generation methods are NP-hard with $O(2^n)$ complexity, while quadratic programming based optimization methods require a polynomial complexity $O(n^m)$, where $n$ is the number of constraints or robots. In addition, they generate trajectories offline based on global maps, which makes them difficult to extend to new environments and not real-time. Fortunately, these shortcomings can be overcome by our approach.

 
%In practice, ${}^iv_r(t)$ is filtered by $\text{ReLU}$ function to ensure consistency and $\text{ReLU}(x) = \max\{x,0\}$.     

%\begin{Remark}
%In practice, pose measurements are only acquired at sampling instants and  discretization is needed to adapt to these discontinuous observations during follower trajectory generation. For example, the curvature $\frac{d({}^j\theta_l)}{d\boldsymbol{s}_l}$ at time $t$ can be estimated by $\frac{{}^j\theta_l(t)-{}^j\theta_l(t-\Delta T)}{\Vert {}^j\bm{p}_l(t)-{}^j\bm{p}_l(t-\Delta T)\Vert}$, and $O_L^j$ is calculated by linear interpolation methods if it falls into the interval between two sampling points. At the beginning, the trajectory of the leader before $0s$ is required by the follower to establish the reference path, and the missing trajectory of the leader can be created by the extension line along the negative direction of the tangent at $0s$.              
%\end{Remark}

%Another issue to consider is the acquisition of ${}^i\bm{m}_j$ among robots. There are two methods to attain the measurement data of ${}^i\bm{m}_j$. One is achieved by combination of transmitted velocity information from the leader robot   and robot local odometry. The other one is the direct measurements from visual feedbacks of onboard cameras. In this paper, these two are fused by the extended Kalman filter (EKF). Since the camera suffers from limited field of view (FOV), some follower robots are not capable of observing all their neighbors and obtaining enough measurements for the updating process in EKF filter. Here, we utilize two ways to resolve this problem. The first one is that we attempt to mount cameras with larger FOV on the robots if possible, and the second one is that we can rotate the onboard camera to enlarge the sensing range and observe more robots. Assume $\Delta T$ is the sampling time, and details are summarized in Algorithm \ref{algorithm_3}. 
%\begin{algorithm} \label{algorithm_3}
%\caption{Relative Pose Estimation with Camera Rotation Strategy and Sensor Fusion}
%\KwIn{$\varphi_{ij}^m$, $b_{i}^j,v_j,\omega_j\,(j\in \mathcal{N}_i)$, $k_c$, $\Delta T$}
%\KwOut{$\omega_c^i$, $b_{i}^j$}
%$\omega_c^i=-\sum_{j \in \mathcal{N}_i}b_{i}^j\nabla_{\varphi_{ij}^m}P(\varphi_{ij}^m)$\;
%\For{$j\in \mathcal{N}_i$}{
%\tcp{Sensor fusion with EKF}
%Predict ${}^j\hat{\bm{m}}_l$ with $v_i$, $\omega_i$ from odoemtry and $v_j$, $\omega_j$ from data transmission\;
%Update ${}^j\tilde{\bm{m}}_l$ based on camera measurements\; 
%\tcp{Update the weight}
%\uIf{$\vert \varphi_{ij}^m \vert \le \phi_c$ and $b_{i}^j > b_{\min}$}
%{
%    $b_{i}^j = b_{i}^j -k_c\Delta T$\;  
%
%}\uElseIf{$\vert \varphi_{ij}^m \vert \le \phi_c$ and $b_{i}^j \le b_{\min}$}
%{
%    $b_{i}^j = b_{\min}$\;
%}\uElseIf{$\vert \varphi_{ij}^m \vert > \phi_c$ and $b_{i}^j \le b_{\max}$}
%{
%    $b_{i}^j = b_{i}^j + k_c\Delta T$\;
%}\Else
%{$b_{i}^j = b_{\max}$\;
%}
%}
%\end{algorithm}
%
%In order to design a proper rotation strategy for onboard cameras to obtain more visual feedbacks, the robust Huber kernel $P(x)$ is applied here.     
%\begin{equation} \label{eq9}
%P(x)=\left\{\begin{array}{l}
%0\;(\vert x \vert \le \delta)\\
%\frac{a}{2}(\vert x \vert - \delta)^2\;(\delta < \vert x \vert \le 2\delta)\\
%a\delta(\vert x \vert - \frac{3}{2}\delta)\;(2\delta < \vert x \vert \le \pi)
%\end{array}\right.
%\end{equation}
%Here, $a$ is the parameter to adjust the amplitude of $\omega_c^i$ and $\delta$ is the constant to determine value ranges. The relative angle $\varphi_{ij}$ is defined as $\varphi_{ij}=\text{atan2}(y_j-y_i,x_j-x_i)-\theta_i = \varphi_{ij}^m+\theta_{c}^{i}$, while $\varphi_{ij}^m$ is the actual relative angle measurement from the camera and $\theta_{c}^{i}$ is the camera rotation angle. The camera is rotated with angular velocity $\omega_c^i$ in Line 1, which is the weighted average of the gradient of $P(\varphi_{ij}^m)$. For each neighboring robot $j$, the follower robot $i$ estimates the relative pose ${}^j{\bm{m}}_l$ by EKF filter. The predirection process is completed with the velocity measurements $v_i$, $\omega_i$ from robot own odometry, and $v_j$, $\omega_j$ transmitted by inter-robot communication. Details of EKF filter are included in our previous paper. The weight $b_{i}^j$ is designed to ensure the neighboring robot out of view to be rediscovered and measured in time. When the robot $j$ leaves the view of the robot $i$, the weight $b_{i}^j$ increases with speed $k_c$. Otherwise, it will decrease. Besides, the weight $b_{i}^j$ is bounded with the maximum $b_{\max}$ and the minimum $b_{\min}$ to prevent sharp turn of camera. Additionally, each $b_{i}^j$ is initialized by $\frac{b_{\max}+b_{\min}}{2}$.      
%\begin{Remark}
%As the experiment part shows, the wide-angle cameras with $135^{\circ}-150^{\circ}$ view are equipped by the robot, which can nearly cover all neighboring robots after proper rotation. In addition, the switching of $b_i^j$ may cause the instability of the camera rotation devices in theory. However, if we apply the camera with a large angle range and select the parameters $t_l$, $\tilde{b}$ properly, the instability of the camera rotation devices would be avoided. 
%\end{Remark}
%
%Based on above discussions, the following assumptions are provided.
%\begin{Assumption}
%With our camera rotation strategies and EKF filter, the estimation ${}^i\hat{\bm{ m}}_j$ of the relative pose ${}^i\bm{m}_j$ is accurate enough so that we can utilize estimation ${}^i\hat{\bm{ m}}_j$ to substitute ${}^i\bm{m}_j$ directly in robot motion controllers.    
%\end{Assumption}
\section{Time-efficient Cooperative Transportation under Scalable Constraints}
As in Fig. \ref{flowchart}, the follower is required to track the generated trajectory and maintain constraints based on three designed processes. In the normal tracking process, the follower has no tendency to break any intra-process constraints. It tracks the trajectory normally and preserves inter-process constraints like velocity constraints. When any intra-process constraints are about to break, it comes into the constraint preservation process and actions are taken to avoid them without considering the tracking mission. Otherwise, the follower is in the transition process, where the tracking mission and constraint maintenance are considered concurrently. The three processes and the associated algorithms are discussed as follows.
\subsection{Normal Tracking Process}
Based on \cite{X.Y.2015}, the control strategies for the follower $i$ in the normal tracking process are designed as
\begin{equation}
\nonumber
\begin{aligned}
v_i^n &={}^iv_{r}+\frac{c_{1} {}^ix_{e}}{\sqrt{1+{}^ix_{e}^{2}+{}^iy_{e}^{2}}} \\
\omega_i^n &={}^i\omega_{r}+\frac{c_{2} {}^iv_{r}({}^iy_{e} \cos \frac{{}^i\theta_{e}}{2}-{}^ix_{e} \sin \frac{{}^i\theta_{e}}{2})}{\sqrt{1+{}^ix_{e}^{2}+{}^iy_{e}^{2}}}+c_{3} \sin \frac{{}^i\theta_{e}}{2}
\end{aligned}
\end{equation}
where $c_1$, $c_2$ and $c_3$ are positive parameters. The tracking errors are ${}^ix_{e}=\Vert {}^i\bm{p}_e \Vert \cos ({}^i\alpha_e-\theta_i)$, ${}^iy_{e}=\Vert {}^i\bm{p}_e \Vert \sin ({}^i\alpha_e-\theta_i)$ and ${}^i\theta_{e}=\theta_i^d-\theta_i$ in the local frame of follower $i$, while $\Vert {}^i\bm{p}_e \Vert=\sqrt{(x_i^d-x_i)^2+(y_i^d-y_i)^2}$, ${}^i\alpha_e =atan2(y_i^d-y_i,x_i^d-x_i)$, $[x_i^d,y_i^d]^T$ is the position of $O_i^d$ and reference velocities ${}^iv_{r}$, ${}^i\omega_{r}$ are obtained from Equation (\ref{eq8}). 

Then, we discuss the velocity constraint in Equation (\ref{eq2e}). The items in $v_i^n$ and $\omega_i^n$ satisfy $\vert \frac{c_{1} {}^ix_{e}}{\sqrt{1+{}^ix_{e}^{2}+{}^iy_{e}^{2}}}\vert \le c_1$ and $\vert\frac{c_{2} ({}^iy_{e} \cos \frac{{}^i\theta_{e}}{2}-{}^ix_{e} \sin \frac{{}^i\theta_{e}}{2})}{\sqrt{1+{}^ix_{e}^{2}+{}^iy_{e}^{2}}}\vert \le \vert \frac{c_{2} \sqrt{{}^ix_{e}^{2}+{}^iy_{e}^{2}}}{\sqrt{1+{}^ix_{e}^{2}+{}^iy_{e}^{2}}}\vert\le c_2$. 
%The upper bounds of velocities ${}^iv_{r}$ and ${}^i\omega_{r}$ are related to the curvature $\frac{d \theta_l}{d\boldsymbol{s}_l}$ of the leader's path, which satisfies $\frac{d\theta_l}{d\boldsymbol{s}_l}=\frac{\left|\dot x_l \ddot y_l-\ddot x_l \dot y_l\right|}{\left(\dot x_l^{2}+\dot y_l^{2}\right)^{3 / 2}}=\frac{\omega_l}{v_l}$. 
To preserve the constraint, we have $\vert v_i \vert \le\vert {}^iv_{r}\vert +c_1\le \tilde v+\tilde \omega \vert {}^lq_j^d \vert + c_1\le \bar v$ and $\vert \omega_i\vert \le \tilde \omega+c_2 \tilde v + c_3 \le \bar\omega$.
% \begin{equation}
% \left\{\begin{array}{l}
% \begin{aligned}
% \vert v_i \vert &\le\vert {}^iv_{r}\vert +c_1\le \tilde v+\tilde \omega \vert {}^lq_j^d \vert + c_1\le \bar v\\
% \vert \omega_i\vert &\le \tilde \omega+c_2 \tilde v + c_3 \le \bar\omega 
% \end{aligned}
% \end{array}\right.
% \end{equation} 
\subsection{Constraint Preservation Process}
Next, the constraint preservation issue is considered. To achieve it for the follower $i$, three different kinds of intra-process constraints are discussed as follows.
\subsubsection{Two-sided Constraints} 
These constraints have both maximum and minimum values, such as Equation (\ref{eq2a}) and constraints merged by Equation (\ref{eq2c}), (\ref{eq2f}). We can rewrite them uniformly as $\delta_{a}^{i-}\le g_a^i(\bm{p}_i,\bm{p}_j) \le \delta_{a}^{i+}\,(j\in \mathcal{N}_i)$, where $\delta_{a}^{i-}$ and $\delta_{a}^{i+}$ are the corresponding lower and upper bounds. To maintain them, the function $\mathcal{Q}_{a}^i(g_a^i)$ is designed as  
\begin{equation}
\nonumber
\mathcal{Q}_{a}^i(g_a^i)=\left\{\begin{array}{l}
\frac{(g_a^i-\delta_{a}^{i-}-\gamma_a^{i})^2}{-\delta_{a}^{i-}+g_a^i+(\gamma_a^{i})^2}\;(\delta_{a}^{i-} \le g_a^i \le \delta_{a}^{i-} +\gamma_a^{i})\\
0\;(\delta_{a}^{i-} + \gamma_a^{i}< g_a^i \le \delta_{a}^{i+} - \gamma_a^{i})\\
\frac{(g_a^i-\delta_{a}^{i+}+\gamma_a^{i})^2}{\delta_{a}^{i+}-g_a^i+(\gamma_a^{i})^2}\;(\delta_{a}^{i+} - \gamma_a^{i} < g_a^i \le \delta_{a}^{i+})
\end{array}\right.
\end{equation}
where $\gamma_a^{i}<\frac{\delta_{a}^{i+}-\delta_{a}^{i-}}{2}$ is a positive parameter to adjust the available range of $g_a^i$. We define the function for the $k^{th}$ two-sided constraint of the follower $i$ as $\mathcal{Q}_{a}^{ik}$, the corresponding variable as $g_a^{ik}$, the parameter as $\gamma_a^{ik}\,(k\in \{1,2,...,q_a\})$ and the number of two-sided constraints as $q_a$.  
\subsubsection{One-sided Constraints}
These constraints are bounded only on one side, such as constraints in Equation (\ref{eq2b}), (\ref{eq2d}). They are summarized as two types, including $g_b^i(\bm{p}_i,\bm{p}_j) \ge \delta_{b}\,(j\in \mathcal{N}_i)$ and $g_c^i(\bm{p}_i,\bm{p}_j) \le \delta_{c}\,(j\in \mathcal{N}_i)$, where $\delta_{b}$ and $\delta_{c}$ are the lower and upper bounds. Then, the functions corresponding to these two types are respectively designed as
\begin{equation}
\nonumber
\mathcal{Q}_b^i(g_b^i)=\left\{\begin{array}{l}
\frac{(g_b^i-\delta_{b}^{i}-\gamma_b^{i})^2}{-\delta_{b}^{i}+g_b^i+(\gamma_b^{i})^2}\;(\delta_{b}^{i} \le g_b^i < \delta_{b}^{i} + \gamma_b^{i})\\
0\;(g_b^i  \ge \delta_{b}^{i} + \gamma_b^{i})
\end{array}\right.
\end{equation}
\begin{equation}
\nonumber
\mathcal{Q}_c^i(g_c^i)=\left\{\begin{array}{l}
\frac{(g_c^i-\delta_{c}^{i}+\gamma_c^{i})^2}{\delta_{c}^{i}-g_c^i+(\gamma_c^{i})^2}\;(\delta_{c}^{i} - \gamma_c^{i} < g_c^i \le \delta_{c}^{i})\\
0\;(g_b^i  \le \delta_{c}^{i} - \gamma_c^{i})
\end{array}\right.
\end{equation}
where $\gamma_b^{i}$ and $\gamma_c^{i}$ are adjustable parameters. Similarly, we define the function for the $k^{th}$ left-bounded constraint as $\mathcal{Q}_b^{ik}$, while $\mathcal{Q}_c^{ik}$ is for the $k^{th}$ right-bounded constraint. The corresponding parameters are $\gamma_b^{i}$ and $\gamma_c^{i}$, while the corresponding variables are  $g_b^{ik}$ and $g_c^{ik}$. Besides, the number of these two kinds of constraints are $q_b$ and $q_c$, relatively. 
\subsubsection{Mixed Constraints}
There are some constraints that may be mixed with velocities like Equation (\ref{eq2g}), which are related to inter-process constraints. 
We assume that the upper bound of $f_i$ can be inferred from Equation (\ref{eq2e}). For example, $f_i=v_i^2+v_i\omega_i$ satisfies our assumptions, because it is deduced that $\vert f_i \vert \le \bar v^2+\bar v\bar \omega$. Instead, $f_i=\frac{1}{v_i}$ is not suitable, because the upper bound of $f_i$ can not be obtained from $\vert v_i \vert \le \bar v$.
Suppose the upper bound of $f_i$ calculated from Equation (\ref{eq2e}) as $\vert f_i \vert \le \bar f$. We can decouple two functions $f_i$, $g_i$ and obtain 
\begin{equation} \label{eq4a}
\bar f+\delta_i^- \le g_i(\boldsymbol{p}_i,\boldsymbol{p}_j) \le \delta_i^+-\bar f    
\end{equation}
as a new intra-process constraint to maintain. To achieve it, $\bar f $ should satisfy $\bar f \le \frac{1}{2}(\delta_i^+-\delta_i^-)$, which can be decreased by lowering $\bar v$ and $\bar \omega$ when Equation (\ref{eq4a}) does not hold.

% In this way, we transfer the constraint from Equation (\ref{eq2e}) to Equation (\ref{eq4a}) and


% including the function $\mathcal{Q}_{rj}^i(\Vert {}^i\bm{p}_j \Vert)$ to maintain the proper relative distance with robot $j\,(j\in \mathcal{N}_i)$, $\mathcal{Q}_o^i(\rho_{io})$ to avoid obstacles and $\mathcal{Q}_l^i(\rho_{il})$ to protect the transportation system from possible collisions. Specifically, the function $\mathcal{Q}_{rj}^i(\Vert {}^i\bm{p}_j \Vert)$ is
% \begin{equation}
% \nonumber
% \mathcal{Q}_{rj}^i(\Vert {}^i\bm{p}_j \Vert)=\left\{\begin{array}{l}
% \frac{(\Vert {}^i\bm{p}_j \Vert-{}^i\rho_{j}^{-}-\delta_r)^2}{-{}^i\rho_{j}^{-}+\Vert {}^i\bm{p}_j \Vert+\delta_r^2}\;({}^i\rho_{j}^{-} \le \Vert {}^i\bm{p}_j \Vert \le {}^i\rho_{j}^{-} + \delta_r)\\
% 0\;({}^i\rho_{j}^{-} + \delta_r< \Vert {}^i\bm{p}_j \Vert \le {}^i\rho_{j}^{+} - \delta_r)\\
% \frac{(\Vert {}^i\bm{p}_j \Vert-{}^i\rho_{j}^{+}+\delta_r)^2}{{}^i\rho_{j}^{+}-\Vert {}^i\bm{p}_j \Vert+\delta_r^2}\;({}^i\rho_{j}^{+} - \delta_r < \Vert {}^i\bm{p}_j \Vert \le {}^i\rho_{j}^{+})
% \end{array}\right.
% \end{equation}
% where $\delta_r$ is a positive parameter to adjust the available range of $\Vert {}^i\bm{p}_j \Vert$. Similarly, the function $\mathcal{Q}_o^i(\rho_{io})$ is proposed as
% \begin{equation}
% \nonumber
% \mathcal{Q}_o^i(\rho_{io})=\left\{\begin{array}{l}
% \frac{(\rho_{io}-d_o-\delta_o)^2}{-d_o+\rho_{io}+\delta_o^2}\;(d_o \le \rho_{io} < d_o + \delta_o)\\
% 0\;(\rho_{io} \ge d_o + \delta_o)
% \end{array}\right.
% \end{equation}
% and $\delta_o$ is the corresponding parameter. As for the function $\mathcal{Q}_l^i(\rho_{il})$, it is defined as
% \begin{equation}
% \nonumber
% \mathcal{Q}_l^i(\rho_{il})=\left\{\begin{array}{l}
% \frac{(\rho_{il}-d_l-\delta_l)^2}{-d_l+\rho_{il}+\delta_l^2}\;(d_l \le \rho_{il} < d_l + \delta_l)\\
% 0\;(\rho_{il} \ge d_l + \delta_l)
% \end{array}\right.
% \end{equation}
% The function ${dist}()$ in the definition of $\rho_{il}$ represents the distance from the obstacle point $\boldsymbol{p}_o$ to the connection line $L_{ij}$ between robot $i$ and $j$, which is created by referring to paper \cite{D.S.2018}. It is defined as ${dist}({}^i\boldsymbol{p}_o,L_{ij}) = \frac{{}^i\boldsymbol{p}_o^TG{}^i\boldsymbol{p}_j}{\Vert G{}^i\boldsymbol{p}_j \Vert}$ when ${}^i\boldsymbol{p}_o \in D_{ij}$ 
% \begin{equation}
% \text{dist}({}^i\boldsymbol{p}_o,L_{ij})=\left\{\begin{array}{l}
% \frac{{}^i\boldsymbol{p}_o^TG{}^i\boldsymbol{p}_j}{\Vert G{}^i\boldsymbol{p}_j \Vert}\;({}^i\boldsymbol{p}_o \in D_{ij})\\
% \text{undefined}\;({}^i\boldsymbol{p}_o \notin D_{ij})
% \end{array}\right.
% \end{equation}
% , where ${}^i\boldsymbol{p}_o$ is the coordinate of $\boldsymbol{p}_o$ in the frame of robot $i$, $D_{ij}=\left\{q \mid\left(q-\boldsymbol{p}_{i}\right)^{T}{}^{i} \boldsymbol{p}_{j}>0,\left(q-\boldsymbol{p}_{j}\right)^{T} {}^{i} \boldsymbol{p}_{j}<0\right\}$ and the matrix $G$ is 
% % $[0,-1;1,0]$. 
% $\left[ \begin{array}{ccc}
% 0 & -1\\
% 1& 0
% \end{array}
% \right ]$. 

In general, the above three functions approach the maximum value $1$ when constraints tend to be avoided, while they remain the minimum $0$ if constraints are protected. Define $\beta_i$ as the maximum value of all related functions for follower $i$, we have 
\begin{equation}
\beta_i = \max\{\mathcal{Q}_{a}^{ik_a}\,, \mathcal{Q}_b^{ik_b}, \mathcal{Q}_c^{ik_c}\} \in [0,1]
\end{equation}
where $k_a$, $k_b$ and $k_c$ are the indexes of functions. 

The process that the follower belongs to is recognized by $\beta_i$. When $\beta_i=0$, the follower $i$ is in the normal tracking process. If $\beta_i$ is larger than the threshold $\beta_t \in (0,1)$, the follower $i$ enters the constraint preservation process. Otherwise, it moves into the transition process. Then, the multi-objective control strategies for followers under constraints are summarized in Algorithm \ref{algorithm_3}. Here, the saturation function ${sat}(x,y)$ is equal to $1$ when $|x|\le y$ and ${sgn}(x) \frac{y}{x}$ otherwise. Obviously, the function ${sat}(x,y)$ is always greater than or equal to zero. The vector $ \tau_i=\nabla_{\bm{p}_i} \Psi_i=[ \nabla_x \Psi_i, \nabla_y \Psi_i]^T$ is the gradient of $\Psi_i$ with respect to $\bm{p}_i$. Next, the following theorem is obtained. 
\vspace{-0.3cm}
\begin{algorithm} \label{algorithm_3}
\caption{Follower $i$'s Strategy with Constraints}
%\KwIn{$\beta_i$, ${}^i\bm{p}_j$, $g_a^{ik_a}$, $g_b^{ik_b}$, $g_c^{ik_c}$}
\KwOut{$v_i$, $\omega_i$}
$\mathcal{P}_{a}^{ik_a}=1-\mathcal{Q}_{a}^{ik_a},\mathcal{P}_b^{ik_b}=1-\mathcal{Q}_b^{ik_b},\mathcal{P}_c^{ik_c}=1-\mathcal{Q}_c^{ik_c}$\;
$\Psi_i = 1-(\prod_{k_a=1}^{q_a}\mathcal{ P}_{a}^{ik_a}) (\prod_{k_b=1}^{q_b}\mathcal{ P}_{b}^{ik_b})(\prod_{k_c=1}^{q_c}\mathcal{ P}_{c}^{ik_c})$\;
$\tau^i = [\tau_x^i,\tau_y^i]^T=[\nabla_x \Psi_i, \nabla_y \Psi_i]^T$\;
$\phi_i^d = \text{atan2}(\tau_y^i,\tau_x^i)$\;
$\hat v_i^o = -k_v^o\cos(\theta_i-\phi_i^d)\sqrt{(\tau_x^i)^2+(\tau_y^i)^2}$\;
$\hat \omega_i^o=-k_\omega^o(\theta_i-\phi_i^d)$\;
$v_i^o = \text{sat}(\hat{v}_i^o, \bar v)\hat{v}_i^o$, $\omega_i^o = \text{sat}(\hat{\omega}_i^o, \bar \omega)\hat{\omega}_i^o$\;
\uIf{$\beta_{i} = 0$}
{
    $v_i = v_i^n$, $\omega_i = \omega_i^n$\;  

}\uElseIf{$0<\beta_{i}\le \beta_t$}
{
    $v_i = \frac{\beta_t-\beta_i}{\beta_t}v_i^n + \frac{\beta_i}{\beta_t}v_i^o$, $\omega_i = \frac{\beta_t-\beta_i}{\beta_t}\omega_i^n + \frac{\beta_i}{\beta_t}\omega_i^o$\;
}\ElseIf{$\beta_t < \beta_{i} \le 1$}
{
    $v_i = v_i^o$, $\omega_i = \omega_i^o$\;
}
\end{algorithm}
\vspace{-0.3cm}
% Next, we can discuss about the constraint preservation process, where $\beta_t < \beta_{i} \le 1$. The theorem for robots under such process is provided as follows.
\begin{Theorem}
For each follower $i$ in the system, it can preserve all intra-process constraints, i.e. $\beta_i \le 1$ and inter-process constraints on velocities in Equation (\ref{eq2e}), if strategies in Algorithm \ref{algorithm_3} are applied and $\beta_i\le \beta_t$ is satisfied initially.    
\end{Theorem}
\begin{Proof}
In the normal tracking process and the transition process, there exists $\beta_i \le \beta_t < 1$, which means that $\mathcal{Q}_{a}^{ik_a}<1$, $\mathcal{Q}_{b}^{ik_b}<1$ and $\mathcal{Q}_{c}^{ik_c}<1$. As designed, the constraints will not be avoided when the function $\mathcal{Q}^i$ is less than $1$. Thus, if we can show that these constraints are also kept during the constraint preservation process, the theorem would be proved.

First, the dangerous region $D_d^i$ is defined as the set of positions that cause the follower $i$ into the constraint preservation process. For the mobile robot system $\dot{\bm{p}}_i = \bm{u}_s^i$ with the single integrator model, there always exists $\Psi_i(\bm{p}_i(t))>0$ when $\bm{p}_i \in D_d^i$ and $\bm{u}_s^i$ is $-\tau^i$, based on the definition of $\Psi_i$. 

Consider a Lyapunov function candidate $V_i=\Psi_i$ for $\dot{\bm{p}}_i = \bm{u}_s^i$. The time derivative of $V_i$ is
\begin{equation} \label{eq13}
\dot V_i = (\nabla_{\bm{p}_i} \Psi_i)^T\dot{\bm{p}}_i = -(\nabla_{\bm{p}_i} \Psi_i)^T\nabla_{\bm{p}_i} \Psi_i \le 0.    
\end{equation}
Assume the instant when the follower $i$ comes into $D_d^i$ as $t_0$, there exists $V_i(t_0) = \Psi_i(t_0) \le 1-(1-\beta_t)^{q_a+q_b+q_c}$ when $\bm{p}_i \in D_d^i$, due to $\beta_i > \beta_t$. By combining Equation (\ref{eq13}), we have $\Psi_i(t) \le \Psi_i(t_0) \le 1-(1-\beta_t)^{q_a+q_b+q_c} < 1$ for arbitrary instant $t$ in the constraint preservation process. When any intra-process constraint is totally violated, $\Psi_i(t)$ is larger than $1$.   

Since we assume that there is enough space in the environment for the transportation system to pass through, there exists an attraction region $\Omega_i$ for the robot system $\dot{\bm{p}}_i = -\tau^i$, such that the robot in $\Omega_i$ can eventually drive $\Psi_i$ to the minimum value 0. Based on Theorem 4 in \cite{S.Z.2018}, the control law $v_i = v_i^o$ and $\omega_i = \omega_i^o$ causes the system with the nonholonomic model in Equation (\ref{eq1}) to converge into the same attraction region $\Omega_i$ as the system $\dot{\bm{p}}_i = -\tau^i$. Thus, $\Psi_i(t) < 1$ holds for the follower $i$ if Algorithm \ref{algorithm_3} is applied.

Besides, $v_i^o$ and $\omega_i^o$ in the constraint preservation process are saturated within the upper bounds $\bar v$ and $\bar \omega$, which means that $|v_i^o|\le \bar v$ and $|\omega_i^o|\le \bar \omega$. Thus, the inter-process constraints on velocities are also maintained when $\beta_t < \beta_i \le 1$.
% Select a Lyapunov function for the robot $i$ in the constraint preservation process as $V_i=\Psi_i+\frac{\gamma_i}{2}(\theta_i-\phi_i^d)^2$, where $\gamma_i$ is a positive parameter. Define the function $V=\sum_{i\in \mathcal{K}}V_i$, where $\mathcal{K}$ is the set of robots in the constraint preservation process. Take the derivative of $V$ with respect to time $t$, we have
% \begin{align}
% \nonumber&\dot V=\sum_{i\in \mathcal{K}}\dot V_i=\sum_{i\in \mathcal{K}}(\frac{\partial \Psi_i}{\partial x_{k}} \dot{x}_{k}+\frac{\partial \Psi_i}{\partial y_{k}} \dot{y}_{k}+\gamma_i\omega_i(\theta_i-\phi_i^d))\\\nonumber
% =&\sum_{i\in \mathcal{K}}(\text{sat}(\hat v_i^o,\bar v)(-k_v^o\cos(\theta_i-\phi_i^d)\sqrt{(\tau_x^i)^2+(\tau_y^i)^2}(\frac{\partial \Psi_i}{\partial x_{k}} \cos \theta_i\\\nonumber
% &+\frac{\partial \Psi_i}{\partial y_{k}}\sin \theta_i)-\text{sat}(\hat \omega_i^o,\bar \omega)\gamma_i k_\omega^o (\theta_i-\phi_i^d)^2))\\\nonumber
% =&\sum_{i\in \mathcal{K}}(-\text{sat}(\hat v_i^o,\bar v)k_v^o\cos(\theta_i-\theta_i^d)^2((\tau_x^i)^2+(\tau_y^i)^2)\\&-\text{sat}(\hat \omega_i^o,\bar \omega)\gamma_i k_\omega^o (\theta_i-\phi_i^d)^2) \le 0
% \end{align}
% Due to the fact that $\beta_i \le \beta_t$ is satisfied initially and $\dot V \le 0$, the worst condition during transportation is that all robots tend to move into the constraint preservation process simultaneously at time $t_0$. Then, there exists $V_i(t_0+\Delta T) \le V(t_0+\Delta T) \le V(t_0)=\sum_{i\in \mathcal{K}}V_i(t_0)\le (n+1)\beta_t+\sum_{i\in \mathcal{K}}2\pi^2 \gamma_i$, where $\Delta T$ is the time interval. Since the parameter $\gamma_i$ is an arbitrary positive constant, we can always find a proper $\gamma_i < \frac{1-(n+1)\beta_t}{2(n+1)\pi^2}$ to ensure the stability and preserve $V_i$ less than $1$. Thus, the constraints are maintained by all robots in the group.             
\end{Proof}

Next, we discuss how to calculate related gradients. Specifically, $\nabla_{\boldsymbol p_i}\mathcal{Q}^i(\Vert {}^i\bm{p}_j \Vert)=\frac{d \mathcal{Q}^i(\Vert {}^i\bm{p}_j \Vert)}{d (\Vert {}^i\bm{p}_j \Vert)}\frac{{}^i\bm{p}_j}{\Vert {}^i\bm{p}_j \Vert}$, $\nabla_{\boldsymbol p_i}\mathcal{Q}^i(\rho_{io})=\frac{d \mathcal{Q}^i(\rho_{io})}{d \rho_{io}}\frac{{}^i\bm{p}_o}{\rho_{io}}$ and $\nabla_{\boldsymbol p_i}\mathcal{Q}^i(\rho_{il})=\frac{d \mathcal{Q}^i(\rho_{il})}{d \rho_{il}}\nabla_{\boldsymbol p_i}\rho_{il}$, where $\mathcal{Q}^i$ is an arbitrary $\mathcal{Q}$ function of $i$ and $\nabla_{\boldsymbol p_i}\rho_{il}$ is $\nabla_{\boldsymbol p_i }\rho_{il}=\frac{\nabla_{\boldsymbol p_i }({}^i\boldsymbol{p}_oG{}^i\boldsymbol{p}_j)\Vert G{}^i\boldsymbol{p}_j \Vert-{}^i\boldsymbol{p}_oG{}^i\boldsymbol{p}_j\nabla_{\boldsymbol p_i }(\Vert G{}^i\boldsymbol{p}_j \Vert)}{\Vert G{}^i\boldsymbol{p}_j \Vert^2}
=\frac{\Vert {}^i\boldsymbol{p}_j \Vert G{}^j\boldsymbol{p}_o+\rho_{il}{}^i\boldsymbol{p}_j}{\Vert {}^i\boldsymbol{p}_j \Vert^2}$.  
% \begin{align} \label{eq13}
% \nonumber\nabla_{\boldsymbol p_i }\rho_{il}=&\frac{\nabla_{\boldsymbol p_i }({}^i\boldsymbol{p}_oG{}^i\boldsymbol{p}_j)\Vert G{}^i\boldsymbol{p}_j \Vert-{}^i\boldsymbol{p}_oG{}^i\boldsymbol{p}_j\nabla_{\boldsymbol p_i }(\Vert G{}^i\boldsymbol{p}_j \Vert)}{\Vert G{}^i\boldsymbol{p}_j \Vert^2}\\
% =&\frac{\Vert {}^i\boldsymbol{p}_j \Vert G{}^j\boldsymbol{p}_o+\rho_{il}{}^i\boldsymbol{p}_j}{\Vert {}^i\boldsymbol{p}_j \Vert^2}
% \end{align} 
    
\subsection{Transition Process}
As for the transition process, the follower ought to balance trajectory tracking and constraint preservation concurrently. Here, we design a multi-objective control law based on $\beta_i$, which describes the risk of breaking intra-process constraints. When $\beta_i$ is close to $0$, it means that the follower operates safely and velocities for trajectory tracking mission should take up a larger proportion. Otherwise, if $\beta_i$ approaches to $\beta_t$, $v_i^o$ and $\omega_i^o$ would become main components. To make velocities continuous at $\beta_i = 0$ and $\beta_i = \beta_t$, the coefficients of $v_i^n$ and $v_i^o$ are designed as $\frac{\beta_t-\beta_i}{\beta_t}$ and $\frac{\beta_i}{\beta_t}$ relatively, and the same as $\omega_i^n$ and $\omega_i^o$. Furthermore, since $|\frac{\beta_t-\beta_i}{\beta_t}| + |\frac{\beta_i}{\beta_t}| = 1$, we can conclude that the inter-process constraints on robot velocities during the transition process are satisfied as well.  
\subsection{Complexity Analysis}
The most time-consuming operation in Algorithm \ref{algorithm_3} is the calculation of the gradient $\tau^i$ of $\Psi_i$. It is $\tau^i=-\sum_{k=1}^{q_a+q_b+q_c} \nabla_{\boldsymbol p_i}\mathcal{P}^{ik}\frac{1-\Psi_i}{\mathcal{P}^{ik}}$, where $\mathcal{P}^{ik}$ is an arbitrary $\mathcal{P}$ function for the $k^{th}$ constraint of follower $i$ and the total number of constraints is $n=q_a+q_b+q_c$. Normally, the number $n$ is larger than the number of neighboring robots $n_r$. If we can calculate in advance the expression for each gradient $\nabla_{\boldsymbol p_i}\mathcal{P}^{ik}$, the calculation of $\tau^i$ will become a combination of basic operations, which are repeated $n$ times. Thus, we can roughly consider the complexity as $O(n)$.

% , because the number of inter-robot collision avoidance constraints is at least equal to $n_r$

In contrast, other methods like hierarchical quadratic programming (HQP) suffer from higher complexity. As shown in \cite{D.K.2021}, if each robot has $n$ constraints, $n_r$ robots have roughly $\frac{nn_r}{2}$ constraints in total after removing duplicates. Based on \cite{E.A.2014}, HQP based on centralized optimization have a complexity of at least $O(m^2n_r)+O(n_r^2m)$, where $m$ is the number of constraints. Here, $m$ is $\frac{nn_r}{2}$ and the final complexity of HQP is about $O(n^5)$, worse than our methods with $O(n)$.       
% \begin{align}
% \nonumber \tau^i =& -(\sum_{k \in \mathcal{N}_i} \nabla_{\boldsymbol p_i}\mathcal{P}_{rk}^i \prod_{j\in \mathcal{N}_i\backslash k}\mathcal{P}_{rj}^i \mathcal{P}_o^i\mathcal{P}_l^i + \nabla_{\boldsymbol p_i}\mathcal{P}_o^i\prod_{j\in \mathcal{N}_i}\mathcal{P}_{rj}^i\mathcal{P}_l^i \\&+\nabla_{\boldsymbol p_i}\mathcal{P}_l^i\prod_{j\in \mathcal{N}_i}\mathcal{P}_{rj}^i\mathcal{P}_o^i)
% \end{align}

\section{Simulation and Experiment} 
\subsection{Numerical Simulation} 
Here, several simulations are provided to verify our proposed methods in MATLAB. As in Fig. \ref{Simulation_1}, the robot formation is required to transport the payload to $\bm{p}_g = [25,25]^T(m)$, while constraints in Equation (\ref{eq2a})-(\ref{eq2f}) should be maintained. As for scalable constraints, we select $\bar v_i^2+\vert \omega_i \vert \Vert {}^i\bm{p}_j \Vert \le 8$ and $\bar \omega_i + \Vert {}^i\bm{p}_j \Vert^2 \le 8$ for each follower $i$.               
%\begin{figure}[htbp]
%\centering
%\includegraphics[width=1.6in]{Environment_map.pdf}  
%\caption{Trajectories of robots and payload in simulation environment}
%\label{Simulation_env}
%\end{figure}  
\begin{figure} [htbp]
\vspace{-0.5cm}
\begin{minipage}{0.5\linewidth}
\centering
\includegraphics[height=1.42in]{simulation_new_1.pdf}
%\caption{0s}
\end{minipage}%
\begin{minipage}{0.5\linewidth}
\centering
\includegraphics[height=1.37in]{simulation_new_2.pdf}
%\caption{3s}
\end{minipage}
\caption{Robot trajectories in the simulation environment, $\rho_{io}$ and $\rho_{il}$}
\label{Simulation_1}
\vspace{-0.3cm}
\end{figure} 
% The leader robot first generates a reference trajectory in the unknown environment based on Algorithm \ref{algorithm_1}. Each follower robot calculates its own desired trajectory based on ${}^j{\bm{m}}_l$ and expected relative displacement ${}^i_C\boldsymbol{p}_j^d$ with respect to the leader in the curvilinear coordinate system.   

In this simulation, the desired displacements of followers are set as ${}^1\boldsymbol{c}_l^d = [1,-1]^T(m)$, ${}^2\boldsymbol{c}_l^d = [1,1]^T(m)$ and ${}^3\boldsymbol{c}_l^d = [2,0]^T(m)$ with $R_f=1m$. The related parameters are $l=0.9m$, $d=1.5m$, $h_0=0.1m$, $h_{\min}=0.1m$, $R_{s}=0.3m$, $\rho_c=0.4m$ and $c_{\max}=10m$, which implies that $r_{+}=1.4$ and $r_{-}=0.3$. The upper bounds of leader velocities are $\tilde{v}_l=0.5m/s$ and $\tilde{\omega}_l=0.4rad/s$. As for camera parameters, $\delta_c=0.5rad$ and $k_c=0.2$. The tracking parameter $c_1$ is set as $0.4$, while $c_2=0.7$ and $c_3=0.4$. For the constraint preservation process, $k_v^o=0.2$, $\beta_t=0.5$, $d_o=0.5m$, $d_l=0.4m$, $\delta_r = 0.5m$, $\delta_o=0.8m$ and $\delta_l=0.8m$. In each figure, we use $L$ to represent the leader and $Fi$ to represent the follower $i$.

\begin{table}[!htbp]\label{table_1} 
\vspace{-0.35cm}
\centering
\caption{Our scheme versus other frameworks in Matlab}
\begin{tabular}{ccccccccccc}
\toprule 
\multicolumn{3}{c}{\multirow{2}*{Method}}& \multicolumn{2}{c}{Trajectory generation}& &\multicolumn{2}{c}{Trajectory tracking}\\
\cmidrule(r){4-9} 
\multicolumn{3}{c}{}&Mean\,(ms)&Std\,(ms)&&Mean\,(ms)&Std\,(ms)&\\ 
\hline 
\multicolumn{3}{c}{Cascade QP\cite{O.K.2011}}& -& -&  &730.1& 130.5\\ 
\multicolumn{3}{c}{HQP\cite{D.K.2021}}& -& -&  &415.3& 80.1\\   
\multicolumn{3}{c}{MIQP\cite{D.M.2011}}&31261.2&2514.6& &-&-\\
\multicolumn{3}{c}{dec\_iSCP\cite{Y.C.2015}}&10524.4&975.1& &-&-\\
\multicolumn{3}{c}{Ours}&0.091&0.013& &0.17&0.022\\
\bottomrule 
\end{tabular}
\vspace{-0.3cm}
\end{table}

The tracking errors in $x$ and $y$ directions are depicted in Fig. \ref{Simulation_1} and the angle error is shown in Fig. \ref{Simulation_2} The trajectory tracking errors always converge to $0$ except instants when constraints tend to be destroyed. The obstacle distance $\rho_{io}$ is always kept larger than $d_o$ as in Fig. \ref{Simulation_1}, which implies that obstacle avoidance is achieved. Besides, the relative distances between robots are listed in Fig. \ref{Simulation_2}. Here, we define the minimum relative distance for the follower $i$ as $\rho_{ir}^{\min}=\min_{j\in \mathcal{N}_i}\{\Vert {}^i\bm{p}_j \Vert\}$ and the maximum relative distance as $\rho_{ir}^{\max}=\max_{j\in \mathcal{N}_i}\{\Vert {}^i\bm{p}_j \Vert\}$. For each follower, $\rho_{ir}^{\min}$ should be larger than $\sqrt{2}r_{-}=0.42m$ and $\rho_{ir}^{\max}$ less than $2r_{+}=2.8m$ under above constraints. It is found that all constraints for relative distances are satisfied.     
\begin{figure} [htbp]
\vspace{-0.35cm}
\begin{minipage}{0.5\linewidth}
\centering
\includegraphics[height=1.2in]{simulation_new_3.pdf}
%\caption{0s}
\end{minipage}%
\begin{minipage}{0.5\linewidth}
\centering
\includegraphics[height=1.2in]{simulation_new_4.pdf}
%\caption{3s}
\end{minipage}
\caption{The extreme values of $\Vert {}^i\bm{p}_j \Vert$ and tracking errors ${}^ix_e$, ${}^iy_e$}
\label{Simulation_2}
\vspace{-0.35cm}
\end{figure} 
%\begin{figure} [htbp]
%\begin{minipage}{0.5\linewidth}
%\centering
%\includegraphics[width=1.6in]{Tracking_error_theta.pdf}
%%\caption{0s}
%\end{minipage}%
%\begin{minipage}{0.5\linewidth}
%\centering
%\includegraphics[width=1.6in]{Obstacle_avoidance.pdf}
%%\caption{3s}
%\end{minipage}
%\caption{Trajectory tracking errors of ${}^j\theta_l$ and obstacle distance $d_o$}
%\label{Simulation_2}
%\end{figure} 

%\begin{figure} [htbp]
%\begin{minipage}{0.5\linewidth}
%\centering
%\includegraphics[width=1.6in]{Minimum_relative_dis.pdf}
%%\caption{0s}
%\end{minipage}%
%\begin{minipage}{0.5\linewidth}
%\centering
%\includegraphics[width=1.6in]{Maximum_relative_dis.pdf}
%%\caption{3s}
%\end{minipage}
%\caption{The minimum and maximum relative distance between robots}
%\label{Simulation_3}
%\end{figure} 

Another constraints are the link distance constraint in Equation (\ref{eq2d}) and velocity constraint. The link distance $\rho_{il}$ are maintained as in Fig. \ref{Simulation_1}. Here, the upper bounds of velocities are $\bar v = 1.8m/s$ and $\bar \omega = 1.8rad/s$. Based on above parameters, the constraint velocities should satisfy $\vert v_i^o\vert \le 0.2m/s$ and $\vert \omega_i^o\vert \le 0.2rad/s$ as in Fig. \ref{Simulation_3}. Furthermore, the rotation angles of cameras for leader tracking are shown beside the constraint velocities. In general, the system can finally transport the payload to the goal and preserve related constraints.       

%\begin{figure} [htbp]
%\begin{minipage}{0.5\linewidth}
%\centering
%\includegraphics[width=1.6in]{Minimum_Link_dis.pdf}
%%\caption{0s}
%\end{minipage}%
%\begin{minipage}{0.5\linewidth}
%\centering
%\includegraphics[width=1.6in]{Camera_rotation.pdf}
%%\caption{3s}
%\end{minipage}
%\caption{The minimum link distance and camera rotation angles}
%\label{Simulation_4}
%\end{figure}  

% The camera on Follower 1 rotates in the positive direction to search for Follower 3, while Follower 2 turns in the negative direction to include Follower 1 and 3. For the Follower 3, it rotates around zero due to the expected robot relative configuration.   
\begin{figure} [htbp]
\vspace{-0.3cm}
\begin{minipage}{0.5\linewidth}
\centering
\includegraphics[height=1.2in]{simulation_new_5.pdf}
%\caption{0s}
\end{minipage}%
\begin{minipage}{0.5\linewidth}
\centering
\includegraphics[height=1.2in]{simulation_new_6.pdf}
%\caption{3s}
\end{minipage}
\caption{The constraint velocities $v_i^o$ and $\omega_i^o$, ${}^i\theta_e$ and $\delta_c$}
\label{Simulation_3}
\vspace{-0.45cm}
\end{figure} 

Besides, we compare ours with other trajectory generation and trajectory tracking methods on our Acer Predator laptop with i7-12700H CPU as in Table \uppercase\expandafter{\romannumeral1}, where we randomly select $10$ execution results of each method to calculate the mean and standard deviation. Since most trajectory generation algorithms are done offline based on global maps, we record the time spent by them in offline planning. Compared to the tens of seconds they spend offline, our robots plan in real time and spend on average less than 0.1 ms per step. As for trajectory tracking under constraints, other methods like Cascade QP and HQP consumes a few hundred milliseconds per step, while our scheme only takes about 0.2 ms in a distributed configuration. Here, when calculating the consuming time of our method, we first average the consuming time of all robots as $t_a$. Then, the results are calculated by taking $t_a$ at different moments, which also applies to the experiment part.

\subsection{Robot Formation Experiments}
In this part, the experiment is performed by three nonholonomic mobile robots to verify our strategies. As in Fig. \ref{experiment}, these robots are divided into one leader and two followers. The robot formation is required to transport the suspended payload to the goal $\boldsymbol{p}_g=[5.5, 2]^T(m)$, with constraints in Equation (\ref{eq2a})-(\ref{eq2f}) preserved. Besides, the video of simulation and experiment can be found via the link \href{https://youtu.be/qAHkj-s8STE}{https://youtu.be/qAHkj-s8STE}.    
%In this section, the actual formation control experiment is accomplished with our proposed strategies. As shown in Fig. \ref{experiment}, two nonholonomic mobile robots are applied, including one leader robot and one follower. There is a green ball on the leader robot to serve as the feature point for recognition. The follower robot is equipped with the 2-DOF rotating camera for tracking and a laser scanner for obstacle detection as discussed before. In practice, the collision-free trajectory for the leader robot in unknown environment can be generated with the methods in \cite{A.S.2013, B.T.2007}. Here, without loss of generality, we input an arbitrary collision-free path to the leader robot and observe the reaction of the follower without environment map. The video recording of this formation experiment can be found with the link \href{https://youtu.be/CNvtz5Vo-Dk}{https://youtu.be/CNvtz5Vo-Dk}.                
%\begin{figure}[htbp]
%\centering
%\includegraphics[width=2.8in]{IMG_0020(copy).jpg}  
%\caption{Formation experiments in unknown obstacle districts}
%\label{experiment}
%\end{figure}
%
%\begin{figure}[htbp]
%\centering
%\includegraphics[width=2in]{IMG_0103.jpg}  
%\caption{Formation experiments in unknown obstacle districts}
%\label{experiment}
%\end{figure}
\begin{figure} [htbp]
\vspace{-0.35cm}
\begin{minipage}{0.5\linewidth}
\centering
\includegraphics[width=1.85in]{cooperative_trans.jpg}
%\caption{0s}
\end{minipage}%
\begin{minipage}{0.54\linewidth}
\centering
\includegraphics[width=1.38in]{IMG_0103.jpg}
%\caption{3s}
\end{minipage}
\caption{Actual cooperative transportation system and the rotating camera}
\label{experiment}
\vspace{-0.35cm}
\end{figure}

The desired trajectory tracking displacements for followers are ${}^1\boldsymbol{c}_l^d =[1.4,-0.5]^T (m)$ and ${}^2\boldsymbol{c}_l^d =[1.4,0.5]^T (m)$ with $R_f \approx 0.8m$. The robot trajectories are illustrated in the left of Fig. \ref{experiment_1}, where the red line corresponds to the leader, the green line and brown line are for Follower 1 and 2. The trajectory tracking errors for followers are provided in the right, which converge to zero finally. In the following figures, the blue line records data about Follower 1, the red line is for Follower 2.                      

%In this experiment, the expected distance in the $x$ axis is set as $2m$, while it is $-0.25m$ in $y$ direction. The maximum value $x_{lf}^{\max}$ is $5m$, while $x_{lf}^{\min}$ is equal to $0.9m$ and $\alpha_{\max}$ is $1.3rad$. As for the bounds of velocities, $\bar{\tau}_l = 0.5m/s$, $\bar{\tau}_f = 2m/s$, $\bar{\omega}_f = 1.2rad/s$, $\overline{\omega}_{r}^h = \pi rad/s$, $\overline{\omega}_{r}^v = \pi rad/s$. The parameters of image are $u_{\max} = 640$, $v_{\max} = 480$, $\alpha_u = 608.661$, $\alpha_v = 608.882$, $a_v = 0.105$, $u_s = 130$ and $v_s = 170$. The threshold for obstacle avoidance is $d_t = 0.9m$ and safety distance is $d_s = 0.3m$. The control parameters like $k_p$, $k_q$ and $k_o$ are set as $0.001$, while $\gamma_p$ and $\gamma_q$ are $0.08$.

%\begin{figure}[htbp]
%\centering
%\includegraphics[width=2.3in]{map.png}  
%\caption{Trajectories of robots and payload in the experiment}
%\label{Simulation_env}
%\end{figure}  
\begin{figure} [htbp]
\begin{minipage}{0.5\linewidth}
\centering
\includegraphics[width=1.6in,height=1.3in]{map.png}
%\caption{0s}
\end{minipage}%
\begin{minipage}{0.5\linewidth}
\centering
\includegraphics[width=1.8in,height=1.4in]{experiment_new_one.pdf}
%\caption{3s}
\end{minipage}
\caption{Robot trajectories in RVIZ, ${}^i{x}_e$, ${}^i{y}_e $ and ${}^i{\theta}_e $}
\label{experiment_1}
\vspace{-0.6cm}
\end{figure} 

The relative distance $\Vert {}^i\bm{p}_j \Vert$, the obstacle distance $\rho_{io}$ and angle $\alpha_{io}$ are shown in Fig. \ref{experiment_2}. Here, $c_{\max}=5m$, $l=0.7m$, $d=0.83m$ approximately, $\rho_=0.5m$, $\rho_o=0.3m$, $\delta_r = 0.3m$, $\delta_o = \delta_l = 0.3m$, $R_s=0.36m$, $r_{+}=1.325$, $r_{-}=0.65$, $h_0=0.1m$ and $h_{\min}=0.05m$. Thus, the lower bound of distance between two followers is $\max\{\rho_c,r_{-}\}=0.65m$, while the upper bound is $\min\{c_{\max},r_{+}\}=1.325m$. For each leader-follower pair, the bounds are $0.97m$ and $1.96m$. As shown, the constraints of relative distance and obstacle avoidance are preserved. Besides, $\vert \alpha_{io} \vert$ changes towards $\frac{\pi}{2}$, which obeys the former analysis. The results of $\rho_{il}$ are omitted here, because they are nearly the same as $\rho_{io}$ in our lab environment.

\begin{figure} [htbp]
\vspace{-0.3cm}
\begin{minipage}{0.5\linewidth}
\centering
\includegraphics[width=1.75in]{experiment_new_two.pdf}
%\caption{0s}
\end{minipage}%
\begin{minipage}{0.5\linewidth}
\centering
\includegraphics[width=1.75in]{experiment_new_three.pdf}
%\caption{3s}
\end{minipage}
\caption{$\Vert {}^i\bm{p}_j \Vert$, obstacle measurements, robot velocities and camera angles, where the yellow line describes $\Vert {}^1\bm{p}_2 \Vert$ in the first figure and the leader data in the following two.}
\label{experiment_2}
\vspace{-0.3cm}
\end{figure}

As for velocities, the leader velocity is bounded by $\tilde{v}_l=0.2m/s$ and $\tilde{\omega}_l=0.3rad/s$, while the follower velocity is constrained within $\bar v=1.2m/s$ and $\bar \omega = \frac{5\pi}{6}rad/s$ according to robot datasheet. Here, $c_1=0.2$, $c_2=0.4$, $c_3=0.4$, $k_{v}^o=0.1$, $k_{\omega}^o=0.3$. As in Fig. \ref{experiment_2}, velocities of two followers are limited within robot maximum velocities. Furthermore, $\delta_c=0.4rad$ and $k_c=1$. As illustrated, the follower camera is rotated actively to catch the leader. From the experiment results, we know that the payload is transported to the goal, with all related constraints preserved. Furthermore, the average time for each update in our algorithm is only $0.0087 \pm 0.0011$ ms on C++ platform, which is quite time-efficient compared with HQP methods taking at least $4$ ms per update.  

%The performance of obstacle avoidance is shown in Fig. \ref{u_and_horizontal}. When the distance $d_o$ is lower than $d_t$, the robot will come into transition district and attempt to steer away from obstacles as shown in the time interval $20-40s$, $80-110s$ and $120-130s$. In the transition area, the follower robot adjusts its heading angle and drives the relative angle $\alpha_{fo}$ to the direction $|\alpha_{fo}|>\frac{\pi}{2}$ for obstacle avoidance. It can be roughly concluded that nearby obstacles are kept away from the follower robot with our proposed methods. 

%The results of this experiment are listed as follows. In Fig. \ref{Obstacle_avoidance}, the corresponding pixels of the feature point on the follower's image plane and rotation angles of two motors are illustrated. It is shown that the $u$ pixel is always kept in the range $[0,u_{\max}]$. When the value of $u$ is lower than $u_s$ or higher than $u_{\max}-u_s$, the angle of horizontal motor will increase or decrease to prevent the feature point from running out of view. Also, the value of $v$ and the angle of vertical motor keep the similar relationships, and $v$ always remains in $[0,v_{\max}]$. Obviously, our design of 2-DOF rotating camera can decrease risks of tracking loss significantly. 

%Besides, the relative positions are measured by the overhead localization system and shown in Fig. \ref{Obstacle_avoidance}. We can know that the relative distance finally converges to the neighborhood of expected
% The relative positions may deviate from $x_i^d$ and $y_i^d$ when there are obstacles nearby, especially in $y$ direction. It is because the robot has to steer a sharp turn to avoid possible collisions, which may cause large fluctuations in $y_i^e$ and the heading angle $\theta_i$. Instead, when the follower robot runs away from dangerous areas, the relative positions will return back to the desired values as normal. From the experiment results, we know that the payload can be transported to the desired position, with all the related constraints preserved.
%\begin{figure} [htbp]
%\begin{minipage}{0.5\linewidth}
%\centering
%\includegraphics[width=1.55in]{new_exp_three.pdf}
%%\caption{0s}
%\end{minipage}%
%\begin{minipage}{0.5\linewidth}
%\centering
%\includegraphics[width=1.55in]{new_exp_four.pdf}
%%\caption{3s}
%\end{minipage}
%\caption{Distance and relative angle towards obstacle}
%\label{Obstacle_avoidance}
%\end{figure}    


% An example of a floating figure using the graphicx package.
% Note that \label must occur AFTER (or within) \caption.
% For figures, \caption should occur after the \includegraphics.
% Note that IEEEtran v1.7 and later has special internal code that
% is designed to preserve the operation of \label within \caption
% even when the captionsoff option is in effect. However, because
% of issues like this, it may be the safest practice to put all your
% \label just after \caption rather than within \caption{}.
%
% Reminder: the "draftcls" or "draftclsnofoot", not "draft", class
% option should be used if it is desired that the figures are to be
% displayed while in draft mode.
%
%\begin{figure}[!t]
%\centering
%\includegraphics[width=2.5in]{myfigure}
% where an .eps filename suffix will be assumed under latex, 
% and a .pdf suffix will be assumed for pdflatex; or what has been declared
% via \DeclareGraphicsExtensions.
%\caption{Simulation results for the network.}
%\label{fig_sim}
%\end{figure}

% Note that the IEEE typically puts floats only at the top, even when this
% results in a large percentage of a column being occupied by floats.


% An example of a double column floating figure using two subfigures.
% (The subfig.sty package must be payloaded for this to work.)
% The subfigure \label commands are set within each subfloat command,
% and the \label for the overall figure must come after \caption.
% \hfil is used as a separator to get equal spacing.
% Watch out that the combined width of all the subfigures on a 
% line do not exceed the text width or a line break will occur.
%
%\begin{figure*}[!t]
%\centering
%\subfloat[Case I]{\includegraphics[width=2.5in]{box}%
%\label{fig_first_case}}
%\hfil
%\subfloat[Case II]{\includegraphics[width=2.5in]{box}%
%\label{fig_second_case}}
%\caption{Simulation results for the network.}
%\label{fig_sim}
%\end{figure*}
%
% Note that often IEEE papers with subfigures do not employ subfigure
% captions (using the optional argument to \subfloat[]), but instead will
% reference/describe all of them (a), (b), etc., within the main caption.
% Be aware that for subfig.sty to generate the (a), (b), etc., subfigure
% labels, the optional argument to \subfloat must be present. If a
% subcaption is not desired, just leave its contents blank,
% e.g., \subfloat[].


% An example of a floating table. Note that, for IEEE style tables, the
% \caption command should come BEFORE the table and, given that table
% captions serve much like titles, are usually capitalized except for words
% such as a, an, and, as, at, but, by, for, in, nor, of, on, or, the, to
% and up, which are usually not capitalized unless they are the first or
% last word of the caption. Table text will default to \footnotesize as
% the IEEE normally uses this smaller font for tables.
% The \label must come after \caption as always.
%
%\begin{table}[!t]
%% increase table row spacing, adjust to taste
%\renewcommand{\arraystretch}{1.3}
% if using array.sty, it might be a good idea to tweak the value of
% \extrarowheight as needed to properly center the text within the cells
%\caption{An Example of a Table}
%\label{table_example}
%\centering
%% Some packages, such as MDW tools, offer better commands for making tables
%% than the plain LaTeX2e tabular which is used here.
%\begin{tabular}{|c||c|}
%\hline
%One & Two\\
%\hline
%Three & Four\\
%\hline
%\end{tabular}
%\end{table}


% Note that the IEEE does not put floats in the very first column
% - or typically anywhere on the first page for that matter. Also,
% in-text middle ("here") positioning is typically not used, but it
% is allowed and encouraged for Computer Society conferences (but
% not Computer Society journals). Most IEEE journals/conferences use
% top floats exclusively. 
% Note that, LaTeX2e, unlike IEEE journals/conferences, places
% footnotes above bottom floats. This can be corrected via the
% \fnbelowfloat command of the stfloats package.




\section{Conclusion}
This paper proposes a new cooperative transportation scheme for nonholonomic mobile robots using a leader-follower approach. Unlike most existing methods, it combines low computational complexity with scalable constraints, is distributed, and operates without prior environment maps. However, it still depends on inter-robot communication and does not consider payload dynamics or force balance. Future work will address these limitations and explore more cost-effective solutions.
    


% ours considers more practical and challenging conditions including nonholonomic motion constraints, the absence of prior environment maps and global localization systems, the limited FOV of camera and requirements for payload protection and actuator saturation. Based on the leader-follower structure, several control laws are proposed for the leader and followers relatively. Consequently, the leader robot can navigate to the destination without knowing the environment in advance, while the followers can track the motion of the leader and protect all constraints. However, inter-robot communication is still needed in our algorithm, which will be considered in our future works.      

%In this paper, the new image-based formation tracking strategy is proposed for multi-robot systems based on the leader follower approach. With our designed 2-DOF rotatable camera, the feature point on the leader robot is always kept in the follower's image plane, and camera rotation is triggered when the feature point is about to escape. With direct visual feedbacks from the feature point, our algorithm can drive relative positions of leader-follower formation into the neighborhood of desired values. Under the help of Laser scanner, obstacle avoidance mission is achieved, while velocity saturation is ensured as well. In addition to theoretical analysis, simulation results and real experiments illustrate the effectiveness of our presented algorithm as well. In the future work, more challenging conditions like image occlusion and inter-robot collision will be further investigated.





% if have a single appendix:
%\appendix[Proof of the Zonklar Equations]
% or
%\appendix  % for no appendix heading
% do not use \section anymore after \appendix, only \section*
% is possibly needed

% use appendices with more than one appendix
% then use \section to start each appendix
% you must declare a \section before using any
% \subsection or using \label (\appendices by itself
% starts a section numbered zero.)
%


%\appendices
%\section{Proof of the First Zonklar Equation}
%Appendix one text goes here.
%
%% you can choose not to have a title for an appendix
%% if you want by leaving the argument blank
%\section{}
%Appendix two text goes here.
%
%
%% use section* for acknowledgment
%\section*{Acknowledgment}
%
%
%The authors would like to thank...
%
%
%% Can use something like this to put references on a page
%% by themselves when using endfloat and the captionsoff option.
%\ifCLASSOPTIONcaptionsoff
%  \newpage
%\fi



% trigger a \newpage just before the given reference
% number - used to balance the columns on the last page
% adjust value as needed - may need to be readjusted if
% the document is modified later
%\IEEEtriggeratref{8}
% The "triggered" command can be changed if desired:
%\IEEEtriggercmd{\enlargethispage{-5in}}

% references section

% can use a bibliography generated by BibTeX as a .bbl file
% BibTeX documentation can be easily obtained at:
% http://mirror.ctan.org/biblio/bibtex/contrib/doc/
% The IEEEtran BibTeX style support page is at:
% http://www.michaelshell.org/tex/ieeetran/bibtex/
%\bibliographystyle{IEEEtran}
% argument is your BibTeX string definitions and bibliography database(s)
%\bibliography{IEEEabrv,../bib/paper}
%
% <OR> manually copy in the resultant .bbl file
% set second argument of \begin to the number of references
% (used to reserve space for the reference number labels box)
\begin{thebibliography}{99}
\bibitem{Y.L.2023} Y. Liu, X. Tao, X. Li, A. W. Colombo and S. Hu, "Artificial Intelligence in Smart Logistics Cyber-Physical Systems: State-of-The-Arts and Potential Applications," in IEEE Transactions on Industrial Cyber-Physical Systems, vol. 1, pp. 1-20, 2023.

\bibitem{B.L.2023} B. Liu, Y. Liu, S. Hu and W. Zhe, "Opportunities and Challenges of Scheduling in Logistics Industrial Park Cyber-Physical Systems," in IEEE Transactions on Industrial Cyber-Physical Systems, vol. 1, pp. 322-334, 2023.

% \bibitem{J.C.2015} J. Chen, M. Gauci, W. Li, A. Kolling and R. Gro, "Occlusion-Based Cooperative Transport with a Swarm of Miniature Mobile Robots," in IEEE Transactions on Robotics, vol. 31, no. 2, pp. 307-321, April 2015.
\bibitem{W.Z.2016} Wang Z, Schwager M. Force-Amplifying N-robot Transport System (Force-ANTS) for cooperative planar manipulation without communication. The International Journal of Robotics Research. 2016;35(13):1564-1586.
\bibitem{Z.W.2016} Z. Wang and M. Schwager, "Kinematic multi-robot manipulation with no communication using force feedback," 2016 IEEE International Conference on Robotics and Automation (ICRA), 2016, pp. 427-432.
\bibitem{J.F.2011} Fink J, Michael N, Kim S, Kumar V. Planning and control for cooperative manipulation and transportation with aerial robots. The International Journal of Robotics Research. 2011;30(3):324-334. 
% \bibitem{G.H.2015} G. Habibi, Z. Kingston, W. Xie, M. Jellins and J. McLurkin, "Distributed centroid estimation and motion controllers for collective transport by multi-robot systems," 2015 IEEE International Conference on Robotics and Automation (ICRA), 2015, pp. 1282-1288.
\bibitem{P.G.2004} Pereira GAS, Campos MFM, Kumar V. Decentralized Algorithms for Multi-Robot Manipulation via Caging. The International Journal of Robotics Research. 2004;23(7-8):783-795.
\bibitem{J.F.2008}  J. Fink, M. A. Hsieh and V. Kumar, "Multi-robot manipulation via caging in environments with obstacles," 2008 IEEE International Conference on Robotics and Automation, 2008, pp. 1471-1476.
% \bibitem{Z.W.2005} ZhiDong Wang, Y. Hirata and K. Kosuge, "An algorithm for testing object caging condition by multiple mobile robots," 2005 IEEE/RSJ International Conference on Intelligent Robots and Systems, 2005, pp. 3022-3027.
% \bibitem{H.F.2016} H. Farivarnejad, S. Wilson and S. Berman, "Decentralized sliding mode control for autonomous collective transport by multi-robot systems," 2016 IEEE 55th Conference on Decision and Control (CDC), 2016, pp. 1826-1833.
\bibitem{W.W.2020} W. Wan, B. Shi, Z. Wang and R. Fukui, "Multirobot Object Transport via Robust Caging," in IEEE Transactions on Systems, Man, and Cybernetics: Systems, vol. 50, no. 1, pp. 270-280, Jan. 2020.
\bibitem{G.A.2009} G. Antonelli, F. Arrichiello, and S. Chiaverini, Experiments of formation control with multirobot systems using the null-space-based behavioral control, IEEE Trans. Control Syst. Technol., vol. 17, no. 5, pp. 11731182, 2009.
% \bibitem{Y.W.2020} Y. Wang, M. Shan, Y. Yue and D. Wang, "Vision-Based Flexible LeaderFollower Formation Tracking of Multiple Nonholonomic Mobile Robots in Unknown Obstacle Environments," in IEEE Transactions on Control Systems Technology, vol. 28, no. 3, pp. 1025-1033, May 2020.
\bibitem{B.E.2020} B. E. Jackson, T. A. Howell, K. Shah, M. Schwager and Z. Manchester, "Scalable Cooperative Transport of Cable-Suspended Loads With UAVs Using Distributed Trajectory Optimization," in IEEE Robotics and Automation Letters, vol. 5, no. 2, pp. 3368-3374, April 2020.
% \bibitem{V.S.2019} V. Spurny et al., Cooperative autonomous search, grasping, and delivering in a treasure hunt scenario by a team of unmanned aerial vehicles, J. Field Robot., vol. 36, no. 1, pp. 125148, 2019.
% \bibitem{Y.K.2011} Y. Kuwata and J. P. How, "Cooperative Distributed Robust Trajectory Optimization Using Receding Horizon MILP," in IEEE Transactions on Control Systems Technology, vol. 19, no. 2, pp. 423-431, March 2011.
\bibitem{D.M.2011} D. Mellinger, A. Kushleyev and V. Kumar, "Mixed-integer quadratic program trajectory generation for heterogeneous quadrotor teams," 2012 IEEE International Conference on Robotics and Automation, 2012, pp. 477-483.
\bibitem{F.A.2012} F. Augugliaro, A. P. Schoellig and R. D'Andrea, "Generation of collision-free trajectories for a quadrocopter fleet: A sequential convex programming approach," 2012 IEEE/RSJ International Conference on Intelligent Robots and Systems, 2012, pp. 1917-1922.
\bibitem{Y.C.2015} Y. Chen, M. Cutler and J. P. How, "Decoupled multiagent path planning via incremental sequential convex programming," 2015 IEEE International Conference on Robotics and Automation (ICRA), 2015, pp. 5954-5961.
% \bibitem{H.L.2017} H. Lee and H. J. Kim, Constraint-based cooperative control of multiple aerial manipulators for handling an unknown payload, IEEE Trans. Ind. Informat., vol. 13, no. 6, pp. 27802790, Dec 2017.
% \bibitem{M.A.2018} M. A. Trujillo, H. M. Becerra, D. Gmez-Gutirrez, J. Ruiz-Len, and A. Ramrez-Trevio, Priority task-based formation control and obstacle avoidance of holonomic agents with continuous control inputs, Ifac-papersonline, vol. 51, pp. 216222, 2018.
\bibitem{J.A.2015} J. Alonso-Mora, R. Knepper, R. Siegwart and D. Rus, "Local motion planning for collaborative multi-robot manipulation of deformable objects," 2015 IEEE International Conference on Robotics and Automation (ICRA), 2015, pp. 5495-5502.
\bibitem{J.A2.2015} J. Alonso-Mora, R. Knepper, R. Siegwart and D. Rus "Multi-robot formation control and object transport in dynamic environments via constrained optimization," The International Journal of Robotics Research, 36(9), pp. 10001021.
\bibitem{D.K.2021} D. Koung, O. Kermorgant, I. Fantoni and L. Belouaer, "Cooperative Multi-Robot Object Transportation System Based on Hierarchical Quadratic Programming," in IEEE Robotics and Automation Letters, vol. 6, no. 4, pp. 6466-6472, Oct. 2021.
\bibitem{N.L.2020} N. Lissandrini, C. K. Verginis, P. Roque, A. Cenedese and D. V. Dimarogonas, "Decentralized Nonlinear MPC for Robust Cooperative Manipulation by Heterogeneous Aerial-Ground Robots," 2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2020, pp. 1531-1536.
% \bibitem{F.H.2019} F. Huzaefa and Y. Liu, "Centralized Control Architecture for Cooperative Object Transportation using Multiple Omnidirectional AGVs," 2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2019, pp. 6526-6532.
% \bibitem{G.L.2017} G. Loianno and V. Kumar, "Cooperative Transportation Using Small Quadrotors Using Monocular Vision and Inertial Sensing," in IEEE Robotics and Automation Letters, vol. 3, no. 2, pp. 680-687, April 2018.
% \bibitem{M.G.2017} M. Gassner, T. Cieslewski and D. Scaramuzza, "Dynamic collaboration without communication: Vision-based cable-suspended payload transport with two quadrotors," 2017 IEEE International Conference on Robotics and Automation (ICRA), 2017, pp. 5196-5202.
% \bibitem{H.L.2018} H. Lee, H. Kim, W. Kim and H. J. Kim, "An Integrated Framework for Cooperative Aerial Manipulators in Unknown Environments," in IEEE Robotics and Automation Letters, vol. 3, no. 3, pp. 2307-2314, July 2018.
% \bibitem{H.K.2017} H. Kim, H. Lee, S. Choi, Y. Noh and H. J. Kim, "Motion planning with movement primitives for cooperative aerial transportation in obstacle environment," 2017 IEEE International Conference on Robotics and Automation (ICRA), 2017, pp. 2328-2334.
% \bibitem{T.M.2016} T. Machado, T. Malheiro, S. Monteiro, W. Erlhagen and E. Bicho, "Multi-constrained joint transportation tasks by teams of autonomous mobile robots using a dynamical systems approach," 2016 IEEE International Conference on Robotics and Automation (ICRA), 2016, pp. 3111-3117.
% \bibitem{E.S.2017} E. S. Ardakani, H. Ebel and P. Eberhard, "Transporting an elastic plate using a group of swarm mobile robots," 2017 IEEE International Conference on Advanced Intelligent Mechatronics (AIM), 2017, pp. 1393-1398.
% \bibitem{D.K.2021} D. Koung, O. Kermorgant, I. Fantoni and L. Belouaer, "Cooperative Multi-Robot Object Transportation System Based on Hierarchical Quadratic Programming," in IEEE Robotics and Automation Letters, vol. 6, no. 4, pp. 6466-6472, Oct. 2021.
\bibitem{E.A.2014} Escande A, Mansard N, Wieber P-B. Hierarchical quadratic programming: Fast online humanoid-robot motion generation. The International Journal of Robotics Research. 2014;33(7):1006-1028.
% \bibitem{K.B.2016} Kim, B., Um, T., Suh, C., Park, F. (2016). Tangent bundle RRT: A randomized algorithm for constrained motion planning. Robotica, 34(1), 202-225.
% \bibitem{B.E.2020} B. E. Jackson, T. A. Howell, K. Shah, M. Schwager and Z. Manchester, "Scalable Cooperative Transport of Cable-Suspended payloads With UAVs Using Distributed Trajectory Optimization," in IEEE Robotics and Automation Letters, vol. 5, no. 2, pp. 3368-3374, April 2020.
\bibitem{O.K.2011} O. Kanoun, F. Lamiraux and P. -B. Wieber, "Kinematic Control of Redundant Manipulators: Generalizing the Task-Priority Framework to Inequality Task," in IEEE Transactions on Robotics, vol. 27, no. 4, pp. 785-792, Aug. 2011.
% \bibitem{E.T.2018} E. Tuci, M. Alkilabi, and O. Akanyeti, Cooperative object transport in multi-robot systems: A review of the state-of-the-art, Frontier in Robotics and AI, vol. 5, 05 2018.
\bibitem{A.S.2013} A.S. Matveev, M.C. Hoy, A.V. Savkin, A method for reactive navigation of nonholonomic under-actuated robots in maze-like environments, Automatica, Volume 49, Issue 5, 2013, pp. 1268-1274, ISSN 0005-1098.
% \bibitem{Y.W.2020} Y. Wang, M. Shan, Y. Yue and D. Wang, "Vision-Based Flexible LeaderFollower Formation Tracking of Multiple Nonholonomic Mobile Robots in Unknown Obstacle Environments," in IEEE Transactions on Control Systems Technology, vol. 28, no. 3, pp. 1025-1033, May 2020.
\bibitem{J.W.2016} J. Wang and E. Olson, "AprilTag 2: Efficient and robust fiducial detection," 2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2016, pp. 4193-4198.
\bibitem{X.Y.2015} X. Yu, L. Liu, G. Feng, Trajectory Tracking for Nonholonomic Vehicles with Velocity Constraints, IFAC-PapersOnLine, Volume 48, Issue 11, 2015, Pages 918-923, ISSN 2405-8963.
% \bibitem{D.S.2018} D. Sakai, H. Fukushima and F. Matsuno, "LeaderFollower Navigation in Obstacle Environments While Preserving Connectivity Without Data Transmission," in IEEE Transactions on Control Systems Technology, vol. 26, no. 4, pp. 1233-1248, July 2018.

\bibitem{S.Z.2018} S. Zhao, D. V. Dimarogonas, Z. Sun and D. Bauso, "A General Approach to Coordination Control of Mobile Agents With Motion Constraints," in IEEE Transactions on Automatic Control, vol. 63, no. 5, pp. 1509-1516, May 2018.

\end{thebibliography}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{IMG_2241.JPG}}]
{Renhe Guan} received the Bachelor of Engineering (B.E.) degree in Automation from Harbin Institute of Technology, Harbin, China, in 2018. He completed the Doctor of Philosophy (Ph.D.) degree in Electrical and Electronic Engineering at Nanyang Technological University, Singapore, in 2024. He is currently with Harbin Institute of Technology Shenzhen, Shenzhen,
China. His research interests include advanced multi-robot coordination strategies, cooperative transportation mechanisms and vision-based servo control.
%\\ \\ 
\end{IEEEbiography}

% \begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{IMG_2241.JPG}}]
% {Jiahou Tan} received the Bachelor of Engineering (B. Eng) in Electrical-Mechatronic degree from Universiti Teknologi Malaysia (UTM), Skudai, Malaysia, in year 2016 and Doctor of Philosophy (Ph.D) degree in Biomedical Engineering at University Teknologi Malaysia (UTM), Skudai, Malaysia, in year 2020. He is conducting the research on artificial intelligence based system controller for electronics system, for example Negative Pressure Wound Therapy (NPWT) machine, UV disinfection, and Nano-meter scale precision motion system. Previously, he was appointed as R\&D Engineer in Akribis System Pte Ltd for the Precision Motion system R\&D project and Axis-Tec Pte Ltd for Semicon wafer machine R\&D project. Currently he is the registed Professional Engineer in Board of Engineer Malaysia (BEM). His research interest including artificial intelligence for electronics system, biomedical system, precision system, power electronics, image processing, and Generative AI. 
% %\\ \\ 
% \end{IEEEbiography}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{1-s2.0-S0005109823005393-fx1.jpg}}]
{Tao Liu} received his B.Eng. degree from the University of Science and Technology of China in 2014 and Ph.D. degree from The Chinese University of Hong Kong (CUHK) in 2018. From 2019 to 2022, he worked as a Postdoctoral Fellow with the Department of Mechanical and Automation Engineering, CUHK, supported by the Impact Postdoctoral Fellowship of CUHK and the RGC Postdoctoral Fellowship of the Hong Kong Research Grants Council. He is now an Associate Professor with the College of Engineering, Southern University of Science and Technology, Shenzhen, China.
Dr. Liu is a recipient of the 2019 CAA Excellent Doctoral Dissertation Award. His research interests include output regulation, nonlinear control, cooperative control, and their applications to robotic systems.
\end{IEEEbiography}


\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{wangyan.jpg}}]
{Yan Wang} received the B.E. degree in automation and the Ph.D. degree in control science and
engineering from the University of Science and
Technology of China, Hefei, China, in 2014 and
2019, respectively.


From 2019 to 2021, he was a Research Fellow with Nanyang Technological University, Singapore. From 2021 to January 2023, he was affiliated with The Hong Kong Polytechnic University, Hong Kong, and The Chinese University of
Hong Kong, Hong Kong. He is currently an Associate Professor with the School of Mechanical Electrical Engineering
and Automation, Harbin Institute of Technology Shenzhen, Shenzhen,
China. His research interests include optimal control/estimation of interconnected systems, connected vehicle system control and optimization,
and AGV schedule in flexible manufacturing systems.
%\\ \\ 
\end{IEEEbiography}

% biography section
% 
% If you have an EPS/PDF photo (graphicx package needed) extra braces are
% needed around the contents of the optional argument to biography to prevent
% the LaTeX parser from getting confused when it sees the complicated
% \includegraphics command within an optional argument. (You could create
% your own custom macro containing the \includegraphics command to make things
% simpler here.)
%\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{mshell}}]{Michael Shell}
% or if you just want to reserve a space for a photo:
%
%\begin{IEEEbiography}{Michael Shell}
%Biography text here.
%\end{IEEEbiography}
%
%% if you will not have a photo at all:
%\begin{IEEEbiographynophoto}{John Doe}
%Biography text here.
%\end{IEEEbiographynophoto}
%
%% insert where needed to balance the two columns on the last page with
%% biographies
%%\newpage
%
%\begin{IEEEbiographynophoto}{Jane Doe}
%Biography text here.
%\end{IEEEbiographynophoto}

% You can push biographies down or up by placing
% a \vfill before or after them. The appropriate
% use of \vfill depends on what kind of text is
% on the last page and whether or not the columns
% are being equalized.

%\vfill

% Can be used to pull up biographies so that the bottom of the last one
% is flush with the other column.
%\enlargethispage{-5in}



% that's all folks
\end{document}


