\section{Methodology}

% *****Table Version Start
% In this section, we present our proposed model, CryptoPulse, which consists of three major components: 1) macro market environment-based next-day fluctuation prediction, 2) price dynamics-based fluctuation prediction, and 3) market sentiment-based dual-prediction rescaling and fusion. 
% \amit{Added the preprocessing part  where I mentioned about technical indicators and also created a table for the formulas of these indicators}As part of the preprocessing step, we calculate seven technical indicators for each trading day as proposed by~\cite{oncharoen2018deep,zhai2007combining,10.1016/s0925-2312(03)00372-2}, based on price data from the previous seven days, to capture essential market patterns. The mathematical formulas of these indicators are summarized in Table~\ref{tab:technical-indicators}. An overview of the model is shown in Figure~\ref{fig:model}.

% \begin{figure}[htpb]
%     \centering
%     \includegraphics[width=\linewidth]{imgs/model.png}
%     \caption{Overview of CryptoPulse architecture for next-day closing price prediction.}\label{fig:model}
%     \vspace{-10pt}
% \end{figure}


% \begin{table}[htbp]
% \centering
% \caption{Summary of Price Features. $C_t$ is the closing price at day $t$, $L_t$ is the lowest price at day $t$, $H_t$ is the highest price at day $t$, $MA_n$ is the moving average of the past $n$ days, $LL_n$ and $HH_n$ are the lowest low and highest high in the past $n$ days, respectively.}
% \label{tab:technical-indicators}
% \vspace{-5pt}
% \begin{tabular}{ll ll}
% \toprule
% \textbf{Feature} & \textbf{Formula} & \textbf{Feature} & \textbf{Formula} \\ \midrule
% \textbf{Stochastic \%K} & $\frac{C_t - LL_n}{HH_n - LL_n}$ & \textbf{William's \%R} & $\frac{H_n - C_t}{H_n - L_n} \times 100$ \\ \addlinespace
% \textbf{Stochastic \%D} & $\frac{\sum_{i=0}^{n-1} \%K_{t-i}}{n}$ & \textbf{A/D Oscillator} & $\frac{H_t - C_{t-1}}{H_t - L_t}$ \\ \addlinespace
% \textbf{Momentum} & $C_t - C_{t-4}$ & \textbf{Disparity} & $\frac{C_t}{MA_7} \times 100$ \\ \addlinespace
% \textbf{Rate of Change} & $\frac{C_t}{C_{t-n}} \times 100$ & & \\ \bottomrule
% \end{tabular}
% \end{table}
% **table version end



% In this section, we present our proposed model, CryptoPulse, which consists of three major components: 1) macro market environment-based next-day fluctuation prediction, 2) price dynamics-based fluctuation prediction, and 3) market sentiment-based dual-prediction rescaling and fusion. 
% A critical pre-processing step is employed to prepare the input data by calculating a set of seven technical indicators for each trading day, as proposed by ~\cite{oncharoen2018deep,zhai2007combining,10.1016/s0925-2312(03)00372-2}, using price data of past few days to capture essential market patterns. 
% An overview of the model is shown in Figure~\ref{fig:model}.

In this section, we present our proposed model, CryptoPulse, which consists of three major components: 1) macro market environment-based next-day fluctuation prediction, 2) price dynamics-based fluctuation prediction, and 3) market sentiment-based dual-prediction rescaling and fusion. 
Also, an essential preprocessing step is employed to prepare the input data by calculating a set of technical indicators for each trading day, using price data of past few days to capture essential market patterns. 
An overview of the model is shown in Figure~\ref{fig:model}.

\begin{figure}[htpb]
    \centering
    \includegraphics[width=\linewidth]{imgs/model.png}
    \caption{Overview of CryptoPulse architecture for next-day closing price prediction.}\label{fig:model}
    \vspace{-10pt}
\end{figure}

\subsection{Technical Indicator-Based Preprocessing}\label{subsec:m0}
In this subsection, we incorporate seven technical indicators commonly 
used in market movement 
prediction~\cite{oncharoen2018deep,zhai2007combining,10.1016/s0925-2312(03)00372-2}, including Stochastic \%K, Stochastic \%D,
Williams \%R, Accumulation/Distribution (A/D) Oscillator, Momentum, 
Disparity 7, and Rate of Change (ROC). The detailed computation process for each indicator is outlined below.

The Stochastic \%K indicator is traditionally used to measure the current closing price relative to the lowest low and highest high over a specified period. It helps identify overbought or oversold conditions, providing signals for potential market reversal points~\cite{kaur2023data}.
\begin{equation}\label{eq:stochastic_k}
    \text{Stochastic \%K} = \frac{p_t - p_t^{-}(N)}{
        p_t^{+}(N) - p_t^{-}(N)} \times 100,
\end{equation}
where $p_t$ is the closing price on day $t$, $p_t^{-}(N)$ is the lowest 
price over the past $14$ days (i.e., $N = 14$), and $p_t^{+}(N)$ is the 
highest price over the same period. 
A Stochastic \%K value above 80 implies that the asset may be overbought, 
while values below 20 suggest it may be oversold.

The Stochastic \%D is a 3-day simple moving average of the Stochastic \%K 
line. This smoothed indicator provides a clearer trend by eliminating
the noise present in the \%K line, and is often used to confirm buy or 
sell signals by traders~\cite{kaur2023data}:
\begin{equation}\label{eq:stochastic_d}
    \text{Stochastic \%D} = \frac{\sum_{i=0}^{n-1} \%K_{t-i}}{N},
\end{equation}
where $\%K_{t-i}$ is the Stochastic \%K value on the $i$-the previous day, and $N = 3$ the number of periods for the moving average.

Williams \%R is a momentum indicator that measures the level of the closing price relative to the high-low range over a specified period, usually 14 days. The indicator ranges from -100 to 0, with readings below -80 indicating oversold conditions and readings above -20 indicating overbought conditions. This indicator provides insights into potential price reversals based on market sentiment~\cite{kaur2023data}:

\begin{equation}\label{eq:williams_r}
    \text{Williams \%R} = \frac{p_t^{+}(N) - p_t}{
    p_t^{+}(N) - p_t^{-}(N)} \times 100,
\end{equation}
where $p_t^{+}(N)$ is the highest price over the past $14$ days (i.e., $N = 14$),
$p_t^{-}(N)$ is the lowest price over the same time, and $p_t$ is the closing price on day $t$.

The Accumulation/Distribution (A/D) Oscillator measures the cumulative buying and selling pressure in the market. It is calculated by taking the difference between the A/D line and its moving average. A rising A/D Oscillator suggests that buying pressure is increasing, which may indicate a bullish trend, while a declining oscillator may suggest bearish sentiment~\cite{article}:
\begin{equation}\label{eq:ad_oscillator}
    \text{A/D Oscillator} = \frac{p_t - p_{t-1}}{p_t^{+} - p_t^{-}},
\end{equation}
where $p_t^{+}$ is the highest price on day $t$, $p_t^{-}$ is the lowest price on day $t$, and $p_{t-1}$ is the closing price on the previous day.

The Momentum indicator measures the rate of change of a security's price over a specified period. This indicator can signal potential reversals or continuations in trends. A rising momentum indicates that the price is increasing at an accelerating rate, while a declining momentum suggests a deceleration in price movement:
\begin{equation}\label{eq:momentum}
    \text{Momentum} = p_t - p_{t-N},
\end{equation}
where $p_t$ is the closing price at day $t$ and $p_{t-N}$ is the closing price $10$ days prior to day $t$. We set $N$ to 10.



Disparity 7 compares the current price of a security to a 7-day moving average. A positive disparity indicates that the price is above the moving average, suggesting overbought conditions, while a negative disparity indicates that the price is below the moving average, suggesting oversold conditions. This indicator helps traders assess the strength of price movements relative to historical averages:
\begin{equation}\label{eq:disparity_index}
    \text{Disparity 7} = \frac{p_t}{
    \text{mov\_avg}_t(7)} \times 100,
\end{equation}
where $p_t$ is the closing price on day $t$ and
$\text{mov\_avg}_t(7)$ is the 7-day moving average of the closing price.

At last, the Rate of Change (ROC) measures the speed at which the price changes over a specified period. It is calculated by comparing the current price to the price from a specific number of periods ago. A high ROC indicates a rapid price increase, while a low or negative ROC may indicate a price decline. This indicator is useful for identifying potential trend reversals and assessing market momentum~\cite{kaur2023data}:
\begin{equation}\label{eq:roc}
    \text{Rate of Change} = \frac{p_t}{p_{t-N}} \times 100,
\end{equation}
where $p_t$ is the closing price on day $t$, and $p_{t-N}$ is the closing price $12$ days ago, with $N = 12$. 

\subsection{Macro Market Environment-Based Fluctuation Prediction}\label{subsec:m1}

% In this paper, we propose using the collective behavior of the top $k$ cryptocurrencies as a proxy for the macro investment environment's impact on the crypto market. 
% Moreover, we aim to leverage this macro environment to directly predict the next-day price fluctuations of a target cryptocurrency.

The overall macro market environment (e.g., gold and dollar value, policy and public attention, etc.) plays a crucial role in influencing cryptocurrency price volatility~\cite{dastgir2019causal}. 
However, directly quantifying the macro investing environment remains challenging and most existing studies~\cite{dyhrberg2016bitcoin, gandal2016can} narrow their focus to specific market indicators for particular cryptocurrencies. 
In this paper, we propose leveraging the collective behavior of the top $n$ cryptocurrencies as a proxy to understand the macro investment environment's influence on the cryptocurrency market. 

Mathematically, let $\mathbf{x}_{g} \in \mathbb{R}^{L \times 5}$ represent a length-$L$ series of observations from the target cryptocurrency, extracted from $\mathbf{c}_i$. 
Note that we did not use the technical indicators.
Only the first five direct market data points are used: opening price, closing price, high, low, and trading volume.
Similarly, let $\mathbf{x}_m \in \mathbb{R}^{n \times L \times 5}$ denote a corresponding series of the same length $L$, derived from historical price observations of the top $n$ cryptocurrencies by market capitalization.
We first process these series by embedding their values and positions using a 1D convolutional layer along the temporal dimension and a sinusoidal positional encoding layer~\cite{vaswani2017attention}, then add these embeddings separately for each series.
The resulting embedded observations are represented as $\mathbf{x}_g^{\text{emb}} \in \mathbb{R}^{L \times d_m}$ and $\mathbf{x}_m^{\text{emb}} \in \mathbb{R}^{L \times d_m}$, respectively.

Next, we seek to modulate the correlation and interaction between price fluctuation patterns embedded in the target cryptocurrency information $\mathbf{x}_g^{\text{emb}}$ and the macro environment represented by $\mathbf{x}_m^{\text{emb}}$.
We formulate this task as \textit{directing the model to learn which sub-series of market behaviors from the top $n$ cryptocurrencies can be aggregated to most effectively approximate the macro investing environment}:
\begin{equation}
    \mathbf{h}_{m} = \sum_{\tau}a_{\tau}\mathbf{r}_{\tau}, 
    \mathbf{r}_{\tau} = \text{roll}\left(\mathbf{x}_m^{\text{emb}}, \tau\right),
\end{equation}
where $\mathbf{h}_{m} \in \mathbb{R}^{L \times d_m}$ represents the learned representation of the macro investing environment, and the function $\text{roll}(\cdot, \tau)$ cyclically shifts the input tensor along the temporal dimension by $\tau$ steps.
The attention weight $a_{\tau}$ for each sub-series is calculated by using the target cryptocurrency $\mathbf{x}_g^{\mathrm{\text{emb}}}$ as the query, while all possible shifts of $\mathbf{x}_m^{\text{emb}}$ serve as both keys and values:
\begin{equation}
    a_{\tau} = \text{Softmax}\left(
        \text{attn}(\mathbf{x}_g^{\text{emb}}, \mathbf{r}_{1}), \ldots, 
        \text{attn}(\mathbf{x}_g^{\text{emb}}, \mathbf{r}_{L - 1}).
        \right)
\end{equation}


Technically, the attention function $\text{attn}(\cdot, \cdot)$ can be any time series similarity function. In our experiments, we utilize the period-based similarity calculation method, as introduced in the paper~\cite{wu2021autoformer}. 

At last, we use the learned macro investing tensor $\mathbf{h}_{m}$ to directly predict the next day's closing price fluctuation of the target cryptocurrency $\Delta_{L + 1}^{i, 1}$.
Specifically, $\mathbf{h}_{m}$ goes through a position-wise feed-forward layer~\cite{vaswani2017attention}, followed by two separate linear layers along the temporal and feature dimensions. 
Since these linear layers are used multiple times in this paper, we will refer to this process as $\zeta(\cdot)$ in the subsequent sections. 
The estimated fluctuation is then employed to generate the first prediction for the next-day price: $\hat{p}_{L+1}^{i, 1} = p_{L}^{i} + \kappa\Delta_{L + 1}^{i, 1}$, where $\kappa$ is a scaling factor whose calculation is detailed in Section~\ref{subsec:sent}.
In our experiments, we use the top 5 cryptocurrencies to approximate the macro environment.

\subsection{Price Dynamics-Based Fluctuation Prediction}
The task of predicting the next day's closing price, based on
historical observations and technical indicators of the target 
cryptocurrency $\mathbf{x}_g$ falls under multivariate to
univariate time series forecasting. 
However, we observed that allowing the model to directly predict the next day's price results in poor projections. 
We believe this issue stems from the extreme volatility of cryptocurrencies, which can cause the model to make overly drastic predictions. 
This problem can be mitigated by first predicting the next day's fluctuation and then using the previous day's closing price to reconstruct the next day's price:
\begin{equation}\label{eq:pred2}
    \hat{p}_{L+1}^{i, 2} = p_{L}^{i} + \kappa\Delta_{L + 1}^{i, 2},  \Delta_{L + 1}^{i, 2} = f(\mathbf{x}_g),
\end{equation}
where $\hat{p}_{L+1}^{i, 2}$ is the second price prediction, which is 
constructed based on the predicted fluctuation ($\Delta_{L + 1}^{i, 2}$) 
and the last observed price $p_{L}^{i}$, $\kappa$ is a scaling factor 
introduced in Section~\ref{subsec:sent} and $f$ is our prediction model.
In terms of model design, we observed that Transformer layers and linear layers often yield comparable results, a phenomenon also noted in the study~\cite{zeng2023transformers}. 
For efficiency in computation, we modified the NLinear structure~\cite{zeng2023transformers} to forecast $\Delta_{L + 1}^{i, 2}$. 
Specifically, a linear layer along the timeline is applied on $\mathbf{x}_g$ with a last-day closing price based normalization.


\subsection{Market Sentiment-Guided Dual-Prediction Rescaling and Fusion}\label{subsec:sent}
% Investors, especially in this volatile market, often react strongly to news signaling potential positive or negative changes, such as regulatory updates or fraud reports~\cite{schulp2022crypto}. 
% While traditional sentiment analysis models~\cite{xu2019bert, vo2019sentiment} rely on manually annotated datasets tailored to specific scenarios, this approach is labor-intensive and not scalable for real-time analysis in dynamic environments like the cryptocurrency market. To address this challenge, we propose using a few-shot learning-based prompting method to leverage large language models (LLMs) for the automatic analysis of sentiment in cryptocurrency news, thereby minimizing the need for extensive manual labeling.

% as follows: 
% \begin{quote}
%     Given the news, assign a sentiment label from ["negative", "positive", "neutral"] to describe how the news could influence the cryptocurrency market sentiment. Return only the label without any other text.\\
%     News:[News content]\\
%     Label:[True sentiment label]
% \end{quote}
% Then the target news is presented, followed by an empty \textit{Label} for the LLMs to answer.

As mentioned in Section~\ref{sec:intro}, news media significantly influences fluctuations in cryptocurrency markets~\cite{10.1098/rsos.220276,10.22541/au.167285886.66422340/v1, schulp2022crypto}. 
However, incorporating this factor into prediction models is challenging because traditional sentiment analysis models~\cite{xu2019bert, vo2019sentiment} often rely on datasets manually annotated for specific scenarios, which are not scalable for real-time analysis in the dynamically changing cryptocurrency market.
The recent advancements in LLMs offer an alternative approach for sentiment analysis without requiring extensive fine-tuning on annotated datasets. Nevertheless, designing an effective prompting strategy is crucial for analyzing cryptocurrency news, as recent studies~\cite{white2023prompt} have found that prompt patterns significantly influence the responses of LLMs across various tasks.

% In this paper, we propose a prompt pattern that combines few-shot learning with a consistency-based calibration approach for effective cryptocurrency news sentiment analysis. Inspired by recent research suggesting that few-shot in-context learning enhances LLM accuracy and reliability~\cite{zhang2023sentiment, si2022prompting}, our prompt pattern begins with a task description followed by $k$ examples (i.e., 3-way-$k$-shot learning). The target news is then presented with an empty \textit{Label} for the LLMs to complete. However, we identified two drawbacks: the LLM's responses are unstable, and the model's performance is vulnerable to noisy contexts, common in cryptocurrency news. By simulating environments with manual adversarial attacks, we observed that misleading sentences could reduce LLM accuracy and increase misclassification.

% To address this, we integrated a 'think-tank discussion'-like prompt pattern, simulating a scenario where cryptocurrency traders collaboratively determine market sentiment. The proposed prompt repeats the following block multiple times with different examples:
% \begin{quote}
%     [m] different cryptocurrency traders read this news. Each trader assigns a sentiment label from ["negative", "positive", "neutral"]. They then share their labels, and the majority label is accepted. Return only the majority label. The news is [news content]. Label: [True sentiment label]
% \end{quote}
% This pattern enhances response stability and accuracy. It aligns with consistency-based calibration methods~\cite{wang2022self, zhang2024don}, where the agreement among LLM 'voters' determines the confidence score, and the response with the highest confidence is selected. Our method is more efficient and cost-effective, as it avoids running the LLM multiple times for confidence collection. In our experiments, we set $m$ to 3 and used GPT-3.5-Turbo~\cite{ouyang2022training} for sentiment analysis of all news articles collected from Cointelegraph.

In this paper, we combined a ``think-tank discussion''-like prompt pattern with the few-shot learning technique to simulate a situation where a group of cryptocurrency traders collaboratively determines the market's reaction to specific news. 
Recent work suggests that few-shot learning can enhance accuracy and reliability~\cite{zhang2023sentiment, si2022prompting}. However, we found that few-shot learning alone is insufficient.
Firstly, the LLM's responses are unstable and sometimes yield different outcomes even with the same prompt. Secondly, the model's performance is vulnerable to noisy contexts, which are common in cryptocurrency news. For example, sentences like ``the movie is good,'' if injected into the news, could increase misclassification.
As a result, we incorporated a ``think-tank discussion''-like prompt pattern into the few-shot learning technique by repeating the following block multiple times with $k$ examples for three different sentiment labels (i.e., 3-way-$k$-shot learning):
\begin{quote}
    [m] different cryptocurrency traders are reading this news. Each trader will assign a sentiment label from [``negative'', ``positive'', ``neutral'']. Then, each trader will share their label with the group. The majority label will be accepted. Return the majority label without any other text. The news is [news content] Label: [True sentiment label]
\end{quote}
It's worth noting that this approach aligns with consistency-based calibration methods~\cite{wang2022self, zhang2024don}, which use agreement scores among LLM ``voters'' to determine confidence. Our method, however, is more efficient and cost-effective, as it doesn't require running the LLM multiple times with the same prompt. In our experiments, we set $m$ to 3 and used GPT-3.5-Turbo~\cite{ouyang2022training} for sentiment analysis. %on all news articles collected from Cointelegraph.


% We observed that this prompt pattern enhances the stability and accuracy of responses in general. 
% Moreover, this approach aligns with the philosophy of consistency-based calibration methods~\cite{wang2022self, zhang2024don}, where the agreement score among different LLM ``voters'' is considered the confidence score of a response, and the response with the highest confidence score is selected. 
% However, our method is more efficient and cost-effective, as it doesn't require running the LLM multiple times with the same prompt to collect the most confident results. 
% In experiments, we set $m$ to 3 and used GPT-3.5-Turbo~\cite{ouyang2022training} to complete the sentiment analysis for all news articles collected from Cointelegraph. 

% In this paper, we propose a prompt pattern that combines a few-shot learning-based technique with a consistency-based calibration approach for effective cryptocurrency news sentiment analysis. 
% Specifically, we designed 

% Inspired by recent research suggesting that few-shot in-context learning can enhance the accuracy and reliability of LLMs~\cite{zhang2023sentiment, si2022prompting}, we initially design our prompt pattern to begin with a task description followed by $k$ examples (i.e., $k$-shot learning).
% However, we observed two drawbacks with this approach. 
% Firstly, the LLM's responses are unstable and sometimes yield different outcomes even if the prompt is the same.
% Secondly, the model's performance is vulnerable to noisy contexts which is common in cryptocurrency news.
% For example, we found that sentences like ``the movie is good,'' if injected into the news, could increase misclassification.

% We combined a ``think-tank discussion''-like prompt pattern with the above strategy to simulate a situation where a group of cryptocurrency traders collaboratively determines the market's reaction to specific news.
% The proposed prompt is designed by repeating the following block multiple times with different examples (i.e., 3-way-$k$-shot learning):
% \begin{quote}
%     [m] different cryptocurrency traders are reading this news. Each trader will assign a sentiment label from ["negative", "positive", "neutral"]. Then, each trader will share their label with the group. The majority label will be accepted. Return the majority label without any other text.\\
%     The news is [news content]\\
%     Label: [True sentiment label]
% \end{quote}
% We observed that this prompt pattern enhances the stability and accuracy of responses in general. 
% Moreover, this approach aligns with the philosophy of consistency-based calibration methods~\cite{wang2022self, zhang2024don}, where the agreement score among different LLM ``voters'' is considered the confidence score of a response, and the response with the highest confidence score is selected. 
% However, our method is more efficient and cost-effective, as it doesn't require running the LLM multiple times with the same prompt to collect the most confident results. 
% In experiments, we set $m$ to 3 and used GPT-3.5-Turbo~\cite{ouyang2022training} to complete the sentiment analysis for all news articles collected from Cointelegraph. 

% For example, we simulated environments with manual adversarial attacks and found that some sentences like ``the movie is good'' in news content could increase misclassification.

% For example, we find that some sentences like ``the movie is good'' if injected into the news would could increase misclassification.

% simulated environments with manual adversarial attacks and found that some sentences like ``the movie is good'' in news content could increase misclassification.

% Specifically, we simulated such environments by introducing manual adversarial attacks and observed that misleading sentences, such as ``the movie is good,'' when inserted into the news content, could reduce the accuracy of the LLMs and increase the likelihood of misclassification.

% Firstly, the LLM's responses are unstable, with different iterations of the same prompt yielding varied outcomes. 
% Secondly, the model's performance is susceptible to noisy contexts, which are common in cryptocurrency news. 
% Specifically, we simulated such environments by introducing manual adversarial attacks and observed that misleading sentences, such as ``the movie is good,'' when inserted into the news content, could reduce the accuracy of the LLMs and increase the likelihood of misclassification.



% Then the target news is presented, followed by an empty \textit{Label} for the LLMs to answer. 
% However, we observed two drawbacks with this approach. 
% Firstly, the LLM's responses are unstable, with different iterations of the same prompt yielding varied outcomes. 
% Secondly, the model's performance is susceptible to noisy contexts, which are common in cryptocurrency news. 
% Specifically, we simulated such environments by introducing manual adversarial attacks and observed that misleading sentences, such as ``the movie is good,'' when inserted into the news content, could reduce the accuracy of the LLMs and increase the likelihood of misclassification.

% To further improve accuracy, we combined a ``think-tank discussion''-like prompt pattern with the above strategy to simulate a situation where a group of cryptocurrency traders collaboratively determines the market's reaction to specific news.
% The proposed prompt is designed by repeating the following block multiple times with different examples (i.e., 3-way-$k$-shot learning):
% \begin{quote}
%     [m] different cryptocurrency traders are reading this news. Each trader will assign a sentiment label from ["negative", "positive", "neutral"]. Then, each trader will share their label with the group. The majority label will be accepted. Return the majority label without any other text.\\
%     The news is [news content]\\
%     Label:[True sentiment label].
% \end{quote}
% We observed that this prompt pattern enhances the stability and accuracy of responses in general. 
% Moreover, this approach aligns with the philosophy of consistency-based calibration methods~\cite{wang2022self, zhang2024don}, where the agreement score among different LLM ``voters'' is considered the confidence score of a response, and the response with the highest confidence score is selected. 
% However, our method is more efficient and cost-effective, as it doesn't require running the LLM multiple times with the same prompt to collect the most confident results. 
% In experiments, we set $m$ to 3 and used GPT-3.5-Turbo~\cite{ouyang2022training} to complete the sentiment analysis for all news articles collected from Cointelegraph. 




%As a result, for each day $t$, we collected a series of sentiment labels $\mathbf{s}_t$, where $|\mathbf{s}_t| = |\mathbf{d}_t|$ because each news article has a sentiment label.
%, nor does it require calculating a confidence score for each different response.

% We observed that this prompt pattern greatly enhances the stability and accuracy of responses. 
% Moreover, this approach aligns with the philosophy of consistency-based calibration methods~\cite{wang2022self, zhang2024don}, where the agreement score among different LLM ``voters'' is considered as the confidence score of a response, and the response with the highest confidence score is selected.
% However, our method is more efficient and cost-effective, as it doesn't require running the LLM multiple times with the same prompt to collect the most confident results and does not require the calculation of a confidence score for each different response. 


% Also, we integrated this concept with the $k$-shot learning pattern by repeating a complete prompt with $k$ examples for each of the three sentiment labels.
% A complete pattern begins with a task description: ``\textit{[n] different cryptocurrency traders are reading this news. Each trader will assign a sentiment label from ["negative", "positive", "neutral"]. Then, each trader will share their label with the group. The majority label will be accepted. Return the majority label without any other text.}'', where $n$ specifies the number of traders involved in this simulated discussion.
% Following this task description, an example of news and its correct sentiment label is provided, formatted similarly to the $k$-shot learning examples.

% Cryptocurrency market sentiment is more intense and volatile than that of other financial instruments, like stocks. 
% Thus using sentiment as a feature for price prediction can introduce noise, potentially harming model performance. 
% However, we find that market sentiment can be used to regularize the direction and range of fluctuation predictions.

Using cryptocurrency market sentiment directly is challenging since it's volatile and may introduce noise into the system; however, we found that market sentiment can be used to regularize the range of fluctuation predictions.
First, we embed the sentiment vector during the observation window using the previously introduced embedding structure. 
The resulting tensor $\mathbf{s}^{\text{emb}}$ serves two purposes.
First, it passes through the $\zeta(\cdot)$ structure from 
Section~\ref{subsec:m1}, followed by a $\mathrm{Tanh}$ activation function, to produce $\kappa \in (-1, 1)$, which is used to regularize the range of price changes in the fluctuation prediction.
Second, the embedded sentiment tensor is combined with $\mathbf{x}_g^{\text{emb}}$ to determine how to fuse the previous two predictions. 
This is crucial because \textit{market environment-based predictions are less volatile, while price dynamics predictions are more volatile}, and combining them enhances the model's generality across different cryptocurrencies:
\begin{equation}
    \hat{p}_{L + 1}^{i} = \gamma * \hat{p}_{L+1}^{i, 1} + (1 - \gamma) * \hat{p}_{L+1}^{i, 2}, 
    \gamma = \zeta([\mathbf{x}_g^{\text{emb}}; \mathbf{s}^{\text{emb}}]).
\end{equation}

Mean Squared Error (MSE) between predicted and true next-day prices is 
used as the loss function. To regularize, we applied a dropout rate of 
0.1 to the output of each sublayer. For optimization, we used the ADAM 
optimizer~\cite{kingma2014adam} with an initial learning rate of 0.0005, 
which is halved after each epoch.

% is then used for two purposes. 
% First, it's fed through the $\zeta(\cdot)$ structure defined at the end of Section~\ref{subsec:m1}, followed by a $\mathrm{Tanh}$ activation function, to produce $\kappa \in (-1, 1)$, which simultaneously scales and determines the direction of price changes in the fluctuation prediction.
% Second, it is combined with the embedded observations of cryptocurrency $\mathbf{x}_g$ to fuse the market environment-based prediction and the price dynamics prediction. 
% This is crucial because the \textit{market environment-based prediction is less volatile, while the price dynamics prediction is more volatile}, and effectively combining these predictions can enhance the model's generality across different cryptocurrencies:

% Using the same embedding structure as before, we first apply value embedding and positional encoding to the sentiment vector $\mathbf{s}_{1:L}$ for the observation window.
% The obtained embedding tensor $\mathbf{s}^{\text{emb}}$ is used for two purposes. 
% First, it's fed through the $\zeta(\cdot)$ structure defined at the end of Section~\ref{subsec:m1}, followed by a $\mathrm{Tanh}$ activation function, to produce $\kappa \in (-1, 1)$, which simultaneously scales and determines the direction of price changes in the fluctuation prediction.
% Second, it is combined with the embedded observations of cryptocurrency $\mathbf{x}_g$ to fuse the market environment-based prediction and the price dynamics prediction. 
% This is crucial because the \textit{market environment-based prediction is less volatile, while the price dynamics prediction is more volatile}, and effectively combining these predictions can enhance the model's generality across different cryptocurrencies:
% \begin{equation}
%     \hat{p}_{L + 1}^{i} = \gamma * \hat{p}_{L+1}^{i, 1} + (1 - \gamma) * \hat{p}_{L+1}^{i, 2}, 
%     \gamma = \zeta([\mathbf{x}_g^{\text{emb}}; \mathbf{s}^{\text{emb}}]).
% \end{equation}


% First, it's fed through two separate linear layers along the temporal and feature dimensions followed by a $\text{Tanh}$ activation function, to produce $\kappa \in (-1, 1)$, which is used to simultaneously scales and determines the direction of price changes in the above fluctuation prediction.
% Second, it's combined with the embedded observations of crypbocurrency $\mathbf{x}_g$ to determine how the market environment based prediction and the price dynamics prediction should be fused. This is important, since, intuitively, the market environment based prediction is less volatile while the price dynamics is more volatile, and an effective combination of them could enhance the results:



% The sentiment in the cryptocurrency market is much more intense than in other financial instruments, such as stocks, due to its highly volatile nature. Thus, using sentiment as a source feature for price prediction could unexpectedly introduce extra noise, potentially harming model performance. 
% However, we find that market sentiment can serve as a useful scale and indicator to help regularize the direction and range of fluctuation predictions.
% Following the same embedding structure introduced above, we applied value embedding and positional encoding to the sentiment vector $\mathbf{s}_{1:L}$ associated with the observation window. 
% Subsequently, a simple linear transformation is applied along the temporal dimension, followed by another along the feature dimension, and at last a $\mathrm{Tanh}$ activation layer to generate an indicator $\beta$.
% We then propose a gating mechanism that automatically determines the balance between two predictions based on the less volatile macro environment and the more volatile individual price dynamics:
% \begin{equation}
%     \hat{p}_{L + 1}^{i} = p_{L}^{i} 
%                           + \gamma * \left(\beta\Delta_{L + 1}^{i, 1}\right) 
%                           + (1 - \gamma) * \left(\beta\Delta_{L + 1}^{i, 2}\right), 
%     \gamma = \mathrm{L}_m(\mathrm{L}_t([\mathbf{x}_g^{emb}, \mathbf{s}^{emb}])),
% \end{equation}
% where the embeddings of the target cryptocurrency and the sentiment for the observation window jointly determine how to balance the weights of the two predictions, with $L_t$ being a linear transformation along the temporal dimension and $L_m$ a linear transformation along the feature dimension.

%To regularize, we applied a dropout rate of 0.1 to the output of each sublayer. For optimization, we used the ADAM optimizer~\cite{kingma2014adam} with an initial learning rate of 0.0005, which is halved after each epoch.