\label{sec:appendix-exp}
In this section, we provide some supplementary experiments that are omitted in the main context due to the space limit.

\begin{figure}[h]
    \centering
    % \vspace{-8pt} 
    \includegraphics[width=1\linewidth]{figure/appendix_fig/open-source-model-evaluation.pdf}
    % \vspace{-1mm}
    \caption{Evaluation of the {mathstral-7B} and {rho-math-7b-v0.1} model.}
    \label{fig: open model evaluation}
    % \vspace{-2mm}
\end{figure}



\subsection{Supplementary evaluation of open-source models}
\label{subsection:appendix-open-source models}
In addition to the evaluation of DeepSeek model we presented in section~\ref{subsection: Reasoning-Equivalence Evaluation}, we also provide the evaluation results of {Mathstral-7B} and \texttt{Rho-math-7b-v0.1}. The results of the $8$-shot accuracy evaluation are presented in Figure~\ref{fig: open model evaluation}. The findings are consistent with those in section~\ref{subsection: Reasoning-Equivalence Evaluation} that LLMs are vulnerable to order permutation and redundancy addition.

\subsection{Supplementary results about permutation order experiments}
\label{subsection:appendix-permutation-order-experiments}
\input{table/appendix_permutation}
The supplementary experiment results about arithmetic reasoning tasks using {Llama-3.2-1B} model are shown in Table~\ref{tab:appendix-permutation}. The observations are basically the same as those in Section~\ref{subsection:exp reasoning-equivalence enhancement}: the proposed \method\ achieves the best performance in OOD scenarios against all the baseline methods.

% \begin{figure*}[t]
%     \centering
%     % \vspace{-8pt} 
%     \includegraphics[width=1\linewidth]{figure/appendix_fig/logic-3B.pdf}
%     % \vspace{-1mm}
%     \caption{Evaluation with respect to different query variations of logic reasoning dataset with the {Llama-3.2-3B} model. Each figure refers to one permutation order type, the x-axis represents the number of redundancies of the test set, and the y-axis represents the accuracy of final answers. For each dataset, we report the accuracy value over a dataset with a size of $200$. \textbf{In-distribution data:} training dataset including augmented data only covers the redundancy ranging from 0 to 4.}
%     \label{fig: logic reasoning 3B}
%     % \vspace{-2mm}
% \end{figure*}

\begin{figure*}[t]
    \centering
    % \vspace{-8pt} 
    \includegraphics[width=1\linewidth]{figure/appendix_fig/appendix-redundancy_exp.pdf}
    % \vspace{-1mm}
    \caption{Evaluations with respect to different query variations. Each figure refers to one permutation order type, the x-axis represents the number of redundancies of the test set, and the y-axis represents the accuracy of final answers. For each dataset, we report the accuracy value over a dataset with a size of $200$.}
    \label{fig: Math reasoning 1B}
    % \vspace{-2mm}
\end{figure*}

\subsection{Supplementary results about redundancy addition experiments}
\label{subsection:supplementary-exp-redundancy}
The results for logical reasoning with the base model {Llama-3.2-3B} and arithmetic reasoning with the base model {Llama-3.2-1B} are presented in Figure \ref{fig: Math reasoning 1B}. The findings are mostly consistent with those presented in Section~\ref{subsection:exp reasoning-equivalence enhancement}, showing that \method\ achieves the best performance. 
One exception is that the inference-time scaling baseline, \texttt{SCoP}, performs better in the logical reasoning tasks. This may be because the {Llama-3.2-3B} model is strong enough for this relatively easy task, allowing the inference-time scaling method to achieve good results through majority voting.



\subsection{Supplementary experiments about model probing}
\label{subsection: appendix-model-probing}
In Section~\ref{subsection: probing}, we discuss that the KNN classification method used in~\cite{hou2023towards} makes ideal assumptions and faces information aggregation issues. Here, we provide a comparison between KNN classification and the linear probing technique used in this paper. The comparison is presented in Figure~\ref{fig: exp-probing-comparison}, where we observe that although KNN probing can reveal differences between tasks with varying levels of redundancy, the F1-Macro score remains relatively low, reducing the confidence of the claims. Additionally, for harder tasks with more redundant information, the performance gap between different methods becomes minor. This is because information tends to aggregate on the beginning tokens, making it difficult to assign appropriate weights to all attention entries for information retrieval probing. Based on this experiment, we reconfirm that our linear probing technique is more suitable for revealing the model's capability.


\begin{figure}[t]
    \centering
    % \vspace{-8pt} 
    \includegraphics[width=1\linewidth]{figure/appendix_fig/probing_comparison.pdf}
    % \vspace{-1mm}
    \caption{Comparison between linear probing and KNN-based probing used in~\citep{hou2023towards}. Left: linear probing; Right: KNN-based probing.}
    \label{fig: exp-probing-comparison}
    % \vspace{-2mm}
\end{figure}



\clearpage
\newpage

\subsection{Supplementary evaluation of closed-source models}
\label{subsection: close-source model evaluation}
The Full QA pairs presented in Figure~\ref{fig: motivation} are provided the following code blocks.

% \textbf{Correct answer of DeepSeek-V3 to the original question.}
% \begin{tcolorbox}[colback=yellow!2!white, colframe=black, boxrule=0.5pt]
% \small
% \textit{""}
% \end{tcolorbox}

% \textbf{Correct answer of GPT-4 to the original question.}
% \begin{tcolorbox}[colback=yellow!2!white, colframe=black, boxrule=0.5pt]
% \small
% \textit{""}
% \end{tcolorbox}

% % \textbf{Incorrect answer of DeepSeek-V3 to Q1.}
% % \begin{tcolorbox}[colback=yellow!2!white, colframe=black, boxrule=0.5pt]
% % \small



% \end{tcolorbox}
\textbf{Incorrect answer of DeepSeek-V3 to Q1.}
\begin{tcolorbox}[
   enhanced,             % allow advanced features
   breakable,            % allow the box to split across pages
   colback=yellow!2!white,
   colframe=black,
   boxrule=0.5pt
]
\small
\begin{verbatim}
Let's break down the problem step by step to 
determine how many pieces of popcorn Gary 
has to eat.
1. **First 30 Seconds:**
   - **Popped Kernels:** 20
2. **Next 30 Seconds (30 to 60 seconds):**
   - The number of kernels that pop 
   is **three times** the amount that 
   popped in the first 30 seconds.
   - **Calculation:** \( 3 \times 20 = 60 \)
   - **Total Popped So Far:
   ** \( 20 + 60 = 80 \)
3. **After Removing from Heat (Residual Heat):
**
   - A **quarter** of the kernels that popped 
   in the last 30 seconds of cooking also pop 
   due to residual heat.
   - **Calculation:** \( \frac{1}{4} 
   \times 60 = 15 \)
   - **Total Popped So Far:** \( 80 + 15 = 95 \)
4. **Next 30 Seconds (60 to 90 seconds):**
   - The popping rate **increases by 20** 
   from the previous rate.
   - **Previous Rate:** 60 kernels per 30 
   seconds
   - **New Rate:** \( 60 + 20 = 80 \) kernels 
   per 30 seconds
   - **Total Popped So Far:** \( 95 + 80 = 175 \)
5. **Final 30 Seconds (90 to 120 seconds):**
   - The popping rate **slows down to half** 
   the rate of the past 30 seconds.
   - **Previous Rate:** 80 kernels per 
   30 seconds
   - **New Rate:** \( \frac{80}{2} = 40 \) 
   kernels per 30 seconds
   - **Total Popped So Far:** \( 175 + 40 = 215 \)
**Final Calculation:**
- **Total Popcorn Popped:** 215
However, let's verify the steps to 
ensure accuracy:
- **First 30 Seconds:** 
20 kernels
- **Next 30 Seconds:** \( 3 \times 20 = 60 \) 
kernels
- **Residual Heat:** 
\( \frac{1}{4} \times 60 = 15 \) kernels
- **Next 30 Seconds:** \( 60 + 20 = 80 \) kernels
- **Final 30 Seconds:** 
\( \frac{80}{2} = 40 \) kernels
Adding them up:
\[ 20 + 60 + 15 + 80 + 40 = 215 \]
Therefore, Gary has **215** pieces 
of popcorn to eat.
\[\boxed{215}\]
\end{verbatim}
\end{tcolorbox}

\newpage

\textbf{Incorrect answer of GPT-4 to Q2.}
\begin{tcolorbox}[colback=yellow!2!white, colframe=black, boxrule=0.5pt]
\small
\textit{"In the first 30 seconds, 20 kernels popped.
In the next 30 seconds, three times that amount popped, so 20 * 3 = <<20*3=60>>60 kernels popped.
In the next 30 seconds, four times the initial popping rate popped, so 20 * 4 = <<20*4=80>>80 kernels popped.
In the final 30 seconds, the popping slowed down to half the rate as the past 30 seconds, so 80 / 2 = <<80/2=40>>40 kernels popped.
After Garrett takes the pan off the heat, a quarter of the number of kernels that popped in the final 30 seconds of cooking also pop from the residual heat, so 40 / 4 = <<40/4=10>>10 kernels popped.
He believes that five kernels would not have popped if he had not shaken them to the center of the pan, so he has 20 + 60 + 80 + 40 + 10 + 5 = <<20+60+80+40+10+5=215>>215 pieces of popcorn to eat."}
\end{tcolorbox}
