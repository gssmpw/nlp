\section{Related Work}

Most of existing studies designed data valuation methods for CML based on two data valuation metrics: LOO~\citep{cook1977detection} and the SV~\citep{shapley1953value}. 
Since computing these metrics usually requires evaluating the model utilities for a large number of data subsets, substantial research efforts have been devoted to improving the efficiency of the computation. 
Their approaches include downsampling data subsets~\cite{ghorbani2019data, jia2019towards, luo2024fast, luo2022shapley, lin2022measuring, jia2019efficient, kwon2021efficient}, designing training-free utility functions~\citep{wang2024helpful, pruthi2020estimating, koh2017understanding}, and approximating retrained models~\citep{wu2022davinz, just2023lava, nohyun2022data}.

Another line of research focuses on enhancing the robustness and reliability of data valuation. 
Xu et al.~\yrcite{xu2021validation} designed a new utility function that is more robust to clients’ data replication behavior. 
Lin et al.~\yrcite{lin2024distributionally} provided a validation-free utility function for clients without a joinly-agreed validation dataset. 
Some studies~\citep{schoch2022cs, xu2024model, xia2024p} have designed utility functions that capture a model’s predictive capability at a finer granularity than prediction accuracy. 
Tian et al.~\yrcite{tian2024derdava} and Xia et al.~\yrcite{xia2023equitable} proposed methods to accelerate recomputing data values in machine unlearning scenarios. 
Zheng et al.~\yrcite{zheng2023secure} and Wang et al.~\yrcite{wang2024privacy} proposed methods to ensure privacy and security in data valuation.
Wang et al.~\yrcite{wang2023data} introduced the Banzhaf value as a data valuation metric, which is robust to the randomness of model retraining. 
Kwon et al.~\yrcite{kwon2022beta} extended the SV to Beta Shapley, improving the detection of noisy data points.
\textit{Our work reveals a new vulnerability in data valuation, i.e., data overvaluation, and proposes Truth-Shapley to enhance robustness/reliability against data overvaluation.}
