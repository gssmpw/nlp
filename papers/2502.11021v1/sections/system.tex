\section{Method}
\subsection{Overview} \label{sec:system_overview}
Inspired by prior work~\cite{kuhn2023semantic, Bakman2024MARSMR}, we quantify uncertainty in natural language generation based on semantic content rather than token-level variations, using it as a performance indicator for training the router.

SE~\cite{kuhn2023semantic} captures uncertainty by clustering generated outputs with equivalent meanings and computing entropy over their aggregated probabilities. Unlike traditional entropy, which treats all token sequences distinctly, SE accounts for semantic equivalence, ensuring paraphrases contribute to the same uncertainty estimate. A lower SE score indicates higher confidence, while a higher score signals greater uncertainty.

Formally, we define the probability of a meaning cluster $c$ given an input prompt $\mathbf{x}$ as:

\begin{equation}
% \[
p(c | \mathbf{x}) = \sum_{\substack{s, \mathbf{x} \in c}} p(s | \mathbf{x}).
% \]
\label{equation:cluster}
\end{equation}
The semantic entropy of $\mathbf{x}$ is then computed as:
\begin{equation}
% \[
SE(\mathbf{x}) = -\frac{1}{|C|} \sum_{i=1}^{|C|} \log p(C_i | \mathbf{x}),
% \]
\label{equation:se}
\end{equation}
where $C$ represents the set of all clusters.


\subsection{System Design of the Confidence-Driven LLM Router}
The training and deployment of the Confidence-Driven LLM Router consist of three key phases:

\noindent \textbf{Phase 1: Router Data Preparation.} 
To create a training dataset that reflects real deployment scenarios, we select factual-related datasets, such as Natural QA and Trivia QA, to probe model confidence and knowledge capabilities. Additionally, domain-specific instruction datasets can be incorporated to tailor the router to specialized applications. 

Clustering generated outputs is a critical preprocessing step before computing SE. In this work, we adopt a bidirectional entailment mechanism following the previous work~\cite{kuhn2023semantic}. The first generated response initializes a cluster. For each subsequent response, a semantic entailment classifier, fine-tuned on DeBERTa-large model~\cite{He2020DeBERTaDB}, evaluates bidirectional entailment between the response and the current cluster representative. If both forward and backward entailments hold, the response is assigned to the existing cluster; otherwise, a new cluster is formed. This bidirectional criterion ensures that only semantically equivalent responses are grouped, allowing the number of clusters to be dynamically determined based on meaning variations among generated outputs.


\noindent \textbf{Phase 2: Constructing Preference Data from Semantic Entropy Scores.}
In the second phase, we create preference data by comparing the SE scores across models for each unique prompt. Although no two SE values are exactly the same, some prompts yield similar performance between models, which we denote as a “tie” case. To identify ties, we treat cases with close uncertainty levels as equivalent, where neither model is a clear winner.
To quantify the relative difference in uncertainty, we compute the normalized SE difference between the two models as:
\vspace{-1mm}
\begin{equation}
\delta_{\text{SE}}(\mathbf{x}) = \left| \frac{SE_{\text{strong}}(\mathbf{x}) - SE_{\text{weak}}(\mathbf{x})}{SE_{\text{strong}}(\mathbf{x})} \right|
\label{equation:normalized_se}
\end{equation}
$SE_{\text{strong}}(\mathbf{x})$ represents the high-cost model, and $SE_{\text{weak}}(\mathbf{x})$ represents the low-cost model. Using this metric, we determine the preferred model as:
\begin{equation} 
\text{Winner} = 
\begin{cases} 
\arg\min\limits_{M} SE(M, \mathbf{x}) & \text{if } \delta_{\text{SE}}(\mathbf{x}) > \tau, \\
\text{Tie} & \text{otherwise}.
\end{cases} 
\label{equation:threshold} 
\end{equation}
The predefined threshold $\tau$ controls sensitivity to uncertainty differences. If $\delta_{\text{SE}}(\mathbf{x})$ exceeds the predefined $\tau$, the uncertainties are considered sufficiently distinct, and the model with the lower semantic entropy is designated as the preferred model. Otherwise, we consider both models equal in performance for the given prompt.

A higher $\tau$ enforces stricter distinctions, aligning the preference data more closely with traditional accuracy-based evaluations. Conversely, a lower $\tau$ increases sensitivity to subtle linguistic variations in model responses. By tuning $\tau$, we balance robustness with linguistic granularity.


\noindent \textbf{Phase 3: Training the Confidence-Driven Router.}
After generating the SE-based preference data in Phase 2, we format each training sample as follows: \{id, model a, model b, prompt, response a, response b, winner model a, winner model b, winner tie\}. In the last three columns, we use binary values (0 or 1) to represent the routing outcomes. For instance, if model\_a is the preferred model, then \texttt{winner\_model\_a} is set to 1, while \texttt{winner\_model\_b} and \texttt{winner\_tie} are set to 0. The dataset used in this study is now publicly available on Huggingface~\footnote{\url{https://huggingface.co/datasets/AsalMehradfar/uncertainty_0.1}}. Once the dataset is prepared, we transform the instruction records into vectorized representations using the pre-trained embedding model, which serves as inputs for training the router classifiers.

% ~\footnote{The training dataset would be available when the paper is public.}. 










