\section{Conclusion}
In-context learning with longer input sequences remains a prominent yet challenging topic in large language models (LLMs). 
In this work, we introduce a fully novel perspective to address this challenge by leveraging much lightweight visual encoder.
To support longer input sequences in LLMs, we present \ourname, a vision-centric token expansion method built upon a visual encoder framework. 
Our analysis further reveals there exists significant redundancy in text tokens, further validating the effectiveness and efficiency of our vision-encoder-based approach.
With these advancements, \ourname\ surpasses text-encoder-based token compression counterparts in both performance and efficiency. 
In future work, we plan to evaluate \ourname\ across a broader range of downstream tasks and conduct a deeper investigation into text token redundancy.
