@article{jiang2024loopy,
  title={Loopy: Taming audio-driven portrait avatar with long-term motion dependency},
  author={Jiang, Jianwen and Liang, Chao and Yang, Jiaqi and Lin, Gaojie and Zhong, Tianyun and Zheng, Yanbo},
  journal={arXiv preprint arXiv:2409.02634},
  year={2024}
}
@article{razzhigaev2023kandinsky,
  title={Kandinsky: an improved text-to-image synthesis with image prior and latent diffusion},
  author={Razzhigaev, Anton and Shakhmatov, Arseniy and Maltseva, Anastasia and Arkhipkin, Vladimir and Pavlov, Igor and Ryabov, Ilya and Kuts, Angelina and Panchenko, Alexander and Kuznetsov, Andrey and Dimitrov, Denis},
  journal={arXiv preprint arXiv:2310.03502},
  year={2023}
}


@inproceedings{patel2024eclipse,
  title={Eclipse: A resource-efficient text-to-image prior for image generations},
  author={Patel, Maitreya and Kim, Changhoon and Cheng, Sheng and Baral, Chitta and Yang, Yezhou},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9069--9078},
  year={2024}
}
@article{cui2024hallo2,
  title={Hallo2: Long-Duration and High-Resolution Audio-Driven Portrait Image Animation},
  author={Cui, Jiahao and Li, Hui and Yao, Yao and Zhu, Hao and Shang, Hanlin and Cheng, Kaihui and Zhou, Hang and Zhu, Siyu and Wang, Jingdong},
  journal={arXiv preprint arXiv:2410.07718},
  year={2024}
}

@inproceedings{langley00,
 author    = {P. Langley},
 title     = {Crafting Papers on Machine Learning},
 year      = {2000},
 pages     = {1207--1216},
 editor    = {Pat Langley},
 booktitle     = {Proceedings of the 17th International Conference
              on Machine Learning (ICML 2000)},
 address   = {Stanford, CA},
 publisher = {Morgan Kaufmann}
}

@TechReport{mitchell80,
  author = 	 "T. M. Mitchell",
  title = 	 "The Need for Biases in Learning Generalizations",
  institution =  "Computer Science Department, Rutgers University",
  year = 	 "1980",
  address =	 "New Brunswick, MA",
}

@phdthesis{kearns89,
  author = {M. J. Kearns},
  title =  {Computational Complexity of Machine Learning},
  school = {Department of Computer Science, Harvard University},
  year =   {1989}
}

@Book{MachineLearningI,
  editor = 	 "R. S. Michalski and J. G. Carbonell and T.
		  M. Mitchell",
  title = 	 "Machine Learning: An Artificial Intelligence
		  Approach, Vol. I",
  publisher = 	 "Tioga",
  year = 	 "1983",
  address =	 "Palo Alto, CA"
}

@Book{DudaHart2nd,
  author =       "R. O. Duda and P. E. Hart and D. G. Stork",
  title =        "Pattern Classification",
  publisher =    "John Wiley and Sons",
  edition =      "2nd",
  year =         "2000"
}

@misc{anonymous,
  title= {Suppressed for Anonymity},
  author= {Author, N. N.},
  year= {2021}
}

@InCollection{Newell81,
  author =       "A. Newell and P. S. Rosenbloom",
  title =        "Mechanisms of Skill Acquisition and the Law of
                  Practice", 
  booktitle =    "Cognitive Skills and Their Acquisition",
  pages =        "1--51",
  publisher =    "Lawrence Erlbaum Associates, Inc.",
  year =         "1981",
  editor =       "J. R. Anderson",
  chapter =      "1",
  address =      "Hillsdale, NJ"
}


@Article{Samuel59,
  author = 	 "A. L. Samuel",
  title = 	 "Some Studies in Machine Learning Using the Game of
		  Checkers",
  journal =	 "IBM Journal of Research and Development",
  year =	 "1959",
  volume =	 "3",
  number =	 "3",
  pages =	 "211--229"
}

@article{ye2023geneface,
  title={Geneface: Generalized and high-fidelity audio-driven 3d talking face synthesis},
  author={Ye, Zhenhui and Jiang, Ziyue and Ren, Yi and Liu, Jinglin and He, Jinzheng and Zhao, Zhou},
  journal={arXiv preprint arXiv:2301.13430},
  year={2023}
}

@article{ye2024real3d,
  title={Real3d-portrait: One-shot realistic 3d talking portrait synthesis},
  author={Ye, Zhenhui and Zhong, Tianyun and Ren, Yi and Yang, Jiaqi and Li, Weichuang and Huang, Jiawei and Jiang, Ziyue and He, Jinzheng and Huang, Rongjie and Liu, Jinglin and others},
  journal={arXiv preprint arXiv:2401.08503},
  year={2024}
}

@inproceedings{zhou2021pose,
  title={Pose-controllable talking face generation by implicitly modularized audio-visual representation},
  author={Zhou, Hang and Sun, Yasheng and Wu, Wayne and Loy, Chen Change and Wang, Xiaogang and Liu, Ziwei},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={4176--4186},
  year={2021}
}

@inproceedings{liang2022expressive,
  title={Expressive talking head generation with granular audio-visual control},
  author={Liang, Borong and Pan, Yan and Guo, Zhizhi and Zhou, Hang and Hong, Zhibin and Han, Xiaoguang and Han, Junyu and Liu, Jingtuo and Ding, Errui and Wang, Jingdong},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3387--3396},
  year={2022}
}


@article{yang2024megactor,
  title={MegActor-Sigma: Unlocking Flexible Mixed-Modal Control in Portrait Animation with Diffusion Transformer},
  author={Yang, Shurong and Li, Huadong and Wu, Juhao and Jing, Minhao and Li, Linze and Ji, Renhe and Liang, Jiajun and Fan, Haoqiang and Wang, Jin},
  journal={arXiv preprint arXiv:2408.14975},
  year={2024}
}

@article{unterthiner2019fvd,
  title={FVD: A new metric for video generation},
  author={Unterthiner, Thomas and van Steenkiste, Sjoerd and Kurach, Karol and Marinier, Rapha{\"e}l and Michalski, Marcin and Gelly, Sylvain},
  year={2019}
}

@inproceedings{chung2017out,
  title={Out of time: automated lip sync in the wild},
  author={Chung, Joon Son and Zisserman, Andrew},
  booktitle={Computer Vision--ACCV 2016 Workshops: ACCV 2016 International Workshops, Taipei, Taiwan, November 20-24, 2016, Revised Selected Papers, Part II 13},
  pages={251--263},
  year={2017},
  organization={Springer}
}

@inproceedings{deng2019accurate,
  title={Accurate 3d face reconstruction with weakly-supervised learning: From single image to image set},
  author={Deng, Yu and Yang, Jiaolong and Xu, Sicheng and Chen, Dong and Jia, Yunde and Tong, Xin},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition workshops},
  pages={0--0},
  year={2019}
}

@inproceedings{deng2019arcface,
  title={Arcface: Additive angular margin loss for deep face recognition},
  author={Deng, Jiankang and Guo, Jia and Xue, Niannan and Zafeiriou, Stefanos},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={4690--4699},
  year={2019}
}


@article{wang2004image,
  title={Image quality assessment: from error visibility to structural similarity},
  author={Wang, Zhou and Bovik, Alan C and Sheikh, Hamid R and Simoncelli, Eero P},
  journal={IEEE transactions on image processing},
  volume={13},
  number={4},
  pages={600--612},
  year={2004},
  publisher={IEEE}
}

@article{heusel2017gans,
  title={Gans trained by a two time-scale update rule converge to a local nash equilibrium},
  author={Heusel, Martin and Ramsauer, Hubert and Unterthiner, Thomas and Nessler, Bernhard and Hochreiter, Sepp},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{guo2021sample,
  title={Sample and Computation Redistribution for Efficient Face Detection},
  author={Guo, Jia and Deng, Jiankang and Lattas, Alexandros and Zafeiriou, Stefanos},
  journal={arXiv preprint arXiv:2105.04714},
  year={2021}
}
@inproceedings{su2020blindly,
  title={Blindly assess image quality in the wild guided by a self-adaptive hyper network},
  author={Su, Shaolin and Yan, Qingsen and Zhu, Yu and Zhang, Cheng and Ge, Xin and Sun, Jinqiu and Zhang, Yanning},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={3667--3676},
  year={2020}
}
@inproceedings{tan2024flowvqtalker,
  title={FlowVQTalker: High-Quality Emotional Talking Face Generation through Normalizing Flow and Quantization},
  author={Tan, Shuai and Ji, Bin and Pan, Ye},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={26317--26327},
  year={2024}
}
@inproceedings{hong2022depth,
  title={Depth-aware generative adversarial network for talking head video generation},
  author={Hong, Fa-Ting and Zhang, Longhao and Shen, Li and Xu, Dan},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={3397--3406},
  year={2022}
}
@inproceedings{wang2021one,
  title={One-shot free-view neural talking-head synthesis for video conferencing},
  author={Wang, Ting-Chun and Mallya, Arun and Liu, Ming-Yu},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={10039--10049},
  year={2021}
}



@inproceedings{pumarola2018ganimation,
  title={Ganimation: Anatomically-aware facial animation from a single image},
  author={Pumarola, Albert and Agudo, Antonio and Martinez, Aleix M and Sanfeliu, Alberto and Moreno-Noguer, Francesc},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={818--833},
  year={2018}
}
@article{song2020score,
  title={Score-based generative modeling through stochastic differential equations},
  author={Song, Yang and Sohl-Dickstein, Jascha and Kingma, Diederik P and Kumar, Abhishek and Ermon, Stefano and Poole, Ben},
  journal={arXiv preprint arXiv:2011.13456},
  year={2020}
}
@InProceedings{rombach2022high,
  author    = {Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
  title     = {High-resolution image synthesis with latent diffusion models},
  booktitle = {Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  year      = {2022},
  pages     = {10684--10695},
}
@article{ma2024follow,
  title={Follow-Your-Emoji: Fine-Controllable and Expressive Freestyle Portrait Animation},
  author={Ma, Yue and Liu, Hongyu and Wang, Hongfa and Pan, Heng and He, Yingqing and Yuan, Junkun and Zeng, Ailing and Cai, Chengfei and Shum, Heung-Yeung and Liu, Wei and others},
  journal={arXiv preprint arXiv:2406.01900},
  year={2024}
}

@article{zhou2020makelttalk,
  title={Makelttalk: speaker-aware talking-head animation},
  author={Zhou, Yang and Han, Xintong and Shechtman, Eli and Echevarria, Jose and Kalogerakis, Evangelos and Li, Dingzeyu},
  journal={ACM Transactions On Graphics (TOG)},
  volume={39},
  number={6},
  pages={1--15},
  year={2020},
  publisher={ACM New York, NY, USA}
}

@article{vougioukas2020realistic,
  title={Realistic speech-driven facial animation with gans},
  author={Vougioukas, Konstantinos and Petridis, Stavros and Pantic, Maja},
  journal={International Journal of Computer Vision},
  volume={128},
  number={5},
  pages={1398--1413},
  year={2020},
  publisher={Springer}
}

@article{goodfellow2014generative,
  title={Generative adversarial nets},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}
@inproceedings{hong2022headnerf,
  title={Headnerf: A real-time nerf-based parametric head model},
  author={Hong, Yang and Peng, Bo and Xiao, Haiyao and Liu, Ligang and Zhang, Juyong},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={20374--20384},
  year={2022}
}

@inproceedings{yang2023effective,
  title={Effective whole-body pose estimation with two-stages distillation},
  author={Yang, Zhendong and Zeng, Ailing and Yuan, Chun and Li, Yu},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={4210--4220},
  year={2023}
}

@article{sun2023vividtalk,
  title={Vividtalk: One-shot audio-driven talking head generation based on 3d hybrid prior},
  author={Sun, Xusen and Zhang, Longhao and Zhu, Hao and Zhang, Peng and Zhang, Bang and Ji, Xinya and Zhou, Kangneng and Gao, Daiheng and Bo, Liefeng and Cao, Xun},
  journal={arXiv preprint arXiv:2312.01841},
  year={2023}
}

@article{guo2024liveportrait,
  title={Liveportrait: Efficient portrait animation with stitching and retargeting control},
  author={Guo, Jianzhu and Zhang, Dingyun and Liu, Xiaoqiang and Zhong, Zhizhou and Zhang, Yuan and Wan, Pengfei and Zhang, Di},
  journal={arXiv preprint arXiv:2407.03168},
  year={2024}
}

@inproceedings{chan2022efficient,
  title={Efficient geometry-aware 3d generative adversarial networks},
  author={Chan, Eric R and Lin, Connor Z and Chan, Matthew A and Nagano, Koki and Pan, Boxiao and De Mello, Shalini and Gallo, Orazio and Guibas, Leonidas J and Tremblay, Jonathan and Khamis, Sameh and others},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={16123--16133},
  year={2022}
}

@article{kim2018deep,
  title={Deep video portraits},
  author={Kim, Hyeongwoo and Garrido, Pablo and Tewari, Ayush and Xu, Weipeng and Thies, Justus and Niessner, Matthias and P{\'e}rez, Patrick and Richardt, Christian and Zollh{\"o}fer, Michael and Theobalt, Christian},
  journal={ACM transactions on graphics (TOG)},
  volume={37},
  number={4},
  pages={1--14},
  year={2018},
  publisher={ACM New York, NY, USA}
}

@inproceedings{peng2024synctalk,
  title={Synctalk: The devil is in the synchronization for talking head synthesis},
  author={Peng, Ziqiao and Hu, Wentao and Shi, Yue and Zhu, Xiangyu and Zhang, Xiaomei and Zhao, Hao and He, Jun and Liu, Hongyan and Fan, Zhaoxin},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={666--676},
  year={2024}
}
@Article{mirza2014conditional,
  author  = {Mirza, Mehdi and Osindero, Simon},
  title   = {Conditional generative adversarial nets},
  journal = {arXiv preprint arXiv:1411.1784},
  year    = {2014},
}
@inproceedings{ma2021pixel,
  title={Pixel codec avatars},
  author={Ma, Shugao and Simon, Tomas and Saragih, Jason and Wang, Dawei and Li, Yuecheng and De La Torre, Fernando and Sheikh, Yaser},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={64--73},
  year={2021}
}

@inproceedings{tan2023emmn,
  title={Emmn: Emotional motion memory network for audio-driven emotional talking face generation},
  author={Tan, Shuai and Ji, Bin and Pan, Ye},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={22146--22156},
  year={2023}
}

@inproceedings{ji2021audio,
  title={Audio-driven emotional video portraits},
  author={Ji, Xinya and Zhou, Hang and Wang, Kaisiyuan and Wu, Wayne and Loy, Chen Change and Cao, Xun and Xu, Feng},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={14080--14089},
  year={2021}
}

@inproceedings{prajwal2020lip,
  title={A lip sync expert is all you need for speech to lip generation in the wild},
  author={Prajwal, KR and Mukhopadhyay, Rudrabha and Namboodiri, Vinay P and Jawahar, CV},
  booktitle={Proceedings of the 28th ACM international conference on multimedia},
  pages={484--492},
  year={2020}
}

@article{wang2024v,
  title={V-Express: Conditional Dropout for Progressive Training of Portrait Video Generation},
  author={Wang, Cong and Tian, Kuan and Zhang, Jun and Guan, Yonghang and Luo, Feng and Shen, Fei and Jiang, Zhiwei and Gu, Qing and Han, Xiao and Yang, Wei},
  journal={arXiv preprint arXiv:2406.02511},
  year={2024}
}

@article{cao2014crema,
  title={Crema-d: Crowd-sourced emotional multimodal actors dataset},
  author={Cao, Houwei and Cooper, David G and Keutmann, Michael K and Gur, Ruben C and Nenkova, Ani and Verma, Ragini},
  journal={IEEE transactions on affective computing},
  volume={5},
  number={4},
  pages={377--390},
  year={2014},
  publisher={IEEE}
}
@article{chen2024echomimic,
  title={Echomimic: Lifelike audio-driven portrait animations through editable landmark conditions},
  author={Chen, Zhiyuan and Cao, Jiajiong and Chen, Zhiquan and Li, Yuming and Ma, Chenguang},
  journal={arXiv preprint arXiv:2407.08136},
  year={2024}
}
@inproceedings{zhu2022celebv,
  title={CelebV-HQ: A large-scale video facial attributes dataset},
  author={Zhu, Hao and Wu, Wayne and Zhu, Wentao and Jiang, Liming and Tang, Siwei and Zhang, Li and Liu, Ziwei and Loy, Chen Change},
  booktitle={European conference on computer vision},
  pages={650--667},
  year={2022},
  organization={Springer}
}

@inproceedings{stypulkowski2024diffused,
  title={Diffused heads: Diffusion models beat gans on talking-face generation},
  author={Stypu{\l}kowski, Micha{\l} and Vougioukas, Konstantinos and He, Sen and Zi{k{e}}ba, Maciej and Petridis, Stavros and Pantic, Maja},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={5091--5100},
  year={2024}
}
@inproceedings{zhang2021flow,
  title={Flow-guided one-shot talking face generation with a high-resolution audio-visual dataset},
  author={Zhang, Zhimeng and Li, Lincheng and Ding, Yu and Fan, Changjie},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3661--3670},
  year={2021}
}
@article{wang2021audio2head,
  title={Audio2head: Audio-driven one-shot talking-head generation with natural head motion},
  author={Wang, Suzhen and Li, Lincheng and Ding, Yu and Fan, Changjie and Yu, Xin},
  journal={arXiv preprint arXiv:2107.09293},
  year={2021}
}

@article{guo2023animatediff,
  title={Animatediff: Animate your personalized text-to-image diffusion models without specific tuning},
  author={Guo, Yuwei and Yang, Ceyuan and Rao, Anyi and Liang, Zhengyang and Wang, Yaohui and Qiao, Yu and Agrawala, Maneesh and Lin, Dahua and Dai, Bo},
  journal={arXiv preprint arXiv:2307.04725},
  year={2023}
}
@article{van2008visualizing,
  title={Visualizing data using t-SNE.},
  author={Van der Maaten, Laurens and Hinton, Geoffrey},
  journal={Journal of machine learning research},
  volume={9},
  number={11},
  year={2008}
}
@inproceedings{li2023blip,
  title={Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models},
  author={Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven},
  booktitle={International conference on machine learning},
  pages={19730--19742},
  year={2023},
  organization={PMLR}
}

@inproceedings{
anonymous2024dawn,
title={{DAWN}: Dynamic Frame Avatar with Non-autoregressive Diffusion Framework for Talking head Video Generation},
author={Anonymous},
booktitle={Submitted to The Thirteenth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=vjHySpxDsv},
note={under review}
}
@inproceedings{
anonymous2024synergizing,
title={Synergizing Motion and Appearance: Multi-Scale Compensatory Codebooks for Talking Head Video Generation},
author={Anonymous},
booktitle={Submitted to The Thirteenth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=LDtNetvNQp},
note={under review}
}
@misc{
zheng2024memo,
title={{MEMO}: Memory-Guided and Emotion-Aware Talking Video Generation},
author={Longtao Zheng and Yifan Zhang and Hanzhong Allan Guo and Jiachun Pan and Zhenxiong Tan and Jiahao Lu and Chuanxin Tang and Bo An and Shuicheng YAN},
year={2024},
url={https://openreview.net/forum?id=CpgWRFqxhD}
}
@article{choromanski2020rethinking,
  title={Rethinking attention with performers},
  author={Choromanski, Krzysztof and Likhosherstov, Valerii and Dohan, David and Song, Xingyou and Gane, Andreea and Sarlos, Tamas and Hawkins, Peter and Davis, Jared and Mohiuddin, Afroz and Kaiser, Lukasz and others},
  journal={arXiv preprint arXiv:2009.14794},
  year={2020}
}

@article{kingma2013auto,
  title={Auto-encoding variational bayes},
  author={Kingma, Diederik P},
  journal={arXiv preprint arXiv:1312.6114},
  year={2013}
}
@inproceedings{peebles2023scalable,
  title={Scalable diffusion models with transformers},
  author={Peebles, William and Xie, Saining},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={4195--4205},
  year={2023}
}

@inproceedings{perez2018film,
  title={Film: Visual reasoning with a general conditioning layer},
  author={Perez, Ethan and Strub, Florian and De Vries, Harm and Dumoulin, Vincent and Courville, Aaron},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={32},
  number={1},
  year={2018}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@article{baevski2020wav2vec,
  title={wav2vec 2.0: A framework for self-supervised learning of speech representations},
  author={Baevski, Alexei and Zhou, Yuhao and Mohamed, Abdelrahman and Auli, Michael},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={12449--12460},
  year={2020}
}

@inproceedings{zhang2023sadtalker,
  title={Sadtalker: Learning realistic 3d motion coefficients for stylized audio-driven single image talking face animation},
  author={Zhang, Wenxuan and Cun, Xiaodong and Wang, Xuan and Zhang, Yong and Shen, Xi and Guo, Yu and Shan, Ying and Wang, Fei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8652--8661},
  year={2023}
}
@inproceedings{hu2024animate,
  title={Animate anyone: Consistent and controllable image-to-video synthesis for character animation},
  author={Hu, Li},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8153--8163},
  year={2024}
}

@article{wei2024aniportrait,
  title={Aniportrait: Audio-driven synthesis of photorealistic portrait animation},
  author={Wei, Huawei and Yang, Zejun and Wang, Zhisheng},
  journal={arXiv preprint arXiv:2403.17694},
  year={2024}
}

@article{xu2024hallo,
  title={Hallo: Hierarchical Audio-Driven Visual Synthesis for Portrait Image Animation},
  author={Xu, Mingwang and Li, Hui and Su, Qingkun and Shang, Hanlin and Zhang, Liwei and Liu, Ce and Wang, Jingdong and Van Gool, Luc and Yao, Yao and Zhu, Siyu},
  journal={arXiv preprint arXiv:2406.08801},
  year={2024}
}
@article{tian2024emo,
  title={Emo: Emote portrait alive-generating expressive portrait videos with audio2video diffusion model under weak conditions},
  author={Tian, Linrui and Wang, Qi and Zhang, Bang and Bo, Liefeng},
  journal={arXiv preprint arXiv:2402.17485},
  year={2024}
}
