\section{Related Work}
\label{app:related}

\paragraph{AI text detection datasets}
Several benchmark datasets have been introduced to evaluate AI-based text detection models.
RAID-TD ____ provides a large-scale benchmark designed to assess text detection under adversarial conditions, ensuring robustness against manipulated AI-generated content. The M4 Dataset ____ expands the scope by incorporating reviews from multiple LLMs across different languages, offering a more diverse linguistic evaluation. The HC3 Dataset ____ consists of responses from ChatGPT and human experts, covering specialized domains such as finance, medicine, and law, in addition to general open-domain content. In contrast, the GPT Reddit Dataset (GRiD) ____ focuses on social media conversations, compiling a diverse set of human- and AI-generated responses to Reddit discussions. Meanwhile, Beemo ____ introduces a benchmark of expert-edited machine-generated outputs, spanning creative writing, summarization, and other practical applications, further refining detection challenges. These benchmarks primarily evaluate AI-generated text from a single model and do not address the domain of AI text in peer review. In contrast, our dataset is larger than most existing datasets (788k generations) and is unique in its focus on AI text detection in peer review.

\paragraph{AI-generated text detection}
AI-generated text detection has been framed as a binary classification task to distinguish human-written from machine-generated text ____. ____ used a bag-of-words model with logistic regression for GPT-2 detection, while fine-tuned language models like RoBERTa ____ improved accuracy ____. Zero-shot methods based on perplexity and entropy emerged as alternatives ____. Other studies focused on linguistic patterns and syntactic features for model-agnostic detection ____. Watermarking techniques, such as DetectGPT ____, have also been proposed for proactive identification.
Centralized frameworks like MGTBench ____ and its refined version, IMGTB ____, provide standardized evaluations for AI text detection. IMGTB categorizes methods into model-based and metric-based approaches. Model-based methods leverage large language models such as ChatGPT-turbo ____
and Claude ____. Metric-based methods, including Log-Likelihood ____, Rank ____, Entropy ____, DetectGPT ____, and LRR ____, rely on log-likelihood and ranking for classification. 



\paragraph{AI-assisted peer review}
Recent studies have explored the role of LLMs in peer review, examining their influence on reviewing practices ____, simulating multi-turn interactions ____, and assessing their reviewing capabilities ____. Tools like OpenReviewer ____ provide AI-assisted review improvements, while other works focus on LLM transparency ____ and distinguishing AI-generated content ____. Other recent work has investigated AI-driven review systems ____, agentic frameworks ____, and comparative analyses of LLM-generated reviews ____, along with broader explorations of LLMsâ€™ role in peer review ____.
While it is not the primary focus of our work, we analyze the quality of LLM-generated peer reviews in Section~\ref{sec:analysis}.