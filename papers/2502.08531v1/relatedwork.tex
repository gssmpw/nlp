\section{Related Work}
\looseness=-1To the best of our knowledge we are the first to study how the graphical constraints on CI-statements can be used to \emph{detect} and \emph{correct} errors in graph discovery, although e.g.  \citet{ramsey2006adjacency,colombo2014order} have noted that some special CI-statements can achieve this.
The restrictiveness of graphical causal models w.r.t. to their entailed independence models has been noted by \citet{tsamardinos2012towards,janzing2023reinterpreting} and in terms of structural causal models by \citet{gresele2022causal}.
Building on these insights \citet{faller2024self,schkoda2024cross} have also proposed to falsify causal models by exploiting these constraints.
%Particularly, they leverage that graphical models on subsets of the variables can entail constraints for the conditional independences in the joint distribution of all variables.
They highlight the distinction between constraints from the graphical model and from probability theory (via the probabilistic marginal problem),
yet we are the first to highlight the importance of this distinction for CI-tests on a single observed dataset.
\citet{bromberg2009improving} have also noted that contradictions between CI-tests can be corrected to improve discovery results, yet they focus on violations of the Graphoid axioms, which we have argued to be of lesser interest.
%Further, \citet{faller2024self} argue that causal discovery algorithms should strive to be stable w.r.t. to the addition of variables.
\citet{russo2024argumentative} propose to use symbolic reasoning to resolve conflicts in the provided CI-statements but do not make the distinction between graphically and probabilistically redundant tests.\todo{Need to understand this one better.}


%There are classical results in numerics on the condition of matrices \cite{???}.
%But our problem is different as it has a more discrete character.
%In discrete optimization there is a wide literature on \emph{stability} of optimization problem \cite{sotskov1995some}. \textcolor{red}{Need more}.
%But they are more interested in algorithmic aspects (calculating other solutions from an existing one), where we are striving to correct errors.

\looseness=-1There is also a vast literature on making discovery of graphical models robust against statistical uncertainty.
E.g. \citet{kalisch2007estimating} propose a stronger version of faithfulness under which the PC algorithm is uniformly consistent, while \citet{bhattacharyya2021near} show finite-sample bounds for tree learning.
\citet{strobl2016estimating,li2009controlling} use techniques from multi-hypothesis testing to control the error rate of edges. %(see also papers of Tsamardinos in there).
%\todo{Add following and previous line back in}
\citet{kalisch2008robustification, harris2013pc} study how to make PC more robust towards violations of parametric assumptions, while \citet{kim2024causal} use Graphoid axioms to conduct a set of tests that is equivalent it terms of their graphical implications but statistically better conditioned.
%\cite{cano2008score,abellan2006some} propose miscellaneous modifications of the PC algorithm. 
%Also cite this technical report that proposes to use sep set with maximal $p$ value and conservative PC.

\looseness=-1\citet{zhang2016three} argue that the faithfulness assumption serves three functions in graph discovery.
%It makes the problem uniquely solvable in many cases, it reduces the complexity of the problem algorithmically and it makes the problem statistically more tractable.
Our work can be interpreted as adding a fourth \enquote{face} to their three faces of faithfulness by showing that in many cases we get error detection and correction properties only through graphical assumptions that are stronger than the laws of probability, such as faithfulness.
%\dominik{explain in what sense}