\begin{figure*}[!ht]
    \centering
    \includegraphics[width=0.85\linewidth]{figs/pipeline.pdf}
     \vspace{-10pt}
    \caption{\sys{} watermarking procedure. The watermark insertion takes the original code and watermark message as input and fuses their features by CodeT5's encoder $\mathbf{S}_e$. Two sets of decoders $\mathbf{S}_{d1}$ and $\mathbf{S}_{d2}$ predicts the probability over the available syntactic transformations and the renamed variable over the vocabulary. Then, the watermark extraction module decodes watermarks from the syntactic-transformed and variable-renamed watermarked code $S(T, M)$, as well as its malicious transformation $\hat{S}(T, M)$. The two parts are trained jointly to ensure (i) functionality-invariant by minimizing functionality loss $L_f$ and (ii) accuracy and robust message decoding by minimizing detectability loss $L_d$ and robustness loss $L_r$.  }
    \label{fig:pipeline}
    \vspace{-5pt}
\end{figure*}

\subsection{Threat Model}~\label{sec:threat}
As shown in Figure~\ref{fig:overview}, we aim to watermark LLM-generated code before distributing the content to users~\cite{lee2023wrote,yang2024srcmarker}. The watermark insertion ensures the detectability of the encoded signature while maintaining code functionality unaltered and robustness against adversarial attacks. 
Due to the code's low-entropy nature, high-quality watermarks aligning with those objectives are limited per code segment.  
Thus, we also aim to avoid revealing and re-encoding new signatures after the code source verification.
We consider malicious end users may attempt to retain the code functionality but remove the encoded signature. The adversary has general knowledge of the watermarking framework, but he/she 
cannot access or manipulate the owner's watermark insertion/extraction.

%\sys{} leverages ML/Crypto codesign to ensure: (i) high-capacity ML-based watermarking network that balances the detectability-functionality-robustness tri-objective; (ii) secure crypto-based watermark verification without disclosing encoded watermarks to improve usability. To achieve these, \sys{} trains a watermark encoder and decoder end-to-end, aiming to optimize the watermark detection loss, functionality approximation loss, and adversarial detection loss jointly. With the trained network, as in Figure~\ref{fig:overview}, the watermark encoder takes the original LLM-generated code as well as the owner's signature as input and generates the watermarked code to distribute to users. If a code snippet is suspected to be LLM-generated, the LLM owners or any public can request the inspection from a third-party arbitrator by inputting the snippet and requesting the LLM owner input their signature to the ZKP circuit and determine if the decoded signature matches the owner-provided ones.


\subsection{\sys{} Design}
\sys{} consists of a watermark insertion and a watermark extraction module. As shown in Figure~\ref{fig:pipeline}, the watermark insertion backbone $\textbf{S}$ takes the watermark message $M$ and the code $T$ as input and generates (i) a probability over the syntactic transformations and (ii) variable name distribution over the vocabulary. Then, the code is watermarked by performing the transformations to get the watermarked code $S(T, M)$. Then, a watermark decoder decodes the message $M^\prime$ from the watermarked code $S(T, M)$. 

% a watermarked distribution over the vocabulary for each predicted token. Then, the watermark decoder takes the distribution as input and decodes the message. % The system is trained end-to-end aiming to ens

\textbf{Watermark Insertion} 
The watermark insertion employs the CodeT5~\cite{wang2021codet5}, pre-trained on millions of high-quality code files, as the backbone $\textbf{S}$ for watermark encoding. The encoder $\textbf{S}_e$ extracts the code feature and fuses with the message $M$'s feature extracted by $\textbf{R}_m$. The decoder $\mathbf{S}_{d1}$ and $\mathbf{S}_{d2}$ decodes two sets of probabilities over the syntactic transformations as $p_{syn}$ and variable token distributions $p_{var}$.  
Then, \sys{} obtains the watermarked code $S(T, M)$ by executing the predicted transformations from $argmax(p_{syn})$ and $argmax(p_{var})$. The syntactic transformation details are in Appendix~\ref{ap:trans}. 


To mimic the malicious transformations the adversaries can perform over the watermarked code, the watermark insertion also perturbs the decoded probability $p_{syn}$ and $p_{var}$ to obtain $\hat{p_{syn}}$ and $\hat{p_{var}}$. As shown in Equation~\ref{eq:perturb}, it adds Gaussian noise centered in 0 with variance equals $\sigma_p$. Then, \sys{} obtains the adversarial example $\hat{S}(T, M)$ for robust message recovery during training.  

 \vspace{-5pt}

 \begin{equation}
\label{eq:perturb}
\begin{array}{ll}
\hat{p}_{syn} &= p_{syn} + \epsilon \\
\hat{p}_{var} &= p_{var} + \epsilon, \quad \epsilon \sim \mathcal{N}(0, \sigma_p^2)
 \end{array}
\end{equation}
 \vspace{-5pt}

% The input code $T$ first goes through the transformations decoded from $\mathbf{S}_{d1}$ and then replace the variables from $\mathbf{S}_{d2}$ to obtain the watermarked distribution $S(T, M)$. In order to ensure successful watermark extraction of the code, we approximate $S(T, M)$ to its one-hot distribution, while maintaining the differability using Gumbel-Softmax to 
%  $\hat{S}(T, M)$ using Equation~\ref{eq:gumbel}.

%  \begin{equation}
% \label{eq:gumbel}
% \begin{array}{ll}
% \hat{\mathcal{S}}_i=\frac{\exp \left(\left(\log \left(\mathcal{S}_i\right)+g_i\right) / \tau\right)}{\sum_{j=1}^{|V|} \exp \left(\left(\log \left(\mathcal{S}_j\right)+g_j\right) / \tau\right)} 
% \quad   \text{for } i=1, \ldots, |T|
%  \end{array}
% \end{equation}

\textbf{Watermark Extraction} The watermark extraction decodes messages from the watermarked code $S(T, M)$. The encoder $\textbf{S}_e$, with shared parameters and architecture as the watermark insertion, is used to extract code features. Then, a shallow decoder $\textbf{R}_e$ is used to recover message $M^\prime$.

\textbf{Watermarking Strength} We measure the watermarking strength under the null hypothesis using z-score in Equation~\ref{eq:zscore}. The higher the z-score is, the more confident an owner can claim the code has been watermarked. $M$ is a binary sequence whose message generation is random and follows binomial distributions. The probability for generating bit 0 is $p=0.5$, and bit 1 is $1-p = 0.5$. The mean of the message distribution is $\mu= |M| \times p$, and the variance can be calculated as $ \sigma^2= |M| \times p \times(1-p)$. $|N|$ bits out of the message $M$ match $M^\prime$. 

 \vspace{-5pt}
\begin{equation}
\begin{aligned}\label{eq:zscore}
z=\frac{|N|-\mu}{\sigma}
\end{aligned}
\end{equation}
 \vspace{-5pt}

 %To reduce the computation overhead for watermark verification, we employ a shadow transformer $\mathbf{R}_e$ to extract the feature of the code, followed by a extractor $\mathbf{E}$ to decode the message as $M^\prime$.  

\subsection{\sys{} End-to-End Training}
We guide the training by minimizing the loss $L$ in Equation~\ref{eq:loss}. 
\sys{} is trained to meet three criteria: (i) Functionality-invariant: the functionality of watermarked code $S(T, M)$ remains the same as the input code $T$ as $L_f$; (ii) Detectability: the decoded message $M^\prime$ matches the encoded $M$ for successful detection as $L_d$; (iii) Robustness: the adversarial sample $\hat{S}(T, M)$'s decoded message $\hat{M}$ matches the encoded $M$ for robust detection as $L_r$. 


\begin{equation}
\label{eq:loss}
L = w_f L_f + w_d L_d + w_r L_r
\end{equation}


\textbf{Functionality Loss} Performing transformations over $T$ results in non-differentiable watermarked $S(T, M)$. Inspired by SrcMarker~\cite{yang2024srcmarker}, we employ $\textbf{R}_f$ to approximate the watermark insertion/extraction. The $\textbf{R}_f$ encourages the code functionality feature to be close during training. This is achieved by minimizing the mean square error (MSE)~\cite{allen1971mean} $L_{f1}$ between $\textbf{R}_f (\mathbf{S}_e, p_{syn}, p_{var})$ and $\textbf{S}_e (S(T, M))$ as in Equation~\ref{eq:functionality}. We also ensure the $\textbf{R}_f$'s approximation is correct for watermark extraction by minimizing the binary cross entropy (BCE) loss~\cite{ruby2020binary} $L_{f2}$ between $\textbf{R}_f(T)$ and predicted $M^\prime$.
 %\textcolor{red}{TODO: add another approximation loss}


\begin{equation}
\label{eq:functionality}
\begin{array}{rr}
L_f = MSE(\textbf{R}_f (\mathbf{S}_e, p_{syn}, p_{var}), \textbf{S}_e (S(T, M))) + \\ BCE(\textbf{R}_e(\textbf{R}_f(T)), M^\prime)
\end{array}
\end{equation}


\textbf{Detectability Loss} \sys{} minimize the BCE loss between $M$ and $M^\prime$ in Equation~\ref{eq:detect} to recover correct message in watermark extraction.

\begin{equation}
\label{eq:detect}
L_d = BCE(M, M^\prime)
\end{equation}

\textbf{Robustness Loss} To enable robust message recovery over malicious transformations, the watermark extraction also decodes the malicious message $\hat{M}^\prime$ over $\hat{S}(T, M)$ and minimizes the BCE loss between $M$ and $\hat{M}^\prime$ in Equation~\ref{eq:robust}.

\begin{equation}
\label{eq:robust}
L_r = BCE(M, \hat{M}^\prime)
\end{equation}

% the modules are trained end-to-end, targeting to (1) maintain logic invariant by minimizing the cross-entropy loss $L_l (T, \mathcal{S}(T, M))$ between original and watermarked codes, where each token in $T$ is masked by $T_M$, and employ a unique sentinel token for all occurrences of one
% specific identifier. (2) ensure watermark extraction by minimizing $L_1$ loss $L_d(M, M^\prime)$ 
% between the inserted and extracted signatures from the watermarked code, (3) enhance robustness by minimizing the $L_1$ loss $L_d(M, M_t^\prime)$ between the inserted and extracted signatures from the malicious transformed code.  




\subsection{Secure Watermark Verification}

%\textcolor{red}{@Nojan: See if you want to update anything. A few notable changes are: (1) we should only use zkp to verify $\textbf{R}_e$}

The core problem with watermark extraction is the requirement of revealing the watermarked info to prove that you own something. This presents a significant challenge because each time a signature is exposed, the data must undergo re-watermarking to prevent adversaries from altering or erasing the exposed signature. Utilizing zero-knowledge proofs (ZKPs) we can solve this problem. We present a unique watermark extraction scheme, built using non-interactive ZKPs, that can efficiently prove that code has been generated using a proprietary LLM, without revealing what the original watermark was. Our solution generates publicly verifiable proofs, such that one proof can be generated and universally verified to prove that a code snippet was generated from a proprietary code LLM. 

% Our zero-knowledge watermark extraction requires the prover to generate a ZKP attesting to valid input embeddings of the watermarked code and valid evaluation of the shallow decoder model, which will be optimized for private computation.
We utilize Halo2-based zk-SNARKs \cite{halo2_repo}, a class of non-interactive ZKPs that offer high scalability and fast verification time. Our proposed system benefits from the fact that proof generation only has to be done once, and, as proof generation is the slowest aspect of Halo2-based zk-SNARKs, we do not need to view this as a bottleneck. Due to the computational overhead of ZKPs, our approach includes non-interactive ZKP-specific optimizations, such as custom quantization, to ensure that the operation is runtime and memory-efficient. 

A high-level approach towards our zero-knowledge watermark extraction scheme can be seen in Algorithm \ref{alg:extract}. To verify copyrights, the model owner starts by mapping the watermarked code $\mathcal{S}(T, M)$ into its embedding space using $\mathbf{S}_e$. This is done by running a feed-forward process on $\mathbf{S}_e$ with input $\mathcal{S}(T, M)$, which results in a feature vector $\mathcal{S}(T, M)_\textsf{embed}$ that represents the watermarked code in the correct embedding space. Then, the model owner begins the ZKP generation process. $\mathcal{S}(T, M)_\textsf{embed}$ and a target bit error rate (BER) $\theta$ are taken in as public inputs, as they do not reveal any sensitive information about the proprietary LLM or watermarking scheme. The parameters of the shallow linear decoder $\bf{R}_e$ and the original signature $M$ are taken in as private inputs. With all computation represented as a zero-knowledge circuit, the trained watermark extraction module $\mathbf{R}_e$ decodes the signature $M^\prime$ from the watermarked code by performing our custom $zkFeedForward$ function on $\bf{R}_e$, with the input set to $\mathcal{S}(T, M)_\textsf{embed}$. This results in an extracted signature $M^\prime$, of the same length as $M$. Within the same zero-knowledge circuit, the BER between the extracted signature $M^\prime$ and the original signature $\bar{M}$ that the LLM owner provides is calculated. This is done with our provided custom $zkBER$ function, which returns $1$ if the BER between $M^\prime$ and $M$ is less than $\theta$, or else it returns $0$. The resulting proof $\pi$ will only be valid if the extracted signature $M^\prime$ has a low enough BER compared to the original signature $M$. This proof $\pi$ can be sent to any verifier \Vrf to prove that the inspected watermarked code was a result of the model owner's proprietary LLM. 

A majority of the computational burden lies in the $zkFeedForward$, which requires custom optimization of the shallow linear decoder to ensure efficient operation when translated to ZK computation. Specifically, $\bf{R}_e$ is made up of batch normalization, fully-connected, ReLU, and dropout layers. To implement and run $zkFeedForward$, we use a customized version of the EZKL Rust package \cite{ezkl}. EZKL accepts a computational graph as input, allowing us to optimize our computation before converting it to the correct input format. We provide four custom optimizations and capabilities to ensure efficient proof generation, while maintaining small proof size and fast verification:
\begin{enumerate}
    \item We lower the memory requirement that is necessary for non-linear layers by adding support for polynomial approximations, which is an important technique in privacy-preserving applications. We approximate ReLU using $\sigma(x)=x^2+x$, which has been shown to closely replicate the ReLU \cite{ali2020polynomial}.
    \item We quantize parameters into Bfloat16 (BF16) format, a 16-bit floating point format that reduces the memory requirement for proof generation \cite{burgess2019bfloat16}, while maintaining network-level accuracy.
    \item We add support for a highly efficient, zero-knowledge bit error rate calculation circuit based on the Halo2 proof system to represent $zkBER$. This is done using the bitwise AND operator to calculate the number of bits that differ between the $M^\prime$ and $M$.
    \item We add a composability layer that allows for efficient combination of Halo2-based and EZKL circuits (e.g. $zkFeedForward$ and $zkBER$) for representation in a single computational graph.
\end{enumerate}

Using these optimizations, we are able to build an efficient ZK watermark extraction and verification scheme with small proofs and fast verification that cleanly integrates into \sys{}'s end-to-end workflow.

% with the added support of polynomial approximations for non-linear layers. This added support allows for the operation of $zkFeedForward$ on consumer hardware, such as standard laptops, that do not have server-grade RAM available. Alongside this, we add support for a highly efficient, zero-knowledge bit error rate calculation circuit based on the Halo2 proof system to represent $zkBER$. This is done using the bitwise AND operator to calculate the number of bits that differ between the $M^\prime$ and $M$. We make this circuit compatible with EZKL to allow for our ZK watermark extraction and verification calculation to be represented in a single circuit. EZKL accepts a computational graph as input, allowing us to optimize $\bf{R}_e$ before converting it to the correct input format. The most effective optimization we apply is conversion to fixed point data types followed by quantization to 16-bit parameters. This results in a negligible effect in accuracy, while significantly reducing the memory footprint of $\bf{R}_e$. Finally, we define our ZK circuit as the sequential operations of $zkFeedForward$ and $zkBER$ and generate a Halo2-based zk-SNARK with EZKL and the Halo2 framework.

% in which we replace non-linear functions, namely ReLU, with polynomial approximations for operation on lower 



\begin{algorithm}[h]
\small
\caption{ZK Watermark Extraction and Verification}
\label{alg:extract}
\begin{algorithmic} [1]
    \STATE {\bfseries Public Values:} Watermarked text embedding $\mathcal{S}(T, M)_\textsf{embed}$, Target bit error rate (BER) $\theta$
    \STATE {\bfseries Private Input:} Shallow linear decoder $\bf{R}_e$, Signature $M$
    \STATE {\bfseries Circuit:} 
    \STATE \hspace{1em} $M^\prime = zkFeedForward(\mathbf{R}_e)$ on input $\bf{S}_e(\mathcal{S}(T, M))$
    \STATE \hspace{1em} $valid\_BER = zkBER(M, M^\prime, \theta)$ 
    \STATE \hspace*{1em}  \textbf{return} $valid\_BER$
    
\end{algorithmic}
\end{algorithm}


