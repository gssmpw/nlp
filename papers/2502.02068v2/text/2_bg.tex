


\textbf{Code Watermarking for Large Language Models}
Compared to natural language, watermarking code needs to preserve both its semantics and functionality. Prior work can be methodologically categorized into two approaches~\cite{zhang2024remark}:  (i) inference-based watermarking~\cite{lee2023wrote,ning2024mcgmark}, and (ii) neural-based watermarking~\cite{yang2024srcmarker}. 
The inference-based watermarking~\cite{lee2023wrote} encodes signatures at the LLM inference stage. It splits vocabulary into green/red lists only on high-entropy tokens and restricts the LLM decoding to predict the next token from the green list. However, 
such insertion loses the global view of the code, in which performing watermark insertions may violate syntactic constraints and corrupt code functionality.    
Neural-based code watermarking approach~\cite{yang2024srcmarker} tries to maintain code functionality by encoding watermarks on both the syntactic transformation structures and the variable names. It leverages a dual-channel neural network to embed watermarks on code feature space and decodes a set of probably over potential syntactic transformations, as well as the variable to rename. Nevertheless, SrcMarker~\cite{yang2024srcmarker} employs a shallow transformer trained from scratch for watermark insertion/extraction, which limits the code feature extractability and results in weak watermark detectability. 

There is another line of work that employs rule-based methods~\cite{li2023protecting,li2024resilient} to watermark code. It maintains a transformation table containing the transformation ID and the rule to transform the code. For each code segment, rule-based watermarking applies available transformations on the original code to form the watermark and obtains the watermarked snippets. The watermarks may be vulnerable to watermark removal attacks that statistically change the syntactics. As such, we do not consider them in this paper. 


Due to the code's low-entropy nature, high-quality watermarks adhering to the detectability-fidelity-robustness tri-objectives are limited. After the watermark is revealed to the third party for legal verification, re-encoding another set of signatures on code data may hurt its usability. Prior solutions only design the code watermark insertion/detection algorithms without considering such cases for secure watermark verification to protect owner's signatures.

%Similar to natural language watermarking, watermarking code data can generally be categorized into three types~\cite{zhang2023remark}: (i) rule-based watermarking, (ii) inference-based watermarking, and, (iii) neural-based watermarking.  
%The rule-based watermarking ACW~\cite{li2024resilient} maintains a transformation table and uses the code style transfer as the watermarks. However, the methodology requires additional engineering for new programming languages and exhibits low transferability. The inference-based watermarking SWEET~\cite{lee2023wrote} encodes signatures during the LLM inference stages. By watermarking on the high-entropy tokens, SWEET~\cite{lee2023wrote} maintains the correctness and the executability of the watermarked code. However, it comes at the cost of the lower watermarking strength the framework can provide. The neural-based watermarking SrcMarks~\cite{yang2023towards} leverages an end-to-end learning technique to integrate the watermarking signatures into the codes while maintaining AST-invariant.
%However, it falls short of the watermarking capacity it can provide and requires re-training for new programming languages.  

\textbf{Zero-knowledge Proofs}
(ZKPs) are a cryptographic primitive that allows a prover to prove knowledge of a secret value $w$ to a verifier. In a standard ZKP scheme, the prover $\mathcal{P}$ convinces a verifier $\mathcal{V}$ that $w$ is a valid private input such that $y=\mathcal{C}(x, w)$, in which $\mathcal{C}$ is an arbitrary computation and $x$ and $y$ are public inputs and outputs, respectively.
In general, ZKPs are extremely useful in computations where verification of outputs is costly (e.g. machine learning), as ZKPs allow users to verify a small proof rather than repeating the computation themselves \cite{xing2023zero}. In most ZK schemes, the majority of the computation lies in the setup and proving phases, as any computation $\mathcal{C}$ must be properly encoded in a way that ensures efficient processing during proof generation. In the context of ZK machine learning, for example, the layers, activation functions, and parameters, must all be represented as \textit{circuits}. This process, called \textit{arithmetization}, generally involves the conversion of the computations into arithmetic operations that can be efficiently performed over a finite field \cite{mouris2021zilch}. The setup and arithmetization phases of ZKP protocols are typically where the cryptographic elements are injected to ensure the privacy of $w$.
% A ZKP protocol results in an easy-to-verify proof $\pi$ that $\mathcal{P}$ sends to $\mathcal{V}$. 
% \textcolor{red}{NS: not sure how technical to get - I have commented out a paragraph under this. I can also get more mathematical if needed, just don't want to take up too much space}

% \textcolor{red}{I can remove the rest of this paragraph if needed} 

Zero-knowledge proof generation can be performed in an interactive or non-interactive manner, depending on the application. One of the main drawbacks of interactive schemes is that they limit proofs to \textit{designated-verifier} settings, meaning proof generation, which is the most computationally heavy process in ZKP workflows, must be repeated for every new verifier. Non-interactive ZKPs allow for the \textit{publicly verifiable} setting, meaning that once a proof is generated attesting correct computation or valid data, it can be verified by any third party. Generally, non-interactive ZKP schemes can be represented with the three following algorithms: 
% \textcolor{red}{add zk equations}

\begin{itemize}
    \item $(\mathcal{VK, PK})\xleftarrow[]{}$ Setup($\mathcal{C}$): A trusted third party, when trusted setup is needed, or \Vrf (with publicly verifiable randomness) runs a setup procedure to generate a prover key $\mathcal{PK}$ and verifier key $\mathcal{VK}$.
    \item $\pi \xleftarrow[]{}$ Prove($\mathcal{PK}$, \Cir, $x$, $y$, $w$): \Prv generates proof $\pi$ to convince \Vrf that $w$ is a valid witness. A malicious \Prv cannot generate a valid proof without knowledge of $w$. Alongside this, $\pi$ does not reveal anything about $w$.
    \item $1/0 \xleftarrow[]{}$ Verify($\mathcal{VK}$, \Cir, $x$, $y$, $\pi$): \Vrf accepts or rejects proof $\pi$. \Vrf cannot be convinced by an invalid proof due to soundness property of ZKPs.
\end{itemize}

The most notable non-interactive ZKP scheme is Groth16-based zero-knowledge succinct non-interactive arguments of knowledge (zk-SNARKs), which generate succinct proofs that are of constant size 128 bytes \cite{groth2016size}. Due to their succinctness, verification of zk-SNARKs is also very fast - in the order of milliseconds. The main drawback of zk-SNARKs that operate in the Groth16 proof system is the reliance on a computationally heavy trusted setup process, done by a trusted third party, in the presence of every new computation $\mathcal{C}$. This approach is best suited for applications in which $\mathcal{C}$ is relatively static.
ZKROWNN~\cite{sheybani2023zkrownn} shows the feasibility of Groth16 zk-SNARKs for watermark verification in deep neural networks (DNN), requiring only low communication and runtime for a user to verify a proof. However, its primary goal is to protect the watermarks of deep neural networks for IP protection of the models, rather than protecting the watermarks embedded in the data generated by a generative model, which is different from \sys{}. 

Although Groth16-based zk-SNARKs work well for computation on the scale of DNNs, their performance begins to falter as $\mathcal{C}$ grows, as they require quite heavy computation on the prover side to ensure succinctness. \sys{} utilizes the Halo2 proof system \cite{halo2_repo} to build efficient zk-SNARKs at a real-world scale, with support for dynamic $\mathcal{C}$. Halo2 utilizes a \textit{universal} and \textit{updatable} setup process, such that trusted setup does not have to be performed for every new $\mathcal{C}$. Besides this, Halo2 does not enforce constant size proofs. Instead, this proof system produces larger proofs, generally in the range of tens to hundreds of kilobytes, as a tradeoff to provide higher prover scalability.