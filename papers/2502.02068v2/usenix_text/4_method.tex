As in Figure~\ref{fig:system}, \sys{} consists of three modules, namely, watermark insertion, reparameterization, and watermark extraction. The watermark insertion inserts invisible watermarks into the LLM-generated codes via a CodeT5+~\cite{wang2023codet5plus} based sequence-to-sequence (Seq2Seq) model $\mathbf{S}$. Since the watermark extraction is performed over textural tokens, reparameterization converts the watermarked distribution from $\mathbf{S}$ towards a more sparse representation using Gumbel-Softmax~\cite{jang2016categorical}. Watermark extraction first maps the reparameterized distribution into their respective embedding representation using a mapper network $\mathbf{R}_e$. It then employs a transformer-based decoder $\mathbf{E}$ to extract the secret messages from the embedding.

\subsection{Watermarking Framework}
In this subsection, we first introduce the 

\paragraph{}

\subsection{Secure Watermark Verification}

\textcolor{red}{@Nojan: See if you want to update anything}


To verify copyrights, the watermarked code  $\bar{T}_{wm}$ is first mapped into its embedding space using $\mathbf{R}_e$. Then, the trained watermark extraction module $\mathbf{E}$ decodes the signature $\bar{M}^\prime$ from the watermarked code. The third-party arbitrators justify the ownership by comparing $\bar{M}^\prime$ with the encoded signature $\bar{M}$ LLM  owner provides. 


The core problem with watermark extraction is the requirement of revealing the watermarked info to prove that you own something. This presents a significant challenge because each time a signature is exposed, the data must undergo re-watermarking to prevent adversaries from altering or erasing the exposed signature. Utilizing zero-knowledge proofs (ZKPs) we can solve this problem. We propose a unique LLM watermark extraction scheme, built using ZKPs, that can efficiently prove that code has been generated using a proprietary LLM, without revealing what the original watermark was. Our solution benefits from non-interactive schemes, as one proof can be generated and universally verified to prove that a code snippet was generated from a proprietary code-LLM. Our zero-knowledge watermark extraction requires the prover to generate a ZKP attesting to valid inputs and valid evaluation of the shallow decoding transformer, which will be optimized for private computation. Due to the computational overhead of ZKPs, our approach includes non-interactive ZKP-specific optimizations, such as custom quantization, to ensure that operation is runtime and memory-efficient. A very high-level approach towards our zero-knowledge watermark extraction scheme can be seen in Algorithm \ref{alg:extract}. A majority of the computational burden lies in the $zkFeedForward$, which will require optimal design of the transformer-based decoder, alongside clever application of non-interactive ZKPs to preserve utility while guaranteeing scalability.

\begin{algorithm}[h]
\small
\caption{Watermark Extraction}
\label{alg:extract}
\begin{algorithmic} [1]
    \State {\bfseries Public Values:} WM text $\bar{T}_{wm}$, Target bit error rate (BER) $\theta$
    \State {\bfseries Private Input:} Shallow transformer decoder $\mathbf{E}$, Signature $\bar{M}$
    \State {\bfseries Circuit:} 
    \State \hspace{1em} $check=1$
    \State \hspace{1em} $\bar{M}^\prime = zkFeedForward(\mathbf{E})$ on input $\bar{T}_{wm}$
    \State \hspace{1em} $valid\_BER = zkBER(\bar{M}, \bar{M}^\prime, \theta)$ 
    \State \hspace*{1em}  \textbf{return} $check \land valid\_BER$
    
\end{algorithmic}
\end{algorithm}

