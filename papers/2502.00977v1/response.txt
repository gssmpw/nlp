\section{Related Work}
\label{sec:related_work}

%\subsection{Long Document Summarization}

The literature is rife with proposals aiming to  mitigate LLM difficulties with processing inputs that exceed their context lengths. A significant challenge in overcoming the context limit is addressing the quadratic computational
burden of the self-attention mechanism. Previous work has 
attempted to reduce this cost by architectural modifications such as introducing sparse attention **Vaswani, "Attention Is All You Need"**, linearized attention **Tay et al., "Sparse Sequence-to-Sequence Models"**,  changes to positional encoding **Shaw et al., "Self-Attention with Relative Position Representations"**,  and special-purpose fine-tuning methods which directly modify the attention mechanism  **Kitaev et al., "Reformer: The Efficient Transformer"** or incorporate discourse-level information. %____ in LoRA fine-tuning ____. 

Another line of work adopts a divide-and-conquer approach, splitting the long input into manageable chunks. The chunks can be processed independently  **Lee et al., "Hierarchical Text Generation for Long Document Summarization"** or through progressively merging adjacent chunks as they
are processed along the transformer layers **Wu et al., "Long Document Summarization with Transformers"**. 
**Chen et al., "Long Document Summarization via Reinforcement Learning and Hierarchical Merging"** propose a dive-and-conquer approach for long document summarization in which an LLM is fine-tuned via reinforcement learning to summarize each chunk and then hierarchically merge
chunk-level summaries  into a final summary. Their method has since been adapted to use zero-shot prompting for summary generation **Huang et al., "Zero-Shot Long Document Summarization"**, without further training (as shown in Figure~\ref{fig:hm}). 

Our proposal modifies hierarchical merging to consider evidence from the source document at the intermediate summary generation stage. It draws inspiration from retrieval augmented generation (RAG) techniques which have proven particularly effective in long-form question answering **Karpukhin et al., "Dense Retrieval for Question Answering"**, as a means to integrate up-to-date information, mitigate hallucinations, and enhance response quality. Our work explores various proposals for context integration, e.g.,~as a replacement of  intermediate summaries or additional supporting evidence, as well as retrieval augmentation methods. In addition to traditional query-based retrieval which we implement using the intermediate summaries as queries, we also turn to extractive summarization to select and rank source document sentences that best represent its content.  

Various methods have been proposed for long document extractive
summarization, focusing on reinforcement learning
**Zhang et al., "Reinforcement Learning of Extractive Summaries"**
and adapting LLMs for sentence extraction **Rajani et al., "Extracting and Composing Robust Features from Pre-Trained Transformers"**. However, these methods were primarily
evaluated on datasets with relatively short inputs, such as arXiv
**(Huang et al., "Long Document Summarization via Reinforcement Learning and Hierarchical Merging"; ~5K tokens)** and GovReport
**(Liu et al., "GovReport: A Dataset for Long Document Summarization; ~10K tokens)**, making their
effectiveness on inputs exceeding 100K tokens uncertain. As we
identify salient sentences within each chunk, we expect extractive
methods to be able to isolate supporting evidence for ultimately
generating more factual \emph{abstractive} summaries.

Our work also  has connections to recent efforts in creating verifiable systems that generate responses to queries by incorporating citations to source material **Rajani et al., "Extracting and Composing Robust Features from Pre-Trained Transformers"**. Most existing models learn to generate citations  **Zhu et al., "Generating Accurate Citations with Reinforcement Learning"** or implement a post-processing step  **Kang et al., "Post-Processing Text for Attributability"** where the text is first generated and then edited to be made attributable (e.g.,~to retrieved web content).  For hierarchical merging, generating intermediate summaries with citations is advantageous as it  eschews the need for additional retrieval or extraction mechanisms. However, we experimentally find that generating \emph{accurate} citations is challenging requiring models to understand and execute complex instructions. 

%The advanced instruction-following capabilities of LLMs have also made prompting-based methods effective for long document summarization. 

%____ introduced a hierarchical approach that segments the input into chunks, generates summaries for each chunk, and recursively combines them into a final summary. This method was later adapted to use zero-shot prompting for summary generation  proving effective in producing coherent summaries.

%researchers can fine-tune them with specialized methods that overcome transformer limitations. For example, LongLoRA **Wang et al., "LongLoRA: Efficiently Extending Transformers"** modifies the attention mechanism in LoRA fine-tuning **Li et al., "Efficient Neural Network Pruning"** by implementing shifted sparse attention, which efficiently extends LLMs' context length while maintaining performance. Another variant, RST-LoRA  **Zhou et al., "RST-LoRA: Retrieval-Augmented Generation with LoRA"**, specifically targets summarization by incorporating discourse information into the LoRA model, demonstrating strong results on long document summarization.



\begin{figure}[t]
  \includegraphics[width=0.45\textwidth, trim=0cm 0cm 0cm 0cm, clip]{proposed.pdf}
  \caption{Illustration of proposed pipeline for the first two
    levels. The Incorporate Context (IC) module is applied at the
    first-level to obtain relevant input contexts~$p^1_i$ alongside
    summaries~$s^1_i$. At the \mbox{second-level}, we either use
    $p^1_1 \dots p^1_m$ as supporting evidence (\textbf{Support}), or
    replace $s^1_1 \dots s^1_m$ entirely with $p^1_1 \dots p^1_m$
    (\textbf{Replace}) for generating~$s^2_1$ and subsequently
    obtaining~$p^2_1$.}
  \label{fig:proposed}
\end{figure}

\begin{figure*}[t]
  \includegraphics[width=\textwidth, trim=0cm 0cm 0cm 0cm, clip]{ic.pdf}
 \caption{\label{fig:ic} Incorporate Context (IC)
   module from Figure~\ref{fig:proposed} with three context
   augmentation methods: Extractive Summarization (Extract),
   Retrieval-augmented Generation (Retrieve), and Generating text with
   citations (Cite).} 
\end{figure*}

%\begin{figure}[t]
%\caption{
%Illustration of the Incorporate Context (IC) module in Figure \ref{fig:proposed} with three context augmentation methods: Extractive Summarization (Extract), Retrieval-augmented Generation (Retrieve) and Generating text with citations (Cite).}
 %   \end{figure}
    

%\subsection{Incorporating Input Context into Hierarchical Merging}

%This section reviews prior work related to our methods of incorporating input context into hierarchical merging.

%\paragraph{Extractive summarization} involves ranking and selecting input sentences that best represent the document's content. 

%\paragraph{Information Retrieval} enhances model performance by retrieving relevant information from external knowledge bases **Karpukhin et al., "Dense Retrieval for Question Answering"**. While retrieval was widely adopted for question answering, research has shown its effectiveness in summarization  **Huang et al., "Zero-Shot Long Document Summarization"** and general knowledge integration **Seo et al., "Real-time Open-domain Question Answering"**. Retrieval performance depends on various factors, including retriever selection  **Karpukhin et al., "Dense Retrieval for Question Answering"** and query quality  **Chen et al., "Query Generation with Deep Reinforcement Learning"**.

%\paragraph{Generating text with citations} focuses on producing verifiable content by incorporating citations to source material after generated sentences or paragraphs **Kang et al., "Post-Processing Text for Attributability"**. This approach requires models to generate accurate citations corresponding to input contexts and understand complex citation-generation instructions  **Zhu et al., "Generating Accurate Citations with Reinforcement Learning"**.