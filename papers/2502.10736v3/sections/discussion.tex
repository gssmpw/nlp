\section{Discussion}
The user study findings demonstrate the effectiveness of our impact caption design space and the usefulness of our \system{} system. 
Related to findings and the literature, we first discuss the potentials of using impact captions as a form of visual rhetoric with interactivity to enhance communication and interactions in social VR.
Next, we present an in-depth understanding of the ambiguity in \system{} and proposed future research directions regarding it for designing communication tools in social VR.
Then, we provide three design implications for future tools for interpersonal communication in social VR based on the study results.
Finally, we explain the scalability of \system{}, showing the limitations and corresponding future directions to improve our \system{}.

% Study Findings:
% Textual Elements Can Effectively Support Conversations in Social VR.
% Non-textual Elements are Engaging but Possibly Ambiguous.
% Impact Captions is a Powerful Medium for Facilitating Interactions between Users

% Specifically, textual elements can clearly convey the information in speech-based conversations. Non-textual elements make the experiences engaging and informative, while they may also introduce unexpected risks of miscommunication caused by ambiguity. Moreover, we found that impact captions can also facilitate social interactions between users beyond speech conversations in social VR. Additionally, we illustrate three application scenarios to further explore the generalizability of our impact-caption-mediated method for diverse contexts in social VR.


\subsection{Designing Interactive Visual Rhetoric for Interpersonal Communication in Social VR}
As suggested by previous research, mediating interpersonal communication in virtual spaces involves supporting people in building cognitive and emotional connections ~\cite{mcveigh2021case, palmer1995interpersonal} and exploring self-identity beyond the real world ~\cite{freeman2021body, sykownik2022something, maloney2020talking}. 
However, most of the known communication methods in social VR are still imperfect ~\cite{wei2022communication, dzardanova2022virtual, akselrad2023body, sykownik2023vr, tanenbaum2020make, baker2021avatar}.

\subsubsection{Highlighting the Visual Rhetoric and Interactivity}
To fill this gap, our work incorporates speech-driven captioning mechanisms into social VR with improvements on captions' visual design and interactivity.
Inspired by the original impact captions used in entertaining TV shows ~\cite{sasamoto2014impact}, we designed and implemented a visual rhetoric that integrates textual and non-textual elements to convey verbal and non-verbal information simultaneously, while enabling various human-caption interactions to support speech conversations in social VR

\altcolor{
The user study revealed that our impact-caption-mediated approach have the potential to effectively support verbal communication in social VR (\autoref{finding_text}).
The rich interactivity provided by impact captions fosters more engaging and dynamic interpersonal interactions (\autoref{finding_interaction}).
However, it also faces challenges like the ambiguous non-verbal elements (\autoref{finding_ambiguity}) and the difficulties on keyword extraction (\autoref{finding_keywords}).
Overall, \system{} provides a concrete example of how interactive and expressive visual objects can mediate communication and enhance social interactions in social VR.
}

\subsubsection{Considering Generalizability}
As for the generalizability of our impact-caption-mediated method, the aforementioned application scenarios (\autoref{sec_apps}) demonstrate that \system{} have the potential to be widely applied in different contexts. It can enhance emotional expressions to create engaging and intimate atmospheres, support live presentations for teaching scientific knowledge in educational scenarios, and further provide a promising captioning mechanism that can bring immersive social VR experiences to deaf and hard-of-hearing (DHH) individuals.

\subsubsection{Future Directions}
In summary, our work emphasizes the value of visual rhetoric integrating with interactivity for facilitating communication in social VR, showing how invisible verbal and non-verbal information can be made perceptible and playable. \system{} expands on the ``superpowers'' of social VR ~\cite{mcveigh2022beyond, mcveigh2021case}, leading the way towards unique immersive communication experiences and fostering novel interactions not only between two human users, but also between humans and the digital media.

As the design space of impact captions in \system{} is generalizable, future work can borrow from or build on our impact captions to create novel digital mediums to support communication needs in a wide range of social VR applications, including facilitating distinctive activities ~\cite{chen2024drink, maloney2020falling}, enhancing self-presentations ~\cite{freeman2021body, sykownik2022something, maloney2020talking}, and constructing social connections ~\cite{li2019measuring}. Besides, further studies are required to investigate the long-term influence of using \system{} for communication on users and explore whether such a method can interfere with the ``proteus effect'' in social VR ~\cite{maloney2020talking} to reveal opportunities for expanding and enriching the application scenarios.


\subsection{Understanding the Ambiguity in \system{}}
Ambiguity in computer-mediated communication (CMC) systems is unavoidable, arising from socio-technical factors such as cultural differences, personal preferences, and technical limitations ~\cite{stacey2003against, aoki2005making}.
Impact captions in \system{} also face risks of miscommunication due to inherent ambiguity in the design space.

The user study revealed participants' concerns that the current heuristic rule-based method for determining visual appearances might not meet the diverse needs of users, as individuals may perceive the same impact captions differently (\autoref{finding_ambiguity}).
Previous research pointed out that visual elements in the design space, such as color-emotion association ~\cite{hanada2018correspondence, wilms2018color} and emoji ~\cite{czkestochowska2022context, miller2017understanding}, could imply ambiguous interpretations by different people, which also supports our study findings.

However, inevitable ambiguity in digital media design can be a double-edged sword, presenting both challenges and opportunities. 
Although it may introduce risks of miscommunication, ambiguity can foster creativity ~\cite{stacey2003against}, support negotiation ~\cite{gaver2003ambiguity}, and even enhance the human-like qualities of AI agents in human-AI communication ~\cite{liu2024let}.
Therefore, a trade-off arises: for CMC tools, designers must balance the clarity of communication while maintaining certain ambiguity to meet other design goals ~\cite{stacey2003against, aoki2005making}. This trade-off leads to two directions of dealing with the ambiguity: mitigating and utilizing.

Yet, the way to mitigate ambiguity for communication in social VR has not been fully explored. Though previous work revealed the potential of using biosignal visualizations ~\cite{lee2022understanding}.
As a complement, our impact caption design space and \system{} illustrate another way to reduce the risks of miscommunication caused by the ambiguity in social VR conversations. Particularly, our impact captions can reduce ambiguity by providing contextual information, which is a known effective method for communication in contexts other than social VR ~\cite{cottone2009solving, dey2005designing, miller2017understanding}.

For a single impact caption in \system{}, the integration of textual and non-textual visual elements allows the elements to complement each other and provide mutual confirmation in terms of their meanings. This can reduce ambiguity conveyed by a single element (i.e., a single emoji) (\autoref{finding_ambiguity}). 
At the speech level, the speech-driven approach produces impact captions sequentially aligning with the voice input, in which the conversation contexts could be naturally visualized and presented. 
Moreover, users can persistently present an impact caption by simply dragging and placing it at an arbitrary position in the virtual space (\autoref{sec_visual_clutter}) to intentionally create environmental cues ~\cite{cottone2009solving} for providing contextual information with flexibility.
Overall, these features embedded in \system{} pave the way towards designing communication tools in social VR with the consideration of mitigating ambiguity. 
Future work can refer to the self-explanatory visual design of impact captions to construct visual cues that can convey meanings with clarity and can also leave space for users to actively create environmental cues in the virtual space to support their communication activities.

% \subsubsection{Utilizing Ambiguity in Future Work}
As for utilizing the ambiguity for particular design aims, which is not covered in the current stage of \system{} and the design space of impact captions, we believe it would be a promising research direction for future work that aims to support interpersonal communication and social interactions in social VR.
With the unique affordances ~\cite{mcveigh2022beyond, freeman2021body, freeman2021hugging, wei2022communication} offered by social VR and growing application scenarios with communication needs ~\cite{maloney2020falling, chen2024drink, mei2021cakevr}, ambiguity should have great potential to foster valuable design and mediums to satisfy specific user needs ~\cite{stacey2003against, gaver2003ambiguity}.



\subsection{Design Implications}
Based on \system{} and the findings, we identify the following potential design implications for designing digital mediums and tools to support interpersonal communication in social VR.
With the fast evolution of VR and related computing technologies, the contexts of conducting interpersonal communication in VR may change rapidly. However, we hope these implications can highlight the invariant knowledge learned from \system{} to inspire future work.

\subsubsection{Presenting Verbal Information Selectively}
Verbal information is fundamental in interpersonal communication ~\cite{liu2023visual}. However, when enhancing verbal information in social VR, it is essential to focus on selective presentation rather than displaying every spoken word.
In our user study, participants suggested avoiding presenting every word in speech, since too many insignificant words could be distracting and cause unexpected visual clutter (\autoref{finding_keywords}). 
Although we have already designed a mechanism to softly control the number of impact captions, trying to minimize the possibility of visual clutter (\autoref{sec_visual_clutter}), the POS-tag-based filtering mechanism in the text processor of \system{} is too simple to be an effective keyword extraction method.
With the fact evolution of AI and NLP technologies, future work can explore the ways to involve advanced NLP technologies such as Large Language Models (LLMs) ~\cite{maragheh2023llm} to achieve keyword extraction with accurate understandings of the speech content and the user's intentions.


% For improving \system{}, the keyword extraction method should be able to retrieve meaningful words from lengthy speeches and reduce the number of words to be presented, so that our visual-centered communicative mediums can avoid visual clutter in virtual space, avoid overwhelming caused by too much insignificant information, and make the presentation concise and meaningful.
% Although successful keyword extraction relies on accurate understandings of the speech content and the user's intentions, it is possible now with the advancements of NLP technologies such as Large Language Models (LLMs) ~\cite{maragheh2023llm}. 

\subsubsection{Using Visual Rhetoric to Present Non-verbal Information}
Non-verbal information plays an important role in communication, social interactions ~\cite{mcveigh2022beyond, maloney2020talking, aburumman2022nonverbal, liebman2016s}, and self-presentations ~\cite{freeman2021body, sykownik2022something, zhang2022s} in social VR.
Our work demonstrates that rich visual elements can effectively convey non-verbal information in social VR, highlighting the value of visual rhetoric as a design strategy for communication tools.
However, we currently only use simple mapping rules to decide how captions correspond to specific visual elements in \system{}. These rules are inadequate for sufficiently and accurately expressing the various types of non-verbal information, as pointed out by participants in the user study.
Therefore, future research can start from seeking in-depth understandings of the associations between specific visual elements and non-verbal information (such as color-emotion association ~\cite{hanada2018correspondence, wilms2018color}), and create novel visual rhetoric designs with effectiveness and elegance for supporting various applications of social VR.


\subsubsection{Enhancing the Interactivity of Communication Medium}
The impact captions in \system{} embed rich interactivity, enabling users to create multiple new forms of interpersonal interactive actions (\autoref{sec_interactivity_functions}).
This again demonstrates the unique interactive and immersive nature of social VR ~\cite{maloney2020talking}, highlighting the value of the interactivity for supporting creative, engaging, and emotional communication experiences.
On top of \system{} and previous work, future research can explore more on the interactivity afforded by the digital mediums in social VR, investigating their influences and creating novel designs and technologies to enhance the existing communication channels or even introduce new channels to support interpersonal communication and interactions in social VR.



% \subsubsection{Providing Personalized Digital Mediums to Support}
% When introducing affective factors to computationally generate content for human needs, we should not neglect personalized needs.

% There is a strong user demand for customization options. This need stems from the diverse ways individuals interpret and interact with visual elements ~\autoref{finding_ambiguity}. Different users have unique preferences and cultural backgrounds that influence their perception of impact captions. By allowing customization, users can tailor their experiences, making interactions more meaningful and comfortable.

% Integrating with advanced generative-AI technology
% To implement customization effectively, platforms should offer flexible design options, providing a range of choices for typefaces, sizes, colors, etc.

% Currently, generative AI technology has shown great potential to assist individuals in rapidly and effectively creating rich computer graphics. Previous research has shown that AI can collaborate with humans in creative endeavors ~\cite{wan2023gancollage}, producing digital products that are expressive ~\cite{iluz2023word, xie2023wakey} and serve personalized needs. 
% Combining generative AI technology with the design space of impact captions can lead to more flexibility and expressive capabilities, enabling the creation of content that better supports communication and interaction among users in social VR.

% AI-powered adaptive personalized recommendations and configurations could be a direction to be explored. 

% By supporting customization, social VR platforms can enhance user satisfaction, improve accessibility, and foster a more inclusive and engaging environment.

% Furthermore, to differentiate the parameters for rendering an impact caption based on users' own preferences is technically feasible. 

 

\subsection{Technical Scalability and Future Improvements}
\system{} is theoretically scalable in terms of architecture and algorithms (\autoref{sec_pipeline}). However, the current implementation of \system{} as a proof-of-concept system has limited scalability when considering real-world deployment. We identified three main aspects of the limitations and discuss possible solutions for future improvements.

\subsubsection{Seeking for Better Speech-to-text Solution}
First, our custom speech transcribing algorithm introduces limitations.
The algorithm integrates the Whisper model ~\cite{radford2023robust} with multi-thread processing for approximate real-time processing, which is inferior to the cloud-based end-to-end speech-to-text services provided by business companies in terms of performance (i.e., speed and accuracy). 
Running on laptops further restricts its performance due to the limited computational resources.
For future improvement, we can replace the voice interface module with a well-developed real-time speech transcribing solution, such as a cloud-based business solution or a locally-deployable SDK.

\subsubsection{Reducing Network Load by Simplifying Architecture}
Second, the architecture of \system{} heavily relies on network communication.
The back-end web server works as a centric hub that generates parameters of impact captions and exposes APIs to feed VR applications.
The VR application, as the user end, keeps polling the back-end server to continuously fetch newly generated impact captions through the network. In the meantime, multiple VR application instances also continuously sync with each other to achieve the multi-user session across the network.
As pointed out by recent research, the growing number of users will significantly increase the network load for social VR applications ~\cite{cheng2022we}. This challenge also applies to \system{}.
For improvement, through the perspective of architecture, the back-end server could be reduced, because ideally, all the computations, including speech transcribing and caption generation, can be processed in place in a single computational node (i.e., the VR HMDs). Though this relies on the growth of computational power provided by advanced chips in the future. 
Without the back-end server, only the synchronization mechanism among VR devices requires network resources.

\subsubsection{Simplifying the Hardware Requirements}
Third, the hardware setting is too complex. Currently, we employ a laptop, a microphone, and a VR HMD to serve a single user. This setting requires coordination among the devices to smoothly run \system{}. Even though the setting is manageable under lab settings for user study, it is far from being used by ordinary people out of the lab.
This limitation can also be addressed with the simplification of architecture, as the laptop and external microphone are used for running the back end for speech input and processing. Once those computational tasks are embedded into VR HMDs, no extra hardware will be needed for \system{}.


% \subsubsection{Limitations on User Study}
% % \subsubsection{Study in Real-World Contexts with Participants with Diverse Backgrounds}
% One limitation of the user study is the lack of consideration for participants' varying levels of VR expertise. This oversight could impact the study's findings, as experienced users might interact with and interpret impact captions differently than those new to VR. The disparity in familiarity can influence engagement levels and the effectiveness of communication, potentially skewing the results.

% Another limitation is the insufficient diversity in the participant sample. The study's conclusions may not be broadly applicable due to the limited range of cultural and personal backgrounds represented. Cultural differences can greatly affect how impact captions are perceived and understood, impacting their overall effectiveness. Addressing this limitation in future research would provide a more comprehensive understanding of user experiences across diverse populations.

% By acknowledging these limitations, future studies can be designed to capture a wider range of perspectives, ultimately leading to more universally applicable insights into the use of impact captions in social VR.

% The scope of our study is limited in terms of its scale and lab setup. Thus, further in-depth and long-term evaluations in real-world contexts would be necessary to gain a
% better understanding of its impact in such settings. For future work, deploying the \system{} tool in work meetings, classrooms, and informal social gatherings could provide valuable insights. 
%However, studying \system{} in different contexts may require different


% \subsubsection{It's Age of AI}

% Might be useful
% A growing body of research is exploring enhancing communication using AI agents:
% https://dl.acm.org/doi/10.1145/3613904.3642163
% https://dl.acm.org/doi/full/10.1145/3544549.3585651

% How People Prompt Generative AI to Create Interactive VR Scenes ~\cite{aghel2024people}

\subsection{\altcolor{Limitations and Future Work}}
\altcolor{
Although \system{} demonstrates the potential of impact captions to enhance interpersonal communication in social VR, several limitations remain. 
First, the current rule-based method for determining visual appearances of captions is simplistic and may lead to ambiguity, as users interpret visual elements like colors and emojis differently. 
Future work could incorporate advanced NLP techniques, such as LLMs, to extract contextually meaningful keywords and adapt visual designs dynamically to user preferences. 
Second, the system's reliance on multiple hardware components (e.g., laptops, external microphones, and VR headsets) limits scalability and real-world deployment. Future improvements could focus on integrating all functionalities into standalone VR headsets to simplify the setup. 
Finally, while the study explored dyad and group conversation scenarios, further research is needed to evaluate \system{} in diverse social VR applications, such as education, live streaming, and accessibility for deaf and hard-of-hearing users. Long-term studies are also required to investigate the impact of using impact captions on communication behaviors and social dynamics in virtual environments.
}

