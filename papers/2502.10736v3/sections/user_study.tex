\section{User Study}
To understand the effectiveness of the design space and \system{} system in supporting interpersonal communication in social VR, we conducted a user study, inviting 14 participants of various backgrounds from local universities to experience simulated conversations in VR with interactive impact captions using \system{}. User feedback was evaluated from both quantitative and qualitative perspectives through a post-study survey and semi-structured interviews. 

% RQ1: What is the user experience of conversation with speech-driven impact captions in social VR scenarios using \system{}?
% RQ2: Does the (visual and interactive) design of impact captions afford meanings in conversations in social VR?

\subsection{Participants}
We recruited 14 participants (6 female and 8 male, aged between 18 and 35) from local universities through advertisements on social media. 
None of the participants overlapped with the four experts involved in the previous co-design activity. 
Five participants (P1 to P5) were novice users who had never used VR head-mounted displays (HMDs) before, while the other nine participants (P6 to P14) self-reported having extensive experience with VR games, social VR, and application development.


\subsection{Procedure}
The user study was conducted in a one-on-one format, where an experimenter (either the first or second author of this paper) guided each participant through the procedure.
The study sessions lasted 75 to 90 minutes and were held in a university lab space. After the study, the participant received a gift card valued \$50 in local currency. For analysis, the study processes were fully audio-taped and the activities in VR were screen-recorded.
Each session utilized two Meta Quest 2 devices and two laptops, each paired with a Bluetooth microphone, for the experimenter and the participant. An additional router was configured to host a local area network to serve the multi-user session of \system{}'s VR application (\autoref{sec_hardware}). 

% Figure showing how the is study is conducted?

The primary goal of this user study was to evaluate \system{} using two common social VR scenarios: (1) a private conversation between two friends and (2) a public discussion on a debatable topic.
The dyad conversation scenario simulated a private conversation designed to evoke rich emotional expressions.
In this scenario, the experimenter and the participant play as close friends to talk about their daily life and personal feelings with the help of impact captions. 
In the multi-person conversation scenario, the participant joined an ongoing discussion, listened to others, and then shared their own opinion.
In the two scenarios, participants will have opportunities to play the role of both speaker (i.e., information sender) and listener (i.e., information receiver) in turns, allowing them to play with various impact caption instances in very different visual and interactive appearances.
Specifically, a full user study session consists of four sections as follows: 

\subsubsection{Introduction and System Walk-through (\textasciitilde20 min)}
At the beginning, the experimenter briefly introduced the background and main purpose of \system{} (i.e., facilitating interpersonal communication in social VR). Next, the experimenter guided the participant to get familiar with basic usages of the hardware devices if they were not, and then walked through the \system{} system. During the walk-through, the experimenter provided verbal and hand-in-hand guidance, ensuring that the participant could see and generate impact captions with their own speech, and know how to interact with the impact captions in VR. After the walk-through, the experimenter would inform the participants about the next dyad and multi-person scenarios.

\subsubsection{Dyad Conversation Scenario (\textasciitilde15-20 min)}
Once the participant and the hardware settings were ready, the experimenter would take another set of devices, go to a separate room (avoiding conflict with the speech-to-text program running on the laptop), and initiate the conversation in VR by telling a pre-defined sad story about losing her cat recently. During the storytelling, the experimenter employed several impact captions to enhance the speech and seek emotional support from the participant. The participant was then asked to comfort the experimenter by telling some happy moments from recent daily life, using impact captions generated along with the conversation's development. 

\subsubsection{Public Discussion Scenario (\textasciitilde15-20 min)}
In this scenario, the participant was asked to join a discussion of the topic ``\textit{what privacy and security issues will arise around AI?}''
The discussion was started between the experimenter and a ``NPC'' character who was configured to speak based on a pre-defined script and timeline, due to the limitation of hardware resources. Once joining the session, the participant was asked to first listen to the ongoing conversation for a while and then present her/his own opinions with the help of impact captions.

\subsubsection{Survey and Semi-structured Interview (\textasciitilde25-30 min)}
After the two conversation scenarios, the participant was asked to complete a survey about their experience with \system{}. The participant was also encouraged to think aloud while completing the questionnaire. When the survey was done, the experimenter would conduct a semi-structured interview with the participant, diving into their experiences and thoughts in depth.


\subsection{Results and Findings of Post-study Survey}
The post-study survey questionnaires consisted of two sections. The first section employs four questions that ask whether the impact caption design space is understandable, interesting, and meaningful.
The second section contains six questions about the user experience with \system{}, considering enjoyment, emotional expression, clarity of presentation, and overall experience of having conversations with impact captions in VR. The questions are designed in a 7-point Likert scale format ~\cite{joshi2015likert}, requiring the participants to respond with their level of agreement on the statements.

\begin{figure}[htb]
    \includegraphics[width=\linewidth]{img/survey_revision.png}
    \caption{
        Post-study Survey with Results. 
        The survey consists of two sections in which the first section contains four questions (Q1-Q4) about the design space of impact captions and the second section contains six questions (Q6-Q10) about the experience with SpeechCap. 
        Overall, participants believed the design space of impcat captions was meaningful and the experiences of using \system{} is enjoyable and helpful.
    }
    \Description{.}
    \label{fig:survey}
\end{figure}

In the first section (\autoref{fig:survey} upper), participants agreed that the design of impact captions for VR communication was both understandable (Q1, M=6.36, SD=0.74) and interesting (Q2, M=6.14, SD=0.95). 
Regarding the visual design of individual captions, 12 participants agreed that combining non-textual elements (ornaments, emojis, speech bubbles) with text was meaningful (Q3, M=5.71, SD=1.07). 
And 13 participants believed that the visual design (i.e., color, typeface, and size) of textual elements was reasonable (Q4, M=5.79, SD=0.89). No participants responded with disagreement on the design of impact captions.

In the second section (\autoref{fig:survey} lower), most of the participants (11/14) agreed that their experiences with \system{} were somewhat enjoyable (Q5, M=5.50, SD=1.22). 

\altcolor{
From an information sender's perspective, participants diverged on the effectiveness of using impact captions for emotional expression in social VR (Q6, M=4.29, SD=1.20). Six participants agreed that impact captions can help express their emotions effectively, while the other five committed objections. Two participants responded with a neutral opinion. 
For the next question about clarity (Q7, M=4.43, SD=0.76), six participants responded with agreement, while five participants stayed neutral and one responded ``somewhat disagreed''.
The results of these two questions indicate that \system{} is not always helpful for users to express their emotions and thoughts. 
}

From a receiver's perspective, the majority of the participants (13/14) agreed that they could perceive the emotions of others by seeing and playing with the impact captions in VR (Q8, M=5.43, SD=0.65). 
\altcolor{
Most participants (12/14) agreed that impact captions improved their understanding of others in VR (Q9, M=5.36, SD=0.74). 
}
In addition, ten participants agreed that impact captions were useful in setting the tone of conversation (Q10, M=5.00, SD=0.96).
\altcolor{
Overall, \system{} seems more helpful for information receivers as they felt the conversation clear and understandable, while around half of information senders thought the system failed to improve their expressions.
}

\subsection{Results and Findings of Semi-structured Interviews}
During the study, All participants completed both scenarios, playing the roles of both sender and receiver in conversations. Creative usages of impact captions in VR emerged from their play-through. 
In the semi-structured interviews, we discussed questions regarding the impact captions' design space and user experiences of \system{} with the participants based on their individual performance.
Overall, participants responded positively, describing the impact captions as ``interesting and enjoyable'' (P1, P2, P4, P10, P13).

Two authors analyzed the transcribed scripts of the interviews by iterative open coding ~\cite{corbin2014basics} and finally revealed the following findings showing the meaningfulness of our impact captions' design space, and the usefulness of \system{} system.


\subsubsection{F1: Textual Elements Can Effectively Support Conversations in Social VR}
\label{finding_text}
Participants generally agreed that visible impact captions enhanced their conversational experience in VR (P2, P3, P4, P6, P7, P11, P12, P13, P14). 
On one hand, text elements help users accurately express complex and profound meanings. P12 emphasized the expressive capability of impact captions: ``\textit{The texts within impact captions have a high potential in expressiveness, because texts can convey complex, abstract concepts as well as accurately represent ironic or literary content, which non-textual elements cannot achieve.}''

On the other hand, some participants (P2, P7, P8, P13, P14) believed impact captions help extract and emphasize key information from dialogues. 
In \system{}, impact captions automatically disappear if not touched by users in several seconds (\autoref{sec_visual_clutter}). Therefore, besides filtering trivial words in the back-end processing (\autoref{sec_text_processor}), \system{} also allows users to actively select impact captions with keywords they consider important to remain in VR. ``\textit{...if I was sharing some knowledge with others with \system{}, I could easily make the keywords of my speech persistent and let them floating around my avatar so that my audiences won't lose focus...}'', said P7. 
And when talking about the multi-person conversation scenario, P14 said ``\textit{I'd appreciate \system{} if it can always correctly recognize and show the meaningful words by impact captions. This prevents me from listening to lengthy speeches in meetings.}''

Additionally, one participant (P7), a non-native English speaker, felt that impact captions lower the barrier for her to engage in English conversations. P7 said, ``\textit{English is not my native language, and when speaking with native speakers, I often struggle to understand due to different accents and fast speed of speech... but impact captions allow me to clearly and accurately see what others are saying, and they can remain in the VR space as a conversation record for later review.}''



\subsubsection{\altcolor{F2: Non-textual Elements are Engaging but Ambiguous}}
\label{finding_ambiguity}
Overall, participants agreed that the non-textual visual elements in impact captions are engaging and making the speech-driven captions really ``impactful'' (P1, P2, P3, P4, P5, P6, P8, P10, P11, P12, P13). 
P1 said ``\textit{I love the idea you combine those cute emojis with the colorful texts. It makes those captions not only interesting but also meaningful.}'' 
Among the multiple non-textual dimensions in the design space, the colors, ornaments, emojis, and motion effects are perceived by participants as the most noticeable features (P1, P3, P4, P7, P10, P11, P12). 

\altcolor{
Nevertheless, the non-textual elements in impact captions cannot convey meanings as clearly as texts can do. The ambiguity was reported across multiple dimensions, including color and emoji.
}
First, the current colors of impact captions in \system{} were reported to be confusing and ambiguous by some participants (P1, P8, P9). P1 asked ``\textit{I noticed that those impact captions had different colors, but actually I didn't figure out why a word should be rendered in blue while others were not?}'', and P9 made another similar comment saying that ``\textit{I don't quite understand why you choose orange color for the word "happy" while other words are in white.}''. 
Similar issues arise for emojis. P4 commented, ``\textit{Expressing with visual elements alone can lead to misunderstandings; some people like to use a smiling face for implicit sarcasm or be \'ironic\'}.
These cases may relate to findings of previous research that different people may have different perceptions of the same visual elements when conveying non-verbal meanings ~\cite{hanada2018correspondence, wilms2018color, czkestochowska2022context, miller2017understanding}, revealing the existence of ambiguity in our design of impact captions.

However, on the other hand, three participants (P3, P10, P12) believed that the integration of textual and non-textual elements in impact captions can also mitigate the potential ambiguity. P3 highlighted, ``\textit{I might misunderstand the meaning when only seeing the smiling face, but if there was a word "happy" nearby, it would be much clearer,}''. In other words, the meanings of different components of a single impact caption can mutually reinforce each other, reducing the chances of misinterpretation by the recipient. 
When discussing the color-mapping rules in \system{}, P10 commented, ``\textit{I think using different colors to show the emotions in a conversation is a good idea, and I don't worry about misunderstandings because when the overall tone is positive, I can see most words are in orange. The number of colored captions not only can avoid the ambiguity produced by a single word, but also can reflect how strong the emotional expression is.}''

\altcolor{
In summary, the ambiguity of non-textual elements could reduce the clarity in conversations, while it is still possible to deal with the unavoidable ambiguity with design considerations, such as using the combination of multiple dimensions to complement each other.
}


\subsubsection{F3: Interactivity is a Key to Engaging Communication Experience in Social VR}
\label{finding_interaction}
Most participants (P1, P2, P4, P5, P6, P7, P8, P10, P11, P13, P14) agreed that the interactivity of impact captions in \system{} could bring novel collaborative social experiences and help develop a sense of intimacy between the users in social VR. ``\textit{Throwing a caption to people in social VR makes me think of the "squat and strait" movement before starting a game when playing "Fall Guys", in which everybody feels fun together.}'', said P6. She believed the interpersonal actions mediated by impact captions in \system{} were meaningful for building connections with others in social VR, even such interactive capabilities were somehow ``\textit{unnecessary}'' for a speech-driven captioning system. 

Besides the fundamental interactions, more creative usages of impact captions were explored by the participants.
Note-taking is one method commonly proposed. P7 recalled his experience of the multi-person discussion scenario in our study and said, ``\textit{During the group discussion, I would like to grab the keywords mentioned by other members, enlarge them, and place them in the virtual space, just like using a whiteboard,}''. P4 also talked about similar use cases, saying that ``\textit{I used to capture the key points mentioned by others and record them with notes in meetings. In \system{}, impact captions can be the notes, I can just take the captions aside ... this could also be used in multiplayer reasoning games, right? You can note what others have said (as a basis for reasoning),}''.
Note-taking allows impact captions to persistently present the conversation in the virtual space like dialogue records, achieving a means of asynchronous communication. ``\textit{Impact captions can be like email ... other users can read the meeting record whenever they join the session, as long as the impact captions remain there.} said P12.

Another creative use case was conducted by P10. When conducting the dyad conversation scenario in which there was a sad story about a missing cat, he purposefully generated several impact captions with negative words and used these captions as blocks to construct a small shelter in VR by resizing and placing. P10 explained, ``\textit{When I felt sad and uncomfortable, I always find somewhere to hide myself avoiding meeting with other people. So I take these many "sad" words to build a blue room for taking a break.}''. He also invited the researcher to join his room made by impact captions to relax in VR.


\subsubsection{F4: Needs for Identifying Keywords in Conversations}
\label{finding_keywords}
\altcolor{
Other drawbacks of \system{} were exposed by the user study, too.
}
One of the most commonly asked questions by the participants when they started using \system{} was about how we decided the words to be rendered as impact captions, as they usually found there were too many impact captions emerging when speaking continuously.
After knowing our simple POS-tag-based filtering method to remove functional words, most participants suggested an improvement on it. 
P2 suggested, ``\textit{Don not turn every word into an impact caption. Please extract the key information (of the speech) and only show impact captions of the relevant keywords.}'' 
Other participants, like P11, thought too much text content increased the reading and comprehension costs and then reduced the overall experience of having a conversation with \system{}. P11 complained, ``\textit{No one wants to read that much text when using VR.}'' 
Particularly, in the multi-person conversation scenario, as more impact captions were spawned and accumulated in limited space, some participants (P1, P2) reported that they felt the field of vision was partially obstructed. 


% Talk about user's feed back on the possible visual clutter and the insufficient of keywords extraction.

% -> implication on keywords extraction: take user's preference as input to consider 
% e.g./ for English learners, the system can allows them to record which words are more important to be learnt. sth.//.




