\section{Related Work}
Starting from the background of interpersonal communication in social virtual reality (VR), we highlight the needs for better ways to support communication with both verbal and non-verbal information, and then introduce previous research systems to augment computer-mediated communication (CMC), which inspired our work. Finally, we introduce impact captions and captioning systems for communication purposes in HCI, showing our motivation for this research.

\subsection{Interpersonal Communication in Social Virtual Reality}
Social Virtual Reality (VR) refers to immersive virtual spaces where multiple users can interact synchronously through VR head-mounted displays (HMDs) ~\cite{mcveigh2019shaping, freeman2021body}. It provides high-fidelity virtual presence to facilitate various forms of interpersonal communication with both verbal and non-verbal cues over other computer-mediated communication channels ~\cite{yassien2020design, mcveigh2021case}. 

In an immersive and synchronous environment, social VR can effectively support collaborative tasks and promote social interactions in a wide range of application scenarios, including collaborative prototyping ~\cite{mei2021cakevr}, healthcare and treatment ~\cite{li2020designing, udapola2022social}, immersive learning ~\cite{thanyadit2022xr, peng2021exploring, jensen2018review}, intimate relationship building ~\cite{wang2023designing, freeman2021hugging}, and inter-generational communication ~\cite{shen2024legacysphere, du2024ai, wei2023bridging, baker2019exploring}.

Although social VR has been increasingly applied in various domains, it is still far from fulfilling users’ social and emotional needs as a digital space ~\cite{wei2022communication, tanenbaum2020make, maloney2020talking}. Previous research identified several limitations regarding interpersonal communication in social VR.
A known issue is that current social VR applications do not allow users to easily express emotions (e.g., mood and excitement) and intentions through non-verbal cues, which are common in real-world conversations ~\cite{maloney2020talking, sykownik2023vr, wu2023interactions}, because virtual avatars reduce or even filter out several important non-verbal signals such as facial expressions and body language ~\cite{baker2021avatar, freeman2021body, zhang2022s, lee2022understanding, fu2023mirror}. As an extreme case, imperfect avatars with realism will lead to the uncanny valley effect, bringing discomfortable social experiences to users ~\cite{latoschik2017effect, kyrlitsias2022social}. 
Besides the lack of expressiveness, voice-based communication, a common method in social VR, faces challenges in coordinating speakers in multi-user virtual spaces ~\cite{yan2023conespeech}.

Recent research proposed several computational methods to improve interpersonal communication experiences in social VR, such as generating realistic avatars that could capture users' facial expressions and body movements using deep learning models ~\cite{van2022deep}, adding haptic technologies to facilitate co-presence to allow affective communication ~\cite{fermoselle2020let, ahmed2016reach}, and simulating spatial sound effects to enhance the convenience and flexibility of voice-based communication ~\cite{yan2023conespeech}. 
In summary, all of these efforts aim to make the interpersonal communication in social VR close to the situations of the realistic world. 

However, people appreciate social VR not because it can simulate the real world. Instead, a significant reason is that 
the unique affordances of social VR can offer users immersive and unrealistic social experiences ~\cite{freeman2021body, maloney2020talking}. In other words, social VR can augment social signaling and unlock new social interactions that are unattainable in the realistic world ~\cite{mcveigh2022beyond, mcveigh2021case}.
At present, the potential of virtual reality to create unrealistic experiences for enhancing interpersonal communication for socialization needs is still under-explored. This leaves us opportunities to dive deep into the potentials of virtual reality and build novel tools with the idea of ``superpowers'' ~\cite{mcveigh2022beyond, mcveigh2021case} to support interpersonal communication in social VR.



\subsection{Combining Verbal and Non-verbal Information to Augment Communication}
Both verbal and non-verbal information is crucial in interpersonal communication in social VR ~\cite{palmer1995interpersonal}.
Besides verbal cues that mainly convey semantic meanings, non-verbal cues convey emotions ~\cite{liebman2016s, luo2024emotion}, enhance understanding ~\cite{aburumman2022nonverbal}, regulate interactions ~\cite{maloney2020talking}, reflect cultural norms ~\cite{freeman2021hugging}, and overall enrich communication experiences, whether in offline face-to-face scenarios or online digital spaces.

Recent research in the HCI and CSCW fields has explored ways to involve non-verbal signals in verbal-centric communications (e.g., live presentations) to facilitate interpersonal communication and build social connections through computational approaches ~\cite{liao2022realitytalk, liu2023visual, cao2024elastica, an2024emowear, chen2021bubble, aoki2022emoballoon, choi2019emotype}.
A thread of research aims to provide visual aids for computer-mediated spoken presentations. ``RealityTalk'' ~\cite{liao2022realitytalk} explores a speech-driven approach that allows users to give a speech with predefined visual elements while mentioning particular key words. ``Visual Captions'' ~\cite{liu2023visual} and ``CrossTalk'' ~\cite{xia2023crosstalk} further automate the process by introducing machine-learning-based models to predict users' intentions and automatically provide potential visual elements while processing speech input. ``Elastica'' ~\cite{cao2024elastica} further enables adaptive animations on the associated visuals to effectively enhance the expressiveness of presentations.

Beyond visual aids, enhancing emotional communication is another important dimension explored by previous research. For voice messaging interfaces, ``Emowear'' ~\cite{an2024emowear} introduced the concept of ``Emotional Teasers,'' a collection of animated emoticons designed to show the emotional tone of upcoming voice messages for smartwatch users.
For text-centered communication mediums such as text messaging interfaces, previous research has explored how the color and shape of speech bubbles ~\cite{chen2021bubble, aoki2022emoballoon}, and the typeface of textual content ~\cite{choi2019emotype, de2023visualization} can be purposefully designed and computationally generated to convey the speaker's moods in conversations. 

However, still less research explores how communication mediums in social VR can borrow the ideas from other CMC forms to enhance the interpersonal communication experiences, especially with the considerations of integrating both verbal and non-verbal information.
So far, previous research revealed that non-verbal cues play an important and unique role in interpersonal communication in social VR.
In unrealistic virtual spaces, users tend to engage in social interactions with more active and bold non-verbal behaviors ~\cite{maloney2020falling, chen2024drink}. 
This phenomenon reflects a ``proteus effect'' in which users intentionally manipulate virtual avatars to express themselves beyond pure verbal-language-based communication ~\cite{maloney2020talking}. 
With more application scenarios and novel user activities emerging in social VR, strong demands for tools for facilitating interpersonal communication and interactions arise ~\cite{tanenbaum2020make}.


\subsection{Impact Captions: A Typographic-Centered Visual Design Beyond Pure Verbal Communication}
Impact captions refer to a type of typographic-centered visual effect that is prevalent in TV shows and online videos to engage viewers ~\cite{sasamoto2014impact}. 
Traditionally, impact captions are used as a supplementary channel to provide information outside the screen (e.g., commentary messages from the TV show's editor ~\cite{o2010japanese}) or to visualize implicit non-verbal information within frames (e.g., characters’ moods or environmental sound effects ~\cite{wang2016visualizing}).
Unlike visual cues in previous work for improving interpersonal communication ~\cite{liao2022realitytalk, liu2023visual, cao2024elastica, an2024emowear, chen2021bubble, aoki2022emoballoon, choi2019emotype}, impact captions always use text as the main visual component that conveys verbal information and apply artistic modifications with additional visual decorations to textual elements to convey non-verbal cues simultaneously. The integration of both verbal and non-verbal information in the visual design of impact captions makes the captions a powerful medium that can provide rich semantics, evoke emotional reactions in viewers, and provoke thoughts ~\cite{o2010japanese, sasamoto2021hookability, chow2023impact}.

HCI researchers have noticed the potential of captioning mechanisms in supporting communication and have built captioning systems to help people with deaf and hard-of-hearing (DHH) situations perceive in-depth information in videos ~\cite{kim2023visible, de2023visualization, bragg2017designing, wang2016visualizing, seto2010subtitle}. In these cases, modifications on textual elements (e.g., irregular typefaces, coloring, and introducing dynamic visual effects) of subtitles have been proved to be effective in conveying semantic information of both verbal words and implicit non-verbal content of videos ~\cite{kim2023visible, de2023visualization, seto2010subtitle}. Yet, their explorations have not reached the scope of immersive media, such as VR.
When considering textual captions in VR, another line of research indicates that the reading experience of texts in VR varies depending on the displaying conditions ~\cite{rzayev2021reading}, and prolonged reading would reduce the comfort of using VR ~\cite{ubur2024easycaption}. 
Yet, it is also unknown whether typographic-centered impact captions can effectively mediate communication in social VR.

To fill the research gap on tools for interpersonal communication in social VR and to respond to the needs of social VR users, this work explores how impact captions, as a type of elegant typographic design, can be applied to mediate and facilitate interpersonal communication in social VR with the inspirations from previous research on augmenting computer-mediated communication using visual cues and captioning mechanisms.
By investigating a design space for using impact captions as a communication tool and conducting a study with the proof-of-concept system, we demonstrate a concrete example envisioning the potentials of social VR in interpersonal communication and socialization.

