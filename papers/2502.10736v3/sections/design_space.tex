\section{Design Space of Impact Captions}
\label{section_design_space}
In order to introduce impact captions into social VR as a medium for interpersonal communication, we explored the design space of impact captions through a content analysis on the TV variety show videos.
Our design space consists of the visual design (\autoref{fig:ds_visual_elements}) and the interaction design (\autoref{fig:ds_interactions}) of impact captions. 
Furthermore, the visual design space separately considered textual elements and non-textual elements.

% As a form of typographic design as well as visual rhetoric, impact captions can convey both verbal and non-verbal information on multiple dimensions. 


% \subsection{Methods: Analyzing Videos with Impact Captions}
% To obtain a comprehensive understanding of impact captions currently used in videos (e.g., TV shows and online videos), we conducted a content analysis on a collection of videos of TV show recordings retrieved from popular online video-sharing platforms.

% \subsubsection{Data Collection}
% We collected relevant videos using a two-stage approach.
% In the first stage, we followed the top TV series rankings (i.e., IMDb\footnote{https://www.imdb.com/?ref\_=nv\_home}, TV Time\footnote{https://www.tvtime.com/}, and Douban\footnote{https://m.douban.com/tv/tvshow}) to collect and review videos of three representative variety show series: ``Arashi'' (from Japan), ``Running Man'' (from South Korea), and ``Who is the Murderer'' (from China). These videos helped us get an initial sense and identify preliminary dimensions of the design space.
% In the second stage, we iteratively enhanced the design space by analyzing videos from an enlarged sample video set collected from online video-sharing platforms including YouTube and Bilibili. Specifically, we used the keywords ``variety show with captions'' and ``popular variety shows'' to search on these platforms with a newly registered account on YouTube and Bilibili, respectively. For each keyword, we focused on the top 30 videos of the raw results and filtered out irrelevant or redundant videos. As a result, a total of 46 sample videos were included in the dataset.


% \subsubsection{Content Analysis}
% Three authors collaboratively conducted content analysis on the video collection to build the design space. 
% First, three authors randomly selected a subset of videos (N=10) to individually code the visual elements and behaviors of the impact captions in the videos, with the aim of determining initial dimensions.
% Next, three authors sat together to reflect and discuss their initial insights and ultimately generated a consensus codebook. Finally, three authors reviewed and analyzed the complete data set.
% Consequently, we categorized the impact caption design space into visual space and interaction space, in which visual space focuses on textual and non-textual elements (\autoref{fig:ds_visual_elements}), and interaction space (\autoref{fig:ds_interactions}) relates to motions, physicalization, and embodied interactive operations.




\subsection{Methods: Analyzing Videos with Impact Captions}
Three researchers conducted the content analysis collaboratively on a collection of videos of TV variety show, in which impact captions are commonly used, to explore the design of impact captions.

% To understand how impact captions are designed and how it can interact with the human characters, we conducted a content analysis on a collection of videos of TV show recordings, in which impact captions are commonly used in various scenes.

% To obtain a comprehensive understanding of impact captions currently used in videos (e.g., TV
% shows and online videos), 

\subsubsection{Data Collection}
We collected relevant videos using a two-stage approach.
Firstly, we followed the top TV series rankings (i.e., IMDb\footnote{https://www.imdb.com/?ref\_=nv\_home}, TV Time\footnote{https://www.tvtime.com/}, and Douban\footnote{https://m.douban.com/tv/tvshow}) to select TV shows where impact captions are widely used. 
Specifically, we concentrated on three representative variety show series: ``Arashi'' (from Japan), ``Running Man'' (from South Korea), and ``Who is the Murderer'' (from China). For each show, we reviewed one randomly-selected episode.
Secondly, we enlarged the collection by including videos found from YouTube and Bilibili, which are two popular online video-sharing platforms. 
On both platforms, we used the keywords ``variety show with captions'' and ``popular variety shows'' (we translated the keywords into Chinese version on Bilibili) to search for videos using a newly registered account. From the raw results of each keyword, we took the top-30 videos and filtered out irrelevant or redundant videos. Finally, 46 sample videos were included.

% Secondly, we iteratively enhanced the design space by reviewing videos from two online video-sharing platforms: YouTube and Bilibili. 
% Specifically, we used the keywords ``variety show with captions'' and ``popular variety shows'' to search for videos using a newly registered account, respectively. For each keyword, we focused on the top 30 videos of the raw results and filtered out irrelevant or redundant videos on each platform. As a result, 46 sample videos were included and analyzed.


\subsubsection{Content Analysis}
\altcolor{
Three authors collaboratively conducted content analysis on the video collection to build the design space. 
At the beginning, three authors started from a subset (N=10) of videos, 3 from the three popular TV shows and 7 randomly-selected online videos, to individually code the visual elements and behaviors of the impact captions in the videos, with the aim of determining initial dimensions. 
Through a round of discussion and merging on their initial insights, three authors ultimately determined the dimensions in the design space, including textual visual dimensions (i.e., typeface, size and color), non-textual visual dimensions (i.e., ornament, speech bubble and emoji), and interactions (i.e., physicalization, motion, embodied interaction).
}

\altcolor{
Using the determined dimensions as a codebook, each of the three authors took 13 videos (i.e., one third of the rest videos) to review. During the process, the reviewers also had multiple rounds of discussions on the possible values of some dimensions (e.g., spiky bubbles in speech bubble).
As a result, we found that all of the 49 (i.e., 3 from the TV shows plus 46 online) videos manipulated both textual and non-textual visual dimensions to design impact captions. For the dimensions under the interaction category, 29 videos significant used motions, 13 videos had physicalization, and 15 made impact captions to interplay with human characters.}


% Consequently, we categorized the impact caption design space into visual space and interaction space, in which the visual space consists of textual elements and non-textual elements (\autoref{fig:ds_visual_elements}), and the interaction space (\autoref{fig:ds_interactions}) includes, physicalization, motion and embodied interaction.


\subsection{The Visual Design of Textual Elements}
As the primary visual component, the textual elements of impact captions follow the principles of general typographic design ~\cite{carter2011typographic}, in which \emph{typeface}, \emph{size}, and \emph{color} are three main visual dimensions.

% These three dimensions are usually used to encode non-verbal information, such as indicating the emotions of human characters, to complement the meaning of texts.
% In TV shows, the content of the textual elements varies among conversations, onomatopoeia, voiceover, and entertaining commentary added during the post-editing process ~\cite{sasamoto2014impact}.

\begin{figure}[htb]
    \includegraphics[width=12cm]{img/design_space_visual_revision.png}
    \caption{The Visual Design Space of Impact Captions.
    Two impact captions, a ``No Way'' and a ``Shocked Face'' (translated from Chinese), demonstrate the \textbf{textual} and \textbf{non-textual} elements with relevant dimensions that form the visual design space. 
    For textual elements, the typeface, the color, and the size of texts are three major dimensions. 
    Non-textual elements include emoji, ornament, and speech bubble.}
    \Description{.}
    \label{fig:ds_visual_elements}
\end{figure}

\subsubsection{Typeface}
Typeface denotes the fundamental visual style of each letters in a piece of text ~\cite{carter2011typographic}. It can affect the perceptions and emotional responses of the readers ~\cite{bianchi2021emotional, amare2012seeing}. 
Impact captions widely utilize typeface to make impressions for the audiences ~\cite{sasamoto2021hookability}. 
Although there is no strict standard that defines which typeface should be used under which circumstance, we found that the regularity of strokes can relate to the content of impact captions. Specifically, artistic typefaces with irregular strokes are usually used to highlight characters' moods or to emphasize surprising situations, while formal and regular typefaces (e.g., serif fonts) are used for presenting neutral and factual information.

% This kind of caption provides additional knowledge to the original video content and should be optimized for viewers to read.

% In addition, the visual style of the texts can also be designed to fit the overall visual theme of the video in TV shows. In other words, various deeply customized typefaces were created for impact captions in current TV shows beyond standard typefaces used in common computer interfaces such as desktop and mobile phones.



\subsubsection{Size}
The size of the textual elements is a powerful dimension used for several purposes.
First, impact captions with changeable sizes attract attention, making the particular text content stand out on the screen to engage viewers.
Second, larger texts helps enhance the readability and accessibility of video content.
Third, size can convey liveliness atmosphere and the excitement of characters.
Additionally, size can also encode some highly abstract semantic meanings, such as strength, effectiveness, and severity.

\subsubsection{Color}
\label{sec_space_color}
Similar to size, color can be vibrant and eye-catching to attract the audience's attention and highlight important information. 
In addition, color of the textual elements of impact captions is commonly used to imply the moods of characters in TV shows, which reflects the color-emotion associations in human perceptions ~\cite{plutchik2013theories, hanada2018correspondence}.
% Empirical evidence shows that bright and highly-saturated colors associate with positive feelings, while dark and low-saturated colors tend to negative feelings ~\cite{wilms2018color, hanada2018correspondence, plutchik2013theories, chen2021bubble}.
Although the perceptions of the emotion conveyed by the same color can vary among different people ~\cite{wilms2018color, hanada2018correspondence, chen2021bubble}, the color-emotion associations still reveal the potential of color as a dimension to convey emotional information for bi-directional interpersonal communication.


% Because the color-emotion associations are not strict one-to-one mapping rules. A single color may reflect more than one type of emotion and vice versa ~\cite{hanada2018correspondence, wilms2018color}. Moreover, the perceptions of emotion conveyed by the same color also vary among different groups of people ~\cite{wilms2018color, hanada2018correspondence, chen2021bubble}.}

% \altcolor{Nevertheless, the color-emotion associations still highlight the potential of using color to convey emotional information for interpersonal communication bi-directionally. Color can help users receive emotional information from others and express emotional feelings of themselves.}


\subsection{The Visual Design of Non-textual Elements}
We identified \emph{typographic ornaments}, \emph{speech bubbles}, and \emph{emojis \& emoticons} as three types of commonly used non-textual elements of impact captions through the content analysis.
% In general, these elements provide non-verbal cues to convey invisible information, enhance expressiveness, and leverage engaging communication experiences.

\subsubsection{Typographic ornaments}
Typographic ornaments refer to the decorative elements or symbols used to embellish and enhance the appearance of impact captions. They are typically small, non-alphabetic characters that add artistic flair and visual interest to the textual elements.
For example, the ``erupting gas'' ornaments strengthen the tone of saying ``No Way'' (\autoref{fig:ds_visual_elements}).

\subsubsection{Speech bubbles}
Speech bubbles (a.k.a. speech balloons, ornamental frames) refer to the background containers to display text inside.
In comics, speech bubbles is widely used for presenting speech or thoughts and indicating the source of the speech or thoughts with a tail pointing to characters ~\cite{cohn2013beyond}. 
As a non-textual visual element in impact captions, speech bubbles not only inherit the functionalities as they have in comics, but also convey non-verbal information such as the emotion of characters and the tone of speech through shape and color. This feature has been in other contexts like text messaging ~\cite{aoki2022emoballoon}.

\subsubsection{Emojis and Emoticons}
Emojis and Emoticons, as non-textual glyphs that represent facial expressions ~\cite{lo2008nonverbal}, are a special group of decorative elements used in impact captions to convey feelings or simulate human reactions that can not be easily expressed through texts alone.
For example, the ``amazed face'' emoji in the lower impact caption in \autoref{fig:ds_visual_elements} visually repeats the meaning of the text to enhance the impressiveness.

% commonly used in text-based communication, such as text messaging, social media posts, and online forums, 

% Emojis and emoticons can be integrated into impact captions to enhance the emotional tone and expressiveness.


\subsection{The Interaction Design of Impact Captions}
\altcolor{
Shifting from video to VR, impact captions are no longer post-edited visual effects but become ``alive''---real-time rendering allows impact captions to lively interact with users, while the human-caption interactions in VR remain under-explored. 
Through the content analysis, we found that impact captions in TV shows are often designed to simulate physical properties and possess motion effects, or made to coordinate with the embodied actions of human characters. 
Inspired by these post-edited behaviors, we explored the interaction design space of impact captions for VR, considering \emph{Physicalization}, \emph{Motion}, and \emph{Embodied Interaction}.
}

% Ideally, various user inputs such as voice and embodied actions (e.g., gestures and body movements) can be used to trigger the interactions with impact captions 


\subsubsection{Physicalization}
Physicalization allows virtual objects to simulate physical properties to create tangible sensations for users to enrich their interactions with digital user interfaces ~\cite{sauve2024physicalization, hornecker2006getting}.
We found that impact captions can also appear like they have physical properties in TV show videos to convey non-verbal meanings. Three commonly used physical properties are mass, velocity, and volume (\autoref{fig:ds_interactions} A). 
Mass implies the perception of weight and can be used to represent the feeling of ``light'' and ``heavy'' of abstract concepts such as the seriousness of speech. 
Velocity associates with time, indicating the sense of urgency. 
Volume relate to the size of text in impact captions but the overall volume of an impact caption can still convey the sense of ``small'' and ``big'' without words.

% Overall, physicalization offers opportunities for impact captions to achieve tangible interactions ~\cite{hornecker2006getting} in interpersonal communication in social VR. 

% Our design space includes two physical quantities: mass and velocity \autoref{fig:ds_interactions}.

% Mass directly relates to the perception of ``light'' and ``heavy''. When impact captions are assigned mass, gravity effects can be applied to them so that they would naturally convey the degree of abstraction in terms of weight.
% For example, assigning gravitational acceleration to an impact caption with the content ``heavy-hearted'' results in a dropping motion, physically conveying the feeling of ``heaviness''.

% The concept of velocity is related to time. When adjusting the motion speed of impact captions, it can enhance the sense of urgency in expressing the textual content.

% Using the physical engine provided by current VR technology, impact captions can be endowed with various physical effects. 
% These physical effects allow impact captions to behave like objects in the real world, helping users establish perception beyond language.

% For impact captions with specific meanings, physical sensations can be employed to enhance the semantics of the text. 



\begin{figure*}[ht]
    \centering
    \includegraphics[width=\linewidth]{img/design_space_interaction_r3.png}
    \caption{
        The Interaction Design of Impact Captions.
        The design space includes three dimensions: \textbf{Physicalization}, \textbf{Motion}, and \textbf{Interaction}.
        With Physicalization, impact captions can appear like physical objects to be affected by the gravity with mass, have velocity for movement, and take spaces with volume.
        With Motion, impact captions appear to be ``alive'' and be responsive to user actions.
        Interaction describes how users can play with impact captions using embodied interaction.
    }
    \Description{.}
    \label{fig:ds_interactions}
\end{figure*}


\subsubsection{Motion}
Motions make impact captions alive and attractive by endowing changing appearances. 
%Motions can be independent (i.e., only affecting an impact caption itself) or dependent (i.e., relying on other objects to take effect). 
Four kinds of motions were found and included in our design space: shivering, blinking, and explosion (\autoref{fig:ds_interactions} B).
Shivering means that impact captions will swing periodically . 
Blinking makes the color of visual components (e.g., text or speech bubble) change rapidly and glowing.
Explosion is an effect where an original caption splits into several pieces of fragments or replicas spreading around.
Circling makes impact captions orbit an object or human characters.

% Surrounding is a useful motion where impact captions move following an orbit. Surrounding impact captions usually represent the unique personalities or properties of avatars.


\subsubsection{Embodied Interaction}
Embodied interaction emphasizes the integration of the human body and physical actions, such as gestures ~\cite{luo2024emotion} and bodily movements ~\cite{mueller2018experiencing}, as integral components of interaction with digital technology ~\cite{smith2018communication, kirsh2013embodied}.
Inspired by the patterns of how impact captions interplay with characters in TV shows, we include four gestures (i.e., drag, drop, stretch, and throw) and a bodily movement (i.e., attach to avatar) in our design space.
With these embodied interactions as triggers, users can intuitively manipulate and play with impact captions in VR.

% We found that impact captions, as a post-edited visual effects in TV shows, can be purposefully made to ``interact'' with human characters. Those patterns inspired our design to enable embodied interactions with impact captions in VR for interpersonal communication. 

