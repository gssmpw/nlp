@inproceedings{9355301,
	title        = {{ZeRO: Memory optimizations Toward Training Trillion Parameter Models}},
	author       = {Rajbhandari, Samyam and Rasley, Jeff and Ruwase, Olatunji and He, Yuxiong},
	year         = 2020,
	booktitle    = {SC20: International Conference for High Performance Computing, Networking, Storage and Analysis},
	pages        = {1--16},
	doi          = {10.1109/SC41405.2020.00024},
	keywords     = {Training;Solid modeling;Computational modeling;Memory management;Redundancy;Parallel processing;Data models}
}
@misc{aimo_aime,
	title        = {{AIMO Validation AIME}},
	author       = {AI-MO},
	year         = 2023,
	journal      = {Hugging Face repository},
	publisher    = {Hugging Face},
	howpublished = {\url{https://huggingface.co/datasets/AI-MO/aimo-validation-aime}}
}
@inproceedings{allen-zhu2025physics,
	title        = {{Physics of Language Models: Part 3.3, Knowledge Capacity Scaling Laws}},
	author       = {Zeyuan Allen-Zhu and Yuanzhi Li},
	year         = 2025,
	booktitle    = {The Thirteenth International Conference on Learning Representations},
	url          = {https://openreview.net/forum?id=FxNNiUgtfa}
}
@misc{bai2022constitutionalaiharmlessnessai,
	title        = {{Constitutional AI: Harmlessness from AI Feedback}},
	author       = {Yuntao Bai and Saurav Kadavath and Sandipan Kundu and Amanda Askell and Jackson Kernion and Andy Jones and Anna Chen and Anna Goldie and Azalia Mirhoseini and Cameron McKinnon and Carol Chen and Catherine Olsson and Christopher Olah and Danny Hernandez and Dawn Drain and Deep Ganguli and Dustin Li and Eli Tran-Johnson and Ethan Perez and Jamie Kerr and Jared Mueller and Jeffrey Ladish and Joshua Landau and Kamal Ndousse and Kamile Lukosuite and Liane Lovitt and Michael Sellitto and Nelson Elhage and Nicholas Schiefer and Noemi Mercado and Nova DasSarma and Robert Lasenby and Robin Larson and Sam Ringer and Scott Johnston and Shauna Kravec and Sheer El Showk and Stanislav Fort and Tamera Lanham and Timothy Telleen-Lawton and Tom Conerly and Tom Henighan and Tristan Hume and Samuel R. Bowman and Zac Hatfield-Dodds and Ben Mann and Dario Amodei and Nicholas Joseph and Sam McCandlish and Tom Brown and Jared Kaplan},
	year         = 2022,
	url          = {https://arxiv.org/abs/2212.08073},
	eprint       = {2212.08073},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
@misc{beeching2024scalingtesttimecompute,
	title        = {{Scaling test-time compute with open models}},
	author       = {Edward Beeching and Lewis Tunstall and Sasha Rush},
	url          = {https://huggingface.co/spaces/HuggingFaceH4/blogpost-scaling-test-time-compute},
    year         = {2024}
}
@misc{bespokestratos,
	title        = {{Bespoke-Stratos: The unreasonable effectiveness of reasoning distillation}},
	author       = {Bespoke Labs},
	year         = 2025,
	note         = {Accessed: 2025-01-22},
	howpublished = {www.bespokelabs.ai/blog/bespoke-stratos-the-unreasonable-effectiveness-of-reasoning-distillation}
}
@article{Besta_Blach_Kubicek_Gerstenberger_Podstawski_Gianinazzi_Gajda_Lehmann_Niewiadomski_Nyczyk_Hoefler_2024,
	title        = {{Graph of Thoughts: Solving Elaborate Problems with Large Language Models}},
	author       = {Besta, Maciej and Blach, Nils and Kubicek, Ales and Gerstenberger, Robert and Podstawski, Michal and Gianinazzi, Lukas and Gajda, Joanna and Lehmann, Tomasz and Niewiadomski, Hubert and Nyczyk, Piotr and Hoefler, Torsten},
	year         = 2024,
	month        = {Mar.},
	journal      = {Proceedings of the AAAI Conference on Artificial Intelligence},
	volume       = 38,
	number       = 16,
	pages        = {17682--17690},
	doi          = {10.1609/aaai.v38i16.29720},
	url          = {https://ojs.aaai.org/index.php/AAAI/article/view/29720},
	abstractnote = {We introduce Graph of Thoughts (GoT): a framework that advances prompting capabilities in large language models (LLMs) beyond those offered by paradigms such as Chain-of-Thought or Tree of Thoughts (ToT). The key idea and primary advantage of GoT is the ability to model the information generated by an LLM as an arbitrary graph, where units of information (&quot;LLM thoughts&quot;) are vertices, and edges correspond to dependencies between these vertices. This approach enables combining arbitrary LLM thoughts into synergistic outcomes, distilling the essence of whole networks of thoughts, or enhancing thoughts using feedback loops. We illustrate that GoT offers advantages over state of the art on different tasks, for example increasing the quality of sorting by 62% over ToT, while simultaneously reducing costs by &gt;31%. We ensure that GoT is extensible with new thought transformations and thus can be used to spearhead new prompting schemes. This work brings the LLM reasoning closer to human thinking or brain mechanisms such as recurrence, both of which form complex networks}
}
@misc{bi2025forestofthoughtscalingtesttimecompute,
	title        = {{Forest-of-Thought: Scaling Test-Time Compute for Enhancing LLM Reasoning}},
	author       = {Zhenni Bi and Kai Han and Chuanjian Liu and Yehui Tang and Yunhe Wang},
	year         = 2025,
	url          = {https://arxiv.org/abs/2412.09078},
	eprint       = {2412.09078},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
@misc{c,
	title        = {{Prompt-Based Monte Carlo Tree Search for Mitigating Hallucinations in Large Models}},
	author       = {Zhihua Duan and Jialin Wang},
	year         = 2025,
	url          = {https://arxiv.org/abs/2501.13942},
	eprint       = {2501.13942},
	archiveprefix = {arXiv},
	primaryclass = {cs.AI}
}
@inproceedings{chen-etal-2024-breaking,
	title        = {{Breaking Language Barriers in Multilingual Mathematical Reasoning: Insights and Observations}},
	author       = {Chen, Nuo  and Zheng, Zinan  and Wu, Ning  and Gong, Ming  and Zhang, Dongmei  and Li, Jia},
	year         = 2024,
	month        = nov,
	booktitle    = {Findings of the Association for Computational Linguistics: EMNLP 2024},
	publisher    = {Association for Computational Linguistics},
	address      = {Miami, Florida, USA},
	pages        = {7001--7016},
	doi          = {10.18653/v1/2024.findings-emnlp.411},
	url          = {https://aclanthology.org/2024.findings-emnlp.411/},
	editor       = {Al-Onaizan, Yaser  and Bansal, Mohit  and Chen, Yun-Nung},
}
@misc{chen2023programthoughtspromptingdisentangling,
	title        = {{Program of Thoughts Prompting: Disentangling Computation from Reasoning for Numerical Reasoning Tasks}},
	author       = {Wenhu Chen and Xueguang Ma and Xinyi Wang and William W. Cohen},
	year         = 2023,
	url          = {https://arxiv.org/abs/2211.12588},
	eprint       = {2211.12588},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
@misc{cobbe2021trainingverifierssolvemath,
	title        = {{Training Verifiers to Solve Math Word Problems}},
	author       = {Karl Cobbe and Vineet Kosaraju and Mohammad Bavarian and Mark Chen and Heewoo Jun and Lukasz Kaiser and Matthias Plappert and Jerry Tworek and Jacob Hilton and Reiichiro Nakano and Christopher Hesse and John Schulman},
	year         = 2021,
	url          = {https://arxiv.org/abs/2110.14168},
	eprint       = {2110.14168},
	archiveprefix = {arXiv},
	primaryclass = {cs.LG}
}
@misc{cui2024ultrafeedbackboostinglanguagemodels,
	title        = {{UltraFeedback: Boosting Language Models with Scaled AI Feedback}},
	author       = {Ganqu Cui and Lifan Yuan and Ning Ding and Guanming Yao and Bingxiang He and Wei Zhu and Yuan Ni and Guotong Xie and Ruobing Xie and Yankai Lin and Zhiyuan Liu and Maosong Sun},
	year         = 2024,
	url          = {https://arxiv.org/abs/2310.01377},
	eprint       = {2310.01377},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
@misc{dao2023flashattention2fasterattentionbetter,
	title        = {{FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning}},
	author       = {Tri Dao},
	year         = 2023,
	url          = {https://arxiv.org/abs/2307.08691},
	eprint       = {2307.08691},
	archiveprefix = {arXiv},
	primaryclass = {cs.LG}
}
@misc{deepseekai2025deepseekr1incentivizingreasoningcapability,
	title        = {{DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning}},
	author       = {DeepSeek-AI},
	year         = 2025,
	url          = {https://arxiv.org/abs/2501.12948},
	eprint       = {2501.12948},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
@inproceedings{ding-etal-2024-everything,
	title        = {{Everything of Thoughts: Defying the Law of Penrose Triangle for Thought Generation}},
	author       = {Ding, Ruomeng  and Zhang, Chaoyun  and Wang, Lu  and Xu, Yong  and Ma, Minghua  and Zhang, Wei  and Qin, Si  and Rajmohan, Saravan  and Lin, Qingwei  and Zhang, Dongmei},
	year         = 2024,
	month        = aug,
	booktitle    = {Findings of the Association for Computational Linguistics: ACL 2024},
	publisher    = {Association for Computational Linguistics},
	address      = {Bangkok, Thailand},
	pages        = {1638--1662},
	doi          = {10.18653/v1/2024.findings-acl.95},
	url          = {https://aclanthology.org/2024.findings-acl.95/},
	editor       = {Ku, Lun-Wei  and Martins, Andre  and Srikumar, Vivek},
}
@misc{duan2025promptbasedmontecarlotree,
	title        = {{Prompt-Based Monte Carlo Tree Search for Mitigating Hallucinations in Large Models}},
	author       = {Zhihua Duan and Jialin Wang},
	year         = 2025,
	url          = {https://arxiv.org/abs/2501.13942},
	eprint       = {2501.13942},
	archiveprefix = {arXiv},
	primaryclass = {cs.AI}
}
@inproceedings{evalperf,
	title        = {{Evaluating Language Models for Efficient Code Generation}},
	author       = {Liu, Jiawei and Xie, Songrun and Wang, Junhao and Wei, Yuxiang and Ding, Yifeng and Zhang, Lingming},
	year         = 2024,
	booktitle    = {First Conference on Language Modeling},
	url          = {https://openreview.net/forum?id=IBCBMeAhmC}
}
@inproceedings{evalplus,
	title        = {{Is Your Code Generated by Chat{GPT} Really Correct? Rigorous Evaluation of Large Language Models for Code Generation}},
	author       = {Liu, Jiawei and Xia, Chunqiu Steven and Wang, Yuyao and Zhang, Lingming},
	year         = 2023,
	booktitle    = {Thirty-seventh Conference on Neural Information Processing Systems},
	url          = {https://openreview.net/forum?id=1qvx610Cu7}
}
@misc{gao2023palprogramaidedlanguagemodels,
	title        = {{PAL: Program-aided Language Models}},
	author       = {Luyu Gao and Aman Madaan and Shuyan Zhou and Uri Alon and Pengfei Liu and Yiming Yang and Jamie Callan and Graham Neubig},
	year         = 2023,
	url          = {https://arxiv.org/abs/2211.10435},
	eprint       = {2211.10435},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
@misc{grattafiori2024llama3herdmodels,
	title        = {{The Llama 3 Herd of Models}},
	author       = {Aaron Grattafiori and Abhimanyu Dubey and Abhinav Jauhri and Abhinav Pandey and Abhishek Kadian and Ahmad Al-Dahle and Aiesha Letman and Akhil Mathur and Alan Schelten and Alex Vaughan and Amy Yang and Angela Fan and Anirudh Goyal and Anthony Hartshorn and Aobo Yang and Archi Mitra and Archie Sravankumar and Artem Korenev and Arthur Hinsvark and Arun Rao and Aston Zhang and Aurelien Rodriguez and Austen Gregerson and Ava Spataru and Baptiste Roziere and Bethany Biron and Binh Tang and Bobbie Chern and Charlotte Caucheteux and Chaya Nayak and Chloe Bi and Chris Marra and Chris McConnell and Christian Keller and Christophe Touret and Chunyang Wu and Corinne Wong and Cristian Canton Ferrer and Cyrus Nikolaidis and Damien Allonsius and Daniel Song and Danielle Pintz and Danny Livshits and Danny Wyatt and David Esiobu and Dhruv Choudhary and Dhruv Mahajan and Diego Garcia-Olano and Diego Perino and Dieuwke Hupkes and Egor Lakomkin and Ehab AlBadawy and Elina Lobanova and Emily Dinan and Eric Michael Smith and Filip Radenovic and Francisco Guzmán and Frank Zhang and Gabriel Synnaeve and Gabrielle Lee and Georgia Lewis Anderson and Govind Thattai and Graeme Nail and Gregoire Mialon and Guan Pang and Guillem Cucurell and Hailey Nguyen and Hannah Korevaar and Hu Xu and Hugo Touvron and Iliyan Zarov and Imanol Arrieta Ibarra and Isabel Kloumann and Ishan Misra and Ivan Evtimov and Jack Zhang and Jade Copet and Jaewon Lee and Jan Geffert and Jana Vranes and Jason Park and Jay Mahadeokar and Jeet Shah and Jelmer van der Linde and Jennifer Billock and Jenny Hong and Jenya Lee and Jeremy Fu and Jianfeng Chi and Jianyu Huang and Jiawen Liu and Jie Wang and Jiecao Yu and Joanna Bitton and Joe Spisak and Jongsoo Park and Joseph Rocca and Joshua Johnstun and Joshua Saxe and Junteng Jia and Kalyan Vasuden Alwala and Karthik Prasad and Kartikeya Upasani and Kate Plawiak and Ke Li and Kenneth Heafield and Kevin Stone and Khalid El-Arini and Krithika Iyer and Kshitiz Malik and Kuenley Chiu and Kunal Bhalla and Kushal Lakhotia and Lauren Rantala-Yeary and Laurens van der Maaten and Lawrence Chen and Liang Tan and Liz Jenkins and Louis Martin and Lovish Madaan and Lubo Malo and Lukas Blecher and Lukas Landzaat and Luke de Oliveira and Madeline Muzzi and Mahesh Pasupuleti and Mannat Singh and Manohar Paluri and Marcin Kardas and Maria Tsimpoukelli and Mathew Oldham and Mathieu Rita and Maya Pavlova and Melanie Kambadur and Mike Lewis and Min Si and Mitesh Kumar Singh and Mona Hassan and Naman Goyal and Narjes Torabi and Nikolay Bashlykov and Nikolay Bogoychev and Niladri Chatterji and Ning Zhang and Olivier Duchenne and Onur Çelebi and Patrick Alrassy and Pengchuan Zhang and Pengwei Li and Petar Vasic and Peter Weng and Prajjwal Bhargava and Pratik Dubal and Praveen Krishnan and Punit Singh Koura and Puxin Xu and Qing He and Qingxiao Dong and Ragavan Srinivasan and Raj Ganapathy and Ramon Calderer and Ricardo Silveira Cabral and Robert Stojnic and Roberta Raileanu and Rohan Maheswari and Rohit Girdhar and Rohit Patel and Romain Sauvestre and Ronnie Polidoro and Roshan Sumbaly and Ross Taylor and Ruan Silva and Rui Hou and Rui Wang and Saghar Hosseini and Sahana Chennabasappa and Sanjay Singh and Sean Bell and Seohyun Sonia Kim and Sergey Edunov and Shaoliang Nie and Sharan Narang and Sharath Raparthy and Sheng Shen and Shengye Wan and Shruti Bhosale and Shun Zhang and Simon Vandenhende and Soumya Batra and Spencer Whitman and Sten Sootla and Stephane Collot and Suchin Gururangan and Sydney Borodinsky and Tamar Herman and Tara Fowler and Tarek Sheasha and Thomas Georgiou and Thomas Scialom and Tobias Speckbacher and Todor Mihaylov and Tong Xiao and Ujjwal Karn and Vedanuj Goswami and Vibhor Gupta and Vignesh Ramanathan and Viktor Kerkez and Vincent Gonguet and Virginie Do and Vish Vogeti and Vítor Albiero and Vladan Petrovic and Weiwei Chu and Wenhan Xiong and Wenyin Fu and Whitney Meers and Xavier Martinet and Xiaodong Wang and Xiaofang Wang and Xiaoqing Ellen Tan and Xide Xia and Xinfeng Xie and Xuchao Jia and Xuewei Wang and Yaelle Goldschlag and Yashesh Gaur and Yasmine Babaei and Yi Wen and Yiwen Song and Yuchen Zhang and Yue Li and Yuning Mao and Zacharie Delpierre Coudert and Zheng Yan and Zhengxing Chen and Zoe Papakipos and Aaditya Singh and Aayushi Srivastava and Abha Jain and Adam Kelsey and Adam Shajnfeld and Adithya Gangidi and Adolfo Victoria and Ahuva Goldstand and Ajay Menon and Ajay Sharma and Alex Boesenberg and Alexei Baevski and Allie Feinstein and Amanda Kallet and Amit Sangani and Amos Teo and Anam Yunus and Andrei Lupu and Andres Alvarado and Andrew Caples and Andrew Gu and Andrew Ho and Andrew Poulton and Andrew Ryan and Ankit Ramchandani and Annie Dong and Annie Franco and Anuj Goyal and Aparajita Saraf and Arkabandhu Chowdhury and Ashley Gabriel and Ashwin Bharambe and Assaf Eisenman and Azadeh Yazdan and Beau James and Ben Maurer and Benjamin Leonhardi and Bernie Huang and Beth Loyd and Beto De Paola and Bhargavi Paranjape and Bing Liu and Bo Wu and Boyu Ni and Braden Hancock and Bram Wasti and Brandon Spence and Brani Stojkovic and Brian Gamido and Britt Montalvo and Carl Parker and Carly Burton and Catalina Mejia and Ce Liu and Changhan Wang and Changkyu Kim and Chao Zhou and Chester Hu and Ching-Hsiang Chu and Chris Cai and Chris Tindal and Christoph Feichtenhofer and Cynthia Gao and Damon Civin and Dana Beaty and Daniel Kreymer and Daniel Li and David Adkins and David Xu and Davide Testuggine and Delia David and Devi Parikh and Diana Liskovich and Didem Foss and Dingkang Wang and Duc Le and Dustin Holland and Edward Dowling and Eissa Jamil and Elaine Montgomery and Eleonora Presani and Emily Hahn and Emily Wood and Eric-Tuan Le and Erik Brinkman and Esteban Arcaute and Evan Dunbar and Evan Smothers and Fei Sun and Felix Kreuk and Feng Tian and Filippos Kokkinos and Firat Ozgenel and Francesco Caggioni and Frank Kanayet and Frank Seide and Gabriela Medina Florez and Gabriella Schwarz and Gada Badeer and Georgia Swee and Gil Halpern and Grant Herman and Grigory Sizov and Guangyi and Zhang and Guna Lakshminarayanan and Hakan Inan and Hamid Shojanazeri and Han Zou and Hannah Wang and Hanwen Zha and Haroun Habeeb and Harrison Rudolph and Helen Suk and Henry Aspegren and Hunter Goldman and Hongyuan Zhan and Ibrahim Damlaj and Igor Molybog and Igor Tufanov and Ilias Leontiadis and Irina-Elena Veliche and Itai Gat and Jake Weissman and James Geboski and James Kohli and Janice Lam and Japhet Asher and Jean-Baptiste Gaya and Jeff Marcus and Jeff Tang and Jennifer Chan and Jenny Zhen and Jeremy Reizenstein and Jeremy Teboul and Jessica Zhong and Jian Jin and Jingyi Yang and Joe Cummings and Jon Carvill and Jon Shepard and Jonathan McPhie and Jonathan Torres and Josh Ginsburg and Junjie Wang and Kai Wu and Kam Hou U and Karan Saxena and Kartikay Khandelwal and Katayoun Zand and Kathy Matosich and Kaushik Veeraraghavan and Kelly Michelena and Keqian Li and Kiran Jagadeesh and Kun Huang and Kunal Chawla and Kyle Huang and Lailin Chen and Lakshya Garg and Lavender A and Leandro Silva and Lee Bell and Lei Zhang and Liangpeng Guo and Licheng Yu and Liron Moshkovich and Luca Wehrstedt and Madian Khabsa and Manav Avalani and Manish Bhatt and Martynas Mankus and Matan Hasson and Matthew Lennie and Matthias Reso and Maxim Groshev and Maxim Naumov and Maya Lathi and Meghan Keneally and Miao Liu and Michael L. Seltzer and Michal Valko and Michelle Restrepo and Mihir Patel and Mik Vyatskov and Mikayel Samvelyan and Mike Clark and Mike Macey and Mike Wang and Miquel Jubert Hermoso and Mo Metanat and Mohammad Rastegari and Munish Bansal and Nandhini Santhanam and Natascha Parks and Natasha White and Navyata Bawa and Nayan Singhal and Nick Egebo and Nicolas Usunier and Nikhil Mehta and Nikolay Pavlovich Laptev and Ning Dong and Norman Cheng and Oleg Chernoguz and Olivia Hart and Omkar Salpekar and Ozlem Kalinli and Parkin Kent and Parth Parekh and Paul Saab and Pavan Balaji and Pedro Rittner and Philip Bontrager and Pierre Roux and Piotr Dollar and Polina Zvyagina and Prashant Ratanchandani and Pritish Yuvraj and Qian Liang and Rachad Alao and Rachel Rodriguez and Rafi Ayub and Raghotham Murthy and Raghu Nayani and Rahul Mitra and Rangaprabhu Parthasarathy and Raymond Li and Rebekkah Hogan and Robin Battey and Rocky Wang and Russ Howes and Ruty Rinott and Sachin Mehta and Sachin Siby and Sai Jayesh Bondu and Samyak Datta and Sara Chugh and Sara Hunt and Sargun Dhillon and Sasha Sidorov and Satadru Pan and Saurabh Mahajan and Saurabh Verma and Seiji Yamamoto and Sharadh Ramaswamy and Shaun Lindsay and Shaun Lindsay and Sheng Feng and Shenghao Lin and Shengxin Cindy Zha and Shishir Patil and Shiva Shankar and Shuqiang Zhang and Shuqiang Zhang and Sinong Wang and Sneha Agarwal and Soji Sajuyigbe and Soumith Chintala and Stephanie Max and Stephen Chen and Steve Kehoe and Steve Satterfield and Sudarshan Govindaprasad and Sumit Gupta and Summer Deng and Sungmin Cho and Sunny Virk and Suraj Subramanian and Sy Choudhury and Sydney Goldman and Tal Remez and Tamar Glaser and Tamara Best and Thilo Koehler and Thomas Robinson and Tianhe Li and Tianjun Zhang and Tim Matthews and Timothy Chou and Tzook Shaked and Varun Vontimitta and Victoria Ajayi and Victoria Montanez and Vijai Mohan and Vinay Satish Kumar and Vishal Mangla and Vlad Ionescu and Vlad Poenaru and Vlad Tiberiu Mihailescu and Vladimir Ivanov and Wei Li and Wenchen Wang and Wenwen Jiang and Wes Bouaziz and Will Constable and Xiaocheng Tang and Xiaojian Wu and Xiaolan Wang and Xilun Wu and Xinbo Gao and Yaniv Kleinman and Yanjun Chen and Ye Hu and Ye Jia and Ye Qi and Yenda Li and Yilin Zhang and Ying Zhang and Yossi Adi and Youngjin Nam and Yu and Wang and Yu Zhao and Yuchen Hao and Yundi Qian and Yunlu Li and Yuzi He and Zach Rait and Zachary DeVito and Zef Rosnbrick and Zhaoduo Wen and Zhenyu Yang and Zhiwei Zhao and Zhiyu Ma},
	year         = 2024,
	url          = {https://arxiv.org/abs/2407.21783},
	eprint       = {2407.21783},
	archiveprefix = {arXiv},
	primaryclass = {cs.AI}
}
@misc{gu2024olmesstandardlanguagemodel,
	title        = {{OLMES: A Standard for Language Model Evaluations}},
	author       = {Yuling Gu and Oyvind Tafjord and Bailey Kuehl and Dany Haddad and Jesse Dodge and Hannaneh Hajishirzi},
	year         = 2024,
	url          = {https://arxiv.org/abs/2406.08446},
	eprint       = {2406.08446},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
@misc{guan2025rstarmathsmallllmsmaster,
	title        = {{rStar-Math: Small LLMs Can Master Math Reasoning with Self-Evolved Deep Thinking}},
	author       = {Xinyu Guan and Li Lyna Zhang and Yifei Liu and Ning Shang and Youran Sun and Yi Zhu and Fan Yang and Mao Yang},
	year         = 2025,
	url          = {https://arxiv.org/abs/2501.04519},
	eprint       = {2501.04519},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
@inproceedings{hendrycks2021measuring,
	title        = {{Measuring Mathematical Problem Solving With the {MATH} Dataset}},
	author       = {Dan Hendrycks and Collin Burns and Saurav Kadavath and Akul Arora and Steven Basart and Eric Tang and Dawn Song and Jacob Steinhardt},
	year         = 2021,
	booktitle    = {Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2)},
	url          = {https://openreview.net/forum?id=7Bywt2mQsCe}
}
@misc{hsu2025ligerkernelefficienttriton,
	title        = {{Liger Kernel: Efficient Triton Kernels for LLM Training}},
	author       = {Pin-Lun Hsu and Yun Dai and Vignesh Kothapalli and Qingquan Song and Shao Tang and Siyu Zhu and Steven Shimizu and Shivam Sahni and Haowen Ning and Yanning Chen},
	year         = 2025,
	url          = {https://arxiv.org/abs/2410.10989},
	eprint       = {2410.10989},
	archiveprefix = {arXiv},
	primaryclass = {cs.LG}
}
@inproceedings{hua-etal-2024-mothello,
	title        = {{m{O}thello: When Do Cross-Lingual Representation Alignment and Cross-Lingual Transfer Emerge in Multilingual Models?}},
	author       = {Hua, Tianze  and Yun, Tian  and Pavlick, Ellie},
	year         = 2024,
	month        = jun,
	booktitle    = {Findings of the Association for Computational Linguistics: NAACL 2024},
	publisher    = {Association for Computational Linguistics},
	address      = {Mexico City, Mexico},
	pages        = {1585--1598},
	doi          = {10.18653/v1/2024.findings-naacl.103},
	url          = {https://aclanthology.org/2024.findings-naacl.103/},
	editor       = {Duh, Kevin  and Gomez, Helena  and Bethard, Steven},
}
@inproceedings{huang-etal-2023-languages,
	title        = {{Not All Languages Are Created Equal in {LLM}s: Improving Multilingual Capability by Cross-Lingual-Thought Prompting}},
	author       = {Huang, Haoyang  and Tang, Tianyi  and Zhang, Dongdong  and Zhao, Xin  and Song, Ting  and Xia, Yan  and Wei, Furu},
	year         = 2023,
	month        = dec,
	booktitle    = {Findings of the Association for Computational Linguistics: EMNLP 2023},
	publisher    = {Association for Computational Linguistics},
	address      = {Singapore},
	pages        = {12365--12394},
	doi          = {10.18653/v1/2023.findings-emnlp.826},
	url          = {https://aclanthology.org/2023.findings-emnlp.826/},
	editor       = {Bouamor, Houda  and Pino, Juan  and Bali, Kalika},
}
@misc{huang2024o1replicationjourney,
	title        = {{O1 Replication Journey -- Part 2: Surpassing O1-preview through Simple Distillation, Big Progress or Bitter Lesson?}},
	author       = {Zhen Huang and Haoyang Zou and Xuefeng Li and Yixiu Liu and Yuxiang Zheng and Ethan Chern and Shijie Xia and Yiwei Qin and Weizhe Yuan and Pengfei Liu},
	year         = 2024,
	url          = {https://arxiv.org/abs/2411.16489},
	eprint       = {2411.16489},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
@misc{huang2025adacotrethinkingcrosslingualfactual,
	title        = {{AdaCoT: Rethinking Cross-Lingual Factual Reasoning through Adaptive Chain-of-Thought}},
	author       = {Xin Huang and Tarun Kumar Vangani and Zhengyuan Liu and Bowei Zou and Ai Ti Aw},
	year         = 2025,
	url          = {https://arxiv.org/abs/2501.16154},
	eprint       = {2501.16154},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
@inproceedings{khade-etal-2025-challenges,
	title        = {{Challenges in Adapting Multilingual {LLM}s to Low-Resource Languages using {L}o{RA} {PEFT} Tuning}},
	author       = {Khade, Omkar  and Jagdale, Shruti  and Phaltankar, Abhishek  and Takalikar, Gauri  and Joshi, Raviraj},
	year         = 2025,
	month        = jan,
	booktitle    = {Proceedings of the First Workshop on Challenges in Processing South Asian Languages (CHiPSAL 2025)},
	publisher    = {International Committee on Computational Linguistics},
	address      = {Abu Dhabi, UAE},
	pages        = {217--222},
	url          = {https://aclanthology.org/2025.chipsal-1.22/},
	editor       = {Sarveswaran, Kengatharaiyer  and Vaidya, Ashwini  and Krishna Bal, Bal  and Shams, Sana  and Thapa, Surendrabikram}
}
@inproceedings{kojima2022large,
	title        = {{Large Language Models are Zero-Shot Reasoners}},
	author       = {Takeshi Kojima and Shixiang Shane Gu and Machel Reid and Yutaka Matsuo and Yusuke Iwasawa},
	year         = 2022,
	booktitle    = {Advances in Neural Information Processing Systems},
	url          = {https://openreview.net/forum?id=e2TBb5y0yFf},
	editor       = {Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho}
}
@inproceedings{kotha2024understanding,
	title        = {{Understanding Catastrophic Forgetting in Language Models via Implicit Inference}},
	author       = {Suhas Kotha and Jacob Mitchell Springer and Aditi Raghunathan},
	year         = 2024,
	booktitle    = {The Twelfth International Conference on Learning Representations},
	url          = {https://openreview.net/forum?id=VrHiF2hsrm}
}
@inproceedings{kwon2023efficient,
	title        = {{Efficient Memory Management for Large Language Model Serving with PagedAttention}},
	author       = {Woosuk Kwon and Zhuohan Li and Siyuan Zhuang and Ying Sheng and Lianmin Zheng and Cody Hao Yu and Joseph E. Gonzalez and Hao Zhang and Ion Stoica},
	year         = 2023,
	booktitle    = {Proceedings of the ACM SIGOPS 29th Symposium on Operating Systems Principles}
}
@misc{lambert2025tulu3pushingfrontiers,
	title        = {{Tulu 3: Pushing Frontiers in Open Language Model Post-Training}},
	author       = {Nathan Lambert and Jacob Morrison and Valentina Pyatkin and Shengyi Huang and Hamish Ivison and Faeze Brahman and Lester James V. Miranda and Alisa Liu and Nouha Dziri and Shane Lyu and Yuling Gu and Saumya Malik and Victoria Graf and Jena D. Hwang and Jiangjiang Yang and Ronan Le Bras and Oyvind Tafjord and Chris Wilhelm and Luca Soldaini and Noah A. Smith and Yizhong Wang and Pradeep Dasigi and Hannaneh Hajishirzi},
	year         = 2025,
	url          = {https://arxiv.org/abs/2411.15124},
	eprint       = {2411.15124},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
@inproceedings{li-etal-2024-teaching,
	title        = {{Teaching Small Language Models to Reason for Knowledge-Intensive Multi-Hop Question Answering}},
	author       = {Li, Xiang  and He, Shizhu  and Lei, Fangyu  and JunYang, JunYang  and Su, Tianhuang  and Liu, Kang  and Zhao, Jun},
	year         = 2024,
	month        = aug,
	booktitle    = {Findings of the Association for Computational Linguistics: ACL 2024},
	publisher    = {Association for Computational Linguistics},
	address      = {Bangkok, Thailand},
	pages        = {7804--7816},
	doi          = {10.18653/v1/2024.findings-acl.464},
	url          = {https://aclanthology.org/2024.findings-acl.464/},
	editor       = {Ku, Lun-Wei  and Martins, Andre  and Srikumar, Vivek},
}
@inproceedings{lightman2024lets,
	title        = {{Let's Verify Step by Step}},
	author       = {Hunter Lightman and Vineet Kosaraju and Yuri Burda and Harrison Edwards and Bowen Baker and Teddy Lee and Jan Leike and John Schulman and Ilya Sutskever and Karl Cobbe},
	year         = 2024,
	booktitle    = {The Twelfth International Conference on Learning Representations},
	url          = {https://openreview.net/forum?id=v8L0pN6EOi}
}
@misc{luo2023wizardcoder,
	title        = {{WizardCoder: Empowering Code Large Language Models with Evol-Instruct}},
	author       = {Ziyang Luo and Can Xu and Pu Zhao and Qingfeng Sun and Xiubo Geng and Wenxiang Hu and Chongyang Tao and Jing Ma and Qingwei Lin and Daxin Jiang},
	year         = 2023
}
@misc{luo2025empiricalstudycatastrophicforgetting,
	title        = {{An Empirical Study of Catastrophic Forgetting in Large Language Models During Continual Fine-tuning}},
	author       = {Yun Luo and Zhen Yang and Fandong Meng and Yafu Li and Jie Zhou and Yue Zhang},
	year         = 2025,
	url          = {https://arxiv.org/abs/2308.08747},
	eprint       = {2308.08747},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
@misc{muennighoff2025s1simpletesttimescaling,
	title        = {{s1: Simple test-time scaling}},
	author       = {Niklas Muennighoff and Zitong Yang and Weijia Shi and Xiang Lisa Li and Li Fei-Fei and Hannaneh Hajishirzi and Luke Zettlemoyer and Percy Liang and Emmanuel Candès and Tatsunori Hashimoto},
	year         = 2025,
	url          = {https://arxiv.org/abs/2501.19393},
	eprint       = {2501.19393},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
@inproceedings{NEURIPS2020_1457c0d6,
	title        = {{Language Models are Few-Shot Learners}},
	author       = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
	year         = 2020,
	booktitle    = {Advances in Neural Information Processing Systems},
	publisher    = {Curran Associates, Inc.},
	volume       = 33,
	pages        = {1877--1901},
	url          = {https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf},
	editor       = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin}
}
@inproceedings{NEURIPS2023_a85b405e,
	title        = {{Direct Preference Optimization: Your Language Model is Secretly a Reward Model}},
	author       = {Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Manning, Christopher D and Ermon, Stefano and Finn, Chelsea},
	year         = 2023,
	booktitle    = {Advances in Neural Information Processing Systems},
	publisher    = {Curran Associates, Inc.},
	volume       = 36,
	pages        = {53728--53741},
	url          = {https://proceedings.neurips.cc/paper_files/paper/2023/file/a85b405ed65c6477a4fe8302b5e06ce7-Paper-Conference.pdf},
	editor       = {A. Oh and T. Naumann and A. Globerson and K. Saenko and M. Hardt and S. Levine}
}
@misc{no_robots,
	title        = {{No Robots}},
	author       = {Nazneen Rajani and Lewis Tunstall and Edward Beeching and Nathan Lambert and Alexander M. Rush and Thomas Wolf},
	year         = 2023,
	journal      = {Hugging Face repository},
	publisher    = {Hugging Face},
	howpublished = {\url{https://huggingface.co/datasets/HuggingFaceH4/no_robots}}
}
@misc{nye2021workscratchpadsintermediatecomputation,
	title        = {{Show Your Work: Scratchpads for Intermediate Computation with Language Models}},
	author       = {Maxwell Nye and Anders Johan Andreassen and Guy Gur-Ari and Henryk Michalewski and Jacob Austin and David Bieber and David Dohan and Aitor Lewkowycz and Maarten Bosma and David Luan and Charles Sutton and Augustus Odena},
	year         = 2021,
	url          = {https://arxiv.org/abs/2112.00114},
	eprint       = {2112.00114},
	archiveprefix = {arXiv},
	primaryclass = {cs.LG}
}
@misc{olmo20252olmo2furious,
	title        = {{2 OLMo 2 Furious}},
	author       = {Team OLMo and Pete Walsh and Luca Soldaini and Dirk Groeneveld and Kyle Lo and Shane Arora and Akshita Bhagia and Yuling Gu and Shengyi Huang and Matt Jordan and Nathan Lambert and Dustin Schwenk and Oyvind Tafjord and Taira Anderson and David Atkinson and Faeze Brahman and Christopher Clark and Pradeep Dasigi and Nouha Dziri and Michal Guerquin and Hamish Ivison and Pang Wei Koh and Jiacheng Liu and Saumya Malik and William Merrill and Lester James V. Miranda and Jacob Morrison and Tyler Murray and Crystal Nam and Valentina Pyatkin and Aman Rangapur and Michael Schmitz and Sam Skjonsberg and David Wadden and Christopher Wilhelm and Michael Wilson and Luke Zettlemoyer and Ali Farhadi and Noah A. Smith and Hannaneh Hajishirzi},
	year         = 2025,
	url          = {https://arxiv.org/abs/2501.00656},
	eprint       = {2501.00656},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
@article{pipatanakul2023typhoon,
	title        = {{Typhoon: Thai Large Language Models}},
	author       = {Pipatanakul, Kunat and Jirabovonvisut, Phatrasek and Manakul, Potsawee and Sripaisarnmongkol, Sittipong and Patomwong, Ruangsak and Chokchainant, Pathomporn and Tharnpipitchai, Kasima},
	year         = 2023,
	journal      = {arXiv preprint arXiv:2312.13951}
}
@misc{pipatanakul2024typhoon2familyopen,
	title        = {{Typhoon 2: A Family of Open Text and Multimodal Thai Large Language Models}},
	author       = {Kunat Pipatanakul and Potsawee Manakul and Natapong Nitarach and Warit Sirichotedumrong and Surapon Nonesung and Teetouch Jaknamon and Parinthapat Pengpun and Pittawat Taveekitworachai and Adisai Na-Thalang and Sittipong Sripaisarnmongkol and Krisanapong Jirayoot and Kasima Tharnpipitchai},
	year         = 2024,
	url          = {https://arxiv.org/abs/2412.13702},
	eprint       = {2412.13702},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
@misc{qin2024o1replicationjourneystrategic,
	title        = {{O1 Replication Journey: A Strategic Progress Report -- Part 1}},
	author       = {Yiwei Qin and Xuefeng Li and Haoyang Zou and Yixiu Liu and Shijie Xia and Zhen Huang and Yixin Ye and Weizhe Yuan and Hector Liu and Yuanzhi Li and Pengfei Liu},
	year         = 2024,
	url          = {https://arxiv.org/abs/2410.18982},
	eprint       = {2410.18982},
	archiveprefix = {arXiv},
	primaryclass = {cs.AI}
}
@inproceedings{rein2024gpqa,
	title        = {{{GPQA}: A Graduate-Level Google-Proof Q\&A Benchmark}},
	author       = {David Rein and Betty Li Hou and Asa Cooper Stickland and Jackson Petty and Richard Yuanzhe Pang and Julien Dirani and Julian Michael and Samuel R. Bowman},
	year         = 2024,
	booktitle    = {First Conference on Language Modeling},
	url          = {https://openreview.net/forum?id=Ti67584b98}
}
@misc{skyt12025,
	title        = {{Sky-T1: Train your own O1 preview model within \$450}},
	author       = {NovaSky Team},
	year         = 2025,
	note         = {Accessed: 2025-01-09},
	howpublished = {https://novasky-ai.github.io/posts/sky-t1}
}
@misc{skyworkopeno12024,
	title        = {{Skywork-o1 Open Series}},
	author       = {Skywork-o1 Team},
	year         = 2024,
	month        = {November},
	url          = {https://huggingface.co/Skywork},
	howpublished = {\url{https://huggingface.co/Skywork}}
}
@misc{snell2024scalingllmtesttimecompute,
	title        = {{Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters}},
	author       = {Charlie Snell and Jaehoon Lee and Kelvin Xu and Aviral Kumar},
	year         = 2024,
	url          = {https://arxiv.org/abs/2408.03314},
	eprint       = {2408.03314},
	archiveprefix = {arXiv},
	primaryclass = {cs.LG}
}
@inproceedings{wan-etal-2023-universal,
	title        = {{Universal Self-Adaptive Prompting}},
	author       = {Wan, Xingchen  and Sun, Ruoxi  and Nakhost, Hootan  and Dai, Hanjun  and Eisenschlos, Julian  and Arik, Sercan  and Pfister, Tomas},
	year         = 2023,
	month        = dec,
	booktitle    = {Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
	publisher    = {Association for Computational Linguistics},
	address      = {Singapore},
	pages        = {7437--7462},
	doi          = {10.18653/v1/2023.emnlp-main.461},
	url          = {https://aclanthology.org/2023.emnlp-main.461/},
	editor       = {Bouamor, Houda  and Pino, Juan  and Bali, Kalika}
}
@inproceedings{wang-etal-2023-plan,
	title        = {{Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models}},
	author       = {Wang, Lei  and Xu, Wanyu  and Lan, Yihuai  and Hu, Zhiqiang  and Lan, Yunshi  and Lee, Roy Ka-Wei  and Lim, Ee-Peng},
	year         = 2023,
	month        = jul,
	booktitle    = {Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
	publisher    = {Association for Computational Linguistics},
	address      = {Toronto, Canada},
	pages        = {2609--2634},
	doi          = {10.18653/v1/2023.acl-long.147},
	url          = {https://aclanthology.org/2023.acl-long.147/},
	editor       = {Rogers, Anna  and Boyd-Graber, Jordan  and Okazaki, Naoaki}
}
@misc{wang2023helpsteermultiattributehelpfulnessdataset,
	title        = {{HelpSteer: Multi-attribute Helpfulness Dataset for SteerLM}},
	author       = {Zhilin Wang and Yi Dong and Jiaqi Zeng and Virginia Adams and Makesh Narsimhan Sreedhar and Daniel Egert and Olivier Delalleau and Jane Polak Scowcroft and Neel Kant and Aidan Swope and Oleksii Kuchaiev},
	year         = 2023,
	url          = {https://arxiv.org/abs/2311.09528},
	eprint       = {2311.09528},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
@inproceedings{wang2023selfconsistency,
	title        = {{Self-Consistency Improves Chain of Thought Reasoning in Language Models}},
	author       = {Xuezhi Wang and Jason Wei and Dale Schuurmans and Quoc V Le and Ed H. Chi and Sharan Narang and Aakanksha Chowdhery and Denny Zhou},
	year         = 2023,
	booktitle    = {The Eleventh International Conference on Learning Representations},
	url          = {https://openreview.net/forum?id=1PL1NIMMrw}
}
@inproceedings{wang2024mmlupro,
	title        = {{{MMLU}-Pro: A More Robust and Challenging Multi-Task Language Understanding Benchmark}},
	author       = {Yubo Wang and Xueguang Ma and Ge Zhang and Yuansheng Ni and Abhranil Chandra and Shiguang Guo and Weiming Ren and Aaran Arulraj and Xuan He and Ziyan Jiang and Tianle Li and Max Ku and Kai Wang and Alex Zhuang and Rongqi Fan and Xiang Yue and Wenhu Chen},
	year         = 2024,
	booktitle    = {The Thirty-eight Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
	url          = {https://openreview.net/forum?id=y10DM6R2r3}
}
@misc{wang2024openropensourceframework,
	title        = {{OpenR: An Open Source Framework for Advanced Reasoning with Large Language Models}},
	author       = {Jun Wang and Meng Fang and Ziyu Wan and Muning Wen and Jiachen Zhu and Anjie Liu and Ziqin Gong and Yan Song and Lei Chen and Lionel M. Ni and Linyi Yang and Ying Wen and Weinan Zhang},
	year         = 2024,
	url          = {https://arxiv.org/abs/2410.09671},
	eprint       = {2410.09671},
	archiveprefix = {arXiv},
	primaryclass = {cs.AI}
}
@misc{wealth_alapca,
	title        = {{Wealth Alpaca}},
	author       = {Gaurang Bharti},
	year         = 2023,
	journal      = {Hugging Face repository},
	publisher    = {Hugging Face},
	howpublished = {\url{https://huggingface.co/datasets/gbharti/wealth-alpaca_lora}}
}
@inproceedings{wei2022chain,
	title        = {{Chain of Thought Prompting Elicits Reasoning in Large Language Models}},
	author       = {Jason Wei and Xuezhi Wang and Dale Schuurmans and Maarten Bosma and brian ichter and Fei Xia and Ed H. Chi and Quoc V Le and Denny Zhou},
	year         = 2022,
	booktitle    = {Advances in Neural Information Processing Systems},
	url          = {https://openreview.net/forum?id=_VjQlMeSB_J},
	editor       = {Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho}
}
@misc{wu2024thinkingllmsgeneralinstruction,
	title        = {{Thinking LLMs: General Instruction Following with Thought Generation}},
	author       = {Tianhao Wu and Janice Lan and Weizhe Yuan and Jiantao Jiao and Jason Weston and Sainbayar Sukhbaatar},
	year         = 2024,
	url          = {https://arxiv.org/abs/2410.10630},
	eprint       = {2410.10630},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
@misc{xu2024surveyknowledgedistillationlarge,
	title        = {{A Survey on Knowledge Distillation of Large Language Models}},
	author       = {Xiaohan Xu and Ming Li and Chongyang Tao and Tao Shen and Reynold Cheng and Jinyang Li and Can Xu and Dacheng Tao and Tianyi Zhou},
	year         = 2024,
	url          = {https://arxiv.org/abs/2402.13116},
	eprint       = {2402.13116},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
@inproceedings{yao2023tree,
	title        = {{Tree of Thoughts: Deliberate Problem Solving with Large Language Models}},
	author       = {Shunyu Yao and Dian Yu and Jeffrey Zhao and Izhak Shafran and Thomas L. Griffiths and Yuan Cao and Karthik R Narasimhan},
	year         = 2023,
	booktitle    = {Thirty-seventh Conference on Neural Information Processing Systems},
	url          = {https://openreview.net/forum?id=5Xc1ecxO1h}
}
@misc{yuenyong2024openthaigpt15thaicentricopen,
	title        = {{OpenThaiGPT 1.5: A Thai-Centric Open Source Large Language Model}},
	author       = {Sumeth Yuenyong and Kobkrit Viriyayudhakorn and Apivadee Piyatumrong and Jillaphat Jaroenkantasima},
	year         = 2024,
	url          = {https://arxiv.org/abs/2411.07238},
	eprint       = {2411.07238},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
@inproceedings{zheng2024llamafactory,
	title        = {{LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models}},
	author       = {Yaowei Zheng and Richong Zhang and Junhao Zhang and Yanhan Ye and Zheyan Luo and Zhangchi Feng and Yongqiang Ma},
	year         = 2024,
	booktitle    = {Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 3: System Demonstrations)},
	publisher    = {Association for Computational Linguistics},
	address      = {Bangkok, Thailand},
	url          = {http://arxiv.org/abs/2403.13372}
}
@misc{zhou2023instructionfollowingevaluationlargelanguage,
	title        = {{Instruction-Following Evaluation for Large Language Models}},
	author       = {Jeffrey Zhou and Tianjian Lu and Swaroop Mishra and Siddhartha Brahma and Sujoy Basu and Yi Luan and Denny Zhou and Le Hou},
	year         = 2023,
	url          = {https://arxiv.org/abs/2311.07911},
	eprint       = {2311.07911},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
@misc{zhou2023threadthoughtunravelingchaotic,
	title        = {{Thread of Thought Unraveling Chaotic Contexts}},
	author       = {Yucheng Zhou and Xiubo Geng and Tao Shen and Chongyang Tao and Guodong Long and Jian-Guang Lou and Jianbing Shen},
	year         = 2023,
	url          = {https://arxiv.org/abs/2311.08734},
	eprint       = {2311.08734},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
@inproceedings{ziqi-lu-2023-tab,
	title        = {{Tab-{C}o{T}: Zero-shot Tabular Chain of Thought}},
	author       = {Ziqi, Jin  and Lu, Wei},
	year         = 2023,
	month        = jul,
	booktitle    = {Findings of the Association for Computational Linguistics: ACL 2023},
	publisher    = {Association for Computational Linguistics},
	address      = {Toronto, Canada},
	pages        = {10259--10277},
	doi          = {10.18653/v1/2023.findings-acl.651},
	url          = {https://aclanthology.org/2023.findings-acl.651/},
	editor       = {Rogers, Anna  and Boyd-Graber, Jordan  and Okazaki, Naoaki}
}
