\section{Related Works}
\paragraph{Test-Time Scaling}~As concerns grow that the benefits of scaling pre-training compute may be saturating~\citep{longpre2024consent}, research has shifted toward \emph{test-time scaling}, which expands the notion of chain-of-thought reasoning~\citep{wei2022chain}. Intuitively, the reasoning capacity of an LLM is limited by the number of tokens it can generate; hence, more challenging questions may require a longer chain of thought~\citep{wu2025more}. An early example is self-consistency CoT~\citep{wang2022self}, which generates multiple responses and selects the best via voting. This idea has since been developed into more cost-effective strategies for searching broader solution spaces (e.g., tree-of-thought methods~\citep{yao2024tree}, Monte Carlo Tree Search~\citep{guan2025rstar}, and process supervision~\citep{zhang2025lessons, luo2024improve}). Recently, models trained with online reinforcement learning~\citep{shao2024deepseekmathpushinglimitsmathematical} appear to exhibit an ``aha moment,''~\citep{guo2025deepseek} wherein they dynamically decide to generate longer sequences to iteratively explore, solve, and self-correct. 


\paragraph{Mathematical Reasoning in Non-English}~Early attempts at multilingual math reasoning involved supervised fine-tuning on translated datasets~\citep{chen2023breaking, lai2024mcot}, but performance often deteriorated when models shifted away from their original language embeddings~\citep{hong2024cross}. To minimize such degradation, more recent work has increasingly relied on English as a pivot language. This approach can be implemented in various ways: either internally, by mapping multilingual inputs into an English-centric latent space \citep{yoon2024langbridge, fan2025slam, zhu2024question, she2024mapo}, or externally, by translating non-English tasks into English and then back to the target language \citep{zhang2023plug, ko2025understand}. Although this strategy has reduced the performance gap between English and other languages, the stability of transfer under different training conditions remains underexplored. Moreover, many studies rely on the MGSM benchmark~\citep{shi2022language}, which appears too easy for large-scale models or those enhanced by advanced reasoning techniques such as test-time scaling.