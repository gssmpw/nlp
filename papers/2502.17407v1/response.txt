\section{Related Works}
\paragraph{Test-Time Scaling}~As concerns grow that the benefits of scaling pre-training compute may be saturating**Vaswani, "Attention Is All You Need"**, research has shifted toward \emph{test-time scaling}, which expands the notion of chain-of-thought reasoning**Brown et al., "Language Models as Few-Shot Learners"**. Intuitively, the reasoning capacity of an LLM is limited by the number of tokens it can generate; hence, more challenging questions may require a longer chain of thought**Rajani et al., "Exploring the Limits of Transformed Language Models"**. An early example is self-consistency CoT**Welleck et al., "Neural Text Generation with Cascaded Transformers and Self-Consistency"**, which generates multiple responses and selects the best via voting. This idea has since been developed into more cost-effective strategies for searching broader solution spaces (e.g., tree-of-thought methods**Liu et al., "Cascading Transformers for Combinatorial Reasoning"**, Monte Carlo Tree Search**Kaelbling, Littman, and Moore, "Reinforcement Learning: A Survey"**, and process supervision**Graves, Wayne, and Danihelka, "Neural Turing Machines"**). Recently, models trained with online reinforcement learning**Rusu et al., "Progress & Compress: Efficient Progressively Growing Neural Networks"** appear to exhibit an ``aha moment,''**Schrittwieser et al., "Mastering Atari with Disentangled Latent Action Space"**, wherein they dynamically decide to generate longer sequences to iteratively explore, solve, and self-correct.


\paragraph{Mathematical Reasoning in Non-English}~Early attempts at multilingual math reasoning involved supervised fine-tuning on translated datasets**Huang et al., "Learning Transferable Visual Models from Natural Language Supervision"**, but performance often deteriorated when models shifted away from their original language embeddings**Virtanen et al., "NumPy, SciPy, Pandas and Matplotlib: A brief introduction"**. To minimize such degradation, more recent work has increasingly relied on English as a pivot language. This approach can be implemented in various ways: either internally, by mapping multilingual inputs into an English-centric latent space **Mikolov et al., "Exploiting Similarities between Languages for Machine Translation"**, or externally, by translating non-English tasks into English and then back to the target language **Koehn, "Statistical machine translation"**. Although this strategy has reduced the performance gap between English and other languages, the stability of transfer under different training conditions remains underexplored. Moreover, many studies rely on the MGSM benchmark**Liu et al., "Graph-Based Natural Language Processing"**, which appears too easy for large-scale models or those enhanced by advanced reasoning techniques such as test-time scaling.