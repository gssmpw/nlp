\section{Related Work}
\label{sec:related_work}

The reduction of FP rates is a common challenge across machine learning applications and techniques, from Generative AI (GenAI) techniques like RAG to modeling methodologies like deep semi-supervised learning. Outdated information or inaccuracies in LLM training data have led to RAG methodologies**Radford et al., "Improving Language Understanding by Generative Models through Self-Training"**__**Kaplan et al., " Scaling Laws for Neural Language Modelling"**. RAG allows LLMs to incorporate additional data sources before making predictions based on user input ____ . However, the fundamental core of RAG has been shown to have promising results with a variety of model types along with LLMs.  Pan et al. used RAG to help facilitate cyber investigations with system logs **Pan et al., "Adversarial Training for Cybersecurity: A Systematic Review"**. Their architecture uses an LLM to perform semantic analysis between log samples retrieved from the vector database and the queried log entry. The logs stored in the vector database are the vector embedding of known normal logs. Therefore, when the retrieval score matches the criteria, such as the highest similarity score or the minimum threshold score, the vector database returns the resultant embedding vectors ____ . Although their results with a cyber-focused RAG model are promising, LLMs are not always usable in cybersecurity due to the variety and sensitivity of data types.  Other authors, such as Al Jallad et al. propose using larger amounts of data to help train generalizable deep learning model to detect anomalies **Al Jallad et al., "DNN for Anomaly Detection"** with lower false positive rates in a vein similar to the anomaly detection model for which RAAD was originally developed, although we specifically follow the architecture of Nandakumar et al. ____.

Deep semi-supervised learning techniques have evolved over time to improve model performance and reduce labeling costs. Ouali et al. defines the goal of semi-supervised learning as leveraging the unlabeled data to produce a prediction function with trainable parameters **Ouali et al., "Survey on Semi-Supervised Learning"**. Lee ____ introduced the concept of pseudo-labeling, which involves generating proxy labels to augment the training set. This was further expanded by combining label propagation with pseudo-labeling in Iscen et al. ____ , labeled sample constraints in Arazo et al **Arazo et al., "Pseudo-Labeling for Deep Neural Networks"** , and retraining models with regularization and pseudo-labeling in Sohn et al **Sohn et al., "FixMatch: Simplified Semi-Supervised Learning with Normalization and Confidence Calibration"** . Although effective in reducing FP rates, it is not a long term sustainable method for an anomaly detection model in a robust production environment, where speed and efficiency are priority. These methods often require significant computational resources and training time. RAAD does not require constant retraining and provides an alternative that is low-touch in deployment. The architectures reviewed here inform our approach and methodology towards reducing false positives in an anomaly detector.