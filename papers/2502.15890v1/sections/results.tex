\section{Results}
\label{sec:results}

\input{tables/distances}

\input{figures/accuracy}

\input{figures/diff_mean}

\input{tables/timings}

\subsection{Accuracy of Framework}

We evaluate the accuracy of our framework by examining the Wasserstein-1 distance between the distribution estimated by our framework and actual distributions obtained through sampling. Intuitively, the Wasserstein-1 distance measures the ``amount'' of probability that needs to be moved to make two distributions identical, weighted by the ``distance'' it needs to be moved. We report the mean distance and the standard deviation of the distances for all settings in Table \ref{tab:distances}. We also provide plots visually illustrating the differences in distributions for different Wasserstein-1 distances in Figure \ref{fig:accuracy}.

Our framework demonstrates high accuracy in the binomial and power-law settings, with mean Wasserstein-1 distances less than $0.09$ in all cases. Our framework is especially accurate for binomial graphs, where the mean Wasserstein-1 distance is always less than $0.03$. There does not appear to be any differences in accuracy with respect to graph size, sampling method, or sampling size. Figures \ref{fig:accuracy_bin}, \ref{fig:accuracy_pow_a}, and \ref{fig:accuracy_pow_b} visually illustrate the accuracy associated with these Wasserstein-1 distances.

For SBM graphs, the framework's accuracy decreases under certain conditions: for a graph size of $20000$ and a snowball sample of size $200$, the mean Wasserstein-1 distance is $0.7078$ (see Figure \ref{fig:accuracy_sbm_1}). In general on SBM graphs, the framework is less accurate when the graph is smaller, when the sample size is smaller and/or when using snowball sampling. However, the accuracy does improve with increasing graph size: at size $100000$, the Wasserstein-1 distance for random sampling is less than $0.03$ compared to $0.2$ for smaller graph sizes, and the Wasserstein-1 distance for snowball sampling is less than $0.2$ compared to $0.8$ for smaller graph sizes. Figures \ref{fig:accuracy_sbm_2} and \ref{fig:accuracy_sbm_3} visually illustrate these accuracies at larger graph sizes.

These results suggest that the presence of community structures poses a challenge for the framework. In binomial and power law graphs, there is no community structure, and our framework is very accurate. In SBM graphs, there is community structure, and this is exasperated under snowball sampling, where nodes in the sample are likely to come from the same community. This may be why our framework is more accurate under random sampling than snowball sampling in SBM graphs: random sampling ameliorates some of the difficulty from community structures. Interestingly, our framework appears to be more accurate as graph size increases, indicating that it will remain useful in the domains where graph sampling is of most use: very large graph sizes. Still, we show that despite poor accuracy in some cases, there is still useful information to be gleaned from the estimates.

\subsubsection{Performance on Downstream Task}

The framework proves to be a reliable estimator for DSPD in binomial and power-law graphs, and certain configurations and sampling methods on SBM graphs. However, even on the SBM graph configurations where our framework does not produce an accurate estimate, the estimate is still effective at downstream tasks. Specifically, we evaluate how accurately our model can compare the mean distances resulting from random or snowball sampling for a fixed graph configuration and sample size. This is analogous to using our framework to choose a sampling method for a specific network and sampling budget.

Our framework accurately compares mean distances across all graph configurations and sampling methods, including for the SBM graphs where the immediate estimation is inaccurate. For all graph configurations and sample sizes, the mean distance comparison in the estimated distributions matched exactly with the mean distance comparison in the empirical distributions. These include cases where snowball sampling gives smaller mean distance (e.g., Power Law A) and cases where random sampling gives smaller mean distance (e.g., Power Law B). Additionally, this method is very sensitive, able to correctly compare distributions when most differences are less than $0.1$. The minimum difference was $0.0175$. A scatterplot of all the differences is presented in Figure \ref{fig:diff_mean}.

\subsection{Efficiency of Framework}

The framework demonstrates significantly greater efficiency compared to empirically determining the DSPD to a sample, which requires first obtaining a graph then performing sampling, at a minimum. This can be costly even in simulation settings, and more so in the real world. On the other hand, our framework only requires specifying a graph configuration, sampling method, and sample size, with no need to obtain or produce a graph or sample. For example, it took around 8 minutes to generate a binomial graph of size $100000$ to obtain empirical distributions, but this step is not necessary for our framework. However, even when just considering the cost to calculate the distribution (i.e., timing after having the graph and sample), our framework has good efficiency.

Table \ref{tab:timings} describes the time taken to calculate a single DSPD, with means and standard deviations over $100$ trials. In practice, to empirically determine the DSPD one would want to take an average over multiple trials to account for randomness in graph generation and sample selection, but here we just report the timings for a single trial. In nearly all scenarios, the framework consistently outperforms empirical methods in terms of speed, except for small graphs with large sample sizes. In some cases, our framework can be an order of magnitude faster (e.g., Power A graphs of size $40000$ with a snowball sample of size $200$). 

These results align with expectations given algorithm implementations. Empirical distributions can be determined via a breadth-first search, which scales linearly with graph size. Our framework employs polynomial exponentiation with order equal to the sample size, which scales quadratically with sample size but is constant with graph size. %This distinction is clearly reflected in our timing results. 
Thus, our framework is most performant for very large graphs with small sample sizes, which is a common use case for graph sampling. 
