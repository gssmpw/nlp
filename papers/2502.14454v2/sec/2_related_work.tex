\section{Related Work}
\label{sec:releated_work}

\paragraph{Radiance field deblurring}
Several works have recently been proposed to tackle radiance field deblurring~\cite{ma2022deblurnerf, wang2023badnerf, lee2023dpnerf, lee2023exblurf, peng2023pdrf}.
Ma \etal~presented Deblur-NeRF, the first framework to train a sharp radiance field from blurry training views~\cite{ma2022deblurnerf}.
Deblur-NeRF adopts an additional MLP to model blur kernels and jointly optimizes them with a radiance field.
DP-NeRF~\cite{lee2023dpnerf} models blur kernels based on physical priors for rigid motions, while PDRF~\cite{peng2023pdrf} uses a two-stage kernel modeling scheme where the first stage coarsely aggregates kernel points to reduce computational cost.
All these methods support both camera motion blur and defocus blur by modeling them using multiple rays.
On the other hand, BAD-NeRF~\cite{wang2023badnerf} and ExBluRF~\cite{lee2023exblurf} propose radiance field deblurring for camera motion blur, modeling camera motion blur using camera trajectories. 
Nevertheless, all these methods rely on linear blur models, and require multiple ray-tracing steps, resulting in limited deblurring quality and slow training speeds.

More recently, with the emergence of 3D Gaussian Splatting~\cite{kerbl2023gaussiansplatting}, 3D Gaussian-based radiance field deblurring methods have been proposed.
Deblurring-3DGS~\cite{lee2024deblurring} handles camera motion blur with small offsets in 3D Gaussian positions and defocus blur by adjusting the geometry of Gaussians. 
BAGS~\cite{peng2024bags} models both types of blur using dense per-pixel blur kernels optimized in a coarse-to-fine manner.
However, BAGS requires substantial computation time to optimize dense blur kernels.
Moreover, these methods also rely on linear blur models and are limited in handling real-world blurred images. 

\paragraph{Image deblurring}
Image deblurring has been widely studied to address blur that degrades image quality. 
Traditional methods, relying on linear blur models, often struggle with real-world blurred images containing non-linear outliers~\cite{cho2009fast, hirsch2011fast, zhang2013non, pan2014deblurring, whyte10nonuniform, cho2012video, cho2007removing, rav2005two}. 
Their iterative optimization processes are also computationally intensive, limiting their practical use. 
Recent advancements in deep learning have introduced DNN-based approaches, including single-image~\cite{nah2017gopro, tao2018srn, kupyn2018deblurgan, zamir2021mprnet, cho2021mimounet, chen2022nafnet} and multi-frame/video deblurring~\cite{wieschollek2017learning, aittala2018burst, zhou2019davanet, gu2020blur, su2017video, nah2019video, deng2021video, hyun2017video, zhou2019video}. 
These methods can handle more complex blurs and reduce processing time with a feed-forward structure.

While applying DNN-based deblurring approaches might be a potential solution for constructing radiance fields from blurry images, na\"ively using single-image deblurring techniques yields unsatisfactory results as discussed in \cref{sec:intro}. 
Another possible direction is to adopt multi-frame and video deblurring approaches that leverage complementary information from multiple images for higher-quality results.
However, these methods assume that input images are captured from nearly the same viewpoints, a condition that does not hold for training views in radiance field construction.
