%#############################################################################################
\section{Introduction}
%#############################################################################################

%Motivation. Broadly, what is problem area, why important?
%\begin{itemize}
%	\item Narrow down. What is problem you specifically consider?
%	\item ``In the paper'', we... Most crucial paragraph, tell your elevator pitch.
%	\item Relation to other works. How different/better/relates to other work.
%	\item Contributions. Bullet points with main contributions of this study.
%	\item Structure. ``The remainder of this paper is structured as follows"
%\end{itemize}

Prototyping a scientific instrument to explore the design space of future and emerging digital infrastructures has often been considered as impossible or irrelevant. The reasons are manifold, i) it is hard to predict the future landscape and challenging scientific questions, ii) the technology is evolving too quickly, and iii) the community is fragmented.  Unfortunately, the recent COVID episode demonstrated that providing evidence is a difficult task, often grounded on experimental research, and that this process is long and complex but timely and absolutely necessary. 

Up to now, networking test platforms have tried to capture a variety of demands. Academia represents the first target group, necessitating  tools  to support the validity of the assumptions and provenance of results and data published in scientific papers.  However, very little has been done to cover the entire research and data lineage lifecycle to ensure the longevity of such data as well as its access to the wider research and innovation community. It is for that reason that the FAIR (Findable, Accessible, Interoperable, and Reusable) and Open Science Principles were developed promoting interoperability and reproducibility of the results. Industry forms a second target group that often emphasizes the value of solutions to support conformance or interoperability testing, or the importance to make test platforms available for SMEs or startup companies, because otherwise they will never have the opportunity to access such instruments. As a consequence, different target groups impose unique requirements and expectations that need to be addressed by current and future testbeds. 

The field has matured quite a lot over the last decades. The first phase of test platforms can be illustrated by facilities such as PlanetLab~\footnote{PlanetLab, https://planetlab.cs.princeton.edu/} and Orbit~\footnote{Open-Access Research Testbed for Next-Generation Wireless Networks (ORBIT), https://www.orbit-lab.org/}. In 2005, the concept of testbed federation was introduced and applied to PlanetLab with the deployment of PlanetLab Europe in 2007 \cite{planetlab}.  Since then, this concept has developed quite a lot~\cite{fed4fire},~\cite{federation}. Orbit's success~\cite{orbit} has been due to addressing the need for realistic environments to test wireless protocols that were becoming essentials. The second phase of test platforms was initiated in 2007 with the ambition of the NSF GENI \cite{geni} (\verb-120M$ 2008/2016-) and EU FIRE \cite{eu-fire} initiatives (\verb-200M€ 2007/2022-). This corresponds somehow to a more structured approach to build a research infrastructure for this domain. GENI’s approach was meant to design a nationwide test platform, composed of GENI Nodes and racks that the experimenters could program. In Europe, the ambition was to federate testbeds with very heterogeneous resources. Both initiatives were nicely articulated and produced SFA~\cite{sfa}, the Slice-based Federation Architecture, proposing a practical solution to federate the facilities managed  by independent authorities. The third phase already started with initiatives such as NSF PAWR in the US~\cite{pawr}, CENI in China and ICT 17/19/52 in Europe~\cite{5geve, 5genesis, 5gvinni}. Those are developed in parallel without much cooperation and collaboration at present. The novelty comes from two new types of stakeholders. The tech giants are developing their own facilities (experimental or production), which is providing a risk with respect to the competition with academic research as these private platforms are not open, neither are the data that they use to produce their results. Second, other initiatives have emerged supported by the open-source community, such as ONAP~\cite{onap}, ORAN~\cite{oran}, OpenAirInterface~\cite{oai} enabling new and unique opportunities to deploy fully programmable and virtualised network infrastructures.

As a scientific community, our first message is that we have to continue to raise global awareness and promote the importance of a scientific instrument, because it is a community responsibility. All the efforts highlighted above address the demand for the networking field, including the demand for the experimental validation of research results.
This experimental validation constitutes a cornerstone of any sound scientific methodology. Both for historical and practical reasons, though, experimentally-driven research in the networking field has been so far quite fragmented, characterised by the development of ``in-house" testbeds, with the purpose of validating specific innovations (of specific research groups). This has (i) limited the scale at which experiments can be executed, (ii) limited the reproducibility of results (another pillar of scientific research) due to customizations at the individual testbed level, and thus (iii) limited the credibility of results produced. Because digital infrastructures are rapidly becoming a fundamental technological basis of our society, we think this gap needs to be urgently filled, such that next generation networks (starting from beyond-5G and 6G) can be developed based on reference, large-scale experimental infrastructures that could act as reference point for the wide community of computer networks and distributed systems researchers.
%It does not mean that a single tool will fit all needs, but we certainly must expect a much more integrated vision of a facility, because what we have today is very fragmented. This fragmentation is meaningful and simpler, but do not reach the scale that will provide the arguments to propose a scientific instrument and sustain the facility.

In Europe, there exists a framework called ESFRI - European Strategy Forum on Research Infrastructures~\cite{esfri} that supports the design, implementation and operation of scientific instruments. ESFRI is fully driven by science and organized in phases that should guarantee the feasibility and sustainability of the instrument. This framework is used by all scientific domains with a similar vision about the objectives and methodology. Targeting a scientific instrument for our community means that we have to align and adopt the principles promoted by ESFRI. It starts with a clear statement about the scientific question that this particular instrument will address. For instance, does the Higgs boson exist? Formulating such a question, which is easily understandable by other disciplines, the stakeholders and citizens, is not straightforward in our domain. 


%Duplicate figure ???
%\begin{figure*}[h]
%	\include{figures/tex/ESFRI_life_cycle}
%	\caption{ESFRI lifecycle approach.}
%	\label{fig:ESFRI_live_cycle}
%\end{figure*}


In this paper, we present the SLICES ESFRI initiative that is meant to support the discovery process related to the future, emerging digital infrastructures. In~\Cref{section:The ESFRI framework}, we focus on the ESFRI framework defining the requirements to enter into the roadmap. It relates to the ability and value of the future facility as well its sustainability. \Cref{section:Design foundation principles} highlights some of the design issues that are still being debated. We illustrate these foundations with the example of a 5G network in~\Cref{section:5G}. From this analysis, we derive preliminary architecture guidelines for SLICES in~\Cref{section:Architecture}. The research lifecycle dimension is of utmost importance. We introduce EOSC as a valuable target to be articulated with SLICES and discuss the components of the full-research lifecycle in \Cref{section:research}. The interoperability with EOSC is presented in \Cref{section:Interoperability}. We illustrate this with an example borrowed from another discipline, presented in \Cref{section:Example}. Finally, we conclude in \Cref{section:conclusion} and list topics for future investigations.

