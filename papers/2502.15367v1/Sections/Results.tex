\section{Results}
% In this study, as previously mentioned, 60 participants joined our user study. However, due to various reasons, we ultimately obtained 242 valid audio files from our server, distributed as follows: 63 for the happy emotional scenario, 43 for the neutral emotional scenario, 43 for the angry emotional scenario, 50 for the sad emotional scenario, and 43 for the fear emotional scenario. These speech data were subsequently used for speech analysis and linguistic analysis, providing valuable insights into participants' emotional and verbal responses across different scenarios.
Our study involved 60 participants, resulting in 242 valid audio files across five emotional scenarios: happy, neutral, angry, sad, and fear. Through a combination of speech signal analysis and linguistic evaluation, we identified key patterns in participants' emotional responses and speech features.

\subsection{Results from Speech Signals}
\subsubsection{Speech Emotion Analysis}


\begin{figure}[ht]
    \centering
    \begin{subfigure}{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Figure/Happy_distribution.png}
        \caption{Happy Speech Scenarios}
        \label{fig:happy_distribution}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Figure/Neutral_Distribution.png}
        \caption{Neutral Speech Scenarios}
        \label{fig:neutral_distribution}
    \end{subfigure}
    
    \caption{The Emotional Responding Distribution from Different Emotional Scenarios}
    \label{fig:emotion_distribution}
\end{figure}

% In this study, we aim to find the strategies from the users how they responding to different emotional scenarios speech. Thus, we used the Openvokaturi as our emotion analysis tool to obtain the emotional states from these collected audio data. As it shown in Figure~\ref{fig:emotion_distribution}, we can find in the happy and neutral speech scenarios participants are mainly used the neutral and happy emotional responding way to communicate with others. For the other negative emotional scenarios, we found most of the participants perfer to use the neutral emotional responding way to talk with others.  
In this study, we aimed to uncover the strategies users employ when responding to different emotional scenarios. To achieve this, we utilized OpenVokaturi as our emotion analysis tool to extract emotional states from the collected audio data. As shown in Figure~\ref{fig:emotion_distribution}, we observed that in happy and neutral speech scenarios, participants primarily used neutral and happy emotional responses to communicate. However, in the case of negative emotional scenarios (e.g., anger, sadness, and fear), the majority of participants preferred to use neutral emotional responses when interacting with others. This suggests that users tend to adopt a balanced and non-confrontational approach when dealing with negative emotions, highlighting the importance of neutrality in emotional communication.


\subsubsection{Speech Signal Analysis}
% Speech analysis generally includes time-domain speech features analysis and frequency domain speech features analysis~\cite{Madan2014SpeechFE}. In this study, we mainly used the librosa and opensmile to extract the time and frequency speech features. We used the T-test to compare the difference between the different emotional scenarios. From the result as it shown in Figure~\ref{fig:feature_comparison}, we can find only root mean squre (RMS), zero-cross rate (ZCR) and speech jitter exists the difference in some emotional scenarios. For instance, in the RMS, we find there are the difference in the happy speech scenario and angry speech scenario, and happy speech scenario and sad speech scenario. In the ZCR, we find it exists the significately difference in the happy speech scenario and neutral speech scenario, and happy speech scenario and fear speech scenario. In the speech features of jitter, we find there are the difference in  happy speech scenario and angry speech scenario, and happy speech scenario and fear speech scenario, and happy speech scenario and sad speech scenario. It also means that    

\begin{figure}[ht]
    \centering
    \begin{subfigure}{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Figure/RMS_T_Test_NEW.png}
        \caption{ Root Mean Square}
        \label{fig:rms_distribution}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Figure/zcr-t-test-update.png}
        \caption{ Zero-Cross Rate}
        \label{fig:zcr_distribution}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Figure/Jitter_t_test.png}
        \caption{Jitter}
        \label{fig:jitter_distribution}
    \end{subfigure}
    
    \caption{Comparison of Different Features Using T-Test from Five Basic Emotional Scenarios: (a) Root Mean Square, (b) Zero-Cross Rate, and (c) Jitter.}
    \label{fig:feature_comparison}
\end{figure}

Speech analysis typically involves examining time-domain speech features and frequency-domain speech features (Madan et al., 2014). In this study, we primarily used Librosa and OpenSMILE to extract these features. We then employed T-tests to compare the differences between various emotional scenarios. As shown in Figure~\ref{fig:feature_comparison}, we found that only three features—root mean square (RMS), zero-crossing rate (ZCR), and speech jitter—exhibited significant differences across some emotional scenarios.
For instance, in RMS, we observed differences between the happy speech scenario and the angry speech scenario, as well as between the happy speech scenario and the sad speech scenario. In ZCR, significant differences were found between the happy speech scenario and the neutral speech scenario, as well as between the happy speech scenario and the fear speech scenario. For speech jitter, differences were identified between the happy speech scenario and the angry speech scenario, the happy speech scenario and the fear speech scenario, and the happy speech scenario and the sad speech scenario.
These findings suggest that RMS, ZCR, and jitter are sensitive to variations in emotional expression, particularly in distinguishing between positive and negative emotional states. This highlights their potential as key indicators for emotion-aware systems to detect and respond to different emotional contexts effectively.

\subsection{Results from Speech Content}
\subsubsection{Result from Word Cloud}

\begin{figure}[ht]
    \centering
    % First row: Angry, Fear, Happy
    \begin{subfigure}{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Figure/NLP_Word_Cloud_Angry.png}
        \caption{ Angry}
        \label{fig:wordcloud_angry}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Figure/NLP_Word_Cloud_Fear.png}
        \caption{ Fear}
        \label{fig:wordcloud_fear}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Figure/NLP_Word_Cloud_Happy.png}
        \caption{ Happy}
        \label{fig:wordcloud_happy}
    \end{subfigure}
    
    % Second row: Neutral and Sad (Centered)
    \vspace{0.5cm} % Adds vertical spacing
    \begin{subfigure}{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Figure/NLP_Word_Cloud_Neutral.png}
        \caption{ Neutral}
        \label{fig:wordcloud_neutral}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Figure/NLP_Word_Cloud_Sad.png}
        \caption{ Sad}
        \label{fig:wordcloud_sad}
    \end{subfigure}

    \caption{Word Cloud Representations for Different Emotional Scenarios: (a) Angry, (b) Fear, (c) Happy, (d) Neutral, and (e) Sad.}
    \label{fig:wordclouds}
\end{figure}

% In this study, we used wordcloud package to analysis linguistic. From the Figure~\ref{fig:wordclouds}, it shows how individuals linguistically express emotions across different emotional states.
% In the angry speech scenario, frequently used words such as "angry," "think," "betrayed," and "frustration" highlight a strong focus on personal reflection, conflict, and perceived injustice. The presence of words like "understand" and "really" suggests an attempt to justify emotions or seek validation in confrontational situations.
% For the fear speech scenario, words like "help," "calm," "police," "scared," and "run" indicate a mix of distress and an urgent need for safety or assistance. The emphasis on "stay calm" and "know" suggests that individuals also attempt to manage their fear and seek solutions during stressful situations.
% In the happy speech scenario, the dominant words "excited," "ha ha," "fun," "happy," and "wait" reflect expressions of joy, enthusiasm, and anticipation. The frequent use of "see," "hear," and "trip" indicates that happiness is often associated with experiences, events, and social interactions.
% The neutral speech scenario includes words such as "routine," "shoes," "morning," and "house," indicating discussions about daily life, habits, and general observations. The frequent appearance of "story" and "interesting" suggests that even in neutral emotional states, people engage in conversations about experiences and narratives rather than strong emotional reactions.
% Lastly, in the sad speech scenario, key words such as "sad," "sorry," "feel," "trying," and "children" highlight expressions of emotional distress, regret, and concern for others. Words like "understand," "hear," and "people" indicate a search for empathy, connection, or support in difficult situations.
% These word clouds demonstrate the distinct linguistic patterns associated with different emotional expressions, offering valuable insights for emotion-aware AI systems, sentiment analysis, and affective computing applications.
In this study, we utilized the wordcloud package to analyze linguistic patterns across various emotional states. The resulting word clouds, as depicted in Figure~\ref{fig:wordclouds}, provide a visual representation of how individuals linguistically express emotions in different scenarios. Each emotional state reveals unique linguistic tendencies, reflecting the underlying feelings and cognitive processes associated with anger, fear, happiness, neutrality, and sadness.
In the angry speech scenario, the most frequently used words include "angry," "think," "betrayed," and "frustration." These terms highlight a strong focus on personal reflection, conflict, and perceived injustice. The presence of words like "understand" and "really" suggests that individuals in angry states often attempt to justify their emotions or seek validation, particularly in confrontational or tense situations. This linguistic pattern underscores the cognitive effort to rationalize or communicate feelings of anger.
For the fear speech scenario, the word cloud features terms such as "help," "calm," "police," "scared," and "run." These words reflect a mix of distress and an urgent need for safety or assistance. The emphasis on phrases like "stay calm" and "know" indicates that individuals experiencing fear also strive to manage their emotions and seek solutions during stressful or threatening situations. This linguistic behavior highlights the dual focus on expressing fear while attempting to regain control.
In the happy speech scenario, the dominant words include "excited," "ha ha," "fun," "happy," and "wait." These terms reflect expressions of joy, enthusiasm, and anticipation. The frequent use of words like "see," "hear," and "trip" suggests that happiness is often associated with experiences, events, and social interactions. This linguistic pattern emphasizes the outward and experiential nature of happiness, as individuals share their positive emotions and engage with the world around them.
The neutral speech scenario is characterized by words such as "routine," "shoes," "morning," and "house." These terms indicate discussions about daily life, habits, and general observations. The frequent appearance of "story" and "interesting" suggests that even in neutral emotional states, people engage in conversations about experiences and narratives rather than expressing strong emotional reactions. This linguistic pattern reflects the mundane yet meaningful nature of everyday communication.
Finally, in the sad speech scenario, key words such as "sad," "sorry," "feel," "trying," and "children" highlight expressions of emotional distress, regret, and concern for others. Words like "understand," "hear," and "people" indicate a search for empathy, connection, or support in difficult situations. This linguistic pattern underscores the introspective and relational aspects of sadness, as individuals seek to articulate their feelings and connect with others during challenging times.
These word clouds illustrate the distinct linguistic patterns associated with different emotional scenarios, offering valuable insights into how individuals communicate their emotions. Understanding these patterns can play a crucial role in enhancing the development of emotion-aware VAs, enabling them to generate more contextually appropriate and empathetic responses tailored to users' emotional states.
% These word clouds illustrate the distinct linguistic patterns associated with responses to different emotional scenarios, offering valuable insights into how individuals communicate their emotions. Understanding these patterns can play a crucial role in enhancing the development of emotion-aware VAs, enabling them to generate more contextually appropriate and empathetic responses tailored to users' emotional states. By analyzing these linguistic trends, we can better design VAs that not only recognize emotions but also respond in ways that align with users' natural communication styles, fostering more meaningful and effective human-computer interactions.

\subsubsection{Result from Correlation Between NLP Features}
\begin{figure}[ht]
    \centering
    \includegraphics[width=0.7\textwidth]{Figure/NLP_Correlation.png} % Adjust the path if needed
    \caption{Correlation Heatmap Between NLP Features. The heatmap visualizes the relationships among key linguistic features, including polarity, subjectivity, word count, and type-token ratio (TTR). Warmer colors indicate stronger positive correlations, while cooler colors represent negative correlations.}
    \label{fig:nlp_heatmap}
\end{figure}

As it show in Figure~\ref{fig:nlp_heatmap}, it reveals relationships between key linguistic metrics, including polarity, word count, and Type-Token Ratio (TTR). Polarity, which quantifies sentiment on a scale from negative to positive, exhibits a weak positive correlation (0.12) with word count, suggesting that longer texts may slightly amplify sentiment intensity.
TTR, a measure of lexical diversity, demonstrates a strong correlation with itself (1.00) and a moderate positive correlation with word count (0.16), indicating that longer texts tend to exhibit greater vocabulary variety. Notably, a significant negative correlation (-0.35) between polarity and another linguistic feature suggests an inverse relationship, potentially reflecting how emotions or linguistic structures influence sentiment expression.
These findings highlight the intricate interplay among linguistic features, offering valuable insights for the future design of emotion-aware VAs that can better interpret and respond to user sentiment.

\subsubsection{Result from Polarity and TTR Across Different Emotion Responses}
\begin{figure}[ht]
    \centering
    \includegraphics[width=0.8\textwidth]{Figure/NLP_Polarity_TTR.png}
    \caption{Polarity vs. Type-Token Ratio (TTR) Across Different Emotion Scenarios. Each marker represents a distinct emotional response: Angry, Happy, Sad, Fear, and Neutral. The distribution highlights differences in lexical diversity and sentiment across emotions.}
    \label{fig:polarity_ttr}
\end{figure}

From Figure~\ref{fig:polarity_ttr}, the relationship between polarity (sentiment positivity/negativity) and type-token ratio (TTR) (lexical diversity) across different emotional responses is illustrated. Each emotion category — Angry, Happy, Sad, Fear, and Neutral — is represented by distinct markers. The distribution reveals that happy responses (orange crosses) tend to have higher polarity values, indicating more positive sentiment, and exhibit a relatively high TTR, suggesting greater lexical diversity in positive speech. In contrast, angry and fearful responses (blue circles and red crosses) are more dispersed across the polarity spectrum, with many clustering in the negative range, reflecting their association with more negative sentiment. Neutral responses (purple diamonds) are spread across both low and high TTR values, indicating varied linguistic complexity in neutral expressions. This visualization highlights how emotional states influence both sentiment and lexical diversity, providing valuable insights into the linguistic patterns associated with different emotions.

\subsubsection{Result from Sentiment Polarity Across Different Emotion Responses}
\begin{figure}[ht]
    \centering
    \includegraphics[width=0.8\textwidth]{Figure/NLP_Sentiment_Polarity.png} % Adjust the path if needed
    \caption{Sentiment Polarity Across Different Emotion Scenarios. The bar plot illustrates the polarity (positive or negative sentiment) associated with each emotion category, including Angry, Happy, Sad, Fear, and Neutral responses. Happy responses show the highest positive polarity, while sad responses exhibit slightly negative polarity.}
    \label{fig:sentiment_polarity}
\end{figure}

The Figure~\ref{fig:sentiment_polarity} illustrates the Sentiment Polarity Across Different Emotion Responses, providing a clear understanding of how sentiment varies across emotions. The bar chart reveals that "Happy" emotions exhibit the highest positive polarity (~0.4), indicating a strong positive sentiment, whereas "Angry" emotions have the lowest polarity (close to -0.1), reflecting a more negative sentiment.
As expected, "Neutral" emotions remain close to zero, representing a balanced sentiment with neither strong positivity nor negativity. This figure effectively highlights the distinct variations in sentiment polarity across emotional responses, demonstrating that happiness is strongly associated with positive sentiment, while anger is linked to negative sentiment. These insights contribute to the development of emotion-aware VAs systems, enabling AI models to better recognize and respond to different emotional tones.