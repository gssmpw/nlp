\section{Related Work}
\subsection{Emotion Recognition in Voice Assistants}
Emotion recognition is a critical component of emotion-aware voice assistants (VAs). By analyzing speech features such as tone, pitch, and speech patterns~\cite{el2011survey,rathi2024analyzing,ma2024understanding}, speech emotion recognition (SER) enables VAs to detect emotional states from speech signals. Recent advancements in AI technologies, particularly in Large Language Models (LLMs) ~\cite{ma2024leveraging} and multimodal approaches~\cite{kumar2024multimodal} to SER, have significantly enhanced the accuracy and robustness of emotion detection ~\cite{lieskovska2021review,khalil2019speech}. These technologies leverage machine learning and deep learning models to identify emotions such as happiness, sadness, and anger, fostering more emotionally intelligent and contextually aware interactions in VAs.
Despite these advancements, challenges remain in handling variability in emotional expression due to factors such as cultural differences, accents, and background noise~\cite{mesquita1992cultural,can2023approaches}. For example, SER systems may misinterpret emotional cues in diverse linguistic or cultural contexts, reducing their effectiveness in real-world applications. Addressing these limitations requires further research into adaptive and context-aware emotion recognition models that can better generalize across different user demographics and environmental conditions.

\subsection{Empathetic Responses in Human-Computer Interaction}
% Empathy in AI refers to the ability of conversational agents to recognize, interpret, and appropriately respond to a user’s emotional state~\cite{srinivasan2022role}. Empathetic responses are critical for creating engaging and emotionally resonant interactions~\cite{raamkumar2022empathetic,liu2022artificial} and thus can enhance user engagement and trust by adapting their speech tone, word choices, and emotional expressiveness~\cite{barange2022impact}.
% Studies have shown that users respond positively to empathetic reactions from AI systems, such as Alexa’s ability to provide comforting or supportive responses~\cite{carolus2021alexa,mari2024empathic}.
% However, designing appropriate responses to negative emotions remains a significant challenge. While empathetic reactions can enhance user satisfaction, overly intrusive or artificial responses may feel misaligned with user expectations, ultimately undermining trust~\cite{atta2024influence,berking2012emotion} . This highlights the need for contextually appropriate and culturally sensitive emotional responses in emotion-aware systems.
Empathy in AI refers to a conversational agent's ability to recognize, interpret, and respond appropriately to a user’s emotional state~\cite{srinivasan2022role}. Empathetic responses play a crucial role in fostering engaging and emotionally resonant interactions\cite{raamkumar2022empathetic,liu2022artificial}, enhancing user engagement and trust by adapting speech tone, word choices, and emotional expressiveness\cite{barange2022impact}.
studies have shown that users respond positively to empathetic reactions from AI systems, such as Alexa’s ability to provide comforting and supportive responses\cite{carolus2021alexa,mari2024empathic}. However, designing appropriate responses to negative emotions remains a significant challenge. Although empathetic reactions can improve user satisfaction, overly intrusive or artificial responses may feel misaligned with user expectations, ultimately undermining trust\cite{atta2024influence,berking2012emotion}. This underscores the need for contextually appropriate and culturally sensitive emotional responses in emotion-aware AI systems.

% \subsection{Cultural and Gender Differences in Emotional Expression}
% Emotional expression varies significantly across cultures and genders, posing a challenge for emotion-aware systems. For example, cultural norms influence how emotions like anger or sadness are expressed and perceived, making it difficult to design universally effective systems (Mesquita, 1992; Fischer, 2004). Similarly, gender differences in emotional expression—such as women being more likely to express sadness and men more likely to express anger—further complicate the design of empathetic responses (Fischer et al., 2000). These variations underscore the importance of developing adaptive strategies that account for individual and cultural differences in emotional expression.

\subsection{Role-Swapping in Emotion Regulation}
% Role-swapping, where individuals take on the role of regulating another’s emotions, is an emerging area of research in human-computer interaction. This approach is particularly relevant for emotion-aware VAs, as it allows researchers to study how humans naturally respond to emotional cues from AI systems. For example, studies have explored how users interact with avatars or AI systems displaying negative emotions, revealing that neutral responses are common but vary by gender and context~\cite{ma2022should,huang2024relationship}. These insights can inform the design of VAs that mimic human emotional responding strategies, creating more natural and empathetic interactions.
% Role-swapping in emotion regulation is a promising approach to enhance voice user interface design, particularly in the design of emotion-aware VAs. In order to understand how the other emotional repsonding or reacting strategies, users can take on the responsibility of regulating the emotions of AI systems, such as responding to negative emotional cues displayed by VAs. Studies have shown that individuals often adopt neutral emotional responses when interacting with emotionally expressive AI systems, but gender and cultural differences can influence these strategies~\cite{ma2022should,huang2024relationship}. Moreover, research on interpersonal emotion regulation highlights how individuals adapt their strategies to support others, such as using cognitive reappraisal to reinterpret stressful situations or employing expressive suppression to avoid escalating conflicts~\cite{zaki2013interpersonal,gross2015emotion}. These insights can be applied to AI systems, enabling them to mimic human emotional responding strategies and create more empathetic interactions. However, challenges remain in addressing cultural and contextual differences in emotional expression, as well as ensuring that role-swapping systems are adaptive and effective across diverse user demographics~\cite{mesquita1992cultural,fischer2004gender}. By leveraging role-swapping approaches, researchers can develop VAs that provide more contextually appropriate and emotionally resonant responses, ultimately enhancing user satisfaction and trust.
Role-swapping in emotion regulation is a promising approach for enhancing voice user interface design, particularly in the development of emotion-aware voice assistants (VAs). By reversing traditional roles, users take on the responsibility of regulating the emotions of AI systems, such as responding to negative emotional cues displayed by VAs. This approach allows researchers to explore alternative emotional responding and reacting strategies, shedding light on how humans manage AI-driven emotions.
Studies have shown that individuals often adopt neutral emotional responses when interacting with emotionally expressive AI systems. However, gender and cultural differences can significantly influence these strategies~\cite{ma2022should,huang2024relationship}. Furthermore, research on interpersonal emotion regulation highlights how individuals adjust their strategies to support others—for example, using cognitive reappraisal to reinterpret stressful situations or employing expressive suppression to prevent conflict escalation~\cite{zaki2013interpersonal,gross2015emotion}. These insights can be applied to AI systems, enabling them to mimic human emotional responding strategies and create more empathetic and adaptive interactions.
Despite its potential, role-swapping in emotion regulation presents challenges, particularly in addressing cultural and contextual differences in emotional expression and ensuring that such systems remain adaptive and effective across diverse user demographics~\cite{mesquita1992cultural,fischer2004gender}. By leveraging role-swapping approaches, researchers can develop emotion-aware VAs capable of providing contextually appropriate and emotionally resonant responses, ultimately enhancing user satisfaction and trust in AI-driven interactions.

\subsection{Research Gaps}
While significant progress has been made in emotion recognition and empathetic response generation, research on how humans naturally respond to emotional cues from AI systems—particularly in role-swapping scenarios—remains limited. Most existing studies focus on how AI systems respond to human emotions, rather than how humans regulate the emotions of AI systems.
Our study addresses this gap by introducing a role-swapping approach, where participants interact with emotion-aware voice assistants (VAs) to transform negative emotions into positive or neutral states. By analyzing participants’ emotional responses, we aim to develop effective strategies for designing more adaptive and empathetic VAs. This approach not only deepens our understanding of human emotional responding strategies but also provides valuable insights for enhancing emotion-aware AI systems, leading to more natural and engaging human-AI interactions.