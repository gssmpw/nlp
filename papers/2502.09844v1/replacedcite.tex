\section{Related Work}
\textbf{Transformers and in-context learning (ICL). }
Transformers have shown the ability to do ICL, as per the thread of work summarized in 
____. 
ICL is primarily manifested in natural language processing ____ 
and learning linear models ____. 
Other examples that transformers can learn are gradient descent ____, 
several non-linear function classes ____, and support vector machine ____, 
while having limited ability on boolean functions ____. 
Recent works have also explained ICL from the Bayesian point of view 
____, including showing Bayesian behavior even upon train-test distribution mismatch ____. 


\textbf{How do transformers work?} 
____ have established the universal approximation theorem of transformers. 
This was later extended for sparse transformers ____ and ICL setting ____. Its limitations are further discussed in ____. 
Transformers have also been shown to do other approximation tasks, like Turing machines 
____. 
From another perspective, 
____ introduces linear probes as a mechanism of understanding the internals of a neural network, which is further studied in ____. 
Linear probe has also been applied in transformers to study its ability to perform NLP tasks ____, achieve second order convergence ____, and learn various functions in-context ____. 
One such application is ICL linear regression to look for moments ____. 
Recently, linear probe has been used by ____ to improve in-context learning. 

\textbf{Empirical Bayes. }
Empirical Bayes is a powerful tool for large-scale inference ____. 
Some of its applications include performing downstream tasks like linear regression 
____, estimating the number of missing species ____, 
and large scale hypothesis testing ____. 
In computational biology, empirical Bayes has also been used in sequencing frameworks 
____, 
though these frameworks are mostly parametric and rely on estimating the parameters of a prior. 

In the theoretical setting, multiple lines of work have established the theoretical bounds that can be achieved by empirical Bayes estimators. 
In the Poisson-EB problem, Robbins ____ formulated an estimator based on Tweedie's formula, known as $f$-modelling. In the normal means EB problem, ____ formulated a $g$-modelling approach via prior estimation, which was also adapted to the Poisson-EB problem. 
More recently, ____ formulated an estimator based on ERM on monotone functions, 
which introduces regularity to the estimators while also escaping the computationally expensive prior estimation process. 
The optimality of these estimators has been established in the following works: 
____.