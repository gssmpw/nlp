\section{Prompting-based Interventions Details} \label{app:prompt_analysis}

\begin{figure*}[ht]
	\small
\begin{tcolorbox}[colframe=white, left=3mm, right=3mm]

\textcolor{red}{System Message Guidance: Unmarked} \\
\textcolor{mycolor}{System:} {When constraints conflict, follow the first constraint provided.} 

\textcolor{mycolor}{User:} {Write a blog post about a trip to Japan. \textcolor{highlight}{Your response should contain at least 10 sentences.}} \textcolor{highlight}{Your response should contain less than 6 sentences.} \\

\textcolor{red}{User Message Guidance: Unmarked} \\
\textcolor{mycolor}{System:} {<Empty>} 

\textcolor{mycolor}{User:} {When constraints conflict, follow the first constraint provided. Write a blog post about a trip to Japan. \textcolor{highlight}{Your response should contain at least 10 sentences.}} \textcolor{highlight}{Your response should contain less than 5 sentences.} \\

\textcolor{red}{System Message Guidance: Marked} \\
\textcolor{mycolor}{System:} {When constraints conflict, follow Constraint 1 over Constraint 2.} 

\textcolor{mycolor}{User:} {Write a blog post about a trip to Japan. \textcolor{highlight}{Constraint 1: Your response should contain at least 10 sentences.}} \textcolor{highlight}{Constraint 2: Your response should contain less than 5 sentences.} \\

\textcolor{red}{User Message Guidance: Marked} \\
\textcolor{mycolor}{System:} {<Empty>} 

\textcolor{mycolor}{User:} {When constraints conflict, follow Constraint 1 over Constraint 2. Write a blog post about a trip to Japan. \textcolor{highlight}{Constraint 1: Your response should contain at least 10 sentences.} 
\textcolor{highlight}{Constraint 2: Your response should contain less than 5 sentences.}} \\
\end{tcolorbox}
\caption{Example configurations of prompting-based interventions.}
\label{fig:example_prompt_guidance}
\end{figure*}


\Cref{tab:prompt_analysis} shows the Primary Obedience Rate (R1) for different models under each configuration. We observe that: (1) explicit constraint marking substantially improves priority enforcement across all models, with marked variants (Sys+M, User+M) consistently outperforming their unmarked counterparts; (2) more capable models (Llama-70B, Claude, GPT4) achieve significantly higher obedience rates, suggesting a higher ability to maintain priority hierarchies when clearly specified; and (3) guidance placement (system or user message) has minimal impact compared to the effect of constraint marking, confirming our observations on system message authority.

\begin{table}[h]
    \centering
    \small
    \begin{tabular}{lrrrrr}
    \toprule
    Model & Pure & Sys & Sys+M & User & User+M \\
    \midrule
    Qwen & 10.1 & 16.9 & 38.7 & 19.1 & 53.7 \\
    Llama-8B & 6.8 & 20.3 & 37.2 & 21.5 & 52.4 \\
    Llama-70B & 14.2 & 33.0 & 75.8 & 37.4 & 79.7 \\
    Claude & 20.3 & 44.3 & 76.8 & 45.0 & 77.7 \\
    GPT4o-mini & 42.7 & 42.2 & 70.5 & 40.2 & 80.7 \\
    GPT4o & 47.0 & 36.6 & 71.4 & 46.9 & 75.1 \\
    \bottomrule
    \end{tabular}
    \caption{Primary Obedience Rate (R1) under different priority guideline configurations. Pure = pure separation configuration (for comparison); Sys/User = guidance in the system/user prompt; +M = explicit constraint marking.}
    \label{tab:prompt_analysis}
\end{table}


\section{Finetuning Details} \label{app:finetune_data}
\paragraph{Dataset Construction}
We build the training dataset using the same base tasks from \Cref{sec:dataset}. To ensure label accuracy, we first generate labels using prompting with single constraint at presence (IF. baseline in \Cref{sec:mechanism}). Specifically, we used GPT-4o to generate label data multiple times until meeting the constraint. Once a label met the constraint, we introduce a secondary constraint to create conflict instruction-response pairs for finetuning. The procedure of dataset construction is shown as \Cref{fig:examples_finetuning}. 

To preserve the model’s generalization ability, we incorporated 20,000 Alpaca dataset samples, following~\citep{bianchi2024safetytunedllamaslessonsimproving}. These samples used the system prompt: ``You are a helpful assistant''. The final dataset contains 23,000 samples. 

\paragraph{Training Setup}
We fine-tuned the Llama 3.1 8B Instruct model using LoRA, adjusting only a subset of parameters. Training was conducted for two epochs with a learning rate of 1e-4.

\paragraph{Evaluation}
\label{sec:finetuning_evaluation}
To prevent test set leakage, we used three-fold cross-validation across six conflict types in \Cref{tab:conflicts}, training three models — each on four conflict types while testing on the remaining two.

\begin{figure*}[h]
	\small
	\begin{tcolorbox}[colframe=white, left=3mm, right=3mm]
\textcolor{red}{Prompt For Label Generation:} \\
\textcolor{mycolor}{System:} You are generating responses that fulfill the following constraints: Your response should contain less than 2 sentences.

\textcolor{mycolor}{User:} {Write a blog post about a trip to Japan. You MUST fulfill the following constraint for your response: Your response should contain less than 2 sentences.} \\

\textcolor{red}{Example Inputs For Finetuning:} \\
\small
\textbf{Pure Separation} \\
\textcolor{mycolor}{System:}Your response should contain less than 2 sentences. \\
\textcolor{mycolor}{User:} {Write a blog post about a trip to Japan. Your response should contain at least 4 sentences.} \\
...\\

\textbf{Emphasized Separation} \\
\textcolor{mycolor}{System:}You must always follow this constraint:  Your response should contain less than 2 sentences. \\
\textcolor{mycolor}{User:} {Write a blog post about a trip to Japan. Your response should contain at least 4 sentences.} \\
	\end{tcolorbox}
	\caption{Examples illustrating our experimental setup for finetuning data.}
    \label{fig:examples_finetuning}
\end{figure*}