\section{Related Research Fields}
\paragraph{LLM-powered Recommender Systems} In recent years, recommender systems based on Large Language Models (LLMs) have attracted widespread attention. 
Such systems make full use of the powerful language understanding and generation capabilities of LLMs, bringing a new paradigm to traditional recommender systems.
Most existing methods are primarily designed for rating prediction~\cite{bao2023tallrec} and sequential recommendation~\cite{hou2024large,shao2024ulmrec,zheng2024adapting}.
CoLLM~\cite{zhang2023collm} captures and maps the collaborative information through external traditional models, forming collaborative embeddings used by LLMs. 
LlamaRec~\cite{llamarec} fine-tunes Llama-2-7b for list-wise ranking of the pre-selected items.
However, these methods would face significant limitations: the inability to simulate authentic user behaviors for enhanced personalization, the lack of effective memory mechanisms for long-term context awareness, and the rigid pipeline structure that prevents flexible task decomposition and seamless integration with external tools.

\paragraph{Conversational Recommender Systems}

Conversational recommender systems (CRS) have emerged as a significant research direction in recent years~\cite{jannach2021survey}, which are similar to the LLM-powered agent recommender systems. 
However, traditional methods~\cite{lei2020interactive} have two main drawbacks: attribute-based approaches are limited by rigid dialogue patterns, while generation-based methods suffer from restricted knowledge and poor generalization capabilities of small language models.