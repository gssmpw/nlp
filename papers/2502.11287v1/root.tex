%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%2345678901234567890123456789012345678901234567890123456789012345678901234567890
%        1         2         3         4         5         6         7         8

\documentclass[letterpaper, 10 pt, conference, final]{ieeeconf}  % Comment this line out if you need a4paper

%\documentclass[a4paper, 10pt, conference]{ieeeconf}      % Use this line for a4 paper

\IEEEoverridecommandlockouts                              % This command is only needed if 
                                                          % you want to use the \thanks command

\overrideIEEEmargins                                      % Needed to meet printer requirements.

%In case you encounter the following error:
%Error 1010 The PDF file may be corrupt (unable to open PDF file) OR
%Error 1000 An error occurred while parsing a contents stream. Unable to analyze the PDF file.
%This is a known problem with pdfLaTeX conversion filter. The file cannot be opened with acrobat reader
%Please use one of the alternatives below to circumvent this error by uncommenting one or the other
%\pdfobjcompresslevel=0
%\pdfminorversion=4

% See the \addtolength command later in the file to balance the column lengths
% on the last page of the document

% The following packages can be found on http:\\www.ctan.org
\usepackage{graphics} % for pdf, bitmapped graphics files
\usepackage{epsfig} % for postscript graphics files
\usepackage{mathptmx} % assumes new font selection scheme installed
\usepackage{times} % assumes new font selection scheme installed
\usepackage{amsmath} % assumes amsmath package installed
\usepackage{amssymb}  % assumes amsmath package installed

\usepackage{hyperref}
\usepackage{multirow}
\usepackage{caption}


\title{\LARGE \bf
MC-BEVRO: Multi-Camera Bird Eye View Road Occupancy Detection for Traffic Monitoring}

\author{Arpitsinh Vaghela$^{1}$, Duo Lu$^{2}$, Aayush Atul Verma$^{1}$, Bharatesh Chakravarthi$^{1}$, Hua Wei$^{1}$ and Yezhou Yang$^{1}$%
\thanks{$^{1}$School of Computing and Augmented Intelligence, Arizona State University, Tempe, AZ, USA. Correspondence to \href{mailto:avaghel3@asu.edu}{\tt{avaghel3@asu.edu}}}  
\thanks{$^{2}$Department of Computer Science and Physics, Rider University, Lawrenceville, NJ, USA. {\tt dlu@rider.edu}}
\thanks{For more information, please visit the official MC-BEVRO website: {\tt\href{https://arpitvaghela.github.io/MC-BEVRO/}{\tt{https://arpitvaghela.github.io/MC-BEVRO/}}}}
}%


\begin{document}



\maketitle
\IEEEpeerreviewmaketitle
\thispagestyle{empty}
\pagestyle{empty}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}
% Single camera $3D$ perception for traffic monitoring faces significant challenges due to occlusion and limited field of view. Moreover, fusing information from multiple cameras at the image feature level is difficult because of different view angles. Furthermore, the necessity for practical implementation and compatibility with existing traffic infrastructure compounds these challenges. To address these issues, this paper introduces a novel Bird-Eye-View (BEV) road occupancy detection framework that leverages multiple cameras on the roadside to overcome the aforementioned limitations. A synthetic dataset encompassing diverse scenes and varying camera configurations is generated using the CARLA simulator, and three detection models are developed. Subsequent extensive evaluation of these models showcases our framework and explains the performance influence of using multi-views and different BEV grid sizes. Additionally, we demonstrate another pipeline for data collection in the real world, which complements our synthetic data. We further evaluated the sim-to-real capability of our model to ensure its practical application, showing insight into the influence of robust dataset design in refining ITS perception systems. Our research aims to advance $3D$ traffic perception so as to improve traffic management, operational efficiency, and road safety.
Single camera $3D$ perception for traffic monitoring faces significant challenges due to occlusion and limited field of view. Moreover, fusing information from multiple cameras at the image feature level is difficult because of different view angles. Further, the necessity for practical implementation and compatibility with existing traffic infrastructure compounds these challenges. To address these issues, this paper introduces a novel Bird's-Eye-View road occupancy detection framework that leverages multiple roadside cameras to overcome the aforementioned limitations. To facilitate the framework's development and evaluation, a synthetic dataset featuring diverse scenes and varying camera configurations is generated using the CARLA simulator. A late fusion and three early fusion methods were implemented within the proposed framework, with performance further enhanced by integrating backgrounds. Extensive evaluations were conducted to analyze the impact of multi-camera inputs and varying BEV occupancy map sizes on model performance. Additionally, a real-world data collection pipeline was developed to assess the modelâ€™s ability to generalize to real-world environments. The sim-to-real capabilities of the model were evaluated using zero-shot and few-shot fine-tuning, demonstrating its potential for practical application. This research aims to advance perception systems in traffic monitoring, contributing to improved traffic management, operational efficiency, and road safety.

\end{abstract}
\input{introduction}
\input{related_works}
\input{methodology}
\input{experiments}
\input{conclusion}

\bibliographystyle{ieeetr}
\bibliography{root}

\end{document}
