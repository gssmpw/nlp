\section{CONCLUSION}
\label{conclusion}

This paper introduces a novel framework for multi-camera Bird-Eye-View (BEV) road occupancy detection using roadside cameras, addressing challenges such as occlusion and limited field of view in traffic monitoring. We developed and implemented three different early fusion models, with proposed background integration to further boost the performance. To address lack of dataset, we created a synthetic dataset using CARLA, featuring diverse scenes and camera setups. An evaluation with real-world data is also provided, demonstrating our model's ability to generalize to real-world scenes, with few shot fine-tuning further improving performance. Our contributions advance perception in traffic monitoring, provide valuable research data, and offer a practical approach for downstream traffic analysis applications.

% Future advancements could include fusing sensors such as LiDAR \cite{fazlali2022versatile} and event cameras \cite{verma2024etram, aliminati2024sevd} in the BEV space and predicting other traffic characteristics such as the velocity. We also plan to compare the multi-view performance of occupancy detection vs. $3D$ object detection with object-level fusion. Another potential area for improvement is optimizing computational efficiency and testing the real-world deployment of such a multi-camera system. We hope this research can improve traffic management, operational efficiency, and road safety in the long term.
