\section{RELATED WORKS}
\label{sec:related_works}
This section reviews existing datasets and methodologies for roadside traffic monitoring followed by multi-camera approaches for BEV people occupancy detection.

\textbf{Roadside Traffic Monitoring Datasets:} Several datasets have been developed to facilitate the study of roadside traffic monitoring. CityFlow Chen, et al., "CityFlow: A Large-Scale Video Dataset for Surveillance and Monitoring" comprises over $3$ hours of synchronized videos of $40$ cameras across $10$ intersections, with $200K$ $2D$ annotations spanning multiple camera views but lacks $3D$ annotations necessary for more advanced tasks like depth estimation and precise localization, limiting its applicability. BoxCars Li, et al., "BoxCars: A 3D Object Detection Dataset" offers $116K$ images with $3D$ vehicle annotations from a surveillance camera but is captured from a single view. Rope3D Wang, et al., "Rope3D: A Large-Scale 3D Object Detection and Tracking Dataset" provides $1.5M$ $3D$ bounding box $50K$ LiDAR scans and images from multiple cameras in a roadside perspective. However, this dataset is limited to non-overlapping individual views, which is unsuitable for studying data fusion from multiple cameras. Chen, et al., "Vehicle Infrastructure Cooperative Dataset" introduces a vehicle infrastructure cooperative dataset consisting of $71K$ LiDAR scans and camera samples with $3D$ annotations. However, since the data is collected for a single traffic scene, it limits the ability to assess the model's generalization to unseen environments with varying camera configurations.

\textbf{3D Perception in Traffic Monitoring:} Detecting traffic participants and localizing them in the 3D space has been a long-term goal for traffic monitoring. Many prior works tried to predict the 3D clues directly from images. BEVHeight Liu, et al., "BEVHeight: A Robust Method for Roadside 3D Object Detection" introduces a robust method for roadside $3D$ object detection by predicting vehicle height instead of depth, which remains consistent across varying distances from the camera. CAROM Chen, et al., "CAROM: A Pipeline for Vehicle 3D Bounding Box Detection" provides a pipeline to detect vehicle $3D$ bounding boxes from segmentation masks and allows object-level fusion from multiple monocular cameras. In Li, et al., "Fusion Techniques for Multi-Camera Traffic Monitoring" different fusion techniques like early, late, and hybrid are explored to optimize $3D$ perception using both camera and LiDAR data. TransIFF Wang, et al., "TransIFF: A Transformer-Based Fusion Framework for Multi-Camera Traffic Monitoring" leverages a transformer-based fusion framework to address the domain gap and enhance feature fusion robustness. Similarly, the Feature Flow Net Zhang, et al., "Feature Flow Net: A Flow-Based Feature Fusion Approach for Cooperative 3D Object Detection" uses a flow-based feature fusion approach for cooperative $3D$ object detection. Additionally, MonoUNI Liu, et al., "MonoUNI: A Unified Optimization Target for Multi-Camera Traffic Monitoring" introduces normalized depth as a unified optimization target, leading to top performance in infrastructure-side benchmarks without relying on additional data inputs. However, these methods focus on object-level detection, which is limited by its focus on individual objects, struggles with occlusions, and lacks the ability to handle rare and irregular objects, such as trailers towed by a truck or a crowd of pedestrians. In contrast, BEV occupancy detection offers a more comprehensive spatial representation, handling occlusions and crowded environments more effectively and providing better generalization across diverse scenarios.


% The occupancy grid can be realized by estimating each cell's state from sensor data. 
% Traditional MVD techniques employ background subtraction and use a set of anchor boxes derived from scene geometry. These boxes are projected onto a BEV plan, and Conditional Random Fields (CRF) or mean-field inference is used for spatial aggregation.

\textbf{BEV People Detection from Multiple Cameras:} The concept of predicting occupancy probabilities from multiple views using a discrete occupancy map was first introduced for pedestrian detection Li, et al., "Occupancy Grids for Multi-Camera Traffic Monitoring". The occupancy map corresponds to a discrete-state (binary) random field. Given a $3D$ world space observed by the cameras, the BEV occupancy map divides the $XY$ plane of $3D$ space into discrete vertical columns of resolution. The presence or absence of objects within this $3D$ space is then represented on the map using binary encoding. The resolution parameters, $\Delta x\, \text{ and }\, \Delta y$, dictate the level of detail and granularity of the occupancy information captured in the map, enabling a balance between precision and computational efficiency in processing and analysis. Liang, et al., "Multi-View Convolutional Neural Networks for BEV Occupancy Prediction" combine the convolutional neural net (CNN) network with conditional random fields (CRF) to predict BEV occupancy. Deep-MCD Chen, et al., "Deep-MCD: A Deep Learning Framework for Multi-Camera Traffic Monitoring" uses CNN architecture followed by multilayer perceptron over the generated feature map to predict the BEV occupancy. MVDet Wang, et al., "MVDet: An Anchor-Free Approach to Multi-View Object Detection" proposes an anchor-free approach to aggregate multiview. It first applies a perspective transformation, followed by concatenating the projected feature maps from multiple viewpoints and performing large kernel convolution for spatial aggregation. MVDeTr Li, et al., "MVDeTr: A Shadow Transformer for Multi-Camera Traffic Monitoring" introduces the concept of a shadow transformer, which uses a deformable transformer on multiple camera images for spatial aggregation. SHOT Song, et al., "SHOT: A Stacked Homography Estimation Network for Multi-Camera Traffic Monitoring" introduced a combination of homographies at different heights to improve the quality of projections. GMVD Chen, et al., "GMVD: A Generalization Framework for Multi-Camera Traffic Monitoring" focuses on generalization ability across multiple camera configurations by using average pooling. These methods have been applied to people detection in open spaces, where each person is typically assumed to occupy a single cell. In contrast, detecting traffic participants in traffic monitoring requires handling multi-cell occupancy due to larger size of vehicles, adding complexity to the spatial representation and detection process.