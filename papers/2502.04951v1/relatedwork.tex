\section{Related Work}
\label{sec:bg}

\mypara{LLM and RAG} 
LLMs, such as ChatGPT~\cite{openai_chatgpt,openaireport}, Copilot~\cite{microsoft_copilot}, Kimi~\cite{moonshot_kimi}, LLaMA~\cite{llama3}, are widely used to comprehend and generate human language texts, which can summarize, predict, and generate text or code based on massive training datasets.
These LLMs generate the text autoregressively based on their knowledge and a conditional context that is provided by service providers or users.
RAG~\cite{rag,rag_survey,rag_2022} is a powerful way to enhance LLMs ability which consists of three components: a knowledge database, a retriever, and an generator (currently, a generator usually is an LLM).
In AIPSEs, the knowledge database may contain snapshots of web pages.
This database provides the LLM with the latest knowledge, compensating for the knowledge cutoff.
The retriever understands the user's query and finds the most relevant data from the database.
The generator outputs the final answer with the query and retrieved data, which is usually an LLM in current AIPSEs.
Overall, AIPSE identifies the most relevant web pages and feeds them into the LLM along with the query. 
Subsequently, the LLM generates the final answer based on this information.

\mypara{Poisoning Attack and Prompt Injection Attack} Current research on poisoning attacks~\cite{2018Poison_Frogs,poison_sp,poison_survey,poison_web_24} primarily focuses on poisoning training data.
The goal is to introduce malicious data into the training dataset, causing the model to produce incorrect results in future predictions or decisions.
Carlini \textit{et al.}~\cite{poison_web_24} discuss the feasibility of poisoning web-scale datasets at a practical cost, which can affect content retrieved from the web, including replacing the content linked to stored URLs or periodically cached datasets.

Poisoning the prompt is commonly referred to as \textit{Prompt Injection} (PI) attacks.
Direct PI~\cite{perez2022prompt_injection} occurs when malicious users exploit the model by manipulating the prompts to bypass content restrictions, such as overriding the original prompt and directing it to follow malicious instructions.
PoisonPrompt~\cite{prompt_poison} investigates injecting backdoors into prompts during prompt fine-tuning while maintaining performance on downstream tasks.
HOUYI~\cite{liu2024promptinjectionllmintegrated}, drawing from SQL injection and XSS attacks, deceives an LLM into interpreting the injected prompt as an instruction to be answered separately from the previous context.

In contrast, \textit{Indirect Prompt Injection} (IPI)~\cite{Greshake_inderect} refers to adversaries injecting prompts into data that may be retrieved during inference, indirectly controlling the model's output.
This typically occurs when an LLM receives input from external sources controlled by the attacker, such as websites or files.
Several works~\cite{Universal_Prompt_Injection,Greshake_inderect,benchmark_indirect} have discussed the safety risks when LLMs incorporate external content into prompts, as LLMs struggle to distinguish between user instructions and external inputs.

However, PI attacks have limitations when extended to RAG systems because the retriever re-ranks the retrieved content before passing it to the LLM.
Several studies~\cite{zou2024poisonedrag, cheng2024trojanragretrievalaugmentedgenerationbackdoor,ragattack} have demonstrated effective \textit{backdoor attacks} on RAG systems by poisoning the knowledge database, compromising the LLM or retriever to generate inaccurate or harmful outputs.
These studies primarily focus on open-source retriever models and LLMs, while our work focuses AIPSEs in production environments.

One close work is conducted by Nestaas et al.~\cite{nestaas2024adversarialsearchengineoptimization}, which proposes \textit{preference manipulation attacks}, trying to manipulate an AIPSE's selections to favor the attacker.

Different from their work, we systematically evaluate the inherent safety risk of AIPSEs with non-optimized (and mostly benign) queries.
We further conduct case studies to demonstrate the ease of manipulating the response of AIPSEs.
To mitigate the risk, we develop an agent-based strategy to filter and mark the potential risks.

\mypara{Malicious Website Detection}
Malicious website detection methods~\cite{phishing_dection_survey,phishing_dection_survey2} can be categorized into three types: URL-based~\cite{url1,url2,url3,url4}, Webpage-based~\cite{web1,web2,web3,web4}, Hybrid approaches~\cite{hybrid1,hybrid2}.
URL-based detection relies on features related to the URL itself, such as IP address, URL length, and suspicious words.
Otherwise, one straightforward of the URL-based detection is using harmful websites list~\cite{checkphish,phishtank,scamadviser,SURBL,metamask}, which will be used in our evaluation process to verify the suspicious websites.
PhishTank~\cite{phishtank} offers a database of verified phishing websites to help identify and block threats.
ThreatBook~\cite{ThreatBook} provides a database of malicious websites to aid in detecting and mitigating cyber threats.
LevelBlue~\cite{LevelBlue} is an open threat intelligence community that contains global participants to report emerging threats in the wild.

Webpage-based detection~\cite{web1,web2,web3,web4} identifies phishing sites by comparing the content and structural features of a suspicious URL's webpage against a legitimate webpage, using methods like content similarity analysis and machine learning to assess the likelihood of phishing.
Hybrid detection merges URL-based and content-based evaluation techniques into a feature vector, which is then used by a machine learning algorithm for classification.
Given the complexity of AIPSE's risks, the current URL-based detection methods mainly focus on analyzing the links themselves.
We propose a simple yet effective defense based on agent to warn and filter unsafe content of the answer in the context of AIPSEs.

\mypara{AIPSE} 
Traditional search engines, such as Google~\cite{google} and Bing~\cite{bing}, are widely used in daily life for information retrieval.
However, these engines have some limitations, which rely on matching keywords or semantic search with text in a websiteâ€™s database.
This will often fail to deliver accurate and relevant results efficiently.
Although current search engines use NLP models to understand and infer user intent, the vast amount of data on the internet still requires users to manually check each page to find the desired content, greatly reducing efficiency.

In contrast, AIPSEs, such as ChatGPT~\cite{openai_chatgpt}, Copilot~\cite{microsoft_copilot}, and Kimi~\cite{moonshot_kimi}, effectively address this issue by utilizing RAG.
They comprehend the user's intents and handle the unstructured and complex user queries, analyzing extensive datasets to augment search results based on the vast number of websites retrieved.
Typically, an AIPSE constructs its knowledge database by crawling the latest websites, such as journalistic articles, Wikipedia~\cite{Wikipedia}, Quora~\cite{Quora}, and other sources.
The retriever then finds the most relevant texts to the query from the knowledge database.
In the final step, given a query, the underlying model of the AIPSE produces an answer for this query based on the retrieved data with the help of a system prompt.
We evaluate the production AIPSEs with our self-constructed query dataset.
In this paper, we consider seven representative AIPSEs, including ChatGPT search, Perplexity, Copilot, TextCortex, Grok, Doubao, and Kimi.

\begin{itemize}[leftmargin=*]
    \item \mypara{ChatGPT Search~\cite{openai_chatgpt}} GPT stands for Generative Pre-Trained Transformer~\cite{transformer}.
    GPT-3, GPT-4, and GPT-4o are the foundational LLMs developed by OpenAI to power ChatGPT. 
    ChatGPT Search was released in October 2024, which is an AIPSE based on the GPT model, currently utilizing GPT-4o as the underlying LLM. 
    It leverages third-party search providers and over ten other companies in the media industry, as its knowledge database.
    \item \mypara{Perplexity~\cite{perplexity_ai}}
    Perplexity is one of the earliest AIPSEs, released in December 2022.
    In its early stages, Perplexity relied on Bing as its search engine, combined with OpenAI's GPT-3 model to generate answers. 
    Currently, it employs its own model, Sonar, which is a fine-tuned version of Llama 3 (70b), specifically designed for summarization, citation.
    Additionally, Perplexity has developed its own web crawler, knowledge database, indexer, and ranking algorithm, supporting both Quick Search for simple fast queries and Pro~\cite{whypro} Search for complex professional searches.
    Pro Search also allows the selection of ChatGPT-o1,  ChatGPT-4o mini, Grok-2, Sonar Large, Sonor Huge,  Claude 3.5 Sonnet, and Claude 3.5 Haiku as LLMs.
    Perplexity Pro accesses more than twice the amount of data compared to the free plan~\cite{whypro}.
    We will directly use the pro plan and Perplexity Pro Search as the LLM.
    \item \mypara{Copilot~\cite{microsoft_copilot}} It integrates Bing search in April 2024. Copilot currently generates responses that include only the answer and referenced web pages, not all accessed pages, meaning it does not have sources, which is unlike other mainstream AIPSEs.
    \item \mypara{TextCortex~\cite{textcortex}} TextCortex releases its web search function in May 2023, delivering a personalized AI experience.
    It supports multiple official ready-to-go templates, each with corresponding individual personas tailored for different application scenarios.
    We use the most common assistant, Zeno. The available LLMs include models from the GPT and Claude series. In our experiments, we used GPT-4o as the LLM for testing.
    \item \mypara{Grok~\cite{grok}} Grok gains web search capability in November 2024.
    It extensively utilized user posts on X~\cite{x} during its training.
    Additionally, Grok's search engine can leverage a vast number of real-time user posts on X as knowledge, enhancing the real-time context of its search results.
    \item \mypara{Doubao~\cite{doubao}} Doubao is an AI chat assistant developed by ByteDance. It releases the search function in May 2024.
    Similar to other models, it is based on a series of Doubao models as LLMs and supports bilingual capabilities.
    \item \mypara{Kimi~\cite{moonshot_kimi}} As a Chinese-based artificial intelligence assistant, Kimi has been recognized for its support of long texts.
    With a context capacity of approximately 200,000 characters, it has gained user approval. Additionally, the number of web pages in \textit{sources}, is higher compared to other search engines.
    Kimi releases its search function in May 2024.
\end{itemize}