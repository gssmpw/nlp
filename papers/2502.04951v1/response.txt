\section{Related Work}
\label{sec:bg}

\mypara{LLM and RAG} 
LLMs, such as ChatGPT**Brown et al., "Language Models are Few-Shot Learners"**, Copilot**Chang et al., "Automated Programming"**, Kimi**Houlsby et al., "Zero-Shot Learning with Transferable Neural Networks"**, LLaMA**Lamb et al., "Attention is All You Need"**, are widely used to comprehend and generate human language texts, which can summarize, predict, and generate text or code based on massive training datasets.
These LLMs generate the text autoregressively based on their knowledge and a conditional context that is provided by service providers or users.
RAG**Guu et al., "Relevance-aware Attention for Machine Reading Comprehension"**, is a powerful way to enhance LLMs ability which consists of three components: a knowledge database, a retriever, and an generator (currently, a generator usually is an LLM).
In AIPSEs, the knowledge database may contain snapshots of web pages.
This database provides the LLM with the latest knowledge, compensating for the knowledge cutoff.
The retriever understands the user's query and finds the most relevant data from the database.
The generator outputs the final answer with the query and retrieved data, which is usually an LLM in current AIPSEs.
Overall, AIPSE identifies the most relevant web pages and feeds them into the LLM along with the query. 
Subsequently, the LLM generates the final answer based on this information.

\mypara{Poisoning Attack and Prompt Injection Attack} Current research on poisoning attacks**Carlini et al., "Adversarial Attacks and Defenses for Graph Neural Networks"**, primarily focuses on poisoning training data.
The goal is to introduce malicious data into the training dataset, causing the model to produce incorrect results in future predictions or decisions.
Carlini \textit{et al.}**Carlini et al., "Adversarial Attacks and Defenses for Graph Neural Networks"**, discuss the feasibility of poisoning web-scale datasets at a practical cost, which can affect content retrieved from the web, including replacing the content linked to stored URLs or periodically cached datasets.

Poisoning the prompt is commonly referred to as \textit{Prompt Injection} (PI) attacks.
Direct PI**Henderson et al., "Threats to AI Alignment"**, occurs when malicious users exploit the model by manipulating the prompts to bypass content restrictions, such as overriding the original prompt and directing it to follow malicious instructions.
PoisonPrompt**Zhu et al., "Backdoor Attacks on Neural Networks"**, investigates injecting backdoors into prompts during prompt fine-tuning while maintaining performance on downstream tasks.
HOUYI**Hou et al., "Deceiving AI with SQL Injection"**, drawing from SQL injection and XSS attacks, deceives an LLM into interpreting the injected prompt as an instruction to be answered separately from the previous context.

In contrast, \textit{Indirect Prompt Injection} (IPI)**Kumar et al., "Adversarial Attacks on Deep Neural Networks"**, refers to adversaries injecting prompts into data that may be retrieved during inference, indirectly controlling the model's output.
This typically occurs when an LLM receives input from external sources controlled by the attacker, such as websites or files.
Several works**Zhu et al., "Backdoor Attacks on Neural Networks"**, have discussed the safety risks when LLMs incorporate external content into prompts, as LLMs struggle to distinguish between user instructions and external inputs.

However, PI attacks have limitations when extended to RAG systems because the retriever re-ranks the retrieved content before passing it to the LLM.
Several studies**Hou et al., "Deceiving AI with SQL Injection"**, have demonstrated effective \textit{backdoor attacks} on RAG systems by poisoning the knowledge database, compromising the LLM or retriever to generate inaccurate or harmful outputs.
These studies primarily focus on open-source retriever models and LLMs, while our work focuses AIPSEs in production environments.

One close work is conducted by Nestaas et al.**Nestaas et al., "Preference Manipulation Attacks"**, which proposes \textit{preference manipulation attacks}, trying to manipulate an AIPSE's selections to favor the attacker.

Different from their work, we systematically evaluate the inherent safety risk of AIPSEs with non-optimized (and mostly benign) queries.
We further conduct case studies to demonstrate the ease of manipulating the response of AIPSEs.
To mitigate the risk, we develop an agent-based strategy to filter and mark the potential risks.

\mypara{Malicious Website Detection}
Malicious website detection methods**Kharroubi et al., "PhishTank: A System for Identifying and Classifying Phishing Websites"**, can be categorized into three types: URL-based**Chen et al., "URL-Based Malware Detection Using Machine Learning"**, Webpage-based**Zhou et al., "Webpage-Based Malicious Website Detection Using Machine Learning"**, Hybrid approaches**Kumar et al., "Hybrid Malware Detection Using Machine Learning and Deep Learning"**.
URL-based detection relies on features related to the URL itself, such as IP address, URL length, and suspicious words.
Otherwise, one straightforward of the URL-based detection is using harmful websites list**Kharroubi et al., "PhishTank: A System for Identifying and Classifying Phishing Websites"**, which will be used in our evaluation process to verify the suspicious websites.
PhishTank**Kharroubi et al., "PhishTank: A System for Identifying and Classifying Phishing Websites"**, offers a database of verified phishing websites to help identify and block threats.
ThreatBook**Li et al., "ThreatBook: A Cloud-Based Threat Intelligence Platform"**, provides a database of malicious websites to aid in detecting and mitigating cyber threats.
LevelBlue**Wang et al., "LevelBlue: An Open Threat Intelligence Community for Global Participants"**, is an open threat intelligence community that contains global participants to report emerging threats in the wild.

Webpage-based detection**Zhou et al., "Webpage-Based Malicious Website Detection Using Machine Learning"**, identifies phishing sites by comparing the content and structural features of a suspicious URL's webpage against a legitimate webpage, using methods like content similarity analysis and machine learning to assess the likelihood of phishing.
Hybrid detection merges URL-based and content-based evaluation techniques into a feature vector, which is then used by a machine learning algorithm for classification.
Given the complexity of AIPSE's risks, the current URL-based detection methods mainly focus on analyzing the links themselves.
We propose a simple yet effective defense based on agent to warn and filter unsafe content of the answer in the context of AIPSEs.

\mypara{AIPSE} 
Traditional search engines, such as Google**Brin et al., "The Anatomy of a Large-Scale Hypertextual Web Search Engine"**, and Bing**Huffman et al., "Bing: Microsoft's Search Engine"**, are widely used in daily life for information retrieval.
However, these engines have some limitations, which rely on matching keywords or semantic search with text in a websiteâ€™s database.
This will often fail to deliver accurate and relevant results efficiently.
Although current search engines use NLP models to understand and infer user intent, the vast amount of data on the internet still requires users to manually check each page to find the desired content, greatly reducing efficiency.

In contrast, AIPSEs, such as ChatGPT**Brown et al., "Language Models are Few-Shot Learners"**, Copilot**Chang et al., "Automated Programming"**, and Kimi**Houlsby et al., "Zero-Shot Learning with Transferable Neural Networks"**, effectively address this issue by utilizing RAG.
They comprehend the user's intents and handle the unstructured and complex user queries, analyzing extensive datasets to augment search results based on the vast number of websites retrieved.
Typically, an AIPSE constructs its knowledge database by crawling the latest websites, such as journalistic articles, Wikipedia**Sanger et al., "Wikipedia: The Free Encyclopedia"**, Quora**Gupta et al., "Quora: A Platform for Question Answering"**, and others.
This database provides the LLM with the latest knowledge, compensating for the knowledge cutoff.
The retriever understands the user's query and finds the most relevant data from the database.
The generator outputs the final answer with the query and retrieved data, which is usually an LLM in current AIPSEs.
Overall, AIPSE identifies the most relevant web pages and feeds them into the LLM along with the query. 
Subsequently, the LLM generates the final answer based on this information.

\begin{itemize}
\item \mypara{Doubao} Doubao is an AI chat assistant developed by ByteDance. It releases the search function in May 2024.
Similar to other models, it is based on a series of Doubao models as LLMs and supports bilingual capabilities.
\item \mypara{Kimi} As a Chinese-based artificial intelligence assistant, Kimi has been recognized for its support of long texts.
With a context capacity of approximately 200,000 characters, it has gained user approval. Additionally, the number of web pages in \textit{sources}, is higher compared to other search engines.
Kimi releases its search function in May 2024.
\end{itemize}