Review #888A
===========================================================================

Paper summary
-------------
This paper tries to reevaluate existing defenses against attacks to federated learning. In particular, the paper tries to identify weaknesses in the evaluation of existing defenses.

Strengths / Reasons to accept
-----------------------------
1. The work surveys many existing defenses against untargeted model poisoning attacks to FL.

2. In general, the paper is not hard to follow.

Weaknesses / Reasons to reject
------------------------------
1. This paper is closely related to [43]. In particular, many figures and results from [43] are used as the results/findings of this paper, but [43] is not cited for those results/findings. Given [43] is formally published, the authors may consider citing [43] when the results/findings from [43] are used.

Answer: Cite major results from [43], and try to use different results wherever possible.

2. In pitfall-1, it is recommended that more complex datasets could be used in evaluation. This is very straightforward. Additionally, it is recommended that datasets like FEMNIST and CIFAR10 can be used. Those datasets are also toy datasets as they cannot represent real-world scenarios of FL.

Answer: Re-phrase your recommendation to use FEMNIST and CIFAR10. CIFAR10 is a toy dataset but it should be distributed according to techniques that mimic real world distributions, e.g., Dirichlet Distribution. FEMNIST is a dataset designed for FL specifically so here the reviewers comment is not justified.

3. It is assumed that 20\% of clients are malicious, which is very high. In other words, this setting may not be realistic in the real world for both cross-device and cross-silo FL. As pointed out by the authors, the evaluation of both attacks and defenses heavily relies on the settings. Thus, a systematic evaluation for a different fraction of malicious clients is needed. Same for many other hyperparameters.

Answer: We use 20\% malicious clients to match the settings in the previous papers to compare our results with them.
TODO: Make a graph that shows the impact of varying percentages of malicious clients.

4. Only three defenses are evaluated in Section 5, making the conclusions less convincing. More defenses could be evaluated since the major contribution of this paper is evaluation.

Answer: bruh. read the systemization section.

5. It is unsurprising that attacks are more effective while defenses are less effective for higher data heterogeneity. Additionally, there is always a tradeoff between security and utility. Therefore, it is unclear whether it is possible to develop perfect defenses under high data heterogeneity.

Answer: That is the point we are trying to make. Many defenses are evaluated only under low-heterogeneity/IID settings and they fail under non-iid settings. IID data distribution is extremely non-practical, hence we term this approach a pitfall.


6. The evaluation is limited to untargeted model poisoning attacks, leaving other attacks such as backdoor attacks unexplored.

Answer: We used untargeted model poisoning attacks because they are the strongest.
TODO: Use some targeted attack for your evaluation as well(If time).

In summary, it would be more convincing if the evaluation is conducted on a FL system that is deployed in the real world. Otherwise, it is less convincing which settings are more realistic. Additionally, the evaluation is not very systematic, which may lead to biased conclusions. Finally, results/findings from [43] should be properly cited as [43] is formally published.

Does the paper raise ethical concerns?
--------------------------------------
1. No

Reviewer expertise in this domain
---------------------------------
3. Knowledgeable (I don't necessarily work in this topic domain, but I work
 on related topics or I am cognizant of the work in this domain in recent
 years)

Reviewer confidence
-------------------
3. Quite confident

Overall merit
-------------
1. Reject


* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *


Review #888B
===========================================================================

Paper summary
-------------
This paper is a systematization study of the plethora of defenses that have been proposed against poisoning attacks in federated learning. In particular, the focus is on the pitfalls of defenses against untargeted model poisoning attacks, which modify model parameters in order to lower the test accuracy of the global model. The paper uses 3 defenses (Trimmed Mean, FL Detector and FL Recover) to illustrate salient pitfalls in their evaluation. The experimental evaluation highlights how defense strengths may have been overestimated by not considering a wide range of datasets, client-wise distributions and adaptive attacks. The paper provides recommendations for future evaluation of defenses.

Strengths / Reasons to accept
-----------------------------
- The paper represents a good effort towards unifying the themes that guide the creation of defenses against model poisoning attacks, particularly untargeted ones. The identified pitfalls are useful ones for defenses proposed in the future to be aware of, and the overview provided in Table 1 effectively captures the scope of existing defenses in terms of their actions and knowledge.
- The 3 defenses chosen to illustrate the pitfalls are reasonable, covering different defenses philosophies around direct parameter modification, detection of malicious updates and post-facto restoration of models.
- The proposed adaptive attack on FL Detector is a good attempt at demonstrating how adaptive adversaries can bypass defenses that are not provably robust under practical conditions.

Weaknesses / Reasons to reject
------------------------------
- I think the paper misses a trick by completely ignoring targeted attacks. These present a different challenge for defenses as they are much stealthier, but weaker. In some cases, they may be worse since models could be deployed with ostensibly high performance on the test/validation data but have triggered or triggered backdoors embedded that cause misclassification. It would be very interesting to see if the same pitfalls exist, and if defenses proposed against untargeted attacks are able to tackle the stealthier mode in which targeted attacks operate.

Answer: We used untargeted model poisoning attacks because they are the strongest.
TODO: Use some targeted attack for your evaluation as well(If time).


------------------------------------------------------------------------------------------------------------------------------------------------------------
- While the considered fraction of malicious clients (20\%) is good from the perspective of considering strong attackers, the paper needs to ablate over different malicious client percentages to understand how realistic proposed attacks are, and if stronger attacks are also something the community needs to focus on. While Section 5.4 does consider how FL systems can be intrinsically robust in the cross-device setting, it does not consider powerful attacks that have been proposed in the targeted setting such as Neurotoxin (Zhang et al., ICML 2022), which need far smaller fractions of malicious clients.

Answer: again, we did that to match our results to previous works. how can we compare otherwise?
TODO: perform the percentage of malicious clients ablation.
---------------------------------------------------------------------------DONE-----------------------------------------------------------------------------


- The paper does not consider heterogenity-aware aggregation mechanisms such as agnostic federated learning (Mohri et al., ICML 2019), which account for a diversity of distributions across clients. There are other popular averaging algorithms such as Matched Averaging as well (Wang et al., ICLR 2020) which operate in a layer-wise fashion. For a systemization paper, there needs to be more focus on the aggregation mechanisms used as these will have a large impact on the success of proposed attacks.

TODO: See if you have time to include one of these aggregation mechanisms.

- I found the conclusions in 5.1 and 5.2 to be largely identical, since both revolve around the concern of sufficient heterogenity in benchmark datasets. Also, Section 5.5.2. relies too much on prior knowledge of FLDetector. The paper would benefit from a better description of these defenses that then brings out the novelty of the adaptive attack.

TODO: Re-phrase your findings in these sections.

- One of the defenses considered for a detailed analysis should have been a provable one like CRFL, to see if the assumptions under which they are provably robust hold in practice.

Constructive comments for author
--------------------------------
See Strengths and Weaknesses

Questions for authors’ response
-------------------------------

------------------------------------------------------------------------------------------------------------------------------------------------------------
- Why does the accuracy increase monotonically with the client number in Figure 12?
Answer: It does not monotonically increase. It is sorted in ascending order and then plotted.
---------------------------------------------------------------------(DONE)---------------------------------------------------------------------------------

------------------------------------------------------------------------------------------------------------------------------------------------------------
- Isn’t Pitfall 4 really more of an attack pitfall, since supposedly stronger attacks should consider how effective they are in cross-device settings?
TODO: Re-phrase to clarify that it isn't an attack pitfall.
---------------------------------------------------------------------(DONE)---------------------------------------------------------------------------------

Does the paper raise ethical concerns?
--------------------------------------
1. No

Concerns to be addressed during the revision/shepherding
--------------------------------------------------------
See Strengths and Weaknesses, but overall I think the paper needs more work to come to crisper and more interesting observations about the interaction between attacks and defenses in FL.

Reviewer expertise in this domain
---------------------------------
4. Expert (I've worked on this topic domain or a closely related topic
 domain)

Reviewer confidence
-------------------
4. Confident

Overall merit
-------------
2. Weak reject