% \vspace{-.2cm}
\section{Pitfalls in FL Defense Evaluations}\label{sec:pitfalls}
% \momin{Now that you have more space, write more on each pitfall's grey box.}
% \begin{itemize}
%     \item Go through each pitfall.
%     \item Explain what the pitfall is and how prevalent it is.
%     \item Explain the implications of that pitfall on FL security.
%     \item While explaining implications, use forward references to the impact analysis section
%     \item See if recommendations fit in this section or the impact analysis section
% \end{itemize}
% In this section, we identify six crucial pitfalls of an FL setup for robustness evaluation. After conducting a comprehensive survey of 50 defenses outlined in Table~\ref{tab:defenses}, we systematically correlate each defense strategy with a specific component of FL workflow depicted in Figure~\ref{fig:fl_flowchart}. 
% The pitfalls are presented in Figure~\ref{fig:defense_survey}, showcasing the frequency of choices for each component, shown in the sequential order of their occurrence in the FL workflow.
% We explore each pitfall's prevalence across the 50 works, discuss potential consequences on FL robustness evaluation, and conclude with practical recommendations. Subsequently, in \S\ref{sec:impact}, we thoroughly show the effects of different experimental settings on the performance of FL defenses using our chosen representative defenses TrMean, FLDetector, and FedRecover as case studies.
After presenting the detailed systemization of defenses, it is imperative to unveil critical pitfalls in FL robustness evaluations. By scrutinizing 50 defenses (Table~\ref{tab:defenses} in Appendix), we link each pitfall to specific components in the FL workflow (Figure~\ref{fig:fl_flowchart}). We examine each pitfall's prevalence (Figure~\ref{fig:defense_survey}) across the 50 works, discuss their implications, and conclude with practical recommendations. 
%In \S\ref{sec:impact}, we demonstrate the impact of pitfalls on three representative defenses and how our recommendations help to overcome them.

% \vspace{-0.2cm}
\begin{mybox}
\paragraphb{Pitfall-1: Intrinsically robust datasets.}\label{pitfalls:1}
The chosen datasets are intrinsically robust and lead to incorrect conclusions about a defense's performance.
\end{mybox}
% \vspace{-0.2cm}
\noindent\textbf{Description:}
A designed defense may seem to perform well against specific attacks upon evaluation~\cite{yin2018byzantine}. However, the evaluation dataset might be inherently robust because it is simple and lacks complexity. Therefore, in such situations, we cannot tell if an attack is mitigated due to the inherent robustness of the dataset or the effectiveness of the defense.

\noindent\textbf{Prevalence and implications:}
While it is intuitive that a defense mechanism's performance inevitably varies across datasets, using overly simple datasets like MNIST fails to yield meaningful insights into the true robustness of a defense mechanism, (\S\ref{impact:datasets}). MNIST is a class-balanced dataset used in FL using synthetic techniques such as Dirichlet Distribution~\cite{minka2000estimating}. Conversely, real-world FL tasks are complex and characterized by highly class-imbalanced datasets (\S\ref{impact:distribution:statistical_analyses}).

Despite efforts to create open-source datasets mirroring real-world scenarios~\cite{caldas2018leaf, du2022flamby}, \textbf{\emph{our survey reveals that MNIST remains predominant, constituting 30\% of the  works}~\cite{karimireddy2020byzantine,yin2018byzantine,cao2021provably,wu2020mitigating,li2019rsa,liu2021towards}} (Figure~\ref{fig:defense_survey}a). CIFAR10 and FashionMNIST, though commonly used, lack true FL representation due to their class-balanced nature (\S\ref{impact:distribution:statistical_analyses}). FEMNIST~\cite{caldas2018leaf}, a real-world dataset specifically curated for FL, is used by only $20\%$.
% and works such as~\cite{caldas2018leaf, du2022flamby} have designed open-source datasets representative of real-world datasets. Despite this, we find that MNIST is the most popular dataset in our survey(Figure~\ref{fig:defense_survey}-(a)) as $30\%$ of the works use only MNIST for their evaluations, e.g.,~\cite{karimireddy2020byzantine,yin2018byzantine,cao2021provably,wu2020mitigating,li2019rsa,liu2021towards}, while others report significant results using MNIST~\cite{cao2020fltrust,cao2022fedrecover,li2021byzantine}. CIFAR10 and FashionMNIST are also commonly used, but they are not FL datasets as they are class-balanced and do not represent real-world distributions. Furthermore, the commonly used synthetic methods of converting these into federated datasets still are not the best representation of real-world distributions (\S\ref{impact:distribution:statistical_analyses}). FEMNIST~\cite{caldas2018leaf}, a real-world dataset specifically curated for FL, is used by only $20\%$ of our survey's works.
Another interesting observation from Figure~\ref{fig:defense_survey}a is the \emph{exclusive reliance on image-classification datasets}, despite the popularity of language and vision-language models in contemporary research.

\noindent\textbf{Recommendations:}
Future Evaluations should consider using FL tasks of varying complexities, such as FEMNIST and CIFAR10, for classification and exploring other modalities, such as language, for NLP tasks. In our evaluations in \S\ref{sec:impact} we use image classification datasets, FEMNIST and CIFAR10, 
and a language dataset, StackOverflow, in \S\ref{impact:scalability:stackoverflow} for large-scale FL evaluation.
% \vspace{-0.2cm}
\begin{mybox}
\paragraphb{Pitfall-2: Homogeneous client data distributions.}\label{pitfalls:2}
% Using i.i.d. (homogeneous) distributions with low heterogeneity, which do not encapsulate the complexities of real-world scenarios, may lead to a false perception of system robustness.
Using i.i.d. (homogeneous) distributions with low heterogeneity may create a deceptive sense of system robustness that does not reflect real-world complexities.
\end{mybox}
% \vspace{-0.2cm}
\noindent\textbf{Description:}
Evaluating a defense on a particular dataset may yield perceived robustness due to inherent homogeneity (\S\ref{impact:distribution:statistical_analyses}) in the dataset distribution rather than the efficacy of the defense technique itself. 
% , the observed robustness could stem from the
% underlying homogeneity in the dataset distribution rather than the working of the defense technique itself.
% It is essential to distribute datasets among clients heterogeneously to ensure a more realistic evaluation, particularly when employing class-balanced datasets such as MNIST, FashionMNIST, and CIFAR10. This approach aims to better mimic, at least to some extent, the diversity found in real-world distributions.

\noindent\textbf{Prevalence and implications:}
% We classify a defense based on distribution strategies it uses to generate federated datasets from a centralized dataset, e.g., MNIST and CIFAR10, and observe in Figur~\ref{fig:defense_survey}b that 
We find that \textbf{\emph{around 50\% of the works, use i.i.d. distributed data, despite evidence that it is easier to defend against such distributions}}~\cite{fang2020local,shejwalkar2021manipulating,baruch2019a,zawad2021curse} (as seen in Figure~\ref{fig:defense_survey}b). 
The second most common approach involves a natural data distribution where each sample is associated with a client such as StackOverflow~\cite{stackoverflow}.
Other artificial distributions include \emph{FCJ}~\cite{fang2020local}, \emph{Dirichlet (Dir)}~\cite{bagdasaryan2018how,reddi2020adaptive} and \emph{Mcmahan}~\cite{mcmahan2017communication}.
In \S\ref{impact:distribution:statistical_analyses}, we prove that Dirichlet more closely aligns with real-world distributions, informing our subsequent analysis in \S\ref{impact:distribution} on how defense performance varies with different distributions and levels of heterogeneity.
% we analyze the heterogeneity of FL datasets with these strategies using three statistical measures in Subsequently, in \S\ref{impact:distribution}, we will show that defenses' performance varies with different distributions and varying levels of heterogeneity.\\

\noindent\textbf{Recommendations:}
Future works should prioritize the use of real-world datasets to provide a more realistic evaluation. When working with class-balanced datasets like MNIST, FashionMNIST, and CIFAR10, it is crucial to distribute them among clients heterogeneously. This approach aims to mimic, to some extent, the diversity found in real-world distributions.
% \vspace{-0.5cm}
\begin{mybox}
\paragraphb{Pitfall-3: Slow-converging algorithms.}\label{pitfalls:3}
Evaluations often overlook the use of state-of-the-art, fast-converging algorithms, thereby compromising robustness.
\end{mybox}
% \vspace{-0.3cm}
\noindent\textbf{Description:}
The robustness evaluation of an FL defense may heavily rely on the choice of FL algorithms, such as FedAvg or FedSGD, used in its implementation. 
Using a superior algorithm can enhance system robustness by addressing potential weaknesses in the FL algorithm rather than focusing solely on defense improvement. 

% . This is because the attack might be taking advantage of some underlying weakness in the FL algorithm, and simply using a better algorithm would make the system robust instead of focusing on improving a defense or designing a new one.\\
\noindent\textbf{Prevalence and implications:} 
% We classify the 50 works based on one of the two types of popular FL Algorithms: FedAvg or FedSGD\footnote{TDFL~\cite{xu2022tdfl} work does not mention which FL algorithm they use, but their Algorithms 1 and 2 describing FL uses FedAvg. Hence, we assume they use FedAvg.}.
Despite FedAvg's recognized advantages in performance, faster convergence, and lower communication overhead compared to FedSGD~\cite{mcmahan2017communication}, \textbf{\emph{approximately 40\% of prior works employ the slow-converging FedSGD algorithm for evaluations}} (Figure~\ref{fig:defense_survey}c). This suboptimal choice contributes to a larger window for attacks and results in a more significant accuracy drop (\S\ref{impact:algorithm}).
% FedAvg boasts higher performance, faster convergence, and lower communication than FedSGD, as the clients optimize for multiple local epochs over their data as opposed to a single local epoch in FedSGD, and several works have pointed this out~\cite{mcmahan2017communication,karimireddy2020scaffold}. Even though this performance difference is known, we find that about $40\%$ of prior works use the slow-converging FedSGD algorithm for their evaluations (Figure~\ref{fig:defense_survey}-(c)).\\

\noindent\textbf{Recommendations:}
% Robustness evaluations should use state-of-the-art, fast-converging FL algorithms to assess the robustness of their system. We will show in~\S\ref{impact:algorithm} that the slow-converging nature of FedSGD makes it easier for the attack to work because it gets more time to attack and causes a larger accuracy drop.
Future evaluations should prioritize state-of-the-art, fast-converging FL algorithms to remove any weaknesses (such as slow convergence) associated with the FL algorithm.
% Our analysis in \S\ref{impact:algorithm} demonstrates the detrimental impact of FedSGD's slow convergence on defense effectiveness.
% \vspace{-0.2cm}
\begin{mybox}
\paragraphb{Pitfall-4: Limited FL settings.}\label{pitfalls:4}
Considering only limited scenarios while ignoring practical limitations and factors related to scalability, such as computation, communication, cost, and storage.
\end{mybox}
% \vspace{-0.2cm}
\noindent\textbf{Description:}
The performance of a defense can vary when constrained by real-world limitations, e.g., cost constraints may lead to selecting a very low percentage of malicious clients. Also, the computation, communication, cost, and storage overhead associated with scaling up the system might not be feasible in practical scenarios.


\noindent\textbf{Prevalence and implications:} 
Only $24\%$ of the works in our survey use the cross-device setting (Figure~\ref{fig:defense_survey}d).
As demonstrated by~\cite{shejwalkar2022back} on FEMNIST, CIFAR10, and Purchase datasets with the cross-device setting, using a low percentage of malicious clients due to cost constraints reduces attack performance. We show that on an even larger scale using the naturally distributed Stackoverflow dataset in the cross-device setting, the attack shows \emph{shows no effect on the non-robust mean AGR} (\S\ref{impact:scalability:stackoverflow}). Additionally, defenses that rely on consistent historical information~\cite{zhang2022fldetector, cao2022fedrecover} are incompatible with the cross-device setting (\S\ref{impact:scalability:fdr_fld}) because a client is not selected in every round. We thoroughly discuss the scalability issues of FedRecover and FLDetector in \S\ref{impact:scalability:fdr_fld}.
%comment
% It is important to mention here that this pitfall can be applied to an attack as well, i.e., an attack may be only strong at a very high percentage of malicious clients but fails to achieve a decent success rate at low percentages of malicious clients when constrained by practical limitations. Therefore, a strong attack should also consider how effective they are in cross-device settings. In fact, other defense pitfalls may be applicable to attacks as well, but the focus of this paper is on defenses for now.
 % Additionally, defenses should be scrutinized for their computation and communication cost, especially as the system scales up, involving more clients, training rounds, and using larger models for complex and larger datasets. Our analysis in \S\ref{impact:scalability:fdr_fld} shows the feasibility of deploying such as FedRecover, considering communication, computation, and storage costs.
% , we report our analysis of the communication, computation, and storage cost for
% and comment on the feasibility of deploying such a defense.\\

\noindent\textbf{Recommendations:}
Future evaluations should include deployment conditions of a much larger scale (cross-device) and ensure that the defense provides significant utility compared to the computation and communication cost it incurs.
While we do not label the cross-silo setting as impractical, we emphasize designing defenses that are compatible with the cross-device setting as well. 

% \vspace{-0.2cm}
\begin{mybox}
\paragraphb{Pitfall-5: Naive attacks.}\label{pitfalls:5}
Evaluating defenses solely against simple and naive attacks rather than incorporating strong state-of-the-art attacks makes a defense seem robust.
\end{mybox}
% \vspace{-0.2cm}
\noindent\textbf{Description:} 
The true robustness of a defense emerges when tested against strong and adaptive attacks, i.e., attacks tailored for a defense algorithm. Relying on attacks known to be weak and naive for evaluating a new defense will not give us a true picture of the defense's robustness.

\noindent\textbf{Prevalence and implications:} 
Figure~\ref{fig:defense_survey}e shows the frequency of various attacks used in our survey.
Despite the existence of several strong poisoning attacks in the literature~\cite{shejwalkar2021manipulating,fang2020local,xie2019fall,baruch2019a, wang2020attack}, our analysis reveals that \textbf{\emph{about 40\% of the works opt for simplistic approaches}} such as random Gaussian~\cite{blanchard2017machine}, label flipping~\cite{li2021ditto}, sign flipping~\cite{li2019rsa}, bit flipping~\cite{xie2018generalized}), even though prior works have shown their poor performance even under strong adversarial settings~\cite{shejwalkar2022back,fang2020local,li2019rsa,praneeth2020learning}.
% Ideally, defenses should consider multiple strong attacks for their evaluations. However, approximately $95\%$ of the surveyed works do not evaluate against state-of-the-art attacks such as~\cite{shejwalkar2021manipulating, wang2020attack}.
We discuss the impact of this pitfall extensively in~\S\ref{impact:attacks} by using state-of-the-art attacks, and in \S\ref{impact:attacks:fld}, we design our own adaptive attack against FLDetector. Our impact analysis reveals that this is one of the most crucial components of FL evaluation.

\noindent\textbf{Recommendations:}
To correctly evaluate the robustness of a defense, one should use 1) strong adaptive attacks that are tailored to the defense algorithm and maximally reduce its performances and 2) strong state-of-the-art attacks from existing literature.
\begin{figure*}[t]
    \begin{subfigure}{0.24\textwidth}
        \centering
    \includegraphics[width=1.05\linewidth]{figures/baseline_mnist.pdf}
        % \vspace{-0.7cm}
        \caption{MNIST}
        \label{fig:baseline_mnist}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.24\textwidth}
        \centering
        \includegraphics[width=\linewidth]{figures/baseline_fashion.pdf}
        % \vspace{-0.7cm}
        \caption{FashionMNIST}
        \label{fig:baseline_fashion}
    \end{subfigure}
    \begin{subfigure}{0.24\textwidth}
        \centering
        \includegraphics[width=\linewidth]{figures/baseline_cifar.pdf}
        % \vspace{-0.7cm}
        \caption{CIFAR10}
        \label{fig:baseline_cifar}
    \end{subfigure}
    \begin{subfigure}{0.24\textwidth}
        \centering
        \includegraphics[width=\linewidth]{figures/baseline_femnist.pdf}
        % \vspace{-0.7cm}
        \caption{FEMNIST}
        \label{fig:baseline_femnist}
    \end{subfigure}
    % \vspace{-0.3cm}
    \caption{Comparative analysis of TrMean AGR with FedSGD and FedAvg under trim attack. TrMean is more susceptible to poisoning with FedSGD due to slow convergence, which gives adversaries more time for poisoning (threat model in~\S\ref{background:threat_model})}
    % \vspace{-0.4cm}
\label{fig:fl_baseline}
\end{figure*}
\begin{mybox}
\paragraphb{Pitfall-6: Unfair metrics.}\label{pitfalls:6}
Not capturing clients' performances separately and only reporting global accuracy metrics does not give a good measure of per-client robustness.
\end{mybox}
% \vspace{-0.2cm}
\noindent\textbf{Description:}
Data heterogeneity across clients in practical FL systems results in varying performance across clients. This phenomenon is also known as \textit{representation disparity}~\cite{hashimoto2018fairness}. Global accuracy does not give us any idea of the individual performances of clients.
In addition to this, real-world datasets are class imbalanced~\cite{caldas2018leaf} as opposed to synthetic datasets such as MNIST and CIFAR10. The commonly reported overall accuracy metric lacks information on per-class performance.\\
\noindent\textbf{Prevalence and implications:}
% We classify papers into two categories of evaluation type: global and personalized, where global refers to papers that consider the accuracy of the global model for their evaluation, whereas personalized refers to the papers that consider accuracy on a per-client basis.
Despite heterogeneity being a well-known issue, only $4\%$ of the surveyed works incorporate personalized evaluations (Figure~\ref{fig:defense_survey}f).
Our per-client analysis of TrMean and FedRecover demonstrates that per-client performances vary a lot, highlighting the need to account for these variations in real-world FL systems (\S\ref{impact:evaluation}). We also highlight the importance of reporting per-class accuracies, as we show that the overall accuracy is a misleading metric (\S\ref{impact:evaluation:imbalance}).

\noindent\textbf{Recommendations:}
Future evaluations should include personalized evaluations along with global evaluations to capture the variation in clients' performances. In addition to this per-client evaluation, future works should also report per-class performance, especially when using class-imbalanced datasets.

