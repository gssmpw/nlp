\section{Systemization of Defenses Against  FL Poisoning}\label{sec:systemization}
Here, we introduce a systematization for FL defenses and use it to
rationalize the selection of three representative defenses from the literature. Later, 
in \S\ref{sec:impact}, we use these chosen defenses to conduct a comprehensive impact analysis of the pitfalls outlined in \S\ref{sec:pitfalls}.
% we use these three defenses in \S\ref{sec:impact} to perform an impact analysis of the pitfalls in \S\ref{sec:pitfalls}.
% \vspace{-0.2cm}
\subsection{Classification of Defenses}\label{systemization:classification}
Here, we present the three key dimensions along which we classify FL defenses in literature, as shown in Table~\ref{tab:systemization}. In Figure~\ref{fig:defenses_systemization}, we group defenses according to the third dimension, i.e., \emph{defense phase}, and highlight their dependencies. 

% \newline
% It is essential to mention here that there could be more attributes for the dimensions in the table, and our table is expandable. For example, we found FedRecover to be the only estimation-based recovery mechanism in the literature, and we would not have the \emph{estimation} attribute in our table before FedRecover. This expandability of our systemization will help researchers design new defenses, as it highlights the under-represented categories of defenses and shows the potential for future innovation. Next, we explain the dimensions of our systemization in great detail.
% \noindent\textit{1) Update operation:}
% \vspace{-0.2cm}
\subsubsection{Processing of client updates}\label{systemization:classification:operation}
Client model updates undergo several processing steps before they are aggregated at the server. The commonly used processing operations are:

\noindent\textbf{Filtering updates} 
% This processing operation aims 
to entirely or partially eliminate local updates. \emph{Filtering} defenses fall into two main categories: 
those based on the values of local model updates, termed \emph{update-based filtering}~\cite{yin2018byzantine, blanchard2017machine, pillutla2019robust}, and those relying on some metrics associated with local models, known as \emph{metric-based filtering}~\cite{ranjan2022securing, jebreel2022defending, fang2020local, zhang2022fldetector}.

\begin{enumerate}[leftmargin=*, label=\alph*), wide]
% \begin{itemize}
    \item \emph{Update-based filtering ~\cite{yin2018byzantine, blanchard2017machine, pillutla2019robust}} is based on the values of local model updates. It further divides into \emph{dimension-wise} and \emph{vector-wise} filtering. Dimension-wise filtering defenses, such as TrMean~\cite{yin2018byzantine} and Median~\cite{yin2018byzantine}, filter out malicious values along each update dimension, while vector-wise filtering defenses, such as, Krum~\cite{blanchard2017machine}, remove entire malicious updates.
    \item \emph{Metric-based filtering~\cite{ranjan2022securing, jebreel2022defending, fang2020local, zhang2022fldetector}} relies on some metrics associated with local models, e.g., FLDetector~\cite{zhang2022fldetector} uses a \emph{suspicious score} as the metric to identify and remove malicious clients from the training process. We describe FLDetector in detail in \S\ref{systemization:defenses_study:descriptions}. In \emph{loss-based rejection}~\cite{fang2020local}, the loss associated with and without incorporating an update for aggregation is calculated, and updates with higher loss are removed. Similarly, \emph{error-based rejection}~\cite{fang2020local} removes updates by assessing the error instead of the loss.
% \end{itemize}
\end{enumerate}

\noindent\textbf{Update re-weighing} 
% The defense type 
involves assigning a weight to each local update, reflecting its perceived level of maliciousness. Various re-weighting approaches exist, including:
% \red{write the defenses you want and then go to next line and explain. these linebreak are incorrect. OR you can say "Various re-weighting approaches exist as follows."}:
\begin{enumerate}[leftmargin=*, label=\alph*), wide]
    \item \emph{Similarity-based re-weighting~\cite{awan2021contra, cao2020fltrust}} is shown by FLTrust~\cite{cao2020fltrust}, where the server assigns a trust score to each client based on the similarity of its updates to the server's update, computed on a small dataset.
    \item \emph{Loss-based re-weighting~\cite{park2021sageflow, li2020learning}} illustrated by Sageflow~\cite{park2021sageflow}, involves the server assigning a weight to each update based on local model loss on a small dataset at the server.
    \item \emph{Optimization-based re-weighting} is demonstrated by SmartFL~\cite{xie2022robust}, which assigns weights through an optimization problem with the same number of parameters as that of clients.
\end{enumerate}
% \vspace{-0.1cm}
\noindent\textbf{Update Modification} changes the update itself to safeguard the global model from the impact of malicious updates. The key techniques within this approach are:
\begin{enumerate}[leftmargin=*, label=\alph*), wide]
    \item \emph{Scaling Updates} limits a local update by clipping it if it exceeds a certain threshold, for example, defenses like Norm-bounding~\cite{sun2019can, xu2021signguard}.
    \item \emph{Distilling update knowledge~\cite{chang2019cronus, shen2016auror}} is another facet of update modification that involves avoiding the transmission of the entire local model update to the server due to the \emph{curse of dimensionality}~\cite{chang2019cronus}, which increases the risk of higher impact from poisoning attacks. Instead, clients send distilled information to the server. In Cronus~\cite{chang2019cronus}, clients send soft labels to the server, and the aggregate is used to update local models. This defense mitigates the risk of poisoning attacks and directly prevents whitebox inference attacks, as the server cannot access the local model parameters.
    \item \emph{Regularization} defenses perform regularization to achieve personalized~\cite{hanzely2020federated, hanzely2020lower} client models. An example is Ditto~\cite{li2021ditto}, which modifies the local training objective by introducing a regularization term to control the tradeoff between privacy and robustness of the local model.
    \item \emph{Estimation} is exemplified by FedRecover~\cite{cao2022fedrecover}, which leverages past information and estimation to recover the unpoisoned global model. We discuss the mechanism of FedRecover in detail in \S\ref{systemization:defenses_study:descriptions}.
\end{enumerate}
% \vspace{-0.3cm}
% \noindent\textit{2) Server's Knowledge:}
\subsubsection{Server's Knowledge}\label{systemization:classification:knowledge}
The defense is generally applied at the server, where it collects all local updates and strives to obtain the best possible global model that is least affected by malicious updates. The server's knowledge varies across different defenses and can be described in terms of data and local model updates:

\noindent\textbf{Knowledge of Data:} 
In the \emph{no-knowledge} setting~\cite{yin2018byzantine, cao2022fedrecover, zhang2022fldetector, chang2019cronus}, as the name suggests, the server lacks information about the data used for training and testing. It only possesses knowledge of the collected local model updates, examples of which include TrMean~\cite{yin2018byzantine}, Krum~\cite{blanchard2017machine}, and Median~\cite{yin2018byzantine}. Conversely, in the \emph{partial-knowledge} setting~\cite{park2021sageflow, xie2022robust, cao2020fltrust}, the server possesses a small dataset, which it deploys in various ways, such as calculating entropy associated with updates~\cite{park2021sageflow} or assigning a trust score to each client~\cite{cao2020fltrust} to enhance aggregation robustness against attacks.
\begin{figure*}[t]
\centering
\includegraphics[width=.97\linewidth]{figures/defenses_survey_donuts.pdf}
% \vspace*{-.2cm}
\caption{Frequency of choices of the six key components of robustness evaluation setup: dataset, distribution of clients' data, FL algorithm, FL type, attacks, and evaluation. \S~\ref{sec:impact} discusses the impacts of choices on the robustness of FL poisoning defenses.}
\label{fig:defense_survey}
% \vspace*{-.5cm}
\end{figure*}

\noindent\textbf{Knowledge of Local Model Updates:} 
In the \emph{full-knowledge} setting~\cite{cao2022flcert, blanchard2017machine, li2020learning}, the server has complete access to the model parameters of all clients, representing the widely used scenario. In the \emph{partial-knowledge}, or \emph{distilled-knowledge} setting~\cite{shen2016auror, chang2019cronus}, the server only has access to some distilled form of the model parameters, such as the output layers~\cite{chang2019cronus}.
% \vspace{-0.3cm}
% \noindent\textit{3) Defense Phase:}
\subsubsection{Defense Phase}\label{systemization:classification:phase}
We categorize defenses based on the training \emph{phase}, specifying when and where in the training pipeline the defense is applied.

\noindent\textbf{Aggregation-based} defenses are applied during the aggregation phase. These defenses can be further categorized into \emph{pre-aggregation} \cite{ranjan2022securing, mhamdi2018the, yin2018byzantine, blanchard2017machine, park2021sageflow} defenses that perform processing of client updates such as dimension-wise filtering before aggregating updates, or \emph{post-aggregation}~\cite{cao2022flcert, fang2020local, cao2021provably} defenses, e.g., Ensemble FL~\cite{cao2021provably} that creates all possible aggregations of k models from N clients, then selects the most frequent predicted label as the correct one.

\noindent\textbf{Non-aggregation-based} defenses that are not performed at aggregation can be further categorized based on their \emph{phase}:
\begin{enumerate}[leftmargin=*, label=\alph*), wide]
    \item \emph{During Local Training:}~\cite{zhang2022flip, li2021ditto, chang2019cronus} The defense takes place at the client's side during local training. For instance, Ditto~\cite{li2021ditto} uses regularization in client training to control the deviation of benign local models from poisoned global models.
    \item \emph{Post-Training:} FedRecover~\cite{cao2022fedrecover}, employing a recovery-based mechanism, falls into this category as it requires historical information from one training session to estimate the un-poisoned global model during the \emph{recovery} phase.
\end{enumerate}
% \vspace{-0.3cm}


\subsection{Our Selected Case Study Defenses}\label{systemization:justification}

We choose three defenses for brevity to analyze the impact of pitfalls in \S\ref{sec:impact}; TrMean, FLDetector, and FedRecover. We first provide each of their descriptions and then give a detailed justification for choosing them for our impact analysis.

\subsubsection{Descriptions of our chosen defenses}\label{systemization:defenses_study:descriptions}
\paragraphb{Trimmed Mean (\emph{TrMean})}~\cite{yin2018byzantine}
\label{background:trmean}
is a foundational defense used in advanced defenses~\cite{cao2022fedrecover,zhang2022fldetector,shejwalkar2021manipulating}. It sorts each input dimension $j$ of the client updates, discards the $m$ largest and smallest values (where $m$ indicates compromised clients), and averages the rest.

\paragraphb{FLDetector~\cite{zhang2022fldetector}}\label{background:fld}
is designed to \emph{detect} and eliminate malicious clients, ensuring a byzantine-robust FL system obtains a precise global model. FLDetector operates on the principle that malicious updates, tainted by adversaries, differ statistically from benign ones.


For discerning these updates, the server estimates a global model update for client $k$ at round $t$ using the L-BFGS algorithm: ($\hat{\nabla}_{t}^{k} = \nabla_{t-1}^{k} + \hat{H}^{t}\cdot(\theta_{t} - \theta_{t-1})$). Here, $\nabla_{t-1}^{k}$. The server retains past $N$ global model differences ($\Delta \theta_{t}$) and updates differences ($\Delta \nabla_{t-1}$) to compute the \emph{HVP (Hessian Vector Product)} with \emph{L-BFGS}. It then gauges a client's \emph{suspicious score} by comparing actual and predicted updates through their Euclidean distance. With scores from the last $N$ rounds, clients are clustered via Gap statistics~\cite{tibshirani2001estimating} and K-means. The group with higher average scores is deemed malicious. Upon detecting a rogue client, the server ceases training, removes the offender, and restarts training to achieve enhanced accuracy.

\paragraphb{FedRecover~\cite{cao2022fedrecover}}\label{background:fdr}
aims to \emph{recover} an FL global model compromised by a poisoning attack. In the \emph{original training phase}, for each round $t$, FedRecover saves $\nabla^k_t$ from client $k$ and global models $\theta^t_g$. This data is used as \emph{historical information} in the \emph{recovery phase}, which consists of the following stages.
In the \emph{warmup phase}, the server requests clients' \emph{exact updates} for the initial $T_w$ rounds. In the \emph{estimation phase}, the server \emph{estimates} client updates each round, with $\hat{\nabla}^t_k$\ representing client $k$'s estimated update at round $t$. This estimate is derived using the L-BFGS algorithm~\cite{nocedal1980updating} based on the original global model, client update, and recovered global model. The model's estimated update is defined as $\hat{\nabla}^k_t = \overline{\nabla}^t_k + \Tilde{H}^t_k(\hat{\theta}^t_g - \overline{\theta}^t_g)$, where the latter term is the HVP(Hessian Vector Product).
Every $T_c$ rounds, to ensure the estimated global model $\hat{\theta}^t_g$ aligns closely with the accurate model, the server initiates a \emph{periodic correction} by requesting \emph{exact updates}. If any component of a client's estimated update surpasses the \emph{abnormality threshold} $\tau$, that client is prompted for an exact update.
In the final \emph{fine-tuning phase}, spanning $T_f$ rounds, clients are asked to provide their exact updates,$\nabla^t_k$, to refine the global model by eliminating potential estimation errors.



\subsubsection{Justification for our choice of representative defenses}\label{systemization:defenses_study:justification}
We justify that the chosen defenses are distinct along the dimensions in Table~\ref{tab:systemization}.
TrMean~\cite{yin2018byzantine} is a \textbf{\emph{pre-aggregation, update-based filtering}} defense that removes malicious components of client updates dimension-wise during training. FLDetector~\cite{zhang2022fldetector} is a \textbf{\emph{pre-aggregation, metric-based filtering}} defense designed to detect and remove malicious clients during training by analyzing their updates. The metric FLDetector uses is the \emph{suspicious score}, which measures the consistency between the actual update and an estimated one. It is important to note that although TrMean and FLDetector seem similar in their filtering mechanisms, they are different and have distinct approaches. TrMean filters \emph{components} of updates before aggregating them, while FLDetector removes entire \emph{clients} from the training process if they deviate too much from an estimated reference update, which is calculated using historical information. FedRecover~\cite{cao2022fedrecover} is a \textbf{\emph{post-training, update modification}} defense that uses \emph{estimation} to \emph{recover} from a previously poisoned global model. It is an advanced defense that uses TrMean in its aggregation phase and relies on a detection mechanism to remove malicious clients before it starts the recovery process. In \S\ref{impact:datasets:fdr} and \S\ref{impact:attacks:fdr}, we show the performance of FedRecover when we perform Stat-Opt on TrMean and FLDetector, respectively.

All three defenses do not require any auxiliary dataset at the server, and we prefer this setting because the server might not have access to the dataset in practical, real-world scenarios. Similarly, we prefer the \emph{full-knowledge} of client updates scenario, as most of the works~\cite{cao2022flcert, blanchard2017machine, li2020learning, li2021ditto, park2021sageflow, cao2020fltrust} use this setting, and it leads to a stronger adversarial setting. Although the server in all three of our chosen defenses has full knowledge of the client model updates, the defenses differ in the amount of historical information needed. Figure~\ref{fig:defenses_systemization} clearly shows these different dependencies. TrMean does not require model updates from the past rounds and performs filtering using client model updates of the current round. FLDetector requires updates from the past \emph{few} rounds and uses them to calculate the malicious score for updates in the current round. Since FedRecover is a post-training defense, it requires updates from all the rounds in the original training. Therefore, the volume of updates required is highest for FedRecover and lowest for TrMean.

% Figure~\ref{fig:defenses_systemization} clearly shows\red{not really; we use the figure 2 to show how chosen defenses are representitive of different categories/dimensions/strategy.} the different nature of our chosen defenses. Trimmed Mean and FLDetector are both pre-aggregation mechanisms but have different dependencies. Trimmed Mean requires only the client model updates of the current FL round, whereas FLDetector requires past updates as well. FedRecover has a more complex mechanism, as it requires past updates for estimation and uses Trimmed Mean and FLDetector in the pre-aggregation phase to make aggregation robust. Next, we describe the three defenses in detail.



% \subsubsection{Descriptions of our chosen defenses}\label{systemization:defenses_study:descriptions}
% \red{you can move this to appendix if after moving other things there is still any space issue.}
% \noindent \textbf{Trimmed Mean (\emph{TrMean})}~\cite{yin2018byzantine}
% \label{background:trmean}
% is a foundational defense used in advanced defenses~\cite{cao2022fedrecover,zhang2022fldetector,shejwalkar2021manipulating}. It sorts each input dimension $j$ of the client updates, discards the $m$ largest and smallest values (where $m$ indicates compromised clients), and averages the rest.

% \paragraphb{FLDetector~\cite{zhang2022fldetector}}\label{background:fld}
% is designed to \emph{detect} and eliminate malicious clients, ensuring a byzantine-robust FL system obtains a precise global model. FLDetector operates on the principle that malicious updates, tainted by adversaries, differ statistically from benign ones.\\
% For discerning these updates, the server estimates a global model update for client $k$ at round $t$ using the L-BFGS algorithm: ($\hat{\nabla}_{t}^{k} = \nabla_{t-1}^{k} + \hat{H}^{t}\cdot(\theta_{t} - \theta_{t-1})$). Here, $\nabla_{t-1}^{k}$. The server retains past $N$ global model differences ($\Delta \theta_{t}$) and updates differences ($\Delta \nabla_{t-1}$) to compute the \emph{HVP (Hessian Vector Product)} with \emph{L-BFGS}. It then gauges a client's \emph{suspicious score} by comparing actual and predicted updates through their Euclidean distance. With scores from the last $N$ rounds, clients are clustered via Gap statistics~\cite{tibshirani2001estimating} and K-means. The group with higher average scores is deemed malicious. Upon detecting a rogue client, the server ceases training, removes the offender, and restarts training to achieve enhanced accuracy.

% \paragraphb{FedRecover~\cite{cao2022fedrecover}}\label{background:fdr}
% aims to \emph{recover} an FL global model compromised by a poisoning attack. In the \emph{original training phase}, for each round $t$, FedRecover saves $\nabla^k_t$ from client $k$ and global models $\theta^t_g$. This data is used as \emph{historical information} in the \emph{recovery phase}, which consists of the following stages.
% In the \emph{warmup phase}, the server requests clients' \emph{exact updates} for the initial $T_w$ rounds. In the \emph{estimation phase}, the server \emph{estimates} client updates each round, with $\hat{\nabla}^t_k$\ representing client $k$'s estimated update at round $t$. This estimate is derived using the L-BFGS algorithm~\cite{nocedal1980updating} based on the original global model, client update, and recovered global model. The model's estimated update is defined as $\hat{\nabla}^k_t = \overline{\nabla}^t_k + \Tilde{H}^t_k(\hat{\theta}^t_g - \overline{\theta}^t_g)$, where the latter term is the HVP(Hessian Vector Product).
% Every $T_c$ rounds, to ensure the estimated global model $\hat{\theta}^t_g$ aligns closely with the accurate model, the server initiates a \emph{periodic correction} by requesting \emph{exact updates}. If any component of a client's estimated update surpasses the \emph{abnormality threshold} $\tau$, that client is prompted for an exact update.
% In the final \emph{fine-tuning phase}, spanning $T_f$ rounds, clients are asked to provide their exact updates,$\nabla^t_k$, to refine the global model by eliminating potential estimation errors.
