% This work started off as a paper at the DLSP workshop at IEEE S\&P 2023. There we initiated the identification of FL pitfalls in FL defenses and used FedRecover as a case study to assess the impact of four pitfalls.
% The DLSP paper was the first step in the direction of this paper, where we identify two more pitfalls, and use another SOTA defense FLDetector as a case study. Here, before diving into the pitfalls and their prevention, we found it important to first classify defenses according to their working mechanisms so that it becomes easier to understand the choice of our defense mechanism selection. It also makes a natural transition from systemization to pitfalls because in systemization we thoroughly explain how different defenses work and how they are different from each other. We then proceed to pitfalls and their impact analysis in the paper. In this paper, we not only perform a lot more experiments but also a much more extensive analysis of pitfalls, their impact, and our recommendations. We also include a large-scale evaluation using the very large StackOverflow dataset, something which the workshop paper lacked. Using StackOverflow also helped us expand our study into the language domain, as the workshop paper only had image datasets and models. The difference in scope of evaluation and analysis is clearly evident by the number of figures in both papers. The workshop paper has 5 figures, while this paper has 15. The overlap that exists between the two papers is because this paper builds upon the previous one and we had to use the first four pitfalls in our current study as well. Therefore, we performed more experiments and analysis with the first four pitfalls, while also including two new pitfalls.



Dear Editor-in-chief,

We are submitting our manuscript for consideration for publication in ACM Transactions on Privacy and Security (TOPS). This work builds upon our earlier workshop paper presented at the IEEE DLSP Workshop at IEEE S\&P 2023. While the workshop paper provided an initial exploration of pitfalls in Federated Learning (FL) defenses using FedRecover as a case study, the current journal submission significantly expands both the scope and depth of our investigation.

In our workshop paper, we identified and analyzed the impact of four key pitfalls. The current paper not only revisits these pitfalls with additional experiments and in-depth analysis but also identifies two new pitfalls, thereby extending the conceptual framework. Furthermore, we introduce a novel systemization for FL defenses based on their working mechanisms, providing a systematic perspective that aids in understanding the rationale behind our choice of defense mechanisms. This systemization forms a natural progression into our expanded study of pitfalls and their prevention.

A significant enhancement in this work is the scale and diversity of evaluation. Unlike the workshop paper, which focused exclusively on image datasets and models, the present study includes a large-scale evaluation using the StackOverflow dataset. This addition allows us to extend our analysis to the language domain, demonstrating the broader applicability of our findings. The difference in scope is also reflected in the volume of results and visualizations: the workshop paper included 5 figures, whereas the current submission contains 15 figures to comprehensively present our findings.

The overlap between the two papers arises naturally from the progression of the research, as we revisit the initial four pitfalls in light of new experiments and integrate them into the broader framework developed in this submission. This overlap is limited to foundational aspects that were essential to build upon and is complemented by the substantial new contributions in this paper.

We believe that the manuscript represents a significant advancement over the workshop paper and will be of interest to the readership of ACM TOPS. We have ensured that all necessary citations to the prior work are included.

Thank you for considering our submission. We look forward to the possibility of contributing to ACM TOPS.

Sincerely,
Authors