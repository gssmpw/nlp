@article{feldman2020does,
    title   = {Does Learning Require Memorization? A Short Tale about a Long Tail},
    author  = {Feldman, Vitaly},
    journal = {arXiv preprint arXiv:1906.05271},
    year    = {2020}
}

@article{gekhman2024does,
    title   = {Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?},
    author  = {Gekhman, Zorik and Yona, Gal and Aharoni, Roee and Eyal, Matan and Feder, Amir and Reichart, Roi and Herzig, Jonathan},
    journal = {arXiv preprint arXiv:2402.04333},
    year    = {2024}
}

@inproceedings{kalai2024calibrated,
  title     = {Calibrated Language Models Must Hallucinate},
  author    = {Kalai, Adam Tauman and Vempala, Santosh S.},
  booktitle = {Proceedings of the 56th Annual {ACM} Symposium on Theory of Computing (STOC)},
  year      = {2024}
}

@article{kang2023unfamiliar,
    title   = {Unfamiliar Finetuning Examples Control How Language Models Hallucinate},
    author  = {Kang, Katie and Wallace, Eric and Tomlin, Claire and Kumar, Aviral and Levine, Sergey},
    journal = {arXiv preprint arXiv:2310.01848},
    year    = {2023}
}

