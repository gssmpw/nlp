\appendix  % This declares the start of the appendix section
\onecolumn  % Ensure single column layout
\section{Appendix}  % The title of the appendix section comes first
% \begin{table}[!htbp]
% \vspace{0.1in}
% \caption{Number of Bins in $g$ ($\epsilon = 0$)}
% \vspace{0.1in}
% \label{mono-bin-table}
% % \vskip 0.15in
% \begin{center}
% \begin{small}
% \begin{sc}
% \begin{tabular}{lcc}
% \toprule
% Monofact Rate (\%) & Number of Bins \\
% \midrule
% 6.7 & 75 \\
% 14.6 & 120 \\
% 32.1 & 265 \\
% 55.3 & 385 \\
% 69.4 & 455 \\
% 73.5 & 425 \\
% 75.0 & 455 \\
% 82.5 & 430 \\
% \bottomrule
% \end{tabular}
% \end{sc}
% \end{small}
% \end{center}
% \vspace{0.1in}
% \end{table}

% \begin{figure*}[!htbp]
%     \centering
%     \includegraphics[width=\textwidth]{icml2025/images/distributions_grid.png}
%     \caption{Visual comparison of fact repetition frequencies for four probability distributions—Pareto, Zipf, Normal, and Poisson—across varying parameters. Each subplot shows how often a fact appears (x-axis) versus how many facts have that appearance count (y-axis, log scale).}
%     \label{fig:distributions}
% \end{figure*}


% \begin{figure*}[!htbp]
%    \centering
%    \includegraphics[width=\textwidth]{icml2025/images/zipf.png}
%    \caption{Experiments with Zipf distributions. Left: Relationship between mono-fact rates and hallucination rates. Right: Effect of varying the shape parameter ($\rho$) on monofact rates.}
%    \label{fig:zipf}
% \end{figure*}

% \begin{figure*}[!htbp]
%     \centering
%     \includegraphics[width=\textwidth]{icml2025/images/poisson.png}
%     \caption{Experiments with Poisson distributions. Left: Relationship between mono-fact rates and hallucination rates. Right: Effect of varying the parameter ($\lambda$) on monofact rates, where higher $\lambda$ values indicate higher distributional means.}
%     \label{fig:poisson}
% \end{figure*}

% \begin{figure*}[!htbp]
%     \centering
%     \includegraphics[width=\textwidth]{icml2025/images/comparison_miscal_mono.png}
%     \caption{Relationship between miscalibration and mono-fact rates for Pareto and Zipf distributions, showing that lower mono-fact rates consistently correspond to lower miscalibration scores prior to intervention.}
%     \label{fig:miscal}
% \end{figure*}

% \begin{figure*}[!htbp]
% \centering
% \includegraphics[width=\textwidth]{icml2025/images/miscalibration_final.png}
% \caption{Relationship between miscalibration (blue line, left y-axis) and hallucination rates (red line, right y-axis) for select Pareto shape parameters $\gamma$ holding monofact constant. Dotted lines indicate metrics prior to any intervetions. Each subplot shows how miscalibration and hallucination evolve as we duplicate token occurence for more and more statements from the training data (size of 5,000).
% }
% \label{fig:miscalibration}
% \end{figure*}

% \begin{figure*}[!htbp]
%     \centering
%     \includegraphics[width=\textwidth]{icml2025/images/gemini_binned_boxplot_normal.png}
%     \caption{Distribution of hallucination rates as a function of monofact rate and $\mu$ and $\delta$ = 1/2 *  $\mu$. Each box plot shows the distribution of hallucination rates across 100 iterations.}
%     \label{fig:gemini_normal_boxplot}
% \end{figure*}


% \begin{algorithm}[tb]
% \sloppy
% \caption{Controlled Miscalibration via Sample Upweighting}
% \label{alg:miscal}
% \begin{algorithmic}[1]
% \STATE \textbf{Input:}
% \STATE \quad Original bigram model $M$ with transition counts trained on $S$
% \STATE \quad Training examples ${x_1,\ldots,x_n} \in S$
% \STATE \quad Number of examples to upweight, as indicated by $k$
% \STATE \textbf{Output:} Updated model $M'$ with upweighted transitions
% \STATE Initialize $M'$ as a copy of $M$
% \FOR{$i = 1$ \textbf{to} $k$}
% \STATE $\text{tokens} \leftarrow \text{Tokenize}(x_i)$
% \IF{$\text{len(tokens)} \geq \text{order}$}
% \STATE $\text{start} \leftarrow \text{tokens[1:order]}$
% \STATE $M'{\text{initial}}[\text{start}] \leftarrow M'{\text{initial}}[\text{start}] + 1$
% \FOR{$j = 0$ \textbf{to} $\text{len(tokens)} - \text{order}$}
% \STATE $\text{current} \leftarrow \text{tokens}[j:j+\text{order}]$
% \STATE $\text{next} \leftarrow \text{tokens}[j+\text{order}]$
% \STATE $M'{\text{trans}}[\text{current}][\text{next}] \leftarrow M'{\text{trans}}[\text{current}][\text{next}] + 1$
% \ENDFOR
% \ENDIF
% \ENDFOR
% \STATE Normalize all transition probabilities and initial state probabilities in $M'$ by calling Algorithm \ref{alg:subroutine}
% \STATE \textbf{Return} $M'$
% \end{algorithmic}
% \end{algorithm}


% \begin{algorithm}
% \sloppy
% \caption{Bigram Model Update Subroutine}
% \label{alg:subroutine}
% \begin{algorithmic}[1]
%     \STATE \textbf{Input:}
%     \STATE \quad $initial\_probs$: Dictionary of initial state probabilities
%     \STATE \quad $transitions$: Dictionary of transition probabilities \{state: \{next\_state: probability, ...\}, ...\}
%     \STATE \textbf{Output:}
%     \STATE \quad Normalized $initial\_probs$ and $transitions$
%     \STATE \textbf{Procedure:}
%     \STATE \textbf{1. Normalize Initial Probabilities}
%     \STATE \quad $init\_total \gets \sum_{state} initial\_probs[state]$
%     \FOR{each $state$ in $initial\_probs$}
%         \STATE $initial\_probs[state] \gets initial\_probs[state] / init\_total$
%     \ENDFOR
%     \STATE \textbf{2. Normalize Transition Probabilities}
%     \FOR{each $state$ in $transitions$}
%         \STATE $transition\_total \gets \sum_{next\_state} transitions[state][next\_state]$
%         \FOR{each $next\_state$ in $transitions[state]$}
%             \STATE $transitions[state][next\_state] \gets transitions[state][next\_state] / transition\_total$
%         \ENDFOR
%     \ENDFOR
%     \STATE \textbf{Return} $initial\_probs$, $transitions$
% \end{algorithmic}
% \end{algorithm}