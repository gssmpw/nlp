@inproceedings{Muhammad2025AfriHateAM,
  title={AfriHate: A Multilingual Collection of Hate Speech and Abusive Language Datasets for African Languages},
  author={Shamsuddeen Hassan Muhammad and Idris Abdulmumin and Abinew Ali Ayele and David Ifeoluwa Adelani and Ibrahim Said Ahmad and Saminu Mohammad Aliyu and Nelson Odhiambo Onyango and Lilian D. A. Wanzare and Samuel Rutunda and Lukman Jibril Aliyu and Esubalew Alemneh and Oumaima Hourrane and Hagos Tesfahun Gebremichael and Elyas Abdi Ismail and Meriem Beloucif and Ebrahim Chekol Jibril and Andiswa Bukula and Rooweither Mabuya and Salomey Osei and Abigail Oppong and Tadesse Destaw Belay and Tadesse Kebede Guge and Tesfa Tegegne Asfaw and Chiamaka Ijeoma Chukwuneke and Paul Rottger and Seid Muhie Yimam and Nedjma Djouhra Ousidhoum},
  year={2025},
  url={https://api.semanticscholar.org/CorpusID:275515951}
}

@article{adelani-etal-2021-masakhaner,
    title = "{M}asakha{NER}: Named Entity Recognition for {A}frican Languages",
    author = "Adelani, David Ifeoluwa  and
      Abbott, Jade  and
      Neubig, Graham  and
      D{'}souza, Daniel  and
      Kreutzer, Julia  and
      Lignos, Constantine  and
      Palen-Michel, Chester  and
      Buzaaba, Happy  and
      Rijhwani, Shruti  and
      Ruder, Sebastian  and
      Mayhew, Stephen  and
      Azime, Israel Abebe  and
      Muhammad, Shamsuddeen H.  and
      Emezue, Chris Chinenye  and
      Nakatumba-Nabende, Joyce  and
      Ogayo, Perez  and
      Anuoluwapo, Aremu  and
      Gitau, Catherine  and
      Mbaye, Derguene  and
      Alabi, Jesujoba  and
      Yimam, Seid Muhie  and
      Gwadabe, Tajuddeen Rabiu  and
      Ezeani, Ignatius  and
      Niyongabo, Rubungo Andre  and
      Mukiibi, Jonathan  and
      Otiende, Verrah  and
      Orife, Iroro  and
      David, Davis  and
      Ngom, Samba  and
      Adewumi, Tosin  and
      Rayson, Paul  and
      Adeyemi, Mofetoluwa  and
      Muriuki, Gerald  and
      Anebi, Emmanuel  and
      Chukwuneke, Chiamaka  and
      Odu, Nkiruka  and
      Wairagala, Eric Peter  and
      Oyerinde, Samuel  and
      Siro, Clemencia  and
      Bateesa, Tobius Saul  and
      Oloyede, Temilola  and
      Wambui, Yvonne  and
      Akinode, Victor  and
      Nabagereka, Deborah  and
      Katusiime, Maurice  and
      Awokoya, Ayodele  and
      MBOUP, Mouhamadane  and
      Gebreyohannes, Dibora  and
      Tilaye, Henok  and
      Nwaike, Kelechi  and
      Wolde, Degaga  and
      Faye, Abdoulaye  and
      Sibanda, Blessing  and
      Ahia, Orevaoghene  and
      Dossou, Bonaventure F. P.  and
      Ogueji, Kelechi  and
      DIOP, Thierno Ibrahima  and
      Diallo, Abdoulaye  and
      Akinfaderin, Adewale  and
      Marengereke, Tendai  and
      Osei, Salomey",
    editor = "Roark, Brian  and
      Nenkova, Ani",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "9",
    year = "2021",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    url = "https://aclanthology.org/2021.tacl-1.66/",
    doi = "10.1162/tacl_a_00416",
    pages = "1116--1131",
    abstract = "We take a step towards addressing the under- representation of the African continent in NLP research by bringing together different stakeholders to create the first large, publicly available, high-quality dataset for named entity recognition (NER) in ten African languages. We detail the characteristics of these languages to help researchers and practitioners better understand the challenges they pose for NER tasks. We analyze our datasets and conduct an extensive empirical evaluation of state- of-the-art methods across both supervised and transfer learning settings. Finally, we release the data, code, and models to inspire future research on African NLP.1"
}

@inproceedings{adelani-etal-2022-masakhaner,
    title = "{M}asakha{NER} 2.0: {A}frica-centric Transfer Learning for Named Entity Recognition",
    author = "Adelani, David  and
      Neubig, Graham  and
      Ruder, Sebastian  and
      Rijhwani, Shruti  and
      Beukman, Michael  and
      Palen-Michel, Chester  and
      Lignos, Constantine  and
      Alabi, Jesujoba  and
      Muhammad, Shamsuddeen  and
      Nabende, Peter  and
      Dione, Cheikh M. Bamba  and
      Bukula, Andiswa  and
      Mabuya, Rooweither  and
      Dossou, Bonaventure F. P.  and
      Sibanda, Blessing  and
      Buzaaba, Happy  and
      Mukiibi, Jonathan  and
      Kalipe, Godson  and
      Mbaye, Derguene  and
      Taylor, Amelia  and
      Kabore, Fatoumata  and
      Emezue, Chris Chinenye  and
      Aremu, Anuoluwapo  and
      Ogayo, Perez  and
      Gitau, Catherine  and
      Munkoh-Buabeng, Edwin  and
      Memdjokam Koagne, Victoire  and
      Tapo, Allahsera Auguste  and
      Macucwa, Tebogo  and
      Marivate, Vukosi  and
      Elvis, Mboning Tchiaze  and
      Gwadabe, Tajuddeen  and
      Adewumi, Tosin  and
      Ahia, Orevaoghene  and
      Nakatumba-Nabende, Joyce",
    editor = "Goldberg, Yoav  and
      Kozareva, Zornitsa  and
      Zhang, Yue",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.298/",
    doi = "10.18653/v1/2022.emnlp-main.298",
    pages = "4488--4508",
    abstract = "African languages are spoken by over a billion people, but they are under-represented in NLP research and development. Multiple challenges exist, including the limited availability of annotated training and evaluation datasets as well as the lack of understanding of which settings, languages, and recently proposed methods like cross-lingual transfer will be effective. In this paper, we aim to move towards solutions for these challenges, focusing on the task of named entity recognition (NER). We present the creation of the largest to-date human-annotated NER dataset for 20 African languages. We study the behaviour of state-of-the-art cross-lingual transfer methods in an Africa-centric setting, empirically demonstrating that the choice of source transfer language significantly affects performance. While much previous work defaults to using English as the source language, our results show that choosing the best transfer language improves zero-shot F1 scores by an average of 14{\%} over 20 languages as compared to using English."
}

@inproceedings{adelani-etal-2023-masakhanews,
    title = "{M}asakha{NEWS}: News Topic Classification for {A}frican languages",
    author = "Adelani, David Ifeoluwa  and
      Masiak, Marek  and
      Azime, Israel Abebe  and
      Alabi, Jesujoba  and
      Tonja, Atnafu Lambebo  and
      Mwase, Christine  and
      Ogundepo, Odunayo  and
      Dossou, Bonaventure F. P.  and
      Oladipo, Akintunde  and
      Nixdorf, Doreen  and
      Emezue, Chris Chinenye  and
      Al-azzawi, Sana  and
      Sibanda, Blessing  and
      David, Davis  and
      Ndolela, Lolwethu  and
      Mukiibi, Jonathan  and
      Ajayi, Tunde  and
      Moteu, Tatiana  and
      Odhiambo, Brian  and
      Owodunni, Abraham  and
      Obiefuna, Nnaemeka  and
      Mohamed, Muhidin  and
      Muhammad, Shamsuddeen Hassan  and
      Ababu, Teshome Mulugeta  and
      Salahudeen, Saheed Abdullahi  and
      Yigezu, Mesay Gemeda  and
      Gwadabe, Tajuddeen  and
      Abdulmumin, Idris  and
      Taye, Mahlet  and
      Awoyomi, Oluwabusayo  and
      Shode, Iyanuoluwa  and
      Adelani, Tolulope  and
      Abdulganiyu, Habiba  and
      Omotayo, Abdul-Hakeem  and
      Adeeko, Adetola  and
      Afolabi, Abeeb  and
      Aremu, Anuoluwapo  and
      Samuel, Olanrewaju  and
      Siro, Clemencia  and
      Kimotho, Wangari  and
      Ogbu, Onyekachi  and
      Mbonu, Chinedu  and
      Chukwuneke, Chiamaka  and
      Fanijo, Samuel  and
      Ojo, Jessica  and
      Awosan, Oyinkansola  and
      Kebede, Tadesse  and
      Sakayo, Toadoum Sari  and
      Nyatsine, Pamela  and
      Sidume, Freedmore  and
      Yousuf, Oreen  and
      Oduwole, Mardiyyah  and
      Tshinu, Kanda  and
      Kimanuka, Ussen  and
      Diko, Thina  and
      Nxakama, Siyanda  and
      Nigusse, Sinodos  and
      Johar, Abdulmejid  and
      Mohamed, Shafie  and
      Hassan, Fuad Mire  and
      Mehamed, Moges Ahmed  and
      Ngabire, Evrard  and
      Jules, Jules  and
      Ssenkungu, Ivan  and
      Stenetorp, Pontus",
    editor = "Park, Jong C.  and
      Arase, Yuki  and
      Hu, Baotian  and
      Lu, Wei  and
      Wijaya, Derry  and
      Purwarianti, Ayu  and
      Krisnadhi, Adila Alfa",
    booktitle = "Proceedings of the 13th International Joint Conference on Natural Language Processing and the 3rd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = nov,
    year = "2023",
    address = "Nusa Dua, Bali",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.ijcnlp-main.10/",
    doi = "10.18653/v1/2023.ijcnlp-main.10",
    pages = "144--159"
}

@article{adelani2024irokobench,
  title={IrokoBench: A New Benchmark for African Languages in the Age of Large Language Models},
  author={Adelani, David Ifeoluwa and Ojo, Jessica and Azime, Israel Abebe and Zhuang, Jian Yun and Alabi, Jesujoba O and He, Xuanli and Ochieng, Millicent and Hooker, Sara and Bukula, Andiswa and Lee, En-Shiun Annie and others},
  journal={arXiv preprint arXiv:2406.03368},
  year={2024}
}

@inproceedings{chen2022contrastnet,
  title={Contrastnet: A contrastive learning framework for few-shot text classification},
  author={Chen, Junfan and Zhang, Richong and Mao, Yongyi and Xu, Jie},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={36},
  number={10},
  pages={10492--10500},
  year={2022}
}

@inproceedings{dopierre2021protaugment,
  title={ProtAugment: Intent detection meta-learning through unsupervised diverse paraphrasing},
  author={Dopierre, Thomas and Gravier, Christophe and Logerais, Wilfried},
  booktitle={Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
  pages={2454--2466},
  year={2021},
  organization={Association for Computational Linguistics}
}

@inproceedings{fitzgerald-etal-2023-massive,
    title = "{MASSIVE}: A 1{M}-Example Multilingual Natural Language Understanding Dataset with 51 Typologically-Diverse Languages",
    author = "FitzGerald, Jack  and
      Hench, Christopher  and
      Peris, Charith  and
      Mackie, Scott  and
      Rottmann, Kay  and
      Sanchez, Ana  and
      Nash, Aaron  and
      Urbach, Liam  and
      Kakarala, Vishesh  and
      Singh, Richa  and
      Ranganath, Swetha  and
      Crist, Laurie  and
      Britan, Misha  and
      Leeuwis, Wouter  and
      Tur, Gokhan  and
      Natarajan, Prem",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.235/",
    doi = "10.18653/v1/2023.acl-long.235",
    pages = "4277--4302",
    abstract = "We present the MASSIVE dataset{--}Multilingual Amazon Slu resource package (SLURP) for Slot-filling, Intent classification, and Virtual assistant Evaluation. MASSIVE contains 1M realistic, parallel, labeled virtual assistant utterances spanning 51 languages, 18 domains, 60 intents, and 55 slots. MASSIVE was created by tasking professional translators to localize the English-only SLURP dataset into 50 typologically diverse languages from 29 genera. We also present modeling results on XLM-R and mT5, including exact match accuracy, intent classification accuracy, and slot-filling F1 score. We have released our dataset, modeling code, and models publicly."
}

@article{krone2020learning,
  title={Learning to classify intents and slot labels given a handful of examples},
  author={Krone, Jason and Zhang, Yi and Diab, Mona},
  journal={arXiv preprint arXiv:2004.10793},
  year={2020}
}

@article{larson2022survey,
  title={A Survey of Intent Classification and Slot-Filling Datasets for Task-Oriented Dialog},
  author={Stefan Larson and Kevin Leach},
  journal={arXiv preprint arXiv:2207.13211},
  year={2022},
  url={https://doi.org/10.48550/arXiv.2207.13211}
}

@inproceedings{li-etal-2021-mtop,
    title = "{MTOP}: A Comprehensive Multilingual Task-Oriented Semantic Parsing Benchmark",
    author = "Li, Haoran  and
      Arora, Abhinav  and
      Chen, Shuohui  and
      Gupta, Anchit  and
      Gupta, Sonal  and
      Mehdad, Yashar",
    editor = "Merlo, Paola  and
      Tiedemann, Jorg  and
      Tsarfaty, Reut",
    booktitle = "Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume",
    month = apr,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.eacl-main.257/",
    doi = "10.18653/v1/2021.eacl-main.257",
    pages = "2950--2962",
    abstract = "Scaling semantic parsing models for task-oriented dialog systems to new languages is often expensive and time-consuming due to the lack of available datasets. Available datasets suffer from several shortcomings: a) they contain few languages b) they contain small amounts of labeled examples per language c) they are based on the simple intent and slot detection paradigm for non-compositional queries. In this paper, we present a new multilingual dataset, called MTOP, comprising of 100k annotated utterances in 6 languages across 11 domains. We use this dataset and other publicly available datasets to conduct a comprehensive benchmarking study on using various state-of-the-art multilingual pre-trained models for task-oriented semantic parsing. We achieve an average improvement of +6.3 points on Slot F1 for the two existing multilingual datasets, over best results reported in their experiments. Furthermore, we demonstrate strong zero-shot performance using pre-trained models combined with automatic translation and alignment, and a proposed distant supervision method to reduce the noise in slot label projection."
}

@inproceedings{muhammad-etal-2023-afrisenti,
    title = "{A}fri{S}enti: A {T}witter Sentiment Analysis Benchmark for {A}frican Languages",
    author = "Muhammad, Shamsuddeen  and
      Abdulmumin, Idris  and
      Ayele, Abinew  and
      Ousidhoum, Nedjma  and
      Adelani, David  and
      Yimam, Seid  and
      Ahmad, Ibrahim  and
      Beloucif, Meriem  and
      Mohammad, Saif  and
      Ruder, Sebastian  and
      Hourrane, Oumaima  and
      Jorge, Alipio  and
      Brazdil, Pavel  and
      Ali, Felermino  and
      David, Davis  and
      Osei, Salomey  and
      Shehu-Bello, Bello  and
      Lawan, Falalu  and
      Gwadabe, Tajuddeen  and
      Rutunda, Samuel  and
      Belay, Tadesse Destaw  and
      Messelle, Wendimu  and
      Balcha, Hailu  and
      Chala, Sisay  and
      Gebremichael, Hagos  and
      Opoku, Bernard  and
      Arthur, Stephen",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.862/",
    doi = "10.18653/v1/2023.emnlp-main.862",
    pages = "13968--13981",
    abstract = "Africa is home to over 2,000 languages from over six language families and has the highest linguistic diversity among all continents. This includes 75 languages with at least one million speakers each. Yet, there is little NLP research conducted on African languages. Crucial in enabling such research is the availability of high-quality annotated datasets. In this paper, we introduce AfriSenti, a sentiment analysis benchmark that contains a total of {\ensuremath{>}}110,000 tweets in 14 African languages (Amharic, Algerian Arabic, Hausa, Igbo, Kinyarwanda, Moroccan Arabic, Mozambican Portuguese, Nigerian Pidgin, Oromo, Swahili, Tigrinya, Twi, Xitsonga, and Yoruba) from four language families. The tweets were annotated by native speakers and used in the AfriSenti-SemEval shared task (with over 200 participants, see website: https://afrisenti-semeval.github.io). We describe the data collection methodology, annotation process, and the challenges we dealt with when curating each dataset. We further report baseline experiments conducted on the AfriSenti datasets and discuss their usefulness."
}

@inproceedings{ogundepo-etal-2023-cross,
    title = "Cross-lingual Open-Retrieval Question Answering for {A}frican Languages",
    author = "Ogundepo, Odunayo  and
      Gwadabe, Tajuddeen  and
      Rivera, Clara  and
      Clark, Jonathan  and
      Ruder, Sebastian  and
      Adelani, David  and
      Dossou, Bonaventure  and
      Diop, Abdou  and
      Sikasote, Claytone  and
      Hacheme, Gilles  and
      Buzaaba, Happy  and
      Ezeani, Ignatius  and
      Mabuya, Rooweither  and
      Osei, Salomey  and
      Emezue, Chris  and
      Kahira, Albert  and
      Muhammad, Shamsuddeen  and
      Oladipo, Akintunde  and
      Owodunni, Abraham  and
      Tonja, Atnafu  and
      Shode, Iyanuoluwa  and
      Asai, Akari  and
      Aremu, Anuoluwapo  and
      Awokoya, Ayodele  and
      Opoku, Bernard  and
      Chukwuneke, Chiamaka  and
      Mwase, Christine  and
      Siro, Clemencia  and
      Arthur, Stephen  and
      Ajayi, Tunde  and
      Otiende, Verrah  and
      Rubungo, Andre  and
      Sinkala, Boyd  and
      Ajisafe, Daniel  and
      Onwuegbuzia, Emeka  and
      Lawan, Falalu  and
      Ahmad, Ibrahim  and
      Alabi, Jesujoba  and
      Mbonu, Chinedu  and
      Adeyemi, Mofetoluwa  and
      Phiri, Mofya  and
      Ahia, Orevaoghene  and
      Iro, Ruqayya  and
      Adhiambo, Sonia",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-emnlp.997/",
    doi = "10.18653/v1/2023.findings-emnlp.997",
    pages = "14957--14972",
    abstract = "African languages have far less in-language content available digitally, making it challenging for question answering systems to satisfy the information needs of users. Cross-lingual open-retrieval question answering (XOR QA) systems {--} those that retrieve answer content from other languages while serving people in their native language{---}offer a means of filling this gap. To this end, we create Our Dataset, the first cross-lingual QA dataset with a focus on African languages. Our Dataset includes 12,000+ XOR QA examples across 10 African languages. While previous datasets have focused primarily on languages where cross-lingual QA augments coverage from the target language, Our Dataset focuses on languages where cross-lingual answer content is the only high-coverage source of answer content. Because of this, we argue that African languages are one of the most important and realistic use cases for XOR QA. Our experiments demonstrate the poor performance of automatic translation and multilingual retrieval methods. Overall, Our Dataset proves challenging for state-of-the-art QA models. We hope that the dataset enables the development of more equitable QA technology."
}

@article{parikh2023exploring,
  title={Exploring zero and few-shot techniques for intent classification},
  author={Parikh, Soham and Vohra, Quaizar and Tumbade, Prashil and Tiwari, Mitul},
  journal={arXiv preprint arXiv:2305.07157},
  year={2023}
}

@inproceedings{ruder-etal-2023-xtreme,
    title = "{XTREME}-{UP}: A User-Centric Scarce-Data Benchmark for Under-Represented Languages",
    author = "Ruder, Sebastian  and
      Clark, Jonathan  and
      Gutkin, Alexander  and
      Kale, Mihir  and
      Ma, Min  and
      Nicosia, Massimo  and
      Rijhwani, Shruti  and
      Riley, Parker  and
      Sarr, Jean-Michel  and
      Wang, Xinyi  and
      Wieting, John  and
      Gupta, Nitish  and
      Katanova, Anna  and
      Kirov, Christo  and
      Dickinson, Dana  and
      Roark, Brian  and
      Samanta, Bidisha  and
      Tao, Connie  and
      Adelani, David  and
      Axelrod, Vera  and
      Caswell, Isaac  and
      Cherry, Colin  and
      Garrette, Dan  and
      Ingle, Reeve  and
      Johnson, Melvin  and
      Panteleev, Dmitry  and
      Talukdar, Partha",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-emnlp.125/",
    doi = "10.18653/v1/2023.findings-emnlp.125",
    pages = "1856--1884",
    abstract = "Data scarcity is a crucial issue for the development of highly multilingual NLP systems. Yet for many under-represented languages (ULs) {---} languages for which NLP research is particularly far behind in meeting user needs {---} it is feasible to annotate small amounts of data. Motivated by this, we propose XTREME-UP, a benchmark defined by: its focus on the scarce-data scenario rather than zero-shot; its focus on user-centric tasks {---} tasks with broad adoption by speakers of high-resource languages; and its focus on under-represented languages where this scarce-data scenario tends to be most realistic. XTREME-UP evaluates the capabilities of language models across 88 under-represented languages over 9 key user-centric technologies including ASR, OCR, MT, and information access tasks that are of general utility. We create new datasets for OCR, autocomplete, semantic parsing, and transliteration, and build on and refine existing datasets for other tasks. XTREME-UP provides methodology for evaluating many modeling scenarios including text only, multi-modal (vision, audio, and text), supervised parameter tuning, and in-context learning. We evaluate commonly used models on the benchmark. We release all code and scripts to train and evaluate models."
}

@inproceedings{schuster-etal-2019-cross-lingual,
    title = "Cross-lingual Transfer Learning for Multilingual Task Oriented Dialog",
    author = "Schuster, Sebastian  and
      Gupta, Sonal  and
      Shah, Rushin  and
      Lewis, Mike",
    editor = "Burstein, Jill  and
      Doran, Christy  and
      Solorio, Thamar",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1380/",
    doi = "10.18653/v1/N19-1380",
    pages = "3795--3805",
    abstract = "One of the first steps in the utterance interpretation pipeline of many task-oriented conversational AI systems is to identify user intents and the corresponding slots. Since data collection for machine learning models for this task is time-consuming, it is desirable to make use of existing data in a high-resource language to train models in low-resource languages. However, development of such models has largely been hindered by the lack of multilingual training data. In this paper, we present a new data set of 57k annotated utterances in English (43k), Spanish (8.6k) and Thai (5k) across the domains weather, alarm, and reminder. We use this data set to evaluate three different cross-lingual transfer methods: (1) translating the training data, (2) using cross-lingual pre-trained embeddings, and (3) a novel method of using a multilingual machine translation encoder as contextual word representations. We find that given several hundred training examples in the the target language, the latter two methods outperform translating the training data. Further, in very low-resource settings, multilingual contextual word representations give better results than using cross-lingual static embeddings. We also compare the cross-lingual methods to using monolingual resources in the form of contextual ELMo representations and find that given just small amounts of target language data, this method outperforms all cross-lingual methods, which highlights the need for more sophisticated cross-lingual methods."
}

@inproceedings{van-der-goot-etal-2021-masked,
    title = "From Masked Language Modeling to Translation: Non-{E}nglish Auxiliary Tasks Improve Zero-shot Spoken Language Understanding",
    author = {van der Goot, Rob  and
      Sharaf, Ibrahim  and
      Imankulova, Aizhan  and
      {\"U}st{\"u}n, Ahmet  and
      Stepanovi{\'c}, Marija  and
      Ramponi, Alan  and
      Khairunnisa, Siti Oryza  and
      Komachi, Mamoru  and
      Plank, Barbara},
    editor = "Toutanova, Kristina  and
      Rumshisky, Anna  and
      Zettlemoyer, Luke  and
      Hakkani-Tur, Dilek  and
      Beltagy, Iz  and
      Bethard, Steven  and
      Cotterell, Ryan  and
      Chakraborty, Tanmoy  and
      Zhou, Yichao",
    booktitle = "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.naacl-main.197/",
    doi = "10.18653/v1/2021.naacl-main.197",
    pages = "2479--2497",
    abstract = "The lack of publicly available evaluation data for low-resource languages limits progress in Spoken Language Understanding (SLU). As key tasks like intent classification and slot filling require abundant training data, it is desirable to reuse existing data in high-resource languages to develop models for low-resource scenarios. We introduce xSID, a new benchmark for cross-lingual (x) Slot and Intent Detection in 13 languages from 6 language families, including a very low-resource dialect. To tackle the challenge, we propose a joint learning approach, with English SLU training data and non-English auxiliary tasks from raw text, syntax and translation for transfer. We study two setups which differ by type and language coverage of the pre-trained embeddings. Our results show that jointly learning the main tasks with masked language modeling is effective for slots, while machine translation transfer works best for intent classification."
}

@inproceedings{xu-etal-2020-end,
    title = "End-to-End Slot Alignment and Recognition for Cross-Lingual {NLU}",
    author = "Xu, Weijia  and
      Haider, Batool  and
      Mansour, Saab",
    editor = "Webber, Bonnie  and
      Cohn, Trevor  and
      He, Yulan  and
      Liu, Yang",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.410/",
    doi = "10.18653/v1/2020.emnlp-main.410",
    pages = "5052--5063",
    abstract = "Natural language understanding (NLU) in the context of goal-oriented dialog systems typically includes intent classification and slot labeling tasks. Existing methods to expand an NLU system to new languages use machine translation with slot label projection from source to the translated utterances, and thus are sensitive to projection errors. In this work, we propose a novel end-to-end model that learns to align and predict target slot labels jointly for cross-lingual transfer. We introduce MultiATIS++, a new multilingual NLU corpus that extends the Multilingual ATIS corpus to nine languages across four language families, and evaluate our method using the corpus. Results show that our method outperforms a simple label projection method using fast-align on most languages, and achieves competitive performance to the more complex, state-of-the-art projection method with only half of the training time. We release our MultiATIS++ corpus to the community to continue future research on cross-lingual NLU."
}

