@Article{AdamW,
  author        = {Loshchilov, Ilya and Hutter, Frank},
  title         = {Decoupled Weight Decay Regularization},
  year          = {2017},
  month         = nov,
  abstract      = {L$_2$ regularization and weight decay regularization are equivalent for standard stochastic gradient descent (when rescaled by the learning rate), but as we demonstrate this is \emph{not} the case for adaptive gradient algorithms, such as Adam. While common implementations of these algorithms employ L$_2$ regularization (often calling it "weight decay" in what may be misleading due to the inequivalence we expose), we propose a simple modification to recover the original formulation of weight decay regularization by \emph{decoupling} the weight decay from the optimization steps taken w.r.t. the loss function. We provide empirical evidence that our proposed modification (i) decouples the optimal choice of weight decay factor from the setting of the learning rate for both standard SGD and Adam and (ii) substantially improves Adam's generalization performance, allowing it to compete with SGD with momentum on image classification datasets (on which it was previously typically outperformed by the latter). Our proposed decoupled weight decay has already been adopted by many researchers, and the community has implemented it in TensorFlow and PyTorch; the complete source code for our experiments is available at https://github.com/loshchil/AdamW-and-SGDW},
  archiveprefix = {arXiv},
  copyright     = {arXiv.org perpetual, non-exclusive license},
  doi           = {10.48550/ARXIV.1711.05101},
  eprint        = {1711.05101},
  file          = {:http\://arxiv.org/pdf/1711.05101v3:PDF},
  keywords      = {Machine Learning (cs.LG), Neural and Evolutionary Computing (cs.NE), Optimization and Control (math.OC), FOS: Computer and information sciences, FOS: Mathematics},
  primaryclass  = {cs.LG},
  publisher     = {arXiv},
}

@InProceedings{MasakhaNER,
  author    = {Adelani, David and Neubig, Graham and Ruder, Sebastian and Rijhwani, Shruti and Beukman, Michael and Palen-Michel, Chester and Lignos, Constantine and Alabi, Jesujoba and Muhammad, Shamsuddeen and Nabende, Peter and Dione, Cheikh M. Bamba and Bukula, Andiswa and Mabuya, Rooweither and Dossou, Bonaventure F. P. and Sibanda, Blessing and Buzaaba, Happy and Mukiibi, Jonathan and Kalipe, Godson and Mbaye, Derguene and Taylor, Amelia and Kabore, Fatoumata and Emezue, Chris Chinenye and Aremu, Anuoluwapo and Ogayo, Perez and Gitau, Catherine and Munkoh-Buabeng, Edwin and Memdjokam Koagne, Victoire and Tapo, Allahsera Auguste and Macucwa, Tebogo and Marivate, Vukosi and Elvis, Mboning Tchiaze and Gwadabe, Tajuddeen and Adewumi, Tosin and Ahia, Orevaoghene and Nakatumba-Nabende, Joyce},
  booktitle = {Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
  title     = {{M}asakha{NER} 2.0: {A}frica-centric Transfer Learning for Named Entity Recognition},
  year      = {2022},
  address   = {Abu Dhabi, United Arab Emirates},
  editor    = {Goldberg, Yoav and Kozareva, Zornitsa and Zhang, Yue},
  month     = dec,
  pages     = {4488--4508},
  publisher = {Association for Computational Linguistics},
  abstract  = {African languages are spoken by over a billion people, but they are under-represented in NLP research and development. Multiple challenges exist, including the limited availability of annotated training and evaluation datasets as well as the lack of understanding of which settings, languages, and recently proposed methods like cross-lingual transfer will be effective. In this paper, we aim to move towards solutions for these challenges, focusing on the task of named entity recognition (NER). We present the creation of the largest to-date human-annotated NER dataset for 20 African languages. We study the behaviour of state-of-the-art cross-lingual transfer methods in an Africa-centric setting, empirically demonstrating that the choice of source transfer language significantly affects performance. While much previous work defaults to using English as the source language, our results show that choosing the best transfer language improves zero-shot F1 scores by an average of 14{\%} over 20 languages as compared to using English.},
  doi       = {10.18653/v1/2022.emnlp-main.298},
  url       = {https://aclanthology.org/2022.emnlp-main.298/},
}

@inproceedings{chen2022contrastnet,
  title={Contrastnet: A contrastive learning framework for few-shot text classification},
  author={Chen, Junfan and Zhang, Richong and Mao, Yongyi and Xu, Jie},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={36},
  number={10},
  pages={10492--10500},
  year={2022}
}

@inproceedings{dopierre2021protaugment,
  title={ProtAugment: Intent detection meta-learning through unsupervised diverse paraphrasing},
  author={Dopierre, Thomas and Gravier, Christophe and Logerais, Wilfried},
  booktitle={Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
  pages={2454--2466},
  year={2021},
  organization={Association for Computational Linguistics}
}

@article{krone2020learning,
  title={Learning to classify intents and slot labels given a handful of examples},
  author={Krone, Jason and Zhang, Yi and Diab, Mona},
  journal={arXiv preprint arXiv:2004.10793},
  year={2020}
}

@article{parikh2023exploring,
  title={Exploring zero and few-shot techniques for intent classification},
  author={Parikh, Soham and Vohra, Quaizar and Tumbade, Prashil and Tiwari, Mitul},
  journal={arXiv preprint arXiv:2305.07157},
  year={2023}
}

@article{larson2022survey,
  title={A Survey of Intent Classification and Slot-Filling Datasets for Task-Oriented Dialog},
  author={Stefan Larson and Kevin Leach},
  journal={arXiv preprint arXiv:2207.13211},
  year={2022},
  url={https://doi.org/10.48550/arXiv.2207.13211}
}

@article{adelani2024irokobench,
  title={IrokoBench: A New Benchmark for African Languages in the Age of Large Language Models},
  author={Adelani, David Ifeoluwa and Ojo, Jessica and Azime, Israel Abebe and Zhuang, Jian Yun and Alabi, Jesujoba O and He, Xuanli and Ochieng, Millicent and Hooker, Sara and Bukula, Andiswa and Lee, En-Shiun Annie and others},
  journal={arXiv preprint arXiv:2406.03368},
  year={2024}
}


@article{Coucke2018SnipsVP,
  title={Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces},
  author={Alice Coucke and Alaa Saade and Adrien Ball and Th{\'e}odore Bluche and Alexandre Caulier and David Leroy and Cl{\'e}ment Doumouro and Thibault Gisselbrecht and Francesco Caltagirone and Thibaut Lavril and Ma{\"e}l Primet and Joseph Dureau},
  journal={ArXiv},
  year={2018},
  volume={abs/1805.10190},
  url={https://api.semanticscholar.org/CorpusID:44061213}
}

@article{Larson2022ASO,
  title={A Survey of Intent Classification and Slot-Filling Datasets for Task-Oriented Dialog},
  author={Stefan Larson and Kevin Leach},
  journal={ArXiv},
  year={2022},
  volume={abs/2207.13211},
  url={https://api.semanticscholar.org/CorpusID:251105002}
}


@inproceedings{gupta-etal-2018-semantic-parsing,
    title = "Semantic Parsing for Task Oriented Dialog using Hierarchical Representations",
    author = "Gupta, Sonal  and
      Shah, Rushin  and
      Mohit, Mrinal  and
      Kumar, Anuj  and
      Lewis, Mike",
    editor = "Riloff, Ellen  and
      Chiang, David  and
      Hockenmaier, Julia  and
      Tsujii, Jun{'}ichi",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D18-1300/",
    doi = "10.18653/v1/D18-1300",
    pages = "2787--2792",
    abstract = "Task oriented dialog systems typically first parse user utterances to semantic frames comprised of intents and slots. Previous work on task oriented intent and slot-filling work has been restricted to one intent per query and one slot label per token, and thus cannot model complex compositional requests. Alternative semantic parsing systems have represented queries as logical forms, but these are challenging to annotate and parse. We propose a hierarchical annotation scheme for semantic parsing that allows the representation of compositional queries, and can be efficiently and accurately parsed by standard constituency parsing models. We release a dataset of 44k annotated queries (\url{http://fb.me/semanticparsingdialog}), and show that parsing models outperform sequence-to-sequence approaches on this dataset."
}


@inproceedings{hemphill-etal-1990-atis,
    title = "The {ATIS} Spoken Language Systems Pilot Corpus",
    author = "Hemphill, Charles T.  and
      Godfrey, John J.  and
      Doddington, George R.",
    booktitle = "Speech and Natural Language: Proceedings of a Workshop Held at Hidden Valley, {P}ennsylvania, June 24-27,1990",
    year = "1990",
    url = "https://aclanthology.org/H90-1021/"
}

@inproceedings{fitzgerald-etal-2023-massive,
    title = "{MASSIVE}: A 1{M}-Example Multilingual Natural Language Understanding Dataset with 51 Typologically-Diverse Languages",
    author = "FitzGerald, Jack  and
      Hench, Christopher  and
      Peris, Charith  and
      Mackie, Scott  and
      Rottmann, Kay  and
      Sanchez, Ana  and
      Nash, Aaron  and
      Urbach, Liam  and
      Kakarala, Vishesh  and
      Singh, Richa  and
      Ranganath, Swetha  and
      Crist, Laurie  and
      Britan, Misha  and
      Leeuwis, Wouter  and
      Tur, Gokhan  and
      Natarajan, Prem",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.235/",
    doi = "10.18653/v1/2023.acl-long.235",
    pages = "4277--4302",
    abstract = "We present the MASSIVE dataset{--}Multilingual Amazon Slu resource package (SLURP) for Slot-filling, Intent classification, and Virtual assistant Evaluation. MASSIVE contains 1M realistic, parallel, labeled virtual assistant utterances spanning 51 languages, 18 domains, 60 intents, and 55 slots. MASSIVE was created by tasking professional translators to localize the English-only SLURP dataset into 50 typologically diverse languages from 29 genera. We also present modeling results on XLM-R and mT5, including exact match accuracy, intent classification accuracy, and slot-filling F1 score. We have released our dataset, modeling code, and models publicly."
}


@inproceedings{ruder-etal-2023-xtreme,
    title = "{XTREME}-{UP}: A User-Centric Scarce-Data Benchmark for Under-Represented Languages",
    author = "Ruder, Sebastian  and
      Clark, Jonathan  and
      Gutkin, Alexander  and
      Kale, Mihir  and
      Ma, Min  and
      Nicosia, Massimo  and
      Rijhwani, Shruti  and
      Riley, Parker  and
      Sarr, Jean-Michel  and
      Wang, Xinyi  and
      Wieting, John  and
      Gupta, Nitish  and
      Katanova, Anna  and
      Kirov, Christo  and
      Dickinson, Dana  and
      Roark, Brian  and
      Samanta, Bidisha  and
      Tao, Connie  and
      Adelani, David  and
      Axelrod, Vera  and
      Caswell, Isaac  and
      Cherry, Colin  and
      Garrette, Dan  and
      Ingle, Reeve  and
      Johnson, Melvin  and
      Panteleev, Dmitry  and
      Talukdar, Partha",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-emnlp.125/",
    doi = "10.18653/v1/2023.findings-emnlp.125",
    pages = "1856--1884",
    abstract = "Data scarcity is a crucial issue for the development of highly multilingual NLP systems. Yet for many under-represented languages (ULs) {---} languages for which NLP research is particularly far behind in meeting user needs {---} it is feasible to annotate small amounts of data. Motivated by this, we propose XTREME-UP, a benchmark defined by: its focus on the scarce-data scenario rather than zero-shot; its focus on user-centric tasks {---} tasks with broad adoption by speakers of high-resource languages; and its focus on under-represented languages where this scarce-data scenario tends to be most realistic. XTREME-UP evaluates the capabilities of language models across 88 under-represented languages over 9 key user-centric technologies including ASR, OCR, MT, and information access tasks that are of general utility. We create new datasets for OCR, autocomplete, semantic parsing, and transliteration, and build on and refine existing datasets for other tasks. XTREME-UP provides methodology for evaluating many modeling scenarios including text only, multi-modal (vision, audio, and text), supervised parameter tuning, and in-context learning. We evaluate commonly used models on the benchmark. We release all code and scripts to train and evaluate models."
}


@inproceedings{li-etal-2021-mtop,
    title = "{MTOP}: A Comprehensive Multilingual Task-Oriented Semantic Parsing Benchmark",
    author = "Li, Haoran  and
      Arora, Abhinav  and
      Chen, Shuohui  and
      Gupta, Anchit  and
      Gupta, Sonal  and
      Mehdad, Yashar",
    editor = "Merlo, Paola  and
      Tiedemann, Jorg  and
      Tsarfaty, Reut",
    booktitle = "Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume",
    month = apr,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.eacl-main.257/",
    doi = "10.18653/v1/2021.eacl-main.257",
    pages = "2950--2962",
    abstract = "Scaling semantic parsing models for task-oriented dialog systems to new languages is often expensive and time-consuming due to the lack of available datasets. Available datasets suffer from several shortcomings: a) they contain few languages b) they contain small amounts of labeled examples per language c) they are based on the simple intent and slot detection paradigm for non-compositional queries. In this paper, we present a new multilingual dataset, called MTOP, comprising of 100k annotated utterances in 6 languages across 11 domains. We use this dataset and other publicly available datasets to conduct a comprehensive benchmarking study on using various state-of-the-art multilingual pre-trained models for task-oriented semantic parsing. We achieve an average improvement of +6.3 points on Slot F1 for the two existing multilingual datasets, over best results reported in their experiments. Furthermore, we demonstrate strong zero-shot performance using pre-trained models combined with automatic translation and alignment, and a proposed distant supervision method to reduce the noise in slot label projection."
}

@inproceedings{xu-etal-2020-end,
    title = "End-to-End Slot Alignment and Recognition for Cross-Lingual {NLU}",
    author = "Xu, Weijia  and
      Haider, Batool  and
      Mansour, Saab",
    editor = "Webber, Bonnie  and
      Cohn, Trevor  and
      He, Yulan  and
      Liu, Yang",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.410/",
    doi = "10.18653/v1/2020.emnlp-main.410",
    pages = "5052--5063",
    abstract = "Natural language understanding (NLU) in the context of goal-oriented dialog systems typically includes intent classification and slot labeling tasks. Existing methods to expand an NLU system to new languages use machine translation with slot label projection from source to the translated utterances, and thus are sensitive to projection errors. In this work, we propose a novel end-to-end model that learns to align and predict target slot labels jointly for cross-lingual transfer. We introduce MultiATIS++, a new multilingual NLU corpus that extends the Multilingual ATIS corpus to nine languages across four language families, and evaluate our method using the corpus. Results show that our method outperforms a simple label projection method using fast-align on most languages, and achieves competitive performance to the more complex, state-of-the-art projection method with only half of the training time. We release our MultiATIS++ corpus to the community to continue future research on cross-lingual NLU."
}

@inproceedings{van-der-goot-etal-2021-masked,
    title = "From Masked Language Modeling to Translation: Non-{E}nglish Auxiliary Tasks Improve Zero-shot Spoken Language Understanding",
    author = {van der Goot, Rob  and
      Sharaf, Ibrahim  and
      Imankulova, Aizhan  and
      {\"U}st{\"u}n, Ahmet  and
      Stepanovi{\'c}, Marija  and
      Ramponi, Alan  and
      Khairunnisa, Siti Oryza  and
      Komachi, Mamoru  and
      Plank, Barbara},
    editor = "Toutanova, Kristina  and
      Rumshisky, Anna  and
      Zettlemoyer, Luke  and
      Hakkani-Tur, Dilek  and
      Beltagy, Iz  and
      Bethard, Steven  and
      Cotterell, Ryan  and
      Chakraborty, Tanmoy  and
      Zhou, Yichao",
    booktitle = "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.naacl-main.197/",
    doi = "10.18653/v1/2021.naacl-main.197",
    pages = "2479--2497",
    abstract = "The lack of publicly available evaluation data for low-resource languages limits progress in Spoken Language Understanding (SLU). As key tasks like intent classification and slot filling require abundant training data, it is desirable to reuse existing data in high-resource languages to develop models for low-resource scenarios. We introduce xSID, a new benchmark for cross-lingual (x) Slot and Intent Detection in 13 languages from 6 language families, including a very low-resource dialect. To tackle the challenge, we propose a joint learning approach, with English SLU training data and non-English auxiliary tasks from raw text, syntax and translation for transfer. We study two setups which differ by type and language coverage of the pre-trained embeddings. Our results show that jointly learning the main tasks with masked language modeling is effective for slots, while machine translation transfer works best for intent classification."
}

@inproceedings{schuster-etal-2019-cross-lingual,
    title = "Cross-lingual Transfer Learning for Multilingual Task Oriented Dialog",
    author = "Schuster, Sebastian  and
      Gupta, Sonal  and
      Shah, Rushin  and
      Lewis, Mike",
    editor = "Burstein, Jill  and
      Doran, Christy  and
      Solorio, Thamar",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1380/",
    doi = "10.18653/v1/N19-1380",
    pages = "3795--3805",
    abstract = "One of the first steps in the utterance interpretation pipeline of many task-oriented conversational AI systems is to identify user intents and the corresponding slots. Since data collection for machine learning models for this task is time-consuming, it is desirable to make use of existing data in a high-resource language to train models in low-resource languages. However, development of such models has largely been hindered by the lack of multilingual training data. In this paper, we present a new data set of 57k annotated utterances in English (43k), Spanish (8.6k) and Thai (5k) across the domains weather, alarm, and reminder. We use this data set to evaluate three different cross-lingual transfer methods: (1) translating the training data, (2) using cross-lingual pre-trained embeddings, and (3) a novel method of using a multilingual machine translation encoder as contextual word representations. We find that given several hundred training examples in the the target language, the latter two methods outperform translating the training data. Further, in very low-resource settings, multilingual contextual word representations give better results than using cross-lingual static embeddings. We also compare the cross-lingual methods to using monolingual resources in the form of contextual ELMo representations and find that given just small amounts of target language data, this method outperforms all cross-lingual methods, which highlights the need for more sophisticated cross-lingual methods."
}


@article{Yu2023OpenCO,
  title={Open, Closed, or Small Language Models for Text Classification?},
  author={Hao Yu and Zachary Yang and Kellin Pelrine and Jean FranÃ§ois Godbout and Reihaneh Rabbany},
  journal={ArXiv},
  year={2023},
  volume={abs/2308.10092},
  url={https://api.semanticscholar.org/CorpusID:261049379}
}


@inproceedings{adelani-etal-2022-thousand,
    title = "A Few Thousand Translations Go a Long Way! Leveraging Pre-trained Models for {A}frican News Translation",
    author = "Adelani, David  and
      Alabi, Jesujoba  and
      Fan, Angela  and
      Kreutzer, Julia  and
      Shen, Xiaoyu  and
      Reid, Machel  and
      Ruiter, Dana  and
      Klakow, Dietrich  and
      Nabende, Peter  and
      Chang, Ernie  and
      Gwadabe, Tajuddeen  and
      Sackey, Freshia  and
      Dossou, Bonaventure F. P.  and
      Emezue, Chris  and
      Leong, Colin  and
      Beukman, Michael  and
      Muhammad, Shamsuddeen  and
      Jarso, Guyo  and
      Yousuf, Oreen  and
      Niyongabo Rubungo, Andre  and
      Hacheme, Gilles  and
      Wairagala, Eric Peter  and
      Nasir, Muhammad Umair  and
      Ajibade, Benjamin  and
      Ajayi, Tunde  and
      Gitau, Yvonne  and
      Abbott, Jade  and
      Ahmed, Mohamed  and
      Ochieng, Millicent  and
      Aremu, Anuoluwapo  and
      Ogayo, Perez  and
      Mukiibi, Jonathan  and
      Ouoba Kabore, Fatoumata  and
      Kalipe, Godson  and
      Mbaye, Derguene  and
      Tapo, Allahsera Auguste  and
      Memdjokam Koagne, Victoire  and
      Munkoh-Buabeng, Edwin  and
      Wagner, Valencia  and
      Abdulmumin, Idris  and
      Awokoya, Ayodele  and
      Buzaaba, Happy  and
      Sibanda, Blessing  and
      Bukula, Andiswa  and
      Manthalu, Sam",
    booktitle = "Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jul,
    year = "2022",
    address = "Seattle, United States",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.naacl-main.223",
    doi = "10.18653/v1/2022.naacl-main.223",
    pages = "3053--3070",
    abstract = "Recent advances in the pre-training for language models leverage large-scale datasets to create multilingual models. However, low-resource languages are mostly left out in these datasets. This is primarily because many widely spoken languages that are not well represented on the web and therefore excluded from the large-scale crawls for datasets. Furthermore, downstream users of these models are restricted to the selection of languages originally chosen for pre-training. This work investigates how to optimally leverage existing pre-trained models to create low-resource translation systems for 16 African languages. We focus on two questions: 1) How can pre-trained models be used for languages not included in the initial pretraining? and 2) How can the resulting translation models effectively transfer to new domains? To answer these questions, we create a novel African news corpus covering 16 languages, of which eight languages are not part of any existing evaluation dataset. We demonstrate that the most effective strategy for transferring both additional languages and additional domains is to leverage small quantities of high-quality translation data to fine-tune large pre-trained models.",
}


@article{adelani-etal-2021-masakhaner,
    title = "{M}asakha{NER}: Named Entity Recognition for {A}frican Languages",
    author = "Adelani, David Ifeoluwa  and
      Abbott, Jade  and
      Neubig, Graham  and
      D{'}souza, Daniel  and
      Kreutzer, Julia  and
      Lignos, Constantine  and
      Palen-Michel, Chester  and
      Buzaaba, Happy  and
      Rijhwani, Shruti  and
      Ruder, Sebastian  and
      Mayhew, Stephen  and
      Azime, Israel Abebe  and
      Muhammad, Shamsuddeen H.  and
      Emezue, Chris Chinenye  and
      Nakatumba-Nabende, Joyce  and
      Ogayo, Perez  and
      Anuoluwapo, Aremu  and
      Gitau, Catherine  and
      Mbaye, Derguene  and
      Alabi, Jesujoba  and
      Yimam, Seid Muhie  and
      Gwadabe, Tajuddeen Rabiu  and
      Ezeani, Ignatius  and
      Niyongabo, Rubungo Andre  and
      Mukiibi, Jonathan  and
      Otiende, Verrah  and
      Orife, Iroro  and
      David, Davis  and
      Ngom, Samba  and
      Adewumi, Tosin  and
      Rayson, Paul  and
      Adeyemi, Mofetoluwa  and
      Muriuki, Gerald  and
      Anebi, Emmanuel  and
      Chukwuneke, Chiamaka  and
      Odu, Nkiruka  and
      Wairagala, Eric Peter  and
      Oyerinde, Samuel  and
      Siro, Clemencia  and
      Bateesa, Tobius Saul  and
      Oloyede, Temilola  and
      Wambui, Yvonne  and
      Akinode, Victor  and
      Nabagereka, Deborah  and
      Katusiime, Maurice  and
      Awokoya, Ayodele  and
      MBOUP, Mouhamadane  and
      Gebreyohannes, Dibora  and
      Tilaye, Henok  and
      Nwaike, Kelechi  and
      Wolde, Degaga  and
      Faye, Abdoulaye  and
      Sibanda, Blessing  and
      Ahia, Orevaoghene  and
      Dossou, Bonaventure F. P.  and
      Ogueji, Kelechi  and
      DIOP, Thierno Ibrahima  and
      Diallo, Abdoulaye  and
      Akinfaderin, Adewale  and
      Marengereke, Tendai  and
      Osei, Salomey",
    editor = "Roark, Brian  and
      Nenkova, Ani",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "9",
    year = "2021",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    url = "https://aclanthology.org/2021.tacl-1.66/",
    doi = "10.1162/tacl_a_00416",
    pages = "1116--1131",
    abstract = "We take a step towards addressing the under- representation of the African continent in NLP research by bringing together different stakeholders to create the first large, publicly available, high-quality dataset for named entity recognition (NER) in ten African languages. We detail the characteristics of these languages to help researchers and practitioners better understand the challenges they pose for NER tasks. We analyze our datasets and conduct an extensive empirical evaluation of state- of-the-art methods across both supervised and transfer learning settings. Finally, we release the data, code, and models to inspire future research on African NLP.1"
}


@inproceedings{adelani-etal-2022-masakhaner,
    title = "{M}asakha{NER} 2.0: {A}frica-centric Transfer Learning for Named Entity Recognition",
    author = "Adelani, David  and
      Neubig, Graham  and
      Ruder, Sebastian  and
      Rijhwani, Shruti  and
      Beukman, Michael  and
      Palen-Michel, Chester  and
      Lignos, Constantine  and
      Alabi, Jesujoba  and
      Muhammad, Shamsuddeen  and
      Nabende, Peter  and
      Dione, Cheikh M. Bamba  and
      Bukula, Andiswa  and
      Mabuya, Rooweither  and
      Dossou, Bonaventure F. P.  and
      Sibanda, Blessing  and
      Buzaaba, Happy  and
      Mukiibi, Jonathan  and
      Kalipe, Godson  and
      Mbaye, Derguene  and
      Taylor, Amelia  and
      Kabore, Fatoumata  and
      Emezue, Chris Chinenye  and
      Aremu, Anuoluwapo  and
      Ogayo, Perez  and
      Gitau, Catherine  and
      Munkoh-Buabeng, Edwin  and
      Memdjokam Koagne, Victoire  and
      Tapo, Allahsera Auguste  and
      Macucwa, Tebogo  and
      Marivate, Vukosi  and
      Elvis, Mboning Tchiaze  and
      Gwadabe, Tajuddeen  and
      Adewumi, Tosin  and
      Ahia, Orevaoghene  and
      Nakatumba-Nabende, Joyce",
    editor = "Goldberg, Yoav  and
      Kozareva, Zornitsa  and
      Zhang, Yue",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.298/",
    doi = "10.18653/v1/2022.emnlp-main.298",
    pages = "4488--4508",
    abstract = "African languages are spoken by over a billion people, but they are under-represented in NLP research and development. Multiple challenges exist, including the limited availability of annotated training and evaluation datasets as well as the lack of understanding of which settings, languages, and recently proposed methods like cross-lingual transfer will be effective. In this paper, we aim to move towards solutions for these challenges, focusing on the task of named entity recognition (NER). We present the creation of the largest to-date human-annotated NER dataset for 20 African languages. We study the behaviour of state-of-the-art cross-lingual transfer methods in an Africa-centric setting, empirically demonstrating that the choice of source transfer language significantly affects performance. While much previous work defaults to using English as the source language, our results show that choosing the best transfer language improves zero-shot F1 scores by an average of 14{\%} over 20 languages as compared to using English."
}


@inproceedings{muhammad-etal-2023-afrisenti,
    title = "{A}fri{S}enti: A {T}witter Sentiment Analysis Benchmark for {A}frican Languages",
    author = "Muhammad, Shamsuddeen  and
      Abdulmumin, Idris  and
      Ayele, Abinew  and
      Ousidhoum, Nedjma  and
      Adelani, David  and
      Yimam, Seid  and
      Ahmad, Ibrahim  and
      Beloucif, Meriem  and
      Mohammad, Saif  and
      Ruder, Sebastian  and
      Hourrane, Oumaima  and
      Jorge, Alipio  and
      Brazdil, Pavel  and
      Ali, Felermino  and
      David, Davis  and
      Osei, Salomey  and
      Shehu-Bello, Bello  and
      Lawan, Falalu  and
      Gwadabe, Tajuddeen  and
      Rutunda, Samuel  and
      Belay, Tadesse Destaw  and
      Messelle, Wendimu  and
      Balcha, Hailu  and
      Chala, Sisay  and
      Gebremichael, Hagos  and
      Opoku, Bernard  and
      Arthur, Stephen",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.862/",
    doi = "10.18653/v1/2023.emnlp-main.862",
    pages = "13968--13981",
    abstract = "Africa is home to over 2,000 languages from over six language families and has the highest linguistic diversity among all continents. This includes 75 languages with at least one million speakers each. Yet, there is little NLP research conducted on African languages. Crucial in enabling such research is the availability of high-quality annotated datasets. In this paper, we introduce AfriSenti, a sentiment analysis benchmark that contains a total of {\ensuremath{>}}110,000 tweets in 14 African languages (Amharic, Algerian Arabic, Hausa, Igbo, Kinyarwanda, Moroccan Arabic, Mozambican Portuguese, Nigerian Pidgin, Oromo, Swahili, Tigrinya, Twi, Xitsonga, and Yoruba) from four language families. The tweets were annotated by native speakers and used in the AfriSenti-SemEval shared task (with over 200 participants, see website: https://afrisenti-semeval.github.io). We describe the data collection methodology, annotation process, and the challenges we dealt with when curating each dataset. We further report baseline experiments conducted on the AfriSenti datasets and discuss their usefulness."
}


@inproceedings{adelani-etal-2023-masakhanews,
    title = "{M}asakha{NEWS}: News Topic Classification for {A}frican languages",
    author = "Adelani, David Ifeoluwa  and
      Masiak, Marek  and
      Azime, Israel Abebe  and
      Alabi, Jesujoba  and
      Tonja, Atnafu Lambebo  and
      Mwase, Christine  and
      Ogundepo, Odunayo  and
      Dossou, Bonaventure F. P.  and
      Oladipo, Akintunde  and
      Nixdorf, Doreen  and
      Emezue, Chris Chinenye  and
      Al-azzawi, Sana  and
      Sibanda, Blessing  and
      David, Davis  and
      Ndolela, Lolwethu  and
      Mukiibi, Jonathan  and
      Ajayi, Tunde  and
      Moteu, Tatiana  and
      Odhiambo, Brian  and
      Owodunni, Abraham  and
      Obiefuna, Nnaemeka  and
      Mohamed, Muhidin  and
      Muhammad, Shamsuddeen Hassan  and
      Ababu, Teshome Mulugeta  and
      Salahudeen, Saheed Abdullahi  and
      Yigezu, Mesay Gemeda  and
      Gwadabe, Tajuddeen  and
      Abdulmumin, Idris  and
      Taye, Mahlet  and
      Awoyomi, Oluwabusayo  and
      Shode, Iyanuoluwa  and
      Adelani, Tolulope  and
      Abdulganiyu, Habiba  and
      Omotayo, Abdul-Hakeem  and
      Adeeko, Adetola  and
      Afolabi, Abeeb  and
      Aremu, Anuoluwapo  and
      Samuel, Olanrewaju  and
      Siro, Clemencia  and
      Kimotho, Wangari  and
      Ogbu, Onyekachi  and
      Mbonu, Chinedu  and
      Chukwuneke, Chiamaka  and
      Fanijo, Samuel  and
      Ojo, Jessica  and
      Awosan, Oyinkansola  and
      Kebede, Tadesse  and
      Sakayo, Toadoum Sari  and
      Nyatsine, Pamela  and
      Sidume, Freedmore  and
      Yousuf, Oreen  and
      Oduwole, Mardiyyah  and
      Tshinu, Kanda  and
      Kimanuka, Ussen  and
      Diko, Thina  and
      Nxakama, Siyanda  and
      Nigusse, Sinodos  and
      Johar, Abdulmejid  and
      Mohamed, Shafie  and
      Hassan, Fuad Mire  and
      Mehamed, Moges Ahmed  and
      Ngabire, Evrard  and
      Jules, Jules  and
      Ssenkungu, Ivan  and
      Stenetorp, Pontus",
    editor = "Park, Jong C.  and
      Arase, Yuki  and
      Hu, Baotian  and
      Lu, Wei  and
      Wijaya, Derry  and
      Purwarianti, Ayu  and
      Krisnadhi, Adila Alfa",
    booktitle = "Proceedings of the 13th International Joint Conference on Natural Language Processing and the 3rd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = nov,
    year = "2023",
    address = "Nusa Dua, Bali",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.ijcnlp-main.10/",
    doi = "10.18653/v1/2023.ijcnlp-main.10",
    pages = "144--159"
}



@inproceedings{Muhammad2025AfriHateAM,
  title={AfriHate: A Multilingual Collection of Hate Speech and Abusive Language Datasets for African Languages},
  author={Shamsuddeen Hassan Muhammad and Idris Abdulmumin and Abinew Ali Ayele and David Ifeoluwa Adelani and Ibrahim Said Ahmad and Saminu Mohammad Aliyu and Nelson Odhiambo Onyango and Lilian D. A. Wanzare and Samuel Rutunda and Lukman Jibril Aliyu and Esubalew Alemneh and Oumaima Hourrane and Hagos Tesfahun Gebremichael and Elyas Abdi Ismail and Meriem Beloucif and Ebrahim Chekol Jibril and Andiswa Bukula and Rooweither Mabuya and Salomey Osei and Abigail Oppong and Tadesse Destaw Belay and Tadesse Kebede Guge and Tesfa Tegegne Asfaw and Chiamaka Ijeoma Chukwuneke and Paul Rottger and Seid Muhie Yimam and Nedjma Djouhra Ousidhoum},
  year={2025},
  url={https://api.semanticscholar.org/CorpusID:275515951}
}


@inproceedings{ogundepo-etal-2023-cross,
    title = "Cross-lingual Open-Retrieval Question Answering for {A}frican Languages",
    author = "Ogundepo, Odunayo  and
      Gwadabe, Tajuddeen  and
      Rivera, Clara  and
      Clark, Jonathan  and
      Ruder, Sebastian  and
      Adelani, David  and
      Dossou, Bonaventure  and
      Diop, Abdou  and
      Sikasote, Claytone  and
      Hacheme, Gilles  and
      Buzaaba, Happy  and
      Ezeani, Ignatius  and
      Mabuya, Rooweither  and
      Osei, Salomey  and
      Emezue, Chris  and
      Kahira, Albert  and
      Muhammad, Shamsuddeen  and
      Oladipo, Akintunde  and
      Owodunni, Abraham  and
      Tonja, Atnafu  and
      Shode, Iyanuoluwa  and
      Asai, Akari  and
      Aremu, Anuoluwapo  and
      Awokoya, Ayodele  and
      Opoku, Bernard  and
      Chukwuneke, Chiamaka  and
      Mwase, Christine  and
      Siro, Clemencia  and
      Arthur, Stephen  and
      Ajayi, Tunde  and
      Otiende, Verrah  and
      Rubungo, Andre  and
      Sinkala, Boyd  and
      Ajisafe, Daniel  and
      Onwuegbuzia, Emeka  and
      Lawan, Falalu  and
      Ahmad, Ibrahim  and
      Alabi, Jesujoba  and
      Mbonu, Chinedu  and
      Adeyemi, Mofetoluwa  and
      Phiri, Mofya  and
      Ahia, Orevaoghene  and
      Iro, Ruqayya  and
      Adhiambo, Sonia",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-emnlp.997/",
    doi = "10.18653/v1/2023.findings-emnlp.997",
    pages = "14957--14972",
    abstract = "African languages have far less in-language content available digitally, making it challenging for question answering systems to satisfy the information needs of users. Cross-lingual open-retrieval question answering (XOR QA) systems {--} those that retrieve answer content from other languages while serving people in their native language{---}offer a means of filling this gap. To this end, we create Our Dataset, the first cross-lingual QA dataset with a focus on African languages. Our Dataset includes 12,000+ XOR QA examples across 10 African languages. While previous datasets have focused primarily on languages where cross-lingual QA augments coverage from the target language, Our Dataset focuses on languages where cross-lingual answer content is the only high-coverage source of answer content. Because of this, we argue that African languages are one of the most important and realistic use cases for XOR QA. Our experiments demonstrate the poor performance of automatic translation and multilingual retrieval methods. Overall, Our Dataset proves challenging for state-of-the-art QA models. We hope that the dataset enables the development of more equitable QA technology."
}

@inproceedings{vanmassenhove-etal-2021-machine,
    title = "Machine Translationese: Effects of Algorithmic Bias on Linguistic Complexity in Machine Translation",
    author = "Vanmassenhove, Eva  and
      Shterionov, Dimitar  and
      Gwilliam, Matthew",
    editor = "Merlo, Paola  and
      Tiedemann, Jorg  and
      Tsarfaty, Reut",
    booktitle = "Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume",
    month = apr,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.eacl-main.188/",
    doi = "10.18653/v1/2021.eacl-main.188",
    pages = "2203--2213",
    abstract = "Recent studies in the field of Machine Translation (MT) and Natural Language Processing (NLP) have shown that existing models amplify biases observed in the training data. The amplification of biases in language technology has mainly been examined with respect to specific phenomena, such as gender bias. In this work, we go beyond the study of gender in MT and investigate how bias amplification might affect language in a broader sense. We hypothesize that the {\textquoteleft}algorithmic bias', i.e. an exacerbation of frequently observed patterns in combination with a loss of less frequent ones, not only exacerbates societal biases present in current datasets but could also lead to an artificially impoverished language: {\textquoteleft}machine translationese'. We assess the linguistic richness (on a lexical and morphological level) of translations created by different data-driven MT paradigms {--} phrase-based statistical (PB-SMT) and neural MT (NMT). Our experiments show that there is a loss of lexical and syntactic richness in the translations produced by all investigated MT paradigms for two language pairs (EN-FR and EN-ES)."
}


@inproceedings{bizzoni-etal-2020-human,
    title = "How Human is Machine Translationese? Comparing Human and Machine Translations of Text and Speech",
    author = "Bizzoni, Yuri  and
      Juzek, Tom S  and
      Espa{\~n}a-Bonet, Cristina  and
      Dutta Chowdhury, Koel  and
      van Genabith, Josef  and
      Teich, Elke",
    editor = {Federico, Marcello  and
      Waibel, Alex  and
      Knight, Kevin  and
      Nakamura, Satoshi  and
      Ney, Hermann  and
      Niehues, Jan  and
      St{\"u}ker, Sebastian  and
      Wu, Dekai  and
      Mariani, Joseph  and
      Yvon, Francois},
    booktitle = "Proceedings of the 17th International Conference on Spoken Language Translation",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.iwslt-1.34/",
    doi = "10.18653/v1/2020.iwslt-1.34",
    pages = "280--290",
    abstract = "Translationese is a phenomenon present in human translations, simultaneous interpreting, and even machine translations. Some translationese features tend to appear in simultaneous interpreting with higher frequency than in human text translation, but the reasons for this are unclear. This study analyzes translationese patterns in translation, interpreting, and machine translation outputs in order to explore possible reasons. In our analysis we {--} (i) detail two non-invasive ways of detecting translationese and (ii) compare translationese across human and machine translations from text and speech. We find that machine translation shows traces of translationese, but does not reproduce the patterns found in human translation, offering support to the hypothesis that such patterns are due to the model (human vs machine) rather than to the data (written vs spoken)."
}


@inproceedings{
llm2vec,
title={{LLM2V}ec: Large Language Models Are Secretly Powerful Text Encoders},
author={Parishad BehnamGhader and Vaibhav Adlakha and Marius Mosbach and Dzmitry Bahdanau and Nicolas Chapados and Siva Reddy},
booktitle={First Conference on Language Modeling},
year={2024},
url={https://openreview.net/forum?id=IW1PR7vEBf}
}



@article{Reid2024Gemini1U,
  title={Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context},
  author={Machel Reid and Nikolay Savinov and Denis Teplyashin and Dmitry Lepikhin and Timothy P. Lillicrap and Jean-Baptiste Alayrac and Radu Soricut and Angeliki Lazaridou and Orhan Firat and Julian Schrittwieser and Ioannis Antonoglou and Rohan Anil and Sebastian Borgeaud and Andrew M. Dai and et al.},
  journal={ArXiv},
  year={2024},
  volume={abs/2403.05530},
  url={https://api.semanticscholar.org/CorpusID:268297180}
}



@article{oladipo2024scaling,
  title={Scaling Pre-training Data and Language Models for African Languages},
  author={Oladipo, Akintunde},
  year={2024}
}

@article{Ojo2023HowGA,
  title={How good are Large Language Models on African Languages?},
  author={Jessica Ojo and Kelechi Ogueji and Pontus Stenetorp and David Ifeoluwa Adelani},
  journal={ArXiv},
  year={2023},
  volume={abs/2311.07978},
  url={https://api.semanticscholar.org/CorpusID:265157948}
}


@inproceedings{
kudugunta2023madlad,
title={{MADLAD}-400: A Multilingual And Document-Level Large Audited Dataset},
author={Sneha Kudugunta and Isaac Rayburn Caswell and Biao Zhang and Xavier Garcia and Derrick Xin and Aditya Kusupati and Romi Stella and Ankur Bapna and Orhan Firat},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
year={2023},
url={https://openreview.net/forum?id=Y45ZCxslFx}
}