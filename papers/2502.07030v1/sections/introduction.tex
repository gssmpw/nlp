\section{Introduction}

Recent years have seen a surge of interest in photorealistic 3D human avatars, motivated by potential applications in teleconferencing, virtual assistants, entertainment and virtual reality experiences. Much of the latest research has focused on dynamic neural fields, such as deformable neural radiance fields (NeRFs). The main advantage offered by neural radiance fields is that they do not require explicit modeling of complex geometric details or the reflective properties of materials. However, even the more computationally efficient NeRF models generally demand a significant amount of GPU VRAM, as well as custom rendering pipelines based on general-purpose GPU libraries such as CUDA. This limits their usage in resource-constrained environments, such as mobile devices, smart TVs and car infotainment systems. It also restricts their use in environments with limited GPU programming capabilities, such as web applications. These drawbacks have limited their attractiveness for real-world product applications.

In this work, we present PrismAvatar, a novel model for dynamic 3D neural head avatars on edge devices. Our model maintains high rendering speed and compatibility with the constrained computing environment of mobile device browsers by using only the triangular mesh rendering pipeline of the GPU at inference time. At training time, however, we use a novel hybrid mesh-volume 3D representation in which the complex geometry of the hair is learned as a deformable neural radiance field. The deformation of the NeRF is controlled by a dense prism lattice which is rigged to move together with a 3D morphable model of the head. Grounding our model in a statistical 3DMM helps to ensure that our head avatars have plausible head shapes, while also allowing the model to be animated efficiently using a combination of blendshapes and linear blend skinning. It also allows us to leverage the strengths of mesh rendering for much of the face, thus avoiding NeRF artifacts such as floaters in the face region. For mobile device compatibility and efficient rendering at inference time, we take inspiration from recent work on static NeRF rendering for mobile devices~\cite{chen2023mobilenerf} to distill the canonical radiance field into a triangle soup with an associated neural texture. We implement animation and deferred neural rendering of these triangles using the basic vertex and fragment shading capabilities available on most  mobile devices and smart TVs.

In summary, our main contributions are:
\begin{enumerate}
    \item A technique for constructing a novel prism lattice structure that controls a deformable NeRF, allowing it to be animated by a 3D morphable model.
    \item A novel hybrid rendering approach to 3D head avatar reconstruction, which leverages the strengths of both surface and volume rendering. We demonstrate that this 3D avatar can be distilled into a purely mesh-based representation, allowing it to be rendered in real-time without significant loss of quality in constrained environments such as browsers on edge devices.
\end{enumerate}
