\section{Introduction}
\label{sec:intro}
%
\begin{figure*}[t]
    \centering
    \includegraphics[width=1.\linewidth, trim=0 191.25 0 190.25, clip]{gfx/gimmick_fig1_D.pdf}
    \caption{An overview of the \dsname benchmark and its tasks.}
    \label{fig:figure1}
\end{figure*}

%
Recently, proprietary as well as open-weight Large Vision-Language Models (LVLMs)~\cite[\textit{inter alia}]{openai2023gpt4v,liu2023llava,wang2024qwen2vl,chen2024internvl} have attracted marked attention due to their broad applicability across various domains.
%
Several large-scale holistic benchmarks~\cite{duan2024vlmevalkit,yue2023mmmu,fu2023mme} demonstrate LVLMs' remarkable performances in a wide range of multimodal tasks. % ranging from classical tasks like visual question answering (VQA) in several variations \cite{ren2015vqa,mathew2021docvqa} to complex multistep reasoning tasks~\cite{yue2023mmmu,fu2023mme}.
%
However, most benchmarks concentrate on Western-centric English tasks, and multilingual benchmarks~\cite{ahuja2023megaverse,schneider-sitaram-2024-m5} reveal a significant deterioration in performance on non-English tasks.
%
While multilingualism is essential for globally equitable AI, \emph{multi-culturalism}~\cite{gabriel2020aivalues,adilazuarda-etal-2024-towards} is equally crucial for models to reflect and respect the diverse cultural backgrounds of users worldwide.
%
In this context, it has been shown that current LLMs~\cite{myung2024blend,chiu2024culturalbench} and LVLMs suffer in tasks involving knowledge from non-Western cultures. However, the scope of existing multimodal cultural studies is still severely limited:
%
Existing research often focuses only on specific concepts like food or dance~\cite{winata2024worldcuisines,burda2024culturally}, covers a limited number of cultures~\cite{urailertprasert-etal-2024-sea,baek2024kviscuit}, evaluates only a small selection of LVLM models~\cite{cao2024exploring,nayak-etal-2024-benchmarking}, or tests only a single combination of input modalities.% (see Table~\ref{tab:rw:compare}).

\noindent To address these gaps, we introduce \dsname, a comprehensive evaluation framework assessing 31 state-of-the-art models, ranging from proprietary LVLMs to open-weight LLMs and LVLMs of all sizes---from 500M to 78B parameters---across multiple model families.
%
It comprises six tasks built on three novel datasets that contain 728 unique cultural events or facets (CEFs) from 144 countries in six global macro-regions and target both high-level and nuanced cultural knowledge through multimodal and unimodal tasks.
%
Our VQA tasks span a total of $57$ cultural aspects (see~\S\ref{appedix:sec:sivqa:aspects})
%
Ultimately, \dsname enables us to answer four research questions:

\noindent\textbf{(RQ1) \emph{Are there regional biases in LLMs' and LVLMs' cultural knowledge, and if so, which?}} For the most complex tasks, we observe consistent cultural regional biases (up to 14.72pp difference between instances targeting Western Europe \& North America vs. Subsaharian Africa; \S\ref{sec:analyses:a1_bias}) -- even for the largest models. For less complex tasks, these differences flatten out. 

\noindent\textbf{(RQ2) \emph{To what degree does model size influence performance?}} % removing characteristics
We show that increasing the number of parameters significantly boosts performance on complex tasks, with larger models exhibiting less regional biases~(\S\ref{sec:analyses:a2_model}). Still, even the largest models still struggle with nuanced cultural understanding.

\noindent\textbf{(RQ3) \emph{How do input modalities affect cultural understanding?}} We observe that providing input in multiple modalities typically leads to the best results, as models leverage the cultural cues present in the visual inputs we provide (\S\ref{sec:analyses:a3_modality}). Interestingly, on text-only tasks, LVLMs perform consistently worse than their LLM backbones, indicating a loss of cultural knowledge during integration training. 

\noindent\textbf{(RQ4) \emph{What is the influence of external cultural cues?}} We demonstrate that providing country information consistently guides the models towards better answers, especially for regions for which the models perform poorly (\S\ref{sec:analyses:a4_external}). 
%
%\noindent
%Although strong correlations between a model's performance and its size, as well as a large gap between proprietary and open-weight models, are evident, our analyses reveal a pronounced bias favoring Western and disadvantaging African cultures across all tasks and models.
%
%
%
Overall, with \dsname, we hope to encourage more research on culturally-aware and more globally-inclusive AI. %provide an additional building block towards more research on this issue.
%