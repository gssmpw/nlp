\documentclass[11pt]{article}
\pdfoutput=1
\usepackage[margin=1in]{geometry}
\usepackage[onehalfspacing]{setspace}
\usepackage{xcolor}
\usepackage{amsmath}
\usepackage{natbib}
\usepackage{hyperref}
\usepackage[capitalize]{cleveref}
\usepackage{graphicx,amssymb}
\usepackage{amsthm}
\usepackage{float}
\usepackage{xfrac}
\usepackage{xspace}
\usepackage{paralist}
\usepackage{libertine}
\usepackage{enumerate,multicol,multirow}
\usepackage{cases}
\usepackage{caption,subcaption}

\usepackage{todonotes}
\newtheorem{assumption}{Assumption}
\DeclareMathOperator*{\argmin}{argmin}
\DeclareMathOperator*{\argmax}{argmax}
\DeclareMathOperator{\poly}{poly}
\DeclareMathOperator{\polylog}{polylog}
\DeclareRobustCommand\iff{\;\Longleftrightarrow\;}
\DeclareMathOperator{\Span}{Span}
\DeclareMathOperator{\Graph}{Gra}


\newtheorem{definition}{Definition}[section]
\newtheorem{corollary}{Corollary}[section]
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}{Lemma}[section]
\newtheorem{fact}{Fact}[section]
\newtheorem{observation}{Observation}[section]
\newtheorem{claim}{Claim}[section]
\newtheorem{proposition}{Proposition}[section]
\newtheorem{remark}{Remark}
\newtheorem{problem}{Problem}

\newcommand{\notshow}[1]{{}}
\newcommand{\AutoAdjust}[3]{{ \mathchoice{ \left #1 #2  \right #3}{#1 #2 #3}{#1 #2 #3}{#1 #2 #3} }}
\newcommand{\Xcomment}[1]{{}}
\newcommand{\eval}[1]{\left.#1\vphantom{\big|}\right|}
\newcommand{\InParentheses}[1]{\AutoAdjust{(}{#1}{)}}
\newcommand{\InBrackets}[1]{\AutoAdjust{[}{#1}{]}}
\newcommand{\InAngles}[1]{\AutoAdjust{\langle}{#1}{\rangle}}
\newcommand{\InNorms}[1]{\AutoAdjust{\|}{#1}{\|}}

\newcommand{\xmark}{\ding{55}}\renewcommand{\P}{\mathcal{P}}
\newcommand{\R}{\mathbbm{R}} 
\newcommand{\N}{\mathcal{N}}

\newcommand{\X}{\mathcal{X}}
\newcommand{\Y}{\mathcal{Y}}
\newcommand{\Z}{\mathcal{Z}}
\newcommand{\C}{\mathcal{C}}

\newcommand{\half}{\frac{1}{2}}
\newcommand{\prox}{\mathbf{Prox}}
\newcommand{\PP}{\mathbf{PP}}
\newcommand{\dg}{\mathsf{dg}}
\newcommand{\ham}{\mathsf{H}}
\newcommand{\Dom}[1]{\mathbf{dom}~#1}
\newcommand{\hx}{\hat{x}}
\newcommand{\hy}{\hat{y}}
\newcommand{\hz}{\hat{z}}
\newcommand{\hZ}{\widehat{\Z}}
\newcommand{\hF}{\widehat{F}}
\newcommand{\hH}{\widehat{H}}
\newcommand{\oalpha}{\overline{\alpha}}
\newcommand{\obeta}{\overline{\beta}}
\newcommand{\ba}{\overline{a}}
\newcommand{\bb}{\overline{b}}
\newcommand{\bz}{\overline{z}}
\newcommand{\be}{\overline{e}}
\newcommand{\bZ}{\overline{Z}}
\newcommand{\bF}{\overline{F}}
\newcommand{\bx}{\overline{x}}
\newcommand{\bw}{\overline{w}}
\newcommand{\boldx}{\boldsymbol{x}}
\newcommand{\boldy}{\boldsymbol{y}}
\newcommand{\boldzero}{\boldsymbol{0}}
\newcommand{\hw}{\hat{w}}
\newcommand{\hS}{\widehat{S}}
\newcommand{\supp}{\mathbf{Supp}}
\newcommand{\newpoint}[1]{#1_{\mathsf{new}}}
\newcommand{\ind}{\mathbbm{1}}
\newcommand{\indSet}{\mathbbm{I}}
\newcommand{\real}{\mathbbm{R}}
\newcommand{\ha}{\hat{a}}
\newcommand{\hb}{\hat{b}}
\newcommand{\tar}{\textsc{Target}}
\newcommand{\gap}{\textsc{Gap}}
\newcommand{\sos}{\textsc{SOS}}
\newcommand{\LHSI}{\text{LHS of Inequality}}
\newcommand{\by}{\boldsymbol{y}}
\newcommand{\ball}[2]{\mathcal{B}({#1},{#2})}


\newcommand{\LHSE}{\text{LHS of Equation}}

\newcommand{\RHSE}{\text{RHS of Equation}}

\newcommand{\Term}{\text{Expression}}


\newenvironment{prevproof}[2]{\noindent {\bf {Proof of {#1}~\ref{#2}:}}}{$\hfill \blacksquare$}

\newenvironment{nalign}{    
\begin{equation}
    \begin{aligned}
}{
    \end{aligned}
    \end{equation}
    \ignorespacesafterend
}



\newcommand{\LF}{\textsc{Left}}
\newcommand{\RT}{\textsc{Right}}
















\newcommand{\setsize}[1]{{\left|#1\right|}}

\newcommand{\floor}[1]{
{\lfloor {#1} \rfloor}
}
\newcommand{\bigfloor}[1]{
{\left\lfloor {#1} \right\rfloor}
}

\newcommand{\given}{\,\vert\,}
\newcommand{\wgiven}{\,\vert\,}

\newcommand{\prob}[2][]{\text{\bf Pr}\ifthenelse{\not\equal{}{#1}}{_{#1}}{}\!\left[{\def\givenn{\middle|}#2}\right]}
\newcommand{\expect}[2][]{\text{\bf E}\ifthenelse{\not\equal{}{#1}}{_{#1}}{}\!\left[{#2}\right]}


\newcommand{\tparen}{\big}
\newcommand{\tprob}[2][]{\text{\bf Pr}\ifthenelse{\not\equal{}{#1}}{_{#1}}{}\tparen[{\def\given{\tparen|}#2}\tparen]}
\newcommand{\texpect}[2][]{\text{\bf E}\ifthenelse{\not\equal{}{#1}}{_{#1}}{}\tparen[{\def\given{\tparen|}#2}\tparen]}


\newcommand{\sprob}[2][]{\text{\bf Pr}\ifthenelse{\not\equal{}{#1}}{_{#1}}{}[#2]}
\newcommand{\sexpect}[2][]{\text{\bf E}\ifthenelse{\not\equal{}{#1}}{_{#1}}{}[#2]}


\newcommand{\lbr}[1]{\left\{#1\right\}}
\newcommand{\rbr}[1]{\left(#1\right)}
\newcommand{\cbr}[1]{\left[#1\right]}



\newcommand{\suchthat}{\,:\,}


\newcommand{\partialx}[2][]{{\tfrac{\partial #1}{\partial #2}}}
\newcommand{\nicepartialx}[2][]{{\nicefrac{\partial #1}{\partial #2}}}
\newcommand{\dd}{{\,\mathrm d}}
\newcommand{\ddx}[2][]{{\tfrac{\dd #1}{\dd #2}}}
\newcommand{\niceddx}[2][]{{\nicefrac{\dd #1}{\dd #2}}}
\newcommand{\grad}{\nabla}

\newcommand{\symdiff}{\triangle}
\newcommand{\abs}[1]{\left|#1\right|}
\newcommand{\indicate}[1]{\mathbf{1}\left[#1\right]}
\newcommand{\reals}{\mathbb{R}}
\newcommand{\posreals}{\reals_+}



\newcommand{\virtualval}{\varphi}
\newcommand{\tmpname}{virtual value}
\newcommand{\LLtmpname}{Virtual Value}
\newcommand{\Ltmpname}{Virtual value}
\newcommand{\menualloc}{\menuentry^{\alloc}}
\newcommand{\menupay}{\menuentry^{\pay}}
\newcommand{\fav}{\mathsf{Fav}}
\newcommand{\val}{v}
\newcommand{\belief}{\nu}
\newcommand{\smark}{\ding{117}}
\newcommand{\sigprob}{ r\InParentheses{s} }
\newcommand{\sigprobsingle}{ r }
\newcommand{\vals}{V}
\newcommand{\menu}{\mathsf{MENU}}
\newcommand{\genmenu}{\Phi}
\newcommand{\menuentry}{\phi}
\newcommand{\dist}{F}
\newcommand{\density}{f}
\newcommand{\util}{u}
\newcommand{\alloc}{x}
\newcommand{\pay}{p}
\newcommand{\experiment}{\sigma}
\newcommand{\signal}{s}
\newcommand{\signals}{S}
\newcommand{\sets}{\mathcal{S}}
\newcommand{\dpf}{{\rm FEA}}
\newcommand{\dps}{{\rm FEA}}
\newcommand{\mech}{M}
\newcommand{\mechs}{\mathcal{M}}
\newcommand{\rev}{{\rm Rev}}
\newcommand{\pprev}{{\rm PP\text{-} Rev}}
\newcommand{\optrev}{{\rm OPT\text{-}Rev}}
\newcommand{\optwel}{{\rm OPT\text{-}Wel}}
\newcommand{\wel}{{\rm Wel}}
\newcommand{\indic}{\mathbf{1}}
\newcommand{\signalStructure}{I}
\newcommand{\probname}{optimal $k$-signal }
\newcommand{\graph}{G}
\newcommand{\edge}{e}
\newcommand{\edges}{E}
\newcommand{\posterior}{\mu}
\newcommand{\weight}{w} 
\setcitestyle{authoryear}

\begin{document}

\begin{titlepage}
\title{Information Disclosure Makes Simple Mechanisms Competitive}




\author{Yang Cai\thanks{Yang Cai was supported by the NSF Awards CCF-1942583 (CAREER) and CCF-2342642.}\\ \normalsize Department of Computer Science \\ \normalsize Yale University \\ \normalsize\href{mailto:yang.cai@yale.edu}{yang.cai@yale.edu}
\and Yingkai Li\\ \normalsize Department of Economics \\ \normalsize National University of Singapore \\
\normalsize \href{mailto:yk.li@nus.edu.sg}{yk.li@nus.edu.sg}
\and Jinzhao Wu\thanks{Jinzhao Wu was supported by the NSF Awards CCF-1942583 (CAREER), CCF-2342642, and a CADMY Research Fellowship.}\\ \normalsize Department of Computer Science \\ \normalsize Yale University \\ \normalsize\href{mailto:jinzhao.wu@yale.edu}{jinzhao.wu@yale.edu}} 

\date{}

\maketitle



\begin{abstract}
In classical mechanism design, the prevailing assumption is that the information structure about agents' types is \emph{exogenous}. This assumption introduces complexity, especially with multi-dimensional agent types, leading to mechanisms that, while optimal, may appear complex and unnatural. Furthermore, \citet{hart2019selling} show that the gap between the performance of any simple mechanism and the optimal solution could be potentially unbounded. We challenge this conventional view by showing that \emph{simple mechanisms can be highly competitive} if the information structure is \emph{endogenous} and can be influenced by the designer.

   
We study a multi-dimensional generalization of a single-dimensional model proposed by~\citet{bergemann2007information}, where the designer can shape the information structure via  \emph{information disclosure}. Specifically, we consider a fundamental multi-dimensional mechanism design problem, where a seller is selling $m$ items to a single \emph{unit-demand} buyer to maximize her revenue. The buyer's values can be arbitrarily correlated across the items. Our main result shows that, following an appropriately chosen information disclosure scheme, \emph{item pricing}, i.e., set a take-it-or-leave-it price on each item is highly competitive and guarantees to attain at least \emph{$50.1\%$ of the optimal revenue}. To our knowledge, this is the first result demonstrating the (approximate) optimality of simple mechanisms in this extensively studied multi-dimensional setting, without making any assumptions about the buyer’s value distribution. We believe our result not only demonstrates the power of information disclosure in enhancing the performance of simple mechanisms but also suggests a new framework for reevaluating their efficacy in multi-dimensional settings.
\end{abstract}




\end{titlepage}














\section{Introduction}
\label{sec:intro}

Mechanism design for multi-item auctions is one of the most challenging problems in economic theory. 
There are extensive studies on the approximations of simple mechanisms in environments with independent private values \citep[e.g.,][]{chawla2010multi,babaioff2020simple,yao2014n,cai2016duality} but little is known for environments with correlated values.\footnote{Several exceptions include \citet{carroll2017robustness} and \citet{haghpanah2021pure} for additive valuations where \citet{carroll2017robustness} shows selling separately is robustly optimal when the seller does not know the correlation structure, and \citet{haghpanah2021pure} provide sufficient conditions on the correlation structure such that pure bundling is optimal.} 
However, correlation plays a crucial role in many multi-item auctions. For example, for hotel pricing in online platforms, each consumer's values for different hotels are correlated through their locations, their brands, their policies regarding smoking, and etc. 
As shown in \citet{hart2019selling}, even if the principal only hopes to approximate the optimal revenue, in auction environments with correlated values, the approximately optimal mechanism still requires unbounded menu size and may not admit simple representations. 
Our paper addresses this issue by providing theoretical justifications for simple mechanisms, such as item pricing, in auction environments where the buyer has unit-demand for items with \emph{correlated values}. This framework applies to scenarios like hotel pricing, where a consumer selects only one hotel for their travel dates.


We first observe that in many practical applications, the design of optimal mechanisms is not an isolated task. It often is part of a larger market where the principal can also influence the primitives in auction environments, such as the buyer's value distribution for the items. In particular, our paper focuses on a joint design problem where the principal can design both the information disclosure policy to affect the buyer's posterior value of the items and the mechanisms for selling these items. For example, online markets such as Priceline and Hotwire adopt opaque pricing strategies, offering discounts on hotel bookings while revealing only partial information---such as star ratings, a sample of reviews from previous consumers, or a general location---before purchase.
Similarly, in housing or used car markets, dealers can offer private inspections to disclose quality information to potential buyers. 

Formally, we study a multi-dimensional extension of the model introduced by \citet{bergemann2007information} for the joint design problem. In this model, a seller offers $m$ items for sale to a \emph{unit-demand} buyer with correlated valuations for the items. While the prior distribution is initially common knowledge between the seller and the buyer, the buyer's actual valuation profile remains unknown to both parties. Instead, the seller can design Blackwell experiments that allow the buyer to privately learn their own values. These Blackwell experiments, or equivalently signal structures, map true valuation profiles to distributions over signals. It’s important to note that although the seller designs these experiments, the signals generated are privately observed by the buyers. This aligns with applications such as private inspections, where the seller controls the inspection method but the outcomes are observed only by the buyers. 

Following the signals, the seller commits to a mechanism for selling the items. This mechanism must satisfy two key constraints: it must be incentive compatible, meaning it incentivizes the buyer to truthfully report their posterior valuation profile based on the signal, and individually rational, ensuring the buyer has non-negative expected utility when participating. The seller’s objective is to \emph{jointly} design the signal structures and the subsequent mechanism to maximize the expected payments collected from the buyer, subject to these constraints. Our paper focuses on the following question: 
\begin{align*}\label{eq:question1}
\emph{Are simple mechanisms competitive in the joint design problem?} \tag{*}
\end{align*}
\subsection{Our Contributions}
We show that in the aforementioned joint design problem, \emph{item pricing}, when paired with an appropriately chosen signal structure, is competitive,\footnote{We say a mechanism is competitive, if it extracts at least a constant fraction of the optimal revenue.} extracting \emph{strictly more than $\frac{1}{2}$} of the optimal revenue. This result stands in stark contrast to the findings of~\citet{hart2019selling}, where the information structure is exogenous.

Specifically, \citet{hart2019selling} demonstrate that without information disclosure, item pricing can be arbitrarily worse than the optimal mechanism, which employs complex lotteries. In contrast, our result shows that with an appropriately chosen information disclosure policy, simple mechanisms such as item pricing are already competitive. To provide intuition, we present three examples to highlight both the strengths and limitations of item pricing in this setting, as well as the complex landscape of the optimal solution. 


\paragraph{Example 1: Strength of information disclosure + item pricing.} In this example, there are two items for sale, and the buyer has three possible valuation profiles:
\begin{equation}
    (v_1, v_2) =
    \begin{cases}
      (10,0) & \text{with probability } 0.3 \\
      (6,7) & \text{with probability } 0.3\\
      (0,10) & \text{with probability } 0.4
    \end{cases}
  \end{equation}

If the principal cannot design the information structure, they benefit from using lotteries, as these provide additional instruments for price discrimination. Specifically, the optimal mechanism involves offering item $1$ at a price of $10$ to buyers with the valuation profile $(10, 0)$, item $2$ at a price of $10$ to those with the profile $(0, 10)$, and a lottery $(\frac{1}{3}, \frac{2}{3})$ at a price of $\frac{20}{3}$ to buyers with the profile $(6, 7)$. The expected revenue under this lottery mechanism is $9$. 

Notably, offering a lottery to buyers with the valuation profile $(6, 7)$ is particularly effective, as these buyers value both items similarly. Using a lottery helps reduce the information rent for buyers with the valuation profile $(0, 10)$. However, if the principal can jointly design the information structure, they can disclose information by revealing only whether the buyer’s valuation profile is $(10, 0)$ or within the set ${(6, 7), (0, 10)}$. Under this information structure, the buyer is informed about their most preferred item but cannot distinguish between the profiles $(6, 7)$ and $(0, 10)$ when they prefer the second item.

After pooling these profiles, the principal offers item $2$ at a price of $\frac{61}{7}$ and item $1$ at a price of $10$. From the buyer’s perspective, if they know their valuation profile is $(10, 0)$, they will purchase item $1$. If they learn their valuation profile lies within ${(6, 7), (0, 10)}$, they will purchase item $2$. Hence, this item-pricing mechanism sells item $1$ with probability $0.3$ and item $2$ with probability $0.7$, generating an expected revenue of $9.1$, which exceeds the $9$ achieved by the lottery mechanism. By pooling these types together, the need for lotteries to reduce information rent is eliminated while maintaining high allocation welfare.





In the above example, when the principal can jointly design the information structures, they can extract the full surplus through horizontal disclosure—i.e., by informing the buyer which item they prefer the most (see \cref{def:horizontal})—followed by item pricing. In~\Cref{sub:full_surplus_multi}, we identify that a particular form of weakly negative correlation across item values suffices to guarantee that horizontal disclosure combined with item pricing extracts the full surplus and, therefore, constitutes the optimal mechanism.

A special case satisfying this condition is when the values are independently distributed. Intuitively, when the values are negatively correlated, horizontal disclosure ensures that the buyer’s posterior value for item $i$ is highest when they receive a signal indicating that item $i$ is the highest value item. By offering prices equal to these posterior values for each item $i$, the principal extracts the full surplus.

However, full surplus extraction and the optimality of horizontal disclosure do not hold in general. In particular, when values are correlated across items, disclosing which item the buyer values the most may inadvertently reveal additional information, resulting in high information rent for the buyer and leading to suboptimal outcomes. We illustrate this in our second example.

\paragraph{Example 2: No Full Surplus Extraction.} In this example, there are two items for sale, and the buyer has two possible valuation profiles:

\begin{equation}
    (v_1, v_2) =
    \begin{cases}
      (5,4) & \text{with probability } \frac{1}{2} \\
      (9,10) & \text{with probability } \frac{1}{2}
    \end{cases}
  \end{equation}
If the principal uses horizontal disclosure, the buyer learns exactly which valuation profile they have. Under this information structure, the optimal mechanism is to post a price of $5$ for item 
$1$ and $6$ for item $2$, yielding an expected revenue of $5.5$.

In contrast, by withholding all information and posting a price of $7$ for item $2$ and an infinite price for item $1$, item $2$ is sold with probability $1$, generating an expected revenue of $7$, which exceeds $5.5$. Moreover, while this mechanism is optimal for the principal, the expected revenue remains strictly less than the optimal welfare of $7.5$.



From the first two examples, it may seem that item pricing is always the optimal mechanism as long as the principal chooses an appropriate information structure. Unfortunately, this is not the case. We show that, when there are three or more items, item-pricing mechanisms may not be optimal for revenue maximization. 

\paragraph{Example 3: Item Pricing is Suboptimal.} In this example, there are three items for sale, and the buyer has two possible valuation profiles:

\begin{equation}
    (v_1, v_2, v_3) =
    \begin{cases}
      (0,20,9) & \text{with probability } \frac{1}{2} \\
      (4,0,5) & \text{with probability } \frac{1}{2}
    \end{cases}
  \end{equation}
We show that the principal strictly benefits from using lotteries to sell the items in the above example, even when they can jointly design the information structures. The suboptimality is established through a connection to a Bayesian persuasion problem~\citep{kamenica2011bayesian}, which we illustrate in details in~\cref{sub:Suboptimality_of_Item_Pricing}. This final example offers a glimpse into the complex nature of the optimal solution to our problem. Interestingly, we have neither been able to prove nor disprove the optimality of item pricing for selling two items. We conjecture that item pricing is indeed optimal when only two items are for sale and leave this as an open problem.

Nevertheless, we show that \emph{item pricing remains competitive} regardless of the number of items. Specifically, mechanisms employing \emph{coarse horizontal disclosure}—a generalization of horizontal disclosure—and \emph{item pricing} achieve at least $50.17\%$ of the optimal revenue. Additionally, the principal can still guarantee half of the optimal revenue even when restricted to uniform pricing.
We also show that this bound is tight for uniform pricing. 
Naturally, the approximation weakly improves if the principal can use multiple prices, and our results show that it strictly improves even when the principal uses only two prices. 




\subsection{Related Work}
\label{sub:literature}
The papers that are closest to us are the ones on information design in auctions. 
For selling a single item, \citet{bergemann2007information} show that the revenue optimal information structure is partitional. 
However, \citet{cai2024algorithmic} show that computing the optimal partition is NP-hard, and they provide a PTAS for computing the optimal partition. 
The design of optimal information structures in mechanisms has also been considered for second-price auctions \citep{Bergemann2022Optimal}, bilateral trade \citep{schottmuller2023optimal}
and non-linear pricing \citep{bergemann2022screening}.
We consider the design of optimal information structures in multi-dimensional environments and show that the ability to design information structures makes simple mechanisms competitive. 

There is an extensive study for providing approximation guarantee of simple mechanisms in auctions environments for selling a single-item \citep[e.g.,][]{bulow1989simple,hartline2009simple,yan2011mechanism,alaei2019optimal,jin2019tight,feng2019optimal,beyhaghi2021improved,feng2023simple}
or multiple items with combinatorial values \citep[e.g.,][]{chawla2010multi,chawla2010power,babaioff2020simple,hart2017approximate,cai2016duality,cai_simple_2017,cai_computing_2022, cai_simultaneous_2023,daskalakis_multi-item_2022, babaioff2017menu}. 
For combinatorial auctions, these papers focus exclusively on settings with independent item values. In contrast, \citet{hart2019selling} show that when item values are correlated, even in the case of selling just two items to a single buyer, the revenue gap between the optimal mechanism and simple mechanisms, such as item pricing, can be unbounded.
Recently, \citet{chawla2019buy} consider the buy-many model for selling multiple items with correlated valuations to a unit-demand buyer, where the buyer can make multiple purchases from the menu offered from the seller. The authors show that item pricing achieves an $O(\log m)$-approximation to the optimal revenue. 

The simplicity notion we adopted in our paper is the simplicity in the auction format, such as item pricing for selling multiple items \citep{carroll2017robustness} or linear contracts in contracting environments \citep{carroll2015robustness}.
This is different from the requirement for strategic simplicity such as dominant strategy-proof \citep{chung2007foundations}, strategy-proof based on first order reasoning \citep{borgers2019strategically} or obviously strategy-proof \citep{li2017obviously}. 

The idea that endogenous information makes simple mechanism competitive has also been observed in other auction environments where the endogeneity arises since the buyers are acquiring information optimally. 
For example, with optimal buyer learning, \citet{deb2021multi} show that bundling is optimal for selling multiple items with additive valuations under the exchangeable prior assumption, 
and \citet{li2022selling} shows that selling full information using posted pricing is a 2-approximation to the optimal. 
 \section{Model}
\label{sec:model}

We consider the problem of selling $m$ heterogeneous item to a buyer. 
The buyer has private value $\val = (\val_1,\dots,\val_m)$ drawn from potentially correlated distribution $\dist$, 
where $\val_i\in \reals_{+}$ is the buyer's value for item $i$ for any $i\in[m]$.
Let $\vals\subseteq \reals^m_{+}$ be the support of distribution~$\dist$. 
To simplify the exposition, we assume that $\dist$ is a discrete distribution with finite support size $|\vals|$.\footnote{All results in our paper extend for continuous distributions as well. }
Let $\density$ be the probability mass function. 
For any item $i$, let $\dist_i$ be the marginal distribution over values for item $i$ and let $\vals_i$ be the support of distribution~$\dist_i$. 



\paragraph{Information Structures}
In contrast to classic auction settings where the buyer is privately informed about his values for the items, 
the buyer in our model is initially uninformed and relies on the information structure designed by the seller for learning his values. 
Specifically, the seller can commit to a information structure $(\signals,\experiment)$ 
where~$\signals$ is a measurable signal space
and $\experiment: \vals \to \Delta(\signals)$ is a mapping from values to signals. 
The buyer privately observes the realized signal $\signal\in\signals$
and updates his belief according to the Bayes' rule. 

For any signal $\signal\in\signals$, let \( \sigprob \) denote the ex-ante probability of receiving a specific signal~$\signal$, and \( \belief(\signal) \) represent the buyer's posterior mean values upon receiving signal~$\signal$. 
Furthermore, \( \belief_i(\signal) \) specifies the \(i\)-th coordinate in \( \belief(\signal) \).
That is, 
\begin{align*}
   \sigprob = \expect[\val \sim \dist]{\prob[\signal' \sim \experiment\InParentheses{\val}]{\signal = \signal'}} \text{ and }  
   \belief_i\InParentheses{\signal} = \expect[\val \sim \dist]{\expect[\signal' \sim \experiment\InParentheses{\val}]{\val_i \given \signal = \signal'}} \text{ for all } i\in [m]. 
\end{align*}


\paragraph{Agent's Utilities}
In this paper, we assume that the agent has unit demand for the item. 
Moreover, after receiving the signal from the mechanism, the agent must make a consumption choice before the realization of the values to enjoy the utility.\footnote{For instance, when the agent books hotel rooms for their travel destination, the values are realized only after staying at a single hotel room for each night. } 
That is, for any realized allocation $\alloc\in\{0,1\}^m$, the utility of the agent with posterior value $\belief$ for receiving allocation $\alloc$ while paying price $\pay$ is 
\begin{align*}
\util(\alloc,\pay;\belief) = \max_{i\in[m]} \belief_i\alloc_i - \pay.
\end{align*}
Given such unit-demand utility of the agent, we focus on mechanisms with allocation $x\in [0,1]^m$ such that $\sum_i x_i\leq 1$.
Moreover, for any (random) allocation $x\in [0,1]^m$, the expected utility of the agent is
\begin{align*}
\util(\alloc,\pay;\belief) = \sum_{i\in[m]} \belief_i\alloc_i - \pay
= \expect[v\sim\belief]{\sum_{i\in[m]} v_i\alloc_i} - \pay.
\end{align*}
Finally, we omit $\belief$ in the notation when the value of the agent is clear from context. 


\paragraph{Mechanisms}
A mechanism $\mech=((\signals,\experiment), \alloc,\pay)$ is a tuple containing 
an information structure $(\signals,\experiment)$, 
an allocation rule $\alloc : \signals \to [0,1]^m$
and a payment rule $\pay : \signals \to \reals$. 
Mechanism~$\mech$ is 
\emph{incentive compatible} (IC) if 
\[\expect[v\sim F,s\sim \sigma(v)]{\util(\alloc(\signal), \pay(\signal); \belief(\signal)) \given \signal}\ge \expect[v\sim F,s\sim \sigma(v)]{\util(\alloc(\signal'), \pay(\signal'); \belief(\signal)) \given \signal}\]
for all $\signal,\signal'\in\signals$.
Moreover, this mechanism is \emph{individually rational} (IR) if
\begin{align*}
\expect[v\sim F,s\sim \sigma(v)]{\util(\alloc(\signal), \pay(\signal); \belief(\signal)) \given \signal} \geq 0
\end{align*}
for all $\signal\in\signals$. 
To simplify the notation, we use $\expect[\dist,\experiment]{\cdot}$ to denote $\expect[v\sim F,s\sim \sigma(v)]{\cdot}$, and we also omit $\dist$ in $\expect[\dist,\experiment]{\cdot}$
when it is clear from context. 





For any IC-IR mechanism $\mech$, we denote its expected revenue as 
\begin{align*}
\rev(\mech) 
= \expect[\dist,\experiment]{\pay(\signal)}
\end{align*}
and its expected welfare as 
\begin{align*}
\wel(\mech) = \expect[\dist,\experiment]{\sum_{i\in[m]}\val_i\cdot\alloc_i(\signal)}. 
\end{align*}
The optimal revenue and optimal welfare are denoted as 
\begin{align*}
\optrev = \max_{\mech \text{ is IC-IR}} \rev(\mech) 
\quad\text{and}\quad
\optwel = \max_{\mech \text{ is IC-IR}} \wel(\mech).
\end{align*}

By the revelation principle, it is without loss to focus on IC-IR mechanisms. 
The objective of the seller is to maximize the expected revenue. 

In the following, we introduce an alternative representation of an IC-IR mechanism, referred to as its menu representation.

\label{subapx:menu}
\begin{definition}[Menu Representation of Mechanism \(\mech\)]
\label{def:menu}
Given any IC-IR mechanism \(\mech=((\signals,\experiment), \alloc,\pay)\), we define its \textit{menu} as the set of possible outcomes:
\[
\menu(\mech) := \left\{\rbr{\alloc(\signal),\pay(\signal)} \given \signal \in \signals \right\} \cup \lbr{\rbr{\rbr{0,0,\cdots, 0}, 0}} \subseteq [0, 1]^m \times \mathbb{R}_{+}. 
\]
\end{definition}







For any menu, denoted as \(\genmenu\), and for any menu entry $\menuentry\in\genmenu$, we use \(\menualloc \in [0, 1]^m\) and \(\menupay \in \mathbb{R}_{+}\) to respectively represent the allocation and the payment of the \(i\)-th entry in the menu. Note that for the allocation to be feasible, we have
\[
\sum_{i=1}^m \menualloc_i \leq 1 ,\quad \forall \menuentry \in \genmenu.
\]
Observe that the menu representation of a mechanism is independent of the information structure. 
However, for any given menu \(\genmenu\), a corresponding mechanism $\mech$ can be constructed with respect to an information structure $(\signals, \experiment)$. Based on the buyer's signal $\signal$, the mechanism $\mech$ selects an entry from menu $\genmenu$ that optimizes the buyer's utility:
\[(\alloc(\signal), \pay(\signal) ) \in \argmax_{\menuentry\in \genmenu} \InParentheses{\belief \cdot \menualloc - \menupay}. \]

In this paper, we break tie deterministically according to the payment. When there are multiple entries that maximizes the expected utility, the mechanism \(\mech\) always chooses the one with the highest payment. 





\paragraph{Item Pricing}
Among all possible IC-IR mechanisms, an interesting class that is easy to implement in practical applications is item pricing mechanisms.
Specifically, for any $i\in[m]$, let $\delta_i$ be the point mass distribution on selling item $i$. 
\begin{definition}[Item Pricing]
A mechanism $\mech=((\signals,\experiment), \alloc,\pay)$ is implemented by \emph{item pricing} if for any $\signal \in \signals$, 
there exists $i\in[m]$ such that $\alloc(\signal) = \delta_i$. 
Moreover, mechanism $\mech$ is a \emph{uniform item pricing} mechanism if in addition there exists $\pay^*$ such that $\pay(\signal)\in\{0,\pay^*\}$ for all $\signal\in\signals$.
\end{definition}

\subsection{Timeline}
\label{subsec:timeline}

In this section, we outline the timeline of our model, accompanied by a specific example for better understanding. The model proceeds as follows:

\begin{itemize}
    \item[1.] The prior distribution of the buyer, \(\dist \in \Delta\InParentheses{\vals}\), is known to both the buyer and the seller.
    \item[2.] The seller selects an information structure \((\signals, \experiment)\) based on distribution $\dist$, where \(\experiment:\vals \rightarrow \Delta(\signals)\) maps values to signals. The seller then designs a mechanism \(\mech = (\alloc, \pay)\) on top of the information structure, where \(\alloc: \signals \rightarrow [0,1]^m\) is the allocation rule, and \(\pay: \signals \rightarrow \mathbb{R}\) is the payment rule.
    \item[3.] The value profile \(\val\) is drawn from \(\dist\) and is unknown to both parties. A signal \(\signal \sim \experiment(\val)\) is generated according to the seller’s chosen information structure and is \emph{privately} revealed to the buyer.
    \item[4.] The buyer reports a signal \(\signal'\). The final allocation is determined by \(\alloc(\signal')\), and the buyer must make the corresponding payment \(\pay(\signal')\).
\end{itemize}

We now revisit \textit{Example 1} from \Cref{sec:intro} as an illustrative example. Suppose there are two items, and their values are distributed as follows:

\begin{equation*}
    (v_1, v_2) =
    \begin{cases}
      (10,0) & \text{with probability } 0.3, \\
      (6,7) & \text{with probability } 0.3, \\
      (0,10) & \text{with probability } 0.4.
    \end{cases}
\end{equation*}

Now, suppose the seller designs the following information structure: when the value profile is \((10,0)\), signal \(\signal_1\) is generated. Otherwise, if the value of item \(2\) is higher—i.e., when the value profile is either \((6,7)\) or \((0,10)\)— signal \(\signal_2\) is revealed. Furthermore, the seller implements a posted-price mechanism, setting the price of the first item at \(10\) and the price of the second item at~\(\frac{61}{7}\).

When the buyer receives signal \(\signal_1\), he infers that his value profile must be \((10,0)\) and thus purchases the first item. Upon receiving signal \(\signal_2\), his belief updates according to Bayes' rule:
\[
\frac{3}{7}(6,7) + \frac{4}{7}(0,10) = \left(\frac{18}{7}, \frac{61}{7}\right).
\]
In this case, the buyer purchases the second item. Consequently, the seller's total revenue is:
\[
\frac{3}{10} \cdot 10 + \frac{7}{10} \cdot \frac{61}{7} = 9.1.
\]
 \section{Optimality of Horizontal Disclosure and Item Pricing}
\label{sec:optimal}
In general, fixing the information structures, the optimal mechanism for a unit demand agent is complicated and may involve lotteries. Moreover, the menu complexity of any approximately optimal mechanism can be unbounded even with just two items when values are correlated \citep{hart2019selling}. 
In this section, we provide sufficient conditions on the correlation structures of the value distributions such that when the principal has joint design power over information structures and selling mechanisms, item pricing mechanisms are revenue optimal for the principal. Moreover, we show that the optimal information structures in this case can be captured by horizontal disclosure. 

\begin{definition}[Horizontal Disclosure]
\label{def:horizontal}
An information structure $(\signals,\experiment)$ is a \emph{horizontal disclosure} if $\signals = [m]$
and $i^* \in \supp(\experiment(\val))$ only if $i^*\in \argmax_{i\in[m]} \val_i$. 
\end{definition}

Intuitively, under horizontal disclosure, the principal informs the buyer which item he prefers the most while keeping the agent ignorant about the magnitude of preference. 
The main idea behind horizontal disclosure is to allow the agent to discern the relative qualities among different items to improve allocation efficiency, while keeping vertical information to a minimum to reduce information rent.


\subsection{Full Surplus Extraction}
\label{sub:full_surplus_multi}
In this section, we provide general sufficient conditions such that the principal can extract the full surplus for selling any number of items. This immediately implies that the constructed mechanism is revenue optimal. 
Our general condition assumes a form of weakly negative correlation that satisfies the well-known Fortuin–Kasteleyn–Ginibre (FKG) lattice condition~\citep{fortuin1971correlation} and includes independent values as special cases. 

\begin{definition}[Pairwise Conditional Log-Submodularity]
\label{def:pairwise_logsubmodular}
A distribution $\dist$ satisfies \emph{pairwise conditional log-submodularity} if for any pair of items $i\neq i'$, any value profile $\val_{-(i,i')}$, and any pairs of values $(\val_i,\val_{i'}),(\val'_i,\val'_{i'})$, 
we have 
\begin{align*}
& \density(\max\lbr{\val_i,\val'_i}, \min\lbr{\val_{i'},\val'_{i'}} \given \val_{-(i,i')})
\cdot \density(\min\lbr{\val_i,\val'_i}, \max\lbr{\val_{i'},\val'_{i'}} \given \val_{-(i,i')} \given \val_{-(i,i')})\\
\geq\,& \density(\val_i,\val_{i'} \given \val_{-(i,i')})
\cdot \density(\val'_i,\val'_{i'} \given \val_{-(i,i')}). 
\end{align*}
\end{definition}

Note that pairwise conditional log-submodularity implies pairwise conditional weakly negative correlation, 
and is satisfied if distribution $\dist$ is a product distribution. 
In the special case of selling two item, the definition of pairwise conditional log-submodularity reduces to the log-submodularity defined in \cref{subapx:full_surplus_multi}.


\begin{proposition}[Full Surplus Extraction]
\label{thm:full_surplus_multi}
For any number of items and for any distribution~$\dist$ that satisfies pairwise conditional log-submodularity, 
there exists an item pricing mechanism~$\mech$ with horizontal disclosure that extracts the full surplus, 
i.e., $\rev(\mech) = \optwel$. 
\end{proposition}
\cref{thm:full_surplus_multi} holds by directly combining the following two lemmas. 

\begin{lemma}\label{lem:full_surplus}
For any number of items and for any distribution $\dist$, 
there exists an item pricing mechanism $\mech$ with horizontal disclosure that extracts the full surplus, 
i.e., $\rev(\mech) = \optwel$
if and only if for any $i\neq i'$, we have 
\begin{align*}
\expect[\dist]{ \val_i \given i^*(\val) = i} 
\geq \expect[\dist]{ \val_i \given i^*(\val) = i'}.
\end{align*}

\end{lemma}
\begin{proof}
We first prove the ``if'' direction. 
Consider item pricing mechanism $\mech$ with horizontal disclosure such that 
the price $\pay_i$ for item $i$ is 
\begin{align*}
\pay_i = \expect[\dist]{ \val_i \given i^*(\val) = i}.
\end{align*}
Note that given mechanism $\mech$, when the agent receives signal $i$, the posterior value for item~$i'$ is 
$\mu_{i',i}\triangleq \expect[\dist]{ \val_{i'} \given i^*(\val) = i}$. 
It is easy to verify that by construction, 
$\mu_{i,i} = \pay_i$ and $\mu_{i',i} \leq \pay_{i'}$ for any $i'\neq i$. 
Therefore, given mechanism $\mech$, the agent has incentive to purchase item $i$ at price $\pay_i$ upon receiving signal $i$, 
and the expected revenue of mechanism $\mech$ equals the optimal welfare.


Next we prove the ``only if'' direction. Suppose item pricing mechanism $\mech$ with horizontal disclosure extracts full surplus. 
This implies that the price $\pay_i$ for selling item $i$ given mechanism $\mech$ must satisfy $\pay_i = \expect[\dist]{ \val_i \given i^*(\val) = i}$. 
The incentive constraints of the agents immediately imply that 
\begin{align*}
\expect[\dist]{ \val_i \given i^*(\val) = i} 
\geq \expect[\dist]{ \val_i \given i^*(\val) = i'}
\end{align*}
for any $i\neq i'$.
\end{proof}


\begin{lemma}\label{lem:pairwise_submodularity}
For any number of items and for any distribution $\dist$ that satisfies pairwise conditional log-submodularity, 
for any $i\neq i'$, we have 
\begin{align*}
\expect[\dist]{ \val_i \given i^*(\val) = i} 
\geq \expect[\dist]{ \val_i \given i^*(\val) = i'}.
\end{align*}
\end{lemma}
\begin{proof}
For any pair of items $i\neq i'$, let $F_{-(i,i')}^{\val_{-(i,i')}}$ be the joint distribution over values $(\val_i,\val_{i'})$ 
conditional on the value profile $\val_{-(i,i')}$ for other items and the event that $\max\{\val_i,\val_{i'}\} \geq \max_{j\neq i,i'}\val_j$. 
Since $\dist$ satisfies pairwise conditional log-submodularity, 
distribution $\dist_{-(i,i')}^{\val_{-(i,i')}}$ satisfies log-submodularity. 
By \cref{cor:conditional_expectation}, an application of the FKG inequality to our setting, it follows easily that
\begin{align*}
\expect[\dist_{-(i,i')}^{\val_{-(i,i')}}]{ \val_i \given \indicate{\val_i\geq\val_{i'}}} 
\geq \expect[\dist_{-(i,i')}^{\val_{-(i,i')}}]{ \val_i} 
\geq \expect[\dist_{-(i,i')}^{\val_{-(i,i')}}]{ \val_i \given \indicate{\val_i<\val_{i'}}}.
\end{align*}
Finally, \cref{lem:pairwise_submodularity} holds by taking the summation over $\val_{-(i,i')}$.
\end{proof}

\subsection{Suboptimality of Horizontal Disclosure}
If the weakly negative correlation condition in \cref{def:pairwise_logsubmodular} is violated, mechanisms with horizontal disclosure can be far from revenue optimal even if the principal is not restricted to item pricing mechanisms. 
The main intuition is that when the values are positively correlated, simply revealing which item has the highest value for the agent may disclose too much vertical information, allowing the agent to perfectly infer the realized values of each item. This excessive information disclosure creates significant information rents for the agent, making such a construction suboptimal.

Specifically, consider an instance with $n$ items and $n$ value profiles. 
Fixing a sufficiently small parameter $\epsilon > 0$. 
For each $i\in [n]$, the probability of value profile $v^{(i)}$ is $\frac{1}{2^i(1-2^{-n})}$, $v^{(i)}_j = 2^i$ for any $j\neq i$, and $v^{(i)}_i = 2^i + \epsilon$. 

In this instance, if the mechanism discloses which item has the highest value, the agent can infer the value profile from the highest value item. That is, horizontal disclosure is equivalent to fully revealing information structures in this example. 
Moreover, by fully revealing the values, it is easy to verify that the optimal revenue in this case is at most $\frac{1}{1-2^{-n}}+\epsilon$. 
However, if the principal reveals no information to the agent, the principal can extract the expected value of each marginal distribution, which is at least $\frac{n}{1-2^{-n}}$.
The multiplicative gap in expected revenue is $n$ when $\epsilon\to 0$. 



\subsection{Suboptimality of Item Pricing}
\label{sub:Suboptimality_of_Item_Pricing}
In this section, we show that when the weakly negative correlation condition in \cref{def:pairwise_logsubmodular} is violated, item pricing mechanisms are not revenue optimal even if the principal can adopt arbitrary information structures. 
Intuitively, without the negative correlation assumption, when the principal can use lotteries, the principal can sell the items more efficiently to the value profile with lower values without creating additional information rent for the value profile with higher values.
Our construction of counterexample for illustrating this intuition relies on the fact that there are at least three items. 
In the special case with two items, we conjecture that item pricing mechanisms are always revenue optimal without any distributional assumptions. 

Consider an instance with three items. The agent has two different types of values. Specifically, with probability half each, the agent has value either $\val^{(1)}=(0, 20, 9)$ or $\val^{(2)}=(4, 0, 5)$. 
A feasible mechanism is to fully reveal the values to the agent, and consider allocation and payment rule such that 
$\alloc(\val^{(1)}) = (0,1,0), \alloc(\val^{(2)}) = (0.5,0,0.5)$
and $\pay(\val^{(1)}) = 20, \pay(\val^{(2)})=4.5$. 
The expected revenue from this mechanism is $12.25$.


Next, we restrict attention to item pricing mechanisms and show that the optimal revenue for these mechanisms is at most $12$. Note that our joint design problem can be viewed as first fixing an item pricing mechanism, and then finding the information structure that maximizes the expected revenue within the given mechanism. 
The latter problem of finding the optimal information structure can be framed as a Bayesian persuasion problem, where the sender's utility function is determined by the item pricing mechanism.
By \citet{kamenica2011bayesian}, since the state is binary, it is without loss of optimality to consider only information structures with binary signals. 
This further implies that in the example of selling three items, it is without loss of optimality to restrict attention to item pricing mechanisms that offer only two items for sale.
If item $1$ and $3$ are offered, the optimal welfare under such mechanism is at most $7$, 
and if item $1$ and $2$ are offered, the optimal welfare under such mechanism is at most $12$.
In both cases, due to the individual rationality constraint, the revenue of the seller is at most the welfare, which is at most $12$. 
Similarly, the revenue from selling only one item is at most $10$. 

Now we focus on mechanisms which offers only item $2$ and $3$. 
Let $\signals = \{\signal_2,\signal_3\}$ and 
let $p_2, p_3$ be the price on items $2$ and $3$ respectively. 
Without loss of generality we assume that the agent will prefer purchasing item $i$ upon receiving signal $\signal_i$ for $i\in\{2,3\}$. 
Let $\alpha_1,\alpha_2$ be the probabilities such that the agent receives signal $\signal_2$ conditional on value being $\val^{(1)}$ and $\val^{(2)}$ respectively. 
To ensure that the expected welfare is at least $12$, we must have $\alpha_1 \geq \frac{10}{11}$ and $\alpha_2 \leq \frac{1}{5}$. 
In this case, the posterior value for item 3 conditional on signal $\signal_2$ is higher than signal $\signal_3$. 
Therefore, in the optimal mechanism, it must be the case that 
$$p_3 = \frac{\frac{9}{2}(1-\alpha_1) + \frac{5}{2}(1-\alpha_2)}{\frac{1}{2}(2-\alpha_1-\alpha_2)}$$
and 
$$p_2 = \frac{10\alpha_1}{\frac{1}{2}(\alpha_1+\alpha_2)}
- \frac{\frac{9}{2}\alpha_1+\frac{5}{2}\alpha_2}{\frac{1}{2}(\alpha_1+\alpha_2)} + p_3.$$
The expected revenue of the seller is 
\begin{align*}
R&=\frac{1}{2}(\alpha_1+\alpha_2)p_2 
+ \frac{1}{2}(2-\alpha_1-\alpha_2)p_3 = \frac{11}{2}\alpha_1 - \frac{5}{2}\alpha_2
+ \frac{9(1-\alpha_1) + 5(1-\alpha_2)}{(2-\alpha_1-\alpha_2)}. 
\end{align*}
First note that 
\begin{align*}
\frac{\partial R}{\partial \alpha_1} 
= 1 + \frac{(7 - 2\alpha_2)
(2-\alpha_1-\alpha_2) + (\alpha_1+\alpha_2)(\frac{9}{2}(1-\alpha_1) + \frac{5}{2}(1-\alpha_2))}{(2-\alpha_1-\alpha_2)^2} > 0.
\end{align*}
Therefore, the optimal revenue is maximized when $\alpha_1 = 1$, 
which simplifies to 
\begin{align*}
R&= \frac{21}{2}-\frac{5}{2}\alpha_2\leq \frac{21}{2} < 12. 
\end{align*}
Combining all cases, we show that the optimal revenue from item pricing is at most $12$, which is strictly less than the optimal revenue from lottery pricing. 

 \section{Approximate Optimality}
\label{sec:approximation}

In this section, we show that although item pricing may not be optimal in general with three or more items, it is approximately optimal given any prior distribution over values. 
In particular, we show constant approximations can be achieved by mechanisms that use coarse horizontal disclosure and item pricing.




\begin{definition}[Coarse Horizontal Disclosure]
An information structure $(\signals,\experiment)$ is a \emph{coarse horizontal disclosure} if for any $\val,\val'$ such that $i^*(\val) = i^*(\val')$, 
we have $\experiment(\val) = \experiment(\val')$. 
\end{definition}
Coarse horizontal disclosure is a generalization of horizontal disclosure, where the item with highest value is not necessarily disclosed to the agent. 
Instead, the signal space consists of sets of items, and the principal can disclose a set such that the agent's highest value is promised to be in the set. 

\begin{theorem}[Approximate Optimality of Item Pricing and Coarse Horizontal Disclosure]
\label{thm:approx_opt}
For any number of items and any distribution $\dist$ over values, there exists a mechanism $\mech$ with coarse horizontal disclosure and item pricing that achieves at least $50.17\%$ of the optimal revenue, i.e., $\rev(\mech) \geq 0.5017\cdot\optrev$. 
\end{theorem}


In this section, we will first provide a weaker approximation result by showing that half of the optimal revenue can be attained by using uniform item-pricing. That is, the prices posted on all items are the same. 
After that, we show that the improved approximation in \cref{thm:approx_opt} can be attained using at most two different prices. 



\begin{proposition}\label{prop:uniform_pricing}
For any number of items and any distribution $\dist$ over values, there exists a uniform item pricing mechanism $\mech$ with coarse horizontal disclosure that achieves at least half of the optimal revenue, i.e., $\rev(\mech) \geq \frac{1}{2}\optrev$. Moreover, there exist instances where the revenue loss of half is necessary when the seller restrict attention to uniform item-pricing mechanisms. 
\end{proposition}

To prove \cref{prop:uniform_pricing}, instead of directly comparing to the optimal revenue, we are going to compare to a relaxed benchmark of optimal welfare. 

\begin{proof}[Proof of \cref{prop:uniform_pricing}]
For any uniform price $\pay>0$, let
\begin{align*}
I_+(\pay) = \lbr{i\in[m] : \expect[\dist]{\val_i \given i=i^*(\val)} \geq \pay}.
\end{align*}
That is, by only disclosing to the agent on which item he values the most, $I_+(\pay)$ is the set of items such that the posterior value of the agent on the highest value item is at least $\pay$. 
Let $I_-(\pay) = [m]\backslash I_+(\pay)$. 
Moreover, let 
\begin{align*}
\wel_+(\pay) = \expect[\dist]{\max_i \val_i \cdot\indicate{i^*(\val)\in I_+(\pay)}}
\quad\text{and}\quad
\wel_-(\pay) = \expect[\dist]{\max_i \val_i \cdot\indicate{i^*(\val)\in I_-(\pay)}}.
\end{align*}


For any uniform price $\pay>0$, consider a coarse horizontal disclosure information structure $(\signals_{\pay},\experiment_{\pay})$ 
induced by a mapping $\tau: I_-(\pay) \to \Delta([m])$
such that $\signals_{\pay} = [m]$ and
\begin{enumerate}
\item for any value $\val$ such that $i^*(\val)\in I_+(\pay)$, signal $i^*(\val)$ is sent;
\item for any value $\val$ such that $i^*(\val)\in I_-(\pay)$, signal is sent according to $\tau(i^*(\val))$;
\item for any item $i\in I_+(\pay)$, the posterior value on item $i$ for receiving signal $i$ is at least~$\pay$, i.e., 
\begin{align*}
\expect[\experiment_{\pay},\dist]{\val_i \given \signal = i} \geq \pay.
\end{align*}
\end{enumerate}
Essentially, the above constructed information structure randomly pools types with different highest value items subject to the constraints that after pooling, the agent receiving a signal $i\in I_+(\pay)$ is still willing to purchase item $i$ from the seller given uniform price $\pay$. 

Let $\pay^*$ be the maximum price such that there exists a coarse horizontal disclosure information structure $(\signals_{\pay^*},\experiment_{\pay^*})$ defined above under which an item is sold to the agent with probability one. 
For any $\epsilon > 0$, we first show that for $(\signals_{\pay^*+\epsilon},\experiment_{\pay^*+\epsilon})$
that maximizes the selling probability, which is strictly less than 1 by the definition of $\pay^*$, we have 
\begin{align*}
\wel_+(\pay^*+\epsilon) 
&= \expect[\dist]{\sum_{i\in I_+(\pay^*+\epsilon)} \val_i \cdot\indicate{i^*(\val)=i}}\\
&\leq \expect[\experiment_{\pay^*+\epsilon},\dist]{\sum_{i\in I_+(\pay^*+\epsilon)} (\pay^*+\epsilon) \cdot\indicate{\signal=i}}
\leq \pay^*+\epsilon.
\end{align*}
The first inequality holds since for any item $i \in I_+(\pay^*+\epsilon)$, the posterior value on item $i$ for receiving signal $i$ is exactly $\pay^*+\epsilon$. This is because otherwise we can further pool types with highest value item in $I_-(\pay^*+\epsilon)$ with those with highest value item in $I_+(\pay^*+\epsilon)$ to strictly increase the selling probability. 
Moreover, it is easy to show that 
\begin{align*}
\wel_-(\pay^*+\epsilon) = \expect[\dist]{\max_i \val_i \cdot\indicate{i^*(\val)\in I_-(\pay^*+\epsilon)}} \leq \pay^*+\epsilon.
\end{align*}

Let $\mech$ be the uniform item pricing mechanism that sells the item using uniform price~$\pay^*$
in which the information structure $(\signals_{\pay^*},\experiment_{\pay^*})$ is chosen as a coarse horizontal disclosure information structure such that an item is sold with probability one. 
For any $\epsilon > 0$, we have
\begin{align*}
\optwel = \wel_+(\pay^*+\epsilon) + \wel_-(\pay^*+\epsilon) 
\leq 2(\pay^* + \epsilon)
= 2(\rev(\mech) + \epsilon).
\end{align*}
Since the above inequality holds for any $\epsilon > 0$, 
we have 
\begin{equation*}
\rev(\mech) \geq \frac{1}{2}\optwel \geq \frac{1}{2}\optrev.
\end{equation*}

For the worst-case example, consider an instance with two items. 
For any parameter $\epsilon > 0$, with probability $\epsilon$, the buyer has value $\frac{1}{\epsilon}$ for the first item and value $0$ for the second item. 
With probability $1-\epsilon$, the buyer has value $0$ for the first item and value $1$ for the second item. 
In this example, the optimal mechanism is to fully disclose the value to the agent, and charge price $\frac{1}{\epsilon}$ for the first item, and price $1$ for the second item. 
The seller extracts the full surplus in this mechanism, with expected revenue equals $2-\epsilon$. 

Now suppose the seller is restricted to uniform item pricing mechanisms. 
In this case, if the price is at most 1, then the expected revenue given any information structure is at most~1. 
If the price is strictly larger than 1, given any information structure, only the first item can be sold to the buyer regardless of the valuation of the buyer. 
In this case, the expected welfare from selling the item to the buyer is at most 1, which implies that the expected revenue is at most 1. 
Therefore, the optimal revenue from uniform item pricing is at most~1, 
and the approximation ratio of uniform item pricing in this example is $2-\epsilon$. 
By taking $\epsilon$ to 0, the worst case gap is 2. 
\end{proof}

Finally, we show that the approximation factor of $2$ can be strictly improved by using only two prices. Note that the approximation of $0.5017$ is not tight for the item pricing mechanisms. 
In our paper, we did not optimize the approximation factors for item pricing mechanisms. 
Our improved approximation ratio in \cref{thm:approx_opt} only serves the purpose of showing that the principal can strictly improve its approximation guarantee by using multiple prices compared to uniform pricing. 

\begin{proof}[Proof of \Cref{thm:approx_opt}]
     
We analyze the approximation ratio in two different cases. 
Let $\pay^*$ be the maximum price such that there exists a coarse horizontal disclosure information structure $(\signals_{\pay^*},\experiment_{\pay^*})$ under which an item is sold to the agent with probability one. 
Recall that $I_+(\pay^*)$ is the set of items such that the posterior value of the agent on the highest value item is at least $\pay^*$ when the seller only disclose to the agent on which item he values the most. 
Let $I_-(\pay^*) = [m]\backslash I_+(\pay^*)$. 
Moreover, let 
\begin{align*}
\wel_+(\pay^*) = \expect[\dist]{\max_i \val_i \cdot\indicate{i^*(\val)\in I_+(\pay^*)}}
\quad\text{and}\quad
\wel_-(\pay^*) = \expect[\dist]{\max_i \val_i \cdot\indicate{i^*(\val)\in I_-(\pay^*)}}.
\end{align*}

\paragraph{Low social welfare:} In the first case, there exists $\epsilon > 0$ such that $\wel_-(\pay^*+\epsilon)\leq (1-\delta)\pay^*$. 
Note that this implies that the same inequality holds for all $\epsilon' \leq \epsilon$.
Therefore, in this case, by using a uniform price $\pay^*$, 
the expected revenue is $\pay^*$ and the approximation ratio is $(2-\delta)$
since the optimal welfare is at most $(2-\delta)\pay^*$. 

\paragraph{High social welfare:} In the second case, $\wel_-(\pay^*+\epsilon) > (1-\delta)\pay^*$ for all $\epsilon > 0$.
By Markov's inequality, with probability at least $\frac{1-\delta-\hat{\delta}}{1-\hat{\delta}}$, the highest value of a type $\val\in \wel_-(\pay^*)$ is at least $\hat{\delta}\pay^*$. 
This further implies that the probability that the highest value of a type $\val\in \wel_+(\pay^*)$ is at most~$\delta$. 
We first pool the types such that the highest posterior value is at most $kp^*$. 
Note that the expected welfare from $I_+$ given $\posterior_{i,i}\geq k p^*$ is at least $(1-(k+1)\delta)p^*$ and at most $p^*$.
Therefore, the probability a type in $I_-$ that is not pooled in this process is at least $1-\frac{1}{k}$. 

{Recall that \(\mu_{i',i} \triangleq \expect[\dist]{\val_{i'} \mid i^*(\val) = i}\) represents the expected value of item \(i'\) given that item \(i\) has the highest value.}
Let $I^k_+$ be the set of items such that conditional on $i$ is the highest value item, there exists $i'\in I_-$ such that $kp^*\leq \posterior_{i,i} \leq 2\posterior_{i',i}$. 
Consider a bipartite graph between $I^k_+$ and $I_-$ where $i\in I^k_+$ is connected with $i'\in I_-$ if $\posterior_{i',i'}\geq \hat{\delta}p^*$ and $\posterior_{i',i}\geq \frac{1}{2}\posterior_{i,i}$. 
In this bipartite graph, the out flow for any $i\in I^k_+$ is at most the probability of signal $i$ and the in flow for any $i'\in I_-$ is at most the probability of signal $i'$ times $c\triangleq\frac{\frac{k}{2}-\frac{2}{2-\delta}}{\frac{2}{2-\delta}-\hat{\delta}}$. 
Now consider a maximum flow for the given bipartite graph, and let $w$ be the total amount of flow. 
Moreover, let $I^k_-$ be the set of items such that in the maximum flow, the in flow of the item reaches its maximum capacity. 
Let 
\begin{align*}
    \underline{w}\triangleq \frac{\frac{2}{2-\delta}(1+\frac{1-(k+1)\delta}{k}) - 1 + (k+1)\delta}{c+1-k}.
\end{align*}

We divide the analysis into two sub-cases.
\begin{enumerate}
    \item In the maximum flow, we have $w\geq \underline{w}$.
    In this case, it is easy to verify that there exists a signal structure which first pooling types according to the maximum flow, such that with probability 1, the posterior value of maximum value item given any signal is at least $\frac{2p^*}{2-\delta}$. Therefore, given uniform price $\frac{2p^*}{2-\delta}$, an item is sold with probability 1, and hence the approximation ratio is at most $2-\delta$.

    \item In the maximum flow, we have $w< \underline{w}$.
    In this case, consider the mechanism that set price $\frac{kp^*}{2}$ for items in $I_+ \cup I^k_-$ and price $\hat{\delta}p^*$ for the rest of the items. 
    Note that given this mechanism, types with signals in $I_+$ that are not in the maximum flow always weakly prefer purchasing an item with price $\frac{kp^*}{2}$ with posterior value $kp^*$ rather than purchasing an item with price $\hat{\delta}p^*$ with value at most $\frac{kp^*}{2}$. Therefore, the expected revenue is at least 
    \begin{align*}
        \rbr{\frac{1}{2}\rbr{1-(k+1)\delta-\underline{w}k} + \rbr{1-\frac{2}{k}-c\underline{w}}\hat{\delta}}p^*
    \end{align*}
\end{enumerate}
By setting $\delta = 0.0068, \hat{\delta} = 0.925$ and $k=11$, 
we have 
\begin{align*}
\rbr{\frac{1}{2}\rbr{1-(k+1)\delta-qk} + \rbr{1-\frac{2}{k}+q}\hat{\delta}}p^*
> 1.007
> \frac{2}{2-\delta}.
\end{align*}
Therefore, the approximation ratios in all cases are at most $2-\delta = 1.9932$. 
\end{proof} \section{Discussions and Extensions}
\label{sec:conclusion}
In this paper, we show that, unlike in classic multi-dimensional Bayesian mechanism design---where simple mechanisms fail to provide any approximation guarantees for correlated distributions---the additional power of information design enables simple mechanisms, such as item pricing, to achieve a constant-factor approximation to the optimal revenue.
The high-level intuition is that the worst-case distributions, which make item pricing a poor approximation, do not arise endogenously under the optimal information design. Our paper also leaves several important open questions that warrant further investigation. 
First, our paper provides an example showing that lotteries are necessary when there are at least three items. However, in the important special case of two items, we conjecture that item pricing mechanisms are exactly optimal. Resolving this open question may require novel techniques for characterizing the optimal revenue under information disclosure.
Moreover, our analysis has focused on single-buyer settings. An interesting direction for future research is extending our results to multi-buyer settings and examining whether item pricing or its natural generalizations maintain a constant-factor approximation to the optimal revenue with multiple buyers. Finally, it would be interesting to extend our results to other combinatorial environments, such as settings where buyers have more complex valuation functions.




 

\newpage

\bibliographystyle{ACM-Reference-Format}
\bibliography{ref,reference}
\newpage
\appendix
\section{Missing Proofs}
\label{apx:multi}







\label{subapx:full_surplus_multi}

For convenience, we present the proof based on log-supermodularity instead of log-submodularity in this section. See \Cref{rmk:FKG application} for how to apply our results from this section to \Cref{sub:full_surplus_multi}. Let~$Z$ be a finite distributive lattice, and let $\mu$ be a non-negative function on it. 
Function $\mu$ satisfies log-supermodularity if 
for any $z,z'\in Z$, 
\begin{align*}
\mu(z\wedge z')\cdot\mu(z\vee z')\geq \mu(z)\cdot\mu(z).
\end{align*}
\begin{proposition}[FKG Inequality~\citep{fortuin1971correlation}]
\label{prop:fkg}
For any finite distributive lattice and any non-negative function $\mu$ that satisfies log-supermodularity,
for any non-decreasing functions $g, \hat{g}$ defined on $Z$, 
it holds that 
\begin{align*}
\rbr{\sum_{z\in Z} g(z)\hat{g}(z)\mu(z)}\rbr{\sum_{z\in Z} \mu(z)} \geq \rbr{\sum_{z\in Z} g(z)\mu(z)}
\rbr{\sum_{z\in Z} \hat{g}(z)\mu(z)}.
\end{align*}
\end{proposition}

\begin{corollary}\label{cor:conditional_expectation}
Consider a finite distributive lattice \(\vals \subseteq \mathbb{R}^2\), where for any \(\val, \val' \in \vals\), the meet and join operations are given by 
\[
\val \wedge \val' = (\min\{\val_1, \val'_1\}, \max\{\val_2, \val'_2\})
\quad \text{and} \quad
\val \vee \val' = (\max\{\val_1, \val'_1\}, \min\{\val_2, \val'_2\}).
\]
Let $\density$ be a probability mass function suppported on $\vals$ and satisfies log-supermodularity, i.e., \begin{equation}\label{eq:supermodularity}
    f(\min\{\val_1, \val'_1\}, \max\{\val_2, \val'_2\})\cdot f(\max\{\val_1, \val'_1\}, \min\{\val_2, \val'_2\})\geq f(\val)\cdot f(\val')
\end{equation} Then, the following inequality holds: 
\begin{align*}
\sum_{\val\in \vals} \val_1\cdot\indicate{\val_1\geq \val_2} \cdot\density(\val) \geq \rbr{\sum_{\val\in \vals} \val_1\cdot\density(\val)}
\rbr{\sum_{\val\in \vals} \indicate{\val_1\geq \val_2} \cdot\density(\val)},
\end{align*}
which implies that \[(i)~\expect{\val_1 \mid \val_1\geq \val_2}\geq \expect{\val_1} \quad \text{and} \quad (ii)~\expect{\val_1 \mid \val_1\geq \val_2}\geq \expect{\val_1 \mid \val_1< \val_2}.\] 
\end{corollary}
\begin{proof}
We choose $g(\val) = \val_1$ and $\hat{g}(\val) = \indicate{\val_1\geq \val_2}$. Using the partial order induced by $\vals$, if $\val\geq \val'$, i.e., $\val\wedge \val'=\val'$, then: (i) $\val_1\geq \val_1'$ and (ii) $\val_2\leq \val_2'$. Thus, both $g$ and $\hat{g}$ are non-decreasing on $\vals$.
Applying \cref{prop:fkg} to our chosen functions $g$ and $\hat{g}$, we conclude that \cref{cor:conditional_expectation} holds.
\end{proof}

\begin{remark}\label{rmk:FKG application}
    It is not hard to verify if $\dist$ satisfies the Pairwise Conditional Log-Submodularity in~\Cref{def:pairwise_logsubmodular}, then the probability mass function of $\dist_{-(i,i')}^{\val_{-(i,i')}}$ for any $i,i'$ and $\val_{-(i,i')}$ satisfies inequality~\eqref{eq:supermodularity}. Hence, \cref{cor:conditional_expectation} applies to these pariwise conditional distributions.
\end{remark}










%
 
\end{document}
