%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%% LaTeX Template for AAMAS-2025 (based on sample-sigconf.tex)
%%% Prepared by the AAMAS-2025 Program Chairs based on the version from AAMAS-2025. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%% Start your document with the \documentclass command.


%%% == IMPORTANT ==
%%% Use the first variant below for the final paper (including auithor information).
%%% Use the second variant below to anonymize your submission (no authoir information shown).
%%% For further information on anonymity and double-blind reviewing, 
%%% please consult the call for paper information
%%% https://aamas2025.org/index.php/conference/calls/submission-instructions-main-technical-track/

%%%% For anonymized submission, use this
\documentclass[sigconf]{aamas} 

%%%% For camera-ready, use this
%\documentclass[sigconf]{aamas} 


%%% Load required packages here (note that many are included already).

\usepackage{balance} % for balancing columns on the final page

\usepackage{savesym}
\savesymbol{Bbbk}
\savesymbol{openbox}

\usepackage{xcolor}
\usepackage{url}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{MnSymbol}
\usepackage{booktabs}
\usepackage{algorithm}
\urlstyle{same}
\usepackage{multirow}



\restoresymbol{NEW}{Bbbk}
\restoresymbol{NEW}{openbox}
\usepackage{tcolorbox}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%% AAMAS-2025 copyright block (do not change!)

\makeatletter
\gdef\@copyrightpermission{
  \begin{minipage}{0.2\columnwidth}
   \href{https://creativecommons.org/licenses/by/4.0/}{\includegraphics[width=0.90\textwidth]{by}}
  \end{minipage}\hfill
  \begin{minipage}{0.8\columnwidth}
   \href{https://creativecommons.org/licenses/by/4.0/}{This work is licensed under a Creative Commons Attribution International 4.0 License.}
  \end{minipage}
  \vspace{5pt}
}
\makeatother

\setcopyright{ifaamas}
\acmConference[AAMAS '25]{Proc.\@ of the 24th International Conference
on Autonomous Agents and Multiagent Systems (AAMAS 2025)}{May 19 -- 23, 2025}
{Detroit, Michigan, USA}{Y.~Vorobeychik, S.~Das, A.~Now√©  (eds.)}
\copyrightyear{2025}
\acmYear{2025}
\acmDOI{}
\acmPrice{}
\acmISBN{}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%% == IMPORTANT ==
%%% Use this command to specify your OpenReview submission number.
%%% In anonymous mode, it will be printed on the first page.

\acmSubmissionID{765}

%%% Use this command to specify the title of your paper.

\title{Free Argumentative Exchanges for Explaining Image Classifiers}

%%% Provide names, affiliations, and email addresses for all authors.


\author{Avinash Kori}
\affiliation{
  \institution{Imperial College London}
  \country{United Kingdom}}
\email{a.kori21@imperial.ac.uk}

\author{Antonio Rago}
\affiliation{
  \institution{Imperial College London}
  \country{United Kingdom}}
\email{a.rago@imperial.ac.uk}

\author{Francesca Toni}
\affiliation{
  \institution{Imperial College London}
  \country{United Kingdom}}
\orcid{0000-0001-8194-1459}
\email{f.toni@imperial.ac.uk}

%%% Use this environment to specify a short abstract for your paper.

\begin{abstract}

Deep learning models are powerful image classifiers but their opacity hinders their trustworthiness.
Explanation methods for capturing the reasoning process within these classifiers faithfully and in a %\todo{cognitively manageable manner} 
\CR{clear manner} are scarce, due to their sheer complexity and size.
%lacking because modelling this process in a cognitively manageable manner is exceptionally difficult if not impossible. often hinders the faithfulness of explanations for their outputs.
%In this paper, we 
\CR{We} provide a solution for this problem by defining a novel method for explaining the outputs of image classifiers with debates  between two agents, each arguing for a particular class. 
%In order to produce faithful explanations of classifications, capturing all the uncertainties within a classifier, we frame this process as a debate between agents, with each arguing for a particular class.
We obtain these debates as concrete instances of \emph{Free Argumentative eXchanges} (FAXs), a novel  argumentation-based multi-agent framework
%in which  the lingua franca assumption between agents is relaxed, allowing us to model the classifier's internal ``debate'' between different classes as agents with different opinions.
allowing agents to internalise opinions by other agents differently than originally stated. 
We %identify theoretical properties of FAXs and 
define two metrics \CR{(\emph{consensus} and \emph{persuasion rate})} to assess 
the usefulness of FAXs as argumentative explanations for image classifiers.
We then conduct a number of
empirical experiments % with concrete instances of FAXs for image classification, that %these properties witness FAXs' suitability 
showing that FAXs 
perform well along these metrics as well as being more faithful to the image  classifiers than conventional, non-argumentative explanation methods.
\CR{All our implementations can be found at \url{https://github.com/koriavinash1/FAX}}.
%\delete{In our experimental analysis, we examine fair, biased, and random classifiers. We train a ResNet-18 model using both balanced and unbalanced class splits on the AFHQ dataset, which produces models with varying levels of bias.  To interpret the behavior of these trained models, we employ FAXs. Our findings indicate that characteristics such as persuasion ability and resolution representation are indicative of classifier behavior.}

\end{abstract}

%%% The code below was generated by the tool at http://dl.acm.org/ccs.cfm.
%%% Please replace this example with code appropriate for your own paper.


%%% Use this command to specify a few keywords describing your work.
%%% Keywords should be separated by commas.

\keywords{Argumentation, Explainable AI, Quantization}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%% Include any author-defined commands here.

\usepackage[noend]{algpseudocode}
\usepackage{amssymb}
\usepackage{xcolor}

\input{notations}
         
\newcommand{\BibTeX}{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em\TeX}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

%%% The following commands remove the headers in your paper. For final 
%%% papers, these will be inserted during the pagination process.

\pagestyle{fancy}
\fancyhead{}

%%% The next command prints the information defined in the preamble.

\maketitle 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\todo{We will clarify this in the discussion to set the expectation correctly, starting from the abstract (where the mention of cognitive tractability will be dropped and considerations on the new metrics we propose expanded).}

\section{Introduction}

With the increasing complexity and widespread deployment of deep learning models in our daily lives, the interpretation and explanation of these models' decisions have become a central focus in recent eXplainable Artificial Intelligence (XAI) literature \cite{lime,SHAP,deeplift}. 
Many existing approaches for explaining image classification models heavily rely on heatmaps and segments to localize regions of interest in input images that contribute to the model's output \cite{selvaraju2017grad,gradcampp,integratedcam}, %these methods 
typically offering static input-output-based explanations while lacking deeper insights into the underlying model being explained.
The literature has repeatedly highlighted the need for deeper and more dynamic explanations \cite{miller2019explanation,lakkaraju2022rethinking,madumal2019grounded},  
%Ideally, explanations should not only 
highlighting the input-output relationships of the model but also delving into its internal mechanisms and elucidating %implicit biases and shortcuts employed by 
the model's reasoning. Also, there is an ongoing debate about the necessity of interactive %, socially aware
explanations \cite{cawsey1991generating,miller2019explanation} and explanations that are contrastive and selected \cite{miller2019explanation}.


Dialogue-based explanations have been advocated as being useful in understanding the inner working of deep learning models \cite{lakkaraju2022rethinking}%, while several forms of interactive machine learning for model debugging \cite{teso2023leveraging}
.
\cite{wang2019deliberative} argues that explanations are especially important when the model has high uncertainty about the output when the prediction oscillates between different classes resulting in different interpretations of the model behaviour.
\cite{Rago_23} proposes %an argumentation framework 
argumentative exchanges to explain models via interactions amongst agents.
%with human and agent interactions to explain the underlying classifier models.
Motivated by these varied lines of work, the main focus of this work is to extract explanations for image classifiers as %a visual conversations 
debates between two artificial agents, arguing, in the spirit of bipolar argumentation~\cite{Cayrol_05}, for and against %particular interpretations of the model
the classifiers' outputs for given inputs.
%\todo{motivate argumentation} The objective is to gauge the model properties based on these conversation records.




\begin{example}%(Debate Intuition) 
\label{ex:illu} 
As an abstract illustration, 
    consider two agents $\Agents^1$ and $\Agents^2$ as outlined in Figure \ref{fig:example} (black and grey, respectively). 
    Each agent has an initial  perception (at timestep $t=0$) of their environment as a bipolar argumentation framework (BAF) about a topic of interest ($a$ in the figure) which we consider as private. 
    As agents start debating, they share  their knowledge
    (see the exchange BAF figure \ref{fig:example}) and may expand their private BAFs (e.g. $\Agents^2$ learns that $b$ supports $a$ at timestep $t=1$ and agent $\Agents^1$ learns that $c$ attacks $a$ at timestep $t=2$). As in human debates,
    as agents expand their knowledge they may see things differently from the other agents (e.g. at the alternative timestep $t=2'$ $\Agents^1$ sees $\Agents^2s$'s attack  from $c$ to $a$ as a support). 
\end{example}

Overall,  we make the following contributions:

\begin{itemize}
    \item we define a novel form of \emph{free argumentative exchanges} (FAXs) to characterise explanations amongst agents as illustrated in Figure~\ref{fig:example}; differently from %the approach in 
    \cite{Rago_23}, these exchanges allow for agents to disagree on what constitutes an attack or support amongst arguments exchanged during debates (and are thus \emph{free});
    \CR{%We would like to stress that the element of novelty FAXs bring is significant in our opinion. Technically, the novelty amounts to dropping 1) the need for a base score (using BAFs rather than QBAFs for each agent) and 2) the requirement that agents agree on a lingua franca for relations. Practically, 
    this technical novelty empowers the use of \FAXIC s for explanation of image classifiers; }
    \item we instantiate FAXs so that they can serve as the basis for explaining the outputs of image classifiers; %additionally, we provide a methodological implementation for the same
   \item we provide an implementation of the instantiated FAXs, by adapting the methodology of \cite{kori2022explaining} to allow agents to generate their own arguments;
    \item we evaluate our methodology and implementation quantitatively  and qualitatively, with two types of image classifiers on two datasets;
    for the quantitative evaluation, we use two novel metrics %\todo{are they not already in \cite{DS-visual debates}?} 
    to assess the argumentative quality of the generated debates, and, for comparison with baselines% methods
    , two existing metrics (adapted to our setting) for ascertaining the %input-output
    faithfulness of explanations to the explained classifiers.
\end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Related Work}
\label{sec:related_Work}
\begin{figure}
    \centering  \includegraphics[width=1\columnwidth]{imgs/example2.png}
    \caption{
    Illustration of FAXs (see Example~\ref{ex:illu}). }
    \label{fig:example}
    \vspace{-10pt}
\end{figure}

\paragraph{XAI methods} 
There has been a recent surge in methods advocating for a shift in how we perceive explanations, emphasizing the importance of viewing them as dialogues rather than solely relying on heatmaps or feature attributions, as %often seen 
standard in much of the XAI literature~\cite{miller2019explanation,madumal2019grounded,lakkaraju2022rethinking}. 
%Additionally, explanations in the form of dialogues enable us to address various model ambiguities, such as model certainties and biases.
%From a practical standpoint, 
Within the multi-agent setting,
\cite{Rago_23} proposed an argumentative framework for expressing (interactive) explanations in the form of dialogues. 
Additionally, \cite{debate} demonstrated a debate framework, which was further expanded in \cite{kori2022explaining} to scale, allowing for the extraction of post-hoc explanations in the form of dialogues between two fictional %players
agents.
Inspired by \cite{Rago_23}, we define a multi-agent argumentative framework for explanation, 
and we adopt a variant of approach in \cite{kori2022explaining} to implement the framework.
%
Both \cite{kori2022explaining} and our implementation utilize a surrogate model that faithfully represents the given classifier. 
The use of surrogate models is a standard practice in XAI, as seen e.g. in \cite{yoon2018invase,goyal2019counterfactual,glance}.

 
%Similar to the approach proposed by \cite{kori2022explaining}, our method can be considered to fall within the general family of feature attribution explanations. 
The agents in our explanations put forward arguments which can be understood as feature attributions such as 
LIME~\cite{lime}.
%In which, \cite{lime} can be viewed as a special instance of our framework. 
However, unlike \cite{lime}, we do not randomly select input regions to mask; instead, %we 
our agents learn two different strategies to select regions to argue for and against a particular explanandum (input-output).

Our method is also related to
%Some interesting work by
\cite{shitole2021one}, which argues against the rigidity of static and shallow explanations and introduces a new method for compactly visualizing how different combinations of regions in images impact the confidence of a classifier. 
%Another notable work, 
Also, \cite{wang2019deliberative} aims to encourage the capturing of uncertain image regions, 
%However, 
while \cite{wang2019deliberative} focus on statically capturing ambiguities in an image with respect to the given classifier, we generate both certain and uncertain regions through %player
agent interactions in an iterative fashion \cite{Thauvin_24}.


\paragraph{Argumentation methods}
%Another avenue of 
Some research in XAI explores the use of computational argumentation \cite{vcyras2021argumentative}. 
%Computational argumentation 
This typically aims to assess specific claims by considering arguments that %both
support and/or challenge the claim, as well as their relations within %specific 
argumentative frameworks (AFs). 
These AFs 
%are often modeled based on principles advocated in works such as 
may be as in \cite{dung1995acceptability} or %in Bipolar Argumentation Frameworks 
Bipolar AFs (BAFs).
%At a broad level, 
Broadly, with our XAI 
approach 
\iffalse leads to debates that can be viewed as %simplified instances of AFs
simple BAFs; however, conducting a comprehensive analysis of these AFs' properties is beyond the scope of this paper. 
Instead, 
\fi 
we delve into a relatively unexplored area: explaining image classifiers through debates amounting to %(simple)
BAFs, which involve interactive gameplay among learning %players
agents. 
%
Other approaches employing AFs for explainable image classification either utilize intrinsically argumentative models, e.g. as in \cite{hamed}, or mirror the mechanics of the model itself, e.g. as seen in  \cite{Purin21}. 
In contrast, our approach focuses on explaining classifiers using latent features through (free) argumentative exchanges.
%\todo[inline]{add discussion of \cite{DS-visual debates}?} NO AS NOT ARG PROPER....

%\href{https://doi.org/10.1145/3539618.3591917}{related but probably not useful} 
%are we performing a form of \href{https://proceedings.mlr.press/v202/aher23a/aher23a.pdf}{Turing Experiment} for RL as they introduce?
%
%\href{https://www.ijcai.org/proceedings/2023/48}{an option} for providing depth with training examples



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Preliminaries}
\label{sec:prelim}

\subsection{Computational Argumentation Background}



We use (BAFs) \cite{Cayrol_05}, i.e. triples $\langle \Args, \Atts, \Supps \rangle$ such that $\Args$ is a finite set of \emph{arguments}, $\Atts \subseteq \Args \times \Args$ is an \emph{attack} relation and $\Supps \subseteq \Args \times \Args$
is a \emph{support} relation.
For all BAFs in this paper, we assume that $\Atts \!\cap \! \Supps \!= \!\emptyset$.
%Given a BAF   $\langle \Args, \Atts, \Supps \rangle$, for 
For 
any $\argument \!\in \! \Args$,  $\Atts(\argument)\!=\!\{ \otherargument \!\in \!\Args | (\otherargument, \argument) \!\in \! \Atts \}$ are the \emph{attackers}  of $\argument$ and  $\Supps(\argument)\!=\!\{ \otherargument \!\in \! \Args | (\otherargument, \argument) \!\in \!\Supps \}$ are the \emph{supporters} of $\argument$.

We use the following notation from \cite{Rago_23}:
given BAFs $\BAF\!=\!\langle \Args, \Atts, \Supps \rangle$, $\BAF'\!=\!\langle \Args', \Atts', \Supps' \rangle$, we say that $\BAF \sqsubseteq \BAF'$ iff $\Args\subseteq \Args'$,
$\Atts\subseteq \Atts'$ and
$\Supps\subseteq \Supps'$; 
also, we use $\BAF' \setminus \BAF$ to denote $\langle \Args' \setminus \Args, \Atts' \setminus \Atts, \Supps' \setminus \Supps \rangle$.
%Trivially, we 
We also say that $\BAF = \BAF'$ iff $\BAF \sqsubseteq \BAF'$ and $\BAF' \sqsubseteq \BAF$, and $\BAF \sqsubset \BAF'$ iff $\BAF \sqsubseteq \BAF'$ but $\BAF \neq \BAF'$. 

As conventional in the literature \cite{Baroni_19}, a BAF $\langle \Args, \Atts, \Supps \rangle$ may be equipped with
\emph{gradual semantics}
$\SF: \Args \rightarrow \Range$
assigning to arguments $\argument\in \Args$ values in 
$\Range$,
which is some set equipped with a pre-order $\leq$ (where, as usual $v < w$ denotes $v \leq w$ and $w \nleq v$).
In line with \cite{Rago_23}, we refer to $\SF$ as \emph{evaluation method} and to $\Range$ as \emph{evaluation range}, to indicate their use by agents
to evaluate arguments internally.
We say %that an evaluation method 
$\SF$ is \emph{dialectically monotonic} iff, %following a restricted form of monotony 
as in \cite{Baroni_19}: 
\begin{itemize}
    %
    \item given two BAFs $\BAF = \langle \Args, \Atts, \Supps \rangle$ and $\BAF' = \langle \Args', \Atts', \Supps' \rangle$, where $\Args' = \Args \cup \{ \arga \}$, $\Atts' \cup \Supps' = \Atts \cup \Supps \cup \{ (\arga, \argb) \}$, 
    it is always the case that if $(\arga, \argb) \in \Atts'$, then $\SF(\BAF',\argb) \leq \SF(\BAF,\argb)$, while if $(\arga, \argb) \in \Supps'$, then $\SF(\BAF',\argb) \geq \SF(\BAF,\argb)$; and
    %
    %\item \delete{given two BAFs $\BAF = \langle \Args, \Atts, \Supps \rangle$ and $\BAF' = \langle \Args', \Atts', \Supps' \rangle$, where $\Args' = \Args \cup \{ \arga \}$, $\Atts' = \Atts \cup \{ (\arga, \argb) \}$ and $\Supps' = \Supps$, it is always the case that $\SF(\BAF',\argb) \leq \SF(\BAF,\argb)$; and}
    %
    %\item \delete{given two BAFs $\BAF = \langle \Args, \Atts, \Supps \rangle$ and $\BAF' = \langle \Args', \Atts', \Supps' \rangle$, where $\Args' = \Args \cup \{ \arga \}$, $\Atts' = \Atts$ and $\Supps' = \Supps \cup \{ (\arga, \argb) \}$, it is always the case that $\SF(\BAF',\argb) \geq \SF(\BAF,\argb)$; and}
    %
    \item given two BAFs $\BAF = \langle \Args, \Atts, \Supps \rangle$ and $\BAF' = \langle \Args', \Atts', \Supps' \rangle$, where for an argument $\arga \in \Args \cap \Args'$, $\Atts'(\arga) = \Atts(\arga)$, $\Supps'(\arga) = \Supps(\arga)$, $\exists \argb \in \Atts'(\arga) \cup \Supps'(\arga)$ such that $\SF(\BAF',\argb) > \SF(\BAF,\argb)$ and $\forall \argc \in \Atts'(\arga) \cup \Supps'(\arga) \setminus \{ \argb \}$, $\SF(\BAF',\argc) = \SF(\BAF,\argc)$
    it is always the case that if $\argb \in \Atts'(\arga)$, then $\SF(\BAF',\arga) \leq \SF(\BAF,\arga)$, while if $\argb \in \Supps'(\arga)$, then $\SF(\BAF',\arga) \geq \SF(\BAF,\arga)$.
    %
\end{itemize}

\CR{The first bullet states that an argument‚Äôs strength cannot increase/decrease when a new attacker against/supporter for (respectively) the argument is added, all else being equal; the second bullet states that an argument‚Äôs strength cannot increase/decrease when an attacker against/supporter for (respectively) the argument is strengthened, all else being equal.}

Given a BAF $\BAF \!\!=\!\! \langle \Args, \Atts, \Supps \rangle$, for %any arguments 
$\arga, \argb \!\in \! \Args$,
we let a \emph{path} from $\arga$ to $\argb$ be defined as $(\argc_0,\argc_1), \ldots, (\argc_{n-1}, \argc_{n})$ for some $n\!>\!0$ (%i.e. 
the \emph{length} of the path) where $\argc_0 = \arga$, $\argc_n = \argb$ and, for any $1 \leq i \leq n$, $(\argc_{i-1}, \argc_{i}) \in \Atts \cup \Supps$. We also use $\argpaths(\arga,\argb)$ to denote the set of all paths from $\arga$ to $\argb$ (leaving the BAF implicit), and use $|p|$ for the length of path $p$. Also, we may see paths as sets of pairs. 
Then, 
as in \cite{Tarle_22,Rago_23},
we say that $\BAF$ is a \emph{BAF for explanandum $\arge\in \Args$} iff i.) $\nexists (\arge,\arga) \in \Atts \cup \Supps$; ii.) $\forall \arga \in \Args \setminus \{\arge\}$, there is a path from $\arga$ to $\arge$; and 
iii.) $\nexists \arga \!\in\! \Args$ with a path from $\arga$ to $\arga$.
%Also as in \cite{Rago_23}, we also use the notions of \emph{pro arguments} and \emph{con arguments} for $\BAF$, defined respectively as: $\Pros(\BAF) = \{ \arga \in \Args | \exists p \in \argpaths(\arga,\arge), \text{ where } | p \cap \Atts | \text{ is even} \}$ and $\Cons(\BAF) = \{ \arga \in \Args | \exists p \in \argpaths(\arga,\arge), \text{ where } | p \cap \Atts | \text{ is odd} \}$. \todo{delete pro con?}


%\todo{add a simple example?focusing on BAF for e vs non?} \AR{I wouldn't bothezr, the illustrated BAFs in the next section are already simple}



%\todo{do we also need to give credit to ``Multiagent Dynamics of Gradual Argumentation Semantics''? \AR{hmm maybe here will do?}}

\iffalse 

\todo{overkill/not needed?}
%\begin{definition}
%\label{def:tree}
    Given any BAF $\langle \Args, \Atts, \Supps \rangle$ % or QBAF $\langle \Args, \Atts, \Supps, \BS \rangle$. For 
    and $\arga, \argb \in \Args$, let a \emph{path} from $\arga$ to $\argb$ via a relation $\mathcal{R} \subseteq \Args \times \Args$ be defined as $(\argument_1,\argument_2), \ldots, (\argument_{n-1}, \argn)$ for some $n>0$ %(referred to as the \emph{length} of the path) 
    where $\argument_1 = \arga$, $\argn = \argb$ and, for any $1 < i \leq n$, $(\argument_{i-1}, \argi) \in %\Atts \cup \Supps
    \mathcal{R}$.\footnote{\delete{Later, we will use $\argpaths(\argx,\argy)$ to indicate the set of all paths between arguments $\argx$ and $\argy$, leaving the %(Q)
    BAF implicit, and  use $|p|$ for the length of path $p$. Also, we may see paths as sets of pairs.}} 
    Then, given $\arge \in \Args$, %$\mathcal{F}$ 
    $\langle \Args, \Atts, \Supps \rangle$ is 
    a \emph{BAF%/QBAF
    } %(respectively)  
    \emph{for $\arge$} iff
    i) $\nexists (\arge,\arga) \in \Atts \cup \Supps$;
    ii) $\forall \arga \in \Args \setminus \{\arge\}$, there is a path from $\arga$ to $\arge$ via $\Atts \cup \Supps$; and 
    iii) $\nexists \arga \in \Args$  with a path from $\arga$ to $\arga$ via $\Atts \cup \Supps$.
%\end{definition}
\todo{maybe I would keep it, need to introduce explananda though}

 








\todo{add note for shorthand notation of stance (or revert all which follows to full notation)}

%\begin{definition}
%\label{def:AXs}
Then, an \emph{Argumentative eXchange (AX) for an explanandum $\arge$ amongst agents} $\Agents$ (where $|\Agents| \geq 2$) is a tuple \\
$\langle \BAFx_{0}, \ldots, \BAFx_{n}, \Agents_0, \ldots,\Agents_n, \SpeakerM \rangle$ where $n>0$ and:
\begin{itemize}
    \item for every timestep $0 \leq t \leq n$:
    \begin{itemize}
        %
        \item $\BAFx_t = \langle \ArgsX_t, \AttsX_t, \SuppsX_t \rangle$ is a BAF for $\arge$, called the \emph{exchange BAF at $t$},  such that $\ArgsX_0 = \{ \arge \}$, $\AttsX_0 = \SuppsX_0 = \emptyset$ and for $t > 0$, $\BAFx_{t-1} \sqsubseteq \BAFx_{t}$;
        %
        \item $\Agents_t$ is a set of private triples $(\RangeI_t,\BAFi_t,\SFi_t)$ for $\arge$, one for each agent $\AgentI \in \Agents$, where, for $t >0$, $\RangeI_{t-1}=\RangeI_t$, $\SFi_{t-1}=\SFi_t$, $\BAFi_{t-1} \sqsubseteq \BAFi_{t}$ and $\BAFi_{t} \setminus \BAFi_{t-1} \sqsubseteq \BAFx_t \setminus \BAFx_{t-1}$;
        %
    \end{itemize}
    %
    \item $\SpeakerM$, referred to as the \emph{contributor mapping}, is a mapping such that, for every $(\arga,\argb) \in \AttsX_{n} \cup \SuppsX_{n}$ such that $\SpeakerM((\arga,\argb))=(\AgentI,t)$ with $0 < t \leq n$ and $\AgentI \in \Agents$.
]
\end{itemize}
%\end{definition}

Given that, for any agent $\AgentI \in \Agents$, $\SFi$ and $\RangeI$ do not vary with timestep, we drop the $t$ subscript from both in the remainder of the paper.

%\todo{need to say something about $n$ being the final state?}


%\begin{definition}
%\label{def:resolution}
    Let $E=\langle \BAFi_0, \ldots, \BAFi_{n},  \Agents_0,\ldots,\Agents_n, \SpeakerM \rangle$ be an AX for explanandum $\arge$ amongst agents $\Agents$ such that  $\Stance^j_0(\arge) \neq \Stance^k_0(\arge)$ for some $\Agents^j, \Agents^k \in \Agents$. Then: 
    \begin{itemize}
        %
        \item $E$ is \emph{resolved at timestep $t$}, for some $0< t \leq n$, iff $\forall \Agents^j, \Agents^k \in \Agents$, $\Stance^j_{t}(\arge) = \Stance^k_{t}(\arge)$, and is \emph{unresolved at $t$} otherwise;
        %
        \item $E$ is \emph{resolved} iff it is resolved at timestep $n$ and it is unresolved at every timestep $0 \leq t <n$; 
        %
        \item $E$ is \emph{unresolved} iff it is unresolved at every $0 < t \leq n$.
    \end{itemize}
%\end{definition}


\fi

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\subsection{Image Classification Set-up}



Consider a dataset $\mathcal{D} \subseteq \mathcal{X} \times \mathcal{Y}$, where $\mathcal{X} \in \mathbb{R}^{h \times w \times c}$ represents a vector space with dimensions $h \times w$ corresponding to an image and $c$ channels $(c \geq 1)$. 
The label space $\mathcal{Y} = {1, \dots, N}$ consists of $N \geq 2$ classes.
Following conventions in image classification \cite{huang2017densely,he2016deep}, we consider an image classifier trained on $\mathcal{D}$, comprising a feature extractor $f: \mathcal{X} \rightarrow \mathcal{Z}$ and a feature classifier $g:\mathcal{Z} \rightarrow \mathcal{Y}$. 
The feature extractor $f$ maps the observational space $\mathcal{X}$ to a continuous latent space $\mathcal{Z} \subseteq \mathbb{R}^{m\times d}$, where each element of $\mathcal{Z}$ represents a set of latent features with $m$ elements, each of length $d$.
Given an input $x \in \mathcal{X}$, the image classifier orders the classes in $\mathcal{Y}$ based on $g(f(x))$, predicting the top-class $y$ as the output (with an abuse of notation we often write $g(f(x))=y$).
Consistent with prior works \cite{van2017neural,kori2022explaining}, we assume the existence of a set $\mathcal{Z}^i\subset \mathcal{Z}$ of features associated with each class $i \in \mathcal{Y}$. 
These are referred to as the \emph{class-$i$-specific features}. Up to Section~\ref{sec:set-up}, we defer discussion on how these class-specific features are obtained.

 % We assume that each $\mathcal{Z}^i$ is a finite set $\{z^i_1, \ldots, z^i_{M^i}\}$, with $z^i_j \in \mathbb{R}^d$. 
 %\todo{we are mixing sets and vectors....to be discussed...\AR{it looks okay to me, $\mathcal{Z}^i$ and $\mathcal{Z}$ are sets of vectors}}
 %
%We also assume, for each class $j \in \mathcal{Y}$,  the existence of classifiers $q^i_j$ mapping from  $2^{\mathcal{Z}^i \cup \mathcal{Z}^j}$ to probabilities over $\mathcal{Y}$. We refer to $q^i_j$ as the \emph{class-$i$-specific classifier wrt class $j$}. 
%

 
%\todo{add a simple example - an image 2x2 with 2 channels (corresponding to two colours)? each cell could have a dot of one of two colours;  with two? latent features? and two classes? e.g. class 1 if pixels in cell (11) and (22) are the same colour? PROBABLY NO TIME}


% \delete{Each player maps a set of  latent representation $z' \in \mathcal{Z}$ to their \emph{private} set of discrete features $z^i$ and $z=\{z^1, \dots, z^K \}$ be a set of private features of all the players.  \todo{this isn't clear to me}.\footnote{In later sections, we discuss on how to extract these private features.}
% Then, let $h=\{h^1, \dots h^K\}$ and $q=\{q^1, \dots, q^K\}$ be the a \emph{context} information set encoding the state of the AXs and an agent specific classifier respectively, where $h^i, q^i$ is private to agent $\AgentI$.
% }


\section{Agents and 
%Explanatory Exchanges
Explanations}


Agents are represented as \emph{private triples for explananda}, a notion adapted from \cite{Rago_23}, as follows.

\begin{definition}
\label{def:agent}
An agent $\AgentI$ is a \emph{private triple for an explanandum $\arge$}, amounting to
 $(\RangeI,\BAFi,\SFi)$ where: 
    \begin{itemize}
        \item  $\RangeI = \RPosI \cup \RNegI$ is an evaluation range, referred to as $\AgentI$'s \emph{private 
        evaluation range},
         where $\RPosI$ (referred to as \emph{positive evaluations})
         and $\RNegI$ (referred to as \emph{negative evaluations}) are disjoint and for any $v_+ \in \RPosI$ and $v_- \in \RNegI$, $v_+ > v_-$;
        %
        \item  $\BAFi \!=\! \langle \ArgsI, \AttsI, \SuppsI \rangle$ is a BAF for $\arge$, referred to as $\AgentI$'s \emph{private BAF};
        %
        \item  $\SFi$  is an evaluation method, referred to as $\AgentI$'s \emph{private 
        evaluation method}, such that, for any BAF $\BAF = \langle \Args, \Atts, \Supps \rangle$ and, for any $\arga \in \Args$,
         $\SFi(\BAF,\arga) \in \RangeI$.
    \end{itemize}
\end{definition}


%Differently from \cite{Rago_23}, 
Here, we use BAFs instead of quantitative BAFs~\cite{Baroni_18} as in \cite{Rago_23}, and rely upon evaluation ranges split into two, rather than three, partitions as in \cite{Rago_23} (so we disregard the neutral partition in \cite{Rago_23}). 
\iffalse Note however that these BAFs and their evaluation method may be seen as abstractions of QBAFs under suitable semantics% applied and we make this modification to simplify notation only
.
\fi
%\todo{note that BAFs can be seens as abstractions of qbafs, once we have the semntics all cooked up....}
The threshold between the two partitions is seen as the point where an agent ``changes their mind'' on the explanandum, and may correspond to a classifier's decision boundary, as we will see later.
We assume, for the remainder of this section, that any evaluation method is dialectically monotonic (as defined in Section \ref{sec:prelim}).
\CR{We exemplify our notion of an agent in a simple, generic setting below (see Section~\ref{sec:EX-IC} for instantiations for image classification).}


\begin{example}
\label{ex:agents}
    An agent $\Agents^1$ is a private triple for an explanandum $a$, amounting to $(\Range^1,\BAF^1,\SF^1)$ where: $\Range^1 = [0,1]$ with $\RNeg^1 = [0,0.6[$ and $\RPos^1 = [0.6,1]$; $\BAF^1 = \langle \Args^1, \Atts^1, \Supps^1 \rangle$ such that $\Args^1 = \{ a, b \}$ with arguments
    $a$: \emph{we should eat at this pizzeria} and
    $b$: \emph{it is highly recommmended}, 
    $\Supps^1(a) = \{ (b, a) \}$ and 
    $\Atts^1(a) = \emptyset$; and $\SF^1$ is some dialectically monotonic semantics, which in this case could give, for example $\SF^1(\BAF^1,a)= 0.75$ and $\SF^1(\BAF^1,b)=0.5$ (given the asymmetric set-up of $a$'s attackers and supporters). 
    Here we can see that $\Agents^1$'s positive reasoning for the explanandum overcomes the (absent) negative reasoning against it, resulting in its strength being above the threshold of $0.6$ and thus gives a positive evaluation.
\end{example}

We define a novel form of \emph{argumentation exchanges} amongst agents% as follows (we will see later how these exchanges can serve as explanations)
, which will serve, later, as explanations:\footnote{ %Here and throughout the paper
Throughout, we denote with $[k]$ the set $\{0,1,\ldots,k\}$, with $]k]$ %the set 
$\{1,\ldots,k\}$, 
%\todo{with $[k[$?  $]k[$?}
etc.}

\begin{definition}
\label{def:FAXs}
    A \emph{free argumentative exchange (FAX) for an explanandum $\arge$ amongst agents} $\Agents$, where $|\Agents|=m \geq 2$ and each agent in $\Agents$ is a private triple for $\arge$, is a tuple:
    $$\langle \BAFx_0, \ldots, \BAFx_{n}, \Agents_0, \ldots,\Agents_n, \SpeakerM 
    \rangle \quad (n \geq 0)$$ 
    where, for all %$0 \leq t \leq n$
    timesteps $t \in [n]$, $\BAFx_t$ (referred to as the \emph{exchange BAF at step} $t$) is a BAF for $\arge$ and $\Agents_t$ is a set of $k$ agents, all private triples for  $\arge$, such that:
    \begin{itemize}
        \item  $\BAFx_0 = \langle \ArgsX_0, \AttsX_0, \SuppsX_0 \rangle$ is a BAF such that: 
        \begin{itemize}
            \item $\ArgsX_0 = \{ \arge \}$;
            %    
            %\item 
            $\AttsX_0 = \emptyset$;
            %
            %\item 
            $\SuppsX_0 = \emptyset$;
           
        \end{itemize}
         \item $\Agents_0=\Agents$;
    \end{itemize} 
    and, at timestep %$0 <t \leq n$
    $t \in ]n]$, letting
        $\BAFx_* = \langle \ArgsX_*, \AttsX_*, \SuppsX_* \rangle = \BAFx_t \setminus \BAFx_{t-1}$:
    \begin{itemize}
        
        %
        \item $\BAFx_{t} \sqsupseteq \BAFx_{t-1}$, where $\forall (a,b) \in \AttsX_*$, $\exists j \in ]m]$ such that $(a,b) \in \Atts^j_{t-1}$ and $\forall (c,d) \in \SuppsX_*$, $\exists k \in ]m]$ such that $(c,d) \in \Supps^k_{t-1}$;
        
        \item  $\Agents_t$ is a set of private triples $(\Range^i,\BAF^i_t,\SF^i)$ for $\arge$, one for each  %agent $\Agents^i \in \Agents$
        $i\in%\{1,\ldots,k\}
        ]m]$, where  $\BAFi_{t} \sqsupseteq \BAFi_{t-1}$ and $\ArgsX_* \subseteq \ArgsI_t$ and $\AttsX_* \cup \SuppsX_* \subseteq \AttsI_t \cup \SuppsI_t$; 
        %\todo{FT: should all  $\supseteq$ not be $\subseteq$? $=$? let us discuss, I am unclear... \AR{here we are just saying that all agents learn everything that is shared?}}
          %\todo{we removed the $t$ subscript in the AXIC work from $\RangeI$ and $\SFi$ since it's neater I think... }
    \end{itemize}
    $\SpeakerM$%, referred to as the \emph{contributor mapping}, is a mapping 
    \CR{is the \emph{contributor mapping},} such that, for  $\BAFx_n = \langle \ArgsX_n, \AttsX_n, \SuppsX_n \rangle$, for every $(\arga,\argb) \in \AttsX_{n} \cup \SuppsX_{n}$: $\SpeakerM((\arga,\argb))=(%\Agents^
    i,t)$ 
    %\todo{in AXs we have the agent being returned from this, not the index?} \todo{but this is a bit improper there...and here an agent is a triple, the index is the name of the agent....} 
    with %$0 < t \leq n$ 
    $i \in ]m]$ and  %$\Agents^i \in \Agents$
     $t \in ]n]$.
    %\footnote{\AR{We deviate from the notation in \cite{Rago_23} by referring to the agent's index, rather than the agent itself, in the codomain of $\SpeakerM$.\todo{why do we need to say this? we deviate about other small things and we do not make a fuss} \AR{I wasn't sure, happy to remove if you want}}}
\end{definition}
FAXs thus allow agents to add attacks or supports from their private to the exchange BAF, which are then incorporated to all other agents' frameworks as some form of relation. Note that it is only the BAFs which change with the timestep, not, for example, the evaluation ranges or methods.
Intuitively, the contributor mapping returns, for each attack/support pair in the final exchange BAF,  the agent who contributes the pair as well as the timestep at which the pair was contributed. Note that,  by defining $\SpeakerM$ as a mapping, we impose that there is a single contributor and timestep for each attack/support pair in the final exchange BAF, and therefore pairs cannot be introduced multiple times in FAXs%, in keeping with the choice of shared BAFs as \emph{BAFs for the explanandum} NOT SURE WHY THIS PLAYS A ROLE....
.
%
Note that FAXs are 
variants of argumentative exchanges (AXs) in \cite{Rago_23}:
whereas in AXs agents are equipped with quantitative BAFs, in FAXs they are equipped with BAFs;  
%\todo{eval range and method do not change over time in EXs, but they may in AXs. \AR{no, they do not in AXs either, we just included the notation there, which is thus redundant}} 
and, %giving their ``free'' nature, 
whereas in AXs agents are assumed to share a \emph{lingua franca} of arguments' attackers and supporters  (so that if an argument attacks or supports another for an agent it does so for all others), in FAXs attackers/supporters for an agent may be supporters/attackers for another% (but still they understand each others' arguments)
, witnessing the `free'' nature of FAXs.
%The following example illustrates
Next, we illustrate \CR{(in the earlier simple, generic setting)} why this may be useful.



\begin{example}
\label{ex:FAXs}
    Continuing from Example \ref{ex:agents}, a second agent 
    $\Agents^2$ is a private triple for $a$, amounting to $(\Range^2,\BAF^2,\SF^2)$ where: $\Range^2 = \Range^1$; $\BAF^2 = \langle \Args^2, \Atts^2, \Supps^2 \rangle$ such that $\Args^2 = \{ a, c \}$ with argument $c$: \emph{there is pineapple on the pizza},  $\Atts^2(a) = \{ (c, a) \}$ and
    $\Supps^2(a) = \emptyset$; 
    and $\SF^2$ is some dialectically monotonic semantics, which in this case could give, %for example 
    e.g., $\SF^2(\BAF^2,a)\!=\! 0.25$ and $\SF^2(\BAF^2,c)\!=\!0.5$ (again given the asymmetric set-up of $a$'s attackers and supporters).
    Here %we can see that 
    $\Agents^2$'s negative reasoning for the explanandum overcomes the (absent) positive reasoning against it, resulting in its strength being below the threshold of $0.6$ and thus gives a negative evaluation.
    A FAX for $a$ amongst agents $\Agents = \{ \Agents^1, \Agents^2 \}$ is then a tuple
    $\langle \BAFx_0, \BAFx_1, \BAFx_2, \Agents_0, \Agents_1, \Agents_2, \SpeakerM 
    \rangle$ such that:
    \begin{itemize}
    %
        \item $\BAFx_{1} \setminus \BAFx_{0} = \langle \{ b \}, \emptyset, \{ (b, a) \} \rangle$, where $\SpeakerM((b,a)) = (1, 1)$, and thus $\Agents_1 \neq \Agents_0$, where $\Agents_1^1 = \Agents_0^1$ and $\Agents_1^2 \neq \Agents_0^2$ with $\BAF^2_{1} \setminus \BAF^2_{0} = \langle \{ b \}, \emptyset, \{ (b, a) \} \rangle $;
        %
        \item $\BAFx_{2} \setminus \BAFx_{1} = \langle \{ c \}, \{ (c, a) \}, \emptyset \rangle$, where $\SpeakerM((c,a)) = (2, 2)$, and thus $\Agents_2 \neq \Agents_1$, where $\Agents_2^2 = \Agents_1^2$ and $\Agents_2^1 \neq \Agents_1^1$ with $\BAF^1_{2} \setminus \BAF^1_{1} = \langle \{ c \}, \emptyset, \{ (c, a) \} \rangle $.
    \end{itemize}
    %It can be seen here that the
    Here, support $(b,a)$ provided at timestep $2$ by $\Agents^1$ is learnt by $\Agents^2$ (as is conventional in AXs \cite{Rago_23}) as a support, indicating that the agents agree on the relation.
    Then, at timestep $2$, $\Agents^2$ provides the attack $(c,a)$, e.g. because pineapple on a pizza is anathema in Italy.
    However, $\Agents^1$ learns the relation $(c, a)$ as a support, indicating that they considered $c$ to be providing reasoning for $a$, e.g. because $\Agents^1$ likes pineapple on %their 
    pizza.
    This %demonstrates 
    shows how FAXs, differently to AXs, allow for differences in the way %that 
    agents interpret relations.
    Given that $\SF^1$ and $\SF^2$ are dialectically monotonic% semantics
    , we know that $\SF^1(\BAF^1_0, \arga) = \SF^1(\BAF^1_1, \arga) \leq \SF^1(\BAF^1_2, \arga)$ and $\SF^2(\BAF^2_0, \arga) \leq \SF^2(\BAF^2_1, \arga) = \SF^2(\BAF^2_2, \arga)$, respectively.
\end{example}

We can define a notion to restrict FAXs so that agents therein can be deemed to share a lingua franca, 
%which was enforced in \cite{Rago_23} but relaxed in FAXs, holds.
as follows.
\todoE{test how often this restriction is satisfied in practice?}

\begin{definition}
\label{def:linguafranca}
    Given a FAX $F$ for $e$ amongsts $\Agents$, with 
    $F=\langle \BAFx_0, \ldots,$ $ \BAFx_{n}, \Agents_0, \ldots,\Agents_n, \SpeakerM 
    \rangle$, $\Agents_n^i \in \Agents_n$ such that $\Agents_n^i=(\Range^i,\BAF^i_n,\SF^i)$ and  $\BAFi_n = \langle \ArgsI_n, \AttsI_n, \SuppsI_n \rangle$,
    %
    we say that $F$ has an \emph{effective lingua franca} iff    
    
    $(\bigcup_{\Agents^i_n \in \Agents_n} \AttsI_n ) \cap (\bigcup_{\Agents^i_n \in \Agents_n} \SuppsI_n ) \!=\! \emptyset$.
\end{definition}

It can be seen that the FAX in Example \ref{ex:FAXs} does not have a lingua franca since the agents disagree on the relation $(c,a)$.
%
%Intuitively, 
Typically, FAXs begin because there is a \emph{conflict} between agents, amounting to a different \emph{stance} on the explanandum: 

\begin{definition}
\label{def:stance} \label{def:conflict}
    Given an agent  $\AgentI$, i.e. a private triple $(\RangeI,\BAFi,\SFi)$    (for some explanandum $\arge$)  with $\BAFi = \langle \ArgsI, \AttsI, \SuppsI \rangle$, for any $\arga \in \ArgsI$, let $\AgentI$'s \emph{stance on $\arga$} be defined as $\StanceI(\BAFi,\arga) = +$ (\emph{positive stance}) iff $\SFi(\BAFi, \arga) \in \RPosI$, and $\StanceI(\BAFi,\arga) = -$ (\emph{negative stance}) otherwise.
%
Then, a set $\Agents$ of agents/ private triples for explanandum 
%the same 
$\arge$ is \emph{in conflict wrt $\arge$}  iff there are two or more agents in $\Agents$  with different stances on $\arge$.
\end{definition}

Note that this
 notion of stance is adapted from \cite{Rago_23}, ignoring the neutral stance therein.

We see FAXs as means to lead to resolution of initial conflicts, by allowing agents to argue while identifying and filling any gaps in their beliefs (represented by their private BAFs). We adapt the following from \cite{Rago_23}, to characterise FAXs successfully leading to resolution (or not), from an initial conflict.

\begin{definition}\label{def:resolution}
 Let  $\Agents$ be a set of agents/private triples for explanandum $\arge$.
 Let $\Agents$ be in conflict wrt %explanandum 
 $\arge$. %\todo{AR: in the AX paper we assumed a conflict existed?}
Let $F\!=\!\langle \BAFx_0, \ldots, \BAFx_{n}, \Agents_0, \ldots,\Agents_n, \SpeakerM 
    \rangle$ 
    be a FAX for $\arge$ amongst 
    $\Agents$. Then: 
    
    \begin{itemize}
        \item $F$ is 
        \emph{unresolved at timestep $t$}, for %$0< t \leq n$
        $t \in ]n]$, iff $\Agents_t$ is in conflict wrt $\arge$, and  \emph{resolved at $t$} otherwise;
         \item $F$ is \emph{unresolved} iff it is unresolved at every timestep 
        %$0 %\leq 
        %< t \leq n$
        $t \in ]n]$%\todo{should we not add 0?} NO, AS ASSUMING INITIAL CONFLICT
        ;
        \item $F$ is \emph{resolved} iff it is resolved at timestep $n$% \delete{and it is unresolved \todo{this may be too strong for IC, where we have a fixed length \AR{I think we can simplify to this and leave a footnote?}} at every timestep %$0 < t <n$
        %$t \in \{1,\ldots, n-1\}$}%\todo{should we not add 0?} NO, AS ASSUMING INITIAL CONFLICT
        . %\todo{it makes sense to me to say that you stop as soon as you resolve, is it? this is a choice, and does not need to be in the definition, it could be an assumption we make oiutside } 
       \end{itemize}
    \end{definition}

\begin{example}
\label{ex:(non)resolution}
  Continuing from Example \ref{ex:FAXs}, we know that $\SF^1(\BAF^1_0, \arga) \in \RPos^1$ and $\SF^2(\BAF^2_0, \arga) \in \RNeg^2$, and so $\Stance^1(\BAF^1_0, \arga) = +$ $\Stance^2(\BAF^2_0, \arga) = -$, meaning $\Agents$ is in conflict wrt $\arga$. 
  At timestep 1, let us assume that, although $\SF^2(\BAF^2_0, \arga) \leq \SF^2(\BAF^2_1, \arga)$, it remains the case that $\SF^2(\BAF^2_1, \arga) \in \RNeg^2$. Since $\SF^1(\BAF^1_0, \arga) = \SF^1(\BAF^1_1, \arga) \in \RPos^1$, we can see that the FAX is unresolved at timestep 1. Then, since $\SF^1(\BAF^1_1, \arga) \leq \SF^1(\BAF^1_2, \arga)$, thus $\SF^1(\BAF^1_2, \arga) \in \RPos^1$ and $\SF^2(\BAF^2_1, \arga) = \SF^2(\BAF^2_2, \arga)  \in \RNeg^1$, we know that $\Stance^1(\BAF^1_2, \arga) = +$, $\Stance^2(\BAF^2_2, \arga) = -$ and thus the FAX is unresolved.
  Meanwhile, if $\Agents^1$ had interpreted $(\argc,\arga)$ as an attack, let us say at an alternate $t=2'$, since $\SF^1$ is dialectically monotonic we know that it would have been the case that $\SF^1(\BAF^1_1, \arga) \geq \SF^1(\BAF^1_2, \arga)$, and the FAX may have been resolved if $\SF^1(\BAF^1_{2'}, \arga) \in \RNeg^1$, thus giving $\Stance^1(\BAF^1_{2'}, \arga) = \Stance^2(\BAF^2_{2'}, \arga) = -$.
\end{example}
 

When FAXs are used for conflict resolution,
exchange BAFs therein can be seen as \emph{explanations}, in that they unearth the reasoning behind the resolution or otherwise of the conflict amongst the agents, with evidence that the explanandum is ``correct'' or not (when the FAX is resolved, depending on the final stance of all agents) or why it cannot be deemed ``correct'' or otherwise (when the FAX is unresolved).
For illustration,
in the first FAX ($t=2$) in Example~\ref{ex:(non)resolution}, the agents do not share the same stance on the explanandum due to their differing interpretations of $(\argc,\arga)$,
whereas in the second FAX ($t=2'$), they agree on both this relation being an attack and on their final stances on the explanandum.
\iffalse 
%Based on the resolution of the FAX, we 
We now introduce levels of certainty in the explanations the FAXs represent,
based on their resolution, as follows. \todo{do we need this? do we ever use it?}

\begin{definition} 
\label{def:confidence}
    Let  $\Agents$ be a set of agents in conflict wrt %explanandum 
    $\arge$.
    Let $F=\langle \BAFx_0, \ldots, \BAFx_{n}, \Agents_0, \ldots,\Agents_n, \SpeakerM 
    \rangle$ 
    be a FAX for $\arge$ amongst 
    $\Agents$. Then $F$ has:   
    \begin{itemize}
     \item \emph{low certainty of $\arge$} iff $F$ is unresolved; 
        \item \emph{high certainty in favour of $\arge$} iff $F$ is resolved and, for all $\Agents_n^i \in \Agents_n$, with $\Agents_n^i=(\Range^i,\BAF^i_n,\SF^i)$,
        $\StanceI(\BAFi_n,\arge) = +$;
       \item \emph{high certainty against $\arge$} iff $F$ is resolved and, for all $\Agents_n^i \in \Agents_n$, with $\Agents_n^i=(\Range^i,\BAF^i_n,\SF^i)$,
        $\StanceI(\BAFi_n,\arge) = -$.
        %iff $e$ is either: 
        %\begin{itemize}
        %     \item unresolved; or
        %     \item resolved such that $\forall \Agents_n^i \in \Agents$ $\StanceI(\BAFi,\arge) = -$;
        % \end{itemize}  
    \end{itemize}
\end{definition}

Intuitively, the certainty level expressed by a FAX reflects how persuasive an explanation the (exchange BAF in the) FAX amounts to: a FAX with low certainty of the explanandum is not at all persuasive (either that the explanandum is ``correct'' or that it is not); a FAX with high certainty (in favour or against the explanandum) is highly persuasive  (that the explanandum is ``correct'' or not, respectively). 



%\begin{example}
It can be seen that for the FAXs in Example \ref{ex:(non)resolution}, that in which $(\argc,\arga)$ is interpreted by $\Agents^1$ as a support has low certainty of $\arga$, since all agents stand by their own, initial opinions. Meanwhile, that in which $(\argc,\arga)$ is interpreted as an attack, giving $\Stance^1(\BAF^1_2, \arga) = -$, has high certainty against $\arga$, since all agents form of negative opinion of the explanandum.
%Continuing from Example~\ref{ex:(non)resolution}, it can add argument here, something along the lines of $d$: it is not authentically italian. we could actually do something interesting here, e.g. include the attack $(d,a)$ for both agents but also the support $(c,d)$ for both agents
%\end{example}

 \fi

When using FAX for explaining image classification (from Section~\ref{sec:EX-IC}), we will restrict attention to special forms of FAXs, as follows.

\begin{definition}
A \emph{strictly interleaved FAX} for  $\arge$ amongst 
    $\Agents$ is a FAX
$\langle \BAFx_0, \ldots, \BAFx_{n}, \Agents_0, \ldots,\Agents_n, \SpeakerM 
    \rangle$ 
    for  $\arge$ amongst 
    $\Agents$ 
such that

    \begin{itemize}
        \item $\Agents=\{\Agents^1,\Agents^2\}$ (i.e. with $|\Agents|=2$);
    \item for each timestep %$0 <t \leq n$
    $t \in ]n]$ there exists exactly one $(\arga,\argb)$ \todoE{is this really happening in the implementation? to be discussed after deadline} such that $\SpeakerM((\arga,\argb))=(%\Agents^
    k,t)$ and %\AR{for $i,j \in \{ 1, 2\}$}
    %\begin{itemize}
        %\item 
        if $t$ is odd then %\delete{$\SpeakerM((\arga,\argb))=(\Agents^i,t)$}
        $k=%i
        1$;
        \CR{else $k=2$.}
        %
        %%%\item if $t$ is even then %\delete{$\SpeakerM((\arga,\argb))=(\Agents^j,t)$}
        %%%$k=%j
        %%%2$.
    %\end{itemize}
    \end{itemize} 
    %An \emph{equal opportunity strictly interleaved FAX} is a  strictly interleaved FAX where $n$ is even.
    If $n$ is even,
    then the %strictly interleaved 
    FAX is \emph{equal opportunity}.
    \end{definition}

%For illustration,
The FAX in Example~\ref{ex:FAXs} is equal opportunity strictly interleaved.
Intuitively,  in a strictly interleaved FAX agents take turns, contributing one attack/support at a time %.  In an equal opportunity strictly interleaved FAX both agents make
and making the same number of contributions, %so they 
to have the same chances at persuading the other% agent
.





\section{%FAXs 
Explanations for Image Classification}
\label{sec:EX-IC}


We see explanations for image classification as (exchange BAFs of) equal opportunity strictly interleaved FAXs amongst:
\begin{itemize}
    \item 
$\Agents^1$ (the \emph{proponent}, arguing for the class in $\mathcal{Y}$ predicted by the underlying image classifier for input image $x\in \mathcal{X}$ of interest), and

\item $\Agents^2$ (the \emph{opponent}, arguing against the predicted class). 
\end{itemize}
%
For simplicity, we restrict attention to the top two classes in the ordering determined by the image classifier ($g$, see Section~\ref{sec:prelim}) for the input image% of interest
, so that 
%agent 
$\Agents^2$
argues against the predicted (top) class by arguing for the 
second best in the ordering.
In the remainder of the paper we assume, without loss of generality, that class $1$ is the predicted class for $x$ and class $2$ is the second best. In line with the machine learning literature, we also  refer to class 1 as $y$.
%\delete{ and class 2 as $\overline{y}$}.

In our approach to explaining image classification using FAXs, each agent argues for a particular class, and thus class-specific features (see Section~\ref{sec:prelim}) play the role of arguments exchanged between agents.
The arguments put forward by the proponent and opponent can be seen as playing the role of positive and negative, respectively, feature attributions as in some XAI literature \cite{lime,SHAP,deeplift,selvaraju2017grad}. However, intuitively, the exchange BAF in the FAX can also convey the reasoning of the classifier.
%\delete{For it to be a \emph{faithful explanation} thereof,  the level of certainty of the FAX (as per Definition~\ref{def:confidence}) needs to ``match'' the classifier's ``confidence''.} 
We will provide an evaluation of FAXs as explanations of image classifiers in Section~\ref{sec:results}. Here, we focus on instantiating the generic FAXs for our purposes.    


Concretely, we assume that the two agents explaining the output of an underlying image classifier by virtue of a %(equal opportunity strictly interleaved) 
FAX 
can leverage on 
\emph{class-specific classifiers} $q^1:2^{\mathcal{Z}^1\cup\mathcal{Z}^2}\rightarrow [0%-1
,1]$ and $q^2:2^{\mathcal{Z}^1\cup\mathcal{Z}^2}\rightarrow [0%-1
,1]$, %\delete{respectively,} 
allowing the agents to evaluate sets of their own and other agents' arguments (in other words, amounting to their private evaluation methods). 
Until 
Section~\ref{sec:set-up}, we ignore how
%the
these class-specific classifiers can be learnt, alongside the class-specific features, so that they are faithful to the original image classifier being explained (see Section~\ref{sec:eval}), %\delete{as this faithfulness}
which is crucial to guarantee that FAXs as explanations are also faithful. 
%\delete{THIS SEEMS SWAPPED, AM I MISSING SOMETHING? refer to the agent-$1$-specific classifier wrt class $2$ simply as $q^1$ and to the agent-$2$-specific classifier wrt class $1$ as $q^2$}
We also refer to  the class-specific classifiers as \emph{private classifiers} (with $\mathcal{Z}^{1}$  and 
$\mathcal{Z}^{2}$
also referred to  as \emph{private features})%\todo{get rid of this if time})
.
Finally, given that we aim at explaining the output of the image classifier, we use 
$(x,y)$ as the \emph{explanandum} \arge.


%\delete{In the remainder of this section we} %define these concrete agents
We now instantiate the general Definition~\ref{def:agent}, describing agents, to capture proponent and opponent for image classification. 
%We characterise these agents argumentatively as follows:

\begin{definition}
\label{def:imagetriple}
    Let $\indexAg\in \{1,2\}$.  Then, the \emph{%(proponent/opponent)
    initial image classification agent} %$\Agents^i_0$ 
    is a private triple $(\RangeW,\BAFW,\SFW)$ for $(x,y)$ such that: 
    \begin{itemize}
        %
        \item $\RangeW \!=\! [0,1]$ is the  \emph{agent's evaluation range}, with $\RNeg^\indexAg\! =\! [0,\tau)$ and $\RPos^\indexAg \!=\! [\tau,1]$, for some \emph{threshold} $\tau \in [0,1]$; 
        %
        \item $\BAFW= \langle \ArgsW, \AttsW, \SuppsW \rangle$ is a BAF where if $i=1$ then
        \begin{itemize}
            %
            \item $\ArgsW \subseteq \{(x,y)\} \cup \mathcal{Z}^1$ such that $(x,y) \in \ArgsW$,
            %
            \item $\AttsW = \emptyset$,
            %
            \item $\SuppsW \subseteq \mathcal{Z}^1 \times \{(x,y)\}$; 
            %
        \end{itemize}
        and if $i=2$ then
        \begin{itemize}
            %
            \item $\ArgsW \subseteq \{(x,y)\} \cup \mathcal{Z}^2$ such that $(x,y) \in \ArgsW$,
            %
            \item $\AttsW \subseteq \mathcal{Z}^2 \times \{(x,y)\}$,
            %
            \item $\SuppsW = \emptyset$; 
            %
        \end{itemize}
        %
        \item $\SFW: \ArgsW \rightarrow \RangeW$ is such that:   
        \begin{itemize}
            %
            \item $\SFW(\BAFW,(x,y))= \qAgentW(\AttsW((x,y))\cup \SuppsW((x,y)))$;
            %
            \item for $z \in \ArgsW \setminus \{(x,y)\}$, %\delete{$\SFW(z)=|q^{\indexAg}(\AttsW((x,y)) \cup \SuppsW((x,y)) \cup  \{z\}) - \qAgentW((\AttsW((x,y)) \cup \SuppsW((x,y))) \setminus \{z\})|$}
            $\SFW(\BAFW,z)=q^{\indexAg}(\{ z \})$.   
            %
        \end{itemize}
        %
    \end{itemize}
  %  \todo{drop all of this?} \delete{Let $\indexotherAg \in \{1,2\}\setminus \{\indexAg\}$. When  $\AttsW \cap (\mathcal{Z}^{\indexotherAg}\times \{(x,y)\})=\emptyset$, $\SuppsW \cap (\mathcal{Z}^{\indexotherAg}\times \{(x,y)\})=\emptyset$ and $\ArgsW \subseteq \{(x,y)\} \cup \mathcal{Z}^{\indexAg}$, we refer to $\Agents^i$ / $(\RangeW,\BAFW,\SFW)$  as \emph{introverted}.}
\end{definition}


\begin{corollary}
\label{lem:tau}
    %if at the initial private BAFs the sets of non-zero strength attackers and supporters of the agents are non-empty, then there exists a threshold in which there is a conflict 
    \CR{If $\SF^1(\BAF^1,\!(x,y)) \!\!\neq\!\! \SF^2(\BAF^2,\!(x,y))$, i.e. 
    $\qAgentI( \Supps^1((x,y))) \!$ $\neq\! \qAgentJ(\Atts^2((x,y)))$, then $\exists \tau \in [0,1]$ such that $\Agents$ is in conflict.}
\end{corollary}

%\todo{how do we know strength is between 0 and 1? ADD LEMMA?}
%\AK{$q^i$ for any time t ranges between [-1, 1]}
Here, we use specialised notions compared to those in Definition~\ref{def:agent}. 
Specifically, the private BAFs are ``shallow'' and acyclic, with all attacks and supports from private features (of either agent) to the explanandum.
%\cite{Rago_23} as concerns the evaluation method and the structure of the BAFs%(which are shallow and acyclic)
%Attacks and supports are restricted so that features can attack/support the explanandum, but not vice-versa or one-another. Graphically, the considered BAFs are shallow (and acyclic), but they are nonetheless sufficient to provide explanations well-beyond the state-of-the-art in explainability for image classification, as we shall see.
The evaluation ranges are divided into positive and negative evaluations by a threshold $\tau$% (for simplicity, the same for both agents)
, which, as Lemma \ref{lem:tau} demonstrates, can be guaranteed to provide a dividing line between the two classes if the agents' class-specific features 
%are non-trivial (in that they 
have an effect on the private classifiers' outputs.
%\delete{Given that agents take opposite stances to start with, arguing for and against the classifier's output/explanandum and using their private classifiers to obtain the strength of the explanandum, in practice (Section~\ref{sec:set-up}) $\tau$  corresponds to the decision boundary of the classifier between top- and second-best class (thus, $\tau$ is the same for both agents).}
%\todo{check with avinash}
The evaluation method is defined in terms of the class-specific classifier of the agent: the evaluation of the explanandum is given by the classifier applied to its attackers and supporters (which are class-specific
features), while the evaluation of a class-specific feature is given by the private classifier applied to this feature only. 
%each agent's gradual semantics is defined in terms of the agent's private classifier, by assessing: for the explanandum, the agent's classifier's output for the features represented by the attackers and supporters; and for each argument constituting its attackers and supporters, the difference therein when the argument is removed. Our intuition here is for attackers and supporters of the explanandum to represent negative and positive contributions towards it. 
%
%\delete{Introvert agents use only their own class-specific features as arguments, alongside the explanandum. %Note that, in the case of introverted private triples, BAFs are further restricted so that only arguments drawn from the agent's private features are used.
% Non-introverted private triples, meanwhile, include attacks/supports from features of the other agent, which may emerge during FAXs when agents need to accommodate within their private triples the arguments put forward by the other agent, as we shall see.}

%
 

%\todo{massage some of this beforehand} Note that our notion of agent's private triple above is a variant of the notion of private triple  in \cite{Rago_23}: while they use Quantified BAFs (where arguments are equpped with a quantitative `bias') we use BAFs; 


%\delete{Given the lack of a fixed lingua franca among agents in FAXs, an agent may adopt different \emph{learning strategies} for incorporating unseen relations which are contributed by the other agent into their own private BAF.  We characterise a certain type of such strategies in the following. \todo{do we want to sell it as faithfulness?}}

% \begin{definition}
%     A \emph{monotonic FAX for an explanandum $(x,y)$ amongst agents} $\Agents = \{ \Agents^1, \Agents^2 \}$ is a FAX $\langle \BAFx_0, \ldots, \BAFx_{n}, \Agents_0, \ldots,\Agents_n, \SpeakerM 
%     \rangle$ where for $i, j \in \{ 1, 2 \}$ where $i \neq j$:
%     \begin{itemize}
%         \item  at timestep $0$, $\BAF^i_0 = \langle \Args^i_0, \Atts^i_0, \Supps^i_0\rangle$ is a BAF for $(x,y)$ such that: 
%         \begin{itemize}
%             \item $\Args^i_0 = \{ (x,y)\} \cup \mathcal{Z}^{i}$;
%             %    
%             \item $\Atts^i_0 \subseteq \mathcal{Z}^{i} \times \{ (x,y) \}$ where $\forall z \in \mathcal{Z}^{i}$, $(z, (x,y)) \in \Atts^i_0$ iff $q^{i}(\mathcal{Z}^{i} \cup  \{z\}) - q^{i}(\mathcal{Z}^{i} \setminus \{z\}) < 0$;
%             %
%             \item $\Supps^i_0 \subseteq \mathcal{Z}^{i} \times \{ (x,y) \}$ where $\forall z \in \mathcal{Z}^{i}$, $(z, (x,y)) \in \Supps^i_0$ iff $q^{i}(\mathcal{Z}^{i} \cup  \{z\}) - q^{i}(\mathcal{Z}^{i} \setminus \{z\}) \geq 0$;
           
%         \end{itemize}
%         \item and, at timestep $0 <t \leq n$, $\BAF^i_t = \langle \Args^i_t, \Atts^i_t, \Supps^i_t \rangle$ is a BAF for $(x,y)$ such that: 
%         \begin{itemize}
%             \item $\Args^i_t \setminus \Args^i_0  \subseteq \mathcal{Z}^{j}$;
%             %    
%             \item $\Atts^i_t \setminus \Atts^i_0 \subseteq \mathcal{Z}^{j} \times \{ (x,y) \}$ where $\forall (z, (x,y)) \in \Atts^i_t \setminus \Atts^i_0$, $q^{i}(\Atts^i_{t'}((z, (x,y))) \cup \Supps^i_{t'}((z, (x,y)))) - q^{i}(\Atts^i_{t'}((z, (x,y))) \cup \Supps^i_{t'}((z, (x,y))) \setminus \{ (z, (x,y)) \}) < 0$, where $\SpeakerM((z, (x,y))) = (\Agents^j, t')$; 
%             %
%             \item $\Supps^i_t \setminus \Supps^i_0 \subseteq \mathcal{Z}^{j} \times \{ (x,y) \}$ where $\forall (z, (x,y)) \in \Supps^i_t \setminus \Supps^i_0$, $q^{i}(\Atts^i_{t'}((z, (x,y))) \cup \Supps^i_{t'}((z, (x,y)))) - q^{i}(\Atts^i_{t'}((z, (x,y))) \cup \Supps^i_{t'}((z, (x,y))) \setminus \{ (z, (x,y)) \}) \geq 0$, where $\SpeakerM((z, (x,y))) = (\Agents^j, t')$.
%         \end{itemize}
%     \end{itemize} 
% \end{definition}

%how do agents choose their initial private BAFs? how do they decide how to update their provate BAFs during a FAX?
To obtain explanations for image classifiers, we will use FAXs where agents %\delete{are initially introverted and they} 
update their private BAFs guided by their private classifiers, using the following ``learning strategy''. 

%\delete{ Note also that this means that the initial (necessarily introverted) private triples are such that $\Agents^1$ has only supports towards the explanandum, and $\Agents^2$ has only attacks\todo{how are we sure about this? don't we need to impose it?}} ACTUALLY IT SEEMS FALSE FROM THE DEFINITION BELOW


\begin{definition}
\label{def:imagemonotonic}
    Let  $\langle \BAFx_0, \ldots, \BAFx_{n}, \Agents_0, \ldots,\Agents_n, \SpeakerM 
    \rangle$ be an equal opportunity strictly interleaved FAX for explanandum $(x,y)$ amongst initial image classification agents $\Agents = \{ \Agents^1, \Agents^2 \}$.  Then, for $i, j \in \{ 1, 2 \}$ with $i \neq j$,
     $\Agents^i$ adopts a \emph{dialectically monotonic learning strategy} iff
    %\begin{itemize}
    \iffalse 
        \item  \delete{at timestep $0$, $\BAF^i_0 = \langle \Args^i_0, \Atts^i_0, \Supps^i_0\rangle$ is such that: 
        \begin{itemize}
            \item $\Args^i_0 = \{ (x,y)\} \cup \mathcal{Z}^{i}$;
            %    
            \item $\Atts^i_0 \subseteq \mathcal{Z}^{i} \times \{ (x,y) \}$ where $\forall z \in \mathcal{Z}^{i}$, $(z, (x,y)) \in \Atts^i_0$ iff $q^{i}(\mathcal{Z}^{i}) - q^{i}(\mathcal{Z}^{i} \setminus \{z\}) < 0$;
            %
            \item $\Supps^i_0 \subseteq \mathcal{Z}^{i} \times \{ (x,y) \}$ where $\forall z \in \mathcal{Z}^{i}$, $(z, (x,y)) \in \Supps^i_0$ iff $q^{i}(\mathcal{Z}^{i} ) - q^{i}(\mathcal{Z}^{i} \setminus \{z\}) \geq 0$;
            %
        \end{itemize}
        \fi
     %   \item and,} 
     at timestep %$0 <t \leq n$
        $t \in ]n]$, if $\exists (z,(x,y))$ such that $\SpeakerM((z,(x,y)))=(%\Agents^
        i,t)$, then $\BAF^i_t = \BAF^i_{t-1}$; otherwise $\SpeakerM((z,(x,y)))=(%\Agents^
        j,t)$ and $\BAF^i_t = \langle \Args^i_t, \Atts^i_t, \Supps^i_t \rangle$ is such that: 
        \begin{itemize}
            
            \item %\delete{$(z,(x,y)) \in \Atts^i_t \setminus \Atts^i_{t-1}$ iff $q^{i}(\Atts^i_{t}((x,y)) \cup \Supps^i_{t}((x,y))) - q^{i}(\Atts^i_{t}((x,y)) \cup \Supps^i_{t}((x,y)) \setminus \{ z \}) < 0$;} 
            %\todo{probably better:}
            $(z,(x,y)) \!\in \! \Atts^i_t \!\setminus \!\Atts^i_{t-1}$ iff $q^{i}(\Atts^i_{t-1}((x,y)) \cup \Supps^i_{t-1}((x,y)) \cup \{ z \}) - q^{i}(\Atts^i_{t-1}((x,y)) \cup \Supps^i_{t-1}((x,y))) < 0$;
            %
            \item %\delete{$(z,(x,y)) \in \Supps^i_t \setminus \Supps^i_{t-1}$ iff $q^{i}(\Atts^i_{t}((x,y)) \cup \Supps^i_{t}((x,y))) - q^{i}(\Atts^i_{t}((x,y)) \cup \Supps^i_{t}((x,y)) \setminus \{ z \}) \geq 0$;} 
            %\todo{probably better:}
            $(z,(x,y)) \!\in \! \Supps^i_t \setminus \Supps^i_{t-1}$ iff $q^{i}(\Atts^i_{t-1}((x,y)) \cup \Supps^i_{t-1}((x,y)) \cup \{ z \}) - q^{i}(\Atts^i_{t-1}((x,y)) \cup \Supps^i_{t-1}((x,y))) \geq 0$;
            %
        \end{itemize}
        and $\SF^i$ is such that:
        \begin{itemize}
            %
            \item $\SF^i(\BAF^i_t,(x,y))= \qAgentW(\Atts^i_{t-1}((x,y)) \cup \Supps^i_{t-1}((x,y)) \cup \{ z \})$;
            %  
            \item $\forall z' \in \Args^i_t \cap \Args^i_{t-1}$, $\SF^i(\BAF^i_{t},z') = \SF^i(\BAF^i_{t-1},z')$; and 
            %
            
            
            \item $\SF^i(\BAF^i_{t},z) = |q^{i}(\Atts^i_{t-1}((x,y)) \cup \Supps^i_{t-1}((x,y)) \cup \{ z \}) -$ 
            
            $ q^{i}(\Atts^i_{t-1}((x,y)) \cup \Supps^i_{t-1}((x,y)))|$.
        \end{itemize}
    %\end{itemize}  
\end{definition}





In the remainder, we refer to equal opportunity strictly interleaved FAXs where both agents adopt a dialectically monotonic learning strategy simply as \FAXIC s.
%
%This type of learning strategy thus requires that 
Note that, in \FAXIC s, the initial private BAF of each agent %, which we know is flat and acyclic, 
contains all %\delete{attackers and supporters}
arguments representing the agent's private features. %which satisfy the conditions of Definition \ref{def:imagetriple}
%\delete{with a negative  and positive impact, respectively, on the agent's private classifier}. 
Then, any arguments learned from the other agent's contributions are such that their addition to the agent's private BAF results in dialectically monotonic behaviour (due to the agent's characterisation of the relation as an attacker or supporter), in the spirit of \cite{Rago_22}.
This naturally leads to% the following theoretical result%, which demonstrates the intuitive argumentative characteristics of the explanations
:


\begin{proposition}
    In any %strictly interleaved FAX $\langle \BAFx_0, \ldots, \BAFx_{n}, \Agents_0, \ldots,\Agents_n, \SpeakerM  \rangle$ 
    \FAXIC\ for an explanandum $(x,y)$ amongst agents $\Agents = \{ \Agents^1, \Agents^2 \}$, %where for $i, j \in \{ 1, 2 \}$ with $i \neq j$,
     for any $\Agents^i \in \Agents$, %if $\Agents^i$ adopts a dialectically monotonic learning strategy, then 
     $\SFi$ is dialectically monotonic. 
\end{proposition}


\begin{proof}
    %It can be seen 
    From Definition \ref{def:imagetriple}, %that 
    for any $\Agents^i \in \Agents$ and any timestep $t$, $\BAF^i_t$ is flat, i.e. it consists of the explanandum $(x,y)$ and its attackers or supporters.
    It can then be seen from Definition \ref{def:imagemonotonic} that the strength of any argument $a \in \Args^i \setminus \{ (x,y) \}$ does not change with the timestep (its attackers and supporters remain empty throughout), i.e. for any timesteps $t>0$, it is necessarily the case that $\SF^i(\BAF^i_t,a) = \SF^i(\BAF^i_{t-1},a)$. Thus, the last bullet of the definition of dialectical monotonicity (see Section \ref{sec:prelim}) is satisfied.
    Meanwhile, the first bullet can only apply to arguments added which attack or support $(x,y)$, since this is the only argument which is attacked or supported, by Definition \ref{def:imagetriple}.
    We can see from Definition \ref{def:imagemonotonic} that for any $t$ such that there exists some $(z,(x,y)) \in \Atts^i_t \setminus \Atts^i_{t-1}$, it is necessarily the case that $q^{i}(\Atts^i_{t}((x,y)) \cup \Supps^i_{t}((x,y))) < q^{i}(\Atts^i_{t-1}((x,y)) \cup \Supps^i_{t-1}((x,y)))$, and thus, by Definition \ref{def:imagetriple}, $\SF^i(\BAF^i_t,(x,y)) < \SF^i(\BAF^i_{t-1},(x,y))$.
    %
    Again from Definition \ref{def:imagemonotonic}, we can see that for any $t$ such that there exists some $(z,(x,y)) \in \Supps^i_t \setminus \Supps^i_{t-1}$, it is necessarily the case that $q^{i}(\Atts^i_{t}((x,y)) \cup \Supps^i_{t}((x,y))) \geq q^{i}(\Atts^i_{t-1}((x,y)) \cup \Supps^i_{t-1}((x,y)))$, and therefore, by Definition \ref{def:imagetriple}, $\SF^i(\BAF^i_t,(x,y)) \geq \SF^i(\BAF^i_{t-1},(x,y))$. 
    Thus, the property is satisfied in both cases for the first bullet, and dialectical monotonicity is satisfied overall.
\end{proof}


\iffalse 
This result is important because it sanctions the suitability of our choices in instantiating the semantics for \FAXIC s %for image classification
so that the resulting explanations have properties that argumentation practitioners have identified as important~\cite{Amgoud_18,Baroni_19,Potyka_21} and that humans find intuitive (as shown for a form of dialectical monotonicity in \cite{dax}).
\fi

\CR{This result sanctions that our choices in instantiating the semantics for \FAXIC s leads to explanations that are dialectically monotonic, which has been identified as an important property by argumentation practitioners~\cite{Amgoud_18,Baroni_19,Potyka_21} and found to be intuitive by humans (as shown for a form of dialectical monotonicity in \cite{dax}).}


\iffalse
Experiments:
\begin{itemize}
    \item checking number of each type of FAXs as per Definition \ref{def:confidence}
    \item checking how the types of FAXs as per Definition \ref{def:confidence} correspond to variance and bias of the classifiers
    %\item checking how often the effective lingua franca holds as per Definition \ref{def:linguafranca}
    \item checking how often attackers and supporters are monotonic?
\end{itemize}
\fi



\input{implementation}



\section{%Discussion
Conclusions}

%Our main focus in this paper was on generating highly expressive post-hoc explanations for image classification, pointing towards classifiers' inner reasoning. To achieve this goal, we considered 
We have defined explanations for image classification as (free) argumentative exchanges between two %fictional 
agents, %believing that we can 
aiming to demystify trained image classifiers based on the argument contribution strategies by %all the %players 
the agents. % involved in the exchange.
%Qualitatively, as opposed to 
Differently from standard feature attribution methods generating heatmaps over responsible regions in images, our %proposed explanations 
method generates more fine-grained composition of sub-regions, incrementally.
%\todo{comment on main argumentation takeaways ...}
%
Our work %presents %numerous 
opens 
many opportunities for future work. 
%One intriguing avenue  involves investigating 
We plan to investigate whether \FAXIC s can %effectively 
uncover shortcuts in classifiers% more adeptly than %standard 
%other methods% due to their nuanced nature
. 
Further, it would be valuable to collaborate with domain experts to attribute semantic meaning to %the contributed 
arguments, potentially aiding %in ontology 
alignment between human understanding and the latent knowledge of models.
\iffalse 
Also, given the tractability of our debate framework, particularly in settings with finite actions and %players
agents, \FAXIC s' scalability can be leveraged effectively. 
%As demonstrated in our experiments with the %more complex 
%AFHQ and FFHQ datasets, this scalability suggests promising applications across various domains.
\fi 
Also, it would be %particularly 
interesting to apply our approach in settings where quantized representation learning is already explored, ranging from natural images to medical data \cite{van2017neural,esser2021taming,santhirasekaram2022vector}\CR{, or by targeting other (potentially more complex) architectures, e.g. transformers \cite{Vaswani_17}}.
Methodologically,
we also plan to explore the use of object identification methods such as grounded slot attention \cite{ICLR24},
instead of quantization, 
%REPEATED FEATURES: PROBLEM WITH THE CODEBOOK, NOT THE REWARD THAT PUSHES FOR DIVERSITY...
to improve the human understandability of arguments in our \FAXIC s.
%\todo[inline]{massage rebuttal below}
\CR{Finally, a promising avenue for fully exploiting the capabilities of FAXs amounts to leveraging notions from \cite{Kenny_23,Santhirasekaram_23,Xie_23} to create hierarchical concepts, giving FAXs with more interesting argument interactions.
%including hierarchies as detailed in \cite{Xie_23}, leading to a three level hierarchy with data, feature and the output, potentially giving FAXs with more interesting argument interactions. Another option to achieve this would be to leverage notions from \cite{Kenny_23,Santhirasekaram_23} to create hierarchical concepts.
}


%\todo[inline]{add further future work:}

%\FT{it would definitely be interesting to consider recently proposed transformer-based architectures as a part of future work - we will mention this.}
%%% The acknowledgments section is defined using the "acks" environment
%%% (rather than an unnumbered section). The use of this environment 
%%% ensures the proper identification of the section in the article 
%%% metadata as well as the consistent spelling of the heading.



\begin{acks}
This research was partially supported by the ERC under the EU‚Äôs Horizon 2020 research and innovation programme (grant no. 101020934), by J.P. Morgan and the %Royal Academy of Engineering 
RAEng %under the Research Chairs and Senior Research Fellowships scheme 
(grant no. RCSRF2021/11/45) 
and by the UKRI (grant no. EP/S023356/1) via the CDT in Safe and Trusted Artificial Intelligence.
\end{acks}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%% The next two lines define, first, the bibliography style to be 
%%% applied, and, second, the bibliography file to be used.

\bibliographystyle{ACM-Reference-Format} 
\bibliography{ref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

