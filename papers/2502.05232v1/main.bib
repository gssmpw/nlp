@article{graves2012sequence,
  title={Sequence transduction with recurrent neural networks},
  author={Graves, Alex},
  journal={arXiv preprint arXiv:1211.3711},
  year={2012}
}

@inproceedings{graves2006connectionist,
  title={Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks},
  author={Graves, Alex and Fern{\'a}ndez, Santiago and Gomez, Faustino and Schmidhuber, J{\"u}rgen},
  booktitle={Proceedings of the 23rd international conference on Machine learning},
  pages={369--376},
  year={2006}
}

@article{chan2015listen,
  title={Listen, attend and spell},
  author={Chan, William and Jaitly, Navdeep and Le, Quoc V and Vinyals, Oriol},
  journal={arXiv preprint arXiv:1508.01211},
  year={2015}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}


@article{gulati2020conformer,
  title={Conformer: Convolution-augmented transformer for speech recognition},
  author={Gulati, Anmol and Qin, James and Chiu, Chung-Cheng and Parmar, Niki and Zhang, Yu and Yu, Jiahui and Han, Wei and Wang, Shibo and Zhang, Zhengdong and Wu, Yonghui and others},
  journal={arXiv preprint arXiv:2005.08100},
  year={2020}
}

@article{wu2016google,
  title={Google's neural machine translation system: Bridging the gap between human and machine translation},
  author={Wu, Yonghui and Schuster, Mike and Chen, Zhifeng and Le, Quoc V and Norouzi, Mohammad and Macherey, Wolfgang and Krikun, Maxim and Cao, Yuan and Gao, Qin and Macherey, Klaus and others},
  journal={arXiv preprint arXiv:1609.08144},
  year={2016}
}

@INPROCEEDINGS{ChiuEtAl18-sota,
  author={Chiu, Chung-Cheng and Sainath, Tara N. and Wu, Yonghui and Prabhavalkar, Rohit and Nguyen, Patrick and Chen, Zhifeng and Kannan, Anjuli and Weiss, Ron J. and Rao, Kanishka and Gonina, Ekaterina and Jaitly, Navdeep and Li, Bo and Chorowski, Jan and Bacchiani, Michiel},
  booktitle={2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={State-of-the-Art Speech Recognition with Sequence-to-Sequence Models}, 
  year={2018},
  volume={},
  number={},
  pages={4774-4778},
  keywords={Training;Hidden Markov models;Decoding;Task analysis;Optimization;Acoustics;Neural networks},
  doi={10.1109/ICASSP.2018.8462105}}
  
  @INPROCEEDINGS{MahadeokarEtAl21-alignment_restricted,
  author={Mahadeokar, Jay and Shangguan, Yuan and Le, Duc and Keren, Gil and Su, Hang and Le, Thong and Yeh, Ching-Feng and Fuegen, Christian and Seltzer, Michael L.},
  booktitle={2021 IEEE Spoken Language Technology Workshop (SLT)}, 
  title={Alignment Restricted Streaming Recurrent Neural Network Transducer}, 
  year={2021},
  volume={},
  number={},
  pages={52-59},
  keywords={Training;Transducers;Recurrent neural networks;Computational modeling;Throughput;Delays;Long short term memory;streaming;ASR;RNN-T;end-pointer;latency;token emission delays},
  doi={10.1109/SLT48900.2021.9383606}}
  
  @ARTICLE{PrabhavalkarEtAl24-E2ESurvey,
  author={Prabhavalkar, Rohit and Hori, Takaaki and Sainath, Tara N. and Schlüter, Ralf and Watanabe, Shinji},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing}, 
  title={End-to-End Speech Recognition: A Survey}, 
  year={2024},
  volume={32},
  number={},
  pages={325-351},
  keywords={Hidden Markov models;Training;Data models;Acoustics;Task analysis;Deep learning;Decoding;End-to-end;automatic speech recognition},
  doi={10.1109/TASLP.2023.3328283}}
  
  @article{Li2022-E2ESurvey,
  title={Recent advances in end-to-end automatic speech recognition},
  author={Li, Jinyu},
  journal={APSIPA Transactions on Signal and Information Processing},
  volume={11},
  number={1},
  year={2022},
  publisher={Now Publishers, Inc.}
}

@incollection{bourlard1996hybrid,
  title={Hybrid connectionist models for continuous speech recognition},
  author={Bourlard, Herv{\'e} and Morgan, Nelson},
  booktitle={Automatic Speech and Speaker Recognition: Advanced Topics},
  pages={259--283},
  year={1996},
  publisher={Springer}
}

@INPROCEEDINGS{monotonicrnnt,
  author={Tripathi, Anshuman and Lu, Han and Sak, Hasim and Soltau, Hagen},
  booktitle={2019 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)}, 
  title={Monotonic Recurrent Neural Network Transducer and Decoding Strategies}, 
  year={2019},
  volume={},
  number={},
  pages={944-948},
  keywords={Decoding;Computational modeling;Standards;Training;Recurrent neural networks;Speech recognition;Transducers},
  doi={10.1109/ASRU46091.2019.9003822}}
  
@misc{raffel2017online,
      title={Online and Linear-Time Attention by Enforcing Monotonic Alignments}, 
      author={Colin Raffel and Minh-Thang Luong and Peter J. Liu and Ron J. Weiss and Douglas Eck},
      year={2017},
      eprint={1704.00784},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{kuang2022pruned,
      title={Pruned RNN-T for fast, memory-efficient ASR training}, 
      author={Fangjun Kuang and Liyong Guo and Wei Kang and Long Lin and Mingshuang Luo and Zengwei Yao and Daniel Povey},
      year={2022},
      eprint={2206.13236},
      archivePrefix={arXiv},
      primaryClass={eess.AS}
}


@misc{dong2020cif,
      title={CIF: Continuous Integrate-and-Fire for End-to-End Speech Recognition}, 
      author={Linhao Dong and Bo Xu},
      year={2020},
      eprint={1905.11235},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@INPROCEEDINGS{rnnt-efficient-implementation,
  author={Bagby, Tom and Rao, Kanishka and Sim, Khe Chai},
  booktitle={2018 IEEE Spoken Language Technology Workshop (SLT)}, 
  title={Efficient Implementation of Recurrent Neural Network Transducer in Tensorflow}, 
  year={2018},
  volume={},
  number={},
  pages={506-512},
  keywords={Computational modeling;Graphics processing units;Transducers;Acoustics;Recurrent neural networks;Hidden Markov models;Benchmark testing;recurrent neural network transducer;forward-backward algorithm;TensorFlow;GPU;TPU},
  doi={10.1109/SLT.2018.8639690}}
  
@INPROCEEDINGS{forward-backward-efficiency,
  author={Sim, Khe Chai and Narayanan, Arun and Bagby, Tom and Sainath, Tara N. and Bacchiani, Michiel},
  booktitle={2017 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)}, 
  title={Improving the efficiency of forward-backward algorithm using batched computation in TensorFlow}, 
  year={2017},
  volume={},
  number={},
  pages={258-264},
  keywords={Hidden Markov models;Computational modeling;Recurrent neural networks;Acoustics;Training;Bidirectional control;forward-backward algorithm;connectionist temporal classification;lattice-free maximum mutual information},
  doi={10.1109/ASRU.2017.8268944}}
  
  
 @article{yeh2019transformer,
  title={Transformer-transducer: End-to-end speech recognition with self-attention},
  author={Yeh, Ching-Feng and Mahadeokar, Jay and Kalgaonkar, Kaustubh and Wang, Yongqiang and Le, Duc and Jain, Mahaveer and Schubert, Kjell and Fuegen, Christian and Seltzer, Michael L},
  journal={arXiv preprint arXiv:1910.12977},
  year={2019}
}
  
  
 @INPROCEEDINGS{transformer-transducer,
  author={Zhang, Qian and Lu, Han and Sak, Hasim and Tripathi, Anshuman and McDermott, Erik and Koo, Stephen and Kumar, Shankar},
  booktitle={ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Transformer Transducer: A Streamable Speech Recognition Model with Transformer Encoders and RNN-T Loss}, 
  year={2020},
  volume={},
  number={},
  pages={7829-7833},
  keywords={Transducers;Recurrent neural networks;Limiting;Computational modeling;Speech recognition;Encoding;Decoding;Transformer;RNN-T;sequence-to-sequence;encoder-decoder;end-to-end;speech recognition},
  doi={10.1109/ICASSP40776.2020.9053896}}
  
  @inproceedings{wang2020transformer,
  title={Transformer-based acoustic modeling for hybrid speech recognition},
  author={Wang, Yongqiang and Mohamed, Abdelrahman and Le, Due and Liu, Chunxi and Xiao, Alex and Mahadeokar, Jay and Huang, Hongzhao and Tjandra, Andros and Zhang, Xiaohui and Zhang, Frank and others},
  booktitle={ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={6874--6878},
  year={2020},
  organization={IEEE}
}


@article{liang2022debias,
  title={The Implicit Length Bias of Label Smoothing on Beam Search Decoding},
  author={Liang, Bowen and Wang, Pidong and Cao, Yuan},
  journal={arXiv preprint arXiv:2205.00659},
  year={2022}
}

@inproceedings{panayotov2015librispeech,
  title={Librispeech: an asr corpus based on public domain audio books},
  author={Panayotov, Vassil and Chen, Guoguo and Povey, Daniel and Khudanpur, Sanjeev},
  booktitle={2015 IEEE international conference on acoustics, speech and signal processing (ICASSP)},
  pages={5206--5210},
  year={2015},
  organization={IEEE}
}

@article{watanabe2017hybrid,
  title={Hybrid CTC/attention architecture for end-to-end speech recognition},
  author={Watanabe, Shinji and Hori, Takaaki and Kim, Suyoun and Hershey, John R and Hayashi, Tomoki},
  journal={IEEE Journal of Selected Topics in Signal Processing},
  volume={11},
  number={8},
  pages={1240--1253},
  year={2017},
  publisher={IEEE}
}


@inproceedings{variani2020hybrid,
  title={Hybrid autoregressive transducer (hat)},
  author={Variani, Ehsan and Rybach, David and Allauzen, Cyril and Riley, Michael},
  booktitle={ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={6139--6143},
  year={2020},
  organization={IEEE}
}

@inproceedings{meng2023modular,
  title={Modular hybrid autoregressive transducer},
  author={Meng, Zhong and Chen, Tongzhou and Prabhavalkar, Rohit and Zhang, Yu and Wang, Gary and Audhkhasi, Kartik and Emond, Jesse and Strohman, Trevor and Ramabhadran, Bhuvana and Huang, W Ronny and others},
  booktitle={2022 IEEE Spoken Language Technology Workshop (SLT)},
  pages={197--204},
  year={2023},
  organization={IEEE}
}

@inproceedings{szegedy2016rethinking,
  title={Rethinking the inception architecture for computer vision},
  author={Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jon and Wojna, Zbigniew},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2818--2826},
  year={2016}
}

@article{chorowski2016towards,
  title={Towards better decoding and language model integration in sequence to sequence models},
  author={Chorowski, Jan and Jaitly, Navdeep},
  journal={arXiv preprint arXiv:1612.02695},
  year={2016}
}

@article{zhang2023usm,
  title={Google usm: Scaling automatic speech recognition beyond 100 languages},
  author={Zhang, Yu and Han, Wei and Qin, James and Wang, Yongqiang and Bapna, Ankur and Chen, Zhehuai and Chen, Nanxin and Li, Bo and Axelrod, Vera and Wang, Gary and others},
  journal={arXiv preprint arXiv:2303.01037},
  year={2023}
}

@article{bengio2015scheduled,
  title={Scheduled sampling for sequence prediction with recurrent neural networks},
  author={Bengio, Samy and Vinyals, Oriol and Jaitly, Navdeep and Shazeer, Noam},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}

@inproceedings{rao2017exploring,
  title={Exploring architectures, data and units for streaming end-to-end speech recognition with rnn-transducer},
  author={Rao, Kanishka and Sak, Ha{\c{s}}im and Prabhavalkar, Rohit},
  booktitle={2017 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)},
  pages={193--199},
  year={2017},
  organization={IEEE}
}

@misc{wang2023massive,
      title={Massive End-to-end Models for Short Search Queries}, 
      author={Weiran Wang and Rohit Prabhavalkar and Dongseong Hwang and Qiujia Li and Khe Chai Sim and Bo Li and James Qin and Xingyu Cai and Adam Stooke and Zhong Meng and CJ Zheng and Yanzhang He and Tara Sainath and Pedro Moreno Mengibar},
      year={2023},
      eprint={2309.12963},
      archivePrefix={arXiv},
      primaryClass={eess.AS}
}


@inproceedings{DBLP:conf/interspeech/HwangSHS22,
  author       = {Dongseong Hwang and
                  Khe Chai Sim and
                  Zhouyuan Huo and
                  Trevor Strohman},
  editor       = {Hanseok Ko and
                  John H. L. Hansen},
  title        = {Pseudo Label Is Better Than Human Label},
  booktitle    = {Interspeech 2022, 23rd Annual Conference of the International Speech
                  Communication Association, Incheon, Korea, 18-22 September 2022},
  pages        = {1421--1425},
  publisher    = {{ISCA}},
  year         = {2022},
  url          = {https://doi.org/10.21437/Interspeech.2022-11034},
  doi          = {10.21437/INTERSPEECH.2022-11034},
  timestamp    = {Wed, 21 Jun 2023 17:18:06 +0200},
  biburl       = {https://dblp.org/rec/conf/interspeech/HwangSHS22.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@INPROCEEDINGS{chiu2021rnntgeneralize,
  author={Chiu, Chung-Cheng and Narayanan, Arun and Han, Wei and Prabhavalkar, Rohit and Zhang, Yu and Jaitly, Navdeep and Pang, Ruoming and Sainath, Tara N. and Nguyen, Patrick and Cao, Liangliang and Wu, Yonghui},
  booktitle={2021 IEEE Spoken Language Technology Workshop (SLT)}, 
  title={RNN-T Models Fail to Generalize to Out-of-Domain Audio: Causes and Solutions}, 
  year={2021},
  volume={},
  number={},
  pages={873-880},
  keywords={Training;Analytical models;Transducers;Recurrent neural networks;Predictive models;Data models;Task analysis;Speech recognition;RNN-T;end-to-end;sequence-to-sequence;long-form},
  doi={10.1109/SLT48900.2021.9383518}}
  
 %%%%%%%%%%%%% end of old references %%%%%%%%%%%%%%%%%%%
 
 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% new references added %%%%%%%%%%%%%%%%%%%%%%%%%%%%
 @INPROCEEDINGS{dong2018speech-transformer,
  author={Dong, Linhao and Xu, Shuang and Xu, Bo},
  booktitle={2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Speech-Transformer: A No-Recurrence Sequence-to-Sequence Model for Speech Recognition}, 
  year={2018},
  pages={5884-5888},
}

@INPROCEEDINGS{karita2019comparative,
  author={Karita, Shigeki and Chen, Nanxin and Hayashi, Tomoki and Hori, Takaaki and Inaguma, Hirofumi and Jiang, Ziyan and Someki, Masao and Soplin, Nelson Enrique Yalta and Yamamoto, Ryuichi and Wang, Xiaofei and Watanabe, Shinji and Yoshimura, Takenori and Zhang, Wangyou},
  booktitle={2019 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)}, 
  title={A Comparative Study on Transformer vs RNN in Speech Applications}, 
  year={2019},
  pages={449-456},
  }
  
@inproceedings{tian2019self-attention,
  title={Self-attention transducers for end-to-end speech recognition},
  author={Tian, Zhengkun and Yi, Jiangyan and Tao, Jianhua and Bai, Ye and Wen, Zhengqi},
  booktitle={Interspeech},
  pages={2019--2023},
  year={2019}
}

@article{chorowski2015attention-based,
  title={Attention-based models for speech recognition},
  author={Chorowski, Jan K and Bahdanau, Dzmitry and Serdyuk, Dmitriy and Cho, Kyunghyun and Bengio, Yoshua},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}

@article{chorowski2014end-to-end,
  title={End-to-end continuous speech recognition using attention-based recurrent nn: First results},
  author={Chorowski, Jan and Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1412.1602},
  year={2014}
}

@INPROCEEDINGS{bahdanau2016end-to-end,
  author={Bahdanau, Dzmitry and Chorowski, Jan and Serdyuk, Dmitriy and Brakel, Philémon and Bengio, Yoshua},
  booktitle={2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={End-to-end attention-based large vocabulary speech recognition}, 
  year={2016},
  volume={},
  number={},
  pages={4945-4949},
 }

@INPROCEEDINGS{mahadeokar2021alignment,
  author={Mahadeokar, Jay and Shangguan, Yuan and Le, Duc and Keren, Gil and Su, Hang and Le, Thong and Yeh, Ching-Feng and Fuegen, Christian and Seltzer, Michael L.},
  booktitle={2021 IEEE Spoken Language Technology Workshop (SLT)}, 
  title={Alignment Restricted Streaming Recurrent Neural Network Transducer}, 
  year={2021},
  volume={},
  number={},
  pages={52-59},
  }
  
  
@article{hochreiter1997long,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT press}
}

@INPROCEEDINGS{chen2022factorized,
  author={Chen, Xie and Meng, Zhong and Parthasarathy, Sarangarajan and Li, Jinyu},
  booktitle={ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Factorized Neural Transducer for Efficient Language Model Adaptation}, 
  year={2022},
  volume={},
  number={},
  pages={8132-8136},
}

@inproceedings{bahdanau2015neural,
  title={Neural machine translation by jointly learning to align and translate},
  author={Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
  booktitle={International Conference on Learning Representations},
  year={2015}
}

@inproceedings{berard2016listen,
      title={Listen and Translate: A Proof of Concept for End-to-End Speech-to-Text Translation}, 
      author={Alexandre Berard and Olivier Pietquin and Christophe Servan and Laurent Besacier},
      year={2016},
      booktitle={NIPS Workshop on End-to-End Learning for Speech and Audio Processing}
}

@inproceedings{liu-etal-2021-cross,
    title = "Cross Attention Augmented Transducer Networks for Simultaneous Translation",
    author = "Liu, Dan  and
      Du, Mengge  and
      Li, Xiaoxi  and
      Li, Ya  and
      Chen, Enhong",
    editor = "Moens, Marie-Francine  and
      Huang, Xuanjing  and
      Specia, Lucia  and
      Yih, Scott Wen-tau",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    pages = "39--55",
}

@inproceedings{chuang-etal-2021-investigating,
    title = "Investigating the Reordering Capability in {CTC}-based Non-Autoregressive End-to-End Speech Translation",
    author = "Chuang, Shun-Po  and
      Chuang, Yung-Sung  and
      Chang, Chih-Chiang  and
      Lee, Hung-yi",
    editor = "Zong, Chengqing  and
      Xia, Fei  and
      Li, Wenjie  and
      Navigli, Roberto",
    booktitle = "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021",
    month = aug,
    year = "2021",
    address = "Online",
    pages = "1068--1077",
}

@inproceedings{xue22022large-scale,
  author={Jian Xue and Peidong Wang and Jinyu Li and Matt Post and Yashesh Gaur},
  title={{Large-Scale Streaming End-to-End Speech Translation with Neural Transducers}},
  year=2022,
  booktitle={Proc. Interspeech 2022},
  pages={3263--3267}
}

@article{deng2023label-synchronous,
  title={Label-synchronous neural transducer for end-to-end ASR},
  author={Deng, Keqi and Woodland, Philip C},
  journal={arXiv preprint arXiv:2307.03088},
  year={2023}
}

@INPROCEEDINGS{zhang24cif-t,
  author={Zhang, Tian-Hao and Zhou, Dinghao and Zhong, Guiping and Zhou, Jiaming and Li, Baoxiang},
  booktitle={ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={CIF-T: A Novel CIF-Based Transducer Architecture for Automatic Speech Recognition}, 
  year={2024},
  pages={10531-10535},
  }
  
  
@inproceedings{tang-etal-2023-hybrid,
    title = "Hybrid Transducer and Attention based Encoder-Decoder Modeling for Speech-to-Text Tasks",
    author = "Tang, Yun  and
      Sun, Anna  and
      Inaguma, Hirofumi  and
      Chen, Xinyue  and
      Dong, Ning  and
      Ma, Xutai  and
      Tomasello, Paden  and
      Pino, Juan",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    pages = "12441--12455",
}

@article{tian2022bayes,
  title={Bayes risk ctc: Controllable ctc alignment in sequence-to-sequence tasks},
  author={Tian, Jinchuan and Yan, Brian and Yu, Jianwei and Weng, Chao and Yu, Dong and Watanabe, Shinji},
  journal={arXiv preprint arXiv:2210.07499},
  year={2022}
}

@article{tian2023bayes,
  title={Bayes Risk Transducer: Transducer with Controllable Alignment Prediction},
  author={Tian, Jinchuan and Yu, Jianwei and Chen, Hangting and Yan, Brian and Weng, Chao and Yu, Dong and Watanabe, Shinji},
  journal={arXiv preprint arXiv:2308.10107},
  year={2023}
}

@article{dai2019transformer,
  title={Transformer-xl: Attentive language models beyond a fixed-length context},
  author={Dai, Zihang and Yang, Zhilin and Yang, Yiming and Carbonell, Jaime and Le, Quoc V and Salakhutdinov, Ruslan},
  journal={arXiv preprint arXiv:1901.02860},
  year={2019}
}

@article{su2024roformer,
  title={Roformer: Enhanced transformer with rotary position embedding},
  author={Su, Jianlin and Ahmed, Murtadha and Lu, Yu and Pan, Shengfeng and Bo, Wen and Liu, Yunfeng},
  journal={Neurocomputing},
  volume={568},
  pages={127063},
  year={2024},
  publisher={Elsevier}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% new references not yet added %%%%%%%%%%%%%%%%%%%%%%%%%%%%
 
 
  
@inproceedings{sak2017recurrent,
  author={Haşim Sak and Matt Shannon and Kanishka Rao and Françoise Beaufays},
  title={{Recurrent Neural Aligner: An Encoder-Decoder Neural Network Model for Sequence to Sequence Mapping}},
  year=2017,
  booktitle={Proc. Interspeech 2017},
  pages={1298--1302},
  doi={10.21437/Interspeech.2017-1705},
  issn={2308-457X}
}

@inproceedings{zeyer2020new,
  title={A New Training Pipeline for an Improved Neural Transducer},
  author={Zeyer, Albert and Merboldt, Andr{\'e} and Schl{\"u}ter, Ralf and Ney, Hermann},
  year={2020},
  booktitle={Proc. Interspeech},
}



@article{chaudhari2021attentive,
author = {Chaudhari, Sneha and Mithal, Varun and Polatkan, Gungor and Ramanath, Rohan},
title = {An Attentive Survey of Attention Models},
year = {2021},
issue_date = {October 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {5},
issn = {2157-6904},
url = {https://doi.org/10.1145/3465055},
doi = {10.1145/3465055},
journal = {ACM Trans. Intell. Syst. Technol.},
month = {oct},
articleno = {53},
numpages = {32},
keywords = {neural networks, attention models, Attention}
}

@ARTICLE{galassi2021attention,
  author={Galassi, Andrea and Lippi, Marco and Torroni, Paolo},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Attention in Natural Language Processing}, 
  year={2021},
  volume={32},
  number={10},
  pages={4291-4308},
 }
 
@ARTICLE{brauwers2023general,
  author={Brauwers, Gianni and Frasincar, Flavius},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={A General Survey on Attention Mechanisms in Deep Learning}, 
  year={2023},
  volume={35},
  number={4},
  pages={3279-3298},
}
  
@inproceedings{mai23_interspeech,
  author={Florian Mai and Juan Zuluaga-Gomez and Titouan Parcollet and Petr Motlicek},
  title={{HyperConformer: Multi-head HyperMixer for Efficient Speech Recognition}},
  year=2023,
  booktitle={Proc. INTERSPEECH 2023},
  pages={2213--2217}
}

@article{parcollet2023summarymixing,
  title={SummaryMixing: A Linear-Complexity Alternative to Self-Attention for Speech Recognition and Understanding},
  author={Parcollet, Titouan and van Dalen, Rogier and Zhang, Shucong and Bhattacharya, Sourav},
  year={2023},
  journal={arXiv preprint arXiv:2307.07421},
}

@inproceedings{prabhavalkar2024extreme,
  title={Extreme encoder output frame rate reduction: Improving computational latencies of large end-to-end models},
  author={Prabhavalkar, Rohit and Meng, Zhong and Wang, Weiran and Stooke, Adam and Cai, Xingyu and He, Yanzhang and Narayanan, Arun and Hwang, Dongseong and Sainath, Tara N and Moreno, Pedro J},
  booktitle={ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={11816--11820},
  year={2024},
  organization={IEEE}
}

@inproceedings{kang2021partially,
  title={Partially overlapped inference for long-form speech recognition},
  author={Kang, Tae Gyoon and Kim, Ho-Gyeong and Lee, Min-Joong and Lee, Jihyun and Lee, Hoshik},
  booktitle={ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={5989--5993},
  year={2021},
  organization={IEEE}
}

@inproceedings{kim2023branchformer,
  title={E-branchformer: Branchformer with enhanced merging for speech recognition},
  author={Kim, Kwangyoun and Wu, Felix and Peng, Yifan and Pan, Jing and Sridhar, Prashant and Han, Kyu J and Watanabe, Shinji},
  booktitle={2022 IEEE Spoken Language Technology Workshop (SLT)},
  pages={84--91},
  year={2023},
  organization={IEEE}
}

@article{gers2000learning,
  title={Learning to forget: Continual prediction with LSTM},
  author={Gers, Felix A and Schmidhuber, J{\"u}rgen and Cummins, Fred},
  journal={Neural computation},
  volume={12},
  number={10},
  pages={2451--2471},
  year={2000},
  publisher={MIT press}
}