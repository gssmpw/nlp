%%%%%%%% ICML 2025 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}
\pdfoutput=1%For ARXIV
% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2025} with \usepackage[nohyperref]{icml2025} above.
\usepackage{hyperref}


% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
%\usepackage{icml2025}

% If accepted, instead use the following line for the camera-ready submission:
\usepackage[accepted]{icml2025}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{tcolorbox}
\usepackage{pifont}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}

%math commands
%%%%% NEW MATH DEFINITIONS %%%%%

\usepackage{amsmath,amsfonts,bm}

% Mark sections of captions for referring to divisions of figures
\newcommand{\figleft}{{\em (Left)}}
\newcommand{\figcenter}{{\em (Center)}}
\newcommand{\figright}{{\em (Right)}}
\newcommand{\figtop}{{\em (Top)}}
\newcommand{\figbottom}{{\em (Bottom)}}
\newcommand{\captiona}{{\em (a)}}
\newcommand{\captionb}{{\em (b)}}
\newcommand{\captionc}{{\em (c)}}
\newcommand{\captiond}{{\em (d)}}

% Highlight a newly defined term
\newcommand{\newterm}[1]{{\bf #1}}


% Figure reference, lower-case.
\def\figref#1{figure~\ref{#1}}
% Figure reference, capital. For start of sentence
\def\Figref#1{Figure~\ref{#1}}
\def\twofigref#1#2{figures \ref{#1} and \ref{#2}}
\def\quadfigref#1#2#3#4{figures \ref{#1}, \ref{#2}, \ref{#3} and \ref{#4}}
% Section reference, lower-case.
\def\secref#1{section~\ref{#1}}
% Section reference, capital.
\def\Secref#1{Section~\ref{#1}}
% Reference to two sections.
\def\twosecrefs#1#2{sections \ref{#1} and \ref{#2}}
% Reference to three sections.
\def\secrefs#1#2#3{sections \ref{#1}, \ref{#2} and \ref{#3}}
% Reference to an equation, lower-case.
\def\eqref#1{equation~\ref{#1}}
% Reference to an equation, upper case
\def\Eqref#1{Equation~\ref{#1}}
% A raw reference to an equation---avoid using if possible
\def\plaineqref#1{\ref{#1}}
% Reference to a chapter, lower-case.
\def\chapref#1{chapter~\ref{#1}}
% Reference to an equation, upper case.
\def\Chapref#1{Chapter~\ref{#1}}
% Reference to a range of chapters
\def\rangechapref#1#2{chapters\ref{#1}--\ref{#2}}
% Reference to an algorithm, lower-case.
\def\algref#1{algorithm~\ref{#1}}
% Reference to an algorithm, upper case.
\def\Algref#1{Algorithm~\ref{#1}}
\def\twoalgref#1#2{algorithms \ref{#1} and \ref{#2}}
\def\Twoalgref#1#2{Algorithms \ref{#1} and \ref{#2}}
% Reference to a part, lower case
\def\partref#1{part~\ref{#1}}
% Reference to a part, upper case
\def\Partref#1{Part~\ref{#1}}
\def\twopartref#1#2{parts \ref{#1} and \ref{#2}}

\def\ceil#1{\lceil #1 \rceil}
\def\floor#1{\lfloor #1 \rfloor}
\def\1{\bm{1}}
\newcommand{\train}{\mathcal{D}}
\newcommand{\valid}{\mathcal{D_{\mathrm{valid}}}}
\newcommand{\test}{\mathcal{D_{\mathrm{test}}}}

\def\eps{{\epsilon}}


% Random variables
\def\reta{{\textnormal{$\eta$}}}
\def\ra{{\textnormal{a}}}
\def\rb{{\textnormal{b}}}
\def\rc{{\textnormal{c}}}
\def\rd{{\textnormal{d}}}
\def\re{{\textnormal{e}}}
\def\rf{{\textnormal{f}}}
\def\rg{{\textnormal{g}}}
\def\rh{{\textnormal{h}}}
\def\ri{{\textnormal{i}}}
\def\rj{{\textnormal{j}}}
\def\rk{{\textnormal{k}}}
\def\rl{{\textnormal{l}}}
% rm is already a command, just don't name any random variables m
\def\rn{{\textnormal{n}}}
\def\ro{{\textnormal{o}}}
\def\rp{{\textnormal{p}}}
\def\rq{{\textnormal{q}}}
\def\rr{{\textnormal{r}}}
\def\rs{{\textnormal{s}}}
\def\rt{{\textnormal{t}}}
\def\ru{{\textnormal{u}}}
\def\rv{{\textnormal{v}}}
\def\rw{{\textnormal{w}}}
\def\rx{{\textnormal{x}}}
\def\ry{{\textnormal{y}}}
\def\rz{{\textnormal{z}}}

% Random vectors
\def\rvepsilon{{\mathbf{\epsilon}}}
\def\rvtheta{{\mathbf{\theta}}}
\def\rva{{\mathbf{a}}}
\def\rvb{{\mathbf{b}}}
\def\rvc{{\mathbf{c}}}
\def\rvd{{\mathbf{d}}}
\def\rve{{\mathbf{e}}}
\def\rvf{{\mathbf{f}}}
\def\rvg{{\mathbf{g}}}
\def\rvh{{\mathbf{h}}}
\def\rvu{{\mathbf{i}}}
\def\rvj{{\mathbf{j}}}
\def\rvk{{\mathbf{k}}}
\def\rvl{{\mathbf{l}}}
\def\rvm{{\mathbf{m}}}
\def\rvn{{\mathbf{n}}}
\def\rvo{{\mathbf{o}}}
\def\rvp{{\mathbf{p}}}
\def\rvq{{\mathbf{q}}}
\def\rvr{{\mathbf{r}}}
\def\rvs{{\mathbf{s}}}
\def\rvt{{\mathbf{t}}}
\def\rvu{{\mathbf{u}}}
\def\rvv{{\mathbf{v}}}
\def\rvw{{\mathbf{w}}}
\def\rvx{{\mathbf{x}}}
\def\rvy{{\mathbf{y}}}
\def\rvz{{\mathbf{z}}}
\def\rvdelta{{\boldsymbol{\delta}}}
\def\rvtheta{{\boldsymbol{\theta}}}
\def\rvthetacap{{\boldsymbol{\Theta}}}

% Elements of random vectors
\def\erva{{\textnormal{a}}}
\def\ervb{{\textnormal{b}}}
\def\ervc{{\textnormal{c}}}
\def\ervd{{\textnormal{d}}}
\def\erve{{\textnormal{e}}}
\def\ervf{{\textnormal{f}}}
\def\ervg{{\textnormal{g}}}
\def\ervh{{\textnormal{h}}}
\def\ervi{{\textnormal{i}}}
\def\ervj{{\textnormal{j}}}
\def\ervk{{\textnormal{k}}}
\def\ervl{{\textnormal{l}}}
\def\ervm{{\textnormal{m}}}
\def\ervn{{\textnormal{n}}}
\def\ervo{{\textnormal{o}}}
\def\ervp{{\textnormal{p}}}
\def\ervq{{\textnormal{q}}}
\def\ervr{{\textnormal{r}}}
\def\ervs{{\textnormal{s}}}
\def\ervt{{\textnormal{t}}}
\def\ervu{{\textnormal{u}}}
\def\ervv{{\textnormal{v}}}
\def\ervw{{\textnormal{w}}}
\def\ervx{{\textnormal{x}}}
\def\ervy{{\textnormal{y}}}
\def\ervz{{\textnormal{z}}}

% Random matrices
\def\rmA{{\mathbf{A}}}
\def\rmB{{\mathbf{B}}}
\def\rmC{{\mathbf{C}}}
\def\rmD{{\mathbf{D}}}
\def\rmE{{\mathbf{E}}}
\def\rmF{{\mathbf{F}}}
\def\rmG{{\mathbf{G}}}
\def\rmH{{\mathbf{H}}}
\def\rmI{{\mathbf{I}}}
\def\rmJ{{\mathbf{J}}}
\def\rmK{{\mathbf{K}}}
\def\rmL{{\mathbf{L}}}
\def\rmM{{\mathbf{M}}}
\def\rmN{{\mathbf{N}}}
\def\rmO{{\mathbf{O}}}
\def\rmP{{\mathbf{P}}}
\def\rmQ{{\mathbf{Q}}}
\def\rmR{{\mathbf{R}}}
\def\rmS{{\mathbf{S}}}
\def\rmT{{\mathbf{T}}}
\def\rmU{{\mathbf{U}}}
\def\rmV{{\mathbf{V}}}
\def\rmW{{\mathbf{W}}}
\def\rmX{{\mathbf{X}}}
\def\rmY{{\mathbf{Y}}}
\def\rmZ{{\mathbf{Z}}}

% Elements of random matrices
\def\ermA{{\textnormal{A}}}
\def\ermB{{\textnormal{B}}}
\def\ermC{{\textnormal{C}}}
\def\ermD{{\textnormal{D}}}
\def\ermE{{\textnormal{E}}}
\def\ermF{{\textnormal{F}}}
\def\ermG{{\textnormal{G}}}
\def\ermH{{\textnormal{H}}}
\def\ermI{{\textnormal{I}}}
\def\ermJ{{\textnormal{J}}}
\def\ermK{{\textnormal{K}}}
\def\ermL{{\textnormal{L}}}
\def\ermM{{\textnormal{M}}}
\def\ermN{{\textnormal{N}}}
\def\ermO{{\textnormal{O}}}
\def\ermP{{\textnormal{P}}}
\def\ermQ{{\textnormal{Q}}}
\def\ermR{{\textnormal{R}}}
\def\ermS{{\textnormal{S}}}
\def\ermT{{\textnormal{T}}}
\def\ermU{{\textnormal{U}}}
\def\ermV{{\textnormal{V}}}
\def\ermW{{\textnormal{W}}}
\def\ermX{{\textnormal{X}}}
\def\ermY{{\textnormal{Y}}}
\def\ermZ{{\textnormal{Z}}}

% Vectors
\def\vzero{{\bm{0}}}
\def\vone{{\bm{1}}}
\def\vmu{{\bm{\mu}}}
\def\vtheta{{\bm{\theta}}}
\def\va{{\bm{a}}}
\def\vb{{\bm{b}}}
\def\vc{{\bm{c}}}
\def\vd{{\bm{d}}}
\def\ve{{\bm{e}}}
\def\vf{{\bm{f}}}
\def\vg{{\bm{g}}}
\def\vh{{\bm{h}}}
\def\vi{{\bm{i}}}
\def\vj{{\bm{j}}}
\def\vk{{\bm{k}}}
\def\vl{{\bm{l}}}
\def\vm{{\bm{m}}}
\def\vn{{\bm{n}}}
\def\vo{{\bm{o}}}
\def\vp{{\bm{p}}}
\def\vq{{\bm{q}}}
\def\vr{{\bm{r}}}
\def\vs{{\bm{s}}}
\def\vt{{\bm{t}}}
\def\vu{{\bm{u}}}
\def\vv{{\bm{v}}}
\def\vw{{\bm{w}}}
\def\vx{{\bm{x}}}
\def\vy{{\bm{y}}}
\def\vz{{\bm{z}}}

% Elements of vectors
\def\evalpha{{\alpha}}
\def\evbeta{{\beta}}
\def\evepsilon{{\epsilon}}
\def\evlambda{{\lambda}}
\def\evomega{{\omega}}
\def\evmu{{\mu}}
\def\evpsi{{\psi}}
\def\evsigma{{\sigma}}
\def\evtheta{{\theta}}
\def\eva{{a}}
\def\evb{{b}}
\def\evc{{c}}
\def\evd{{d}}
\def\eve{{e}}
\def\evf{{f}}
\def\evg{{g}}
\def\evh{{h}}
\def\evi{{i}}
\def\evj{{j}}
\def\evk{{k}}
\def\evl{{l}}
\def\evm{{m}}
\def\evn{{n}}
\def\evo{{o}}
\def\evp{{p}}
\def\evq{{q}}
\def\evr{{r}}
\def\evs{{s}}
\def\evt{{t}}
\def\evu{{u}}
\def\evv{{v}}
\def\evw{{w}}
\def\evx{{x}}
\def\evy{{y}}
\def\evz{{z}}

% Matrix
\def\mA{{\bm{A}}}
\def\mB{{\bm{B}}}
\def\mC{{\bm{C}}}
\def\mD{{\bm{D}}}
\def\mE{{\bm{E}}}
\def\mF{{\bm{F}}}
\def\mG{{\bm{G}}}
\def\mH{{\bm{H}}}
\def\mI{{\bm{I}}}
\def\mJ{{\bm{J}}}
\def\mK{{\bm{K}}}
\def\mL{{\bm{L}}}
\def\mM{{\bm{M}}}
\def\mN{{\bm{N}}}
\def\mO{{\bm{O}}}
\def\mP{{\bm{P}}}
\def\mQ{{\bm{Q}}}
\def\mR{{\bm{R}}}
\def\mS{{\bm{S}}}
\def\mT{{\bm{T}}}
\def\mU{{\bm{U}}}
\def\mV{{\bm{V}}}
\def\mW{{\bm{W}}}
\def\mX{{\bm{X}}}
\def\mY{{\bm{Y}}}
\def\mZ{{\bm{Z}}}
\def\mBeta{{\bm{\beta}}}
\def\mPhi{{\bm{\Phi}}}
\def\mLambda{{\bm{\Lambda}}}
\def\mSigma{{\bm{\Sigma}}}

% Tensor
\DeclareMathAlphabet{\mathsfit}{\encodingdefault}{\sfdefault}{m}{sl}
\SetMathAlphabet{\mathsfit}{bold}{\encodingdefault}{\sfdefault}{bx}{n}
\newcommand{\tens}[1]{\bm{\mathsfit{#1}}}
\def\tA{{\tens{A}}}
\def\tB{{\tens{B}}}
\def\tC{{\tens{C}}}
\def\tD{{\tens{D}}}
\def\tE{{\tens{E}}}
\def\tF{{\tens{F}}}
\def\tG{{\tens{G}}}
\def\tH{{\tens{H}}}
\def\tI{{\tens{I}}}
\def\tJ{{\tens{J}}}
\def\tK{{\tens{K}}}
\def\tL{{\tens{L}}}
\def\tM{{\tens{M}}}
\def\tN{{\tens{N}}}
\def\tO{{\tens{O}}}
\def\tP{{\tens{P}}}
\def\tQ{{\tens{Q}}}
\def\tR{{\tens{R}}}
\def\tS{{\tens{S}}}
\def\tT{{\tens{T}}}
\def\tU{{\tens{U}}}
\def\tV{{\tens{V}}}
\def\tW{{\tens{W}}}
\def\tX{{\tens{X}}}
\def\tY{{\tens{Y}}}
\def\tZ{{\tens{Z}}}


% Graph
\def\gA{{\mathcal{A}}}
\def\gB{{\mathcal{B}}}
\def\gC{{\mathcal{C}}}
\def\gD{{\mathcal{D}}}
\def\gE{{\mathcal{E}}}
\def\gF{{\mathcal{F}}}
\def\gG{{\mathcal{G}}}
\def\gH{{\mathcal{H}}}
\def\gI{{\mathcal{I}}}
\def\gJ{{\mathcal{J}}}
\def\gK{{\mathcal{K}}}
\def\gL{{\mathcal{L}}}
\def\gM{{\mathcal{M}}}
\def\gN{{\mathcal{N}}}
\def\gO{{\mathcal{O}}}
\def\gP{{\mathcal{P}}}
\def\gQ{{\mathcal{Q}}}
\def\gR{{\mathcal{R}}}
\def\gS{{\mathcal{S}}}
\def\gT{{\mathcal{T}}}
\def\gU{{\mathcal{U}}}
\def\gV{{\mathcal{V}}}
\def\gW{{\mathcal{W}}}
\def\gX{{\mathcal{X}}}
\def\gY{{\mathcal{Y}}}
\def\gZ{{\mathcal{Z}}}

% Sets
\def\sA{{\mathbb{A}}}
\def\sB{{\mathbb{B}}}
\def\sC{{\mathbb{C}}}
\def\sD{{\mathbb{D}}}
% Don't use a set called E, because this would be the same as our symbol
% for expectation.
\def\sF{{\mathbb{F}}}
\def\sG{{\mathbb{G}}}
\def\sH{{\mathbb{H}}}
\def\sI{{\mathbb{I}}}
\def\sJ{{\mathbb{J}}}
\def\sK{{\mathbb{K}}}
\def\sL{{\mathbb{L}}}
\def\sM{{\mathbb{M}}}
\def\sN{{\mathbb{N}}}
\def\sO{{\mathbb{O}}}
\def\sP{{\mathbb{P}}}
\def\sQ{{\mathbb{Q}}}
\def\sR{{\mathbb{R}}}
\def\sS{{\mathbb{S}}}
\def\sT{{\mathbb{T}}}
\def\sU{{\mathbb{U}}}
\def\sV{{\mathbb{V}}}
\def\sW{{\mathbb{W}}}
\def\sX{{\mathbb{X}}}
\def\sY{{\mathbb{Y}}}
\def\sZ{{\mathbb{Z}}}

% Entries of a matrix
\def\emLambda{{\Lambda}}
\def\emA{{A}}
\def\emB{{B}}
\def\emC{{C}}
\def\emD{{D}}
\def\emE{{E}}
\def\emF{{F}}
\def\emG{{G}}
\def\emH{{H}}
\def\emI{{I}}
\def\emJ{{J}}
\def\emK{{K}}
\def\emL{{L}}
\def\emM{{M}}
\def\emN{{N}}
\def\emO{{O}}
\def\emP{{P}}
\def\emQ{{Q}}
\def\emR{{R}}
\def\emS{{S}}
\def\emT{{T}}
\def\emU{{U}}
\def\emV{{V}}
\def\emW{{W}}
\def\emX{{X}}
\def\emY{{Y}}
\def\emZ{{Z}}
\def\emSigma{{\Sigma}}

% entries of a tensor
% Same font as tensor, without \bm wrapper
\newcommand{\etens}[1]{\mathsfit{#1}}
\def\etLambda{{\etens{\Lambda}}}
\def\etA{{\etens{A}}}
\def\etB{{\etens{B}}}
\def\etC{{\etens{C}}}
\def\etD{{\etens{D}}}
\def\etE{{\etens{E}}}
\def\etF{{\etens{F}}}
\def\etG{{\etens{G}}}
\def\etH{{\etens{H}}}
\def\etI{{\etens{I}}}
\def\etJ{{\etens{J}}}
\def\etK{{\etens{K}}}
\def\etL{{\etens{L}}}
\def\etM{{\etens{M}}}
\def\etN{{\etens{N}}}
\def\etO{{\etens{O}}}
\def\etP{{\etens{P}}}
\def\etQ{{\etens{Q}}}
\def\etR{{\etens{R}}}
\def\etS{{\etens{S}}}
\def\etT{{\etens{T}}}
\def\etU{{\etens{U}}}
\def\etV{{\etens{V}}}
\def\etW{{\etens{W}}}
\def\etX{{\etens{X}}}
\def\etY{{\etens{Y}}}
\def\etZ{{\etens{Z}}}

% The true underlying data generating distribution
\newcommand{\pdata}{p_{\rm{data}}}
% The empirical distribution defined by the training set
\newcommand{\ptrain}{\hat{p}_{\rm{data}}}
\newcommand{\Ptrain}{\hat{P}_{\rm{data}}}
% The model distribution
\newcommand{\pmodel}{p_{\rm{model}}}
\newcommand{\Pmodel}{P_{\rm{model}}}
\newcommand{\ptildemodel}{\tilde{p}_{\rm{model}}}
% Stochastic autoencoder distributions
\newcommand{\pencode}{p_{\rm{encoder}}}
\newcommand{\pdecode}{p_{\rm{decoder}}}
\newcommand{\precons}{p_{\rm{reconstruct}}}

\newcommand{\laplace}{\mathrm{Laplace}} % Laplace distribution

\newcommand{\E}{\mathbb{E}}
\newcommand{\Ls}{\mathcal{L}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\emp}{\tilde{p}}
\newcommand{\lr}{\alpha}
\newcommand{\reg}{\lambda}
\newcommand{\rect}{\mathrm{rectifier}}
\newcommand{\softmax}{\mathrm{softmax}}
\newcommand{\sigmoid}{\sigma}
\newcommand{\softplus}{\zeta}
\newcommand{\KL}{D_{\mathrm{KL}}}
\newcommand{\Var}{\mathrm{Var}}
\newcommand{\standarderror}{\mathrm{SE}}
\newcommand{\Cov}{\mathrm{Cov}}
% Wolfram Mathworld says $L^2$ is for function spaces and $\ell^2$ is for vectors
% But then they seem to use $L^2$ for vectors throughout the site, and so does
% wikipedia.
\newcommand{\normlzero}{L^0}
\newcommand{\normlone}{L^1}
\newcommand{\normltwo}{L^2}
\newcommand{\normlp}{L^p}
\newcommand{\normmax}{L^\infty}

\newcommand{\parents}{Pa} % See usage in notation.tex. Chosen to match Daphne's book.

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\DeclareMathOperator{\sign}{sign}
\DeclareMathOperator{\Tr}{Tr}
\let\ab\allowbreak




% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Submission and Formatting Instructions for ICML 2025}

\begin{document}

\twocolumn[
\icmltitle{Optimizing Robustness and Accuracy in Mixture of Experts: \\ A Dual-Model Approach}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2025
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Xu Zhang}{iit}
\icmlauthor{Kaidi Xu}{drexel}
\icmlauthor{Ziqing Hu}{Perp}
\icmlauthor{Ren Wang}{iit}
% \icmlauthor{Firstname5 Lastname5}{yyy}
% \icmlauthor{Firstname6 Lastname6}{sch,yyy,comp}
% \icmlauthor{Firstname7 Lastname7}{comp}
%\icmlauthor{}{sch}
% \icmlauthor{Firstname8 Lastname8}{sch}
% \icmlauthor{Firstname8 Lastname8}{yyy,comp}
%\icmlauthor{}{sch}
%\icmlauthor{}{sch}
\end{icmlauthorlist}

\icmlaffiliation{iit}{Illinois Institute of Technology}
\icmlaffiliation{drexel}{Drexel University}
\icmlaffiliation{Perp}{Perplexity AI}

\icmlcorrespondingauthor{Ren Wang}{rwang74@iit.edu}
% \icmlcorrespondingauthor{Firstname2 Lastname2}{first2.last2@www.uk}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Machine Learning, ICML} % Ensure compatibility with hyperref

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
%\printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.

\begin{abstract}
Mixture of Experts (MoE) have shown remarkable success in leveraging specialized expert networks for complex machine learning tasks. However, their susceptibility to adversarial attacks presents a critical challenge for deployment in robust applications. This paper addresses the critical question of how to incorporate robustness into MoEs while maintaining high natural accuracy. We begin by analyzing the vulnerability of MoE components, finding that expert networks are notably more susceptible to adversarial attacks than the router. Based on this insight, we propose a targeted robust training technique that integrates a novel loss function to enhance the adversarial robustness of MoE, requiring only the robustification of one additional expert without compromising training or inference efficiency. Building on this, we introduce a dual-model strategy that linearly combines a standard MoE model with our robustified MoE model using a smoothing parameter. This approach allows for flexible control over the robustness-accuracy trade-off. We further provide theoretical foundations by deriving certified robustness bounds for both the single MoE and the dual-model. To push the boundaries of robustness and accuracy, we propose a novel joint training strategy JTDMoE for the dual-model. This joint training enhances both robustness and accuracy beyond what is achievable with separate models. Experimental results on CIFAR-10 and TinyImageNet datasets using ResNet18 and Vision Transformer (ViT) architectures demonstrate the effectiveness of our proposed methods.
\end{abstract}

\section{Introduction}
The Mixture of Experts (MoE) architecture has emerged as a powerful framework in machine learning, enabling models to capture complex patterns by combining the strengths of multiple specialized expert networks. Originally introduced to enhance model capacity without a proportional increase in computational cost, the MoE framework operates in a straightforward but effective way: different components of the model, known as experts, specialize in distinct tasks or features of the data \cite{jacobs1991adaptive,jordan1994hierarchical}. MoE leverage a router to dynamically assign input data to the most appropriate expert \cite{shazeer2017outrageously}. Such mechanism makes them particularly valuable in large-scale applications such as natural language processing \cite{du2022glam} and computer vision \cite{riquelme2021scaling}.

Despite their success in achieving high accuracy, MoE, similar to other deep learning models, are vulnerable to adversarial attacks. Adversarial examples, which are input samples perturbed by imperceptible noise, can induce deep learning models to produce incorrect predictions with high confidence \cite{goodfellow2014explaining,carlini2017towards,papernot2016limitations}, posing significant risks in safety-critical applications \cite{finlayson2019adversarial,li2023physics}. The same modular structure that empowers MoE renders them particularly susceptible to adversarial attacks, as each expert presents a potential vulnerability. Our experiments in Section~\ref{sec:assess_rob} confirm that targeting MoE experts can be an effective strategy for compromising the model, underscoring the need for enhanced robustness measures in MoE.

Adversarial Training (AT) and its variants have been extensively researched to defend against adversarial attacks, attracting considerable research interest \cite{mkadry2017towards,zhang2019theoretically,wang2020fast,Wong2020Fast}. However, these methods predominantly focus on standard architectures and don't directly address the unique challenges of MoE. The heterogeneous structure of MoE, comprising a router and multiple expert networks, complicates the application of traditional robustness techniques. A few existing works have explored adversarial robustness in MoE architectures \cite{puigcerver2022adversarial, zhang2023robust}. Nonetheless, they often fail to analyze the robustness of each component and typically only consider traditional AT or impose architectural restrictions. Moreover, the robustness enhancements in these works significantly degrade standard accuracy, limiting their practical utility.
\begin{figure*}[htbp]
\centering
\includegraphics[trim=10 10 10 2,clip,width=0.85\linewidth]{fig/Framework.drawio}
\caption{Illustration of our methods to enhancing the robustness of a single MoE and our joint training strategy for the dual-model. \textbf{Right:} Our single MoE robustification method enhances the robustness of a single MoE $F_R$ by introducing an additional term to reinforce the robustness of second-top expert $f_{2}$ beyond standard adversarial training. \textbf{Left:} The dual-model is a linear combination of a standard MoE $F_S$ and a robust MoE $F_R$. The jointly-trained dual-model (JTDMoE) improves robustness while maintaining high standard accuracy using a bi-level alternating training approach. 
}
\label{fig_overview}
\end{figure*}

In this paper, we aim to bridge the gap between adversarial robustness and accuracy in MoEs. We begin by examining MoE components to identify their susceptibility to adversarial attacks, finding that expert networks are more vulnerable than the router. Based on this, we propose Robust Training with Experts' Robustification (RT-ER) to enhance MoE robustness by applying robust training to the expert networks without sacrificing training or inference efficiency. Additionally, we explore combining standard and robust MoE models as dual-models to balance accuracy and robustness. We also derive theoretical robustness bounds for both the single MoE and dual-model, offering insights into achievable limits of adversarial robustness and guiding the development of a joint training strategy, JTDMoE. Our methods are illustrated in Figure~\ref{fig_overview}.

Our contributions are summarized as follows:
\begin{itemize}
  \setlength{\itemsep}{0pt}  
  \setlength{\parskip}{0pt}  
  \setlength{\parsep}{0pt}   
\item \textbf{Assessment of MoE Vulnerabilities and Incorporation of Robustness:} We identify key MoE components vulnerable to adversarial attacks and propose the RT-ER method, which enhances the robustness of expert networks within the MoE architecture while maintaining efficiency in both training and inference.
\item \textbf{Dual-Model Strategy:} We introduce a framework combining standard and robust MoE models to balance the trade-off between accuracy and robustness.
\item \textbf{Theoretical Foundations:} We derive robustness bounds for MoE and the dual-model, offering deeper insights into the capabilities and constraints of our approach.
\item \textbf{Joint Training Strategy:} Leveraging our theoretical findings, we develop a joint training strategy, JTDMoE, for the dual MoE model that enhances both robustness and accuracy. 
\end{itemize}

\section{Related Work}
MoE has long been explored in the machine learning community as a method for tackling complex tasks by combining specialized expert networks \cite{jacobs1991adaptive}. Each expert focuses on certain aspects of the data, and their outputs are combined through a weighted sum determined by a gating mechanism or router \cite{yuksel2012twenty}. A notable advancement is the sparsely gated MoE \cite{shazeer2017outrageously,wang2020deep,riquelme2021scaling,fedus2022switch,xue2022go}, which activates only a subset of experts based on a routing mechanism, allowing conditional computation and enabling models to scale parameters independently of computational cost \cite{patterson2021carbon}. This approach has been successfully applied in Natural Language Processing \cite{du2022glam,lewis2021base} and Computer Vision \cite{riquelme2021scaling,xue2022go}. 

Despite their widespread application, there has been limited research on the robustness of MoE, especially in adversarial settings.Small, carefully crafted perturbations, known as adversarial examples, can cause deep neural networks to make incorrect predictions\cite{goodfellow2014explaining,carlini2017towards,papernot2016limitations}. Defenses against such attacks often rely on adversarial training methods based on min-max optimization \cite{mkadry2017towards,zhang2019theoretically,wang2020fast,Wong2020Fast}. In the context of MoEs, only a few initial studies have begun exploring adversarial robustness with obvious limitations. The first work focused on Vision Transformers (ViTs) with MoE structures, examining the relationship between model capacity and robustness, only considering traditional adversarial training to robustify the model \cite{puigcerver2022adversarial}. Another study investigated adversarial robustness of MoEs with a method only working on convolutional neural networks \cite{zhang2023robust}. Moreover, these methods sacrifice standard accuracy for robustness, limiting their practical applications. Another line of related works is ensemble methods, which combine predictions from multiple models. Ensembles can improve robustness by aggregating predictions from multiple models, reducing the impact of individual vulnerabilities \cite{liu2018towards,alam2022resisting,co2022jacobian,bai2024improving,bai2024mixednuts}. While MoE models share conceptual similarities with ensembles by leveraging multiple sub-models, they differ fundamentally due to their dynamic routing mechanism, where a router assigns inputs to specific experts rather than combining outputs from all experts. This distinction necessitates tailored approaches for enhancing MoE robustness. Our work introduces a comprehensive framework to robustify MoEs while optimizing the balance between robustness and accuracy.

\section{Preliminaries}\label{sec:pre}
In this section, we introduce MoE architecture considered in this paper and outline how adversarial attacks can target different components of the MoE model.

\textbf{MoE Architecture.}
The MoE~\cite{jacobs1991adaptive,jordan1994hierarchical} is a neural network architecture that leverages multiple specialized sub-networks, known as experts, to improve modeling capacity and performance on complex tasks. A router (also referred to as a gating network) determines the contribution of each expert to the final prediction based on the input data. Formally, let $E$ denote the number of experts in the MoE model. Each expert is a function $f_i(\rvx)$, where $i=1,2,\cdots,E$, and $\rvx \in \sR^{d}$ represents the input data. The router computes routing weights $a_i(\rvx)$, which are typically non-negative and sum to one, i.e., $\sum_{i=1}^E a_i(\rvx)=1$. The final prediction of the MoE model is given by a weighted sum of the experts' outputs $F(\rvx)=\sum_{i=1}^E a_i(\rvx) f_i(\rvx)$. In our setup, the router $a_i(\rvx)$ is implemented using a fully connected layer, and each expert is a neural network tailored to capture specific aspects of the data.

\textbf{Adversarial Attacks on MoE Models.}
An adversarial attack on the entire MoE model seeks to find a perturbation $\rvdelta$ such that the model's output on the perturbed input $\rvx+\rvdelta$ differs significantly from the output on the original input $\rvx$ or its ground truth label $y$: $F(\rvx+\rvdelta)=\sum_{i=1}^E a_i(\rvx+\rvdelta) f_i(\rvx+\rvdelta)$, where the $\rvdelta$ is usually generated by maximizing the loss function $\arg\max_{\|\rvdelta\|_p \le \epsilon} \gL(F(\rvx+\rvdelta), y)$ under the $\ell_p$ norm and the attack budget $\epsilon$. We also consider loss terms that do not rely on $y$. Notice that the attack is on the whole MoE. We implement adversarial attacks focusing on specific components of the MoE model. An attack targeting the router aims to alter the routing weights without affecting the experts' outputs. The perturbation $\rvdelta$ is crafted by changing the router's decisions while the experts receiving the original input: $F(\rvx+\rvdelta)=\sum_{i=1}^E a_i(\rvx+\rvdelta) f_i(\rvx)$. An attack targeting the experts aims to alter the experts' outputs without changing the routing weights. $\rvdelta$ is designed such that: $F(\rvx+\rvdelta)=\sum_{i=1}^E a_i(\rvx) f_i(\rvx+\rvdelta)$. We remark that once the perturbation $\rvdelta$ is generated, it will be implemented on both the router and experts despite of its target.
\section{Robust Training for Mixture of Experts }
In this section, we aim to enhance the adversarial robustness of MoE. The key question we pose here is as follows.
\begin{tcolorbox}[before skip=2.0mm, after skip=2.0mm, boxsep=0.0cm, middle=0.1cm, top=0.1cm, bottom=0.1cm]
\textbf{(Q1)} \textit{Which part of MoE is most vulnerable to attacks and how should we robustify the critical part?}
\end{tcolorbox}

\subsection{Assessing the Robustness of MoE Components}\label{sec:assess_rob}
To enhance the robustness of MoE, it is essential to understand which component is most susceptible to adversarial attacks. We begin by assessing the robustness of both the router and expert networks in MoE when subjected to adversarial attacks. We analyze the vulnerability of these components by evaluating a standard MoE model trained with the cross-entropy loss $\arg\min_{\rvthetacap_S}\ell_{CE}(F_S(\rvx),y)$, where $F_S(\cdot)$ is the output of the standard MoE model $\rvthetacap_S$ that has only seen clean data during the training.


To specifically evaluate the accuracy and robustness of MoE, and the robustness of the router and the experts, we introduce four metrics: \ding{202} Standard Accuracy (\textbf{SA}) is the accuracy on clean test data; \ding{203} Robust Accuracy (\textbf{RA}) is the accuracy on adversarially perturbed test data generated by attacking the whole MoE; \ding{204} \textbf{RA-E} is the accuracy on adversarially perturbed test data generated by attacking the experts; \ding{205} \textbf{RA-R} is the accuracy on adversarially perturbed test data generated by attacking the router. The RA-E/RA-R reflects the experts'/router's ability to maintain correct predictions when subjected to adversarial perturbations. 
\begin{table}[htbp]
\centering
\caption{Robustness assessment of MoE components on CIFAR-10 and TinyImageNet. RA-E values are small under both Projected Gradient Descent Attack (PGD) \cite{mkadry2017towards} and AutoAttack (AA) \cite{croce2020reliable}, indicating the vulnerability of the experts. Throughout the paper, we highlight the most vulnerable metric in bold to emphasize its susceptibility.}
\label{table_smoe_vulnerability}
\resizebox{0.45\textwidth}{!}{
\begin{tabular}{ccccc}
    \hline
    \multicolumn{5}{c}{\textbf{CIFAR-10}} \\ \hline
	Attack Method  &  SA(\%)   & RA(\%) & RA-E(\%)   &   RA-R(\%)   \\ \hline
	PGD & 92.14 & 52.54 & \textbf{3.11} & 54.67 \\ \hline
	AutoAttack & 92.14 & 14.25 & \textbf{2.95} & 55.2 \\ \hline
    \multicolumn{5}{c}{\textbf{TinyImageNet}} \\ \hline
	Attack Method  &  SA(\%)   & RA(\%) & RA-E(\%)   &   RA-R(\%)   \\ \hline
	PGD & 82.05 & 34.53 & \textbf{29.21} & 59 \\ \hline
	AutoAttack & 82.05  & \textbf{14.24} & 26.11 & 58.95 \\ \hline

\end{tabular}
}
\end{table}

We conduct a pilot study on CIFAR-10 and TinyImageNet datasets using MoE models with four experts. For CIFAR-10, we use ResNet18 as experts and set $\epsilon = 8/255$. For TinyImageNet, we use ViT-small as experts with $\epsilon = 2/255$. We employ a 50-step Projected Gradient Descent Attack (PGD) \cite{mkadry2017towards} and AutoAttack (AA) \cite{croce2020reliable}. The results are summarized in Table~\ref{table_smoe_vulnerability}. On both datasets, the RA-R remains above 50\% under both PGD and AA, suggesting that the router maintains reasonable performance under attack. In contrast, the RA-E drops below 4\%/30\% on CIFAR-10/TinyImageNet, indicating that the experts are highly susceptible to adversarial perturbations. This vulnerability causes the overall RA of the MoE model to be low. The experimental results indicate that the expert networks are significantly more vulnerable to adversarial attacks than the router. This is due to the fact that the experts are more complex than the router architecture. These findings highlight the importance of focusing on enhancing the robustness of the expert networks to improve the overall resilience of MoE models against adversarial attacks.

\subsection{Incorporating Robustness into MoE Architecture}
To incorporate robustness into the MoE architecture, a straightforward approach is to apply traditional adversarial training \cite{mkadry2017towards}, which involves training the model on adversarial examples generated during training. The traditional adversarial training is defined as:
\begin{equation}\label{loss_at}
	\min_{\rvthetacap_R} \max_{\|\rvdelta\|_p \le \epsilon} \ell_{CE}(F_R(\rvx + \rvdelta),y),
\end{equation}
where $F_R(\cdot)$ is the output of the robust MoE model $\rvthetacap_R$ under robust training.
However, when applied to MoE models, traditional adversarial training exhibits several issues: (\textbf{I1}) \textbf{Low Robust Accuracy:} The final RA remains unacceptably low. In our experiments on CIFAR-10 with ResNet18 experts, the model achieves 79.08\% SA and only 53.74\% RA on the test set using PGD after 130 training epochs. (\textbf{I2}) \textbf{Training Instability:} The training process is unstable, with sudden drops in both SA and RA.  As shown in Figure~\ref{fig_at_moe}, both metrics decline sharply between epochs 80 and 90. This is due to the router selecting a different expert as the primary contributor when faced with adversarially perturbed inputs. Since standard adversarial training primarily focuses on optimizing the robustness of the overall model output, it may overlook individual experts’ robustness, resulting in some experts remaining vulnerable to attacks. Consequently, when the router routes to one of these weaker experts, the model’s robustness is compromised. These issues suggest that traditional adversarial training is not well-suited for MoE architectures due to the complex interplay between the router and expert networks. 

Based on our earlier assessment (in Section~\ref{sec:assess_rob}) that the experts are the most vulnerable components, we propose a new robust training approach that specifically targets enhancing the robustness of the expert networks. Our approach modifies the loss function to include a Kullback-Leibler (KL) divergence term that encourages the experts' outputs on adversarial examples to be similar to their outputs on clean inputs. We propose a Robust Training with Expert Robustification (RT-ER) approach:
\begin{equation}\label{loss_rmoe}
\begin{aligned}
\min_{\rvthetacap_R} [\gL_{rob}=&\max_{\|\rvdelta\|_p \le \epsilon} \ell_{CE}(F_R(\rvx + \rvdelta),y) \\&+ \beta \cdot \ell_{KL}(f_{2}(\rvx + \rvdelta),f_{2}(\rvx))],
\end{aligned}
\end{equation}
where \( f_2(\rvx) \) denotes the output of the expert with the second-largest router weight for the adversarial example. The term \(\ell_{KL}(f_{2}(\rvx + \rvdelta), f_{2}(\rvx))\) represents the KL divergence between the output of this expert on the adversarial example and its output on the clean input. RT-ER is compatible with various routing strategies. For instance, when the router employs a top- n  strategy, RT-ER selects an additional expert—one not initially chosen by the router—based on the router weights, leveraging the router’s output. We use KL divergence instead of cross-entropy because cross-entropy requires a well-defined ground truth for the target distribution, which is not applicable in this context. The hyperparameter $\beta$ controls the trade-off between MoE-wide robustness and expert-specific robustness. For clarity, we refer to the expert with the second-largest router weight as the second-top expert in the following discussion.

The concept of RT-ER is illustrated in the right panel of Figure~\ref{fig_overview}. By incorporating the KL divergence term, we explicitly encourage second-top expert to produce similar outputs for both clean and adversarial inputs. RT-ER offers several advantages: (\textbf{A1}) By penalizing deviations in experts' outputs due to adversarial perturbations, we strengthen the experts against attacks and thus contributes to better overall RA for the MoE model. (\textbf{A2}) The inclusion of the KL divergence term helps stabilize training by regularizing the experts' behavior. When second-top expert is also robust to adversarial inputs, the model maintains greater stability, even when the router activates different experts. This enhanced consistency reduces performance fluctuations under adversarial attacks, allowing the model to sustain stronger performance on adversarial samples. By ensuring all experts are robust, the model avoids scenarios where only a subset of experts is resilient, leaving others vulnerable. This uniform robustness across experts leads to a more reliable defense against adversarial perturbations, improving the model’s overall resilience. The effectiveness of our proposed robust training method is demonstrated through the experimental results presented in Section~\ref{sec_experiment}. We observe significant improvements in RA compared to traditional adversarial training and a more stable training process, validating the efficacy of focusing on expert robustness in MoE models.
\begin{table}[htbp]
\centering
\caption{Robustness evaluation of adversarial training (AT) and our method (RT-ER) under PGD attacks across different routing strategies. RT-ER consistently achieves higher robust accuracy (RA) than AT under both top-1 and top-2 routing strategies.}
\label{table_router_strategy}
\resizebox{0.4\textwidth}{!}{
\begin{tabular}{ccccc}
    \hline
    \multicolumn{5}{c}{\textbf{Top-1 Strategy}} \\ \hline
	Method  &  SA(\%)   & RA(\%) & RA-E(\%)   &   RA-R(\%)   \\ \hline
	AT & 79.08 & \textbf{53.74} & 73.85 & 78.91 \\ \hline
	RT-ER & 77.81 & \textbf{69.09} & 75.71 & 72.28 \\ \hline
    \multicolumn{5}{c}{\textbf{Top-2 Strategy}} \\ \hline
	Method  &  SA(\%)   & RA(\%) & RA-E(\%)   &   RA-R(\%)   \\ \hline
	AT & 79.20 & \textbf{54.65} & 74.66 & 76.09 \\ \hline
	RT-ER & 78.78  & \textbf{70.05} & 76.2 & 72.35 \\ \hline

\end{tabular}
}
\end{table}

Compared to AT, our proposed method, RT-ER, is more efficient and adaptable to various routing strategies, as demonstrated in Table~\ref{table_router_strategy}. We evaluate robustness under both the top-1 and top-2 routing strategies, where the router activates one or two experts, respectively. First, AT, as an end-to-end training approach, proves insufficient for robustifying MoE architectures. Even with AT applied, the MoE model achieves only around 54\% RA, whereas RT-ER improves RA by more than 16\%. Second, RT-ER effectively enhances robustness across different routing strategies, consistently outperforming AT under both top-1 and top-2 routing. Moreover, RT-ER requires training only one additional expert, introducing minimal overhead to training efficiency. Further robustness evaluations under smooth attacks on MoE are provided in Appendix~\ref{appendix_singleMoE}. In summary, RT-ER not only strengthens the robustness of MoE architectures but also preserves both training and inference efficiency.

\section{Dual-Model Strategy for Robustness and Accuracy}
While our proposed RT-ER method enhances robustness against adversarial attacks (measured by RA), it may inadvertently degrade performance on clean data (measured by SA). This prompts the following research question:
\begin{tcolorbox}[before skip=2.0mm, after skip=2.0mm, boxsep=0.0cm, middle=0.1cm, top=0.1cm, bottom=0.1cm]
\textbf{(Q2)} \textit{How can we incorporate robustness into Mixture of Experts while minimizing the robustness-accuracy trade-off?}
\end{tcolorbox}

\subsection{Dual-Model with Post-Training MoE}\label{subsec_combined_model}
Traditional MoE models are efficient but vulnerable to attacks, while robust MoEs withstand attacks but often reduce standard accuracy. We explore whether combining both models can balance robustness and accuracy. Let $F_S(\rvx)$ be a standard MoE and $F_R(\rvx)$ a robust MoE. The dual-model, $F_D(\rvx)$, is defined as:
\begin{equation}
F_D(\rvx) = (1-\alpha) \cdot F_S(\rvx) + \alpha \cdot F_R(\rvx),
\end{equation}
where $\alpha$ controls the robustness-accuracy trade-off. In general, the standard MoE exhibits higher SA, while the robust MoE exhibits higher RA. The parameter $\alpha$ controls the contribution of the robust MoE to the final prediction. As $\alpha$ increases, the robust MoE contributes more to the final prediction, enhancing adversarial robustness but potentially degrading performance on clean data. We set $\alpha \geq 0.5$ to ensure that the dual-model remains robust.

Although the dual-model structure helps balance performance on clean and adversarial data, it introduces additional complexity in understanding its robustness. To clarify the influence of each parameter on robustness, we derive a certified robustness bound for the dual model $F_D$.

We first provide the definition of certified robustness in MoE under the perturbation bounded by $\ell_p$ norm\footnote{While our theorems hold for $p\in [1,\infty)$, we implement $p=\infty$ in all our experiments.}

\begin{definition}\label{defi_rmoe_robust}
Consider a robust MoE $F_R : \sR^d \rightarrow \sR^c$ and an arbitrary input $\rvx \in \sR^d$. Let $y = \arg\max_i F_R(\rvx)$, with bound $\epsilon \geq 0$. We say $F_R$ is certifiably robust at $\rvx$ with bound $\epsilon$ if for all $k \neq y$ and $\rvdelta \in \sR^d$ such that $\|\rvdelta\|_p \leq \epsilon$, the following holds:
\begin{equation}
	F_R^{(y)}(\rvx + \rvdelta) \geq F_R^{(k)}(\rvx	+ \rvdelta)
\end{equation}
\end{definition}
This definition formalizes the certifiable robustness of $F_R$ at $x$, ensuring that the model's top prediction remains consistent under perturbations within an $\ell_p$-norm ball of radius $\epsilon$. For practical classifiers, the robust margin $F_R^{(y)}(\rvx + \rvdelta) - F_R^{(k)}(\rvx + \rvdelta)$ can be estimated by evaluating the confidence gap between predicted and runner-up classes on a strong adversarial input.

\begin{definition}
A function $f: \sR^d \rightarrow \sR$ is $\ell_p$-Lipschitz continuous if there exists $L \in (0,\infty)$ such that for all $\rvx^{\prime}, \rvx \in \sR^{d}$, $
| f(\rvx^{\prime}) - f(\rvx) | \leq L \| \rvx^{\prime} - \rvx \|_p
$. The Lipschitz constant of $f$ is defined as
\begin{equation}
	{Lip_p(f) := \inf \{L : |f(\rvx^{\prime}) - f(\rvx)| \leq L \|\rvx^{\prime} - \rvx\|_p \}}
\end{equation}
\end{definition}

Following the definition of $\ell_p$-Lipschitz continuity, we can introduce the following assumption:

\begin{assumption} \label{assumption_lipschitz}
Each expert and the router in the robust MoE $F_R(\rvx)$ is $\ell_p$-Lipschitz continuous, where the experts’ Lipschitz continuity is given by
\begin{equation}
	|f_{R_i}^{(y)} (\rvx + \rvdelta) - f_{R_i}^{(y)} (\rvx)| \leq L_{R_i}\|\rvdelta\|_p
\end{equation}
and the router’s Lipschitz continuity at $i$-th output by
\begin{equation}
	|a_{R_i}(\rvx + \rvdelta) - a_{R_i}(\rvx) | \leq r_{R_i} \|\rvdelta \|_p
\end{equation}
\end{assumption}

\begin{theorem}\label{theorem_rmoe}
Under Assumption~\ref{assumption_lipschitz}, let $ M_{R_i} \leq 1$ be an upper bound on $ f_{R_i}^{(y)}(\rvx) $ for any input $\rvx \in \sR^d$. Then the robustness bound $\epsilon$ for $F_R(\rvx)$ is:
\begin{equation}\label{eq_t_rmoe}
	\epsilon = \min_{k \neq y} \frac{F_R^{(y)}(\rvx) - F_R^{(k)}(\rvx) }{\sum_{i} (r_{R_i}M_{R_i} + a_{R_i}(\rvx)L_{R_i})},
\end{equation}
\end{theorem}
where $y$ is the true label and $k$ represents other classes. From Equation (\ref{eq_t_rmoe}), we observe that when the experts are complex neural networks, the robustness of the robust MoE is primarily determined by the Lipschitz constants of its individual experts. If any expert lacks robustness, the output of the vulnerable expert will vary significantly when handling adversarial inputs, indicating a large Lipschitz constant $L_{R_i}$. Consequently, the achievable certified robustness bound $\epsilon$ for the robust MoE becomes smaller. This implies that, to enhance the robustness of the robust MoE, it is essential to robustify each expert. This conclusion provides theoretical support for our proposed RT-ER method.

Motivated by Theorem 3.5 in~\cite{bai2024improving}, we derive a certified bound to provide a formal guarantee on the dual-model’s resistance to adversarial perturbations, stated as follows:

\begin{theorem}\label{theorem_dual_model}
For a dual-model $F_D(\rvx)$ comprising a standard MoE $F_S(\rvx)$ and a robust MoE $F_R(\rvx)$, with smoothing parameter $\alpha \in [\frac{1}{2},1]$, we have that $F_D(\rvx + \rvdelta) = y$ for all $\rvdelta \in \sR^d$ such that
\begin{equation}
	\|\rvdelta \|_{p} \leq \epsilon = \min_{k \neq y} \frac{\alpha  (F_R^{(y)}(\rvx) - F_R^{(k)}(\rvx))+\alpha-1}{\alpha \sum_i\left(2 r_{R_i}+a_{R_i}(\rvx)(L_{R_i}^{(y)}+L_{R_i}^{(k)})\right)}
\end{equation}
\end{theorem}

The proofs for Theorems~\ref{theorem_rmoe} and~\ref{theorem_dual_model} are provided in Appendix~\ref{appendix_proof}. Theorem~\ref{theorem_dual_model} demonstrates that the dual-model’s robustness is fundamentally rooted in the robust MoE, and increasing the margin $F_R^{(y)}(\rvx) - F_R^{(k)}(\rvx)$ could enhance the overall robustness bound. Additionally, each expert in the robust MoE influences both the robust MoE and the dual-model, underscoring the critical role of fortifying each expert’s robustness. This also supports the use of our proposed loss function in Equation (\ref{loss_rmoe}), designed to reinforce the robustness of individual experts in the MoE.

Based on Theorem~\ref{theorem_dual_model}, there are three ways to further enhance the robustness of the dual-model: increasing the value of $\alpha$, enlarging the margin, and decreasing the Lipschitz constant of both the experts and the router. To ensure that the dual-model retains its robustness, $\alpha$ must remain within the range of $[0.5,1]$. Furthermore, a higher value of $\alpha$, which implies a larger contribution of the robust MoE to the final prediction, would result in a decrease in SA, which contradicts the motivation for using the dual-model architecture. As for the Lipschitz constants, they have already been optimized during RT-ER. In summary, the most efficient way to enhance the dual-model’s performance is by enlarging its margin. Additionally, a larger margin also leads to better accuracy on clean data.

After analyzing the implications of the theorem, it becomes evident that the dual-model must excel as a unified system. This observation raises the following research question:

\begin{tcolorbox}[before skip=2.0mm, after skip=2.0mm, boxsep=0.0cm, middle=0.1cm, top=0.1cm, bottom=0.1cm]
\textbf{(Q3)} \textit{Can we further enhance performance by employing a joint training strategy?}
\end{tcolorbox}

\subsection{Boost Dual-Model with Joint Training}\label{sec:JTDMoE_definition}
Inspired by Theorem~\ref{theorem_dual_model} and the insights from Section~\ref{subsec_combined_model}, we explore the joint training strategy that considers both the dual-model and single components. By jointly training, we aim to increase the robust MoE’s margin, thereby boosting both robustness and accuracy. Traditional adversarial training methods focus primarily on the overall model robustness, often overlooking the individual robustness of each MoE component, making these methods less effective in improving MoE-specific robustness.

To address this gap, we introduce a novel adversarial training framework for the dual-model based on bi-level optimization. It provides a hierarchical learning approach, where the upper-level objective depends on the solution of the lower-level problem. Specifically, it is formulated as follows:
\begin{equation}\label{loss_dual_model}
\begin{aligned}
& \min_{\rvthetacap_S, \rvthetacap_R} \ell_{CE}(F_D(\rvx),y) ~~~~\text{subject to } \min_{\rvthetacap_R} \gL_{rob}, 
\end{aligned}
\end{equation}

where $\gL_{rob}$ denotes the proposed loss function in Equation (\ref{loss_rmoe}). Here, the dual-model parameters are divided into variables $\rvthetacap_R$ for the robust MoE and variables $\rvthetacap_S$ for the standard MoE. We term this new approach Joint Training for Dual-Model based on MoE (JTDMoE). JTDMoE promotes alignment between the standard MoE and robust MoE, ultimately enhancing the dual-model’s performance. The complete training process is outlined in Algorithm~\ref{algorithm_JTDMoE}.

\begin{algorithm}[]
\caption{The JTDMoE algorithm}
\label{algorithm_JTDMoE}
\begin{algorithmic}[1]
	\STATE{\textbf{Initialize:} robust MoE parameters $\rvthetacap_R$, standard MoE parameters $\rvthetacap_S$, batch size $\mathcal{b}$, and attack step count $K$.}
	\FOR{iteration $t = 0, 1, \dots$}
	\STATE{Lower-level $\rvthetacap_R$-update:
update $\rvthetacap_R$ by minimizing $\gL_{rob}$ using a $K$-step PGD attack on batch $\mathcal{B}$.}
	\STATE{Upper-level $\rvthetacap_S, \rvthetacap_R$-update:
update $\rvthetacap_S$ and $\rvthetacap_R$ by minimizing $\ell_{CE}(F_D(\rvx),y)$ on batch $\mathcal{B}$.}
	\ENDFOR
\end{algorithmic}
\end{algorithm}
The reason we use this bi-level alternating training approach is to enhance the dual-model’s accuracy on clean data while maintaining its robustness as much as possible. For the lower-level optimization problem, we use RT-ER to robustify the robust MoE, as the dual-model’s robustness derives from the robust MoE (Theorem~\ref{theorem_dual_model}). This approach leads to smaller Lipschitz constants for the experts and router, thus guaranteeing the dual-model’s robustness. For the upper-level optimization problem, our goal is to enhance the dual-model’s SA by minimizing $\ell_{CE}(F_D(\rvx),y)$. Additionally, the margin of the robust MoE can increase as a side effect, further improving the dual-model’s robustness. Based on this analysis, we argue that the dual-model can enhance its performance in both SA and RA through the JTDMoE approach.

\section{Experiments}\label{sec:experiments}
In this section, we present the effectiveness of our proposed RT-ER and the JTDMoE approach.
\setlength{\textfloatsep}{0pt} 
\begin{table*}[htbp]
\centering
\caption{Evaluation of our proposed methods, RT-ER, Dual-Model (Pretrained), and Dual-Model (JTDMoE), compared with Standard Training (ST) and Adversarial Training (AT) \cite{madry2018towards} on the CIFAR-10 and TinyImageNet datasets. We report standard accuracy (SA), robust accuracy against attacks on the entire model (RA), on experts (RA-E), and on the router (RA-R) using a 50-step PGD attack~\cite{madry2018towards} in the single MoE scenario. The RT-ER method achieves the highest RA, RA-E, and RA-R among single MoE models. For dual-model scenarios, RA-R and RA-E are replaced with robust accuracy against attacks on the robust MoE (RA-RMoE) and on the standard MoE (RA-SMoE). The results show that the Dual-Model improves upon RT-ER in the accuracy-robustness trade-off, and our JTDMoE method outperforms the Dual-Model (Pre-trained) under the same smoothing parameter $\alpha$.}
\label{table_experimental_results}
\resizebox{0.83\linewidth}{!}{
\begin{tabular}{*{10}{c}}
\toprule
\multicolumn{5}{c|}{\textbf{CIFAR-10}} & \multicolumn{5}{|c}{\textbf{TinyImageNet}} \\ \midrule
\multicolumn{10}{c}{Single MoE Performance} \\ \midrule
 Method & SA(\%) & RA(\%) & RA-E(\%) & \multicolumn{1}{c|}{RA-R(\%)} & \multicolumn{1}{|c}{Method} & SA(\%) & RA(\%) & RA-E(\%) & RA-R(\%)\\ \hline
 ST & 92.14 & 52.54 & \textbf{3.11} & \multicolumn{1}{c|}{54.67} & \multicolumn{1}{|c}{ST} & 82.05 & 34.53 & \textbf{29.21} & 59.00 \\ \hline
 AT & 79.08 & \textbf{53.74} & 73.85 &  \multicolumn{1}{c|}{78.91}  & \multicolumn{1}{|c}{AT} & 70.77 & 50.94  & \textbf{42.09} & 83.81 \\ \hline
 RT-ER & 77.81 & \textbf{69.09}  & 75.71 & \multicolumn{1}{c|}{72.28}  & \multicolumn{1}{|c}{RT-ER} & 68.51 & 56.79 & \textbf{46.32} & 81.26\\ \midrule
\multicolumn{10}{c}{Dual-Model (Pre-trained)} \\ \midrule
$\alpha$ & SA(\%) & RA(\%) & RA-RMoE(\%) & \multicolumn{1}{c|}{RA-SMoE(\%)}  & \multicolumn{1}{|c}{$\alpha$} & SA(\%) & RA(\%) & RA-RMoE(\%) & RA-SMoE(\%) \\ \hline
0.7 & 89.81& 67.81 & 79.47& \multicolumn{1}{c|}{\textbf{52.93}}  & \multicolumn{1}{|c}{0.7} & 80.74 & 53.11 & 68.92 & \textbf{47.39} \\ \hline

0.8& 87.58 & 68.27& 77.25& \multicolumn{1}{c|}{54.99}  & \multicolumn{1}{|c}{0.8} & 77.89 & 55.27 & 65.94 & 55.16 \\ \hline

0.9 & 83.27 & 70.73 & 75.03 & \multicolumn{1}{c|}{60.87}  & \multicolumn{1}{|c}{0.9} & 74.2 & 56.58 & 61.95 & 62.80  \\ \midrule

\multicolumn{10}{c}{Dual-Model (JTDMoE)} \\ \midrule
$\alpha$ & SA(\%) & RA(\%) & RA-RMoE(\%) & \multicolumn{1}{c|}{RA-SMoE(\%)}  & \multicolumn{1}{|c}{$\alpha$} & SA(\%) & RA(\%) & RA-RMoE(\%) & RA-SMoE(\%) \\ \hline
0.7 & 92.29 & 74.62 & 85.42 & \multicolumn{1}{c|}{\textbf{68.73}}  & \multicolumn{1}{|c}{0.7} & 84.91 & 57.39 & 69.58  & \textbf{53.32} \\ \bottomrule

\end{tabular}
}
\end{table*}

\subsection{Experiment Setup}
\paragraph{Datasets and Model Architectures.}Our experiments use the MoE architecture on CIFAR-10~\cite{krizhevsky2009learning} and TinyImageNet~\cite{deng2009imagenet}, with a fully connected top-1 router and 4 experts ($E = 4$). We use ResNet18~\cite{he2016deep} for CIFAR-10 and pre-trained ViT-small~\cite{liu2021efficient} for TinyImageNet. Instead of training the dual-model from scratch, we apply the JTDMoE algorithm to pre-trained models for efficiency, using ST MoE as the standard and RT-ER MoE as the robust MoE, with $\alpha$ ranging from 0.5 to 1.

\paragraph{Robustness Evaluation.} We use PGD~\cite{mkadry2017towards} and AutoAttack~\cite{croce2020reliable} to assess model performance under adversarial conditions, with $\epsilon = 8/255$ for CIFAR-10 and $\epsilon = 2/255$ for TinyImageNet. We train ResNet18-based MoE for 130 epochs on CIFAR-10 and fine-tune pre-trained ViT-small-based MoE for 10 epochs on TinyImageNet. A Cyclic Learning Rate strategy~\cite{smith2017cyclical}, starting at 0.0001, and data augmentation~\cite{rebuffi2021fixing} are used to enhance performance. Evaluation is done using either a 50-step PGD or AutoAttack with the same step size.

\paragraph{Baseline Methods.} For comparative analysis, we define three approaches for the single MoE:
	(1) ST: Standard training on MoE.
	(2) AT: Adversarial training on MoE~\cite{madry2017towards}.
	(3) RT-ER: Robust training with expters robustification on MoE. In addition we cover (4) TRADES~\cite{zhang2019theoretically} and (5) AdvMoE~\cite{zhang2023robust} (a new router-expert alternating Adversarial training framework for MoE) in the Appendix~\ref{appendix_singleMoE}.

\subsection{Evaluation of RT-ER}\label{sec_experiment}
\begin{figure}[htbp]
\centering
\subfigure[CIFAR-10 SA]{
\begin{minipage}[b]{0.47\linewidth}
\includegraphics[width=1.0\textwidth]{fig/AT_ATN_Resnet18_SA.pdf}
\end{minipage}
}
\subfigure[CIFAR-10 RA]{
\begin{minipage}[b]{0.47\linewidth}
\includegraphics[width=1.0\textwidth]{fig/AT_ATN_Resnet18_RA.pdf}
\end{minipage}
}
\caption{Performance evaluation of AT MoE and RT-ER MoE models with ResNet18 on the CIFAR-10 test dataset. We report standard accuracy (SA) and robust accuracy (RA) under a 50-step PGD attack, using models trained with a 10-step PGD attack. Our results indicate that RT-ER achieves consistently higher RA and demonstrates greater stability than AT MoE. For a comparable analysis using ViT-small, please refer to Appendix~\ref{appendix_singleMoE}.}
\label{fig_at_moe}
\end{figure}
To showcase the improved robustness and training stability of RT-ER, we compare its SA and RA to those of AT during training. The experimental results of MoE-Resnet18 on CIFAR-10 dataset are illustrated in Figure~\ref{fig_at_moe}. RT-ER demonstrates greater stability compared to traditional adversarial training (AT). In the case of AT-trained MoE, both SA and RA drop significantly—by over 20\% and 10\%, respectively—between epochs 80 and 90. Although the ViT-small MoE model shows some fluctuations as well, the variation is less pronounced, due to the robustness of the pre-trained ViT-small experts used. The experimental results of ViT-small are presented in Appendix~\ref{appendix_singleMoE}. In terms of RA, our method consistently outperforms AT across all epochs, achieving over 15.35\% and 5.5\% improvements in final performance on CIFAR-10 and TinyImageNet, respectively. This suggests that RT-ER is a more effective approach for enhancing the robustness of MoE architectures. Overall, our method enables faster, more efficient robustness enhancement for MoE models while reducing SA by $<$ 1.3\%.

In the Single MoE Performance section of Table~\ref{table_experimental_results}, we compare ST, AT, and RT-ER using ResNet18 on CIFAR-10 and ViT-small on TinyImageNet under PGD attack. RT-ER improves RA-E by over 70\% and 17\% on ResNet18 and ViT-small, respectively, compared to ST, and achieves 5.8\% and 4.2\% improvements in RA and RA-E over AT using ViT-small. These results show RT-ER’s effectiveness in robustifying single MoE models. For a single MoE, robustness is measured by the minimum of {RA, RA-E, RA-R}, reflecting the worst-case performance. RT-ER outperforms AT and ST in this regard. We also compare our method with TRADES~\cite{zhang2019theoretically} and AdvMoE~\cite{zhang2023robust}, and examine the effect of expert number on RT-ER. Details are in Appendix~\ref{appendix_singleMoE}.

\subsection{Evaluation of the Dual-Model Based on Pre-Trained MoE}\label{sec:pretrained} 
The pre-trained dual-model combines a standard MoE and a robust MoE with a fixed $\alpha$ to improve clean data performance. On CIFAR-10, the standard MoE achieves 92.14\% SA and 52.54\% RA, while the robust MoE reaches 77.81\% SA and 69.09\% RA. On TinyImageNet, the standard MoE achieves 82.05\% SA and 34.53\% RA, and the robust MoE reaches 68.51\% SA and 56.79\% RA. As $\alpha$ increases, SA decreases but RA improves, as the robust MoE’s contribution grows. When $\alpha$ = 1, the dual-model becomes RT-ER, with only the robust MoE. Results for $\alpha$ = 0.7, 0.8, and 0.9 under PGD attack show that increasing $\alpha$ decreases SA (by 6.54\% and 13.54\% on CIFAR-10 and TinyImageNet, respectively) but improves RA (by 2.92\% and 3.47\%, respectively) and RA-SMoE (by 7.94\% and 15.41\%).

\begin{figure}[h!]
\centering
\subfigure[CIFAR-10]{
\begin{minipage}[b]{0.47\linewidth}
\includegraphics[width=\linewidth]{fig/Pretrained_Resenet18.pdf}
\end{minipage}
}
\subfigure[TinyImageNet]{
\begin{minipage}[b]{0.47\linewidth}
\includegraphics[width=\linewidth]{fig/Pretrained_ViT.pdf}
\end{minipage}
}
\caption{Performance evaluation of the Dual-Model using pre-trained MoE models. We assess the performance of the Dual-Model, which combines a standard MoE (ST) and a robust MoE (RT-ER) from Table~\ref{table_experimental_results}. The weighting parameter $\alpha$ is incremented from 0.5 to 1.0 in steps of 0.1; at $\alpha = 1$, the Dual-Model relies exclusively on the robust MoE. All other configurations are consistent with those detailed in Figure~\ref{fig_at_moe}.}
\label{table_mixed_model}
\end{figure}
Specifically, when adversarial perturbations target the robust MoE, they have minimal effect on the standard MoE, so RA-RMoE decreases as $\alpha$ increases. Conversely, when the standard MoE is attacked, the robust MoE is minimally impacted, leading to an increase in RA-SMoE with $\alpha$. However, when $\alpha$ shifts from 0.5 to 0.7, RA-SMoE shows only slight improvement, suggesting the robust MoE lacks confidence in its predictions and can be influenced by the standard MoE. This motivates our joint training approach to improve dual-model performance. Further analysis of the dual-model’s performance with pre-trained MoE under AutoAttack is in Appendix~\ref{appendix_pretrained}.

\subsection{Evaluation of JTDMoE}\label{sec:experiments_JTDMoE}
To compare with the results in Section~\ref{sec:pretrained}, we use the same standard MoE and robust MoE models for $\alpha = 0.7$. As shown in Table~\ref{table_experimental_results} and Table~\ref{table_dualmodel_aa}, our JTDMoE algorithm significantly improves the performance of the pre-trained dual-model across all evaluation metrics. Specifically, it increases SA by 2.48\% and 4.17\%, and RA by 6.81\% and 4.28\% under PGD attacks for CIFAR-10 and TinyImageNet, respectively. When evaluated with AutoAttack, JTDMoE achieves a 19.91\% improvement in RA for CIFAR-10 and 1.64\% for TinyImageNet. Additionally, JTDMoE outperforms the baseline in both RA-RMoE and RA-SMoE, further validating the effectiveness of aligning the standard and robust MoE models. These improvements are consistent with our theoretical expectations and support Theorem~\ref{theorem_dual_model}. Further analysis of margin improvement and additional experiments with different $\alpha$ values can be found in Appendix~\ref{appendix_dualmodel}.

\begin{table}[htbp]
\centering
\caption{Performance evaluation of JTDMoE versus the baseline (Pre-trained Dual-Model) when attacked by AutoAttack. In the case of $\alpha = 0.7$, we report standard accuracy (SA), robust accuracy (RA), robust accuracy of the robust MoE (RA-RMoE), and robust accuracy of the standard MoE (RA-SMoE) using AutoAttack (AA) \cite{croce2020reliable}. Results demonstrate that JTDMoE consistently outperforms the baseline across all metrics.}
\label{table_dualmodel_aa}
\resizebox{0.45\textwidth}{!}{
\begin{tabular}{ccccc}
    \hline
    \multicolumn{5}{c}{\textbf{CIFAR-10}} \\ \hline
	Method  &  SA(\%)   & RA(\%) & RA-RMoE(\%)   &   RA-SMoE(\%)   \\ \hline
	Pre-trained & 89.81 & 33.64 & 34.20 & 14.34 \\ \hline
    JTDMoE & \textbf{92.29} & \textbf{54.55} & \textbf{51.13} & \textbf{45.55} \\ \hline
    \multicolumn{5}{c}{\textbf{TinyImageNet}} \\ \hline
	Method  &  SA(\%)   & RA(\%) & RA-RMoE(\%)   &   RA-SMoE(\%)   \\ \hline
	Pre-trained & 80.74 & 51.27 & 56.25 & 26.88 \\ \hline
    JTDMoE & \textbf{84.91} & \textbf{52.91} & \textbf{60.98} & \textbf{28.82} \\ \hline

\end{tabular}
}
\end{table}

\section{Conclusion}
Our study presents a framework for enhancing adversarial robustness and accuracy in MoE architectures, focusing on vulnerable expert networks and strategies that balance both, supported by theoretical analysis and empirical validation.

\section{Impact Statement}
This paper presents work aimed at advancing the field of Machine Learning, specifically in improving the adversarial robustness of Mixture of Experts (MoE) models. Our contributions enhance the security and reliability of MoEs, which are widely used in large-scale and specialized AI applications. While this research primarily focuses on technical advancements, its broader implications include improving the deployment of MoE-based models in safety-critical domains. However, we do not identify any specific societal consequences that must be highlighted here.

\bibliography{main}
\bibliographystyle{icml2025}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix
%\onecolumn
\twocolumn
\section{Supplementary Material}

In this supplementary material, we provide the proofs of Theorems~\ref{theorem_rmoe} and~\ref{theorem_dual_model} in Section~\ref{appendix_proof}. Additional experimental results are presented as follows: single MoE experiments in Section~\ref{appendix_singleMoE}, dual-model experiments based on pre-trained MoE in Section~\ref{appendix_pretrained}, and JTDMoE experiments in Section~\ref{appendix_dualmodel}.

\subsection{Proof of Key Theorems}\label{appendix_proof}
\paragraph{Proof of Theorem~\ref{theorem_rmoe}:} When the input is perturbed from $\rvx$ to $\rvx + \rvdelta$, the change in the final output of the MoE can be expressed as:
\begin{align}
    \Delta =& F_R^{(y)}(\rvx + \rvdelta) - F_R^{(y)}(\rvx) \nonumber \\
    =& \sum_i\left[a_{R_i}(\rvx+\rvdelta) f_{R_i}^{(y)}(\rvx + \rvdelta)-a_{R_i}(\rvx) f_{R_i}^{(y)}(\rvx)\right]  \nonumber
\end{align}

We decompose $\Delta$ into two terms:
\begin{align}
    \Delta_1 &=\sum_i  \left(a_{R_i}(\rvx + \rvdelta)-a_{R_i}(\rvx)\right) f_{R_i}^{(y)}(\rvx + \rvdelta) \nonumber\\
    \Delta_2 &=\sum_i  a_{R_i}(\rvx)\left(f_{R_i}^{(y)}(\rvx + \rvdelta)-f_{R_i}^{(y)}(\rvx) \right)\nonumber\\
    \Delta &= \Delta_1 + \Delta_2 \nonumber
\end{align}

By this decomposition, $\Delta_1$ captures the change due to the router’s output, while $\Delta_2$ represents the change due to the experts’ outputs. To derive a certified bound for the overall MoE, we need to bound both $\Delta_1$ and $\Delta_2$.

\textbf{Bounding $\Delta_1$:}
\begin{align}
    \Delta_1 &\leq \sum_i |a_{R_i}(\rvx + \rvdelta) - a_{R_i}(\rvx)|\cdot f_{R_i}^{(y)}(\rvx + \rvdelta) \nonumber \\
    & \leq \sum_i r_{R_i}\| \rvdelta \|  M_{R_i}, \nonumber
\end{align}
where $M_{R_i} \leq 1$ is an upper bound on $f_{R_i}^{(y)}(\rvx + \rvdelta)$ or an upper bound on $f_{R_i}^{(y)}(\rvx)$ for any inputs and $r_{R_i}$ is the Lipschitz constant of the router $a_{R_i}$.

\textbf{Bounding $\Delta_2$:}
\begin{align}
    \Delta_2 &\leq \sum_i a_{R_i}(\rvx)| f_{R_i}^{(y)}(\rvx + \rvdelta)-f_{R_i}^{(y)}(\rvx) |\nonumber \\
    & \leq \sum_i a_{R_i}(\rvx) L_{R_i}\|\rvdelta\| \nonumber
\end{align}
where $L_{R_i}$ is the Lipschitz constant of the expert $f_{R_i}^{(y)}$.

\textbf{Bounding $\Delta$:}
Combining the bounds for $\Delta_1$ and $\Delta_2$, we have:
\begin{align}
    \Delta \leq \sum_i (r_{R_i} M_{R_i}  + a_{R_i}(\rvx) L_{R_i})\| \rvdelta \| \nonumber
\end{align}

By defining the total Lipschitz constant $L_{total}$ as
\begin{align}
    L_{total} = \sum_i (r_{R_i} M_{R_i}  + a_{R_i}(\rvx) L_{R_i}), \nonumber
\end{align}
the upper bound on the change in the final output becomes:
\begin{align}
    \left|F_{R_i}^{(y)}(\rvx + \rvdelta)-F_{R_i}^{(y)}(\rvx)\right| \leq L_{total }\|\rvdelta\|\nonumber
\end{align}

To ensure the prediction remains unchanged under perturbation $\rvdelta$,  the change in output must not exceed the classification margin $m = \min_{k\neq y} F_R^{(y)}(\rvx) - F_R^{(k)}(\rvx) $. Thus:
\begin{align}
    L_{total } \|\rvdelta \| &\leq  m  \nonumber \\
    \|\rvdelta \| & \leq  \frac{m}{L_{total }} \nonumber
\end{align}

The overall robustness bound $\epsilon$ is therefore:
\begin{align}
    \epsilon &= \frac{m}{\sum_i (r_{R_i} M_{R_i}  + a_{R_i}(\rvx) L_{R_i})} \nonumber \\
    &= \min_{k \neq y} \frac{F_R^{(y)}(\rvx) - F_R^{(k)}(\rvx) }{\sum_{i} (r_{R_i}M_{R_i} + a_{R_i}(\rvx)L_{R_i})} \nonumber
\end{align}
This concludes the proof. $\hfill\blacksquare$

\paragraph{Proof of Theorem~\ref{theorem_dual_model}:} To derive the certified bound for the dual-model, we utilize Theorem 3.5 from~\cite{bai2024improving}, which relates the robustness bound of a dual-model to the properties of the robust model. Since $\alpha$ is assumed to be in $[\frac{1}{2},1]$, let $\delta \in \mathbb{R}^{d}$ satisfy $\|\delta\|_p \leq r_{\operatorname{Lip}, p}^\alpha(x)$. Furthermore, for $i \in[c] \backslash\{y\}$, we have
\begin{equation}
\begin{aligned}
\sigma \circ h_y(x+\delta) & -\sigma \circ h_i(x+\delta) \\
& =\sigma \circ h_y(x)-\sigma \circ h_i(x)+\sigma \circ h_y(x+\delta) \\ 
&\quad-\sigma \circ h_y(x)+\sigma \circ h_i(x)-\sigma \circ h_i(x+\delta) \\
& \geq \sigma \circ h_y(x)-\sigma \circ h_i(x)-\operatorname{Lip}_p\left(\sigma \circ h_y\right)\|\delta\|_p\\
&\quad-\operatorname{Lip}_p\left(\sigma \circ h_i\right)\|\delta\|_p \\
& \geq \sigma \circ h_y(x)-\sigma \circ h_i(x)\\
&\quad-\left(\operatorname{Lip}_p\left(\sigma \circ h_y\right)+\operatorname{Lip}_p\left(\sigma \circ h_i\right)\right) r_{\text {Lip }, p}^\alpha(x)\\
& \geq \frac{1-\alpha}{\alpha},
\end{aligned}
\end{equation}

where $\alpha$ is the parameter controlling the contribution of the robust model to the dual-model, $\sigma \circ h_y(x)$ represents the output of the robust model for the true class $y$ and $\operatorname{Lip}_p\left(\sigma \circ h_i\right)$ denotes the Lipschitz constant of the robust model for class $i$.

Then, the robustness bound of the dual-model can be expressed as:
\begin{align}
    \|\delta\|_p \leq \min _{i \neq y} \frac{\alpha\left(\sigma \circ h_y(x)-\sigma \circ h_i(x)\right)+\alpha-1}{\alpha\left(\operatorname{Lip}_p\left(\sigma \circ h_y\right)+\operatorname{Lip}_p\left(\sigma \circ h_i\right)\right)}. \nonumber
\end{align}

From the previous proof, we already derived the Lipschitz constant for the robust MoE. Using this result, we can now represent the robustness bound $\epsilon$ for the dual-model as:
\begin{align}
    \epsilon = \min_{k \neq y} \frac{\alpha  (F_R^{(y)}(\rvx) - F_R^{(k)}(\rvx))+\alpha-1}{\alpha \sum_i\left(2 r_{R_i}+a_{R_i}(\rvx)(L_{R_i}^{(y)}+L_{R_i}^{(k)})\right)} \nonumber
\end{align}
This concludes the proof. $\hfill\blacksquare$

\subsection{Additional Experiments on Robust MoE} \label{appendix_singleMoE}
\paragraph{Performance of RT-ER on TinyImageNet Dataset} For For the TinyImageNet dataset~\cite{deng2009imagenet}, we adversarially trained an MoE model using ViT-small as the experts. The experimental setup follows the same settings outlined in Section~\ref{sec:experiments}. The RA and SA performance curves are shown in Figure~\ref{fig_at_moe_vit}.

\begin{figure}[htbp]
\centering
\subfigure[TinyImageNet SA]{
\begin{minipage}[b]{0.47\linewidth}
\includegraphics[width=1.0\textwidth]{fig/AT_ATN_ViT_SA.pdf}
\end{minipage}
}
\subfigure[TinyImageNet RA]{
\begin{minipage}[b]{0.47\linewidth}
\includegraphics[width=1.0\textwidth]{fig/AT_ATN_ViT_RA.pdf}
\end{minipage}
}
\caption{Performance evaluation of AT MoE and RT-ER MoE models with ViT-small on the TinyImageNet test dataset. We report standard accuracy (SA) and robust accuracy (RA) under a 50-step PGD attack, using models trained with a 10-step PGD attack. Our results indicate that RT-ER achieves higher RA and demonstrates greater stability compared to AT MoE.}
\label{fig_at_moe_vit}
\end{figure}

RT-ER achieves noticeably higher RA and demonstrates more consistent performance compared to the AT MoE model. While the AT model exhibits some fluctuations in performance, these are less pronounced than those observed on the CIFAR-10 dataset. This improved stability can be attributed to the use of a pre-trained ViT-small model, which inherently possesses adversarial robustness due to its training on a large and diverse dataset. In summary, RT-ER improves RA by over 5.8\% while incurring only a modest 2.2\% decrease in SA, highlighting its effectiveness in enhancing the robustness of MoE models.
\begin{figure}[htbp]
\centering
\subfigure[SA]{
\begin{minipage}[b]{0.47\linewidth}
\includegraphics[width=1.0\textwidth]{fig/Trades_AdvMoE_SA.pdf}
\end{minipage}
}
\subfigure[RA]{
\begin{minipage}[b]{0.47\linewidth}
\includegraphics[width=1.0\textwidth]{fig/Trades_AdvMoE_RA.pdf}
\end{minipage}
}
\caption{Performance comparison of TRADES, AdvMoE, and RT-ER with ResNet18 on the CIFAR-10 test dataset. SA and RA are evaluated under a 50-step PGD attack, using models trained with a 10-step PGD attack. RT-ER achieves higher RA and exhibits greater stability compared to TRADES and AdvMoE. Numerical analysis comparisons are presented in Table~\ref{table_trades_advmoe}.}
\label{fig_at_moe_comparison}
\end{figure}

\paragraph{Smooth Attack}Throughout this paper, we adopt the top-1 strategy for expert selection, which is inherently non-differentiable and may cause standard gradient-based attacks to fail. To enable effective robustness evaluation, we employ adaptive attacks by replacing the top-1 selection with a dense smooth approximation. Specifically, we compute a weighted average of expert outputs using the routing weights and generate perturbations $\delta$ based on this smoothed output. This approach ensures that expert selection remains differentiable, allowing gradients to propagate. The results, presented in Table~\ref{table_smooth_attack}, demonstrate that our method, RT-ER, continues to outperform ST and AT in RA.
\begin{table}[htbp]
\centering
\caption{Robustness evaluation of standard training (ST), adversarial training (AT), and our method (RT-ER). We adopt a dense smooth approximation to ensure differentiable expert selection. The experiment is conducted on CIFAR-10 using an MoE model with ResNet18 experts.}
\label{table_smooth_attack}
\resizebox{0.45\textwidth}{!}{
\begin{tabular}{ccccc}
    \hline
    \multicolumn{5}{c}{\textbf{CIFAR-10 (Smooth Attack)}} \\ \hline
	Method  &  SA(\%)   & RA(\%) & RA-E(\%)   &   RA-R(\%)   \\ \hline
	ST & 92.14 & 46.02 & \textbf{3.11} & 54.67 \\ \hline
    AT & 79.08 & \textbf{51.03} & 73.85 & 78.91 \\ \hline
    RT-ER & 77.81 & \textbf{68.96} & 75.71 & 72.28 \\ \hline

\end{tabular}
}
\end{table}

\paragraph{Comparison with Trades and AdvMoE}We compare our method, RT-ER, with TRADES~\cite{zhang2019theoretically} and AdvMoE~\cite{zhang2023robust} using an MoE architecture based on ResNet18 on the CIFAR-10 dataset. All experiments are conducted under the same settings for a fair comparison. The results for standard accuracy (SA) and robust accuracy (RA) are presented in Figure~\ref{fig_at_moe_comparison}.

All methods are trained from scratch to ensure consistency. While TRADES and AdvMoE exhibit performance fluctuations similar to those observed in standard adversarial training, RT-ER demonstrates significantly improved stability. Although RT-ER achieves a marginally higher SA—by less than 1\%—compared to TRADES, it achieves a notable 10.42\% improvement in RA, underscoring its effectiveness in enhancing robustness. In conclusion, RT-ER is the superior choice for robustifying the MoE layer, delivering both improved robustness and more reliable performance.

\begin{table}[h]
\centering
\caption{Performance comparison of TRADES, AdvMoE, and RT-ER with ResNet18 on the CIFAR-10 test dataset under PGD and AutoAttack. As AdvMoE is specifically designed for CNN-based MoE, this experiment is conducted using MoE with ResNet18 experts on the CIFAR-10 dataset.}
\label{table_trades_advmoe}
\resizebox{0.45\textwidth}{!}{
\begin{tabular}{ccccc}
    \hline
    \multicolumn{5}{c}{\textbf{CIFAR-10 (PGD)}} \\ \hline
	Method  &  SA(\%)   & RA(\%) & RA-E(\%)   &   RA-R(\%)   \\ \hline
	Trades & 83.81 & \textbf{52.54} & 72.72 & 76.63 \\ \hline
    AdvMoE & 76.83 & \textbf{58.67} & 73.79 & 74.03 \\ \hline
    RT-ER & 77.81 & \textbf{69.09} & 75.71 & 72.28 \\ \hline
    \multicolumn{5}{c}{\textbf{CIFAR-10 (AA)}} \\ \hline
	Method  &  SA(\%)   & RA(\%) & RA-E(\%)   &   RA-R(\%)   \\ \hline
	Trades & 83.81 & \textbf{38.90} & 54.72 & 56.84 \\ \hline
    AdvMoE & 76.83 & \textbf{44.17} & 54.62 & 55.06 \\ \hline
    RT-ER & 75.92 & \textbf{54.36} & 57.86 & 54.84 \\ \hline

\end{tabular}
}
\end{table}

\paragraph{The Impact of Number of Experts $E$}We investigate the impact of the number of experts on RT-ER in Table~\ref{table_number_experts}. Specifically, we consider three cases: $E \in \{3, 4, 5\}$, using the default CIFAR-10 settings, with the only change being the number of experts. As the number of experts (E) increases, the capacity of the MoE architecture grows. After 130 epochs of training, we observe an approximate 2\% improvement in SA, while RA shows only a slight improvement. This is attributed to the sparse MoE and top-1 routing strategy, where only one expert (ResNet18) is activated for each input image. Since each expert is robustified during training and capable of handling classification tasks independently, the SA improvement is more noticeable. These results also demonstrate that RT-ER is adaptable to various configurations of the MoE architecture.

\begin{table}[h]
\centering
\caption{Robustness evaluation of RT-ER with varying numbers of experts $E$ on the CIFAR-10 dataset. Increasing  E  enhances model capacity, leading to improvements in both standard accuracy (SA) and robust accuracy (RA).}
\label{table_number_experts}
\resizebox{0.38\textwidth}{!}{
\begin{tabular}{ccccc}
    \hline
    \multicolumn{5}{c}{\textbf{CIFAR-10}} \\ \hline
	E  &  SA(\%)   & RA(\%) & RA-E(\%)   &   RA-R(\%)   \\ \hline
	3 & 75.85 & \textbf{69.03} & 74.79 & 72.42 \\ \hline
	4 & 77.81 & \textbf{69.09} & 75.71 & 72.28 \\ \hline
	5 & 79.77 & \textbf{70.00} & 76.51 & 71.86 \\ \hline

\end{tabular}
}
\end{table}

\paragraph{The Impact of Different $\beta$}Recall that the loss function $\gL_{rob}$ used in the RT-ER method is defined as:
\[
\max_{\|\rvdelta\|_p \leq \epsilon} \ell_{CE}(F_R(\rvx + \rvdelta), y) + \beta \cdot \sum_{i=1}^{E} \ell_{KL}(f_{R_i}(\rvx + \rvdelta), f_{R_i}(\rvx)).
\]
We examine the impact of varying $\beta$ on the model’s performance, setting $\beta$ to 1, 3, 6, and 9. The results are summarized in Table~\ref{table_different_beta}.
\begin{table}[htbp]
\centering
\caption{Performance evaluation of RT-ER with different values of $\beta$ in $\gL_{rob}$. Metrics reported are standard accuracy (SA), robust accuracy on the entire model (RA), robust accuracy on experts (RA-E), and robust accuracy on the router (RA-R) under a 50-step PGD attack. Results show the influence of $\beta$ on robustness and standard accuracy.}
\label{table_different_beta}
\resizebox{0.38\textwidth}{!}{
\begin{tabular}{ccccc}
    \hline
    \multicolumn{5}{c}{\textbf{CIFAR-10}} \\ \hline
	$\beta$  &  SA(\%)   & RA(\%) & RA-E(\%)   &   RA-R(\%)   \\ \hline
	1 & 81.68 & 64.13 & 68.67 & 69.64 \\ \hline
    3 & 79.91 & 65.92 & 70.75 & 72.05 \\ \hline
    6 & 77.81 & 69.09 & 75.71 & 72.28 \\ \hline
    9 & 10 & 10 & 10 & 10 \\ \hline
\end{tabular}
}
\end{table}

As shown in the table, increasing $\beta$ leads to a consistent decrease in SA and corresponding increases in RA, RA-E, and RA-R, reflecting improved robustness. However, for $\beta = 9$, all metrics collapse to 10\%, indicating random guessing by the model. This phenomenon arises because the second term in $\gL_{rob}$, \(\sum_{i=1}^{E} \ell_{KL}(f_{R_i}(\rvx + \rvdelta), f_{R_i}(\rvx))\), dominates the loss at this value of $\beta$. This term forces experts to approximate their adversarial outputs \(f_{R_i}(\rvx + \rvdelta)\) to their initial outputs \(f_{R_i}(\rvx)\). Since the MoE is trained from scratch, its initial outputs are meaningless at the beginning of training. Consequently, the model fails to learn effectively, resulting in degenerate performance.

\subsection{Experiments with Pre-trained Dual-Model} \label{appendix_pretrained}
In this section, we evaluate the dual-model’s performance using pre-trained MoE models under AutoAttack. The results are shown in Figure~\ref{fig_appendix_pre-trained_dual-model}. For CIFAR-10, the attack strength is set to $\epsilon = 8/255$, while for TinyImageNet, it is $\epsilon = 2/255$. We use a 50-step AutoAttack with a step size of $\epsilon = 2/255$.

\begin{figure}[htbp]
\centering
\subfigure[CIFAR-10]{
\begin{minipage}[b]{0.47\linewidth}
\includegraphics[width=1.0\textwidth]{fig/Pretrained_Resnet18_AA.pdf}
\end{minipage}
}
\subfigure[TinyImageNet]{
\begin{minipage}[b]{0.47\linewidth}
\includegraphics[width=1.0\textwidth]{fig/Pretrained_ViT_AA.pdf}
\end{minipage}
}
\caption{Performance evaluation of the Dual-Model using pre-trained MoE models. The Dual-Model is evaluated under AutoAttack, combining a standard MoE (ST) and a robust MoE (RT-ER) from Table~\ref{table_experimental_results}. The parameter $\alpha$ is varied from 0.5 to 1.0 in steps of 0.1; at $\alpha = 1$, the Dual-Model relies entirely on the robust MoE.}
\label{fig_appendix_pre-trained_dual-model}
\end{figure}

The results indicate that the dual-model's SA decreases while RA increases as $\alpha$ grows. This trend aligns with the structure of the dual-model: as the robust MoE's contribution increases (i.e., higher $\alpha$), RA improves because the robust MoE dominates the final predictions, mitigating the effect of adversarial perturbations on the standard MoE. These findings are consistent with the model performance under PGD attacks, as shown in Section~\ref{sec:pretrained}.

\subsection{JTDMoE Experimental Results}\label{appendix_dualmodel}
\paragraph{Effectiveness of JTDMoE Under Different $\alpha$}We demonstrated the effectiveness of JTDMoE when $\alpha = 0.7$ in Section~\ref{sec:experiments}. Here, we evaluate the performance of the dual-model for different values of $\alpha = { 0.5, 0.6, 0.7, 0.8}$ to show that JTDMoE remains effective across a range of $\alpha$. The standard MoE and robust MoE utilize ResNet18 as the experts. All other settings remain consistent with those in Appendix~\ref{appendix_singleMoE}. The results are illustrated in Figure~\ref{fig_appendix_dual-model}.

\begin{figure}[htbp]
\centering
\subfigure[SA]{
\begin{minipage}[b]{0.47\linewidth}
\includegraphics[width=1.0\textwidth]{fig/Different_a_SA.pdf}
\end{minipage}
}
\subfigure[RA]{
\begin{minipage}[b]{0.47\linewidth}
\includegraphics[width=1.0\textwidth]{fig/Different_a_RA.pdf}
\end{minipage}
}
\caption{Performance evaluation of JTDMoE under different values of $\alpha$ on the CIFAR-10 test dataset. We use the dual-model performance at $\alpha$ = 0.7 as the baseline, depicted by green squares in this figure. Standard accuracy (SA) and robust accuracy (RA) under a 50-step PGD attack are reported, with models trained using a 10-step PGD attack. The results demonstrate that JTDMoE maintains effectiveness across different $\alpha$ values.}
\label{fig_appendix_dual-model}
\end{figure}

From Figure~\ref{fig_appendix_dual-model}, we observe that SA consistently improves under different $\alpha$ during the training process, while RA remains stable or improves slightly. When $\alpha$ is small—indicating that the robust MoE contributes less to the dual-model—the RA continues to increase, showcasing the model’s potential for robustness. These results highlight JTDMoE’s ability to improve the dual-model’s performance, particularly in terms of SA, while maintaining robust accuracy. This demonstrates the effectiveness and adaptability of JTDMoE across varying values of $\alpha$.

\begin{table}[htbp]
\centering
\caption{Margin comparison of JTDMoE and pre-trained dual-model on the CIFAR-10 test dataset. Using the pre-trained dual-model as the baseline, we report margin improvements for each class. Results show that JTDMoE consistently improves margins across all classes, supporting Theorem~\ref{theorem_dual_model}.}
\label{table_margin_comparison}
\resizebox{0.45\textwidth}{!}{
\begin{tabular}{cccccc}
    \hline
    \multicolumn{6}{c}{\textbf{CIFAR-10}} \\ \hline
    Class  &  Airplane   & Automobile & Bird   &   Cat & Deer  \\ \hline
    Improvement & 5.11\% & 3.49\% & 7.5\% & 5.55\% &  10.27\% \\ \hline
    Class  &  Dog   & Frog & Horse   & Ship & Truck  \\ \hline
    Improvement & 14.42\% & 6.46\% & 4.03\% & 1.25\% & 4.58\% \\ \hline
\end{tabular}
}
\end{table}
\paragraph{Margin Comparison} Based on Theorem~\ref{theorem_dual_model}, increasing the margin \( F_R^{(y)}(\rvx) - F_R^{(k)}(\rvx) \) enhances the robustness of the dual-model. To validate this, we compare the margins between JTDMoE and the pre-trained dual-model under $\alpha$ = 0.7 on the CIFAR-10 dataset. The results are summarized in Table~\ref{table_margin_comparison}.

% \begin{table}[htbp]
% \centering
% \caption{Margin comparison of JTDMoE and pre-trained dual-model on the CIFAR-10 test dataset. Using the pre-trained dual-model as the baseline, we report margin improvements for each class. Results show that JTDMoE consistently improves margins across all classes, supporting Theorem~\ref{theorem_dual_model}.}
% \label{table_margin_comparison}
% \resizebox{0.45\textwidth}{!}{
% \begin{tabular}{cccccc}
%     \hline
%     \multicolumn{6}{c}{\textbf{CIFAR-10}} \\ \hline
%     Class  &  Airplane   & Automobile & Bird   &   Cat & Deer  \\ \hline
%     Improvement & 5.11\% & 3.49\% & 7.5\% & 5.55\% &  10.27\% \\ \hline
%     Class  &  Dog   & Frog & Horse   & Ship & Truck  \\ \hline
%     Improvement & 14.42\% & 6.46\% & 4.03\% & 1.25\% & 4.58\% \\ \hline
% \end{tabular}
% }
% \end{table}

As shown in Table~\ref{table_margin_comparison}, JTDMoE improves the margin for every class, with improvements ranging from 1.25\% to 14.42\%. The class Dog exhibits the most significant margin improvement of 14.42\%, followed by Deer with a 10.27\% improvement. These results empirically verify Theorem~\ref{theorem_dual_model}, demonstrating that margin enhancement contributes to JTDMoE’s superior robust accuracy (RA).

\end{document}


% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was created
% by Iain Murray in 2018, and modified by Alexandre Bouchard in
% 2019 and 2021 and by Csaba Szepesvari, Gang Niu and Sivan Sabato in 2022.
% Modified again in 2023 and 2024 by Sivan Sabato and Jonathan Scarlett.
% Previous contributors include Dan Roy, Lise Getoor and Tobias
% Scheffer, which was slightly modified from the 2010 version by
% Thorsten Joachims & Johannes Fuernkranz, slightly modified from the
% 2009 version by Kiri Wagstaff and Sam Roweis's 2008 version, which is
% slightly modified from Prasad Tadepalli's 2007 version which is a
% lightly changed version of the previous year's version by Andrew
% Moore, which was in turn edited from those of Kristian Kersting and
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.
