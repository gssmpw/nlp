[
  {
    "index": 0,
    "papers": [
      {
        "key": "brown2020language",
        "author": "Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others",
        "title": "Language models are few-shot learners"
      },
      {
        "key": "chen2021evaluating",
        "author": "Chen, Mark and Tworek, Jerry and Jun, Heewoo and Yuan, Qiming and Pinto, Henrique Ponde De Oliveira and Kaplan, Jared and Edwards, Harri and Burda, Yuri and Joseph, Nicholas and Brockman, Greg and others",
        "title": "Evaluating large language models trained on code"
      },
      {
        "key": "nakano2021webgpt",
        "author": "Nakano, Reiichiro and Hilton, Jacob and Balaji, Suchir and Wu, Jeff and Ouyang, Long and Kim, Christina and Hesse, Christopher and Jain, Shantanu and Kosaraju, Vineet and Saunders, William and others",
        "title": "Webgpt: Browser-assisted question-answering with human feedback"
      },
      {
        "key": "achiam2023gpt",
        "author": "Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others",
        "title": "Gpt-4 technical report"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "touvron2023llama",
        "author": "Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\\'e}e and Rozi{\\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others",
        "title": "Llama: Open and efficient foundation language models"
      },
      {
        "key": "taori2023alpaca",
        "author": "Taori, Rohan and Gulrajani, Ishaan and Zhang, Tianyi and Dubois, Yann and Li, Xuechen and Guestrin, Carlos and Liang, Percy and Hashimoto, Tatsunori B",
        "title": "Alpaca: A strong, replicable instruction-following model"
      },
      {
        "key": "young2024yi",
        "author": "Young, Alex and Chen, Bei and Li, Chao and Huang, Chengen and Zhang, Ge and Zhang, Guanwei and Wang, Guoyin and Li, Heng and Zhu, Jiangcheng and Chen, Jianqun and others",
        "title": "Yi: Open foundation models by 01. ai"
      },
      {
        "key": "dubey2024llama",
        "author": "Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and others",
        "title": "The llama 3 herd of models"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "team2024gemma_a",
        "author": "Team, Gemma and Mesnard, Thomas and Hardin, Cassidy and Dadashi, Robert and Bhupatiraju, Surya and Pathak, Shreya and Sifre, Laurent and Rivi{\\`e}re, Morgane and Kale, Mihir Sanjay and Love, Juliette and others",
        "title": "Gemma: Open models based on gemini research and technology"
      },
      {
        "key": "team2024gemma_b",
        "author": "Team, Gemma and Riviere, Morgane and Pathak, Shreya and Sessa, Pier Giuseppe and Hardin, Cassidy and Bhupatiraju, Surya and Hussenot, L{\\'e}onard and Mesnard, Thomas and Shahriari, Bobak and Ram{\\'e}, Alexandre and others",
        "title": "Gemma 2: Improving open language models at a practical size"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "peng2024eagle",
        "author": "Peng, Bo and Goldstein, Daniel and Anthony, Quentin and Albalak, Alon and Alcaide, Eric and Biderman, Stella and Cheah, Eugene and Du, Xingjian and Ferdinan, Teddy and Hou, Haowen and others",
        "title": "Eagle and finch: Rwkv with matrix-valued states and dynamic recurrence"
      },
      {
        "key": "peng2023rwkv",
        "author": "Peng, Bo and Alcaide, Eric and Anthony, Quentin and Albalak, Alon and Arcadinho, Samuel and Biderman, Stella and Cao, Huanqi and Cheng, Xin and Chung, Michael and Grella, Matteo and others",
        "title": "Rwkv: Reinventing rnns for the transformer era"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "bi2024deepseek",
        "author": "Bi, Xiao and Chen, Deli and Chen, Guanting and Chen, Shanhuang and Dai, Damai and Deng, Chengqi and Ding, Honghui and Dong, Kai and Du, Qiushi and Fu, Zhe and others",
        "title": "Deepseek llm: Scaling open-source language models with longtermism"
      },
      {
        "key": "liu2024deepseek",
        "author": "Liu, Aixin and Feng, Bei and Wang, Bin and Wang, Bingxuan and Liu, Bo and Zhao, Chenggang and Dengr, Chengqi and Ruan, Chong and Dai, Damai and Guo, Daya and others",
        "title": "Deepseek-v2: A strong, economical, and efficient mixture-of-experts language model"
      },
      {
        "key": "guo2025deepseek",
        "author": "Guo, Daya and Yang, Dejian and Zhang, Haowei and Song, Junxiao and Zhang, Ruoyu and Xu, Runxin and Zhu, Qihao and Ma, Shirong and Wang, Peiyi and Bi, Xiao and others",
        "title": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "hao2023reasoning",
        "author": "Hao, Shibo and Gu, Yi and Ma, Haodi and Hong, Joshua Jiahua and Wang, Zhen and Wang, Daisy Zhe and Hu, Zhiting",
        "title": "Reasoning with language model is planning with world model"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "yao2023tree",
        "author": "Yao, Shunyu and Yu, Dian and Zhao, Jeffrey and Shafran, Izhak and Griffiths, Tom and Cao, Yuan and Narasimhan, Karthik",
        "title": "Tree of thoughts: Deliberate problem solving with large language models"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "feng2023alphazero",
        "author": "Feng, Xidong and Wan, Ziyu and Wen, Muning and McAleer, Stephen Marcus and Wen, Ying and Zhang, Weinan and Wang, Jun",
        "title": "Alphazero-like tree-search can guide large language model decoding and training"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "wu2024beyond",
        "author": "Wu, Jinyang and Feng, Mingkuan and Zhang, Shuai and Che, Feihu and Wen, Zengqi and Tao, Jianhua",
        "title": "Beyond examples: High-level automated reasoning paradigm in in-context learning via mcts"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "qi2024mutual",
        "author": "Qi, Zhenting and Ma, Mingyuan and Xu, Jiahang and Zhang, Li Lyna and Yang, Fan and Yang, Mao",
        "title": "Mutual reasoning makes smaller llms stronger problem-solvers"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "chen2024alphamath",
        "author": "Chen, Guoxin and Liao, Minpeng and Li, Chengxi and Fan, Kai",
        "title": "AlphaMath Almost Zero: process Supervision without process"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "li2023reinforcement",
        "author": "Li, Zihao and Yang, Zhuoran and Wang, Mengdi",
        "title": "Reinforcement learning with human feedback: Learning dynamic choices via pessimism"
      },
      {
        "key": "ouyang2022training",
        "author": "Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others",
        "title": "Training language models to follow instructions with human feedback"
      },
      {
        "key": "rafailov2024direct",
        "author": "Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Manning, Christopher D and Ermon, Stefano and Finn, Chelsea",
        "title": "Direct preference optimization: Your language model is secretly a reward model"
      },
      {
        "key": "ethayarajh2024kto",
        "author": "Ethayarajh, Kawin and Xu, Winnie and Muennighoff, Niklas and Jurafsky, Dan and Kiela, Douwe",
        "title": "Kto: Model alignment as prospect theoretic optimization"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "shao2024deepseekmath",
        "author": "Shao, Zhihong and Wang, Peiyi and Zhu, Qihao and Xu, Runxin and Song, Junxiao and Bi, Xiao and Zhang, Haowei and Zhang, Mingchuan and Li, YK and Wu, Y and others",
        "title": "Deepseekmath: Pushing the limits of mathematical reasoning in open language models"
      },
      {
        "key": "yang2024qwen2b",
        "author": "Yang, An and Zhang, Beichen and Hui, Binyuan and Gao, Bofei and Yu, Bowen and Li, Chengpeng and Liu, Dayiheng and Tu, Jianhong and Zhou, Jingren and Lin, Junyang and others",
        "title": "Qwen2. 5-math technical report: Toward mathematical expert model via self-improvement"
      },
      {
        "key": "ying2024internlm",
        "author": "Ying, Huaiyuan and Zhang, Shuo and Li, Linyang and Zhou, Zhejian and Shao, Yunfan and Fei, Zhaoye and Ma, Yichuan and Hong, Jiawei and Liu, Kuikun and Wang, Ziyi and others",
        "title": "Internlm-math: Open math large language models toward verifiable reasoning"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "guo2025deepseek",
        "author": "Guo, Daya and Yang, Dejian and Zhang, Haowei and Song, Junxiao and Zhang, Ruoyu and Xu, Runxin and Zhu, Qihao and Ma, Shirong and Wang, Peiyi and Bi, Xiao and others",
        "title": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning"
      },
      {
        "key": "zhong2024evaluation",
        "author": "Zhong, Tianyang and Liu, Zhengliang and Pan, Yi and Zhang, Yutong and Zhou, Yifan and Liang, Shizhe and Wu, Zihao and Lyu, Yanjun and Shu, Peng and Yu, Xiaowei and others",
        "title": "Evaluation of openai o1: Opportunities and challenges of agi"
      },
      {
        "key": "team2024qwq",
        "author": "Team, Qwen",
        "title": "Qwq: Reflect deeply on the boundaries of the unknown"
      },
      {
        "key": "team2025kimi",
        "author": "Team, Kimi and Du, Angang and Gao, Bofei and Xing, Bowei and Jiang, Changjiu and Chen, Cheng and Li, Cheng and Xiao, Chenjun and Du, Chenzhuang and Liao, Chonghua and others",
        "title": "Kimi k1. 5: Scaling Reinforcement Learning with LLMs"
      }
    ]
  }
]