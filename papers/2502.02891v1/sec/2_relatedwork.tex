\section{Related Work}

\subsection{Implicit Neural Representations}
Also known as neural fields, INRs have recently emerged as a powerful approach for representing continuous signals at infinite resolution \cite{Xie2021NeuralFields}. Parameterized by MLPs, INRs map input coordinates directly to field values, making them resolution-independent and providing an alternative to traditional grid-based representations that rely on discrete sampling. Before neural networks, implicit functions were widely used in graphics and vision, such as CSG with analytic SDFs \cite{iquilezles} or fractal generation using complex equations \cite{mandelbrot1983fractal}. Neural networks expanded their applicability, as demonstrated in Neural Radiance Fields (NeRF) \cite{mildenhall2021nerf}, which model radiance and density fields to synthesize realistic views, and DeepSDF \cite{park2019deepsdf}, which represents 3D geometry via continuous SDFs parameterized by MLPs.

Despite their effectiveness, INRs struggle with high-frequency details due to the low-frequency bias of MLPs, leading to oversmoothing in complex textures and fine-grained geometry. Several methods address this limitation. Positional encoding, originally from transformers \cite{vaswani2017attention}, and Fourier features \cite{tancik2020fourier} lift input coordinates into a higher-dimensional space to improve high-frequency representation. SIREN instead employs sinusoidal activation functions to encode high-frequency information without requiring input transformation \cite{sitzmann2020implicit}.

INRs are also computationally intensive, particularly in real-time applications. Research has explored techniques such as neural hash maps and adaptive sampling to optimize efficiency while preserving fidelity \cite{muller2022instant}. KiloNeRF \cite{reiser2021kilonerf} speeds up NeRF \cite{mildenhall2021nerf} by partitioning the scene into a grid of small MLPs, each responsible for a localized region, significantly reducing training and inference time.

Neural fields that parameterize geometry are central to our work. DeepSDF \cite{park2019deepsdf} represents a shape’s SDF with an MLP and generalizes to shape classes using latent codes. Occupancy Networks follow a similar approach but learn a continuous occupancy probability field \cite{mescheder2019occupancy}. SAL \cite{atzmon2020sal} discards the sign and instead learns an unsigned distance function, while SALD \cite{atzmon2020sald} refines this by incorporating derivative information in the loss. Other methods integrate the eikonal property of SDFs as a loss term \cite{yang2024stabilizing}. Beyond loss-based improvements, some works introduce alternative supervision strategies, such as using 2D images instead of 3D point clouds. For instance, \cite{bangaru2022differentiable} employs reparameterization techniques for differentiable end-to-end optimization from image supervision, achieving high-quality geometry reconstruction.

\subsection{Shape Editing Techniques}
Shape editing has been a key area in geometric modeling, evolving from explicit surface-based methods to deep-learning approaches. Traditional techniques relied on explicit geometry representations like meshes and NURBS (Non-Uniform Rational B-Splines) \cite{versprille1975computer}, allowing precise vertex and control point manipulation. Methods such as Free-Form Deformation \cite{sederberg1986free} and Skeletal Animation/rigging enabled localized transformations without manual vertex adjustments. More advanced techniques, like vector field-guided deformations \cite{von2006vector}, leverage vector fields to control shape transformations, while multi-resolution editing \cite{zorin1997interactive} allows modifications at different levels of detail.

In implicit modeling, shape editing is less intuitive than in explicit representations. For analytic implicit functions, CSG offers a structured approach for complex shape creation via boolean operations \cite{requicha1985boolean}. Editing in CSG is often achieved by tuning shape parameters through slider-based interfaces for real-time control. Recently, Riso \etal \cite{riso24direct} introduced a viewport-based editing method that enables real-time parameter adjustments via a co-parameterization scheme, leveraging gradients for direct manipulation.

In the domain of neural SDFs, numerous advancements have improved editability. Mehta \etal \cite{mehta2022level} extend level-set theory to neural SDFs by introducing flow fields over triangle meshes, enabling smooth deformations of parametric implicit surfaces. Similarly, Yang \etal \cite{yang2021geometry} achieve topology-preserving deformations by accessing network derivatives and modeling invertible fields with residual networks. INSP \cite{xu2022signal} provides a framework for signal processing within INRs, using a CNN-based operator on higher-order derivatives, similar to a Taylor expansion, to filter and manipulate features in the latent space. Additionally, NGC \cite{zhu2024controllable} introduces a generalized cylinder representation, parameterizing neural SDFs in a relative coordinate system, where individual cylinders can be modified independently for blending, twisting, and other complex deformations.

\subsection{Interactive Sculpting}
Our work addresses a specialized form of editing in the modeling community: digital sculpting, which enables artists to shape, carve, push, and pull a 3D model to create intricate forms. Typically, sculpting is achieved through user-defined strokes using virtual brushes that vary in intensity, size, and shape, allowing for highly detailed and expressive edits. For explicit representations, there are numerous tools, the most notable of which include Blender \cite{blender} and ZBrush \cite{zbrush}, offering intuitive and highly interactive sculpting experience.

For implicit representations, however, interactive sculpting options are more limited. Some CSG-based applications, such as the open-source tool MagicaCSG \cite{magicacsg} and the web-based platform Womp \cite{womp}, provide basic shape editing through Boolean operations. 

For neural implicit representations, the only relevant work we found for sculpting on a surface represented as a zero level-set is 3D Neural Sculpting (3DNS) \cite{tzathas20233d}, which serves as our baseline by enabling interactive editing of neural SDF. 3DNS provides a framework for interactively editing neural SDFs via point-based modifications on a surface’s zero-level isoset. Users sculpt the surface using analytic polynomial radial brushes, each defined by radius and intensity. These brushes are smooth, positive 2D functions defined over a unit disk, reaching a maximum at the origin and tapering to zero at the unit circle. To apply an edit, 3DNS selects sample points on a disk tangent to the interaction point,  then projects them onto the unaltered surface, and finally shifts them perpendicularly by a distance defined by the brush function. The system modifies the surface only within the disk area, creating localized edits based on the brush template and radial distance from the interaction point. For surface sampling, 3DNS balances model-preserving samples outside the disk and interaction samples within the disk using a weighting scheme. For model-preserving samples, a Markov chain process is used to ensure more uniform sample distribution on the surface. 

While 3DNS achieves point-based edits, it lacks flexibility in brush profiles and the more typical stroke-based deformations in sculpting. Its operations approximate heat kernel deformations and are confined to additive unions of point edits, making continuous, modulated strokes impractical. Attempting to replicate a stroke by sequential point edits is not only computationally expensive but can also fail to achieve the intended result due to overlapping influences that limit precise control over the edit shape.






% \begin{enumerate}
%     \item Mesh based frameworks: ZBrush, Blender
%     \item SDF based frameworks: CSG Toolkit, Magica, Womp
%     \item NN based frameworks: 3D Neural Sculpting (3DNS): Editing Neural Signed Distance Functions
% \end{enumerate}