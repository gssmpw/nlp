\begin{table}[htbp]
\centering
\small
\begin{tabular}{|p{0.3\linewidth}|p{0.3\linewidth}|p{0.3\linewidth}|}
\hline
\textbf{LLM/AI for Planning} & \textbf{LLM/AI for Reasoning} & \textbf{Benchmark Efforts} \\
\hline
\begin{itemize}[leftmargin=*]
    \item \textbf{zhou2023isrllm}: ISR-LLM: Iterative Self-Refined LLM for Long-Horizon Sequential Task Planning
    \item \textbf{zhuang2024toolchain}: ToolChain*: Efficient Action Space Navigation in LLMs with A* Search
    \item \textbf{dagan2023dynamic}: Dynamic Planning with a LLM
    \item \textbf{ruan2023tptu}: TPTU: Task Planning and Tool Usage of LLM-based AI Agents
    \item \textbf{liu2023llm}: LLM+P: Empowering LLMs with Optimal Planning Proficiency
    \item \textbf{hu2023chainofsymbol}: Chain-of-Symbol Prompting Elicits Planning in LLMs
    \item \textbf{huang2024qdmrplanning}: QDMR-Based Planning-and-Solving Prompting for Complex Reasoning Tasks
    \item \textbf{wang2023iplanandsolve}: Plan-and-Solve Prompting: Improving Zero-Shot CoT Reasoning
    \item \textbf{wang2023lplanningtokens}: Guiding LLM Reasoning with Planning Tokens
\end{itemize} 
&
\begin{itemize}[leftmargin=*]
    \item \textbf{zhu2024deductive}: Deductive Beam Search: Decoding Deducible Rationale for CoT Reasoning
    \item \textbf{zhu2023pad}: PAD: Program-Aided Distillation Specializes LLMs in Reasoning
    \item \textbf{zhu2024eqot}: Improving Small LLMs' Mathematical Reasoning via Equation-of-Thought Distillation
    \item \textbf{jin2023tabcot}: Tab-CoT: Zero-Shot Tabular Chain of Thought
    \item \textbf{zou2024aurora}: Aurora: A One-for-All Platform for Augmented Reasoning with Task-Adaptive CoT Prompting
    \item \textbf{zou2023metacot}: Meta-CoT: Generalizable CoT Prompting in Mixed-Task Scenarios
    \item \textbf{zhang2023autocot}: Automatic Chain-of-Thought Prompting in LLMs
    \item \textbf{zhang2023multimodalcot}: Multimodal Chain-of-Thought Reasoning in LLMs
    \item \textbf{zhao2023verifyedit}: Verify-and-Edit: A Knowledge-Enhanced CoT Framework
    \item \textbf{zheng2023progressivehint}: Progressive-Hint Prompting Improves Reasoning in LLMs
    \item \textbf{zheng2024abstractioncot}: Evoking Reasoning via Abstraction in LLMs
    \item \textbf{zhou2023latreesearch}: Language Agent Tree Search Unifies Reasoning, Acting, and Planning
\end{itemize} 
&
\begin{itemize}[leftmargin=*]
    \item \textbf{zhu2021tatqa}: TAT-QA: A QA Benchmark on Tabular and Textual Content in Finance
    \item \textbf{chu2023timebench}: Timebench: A Comprehensive Evaluation of Temporal Reasoning in LLMs
    \item \textbf{chen2021finqa}: FinQA: A Dataset of Numerical Reasoning over Financial Data
    \item \textbf{chen2022convfinqa}: ConvFinQA: Conversational Numerical Reasoning Benchmark
    \item \textbf{hendrycks2021math}: MATH: A Benchmark for Mathematical Problem Solving
    \item \textbf{huang2023ceval}: CEVAL: A Multi-Level Chinese Evaluation Suite for Foundation Models
    \item \textbf{huang2023metatool}: MetaTool Benchmark: Deciding Whether to Use Tools and Which to Use
    \item \textbf{shen2023taskbench}: Taskbench: Benchmarking LLMs for Task Automation
    \item \textbf{yu2020reclor}: ReClor: A Reading Comprehension Dataset Requiring Logical Reasoning
\end{itemize} \\
\hline
\end{tabular}
\caption{Selected References Grouped by (1) LLM/AI for Planning, (2) LLM/AI for Reasoning, and (3) Benchmark Efforts for Evaluating LLM Performance in Reasoning and Planning.}
\label{tab:categories}
\end{table}
