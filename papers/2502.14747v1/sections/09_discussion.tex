\section{DISCUSSION, LIMITATIONS, AND FUTURE WORK}

% 2. AI expose Stucture，透明度，很容易讀（可以generalize），不知道背後在幹嘛，很難control，我們organize讓user能夠立刻了解這些key attributes。其他AI工具也可以參考這樣的做法。（expose這些attribute，讓使用者可以更精准控制） 1. 提供系統化資訊很快了解2 提供界面很快修改

\subsection{Addressing Barriers to Adoption: Transparency, Accuracy, and User Perceptions in AI Design Tools}
A significant proportion of designers and artists exhibit resistance to the adoption of GenAI tools ~\cite{kawakami2024impact, jiang2023ai}. Although concerns such as copyright and other factors discussed previously play a role, another critical reason for this reluctance is the lack of transparency in these systems ~\cite{zhang2024confrontation, shi2023understanding}. Without a clear understanding of the underlying actions of the system, users struggle to control and communicate with it effectively, ultimately reducing acceptance and adoption~\cite{auernhammer2020human, Usmani2023Human-Centered}. 
% 2nd review
To address this, prior work has explored enhancing interpretability and user control through multi-modal feedback and visualization. XCreation ~\cite{yan2023xcreation} integrates an entity-relation graph to visually map picture elements and their relationships, making generative structures more transparent. In product design, PhotoDreamer ~\cite{zhang2024protodreamer} allows designers to prototype with physical materials while AI interprets their inputs, providing clear feedback on how designs evolve. And AutoSpark~\cite{chen2024autospark} enables fine-grained comparisons to improve text-image relevance. 

On the other hand, AIdeation is specifically designed to meet the needs of concept designers by breaking down brainstorming results into visuals and categorized keywords, helping designers quickly grasp key attributes. Building on this understanding, AIdeation enables designers to fine-tune elements precisely. At each step, it eliminates the traditional need for designers to spend excessive time interpreting generated images or manually crafting and modifying complex prompts, while still preserving high-level control over design directions. As one participant noted: “\textit{Compared to other image-generation tools I've used before, I can clearly see what to do next, making it much more efficient to achieve the desired outcome}” (P14). By enhancing AI transparency and control of creative directions, AI design tools would improve engagement, foster human-AI collaboration, and improve user satisfaction, as proposed by human-centered AI design principles~\cite{shneiderman2022human}.

Hallucination is another critical concern in GenAI, 
Hegazy et al.\cite{hegazy2023evolution} identified potential issues with using GenAI in architectural design, such as a lack of consideration for structural feasibility and inconsistencies in generated outcomes. Similarly, concept designers rely heavily on factual, real-world information\cite{maleki2024ai, monteith2024artificial}, distinguishing them from other design disciplines. Both formative and summative studies revealed that designers hesitate to adopt AI tools due to fears of receiving inaccurate output, compounded by a general preference to avoid over-reliance on others' designs. As one participant (P2) explained: “\textit{I mainly use photos as references and avoid concept art since, despite looking good, it may lack thorough, factual research. AI-generated images have the same problem}.” 
While prior work in architectural design explores pre-trained models and ControlNet~\cite{zhang2023adding} to improve accuracy~\cite{chen2024enhancing}, these methods are unsuitable for concept design due to its broader scope.
To mitigate this problem, AIdeation integrates non-AI image search to provide real-world reference images, supporting the design elements of its generated ideas and aligning with designers' existing workflow for reference gathering. This approach significantly increased designers' willingness to engage with the tool. As another participant (P15) noted, “\textit{Although I still don't like AI-generated images, the keywords and references are very useful}.” These findings, coupled with our observations in Section 7.4.3, highlight the substantial impact of user attitudes and expectations on their experience with AI systems, a conclusion supported by recent research~\cite{kang2024impact}.

% Hegazy et al ~\cite{hegazy2023evolution} stated the possible problems using GenAI in architectural design, such as Lack of consideration for structural design feasibility and Inconsistency of outcomes.

These issues also extend to other domains. While GenAI is powerful, designers need to identify and address the root causes of possible negative attitudes toward it. A user-centered approach is helpful in identifying the root causes, making it possible to design strategies to specifically address each of users' concerns, incorporating both GenAI and traditional approaches as needed. 
%Ensuring systems are trustworthy, transparent, and aligned with workflows is critical. Addressing these challenges can lead to greater adoption and improved user satisfaction in future systems.

% 3. 這個領域有高比例反AI，1. 覺得資訊是錯誤的 （我們的設計就是用真實世界的search reference來support）User 對 AI 的態度差異。要注意User的negative thought。工具好用但不是每個user都這樣。要給什麼建議，針對對AI負面的user (資訊是不正確的) 用真實的東西去Back AI產出的Idea
% \textbf{對ai負面態度的原因很多類型，針對不同原因去設計}

\subsection{Implication for GenAI in Iterative Ideation}
% 4. 不同階段user會要不同的control。拆成不同Phase，creative process convergence divergence。過去的做法是會用slider。我們是拆成brainstorming和refinement (concept designer workflow)。不同creative process，背後概念都是這樣。怎麼去support 這個progression
Unlike existing AI tools commonly used by concept designers, which typically follow a linear, one-step solution, AIdeation adopts a nonlinear and iterative approach that aligns more closely with designers' ideation processes. This design philosophy is similar to frameworks such as OptiMuse ~\cite{OptiMuse} and DesignGPT ~\cite{ding2023designgpt}, recognizing iteration as a fundamental aspect of the design process ~\cite{adams1999cognitive}, and many prior work has incorporated this principles ~\cite{hou2024c2ideas, han2024teams}.
At different stages of the design process, designers may require varying levels of divergent and convergent thinking, along with cognitive processes that balance exploring both breadth and depth. ~\cite{tversky2011creativity, goldschmidt2016linkographic}. Tools such as RoomDreaming used sliders to control the diversity of visual outputs ~\cite{wang2024roomdreaming}, while GenQuery employs visual search and image combination techniques to dynamically shift focus ~\cite{son2024genquery}. In contrast, AIdeation organizes the functionality into modular components, where designers can switch between based on their current needs, providing the flexibility to adapt to different phases of the creative process. 
These concepts apply to most creative processes. Future work could explore how GenAI can support different stages of ideation across various creative domains while allowing users to seamlessly switch between them.

During interviews, many designers highlighted that AIdeation was significantly easier to control and communicate with compared to other AI tools they had used. One participant noted, “\textit{I feel that AIdeation can effectively understand how I wish to modify the current idea}” (P6). This observation highlights the importance of systems that understand user intentions and support clear and effective communication. ~\cite{verganti2020innovation, shneiderman2022human}. Previous work, such as IntentTuner, has proposed frameworks to integrate human intentions into fine-tuning general image generation systems ~\cite{zeng2024intenttuner}. In contrast, AIdeation uses domain-specific knowledge to guide each AI module, ensuring that it aligns with the different phases of concept design. This approach improves communication between the tool and designers.

The principles behind AIdeation can guide the future development of AI-assisted design tools. One promising direction is exploring how GenAI can better support collaboration, enabling directors and designers to co-create in shared workflows. Such systems could act as a communication bridge,  integrating team inputs and supporting both broad exploration and focused refinement. This aligns with the frameworks of Han et al., which highlights AI’s role in enhancing team creativity ~\cite{han2024teams}.

\subsection{Integrating GenAI into the Design Workflow with a Human-Centered AI Approach}
% 1. Revisit Contribution and Research Goal
% We are integrating AI into a group that already using GenAI
% Objective: Restate the research goals and contributions of AIdeation.
% Highlight how AIdeation fills gaps in existing tools by combining breadth and depth in idea exploration. ()
% Note its role in advancing HCI knowledge by supporting divergent and convergent thinking in iterative workflows.
% Notice: Emphasize novelty and address specific challenges (e.g., inefficiency in traditional workflows, limited control in current AI tools).

% 1. 從最broad開始講，大家都用AI tool， 但沒效率。各個domain都有這樣的work。
% Highlight human centered approach, 可以更符合使用者需求, 有兩間還在用
%The findings from both studies indicate that AIdeation effectively integrates multiple GenAI models to support the ideation process and address the complex workflows of concept designers. 

While GenAI tools are increasingly used by designers across various domains, research shows they often fail to align with user-centered design principles. These shortcomings often result in user reluctance and inefficiencies~\cite{vimpari2023adapt, zhang2024confrontation, mahdavi2024ai}. Aligned with established principles of human-centered AI design ~\cite{shneiderman2022human, xu2023transitioning, auernhammer2020human}, AIdeation provides a solution that prioritizes the needs and workflows of concept designers.

Previous research in various design domains has demonstrated the use of GenAI to simplify nuanced tasks, enabling designers to rapidly explore various visual concepts~\cite{wang2024roomdreaming, davis2024fashioning, oh2024lumimood}. Furthermore, studies have demonstrated the effectiveness of AI multi-agent collaboration in managing complex tasks~\cite{talebirad2023multi, de2024llmr}. 
AIdeation, on the other hand, deconstructs complex workflows into modular tasks, combining both suitable AI modules and non-AI tools for each phase and integrating them into a cohesive workflow for concept designers. This approach eliminates labor-intensive steps while retaining essential creative decisions, allowing users to focus on the core creative aspects of their work. In this context, GenAI functions as a tool to augment human capabilities ~\cite{chen2023next}. As one participant remarked, “\textit{Using AIdeation felt like being an art director, with multiple design assistants gathering information and proposing ideas}” (P13).

A similar approach can be generalized to other design domains that involve multiple phases of ideation, prototyping, and refinement, such as fashion, graphic, architectural, and industrial design~\cite{camburn2017design, carlgren2016framing}. Although many design fields have already integrated AI tools into their workflows~\cite{anantrasirichai2022artificial}, these tools often do not align with domain-specific needs, which presents a significant opportunity for HCI researchers to bridge this gap.
Instead of relying on one-size-fits-all AI solutions, researchers should use domain expertise to integrate the right tools, AI or otherwise, into workflows and ensure designers retain control over core creative decisions. This approach results in systems that better meet user needs and outperform traditional or purely AI-driven solutions.


\subsection{Limitations and Future Work}
\subsubsection{Limitations of the study}
% Discuss study duration, self report method
% Reflect on generalizability to other contexts or domains.
% Notice: Frame limitations constructively, linking them to potential future studies.
Due to the difficulty of including the entire ideation process in our summative study and the challenge of directly comparing the results of the ideation between conditions, we relied mainly on self-reported data, which is a limitation of this work. While a follow-up field study evaluated real-world design outputs with input from designers, directors, and clients, it lacked quantitative measures and had less control compared to lab studies. Future research could explore longer summative sessions focused on narrower tasks, like designing a single prop, which is simpler than broader tasks like environment design.

\subsubsection{Controllability}
% Objective: Discuss the trade-offs between user control and automation in AIdeation.
% Address how increased control could either support or hinder creative exploration.
% Notice: Use participant feedback to support arguments about user needs for control.
Although AIdeation emphasizes idea exploration, participants noted its limitations in controlling specific details of generated results. Features like "combine with the reference" and "refine by instruction" provide high-level control but lack the ability to adjust elements such as lighting, atmosphere, camera angles, and composition while preserving other elements. These aspects remain challenging and are active areas of AI research. As one participant (P4) remarked, “\textit{The system covers 70-80\% for client communication, but control over lighting, atmosphere, and camera angles is needed for the final 20\%}.” As AI technology continues to advance, such controllability features could be integrated into AIdeation. Future iterations of AIdeation could integrate such detailed controls to better support designers' focus and refinement during the convergence phase of their work.

\subsubsection{Customization and personalization}
% Customization and Personalization
% Objective: Reflect on how AIdeation can be personalized to suit diverse workflows.
% Explore adaptive AI features, such as tailoring outputs to user preferences or expertise levels.
% Notice: Highlight ethical implications, like avoiding bias and ensuring inclusivity.
Many users noted the limited diversity in art styles, atmosphere, and camera angles, largely due to the constraints of the image generation model used in AIdeation. Different models have distinct strengths; for instance, users appreciated MidJourney for its aesthetic quality, while Stable Diffusion, fine-tuned with LoRA ~\cite{hu2021lora}, offers more style variety and specialized designs. Future updates could let users select specific styles or atmospheres, choose fine-tuned models, or allow the system to automatically pick the most suitable model based on input. Another option could be to generate multiple outputs from different models to better match the design task.

Beyond image generation tuning, AIdeation can be personalized to fit the design field, the designer's specialization, and work habits, similar to the ideas proposed by Long et al.~\cite{long2024not}. The system could adapt to various design domains by modifying the prompts or highlighting specific design elements to better suit individual users. For instance, designers could select a focus, such as environments, props, or characters, and AIdeation would generate customized output accordingly. Although the system currently lacks the ability to retain context from previous sessions, future updates could include memory features and personalized recommendations. Furthermore, incorporating self-adaptive capabilities, where the system adjusts its behavior based on user preferences or current work stage, could further improve its effectiveness, as suggested in previous research ~\cite{macias2013self}.


% \subsection{Controllability, Customization, and Personalization of GenAI}
% Another limitation noted by many users is the lack of diverse options in art style, atmosphere, and camera angles, primarily due to the constraints of the image generation model behind AIdeation. Different models have their strengths; for example, several users praised MidJourney for its aesthetic quality, while Stable Diffusion’s fine-tuning through LoRA ~\cite{hu2021lora} offers a variety of styles and specialized designs. Future improvements could allow users to intentionally select specific styles or atmospheres, choose corresponding fine-tuned models, or let the system automatically select the best model based on input. Alternatively, the system could generate multiple results from different models to better suit the design task.

% Beyond image generation tuning, AIdeation can also be personalized based on the design field, designer specialization, and work habits. As discussed in Section 8.2, the system could be customized for various design areas by adjusting prompts or emphasizing specific design elements that align with the user’s needs. For instance, designers could select their focus—whether environments, props, or characters—and AIdeation would generate results tailored to that area. While AIdeation currently lacks context from previous sessions, future versions could integrate memory and personalized recommendations, adapting to ongoing projects and user preferences for more targeted results.


% 2. Contextualize Findings
% Objective: Connect key findings to broader themes in HCI and GenAI.
% Designer rely on getting info <-> Brainstorm loop. AIdeation provided continuously rapid stimulation of both stages.
% AIdeation improves ideation efficiency and creativity through iterative refinement.
% It supports breadth (diverse idea generation) and depth (focused exploration), aligning with HCI principles of flexibility and user empowerment.
% Human Centered AI design with workflow integration. Increase quality and creativity than pureAI and human traditional workflow. Also improving designer's accepabiliy
% new guideline of disucssion


% GAI 快速實驗
% 1. 從最broad開始講，大家都用AI tool， 但沒效率。各個domain都有這樣的work。
% Highlight human centered approach, 可以更符合使用者需求, 有兩間還在用

% 2. AI expose Stucture，透明度，很容易讀（可以generalize），不知道背後在幹嘛，很難control，我們organize讓user能夠立刻了解這些key attributes。其他AI工具也可以參考這樣的做法。（expose這些attribute，讓使用者可以更精准控制） 1. 提供系統化資訊很快了解2 提供界面很快修改


% 3. 這個領域有高比例反AI，1. 覺得資訊是錯誤的 （我們的設計就是用真實世界的search reference來support）User 對 AI 的態度差異。要注意User的negative thought。工具好用但不是每個user都這樣。要給什麼建議，針對對AI負面的user (資訊是不正確的) 用真實的東西去Back AI產出的Idea
% \textbf{對ai負面態度的原因很多類型，針對不同原因去設計}

% 4. 不同階段user會要不同的control。拆成不同Phase，creative process convergence divergence。過去的做法是會用slider。我們是拆成brainstorming和refinement (concept designer workflow)。不同creative process，背後概念都是這樣。怎麼去support 這個progression

% 2. GenAI + Image Search Integration 
% Ideation 我們和其他人有什麼不一樣
% Notice: Mention unexpected findings or contrasts with prior research, emphasizing the novelty of results.

% 3. Expectations and Attitudes
% Objective: Explore how user expectations shape their experience with AIdeation.
% Attitude and Creativity
% Users expecting precise, finished designs often overlook exploratory benefits, while those with an open mindset utilize AIdeation more effectively.
% Discuss the implications of these findings for system onboarding and training.
% Notice: Use participant quotes to substantiate claims, linking findings to broader HCI challenges like trust, usability, and cognitive load.


% 2.1 Usage in the Same Domain
% Objective: Highlight how AIdeation can be further applied within environment concept design.
% Address specific scenarios, such as collaborative workflows or large-scale projects.
% Reflect on how iterative refinement could enhance multi-designer collaboration or client communication.
% Notice: Provide concrete examples to clarify potential applications.

% 2.2 Application in Other Design Domains
% Objective: Propose extending AIdeation’s principles to other domains.
% Suggest domains such as architecture, fashion, industrial design, or education.
% Emphasize how domain-specific adaptations (e.g., integrating specialized datasets) could improve relevance.
% Notice: Acknowledge challenges, such as adapting to domain-specific workflows or accommodating varied data needs.
% 我們學到：每個domain 都有 generalize的tool，但不太符合現在的workflow. 所以要針對使用者的workflow去。

% 2.3 Broader Lessons
% Objective: Derive generalizable lessons for designing AI systems.
% Reflect on how AI systems can integrate into workflows across creative domains. Like specific Prompt engineering and Design modules cooperation
% Highlight potential interdisciplinary creative applications, e.g., in collaborative or story-telling.

% Notice: Address ethical considerations, such as bias, over-reliance on AI, and maintaining human creativity.

% \subsection{Limitations and Future Work}
% \subsubsection{Limitation of Study}
% Discuss study duration, self report method
% Reflect on generalizability to other contexts or domains.
% Notice: Frame limitations constructively, linking them to potential future studies.


% \begin{figure*}
%     \centering
%     \includegraphics[width=1\linewidth]{figures/11 Design tools comparison.png}
%     \caption{A comparison between the initial outputs from AIdeation and DALL-E 3 on ChatGPT, using the same input provided by Field Study Participant S3, revealed notable differences. The participant observed that AIdeation produced designs with significantly greater diversity and richness compared to those generated by DALL-E 3 on ChatGPT.}
%     \label{fig:design tool}
% \end{figure*}

% Figure 11 compares the output from AIdeation with Dall-E 3 on ChatGPT using the same input provided by one of our field study participants (S3). With just a single well-crafted prompt through the LLM before engaging the image generation model, the diversity and richness of the designs increased significantly, as noted by a designer (S3). 

% In this research, AIdeation focuses on environment concept design, but with fine-tuned prompts and specific references, the same approach can be adapted for characters, props, and other design areas. This method could also extend to other domains by breaking down complex tasks, with each LLM handling specific subtasks (similar to \cite{de2024llmr}), supporting designers across various fields.

% \subsection{Implication for GenAI for Workflow Support}


% \subsection{Expanding AIdeation's Applicability}
% The findings from our study offer valuable insights into how AIdeation can enhance concept designers' workflows. As highlighted in the user study, AIdeation can be effectively used during meetings to communicate with clients or directors (P3–P4, P7–P9, P13–P14, P16). Its ability to generate diverse outputs and allow flexible real-time refinements enables designers to present multiple ideas instantly and adjust them based on feedback, significantly reducing the traditional trial-and-error process typical in designer-client collaborations.

% Another potential case is when designers need to explore multiple design topics based on the same theme. For example, when designing environments, props, and characters in a related game region, designers can start with an initial concept, such as an exterior reference, and type commands like “design a flying machine based on this environment” (P4). “This narrative-driven exploration process could greatly enhance the ideation workflow” (P10) for concept designers, particularly in the development and pre-production stages.


%Mike comments
%what did we learn? I sthere anything that we can improve or that the scientific community can learn from our work? What part do they don't like, the users? Look at roomdreaming. what are the things that can be accepted and what are the things that cannot be acceptable. What 建議 can we give? Because there are some of the users have a bad view 

