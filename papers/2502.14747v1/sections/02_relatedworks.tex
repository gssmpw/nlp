% > 1AC:
% > Insufficient context of related work to differentiate contribution from previous work. See individual reviews for specific areas of weakness.
% > 2AC:    
% > The related work section covers the main themes of the paper, but it feels a little bit surface level, a list of related references, with no particular discussion, with the exception of section 2.3 where they do explore a few specific examples. It might be useful to explore some other examples of AI that are tailored to specific human workflows, even if they are outside the specifics of this setting, it would help the authors identify and set-out key concerns.



% In our work, we aim to support concept designers' ideation workflows, explore design ideas, supporting their design workflow through AI-enhanced tools. To this end, we review related work in (1) the existing concept of the design exploration process, (2) AI approaches for design idea exploration, and (3) AI tools that support and integrate into the design workflow.%  


%Insufficient context of related work to differentiate contribution from previous work.
%Emphasized More on Human-AI Collaboration, how AIdeation better support workflow compare to other AI tools
%Find more related works, add more discussion in related works.

% -----------------NEW PART1-----------
\section{RELATED WORK}
We aim to integrate GenAI into the ideation process of concept designers and enhance their workflows. To achieve this, we reviewed related work in three key areas: (1) ideation within the design process, (2) GenAI tools that support visual exploration and ideation for designers, and (3) human-centered approaches for integrating AI into workflows.

\subsection{Idea Exploration Process of Designers} %fundamental or traditional
% Concept designers as well as any other creative professionals utilize a variety of methods to explore and refine ideas during the idea exploration process.

Like many other creative professionals, concept designers engage in an iterative process throughout their ideation workflows ~\cite{adams1999cognitive}. The process starts with divergent thinking, where the designer explores various possibilities and generates diverse ideas without the burden of constraints~\cite{rw5,rw8,rw9,rw10,Imagination}. During this stage, designers conduct intensive visual exploration ~\cite{rw11,rw12}, accumulate a collection of references ~\cite{rw17}, and organize in reference boards ~\cite{rw18}. This visual process encourages designers to absorb visual elements, inspiring their future designs ~\cite{linsey2011experimental}. Similarly to concept design, in some other design fields, such as architecture ~\cite{newland1987understanding}, product design ~\cite{boston1998design}, and interactive design ~\cite{park1993empirically}, not only do these fields rely on visual references, but they also require extensive research to gather factual knowledge and data. A previous study highlights research methodologies tailored for designers, emphasizing the potential of integrating research into the iterative creative process ~\cite{Navarro2022Research}. 
Both visual exploration and research serve as core sources of inspiration ~\cite{eckert2000sources}, fostering innovation and preventing design fixation ~\cite{rw4, rw21}.

Once a variety of ideas are generated, convergent thinking helps designers identify the most effective solution ~\cite{rw6}. During this phase, designers utilize the resources collected earlier to sketch the evolving idea on paper ~\cite{rw14, rw15, rw16}. They continuously evaluate and iteratively refine their ideas, explore different aesthetics, and ensure clear communication with stakeholders until a satisfactory result is achieved ~\cite{johnson1997analysis, Stamps1999Demographic, Stigliani2018The}. 

Numerous studies have proposed frameworks based on similar concepts to support the iterative process, such as the Wizard of Oz approach ~\cite{dow2005wizard} and Muse ~\cite{muller2013muse}. AIdeation integrates these insights to enhance concept designers' design process, supporting flexible divergent and convergent thinking while bridging designers with the latest GenAI tools that preserve the core elements of creativity and exploration.
% ------------------------------------



% -----------------NEW PART2-----------
\subsection{GenAI as a Catalyst for Visual Exploration and Ideation}


% comments
% I think we should put general GenAI tool likes Image generation model(Like Dall-E) first. Talk about how those basic model effect ideation process. And then discuss why those basic model cannot integrate into designer's ideation workflow. Then we talk about some related works that try to integrate GenAI into workflow or boosting ideation process.
%let's see if this is well written.

With the advancement of GenAI tools, many design domains have already integrated them into creative processes ~\cite{ko2023large, qin2023does}. Designers and artists extensively use general image generation tools to transform text prompts into visuals ~\cite{Epstein2023Art, Rick2023Supermind}. However, these tools are not specifically adapted to designers' creative process ~\cite{boucher2024resistance, vimpari2023adapt}.
Recent research has increasingly focused on enhancing user experience with image-generation tools. Reprompt ~\cite{wang2023reprompt} automatically refines the text prompts for the generated images.
Promptify ~\cite{rw23}, PromptCharm~\cite{PromptCharm2024} and DesignPrompt~\cite{DesignPrompt2024} introduce interactive prompt refinement to improve text-to-image generation workflows. IntentTuner ~\cite{zeng2024intenttuner} combines fine-tuning and generation functionalities to support a flexible workflow for text-to-image generation. StyleFactory~\cite{zhou2024stylefactory}
facilitates style alignment in image creation. DreamSheets~\cite{almeda2024prompting} enables users to explore the relationship between input prompts and image outputs through a spreadsheet interface. Collectively, these tools reduce the burden on designers to craft intricate prompts and help generate visuals that better align with their intentions.

Additionally, recent research explores the potential of GenAI by closely examining designers' needs during the ideation process. Researchers designed systems and user interfaces specifically to address the challenges they face.
For visual exploration, GenQuery ~\cite{son2024genquery} addresses the challenge of reference search by supporting expressive visual searches and enabling iterative refinement of image-based queries. 
CreativeConnect ~\cite{choi2024creativeconnect} streamlines the traditionally time-consuming process of recombining references by providing automated suggestion options.  C2Ideas ~\cite{hou2024c2ideas} assisted interior designers in generating color schemes aligned with user intentions. 
For ideation, DesignAID ~\cite{rw22} and MuseTree\footnote{MuseTree, https://www.asus.com/proart/software-solutions/musetree/} combat creative blocks by using large language models (LLM) to deliver diverse prompts and generate visuals. These systems effectively integrate GenAI to address specific challenges in traditional ideation processes across various domains. 

Recent works have explored new possibilities for human-AI collaboration in creativity. A study found AI can foster novel communication, with designers curating and refining generated images ~\cite{DesigningChiou2023}. Optimuse ~\cite{OptiMuse} aligns with designers' nonlinear creative processes and proposes a human-AI co-design framework that supports iterative idea exploration and flexible communication. COFI ~\cite{rezwana2023designing} advocates for AI systems that balance divergent and convergent process, and calls for expanding AI's creative roles beyond generation and evaluation to include conceptual exploration. These works mentioned above provide valuable insights to integrate GenAI into the creative process, such as optimizing user experience, designing tools to address specific challenges, and exploring models of human-AI collaboration.

% empowers designers to engage with AI agents as opinionated colleagues, enhancing creativity and producing richer, more innovative outcomes.


% Those works inspired us for the development of AIdeation, 

% While many recents works offer valuable insights into how GenAI enhances creativity but do not fully address the complexity of concept designers' ideation process. 

% Their unique visual exploration, reference collection, and focus on specific design elements require more tailored support distinct from other design domains.

% Inspired by the aforementioned works, we recognize the need for a tool that effectively leverages existing GenAI capabilities, DALL-E in particular, to benefit concept designers and that aligns with their creative needs.

%  Tools like DesignAID~\cite{rw22} address creative blocks by combining large language models (LLMs) with image generation to provide tailored prompts and visual inspirations, emphasizing quality over quantity in their outputs. Similarly, Drawing with Reframer~\cite{lawton2023drawing} enables real-time collaboration between users and AI in the drawing process, fostering interactive and iterative creativity. These tools emphasize user control and adaptability, ensuring the AI complements rather than replaces human creativity.

% Further advancing ideation, MuseTree\footnote{MuseTree, https://www.asus.com/proart/software-solutions/musetree/} supports imaginative exploration by offering iterative, AI-driven prompts that organically evolve ideas. This approach encourages a non-linear creative journey, allowing users to explore a wide range of possibilities while refining their concepts progressively. Enhancing visualization capabilities, CreativeConnect~\cite{choi2024creativeconnect} aids early-stage graphic design through reference recombination, striking a balance between automated suggestions and manual controls. Likewise, GenQuery~\cite{son2024genquery} supports expressive visual search, enabling iterative refinement of image-based searches. This fosters both divergent and convergent thinking, advancing creative workflows by aligning GenAI functionalities with designers' natural ideation processes.


% These works offer valuable insights into how GenAI enhances creativity but do not fully address the complexity of concept designers' ideation process. Their unique visual exploration, reference collection, and focus on specific design elements require more tailored support distinct from other design domains.


% CreativeConnect~\cite{choi2024creativeconnect} aids early-stage graphic design through reference recombination, striking a balance between automated suggestions and manual controls. Likewise, GenQuery~\cite{son2024genquery} supports expressive visual search, enabling iterative refinement of image-based searches. This fosters both divergent and convergent thinking, advancing creative workflows by aligning GenAI functionalities with designers' natural ideation processes.



% For instance, while generating numerous images can provide a broad array of visual inspirations, studies have found that an excessive number of outputs can overwhelm artists, detracting from their ability to focus on meaningful ideation~\cite{Epstein2023Art}. Moreover, these general-purpose tools lack customization tailored to specific creative contexts, failing to align with the nuanced needs of a designer's ideation workflow ~\cite{LongGero}.


% ------------------------------------

% \subsection{GenAI as a Catalyst for Creative Exploration and Ideation} % think about the tittle: ietration ideattion creative etc... research and brainstorming
%there is no organization here, organize it and connection look at designer workflow ection 
% design focused works
% GenAI tools have become powerful aids in the exploration of creative ideas, offering designers and artists new ways to brainstorm, iterate, and refine concepts~\cite{Epstein2023Art, Rick2023Supermind}. (if not important don't say)GANzilla allows users to discover image editing directions within Generative Adversarial Networks (GANs)~\cite{evirgen2022ganzilla}. DesignAID~\cite{rw22} combines large language models (LLMs) with image generation to help artists overcome creative blocks by providing prompts and visual inspirations without needing to generate excessive images. Drawing with Reframer ~\cite{lawton2023drawing} allows users to collaborate with AI in real-time drawing. (important)MuseTree \footnote{MuseTree, https://www.asus.com/proart/software-solutions/musetree/} fosters imaginative exploration by offering AI-driven prompts that evolve ideas iteratively and organically, encouraging a non-linear creative journey. CreativeConnect~\cite{choi2024creativeconnect} enhances early-stage graphic design by suggesting visual variations and new ideas through reference recombination, offering a balance of automatic suggestions and manual controls. GenQuery~\cite{son2024genquery} supports expressive visual search by allowing users to iteratively refine image-based searches, facilitating both divergent and convergent thinking. In addition, Promptify ~\cite{rw23} further improves the prompt engineering process by optimizing the quality and relevance of generated content, enhancing the efficiency of idea exploration. PromptCharm~\cite{PromptCharm2024} and DesignPrompt~\cite{DesignPrompt2024} introduce interactive prompt refinement to improve text-to-image generation workflows, and a recent RTD  (Research through design)~\cite{DesigningChiou2023} study highlights how AI can expand artistic expression through collaborative ideation between designers and image generators. 

% These works offer valuable insights into how GenAI enhances creativity but do not fully address the complexity of concept designers' ideation process. Their unique visual exploration, reference collection, and focus on specific design elements require more tailored support distinct from other design domains.

%While these tools expand creative possibilities and streamline early-stage ideation, they often fall short of addressing the deeper, more complex needs of concept artists during the exploration phase.


%Main Issue

% AC2: Surface Level, related references without particular discussion
% Lack of Depth and Contextualization:

% Solution

% exploring more examples, even outside the specific design context, to identify relevant comparisons and key concerns.

% Highlevel: Iterative Ideation
% subtopics: research the topic, 
% perform visual searches, 
% brainstorm ideas,

% 結論 太籠統
% -----------------NEW PART3-----------
\subsection{Human-Centered AI for Workflow Support}%our range is outside the designers, find more papaers about AI.h Human centered AI focused collaboration workflow

With advancements in AI, human-centered AI (HCAI) has emerged as a crucial approach to enhance human abilities by fostering collaboration between humans and AI systems. It emphasizes a symbiotic relationship where AI tools enhance human capabilities and streamline workflows in various domains ~\cite{Venigandla2024Hybrid, shneiderman2022human, xu2023transitioning}. 
In alignment with user needs, these systems amplify human expertise while ensuring transparency and explainability, helping users understand the decisions and limitations of AI ~\cite{Ehsan2021Expanding, Kim2024Establishing}. Through effective communication, iterative feedback, and user control, these systems create dynamic collaborations to enhance workflows ~\cite{Hois2019How, Scharowski2023Exploring, Usmani2023Human-Centered}.

% Human-centered AI has emerged as a pivotal approach to fostering collaboration between humans and machines. It focus on fostering a symbiotic relationship between humans and AI, where AI tools amplify human capabilities and enhance experts' workflows across a wide range of domains~\cite{Venigandla2024Hybrid, shneiderman2022human, xu2023transitioning}.
% Human-centered AI enhances workflows by amplifying human expertise through systems designed to align with user needs. Transparency and explainability are crucial~\cite{Ehsan2021Expanding}~\cite{Kim2024Establishing}, ensuring users understand AI decisions and its limitations. Effective communication and iterative feedback create a dynamic collaboration, while user control and customization allow systems to adapt to specific workflows~\cite{Hois2019How}~\cite{Scharowski2023Exploring}. These principles ensure seamless and symbiotic integration, fostering trust and usability across diverse domains~\cite{Usmani2023Human-Centered}.
%
%usability, why sucess? becuse human ai guidelines 
% Overview: User Centered Workflow: Integration AI into workflow "consideration", following the workflow
% Typical Cases
% https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=human+centered+AI+system&btnG=


Recent research has applied these principles across various fields. In the creative industry, researchers have delved deeply into domain knowledge and workflows of different design disciplines, crafting systems thoughtfully tailored to align with user workflows ~\cite{Anantrasirichai2020Artificial, Knearem2023Exploring, Mccormack2020Design}. For example, 
RoomDreaming ~\cite{wang2024roomdreaming} generates photorealistic interior design alternatives and enables the user to clearly understand and iteratively refine their options, allowing designers to work collaboratively with their clients. 
MemoVis ~\cite{rw20} enables feedback providers to create companion reference images for 3D designs with real-time viewpoints, democratizing actionable feedback regardless of 3D expertise. Both works reduce the communication time between clients and designers.
PlantoGraphy ~\cite{PlantoGraphy2024} integrates iterative design processes into landscape rendering, offering users control and flexibility to better align with their unique workflows. 
Keyframer ~\cite{Tseng2024KeyframerEA} uses a natural language interface to make motion design intuitive and accessible, fostering a feedback loop that allows animators to explore and refine ideas with creative autonomy. 
In addition to these works, researchers have developed GenAI systems for fashion ~\cite{rw29}, UX and industrial design ~\cite{claytoplay2024}, and 3D scene design ~\cite{oh2024lumimood}. 
These works enhance design workflows by leveraging GenAI to reduce repetitive tasks, providing intuitive user interfaces that foster system understanding and enabling precise control to refine design outputs.
% Reframer ~\cite{lawton2023drawing} facilitates real-time user-AI collaboration in drawing, highlighting the importance of balancing fine-grained control with emergent creativity.

Research beyond the design field also offers valuable insights for developing human-centered AI systems. In medicine, NaviPath ~\cite{navipath2023} uses AI models to simplify the navigation of high-resolution tumor images, aligning with pathologists' workflows by enabling smooth transitions between low to high magnifications. It allows customization of AI recommendations and provides clear explanations, enhancing user engagement and improving overall accuracy. 
In aviation, the AI Support System for Pilots’ Decision-Making Process ~\cite{pilot} highlights the importance of transparent feedback loops, enabling pilots to understand AI recommendations. Its real-time guidance and customization enhance decision-making, safety, and efficiency, especially under information overload. Both approaches emphasize user control and refining AI contributions to effectively augment human expertise.

% With all the contributions of these works in mind, it was clear that we needed to create a system that allowed AI to be integrated to the concept designers' workflow. Thus we developed Aideation, a tool specifically designed for concept designers. Aideation enhances exploration, broadens and enhances the first stages of ideation, and provides the flexibility required to meet the complex and dynamic demands of concept designers' creative workflows. A system that allows a high degree of controllability, transparency and dynamic interaction between the Human and the AI. 

While many studies demonstrate how GenAI can enhance creative processes and design workflows, no tool fully addresses the complexities of concept designers' workflows. Concept design requires specialized support throughout the iterative process, from research and brainstorming to refining ideas. These threads of work offer valuable inspiration for developing AIdeation, paving the way for a solution tailored to the unique needs of concept designers.


% Keyframer~\cite{Tseng2024KeyframerEA}, with its natural language interface, achieves success by making motion design intuitive and accessible, fostering a seamless feedback loop and enabling animators to explore and refine their ideas with creative autonomy. Each system thrives by adhering to core human-AI interaction principles such as transparency, communication, and customization. 
% MemoVis~\cite{rw20} enhances AI-powered reference image generation through transparency, explainability, and real-time viewpoint suggestions, enabling dynamic collaboration. Its "text + scribble" and "text + paint" features offer customization. By adhering to these human-AI interaction principles, MemoVis effectively streamlines the feedback process for 3D design projects.

% Reframer~\cite{lawton2023drawing} enables real-time collaboration between users and AI in the drawing process, fostering interactive 
% https://dl.acm.org/doi/proceedings/10.1145/3613904#heading36
% https://dl.acm.org/doi/10.1145/3613904.3642812

% 這邊開始介紹 how AI assist workflow in other field 
%what did they do but also why this works so well and what did they do it like this.




% ---------------------------------------------------------------------------------------
% ---------------------------------------------------------------------------------------
 
%  Integrating AI into Workflow 
% ?? tittle? GenAI workers support? 
% AI tools have made significant inroads into the creative industries, particularly in design workflows~\cite{Anantrasirichai2020Artificial, Knearem2023Exploring, Mccormack2020Design}.
% %Pt it into the second

% %till here some others they also have other go there so look at it. 

% MemoVis~\cite{rw20}, a browser-based tool, simplifies providing feedback for 3D design projects by generating reference images with AI. Since feedback often requires 3D and image editing skills, which not all users have, MemoVis offers real-time viewpoint suggestions and tools like "text + scribble" and "text + paint" for creating accurate visual feedback. Similarly, the paper "Large-scale Text-to-Image Generation Models for Visual Artists’ Creative Works"~\cite{ko2023large} highlights how models like DALL-E assist artists by automating parts of the creative process, expanding ideas, and facilitating communication. However, it also notes challenges such as limited control and customization, making it difficult for artists to fully integrate these tools into specialized workflows.
% Deep Dream Generator \footnote{Deep Dreamer Generator, https://deepdreamgenerator.com/} is another AI tool that manipulates images to create surreal, stylized art, exploring aesthetics beyond traditional methods. GANPaint Studio\footnote{GANPaint Studio, https://ganpaint-demo.vizhub.ai} allows users to modify high-level visual content, altering elements like lighting, objects, and textures.
% Other tools focus on blending references or concepts, such as Visi-Blends~\cite{rw25} and VisiFit~\cite{rw26}, which combine two objects to create integrated meanings. ICONATE~\cite{rw27} merges different icons to generate new ones, while Pop-Blends~\cite{Wang2021PopBlends} suggests conceptual blends of images. FashionQ~\cite{rw29} applies blending techniques to fashion design, and Artinter~\cite{rw28} supports merging style elements to improve communication.
% RoomDreaming~\cite{wang2024roomdreaming} is designed for interior designers, it generates photo-realistic design alternatives based on room layouts and preferences, enabling quick iterations and visual feedback for collaborative refinement.  PlantoGraphy~\cite{PlantoGraphy2024} introduces iterative design processes into AI-generated landscape renderings, further expanding AI's application in specific design domains. 

% %read abstract aGenAIn to chack is this section
% Keyframer~\cite{Tseng2024KeyframerEA} supports animators by allowing them to animate static images using large language models (LLMs) through natural language descriptions, offering new methods for exploring motion design. 


% %Include Navipath
% % Check other Human-Centered GenAI on workflow support paper
% % https://scholar.google.com/scholar?cites=16620602765115049001&as_sdt=2005&sciodt=0,5&hl=en
% % https://arxiv.org/abs/2306.15774

% % whaat do they cite? lookwhat they are and include the relevant ones.
% While these tools showcase how GenAI can integrate into various design fields, there is currently no AI tool specifically tailored to the concept designer’s workflow. Concept design demands specialized support across the entire process, including research, visual exploration, brainstorming, reference gathering, and idea presentation. These works provide valuable inspiration for AIdeation’s development, guiding the creation of a solution more aligned with the unique needs of concept designers.

% 結論太籠統
% rewrite
% Each design domain has its own workflow and requirements. While many AI tools provide valuable support, concept designers face more intricate challenges. These tools offer visual alternatives and feedback but often lack the depth, diversity, and control needed for early ideation. To address this, we developed Aideation, a tool tailored specifically for concept designers, offering enhanced exploration, broader ideation, and the flexibility required to meet the complex demands of their creative workflows. 
% concept designer 有需求, 其他是for other design workflow