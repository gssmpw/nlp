\section{Introduction} \label{sec:intro}

While legged locomotion control has been well-addressed through reinforcement learning with effective data collection \cite{makoviychuk2021isaac, gu2024humanoid, Genesis, zakka2025mujoco} and well-crafted reward guidance \cite{margolis2023walk, hwangbo2019learning, radosavovic2024learning, chen2024learning, li2023robust, long2024learning, margolis2024rapid}, the performance of such policies remains highly dependent on the accuracy and comprehensiveness of state observations \cite{nahrendra2023dreamwaq, sun2024leg, long2024hybrid, margolis2024rapid}. The state space can be roughly categorized into three types: 1) Accessible states, which are reliable and obtainable on real robots, such as joint encoders and IMU; 2) Privileged states \cite{kumar2021rma, lee2020learning}, which are unavailable on real robots, including velocity and static hardware parameters; and 3) External states \cite{miki2022learning, li2023robust, zhuang2024humanoid, long2024learning, yang2021learning}, which are observable but inherently noisy and occasionally unreliable. Previous works \cite{lee2020learning, kumar2021rma} have focused on encoding historical accessible states to approximate privileged and external states and these attempts on quadrupeds achieves successful traversal of static unstructured terrains such as stairs and slopes. However, these estimation methods often require robots to physically interact with unstructured terrains before responding \cite{long2024hybrid, cuiadapting, margolis2023walk}, forcing a trade-off between sacrificing speed to ensure safety or acting quickly but failing in scenarios that demand rapid responses, potentially leading to falls. 

To address this, perceptive locomotion methods have been developed \cite{cheng2024extreme, agarwal2023legged, yang2023neural}, enabling robots to anticipate incoming terrains and plan motions in advance using onboard sensors to obtain external states. Despite their impressive results, these methods are heavily dependent on maintaining consistency between perceived external states and those appeared during simulation \cite{hoeller2024anymal}. When mismatches occur, the robot may exhibit abnormal or dangerous behaviors.

In practice, it is impossible to provide the robot with all potentially encountered external states within the simulator \cite{zhu2025vr}. Current contact models in simulators are limited to rigid-body interactions and it is computationally expensive to incorporate dynamic terrains and obstacles during training \cite{choi2023learning}. Although previous research has highlighted the combination of perception and proprioception to achieve robust locomotion performance \cite{miki2022learning, zhang2024resilient, fu2022coupling} against perception inaccuracy, these studies have primarily focused on quadruped robots and low-risk scenarios, where a delayed response to the environment does not typically lead to locomotion failure.

Despite the impressive results of recent research achieving humanoid motions through tele-operation and imitation learning \cite{cheng2024expressive, ji2024exbody2, lu2024mobile, he2024hover, fu2024humanplus, he2024omnih2o}, the bipedal lower-limb structure of humanoid robots presents unique challenges in locomotion control compared to quadrupeds \cite{gu2024advancing, radosavovic2024learning}. The shifting of the gravity center in humanoid robots makes them more prone to unrecoverable falls. As a result, humanoid robots are more vulnerable to unexpected physical interactions given deficient perception. Consequently, current perceptive humanoid locomotion studies are limited to static terrains and confined environments, with performance heavily reliant on the quality of the perception module \cite{long2024learning, zhuang2024humanoid}.

In this work, we propose \textbf{VB-Com} (Vision-Blind Composite Humanoid Control), a locomotion policy capable of handling dynamic obstacles and compensating for deficient perception. VB-Com enables the robot to determine when to trust the perception module for accurate external state observations and when to disregard it to avoid misleading information that could result in locomotion failures. To achieve this, we first develop a vision policy that utilizes external visual observations from an onboard perception module, and a blind policy that relies solely on proprioceptive observations. The policies are combined using two return estimators, trained alongside the locomotion policies. These estimators predict future returns for each policy based on the current state and determining whether to rely on the vision policy or switch to the blind policy. As demonstrated in Fig \ref{fig:teaser}, in situations where the onboard sensors fail to provide comprehensive perception, VB-Com effectively enables the robot to quickly recover from potential failures caused by deficient perception, allowing it to traverse challenging terrains and obstacles. The contributions of this work can be summarized as follows:

\begin{itemize}
    \item A perceptive and a non-perceptive humanoid locomotion policy that can traverse gaps, hurdles and avoid obstacles.
    \item A novel hardware-deployable return estimator that predicts future returns achieved by current policy conditioned on proprioceptive states observation.
    \item A dual-policy composition system that integrates vision and blind policies for robust locomotion through dynamic obstacles and terrains where onboard sensors provide deficient external perception.
\end{itemize}
