\section{Result} \label{sec:result}

\subsection{Setup}

In this section, we evaluate VB-Com across the following perspectives:
\begin{itemize}
    \item Under what conditions does VB-Com demonstrate superior performance compared to using a single-policy approach?
    \item How does VB-Com outperforms baseline methods in those scenarios?
    \item How well does the proposed return estimator contribute to the composition system?
\end{itemize}

\begin{figure}[h]
\centering{\includegraphics[width=0.5\textwidth]{figures/noise.png}}
\caption{We present four types of perception noises and implement them on heightmaps during evaluation: gaussian noise, \textcolor{red}{forward shifting noise}, \textcolor{green}{lateral shifting noise} and \textcolor{blue}{floating noise}.}
\label{noise}
\end{figure}

\subsubsection{Evaluation Noise}
To simulate situations where the robot encounters perception outliers not present in the simulation, we introduce a quantitative curriculum noise designed to mimic varying levels of perception deficiency. As shown in Fig. \ref{noise}, we focus on four types of noise: (1) \textbf{Gaussian noise}: noise points sampled from a Gaussian distribution, to the original heightmap. The noise level is scaled from 0.0 to 1.0, where the training noise level corresponds to a 0.1 noise level in this scenario. (2) \textbf{Shifting noise}: replacing points in the original heightmap with noise sampled from a Gaussian distribution. The range of replacement points is controlled by the noise level, where a $100\%$ noise level results in a fully noisy heightmap. The shifting direction can either be along the heading direction (red box) or sideways (green box). (3) \textbf{Floating noise}: The heightmap is displaced vertically, either upwards or downwards, the floating noise simulates variations in terrain height. (blue box).

\begin{table}[!ht]
\caption{Terrain Size Scales (m)}
\label{tab:terrains}
\begin{center}
\renewcommand\arraystretch{1.25}
\begin{tabular}{lcccc}
\toprule[1.0pt]
Terrain & Length & Width & Heights\\
\midrule[0.8pt]

Gaps        & $(0.6, 1.2)$ & $(\bm{0.6}, \bm{0.8})$ & $(-1.8, -1.5)$\\  
Hurdles     & $(0.8, 1.0)$ & $(0.1, 0.2)$ & $(\bm{0.2}, \bm{0.4})$\\  
Obstacles   & $(\bm{0.2}, \bm{0.4})$ & $(0.2, 0.4)$ & $(1.4,1.8)$\\  

\bottomrule[1.0pt]
\end{tabular}
\end{center}
\end{table}

\subsubsection{Experiments Setup}
In simulation, we conduct $10 \times 3$ experiments for each method across three types of terrain, replicating the experiments three times to calculate the variance. Each episode involves the robot navigating through 8 goal points, with each goal paired with a corresponding challenging terrain or obstacle. The size of the terrains is set to the maximum curriculum terrain level, as shown in Table \ref{tab:terrains}. The bolded values indicate the primary factors that contribute to the difficulty for the terrain.

\subsubsection{Baselines}
We primarily compare VB-Com with the vision and blind policies operating independently. Additionally, as previous works have shown that robust perceptive locomotion can be learned by incorporating various perception noises during training \cite{miki2022learning}, we add a \textbf{Noisy Perceptive policy baseline} trained using the same noises implemented in the evaluation. This allows us to examine how well the proposed VB-Com policy performs compared to policies that have already seen the evaluation noises. The evaluation noises are introduced to the Noisy Perceptive policy in a curriculum format during training, which evolves with the terrain level.

\begin{figure*}[h]
\centering{\includegraphics[width=\textwidth]{figures/returnsim.png}}
\caption{Illustrations of the variation in estimated return and action phases(0 for $a_b$ and 1 for $a_v$) across three concerned terrains.}
\label{return}
\end{figure*}

\subsection{Example Case}
First, we illustrate how VB-Com operates, specifically when the composition switches to $\pi_b$ and how it effectively controls the robot to traverse the terrain against deficient perception (Fig. \ref{return}). We demonstrate $3$ seconds of the estimated returns, along with the policy composition phase, as the robot walking through the challenging terrain during the simulation experiments at the noise level of $100\%$. Before the robot encounters challenging terrains, we observe that the estimated return $G^e_{\pi_v}(s_t)$ consistently exceeds $G^e_{\pi_b}(s_t)$, as the robot is walking on flat ground with relatively stable motion. This observation aligns with the discussion in Section \ref{subsec:vb-com}, where it was explained that $\pi_v$ benefits from the external state observation and results in a higher return $G_t$. This characteraistic ensures the robot operates at $\pi_b$ while stable motion. 

Once the deficient perception reaches the $100\%$ noise level, the robot will not be aware of the incoming challenging terrains until it collides with them. At this point, we observe that $G^e_{\pi}(s_t)$ drops sharply within several control steps, prompting the switch to the blind policy. This switch allows the robot to respond to the terrain, and once the motion stabilizes, $G^e_{\pi}(s_t)$ returns to a normal level, at which point the vision policy regains control. These cases demonstrate the effectiveness of VB-Com, which responds quickly to deficient perception, but avoids unnecessary switches to the blind policy when it is not needed.


\begin{table*}[!h]
\caption{VB-Com Evaluations}
\label{tab:VB-Com}
\begin{center}
\renewcommand\arraystretch{1.25}
\begin{tabular}{lccccccc}
\toprule[1.0pt]
Noise Level &Method & Goals Completed($\%$) & Rewards & Average Velocity & Fail Rate & Collision Steps($\%$) & Reach Steps\\
\midrule[0.8pt]

% \multirow{4}{*}{Prop Advisor}&0.25& $0.7560$& $0.7964$& $0.7001$ & \multirow{4}{*}{$0.8600$}\\

\multirow{2}{*}{0\% noise} & VB-Com & $84.05 \pm 2.28$ & \bm{$142.07 \pm 4.19$} & $0.71 \pm 0.01$ & \bm{$0.29 \pm 0.01$} & $1.50 \pm 0.14$ & $177.29 \pm 4.66$\\  
                              & Vision & $73.57 \pm 4.97$ & $118.07 \pm 10.42$ & $0.73 \pm 0.01$ & $0.42 \pm 0.07$ & \bm{$1.39 \pm 0.53$} & $204.82 \pm 28.91$\\  \midrule
\multirow{2}{*}{30\% noise} & VB-Com & $82.24 \pm 6.6$ & $132.81 \pm 7.64$ & $0.71 \pm 0.01$ & $0.34 \pm 0.10$ & $2.09 \pm 0.13$ & $178.13 \pm 4.13$\\  
                              & Vision & $72.76 \pm 2.29$ & $115.20 \pm 2.43$ & $0.75 \pm 0.02$ & $0.43 \pm 0.05$ & $2.52 \pm 0.32$ & $195.58 \pm 21.98$\\  \midrule
\multirow{2}{*}{70\% noise} & VB-Com & $82.48 \pm 1.20$ & $132.44 \pm 6.17$ & $0.70 \pm 0.02$ & $0.33 \pm 0.03$ & $2.12 \pm 0.11$ & $184.81 \pm 4.47$\\  
                              & Vision & $55.38 \pm 3.33$ & $58.24 \pm 13.97$ & $0.73 \pm 0.03$ & $0.67 \pm 0.07$ & $6.08 \pm 0.82$ & $190.50 \pm 18.28$\\  \midrule
\multirow{3}{*}{100\% noise} & VB-Com & \bm{$84.81 \pm 6.45$} & $129.99 \pm 9.84$ & $0.72 \pm 0.02$ & \bm{$0.29 \pm 0.08$} & $2.60 \pm 0.68$ & $182.29 \pm 11.47$\\  
                              & Vision & $48.71 \pm 5.60$ & $47.53 \pm 17.55$ & $0.70 \pm 0.06$ & $0.69 \pm 0.06$ & $6.92 \pm 1.36$ & $268.40 \pm 57.11$\\  
                              & Noisy Perceptive & $80.52 \pm 0.91$ & $116.94 \pm 4.07$ & \bm{$0.76 \pm 0.02$} & $0.32 \pm 0.04$ & $3.49 \pm 0.38$ & \bm{$154.98 \pm 4.41$}\\ \midrule
& Blind & $83.76 \pm 1.35$ & $131.29 \pm 3.48$ & $0.70 \pm 0.01$ & $0.33 \pm 0.05$ & $2.57 \pm 0.27$ & $184.08 \pm 1.85$\\  

% Perceptive  & $0.00 \pm 0.00$ & $0.00 \pm 0.00$ & $0.00 \pm 0.00$ & $0.00 \pm 0.00$ & $0.00 \pm 0.00$\\  
% Blind  & $0.00 \pm 0.00$ & $0.00 \pm 0.00$ & $0.00 \pm 0.00$ & $0.00 \pm 0.00$ & $0.00 \pm 0.00$\\  
% Noisy Perceptive & $0.00 \pm 0.00$ & $0.00 \pm 0.00$ & $0.00 \pm 0.00$ & $0.00 \pm 0.00$ & $0.00 \pm 0.00$\\  

\bottomrule[1.0pt]
\end{tabular}
\end{center}
\end{table*}

\subsection{Evaluations on Different Noise Levels}
\textbf{VB-Com achieves robust locomotion performance under different levels of perception deficiency.} As shown in Tab \ref{tab:VB-Com}, performance of the vision policy declines shaprly with the arise of noise level. In addition, since the evaluation experiments set the terrain curriculum to the maximum level, the vision policy struggles even at a $0\%$ noise level: It only achieves around $73\%$ goal-reaching success, with a termination rate exceeding $40\%$. This poor performance is likely due to the severe challenge terrains, such as the farthest range of the heightmap $(0.85m)$ is only $0.05m$ wider than the width of the gaps$(0.8m)$. In contrast, VB-Com achieves a stable higher goal-reaching success against different levels of perception deficiency. In contrast, VB-Com achieves consistently higher goal-reaching success across varying levels of perception deficiency, including both noise and perception range limitations.

Despite the high goal-reaching success, we also include additional metrics to further analyze the performance. The reward values recorded throughout each episode indicate the proposed method’s ability to achieve both goal completion and collision avoidance. These rewards strongly correlate with the robot’s success in reaching the target while minimizing collisions. For instance, VB-Com at the $0\%$ noise level achieves the highest rewards$(142.07)$, although the goal completion rate$(84.05)$ is slightly lower compared to the trail in $100\%$ noise level $(84.81)$. This is because VB-Com switches to the blind policy more often in  $100\%$  noise level, resulting in more frequent collisions and lower rewards obtained. 

The reach steps metrics indicates the smoothness of the policy in overcoming challenging obstacles. Since the switching mechanism requires several steps to respond effectively, VB-Com results in a higher number of reach steps as the noise level increases. This is because, under higher noise conditions, the system needs additional time to transition from the vision policy to the blind policy, which leads to more gradual and controlled responses to terrain challenges.
\begin{figure}[h]
\centering{\includegraphics[width=0.5\textwidth]{figures/noiseevalueate.png}}
\caption{We compare the collision and goal-reaching performances under different noise levels. VB-Com achieves low collisions and high success rates with accurate perception, and its success rate remains high under deficient perception.}
\label{noiseevalueate}
\end{figure}

\begin{figure}[h]
\centering{\includegraphics[width=0.5\textwidth]{figures/terraineval.png}}
\caption{Comparisons between the Noisy Perceptive policy and VB-Com in navigating gaps and hurdles separately.}
\label{terraineval}
\end{figure}


\subsection{Comparisons with Blind Policy}
\textbf{VB-Com achieves less collision than the blind policy when perception becomes less dificient.} As shown in Tab \ref{tab:VB-Com}, the blind policy achieves a relatively high Goals Completed rate $(83.76\%)$, as its performance is unaffected by deficient perception. Therefore, we include an evaluation of the collision performance between VB-Com and the blind policy to further highlight the advantage of the proposed framework. In our evaluations, "Collision Steps" is defined as the ratio of the number of steps during which the robot collision model (Fig \ref{robot}) makes illegal contact with the terrain or obstacles, relative to the total number of steps within an episode.

We can observe from Tab \ref{tab:VB-Com} that the collision steps increase with the noise level for VB-Com. Fig \ref{noiseevalueate} provides a more intuitive illustration: as perception becomes more comprehensive, VB-Com achieves both fewer collisions and better goal-reaching performance. In contrast, the blind policy maintains a high goal-reaching rate but results in more collisions, while the vision policy performs better in avoiding collisions when the perception is accurate and comprehensive. As the noise level increases, the performance of VB-Com begins to resemble that of the blind policy. These results demonstrate the effectiveness of the composition system, which benefits from both sub-policies to achieve better performance in terms of both goal-reaching and minimizing collisions.

\subsection{Comparisons with Noisy Perceptive Training}
\textbf{Compared to policies trained with noisy priors, VB-Com achieves equivalent performance without prior knowledge of the noise, while also demonstrating better training efficiency and the ability to handle more challenging terrain difficulties.} The comparisons (Tab \ref{tab:VB-Com}) with Noisy Perceptive policy show that the Noisy Perceptive policy achieves a relatively high goal completion rate $(80.52\%)$ but exhibits a higher collision step rate $(3.49\%)$. It can be concluded that, as severe noise is introduced during evaluation, the heightmap quickly becomes random noise with the increasing noise level. In response, the Noisy Perceptive policy begins to exhibit behavior similar to that of the blind policy—making contact with obstacles and reacting when the noisy signals overwhelm the external observations.

To further investigate the conditions under which the Noisy Perceptive policy fails to surpass the performance of VB-Com, we evaluate goal-reaching performance under different terrains (Fig. \ref{terraineval}). The results show that VB-Com outperforms the Noisy Perceptive policy in gap terrains, while the Noisy Perceptive policy performs better in hurdle situations, achieving a higher success rate in preventing the robot from being tripped by hurdles. However, recovering from missed gaps requires a quicker response, or the robot risks falling. These results demonstrate that the single-policy method fails to handle such dynamic challenges effectively, highlighting the advantages of the composition in VB-Com.

\begin{figure}[h]
\centering{\includegraphics[width=0.5\textwidth]{figures/trainplot.png}}
\caption{Training curves for terrain levels and the return estimation loss.}
\label{train}
\end{figure}

Moreover, the terrain level rises slowly for the Noisy Perceptive policy (Fig. \ref{train}-(a)), and it fails to reach the maximum level achieved by the vision and blind policies. This is because the policy struggles with the trade-off of whether to trust the external perception, which requires the addition of an extra module to address the challenge. This slow progression highlights the difficulty of handling high levels of perception deficiency, whereas VB-Com can efficiently navigate such situations by leveraging the strengths of both the vision and blind policies.

\begin{table}[!ht]
\caption{Return Estimation Evaluations}
\label{tab:RE}
\begin{center}
\renewcommand\arraystretch{1.25}
\begin{tabular}{lcccc}
\toprule[1.0pt]
Method & Goals Completed($\%$) & Collisions & Reach Steps\\
\midrule[0.8pt]

100-steps) & $78.24 \pm 1.86$ & \bm{$2.49 \pm 0.04$} & $193.7 \pm 3.2$\\  
RE(50-steps)  & \bm{$81.90 \pm 2.81$} & $2.75 \pm 0.17$ & $184.6 \pm 1.4$\\ 
Re(5-steps)   & $69.90 \pm 7.34$ & $5.23 \pm 0.59$ & $192.6 \pm 3.3$\\  
Re(1-step)    & $59.57 \pm 2.00$ & $4.78 \pm 0.16$ & \bm{$167.4 \pm 5.0$}\\  
MC-based      & $74.14 \pm 2.69$ & $4.26 \pm 0.56$ & $192.8 \pm 11.8$\\  

\bottomrule[1.0pt]
\end{tabular}
\end{center}
\end{table}

\subsection{Return Estimator Evaluations}
\textbf{The proposed return estimator achieves accurate and efficient return estimation with accessible states observations.} Since we update the return estimator using temporal difference, we compare it with the Monte Carlo-based search return estimator that estimate the furtuen expected returns with the following regression loss directly: $\mathbb{E}_t[\hat{G}_{\pi_i}^e(s_t) - \sum_{t} ^ {t+T} \gamma^t r(s_t, a_t)]$. As shown in Fig. \ref{train}-(a), the MC-based estimator struggles to converge due to the accumulation of noise. In contrast, the proposed TD-based return estimator within the vision policy convergent stably as it updates alongside the locomotion policy. The results in Tab \ref{tab:RE} further highlight the ineffectiveness of the MC-based return estimator in providing accurate estimations to guide the policy composition. Specifically, the MC-based estimator struggles to respond promptly to collisions with obstacles, this delay in response leads to larger collisions and longer reach steps, as the policy cannot effectively adjust its actions in real-time. 

\textbf{We also evaluate the impact of different switch periods (T), which define the expected return duration during return estimator updates.} While training performance remains consistent across varying periods, we observe that excessively short switch periods can negatively impact system performance. In such cases, the two policies may conflict, resulting in incomplete motion trajectories when traversing the challenging terrains and failures.

\textbf{We observe that training effectiveness is highly dependent on data variance.} For instance, the estimator within vision policy converges the fastest due to its access to more accurate and comprehensive state observations, leading to fewer low-return instances. In contrast, the estimator within Noisy Perceptive and blind policies encounter more collisions and lower returns, causing their loss to degrade more slowly.

\textbf{We demonstrate that the estimated return threhold $G_{th}$ is crucial to the performance of VB-Com.} Tab \ref{tab:TH} evaluates the system's performance under different values of $\alpha$, as well as without $G_{th}$. The results demonstrate that $G_{th}$ is critical for mitigating miscorrection during motion abnormalities, and that a value of $\alpha < 1.0$ ensures a sensitive response to the states that could lead to motion failures.

\begin{table}[!ht]
\caption{Estimated Return Threhold Evaluations}
\label{tab:TH}
\begin{center}
\renewcommand\arraystretch{1.25}
\begin{tabular}{lcccc}
\toprule[1.0pt]
Method & Goals Completed($\%$) & Collisions & Reach Steps\\
\midrule[0.8pt]
 
$\alpha = 2.0$   & $77.10 \pm 4.71$ & $2.63 \pm 0.68$ & $185.11 \pm 7.17$\\ 
$\alpha = 0.5$   & \bm{$85.76 \pm 2.88$} & $2.29 \pm 0.17$ & $186.96 \pm 3.83$\\  
$\alpha = 0.1$   & $84.43 \pm 1.23$ & \bm{$2.10 \pm 0.25$} & $\bm{184.35 \pm 6.27}$\\  
w/o $G_{th}$     & $48.48 \pm 1.28$ & $6.24 \pm 0.41$ & $261.96 \pm 35.63$\\  

\bottomrule[1.0pt]
\end{tabular}
\end{center}
\end{table}



\subsection{Real-World Experiments}

We deploy the proposed system on both the Unitree G1 and Unitree H1 robots and evaluate the performance of the proposed VB-Com method. 
\begin{figure*}[h]
\centering{\includegraphics[width= \textwidth]{figures/hardwarecurve.png}}
\caption{Illustrations of the variation in estimated return under static/dynamic obstacles in hardware experiments.}
\label{hardwarecurve}
\end{figure*}

\subsubsection{Hardware Return Estimations}

We illustrate how VB-Com operates on real robots by plotting $4$ seconds of the estimated return while the robot avoids static (left) and dynamic (right) obstacles (Fig \ref{hardwarecurve}). The results demonstrate that, for static obstacles (a standing person), the elevation map can accurately perceive the obstacle, allowing the robot to plan motions in advance and avoid collisions. Corresponding to this behavior, we observe that the estimated return on the G1 stays a high value, with $\hat{G}^e_{\pi_b}$ slightly lower than $\hat{G}^e_{\pi_v}$, consistent with the scenario where the vision policy continues to operate within VB-Com.

On the other hand, when a person moves towards the robot at high speed, the perception module fails to detect the obstacle, causing a collision, both $\hat{G}^e_{\pi_b}$ and $\hat{G}^e_{\pi_v}$ decline sharply upon collision. However, VB-Com quickly switches to $\pi_b$ to avoid the person, demonstrating the  \textbf{rapid response to collision provided by the proposed return estimation and the successful obstacle avoidance capability of VB-Com under perceptual deficiency}.


\begin{figure}[h]
\centering{\includegraphics[width=0.5\textwidth]{figures/g1avoid.png}}
\caption{ Real-world comparisons of VB-Com, vision, and blind policies in obstacle avoidance on the G1.}
\label{avoid}
\end{figure}

\subsubsection{Avoid Obstacles}
In this section, we make comparisons between VB-Com along with the vision policy and blind policy on G1 (Fig \ref{avoid}), to demonstrate the superior performance of VB-Com in hardware compared with signle policies. In the evaluation scenario, G1 encounters two consecutive obstacles along its path. The second dynamic obstacle obstructs the robot's direction before the elevation map can perceive it. VB-Com enables the robot to avoid the static obstacle without collision and subsequently avoid the dynamic obstacle after it collides with the suddenly appearing obstacle.

In contrast, for the baseline policies, the blind policy makes unnecessary contact with the static obstacles before avoiding them, which damages the environment. As for the vision policy, the robot collides with the obstacle and is unable to avoid it until the newly added obstacle is detected and integrated into the map.

\begin{figure}[h]
\centering{\includegraphics[width=0.5\textwidth]{figures/hurdlegap.png}}
\caption{Hardware demonstrations on the robots traversing gaps and hurldes given deficient perception with VB-Com.}
\label{hurdlegap}
\end{figure}

\subsubsection{Performance Against Deficient Perception}
In this section, we demonstrate the ability of VB-Com to traverse challenging terrains given deficient perception (Fig. \ref{hurdlegap}). We provide zero inputs for the heightmaps to evaluate the performance of VB-Com under perceptual deficiency. We introduce two consecutive hurdles, and the robot successfully recovers after colliding with them by switching to $\pi_b$. Additionally, we demonstrate that VB-Com enables recovery from a missed step on an unobserved gap. In this case, VB-Com saves the robot by performing a larger forward step to traverse the gap without perception, as the blind policy has learned during simulation.


