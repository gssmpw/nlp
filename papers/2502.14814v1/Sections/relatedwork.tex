\section{Related Work} \label{sec:relatedwork}

\subsection{Robust Perceptive Legged Locomotion}

Typically, perceptive legged locomotion policies encode external state observations from onboard sensors as inputs of the policy network, allowing the robot to plan motions in advance to navigate unstructured terrains and avoid penalties for collisions or imbalance \cite{long2024learning, hoeller2024anymal, he2024agile}. Generally, lidar-based elevation maps \cite{miki2022elevation, hoeller2024anymal} and depth images \cite{cheng2024extreme, agarwal2023legged, yu2024walking, luo2024pie} are widely used to acquire external state observations. However, depth images are significantly affected by lighting conditions and limited field of view, while lidar-based elevation maps require time to construct, restricting their applicability to static environments.

Since comprehensive perception cannot be guaranteed on hardware, later studies have focused on integrating proprioceptive and exteroceptive observations to achieve robust locomotion or navigation against deficient perception \cite{miki2022learning, chen2024identifying, zhang2024resilient, fu2022coupling, ren2024top}. These approaches either employ a belief encoder that integrates exteroceptive and historical proprioceptive observations, or they address deficient perception at the path planning level. However, none of these methods have demonstrated the ability to perform rapid recovery actions in scenarios where deficient perception could quickly lead to failure, such as stepping into an unobserved gap and regaining balance before falling.

In this work, we address the mentioned challenge through policy composition: The blind policy is activated when deficient perception disrupts locomotion. Since both policies share the same state and action space, the proposed method allows the robot to recover from such situations quickly and safely.


\subsection{Hierarchical Reinforcement Learning}
Hierarchical reinforcement learning has been extensively explored in the literature, with the composition of low-level skills emerging as a popular approach for addressing long-horizon or complex tasks \cite{peng2019mcp, gupta2023bootstrapped, bacon2017option}. Among these works, value functions play a crucial role in policy composition \cite{shah2021value, nasiriany2022augmenting, zhang2023policy}, particularly in capturing the affordances of each sub-task. VB-Com draws inspiration from these approaches by training two return estimators, each representing the capabilities of the vision and blind policies, respectively.

In addition, several works in legged locomotion have explored hierarchical structures, such as employing DAgger to distill a set of locomotion skills \cite{zhuang2023robot}. Recent research \cite{he2024agile} also proposed a switching mechanism to achieve high-speed locomotion while avoiding obstacles. However, these frameworks rely heavily on vision observations, making them intolerant to perception outliers. In contrast, VB-Com addresses the novel challenge of maintaining stable locomotion despite deficient perception, with a specific focus on humanoid robots and high-dynamic tasks.