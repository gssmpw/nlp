\section{Conclusion}
\label{sec:conclusion}

We consider the problem of adversarially robust probabilistic inference.
Using the generalized Bayesian inference framework, we propose adversarially robust posteriors.
%Following the strategy of adversarial perturbations in training point estimators,
We show that for exponential family models, closed-form  adversarial NLLs %adversarially perturbed NLLs 
result in posteriors that are robust to adversarial perturbations.
We derive PAC-Bayes generalization bounds for the four cases as summarized in \Cref{tab:overview}.
The $2\times 2$ table corresponds to combinations of the following settings:
$(i)$ standard NLL $\ell$, and adversarial NLL $\ell_{\deltat}$;
$(ii)$ the classical Bayes posterior $q$, and the robust posterior $q_\delta$.
%Our experimental results validate that the derived PAC-Bayesian bounds capture the empirical behavior and demonstrate the adversarial robustness of $q_\delta$. %are also meaningful in practice.
Our experiments validate that the derived PAC-Bayes bounds capture the empirical behavior, and demonstrate that the robust posterior $q_\delta$ consistently improves adversarial robustness.

Our work primarily focuses on Bayesian linear regression, with the exception of \Cref{lm:robust-expfam-loss} which may be of independent interest. 
This result opens the possibility of extending our analysis to other generalized linear models. 
We hope that our notion of adversarially robust posterior
will lead to further results in other machine learning problems, and provide useful analysis
for practical adversarial learning tasks in the real world.