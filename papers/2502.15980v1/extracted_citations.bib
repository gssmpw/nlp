@inproceedings{-dialsql,
    title = "{D}ial{SQL}: Dialogue Based Structured Query Generation",
    author = "Gur, Izzeddin  and
      Yavuz, Semih  and
      Su, Yu  and
      Yan, Xifeng",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P18-1124",
    doi = "10.18653/v1/P18-1124",
    pages = "1339--1349",
    abstract = "The recent advance in deep learning and semantic parsing has significantly improved the translation accuracy of natural language questions to structured queries. However, further improvement of the existing approaches turns out to be quite challenging. Rather than solely relying on algorithmic innovations, in this work, we introduce DialSQL, a dialogue-based structured query generation framework that leverages human intelligence to boost the performance of existing algorithms via user interaction. DialSQL is capable of identifying potential errors in a generated SQL query and asking users for validation via simple multi-choice questions. User feedback is then leveraged to revise the query. We design a generic simulator to bootstrap synthetic training dialogues and evaluate the performance of DialSQL on the WikiSQL dataset. Using SQLNet as a black box query generation tool, DialSQL improves its performance from 61.3{\%} to 69.0{\%} using only 2.4 validation questions per dialogue.",
}

@misc{ARAIDA,
      title={ARAIDA: Analogical Reasoning-Augmented Interactive Data Annotation}, 
      author={Chen Huang and Yiping Jin and Ilija Ilievski and Wenqiang Lei and Jiancheng Lv},
      year={2024},
      eprint={2405.11912},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2405.11912}, 
}

@article{ATHENA,
author = {Saha, Diptikalyan and Floratou, Avrilia and Sankaranarayanan, Karthik and Minhas, Umar Farooq and Mittal, Ashish R. and \"{O}zcan, Fatma},
title = {ATHENA: An Ontology-Driven System for Natural Language Querying over Relational Data Stores},
year = {2016},
issue_date = {August 2016},
publisher = {VLDB Endowment},
volume = {9},
number = {12},
issn = {2150-8097},
url = {https://doi.org/10.14778/2994509.2994536},
doi = {10.14778/2994509.2994536},
abstract = {In this paper, we present ATHENA, an ontology-driven system for natural language querying of complex relational databases. Natural language interfaces to databases enable users easy access to data, without the need to learn a complex query language, such as SQL. ATHENA uses domain specific ontologies, which describe the semantic entities, and their relationships in a domain. We propose a unique two-stage approach, where the input natural language query (NLQ) is first translated into an intermediate query language over the ontology, called OQL, and subsequently translated into SQL. Our two-stage approach allows us to decouple the physical layout of the data in the relational store from the semantics of the query, providing physical independence. Moreover, ontologies provide richer semantic information, such as inheritance and membership relations, that are lost in a relational schema. By reasoning over the ontologies, our NLQ engine is able to accurately capture the user intent. We study the effectiveness of our approach using three different workloads on top of geographical (GEO), academic (MAS) and financial (FIN) data. ATHENA achieves 100% precision on the GEO and MAS workloads, and 99% precision on the FIN workload which operates on a complex financial ontology. Moreover, ATHENA attains 87.2%, 88.3%, and 88.9% recall on the GEO, MAS, and FIN workloads, respectively.},
journal = {Proc. VLDB Endow.},
month = {aug},
pages = {1209–1220},
numpages = {12}
}

@inproceedings{Generation-NL-Explanations,
author = {Costa, Felipe and Ouyang, Sixun and Dolog, Peter and Lawlor, Aonghus},
title = {Automatic Generation of Natural Language Explanations},
year = {2018},
isbn = {9781450355711},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3180308.3180366},
doi = {10.1145/3180308.3180366},
abstract = {An interesting challenge for explainable recommender systems is to provide successful interpretation of recommendations using structured sentences. It is well known that user-generated reviews, have strong influence on the users' decision. Recent techniques exploit user reviews to generate natural language explanations. In this paper, we propose a character-level attention-enhanced long short-term memory model to generate natural language explanations. We empirically evaluated this network using two real-world review datasets. The generated text present readable and similar to a real user's writing, due to the ability of reproducing negation, misspellings, and domain-specific vocabulary.},
booktitle = {Proceedings of the 23rd International Conference on Intelligent User Interfaces Companion},
articleno = {57},
numpages = {2},
keywords = {Explainability, Neural Network, Recommender systems, Natural Language Generation, Explanations},
location = {Tokyo, Japan},
series = {IUI '18 Companion}
}

@inproceedings{INCEpTION,
    title = "The {INCE}p{TION} Platform: Machine-Assisted and Knowledge-Oriented Interactive Annotation",
    author = "Klie, Jan-Christoph  and
      Bugert, Michael  and
      Boullosa, Beto  and
      Eckart de Castilho, Richard  and
      Gurevych, Iryna",
    editor = "Zhao, Dongyan",
    booktitle = "Proceedings of the 27th International Conference on Computational Linguistics: System Demonstrations",
    month = aug,
    year = "2018",
    address = "Santa Fe, New Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/C18-2002",
    pages = "5--9",
    abstract = "We introduce INCEpTION, a new annotation platform for tasks including interactive and semantic annotation (e.g., concept linking, fact linking, knowledge base population, semantic frame annotation). These tasks are very time consuming and demanding for annotators, especially when knowledge bases are used. We address these issues by developing an annotation platform that incorporates machine learning capabilities which actively assist and guide annotators. The platform is both generic and modular. It targets a range of research domains in need of semantic annotation, such as digital humanities, bioinformatics, or linguistics. INCEpTION is publicly available as open-source software.",
}

@inproceedings{INCEpTION2,
    title = "The {INCE}p{TION} Platform: Machine-Assisted and Knowledge-Oriented Interactive Annotation",
    author = "Klie, Jan-Christoph  and
      Bugert, Michael  and
      Boullosa, Beto  and
      Eckart de Castilho, Richard  and
      Gurevych, Iryna",
    editor = "Zhao, Dongyan",
    booktitle = "Proceedings of the 27th International Conference on Computational Linguistics: System Demonstrations",
    month = aug,
    year = "2018",
    address = "Santa Fe, New Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/C18-2002",
    pages = "5--9",
    abstract = "We introduce INCEpTION, a new annotation platform for tasks including interactive and semantic annotation (e.g., concept linking, fact linking, knowledge base population, semantic frame annotation). These tasks are very time consuming and demanding for annotators, especially when knowledge bases are used. We address these issues by developing an annotation platform that incorporates machine learning capabilities which actively assist and guide annotators. The platform is both generic and modular. It targets a range of research domains in need of semantic annotation, such as digital humanities, bioinformatics, or linguistics. INCEpTION is publicly available as open-source software.",
}

@misc{IRnet,
      title={IRNet: Iterative Refinement Network for Noisy Partial Label Learning}, 
      author={Zheng Lian and Mingyu Xu and Lan Chen and Licai Sun and Bin Liu and Jianhua Tao},
      year={2023},
      eprint={2211.04774},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2211.04774}, 
}

@misc{NSText2SQL,
  author = {{Numbers Station Labs}},
  title = {NSText2SQL: An Open Source Text-to-SQL Dataset for Foundation Model Training},
  year = {2023},
  month = jul,
  howpublished = {\url{https://github.com/NumbersStationAI/NSQL}}
}

@inproceedings{NaLIR,
author = {Li, Fei and Jagadish, Hosagrahar V},
title = {NaLIR: An Interactive Natural Language Interface for Querying Relational Databases},
year = {2014},
isbn = {9781450323765},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2588555.2594519},
doi = {10.1145/2588555.2594519},
abstract = {In this demo, we present NaLIR, a generic interactive natural language interface for querying relational databases. NaLIR can accept a logically complex English language sentence as query input. This query is first translated into a SQL query, which may include aggregation, nesting, and various types of joins, among other things, and then evaluated against an RDBMS. In this demonstration, we show that NaLIR, while far from being able to pass the Turing test, is perfectly usable in practice, and able to handle even quite complex queries in a variety of application domains. In addition, we also demonstrate how carefully designed interactive communication can avoid misinterpretation with minimum user burden.},
booktitle = {Proceedings of the 2014 ACM SIGMOD International Conference on Management of Data},
pages = {709–712},
numpages = {4},
keywords = {usability, natural language interface, relational database},
location = {Snowbird, Utah, USA},
series = {SIGMOD '14}
}

@inproceedings{PCFG_SQL_synthesize,
    title = "Learning to Synthesize Data for Semantic Parsing",
    author = "Wang, Bailin  and
      Yin, Wenpeng  and
      Lin, Xi Victoria  and
      Xiong, Caiming",
    editor = "Toutanova, Kristina  and
      Rumshisky, Anna  and
      Zettlemoyer, Luke  and
      Hakkani-Tur, Dilek  and
      Beltagy, Iz  and
      Bethard, Steven  and
      Cotterell, Ryan  and
      Chakraborty, Tanmoy  and
      Zhou, Yichao",
    booktitle = "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.naacl-main.220",
    doi = "10.18653/v1/2021.naacl-main.220",
    pages = "2760--2766",
    abstract = "Synthesizing data for semantic parsing has gained increasing attention recently. However, most methods require handcrafted (high-precision) rules in their generative process, hindering the exploration of diverse unseen data. In this work, we propose a generative model which features a (non-neural) PCFG that models the composition of programs (e.g., SQL), and a BART-based translation model that maps a program to an utterance. Due to the simplicity of PCFG and pre-trained BART, our generative model can be efficiently learned from existing data at hand. Moreover, explicitly modeling compositions using PCFG leads to better exploration of unseen programs, thus generate more diverse data. We evaluate our method in both in-domain and out-of-domain settings of text-to-SQL parsing on the standard benchmarks of GeoQuery and Spider, respectively. Our empirical results show that the synthesized data generated from our model can substantially help a semantic parser achieve better compositional and domain generalization.",
}

@inproceedings{Rationalization,
author = {Ehsan, Upol and Harrison, Brent and Chan, Larry and Riedl, Mark O.},
title = {Rationalization: A Neural Machine Translation Approach to Generating Natural Language Explanations},
year = {2018},
isbn = {9781450360128},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3278721.3278736},
doi = {10.1145/3278721.3278736},
abstract = {We introduce em AI rationalization, an approach for generating explanations of autonomous system behavior as if a human had performed the behavior. We describe a rationalization technique that uses neural machine translation to translate internal state-action representations of an autonomous agent into natural language. We evaluate our technique in the Frogger game environment, training an autonomous game playing agent to rationalize its action choices using natural language. A natural language training corpus is collected from human players thinking out loud as they play the game. We motivate the use of rationalization as an approach to explanation generation and show the results of two experiments evaluating the effectiveness of rationalization. Results of these evaluations show that neural machine translation is able to accurately generate rationalizations that describe agent behavior, and that rationalizations are more satisfying to humans than other alternative methods of explanation.},
booktitle = {Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society},
pages = {81–87},
numpages = {7},
keywords = {artificial intelligence, user perception, ai rationalization, transparency, machine learning, interpretability, explainable ai},
location = {New Orleans, LA, USA},
series = {AIES '18}
}

@inproceedings{SQL-to-text,
    title = "{SQL}-to-Text Generation with Graph-to-Sequence Model",
    author = "Xu, Kun  and
      Wu, Lingfei  and
      Wang, Zhiguo  and
      Feng, Yansong  and
      Sheinin, Vadim",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D18-1112",
    doi = "10.18653/v1/D18-1112",
    pages = "931--936",
    abstract = "Previous work approaches the SQL-to-text generation task using vanilla Seq2Seq models, which may not fully capture the inherent graph-structured information in SQL query. In this paper, we propose a graph-to-sequence model to encode the global structure information into node embeddings. This model can effectively learn the correlation between the SQL query pattern and its interpretation. Experimental results on the WikiSQL dataset and Stackoverflow dataset show that our model outperforms the Seq2Seq and Tree2Seq baselines, achieving the state-of-the-art performance.",
}

@article{SQLizer,
author = {Yaghmazadeh, Navid and Wang, Yuepeng and Dillig, Isil and Dillig, Thomas},
title = {SQLizer: Query Synthesis from Natural Language},
year = {2017},
issue_date = {October 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {OOPSLA},
url = {https://doi.org/10.1145/3133887},
doi = {10.1145/3133887},
abstract = {This paper presents a new technique for automatically synthesizing SQL queries from natural language (NL). At the core of our technique is a new NL-based program synthesis methodology that combines semantic parsing techniques from the NLP community with type-directed program synthesis and automated program repair. Starting with a program sketch obtained using standard parsing techniques, our approach involves an iterative refinement loop that alternates between probabilistic type inhabitation and automated sketch repair. We use the proposed idea to build an end-to-end system called SQLIZER that can synthesize SQL queries from natural language. Our method is fully automated, works for any database without requiring additional customization, and does not require users to know the underlying database schema. We evaluate our approach on over 450 natural language queries concerning three different databases, namely MAS, IMDB, and YELP. Our experiments show that the desired query is ranked within the top 5 candidates in close to 90% of the cases and that SQLIZER outperforms NALIR, a state-of-the-art tool that won a best paper award at VLDB'14.},
journal = {Proc. ACM Program. Lang.},
month = {oct},
articleno = {63},
numpages = {26},
keywords = {Program Synthesis, Programming by Natural Languages, Relational Databases}
}

@misc{STEPS,
      title={Interactive Text-to-SQL Generation via Editable Step-by-Step Explanations}, 
      author={Yuan Tian and Zheng Zhang and Zheng Ning and Toby Jia-Jun Li and Jonathan K. Kummerfeld and Tianyi Zhang},
      year={2024},
      eprint={2305.07372},
      archivePrefix={arXiv},
      primaryClass={cs.DB},
      url={https://arxiv.org/abs/2305.07372}, 
}

@inproceedings{Semantic-Tractability,
    title = "Modern Natural Language Interfaces to Databases: Composing Statistical Parsing with Semantic Tractability",
    author = "Popescu, Ana-Maria  and
      Armanasu, Alex  and
      Etzioni, Oren  and
      Ko, David  and
      Yates, Alexander",
    booktitle = "{COLING} 2004: Proceedings of the 20th International Conference on Computational Linguistics",
    month = "aug 23{--}aug 27",
    year = "2004",
    address = "Geneva, Switzerland",
    publisher = "COLING",
    url = "https://aclanthology.org/C04-1021",
    pages = "141--147",
}

@article{XAI,
  author    = {Wojciech Samek and
               Thomas Wiegand and
               Klaus{-}Robert M{\"{u}}ller},
  title     = {Explainable Artificial Intelligence: Understanding, Visualizing and
               Interpreting Deep Learning Models},
  journal   = {CoRR},
  volume    = {abs/1708.08296},
  year      = {2017},
  url       = {http://arxiv.org/abs/1708.08296},
  eprinttype = {arXiv},
  eprint    = {1708.08296},
  timestamp = {Mon, 13 Aug 2018 16:48:36 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1708-08296.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{academic,
author = {Li, Fei and Jagadish, H. V.},
title = {Constructing an interactive natural language interface for relational databases},
year = {2014},
issue_date = {September 2014},
publisher = {VLDB Endowment},
volume = {8},
number = {1},
issn = {2150-8097},
url = {https://doi.org/10.14778/2735461.2735468},
doi = {10.14778/2735461.2735468},
abstract = {Natural language has been the holy grail of query interface designers, but has generally been considered too hard to work with, except in limited specific circumstances. In this paper, we describe the architecture of an interactive natural language query interface for relational databases. Through a carefully limited interaction with the user, we are able to correctly interpret complex natural language queries, in a generic manner across a range of domains. By these means, a logically complex English language sentence is correctly translated into a SQL query, which may include aggregation, nesting, and various types of joins, among other things, and can be evaluated against an RDBMS. We have constructed a system, NaLIR (Natural Language Interface for Relational databases), embodying these ideas. Our experimental assessment, through user studies, demonstrates that NaLIR is good enough to be usable in practice: even naive users are able to specify quite complex ad-hoc queries.},
journal = {Proc. VLDB Endow.},
month = {sep},
pages = {73–84},
numpages = {12}
}

@inproceedings{active_learning1,
    title = "Reduce Human Labor On Evaluating Conversational Information Retrieval System: A Human-Machine Collaboration Approach",
    author = "Huang, Chen  and
      Qin, Peixin  and
      Lei, Wenqiang  and
      Lv, Jiancheng",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.670",
    doi = "10.18653/v1/2023.emnlp-main.670",
    pages = "10876--10891",
    abstract = "Evaluating conversational information retrieval (CIR) systems is a challenging task that requires a significant amount of human labor for annotation. It is imperative to invest significant effort into researching more labor-effective methods for evaluating CIR systems. To touch upon this challenge, we take the first step to involve active testing in CIR evaluation and propose a novel method, called HomCoE. It strategically selects a few data for human annotation, then calibrates the evaluation results to eliminate evaluation biases. As such, it makes an accurate evaluation of the CIR system at low human labor. We experimentally reveal that it consumes less than 1{\%} of human labor and achieves a consistency rate of 95{\%}-99{\%} with human evaluation results. This emphasizes the superiority of our method over other baselines.",
}

@misc{active_learning2,
      title={Reinforced active learning for image segmentation}, 
      author={Arantxa Casanova and Pedro O. Pinheiro and Negar Rostamzadeh and Christopher J. Pal},
      year={2020},
      eprint={2002.06583},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2002.06583}, 
}

@inproceedings{active_learning3,
    title = "Active Learning with {A}mazon {M}echanical {T}urk",
    author = {Laws, Florian  and
      Scheible, Christian  and
      Sch{\"u}tze, Hinrich},
    editor = "Barzilay, Regina  and
      Johnson, Mark",
    booktitle = "Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing",
    month = jul,
    year = "2011",
    address = "Edinburgh, Scotland, UK.",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D11-1143",
    pages = "1546--1556",
}

@inproceedings{advising,
    title = "Improving Text-to-{SQL} Evaluation Methodology",
    author = "Finegan-Dollak, Catherine  and
      Kummerfeld, Jonathan K.  and
      Zhang, Li  and
      Ramanathan, Karthik  and
      Sadasivam, Sesh  and
      Zhang, Rui  and
      Radev, Dragomir",
    editor = "Gurevych, Iryna  and
      Miyao, Yusuke",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P18-1033",
    doi = "10.18653/v1/P18-1033",
    pages = "351--360",
    abstract = "To be informative, an evaluation must measure how well systems generalize to realistic unseen data. We identify limitations of and propose improvements to current evaluations of text-to-SQL systems. First, we compare human-generated and automatically generated questions, characterizing properties of queries necessary for real-world applications. To facilitate evaluation on multiple datasets, we release standardized and improved versions of seven existing datasets and one new text-to-SQL dataset. Second, we show that the current division of data into training and test sets measures robustness to variations in the way questions are asked, but only partially tests how well systems generalize to new queries; therefore, we propose a complementary dataset split for evaluation of future work. Finally, we demonstrate how the common practice of anonymizing variables during evaluation removes an important challenge of the task. Our observations highlight key difficulties, and our methodology enables effective measurement of future development.",
}

@inproceedings{annollm,
    title = "{A}nno{LLM}: Making Large Language Models to Be Better Crowdsourced Annotators",
    author = "He, Xingwei  and
      Lin, Zhenghao  and
      Gong, Yeyun  and
      Jin, A-Long  and
      Zhang, Hang  and
      Lin, Chen  and
      Jiao, Jian  and
      Yiu, Siu Ming  and
      Duan, Nan  and
      Chen, Weizhu",
    editor = "Yang, Yi  and
      Davani, Aida  and
      Sil, Avi  and
      Kumar, Anoop",
    booktitle = "Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 6: Industry Track)",
    month = jun,
    year = "2024",
    address = "Mexico City, Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.naacl-industry.15",
    doi = "10.18653/v1/2024.naacl-industry.15",
    pages = "165--190",
    abstract = "Many natural language processing (NLP) tasks rely on labeled data to train machine learning models with high performance. However, data annotation is time-consuming and expensive, especially when the task involves a large amount of data or requires specialized domains. Recently, GPT-3.5 series models have demonstrated remarkable few-shot and zero-shot ability across various NLP tasks. In this paper, we first claim that large language models (LLMs), such as GPT-3.5, can serve as an excellent crowdsourced annotator when provided with sufficient guidance and demonstrated examples. Accordingly, we propose AnnoLLM, an annotation system powered by LLMs, which adopts a two-step approach, explain-then-annotate. Concretely, we first prompt LLMs to provide explanations for why the specific ground truth answer/label was assigned for a given example. Then, we construct the few-shot chain-of-thought prompt with the self-generated explanation and employ it to annotate the unlabeled data with LLMs. Our experiment results on three tasks, including user input and keyword relevance assessment, BoolQ, and WiC, demonstrate that AnnoLLM surpasses or performs on par with crowdsourced annotators. Furthermore, we build the first conversation-based information retrieval dataset employing AnnoLLM. This dataset is designed to facilitate the development of retrieval models capable of retrieving pertinent documents for conversational text. Human evaluation has validated the dataset{'}s high quality.",
}

@inproceedings{atis,
    title = "The {ATIS} Spoken Language Systems Pilot Corpus",
    author = "Hemphill, Charles T.  and
      Godfrey, John J.  and
      Doddington, George R.",
    booktitle = "Speech and Natural Language: Proceedings of a Workshop Held at Hidden Valley, {P}ennsylvania, June 24-27,1990",
    year = "1990",
    url = "https://aclanthology.org/H90-1021",
}

@inproceedings{attribution-for-DNN,
author = {Sundararajan, Mukund and Taly, Ankur and Yan, Qiqi},
title = {Axiomatic Attribution for Deep Networks},
year = {2017},
publisher = {JMLR.org},
abstract = {We study the problem of attributing the prediction of a deep network to its input features, a problem previously studied by several other works. We identify two fundamental axioms— Sensitivity and Implementation Invariance that attribution methods ought to satisfy. We show that they are not satisfied by most known attribution methods, which we consider to be a fundamental weakness of those methods. We use the axioms to guide the design of a new attribution method called Integrated Gradients. Our method requires no modification to the original network and is extremely simple to implement; it just needs a few calls to the standard gradient operator. We apply this method to a couple of image models, a couple of text models and a chemistry model, demonstrating its ability to debug networks, to extract rules from a network, and to enable users to engage with models better.},
booktitle = {Proceedings of the 34th International Conference on Machine Learning - Volume 70},
pages = {3319–3328},
numpages = {10},
location = {Sydney, NSW, Australia},
series = {ICML'17}
}

@inproceedings{bansal2021does,
  title={Does the whole exceed its parts? the effect of ai explanations on complementary team performance},
  author={Bansal, Gagan and Wu, Tongshuang and Zhou, Joyce and Fok, Raymond and Nushi, Besmira and Kamar, Ece and Ribeiro, Marco Tulio and Weld, Daniel},
  booktitle={Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
  pages={1--16},
  year={2021}
}

@inproceedings{bart,
    title = "{BART}: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension",
    author = "Lewis, Mike  and
      Liu, Yinhan  and
      Goyal, Naman  and
      Ghazvininejad, Marjan  and
      Mohamed, Abdelrahman  and
      Levy, Omer  and
      Stoyanov, Veselin  and
      Zettlemoyer, Luke",
    editor = "Jurafsky, Dan  and
      Chai, Joyce  and
      Schluter, Natalie  and
      Tetreault, Joel",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.703",
    doi = "10.18653/v1/2020.acl-main.703",
    pages = "7871--7880",
    abstract = "We present BART, a denoising autoencoder for pretraining sequence-to-sequence models. BART is trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text. It uses a standard Tranformer-based neural machine translation architecture which, despite its simplicity, can be seen as generalizing BERT (due to the bidirectional encoder), GPT (with the left-to-right decoder), and other recent pretraining schemes. We evaluate a number of noising approaches, finding the best performance by both randomly shuffling the order of sentences and using a novel in-filling scheme, where spans of text are replaced with a single mask token. BART is particularly effective when fine tuned for text generation but also works well for comprehension tasks. It matches the performance of RoBERTa on GLUE and SQuAD, and achieves new state-of-the-art results on a range of abstractive dialogue, question answering, and summarization tasks, with gains of up to 3.5 ROUGE. BART also provides a 1.1 BLEU increase over a back-translation system for machine translation, with only target language pretraining. We also replicate other pretraining schemes within the BART framework, to understand their effect on end-task performance.",
}

@misc{bird,
      title={Can LLM Already Serve as A Database Interface? A BIg Bench for Large-Scale Database Grounded Text-to-SQLs}, 
      author={Jinyang Li and Binyuan Hui and Ge Qu and Jiaxi Yang and Binhua Li and Bowen Li and Bailin Wang and Bowen Qin and Rongyu Cao and Ruiying Geng and Nan Huo and Xuanhe Zhou and Chenhao Ma and Guoliang Li and Kevin C. C. Chang and Fei Huang and Reynold Cheng and Yongbin Li},
      year={2023},
      eprint={2305.03111},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2305.03111}, 
}

@article{blackbox,
  doi = {10.48550/ARXIV.1811.10154},
  
  url = {https://arxiv.org/abs/1811.10154},
  
  author = {Rudin, Cynthia},
  
  keywords = {Machine Learning (stat.ML), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Stop Explaining Black Box Machine Learning Models for High Stakes Decisions and Use Interpretable Models Instead},
  
  publisher = {arXiv},
  
  year = {2018},
  
  copyright = {Creative Commons Attribution Share Alike 4.0 International}
}

@article{chatgpt_outperform_crowd_workers,
   title={ChatGPT outperforms crowd workers for text-annotation tasks},
   volume={120},
   ISSN={1091-6490},
   url={http://dx.doi.org/10.1073/pnas.2305016120},
   DOI={10.1073/pnas.2305016120},
   number={30},
   journal={Proceedings of the National Academy of Sciences},
   publisher={Proceedings of the National Academy of Sciences},
   author={Gilardi, Fabrizio and Alizadeh, Meysam and Kubli, Maël},
   year={2023},
   month=jul }

@misc{codes,
      title={CodeS: Towards Building Open-source Language Models for Text-to-SQL}, 
      author={Haoyang Li and Jing Zhang and Hanbing Liu and Ju Fan and Xiaokang Zhang and Jun Zhu and Renjie Wei and Hongyan Pan and Cuiping Li and Hong Chen},
      year={2024},
      eprint={2402.16347},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.16347}, 
}

@article{collapse,
  title={AI models collapse when trained on recursively generated data},
  author={Shumailov, Ilia and Shumaylov, Zakhar and Zhao, Yiren and Papernot, Nicolas and Anderson, Ross and Gal, Yarin},
  journal={Nature},
  volume={631},
  number={8022},
  pages={755--759},
  year={2024},
  publisher={Nature Publishing Group UK London}
}

@article{conda,
  title={ConDA: state-based data augmentation for context-dependent text-to-SQL},
  author={Wang, Dingzirui and Dou, Longxu and Che, Wanxiang and Wang, Jiaqi and Liu, Jinbo and Li, Lixin and Shang, Jingan and Tao, Lei and Zhang, Jie and Fu, Cong and others},
  journal={International Journal of Machine Learning and Cybernetics},
  pages={1--12},
  year={2024},
  publisher={Springer}
}

@article{construct_interface,
author = {Li, Fei and Jagadish, H. V.},
title = {Constructing an Interactive Natural Language Interface for Relational Databases},
year = {2014},
issue_date = {September 2014},
publisher = {VLDB Endowment},
volume = {8},
number = {1},
issn = {2150-8097},
url = {https://doi.org/10.14778/2735461.2735468},
doi = {10.14778/2735461.2735468},
abstract = {Natural language has been the holy grail of query interface designers, but has generally been considered too hard to work with, except in limited specific circumstances. In this paper, we describe the architecture of an interactive natural language query interface for relational databases. Through a carefully limited interaction with the user, we are able to correctly interpret complex natural language queries, in a generic manner across a range of domains. By these means, a logically complex English language sentence is correctly translated into a SQL query, which may include aggregation, nesting, and various types of joins, among other things, and can be evaluated against an RDBMS. We have constructed a system, NaLIR (Natural Language Interface for Relational databases), embodying these ideas. Our experimental assessment, through user studies, demonstrates that NaLIR is good enough to be usable in practice: even naive users are able to specify quite complex ad-hoc queries.},
journal = {Proc. VLDB Endow.},
month = {sep},
pages = {73–84},
numpages = {12}
}

@inproceedings{cosql,
    title = "{C}o{SQL}: A Conversational Text-to-{SQL} Challenge Towards Cross-Domain Natural Language Interfaces to Databases",
    author = "Yu, Tao  and
      Zhang, Rui  and
      Er, Heyang  and
      Li, Suyi  and
      Xue, Eric  and
      Pang, Bo  and
      Lin, Xi Victoria  and
      Tan, Yi Chern  and
      Shi, Tianze  and
      Li, Zihan  and
      Jiang, Youxuan  and
      Yasunaga, Michihiro  and
      Shim, Sungrok  and
      Chen, Tao  and
      Fabbri, Alexander  and
      Li, Zifan  and
      Chen, Luyao  and
      Zhang, Yuwen  and
      Dixit, Shreya  and
      Zhang, Vincent  and
      Xiong, Caiming  and
      Socher, Richard  and
      Lasecki, Walter  and
      Radev, Dragomir",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-1204",
    doi = "10.18653/v1/D19-1204",
    pages = "1962--1979",
    abstract = "We present CoSQL, a corpus for building cross-domain, general-purpose database (DB) querying dialogue systems. It consists of 30k+ turns plus 10k+ annotated SQL queries, obtained from a Wizard-of-Oz (WOZ) collection of 3k dialogues querying 200 complex DBs spanning 138 domains. Each dialogue simulates a real-world DB query scenario with a crowd worker as a user exploring the DB and a SQL expert retrieving answers with SQL, clarifying ambiguous questions, or otherwise informing of unanswerable questions. When user questions are answerable by SQL, the expert describes the SQL and execution results to the user, hence maintaining a natural interaction flow. CoSQL introduces new challenges compared to existing task-oriented dialogue datasets: (1) the dialogue states are grounded in SQL, a domain-independent executable representation, instead of domain-specific slot value pairs, and (2) because testing is done on unseen databases, success requires generalizing to new domains. CoSQL includes three tasks: SQL-grounded dialogue state tracking, response generation from query results, and user dialogue act prediction. We evaluate a set of strong baselines for each task and show that CoSQL presents significant challenges for future research. The dataset, baselines, and leaderboard will be released at https://yale-lily.github.io/cosql.",
}

@misc{dailsql,
      title={Text-to-SQL Empowered by Large Language Models: A Benchmark Evaluation}, 
      author={Dawei Gao and Haibin Wang and Yaliang Li and Xiuyu Sun and Yichen Qian and Bolin Ding and Jingren Zhou},
      year={2023},
      eprint={2308.15363},
      archivePrefix={arXiv},
      primaryClass={cs.DB},
      url={https://arxiv.org/abs/2308.15363}, 
}

@inproceedings{dbtalkback,
  doi = {10.48550/ARXIV.0909.1786},
  
  url = {https://arxiv.org/abs/0909.1786},
  
  author = {Simitsis, Alkis and Ioannidis, Yannis},
  
  keywords = {Databases (cs.DB), Human-Computer Interaction (cs.HC), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {DBMSs Should Talk Back Too},

  booktitle = {10.48550/ARXIV.0909.1786},

  publisher = {arXiv},
  
  year = {2009},
  
  copyright = {Creative Commons Attribution 3.0 Unported}
}

@misc{distillery,
      title={The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models}, 
      author={Karime Maamari and Fadhil Abubaker and Daniel Jaroslawicz and Amine Mhedhbi},
      year={2024},
      eprint={2408.07702},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2408.07702}, 
}

@misc{diverse_beam_search,
      title={Diverse Beam Search: Decoding Diverse Solutions from Neural Sequence Models}, 
      author={Ashwin K Vijayakumar and Michael Cogswell and Ramprasath R. Selvaraju and Qing Sun and Stefan Lee and David Crandall and Dhruv Batra},
      year={2018},
      eprint={1610.02424},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/1610.02424}, 
}

@inproceedings{diy,
author = {Narechania, Arpit and Fourney, Adam and Lee, Bongshin and Ramos, Gonzalo},
title = {DIY: Assessing the Correctness of Natural Language to SQL Systems},
year = {2021},
isbn = {9781450380171},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3397481.3450667},
doi = {10.1145/3397481.3450667},
abstract = {Designing natural language interfaces for querying databases remains an important goal pursued by researchers in natural language processing, databases, and HCI. These systems receive natural language as input, translate it into a formal database query, and execute the query to compute a result. Because the responses from these systems are not always correct, it is important to provide people with mechanisms to assess the correctness of the generated query and computed result. However, this assessment can be challenging for people who lack expertise in query languages. We present Debug-It-Yourself (DIY), an interactive technique that enables users to assess the responses from a state-of-the-art natural language to SQL (NL2SQL) system for correctness and, if possible, fix errors. DIY provides users with a sandbox where they can interact with (1) the mappings between the question and the generated query, (2) a small-but-relevant subset of the underlying database, and (3) a multi-modal explanation of the generated query. End-users can then employ a back-of-the-envelope calculation debugging strategy to evaluate the system’s response. Through an exploratory study with 12 users, we investigate how DIY helps users assess the correctness of the system’s answers and detect &amp; fix errors. Our observations reveal the benefits of DIY while providing insights about end-user debugging strategies and underscore opportunities for further improving the user experience.},
booktitle = {26th International Conference on Intelligent User Interfaces},
pages = {597–607},
numpages = {11},
keywords = {human computer interaction, natural language interface, database systems},
location = {College Station, TX, USA},
series = {IUI '21}
}

@inproceedings{dusql,
    title = "{D}u{SQL}: A Large-Scale and Pragmatic {C}hinese Text-to-{SQL} Dataset",
    author = "Wang, Lijie  and
      Zhang, Ao  and
      Wu, Kun  and
      Sun, Ke  and
      Li, Zhenghua  and
      Wu, Hua  and
      Zhang, Min  and
      Wang, Haifeng",
    editor = "Webber, Bonnie  and
      Cohn, Trevor  and
      He, Yulan  and
      Liu, Yang",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.562",
    doi = "10.18653/v1/2020.emnlp-main.562",
    pages = "6923--6935",
    abstract = "Due to the lack of labeled data, previous research on text-to-SQL parsing mainly focuses on English. Representative English datasets include ATIS, WikiSQL, Spider, etc. This paper presents DuSQL, a larges-scale and pragmatic Chinese dataset for the cross-domain text-to-SQL task, containing 200 databases, 813 tables, and 23,797 question/SQL pairs. Our new dataset has three major characteristics. First, by manually analyzing questions from several representative applications, we try to figure out the true distribution of SQL queries in real-life needs. Second, DuSQL contains a considerable proportion of SQL queries involving row or column calculations, motivated by our analysis on the SQL query distributions. Finally, we adopt an effective data construction framework via human-computer collaboration. The basic idea is automatically generating SQL queries based on the SQL grammar and constrained by the given database. This paper describes in detail the construction process and data statistics of DuSQL. Moreover, we present and compare performance of several open-source text-to-SQL parsers with minor modification to accommodate Chinese, including a simple yet effective extension to IRNet for handling calculation SQL queries.",
}

@inproceedings{editsql,
    title = "Editing-Based {SQL} Query Generation for Cross-Domain Context-Dependent Questions",
    author = "Zhang, Rui  and
      Yu, Tao  and
      Er, Heyang  and
      Shim, Sungrok  and
      Xue, Eric  and
      Lin, Xi Victoria  and
      Shi, Tianze  and
      Xiong, Caiming  and
      Socher, Richard  and
      Radev, Dragomir",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-1537",
    doi = "10.18653/v1/D19-1537",
    pages = "5338--5349",
    abstract = "We focus on the cross-domain context-dependent text-to-SQL generation task. Based on the observation that adjacent natural language questions are often linguistically dependent and their corresponding SQL queries tend to overlap, we utilize the interaction history by editing the previous predicted query to improve the generation quality. Our editing mechanism views SQL as sequences and reuses generation results at the token level in a simple manner. It is flexible to change individual tokens and robust to error propagation. Furthermore, to deal with complex table structures in different domains, we employ an utterance-table encoder and a table-aware decoder to incorporate the context of the user utterance and the table schema. We evaluate our approach on the SParC dataset and demonstrate the benefit of editing compared with the state-of-the-art baselines which generate SQL from scratch. Our code is available at \url{https://github.com/ryanzhumich/sparc_atis_pytorch}.",
}

@inproceedings{eiband2019people,
  title={When people and algorithms meet: User-reported problems in intelligent everyday applications},
  author={Eiband, Malin and V{\"o}lkel, Sarah Theres and Buschek, Daniel and Cook, Sophia and Hussmann, Heinrich},
  booktitle={Proceedings of the 24th international conference on intelligent user interfaces},
  pages={96--106},
  year={2019}
}

@misc{evol_instruct,
      title={WizardLM: Empowering Large Language Models to Follow Complex Instructions}, 
      author={Can Xu and Qingfeng Sun and Kai Zheng and Xiubo Geng and Pu Zhao and Jiazhan Feng and Chongyang Tao and Daxin Jiang},
      year={2023},
      eprint={2304.12244},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2304.12244}, 
}

@INPROCEEDINGS{explaininnl,  author={Koutrika, Georgia and Simitsis, Alkis and Ioannidis, Yannis E.},  booktitle={2010 IEEE 26th International Conference on Data Engineering (ICDE 2010)},   title={Explaining structured queries in natural language},   year={2010},  volume={},  number={},  pages={333-344},  doi={10.1109/ICDE.2010.5447824}}

@misc{finetune_sql_llm,
      title={Fine-Tuning Language Models for Context-Specific SQL Query Generation}, 
      author={Amine Rebei},
      year={2023},
      eprint={2312.02251},
      archivePrefix={arXiv},
      primaryClass={cs.DB},
      url={https://arxiv.org/abs/2312.02251}, 
}

@inproceedings{fitannotator,
    title = "{FITA}nnotator: A Flexible and Intelligent Text Annotation System",
    author = "Li, Yanzeng  and
      Yu, Bowen  and
      Quangang, Li  and
      Liu, Tingwen",
    editor = "Sil, Avi  and
      Lin, Xi Victoria",
    booktitle = "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Demonstrations",
    month = jun,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.naacl-demos.5",
    doi = "10.18653/v1/2021.naacl-demos.5",
    pages = "35--41",
    abstract = "In this paper, we introduce FITAnnotator, a generic web-based tool for efficient text annotation. Benefiting from the fully modular architecture design, FITAnnotator provides a systematic solution for the annotation of a variety of natural language processing tasks, including classification, sequence tagging and semantic role annotation, regardless of the language. Three kinds of interfaces are developed to annotate instances, evaluate annotation quality and manage the annotation task for annotators, reviewers and managers, respectively. FITAnnotator also gives intelligent annotations by introducing task-specific assistant to support and guide the annotators based on active learning and incremental learning strategies. This assistant is able to effectively update from the annotator feedbacks and easily handle the incremental labeling scenarios.",
}

@inproceedings{flashPog,
author = {Mayer, Mikaël and Soares, Gustavo and Grechkin, Maxim and Le, Vu and Marron, Mark and Polozov, Alex and Singh, Rishabh and Zorn, Ben and Gulwani, Sumit},
title = {User Interaction Models for Disambiguation in Programming by Example},
booktitle = {28th ACM User Interface Software and Technology Symposium (UIST 2015)},
year = {2015},
month = {November},
abstract = {Programming by Examples (PBE) has the potential to revolutionize end-user programming by enabling end users, most of whom are non-programmers, to create small scripts for automating repetitive tasks. However, examples, though often easy to provide, are an ambiguous specification of the user’s intent. Because of that, a key impedance in adoption of PBE systems is the lack of user confidence in the correctness of the program that was synthesized by the system. We present two novel user interaction models that communicate actionable information to the user to help resolve ambiguity in the examples. One of these models allows the user to effectively navigate between the huge set of programs that are consistent with the examples provided by the user. The other model uses active learning to ask directed example-based questions to the user on the test input data over which the user intends to run the synthesized program. Our user studies show that each of these models significantly reduces the number of errors in the performed task without any difference in completion time. Moreover, both models are perceived as useful, and the proactive active-learning based model has a slightly higher preference regarding the users’ confidence in the result.},
publisher = {ACM – Association for Computing Machinery},
url = {https://www.microsoft.com/en-us/research/publication/user-interaction-models-for-disambiguation-in-programming-by-example/},
edition = {28th ACM User Interface Software and Technology Symposium (UIST 2015)},
}

@inproceedings{freeal,
    title = "{F}ree{AL}: Towards Human-Free Active Learning in the Era of Large Language Models",
    author = "Xiao, Ruixuan  and
      Dong, Yiwen  and
      Zhao, Junbo  and
      Wu, Runze  and
      Lin, Minmin  and
      Chen, Gang  and
      Wang, Haobo",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.896",
    doi = "10.18653/v1/2023.emnlp-main.896",
    pages = "14520--14535",
    abstract = "Collecting high-quality labeled data for model training is notoriously time-consuming and labor-intensive for various NLP tasks. While copious solutions, such as active learning for small language models (SLMs) and prevalent in-context learning in the era of large language models (LLMs), have been proposed and alleviate the labeling burden to some extent, their performances are still subject to human intervention. It is still underexplored how to reduce the annotation cost in the LLMs era. To bridge this, we revolutionize traditional active learning and propose an innovative collaborative learning framework FreeAL to interactively distill and filter the task-specific knowledge from LLMs. During collaborative training, an LLM serves as an active annotator inculcating its coarse-grained knowledge, while a downstream SLM is incurred as a student to filter out high-quality in-context samples to feedback LLM for the subsequent label refinery. Extensive experiments on eight benchmark datasets demonstrate that FreeAL largely enhances the zero-shot performances for both SLM and LLM without any human supervision.",
}

@inproceedings{geoquery,
author = {Zelle, John M. and Mooney, Raymond J.},
title = {Learning to parse database queries using inductive logic programming},
year = {1996},
isbn = {026251091X},
publisher = {AAAI Press},
abstract = {This paper presents recent work using the CHILL parser acquisition system to automate the construction of a natural-language interface for database queries. CHILL treats parser acquisition as the learning of search-control rules within a logic program representing a shift-reduce parser and uses techniques from Inductive Logic Programming to learn relational control knowledge. Starting with a general framework for constructing a suitable logical form, CHILL is able to train on a corpus comprising sentences paired with database queries and induce parsers that map subsequent sentences directly into executable queries. Experimental results with a complete database-query application for U.S. geography show that CHILL is able to learn parsers that outperform a preexisting, hand-crafted counterpart. These results demonstrate the ability of a corpus-based system to produce more than purely syntactic representations. They also provide direct evidence of the utility of an empirical approach at the level of a complete natural language application.},
booktitle = {Proceedings of the Thirteenth National Conference on Artificial Intelligence - Volume 2},
pages = {1050–1055},
numpages = {6},
location = {Portland, Oregon},
series = {AAAI'96}
}

@article{heatmap1,
  author    = {Laura Rieger and
               Lars Kai Hansen},
  title     = {A simple defense against adversarial attacks on heatmap explanations},
  journal   = {CoRR},
  volume    = {abs/2007.06381},
  year      = {2020},
  url       = {https://arxiv.org/abs/2007.06381},
  eprinttype = {arXiv},
  eprint    = {2007.06381},
  timestamp = {Tue, 21 Jul 2020 12:53:33 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2007-06381.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{heatmap2,
author = {Zhou, Bolei and Sun, Yiyou and Bau, David and Torralba, Antonio},
title = {Interpretable Basis Decomposition for Visual Explanation},
year = {2018},
isbn = {978-3-030-01236-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-01237-3_8},
doi = {10.1007/978-3-030-01237-3_8},
abstract = {Explanations of the decisions made by a deep neural network are important for human end-users to be able to understand and diagnose the trustworthiness of the system. Current neural networks used for visual recognition are generally used as black boxes that do not provide any human interpretable justification for a prediction. In this work we propose a new framework called Interpretable Basis Decomposition for providing visual explanations for classification networks. By decomposing the neural activations of the input image into semantically interpretable components pre-trained from a large concept corpus, the proposed framework is able to disentangle the evidence encoded in the activation feature vector, and quantify the contribution of each piece of evidence to the final prediction. We apply our framework for providing explanations to several popular networks for visual recognition, and show it is able to explain the predictions given by the networks in a human-interpretable way. The human interpretability of the visual explanations provided by our framework and other recent explanation methods is evaluated through Amazon Mechanical Turk, showing that our framework generates more faithful and interpretable explanations (The code and data are available at ).},
booktitle = {Computer Vision – ECCV 2018: 15th European Conference, Munich, Germany, September 8-14, 2018, Proceedings, Part VIII},
pages = {122–138},
numpages = {17},
location = {Munich, Germany}
}

@inproceedings{interactive_video_object_mask_annotation,
  title={Interactive video object mask annotation},
  author={Le, Trung-Nghia and Nguyen, Tam V and Tran, Quoc-Cuong and Nguyen, Lam and Hoang, Trung-Hieu and Le, Minh-Quan and Tran, Minh-Triet},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={18},
  pages={16067--16070},
  year={2021}
}

@inproceedings{kaggledbqa,
    title = "{K}aggle{DBQA}: Realistic Evaluation of Text-to-{SQL} Parsers",
    author = "Lee, Chia-Hsuan  and
      Polozov, Oleksandr  and
      Richardson, Matthew",
    editor = "Zong, Chengqing  and
      Xia, Fei  and
      Li, Wenjie  and
      Navigli, Roberto",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-long.176",
    doi = "10.18653/v1/2021.acl-long.176",
    pages = "2261--2273",
    abstract = "The goal of database question answering is to enable natural language querying of real-life relational databases in diverse application domains. Recently, large-scale datasets such as Spider and WikiSQL facilitated novel modeling techniques for text-to-SQL parsing, improving zero-shot generalization to unseen databases. In this work, we examine the challenges that still prevent these techniques from practical deployment. First, we present KaggleDBQA, a new cross-domain evaluation dataset of real Web databases, with domain-specific data types, original formatting, and unrestricted questions. Second, we re-examine the choice of evaluation tasks for text-to-SQL parsers as applied in real-life settings. Finally, we augment our in-domain evaluation task with database documentation, a naturally occurring source of implicit domain knowledge. We show that KaggleDBQA presents a challenge to state-of-the-art zero-shot parsers but a more realistic evaluation setting and creative use of associated database documentation boosts their accuracy by over 13.2{\%}, doubling their performance.",
}

@inproceedings{kocielnik2019will,
  title={Will you accept an imperfect ai? exploring designs for adjusting end-user expectations of ai systems},
  author={Kocielnik, Rafal and Amershi, Saleema and Bennett, Paul N},
  booktitle={Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
  pages={1--14},
  year={2019}
}

@inproceedings{liao2020questioning,
  title={Questioning the AI: informing design practices for explainable AI user experiences},
  author={Liao, Q Vera and Gruen, Daniel and Miller, Sarah},
  booktitle={Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
  pages={1--15},
  year={2020}
}

@inproceedings{lime,
    title = "{``}Why Should {I} Trust You?{''}: Explaining the Predictions of Any Classifier",
    author = "Ribeiro, Marco  and
      Singh, Sameer  and
      Guestrin, Carlos",
    booktitle = "Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Demonstrations",
    month = jun,
    year = "2016",
    address = "San Diego, California",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N16-3020",
    doi = "10.18653/v1/N16-3020",
    pages = "97--101",
}

@article{lin2020bridging,
  title={Bridging textual and tabular data for cross-domain text-to-sql semantic parsing},
  author={Lin, Xi Victoria and Socher, Richard and Xiong, Caiming},
  journal={arXiv preprint arXiv:2012.12627},
  year={2020}
}

@inproceedings{llm_annotator_1,
    title = "{GPT}s Are Multilingual Annotators for Sequence Generation Tasks",
    author = "Choi, Juhwan  and
      Lee, Eunju  and
      Jin, Kyohoon  and
      Kim, YoungBin",
    editor = "Graham, Yvette  and
      Purver, Matthew",
    booktitle = "Findings of the Association for Computational Linguistics: EACL 2024",
    month = mar,
    year = "2024",
    address = "St. Julian{'}s, Malta",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-eacl.2",
    pages = "17--40",
    abstract = "Data annotation is an essential step for constructing new datasets. However, the conventional approach of data annotation through crowdsourcing is both time-consuming and expensive. In addition, the complexity of this process increases when dealing with low-resource languages owing to the difference in the language pool of crowdworkers. To address these issues, this study proposes an autonomous annotation method by utilizing large language models, which have been recently demonstrated to exhibit remarkable performance. Through our experiments, we demonstrate that the proposed method is not just cost-efficient but also applicable for low-resource language annotation. Additionally, we constructed an image captioning dataset using our approach and are committed to open this dataset for future study. We have opened our source code for further study and reproducibility.",
}

@misc{llm_data_annotation,
      title={Large Language Models for Data Annotation: A Survey}, 
      author={Zhen Tan and Dawei Li and Song Wang and Alimohammad Beigi and Bohan Jiang and Amrita Bhattacharjee and Mansooreh Karami and Jundong Li and Lu Cheng and Huan Liu},
      year={2024},
      eprint={2402.13446},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.13446}, 
}

@misc{llm_hallucination,
      title={A Survey on Hallucination in Large Language Models: Principles, Taxonomy, Challenges, and Open Questions},
      author={Lei Huang and Weijiang Yu and Weitao Ma and Weihong Zhong and Zhangyin Feng and Haotian Wang and Qianglong Chen and Weihua Peng and Xiaocheng Feng and Bing Qin and Ting Liu},
      year={2023},
      eprint={2311.05232},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2311.05232}, 
}

@inproceedings{logic1,
    title = "{TEAM}: A Transportable Natural-Language Interface System",
    author = "Grosz, Barbara J.",
    booktitle = "First Conference on Applied Natural Language Processing",
    month = feb,
    year = "1983",
    address = "Santa Monica, California, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/A83-1006",
    doi = "10.3115/974194.974201",
    pages = "39--45",
}

@article{logic2,
    title = "An Efficient Easily Adaptable System for Interpreting Natural Language Queries",
    author = "Warren, David H.D.  and
      Pereira, Fernando C.N.",
    journal = "American Journal of Computational Linguistics",
    volume = "8",
    number = "3-4",
    year = "1982",
    url = "https://aclanthology.org/J82-3002",
    pages = "110--122",
}

@inproceedings{logos,
author = {Kokkalis, Andreas and Vagenas, Panagiotis and Zervakis, Alexandros and Simitsis, Alkis and Koutrika, Georgia and Ioannidis, Yannis},
title = {Logos: A System for Translating Queries into Narratives},
year = {2012},
isbn = {9781450312479},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2213836.2213929},
doi = {10.1145/2213836.2213929},
abstract = {This paper presents Logos, a system that provides natural language translations for relational queries expressed in SQL. Our translation mechanism is based on a graph-based approach to the query translation problem. We represent various forms of structured queries as directed graphs and we annotate the graph edges with template labels using an extensible template mechanism. Logos uses different graph traversal strategies for efficiently exploring these graphs and composing textual query descriptions. The audience may interactively explore Logos using various database schemata and issuing either sample or ad hoc queries.},
booktitle = {Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data},
pages = {673–676},
numpages = {4},
keywords = {sql queries, natural language, query translation},
location = {Scottsdale, Arizona, USA},
series = {SIGMOD '12}
}

@inproceedings{luger2016like,
  title={" Like Having a Really Bad PA" The Gulf between User Expectation and Experience of Conversational Agents},
  author={Luger, Ewa and Sellen, Abigail},
  booktitle={Proceedings of the 2016 CHI conference on human factors in computing systems},
  pages={5286--5297},
  year={2016}
}

@article{lunar,
author = {Woods, William and Kaplan, Ronald and Webber, Bonnie},
year = {1972},
month = {01},
pages = {},
title = {The Lunar Science Natural Language Information System: Final Report}
}

@ARTICLE{man-computer,
  author={Licklider, J. C. R.},
  journal={IRE Transactions on Human Factors in Electronics}, 
  title={Man-Computer Symbiosis}, 
  year={1960},
  volume={HFE-1},
  number={1},
  pages={4-11},
  doi={10.1109/THFE2.1960.4503259},
  url={https://ieeexplore.ieee.org/document/4503259}
}

@inproceedings{misp,
    title = "Model-based Interactive Semantic Parsing: A Unified Framework and A Text-to-{SQL} Case Study",
    author = "Yao, Ziyu  and
      Su, Yu  and
      Sun, Huan  and
      Yih, Wen-tau",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-1547",
    doi = "10.18653/v1/D19-1547",
    pages = "5447--5458",
    abstract = "As a promising paradigm, interactive semantic parsing has shown to improve both semantic parsing accuracy and user confidence in the results. In this paper, we propose a new, unified formulation of the interactive semantic parsing problem, where the goal is to design a model-based intelligent agent. The agent maintains its own state as the current predicted semantic parse, decides whether and where human intervention is needed, and generates a clarification question in natural language. A key part of the agent is a world model: it takes a percept (either an initial question or subsequent feedback from the user) and transitions to a new state. We then propose a simple yet remarkably effective instantiation of our framework, demonstrated on two text-to-SQL datasets (WikiSQL and Spider) with different state-of-the-art base semantic parsers. Compared to an existing interactive semantic parsing approach that treats the base parser as a black box, our approach solicits less user feedback but yields higher run-time accuracy.",
}

@book{molnar2020interpretable,
  title={Interpretable machine learning},
  author={Molnar, Christoph},
  year={2020},
  publisher={Lulu. com}
}

@article{nl-explanation-visual-question,
  author    = {Shalini Ghosh and
               Giedrius Burachas and
               Arijit Ray and
               Avi Ziskind},
  title     = {Generating Natural Language Explanations for Visual Question Answering
               using Scene Graphs and Visual Attention},
  journal   = {CoRR},
  volume    = {abs/1902.05715},
  year      = {2019},
  url       = {http://arxiv.org/abs/1902.05715},
  eprinttype = {arXiv},
  eprint    = {1902.05715},
  timestamp = {Tue, 21 May 2019 18:03:39 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1902-05715.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{nlp_data_annotate,
title = {Data augmentation approaches in natural language processing: A survey},
journal = {AI Open},
volume = {3},
pages = {71-90},
year = {2022},
issn = {2666-6510},
doi = {https://doi.org/10.1016/j.aiopen.2022.03.001},
url = {https://www.sciencedirect.com/science/article/pii/S2666651022000080},
author = {Bohan Li and Yutai Hou and Wanxiang Che},
keywords = {Machine learning, Data augmentation, Natural language processing},
abstract = {As an effective strategy, data augmentation (DA) alleviates data scarcity scenarios where deep learning techniques may fail. It is widely applied in computer vision then introduced to natural language processing and achieves improvements in many tasks. One of the main focuses of the DA methods is to improve the diversity of training data, thereby helping the model to better generalize to unseen testing data. In this survey, we frame DA methods into three categories based on the diversity of augmented data, including paraphrasing, noising, and sampling. Our paper sets out to analyze DA methods in detail according to the above categories. Further, we also introduce their applications in NLP tasks as well as the challenges. Some useful resources are provided in Appendix A.}
}

@inproceedings{nlp_synthetic_1,
author = {Barzilay, Regina and McKeown, Kathleen R.},
title = {Extracting paraphrases from a parallel corpus},
year = {2001},
publisher = {Association for Computational Linguistics},
address = {USA},
url = {https://doi.org/10.3115/1073012.1073020},
doi = {10.3115/1073012.1073020},
abstract = {While paraphrasing is critical both for interpretation and generation of natural language, current systems use manual or semi-automatic methods to collect paraphrases. We present an unsupervised learning algorithm for identification of paraphrases from a corpus of multiple English translations of the same source text. Our approach yields phrasal and single word lexical paraphrases as well as syntactic paraphrases.},
booktitle = {Proceedings of the 39th Annual Meeting on Association for Computational Linguistics},
pages = {50–57},
numpages = {8},
location = {Toulouse, France},
series = {ACL '01}
}

@inproceedings{nlp_synthetic_2,
    title = "Improving Neural Machine Translation Models with Monolingual Data",
    author = "Sennrich, Rico  and
      Haddow, Barry  and
      Birch, Alexandra",
    editor = "Erk, Katrin  and
      Smith, Noah A.",
    booktitle = "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2016",
    address = "Berlin, Germany",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P16-1009",
    doi = "10.18653/v1/P16-1009",
    pages = "86--96",
}

@inproceedings{nlp_synthetic_3,
    title = "Counterfactual Data Augmentation for Neural Machine Translation",
    author = "Liu, Qi  and
      Kusner, Matt  and
      Blunsom, Phil",
    editor = "Toutanova, Kristina  and
      Rumshisky, Anna  and
      Zettlemoyer, Luke  and
      Hakkani-Tur, Dilek  and
      Beltagy, Iz  and
      Bethard, Steven  and
      Cotterell, Ryan  and
      Chakraborty, Tanmoy  and
      Zhou, Yichao",
    booktitle = "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.naacl-main.18",
    doi = "10.18653/v1/2021.naacl-main.18",
    pages = "187--197",
    abstract = "We propose a data augmentation method for neural machine translation. It works by interpreting language models and phrasal alignment causally. Specifically, it creates augmented parallel translation corpora by generating (path-specific) counterfactual aligned phrases. We generate these by sampling new source phrases from a masked language model, then sampling an aligned counterfactual target phrase by noting that a translation language model can be interpreted as a Gumbel-Max Structural Causal Model (Oberst and Sontag, 2019). Compared to previous work, our method takes both context and alignment into account to maintain the symmetry between source and target sequences. Experiments on IWSLT{'}15 English → Vietnamese, WMT{'}17 English → German, WMT{'}18 English → Turkish, and WMT{'}19 robust English → French show that the method can improve the performance of translation, backtranslation and translation robustness.",
}

@inproceedings{nlp_synthetic_4,
    title = "An Exploration of Data Augmentation and Sampling Techniques for Domain-Agnostic Question Answering",
    author = "Longpre, Shayne  and
      Lu, Yi  and
      Tu, Zhucheng  and
      DuBois, Chris",
    editor = "Fisch, Adam  and
      Talmor, Alon  and
      Jia, Robin  and
      Seo, Minjoon  and
      Choi, Eunsol  and
      Chen, Danqi",
    booktitle = "Proceedings of the 2nd Workshop on Machine Reading for Question Answering",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-5829",
    doi = "10.18653/v1/D19-5829",
    pages = "220--227",
    abstract = "To produce a domain-agnostic question answering model for the Machine Reading Question Answering (MRQA) 2019 Shared Task, we investigate the relative benefits of large pre-trained language models, various data sampling strategies, as well as query and context paraphrases generated by back-translation. We find a simple negative sampling technique to be particularly effective, even though it is typically used for datasets that include unanswerable questions, such as SQuAD 2.0. When applied in conjunction with per-domain sampling, our XLNet (Yang et al., 2019)-based submission achieved the second best Exact Match and F1 in the MRQA leaderboard competition.",
}

@misc{oss_instruct,
      title={Magicoder: Empowering Code Generation with OSS-Instruct}, 
      author={Yuxiang Wei and Zhe Wang and Jiawei Liu and Yifeng Ding and Lingming Zhang},
      year={2024},
      eprint={2312.02120},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2312.02120}, 
}

@inproceedings{picard,
    title = "{PICARD}: Parsing Incrementally for Constrained Auto-Regressive Decoding from Language Models",
    author = "Scholak, Torsten  and
      Schucher, Nathan  and
      Bahdanau, Dzmitry",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-main.779",
    doi = "10.18653/v1/2021.emnlp-main.779",
    pages = "9895--9901",
    abstract = "Large pre-trained language models for textual data have an unconstrained output space; at each decoding step, they can produce any of 10,000s of sub-word tokens. When fine-tuned to target constrained formal languages like SQL, these models often generate invalid code, rendering it unusable. We propose PICARD (code available at https://github.com/ElementAI/picard), a method for constraining auto-regressive decoders of language models through incremental parsing. PICARD helps to find valid output sequences by rejecting inadmissible tokens at each decoding step. On the challenging Spider and CoSQL text-to-SQL translation tasks, we show that PICARD transforms fine-tuned T5 models with passable performance into state-of-the-art solutions.",
}

@inproceedings{ratsql,
    title = "{RAT-SQL}: Relation-Aware Schema Encoding and Linking for Text-to-{SQL} Parsers",
    author = "Wang, Bailin  and
      Shin, Richard  and
      Liu, Xiaodong  and
      Polozov, Oleksandr  and
      Richardson, Matthew",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.677",
    doi = "10.18653/v1/2020.acl-main.677",
    pages = "7567--7578",
    abstract = "When translating natural language questions into SQL queries to answer questions from a database, contemporary semantic parsing models struggle to generalize to unseen database schemas. The generalization challenge lies in (a) encoding the database relations in an accessible way for the semantic parser, and (b) modeling alignment between database columns and their mentions in a given query. We present a unified framework, based on the relation-aware self-attention mechanism, to address schema encoding, schema linking, and feature representation within a text-to-SQL encoder. On the challenging Spider dataset this framework boosts the exact match accuracy to 57.2{\%}, surpassing its best counterparts by 8.7{\%} absolute improvement. Further augmented with BERT, it achieves the new state-of-the-art performance of 65.6{\%} on the Spider leaderboard. In addition, we observe qualitative improvements in the model{'}s understanding of schema linking and alignment. Our implementation will be open-sourced at https://github.com/Microsoft/rat-sql.",
}

@inproceedings{restaurants,
    title = "Automated Construction of Database Interfaces: Intergrating Statistical and Relational Learning for Semantic Parsing",
    author = "Tang, Lappoon R.  and
      Mooney, Raymond J.",
    booktitle = "2000 Joint {SIGDAT} Conference on Empirical Methods in Natural Language Processing and Very Large Corpora",
    month = oct,
    year = "2000",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W00-1317",
    doi = "10.3115/1117794.1117811",
    pages = "133--141",
}

@article{rule1,
  author    = {Christopher Baik and
               H. V. Jagadish and
               Yunyao Li},
  title     = {Bridging the Semantic Gap with {SQL} Query Logs in Natural Language
               Interfaces to Databases},
  journal   = {CoRR},
  volume    = {abs/1902.00031},
  year      = {2019},
  url       = {http://arxiv.org/abs/1902.00031},
  eprinttype = {arXiv},
  eprint    = {1902.00031},
  timestamp = {Tue, 21 May 2019 18:03:40 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1902-00031.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{scholar,
    title = "Learning a Neural Semantic Parser from User Feedback",
    author = "Iyer, Srinivasan  and
      Konstas, Ioannis  and
      Cheung, Alvin  and
      Krishnamurthy, Jayant  and
      Zettlemoyer, Luke",
    editor = "Barzilay, Regina  and
      Kan, Min-Yen",
    booktitle = "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P17-1089",
    doi = "10.18653/v1/P17-1089",
    pages = "963--973",
    abstract = "We present an approach to rapidly and easily build natural language interfaces to databases for new domains, whose performance improves over time based on user feedback, and requires minimal intervention. To achieve this, we adapt neural sequence models to map utterances directly to SQL with its full expressivity, bypassing any intermediate meaning representations. These models are immediately deployed online to solicit feedback from real users to flag incorrect queries. Finally, the popularity of SQL facilitates gathering annotations for incorrect predictions using the crowd, which is directly used to improve our models. This complete feedback loop, without intermediate representations or database specific engineering, opens up new ways of building high quality semantic parsers. Experiments suggest that this approach can be deployed quickly for any new target domain, as we show by learning a semantic parser for an online academic database from scratch.",
}

@inproceedings{search-trace,
author = {Zhang, Tianyi and Chen, Zhiyang and Zhu, Yuanli and Vaithilingam, Priyan and Wang, Xinyu and Glassman, Elena L.},
title = {Interpretable Program Synthesis},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445646},
doi = {10.1145/3411764.3445646},
abstract = {Program synthesis, which generates programs based on user-provided specifications, can be obscure and brittle: users have few ways to understand and recover from synthesis failures. We propose interpretable program synthesis, a novel approach that unveils the synthesis process and enables users to monitor and guide a synthesizer. We designed three representations that explain the underlying synthesis process with different levels of fidelity. We implemented an interpretable synthesizer for regular expressions and conducted a within-subjects study with eighteen participants on three challenging regex tasks. With interpretable synthesis, participants were able to reason about synthesis failures and provide strategic feedback, achieving a significantly higher success rate compared with a state-of-the-art synthesizer. In particular, participants with a high engagement tendency (as measured by NCS-6) preferred a deductive representation that shows the synthesis process in a search tree, while participants with a relatively low engagement tendency preferred an inductive representation that renders representative samples of programs enumerated during synthesis.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {105},
numpages = {16},
keywords = {Programming by example, Program synthesis, Interpretability},
location = {Yokohama, Japan},
series = {CHI '21}
}

@misc{self_instruct,
      title={Self-Instruct: Aligning Language Models with Self-Generated Instructions}, 
      author={Yizhong Wang and Yeganeh Kordi and Swaroop Mishra and Alisa Liu and Noah A. Smith and Daniel Khashabi and Hannaneh Hajishirzi},
      year={2023},
      eprint={2212.10560},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2212.10560}, 
}

@misc{semantic_parsing_data_augmentation_1,
      title={Data Recombination for Neural Semantic Parsing}, 
      author={Robin Jia and Percy Liang},
      year={2016},
      eprint={1606.03622},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1606.03622}, 
}

@misc{semantic_parsing_data_augmentation_2,
      title={Sequence-to-Sequence Data Augmentation for Dialogue Language Understanding}, 
      author={Yutai Hou and Yijia Liu and Wanxiang Che and Ting Liu},
      year={2018},
      eprint={1807.01554},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1807.01554}, 
}

@misc{semantic_parsing_data_augmentation_3,
      title={GraPPa: Grammar-Augmented Pre-Training for Table Semantic Parsing}, 
      author={Tao Yu and Chien-Sheng Wu and Xi Victoria Lin and Bailin Wang and Yi Chern Tan and Xinyi Yang and Dragomir Radev and Richard Socher and Caiming Xiong},
      year={2021},
      eprint={2009.13845},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2009.13845}, 
}

@inproceedings{semantic_parsing_data_augmentation_4,
    title = "Grounded Adaptation for Zero-shot Executable Semantic Parsing",
    author = "Zhong, Victor  and
      Lewis, Mike  and
      Wang, Sida I.  and
      Zettlemoyer, Luke",
    editor = "Webber, Bonnie  and
      Cohn, Trevor  and
      He, Yulan  and
      Liu, Yang",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.558",
    doi = "10.18653/v1/2020.emnlp-main.558",
    pages = "6869--6882",
    abstract = "We propose Grounded Adaptation for Zeroshot Executable Semantic Parsing (GAZP) to adapt an existing semantic parser to new environments (e.g. new database schemas). GAZP combines a forward semantic parser with a backward utterance generator to synthesize data (e.g. utterances and SQL queries) in the new environment, then selects cycle-consistent examples to adapt the parser. Unlike data-augmentation, which typically synthesizes unverified examples in the training environment, GAZP synthesizes examples in the new environment whose input-output consistency are verified through execution. On the Spider, Sparc, and CoSQL zero-shot semantic parsing tasks, GAZP improves logical form and execution accuracy of the baseline parser. Our analyses show that GAZP outperforms data-augmentation in the training environment, performance increases with the amount of GAZP-synthesized data, and cycle-consistency is central to successful adaptation.",
}

@article{semi_automatic_data_annotation,
title = {Semi-automatic data annotation guided by feature space projection},
journal = {Pattern Recognition},
volume = {109},
pages = {107612},
year = {2021},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2020.107612},
url = {https://www.sciencedirect.com/science/article/pii/S0031320320304155},
author = {Bárbara C. Benato and Jancarlo F. Gomes and Alexandru C. Telea and Alexandre X. Falcão},
keywords = {Semi-supervised learning, Unsupervised feature learning, Interactive data annotation, Autoencoder-neural networks, Data visualization},
abstract = {Data annotation using visual inspection (supervision) of each training sample can be laborious. Interactive solutions alleviate this by helping experts propagate labels from a few supervised samples to unlabeled ones based solely on the visual analysis of their feature space projection (with no further sample supervision). We present a semi-automatic data annotation approach based on suitable feature space projection and semi-supervised label estimation. We validate our method on the popular MNIST dataset and on images of human intestinal parasites with and without fecal impurities, a large and diverse dataset that makes classification very hard. We evaluate two approaches for semi-supervised learning from the latent and projection spaces, to choose the one that best reduces user annotation effort and also increases classification accuracy on unseen data. Our results demonstrate the added-value of visual analytics tools that combine complementary abilities of humans and machines for more effective machine learning.}
}

@article{seq2sql,
  author    = {Victor Zhong and
               Caiming Xiong and
               Richard Socher},
  title     = {Seq2SQL: Generating Structured Queries from Natural Language using
               Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1709.00103},
  year      = {2017},
  url       = {http://arxiv.org/abs/1709.00103},
  eprinttype = {arXiv},
  eprint    = {1709.00103},
  timestamp = {Mon, 13 Aug 2018 16:48:41 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1709-00103.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{simiar_algorithm,
    title = "Question Generation from {SQL} Queries Improves Neural Semantic Parsing",
    author = "Guo, Daya  and
      Sun, Yibo  and
      Tang, Duyu  and
      Duan, Nan  and
      Yin, Jian  and
      Chi, Hong  and
      Cao, James  and
      Chen, Peng  and
      Zhou, Ming",
    editor = "Riloff, Ellen  and
      Chiang, David  and
      Hockenmaier, Julia  and
      Tsujii, Jun{'}ichi",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D18-1188",
    doi = "10.18653/v1/D18-1188",
    pages = "1597--1607",
    abstract = "In this paper, we study how to learn a semantic parser of state-of-the-art accuracy with less supervised training data. We conduct our study on WikiSQL, the largest hand-annotated semantic parsing dataset to date. First, we demonstrate that question generation is an effective method that empowers us to learn a state-of-the-art neural network based semantic parser with thirty percent of the supervised training data. Second, we show that applying question generation to the full supervised training data further improves the state-of-the-art model. In addition, we observe that there is a logarithmic relationship between the accuracy of a semantic parser and the amount of training data.",
}

@inproceedings{smbop,
    title = "{S}m{B}o{P}: Semi-autoregressive Bottom-up Semantic Parsing",
    author = "Rubin, Ohad  and
      Berant, Jonathan",
    booktitle = "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.naacl-main.29",
    doi = "10.18653/v1/2021.naacl-main.29",
    pages = "311--324",
    abstract = "The de-facto standard decoding method for semantic parsing in recent years has been to autoregressively decode the abstract syntax tree of the target program using a top-down depth-first traversal. In this work, we propose an alternative approach: a Semi-autoregressive Bottom-up Parser (SmBoP) that constructs at decoding step t the top-K sub-trees of height {\mbox{$\leq$}} t. Our parser enjoys several benefits compared to top-down autoregressive parsing. From an efficiency perspective, bottom-up parsing allows to decode all sub-trees of a certain height in parallel, leading to logarithmic runtime complexity rather than linear. From a modeling perspective, a bottom-up parser learns representations for meaningful semantic sub-programs at each step, rather than for semantically-vacuous partial trees. We apply SmBoP on Spider, a challenging zero-shot semantic parsing benchmark, and show that SmBoP leads to a 2.2x speed-up in decoding time and a {\textasciitilde}5x speed-up in training time, compared to a semantic parser that uses autoregressive decoding. SmBoP obtains 71.1 denotation accuracy on Spider, establishing a new state-of-the-art, and 69.5 exact match, comparable to the 69.6 exact match of the autoregressive RAT-SQL+GraPPa.",
}

@inproceedings{sparc,
    title = "{SP}ar{C}: Cross-Domain Semantic Parsing in Context",
    author = "Yu, Tao  and
      Zhang, Rui  and
      Yasunaga, Michihiro  and
      Tan, Yi Chern  and
      Lin, Xi Victoria  and
      Li, Suyi  and
      Er, Heyang  and
      Li, Irene  and
      Pang, Bo  and
      Chen, Tao  and
      Ji, Emily  and
      Dixit, Shreya  and
      Proctor, David  and
      Shim, Sungrok  and
      Kraft, Jonathan  and
      Zhang, Vincent  and
      Xiong, Caiming  and
      Socher, Richard  and
      Radev, Dragomir",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1443",
    doi = "10.18653/v1/P19-1443",
    pages = "4511--4523",
    abstract = "We present SParC, a dataset for cross-domainSemanticParsing inContext that consists of 4,298 coherent question sequences (12k+ individual questions annotated with SQL queries). It is obtained from controlled user interactions with 200 complex databases over 138 domains. We provide an in-depth analysis of SParC and show that it introduces new challenges compared to existing datasets. SParC demonstrates complex contextual dependencies, (2) has greater semantic diversity, and (3) requires generalization to unseen domains due to its cross-domain nature and the unseen databases at test time. We experiment with two state-of-the-art text-to-SQL models adapted to the context-dependent, cross-domain setup. The best model obtains an exact match accuracy of 20.2{\%} over all questions and less than10{\%} over all interaction sequences, indicating that the cross-domain setting and the con-textual phenomena of the dataset present significant challenges for future research. The dataset, baselines, and leaderboard are released at https://yale-lily.github.io/sparc.",
}

@inproceedings{spider,
    title = "{S}pider: A Large-Scale Human-Labeled Dataset for Complex and Cross-Domain Semantic Parsing and Text-to-{SQL} Task",
    author = "Yu, Tao  and
      Zhang, Rui  and
      Yang, Kai  and
      Yasunaga, Michihiro  and
      Wang, Dongxu  and
      Li, Zifan  and
      Ma, James  and
      Li, Irene  and
      Yao, Qingning  and
      Roman, Shanelle  and
      Zhang, Zilin  and
      Radev, Dragomir",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D18-1425",
    doi = "10.18653/v1/D18-1425",
    pages = "3911--3921",
    abstract = "We present \textit{Spider}, a large-scale complex and cross-domain semantic parsing and text-to-SQL dataset annotated by 11 college students. It consists of 10,181 questions and 5,693 unique complex SQL queries on 200 databases with multiple tables covering 138 different domains. We define a new complex and cross-domain semantic parsing and text-to-SQL task so that different complicated SQL queries and databases appear in train and test sets. In this way, the task requires the model to generalize well to both new SQL queries and new database schemas. Therefore, Spider is distinct from most of the previous semantic parsing tasks because they all use a single database and have the exact same program in the train set and the test set. We experiment with various state-of-the-art models and the best model achieves only 9.7{\%} exact matching accuracy on a database split setting. This shows that Spider presents a strong challenge for future research. Our dataset and task with the most recent updates are publicly available at \url{https://yale-lily.github.io/seq2sql/spider}.",
}

@misc{spider_dk,
      title={Exploring Underexplored Limitations of Cross-Domain Text-to-SQL Generalization}, 
      author={Yujian Gan and Xinyun Chen and Matthew Purver},
      year={2021},
      eprint={2109.05157},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2109.05157}, 
}

@misc{spider_syn,
      title={Towards Robustness of Text-to-SQL Models against Synonym Substitution}, 
      author={Yujian Gan and Xinyun Chen and Qiuping Huang and Matthew Purver and John R. Woodward and Jinxia Xie and Pengsheng Huang},
      year={2021},
      eprint={2106.01065},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2106.01065}, 
}

@misc{sql_to_text2,
      title={Question Generation from SQL Queries Improves Neural Semantic Parsing}, 
      author={Daya Guo and Yibo Sun and Duyu Tang and Nan Duan and Jian Yin and Hong Chi and James Cao and Peng Chen and Ming Zhou},
      year={2018},
      eprint={1808.06304},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1808.06304}, 
}

@misc{sql_to_text3,
      title={Data Augmentation with Hierarchical SQL-to-Question Generation for Cross-domain Text-to-SQL Parsing}, 
      author={Kun Wu and Lijie Wang and Zhenghua Li and Ao Zhang and Xinyan Xiao and Hua Wu and Min Zhang and Haifeng Wang},
      year={2022},
      eprint={2103.02227},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2103.02227}, 
}

@misc{sqlcoder,
  author = {Wong, Wendy Aw and Srivastava, Rishabh},
  title = {Open-sourcing sqlcoder},
  year = {2023},
  howpublished = {\url{https://defog.ai/blog/open-sourcing-sqlcoder2-7b/}}
}

@inproceedings{sqlova,
  doi = {10.48550/ARXIV.1902.01069},
  
  url = {https://arxiv.org/abs/1902.01069},
  
  author = {Hwang, Wonseok and Yim, Jinyeong and Park, Seunghyun and Seo, Minjoon},
  
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {A Comprehensive Exploration on WikiSQL with Table-Aware Word Contextualization},

  booktitle = {ArXiv preprint arXiv:1902.01069.},
  
  publisher = {arXiv},
  
  year = {2019},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{sqlucid,
      title={SQLucid: Grounding Natural Language Database Queries with Interactive Explanations}, 
      author={Yuan Tian and Jonathan K. Kummerfeld and Toby Jia-Jun Li and Tianyi Zhang},
      year={2024},
      eprint={2409.06178},
      archivePrefix={arXiv},
      primaryClass={cs.HC},
      url={https://arxiv.org/abs/2409.06178}, 
}

@inproceedings{syntaxsqlnet,
    title = "{S}yntax{SQLN}et: Syntax Tree Networks for Complex and Cross-Domain Text-to-{SQL} Task",
    author = "Yu, Tao  and
      Yasunaga, Michihiro  and
      Yang, Kai  and
      Zhang, Rui  and
      Wang, Dongxu  and
      Li, Zifan  and
      Radev, Dragomir",
    editor = "Riloff, Ellen  and
      Chiang, David  and
      Hockenmaier, Julia  and
      Tsujii, Jun{'}ichi",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D18-1193",
    doi = "10.18653/v1/D18-1193",
    pages = "1653--1663",
    abstract = "Most existing studies in text-to-SQL tasks do not require generating complex SQL queries with multiple clauses or sub-queries, and generalizing to new, unseen databases. In this paper we propose SyntaxSQLNet, a syntax tree network to address the complex and cross-domain text-to-SQL generation task. SyntaxSQLNet employs a SQL specific syntax tree-based decoder with SQL generation path history and table-aware column attention encoders. We evaluate SyntaxSQLNet on a new large-scale text-to-SQL corpus containing databases with multiple tables and complex SQL queries containing multiple SQL clauses and nested queries. We use a database split setting where databases in the test set are unseen during training. Experimental results show that SyntaxSQLNet can handle a significantly greater number of complex SQL examples than prior work, outperforming the previous state-of-the-art model by 9.5{\%} in exact matching accuracy. To our knowledge, we are the first to study this complex text-to-SQL task. Our task and models with the latest updates are available at \url{https://yale-lily.github.io/seq2sql/spider}.",
}

@misc{thorpe2024dubosqldiverseretrievalaugmentedgeneration,
      title={Dubo-SQL: Diverse Retrieval-Augmented Generation and Fine Tuning for Text-to-SQL}, 
      author={Dayton G. Thorpe and Andrew J. Duberstein and Ian A. Kinsey},
      year={2024},
      eprint={2404.12560},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2404.12560}, 
}

@article{where-are-we,
author = {Kim, Hyeonji and So, Byeong-Hoon and Han, Wook-Shin and Lee, Hongrae},
title = {Natural Language to SQL: Where Are We Today?},
year = {2020},
issue_date = {June 2020},
publisher = {VLDB Endowment},
volume = {13},
number = {10},
issn = {2150-8097},
url = {https://doi.org/10.14778/3401960.3401970},
doi = {10.14778/3401960.3401970},
abstract = {Translating natural language to SQL (NL2SQL) has received extensive attention lately, especially with the recent success of deep learning technologies. However, despite the large number of studies, we do not have a thorough understanding of how good existing techniques really are and how much is applicable to real-world situations. A key difficulty is that different studies are based on different datasets, which often have their own limitations and assumptions that are implicitly hidden in the context or datasets. Moreover, a couple of evaluation metrics are commonly employed but they are rather simplistic and do not properly depict the accuracy of results, as will be shown in our experiments. To provide a holistic view of NL2SQL technologies and access current advancements, we perform extensive experiments under our unified framework using eleven of recent techniques over 10+ benchmarks including a new benchmark (WTQ) and TPC-H. We provide a comprehensive survey of recent NL2SQL methods, introducing a taxonomy of them. We reveal major assumptions of the methods and classify translation errors through extensive experiments. We also provide a practical tool for validation by using existing, mature database technologies such as query rewrite and database testing. We then suggest future research directions so that the translation can be used in practice.},
journal = {Proc. VLDB Endow.},
month = {jun},
pages = {1737–1750},
numpages = {14}
}

@inproceedings{wikisql,
  doi = {10.48550/ARXIV.1709.00103},
  
  url = {https://arxiv.org/abs/1709.00103},
  
  author = {Zhong, Victor and Xiong, Caiming and Socher, Richard},
  
  keywords = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Seq2SQL: Generating Structured Queries from Natural Language using Reinforcement Learning},
  
  publisher = {arXiv},

  booktitle = {arxiv preprint, arxiv/1709.00103.},
  year = {2017},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{xiyan,
      title={XiYan-SQL: A Multi-Generator Ensemble Framework for Text-to-SQL}, 
      author={Yingqi Gao and Yifu Liu and Xiaoxia Li and Xiaorong Shi and Yin Zhu and Yiming Wang and Shiqi Li and Wei Li and Yuntao Hong and Zhiling Luo and Jinyang Gao and Liyu Mou and Yu Li},
      year={2024},
      eprint={2411.08599},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2411.08599}, 
}

@misc{yelp_and_IMDB,
      title={Type- and Content-Driven Synthesis of SQL Queries from Natural Language}, 
      author={Navid Yaghmazadeh and Yuepeng Wang and Isil Dillig and Thomas Dillig},
      year={2017},
      eprint={1702.01168},
      archivePrefix={arXiv},
      primaryClass={cs.DB},
      url={https://arxiv.org/abs/1702.01168}, 
}

@inproceedings{zhong-etal-2020-grounded,
    title = "Grounded Adaptation for Zero-shot Executable Semantic Parsing",
    author = "Zhong, Victor  and
      Lewis, Mike  and
      Wang, Sida I.  and
      Zettlemoyer, Luke",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.558",
    doi = "10.18653/v1/2020.emnlp-main.558",
    pages = "6869--6882",
    abstract = "We propose Grounded Adaptation for Zeroshot Executable Semantic Parsing (GAZP) to adapt an existing semantic parser to new environments (e.g. new database schemas). GAZP combines a forward semantic parser with a backward utterance generator to synthesize data (e.g. utterances and SQL queries) in the new environment, then selects cycle-consistent examples to adapt the parser. Unlike data-augmentation, which typically synthesizes unverified examples in the training environment, GAZP synthesizes examples in the new environment whose input-output consistency are verified through execution. On the Spider, Sparc, and CoSQL zero-shot semantic parsing tasks, GAZP improves logical form and execution accuracy of the baseline parser. Our analyses show that GAZP outperforms data-augmentation in the training environment, performance increases with the amount of GAZP-synthesized data, and cycle-consistency is central to successful adaptation.",
}

