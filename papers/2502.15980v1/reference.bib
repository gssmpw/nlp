@Misc{CHINOSAUR:venue,
  author =       {@\_CHINOSAUR},
  key =          {_CHINOSAUR},
  howpublished = {Tweet},
  title =        {"VENUE IS TOO COLD" \#BINGO \#CHI2014},
  month =        {May},
  day =          1,
  year =         2014,
  note =         {Retrieved Febuary 2, 2015 from
                  \url{https://twitter.com/_CHINOSAUR/status/461864317415989248}},
  annote =       {Tweet}
}

@inproceedings{zelle1996learning,
  title={Learning to parse database queries using inductive logic programming},
  author={Zelle, John M and Mooney, Raymond J},
  booktitle={Proceedings of the national conference on artificial intelligence},
  pages={1050--1055},
  year={1996}
}

@inproceedings{kate2005learning,
  title={Learning to transform natural to formal languages},
  author={Kate, Rohit J and Wong, Yuk Wah and Mooney, Raymond J and others},
  booktitle={AAAI},
  volume={5},
  pages={1062--1068},
  year={2005}
}

@misc{supermetroid:snes,
	Address = {Kyoto, Japan},
	Author = {{Nintendo R\&D1} and {Intelligent Systems}},
	Day = {18},
	Howpublished = {Game [SNES]},
	Month = {April},
	Note = {Nintendo, Kyoto, Japan. Played August 2011.},
	Publisher = {Nintendo},
	Title = {\emph{Super Metroid}},
	Year = {1994}
}

@inproceedings{Klemmer:2002:WSC:503376.503378,
  author =       {Klemmer, Scott R. and Thomsen, Michael and
                  Phelps-Goodman, Ethan and Lee, Robert and Landay,
                  James A.},
  title =        {Where Do Web Sites Come from?: Capturing and
                  Interacting with Design History},
  booktitle =    {Proceedings of the SIGCHI Conference on Human
                  Factors in Computing Systems},
  series =       {CHI '02},
  year =         2002,
  isbn =         {1-58113-453-3},
  location =     {Minneapolis, Minnesota, USA},
  pages =        {1--8},
  url =          {http://doi.acm.org/10.1145/503376.503378},
  doi =          {10.1145/503376.503378},
  acmid =        503378,
  publisher =    {ACM},
  address =      {New York, NY, USA},
  keywords =     {CSCW, activity capture, design rationale, history
                  management, informal interfaces, sketching, tangible
                  UI, web design},
}

@inproceedings{Mather:2000:MUT,
  title =        {Making up titles for conference papers},
  author =       {Mather, B. D.},
  booktitle =    {Ext. Abstracts CHI 2000},
  year =         2000,
  publisher =    "ACM Press",
  pages =        "1-2",
}

@book{Schwartz:1995:GBF,
  title =        {Guidelines for Bias-Free Writing},
  author =       {Marilyn Schwartz},
  address =      {Bloomington, IN, USA},
  year =         1995,
  publisher =    {ERIC}
}

@inproceedings{Zellweger:2001:FAO:504216.504224,
  author =       {Zellweger, Polle T. and Bouvin, Niels Olof and
                  Jeh{\o}j, Henning and Mackinlay, Jock D.},
  title =        {Fluid annotations in an open world},
  booktitle =    {Proc. Hypertext 2001},
  year =         2001,
  pages =        {9--18},
  publisher =    {ACM Press},
}

@misc{acm_categories,
  key =          "ACM",
  author =       {ACM},
  title =        {How to Classify Works Using ACM's Computing
                  Classification System},
  year =         1998,
  note =         {\url{http://www.acm.org/class/how_to_use.html}},
}

@Misc{cavender:writing,
  author =       {Anna Cavender and Shari Trewin and Vicki Hanson},
  title =        {Accessible Writing Guide},
  year =         2014,
  day =          22,
  note =
                  {\url{http://www.sigaccess.org/welcome-to-sigaccess/resources/accessible-writing-guide/}},
  annote =       {URL}
}

@article{ethics,
  title =        {{Social Impacts of Computing: Codes of Professional
                  Ethics}},
  author =       {R. E. Anderson},
  doi =          "10.1177/089443939201000402",
  journal =      "Social Science Computer Review December",
  year =         1992,
  volume =       10,
  number =       4,
  pages =        "453-469"
}

@Misc{heilig:sensorama,
  author =       {Morton L. Heilig},
  title =        {Sensorama Simulator},
  howpublished = {U.S. Patent 3,050,870},
  month =        {August},
  day =          28,
  year =         1962,
  note =         {Filed Februrary 22, 1962.},
  annote =       {is this right?}
},

@article{kaye:puc,
  year =         2014,
  issn =         {1617-4909},
  journal =      {Personal and Ubiquitous Computing},
  volume =       18,
  number =       4,
  doi =          {10.1007/s00779-014-0773-4},
  title =        {Special issue on science fiction and ubiquitous
                  computing},
  url =          {http://dx.doi.org/10.1007/s00779-014-0773-4},
  publisher =    {Springer London},
  author =       {Kaye, Jofish and Dourish, Paul},
  pages =        {765-766},
  language =     {English}
}

@Misc{psy:gangnam,
  author =       {Psy},
  title =        {Gangnam Style},
  howpublished = {Video},
  month =        {July},
  day =          15,
  year =         2012,
  note =         {Retrieved August 22, 2014 from
                  \url{https://www.youtube.com/watch?v=9bZkp7q19f0}},
  annote =       {Video URL}
}

@PhdThesis{sutherland:sketchpad,
  author =       {Ivan E. Sutherland},
  title =        {Sketchpad, a Man-Machine Graphical Communication
                  System},
  school =       {Massachusetts Institute of Technology},
  year =         1963,
  address =      {Cambridge, MA},
}

@InBook{winner:politics,
  author =       {Langdon Winner},
  title =        {The Social Shaping of Technology},
  chapter =      {Do artifacts have politics?},
  publisher =    {Open University Press},
  year =         1999,
  address =      {UK},
  edition =      {2nd},
  pages =        {28--40},
}

% Please download the latest anthology.bib from
%
% http://aclweb.org/anthology/anthology.bib.gz

% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").




@inproceedings{zhang2020interactive,
  title={Interactive program synthesis by augmented examples},
  author={Zhang, Tianyi and Lowmanstone, London and Wang, Xinyu and Glassman, Elena L},
  booktitle={Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology},
  pages={627--648},
  year={2020}
}

@inproceedings{lee2017towards,
  title={Towards understanding human mistakes of programming by example: an online user study},
  author={Lee, Tak Yeon and Dugan, Casey and Bederson, Benjamin B},
  booktitle={Proceedings of the 22Nd International Conference on Intelligent User Interfaces},
  pages={257--261},
  year={2017}
}

@inproceedings{kandel2011wrangler,
  title={Wrangler: Interactive visual specification of data transformation scripts},
  author={Kandel, Sean and Paepcke, Andreas and Hellerstein, Joseph and Heer, Jeffrey},
  booktitle={Proceedings of the sigchi conference on human factors in computing systems},
  pages={3363--3372},
  year={2011}
}

@inproceedings{yessenov2013colorful,
  title={A colorful approach to text processing by example},
  author={Yessenov, Kuat and Tulsiani, Shubham and Menon, Aditya and Miller, Robert C and Gulwani, Sumit and Lampson, Butler and Kalai, Adam},
  booktitle={Proceedings of the 26th annual ACM symposium on User interface software and technology},
  pages={495--504},
  year={2013}
}

@inproceedings{zhou2022intent,
  title={INTENT: Interactive Tensor Transformation Synthesis},
  author={Zhou, Zhanhui and Tang, Man To and Pan, Qiping and Tan, Shangyin and Wang, Xinyu and Zhang, Tianyi},
  booktitle={Proceedings of the 35th Annual ACM Symposium on User Interface Software and Technology},
  pages={1--16},
  year={2022}
}

@inproceedings{leshed2008coscripter,
  title={CoScripter: automating \& sharing how-to knowledge in the enterprise},
  author={Leshed, Gilly and Haber, Eben M and Matthews, Tara and Lau, Tessa},
  booktitle={Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
  pages={1719--1728},
  year={2008}
}

@inproceedings{chasins2018rousillon,
  title={Rousillon: Scraping distributed hierarchical web data},
  author={Chasins, Sarah E and Mueller, Maria and Bodik, Rastislav},
  booktitle={Proceedings of the 31st Annual ACM Symposium on User Interface Software and Technology},
  pages={963--975},
  year={2018}
}

@INPROCEEDINGS{1,  
    author={Hassan, Mohammad A.},  
    booktitle={2021 22nd International Arab Conference on Information Technology (ACIT)},   
    title={Relational and NoSQL Databases: The Appropriate Database Model Choice},   
    year={2021},  
    volume={},  
    number={},  
    pages={1-6},  
    doi={10.1109/ACIT53391.2021.9677042},
    url={https://ieeexplore.ieee.org/abstract/document/9677042}
    }
    
    
@article{2,
    author = {Malik, Ahsan and Burney, S.M.Aqil and Ahmed, Fawwad},
    year = {2020},
    month = {01},
    pages = {59-71},
    title = {A Comparative Study of Unstructured Data with SQL and NO-SQL Database Management Systems},
    volume = {08},
    journal = {Journal of Computer and Communications},
    doi = {10.4236/jcc.2020.84005},
    url = {https://www.researchgate.net/publication/340622952_A_Comparative_Study_of_Unstructured_Data_with_SQL_and_NO-SQL_Database_Management_Systems}
}

@article{3,
    author = {Hendrix, Gary G. and Sacerdoti, Earl D. and Sagalowicz, Daniel and Slocum, Jonathan},
    title = {Developing a Natural Language Interface to Complex Data},
    year = {1978},
    issue_date = {June 1978},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {3},
    number = {2},
    issn = {0362-5915},
    url = {https://doi.org/10.1145/320251.320253},
    doi = {10.1145/320251.320253},
    abstract = {Aspects of an intelligent interface that provides natural language access to a large body of data distributed over a computer network are described. The overall system architecture is presented, showing how a user is buffered from the actual database management systems (DBMSs) by three layers of insulating components. These layers operate in series to convert natural language queries into calls to DBMSs at remote sites. Attention is then focused on the first of the insulating components, the natural language system. A pragmatic approach to language access that has proved useful for building interfaces to databases is described and illustrated by examples. Special language features that increase system usability, such as spelling correction, processing of incomplete inputs, and run-time system personalization, are also discussed. The language system is contrasted with other work in applied natural language processing, and the system's limitations are analyzed.},
    journal = {ACM Trans. Database Syst.},
    month = {jun},
    pages = {105–147},
    numpages = {43},
    keywords = {run-time personalization, natural language, semantic grammar, human engineering, intelligent interface, database access}
}

@inproceedings{spider,
    title = "{S}pider: A Large-Scale Human-Labeled Dataset for Complex and Cross-Domain Semantic Parsing and Text-to-{SQL} Task",
    author = "Yu, Tao  and
      Zhang, Rui  and
      Yang, Kai  and
      Yasunaga, Michihiro  and
      Wang, Dongxu  and
      Li, Zifan  and
      Ma, James  and
      Li, Irene  and
      Yao, Qingning  and
      Roman, Shanelle  and
      Zhang, Zilin  and
      Radev, Dragomir",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D18-1425",
    doi = "10.18653/v1/D18-1425",
    pages = "3911--3921",
    abstract = "We present \textit{Spider}, a large-scale complex and cross-domain semantic parsing and text-to-SQL dataset annotated by 11 college students. It consists of 10,181 questions and 5,693 unique complex SQL queries on 200 databases with multiple tables covering 138 different domains. We define a new complex and cross-domain semantic parsing and text-to-SQL task so that different complicated SQL queries and databases appear in train and test sets. In this way, the task requires the model to generalize well to both new SQL queries and new database schemas. Therefore, Spider is distinct from most of the previous semantic parsing tasks because they all use a single database and have the exact same program in the train set and the test set. We experiment with various state-of-the-art models and the best model achieves only 9.7{\%} exact matching accuracy on a database split setting. This shows that Spider presents a strong challenge for future research. Our dataset and task with the most recent updates are publicly available at \url{https://yale-lily.github.io/seq2sql/spider}.",
}


@inproceedings{wikisql,
  doi = {10.48550/ARXIV.1709.00103},
  
  url = {https://arxiv.org/abs/1709.00103},
  
  author = {Zhong, Victor and Xiong, Caiming and Socher, Richard},
  
  keywords = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Seq2SQL: Generating Structured Queries from Natural Language using Reinforcement Learning},
  
  publisher = {arXiv},

  booktitle = {arxiv preprint, arxiv/1709.00103.},
  year = {2017},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{smbop,
    title = "{S}m{B}o{P}: Semi-autoregressive Bottom-up Semantic Parsing",
    author = "Rubin, Ohad  and
      Berant, Jonathan",
    booktitle = "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.naacl-main.29",
    doi = "10.18653/v1/2021.naacl-main.29",
    pages = "311--324",
    abstract = "The de-facto standard decoding method for semantic parsing in recent years has been to autoregressively decode the abstract syntax tree of the target program using a top-down depth-first traversal. In this work, we propose an alternative approach: a Semi-autoregressive Bottom-up Parser (SmBoP) that constructs at decoding step t the top-K sub-trees of height {\mbox{$\leq$}} t. Our parser enjoys several benefits compared to top-down autoregressive parsing. From an efficiency perspective, bottom-up parsing allows to decode all sub-trees of a certain height in parallel, leading to logarithmic runtime complexity rather than linear. From a modeling perspective, a bottom-up parser learns representations for meaningful semantic sub-programs at each step, rather than for semantically-vacuous partial trees. We apply SmBoP on Spider, a challenging zero-shot semantic parsing benchmark, and show that SmBoP leads to a 2.2x speed-up in decoding time and a {\textasciitilde}5x speed-up in training time, compared to a semantic parser that uses autoregressive decoding. SmBoP obtains 71.1 denotation accuracy on Spider, establishing a new state-of-the-art, and 69.5 exact match, comparable to the 69.6 exact match of the autoregressive RAT-SQL+GraPPa.",
}

@article{gulwani2015inductive,
  title={Inductive programming meets the real world},
  author={Gulwani, Sumit and Hern{\'a}ndez-Orallo, Jos{\'e} and Kitzelmann, Emanuel and Muggleton, Stephen H and Schmid, Ute and Zorn, Benjamin},
  journal={Communications of the ACM},
  volume={58},
  number={11},
  pages={90--99},
  year={2015},
  publisher={ACM New York, NY, USA}
}

@inproceedings{jayagopal2022exploring,
  title={Exploring the learnability of program synthesizers by novice programmers},
  author={Jayagopal, Dhanya and Lubin, Justin and Chasins, Sarah E},
  booktitle={Proceedings of the 35th Annual ACM Symposium on User Interface Software and Technology},
  pages={1--15},
  year={2022}
}

@inproceedings{hu2021assuage,
  title={Assuage: Assembly synthesis using a guided exploration},
  author={Hu, Jingmei and Vaithilingam, Priyan and Chong, Stephen and Seltzer, Margo and Glassman, Elena L},
  booktitle={The 34th Annual ACM Symposium on User Interface Software and Technology},
  pages={134--148},
  year={2021}
}

@article{chen2021evaluating,
  title={Evaluating large language models trained on code},
  author={Chen, Mark and Tworek, Jerry and Jun, Heewoo and Yuan, Qiming and Pinto, Henrique Ponde de Oliveira and Kaplan, Jared and Edwards, Harri and Burda, Yuri and Joseph, Nicholas and Brockman, Greg and others},
  journal={arXiv preprint arXiv:2107.03374},
  year={2021}
}

@inproceedings{drosos2020wrex,
  title={Wrex: A unified programming-by-example interaction for synthesizing readable code for data scientists},
  author={Drosos, Ian and Barik, Titus and Guo, Philip J and DeLine, Robert and Gulwani, Sumit},
  booktitle={Proceedings of the 2020 CHI conference on human factors in computing systems},
  pages={1--12},
  year={2020}
}

@inproceedings{misp,
    title = "Model-based Interactive Semantic Parsing: A Unified Framework and A Text-to-{SQL} Case Study",
    author = "Yao, Ziyu  and
      Su, Yu  and
      Sun, Huan  and
      Yih, Wen-tau",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-1547",
    doi = "10.18653/v1/D19-1547",
    pages = "5447--5458",
    abstract = "As a promising paradigm, interactive semantic parsing has shown to improve both semantic parsing accuracy and user confidence in the results. In this paper, we propose a new, unified formulation of the interactive semantic parsing problem, where the goal is to design a model-based intelligent agent. The agent maintains its own state as the current predicted semantic parse, decides whether and where human intervention is needed, and generates a clarification question in natural language. A key part of the agent is a world model: it takes a percept (either an initial question or subsequent feedback from the user) and transitions to a new state. We then propose a simple yet remarkably effective instantiation of our framework, demonstrated on two text-to-SQL datasets (WikiSQL and Spider) with different state-of-the-art base semantic parsers. Compared to an existing interactive semantic parsing approach that treats the base parser as a black box, our approach solicits less user feedback but yields higher run-time accuracy.",
}

@inproceedings{nledit,
    title = "{NL}-{EDIT}: Correcting Semantic Parse Errors through Natural Language Interaction",
    author = "Elgohary, Ahmed  and
      Meek, Christopher  and
      Richardson, Matthew  and
      Fourney, Adam  and
      Ramos, Gonzalo  and
      Awadallah, Ahmed Hassan",
    booktitle = "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.naacl-main.444",
    doi = "10.18653/v1/2021.naacl-main.444",
    pages = "5599--5610",
    abstract = "We study semantic parsing in an interactive setting in which users correct errors with natural language feedback. We present NL-EDIT, a model for interpreting natural language feedback in the interaction context to generate a sequence of edits that can be applied to the initial parse to correct its errors. We show that NL-EDIT can boost the accuracy of existing text-to-SQL parsers by up to 20{\%} with only one turn of correction. We analyze the limitations of the model and discuss directions for improvement and evaluation. The code and datasets used in this paper are publicly available at http://aka.ms/NLEdit.",
}

@inproceedings{padhi2019overfitting,
  title={Overfitting in synthesis: Theory and practice},
  author={Padhi, Saswat and Millstein, Todd and Nori, Aditya and Sharma, Rahul},
  booktitle={International Conference on Computer Aided Verification},
  pages={315--334},
  year={2019},
  organization={Springer}
}

@inproceedings{lee2017towards,
  title={Towards understanding human mistakes of programming by example: an online user study},
  author={Lee, Tak Yeon and Dugan, Casey and Bederson, Benjamin B},
  booktitle={Proceedings of the 22Nd International Conference on Intelligent User Interfaces},
  pages={257--261},
  year={2017}
}

@inproceedings{splash,
    title = "Speak to your Parser: Interactive Text-to-{SQL} with Natural Language Feedback",
    author = "Elgohary, Ahmed  and
      Hosseini, Saghar  and
      Hassan Awadallah, Ahmed",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.187",
    doi = "10.18653/v1/2020.acl-main.187",
    pages = "2065--2077",
    abstract = "We study the task of semantic parse correction with natural language feedback. Given a natural language utterance, most semantic parsing systems pose the problem as one-shot translation where the utterance is mapped to a corresponding logical form. In this paper, we investigate a more interactive scenario where humans can further interact with the system by providing free-form natural language feedback to correct the system when it generates an inaccurate interpretation of an initial utterance. We focus on natural language to SQL systems and construct, SPLASH, a dataset of utterances, incorrect SQL interpretations and the corresponding natural language feedback. We compare various reference models for the correction task and show that incorporating such a rich form of feedback can significantly improve the overall semantic parsing accuracy while retaining the flexibility of natural language interaction. While we estimated human correction accuracy is 81.5{\%}, our best model achieves only 25.1{\%}, which leaves a large gap for improvement in future research. SPLASH is publicly available at https://aka.ms/Splash{\_}dataset.",
}


@inproceedings{diy,
author = {Narechania, Arpit and Fourney, Adam and Lee, Bongshin and Ramos, Gonzalo},
title = {DIY: Assessing the Correctness of Natural Language to SQL Systems},
year = {2021},
isbn = {9781450380171},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3397481.3450667},
doi = {10.1145/3397481.3450667},
abstract = {Designing natural language interfaces for querying databases remains an important goal pursued by researchers in natural language processing, databases, and HCI. These systems receive natural language as input, translate it into a formal database query, and execute the query to compute a result. Because the responses from these systems are not always correct, it is important to provide people with mechanisms to assess the correctness of the generated query and computed result. However, this assessment can be challenging for people who lack expertise in query languages. We present Debug-It-Yourself (DIY), an interactive technique that enables users to assess the responses from a state-of-the-art natural language to SQL (NL2SQL) system for correctness and, if possible, fix errors. DIY provides users with a sandbox where they can interact with (1) the mappings between the question and the generated query, (2) a small-but-relevant subset of the underlying database, and (3) a multi-modal explanation of the generated query. End-users can then employ a back-of-the-envelope calculation debugging strategy to evaluate the system’s response. Through an exploratory study with 12 users, we investigate how DIY helps users assess the correctness of the system’s answers and detect &amp; fix errors. Our observations reveal the benefits of DIY while providing insights about end-user debugging strategies and underscore opportunities for further improving the user experience.},
booktitle = {26th International Conference on Intelligent User Interfaces},
pages = {597–607},
numpages = {11},
keywords = {human computer interaction, natural language interface, database systems},
location = {College Station, TX, USA},
series = {IUI '21}
}

@inproceedings{dialsql,
    title = "{D}ial{SQL}: Dialogue Based Structured Query Generation",
    author = "Gur, Izzeddin  and
      Yavuz, Semih  and
      Su, Yu  and
      Yan, Xifeng",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P18-1124",
    doi = "10.18653/v1/P18-1124",
    pages = "1339--1349",
    abstract = "The recent advance in deep learning and semantic parsing has significantly improved the translation accuracy of natural language questions to structured queries. However, further improvement of the existing approaches turns out to be quite challenging. Rather than solely relying on algorithmic innovations, in this work, we introduce DialSQL, a dialogue-based structured query generation framework that leverages human intelligence to boost the performance of existing algorithms via user interaction. DialSQL is capable of identifying potential errors in a generated SQL query and asking users for validation via simple multi-choice questions. User feedback is then leveraged to revise the query. We design a generic simulator to bootstrap synthetic training dialogues and evaluate the performance of DialSQL on the WikiSQL dataset. Using SQLNet as a black box query generation tool, DialSQL improves its performance from 61.3{\%} to 69.0{\%} using only 2.4 validation questions per dialogue.",
}


@inproceedings{treesql,
author = {Wang, Xiaxia and Wu, Sai and Shou, Lidan and Chen, Ke},
title = {An Interactive NL2SQL Approach with Reuse Strategy},
year = {2021},
isbn = {978-3-030-73196-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-73197-7_19},
doi = {10.1007/978-3-030-73197-7_19},
abstract = {This paper studies a recently proposed task that maps contextual natural language questions to SQL queries in a multi-turn interaction. Instead of synthesizing an SQL query in an end-to-end way, we propose a new model which first generates an SQL grammar tree, called Tree-SQL, as the intermediate representation, and then infers an SQL query from the Tree-SQL with domain knowledge. For semantic dependency among context-dependent questions, we propose a reuse strategy that assigns a probability for each sub-tree of historical Tree-SQLs. On the challenging contextual Text-to-SQL benchmark SParC () with the ‘value selection’ task which includes values in queries, our approach achieves SOTA accuracy of 48.5% in question execution accuracy and 21.6% in interaction execution accuracy. In addition, we experimentally demonstrate the significant improvements on the reuse strategy.},
booktitle = {Database Systems for Advanced Applications: 26th International Conference, DASFAA 2021, Taipei, Taiwan, April 11–14, 2021, Proceedings, Part II},
pages = {280–288},
numpages = {9},
keywords = {Context-dependent semantic parsing, Intermediate representation, Reuse strategy},
location = {Taipei, Taiwan}
}

@inproceedings{ratsql,
    title = "{RAT-SQL}: Relation-Aware Schema Encoding and Linking for Text-to-{SQL} Parsers",
    author = "Wang, Bailin  and
      Shin, Richard  and
      Liu, Xiaodong  and
      Polozov, Oleksandr  and
      Richardson, Matthew",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.677",
    doi = "10.18653/v1/2020.acl-main.677",
    pages = "7567--7578",
    abstract = "When translating natural language questions into SQL queries to answer questions from a database, contemporary semantic parsing models struggle to generalize to unseen database schemas. The generalization challenge lies in (a) encoding the database relations in an accessible way for the semantic parser, and (b) modeling alignment between database columns and their mentions in a given query. We present a unified framework, based on the relation-aware self-attention mechanism, to address schema encoding, schema linking, and feature representation within a text-to-SQL encoder. On the challenging Spider dataset this framework boosts the exact match accuracy to 57.2{\%}, surpassing its best counterparts by 8.7{\%} absolute improvement. Further augmented with BERT, it achieves the new state-of-the-art performance of 65.6{\%} on the Spider leaderboard. In addition, we observe qualitative improvements in the model{'}s understanding of schema linking and alignment. Our implementation will be open-sourced at https://github.com/Microsoft/rat-sql.",
}

@inproceedings{picard,
    title = "{PICARD}: Parsing Incrementally for Constrained Auto-Regressive Decoding from Language Models",
    author = "Scholak, Torsten  and
      Schucher, Nathan  and
      Bahdanau, Dzmitry",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-main.779",
    doi = "10.18653/v1/2021.emnlp-main.779",
    pages = "9895--9901",
    abstract = "Large pre-trained language models for textual data have an unconstrained output space; at each decoding step, they can produce any of 10,000s of sub-word tokens. When fine-tuned to target constrained formal languages like SQL, these models often generate invalid code, rendering it unusable. We propose PICARD (code available at https://github.com/ElementAI/picard), a method for constraining auto-regressive decoders of language models through incremental parsing. PICARD helps to find valid output sequences by rejecting inadmissible tokens at each decoding step. On the challenging Spider and CoSQL text-to-SQL translation tasks, we show that PICARD transforms fine-tuned T5 models with passable performance into state-of-the-art solutions.",
}


@article{grappa,
  author    = {Tao Yu and
               Chien{-}Sheng Wu and
               Xi Victoria Lin and
               Bailin Wang and
               Yi Chern Tan and
               Xinyi Yang and
               Dragomir R. Radev and
               Richard Socher and
               Caiming Xiong},
  title     = {GraPPa: Grammar-Augmented Pre-Training for Table Semantic Parsing},
  journal   = {CoRR},
  volume    = {abs/2009.13845},
  year      = {2020},
  url       = {https://arxiv.org/abs/2009.13845},
  eprinttype = {arXiv},
  eprint    = {2009.13845},
  timestamp = {Sun, 02 Oct 2022 15:32:04 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2009-13845.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{fine-grained,
author = {Su, Yu and Hassan Awadallah, Ahmed and Wang, Miaosen and White, Ryen W.},
title = {Natural Language Interfaces with Fine-Grained User Interaction: A Case Study on Web APIs},
year = {2018},
isbn = {9781450356572},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3209978.3210013},
doi = {10.1145/3209978.3210013},
abstract = {The rapidly increasing ubiquity of computing puts a great demand on next-generation human-machine interfaces. Natural language interfaces, exemplified by virtual assistants like Apple Siri and Microsoft Cortana, are widely believed to be a promising direction. However, current natural language interfaces provide users with little help in case of incorrect interpretation of user commands. We hypothesize that the support of fine-grained user interaction can greatly improve the usability of natural language interfaces. In the specific setting of natural language interface to web APIs, we conduct a systematic study to verify our hypothesis. To facilitate this study, we propose a novel modular sequence-to-sequence model to create interactive natural language interfaces. By decomposing the complex prediction process of a typical sequence-to-sequence model into small, highly-specialized prediction units called modules, it becomes straightforward to explain the model prediction to the user, and solicit user feedback to correct possible prediction errors at a fine-grained level. We test our hypothesis by comparing an interactive natural language interface with its non-interactive version through both simulation and human subject experiments with real-world APIs. We show that with the interactive natural language interface, users can achieve a higher success rate and a lower task completion time, which lead to greatly improved user satisfaction.},
booktitle = {The 41st International ACM SIGIR Conference on Research \& Development in Information Retrieval},
pages = {855–864},
numpages = {10},
keywords = {natural language interface, user feedback, web api},
location = {Ann Arbor, MI, USA},
series = {SIGIR '18}
}

@inproceedings{-dialsql,
    title = "{D}ial{SQL}: Dialogue Based Structured Query Generation",
    author = "Gur, Izzeddin  and
      Yavuz, Semih  and
      Su, Yu  and
      Yan, Xifeng",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P18-1124",
    doi = "10.18653/v1/P18-1124",
    pages = "1339--1349",
    abstract = "The recent advance in deep learning and semantic parsing has significantly improved the translation accuracy of natural language questions to structured queries. However, further improvement of the existing approaches turns out to be quite challenging. Rather than solely relying on algorithmic innovations, in this work, we introduce DialSQL, a dialogue-based structured query generation framework that leverages human intelligence to boost the performance of existing algorithms via user interaction. DialSQL is capable of identifying potential errors in a generated SQL query and asking users for validation via simple multi-choice questions. User feedback is then leveraged to revise the query. We design a generic simulator to bootstrap synthetic training dialogues and evaluate the performance of DialSQL on the WikiSQL dataset. Using SQLNet as a black box query generation tool, DialSQL improves its performance from 61.3{\%} to 69.0{\%} using only 2.4 validation questions per dialogue.",
}

@inproceedings{binary,
    title = "Learning a Neural Semantic Parser from User Feedback",
    author = "Iyer, Srinivasan  and
      Konstas, Ioannis  and
      Cheung, Alvin  and
      Krishnamurthy, Jayant  and
      Zettlemoyer, Luke",
    booktitle = "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P17-1089",
    doi = "10.18653/v1/P17-1089",
    pages = "963--973",
    abstract = "We present an approach to rapidly and easily build natural language interfaces to databases for new domains, whose performance improves over time based on user feedback, and requires minimal intervention. To achieve this, we adapt neural sequence models to map utterances directly to SQL with its full expressivity, bypassing any intermediate meaning representations. These models are immediately deployed online to solicit feedback from real users to flag incorrect queries. Finally, the popularity of SQL facilitates gathering annotations for incorrect predictions using the crowd, which is directly used to improve our models. This complete feedback loop, without intermediate representations or database specific engineering, opens up new ways of building high quality semantic parsers. Experiments suggest that this approach can be deployed quickly for any new target domain, as we show by learning a semantic parser for an online academic database from scratch.",
}



@misc{scaling_law,
  doi = {10.48550/ARXIV.2001.08361},
  
  url = {https://arxiv.org/abs/2001.08361},
  
  author = {Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B. and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  
  keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Scaling Laws for Neural Language Models},
  
  publisher = {arXiv},
  
  year = {2020},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{construct_interface,
author = {Li, Fei and Jagadish, H. V.},
title = {Constructing an Interactive Natural Language Interface for Relational Databases},
year = {2014},
issue_date = {September 2014},
publisher = {VLDB Endowment},
volume = {8},
number = {1},
issn = {2150-8097},
url = {https://doi.org/10.14778/2735461.2735468},
doi = {10.14778/2735461.2735468},
abstract = {Natural language has been the holy grail of query interface designers, but has generally been considered too hard to work with, except in limited specific circumstances. In this paper, we describe the architecture of an interactive natural language query interface for relational databases. Through a carefully limited interaction with the user, we are able to correctly interpret complex natural language queries, in a generic manner across a range of domains. By these means, a logically complex English language sentence is correctly translated into a SQL query, which may include aggregation, nesting, and various types of joins, among other things, and can be evaluated against an RDBMS. We have constructed a system, NaLIR (Natural Language Interface for Relational databases), embodying these ideas. Our experimental assessment, through user studies, demonstrates that NaLIR is good enough to be usable in practice: even naive users are able to specify quite complex ad-hoc queries.},
journal = {Proc. VLDB Endow.},
month = {sep},
pages = {73–84},
numpages = {12}
}

@inproceedings{sqlova,
  doi = {10.48550/ARXIV.1902.01069},
  
  url = {https://arxiv.org/abs/1902.01069},
  
  author = {Hwang, Wonseok and Yim, Jinyeong and Park, Seunghyun and Seo, Minjoon},
  
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {A Comprehensive Exploration on WikiSQL with Table-Aware Word Contextualization},

  booktitle = {ArXiv preprint arXiv:1902.01069.},
  
  publisher = {arXiv},
  
  year = {2019},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{lunar,
author = {Woods, William and Kaplan, Ronald and Webber, Bonnie},
year = {1972},
month = {01},
pages = {},
title = {The Lunar Science Natural Language Information System: Final Report}
}

@article{quest,
author = {Bergamaschi, Sonia and Guerra, Francesco and Interlandi, Matteo and Trillo-Lado, Raquel and Velegrakis, Yannis},
title = {QUEST: A Keyword Search System for Relational Data Based on Semantic and Machine Learning Techniques},
year = {2013},
issue_date = {August 2013},
publisher = {VLDB Endowment},
volume = {6},
number = {12},
issn = {2150-8097},
url = {https://doi.org/10.14778/2536274.2536281},
doi = {10.14778/2536274.2536281},
abstract = {We showcase QUEST (QUEry generator for STructured sources), a search engine for relational databases that combines semantic and machine learning techniques for transforming keyword queries into meaningful SQL queries. The search engine relies on two approaches: the forward, providing mappings of keywords into database terms (names of tables and attributes, and domains of attributes), and the backward, computing the paths joining the data structures identified in the forward step. The results provided by the two approaches are combined within a probabilistic framework based on the Dempster-Shafer Theory. We demonstrate QUEST capabilities, and we show how, thanks to the flexibility obtained by the probabilistic combination of different techniques, QUEST is able to compute high quality results even with few training data and/or with hidden data sources such as those found in the Deep Web.},
journal = {Proc. VLDB Endow.},
month = {aug},
pages = {1222–1225},
numpages = {4}
}

@inproceedings{queryvis,
author = {Leventidis, Aristotelis and Zhang, Jiahui and Dunne, Cody and Gatterbauer, Wolfgang and Jagadish, H.V. and Riedewald, Mirek},
title = {QueryVis: Logic-Based Diagrams Help Users Understand Complicated SQL Queries Faster},
year = {2020},
isbn = {9781450367356},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3318464.3389767},
doi = {10.1145/3318464.3389767},
abstract = {Understanding the meaning of existing SQL queries is critical for code maintenance and reuse. Yet SQL can be hard to read, even for expert users or the original creator of a query. We conjecture that it is possible to capture the logical intent of queries in automatically-generated visual diagrams that can help users understand the meaning of queries faster and more accurately than SQL text alone. We present initial steps in that direction with visual diagrams that are based on the first-order logic foundation of SQL and can capture the meaning of deeply nested queries. Our diagrams build upon a rich history of diagrammatic reasoning systems in logic and were designed using a large body of human-computer interaction best practices: they are minimal in that no visual element is superfluous; they are unambiguous in that no two queries with different semantics map to the same visualization; and they extend previously existing visual representations of relational schemata and conjunctive queries in a natural way. An experimental evaluation involving 42 users on Amazon Mechanical Turk shows that with only a 2--3 minute static tutorial, participants could interpret queries meaningfully faster with our diagrams than when reading SQL alone. Moreover, we have evidence that our visual diagrams result in participants making fewer errors than with SQL. We believe that more regular exposure to diagrammatic representations of SQL can give rise to a pattern-based and thus more intuitive use and re-use of SQL. A full version of this paper with all appendices and supplemental material for the experimental study (stimuli, raw data, and analysis code) are available at https://osf.io/btszh.},
booktitle = {Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data},
pages = {2303–2318},
numpages = {16},
keywords = {query understanding, query interpretation, query patterns, first-order logic, database usability, nested queries, diagrammatic reasoning, user study, visualization design, SQL, visual query language, query visualization},
location = {Portland, OR, USA},
series = {SIGMOD '20}
}

@inproceedings{dbtalkback,
  doi = {10.48550/ARXIV.0909.1786},
  
  url = {https://arxiv.org/abs/0909.1786},
  
  author = {Simitsis, Alkis and Ioannidis, Yannis},
  
  keywords = {Databases (cs.DB), Human-Computer Interaction (cs.HC), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {DBMSs Should Talk Back Too},

  booktitle = {10.48550/ARXIV.0909.1786},

  publisher = {arXiv},
  
  year = {2009},
  
  copyright = {Creative Commons Attribution 3.0 Unported}
}

@inproceedings{logos,
author = {Kokkalis, Andreas and Vagenas, Panagiotis and Zervakis, Alexandros and Simitsis, Alkis and Koutrika, Georgia and Ioannidis, Yannis},
title = {Logos: A System for Translating Queries into Narratives},
year = {2012},
isbn = {9781450312479},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2213836.2213929},
doi = {10.1145/2213836.2213929},
abstract = {This paper presents Logos, a system that provides natural language translations for relational queries expressed in SQL. Our translation mechanism is based on a graph-based approach to the query translation problem. We represent various forms of structured queries as directed graphs and we annotate the graph edges with template labels using an extensible template mechanism. Logos uses different graph traversal strategies for efficiently exploring these graphs and composing textual query descriptions. The audience may interactively explore Logos using various database schemata and issuing either sample or ad hoc queries.},
booktitle = {Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data},
pages = {673–676},
numpages = {4},
keywords = {sql queries, natural language, query translation},
location = {Scottsdale, Arizona, USA},
series = {SIGMOD '12}
}

@inproceedings{webapi,
author = {Su, Yu and Awadallah, Ahmed Hassan and Khabsa, Madian and Pantel, Patrick and Gamon, Michael and Encarnacion, Mark},
title = {Building Natural Language Interfaces to Web APIs},
year = {2017},
isbn = {9781450349185},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3132847.3133009},
doi = {10.1145/3132847.3133009},
abstract = {As the Web evolves towards a service-oriented architecture, application program interfaces (APIs) are becoming an increasingly important way to provide access to data, services, and devices. We study the problem of natural language interface to APIs (NL2APIs), with a focus on web APIs for web services. Such NL2APIs have many potential benefits, for example, facilitating the integration of web services into virtual assistants.We propose the first end-to-end framework to build an NL2API for a given web API. A key challenge is to collect training data, i.e., NL command-API call pairs, from which an NL2API can learn the semantic mapping from ambiguous, informal NL commands to formal API calls. We propose a novel approach to collect training data for NL2API via crowdsourcing, where crowd workers are employed to generate diversified NL commands. We optimize the crowdsourcing process to further reduce the cost. More specifically, we propose a novel hierarchical probabilistic model for the crowdsourcing process, which guides us to allocate budget to those API calls that have a high value for training NL2APIs. We apply our framework to real-world APIs, and show that it can collect high-quality training data at a low cost, and build NL2APIs with good performance from scratch. We also show that our modeling of the crowdsourcing process can improve its effectiveness, such that the training data collected via our approach leads to better performance of NL2APIs than a strong baseline.},
booktitle = {Proceedings of the 2017 ACM on Conference on Information and Knowledge Management},
pages = {177–186},
numpages = {10},
keywords = {hierarchical probabilistic model, web api, crowdsourcing, natural language interface},
location = {Singapore, Singapore},
series = {CIKM '17}
}

@INPROCEEDINGS{sqlvis,  author={Miedema, Daphne and Fletcher, George},  booktitle={2021 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC)},   title={SQLVis: Visual Query Representations for Supporting SQL Learners},   year={2021},  volume={},  number={},  pages={1-9},  doi={10.1109/VL/HCC51201.2021.9576431}}

@INPROCEEDINGS{explaininnl,  author={Koutrika, Georgia and Simitsis, Alkis and Ioannidis, Yannis E.},  booktitle={2010 IEEE 26th International Conference on Data Engineering (ICDE 2010)},   title={Explaining structured queries in natural language},   year={2010},  volume={},  number={},  pages={333-344},  doi={10.1109/ICDE.2010.5447824}}

@inproceedings{piia,
    title = "{``}What Do You Mean by That?{''} A Parser-Independent Interactive Approach for Enhancing Text-to-{SQL}",
    author = "Li, Yuntao  and
      Chen, Bei  and
      Liu, Qian  and
      Gao, Yan  and
      Lou, Jian-Guang  and
      Zhang, Yan  and
      Zhang, Dongmei",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.561",
    doi = "10.18653/v1/2020.emnlp-main.561",
    pages = "6913--6922",
    abstract = "In Natural Language Interfaces to Databases systems, the text-to-SQL technique allows users to query databases by using natural language questions. Though significant progress in this area has been made recently, most parsers may fall short when they are deployed in real systems. One main reason stems from the difficulty of fully understanding the users{'} natural language questions. In this paper, we include human in the loop and present a novel parser-independent interactive approach (PIIA) that interacts with users using multi-choice questions and can easily work with arbitrary parsers. Experiments were conducted on two cross-domain datasets, the WikiSQL and the more complex Spider, with five state-of-the-art parsers. These demonstrated that PIIA is capable of enhancing the text-to-SQL performance with limited interaction turns by using both simulation and human evaluation.",
}


@article{quillbot,
	author = {Tira Fitria},
	title = {QuillBot as an online tool: Students’ alternative in paraphrasing and rewriting of English writing},
	journal = {Englisia: Journal of Language, Education, and Humanities},
	volume = {9},
	number = {1},
	year = {2021},
	keywords = {QuillBot; Artificial intelligence (AI); Online tool; Writing; Paraphrasing},
	abstract = {QuillBot is an online application to paraphrase writing, avoid plagiarism, summarize long sentences and improve grammar to be more precise and look professional. The objective of this research is to review the QuillBot as an Artificial Intelligence (AI) tool system for students’ in paraphrasing and rewriting English writing both in the free and premium versions. This research applies descriptive qualitative. The data used is an English abstract article. The results show that QuillBot paraphrasing tools use several ways to paraphrase the text: 1) paraphrasing by using equations or synonyms, 2) paraphrasing by changing the form of the word, 3) paraphrasing by using active or passive sentences, and 4) paraphrasing by changing the order of words in sentences. This paraphrasing uses Standard Mode, which serves to balance changes to the text when users input them but still keeps them from changing the actual (original) meaning of the text, also making the result look more original. QuillBot is one of the paraphrasings and summarizing tools that can be used by students for rewriting any content based on a state-of-the-art AI system. This tool can be the students’ alternative which provides a solution by helping paraphrase when students do not have the idea to paraphrase English writing manually. However, a good knowledge of vocabulary and understanding of English grammar, of course, will help students or other users (s) both in using online or manual paraphrasing to be better or the best quality.},
	issn = {2527-6484},	pages = {183--196},	doi = {10.22373/ej.v9i1.10233},
	url = {https://jurnal.ar-raniry.ac.id/index.php/englisia/article/view/10233}
}

@inproceedings{zhang2019editing,
  title={Editing-Based SQL Query Generation for Cross-Domain Context-Dependent Questions},
  author={Zhang, Rui and Yu, Tao and Er, Heyang and Shim, Sungrok and Xue, Eric and Lin, Xi Victoria and Shi, Tianze and Xiong, Caiming and Socher, Richard and Radev, Dragomir},
  booktitle={Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
  pages={5338--5349},
  year={2019}
}


@article{sqlnet,
  author    = {Xiaojun Xu and
               Chang Liu and
               Dawn Song},
  title     = {SQLNet: Generating Structured Queries From Natural Language Without
               Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1711.04436},
  year      = {2017},
  url       = {http://arxiv.org/abs/1711.04436},
  eprinttype = {arXiv},
  eprint    = {1711.04436},
  timestamp = {Mon, 22 Jul 2019 13:37:30 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1711-04436.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{andreas2020task,
  title={Task-oriented dialogue as dataflow synthesis},
  author={Andreas, Jacob and Bufe, John and Burkett, David and Chen, Charles and Clausman, Josh and Crawford, Jean and Crim, Kate and DeLoach, Jordan and Dorner, Leah and Eisner, Jason and others},
  journal={Transactions of the Association for Computational Linguistics},
  volume={8},
  pages={556--571},
  year={2020},
  publisher={MIT Press}
}

@inproceedings{sparc,
    title = "{SP}ar{C}: Cross-Domain Semantic Parsing in Context",
    author = "Yu, Tao  and
      Zhang, Rui  and
      Yasunaga, Michihiro  and
      Tan, Yi Chern  and
      Lin, Xi Victoria  and
      Li, Suyi  and
      Er, Heyang  and
      Li, Irene  and
      Pang, Bo  and
      Chen, Tao  and
      Ji, Emily  and
      Dixit, Shreya  and
      Proctor, David  and
      Shim, Sungrok  and
      Kraft, Jonathan  and
      Zhang, Vincent  and
      Xiong, Caiming  and
      Socher, Richard  and
      Radev, Dragomir",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1443",
    doi = "10.18653/v1/P19-1443",
    pages = "4511--4523",
    abstract = "We present SParC, a dataset for cross-domainSemanticParsing inContext that consists of 4,298 coherent question sequences (12k+ individual questions annotated with SQL queries). It is obtained from controlled user interactions with 200 complex databases over 138 domains. We provide an in-depth analysis of SParC and show that it introduces new challenges compared to existing datasets. SParC demonstrates complex contextual dependencies, (2) has greater semantic diversity, and (3) requires generalization to unseen domains due to its cross-domain nature and the unseen databases at test time. We experiment with two state-of-the-art text-to-SQL models adapted to the context-dependent, cross-domain setup. The best model obtains an exact match accuracy of 20.2{\%} over all questions and less than10{\%} over all interaction sequences, indicating that the cross-domain setting and the con-textual phenomena of the dataset present significant challenges for future research. The dataset, baselines, and leaderboard are released at https://yale-lily.github.io/sparc.",
}

@inproceedings{cosql,
    title = "{C}o{SQL}: A Conversational Text-to-{SQL} Challenge Towards Cross-Domain Natural Language Interfaces to Databases",
    author = "Yu, Tao  and
      Zhang, Rui  and
      Er, Heyang  and
      Li, Suyi  and
      Xue, Eric  and
      Pang, Bo  and
      Lin, Xi Victoria  and
      Tan, Yi Chern  and
      Shi, Tianze  and
      Li, Zihan  and
      Jiang, Youxuan  and
      Yasunaga, Michihiro  and
      Shim, Sungrok  and
      Chen, Tao  and
      Fabbri, Alexander  and
      Li, Zifan  and
      Chen, Luyao  and
      Zhang, Yuwen  and
      Dixit, Shreya  and
      Zhang, Vincent  and
      Xiong, Caiming  and
      Socher, Richard  and
      Lasecki, Walter  and
      Radev, Dragomir",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-1204",
    doi = "10.18653/v1/D19-1204",
    pages = "1962--1979",
    abstract = "We present CoSQL, a corpus for building cross-domain, general-purpose database (DB) querying dialogue systems. It consists of 30k+ turns plus 10k+ annotated SQL queries, obtained from a Wizard-of-Oz (WOZ) collection of 3k dialogues querying 200 complex DBs spanning 138 domains. Each dialogue simulates a real-world DB query scenario with a crowd worker as a user exploring the DB and a SQL expert retrieving answers with SQL, clarifying ambiguous questions, or otherwise informing of unanswerable questions. When user questions are answerable by SQL, the expert describes the SQL and execution results to the user, hence maintaining a natural interaction flow. CoSQL introduces new challenges compared to existing task-oriented dialogue datasets: (1) the dialogue states are grounded in SQL, a domain-independent executable representation, instead of domain-specific slot value pairs, and (2) because testing is done on unseen databases, success requires generalizing to new domains. CoSQL includes three tasks: SQL-grounded dialogue state tracking, response generation from query results, and user dialogue act prediction. We evaluate a set of strong baselines for each task and show that CoSQL presents significant challenges for future research. The dataset, baselines, and leaderboard will be released at https://yale-lily.github.io/cosql.",
}

@inproceedings{guo2021chase,
  title={CHASE: A Large-Scale and Pragmatic Chinese Dataset for Cross-Database Context-Dependent Text-to-SQL},
  author={Guo, Jiaqi and Si, Ziliang and Wang, Yu and Liu, Qian and Fan, Ming and Lou, Jian-Guang and Yang, Zijiang and Liu, Ting},
  booktitle={Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
  pages={2316--2331},
  year={2021}
}

@inproceedings{hui2021dynamic,
  title={Dynamic hybrid relation exploration network for cross-domain context-dependent semantic parsing},
  author={Hui, Binyuan and Geng, Ruiying and Ren, Qiyu and Li, Binhua and Li, Yongbin and Sun, Jian and Huang, Fei and Si, Luo and Zhu, Pengfei and Zhu, Xiaodan},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={14},
  pages={13116--13124},
  year={2021}
}

@inproceedings{cai2020igsql,
  title={IGSQL: Database Schema Interaction Graph Based Neural Model for Context-Dependent Text-to-SQL Generation},
  author={Cai, Yitao and Wan, Xiaojun},
  booktitle={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  pages={6903--6912},
  year={2020}
}

@inproceedings{wang2021tracking,
  title={Tracking interaction states for multi-turn text-to-sql semantic parsing},
  author={Wang, Run-Ze and Ling, Zhen-Hua and Zhou, Jingbo and Hu, Yu},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={16},
  pages={13979--13987},
  year={2021}
}


@article{needleman,
title = {A general method applicable to the search for similarities in the amino acid sequence of two proteins},
journal = {Journal of Molecular Biology},
volume = {48},
number = {3},
pages = {443-453},
year = {1970},
issn = {0022-2836},
doi = {https://doi.org/10.1016/0022-2836(70)90057-4},
url = {https://www.sciencedirect.com/science/article/pii/0022283670900574},
author = {Saul B. Needleman and Christian D. Wunsch},
abstract = {A computer adaptable method for finding similarities in the amino acid sequences of two proteins has been developed. From these findings it is possible to determine whether significant homology exists between the proteins. This information is used to trace their possible evolutionary development. The maximum match is a number dependent upon the similarity of the sequences. One of its definitions is the largest number of amino acids of one protein that can be matched with those of a second protein allowing for all possible interruptions in either of the sequences. While the interruptions give rise to a very large number of comparisons, the method efficiently excludes from consideration those comparisons that cannot contribute to the maximum match. Comparisons are made from the smallest unit of significance, a pair of amino acids, one from each protein. All possible pairs are represented by a two-dimensional array, and all possible comparisons are represented by pathways through the array. For this maximum match only certain of the possible pathways must be evaluated. A numerical value, one in this case, is assigned to every cell in the array representing like amino acids. The maximum match is the largest number that would result from summing the cell values of every pathway.}
}


@inproceedings{SPARQL,
author = {Ngonga Ngomo, Axel-Cyrille and B\"{u}hmann, Lorenz and Unger, Christina and Lehmann, Jens and Gerber, Daniel},
title = {SPARQL2NL: Verbalizing Sparql Queries},
year = {2013},
isbn = {9781450320382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2487788.2487936},
doi = {10.1145/2487788.2487936},
abstract = {Linked Data technologies are now being employed by a large number of applications. While experts can query the backend of these applications using the standard query language SPARQL, most lay users lack the expertise necessary to proficiently interact with these applications. Consequently, non-expert users usually have to rely on forms, query builders, question answering or keyword search tools to access RDF data. Yet, these tools are usually unable to make the meaning of the queries they generate plain to lay users, making it difficult for these users to i) assess the correctness of the query generated out of their input, and ii) to adapt their queries or iii) to choose in an informed manner between possible interpretations of their input.We present SPARQL2NL, a generic approach that allows verbalizing SPARQL queries, i.e., converting them into natural language. In addition to generating verbalizations, our approach can also explain the output of queries by providing a natural-language description of the reasons that led to each element of the result set being selected. Our evaluation of SPARQL2NL within a large-scale user survey shows that SPARQL2NL generates complete and easily understandable natural language descriptions. In addition, our results suggest that even SPARQL experts can process the natural language representation of SPARQL queries computed by our approach more efficiently than the corresponding SPARQL queries. Moreover, non-experts are enabled to reliably understand the content of SPARQL queries. Within the demo, we present the results generated by our approach on arbitrary questions to the DBpedia and MusicBrainz datasets. Moreover, we present how our framework can be used to explain results of SPARQL queries in natural language},
booktitle = {Proceedings of the 22nd International Conference on World Wide Web},
pages = {329–332},
numpages = {4},
keywords = {query verbalization, natural language generation, sparql},
location = {Rio de Janeiro, Brazil},
series = {WWW '13 Companion}
}

@inproceedings{graph-data-management-HCI,
  author    = {Sourav S. Bhowmick},
  editor    = {Hendrik Decker and
               Lenka Lhotsk{\'{a}} and
               Sebastian Link and
               Marcus Spies and
               Roland R. Wagner},
  title     = {{DB} {\(\bowtie\)} {HCI:} Towards Bridging the Chasm between Graph
               Data Management and {HCI}},
  booktitle = {Database and Expert Systems Applications - 25th International Conference,
               {DEXA} 2014, Munich, Germany, September 1-4, 2014. Proceedings, Part
               {I}},
  series    = {Lecture Notes in Computer Science},
  volume    = {8644},
  pages     = {1--11},
  publisher = {Springer},
  year      = {2014},
  url       = {https://doi.org/10.1007/978-3-319-10073-9\_1},
  doi       = {10.1007/978-3-319-10073-9\_1},
  timestamp = {Sun, 25 Oct 2020 22:45:34 +0100},
  biburl    = {https://dblp.org/rec/conf/dexa/Bhowmick14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{10.1145/273133.274318,
author = {Mitrovic, Antonija},
title = {Learning SQL with a Computerized Tutor},
year = {1998},
isbn = {0897919947},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/273133.274318},
doi = {10.1145/273133.274318},
abstract = {SQL, the dominant database language, is a simple and highly structured language; yet, students have many difficulties learning it. This paper presents SQL-Tutor, an Intelligent Teaching System designed as a guided discovery learning environment, which helps students in overcoming these difficulties. We present design issues and the current state in the implementation of the system, with special focus on individualization of instruction towards a particular student.},
booktitle = {Proceedings of the Twenty-Ninth SIGCSE Technical Symposium on Computer Science Education},
pages = {307–311},
numpages = {5},
location = {Atlanta, Georgia, USA},
series = {SIGCSE '98}
}

@article{sqltutor,
author = {Mitrovic, Antonija},
title = {Learning SQL with a Computerized Tutor},
year = {1998},
issue_date = {Mar. 1998},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {30},
number = {1},
issn = {0097-8418},
url = {https://doi.org/10.1145/274790.274318},
doi = {10.1145/274790.274318},
abstract = {SQL, the dominant database language, is a simple and highly structured language; yet, students have many difficulties learning it. This paper presents SQL-Tutor, an Intelligent Teaching System designed as a guided discovery learning environment, which helps students in overcoming these difficulties. We present design issues and the current state in the implementation of the system, with special focus on individualization of instruction towards a particular student.},
journal = {SIGCSE Bull.},
month = {mar},
pages = {307–311},
numpages = {5}
}

@article{visual-representations-in-science-education,
author = {Cook, Michelle Patrick},
title = {Visual representations in science education: The influence of prior knowledge and cognitive load theory on instructional design principles},
journal = {Science Education},
volume = {90},
number = {6},
pages = {1073-1091},
doi = {https://doi.org/10.1002/sce.20164},
url = {https://onlinelQuestion Generation from SQL Queries Improves Neural Semantic Parsingibrary.wiley.com/doi/abs/10.1002/sce.20164},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/sce.20164},
abstract = {Abstract Visual representations are essential for communicating ideas in the science classroom; however, the design of such representations is not always beneficial for learners. This paper presents instructional design considerations providing empirical evidence and integrating theoretical concepts related to cognitive load. Learners have a limited working memory, and instructional representations should be designed with the goal of reducing unnecessary cognitive load. However, cognitive architecture alone is not the only factor to be considered; individual differences, especially prior knowledge, are critical in determining what impact a visual representation will have on learners' cognitive structures and processes. Prior knowledge can determine the ease with which learners can perceive and interpret visual representations in working memory. Although a long tradition of research has compared experts and novices, more research is necessary to fully explore the expert–novice continuum and maximize the potential of visual representations. © 2006 Wiley Periodicals, Inc. Sci Ed 90:1073–1091, 2006},
year = {2006}
}


@article{3-important-determinants,
author = {CHAN, HOCK C. and TAN, BERNARD C.Y. and WEI, KWOK-KEE},
title = {Three Important Determinants of User Performance for Database Retrieval},
year = {1999},
issue_date = {Nov. 1999},
publisher = {Academic Press, Inc.},
address = {USA},
volume = {51},
number = {5},
issn = {1071-5819},
url = {https://doi.org/10.1006/ijhc.1999.0272},
doi = {10.1006/ijhc.1999.0272},
abstract = {Three important factors that determine user performance during database retrieval are representation realism, expressive ease, and task complexity. Representation realism is the level of abstraction used when formulating queries. Expressive ease is the syntactic flexibility permitted when formulating queries. Task complexity is the level of difficulty of queries. A controlled laboratory experiment was conducted to assess the effects of these three factors on user productivity during database retrieval. The independent variables were representation realism (high versus low), expressive ease (high versus low), and query complexity (simple versus complex). The dependent variables were query accuracy and query time. Results show that all these three factors significantly affected user performance during database retrieval. However, their relative impact on query accuracy and query time differed. Moreover, these factors interacted in unique ways to moderate query accuracy and query time. Besides verifying prior empirical findings, these results offer several suggestions for future research and development work in the area of database retrieval.},
journal = {Int. J. Hum.-Comput. Stud.},
month = {nov},
pages = {895–918},
numpages = {24}
}

@inproceedings{casual-user,
author = {Ogden, William C. and Brooks, Susan R.},
title = {Query Languages for the Casual User: Exploring the Middle Ground between Formal and Natural Languages},
year = {1983},
isbn = {0897911210},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/800045.801602},
doi = {10.1145/800045.801602},
abstract = {In the past the non-programmer who wanted the information contained in a computer database had to employ an expert programmer knowledgeable in the language and structure of the database. Now languages are being developed that are designed to be used by an infrequent or “casual” user who has limited knowledge of how the data is stored or retrieved by the computer. These special purpose query languages which allow these casual users to retrieve information from computer databases are commonly referred to as “nonprocedural” (Leavenworth and Sammet, 1974) because users need only describe the data to be retrieved, not how it is to be retrieved. These languages can be classified into two basic types which are characterized by the level of constraint imposed on the syntax and vocabulary of the language (Ehrenreich, 1981). Formal query languages have a very constrained syntax and vocabulary, while natural query languages have a relatively unconstrained syntax and vocabulary.If we consider the level of constraint that can be imposed on a query language as a continuum, then formal and natural query languages represent the two ends of this continuum. There has been considerable debate over the issue of which end of this continuum best meets the needs of the casual database user (e.g. Hill, 1972; Petrick, 1976; Shneiderman, 1980). Proponents of formal languages contend that these users benefit from learning a constrained language which teaches a concise and unambiguous way of communicating with the computer. Proponents of natural languages, on the other hand, contend that more people would be able to access database information if they could use their own natural languages. Evidence from studies of the use of some of these query languages however, indicate that neither formal, nor natural languages are easy to use. These studies suggest that the casual user will have difficulty operating at either end of the level-of-constraint continuum.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {161–165},
numpages = {5},
location = {Boston, Massachusetts, USA},
series = {CHI '83}
}


@InProceedings{software-psychology,
author="Leventhal, Laura Marie
and Mynatt, Barbee T.",
editor="Ford, Gary A.",
title="A scarce resource in undergraduate software engineering courses: User interface design materials",
booktitle="Software Engineering Education",
year="1988",
publisher="Springer New York",
address="New York, NY",
pages="187--198",
abstract="A recent survey by Leventhal and Mynatt (1987) has suggested that user interface issues have become one of the major topics in undergraduate software engineering courses. In their view, this emphasis potentially presents numerous difficulties for the software engineering educator. In particular, issues of instructor training and availability of suitable materials arise as problem areas. In order to more effectively incorporate user interface concepts into undergraduate software engineering courses, a compact body of material has been developed. This body of material incorporates both practical guidelines to interface design, and discussion of a major theoretical issue in interface design. The material is described in some detail, and observations about its usefulness are included.",
isbn="978-0-387-34779-0"
}

@inproceedings{human-factor-NLQ,
author = {Ogden, William C.},
title = {The Human Factors of Natural Language Query Systems},
year = {1985},
isbn = {0897911504},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/320599.320670},
doi = {10.1145/320599.320670},
abstract = {Understanding the hidden limitations and constraints of the system is the largest potential problem for users of natural language query (NLQ). By their nature, most NLQ systems hide “how it works” because they are intended for users who do not want to know. However, human factors research indicates that when users do not have a good understanding of a system, the behavior of the system becomes unpredictable. For example, consider the two natural language questions: “Which students have more than 20 credits?” and “Which students have more than 20 courses?” Some NLQ systems may be able to answer the first but not the second question and when the user knows that both answers can be derived from the database, the system appears to be inconsistent. To be able to use this type of NLQ system effectively, a user will have to learn the hidden system constraints that produce this type of inconsistency. There are two approaches to minimize the impact of the hidden constraints. One approach is to customize the linguistic coverage of the NLQ system for a particular user population so that most of their questions can be processed correctly. Another approach that is being investigated in our laboratory is to explicitly define a learnable and memorable subset of the language so that the limitations and constraints will no longer be hidden.The first approach may not guarantee a solution. In order to gain good linguistic coverage of a domain, the system must initially have a powerful enough linguistic capability to be able to represent a deep structure of the processed sentence. In addition, however, the grammar and lexicon needs to be augmented with semantic and pragmatic information about the task domain and linguistic requirement of the users. For each application of a NLQ system a great deal of effort is required to capture, define and enter this information into the system. This requires a user who is knowledgeable about how to acquire this information and how to translate this information into the form required by the NLQ program. Thus, the human factors of the NLQ application depends on the ability of knowledgeable users to initially supply this information to the system as well as their ability to maintain the system as it changes and as the needs of the users change. It is unlikely that this ability will be uniformly present in all environments in which a NLQ system could be applied. Therefore this approach to solving the human factors problem of these systems will likely produce mixed results. This approach, then, may be feasible only in situations where a great deal of work has been done at understanding the task domain such as in the domains in which expert systems have been developed.The second approach may not be in the spirit of providing unconstrained natural language to end user populations, but it is an approach that promises to be a more general solution to the human factors problems associated with NLQ systems. By restricting users to a memorable subset of natural language we are taking the burden off of the computer system (and the programmers ability to customize it) and are shifting the burden to the user who will have to learn and remember how to restrict their own natural language. However, the burden that we shift to the user should be a light one. Humans are naturally skillful at processing language and in our laboratory we are exploring what kinds of language restrictions are easy for a user to follow.Our approach is empirical. A general methodology for obtaining a usable subset of English for query could consist of the following steps: Determine users' natural form of question asking within a database application domain.Select a subset which can be expressed as rules to be learned and followed.Test users, identifying which rules can or cannot be easily followed.Iterate the previous steps until all rules can be followed and users can still express all required retrieval requests.Move to other database applications.We feel all steps are important. For example, rules not based on users' natural forms of question asking will likely not be successful. Similarly, English subsets based on users' natural forms may not be successful unless the rules are communicable to the user.A major obstacle to overcome in the study of natural forms of question writing, is to develop a task that does not bias the subjects' natural language. To overcome this problem, some researchers have given subjects open-ended problem statements that require many questions to solve. This is adequate for studying connected discourse, but the experimenter has very little control over the types of questions that can be asked. In our studies, we wanted to be able to ensure that the users would be able to express all of the data retrieval functions that are currently available in existing formal query languages. Thus, we needed to control the types of questions that subjects would be required to enter.To meet these needs, we presented forms to subjects that contained information that was obtainable from the database. On each form some of the information was missing however, and it was the subject's task to type a question that would retrieve the missing information. The form contained enough context to indicate the retrieval keys but not enough to bias the syntax of the user's question. This technique did, of course, bias the vocabulary the subjects used. However, this bias was in a direction which represented knowledge actual users normally have about the database they use. Thus, query writing performance would not be affected by the subject's inability to think of appropriate task-related questions.The forms were constructed to represent all of the data retrieval capability contained in a powerful formal query language such as SQL. Thus, they represented questions that were based on a relational database consisting of six tables of information about a hypothetical college, including information about students, faculty, courses, and departments. Therefore, all questions which were represented on the forms had analogous SQL solutions and covered the full range of SQL function.Our research examined the effects that various sets of restrictions would have on the types of syntactical constructions subjects would use to express the questions indicated on the forms. The first set of studies imposed a vocabulary restriction on subject's responses. They could use only the pre-defined names of the attributes in the database but they had no restriction on how they could combine these words into a sentence. The results showed that performance was very poor. Thus, vocabulary restrictions of the type that are commonly imposed by formal query languages create difficulties for the user.The second set of studies removed the vocabulary restrictions and showed that a large percentage of the natural queries that our subjects produced could be described with a limited set of grammatical rules. A parser based on these rules was implemented and a simple set of instructions were given to a new set of subjects. These subjects showed that they could follow the instructions and could restrict the grammatical form of their questions to the subset selected. Thus, these results indicated that users would be able to learn to use a natural subset of English for database query when the syntactic rules were exposed.However, it became clear that even when the subjects could restrict their questions using the syntactic rules of this natural subset, a NLQ system would still require a significant amount semantic and pragmatic knowledge to be able process the questions that were asked. Thus, a large amount of customization would still be required. Therefore, the next phase of experimentation was focused on discovering the types of semantic restrictions that users would be able to learn and remember.In addition to the syntactic restrictions, new subjects were asked to include more semantic information in their questions. Specifically, they were given a model of the database and asked to include the name or a synonym of the name of the attribute associated with each database value expressed in the query. Thus, instead of asking “What is the major of David Lee,” subjects were required to ask “What is the major of the student David Lee.” The results showed that users could easily specify the attribute name when selecting on a particular value of that attribute but had difficulty specifying the name when the attribute was used to calculate a value not in the database. For example, user had trouble expressing the concept of a “full class” as a class with “size greater than or equal to limit.”These results suggest that any database query system which is intended to be for general use (i.e. transportable across application domains) will require that it's users have a good understanding of what is in the database so that they will know what attributes of the data they can refer to. This suggests that a well human factored database query systems will exposed in a natural way the underlying structure of the database and then to allow a flexible vocabulary to be used to reference the items in the database that they know about.},
booktitle = {Proceedings of the 1985 ACM Thirteenth Annual Conference on Computer Science},
pages = {174–175},
numpages = {2},
location = {New Orleans, Louisiana, USA},
series = {CSC '85}
}

@article{where-are-we,
author = {Kim, Hyeonji and So, Byeong-Hoon and Han, Wook-Shin and Lee, Hongrae},
title = {Natural Language to SQL: Where Are We Today?},
year = {2020},
issue_date = {June 2020},
publisher = {VLDB Endowment},
volume = {13},
number = {10},
issn = {2150-8097},
url = {https://doi.org/10.14778/3401960.3401970},
doi = {10.14778/3401960.3401970},
abstract = {Translating natural language to SQL (NL2SQL) has received extensive attention lately, especially with the recent success of deep learning technologies. However, despite the large number of studies, we do not have a thorough understanding of how good existing techniques really are and how much is applicable to real-world situations. A key difficulty is that different studies are based on different datasets, which often have their own limitations and assumptions that are implicitly hidden in the context or datasets. Moreover, a couple of evaluation metrics are commonly employed but they are rather simplistic and do not properly depict the accuracy of results, as will be shown in our experiments. To provide a holistic view of NL2SQL technologies and access current advancements, we perform extensive experiments under our unified framework using eleven of recent techniques over 10+ benchmarks including a new benchmark (WTQ) and TPC-H. We provide a comprehensive survey of recent NL2SQL methods, introducing a taxonomy of them. We reveal major assumptions of the methods and classify translation errors through extensive experiments. We also provide a practical tool for validation by using existing, mature database technologies such as query rewrite and database testing. We then suggest future research directions so that the translation can be used in practice.},
journal = {Proc. VLDB Endow.},
month = {jun},
pages = {1737–1750},
numpages = {14}
}

@inproceedings{editsql,
    title = "Editing-Based {SQL} Query Generation for Cross-Domain Context-Dependent Questions",
    author = "Zhang, Rui  and
      Yu, Tao  and
      Er, Heyang  and
      Shim, Sungrok  and
      Xue, Eric  and
      Lin, Xi Victoria  and
      Shi, Tianze  and
      Xiong, Caiming  and
      Socher, Richard  and
      Radev, Dragomir",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-1537",
    doi = "10.18653/v1/D19-1537",
    pages = "5338--5349",
    abstract = "We focus on the cross-domain context-dependent text-to-SQL generation task. Based on the observation that adjacent natural language questions are often linguistically dependent and their corresponding SQL queries tend to overlap, we utilize the interaction history by editing the previous predicted query to improve the generation quality. Our editing mechanism views SQL as sequences and reuses generation results at the token level in a simple manner. It is flexible to change individual tokens and robust to error propagation. Furthermore, to deal with complex table structures in different domains, we employ an utterance-table encoder and a table-aware decoder to incorporate the context of the user utterance and the table schema. We evaluate our approach on the SParC dataset and demonstrate the benefit of editing compared with the state-of-the-art baselines which generate SQL from scratch. Our code is available at \url{https://github.com/ryanzhumich/sparc_atis_pytorch}.",
}

@inproceedings{gazp,
    title = "Grounded Adaptation for Zero-shot Executable Semantic Parsing",
    author = "Zhong, Victor  and
      Lewis, Mike  and
      Wang, Sida I.  and
      Zettlemoyer, Luke",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.558",
    doi = "10.18653/v1/2020.emnlp-main.558",
    pages = "6869--6882",
    abstract = "We propose Grounded Adaptation for Zeroshot Executable Semantic Parsing (GAZP) to adapt an existing semantic parser to new environments (e.g. new database schemas). GAZP combines a forward semantic parser with a backward utterance generator to synthesize data (e.g. utterances and SQL queries) in the new environment, then selects cycle-consistent examples to adapt the parser. Unlike data-augmentation, which typically synthesizes unverified examples in the training environment, GAZP synthesizes examples in the new environment whose input-output consistency are verified through execution. On the Spider, Sparc, and CoSQL zero-shot semantic parsing tasks, GAZP improves logical form and execution accuracy of the baseline parser. Our analyses show that GAZP outperforms data-augmentation in the training environment, performance increases with the amount of GAZP-synthesized data, and cycle-consistency is central to successful adaptation.",
}

@article{bridgeGap,
  author    = {Christopher Baik and
               H. V. Jagadish and
               Yunyao Li},
  title     = {Bridging the Semantic Gap with {SQL} Query Logs in Natural Language
               Interfaces to Databases},
  journal   = {CoRR},
  volume    = {abs/1902.00031},
  year      = {2019},
  url       = {http://arxiv.org/abs/1902.00031},
  eprinttype = {arXiv},
  eprint    = {1902.00031},
  timestamp = {Tue, 21 May 2019 18:03:40 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1902-00031.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}



@misc{learningFramework,
  author       = {Huda Al Shuaily and
                  Karen Renaud},
  title        = {{A Framework for SQL Learning: Linking Learning 
                   Taxonomy, Cognitive Model and Cross Cutting
                   Factors}},
  month        = jul,
  year         = 2016,
  publisher    = {Zenodo},
  version      = 10005310,
  doi          = {10.5281/zenodo.1126325},
  url          = {https://doi.org/10.5281/zenodo.1126325}
}

@inproceedings{10.1145/22627.22357,
author = {Schlager, M. S. and Ogden, W. C.},
title = {A Cognitive Model of Database Querying: A Tool for Novice Instruction},
year = {1986},
isbn = {0897911806},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/22627.22357},
doi = {10.1145/22627.22357},
abstract = {Two experiments examine the effects of incorporating user knowledge into the design of training materials for a database querying system. In Experiment 1 an informal cognitive model of a query language is derived from the verbal reports of expert users, and incorporated into existing documentation. Two groups of subjects were then asked to solve queries using either the revised or original manual. In Experiment 2 the cognitive model was formalized to explicitly describe the conceptual and procedural information that was incorporated into training materials. Three groups of subjects then received either a conceptual model, procedural model, or neither in addition to basic instructions, and then solved four sets of queries. The results show that whether or not a given type of information facilitates performance depends on the type of query, and whether the model is consistent with the operation of the query system.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {107–113},
numpages = {7},
location = {Boston, Massachusetts, USA},
series = {CHI '86}
}

@article{conitiveModel,
author = {Schlager, M. S. and Ogden, W. C.},
title = {A Cognitive Model of Database Querying: A Tool for Novice Instruction},
year = {1986},
issue_date = {April 1986},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {4},
issn = {0736-6906},
url = {https://doi.org/10.1145/22339.22357},
doi = {10.1145/22339.22357},
abstract = {Two experiments examine the effects of incorporating user knowledge into the design of training materials for a database querying system. In Experiment 1 an informal cognitive model of a query language is derived from the verbal reports of expert users, and incorporated into existing documentation. Two groups of subjects were then asked to solve queries using either the revised or original manual. In Experiment 2 the cognitive model was formalized to explicitly describe the conceptual and procedural information that was incorporated into training materials. Three groups of subjects then received either a conceptual model, procedural model, or neither in addition to basic instructions, and then solved four sets of queries. The results show that whether or not a given type of information facilitates performance depends on the type of query, and whether the model is consistent with the operation of the query system.},
journal = {SIGCHI Bull.},
month = {apr},
pages = {107–113},
numpages = {7}
}

@INPROCEEDINGS{explainingInNL,
  author={Koutrika, Georgia and Simitsis, Alkis and Ioannidis, Yannis E.},
  booktitle={2010 IEEE 26th International Conference on Data Engineering (ICDE 2010)}, 
  title={Explaining structured queries in natural language}, 
  year={2010},
  volume={},
  number={},
  pages={333-344},
  doi={10.1109/ICDE.2010.5447824}}


@inproceedings{logic1,
    title = "{TEAM}: A Transportable Natural-Language Interface System",
    author = "Grosz, Barbara J.",
    booktitle = "First Conference on Applied Natural Language Processing",
    month = feb,
    year = "1983",
    address = "Santa Monica, California, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/A83-1006",
    doi = "10.3115/974194.974201",
    pages = "39--45",
}

@article{logic2,
    title = "An Efficient Easily Adaptable System for Interpreting Natural Language Queries",
    author = "Warren, David H.D.  and
      Pereira, Fernando C.N.",
    journal = "American Journal of Computational Linguistics",
    volume = "8",
    number = "3-4",
    year = "1982",
    url = "https://aclanthology.org/J82-3002",
    pages = "110--122",
}

@inproceedings{Semantic-Tractability,
    title = "Modern Natural Language Interfaces to Databases: Composing Statistical Parsing with Semantic Tractability",
    author = "Popescu, Ana-Maria  and
      Armanasu, Alex  and
      Etzioni, Oren  and
      Ko, David  and
      Yates, Alexander",
    booktitle = "{COLING} 2004: Proceedings of the 20th International Conference on Computational Linguistics",
    month = "aug 23{--}aug 27",
    year = "2004",
    address = "Geneva, Switzerland",
    publisher = "COLING",
    url = "https://aclanthology.org/C04-1021",
    pages = "141--147",
}

@article{TEAM,
title = {TEAM: An experiment in the design of transportable natural-language interfaces},
journal = {Artificial Intelligence},
volume = {32},
number = {2},
pages = {173-243},
year = {1987},
issn = {0004-3702},
doi = {https://doi.org/10.1016/0004-3702(87)90011-7},
url = {https://www.sciencedirect.com/science/article/pii/0004370287900117},
author = {Barbara J. Grosz and Douglas E. Appelt and Paul A. Martin and Fernando C.N. Pereira},
abstract = {This article describes TEAM, a transportable natural-language interface system. TEAM was constructed to test the feasibility of building a natural-language system that could be adapted to interface with new databases by users who are not experts in natural-language processing. An overview of the system design is presented, emphasizing those choices that were imposed by the demands of transportability. Several general problems of natural-language processing that were faced in constructing the system are discussed, including quantifier scoping, various pragmatic issues, and verb acquisition. TEAM is compared with several other transportable systems; this comparison includes a discussion of the range of natural language handled by each as well as a description of the approach taken to achieving transportability in each system.}
}

@article{rule1,
  author    = {Christopher Baik and
               H. V. Jagadish and
               Yunyao Li},
  title     = {Bridging the Semantic Gap with {SQL} Query Logs in Natural Language
               Interfaces to Databases},
  journal   = {CoRR},
  volume    = {abs/1902.00031},
  year      = {2019},
  url       = {http://arxiv.org/abs/1902.00031},
  eprinttype = {arXiv},
  eprint    = {1902.00031},
  timestamp = {Tue, 21 May 2019 18:03:40 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1902-00031.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{ATHENA,
author = {Saha, Diptikalyan and Floratou, Avrilia and Sankaranarayanan, Karthik and Minhas, Umar Farooq and Mittal, Ashish R. and \"{O}zcan, Fatma},
title = {ATHENA: An Ontology-Driven System for Natural Language Querying over Relational Data Stores},
year = {2016},
issue_date = {August 2016},
publisher = {VLDB Endowment},
volume = {9},
number = {12},
issn = {2150-8097},
url = {https://doi.org/10.14778/2994509.2994536},
doi = {10.14778/2994509.2994536},
abstract = {In this paper, we present ATHENA, an ontology-driven system for natural language querying of complex relational databases. Natural language interfaces to databases enable users easy access to data, without the need to learn a complex query language, such as SQL. ATHENA uses domain specific ontologies, which describe the semantic entities, and their relationships in a domain. We propose a unique two-stage approach, where the input natural language query (NLQ) is first translated into an intermediate query language over the ontology, called OQL, and subsequently translated into SQL. Our two-stage approach allows us to decouple the physical layout of the data in the relational store from the semantics of the query, providing physical independence. Moreover, ontologies provide richer semantic information, such as inheritance and membership relations, that are lost in a relational schema. By reasoning over the ontologies, our NLQ engine is able to accurately capture the user intent. We study the effectiveness of our approach using three different workloads on top of geographical (GEO), academic (MAS) and financial (FIN) data. ATHENA achieves 100% precision on the GEO and MAS workloads, and 99% precision on the FIN workload which operates on a complex financial ontology. Moreover, ATHENA attains 87.2%, 88.3%, and 88.9% recall on the GEO, MAS, and FIN workloads, respectively.},
journal = {Proc. VLDB Endow.},
month = {aug},
pages = {1209–1220},
numpages = {12}
}

@article{SQLizer,
author = {Yaghmazadeh, Navid and Wang, Yuepeng and Dillig, Isil and Dillig, Thomas},
title = {SQLizer: Query Synthesis from Natural Language},
year = {2017},
issue_date = {October 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {OOPSLA},
url = {https://doi.org/10.1145/3133887},
doi = {10.1145/3133887},
abstract = {This paper presents a new technique for automatically synthesizing SQL queries from natural language (NL). At the core of our technique is a new NL-based program synthesis methodology that combines semantic parsing techniques from the NLP community with type-directed program synthesis and automated program repair. Starting with a program sketch obtained using standard parsing techniques, our approach involves an iterative refinement loop that alternates between probabilistic type inhabitation and automated sketch repair. We use the proposed idea to build an end-to-end system called SQLIZER that can synthesize SQL queries from natural language. Our method is fully automated, works for any database without requiring additional customization, and does not require users to know the underlying database schema. We evaluate our approach on over 450 natural language queries concerning three different databases, namely MAS, IMDB, and YELP. Our experiments show that the desired query is ranked within the top 5 candidates in close to 90% of the cases and that SQLIZER outperforms NALIR, a state-of-the-art tool that won a best paper award at VLDB'14.},
journal = {Proc. ACM Program. Lang.},
month = {oct},
articleno = {63},
numpages = {26},
keywords = {Program Synthesis, Programming by Natural Languages, Relational Databases}
}

@inproceedings{transformer,
author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, \L{}ukasz and Polosukhin, Illia},
title = {Attention is All You Need},
year = {2017},
isbn = {9781510860964},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.0 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature.},
booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems},
pages = {6000–6010},
numpages = {11},
location = {Long Beach, California, USA},
series = {NIPS'17}
}


@article{yin2020tabert,
  title={TaBERT: Pretraining for joint understanding of textual and tabular data},
  author={Yin, Pengcheng and Neubig, Graham and Yih, Wen-tau and Riedel, Sebastian},
  journal={arXiv preprint arXiv:2005.08314},
  year={2020}
}

@article{herzig2020tapas,
  title={TaPas: Weakly supervised table parsing via pre-training},
  author={Herzig, Jonathan and Nowak, Pawe{\l} Krzysztof and M{\"u}ller, Thomas and Piccinno, Francesco and Eisenschlos, Julian Martin},
  journal={arXiv preprint arXiv:2004.02349},
  year={2020}
}

@article{lin2020bridging,
  title={Bridging textual and tabular data for cross-domain text-to-sql semantic parsing},
  author={Lin, Xi Victoria and Socher, Richard and Xiong, Caiming},
  journal={arXiv preprint arXiv:2012.12627},
  year={2020}
}

@article{blackbox,
  doi = {10.48550/ARXIV.1811.10154},
  
  url = {https://arxiv.org/abs/1811.10154},
  
  author = {Rudin, Cynthia},
  
  keywords = {Machine Learning (stat.ML), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Stop Explaining Black Box Machine Learning Models for High Stakes Decisions and Use Interpretable Models Instead},
  
  publisher = {arXiv},
  
  year = {2018},
  
  copyright = {Creative Commons Attribution Share Alike 4.0 International}
}

@book{molnar2020interpretable,
  title={Interpretable machine learning},
  author={Molnar, Christoph},
  year={2020},
  publisher={Lulu. com}
}

@article{clark1991groundingold,
  title={Grounding in communication.},
  author={Clark, Herbert H and Brennan, Susan E},
  year={1991},
  publisher={American Psychological Association}
}

@incollection{clark1991grounding,
	author = {H. Clark and S. Brennan},
	booktitle = {Perspectives on Socially Shared Cognition},
	editor = {Lauren Resnick and Levine B. and M. John and Stephanie Teasley and D.},
	pages = {259--292},
	publisher = {American Psychological Association},
	title = {Grounding in Communication', 127-149 in Resnick Lb, Levine Jm and Teasley Sd},
	year = {1991}
}


@inproceedings{ashktorab2019resilient,
  title={Resilient chatbots: Repair strategy preferences for conversational breakdowns},
  author={Ashktorab, Zahra and Jain, Mohit and Liao, Q Vera and Weisz, Justin D},
  booktitle={Proceedings of the 2019 CHI conference on human factors in computing systems},
  pages={1--12},
  year={2019}
}

@inproceedings{beneteau2019communication,
  title={Communication breakdowns between families and Alexa},
  author={Beneteau, Erin and Richards, Olivia K and Zhang, Mingrui and Kientz, Julie A and Yip, Jason and Hiniker, Alexis},
  booktitle={Proceedings of the 2019 CHI conference on human factors in computing systems},
  pages={1--13},
  year={2019}
}

@inproceedings{zhong-etal-2020-grounded,
    title = "Grounded Adaptation for Zero-shot Executable Semantic Parsing",
    author = "Zhong, Victor  and
      Lewis, Mike  and
      Wang, Sida I.  and
      Zettlemoyer, Luke",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.558",
    doi = "10.18653/v1/2020.emnlp-main.558",
    pages = "6869--6882",
    abstract = "We propose Grounded Adaptation for Zeroshot Executable Semantic Parsing (GAZP) to adapt an existing semantic parser to new environments (e.g. new database schemas). GAZP combines a forward semantic parser with a backward utterance generator to synthesize data (e.g. utterances and SQL queries) in the new environment, then selects cycle-consistent examples to adapt the parser. Unlike data-augmentation, which typically synthesizes unverified examples in the training environment, GAZP synthesizes examples in the new environment whose input-output consistency are verified through execution. On the Spider, Sparc, and CoSQL zero-shot semantic parsing tasks, GAZP improves logical form and execution accuracy of the baseline parser. Our analyses show that GAZP outperforms data-augmentation in the training environment, performance increases with the amount of GAZP-synthesized data, and cycle-consistency is central to successful adaptation.",
}

@inproceedings{li_sugilite:_2017,
	address = {New York, NY, USA},
	series = {{CHI} '17},
	title = {{SUGILITE}: {Creating} {Multimodal} {Smartphone} {Automation} by {Demonstration}},
	isbn = {978-1-4503-4655-9},
	shorttitle = {{SUGILITE}},
	url = {http://doi.acm.org/10.1145/3025453.3025483},
	doi = {10.1145/3025453.3025483},
	abstract = {SUGILITE is a new programming-by-demonstration (PBD) system that enables users to create automation on smartphones. SUGILITE uses Android's accessibility API to support automating arbitrary tasks in any Android app (or even across multiple apps). When the user gives verbal commands that SUGILITE does not know how to execute, the user can demonstrate by directly manipulating the regular apps' user interface. By leveraging the verbal instructions, the demonstrated procedures, and the apps? UI hierarchy structures, SUGILITE can automatically generalize the script from the recorded actions, so SUGILITE learns how to perform tasks with different variations and parameters from a single demonstration. Extensive error handling and context checking support forking the script when new situations are encountered, and provide robustness if the apps change their user interface. Our lab study suggests that users with little or no programming knowledge can successfully automate smartphone tasks using SUGILITE.},
	booktitle = {Proceedings of the 2017 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Li, Toby Jia-Jun and Azaria, Amos and Myers, Brad A.},
	year = {2017},
	keywords = {end-user development, programming by demonstration, smartphone automation},
	pages = {6038--6049}
}

@inproceedings{li_pumice:_2019,
	series = {{UIST} 2019},
	title = {{PUMICE}: {A} {Multi}-{Modal} {Agent} that {Learns} {Concepts} and {Conditionals} from {Natural} {Language} and {Demonstrations}},
	doi = {http://doi.acm.org/10.1145/3332165.3347899},
	booktitle = {Proceedings of the 32nd {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {ACM},
	author = {Li, Toby Jia-Jun and Radensky, Marissa and Jia, Justin and Singarajah, Kirielle and Mitchell, Tom M. and Myers, Brad A.},
	year = {2019}
}

@article{seq2sql,
  author    = {Victor Zhong and
               Caiming Xiong and
               Richard Socher},
  title     = {Seq2SQL: Generating Structured Queries from Natural Language using
               Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1709.00103},
  year      = {2017},
  url       = {http://arxiv.org/abs/1709.00103},
  eprinttype = {arXiv},
  eprint    = {1709.00103},
  timestamp = {Mon, 13 Aug 2018 16:48:41 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1709-00103.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{price-1990-evaluation,
    title = "Evaluation of Spoken Language Systems: the {ATIS} Domain",
    author = "Price, P. J.",
    booktitle = "Speech and Natural Language: Proceedings of a Workshop Held at Hidden Valley, {P}ennsylvania, June 24-27,1990",
    year = "1990",
    url = "https://aclanthology.org/H90-1020",
}

@inproceedings{NaLIR,
author = {Li, Fei and Jagadish, Hosagrahar V},
title = {NaLIR: An Interactive Natural Language Interface for Querying Relational Databases},
year = {2014},
isbn = {9781450323765},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2588555.2594519},
doi = {10.1145/2588555.2594519},
abstract = {In this demo, we present NaLIR, a generic interactive natural language interface for querying relational databases. NaLIR can accept a logically complex English language sentence as query input. This query is first translated into a SQL query, which may include aggregation, nesting, and various types of joins, among other things, and then evaluated against an RDBMS. In this demonstration, we show that NaLIR, while far from being able to pass the Turing test, is perfectly usable in practice, and able to handle even quite complex queries in a variety of application domains. In addition, we also demonstrate how carefully designed interactive communication can avoid misinterpretation with minimum user burden.},
booktitle = {Proceedings of the 2014 ACM SIGMOD International Conference on Management of Data},
pages = {709–712},
numpages = {4},
keywords = {usability, natural language interface, relational database},
location = {Snowbird, Utah, USA},
series = {SIGMOD '14}
}

@article{direct-manipulation-vs-interface-agent,
author = {Shneiderman, Ben and Maes, Pattie},
title = {Direct Manipulation vs. Interface Agents},
year = {1997},
issue_date = {Nov./Dec. 1997},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {6},
issn = {1072-5520},
url = {https://doi.org/10.1145/267505.267514},
doi = {10.1145/267505.267514},
journal = {Interactions},
month = {nov},
pages = {42–61},
numpages = {20}
}

@inproceedings{datatone,
author = {Gao, Tong and Dontcheva, Mira and Adar, Eytan and Liu, Zhicheng and Karahalios, Karrie G.},
title = {DataTone: Managing Ambiguity in Natural Language Interfaces for Data Visualization},
year = {2015},
isbn = {9781450337793},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2807442.2807478},
doi = {10.1145/2807442.2807478},
abstract = {Answering questions with data is a difficult and time-consuming process. Visual dashboards and templates make it easy to get started, but asking more sophisticated questions often requires learning a tool designed for expert analysts. Natural language interaction allows users to ask questions directly in complex programs without having to learn how to use an interface. However, natural language is often ambiguous. In this work we propose a mixed-initiative approach to managing ambiguity in natural language interfaces for data visualization. We model ambiguity throughout the process of turning a natural language query into a visualization and use algorithmic disambiguation coupled with interactive ambiguity widgets. These widgets allow the user to resolve ambiguities by surfacing system decisions at the point where the ambiguity matters. Corrections are stored as constraints and influence subsequent queries. We have implemented these ideas in a system, DataTone. In a comparative study, we find that DataTone is easy to learn and lets users ask questions without worrying about syntax and proper question form.},
booktitle = {Proceedings of the 28th Annual ACM Symposium on User Interface Software \& Technology},
pages = {489–500},
numpages = {12},
keywords = {natural language interaction, mixed-initiative interfaces, visualization},
location = {Charlotte, NC, USA},
series = {UIST '15}
}

@inproceedings{Eviza,
author = {Setlur, Vidya and Battersby, Sarah E. and Tory, Melanie and Gossweiler, Rich and Chang, Angel X.},
title = {Eviza: A Natural Language Interface for Visual Analysis},
year = {2016},
isbn = {9781450341899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2984511.2984588},
doi = {10.1145/2984511.2984588},
abstract = {Natural language interfaces for visualizations have emerged as a promising new way of interacting with data and performing analytics. Many of these systems have fundamental limitations. Most return minimally interactive visualizations in response to queries and often require experts to perform modeling for a set of predicted user queries before the systems are effective. Eviza provides a natural language interface for an interactive query dialog with an existing visualization rather than starting from a blank sheet and asking closed-ended questions that return a single text answer or static visualization. The system employs a probabilistic grammar based approach with predefined rules that are dynamically updated based on the data from the visualization, as opposed to computationally intensive deep learning or knowledge based approaches.The result of an interaction is a change to the view (e.g., filtering, navigation, selection) providing graphical answers and ambiguity widgets to handle ambiguous queries and system defaults. There is also rich domain awareness of time, space, and quantitative reasoning built in, and linking into existing knowledge bases for additional semantics. Eviza also supports pragmatics and exploring multi-modal interactions to help enhance the expressiveness of how users can ask questions about their data during the flow of visual analysis.},
booktitle = {Proceedings of the 29th Annual Symposium on User Interface Software and Technology},
pages = {365–377},
numpages = {13},
keywords = {visualization, ambiguity, probabilistic grammar, visual data analysis, pragmatics, parser, natural language},
location = {Tokyo, Japan},
series = {UIST '16}
}

@ARTICLE{Orko,
  author={Srinivasan, Arjun and Stasko, John},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={Orko: Facilitating Multimodal Interaction for Visual Exploration and Analysis of Networks}, 
  year={2018},
  volume={24},
  number={1},
  pages={511-521},
  doi={10.1109/TVCG.2017.2745219}
  }

@inproceedings{Quantitative-Study-of-the-Relative-Difficulty,
author = {Ahadi, Alireza and Prior, Julia and Behbood, Vahid and Lister, Raymond},
title = {A Quantitative Study of the Relative Difficulty for Novices of Writing Seven Different Types of SQL Queries},
year = {2015},
isbn = {9781450334402},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2729094.2742620},
doi = {10.1145/2729094.2742620},
abstract = {This paper presents a quantitative analysis of data collected by an online testing system for SQL "select" queries. The data was collected from almost one thousand students, over eight years. We examine which types of queries our students found harder to write. The seven types of SQL queries studied are: simple queries on one table; grouping, both with and without "having"; natural joins; simple and correlated sub-queries; and self-joins. The order of queries in the preceding sentence reflects the order of student difficulty we see in our data.},
booktitle = {Proceedings of the 2015 ACM Conference on Innovation and Technology in Computer Science Education},
pages = {201–206},
numpages = {6},
keywords = {databases, online assessment, SQL queries},
location = {Vilnius, Lithuania},
series = {ITiCSE '15}
}

﻿@Article{2-stages,
author={Cong, Hao
and Chen, Wei-Neng
and Yu, Wei-Jie},
title={A two-stage information retrieval system based on interactive multimodal genetic algorithm for query weight optimization},
journal={Complex {\&} Intelligent Systems},
year={2021},
month={Oct},
day={01},
volume={7},
number={5},
pages={2765-2781},
abstract={Query weight optimization, which aims to find an optimal combination of the weights of query terms for sorting relevant documents, is an important topic in the information retrieval system. Due to the huge search space, the query optimization problem is intractable, and evolutionary algorithms have become one popular approach. But as the size of the database grows, traditional retrieval approaches may return a lot of results, which leads to low efficiency and poor practicality. To solve this problem, this paper proposes a two-stage information retrieval system based on an interactive multimodal genetic algorithm (IMGA) for a query weight optimization system. The proposed IMGA has two stages: quantity control and quality optimization. In the quantity control stage, a multimodal genetic algorithm with the aid of the niching method selects multiple promising combinations of query terms simultaneously by which the numbers of retrieved documents are controlled in an appropriate range. In the quality optimization stage, an interactive genetic algorithm is designed to find the optimal query weights so that the most user-friendly document retrieval sequence can be yielded. Users' feedback information will accelerate the optimization process, and a genetic algorithm (GA) performs interactively with the action of relevance feedback mechanism. Replacing user evaluation, a mathematical model is built to evaluate the fitness values of individuals. In the proposed two-stage method, not only the number of returned results can be controlled, but also the quality and accuracy of retrieval can be improved. The proposed method is run on the database which with more than 2000 documents. The experimental results show that our proposed method outperforms several state-of-the-art query weight optimization approaches in terms of the precision rate and the recall rate.},
issn={2198-6053},
doi={10.1007/s40747-021-00450-6},
url={https://doi.org/10.1007/s40747-021-00450-6}
}

@inproceedings{zamfirescu2023johnny,
  title={Why Johnny can’t prompt: how non-AI experts try (and fail) to design LLM prompts},
  author={Zamfirescu-Pereira, JD and Wong, Richmond Y and Hartmann, Bjoern and Yang, Qian},
  booktitle={Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
  pages={1--21},
  year={2023}
}

@inproceedings{making-DB-usable,
author = {Jagadish, H. V. and Chapman, Adriane and Elkiss, Aaron and Jayapandian, Magesh and Li, Yunyao and Nandi, Arnab and Yu, Cong},
title = {Making Database Systems Usable},
year = {2007},
isbn = {9781595936868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1247480.1247483},
doi = {10.1145/1247480.1247483},
abstract = {Database researchers have striven to improve the capability of a database in terms of both performance and functionality. We assert that the usability of a database is as important as its capability. In this paper, we study why database systems today are so difficult to use. We identify a set of five pain points and propose a research agenda to address these. In particular, we introduce a presentation data model and recommend direct data manipulation with a schema later approach. We also stress the importance of provenance and of consistency across presentation models.},
booktitle = {Proceedings of the 2007 ACM SIGMOD International Conference on Management of Data},
pages = {13–24},
numpages = {12},
keywords = {database, user interface, usability},
location = {Beijing, China},
series = {SIGMOD '07}
}

@article{Self-Assessment,
author = {Abiteboul, Serge and Agrawal, Rakesh and Bernstein, Phil and Carey, Mike and Ceri, Stefano and Croft, Bruce and DeWitt, David and Franklin, Mike and Molina, Hector Garcia and Gawlick, Dieter and Gray, Jim and Haas, Laura and Halevy, Alon and Hellerstein, Joe and Ioannidis, Yannis and Kersten, Martin and Pazzani, Michael and Lesk, Mike and Maier, David and Naughton, Jeff and Schek, Hans and Sellis, Timos and Silberschatz, Avi and Stonebraker, Mike and Snodgrass, Rick and Ullman, Jeff and Weikum, Gerhard and Widom, Jennifer and Zdonik, Stan},
title = {The Lowell Database Research Self-Assessment},
year = {2005},
issue_date = {May 2005},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {5},
issn = {0001-0782},
url = {https://doi.org/10.1145/1060710.1060718},
doi = {10.1145/1060710.1060718},
abstract = {Database needs are changing, driven by the Internet and increasing amounts of scientific and sensor data. In this article, the authors propose research into several important new directions for database management systems.},
journal = {Commun. ACM},
month = {may},
pages = {111–118},
numpages = {8}
}

@inproceedings{liao2020questioning,
  title={Questioning the AI: informing design practices for explainable AI user experiences},
  author={Liao, Q Vera and Gruen, Daniel and Miller, Sarah},
  booktitle={Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
  pages={1--15},
  year={2020}
}

@inproceedings{bansal2021does,
  title={Does the whole exceed its parts? the effect of ai explanations on complementary team performance},
  author={Bansal, Gagan and Wu, Tongshuang and Zhou, Joyce and Fok, Raymond and Nushi, Besmira and Kamar, Ece and Ribeiro, Marco Tulio and Weld, Daniel},
  booktitle={Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
  pages={1--16},
  year={2021}
}

@inproceedings{eiband2019people,
  title={When people and algorithms meet: User-reported problems in intelligent everyday applications},
  author={Eiband, Malin and V{\"o}lkel, Sarah Theres and Buschek, Daniel and Cook, Sophia and Hussmann, Heinrich},
  booktitle={Proceedings of the 24th international conference on intelligent user interfaces},
  pages={96--106},
  year={2019}
}

@inproceedings{vaithilingam2022expectation,
  title={Expectation vs. experience: Evaluating the usability of code generation tools powered by large language models},
  author={Vaithilingam, Priyan and Zhang, Tianyi and Glassman, Elena L},
  booktitle={Chi conference on human factors in computing systems extended abstracts},
  pages={1--7},
  year={2022}
}

@article{song2022llm,
  title={Llm-planner: Few-shot grounded planning for embodied agents with large language models},
  author={Song, Chan Hee and Wu, Jiaman and Washington, Clayton and Sadler, Brian M and Chao, Wei-Lun and Su, Yu},
  journal={arXiv preprint arXiv:2212.04088},
  year={2022}
}

@article{jiang2023self,
  title={Self-planning code generation with large language model},
  author={Jiang, Xue and Dong, Yihong and Wang, Lecheng and Shang, Qiwei and Li, Ge},
  journal={arXiv preprint arXiv:2303.06689},
  year={2023}
}

@inproceedings{patel2022question,
  title={Is a Question Decomposition Unit All We Need?},
  author={Patel, Pruthvi and Mishra, Swaroop and Parmar, Mihir and Baral, Chitta},
  booktitle={2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022},
  year={2022}
}


@inproceedings{kocielnik2019will,
  title={Will you accept an imperfect ai? exploring designs for adjusting end-user expectations of ai systems},
  author={Kocielnik, Rafal and Amershi, Saleema and Bennett, Paul N},
  booktitle={Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
  pages={1--14},
  year={2019}
}

@inproceedings{luger2016like,
  title={" Like Having a Really Bad PA" The Gulf between User Expectation and Experience of Conversational Agents},
  author={Luger, Ewa and Sellen, Abigail},
  booktitle={Proceedings of the 2016 CHI conference on human factors in computing systems},
  pages={5286--5297},
  year={2016}
}

@inproceedings{SQLrepair,
author = {Presler-Marshall, Kai and Heckman, Sarah and Stolee, Kathryn T.},
title = {SQLRepair: Identifying and Repairing Mistakes in Student-Authored SQL Queries},
year = {2021},
isbn = {9780738133201},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-SEET52601.2021.00030},
doi = {10.1109/ICSE-SEET52601.2021.00030},
abstract = {Computer science educators seek to understand the types of mistakes that students make when learning a new (programming) language so that they can help students avoid those mistakes in the future. While educators know what mistakes students regularly make in languages such as C and Python, students struggle with SQL and regularly make mistakes when working with it. We present an analysis of mistakes that students made when first working with SQL, classify the types of errors introduced, and provide suggestions on how to avoid them going forward. In addition, we present an automated tool, SQLRepair, that is capable of repairing errors introduced by undergraduate programmers when writing SQL queries. Our results show that students find repairs produced by our tool comparable in understandability to queries written by themselves or by other students, suggesting that SQL repair tools may be useful in an educational context. We also provide to the community a benchmark of SQL queries written by the students in our study that we used for evaluation of SQLRepair.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering: Joint Track on Software Engineering Education and Training},
pages = {199–210},
numpages = {12},
location = {Virtual Event, Spain},
series = {ICSE-JSEET '21}
}

@incollection{NASA-TLX,
title = {Development of NASA-TLX (Task Load Index): Results of Empirical and Theoretical Research},
editor = {Peter A. Hancock and Najmedin Meshkati},
series = {Advances in Psychology},
publisher = {North-Holland},
volume = {52},
pages = {139-183},
year = {1988},
booktitle = {Human Mental Workload},
issn = {0166-4115},
doi = {https://doi.org/10.1016/S0166-4115(08)62386-9},
url = {https://www.sciencedirect.com/science/article/pii/S0166411508623869},
author = {Sandra G. Hart and Lowell E. Staveland},
abstract = {The results of a multi-year research program to identify the factors associated with variations in subjective workload within and between different types of tasks are reviewed. Subjective evaluations of 10 workload-related factors were obtained from 16 different experiments. The experimental tasks included simple cognitive and manual control tasks, complex laboratory and supervisory control tasks, and aircraft simulation. Task-, behavior-, and subject-related correlates of subjective workload experiences varied as a function of difficulty manipulations within experiments, different sources of workload between experiments, and individual differences in workload definition. A multi-dimensional rating scale is proposed in which information about the magnitude and sources of six workload-related factors are combined to derive a sensitive and reliable estimate of workload.}
}

@article{Models-of-Attention,
author = {Horvitz, Eric and Kadie, Carl and Paek, Tim and Hovel, David},
title = {Models of Attention in Computing and Communication: From Principles to Applications},
year = {2003},
issue_date = {March 2003},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {46},
number = {3},
issn = {0001-0782},
url = {https://doi.org/10.1145/636772.636798},
doi = {10.1145/636772.636798},
abstract = {Creating computing and communication systems that sense and reason about human attention by fusing together information from multiple streams.},
journal = {Commun. ACM},
month = {mar},
pages = {52–59},
numpages = {8}
}

@article{principle-of-behavior,
  title={Principles of behavior: an introduction to behavior theory.},
  author={Hull, Clark Leonard},
  year={1943},
  publisher={Appleton-Century}
}

@inproceedings{flashPog,
author = {Mayer, Mikaël and Soares, Gustavo and Grechkin, Maxim and Le, Vu and Marron, Mark and Polozov, Alex and Singh, Rishabh and Zorn, Ben and Gulwani, Sumit},
title = {User Interaction Models for Disambiguation in Programming by Example},
booktitle = {28th ACM User Interface Software and Technology Symposium (UIST 2015)},
year = {2015},
month = {November},
abstract = {Programming by Examples (PBE) has the potential to revolutionize end-user programming by enabling end users, most of whom are non-programmers, to create small scripts for automating repetitive tasks. However, examples, though often easy to provide, are an ambiguous specification of the user’s intent. Because of that, a key impedance in adoption of PBE systems is the lack of user confidence in the correctness of the program that was synthesized by the system. We present two novel user interaction models that communicate actionable information to the user to help resolve ambiguity in the examples. One of these models allows the user to effectively navigate between the huge set of programs that are consistent with the examples provided by the user. The other model uses active learning to ask directed example-based questions to the user on the test input data over which the user intends to run the synthesized program. Our user studies show that each of these models significantly reduces the number of errors in the performed task without any difference in completion time. Moreover, both models are perceived as useful, and the proactive active-learning based model has a slightly higher preference regarding the users’ confidence in the result.},
publisher = {ACM – Association for Computing Machinery},
url = {https://www.microsoft.com/en-us/research/publication/user-interaction-models-for-disambiguation-in-programming-by-example/},
edition = {28th ACM User Interface Software and Technology Symposium (UIST 2015)},
}


@inproceedings{Rationalization,
author = {Ehsan, Upol and Harrison, Brent and Chan, Larry and Riedl, Mark O.},
title = {Rationalization: A Neural Machine Translation Approach to Generating Natural Language Explanations},
year = {2018},
isbn = {9781450360128},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3278721.3278736},
doi = {10.1145/3278721.3278736},
abstract = {We introduce em AI rationalization, an approach for generating explanations of autonomous system behavior as if a human had performed the behavior. We describe a rationalization technique that uses neural machine translation to translate internal state-action representations of an autonomous agent into natural language. We evaluate our technique in the Frogger game environment, training an autonomous game playing agent to rationalize its action choices using natural language. A natural language training corpus is collected from human players thinking out loud as they play the game. We motivate the use of rationalization as an approach to explanation generation and show the results of two experiments evaluating the effectiveness of rationalization. Results of these evaluations show that neural machine translation is able to accurately generate rationalizations that describe agent behavior, and that rationalizations are more satisfying to humans than other alternative methods of explanation.},
booktitle = {Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society},
pages = {81–87},
numpages = {7},
keywords = {artificial intelligence, user perception, ai rationalization, transparency, machine learning, interpretability, explainable ai},
location = {New Orleans, LA, USA},
series = {AIES '18}
}

@inproceedings{Generation-NL-Explanations,
author = {Costa, Felipe and Ouyang, Sixun and Dolog, Peter and Lawlor, Aonghus},
title = {Automatic Generation of Natural Language Explanations},
year = {2018},
isbn = {9781450355711},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3180308.3180366},
doi = {10.1145/3180308.3180366},
abstract = {An interesting challenge for explainable recommender systems is to provide successful interpretation of recommendations using structured sentences. It is well known that user-generated reviews, have strong influence on the users' decision. Recent techniques exploit user reviews to generate natural language explanations. In this paper, we propose a character-level attention-enhanced long short-term memory model to generate natural language explanations. We empirically evaluated this network using two real-world review datasets. The generated text present readable and similar to a real user's writing, due to the ability of reproducing negation, misspellings, and domain-specific vocabulary.},
booktitle = {Proceedings of the 23rd International Conference on Intelligent User Interfaces Companion},
articleno = {57},
numpages = {2},
keywords = {Explainability, Neural Network, Recommender systems, Natural Language Generation, Explanations},
location = {Tokyo, Japan},
series = {IUI '18 Companion}
}



@article{heatmap1,
  author    = {Laura Rieger and
               Lars Kai Hansen},
  title     = {A simple defense against adversarial attacks on heatmap explanations},
  journal   = {CoRR},
  volume    = {abs/2007.06381},
  year      = {2020},
  url       = {https://arxiv.org/abs/2007.06381},
  eprinttype = {arXiv},
  eprint    = {2007.06381},
  timestamp = {Tue, 21 Jul 2020 12:53:33 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2007-06381.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{heatmap2,
author = {Zhou, Bolei and Sun, Yiyou and Bau, David and Torralba, Antonio},
title = {Interpretable Basis Decomposition for Visual Explanation},
year = {2018},
isbn = {978-3-030-01236-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-01237-3_8},
doi = {10.1007/978-3-030-01237-3_8},
abstract = {Explanations of the decisions made by a deep neural network are important for human end-users to be able to understand and diagnose the trustworthiness of the system. Current neural networks used for visual recognition are generally used as black boxes that do not provide any human interpretable justification for a prediction. In this work we propose a new framework called Interpretable Basis Decomposition for providing visual explanations for classification networks. By decomposing the neural activations of the input image into semantically interpretable components pre-trained from a large concept corpus, the proposed framework is able to disentangle the evidence encoded in the activation feature vector, and quantify the contribution of each piece of evidence to the final prediction. We apply our framework for providing explanations to several popular networks for visual recognition, and show it is able to explain the predictions given by the networks in a human-interpretable way. The human interpretability of the visual explanations provided by our framework and other recent explanation methods is evaluated through Amazon Mechanical Turk, showing that our framework generates more faithful and interpretable explanations (The code and data are available at ).},
booktitle = {Computer Vision – ECCV 2018: 15th European Conference, Munich, Germany, September 8-14, 2018, Proceedings, Part VIII},
pages = {122–138},
numpages = {17},
location = {Munich, Germany}
}

@inproceedings{search-trace,
author = {Zhang, Tianyi and Chen, Zhiyang and Zhu, Yuanli and Vaithilingam, Priyan and Wang, Xinyu and Glassman, Elena L.},
title = {Interpretable Program Synthesis},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445646},
doi = {10.1145/3411764.3445646},
abstract = {Program synthesis, which generates programs based on user-provided specifications, can be obscure and brittle: users have few ways to understand and recover from synthesis failures. We propose interpretable program synthesis, a novel approach that unveils the synthesis process and enables users to monitor and guide a synthesizer. We designed three representations that explain the underlying synthesis process with different levels of fidelity. We implemented an interpretable synthesizer for regular expressions and conducted a within-subjects study with eighteen participants on three challenging regex tasks. With interpretable synthesis, participants were able to reason about synthesis failures and provide strategic feedback, achieving a significantly higher success rate compared with a state-of-the-art synthesizer. In particular, participants with a high engagement tendency (as measured by NCS-6) preferred a deductive representation that shows the synthesis process in a search tree, while participants with a relatively low engagement tendency preferred an inductive representation that renders representative samples of programs enumerated during synthesis.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {105},
numpages = {16},
keywords = {Programming by example, Program synthesis, Interpretability},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{SQL-to-text,
    title = "{SQL}-to-Text Generation with Graph-to-Sequence Model",
    author = "Xu, Kun  and
      Wu, Lingfei  and
      Wang, Zhiguo  and
      Feng, Yansong  and
      Sheinin, Vadim",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D18-1112",
    doi = "10.18653/v1/D18-1112",
    pages = "931--936",
    abstract = "Previous work approaches the SQL-to-text generation task using vanilla Seq2Seq models, which may not fully capture the inherent graph-structured information in SQL query. In this paper, we propose a graph-to-sequence model to encode the global structure information into node embeddings. This model can effectively learn the correlation between the SQL query pattern and its interpretation. Experimental results on the WikiSQL dataset and Stackoverflow dataset show that our model outperforms the Seq2Seq and Tree2Seq baselines, achieving the state-of-the-art performance.",
}

@article{shneiderman1983direct,
  title={Direct manipulation: A step beyond programming languages},
  author={Shneiderman, Ben},
  journal={Computer},
  volume={16},
  number={08},
  pages={57--69},
  year={1983},
  publisher={IEEE Computer Society}
}

@article{XAI,
  author    = {Wojciech Samek and
               Thomas Wiegand and
               Klaus{-}Robert M{\"{u}}ller},
  title     = {Explainable Artificial Intelligence: Understanding, Visualizing and
               Interpreting Deep Learning Models},
  journal   = {CoRR},
  volume    = {abs/1708.08296},
  year      = {2017},
  url       = {http://arxiv.org/abs/1708.08296},
  eprinttype = {arXiv},
  eprint    = {1708.08296},
  timestamp = {Mon, 13 Aug 2018 16:48:36 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1708-08296.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@ARTICLE{man-computer,
  author={Licklider, J. C. R.},
  journal={IRE Transactions on Human Factors in Electronics}, 
  title={Man-Computer Symbiosis}, 
  year={1960},
  volume={HFE-1},
  number={1},
  pages={4-11},
  doi={10.1109/THFE2.1960.4503259},
  url={https://ieeexplore.ieee.org/document/4503259}
}

@inproceedings{lime,
    title = "{``}Why Should {I} Trust You?{''}: Explaining the Predictions of Any Classifier",
    author = "Ribeiro, Marco  and
      Singh, Sameer  and
      Guestrin, Carlos",
    booktitle = "Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Demonstrations",
    month = jun,
    year = "2016",
    address = "San Diego, California",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N16-3020",
    doi = "10.18653/v1/N16-3020",
    pages = "97--101",
}

@article{nl-explanation-visual-question,
  author    = {Shalini Ghosh and
               Giedrius Burachas and
               Arijit Ray and
               Avi Ziskind},
  title     = {Generating Natural Language Explanations for Visual Question Answering
               using Scene Graphs and Visual Attention},
  journal   = {CoRR},
  volume    = {abs/1902.05715},
  year      = {2019},
  url       = {http://arxiv.org/abs/1902.05715},
  eprinttype = {arXiv},
  eprint    = {1902.05715},
  timestamp = {Tue, 21 May 2019 18:03:39 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1902-05715.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{attribution-for-DNN,
author = {Sundararajan, Mukund and Taly, Ankur and Yan, Qiqi},
title = {Axiomatic Attribution for Deep Networks},
year = {2017},
publisher = {JMLR.org},
abstract = {We study the problem of attributing the prediction of a deep network to its input features, a problem previously studied by several other works. We identify two fundamental axioms— Sensitivity and Implementation Invariance that attribution methods ought to satisfy. We show that they are not satisfied by most known attribution methods, which we consider to be a fundamental weakness of those methods. We use the axioms to guide the design of a new attribution method called Integrated Gradients. Our method requires no modification to the original network and is extremely simple to implement; it just needs a few calls to the standard gradient operator. We apply this method to a couple of image models, a couple of text models and a chemistry model, demonstrating its ability to debug networks, to extract rules from a network, and to enable users to engage with models better.},
booktitle = {Proceedings of the 34th International Conference on Machine Learning - Volume 70},
pages = {3319–3328},
numpages = {10},
location = {Sydney, NSW, Australia},
series = {ICML'17}
}

@article{NLI-DB, title={Natural language interfaces to databases – an introduction}, volume={1}, DOI={10.1017/S135132490000005X}, number={1}, journal={Natural Language Engineering}, publisher={Cambridge University Press}, author={Androutsopoulos, I. and Ritchie, G.D. and Thanisch, P.}, year={1995}, pages={29–81}}


@article{NLI2DB, title={Natural language interfaces to databases}, volume={5}, DOI={10.1017/S0269888900005476}, number={4}, journal={The Knowledge Engineering Review}, publisher={Cambridge University Press}, author={Copestake, Ann and Jones, Karen Sparck}, year={1990}, pages={225–249}}

@INPROCEEDINGS{good_code_example,
  author={Nasehi, Seyed Mehdi and Sillito, Jonathan and Maurer, Frank and Burns, Chris},
  booktitle={2012 28th IEEE International Conference on Software Maintenance (ICSM)}, 
  title={What makes a good code example?: A study of programming Q&A in StackOverflow}, 
  year={2012},
  volume={},
  number={},
  pages={25-34},
  doi={10.1109/ICSM.2012.6405249}}

@misc{gpt3,
      title={Language Models are Few-Shot Learners}, 
      author={Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
      year={2020},
      eprint={2005.14165},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{llama,
      title={LLaMA: Open and Efficient Foundation Language Models}, 
      author={Hugo Touvron and Thibaut Lavril and Gautier Izacard and Xavier Martinet and Marie-Anne Lachaux and Timothée Lacroix and Baptiste Rozière and Naman Goyal and Eric Hambro and Faisal Azhar and Aurelien Rodriguez and Armand Joulin and Edouard Grave and Guillaume Lample},
      year={2023},
      eprint={2302.13971},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{llama2,
      title={Llama 2: Open Foundation and Fine-Tuned Chat Models}, 
      author={Hugo Touvron and Louis Martin and Kevin Stone and Peter Albert and Amjad Almahairi and Yasmine Babaei and Nikolay Bashlykov and Soumya Batra and Prajjwal Bhargava and Shruti Bhosale and Dan Bikel and Lukas Blecher and Cristian Canton Ferrer and Moya Chen and Guillem Cucurull and David Esiobu and Jude Fernandes and Jeremy Fu and Wenyin Fu and Brian Fuller and Cynthia Gao and Vedanuj Goswami and Naman Goyal and Anthony Hartshorn and Saghar Hosseini and Rui Hou and Hakan Inan and Marcin Kardas and Viktor Kerkez and Madian Khabsa and Isabel Kloumann and Artem Korenev and Punit Singh Koura and Marie-Anne Lachaux and Thibaut Lavril and Jenya Lee and Diana Liskovich and Yinghai Lu and Yuning Mao and Xavier Martinet and Todor Mihaylov and Pushkar Mishra and Igor Molybog and Yixin Nie and Andrew Poulton and Jeremy Reizenstein and Rashi Rungta and Kalyan Saladi and Alan Schelten and Ruan Silva and Eric Michael Smith and Ranjan Subramanian and Xiaoqing Ellen Tan and Binh Tang and Ross Taylor and Adina Williams and Jian Xiang Kuan and Puxin Xu and Zheng Yan and Iliyan Zarov and Yuchen Zhang and Angela Fan and Melanie Kambadur and Sharan Narang and Aurelien Rodriguez and Robert Stojnic and Sergey Edunov and Thomas Scialom},
      year={2023},
      eprint={2307.09288},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{palm,
      title={PaLM: Scaling Language Modeling with Pathways}, 
      author={Aakanksha Chowdhery and Sharan Narang and Jacob Devlin and Maarten Bosma and Gaurav Mishra and Adam Roberts and Paul Barham and Hyung Won Chung and Charles Sutton and Sebastian Gehrmann and Parker Schuh and Kensen Shi and Sasha Tsvyashchenko and Joshua Maynez and Abhishek Rao and Parker Barnes and Yi Tay and Noam Shazeer and Vinodkumar Prabhakaran and Emily Reif and Nan Du and Ben Hutchinson and Reiner Pope and James Bradbury and Jacob Austin and Michael Isard and Guy Gur-Ari and Pengcheng Yin and Toju Duke and Anselm Levskaya and Sanjay Ghemawat and Sunipa Dev and Henryk Michalewski and Xavier Garcia and Vedant Misra and Kevin Robinson and Liam Fedus and Denny Zhou and Daphne Ippolito and David Luan and Hyeontaek Lim and Barret Zoph and Alexander Spiridonov and Ryan Sepassi and David Dohan and Shivani Agrawal and Mark Omernick and Andrew M. Dai and Thanumalayan Sankaranarayana Pillai and Marie Pellat and Aitor Lewkowycz and Erica Moreira and Rewon Child and Oleksandr Polozov and Katherine Lee and Zongwei Zhou and Xuezhi Wang and Brennan Saeta and Mark Diaz and Orhan Firat and Michele Catasta and Jason Wei and Kathy Meier-Hellstern and Douglas Eck and Jeff Dean and Slav Petrov and Noah Fiedel},
      year={2022},
      eprint={2204.02311},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{gpt4,
      title={GPT-4 Technical Report}, 
      author={OpenAI},
      year={2023},
      eprint={2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{COT,
  author       = {Jason Wei and
                  Xuezhi Wang and
                  Dale Schuurmans and
                  Maarten Bosma and
                  Ed H. Chi and
                  Quoc Le and
                  Denny Zhou},
  title        = {Chain of Thought Prompting Elicits Reasoning in Large Language Models},
  journal      = {CoRR},
  volume       = {abs/2201.11903},
  year         = {2022},
  url          = {https://arxiv.org/abs/2201.11903},
  eprinttype    = {arXiv},
  eprint       = {2201.11903},
  timestamp    = {Fri, 22 Apr 2022 16:06:31 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2201-11903.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@misc{COT-self-consistency,
      title={Self-Consistency Improves Chain of Thought Reasoning in Language Models}, 
      author={Xuezhi Wang and Jason Wei and Dale Schuurmans and Quoc Le and Ed Chi and Sharan Narang and Aakanksha Chowdhery and Denny Zhou},
      year={2023},
      eprint={2203.11171},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@InProceedings{PBE,
author="Gulwani, Sumit
and Jain, Prateek",
editor="Chang, Bor-Yuh Evan",
title="Programming by Examples: PL Meets ML",
booktitle="Programming Languages and Systems",
year="2017",
publisher="Springer International Publishing",
address="Cham",
pages="3--20",
abstract="Programming by Examples (PBE) involves synthesizing intended programs in an underlying domain-specific language from example-based specifications. PBE systems are already revolutionizing the application domain of data wrangling and are set to significantly impact several other domains including code refactoring.",
isbn="978-3-319-71237-6"
}

@misc{LLM_errors,
      title={LLMs as Factual Reasoners: Insights from Existing Benchmarks and Beyond}, 
      author={Philippe Laban and Wojciech Kryściński and Divyansh Agarwal and Alexander R. Fabbri and Caiming Xiong and Shafiq Joty and Chien-Sheng Wu},
      year={2023},
      eprint={2305.14540},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{LLM_COT_inconsistency,
      title={RCOT: Detecting and Rectifying Factual Inconsistency in Reasoning by Reversing Chain-of-Thought}, 
      author={Tianci Xue and Ziqi Wang and Zhenhailong Wang and Chi Han and Pengfei Yu and Heng Ji},
      year={2023},
      eprint={2305.11499},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{dinsql,
      title={DIN-SQL: Decomposed In-Context Learning of Text-to-SQL with Self-Correction}, 
      author={Mohammadreza Pourreza and Davood Rafiei},
      year={2023},
      eprint={2304.11015},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{emnlp-steps,
      title={Interactive Text-to-SQL Generation via Editable Step-by-Step Explanations}, 
      author={Yuan Tian and Zheng Zhang and Zheng Ning and Toby Jia-Jun Li and Jonathan K. Kummerfeld and Tianyi Zhang},
      year={2024},
      eprint={2305.07372},
      archivePrefix={arXiv},
      primaryClass={cs.DB}
}

@inproceedings{what_it_wants_me_to_say, series={CHI ’23},
   title={“What It Wants Me To Say”: Bridging the Abstraction Gap Between End-User Programmers and Code-Generating Large Language Models},
   url={http://dx.doi.org/10.1145/3544548.3580817},
   DOI={10.1145/3544548.3580817},
   booktitle={Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
   publisher={ACM},
   author={Liu, Michael Xieyang and Sarkar, Advait and Negreanu, Carina and Zorn, Benjamin and Williams, Jack and Toronto, Neil and Gordon, Andrew D.},
   year={2023},
   month=apr, collection={CHI ’23} 
}


@article{Clark1989,
	author = {Herbert H. Clark and Edward F. Schaefer},
	doi = {10.1207/s15516709cog1302\_7},
	journal = {Cognitive Science},
	number = {2},
	pages = {259--294},
	title = {Contributing to Discourse},
	volume = {13},
	year = {1989}
}

@inproceedings{expectation_experience,
author = {Vaithilingam, Priyan and Zhang, Tianyi and Glassman, Elena L.},
title = {Expectation vs. Experience: Evaluating the Usability of Code Generation Tools Powered by Large Language Models},
year = {2022},
isbn = {9781450391566},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491101.3519665},
doi = {10.1145/3491101.3519665},
abstract = {Recent advances in Large Language Models (LLM) have made automatic code generation possible for real-world programming tasks in general-purpose programming languages such as Python. However, there are few human studies on the usability of these tools and how they fit the programming workflow. In this work, we conducted a within-subjects user study with 24 participants to understand how programmers use and perceive Copilot, a LLM-based code generation tool. We found that, while Copilot did not necessarily improve the task completion time or success rate, most participants preferred to use Copilot in daily programming tasks, since Copilot often provided a useful starting point and saved the effort of searching online. However, participants did face difficulties in understanding, editing, and debugging code snippets generated by Copilot, which significantly hindered their task-solving effectiveness. Finally, we highlighted several promising directions for improving the design of Copilot based on our observations and participants’ feedback.},
booktitle = {Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {332},
numpages = {7},
keywords = {github copilot, large language model},
location = {New Orleans, LA, USA},
series = {CHI EA '22}
}

@article{taking_flight,
author = {Bird, Christian and Ford, Denae and Zimmermann, Thomas and Forsgren, Nicole and Kalliamvakou, Eirini and Lowdermilk, Travis and Gazit, Idan},
title = {Taking Flight with Copilot: Early insights and opportunities of AI-powered pair-programming tools},
year = {2023},
issue_date = {November/December},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {20},
number = {6},
issn = {1542-7730},
url = {https://doi.org/10.1145/3582083},
doi = {10.1145/3582083},
abstract = {Over the next five years, AI-powered tools likely will be helping developers in many diverse tasks. For example, such models may be used to improve code review, directing reviewers to parts of a change where review is most needed or even directly providing feedback on changes. Models such as Codex may suggest fixes for defects in code, build failures, or failing tests. These models are able to write tests automatically, helping to improve code quality and downstream reliability of distributed systems. This study of Copilot shows that developers spend more time reviewing code than actually writing code. As AI-powered tools are integrated into more software development tasks, developer roles will shift so that more time is spent assessing suggestions related to the task than doing the task itself.},
journal = {Queue},
month = {jan},
pages = {35–57},
numpages = {23}
}

@misc{barke2022grounded,
      title={Grounded Copilot: How Programmers Interact with Code-Generating Models}, 
      author={Shraddha Barke and Michael B. James and Nadia Polikarpova},
      year={2022},
      eprint={2206.15000},
      archivePrefix={arXiv},
      primaryClass={cs.HC}
}

@misc{codex,
      title={Evaluating Large Language Models Trained on Code}, 
      author={Mark Chen and Jerry Tworek and Heewoo Jun and Qiming Yuan and Henrique Ponde de Oliveira Pinto and Jared Kaplan and Harri Edwards and Yuri Burda and Nicholas Joseph and Greg Brockman and Alex Ray and Raul Puri and Gretchen Krueger and Michael Petrov and Heidy Khlaaf and Girish Sastry and Pamela Mishkin and Brooke Chan and Scott Gray and Nick Ryder and Mikhail Pavlov and Alethea Power and Lukasz Kaiser and Mohammad Bavarian and Clemens Winter and Philippe Tillet and Felipe Petroski Such and Dave Cummings and Matthias Plappert and Fotios Chantzis and Elizabeth Barnes and Ariel Herbert-Voss and William Hebgen Guss and Alex Nichol and Alex Paino and Nikolas Tezak and Jie Tang and Igor Babuschkin and Suchir Balaji and Shantanu Jain and William Saunders and Christopher Hesse and Andrew N. Carr and Jan Leike and Josh Achiam and Vedant Misra and Evan Morikawa and Alec Radford and Matthew Knight and Miles Brundage and Mira Murati and Katie Mayer and Peter Welinder and Bob McGrew and Dario Amodei and Sam McCandlish and Ilya Sutskever and Wojciech Zaremba},
      year={2021},
      eprint={2107.03374},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{color_psychology, title={Can color really influence your mood and behavior? here’s what to know}, url={https://www.verywellmind.com/color-psychology-2795824}, journal={Verywell Mind}, publisher={Verywell Mind}, author={Kendra Cherry, MSEd}, year={2024}, month={Feb}} 



@misc{bird,
      title={Can LLM Already Serve as A Database Interface? A BIg Bench for Large-Scale Database Grounded Text-to-SQLs}, 
      author={Jinyang Li and Binyuan Hui and Ge Qu and Jiaxi Yang and Binhua Li and Bowen Li and Bailin Wang and Bowen Qin and Rongyu Cao and Ruiying Geng and Nan Huo and Xuanhe Zhou and Chenhao Ma and Guoliang Li and Kevin C. C. Chang and Fei Huang and Reynold Cheng and Yongbin Li},
      year={2023},
      eprint={2305.03111},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2305.03111}, 
}

@article{collapse,
  title={AI models collapse when trained on recursively generated data},
  author={Shumailov, Ilia and Shumaylov, Zakhar and Zhao, Yiren and Papernot, Nicolas and Anderson, Ross and Gal, Yarin},
  journal={Nature},
  volume={631},
  number={8022},
  pages={755--759},
  year={2024},
  publisher={Nature Publishing Group UK London}
}

@misc{diverse_beam_search,
      title={Diverse Beam Search: Decoding Diverse Solutions from Neural Sequence Models}, 
      author={Ashwin K Vijayakumar and Michael Cogswell and Ramprasath R. Selvaraju and Qing Sun and Stefan Lee and David Crandall and Dhruv Batra},
      year={2018},
      eprint={1610.02424},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/1610.02424}, 
}

@misc{codes,
      title={CodeS: Towards Building Open-source Language Models for Text-to-SQL}, 
      author={Haoyang Li and Jing Zhang and Hanbing Liu and Ju Fan and Xiaokang Zhang and Jun Zhu and Renjie Wei and Hongyan Pan and Cuiping Li and Hong Chen},
      year={2024},
      eprint={2402.16347},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.16347}, 
}

@misc{finetune_sql_llm,
      title={Fine-Tuning Language Models for Context-Specific SQL Query Generation}, 
      author={Amine Rebei},
      year={2023},
      eprint={2312.02251},
      archivePrefix={arXiv},
      primaryClass={cs.DB},
      url={https://arxiv.org/abs/2312.02251}, 
}

@misc{sqlcoder,
  author = {Wong, Wendy Aw and Srivastava, Rishabh},
  title = {Open-sourcing sqlcoder},
  year = {2023},
  howpublished = {\url{https://defog.ai/blog/open-sourcing-sqlcoder2-7b/}}
}

@misc{NSText2SQL,
  author = {{Numbers Station Labs}},
  title = {NSText2SQL: An Open Source Text-to-SQL Dataset for Foundation Model Training},
  year = {2023},
  month = jul,
  howpublished = {\url{https://github.com/NumbersStationAI/NSQL}}
}

@misc{thorpe2024dubosqldiverseretrievalaugmentedgeneration,
      title={Dubo-SQL: Diverse Retrieval-Augmented Generation and Fine Tuning for Text-to-SQL}, 
      author={Dayton G. Thorpe and Andrew J. Duberstein and Ian A. Kinsey},
      year={2024},
      eprint={2404.12560},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2404.12560}, 
}

@article{nlp_data_annotate,
title = {Data augmentation approaches in natural language processing: A survey},
journal = {AI Open},
volume = {3},
pages = {71-90},
year = {2022},
issn = {2666-6510},
doi = {https://doi.org/10.1016/j.aiopen.2022.03.001},
url = {https://www.sciencedirect.com/science/article/pii/S2666651022000080},
author = {Bohan Li and Yutai Hou and Wanxiang Che},
keywords = {Machine learning, Data augmentation, Natural language processing},
abstract = {As an effective strategy, data augmentation (DA) alleviates data scarcity scenarios where deep learning techniques may fail. It is widely applied in computer vision then introduced to natural language processing and achieves improvements in many tasks. One of the main focuses of the DA methods is to improve the diversity of training data, thereby helping the model to better generalize to unseen testing data. In this survey, we frame DA methods into three categories based on the diversity of augmented data, including paraphrasing, noising, and sampling. Our paper sets out to analyze DA methods in detail according to the above categories. Further, we also introduce their applications in NLP tasks as well as the challenges. Some useful resources are provided in Appendix A.}
}

@inproceedings{nlp_synthetic_1,
author = {Barzilay, Regina and McKeown, Kathleen R.},
title = {Extracting paraphrases from a parallel corpus},
year = {2001},
publisher = {Association for Computational Linguistics},
address = {USA},
url = {https://doi.org/10.3115/1073012.1073020},
doi = {10.3115/1073012.1073020},
abstract = {While paraphrasing is critical both for interpretation and generation of natural language, current systems use manual or semi-automatic methods to collect paraphrases. We present an unsupervised learning algorithm for identification of paraphrases from a corpus of multiple English translations of the same source text. Our approach yields phrasal and single word lexical paraphrases as well as syntactic paraphrases.},
booktitle = {Proceedings of the 39th Annual Meeting on Association for Computational Linguistics},
pages = {50–57},
numpages = {8},
location = {Toulouse, France},
series = {ACL '01}
}

@inproceedings{nlp_synthetic_2,
    title = "Improving Neural Machine Translation Models with Monolingual Data",
    author = "Sennrich, Rico  and
      Haddow, Barry  and
      Birch, Alexandra",
    editor = "Erk, Katrin  and
      Smith, Noah A.",
    booktitle = "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2016",
    address = "Berlin, Germany",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P16-1009",
    doi = "10.18653/v1/P16-1009",
    pages = "86--96",
}

@inproceedings{nlp_synthetic_3,
    title = "Counterfactual Data Augmentation for Neural Machine Translation",
    author = "Liu, Qi  and
      Kusner, Matt  and
      Blunsom, Phil",
    editor = "Toutanova, Kristina  and
      Rumshisky, Anna  and
      Zettlemoyer, Luke  and
      Hakkani-Tur, Dilek  and
      Beltagy, Iz  and
      Bethard, Steven  and
      Cotterell, Ryan  and
      Chakraborty, Tanmoy  and
      Zhou, Yichao",
    booktitle = "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.naacl-main.18",
    doi = "10.18653/v1/2021.naacl-main.18",
    pages = "187--197",
    abstract = "We propose a data augmentation method for neural machine translation. It works by interpreting language models and phrasal alignment causally. Specifically, it creates augmented parallel translation corpora by generating (path-specific) counterfactual aligned phrases. We generate these by sampling new source phrases from a masked language model, then sampling an aligned counterfactual target phrase by noting that a translation language model can be interpreted as a Gumbel-Max Structural Causal Model (Oberst and Sontag, 2019). Compared to previous work, our method takes both context and alignment into account to maintain the symmetry between source and target sequences. Experiments on IWSLT{'}15 English → Vietnamese, WMT{'}17 English → German, WMT{'}18 English → Turkish, and WMT{'}19 robust English → French show that the method can improve the performance of translation, backtranslation and translation robustness.",
}

@inproceedings{nlp_synthetic_4,
    title = "An Exploration of Data Augmentation and Sampling Techniques for Domain-Agnostic Question Answering",
    author = "Longpre, Shayne  and
      Lu, Yi  and
      Tu, Zhucheng  and
      DuBois, Chris",
    editor = "Fisch, Adam  and
      Talmor, Alon  and
      Jia, Robin  and
      Seo, Minjoon  and
      Choi, Eunsol  and
      Chen, Danqi",
    booktitle = "Proceedings of the 2nd Workshop on Machine Reading for Question Answering",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-5829",
    doi = "10.18653/v1/D19-5829",
    pages = "220--227",
    abstract = "To produce a domain-agnostic question answering model for the Machine Reading Question Answering (MRQA) 2019 Shared Task, we investigate the relative benefits of large pre-trained language models, various data sampling strategies, as well as query and context paraphrases generated by back-translation. We find a simple negative sampling technique to be particularly effective, even though it is typically used for datasets that include unanswerable questions, such as SQuAD 2.0. When applied in conjunction with per-domain sampling, our XLNet (Yang et al., 2019)-based submission achieved the second best Exact Match and F1 in the MRQA leaderboard competition.",
}

@misc{semantic_parsing_data_augmentation_1,
      title={Data Recombination for Neural Semantic Parsing}, 
      author={Robin Jia and Percy Liang},
      year={2016},
      eprint={1606.03622},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1606.03622}, 
}

@misc{semantic_parsing_data_augmentation_2,
      title={Sequence-to-Sequence Data Augmentation for Dialogue Language Understanding}, 
      author={Yutai Hou and Yijia Liu and Wanxiang Che and Ting Liu},
      year={2018},
      eprint={1807.01554},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1807.01554}, 
}

@misc{semantic_parsing_data_augmentation_3,
      title={GraPPa: Grammar-Augmented Pre-Training for Table Semantic Parsing}, 
      author={Tao Yu and Chien-Sheng Wu and Xi Victoria Lin and Bailin Wang and Yi Chern Tan and Xinyi Yang and Dragomir Radev and Richard Socher and Caiming Xiong},
      year={2021},
      eprint={2009.13845},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2009.13845}, 
}

@inproceedings{semantic_parsing_data_augmentation_4,
    title = "Grounded Adaptation for Zero-shot Executable Semantic Parsing",
    author = "Zhong, Victor  and
      Lewis, Mike  and
      Wang, Sida I.  and
      Zettlemoyer, Luke",
    editor = "Webber, Bonnie  and
      Cohn, Trevor  and
      He, Yulan  and
      Liu, Yang",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.558",
    doi = "10.18653/v1/2020.emnlp-main.558",
    pages = "6869--6882",
    abstract = "We propose Grounded Adaptation for Zeroshot Executable Semantic Parsing (GAZP) to adapt an existing semantic parser to new environments (e.g. new database schemas). GAZP combines a forward semantic parser with a backward utterance generator to synthesize data (e.g. utterances and SQL queries) in the new environment, then selects cycle-consistent examples to adapt the parser. Unlike data-augmentation, which typically synthesizes unverified examples in the training environment, GAZP synthesizes examples in the new environment whose input-output consistency are verified through execution. On the Spider, Sparc, and CoSQL zero-shot semantic parsing tasks, GAZP improves logical form and execution accuracy of the baseline parser. Our analyses show that GAZP outperforms data-augmentation in the training environment, performance increases with the amount of GAZP-synthesized data, and cycle-consistency is central to successful adaptation.",
}

@inproceedings{PCFG_SQL_synthesize,
    title = "Learning to Synthesize Data for Semantic Parsing",
    author = "Wang, Bailin  and
      Yin, Wenpeng  and
      Lin, Xi Victoria  and
      Xiong, Caiming",
    editor = "Toutanova, Kristina  and
      Rumshisky, Anna  and
      Zettlemoyer, Luke  and
      Hakkani-Tur, Dilek  and
      Beltagy, Iz  and
      Bethard, Steven  and
      Cotterell, Ryan  and
      Chakraborty, Tanmoy  and
      Zhou, Yichao",
    booktitle = "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.naacl-main.220",
    doi = "10.18653/v1/2021.naacl-main.220",
    pages = "2760--2766",
    abstract = "Synthesizing data for semantic parsing has gained increasing attention recently. However, most methods require handcrafted (high-precision) rules in their generative process, hindering the exploration of diverse unseen data. In this work, we propose a generative model which features a (non-neural) PCFG that models the composition of programs (e.g., SQL), and a BART-based translation model that maps a program to an utterance. Due to the simplicity of PCFG and pre-trained BART, our generative model can be efficiently learned from existing data at hand. Moreover, explicitly modeling compositions using PCFG leads to better exploration of unseen programs, thus generate more diverse data. We evaluate our method in both in-domain and out-of-domain settings of text-to-SQL parsing on the standard benchmarks of GeoQuery and Spider, respectively. Our empirical results show that the synthesized data generated from our model can substantially help a semantic parser achieve better compositional and domain generalization.",
}

@inproceedings{syntaxsqlnet,
    title = "{S}yntax{SQLN}et: Syntax Tree Networks for Complex and Cross-Domain Text-to-{SQL} Task",
    author = "Yu, Tao  and
      Yasunaga, Michihiro  and
      Yang, Kai  and
      Zhang, Rui  and
      Wang, Dongxu  and
      Li, Zifan  and
      Radev, Dragomir",
    editor = "Riloff, Ellen  and
      Chiang, David  and
      Hockenmaier, Julia  and
      Tsujii, Jun{'}ichi",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D18-1193",
    doi = "10.18653/v1/D18-1193",
    pages = "1653--1663",
    abstract = "Most existing studies in text-to-SQL tasks do not require generating complex SQL queries with multiple clauses or sub-queries, and generalizing to new, unseen databases. In this paper we propose SyntaxSQLNet, a syntax tree network to address the complex and cross-domain text-to-SQL generation task. SyntaxSQLNet employs a SQL specific syntax tree-based decoder with SQL generation path history and table-aware column attention encoders. We evaluate SyntaxSQLNet on a new large-scale text-to-SQL corpus containing databases with multiple tables and complex SQL queries containing multiple SQL clauses and nested queries. We use a database split setting where databases in the test set are unseen during training. Experimental results show that SyntaxSQLNet can handle a significantly greater number of complex SQL examples than prior work, outperforming the previous state-of-the-art model by 9.5{\%} in exact matching accuracy. To our knowledge, we are the first to study this complex text-to-SQL task. Our task and models with the latest updates are available at \url{https://yale-lily.github.io/seq2sql/spider}.",
}

@misc{IRnet,
      title={IRNet: Iterative Refinement Network for Noisy Partial Label Learning}, 
      author={Zheng Lian and Mingyu Xu and Lan Chen and Licai Sun and Bin Liu and Jianhua Tao},
      year={2023},
      eprint={2211.04774},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2211.04774}, 
}

@misc{sql_to_text3,
      title={Data Augmentation with Hierarchical SQL-to-Question Generation for Cross-domain Text-to-SQL Parsing}, 
      author={Kun Wu and Lijie Wang and Zhenghua Li and Ao Zhang and Xinyan Xiao and Hua Wu and Min Zhang and Haifeng Wang},
      year={2022},
      eprint={2103.02227},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2103.02227}, 
}

@misc{STEPS,
      title={Interactive Text-to-SQL Generation via Editable Step-by-Step Explanations}, 
      author={Yuan Tian and Zheng Zhang and Zheng Ning and Toby Jia-Jun Li and Jonathan K. Kummerfeld and Tianyi Zhang},
      year={2024},
      eprint={2305.07372},
      archivePrefix={arXiv},
      primaryClass={cs.DB},
      url={https://arxiv.org/abs/2305.07372}, 
}

@inproceedings{dusql,
    title = "{D}u{SQL}: A Large-Scale and Pragmatic {C}hinese Text-to-{SQL} Dataset",
    author = "Wang, Lijie  and
      Zhang, Ao  and
      Wu, Kun  and
      Sun, Ke  and
      Li, Zhenghua  and
      Wu, Hua  and
      Zhang, Min  and
      Wang, Haifeng",
    editor = "Webber, Bonnie  and
      Cohn, Trevor  and
      He, Yulan  and
      Liu, Yang",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.562",
    doi = "10.18653/v1/2020.emnlp-main.562",
    pages = "6923--6935",
    abstract = "Due to the lack of labeled data, previous research on text-to-SQL parsing mainly focuses on English. Representative English datasets include ATIS, WikiSQL, Spider, etc. This paper presents DuSQL, a larges-scale and pragmatic Chinese dataset for the cross-domain text-to-SQL task, containing 200 databases, 813 tables, and 23,797 question/SQL pairs. Our new dataset has three major characteristics. First, by manually analyzing questions from several representative applications, we try to figure out the true distribution of SQL queries in real-life needs. Second, DuSQL contains a considerable proportion of SQL queries involving row or column calculations, motivated by our analysis on the SQL query distributions. Finally, we adopt an effective data construction framework via human-computer collaboration. The basic idea is automatically generating SQL queries based on the SQL grammar and constrained by the given database. This paper describes in detail the construction process and data statistics of DuSQL. Moreover, we present and compare performance of several open-source text-to-SQL parsers with minor modification to accommodate Chinese, including a simple yet effective extension to IRNet for handling calculation SQL queries.",
}

@misc{spider_dk,
      title={Exploring Underexplored Limitations of Cross-Domain Text-to-SQL Generalization}, 
      author={Yujian Gan and Xinyun Chen and Matthew Purver},
      year={2021},
      eprint={2109.05157},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2109.05157}, 
}

@misc{spider_syn,
      title={Towards Robustness of Text-to-SQL Models against Synonym Substitution}, 
      author={Yujian Gan and Xinyun Chen and Qiuping Huang and Matthew Purver and John R. Woodward and Jinxia Xie and Pengsheng Huang},
      year={2021},
      eprint={2106.01065},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2106.01065}, 
}

@inproceedings{atis,
    title = "The {ATIS} Spoken Language Systems Pilot Corpus",
    author = "Hemphill, Charles T.  and
      Godfrey, John J.  and
      Doddington, George R.",
    booktitle = "Speech and Natural Language: Proceedings of a Workshop Held at Hidden Valley, {P}ennsylvania, June 24-27,1990",
    year = "1990",
    url = "https://aclanthology.org/H90-1021",
}

@inproceedings{advising,
    title = "Improving Text-to-{SQL} Evaluation Methodology",
    author = "Finegan-Dollak, Catherine  and
      Kummerfeld, Jonathan K.  and
      Zhang, Li  and
      Ramanathan, Karthik  and
      Sadasivam, Sesh  and
      Zhang, Rui  and
      Radev, Dragomir",
    editor = "Gurevych, Iryna  and
      Miyao, Yusuke",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P18-1033",
    doi = "10.18653/v1/P18-1033",
    pages = "351--360",
    abstract = "To be informative, an evaluation must measure how well systems generalize to realistic unseen data. We identify limitations of and propose improvements to current evaluations of text-to-SQL systems. First, we compare human-generated and automatically generated questions, characterizing properties of queries necessary for real-world applications. To facilitate evaluation on multiple datasets, we release standardized and improved versions of seven existing datasets and one new text-to-SQL dataset. Second, we show that the current division of data into training and test sets measures robustness to variations in the way questions are asked, but only partially tests how well systems generalize to new queries; therefore, we propose a complementary dataset split for evaluation of future work. Finally, we demonstrate how the common practice of anonymizing variables during evaluation removes an important challenge of the task. Our observations highlight key difficulties, and our methodology enables effective measurement of future development.",
}

@misc{yelp_and_IMDB,
      title={Type- and Content-Driven Synthesis of SQL Queries from Natural Language}, 
      author={Navid Yaghmazadeh and Yuepeng Wang and Isil Dillig and Thomas Dillig},
      year={2017},
      eprint={1702.01168},
      archivePrefix={arXiv},
      primaryClass={cs.DB},
      url={https://arxiv.org/abs/1702.01168}, 
}

@inproceedings{scholar,
    title = "Learning a Neural Semantic Parser from User Feedback",
    author = "Iyer, Srinivasan  and
      Konstas, Ioannis  and
      Cheung, Alvin  and
      Krishnamurthy, Jayant  and
      Zettlemoyer, Luke",
    editor = "Barzilay, Regina  and
      Kan, Min-Yen",
    booktitle = "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P17-1089",
    doi = "10.18653/v1/P17-1089",
    pages = "963--973",
    abstract = "We present an approach to rapidly and easily build natural language interfaces to databases for new domains, whose performance improves over time based on user feedback, and requires minimal intervention. To achieve this, we adapt neural sequence models to map utterances directly to SQL with its full expressivity, bypassing any intermediate meaning representations. These models are immediately deployed online to solicit feedback from real users to flag incorrect queries. Finally, the popularity of SQL facilitates gathering annotations for incorrect predictions using the crowd, which is directly used to improve our models. This complete feedback loop, without intermediate representations or database specific engineering, opens up new ways of building high quality semantic parsers. Experiments suggest that this approach can be deployed quickly for any new target domain, as we show by learning a semantic parser for an online academic database from scratch.",
}

@inproceedings{restaurants,
    title = "Automated Construction of Database Interfaces: Intergrating Statistical and Relational Learning for Semantic Parsing",
    author = "Tang, Lappoon R.  and
      Mooney, Raymond J.",
    booktitle = "2000 Joint {SIGDAT} Conference on Empirical Methods in Natural Language Processing and Very Large Corpora",
    month = oct,
    year = "2000",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W00-1317",
    doi = "10.3115/1117794.1117811",
    pages = "133--141",
}

@inproceedings{geoquery,
author = {Zelle, John M. and Mooney, Raymond J.},
title = {Learning to parse database queries using inductive logic programming},
year = {1996},
isbn = {026251091X},
publisher = {AAAI Press},
abstract = {This paper presents recent work using the CHILL parser acquisition system to automate the construction of a natural-language interface for database queries. CHILL treats parser acquisition as the learning of search-control rules within a logic program representing a shift-reduce parser and uses techniques from Inductive Logic Programming to learn relational control knowledge. Starting with a general framework for constructing a suitable logical form, CHILL is able to train on a corpus comprising sentences paired with database queries and induce parsers that map subsequent sentences directly into executable queries. Experimental results with a complete database-query application for U.S. geography show that CHILL is able to learn parsers that outperform a preexisting, hand-crafted counterpart. These results demonstrate the ability of a corpus-based system to produce more than purely syntactic representations. They also provide direct evidence of the utility of an empirical approach at the level of a complete natural language application.},
booktitle = {Proceedings of the Thirteenth National Conference on Artificial Intelligence - Volume 2},
pages = {1050–1055},
numpages = {6},
location = {Portland, Oregon},
series = {AAAI'96}
}

@article{academic,
author = {Li, Fei and Jagadish, H. V.},
title = {Constructing an interactive natural language interface for relational databases},
year = {2014},
issue_date = {September 2014},
publisher = {VLDB Endowment},
volume = {8},
number = {1},
issn = {2150-8097},
url = {https://doi.org/10.14778/2735461.2735468},
doi = {10.14778/2735461.2735468},
abstract = {Natural language has been the holy grail of query interface designers, but has generally been considered too hard to work with, except in limited specific circumstances. In this paper, we describe the architecture of an interactive natural language query interface for relational databases. Through a carefully limited interaction with the user, we are able to correctly interpret complex natural language queries, in a generic manner across a range of domains. By these means, a logically complex English language sentence is correctly translated into a SQL query, which may include aggregation, nesting, and various types of joins, among other things, and can be evaluated against an RDBMS. We have constructed a system, NaLIR (Natural Language Interface for Relational databases), embodying these ideas. Our experimental assessment, through user studies, demonstrates that NaLIR is good enough to be usable in practice: even naive users are able to specify quite complex ad-hoc queries.},
journal = {Proc. VLDB Endow.},
month = {sep},
pages = {73–84},
numpages = {12}
}

@inproceedings{kaggledbqa,
    title = "{K}aggle{DBQA}: Realistic Evaluation of Text-to-{SQL} Parsers",
    author = "Lee, Chia-Hsuan  and
      Polozov, Oleksandr  and
      Richardson, Matthew",
    editor = "Zong, Chengqing  and
      Xia, Fei  and
      Li, Wenjie  and
      Navigli, Roberto",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-long.176",
    doi = "10.18653/v1/2021.acl-long.176",
    pages = "2261--2273",
    abstract = "The goal of database question answering is to enable natural language querying of real-life relational databases in diverse application domains. Recently, large-scale datasets such as Spider and WikiSQL facilitated novel modeling techniques for text-to-SQL parsing, improving zero-shot generalization to unseen databases. In this work, we examine the challenges that still prevent these techniques from practical deployment. First, we present KaggleDBQA, a new cross-domain evaluation dataset of real Web databases, with domain-specific data types, original formatting, and unrestricted questions. Second, we re-examine the choice of evaluation tasks for text-to-SQL parsers as applied in real-life settings. Finally, we augment our in-domain evaluation task with database documentation, a naturally occurring source of implicit domain knowledge. We show that KaggleDBQA presents a challenge to state-of-the-art zero-shot parsers but a more realistic evaluation setting and creative use of associated database documentation boosts their accuracy by over 13.2{\%}, doubling their performance.",
}

@misc{llm_hallucination,
      title={A Survey on Hallucination in Large Language Models: Principles, Taxonomy, Challenges, and Open Questions},
      author={Lei Huang and Weijiang Yu and Weitao Ma and Weihong Zhong and Zhangyin Feng and Haotian Wang and Qianglong Chen and Weihua Peng and Xiaocheng Feng and Bing Qin and Ting Liu},
      year={2023},
      eprint={2311.05232},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2311.05232}, 
}

@inproceedings{simiar_algorithm,
    title = "Question Generation from {SQL} Queries Improves Neural Semantic Parsing",
    author = "Guo, Daya  and
      Sun, Yibo  and
      Tang, Duyu  and
      Duan, Nan  and
      Yin, Jian  and
      Chi, Hong  and
      Cao, James  and
      Chen, Peng  and
      Zhou, Ming",
    editor = "Riloff, Ellen  and
      Chiang, David  and
      Hockenmaier, Julia  and
      Tsujii, Jun{'}ichi",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D18-1188",
    doi = "10.18653/v1/D18-1188",
    pages = "1597--1607",
    abstract = "In this paper, we study how to learn a semantic parser of state-of-the-art accuracy with less supervised training data. We conduct our study on WikiSQL, the largest hand-annotated semantic parsing dataset to date. First, we demonstrate that question generation is an effective method that empowers us to learn a state-of-the-art neural network based semantic parser with thirty percent of the supervised training data. Second, we show that applying question generation to the full supervised training data further improves the state-of-the-art model. In addition, we observe that there is a logarithmic relationship between the accuracy of a semantic parser and the amount of training data.",
}

@misc{byokg,
      title={Bring Your Own KG: Self-Supervised Program Synthesis for Zero-Shot KGQA}, 
      author={Dhruv Agarwal and Rajarshi Das and Sopan Khosla and Rashmi Gangadharaiah},
      year={2024},
      eprint={2311.07850},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2311.07850}, 
}

@article{conda,
  title={ConDA: state-based data augmentation for context-dependent text-to-SQL},
  author={Wang, Dingzirui and Dou, Longxu and Che, Wanxiang and Wang, Jiaqi and Liu, Jinbo and Li, Lixin and Shang, Jingan and Tao, Lei and Zhang, Jie and Fu, Cong and others},
  journal={International Journal of Machine Learning and Cybernetics},
  pages={1--12},
  year={2024},
  publisher={Springer}
}

@inproceedings{bart,
    title = "{BART}: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension",
    author = "Lewis, Mike  and
      Liu, Yinhan  and
      Goyal, Naman  and
      Ghazvininejad, Marjan  and
      Mohamed, Abdelrahman  and
      Levy, Omer  and
      Stoyanov, Veselin  and
      Zettlemoyer, Luke",
    editor = "Jurafsky, Dan  and
      Chai, Joyce  and
      Schluter, Natalie  and
      Tetreault, Joel",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.703",
    doi = "10.18653/v1/2020.acl-main.703",
    pages = "7871--7880",
    abstract = "We present BART, a denoising autoencoder for pretraining sequence-to-sequence models. BART is trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text. It uses a standard Tranformer-based neural machine translation architecture which, despite its simplicity, can be seen as generalizing BERT (due to the bidirectional encoder), GPT (with the left-to-right decoder), and other recent pretraining schemes. We evaluate a number of noising approaches, finding the best performance by both randomly shuffling the order of sentences and using a novel in-filling scheme, where spans of text are replaced with a single mask token. BART is particularly effective when fine tuned for text generation but also works well for comprehension tasks. It matches the performance of RoBERTa on GLUE and SQuAD, and achieves new state-of-the-art results on a range of abstractive dialogue, question answering, and summarization tasks, with gains of up to 3.5 ROUGE. BART also provides a 1.1 BLEU increase over a back-translation system for machine translation, with only target language pretraining. We also replicate other pretraining schemes within the BART framework, to understand their effect on end-task performance.",
}

@misc{sql_to_text2,
      title={Question Generation from SQL Queries Improves Neural Semantic Parsing}, 
      author={Daya Guo and Yibo Sun and Duyu Tang and Nan Duan and Jian Yin and Hong Chi and James Cao and Peng Chen and Ming Zhou},
      year={2018},
      eprint={1808.06304},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1808.06304}, 
}


@misc{sqlucid,
      title={SQLucid: Grounding Natural Language Database Queries with Interactive Explanations}, 
      author={Yuan Tian and Jonathan K. Kummerfeld and Toby Jia-Jun Li and Tianyi Zhang},
      year={2024},
      eprint={2409.06178},
      archivePrefix={arXiv},
      primaryClass={cs.HC},
      url={https://arxiv.org/abs/2409.06178}, 
}

@article{semi_automatic_data_annotation,
title = {Semi-automatic data annotation guided by feature space projection},
journal = {Pattern Recognition},
volume = {109},
pages = {107612},
year = {2021},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2020.107612},
url = {https://www.sciencedirect.com/science/article/pii/S0031320320304155},
author = {Bárbara C. Benato and Jancarlo F. Gomes and Alexandru C. Telea and Alexandre X. Falcão},
keywords = {Semi-supervised learning, Unsupervised feature learning, Interactive data annotation, Autoencoder-neural networks, Data visualization},
abstract = {Data annotation using visual inspection (supervision) of each training sample can be laborious. Interactive solutions alleviate this by helping experts propagate labels from a few supervised samples to unlabeled ones based solely on the visual analysis of their feature space projection (with no further sample supervision). We present a semi-automatic data annotation approach based on suitable feature space projection and semi-supervised label estimation. We validate our method on the popular MNIST dataset and on images of human intestinal parasites with and without fecal impurities, a large and diverse dataset that makes classification very hard. We evaluate two approaches for semi-supervised learning from the latent and projection spaces, to choose the one that best reduces user annotation effort and also increases classification accuracy on unseen data. Our results demonstrate the added-value of visual analytics tools that combine complementary abilities of humans and machines for more effective machine learning.}
}

@misc{ARAIDA,
      title={ARAIDA: Analogical Reasoning-Augmented Interactive Data Annotation}, 
      author={Chen Huang and Yiping Jin and Ilija Ilievski and Wenqiang Lei and Jiancheng Lv},
      year={2024},
      eprint={2405.11912},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2405.11912}, 
}

@inproceedings{INCEpTION2,
    title = "The {INCE}p{TION} Platform: Machine-Assisted and Knowledge-Oriented Interactive Annotation",
    author = "Klie, Jan-Christoph  and
      Bugert, Michael  and
      Boullosa, Beto  and
      Eckart de Castilho, Richard  and
      Gurevych, Iryna",
    editor = "Zhao, Dongyan",
    booktitle = "Proceedings of the 27th International Conference on Computational Linguistics: System Demonstrations",
    month = aug,
    year = "2018",
    address = "Santa Fe, New Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/C18-2002",
    pages = "5--9",
    abstract = "We introduce INCEpTION, a new annotation platform for tasks including interactive and semantic annotation (e.g., concept linking, fact linking, knowledge base population, semantic frame annotation). These tasks are very time consuming and demanding for annotators, especially when knowledge bases are used. We address these issues by developing an annotation platform that incorporates machine learning capabilities which actively assist and guide annotators. The platform is both generic and modular. It targets a range of research domains in need of semantic annotation, such as digital humanities, bioinformatics, or linguistics. INCEpTION is publicly available as open-source software.",
}
@inproceedings{INCEpTION,
    title = "The {INCE}p{TION} Platform: Machine-Assisted and Knowledge-Oriented Interactive Annotation",
    author = "Klie, Jan-Christoph  and
      Bugert, Michael  and
      Boullosa, Beto  and
      Eckart de Castilho, Richard  and
      Gurevych, Iryna",
    editor = "Zhao, Dongyan",
    booktitle = "Proceedings of the 27th International Conference on Computational Linguistics: System Demonstrations",
    month = aug,
    year = "2018",
    address = "Santa Fe, New Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/C18-2002",
    pages = "5--9",
    abstract = "We introduce INCEpTION, a new annotation platform for tasks including interactive and semantic annotation (e.g., concept linking, fact linking, knowledge base population, semantic frame annotation). These tasks are very time consuming and demanding for annotators, especially when knowledge bases are used. We address these issues by developing an annotation platform that incorporates machine learning capabilities which actively assist and guide annotators. The platform is both generic and modular. It targets a range of research domains in need of semantic annotation, such as digital humanities, bioinformatics, or linguistics. INCEpTION is publicly available as open-source software.",
}

@inproceedings{interactive_video_object_mask_annotation,
  title={Interactive video object mask annotation},
  author={Le, Trung-Nghia and Nguyen, Tam V and Tran, Quoc-Cuong and Nguyen, Lam and Hoang, Trung-Hieu and Le, Minh-Quan and Tran, Minh-Triet},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={18},
  pages={16067--16070},
  year={2021}
}

@inproceedings{annollm,
    title = "{A}nno{LLM}: Making Large Language Models to Be Better Crowdsourced Annotators",
    author = "He, Xingwei  and
      Lin, Zhenghao  and
      Gong, Yeyun  and
      Jin, A-Long  and
      Zhang, Hang  and
      Lin, Chen  and
      Jiao, Jian  and
      Yiu, Siu Ming  and
      Duan, Nan  and
      Chen, Weizhu",
    editor = "Yang, Yi  and
      Davani, Aida  and
      Sil, Avi  and
      Kumar, Anoop",
    booktitle = "Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 6: Industry Track)",
    month = jun,
    year = "2024",
    address = "Mexico City, Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.naacl-industry.15",
    doi = "10.18653/v1/2024.naacl-industry.15",
    pages = "165--190",
    abstract = "Many natural language processing (NLP) tasks rely on labeled data to train machine learning models with high performance. However, data annotation is time-consuming and expensive, especially when the task involves a large amount of data or requires specialized domains. Recently, GPT-3.5 series models have demonstrated remarkable few-shot and zero-shot ability across various NLP tasks. In this paper, we first claim that large language models (LLMs), such as GPT-3.5, can serve as an excellent crowdsourced annotator when provided with sufficient guidance and demonstrated examples. Accordingly, we propose AnnoLLM, an annotation system powered by LLMs, which adopts a two-step approach, explain-then-annotate. Concretely, we first prompt LLMs to provide explanations for why the specific ground truth answer/label was assigned for a given example. Then, we construct the few-shot chain-of-thought prompt with the self-generated explanation and employ it to annotate the unlabeled data with LLMs. Our experiment results on three tasks, including user input and keyword relevance assessment, BoolQ, and WiC, demonstrate that AnnoLLM surpasses or performs on par with crowdsourced annotators. Furthermore, we build the first conversation-based information retrieval dataset employing AnnoLLM. This dataset is designed to facilitate the development of retrieval models capable of retrieving pertinent documents for conversational text. Human evaluation has validated the dataset{'}s high quality.",
}

@article{chatgpt_outperform_crowd_workers,
   title={ChatGPT outperforms crowd workers for text-annotation tasks},
   volume={120},
   ISSN={1091-6490},
   url={http://dx.doi.org/10.1073/pnas.2305016120},
   DOI={10.1073/pnas.2305016120},
   number={30},
   journal={Proceedings of the National Academy of Sciences},
   publisher={Proceedings of the National Academy of Sciences},
   author={Gilardi, Fabrizio and Alizadeh, Meysam and Kubli, Maël},
   year={2023},
   month=jul }

@inproceedings{freeal,
    title = "{F}ree{AL}: Towards Human-Free Active Learning in the Era of Large Language Models",
    author = "Xiao, Ruixuan  and
      Dong, Yiwen  and
      Zhao, Junbo  and
      Wu, Runze  and
      Lin, Minmin  and
      Chen, Gang  and
      Wang, Haobo",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.896",
    doi = "10.18653/v1/2023.emnlp-main.896",
    pages = "14520--14535",
    abstract = "Collecting high-quality labeled data for model training is notoriously time-consuming and labor-intensive for various NLP tasks. While copious solutions, such as active learning for small language models (SLMs) and prevalent in-context learning in the era of large language models (LLMs), have been proposed and alleviate the labeling burden to some extent, their performances are still subject to human intervention. It is still underexplored how to reduce the annotation cost in the LLMs era. To bridge this, we revolutionize traditional active learning and propose an innovative collaborative learning framework FreeAL to interactively distill and filter the task-specific knowledge from LLMs. During collaborative training, an LLM serves as an active annotator inculcating its coarse-grained knowledge, while a downstream SLM is incurred as a student to filter out high-quality in-context samples to feedback LLM for the subsequent label refinery. Extensive experiments on eight benchmark datasets demonstrate that FreeAL largely enhances the zero-shot performances for both SLM and LLM without any human supervision.",
}

@inproceedings{active_learning1,
    title = "Reduce Human Labor On Evaluating Conversational Information Retrieval System: A Human-Machine Collaboration Approach",
    author = "Huang, Chen  and
      Qin, Peixin  and
      Lei, Wenqiang  and
      Lv, Jiancheng",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.670",
    doi = "10.18653/v1/2023.emnlp-main.670",
    pages = "10876--10891",
    abstract = "Evaluating conversational information retrieval (CIR) systems is a challenging task that requires a significant amount of human labor for annotation. It is imperative to invest significant effort into researching more labor-effective methods for evaluating CIR systems. To touch upon this challenge, we take the first step to involve active testing in CIR evaluation and propose a novel method, called HomCoE. It strategically selects a few data for human annotation, then calibrates the evaluation results to eliminate evaluation biases. As such, it makes an accurate evaluation of the CIR system at low human labor. We experimentally reveal that it consumes less than 1{\%} of human labor and achieves a consistency rate of 95{\%}-99{\%} with human evaluation results. This emphasizes the superiority of our method over other baselines.",
}

@misc{active_learning2,
      title={Reinforced active learning for image segmentation}, 
      author={Arantxa Casanova and Pedro O. Pinheiro and Negar Rostamzadeh and Christopher J. Pal},
      year={2020},
      eprint={2002.06583},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2002.06583}, 
}

@inproceedings{active_learning3,
    title = "Active Learning with {A}mazon {M}echanical {T}urk",
    author = {Laws, Florian  and
      Scheible, Christian  and
      Sch{\"u}tze, Hinrich},
    editor = "Barzilay, Regina  and
      Johnson, Mark",
    booktitle = "Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing",
    month = jul,
    year = "2011",
    address = "Edinburgh, Scotland, UK.",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D11-1143",
    pages = "1546--1556",
}

@inproceedings{fitannotator,
    title = "{FITA}nnotator: A Flexible and Intelligent Text Annotation System",
    author = "Li, Yanzeng  and
      Yu, Bowen  and
      Quangang, Li  and
      Liu, Tingwen",
    editor = "Sil, Avi  and
      Lin, Xi Victoria",
    booktitle = "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Demonstrations",
    month = jun,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.naacl-demos.5",
    doi = "10.18653/v1/2021.naacl-demos.5",
    pages = "35--41",
    abstract = "In this paper, we introduce FITAnnotator, a generic web-based tool for efficient text annotation. Benefiting from the fully modular architecture design, FITAnnotator provides a systematic solution for the annotation of a variety of natural language processing tasks, including classification, sequence tagging and semantic role annotation, regardless of the language. Three kinds of interfaces are developed to annotate instances, evaluate annotation quality and manage the annotation task for annotators, reviewers and managers, respectively. FITAnnotator also gives intelligent annotations by introducing task-specific assistant to support and guide the annotators based on active learning and incremental learning strategies. This assistant is able to effectively update from the annotator feedbacks and easily handle the incremental labeling scenarios.",
}

@misc{llm_sql_equivalence,
      title={LLM-SQL-Solver: Can LLMs Determine SQL Equivalence?}, 
      author={Fuheng Zhao and Lawrence Lim and Ishtiyaque Ahmad and Divyakant Agrawal and Amr El Abbadi},
      year={2024},
      eprint={2312.10321},
      archivePrefix={arXiv},
      primaryClass={cs.DB},
      url={https://arxiv.org/abs/2312.10321}, 
}

@misc{calibration_and_correctness,
      title={Calibration and Correctness of Language Models for Code}, 
      author={Claudio Spiess and David Gros and Kunal Suresh Pai and Michael Pradel and Md Rafiqul Islam Rabin and Amin Alipour and Susmit Jha and Prem Devanbu and Toufique Ahmed},
      year={2024},
      eprint={2402.02047},
      archivePrefix={arXiv},
      primaryClass={cs.SE},
      url={https://arxiv.org/abs/2402.02047}, 
}

@misc{tian2023justaskcalibrationstrategies,
      title={Just Ask for Calibration: Strategies for Eliciting Calibrated Confidence Scores from Language Models Fine-Tuned with Human Feedback}, 
      author={Katherine Tian and Eric Mitchell and Allan Zhou and Archit Sharma and Rafael Rafailov and Huaxiu Yao and Chelsea Finn and Christopher D. Manning},
      year={2023},
      eprint={2305.14975},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2305.14975}, 
}

@misc{llm_data_annotation,
      title={Large Language Models for Data Annotation: A Survey}, 
      author={Zhen Tan and Dawei Li and Song Wang and Alimohammad Beigi and Bohan Jiang and Amrita Bhattacharjee and Mansooreh Karami and Jundong Li and Lu Cheng and Huan Liu},
      year={2024},
      eprint={2402.13446},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.13446}, 
}

@inproceedings{llm_annotator_1,
    title = "{GPT}s Are Multilingual Annotators for Sequence Generation Tasks",
    author = "Choi, Juhwan  and
      Lee, Eunju  and
      Jin, Kyohoon  and
      Kim, YoungBin",
    editor = "Graham, Yvette  and
      Purver, Matthew",
    booktitle = "Findings of the Association for Computational Linguistics: EACL 2024",
    month = mar,
    year = "2024",
    address = "St. Julian{'}s, Malta",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-eacl.2",
    pages = "17--40",
    abstract = "Data annotation is an essential step for constructing new datasets. However, the conventional approach of data annotation through crowdsourcing is both time-consuming and expensive. In addition, the complexity of this process increases when dealing with low-resource languages owing to the difference in the language pool of crowdworkers. To address these issues, this study proposes an autonomous annotation method by utilizing large language models, which have been recently demonstrated to exhibit remarkable performance. Through our experiments, we demonstrate that the proposed method is not just cost-efficient but also applicable for low-resource language annotation. Additionally, we constructed an image captioning dataset using our approach and are committed to open this dataset for future study. We have opened our source code for further study and reproducibility.",
}

@misc{ICL1,
      title={A Survey on In-context Learning}, 
      author={Qingxiu Dong and Lei Li and Damai Dai and Ce Zheng and Jingyuan Ma and Rui Li and Heming Xia and Jingjing Xu and Zhiyong Wu and Baobao Chang and Xu Sun and Lei Li and Zhifang Sui},
      year={2024},
      eprint={2301.00234},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2301.00234}, 
}

@misc{ICL2,
      title={In-context Learning with Retrieved Demonstrations for Language Models: A Survey}, 
      author={Man Luo and Xin Xu and Yue Liu and Panupong Pasupat and Mehran Kazemi},
      year={2024},
      eprint={2401.11624},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2401.11624}, 
}

@misc{rag1,
      title={Retrieval-Augmented Generation for Large Language Models: A Survey}, 
      author={Yunfan Gao and Yun Xiong and Xinyu Gao and Kangxiang Jia and Jinliu Pan and Yuxi Bi and Yi Dai and Jiawei Sun and Meng Wang and Haofen Wang},
      year={2024},
      eprint={2312.10997},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2312.10997}, 
}

@misc{rag2,
      title={Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks}, 
      author={Patrick Lewis and Ethan Perez and Aleksandra Piktus and Fabio Petroni and Vladimir Karpukhin and Naman Goyal and Heinrich Küttler and Mike Lewis and Wen-tau Yih and Tim Rocktäschel and Sebastian Riedel and Douwe Kiela},
      year={2021},
      eprint={2005.11401},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2005.11401}, 
}


@article{NLI1,
author = {Hendrix, Gary G. and Sacerdoti, Earl D. and Sagalowicz, Daniel and Slocum, Jonathan},
title = {Developing a natural language interface to complex data},
year = {1978},
issue_date = {June 1978},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {2},
issn = {0362-5915},
url = {https://doi.org/10.1145/320251.320253},
doi = {10.1145/320251.320253},
abstract = {Aspects of an intelligent interface that provides natural language access to a large body of data distributed over a computer network are described. The overall system architecture is presented, showing how a user is buffered from the actual database management systems (DBMSs) by three layers of insulating components. These layers operate in series to convert natural language queries into calls to DBMSs at remote sites. Attention is then focused on the first of the insulating components, the natural language system. A pragmatic approach to language access that has proved useful for building interfaces to databases is described and illustrated by examples. Special language features that increase system usability, such as spelling correction, processing of incomplete inputs, and run-time system personalization, are also discussed. The language system is contrasted with other work in applied natural language processing, and the system's limitations are analyzed.},
journal = {ACM Trans. Database Syst.},
month = jun,
pages = {105–147},
numpages = {43},
keywords = {database access, human engineering, intelligent interface, natural language, run-time personalization, semantic grammar}
}

@incollection{NLI2,
title = {Chapter 4 - Natural-Language Interfaces},
editor = {Howard E. Shrobe and  {the American Association for Artificial Intelligence}},
booktitle = {Exploring Artificial Intelligence},
publisher = {Morgan Kaufmann},
pages = {133-172},
year = {1988},
isbn = {978-0-934613-67-5},
doi = {https://doi.org/10.1016/B978-0-934613-67-5.50008-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780934613675500083},
author = {C. Raymond Perrault and Barbara J. Grosz},
abstract = {Publisher Summary
Since the early 1960s when support decreased for machine translation, much of the research on natural-language processing in North America has been motivated by its potential use for communicating with software systems. Natural-language systems have been developed to extract information from databases, to control (simulated) robots, to interact with graphic systems, to specify simulation problems, and to communicate with systems embodying expertise in some task or problem area. This chapter discusses the interfaces to database management systems. Apart from being among the earliest interface systems developed, interfaces to databases account for most of the natural-language interfaces (NLIs) implemented and they are the subject of a substantial literature. The chapter discusses the main system architectures used in NLIs and the body of techniques developed for them. In doing so, it distinguishes between the task of an interface and its domain. Natural language is but one of the methods available for human–machine interaction. The reasons for its attractiveness are obvious. They are: it provides an immediate vocabulary for talking about the contents of the database and a means of accessing information in the database independently of its structure and encodings, shields the user from the formal access language of the underlying system, and is available with a minimum of training to both novice and occasional user.}
}

@article{NLI3,
    title = "Natural-Language Interface",
    author = "Hendrix, Gary G.",
    journal = "American Journal of Computational Linguistics",
    volume = "8",
    number = "2",
    year = "1982",
    url = "https://aclanthology.org/J82-2002",
    pages = "56--61",
}

@misc{market1,
  author       = {Forbes Business Council},
  title        = {Embracing AI And Natural Language Interfaces},
  howpublished = {\url{https://www.forbes.com/councils/forbesbusinesscouncil/2023/07/11/embracing-ai-and-natural-language-interfaces/?formCode=MG0AV3}},
  year         = {2023},
  note         = {Accessed: October 3, 2024}
}

@misc{market2,
 author       = {marketsandmarkets},
  title        = {Natural Language Processing (NLP) Market by Component, Type, Application, Vertical - Global Forecast to 2026},
  howpublished = {\url{https://www.marketsandmarkets.com/Market-Reports/natural-language-processing-nlp-825.html}},
  year         = {n.d.},
  note         = {Accessed: October 3, 2024}
}


@misc{market3,
  author       = {smartcustomerservice},
  title        = {Conversational AI Market to Be Worth \$18.4 Billion by 2026},
  howpublished = {\url{https://www.smartcustomerservice.com/Articles/News-Briefs/Conversational-AI-Market-to-Be-Worth-\$18.4-Billion-by-2026-150912.aspx}},
  year         = {n.d.},
  note         = {Accessed: October 3, 2024}
}


@article{domain_adaption1,
  title={A brief review of domain adaptation},
  author={Farahani, Abolfazl and Voghoei, Sahar and Rasheed, Khaled and Arabnia, Hamid R},
  journal={Advances in data science and information engineering: proceedings from ICDATA 2020 and IKE 2020},
  pages={877--894},
  year={2021},
  publisher={Springer}
}

@article{domain_adaption2,
  title={Deep unsupervised domain adaptation: A review of recent advances and perspectives},
  author={Liu, Xiaofeng and Yoo, Chaehwa and Xing, Fangxu and Oh, Hyejin and El Fakhri, Georges and Kang, Je-Won and Woo, Jonghye and others},
  journal={APSIPA Transactions on Signal and Information Processing},
  volume={11},
  number={1},
  year={2022},
  publisher={Now Publishers, Inc.}
}

@article{domain_adaption3,
  title={Fast domain adaptation for neural machine translation},
  author={Freitag, Markus and Al-Onaizan, Yaser},
  journal={arXiv preprint arXiv:1612.06897},
  year={2016}
}

@misc{SPA,
      title={Selective Prompt Anchoring for Code Generation}, 
      author={Yuan Tian and Tianyi Zhang},
      year={2024},
      eprint={2408.09121},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2408.09121}, 
}

@misc{longformer,
      title={Longformer: The Long-Document Transformer}, 
      author={Iz Beltagy and Matthew E. Peters and Arman Cohan},
      year={2020},
      eprint={2004.05150},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2004.05150}, 
}

@article{sus,
author = {Brooke, John},
title = {SUS: a retrospective},
year = {2013},
issue_date = {February 2013},
publisher = {Usability Professionals' Association},
address = {Bloomingdale, IL},
volume = {8},
number = {2},
abstract = {Rather more than 25 years ago, as part of a usability engineering program, I developed a questionnaire---the System Usability Scale (SUS)---that could be used to take a quick measurement of how people perceived the usability of computer systems on which they were working. This proved to be an extremely simple and reliable tool for use when doing usability evaluations, and I decided, with the blessing of engineering management at Digital Equipment Co. Ltd (DEC; where I developed SUS), that it was probably something that could be used by other organizations (the benefit for us being that if they did use it, we potentially had something we could use to compare their systems against ours). So, in 1986, I made SUS freely available to a number of colleagues, with permission to pass it on to anybody else who might find it useful, and over the next few years occasionally heard of evaluations of systems where researchers and usability engineers had used it with some success.},
journal = {J. Usability Studies},
month = feb,
pages = {29–40},
numpages = {12}
}

@misc{self_instruct,
      title={Self-Instruct: Aligning Language Models with Self-Generated Instructions}, 
      author={Yizhong Wang and Yeganeh Kordi and Swaroop Mishra and Alisa Liu and Noah A. Smith and Daniel Khashabi and Hannaneh Hajishirzi},
      year={2023},
      eprint={2212.10560},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2212.10560}, 
}

@misc{oss_instruct,
      title={Magicoder: Empowering Code Generation with OSS-Instruct}, 
      author={Yuxiang Wei and Zhe Wang and Jiawei Liu and Yifeng Ding and Lingming Zhang},
      year={2024},
      eprint={2312.02120},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2312.02120}, 
}

@misc{evol_instruct,
      title={WizardLM: Empowering Large Language Models to Follow Complex Instructions}, 
      author={Can Xu and Qingfeng Sun and Kai Zheng and Xiubo Geng and Pu Zhao and Jiazhan Feng and Chongyang Tao and Daxin Jiang},
      year={2023},
      eprint={2304.12244},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2304.12244}, 
}

@misc{multi_agent_collaboration,
      title={Multi-Agent Collaboration Mechanisms: A Survey of LLMs}, 
      author={Khanh-Tung Tran and Dung Dao and Minh-Duong Nguyen and Quoc-Viet Pham and Barry O'Sullivan and Hoang D. Nguyen},
      year={2025},
      eprint={2501.06322},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2501.06322}, 
}

@misc{xiyan,
      title={XiYan-SQL: A Multi-Generator Ensemble Framework for Text-to-SQL}, 
      author={Yingqi Gao and Yifu Liu and Xiaoxia Li and Xiaorong Shi and Yin Zhu and Yiming Wang and Shiqi Li and Wei Li and Yuntao Hong and Zhiling Luo and Jinyang Gao and Liyu Mou and Yu Li},
      year={2024},
      eprint={2411.08599},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2411.08599}, 
}

@misc{qwen,
      title={Qwen Technical Report}, 
      author={Jinze Bai and Shuai Bai and Yunfei Chu and Zeyu Cui and Kai Dang and Xiaodong Deng and Yang Fan and Wenbin Ge and Yu Han and Fei Huang and Binyuan Hui and Luo Ji and Mei Li and Junyang Lin and Runji Lin and Dayiheng Liu and Gao Liu and Chengqiang Lu and Keming Lu and Jianxin Ma and Rui Men and Xingzhang Ren and Xuancheng Ren and Chuanqi Tan and Sinan Tan and Jianhong Tu and Peng Wang and Shijie Wang and Wei Wang and Shengguang Wu and Benfeng Xu and Jin Xu and An Yang and Hao Yang and Jian Yang and Shusheng Yang and Yang Yao and Bowen Yu and Hongyi Yuan and Zheng Yuan and Jianwei Zhang and Xingxuan Zhang and Yichang Zhang and Zhenru Zhang and Chang Zhou and Jingren Zhou and Xiaohuan Zhou and Tianhang Zhu},
      year={2023},
      eprint={2309.16609},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2309.16609}, 
}

@misc{dailsql,
      title={Text-to-SQL Empowered by Large Language Models: A Benchmark Evaluation}, 
      author={Dawei Gao and Haibin Wang and Yaliang Li and Xiuyu Sun and Yichen Qian and Bolin Ding and Jingren Zhou},
      year={2023},
      eprint={2308.15363},
      archivePrefix={arXiv},
      primaryClass={cs.DB},
      url={https://arxiv.org/abs/2308.15363}, 
}

@misc{distillery,
      title={The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models}, 
      author={Karime Maamari and Fadhil Abubaker and Daniel Jaroslawicz and Amine Mhedhbi},
      year={2024},
      eprint={2408.07702},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2408.07702}, 
}

@article{tiis_sql,
author = {Ning, Zheng and Tian, Yuan and Zhang, Zheng and Zhang, Tianyi and Li, Toby Jia-Jun},
title = {Insights into Natural Language Database Query Errors: from Attention Misalignment to User Handling Strategies},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {4},
issn = {2160-6455},
url = {https://doi.org/10.1145/3650114},
doi = {10.1145/3650114},
abstract = {Querying structured databases with natural language (NL2SQL) has remained a difficult problem for years. Recently, the advancement of machine learning (ML), natural language processing (NLP), and large language models (LLM) have led to significant improvements in performance, with the best model achieving ∼85\% percent accuracy on the benchmark Spider dataset. However, there is a lack of a systematic understanding of the types, causes, and effectiveness of error-handling mechanisms of errors for erroneous queries nowadays. To bridge the gap, a taxonomy of errors made by four representative NL2SQL models was built in this work, along with an in-depth analysis of the errors. Second, the causes of model errors were explored by analyzing the model-human attention alignment to the natural language query. Last, a within-subjects user study with 26 participants was conducted to investigate the effectiveness of three interactive error-handling mechanisms in NL2SQL. Findings from this article shed light on the design of model structure and error discovery and repair strategies for natural language data query interfaces in the future.},
journal = {ACM Trans. Interact. Intell. Syst.},
month = dec,
articleno = {25},
numpages = {32},
keywords = {Empirical study, human-computer interaction, error handling, database systems}
}

@inproceedings{ning_empirical_2023,
author = {Ning, Zheng and Zhang, Zheng and Sun, Tianyi and Tian, Yuan and Zhang, Tianyi and Li, Toby Jia-Jun},
title = {An Empirical Study of Model Errors and User Error Discovery and Repair Strategies in Natural Language Database Queries},
year = {2023},
isbn = {9798400701061},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581641.3584067},
doi = {10.1145/3581641.3584067},
abstract = {Recent advances in machine learning (ML) and natural language processing (NLP) have led to significant improvement in natural language interfaces for structured databases (NL2SQL). Despite the great strides, the overall accuracy of NL2SQL models is still far from being perfect (∼ 75\% on the Spider benchmark). In practice, this requires users to discern incorrect SQL queries generated by a model and manually fix them when using NL2SQL models. Currently, there is a lack of comprehensive understanding about the common errors in auto-generated SQLs and the effective strategies to recognize and fix such errors. To bridge the gap, we (1) performed an in-depth analysis of errors made by three state-of-the-art NL2SQL models; (2) distilled a taxonomy of NL2SQL model errors; and (3) conducted a within-subjects user study with 26 participants to investigate the effectiveness of three representative interactive mechanisms for error discovery and repair in NL2SQL. Findings from this paper shed light on the design of future error discovery and repair strategies for natural language data query interfaces.},
booktitle = {Proceedings of the 28th International Conference on Intelligent User Interfaces},
pages = {633–649},
numpages = {17},
keywords = {Empirical study, database systems, human-computer interaction},
location = {Sydney, NSW, Australia},
series = {IUI '23}
}

@misc{llm_repetitive,
      title={On LLMs-Driven Synthetic Data Generation, Curation, and Evaluation: A Survey}, 
      author={Lin Long and Rui Wang and Ruixuan Xiao and Junbo Zhao and Xiao Ding and Gang Chen and Haobo Wang},
      year={2024},
      eprint={2406.15126},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.15126}, 
}

@article{bm25,
author = {Robertson, Stephen and Zaragoza, Hugo},
title = {The Probabilistic Relevance Framework: BM25 and Beyond},
year = {2009},
issue_date = {April 2009},
publisher = {Now Publishers Inc.},
address = {Hanover, MA, USA},
volume = {3},
number = {4},
issn = {1554-0669},
url = {https://doi.org/10.1561/1500000019},
doi = {10.1561/1500000019},
abstract = {The Probabilistic Relevance Framework (PRF) is a formal framework for document retrieval, grounded in work done in the 1970—1980s, which led to the development of one of the most successful text-retrieval algorithms, BM25. In recent years, research in the PRF has yielded new retrieval models capable of taking into account document meta-data (especially structure and link-graph information). Again, this has led to one of the most successful Web-search and corporate-search algorithms, BM25F. This work presents the PRF from a conceptual point of view, describing the probabilistic modelling assumptions behind the framework and the different ranking algorithms that result from its application: the binary independence model, relevance feedback models, BM25 and BM25F. It also discusses the relation between the PRF and other statistical models for IR, and covers some related topics, such as the use of non-textual features, and parameter optimisation for models with free parameters.},
journal = {Found. Trends Inf. Retr.},
month = apr,
pages = {333–389},
numpages = {57}
}

@misc{dense_retrieve,
      title={Dense Passage Retrieval for Open-Domain Question Answering}, 
      author={Vladimir Karpukhin and Barlas Oğuz and Sewon Min and Patrick Lewis and Ledell Wu and Sergey Edunov and Danqi Chen and Wen-tau Yih},
      year={2020},
      eprint={2004.04906},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2004.04906}, 
}

@book{flesch_score,
  author    = {Rudolf Franz Flesch},
  title     = {Marks of Readable Style: A Study in Adult Education},
  year      = {1943},
  publisher = {Teachers College, Columbia University},
  language  = {English},
  url       = {https://nla.gov.au/nla.cat-vn916503},
  note      = {Accessed: 30 January 2025, via National Library of Australia}
}

@article{simpson_diversity,
  author = {Simpson, E. H.},
  title = {Measurement of Diversity},
  journal = {Nature},
  year = {1949},
  volume = {163},
  number = {4148},
  pages = {688},
  doi = {10.1038/163688a0},
  url = {https://doi.org/10.1038/163688a0}
}
