\section{Proof of Lemma \ref{lem:continuity_of_psi}}
\label{apx:lemma-continuitiy}

The monotonicity of each function $\psi_i$ follows from the fact that if the random variable $\Psi_i(v)$ is realized to be equal to one for some $v$, then for all $v' > v$, $\Psi_i(v')$ must also be equal to one (based on the definition of $\Psi_i$). Since $\psi_i(v)$ and $\psi_i(v')$ represent the expected values of $\Psi_i(v)$ and $\Psi_i(v')$, respectively, this property ensures that each $\psi_i$ is increasing. Furthermore, by the definition of the state variables $q_{i}$ and $q_{i+1}$, whenever $\Psi_{i+1}(v) = 1$, the allocation must have reached at least $i+1$ units, which implies $\Psi_i(v) = 1$. Consequently, it follows that $ \psi_{i}(v) \ge \psi_{i+1}(v) $.

\section{Proof of Proposition \ref{lemma:lower-bound-algorithm-performance}}
\label{appendix:lemma:proof-lower-bound-algorithm-performance}
For any randomized algorithm \ALG, let $D(L)$ denote the number of units that  \ALG allocates under the instance $ \mathcal{I}^{(\epsilon)}_{L} $ (i.e., the instance $\mathcal{I}^{(\epsilon)}$ by the end of stage-$L$). Thus, $D(L)$ is a random variable taking values from $0$ to $k$. Based on definition of $D(L)$, $\ALG(\mathcal{I}^{(\epsilon)}_{L})$ can be computed as follows:
\begin{align*}
    \ALG\left(\mathcal{I}^{(\epsilon)}_{L}\right) = \mathbb{E} \left[D(L) \cdot L - \sum_{i=1}^{D(L)} c_i \right],
\end{align*}
where the expectation is taken with respect to the randomness of $D(L)$ (the distribution depends on the randomness of the algorithm \ALG). 
Let the indicator function $\mathds{1}_{\{D(L)=j\}} = 1 $  if \ALG allocates exactly $j$ units at the end of stage-$L$, and $\mathds{1}_{\{D(L)=j\}} = 0 $ otherwise.
Based on definition of the random variables ${\{\Psi_i(L)\}}_{\forall i \in [k]}$, we argue that:
\begin{align}
\label{k-selection-lb2}
    {\mathds{1}}_{\{D(L)=j\}} = \Psi_{j}(L) - \Psi_{j+1}(L), \qquad 1 \leq j \leq k.
\end{align}
Here,  $\Psi_{k+1}(L) = 0 $ always holds.  To see why Eq. \eqref{k-selection-lb2} is true, consider the case where the random variable $D(L) = j $, then:
\begin{align*}
    \Psi_i(L) = 1 , \quad \forall i \leq j,\\
    \Psi_i(L) = 0,  \quad \forall i > j.
\end{align*}
From the equation above, we can observe that when the indicator function $\mathds{1}_{\{D(L)=j\}} =  1 $, $\Psi_{j+1}(L) - \Psi_{j}(L) = 1 $ holds. For the case when $\mathds{1}_{\{D(L)=j\}} = 0  $, if $D(L) < j$, then $\Psi_{j}(L) = \Psi_{j+1}(L) = 0$ and $ {\mathds{1}}_{\{D(L)=j\}} = \Psi_{j}(L) - \Psi_{j+1}(L)$ follows. For the case $D(L)>j$, the two equations   $\Psi_{j}(L) = \Psi_{j+1}(L) = 1$ and $ {\mathds{1}}_{\{D(L)=j\}} = \Psi_{j}(L) - \Psi_{j+1}(L)$ again follow.
As a result, $\ALG(\mathcal{I}^{(\epsilon)}_{L})$ can be computed as follows:
\begin{align*}
\ALG\left(\mathcal{I}^{(\epsilon)}_{L}\right) &= \mathbb{E} \left[D(L) \cdot L - \sum_{i=1}^{D(L)} c_i \right] \\
& = \sum_{j=1}^{k} \mathbb{E} \left[ \mathds{1}_{\{D(L) = j\}} \right] \cdot \left(j \cdot L - \sum_{i=1}^{j} c_i \right) \\
& = \sum_{j=1}^{k} \mathbb{E} \left[\Psi_{j}(L) - \Psi_{j+1}(L) \right] \cdot \left(j \cdot L - \sum_{i=1}^{j} c_i \right)\\
& =  \sum_{j=1}^{k} \big(\psi_{j}(L) - \psi_{j+1}(L)\big) \cdot \left(j \cdot L - \sum_{i=1}^{j} c_i \right)\\
& = \sum_{j=1}^{k} \psi_{j}(L) \cdot (L - c_{j}) - \psi_{k+1}(L) \cdot \left(k\cdot L - \sum_{i=1}^{k} c_{i} \right)\\
& = \sum_{j=1}^{k} \psi_{j}(L) \cdot (L - c_{j}).
\end{align*}

Now, let us compute the objective of the $\alpha$-competitive algorithm at the end of stage-$v$, $ \forall v\in V^{(\epsilon)}$, such that $v = L + m \cdot \epsilon$. Let the random variable $X_{i}(v)$ be the value obtained from allocating the $i$-th unit of the item at the end of some stage-$v \in V^{(\epsilon)}$. It follows that
\begin{align*}
    \mathbb{E}[X_{i}(v)-c_{i}] =\ & \psi_{i}(L)\cdot(L-c_{i}) +  \mathbb{E}\left[\sum_{j=1}^{m} (L + j \cdot \epsilon - c_{i}) \cdot \Big(\Psi_{i}(L + j \cdot \epsilon) - \Psi_{i}(L + (j-1) \cdot \epsilon) \Big) \right] \\
    =\ &  \psi_{i}(L)\cdot(L-c_{i}) + \sum_{j=1}^{m} (L + j \cdot \epsilon - c_{i}) \cdot \mathbb{E}\left[\Psi_{i}(L + j \cdot \epsilon) - \Psi_{i}(L + (j-1) \cdot \epsilon) \right] \\
    =\ & \psi_{i}(L)\cdot(L-c_{i}) + \sum_{j=1}^{m} (L + j \cdot \epsilon - c_{i}) \cdot \left ( \psi_{i}(L + j \cdot \epsilon) - \psi_{i}(L + (j-1) \cdot \epsilon) \right).
\end{align*}
where the first equality follows because if the $i$-th unit is allocated at some stage $L + j \cdot \epsilon$, then the algorithm must have sold at least $i$ units of the item by the end of $L + j \cdot \epsilon$, leading to $\Psi_i(L + j \cdot \epsilon) = 1 $. Additionally, if the $i$-th unit is allocated at stage $L + j \cdot \epsilon$, then at stage $L + (j-1) \cdot \epsilon $, the algorithm must have allocated fewer than $i$ units, indicating that $\Psi_i(L + (j-1) \cdot \epsilon) = 0 $.
Putting together the above results, it follows that:
\begin{align*}
      & \ALG\left(\mathcal{I}^{(\epsilon)}_{v}\right) \\
    =\ &  \sum_{i=1}^{k}  \mathbb{E}[X_{i}(v)-c_{i}]  \\
    =\ &  \sum_{i=1}^{k} \Big[\psi_{i}(L)\cdot(L-c_{i})+ \sum_{j=1}^{m} (L + j \cdot \epsilon - c_{i}) \cdot \Big(\psi_{i}(L + j \cdot \epsilon) - \psi_{i}(L + (j-1) \cdot \epsilon)\Big) \Big] , \\
    =\ &  \ALG\left(\mathcal{I}^{(\epsilon)}_{L}\right) +  \sum_{i=1}^{k}  \sum_{j=1}^{m} (L + j \cdot \epsilon - c_{i}) \cdot \Big( \psi_{i}(L + j \cdot \epsilon) - \psi_{i}(L + (j-1) \cdot \epsilon) \Big), \quad \forall m \in \left\{1,\dots, \lfloor \frac{U-L}{\epsilon} \rfloor \right\}.
\end{align*}
Proposition  \ref{lemma:lower-bound-algorithm-performance} thus follows.

\section{Proof of Lemma \ref{lemma:nec-cond}}
\label{apx:lb-system-ode}
Based on Proposition \ref{lemma:lower-bound-algorithm-performance}, for any online algorithm \ALG, we have: 
\begin{align*}
&\ALG \left(\mathcal{I}_{L}^{(\epsilon)}\right) = \sum_{i=1}^{k} \psi_i^{(L)} \cdot (L - c_i), \\
&\ALG\left(\mathcal{I}_{L+ j\cdot \epsilon}^{(\epsilon)}\right) =  \ALG\left(\mathcal{I}_{L}^{(\epsilon)}\right) +  \sum_{i=1}^{k} \sum_{m=1}^{j} \bigg((L + m \cdot \epsilon) \cdot  \Big(\psi_i(L + m \cdot \epsilon) \\
& \hspace{+4cm} - \psi_i(L + m \cdot \epsilon - \epsilon) \Big)  \bigg), \forall j = 1, 2, \ldots, \left\lfloor \frac{U - L}{\epsilon} \right\rfloor.
\end{align*}
As $\epsilon \rightarrow 0$, following the Riemann summation, it follows that:
\begin{align*}
    \ALG\left(\mathcal{I}_{v}^{(\epsilon)}\right) 
    = \ALG\left(\mathcal{I}_{L}^{(\epsilon)}\right) + \sum_{i=1}^{k} \int_{\eta = L}^{v} (\eta-c_i) \cdot \Big[ \psi_i(\eta) - \psi_i(\eta - d\eta) \Big], \forall v \in [L,U].
\end{align*}
Based on above, the set of functions $\{\psi_i\}_{i \in [k]}$ should be defined over the range $[L,U]$. 

In the next step, we prove that the set of functions  $\{\psi_i\}_{i \in [k]}$ exists such that these set of functions are continous within their range $[L,U]$. For now, let us assume this claim holds. Then, it follows that :
\begin{align*}
    \ALG\left(\mathcal{I}_{v}^{(\epsilon)}\right) &= \ALG\left(\mathcal{I}_{L}^{(\epsilon)}\right) + \sum_{i=1}^{k} \int_{\eta = L}^{v} (\eta-c_i) \cdot \left [ \psi_i(\eta) - \psi_i(\eta - d\eta) \right ]\\
    & = \ALG\left(\mathcal{I}_{L}^{(\epsilon)}\right) + \sum_{i=1}^{k} \int_{\eta = L}^{v} (\eta-c_i) \cdot  d\psi(\eta).
\end{align*}
 Following from Eq.~\eqref{lower-bound-system-kselection-cost}, if there exists an $\alpha$-competitive algorithm, then there should exists a set of functions  $\{\psi_i\}_{i \in [k]}$ such that:
\begin{align*}
 \ALG\left(\mathcal{I}_{v}^{(\epsilon)}\right) & = \ALG\left(\mathcal{I}_{L}^{(\epsilon)}\right) + \sum_{i=1}^{k} \int_{\eta = L}^{v} (\eta-c_i) \cdot  d\psi(\eta) \\
 & \ge\ \frac{1}{\alpha} \cdot \left(k v - \sum\nolimits_{i=1}^k c_{i}\right), \qquad \forall v \in [L,U].
\end{align*}
Now, let us get back to prove that a set of functions $\{\psi_i\}_{i \in [k]}$ exists corresponding to some online algorithm, that all these functions are continuous within the range $[L,U]$.
Let $\ALG$ be an $\alpha$-competitive algorithm. For some $v \in (L,U)$ and $i \in [k]$, let the function $\psi_{i}(.)$ corresponding to $\ALG$ be non-continuous at $v$. 
Let $\lim_{x \rightarrow v^{-}} \psi_{i}(v) = \nu$ and $\psi_{i}(v) = \lim_{x \rightarrow v^{+}} \psi_{i}(v) = \nu + \delta$, for some $\delta > 0$.  Then the algorithm must be selling at least in expectation a $\delta$-fraction of the $i$-th unit to the buyers with valuation $v$ in instance $\mathcal{I}$. 
Conversely, for $\ALG$ to be $\alpha$-competitive, the expected objective of the algorithm before the arrival of buyers with valuation $v$, $\ALG(\mathcal{I}_{v^{-}}^{(\epsilon)})$, must be
at least equal to $\frac{1}{\alpha} \cdot \OPT(\mathcal{I}_{v^{-}}^{(\epsilon)}) = \frac{1}{\alpha} \cdot \OPT(\mathcal{I}_{v}^{(\epsilon)})$, where $ \OPT(\mathcal{I}_{v}^{(\epsilon)}) $ denotes the objective value of the offline optimal algorithm on the hard instance $ \mathcal{I}^{(\epsilon)} $ up to the end of stage-$v$. 
It can be seen that selling in expectation at least a $\delta $ fraction of the $i$-th unit is unnecessary and $\ALG$ could save this fraction of the unit and sell it to buyers with higher valuations. In other words, 
we can construct another online algorithm, say $\widehat{\ALG}$, that follows $\ALG$ up to the arrival of buyers with valuation  $v$, 
but sells the $\delta$-fraction of the $i$-th unit to buyers with valuation strictly greater than $v$ instead. It is easy to see that  $\widehat{\ALG}$ will obtain a better objective value with its $ \hat{\psi}_{i}$ being continuous at $v$. Lemma \ref{lem:continuity_of_psi} follows by repeating the same process for any other discontinuous point of $ \psi_i(v) $.

\section{Proof of Lemma \ref{lemma:lb:tightness}}
\label{appendix:lemma:lb:tightness}
For any $v \in [L,U]$, let us define $C_v$ as follows:
    \begin{align*}
        C_{v} &= C_{L} + \sum_{i=1}^{k} \int_{\eta =L}^{v} (\eta - c_{i} )d\psi^{\alpha}_{i}(\eta), \quad \forall v\in (L,U],\\
        C_{L} &= \sum_{i=1}^{k} \psi^{\alpha}_{i}(L) \cdot (L - c_{i}).
    \end{align*}
To prove Lemma~\ref{lemma:lb:tightness}, we need to first  prove the feasibility of ${\{\psi^{(\alpha)}_{i}\}}_{\forall i \in [k]}$, namely, $C_{v}$ is greater than $\frac{1}{\alpha} \cdot (k \cdot v - \sum_{i} c_{i})$ for all $v  \in [L,U]$. 
     
For some $v \in [L,U]$, based on the definition of $\chi^{\alpha}(v)$ in Eq. \eqref{lower-bound-proof-define-chi-function}, there exist a set of functions ${\{\psi_{i}(v)\}}_{\forall i \in [k]}$ that satisfy Eq.~\eqref{eq:lb-system-ineq} and in the meanwhile, for some arbitrary small value $\epsilon$, we have:
\begin{align}
    \label{inequality-lower-bound}
    \chi^{\alpha}(v) + \epsilon \ge \sum_{i=1}^{k} \psi_{i}(v).
\end{align}
Next, using integration by parts, we have
\begin{align*}
    C_{v}
    =\ & C_{L} + \sum_{i=1}^{k} \int_{\eta =L}^{v} (\eta - c_{i} )d\psi^{\alpha}_{i}(\eta) \\
    =\ & C_{L} + \sum_{i=1}^{k} \psi^{\alpha}_{i}(v) \cdot (v - c_{i}) - \sum_{i=1}^{k} \psi^{\alpha}_{i}(L) \cdot (L - c_{i}) - \int_{\eta =L}^{v} \left( \sum_{i=1}^{k}  \psi^{\alpha}_{i}(\eta) \right) d\eta \\
    =\ &  \sum_{i=1}^{k} \psi^{\alpha}_{i}(v) \cdot (v - c_{i})  - \int_{\eta =L}^{v} \left( \sum_{i=1}^{k}  \psi^{\alpha}_{i}(\eta) \right) d\eta \\
    =\ & v \cdot \left(\sum_{i=1}^{k} \psi^{\alpha}_{i}(p)\right) - \sum_{i=1}^{k} \psi^{\alpha}_{i}(v) \cdot  c_{i}  - \int_{\eta =L}^{v} \left( \sum_{i=1}^{k}  \psi^{\alpha}_{i}(\eta) \right)  d\eta \\
    =\ & v \cdot \chi^{\alpha}(v) -\sum_{i=1}^{k} \psi^{\alpha}_{i}(v) \cdot  c_{i}  - \int_{\eta =L}^{v} \chi^{\alpha}(v) d\eta,
\end{align*}
where the last equality follows the definition of $\{\psi^{\alpha}_{i}\}_{\forall i \in [k]}$ in Eq. \eqref{lower-bound-optimal-functions-design}. Thus, we have
\begin{align}
    C_{v} =\ &  v \cdot \chi^{\alpha}(v) -\sum_{i=1}^{k} \psi^{\alpha}_{i}(v) \cdot  c_{i}  - \int_{\eta =L}^{v} \chi^{\alpha}(v) \cdot d\eta, \nonumber \\
   \ge\ & v \cdot \sum_{i=1}^{k} \psi_{i}(v) - v \cdot \epsilon -\sum_{i=1}^{k} \psi^{\alpha}_{i}(v) \cdot  c_{i}  - \int_{\eta =L}^{v} \chi^{\alpha}(v) \cdot d\eta , \nonumber \\
   \ge\ & v \cdot \sum_{i=1}^{k} \psi_{i}(v) -  \int_{\eta =L}^{v}  \left(\sum_{i=1}^{k} \psi_{i}(\eta)\right)  \cdot d\eta - \sum_{i=1}^{k} \psi^{\alpha}_{i}(v) \cdot  c_{i}  - v \cdot \epsilon, \label{lower-bound-inequality2}
\end{align}
where the first inequality follows Eq. \eqref{inequality-lower-bound} and the second inequality directly follows the definition of $\chi^{\alpha}(v)$ (recall that $\chi^{\alpha}(v) \leq \sum_{i=1}^{k} \psi_{i}(v) $ holds for all $v \in [L,U]$).

By the definition of ${\{\psi^{\alpha}_{i}\}}_{\forall i \in [k]}$, we have $\sum_{i \in [k]} \psi^{\alpha}_{i}(v) = \chi^{\alpha}(v) $. Putting together the inequality $\chi^{\alpha}(v)\leq \sum_{i=1}^{k} \psi_{i}(v)$ and the fact that productions costs are increasing, we have
\begin{align*}
    \sum_{i=1}^{k} \ \psi^{\alpha}_{i}(v) \cdot  c_{i} \leq \sum_{i=1}^{k} \ \psi_{i}(v) \cdot  c_{i}.
\end{align*}
Putting together the above inequality and the right-hand-side of Eq. \eqref{lower-bound-inequality2}, it follows that:
\begin{align*}
    C_{v} & \ge p \cdot \sum_{i=0}^{k-1} \psi_{i}(v) - \sum_{i=0}^{k-1} \int_{\eta =L}^{v}  \psi_{i}(\eta)  \cdot d\eta -  \sum_{i=0}^{k-1} \psi_{i}(v) \cdot  c_{i+1}  - v \cdot \epsilon  \\
    &  \ge \ALG\left(\mathcal{I}^{(\epsilon)}_{v}\right) - v \cdot \epsilon,
\end{align*}
where $\ALG$ is the online algorithm corresponding to the set of allcation functions $\{\psi_{i}\}_{\forall i \in [k]}$ and recall that $\ALG(\mathcal{I}^{(\epsilon)}_{v})$ is defined as follows:
\begin{align*}
& \ALG\left(\mathcal{I}^{(\epsilon)}_{L}\right) = \sum_{i=1}^{k} \psi_{i}(L) \cdot (L - c_{i}), \\
& \ALG\left(\mathcal{I}^{(\epsilon)}_{v}\right) =  \ALG\left(\mathcal{I}^{(\epsilon)}_{L}\right) + \sum_{i=1}^{k} \int_{\eta =L}^{v} (\eta - c_{i} )d\psi_{i}(\eta),\ \  \forall v \in [L,U].
\end{align*}
Since ${\{\psi_{i}\}}_{\forall i \in [k]}$ satisfy Eq. \eqref{eq:lb-system-ineq}, it follows that
\begin{align*}
    C_{v}  \ge\ & \ALG\left(\mathcal{I}^{(\epsilon)}_{v}\right) - v \cdot \epsilon \\
    \ge\ & \frac{1}{\alpha} \cdot \left(k \cdot v - \sum_{i=1}^{k} c_{i}\right) - v \cdot \epsilon,  \quad \forall v \in [L,U]. 
\end{align*}
By setting $\epsilon \rightarrow 0 $, it follows that
\begin{align*}
    C_{v}  \ge \frac{1}{\alpha} \cdot \left(k \cdot v - \sum_{i=1}^{k} c_{i} \right), \quad \forall v \in [L,U]. 
\end{align*}

To complete the proof of Lemma~\ref{lemma:lb:tightness}, we also need to prove that the above inequality holds as an equality for the set of functions $\{\psi^{\alpha}_{i}\}_{\forall i \in [k]}$. This can be proved by contradiction. Suppose that at some point $v \in [L,U]$, the above equality does not hold, then there must exist another set of feasible functions, say ${\{\hat{\psi}_{i}\}}_{\forall i \in [k]}$, induced by a new algorithm, say $\widehat{\ALG}$, that satisfy Eq. \eqref{eq:lb-system-ineq} and 
\begin{align*}
    \sum_{i=1}^{k} \hat{\psi}_{i}(v)   < \sum_{i=1}^{k} \psi^{\alpha}_{i}(v) .
\end{align*}
We argue that the new set of functions $\{\hat{\psi}_{i}\}_{\forall i \in [k]}$ will allocate a smaller fraction of its total units to buyers in $\mathcal{I}^{(\epsilon)}$ arriving at or before stage-$v$ compared to $\{\psi^{\alpha}_{i}\}_{\forall i \in [k]}$. However, by still following the allocation functions $\{\psi^{\alpha}_{i}\}_{\forall i \in [k]}$, $\widehat{\ALG}(\mathcal{I}^{(\epsilon)}_{v})$ will be exactly equal to $\frac{1}{\alpha} (k \cdot v - \sum_{i=1}^{k} c_{i} )$. Given the definition of $\{\psi^{\alpha}_{i}\}_{\forall i \in [k]}$, we have $\sum_{i=1}^{k} \psi^{\alpha}_{i}(v) = \chi^{\alpha}(v)$, meaning that $\sum_{i=1}^{k} \hat{\psi}_{i}(v) < \chi^{\alpha}(v)$. However, this  contradicts the definition of $\chi^{\alpha}(v)$.
We thus complete the proof of Lemma~\ref{lemma:lb:tightness}.


\section{Proof of Proposition \ref{prop:lower-bound-psi-star-design} }
\label{appendix:lower-bound-proof-lemma-function-design-psi-star}
From Lemma \ref{lemma:lb:tightness}, we know that ${\{\psi^{\alpha}_{i}(v)\}}_{\forall i \in [k]} $ satisfy Eq.~\eqref{eq:lb-system-ineq} with an equality. Therefore, the set of allocation functions ${\{\psi^{\alpha}_{i}(v)\}}_{\forall i \in [k]}$ is a solution to the following system of equations: 
\begin{align}
    & \sum_{i=1}^{k} \psi^{\alpha}_{i}(L) \cdot (L - c_{i}) +    \sum_{i=1}^{k} \int_{\eta =L}^{v} (\eta - c_{i} )d\psi^{\alpha}_{i}(\eta)  \nonumber \\
    =\ & \frac{1}{\alpha} \cdot (k\cdot v - \sum_{i} c_{i}), \quad   
    \forall i \in [k], v \in [L,U].  \label{appendix-lower-bound-system-of-eq}
\end{align}
A‌lso, based on Lemma~\ref{property-1}, we argue that if the value of the function $\psi^{\alpha}_{i}(v)$  is changing at some value $v \in [L,U]  $ (i.e., $d\psi^{\alpha}_{i}(v) \not = 0$), then the value of all the functions $\{\psi^{*}_{j}(v)\}_{\forall j \in [i-1]}$ are equal to one, and all the functions in the set $\{\psi^{*}_{j}(v)\}_{j > i}$ are equal to zero. Based on this property, we can assign an interval $[\ell_{i},u_{i}]$ to each $\psi^{\alpha}_{i}(v)$. In the interval of $[\ell_{i},u_{i}]$, only the value of $\psi^{\alpha}_{i}$ changes while the other functions $\{\psi^{\alpha}_{j}\}_{\forall j \not =  i}$ in that interval are fixed to be one or zero. Additionally, the following relation exists between the start and end points of these intervals:
\begin{align*}
    L = \ell_{1} \leq u_{1}=\ell_{2} \leq u_{2}\leq \dots \leq \ell_{k} \leq u_{k} = U.
\end{align*}
To satisfy the equality $\sum_{i \in [k]} \psi^{\alpha}_{i}(L) \cdot (L-c_{i}) = \frac{1}{\alpha} \cdot (k\cdot L - \sum_{i} c_{i}) $, the set of functions $\{\psi^{\alpha}_{i}(v)\}_{\forall i \in [\ubar{k}-1]}$ should be equal to one at the point $v=L$. Thus, the explicit design of the functions $\{\psi^{\alpha}_{i}\}_{\forall i \in [\ubar{k}-1]}$ is as follows:
%\small
\begin{align*}
\psi^{(\alpha)}_{i}(v) = 1, \quad    i = 1, \dots, \ubar{k}-1.
\end{align*}

In the case that $\sum_{i\in[\ubar{k}]} L - c_{i} < \frac{1}{\alpha} \cdot (k\cdot L - \sum_{i} c_{i})$, to satisfy $\sum_{i \in [k]} \psi^{\alpha}_{i}(L) \cdot (L-c_{i}) = \frac{1}{\alpha} \cdot (k\cdot L - \sum_{i} c_{i}) $, we need to have:
\begin{align*}
        &\psi^{\alpha}_{\ubar{k}}(L) = \frac{\sum_{i \in [\ubar{k}-1]} (L-c_i) - \frac{1}{\alpha}\cdot \sum_{i \in [k]}(L-c_{i})}{L-c_{\ubar{k}}} =  \xi.
\end{align*}
Since for all $v \in [\ell_{\ubar{k}},u_{\ubar{k}}]$ with $ \ell_{\ubar{k}} = L $, only the value of  $\psi^{\alpha}_{\ubar{k}}(v)$ changes (i.e., $d\psi^{\alpha}_{i}(v) = 0$ for all $i \not = \ubar{k} $), it follows that:
\begin{align*}
       &\sum_{i=1}^{k} \psi^{\alpha}_{i}(L) \cdot (L - c_{i}) + \sum_{i=1}^{k} \int_{\eta =L}^{v} (\eta - c_{i} )d\psi^{\alpha}_{i}(\eta) \\
    =\ & \sum_{i=1}^{k}  \psi^{\alpha}_{i}(L) \cdot (L - c_{i}) + \int_{\eta =L}^{v} (\eta - c_{\ubar{k}} )d\psi^{*}_{\ubar{k}}(\eta), \ \forall v \in [L,u_{\ubar{k}}].
\end{align*}
Based on the system of  equations in Eq. \eqref{appendix-lower-bound-system-of-eq}, we need to have:
\begin{align*}
  \sum_{i=1}^{k}  \psi^{\alpha}_{i}(L) \cdot (L - c_{i}) + \int_{\eta =L}^{v} (\eta - c_{\ubar{k}} )d\psi^{*}_{\ubar{k}}(\eta)
 = \frac{1}{\alpha} \cdot (k\cdot v - \sum_{i} c_{i}), \qquad \forall v \in [\ell_{\ubar{k}},u_{\ubar{k}}].
\end{align*}
Taking derivative w.r.t. $ v $ from both sides of the equation above, we have
\begin{align*}
    (v - c_{\ubar{k}}) \cdot d\psi^{*}_{\ubar{k}}(v) = \frac{k}{\alpha}.
\end{align*}
Solving the above differential equation leads to 
\begin{align*}
\psi^{*}_{\ubar{k}}(v) = \frac{k}{\alpha} \cdot \ln(v-c_{\ubar{k}}) + Q,  \quad \forall v \in [\ell_{\ubar{k}},u_{\ubar{k}}],
\end{align*}
where $ Q $ is a constant. To find $ Q $, since $\psi^{*}_{\ubar{k}}(L) =\xi$, it follows that $ Q = \xi - \frac{k}{\alpha} \cdot \ln(L-c_{\ubar{k}})$. As a result, the explicit design of the function $\psi^{\alpha}_{\ubar{k}}$ is as follows:
\begin{align*}
    \psi^{(\alpha)}_{\ubar{k}}(v) =
    \begin{cases}
         \xi + \frac{k}{\alpha} \cdot \ln\left(\frac{v - c_{\ubar{k}}}{L - c_{\ubar{k}}}\right) &  v \in [L,u_{\ubar{k}}], \\
         1 & v > u_{\ubar{k}}.
         \end{cases}
\end{align*}
To obtain the value of $u_{\ubar{k}}$, we set $\psi^{*}_{\ubar{k}}(u_{\ubar{k}}) =1$ (the function $\psi^{*}_{\ubar{k}}$ reaches its maximum). Consequently, it follows that:
\begin{align*}
u_{\ubar{k}} = (L-c_{\ubar{k}}) \cdot e^{\frac{\alpha}{k}\cdot(1-\xi)} + c_{\ubar{k}}.
\end{align*}
Using the same procedure as what has been applied to $\psi^{\alpha}_{\ubar{k}}$, for all the other functions $\{\psi^{\alpha}_{i}(v)\}_{\forall i > \ubar{k}}$, we have
\begin{align*}
    &\sum_{j=1}^{k} \psi^{*}_{j}(L) \cdot (L - c_{j}) + \sum_{j=1}^{k} \int_{\eta =L}^{v} (\eta - c_{j} )d\psi^{\alpha}_{i}(\eta) \\
    =\ & \sum_{j=1}^{k}  \psi^{*}_{j}(L) \cdot (L - c_{j}) + \int_{\eta =L}^{v} (\eta - c_{i} )d\psi^{\alpha}_{i}(\eta) ,  \quad \forall v \in [\ell_{i},u_{i}].
\end{align*}
Taking derivative w.r.t. $ v $ from both sides of the equation above, it follows that:
\begin{align*}
    (v - c_{i}) \cdot d\psi^{\alpha}_{i}(v) = \frac{k}{\alpha}.
    \end{align*}
Solving the above differential equation leads to
\begin{align*}
\psi^{\alpha}_{i}(v) = \frac{k}{\alpha} \cdot \ln(v-c_{i}) + \hat{Q}, \quad \forall v \in [\ell_{i},u_{i}].
\end{align*}
Since $\psi^{*}(\ell_{i}) = 0$, we have $ \hat{Q} = - \ln(\ell_{i}-c_{i})$. The explicit design of the function $\psi^{\alpha}_{i}$ is thus as follows:
\begin{align*}
\psi^{(\alpha)}_{i}(v) = \begin{cases} 0 & v \leq \ell_{i}, \\
        \frac{k}{\alpha} \cdot \ln\left(\frac{v - c_{i}}{\ell_{i} - c_{i}}\right) &  v \in [\ell_{i},u_{i}], \\
        1 & v \ge u_{i}.
        \end{cases} \quad  i = \ubar{k}+1,\dots, k-1
\end{align*}
For the function $\psi_{k}^{\alpha}$, since it is the last function, it follows that:
\begin{align*}
    \psi^{(\alpha)}_{k}(v) = \begin{cases} 0 & v \leq \ell_{k}, \\
        \frac{k}{\alpha} \cdot \ln\left(\frac{v - c_{k}}{\ell_{k} - c_{k}}\right) &  v \in [\ell_{k},U].
        \end{cases}
\end{align*}
By setting $\psi^{*}(u_{i}) = 1$, it follows that:
\begin{align*}
u_{i} = (\ell_{i}-c_{i}) \cdot e^{\frac{\alpha}{k}} + c_{i}, \quad   \ubar{k}+1 \leq i \leq k.
\end{align*}
Putting everything together, Proposition \ref{prop:lower-bound-psi-star-design} follows.


\section{Full Proof of Theorem \ref{upper-bound-large-inventory-cr}}
\label{appendix:proof-upper-bound-large-inventory-cr}
In this section, we provide a complete proof of Theorem 5. We begin by introducing several important notations and lemmas. Then, we break the problem into two independent subproblems based on the buyers' valuations in some arbitrary arrival instance $\mathcal{I}$. For each case, we proceed to show how to upper bound $\OPT(\mathcal{I})$, the objective of the optimal offline algorithm on $\mathcal{I}$. We then proceed to lower bound the expected performance of \rDynamic on that instance, $\ALG(\mathcal{I})$. Ultimately, we combine everything and obtain a performance guarantee for \rDynamic under all adversarially chosen instances of \OSDoS for that subproblem.



\subsection{Notations and Definitions}
Consider an arbitrary arrival instance  $\mathcal{I} = \{v_{t}\}_{t \in [T]}$. Recall that the random price vector $\mathbf{P} = \{P_1, \cdots, P_k\} $ is generated using the pricing functions $\{\phi_{i}\}_{\forall i \in [k]}$ at the beginning of \rDynamic (line \ref{line_P_vector} of Algorithm \ref{alg:kselection-cost}). In the following, we will refer to Algorithm \ref{alg:kselection-cost}  as $\rDynamic(\mathbf{P})$ to indicate that the algorithm is executed with the random price vector being realized as $ \mathbf{P}$. Based on the design of  $\{\phi_{i}\}_{\forall i \in [k]}$ in Theorem \ref{upper-bound-large-inventory-cr}, the first $ k^* - 1 $ prices in $ \mathbf{P} $ are all $ L $'s (i.e., $ P_1 = \cdots = P_{k^* - 1} =  L $), the $ k^*$-th price $ P_{k^*} $ is a random variable within $ [L, U_{k^*}]$, and for all $ i \in \{k^*+1, \cdots, k]$, we have $ P_i  \in [L_i, U_i] $ (recall that $ P_i $ is also a random variable). Here, the values of $\ubar{k}^{*} $ and $ \{[L_i,U_i]\}_{\forall i} $ are all defined in Theorem \ref{upper-bound-large-inventory-cr}. 

Let $\mathcal{P}$ denote the support of all possible values of the random price vector $\mathbf{P}$:
\begin{align*}
    \mathcal{P} = \{L\}^{\ubar{k}^{*}-1} \times [L,U_{\ubar{k}^{*}}] \times \prod_{i \in\{\ubar{k}^{*}+1,\cdots, k\}} [L_{i}, U_{i}].
\end{align*}
Given a price vector realization $\mathbf{P} \in \mathcal{P}$, let $W(\mathbf{P})$ represent the total number of items allocated by $\rDynamic(\mathbf{P})$ under the input instance $\mathcal{I}$. Since $\mathbf{P}$ is a random variable, $W(\mathbf{P})$ is also a random variable. For clarity, we will sometimes omit the price vector and refer to it simply as $W$ whenever the context is clear.

Let $\omega$ denote the maximum value in the support of the random variable $ W $ (i.e., $ \omega $ is the maximum possible value of $ W(\mathbf{P}) $ for all $ \mathbf{P}\in\mathcal{P}$). Thus, $\omega$ is a deterministic value that depends only on the input instance $\mathcal{I}$. Furthermore, let $\boldsymbol{\pi} \in \mathcal{P}$ be a price vector such that $\rDynamic(\boldsymbol{\pi})$ allocates the $\omega$-th item earlier than any other price vector in the set $\mathcal{P}$. That is, for all $ \mathbf{P}\in \mathcal{P}$, $\rDynamic(\mathbf{P})$ allocates the $\omega$-th item no earlier than that of $\rDynamic(\boldsymbol{\pi})$. 

Let us define the set $\{(\nu_{i},\tau_{i})\}_{\forall i\in [\omega]}$ so that $\tau_{i}$ is the arrival time of the buyer in the instance $ \mathcal{I} $ to whom $\rDynamic(\boldsymbol{\pi})$ allocates the $i$-th unit and $\nu_i$ is its valuation. Note that for all $ i \in \{1, \cdots, \omega\} $,  $ \tau_i $ and $\nu_i$ are deterministic values once $ \boldsymbol{\pi}$ and $ \mathcal{I} $ are given.  

We can derive the following inequality regarding $\nu_{i}$:
\begin{align}
\label{eq:upper-bound-large-inventory-proof-1}
\nu_{i} \ge L_{i}, \quad \forall i \in [\omega],
\end{align}
where $L_{i}$ is the lower bound for the range of the pricing function $\phi_{i}$, used to generate the random price for the $i$-th unit. This inequality holds since the buyer arriving at time $\tau_{i}$ accepts the price posted for the $i$-th unit by \rDynamic. The price for the $i$-th unit is at least equal to $L_{i}$  based on the design of the pricing functions $\phi_{i}$.

Let the random variable $W^{\tau_{\omega}}(\mathbf{P}) $ denote the total number of items allocated by $\rDynamic(\mathbf{P})$ after the arrival of buyer $\tau_{\omega}$ in the instance $\mathcal{I}$. The lemma below shows that the random variable $ W^{\tau_{\omega}}(\mathbf{P}) $ is always lower bounded by $ \omega - 1$.


\begin{lemma}\label{appendix:prop:omega-1}
Given an arbitrary instance $ \mathcal{I} $, $ W^{\tau_{\omega}}(\mathbf{P}) \geq \omega - 1$ holds for all $ \boldsymbol{P} \in \mathcal{P} $.
\end{lemma}

\begin{proof}
If $\omega = 1$, this lemma is trivial, so we consider the case where $\omega \geq 2$. 
Suppose before the arrival of the buyer at time $\tau_{2}$, no items have been sold. 
From Eq. \eqref{eq:upper-bound-large-inventory-proof-1}, we know that $\nu_{2} \geq L_{2}$. 
Additionally, based on the design of the pricing functions $\phi_{1}(.)$ and $\phi_{2}(.)$, we have $L_{2} \geq U_{1}$. 
Consequently, it follows that $\nu_{2} \geq U_{1}$. Since the realized price for the first unit under any sampled price vector will be at most $U_{1}$ (based on design of the pricing function $\phi_{1}$), 
the buyer arriving at time $\tau_{2}$ will accept the price for the first unit, and the algorithm will sell the first item.
Thus, for all possible price vector $\mathbf{P}$, the value of the random variable $W^{\tau_{2}}(\mathbf{P})$ is at least equal to one. 
By the same reasoning, if before the arrival of the buyer at time $\tau_{3}$, only one item has been sold, the buyer arriving at $\tau_{3}$ will accept the price for the second unit, regardless of its price, and the total number of  items sold by \rDynamic will increase to two. 
This reasoning can be extended to the time $\tau_{\omega}$. As a result, after the arrival of the buyer at time $\tau_{\omega}$, \rDynamic sells at least $\omega-1$ units and thereby the claim in the lemma follows.
\end{proof}

Lemma \ref{appendix:prop:omega-1} implies that the support of the random variable $ W^{\tau_{\omega}} $ consists only of two values: $\omega-1$ and $\omega$. This greatly simplifies the analysis of the algorithm. 


The following two lemmas help us lower bound the expected performance of \rDynamic under the input instance $\mathcal{I}$ and upper bound the objective of the offline optimal algorithm given the instance $\mathcal{I}$, respectively. 


\begin{lemma}\label{appendix:prop:main:claim3-upper-bound-kselection-cost}
    If a buyer in instance $\mathcal{I}$ arrives before time $\tau_{\omega}$ with a valuation within $[L_{\omega}, U]$, then for all $\mathbf{P} \in \mathcal{P}$, $ \rDynamic(\mathbf{P}) $ will allocate one unit of the item to that buyer.
\end{lemma}

\begin{proof}
    According to the definition of $\boldsymbol{\pi}$, $\tau_{\omega}$ is the earliest time across all possible price vectors in $\mathcal{P}$ that the production level exceeds $\omega-1$, causing the posted price to exceed $U_{\omega-1}$. Thus,
    for all possible realization of $\mathbf{P}$, the posted prices by \rDynamic remain below $U_{\omega-1}$ before the arrival of buyer at time $\tau_{\omega}$.  Consequently, when a buyer with a valuation within $[L_{\omega}, U]$ arrives before time $\tau_{\omega}$, the buyer accepts the price posted to him (since $ L_{\omega} \ge U_{\omega-1} $) and a unit of item will thus be allocated to this buyer.
\end{proof}
\begin{lemma}
\label{appendix:prop:main:claim2-kselection-production-cost}
    There are no buyers in instance $\mathcal{I}$ with a valuation within $[U_{\omega}, U]$ arriving after time $\tau_{\omega}$, namely, the valuations of all buyers arrive after $\tau_{\omega}$ are less than $ U_{\omega}$.
\end{lemma}

\begin{proof}
If there exist a buyer with a valuation larger than $U_{\omega}$ arriving after the time $\tau_{\omega}$, then there must exist a price vector in $\mathcal{P}$, say $ \mathbf{P}' $, such that the number of units sold by $\rDynamic(\mathbf{P}')$ will exceed $\omega$. This contradicts the definition of $\omega$. Thus, the lemma follows.\footnote{In fact, such a price vector $ \mathbf{P}' $ for the initial $\omega$ units should have the same prices as the vector $\boldsymbol{\pi}$ and for the $(i+1)$-th unit, $ \mathbf{P}' $ should be equal to $ U^{\omega}$ (i.e., $ P'_{i+1} = U^{\omega}$).} 
\end{proof}

Given an instance $\mathcal{I}$, let the set $\mathcal{B} \subseteq \mathcal{I}$ contain the highest-valued buyers that the offline optimal algorithm selects. We further divide $\mathcal{B}$ into two subsets: $\mathcal{B}_{1}$ and $\mathcal{B}_{2}$. $\mathcal{B}_{1}$ comprises the highest-valued buyers up to time $\tau_{\omega}$, while $\mathcal{B}_{2}$ includes the remaining buyers in $\mathcal{B}$ who arrive at or after time $\tau_{\omega}$.
Let us further partition $\mathcal{B}_{1}$ into two subsets: $\mathcal{B}_{1,1}$ and $\mathcal{B}_{1,2}$. Here, $\mathcal{B}_{1,1}$ consists of buyers in $\mathcal{B}_{1}$ with valuations at least $L_{\omega}$, and $\mathcal{B}_{1,2} = \mathcal{B}_{1} \setminus \mathcal{B}_{1,1}$ comprises those with valuations strictly less than $L_{\omega}$.

For the rest of the analysis, let us study the problem for two separate cases that may occur depending on the instance $\mathcal{I}$. 



\subsection{Case 1: Buyer $ \tau_{\omega}$ Has the Highest Valuation}
In this case, in the set $\mathcal{B}_{2}$, no buyer has a valuation greater than $U_{\omega-1}$ except for the buyer at time $\tau_{\omega}$. Therefore, the buyer at time $\tau_{\omega}$ possesses the highest valuation in the instance $\mathcal{I}$.

\subsubsection{Bound \OPT from Above  for Case 1}
The following upper bound can be derived for $\OPT(\mathcal{I})$, which denotes the objective value of the offline optimal algorithm on instance $\mathcal{I}$:
\begin{align*}
    & \OPT(\mathcal{I}) \\
    =\ & V(\mathcal{B}_{1} ) + V(\mathcal{B}_{2} ) - \sum_{i=1}^{|\mathcal{B}|} c_{i}\\
    \leq\ &  V(\mathcal{B}_{1} ) + (|\mathcal{B}_{2}|-1) \cdot U_{\omega-1} + \nu_{\tau_{\omega}} - \sum_{i=1}^{|\mathcal{B}|} c_{i} \\
    =\ &  V(\mathcal{B}_{1,1}) + V(\mathcal{B}_{1,2}) + (|\mathcal{B}_{2}|-1)  \cdot U_{\omega-1} + \nu_{\tau_{\omega}} - \sum_{i=1}^{|\mathcal{B}|} c_{i} \\
    \leq\ &   |\mathcal{B}_{1,1}| \cdot U_{\omega-1} + (V(\mathcal{B}_{1,1}) - |\mathcal{B}_{1,1}| \cdot U_{\omega-1} )   \\
    & \hspace{1.8cm} + |\mathcal{B}_{1,2}| \cdot U_{\omega-1} + (|\mathcal{B}_{2}|-1) \cdot U_{\omega-1}   + \nu_{\tau_{\omega}} - \sum_{i=1}^{|\mathcal{B}|} c_{i} \\
    \leq\ &  (k-1) \cdot U_{\omega-1} + (V(\mathcal{B}_{1,1}) - |\mathcal{B}_{1,1}| \cdot U_{\omega-1} )  + \nu_{\tau_{\omega}} - \sum_{i=1}^{k} c_{i},
\end{align*}
where the first inequality directly follows the condition of \textbf{Case 1}. The second inequality follows the definition of $\mathcal{B}_{1,1}$ and $\mathcal{B}_{1,2}$. Finally, the third inequality follows the fact that we only focus on the case when $c_{k} < L$.

\subsubsection{Bound \ALG from Below  for Case 1} 
Moving forward, we focus on  establishing a lower bound on the performance of \rDynamic under the arrival instance $\mathcal{I}$. Let the random variables $\{X_{i}\}_{\forall i \in [k]}$ represent the value obtained by \rDynamic from allocating the $i$-th unit of the item. Given the input instance $\mathcal{I}$, let $\mathbb{E}[\ALG(\mathcal{I})]$ denote the expected performance of \rDynamic. Therefore, we have:
\begin{align*}
       & \mathbb{E}[\ALG(\mathcal{I})] \\
    =\ & \mathbb{E}\left[\sum_{i=1}^{k} (X_{i} - c_{i}) \cdot \mathds{1}_{\textit{\{i-th item is sold under price vector $\mathbf{P}$\}}}\right],\\
    \geq\ & \sum_{i=1}^{\omega-1} \mathbb{E}[X_{i} - c_{i}]  \\
    = \ & \sum_{i=1}^{\omega-1} \mathbb{E}[X_{i}]  - \sum_{i=1}^{\omega-1}  c_{i} \\
    \ge\ &   \sum_{i=1}^{\omega-1} \int_{0}^{1} \phi_i(\eta) d\eta \ + (V(\mathcal{B}_{1,1}) - |\mathcal{B}_{1,1}| \cdot U_{\omega-1}) - \sum_{i=1}^{\omega-1} c_{i}.
\end{align*}
In the equations above, all expectations are taken with respect to the randomness of the price vector $\mathbf{P}$. The first inequality follows Lemma \ref{appendix:prop:omega-1}, indicating that under any price vector $\mathbf{P}$, \rDynamic sells at least $\omega-1$ units. The first term in the second inequality follows due to the independent sampling used to set the price of the $i$-th unit using the pricing function $\phi_{i}$, and the second term follows Lemma \ref{appendix:prop:main:claim3-upper-bound-kselection-cost}. 

Let us define $\psi_{i}(v) = \sup\{s: \phi_{i}(s) \leq v\}$ for all $i \in [k]$. From the definition of $\{\phi_{i}\}_{\forall i \in [k]}$ in Theorem \ref{upper-bound-large-inventory-cr}, it follows that:
\begin{align*}
    & \mathbb{E}[\ALG(\mathcal{I})] \\
    \ge\ & \sum_{i=1}^{\omega-1} \int_{0}^{1} \phi_i(\eta) d\eta \  - \sum_{i=1}^{\omega-1} c_{i} + \left(V(\mathcal{B}_{1,1}) - |\mathcal{B}_{1}| \cdot L_{\omega} \right)  \\
  =\ & \sum_{i=1}^{\omega} \psi_{i}(L) \cdot (L - c_{i+1})+ \sum_{i=1}^{\omega-1} \int_{\eta =L}^{U_{\omega-1}} (\eta - c_{i+1} )d\psi_{i}(\eta) + \big(V(\mathcal{B}_{1,1}) - |\mathcal{B}_{1}| \cdot L_{\omega}\big).
\end{align*}
Furthermore, it is evident that based on  the design of $\{\phi_{i}\}_{\forall i \in [k]}$ with $\alpha = \alpha_{\mathcal{S}}^*(k)$, the set of functions $\{\psi_{i}(v)\}_{\forall i \in [k]}$ follows the same design as $\{\psi_{i}^{\alpha}(v)\}_{\forall i \in [k]}$ given in Proposition \ref{prop:lower-bound-psi-star-design}. As a result, it follows that:
\begin{align*}
    & \sum_{i=1}^{k} \psi_{i}(L) \cdot (L - c_{i+1}) + \sum_{i=1}^{\omega-1} \int_{\eta =L}^{U_{\omega-1}} (\eta - c_{i+1} )d\psi_{i}(\eta) + (V(\mathcal{B}_{1}) - |\mathcal{B}_{1}| \cdot L_{\omega}) \\
     \ge\ &  \frac{1}{\alpha_{\mathcal{S}}^*(k)} \cdot \left(k \cdot U_{\omega-1} - \sum_{i} c_{i} \right) + \left(V(\mathcal{B}_{1,1}) - |\mathcal{B}_{1}| \cdot L_{\omega} \right).
\end{align*}

\subsubsection{Putting Everything Together for Case 1}
Putting together the lower bound and upper bound derived for the expected objective value of \rDynamic and the offline optimal algorithm, it follows that:
\begin{align*}
   & \frac{\OPT(\mathcal{I})}{ \mathbb{E}[\ALG(\mathcal{I})]} \\
   \leq\ & \frac{(k-1) \cdot U_{\omega-1} + \nu_{\tau_{\omega}} + (V(\mathcal{B}_{1,1}) - |\mathcal{B}_{1,1}| \cdot L_{\omega} ) - \sum_{i=1}^{k} c_{i}}{\frac{1}{\alpha_{\mathcal{S}}^*(k)} \cdot (k \cdot U_{\omega-1} - \sum_{i} c_{i}) + (V(\mathcal{B}_{1,1}) - |\mathcal{B}_{1,1}| \cdot L_{\omega})} \\
    \leq\  & \frac{(k-1) \cdot U_{\omega-1} + \nu_{\tau_{\omega}} - \sum_{i=1}^{k} c_{i}}{\frac{1}{\alpha_{\mathcal{S}}^*(k)} \cdot \left(k \cdot U_{\omega-1} - \sum_{i} c_{i}\right)} \\
    =\ & \alpha_{\mathcal{S}}^*(k) \cdot \left(1+\frac{\nu_{\tau_{\omega}}-U_{\omega-1}}{k\cdot U_{\omega-1}-C}\right) \\
    \leq\ & \alpha_{\mathcal{S}}^*(k) \cdot \left(1+\frac{U_{\omega}-U_{\omega-1}}{k\cdot U_{\omega-1}-C}\right) \\
    \leq\ & \alpha_{\mathcal{S}}^*(k) \cdot e^{\frac{\alpha_{\mathcal{S}}^*(k)}{k}}.
\end{align*} 
In the equation above, the last inequality is due to the fact that $\frac{U_{\omega}-U_{\omega-1}}{U_{\omega-1} - c_{\omega}} = \frac{U_{\omega}-c_{\omega}}{U_{\omega-1} - c_{\omega}} - 1 \leq 1 + e^{\frac{\alpha_{\mathcal{S}}^*(k)}{k}}$, where the last inequality follows the design in Eq. \eqref{upper-bound-main-theorem-design_U_L_h}.


\subsection{Case 2: Buyer $ \tau_{\omega}$ Does Not Have the Highest Valuation}
In the set of buyers $\mathcal{B}_{2}$, there are other buyers with valuation greater than $U_{\omega-1}$ besides the buyer at time $\tau_{\omega}$.
Let $\lambda$ denote the value of the highest buyer in $\mathcal{B}_{2}$ along with the value of buyer at time $\tau_{\omega}$.
First, let us consider the case that $\lambda \leq \nu_{\tau_{\omega}}$. The proof for the case that $\lambda > \nu_{\tau_{\omega}}$ follows exactly the same as the following case.

\subsubsection{Bound \OPT from Above for Case 2}
Following the same approach as the previous Case 1, let us first upper bound the objective of the offline optimal algorithm on instance $\mathcal{I}$:
\begin{align*}
     & \OPT(\mathcal{I}) \\
     =\ & V(\mathcal{B}_{1}) + V(\mathcal{B}_{2}) - \sum_{i=1}^{|\mathcal{B}|} c_{i}\\ 
    \leq\ & V(\mathcal{B}_{1}) + (|\mathcal{B}_{2}|-1) \cdot \lambda + \nu_{\tau_{\omega}} - \sum_{i=1}^{|\mathcal{B}|} c_{i} \\
    \leq\ &  V(\mathcal{B}_{1,1}) + V(\mathcal{B}_{1,2}) + (|\mathcal{B}_{2}|-1) \cdot \lambda + \nu_{\tau_{\omega}} - \sum_{i=1}^{|\mathcal{B}|} c_{i} \\
    \leq\ &  |\mathcal{B}_{1,1}| \cdot U_{\omega-1} + (V(\mathcal{B}_{1,1}) - |\mathcal{B}_{1,1}| \cdot U_{\omega-1} ) + \\
    & \hspace{1cm} |\mathcal{B}_{1,2}| \cdot U_{\omega-1} + (|\mathcal{B}_{2}|-1) \cdot \lambda + \nu_{\tau_{\omega}} - \sum_{i=1}^{|\mathcal{B}|} c_{i} \\
    \leq\ & (k-1) \cdot \lambda + \nu_{\tau_{\omega}} + (V(\mathcal{B}_{1}) - |\mathcal{B}_{1}| \cdot L_{\omega} ) - \sum_{i=1}^{k} c_{i}.
\end{align*}
 

\subsubsection{Bound \ALG from Below for Case 2}
To establish a lower bound on the performance of \rDynamic in this case, let us consider the following lemma:
\begin{lemma}
\label{claim4-upper-bound-k-selection}
    If the random price of the $\omega$-th unit is realized to be less than $\lambda$ and further assume that $\lambda \leq \nu_{\tau_{\omega}}$, 
    then the number of items allocated by \rDynamic in the end is equal to $\omega$.
\end{lemma}
\begin{proof}
Under any price realization, as established by Lemma \ref{appendix:prop:omega-1}, it is proven that after the arrival of the buyer at time $\tau_{\omega}$, the number of allocated units is at least $\omega-1$. If the price of the $\omega$-th unit is realized to be less than $\lambda$, then upon the arrival of the buyer with valuation $\lambda$ at some time after $\tau_{\omega}$, the buyer will accept the price if the $\omega$-th unit has not already been sold. 
\end{proof}

Next, we obtain a lower bound on the performance of \rDynamic as follows:
\begin{align*}
    & \mathbb{E}[\ALG(\mathcal{I})] \\
    =\ & \mathbb{E}\left[\sum_{i=1}^{k} (X_{i} - c_{i}) \cdot \mathds{1}_{\textit{\{i-th item is sold under pricie vector $\mathbf{P}$\}}}\right]\\
    \geq\ &  \sum_{i=1}^{\omega-1} \mathbb{E}[X_{i} - c_{i}] +    \mathbb{E}[X_{\omega} - c_{\omega} | P_{\omega} \leq \lambda]\\
    \ge\ &  \sum_{i=1}^{\omega-1} \int_{0}^{1} \phi_i(\eta) d\eta \ + \int_{0}^{\phi_{\omega}^{-1}(\lambda)} \phi_{\omega}(\eta) d\eta - \phi_{\omega}^{-1}(\lambda) \cdot c_{\omega} - \sum_{i=1}^{\omega-1} c_{i}  + (V(\mathcal{B}_{1}) - |\mathcal{B}_{1}| \cdot L_{\omega}).
\end{align*}
In the equations above, all expectations are taken with respect to the randomness of the price vector $\mathbf{P} \in \mathcal{P}$.  The first inequality follows Lemma \ref{claim4-upper-bound-k-selection}, where $P_{\omega}$ denotes the  $\omega$-element of the random price vector $\mathbf{P}$ that \rDynamic posts for the $\omega$-th unit.
The second inequality is true because of the independent sampling that is used to set the random price of the $i$-th unit using $\phi_{i}$ and Lemma \ref{appendix:prop:main:claim3-upper-bound-kselection-cost}.  

Let us define $\psi_{i}(v) = \sup\{s : \phi_{i}(s) \leq v\}$, $i \in [k]$. From the definition of $\{\phi_{i}\}_{i \in [k]}$ in Theorem \ref{upper-bound-large-inventory-cr}, it follows that:
\begin{align*}
 &\sum_{i=1}^{\omega-1} \int_{0}^{1} \phi_i(\eta) d\eta \ + \int_{0}^{\phi_{\omega}^{-1}(\lambda)} \phi_{\omega}(\eta) d\eta - \phi_{\omega}^{-1}(\lambda) \cdot c_{\omega}  - \sum_{i=1}^{\omega-1} c_{i} + (V(\mathcal{B}_{1}) - |\mathcal{B}_{1}| \cdot L_{\omega}) \\
 =\ & \sum_{i=1}^{k} \psi_{i}(L) \cdot (L - c_{i+1}) + \sum_{i=1}^{\omega} \int_{\eta =L}^{\lambda} (\eta - c_{i+1} )d\psi_{i}(\eta)  + (V(\mathcal{B}_{1}) - |\mathcal{B}_{1}| \cdot L_{\omega}).
\end{align*}
Furthermore, it is evident that the set of functions $\{\psi_{i}(v)\}_{\forall i \in [k]}$ follows the same design as $\{\psi_{i}^{\alpha}(v)\}_{i \in [k]}$ given in Lemma \ref{prop:lower-bound-psi-star-design} (recall that $\{\psi_{i}^{\alpha}(v)\}_{i \in [k]}$ are based on $\{\phi_{i}\}_{\forall i \in [k]}$). As a result, it follows that:\begin{align*}
    &\sum_{i=1}^{k} \psi_{i}(L) \cdot (L - c_{i+1}) + \sum_{i=1}^{\omega} \int_{\eta =L}^{\lambda} (\eta - c_{i+1} )d\psi_{i}(\eta)   + (V(\mathcal{B}_{1}) - |\mathcal{B}_{1}| \cdot L_{\omega})\\
   \ge\ &  \frac{1}{\alpha_{\mathcal{S}}^*(k)} \cdot \left(k \cdot \lambda - \sum_{i} c_{i}) + (V(\mathcal{B}_{1} \right) - |\mathcal{B}_{1}| \cdot L_{\omega}).
\end{align*}


\subsubsection{Putting Everything Together for Case 2}
Putting together the above lower and upper bounds, it follows that:
\begin{align*}
    & \frac{\OPT(\mathcal{I})}{ \mathbb{E}[\ALG(\mathcal{I})]} \\
    \leq\ & \frac{(k-1) \cdot \lambda + \nu_{\tau_{\omega}} + (V(\mathcal{B}_{1}) - |\mathcal{B}_{1}| \cdot L_{\omega} ) - \sum_{i=1}^{k} c_{i}}{\frac{1}{\alpha_{\mathcal{S}}^*(k)} \cdot (k \cdot \lambda - \sum_{i=1}^{k} c_{i}) + (V(\mathcal{B}_{1}) - |\mathcal{B}_{1}| \cdot L_{\omega})} \\
    \leq\ & \frac{(k-1) \cdot \lambda + \nu_{\tau_{\omega}} - \sum_{i=1}^{k} c_{i}}{\frac{1}{\alpha_{\mathcal{S}}^*(k)} \cdot (k \cdot \lambda - \sum_{i=1}^{k} c_{i})} \\
    =\ & \alpha_{\mathcal{S}}^*(k) \cdot (1+\frac{\nu_{\tau_{\omega}}-\lambda}{k\cdot \lambda -C}) \\
    \leq\ & \alpha_{\mathcal{S}}^*(k) \cdot (1+\frac{U_{\omega}-U_{\omega-1}}{k\cdot U_{\omega-1}-C}) \\
    \leq\ & \alpha_{\mathcal{S}}^*(k) \cdot e^{\frac{\alpha_{\mathcal{S}}^*(k)}{k}}.
\end{align*} 


We thus complete the proof of Theorem~\ref{upper-bound-large-inventory-cr}.


\begin{remark}
    Theorem~\ref{upper-bound-large-inventory-cr} argues that  \rDynamic is asymptotically optimal. We emphasize that our analysis of Theorem \ref{upper-bound-large-inventory-cr} is not tight because it does not differentiate between the sample paths of \rDynamic when the algorithm sells $\omega-1$ units and those when it sells $\omega$ units. As a result, our analysis considers that \rDynamic sells $\omega-1$ units of the item on all sample paths.\footnote{We conjecture that \rDynamic is optimal even in the small inventory regime if a tighter analysis is performed.} However, in the subsequent analysis for the case of $k=2$, we can enumerate all the scenarios and therefore do not require such a reduction. For this reason,  we can prove in the next section that \rDynamic is indeed optimal for $k=2$ (see the proof of Corollary \ref{corrolary:upper-bound-small-inventory-optimality} next).
\end{remark}


\section{Proof of Corollary \ref{corrolary:upper-bound-small-inventory-optimality} }
\label{appendix:proof-corrolary:upper-bound-small-inventory-optimality}
In this section, we prove that for an arbitrary instance $\mathcal{I}$, the expected performance of \rDynamic, denoted as $\mathbb{E}[\ALG(\mathcal{I})]$, is at least $\frac{\OPT(\mathcal{I})}{\alpha_{\mathcal{S}}^*(2)}$. 

Let $v^{*}_{1},v^{*}_{2}$ denote the two highest valuations in the instance $\mathcal{I}$ (we omit the proof for the trivial case with only one buyer in $\mathcal{I}$). Depending on the values of $v^{*}_{1} $ and $v^{*}_{2}$, the following three cases occur. In each scenario, we prove that $\mathbb{E}[\ALG(\mathcal{I})] \geq \frac{\OPT(\mathcal{I})}{\alpha_{\mathcal{S}}^*(2)} = \frac{v^{*}_{1}+v^{*}_{2}-c_1-c_2}{\alpha_{\mathcal{S}}^*(2)}$ holds.

\textbf{\textbf{Case I}: $v^{*}_{1}\leq v^{*}_{2} \leq U_{1}$.}
Let random variables $X_{1}$ and $X_{2}$ denote the valuations of the buyers that purchase the first and second unit of the item, respectively. Then, it follows that
    \begin{align*}
          & \mathbb{E}[\ALG(\mathcal{I})]  \\
       =\ & \mathbb{E}_{\boldsymbol{s} \sim U^{2}(0,1)}[X_{1}+X_{2} - c_{1}-c_{2}]  \\
        \ge & \int_{s_{1}=0}^{\phi_{1}^{-1}(v^{*}_{1})} (\phi_{1}(s_{1})-c_{1}) \cdot ds_{1} + (v^{*}_{2}-c_{1}) \cdot ( \phi_{1}^{-1}(v^{*}_{2})- \phi_{1}^{-1}(v^{*}_{1})), \\
        \ge & \int_{s_{1}=0}^{\phi_{1}^{-1}(v^{*}_{1})} (\phi_{1}(s_{1})-c_{1}) \cdot ds_{1}  + \int_{s_{1}= \phi_{1}^{-1}(v^{*}_{1})}^{\phi_{1}^{-1}(v^{*}_{2})} (\phi_{1}(s_{1})-c_{1}) \cdot ds_{1} \\
         = & \int_{s_{1}=0}^{\phi_{1}^{-1}(v^{*}_{2})} (\phi_{1}(s_{1})-c_{1}) \cdot ds_{1}   \\
        \ge & \frac{v^{*}_{1}+v^{*}_{2}-c_{1}-c_{2}}{\alpha_{\mathcal{S}}^*(2)} \\
        =\ & \frac{\OPT(\mathcal{I})}{\alpha_{\mathcal{S}}^*(2)},
    \end{align*}
where the first two terms in the first inequality arise from the fact that if the realized price for the first unit of the item, denoted as $P_{1} = \phi_{1}(s_1)$, is set below $v^{*}_{1}$, then in the worst-case scenario, the value obtained from the first item will be at least equal to $\phi_{1}(s_1)$. The subsequent two terms are included because if the price for the first item falls within the range from $v^{*}_{1}$ to $v^{*}_{2}$, then the first item is allocated to the buyer whose valuation is $v^{*}_{2}$.
The second inequality follows since $\phi_{1}(s_1)$ is an non-decreasing function. The third inequality follows from the design of $\phi_1(s_1)$ in Theorem \ref{corrolary:upper-bound-small-inventory-optimality}. 

\textbf{\textbf{Case II}: $v^{*}_{1} \leq U_{1} = L_{2} \leq v^{*}_{2} \leq U$.} In this case,  we have  
    \begin{align*}
           & \mathbb{E}[\ALG(\mathcal{I})] \\
        =\ & \mathbb{E}_{\boldsymbol{s} \sim U^{2}(0,1)}[X_{1} - c_{1}] + \mathbb{E}_{\boldsymbol{s} \sim U^{2}(0,1)}[X_{2} - c_{2}] \\
         \ge & \int_{s_{1}=0}^{\phi_{1}^{-1}(v^{*}_{1})} (\phi_{1}(s_{1})-c_1) ds_{1}+ (v^{*}_{2}-c_{1}) \cdot (1-\phi^{-1}_{1}(v^{*}_{1})) + (v^{*}_{2}-c_{2})\cdot \phi_{1}^{-1}(v^{*}_{1})\cdot \phi_{2}^{-1}(v^{*}_{2}) \\
         = & \frac{2\cdot v^{*}_{1}-c_{1}-c_{2}}{\alpha_{\mathcal{S}}^*(2)} + (v^{*}_{2}-c_{1}) \cdot (1-\phi^{-1}_{1}(v^{*}_{1})) + (v^{*}_{2}-c_{2})\cdot \phi_{1}^{-1}(v^{*}_{1})\cdot \phi_{2}^{-1}(v^{*}_{2}).
    \end{align*}
    To prove $\mathbb{E}[\ALG(\mathcal{I})] \ge \frac{\OPT(\mathcal{I})}{\alpha_{\mathcal{S}}^*(2)}= \frac{v^{*}_{1}+v^{*}_{2}-c_1-c_2}{\alpha_{\mathcal{S}}^*(2)}$, we define the following function
    \begin{align*}
    G(v^{*}_{1},v^{*}_{2}) = \ & \frac{2\cdot v^{*}_{1}-c_{1}-c_{2}}{\alpha_{\mathcal{S}}^*(2)} + (v^{*}_{2}-c_{1}) \cdot (1-\phi^{-1}_{1}(v^{*}_{1}))+ \\
    & (v^{*}_{2}-c_{2})\cdot \phi_{1}^{-1}(v^{*}_{1})\cdot \phi_{2}^{-1}(v^{*}_{2}) - \frac{v^{*}_{1}+v^{*}_{2}-c_1-c_2}{\alpha_{\mathcal{S}}^*(2)}.
    \end{align*}
    Then the goal is to prove $  G(v^{*}_{1},v^{*}_{2}) \ge 0 $ in its domain $L \leq v^{*}_{1}\leq U_{1}$ and $L_{2} \leq v^{*}_{2}\leq U$. The proposition below formally states this result.
    \begin{proposition}
        \label{upper-bound-small-inventory-lemma}
    For all $ v^{*}_{1} \in [L_{1},U_{1}]$  and $v^{*}_{2} \in  [L_{2},U_{2}]$, we have $  G(v^{*}_{1},v^{*}_{2}) \ge 0 $.
    \end{proposition} 
   We deferred the proof of the above proposition to Appendix \ref{appendix:upper-bound-small-inventory-lemma}. The idea is to simply prove that $  G(v^{*}_{1},v^{*}_{2}) \ge 0 $ holds at all extreme points within its domain.
   
\textbf{\textbf{Case III}: $L_2 \leq v^{*}_1 \leq v^{*}_2$.} In this case, we show that we can lower bound the expected performance of \rDynamic as follows:
    \begin{align*}
         & \mathbb{E}[\ALG(\mathcal{I})] \\
         =\ & \mathbb{E}_{\boldsymbol{s} \sim U^{2}(0,1)}[X_{1} - c_{1}] + \mathbb{E}_{\boldsymbol{s} \sim U^{2}(0,1)}[X_{2} - c_{2}] \\
         \ge & \int_{s_{1}=0}^{1} (\phi_{1}(s_{1})-c_1)\cdot ds_{1} + \int_{s_{2}=0}^{\phi_{2}^{-1}(v^{*}_{1})} (\phi_{2}(s_{2})-c_2)\cdot ds_{2}   + (v^{*}_{2}-c_{2}) \cdot (\phi^{-1}_{2}(v^{*}_{2})-\phi^{-1}_{2}(v^{*}_{1})) \\
         \ge & \int_{s_{1}=0}^{1} (\phi_{1}(s_{1})-c_1)\cdot ds_{1} + \int_{s_{2}=0}^{\phi_{2}^{-1}(v^{*}_{1})} (\phi_{2}(s_{2})-c_2)\cdot ds_{2} + \int_{s_{2}=\phi_{2}^{-1}(v^{*}_{1})}^{\phi_{2}^{-1}(v^{*}_{2})} (\phi_{2}(s_{2})-c_2)\cdot ds_{2} \\
         = & \int_{s_{1}=0}^{1} (\phi_{1}(s_{1})-c_1)\cdot ds_{1} + \int_{s_{2}=0}^{\phi_{2}^{-1}(v^{*}_{2})} (\phi_{2}(s_{2})-c_2)\cdot ds_{2}  \\
         = & \frac{2\cdot U_{1}-c_1-c_2}{\alpha_{\mathcal{S}}^*(2)} + \int_{s_{2}=0}^{\phi_{2}^{-1}(v^{*}_{2})} (\phi_{2}(s_{2})-c_2)\cdot ds_{2} \\
         = & \frac{2 \cdot v^{*}_{2}-c_1-c_2}{\alpha_{\mathcal{S}}^*(2)} \\
        \ge &  \frac{\OPT(\mathcal{I})}{\alpha_{\mathcal{S}}^*(2)},
    \end{align*}
where the first term in the first inequality arises from the fact that if the realized price for the first unit of the item, denoted as $P_{1} = \phi_{1}(s_1)$, is set below $L_{2}$, then in the worst-case scenario, the value obtained from the first item will be at least equal to $\phi_{1}(s_1)$. The second and third terms follow the same reasoning. The second inequality follows the fact that $\phi_{2}(s_2)$ is non-decreasing. The third and forth equalities follow the design of  
 $\phi_1(s_1)$ and $\phi_2(s_2)$ in Theorem \ref{corrolary:upper-bound-small-inventory-optimality}. 
 
 Combining the analysis of the above three cases, Corollary \ref{corrolary:upper-bound-small-inventory-optimality} follows. 


\section{Proof of Proposition \ref{upper-bound-small-inventory-lemma}}
\label{appendix:upper-bound-small-inventory-lemma}
We first evaluate the value of $G(v^{*}_{1}, v^{*}_{2})$ at its critical points, that is, at the points where $\frac{\partial G(v^{*}_{1}, v^{*}_{2})}{\partial v^{*}_{1}} = 0$ and $\frac{\partial G(v^{*}_{1}, v^{*}_{2})}{\partial v^{*}_{2}} = 0$, and show that $G(v^{*}_{1}, v^{*}_{2}) \geq 0$ holds at these critical points. After that, the proposition follows by evaluating the values of $G(v^{*}_{1}, v^{*}_{2})$ at the four boundary hyperplanes of its domain.

First, let us compute $\frac{\partial G(v^{*}_{1},v^{*}_{2}) }{\partial v^{*}_{1}} $. It follows that:
        \begin{align*}
           \frac{\partial G(v^{*}_{1},v^{*}_{2}) }{\partial v^{*}_{1}}  =  \frac{1}{\alpha_{\mathcal{S}}^*(2)} - \frac{2}{\alpha_{\mathcal{S}}^*(2)}\cdot \frac{v^{*}_{2}-c_{1}}{v^{*}_{1}-c_{1}}  + \frac{2}{\alpha_{\mathcal{S}}^*(2)} \cdot \frac{v^{*}_{2}-c_{2}}{v^{*}_{1}-c_{1}} \cdot \phi_{2}^{-1}(v^{*}_{2}).
            \end{align*}
Setting the right-hand side of above equation to be zero, we have
\begin{align*}
 \phi_{2}^{-1}(v^{*}_{2})\cdot(v^{*}_{2}-c_2) = v^{*}_{2} - c_1 - \frac{v^{*}_{1}-c_1}{2}.
\end{align*}
Using the equation above, we then compute $G(v^{*}_{1},v^{*}_{2})$ at the points that $\frac{\partial G(v^{*}_{1},v^{*}_{2}) }{\partial v^{*}_{1}} = 0$, it follows that:
        \begin{align*}
            G(v^{*}_{1},v^{*}_{2}) 
            =& \frac{v^{*}_{1}-v^{*}_{2}}{\alpha_{\mathcal{S}}^*(2)} + (v^{*}_{2}-c_1)\cdot(1-\phi_1^{-1}(v^{*}_{1})) +  (v^{*}_{2} - c_1 - \frac{v^{*}_{1}-c_1}{2})\cdot\phi_1^{-1}(v^{*}_{1}) \\
             = &  \frac{v^{*}_{1}-v^{*}_{2}}{\alpha_{\mathcal{S}}^*(2)} + (v^{*}_{2} - c_1) - \frac{v^{*}_{1}-c_1}{2}\cdot \phi_{1}^{-1}(v^{*}_{1})  \\
             \ge & \frac{v^{*}_{1}-v^{*}_{2}}{\alpha_{\mathcal{S}}^*(2)} + (v^{*}_{2} - c_1) - \frac{v^{*}_{1}-c_1}{2}\\
            = & v^{*}_{1} \cdot (\frac{1}{\alpha_{\mathcal{S}}^*(2)}-\frac{1}{2}) + v^{*}_{2} \cdot (1-\frac{1}{\alpha_{\mathcal{S}}^*(2)}) - \frac{c_1}{2} \\
            \ge & \frac{v^{*}_{1}-c_1}{2} \\
            > & 0,
        \end{align*}
leading to the conclusion that  $G(v^{*}_{1}, v^{*}_{2}) \geq 0 $ holds at its critical points.
        
        Next, we consider the boundary hyperplanes and prove that $G(v^{*}_{1},v^{*}_{2})$ is positive in all four boundary planes given below:
        \begin{itemize}
            \item $ G(L_1,v^{*}_{2}), \quad \forall v^{*}_{2} \in [L_{2},U_{2}]$.
            \item $G(U_1,v^{*}_{2}), \quad \forall v^{*}_{2} \in [L_{2},U_{2}]$.
            \item $G(v^{*}_{1},L_2), \quad \forall v^*_{1} \in [L_{1},U_{1}]$.
            \item $G(v^{*}_{1},U_2), \quad \forall v^*_{1} \in [L_{1},U_{1}]$.   \end{itemize}

        We start with the first one $G(L_1,v^{*}_{2})$:
        \begin{align*}
            G(L,v^{*}_{2})
            = & \frac{2\cdot L - c_1-c_2}{\alpha_{\mathcal{S}}^*(2)} + (v^{*}_{2}-c_2) - \frac{L+v^{*}_{2}-c_1-c_2}{\alpha_{\mathcal{S}}^*(2)}\\
            = & (v^{*}_{2}-c_2) - \frac{v^{*}_{2} - L}{\alpha_{\mathcal{S}}^*(2)} \\
            \ge & 0, \qquad  \forall L_{2} \leq v^{*}_{2} \leq U_{2},
           \end{align*}
           where the equations above follow  since $L \ge c_{2}$ holds (the assumption that the marginal production costs are always less than the valuations).

           For the second one $ G(U_{1},v^{*}_{2}) $:
           \begin{align*}
            G(U_{1},v^{*}_{2})
            = & \frac{2\cdot U_{1} - c_1-c_2}{\alpha_{\mathcal{S}}^*(2)} +(v^{*}_{2}-c_2)\cdot \phi_{2}^{-1}(v^{*}_{2})- \frac{U_1+v^{*}_{2}-c_1-c_2}{\alpha_{\mathcal{S}}^*(2)} \\
            = & (v^{*}_{2}-c_2)\cdot \phi_{2}^{-1}(v^{*}_{2}) - \frac{v^{*}_{2}-U_1}{\alpha_{\mathcal{S}}^*(2)} \\
            \ge & 0, \qquad   \forall L_2 \leq v^{*}_{2} \leq U_2=U.
            \end{align*}
            The equations above follow since $(v^{*}_{2}-c_2)\cdot \phi_{2}^{-1}(v^{*}_{2}) \ge \int_{s_2=0}^{\phi^{-1}_{2}(v^{*})} (\phi_{2}(s_2)-c_{2})\cdot ds_{2} \ge 2 \cdot \frac{v^{*}_{2}-U_1}{\alpha_{\mathcal{S}}^*(2)}$ based on the definition of $\phi_{2}(s)$. 

            For the third one $ G(v^{*}_{1},L_2) $:
            \begin{align*}
            G(v^{*}_{1},L_2)
            = & \frac{2\cdot v^{*}_{1} - c_1-c_2}{\alpha_{\mathcal{S}}^*(2)} + (L_2-c_1)\cdot\phi_{1}^{-1}(v^{*}_{1}) - \frac{v^{*}_{1}+L_2-c_1-c_2}{\alpha_{\mathcal{S}}^*(2)} \\
             = & (L_2-c_1)\cdot (1-\phi_{1}^{-1}(v^{*}_{1})) - \frac{L_2-v^{*}_{1}}{\alpha_{\mathcal{S}}^*(2)} \\
             \ge & 0, \qquad \forall  L_1\leq v^{*}_{1} \leq U_1,
             \end{align*}
         where the above equation follows since $(L_2-c_1)\cdot (1-\phi_{1}^{-1}(v^{*}_{1})) \ge \int_{s_1=\phi_{1}^{-1}(v^{*}_{1})}^{\phi^{-1}_{1}(L_{2})} (\phi_{1}(s_1)-c_{1})\cdot ds_{1} \ge 2 \cdot \frac{L_{2}-v^{*}_{1}}{\alpha_{\mathcal{S}}^*(2)}$ (based on the definition of $\phi_{1}(s)$).

         Finally, for the last one $ G(v^{*}_{1},U_{2}) $:
             \begin{align*}
            G(v^{*}_{1},U_{2})
            = & \frac{2\cdot v^{*}_{1} - c_1-c_2}{\alpha_{\mathcal{S}}^*(2)} + (U_{2}-c_1) \cdot (1-\phi_{1}^{-1}(v^{*}_{1}))  +  (U_2-c_2) \cdot \phi_{1}^{-1}(v^{*}_{1}) - \frac{v^{*}_{1}+U_{2}-c_1-c_2}{\alpha_{\mathcal{S}}^*(2)} \\
            \ge & (U_{2}-c_2) - \frac{U_{2} - v^{*}_{1}}{\alpha_{\mathcal{S}}^*(2)} \\
            \ge & 0, \qquad  \forall  L = L_1 \leq v^{*}_{1} \leq U_1,
        \end{align*}
        where the equations above follow since $v^{*}_{1} \ge c_{2}$ holds (again, the assumption that the marginal production costs are always less than the valuations).

Combining all the above analysis, we thus complete the proof of Proposition~\ref{upper-bound-small-inventory-lemma}.


\section{Extension of the Lower Bound Results to General Production Cost Functions}
\label{appendix-lower-bound-extension-general-cost-function}
In this section, we extend our lower bound result in Theorem \ref{lower-bound-main-theorem}, originally developed for the high-value case,\footnote{This corresponds to the case when $c_k < L$, or equivalently, the lowest possible valuation $ L $ is no less than the highest marginal production cost $ c_k $.} to general cumulative production cost functions.

Before presenting the main theorem on obtaining a lower bound for general cost functions, let us introduce some notations. Define
$f^{*}(v):[L,U]\rightarrow \mathbb{R}$ as the conjugate of the total production cost function, where $f^{*}(v) = \max_{i \in [k]} \big(v \cdot i -f(i)\big)$. Additionally, let $ g(v) $ be defined as
\begin{align*}
    g(v) = (f^{*})'(v) = \sum_{i \in [k]} \mathds{1}_{\{v \ge c_{i}\}},
\end{align*}
where $\mathds{1}_{\{A\}}$ is the standard indicator function. Let $\ubar{k}$ denote the smallest natural number such that:
\begin{align*}
    \sum_{i=1}^{\ubar{k}} (L-c_{i}) > \frac{1}{\alpha} \cdot f^{*}(L).
\end{align*}
Following Theorem \ref{lower-bound-main-theorem}, we also define $ \xi $ as follows:
\begin{align*}
    \xi = \frac{\frac{1}{\alpha}\cdot f^{*}(L)-\sum_{i=1}^{\ubar{k}-1} (L-c_{i})}{L - c_{\ubar{k}}}.
\end{align*}

Theorem \ref{lower-bound-main-theorem-general} below extends our lower bound results to settings with general cost functions.
\begin{theorem}
    \label{lower-bound-main-theorem-general}
Given $\mathcal{S} = \{L, U, f\} $ for the \OSDoS problem with $k \ge 1$ and general production cost functions $ f $, no online algorithm, including those with randomization, can achieve a competitive ratio smaller than $\crlb$, where $\crlb$ is the solution to the following system of equations of $\alpha$:
\begin{align}
        \label{lower-bound-U-h-computation-general}
     &  \int_{\eta = L}^{u_{\ubar{k}}} \frac{g(\eta)}{\alpha \cdot (\eta-c_{\ubar{k}})} d\eta = 1 - \xi, \\
\label{lower-bound-other-U-computation-general}
     & \int_{\eta = \ell_{i}}^{u_{\ubar{i}}} \frac{g(\eta)}{\alpha \cdot (\eta-c_{i})}  d\eta = 1, u_{i} = \ell_{i+1}, \ i = \ubar{k}+1, \dots ,k, \\
        & u_{k} = U.
    \end{align}
\end{theorem}
\begin{proof}
The proof proceeds similarly to the proof of Theorem \ref{lower-bound-main-theorem} until the derivation of Eq. \eqref{eq:lb-system-ineq}. Given the arrival instance $\mathcal{I}^{(\epsilon)}$ up to the end of stage-$v$, the objective of the offline optimal algorithm equals $f^{*}(v)$. Therefore, we reformulate Eq. \eqref{lower-bound-system-kselection-cost} as follows:
\begin{align*} 
% \label{lower-bound-system-kselection-costgeneral}
    \ALG\left(\mathcal{I}_v^{(\epsilon)}\right) \ge \frac{1}{\alpha} \cdot f^{*}(v), \quad \forall v \in [L,U].
\end{align*}
In the case of general production cost functions, we derive the following inequality to capture the production level changes of an $\alpha$-competitive algorithm:
\begin{align}    
\sum_{i=1}^{k} \psi_{i}(L) \cdot (L - c_{i}) +  \sum_{i=1}^{k} \int_{\eta =L}^{v} (\eta - c_{i} )d\psi_{i}(\eta)  \ge \frac{1}{\alpha} \cdot f^{*}(v).
    \label{eq:lb-system-ineq-general}
\end{align}
In addition, we define $\alpha_{\mathcal{S}}^*(k)$  as follows:
\begin{align*} 
\alpha_{\mathcal{S}}^*(k) = \inf \Big\{ &  \alpha \ge 1 \big | \text{there exist a set of } k \text{ allocation}\\  
& \text{functions } {\{\psi_{i}(v)\}}_{\forall i \in [k]}  \in \Omega \text{ that satisfy Eq. \eqref{eq:lb-system-ineq-general}} \Big \}.
\end{align*}
From this point onward, the proof continues in the same manner as the proof of Theorem \ref{lower-bound-main-theorem}. Let us define the function  $\chi^{\alpha}(v):[L,U] \rightarrow [0,k]$ and the set of functions ${\{\psi^{\alpha}_{i}(v)\}}_{i \in [k]}$ as specified in  Eq. \eqref{lower-bound-proof-define-chi-function} and Eq. \eqref{prop:lower-bound-psi-star-design}. Consequently, Lemma \ref{lemma:lb:tightness} holds as long as we have increasing marginal production costs (i.e., diseconomies of scale) and Lemma  \ref{property-1} that follows the definition of ${\{\psi^{\alpha}_{i}(v)\}}_{i \in [k]}$ holds in this case as well.

The primary distinction between the two proofs arises in the following proposition, which gives an explicit design of the function $\{\psi^{\alpha}_{i}\}_{\forall i \in [k]}$ by replacing the inequality with an equality in  Eq. \eqref{eq:lb-system-ineq-general}. 

\begin{proposition}\label{lemma-function-desing-lower-bound-cost-general}
For any $\alpha \geq \crlb $, there exist a unique set of functions ${\{\psi^{\alpha}_{i}(v)\}}_{\forall i \in [k]}$ that satisfy Eq. \eqref{eq:lb-system-ineq-general} with an equality:
     \begin{align*}
         &\psi^{\alpha}_{i}(v) = 1, \quad \forall v \in [L,U], \  1 \leq i \leq \ubar{k}-1, \\
         &\psi^{\alpha}_{\ubar{k}}(v) = \begin{cases}
         0 &  v \leq \ell_{\ubar{k}}, \\
         \xi + \int_{\eta=L}^{v} \frac{g(\eta)}{\alpha \cdot (\eta -c_{i})} d\eta, &  v \in [L,u_{\ubar{k}}], \\
         1 & v \ge u_{\ubar{k}},
         \end{cases}\\
         &\psi^{\alpha}_{i}(v) =\begin{cases}
         0 &  v \leq \ell_{i}, \\
          \int_{\eta=\ell_{i}}^{v} \frac{g(\eta)}{\alpha \cdot (\eta -c_{i})} d\eta, &  v \in [\ell_{i},u_{i}], \\
         1 & v \ge u_{i},
         \end{cases} ,\quad  i = \ubar{k}+1, \dots ,k-1. \\
         &\psi^{\alpha}_{k}(v) =\begin{cases}
         0 &  v \leq \ell_{k}, \\
          \int_{\eta=\ell_{k}}^{v} \frac{g(\eta)}{\alpha \cdot (\eta -c_{k})} d\eta, &  v \in [\ell_{k},U],
         \end{cases}
     \end{align*}
 where the intervals are specified by:
 \begin{align}
 \label{eq:appex:lb:general-1}
     &  \int_{\eta = L}^{u_{\ubar{k}}} \frac{g(\eta)}{\alpha \cdot (\eta-c_{\ubar{k}})} d\eta = 1 - \xi, \\
     \label{eq:appex:lb:general-2}
     & \int_{\eta = \ell_{i}}^{u_{\ubar{i}}} \frac{g(\eta)}{\alpha \cdot (\eta-c_{i})}  d\eta = 1, u_{i} = \ell_{i+1}, \ \forall i = \ubar{k}+1, \dots ,k.
 \end{align}
 \end{proposition} 
 
In the proposition above, for any given $\alpha \geq \crlb $, the values of $u_{i}$ and $\ell_{i}$ can be determined. We begin by solving Eq. \eqref{eq:appex:lb:general-1} to find the value of $u_{\ubar{k}}$, and then proceed to find the value of other variables $ \{u_{i}\}_{\forall i}$ using Eq. \eqref{eq:appex:lb:general-2}.

 
 Based on the above proposition, as the value of $\alpha$ decreases, the value of $u_{k}$ also decreases. Again, following the same reasoning as the proof of Theorem \ref{lower-bound-main-theorem}, the lower bound $\alpha_{\mathcal{S}}^*(k)$ is the value of $\alpha$ for which $u_{k}$ computed above is equal to $U$. We thus complete the proof of Theorem \ref{lower-bound-main-theorem-general}. 
\end{proof}


\section{Extension of the Upper Bound Results to General Production Cost Functions}
\label{appendix:upper-bound-general-cost-function}
In this section, we extend the randomized dynamic pricing scheme \rDynamic, originally developed for the high-value case, to general cumulative production cost functions.
\vspace{-0.1cm}
\begin{theorem}\label{thm:upper-bound-general-cost-function}
        Given $\mathcal{S} = \{L, U, f\} $ for the \OSDoS problem with $k \ge 1$,  \rDynamic (Algorithm \ref{alg:kselection-cost}) is $\max_{{i \in [k]}} \alpha_{\mathcal{S}}^*(k) \cdot (1+\frac{U_{i}-c_{i}}{f^{*}(U_{i-1})})$-competitive for the following design of the pricing functions $\{\phi_{i}\}_{\forall i \in [k]}$, where $\alpha_{\mathcal{S}}^*(k)$ is the lower bound obtained in Theorem \ref{lower-bound-main-theorem-general}: 
        \begin{align*}
            & \phi_{i}(s) = L, \quad \forall s \in [0,1], \ i \in [\ubar{k}^{*}-1],  \\
        &  \phi_{\ubar{k}^{*}}(s) = \begin{cases}
                L &  s \in [0,\xi^{*}], \\
            \psi_{\ubar{k}^{*}}^{-1}(s) & s \in (\xi^{*},1],
            \end{cases} \\
            & \phi_{i}(s) = \psi^{-1}_{i}(s), \quad \forall s \in [0,1], \ i = \ubar{k}^{*}+1,\dots,k,
        \end{align*}
where the set of functions $\{\psi_{i}\}_{\forall i \in \{\ubar{k}^{*},\cdots, k\}} $ are defined as follows:
\begin{align*}
&\psi_{\ubar{k}^{*}}(v) = 
         \xi^{*} + \int_{\eta=L}^{v} \frac{g(\eta)}{\alpha \cdot (\eta -c_{i})} d\eta, \quad \forall v \in [L,U_{\ubar{k}^{*}}], \\
&\psi_{i}(v) =
          \int_{\eta=\ell_{i}}^{v} \frac{g(\eta)}{\alpha \cdot (\eta -c_{i})} d\eta, \quad  \forall v \in [L_{i},U_{i}],\  i = \ubar{k}^{*}+1, \dots ,k; \\
\end{align*}
the parameters $\ubar{k}^{*} $ and $ \xi^{*} $ are respectively the values of $  \ubar{k} $ and $ \xi $ defined in Appendix~\ref{appendix-lower-bound-extension-general-cost-function}, corresponding to $ \alpha = \alpha_{\mathcal{S}}^*(k) $, and the price intervals $ \{[L_i, U_i]\}_{\forall i\in [k]} $ are given as follows:
\begin{align*}
     &  \int_{\eta = L}^{U_{\ubar{k}^{*}}} \frac{g(\eta)}{\alpha \cdot (\eta-c_{\ubar{k}})} d\eta = 1 - \xi, \\
     & \int_{\eta = L_{i}}^{U_{i}} \frac{g(\eta)}{\alpha \cdot (\eta-c_{i})}  d\eta = 1, u_{i} = \ell_{i+1}, \forall i = \ubar{k}^{*}+1, \dots ,k.
\end{align*}
\end{theorem}

\begin{proof}
The proof will follow the same process as the proof in Appendix \ref{appendix:proof-upper-bound-large-inventory-cr}. So we only provide a brief proof sketch.

Consider an arbitrary arrival instance  $\mathcal{I} = \{v_{t}\}_{t \in [T]}$. Recall that the random price vector $\mathbf{P} = \{P_1, \cdots, P_k\} $ is generated using the pricing functions $\{\phi_{i}\}_{\forall i \in [k]}$ at the beginning of \rDynamic (line \ref{line_P_vector} of Algorithm \ref{alg:kselection-cost}). Let us define the random variable $W(\mathbf{P})$, the variable $\omega$ and the price vector $\boldsymbol{\pi}$, the set $\{\nu_{i}, \tau_{i}\}_{\forall i \in [\omega]}$, and $W^{\tau_{\omega}}(\mathbf{P})$ in the same fashion as in Appendix \ref{appendix:proof-upper-bound-large-inventory-cr}.

Following the same reasoning, the property in Eq. \eqref{eq:upper-bound-large-inventory-proof-1} can be derived for $\{\nu_{i}\}_{\forall i \in [\omega]}$, and the lemmas \ref{appendix:prop:omega-1}, \ref{appendix:prop:main:claim3-upper-bound-kselection-cost}, and \ref{appendix:prop:main:claim2-kselection-production-cost} follow as well.

We also define $\mathcal{B} \subseteq \mathcal{I}$, as before, to be the set of highest-valued buyers to whom the offline optimal algorithm allocates a unit of the item in instance $\mathcal{I}$. We further divide $\mathcal{B}$ into two subsets: $\mathcal{B}_{1}$ and $\mathcal{B}_{2}$, as done in the previous proof. Additionally, we partition $\mathcal{B}_{1}$ into two subsets: $\mathcal{B}_{1,1}$ and $\mathcal{B}_{1,2}$, as before.


We continue our analysis for two separate cases that can arise depending on the instance $\mathcal{I}$. In this proof, we only provide the proof for the first case and the proof of the second case follows similarly as Appendix \ref{appendix:proof-upper-bound-large-inventory-cr}.

\textbf{Case 1:}
In this case,  no buyer in $\mathcal{B}_{2}$ has a valuation greater than $U_{\omega-1}$ except for the buyer at time $\tau_{\omega}$. Therefore, the buyer at time $\tau_{\omega}$ possesses the highest valuation in instance $\mathcal{I}$. The following upper bound can be derived for $\OPT(\mathcal{I})$, which denotes the objective value of the offline optimal algorithm:
\vspace{-0.2cm}
\begin{align*}
    \OPT(\mathcal{I}) &= V(\mathcal{B}_{1} ) + V(\mathcal{B}_{2} ) - \sum_{i=1}^{|\mathcal{B}|} c_{i}\\
    & \leq V(\mathcal{B}_{1} ) + (|\mathcal{B}_{2}|-1) \cdot U_{\omega-1} + \nu_{\tau_{\omega}} - \sum_{i=1}^{|\mathcal{B}|} c_{i} \\
    &=  V(\mathcal{B}_{1,1}) + V(\mathcal{B}_{1,2}) + (|\mathcal{B}_{2}|-1)  \cdot U_{\omega-1} + \nu_{\tau_{\omega}} - \sum_{i=1}^{|\mathcal{B}|} c_{i} \\
    & \leq  |\mathcal{B}_{1,1}| \cdot U_{\omega-1} + (V(\mathcal{B}_{1,1}) - |\mathcal{B}_{1,1}| \cdot U_{\omega-1} )  \\
    & \qquad + |\mathcal{B}_{1,2}| \cdot U_{\omega-1} + (|\mathcal{B}_{2}|-1)  \cdot U_{\omega-1} + \nu_{\tau_{\omega}} - \sum_{i=1}^{|\mathcal{B}|} c_{i} \\
    & = (|\mathcal{B}_{1,1}| + |\mathcal{B}_{1,2}| + |\mathcal{B}_{2}|-1) \cdot U_{\omega-1}  + \nu_{\tau_{\omega}}  \\
    & \qquad + (V(\mathcal{B}_{1,1}) - |\mathcal{B}_{1,1}| \cdot U_{\omega-1} ) - \sum_{i=1}^{|\mathcal{B}|} c_{i} \\
    & \leq f^{*}(U_{\omega-1}) + (V(\mathcal{B}_{1,1}) - |\mathcal{B}_{1,1}| \cdot U_{\omega-1} ) + \nu_{\tau_{\omega}} - c_{\omega},
\end{align*}
where the first inequality follows the condition of \textbf{Case 1}. The second inequality follows the definition of the sets $\mathcal{B}_{1,1}$ and $\mathcal{B}_{1,2}$.
Finally, the third inequality follows since based on definition of $f^{*}$, we have $(|\mathcal{B}_{1,1}| + |\mathcal{B}_{1,2}| + |\mathcal{B}_{2}|-1) \cdot U_{\omega-1}  - \sum_{i=1}^{|\mathcal{B}|-1} c_{i} \leq  f^{*}(U_{\omega-1})$.

Moving forward, we can lower bound the expected performance of \rDynamic under $\mathcal{I}$, denoted by $\mathbb{E} [\ALG(\mathcal{I})]$, using the same approach as before. 
\begin{align*}
    \mathbb{E}  [\ALG(\mathcal{I})]
    \ge  \sum_{i=1}^{\omega-1} \int_{0}^{1} \phi_i(\eta) d\eta \ + (V(\mathcal{B}_{1,1}) - |\mathcal{B}_{1,1}| \cdot U_{\omega-1}) - \sum_{i=1}^{\omega-1} c_{i}.
\end{align*}

Based on the definition of $\{\phi_{i}\}_{\forall i\in[k]}$, we have:
\begin{align*}
    \mathbb{E} [\ALG(\mathcal{I})]
     \ge & \sum_{i=1}^{\omega-1} \int_{0}^{1} \phi_i(\eta) d\eta \  - \sum_{i=1}^{\omega-1} c_{i}  + (V(\mathcal{B}_{1,1}) - |\mathcal{B}_{1}| \cdot U_{\omega-1})  \\
   = & \sum_{i=1}^{k} \psi_{i}(L) \cdot (L - c_{i})+ \sum_{i=1}^{\omega-1} \int_{\eta =L}^{U_{\omega-1}} (\eta - c_{i} )d\psi_{i}(\eta) + (V(\mathcal{B}_{1,1}) - |\mathcal{B}_{1}| \cdot U_{\omega-1}).
\end{align*}
Furthermore, based on the design of $\{\psi_{i}\}_{\forall i \in [k]}$ in Theorem \ref{thm:upper-bound-general-cost-function}, we have
\begin{align*}
    &\sum_{i=1}^{k} \psi_{i}(L) \cdot (L - c_{i}) + \sum_{i=1}^{\omega-1} \int_{\eta =L}^{U_{\omega-1}} (\eta - c_{i} )d\psi_{i}(\eta) + (V(\mathcal{B}_{1}) - |\mathcal{B}_{1}| \cdot U_{\omega-1})  \\
   \ge\  &  \frac{1}{\alpha_{\mathcal{S}}^{*}(k)} f^{*}(U_{\omega-1}) + (V(\mathcal{B}_{1}) - |\mathcal{B}_{1}| \cdot U_{\omega-1}).
\end{align*}
Putting together the above lower and upper bounds, it follows that:
\begin{align*}
    \frac{\OPT(\mathcal{I})}{ \mathbb{E} [\ALG(\mathcal{I})]}
    \leq & \frac{f^{*}(U_{\omega-1}) + (V(\mathcal{B}_{1,1}) - |\mathcal{B}_{1,1}| \cdot U_{\omega-1} ) + \nu_{\tau_{\omega}} - c_{\omega}}{\frac{1}{\alpha_{\mathcal{S}}^*(k)} f^{*}(U_{\omega-1}) + (V(\mathcal{B}_{1}) - |\mathcal{B}_{1}| \cdot U_{\omega-1})} \\
    \leq & \frac{f^{*}(U_{\omega-1})  + \nu_{\tau_{\omega}} - c_{\omega}}{\frac{1}{\alpha_{\mathcal{S}}^*(k)} f^{*}(U_{\omega-1})} \\
     = & \alpha_{\mathcal{S}}^*(k) \cdot \left(1+\frac{\nu_{\tau_{\omega}}-c_{\omega}}{f^{*}(U_{\omega-1})} \right) \\
    \leq & \alpha_{\mathcal{S}}^*(k) \cdot \left(1+\frac{U_{\omega}-c_{\omega}}{f^{*}(U_{\omega-1})} \right) \\
    \leq & \max_{{i \in [k]}} \alpha_{\mathcal{S}}^*(k) \cdot \left( 1+\frac{U_{i}-c_{i}}{f^{*}(U_{i-1})} \right).
\end{align*} 

\textbf{Case 2:}
In the set of buyers $\mathcal{B}_{2}$, there are other buyers with valuations greater than $U_{\omega-1}$ besides the buyer at time $\tau_{\omega}$.
The proof in this case follows the same structure as the proof above and the proof in Appendix \ref{appendix:proof-upper-bound-large-inventory-cr}.
\end{proof}