\begin{table}[t]
\caption{Statistics of the preprocessed datasets available for download and loading by users. The \textit{Finetuned} column indicates whether the corresponding subset was generated using a fine-tuned model, while the \textit{Use Answer} column specifies whether the model was aware of the answer during hint generation. %\texttt{Qs} refers to Questions, %\texttt{Hs} refers to Hints, 
\texttt{Va} and \texttt{FT} refer to Vanilla and Finetuned, respectively, \texttt{Aw} refers to AnswerAware, and \texttt{Ag} refers to AnswerAgnostic.}
\label{tbl:preproccesed_datasets}
\resizebox{\columnwidth}{!}{%
\begin{tabular}{@{}llccll@{}}
\toprule
Dataset                    & Subset                          & Finetuned & Use Answer & Num. of Qs & Num. of Hs \\ \midrule
\multirow{14}{*}{TriviaHG~\cite{mozafari-triviahg}} & Training                        & \ding{55} & \ding{51}  & 14,645             & 140,973        \\
                           & Validation                      & \ding{55} & \ding{51}  & 1,000              & 9,638          \\
                           & Test                            & \ding{55} & \ding{51}  & 1,000              & 9,617          \\ \cmidrule{2-6}
                           & LLaMA 2 7b Va              & \ding{55} & \ding{51}  & 100               & 840           \\
                           & LLaMA 2 7b FT            & \ding{51} & \ding{51}  & 100               & 923           \\
                           & LLaMA 2 13b Va            & \ding{55} & \ding{51}  & 100               & 896           \\
                           & LLaMA 2 13b FT          & \ding{51} & \ding{51}  & 100               & 921           \\
                           & LLaMA 2 70b Va            & \ding{55} & \ding{51}  & 100               & 683           \\
                           & LLaMA 2 70b FT          & \ding{51} & \ding{51}  & 100               & 924           \\
                           & Gemini                          & \ding{55} & \ding{51}  & 100               & 942           \\
                           & WizardLM 70b                    & \ding{55} & \ding{51}  & 100               & 941           \\
                           & GPT 3.5                         & \ding{55} & \ding{51}  & 100               & 898           \\
                           & GPT 4                           & \ding{55} & \ding{51}  & 100               & 949           \\
                           & Copilot                         & \ding{55} & \ding{51}  & 100               & 970           \\ \midrule
\multirow{14}{*}{WikiHint~\cite{2024arXiv241201626M}} & Training                        & \ding{55} & \ding{51}  & 900               & 4,500          \\
                           & Test                            & \ding{55} & \ding{51}  & 100               & 500           \\ \cmidrule{2-6}
                           & LLaMA 3.1 8b Va-Aw  & \ding{55} & \ding{51}  & 100               & 100           \\
                           & LLaMA 3.1 8b Va-Ag  & \ding{55} & \ding{55}  & 100               & 100           \\
                           & LLaMA 3.1 8b FT-Aw         & \ding{51} & \ding{51}  & 100               & 100           \\
                           & LLaMA 3.1 8b FT-Ag     & \ding{51} & \ding{55}  & 100               & 100           \\
                           & LLaMA 3.1 70b Va-Aw    & \ding{55} & \ding{51}  & 100               & 100           \\
                           & LLaMA 3.1 70b Va-Ag & \ding{55} & \ding{55}  & 100               & 100           \\
                           & LLaMA 3.1 70b FT-Aw       & \ding{51} & \ding{51}  & 100               & 100           \\
                           & LLaMA 3.1 70b FT-Ag   & \ding{51} & \ding{55}  & 100               & 100           \\
                           & LLaMA 3.1 405b Va-Aw   & \ding{55} & \ding{51}  & 100               & 100           \\
                           & LLaMA 3.1 405b Va-Ag& \ding{55} & \ding{55}  & 100               & 100           \\
                           & GPT 4 Va-Aw            & \ding{55} & \ding{51}  & 100               & 100           \\
                           & GPT 4 Va-Ag         & \ding{55} & \ding{55}  & 100               & 100           \\ \midrule
\multirow{6}{*}{HintQA~\cite{mozafari-hintqa}}    & TriviaQA Va               & \ding{55} & \ding{55}  & 11,313             & 103,018        \\
                           & TriviaQA FT             & \ding{51} & \ding{55}  & 11,313             & 105,709        \\
                           & NQ Va                    & \ding{55} & \ding{55}  & 3,610              & 30,976         \\
                           & NQ FT                   & \ding{51} & \ding{55}  & 3,610              & 33,131         \\
                           & WebQ Va                   & \ding{55} & \ding{55}  & 2,032              & 15,812         \\
                           & WebQ FT                 & \ding{51} & \ding{55}  & 2,032              & 16,978         \\ \midrule
KG-Hint~\cite{jatowt_kg_hint}                    & Test                            & \ding{55} & \ding{55}  & 30                & 307           \\ \bottomrule
\end{tabular}%
}
\end{table}