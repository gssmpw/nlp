\section{Proposed Method}
% \wei{we should highlight pre-training a few more times in this section. it is not until the last subsection that I realize we are developing a pre-trianing framework} 

% \wei{I feel our focus should be pre-training. Other components are serving for enhancing pre-training instead of using pre-training to enhance other components. }

% \wei{Do you think we should first present our pre-training framework and then detail other components? Following this framework, we then describe the challenges in epidemic pre-trainign and introduce the corresponding solutions in each subsections.}

 In this section, we introduce a novel Covariate-Adjusted Pre-training framework for Epidemic forecasting. Enhanced by components that capture temporal dependency (section ~\ref{sec: temporal_corr}) and infer pseudo-environments (section ~\ref{sec: CA} and ~\ref{sec: env_estimate}), CAPE aims to learn the intrinsic disease dynamics through pre-training (section ~\ref{sec: contrast}).

% to learn broad patterns and diverse environment representations.

\subsection{Model Design}


\begin{figure}[t]
\centering
\includegraphics[scale=0.4]{figures/causal_graph.pdf}
\caption{ Structural causal model (SCM) for epidemic foresting.}
% \wei{variables connections with epidemics} 
\label{fig: causal_graph}
\end{figure}



\subsubsection{Modeling Epidemic Forecasting in a Causal Modeling Perspective/Framework}

Given the complex interplay between environments and epidemic dynamics, effectively integrating them into epidemic pre-training presents a challenging question. Since the environments impact both historical infection patterns and future disease spread, we draw inspiration from causal inference~\cite{zhou2023causal, jiao2024causal} and consider the environment as a confounder, i.e., a variable that simultaneously affects both the independent variable (e.g., treatment) and the dependent variable (e.g., outcome). To accurately capture these relationships, we incorporate the environment as a distinct component within a Structural Causal Model (SCM), as illustrated in Figure~\ref{fig: causal_graph}. The SCM effectively represents the underlying generative processes by using directed edges to connect each variable (node), thereby depicting the causal pathways among them.
% \wei{explain the causal a bit, what are nodes/edges; check how other causal inference paper illustrate this concisely. also we should probably put this figure in introduction as we mentioned it in the intro}
Next, beyond accounting for the environment during pre-training, the key mechanism to disentangle the correlations between diseases and the environment is required. Since we view the environment as the confounder during modeling, we can treat the correlation introduced by the environment as spurious correlations~\cite{ming2022impact}. To mitigate the effects of these spurious correlations, covariate adjustment~\cite{runge2023causal} serves as a standard tool that controls for confounding variables to isolate the true causal effect of interest. Nonetheless, effective covariate adjustment requires a comprehensive set of valid confounders to accurately control for all potential sources of bias. While this can be hard to achieve given scarce data for a certain disease and region, pre-training enables the model to utilize a large volume of historical data across diverse diseases and regions, allowing it to capture a more comprehensive set of confounders.


\subsubsection{Capturing Temporal Correlations}
\label{sec: temporal_corr}
Temporal dependency plays an essential role in epidemic time series data as the observed changes often exhibit lagged effects rooted in historical contexts and intervention strategies, shaping current and future trends. In this study, we incorporate self-attention and additional techniques to effectively capture these temporal patterns.

First, to mitigate the impact of temporal distribution shifts, we employ Reversible Instance Normalization(RevIN)~\cite{kim2021reversible} on the input data. Then, instead of treating each time point as a token, we apply patching~\cite{nie2022time} to efficiently and effectively learn useful representations for forecasting:

% is then partitioned into \( N \) patches of fixed length \( L \) ~\cite{}:

\[
\left\{ \mathbf{x}_0, \mathbf{x}_1, \mathbf{x}_2, \ldots, \mathbf{x}_N \right\} = \text{Patching}(\text{RevIN}(\mathbf{X})), \tag{1}
\]

where $N$ denotes the number of patches. Each patch \( \mathbf{x}_i \) then undergoes a learnable linear projection and is augmented with a positional embedding:
\[
\mathbf{x}_i^{(0)} = \mathbf{W}_{p} \mathbf{x}_i + pos(i), \tag{2}
\]
where $\mathbf{W_{p}}$ is the projection matrix and \( pos(i) \) denotes the Sinusoidal Positional Encoding for patch \( i \). 
The resulting encoded patches, \(\mathbf{X}^{(0)}\), are then passed into the CAPE encoders, with \(\mathbf{X}^{(l)}\) denoting the output of the \(l\)-th encoder. As illustrated in Figure ~\ref{fig:CAPE}, each encoder block applies a self-attention mechanism that yields a contextualized representation \(\mathbf{h}_i^{(l)}\), effectively capturing inter-patch correlations:

% The encoded patches \( \mathbf{X}^{(0)} \) are then fed into the CAPE encoders. We denote the output of the $l$ th encoder as $\mathbf{X}^{(l)}$. As illustrated in Figure ~\ref{fig:CAPE}, each encoder block applies a self-attention mechanism to the input, producing a contextualized representation \( \mathbf{h}_i^{(l)} \) that captures inter-patch correlations:

\[
\small
\mathbf{h}_i^{(l)} = \operatorname{Softmax}\left( \frac{(\mathbf{x}_i^{(l)} \mathbf{W}_Q^{(l)}) (\mathbf{X}^{(l)} \mathbf{W}_K^{(l)})^\top}{\sqrt{d_k^{(l)}}} \right) (\mathbf{X}^{(l)} \mathbf{W}_V^{(l)}). \tag{3} 
\]



% To mitigate the impact of temporal distribution shifts, we employ Reversible Instance Normalization~\cite{kim2021reversible} on the input data:
% \[
% \mathbf{X}_{\text{norm}} = \text{RevIN}(\mathbf{X}). \tag{1}
% \]
% Next, the normalized data is partitioned into \( N \) patches of fixed length \( L \) using a patching strategy:
% \[
% \left\{ \mathbf{x}_0, \mathbf{x}_1, \mathbf{x}_2, \ldots, \mathbf{x}_N \right\} = \text{Patching}(\mathbf{X}_{\text{norm}}). \tag{2}
% \]
% Each patch \( \mathbf{x}_i \) undergoes a learnable linear projection and is augmented with a positional embedding:
% \[
% \mathbf{x}_i^{(0)} = \mathbf{W}_{p} \mathbf{x}_i + pos(i), \tag{3}
% \]
% where $\mathbf{W_{p}}$ is the projection matrix and \( pos(i) \) denotes the positional embedding for patch \( i \).
% The encoded patches \( \mathbf{x}_i^{(0)} \) are then fed into the CAPE encoders. We denote the output of the $l$ th encoder as $\mathbf{x}_i^{(l)}$. As illustrated in Figure ~\ref{fig:CAPE}, each encoder block applies a self-attention mechanism to the input, producing a contextualized representation \( \mathbf{h}_i^{(l)} \) that captures inter-patch correlations:

% \[
% \small
% \mathbf{h}_i^{(l)} = \operatorname{Softmax}\left( \frac{(\mathbf{x}_i^{(l)} \mathbf{W}_Q^{(l)}) (\mathbf{X}^{(l)} \mathbf{W}_K^{(l)})^\top}{\sqrt{d_k^{(l)}}} \right) (\mathbf{X}^{(l)} \mathbf{W}_V^{(l)}). \tag{4} 
% \]


\subsubsection{Layer-Wise Covariate Adjustment}
\label{sec: CA}

% \wei{think about how to connect this with Figure 2} \wei{we should also clearly illustrate how we address the two challenges mentioned in Introduction..}

Covariate adjustment is the most widely recognized technique for de-confounding using observational data ~\cite{runge2023causal}. In general terms, the adjustment can be expressed by the following formula:

\begin{equation}
p(\mathbf{y} | do(\mathcal{X}=\mathbf{x})) = \int p(\mathbf{y} | \mathbf{x}, \mathbf{z}) p(\mathbf{z}) d\mathbf{z}, \tag{4}
\end{equation}

where $do(\mathcal{X}=\mathbf{x})$ refers to assigning value $\mathbf{x}$ to variable $\mathcal{X}$.
To mitigate the confounding influences, we control for a set of variables $\mathbf{Z}$, as shown in Figure ~\ref{fig: causal_graph}, and apply the adjustment to the contextualized representations $\mathbf{h}_i^{(l)}$. Nevertheless, the attributes within each dataset for pre-training are neither aligned nor informative to directly produce the confounders. Therefore, we adopt the following assumption to further constrain the problem.

% In this study, $\mathcal{X}$ is the input history time series, $\mathbf{y}$ is the output predictions, and $\mathbf{z}$ is the corresponding environment. 



% However, directly adjusting for covariates without explicit exogenous variables \( z \) presents challenges, our approach infers environmental factors from historical data to effectively account for confounders in epidemic forecasting.

\begin{assumption}
\label{assumption1}
The epidemic forecasting problem involves a finite set of environments $\mathbf{Z}$, each of which possesses a consistent and distinct representation $\mathbf{z}^i$.
\end{assumption}

Such an assumption is reasonable as the dynamics of epidemics are primarily driven by a limited number of factors, which collectively define distinct environments. By assuming fixed representations for these environments, models can effectively capture and leverage the unique patterns and interactions specific to each environment. This facilitates more accurate and generalizable forecasting, as the model can adapt its predictions based on the consistent characteristics inherent to each environment. Under Assumption ~\ref{assumption1}, we are able to reduce the procedure of covariate adjustment to a weighted sum of $p(\mathbf{y}|\mathbf{x},\mathbf{z})$:

\begin{equation}
\label{Eq: 5}
p(\mathbf{y} | \mathbf{x}) = \sum_{\mathbf{Z}} p(\mathbf{y} | \mathbf{x}, \mathbf{z}) \cdot p(\mathbf{z})   \tag{5}
\end{equation}

Since multiple layers can be stacked together, we perform the adjustment in a layer-wise manner. Specifically, given the contextualized representations $\mathbf{h}_i^{(l)}$ at the $l$ th layer, we model Eq. ~\ref{Eq: 5} as follows:

\begin{align}
\label{Eq: 6}
\mathbf{m}_i^{(l)}  = \sum_{k=1}^{K} (\mathbf{h}_i^{(l)} \odot \mathbf{z}^k) \cdot p(\mathbf{z}^k \mid \mathbf{h}_i^{(l)}), \tag{6}
\end{align}

where \( \mathbf{Z} = \{ \mathbf{z}^1, \mathbf{z}^2, \ldots, \mathbf{z}^K \} \) represents the set of fixed environment representations, and \( p(\mathbf{y} | \mathbf{x}, \mathbf{z}) \) is modeled by a hadamard product between $\mathbf{h}_i^{(l)}$ and $\mathbf{z}^k$. Finally, a feedforward neural network \( \mathbf{x}_i^{(l+1)} = \sigma(\mathbf{W}_f^{(l)} \mathbf{m}_i^{(l)}) \) is applied to acquire the output representations, which also serves as the input for the next block. At the end of the model, we acquire the final representation $\mathbf{X^{(L)}} = g_\theta(\mathbf{X})$. Then, a task-specific head is applied to predict the target variable $\mathbf{y}=\mathbf{h}_\psi(\mathbf{X}^{(L)})$, where $h_\psi$ is a linear transformation.




% In order to estimate the environment and perform the adjustment at the same time, we also use the weighted sum of $\mathbf{Z}$ as the inferred environment, since they are in the same semantic space. Therefore, following the self-attention layer, the environment representation \( \mathbf{z}_i^{(l)} \) for each patch is computed as below:

% \[
% \label{Eq: env_estimator}
% \mathbf{e}_i^{(l)} = g_{\phi}^{(l)}(\mathbf{h}_i^{(l)}, \mathbf{Z}) = \sum_{k=1}^{K} \mathbf{z}^k \cdot p(\mathbf{z}^k \mid \mathbf{h}_i^{(l)}), \tag{6}
% \]

% where \( \mathbf{Z} = \{ \mathbf{z}^1, \mathbf{z}^2, \ldots, \mathbf{z}^K \} \) represents the set of fixed environment representations, and \( p(\mathbf{z}^k \mid \mathbf{h}_i^{(l)}) \) is the probability of environment \( \mathbf{z}^k \) given the contextualized representation \( \mathbf{h}_i^{(l)} \). To perform covariate adjustment, the estimated environment \( \mathbf{e}_i^{(l)} \) is then combined with the encoded input via a hadamard product:
% \[
% \mathbf{m}_i^{(l)} = \mathbf{h}_i^{(l)} \odot \mathbf{e}_i^{(l)} = \sum_{k=1}^{K} (\mathbf{h}_i^{(l)} \odot \mathbf{z}^k) \cdot p(\mathbf{z}^k \mid \mathbf{h}_i^{(l)}). \tag{7}
% \]
% This formulation effectively reduces the original covariate adjustment function to Eq.~\ref{Eq: 6}, where \( p(\mathbf{y} | \mathbf{x}, \mathbf{z}) \) is modeled as \( \mathbf{x} \odot \mathbf{z} \). Finally, a feedforward neural network \( \mathbf{x}_i^{(l+1)} = \sigma(\mathbf{W}_f^{(l)} \mathbf{m}_i^{(l)}) \) is applied to acquire the output representations, which also serves as the input for the next block. At the end of the model, we acquire the final representation $g_\theta(\mathbf{X}) = \mathbf{X^{(L)}}$. Then, a task-specific head is applied to predict the target variable $\mathbf{y}=\mathbf{h}_\psi(\mathbf{X}^{(L)})$.



\subsubsection{Pseudo Environment Estimator}
\label{sec: env_estimate}

In order to estimate the environment and perform the adjustment at the same time, we use the weighted sum of $\mathbf{Z}$ as the inferred environment. Therefore, following the self-attention layer, the environment representation \( \mathbf{z}_i^{(l)} \) for each patch at the $l$ th layer is computed by an environment estimator $g_{\phi}^{(l)}$:

\[
\label{Eq: env_estimator}
\mathbf{e}_i^{(l)} = g_{\phi}^{(l)}(\mathbf{h}_i^{(l)}, \mathbf{Z}) = \sum_{k=1}^{K} \mathbf{z}^k \cdot p(\mathbf{z}^k \mid \mathbf{h}_i^{(l)}), \tag{7}
\]

where \( p(\mathbf{z}^k \mid \mathbf{h}_i^{(l)}) \) is the probability of environment \( \mathbf{z}^k \) given the contextualized representation \( \mathbf{h}_i^{(l)} \). To perform covariate adjustment, the estimated environment \( \mathbf{e}_i^{(l)} \) is then combined with the encoded input via a hadamard product to yield the same output as Eq.~\ref{Eq: 6}:
\[
\mathbf{m}_i^{(l)} = \mathbf{h}_i^{(l)} \odot \mathbf{e}_i^{(l)}. \tag{8}
\]


Next, we detail the modeling of the conditional probability \( p(\mathbf{z}^k \mid \mathbf{h}_i^{(l)}) \). To better model the causal and spurious correlations, we adopt the following decomposition assumption from ~\cite{mao2022causal}:
 
\begin{assumption}
As shown in Figure~\ref{fig: causal_graph}, each input $\mathbf{X}$ can be decomposed into the spurious factor $\mathbf{X}_s$ and the causal factor $\mathbf{X}_c$. Consequently, each representation \( \mathbf{h}_i^{(l)} \) can also be decomposed into two representations:  \( \mathbf{h}_{c,i}^{(l)} \) and \( \mathbf{h}_{s,i}^{(l)} \).
\end{assumption} 

Under this assumption and given that \( \mathbf{h}_{c,i}^{(l)} \perp \mathbf{z}^k \), the probability \( p(\mathbf{z}^k \mid \mathbf{h}_i^{(l)}) \) can be expressed as:
\[
p(\mathbf{z}^k \mid \mathbf{h}_i^{(l)}) = p(\mathbf{z}^k \mid \mathbf{h}_{c,i}^{(l)}, \mathbf{h}_{s,i}^{(l)}) = p(\mathbf{z}^k \mid \mathbf{h}_{s,i}^{(l)}). \tag{9}
\]

Then, we model this conditional probability as an attention score using a softmax function:
\[
\label{eq11}
\pi_i^{k(l)} = \operatorname{Softmax} \left( \mathbf{W}_k^{(l)} \mathbf{z}^k \cdot f_{\text{decomp}}(\mathbf{h}_i^{(l)}) \right), \tag{10}
\]

where \( f_{\text{decomp}}(\mathbf{h}_i^{(l)}) \) denotes the decomposition function extracting spurious factors, modeled as a linear transformation \( f_{\text{decomp}}(\mathbf{h}_i) = \mathbf{W}_h^{(l)} \mathbf{h}_i^{(l)} \), and \( \mathbf{W}_k^{(l)} \) maps the environment representation \( \mathbf{z}^k \) to the same dimensionality as \( \mathbf{h}_{s, i}^{(l)} \). Integrating these components, the final model can be expressed as:

\[
\mathbf{X}^{(l+1)} = \sigma \left\{ \mathbf{W}_f^{(l)} \sum_{k=1}^{K} \left( [\mathbf{H}^{(l)} \odot \mathbf{z}^k] \cdot \pi_i^{k(l)} \right) \right\}, \tag{11}
\]

where \( \sigma \) represents the activation function.

% The CAPE framework integrates environment inference with temporal data processing to enhance epidemic forecasting. By decomposing representations into causal and spurious factors and modeling environment influences through a weighted sum of fixed environment representations, CAPE effectively adjusts for confounders without requiring explicit exogenous covariates. The combination of reversible normalization, patch-based processing, and self-attention mechanisms ensures robust performance against temporal distribution shifts, making CAPE a powerful tool for epidemic forecasting tasks.


\subsection{Pre-training Objectives for Epidemic Forecasting}
\label{sec: contrast}
To capture a wide range of dynamics from the epidemic time series pile, CAPE applies two self-supervised learning strategies for pre-training. 

% \noindent\textbf{Random Masking.} To learn the inherent characteristics from a large sum of unlabeled epidemic time series data, we employ a masked time series modeling task. Specifically, we randomly mask the input patches by zero values with a probability of $\gamma$\%. Then, at the end of the model, a linear layer is applied to the final embedding of each masked patch and transforms them back to the reconstructed time series. During training, MSE loss is applied to encourage the reconstructed data to be as close to the original data as possible. Though this process, the model is able to ...

\noindent\textbf{Random Masking.} \wei{this is the same as PEM?} To capture the inherent characteristics from a vast amount of unlabeled epidemic time series data, we employ a masked time series modeling task~\cite{kamarthi2023pems, goswami2024moment}. Specifically, we randomly mask input patches by setting them to zero with a probability of $\gamma \%$. Then, at the end of the model, a linear layer is applied to the final embeddings of each masked patch to reconstruct the original time series. During training, we utilize Mean Squared Error (MSE) loss to ensure that the reconstructed data closely matches the original input:

\[
\mathcal{L}_{recon} = \frac{1}{N}\sum_{i=1}^{N} MSE(\hat{\mathbf{x}_i}, \mathbf{x}_i) , \tag{12}
\]

where $\mathbf{x}_i$ is the $i$ the patch of the original time series and $\hat{\mathbf{x}_i}$ is the reconstructed time series patch given by the model.
Through this process, the model is able to learn robust representations by predicting the masked segments based on their surrounding context. This not only enhances the model's ability to understand temporal dependencies and patterns within the data but also improves its generalization capabilities when applied to unseen epidemic scenarios. 
% Additionally, the random masking strategy encourages the model to develop resilience against missing or incomplete data, which is common in real-world epidemic datasets.



\noindent\textbf{Hierarchical Environment Contrasting.} 
% To ensure robust and aligned representations of the same time steps under different contexts, we employ a hierarchical contrastive loss ~\cite{fraikin2023t, yue2022ts2vec}. Unlike the implementation in TS2Vec~\cite{yue2022ts2vec}, our approach computes both temporal and instance-wise contrastive losses for the final time series embeddings \( \mathbf{h} \) and the estimated environments \( \mathbf{E}^{(l)} \) in a patch-wise manner within each layer.
To ensure robust and aligned representations of the same time steps under different contexts, we employ a hierarchical contrastive loss on the estimated environment representations during pre-training, as shown in Figure~\ref{fig:CAPE}(b). The contrastive loss includes both the instance level and temporal level, which encourages the representations under different contexts to be similar or dissimilar.
% \textit{Instance-wise Contrastive Loss.} 
\textit{Instance-wise contrasting} treats patches from different time series samples (a total of $B$ samples) as negative pairs and encourages them to be encoded to be dissimilar~\cite{yue2022ts2vec}, as shown in the second term of Eq.~\ref{Eq: CL}. This term makes the estimated environments from different samples far from each other, yielding diverse environments.
% \textit{Temporal Contrastive Loss.}
\textit{Temporal contrasting} creates augmented samples with overlapping areas, as shown in the third term of Eq.~\ref{Eq: CL}. 
Since the environment is independent of the time series in our causal model and remains consistent throughout the sequence, the representations of the overlapping regions (a total of $\Omega$) are encouraged to be similar, even under varying contexts\cite{yue2022ts2vec}.
% Since the environment is not resulted from the time series and should remain the same at any position of the time series, Though under different contexts, the representations of the overlapped areas (a total of $\Omega$) are encouraged to be closer to each other~\cite{yue2022ts2vec}.
In our framework, the contrastive loss for both the final time series embeddings \( \mathbf{X}^{L} \) and the estimated environment representations $\mathbf{E}^{(l)} = g_{\phi}^{(l)}(\mathbf{H}^{(l)}, \mathbf{Z})$ are computed in a patch-wise manner. As an example, the contrastive loss for the estimated environments is shown below:

{
\small
\begin{align}
\label{Eq: CL}
\mathcal{L}_{\text{CL(j, i)}} &= - \mathbf{E}_{j,i} \cdot \mathbf{E'}_{j,i} \nonumber \\
&+ \log \left( \sum_{b\in B} \exp \left( \mathbf{E}_{j,i} \cdot \mathbf{E'}_{b,i} \right) + \mathbb{I}_{j \neq b} \exp \left( \mathbf{E}_{j,i} \cdot \mathbf{E}_{b,i} \right) \right) \nonumber \\
&+ \log \left( \sum_{t \in \Omega} \exp \left( \mathbf{E}_{j,i} \cdot \mathbf{E'}_{j,t} \right) + \mathbb{I}_{j \neq t} \exp \left( \mathbf{E}_{j,i} \cdot \mathbf{E}_{j,t} \right) \right)
\tag{13}
\end{align}
}

% \begin{equation}
% \tiny
% \mathcal{L}_{\text{temp}}^{(j, i)}(\mathbf{h}) = -\log \frac{\exp \left( \mathbf{h}_{j,i} \cdot \mathbf{h}'_{j,i} \right)}{\sum_{i' \in \Omega} \left( \exp \left( \mathbf{h}_{j,i} \cdot \mathbf{h}'_{j,i'} \right) + \mathbb{I}_{i \neq i'} \exp \left( \mathbf{h}_{j,i} \cdot \mathbf{h}_{j,i'} \right) \right)}. \tag{13}
% \end{equation}

% in each layer and the final time series representation are defined as \( \mathcal{L}_{\text{CL}(j, i)}(\mathbf{E}^{(l)}) \) and \( \mathcal{L}_{\text{CL}(j, i)}(\mathbf{X}^{(L)}) \). Therefore, the final loss function is given by:

Finally, combining the reconstruction loss and the contrastive loss, we have the final loss function for pre-training:

{\small
\begin{align}
\mathcal{L}_{final} &= \mathcal{L}_{recon}(\mathbf{X}, \mathbf{y})  \nonumber \\
&+ \alpha \{\mathcal{L}_{\text{CL}}(\mathbf{X}^{(L)}) + \mathcal{L}_{\text{CL}}(\mathbf{X}^{(L)})\} \nonumber \\
&+ \beta \{ 1/l \sum_l [\mathcal{L}_{\text{CL}}(\mathbf{E}^{(l)}) + \mathcal{L}_{\text{CL}}(\mathbf{E}^{(l)})] \}, \tag{14}
\end{align}
}

where $\alpha$ and $\beta$ are hyperparameters used to balance the contrastive loss for the time series and the estimated environments.


\subsection{Optimization}
\subsubsection{Optimization for Pre-Training}
% \wei{can you follow the Aditya's ICML'24 paper to write this section? I feel currently we are describing this procedure in a too straightforward way}

Simply optimizing the likelihood $p_\theta(\mathbf{y}|\mathbf{X})$ will mislead the time series model to capture the shortcut predictive relation between the history input $\mathbf{X}$ and the future predictions $\mathbf{y}$ ~\cite{wu2024graph}, which is why the environment $\mathbf{e}$ should be considered during optimization. However, we may not be able to directly acquire the environment representations due to limited external information. Therefore, we treat these environments as hidden variables and optimize them in a data-driven way. Since the environment affects the distribution of observed data via $p(\mathbf{X}, \mathbf{Y} |\mathbf{E}) = p (\mathbf{X} |\mathbf{E})p (\mathbf{Y} |\mathbf{X}, \mathbf{E})$, if we denote by $p(\mathbf{E})$ the distribution for the hidden training environments and minimize the empirical risk of training samples, the learning algorithm yields:

\begin{equation}
\small
\theta^* = \arg\min_\theta \mathbb{E}_{\mathbf{e} \sim p(E),\ (\mathbf{X}, \mathbf{y}) \sim p(\mathcal{Y}, \mathcal{X} \mid E=\mathbf{e})} \left[ \left\| \mathbf{y} - h_\psi(g_\theta(\mathbf{X})) \right\|^2 \right].  \tag{15}
\end{equation}

% Unlike previous approaches that learn the latent probability distribution of the environments by approximating the variational lower bound ~\cite{wu2024graph}, our method aims to acquire the maximum a posteriori (MAP) estimates of the environment representations using the Expectation-Maximization (EM) algorithm. This strategy does not assume a prior distribution of the environment representations. In addition, the idea of learning the explicit representations is somehow similar to optimizing a codebook~\cite{dong2023peco}, the key difference is that we use the learned representations to perform covariate adjustment instead of reconstructing the input.

% The parameters in CAPE come from mainly three parts: encoder, environment estimator, and learnable environment representations. Since the environment $\mathbf{Z}$ influences the generation of $\mathbf{X}$ as well as $\mathbf{y}$, as shown in the causal graph, we fix $\mathbf{Z}$ during the maximization step and optimize the encoder and the estimator's parameters only. Both supervised loss and contrastive loss are involved at this stage since the estimated environments need to be regularized, which is controlled by the environment estimator. During the expectation step, only the learnable environment representations are considered, and we hope to acquire the best representations that yield the lowest empirical risk. Moreover, to encourage diverse representations, we initialized $\mathbf{Z}$ orthogonally. A detailed learning process is described below.

Unlike previous methods that approximate the latent probability distribution of environments via variational lower bounds~\cite{wu2024graph}, our approach uses the Expectation-Maximization (EM) algorithm to obtain maximum a posteriori (MAP) estimates of environment representations without assuming a prior distribution. Although our strategy for learning explicit representations resembles codebook optimization~\cite{dong2023peco}, we use these representations for covariate adjustment instead of input reconstruction. Since $\mathbf{Z}$ influences both $\mathbf{X}$ and $\mathbf{y}$, we fix $\mathbf{Z}$ in the maximization step and optimize only the encoder and estimator using supervised and contrastive losses to regularize the estimated environments. During the expectation step, we update only the environment representations to minimize empirical risk. To encourage diversity, $\mathbf{Z}$ is initialized orthogonally.

\textbf{Expectation Step (E-Step):} We freeze the transformer encoder and environment estimator, then optimize only the learnable environment representations $\mathbf{Z}$. Setting hyperparameters $\alpha, \beta = 0$, we solve:
\begin{equation}
\mathbf{Z}^{t+1} = \underset{\mathbf{Z}}{\arg\min} \left[ \mathcal{L}_{\text{Task}}(\mathbf{X}, \mathbf{V}) \right]. \tag{16}
\end{equation}

\textbf{Maximization Step (M-Step):} We fix the updated environment variables $\mathbf{Z}^{t+1}$ and optimize the encoder and environment estimator by minimizing $\mathcal{L}_{\text{final}}$. Thus, the representation $g_\theta$ and task-specific head $h_\psi$ are updated as:
\begin{equation}
\theta^{t+1}, \psi^{t+1} = \underset{\theta, \psi}{\arg\min} \left[ \mathcal{L}_{\text{final}}(\mathbf{X}, \mathbf{V}, \mathbf{Z}^{t+1}) \right]. \tag{17}
\end{equation}

% Unlike previous approaches that learn the latent probability distribution of environments by approximating the variational lower bound~\cite{wu2024graph}, our method seeks maximum a posteriori (MAP) estimates of environment representations via the Expectation-Maximization (EM) algorithm, without assuming a prior over these representations. Although our approach to learning explicit representations resembles optimizing a codebook~\cite{dong2023peco}, we use the learned representations for covariate adjustment rather than input reconstruction. The parameters in CAPE comprise three components: an encoder, an environment estimator, and learnable environment representations. Because the environment $\mathbf{Z}$ influences both $\mathbf{X}$ and $\mathbf{y}$ (see the causal graph), we fix $\mathbf{Z}$ during the maximization step and optimize only the encoder and estimator parameters, leveraging both supervised and contrastive losses to regularize the estimated environments through the environment estimator. During the expectation step, only the learnable environment representations are updated to minimize empirical risk. Moreover, to encourage diversity among these representations, $\mathbf{Z}$ is initialized orthogonally.



% \textbf{Expectation Step:} In the E-Step, we infer the environment representations. Specifically, we freeze the transformer encoder and the environment estimator and optimize only the learnable environment representations \( \mathbf{Z} \). Additionally, we set the hyperparameters \( \alpha \), \( \beta \) to 0 at this step, yielding the following optimization function:

% \begin{equation}
% \mathbf{Z}^{t+1} = \underset{\mathbf{Z}}{\arg\min} \left[ \mathcal{L}_{\text{Task}}(\mathbf{X}, \mathbf{V}) \right]. \tag{16}
% \end{equation}

% \textbf{Maximization Step:} In the M-Step, we freeze the learnable environment variables \( \mathbf{Z}^{t+1} \) acquired from the last step and optimize the parameters of the encoder and the environment estimator by minimizing the final loss function $\mathcal{L}_{\text{final}}$. In the end, the final representation $g_\theta$ and the task-specific head $h_\psi$ are updated based on the current $Z^{t+1}$:

% \begin{equation}
% \theta^{t+1}, \psi^{t+1} = \underset{\theta, \psi}{\arg\min} \left[ \mathcal{L}_{\text{final}}(\mathbf{X}, \mathbf{V}, \mathbf{Z}^{t+1}) \right]. \tag{17}
% \end{equation}

To summarize, we repeatedly carry out the E-step and M-step, resulting in the inferred environment representations  $\mathbf{Z}$. The detailed pseudo-code for the optimization procedure is presented in Algorithm ~\ref{alg:hierarchical_contrastive_em}.



% \subsubsection{Representation Learning}

% \textbf{Self-supervised Learning.} We adopt reconstruction with random masking as our self-supervised learning method, as shown in Fig ~\ref{fig:CAPE} (c). The output embedding $x_i^{(L)}$ is transformed into the reconstruction of the original input patch $x_i$, denoted as $\hat{x_i}$. In this case, EM algorithm is applied during pre-training and we use the mean of each patch's MSE loss as our final loss: $\mathcal{L}_{Sup} = 1/N \sum_{i=0} MSE(\hat{x_i}, x_i)$.


% \textbf{Fine-tuning.} During fine-tuning on the downstream datasets, we fine-tune the whole model using the same EM algorithm. We replace the reconstruction head with a prediction head, which concatenates all the latent representations and maps the input to the prediction target $\hat{y}=W[x_1^{(L)}, x_2^{(L)}, ...]$: $\mathcal{L}_{Sup} = MSE(\hat{y}, y)$.



\subsubsection{Optimization for Downstream Tasks}

% \wei{not sure why we put the loss here; it should probably be merged with the contrastive learning section; in this section we focus on describing the optimiation for pre-training and finetuning. }
% \noindent\textbf{Self-supervised Learning.} For pre-training, we employ a self-supervised approach based on reconstruction with random masking, as illustrated in Figure ~\ref{fig:CAPE}(c). Given an input patch $\mathbf{x}_i$, its output embedding $\mathbf{x}_i^{(L)}$ is fed into a reconstruction head to produce $\hat{\mathbf{x}_i}$. EM Algorithm is applied during this process.
% We apply the EM algorithm during pre-training, and define the supervised loss as:
% $\mathcal{L}_{Sup} = \frac{1}{N}\sum_{i=1}^{N} MSE(\hat{\mathbf{x}_i}, \mathbf{x}_i).$

\noindent\textbf{Fine-tuning.} For downstream tasks, we fine-tune the entire model using MSE loss, still employing EM for optimization. The difference is that the reconstruction head is replaced by a prediction head that takes the concatenated latent representations $[\mathbf{x}_1^{(L)}, \mathbf{x}_2^{(L)}, \ldots ]$ and maps them to the future prediction:
$\hat{\mathbf{y}} = \mathbf{W}[\mathbf{x}_1^{(L)}, \mathbf{x}_2^{(L)}, \ldots]$.
% with the training objective:
% $\mathcal{L}_{Sup} = MSE(\hat{\mathbf{y}}, \mathbf{y})$.


\noindent\textbf{Zero-shot.} For zero-shot forecasting, the model remains frozen and no parameter is updated. Like the implementation from the Moment model ~\cite{goswami2024moment}, we retain the pre-trained reconstruction head and mask the last patch of the input to perform forecasting: $\hat{\mathbf{y}} = \hat{\mathbf{x}_n}$.
