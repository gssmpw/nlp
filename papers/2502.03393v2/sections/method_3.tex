\section{Proposed Method}
% We introduce the Covariate-Adjusted Pre-training framework for Epidemic forecasting (Figure~\ref{fig:CAPE}), which accounts for epidemic environmental changes in disease dynamics. 
% A framework overview is shown in Figure~\ref{fig:CAPE}. .

% Enhanced by components that capture temporal dependency and infer latent environment (section~\ref{sec: model}), CAPE aims to learn the intrinsic disease dynamics through pre-training (section~\ref{sec: contrast}).


\subsection{Model Design}
\label{sec: model}

\subsubsection{Causal Analysis for Epidemic Forecasting}
As environments influence both historical infection patterns and future disease spread, we draw inspiration from causal inference~\cite{zhou2023causal, jiao2024causal} and introduce a Structural Causal Model where we treat the environment $Z$ as a confounder that influences both the independent variable (e.g., historical data $X$) and the dependent variable (e.g., future infections $Y$). Furthermore, we adopt a causal decomposition approach~\cite{mao2022causal} that separates $X$ into two components (Figure~\ref{fig: causal_graph}): (1) a \textit{spurious} factor $X_s$ that is environment-dependent, and (2) a \textit{causal} factor $X_c$ that remains environment-independent. Both factors influence the target \( Y \), with \( X_s \) reflecting the impact of environment \( Z \). Since epidemic dynamics are driven by a finite set of critical factors, such as public health policies, we model \( Z \) with the following assumption:
\begin{assumption} \label{assumption} The environment variable $Z$ follows a categorical distribution $p(Z)$ and takes on one of $K$ discrete environmental states, denoted as $z_k$. Each state $z_k$ is associated with a unique latent representation $\mathbf{e}_k \in \mathbb{R}^{h_e}$, capturing the unique features specific to that environment.
\end{assumption}

In constructing a predictive model for input $\mathbf{x}$, we define \(\hat{Y}\) as the predicted time series \(\hat{\mathbf{y}}\) and model the predictive distribution \( p_\Theta(\hat{Y} | X) \) using \( f_\Theta(\mathbf{x}) = h_\psi(g_\theta(\mathbf{x})) \), where \( \Theta = \{\theta, \psi\} \). Training typically involves maximizing the log-likelihood of \( p_\Theta(\hat{Y} | X) \), which in practice translates to minimizing the errors over the pre-training dataset \( \mathcal{D}_\text{pre} \):
\vskip -7mm
\begin{equation}
\Theta^* = \arg\min_{\Theta} - \frac{1}{|\mathcal{D}_\text{pre}|} \sum\nolimits_{(\mathbf{x}, \mathbf{y}) \in \mathcal{D}_\text{pre}} \|\mathbf{y} - f_\Theta(\mathbf{x}))\|^2.
\end{equation}
\vskip -4mm
As the environment $Z$ impacts the distribution of the observed data through $p(X, Y | Z) = p(X | Z)p(Y | X, Z)$, we formulate the following objective:
% let \( p(Z) \) denote the distribution of environments and we have the following objective: 
\begin{equation}
\label{Eq: optim}
\small
\begin{split}
\Theta^* = & \arg\min\nolimits_{\Theta}  \mathbb{E}_{p(Z)} [ \mathbb{E}_{(\mathbf{x}, \mathbf{y}) \sim p(Y, X | Z)} [ \|\mathbf{y} - f_\Theta(\mathbf{x}))\|^2 ]  ].
\end{split}
\end{equation}
% \vskip -4mm
The above equation suggests that the optimal $\Theta^*$ depends on the environment distribution $p(Z)$. If we simply maximize the likelihood $p_\Theta(\hat{Y} |X)$, the confounding effect of $Z$ on $X$ and $Y$ will mislead the model to capture the shortcut predictive relation between the input and the target trajectories, which necessitates explicit modeling of the environment during pre-training. Given that input infection trajectories inherently reflect the influence of the environment, it is crucial to develop mechanisms that disentangle the correlations between infection trajectories and environmental factors.

In this study, we switch to optimize $p_\Theta(\hat{Y} | do(X))$, where the \textit{do}-operation intervenes the variable $X$ and removes the effects from other variables (i.e., $Z$ in our case), thus effectively isolating the disease dynamics from environmental influences. In practice, this operation is usually conducted via covariate adjustment, particularly \textit{backdoor adjustment}~\cite{suncaudits}, which controls for the confounder and uncovers the true causal effects of interest. The theoretical foundation for this is explained through: $p(Y | do(X)) = \int p(Y | X, Z=z) p(Z=z) dz$ (see Appendix~\ref{Appendix: theory}). Under Assumption~\ref{assumption}, this simplifies over different environmental states:
\begin{equation}
\label{Eq: do}
p(Y | do(X)) = \sum\nolimits_{Z} p(Y | X, Z=z) p(Z=z).  
\end{equation}
However, obtaining detailed environmental information, or ${\bf e}_k$, can be challenging due to variability in data availability and quality. To address this,  we resort to a data-driven approach that treats ${\bf e}_k$ as learnable parameters and thus allows us to dynamically infer the environmental distribution directly from the observed data. Specifically, we implement an environment estimator $q_\phi(Z|X)$ that infers the probability of environment states based on historical inputs together with the latent representations of each state. Then, we derive a variational lower bound (see Appendix~\ref{Appendix: theory}):
\begin{equation}
\label{Eq: lb}
\small
\begin{aligned}
&\log{p_\Theta(\hat{Y} | do(X))} \geq \\
& \mathbb{E}_{q_\phi(Z | X)} \left[ \log p_\Theta(\hat{Y} | X, Z) \right] - \operatorname{KL}\left(q_\phi(Z | X) \parallel p(Z)\right),
\end{aligned}
\end{equation}
where the first term maximizes the model's predictive power and the second term regularizes the environment estimator to output a distribution close to the prior distribution $p(Z)$.


\subsubsection{Model Instantiation}
% According to the analysis above, 
To instantiate and train a model that performs the covariate adjustment, we need to model the environment estimator $q_\phi(Z | X)$ and the predictor $p_\Theta(\hat{Y} | X, Z)$.

\textbf{Latent Environment Estimator $q_\phi(Z | X)$.} 
% We characterize \( p(Z|X) \) using a latent environment estimator \( q_\phi(Z|X) \). Given that the influence of each environment may vary across different times, we apply patching~\cite{nie2022time} to control for granularity in the environment estimation process. This approach ensures that the environment estimation avoids overly detailed estimations for specific time points and prevents overly broad approximations that could obscure important temporal fluctuations. Therefore, we split the input $\mathbf{x}$ into a number of $C$ non-overlapping patches $\mathbf{x} = [\mathbf{x}_1, \mathbf{x}_2, ... \mathbf{x}_C]$, where $\mathbf{x}_c \in \mathbb{R}^{\frac{T}{C}}$. Then, a self-attention layer $f_\text{enc}$ is employed to capture the temporal dependency between patches, yielding contextualized representation $\mathbf{h}^{(l)}_c=f_\text{enc}(\mathbf{x}^{(l)}_c)$ for the $i$-th patch at layer $l$. Subsequently, since the environment influences only the spurious component of the contextualized input $\mathbf{h}^{(l)}_c$, we introduce an additional transformation layer $\mathbf{W}_h^{(l)}$ to provide the estimator with the flexibility of highlighting the spurious component of $\mathbf{h}^{(l)}_c$. Finally, we model \( q_\phi(Z | X) \) as a cross-attention layer that models the interaction between each patch and the latent environment representations: 
We model \( p(Z|X) \) using a latent environment estimator \( q_\phi(Z|X) \). Since environmental influences vary over time, we apply patching~\cite{nie2022time} to manage granularity in environment estimation. This prevents overly specific or generalized estimations that could obscure key temporal fluctuations. We divide the input \( \mathbf{x} \) into \( C \) non-overlapping patches, \( \mathbf{x} = [\mathbf{x}_1, \dots, \mathbf{x}_C] \), where \( \mathbf{x}_c \in \mathbb{R}^{T/C} \). Then, a self-attention layer \( f_\text{enc} \) captures temporal dependencies between patches, producing contextualized representations \( \mathbf{h}^{(l)}_c = f_\text{enc}(\mathbf{x}^{(l)}_c) \) for each patch at layer \( l \). Subsequently, since the environment influences only the spurious component of the input, 
% \wei{why we can say $h_c$ captures the spurious component? there seems to be no intuition..}, 
we introduce a transformation $\mathbf{W}_s^{(l)}$ to capture the spurious component of $\mathbf{h}^{(l)}_c$. Finally, we model \( q_\phi(Z | X) \) as a cross-attention layer that captures the relation between each patch and the latent environment representations: 
% Since the environment affects only the spurious component of \( \mathbf{h}^{(l)}_c \), we introduce a transformation layer \( \mathbf{W}_h^{(l)} \) to emphasize this component. Finally, \( q_\phi(Z | X) \) is modeled as a cross-attention layer that captures interactions between each patch and the latent environment representations:
\begin{equation}
\label{eq: env_estimator}
\pi_{k, c}^{(l)} = \operatorname{Softmax} \left( (\mathbf{W}_k^{(l)} \mathbf{e}_k)^\top \cdot (\mathbf{W}_s^{(l)} \mathbf{h}_c^{(l)}) \right),
\end{equation}
where $\pi_{k, c}^{(l)}$ is the output probability of the environment $z_{k}$ for the $c$-th patch, and \( \mathbf{W}_k^{(l)} \) is a transformation layer for  \( \mathbf{e}_k \).
% that maps the environment representation \( \mathbf{e}_k \). 
Such operation not only takes into account the contextualized representation of the current time period, but also considers the latent environment representations, which made it possible to infer the densities of other environment distributions with different latent representations.

\textbf{Epidemic Predictor $p_\Theta(\hat{Y}|X,Z)$.} Unlike previous studies, which do not explicitly model environment states, we incorporate these states directly into the input using their latent representations $\mathbf{e}_k$. Specifically, {we model the predictor $p_\Theta(\hat{Y}|X,Z)$ by employing a weighted sum over the combined representations of each environment and the input using Hadamard product, i.e., $f_\text{enc}(\mathbf{x}_c^{(l)}) \odot \mathbf{e}_k$. Finally, we apply a feed-forward layer to compute the output representations, serving as the input for the next layer.} Integrating these components, the CAPE encoder can be expressed as:
\begin{equation}
\small
\label{Eq: model}
\mathbf{x}^{(l+1)}_{c}
= \sigma \left(
  \mathbf{W}_f^{(l)}
  \sum_{k=1}^{K}
    \pi_{k, c}^{(l)}
    % \cdot
    \left[
      f_{enc}({\mathbf{x}_c^{(l)}})
      \odot 
      \mathbf{e}_k
    \right]
\right),
\end{equation}
where \( \sigma \) represents the activation function and \( \mathbf{W}_f^{(l)} \) denotes the learnable parameters of the feedforward layer. Assuming $L$ layers are stacked, we acquire the final representation $\mathbf{x}^{(L)} = [\mathbf{x}^{(L)}_1, \mathbf{x}^{(L)}_2, \ldots \mathbf{x}^{(L)}_C] = g_\theta({\bf x}) \in \mathbb{R}^{C \cdot d}$ and apply a task-specific head to predict the target variable $\mathbf{y}=h_\psi(\mathbf{x}^{(L)})$, where $h_\psi$ is a linear transformation.

% between the latent environment representations $\mathbf{e}_k$ and the contextualized input \( \mathbf{h}_i^{(l)} \), i.e., $\mathbf{h}_i^{(l)} \odot \mathbf{e}_k$.} 
% \wei{think you missed describing the process of mixing/summation over K environments?}.

% \begin{equation}
% \label{Eq: model}
% \mathbf{X}^{(l+1)} 
% = \sigma \Bigl(
%   \mathbf{W}_f^{(l)}
%   \sum_{k=1}^{K}
%     \Bigl[
%       f_\text{enc}(\mathbf{X}^{(l)})
%       \;\odot\;
%       \underbrace{\bigl(\mathbf{e}_k \mathbf{1}^\top\bigr)}_{\in \mathbb{R}^{c \times d}}
%     \Bigr]
%     (\mathbf{\pi}_{k}^{(l)}\mathbf{1}^\top)
% \Bigr),
% \end{equation}

% \begin{equation}
% \small
% \label{Eq: model}
% \mathbf{X}^{(l+1)} 
% = \sigma \left(
%   \mathbf{W}_f^{(l)}
%   \sum_{k=1}^{K}
%     \underbrace{(\boldsymbol{\pi}_{k}^{(l)})^\top}_{\in \mathbb{R}^{1 \times c}} 
%     \cdot
%     \left[
%       f_{\text{enc}}(\mathbf{X}^{(l)}) 
%       \odot 
%       \underbrace{\left( \mathbf{e}_k \mathbf{1}^\top \right)}_{\in \mathbb{R}^{c \times d}}
%     \right]
% \right),
% \end{equation}



% \begin{equation}
% \small
% \label{Eq: model}
% \mathbf{h}^{(l+1)} = 
% \sigma\left( \operatorname{flatten}\left(
%   \mathbf{W}_f^{(l)}
%   \sum_{k=1}^{K}
%     {(\boldsymbol{\pi}_{k}^{(l)})^\top}
%     \cdot
%     \left[
%       f_{\text{enc}}(\mathbf{h}^{(l)}) 
%       \odot 
%       {\left( \mathbf{e}_k \mathbf{1}^\top \right)}
%     \right]
% \right)\right),
% \end{equation}


% This operation is defined as $\mathbf{x}_i^{(l+1)} = \sigma(\mathbf{W}_f^{(l)} \mathbf{m}_i^{(l)})$, where \( \sigma \) represents the activation function, and \( \mathbf{W}_f^{(l)} \) denotes the learnable parameters of the feedforward layer.



% \textbf{Integrating Environment Labels.} Unlike previous studies, we model the environment labels explicitly and integrate them into the input, which is similar to combining an encoded input from external knowledge~\cite{rombach2022high}. Specifically, we use a hadamard product to integrate the environment labels $\mathbf{z}^{k}$ into the contextualized input $h_i^{(l)}$, which is done in a layer-wise manner. Given $\mathbf{h}_i^{(l)}$ at the $l$ th layer, we model Eq.~\ref{Eq: 5} as follows:
% \begin{equation}
% \label{Eq: ca}
% \mathbf{m}_i^{(l)}  = \sum_{k=1}^{K} (\mathbf{h}_i^{(l)} \odot \mathbf{z}^k) \cdot p(\mathbf{z}^k | \mathbf{h}_i^{(l)}).
% \end{equation} 

% Finally, a feedforward neural network \( \mathbf{x}_i^{(l+1)} = \sigma(\mathbf{W}_f^{(l)} \mathbf{m}_i^{(l)}) \) is applied to acquire the output representations, which serves as the input for the next block. Integrating these components, the final model can be expressed as:


% \vspace{-3mm}
% \begin{equation}
% \mathbf{X}^{(l+1)} 
% = \sigma \Bigl(
%   \mathbf{W}_f^{(l)}
%   \sum_{k=1}^{K}
%     \Bigl[
%       \mathbf{H}^{(l)} 
%       \;\odot\;
%       \underbrace{\bigl(\mathbf{z}^k \mathbf{1}^\top\bigr)}_{\in \mathbb{R}^{d \times T}}
%     \Bigr]
%     \cdot
%     \pi^{k(l)}
% \Bigr),
% \end{equation}
% \vspace{-3mm}

% where \( \sigma \) represents the activation function. At the end of the model, we acquire the final representation $\mathbf{X^{(L)}} = g_\theta(\mathbf{X})$ and a task-specific head is applied to predict the target variable $\mathbf{y}=\mathbf{h}_\psi(\mathbf{X}^{(L)})$, where $h_\psi$ is a linear transformation.

% \wei{do not really see the connection between this and Eq.6. Feel free to use more sentences/space to make this clear. We can always shorten the content later. The notation $E_{IP}$ also looks heavy; something like $\hat{z}$ or $\bar{z}$ could be better} 
% \begin{equation} 
% \label{Eq: env_estimator}
% \mathbf{E}_{IP}^{(l)} = \sum_{k=1}^{K} \mathbf{e}_k \cdot q_\phi(Z=z_k | X_s). 
% \end{equation}
% where $\mathbf{E}_{IP}^{(l)}$ is the latent representation of the interpolation from the defined environment states $\mathbf{z}_k$. Thus, the weight $q_\phi(Z | X_s)$ can be interpreted as the contribution of each state involved in the given period $\mathbf{h}_i^{(l)}$. 

% While self-supervised learning tasks \( \mathcal{T}_{\text{pre}} \) transform the original input into a new input-label pair, prior studies have often neglected the confounding effects of environmental factors on these inputs and labels. This oversight hinders performance and limits the learning capacity of these tasks. To overcome this limitation, CAPE integrates environment estimation seamlessly into the self-supervised learning framework. % , enhancing its effectiveness and robustness.


% To capture a broad range of epidemic time series dynamics from the pre-training dataset, CAPE leverages self-supervised learning tasks to identify universal patterns inherent in the data. While supervised learning tasks \( \mathcal{T}_{\text{pre}} \) transform the original input \( \mathbf{X} \) into a pair of new input and labels, previous studies have overlooked the confounding effects of the environment on these inputs and labels. This oversight hinders performance and limits the learning capacity of these tasks. To address this, CAPE tightly incorporates environment estimation into self-supervised learning. 
% , improving the accuracy of both the self-supervised learning objectives and environment estimation.
% \wei{seems unclear about how the environment estimator helps with the reconstruction as it is not involved in the following loss?}
% During pre-training, the masked time series modeling task samples a batch of $B$ times series $\mathbf{X} \in \mathbb{R}^{B \times T}$ and transforms them into a pair of masked inputs and labels: $(\tilde{\mathbf{X}}, \mathbf{X})$. In this case, the original time series serves as the label $y$.
% Then, the reconstructed time series is acquired via $ \hat{\mathbf{X}} = h_{\phi}(g_\theta(\tilde{\mathbf{X})})$. In this study, MSE is used as the reconstruction loss to ensure that reconstructed data closely matches the original: 
% % $\mathcal{L}_{\text{recon}} = \frac{1}{B}\sum_{i=1}^{B} \text{MSE}_{\hat{Z}}(\hat{\mathbf{X}}_i, \mathbf{X}_i)$
% $\mathcal{L}_{\text{recon}} = \frac{1}{B} \sum_{i \in B}\text{MSE}_{\hat{Z}_i}(\hat{\mathbf{X}_i}, \mathbf{X}_i)$
% where \( \hat{\mathbf{X}_i} \) is the $i$-th sample's reconstruction under the inferred environment $\hat{Z}_i$. 
% \wei{we need to highlight a bit about our novelty here}
% \wei{to highlight the novelty, we typically need to point out the limitations of existing methods, like ``different from existing xxxx..''}
% both $\tilde{\mathbf{X}}$ and \( \mathbf{V} \)
% \wei{why we need to introduce $V$; seems you did not use the notation in the later content}.
% To capture a diverse range of epidemic time series dynamics, CAPE employs self-supervised learning tasks to uncover universal patterns inherent in the pre-training dataset. However, previous approaches often overlooked the confounding impact of environmental factors on input-label pairs defined in \( \mathcal{T}_{\text{pre}} \), which can impair task performance and learning potential. To address this, CAPE seamlessly incorporates environment estimation into its self-supervised learning framework through the following tasks.

% While $ q_\phi(Z|X) $ infers the environment across all patches for a given time series \( \mathbf{X} \) during random masking, the inferred environment for the same patch may vary when the context changes to \( \mathbf{X}' \). This variability arises because changes in context alter the latent representations $ \mathbf{h}^{(l)}_i $, causing the environment estimator to produce inconsistent results. However, such inconsistency is problematic as the environment should be context-invariant. To resolve this, we propose a hierarchical environment contrasting approach to align the estimated environments across different contexts. First, we define the environments to be aligned as \textit{aggregated latent environment representation} $\hat{\mathbf{e}}^{(l)}=\sum_{k=1}^{K}\mathbf{e}_k \pi_{k}^{(l)}$. Next, to ensure robust and contextually aligned representations of the unique aggregated environment within each patch $\mathbf{h}^{(l)}_i$, we designed a hierarchical environment contrastive loss for pre-training (Figure~\ref{fig:CAPE}(b)), in terms of both instance-level and temporal-level. \textit{Instance-wise contrasting} treats $\hat{\mathbf{e}}^{(l)}$ from different time series (a number of B samples) as negative pairs, encouraging dissimilar representations~\cite{yue2022ts2vec} and promoting diversity (second term of Eq.~\ref{Eq: CL}). \textit{Temporal contrasting} uses augmented samples with overlapping regions ($\Omega$) to maintain consistent environment estimation across sequences despite varying contexts~\cite{yue2022ts2vec} (third term of Eq.~\ref{Eq: CL}). In our framework, contrastive loss is computed patch-wise for both final time series embeddings \( \mathbf{X}^{L} \) and batch-wise aggregated environments \( \hat{\mathbf{E}}_{j,i}^{(l)}=\hat{\mathbf{e}}^{(l)}\), where $j$ denotes the sample index and $i$ denotes the patch index. An example of the contrastive loss for the sample $j$ at patch $i$ is shown below:
% \begin{equation}
% \label{Eq: CL}
% \small
% \begin{aligned}
% &\mathcal{L}_{\text{CL(j,i)}} = - \hat{\mathbf{E}}_{(j,i)} \cdot \hat{\mathbf{E}'}_{(j,i)}  \\
% &+ \log \left( \sum_{b\in B} \exp \left( \hat{\mathbf{E}}_{(j,i)} \cdot \hat{\mathbf{E}'}_{(b,i)} \right) + \mathbb{I}_{j \neq b} \exp \left( \hat{\mathbf{E}}_{(j,i)} \cdot \hat{\mathbf{E}}_{(b,i)} \right) \right) \\
% &+ \log \left( \sum_{t \in \Omega} \exp \left( \hat{\mathbf{E}}_{(j,i)} \cdot \hat{\mathbf{E}'}_{(j,t)} \right) + \mathbb{I}_{j \neq t} \exp \left( \hat{\mathbf{E}}_{(j,i)} \cdot \hat{\mathbf{E}}_{(j,t)} \right) \right).
% \end{aligned}
% \end{equation}
% the combination of contextualized representations and aggregated latent environments.



\subsection{Pre-training Objectives for Epidemic Forecasting}
\label{sec: contrast}
CAPE captures diverse epidemic time series dynamics through self-supervised learning tasks that identify universal patterns in the pre-training dataset. While previous studies neglected the confounding effects of environmental factors on input-label pairs in \( \mathcal{T}_{\text{pre}} \), CAPE seamlessly integrates environment estimation into the self-supervised framework.

{\noindent\textbf{Random Masking with Environment Estimation.} 
% To capture characteristics from large unlabeled epidemic time series data, we use a masked time series modeling task~\cite{kamarthi2023pems, goswami2024moment} (Figure~\ref{fig:CAPE}(c)), which randomly masks input patches by setting them to zero with a 30\% probability. Furthermore, as illustrated in Figure~\ref{fig: causal_graph}, the generation of \( X \) is inherently dependent on the corresponding environment. Consequently, accurately reconstructing a patch requires not only capturing temporal dependency from neighboring patches but also the dependency from its associated environment. Unlike previous research, which overlooked the role of the environment in the masked time series modeling task, we adopt the environment estimator \( q_\phi(Z | X) \) to infer the environment to help the reconstructions, which conversely help train the estimator}. During pre-training, the masked time series modeling task transforms $\mathbf{x}$ into a pair of masked input and label: $(\tilde{\mathbf{x}}, \mathbf{x})$. In this case, the original time series serves as the label $y$. Then, the reconstructed time series is acquired via $ \hat{\mathbf{x}} = h_{\psi}(g_\theta(\tilde{\mathbf{x}}))$. In this study, MSE is used as the reconstruction loss to ensure that reconstructed data closely matches the original:  $\mathcal{L}_{\text{recon}} = \sum_{\mathcal{D}'_{s} \in \mathcal{D}_{pre}} \sum_{\mathbf{x} \in \mathcal{D}'_{s}}  \text{MSE}(\hat{\mathbf{x}}, \mathbf{x})$,  where \( \hat{\mathbf{x}} \) is the reconstruction of the input $\mathbf{x}$.
% To capture characteristics from large unlabeled epidemic time series data, we employ a masked time series modeling task~\cite{kamarthi2023pems, goswami2024moment} (Figure~\ref{fig:CAPE}(c)), which masks input patches with a 30\% probability. As illustrated in Figure~\ref{fig: causal_graph}, the generation of \( X \) depends on the environment \( Z \). Therefore, accurately reconstructing a patch requires capturing both temporal dependencies and environmental influences. Unlike previous studies that overlooked the environment's role in masked modeling, we use an environment estimator \( q_\phi(Z | X) \) to infer \( Z \), aiding reconstruction and simultaneously training the estimator. During pre-training, the task transforms the input \( \mathbf{x} \) into masked input and label pairs \((\tilde{\mathbf{x}}, \mathbf{x})\), where the original time series serves as the label \( y \). The reconstructed time series is obtained via \( \hat{\mathbf{x}} = h_{\psi}(g_\theta(\tilde{\mathbf{x}})) \). We use Mean Squared Error (MSE) as the reconstruction loss to ensure that \( \hat{\mathbf{x}} \) closely matches \( \mathbf{x} \): $\mathcal{L}_{\text{recon}} = \sum_{\mathcal{D}'_{s} \in \mathcal{D}_{\text{pre}}} \sum_{\mathbf{x} \in \mathcal{D}'_{s}} \text{MSE}(\hat{\mathbf{x}}, \mathbf{x})$.
To capture features from large unlabeled epidemic time series data, we employ a masked time series modeling task~\cite{kamarthi2023pems, goswami2024moment} (Figure~\ref{fig:CAPE}(c)) that masks 30\% of input patches. As depicted in Figure~\ref{fig: causal_graph}, the generation of $X$ depends on the environment \( Z \), indicating that accurate patch reconstruction requires capturing both temporal and environmental dependencies. Unlike prior studies that overlook the environment's role, we utilize an environment estimator \( q_\phi(Z | X) \) to infer \( Z \), aiding both reconstruction and estimator training. During pre-training, input \( \mathbf{x} \) is transformed into masked input and label pairs \((\tilde{\mathbf{x}}, \mathbf{x})\), with the original time series serving as label \( y \). The reconstruction \( \hat{\mathbf{x}} = h_{\psi}(g_\theta(\tilde{\mathbf{x}})) \) is optimized using Mean Squared Error (MSE): 
% $\mathcal{L}_{\text{recon}}({\mathcal{D}_\text{pre}}) = \sum_{\mathcal{D}'_{s} \in \mathcal{D}_{\text{pre}}} \sum_{\mathbf{x} \in \mathcal{D}'_{s}} \text{MSE}(\hat{\mathbf{x}}, \mathbf{x})$.
$\mathcal{L}_{\text{recon}}(\mathbf{x}, \hat{\mathbf{x}}) = \text{MSE}(\hat{\mathbf{x}}, \mathbf{x})$.



\noindent\textbf{Hierarchical Environment Contrasting.}
% Although Eq.~\eqref{eq: env_estimator} estimates environments across all patches, the inferred environments for the same patch in two consecutive samples, can vary due to contextual changes from neighboring patches. These changes alter the latent representations, leading to inconsistent environment estimates. 
% Although Eq.~\eqref{eq: env_estimator} applies to all patches, 
Two consecutive time series samples, ${\bf x}$ and ${\bf x}'$, can include overlapping regions when divided into multiple patches. These overlapping patches, although identical, can exhibit contextual variations influenced by their different adjacent patches. As indicated by Eq.~\eqref{eq: env_estimator}, such variations can alter the latent patch-wise representations, leading to inconsistencies in the environmental estimates for the same patch across the samples.
% In Eq.~\eqref{eq: env_estimator}, the inferred environments for the same patch in consecutive samples, ${\bf x}$ and ${\bf x}'$, may differ due to overlapping regions. Since ${\bf x}$ and ${\bf x}'$ are sequential samples divided into multiple patches, they share overlapping patches. However, slight variations in the context of these overlapping areas, influenced by adjacent patches, can modify the latent representations. This leads to variations in the environmental estimates for the same patch across the two samples.
To ensure that each patch's environment remains \textit{context-invariant}, we propose a hierarchical environment contrasting scheme inspired by \citet{yue2022ts2vec}. We define an \textit{aggregated latent environment representation} \( \hat{\mathbf{e}}^{(l)}_c = \sum_{k=1}^{K} \mathbf{e}_k \pi_{k, c}^{(l)} \) to represent the weighted environment states for the \( c \)-th patch. For contrastive loss computation, we use the combined representation \( \hat{\mathbf{E}}_{j,c}^{(l)} = \sigma(\mathbf{W}_f^{(l)} (\hat{\mathbf{e}}^{(l)}_c \odot \mathbf{h}^{(l)}_c)) \) for $c$-th patch of sample $j$. Additionally, \( \hat{\mathbf{E}'}_{j,c}^{(l)} \) denotes the representation in the context of \( \mathbf{x}' \). Finally, we compute a patch-wise contrastive loss:
% While Eq.~\eqref{eq: env_estimator} is designed to estimate the environments across all patches, the inferred environments for the same patch appearing in consecutive samples can differ due to context changes, specifically from neighboring patches. These changes in context affect the latent representations and cause the environment estimator to produce inconsistent results for the same patch. Since the environment for the same patch should be \textit{context-invariant}, we draw inspiration from \citet{yue2022ts2vec} and propose a hierarchical environment contrasting scheme to ensure consistency across different contexts. In our framework, we define a \textit{aggregated latent environment representation} $\hat{\mathbf{e}}^{(l)}_c=\sum_{k=1}^{K}\mathbf{e}_k \pi_{k, c}^{(l)}$ to stand for the weighted environment states for the $c$-th patch. To compute contrast loss, we use a combined representation for the $c$-th patch of $j$ sample: $\hat{\mathbf{E}}_{j,c}^{(l)}=\hat{\mathbf{e}}^{(l)}_c \odot \mathbf{h}^{(l)}_c$, where $\hat{\mathbf{e}}^{(l)}_c$ is the aggregated latent environment representation and $\mathbf{h}^{(l)}_c$ is the contextualized input for patch $c$. While $\hat{\mathbf{E}}_{j,c}^{(l)}$ is computed in the context of $\mathbf{x}$, we use $\hat{\mathbf{E}'}_{j,c}^{(l)}$ to denote the representation computed in the context of $\mathbf{x}'$. Finally, a patch-wise contrastive loss is computed:
% While Eq.~\eqref{eq: env_estimator} is designed to estimate the environments across all patches, the inferred environments for the same patch appearing in consecutive samples can differ due to context changes, specifically from neighboring patches. These changes in context affect the latent representations and cause the environment estimator to produce inconsistent results for the same patch. Since the environment for the same patch should be \textit{context-invariant}, we draw inspiration from \citet{yue2022ts2vec} and propose a hierarchical environment contrasting scheme to ensure consistency across different contexts. In our framework, we define a \textit{aggregated latent environment representation} $\hat{\mathbf{e}}^{(l)}_c=\sum_{k=1}^{K}\mathbf{e}_k \pi_{k, c}^{(l)}$ \wei{to stand for xxx for $c$-th patch }. To compute contrast loss, we use a combined representation for the $c$-th patch of $j$ sample: $\hat{\mathbf{E}}_{j,c}^{(l)}=\hat{\mathbf{e}}^{(l)}_c \odot \mathbf{h}^{(l)}_c$, where $\hat{\mathbf{e}}^{(l)}_c$ is the aggregated latent environment representation and $\mathbf{h}^{(l)}_c$ is the contextualized input for patch $c$. While $\hat{\mathbf{E}}_{j,c}^{(l)}$ is computed in the context of $\mathbf{x}$, we use $\hat{\mathbf{E}'}_{j,c}^{(l)}$ to denote the representation computed in the context of $\mathbf{x}'$. Finally, a patch-wise contrastive loss is computed:
{\small
\begin{equation}
\label{Eq: CL}
\begin{aligned}
&\mathcal{L}_{\text{CL}}(j,c) = - \hat{\mathbf{E}}_{(j,c)} \cdot \hat{\mathbf{E}'}_{(j,c)}  \\
&+ \log \left( \sum_{b\in B} \exp \left( \hat{\mathbf{E}}_{(j,c)} \cdot \hat{\mathbf{E}'}_{(b,c)} \right) + \mathbb{I}_{j \neq b} \exp \left( \hat{\mathbf{E}}_{(j,c)} \cdot \hat{\mathbf{E}}_{(b,c)} \right) \right) \\
&+ \log \left( \sum_{t \in \Omega} \exp \left( \hat{\mathbf{E}}_{(j,c)} \cdot \hat{\mathbf{E}'}_{(j,t)} \right) + \mathbb{I}_{c \neq t} \exp \left( \hat{\mathbf{E}}_{(j,c)} \cdot \hat{\mathbf{E}}_{(j,t)} \right) \right). \nonumber
\end{aligned} 
\end{equation}}where $B$ is the batch size, $\Omega$ denotes the overlapping patches, and $\mathbb{I}$ is the indicator function.
The above equation contains three key terms: (1) The first term encourages the representations of the same patch from two different contexts to be similar, which preserves the context-invariant nature of environments. (2) The second term (\textit{Instance-wise Contrasting}) treats $\hat{\mathbf{e}}^{(l)}_c$ from different samples in the batch as negative pairs, which promotes dissimilar representations, and enhances diversity among instances. (3) The third term (\textit{Temporal Contrasting}) treats the representations of different patches from overlapping regions ($\Omega$) as negative pairs, which encourages differences across temporal contexts.
% First, we define the environments to be aligned as \textit{aggregated latent environment representation} $\hat{\mathbf{e}}^{(l)}_c=\sum_{k=1}^{K}\mathbf{e}_k \pi_{k, c}^{(l)}$. 
% Next, to ensure robust and contextually aligned representations of both the contextualized representation $\mathbf{h}^{(l)}_c$ as well as the aggregated environment within each patch, we employ a hierarchical environment contrastive loss for pre-training (Figure~\ref{fig:CAPE}(b)), in terms of both instance-level and temporal-level. 
% \zw{While the first term aims to encourage the representation of the same patch from two different contexts to be similar,  \textit{Temporal contrasting} (the third term of Eq.~\eqref{Eq: CL}) treats the representations of different patches from the overlapping regions ($\Omega$) as negative pairs and encourages dissimilarity between them. Furthermore, \textit{Instance-wise contrasting} (the second term of Eq.~\eqref{Eq: CL}) treats $\hat{\mathbf{e}}^{(l)}_c$ from different time series within the same batch as negative pairs, which aims to encourage dissimilar representations and promoting diversity. }
% Aiming to preserve the context-invariant nature of environments, the first term encourages the representation of the same patch from two different contexts to be similar. As the contrast of the first term, we aim to push the representations of other patches far away, which results in two levels of contrast.
% \textit{(1)Instance-wise Contrasting:} The second term treats $\hat{\mathbf{e}}^{(l)}_c$ from different time series within the same batch as negative pairs. This promotes dissimilar representations, thereby enhancing diversity among instances.
% \textit{(2)Temporal Contrasting:} The third term of Equation~\eqref{Eq: CL} treats the representations of different patches from overlapping regions ($\Omega$) as negative pairs. This encourages dissimilarity between them, specifically enforcing differences across temporal contexts.
% \wei{which contains three key terms: (1) the first term xxx similarity promoting? xxx, (2) the second term instance contrasting  (3) the third term xxx}
% The first encourages representations of the same patch across different contexts to be similar, preserving the context-invariant nature of environments; The second(\textit{Instance Contrasting}) treats $\hat{\mathbf{e}}^{(l)}_c$ from different batch samples as negative pairs, promoting dissimilarity and enhancing instance diversity; The third(\textit{Temporal Contrasting}) treats representations of different patches from overlapping regions ($\Omega$) as negative pairs, encouraging differences across temporal contexts.
% \wei{the way you are using the indcator function is not correct. do you mean $\mathbb{I}_{c \neq t}(\cdot)$?} \wei{you mentioned $\Omega$ is the overlapping region later in this paragraph?}



% To preserve the context-invariant nature of environments, the first term encourages the representations of the same patch from two different contexts to be similar. In contrast, we aim to push the representations of other patches apart, resulting in two distinct levels of contrast.
% \textit{(1)Instance-wise Contrasting:} The second term of Equation~\eqref{Eq: CL} treats $\hat{\mathbf{e}}^{(l)}_c$ from different samples in the batch as negative pairs, which promotes dissimilar representations, and enhances diversity among instances.
% \textit{(2)Temporal Contrasting:} The third term of Equation~\eqref{Eq: CL} treats the representations of different patches from overlapping regions ($\Omega$) as negative pairs, which encourages dissimilarity between them, specifically enforcing differences across temporal contexts.



% we use augmented samples with overlapping regions ($\Omega$) to maintain consistent environment estimation across sequences despite varying contexts, i.e., the third term of Eq.~\eqref{Eq: CL}. 


\textbf{Pre-Training Loss.} Given a batch of $B$ samples $\mathbf{X} \in \mathbb{R}^{B \times T}$, we combine the reconstruction loss and the contrastive loss, yielding the final loss function for pre-training: 
% \wei{$\hat{X}$ undefined}
% \wei{in this pre-training loss can we utilize the notation of $\mathcal{D}_\text{pre}$?}
% \begin{equation}
% \begin{aligned}
% \mathcal{L}_{final} &= \mathcal{L}_{recon}(\mathbf{X}, \hat{\mathbf{X}})  + \alpha  \mathcal{L}_{\text{CL}}(\hat{\mathbf{E}}^{(L)}) 
% % &+ \beta [ 1/L \sum_l \mathcal{L}_{\text{CL}}(\hat{\mathbf{E}}^{(l)}) ],
% \end{aligned}
% \end{equation}
% \mathcal{D}_\text{pre}
% \begin{equation}
% \mathcal{L}_{\text{final}}(\mathbf{X} \sim \mathcal{D}_\text{pre}) = \mathcal{L}_{\text{recon}}(\mathbf{X}, \hat{\mathbf{X}}) + \alpha \, \mathcal{L}_{\text{CL}}(\hat{\mathbf{E}}^{(L)}),
% \end{equation}
{\small
\begin{equation}
\mathcal{L}_{\text{final}} = \sum\nolimits_{\mathbf{x} \in \mathbf{X}}\mathcal{L}_{\text{recon}}(\mathbf{x}, \hat{\mathbf{x}}) + \alpha \, \mathcal{L}_{\text{CL}}(\hat{\mathbf{E}}^{(L)}, \hat{\mathbf{E}}'^{(L)}), \; \mathbf{X} \sim \mathcal{D}_\text{pre}  \nonumber
\end{equation}}where $L$ is the number of layers, and $\alpha$ is the hyperparameter used to balance the contrastive loss and the reconstruction loss. Further analysis can be found in Appendix~\ref{Appendix: hp}.


\subsection{Optimization of the CAPE Framework}
% \subsubsection{Optimization for Pre-Training}
\label{sec: EM}
% \wei{can we replace this work with time series related works or works from general domain? this one looks too specific on graphs}
% \wei{what do we mean by "the specific meaning of the distribution"}
%\wei{check if my edits are correct} To maximize the variational lower bound, previous research~\cite{suncaudits}  often assumes a prior distribution for $p(Z)$ and overlook the modeling of the distribution of environmental states. In this study, we propose to use the \textit{Expectation-Maximization} (EM) algorithm to iteratively learn latent environment representations and {maximize the variational lower bound}. 

To effectively maximize the variational lower bound in Eq.~\eqref{Eq: lb}, we employ the \textit{Expectation-Maximization} (EM) algorithm to iteratively update the latent environments and epidemic predictor. The pseudo algorithm for the optimization procedure is provided in Appendix~\ref{Append_B}. 

% Furthermore, we propose the following two theorems for the optimization objectives. \wei{$\mathbf{E}$ is not defined before}

\textbf{E-Step: Estimating Latent Environments.} In the E-step, we aim to identify the environment states \( Z \) and the corresponding distribution \( p(Z) \) that result in the target distribution $p(Y)$. This involves maximizing the expected likelihood of $p(Y | Z)$ given $p(Z)$. We freeze the epidemic predictor $p_\Theta(\hat{Y}|X,Z)$ and the environment estimator $q_\phi(Z|X)$, treating them as oracles, which means $p_\Theta(\hat{Y}|X,Z) = p(Y|X,Z)$ and $q_\phi(Z|X)=q(Z|X)$. While actively updating the environment representations $\mathbf{E}=[\mathbf{e}_1, \mathbf{e}_2, ... \mathbf{e}_k]$, the optimization of the environment states $Z$ is learned through maximizing $\mathbb{E}_{p(Z)} [p(Y|Z)] = \mathbb{E}_{p(X)} [\mathbb{E}_{q_\phi(Z|X)} p_\Theta(Y|X, Z)]$, which is equivalent to minimizing the expected reconstruction loss: 
\begin{equation}
\mathbf{E}^{t+1} \leftarrow \arg\min\nolimits_{\mathbf{E}} \left[  \mathbb{E}_{\mathbf{x} \sim p(X)} [\mathcal{L}_{\text{recon}}(\mathbf{x}, \hat{\mathbf{x}})] \right].
\end{equation}
We use subscript \( t \) to denote the pre-update distribution  and derive the updated distribution $p^{t+1}(Z)$ as $q^{t+1}_{\phi_t}(Z)$, along with the updated environment representations \( \mathbf{E}^{t+1} \).

% \begin{theorem}
% \label{theorem: e}
% The optimization of the environment states $Z$ is learned through maximizing $\mathbb{E}_{p(Z)} [p(Y|Z)] = \mathbb{E}_{p(X)} [\mathbb{E}_{q_\phi(Z|X=\mathbf{x})} p_\Theta(Y|X=\mathbf{x}, Z=z)] $, which is equivalent to minimizing the expected reconstruction loss: 
% % \wei{do not really understand what this $\leftrightarrow$ means}
% \begin{equation}
% \mathbf{E}^{t+1} = \arg\min\nolimits_{\mathbf{E}} \left[  \mathbb{E}_{\mathbf{x} \sim p(X)} [\mathcal{L}_{\text{recon}}(\mathbf{x}, \hat{\mathbf{x}})] \right].
% \end{equation}
% \end{theorem}
% A detailed proof can be found in Appendix~\ref{Appendix: theory}. {Theorem~\ref{theorem: e} aligns the observed outcomes $Y$ with the corresponding environment states $Z$ in a data-driven way and bridges the gap between the objective with a specific loss function.} 
% We represent the pre-update distribution or parameter with a script \( t \) and obtain the updated distribution \( p^{t+1}(Z) = q^{t+1}_{\phi_t}(Z) \), along with the associated environment representations \( \mathbf{E}^{t+1} \).
% \wei{we need to explain the meaning of t}

\textbf{M-Step: Optimizing Epidemic Predictor.} In the M-step, we aim to optimize the epidemic predictor by maximizing its predictive power and regularizing the environment distribution. During this step, the environment representations $\mathbf{E}^{t+1}$ are held fixed. We have the following theorem:
\begin{theorem}
\label{theorem: m}
Assuming $q^{t+1}_{\phi_{t}}(Z)=p^{t+1}(Z)$ and an L2 norm is applied on $\phi$, the variational lower bound in Eq.~\eqref{Eq: lb} can be approximated as follows:
\begin{equation}
\label{Eq: alb}
\mathbb{E}_{p(X)} \left[ \mathbb{E}_{q^{t+1}_{\phi_{t}}(Z | X)}  \left[ \log p^{t+1}_{\Theta_{t+1}}(\hat{Y} | X, Z) \right]\right] - C,
\end{equation}
which is equivalent to minimizing the expected reconstruction loss $\mathbb{E}_{\mathbf{x}\sim p(X)}[\mathcal{L}_{recon}(\mathbf{x}, \hat{\mathbf{x}})]$ .
% \wei{$\mathbb{E}_{\mathbf{X}\sim p(X)}[\mathcal{L}_{recon}(\mathbf{X}, \hat{\mathbf{X}})]$ ?}.
% \wei{we can remove the constant here by saying "maximizing the xxx can be approximated as minimizing xxx"}
\end{theorem}
% \wei{we provide the proof in xxx.} \wei{transition from the above theorem to the following paragraph..}
The detailed proof can be found in Appendix~\ref{Appendix: theory}. Theorem~\ref{theorem: m} indicates that the optimization of the model's predictive ability can be approximated by Eq.~\eqref{Eq: alb}, which corresponds to the expectation of $\mathcal{L}_{recon}$. To further enhance robustness, the contrastive loss is combined to regularize the environment estimator. Therefore, the overall optimization objective becomes minimizing the final pre-training loss:
\begin{equation}
\Theta_{t+1} \leftarrow \arg\min\nolimits_{\Theta} \left[ \mathcal{L}_{\text{final}}(\mathbf{X}, \hat{\mathbf{X}}, \mathbf{E}^{t+1}) \right].
\end{equation}


% In conclusion, our approach optimizes both the environment, encompassing its states and distribution, and the model’s predictive capabilities using an \textit{EM} scheme.  The detailed pseudo-code for the optimization procedure is provided in Appendix~\ref{Append_B}. 
% while additional theoretical analysis is presented in Appendix~\ref{Appendix: theory}.




% \textbf{Expectation Step (E-Step):} 
% In the E-step, we aim to identify the set of environment states \( Z \) and the corresponding distribution \( p(Z) \) that is most relevant to the prediction target $Y$. This means maximizing the $p(\hat{Y})$, which is equal to maximizing the expectation of the predictor's output over the sample distribution $p(X)$:
% \begin{equation}
% \small
% \begin{aligned}
%     p(\hat{Y}) = \mathbb{E}_{p(X)}[ \mathbb{E}_{q_{\phi(Z|X_s)}} [p_\Theta(\hat{Y}|X,Z)] ]
% \end{aligned}
% \end{equation}
% In the case of pre-training, since $q_\phi(Z|X)$ is frozen, there is no need to apply contrastive learning and the optimization objective becomes minimizing the reconstruction loss: 
% % \wei{why here we optimize $L_{recon}$ but eq. 12 optimizes $L_{final}$}
% \begin{equation}
% Z^{t+1} \leftrightarrow \mathbf{E}^{t+1} = \underset{\mathbf{E}}{\arg\min} \left[ \mathcal{L}_{\text{recon}}(\mathbf{X}, \hat{\mathbf{X}}) \right].
% \end{equation}
% After E-step, we acquire a new distribution $p(Z^{t+1})=q^t_\phi(Z^{t+1})$ with the corresponding environment representations $\mathbf{E}^{t+1}$.

% \textbf{Maximization Step (M-Step):} During the M-step, we update the epidemic predictor $p^t_\Theta$ and environment estimator $q^t_\phi$ to maximize the variational lower bound. By combining minibatch training and applying a L2 norm on the estimator $q_\phi$, we are able to rewrite the Eq.~\eqref{Eq: lb} and produce an \textit{approximated variational lower bound} (see Appendix~\ref{Appendix: theory}) as:
% \begin{equation}
% \small
% \begin{aligned}
% \mathbb{E}_{p(X)} \left[ \mathbb{E}_{q^{t}_\phi(Z^{t+1} | X_s)}  \left[ \log p^{t+1}_\Theta(\hat{Y} | X, Z^{t+1}) \right]\right] - I_{\phi^{t}}(Z; X),
% \end{aligned}
% \end{equation}
% % \wei{why Eq.4 can be written as Eq. 11??}
% where \( I_{\phi^{t}}(Z; X) \) represents the mutual information between \( X \) and \( Z \), treated as a constant under the distribution defined by \( q_{\phi^{t}} \). As a result, we focus solely on optimizing the first term of the equation, which corresponds to minimizing the reconstruction loss. To further enhance robustness, the contrastive loss is added to regularize the environment estimator. The overall optimization objective simplifies to minimizing the final pre-training loss:
% \begin{equation}
% \Theta^{t+1} = \underset{\Theta}{\arg\min} \left[ \mathcal{L}_{\text{final}}(\mathbf{X}, \hat{\mathbf{X}}, \mathbf{E}^{t+1}) \right].
% \end{equation}
% \wei{do we have to mention this work (Dong) here? I feel not many people will think of this work because it is not about time series and it is not super famous; mentioning it here introduces additional questions/confusions} 
% Although our strategy for learning explicit representations resembles a soft version of neural discrete representation learning~\cite{dong2023peco}, we use these representations for covariate adjustment instead of input reconstruction. 
% In conclusion, our approach optimizes both the environment, encompassing its states and distribution, and the model’s predictive capabilities using an \textit{EM} scheme. The detailed pseudo-code for the optimization procedure is provided in Appendix~\ref{Append_B}, while additional theoretical analysis is presented in Appendix~\ref{Appendix: theory}.

% \wei{it is nice that we theorem 7.1 but think we did not connect the theorem well with our proposed framework. Can you put the theorom in the main content as well?}


% Simply optimizing the likelihood $p_\theta(\mathbf{y}|\mathbf{X})$ will mislead the time series model to capture the shortcut predictive relation between the history input $\mathbf{X}$ and the future predictions $\mathbf{y}$~\cite{wu2024graph}, which is why the environment should be considered during optimization:


% \begin{equation}
% \small
% \theta^* = \arg\min_\theta \mathbb{E}_{\mathbf{e} \sim p(E),\ (\mathbf{X}, \mathbf{y}) \sim p(\mathcal{Y}, \mathcal{X} | E=\mathbf{e})} \left[ \left\| \mathbf{y} - h_\psi(g_\theta(\mathbf{X})) \right\|^2 \right]. 
% \end{equation}

% However, we may not be able to directly acquire the environment representations without external materials and the corresponding encoder. To address this, we treat these environments as hidden variables and optimize them in a data-driven way. Unlike previous methods that approximate the latent probability distribution of environments via variational lower bounds~\cite{wu2024graph}, our approach uses the Expectation-Maximization (EM) algorithm to obtain maximum a posteriori (MAP) estimates of environment representations:

% \textbf{Expectation Step (E-Step):} We freeze the transformer encoder and environment estimator, then optimize only the learnable environment representations $\mathbf{Z}$. Setting hyperparameters $\alpha, \beta = 0$, we solve:
% \begin{equation}
% \mathbf{Z}^{t+1} = \underset{\mathbf{Z}}{\arg\min} \left[ \mathcal{L}_{\text{recon}}(\mathbf{X}, \mathbf{V}) \right].
% \end{equation}
% \vspace{-3mm}

% \textbf{Maximization Step (M-Step):} We fix the updated environment variables $\mathbf{Z}^{t+1}$ and optimize the encoder and environment estimator by minimizing $\mathcal{L}_{\text{final}}$. Thus, the representation $g_\theta$ and task-specific head $h_\psi$ are updated as:
% \begin{equation}
% \theta^{t+1}, \psi^{t+1} = \underset{\theta, \psi}{\arg\min} \left[ \mathcal{L}_{\text{final}}(\mathbf{X}, \mathbf{V}, \mathbf{Z}^{t+1}) \right].
% \end{equation}
% \vspace{-3mm}

% Although our strategy for learning explicit representations resembles codebook optimization~\cite{dong2023peco}, we use these representations for covariate adjustment instead of input reconstruction. The detailed pseudo-code for the optimization procedure is presented in Appendix~\ref{Append_B}.



