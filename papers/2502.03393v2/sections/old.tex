
% \begin{table*}[t]
%     \centering
%     \caption{Univariate forecasting results with horizons ranging from 1 to 16 future steps. The lookback window length is set to 36 and all models are evaluated using MSE. \textit{Note: \cellcolor{low1}{\color{red} Best},  \cellcolor{low2}{\color{green} Second Best}, \cellcolor{low3}{\color{yellow} Third Best}}. 
%     % \wei{for the first column, you can break the dataset name using multiple rows, which will make the table more compact} \wei{For table captions, we only capitalize the first letter in the first word.}
%     }
%     \label{tab: baselines}
%     \small
%     \resizebox{.9\textwidth}{!}{%
%     \begin{tabular}{ll*{12}{c}}
%         \toprule
%         \textbf{Dataset} & \textbf{Horizon} & \textbf{ARIMA} & \textbf{LSTM} & \textbf{GRU} & \textbf{Dlinear} & \textbf{Informer} & \textbf{Autoformer} & \textbf{Fedformer} & \textbf{PEM} & \textbf{Moment} & \textbf{PatchTST} & \textbf{CARL} \\
%         \midrule
%         \multirow{6}{*}{ILI USA} 
%             & 1  & \cellcolor{low1}0.138 & 0.338 & 0.259 & 0.220 & \cellcolor{low3}0.175 & 0.457 & 0.368 & 0.179 & 0.269 & 0.195 & \cellcolor{low2}0.155 \\
%             & 2  & \cellcolor{low2}0.203 & 0.377 & 0.301 & 0.247 & 0.370 & 0.710 & 0.380 & \cellcolor{low3}0.226 & 0.321 & 0.264 & \cellcolor{low1}0.200 \\
%             & 4  & \cellcolor{low3}0.354 & 0.458 & 0.386 & 0.376 & 0.517 & 0.670 & 0.433 & \cellcolor{low2}0.304 & 0.397 & 0.385 & \cellcolor{low1}0.270 \\
%             & 8  & 0.701 & 0.579 & 0.529 & \cellcolor{low2}0.506 & 0.597 & 0.842 & 0.570 & 0.538 & \cellcolor{low3}0.510 & 0.535 & \cellcolor{low1}0.404 \\
%             & 16 & 1.121 & 0.691 & 0.626 & 0.617 & 0.812 & 0.835 & 0.701 & \cellcolor{low3}0.570 & 0.610 & \cellcolor{low1}0.485 & \cellcolor{low2}0.516 \\
%             & \textbf{Avg} & 0.503 & 0.489 & 0.420 & \cellcolor{low3}0.393 & 0.494 & 0.703 & 0.490 & \cellcolor{low2}0.363 & 0.421 & 0.373 & \cellcolor{low1}\textbf{\underline{0.309}} \\
            
%         \midrule
%         \multirow{6}{*}{ILI Japan} 
%             & 1  & \cellcolor{low3}0.358 & 1.426 & 1.213 & 1.016 & 0.405 & 0.515 & 0.525 & 0.470 & \cellcolor{low2}0.325 & 0.413 & \cellcolor{low1}0.290 \\
%             & 2  & 0.772 & 1.635 & 1.458 & 1.294 & \cellcolor{low3}0.666 & 0.855 & 1.151 & 0.755 & \cellcolor{low2}0.586 & 0.698 & \cellcolor{low1}0.535 \\
%             & 4  & 1.720 & 1.975 & 1.870 & 1.758 & 1.234 & \cellcolor{low3}1.150 & 1.455 & 1.207 & \cellcolor{low2}1.082 & 1.147 & \cellcolor{low1}0.944 \\
%             & 8  & 2.981 & 2.373 & 2.365 & 2.285 & \cellcolor{low2}1.688 & 1.866 & 2.012 & 1.810 & \cellcolor{low3}1.706 & 1.708 & \cellcolor{low1}1.65 \\
%             & 16 & 2.572 & 2.023 & 2.010 & 2.007 & \cellcolor{low1}1.551 & 2.654 & 4.027 & \cellcolor{low3}1.766 & 2.054 & \cellcolor{low2}1.688 & 1.911 \\
%             & \textbf{Avg} & 1.680 & 1.886 & 1.783 & 1.672 & \cellcolor{low2}1.109 & 1.408 & 1.834 & 1.202 & 1.151 & \cellcolor{low3}1.131 & \cellcolor{low1}\textbf{\underline{1.066}} \\
%         \midrule
%         \multirow{6}{*}{Measles} 
%             & 1  & \cellcolor{low2}0.071 & 0.182 & 0.143 & 0.133 & \cellcolor{low1}0.066 & 0.203 & 0.321 & 0.085 & 0.113 & 0.094 & \cellcolor{low3}0.083 \\
%             & 2  & \cellcolor{low2}0.120 & 0.223 & 0.176 & 0.184 & 0.153 & 0.257 & 0.817 & 0.128 & 0.138 & \cellcolor{low3}0.127 & \cellcolor{low1}0.112 \\
%             & 4  & 0.225 & 0.310 & 0.258 & 0.296 & 0.288 & 0.331 & 0.226 & 0.213 & \cellcolor{low2}0.186 & \cellcolor{low3}0.205 & \cellcolor{low1}0.161 \\
%             & 8  & 0.483 & 0.567 & 0.471 & 0.512 & 0.501 & 0.671 & 0.403 & 0.417 & \cellcolor{low2}0.351 & \cellcolor{low3}0.377 & \cellcolor{low1}0.310 \\
%             & 16 & 1.052 & 1.110 & 1.013 & 1.088 & 0.904 & 1.115 & \cellcolor{low3}0.754 & 0.806 & 0.818 & \cellcolor{low1}0.722 & \cellcolor{low2}0.752 \\
%             & \textbf{Avg} & 0.390 & 0.478 & 0.412 & 0.443 & 0.382 & 0.515 & 0.504 & 0.330 & \cellcolor{low3}0.321 & \cellcolor{low2}0.305 & \cellcolor{low1}\textbf{\underline{0.269}} \\
%         \midrule
%         \multirow{6}{*}{Dengue} 
%             & 1  & 0.244 & 0.250 & 0.261 & \cellcolor{low2}0.224 & 0.255 & 0.525 & 0.521 & \cellcolor{low3}0.225 & 0.420 & 0.240 & \cellcolor{low1}0.223 \\
%             & 2  & 0.373 & 0.343 & 0.343 & \cellcolor{low3}0.316 & 0.450 & 0.807 & 0.670 & \cellcolor{low2}0.314 & 0.579 & 0.334 & \cellcolor{low1}0.302 \\
%             & 4  & 0.696 & \cellcolor{low3}0.564 & 0.579 & \cellcolor{low1}0.560 & 0.798 & 0.957 & 0.766 & 0.571 & 0.661 & 0.586 & \cellcolor{low2}0.561 \\
%             & 8  & 1.732 & \cellcolor{low2}1.168 & \cellcolor{low3}1.183 & 1.256 & 1.239 & 1.684 & 1.539 & 1.223 & 1.308 & 1.292 & \cellcolor{low1}1.046 \\
%             & 16 & 4.082 & 3.876 & 3.315 & 3.109 & 2.659 & 3.364 & 2.934 & 3.376 & \cellcolor{low2}2.532 & \cellcolor{low3}2.537 & \cellcolor{low1}2.509 \\
%             & \textbf{Avg} & 1.426 & 1.240 & 1.136 & 1.093 & \cellcolor{low3}1.080 & 1.467 & 1.286 & 1.142 & 1.100 & \cellcolor{low2}1.000 & \cellcolor{low1}\textbf{\underline{0.892}} \\
%         \midrule
%         \multirow{6}{*}{Covid} 
%             & 1  & 33.780 & \cellcolor{low2}22.592 & \cellcolor{low3}22.009 & 23.811 & 34.161 & 42.049 & 28.130 & 25.088 & 32.376 & 23.645 & \cellcolor{low1}21.548 \\
%             & 2  & 33.193 & 23.460 & \cellcolor{low2}22.542 & 24.809 & 24.883 & 30.631 & 28.059 & \cellcolor{low3}23.123 & 35.418 & 25.047 & \cellcolor{low1}22.224 \\
%             & 4  & 32.482 & 24.729 & 24.816 & 26.345 & 31.328 & 41.029 & 29.432 & \cellcolor{low2}23.889 & 36.251 & \cellcolor{low3}24.224 & \cellcolor{low1}22.476 \\
%             & 8  & 36.573 & \cellcolor{low2}31.019 & 33.934 & 33.081 & 35.964 & 55.812 & 41.791 & \cellcolor{low3}31.217 & 40.429 & 31.548 & \cellcolor{low1}28.403 \\
%             & 16 & \cellcolor{low3}42.910 & 43.820 & \cellcolor{low2}41.432 & 47.561 & 50.244 & 47.993 & 69.976 & 51.265 & 52.590 & 43.309 & \cellcolor{low1}40.555 \\
%             & \textbf{Avg} & 35.787 & \cellcolor{low3}29.124 & \cellcolor{low2}28.947 & 31.121 & 35.316 & 43.503 & 39.478 & 30.917 & 39.413 & 29.555 & \cellcolor{low1}\textbf{\underline{26.559}} \\
%         \bottomrule
%     \end{tabular}
%     }
% \end{table*}



% \begin{table}[t]
%     \centering
%     \caption{Ablation study of removing components from the CARL framework.}
%     \label{tab:ablation_study}
%     \small
%     \resizebox{\columnwidth}{!}{%
%     \begin{tabular}{@{}lcccc{S[table-format=1.3]}@{}}
%         \toprule
%         \textbf{Model Variant} & \textbf{Horizon} & {\textbf{CARL}} & {\textbf{w/o Environment}} & {\textbf{w/o Contrast Loss}} & \textbf{w/o Pretraining} \\
%         \midrule
%         \multirow{6}{*}{ILI USA} 
%             &1 & 0.155 & 0.326 & 0.174 & 0.158 \\
%             &2 & 0.200 & 0.448 & 0.241 & 0.202 \\
%             &4 & 0.270 & 0.508 & 0.335 & 0.283 \\
%             &8 & 0.404 & 0.642 & 0.492 & 0.408 \\
%             &16 & 0.516 & 0.735 & 0.570 & 0.545 \\
%             &Avg & \textbf{0.309} & \textbf{0.532} & \textbf{0.363} & \textbf{0.319} \\
%         \midrule
%         \multirow{6}{*}{Measles} 
%             &1 & 0.069 & 0.083 & 0.090 & 0.074 \\
%             &2 & 0.096 & 0.111 & 0.124 & 0.113 \\
%             &4 & 0.155 & 0.168 & 0.276 & 0.223 \\
%             &8 & 0.280 & 0.407 & 0.431 & 0.402 \\
%             &16 & 0.743 & 0.755 & 0.801 & 0.816 \\
%             &Avg & \textbf{0.269} & \textbf{0.304} & \textbf{0.344} & \textbf{0.326} \\
%         \midrule
%         \multirow{6}{*}{Dengue} 
%             &1 & 0.218 & 0.232 & 0.198 & 0.210 \\
%             &2 & 0.301 & 0.316 & 0.273 & 0.276 \\
%             &4 & 0.540 & 0.484 & 0.460 & 0.449 \\
%             &8 & 1.193 & 1.089 & 1.128 & 1.115 \\
%             &16 & 2.210 & 3.622 & 3.329 & 3.759 \\
%             &Avg & \textbf{0.892} & \textbf{1.149} & \textbf{1.078} & \textbf{1.162} \\
%         \bottomrule
%     \end{tabular}
%     }
% \end{table}







\subsection{Covariate Adjustment for Epidemic Forecasting}
\label{sec: CA}

\begin{figure}[t]
\centering
\includegraphics[scale=0.6]{figures/causal_graph.pdf}
\caption{Causal graph for epidemic forecasting.}
\label{fig: causal_graph}
\end{figure}

% \wei{think about how to connect this with Figure 2} \wei{we should also clearly illustrate how we address the two challenges mentioned in Introduction..}

Covariate adjustment is the most widely recognized technique for de-confounding using observational data ~\cite{runge2023causal}, which serves as a solution to the confounding issue in \textbf{challenge 2}. In general terms, the adjustment can be expressed by the following formula:

\begin{equation}
p(\mathbf{y} | do(\mathcal{X}=\mathbf{x})) = \int p(\mathbf{y} | \mathbf{x}, \mathbf{z}) p(\mathbf{z}) d\mathbf{z}, \tag{4}
\end{equation}

where $do(\mathcal{X}=\mathbf{x})$ refers to assigning value $\mathbf{x}$ to variable $\mathcal{X}$.
To mitigate the confounding influences, we control for a set of variables $\mathbf{Z}$, as shown in Fig.\ref{fig: causal_graph}, and apply the adjustment to the contextualized representations $\mathbf{h}_i^{(l)}$. Nevertheless, given \textbf{challenge 1}, the available data is limited, and neither the number nor the distributions of $\mathbf{Z}$ are known. Therefore, we adopt the following assumption to further constrain the problem.

% In this study, $\mathcal{X}$ is the input history time series, $\mathbf{y}$ is the output predictions, and $\mathbf{z}$ is the corresponding environment. 



% However, directly adjusting for covariates without explicit exogenous variables \( z \) presents challenges, our approach infers environmental factors from historical data to effectively account for confounders in epidemic forecasting.

\begin{assumption}
\label{assumption1}
The epidemic forecasting problem involves a finite set of environments, each of which possesses a consistent and distinct representation.
\end{assumption}

Such an assumption is reasonable as the dynamics of epidemics are primarily driven by a limited number of factors, which collectively define distinct environments. By assuming fixed representations for these environments, models can effectively capture and leverage the unique patterns and interactions specific to each environment. This facilitates more accurate and generalizable forecasting, as the model can adapt its predictions based on the consistent characteristics inherent to each environment. Under Assumption \ref{assumption1}, we are able to reduce the procedure of covariate adjustment to a weighted sum of $p(\mathbf{y}|\mathbf{x},\mathbf{z})$:

\begin{equation}
\label{Eq: 6}
p(\mathbf{y} | \mathbf{x}) = \sum_{\mathbf{Z}} p(\mathbf{y} | \mathbf{x}, \mathbf{z}) \cdot p(\mathbf{z}).  \tag{5}
\end{equation}

In order to estimate the environment and perform the adjustment at the same time, we also use the weighted sum of $\mathbf{Z}$ as the inferred environment, since they are in the same semantic space. Therefore, following the self-attention layer, the environment representation \( \mathbf{z}_i^{(l)} \) for each patch is computed as below:

\[
\label{Eq: env_estimator}
\mathbf{e}_i^{(l)} = g_{\phi}^{(l)}(\mathbf{h}_i^{(l)}, \mathbf{Z}) = \sum_{k=1}^{K} \mathbf{z}^k \cdot p(\mathbf{z}^k \mid \mathbf{h}_i^{(l)}), \tag{6}
\]

where \( \mathbf{Z} = \{ \mathbf{z}^1, \mathbf{z}^2, \ldots, \mathbf{z}^K \} \) represents the set of fixed environment representations, and \( p(\mathbf{z}^k \mid \mathbf{h}_i^{(l)}) \) is the probability of environment \( \mathbf{z}^k \) given the contextualized representation \( \mathbf{h}_i^{(l)} \). To perform covariate adjustment, the estimated environment \( \mathbf{e}_i^{(l)} \) is then combined with the encoded input via a hadamard product:
\[
\mathbf{m}_i^{(l)} = \mathbf{h}_i^{(l)} \odot \mathbf{e}_i^{(l)} = \sum_{k=1}^{K} (\mathbf{h}_i^{(l)} \odot \mathbf{z}^k) \cdot p(\mathbf{z}^k \mid \mathbf{h}_i^{(l)}). \tag{7}
\]
This formulation effectively reduces the original covariate adjustment function to Eq.~\ref{Eq: 6}, where \( p(\mathbf{y} | \mathbf{x}, \mathbf{z}) \) is modeled as \( \mathbf{x} \odot \mathbf{z} \). Finally, a feedforward neural network \( \mathbf{x}_i^{(l+1)} = \sigma(\mathbf{W}_f^{(l)} \mathbf{m}_i^{(l)}) \) is applied to acquire the output representations, which also serves as the input for the next block. At the end of the model, we acquire the final representation $g_\theta(\mathbf{X}) = \mathbf{X^{(L)}}$. Then, a task-specific head is applied to predict the target variable $\mathbf{y}=\mathbf{h}_\psi(\mathbf{X}^{(L)})$.



\subsection{Patch-Wise Pseudo Environment Estimator}
\label{sec: env_estimate}

In this section, we detail the modeling of the conditional probability \( p(\mathbf{z}^k \mid \mathbf{h}_i^{(l)}) \). To better model the causal and spurious correlations, we adopt the following decomposition assumption similar to ~\cite{mao2022causal}:
 
\begin{assumption}
Each representation \( \mathbf{h}_i^{(l)} \) can be decomposed into causal factors \( \mathbf{h}_{c,i}^{(l)} \) and spurious factors \( \mathbf{h}_{s,i}^{(l)} \).
\end{assumption} 

Under this assumption and given that \( \mathbf{h}_{c,i}^{(l)} \perp \mathbf{z}^k \), the probability \( p(\mathbf{z}^k \mid \mathbf{h}_i^{(l)}) \) can be expressed as:
\[
p(\mathbf{z}^k \mid \mathbf{h}_i^{(l)}) = p(\mathbf{z}^k \mid \mathbf{h}_{c,i}^{(l)}, \mathbf{h}_{s,i}^{(l)}) = p(\mathbf{z}^k \mid \mathbf{h}_{s,i}^{(l)}). \tag{8}
\]

Then, we model this conditional probability using a softmax function over the spurious factors:
\[
\label{eq11}
\pi_i^{k(l)} = \underset{\mathbf{Z}}{\operatorname{Softmax}} \left( \mathbf{W}_k^{(l)} \mathbf{z}^k \cdot f_{\text{decomp}}(\mathbf{h}_i^{(l)}) \right), \tag{9}
\]
where \( f_{\text{decomp}}(\mathbf{h}_i^{(l)}) \) denotes the decomposition function extracting spurious factors, modeled as a linear transformation \( f_{\text{decomp}}(\mathbf{h}_i) = \mathbf{W}_h^{(l)} \mathbf{h}_i^{(l)} \), and \( \mathbf{W}_k^{(l)} \) maps the environment representation \( \mathbf{z}^k \) to the same dimensionality as \( \mathbf{h}_{s, i}^{(l)} \). Integrating these components, the final model can be expressed as:

\[
\mathbf{X}^{(l+1)} = \sigma \left\{ \mathbf{W}_f^{(l)} \sum_{k=1}^{K} \left( [\mathbf{H}^{(l)} \odot \mathbf{z}^k] \cdot \pi_i^{k(l)} \right) \right\}, \tag{10}
\]

where \( \sigma \) represents the activation function.

% The CARL framework integrates environment inference with temporal data processing to enhance epidemic forecasting. By decomposing representations into causal and spurious factors and modeling environment influences through a weighted sum of fixed environment representations, CARL effectively adjusts for confounders without requiring explicit exogenous covariates. The combination of reversible normalization, patch-based processing, and self-attention mechanisms ensures robust performance against temporal distribution shifts, making CARL a powerful tool for epidemic forecasting tasks.









% Next, we detail the modeling of the conditional probability \( p(\mathbf{z}^k \mid \mathbf{h}_i^{(l)}) \). To better model the causal and spurious correlations, we adopt the following decomposition assumption from~\cite{mao2022causal}:
 
% \begin{assumption}
% As shown in Figure~\ref{fig: causal_graph}, each input $\mathbf{X}$ can be decomposed into the spurious factor $\mathbf{X}_s$ and the causal factor $\mathbf{X}_c$. Consequently, we decompose representation \( \mathbf{h}_i^{(l)} \) into two corresponding representations:  \( \mathbf{h}_{c,i}^{(l)} \) and \( \mathbf{h}_{s,i}^{(l)} \).
% \end{assumption} 

% Under this assumption and given that the causal factor is independent from the environment, which yeilds \( \mathbf{h}_{c,i}^{(l)} \perp \mathbf{z}^k \), the probability \( p(\mathbf{z}^k \mid \mathbf{h}_i^{(l)}) \) can be expressed as:
% \begin{equation}
% p(\mathbf{z}^k \mid \mathbf{h}_i^{(l)}) = p(\mathbf{z}^k \mid \mathbf{h}_{c,i}^{(l)}, \mathbf{h}_{s,i}^{(l)}) = p(\mathbf{z}^k \mid \mathbf{h}_{s,i}^{(l)}).
% \end{equation}

% Then, we model this conditional probability as a cross-attention score using a softmax function:
% \begin{equation}
% \label{eq11}
% \pi_i^{k(l)} = \operatorname{Softmax} \left( (\mathbf{W}_k^{(l)} \mathbf{z}^k)^\top \cdot f_{\text{decomp}}(\mathbf{h}_i^{(l)}) \right)
% \end{equation}

% where \( f_{\text{decomp}}(\mathbf{h}_i^{(l)}) \) denotes the decomposition function extracting spurious factors, modeled as a linear transformation \( f_{\text{decomp}}(\mathbf{h}_i) = \mathbf{W}_h^{(l)} \mathbf{h}_i^{(l)} \), and \( \mathbf{W}_k^{(l)} \) maps the environment representation \( \mathbf{z}^k \) to the same dimensionality as \( \mathbf{h}_{s, i}^{(l)} \). Finally, a feedforward neural network \( \mathbf{x}_i^{(l+1)} = \sigma(\mathbf{W}_f^{(l)} \mathbf{m}_i^{(l)}) \) is applied to acquire the output representations, which serves as the input for the next block. Integrating these components, the final model can be expressed as:

% \vspace{-3mm}
% \[
% \mathbf{X}^{(l+1)} = \sigma \left\{ \mathbf{W}_f^{(l)} \sum_{k=1}^{K} \left( [\mathbf{H}^{(l)} \odot \mathbf{z}^k] \cdot \pi_i^{k(l)} \right) \right\}, \tag{6}
% \]
% \vspace{-3mm}



%----------------------------------- old theory

% \textbf{E-step.} In the E-step, $\phi$ is frozen and $q_\phi^{t}$ defines the environment distribution space, yielding a categorical distribution for a specific $Z$ with corresponding latent representations $\mathbf{E}$. Therefore, we search for the environment distribution that maximizes the observed target distribution $p(Y)$. Specifically, the latent representations $\mathbf{E}$ are treated as part of the parameters of $q_\phi^{t}$, and the likelihood of $p_E(\hat{Y})$ is maximized. During this process, $q_\phi^{t}(Z^{t}|X)$ naturally approximates $q_\phi^{t}(Z^{t})$ asymptotically as we apply minibatch during training. This means the whole process finds a distribution $p(Z^{t})$ that best describes the data. To explain why $q_\phi^t(Z^{t} | X)$ approximates $q_\phi^t(Z^{t})$, note that the marginal distribution $q_\phi^t(Z^{t})$ is:
% \begin{equation}
% q_\phi^t(Z^{t}) = \int q_\phi^t(Z^{t} | X) p(X) dX = \mathbb{E}_{p(X)}[q_\phi^t(Z^{t} | X)].    
% \end{equation}

% During minibatch training, the expectation $\mathbb{E}_{p(X)}$ is replaced by:
% $q_\phi^t(Z) \approx \frac{1}{B} \sum_{i=1}^B q_\phi^t(Z | X_i).$
% At each iteration, $E$ is updated using the minibatch likelihood:
% $\Delta E = \frac{\partial}{\partial E} \frac{1}{B} \sum_{i=1}^B p_E(Y | X_i).$
% Iteratively updating $E$ across multiple minibatches aggregates partial contributions from different minibatches, ensuring that $q_\phi^t(Z | X) \to q_\phi^t(Z).$ This works because $E$ directly represents the environment $Z$, which is shared across all data points, and minibatch-specific updates to $E$ contribute to its global refinement.


% •	Training will be computationally intensive, especially for large datasets.
% •	Generalization may suffer due to the lack of stochastic regularization from minibatch updates.



% \textbf{M-step.} In the M-step, $q_\phi^{t+1}(Z | X)$ serves as the estimator, given a fixed environment distribution $p(Z)$ previously approximated by $q_\phi^{t}(Z | X)$. We derive an \textbf{approximated variational lower bound} for $ \log p_\theta (\hat{Y} | do(X)) $:

% \begin{equation}
% \begin{aligned}
% &\log \sum_e p_\theta (\hat{Y} | X, Z = z) P(Z = z) \\
% &= \log \sum_e p_\theta (\hat{Y} | X, Z = z) p(Z = z) \frac{q^{t+1}_\phi(Z = z | X)}{q^{t+1}_\phi(Z = z | X)} \\
% &\geq \sum_e q^{t+1}_\phi(Z = z | X) \log p_\theta (\hat{Y} | X, Z = z) \frac{p(Z = z)}{q^{t+1}_\phi(Z = z | X)} \\
% &= \sum_e q^{t+1}_\phi(Z = z | X) \log p_\theta (\hat{Y} | X, Z = z) - \sum_e q^{t+1}_\phi(Z = z | X) \log \frac{q^{t+1}_\phi(Z = z | X)}{p(Z = z)} \\
% &= \mathbb{E}_{q_\phi(Z \mid X)} \left[ \log p_\theta(\hat{Y} \mid X, Z) \right] 
% - KL\left(q_\phi^{t+1}(Z \mid X) \parallel p(Z)\right) \\
% &\approx \mathbb{E}_{q_\phi(Z \mid X)} \left[ \log p_\theta(\hat{Y} \mid X, Z) \right] 
% - KL\left(q_\phi^{t+1}(Z \mid X) \parallel q_\phi^{t}(Z \mid X)\right)
% \end{aligned}
% \end{equation}

% % \[
% % \log p_\theta(\hat{Y} \mid do(X)) 
% % \geq \mathbb{E}_{q_\phi(Z \mid X)} \left[ \log p_\theta(\hat{Y} \mid X, Z) \right] 
% % - KL\left(q_\phi^{t+1}(Z \mid X) \parallel q_\phi^{t}(Z \mid X)\right)
% % \]

% % More details are shown in Figure~\ref{fig: theory}.

% Since $q_\phi$ only involves linear transformations and a softmax function, we argue that minimizing the KL loss between $q_\phi^{t}$ and $q_\phi^{t+1}$ is equivalent to minimizing the difference between $\phi^{t}$ and $\phi^{t+1}$.

% \begin{enumerate}
%     \item The logits  $s_i$  are computed as: $s_i = \mathbf{W}_k^{(l)} \mathbf{z}^k$. A change in  $\mathbf{W}_k^{(l)}$ , denoted as  $\Delta \mathbf{W}_k^{(l)}$ , modifies  $s_i$  as $\Delta s_i = (\Delta \mathbf{W}_k^{(l)}) \mathbf{z}^k$. The change in  $s_i$  is linear with respect to  $\Delta \mathbf{W}_k^{(l)}$  and  $\mathbf{z}^k$ . Therefore, a small change in  $\mathbf{W}_k^{(l)}$ leads to proportionally small changes in  $s_i$.

%     \item The Softmax function introduces nonlinear coupling between logits  $s_i$ , as the output probabilities  $\pi_i$  depend not only on  $s_i$  but also on all other logits  $s_j$ . For a small change in  $s_i$ , the change in  $\pi_i$  can be approximated using the gradient of the Softmax $\frac{\partial \pi_i}{\partial s_i} = \pi_i (1 - \pi_i)$, $\frac{\partial \pi_i}{\partial s_j} = -\pi_i \pi_j \quad \text{for } i \neq j$. Thus, a change in  $\mathbf{W}k^{(l)}$  affects  $\pi_i$  as $\Delta \pi_i \approx \pi_i (1 - \pi_i) \Delta s_i - \sum_{j \neq i} \pi_i \pi_j \Delta s_j$. This implies that the change of the output $\Delta \pi_i$ shrinks proportionally with the change of parameters $\Delta \mathbf{W}_k$.
% \end{enumerate}

% From the above analysis, we are able to formulate the loss of $KL\left(q_\phi^{t+1}(Z \mid X) \parallel q_\phi^{t}(Z \mid X)\right)$ as $\mathcal{L}_{kl} = (\phi^{t} - \phi^{t+1})^2$.
% In our setting, we use weight decay to regularize the model, which indirectly helps control the KL loss. Weight decay adds a penalty to the loss function that encourages smaller parameter values, effectively shrinking the magnitude of the weights during training. The update rule for parameters with weight decay is given by:
% $\phi_{t+1} = \phi_t - \alpha \cdot \nabla_\phi \mathcal{L}_{\text{original}} - \alpha \cdot \lambda \phi_t$,
% where \( \alpha \) is the learning rate and \( \lambda \) is the weight decay coefficient. The total KL loss can be approximated as:

% \[
% \mathcal{L}_{\text{kl}} \approx \| \phi^t - \phi^{t+1} \|^2 = \alpha^2 \| \nabla_\phi \mathcal{L}_{\text{original}} + \lambda \phi_t \|^2.
% \]

% When the training process converges to a minimum, the task-related gradients (\( \nabla_\phi \mathcal{L}_{\text{original}} \)) become small and nearly zero, and the KL loss becomes dominated by the weight decay term, and the approximation simplifies to:
% $\mathcal{L}_{\text{kl}} \approx \alpha^2 \lambda^2 \| \phi^t \|^2$.
% Thus, weight decay contributes to minimizing the KL loss.


% % \begin{equation}
% % \phi_{t+1} = \phi_t - \alpha \cdot \frac{\hat{m}_t}{\sqrt{\hat{v}_t} + \epsilon} - \alpha \cdot \lambda \phi_t
% % \end{equation}


% \begin{figure}[H]
%     \centering
%     \begin{subfigure}[b]{0.45\textwidth}
%         \centering
%         \includegraphics[width=\linewidth]{figures/theory_1.pdf}
%         \caption{Previous Method}
%         \label{fig: previous_theory}
%     \end{subfigure}
%     \hfill
%     \begin{subfigure}[b]{0.45\textwidth}
%         \centering
%         \includegraphics[width=\linewidth]{figures/theory_2.pdf}
%         \caption{Ours}
%         \label{fig: our_theory}
%     \end{subfigure}
    
    
%     \caption{Comparison between previous approach and our implementation.}
%     \label{fig: theory}
% \end{figure}

% \begin{theorem}

% The optimization target in the expectation step is to minimize the reconstruction loss...

% \end{theorem}

% \textbf{E-step.} In the E-step, $\phi$ is frozen and $q_\phi^{t}$ defines the environment distribution space, yielding a categorical distribution for a specific $Z$ with corresponding latent representations $\mathbf{E}$. Therefore, we search for the environment distribution that maximizes the observed target distribution $p(Y)$. Specifically, the latent representations $\mathbf{E}$ are treated as part of the parameters of $q_\phi^{t}$, and the likelihood of $p_E(\hat{Y})$ is maximized, which yields the following maximization target:
% \begin{equation}
% \begin{aligned}
% p(\hat{Y})&=\sum_{\mathbf{X}} p(\hat{Y}|X=\mathbf{X}))p(X=\mathbf{X}) \\
% &=\sum_{\mathbf{X}} p(X=\mathbf{X}) \sum_{Z} p(\hat{Y}|X=\mathbf{X}, Z=z))p(Z=z|X=\mathbf{X}) \\
% &=\sum_{\mathbf{X}} p_\Theta(X=\mathbf{X}) \sum_{Z} p(\hat{Y}|X=\mathbf{X}, Z=z))q_\phi(Z=z|X_s=\mathbf{X}_s) \\
% &=\mathbb{E}_{p(X)}\mathbb{E}_{q_\phi(Z|X_s)}p_\Theta(\hat{Y}|X,Z).
% \end{aligned}
% \end{equation}

% Since $X \rightarrow X_s$ is a deterministic process, we are able to directly replace $p(Z=z|X_s=\mathbf{X}_s)$. Furthermore, a small training set with distribution \( p_{tr}(X) \) may not represent the true prior \( p(X) \). To address this, we adopt minibatch sampling, using sampled data distribution from the training set \( p_s(X) \) to approximate \( p(X) \). This stochastic approach promotes robustness by exposing the model to diverse subsets of the data, reducing its reliance on specific patterns and forcing it to generalize across variations. By preventing the model from memorizing the training dataset distribution \( p_{tr}(X) \), minibatch sampling reduces overfitting and helps it adapt better to unseen data, ultimately enhancing its ability to handle noise and variability in real-world scenarios. In the case of pre-training, when we apply reconstructing the masked inputs as the learning task, the prediction target becomes $\hat{X}$. Therefore, the above optimization function transforms into:
% \begin{equation}
%     \mathbb{E}_{p_s(X)}\mathbb{E}_{q_\phi(Z|X_s)}p_\Theta(\hat{X}|X,Z).
% \end{equation}

% By minimizing $\mathcal{L}_{\text{recon}}(\mathbf{X}, \hat{\mathbf{X}}) = \text{MSE}(\hat{\mathbf{X}}, \mathbf{X})$, the reconstructed sample $\hat{\mathbf{X}}$ given by the model $p_\Theta(\hat{X}|X,Z)$ is matched close to the groundtruth $\mathbf{X}$...



% \textbf{M-step.} In the M-step, $q_\phi^{t+1}(Z | X)$ serves as the estimator, given a fixed environment distribution $p(Z)$ previously approximated by $q_\phi^{t}(Z | X)$. We derive an \textbf{approximated variational lower bound} for $ \log p_\theta (\hat{Y} | do(X)) $:

% \begin{equation}
% \begin{aligned}
% &\log \sum_e p_\theta (\hat{Y} | X, Z = z) P(Z = z) \\
% &= \log \sum_e p_\theta (\hat{Y} | X, Z = z) p(Z = z) \frac{q^{t+1}_\phi(Z = z | X)}{q^{t+1}_\phi(Z = z | X)} \\
% &\geq \sum_e q^{t+1}_\phi(Z = z | X) \log p_\theta (\hat{Y} | X, Z = z) \frac{p(Z = z)}{q^{t+1}_\phi(Z = z | X)} \\
% &= \sum_e q^{t+1}_\phi(Z = z | X) \log p_\theta (\hat{Y} | X, Z = z) - \sum_e q^{t+1}_\phi(Z = z | X) \log \frac{q^{t+1}_\phi(Z = z | X)}{p(Z = z)} \\
% &= \mathbb{E}_{q_\phi(Z \mid X)} \left[ \log p_\theta(\hat{Y} \mid X, Z) \right] 
% - KL\left(q_\phi^{t+1}(Z \mid X) \parallel p(Z)\right) \\
% &\approx \mathbb{E}_{q_\phi(Z \mid X)} \left[ \log p_\theta(\hat{Y} \mid X, Z) \right] 
% - KL\left(q_\phi^{t+1}(Z \mid X) \parallel q_\phi^{t}(Z \mid X)\right)
% \end{aligned}
% \end{equation}

% % \[
% % \log p_\theta(\hat{Y} \mid do(X)) 
% % \geq \mathbb{E}_{q_\phi(Z \mid X)} \left[ \log p_\theta(\hat{Y} \mid X, Z) \right] 
% % - KL\left(q_\phi^{t+1}(Z \mid X) \parallel q_\phi^{t}(Z \mid X)\right)
% % \]

% % More details are shown in Figure~\ref{fig: theory}.

% Since $q_\phi$ only involves linear transformations and a softmax function, we argue that minimizing the KL loss between $q_\phi^{t}$ and $q_\phi^{t+1}$ is equivalent to minimizing the difference between $\phi^{t}$ and $\phi^{t+1}$.

% \begin{enumerate}
%     \item The logits  $s_i$  are computed as: $s_i = \mathbf{W}_k^{(l)} \mathbf{z}^k$. A change in  $\mathbf{W}_k^{(l)}$ , denoted as  $\Delta \mathbf{W}_k^{(l)}$ , modifies  $s_i$  as $\Delta s_i = (\Delta \mathbf{W}_k^{(l)}) \mathbf{z}^k$. The change in  $s_i$  is linear with respect to  $\Delta \mathbf{W}_k^{(l)}$  and  $\mathbf{z}^k$ . Therefore, a small change in  $\mathbf{W}_k^{(l)}$ leads to proportionally small changes in  $s_i$.

%     \item The Softmax function introduces nonlinear coupling between logits  $s_i$ , as the output probabilities  $\pi_i$  depend not only on  $s_i$  but also on all other logits  $s_j$ . For a small change in  $s_i$ , the change in  $\pi_i$  can be approximated using the gradient of the Softmax $\frac{\partial \pi_i}{\partial s_i} = \pi_i (1 - \pi_i)$, $\frac{\partial \pi_i}{\partial s_j} = -\pi_i \pi_j \quad \text{for } i \neq j$. Thus, a change in  $\mathbf{W}k^{(l)}$  affects  $\pi_i$  as $\Delta \pi_i \approx \pi_i (1 - \pi_i) \Delta s_i - \sum_{j \neq i} \pi_i \pi_j \Delta s_j$. This implies that the change of the output $\Delta \pi_i$ shrinks proportionally with the change of parameters $\Delta \mathbf{W}_k$.
% \end{enumerate}

% From the above analysis, we are able to formulate the loss of $KL\left(q_\phi^{t+1}(Z \mid X) \parallel q_\phi^{t}(Z \mid X)\right)$ as $\mathcal{L}_{kl} = (\phi^{t} - \phi^{t+1})^2$.
% In our setting, we use weight decay to regularize the model, which indirectly helps control the KL loss. Weight decay adds a penalty to the loss function that encourages smaller parameter values, effectively shrinking the magnitude of the weights during training. The update rule for parameters with weight decay is given by:
% $\phi_{t+1} = \phi_t - \alpha \cdot \nabla_\phi \mathcal{L}_{\text{original}} - \alpha \cdot \lambda \phi_t$,
% where \( \alpha \) is the learning rate and \( \lambda \) is the weight decay coefficient. The total KL loss can be approximated as:

% \[
% \mathcal{L}_{\text{kl}} \approx \| \phi^t - \phi^{t+1} \|^2 = \alpha^2 \| \nabla_\phi \mathcal{L}_{\text{original}} + \lambda \phi_t \|^2.
% \]

% When the training process converges to a minimum, the task-related gradients (\( \nabla_\phi \mathcal{L}_{\text{original}} \)) become small and nearly zero, and the KL loss becomes dominated by the weight decay term, and the approximation simplifies to:
% $\mathcal{L}_{\text{kl}} \approx \alpha^2 \lambda^2 \| \phi^t \|^2$.
% Thus, weight decay contributes to minimizing the KL loss.









% \textbf{Conceptualization of the Environment Variable $Z$.} We let the environment variable $Z$ 
% follow a categorical distribution $p(Z)$. This variable can assume one of $K$ distinct values $z_k$, each representing a discrete environmental state (e.g., specific public health policy scenarios). Each state $z_k$ is associated with a unique latent representation $\mathbf{e}_k \in \mathbb{R}^{h_e}$, where $\mathbf{e}_k$ encapsulates the invariant features or characteristics specific to that environment. 


% \begin{definition}[Environment] 
% \label{assumption}
% The environment $Z$ is a variable that follows a categorical distribution $p(Z)$, which can take on one of K  discrete labels, where each label corresponds to a specific environmental state (e.g. public health policy) and each state possesses a consistent and distinct latent representation $\mathbf{e}^k \in \mathbb{R}^{h_e}$. 
% \end{definition}
% % \wei{explain what is $Z$.}



% In the above definition, we treat the environment variable $Z$ as a confounder with a finite number of values, which is reasonable given that epidemic dynamics are often driven by a few key factors represented by distinct environmental states with specific latent representations.



%This allows our model to identify and utilize the unique interactions within each environment. 


% \wei{We define \(\hat{Y}\) as the random variable representing the predicted future time series $\hat{\mathbf{y}}$, and $P_\theta(\hat{Y} | X)$ denotes the predictive distribution induced by the model $f_\theta$. The common practice is to adopt maximum likelihood estimation as the training objective which maximizes the likelihood $P_\theta(\hat{Y} | X)$. 
% For time series forecasting, we adopt MSE as the training objective. Since $E$ affects the distribution for observed data via  $P(X,Y|Z)=P(X|Z)P(Y|X,Z)$, the learning algorithm yields xxxx.}



% As illustrated in Figure~\ref{fig: causal_graph}, the generation of \( X \) is inherently dependent on the corresponding environment. Consequently, reconstructing a patch requires not only information from neighboring patches but also an understanding of its associated environment. Accurate reconstruction, therefore, depends on effectively capturing the environmental context. Unlike previous research, which overlooked the role of the environment in the masked time series modeling task, we adopt the environment estimator \( q_\phi(Z \mid X) \) to infer the environment for the  and employ contrastive learning to enhance the robustness of the environment estimator \( q_\phi(Z \mid X) \), ensuring the alignment of inferred environments across diverse contexts.
% As illustrated in Figure~\ref{fig: causal_graph}, the generation of  $X$  is inherently dependent on the corresponding environment. Consequently, the reconstruction of a patch relies not only on the information from neighboring patches but also on its associated environment. Therefore, an accurate reconstruction requires capturing the corresponding environment. While previous random masking and reconstruction tasks neglected the importance of the environment, we adopt contrastive learning to enhance the robustness of the environment estimator $q_\phi(Z|X)$, which enables the alignment of inferred environments across diverse contexts.
% Previous research on general time series forecasting~\cite{liu2024time} has employed majority voting to enhance the accuracy of inferred environments. However, this approach is non-differentiable during training. To address this limitation, we adopt contrastive learning to enhance the robustness of the environment estimator $q_\phi(Z|X)$, which enables the alignment of inferred environments across diverse contexts.
% the integration of latent environment representation $\mathbf{e}_k$ in Eq.~\eqref{Eq: model} is equivalent to producing an environment-aware representation, given that $\sum_{k=1}^{K} \mathbf{H}^{(l)} \odot (\mathbf{e}_k \mathbf{1}^\top) \pi_{k}^{(l)}=\mathbf{H}^{(l)} \odot \sum_{k=1}^{K} (\mathbf{e}_k \mathbf{1}^\top) \pi_{k}^{(l)}$, which can be seen as the combination of the input $\mathbf{H}^{(l)}$ and the \textit{interpolated latent environment representation} $\hat{\mathbf{e}}^{(l)}=\sum_{k=1}^{K}\mathbf{e}_k \pi_{k}^{(l)}$.
% In this case, $\hat{\mathbf{e}}^{(l)}$ becomes the latent representation of the interpolation from the defined environment states $\mathbf{z}_k$, and the weight $q_\phi(Z \mid X)$ can be interpreted as the contribution of each state involved in the given period $\mathbf{h}_i^{(l)}$.
% While $q_\phi(Z \mid X)$ helps infer the environment for a given time series $\mathbf{X}$ during random masking, the inferred result for a patch may vary given a different context $\mathbf{X}'$. Since the changing of context results in a change of the latent representations $\mathbf{h}^{(l)}_i$, the environment estimator can output a different result, which is unreasonable as the environment is context-invariant. To address this, we propose to use hierarchical environment contrasting to align the estimated environments given different contexts.






    \begin{tabular}{llcccccccccccc}
        \toprule
        \textbf{Dataset} & \textbf{Horizon} 
            & \textbf{ARIMA} & \textbf{LSTM} & \textbf{GRU} 
            & \textbf{Dlinear} & \textbf{Informer} & \textbf{Autoformer} 
            & \textbf{Fedformer} & \textbf{PEM} & \textbf{MOMENT} 
            & \textbf{PatchTST} & \textbf{CAPE} \\
        \midrule
        \multirow{6}{*}{ILI USA} 
            & 1  & \cellcolor{low1}0.138 & 0.338 & 0.259 & 0.220 
                  & \cellcolor{low3}0.175 & 0.457 & 0.368 & 0.179 
                  & 0.269 & 0.195 & \cellcolor{low2}0.155 
                   \\[2pt]
            & 2  & \cellcolor{low2}0.203 & 0.377 & 0.301 & 0.247 
                  & 0.370 & 0.710 & 0.380 & \cellcolor{low3}0.226 
                  & 0.321 & 0.264 & \cellcolor{low1}0.200 
                  \\[2pt]
            & 4  & \cellcolor{low3}0.354 & 0.458 & 0.386 & 0.376 
                  & 0.517 & 0.670 & 0.433 & \cellcolor{low2}0.304 
                  & 0.397 & 0.385 & \cellcolor{low1}0.270 
                   \\[2pt]
            & 8  & 0.701 & 0.579 & 0.529 & \cellcolor{low2}0.506 
                  & 0.597 & 0.842 & 0.570 & 0.538 
                  & \cellcolor{low3}0.510 & 0.535 & \cellcolor{low1}0.404 
                  \\[2pt]
            & 16 & 1.121 & 0.691 & 0.626 & 0.617 
                  & 0.812 & 0.835 & 0.701 & \cellcolor{low3}0.570 
                  & 0.610 & \cellcolor{low1}0.485 & \cellcolor{low2}0.516 
                   \\[2pt]
            & \textbf{Avg} & 0.503 & 0.489 & 0.420 & \cellcolor{low3}0.393 
                  & 0.494 & 0.703 & 0.490 & \cellcolor{low2}0.363 
                  & 0.421 & 0.373 & \cellcolor{low1}\textbf{\underline{0.309}}
                   \\
        \midrule        
        \multirow{6}{*}{ILI Japan} 
            & 1  
              & \cellcolor{low3}0.358 & 1.426 & 1.213 & 1.016 
              & 0.405 & 0.515 & 0.525 & 0.470 
              & \cellcolor{low2}0.325 & 0.413 & \cellcolor{low1}0.290 
              \\[2pt]
            & 2  
              & 0.772 & 1.635 & 1.458 & 1.294 
              & \cellcolor{low3}0.666 & 0.855 & 1.151 & 0.755 
              & \cellcolor{low2}0.586 & 0.698 & \cellcolor{low1}0.535 
               \\[2pt]
            & 4  
              & 1.720 & 1.975 & 1.870 & 1.758 
              & 1.234 & \cellcolor{low3}1.150 & 1.455 & 1.207 
              & \cellcolor{low2}1.082 & 1.147 & \cellcolor{low1}0.944 
              \\[2pt]
            & 8  
              & 2.981 & 2.373 & 2.365 & 2.285 
              & \cellcolor{low2}1.688 & 1.866 & 2.012 & 1.810 
              & \cellcolor{low3}1.706 & 1.708 & \cellcolor{low1}1.650 
              \\[2pt]
            & 16 
              & 2.572 & 2.023 & 2.010 & 2.007 
              & \cellcolor{low1}1.551 & 2.654 & 4.027 & \cellcolor{low3}1.766 
              & 2.054 & \cellcolor{low2}1.688 & 1.911 
               \\[2pt]
            & \textbf{Avg} 
              & 1.680 & 1.886 & 1.783 & 1.672 
              & \cellcolor{low2}1.109 & 1.408 & 1.834 & 1.202 
              & 1.151 & \cellcolor{low3}1.131 & \cellcolor{low1}\textbf{\underline{1.066}}
               \\
        \midrule
        \multirow{6}{*}{Measles} 
              & 1  
                & \cellcolor{low2}0.071 & 0.182 & 0.143 & 0.133 
                & \cellcolor{low1}0.066 & 0.203 & 0.321 & 0.085 
                & 0.113 & 0.094 & \cellcolor{low3}0.083 
               \\[2pt]
              & 2  
                & \cellcolor{low2}0.120 & 0.223 & 0.176 & 0.184 
                & 0.153 & 0.257 & 0.817 & 0.128 
                & 0.138 & \cellcolor{low3}0.127 & \cellcolor{low1}0.112 
                 \\[2pt]
              & 4  
                & 0.225 & 0.310 & 0.258 & 0.296 
                & 0.288 & 0.331 & 0.226 & 0.213 
                & \cellcolor{low2}0.186 & \cellcolor{low3}0.205 & \cellcolor{low1}0.161
                 \\[2pt]
              & 8  
                & 0.483 & 0.567 & 0.471 & 0.512 
                & 0.501 & 0.671 & 0.403 & 0.417 
                & \cellcolor{low2}0.351 & \cellcolor{low3}0.377 & \cellcolor{low1}0.310 
                \\[2pt]
              & 16 
                & 1.052 & 1.110 & 1.013 & 1.088 
                & 0.904 & 1.115 & \cellcolor{low3}0.754 & 0.806 
                & 0.818 & \cellcolor{low1}0.722 & \cellcolor{low2}0.752
                 \\[2pt]
              & \textbf{Avg} 
                & 0.390 & 0.478 & 0.412 & 0.443 
                & 0.382 & 0.515 & 0.504 & 0.330 
                & \cellcolor{low3}0.321 & \cellcolor{low2}0.305 
                & \cellcolor{low1}\textbf{\underline{0.269}}
                 \\
        \midrule
        \multirow{6}{*}{Dengue} 
          & 1  
            & 0.244 & 0.250 & 0.261 & \cellcolor{low2}0.224 
            & 0.255 & 0.525 & 0.521 & \cellcolor{low3}0.225 
            & 0.420 & 0.240 & \cellcolor{low1}0.223 
             \\[2pt]
          & 2  
            & 0.373 & 0.343 & 0.343 & \cellcolor{low3}0.316 
            & 0.450 & 0.807 & 0.670 & \cellcolor{low2}0.314 
            & 0.579 & 0.334 & \cellcolor{low1}0.302
             \\[2pt]
          & 4  
            & 0.696 & \cellcolor{low3}0.564 & 0.579 & \cellcolor{low1}0.560 
            & 0.798 & 0.957 & 0.766 & 0.571 
            & 0.661 & 0.586 & \cellcolor{low2}0.561 
             \\[2pt]
          & 8  
            & 1.732 & \cellcolor{low2}1.168 & \cellcolor{low3}1.183 & 1.256 
            & 1.239 & 1.684 & 1.539 & 1.223 
            & 1.308 & 1.292 & \cellcolor{low1}1.046 
             \\[2pt]
          & 16 
            & 4.082 & 3.876 & 3.315 & 3.109 
            & 2.659 & 3.364 & 2.934 & 3.376 
            & \cellcolor{low2}2.532 & \cellcolor{low3}2.537 & \cellcolor{low1}2.509
            \\[2pt]
          & \textbf{Avg} 
            & 1.426 & 1.240 & 1.136 & 1.093 
            & \cellcolor{low3}1.080 & 1.467 & 1.286 & 1.142 
            & 1.100 & \cellcolor{low2}1.000 & \cellcolor{low1}\textbf{\underline{0.892}}
             \\
        \midrule
        \multirow{6}{*}{Covid} 
          & 1  
            & 33.780 & \cellcolor{low2}22.592 & \cellcolor{low3}22.009 & 23.811 
            & 34.161 & 42.049 & 28.130 & 25.088 
            & 32.376 & 23.645 & \cellcolor{low1}21.548
             \\[2pt]
          & 2  
            & 33.193 & 23.460 & \cellcolor{low2}22.542 & 24.809 
            & 24.883 & 30.631 & 28.059 & \cellcolor{low3}23.123 
            & 35.418 & 25.047 & \cellcolor{low1}22.224
             \\[2pt]
          & 4  
            & 32.482 & 24.729 & 24.816 & 26.345 
            & 31.328 & 41.029 & 29.432 & \cellcolor{low2}23.889 
            & 36.251 & \cellcolor{low3}24.224 & \cellcolor{low1}22.476
             \\[2pt]
          & 8  
            & 36.573 & \cellcolor{low2}31.019 & 33.934 & 33.081 
            & 35.964 & 55.812 & 41.791 & \cellcolor{low3}31.217 
            & 40.429 & 31.548 & \cellcolor{low1}28.403
            \\[2pt]
          & 16 
            & \cellcolor{low3}42.910 & 43.820 & \cellcolor{low2}41.432 & 47.561 
            & 50.244 & 47.993 & 69.976 & 51.265 
            & 52.590 & 43.309 & \cellcolor{low1}40.555
             \\[2pt]
          & \textbf{Avg} 
            & 35.787 & \cellcolor{low3}29.124 & \cellcolor{low2}28.947 & 31.121 
            & 35.316 & 43.503 & 39.478 & 30.917 
            & 39.413 & 29.555 & \cellcolor{low1}\textbf{\underline{26.559}}
             \\
        \bottomrule
    \end{tabular}






% We include the measles infections in the USA during pre-training, and fine-tune it on the UK measles dataset, where it outperforms non-pre-trained models (Table~\ref{tab:ablation_study}). Additionally, pre-training on US Influenza data enables CAPE to generalize effectively to Influenza infections in Japan (ILI Japan).  

% \textbf{Cross-Location.} We include the measles infections in the USA during pre-training, and then fine-tune on the measles dataset in the UK. Despite the regional difference, the pre-trained CAPE performs better compared to the model not pre-trained including itself, as shown in Table~\ref{tab:ablation_study}. Besides, we also included the Influenza dataset in the US during pre-training, and the model is able to generalize well on the Influenza infections in Japan (ILI Japan). 
% Specifically, CAPE performs best in forecasting from 2 weeks to 16 weeks on the Measle dataset, and 1 week to 8 weeks on the ILI Japan dataset.


% \begin{algorithm}
% \caption{Hierarchical Contrastive Loss Optimization with EM}
% \label{alg:hierarchical_contrastive_em}
% \begin{algorithmic}[1]
% \State \textbf{Initialize}:
% \State \quad Model parameters $\theta, \psi$
% \State \quad Environment representations $\mathbf{E}$
% \State \quad Hyperparameters $\alpha$, $\beta$, $\gamma$
% \State \quad Learning rates $\eta_{\theta, \psi}$, $\eta_Z$
% \Repeat
%     \State \textbf{E-Step: Optimize $\mathbf{E}$}
%     \State \quad Freeze $\theta, \psi$
%     \State \quad Set $\alpha, \beta \gets 0$
%     \State \quad Compute $\mathcal{L}_{recon}(\mathbf{x}, \hat{\mathbf{x})}$
%     \State \quad Update $\mathbf{E}^{t+1} \gets \mathbf{E} - \eta_{\mathbf{E}} \nabla_Z \mathcal{L}_{Sup}$
    
%     \State \textbf{M-Step: Optimize $\theta$}
%     \State \quad Set $\alpha$ to predefined values
%     % \State \quad Compute embeddings: $H = \text{SelfAttention}(X)$
%     % \State \quad Estimate environments: $E^{(l)} = g_\phi^{(l)}(H^{(l)}, Z)$
%     % \State \quad Compute final representations: $X^{(L)} = g_\theta(X)$

%     \State \quad Compute $\mathcal{L}_{final}(\mathbf{x}, \hat{\mathbf{x}}, \mathbf{E})$
%     \State \quad Update $(\theta, \psi) \gets (\theta, \psi) - \eta_{\theta, \psi} \nabla_{\theta, \psi} \mathcal{L}_{final}$
% \Until{Convergence}
% \end{algorithmic}
% \end{algorithm}






% \begin{proof}
% \label{proof: l2_categorical_detailed}

% We aim to demonstrate that minimizing the Kullback-Leibler (KL) divergence between successive categorical distributions \( q_\phi^{t} \) and \( q_\phi^{t+1} \) is approximately equivalent to minimizing the squared difference between their parameter vectors \( \phi^{t} \) and \( \phi^{t+1} \). Specifically, we intend to show that:
% \[
% \mathcal{L}_{\text{KL}} = \text{KL}\left(q_\phi^{t}(Z \mid X) \parallel q_\phi^{t+1}(Z \mid X)\right) \approx \| \phi^{t} - \phi^{t+1} \|^2.
% \]
% Assume that \( q_\phi(Z \mid X) \) is a categorical distribution parameterized by \( \phi \), where the probabilities for each category \( i \) are obtained via a Softmax activation applied to logits \( s_i \). Specifically, the logits are defined as:
% \[
% s_i = \mathbf{W}_k^{(l)} \mathbf{e}^k + b_i,
% \]
% where \( \mathbf{W}_k^{(l)} \) is the weight matrix at layer \( l \), \( \mathbf{e}^k \) is the input embedding, and \( b_i \) is the bias for category \( i \). The probability for category \( i \) is then:
% \[
% \pi_i = \frac{\exp(s_i)}{\sum_{j} \exp(s_j)}.
% \]

% Consider a small perturbation in the parameters \( \phi \), specifically a change in the weight matrix \( \mathbf{W}_k^{(l)} \):
% \[
% \mathbf{W}_k^{(l)} \rightarrow \mathbf{W}_k^{(l)} + \Delta \mathbf{W}_k^{(l)}.
% \]
% This induces a change in the logits:
% \[
% \Delta s_i = \Delta \mathbf{W}_k^{(l)} \cdot \mathbf{e}^k,
% \]
% which is linear with respect to \( \Delta \mathbf{W}_k^{(l)} \) and \( \mathbf{e}^k \). Consequently, small changes in \( \mathbf{W}_k^{(l)} \) result in proportionally small changes in \( s_i \).

% The Softmax function relates these logits to the categorical probabilities \( \pi_i \). The derivative of \( \pi_i \) with respect to \( s_j \) is:
% \[
% \frac{\partial \pi_i}{\partial s_j} = \pi_i (\delta_{ij} - \pi_j),
% \]
% where \( \delta_{ij} \) is the Kronecker delta. Therefore, a small change \( \Delta s_j \) in \( s_j \) leads to:
% \[
% \Delta \pi_i \approx \sum_{j} \frac{\partial \pi_i}{\partial s_j} \Delta s_j = \pi_i (1 - \pi_i) \Delta s_i - \sum_{j \neq i} \pi_i \pi_j \Delta s_j.
% \]
% This indicates that \( \Delta \pi_i \) scales with \( \Delta s_j \), ensuring that changes in probabilities are bounded and proportionate to parameter changes.

% For small parameter changes, we can approximate the KL divergence between the two categorical distributions using a second-order Taylor expansion around \( q_\phi^{t} \). The KL divergence is defined as:
% \[
% \text{KL}\left(q_\phi^{t} \parallel q_\phi^{t+1}\right) = \sum_{i} \pi_i^{t} \log \left( \frac{\pi_i^{t}}{\pi_i^{t+1}} \right).
% \]
% Expanding \( \log \left( \frac{\pi_i^{t}}{\pi_i^{t+1}} \right) \) around \( \pi_i^{t} \) using the Taylor series for \( \log(1 + x) \) where \( x = -\frac{\Delta \pi_i}{\pi_i^{t}} \) and keeping terms up to second order, we obtain:
% \begin{equation}
% \small
% \begin{aligned}
% \log \left( \frac{\pi_i^{t}}{\pi_i^{t+1}} \right) &= \log \left( 1 + \frac{\pi_i^{t} - \pi_i^{t+1}}{\pi_i^{t}} \right) \\
% &= \log \left( 1 - \frac{\Delta \pi_i}{\pi_i^{t}} \right) \\
% &\approx -\frac{\Delta \pi_i}{\pi_i^{t}} - \frac{1}{2} \left( \frac{\Delta \pi_i}{\pi_i^{t}} \right)^2.
% \end{aligned}
% \end{equation}
% Substituting this into the KL divergence expression and ignoring higher-order terms (since \( \Delta \pi_i \) is small), we get:
% \begin{equation}
% \small
% \begin{aligned}
%     \text{KL}\left(q_\phi^{t} \parallel q_\phi^{t+1}\right) &\approx \sum_{i} \pi_i^{t} \left( -\frac{\Delta \pi_i}{\pi_i^{t}} - \frac{1}{2} \left( \frac{\Delta \pi_i}{\pi_i^{t}} \right)^2 \right) \\
%     &= -\sum_{i} \Delta \pi_i - \frac{1}{2} \sum_{i} \frac{(\Delta \pi_i)^2}{\pi_i^{t}}.
% \end{aligned}
% \end{equation}


% Since \( \sum_{i} \Delta \pi_i = 0 \) (as probabilities sum to one), the first term vanishes, leaving:
% \[
% \text{KL}\left(q_\phi^{t} \parallel q_\phi^{t+1}\right) \approx \frac{1}{2} \sum_{i} \frac{(\Delta \pi_i)^2}{\pi_i^{t}}.
% \]
% Substituting the expression for \( \Delta \pi_i \) from above and noting that \( \Delta s_i \) is linear in \( \Delta \phi \), we observe that the KL divergence is a quadratic function of \( \Delta \phi \). Therefore, for small \( \Delta \phi \), the KL divergence can be approximated as:
% \[
% \mathcal{L}_{\text{KL}} \approx \frac{1}{2} \sum_{i} \frac{(\Delta \pi_i)^2}{\pi_i^{t}} \propto \| \Delta \phi \|^2 = \| \phi^{t} - \phi^{t+1} \|^2.
% \]
% This approximation establishes that minimizing the KL divergence between successive distributions is approximately equivalent to minimizing the squared difference between their parameter vectors.

% Incorporating weight decay, which adds an L2 penalty to the loss function, the parameter update rule becomes:
% \[
% \phi^{t+1} = \phi^{t} - \alpha \nabla_\phi \mathcal{L}_{\text{original}} - \alpha \lambda \phi^{t},
% \]
% where \( \alpha \) is the learning rate and \( \lambda \) is the weight decay coefficient. The change in parameters is thus:
% \[
% \Delta \phi = \alpha (\nabla_\phi \mathcal{L}_{\text{original}} + \lambda \phi^{t}),
% \]
% and the squared norm of this change is:
% \[
% \| \Delta \phi \|^2 = \alpha^2 \| \nabla_\phi \mathcal{L}_{\text{original}} + \lambda \phi^{t} \|^2.
% \]
% As training converges, the gradient of the original loss \( \nabla_\phi \mathcal{L}_{\text{original}} \) approaches zero, leading to:
% \[
% \mathcal{L}_{\text{KL}} \approx \alpha^2 \lambda^2 \| \phi^{t} \|^2.
% \]
% This demonstrates that weight decay, through the L2 norm of the parameters, effectively controls and minimizes the KL divergence between successive categorical distributions. Therefore, minimizing the KL divergence is approximately equivalent to minimizing the squared difference between the parameter vectors, with weight decay ensuring this minimization by regularizing the parameter norms.

% \end{proof}