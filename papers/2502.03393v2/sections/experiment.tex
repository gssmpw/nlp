% \begin{table}[ht]
% \centering
% \caption{Performance comparison of various methods across datasets.}
% \begin{tabular}{lccccccccccccccc}
% \toprule
% \textbf{Dataset} & \textbf{Reduction rate (\%)} & \multicolumn{4}{c}{\textbf{Coreset}} & \multicolumn{1}{c}{\textbf{Coarsening}} & \multicolumn{7}{c}{\textbf{Condensation}} & \textbf{Whole} \\
% \cmidrule(lr){3-6} \cmidrule(lr){7-7} \cmidrule(lr){8-14}
%  & & Cent-D & Cent-P & Random & Herding & K-Center & VNG & GEOM & SFGC & CGDM & GCondX & GCond & DosCond & MSGC & SGDD \\
% \midrule
% CiteSeer & 0.36 & 42.86 & 37.78 & 35.37 & 43.73 & 41.43 & 49.75 & 66.14 & 67.61 & 66.27 & 60.65 & 67.79 & 70.05 & 69.41 & 60.24 & 71.57 \\
%  & 0.90 & 58.87 & 52.83 & 50.71 & 59.24 & 51.15 & 69.56 & 66.67 & 70.70 & 70.27 & 71.27 & 69.89 & 72.08 & 70.25 & 70.83 & 72.6 \\
%  & 1.80 & 62.89 & 63.37 & 62.62 & 66.56 & 59.04 & 74.54 & 73.03 & 72.30 & 72.08 & 68.88 & 69.35 & 72.21 & 69.55 \\
% \midrule
% Cora & 0.50 & 57.79 & 58.44 & 35.14 & 51.68 & 44.64 & 75.94 & 70.40 & 78.14 & 75.11 & 79.21 & 79.74 & 80.17 & 80.65 & 80.54 & 81.15 \\
%  & 1.30 & 66.45 & 65.83 & 63.43 & 68.99 & 63.28 & 75.87 & 74.48 & 82.29 & 79.55 & 80.86 & 78.67 & 80.81 & 80.85 & 80.29 & 81.5 \\
%  & 2.60 & 75.79 & 75.64 & 72.24 & 73.77 & 70.55 & 75.76 & 76.03 & 82.82 & 80.54 & 80.68 & 78.60 & 80.81 & 81.15 & 80.94 & 81.04 \\
% \bottomrule
% \end{tabular}
% \end{table}
% \toprule
% \multirow{2}{*}{\textbf{Dataset}} &\multirow{2}{*}{\textbf{Horizon}} &\multicolumn{1}{c}{\textbf{Statistical Model}} &\multicolumn{2}{c}{\textbf{RNN-Based}} &\multicolumn{1}{c}{\textbf{MLP-Based}} &\multicolumn{3}{c}{\textbf{Transformer-Based}} &\multicolumn{3}{c}{\textbf{Pre-trained Model}} &\multirow{3}{*}{\textbf{CAPE}} \\
%     \cmidrule(lr){3-3} \cmidrule(lr){4-5} \cmidrule(lr){6-6} \cmidrule(lr){7-9} \cmidrule(lr){10-12} \cmidrule(lr){12-12}
%     & & \textbf{ARIMA} 
%     & \textbf{LSTM} & \textbf{GRU} 
%     & \textbf{Dlinear} 
%     & \textbf{Informer} & \textbf{Autoformer} & \textbf{Fedformer}
%     & \textbf{PEM} & \textbf{MOMENT} & \textbf{PatchTST} 
%     &  \\
% \midrule


\begin{table*}[t]
    \centering
    \caption{Univariate forecasting results with horizons ranging from 1 to 16 future steps. The lookback window length is set to 36 and all models are evaluated using MSE. Note that performance rankings are distinguished by \textit{color coding: \cellcolor{low1}{\color{red} Best},  \cellcolor{low2}{\color{green} Second Best}, \cellcolor{low3}{\color{yellow} Third Best}. } $\Delta (\%)$ stands for the relative improvement of CAPE over the baselines in terms of average MSE over all horizons.}
    \label{tab: baselines}
    \small
    \resizebox{.9\textwidth}{!}{%
\begin{tabular}{llcccccccccccc}
    \toprule
    \multirow{4}{*}{\textbf{Dataset}} & \multirow{4}{*}{\textbf{Horizon}} 
    & \multirow{3}{*}{\textit{Statistical Model}} & \multicolumn{2}{c}{\multirow{3}{*}{\textit{RNN-Based}}}  & \multirow{3}{*}{\textit{MLP-Based}} 
    & \multicolumn{6}{c}{\textit{Transformer-Based}} & \multirow{4}{*}{\textbf{CAPE}} \\
    \cmidrule(lr){7-12}
    & & \multirow{4}{*}{\textbf{ARIMA}}
    & \multirow{4}{*}{\textbf{LSTM}} & \multirow{4}{*}{\textbf{GRU}}
    & \multirow{4}{*}{\textbf{Dlinear}}
    & \multicolumn{3}{c|}{\textit{Non-Pre-trained}} & \multicolumn{3}{c}{\textit{Pre-trained}} &  \\
    \cmidrule(lr){3-3} \cmidrule(lr){4-5} \cmidrule(lr){6-6} \cmidrule(lr){7-12} \cmidrule(lr){7-9} \cmidrule(lr){10-12}
    & & 
    & 
    & 
    & 
    & \textbf{Informer} & \textbf{Autoformer} & \textbf{Fedformer} 
    & \textbf{PEM} & \textbf{MOMENT} & \textbf{PatchTST} 
    &  \\
    \midrule
    %%%%%%%%%%%%%%%%%%%%%%%%%%% ILI USA %%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \multirow{7}{*}{ILI USA} 
        & 1  & \cellcolor{low1}0.138 & 0.338 & 0.259 & 0.220 
              & \cellcolor{low3}0.175 & 0.457 & 0.368 & 0.179 
              & 0.269 & 0.195 & \cellcolor{low2}0.155 \\[2pt]
        & 2  & \cellcolor{low2}0.203 & 0.377 & 0.301 & 0.247 
              & 0.370 & 0.710 & 0.380 & \cellcolor{low3}0.226 
              & 0.321 & 0.264 & \cellcolor{low1}0.200 \\[2pt]
        & 4  & \cellcolor{low3}0.354 & 0.458 & 0.386 & 0.376 
              & 0.517 & 0.670 & 0.433 & \cellcolor{low2}0.304 
              & 0.397 & 0.385 & \cellcolor{low1}0.270 \\[2pt]
        & 8  & 0.701 & 0.579 & 0.529 & \cellcolor{low2}0.506 
              & 0.597 & 0.842 & 0.570 & 0.538 
              & \cellcolor{low3}0.510 & 0.535 & \cellcolor{low1}0.404 \\[2pt]
        & 16 & 1.121 & 0.691 & 0.626 & 0.617 
              & 0.812 & 0.835 & 0.701 & \cellcolor{low3}0.570 
              & 0.610 & \cellcolor{low1}0.485 & \cellcolor{low2}0.516 \\[2pt]
        %%% Avg row:
        & \textbf{Avg} 
          & 0.503 & 0.489 & 0.420 & \cellcolor{low3}0.393 
          & 0.494 & 0.703 & 0.490 & \cellcolor{low2}0.363 
          & 0.421 & 0.373 & \cellcolor{low1}\textbf{\underline{0.309}} \\
        %%% Improvement row:
        & \textbf{$\Delta$ (\%)} 
          & 38.57\% & 36.81\% & 26.43\% & 21.37\% & 37.45\% 
          & 56.05\% & 36.94\% & 14.88\% & 26.60\% & 17.16\% & - \\
    \midrule        
    %%%%%%%%%%%%%%%%%%%%%%%%%%% ILI Japan %%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \multirow{7}{*}{ILI Japan} 
        & 1  
          & \cellcolor{low3}0.358 & 1.426 & 1.213 & 1.016 
          & 0.405 & 0.515 & 0.525 & 0.470 
          & \cellcolor{low2}0.325 & 0.413 & \cellcolor{low1}0.290 \\[2pt]
        & 2  
          & 0.772 & 1.635 & 1.458 & 1.294 
          & \cellcolor{low3}0.666 & 0.855 & 1.151 & 0.755 
          & \cellcolor{low2}0.586 & 0.698 & \cellcolor{low1}0.535 \\[2pt]
        & 4  
          & 1.720 & 1.975 & 1.870 & 1.758 
          & 1.234 & \cellcolor{low3}1.150 & 1.455 & 1.207 
          & \cellcolor{low2}1.082 & 1.147 & \cellcolor{low1}0.944 \\[2pt]
        & 8  
          & 2.981 & 2.373 & 2.365 & 2.285 
          & \cellcolor{low2}1.688 & 1.866 & 2.012 & 1.810 
          & \cellcolor{low3}1.706 & 1.708 & \cellcolor{low1}1.650 \\[2pt]
        & 16 
          & 2.572 & 2.023 & 2.010 & 2.007 
          & \cellcolor{low1}1.551 & 2.654 & 4.027 & \cellcolor{low3}1.766 
          & 2.054 & \cellcolor{low2}1.688 & 1.911 \\[2pt]
        %%% Avg row:
        & \textbf{Avg} 
          & 1.680 & 1.886 & 1.783 & 1.672 
          & \cellcolor{low2}1.109 & 1.408 & 1.834 & 1.202 
          & 1.151 & \cellcolor{low3}1.131 & \cellcolor{low1}\textbf{\underline{1.066}} \\
        %%% Improvement row:
        & \textbf{$\Delta$ (\%)} 
          & 36.55\% & 43.48\% & 40.21\% & 36.24\% & 3.88\% 
          & 24.29\% & 41.88\% & 11.31\% & 7.38\% & 5.74\% & - \\
    \midrule
    %%%%%%%%%%%%%%%%%%%%%%%%%%% Measles %%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \multirow{7}{*}{Measles} 
          & 1  
            & \cellcolor{low2}0.071 & 0.182 & 0.143 & 0.133 
            & \cellcolor{low1}0.066 & 0.203 & 0.321 & 0.085 
            & 0.113 & 0.094 & \cellcolor{low3}0.083 \\[2pt]
          & 2  
            & \cellcolor{low2}0.120 & 0.223 & 0.176 & 0.184 
            & 0.153 & 0.257 & 0.817 & 0.128 
            & 0.138 & \cellcolor{low3}0.127 & \cellcolor{low1}0.112 \\[2pt]
          & 4  
            & 0.225 & 0.310 & 0.258 & 0.296 
            & 0.288 & 0.331 & 0.226 & 0.213 
            & \cellcolor{low2}0.186 & \cellcolor{low3}0.205 & \cellcolor{low1}0.161 \\[2pt]
          & 8  
            & 0.483 & 0.567 & 0.471 & 0.512 
            & 0.501 & 0.671 & 0.403 & 0.417 
            & \cellcolor{low2}0.351 & \cellcolor{low3}0.377 & \cellcolor{low1}0.310 \\[2pt]
          & 16 
            & 1.052 & 1.110 & 1.013 & 1.088 
            & 0.904 & 1.115 & \cellcolor{low3}0.754 & 0.806 
            & 0.818 & \cellcolor{low1}0.722 & \cellcolor{low2}0.752 \\[2pt]
        %%% Avg row:
        & \textbf{Avg} 
          & 0.390 & 0.478 & 0.412 & 0.443 
          & 0.382 & 0.515 & 0.504 & 0.330 
          & \cellcolor{low3}0.321 & \cellcolor{low2}0.305 
          & \cellcolor{low1}\textbf{\underline{0.269}} \\
        %%% Improvement row:
        & \textbf{$\Delta$ (\%)} 
          & 31.03\% & 43.72\% & 34.71\% & 39.28\% & 29.58\% 
          & 47.77\% & 46.63\% & 18.49\% & 16.20\% & 11.80\% & - \\
    \midrule
    %%%%%%%%%%%%%%%%%%%%%%%%%%% Dengue %%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \multirow{7}{*}{Dengue} 
      & 1  
        & 0.244 & 0.250 & 0.261 & \cellcolor{low2}0.224 
        & 0.255 & 0.525 & 0.521 & \cellcolor{low3}0.225 
        & 0.420 & 0.240 & \cellcolor{low1}0.223 \\[2pt]
      & 2  
        & 0.373 & 0.343 & 0.343 & \cellcolor{low3}0.316 
        & 0.450 & 0.807 & 0.670 & \cellcolor{low2}0.314 
        & 0.579 & 0.334 & \cellcolor{low1}0.302 \\[2pt]
      & 4  
        & 0.696 & \cellcolor{low3}0.564 & 0.579 & \cellcolor{low1}0.560 
        & 0.798 & 0.957 & 0.766 & 0.571 
        & 0.661 & 0.586 & \cellcolor{low2}0.561 \\[2pt]
      & 8  
        & 1.732 & \cellcolor{low2}1.168 & \cellcolor{low3}1.183 & 1.256 
        & 1.239 & 1.684 & 1.539 & 1.223 
        & 1.308 & 1.292 & \cellcolor{low1}1.046 \\[2pt]
      & 16 
        & 4.082 & 3.876 & 3.315 & 3.109 
        & 2.659 & 3.364 & 2.934 & 3.376 
        & \cellcolor{low2}2.532 & \cellcolor{low3}2.537 & \cellcolor{low1}2.509 \\[2pt]
        %%% Avg row:
        & \textbf{Avg} 
          & 1.426 & 1.240 & 1.136 & 1.093 
          & \cellcolor{low3}1.080 & 1.467 & 1.286 & 1.142 
          & 1.100 & \cellcolor{low2}1.000 & \cellcolor{low1}\textbf{\underline{0.892}} \\
        %%% Improvement row:
        & \textbf{$\Delta$ (\%)} 
          & 37.45\% & 28.06\% & 21.48\% & 18.39\% 
          & 17.41\% & 39.20\% & 30.64\% & 21.89\% 
          & 18.91\% & 10.80\% & - \\
    \midrule
    %%%%%%%%%%%%%%%%%%%%%%%%%%% Covid %%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \multirow{7}{*}{Covid} 
      & 1  
        & 33.780 & \cellcolor{low2}22.592 & \cellcolor{low3}22.009 & 23.811 
        & 34.161 & 42.049 & 28.130 & 25.088 
        & 32.376 & 23.645 & \cellcolor{low1}21.548 \\[2pt]
      & 2  
        & 33.193 & 23.460 & \cellcolor{low2}22.542 & 24.809 
        & 24.883 & 30.631 & 28.059 & \cellcolor{low3}23.123 
        & 35.418 & 25.047 & \cellcolor{low1}22.224 \\[2pt]
      & 4  
        & 32.482 & 24.729 & 24.816 & 26.345 
        & 31.328 & 41.029 & 29.432 & \cellcolor{low2}23.889 
        & 36.251 & \cellcolor{low3}24.224 & \cellcolor{low1}22.476 \\[2pt]
      & 8  
        & 36.573 & \cellcolor{low2}31.019 & 33.934 & 33.081 
        & 35.964 & 55.812 & 41.791 & \cellcolor{low3}31.217 
        & 40.429 & 31.548 & \cellcolor{low1}28.403 \\[2pt]
      & 16 
        & \cellcolor{low3}42.910 & 43.820 & \cellcolor{low2}41.432 & 47.561 
        & 50.244 & 47.993 & 69.976 & 51.265 
        & 52.590 & 43.309 & \cellcolor{low1}40.555 \\[2pt]
        %%% Avg row:
        & \textbf{Avg} 
          & 35.787 & \cellcolor{low3}29.124 & \cellcolor{low2}28.947 & 31.121 
          & 35.316 & 43.503 & 39.478 & 30.917 
          & 39.413 & 29.555 & \cellcolor{low1}\textbf{\underline{26.559}} \\
        %%% Improvement row:
        & \textbf{$\Delta$ (\%)} 
          & 25.79\% & 8.81\% & 8.25\% & 14.66\% 
          & 24.80\% & 38.95\% & 32.72\% & 14.10\% 
          & 32.61\% & 10.14\% & - \\
    \bottomrule
\end{tabular}
    }
% \vskip -1.5em
\end{table*}


\begin{table*}[t]
    \centering
    \caption{Few-shot learning results with horizons ranging from 1 to 16 future steps. The length of the lookback window is set to 36. Each model is evaluated after being trained on 20\%, 40\%, 60\%, and 80\% of the full training data. $\Delta (\%)$ stands for the relative improvement of the model after training with 20\% more data in terms of average MSE over all horizons. The full result is shown in Appendix~\ref{Append_few_shot}.}
    \label{tab: few_shot}
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{l*{5}{c}*{5}{c}*{5}{c}*{5}{c}*{5}{c}}
        \toprule
        \multirow{2}{*}{\textbf{Dataset/Model}} &  \multicolumn{5}{c}{\textbf{CAPE}} & \multicolumn{5}{c}{\textbf{PatchTST}} & \multicolumn{5}{c}{\textbf{Dlinear}} & \multicolumn{5}{c}{\textbf{MOMENT}} & \multicolumn{5}{c}{\textbf{PEM}} \\
        \cmidrule(lr){2-6} \cmidrule(lr){7-11} \cmidrule(lr){12-16} \cmidrule(lr){17-21} \cmidrule(lr){22-26}
         & \textbf{20\%} & \textbf{40\%} & \textbf{60\%} & \textbf{80\%} & \textbf{100\%} 
        & \textbf{20\%} & \textbf{40\%} & \textbf{60\%} & \textbf{80\%} & \textbf{100\%}
        & \textbf{20\%} & \textbf{40\%} & \textbf{60\%} & \textbf{80\%} & \textbf{100\%}
        & \textbf{20\%} & \textbf{40\%} & \textbf{60\%} & \textbf{80\%} & \textbf{100\%}
        & \textbf{20\%} & \textbf{40\%} & \textbf{60\%} & \textbf{80\%} & \textbf{100\%} \\
        \midrule
        \multirow{1}{*}{ILI USA} 
             & \textbf{2.121} & \textbf{1.400} & \textbf{0.760} & \cellcolor{low1}\textbf{0.369} & \cellcolor{low1}\textbf{0.309} 
            & \textbf{2.114} & \textbf{1.219} & \textbf{0.677} & \textbf{0.401} & \textbf{0.373} 
            & \textbf{2.822} & \textbf{1.594} & \textbf{0.816} & \textbf{0.412} & \textbf{0.346} 
            & \textbf{3.990} & \textbf{1.847} & \textbf{0.913} & \textbf{0.459} & \textbf{0.381} 
            & \textbf{2.143} & \textbf{1.261} & \textbf{0.681} & \textbf{0.419} & \textbf{0.353} \\
             % \cmidrule{2-26}
             \multirow{1}{*}{$\Delta$(\%)} 
             & - & 33.99\% & 45.71\% & 51.45\% & 16.26\% 
             & - & 42.34\% & 44.45\% & 40.77\% & 6.98\% 
             & - & 43.53\% & 48.78\% & 49.51\% & 16.02\% 
             & - & 53.69\% & 50.58\% & 49.72\% & 17.00\% 
             & - & 41.13\% & 46.00\% & 38.33\% & 15.76\% \\
        \midrule
        \multirow{1}{*}{Dengue} 
             & \textbf{13.335} & \cellcolor{low1}\textbf{6.386} & \cellcolor{low1}\textbf{2.356} & \cellcolor{low1}\textbf{1.511} & \cellcolor{low1}\textbf{0.892} 
            & \textbf{13.712} & \textbf{7.304} & \textbf{2.771} & \textbf{1.678} & \textbf{0.984} 
            & \textbf{15.828} & \textbf{8.420} & \textbf{2.850} & \textbf{1.748} & \textbf{1.080} 
            & \textbf{15.697} & \textbf{7.536} & \textbf{2.816} & \textbf{1.733} & \textbf{1.358} 
            & \textbf{12.90} & \textbf{7.055} & \textbf{2.745} & \textbf{1.707} & \textbf{0.964} \\
             % \cmidrule{2-26}
             \multirow{1}{*}{$\Delta$(\%)}    
             & - & 52.07\% & 63.12\% & 35.87\% & 40.95\% 
             & - & 46.72\% & 62.06\% & 39.43\% & 41.39\% 
             & - & 46.81\% & 66.15\% & 38.64\% & 38.19\% 
             & - & 52.00\% & 62.63\% & 38.45\% & 21.65\% 
             & - & 45.32\% & 61.09\% & 37.79\% & 43.51\% \\
        \midrule
        \multirow{1}{*}{Measles} 
             & \cellcolor{low1}\textbf{0.483} & \cellcolor{low1}\textbf{0.600} & \cellcolor{low1}\textbf{0.381} & \cellcolor{low1}\textbf{0.285} & \cellcolor{low1}\textbf{0.269}
            & \textbf{0.863} & \textbf{0.834} & \textbf{0.448} & \textbf{0.359} & \textbf{0.306} 
            & \textbf{1.194} & \textbf{1.130} & \textbf{0.602} & \textbf{0.478} & \textbf{0.394} 
            & \textbf{1.661} & \textbf{0.915} & \textbf{0.425} & \textbf{0.471} & \textbf{0.500} 
            & \textbf{0.670} & \textbf{0.896} & \textbf{0.430} & \textbf{0.364} & \textbf{0.306} \\
             % \cmidrule{2-26}
             \multirow{1}{*}{$\Delta$(\%)}  
             & - & -24.22\% & 36.50\% & 25.20\% & 5.61\% 
             & - & 3.36\% & 46.25\% & 19.91\% & 14.81\% 
             & - & 5.36\% & 46.64\% & 20.63\% & 17.58\% 
             & - & 44.91\% & 53.55\% & -10.59\% & -6.16\% 
             & - & -33.87\% & 51.91\% & 15.35\% & 15.93\% \\
        \bottomrule
    \end{tabular}
    }
    \vskip -1em
\end{table*}

% \begin{table*}[hpt]
%     \centering
%     \caption{Few-shot learning results with horizons ranging from 1 to 16 future steps. The length of the lookback window is set to 36. Each model is evaluated after being trained on 20\%, 40\%, 60\% and 80\% of the full training data. The full result is shown in Appendix~\ref{Append_few_shot}.}
%     \label{tab: few_shot}
%     \resizebox{\textwidth}{!}{%
%     \begin{tabular}{l*{5}{c}*{5}{c}*{5}{c}*{5}{c}*{5}{c}}
%         \toprule
%         \multirow{2}{*}{\textbf{Dataset/Model}} &  \multicolumn{5}{c}{\textbf{CAPE}} & \multicolumn{5}{c}{\textbf{PatchTST}} & \multicolumn{5}{c}{\textbf{Dlinear}} & \multicolumn{5}{c}{\textbf{MOMENT}} & \multicolumn{5}{c}{\textbf{PEM}} \\
%         \cmidrule(lr){2-6} \cmidrule(lr){7-11} \cmidrule(lr){12-16} \cmidrule(lr){17-21} \cmidrule(lr){22-26}
%          & \textbf{20\%} & \textbf{40\%} & \textbf{60\%} & \textbf{80\%} & \textbf{100\%} 
%         & \textbf{20\%} & \textbf{40\%} & \textbf{60\%} & \textbf{80\%} & \textbf{100\%}
%         & \textbf{20\%} & \textbf{40\%} & \textbf{60\%} & \textbf{80\%} & \textbf{100\%}
%         & \textbf{20\%} & \textbf{40\%} & \textbf{60\%} & \textbf{80\%} & \textbf{100\%}
%         & \textbf{20\%} & \textbf{40\%} & \textbf{60\%} & \textbf{80\%} & \textbf{100\%} \\
%         \midrule
%         \multirow{1}{*}{ILI USA} 
%              & \textbf{2.121} & \textbf{1.400} & \textbf{0.760} & \cellcolor{low1}\textbf{0.369} & \cellcolor{low1}\textbf{0.309} 
%             & \textbf{2.114} & \textbf{1.219} & \textbf{0.677} & \textbf{0.401} & \textbf{0.373} 
%             & \textbf{2.822} & \textbf{1.594} & \textbf{0.816} & \textbf{0.412} & \textbf{0.346} 
%             & \textbf{3.990} & \textbf{1.847} & \textbf{0.913} & \textbf{0.459} & \textbf{0.381} 
%             & \textbf{2.143} & \textbf{1.261} & \textbf{0.681} & \textbf{0.419} & \textbf{0.353} \\
%         \midrule
%         \multirow{1}{*}{Dengue} 
%              & \textbf{13.335} & \cellcolor{low1}\textbf{6.386} & \cellcolor{low1}\textbf{2.356} & \cellcolor{low1}\textbf{1.511} & \cellcolor{low1}\textbf{0.892} 
%             & \textbf{13.712} & \textbf{7.304} & \textbf{2.771} & \textbf{1.678} & \textbf{0.984} 
%             & \textbf{15.828} & \textbf{8.420} & \textbf{2.850} & \textbf{1.748} & \textbf{1.080} 
%             & \textbf{15.697} & \textbf{7.536} & \textbf{2.816} & \textbf{1.733} & \textbf{1.358} 
%             & \textbf{12.90} & \textbf{7.055} & \textbf{2.745} & \textbf{1.707} & \textbf{0.964} \\
%         \midrule
%         \multirow{1}{*}{Measles} 
%              & \cellcolor{low1}\textbf{0.483} & \cellcolor{low1}\textbf{0.600} & \cellcolor{low1}\textbf{0.381} & \cellcolor{low1}\textbf{0.285} & \cellcolor{low1}\textbf{0.269}
%             & \textbf{0.863} & \textbf{0.834} & \textbf{0.448} & \textbf{0.359} & \textbf{0.306} 
%             & \textbf{1.194} & \textbf{1.130} & \textbf{0.602} & \textbf{0.478} & \textbf{0.394} 
%             & \textbf{1.661} & \textbf{0.915} & \textbf{0.425} & \textbf{0.471} & \textbf{0.500} 
%             & \textbf{0.670} & \textbf{0.896} & \textbf{0.430} & \textbf{0.364} & \textbf{0.306} \\
%         \bottomrule
%     \end{tabular}
%     }
% \end{table*}

% \begin{table}[h]
%     \centering
%     \caption{Zero-shot performance with a lookback window length of 12. All results are averaged over 4 weeks or days in the future. We also incorporated a Naïve approach that simply uses the last observed value as the future predictions. Note that performance rankings are distinguished by \textit{color coding: \cellcolor{low1}{\color{red} Best},  \cellcolor{low2}{\color{green} Second Best}, \cellcolor{low3}{\color{yellow} Third Best}.}}
%     % \textit{Note: \cellcolor{low1}{\color{red} Best},  \cellcolor{low3}{\color{green} Second Best}, \cellcolor{low2}{\color{yellow} Third Best}}.}
%     \label{tab:zero_shot_performance}
%     \scalebox{0.61}{
%     \begin{tabular}{lcccccc}
%             \toprule
%             \textbf{Dataset} & \textbf{CAPE} & \textbf{PatchTST} & \textbf{PEM} & \textbf{MOMENT} & \textbf{Naïve} & \textbf{ARIMA} \\
%             \midrule
%             ILI USA & \cellcolor{low1}\textbf{0.147} & \cellcolor{low2}\textbf{0.164} & \cellcolor{low3}\textbf{0.162} & 0.549 & 0.261 & 0.313   \\
%             ILI Japan & \cellcolor{low1}\textbf{0.705} & \cellcolor{low2}\textbf{0.907} & \cellcolor{low3}\textbf{0.850} & 2.062 & 1.194 & 2.019    \\
%             Measles & \cellcolor{low1}\textbf{0.145} & \cellcolor{low2}\textbf{0.167} & \cellcolor{low3}\textbf{0.159} & 0.533 & 0.194 & 0.258   \\
%             Monkey Pox & \cellcolor{low1}\textbf{0.0004} & \cellcolor{low3}\textbf{0.0005} & \cellcolor{low2}\textbf{0.0005} & 0.0013 & 0.0012 & 0.0014   \\
%             Dengue (mixed) & \cellcolor{low1}\textbf{0.371} & \cellcolor{low2}\textbf{0.427} & \cellcolor{low3}\textbf{0.413} & 1.624 & 0.611 & 0.841   \\
%             RSV & \cellcolor{low1}\textbf{0.834} & \cellcolor{low3}\textbf{1.128} & \cellcolor{low2}\textbf{1.260} & 1.849 & 1.560 & 2.531   \\
%             Covid (daily interval) & \cellcolor{low1}\textbf{5.173} & \cellcolor{low3}\textbf{6.001} & \cellcolor{low2}\textbf{6.320} & 18.881 & 30.350 & 30.315    \\
%             \bottomrule
%         \end{tabular}
%     }
% \end{table}




% \begin{table}[h]
%     \centering
%     \caption{Ablation study of removing components from the CAPE framework.}
%     \label{tab:ablation_study}
%     % \small  % 调整整个表格的字体大小为 small
%     \resizebox{0.8\textwidth}{!}{%
%     \begin{tabular}{@{}l *{18}{S[table-format=1.3]}@{}}
%         \toprule
%         \multirow{4}{*}{\textbf{Horizon}} & 
%         \multicolumn{6}{c}{\textbf{ILI USA}} & 
%         \multicolumn{6}{c}{\textbf{Measles}} & 
%         \multicolumn{6}{c}{\textbf{Dengue}} \\
%         \cmidrule(lr){2-7} \cmidrule(lr){8-13} \cmidrule(lr){14-19}
%          & {1} & {2} & {4} & {8} & {16} & {Avg} 
%          & {1} & {2} & {4} & {8} & {16} & {Avg} 
%          & {1} & {2} & {4} & {8} & {16} & {Avg} \\
%         \midrule
%         CAPE & 0.155 & 0.200 & 0.270 & 0.404 & 0.516 & \textbf{0.309} 
%              & 0.069 & 0.096 & 0.155 & 0.280 & 0.743 & \textbf{0.269} 
%              & 0.218 & 0.301 & 0.540 & 1.193 & 2.210 & \textbf{0.892} \\
%         w/o Env & 0.326 & 0.448 & 0.508 & 0.642 & 0.735 & 0.532 
%                & 0.083 & 0.111 & 0.168 & 0.407 & 0.755 & 0.304
%                & 0.232 & 0.316 & 0.484 & 1.089 & 3.622 & 1.149 \\
%         w/o Contrast & 0.174 & 0.241 & 0.335 & 0.492 & 0.570 & 0.363 
%                       & 0.090 & 0.124 & 0.276 & 0.431 & 0.801 & 0.344 
%                       & 0.198 & 0.273 & 0.460 & 1.128 & 3.329 & 1.078 \\
%         w/o Pretrain & 0.158 & 0.202 & 0.283 & 0.408 & 0.545 & 0.319
%                       & 0.074 & 0.113 & 0.223 & 0.402 & 0.816 & 0.326
%                       & 0.210 & 0.276 & 0.449 & 1.115 & 3.759 & 1.162 \\
%         \bottomrule
%     \end{tabular}
%     }
% \end{table}





\section{Experiment}
\subsection{Experiment Setup}
% \textbf{Datasets.} We evaluate the performance of our proposed CAPE model on 5 downstream datasets with different diseases across various locations: the influenza-like illness in the USA (ILI USA)~\cite{cdc_ili_usa} and Japan (ILI Japan)~\cite{cdc_ili_japan}, the novel COVID-19 infections~\cite{dong2020interactive} in the USA, Measle infections in England~\cite{lau2020competing}, and Dengue infections across countries~\cite{opendengue}. Additionally, we incorporated RSV~\cite{cdc_rsv} and Monkey Pox~\cite{cdc_monkeypox} infections in the US for test the zero-shot performance of the pre-trained models.
% A summary of the datasets we used is shown in Table~\ref{tab:downstream_datasets}. All datasets are normalized using z-score normalization and no further pre-processing is performed. To pretrain our model as well as PatchTST and PEM, we manually collect 17 datasets, with a weekly sampling rate, from Project Tycho~\cite{van2018project} and merge the data to the country level for each dataset. A detailed description of the pre-training dataset is shown in Appendix~\ref{Append_A}.
% \wei{descriptions for pre-training dataset?}
\noindent\textbf{Datasets.} For pre-training CAPE, PatchTST, and PEM, we manually collected 17 distinct weekly-sampled diseases from Project Tycho~\cite{van2018project}. For evaluation, we utilize five downstream datasets covering various diseases and locations: ILI USA~\cite{cdc_ili_usa}, ILI Japan~\cite{cdc_ili_japan}, COVID-19 USA~\cite{dong2020interactive}, Measles England~\cite{lau2020competing}, and Dengue across countries~\cite{opendengue}. Additionally, RSV~\cite{cdc_rsv} and Monkey Pox~\cite{cdc_monkeypox} infections in the US are used to test zero-shot performance. More details can be found in Appendix~\ref{Appendix: dataset}. 
% \wei{let's put the dataset table in the appendix}

% \textbf{Baselines.} We include various baselines including simple statistical models (ARIMA), RNN-based models (LSTM and GRU), a linear model (Dlinear), and transformer-based models (Informer, etc.). We also include self-supervised PatchTST, PEM, and a time series foundation model MOMENT to demonstrate the effectiveness of pre-training on epidemic-specific datasets. Due to the limitation of our univariate time series setting, models requiring external knowledge like SIR are not included as baselines.
% \noindent\textbf{Baselines.}\wei{citations for these methods; mention two sets of models: non-pretrained and pretrained?} We compare CAPE with various baselines, including statistical models (ARIMA), RNN-based models (LSTM, GRU), the linear model Dlinear, and transformer-based models (Informer, etc.). Additionally, we evaluate pre-trained models including PatchTST, PEM, and the time series foundation model MOMENT to demonstrate the effectiveness of pre-training on epidemic-specific datasets. 

\noindent\textbf{Baselines.} For baselines, we leverage the models from the comprehensive toolkit \textit{EpiLearn}~\cite{liu2024epilearn}. To provide a comprehensive evaluation, we compare CAPE with two sets of models: \textit{non-pretrained} and \textit{pre-trained}. Non-pretrained models include statistical methods like ARIMA~\cite{panagopoulos2021transfer}, RNN-based~\cite{wang2020time, natarajan2023outbreak} approaches such as LSTM and GRU, the linear model DLinear~\cite{zeng2023transformers}, and transformer-based methods~\cite{wu2021autoformer, zhou2021informer, zhou2022fedformer}. For pre-trained models, we evaluate popular approaches including PatchTST~\cite{nie2022time}, PEM~\cite{kamarthi2023pems}, and a time series foundation model MOMENT~\cite{goswami2024moment}. {More experimental details can be found in Appendix~\ref{Append_B}.}


\iffalse
% \wei{later we may put some of the content in the appendix when shortening the paper}
\textbf{Settings.}  
We adopt an input length of 36~\cite{wu2023timesnet, wang2024tssurvey} and a patch size of 4 for applicable models. For the environment estimator defined in Eq.~\eqref{eq: env_estimator}, a shared weight \( w_k \) is used for all environment representations. All results are evaluated using Mean Squared Error (MSE). 
% and we measure the improvements with the following equation: $\Delta = \frac{\text{MSE}_{base} - \text{MSE}_{target}}{\text{MSE}_{base}} \times 100$, where $\Delta$ is the improvement of \textit{target} (current model) over \textit{base} (comparison model).
More details are provided in Appendix~\ref{Append_B}.
\fi

% \textbf{Reproducibility.} All data and code is available at \url{https://anonymous.4open.science/r/EFM_improve-B0C3/}. \zw{I will update the code later}


\subsection{Baseline Comparison}
We now evaluate the CAPE model under three settings: \textit{fine-tuning}, \textit{few-shot fine-tuning}, and \textit{zero-shot forecasting}.

% In this subsection, we evaluate the CAPE model and compare it with various baselines in three different settings: \textit{fine-tuning}, \textit{few-shot fine-tuning}, and \textit{zero-shot forecasting}.

\subsubsection{Fine-Tuning (Full-Shot Setting)}
% For non-pre-trained models, we directly train the whole model on the training split. For pre-trained models, we perform fine-tuning on the downstream datasets. Specifically, once the model is pre-trained, the task-specific head \(h_\psi\) is transitioned from the pre-training task to the forecasting task, and the entire model together with the new task-specific head are fine-tuned. To evaluate both short-term and long-term performance, we report the MSE of forecasts across horizons ranging from 1 to 16 time steps. From Tabel~\ref{tab: baselines}, we make the following observations:
% \begin{compactenum}[(a)]
%     \item CAPE consistently delivers state-of-the-art performance, achieving the best average results across both short-term and long-term forecasts (1 to 16 steps ahead). Compared to the best baseline model for each dataset, CAPE surpasses them by 9.91\% on average and 14.85\% at most. Compared to the worst baseline model, CAPE is able to surpass them by 45.09\% on average. Also, CAPE achieves the best performance across all horizons on the COVID dataset, demonstrating its effectiveness on novel diseases.
%     \item Models leveraging pre-training—such as PEM, PatchTST, and MOMENT—consistently rank second or third on 4 out of 5 downstream datasets. On average, the best pre-trained model (excluding CAPE) outperforms the best non-pre-trained model on each dataset by 6.223\%, underscoring the effectiveness of pre-training. Among the pre-trained models, PatchTST achieves the highest average performance, surpassing PEM by 5.51\% and MOMENT by 10.45\%. While PEM demonstrates superior performance over PatchTST in some cases, our efforts to reproduce these results were limited due to the lack of publicly available implementation. Additionally, PEM outperforms MOMENT by 4.86\%, indicating that models pre-trained on epidemic-specific datasets tend to perform better than those pre-trained on general-purpose data.
%     \item Among the non-pretrained transformers, Informer consistently achieves the best performance across all datasets compared to other models, surpassing Autoformer and Fedformer by 24.40\% and 17.90\% respectively. This can be attributed to its sparse attention mechanism, which reduces reliance on full attention computations and helps mitigate overfitting. However, Informer still outperforms Dlinear by 1.90\%, which is an MLP-based model with even fewer parameters. This potentially indicates that the careful selection of model size and parameter count plays a crucial role in achieving optimal performance.
%     \item Furthermore, environment modeling proves valuable, as CAPE consistently outperforms PatchTST, which has a similar design in terms of number of layers and attention heads. While both models are pre-trained on the epidemic-specific datasets, CAPE surpasses PatchTST by 11.13\%.
% \end{compactenum}

For non-pre-trained models, we train the entire model on the training split, while for pre-trained models, we fine-tune on downstream datasets by transferring the task-specific head \( h_\psi \) from pre-training to the forecasting task. We evaluate short-term and long-term performance by reporting MSE across horizons from 1 to 16. From Table~\ref{tab: baselines}, we observe:
(a) CAPE achieves the best average MSE across all downstream datasets. It outperforms the best baseline by 9.91\% on average and up to 14.85\%. On the COVID dataset, CAPE performs best across all horizons, showing effectiveness on novel diseases.
(b) Models like PEM, PatchTST, and MOMENT consistently rank second or third on 4 out of 5 downstream datasets. The best pre-trained model (excluding CAPE) outperforms the best non-pre-trained model by 6.223\% on average. Among them, PatchTST has the highest average performance, surpassing PEM by 5.51\% and MOMENT by 10.45\%. Additionally, PEM outperforms MOMENT by 4.86\%, indicating the importance of epidemic-specific pre-training.
(c) Informer consistently outperforms Autoformer and Fedformer by 24.40\% and 17.90\% respectively, due to its sparse attention mechanism that reduces overfitting. Informer also surpasses Dlinear by 1.90\%, suggesting that careful selection of model size and parameters is crucial for optimal performance.
(d) Furthermore, environment modeling proves valuable, as CAPE consistently outperforms PatchTST, which shares a similar design. While both models are pre-trained on the epidemic-specific datasets, CAPE surpasses PatchTST by 11.13\%.

% \begin{compactenum}[(a)]
%     \item CAPE achieves the best average MSE across all downstream datasets. It outperforms the best baseline by 9.91\% on average and up to 14.85\%. On the COVID dataset, CAPE performs best across all horizons, showing effectiveness on novel diseases.
%     \item Models like PEM, PatchTST, and MOMENT consistently rank second or third on 4 out of 5 downstream datasets. The best pre-trained model (excluding CAPE) outperforms the best non-pre-trained model by 6.223\% on average. Among them, PatchTST has the highest average performance, surpassing PEM by 5.51\% and MOMENT by 10.45\%. Additionally, PEM outperforms MOMENT by 4.86\%, indicating the importance of epidemic-specific pre-training.
%     \item Informer consistently outperforms Autoformer and Fedformer by 24.40\% and 17.90\% respectively, due to its sparse attention mechanism that reduces overfitting. Informer also surpasses Dlinear by 1.90\%, suggesting that careful selection of model size and parameters is crucial for optimal performance.
%     \item Furthermore, environment modeling proves valuable, as CAPE consistently outperforms PatchTST, which shares a similar design. While both models are pre-trained on the epidemic-specific datasets, CAPE surpasses PatchTST by 11.13\%.
% \end{compactenum}


\subsubsection{Few-Shot and Zero-Shot Performance} % main table 3
% \wei{these two paragraphs are too short; please enrich them with more details. please check my previous papers to see how to enrich these}
% In the real world, the outbreak of unknown diseases or diseases at new locations could be hard for pure data-driven models to predict, as they only produce a limited amount of data in the beginning. Therefore, it is crucial for epidemic models to have few-shot or zero-shot forecasting ability. In this study, we further shrink the original training data from 100\% to 20\% to simulate the few-shot scenario, as shown in Table~\ref{tab: few_shot}. Compared with the Dlinear model directly trained on the limited data, most pre-trained models, including CAPE, PatchTST, MOMENT, and PEM show superior performance. 

\textbf{Few-Shot Forecasting.} In real-world scenarios, predicting outbreaks of diseases unknown or in new locations is challenging for purely data-driven models due to limited initial data. Thus, few-shot or zero-shot forecasting capabilities are essential for epidemic models. To simulate a few-shot scenario, we reduce the original training data from 100\% to [20\%, 40\%, 60\%, 80\%]. We report the average MSE across 1 to 16 time steps. From Table~\ref{tab: few_shot}, we make the following observations: (a) With an increasing volume of training materials, the performance of all models consistently improves. (b) CAPE achieves the best performance in most scenarios, demonstrating the superior few-shot ability. (c) Compared with models pre-trained on epidemic-specific datasets, Dlinear failed to achieve better performance when only 20\% of training data is available. However, Dlinear is able to outperform MOMENT on ILI USA and Measles datasets when both models are trained or fine-tuned using 20\% training data, which indicates the importance of pre-training. (d) Though CAPE achieves the best average performance on the ILI USA dataset when the training material is reduced, it achieves a good performance in short-term forecasting from 1 to 4 weeks (see Appendix~\ref{Append_few_shot}).


% \begin{compactenum}[]
%     \item (a) With an increasing volume of training materials, the performance of all models consistently improves.
%     \item (b) CAPE achieves the best performance in most scenarios, demonstrating the superior few-shot ability.
%     \item (c) Comparing models pre-trained on epidemic-specific datasets (CAPE, PatchTST, and PEM), Dlinear failed to achieve better performance when only 20\% of training data is available. However, Dlinear is able to outperform MOMENT on ILI USA and Measles datasets when both models are trained or fine-tuned using 20\% training data, which indicates the importance of pre-training.
%     \item (d) Though CAPE achieve the best average performance on the ILI USA dataset when the training material is reduced, it achieves a better result in short-term forecasting from 1 to 4 weeks (see Appendix~\ref{Append_few_shot}).
% \end{compactenum}
% \begin{enumerate}[label=(\roman*), nosep, leftmargin=*]
%     \item With an increasing volume of materials for training or fine-tuning, the performance of all models consistently improves.
%     \item CAPE achieves the best performance in most scenarios, demonstrating the superior few-shot ability.
%     \item Comparing models pre-trained on epidemic-specific datasets (CAPE, PatchTST, and PEM), Dlinear failed to achieve better performance when only 20\% of training data is available. However, Dlinear is able to outperform MOMENT on ILI USA and Measles datasets when both models are trained or fine-tuned using 20\% training data, which indicates the important role of pre-training materials.
%     \item Though CAPE achieve the best average performance on the ILI USA dataset when the training material is reduced, it achieves a better result in short-term forecasting from 1 to 4 weeks (see Appendix~\ref{Append_few_shot}).
% \end{enumerate}



\begin{table}[t!]
    \centering
    \caption{Zero-shot performance with a lookback window length of 12. All results are averaged over 4 weeks or days in the future. $\Delta (\%)$ stands for the relative improvement of CAPE over the baselines.}
    \label{tab:zero_shot_performance}
    \scalebox{0.70}{
    \begin{tabular}{lccccc}
            \toprule
            \textbf{Dataset} & $\Delta$ (\%) & \textbf{CAPE} & \textbf{PatchTST} & \textbf{PEM} & \textbf{MOMENT} \\
            \midrule
            ILI USA & 9.26\% & \cellcolor{low1}\textbf{0.147} & \cellcolor{low3}\textbf{0.164} & \cellcolor{low2}\textbf{0.162} & 0.549    \\
            ILI Japan & 17.06\% & \cellcolor{low1}\textbf{0.705} & \cellcolor{low3}\textbf{0.907} & \cellcolor{low2}\textbf{0.850} & 2.062   \\
            Measles & 3.97\% & \cellcolor{low1}\textbf{0.145} & \cellcolor{low3}\textbf{0.167} & \cellcolor{low2}\textbf{0.159} & 0.533    \\
            Monkey Pox & 20.00\% & \cellcolor{low1}\textbf{0.0004} & \cellcolor{low2}\textbf{0.0005} & \cellcolor{low3}\textbf{0.0005} & 0.0013   \\
            Dengue (mixed) & 10.17\% & \cellcolor{low1}\textbf{0.371} & \cellcolor{low3}\textbf{0.427} & \cellcolor{low2}\textbf{0.413} & 1.624    \\
            RSV & 26.06\% & \cellcolor{low1}\textbf{0.834} & \cellcolor{low2}\textbf{1.128} & \cellcolor{low3}\textbf{1.260} & 1.849  \\
            Covid (daily interval) & 13.80\% & \cellcolor{low1}\textbf{5.173} & \cellcolor{low2}\textbf{6.001} & \cellcolor{low3}\textbf{6.320} & 18.881    \\
            \bottomrule
        \end{tabular}
    }
    % \vskip -2em
\end{table}
% \subsubsection{Zero-shot Performance} % main table 4
\textbf{Zero-Shot Forecasting.} To further demonstrate the potential of our model, we evaluate CAPE in a zero-shot setting. Specifically, for transformer-based models, we retain the pre-training head and freeze all parameters during testing. All models are provided with a short input sequence of 12 time steps and tasked with predicting infections for the next 4 time steps. From Table~\ref{tab:zero_shot_performance}, we make the following observations: (a) CAPE outperforms baselines across all downstream datasets, showing superior zero-shot forecasting ability. (b) Models pre-trained on epidemic-specific datasets achieve better performance compared to those pre-trained without epidemic-specific data (MOMENT). This indicates the necessity of choosing domain-specific materials for pre-training.




\subsection{Ablation Study}
% % \wei{why we put transferability under ablation study? it does not fit into this subsection}
% We conduct the ablation study to demonstrate the effectiveness of the designed components, as shown in Table~\ref{tab:ablation_study}. 
% First, we remove the environment estimators by replacing them with self-attention layers without disentangling the environment influence and disease dynamics. The exclusion of the environment estimation consistently resulted in significant performance degradation across all datasets, with the most pronounced effect observed in the ILI USA dataset, causing the MSE to increased from 0.309 to 0.532. This underscores the critical role of environmental factors in enhancing forecasting accuracy.
% Next, we keep the environment estimators and remove the contrastive loss, which helps regularize the environment estimator. Removing the Contrast component led to varying degrees of performance decline. Notably, the Measles dataset experienced a substantial increase in error from 0.269 to 0.344 on average, indicating that contrastive mechanisms are particularly beneficial for this dataset. The ILI USA and Dengue datasets also showed performance drops, albeit less severe.
% Lastly, we train the CAPE directly on the downstream datasets without pre-training and found a decreased performance across all datasets. Specifically, without help of pre-training, we observe an increase of MSE from 0.309 to 0.319 for ILI USA, 0.269 to 0.326 for Measles, and 0.892 to 1.162 for Dengue. However, the impact is comparably smaller compared to the absence of environment estimation.

% For optimal forecasting performance, it is recommended to retain all components of the CAPE framework. Additionally, tailoring the emphasis on specific components based on dataset characteristics can further enhance efficacy. 
% We conducted an ablation study to evaluate the effectiveness of CAPE's components, as shown in Table~\ref{tab:ablation_study}. Removing environment estimators by replacing them with self-attention layers that do not disentangle environmental influence from disease dynamics consistently degraded performance across all datasets. Notably, the ILI USA dataset's MSE increased from 0.309 to 0.532, highlighting the crucial role of environmental factors in forecasting accuracy. Retaining environment estimators but removing the contrastive loss also led to performance declines, particularly in the Measles dataset where MSE rose from 0.269 to 0.344, while ILI USA and Dengue experienced smaller drops. Additionally, training CAPE directly on downstream datasets without pre-training resulted in decreased performance across all datasets, with MSE increasing from 0.309 to 0.319 for ILI USA, 0.269 to 0.326 for Measles, and 0.892 to 1.162 for Dengue. However, this impact was less pronounced than removing environment estimation. These results suggest that retaining all CAPE components is essential for optimal forecasting, and adjusting component emphasis based on dataset characteristics can further enhance performance.

We conducted an ablation study to assess CAPE's components (Table~\ref{tab:ablation_study}). Replacing environment estimators with non-disentangling self-attention layers consistently worsened performance across all datasets, notably increasing ILI USA's MSE from 0.309 to 0.532, underscoring the importance of environmental factors. Similarly, removing contrastive loss while retaining environment estimators raised Measles' MSE from 0.269 to 0.344, with smaller increases for ILI USA and Dengue. Training CAPE directly on downstream datasets without pre-training also decreased performance, with MSE rising to 0.319 (ILI USA), 0.326 (Measles), and 1.162 (Dengue), though less than removing environment estimation. These results indicate that all CAPE components are essential for optimal forecasting and that tailoring component emphasis to dataset characteristics can further enhance performance.

% As shown in Table~\ref{tab:ablation_study}, replacing environment estimators with non-disentangling self-attention layers increased ILI USA's MSE from 0.309 to 0.532. Removing contrastive loss while retaining environment estimators raised Measles MSE from 0.269 to 0.344, with smaller increases for ILI USA and Dengue. Training CAPE directly on downstream datasets without pre-training led to MSE increases of 0.010 for ILI USA, 0.057 for Measles, and 0.270 for Dengue, though these effects were less severe than removing environment estimators. These results highlight the necessity of all CAPE components for optimal forecasting and suggest that tailoring component emphasis based on dataset characteristics can further enhance performance.

\begin{table}[t!]
    \centering
    \caption{Ablation study of removing components from CAPE.}
    \label{tab:ablation_study}
    \setlength{\tabcolsep}{3pt} % Reduce space between columns
    \resizebox{0.50\textwidth}{!}{%
    \begin{tabular}{@{}llcccccc@{}}
        \toprule
        \textbf{Dataset} & \textbf{Model} & \textbf{H=1} & \textbf{H=2} & \textbf{H=4} & \textbf{H=8} & \textbf{H=16} & \textbf{Avg} \\
        \midrule
        \multirow{4}{*}{ILI USA} 
            & CAPE           & 0.155 & 0.200 & 0.270 & 0.404 & 0.516 & \textbf{0.309} \\
            & w/o Env        & 0.326 & 0.448 & 0.508 & 0.642 & 0.735 & 0.532 \\
            & w/o Contrast   & 0.174 & 0.241 & 0.335 & 0.492 & 0.570 & 0.363 \\
            & w/o Pretrain   & 0.158 & 0.202 & 0.283 & 0.408 & 0.545 & 0.319 \\
        \midrule
        \multirow{4}{*}{Measles} 
            & CAPE           & 0.069 & 0.096 & 0.155 & 0.280 & 0.743 & \textbf{0.269} \\
            & w/o Env        & 0.083 & 0.111 & 0.168 & 0.407 & 0.755 & 0.304 \\
            & w/o Contrast   & 0.090 & 0.124 & 0.276 & 0.431 & 0.801 & 0.344 \\
            & w/o Pretrain   & 0.074 & 0.113 & 0.223 & 0.402 & 0.816 & 0.326 \\
        \midrule
        \multirow{4}{*}{Dengue} 
            & CAPE           & 0.218 & 0.301 & 0.540 & 1.193 & 2.210 & \textbf{0.892} \\
            & w/o Env        & 0.232 & 0.316 & 0.484 & 1.089 & 3.622 & 1.149 \\
            & w/o Contrast   & 0.198 & 0.273 & 0.460 & 1.128 & 3.329 & 1.078 \\
            & w/o Pretrain   & 0.210 & 0.276 & 0.449 & 1.115 & 3.759 & 1.162 \\
        \bottomrule
    \end{tabular}
    }
    % \vskip -2em
\end{table}




\subsection{Transferability}
% \wei{for the each of the following three paragraphs, let's start with desribing what is in the pretrained dataset and what is new in the downstream test. Then describe the experimental results. }
\textbf{Cross-Location.} 
We include measles data from the USA in the pre-training dataset. To evaluate our model's ability to adapt to cross-region data, we incorporate measles outbreak data from the UK into the downstream datasets. As shown in Table~\ref{tab:ablation_study}, the pre-trained CAPE outperforms the non-pre-trained version by 17.48\%. While we pre-train our model with influenza data from the USA, the zero-shot evaluation on the influenza outbreak in Japan also shows superior performance, underscoring the crucial role of pre-training in enabling generalization to novel regions.

\textbf{Cross-Disease.} 
While we include various types of diseases in our pre-training dataset, novel diseases including Dengue (non-respiratory) and COVID-19 that are unseen in the pre-training stage are incorporated during the downstream evaluation. The ability of our model to adapt to novel diseases is proven compared to the version not pre-trained on the Dengue dataset (Table~\ref{tab:ablation_study}), improving which by 23.24\%, as well as the superior zero-shot performance on the COVID dataset (Table~\ref{tab:zero_shot_performance}), which surpasses the MOMENT that is not pre-trained on other diseases by 72.60\%.
% Besides test on diseases already seen, CAPE also shows strong transferability to unseen diseases, for example, Dengue and COVID-19. As shown in Table~\ref{tab: baselines}, CAPE outperforms the best baseline by 10.8\% on the Dengue dataset and 8.25\% on the Covid Dataset. \wei{we did not pre-train on COVID?}

\textbf{Cross-Interval.} 
While we only pre-train using weekly-sampled data, our model outperformed the non-pre-trained version on the irregularly sampled Dengue dataset, demonstrating robustness to different time intervals. Additionally, on the daily-sampled COVID-19 dataset, our model maintained strong zero-shot performance, further illustrating its ability to generalize across varying temporal resolutions.


% Overall, pre-training on diverse datasets enables the model to generalize effectively to new regions, adapt to novel diseases, and handle varying data sampling frequencies, underscoring the robustness and versatility of the CAPE model.

% During pre-training, we only incorporated diseases sampled in weekly frequency. Nevertheless, Dengue, as a downstream dataset, is sampled irregularly. The comparison between the pre-trained and non-pre-trained model on Dengue dataset proves the robustness of our model in terms of data with different time intervals. Moreover, the COVID-19 is sampled by daily interval, and our model still performs well in terms of zero-shot performance, proving
% Though we only pre-trained our model on the datasets with weekly sampling rate, we found that the model still performs well on dataset with daily or mixed sampling rate. For example, the Dengue dataset contains weekly, monthly, and yearly data, which tends to be more stably sampled in a weekly rate for the more recent data. 



\subsection{Deeper Analysis}
% \textbf{Impact of Pre-Training Epochs.} To further explore the sensitivity to the number of environments as well as the impact of pre-training epochs, we plot the performance under different settings on four different downstream datasets, as shown in Figure~\ref{fig:num_envs}. In terms of pre-training epochs, we observe a consistent improvement in the measles and COVID datasets. However, the reverse is true for the ILI USA dataset. In terms of the number of environment states $K$, we observe that the model with a larger $K$ tends to perform better with more pre-training epochs.
\noindent\textbf{Impact of Pre-Training Epochs.} Evaluating four downstream datasets (Figure~\ref{fig:num_envs}), we find that increasing pre-training epochs consistently improves performance on Measles and COVID datasets but degrades it for ILI USA. Additionally, models with more environment states \( K \) perform better as pre-training epochs increase.
\begin{figure}
\centering
        \includegraphics[width=0.8\columnwidth]{figures/analysis_envs.pdf}
        % \vskip -1em
        \captionof{figure}{Downstream performance with different numbers of environments and pre-training epochs.}
        \label{fig:num_envs}
    % \vskip -1.5em
\end{figure}

\noindent\textbf{Impact of Pre-Training Materials.} We examine potential biases in our pre-training dataset by splitting it into respiratory and non-respiratory diseases. As shown in Figure~\ref{fig: respiratory}, with similar volumes of pre-training data, the model performs better on downstream datasets when their disease types align with the pre-training data (e.g., respiratory diseases). However, the size of the pre-training material has a more significant impact on downstream performance.
\begin{figure}[htbp]
% \vskip -1em
    \centering
    % \vskip -1em
    \includegraphics[scale=0.3]{figures/respiratory.pdf}
    % \vskip -1em
    \caption{Downstream performance variation when the model is pre-trained with either respiratory or non-respiratory diseases only.}
    \label{fig: respiratory}
% \vskip -1em
\end{figure} 

\noindent\textbf{Impact of Pre-Training Material Scale.} To explore how the pre-training material scale affects downstream performance, we scaled the original pre-training dataset and test on downstream datasets. As shown in Figure~\ref{fig: pretrain_scale}, a sudden performance boost is observed at around a 60\% reduction for both Measles and Dengue datasets.
\begin{figure}[tbp]
    \centering
    \includegraphics[scale=0.3]{figures/pretrain_ratio.pdf}
    % \vskip -1.4em
    \caption{Downstream performance across pre-training ratios.}
    \label{fig: pretrain_scale}
\vskip -1em
\end{figure} 

% \wei{need a brief introduction to distribution shift in epidemic pre-training}
\noindent\textbf{Tackling Distribution Shift.} 
In this study, distribution shifts refer to changes in infection patterns observed from the training set to the test set.
To evaluate distribution shifts, we compute the Central Moment Discrepancy (CMD) score~\cite{zellinger2017central} between training and test distributions for each disease (see Appendix~\ref{Append: ds}). Figure~\ref{fig:CMD} shows that our model with environment estimation achieves the lowest CMD score, demonstrating its effectiveness in mitigating the impact of temporal distribution shifts.
\begin{figure}[tbp]
    \centering
    % \vskip -1em
    \includegraphics[width=0.6\linewidth]{figures/CMD.pdf}
    % \vskip -1em
    \caption{We report the CMD scores of the embeddings produced by CAPE with and without environment estimation, which quantify distributional differences between the training and test sets.}
    \label{fig:CMD}
    % \vskip -1.5em
\end{figure}

\noindent\textbf{Disentangling Disease Dynamics.} We validate our model's ability to capture intrinsic disease dynamics by extracting latent embeddings from various datasets and computing the Davies-Bouldin Index (DBI) for each pair. As shown in Figure~\ref{fig: dbi}, CAPE consistently achieves lower DBI scores than PatchTST across all pairs, demonstrating its superior effectiveness in distinguishing diseases and separating disease-specific patterns from environmental influences.
\begin{figure}[htbp]
    \centering
    % \vskip -1em
    \includegraphics[scale=0.7]{figures/DBI.pdf}
    % \vskip -1em
    \caption{Davies-Bouldin Index score between the embeddings of each pair of downstream datasets, output by the pre-trained model without fine-tuning. A visualization is shown in Appendix~\ref{Append_latent}.}
    \label{fig: dbi}
% \vskip -1.5em
\end{figure} 
% \begin{figure*}[ht]
%     \centering
%     % First Minipage for the first figure (66% width)
%     \begin{minipage}[b]{0.29\textwidth}
%         \centering
%         \includegraphics[scale=0.17]{figures/respiratory.pdf}
%         \caption{Downstream performance on Measle and Dengue datasets. The proposed model is pre-trained on datasets with either respiratory or non-respiratory diseases only.}
%         \label{fig: respiratory}
%     \end{minipage}
%     \hfill % Horizontal space between the figures
%     \begin{minipage}[b]{0.29\textwidth}
%         \centering
%         \includegraphics[scale=0.17]{figures/pretrain_ratio.pdf}
%         \caption{Downstream performance with different ratios of pre-training materials.}
%         \label{fig: pretrain_scale}
%     \end{minipage}
%     \hfill % Horizontal space between the figures
%     \begin{minipage}[b]{0.29\textwidth}
%         \centering
%         \includegraphics[width=\linewidth]{figures/CMD.pdf}
%         \caption{CMD scores of the embeddings produced by CAPE on the ILI USA and Measles datasets. We compare versions trained with and without environment estimation.}
%         \label{fig:CMD}
%     \end{minipage}
% \end{figure*}












