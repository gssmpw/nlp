\section{Sample complexity}\label{sec:sample_complexity}
We derive the following lower and upper bounds on the sample complexity of the sets $\XZ,\XD$, and $\XA$. %We start with a general lower bound that applies to any sample set (i.e., not necessarily one derived from a lattice) that is a ${\beta^*}$-cover. We then proceed to lattice-based lower and upper bounds. %To simplify the analysis, for the remainder of the paper, we assume that the configuration space is a $d$-dimensional $R$-ball for some $R\in (0,\infty)$, i.e., $\C:=\B_R$. 


%\subsection{Lattice-based bounds}
% The above result directly follows from~\cite{verger2005covering} which provides a lower bound on the number of $\tfrac{1}{2}$-balls necessary to cover a ball of radius $R \geq \frac{d}{2}$. A simple rescaling argument is used to make it applicable to our setting where ${\beta^*}\left(\de\right)$-balls are used for covering the configuration space. \kiril{Does this description give justice to what you derived or is there something more complicated that I'm missing here?}

% This is a fair upper bound on ${\beta^*}=\delta\alpha$, as $\alpha \leq 1$ and we already take $\delta$ as small value, usually. For example, for a 10 degree problem, we would need ${\beta^*}\leq\frac{1}{6}\approx 0.17$---then for $\delta = 0.1$ we would need $\epsilon < 1.7$. \kiril{I don't understand this discussion. Please clarify.}
% NOTE \itai{I commented out all this part \left(see tex file\right). Its irrelant as I rewrote the theorem.}
% Let us compare this bound with the previous bound~\cite[Theorem~1]{tsao2020sample}, which employed volume arguments. \kiril{Is this the bound you had in mind?} In particular, the previous bound is at least 
% \kiril{please fill in.}
% Thus, the new upper bound is bigger by a factor of \kiril{fill} than the old one. 

% \kiril{The following text needs to be clarified as in the first equation the new bound is stated and I substituted it with the text above.}
% {\color{blue} To compare this LB to the "classic" volume-derived lower bound, let us return to a configuration space defined in a ball of general radius $r\geq {\beta^*} d$. \kiril{return from where? let's keep everything consistent and keep the same setting throughout the paper unless absolutely necessary.}
% We get the following lower bound:
% \begin{align}
%     n \geq k d\cdot\left(2r_0\right)^d =k\cdot d \left(\frac{r}{{\beta^*}}\right)^d 
% \end{align}
% NOTE \itai{I commented out all this part also \left(see tex file\right). To clarify: this is a comparison to the classic "volume divided by volume" lower bound, I didn't compare this lower bound to the one in tsao. you dealt with a square C-Space there and I found it hard to compare your approximation to this one.}
% \begin{proof}
%   We rely on , which states that if a sample set $\X$ is a for  then
% \begin{align}
%    |\X| \geq k\cdot d \cdot\left(2R\right)^{d},\,k>0. 
% \end{align}
% \kiril{What is the purpose of $k$? Does it hold for any $k$? If so, can we substitute $\geq$ with $>$ and get rid of $k$?}
% In our setting, we wish to construct a ${\beta^*}\left(\de\right)$-cover of our configuration space. 
% We want $\frac{1}{2}$-balls in~\cite{verger2005covering}  to be mapped to balls of radius ${\beta^*}\left(\de\right)$-balls, so we need a covering radius of $2{\beta^*}$. This means that if we want to cover a general ball of radius $r$ by ${\beta^*}$-balls, then we need a ball of initial radius $R$ \left(before the rescaling\right) such that:
% \[
%     R\cdot 2{\beta^*}=rarrow R=\frac{r}{2{\beta^*}}
% \]
% Taking $R\geq\frac{d}{2}$ to fit Verger's result, we reach the following bound on $r>0$:
% \begin{align*}
%     \frac{d}{2} \leq R = \frac{r}{2{\beta^*}} arrow r \geq {\beta^*} d
% \end{align*}
% To get a feeling for this bound, let us choose our configuration space as a ball of radius $r=\frac{\sqrt{d}}{2}$. This is logical because it is the circumsphere of the regular $[0,1]^d$ cube. With this we need to have:
% \[
%     \frac{\sqrt{d}}{2} \geq {\beta^*} d arrow {\beta^*} \leq \frac{1}{2\sqrt{d}}
% \]
% \end{proof}

% We are now going to find new upper bounds for our newly defined sample sets \Lattices. We name an upper bound for a sample set by the name \emph{sample complexity}. 
% Throughout the analysis, we assume that the configuration space is the Euclidean $d$-dimensional $R$-ball denoted by $\B_R$. This assumption allows us to obtain tighter bounds, than for, say, unit hypercube configuration spaces, which were assumed in previous sample-complexity analysis. 
% To this end, we first introduce the \emph{Gram matrix} of a lattice, relevant to the following Theorem:
%   \begin{definition}[Gram matrix and quadratic form]
%       The \emph{Gram matrix} of a lattice $\Lambda$ with generator matrix $G_\Lambda$ is defined to be $Gr_\Lambda:=G_\Lambda G^t_\Lambda$. Additionally the quadratic form of $\Lambda$ is defined as $q_\Lambda\left(a\right):=aGr_\Lambda a^t$.
%   \end{definition}
% Next, we will show that those properties lead to superior sample and collision check complexity, among the three lattice types we consider in this work. We mention that in dimension $2$, the lattice $A_2^*$ corresponds to the known "Hexagonal Grid", and in dimension $3$, the lattices $A_3^*$ and $D_3^*$ coincide as the "Body Centered Cubic" (or "Staggered Grid" in~\cite{dayan2023near}).

%Next, we derive analytical lower and upper bounds that exploit the underlying lattice structure.  %Later on, in our experimental results (Section~\ref{sec:experiments}), we compare the sample complexity of those sets for varying values of $\de$, and $d$. 

% previous long version
% \begin{thm}[Sample-complexity bounds]
% \label{thm:general_sample_complexity}
%     Consider a lattice $\Lambda\in \{\dZ^d,D_d^*,A_d^*\}$ with a covering radius $f_\Lambda$, which yields the \decomp set $\XL$ for some $\delta>0,\epsilon>0$, according to Theorem~\ref{thm:decomp_lattices}. Fix a radius $R>0$ and denote $\theta:=\frac{R}{{\beta^*}}$ and $b_d:=\partial(\B_1)$. Then, 
% \begin{align}\label{eq:sample bounds}
%         |\XL\cap \B_R| = \frac{b_d}{\sqrt{\det(\Lambda)}}\theta^df^d_\Lambda + P_d(\theta f_\Lambda), %:=n_{\textup{lattice}}^{\de},
%     \end{align}
%     where for a value $\alpha>0$, $P_d(\alpha)=\Omega(\alpha^{d-2})$ for $d\geq 3$. \kiril{Aren't we missing some upper bounds here?} Additionally, specific results exist for $P_3(\alpha)=O\left(\alpha^{\frac{21}{32}+\epsilon}\right)$ %(see Heath et al.~\cite{heath1999lattice})
%     and  $P_4(\alpha)=O\left(\alpha\log^{2/3}\alpha\right)$ %(see Walfisz et al.~\cite{walfisz1959gitterpunkte})
% .\footnote{For two univariate functions $f,g$, the notation $f(\alpha)=O(g(\alpha))$ (or $f(\alpha)=\Omega(g(\alpha))$)  means that there exists a constant $m_u>0$ (or $m_l>0$) such that for a large enough $\alpha$ it holds that $f(\alpha)\leq m_u(g(\alpha))$ (or $f(\alpha)\geq m_l(g(\alpha))$). Since in our context, $\alpha=\frac{R}{{\beta^*}}f_\Lambda$, where $f_\Lambda$ is fixed, the bounds hold for a sufficiently large ratio $R/{\beta^*}$.}
%     Specifically, for $R=r(\de)$ as in ~\Cref{lem:cover} we can write explicitly that \begin{align}\label{eq:sample bounds}
%         n_{\textup{lattice}}^{\de}= 
%         \frac{b_d}{\sqrt{\det(\Lambda)}}\left(2f_\Lambda\left(1+\frac{1}{\epsilon}\right)\right)^d + P_d\left(f_\Lambda\left(1+\frac{1}{\epsilon}\right)\right),
%     \end{align}
%     that is, the upper limit on the number of samples in the PRM connection-radius ball depends only on $d,\epsilon$.
% \end{thm}

\begin{thm}[Sample-complexity bounds]
\label{thm:general_sample_complexity}
    Consider a lattice $\Lambda\in \{\dZ^d,D_d^*,A_d^*\}$ with a covering radius $f_\Lambda$, which yields the \decomp set $\XL$ for some $\delta>0,\epsilon>0$. %, according to Theorem~\ref{thm:decomp_lattices}.
    Then,
\begin{align}\label{eq:sample bounds}
        |\XL\cap \B_{r^*}|= 
        \frac{\partial(\B_1)}{\sqrt{\det(\Lambda)}}\btheta_{r^*}^d + P_d(\btheta_{r^*}),
    \end{align}
where $\btheta_{r^*}:=2f_\Lambda\left(1+\frac{1}{\epsilon}\right)$, and $P_d(\alpha)\in \dR$ is the discrepancy function~\cite{ivic2004lattice}.\footnote{For a value $\alpha>0$, $|P_3(\alpha)|=\Omega_+(\sqrt{\alpha\log(\alpha)})$ and $|P_3(\alpha)|=O\left(\alpha^{\frac{21}{32}+\epsilon}\right)$, $|P_4(\alpha)|=\Omega(\alpha^{2})$, $|P_4(\alpha)|=O\left(\alpha\log^{2/3}\alpha\right)$, and $|P_d(\alpha)|=\Theta(\alpha^{d-2})$ for $d>4$. Notice that $P_d$ can be negative.  For two functions $f,g$, the notation $f(\alpha)=O(g(\alpha))$ (or $f(\alpha)=\Omega(g(\alpha))$)  means that there exists a constant $m_u>0$ (or $m_l>0$) such that for a large enough $\alpha$ it holds that $f(\alpha)\leq m_u(g(\alpha))$ (or $f(\alpha)\geq m_l(g(\alpha))$). %Since in our context, $\alpha=\frac{R}{{\beta^*}}f_\Lambda$, where $f_\Lambda$ is fixed, the bounds hold for a sufficiently large ratio $R/{\beta^*}$.
}
\end{thm}

\begin{proof}
  We estimate the size of the sample set $\XL$ induced by the lattice $\Lambda$ and the scaling factor $f_\Lambda$ by exploiting the relation between $\XL$ and the grid lattice~$\dZ^d$. In particular, a ball with respect to $\XL$ can be viewed as a rescaled ball for the  $\dZ^d$ lattice. This allows the use of bounds on the number of $\dZ^d$ points within an ellipse. 

  Fix a ball radius $R>0$. 
  Due to the rescaling performed in Theorem~\ref{thm:decomp_lattices}  we transition from the lattice $\Lambda$, which is a $f_\Lambda$-cover for $\dR^d$, into the set $\XL$, which is a ${\beta^*}$-cover for $\dR^d$. In particular, the rescaling factor is $w_\Lambda:={\beta^*}/f_\Lambda$, which is multiplied by $\Lambda$ to obtain $\XL$ (for $\AN$ we also applied an isometric transformation, but this does not change the scale reasoning). Thus, the ball $\B_R$ with respect to $\XL$ can be viewed as the ball $\B_{\btheta}$, where $\btheta_R=R w_\Lambda=\frac{R}{{\beta^*}}f_\Lambda$. Thus, $|\XL\cap \B_R|=|\Lambda\cap\B_{\btheta_R}|$. For the remainder of the proof, we wish to bound the expression $|\Lambda\cap\B_{\btheta_R}|$.

  Let $v=aG_\Lambda$ be a lattice $\Lambda$ point, where $a\in\mathbb{Z}^d$. By definition of the \emph{Gram matrix} $\text{Gr}_\Lambda:=G_\Lambda G_\Lambda^t$, we obtain 
  \[
    a\text{Gr}_\Lambda a^t:=aG_\Lambda G^t_\Lambda a^t=\|aG_\Lambda\|^2=\|v\|^2.
  \]
This leads to the relation
  \begin{align*}
      \B_{\btheta_R}\cap \Lambda &= \{v\in\Lambda |\,\|v\| \leq \btheta_R\} =\{a\in\dZ^d|a \text{Gr}_\Lambda a^t\leq \btheta_R^2\} \\ & =E_{\btheta_R^2}\left(\text{Gr}_\Lambda\right)\cap \dZ^d,
  \end{align*}
  where $E_{s}\left(A\right):=\{x\in\dR^d|x A x^t\leq s\}$ for a matrix $A$ and $s>0$. 
  
  Next, observe that the Gram matrix $Gr_\Lambda$ of the lattices \Lattices contains only rational numbers, and hence defines a \emph{rational quadratic form}, which allows us employ \emph{rational ellipsoid bounds}~\cite{ivic2004lattice} for $|E_{\btheta_R}\left(\text{Gr}_\Lambda\right)\cap \dZ^d|$. Hence,
\begin{align}
    |\XL\cap \B_R
|&=|\B_{\btheta_R}\cap \Lambda|=\left|E_{\btheta_R}\left(\text{Gr}_\Lambda\right)\cap \dZ^d\right|\nonumber\\
&=\frac{\partial(\B_{\btheta_R})}{\sqrt{\det(\Lambda)}}+P_d(\btheta_R)=\frac{\partial(\B_1)}{\sqrt{\det(\Lambda)}}\btheta_R^d+P_d(\btheta_R). \label{eq:sample_complexity}
\end{align}
%where $P_d(\btheta_R)$ is as defined in the statement of Theorem~\ref{thm:general_sample_complexity}.
%For the last transition, see the definition of $A(x,E_p)$ in~\cite[Page 16]{ivic2004lattice}. \kiril{What do mean here? The transition only uses the definition of the ball volume.} 
The expression in Equation~\eqref{eq:sample bounds} immediately follows by plugging
\[\btheta_{r^*}=\frac{r^*}{{\beta^*}}f_\Lambda = \frac{2\delta(1+\epsilon)}{\sqrt{1+\epsilon^2}}\cdot \frac{\sqrt{1+\epsilon^2}}{\delta\epsilon} f_\Lambda = \frac{2(1+\eps)}{\eps}f_\Lambda.\]
\end{proof}
% Hence,
% \begin{align}\label{volume_delta}
%     |\B_{\btheta}\cap \Lambda|\leq \frac{\vol\left(\B_{\btheta}\right)}{\sqrt{d}}+b\btheta^{d-2}.
% As Equation~(\ref{volume_delta}) deals with the unscaled lattice $\Lambda$, we now use the rescaling performed in Theorem~\ref{thm:decomp_lattices} to extend the analysis above to $\XL$. In particular, recall that from the proof in Theorem~\ref{thm:decomp_lattices}, we have that  $\|\XL\cap \B_R\|=\|\Lambda\cap\B_{\bar{\theta}}\|$. Thus, using Equation~(\ref{volume_delta}) we have that 
% \begin{align*}
%     \|\XL\cap \B_R\|&\leq \frac{1}{\sqrt{\pi}d}\left(\frac{2\pi e}{d}\right)^{\frac{d}{2}}\bar{\theta}^d+b\bar{\theta}^{d-2}, %\\
%   %&= \frac{1}{\sqrt{d}}
%    % \left(\frac{2\pi e}{d}\right)^{\frac{d}{2}}\left(\frac{Rf_\Lambda}{{\beta^*}}\right)^d+c\bar{\theta}^{d-2} %\\
%    % &=\frac{1}{\sqrt{\pi}d}\left(\frac{R}{{\beta^*}}\right)^d\left(\frac{2\pi e}{d}\cdot f_\Lambda^2\left(d\right)\right)^{\frac{d}{2}} +  c\left(\frac{R}{{\beta^*}}\right)^{d-2}\left(f_\Lambda\left(d\right)\right)^{d-2}, \nonumber %\\
%    %& \leq \frac{1}{\sqrt{\pi}d}\left(\frac{R}{{\beta^*}}\right)^d\left(\frac{2\pi e}{d}\cdot f_\Lambda^2\left(d\right)\right)^{\frac{d}{2}} +  c\left(\frac{R}{{\beta^*}}\right)^{d-2}\left(f_\Lambda\left(d\right)\right)^{d-2},
% \end{align*}
% with some $c>0$ from~(\ref{volume_delta}). This finishes the proof. 

% The following corollary leverages the last theorem and the specific structure of \Lattices to derive specific upper bounds.
% \begin{cor}[$\XZ,\XD,\XA$ sample complexity]\label{cor:specific_sample_complexity}
%     Fix ${\beta^*}={\beta^*}\left(\delta,\epsilon\right)$ and let $\theta:=\frac{R}{{\beta^*}}$. Consider the configuration space  $\C=\B_R$ for $R=\sqrt{d}{\beta^*}$ or $R \geq d{\beta^*}$ \kiril{Why do we have those conditions on $R$ here? They were only needed for the lower bound, no?}. Then the following bounds hold:
%     \begin{enumerate}[topsep=1pt,itemsep=1ex,partopsep=1ex,parsep=1ex]
%         \item 
%             $|\XZ\cap\B_R| = O\left(\frac{1}{d}\left(2.07\theta\right)^d+\left(\theta\sqrt{\frac{d}{4}}\right)^{d-2}\right)$;
%         \item 
%             $|\XD\cap\B_R| = O\left(\frac{1}{d}\left(1.46\theta\right)^d + \left(\theta\sqrt{\frac{d}{8}-\frac{1}{16}}\right)^{d-2}\right)$; \kiril{Add cases for even and odd dimensions.}
%         \item 
%         $|\XD\cap\B_R| = O\left(\frac{1}{d}\left(1.19\theta\right)^d+\left(\theta\sqrt{\frac{d}{12}}\right)^{d-2}\right)$.
%     \end{enumerate}
%     \kiril{Considering the approximations we use, we need to substitute the equality signs here with $~$.}
% \end{cor}
% \begin{proof}
%     Relying on the rescaling coefficients $f_\Lambda$ we got in Theorem~\ref{thm:decomp_lattices}, and the general lattice sample complexity reached in Theorem~\ref{general_sample_complexity}, we work on analyzing the sample complexity of our lattices. First, we look at $\ZN$. From Theorem~\ref{general_sample_complexity}, we get
%     \begin{align*}
%         |\XZ\cap \B_R| &= O\left(\frac{1}{d}\left(\theta^2\frac{2\pi e}{d}\cdot f_{\ZN}^2\right)^{\frac{d}{2}} + \left(\theta\cdot f_{\ZN}\right)^{d-2}\right) \\
%         &= O\left(\frac{1}{d}\left(\theta\sqrt{\frac{\pi e}{2}}\right)^d+\left(\theta\frac{\sqrt{d}}{2}\right)^{d-2}\right)\\
%        & = O\left(\frac{1}{d}\left(2.07\theta\right)^d+\left(\theta\sqrt{\frac{d}{4}}\right)^{d-2}\right).
%     \end{align*}

%    Next, we look at $\DN$:
%     \begin{align*}
%         |\XD\cap \B_R| &= O\left(\frac{1}{d}\left(\theta^2\frac{2\pi e}{d}\cdot f_{\DN}^2\right)^{\frac{d}{2}} + \left(\theta\cdot f_{\DN}\right)^{d-2}\right) \\
%         &= O\left(\frac{1}{d}\left(\theta^2\frac{2\pi e}{d}\cdot \frac{2d-1}{16}\right)^{\frac{d}{2}}+\left(\theta\frac{\sqrt{2d-1}}{4}\right)^{d-2}\right)\\
%         &=O\left(\frac{1}{d}\left(\theta^2\frac{2\pi e}{8}\cdot \frac{2d-1}{2d}\right)^{\frac{d}{2}}+\left(\theta\sqrt{\frac{d}{8}-\frac{1}{16}}\right)^{d-2}\right).
%     \end{align*}
%     Due to
%     \begin{align*}
%         \left(\frac{2d-1}{2d}\right)^\frac{d}{2}=\left(\left(1+\frac{\left(-1\right)}{2d}\right)^{2d}\right)^\frac{\frac{d}{2}}{2d}\overset{d\rightarrow\infty}{\longrightarrow} e^{\frac{1}{4}},
%     \end{align*}
%     we obtain:
%     \begin{align*}
%          \|\XD\cap \B_R\|&=O\left(\frac{1}{d}\left(\theta\sqrt{\frac{\pi e}{4}}\right)^d+\left(\theta\sqrt{\frac{d}{8}-\frac{1}{16}}\right)^{d-2}\right)\\
%          & = O\left(\frac{1}{d}\left(1.46\theta\right)^d + \left(\theta\sqrt{\frac{d}{8}-\frac{1}{16}}\right)^{d-2}\right).
%     \end{align*}
    
%     Lastly, we look at $\AN$. From equation (7) above it can be seen that
%     \[
%         T^tT=G\left(EP\right)^t\left(EP\right)G^t=
%         \begin{pmatrix}
%             2 & 1 &  1  & \dots & 1 & -1 \\
%             1 & 2  &  1 & \dots & 1 & -1 \\
%             \vdots & \vdots  &  \vdots & \ddots & \vdots & \vdots  \\
%             1 & 1  &  1 & \dots & 2 & -1 \\
%             -1 & -1 & -1 & \dots & -1 & \frac{d}{d+1}
%         \end{pmatrix}\in\dR^{d\times d}.
%     \]
%     Furthermore, it can be shown that $T^tT=GG^t=Gr_{\AN}$. Thus, we can use Theorem~\ref{general_sample_complexity} to approximate the number of lattice points in the embedded lattice, as they both share the Gram matrix $Gr_{\AN}$:%---which intuitively makes sense, as they both represent the lattice (only that one of them is in a higher dimension).
%     %From Theorem~\ref{general_sample_complexity}, we get:
%     \begin{align*}
%         |\XD\cap \B_R|& = O\left(\frac{1}{d}\left(\theta^2\frac{2\pi e}{d}\cdot f_{\AN}^2\right)^{\frac{d}{2}} + \left(\theta\cdot f_{\AN}\right)^{d-2}\right) \\
%         &= O\left(\frac{1}{d}\left(\theta^2\frac{2\pi e}{d}\cdot \frac{d\left(d+2\right)}{12\left(d+1\right)}\right)^{\frac{d}{2}}+\left(\theta\sqrt{\frac{d\left(d+2\right)}{12\left(d+1\right)}}\right)^{d-2}\right)\\
%         &=O\left(\frac{\theta^d}{d}\left(\frac{2\pi e}{12}\cdot \frac{d+2}{d+1}\right)^{\frac{d}{2}}+\left(\theta\sqrt{\frac{d}{12}}\right)^{d-2}\left(\frac{d+2}{d+1}\right)^{\frac{d-2}{2}}\right).
%     \end{align*}
%     Due to
%     \begin{align*}
%         \left(\frac{d+2}{d+1}\right)^\frac{d}{2}=\left(\left(1+\frac{1}{d+1}\right)^{d+1}\right)^\frac{\frac{d}{2}}{d+1}\overset{d\rightarrow\infty}{\longrightarrow} e^{\frac{1}{2}},\\
%     \end{align*}
%     and similarly for the right term, we obtain
%     \begin{align*}
%          |\XA\cap \B_R|& =O\left(\frac{\theta^d}{d}\left(\sqrt{\frac{\pi e}{6}}\right)^d+\left(\theta\sqrt{\frac{d}{12}}\right)^{d-2}\right)\\
%          & = O\left(\frac{1}{d}\left(1.19\theta\right)^d+\left(\theta\sqrt{\frac{d}{12}}\right)^{d-2}\right).
%     \end{align*}
%     \kiril{Note to self: I need to revisit this proof after the details of the approximation are made clear.}
% \end{proof}

\niceparagraph{Discussion.} 
The expression in Equation~\eqref{eq:sample bounds} is identical for our three sample sets, except for the value of the covering radius $f_\Lambda$. This highlights the fact that a smaller covering radii leads to a lower sample complexity. Also, notice that the value $f_\Lambda$ is raised to the power of $d$ in Equation~\eqref{eq:sample bounds}, which emphasizes the difference between the sets in terms of sample complexity. 
See a plot of the sample complexity in theory and practice in~\Cref{fig:limit_graph_upper}, wherein $\XA$ has the lowest sample complexity (except in dimensions $3$ where it coincides with $\XD$). Notice that the theoretical bounds are well-aligned with the practical values. 

For example, consider $d=12$, where the $\XA$ sample set is  $\approx 4$ times smaller than $\XD$.  Even when this difference is not as big, e.g., in dimension $6$ where the size of $\XA$ is  $\approx 1.63$ times smaller than $\XD$, we observe tremendous impact in terms of the running of the motion-planning algorithm in experiments. This follows from the fact that the sample complexity studied here corresponds to the branching factor of the underlying search algorithm, which is known to have a significant impact on the running time. In the next session, we show that the superiority of $\XA$ is maintained also for the collision-check complexity metric.

\begin{figure}[thb]
% \centering  
\includegraphics[width=\columnwidth]{Images/sample_complexity.pdf}
\caption{A sample-complexity  plot for the sample sets $\XZ,\XD$, and $\XA$ with $\delta=1$ and $\eps=2$. The dashed line represents the theoretical approximation (\Cref{eq:sample bounds}), where the asymptotic error term $P_d$ is excluded. The solid line depicts the practical value, i.e., the  number of lattice points within the $r^*$-ball in practice. Missing values are due to memory limitations.}
\label{fig:limit_graph_upper}
\end{figure}


    %Our upper bounds suggest that the sample complexity improves as we move from $\XZ$ to $\XD$, and $\XA$. Both the first term and the error term of the sample complexity expression get better: (i) The first term gets exponentially better, going from $2.07^d$ to $1.46^d$ and $1.19^d$. (ii) The second term also gets better, with its base going from $\sqrt{\frac{d}{4}}$ to $\sqrt{\frac{d}{8}}$ and $\sqrt{\frac{d}{12}}$. (In both comparisons we disregarded the common $\theta$ term.)

%Our experimental results in Section~\ref{sec:experiments} indicate that our theoretical analysis is quite tight in terms of the size of the actual size of $\XL$ as compared to the bounds and correspondingly in terms of the rankings of the sample sets. That is, the sample set $\XA$ is superior in theory and practice. 

    %Finally, we compare the general lower-bound (Equation~\eqref{eq:general_LB}) with the lattice-based lower-bound (Equation~\eqref{eq:sample bounds}). In particular, note that $n_{VG}^{\de}=\Omega(d\theta^d)$, whereas $n_{\textup{lattice}}^{\de}=\frac{b_d}{\sqrt{\det(\Lambda)}}\theta^df^d_\Lambda + \Omega(\theta^{d-2}f_\Lambda^{d-2})$, which implies that the latter is always bigger, and so sharper. \kiril{Is this correct? The lattice bound doesn't have a $d$ multiplied with $\theta^d$.} \kiril{Can we say about it something more concrete? Can we plot the general lower bound in the experiments or is it difficult?} \itai{lets discuss this} \kiril{Remind me, what is the conclusion we ended up with?}

% We complete this section with an analysis of the CC complexity of our sample sets. 
% \begin{thm}[$\XZ,\XD,\XA$ CC complexity]
%   Consider the configuration space $\B_{r_c}$ for (rc=?). Then the following upper bounds on CC complexity hold: \kiril{Why is this missing information?}
%     \begin{enumerate}
%         \item 
%         \begin{align*}
%             \frac{\|\chi_{D_d^*,C-Space\|}}{\|\chi_{LB}\|}= ?? \\
%             \|\chi_{D_d^*,{\beta^*}-ball}\|= ??
%         \end{align*}        
%         \item 
%         \begin{align*}
%             \frac{\|\chi_{A_d^*,C-Space\|}}{\|\chi_{LB}}\|\ = ?? \\
%             \|\chi_{A_d^*,{\beta^*}-ball}\|= ??
%         \end{align*}
%     \end{enumerate}
% \end{thm}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../main"
%%% End:
