\section{Collision-check complexity}\label{sec:collision_complexity}
In this section, we seek to analyze the collision-check complexity of our sample sets $\XZ,\XD,\XA$, as the length of the graph edges is a better proxy for the computational complexity of constructing the resulting PRM than sample complexity. 

%The biggest effect on the runtime of a PRM algorithm are the collision checks. Specifically, running neighborhood checks (like r-NN) forces you to check along all the edges connecting the center of a ball with other vertices for the purpose of finding a possible collision.


%For this reason, we would like to have some estimate on the overall size of the sum of lengths from the ball center to the other vertices.
%
% To make calculations simpler, we'll use $\sum\|\cdot\|^2$ instead. \kiril{Note to self: Need to revise the definition of CC-complexity to account for this squared value and provide a motivation about it.}


%\itai{Some thoughts: this sum can also be seen as the Moment of inertia of a collection of particles of similar mass, scattered on a lattice inside a sphere. Is this useful to note? if anything, the connection could be interesting. In the beginning I tried to find some way to connect the two, as I thought maybe physicists already have estimates for this kind of thing. For example, the Dn* lattice in d=2 is known to be a crystal lattice for some materials. is our calculation getting the approximate moment of inertia for a pure crystal ball? checking online, iron for example is a BCC crystal. so a crystal iron ball has a moment of $0.4Mr^2$, and you'll see later we reach O($r^2$) approximately. I just wonder if we should point out the connection at any point, even as a comparison.} \kiril{This is interesting. We could point out this connection, in a more concise manner, after Problem 2. This could definitely go into the thesis.}


% Next, introduce a few more definitions that are closely related to the  collision-check complexity bounds.
Recall that the collision-check complexity of a lattice-based sample set $\X_\Lambda$  is 
$CC_{\X_\Lambda}=\sum_{x\in \X_\Lambda\cap \B_r}\|x\|$, where $r=r(\delta,\eps)$.
A naive approach to upper-bound $CC_{\X_\Lambda}$ is to multiply the number of points in a $r$-ball (which corresponds to the sample complexity of $\X_\Lambda$) with the radius $r$, i.e.,
\begin{align}
    CC_{\X_\Lambda}\leq r\cdot |X_\Lambda \cap \B_r|=r\cdot \frac{\partial(B_1)}{\sqrt{\det(\Lambda)}}\btheta^d_r + r\cdot P_d(\btheta_r). \label{eq:cc_naive}
\end{align}
The following is a tighter bound, which reduces the coefficient of the dominant factor of the naive bound.  

%A tighter bound can be obtained by partitioning the $r$-ball into annuli and separately counting the distances to the points in a given annulus. %In the proof below, for simplicity, we use the bound  $P_d(\btheta)=\Theta(\btheta^{d-2})$, which is applicable to any dimension $d\geq 3$, even though tighter bounds are available for $d\in \{3,4\}$.

%That is, an annulus is defined as  $A^{r'}_{r''}:=\B_{r'}(o)\setminus \B_
%{r''}(o)$ for some $0\le r''<r'\le r$, and  the distances corresponding to this annulus are $r' \cdot |\X\cap A^{r'}_{r''}|$. Note that the expression $|\X\cap A^{r'}_{r''}|$ can be approximated via Equation~\ref{eq:sample bounds} by subtracting from the upper bound of $|\X\cap \B_{r'}(o)|$ the lower bound of $|\X\cap \B_{r''}(o)|$. However, this should be done carefully since this method can yield a strictly positive number of points for an annulus of zero width due to the slackness in Equation~\ref{eq:sample bounds}. We have the following theorem.

%\begin{definition}[Ball collision complexity]\label{def:lattice_sums}
%  Let \(P_{\Lambda,r}:= \{\Lambda\cap \B_r\left(0\right)\}\) be the lattice $\Lambda$ points inside the $r$-ball centered at $o$, for some $r\geq 0$. The \emph{collision complexity} of $P_r$ is defined to be
%   $$\text{CC}_{\Lambda}\left(r\right):=\sum_{x\in P_{\Lambda,r}} \|x\|.$$
% Also, let \(P_{F_{\Lambda,p}}:=F_{\Lambda,p}\cap \Lambda\) be the lattice samples that belong to an FR $F_{\Lambda,p}$, and consider another FR $F_{\Lambda,p'}$ where both FRs are defined with the same basis of $\Lambda$, where $p,p'\in \dR^d$. \kiril{I made some clarifications. Are they correct?}
% We define the relative sum to be the squared distance of the points in $P_{F_{\Lambda,p}}$ from the center $c_{\Lambda,p'}$ of $F_{\Lambda,p'}$, i.e.,
%         \[
%            I_{F,p'}:=\sum_{x\in P_{F}} \|c_{\Lambda,p'}-x\|^2.
%           %I_{F_{\Lambda,p}}=
%         \]
%\end{definition}

% Using these definitions, we work towards bounding \(I\left(r\right)\), which would then lead to collision-check complexity bounds. 

\begin{thm}[CC complexity bound]
  Consider a lattice $\Lambda\in \{\dZ^d,D_d^*,A_d^*\}$ with a covering radius $f_\Lambda$, which yields the \decomp set $\X:=\XL$ for some $\delta>0,\epsilon>0$ and dimension $d\geq 3$ \kiril{Shouldn't it be dimension 2 and on?}. %Fix a radius $R>0$.\footnote{Notice that since the connection radius we use is $r:=r(\delta,\epsilon)$, we could potentially limit $R$ to be at most $r$. However, we keep $R>0$ for the sake of generality.}
    % Then we have that 
    % \begin{align}
    %     CC_\xi(R)&\leq \left(1 - \frac{x^{d+2} - x}{ dx - (d+1))}\right)\cdot R \frac{\partial(B_1)}{\sqrt{\det(\Lambda)}}\btheta^d_{R}  \nonumber\\&+ R\cdot P_d(\btheta_R).
    % \end{align}
  Then,
    \begin{align}
        CC_\X\leq \left(1 - \frac{x^{d+2} - x}{ dx - (d+1))}\right) \cdot 4\delta \cdot  \btheta_r^d + r \cdot P_d(\btheta_r),
    \end{align}
    where \kiril{$x:=?$ Let's also use a different notation for $x$, e.g., $\xi$}
\end{thm}
\begin{proof}
  We improve the naive bound in Equation~\eqref{eq:cc_naive} by partitioning the $r$-ball into annuli. Let us start with a simple example. Fix $0<r_1<
  r$, and define $\btheta_{r'} := \frac{r'}{\beta}f_\Lambda$, and observe that 
\begin{align}
  CC_\X&\leq  r\cdot
\left|\X\cap (\B_{r}\setminus \B_{r_1})\right| + r_1\cdot
\left|\X\cap \B_{r_1}\right|\nonumber \\ & = r\left(|\X\cap \B_{r}|-|\X \cap \B_{r_1}|\right) + r_1 \left|\X\cap \B_{r_1}\right| \nonumber\\
& = r|\X\cap \B_{r}|+ (r_1-r) |\X\cap \B_{r_1}| \nonumber \\  
  & = r\frac{\partial(B_1)}{\sqrt{\det(\Lambda)}}\btheta^d_{r} +r P_d(\btheta_{r}) + (r_1-r) \frac{\partial(B_1)}{\sqrt{\det(\Lambda)}}\btheta^d_{r_1}\nonumber\\& + (r_1-r) P_d(\btheta_{r_1}) \nonumber
\\
& = \frac{\partial(B_1)}{\sqrt{\det(\Lambda)}}\theta^d\left(r^{d+1}+{r_1}^{d+1}-r{r_1}^{d}\right)\nonumber\\&+ r P_d(\btheta_{r}) + (r_1-r) P_d(\btheta_{r_1})\nonumber \\ & = \frac{\partial(B_1)}{\sqrt{\det(\Lambda)}}\theta^d\left(r^{d+1}+{r_1}^{d+1}-r{r_1}^{d}\right)+ r P_d(\btheta_{r}), \label{eq:CC1}
\end{align}
where the sample complexity bound in Equation~\eqref{eq:sample_complexity} is used. For simplicity, we upper-bound throughout the error term with $r P_d(\btheta_{r})$.
Next, we optimize the value $r_1$ to minimize the expression in Equation~\eqref{eq:CC1}.

Consider the function $f(r_1)=r^{d+1}-r r^d_1 + r^{d+1}_1$. We look for the minimum of $f(r_1)$ by requiring that
\begin{align*}
            f'(r_1)=-r dr_1^{d-1}+(d+1)r_1^d=0,
\end{align*}
which yields the value $r^*_1:=\frac{d}{d+1}r$. This value is  a minimum since
\begin{align*}
 f^{(2)}(r_1)|_{r_1^*}=&\left(-r(d-1)r_1^{d-2}+d(d+1)r_1^{d-1}\right)|_{r_1^*}\\
        =&r^{d-1}\left(\frac{d^d}{(d+1)^{d-2}}-\frac{d^{d-2}(d-1)}{(d+1)^{d-2}}\right)\\
        =&r^{d-1}d^{d-2}\frac{d^2-d+1}{(d+1)^{d-2}},
    \end{align*}
    and we know that $d^2-d+1>0$ for all $d\geq 2$.%, then $r_1=\frac{d}{d+1}r$ indeed minimizes $f(r_1)$.
    
  
  %   We will use the above expression to upper-bound the number of points in the annulus $\{r_{i+1}\leq \|x\| \leq r_i\}$: %which we would then multiply by $r_i$ to obtain an upper-bound of the distances of points within it. In particular,
% %we can then say that the number of samples we have is approximately \itai{what is the right "approx" here?} the difference of the aforementioned expressions. Recalling that we need to work with $r_i'=\frac{f_\Lambda}{\beta}r_i$ due to rescaling, we get
%     \begin{align*}
%       \left|\X\cap (\B_{r_i}\setminus \B_{r_{i+1}})\right| &=O\left(\frac{1}{d}\left(\frac{2\pi e}{d}\right)^{\frac{d}{2}}(\btheta^d_{r_i}-\btheta^d_{r_{i+1}}) + \btheta^{d-2}_{r_i} - \btheta^{d-2}_{r_{i+1}}\right)\\ &=O\left(\left(\frac{f_\Lambda}{\beta}\right)^{d-2}\left(\underbrace{\frac{1}{d}\left(\frac{2\pi e}{d}\right)^{\frac{d}{2}}\left(\frac{f_\Lambda}{\beta}\right)^2}_{=:\gamma}\left(r_{i}^d-r_{i+1}^d\right)+\left(r_{i}^{d-2}-r_{i+1}^{d-2}\right)\right)\right).      
%     \end{align*}
%     For each such annulus, the maximal radius is $r_i$, and so the sum of distances at the annulus is at most 
% \begin{align} r_i\cdot
% \left|\X\cap (\B_{r_i}\setminus \B_{r_{i+1}})\right|=O\left(\left(\frac{f_\Lambda}{\beta}\right)^{d-2}\left(\gamma\left(r_i^{d+1}-r_ir_{i+1}^d\right)+\left(r_i^{d-1}-r_ir_{i+1}^{d-2}\right)\right)\right).
% \end{align}
% Consequently, we can use the above bound to compute. 
% \begin{align*}
%   CC_\X(r)&\leq \sum_{i=0}^{n-1} r_i\cdot
% \left|\X\cap (\B_{r_i}\setminus \B_{r_{i+1}})\right| + r_n\cdot
% \left|\X\cap \B_{r_n}\right|. %\\ &=
% %\sum_{i=0}^nO\left(\left(\frac{f_\Lambda}{\beta}\right)^{d-2}\left(\gamma\left(r_i^{d+1}-r_ir_{i+1}^d\right)+\left(r_i^{d-1}-r_ir_{i+1}^{d-2}\right)\right)\right) + O\left(\left(\frac{f_\Lambda}{\beta}\right)^{d-2}\left(\gamma r_i^{d+1}+r_i^{d-1}\right)\right)
% \end{align*}

% Next, we derive a heuristic for specifying the radii $r_i$ to minimize the expression $CC_\X(r)$. For that purpose, we will start with the simple case where $n=1$. Observe that
% \begin{align*}
%   CC_\X(r)&\leq  r_1\cdot
% \left|\X\cap (\B_{r}\setminus \B_{r_{1}})\right| + r_1\cdot
% \left|\X\cap \B_{r_1}\right| \\
%   & =O\left(\left(\frac{f_\Lambda}{\beta}\right)^{d-2}\left(\gamma\left(r^{d+1}-rr_{1}^d+r_1^{d+1}\right)+\left(r^{d-1}-rr_{1}^{d-2}+r_1^{d-1}\right)\right)\right).
% \end{align*}

Now, we apply the above line of reasoning in a recursive manner by considering a sequence of $k+1\geq 2$ radii ${0<r_k<\ldots<r_0=r}$ where $r_i:=\td^i r$, where $\td:=\frac{d}{d+1}$. This leads to the bound
\begin{align}
\label{eq:cc_eval}
CC_\X(r)&\leq \sum_{i=0}^{k-1}r_i |\X\cap (\B_{r_i}\setminus \B_{r_{i+1}})| + r_k|\X\cap \B_{r_k}|\nonumber\\
  &= \sum_{i=0}^{k-1}r_i\left(|\X\cap \B_{r_i}|- |\X\cap \B_{r_{i+1}}|\right)+ r_k|\X\cap \B_{r_k}| \nonumber\\
  &= r_0|\X\cap \B_{r_0}| + \sum_{i=1}^{k}(r_i - r_{i-1})|\X\cap \B_{r_i}| \nonumber\\
  & =r_0\left(\frac{\partial(B_1)}{\sqrt{d}}\btheta^d_{r_0} +\P_d(\btheta^{d-2}_{r_0})\right) \nonumber\\&+ \sum_{i=1}^{k}(r_i - r_{i-1}) \left(\frac{\partial(B_1)}{\sqrt{d}}\btheta^d_{r_i} +\P_d(\btheta^{d-2}_{r_i})\right) \nonumber\\
  &= \frac{\partial(B_1)}{\sqrt{d}} \left(\underbrace{r_0 \btheta^d_{r_0} + \sum_{i=1}^k(r_i-r_{i-1}) \btheta^d_{r_i}}_{:=\gamma(d)}\right) \nonumber\\&+ \P_d\left(\underbrace{r_0\btheta^{d-2}_{r_0} + \sum_{i=1}^{k}(r_i - r_{i-1}) \btheta^{d-2}_{r_i}}_{:=\gamma(d-2)}\right).
\end{align}

Next, we develop the expression $\gamma(N)$ above for some general $N\in\mathbb{N}$ by substituting $r_i=\td^i r$ and $\btheta_{r_i}= r_i\btheta_{r}/r$: 
\begin{align}
  \gamma(N) &=r \btheta^N_{r} + \sum_{i=1}^k(r_i-r_{i-1}) r_i^d\frac{\btheta^N_{r}}{r^d} \nonumber\\
  & = r \btheta^N_{r} + \sum_{i=1}^kr\td^{i-1}(\td-1) \td^{di} r^d\frac{\btheta^N_{r}}{r^d} \nonumber\\ 
  &=  r \btheta^N_{r} + \sum_{i=1}^kr (\td-1) \td^{Ni+ i -1} \btheta^N_{r} \nonumber\\ 
  &=   r \btheta^d_{r} \left(1 + \sum_{i=1}^k (\td-1) \td^{Ni+ i -1} \right)\nonumber\\
  &= r \btheta^N_{r} \left(1 + \frac{\td-1}{\td}\sum_{i=1}^k \td^{(N+1)i} \right)\nonumber\\
  &= r \btheta^N_{r} \left(1 + \frac{\td-1}{\td}\frac{\left(\td^{N+1}\right)^{k+1} - \td^{N+1}}{\td^{N+1} - 1} \right)\nonumber\\
  &= r \btheta^N_{r} \left(1 + \td^N(\td-1)\frac{\left(\td^{N+1}\right)^k - 1}{\td^{N+1} - 1} \right).\nonumber\\
  % & = r \btheta^d_{r} + \sum_{i=1}^kr\td^{i-1}(\td-1) \td^{di} r^d\frac{\btheta^d_{r}}{r^d} \\ &  =  r \btheta^d_{r} + \sum_{i=1}^kr (\td-1) \td^{di+ i -1} \btheta^d_{r} \\ & =   r \btheta^d_{r} \left(1 + \sum_{i=1}^k (\td-1) \td^{di+ i -1} \right)\\
\end{align}

Taking $k=d$ results in $r_k=(\frac{d}{d+1})^dr\approx\frac{1}{e}r$ . To use the sample set analysis, we need a large enough $r$ value, so assuming the original $r$ is large enough, we can deduce safely that $\frac{r}{e}$ is also large enough. Notice also that $\td - 1 = \frac{-1}{d+1}$, so returning to our expression, we get
\begin{align*}
      &= r \btheta^N_{r} \left(1 - \frac{\td^N\left(\td^{d(N+1)} - 1\right)}{(d+1)(\td^{N+1} - 1)}\right).
      % &= r \btheta^d_{r} \left(1 - \frac{x\left(x^{d+1} - 1\right)}{(d+1)(\td x - 1)}\right)\nonumber\\
      % &= r \btheta^d_{r} \left(1 - \frac{x^{d+2} - x}{ dx - (d+1))}\right).
\end{align*}
Notice that $\td < 1$. Therefore, $\td^{d(N+1)}-1 < 0$ and $\td^{N+1} - 1 < 0$, so our expression in the parenthesis is less than 1---suggesting an improvement on the trivial bound with $\gamma(N)$.
Let $x:=\td^d$, we get:
\begin{align*}
    \gamma(d)&=r \btheta^d_{r} \left(1 - \frac{\td^d\left(\td^{d(d+1)} - 1\right)}{(d+1)(\td^{d+1} - 1)}\right)\\
    &= r \btheta^d_{r} \left(1 - \frac{x\left(x^{d+1} - 1\right)}{(d+1)(\td x - 1)}\right)\nonumber\\
    &= r \btheta^d_{r} \left(1 - \frac{x^{d+2} - x}{ dx - (d+1))}\right),\\
    \gamma(d-2)&=r \btheta^{d-2}_{r} \left(1 - \frac{\td^d\left(\td^{d(d-1)} - 1\right)}{(d+1)(\td^{d-1} - 1)}\right)\\
    &= r \btheta^{d-2}_{r} \left(1 - \frac{x\left(x^{d-1} - 1\right)}{(d+1)(\frac{x}{\td} - 1)}\right)\nonumber\\
    &= r \btheta^{d-2}_{r} \left(1 - \frac{x^d - x}{ \frac{(d+1)^2}{d}x - (d+1))}\right)\nonumber\\
    &= r \btheta^{d-2}_{r} \left(1 - \frac{d(x^d - x)}{ (d+1)^2x - d(d+1))}\right) \nonumber\\
    &= r \btheta^{d-2}_{r} \left(1 - \frac{d}{d+1}\frac{x^d - x}{ (d+1)x - d}\right).
\end{align*}
Finally, we return to our original upper bound in~\ref{eq:cc_eval}, getting
\begin{align*}
    CC_\X(r)&\leq \left(1 - \frac{x^{d+2} - x}{ dx - (d+1))}\right)\cdot r \frac{\partial(B_1)}{\sqrt{\det(\Lambda)}}\btheta^d_{r}  \\&+ \P_d\left(\left(1 - \frac{d(x^d - x)}{ (d+1)^2x - d(d+1))}\right)\cdot r \btheta^{d-2}_{r} \right)
\end{align*}
with $x:=\td^d, \td:=\frac{d}{d+1}$.

% The general expression we get is
%     \begin{align*}
%         r_i^{D+1} - r_ir_{i+1}^D=&
%         \left(\left(\frac{D}{D+1}\right)^ir\right)^{D+1} - \left(\left(\frac{D}{D+1}\right)^ir\right)\left(\left(\frac{D}{D+1}\right)^{i+1}r\right)^D\\
%         =& r^{D+1}\left[\left(\left(\frac{D}{D+1}\right)^i\right)^{D+1} - \frac{D+1}{D}\left(\left(\frac{D}{D+1}\right)^{i+1}\right)^{D+1}\right]\\
%         =& r^{D+1}\left[\left(\left(\frac{D}{D+1}\right)^i\right)^{D+1} -\frac{D+1}{D}\left(\left(\frac{D}{D+1}\right)^i\right)^{D+1}\left(\frac{D}{D+1}\right)^{D+1}\right]\\
%         =& r^{D+1}\left(\left(\frac{D}{D+1}\right)^i\right)^{D+1}\left(1-\left(\frac{D}{D+1}\right)^D\right)
%     \end{align*}
%     After simplifying this, recall that the approximation for the number of samples in a ball is true for radius values that are big enough. Therefor, we need to start from $i=k$ big enough such that $\left(\frac{D}{D+1}\right)^ir$ is still a big enough radius. Dotice that for $i=D$ we get $\left(\frac{D}{D+1}\right)^D\geq\frac{1}{e}$, so we can safely use $i=D,r_D\approx0.36r$ up until even $i=2D,r_{2D}\approx0.13r$. We now sum over all valid annulus, getting
%     \begin{align*}
%         &\sum_{i=0}^{i=k}r^{D+1}\left(\left(\frac{D}{D+1}\right)^i\right)^{D+1}\left(1-\left(\frac{D}{D+1}\right)^D\right)\\
%         =&r^{D+1}\left(1-\left(\frac{D}{D+1}\right)^D\right)\sum_{i=0}^{i=k}\left(\left(\frac{D}{D+1}\right)^{D+1}\right)^i\\
%         =& r^{D+1}\left(1-\left(\frac{D}{D+1}\right)^D\right)\frac{\left(\frac{D}{D+1}\right)^{(k+1)(D+1)} - 1}{\left(\frac{D}{D+1}\right)^{D+1} - 1}\\
%         =& r^{D+1}\frac{1-\left(\frac{D}{D+1}\right)^D}{1-\left(\frac{D}{D+1}\right)^{D+1}}\left(1-\left(\frac{D}{D+1}\right)^{(k+1)(D+1)}\right),
%     \end{align*}
%     We now add the innermost $r_k$-ball, in addition to the annulii, getting
%     \[
%         r^{D+1}\frac{1-\left(\frac{D}{D+1}\right)^D}{1-\left(\frac{D}{D+1}\right)^{D+1}}\left(1-\left(\frac{D}{D+1}\right)^{(k+1)(D+1)}\right)+\left(\frac{D}{D+1}\right)^{k(D+1)}r^{D+1}:=r^{D+1}a_{D,k},
%     \]
    % with letting $a_{D,k}$ be the entire expression without the $r^{D+1}$ part. Let us use this on our original expression
    % \begin{align*}
    %     I(r)=&\frac{1}{d}\left(\frac{2\pi e}{d}\right)^{\frac{d}{2}}\left(\frac{f_\Lambda}{\beta}\right)^{d+1}r^{d+1}a_{D,k} + \left(\frac{f_\Lambda}{\beta}\right)^{d-1}r^{d-1}a_{D-2,k}
    % \end{align*}
\end{proof}

\begin{figure}[thb]
\centering  
\includegraphics[width=0.9\columnwidth]{Images/annuli_bound.png}
\caption{Theoretical sample limit improvement factor using the annuli method. \kiril{Change orientation of improvement factor to vertical.}}
\label{fig:annuli_bound}
\end{figure}

We can see in~\Cref{fig:annuli_bound} the improvement term of the main term as a function of the dimension: notice that the improvement rate diminishes as $d$ gets larger.%Comparatively, the trivial bound would've given us:
%\[
%    CC_\X(r)\leq r \frac{\partial(B_1)}{\sqrt{d}}\btheta^d_{r} + \Theta\left(r \btheta^{d-2}_{r} \right)
%\]
% \begin{figure*}[!h]
%   \centering
%   \subfloat["H" map]{
%     \includegraphics[width=0.3\textwidth]{Images/Hmap_basic.png}
%     \label{fig:exp_3body:hmap}}
%   \hfil
%   \subfloat["Random polygons" map]{
%     \includegraphics[width=0.3\textwidth]{Images/rndpoly_basic.png}
%     \label{fig:exp_3body:rndpoly}}
%   \caption{The scenarios we used to test our sample set, in each map we wanted each disk-robot to switch places with the next neighbor. \kiril{Add more dimensions to the left and right plots.}}
%   \label{fig:exp_3body}
% \end{figure*}

\kiril{Note to self: revise this paragraph.} To compare these values with a theoretical "better" one, a simulation was run with the following algorithm: 
\begin{enumerate}
    \item Assume $d=6,r_0=1, r_D=\left(\frac{D}{D+1}\right)^{k}$.
    \item In addition to these two radii, add $D-2$ more concentric circles of random radius values between the values $r_0, r_D$.
    \item For this random division, calculate the fitting $r^{d+1},r^{d-1}$ improvement parameters (we get them due to setting $r=1$).
\end{enumerate}
After running this process for 1000 iterations, the best parameters we got were $0.881, 0.821$, for $r^{d+1},r^{d-1}$ (respectively). This suggests that while there is room for improvement in this method, it is close enough to the best improvement we can get in the method of "layered approximation."
% \subsection*{A bit of intuition on the achieved upper bound}
% Notice that asymptotically, as $d$ gets very large, the term $\left(1+\frac{1-e^{-d}}{d}\right)$ goes very quickly to $1$. So at higher $d$ values, we are effectively left with the original sample sizes, only now times the rescaled radius again, getting $O(radius\cdot \#samples)$.
% % \[
% %     I\left(r\right)\approx O\left(\left(\sum_i\|e_i\|^2\right)\btheta^{d-2}\left(\frac{\btheta}{r \left(d-1\right)}+1\right)\right).
% % \]
% % Seeing as $\btheta>1$ and $d$ is high, we can ignore the $+1$ term, and get
% % \[
% %     I\left(r\right)\approx O\left(\frac{\sum_i\|e_i\|^2}{r\left(d-1\right)}\btheta^{d-1}\right),
% % \]
% % and because, as we will see below, we deal with lattices such that ${\sum_i\|e_i\|^2=O\left(d\right)}$, we end up with
% % \[
% %     I\left(r\right)\approx O\left(\frac{d}{r\left(d-1\right)}\btheta^{d-1}\right)= O\left(\frac{1}{r}\btheta^{d-1}\right).
% % \]
% % Recall that in theorem~\ref{general_sample_complexity} our dominant term for evaluating the number of samples is $\left(\btheta\right)^{d-2}$. Expecting an average distance of $c\btheta$ for points in the sphere (
% Looking at random points, we have an expected distance from the center of $\frac{n}{n+1}r$, so also with random points we "expect" to get more or less $O(\frac{n}{n+1}\cdot radius\cdot \#samples)=O(radius\cdot \#samples)$, which is similar to our term, suggesting that our upper bound is at least of the optimal order.
% \itai{Next part is irrelevant with this new computation. with this, it just becomes a direct extension of the sample-complexity section calculations.}
% % our total distance for a group of points is 
% % \[
% %     I\left(r\right)\approx c\btheta \cdot \left(\btheta\right)^{d-2}=O\left(\btheta\right)^{r-1},
% % \]
% % which is very similar to the type of term we managed to get. The specific complexity values for the lattices are not significantly different from this intuition, but it is important to show it rigorously.

%Next, we perform experiments to check the effectiveness of our lattices, compared to each other and to other sample sets.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../main"
%%% End:
