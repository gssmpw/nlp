\section{Limitations and future work}\label{sec:future}
We leveraged foundational results in lattice theory to develop a theoretical framework for generating efficient sample sets for motion planning that endow their planners with finite-time guarantees, which are vastly superior to previous asymptotic properties. We demonstrated the practical potential of the framework in challenging motion-planning scenarios wherein our $A_d^*$-based sampling procedures lead to substantial speeds over previous methods (deterministic and random).
Below, we discuss several limitations of our work, which motivate further research directions.

\niceparagraph{Multi-resolution search.} The choice of the sampling parameters $\delta$ and $\epsilon$ can significantly impact the sample and collision-check complexity of the sampling distribution, and hence the planner's performance. In this work, we selected those values according to a rule of thumb, which might not be generally applicable to broader problem settings, or lead to feasible solutions.  We plan on exploring algorithmic extension, which would allow the automatic selection of those parameters during runtime. One promising direction is exploiting multi-resolution search~\cite{saxena2022amra,FuSSA23}, which allows for adjusting sampling densities according to the space's structure. This has the potential of not only simplifying the usage of our sample sets but also significantly improving the planner's performance.  

\niceparagraph{Non-Euclidean systems.} Our current work focuses on geometric systems (whose state space is Euclidean)  and path-length cost functions, which limits its applicability. In the future, we plan to extend our work to more general settings, which entails at least two challenges. First, the adaptation of our sampling distributions to non-Euclidean spaces is non-trivial due to the heterogeneity of the space coordinates, e.g., position and rotation components in SE(3)~\cite{yershova2004deterministic}, or state derivatives in dynamical systems~\cite{janson2018deterministic}. Second, those settings call for more general cost functions, which requires revising the concept of \decomps and its relation to geometric coverage (particularly, Lemma~\ref{lem:cover}). We plan to address those challenges incrementally. As a first step, we plan on generalizing our theory to linear systems with quadratic costs, where we believe that the structure of LQR controllers~\cite{liberzon2011calculus} can be useful. More general approaches could be obtained from exploiting the locally-linear structure of nonlinear systems using differential geometry~\cite{BulloLewis04}.

\niceparagraph{Incremental sampling.} Uniform random sampling is naturally amenable for densification, i.e., the incremental addition of new sampling points, making them applicable for anytime planner like RRT or RRT*~\cite{LaVKuf01,karaman2011sampling}. In contrast, lattice-based sampling requires the introduction of large batches, which currently limits their applicability. One way to bridge this gap could be generalizing Halton sequences~\cite{kuipers2012uniform}, a popular method for deterministic incremental low-discrepancy sampling, to the $A^*_d$ lattice. Halton sequences ensue from transforming points from the standard grid lattice $\dZ^d$, and it would be interesting to understand the structure emerging from feeding those points through the generator matrix of the lattice $A^*_d$. Another interesting direction is incrementally introducing the elements of lattice-based samples according to a random permutation.

 
%\itai{I also considered at a few points using a dRRT-like "oracle" system to create an RRT that runs on a lattice, somehow.} \kiril{Let's discuss this. }


% incremental

% multi-resolution

% improved CC bounds


% \subsection{Better bounds and square bounds}
% Better upper bounds, using the lattice structure more carefully, may be developed---maybe somehow utilizing the lattice structure itself to get a bound.


% In addition to that, we limited ourselves to looking at the sample and collision complexity inside balls, but it could be possible to adept our results to the case of general cubic C-Spaces. For this, the study of $\ZN$-points in $d$-dimensional parallelotopes has to be conducted , as this translates to the number of $\LN$-points in $d$-dimensional cubes.


% In general, this is a difficult subject with much greater mathematical depths and complexity outside the scope of this paper.

% \subsection{A lattice version of the \decomp theory}
% In this paper we used the theoretical results from Dayan et al.~\cite{dayan2023near}, which fit the circumstance well enough. Still, it is possible that a theorem could be fitted ad-hoc to the case of lattices, resulting in a much clearer statement about the resolution needed to solve a problem efficiently.

% \subsection{Dynamic resolution}
% Across testing, a clear problem became choosing the clearance. In our case, wisely choosing the start locations and the maps assisted us in getting a good clearance. In the general case, though, it isn't clear if it is at all possible to get a good clearance. Even if the optimal clearance for a problem is found, it is possible that the resulting lattice sample set is too dense, resulting in an infeasible runtime. One good direction to explore, then, would be to develop an algorithm similar to what Fu et al.~\cite{fu2021toward} did. In this paper, you attempt to develop a tree-like structure in the kynodynamic settings, using a variable set of scaling factors. Borrowing from that, using the $\AN$ sample set with a changing scaling factor to fit the longest edge you can could prove beneficial. It would also serve as a way to bypass the need to "intelligently" guess the correct $\delta$ value for the map.

% \subsection{Lattices in kinodynamic algorithms}
% In some kinodynamic algorithms, like KinoRRT (ref?) and steerable-needles MP~\cite{fu2021toward}, progressing from where the robot is to the next point uses either randomly sampled controls (like in KinoRRT, in which the time and control inputs are randomly sampled) or deterministicly sampled controls (like in the steerable-needle case, which uses motion primitives). It is perhaps interesting, then, to study the influence of specifically using $\AN$ with these algorithms, perhaps to see if some improvements in some aspects of them could be made.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../main"
%%% End:
