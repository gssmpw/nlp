%% 
%% Copyright 2007-2024 Elsevier Ltd
%% 
%% This file is part of the 'Elsarticle Bundle'.
%% ---------------------------------------------
%% 
%% It may be distributed under the conditions of the LaTeX Project Public
%% License, either version 1.3 of this license or (at your option) any
%% later version.  The latest version of this license is in
%%    http://www.latex-project.org/lppl.txt
%% and version 1.3 or later is part of all distributions of LaTeX
%% version 1999/12/01 or later.
%% 
%% The list of all files belonging to the 'Elsarticle Bundle' is
%% given in the file `manifest.txt'.
%% 
%% Template article for Elsevier's document class `elsarticle'
%% with numbered style bibliographic references
%% SP 2008/03/01
%% $Id: elsarticle-template-num.tex 249 2024-04-06 10:51:24Z rishi $
%%
\documentclass[preprint,12pt]{elsarticle}

%% Use the option review to obtain double line spacing
%% \documentclass[authoryear,preprint,review,12pt]{elsarticle}

%% Use the options 1p,twocolumn; 3p; 3p,twocolumn; 5p; or 5p,twocolumn
%% for a journal layout:
%% \documentclass[final,1p,times]{elsarticle}
%% \documentclass[final,1p,times,twocolumn]{elsarticle}
%% \documentclass[final,3p,times]{elsarticle}
%% \documentclass[final,3p,times,twocolumn]{elsarticle}
%% \documentclass[final,5p,times]{elsarticle}
%% \documentclass[final,5p,times,twocolumn]{elsarticle}

%% For including figures, graphicx.sty has been loaded in
%% elsarticle.cls. If you prefer to use the old commands
%% please give \usepackage{epsfig}

%% The amssymb package provides various useful mathematical symbols
\usepackage{amssymb}
%% The amsmath package provides various useful equation environments.
\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{array}
\usepackage{xcolor}
\usepackage{graphicx}
\usepackage{multirow}
\usepackage{xpatch}
\usepackage{colortbl}
\definecolor{lightgray}{gray}{0.95}
\definecolor{lightred}{rgb}{1.0, 0.85, 0.85}
\definecolor{lightgreen}{rgb}{0.85, 1.0, 0.85}

\makeatletter
\renewcommand\paragraph{\@startsection{paragraph}{4}{\z@}%
    {-3.25ex \@plus -1ex \@minus -.2ex}%
    {-1em}%
    {\normalfont\normalsize\itshape}}
\makeatother
%% The amsthm package provides extended theorem environments
%% \usepackage{amsthm}


%% The lineno packages adds line numbers. Start line numbering with
%% \begin{linenumbers}, end it with \end{linenumbers}. Or switch it on
%% for the whole article with \linenumbers.
%% \usepackage{lineno}

% \journal{Computers in Biology and Medicine}

\begin{document}

\begin{frontmatter}

%% Title, authors and addresses

%% use the tnoteref command within \title for footnotes;
%% use the tnotetext command for theassociated footnote;
%% use the fnref command within \author or \affiliation for footnotes;
%% use the fntext command for theassociated footnote;
%% use the corref command within \author for corresponding author footnotes;
%% use the cortext command for theassociated footnote;
%% use the ead command for the email address,
%% and the form \ead[url] for the home page:
%% \title{Title\tnoteref{label1}}
%% \tnotetext[label1]{}
%% \author{Name\corref{cor1}\fnref{label2}}
%% \ead{email address}
%% \ead[url]{home page}
%% \fntext[label2]{}
%% \cortext[cor1]{}
%% \affiliation{organization={},
%%             addressline={},
%%             city={},
%%             postcode={},
%%             state={},
%%             country={}}
%% \fntext[label3]{}

%%\title{Adaptive Voxel-Weighted Loss Using L1 Norms for Automated Detection and Segmentation of Prostate Cancer Lesion via Deep Neural Networks from PET/CT Images}
\title{Adaptive Voxel-Weighted Loss Using L1 Norms in Deep Neural Networks for Detection and Segmentation of Prostate
Cancer Lesions in PET/CT Images}


%% use optional labels to link authors explicitly to addresses:
%% \author[label1,label2]{}
%% \affiliation[label1]{organization={},
%%             addressline={},
%%             city={},
%%             postcode={},
%%             state={},
%%             country={}}
%%
%% \affiliation[label2]{organization={},
%%             addressline={},
%%             city={},
%%             postcode={},
%%             state={},
%%             country={}}
\renewcommand{\thefootnote}{\fnsymbol{footnote}}
\author[a,b,c]{Obed Korshie Dzikunu\footnotemark[1]}
\author[d,b]{Shadab Ahamed\footnotemark[2]}
\author[b,e]{Amirhossein Toosi\footnotemark[2]}
\author[f,c]{Xiaoxiao Li}
\author[a,b,d,e]{Arman Rahmim}
%% Author name

%% Author affiliation

\affiliation[a]{organization={School of Biomedical Engineering},%Department and Organization
            addressline={University of British Columbia}, 
            city={Vancouver},
            country={Canada}}
            
\affiliation[b]{organization={Department of Integrative Oncology},%Department and Organization
            addressline={BC Cancer Research Institute}, 
            city={Vancouver},
            country={Canada}}

\affiliation[c]{organization={Vector Institute},%Department and Organization
            city={Toronto},
            country={Canada}}

            
\affiliation[d]{organization={Department of Physics \& Astronomy},%Department and Organization
            addressline={University of British Columbia}, 
            city={Vancouver},
            country={Canada}}
            
\affiliation[e]{organization={Department of Radiology},%Department and Organization
            addressline={University of British Columbia}, 
            city={Vancouver},
            country={Canada}}
            
\affiliation[f]{organization={Department of Electrical and Computer Engineering},%Department and Organization
            addressline={University of British Columbia}, 
            city={Vancouver},
            country={Canada}}



% Change the footnote symbol to an asterisk
% \renewcommand{\thefootnote}{\fnsymbol{footnote}}

% Add the footnote text with the asterisk
% \footnotetext[1]{These authors contributed equally to this work.}

%% Abstract
\begin{abstract}
This study proposes a new loss function for deep neural networks, L1-weighted Dice Focal Loss (L1DFL), that leverages L1 norms for adaptive weighting of voxels based on their classification difficulty, towards automated detection and segmentation of metastatic prostate cancer lesions in PET/CT scans. We obtained 380 prostate-specific membrane antigen (PSMA) [$^{18}$F]DCFPyL PET/CT scans of patients diagnosed with biochemical recurrence metastatic prostate cancer. We trained two deep neural networks with 3D convolutional neural network backbone --- Attention U-Net and SegResNet --- and concatenated the PET and CT volumes channel-wise as input. The performance of our custom loss function was evaluated against the Dice and Dice Focal Loss functions. For clinical significance, we considered a detected region of interest (ROI) as a true positive if at least the voxel with the maximum standardized uptake value falls within the ROI. We assessed the modelsâ€™ performance based on the number of lesions in an image, tumor volume, activity and extent of lesion spread. The L1DFL outperformed the comparative loss functions by at least $13\%$ on the test set. In addition, the F1 scores of the Dice Loss and the Dice Focal Loss were lower than that of L1DFL by at least $6\%$ and $34\%$, respectively. The Dice Focal Loss yielded more false positives, whereas the Dice Loss was more sensitive to smaller volumes and struggled to segment larger lesions accurately. They also exhibited network-specific variations and yielded declines in segmentation accuracy with increased tumor spread. Our results demonstrate the potential of L1DFL to yield robust segmentation of metastatic prostate cancer lesions in PSMA PET/CT images. The results further highlight potential complexities arising from the variations in lesion characteristics that may influence automated prostate cancer tumor detection and segmentation. The code is publicly available at: https://github.com/ObedDzik/pca\_segment.git.
\end{abstract}

% %%Graphical abstract
% \begin{graphicalabstract}
% %\includegraphics{grabs}
% \end{graphicalabstract}

%%Research highlights
% \begin{highlights}
% \item Besides uptake, tumor characteristics such as volume and dissemination limit automated detection performance.
% \item Dice and Dice Focal Losses may decline in performance with increased metastasis.
% \item Proposed loss function outperforms the Dice and Dice Focal losses by at least $13\%$ based on Dice Score.
% \item Proposed loss function outperforms Dice loss and Dice Focal losses by $6\%$ and $34\%$, respectively, on F1 score.
% \end{highlights}

%% Keywords
\begin{keyword}
Detection \sep segmentation \sep L1 norm, adaptive weighting, loss function, PSMA PET/CT imaging
%% keywords here, in the form: keyword \sep keyword

%% PACS codes here, in the form: \PACS code \sep code

%% MSC codes here, in the form: \MSC code \sep code
%% or \MSC[2008] code \sep code (2000 is the default)

\end{keyword}
\end{frontmatter}
\renewcommand{\thefootnote}{\fnsymbol{footnote}}
\footnotetext[1]{Corresponding author: Obed Dzikunu (email: okdzikunu@gmail.com)}
\footnotetext[2]{These authors contributed equally to this work.}

%% Add \usepackage{lineno} before \begin{document} and uncomment 
%% following line to enable line numbers
%% \linenumbers

%% main text
%%

%% Use \section commands to start a section
\section{Introduction}
\label{intro}
Semantic segmentation involves mapping every pixel of an image to a class, whether an object or a background \cite{farabet2012learning}. It requires both a local and contextual understanding of the image \cite{chen2014semantic}, making it particularly difficult since neighboring pixels are highly related; thus, information on the spatial context and the boundary's smoothness is essential in a segmentation model \cite{7478072}. Particularly in medical image analysis, higher accuracy levels are required for tumor segmentation since false detections may significantly impact patient management \cite{macmanus2009use}. However, medical images are fraught with an imbalance in the proportion of voxels belonging to the regions of interest (ROIs) compared to the background making a balance in precision and sensitivity in automated segmentation a challenging task.

Whole body positron emission tomography (PET) scans of cancer patients are an example of such medical images where voxels corresponding to the foreground class are overwhelmingly outnumbered by background voxels. These images are characterized by high variability in lesion size, shape, and intensity, as well as significant heterogeneity in tracer uptake \cite{hofheinz2013automatic}. In the case of metastatic prostate cancer (mPCa) images, lesions can range from small, low-contrast regions barely distinguishable from surrounding tissues to large, high-uptake areas with well-defined boundaries, and may occupy different anatomical sites \cite{fendler201768}. In localizing these lesions, the prostate-specific membrane antigen (PSMA) is often targeted due to its high expression by tumor cells. However, PSMA expression is not exclusive to prostate cancer lesions; it is also found in other tissues, including salivary glands, kidneys, and the small intestine, as well as in certain non-prostatic malignancies and inflammatory processes \cite{lauri2022psma}. This broad expression can lead to radiotracer uptake in non-cancerous or non-prostatic regions challenging the specificity of computer-aided detection algorithms. Thus, the challenge in artificial intelligence (AI) based lesion detection and segmentation in PET scans of metastatic prostate cancer lesions is avoiding false-positive segmentation of anatomical structures and other artifacts while maintaining accurate lesion detection.

With most of the automated approaches, improved sensitivity of mPCa lesions often comes at the cost of specificity, yet both extremes pose potential risks. One commonly used strategy for limiting false positive rate is standardized uptake value (SUV) thresholding, which involves defining all voxels with SUV greater than some value, typically considering the background uptake of the liver to be foreground and all other voxels as background \cite{foster2014review}. This method may be included as part of the automated segmentation process or as a post-processing step and has been shown to reduce false positive counts \cite{gafita2019qpsma}. Yet, its major drawback is the potential of having a reduced sensitivity for lesions that exhibit lower avidity for the radiotracer, or in patients with extensive liver metastases \cite{li2024automated}. 

Loss function design is another strategy that has received much attention and has led to an improvement in the performance of AI-based segmentation methods. The widely used loss function is the Dice Loss. It is based on the Dice Similarity Coefficient (DSC) and penalizes pixel-wise discrepancies between the predicted maps and their corresponding ground truth for each class \cite{LIU2024103015}.  A model trained using the Dice Loss objective maximizes DSC inherently incorporating a balance in sensitivity and specificity \cite{10.1007/978-3-319-46976-8_19}. Nevertheless, the Dice Loss is not well-suited for handling another type of imbalance caused by a difference in the difficulty in classifying pixels \cite{9338261}. Within a class, be it the minority foreground class or majority background class, some pixels might be easier to classify, with models achieving greater than $50\%$ probability of correctly classifying such pixels \cite{9338261}. However, others may be more challenging to predict, yielding lower probabilities \cite{9338261} and are therefore designated hard to classify. Without a focusing strategy implemented, the Dice Loss can be easily overwhelmed by the easy-to-classify samples and may perform poorly on the harder ones \cite{10.1007/978-3-030-59719-1_51}. Besides, it exhibits an inconsistent performance when segmenting multiple lesions of varying sizes in an image \cite{10.1007/978-3-030-00919-9_26}.

These limitations have prompted the development of alternative loss functions. Distribution-based loss functions like Focal and Cross-Entropy losses are frequently used alternatives due to their dynamic focusing ability. They are often combined with the Dice Loss and its variants to form compound loss \cite{LIU2024103015} since the losses based on overlap measurements are more robust for medical segmentation tasks \cite{10.1007/978-3-319-67558-9_28}. With an additional ability to control the model's focus on detecting ROIs, these combo losses generalize well \cite{LIU2024103015,10.1007/978-3-030-00931-1_70}. The challenge, however, remains on the balance of sensitivity and specificity as these compound losses tend to lose the Dice Loss component, potentially leading to more false positive segmentation \cite{YEUNG2022102026}. Thus, various regularizations and additional constraints are required to improve model accuracy for a medical lesion segmentation task \cite{rana2022data}.

This work proposes a new loss function, \textit{L1-weighted Dice Focal Loss} (L1DFL), with a dynamic weighting strategy based on L1 norms of predicted probabilities and ground truth labels. Using L1 norms, the loss function considers the difficulty of each sample and the prevalence of similar samples in the dataset. In medical image segmentation tasks, datasets are often imbalanced (disproportionately higher number of background voxels than ROIs) and dominated by easy samples (voxels that are easily classified correctly); the L1 norms of these easy samples tend to approach zero. Our technique focuses on down-weighting both easy samples and those with high L1 norm counts, which are likely to represent the background. We demonstrate the efficiency of L1DFL by experiments on [$^{18}$F]DCFPyL PET/CT scans of patients with biochemical recurrence metastatic prostate cancer, for which lesions have varied sizes, primarily small, with low uptake values.

The main contributions of this work are as follows: (i) we introduce a novel loss function, L1-weighted Dice Focal Loss (L1DFL), incorporating a dynamic weighting strategy; (ii) we evaluate the performance of L1DFL, Dice Loss, and Dice Focal Loss functions in handling false positives and false negative rates; (iii) we compare the segmentation performance of the loss functions based on different lesion scenarios: single-lesion, and multiple lesions. These scenarios are based on the number of lesions in an image; (iv) we evaluate the performance of these loss functions on different clinical metrics like molecular tumor volumes and the extent of lesion spread in the body; and (v) we assess performance using two network architectures, Attention U-Net \cite{oktay2018attention} and SegResNet \cite{myronenko20193d}.


\section{Materials and Methods}
\label{method}
\subsection{Dataset}

We analyzed 380 prostate-specific membrane antigen (PSMA) [$^{18}$F]DCFPyL PET/CT scans of patients diagnosed with biochemical recurrence metastatic prostate cancer as part of an ongoing clinical trial (NCT02899312) with informed written consent obtained from the subjects. The image data collection was approved by the University of British Columbia â€“ BC Cancer Ethics Board. The inclusion criteria for the patients were:
(1)	histologically proven prostate cancer with biochemical recurrence after initial curative therapy with radical prostatectomy, with a PSA $>$ 0.4 ng/mL and an additional PSA measurement confirming an increase; and (2) histologically proven prostate cancer with biochemical recurrence after initial curative radiotherapy, with a PSA $>$ 2 ng/mL after therapy, with five or fewer lesions identified on [$^{18}$F]DCFPyL PET/CT \cite{harsini2023outcome}.

Each patient received an average dose of 350 MBq [$^{18}$F]DCFPyL after fasting for four hours, with dose adjustments based on body weight. Imaging was conducted 120 minutes after injection using a GE Discovery 600 or 690 scanner (GE Healthcare, USA). A non-contrast-enhanced CT scan was acquired for localization and attenuation correction (120 kV, automatic mA adjustment from 30â€“200 mA, and a noise index of 20). Following CT acquisition, a whole-body PET scan was conducted at 2â€“4 minutes per bed position, depending on the participantâ€™s size, with reconstruction performed using an ordered subset expectation maximization algorithm and point-spread function modeling. Each transaxial PET image had a matrix resolution of 192 Ã— 192 pixels, with a physical pixel size of \(3.64\text{mm}^2\). An expert nuclear medicine physician performed manual segmentation on all active lesions \cite{harsini2023outcome}.

There were a total of 684 prostate cancer (PCa) lesions across the entire dataset with a mean active lesion volume of 6.68 $\pm$ 10.20 ml. The lesions varied in uptake with the average maximum standardized uptake value (SUVmax) and mean standardized uptake value (SUVmean) being 12.65$\pm$14.46 and 4.62 $\pm$ 3.88, respectively.

\subsection{Ground Truth Annotation}
The ground truth segmentations were performed by a board-certified nuclear medicine physician from the BC Cancer Research Institute. All lesions were annotated using the PET Edge tool, a semi-automated gradient-based segmentation tool, and contours refined using the 3D Brush tool. Both tools are available in the MIM workstation (MIM software, Ohio, USA). These segmentations served as the ground truth labels for training the models.

\subsection{Data Preprocessing and Augmentation}

After acquiring the images, PET activity values were converted to decay-corrected standardized uptake values (SUV), and the CT intensity values (in Haunsfield units) were clipped to the range $[-1000, 3000]$ before normalizing to a uniform range of $[0, 1]$. The PET images however, were left in their absolute SUV values. We resampled all images, including PET, CT and ground truth (GT) masks to an isotropic voxel spacing of $[2 \text{ mm}, 2 \text{ mm}, 2 \text{ mm}]$ using bilinear interpolation for the CT and PET images and nearest-neighbor interpolation for the GT masks. For augmentation, we applied random cropping and affine transformations for the training images, including translations in (-10,10) voxels in every spatial dimension, rotations of up to $\frac{\pi}{15}$, and scaling by a factor of up to 1.1. We obtained cubic patches of dimensions $128 \times 128 \times 128$ voxels with an $80\%$ probability of being centered around a foreground voxel. The augmented CT and PET patches were channel-concatenated and fed as input to the networks.

\subsection{Architectures}
In this work, we implemented and studied two convolutional neural network architectures: Attention U-Net \cite{oktay2018attention} and SegResNet \cite{myronenko20193d}. These networks, built on top of a 3D-CNN backbone, comprise encoder and decoder blocks. The SegResNet uses residual blocks with skip connections for feature propagation and maintaining gradient stability during training \cite{myronenko20193d}. The encoder path contained blocks with the following number of layers: 1, 2, 2, and 4, allowing for increasing levels of feature extraction at different resolutions. The initial filter size was set to 16 channels, then doubled through each downsampling step to capture progressively higher-level features. Each convolutional layer employs a ReLU activation function, and Group Normalization \cite{wu2018group}. The decoder path, containing one layer in each block, gradually reconstructs the segmented output while leveraging skip connections to preserve spatial details from the encoder. The input and output channels were set to 2, accommodating multi-channel input images and dual-class segmented outputs.

On the other hand, Attention U-Net extends the U-Net architecture to include attention gates along the encoder-decoder path, allowing the network to selectively pay attention to essential features \cite{oktay2018attention}. The encoder path consisted of five layers, with each layer increasing in channel depth from 16, 32, 64, 128, to 256 channels, and each layer downsampled by a stride of 2. These attention gates guide the network in emphasizing regions that contribute significantly to the segmentation task. Each convolutional layer employs a ReLU activation function, and Batch Normalization as in the original implementation \cite{oktay2018attention}. The output layer matched the input with two channels for multi-modal inputs and dual-class output, representing background and foreground classes.

\subsection{Model Training}

We divided the dataset into training, validation, and testing sets containing 258, 65, and 57 samples, respectively. The training objective was to minimize the loss functions in the training set. We used AdamW optimizer with weight decay of $10^{-5}$ to optimize the loss functions. We adopted a cosine annealing scheduler to decay the learning rate from $2 \times 10^{-4}$ to zero for 1000 epochs. The loss  was first computed for each batch within an epoch and the overall loss for an epoch was calculated by taking a mean over all the batch losses. The model with the highest mean DSC in the validation phase was chosen for further evaluation of the test set. The code for the implementations is made available at: https://github.com/ObedDzik/pca\_segment.git

\subsection{Loss Functions}
\paragraph{Dice Loss (DL):}
The Dice Loss maximizes the overlap between the predicted segmentation and the ground truth. In this work, for a specific cubic patch of an image, the Dice Loss for a batch was computed as,

\begin{equation}
\label{eq:DiceLoss}
   \mathcal{L}_\text{Dice} = 1 - \frac{1}{2}\sum_{c \in \{0, 1\}} \frac{2 \sum_i p_i (c) g_i(c)}{\sum_i p_i(c) + \sum_i g_i (c) + \epsilon}
\end{equation}
where \( p_i \) and \( g_i \) are, respectively, the predicted probability and ground truth for a given class \( c \) of the voxel \( i \), and \( \epsilon \) is a small constant to prevent division by zero.

\paragraph{Focal Loss:}
The Focal Loss \cite{lin2017focal} helps focus on hard-to-classify examples by down-weighting the easy ones. In this work, the Focal Loss for an image patch was computed over a batch as,

\begin{equation}
\label{eq:Focalloss}
    \mathcal{L}_{\text{Focal}} = - \frac{1}{2}\sum_{c \in \{0, 1\}}\sum_i \alpha_c (1 - p_i(c))^\gamma \log(p_i(c))
\end{equation}
where \( p_i \) is the predicted probability for a given class \( c \) of a voxel \( i \), \( \alpha \) is a factor defining the balance between background and foreground classes in a binary segmentation task, and \( \gamma \) is the focusing parameter that adjusts the rate at which easy examples are down-weighted.

\paragraph{Dice Focal Loss (DFL):}
The Dice Focal Loss \cite{zhu2019anatomynet} combines the Dice Loss and the Focal Loss forming a compound loss function:
\begin{equation}
    \mathcal{L}_{\text{DFL}} = \mathcal{L}_{\text{Dice}} + \mathcal{L}_{\text{Focal}}
\end{equation}
For the Dice Focal Loss formulation, we set \( \gamma =2 \) and  \( \alpha  = 1\) in all our experiments similar to the implementation reported in \cite{10.1007/978-3-031-09002-8_9}.

\paragraph{L1-weighted Dice Focal Loss (L1DFL):}
The L1-weighted Dice Focal Loss (L1DFL) applies a weighting strategy to the Dice Loss (DL) based on the L1 norm between the predicted probabilities and the ground truth labels and combines it with the Focal Loss (FL). The Dice Loss generally has two variants, one with squared terms in the denominator \cite{milletari2016v} and one without \cite{10.1007/978-3-319-46976-8_19}. In L1DFL, we employ the Dice Loss with the squared denominator which was preferred over the non-squared version following its performance in \cite{10.1007/978-3-030-32226-7_10}. We describe the mathematical formulation of the weighting strategy next.

First, we compute the L1 norm, \(\Delta\), between the predicted probabilities \( p \) and the ground truth labels \( g \),
\begin{equation}
\Delta_i = \| g_i - p_i \|_1, \text{ for \(i = 1,2, ... N\) } \label{eq:L1norm}
\end{equation}
where N is the total number of samples.
Next, we partition the range of L1 norm values \(\Delta\) into bins of a consistent nominal bin width of \(\Gamma\). Each bin \(B\) is defined by its center \(B_k\):

\begin{equation}
B_k = \Gamma\cdot k, \text{for \(k = 0,1,2, ... n-1\)} \label{eq:bin}
\end{equation}
where \(n=\lceil{\frac{1}{\Gamma}}+1\rceil\) is the total number of bins. For instance, with a bin width of \(\Gamma = 0.1\) and a total of \(n\) = 11 bins, \(B_k\) takes values at regular intervals in the range [0,1], such that for \(k = 0, 1, 2, \dots, 10\), bin centers (\(B_k\)) = \([0, 0.1, 0.2, \dots, 1.0]\).

We then calculate the count of \(\Delta\) values that fall within each bin:
\begin{equation}
\mathcal{C}(B_k) = \sum_{i=1}^N \delta_\kappa(B_k, \Delta_i) \label{eq:bincount}
\end{equation}
where \(\delta_\kappa(B_k, \Delta_i)\) is an indicator function defined as:
\begin{equation}
\delta_\kappa(B_k, \Delta_i) = 
\begin{cases}
1, & \text{if } |B_k - \Delta_i| \leq \frac{\Gamma}{2} \\
0, & \text{otherwise}
\end{cases} \label{eq:indicator}
\end{equation}
To account for potential truncation near the boundaries of [0,1], we calculate the effective bin width for each bin as:
\begin{equation}
\lambda_\kappa(B_k) = \min \Big\{B_k + \frac{\Gamma}{2}, 1\Big\} - \max\Big\{B_k - \frac{\Gamma}{2}, 0\Big\} \label{eq:binWidth}
\end{equation}
Using \(\lambda_\kappa(B_k)\), the norm density, \(\mathcal{D}(B)\), for each bin is defined as:
\begin{equation}
\mathcal{D}(B_k) = \frac{C(B_k)}{\lambda_\kappa(B_k)} \label{eq:density}
\end{equation}
The density \(\mathcal{D}(B_k)\) represents the concentration of samples around the bin center \(B_k\). For \(B_k\) values close to 0, the L1 norm values (\(\Delta_i\)) are also close to \(0\), indicating easy samples where the predictions align closely with the ground truth. In contrast, bins with centers near 1 represent L1 norms closer to 1, indicating hard-to-classify samples where predictions deviate significantly from the ground truth. Thus, based on the norm density, we can evaluate how common or rare a particular prediction difficulty is, allowing the weighting to be adjusted accordingly. This adjustment ensures that less frequent and difficult samples, which often correspond to foreground samples in an imbalanced scenario receive higher weights than the easy-to-classify samples. The weight for each bin is then calculated as:

\begin{equation}
w(B_k) = \frac{N}{\mathcal{D}(B_k)} \label{eq:weight}
\end{equation}

These weights are applied to the numerator and the denominator of the Dice Loss to account for the imbalances caused by the variations in \(\Delta\)

\begin{equation}
\label{eq:dice_square}
\mathcal{L}_{\text{wDice}} = 1 - \frac{2 \sum_{i=1}^N w_iy_i p_i + \epsilon}{\sum_{i=1}^N w_i(y_i^2 + p_i^2) + \epsilon}
\end{equation}
where \(w_i = w(B_k)\) if \(\Delta_i\) belongs to bin \(B_k\). If the L1 norms of the examples are uniformly distributed, the density \(\mathcal{D}(B_k)\) will be the same for all bins, resulting in equal weights \(w(B_k)\) for all bins. In this case, the weighted Dice Loss, (\(L_{\text{wDice}}\)), will reduce to the standard Dice Loss.

Finally, we combine \(\mathcal{L}_{\text{wDice}}\) with the Focal Loss. The full expression of L1DFL thus is:

\begin{equation}
\label{eq:l1dfl}
\text{L1DFL} = \mathcal{L}_{\text{wDice}} + \mathcal{L}_{\text{Focal}}
\end{equation}

We illustrate the dynamic weighting strategy of L1DFL below. For a given 4x4 matrix, Figure \ref{fig:scheme} highlights how L1DFL downweights contributions from the background class and focuses on regions of classification difficulty. Specifically, the figure shows that higher weights are applied for voxels with L1 norm (\(\Delta\)) close to 1, but for voxels with L1 norms close to 0, representing that those voxels are easily classified, lower weights are applied. Thus, regions corresponding to false positives and negatives receive much attention from the model. In our experiments, we empirically selected a constant bin width, \(\Gamma\), of 0.1 and \( \gamma \) of 2 for the focal loss component of the loss function.  

 \begin{figure}[ht]
   \begin{centering}
   \includegraphics[width=13cm]{fig_1.png}
   \caption{An illustration of the dynamic weighting strategy in L1 weighted Dice Focal Loss (L1DFL). (a) shows the ground truth (G), where 1 indicates lesion areas and 0 indicates background. (b) displays the predicted probability map, where green regions denote false positive predictions and red regions represent ROIs. (c) shows the L1 norm values between the predicted probabilities and ground truth, highlighting the error magnitude for each voxel. Higher values imply higher classification difficulty. (d) presents the density, \(\mathcal{D}\), which reflects the frequency distribution of each L1 norm value, capturing the difficulty of correctly classifying each voxel. Lower values imply higher classification difficulty. (e) depicts the final weights assigned to each voxel, where higher weights focus on rare, misclassified regions while down weighting well-classified background areas. This weighting strategy reduces the influence of abundant, correctly predicted voxels and increases the focus on difficult, misclassified lesions, thereby enhancing the model's focus on challenging samples.
   \label{fig:scheme} 
    } %note label inside caption
    \end{centering}
\end{figure}

\subsection{Model Evaluation}
We assessed the performance of the loss functions on the overall test data. We made predictions on the PET/CT whole-body images using the sliding-window technique \cite{cardoso2022monaiopensourceframeworkdeep} with a window of dimension (128, 128, 128) for all networks. The test set predictions were resampled to the coordinates of the original ground truth masks to compute the evaluation metrics. In addition to assessing performance on the overall test set, we performed evaluations based on two different lesion scenarios, single and multiple lesion scenarios. First, we categorized the set of images (\( I \)) into two subsets: images with a single-lesion (\( S \)) and images with multiple-lesion (\( M \)). For an image \( x \) with \( n(G_l) \) ground truth lesions, we defined these groups as follows:

\begin{equation*}
S = \{ x \in I \mid n(G_l) = 1 \}
\end{equation*}

\begin{equation*}
M = \{ x \in I \mid n(G_l) \geq 2 \}
\end{equation*}
Then, for each scenario, as well as on the overall test set, we performed patient-level and lesion-level assessments based on the methodologies below.

\subsubsection{Patient-Level Analysis}
\paragraph{Segmentation Metrics:}
We evaluated the segmentation performance of the loss functions using the DSC. We report the mean DSC together with the standard deviation and the median DSC with the inter-quartile ranges. Let \( G \) and \( P \) represent the ground truth and predicted masks of an image at the patient level. The patient-level DSC is defined as:

\begin{equation}
\text{DSC} = \frac{2 |G \cap P|}{|G| + |P|}
\end{equation}

\paragraph{Detection Metrics:}
We defined true positive (TP), false positive (FP), and false negative (FN) detections at the patient level, reporting their mean values across the test set and computed F1 scores per patient. A detection is considered as TP if there is a matched pair of \( G_l \) and \( P_l \) such that $G_{l,\text{SUVmax}} \cap P_l \neq 0$, where \( G_{l,\text{SUVmax}} \) is the voxel in \( G_l \) with the maximum standardized uptake value (SUVmax) \cite{ahamed2023comprehensive}. For a prediction \( P_l \), for which there is no corresponding overlap with a ground truth lesion \( G_l \), the detection is designated as an FP. Similarly, a false negative occurs when $G_{l,\text{SUVmax}} \cap P_l = 0$. We provide a visual illustration of the definition of the detection metrics in Figure \ref{fig:detection}. The F1 score is thus computed as:

\begin{equation}
\text{F1} = \frac{\text{TP}}{\text{TP} + \frac{1}{2} (\text{FP} + \text{FN})}
\end{equation}

 \begin{figure}[ht]
   \begin{centering}
   \includegraphics[width=12cm]{fig_2.png}
   \caption{Illustration for defining a true positive detection based on an overlap with the voxel containing the maximum standardized uptake value (SUVmax) in the ground truth lesion. G is the set of ground truth lesions and P is the set of predicted lesions.
   \label{fig:detection} 
    } %note label inside caption
    \end{centering}
\end{figure}

\paragraph{Clinical Metrics:}
For each scenario, we analyzed the performance of the loss functions across different groupings of molecular tumor volume. Specifically, we evaluated the performance of the loss functions on DSC on different thresholds of total molecular tumor volume (TMTV). We computed thresholds $(t)$ based on the inter-quartile range from 0 to the 85th percentile of the ground truth TMTV values and calculated median DSC for all lesions $(l)$ where volume $(v_l > t)$. Additionally, for the multiple-lesion scenario only, we assessed the loss function performance based on the spatial extent of lesion distribution, $D_{\text{max}}$, which is measured as the maximum distance between any pair of foreground voxels in the image. 

For a given ground truth mask, let \(\mathbf{v}_i\) denote foreground voxels, where \(i = 1, 2, \ldots, N\) and \(N\) is the total number of lesion voxels. We calculated the Euclidean distance between every pair of lesion voxels, \( \mathbf{v}_i \) and \( \mathbf{v}_j \), accounting for voxel spacing in each dimension. For voxel coordinates \((x_i, y_i, z_i)\) and \((x_j, y_j, z_j)\) with spacing \((s_x, s_y, s_z)\), the distance \( d_{ij} \) is given by equation (\ref{eq:Dmax}) below:

   \begin{equation}
   \label{eq:Dmax}
   d_{ij} = \sqrt{ \left( s_x (x_i - x_j) \right)^2 + \left( s_y (y_i - y_j) \right)^2 + \left( s_z (z_i - z_j) \right)^2 }
   \end{equation}
The lesion dissemination, \(D_{\text{max}} \), is calculated as the maximum distance among all calculated distances; \(D_{\text{max}} = \max_{i, j} \, d_{ij}\). We categorized the calculated distances into inter-quartile ranges (IQR) indicating the first, second, third and fourth IQR and analyzed the performance of the loss functions on each group. 

\subsubsection{Lesion-Level Analysis}
\paragraph{Segmentation Metrics:}
For lesion-level analysis, we defined the DSC based on the overlap between each predicted lesion mask and its corresponding ground truth mask. We identified which predicted lesion voxels corresponded to the ground truth voxels, especially in the scenario of multiple lesions in an image, based on a voxel-wise matching strategy. Specifically, lesions were segmented as individual connected components in both the ground truth and predicted masks using 18-connectivity to ensure spatial continuity within each identified lesion. This produced unique integer labels for each lesion. Each connected component in the predicted mask was then assessed for spatial overlap with each connected component in the ground truth mask. 

For each pair of ground truth and predicted lesions, a match was defined if there was any voxel overlap between the components (i.e., if any voxels in a predicted lesion occupied the same spatial locations as those in a ground truth lesion). This was computed by checking if any intersecting voxels existed between the two labeled components. When an overlap was identified, the corresponding pair of ground truth and predicted lesion labels was recorded as a matched lesion pair. These matches were used to compute lesion-wise metrics, including lesion-level DSC, by comparing the voxel distributions in each matched pair of lesions. We defined the lesion-wise DSC as:

\begin{equation}
\text{DSC}_l = \frac{2 |G_l \cap P_l|}{|G_l| + |P_l|}
\end{equation}
where \( G_l \) and \( P_l \) denote the ground truth and predicted masks of a specific lesion. For a given ground truth lesion with no match, $|G_l \cap P_l| = 0$ yielding a DSC of $0$. 

\paragraph{Clinical Metrics:}
At the lesion level, analysis was performed only on the molecular tumor volumes of the lesions. Similar to the threshold analysis performed at the patient level, we calculated thresholds $(t)$ based on the inter-quartile range from 0 to the 85th percentile of the ground truth MTV values (molecular volume of individual lesions) and calculated median DSC for all lesions $(l)$ where volume $(v_l > t)$. For each scenario, we analyzed the performance of the loss functions across different groupings of MTV.

\section{Results}
\label{result}
\subsection{Segmentation performance across different networks}
\label{seg1}

In this section, we present results for the segmentation performance of the three loss functions, Dice Loss (DL), Dice Focal Loss (DFL), and L1-weighted Dice Focal Loss (L1DFL) using the Attention U-Net and SegResNet architectures (Table \ref{tab:results}). We report the average and median DSCs at the patient level, with mean values of true positive, false positive, and false negative counts on the test set and the F1 score performance. A one-tailed paired Wilcoxon signed-rank test was performed to evaluate the significance of the performance of L1DFL from those of DL and DFL separately, with corresponding p-values reported.

\begin{table}[ht]
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{ccccccccc}
\toprule
\multirow{2}{*}{\textbf{Network}} & \multirow{2}{*}{\textbf{Loss Function}} & \multicolumn{2}{c}{\textbf{DSC}} & \multicolumn{3}{c}{\textbf{Mean Rates}} & \multirow{2}{*}{\textbf{F1 scores}} & \multirow{2}{*}{\textbf{P values}} \\
\cmidrule(lr){3-4} \cmidrule(lr){5-7}
 & & \textbf{Mean} & \textbf{Median} & \textbf{TP} & \textbf{FP} & \textbf{FN} & \\
\midrule
\multirow{3}{*}{Attention U-Net} 
 & DL & 0.54 $\pm$ 0.24 & 0.58 [0.44, 0.72] & \textbf{0.81 $\pm$ 0.35} & 2.06 $\pm$ 1.89 & \textbf{0.19 $\pm$ 0.35} & 0.50 $\pm$ 0.28 & $<0.01$* \\
 & DFL & 0.51 $\pm$ 0.26 & 0.54 [0.33, 0.73] & 0.77 $\pm$ 0.36 & 2.65 $\pm$ 2.60 & 0.23 $\pm$ 0.36 & 0.44 $\pm$ 0.27 & $<0.01$* \\
 & L1DFL & \textbf{0.58 $\pm$ 0.27} & \textbf{0.66 [0.51, 0.77]} & 0.77 $\pm$ 0.37 & \textbf{0.42 $\pm$ 0.65} & 0.23 $\pm$ 0.37 & \textbf{0.69 $\pm$ 0.34} &  \\
\midrule
\multirow{3}{*}{SegResNet} 
 & DL & 0.52 $\pm$ 0.30 & 0.60 [0.29, 0.76] & 0.73 $\pm$ 0.39 & 0.73 $\pm$ 1.10 & 0.27 $\pm$ 0.39 & 0.62 $\pm$ 0.35 & 0.24 \\
 & DFL & 0.52 $\pm$ 0.25 & 0.59 [0.41, 0.71] & \textbf{0.81 $\pm$ 0.34} & 2.05 $\pm$ 2.00 & \textbf{0.19 $\pm$ 0.34} & 0.49 $\pm$ 0.27 & 0.015* \\
 & L1DFL & \textbf{0.57 $\pm$ 0.29} & \textbf{0.68 [0.47, 0.78]} & 0.76 $\pm$ 0.37 & \textbf{0.52 $\pm$ 0.76} & 0.24 $\pm$ 0.37 & \textbf{0.66 $\pm$ 0.34} & \\
\bottomrule
\end{tabular}
}
\caption{Comparison of the loss functions on the test set based on mean and median patient-level DSC. The mean DSC, TP, FP, FN and F1 scores are presented with standard deviations and the median DSC with interquartile ranges. A detection is considered a true positive if the predicted mask overlaps with the voxel containing the SUVmax value in the ground truth. The P values reflect a one-tailed paired Wilcoxon signed-rank test comparing the median difference in DSC between L1DFL and DL and DFL, with * indicating statistical significance at the $\alpha = 0.05$ level.} 
\label{tab:results}
\end{table}

The median DSCs are higher than the average DSCs, with SegResNet slightly outperforming Attention U-Net in DSC. However, Attention U-Net generally got better true positive rates except in the case of DFL, where SegResNet performed better with a $5\%$ increment. In both architectures, Dice Loss always performed better than Dice Focal Loss in minimizing false positives. However, both loss functions showed varied performances on the different networks regarding true positive rates. Specifically, while the Dice Loss surpassed the other loss functions with a true positive rate of 0.81 $\pm$ 0.35 on the Attention U-Net, Dice Focal Loss also achieved a similar performance but on the SegResNet architecture. Yet, this higher sensitivity of Dice Loss on Attention U-Net came at the cost of more false positives. Compared to a false positive rate of 0.73 $\pm$ 1.10 on SegResNet, the Dice Loss had a rate of 2.06 $\pm$ 1.89 on Attention U-Net, about three times the value on the former network. This imbalance in true and false positives on Attention U-Net led to a lower F1 score for Dice Loss despite its higher sensitivity.

Conversely, L1DFL achieved the best balance of true positive detections and minimum false positives. For example, on Attention U-Net, where Dice Loss and Dice Focal Loss had mean false positive rates above 2.0, the L1DFL minimized the false detection rates. Although its FP rate slightly increased with SegResNet, its value was still low compared to DL and DFL. By lowering false positive rates while maintaining sensitivity to lesions, L1DFL yielded superior mean and median DSCs. Specifically, on Attention U-Net, L1DFL reached a median DSC of 0.66, outperforming DFL and DL by $22\%$ and $13\%$, respectively. Moreover, the high interquartile range of L1DFL indicates that its DSC values fell within a narrow range of high values.

Although the one-tailed Wilcoxon signed-rank test comparing DL and L1DFL did not provide enough evidence to reject the null hypothesis of no significant difference between the two on the SegResNet architecture, statistically significant differences were obtained on the Attention U-Net. Also, comparing DFL versus L1DFL resulted in statistically significant differences in favor of L1DFL across both networks.

 \begin{figure}[ht]
   \begin{centering}
   \includegraphics[width=9cm]{fig_3.png}
   \caption{Segmentation performance of the loss functions across two networks: Attention U-Net (top row) and SegResNet (bottom row). The first column shows the ground truth segmentation (GT) and the remaining columns represent the results for the loss functions: Dice Loss (DL), Dice Focal Loss (DFL), and L1-weighted Dice Focal Loss (L1DFL). The green-colored region denotes the ground truth annotation of the lesion, while the red-colored regions represent the segmentations produced by the models. The bounded area highlights the lesion in the ground truth image alongside the corresponding correct segmentation by the models. Red regions outside the bounded area indicate false positive segmentations.
   \label{fig:segment} 
    } %note label inside caption
    \end{centering}
\end{figure}

Figure \ref{fig:segment} shows a sample segmentation performance of the loss functions on a test PET/CT image. The first-row segmentations are from Attention U-Net, while the second row is from SegResNet, with columns having different loss functions. The bounded region in the figure depicts correct segmentation according to the ground truth highlighting the differences in performance between the loss functions and the network architectures. 

In this example, Attention U-Net yielded better segmentation of the lesion with higher DSC than SegResNet. Yet, for both networks, the Dice and the Dice Focal Loss functions produced instances of false positives further impacting the overall DSC. L1DFL, however, remained robust, providing a consistent performance.

\subsection{Performance in single and multiple lesion scenarios}
\label{scenarios}
We evaluated the performance of the loss functions in two different lesion scenarios: multiple lesions in one PET/CT volumetric image and only one lesion in the volume constituting the single lesion scenario. Figure \ref{fig:sing_multi_dsc} shows that the loss functions performed differently under these scenarios; a wider spread of DSC values is observed in the single lesion scenario than in the multiple scenario for both networks. Also, the DSCs beyond the 75th percentile for each loss function in the single lesion scenario were higher than those in the multiple lesion scenario, with more cases achieving DSCs greater than 0.8. 

Despite this observation, each loss function with Attention U-Net had higher median DSCs in the multiple-lesion scenario than in the single-lesion scenario (Figure \ref{fig:sing_multi_dsc}a). Besides, in the single lesion case, all the loss functions have more lower outliers, reflecting occasional underperformance. On the other hand, for all the loss functions, there are fewer outliers in the multiple-lesion scenario. While similar observations are made on the SegResNet architecture, the median DSC of L1DFL in the single lesion scenario remained slightly higher than the median DSC in the multiple lesion case (Figure \ref{fig:sing_multi_dsc}b).

\begin{figure}[ht]
   \begin{centering}
   \includegraphics{fig_4.png}
   \caption{Box plots overlaid with swarm plots illustrating the distribution of Dice Similarity Coefficient (DSC) performance for the three loss functions across two lesion scenarios: M (lesion count $> 2$) and S (lesion count $= 1$). Each box plot's top and bottom edges represent the interquartile range (IQR), while the horizontal lines within the boxes indicate the median DSC values. Whisker lengths are set to 1.5 times the IQR. (a) Performance on Attention U-Net architecture. (b) Performance on SegResNet. The number of cases in the single lesion scenario was N = 34 and for the multiple lesion scenario, the number of cases was N = 23.
   \label{fig:sing_multi_dsc} 
    } %note label inside caption
    \end{centering}
\end{figure}

Dice Loss generally had higher median DSC for both architectures when compared with DFL, although there were variations in performance between lesion scenarios and architectures. In a single lesion scenario using the Attention U-Net architecture, for example, DL demonstrated more consistent performance as evidenced by an IQR of 0.33 compared to DFL with an IQR of 0.45. However, on SegResNet, DL's performance became highly incoherent, with a wider IQR of 0.72 compared to the DFL's narrower IQR of 0.37. 

In the case of multiple lesions, while both loss functions showed similar IQRs of 0.26 with SegResNet, on Attention U-Net, however, the DSC values from DL are more spread out with lower values in the lower quartile range compared to DFL and L1DFL. Thus, Dice Loss may not be consistent in some scenarios and architectures, particularly where the cases are more complex.

In contrast, L1DFL outperformed DL and DFL in both lesion scenarios on the Attention U-Net. Its median DSCs on the multiple and single lesions were 0.67 and 0.65, respectively. These values are at least $11\%$ higher than the median DSCs of DL in both cases. Similarly, on SegResNet in the single lesion case, L1DFL achieved a median DSC of 0.69, while DL and DFL had 0.56 and 0.55, respectively. However, in the multiple lesion scenario, Dice Loss slightly outperformed L1DFL by $4\%$, although they both had similar IQR.

\subsection{Performance based on lesion molecular volume}
\label{mtv}
For each lesion scenario, we evaluated the performance of the loss functions across different TMTV thresholds at both the patient and lesion levels (Figure \ref{fig:tmtv_trend}). Higher DSC values were generally observed when assessing the performance at the lesion level while the patient-level DSC values tended to be slightly lower due to false-positive segmentations. Notably, the Dice and Dice Focal Losses were more susceptible to false positives, resulting in a reduction of their median DSC by at least $10\%$ in the patient-level assessment. 

 \begin{figure}[h!]
   \begin{centering}
    \includegraphics[width=10cm]{fig_5.png}
   \caption{Patient and lesion-level median Dice Similarity Coefficient (DSC) performance of the different loss functions as a function of various ground truth tumor molecular volume thresholds. Each column shows the plots for the different lesion scenarios: single (S) and multiple (M). At both the patient and lesion levels, the line plots represent the trend of each loss function's performance across different total molecular tumor volume (TMTV) and molecular tumor volume (MTV) thresholds, respectively, with thresholds $(t)$ based on the interquartile range from 0 to the 85th percentile. Median DSC is calculated for all lesions $(l)$ where volume $(v_l > t)$, and each color indicates a different loss function. The first row of plots (a) shows the performance of the loss functions with Attention U-Net. The second row (b) shows the performance of the loss functions with SegResNet. The third row (c) displays area plots of median tumor lesion activity (TLA) values according to the TMTV and MTV thresholds, where median TLA values are calculated for lesions with $(v_l > t)$.
   \label{fig:tmtv_trend} 
    } %note label inside caption
    \end{centering}
\end{figure}

The results further highlight differences in the performance of the loss functions based on tumor volumes. For volumes above $5 \text{ ml}$, considering the single lesion scenario, even though there was a corresponding increase in lesion activity evident by increased TLA values, there was a decline in segmentation accuracy with the Dice Loss being the most impacted. Although generally, brighter and larger lesions are easier to segment \cite{XU2023106882}, as tumor volume increases the proportion of the volume of occupied by the high uptake voxels decreases, potentially leading to a decline in segmentation accuracy. In contrast, for smaller lesions, the high uptake voxels represents a larger fraction of the lesion volume, resulting in higher DSCs when segmentation focuses on this voxel. Thus, the results suggest that the Dice Loss tends to focus on segmenting regions with the highest uptake values and as lesion volume increases with a corresponding reduction in the volume proportion of high-uptake voxels, segmentation performance declines.

Moreover, the results obtained from using the SegResNet architecture highlight additional complexities that may contribute to lesion segmentation accuracy beyond size and uptake value. For example, at the patient assessment level and within the threshold range $0-10 \text{ ml}$, higher TLA values were observed in the multiple lesion scenario compared to the single lesion case due to the summed TLA values of individual lesions. Yet, higher DSC values were achieved in the single lesion scenario than the multiple lesion scenario, indicating that beyond TLA, lesion count also affects performance. Consequently, this points to the influence of other factors, such as anatomical location of lesions, proximity to organs like the bladder, and extent of lesion spread impacting segmentation accuracy. With multiple lesions in an image, the effect of these factors may be more pronounced leading to more variability in performance.

The Dice Loss performed better on SegResNet than on Attention U-Net, outperforming Dice Focal Loss at the patient level in both scenarios due to Dice Focal Loss' higher false positive rate. However, both loss functions showed similar trends at the lesion level. The Dice Focal Loss on the other hand yielded more accurate segmentations with the Attention U-Net outperforming the Dice Loss at both scenarios. Nevertheless L1DFL maintained stable performance across both architectures and lesion scenarios. This consistency suggests the effectiveness of L1DFL's dynamic weighting strategy, making it more robust to false positives at the patient level and achieving better overlap with the ground truth at the lesion level.


\subsection{Performance based on lesion dissemination}
\label{Dmax}
To quantify the spatial distribution of lesions, we calculated \( D_{\text{max}} \), the maximum Euclidean distance between any two lesions in the image.
 \begin{figure}[ht]
   \begin{centering}
   \includegraphics[width=10cm]{fig_6.png}
   \caption{Plots illustrating the Dice Similarity Coefficients (DSC) across four interquartile ranges of \( D_{\text{max}} \). The first row (a) shows the performance with Attention U-Net. The second row (b) shows the performance with SegResNet. The groups G0 (0-9 cm), G1 (9-11cm), G2 (11-14cm), and G3 (14-60cm) correspond to the interquartile ranges of $0-25\%$, $25-50\%$, $50-75\%$, and $75-100\%$, respectively. In the box plots, horizontal lines indicate the median, and whisker lengths are set to 1.5 times the interquartile range (IQR), with outliers represented as black dots. Accompanying bar plots (c) display the median total lesion activity (TLA) values for cases within each \( D_{\text{max}} \) group. The different loss functions are color-coded for clarity. The total number of cases in each group was N = 6.
   \label{fig:dmax}
    } %note label inside caption
    \end{centering}
\end{figure}
For the performance assessment of the loss functions based on the \( D_{\text{max}} \), we categorized the distances into the following groups: 0-9 cm (G0), 9-11 cm (G1), 11-14 cm (G2), and 14-60 cm (G3), representing the first, second, third and fourth quartile ranges, respectively. Patient-level analysis of DSC showed consistent improvement across these ranges (Figure \ref{fig:dmax}). The figure also shows differences in performance across the different architectures. Generally, the Dice Loss performed better on SegResNet than on Attention U-Net but the Dice Focal Loss performed better on the latter architecture. The L1DFL on the other hand, yielded more consistent performance across the two networks, yet had a wider IQR on SegResNet than on Attention U-Net. 

On Attention U-Net, initially, median DSC values for all loss functions ranged from 0.4 to 0.6 (G0), increasing in the third quartile to 0.6-0.8 (G2). The results with SegResNet also show a similar trend; there is a general increase in DSC values up to the third quartile. For both networks, in the last quartile (G3), representing a more expansive lesion spread, all loss functions showed a drop in their performance metrics. Specifically, on Attention U-Net, the Dice Focal Loss performed the worst in this group, and L1DFL and Dice Loss presented similar performances, with a median of 0.62. Yet, the Dice Focal Loss had a smaller interquartile range, reflecting less spread across DSCs in that category. The median DSC of L1DFL dropped from 0.76 to 0.62 by $18.4\%$, and that of Dice Focal Loss dropped from 0.65 to 0.58 by $10.3\%$. Dice Loss also slightly declined in performance with a broader spread in IQR of its DSCs. On SegResNet, the Dice Loss had the worst performance in this group with L1DFL achieving the best segmentation accuracy.

The performance of the loss functions in the lower \( D_{\text{max}} \) ranges (G0 - G2) which characterize less lesion spread in the body further highlight network-specific variations. While the Dice Loss achieved similar high median DSC as L1DFL in these ranges with the SegResNet, it had the worst performance with Attention U-Net. Similarly, the SegResNet model trained with the Dice Focal Loss had a decline in obtaining accurate segmentations while pairing this loss function with Attention U-Net yielded competitive results. L1DFL remained robust to these architecture-specific variations consistently outperforming the baseline models. Figure \ref{fig:dmax} also depicts a higher median total lesion activity (TLA) across the different groups, indicating an increased lesion size or uptake value with greater lesion spread. Although model performance generally improves with higher lesion activity, the slight decrease in median DSC in the highest quartile of \( D_{\text{max}} \), despite high TLA, suggests that other factors might contribute to the segmentation performance such as lesion site and count.

\section{Discussion}
\label{discuss}

In this work, we proposed and evaluated a novel loss function L1-weighted Dice Focal Loss, in segmenting metastatic prostate cancer lesions based on different lesion scenarios characterized by the number of lesions in an image. Specifically, we defined two scenarios: single lesion scenario which include whole body PET/CT images with only a single lesion present in the ground truth mask and multiple lesion scenario being images with more than one lesion. We compared the performance of our proposed loss function with the Dice and Dice Focal Losses. Moreover, we report how the size of a lesion and its spatial distribution influence the segmentation result. The dataset used in this study included tumors which had resurfaced after treatment with relatively low molecular volumes and standardized uptake values (SUV) thus introducing unique challenges for correct segmentations.

Our findings showed that the performance of the loss functions is not uniform across different architectures. For instance, the results show that the Dice Loss generated more false positives on Attention U-Net compared to SegResNet, despite showing higher sensitivity on the former. Similarly, the Dice Focal Loss exhibited lower precision on the Attention U-Net architecture due to increased false positives. By evaluating performance at both the patient and lesion lesions, the effect of false positive rates was highlighted. There was a more than $10\%$ decrease in the median DSC values at the lesion level for both loss functions when assessments were made at the patient level. L1DFL, in contrast, was more robust to these false detections. 

Additionally, by assessing performance based on the different lesion scenarios, the influence of various lesion characteristics such as volume, extent of spread, number of lesions on accuracy could be evaluated. For instance, considering the single lesion scenario, the performance of the Dice Loss is shown to decline as the threshold volume of tumors increased beyond $5 \text{ml}$. This could suggest that Dice Loss is highly sensitive to the voxels of high uptake values. Once the lesion volume increases, the proportionality of such high-uptake voxels to the lesion volume diminishes, reducing the segmentation accuracy. This observation aligns with claims in \cite{LIU2024103015} where it is indicated that the Dice Loss is inherently biased toward smaller regions thus may generally performing poorly on larger lesions with more variable SUV distribution across the volume. Consequently, at lower tumor volumes, the Dice Loss had higher DSC values than the Dice Focal Loss yet declined at larger tumor volumes. The dynamic focusing ability of the L1DFL however led to robustness to the difficulties in accurate segmentations caused by the varying lesion sizes.

Furthermore, comparing the results obtained with SegResNet on the single lesion scenario to the multiple lesion scenario points to the influence of additional factors to segmentation accuracy other than tumor volume and activity. Due to the summation of the TLA values of individual lesions in the multiple lesion scenario, higher activity values are obtained than in the single lesion case yet, lower DSC values are observed. This observation could suggest the introduction of further complexities as lesion count increases. In fact, with more lesions, different anatomical sites may be involved, and the effect of other organs with high uptake values like the bladder could be pronounced \cite{XU2023106882}. Besides, the evaluation based on lesion spread, \(D_{\text{max}}\), highlights the decrease in the models' performance as distribution across the body becomes more expansive. 

The Dice Loss is based on overlap measurement and it inherently balances sensitivity with specificity, making it more robust in scenarios with significant data imbalance such as in lesion segmentation tasks \cite{10.1007/978-3-319-67558-9_28}. Therefore, distribution-based losses are often combined with the Dice Loss or its variants to improve their robustness. However, without adapting its focus to classification difficulty, the Dice Loss fails to adjust dynamically toward heterogeneous lesion characteristics. Despite the unique challenges posed by the tumor heterogeneity, the L1-weighted Dice Focal Loss generally yielded better segmentation performance, achieving better balance in false detection rates. This loss function comprises a dynamic weighting strategy that adapts the model's focus based on sample difficulty. For easier-to-classify examples (characterized by predicted probabilities \( P > 0.5 \)), L1DFL applies a reduced penalty while penalizing more challenging examples (\( P < 0.5 \)) more heavily (Figure \ref{fig:curves}).

 \begin{figure}[ht]
   \begin{centering}
   \includegraphics[width=8cm]{fig_7.png}
   \caption{Plot of loss versus probability for samples with the ground truth label as 1. The curves represent the behavior of each loss function, highlighting how they respond to varying probabilities of correctly classifying examples. The plot illustrates the differences in how each loss function handles both easy-to-classify and hard-to-classify cases based on their predicted probabilities.
   \label{fig:curves} 
    } %note label inside caption
    \end{centering}
\end{figure}


Similarly, the Dice Focal Loss increases the penalty on samples with a lower probability of correctly classifying the ground truth label, P(G), encouraging the model to focus more on "hard" samples, but it applies a much steeper penalty. Thus, it tends to lose the Dice Loss component, where positive and negative examples remain equally weighted, potentially leading to more false positive rates due to misclassification of background areas as lesions \cite{YEUNG2022102026}. On the other hand, the weighting strategy of L1DFL allows for a more balanced approach to penalizing misclassification, consequently reducing false positive rates. Our results indicate that L1DFL yielded the highest F1 and DSCs in this study, underlining its more robust performance across various lesion scenarios and levels of lesion dissemination. This adaptive weighting strategy shows promise in improving segmentation performance in complex metastatic imaging cases.
 
\section{Conclusion}
\label{conc}

We evaluated the performance of a custom loss function, \textit{L1-weighted Dice Focal Loss} (L1DFL), in the detection and segmentation of metastatic prostate cancer lesions in PSMA PET/CT scans across single and multiple lesion scenarios, characterized by lesion count. L1DFL leverages a dynamic weighting scheme that is based on the L1 norms of the predicted probabilities and ground truth labels to modulate the Dice Loss and then combined with the Focal Loss to emphasize challenging pixel classifications. We compared L1DFL's performance against Dice Loss and Dice Focal Loss using two 3D CNN architectures, Attention U-Net, and SegResNet. While Dice Loss demonstrated sensitivity for small lesions, it usually suffered from low precision. Dice Focal Loss showed higher false positive rates and variable performance across the different networks. On the other hand, L1DFL consistently achieved a balanced segmentation performance across the lesion scenarios and architectures, achieving superior F1 scores and Dice Similarity Coefficients. Future work will be directed at exploring the generalizability of L1DFL to other medical imaging datasets and tasks.

\section{Acknowledgments}
This work was supported by the Canadian Institutes of Health Research (CIHR) Project Grants PJT-162216 and PJT-173231. We also acknowledge computational resources and services provided by Microsoft AI for Health.

%%
\bibliographystyle{elsarticle-num-names} 
\bibliography{reference}

\end{document}

\endinput
%%
%% End of file `elsarticle-template-num.tex'.
