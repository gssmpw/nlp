@inproceedings{hu2023reveal,
	title={Reveal: Retrieval-augmented visual-language pre-training with multi-source multimodal knowledge memory},
	author={Hu, Ziniu and Iscen, Ahmet and Sun, Chen and Wang, Zirui and Chang, Kai-Wei and Sun, Yizhou and Schmid, Cordelia and Ross, David A and Fathi, Alireza},
	booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
	pages={23369--23379},
	year={2023}
}
@inproceedings{ramos2023smallcap,
	title={Smallcap: lightweight image captioning prompted with retrieval augmentation},
	author={Ramos, Rita and Martins, Bruno and Elliott, Desmond and Kementchedjhieva, Yova},
	booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages={2840--2849},
	year={2023}
}
@inproceedings{li2024evcap,
	title={EVCap: Retrieval-Augmented Image Captioning with External Visual-Name Memory for Open-World Comprehension},
	author={Li, Jiaxuan and Vo, Duc Minh and Sugimoto, Akihiro and Nakayama, Hideki},
	booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages={13733--13742},
	year={2024}
}
@inproceedings{shi2023large,
	title={Large language models can be easily distracted by irrelevant context},
	author={Shi, Freda and Chen, Xinyun and Misra, Kanishka and Scales, Nathan and Dohan, David and Chi, Ed H and Sch{\"a}rli, Nathanael and Zhou, Denny},
	booktitle={International Conference on Machine Learning},
	pages={31210--31227},
	year={2023},
	organization={PMLR}
}
@article{fang2024enhancing,
	title={Enhancing Noise Robustness of Retrieval-Augmented Language Models with Adaptive Adversarial Training},
	author={Fang, Feiteng and Bai, Yuelin and Ni, Shiwen and Yang, Min and Chen, Xiaojun and Xu, Ruifeng},
	journal={arXiv preprint arXiv:2405.20978},
	year={2024}
}
@article{xu2024unsupervised,
	title={Unsupervised Information Refinement Training of Large Language Models for Retrieval-Augmented Generation},
	author={Xu, Shicheng and Pang, Liang and Yu, Mo and Meng, Fandong and Shen, Huawei and Cheng, Xueqi and Zhou, Jie},
	journal={arXiv preprint arXiv:2402.18150},
	year={2024}
}
@article{yasunaga2022retrieval,
	title={Retrieval-augmented multimodal language modeling},
	author={Yasunaga, Michihiro and Aghajanyan, Armen and Shi, Weijia and James, Rich and Leskovec, Jure and Liang, Percy and Lewis, Mike and Zettlemoyer, Luke and Yih, Wen-tau},
	journal={arXiv preprint arXiv:2211.12561},
	year={2022}
}
@article{ramos2023retrieval,
	title={Retrieval-augmented image captioning},
	author={Ramos, Rita and Elliott, Desmond and Martins, Bruno},
	journal={arXiv preprint arXiv:2302.08268},
	year={2023}
}
@article{yang2023re,
	title={Re-vilm: Retrieval-augmented visual language model for zero and few-shot image captioning},
	author={Yang, Zhuolin and Ping, Wei and Liu, Zihan and Korthikanti, Vijay and Nie, Weili and Huang, De-An and Fan, Linxi and Yu, Zhiding and Lan, Shiyi and Li, Bo and others},
	journal={arXiv preprint arXiv:2302.04858},
	year={2023}
}
@article{hu2024exploring,
	title={Exploring refined dual visual features cross-combination for image captioning},
	author={Hu, Junbo and Li, Zhixin and Su, Qiang and Tang, Zhenjun and Ma, Huifang},
	journal={Neural Networks},
	volume={180},
	pages={106710},
	year={2024},
	publisher={Elsevier}
}
@ARTICLE{Shao2022,
	author={Shao, Zhuang and Han, Jungong and Marnerides, Demetris and Debattista, Kurt},
	journal={IEEE Transactions on Neural Networks and Learning Systems}, 
	title={Region-Object Relation-Aware Dense Captioning via Transformer}, 
	year={2022},
	volume={},
	number={},
	pages={1-12},
	keywords={Transformers;Visualization;Training;Feature extraction;Object detection;Decoding;Task analysis;Dense image captioning;region-object correlation score unit (ROCSU);transformer-based dense image captioner.},
	doi={10.1109/TNNLS.2022.3152990}}
@article{lewis2020retrieval,
	title={Retrieval-augmented generation for knowledge-intensive nlp tasks},
	author={Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and K{\"u}ttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rockt{\"a}schel, Tim and others},
	journal={Advances in Neural Information Processing Systems},
	volume={33},
	pages={9459--9474},
	year={2020}
}
@article{wang2022text,
	title={A text-guided generation and refinement model for image captioning},
	author={Wang, Depeng and Hu, Zhenzhen and Zhou, Yuanen and Hong, Richang and Wang, Meng},
	journal={IEEE Transactions on Multimedia},
	volume={25},
	pages={2966--2977},
	year={2022},
	publisher={IEEE}
}
@article{al2022image,
	title={Image captioning with novel topics guidance and retrieval-based topics re-weighting},
	author={Al-Qatf, Majjed and Wang, Xingfu and Hawbani, Ammar and Abdussalam, Amr and Alsamhi, Saeed Hammod},
	journal={IEEE Transactions on Multimedia},
	volume={25},
	pages={5984--5999},
	year={2022},
	publisher={IEEE}
}
@article{zhu2022unpaired,
	title={Unpaired image captioning by image-level weakly-supervised visual concept recognition},
	author={Zhu, Peipei and Wang, Xiao and Luo, Yong and Sun, Zhenglong and Zheng, Wei-Shi and Wang, Yaowei and Chen, Changwen},
	journal={IEEE Transactions on Multimedia},
	volume={25},
	pages={6702--6716},
	year={2022},
	publisher={IEEE}
}
@article{shen2024imagdressing,
  title={IMAGDressing-v1: Customizable Virtual Dressing},
  author={Shen, Fei and Jiang, Xin and He, Xin and Ye, Hu and Wang, Cong and Du, Xiaoyu and Li, Zechao and Tang, Jinghui},
  journal={arXiv preprint arXiv:2407.12705},
  year={2024}
}
@article{ben2021unpaired,
	title={Unpaired image captioning with semantic-constrained self-learning},
	author={Ben, Huixia and Pan, Yingwei and Li, Yehao and Yao, Ting and Hong, Richang and Wang, Meng and Mei, Tao},
	journal={IEEE Transactions on Multimedia},
	volume={24},
	pages={904--916},
	year={2021},
	publisher={IEEE}
}
@article{song2024embedded,
	title={Embedded Heterogeneous Attention Transformer for Cross-lingual Image Captioning},
	author={Song, Zijie and Hu, Zhenzhen and Zhou, Yuanen and Zhao, Ye and Hong, Richang and Wang, Meng},
	journal={IEEE Transactions on Multimedia},
	year={2024},
	publisher={IEEE}
}
@article{zhao2023boosting,
	title={Boosting entity-aware image captioning with multi-modal knowledge graph},
	author={Zhao, Wentian and Wu, Xinxiao},
	journal={IEEE Transactions on Multimedia},
	year={2023},
	publisher={IEEE}
}
@article{zhu2023minigpt,
	title={Minigpt-4: Enhancing vision-language understanding with advanced large language models},
	author={Zhu, Deyao and Chen, Jun and Shen, Xiaoqian and Li, Xiang and Elhoseiny, Mohamed},
	journal={arXiv preprint arXiv:2304.10592},
	year={2023}
}
@inproceedings{li2022blip,
	title={Blip: Bootstrapping language-image pre-training for unified vision-language understanding and generation},
	author={Li, Junnan and Li, Dongxu and Xiong, Caiming and Hoi, Steven},
	booktitle={International conference on machine learning},
	pages={12888--12900},
	year={2022},
	organization={PMLR}
}
@inproceedings{shen2024imagpose,
  title={IMAGPose: A Unified Conditional Framework for Pose-Guided Person Generation},
  author={Shen, Fei and Tang, Jinhui},
  booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
  year={2024}
}
@inproceedings{li2023blip,
	title={Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models},
	author={Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven},
	booktitle={International conference on machine learning},
	pages={19730--19742},
	year={2023},
	organization={PMLR}
}
@inproceedings{bitton2023breaking,
	title={Breaking common sense: Whoops! a vision-and-language benchmark of synthetic and compositional images},
	author={Bitton-Guetta, Nitzan and Bitton, Yonatan and Hessel, Jack and Schmidt, Ludwig and Elovici, Yuval and Stanovsky, Gabriel and Schwartz, Roy},
	booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
	pages={2616--2627},
	year={2023}
}
@article{mokady2021clipcap,
	title={Clipcap: Clip prefix for image captioning},
	author={Mokady, Ron and Hertz, Amir and Bermano, Amit H},
	journal={arXiv preprint arXiv:2111.09734},
	year={2021}
}
@inproceedings{zhang2021vinvl,
	title={Vinvl: Revisiting visual representations in vision-language models},
	author={Zhang, Pengchuan and Li, Xiujun and Hu, Xiaowei and Yang, Jianwei and Zhang, Lei and Wang, Lijuan and Choi, Yejin and Gao, Jianfeng},
	booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
	pages={5579--5588},
	year={2021}
}
@inproceedings{fei2021memory,
	title={Memory-augmented image captioning},
	author={Fei, Zhengcong},
	booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
	volume={35},
	number={2},
	pages={1317--1324},
	year={2021}
}
@inproceedings{shen2023pbsl,
  title={Pedestrian-specific Bipartite-aware Similarity Learning for Text-based Person Retrieval},
  author={Shen, Fei and Shu, Xiangbo and Du, Xiaoyu  and Tang, Jinhui},
  booktitle={Proceedings of the 31th ACM International Conference on Multimedia},
  year={2023}
}

@article{shen2023triplet,
  title={Triplet Contrastive Learning for Unsupervised Vehicle Re-identification},
  author={Shen, Fei and Du, Xiaoyu and Zhang, Liyan and Tang, Jinhui},
  journal={arXiv preprint arXiv:2301.09498},
  year={2023}
}
@inproceedings{vo2022noc,
	title={NOC-REK: novel object captioning with retrieved vocabulary from external knowledge},
	author={Vo, Duc Minh and Chen, Hong and Sugimoto, Akihiro and Nakayama, Hideki},
	booktitle={2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
	pages={17979--17987},
	year={2022},
	organization={IEEE}
}
@inproceedings{fan2023rca,
	title={Rca-noc: Relative contrastive alignment for novel object captioning},
	author={Fan, Jiashuo and Liang, Yaoyuan and Liu, Leyao and Huang, Shaolun and Zhang, Lei},
	booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
	pages={15510--15520},
	year={2023}
}
@inproceedings{fei2023transferable,
	title={Transferable decoding with visual entities for zero-shot image captioning},
	author={Fei, Junjie and Wang, Teng and Zhang, Jinrui and He, Zhenyu and Wang, Chengjie and Zheng, Feng},
	booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
	pages={3136--3146},
	year={2023}
}
@inproceedings{NEURIPS2023_9a6a435e,
	author = {Dai, Wenliang and Li, Junnan and LI, DONGXU and Tiong, Anthony and Zhao, Junqi and Wang, Weisheng and Li, Boyang and Fung, Pascale N and Hoi, Steven},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {A. Oh and T. Naumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
	pages = {49250--49267},
	publisher = {Curran Associates, Inc.},
	title = {InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning},
	volume = {36},
	year = {2023}
}
@inproceedings{li2020oscar,
	title={Oscar: Object-semantics aligned pre-training for vision-language tasks},
	author={Li, Xiujun and Yin, Xi and Li, Chunyuan and Zhang, Pengchuan and Hu, Xiaowei and Zhang, Lei and Wang, Lijuan and Hu, Houdong and Dong, Li and Wei, Furu and others},
	booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part XXX 16},
	pages={121--137},
	year={2020},
	organization={Springer}
}
@article{bai2023qwen,
	title={Qwen-vl: A frontier large vision-language model with versatile abilities},
	author={Bai, Jinze and Bai, Shuai and Yang, Shusheng and Wang, Shijie and Tan, Sinan and Wang, Peng and Lin, Junyang and Zhou, Chang and Zhou, Jingren},
	journal={arXiv preprint arXiv:2308.12966},
	year={2023}
}
@article{wang2023cogvlm,
	title={Cogvlm: Visual expert for pretrained language models},
	author={Wang, Weihan and Lv, Qingsong and Yu, Wenmeng and Hong, Wenyi and Qi, Ji and Wang, Yan and Ji, Junhui and Yang, Zhuoyi and Zhao, Lei and Song, Xixuan and others},
	journal={arXiv preprint arXiv:2311.03079},
	year={2023}
}
@article{chen2022pali,
	title={Pali: A jointly-scaled multilingual language-image model},
	author={Chen, Xi and Wang, Xiao and Changpinyo, Soravit and Piergiovanni, AJ and Padlewski, Piotr and Salz, Daniel and Goodman, Sebastian and Grycner, Adam and Mustafa, Basil and Beyer, Lucas and others},
	journal={arXiv preprint arXiv:2209.06794},
	year={2022}
}
@article{chen2023pali,
	title={Pali-x: On scaling up a multilingual vision and language model},
	author={Chen, Xi and Djolonga, Josip and Padlewski, Piotr and Mustafa, Basil and Changpinyo, Soravit and Wu, Jialin and Ruiz, Carlos Riquelme and Goodman, Sebastian and Wang, Xiao and Tay, Yi and others},
	journal={arXiv preprint arXiv:2305.18565},
	year={2023}
}
@article{young2014image,
	title={From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions},
	author={Young, Peter and Lai, Alice and Hodosh, Micah and Hockenmaier, Julia},
	journal={Transactions of the Association for Computational Linguistics},
	volume={2},
	pages={67--78},
	year={2014},
	publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}
@inproceedings{agrawal2019nocaps,
	title={Nocaps: Novel object captioning at scale},
	author={Agrawal, Harsh and Desai, Karan and Wang, Yufei and Chen, Xinlei and Jain, Rishabh and Johnson, Mark and Batra, Dhruv and Parikh, Devi and Lee, Stefan and Anderson, Peter},
	booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
	pages={8948--8957},
	year={2019}
}
@inproceedings{lin2014microsoft,
	title={Microsoft coco: Common objects in context},
	author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
	booktitle={Computer Vision--ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part V 13},
	pages={740--755},
	year={2014},
	organization={Springer}
}
@inproceedings{karpathy2015deep,
	title={Deep visual-semantic alignments for generating image descriptions},
	author={Karpathy, Andrej and Fei-Fei, Li},
	booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages={3128--3137},
	year={2015}
}
@inproceedings{papineni2002bleu,
	title={Bleu: a method for automatic evaluation of machine translation},
	author={Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
	booktitle={Proceedings of the 40th annual meeting of the Association for Computational Linguistics},
	pages={311--318},
	year={2002}
}
@inproceedings{banerjee2005meteor,
	title={METEOR: An automatic metric for MT evaluation with improved correlation with human judgments},
	author={Banerjee, Satanjeev and Lavie, Alon},
	booktitle={Proceedings of the acl workshop on intrinsic and extrinsic evaluation measures for machine translation and/or summarization},
	pages={65--72},
	year={2005}
}
@inproceedings{lin2004rouge,
	title={Rouge: A package for automatic evaluation of summaries},
	author={Lin, Chin-Yew},
	booktitle={Text summarization branches out},
	pages={74--81},
	year={2004}
}
@inproceedings{vedantam2015cider,
	title={Cider: Consensus-based image description evaluation},
	author={Vedantam, Ramakrishna and Lawrence Zitnick, C and Parikh, Devi},
	booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages={4566--4575},
	year={2015}
}
@inproceedings{anderson2016spice,
	title={Spice: Semantic propositional image caption evaluation},
	author={Anderson, Peter and Fernando, Basura and Johnson, Mark and Gould, Stephen},
	booktitle={Computer Vision--ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11-14, 2016, Proceedings, Part V 14},
	pages={382--398},
	year={2016},
	organization={Springer}
}
@inproceedings{radford2021learning,
	title={Learning transferable visual models from natural language supervision},
	author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
	booktitle={International conference on machine learning},
	pages={8748--8763},
	year={2021},
	organization={PMLR}
}
@article{wang2022git,
	title={Git: A generative image-to-text transformer for vision and language},
	author={Wang, Jianfeng and Yang, Zhengyuan and Hu, Xiaowei and Li, Linjie and Lin, Kevin and Gan, Zhe and Liu, Zicheng and Liu, Ce and Wang, Lijuan},
	journal={arXiv preprint arXiv:2205.14100},
	year={2022}
}
@article{alayrac2022flamingo,
	title={Flamingo: a visual language model for few-shot learning},
	author={Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc, Karel and Mensch, Arthur and Millican, Katherine and Reynolds, Malcolm and others},
	journal={Advances in neural information processing systems},
	volume={35},
	pages={23716--23736},
	year={2022}
}
@article{liu2024visual,
	title={Visual instruction tuning},
	author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
	journal={Advances in neural information processing systems},
	volume={36},
	year={2024}
}
@inproceedings{kuo2023haav,
	title={Haav: Hierarchical aggregation of augmented views for image captioning},
	author={Kuo, Chia-Wen and Kira, Zsolt},
	booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
	pages={11039--11049},
	year={2023}
}
@inproceedings{zhang2023improving,
	title={Improving Image Captioning through Visual and Semantic Mutual Promotion},
	author={Zhang, Jing and Xie, Yingshuai and Liu, Xiaoqiang},
	booktitle={Proceedings of the 31st ACM International Conference on Multimedia},
	pages={4716--4724},
	year={2023}
}
@inproceedings{vinyals2015show,
	title={Show and tell: A neural image caption generator},
	author={Vinyals, Oriol and Toshev, Alexander and Bengio, Samy and Erhan, Dumitru},
	booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages={3156--3164},
	year={2015}
}
@inproceedings{cornia2020meshed,
	title={Meshed-memory transformer for image captioning},
	author={Cornia, Marcella and Stefanini, Matteo and Baraldi, Lorenzo and Cucchiara, Rita},
	booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
	pages={10578--10587},
	year={2020}
}
@inproceedings{luo2021dual,
	title={Dual-level collaborative transformer for image captioning},
	author={Luo, Yunpeng and Ji, Jiayi and Sun, Xiaoshuai and Cao, Liujuan and Wu, Yongjian and Huang, Feiyue and Lin, Chia-Wen and Ji, Rongrong},
	booktitle={Proceedings of the AAAI conference on artificial intelligence},
	volume={35},
	number={3},
	pages={2286--2293},
	year={2021}
}
@article{wu2019recall,
	title={Recall what you see continually using gridlstm in image captioning},
	author={Wu, Lingxiang and Xu, Min and Wang, Jinqiao and Perry, Stuart},
	journal={IEEE Transactions on Multimedia},
	volume={22},
	number={3},
	pages={808--818},
	year={2019},
	publisher={IEEE}
}
@article{xu2019multi,
	title={Multi-level policy and reward-based deep reinforcement learning framework for image captioning},
	author={Xu, Ning and Zhang, Hanwang and Liu, An-An and Nie, Weizhi and Su, Yuting and Nie, Jie and Zhang, Yongdong},
	journal={IEEE Transactions on Multimedia},
	volume={22},
	number={5},
	pages={1372--1383},
	year={2019},
	publisher={IEEE}
}
@article{singh2021nlp,
	title={The NLP cookbook: modern recipes for transformer based deep learning architectures},
	author={Singh, Sushant and Mahmood, Ausif},
	journal={IEEE Access},
	volume={9},
	pages={68675--68702},
	year={2021},
	publisher={IEEE}
}
@article{xu2022rag,
	title={RAG-TCGCN: aspect sentiment analysis based on residual attention gating and three-channel graph convolutional networks},
	author={Xu, Huan and Liu, Shuxian and Wang, Wei and Deng, Le},
	journal={Applied Sciences},
	volume={12},
	number={23},
	pages={12108},
	year={2022},
	publisher={MDPI}
}
@inproceedings{fang2023eva,
	title={Eva: Exploring the limits of masked visual representation learning at scale},
	author={Fang, Yuxin and Wang, Wen and Xie, Binhui and Sun, Quan and Wu, Ledell and Wang, Xinggang and Huang, Tiejun and Wang, Xinlong and Cao, Yue},
	booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages={19358--19369},
	year={2023}
}
@article{zheng2023judging,
	title={Judging llm-as-a-judge with mt-bench and chatbot arena},
	author={Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric and others},
	journal={Advances in Neural Information Processing Systems},
	volume={36},
	pages={46595--46623},
	year={2023}
}