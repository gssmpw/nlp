
\begin{table*}[t]
\centering
\caption{Compared with other popular models on MSCOCO, NoCaps, and Flickr30k, we also compare the number of trainable parameters and present the training data used. Where B@4, M, C, and S represent BLEU@4, METEOR, CIDEr, and SPICE, respectively. * denotes using a memory bank, {\dag}  denotes the result we reproduced on a single RTX 4090 GPU, the same device used for our method.} 
\vspace*{-0.5\baselineskip}	
\label{tab:overall}
\resizebox{\linewidth}{!}{
\begin{tabular}{l|cc|cccc|cccccccc|cc}
\toprule[1pt]
\multirow{3}{*}{\textbf{Method}} & \multicolumn{2}{c|}{\textbf{Training}} & \multicolumn{4}{c|}{\textbf{COCO}} & \multicolumn{8}{c|}{\textbf{NoCaps Val}} & \multicolumn{2}{c}{\textbf{Flickr30k}} \\
& \multirow{2}{*}{Data} & \multirow{2}{*}{Para.}
& \multicolumn{4}{c|}{Test}
& \multicolumn{2}{c|}{In-domain} & \multicolumn{2}{c|}{Near-domain} 
& \multicolumn{2}{c|}{Out-domain} & \multicolumn{2}{c|}{Overall}
& \multicolumn{2}{c}{Test} \\
& & 
& \multicolumn{1}{c}{B@4} & \multicolumn{1}{c}{M} & \multicolumn{1}{c}{C} & \multicolumn{1}{c|}{S}
& \multicolumn{1}{c}{C} & \multicolumn{1}{c|}{S} 
& \multicolumn{1}{c}{C} & \multicolumn{1}{c|}{S} 
& \multicolumn{1}{c}{C} & \multicolumn{1}{c|}{S} 
& \multicolumn{1}{c}{C} & \multicolumn{1}{c|}{S} 
& \multicolumn{1}{c}{C} & \multicolumn{1}{c}{S} \\
\midrule
\multicolumn{17}{l}{\demph{\textbf{Heavyweight-Training Models}}} \\
\demph{VinVL~\cite{zhang2021vinvl}} & \demph{8.9M}  & \demph{110M}  &\demph{38.2} &\demph{30.3} &\demph{129.3} & \demph{23.6}  & \demph{96.8} & \demph{13.5} & \demph{90.7} & \demph{13.1} & \demph{87.4} & \demph{11.6} & \demph{90.9} & \demph{12.8} & \demph{--} & \demph{--}  \\
\demph{AoANet+MA*~\cite{fei2021memory}} & \demph{COCO}  & \demph{--}  & \demph{38.0} & \demph{28.7} & \demph{121.0}  & \demph{21.8} & \demph{--}  & \demph{--} & \demph{--}  & \demph{--}  & \demph{--} & \demph{--} & \demph{--}  & \demph{--} & \demph{--} & \demph{--}   \\
\demph{NOC-REK*~\cite{vo2022noc}} & \demph{COCO} & \demph{110M} & \demph{--} & \demph{--} & \demph{--}  & \demph{--}  & \demph{104.7} & \demph{14.8} & \demph{100.2} & \demph{14.1} & \demph{100.7} & \demph{13.0} & \demph{100.9} & \demph{14.0}  & \demph{--} & \demph{--}  \\
\demph{RCA-NOC*~\cite{fan2023rca}}  & \demph{COCO} & \demph{110M} & \demph{37.4} & \demph{29.6} & \demph{128.4}  & \demph{23.1}  & \demph{92.2} & \demph{12.9} & \demph{87.8} & \demph{12.6} & \demph{87.5} & \demph{11.5} & \demph{88.3} & \demph{12.4} & \demph{--} & \demph{--} \\
\demph{ViECap \demph{$_\text{GPT2}$}~\cite{fei2023transferable}} & \demph{COCO}   & \demph{124M} & \demph{27.2} & \demph{24.8} & \demph{92.9}  & \demph{18.2}  & \demph{61.1} & \demph{10.4} & \demph{64.3} & \demph{9.9} & \demph{65.0} & \demph{8.6} & \demph{66.2} & \demph{9.5}  & \demph{47.9} & \demph{13.6} \\
\demph{InstructBLIP \demph{$_\text{Vicuna-13B}$}~\cite{NEURIPS2023_9a6a435e}} & \demph{129M}  & \demph{188M} & \demph{--} & \demph{--} & \demph{--}  & \demph{--}  & \demph{--}  & \demph{--}  & \demph{--}  & \demph{--} & \demph{--}  & \demph{--}  & \demph{121.9}  & \demph{--}  & \demph{82.8} & \demph{--} \\
\demph{OSCAR~\cite{li2020oscar}} & \demph{4.1M}  & \demph{338M}  & \demph{37.4} & \demph{30.7} & \demph{127.8} & \demph{23.5} & \demph{83.4} & \demph{12.0} & \demph{81.6} & \demph{12.0} & \demph{77.6} & \demph{10.6} & \demph{81.1} & \demph{11.7} & \demph{--} & \demph{--} \\
\demph{BLIP~\cite{li2022blip}}  & \demph{129M}  & \demph{446M} & \demph{40.4} & \demph{--} & \demph{136.7} & \demph{--} & \demph{114.9} & \demph{15.2} & \demph{112.1} & \demph{14.9} & \demph{115.3} & \demph{14.4} & \demph{113.2} & \demph{14.8} & \demph{--} & \demph{--} \\
\demph{BLIP-2 \demph{$_\text{FlanT5-XL}$}~\cite{li2023blip}}  & \demph{129M}  & \demph{1.2B} & \demph{42.4} & \demph{--} & \demph{144.5} & \demph{--} & \demph{123.7} & \demph{16.3} & \demph{120.2} & \demph{15.9} & \demph{124.8} & \demph{15.1} & \demph{121.6} & \demph{15.8}  & \demph{--} & \demph{--} \\
\demph{REVEAL* \demph{$_\text{T5}$}~\cite{hu2023reveal}}  & \demph{1.3B}  & \demph{2.1B}  & \demph{--} & \demph{--} & \demph{145.4} & \demph{--}  & \demph{--}  & \demph{--}  & \demph{--}  & \demph{--} & \demph{--}  & \demph{--}  & \demph{123.0} & \demph{--}  & \demph{--} & \demph{--} \\
\midrule
\multicolumn{17}{l}{\textbf{Lightweight-Training Models}} \\
MiniGPT4 \demph{$_\text{Vicuna-13B}$}~\cite{zhu2023minigpt} & 5M  & 3.94M & 38.0 & 29.6 & 129.6  & 23.4  & 99.0  & 14.8  & 106.9  & 15.3 & 110.8  & \textbf{14.9}  & 108.8 & \textbf{15.1}  & 78.4 & 16.9 \\
SmallCap* \demph{$_\text{GPT2}$}~\cite{ramos2023smallcap} & COCO  & 7M & 37.0 & 27.9 & 119.7  & 21.3  & --  & --  & --  & -- & --  & --  & -- & --  & 60.6 & -- \\
ClipCap \demph{$_\text{GPT2}$}~\cite{mokady2021clipcap}  & COCO  & 43M & 33.5 & 27.5 & 113.1  & 21.1   & 84.9 & 12.1 & 66.8 & 10.9 & 49.1 & 9.6 & 65.8 & 10.9    & -- & -- \\
EVCap*\dag \demph{$_\text{Vicuna-7B}$}~\cite{li2024evcap} & COCO & 3.97M & 40.3 & \textbf{30.9} & 137.2  & 24.5  & 109.0 & 14.8 & 115.4 & 15.1 & 112.1 & 14.7 & 115.3 & 15.0 & 80.3 & 17.6 \\
\rowcolor{Gray}
Ours \demph{$_\text{Vicuna-7B}$} & COCO & \textbf{0.82M} & \textbf{40.7} & 30.6 & \textbf{138.6} & \textbf{24.6} & \textbf{113.9} & \textbf{15.3} & \textbf{118.5} & \textbf{15.5} & \textbf{114.4} & 14.4 & \textbf{118.2} & \textbf{15.1} & \textbf{84.3} & \textbf{18.2} \\
\midrule
\multicolumn{17}{l}{\demph{\textbf{Specialist SOTAs}}} \\
\demph{Qwen-VL \demph{$_\text{Qwen-7B}$}~\cite{bai2023qwen}} & \demph{1.4B} & \demph{9.6B} & \demph{--} & \demph{--} & \demph{--}  & \demph{--}  & \demph{--}  & \demph{--}  & \demph{--}  & \demph{--} & \demph{--}  & \demph{--}  & \demph{121.4} & \demph{--} & \demph{85.8} & \demph{--} \\
\demph{CogVLM \demph{$_\text{Vicuna-7B}$}~\cite{wang2023cogvlm}} & \demph{1.5B}  & \demph{6.5B} & \demph{--} & \demph{--} & \demph{148.7}  & \demph{--}  & \demph{--}  & \demph{--}  & \demph{--}  & \demph{--} & \demph{132.6}  & \demph{--}  & \demph{128.3} & \demph{--} & \demph{94.9} & \demph{--} \\
\demph{PaLI \demph{$_\text{mT5-XXL}$}~\cite{chen2022pali}} & \demph{1.6B}  & \demph{17B} & \demph{--} & \demph{--} & \demph{149.1}  & \demph{--}  & \demph{--}  & \demph{--}  & \demph{--}  & \demph{--} & \demph{--}  & \demph{--}  & \demph{127.0}  & \demph{--} & \demph{--} & \demph{--}\\
\demph{PaLI-X \demph{$_\text{UL2-32B}$}~\cite{chen2023pali}} & \demph{2.2B}  & \demph{55B} & \demph{--} & \demph{--} & \demph{149.2}  & \demph{--}  & \demph{--}  & \demph{--}  & \demph{--}  & \demph{--} & \demph{--}  & \demph{--}  & \demph{126.3}  & \demph{--} & \demph{--} & \demph{--} \\
\bottomrule[1pt]
\end{tabular}
}
\end{table*}
