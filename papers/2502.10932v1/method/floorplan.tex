\subsection{Phase II: Intra-die Floorplanning}
\label{sec:intradie_floorplan}

%\noindent{\bf Floorplan representation.}
We choose B*-tree~\cite{chang2000btree} for our floorplan representation because of its efficiency, flexibility and ability to handle non-slicing floorplans compared to other representations. 
The operations in a B*-tree, such as search, insertion, and deletion require linear time, and the transformation between a B*-tree and a floorplan solution is also polynomial time. The intra-die floorplanning consists of the placement of blocks $\mathcal{B}_i\subset \mathcal{B}$ into a die $d_i \in \mathcal{D}$, where $\mathcal{B}_i, \forall i\le m$ are disjoint subsets of $\mathcal{B}$ and the floorplan solutions are represented by B*-trees. 


%To reduce the disturbance of inter-die HPWL, a dummy block is inserted in the boundary of die $d_i$ and is connected to blocks in $\mathcal{B}_i$ that have a connection to any block in $\mathcal{B}_j$ of a neighbor die $d_j, j\le m$. In the B*-tree, the dummy insertion to a boundary of the die are follows:
\iffalse
\begin{itemize}
  \item Bottom boundary: Right child node of the root node.
  \item Left boundary: Left child node of the root node.
  \item Top boundary: Right-most child node in the tree.
  \item Right boundary: Left-most child node in the tree.
\end{itemize}
The dummy blocks are fixed during the intra-die floorplanning, and are removed once this stage is finished.
\fi 

We introduce two approaches for intra-die floorplanning: Simulated Annealing (SA) and Reinforcement Learning (RL). Please note after each SA move or RL action, compaction needs to be performed to estimate the objective function $f$, especially the die cost and HPWL.

\subsubsection{Simulated Annealing-based Floorplanning}
\label{sec:sa}
The initial solution is a randomly created B*-tree using the blocks $\mathcal{B}_i$.
An SA move includes the following perturbations to the B*-tree representation:
\begin{itemize}
  \item Swapping two nodes, primarily to reduce HPWL and die cost.
  \item Rotation of a block to reduce die area.
  \item Remove-and-insert, which consists of removing and inserting a node to a leaf of the B*-tree, to diversify the solutions.
  \item Changing the aspect ratio of a block mainly to reduce TNS, power and die cost.
\end{itemize}
The objective function is the same as the $f$ defined in Section~\ref{sec:formulation} for a single die $d_i$. Furthermore, the hyperparameters of the SA algorithm are the initial temperature, %$T_0$ 
the cooling factor, %$\lambda$ 
and the convergence stopping criteria. %$\epsilon_{sa}$.

\subsubsection{Reinforcement Learning-based Floorplanning}
We adopt the PPO algorithm described in Section~\ref{sec:ppo_background}. 
The key elements in the RL-based floorplanning are:
\begin{itemize}
  \item State space $\mathcal{S}$: The set of possible B*-tree configurations of blocks $\mathcal{B}_i$ in die $d_i \in \mathcal{D}$. Thus, a state $s \in \mathcal{S}$ is the B*-tree representation of a floorplan solution.
  \item Action space $\mathcal{A}$: The set of perturbations to a B*-tree as defined earlier in Section~\ref{sec:sa}. Therefore, the action space is discrete.
  %\item The state transition $P_a(s,s')$: The probability of an action $a \in \mathcal{A}$ in state $s$ at time $t$ leads to a neighbor state $s'$ at time $t{+}1$, where $s,s' \in \mathcal{S}$. The probability is formally notated as $\mathbf{Pr} (s_{t+1}{=}s'|s_t{=}s, a_t{=}a)$.
  \item The reward function $R_a(s,s')$: The negative value of the difference of the objective function $f$ defined by Equation~\eqref{eq:objective} when transitioning from state $s$ to $s'$ at time $t$. Formally, the reward function is defined as $-(f_{t+1}-f_t)$ from time step $t$ to $t{+}1$.
\end{itemize}

As described in Section~\ref{sec:ppo_background}, the policy $\pi_\theta(s|a)$ and value function $V_\phi(s)$ are estimated by fully-connected (FC) neural networks, as shown in Figure~\ref{fig:networks}a, that are trained throughout several episodes of intra-die floorplanning. The policy network consists of 2 FC layers with rectified linear unit (ReLU) function and 1 FC layer with Softmax function to obtain a probability distribution. Therefore, the policy is probabilistic and explicit exploration is unnecessary.
Similarly, the value function network consists of 3 FC layers with ReLU function and a single neuron to obtain a scalar value. Note that both networks use the same features as input.

%A \mbox{$p$-node} B*-tree has $2p!/p! (p{+}1)!$ possible configurations, making the B*-tree representation infeasible to be the input of either the policy or value function networks. 
Statistics of the B*-tree are chosen as input features. The feature computation begins with the node features such as height, number of right children, number of left children, number of nodes, HPWL of the blocks in the corresponding sub-tree. For instance, the node features of $b_3$ in Figure~\ref{fig:networks}b are 3, 2, 2, 5, and the HPWL of the sub-tree respectively (highlighted in blue). Next, the level features are the averaged node features for all nodes in the same level. For instance, the level features in level 2 are the averaged node features of $b_{13}, b_{14}, b_3$ and $b_4$, highlighted in red in Figure~\ref{fig:networks}b. Finally, the B*-tree features are simply the concatenation of level features in the first $h$ levels. Note that B*-tree features form a one-dimensional vector of size $5\cdot h$.

\begin{figure}[ht]
\centering
\includegraphics[width=.98\linewidth]{figures/networks_tree1.PNG}
\caption{(a) Architecture of fully-connected neural networks for the policy and value function estimation. (b) The B*-tree feature extraction procedure.}
\label{fig:networks}
\vspace{-6mm}
\end{figure}
