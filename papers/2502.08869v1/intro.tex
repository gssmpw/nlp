\section{Introduction}\label{sec.introduction}

\begin{figure}[!t]
\centering
\includegraphics[width=0.77\columnwidth]{fig/fig_1.pdf}
% \vspace{-1em}
\caption{The general process of leveraging vision models for time series analysis. The red boxes are two views of taxonomy used in this survey. The dashed boxes denote optional, task-dependent steps.}\label{fig.structure}
\vspace{-0.2cm}
\end{figure}

Vision models have historically been used for time series analysis. %In particular,
Since 1-dimensional (1D) convolutional neural networks (CNNs), such as WaveNet \cite{van2016wavenet}, were found effective in sequence modeling \cite{bai2018empirical}, they have been extensively adapted to various time series tasks \cite{koprinska2018convolutional,zhang2020tapnet}. %such as classification \cite{zhang2020tapnet} and forecasting \cite{koprinska2018convolutional}.
Recently, with the significant advances of sequence modeling in the language domain, growing research attentions on time series have been drawn to methods ranging from Transformers \cite{wen2023transformers} to Large Language Models (LLMs) \cite{zhang2024large}. Meanwhile, the demands for %general-purpose
universal modeling have spurred on an explosion of works on time series foundation models, %\cite{liang2024foundation},
such as TimesFM \cite{das2024decoder}, %MOMENT \cite{goswami2024moment},
Chronos \cite{ansari2024chronos} and Time-MoE \cite{shi2024time}.

As Large Vision Models (LVMs), such as ViT \cite{dosovitskiy2021image}, %DeiT \cite{touvron2021training}
BEiT \cite{bao2022beit} and MAE \cite{he2022masked}, become achieving a similar success as LLMs (but in vision domain), a great deal of emergent efforts has been invested to explore the potential of LVMs in time series modeling \cite{chen2024visionts}. This is inspired by the plenty of ways for visualizing time series as images such as line plots of univariate time series (UTS) and heatmaps of multivariate time series (MTS). Such images provide a more straightforward view of time series than the counterpart textual representations to humans and, presumably, AI bots.

Taking a closer inspection reveals more advantages favoring LVMs over LLMs: (1) There is an inherent relationship between images and time series -- each row/column in an image (per channel) is a sequence of {\em continuous} pixel values. By pre-training on massive images, LVMs may have learned important sequential patterns such as trends, periods, and spikes \cite{chen2024visionts}. In contrast, LLMs are pre-trained on {\em discrete} tokens, thus are less aligned with continuous time series. In fact, LLMs' effectiveness on time series modeling is in question \cite{tan2024language}; (2) Instead of using channel-independence assumption \cite{nie2023time} to individually model each variate in an MTS, some imaging methods ($\S$\ref{sec.modelmts}) can naturally represent MTS, enabling explicit correlation encoding; (3) When prompting LLMs, existing methods often struggle with properly %textualizing
verbalizing a long sequence (or a matrix) of floating numbers in a UTS (or MTS), which may be limited by the context length or induce high API costs. In contrast, existing works find that using LVMs on imaged time series is more prompt-friendly and less API-costly \cite{daswani2024plots}; (4) Some imaging methods %\hh{do we have a citation here?}
can encode long time series in a compact manner \cite{naiman2024utilizing}, thus have a great potential in modeling long-term dependency.

%The numerical values of time series align better with the image modality than the text modality; (2) Some image representations can model long-term time series; (3) LVMs have less API costs than LLMs (?).

Also, the concurrent developments of LLMs and LVMs for time series %analysis
%may serve as the cornerstones of a confluence, %the confluence of the two,
pave the way for a confluence, 
{\em i.e.}, leveraging %Vision Language Models (VLMs) or
Large Multimodal Models (LMMs), %\cite{achiam2023gpt,liu2023visual}
such as LLaVA \cite{liu2023visual}, Gemini \cite{team2023gemini} %GPT-4o \cite{achiam2023gpt}
and Claude-3 \cite{anthropic2024claude}, to consolidate the two complementary modalities, which may %also
revolutionize the way ({\em e.g.}, visually, linguistically, {\em etc.}) that users interact with time series.

Despite the significance, %of vision models in time series analysis,
a thorough review of %the works on this topic
relevant works is absent in the existing literature to the best of our knowledge. The survey \cite{zhang2024large} discusses a few vision models, but its focus is %still
LLMs for time series. In light of this, in this survey, we comprehensively investigate the %conventional
% we provide the first survey to comprehensively investigate the 
traditional and the state-of-the-art (SOTA) methods. %which cover diverse domains ranging from healthcare, finance to speech recognition.
%In Fig. \ref{fig.structure}, we identify the general process of %leveraging
Fig. \ref{fig.structure} identifies the general process of applying vision models for time series analysis, which also serves as the structure of this survey. %We have two views of taxonomy:
Our taxonomy has a dual view: (1) in Time Series to Image Transformation ($\S$\ref{sec.tsimage}), we review 5 primary {\em imaging methods} including Line Plot, Heatmap, Spectrogram, Gramian Angular Field (GAF), Recurrence Plot (RP), and some other %minor %\hh{why do we want to call them 'minor'? maybe use a more neutral word such as additional or other?}
methods; (2) in Imaged Time Series Modeling ($\S$\ref{sec.model}), we discuss conventional vision models, LVMs and the initial efforts in LMMs. To highlight the taxonomy, we defer the discussion on the %challenges and solutions
desiderata of pre- and post-processing to the end of this survey ($\S$\ref{sec.processing}). For comparison, we provide Table \ref{tab.taxonomy} to %comprehensively
summarize the existing methods. Finally, we discuss future directions %to further advance time series analysis with LVMs and LMMs
in this %emergent
promising field ($\S$\ref{sec.future}). A Github repository\footnote{\url{https://github.com/D2I-Group/awesome-vision-time-series}} is also maintained to provide up-to-date resources including our code of the imaging methods in $\S$\ref{sec.tsimage}. We hope this survey could be an orthogonal complement to the existing surveys on Transformer \cite{wen2023transformers}, LLMs \cite{zhang2024large,jiang2024empowering} and foundation models \cite{liang2024foundation} for time series, and %could
provide a complete view on the process of using vision models for time series analysis, so as to be an insightful guidebook to the developers in this area.


\vspace{-0.17cm}


% This work focuses on methods that transform time series to images and then use vision models for solving time series tasks (e.g., forecasting, classification, generation, anomaly detection, etc.). The works on sequential images (a.k.a. image time series), e.g., \cite{feng2021convolutional,tarasiou2023vits}, are out of the scope of this work.

%\vspace{0.2cm}

%\noindent{\bf Challenges.} 1. Find a good transformation method; 2. fit image size to pretrained models.



% Imaging methods for spacio-temporal traffic data are not part of this discussion because they are not tranformation of time series to images.

% The review of audio methods focus on representative works because the focus of the survey is on time series.

%The survey \cite{zhang2024large} review a few papers on vision models. Our survey could be a significant complement to the existing surveys \cite{wen2023transformers,zhang2024large,jiang2024empowering}.
