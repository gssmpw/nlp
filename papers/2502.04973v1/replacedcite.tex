\section{Related Work}
%%%%%%%%%%%%%%%%%%%% Section %%%%%%%%%%%%%%%%%%%%

There are two primary approaches in the literature to tackle heart rate variability. The first approach is heartbeat interval normalization, which aims to correct the duration of different heartbeat intervals to a canonical state, thereby reducing variations caused by heart rate changes. The second approach involves data augmentation that aims to generate synthetic data to enrich the training set, often in conjunction with deep learning techniques to enhance feature extraction. 

\subsection{Heartbeat Interval Normalization}
Various normalization methods targeting the duration of specific ECG intervals have been proposed to reduce the effect of heart rate changes.
Fatemian et al. ____ resampled the T-wave section to align it with the standard healthy duration under resting conditions, focusing on stabilizing the most variable segment of the ECG.
Arteaga-Falconi et al. ____ introduced a linear normalization method that normalizes the temporal features of the ECG relative to the total heartbeat duration, improving authentication reliability despite physiological fluctuations.
Choi et al. ____ proposed a fusion normalization approach that combines time-domain and frequency-domain normalization techniques to improve the alignment and consistency of ECG signals. This method linearly interpolated the P and T waves from post-exercise recordings, extending these segments to match estimated pre-exercise durations.
Hwang et al. ____ conducted regression analyses on an auxiliary dataset to establish relationships between PR, QRS, ST, and TP intervals and heart rate.
Based on these relationships, canonical interval durations were calculated at a baseline heart rate of 70 bpm.
Normalizing each interval to this canonical state demonstrated improved performance across diverse conditions, including post-exercise states.

While these approaches show improved performance, they apply uniform adjustments to interval durations across all subjects, disregarding the individual variability in the relationship between heart rate and interval durations ____. This uniformity assumption may lead to inaccuracies in normalization, reducing alignment with the actual physiological characteristics of individual subjects.

\subsection{Data Augmentation}
Unlike normalization methods, data augmentation techniques aim to increase system robustness by simulating intra-subject variability during model training.
Random alterations such as permutation, cropping, noise addition, and scaling of different ECG intervals have been proposed to diversify training datasets ____.
However, these generic augmentations do not account for changes induced by heart rate variability.
Kim et al. ____ introduced a physiology-based augmentation technique targeting the ST interval. Using Hodgesâ€™ QT interval correction formula ____, this method linearly resampled the ST interval over a range of durations for each subject, mimicking physiological variability.
While this approach improved model performance on resting-state data and addressed limitations associated with a small training dataset, the method did not account for individual variability among subjects, potentially resulting in inaccurate approximations.