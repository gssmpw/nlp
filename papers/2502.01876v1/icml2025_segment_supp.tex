\appendix
\onecolumn
\begin{center}
	\vspace*{0.01em}
	\LARGE{\textbf{Appendix}}
	\vspace*{0.3em}
\end{center}

%\tableofcontents
%\clearpage

\section{Details of the Experimental Setup} \label{apx:experimental_setup}

In this section, we detail the instances used in our experiments. 

For the binary segment feedback setting, we consider an MDP as in Figure~\ref{fig:experiment_bi}: There are $9$ states and $5$ actions. For any $a \in \cA$, we have $r(s_0,a)=0$, $r(s_i,a)=r_{\max}$ for any $i \in \{1,3,5,7\}$ (called good states), and $r(s_i,a)=-r_{\max}$ for any $i \in \{2,4,6,8\}$ (called bad states).  There is an optimal action $a^*$ and four suboptimal actions $a^{\sub}$ for all states. The agent starts from an initial state $s_0$. For any $0\leq i \leq 6$, in state $s_i$, under the optimal action $a^*$, the agent transitions to the good state and bad state at the next horizon with probabilities $0.9$ and $0.1$, respectively; Under the suboptimal action $a^{\sub}$, the agent transitions to the good state and bad state at the next horizon with probabilities $0.1$ and $0.9$, respectively. 
In $s_7$ or $s_8$, under the optimal action $a^*$, the agent transitions to $s_1$ and $s_2$ with probabilities $0.9$ and $0.1$, respectively; Under the suboptimal action $a^{\sub}$, the agent transitions to $s_1$ and $s_2$ with probabilities $0.1$ and $0.9$, respectively.

\begin{figure}[h]
	\centering
	\includegraphics[width=0.7\columnwidth]{fig/experiment_instance_bi_crop.pdf} \label{fig:lb_instance_bi}
	\caption{Instance used in the experiment for RL with binary segment feedback.
	}
\end{figure}

For the sum segment feedback setting, since algorithms $\edlinucbseg$ and $\linucbtranseg$ are computationally inefficient (which are mainly designed for revealing the optimal dependency on $H$ and $m$), we consider a smaller MDP as in Figure~\ref{fig:experiment_sum}: There are $3$ states and $5$ actions. For any $a \in \cA$, we have $r(s_0,a)=0$, $r(s_1,a)=r_{\max}$ (called a good state), and $r(s_2,a)=-r_{\max}$ (called a bad state). There is an optimal action $a^*$ and four suboptimal actions $a^{\sub}$ for all states. The agent starts from an initial state $s_0$. In any state $s \in \cS$, under the optimal action $a^*$, the agent transitions to $s_1$ and $s_2$ with probabilities $0.9$ and $0.1$, respectively; Under the suboptimal action $a^{\sub}$, the agent transitions to $s_1$ and $s_2$ with probabilities $0.1$ and $0.9$, respectively. 

\begin{figure}[h]
	\centering   
	\includegraphics[width=0.5\columnwidth]{fig/experiment_instance_sum_crop.pdf} \label{fig:lb_instance_sum}
	\caption{Instance used in the experiment for RL with sum segment feedback.
	}
\end{figure}


\section{Rounding Procedure $\round$} \label{apx:rounding_procedure}

Algorithm $\edlinucbseg$ calls a rounding procedure $\round$~\cite{allen2021near} in the experimental design literature. Taking $X_1,\dots,X_n \in \mathbb{S}^d_{+}$, distribution $w \in \triangle_{\{X_1,\dots,X_n\}}$, rounding approximation error $\gamma>0$ and the number of samples $T \geq \frac{d}{\gamma^2}$ as inputs, $\round$ rounds sampling distribution $w$ into a discrete sampling sequence $(Y_1,\dots,Y_T) \in \{X_1,\dots,X_n\}^T$ that satisfies
\begin{align*}
	\Bigg\| \Bigg( \sum_{t=1}^{T}  Y_t \Bigg)^{-1} \Bigg\| 
	\leq (1+\gamma) \Bigg\| \Bigg( T \sum_{i \in [n]} w(X_i) X_i \Bigg)^{-1} \Bigg\| .
\end{align*}

In implementation, we can regard $x x^\top$ in \cite{allen2021near} as $\sum_{i=1}^{m} \ex_{\tau_i \sim \pi} [\phi^{\tau_i} (\phi^{\tau_i})^\top]$, and regard sampling weight on $x$ as the sampling weight on $\pi$ in our work.

\section{Proofs for RL with Binary Segment Feedback}

In this section, we present the proofs for RL with binary segment feedback.

\subsection{Proof for the Regret Upper Bound with Known Transition}\label{apx:ub_binary_known_tran}

First, we prove the regret upper bound (Theorem~\ref{thm:ub_bits}) of algorithm $\bitsseg$ for known transition.

	For any $k>0$ and $\theta \in \Theta$, define
\begin{align}
	Z_k &:= \sum_{k'=1}^{k} \sum_{i=1}^{m} \varepsilon_{k',i} \cdot \phi^{\tau^{k'}_i} , \nonumber
	\\
	g_{k}(\theta) &:= \sum_{k'=1}^{k} \sum_{i=1}^{m} \mu( (\phi^{\tau^{k'}_i})^\top\theta ) \cdot \phi^{\tau^{k'}_i} + \lambda \theta , \label{eq:def_g_k}
	\\
	\Lambda_{k}(\theta) &:=  \sum_{k'=1}^{k} \sum_{i=1}^{m} \mu'( (\phi^{\tau^{k'}_i})^\top\theta ) \cdot \phi^{\tau^{k'}_i} (\phi^{\tau^{k'}_i})^\top + \lambda I . \label{eq:def_Lambda_k}
\end{align}



\begin{lemma} \label{lemma:Lambda_k}
	For any $k>0$ and $\theta \in \Theta$, we have
	\begin{align*}
		\det(\Lambda_k(\theta)) \leq \sbr{ \frac{H^2 \mu'_{\max} k}{|\cS||\cA| m} + \lambda  }^{|\cS||\cA|} .
	\end{align*}
\end{lemma}
\begin{proof}
	For any $k>0$, we have
	\begin{align*}
		\det(\Lambda_k(\theta)) &\leq \sbr{ \frac{\trace(\Lambda_k(\theta))}{|\cS||\cA|} }^{|\cS||\cA|}
		\\
		&\leq \sbr{ \frac{1}{|\cS||\cA|} \cdot \sbr{ k m \cdot \mu'_{\max} \cdot \sbr{\frac{H}{m}}^2 + \lambda |\cS||\cA| } }^{|\cS||\cA|}
		\\
		&= \sbr{ \frac{H^2 \mu'_{\max} k}{|\cS||\cA| m} + \lambda  }^{|\cS||\cA|} .
	\end{align*}
\end{proof}

For any $k>0$, let $F_k$ denote the filtration that includes all events up to the end of episode $k$, and $\tilde{F}_{k}$ denote the filtration that includes all events before playing $\pi^k$ in episode $k$. Then, $\pi^k$ is $\tilde{F}_{k}$-measurable.

For any $k>0$ and $i \in [m]$, let $\varepsilon_{k,i}:=y^k_i-(\phi^{\tau^k_i})^\top \theta^*$ denote the noise of binary feedback, and $v_{k,i}^2:=\ex[\varepsilon_{k,i}^2 | \tilde{F}_{k}]=(\phi^{\tau^k_i})^\top \theta^* \cdot (1- (\phi^{\tau^k_i})^\top \theta^*)=\mu'((\phi^{\tau^k_i})^\top \theta^*)$ denote the variance of $\varepsilon_{k,i}$ conditioning on $\tilde{F}_{k}$.

Then, we have
\begin{align*}
	\Lambda_{k}(\theta^*) &:= \sum_{k'=1}^{k} \sum_{i=1}^{m} \mu'( (\phi^{\tau^{k'}_i})^\top \theta^* ) \cdot \phi^{\tau^{k'}_i} (\phi^{\tau^{k'}_i})^\top + \lambda I 
	\\
	&= \sum_{k'=1}^{k} \sum_{i=1}^{m} v_{k',i}^2 \cdot \phi^{\tau^{k'}_i} (\phi^{\tau^{k'}_i})^\top + \lambda I .
\end{align*}


\begin{lemma}[Concentration of Noises under Binary Feedback]\label{lemma:noise_seq_martingale}
	With probability at least $1-\delta'$, for any $k>0$,
	\begin{align*}
		\nbr{\sum_{k'=1}^{k} \sum_{i=1}^{m} \varepsilon_{k',i} \cdot \phi^{\tau^{k'}_i}}_{\Lambda_{k}^{-1}(\theta^*)} \leq \frac{\sqrt{\lambda}}{2} + \frac{|\cS||\cA|}{\sqrt{\lambda}} \log \sbr{ \frac{4}{\delta'} \cdot \sbr{ 1 + \frac{H^2 \mu'_{\max} k}{|\cS||\cA| m \lambda}   }  } .
	\end{align*}
\end{lemma}

\begin{proof}
	According to Theorem 1 in \cite{faury2020improved}, we have that with probability at least $1-\delta'$, for any $k>0$,
	\begin{align*}
		\nbr{\sum_{k'=1}^{k} \sum_{i=1}^{m} \varepsilon_{k',i} \cdot \phi^{\tau^{k'}_i}}_{\Lambda_{k}^{-1}(\theta^*)} &\leq \frac{\sqrt{\lambda}}{2} + \frac{2}{\sqrt{\lambda}} \log \sbr{ \frac{\det(\Lambda_{k}(\theta^*))^{\frac{1}{2}} \cdot \lambda^{-\frac{|\cS| |\cA|}{2}}}{\delta'}  } + \frac{2}{\sqrt{\lambda}} |\cS| |\cA| \log(2)
		\\
		&\overset{\textup{(a)}}{\leq} \frac{\sqrt{\lambda}}{2} \!+\! \frac{2}{\sqrt{\lambda}} \log \sbr{ \frac{1}{\delta'}  \sbr{ 1 + \frac{H^2 \mu'_{\max} k}{|\cS||\cA| m \lambda}   }^{\frac{|\cS||\cA|}{2}}  }   \!+\! \frac{2}{\sqrt{\lambda}} |\cS| |\cA| \log(2)
		\\
		&\leq \frac{\sqrt{\lambda}}{2} + \frac{|\cS||\cA|}{\sqrt{\lambda}} \log \sbr{ \frac{1}{\delta'}  \sbr{ 1 + \frac{H^2 \mu'_{\max} k}{|\cS||\cA| m \lambda}   }  }   + \frac{2}{\sqrt{\lambda}} |\cS| |\cA| \log(2)
		\\
		&\leq \frac{\sqrt{\lambda}}{2} + \frac{|\cS||\cA|}{\sqrt{\lambda}} \log \sbr{ \frac{4}{\delta'}  \sbr{ 1 + \frac{H^2 \mu'_{\max} k}{|\cS||\cA| m \lambda}   }  } ,
	\end{align*}
	where (a) uses Lemma~\ref{lemma:Lambda_k}.
\end{proof}

Define event
\begin{align*}
	\cE:=\lbr{ \nbr{g_k(\hat{\theta}_k) - g_k(\theta^*) }_{\Lambda_k^{-1}(\theta^*)} \leq \omega(k), \  \forall k>0 } .
\end{align*}
\begin{lemma}
	It holds that
	\begin{align*}
		\Pr \mbr{ \cE } \geq 1-\delta' .
	\end{align*}
\end{lemma}
\begin{proof}
	This proof is similar to that for Lemma 8 in \cite{faury2020improved}.
	
	Define
	\begin{align*}
		\cL_k(\theta) \!:=\! - \sbr{ \sum_{k'=1}^{k} \sum_{i=1}^{m} \sbr{ y^{k'}_i \cdot \log\sbr{\mu((\phi^{\tau^{k'}_i})^\top \theta)} \!+\! (1 \!-\! y^{k'}_i) \cdot \log\sbr{1 \!-\! \mu((\phi^{\tau^{k'}_i})^\top \theta) } } \!-\! \frac{1}{2} \lambda \|\theta\|_2^2 } .
	\end{align*}
	Recall that $\hat{\theta}_k = \argmin_{\theta} \cL_k(\theta)$.
	Using the facts that $\nabla \cL_k(\hat{\theta}_k)=0$ and $\mu'(x)=\mu(x)(1-\mu(x))$, we have
	\begin{align*}
		\underbrace{\sum_{k'=1}^{k} \sum_{i=1}^{m} \mu( (\phi^{\tau^{k'}_i})^\top \hat{\theta}_k ) \cdot \phi^{\tau^{k'}_i} + \lambda \hat{\theta}_k}_{g_k(\hat{\theta}_k)} = 	\sum_{k'=1}^{k} \sum_{i=1}^{m} y^{k'}_i \cdot \phi^{\tau^{k'}_i} .
	\end{align*}
	
	Hence, we have
	\begin{align}
		g_k(\hat{\theta}_k) - g_k(\theta^*) &= \sum_{k'=1}^{k} \sum_{i=1}^{m} y^{k'}_i \cdot \phi^{\tau^{k'}_i} - \sbr{ \sum_{k'=1}^{k} \sum_{i=1}^{m} \mu( (\phi^{\tau^{k'}_i})^\top \theta^* ) \cdot \phi^{\tau^{k'}_i} + \lambda \theta^* }
		\nonumber\\
		&= \sum_{k'=1}^{k} \sum_{i=1}^{m} \varepsilon_{k',i} \cdot \phi^{\tau^{k'}_i} -  \lambda \theta^* . \label{eq:g_hat_theta-g_theta_star}
	\end{align}
	
	
	Then, using Lemma~\ref{lemma:noise_seq_martingale}, we have that with probability at least $1-\delta'$, for any $k>0$,
	\begin{align*}
		\nbr{ g_k(\hat{\theta}_k) - g_k(\theta^*) }_{\Lambda_k^{-1}(\theta^*)} &\leq \nbr{ \sum_{k'=1}^{k} \sum_{i=1}^{m} \varepsilon_{k',i} \cdot \phi^{\tau^{k'}_i} }_{\Lambda_k^{-1}(\theta^*)} + r_{\max} \sqrt{\lambda |\cS| |\cA|} 
		\\
		&\leq \frac{\sqrt{\lambda}}{2} + \frac{|\cS||\cA|}{\sqrt{\lambda}} \log \sbr{ \frac{4}{\delta'} \cdot \sbr{ 1 + \frac{H^2 \mu'_{\max} k}{|\cS||\cA| m \lambda}   }  } + r_{\max} \sqrt{\lambda |\cS| |\cA|}  
		\\
		&= \omega(k) .
	\end{align*}
	
	
	
\end{proof}

For any $\phi \in \R^{|\cS||\cA|}$ and $\theta_1,\theta_2 \in \Theta$, define
\begin{align*}
	b(\phi,\theta_1,\theta_2)&:=\int_{z=0}^{1} \mu'( (1-z) \cdot \phi^\top \theta_1 + z \cdot \phi^\top \theta_2) dz .
\end{align*}
For any $k>0$ and $\theta_1,\theta_2 \in \Theta$, define
\begin{align*}
	\Gamma_k(\theta_1,\theta_2)&:= \sum_{k'=1}^{k} \sum_{i=1}^{m} b(\phi,\theta_1,\theta_2) \cdot \phi^{\tau^{k'}_i} (\phi^{\tau^{k'}_i})^\top + \lambda I .
\end{align*}
In the definitions of $b(\phi,\theta_1,\theta_2)$ and $\Gamma_k(\theta_1,\theta_2)$, $\theta_1$ and $\theta_2$ have the same roles and can be interchanged.

Recall that 
\begin{align*}
	\alpha := \exp(\frac{H r_{\max}}{m})+\exp(-\frac{H r_{\max}}{m})+2 .
\end{align*}
Then, we have
\begin{align*}
	\sup_{\tau^{\seg}, \theta} \frac{1}{\mu'((\phi^{\tau^{\seg}})^\top \theta)} \leq \alpha ,
\end{align*}
where $\tau^{\seg}$ denotes the visitation indicator of any possible trajectory segment.

\begin{lemma} \label{lemma:transform_Lambda_Sigma}
	For any $k\geq 1$ and $\theta \in \Theta$, we have
	\begin{align*}
		%			\Gamma_k(\theta_1,\theta_2) &\succeq \sbr{1+\frac{2Hr_{\max}}{m}}^{-1} \Lambda_k(\theta_1) ,
		%			\\
		\Sigma_k &\preceq \alpha  \Lambda_k(\theta) .
		%			\\
		%			\Gamma_k(\theta_1,\theta_2) &\succeq \frac{1}{\alpha} \Sigma_k .
	\end{align*}
\end{lemma}
\begin{proof}
	We have
	\begin{align*}
		\frac{1}{\alpha} = \inf_{\tau^{\seg}, \theta} \mu'((\phi^{\tau^{\seg}})^\top \theta) .
	\end{align*}
	
	Then, it holds that
	\begin{align*}
		\Sigma_k &= \sum_{k'=1}^{k} \sum_{i=1}^{m} \phi^{\tau^{k'}_i} (\phi^{\tau^{k'}_i})^\top + \alpha \lambda I
		\\
		&= \alpha  \sbr{ \sum_{k'=1}^{k} \sum_{i=1}^{m} \frac{1}{\alpha} \cdot \phi^{\tau^{k'}_i} (\phi^{\tau^{k'}_i})^\top +  \lambda I }
		\\
		&\preceq \alpha  \sbr{ \sum_{k'=1}^{k} \sum_{i=1}^{m} \mu'( (\phi^{\tau^{k'}_i})^\top\theta ) \cdot \phi^{\tau^{k'}_i} (\phi^{\tau^{k'}_i})^\top + \lambda I }
		\\
		&= \alpha  \Lambda_k(\theta) .
	\end{align*}
\end{proof}

\begin{lemma} \label{lemma:two_equalities}
	For any $\phi \in \R^{|\cS||\cA|}$ and $\theta_1,\theta_2 \in \Theta$, we have
	\begin{align*}
		\mu(\phi^\top \theta_1) - \mu(\phi^\top \theta_2) = b(\phi,\theta_2,\theta_1) \cdot \phi^\top (\theta_1-\theta_2) .
	\end{align*}
	
	In addition, for any $k>0$ and $\theta_1,\theta_2 \in \Theta$, we have
	\begin{align*}
		\nbr{\theta_1-\theta_2}_{\Gamma_{k}(\theta_2,\theta_1)} = \nbr{ g_k(\theta_1) - g_k(\theta_2) }_{\Gamma_{k}^{-1}(\theta_2,\theta_1)} .
	\end{align*}
\end{lemma}
\begin{proof}
	The first statement follows from the mean-value theorem.
	
	Then, using the first statement, we have that for any $k>0$,
	\begin{align*}
		g_k(\theta_1) - g_k(\theta_2) &= \sum_{k'=1}^{k} \sum_{i=1}^{m} \sbr{\mu( (\phi^{\tau^{k'}_i})^\top \theta_1 ) - \mu( (\phi^{\tau^{k'}_i})^\top \theta_2 )} \cdot \phi^{\tau^{k'}_i} + \lambda \sbr{ \theta_1 - \theta_2 }
		\\
		&= \sum_{k'=1}^{k} \sum_{i=1}^{m} b(\phi^{\tau^{k'}_i},\theta_2,\theta_1) \cdot \phi^{\tau^{k'}_i} (\phi^{\tau^{k'}_i})^\top (\theta_1-\theta_2) + \lambda \sbr{ \theta_1 - \theta_2 }
		\\
		&= \Gamma_{k}(\theta_2,\theta_1) \cdot (\theta_1-\theta_2) ,
	\end{align*}
	and thus
	\begin{align*}
		\nbr{\theta_1-\theta_2}_{\Gamma_{k}(\theta_2,\theta_1)} &= \sqrt{ \sbr{\theta_1-\theta_2}^\top \cdot \Gamma_{k}(\theta_2,\theta_1) \cdot \sbr{\theta_1-\theta_2}  }
		\\
		&= \sqrt{ \sbr{\theta_1-\theta_2}^\top \cdot \Gamma_{k}(\theta_2,\theta_1) \cdot \Gamma_{k}^{-1}(\theta_2,\theta_1) \cdot \Gamma_{k}(\theta_2,\theta_1) \cdot \sbr{\theta_1-\theta_2}  }
		\\
		&= \nbr{ g_k(\theta_1) - g_k(\theta_2) }_{\Gamma_{k}^{-1}(\theta_2,\theta_1)} ,
	\end{align*}
	which gives the second statement.
\end{proof}

Recall that for any $k>0$, $Z_k := \sum_{k'=1}^{k} \sum_{i=1}^{m} \varepsilon_{k',i} \cdot \phi^{\tau^{k'}_i}$.

\begin{lemma} \label{lemma:eff_bound_Z_k}
	For any $k>0$, we have
	\begin{align*}
		\Gamma_k(\theta^*,\hat{\theta}_k) &\succeq \sbr{ 1+  \frac{H r_{\max} \sqrt{|\cS| |\cA|}}{m}   + \frac{H}{m\sqrt{\lambda}} \nbr{ Z_k }_{\Gamma_k^{-1}(\theta^*,\hat{\theta}_k)} }^{-1} \Lambda_k(\theta^*) ,
		\\
		\nbr{Z_k}_{\Gamma_k^{-1}(\theta^*,\hat{\theta}_k)} &\leq \sqrt{ 1+  \frac{H r_{\max} \sqrt{|\cS| |\cA|}}{m} } \nbr{Z_k}_{\Lambda_k^{-1}(\theta^*)} + \frac{H}{m\sqrt{\lambda}}  \nbr{Z_k}_{\Lambda_k^{-1}(\theta^*)}^2 .
	\end{align*}
	
	Furthermore, assuming that event $\cE$ holds, we have
	\begin{align*}
		\nbr{Z_k}_{\Gamma_k^{-1}(\theta^*,\hat{\theta}_k)} \leq \sqrt{ 1+  \frac{H r_{\max} \sqrt{|\cS| |\cA|}}{m} } \cdot \omega(k) + \frac{H}{m\sqrt{\lambda}} \cdot \omega(k)^2 .
	\end{align*}
\end{lemma}

\begin{proof}
	This proof follows the analysis of Proposition 6 and Corollary 5 in \cite{russac2021self}.
	
	From Eq.~\eqref{eq:g_hat_theta-g_theta_star}, we have that for any $k>0$,
	\begin{align*}
		g_k(\hat{\theta}_k) - g_k(\theta^*) = Z_k -  \lambda \theta^* .
	\end{align*}
	
	Using Lemma~\ref{lemma:self_concordance}, we have that for any $\phi \in \R^{|\cS| |\cA|}$ such that $\|\phi\|_2 \leq L_{\phi}$, 
	\begin{align*}
		b(\phi,\theta^*,\hat{\theta}_k) &\geq \sbr{ 1+\abr{\phi^\top (\theta^*-\hat{\theta}_k)} }^{-1} \mu'(\phi^\top \theta^*)
		\\
		&= \sbr{ 1+\abr{\phi^\top \Gamma_k^{-1}(\theta^*,\hat{\theta}_k)\cdot (g_k(\theta^*)-g_k(\hat{\theta}_k))} }^{-1} \mu'(\phi^\top \theta^*)
		\\
		&\geq \sbr{ 1+\nbr{\phi}_{ \Gamma_k^{-1}(\theta^*,\hat{\theta}_k)}  \nbr{g_k(\theta^*)-g_k(\hat{\theta}_k)}_{\Gamma_k^{-1}(\theta^*,\hat{\theta}_k)} }^{-1} \mu'(\phi^\top \theta^*)
		\\
		&\geq \sbr{ 1+\frac{L_{\phi}}{\sqrt{\lambda}} \nbr{g_k(\theta^*)-g_k(\hat{\theta}_k)}_{\Gamma_k^{-1}(\theta^*,\hat{\theta}_k)} }^{-1} \mu'(\phi^\top \theta^*)
		\\
		&= \sbr{ 1+\frac{L_{\phi}}{\sqrt{\lambda}} \nbr{ Z_k-\lambda \theta^* }_{\Gamma_k^{-1}(\theta^*,\hat{\theta}_k)} }^{-1} \mu'(\phi^\top \theta^*)
		\\
		&\geq \sbr{ 1+ L_{\phi} r_{\max} \sqrt{|\cS| |\cA|}   + \frac{L_{\phi}}{\sqrt{\lambda}} \nbr{ Z_k }_{\Gamma_k^{-1}(\theta^*,\hat{\theta}_k)} }^{-1} \mu'(\phi^\top \theta^*) .
	\end{align*}
	
	Using the above equation with $\phi=\phi^{\tau^{k'}_i}$ and $L_{\phi}=\frac{H}{m}$, we have
	\begin{align*}
		\Gamma_k(\theta^*,\hat{\theta}_k)&:= \sum_{k'=1}^{k} \sum_{i=1}^{m} b(\phi^{\tau^{k'}_i},\theta^*,\hat{\theta}_k) \cdot \phi^{\tau^{k'}_i} (\phi^{\tau^{k'}_i})^\top + \lambda I 
		\\
		&\succeq \!\!\sum_{k'=1}^{k} \!\sum_{i=1}^{m} \sbr{ 1 \!+\!  \frac{H r_{\max} \sqrt{|\cS| |\cA|}}{m}   \!+\! \frac{H}{m\sqrt{\lambda}} \nbr{ Z_k }_{\Gamma_k^{-1}(\theta^*,\hat{\theta}_k)} }^{\!\!-1} \!\!\!\! \mu'(\phi^\top \theta^*) \cdot \phi^{\tau^{k'}_i} (\phi^{\tau^{k'}_i})^{\!\top} \!\!+\! \lambda I 
		\\
		&=  \sbr{ 1+  \frac{H r_{\max} \sqrt{|\cS| |\cA|}}{m}   + \frac{H}{m\sqrt{\lambda}} \nbr{ Z_k }_{\Gamma_k^{-1}(\theta^*,\hat{\theta}_k)} }^{-1} \Lambda_k(\theta^*) .
	\end{align*}
	
	This implies
	\begin{align*}
		\nbr{Z_k}_{\Gamma_k^{-1}(\theta^*,\hat{\theta}_k)}^2 \leq \sbr{ 1+  \frac{H r_{\max} \sqrt{|\cS| |\cA|}}{m}   + \frac{H}{m\sqrt{\lambda}} \nbr{ Z_k }_{\Gamma_k^{-1}(\theta^*,\hat{\theta}_k)} } \nbr{Z_k}_{\Lambda_k^{-1}(\theta^*)}^2 ,
	\end{align*}
	which is equivalent to
	\begin{align*}	\nbr{Z_k}_{\Gamma_k^{-1}(\theta^*,\hat{\theta}_k)}^2 - \frac{H}{m\sqrt{\lambda}}  \nbr{Z_k}_{\Lambda_k^{-1}(\theta^*)}^2 \nbr{ Z_k }_{\Gamma_k^{-1}(\theta^*,\hat{\theta}_k)} - \sbr{ 1+  \frac{H r_{\max} \sqrt{|\cS| |\cA|}}{m} } \nbr{Z_k}_{\Lambda_k^{-1}(\theta^*)}^2 \leq 0 .
	\end{align*}
	
	By analysis of quadratic functions, we have
	\begin{align*}
		\nbr{Z_k}_{\Gamma_k^{-1}(\theta^*,\hat{\theta}_k)} &\leq \sqrt{ 1+  \frac{H r_{\max} \sqrt{|\cS| |\cA|}}{m} } \nbr{Z_k}_{\Lambda_k^{-1}(\theta^*)} + \frac{H}{m\sqrt{\lambda}}  \nbr{Z_k}_{\Lambda_k^{-1}(\theta^*)}^2 
		\\
		&\leq \sqrt{ 1+  \frac{H r_{\max} \sqrt{|\cS| |\cA|}}{m} } \cdot \omega(k) + \frac{H}{m\sqrt{\lambda}} \cdot \omega(k)^2  .
	\end{align*}
	
\end{proof}



\begin{lemma}[Concentration of $\phi^\top \hat{\theta}_k$ under Binary Feedback] \label{lemma:confence_interval_proj_free}
	Assume that event $\cE$ holds. Then, for any $k>0$ and $\phi \in \R^{|\cS| |\cA|}$,
	\begin{align*}
		|\phi^\top \theta^* - \phi^\top \hat{\theta}_k| \leq \sqrt{\alpha} \cdot \nu(k) \nbr{\phi}_{\Sigma_k^{-1}}  .
	\end{align*}
\end{lemma}
\begin{proof}
	We have
	\begin{align*}
		&\quad\ |\phi^\top \theta^* - \phi^\top \hat{\theta}_k| 
		\\
		&= 	\nbr{\phi}_{\Gamma_k^{-1}(\theta^*,\hat{\theta}_k)} \nbr{\theta^* - \hat{\theta}_k}_{\Gamma_k(\theta^*,\hat{\theta}_k)}
		\nonumber\\
		&\overset{\textup{(a)}}{\leq} \sqrt{ 1+  \frac{H r_{\max} \sqrt{|\cS| |\cA|}}{m}   + \frac{H}{m\sqrt{\lambda}} \nbr{ Z_k }_{\Gamma_k^{-1}(\theta^*,\hat{\theta}_k)} } \nbr{\phi}_{\Lambda_k^{-1}(\theta^*)} \nbr{g_k(\theta^*) - g_k(\hat{\theta}_k)}_{\Gamma_k^{-1}(\theta^*,\hat{\theta}_k)}
		\nonumber\\
		&= \sqrt{ 1+  \frac{H r_{\max} \sqrt{|\cS| |\cA|}}{m}   + \frac{H}{m\sqrt{\lambda}} \nbr{ Z_k }_{\Gamma_k^{-1}(\theta^*,\hat{\theta}_k)} } \nbr{\phi}_{\Lambda_k^{-1}(\theta^*)} \nbr{ Z_k-\lambda \theta^* }_{\Gamma_k^{-1}(\theta^*,\hat{\theta}_k)}
		\nonumber\\
		&\leq \sqrt{ 1 \!+\!  \frac{H r_{\max} \sqrt{|\cS| |\cA|}}{m} \!+\! \frac{H}{m\sqrt{\lambda}} \nbr{ Z_k }_{\Gamma_k^{-1}(\theta^*,\hat{\theta}_k)} } \nbr{\phi}_{\Lambda_k^{-1}(\theta^*)} \sbr{\nbr{ Z_k }_{\Gamma_k^{-1}(\theta^*,\hat{\theta}_k)} \!+\! r_{\max} \sqrt{\lambda |\cS| |\cA|}  }
		\nonumber\\
		&= \frac{m \sqrt{\lambda}}{H} \sqrt{ 1+  \frac{H r_{\max} \sqrt{|\cS| |\cA|}}{m}   + \frac{H}{m\sqrt{\lambda}} \nbr{ Z_k }_{\Gamma_k^{-1}(\theta^*,\hat{\theta}_k)} } \nbr{\phi}_{\Lambda_k^{-1}(\theta^*)} \cdot 
		\\
		&\quad \sbr{ \frac{H}{m \sqrt{\lambda}} \nbr{ Z_k }_{\Gamma_k^{-1}(\theta^*,\hat{\theta}_k)} + \frac{Hr_{\max}\sqrt{|\cS| |\cA|} }{m } } 
		\nonumber\\
		&\leq \frac{m \sqrt{\lambda}}{H} \sbr{ 1+  \frac{H r_{\max} \sqrt{|\cS| |\cA|}}{m}   + \frac{H}{m\sqrt{\lambda}} \nbr{ Z_k }_{\Gamma_k^{-1}(\theta^*,\hat{\theta}_k)} }^{\frac{3}{2}} \nbr{\phi}_{\Lambda_k^{-1}(\theta^*)}  
		\nonumber\\
		&\overset{\textup{(b)}}{\leq} \!\frac{m \sqrt{\alpha \lambda}}{H} \!\! \sbr{ 1 \!+\!  \frac{H r_{\max} \sqrt{|\cS| |\cA|}}{m}   \!+\! \frac{H}{m\sqrt{\lambda}} \sbr{ \sqrt{ 1 \!+\!  \frac{H r_{\max} \sqrt{|\cS| |\cA|}}{m} } \omega(k) \!+\! \frac{H}{m\sqrt{\lambda}} \omega(k)^2 } }^{\!\!\frac{3}{2}} \!\!\nbr{\phi}_{\Sigma_k^{-1}} 
		\\
		&= \sqrt{\alpha} \cdot \nu(k) \nbr{\phi}_{\Sigma_k^{-1}} ,
	\end{align*}
	where inequality (a) is due to Lemmas~\ref{lemma:two_equalities} and \ref{lemma:eff_bound_Z_k}, and inequality (b) follows from  Lemmas~\ref{lemma:transform_Lambda_Sigma} and \ref{lemma:eff_bound_Z_k}.
\end{proof}

\begin{lemma}[Gaussian Anti-Concentration] \label{lemma:Gaussian_anti_concentration}
	Assume that event $\cE$ holds. Then, for any $k>0$ and $F_{k-1}$-measurable random variable $X \in \R^{|\cS| |\cA|}$, we have
	\begin{align*}
		\Pr\mbr{ X^\top \tilde{\theta}_k > X^\top \theta^* \ |\ F_{k-1} } \geq \frac{1}{2\sqrt{2\pi e}} .
	\end{align*}
\end{lemma}
\begin{proof}
	This proof is originated from the analysis of Lemma 11 in \cite{efroni2021reinforcement}. 
	
	Using Lemma~\ref{lemma:confence_interval_proj_free}, we have that for any $k>0$,
	\begin{align*}
		|X^\top \theta^* - X^\top \hat{\theta}_{k-1}| \leq  \sqrt{\alpha} \cdot \nu(k-1) \nbr{X}_{\Sigma_{k-1}^{-1}}  .
	\end{align*}
	
	It holds that
	\begin{align*}
		&\quad\ \Pr\mbr{ X^\top \tilde{\theta}_k > X^\top \theta^* \ |\ F_{k-1} }
		\\
		&= \Pr\mbr{ \frac{X^\top \tilde{\theta}_k - X^\top \hat{\theta}_{k-1} }{ \sqrt{\alpha} \cdot \nu(k-1) \|X\|_{\Sigma_{k-1}^{-1}} } > \frac{X^\top \theta^* - X^\top \hat{\theta}_{k-1} }{ \sqrt{\alpha} \cdot \nu(k-1) \|X\|_{\Sigma_{k-1}^{-1}} } \ |\ F_{k-1} } .
	\end{align*}
	
	Here given $F_{k-1}$, $X^\top \tilde{\theta}_k - X^\top \hat{\theta}_{k-1} = X^\top \xi_k$ is a Gaussian random variable with mean $0$ and standard deviation $\sqrt{\alpha} \cdot \nu(k-1) \|X\|_{\Sigma_{k-1}^{-1}}$.
	
	Since when event $\cE$ holds,
	\begin{align*}
		\frac{X^\top \theta^* - X^\top \hat{\theta}_{k-1}}{ \sqrt{\alpha} \cdot \nu(k-1) \|X\|_{\Sigma_{k-1}^{-1}} }  \leq \frac{ \sqrt{\alpha} \cdot \nu(k-1) \|X\|_{\Sigma_{k-1}^{-1}} }{ \sqrt{\alpha} \cdot \nu(k-1) \|X\|_{\Sigma_{k-1}^{-1}} } =1 ,
	\end{align*}
	we have
	\begin{align*}
		\Pr\mbr{ X^\top \tilde{\theta}_k > X^\top \theta^* \ |\ F_{k-1} }
		&\geq \Pr\mbr{ \frac{X^\top \tilde{\theta}_k - X^\top \hat{\theta}_{k-1}}{ \sqrt{\alpha} \cdot \nu(k-1) \|X\|_{\Sigma_{k-1}^{-1}} } > 1 \ |\ F_{k-1} }
		\\
		&= \Pr\mbr{ \frac{ X^\top \xi_k }{ \sqrt{\alpha} \cdot \nu(k-1) \|X\|_{\Sigma_{k-1}^{-1}} } > 1 \ |\ F_{k-1} }
		\\
		&\overset{\textup{(a)}}{\geq} \frac{1}{2\sqrt{2\pi e}} ,
	\end{align*}
	where inequality (a) comes from that if $Z \sim \cF^{\bi}_{\textup{UTran}}(0,1)$,  $\Pr[Z>z]\geq \frac{1}{\sqrt{2\pi}} \cdot \frac{z}{1+z^2} e^{-\frac{z^2}{2}}$~\cite{borjesson1979simple}.
\end{proof}


\begin{lemma} \label{lemma:xi_xi'}
	Let $\xi_k,\xi'_k \in \R^{|\cS||\cA|}$ be i.i.d. random variables given $F_{k-1}$. Let $\tilde{p}$ be a $F_{k-1}$-measurable transition model, and $x_{k-1} \in \R^{|\cS||\cA|}$ be  a $F_{k-1}$-measurable random variable. For any policy $\pi$, denote the visitation indicator under policy $\pi$ on MDP $\tilde{p}$ by $\tilde{\phi}^{\pi}$. Let $\tilde{\pi}^k:= \argmax_{\pi} (\tilde{\phi}^{\pi})^\top (x_{k-1} + \xi_k)$. Then, we have
	\begin{align*}
		& \ex\mbr{ \sbr{ (\tilde{\phi}^{\tilde{\pi}^k})^\top \sbr{ x_{k-1} + \xi_k } - \ex\mbr{ (\tilde{\phi}^{\tilde{\pi}^k})^\top \sbr{ x_{k-1} + \xi_k } \ |\ F_{k-1}  } }^{+} \ \Big|\ F_{k-1} }
		\\
		&\leq \ex\mbr{ | (\tilde{\phi}^{\tilde{\pi}^k})^\top \xi_k | + | (\tilde{\phi}^{\tilde{\pi}^k})^\top \xi'_k| \ \Big|\ F_{k-1} } .
	\end{align*}
\end{lemma}
\begin{proof}
	This proof is originated from Lemma 12 in \cite{efroni2021reinforcement}.
	
	First, using the definition of $\tilde{\pi}^k$ and the fact that $\xi_k$ and $\xi'_k$ follow the same distribution, we have
	\begin{align}
		\ex\mbr{ (\tilde{\phi}^{\tilde{\pi}^k})^\top \sbr{ x_{k-1} + \xi_k } \ |\ F_{k-1}  } = \ex\mbr{ \max_{\pi} (\tilde{\phi}^{\pi})^\top \sbr{ x_{k-1} + \xi'_k } \ |\ F_{k-1}  } . \label{eq:connect_xi_xi'}
	\end{align}
	
	Then, since given $F_{k-1}$, $\xi_k$ and $\xi'_k$ are independent, we have
	\begin{align}
		\ex\mbr{ \max_{\pi} (\tilde{\phi}^{\pi})^\top \sbr{ x_{k-1} + \xi'_k } \ |\ F_{k-1}  } &= \ex\mbr{ \max_{\pi} (\tilde{\phi}^{\pi})^\top \sbr{ x_{k-1} + \xi'_k } \ |\ F_{k-1} , \xi_k, \tilde{\pi}_k }
		\nonumber\\
		&\geq \ex\mbr{ (\phi^{\tilde{\pi}_k})^\top \sbr{ x_{k-1} + \xi'_k } \ |\ F_{k-1}, \xi_k, \tilde{\pi}_k  } . \label{eq:relax_max_xi'}
	\end{align}
	
	Hence, combining Eqs.~\eqref{eq:connect_xi_xi'} and \eqref{eq:relax_max_xi'}, we have
	\begin{align*}
		&\quad\ \ex\mbr{ \sbr{(\phi^{\tilde{\pi}_k})^\top \sbr{ x_{k-1} + \xi_k } - \ex\mbr{ (\phi^{\tilde{\pi}_k})^\top \sbr{ x_{k-1} + \xi_k } \ |\ F_{k-1}  } }^{+} \ \Big|\ F_{k-1} }
		\\
		&\leq \ex\mbr{ \sbr{ (\phi^{\tilde{\pi}_k})^\top \sbr{ x_{k-1} + \xi_k }  - \ex\mbr{ (\phi^{\tilde{\pi}_k})^\top \sbr{ x_{k-1} + \xi'_k } \ |\ F_{k-1} , \xi_k, \tilde{\pi}_k  } }^{+} \ \Big|\ F_{k-1} } 
		\\
		&= \ex\mbr{ \sbr{ \ex\mbr{ (\phi^{\tilde{\pi}_k})^\top \sbr{ x_{k-1} + \xi_k }  -  (\phi^{\tilde{\pi}_k})^\top \sbr{ x_{k-1} + \xi'_k } \ |\ F_{k-1} , \xi_k, \tilde{\pi}_k  } }^{+} \ \Big|\ F_{k-1} } 
		\\
		&= \ex\mbr{ \sbr{ \ex\mbr{ (\phi^{\tilde{\pi}_k})^\top \xi_k   -  (\phi^{\tilde{\pi}_k})^\top \xi'_k \ |\ F_{k-1} , \xi_k, \tilde{\pi}_k  } }^{+} \ \Big|\ F_{k-1} }
		\\
		&\leq \ex\mbr{ \abr{ \ex\mbr{ (\phi^{\tilde{\pi}_k})^\top \xi_k   -  (\phi^{\tilde{\pi}_k})^\top \xi'_k \ |\ F_{k-1} , \xi_k, \tilde{\pi}_k  } } \ \Big|\ F_{k-1} }
		\\
		&\leq \ex\mbr{  \ex\mbr{ |(\phi^{\tilde{\pi}_k})^\top \xi_k   -  (\phi^{\tilde{\pi}_k})^\top \xi'_k| \ |\ F_{k-1} , \xi_k, \tilde{\pi}_k   } \ \Big|\ F_{k-1} }
		\\
		&= \ex\mbr{   | (\phi^{\tilde{\pi}_k})^\top \xi_k   -  (\phi^{\tilde{\pi}_k})^\top \xi'_k | \ \Big|\ F_{k-1} }
		\\
		&\leq \ex\mbr{   |(\phi^{\tilde{\pi}_k})^\top \xi_k| \ \Big|\ F_{k-1} } + \ex\mbr{   |  (\phi^{\tilde{\pi}_k})^\top \xi'_k| \ \Big|\ F_{k-1} } .
	\end{align*}
	
\end{proof}

For any $k>0$ and $\delta_k \in (0,1)$, define event
\begin{align*}
	\cM_k(\delta_k):=\lbr{ \forall \phi \in \R^{|\cS||\cA|} :\  |\phi^\top \xi_k| \leq \sqrt{\alpha} \cdot \nu(k-1) \sbr{ \sqrt{|\cS||\cA|} + 2 \sqrt{\log\sbr{\frac{1}{\delta_k}}} } \nbr{\phi}_{\Sigma_{k-1}^{-1}} } .
\end{align*}

\begin{lemma} \label{lemma:X_top_xi_k}
	For any $k>0$ and $\delta_k \in (0,1)$, we have
	\begin{align*}
		\Pr\mbr{ \cM_k(\delta_k) \ |\ F_{k-1} } \geq 1 - \delta_k .
	\end{align*}
	
	In addition, for a random variable $X \in \R^{|\cS| |\cA|}$ such that $\|X\|_{\Sigma_{k-1}^{-1}} \leq L_{X}$, we have
	\begin{align*}
		\ex\mbr{|X^\top \xi_k| \ | F_{k-1}} 
		&\leq \sqrt{\alpha} \cdot \nu(k-1) \sbr{ \sqrt{|\cS||\cA|} + 2 \sqrt{\log\sbr{\frac{1}{\delta_k}}} } \ex\mbr{ \nbr{X}_{\Sigma_{k-1}^{-1}} \ | F_{k-1}} 
		\\
		&\quad + \sqrt{\alpha} \cdot \nu(k-1) \cdot L_{X} \sqrt{ |\cS| |\cA| \delta_k } .
	\end{align*}
\end{lemma}
\begin{proof}
	This proof is similar to the analysis of Lemma 13 in \cite{efroni2021reinforcement}.
	
	First, we prove the first statement.
	
	For any $\phi \in \R^{|\cS||\cA|}$, we have
	\begin{align}
		|\phi^\top \xi_k| &= |\phi^\top \Sigma_{k-1}^{-\frac{1}{2}} \Sigma_{k-1}^{\frac{1}{2}} \xi_k|
		\nonumber\\
		&\leq \nbr{ \Sigma_{k-1}^{-\frac{1}{2}} \phi}_2 \nbr{\Sigma_{k-1}^{\frac{1}{2}} \xi_k}_2
		\nonumber\\
		&= \sqrt{\alpha} \cdot \nu(k-1) \nbr{\phi}_{\Sigma_{k-1}^{-1}} \nbr{\frac{1}{\sqrt{\alpha} \cdot \nu(k-1)} \Sigma_{k-1}^{\frac{1}{2}} \xi_k}_2 . \label{eq:known_tran_phi_xi_decomposition}
	\end{align}
	
	Since given $F_{k-1}$, $\frac{1}{\sqrt{\alpha} \cdot \nu(k-1)} \Sigma_{k-1}^{\frac{1}{2}} \xi_k \in \R^{|\cS| |\cA|}$ is a vector with each entry being a standard Gaussian random variable, we have that $\|\frac{1}{\sqrt{\alpha} \cdot \nu(k-1)} \Sigma_{k-1}^{\frac{1}{2}} \xi_k\|_2$ is chi-distributed with parameter $|\cS| |\cA|$. 
	
	Then, using Lemma 1 in \cite{laurent2000adaptive}, we have that with probability at least $1-\delta_k$,
	\begin{align*}
		\nbr{\frac{1}{\sqrt{\alpha} \cdot \nu(k-1)} \Sigma_{k-1}^{\frac{1}{2}} \xi_k}_2 &\leq \sqrt{|\cS| |\cA| + 2\sqrt{|\cS| |\cA| \log\sbr{\frac{1}{\delta_k}}} + 2 \log\sbr{\frac{1}{\delta_k}} }
		\\
		&= \sqrt{ \sbr{ \sqrt{|\cS| |\cA|} + \sqrt{\log\sbr{\frac{1}{\delta_k}}} }^2 +  \log\sbr{\frac{1}{\delta_k}} } 
		\\
		&\leq \sqrt{|\cS| |\cA|} + 2 \sqrt{\log\sbr{\frac{1}{\delta_k}}} .
	\end{align*}
	
	Next, we prove the second statement.
	
	For a random variable $X \in \R^{|\cS| |\cA|}$, we have
	\begin{align*}
		\ex\mbr{|X^\top \xi_k| \ | F_{k-1}} &= \Pr\mbr{ \cM_k(\delta_k) } \cdot \ex\mbr{|X^\top \xi_k| \ | F_{k-1}, \cM_k(\delta_k)} \\& \quad + \Pr\mbr{ \bar{\cM}_k(\delta_k) } \cdot  \ex\mbr{|X^\top \xi_k| \ | F_{k-1}, \bar{\cM}_k(\delta_k) }
		\\
		&\leq \sqrt{\alpha} \cdot \nu(k-1) \sbr{ \sqrt{|\cS||\cA|} + 2 \sqrt{\log\sbr{\frac{1}{\delta_k}}} } \ex\mbr{ \nbr{X}_{\Sigma_{k-1}^{-1}} \ | F_{k-1}} 
		\\
		&\quad + \sqrt{\Pr\mbr{ \bar{\cM}_k(\delta_k) } \cdot  \ex\mbr{|X^\top \xi_k|^2 \ | F_{k-1}, \bar{\cM}_k(\delta_k)} }
		\\
		&\overset{\textup{(a)}}{\leq} \sqrt{\alpha} \cdot \nu(k-1) \sbr{ \sqrt{|\cS||\cA|} + 2 \sqrt{\log\sbr{\frac{1}{\delta_k}}} } \ex\mbr{ \nbr{X}_{\Sigma_{k-1}^{-1}} \ | F_{k-1}} 
		\\
		&\quad + \sqrt{\alpha} \cdot \nu(k-1) \sqrt{ \delta_k  \ex\mbr{ \nbr{X}^2_{\Sigma_{k-1}^{-1}} \cdot \nbr{\frac{1}{\sqrt{\alpha} \cdot \nu(k-1)} \Sigma_{k-1}^{\frac{1}{2}} \xi_k}_2^2 \ | F_{k-1}}  }
				\\
		&\leq \sqrt{\alpha} \cdot \nu(k-1) \sbr{ \sqrt{|\cS||\cA|} + 2 \sqrt{\log\sbr{\frac{1}{\delta_k}}} } \ex\mbr{ \nbr{X}_{\Sigma_{k-1}^{-1}} \ | F_{k-1}} 
		\\
		&\quad + \sqrt{\alpha} \cdot \nu(k-1) \sqrt{ \delta_k L_{X}^2 \ex\mbr{  \nbr{\frac{1}{\sqrt{\alpha} \cdot \nu(k-1)} \Sigma_{k-1}^{\frac{1}{2}} \xi_k}_2^2 \ | F_{k-1}}  }
		\\
		&\overset{\textup{(b)}}{\leq} \sqrt{\alpha} \cdot \nu(k-1) \sbr{ \sqrt{|\cS||\cA|} + 2 \sqrt{\log\sbr{\frac{1}{\delta_k}}} } \ex\mbr{ \nbr{X}_{\Sigma_{k-1}^{-1}} \ | F_{k-1}} 
		\\
		&\quad + \sqrt{\alpha} \cdot \nu(k-1) \cdot L_{X} \sqrt{ |\cS| |\cA| \delta_k }  .
	\end{align*}
	Here inequality (a) follows from the Cauchy-Schwarz inequality. Inequality (b) is due to the fact that given $F_{k-1}$, $\|\frac{1}{\sqrt{\alpha} \cdot \nu(k-1)} \Sigma_{k-1}^{\frac{1}{2}} \xi_k\|_2$ is chi-distributed with parameter $|\cS| |\cA|$, and then $\ex[ \|\frac{1}{\sqrt{\alpha} \cdot \nu(k-1)} \Sigma_{k-1}^{\frac{1}{2}} \xi_k\|_2^2 \ | F_{k-1}] = |\cS| |\cA|$.
\end{proof}

Define event 
\begin{align}
	\cF^{\bi}_{\textup{KTran}}:=\Bigg\{& \abr{\sum_{k'=1}^{k} \sbr{ \ex_{\tau \sim \pi^{k'}}\mbr{ \nbr{ \phi^{\tau}}_{(\Sigma_{k'-1})^{-1}} | F_{k'-1}} - \nbr{ \phi^{\tau}}_{(\Sigma_{k'-1})^{-1}} } } \leq 4H\sqrt{ \frac{k}{\alpha \lambda} \log\sbr{\frac{4k}{\delta'}} } ,
	\nonumber\\
	&\abr{\sum_{k'=1}^{k} \sbr{ \ex\mbr{ (\phi^{\pi^{k'}})^\top \theta^* | F_{k'-1} } - (\phi^{\pi^{k'}})^\top \theta^* }} \leq 4 H r_{\max} \sqrt{ k \log\sbr{\frac{4k}{\delta'}} } ,\ \forall k>0 \Bigg\} .
\end{align}

\begin{lemma} \label{lemma:cF_binary}
	It holds that
	\begin{align*}
		\Pr \mbr{ \cF^{\bi}_{\textup{KTran}} } \geq 1-2\delta' .
	\end{align*}
\end{lemma}
\begin{proof}
	We prove the first inequality as follows.
	
	For any $k'\geq 1$, we have that $\nbr{ \phi^{\tau}}_{(\Sigma_{k'-1})^{-1}} \leq \frac{H}{\sqrt{\alpha \lambda}}$, and then $|\ex_{\tau \sim \pi^{k'}} [\nbr{ \phi^{\tau}}_{(\Sigma_{k'-1})^{-1}} | F_{k'-1}] - \nbr{ \phi^{\tau}}_{(\Sigma_{k'-1})^{-1}}| \leq \frac{2H}{\sqrt{\alpha \lambda}}$. 
	
	
	Using the Azuma-Hoeffding inequality, we have that for any fixed $k>0$, with probability at least $1-\frac{\delta'}{2k^2}$,
	\begin{align*}
		\abr{\sum_{k'=1}^{k} \sbr{ \ex_{\tau \sim \pi^{k'}}\mbr{ \nbr{ \phi^{\tau}}_{(\Sigma_{k'-1})^{-1}} | F_{k'-1}} - \nbr{ \phi^{\tau}}_{(\Sigma_{k'-1})^{-1}} } } &\leq \sqrt{ 2 \cdot \frac{4H^2}{\alpha \lambda} \cdot k \log\sbr{\frac{4k^2}{\delta'}} } .
	\end{align*}
	
	Since $\sum_{k=1}^{\infty} \frac{\delta'}{2k^2} \leq \delta'$, by a union bound over $k$, we have that with probability at least $\delta'$, for any $k\geq 1$,
	\begin{align*}
		\abr{\sum_{k'=1}^{k} \sbr{ \ex_{\tau \sim \pi^{k'}}\mbr{ \nbr{ \phi^{\tau}}_{(\Sigma_{k'-1})^{-1}} | F_{k'-1}} - \nbr{ \phi^{\tau}}_{(\Sigma_{k'-1})^{-1}} } } &\leq \sqrt{ 2 \cdot \frac{4H^2}{\alpha \lambda} \cdot k \log\sbr{\frac{4k^2}{\delta'}} } 
		\\
		&\leq 4H \sqrt{ \frac{k}{\alpha \lambda} \log\sbr{\frac{4k}{\delta'}} } .
	\end{align*}
	The second inequality can be obtained by a similar argument and the fact that $|(\phi^{\pi^{k}})^\top \theta^*| \leq Hr_{\max}$ for any $k>0$.
\end{proof}

\begin{lemma} \label{lemma:sum_phi_seg_binary}
	For any $K\geq 1$, we have
	\begin{align*}
		\sum_{k=1}^{K} \sum_{i=1}^{m} \nbr{ \phi^{\tau^k_i}}_{(\Sigma_{k-1})^{-1}} \leq \sqrt{ 2Km |\cS| |\cA| \cdot \max\lbr{ \frac{H^2}{m \alpha \lambda}, 1} \cdot \log \sbr{ 1+ \frac{  KH^2 }{ \alpha \lambda |\cS| |\cA| m } } } .
	\end{align*}
\end{lemma}
\begin{proof}		
	We have
	\begin{align}
		\sum_{k=1}^{K} \sum_{i=1}^{m} \nbr{ \phi^{\tau^k_i}}_{(\Sigma_{k-1})^{-1}} &\leq \sqrt{ Km   \sum_{k=1}^{K} \sum_{i=1}^{m} \nbr{ \phi^{\tau^k_i}}_{(\Sigma_{k-1})^{-1}}^2 }
		\nonumber\\
		&\overset{\textup{(a)}}{\leq} \sqrt{ 2Km \cdot \max\lbr{ \frac{H^2}{m \alpha \lambda}, 1} \cdot \sum_{k=1}^{K} \log \sbr{ 1+ \sum_{i=1}^{m} \nbr{ \phi^{\tau^k_i}}_{(\Sigma_{k-1})^{-1}}^2} }
		\nonumber\\ 
		&= \sqrt{ 2Km \cdot \max\lbr{ \frac{H^2}{m \alpha \lambda}, 1} \cdot \log \sbr{ \frac{\det(\Sigma_K)}{\det(\alpha \lambda I)} } } 
		\nonumber\\
		&\leq \sqrt{ 2Km |\cS| |\cA| \cdot \max\lbr{ \frac{H^2}{m \alpha \lambda}, 1} \cdot \log \sbr{ 1+ \frac{  KH^2 }{ \alpha \lambda |\cS| |\cA| m } } } , \label{eq:sum_indicator_derivation}
	\end{align}
	where inequality (a) is due to that for any $x \in [0,c]$ with constant $c\geq0$, it holds that $x \leq 2 \max\{c,1\} \cdot \log(1+x)$.
\end{proof}


\begin{proof}[Proof of Theorem~\ref{thm:ub_bits}]
	Letting $\delta'=\frac{\delta}{3}$, we have $\Pr[\cE \cap \cF^{\bi}_{\textup{KTran}}] \leq 1-\delta$. Then, to prove this theorem, it suffices to prove
	the regret bound when event $\cE \cap \cF^{\bi}_{\textup{KTran}}$ holds.
	
	Assume that event $\cE \cap \cF^{\bi}_{\textup{KTran}}$ holds. Then, we have
	\begin{align}
		\cR(K) &= \sum_{k=1}^{K} \sbr{ (\phi^{\pi^*})^\top \theta^* - (\phi^{\pi^k})^\top \theta^* }
		\nonumber\\
		&= \sum_{k=1}^{K} \sbr{ \ex\mbr{ (\phi^{\pi^*})^\top \theta^* - (\phi^{\pi^k})^\top \theta^* | F_{k-1} } + \ex\mbr{ (\phi^{\pi^k})^\top \theta^* | F_{k-1} } - (\phi^{\pi^k})^\top \theta^* } 
		\nonumber\\
		&\leq \sum_{k=1}^{K} \sbr{ \ex\mbr{ (\phi^{\pi^*})^\top \theta^* - (\phi^{\pi^k})^\top \theta^* | F_{k-1} } } + 4 H r_{\max} \sqrt{ K \log\sbr{\frac{4K}{\delta'}} } . \label{eq:known_tran_regret_decomposition}
	\end{align}
	
	
	For the first term, we have
	\begin{align}
		&\sum_{k=1}^{K} \ex\mbr{ (\phi^{\pi^*})^\top \theta^* - (\phi^{\pi^k})^\top \theta^* | F_{k-1} } \nonumber\\
		&= \sum_{k=1}^{K} \sbr{ \ex\mbr{ (\phi^{\pi^*})^\top \theta^* - (\phi^{\pi^k})^\top \tilde{\theta}_k | F_{k-1} } + \ex\mbr{ (\phi^{\pi^k})^\top \tilde{\theta}_k - (\phi^{\pi^k})^\top \theta^* | F_{k-1} } } . \label{eq:known_tran_ex_phi_star-phi_pi_k_theta}
	\end{align}
	
	In the following, we prove
	\begin{align}
		\ex\mbr{ (\phi^{\pi^*})^{\!\top} \theta^* \!-\! (\phi^{\pi^k})^{\!\top} \tilde{\theta}_k | F_{k-1} } \!\leq\! 2\sqrt{2\pi e} \cdot \ex\mbr{ \sbr{ (\phi^{\pi^k})^{\!\top} \tilde{\theta}_k  \!-\! \ex\mbr{ (\phi^{\pi^k})^{\!\top} \tilde{\theta}_k  | F_{k-1} } }^{\!+} | F_{k-1} } . \label{eq:known_tran_fist_term_leq_positive}
	\end{align}
	
	If $\ex[ (\phi^{\pi^*})^\top \theta^* - (\phi^{\pi^k})^\top \tilde{\theta}_k | F_{k-1} ]<0$, then Eq.~\eqref{eq:known_tran_fist_term_leq_positive} trivially holds. 
	
	Otherwise, letting $z:= \ex[ (\phi^{\pi^*})^\top \theta^* - (\phi^{\pi^k})^\top \tilde{\theta}_k | F_{k-1} ]$, we have
	\begin{align*}
		&\quad\ \ex\mbr{ \sbr{ (\phi^{\pi^k})^\top \tilde{\theta}_k  - \ex\mbr{ (\phi^{\pi^k})^\top \tilde{\theta}_k  | F_{k-1} } }^{+} | F_{k-1} }
		\\
		&\geq z \Pr\mbr{  (\phi^{\pi^k})^\top \tilde{\theta}_k  - \ex\mbr{ (\phi^{\pi^k})^\top \tilde{\theta}_k   | F_{k-1} } \geq z | F_{k-1} }
		\\
		&\geq \sbr{\ex\mbr{ (\phi^{\pi^*})^\top \theta^* - (\phi^{\pi^k})^\top \tilde{\theta}_k | F_{k-1} } } \cdot \Pr\mbr{  (\phi^{\pi^k})^\top \tilde{\theta}_k   \geq (\phi^{\pi^*})^\top \theta^* | F_{k-1} }
		\\
		&\overset{\textup{(a)}}{\geq} \sbr{\ex\mbr{ (\phi^{\pi^*})^\top \theta^* - (\phi^{\pi^k})^\top \tilde{\theta}_k | F_{k-1} } } \cdot \Pr\mbr{  (\phi^{\pi^*})^\top \tilde{\theta}_k   \geq (\phi^{\pi^*})^\top \theta^* | F_{k-1} }
		\\
		&\overset{\textup{(b)}}{\geq} \sbr{\ex\mbr{ (\phi^{\pi^*})^\top \theta^* - (\phi^{\pi^k})^\top \tilde{\theta}_k | F_{k-1} } } \cdot \frac{1}{2\sqrt{2\pi e}} ,
	\end{align*}
	where inequality (a) uses the definition of $\pi^k$, and inequality (b) follows from Lemma~\ref{lemma:Gaussian_anti_concentration}. Thus, we complete the proof of Eq.~\eqref{eq:known_tran_fist_term_leq_positive}.
	
	Let $\xi'_k \in \R^{|\cS||\cA|}$ be a random variable that is i.i.d. with $\xi$ given $F_{k-1}$.
	Then, using Lemma~\ref{lemma:xi_xi'} with $p'=p$, $x_{k-1}=\hat{\theta}_{k-1}$ and $\tilde{\pi}^k=\pi^k$, we have
	\begin{align*}
		\ex\mbr{ (\phi^{\pi^*})^\top \theta^* - (\phi^{\pi^k})^\top \tilde{\theta}_k | F_{k-1} } &\leq 2\sqrt{2\pi e} \cdot \ex\mbr{ \sbr{ (\phi^{\pi^k})^\top \tilde{\theta}_k  - \ex\mbr{ (\phi^{\pi^k})^\top \tilde{\theta}_k  | F_{k-1} } }^{+} | F_{k-1} } 
		\\
		&\leq 2\sqrt{2\pi e} \cdot \ex\mbr{ | \phi(\pi^k)^\top \xi_k | + | \phi(\pi^k)^\top \xi'_k| \ | F_{k-1} } .
	\end{align*}
	
	Plugging the above inequality into Eq.~\eqref{eq:known_tran_ex_phi_star-phi_pi_k_theta} and using Lemma~\ref{lemma:X_top_xi_k} with $\delta_k=\frac{1}{k^4}$ and $L_{X}=\frac{H}{\sqrt{\alpha \lambda}}$, we have
	\begin{align}
		&\quad \sum_{k=1}^{K} \ex\mbr{ (\phi^{\pi^*})^\top \theta^* - (\phi^{\pi^k})^\top \theta^* | F_{k-1} } 
		\nonumber\\
		&= \!\sum_{k=1}^{K}\! \bigg(\! 2\sqrt{2\pi e}\   \ex\mbr{ | (\phi^{\pi^k})^\top \xi_k | \!+\! | (\phi^{\pi^k})^\top \xi'_k| \ | F_{k-1} } \!+\! \ex\mbr{ (\phi^{\pi^k})^\top \sbr{\hat{\theta}_{k-1} \!+\! \xi_k} \!-\! (\phi^{\pi^k})^\top \theta^* | F_{k-1} } \!\bigg)
		\nonumber\\
		&= \sum_{k=1}^{K} \bigg( \sbr{2\sqrt{2\pi e} + 1} \cdot \ex\mbr{ | (\phi^{\pi^k})^\top \xi_k | \ | F_{k-1}} + 2\sqrt{2\pi e} \cdot \ex\mbr{ | (\phi^{\pi^k})^\top \xi'_k| \ | F_{k-1} } 
		\nonumber\\
		&\quad + \ex\mbr{ (\phi^{\pi^k})^\top \hat{\theta}_{k-1} - (\phi^{\pi^k})^\top \theta^* | F_{k-1} } \bigg)
		\nonumber\\
		&\overset{\textup{(a)}}{\leq} \sum_{k=1}^{K} \Bigg( \sbr{4\sqrt{2\pi e} + 2} \sqrt{\alpha} \cdot \nu(k-1) \sbr{ \sqrt{|\cS||\cA|} + 4 \sqrt{\log\sbr{k}} } \cdot \ex\mbr{ \nbr{ \phi^{\pi^k} }_{\Sigma_{k-1}^{-1}} \ | F_{k-1}} 
		\nonumber\\
		&\quad + \sbr{4\sqrt{2\pi e} + 1} \sqrt{\alpha} \cdot \nu(k-1)  \frac{\sqrt{|\cS| |\cA|}}{k^2}  \cdot \frac{H}{\sqrt{\alpha \lambda}} \Bigg) , \label{eq:ex_phi_star_theta_star-phi_k_theta_star}
	\end{align}
	where inequality (a) uses Lemmas~\ref{lemma:confence_interval_proj_free} and \ref{lemma:X_top_xi_k}.
	
	Here according to the definition of event $\cF^{\bi}_{\textup{KTran}}$ and Lemma~\ref{lemma:sum_phi_seg_binary}, we have
	\begin{align}
		\sum_{k=1}^{K} \ex\mbr{ \nbr{ \phi^{\pi^k} }_{\Sigma_{k-1}^{-1}} \ | F_{k-1}} &= \sum_{k=1}^{K} \sbr{\ex\mbr{ \nbr{ \phi^{\pi^k} }_{\Sigma_{k-1}^{-1}} \ | F_{k-1}} - \nbr{ \phi^{\pi^k} }_{\Sigma_{k-1}^{-1}} } + \sum_{k=1}^{K}  \nbr{ \phi^{\pi^k} }_{\Sigma_{k-1}^{-1}}
		\nonumber\\
		&\leq 4H\sqrt{ \frac{K}{\alpha \lambda} \log\sbr{\frac{4K}{\delta'}} } 
		\nonumber\\
		&\quad + \sqrt{ 2Km |\cS| |\cA| \cdot \max\lbr{ \frac{H^2}{m \alpha \lambda}, 1} \cdot \log \sbr{ 1+ \frac{  KH^2 }{ \alpha \lambda |\cS| |\cA| m } } } . \label{eq:ex_sum_phi_seg}
	\end{align}
	
	
	Therefore, plugging the above two equations into Eq.~\eqref{eq:known_tran_regret_decomposition}, we have
	\begin{align*}
		\cR(K) &\leq \sbr{4\sqrt{2\pi e} + 2} \sqrt{\alpha} \cdot \nu(K) \sbr{ \sqrt{|\cS||\cA|} + 4 \sqrt{\log\sbr{K}} } \cdot 
		\\
		&\quad \sbr{ 4H\sqrt{ \frac{K}{\alpha \lambda} \log\sbr{\frac{4K}{\delta'}} } + \sqrt{ 2Km |\cS| |\cA|  \max\lbr{ \frac{H^2}{m \alpha \lambda}, 1}  \log \sbr{ 1+ \frac{  KH^2 }{ \alpha \lambda |\cS| |\cA| m } } }  } 
		\\
		&\quad + 2 \sbr{4\sqrt{2\pi e} + 1} H \cdot \nu(K)  \sqrt{ \frac{|\cS| |\cA|}{\lambda} }  + 4 H r_{\max} \sqrt{ K \log\sbr{\frac{4K}{\delta'}} } 
		\\
		&\overset{\textup{(a)}}{=} \tilde{O} \Bigg( \exp(\frac{Hr_{\max}}{2m}) \cdot \nu(K) \sqrt{|\cS||\cA|} \sbr{ \sqrt{ Km |\cS| |\cA| \cdot \max\lbr{ \frac{H^2}{m \alpha \lambda}, 1}  } + H\sqrt{ \frac{K}{\alpha \lambda} }  }
		\Bigg) ,
	\end{align*}
	where in equality (a), the last two terms are absorbed into $\tilde{O}(\cdot)$.
\end{proof}

\subsection{Proof for the Regret Lower Bound with Known Transition} \label{apx:lb_bi_known_tran}

In the following, we prove the regret lower bound (Theorem~\ref{thm:lb_bi_known_tran}) for RL with binary segment feedback and known transition.
	
\begin{proof}[Proof of Theorem~\ref{thm:lb_bi_known_tran}]
	\begin{figure}[t]
		\centering   
		\includegraphics[width=0.8\textwidth]{fig/lower_bound_binary_crop.pdf}
		\caption{Instance for the lower bound under binary segment feedback and known transition.
		} \label{fig:lower_bound_binary}
	\end{figure}
	
	We construct a random instance $\cI$ as follows. As shown in Figure~\ref{fig:lower_bound_binary}, there are $n$ bandit states $s_1,\dots,s_n$ (i.e., there is an optimal action and multiple suboptimal actions), a good absorbing state $s_{n+1}$ and a bad absorbing state $s_{n+2}$. 
	The agent starts from $s_1,\dots,s_n$ with equal probability $\frac{1}{n}$. 
	For any $i \in [n]$, in state $s_i$, one action $a_J$ is uniformly chosen from $\cA$ as the optimal action.
	In state $s_i$, under the optimal action $a_J$, the agent transitions to $s_{n+1}$ deterministically, and $r(s_i,a_J)=r_{\max}$; Under any suboptimal action $a \in \cA \setminus \{s_J\}$, the agent transitions to $s_{n+2}$ deterministically, and $r(s_i,a)=(1-\varepsilon)r_{\max}$, where $\varepsilon \in (0,\frac{1}{2})$ is a parameter specified later. 
	For all actions $a \in \cA$, $r(s_{n+1},a)=r_{\max}$ and $r(s_{n+2},a)=(1-\varepsilon)r_{\max}$.
	
	
	In this proof, we will also use an alternative uniform instance $\cI_{\unif}$. The only difference between $\cI_{\unif}$ and $\cI$ is that for any $i \in [n]$, in state $s_i$, under all actions $a \in \cA$, the agent transitions to $s_{n+2}$ deterministically, and $r(s_i,a)=(1-\varepsilon)r_{\max}$.
	
	Fix an algorithm $\A$.
	Let $\ex_{\unif}[\cdot]$ denote the expectation with respect to $\cI_{\unif}$. Let $\ex_*[\cdot]$ denote the expectation with respect to $\cI$. For any $i \in [n]$ and $j \in [|\cA|]$, let $\ex_{i,j}[\cdot]$ denote the expectation with respect to the case where $a_j$ is the optimal action in state $s_i$, and  $N_{i,j}$ denote the number of episodes where algorithm $\A$ chooses $a_j$ in state $s_i$, i.e., $N_{i,j}=\sum_{k=1}^{K} \indicator\{\pi^k_1(s_i)=a_j\}$. 
	
	The KL divergence of binary observations if taking $a_J$ in $s_i$ in each episode between $\cI_{\unif}$ and $\cI$ is
	\begin{align*}
		& \quad \sum_{i=1}^{m} \kl \sbr{ \bernoulli\sbr{ \mu\sbr{(1-\varepsilon) r_{\max} \cdot \frac{H}{m}} } \Big\| \bernoulli\sbr{ \mu\sbr{ r_{\max} \cdot \frac{H}{m}} } } 
		\\
		&\overset{\textup{(a)}}{\leq} m \cdot \frac{ \sbr{ \mu\sbr{(1-\varepsilon) r_{\max} \cdot \frac{H}{m}} - \mu\sbr{ r_{\max} \cdot \frac{H}{m}} }^2 }{ \mu'\sbr{ r_{\max} \cdot \frac{H}{m}} }
		\\
		&\overset{\textup{(b)}}{\leq} m \cdot \frac{ \mu'\sbr{ (1-\varepsilon) \frac{Hr_{\max}}{m} }^2 \sbr{\varepsilon \cdot \frac{Hr_{\max}}{m}}^2  }{ \mu'\sbr{ \frac{Hr_{\max}}{m} } } ,
	\end{align*}
	where inequality (a) uses the fact that $\kl(\bernoulli(p) \| \bernoulli(q)) \leq \frac{(p-q)^2}{q(1-q)}$, and inequality (b) is due to that $\mu'(x)$ is monotonically decreasing when $x > 0$.  
	
	In addition, the agent has probability only $\frac{1}{n}$ to arrive at (observe) state $s_i$.
	
	Thus, using Lemma A.1 in \cite{auer2002nonstochastic}, we have that for any $i \in [n]$, in state $s_i$,
	\begin{align*}
		\ex_{i,j}[N_{i,j}] &\leq  \ex_{\unif}[N_{i,j}] + \frac{K}{2} \sqrt{ \frac{1}{n} \cdot \ex_{\unif}[N_{i,j}] \cdot m \cdot \frac{ \mu'\sbr{ (1-\varepsilon) \frac{Hr_{\max}}{m} }^2 \sbr{\varepsilon \cdot \frac{Hr_{\max}}{m}}^2  }{ \mu'\sbr{ \frac{Hr_{\max}}{m} } } } 
		\\
		&=  \ex_{\unif}[N_{i,j}] + \frac{K}{2} \cdot \varepsilon \cdot \frac{Hr_{\max}}{m} \sqrt{ \frac{m}{n} \cdot \ex_{\unif}[N_{i,j}] \cdot \frac{ \mu'\sbr{ (1-\varepsilon) \frac{Hr_{\max}}{m} }^2 }{ \mu'\sbr{ \frac{Hr_{\max}}{m} } } } .
	\end{align*}
	
	Summing over $j \in [|\cA|]$, using the Cauchy-Schwarz inequality and the fact that $\sum_{j=1}^{|\cA|} \ex_{\unif}[N_{i,j}]=K$, we have
	\begin{align*}
		\sum_{j=1}^{|\cA|}  \ex_{i,j}[N_{i,j}] &\leq K + \frac{K Hr_{\max} \varepsilon}{2} \sqrt{ \frac{|\cA|  K}{m n} \cdot \frac{ \mu'\sbr{ (1-\varepsilon) \frac{Hr_{\max}}{m} }^2 }{ \mu'\sbr{ \frac{Hr_{\max}}{m} } } } 
		\\
		&\leq K + \frac{K Hr_{\max} \varepsilon}{2}  \sqrt{ \frac{|\cA| K}{m n} \cdot \frac{ \mu'\sbr{ (1-c_0) \frac{Hr_{\max}}{m} }^2 }{ \mu'\sbr{ \frac{Hr_{\max}}{m} } } }  ,
	\end{align*}
	where $c_0 \in (0,\frac{1}{2})$ is a constant which satisfies $c_0 \geq \varepsilon$. We will specify how to make $c_0 \geq \varepsilon$ to satisfy this condition later.
	
	Then, we have
	\begin{align*}
		\cR(K) &= \sum_{k=1}^{K} \ex_{*}\mbr{V^*-V^{\pi^k}}
		\\
		&= r_{\max} HK - \frac{1}{n} \sum_{i=1}^{n} \sbr{ (1-\varepsilon)r_{\max} HK + \varepsilon r_{\max} H \cdot \frac{1}{|\cA|} \sum_{j=1}^{|\cA|} \ex_{i,j}[N_{i,j}] }
		\\
		&\geq \varepsilon r_{\max} H \sbr{K - \frac{K}{|\cA|} - \frac{K Hr_{\max} \varepsilon}{2}  \sqrt{ \frac{K}{|\cA| m n} \cdot \frac{ \mu'\sbr{ (1-c_0) \frac{Hr_{\max}}{m} }^2 }{ \mu'\sbr{ \frac{Hr_{\max}}{m} } } }  } .
	\end{align*}
	
	
	
	Let
	\begin{align*}
		\varepsilon= \frac{1}{2 Hr_{\max}} \sqrt{ \frac{|\cA| m n}{K} \cdot \frac{ \mu'\sbr{ \frac{Hr_{\max}}{m} } }{ \mu'\sbr{ (1-c_0) \frac{Hr_{\max}}{m} }^2 } } .
	\end{align*}
	
	Then, the constant $c_0$ should satisfy
	\begin{align*}
		\varepsilon= \frac{1}{2 Hr_{\max}} \sqrt{ \frac{|\cA| m n}{K} \cdot \frac{ \mu'\sbr{ \frac{Hr_{\max}}{m} } }{ \mu'\sbr{ (1-c_0) \frac{Hr_{\max}}{m} }^2 } } \leq c_0 .
	\end{align*}
	
	Since 
	\begin{align*}
		\frac{ \mu'\sbr{ \frac{Hr_{\max}}{m} } }{ \mu'\sbr{ (1-c_0) \frac{Hr_{\max}}{m} }^2 } &= \frac{ \sbr{ \exp\sbr{ (1-c_0) \frac{Hr_{\max}}{m} } + \exp\sbr{ - (1-c_0) \frac{Hr_{\max}}{m} } +2 }^2 }{ \exp\sbr{ \frac{Hr_{\max}}{m} } + \exp\sbr{ - \frac{Hr_{\max}}{m} } + 2 }
		\\
		&\leq \frac{ \sbr{4 \exp\sbr{ (1-c_0) \frac{Hr_{\max}}{m} } }^2 }{ \exp\sbr{ \frac{Hr_{\max}}{m} } }
		\\
		&= 16 \exp\sbr{ \Big(1-2c_0\Big) \frac{Hr_{\max}}{m} }   ,
	\end{align*}
	it suffices to let $c_0$ satisfy
	\begin{align*}
		\frac{1}{2 Hr_{\max}} \sqrt{ \frac{|\cA| m n}{K} \cdot 16 \exp\sbr{ (1-2c_0) \frac{Hr_{\max}}{m} } } \leq c_0 ,
	\end{align*}
	which is equivalent to
	$
	K \geq \frac{ 4|\cA| m n }{ H^2 r_{\max}^2 c_0^2}  \exp( (1-2c_0) \frac{Hr_{\max}}{m} )
	$.
	
	It suffices to let 
	\begin{align*}
		K \geq \frac{4 |\cA| m n }{ H^2 r_{\max}^2 c_0^2}  \exp\sbr{ \frac{Hr_{\max}}{m} } ,
	\end{align*}
	and then $c_0$ can be any constant in $(0,\frac{1}{2})$.
	
	
	Let $|\cS|\geq 3$, $|\cA|\geq 2$, $c_0 \in (0,\frac{1}{2})$ and $K \geq \frac{4 |\cA| m n}{H^2 r_{\max}^2 c_0^2} \exp( \frac{Hr_{\max}}{m} )$. 
	Since 
	\begin{align*}
		\frac{ \mu'\sbr{ \frac{Hr_{\max}}{m} } }{ \mu'\sbr{ (1-c_0) \frac{Hr_{\max}}{m} }^2 } &= \frac{ \sbr{ \exp\sbr{ (1-c_0) \frac{Hr_{\max}}{m} } + \exp\sbr{ - (1-c_0) \frac{Hr_{\max}}{m} } +2 }^2 }{ \exp\sbr{ \frac{Hr_{\max}}{m} } + \exp\sbr{ - \frac{Hr_{\max}}{m} } + 2 }
		\\
		&\geq \frac{ \sbr{ \exp\sbr{ (1-c_0) \frac{Hr_{\max}}{m} } }^2 }{ 4\exp\sbr{ \frac{Hr_{\max}}{m} } }
		\\
		&= \frac{1}{4} \exp\sbr{ \Big(1-2c_0\Big) \frac{Hr_{\max}}{m} }   ,
	\end{align*}
	we have 
	\begin{align*}
		\cR(K) &\geq \frac{1}{2 Hr_{\max}} \sqrt{ \frac{|\cA| m n}{K} \cdot \frac{ \mu'\sbr{ \frac{Hr_{\max}}{m} } }{ \mu'\sbr{ (1-c_0) \frac{Hr_{\max}}{m} }^2 } } \cdot r_{\max} H \sbr{K - \frac{K}{|\cA|} - \frac{K}{4} }
		\\&= \Omega\sbr{  \sqrt{\exp\sbr{ (1-2c_0) \frac{Hr_{\max}}{m} }  |\cS| |\cA| m K } } 
		\\
		&= \Omega\sbr{ \exp\sbr{ \Big(\frac{1}{2}-c_0\Big) \frac{Hr_{\max}}{m} }  \sqrt{ |\cS| |\cA| m K } } .
	\end{align*}
\end{proof}


\subsection{Pseudo-code and Detailed Description of Algorithm $\bitssegtran$} \label{apx:alg_bi_unknown_tran}

\begin{algorithm}[t]
	\caption{$\bitssegtran$} \label{alg:bits_tran_sum_regret}
	\begin{algorithmic}[1]
	\STATE {\bfseries Input:} $\delta,\delta':=\frac{\delta}{8},\lambda$.
	\FOR{$k=1,\dots,K$}
		\STATE $\hat{\theta}_{k-1} \leftarrow \argmin_{\theta} -(\sum_{k'=1}^{k-1} \sum_{i=1}^{m} ( y^{k'}_i \cdot \log(\mu((\phi^{\tau^{k'}_i})^\top \theta)) + (1-y^{k'}_i) \cdot \log(1-\mu((\phi^{\tau^{k'}_i})^\top \theta) ) ) - \frac{1}{2} \lambda \|\theta\|_2^2)$\; \label{line:hat_theta_bitstran}
		\STATE $\Sigma_{k-1} \leftarrow  \sum_{k'=1}^{k-1} \sum_{i=1}^{m} \phi^{\tau^{k'}_i} (\phi^{\tau^{k'}_i})^\top + \alpha \lambda I$\; \label{line:Sigma_bitstran}
		\STATE Draw a noise $\xi_k \sim \cN(0, \alpha \cdot \nu(k-1)^2 \cdot \Sigma_{k-1}^{-1})$, where $\nu(k-1)$ is defined in Eq.~\eqref{eq:def_nu}\; \label{line:noise_bitstran}
		\STATE $b^{pv}_{k-1}(s,a) \leftarrow \min\{ 2Hr_{\max} \sqrt{\frac{\log\sbr{\frac{KH|\cS||\cA| }{\delta'}}}{n_{k-1}(s,a)}} ,\ Hr_{\max}\}$ for any $(s,a) \in \cS \times \cA$\; \label{line:b_pv_bitstran}
		\STATE $\tilde{\theta}^{b}_k \leftarrow \hat{\theta}_{k-1}+\xi_k+b^{pv}_{k-1}$\; \label{line:tilde_theta_bitstran}
		\STATE $\pi^k \leftarrow \argmax_{\pi} (\hat{\phi}^{\pi}_{k-1})^\top \tilde{\theta}^{b}_k$, where $\hat{\phi}^{\pi}_{k-1}$ is defined in Eq.~\eqref{eq:def_hat_phi}\; \label{line:pi_k_bitstran}
		\STATE Play episode $k$ with policy $\pi^k$. Observe $\tau^k$ and binary segment feedback $\{y^k_i\}_{i=1}^{m}$\; \label{line:play_bitstran}
		%		Update $\hat{p}_k(s'|s,a)$ and $n_k(s,a)$ for any $(s,a,s') \in \cS \times \cA \times \cS$\; \label{line:update_hat_p_bitstran}
	\ENDFOR
	\end{algorithmic}
\end{algorithm}


Algorithm~\ref{alg:bits_tran_sum_regret} illustrates the procedure of $\bitssegtran$. In episode $k$, similar to $\bitsseg$, $\bitssegtran$ first uses MLE with past binary segment observations to obtain a reward estimate $\hat{\theta}_{k-1}$, and calculates the covariance matrix of past observations $\Sigma_{k-1}$ (Lines~\ref{line:hat_theta_bitstran}-\ref{line:Sigma_bitstran}). After that, $\bitssegtran$ samples a Gaussian noise $\xi_k$ using $\Sigma_{k-1}$ (Line~\ref{line:Sigma_bitstran}).

For any $k>0$ and $(s,a) \in \cS \times \cA$, let $\hat{p}_k(\cdot|s,a)$ denote the empirical estimate of $p(\cdot|s,a)$, and $n_k(s,a)$ denote the number of times $(s,a)$ was visited at the end of episode $k$.
Then, $\bitssegtran$ constructs a transition bonus $b^{pv}_{k-1}(s,a)$, which represents the uncertainty on transition estimation.  Incorporating the MLE estimate $\hat{\theta}_{k-1}$, noise $\xi_k$ and transition bonus $b^{pv}_{k-1}(s,a)$, $\bitssegtran$ constitutes a posterior estimate of the reward parameter $\tilde{\theta}_k$ (Line~\ref{line:tilde_theta_bitstran}).

For any policy $\pi$, $k>0$ and $(s,a) \in \cS \times \cA$, we define 
\begin{align}
	\hat{\phi}^{\pi}_k(s,a):=\ex_{\hat{p}_k}\mbr{ \sum_{h=1}^{H} \indicator\{s_h=s, a_h=a\} | \pi } , \label{eq:def_hat_phi}
\end{align}
which denotes the expected number of times $(s,a)$ is visited in an episode under policy $\pi$ on the empirical MDP $\hat{p}_k$.
In addition, let $\hat{\phi}^{\pi}_k:=[\hat{\phi}^{\pi}_k(s,a)]_{(s,a) \in \cS \times \cA} \in \R^{|\cS||\cA|}$.

Then, $\bitssegtran$ finds the optimal policy via $\argmax_{\pi} (\hat{\phi}^{\pi}_{k-1})^\top \tilde{\theta}^{b}_k$, which can be efficiently solved by any MDP planning algorithm with transition $\hat{p}_{k-1}$ and reward $\tilde{\theta}^{b}_k$ (Line~\ref{line:pi_k_bitstran}). With the computed optimal policy $\pi^k$,  $\bitssegtran$ plays episode $k$, and observes a trajectory and binary feedback on each segment (Line~\ref{line:play_bitstran}).


\subsection{Proof for the Regret Upper Bound with Unknown Transition}

In the following, we prove the regret upper bound (Theorem~\ref{thm:ub_bits_tran}) of algorithm $\bitssegtran$ for unknown transition.

Define event
\begin{align*}
	\cG_{\textup{Hoeff}}:=\Biggl\{  &\abr{\hat{p}_{k-1}(\cdot|s,a)^\top V^*_{h+1} - p(\cdot|s,a)^\top V^*_{h+1}} \leq \Bigg( 2H r_{\max} \sqrt{\frac{\log\sbr{\frac{KH|\cS||\cA|}{\delta'}}}{n_{k-1}(s,a)}} \wedge Hr_{\max} \Bigg) , 
	\\
	&\forall (s,a) \in \cS \times \cA,\ \forall k>0 \Biggr\} .
\end{align*}
\begin{lemma}
	It holds that
	\begin{align*}
		\Pr\mbr{ \cG_{\textup{Hoeff}} } \geq 1-2\delta' .
	\end{align*}
\end{lemma}
\begin{proof}
	This lemma follows from the Hoeffding inequality and a union bound over $n_{k-1}(s,a) \in [KH]$ and $(s,a) \in \cS \times \cA$.
\end{proof}

\begin{lemma}[Optimism of Thompson Sampling with Unknown Transition] \label{lemma:ts_optimism}
	Assume that event $\cE$ and $\cG_{\textup{Hoeff}}$ holds. Then, for any $k>0$, we have
	\begin{align*}
		\Pr\mbr{ \hat{\phi}_{k-1}(\pi^k)^\top \tilde{\theta}^{b}_k > (\phi^{\pi^*})^\top \theta^* \ |\ F_{k-1} } \geq \frac{1}{2\sqrt{2\pi e}} .
	\end{align*}
\end{lemma}
\begin{proof}
	This proof follows the analysis of Lemma 17 in \cite{efroni2021reinforcement}.
	
	Using the value difference lemma (see Lemma~\ref{lemma:value_diff_lemma}), we have
	\begin{align*}
		&\quad \hat{\phi}_{k-1}(\pi^*)^\top \tilde{\theta}^{b}_k - (\phi^{\pi^*})^\top \theta^*
		\\
		&= \ex_{\hat{p}_{k-1},\pi^*} \mbr{ \sum_{h=1}^{H} \sbr{ \tilde{\theta}^{b}_k(s_h,a_h) - \theta^*(s_h,a_h)  + \sbr{ \hat{p}_{k-1}(\cdot|s_h,a_h) - p(\cdot|s_h,a_h) }^\top V^*_{h+1} } }
		\\
		&= \ex_{\hat{p}_{k-1},\pi^*} \!\mbr{ \sum_{h=1}^{H} \sbr{ \tilde{\theta}_k(s_h,a_h) \!-\! \theta^*(s_h,a_h) \!+\! b^{pv}_{k-1}(s_h,a_h)  \!+\! \sbr{ \hat{p}_{k-1}(\cdot|s_h,a_h) \!-\! p(\cdot|s_h,a_h) }^{\!\top} \! V^*_{h+1} } }
		\\
		&\overset{\textup{(a)}}{\geq} \ex_{\hat{p}_{k-1},\pi^*} \mbr{ \sum_{h=1}^{H} \sbr{ \tilde{\theta}_k(s_h,a_h) - \theta^*(s_h,a_h) + b^{pv}_{k-1}(s_h,a_h) - b^{pv}_{k-1}(s_h,a_h) } }
		\\
		&= \ex_{\hat{p}_{k-1},\pi^*} \mbr{ \sum_{h=1}^{H} \sbr{ \tilde{\theta}_k(s_h,a_h) - \theta^*(s_h,a_h) } }
		\\
		&= \hat{\phi}_{k-1}(\pi^*)^\top \tilde{\theta}_k - \hat{\phi}_{k-1}(\pi^*)^\top \theta^* ,
	\end{align*}
	where inequality (a) uses the definition of event $\cG_{\textup{Hoeff}}$.
	
	Thus, by the definition of $\pi^k$, we have
	\begin{align*}
		\Pr \mbr{\hat{\phi}_{k-1}(\pi^k)^\top \tilde{\theta}^{b}_k > (\phi^{\pi^*})^\top \theta^* \ |\ F_{k-1}} &\overset{\textup{(a)}}{\geq} \Pr \mbr{\hat{\phi}_{k-1}(\pi^*)^\top \tilde{\theta}^{b}_k > (\phi^{\pi^*})^\top \theta^* \ |\ F_{k-1}}
		\\
		&= \Pr \mbr{\hat{\phi}_{k-1}(\pi^*)^\top \tilde{\theta}^{b}_k - (\phi^{\pi^*})^\top \theta^* > 0 \ |\ F_{k-1}}
		\\
		&\geq \Pr \mbr{ \hat{\phi}_{k-1}(\pi^*)^\top \tilde{\theta}_k - \hat{\phi}_{k-1}(\pi^*)^\top \theta^* >0 \ |\ F_{k-1}}
		\\
		&\overset{\textup{(b)}}{\geq} \frac{1}{2\sqrt{2\pi e}} ,
	\end{align*}
	where inequality (a) is due to the definition of $\pi^k$, and inequality (b) follows from Lemma~\ref{lemma:Gaussian_anti_concentration}.
\end{proof}






Define event
\begin{align}
	\cG_{\textup{KL}} := \lbr{ \kl(\hat{p}_{k-1}(\cdot|s,a),p(\cdot|s,a)) \leq \frac{L}{n_{k-1}(s,a)} ,\  \forall k>0, \forall (s,a) \in \cS \times \cA } . \label{eq:def_event_tran_kl}
\end{align}

\begin{lemma}[Concentration of Transition] \label{lemma:con_transition}
	It holds that
	\begin{align*}
		\Pr[\cG_{\textup{KL}}] \geq 1-\delta' .
	\end{align*}	
\end{lemma}
\begin{proof}
	This lemma can be obtained by Theorem 3 and Lemma 3 in \cite{menard2021fast}.
\end{proof}

Recall that for any $k>0$ and $(s,a) \in \cS \times \cA$,  $n_k(s,a)$ denotes the cumulative number of times that $(s,a)$ is visited at the end of episode $k$. For any $k>0$, $h \in [H]$ and $(s,a) \in \cS \times \cA$, let $w_{k,h}(s,a)$ denote the probability that $(s,a)$ is visited at step $h$ in episode $k$, and let $w_{k}(s,a):=\sum_{h=1}^{H}w_{k,h}(s,a)$.

Define event
\begin{align}
	\cH := \lbr{ n_k(s,a) \geq \frac{1}{2} \sum_{k'=1}^{k} w_{k'}(s,a) - H \log\sbr{\frac{|\cS||\cA|H}{\delta'}} ,\  \forall k>0, \forall (s,a) \in \cS \times \cA } . \label{eq:def_event_visitation_bernoulli}
\end{align}
\begin{lemma}[Concentration of the Number of Visitations] \label{lemma:con_visitation}
	It holds that
	\begin{align*}
		\Pr[\cH] \geq 1-\delta' .
	\end{align*}	
\end{lemma}
\begin{proof}
	This lemma can be obtained from Lemma F.4 in \cite{dann2017unifying} and summing over $h \in [H]$.
\end{proof}


Define event 
\begin{align*}
	\cF^{\bi}_{\textup{UTran}}:=\Bigg\{ 
	&\abr{\sum_{k'=1}^{k} \sbr{ \ex\mbr{ (\phi^{\pi^{k'}})^\top b^{pv}_{k'-1} | F_{k'-1} } - (\phi^{\pi^{k'}})^\top b^{pv}_{k'-1} }} \leq 4 H^2 r_{\max} \sqrt{ k \log\sbr{\frac{4k}{\delta'}} } ,
	\nonumber\\
	&\abr{\sum_{k'=1}^{k} \sbr{\ex\mbr{ \nbr{ \hat{\phi}_{k'-1}(\pi^{k'}) - \phi(\pi^{k'}) }_1 | F_{k'-1} } - \nbr{ \hat{\phi}_{k'-1}(\pi^{k'}) - \phi(\pi^{k'}) }_1 }} 
	\\
	& \leq 8H \sqrt{ k \log\sbr{\frac{4k}{\delta'}} } ,\ \forall k>0 \Bigg\} .
\end{align*}

\begin{lemma}
	It holds that
	\begin{align*}
		\Pr \mbr{ \cF^{\bi}_{\textup{UTran}} } \geq 1-2\delta' .
	\end{align*}
\end{lemma}
\begin{proof}
	This lemma can be obtained by a similar analysis as  Lemma~\ref{lemma:cF_binary}, and the facts that  $|(\phi^{\pi^k})^\top b^{pv}_{k-1}| \leq H^2 r_{\max}$ and $ \| \hat{\phi}_{k-1}(\pi^k) - \phi^{\pi^k} \|_1  \leq 2H$ for any $k\geq1$.
\end{proof}

\begin{lemma} \label{lemma:phi_hat-phi_l1}
	Assume that event $\cF^{\bi}_{\textup{UTran}} \cap \cG_{\textup{KL}} \cap \cH$ holds. Then, we have
	\begin{align*}
		\sum_{k=1}^{K} \ex\mbr{ \nbr{ \hat{\phi}_{k-1}(\pi^k) - \phi^{\pi^k} }_1 | F_{k-1} } &\leq 24 e^{12} |\cS|^{\frac{3}{2}} |\cA|^{\frac{3}{2}} H^{\frac{3}{2}}  \sqrt{ KL\log(2KH) } 
		\\
		&\quad + 192 e^{12} |\cS|^2 |\cA|^2 H^2L \log\sbr{\frac{2KH|\cS||\cA|}{\delta'}}  .
	\end{align*}
\end{lemma}
\begin{proof}
	First, from Lemmas~\ref{lemma:error_in_visitation} and \ref{lemma:ub_B}, we have
	\begin{align*}
		&\quad \sum_{k=1}^{K} \nbr{ \hat{\phi}_{k-1}(\pi) - \phi(\pi) }_1 
		\\
		&\leq e^{12} |\cS||\cA| \sum_{k=1}^{K} \sum_{h=1}^{H} \sum_{(s,a) \in D_k}  w^{\pi^k}_h(s,a)  \sbr{ 8 H \sqrt{ \frac{L}{n_{k-1}(s,a)} }  + \frac{46  H^2L}{n_{k-1}(s,a)} } 
		\\
		&\quad + e^{12} |\cS||\cA|H \sum_{k=1}^{K} \sum_{h=1}^{H} \sum_{(s,a) \notin D_k}  w^{\pi^k}_h(s,a)
		\\
		&\leq  8 e^{12} |\cS||\cA| H \sqrt{L} \sqrt{\sum_{k=1}^{K} \sum_{h=1}^{H} \sum_{(s,a) \in D_k}  w^{\pi^k}_h(s,a) }  \sqrt{ \sum_{k=1}^{K} \sum_{h=1}^{H} \sum_{(s,a) \in D_k} \frac{w^{\pi^k}_h(s,a)}{n_{k-1}(s,a)} }  \\
		&\quad + 46 e^{12} |\cS||\cA| H^2L \sum_{k=1}^{K} \sum_{h=1}^{H} \sum_{(s,a) \in D_k}   \frac{ w^{\pi^k}_h(s,a) }{n_{k-1}(s,a)}  
		+ 8e^{12} |\cS|^2 |\cA|^2 H^2  \log\sbr{\frac{|\cS||\cA|H}{\delta'}}
		\\
		&\leq  16 e^{12} |\cS|^{\frac{3}{2}} |\cA|^{\frac{3}{2}} H^{\frac{3}{2}}  \sqrt{ KL\log(2KH) } + 184 e^{12} |\cS|^2 |\cA|^2 H^2L \log(2KH)  
		\\
		&\quad + 8e^{12} |\cS|^2 |\cA|^2 H^2  \log\sbr{\frac{|\cS||\cA|H}{\delta'}} 
		\\
		&\leq  16 e^{12} |\cS|^{\frac{3}{2}} |\cA|^{\frac{3}{2}} H^{\frac{3}{2}}  \sqrt{ KL\log(2KH) } + 192 e^{12} |\cS|^2 |\cA|^2 H^2L \log\sbr{\frac{2KH|\cS||\cA|}{\delta'}} .
	\end{align*}
	
	Next, we have
	\begin{align*}
		&\quad \sum_{k=1}^{K} \ex\mbr{ \nbr{ \hat{\phi}_{k-1}(\pi^k) - \phi^{\pi^k} }_1 | F_{k-1} } 
		\\
		&\leq \sum_{k=1}^{K} \nbr{ \hat{\phi}_{k-1}(\pi^k) - \phi^{\pi^k} }_1 + \sum_{k=1}^{K} \sbr{\ex\mbr{ \nbr{ \hat{\phi}_{k-1}(\pi^k) - \phi^{\pi^k} }_1 | F_{k-1} } - \nbr{ \hat{\phi}_{k-1}(\pi^k) - \phi^{\pi^k} }_1 }
		\\
		&\leq 16 e^{12} |\cS|^{\frac{3}{2}} |\cA|^{\frac{3}{2}} H^{\frac{3}{2}}  \sqrt{ KL\log(2KH) } + 192 e^{12} |\cS|^2 |\cA|^2 H^2L \log\sbr{\frac{2KH|\cS||\cA|}{\delta'}} 
		\\
		&\quad + 8H \sqrt{ K \log\sbr{\frac{4K}{\delta'}} } 
		\\
		&\leq 24 e^{12} |\cS|^{\frac{3}{2}} |\cA|^{\frac{3}{2}} H^{\frac{3}{2}}  \sqrt{ KL\log(2KH) } + 192 e^{12} |\cS|^2 |\cA|^2 H^2L \log\sbr{\frac{2KH|\cS||\cA|}{\delta'}} .
	\end{align*}
\end{proof}

\begin{lemma} \label{lemma:phi_b_pv}
	Assume that event $\cF^{\bi}_{\textup{UTran}}$ holds. Then, we have
	\begin{align*}
		\sum_{k=1}^{K} \ex\mbr{ (\phi^{\pi^k})^\top b^{pv}_{k-1} | F_{k-1} } &\leq 20|\cS| |\cA| H^{2} r_{\max} \sqrt{K } \log\sbr{\frac{4KH|\cS||\cA|}{\delta'}} .
	\end{align*}
\end{lemma}
\begin{proof}
	It holds that
	\begin{align*}
		&\quad \sum_{k=1}^{K} \ex\mbr{ (\phi^{\pi^k})^\top b^{pv}_{k-1} | F_{k-1} } 
		\\
		&= \sum_{k=1}^{K} (\phi^{\pi^k})^\top b^{pv}_{k-1} + \sum_{k=1}^{K} \sbr{ \ex\mbr{ (\phi^{\pi^k})^\top b^{pv}_{k-1} | F_{k-1} } - (\phi^{\pi^k})^\top b^{pv}_{k-1} }
		\\
		&\leq \sum_{k=1}^{K} \sum_{h=1}^{H} \sum_{s,a} w^{\pi^k}_h(s,a) \sbr{2H r_{\max} \sqrt{\frac{\log\sbr{\frac{KH|\cS||\cA|}{\delta'}}}{n_{k-1}(s,a)}} \wedge H r_{\max}} + 4 H^2 r_{\max} \sqrt{ K \log\sbr{\frac{4K}{\delta'}} }
		\\
		&\leq 2H r_{\max} \sqrt{\log\sbr{\frac{KH|\cS||\cA|}{\delta'}}} \sum_{k=1}^{K} \sum_{h=1}^{H} \sum_{(s,a) \in D_k}   \frac{w^{\pi^k}_h(s,a)}{\sqrt{n_{k-1}(s,a)}}   
		\\
		&\quad + H r_{\max} \sum_{k=1}^{K} \sum_{h=1}^{H} \sum_{(s,a) \notin D_k} w^{\pi^k}_h(s,a) + 4 H^2 r_{\max} \sqrt{ K \log\sbr{\frac{4K}{\delta'}} }
		\\
		&\leq 2H r_{\max} \sqrt{\log\sbr{\frac{KH|\cS||\cA|}{\delta'}}} \cdot \sqrt{KH} \cdot \sqrt{\sum_{k=1}^{K} \sum_{h=1}^{H} \sum_{(s,a) \in D_k}   \frac{w^{\pi^k}_h(s,a)}{n_{k-1}(s,a)}} 
		\\
		&\quad  + 8|\cS||\cA|H^2 r_{\max} \log\sbr{\frac{|\cS||\cA|H}{\delta'}} + 4 H^2 r_{\max} \sqrt{ K \log\sbr{\frac{4K}{\delta'}} }
		\\
		&\leq 2H r_{\max} \sqrt{\log\sbr{\frac{KH|\cS||\cA|}{\delta'}}} \cdot \sqrt{KH} \cdot \sqrt{4 |\cS| |\cA| \log(2KH)} 
		\\
		&\quad +  8|\cS||\cA|H^2 r_{\max} \log\sbr{\frac{|\cS||\cA|H}{\delta'}} + 4 H^2 r_{\max} \sqrt{ K \log\sbr{\frac{4K}{\delta'}} }
		\\
		&\leq 16|\cS| |\cA| H^{2} r_{\max} \sqrt{K } \log\sbr{\frac{4KH|\cS||\cA|}{\delta'}} .
	\end{align*}
\end{proof}



\begin{proof}[Proof of Theorem~\ref{thm:ub_bits_tran}]
	Letting $\delta'=\frac{\delta}{8}$, we have $\Pr[\cE \cap \cF^{\bi}_{\textup{KTran}} \cap \cG_{\textup{Hoeff}} \cap \cG_{\textup{KL}} \cap \cH \cap \cF^{\bi}_{\textup{UTran}}] \leq 1-\delta$. Then, to prove this theorem, it suffices to prove
	the regret bound when event $\cE \cap \cF^{\bi}_{\textup{KTran}} \cap \cG_{\textup{Hoeff}} \cap \cG_{\textup{KL}} \cap \cH \cap \cF^{\bi}_{\textup{UTran}}$ holds.
	
	Assume that event $\cE \cap \cF^{\bi}_{\textup{KTran}} \cap \cG_{\textup{Hoeff}} \cap \cG_{\textup{KL}} \cap \cH \cap \cF^{\bi}_{\textup{UTran}}$ holds. Then, we have
	\begin{align}
		\cR(K) &= \sum_{k=1}^{K} \sbr{ (\phi^{\pi^*})^\top \theta^* - (\phi^{\pi^k})^\top \theta^* }
		\nonumber\\
		&= \sum_{k=1}^{K} \sbr{ \ex\mbr{ (\phi^{\pi^*})^\top \theta^* - (\phi^{\pi^k})^\top \theta^* | F_{k-1} } + \ex\mbr{ (\phi^{\pi^k})^\top \theta^* | F_{k-1} } - (\phi^{\pi^k})^\top \theta^* } 
		\nonumber\\
		&= \sum_{k=1}^{K} \sbr{ \ex\mbr{ (\phi^{\pi^*})^\top \theta^* - (\phi^{\pi^k})^\top \theta^* | F_{k-1} } } + 4 H r_{\max} \sqrt{ K \log\sbr{\frac{4K}{\delta'}} } . \label{eq:regret_decomposition}
	\end{align}
	
	%	First, for the second term, we have
	%	\begin{align*}
		%	\sum_{k=1}^{K} \sbr{ \ex\mbr{ (\phi^{\pi^k})^\top \theta^* | F_{k-1} } - (\phi^{\pi^k})^\top \theta^* } \leq 4 H r_{\max} \sqrt{ K \log\sbr{\frac{4K}{\delta'}} } .
		%	\end{align*}
	
	For the first term, we have
	\begin{align}
		&\sum_{k=1}^{K} \ex\mbr{ (\phi^{\pi^*})^\top \theta^* - (\phi^{\pi^k})^\top \theta^* | F_{k-1} } 
		\nonumber\\
		&= \sum_{k=1}^{K} \sbr{ \ex\mbr{ (\phi^{\pi^*})^\top \theta^* - \hat{\phi}_{k-1}(\pi^k)^\top \tilde{\theta}^{b}_k | F_{k-1} } + \ex\mbr{ \hat{\phi}_{k-1}(\pi^k)^\top \tilde{\theta}^{b}_k - (\phi^{\pi^k})^\top \theta^* | F_{k-1} } } . \label{eq:ex_phi_star-phi_pi_k_theta}
	\end{align}
	
	In the following, we prove
	\begin{align}
		&\ex\mbr{ (\phi^{\pi^*})^\top \theta^* - \hat{\phi}_{k-1}(\pi^k)^\top \tilde{\theta}^{b}_k | F_{k-1} } 
		\nonumber\\
		&\leq 2\sqrt{2\pi e} \cdot \ex\mbr{ \sbr{ \hat{\phi}_{k-1}(\pi^k)^\top \tilde{\theta}^{b}_k  - \ex\mbr{ \hat{\phi}_{k-1}(\pi^k)^\top \tilde{\theta}^{b}_k  | F_{k-1} } }^{+} | F_{k-1} } . \label{eq:fist_term_leq_positive}
	\end{align}
	
	If $\ex[ (\phi^{\pi^*})^\top \theta^* - \hat{\phi}_{k-1}(\pi^k)^\top \tilde{\theta}^{b}_k | F_{k-1} ]<0$, then Eq.~\eqref{eq:fist_term_leq_positive} trivially holds. 
	
	Otherwise, letting $z:= \ex[ (\phi^{\pi^*})^\top \theta^* - \hat{\phi}_{k-1}(\pi^k)^\top \tilde{\theta}^{b}_k | F_{k-1} ]$, we have
	\begin{align*}
		&\quad \ex\mbr{ \sbr{ \hat{\phi}_{k-1}(\pi^k)^\top \tilde{\theta}^{b}_k  - \ex\mbr{ \hat{\phi}_{k-1}(\pi^k)^\top \tilde{\theta}^{b}_k  | F_{k-1} } }^{+} | F_{k-1} }
		\\
		&\geq z \Pr\mbr{  \hat{\phi}_{k-1}(\pi^k)^\top \tilde{\theta}^{b}_k  - \ex\mbr{ \hat{\phi}_{k-1}(\pi^k)^\top \tilde{\theta}^{b}_k   | F_{k-1} } \geq z | F_{k-1} }
		\\
		&\geq \sbr{\ex\mbr{ (\phi^{\pi^*})^\top \theta^* - \hat{\phi}_{k-1}(\pi^k)^\top \tilde{\theta}^{b}_k | F_{k-1} } } \cdot \Pr\mbr{  \hat{\phi}_{k-1}(\pi^k)^\top \tilde{\theta}^{b}_k   \geq (\phi^{\pi^*})^\top \theta^* | F_{k-1} }
		\\
		&\overset{\textup{(a)}}{\geq} \sbr{\ex\mbr{ (\phi^{\pi^*})^\top \theta^* - \hat{\phi}_{k-1}(\pi^k)^\top \tilde{\theta}^{b}_k | F_{k-1} } } \cdot \frac{1}{2\sqrt{2\pi e}} ,
	\end{align*}
	where inequality (a) uses Lemma~\ref{lemma:ts_optimism}. Thus, we complete the proof of Eq.~\eqref{eq:fist_term_leq_positive}.
	
	Let $\xi'_k \in \R^{|\cS||\cA|}$ be an i.i.d. random variable with $\xi$ given $F_{k-1}$.
	Then, using Lemma~\ref{lemma:xi_xi'} with $p'=\hat{p}_{k-1}$, $x_{k-1}=\hat{\theta}_{k-1}+b_{k-1}^{pv}$ and $\tilde{\pi}^k=\pi^k$, we have
	\begin{align*}
		&\quad\ \ex\mbr{ (\phi^{\pi^*})^\top \theta^* - \hat{\phi}_{k-1}(\pi^k)^\top \tilde{\theta}^{b}_k | F_{k-1} } 
		\\
		&\leq 2\sqrt{2\pi e} \cdot \ex\mbr{ \sbr{ \hat{\phi}_{k-1}(\pi^k)^\top \tilde{\theta}^{b}_k  - \ex\mbr{ \hat{\phi}_{k-1}(\pi^k)^\top \tilde{\theta}^{b}_k  | F_{k-1} } }^{+} | F_{k-1} } 
		\\
		&\leq 2\sqrt{2\pi e} \cdot \ex\mbr{ | \hat{\phi}_{k-1}(\pi^k)^\top \xi_k | + | \hat{\phi}_{k-1}(\pi^k)^\top \xi'_k| \ | F_{k-1} } .
	\end{align*}
	
	Plugging the above inequality into Eq.~\eqref{eq:ex_phi_star-phi_pi_k_theta} and using Lemma~\ref{lemma:X_top_xi_k} with $\delta_k=\frac{1}{k^4}$ and $L_{X}=\frac{H}{\sqrt{\alpha \lambda}}$, we have
	\begin{align}
		&\quad\  \sum_{k=1}^{K} \ex\mbr{ (\phi^{\pi^*})^\top \theta^* - (\phi^{\pi^k})^\top \theta^* | F_{k-1} } 
		\nonumber\\
		&= \sum_{k=1}^{K} \bigg( 2\sqrt{2\pi e} \cdot \ex\mbr{ | \hat{\phi}_{k-1}(\pi^k)^\top \xi_k | + | \hat{\phi}_{k-1}(\pi^k)^\top \xi'_k| \ | F_{k-1} } 
		\nonumber\\
		&\quad + \ex\mbr{ \hat{\phi}_{k-1}(\pi^k)^\top \sbr{\hat{\theta}_{k-1} + b^{pv}_{k-1} + \xi_k} - (\phi^{\pi^k})^\top \theta^* | F_{k-1} } \bigg)
		\nonumber\\
		&= \sum_{k=1}^{K} \bigg( \sbr{2\sqrt{2\pi e} + 1} \cdot \ex\mbr{ | \hat{\phi}_{k-1}(\pi^k)^\top \xi_k | \ | F_{k-1}} + 2\sqrt{2\pi e} \cdot \ex\mbr{ | \hat{\phi}_{k-1}(\pi^k)^\top \xi'_k| \ | F_{k-1} } 
		\nonumber\\
		&\quad + \ex\mbr{ \hat{\phi}_{k-1}(\pi^k)^\top \sbr{\hat{\theta}_{k-1} + b^{pv}_{k-1}} - (\phi^{\pi^k})^\top \theta^* | F_{k-1} } \bigg)
		\nonumber\\
		&\leq \sum_{k=1}^{K} \Bigg( \sbr{4\sqrt{2\pi e} + 1} \sqrt{\alpha} \cdot \nu(k-1) \sbr{ \sqrt{|\cS||\cA|} + 4 \sqrt{\log\sbr{k}} }  \ex\mbr{ \nbr{ \hat{\phi}_{k-1}(\pi^k) }_{\Sigma_{k-1}^{-1}} \ | F_{k-1}} 
		\nonumber\\
		&\quad + \sbr{4\sqrt{2\pi e} + 1} \sqrt{\alpha} \cdot \nu(k-1)  \frac{\sqrt{|\cS| |\cA|}}{k^2}  \cdot \frac{H}{\sqrt{\alpha \lambda}}
		\nonumber\\
		&\quad + \ex\mbr{ \hat{\phi}_{k-1}(\pi^k)^\top \sbr{\hat{\theta}_{k-1} + b^{pv}_{k-1}} - (\phi^{\pi^k})^\top \theta^* | F_{k-1} } \Bigg) . \label{eq:known_tran_ex_phi_star_theta_star-phi_k_theta_star}
	\end{align}
	
	We have
	\begin{align*}
		&\quad\  \ex\mbr{ \hat{\phi}_{k-1}(\pi^k)^\top \sbr{\hat{\theta}_{k-1} + b^{pv}_{k-1}} - (\phi^{\pi^k})^\top \theta^* | F_{k-1} }
		\nonumber\\
		&= \ex\mbr{ \hat{\phi}_{k-1}(\pi^k)^\top \sbr{\hat{\theta}_{k-1} - \theta^*} | F_{k-1} } + \ex\mbr{ \sbr{ \hat{\phi}_{k-1}(\pi^k) - \phi^{\pi^k} }^\top \theta^* | F_{k-1} } 
		\nonumber\\
		&\quad + \ex\mbr{ \hat{\phi}_{k-1}(\pi^k)^\top b^{pv}_{k-1} | F_{k-1} }
		\nonumber\\
		&\leq \sqrt{\alpha} \cdot \nu(k-1) \ex\mbr{ \nbr{ \hat{\phi}_{k-1}(\pi^k) }_{\Sigma_{k-1}^{-1}} | F_{k-1} } + r_{\max} \ex\mbr{ \nbr{ \hat{\phi}_{k-1}(\pi^k) - \phi^{\pi^k} }_1 | F_{k-1} }  
		\nonumber\\
		&\quad + \ex\mbr{ \hat{\phi}_{k-1}(\pi^k)^\top b^{pv}_{k-1} | F_{k-1} } . \label{eq:known_tran_error_phi_theta_tran}
	\end{align*}
	
	Hence, plugging the above inequality into Eq.~\eqref{eq:known_tran_ex_phi_star_theta_star-phi_k_theta_star}, we have
	\begin{align*}
		&\quad\  \sum_{k=1}^{K} \ex\mbr{ (\phi^{\pi^*})^\top \theta^* - (\phi^{\pi^k})^\top \theta^* | F_{k-1} } 
		\\
		&\leq \sum_{k=1}^{K} \Bigg( \sbr{4\sqrt{2\pi e} + 2} \sqrt{\alpha} \cdot \nu(k-1) \sbr{ \sqrt{|\cS||\cA|} + 4 \sqrt{\log\sbr{k}} } \cdot \ex\mbr{ \nbr{ \hat{\phi}_{k-1}(\pi^k) }_{\Sigma_{k-1}^{-1}} \ | F_{k-1}} 
		\\
		&\quad + \sbr{4\sqrt{2\pi e} + 1} \cdot \nu(k-1) \frac{H}{k^2} \sqrt{ \frac{|\cS| |\cA|}{\lambda} }
		+ r_{\max} \ex\mbr{ \nbr{ \hat{\phi}_{k-1}(\pi^k) - \phi^{\pi^k} }_1 | F_{k-1} }  
		\\
		&\quad + \ex\mbr{ \hat{\phi}_{k-1}(\pi^k)^\top b^{pv}_{k-1} | F_{k-1} } \Bigg) .
	\end{align*}
	
	Here we have
	\begin{align*}
		&\quad\ \sum_{k=1}^{K} \ex\mbr{ \nbr{ \hat{\phi}_{k-1}(\pi^k) }_{\Sigma_{k-1}^{-1}} \ | F_{k-1}} 
		\\
		&\leq \sum_{k=1}^{K} \ex\mbr{ \nbr{ \phi^{\pi^k} }_{\Sigma_{k-1}^{-1}} \ | F_{k-1}} + \sum_{k=1}^{K} \ex\mbr{ \nbr{ \hat{\phi}_{k-1}(\pi^k) - \phi^{\pi^k} }_{\Sigma_{k-1}^{-1}} \ | F_{k-1}}
		\\
		&\leq \sum_{k=1}^{K} \ex\mbr{ \nbr{ \phi^{\pi^k} }_{\Sigma_{k-1}^{-1}} \ | F_{k-1}} + \frac{1}{\sqrt{\alpha \lambda}} \sum_{k=1}^{K} \ex\mbr{ \nbr{ \hat{\phi}_{k-1}(\pi^k) - \phi^{\pi^k} }_1 \ | F_{k-1}}
		\\
		&\overset{\textup{(a)}}{\leq}  4H\sqrt{ \frac{K}{\alpha \lambda} \log\sbr{\frac{4K}{\delta'}} } + \sqrt{ 2Km |\cS| |\cA| \cdot \max\lbr{ \frac{H^2}{m \alpha \lambda}, 1} \cdot \log \sbr{ 1+ \frac{  KH^2 }{ \alpha \lambda |\cS| |\cA| m } } } 
		\\
		&\quad + \frac{1}{\sqrt{\alpha \lambda}} \sum_{k=1}^{K} \ex\mbr{ \nbr{ \hat{\phi}_{k-1}(\pi^k) - \phi^{\pi^k} }_1 \ | F_{k-1}} ,
	\end{align*}
	where inequality (a) uses Eq.~\eqref{eq:ex_sum_phi_seg}. 
	
	In addition, we have
	\begin{align*}
		&\quad\ \sum_{k=1}^{K} \ex\mbr{ \hat{\phi}_{k-1}(\pi^k)^\top b^{pv}_{k-1} | F_{k-1}  }
		\\
		&\leq \sum_{k=1}^{K} \ex\mbr{ (\phi^{\pi^k})^\top b^{pv}_{k-1} | F_{k-1} } + \sum_{k=1}^{K} \ex\mbr{ \nbr{\hat{\phi}_{k-1}(\pi^k) - \phi^{\pi^k} }_1 \nbr{b^{pv}_{k-1}}_{\infty} | F_{k-1} }
		\\
		&\leq \sum_{k=1}^{K} \ex\mbr{ (\phi^{\pi^k})^\top b^{pv}_{k-1} | F_{k-1} } + H r_{\max} \sum_{k=1}^{K} \ex\mbr{ \nbr{\hat{\phi}_{k-1}(\pi^k) - \phi^{\pi^k} }_1  | F_{k-1} } .
	\end{align*}
	
	Therefore, plugging the above three equations into Eq.~\eqref{eq:regret_decomposition}, we have
	\begin{align*}
	\cR(K) &\leq \sbr{4\sqrt{2\pi e} + 2} \sqrt{\alpha} \cdot \nu(K) \sbr{ \sqrt{|\cS||\cA|} + 4 \sqrt{\log\sbr{K}} } \cdot 
		\\
		&\quad \sbr{ 4H\sqrt{ \frac{K}{\alpha \lambda} \log\sbr{\frac{4K}{\delta'}} } + \sqrt{ 2Km |\cS| |\cA| \max\lbr{ \frac{H^2}{m \alpha \lambda}, 1} \log \sbr{ 1+ \frac{  KH^2 }{ \alpha \lambda |\cS| |\cA| m } } }  }
		\\
		&\quad 
		+\! \sbr{\!\sbr{4\sqrt{2\pi e} \!+\! 2}\!   \frac{\nu(K)}{\sqrt{\lambda}}\! \sbr{\! \sqrt{|\cS||\cA|} \!+\! 4 \sqrt{ \log(K) } } \!+\! 2Hr_{\max} \!} \sum_{k=1}^{K} \ex\mbr{ \nbr{ \hat{\phi}_{k-1}(\pi^k) - \phi^{\pi^k} }_1 \!| F_{k-1} }  
		\\
		&\quad +\! \sum_{k=1}^{K} \ex\mbr{ (\phi^{\pi^k})^\top b^{pv}_{k-1} | F_{k-1} } 
		\!+\! 2 \sbr{4\sqrt{2\pi e} + 1} H \cdot \nu(K)  \sqrt{ \frac{|\cS| |\cA|}{\lambda} }  \!+\! 4 H r_{\max} \sqrt{ K \log\sbr{\frac{4K}{\delta'}} } 
		\\
		&\overset{\textup{(a)}}{=} \tilde{O} \Bigg( \exp\sbr{\frac{Hr_{\max}}{m}} \nu(K) \sqrt{|\cS||\cA|} \sbr{ \sqrt{ Km |\cS| |\cA| \max\lbr{ \frac{H^2}{m \alpha \lambda}, 1}  } + H\sqrt{ \frac{K}{\alpha \lambda} }  }
		\\
		&\qquad \quad
		+ \sbr{ \nu(K) \sqrt{ \frac{|\cS||\cA|}{\lambda} }  + Hr_{\max} } |\cS|^2 |\cA|^{\frac{3}{2}} H^{\frac{3}{2}}  \sqrt{ K }
		\Bigg) ,
	\end{align*}
	where in equality (a), we use Lemmas~\ref{lemma:phi_hat-phi_l1} and \ref{lemma:phi_b_pv}, and the last three terms are absorbed into $\tilde{O}(\cdot)$.
\end{proof}

\section{Proofs for RL with Sum Segment Feedback}

In this section, we provide the proofs for RL with sum segment feedback.

\subsection{Proof for the Regret Upper Bound with Known Transition}

We first prove the regret upper bound (Theorem~\ref{thm:ub_sum_known_tran}) of algorithm $\edlinucbseg$ for known transition.

Define event
\begin{align}
	& \cJ:=\Bigg\{ \nbr{ \sum_{k=1}^{K_0} \sbr{ \sum_{i=1}^{m} \phi^{\tau^k_i} (\phi^{\tau^k_i})^\top  - \ex_{\tau_i \sim \pi^k}\mbr{\sum_{i=1}^{m} \phi(\tau_i) \phi(\tau_i)^\top} } } 
	\nonumber\\
	&\leq \frac{4H^2}{m} \sqrt{K_0\log\sbr{\frac{2|\cS||\cA|}{\delta'}}}  + \frac{4H^2}{m} \log\sbr{\frac{2|\cS||\cA|}{\delta'}} \Bigg\} .
\end{align}

\begin{lemma}[Concentration of Initial Sampling] 
	It holds that
	\begin{align*}
		\Pr \mbr{ \cJ } \geq 1-\delta' .
	\end{align*}
\end{lemma}
\begin{proof}
	Note that $\pi^1,\dots,\pi^{K_0}$ and $K_0$ are fixed before sampling, $\ex[\sum_{i=1}^{m} \phi^{\tau^k_i} (\phi^{\tau^k_i})^\top]=\ex_{\tau_i \sim \pi^k}\mbr{\sum_{i=1}^{m} \phi(\tau_i) \phi(\tau_i)^\top}$, and $\|\sum_{i=1}^{m} \phi^{\tau^k_i} (\phi^{\tau^k_i})^\top\| \leq \frac{H^2}{m}$.
	Then, using the matrix Bernstein inequality (Theorem 6.1.1 in \cite{tropp2015introduction}), we can obtain this lemma.
\end{proof}



\begin{lemma}[E-optimal Design] \label{lemma:seg_e_optimal_design}
	Assume that event $\cJ$ holds. Then, we have
	\begin{align*}
		\nbr{ \sbr{\sum_{k=1}^{K_0} \sum_{i=1}^{m} \phi^{\tau^k_i} (\phi^{\tau^k_i})^\top}^{-1} } \leq \frac{1}{H^2} .
	\end{align*}
\end{lemma}
\begin{proof}
	Using the guarantee of the rounding procedure $\round$ (Theorem 1.1 in \cite{allen2021near}) and the fact that $K_0 \geq \frac{|\cS| |\cA|}{\gamma^2}$, we have
	\begin{align*}
		&\quad \nbr{ \sbr{\sum_{k=1}^{K_0}  \ex_{\tau_i \sim \pi^k}\mbr{\sum_{i=1}^{m} \phi(\tau_i) \phi(\tau_i)^\top} }^{-1} }
		\\
		&\leq (1+\gamma) \nbr{  \sbr{ K_0 \sum_{\pi \in \Pi} w^*(\pi) \cdot  \ex_{\tau_i \sim \pi^k}\mbr{\sum_{i=1}^{m} \phi(\tau_i) \phi(\tau_i)^\top} }^{-1} }
		\\
		&\leq \frac{(1+\gamma) z^*}{K_0} .
	\end{align*}
	
	
	Let $\sigma_{\min}(\cdot)$ denote the minimum eigenvalue.
	Then, we have
	\begin{align}
		&\quad\ \sigma_{\min}\sbr{ \sum_{k=1}^{K_0} \sum_{i=1}^{m} \phi^{\tau^k_i} (\phi^{\tau^k_i})^\top }
		\nonumber\\
		&= \sigma_{\min}\!\sbr{ \sum_{k=1}^{K_0} \ex_{\tau_i \sim \pi^k}\mbr{\sum_{i=1}^{m} \phi(\tau_i) \phi(\tau_i)^{\!\top}} \!+\! \sum_{k=1}^{K_0} \sum_{i=1}^{m} \phi^{\tau^k_i} (\phi^{\tau^k_i})^{\!\top} \!-\! \sum_{k=1}^{K_0} \ex_{\tau_i \sim \pi^k}\!\mbr{\sum_{i=1}^{m} \phi(\tau_i) \phi(\tau_i)^{\!\top}} }
		\nonumber\\
		&\geq \!\sigma_{\min}\!\sbr{ \sum_{k=1}^{K_0} \ex_{\tau_i \sim \pi^k}\!\mbr{\sum_{i=1}^{m} \phi(\tau_i) \phi(\tau_i)^{\!\top}} } \!-\! \nbr{ \sum_{k=1}^{K_0} \sum_{i=1}^{m} \phi^{\tau^k_i} (\phi^{\tau^k_i})^{\!\top} \!-\! \sum_{k=1}^{K_0} \ex_{\tau_i \sim \pi^k}\!\mbr{\sum_{i=1}^{m} \phi(\tau_i) \phi(\tau_i)^{\!\top}} }
		\nonumber\\
		&\geq \frac{ K_0 }{(1+\gamma) z^*} - \frac{4H^2}{m}\sqrt{\log\sbr{\frac{2|\cS||\cA|}{\delta'}}} \cdot \sqrt{K_0} - \frac{4H^2}{m} \log\sbr{\frac{2|\cS||\cA|}{\delta'}} . \label{eq:seg_minimum_eig_derivation}
	\end{align}
	
	
	Let $x=\sqrt{K_0}$ and
	\begin{align*}
		f(x) = \frac{ 1 }{(1+\gamma) z^*} \cdot x^2 - \frac{4H^2}{m} \sqrt{\log\sbr{\frac{2|\cS||\cA|}{\delta'}}} \cdot x - \frac{4H^2}{m} \log\sbr{\frac{2|\cS||\cA|}{\delta'}} - H^2 .
	\end{align*}
	
	According to the property of quadratic functions, when
	\begin{align}
		x \geq \frac{ \frac{4H^2}{m} \sqrt{\log\sbr{\frac{2|\cS||\cA|}{\delta'}}} + \sqrt{ \sbr{ \frac{4H^2}{m} \sqrt{\log\sbr{\frac{2|\cS||\cA|}{\delta'}}} }^2 + 4 \cdot \frac{ 1 }{(1+\gamma) z^*} \sbr{\frac{4H^2}{m} \log\sbr{\frac{2|\cS||\cA|}{\delta'}} + H^2 } } }{ 2 \cdot \frac{ 1 }{(1+\gamma) z^*} } , \label{eq:condition_quadratic_function}
	\end{align} 
	we have $f(x)\geq0$.
	
	To make Eq.~\eqref{eq:condition_quadratic_function} hold, it suffices to set 
	\begin{align*}
		K_0 &\geq \frac{(1+\gamma)^2 (z^*)^2 }{4} \cdot \Bigg( 2 \cdot \sbr{\frac{4H^2}{m}\sqrt{\log\sbr{\frac{2|\cS||\cA|}{\delta'}}}}^2 + 2 \cdot \sbr{ \frac{4H^2}{m}\sqrt{\log\sbr{\frac{2|\cS||\cA|}{\delta'}}} }^2 \\&\quad +  \frac{8  }{(1+\gamma) z^*} \cdot 5H^2 \log\sbr{\frac{2|\cS||\cA|}{\delta'}}   \Bigg)
		\\
		&=  \sbr{ \frac{ 16H^4 (1+\gamma)^2 (z^*)^2 }{m^2 } + 10 H^2 (1+\gamma) z^* } \log\sbr{\frac{2|\cS||\cA|}{\delta'}} .
	\end{align*}
	
	Furthermore, since $\|\sum_{\pi \in \Pi} w^*(\pi)  \ex_{\tau_i \sim \pi^k}\mbr{\sum_{i=1}^{m} \phi(\tau_i) \phi(\tau_i)^\top}\| \leq H^2$ and then $z^* \geq \frac{1}{H^2}$, to make the right-hand-side in Eq.~\eqref{eq:seg_minimum_eig_derivation} no smaller than $H^2$, it suffices to set
	\begin{align*}
		K_0 \geq 26H^4 (1+\gamma)^2 (z^*)^2  \log\sbr{\frac{2|\cS||\cA|}{\delta'}} .
	\end{align*}
	
	Therefore, combining the definition of $K_0$ and Eq.~\eqref{eq:seg_minimum_eig_derivation}, we have
	\begin{align*}
		\sigma_{\min}\sbr{ \sum_{k=1}^{K_0} \phi(\tau^k) \phi(\tau^k)^\top } \geq H^2 ,
	\end{align*}
	which completes the proof.
\end{proof}	


\begin{lemma} \label{lemma:log_det_seg}
	For any $k>0$,
	\begin{align*}
		\sum_{k'=1}^{k} \log\sbr{ 1+\sum_{i=1}^{m} \nbr{\phi^{\tau^{k'}_i}}_{(\Sigma_{k'-1})^{-1}}^2 } = \log \sbr{ \frac{\det(\Sigma_k)}{\det(\lambda I)} }
		\leq |\cS| |\cA| \log \sbr{ 1+ \frac{  kH^2 }{ \lambda |\cS| |\cA| m } } .
	\end{align*}
\end{lemma}
\begin{proof}
	For any $k>0$, it holds that
	\begin{align*}
		\det(\Sigma_k)&=\det\sbr{\Sigma_{k-1}+ \sum_{i=1}^{m} \phi^{\tau^k_i} (\phi^{\tau^k_i})^\top}
		\\
		&=\det(\Sigma_{k-1}) \det\sbr{ I + \sum_{i=1}^{m} (\Sigma_{k-1})^{-\frac{1}{2}}   \phi^{\tau^k_i} (\phi^{\tau^k_i})^\top  (\Sigma_{k-1})^{-\frac{1}{2}} }
		\\
		&=\det(\Sigma_{k-1}) \sbr{ 1+ \sum_{i=1}^{m} \nbr{\phi^{\tau^k_i}}_{(\Sigma_{k-1})^{-1}}^2 }
		\\
		&=\det(\lambda I) \prod_{k'=1}^{k} \sbr{ 1+ \sum_{i=1}^{m} \nbr{\phi^{\tau^{k'}_i}}_{(\Sigma_{k'-1})^{-1}}^2 } .
	\end{align*}
	
	Taking the logarithm on both sides, we have
	\begin{align*}
		\log \det(\Sigma_k) = \log \det(\lambda I) +  \sum_{k'=1}^{k} \log\sbr{ 1+ \sum_{i=1}^{m} \nbr{\phi^{\tau^{k'}_i}}_{(\Sigma_{k'-1})^{-1}}^2 } .
	\end{align*}
	Then,
	\begin{align*}
		\sum_{k'=1}^{k} \log\sbr{ 1+\sum_{i=1}^{m} \nbr{\phi^{\tau^{k'}_i}}_{(\Sigma_{k'-1})^{-1}}^2 } &= \log \sbr{ \frac{\det(\Sigma_k)}{\det(\lambda I)} }
		\\
		&\overset{\textup{(a)}}{\leq} \log \sbr{ \frac{\sbr{ \frac{\trace(\Sigma_k)}{|\cS| |\cA|}}^{|\cS| |\cA|} }{ \lambda^{|\cS| |\cA|} } }
		\\
		&= |\cS| |\cA| \log \sbr{ \frac{  \trace(\Sigma_k) }{ \lambda |\cS| |\cA| } }
		\\
		&\leq |\cS| |\cA| \log \sbr{ \frac{ \lambda |\cS| |\cA| + km \cdot \frac{H^2}{m^2} }{ \lambda |\cS| |\cA| } }
		\\
		&= |\cS| |\cA| \log \sbr{ 1+\frac{ kH^2 }{ \lambda |\cS| |\cA| m } } ,
	\end{align*}
	where (a) uses the arithmetic mean-geometric mean inequality.
\end{proof}


\begin{lemma}[Elliptical Potential with Optimized Initialization]\label{lemma:ellip_potent_with_opt_init_seg}
	Assume that event $\cJ$ holds. 
	Then, for any $k \geq K_0+1$,
	\begin{align*}
		\sum_{i=1}^{m} \nbr{ \phi^{\tau^k_i}}_{(\Sigma_{k-1})^{-1}}^2 \leq 1 .
	\end{align*}
	Furthermore, for any $K\geq K_0+1$,
	\begin{align*}
		\sum_{k=K_0+1}^{K} \sum_{i=1}^{m} \nbr{ \phi^{\tau^k_i}}_{(\Sigma_{k-1})^{-1}} \leq \sqrt{2Km |\cS| |\cA| \log \sbr{ 1+ \frac{  KH^2 }{ \lambda |\cS| |\cA|m } }} .
	\end{align*}
\end{lemma}
\begin{proof}
	Using Lemma~\ref{lemma:seg_e_optimal_design}, for any $k\geq K_0+1$, we have
	\begin{align*}
		\sum_{i=1}^{m} \nbr{ \phi^{\tau^k_i}}_{(\Sigma_{k-1})^{-1}}^2 &= \sum_{i=1}^{m} \nbr{ \phi^{\tau^k_i}}_{\sbr{\lambda I + \sum_{k'=1}^{K_0} \phi^{\tau^{k'}} (\phi^{\tau^{k'}})^\top + \sum_{k'=K_0+1}^{k-1} \phi^{\tau^{k'}} (\phi^{\tau^{k'}})^\top }^{-1}}^2
		\\
		&\leq \sum_{i=1}^{m} \nbr{ \phi^{\tau^i_i} }_{\sbr{ \sum_{k'=1}^{K_0} \phi^{\tau^{k'}} (\phi^{\tau^{k'}})^\top }^{-1}}^2
		\\
		&\leq m \cdot \frac{H^2}{m^2} \cdot \frac{1}{H^2}
		\\
		&\leq 1 .
	\end{align*}
	
	Then, we have
	\begin{align*}
		\sum_{k=K_0+1}^{K} \sum_{i=1}^{m} \nbr{ \phi^{\tau^k_i}}_{(\Sigma_{k-1})^{-1}} &\leq \sqrt{ K m \sum_{k=K_0+1}^{K} \sum_{i=1}^{m} \nbr{ \phi^{\tau^k_i}}_{(\Sigma_{k-1})^{-1}}^2 }
		\\
		&\overset{\textup{(a)}}{\leq} \sqrt{ K m \cdot 2 \sum_{k=K_0+1}^{K} \log \sbr{ 1 +  \sum_{i=1}^{m} \nbr{ \phi^{\tau^k_i}}_{(\Sigma_{k-1})^{-1}}^2 } }
		\\
		&\leq \sqrt{ K m \cdot 2 \sum_{k=1}^{K} \log \sbr{ 1 +  \sum_{i=1}^{m} \nbr{ \phi^{\tau^k_i}}_{(\Sigma_{k-1})^{-1}}^2 } }
		\\
		&\overset{\textup{(b)}}{\leq} \sqrt{2K m |\cS| |\cA| \log \sbr{ 1+ \frac{ KH^2 }{ \lambda |\cS| |\cA|m } }} ,
	\end{align*}
	where (a) uses the fact that $x \leq 2\log(1+x)$ for any $x \in [0,1]$, and (b) follows from Lemma~\ref{lemma:log_det_seg}.
\end{proof}

Define event 
\begin{align}
	\cK\!:=\!\lbr{ \nbr{\hat{\theta}_{k} \!-\! \theta^*}_{\Sigma_{k}} \!\leq\! \sqrt{ \frac{H |\cS||\cA|}{m} \log\sbr{1 \!+\! \frac{kH^2}{\lambda|\cS||\cA|m}} \!+\! 2\log\sbr{\frac{1}{\delta'}} } \!+\! r_{\max}\sqrt{\lambda|\cS||\cA|} ,\  \forall k>0 }\! . \label{eq:concentration_theta_seg}
\end{align}

\begin{lemma}[Concentration of $\hat{\theta}_k$ under Sum Feedback] 
	It holds that
	\begin{align*}
		\Pr \mbr{ \cK } \geq 1-\delta' .
	\end{align*}
\end{lemma}
\begin{proof}
	Since the sum feedback on each segment is $\frac{H}{m}$-sub-Gaussian given the observation of transition and $\|\theta^*\|\leq r_{\max}\sqrt{|\cS| |\cA|}$, using Lemma 2 in \cite{abbasi2011improved}, we can obtain this lemma.
\end{proof}

Define event 
\begin{align}
	&\cF^{\summing}_{\textup{opt}}:=\Bigg\{ \abr{\sum_{k'=K_0+1}^{k} \sbr{ \ex_{\tau \sim \pi^{k'}}\mbr{ \nbr{ \phi^{\tau}}_{(\Sigma_{k'-1})^{-1}} | F_{k'-1}} - \nbr{ \phi^{\tau}}_{(\Sigma_{k'-1})^{-1}} } } 
	\nonumber\\
	&\hspace*{5em} \leq 4\sqrt{ k \log\sbr{\frac{4k}{\delta'}} } ,\ \forall k \geq K_0+1 \Bigg\} . \label{eq:def_martingale}
\end{align}

\begin{lemma}[Concentration of Visitation Indicators] 
	It holds that
	\begin{align*}
		\Pr \mbr{ \cF^{\summing}_{\textup{opt}} } \geq 1-\delta' .
	\end{align*}
\end{lemma}
\begin{proof}
	According to Lemma~\ref{lemma:ellip_potent_with_opt_init_seg}, we have that for any $k'\geq K_0+1$, $\nbr{ \phi^{\tau}}_{(\Sigma_{k'-1})^{-1}} \leq 1$, and then $|\ex_{\tau \sim \pi^{k'}} [\nbr{ \phi^{\tau}}_{(\Sigma_{k'-1})^{-1}} | F_{k'-1}] - \nbr{ \phi^{\tau}}_{(\Sigma_{k'-1})^{-1}}| \leq 2$. 
	
	
	Using the Azuma-Hoeffding inequality, we have that for any fixed $k \geq K_0+1$, with probability at least $1-\frac{\delta'}{2k^2}$,
	\begin{align*}
		\abr{\sum_{k'=K_0+1}^{k} \!\! \sbr{ \ex_{\tau \sim \pi^{k'}}\mbr{ \nbr{ \phi^{\tau}}_{(\Sigma_{k'-1})^{-1}} | F_{k'-1}} \!-\! \nbr{ \phi^{\tau}}_{(\Sigma_{k'-1})^{-1}} } } &\leq \sqrt{ 2 \cdot 4 (k-K_0-1) \log\sbr{\frac{4k^2}{\delta'}} } .
	\end{align*}
	
	Since $\sum_{k=K_0+1}^{\infty} \frac{\delta'}{2k^2} \leq \delta'$, by a union bound over $k$, we have that with probability at least $\delta'$, for any $k\geq K_0+1$,
	\begin{align*}
		\abr{\sum_{k'=K_0+1}^{k} \sbr{ \ex_{\tau \sim \pi^{k'}}\mbr{ \nbr{ \phi^{\tau}}_{(\Sigma_{k'-1})^{-1}} | F_{k'-1}} - \nbr{ \phi^{\tau}}_{(\Sigma_{k'-1})^{-1}} } } &\leq \sqrt{ 2 \cdot 4 (k-K_0-1) \log\sbr{\frac{4k^2}{\delta'}} } 
		\\
		&\leq 4 \sqrt{ k \log\sbr{\frac{4k}{\delta'}} } .
	\end{align*}
\end{proof}


\begin{proof}[Proof of Theorem~\ref{thm:ub_sum_known_tran}]
	Let $\delta'=\frac{\delta}{3}$. We have $\Pr[\cJ \cap \cK \cap \cF^{\summing}_{\textup{opt}}] \geq 1-\delta$.
	To prove this theorem, it suffices to prove the regret bound when event $\cJ \cap \cK \cap \cF^{\summing}_{\textup{opt}}$ holds. 
	
	Assume that event $\cJ \cap \cK \cap \cF^{\summing}_{\textup{opt}}$ holds.
	Then, we have
	\begin{align}
		\cR(K) &= \sum_{k=1}^{K} \sbr{ (\phi^{\pi^*})^\top \theta - (\phi^{\pi^k})^\top \theta }
		\nonumber\\
		&\overset{\textup{(a)}}{\leq} \sum_{k=K_0+1}^{K} \sbr{ (\phi^{\pi^*})^\top \hat{\theta}_{k-1} + \beta(k-1) \cdot \| \phi^{\pi^*} \|_{(\Sigma_{k-1})^{-1}}  - (\phi^{\pi^k})^\top \theta } + K_0 H
		\nonumber\\
		&\overset{\textup{(b)}}{\leq} \sum_{k=K_0+1}^{K} \sbr{ (\phi^{\pi^k})^\top \hat{\theta}_{k-1} + \beta(k-1) \cdot \| \phi^{\pi^k} \|_{(\Sigma_{k-1})^{-1}}  - (\phi^{\pi^k})^\top \theta } + K_0 H
		\nonumber\\
		&\leq \sum_{k=K_0+1}^{K} 2 \beta(k-1) \cdot \| \phi^{\pi^k} \|_{(\Sigma_{k-1})^{-1}} + K_0 H
		\nonumber\\
		&=  2 \beta(K)  \sum_{k=K_0+1}^{K} \nbr{ \ex_{\tau \sim \pi^k}\mbr{\phi^{\tau}| F_{k-1}} }_{(\Sigma_{k-1})^{-1}} + K_0 H
		\nonumber\\
		&\overset{\textup{(c)}}{\leq}  2 \beta(K)  \sum_{k=K_0+1}^{K} \ex_{\tau \sim \pi^k}\mbr{ \nbr{ \phi^{\tau}}_{(\Sigma_{k-1})^{-1}} | F_{k-1}} + K_0 H
		\nonumber\\
		&=  2 \beta(K) \!\!\!\!\!\! \sum_{k=K_0+1}^{K} \!\!\!\!\! \sbr{ \ex_{\tau \sim \pi^k}\mbr{ \nbr{ \phi^{\tau}}_{(\Sigma_{k-1})^{-1}} | F_{k-1}} \!-\! \nbr{ \phi^{\tau}}_{(\Sigma_{k-1})^{-1}} \!+\! \nbr{ \phi^{\tau}}_{(\Sigma_{k-1})^{-1}} } \!+\! K_0 H
		\nonumber\\
		&\leq  2 \beta(K) \!\!\!\! \sum_{k=K_0+1}^{K} \!\!\! \sbr{ \ex_{\tau \sim \pi^k}\mbr{ \nbr{ \phi^{\tau}}_{(\Sigma_{k-1})^{-1}} | F_{k-1}} \!-\! \nbr{ \phi^{\tau}}_{(\Sigma_{k-1})^{-1}} \!+\! \sum_{i=1}^{m} \nbr{ \phi^{\tau^k_i}}_{(\Sigma_{k-1})^{-1}} } 
		\nonumber\\
		&\quad + K_0 H , \label{eq:regret_decomposition_seg}
	\end{align}
	where inequality (a) follows from Eq.~\eqref{eq:concentration_theta_seg}, inequality (b) is due to the definition of $\pi^k$, and inequality (c) uses the Jensen inequality.
	
	Plugging  Eq.~\eqref{eq:def_martingale} and Lemma~\ref{lemma:ellip_potent_with_opt_init_seg} into Eq.~\eqref{eq:regret_decomposition_seg} and using the fact that $\lambda:=\frac{H}{r_{\max}^2 m}$, we have
	\begin{align*}
		\cR(K) & \leq 2 \sbr{ \sqrt{\frac{H|\cS||\cA|}{m}\log\sbr{1+\frac{KH^2}{\lambda|\cS||\cA|m}} + 2\log\sbr{\frac{1}{\delta'}}} + r_{\max}\sqrt{\lambda|\cS||\cA|} } \cdot
		\\
		&\quad \sbr{ 4\sqrt{ K \log\sbr{\frac{4K}{\delta}} } + \sqrt{2Km |\cS| |\cA| \log \sbr{ 1+\frac{  KH^2 }{ \lambda |\cS| |\cA|m } }} } 
		\\ 
		&\quad + H \left\lceil \max\lbr{ 26H^4 (1+\gamma)^2 (z^*)^2  \log\sbr{\frac{2|\cS||\cA|}{\delta'}} ,\ \frac{|\cS||\cA|}{\gamma^2} } \right\rceil
		\\
		&= O\!\sbr{ |\cS| |\cA| \sqrt{HK} \log\sbr{\sbr{1+\frac{KH r_{\max}^2}{|\cS||\cA|m}}  \frac{1}{\delta}} \!+\!   (z^*)^2 H^5 \log\sbr{\frac{|\cS||\cA|}{\delta}} \!+\! |\cS||\cA|H } \!.
	\end{align*}
\end{proof}

\subsection{Proof for the Regret Lower Bound with Known Transition}

Now we prove the regret lower bound (Theorem~\ref{thm:lb_sum_known_tran}) for RL with sum segment feedback and known transition.

\begin{proof}[Proof of Theorem~\ref{thm:lb_sum_known_tran}]
	\begin{figure}[t]
		\centering   
		\includegraphics[width=0.7\textwidth]{fig/lower_bound_crop.pdf}
		\caption{Instance for the lower bound under sum segment feedback and known transition.
		} \label{fig:lb_sum_known_tran}
	\end{figure}
	
	We construct a random instance $\cI$ as follows. As shown in Figure~\ref{fig:lb_sum_known_tran},
	there are $n$ bandit states $s_1,\dots,s_n$ (i.e., there is an optimal action and multiple suboptimal actions), a good absorbing state $s_{n+1}$ and a bad absorbing state $s_{n+2}$. 
	The agent starts from $s_1,\dots,s_n$ with equal probability $\frac{1}{n}$. 
	For any $i \in [n]$, in state $s_i$, one action $a_J$ is uniformly chosen from $\cA$ as the optimal action.
	In state $s_i$, under the optimal action $a_J$, the agent transitions to $s_{n+1}$ deterministically, and $r(s_i,a_J)=(\frac{1}{2}+\varepsilon)r_{\max}$, where $\varepsilon \in (0,\frac{1}{2}]$ is a parameter specified later; Under any suboptimal action $a \in \cA \setminus \{s_J\}$, the agent transitions to $s_{n+2}$ deterministically, and $r(s_i,a)=\frac{1}{2}r_{\max}$. 
	For all actions $a \in \cA$, $r(s_{n+1},a)=(\frac{1}{2}+\varepsilon)r_{\max}$ and $r(s_{n+2},a)=\frac{1}{2}r_{\max}$.
	For any $(s,a) \in \cS \times \cA$, the reward distribution of $(s,a)$ is Gaussian distribution $\cN(r(s,a),1)$.
	
	In this proof, we will also use an alternative uniform instance $\cI_{\unif}$. The only difference between $\cI_{\unif}$ and $\cI$ is that for any $i \in [n]$, in state $s_i$, under all actions $a \in \cA$, the agent transitions to $s_{n+2}$ deterministically, and $r(s_i,a)=\frac{1}{2}r_{\max}$.
	
	Fix an algorithm $\A$.
	Let $\ex_{\unif}[\cdot]$ denote the expectation with respect to $\cI_{\unif}$. Let $\ex_*[\cdot]$ denote the expectation with respect to $\cI$. For any $i \in [n]$ and $j \in [|\cA|]$, let $\ex_{i,j}[\cdot]$ denote the expectation with respect to the case where $a_j$ is the optimal action in state $s_i$, and  $N_{i,j}$ denote the number of episodes where algorithm $\A$ chooses $a_j$ in state $s_i$, i.e., $N_{i,j}=\sum_{k=1}^{K} \indicator\{\pi^k_1(s_i)=a_j\}$. 
	

	The KL divergence of the reward observations if taking $a_J$ in $s_i$ ($i \in [n]$) between $\cI_{\unif}$ and $\cI$ is 
	\begin{align*}
		& \quad \sum_{i=1}^{m} \kl \sbr{ \cN\sbr{ \frac{1}{2} r_{\max} \cdot \frac{H}{m},\ \frac{H}{m}} \Big\| \cN\sbr{\sbr{\frac{1}{2}+\varepsilon} r_{\max} \cdot \frac{H}{m},\ \frac{H}{m}} } 
		\\
		&=  m \cdot \frac{ \sbr{\frac{H}{m} \cdot r_{\max} \varepsilon}^2 }{\frac{H}{m}}
		\\
		&=  H r_{\max}^2 \varepsilon^2 .
	\end{align*}  
	In addition, the agent has probability only $\frac{1}{n}$ to arrive at (observe) state $s_i$.
	
	Hence, using Lemma A.1 in \cite{auer2002nonstochastic}, we have that for any $i \in [n]$, in state $s_i$,
	\begin{align*}
		\ex_{i,j}[N_{i,j}] &\leq  \ex_{\unif}[N_{i,j}] + \frac{K}{2} \sqrt{ \frac{1}{n} \cdot \ex_{\unif}[N_{i,j}] \cdot H r_{\max}^2 \varepsilon^2 } .
	\end{align*}
	
	Summing over $j \in [|\cA|]$, using the Cauchy-Schwarz inequality and the fact that $\sum_{j=1}^{|\cA|} \ex_{\unif}[N_{i,j}]=K$, we have
	\begin{align*}
		\sum_{j=1}^{|\cA|}  \ex_{i,j}[N_{i,j}] &\leq K + \frac{K}{2} \sqrt{ \frac{|\cA|}{n} \cdot K \cdot H r_{\max}^2 \varepsilon^2 } 
		\\
		&= K + \frac{K r_{\max} \varepsilon}{2} \sqrt{ \frac{|\cA|HK}{n} } .
	\end{align*}
	Then, we have
	\begin{align*}
		\cR(K) &= \sum_{k=1}^{K} \ex_{*}\mbr{V^*-V^{\pi^k}}
		\\
		&=\sbr{\frac{1}{2}+\varepsilon} r_{\max}HK - \frac{1}{n} \sum_{i=1}^{n} \sbr{ \frac{1}{2}r_{\max}HK + \varepsilon r_{\max} H \cdot \frac{1}{|\cA|} \sum_{j=1}^{|\cA|} \ex_{i,j}[N_{i,j}] }
		\\
		&= \varepsilon r_{\max} H \sbr{K - \frac{K}{|\cA|} - \frac{K r_{\max} \varepsilon}{2} \sqrt{ \frac{HK}{n |\cA|} } } .
	\end{align*}
	
	Recall that $n=|\cS|-2$.
	Let $|\cS| \geq 3$, $|\cA|\geq 2$, $K\geq \frac{n |\cA|}{r_{\max}^2 H}$ and $\varepsilon=\frac{1}{2r_{\max}}\sqrt{\frac{n |\cA|}{HK}}$. Then, we have 
	\begin{align*}
		\cR(K) 
		=\Omega\sbr{ \sqrt{|\cS||\cA|HK} } .
	\end{align*}
\end{proof}

\subsection{Pseudo-code and Detailed Description of Algorithm $\linucbtranseg$} \label{apx:alg_sum_unknown_tran}

\begin{algorithm}[t]
	\caption{$\linucbtranseg$} \label{alg:linucb_tran_bonus_seg}
	\begin{algorithmic}[1]
	\STATE {\bfseries Input:} $\delta,\delta':=\frac{\delta}{4},\lambda:=\frac{H}{m},L:=\log(\frac{3|\cS||\cA|H}{\delta'})+S\log(8e(1+KH))$. For any $k\geq1$, $\beta(k):=\sqrt{\frac{H|\cS||\cA|}{m} \log(1+\frac{kH^2}{\lambda|\cS||\cA|m})+2\log(\frac{1}{\delta'})} + r_{\max} \sqrt{\lambda|\cS||\cA|}$.
	%	Initialize $\hat{\theta}_0=\mathbf{0}$ and $\Sigma_0=\lambda I$\;
	\FOR{$k=1,\dots,K$}
		\STATE $\hat{\theta}_{k-1} \leftarrow (\lambda I + \sum_{k'=1}^{k-1} \sum_{i=1}^{m} \phi^{\tau^{k'}_i} (\phi^{\tau^{k'}_i})^\top)^{-1} \sum_{k'=1}^{k-1} \sum_{i=1}^{m} \phi^{\tau^{k'}_i} R^{k'}_i$\; \label{line:hat_theta_linucb_tran}
		\STATE $\Sigma_{k-1} \leftarrow \lambda I + \sum_{k'=1}^{k-1} \sum_{i=1}^{m} \phi^{\tau^{k'}_i} (\phi^{\tau^{k'}_i})^\top$\; \label{line:Sigma_linucb_tran}
		\STATE $\pi^k \!\leftarrow\! \argmax_{\pi \in \Pi} ((\hat{\phi}_{k-1}^{\pi})^\top \hat{\theta}_{k-1} + \beta(k-1) \cdot  \|\hat{\phi}_{k-1}^{\pi}\|_{(\Sigma_{k-1})^{-1}} + \sum_{s',a'}\! \ex_{s_1 \sim \rho}[B^{\pi;s',a';k}_1\!(s_1)] )$, where $B^{\pi;s',a';k}_1(s_1)$ is defined in Eq.~\eqref{eq:def_tran_bonus}\; \label{line:pi_k_linucb_tran}
		\STATE Play episode $k$ with policy $\pi^k$. Observe $\tau^k$ and sum segment feedback $\{R^k_i\}_{i=1}^{m}$\; \label{line:play_linucb_tran}
	\ENDFOR	
	\end{algorithmic}
\end{algorithm}

Algorithm~\ref{alg:linucb_tran_bonus_seg} presents the pseudo-code of $\linucbtranseg$.
In each episode $k$, similar to algorithm $\edlinucbseg$, $\linucbtranseg$ first computes the least squares estimate of the reward parameter $\hat{\theta}_{k-1}$ and  covariance matrix $\Sigma_{k-1}$ with past observations (Lines~\ref{line:hat_theta_linucb_tran}-\ref{line:Sigma_linucb_tran}).

Then, we introduce the transition estimation in $\linucbtranseg$.
We first define some notation which also appears in algorithm $\bitssegtran$.
For any $k>0$ and $(s,a) \in \cS \times \cA$, let $\hat{p}_{k}(\cdot|s,a)$ denote the empirical estimate of $p(\cdot|s,a)$, and $n_{k}(s,a)$ denote the number of times $(s,a)$ was visited up to the end of episode $k$.
In addition, for any policy $\pi$, let $\hat{\phi}_{k}^{\pi}(s,a)$ denote the expected number of times $(s,a)$ is visited in an episode under policy $\pi$ on empirical MDP $\hat{p}_{k-1}$ (see Eq.~\eqref{eq:def_hat_phi} for the formal definition). 

Below we establish a bound for the deviation between  $\hat{\phi}_{k-1}^{\pi}$ and $\phi^{\pi}$. 
For ease of analysis, we first connect $\phi^{\pi}$ with a newly-defined visitation value function $G^{\pi;s',a'}_h(s;p)$. 
For any transition model $p'$, policy $\pi$ and $(s',a') \in \cS \times \cA$, if regarding hitting $(s',a')$ as an instantaneous reward one, then we can define a visitation value function:
\begin{equation}
	\left\{\begin{matrix}
		G^{\pi;s',a'}_h(s;p') =& \indicator\{ s=s', \pi_h(s)=a' \} + p(\cdot|s,\pi_h(s))^\top G^{\pi;s',a'}_{h+1}(\cdot) , \hspace*{0.5em} \forall s \in \cS,\ \forall h \in [H] ,
		\\
		G^{\pi;s',a'}_{H+1}(s;p') =& 0 , \hspace*{15.7em} \forall s \in \cS . \label{eq:visit_value_function}
	\end{matrix}\right. 
\end{equation}
$G^{\pi;s',a'}_h(s;p')$ denotes the expected cumulative number of times $(s',a')$ was hit starting from $s$ at step $h$ under policy $\pi$ on MDP $p'$,  till the end of this episode. It holds that $\phi^{\pi}(s',a')=\ex_{s_1 \sim \rho}[G^{\pi;s',a'}_1(s_1|p)]$ and $\hat{\phi}_{k-1}^{\pi}(s',a')=\ex_{s_1 \sim \rho}[G^{\pi;s',a'}_1(s_1|\hat{p}_{k-1})]$ for any $(s',a') \in \cS \times \cA$.

With the definition of $G^{\pi;s',a'}_h$, bounding the deviation between $\hat{\phi}_{k-1}^{\pi}$ and $\phi^{\pi}$ is similar to bounding the gap between the estimated and true value functions. Then, we can build a Bernstern-type uncertainty bound between $\hat{\phi}_{k-1}^{\pi}$ and $\phi^{\pi}$ using the variance of $G^{\pi;s',a'}_h$.
For any policy $\pi$, $(s',a') \in \cS \times \cA$ and $k>0$, define
\begin{equation}
	\left\{\begin{matrix}
		B^{\pi;s',a';k}_h(s)=& \hspace*{-5em} \min\bigg\{ \Big( 4\sqrt{\frac{ \var_{\hat{p}_{k-1}(\cdot|s,\pi_h(s))}(G^{\pi;s',a'}_{h+1}(\cdot|\hat{p}_{k-1})) \cdot L}{{n_{k-1}(s,\pi_h(s))}}}  + \frac{13H^2L}{n_{k-1}(s,\pi_h(s))} 
		\\& + \sbr{1+\frac{2}{H}} \hat{p}_{k-1}(\cdot|s,\pi_h(s))^\top B^{\pi;s',a';k}_{h+1}(\cdot) \Big) ,\ H \bigg\} , \hspace*{1em} \forall s \in \cS , \ \forall h \in [H] ,
		\\
		B^{\pi;s',a';k}_{H+1}(s)=&0 , \hspace*{15.7em} \forall s \in \cS .
	\end{matrix}\right. \label{eq:def_tran_bonus}
\end{equation}
The construction of $B^{\pi;s',a';k}_h(s)$ satisfies (see Lemma~\ref{lemma:error_in_visitation} for more details) 
\begin{align*}
	|\hat{\phi}_{k-1}^{\pi}(s',a')-\phi^{\pi}(s',a')| &\leq \ex_{s_1 \sim \rho}\mbr{B^{\pi;s',a';k}_1(s_1)}, \quad \forall (s',a') \in \cS \times \cA ,
	\\
	\|\hat{\phi}_{k-1}^{\pi} - \phi^{\pi}\|_1 &\leq \sum_{(s',a')} \ex_{s_1 \sim \rho}\mbr{B^{\pi;s',a';k}_1(s_1)} .
\end{align*} 
Incorporating this transition uncertainty $\ex_{s_1 \sim \rho}[B^{\pi;s',a';k}_1(s_1)]$ and reward uncertainty $\|\hat{\phi}_{k-1}^{\pi}\|_{(\Sigma_{k-1})^{-1}}$ into exploration bonuses, $\linucbtranseg$ computes the optimal policy $\pi^k$ under optimistic estimation (Line~\ref{line:pi_k_linucb_tran}). After that, $\linucbtranseg$ plays episode $k$ with $\pi^k$, and collects trajectory $\tau^k$ and reward observation on each segment $\{R^k_i\}_{i=1}^{m}$ (Line~\ref{line:play_linucb_tran}).


\subsection{Proof for the Regret Upper Bound with Unknown Transition} \label{apx:ub_sum_unknown_tran}

In the following, we prove the regret upper bound (Theorem~\ref{thm:ub_sum_unknown_tran}) of algorithm $\linucbtranseg$ for unknown transition.

Recall the definition of events $\cG_{\textup{KL}}$ and $\cH$ in Eqs.~\eqref{eq:def_event_tran_kl} and \eqref{eq:def_event_visitation_bernoulli}, respectively.

For any $k>0$, define the set of state-action pairs  
\begin{align}
	D_k:=\lbr{ (s,a) \in \cS \times \cA:\  \frac{1}{4} \sum_{k'=1}^{k} w_{k'}(s,a) \geq H \log\sbr{\frac{|\cS||\cA|H}{\delta'}} + H } . \label{eq:def_B_k}
\end{align}
$D_k$ stands for the set of state-action pairs which have sufficient visitations in expectation.

\begin{lemma}\label{lemma:B_k_con_visit}
	Assume that event $\cH$ holds. Then, if $(s,a) \in D_k$, 
	\begin{align*}
		n_{k-1}(s,a) \geq \frac{1}{4} \sum_{k'=1}^{k} w_{k'}(s,a) .
	\end{align*}
\end{lemma}
\begin{proof}
	We have
	\begin{align*}
		n_{k-1}(s,a) &\geq \frac{1}{2} \sum_{k'=1}^{k-1} w_{k'}(s,a) - H \log\sbr{\frac{|\cS||\cA|H}{\delta'}} 
		\\
		&= \frac{1}{4} \sum_{k'=1}^{k-1} w_{k'}(s,a) + \frac{1}{4} \sum_{k'=1}^{k-1} w_{k'}(s,a) - H \log\sbr{\frac{|\cS||\cA|H}{\delta'}}
		\\
		&= \frac{1}{4} \sum_{k'=1}^{k} w_{k'}(s,a) + \frac{1}{4} \sum_{k'=1}^{k} w_{k'}(s,a) - H \log\sbr{\frac{|\cS||\cA|H}{\delta'}} - \frac{1}{2} w_{k}(s,a)
		\\
		&\overset{\textup{(a)}}{\geq} \frac{1}{4} \sum_{k'=1}^{k} w_{k'}(s,a) + H - \frac{1}{2} w_{k}(s,a)
		\\
		&\geq \frac{1}{4} \sum_{k'=1}^{k} w_{k'}(s,a) ,
	\end{align*}
	where (a) is due to the definition of $D_k$ (Eq.~\eqref{eq:def_B_k}).
\end{proof}

\begin{lemma} \label{lemma:regret_notin_D_k}
	It holds that
	\begin{align*}
		\sum_{k=1}^{K} \sum_{h=1}^{H} \sum_{(s,a) \notin D_k} w_{k,h}(s,a) \leq 8|\cS||\cA|H \log\sbr{\frac{|\cS||\cA|H}{\delta'}} .
	\end{align*}
\end{lemma}
\begin{proof}
	If $(s,a) \notin D_k$, then
	\begin{align*}
		\frac{1}{4} \sum_{k'=1}^{k} w_{k'}(s,a) < H \log\sbr{\frac{|\cS||\cA|H}{\delta'}} + H .
	\end{align*}
	Thus, we have
	\begin{align*}
		\sum_{k=1}^{K} \sum_{h=1}^{H} \sum_{(s,a) \notin D_k} w_{k,h}(s,a) &= \sum_{(s,a)} \sum_{k=1}^{K} \sum_{h=1}^{H} \indicator\{ (s,a) \notin D_k \} \cdot w_{k,h}(s,a)
		\\
		&= \sum_{(s,a)} \sum_{k=1}^{K} \indicator\{ (s,a) \notin D_k \} \cdot w_{k}(s,a)
		\\
		&\leq 4|\cS||\cA|H \log\sbr{\frac{|\cS||\cA|H}{\delta'}} + 4|\cS||\cA|H 
		\\
		&\leq 8|\cS||\cA|H \log\sbr{\frac{|\cS||\cA|H}{\delta'}} .
	\end{align*}
	
\end{proof}

\begin{lemma} \label{lemma:visitation_ratio}
	Assume that event $\cH$ holds. Then, we have
	\begin{align*}
		\sum_{k=1}^{K} \sum_{h=1}^{H} \sum_{(s,a) \in D_k} \frac{w_{k,h}(s,a)}{n_{k-1}(s,a)} \leq 4 |\cS| |\cA| \log(2KH) .
	\end{align*}
\end{lemma}
\begin{proof}
	It holds that
	\begin{align*}
		\sum_{k=1}^{K} \sum_{h=1}^{H} \sum_{(s,a) \in D_k} \frac{w_{k,h}(s,a)}{n_{k-1}(s,a)} &= \sum_{k=1}^{K}  \sum_{(s,a) \in D_k} \frac{w_{k}(s,a)}{n_{k-1}(s,a)}
		\\
		&= \sum_{k=1}^{K}  \sum_{(s,a)} \frac{w_{k}(s,a)}{n_{k-1}(s,a)} \cdot \indicator\{ (s,a) \in D_k \}
		\\
		&\overset{\textup{(a)}}{\leq} 4 \sum_{k=1}^{K}  \sum_{(s,a)} \frac{w_{k}(s,a)}{\sum_{k'=1}^{k} w_k(s,a)} \cdot \indicator\{ (s,a) \in D_k \}
		\\
		&= 4 \sum_{(s,a)} \sum_{k=1}^{K} \frac{w_{k}(s,a)}{\sum_{k'=1}^{k} w_k(s,a)} \cdot \indicator\{ (s,a) \in D_k \}
		\\
		&\overset{\textup{(b)}}{\leq} 4 |\cS| |\cA| \log(2KH) ,
	\end{align*}
	where (a) uses Lemma~\ref{lemma:B_k_con_visit}, and (b) follows from the analysis of Lemma 13 in \cite{zanette2019tighter}.
\end{proof}

\begin{lemma}[Error in Visitation Vectors] \label{lemma:error_in_visitation}
	Assume that event $\cG_{\textup{KL}}$ holds. Then, for any $k>0$ and policy $\pi$,
	\begin{align*}
		\|\hat{\phi}_{k-1}(\pi) -\phi(\pi) \|_1  \leq \sum_{s',a'} \ex_{s_1 \sim \rho}\mbr{B^{\pi;s',a';k}_1(s_1)} .
	\end{align*}
\end{lemma}
\begin{proof}
	Since $\phi^{\pi}(s',a')=\ex_{s_1 \sim \rho}[G^{\pi;s',a'}_1(s_1|p)]$ and $\hat{\phi}_{k-1}^{\pi}(s',a')=\ex_{s_1 \sim \rho}[G^{\pi;s',a'}_1(s_1|\hat{p}_{k-1})]$, in this proof, we investigate the error in $G^{\pi;s',a'}_h$ due to the estimation of the transition model.
	
	In the following, we prove by induction that for any $h 
	\in [H]$ and $s \in \cS$, $|G^{\pi;s',a'}_{h}(s|\hat{p}_{k-1}) - G^{\pi;s',a'}_{h}(s|p)| \leq B^{\pi;s',a';k}_{h}(s)$.
	
	When $h=H+1$, by definition, we have $G^{\pi;s',a'}_{H+1}(s|\hat{p}_{k-1}) = G^{\pi;s',a'}_{H+1}(s|p) = B^{\pi;s',a';k}_{H+1}(s) = 0$ for any $s \in \cS$, and then the above statement trivially holds. 
	
	When $1\leq h \leq H$, if $|G^{\pi;s',a'}_{h+1}(\cdot|\hat{p}_{k-1}) - G^{\pi;s',a'}_{h+1}(\cdot|p)| \leq B^{\pi;s',a';k}_{h+1}(\cdot)$ element-wise, then for any $s \in \cS$, we have 
	\begin{align}
		&\quad |G^{\pi;s',a'}_h(s|\hat{p}_{k-1}) - G^{\pi;s',a'}_h(s|p)| 
		\nonumber\\
		&= \abr{\hat{p}_{k-1}(\cdot|s,\pi_h(s))^\top G^{\pi;s',a'}_{h+1}(\cdot|\hat{p}_{k-1}) - p(\cdot|s,\pi_h(s))^\top G^{\pi;s',a'}_{h+1}(\cdot|p)}
		\nonumber\\
		&= \hat{p}_{k-1}(\cdot|s,\pi_h(s))^\top \abr{G^{\pi;s',a'}_{h+1}(\cdot|\hat{p}_{k-1}) - G^{\pi;s',a'}_{h+1}(\cdot|p) }
		\nonumber\\
		&\quad + \abr{\sbr{\hat{p}_{k-1}(\cdot|s,\pi_h(s)) - p(\cdot|s,\pi_h(s))}^\top G^{\pi;s',a'}_{h+1}(\cdot|p) }
		\nonumber\\
		&\overset{\textup{(a)}}{\leq} \hat{p}_{k-1}(\cdot|s,\pi_h(s))^\top \abr{G^{\pi;s',a'}_{h+1}(\cdot|\hat{p}_{k-1}) - G^{\pi;s',a'}_{h+1}(\cdot|p) } +  2\sqrt{\frac{\var_{p(\cdot|s,\pi_h(s))}(G^{\pi;s',a'}_{h+1}(\cdot|p)) \cdot L}{n_{k-1}(s,\pi_h(s))}} 
		\nonumber\\
		&\quad + \frac{HL}{n_{k-1}(s,\pi_h(s))}  , \label{eq:diff_G_hat_p_G_p}
	\end{align}
	where (a) is due to Lemma~\ref{lemma:bernstern_kl}.
	
	
	Here, we have
	\begin{align*}
		&\quad\ \var_{p(\cdot|s,\pi_h(s))}(G^{\pi;s',a'}_{h+1}(\cdot|p)) \\
		&\overset{\textup{(a)}}{\leq} 2 \var_{\hat{p}_{k-1}(\cdot|s,\pi_h(s))}(G^{\pi;s',a'}_{h+1}(\cdot|p)) + \frac{4H^2L}{n_{k-1}(s,\pi_h(s))}
		\\
		&\overset{\textup{(b)}}{\leq} 4 \var_{\hat{p}_{k-1}(\cdot|s,\pi_h(s))}(G^{\pi;s',a'}_{h+1}(\cdot|\hat{p}_{k-1}))+ 4H \hat{p}_{k-1}(\cdot|s,\pi_h(s))^\top |G^{\pi;s',a'}_{h+1}(\cdot|\hat{p}_{k-1}) - G^{\pi;s',a'}_{h+1}(\cdot|p) | \\& + \frac{4H^2L}{n_{k-1}(s,\pi_h(s))} ,
	\end{align*}
	where (a) uses Lemma~\ref{lemma:var_change_p} and (b) comes from Lemma~\ref{lemma:var_change_f}.
	
	Then,
	\begin{align}
		&\quad\ \sqrt{\frac{\var_{p(\cdot|s,\pi_h(s))}(G^{\pi;s',a'}_{h+1}(\cdot|p)) \cdot L}{n_{k-1}(s,\pi_h(s))}}
		\\
		&\leq \sqrt{\frac{4 \var_{\hat{p}_{k-1}(\cdot|s,\pi_h(s))}(G^{\pi;s',a'}_{h+1}(\cdot|\hat{p}_{k-1})) \cdot L}{{n_{k-1}(s,\pi_h(s))}}} 
		\nonumber\\&\quad +\! \sqrt{\frac{1}{H} \hat{p}_{k-1}(\cdot|s,\pi_h(s))^\top |G^{\pi;s',a'}_{h+1}(\cdot|\hat{p}_{k-1}) \!-\! G^{\pi;s',a'}_{h+1}(\cdot|p) | \cdot  \frac{4H^2L}{{n_{k-1}(s,\pi_h(s))}}} \!+\! \frac{2HL}{n_{k-1}(s,\pi_h(s))}
		\nonumber\\
		&\overset{\textup{(a)}}{\leq} 2\sqrt{\frac{ \var_{\hat{p}_{k-1}(\cdot|s,\pi_h(s))}(G^{\pi;s',a'}_{h+1}(\cdot|\hat{p}_{k-1})) \cdot L}{{n_{k-1}(s,\pi_h(s))}}} 
		\nonumber\\&\quad + \frac{1}{H} \hat{p}_{k-1}(\cdot|s,\pi_h(s))^\top |G^{\pi;s',a'}_{h+1}(\cdot|\hat{p}_{k-1}) - G^{\pi;s',a'}_{h+1}(\cdot|p) |  + \frac{6H^2L}{n_{k-1}(s,\pi_h(s))} , \label{eq:var_G_p}
	\end{align}
	where (a) is due to the fact that $\sqrt{xy} \leq x+y$.
	
	Hence, plugging Eq.~\eqref{eq:var_G_p} into Eq.~\eqref{eq:diff_G_hat_p_G_p} and using the fact that $|G^{\pi;s',a'}_h(s)| \in [0,H]$, we have
	\begin{align*}
		&\quad\ |G^{\pi;s',a'}_h(s|\hat{p}_{k-1}) - G^{\pi;s',a'}_h(s|p)|
		\\
		&\leq \Bigg(4\sqrt{\frac{ \var_{\hat{p}_{k-1}(\cdot|s,\pi_h(s))}(G^{\pi;s',a'}_{h+1}(\cdot|\hat{p}_{k-1})) \cdot L}{{n_{k-1}(s,\pi_h(s))}}}  + \frac{13H^2L}{n_{k-1}(s,\pi_h(s))}
		\\& \quad + \sbr{1+\frac{2}{H}} \hat{p}_{k-1}(\cdot|s,\pi_h(s))^\top \abr{G^{\pi;s',a'}_{h+1}(\cdot|\hat{p}_{k-1}) - G^{\pi;s',a'}_{h+1}(\cdot|p) } \Bigg) \wedge H  .
		\\
		&\leq \Bigg(4\sqrt{\frac{ \var_{\hat{p}_{k-1}(\cdot|s,\pi_h(s))}(G^{\pi;s',a'}_{h+1}(\cdot|\hat{p}_{k-1})) \cdot L}{{n_{k-1}(s,\pi_h(s))}}}  + \frac{13H^2L}{n_{k-1}(s,\pi_h(s))}
		\\& \quad + \sbr{1+\frac{2}{H}} \hat{p}_{k-1}(\cdot|s,\pi_h(s))^\top B^{\pi;s',a';k}_{h+1}(\cdot) \Bigg) \wedge H 
		\\
		&= B^{\pi;s',a';k}_{h}(s) ,
	\end{align*}
	which completes the induction proof.
	
	
	Therefore, 
	\begin{align*}
		\Big|\hat{\phi}_{k-1}^{\pi}(s',a')-\phi^{\pi}(s',a')\Big| 
		&= \abr{ \ex_{s_1 \sim \rho}\mbr{G^{\pi;s',a'}_1(s_1|\hat{p}_{k-1})} - \ex_{s_1 \sim \rho}\mbr{G^{\pi;s',a'}_1(s_1|p)} }
		\\
		&\leq \ex_{s_1 \sim \rho}\mbr { \abr{ G^{\pi;s',a'}_1(s_1|\hat{p}_{k-1}) - G^{\pi;s',a'}_1(s_1|p) } }
		\\
		&\leq \ex_{s_1 \sim \rho}\mbr{B^{\pi;s',a';k}_1(s_1)} .
	\end{align*}
	Summing over $(s',a') \in \cS \times \cA$, we obtain this lemma.
\end{proof}

\begin{lemma}\label{lemma:ub_B}
	Assume that event $\cG_{\textup{KL}} \cap \cH$ holds. Then, for any $k>0$ and policy $\pi$,
	\begin{align*}
		&\ex_{s_1 \sim \rho}\mbr{B^{\pi;s',a';k}_1(s_1)} 
		\\
		&\leq e^{12} \sum_{h=1}^{H} \sum_{s,a}  w^{\pi}_h(s,a)  \sbr{ 8  \sqrt{ \frac{\var_{p(\cdot|s,a)}(G^{\pi;s',a'}_{h+1}(\cdot|p)) \cdot L}{n_{k-1}(s,a)} }  + \frac{46  H^2L}{n_{k-1}(s,a)} } \wedge H ,
	\end{align*}
	and
	\begin{align*}
		&\sum_{s',a'} \sum_{k=1}^{K}  \ex_{s_1 \sim \rho}\mbr{B^{\pi^k;s',a';k}_1(s_1)} 
		\\
		&\leq 16 e^{12} |\cS|^{\frac{3}{2}} |\cA|^{\frac{3}{2}} H \sqrt{K L \log(2KH) } 
		+ 192 e^{12} |\cS|^2 |\cA|^2 H^2 L \log(2KH) .
	\end{align*}
\end{lemma}
\begin{proof}
	First, we prove the first statement.
	
	For any policy $\pi$, $k>0$, $(s',a') \in \cS \times \cA$, $h \in [H]$ and $s \in \cS$, we have
	\begin{align}
		B^{\pi;s',a';k}_h(s) &\leq 4\sqrt{\frac{ \var_{\hat{p}_{k-1}(\cdot|s,\pi_h(s))}(G^{\pi;s',a'}_{h+1}(\cdot|\hat{p}_{k-1})) \cdot L}{{n_{k-1}(s,\pi_h(s))}}}  + \frac{13H^2L}{n_{k-1}(s,\pi_h(s))}
		\nonumber\\& \quad + \sbr{1+\frac{2}{H}} \hat{p}_{k-1}(\cdot|s,\pi_h(s))^\top B^{\pi;s',a';k}_{h+1}(\cdot)
		\nonumber\\
		&= 4\sqrt{\frac{ \var_{\hat{p}_{k-1}(\cdot|s,\pi_h(s))}(G^{\pi;s',a'}_{h+1}(\cdot|\hat{p}_{k-1})) \cdot L}{{n_{k-1}(s,\pi_h(s))}}}  + \frac{13H^2L}{n_{k-1}(s,\pi_h(s))} 
		\nonumber\\& \quad + \sbr{1+\frac{2}{H}} p(\cdot|s,\pi_h(s))^\top B^{\pi;s',a';k}_{h+1}(\cdot) \nonumber\\
		&\quad + \sbr{1+\frac{2}{H}} \sbr{\hat{p}_{k-1}(\cdot|s,\pi_h(s)) - p(\cdot|s,\pi_h(s))}^\top B^{\pi;s',a';k}_{h+1}(\cdot)
		\nonumber\\
		&\overset{\textup{(a)}}{\leq} 4\sqrt{\frac{ \var_{\hat{p}_{k-1}(\cdot|s,\pi_h(s))}(G^{\pi;s',a'}_{h+1}(\cdot|\hat{p}_{k-1})) \cdot L}{{n_{k-1}(s,\pi_h(s))}}}  + \frac{13H^2L}{n_{k-1}(s,\pi_h(s))} 
		\nonumber\\
		&\quad + \sbr{1+\frac{2}{H}} p(\cdot|s,\pi_h(s))^\top B^{\pi;s',a';k}_{h+1}(\cdot) 
		\nonumber\\& \quad +  \sbr{1+\frac{2}{H}} \cdot \sbr{ 2 \sqrt{ \frac{\var_{p(\cdot|s,\pi_h(s))}(B^{\pi;s',a';k}_{h+1}(\cdot)) \cdot L}{n_{k-1}(s,\pi_h(s))}} + \frac{HL}{n_{k-1}(s,\pi_h(s))} }
		\nonumber\\
		&\leq 4\sqrt{\frac{ \var_{\hat{p}_{k-1}(\cdot|s,\pi_h(s))}(G^{\pi;s',a'}_{h+1}(\cdot|\hat{p}_{k-1})) \cdot L}{{n_{k-1}(s,\pi_h(s))}}}  + \frac{13H^2L}{n_{k-1}(s,\pi_h(s))} 
		\nonumber\\
		&\quad + \sbr{1+\frac{2}{H}} p(\cdot|s,\pi_h(s))^\top B^{\pi;s',a';k}_{h+1}(\cdot) 
		\nonumber\\& \quad \!+\! \sbr{1 \!+\! \frac{2}{H}}  \sbr{ 2\sqrt{ \frac{1}{H} p(\cdot|s,\pi_h(s))^\top B^{\pi;s',a';k}_{h+1}(\cdot) \frac{H^2L}{n_{k-1}(s,\pi_h(s)) }} \!+\! \frac{HL}{n_{k-1}(s,\pi_h(s)) } }
		\nonumber\\
		&\overset{\textup{(b)}}{\leq} 4\sqrt{\frac{ \var_{\hat{p}_{k-1}(\cdot|s,\pi_h(s))}(G^{\pi;s',a'}_{h+1}(\cdot|\hat{p}_{k-1})) \cdot L}{{n_{k-1}(s,\pi_h(s))}}}  + \frac{22H^2L}{n_{k-1}(s,\pi_h(s))} 
		\nonumber\\
		&\quad + \sbr{1+\frac{8}{H}} p(\cdot|s,\pi_h(s))^\top B^{\pi;s',a';k}_{h+1}(\cdot) , \label{eq:unfold_B_k}
	\end{align}
	where (a) uses Lemma~\ref{lemma:bernstern_kl}, and (b) follows from the fact that $\sqrt{xy} \leq x + y$.
	
	
	In addition, we have
	\begin{align*}
		&\quad\  \var_{\hat{p}_{k-1}(\cdot|s,\pi_h(s))}(G^{\pi;s',a'}_{h+1}(\cdot|\hat{p}_{k-1})) \\
		&\overset{\textup{(a)}}{=} 2\var_{p(\cdot|s,\pi_h(s))}(G^{\pi;s',a'}_{h+1}(\cdot|\hat{p}_{k-1})) + \frac{4H^2L}{n_{k-1}(s,a)}
		\\
		&\overset{\textup{(b)}}{\leq} 4\var_{p(\cdot|s,\pi_h(s))}(G^{\pi;s',a'}_{h+1}(\cdot|p)) + 4H p(\cdot|s,\pi_h(s))^\top \abr{G^{\pi;s',a'}_{h+1}(\cdot|\hat{p}_{k-1}) - G^{\pi;s',a'}_{h+1}(\cdot|p) } \\& \quad + \frac{4H^2L}{n_{k-1}(s,a)} 
		\\
		&\leq 4\var_{p(\cdot|s,\pi_h(s))}(G^{\pi;s',a'}_{h+1}(\cdot|p)) + 4H p(\cdot|s,\pi_h(s))^\top B^{\pi;s',a'}_{h+1}(\cdot|\hat{p}_{k-1}) + \frac{4H^2L}{n_{k-1}(s,a)} ,
	\end{align*}
	where (a) uses Lemma~\ref{lemma:var_change_p}, and (b) comes from Lemma~\ref{lemma:var_change_f}.
	
	Then,
	\begin{align}
		&\quad\ \sqrt{\frac{ \var_{\hat{p}_{k-1}(\cdot|s,\pi_h(s))}(G^{\pi;s',a'}_{h+1}(\cdot|\hat{p}_{k-1})) \cdot L}{{n_{k-1}(s,\pi_h(s))}}} 
		\nonumber\\
		&\leq \sqrt{ \frac{4\var_{p(\cdot|s,\pi_h(s))}(G^{\pi;s',a'}_{h+1}(\cdot|p)) \cdot L}{n_{k-1}(s,\pi_h(s))} } + \sqrt{ \frac{1}{H} p(\cdot|s,\pi_h(s))^\top B^{\pi;s',a'}_{h+1}(\cdot|\hat{p}_{k-1}) \cdot \frac{4H^2L}{n_{k-1}(s,\pi_h(s))} } 
		\nonumber\\ 
		&\quad\  + \frac{2HL}{n_{k-1}(s,a)}
		\nonumber\\
		&\leq 2\sqrt{ \frac{\var_{p(\cdot|s,\pi_h(s))}(G^{\pi;s',a'}_{h+1}(\cdot|p)) \cdot L}{n_{k-1}(s,\pi_h(s))} } + \frac{1}{H} p(\cdot|s,\pi_h(s))^\top B^{\pi;s',a'}_{h+1}(\cdot|\hat{p}_{k-1}) 
		\nonumber\\ 
		&\quad\ + \frac{6H^2L}{n_{k-1}(s,\pi_h(s))} \label{eq:unfold_B_k_var} 
	\end{align}
	
	Plugging Eq.~\eqref{eq:unfold_B_k_var} into Eq.~\eqref{eq:unfold_B_k} and using the clipping definition of $B^{\pi;s',a';k}_h(s)$, we have
	\begin{align*}
		B^{\pi;s',a';k}_h(s) &\leq \sbr{ 8\sqrt{ \frac{\var_{p(\cdot|s,\pi_h(s))}(G^{\pi;s',a'}_{h+1}(\cdot|p)) \cdot L}{n_{k-1}(s,\pi_h(s))} }  + \frac{46H^2L}{n_{k-1}(s,\pi_h(s))} } \wedge H 
		\\
		&\quad + \sbr{1+\frac{12}{H}} p(\cdot|s,\pi_h(s))^\top B^{\pi;s',a';k}_{h+1}(\cdot)
	\end{align*}
	
	Using the above inequality, taking $s_1 \sim \rho$, and unfolding $B^{\pi;s',a';k}_1(s_1)$ over $h$, we have
	\begin{align}
		&\ex_{s_1 \sim \rho}\mbr{B^{\pi;s',a';k}_1(s_1)} 
		\nonumber\\
		&\leq e^{12} \sum_{h=1}^{H} \sum_{s,a}  w^{\pi}_h(s,a)  \sbr{ 8  \sqrt{ \frac{\var_{p(\cdot|s,a)}(G^{\pi;s',a'}_{h+1}(\cdot|p)) \cdot L}{n_{k-1}(s,a)} }  + \frac{46  H^2L}{n_{k-1}(s,a)} } \wedge H . \label{eq:bound_B}
	\end{align}
	
	Next, we prove the second statement.
	
	It holds that
	\begin{align*}
		&\quad \sum_{s',a'} \sum_{k=1}^{K}  \ex_{s_1 \sim \rho}\mbr{B^{\pi^k;s',a';k}_1(s_1)}
		\\
		&\leq  e^{12} \sum_{s',a'} \sum_{k=1}^{K} \sum_{h=1}^{H} \sum_{(s,a) \in D_k}  w_{k,h}(s,a) \sbr{ 8  \sqrt{ \frac{\var_{p(\cdot|s,a)}(G^{\pi^k;s',a'}_{h+1}(\cdot|p)) \cdot L}{n_{k-1}(s,a)} }  + \frac{46  H^2L}{n_{k-1}(s,a)} }
		\\&\quad + e^{12} H |\cS| |\cA| \sum_{k=1}^{K} \sum_{h=1}^{H} \sum_{(s,a) \notin D_k}  w_{k,h}(s,a)  
		\\
		&\overset{\textup{(a)}}{\leq}  8 e^{12} \sqrt{L} \sum_{s',a'} \sqrt{ \sum_{k=1}^{K} \sum_{h=1}^{H} \sum_{(s,a) \in D_k} w_{k,h}(s,a) \var_{p(\cdot|s,a)}(G^{\pi^k;s',a'}_{h+1}(\cdot|p)) } \cdot 
		\\&\quad \sqrt{ \sum_{k=1}^{K} \sum_{h=1}^{H} \sum_{(s,a) \in D_k} \frac{w_{k,h}(s,a) }{n_{k-1}(s,a)} } 
		+ e^{12} |\cS| |\cA| \cdot 46  H^2L \sum_{k=1}^{K} \sum_{h=1}^{H} \sum_{(s,a) \in D_k}   \frac{w_{k,h}(s,a) }{n_{k-1}(s,a)} 
		\\&\quad + 8 e^{12}  |\cS|^2 |\cA|^2 H^2 \log\sbr{\frac{|\cS||\cA|H}{\delta'}}
		\\
		&\overset{\textup{(b)}}{\leq}  8 e^{12} |\cS| |\cA| \sqrt{L}  \sqrt{K H^2} \cdot \sqrt{ 4 |\cS| |\cA| \log(2KH) } 
		+ 184 e^{12} |\cS|^2 |\cA|^2 H^2 L \log(2KH)  \\&\quad + 8 e^{12} |\cS|^2 |\cA|^2 H^2 \log\sbr{\frac{|\cS||\cA|H}{\delta'}} 
		\\
		&\leq  16 e^{12} |\cS|^{\frac{3}{2}} |\cA|^{\frac{3}{2}} H \sqrt{K L \log(2KH) } 
		+ 192 e^{12} |\cS|^2 |\cA|^2 H^2 L \log(2KH) ,
	\end{align*}
	where (a) is due to Lemma~\ref{lemma:regret_notin_D_k}, and (b) follows from Lemmas~\ref{lemma:law_of_total_variance} and \ref{lemma:visitation_ratio}.
\end{proof}



\begin{lemma}[Optimism under Sum Feedback and Unknown Transition]	\label{lemma:optimism}
	Assume that event $\cG_{\textup{KL}}$ holds. Then, for any $k>0$ and fixed policy $\pi$,
	\begin{align*}
		V^{\pi}_1(s_1) &\leq \hat{\phi}_{k-1}(\pi)^\top \hat{\theta}_{k-1} + \beta(k-1) \cdot  \|\hat{\phi}_{k-1}(\pi)\|_{(\Sigma_{k-1})^{-1}} + r_{\max} \sum_{s',a'} \ex_{s_1 \sim \rho}\mbr{B^{\pi;s',a';k}_1(s_1)} .
	\end{align*}
\end{lemma}
\begin{proof}
	It holds that
	\begin{align*}
		V^{\pi}_1(s_1) &= \phi(\pi)^\top \theta 
		\\
		&= \hat{\phi}_{k-1}(\pi)^\top \hat{\theta}_{k-1} + \phi(\pi)^\top \theta - \hat{\phi}_{k-1}(\pi)^\top \theta + \hat{\phi}_{k-1}(\pi)^\top \theta - \hat{\phi}_{k-1}(\pi)^\top \hat{\theta}_{k-1}
		\\
		&\leq \hat{\phi}_{k-1}(\pi)^\top \hat{\theta}_{k-1} + \|\phi(\pi) - \hat{\phi}_{k-1}(\pi)\|_1 \cdot \|\theta\|_{\infty} + \beta(k-1) \cdot  \|\hat{\phi}_{k-1}(\pi)\|_{(\Sigma_{k-1})^{-1}}
		\\
		&\overset{\textup{(a)}}{\leq} \hat{\phi}_{k-1}(\pi)^\top \hat{\theta}_{k-1} + \beta(k-1) \cdot  \|\hat{\phi}_{k-1}(\pi)\|_{(\Sigma_{k-1})^{-1}} + r_{\max} \sum_{s',a'} \ex_{s_1 \sim \rho}\mbr{B^{\pi;s',a';k}_1(s_1)} ,
	\end{align*}
	where (a) uses Lemma~\ref{lemma:error_in_visitation}.
\end{proof}


\begin{lemma} \label{lemma:sum_phi_original_seg}
	For any $K\geq 1$, we have
	\begin{align*}
		\sum_{k=1}^{K} \sum_{i=1}^{m} \nbr{ \phi^{\tau^k_i}}_{(\Sigma_{k-1})^{-1}} \leq H \sqrt{ \frac{2K |\cS| |\cA|}{\lambda} \log \sbr{ 1+ \frac{  KH^2 }{ \lambda |\cS| |\cA| m} }} .
	\end{align*}
\end{lemma}
\begin{proof}		
	We have
	\begin{align*}
		\sum_{k=1}^{K} \sum_{i=1}^{m} \nbr{ \phi^{\tau^k_i}}_{(\Sigma_{k-1})^{-1}} &\leq \sqrt{ Km   \sum_{k=1}^{K} \sum_{i=1}^{m} \nbr{ \phi^{\tau^k_i}}_{(\Sigma_{k-1})^{-1}}^2 }
		\\
		&= \sqrt{ Km  \sum_{k=1}^{K} \min\lbr{ \sum_{i=1}^{m} \nbr{ \phi^{\tau^k_i}}_{(\Sigma_{k-1})^{-1}}^2 ,\ \frac{H^2}{m \lambda} } }
		\\
		&= \sqrt{ \frac{H^2 K}{\lambda} \sum_{k=1}^{K} \min\lbr{ \frac{m \lambda}{H^2} \sum_{i=1}^{m}   \nbr{ \phi^{\tau^k_i}}_{(\Sigma_{k-1})^{-1}}^2 ,\ 1 } }
		\\
		&\overset{\textup{(a)}}{\leq}  \sqrt{ \frac{2H^2 K}{\lambda}  \sum_{k=1}^{K} \log\sbr{ 1 +  \min\lbr{ \frac{m \lambda}{H^2} \sum_{i=1}^{m}  \nbr{ \phi^{\tau^k_i}}_{(\Sigma_{k-1})^{-1}}^2 ,\ 1 } } }
		\\
		&\overset{\textup{(b)}}{\leq} \sqrt{ \frac{2H^2 K}{\lambda}  \sum_{k=1}^{K} \log \sbr{ 1 + \sum_{i=1}^{m} \nbr{ \phi^{\tau^k_i}}_{(\Sigma_{k-1})^{-1}}^2 } }
		\\
		&\overset{\textup{(c)}}{\leq} \sqrt{ \frac{2KH^2 |\cS| |\cA|}{\lambda} \log \sbr{ 1+ \frac{ KH^2 }{ \lambda |\cS| |\cA| m} }} ,
	\end{align*}
	where inequality (a) uses the fact that $x \leq 2\log(1+x)$ for any $0 \leq x \leq 1$, inequality (b) is due to the fact that $\lambda \leq \frac{H^2}{m}$, and inequality (c) follows from Lemma~\ref{lemma:log_det_seg}.
\end{proof}

Define event 
\begin{align}
	\cF^{\summing}_{\textup{reg}}:=\Bigg\{& \abr{\sum_{k'=1}^{k} \sbr{ \ex_{\tau \sim \pi^{k'}}\mbr{ \nbr{ \phi^{\tau}}_{(\Sigma_{k'-1})^{-1}} | F_{k'-1}} - \nbr{ \phi^{\tau}}_{(\Sigma_{k'-1})^{-1}} } } \leq 4H\sqrt{ \frac{k}{\lambda} \log\sbr{\frac{4k}{\delta'}} } ,
	\nonumber\\ 
	&\forall k>0 \Bigg\} .
\end{align}
Event $\cF^{\summing}_{\textup{reg}}$ is similar to $\cF^{\summing}_{\textup{opt}}$, except that here the universal upper bound of $\nbr{ \phi^{\tau}}_{(\Sigma_{k'-1})^{-1}}$ is $\frac{H}{\sqrt{\lambda}}$ rather than $1$. 

\begin{lemma} 
	It holds that
	\begin{align*}
		\Pr \mbr{ \cF^{\summing}_{\textup{reg}} } \geq 1-\delta' .
	\end{align*}
\end{lemma}
\begin{proof}
	For any $k'\geq 1$, we have that $\nbr{ \phi^{\tau}}_{(\Sigma_{k'-1})^{-1}} \leq \frac{H}{\sqrt{\lambda}}$, and then $|\ex_{\tau \sim \pi^{k'}} [\nbr{ \phi^{\tau}}_{(\Sigma_{k'-1})^{-1}} | F_{k'-1}] - \nbr{ \phi^{\tau}}_{(\Sigma_{k'-1})^{-1}}| \leq \frac{2H}{\sqrt{\lambda}}$. 
	
	
	Using the Azuma-Hoeffding inequality, we have that for any fixed $k>0$, with probability at least $1-\frac{\delta'}{2k^2}$,
	\begin{align*}
		\abr{\sum_{k'=1}^{k} \sbr{ \ex_{\tau \sim \pi^{k'}}\mbr{ \nbr{ \phi^{\tau}}_{(\Sigma_{k'-1})^{-1}} | F_{k'-1}} - \nbr{ \phi^{\tau}}_{(\Sigma_{k'-1})^{-1}} } } &\leq \sqrt{ 2 \cdot \frac{4H^2}{\lambda} \cdot k \log\sbr{\frac{4k^2}{\delta'}} } .
	\end{align*}
	
	Since $\sum_{k=1}^{\infty} \frac{\delta'}{2k^2} \leq \delta'$, by a union bound over $k$, we have that with probability at least $\delta'$, for any $k\geq 1$,
	\begin{align*}
		\abr{\sum_{k'=1}^{k} \sbr{ \ex_{\tau \sim \pi^{k'}}\mbr{ \nbr{ \phi^{\tau}}_{(\Sigma_{k'-1})^{-1}} | F_{k'-1}} - \nbr{ \phi^{\tau}}_{(\Sigma_{k'-1})^{-1}} } } &\leq \sqrt{ 2 \cdot \frac{4H^2}{\lambda} \cdot k \log\sbr{\frac{4k^2}{\delta'}} } 
		\\
		&\leq 4H \sqrt{ \frac{k}{\lambda} \log\sbr{\frac{4k}{\delta'}} } .
	\end{align*}
\end{proof}



\begin{proof}[Proof of Theorem~\ref{thm:ub_sum_unknown_tran}]
	Let $\delta'=\frac{\delta}{4}$. Then, we have $\Pr[\cK \cap \cF^{\summing}_{\textup{reg}} \cap \cG_{\textup{KL}} \cap \cH] \geq 1-\delta$.
	Thus, it suffices to prove the regret upper bound when event $\cK \cap \cF^{\summing}_{\textup{reg}} \cap \cG_{\textup{KL}} \cap \cH$ holds. 
	
	Assume that event $\cK \cap \cF^{\summing}_{\textup{reg}} \cap \cG_{\textup{KL}} \cap \cH$ holds.
	For any $k>0$, we have
	\begin{align}
		&\quad\ \sum_{k=1}^{K} \sbr{ V^*(s_1)-V^{\pi^k}(s_1) } 
		\nonumber\\
		&\overset{\textup{(a)}}{\leq}  \sum_{k=1}^{K} \Bigg( \hat{\phi}_{k-1}(\pi^*)^\top \hat{\theta}_{k-1} + \beta(k-1) \cdot  \|\hat{\phi}_{k-1}(\pi^*)\|_{(\Sigma_{k-1})^{-1}} + r_{\max} \sum_{s',a'} \ex_{s_1 \sim \rho}\mbr{B^{\pi^*;s',a';k}_1(s_1)} 
		\nonumber\\
		&\quad - V^{\pi^k} \Bigg)
		\nonumber\\
		&\overset{\textup{(b)}}{\leq}  \sum_{k=1}^{K} \Bigg( \hat{\phi}_{k-1}(\pi^k)^\top \hat{\theta}_{k-1} + \beta(k-1) \cdot  \|\hat{\phi}_{k-1}(\pi^k)\|_{(\Sigma_{k-1})^{-1}} + r_{\max} \sum_{s',a'} \ex_{s_1 \sim \rho}\mbr{B^{\pi^k;s',a';k}_1(s_1)} 
		\nonumber\\
		&\quad - V^{\pi^k} \Bigg)
		\nonumber\\
		&\leq \sum_{k=1}^{K} \Bigg( \hat{\phi}_{k-1}(\pi^k)^\top \hat{\theta}_{k-1} - \hat{\phi}_{k-1}(\pi^k)^\top\theta + \hat{\phi}_{k-1}(\pi^k)^\top\theta - (\phi^{\pi^k})^\top\theta \nonumber\\& \quad+ \beta(k-1) \cdot  \|\hat{\phi}_{k-1}(\pi^k)\|_{(\Sigma_{k-1})^{-1}}  + r_{\max} \sum_{s',a'} \ex_{s_1 \sim \rho}\mbr{B^{\pi^k;s',a';k}_1(s_1)} \Bigg) 
		\nonumber\\
		&\overset{\textup{(c)}}{\leq} \sum_{k=1}^{K} \sbr{2 \beta(k-1) \cdot  \|\hat{\phi}_{k-1}(\pi^k)\|_{(\Sigma_{k-1})^{-1}} + 2 r_{\max} \sum_{s',a'} \ex_{s_1 \sim \rho}\mbr{B^{\pi^k;s',a';k}_1(s_1)} }
		\nonumber\\
		&\leq  2 \beta(K)  \sum_{k=1}^{K} \|\hat{\phi}_{k-1}(\pi^k)\|_{(\Sigma_{k-1})^{-1}} + 2 r_{\max} \sum_{k=1}^{K} \sum_{s',a'} \ex_{s_1 \sim \rho}\mbr{B^{\pi^k;s',a';k}_1(s_1)} , \label{eq:regret_decomp_unknown_tran_seg}
	\end{align}
	where (a) uses Lemma~\ref{lemma:optimism}, (b) is due to the definition of $\pi^k$, and (c) follows from Lemma~\ref{lemma:error_in_visitation} and the definition of event $\cK$. 
	
	Next, we first bound $\sum_{k=1}^{K} \|\hat{\phi}_{k-1}(\pi^k)\|_{(\Sigma_{k-1})^{-1}}$.
	
	We have
	\begin{align}
		\sum_{k=1}^{K} \|\hat{\phi}_{k-1}(\pi^k)\|_{(\Sigma_{k-1})^{-1}} &\leq \sum_{k=1}^{K} \sbr{ \|\phi^{\pi^k}\|_{(\Sigma_{k-1})^{-1}} + \|\hat{\phi}_{k-1}(\pi^k) - \phi^{\pi^k}\|_{(\Sigma_{k-1})^{-1}} }
		\nonumber\\
		&\leq \sum_{k=1}^{K} \sbr{ \|\phi^{\pi^k}\|_{(\Sigma_{k-1})^{-1}} + \frac{1}{\sqrt{\lambda}} \cdot \|\hat{\phi}_{k-1}(\pi^k) - \phi^{\pi^k}\|_2 }
		\nonumber\\
		&\leq \sum_{k=1}^{K} \sbr{ \|\phi^{\pi^k}\|_{(\Sigma_{k-1})^{-1}} + \frac{1}{\sqrt{\lambda}} \cdot \|\hat{\phi}_{k-1}(\pi^k) - \phi^{\pi^k}\|_1 } . \label{eq:hat_phi_norm_seg}
	\end{align}
	
%	Recall that for any $k > 0$, $F_k$ denotes the filtration that includes all events up to the end of episode $k$.
	Here we have
	\begin{align}
		&\quad\ \sum_{k=1}^{K}  \|\phi^{\pi^k}\|_{(\Sigma_{k-1})^{-1}} 
		\nonumber\\
		&= \sum_{k=1}^{K} \nbr{ \ex_{\tau \sim \pi^k}\mbr{\phi^{\tau}| F_{k-1}} }_{(\Sigma_{k-1})^{-1}}
		\nonumber\\
		&\overset{\textup{(a)}}{\leq} \sum_{k=1}^{K} \ex_{\tau \sim \pi^k}\mbr{ \nbr{ \phi^{\tau}}_{(\Sigma_{k-1})^{-1}} | F_{k-1}}
		\nonumber\\
		&= \sum_{k=1}^{K} \sbr{ \ex_{\tau \sim \pi^k}\mbr{ \nbr{ \phi^{\tau}}_{(\Sigma_{k-1})^{-1}} | F_{k-1}} - \nbr{ \phi(\tau^k)}_{(\Sigma_{k-1})^{-1}} + \nbr{ \phi(\tau^k)}_{(\Sigma_{k-1})^{-1}} }
		\nonumber\\
		&\leq \sum_{k=1}^{K} \sbr{ \ex_{\tau \sim \pi^k}\mbr{ \nbr{ \phi^{\tau}}_{(\Sigma_{k-1})^{-1}} | F_{k-1}} - \nbr{ \phi(\tau^k)}_{(\Sigma_{k-1})^{-1}} + \sum_{i=1}^{m} \nbr{ \phi^{\tau^k_i}}_{(\Sigma_{k-1})^{-1}} }
		\nonumber\\
		&\overset{\textup{(b)}}{\leq} 4H\sqrt{ \frac{K}{\lambda} \log\sbr{\frac{4K}{\delta'}} } + H \sqrt{ \frac{2K |\cS| |\cA|}{\lambda} \log \sbr{  1+ \frac{ KH^2 }{ \lambda |\cS| |\cA| m } }} , \label{eq:phi_norm_seg}
	\end{align}
	where (a) uses the Jensen inequality, and (b) comes from the definition of $\cF^{\summing}_{\textup{reg}}$ and Lemma~\ref{lemma:sum_phi_original_seg}.
	
	Hence, plugging Eq.~\eqref{eq:phi_norm_seg} into Eq.~\eqref{eq:hat_phi_norm_seg} and using Lemma~\ref{lemma:error_in_visitation}, we have
	\begin{align}
		\sum_{k=1}^{K} \|\hat{\phi}_{k-1}(\pi^k)\|_{(\Sigma_{k-1})^{-1}} &\leq 4H\sqrt{ \frac{K}{\lambda} \log\sbr{\frac{4K}{\delta'}} } + H \sqrt{ \frac{2K |\cS| |\cA|}{\lambda} \log \sbr{ 1+ \frac{  KH^2 }{ \lambda |\cS| |\cA| } }} 
		\nonumber\\
		&\quad + \frac{1}{\sqrt{\lambda}} \sum_{k=1}^{K} \sum_{s',a'} \ex_{s_1 \sim \rho}\mbr{B^{\pi;s',a';k}_1(s_1)} . \label{eq:bound_hat_phi_seg}
	\end{align}
	
	On the other hand, according to Eq.~\eqref{eq:bound_B}, we have
	\begin{align*}
		\ex_{s_1 \sim \rho}\!\mbr{B^{\pi;s',a';k}_1(s_1)} \!\leq\! e^{12} \!\sum_{h=1}^{H} \!\sum_{s,a}  \!w^{\pi}_h(s,a)\!  \sbr{\! 8  \sqrt{ \frac{\var_{p(\cdot|s,a)}(G^{\pi;s',a'}_{h+1}(\cdot|p)) \cdot L}{n_{k-1}(s,a)} }  \!+\! \frac{46  H^2L}{n_{k-1}(s,a)} \!} \!\wedge\! H .
	\end{align*}
	
	
	
	Therefore, plugging Eqs.~\eqref{eq:bound_hat_phi_seg} and \eqref{eq:bound_B} into Eq.~\eqref{eq:regret_decomp_unknown_tran_seg}, we have
	\begin{align*}
		&\quad\ \sum_{k=1}^{K} \sbr{ V^*-V^{\pi^k} } 
		\\
		&\leq 2 \beta(K) \sbr{ 4H\sqrt{ \frac{K}{\lambda} \log\sbr{\frac{4K}{\delta'}} } + H \sqrt{ \frac{2K |\cS| |\cA|}{\lambda} \log \sbr{ 1+ \frac{  KH^2 }{ \lambda |\cS| |\cA| m} }} } 
		\\& \quad + 
		2 \sbr{ \frac{\beta(K)}{\sqrt{\lambda}} + r_{\max} } \sum_{s',a'} \sum_{k=1}^{K}  \ex_{s_1 \sim \rho}\mbr{B^{\pi^k;s',a';k}_1(s_1)}
		\\
		&\overset{\textup{(a)}}{\leq} 2 \beta(K) \sbr{ 4H\sqrt{ \frac{K}{\lambda} \log\sbr{\frac{4K}{\delta'}} } + H \sqrt{ \frac{2K |\cS| |\cA|}{\lambda} \log \sbr{ 1+ \frac{  KH^2 }{ \lambda |\cS| |\cA| m } }} } \\&\quad + \frac{4\beta(K)}{\sqrt{\lambda}} \sbr{ 16 e^{12} |\cS|^{\frac{3}{2}} |\cA|^{\frac{3}{2}} H \sqrt{K L \log(2KH) } + 192 e^{12} |\cS|^2 |\cA|^2 H^2 L \log(2KH) } 
		\\
		%			&\overset{\textup{(a)}}{\leq} 2 \beta(K) \sbr{ 4H\sqrt{ \frac{K}{\lambda} \log\sbr{\frac{4K}{\delta'}} } + H \sqrt{ \frac{2K |\cS| |\cA|}{\lambda} \log \sbr{ 1+ \frac{  KH^2 }{ \lambda |\cS| |\cA| m } }} } \\&\quad + \frac{4\beta(K)}{\sqrt{\lambda}} \cdot 16 e^{12} \sqrt{L} \sum_{s',a'} \sqrt{ \sum_{k=1}^{K} \sum_{h=1}^{H} \sum_{(s,a) \in D_k} w_{k,h}(s,a) \var_{p(\cdot|s,a)}(G^{\pi^k;s',a'}_{h+1}(\cdot|p)) } \cdot \sqrt{ \sum_{k=1}^{K} \sum_{h=1}^{H} \sum_{(s,a) \in D_k} \frac{w_{k,h}(s,a) }{n_{k-1}(s,a)} } 
		%			\\&\quad + \frac{4\beta(K)}{\sqrt{\lambda}} \cdot 2 e^{12} |\cS| |\cA| \cdot 46  H^2L \sum_{k=1}^{K} \sum_{h=1}^{H} \sum_{(s,a) \in D_k}   \frac{w_{k,h}(s,a) }{n_{k-1}(s,a)} 
		%			\\&\quad + \frac{4\beta(K)}{\sqrt{\lambda}} \cdot 16 e^{12}  |\cS|^2 |\cA|^2 H^2 \log\sbr{\frac{|\cS||\cA|H}{\delta'}}
		%			\\
		%			&\overset{\textup{(b)}}{\leq} 2 \beta(K) \sbr{ 4H\sqrt{ \frac{K}{\lambda} \log\sbr{\frac{4K}{\delta'}} } + H \sqrt{ \frac{2K |\cS| |\cA|}{\lambda} \log \sbr{ 1+ \frac{  KH^2 }{ \lambda |\cS| |\cA| m } }} } \\&\quad + \frac{4\beta(K)}{\sqrt{\lambda}} \cdot 16 e^{12} |\cS| |\cA| \sqrt{L}  \sqrt{K H^2} \cdot \sqrt{ 4 |\cS| |\cA| \log(2KH) } 
		%			\\&\quad + \frac{4\beta(K)}{\sqrt{\lambda}} \cdot 368 e^{12} |\cS|^2 |\cA|^2 H^2 L \log(2KH)  + \frac{4\beta(K)}{\sqrt{\lambda}} \cdot 16 e^{12} |\cS|^2 |\cA|^2 H^2 \log\sbr{\frac{|\cS||\cA|H}{\delta'}} 
		%			\\
		&= O \Bigg( \bigg( \sqrt{ \frac{H|\cS||\cA|}{m} \log\sbr{ \sbr{1+\frac{KH^2}{\lambda|\cS||\cA| m}}  \frac{1}{\delta} } } + r_{\max} \sqrt{\lambda|\cS||\cA|}  \bigg) \cdot
		\\&\qquad\quad \bigg( H \sqrt{ \frac{K |\cS| |\cA|}{\lambda} \log \sbr{ \sbr{1+ \frac{  KH^2 }{ \lambda |\cS| |\cA| m}}  \frac{1}{\delta} }}   +  |\cS|^{\frac{3}{2}} |\cA|^{\frac{3}{2}} H  \sqrt{ \frac{K L}{\lambda} \log(KH) }  +  \frac{|\cS|^2 |\cA|^2 H^2 L}{\sqrt{\lambda}} \log(KH) \bigg) \Bigg)
		\\
		&\overset{\textup{(b)}}{=}  O \Bigg( (1+r_{\max}) |\cS|^2 |\cA|^2 H \sqrt{ K}  \bigg( \log \sbr{ \sbr{ 1+ \frac{  KH }{  |\cS| |\cA| } }  \frac{1}{\delta} } 
	+ \sqrt{L \log(KH)} \sqrt{\log\sbr{ \sbr{1+\frac{KH}{|\cS||\cA|}}  \frac{1}{\delta} }} \bigg)  
		\\
		&\qquad\quad +  (1+r_{\max}) |\cS|^{\frac{5}{2}} |\cA|^{\frac{5}{2}} H^2 L \log(KH) \sqrt{\log\sbr{ \sbr{1+\frac{KH}{|\cS||\cA|}} \frac{1}{\delta} }}  \Bigg)
		\\
		&= \tilde{O} \sbr{ (1+r_{\max}) |\cS|^{\frac{5}{2}} |\cA|^2 H \sqrt{K} + (1+r_{\max}) |\cS|^{\frac{7}{2}} |\cA|^{\frac{5}{2}} H^2 } ,
	\end{align*}
	where inequality (a) comes from Lemma~\ref{lemma:ub_B}, and equality (b) uses the fact that $\lambda:=\frac{H}{m}$. 
\end{proof}

\subsection{A Lower Bound for Unknown Transition and its Proof} \label{apx:lb_sum_unknown_tran}

Below we provide a lower bound for RL with sum segment feedback and unknown transition with the proof.



\begin{theorem} \label{thm:lb_sum_unknown_tran}
	Consider the problem of RL with sum segment feedback and unknown transition. There exists a distribution of instances where the regret of any algorithm must be
	\begin{align*}
		\Omega\sbr{r_{\max} H\sqrt{|\cS||\cA|K} } .
	\end{align*}
\end{theorem}
\begin{proof}[Proof of Theorem~\ref{thm:lb_sum_unknown_tran}]
	\begin{figure}[t]
		\centering   
		\includegraphics[width=0.5\textwidth]{fig/lower_bound_unknown_transition_crop.pdf}
		\caption{Instance for the lower bound under sum segment feedback and unknown transition.
		} \label{fig:lower_bound_unknown_transition}
	\end{figure}
	
	We construct a random instance $\cI$ as follows. As shown in Figure~\ref{fig:lower_bound_unknown_transition}, there are $n$ bandit states $s_1,\dots,s_n$ (i.e., there are an optimal action and multiple suboptimal actions), a good absorbing state $s_{n+1}$ and a bad absorbing state $s_{n+2}$.
	The agent starts from $s_1,\dots,s_n$ with equal probability $\frac{1}{n}$. For any $i \in [n]$, in state $s_i$, one action $a_J$ is uniformly chosen from $\cA$ as the optimal action. In state $s_i$, under the optimal action $a_J$, the agent transitions to $s_{n+1}$ and $s_{n+2}$ with probabilities $\frac{1}{2}+\varepsilon$ and $\frac{1}{2}-\varepsilon$, respectively, where $\varepsilon \in (0,\frac{1}{4})$ is a parameter specified later; Under any suboptimal action $a \in \cA \setminus \{s_J\}$, the agent transitions to $s_{n+1}$ and $s_{n+2}$ with equal probability $\frac{1}{2}$.
	
	The rewards are deterministic for all state-action pairs. 
	For any $a \in \cA$, $r(s_{n+1},a)=r_{\max}$. For any $i\in \{1,...,n,n+2\}$ and $a \in \cA$, $r(s_i,a)=0$.
	
	
	In this proof, we will also use an alternative uniform instance $\cI_{\unif}$. The only difference between $\cI_{\unif}$ and $\cI$ is that for any $i \in [n]$, in state $s_i$, under all actions $a \in \cA$, the agent transitions to $s_{n+1}$ and $s_{n+2}$ with equal probability $\frac{1}{2}$.
	
	Fix an algorithm $\A$.
	Let $\ex_{\unif}[\cdot]$ denote the expectation with respect to $\cI_{\unif}$. Let $\ex_*[\cdot]$ denote the expectation with respect to $\cI$. For any $i \in [n]$ and $j \in [|\cA|]$, let $\ex_{i,j}[\cdot]$ denote the expectation with respect to the case where $a_j$ is the optimal action in state $s_i$, and  $N_{i,j}$ denote the number of episodes where algorithm $\A$ chooses $a_j$ in state $s_i$, i.e., $N_{i,j}=\sum_{k=1}^{K} \indicator\{\pi^k_1(s_i)=a_j\}$. 
	
	The KL divergence of transition distribution on $(s_i,a_J)$ ($i \in [n]$) between $\cI_{\unif}$ and $\cI$ is 
	\begin{align*}
		\kl \sbr{ \bernoulli\sbr{\frac{1}{2}} \| \bernoulli\sbr{\frac{1}{2}+\varepsilon} } &=  \frac{1}{2} \ln\sbr{\frac{\frac{1}{2}}{\frac{1}{2}-\varepsilon}} + \frac{1}{2}\ln\sbr{ \frac{\frac{1}{2}}{\frac{1}{2}+\varepsilon} } 
		\\
		&=  \frac{1}{2} \ln\sbr{\frac{\frac{1}{4}}{\frac{1}{4}-\varepsilon^2}} 
		\\
		&=  -\frac{1}{2} \ln\sbr{1-4\varepsilon^2} 
		\\
		&\overset{\textup{(a)}}{\leq} 4 \varepsilon^2 ,
	\end{align*}
	where (a) uses the fact that  $-\ln(1-x)\leq 2 x$ when $x \in (0,\frac{1}{4})$.
	
	In addition, the agent has probability only $\frac{1}{n}$ to arrive at (observe) state $s_i$.
	
	Thus, using Lemma A.1 in \cite{auer2002nonstochastic}, we have that for any $i \in [n]$, in state $s_i$,
	\begin{align*}
		\ex_{i,j}[N_{i,j}] &\leq \ex_{\unif}[N_{i,j}] + \frac{K}{2} \sqrt{ \frac{1}{n} \cdot \ex_{\unif}[N_{i,j}] \cdot \kl \sbr{ \bernoulli\sbr{\frac{1}{2}} \| \bernoulli\sbr{\frac{1}{2}+\varepsilon} } } 
		\\
		&\leq \ex_{\unif}[N_{i,j}] + \frac{K}{2} \sqrt{ \frac{1}{n} \cdot \ex_{\unif}[N_{i,j}] \cdot 4 \varepsilon^2 }
		\\
		&= \ex_{\unif}[N_{i,j}] + K \varepsilon \sqrt{ \frac{1}{n} \cdot \ex_{\unif}[N_{i,j}] } .
	\end{align*}
	
	Summing over $j \in [|\cA|]$, using the Cauchy-Schwarz inequality and the fact that $\sum_{j=1}^{|\cA|} \ex_{\unif}[N_{i,j}]=K$, we have
	\begin{align*}
		\sum_{j=1}^{|\cA|}  \ex_{i,j}[N_{i,j}] &\leq K + K \varepsilon \sqrt{ \frac{|\cA|}{n} \cdot K  } .
	\end{align*}
	Then, we have
	\begin{align*}
		\cR(K) &= \sum_{k=1}^{K} \ex_{*}\mbr{V^*-V^{\pi^k}}
		\\
		&=\sbr{\frac{1}{2}+\varepsilon}(H-1)r_{\max}K 
		\\
		&\quad - \frac{1}{n} \sum_{i=1}^{n} \sbr{ \frac{1}{2}(H-1)r_{\max}K + \varepsilon(H-1)r_{\max} \cdot \frac{1}{|\cA|} \sum_{j=1}^{|\cA|} \ex_{i,j}[N_{i,j}] }
		\\
		&\geq \varepsilon(H-1)r_{\max} \sbr{K - \frac{K}{|\cA|} - K \varepsilon \sqrt{ \frac{K}{|\cA|n} } } .
	\end{align*}
	
	Recall that $n=|\cS|-2$. Let $|\cS|\geq 3$, $|\cA|\geq 2$, $H \geq 2$, $K > |\cA|n$ and $\varepsilon=\frac{1}{4}\sqrt{\frac{|\cA|n}{K}}$. Then, we have 
	\begin{align*}
		\cR(K) = \Omega\sbr{ r_{\max} H\sqrt{|\cS||\cA|K} } .
	\end{align*}
\end{proof}


\section{Technical Tools}

In this section, we introduce several technical tools.

\begin{lemma}[Self-concordance, Lemma 9 in \cite{faury2020improved}] \label{lemma:self_concordance}
	For any $x_1,x_2 \in \R$, we have
	\begin{align*}
		\mu'(x_1) \frac{1-\exp(-|x_1-x_2|)}{|x_1-x_2|} \leq \int_{z=0}^{1} \mu'( (1-z)x_1 + zx_2 ) dz \leq \mu'(x_1) \frac{\exp(|x_1-x_2|)-1}{|x_1-x_2|} .
	\end{align*}
	
	Furthermore, we have
	\begin{align*}
		\int_{z=0}^{1} \mu'( (1-z)x_1 + zx_2 ) dz \geq \frac{\mu'(x_1)}{1+|x_1-x_2|} .
	\end{align*}
\end{lemma}

\begin{lemma}[Value Difference Lemma, Lemma E.15 in \cite{dann2017unifying}] \label{lemma:value_diff_lemma}
	For any two MDPs $M'$ and $M''$ with rewards $r'$ and $r''$ and transition distributions $p'$ and $p''$, we have that for any $h \in [H]$ and $s \in \cS$,
	\begin{align*}
		V'_h(s) \!-\! V''_h(s) \!=\! \ex_{p''}\mbr{ \sum_{t=h}^{H} \sbr{ r'(s_t,a_t) \!-\! r''(s_t,a_t) \!+\! \sbr{ p'(\cdot|s_t,a_t) \!-\! p''(\cdot|s_t,a_t) }^{\!\top} \! V'_{h+1}(\cdot) } | s_t=s } \!.
	\end{align*}
\end{lemma}

\begin{lemma}[Law of Total Variance, Lemma 15 in \cite{zanette2019tighter}] \label{lemma:law_of_total_variance}
	For an MDP $p$ and a fixed policy $\pi$, we have
	\begin{align*}
		\ex_{\pi,p}\! \mbr{ \sbr{\sum_{h=1}^{H} r(s_h,\pi_h(s)) \!-\! V_1^{\pi}(s_1) } \bigg| s_1 } \!=\! \ex_{\pi,p} \mbr{ \sum_{h=1}^{H} \var_{s_{h+1} \sim p(\cdot|s_h,\pi_h(s_h))}\sbr{V^{\pi}_{h+1}(s_{h+1})} \bigg| s_1 } .
	\end{align*}
\end{lemma}

The idea of Lemma~\ref{lemma:law_of_total_variance} was also used in earlier works, e.g.,~\cite{munos1999influence,lattimore2012pac,gheshlaghi2013minimax}.

\begin{lemma}[Lemma 10 in \cite{menard2021fast}] \label{lemma:bernstern_kl}
	For distributions $p,q \in \triangle_{\cS}$ and function $f:\cS \rightarrow [0,b]$, if $\kl(p,q)\leq \alpha$, then
	\begin{align*}
		|(p(\cdot)-q(\cdot))^\top f(\cdot)| \leq \sqrt{2\var_q(f)\alpha}+\frac{2}{3}b\alpha .
	\end{align*}
\end{lemma}

\begin{lemma}[Lemma 11 in \cite{menard2021fast}] \label{lemma:var_change_p}
	For distributions $p,q \in \triangle_{\cS}$ and function $f:\cS \rightarrow [0,b]$, if $\kl(p,q)\leq \alpha$, then
	\begin{align*}
		\var_q(f) \leq 2\var_p(f) + 4 b^2 \alpha .
	\end{align*}
\end{lemma}

\begin{lemma}[Lemma 12 in \cite{menard2021fast}] \label{lemma:var_change_f}
	For distribution $p \in \triangle_{\cS}$ and functions $f,g:\cS \rightarrow [0,b]$, we have
	\begin{align*}
		\var_p(f) \leq 2 \var_p(g) + 2b p(\cdot)^\top |f(\cdot)-g(\cdot)| .
	\end{align*}
\end{lemma}

