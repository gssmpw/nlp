@article{thompson1933likelihood,
	title={On the likelihood that one unknown probability exceeds another in view of the evidence of two samples},
	author={Thompson, William R},
	journal={Biometrika},
	volume={25},
	number={3-4},
	pages={285--294},
	year={1933},
	publisher={Oxford University Press}
}

@book{sutton2018reinforcement,
	title={Reinforcement learning: An introduction},
	author={Sutton, Richard S and Barto, Andrew G},
	year={2018},
	publisher={MIT press}
}

@inproceedings{azar2017minimax,
	title={Minimax regret bounds for reinforcement learning},
	author={Azar, Mohammad Gheshlaghi and Osband, Ian and Munos, R{\'e}mi},
	booktitle={International Conference on Machine Learning},
	pages={263--272},
	year={2017},
	organization={PMLR}
}

@inproceedings{efroni2021reinforcement,
	title={Reinforcement learning with trajectory feedback},
	author={Efroni, Yonathan and Merlis, Nadav and Mannor, Shie},
	booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
	volume={35},
	number={8},
	pages={7288--7295},
	year={2021}
}

@inproceedings{chatterji2021theory,
	title={On the theory of reinforcement learning with once-per-episode feedback},
	author={Chatterji, Niladri and Pacchiano, Aldo and Bartlett, Peter and Jordan, Michael},
	booktitle={Advances in Neural Information Processing Systems},
	volume={34},
	pages={3401--3412},
	year={2021}
}

@inproceedings{abbasi2011improved,
	title={Improved algorithms for linear stochastic bandits},
	author={Abbasi-Yadkori, Yasin and P{\'a}l, D{\'a}vid and Szepesv{\'a}ri, Csaba},
	booktitle={Advances in Neural Information Processing Systems},
	volume={24},
	year={2011}
}

@article{allen2021near,
	title={Near-optimal discrete optimization for experimental design: A regret minimization approach},
	author={Allen-Zhu, Zeyuan and Li, Yuanzhi and Singh, Aarti and Wang, Yining},
	journal={Mathematical Programming},
	volume={186},
	pages={439--478},
	year={2021},
	publisher={Springer}
}

@book{pukelsheim2006optimal,
	title={Optimal design of experiments},
	author={Pukelsheim, Friedrich},
	year={2006},
	publisher={SIAM}
}

@article{jaksch2010near,
	title={Near-optimal Regret Bounds for Reinforcement Learning},
	author={Jaksch, Thomas and Ortner, Ronald and Auer, Peter},
	journal={Journal of Machine Learning Research},
	volume={11},
	pages={1563--1600},
	year={2010}
}

@inproceedings{azar2017minimax,
	title={Minimax regret bounds for reinforcement learning},
	author={Azar, Mohammad Gheshlaghi and Osband, Ian and Munos, R{\'e}mi},
	booktitle={International Conference on Machine Learning},
	pages={263--272},
	year={2017},
	organization={PMLR}
}

@inproceedings{jin2018q,
	title={Is Q-learning provably efficient?},
	author={Jin, Chi and Allen-Zhu, Zeyuan and Bubeck, Sebastien and Jordan, Michael I},
	booktitle={Advances in Neural Information Processing Systems},
	volume={31},
	year={2018}
}

@inproceedings{zanette2019tighter,
	title={Tighter problem-dependent regret bounds in reinforcement learning without domain knowledge using value function bounds},
	author={Zanette, Andrea and Brunskill, Emma},
	booktitle={International Conference on Machine Learning},
	pages={7304--7312},
	year={2019},
	organization={PMLR}
}

@article{osband2016lower,
	title={On lower bounds for regret in reinforcement learning},
	author={Osband, Ian and Van Roy, Benjamin},
	journal={arXiv preprint arXiv:1608.02732},
	year={2016}
}

@inproceedings{filippi2010parametric,
	title={Parametric bandits: The generalized linear case},
	author={Filippi, Sarah and Cappe, Olivier and Garivier, Aur{\'e}lien and Szepesv{\'a}ri, Csaba},
	booktitle={Advances in Neural Information Processing Systems},
	volume={23},
	year={2010}
}

@inproceedings{faury2020improved,
	title={Improved optimistic algorithms for logistic bandits},
	author={Faury, Louis and Abeille, Marc and Calauz{\`e}nes, Cl{\'e}ment and Fercoq, Olivier},
	booktitle={International Conference on Machine Learning},
	pages={3052--3060},
	year={2020},
	organization={PMLR}
}

@inproceedings{russac2021self,
	title={Self-concordant analysis of generalized linear bandits with forgetting},
	author={Russac, Yoan and Faury, Louis and Capp{\'e}, Olivier and Garivier, Aur{\'e}lien},
	booktitle={International Conference on Artificial Intelligence and Statistics},
	pages={658--666},
	year={2021},
	organization={PMLR}
}

@inproceedings{menard2021fast,
	title={Fast active learning for pure exploration in reinforcement learning},
	author={M{\'e}nard, Pierre and Domingues, Omar Darwiche and Jonsson, Anders and Kaufmann, Emilie and Leurent, Edouard and Valko, Michal},
	booktitle={International Conference on Machine Learning},
	pages={7599--7608},
	year={2021},
	organization={PMLR}
}

@inproceedings{dann2017unifying,
	title={Unifying PAC and regret: Uniform PAC bounds for episodic reinforcement learning},
	author={Dann, Christoph and Lattimore, Tor and Brunskill, Emma},
	booktitle={Advances in Neural Information Processing Systems},
	volume={30},
	year={2017}
}

@inproceedings{munos1999influence,
	title={Influence and variance of a Markov chain: Application to adaptive discretization in optimal control},
	author={Munos, R{\'e}mi and Moore, Andrew},
	booktitle={Proceedings of the IEEE Conference on Decision and Control},
	volume={2},
	pages={1464--1469},
	year={1999},
	organization={IEEE}
}

@inproceedings{lattimore2012pac,
	title={PAC bounds for discounted MDPs},
	author={Lattimore, Tor and Hutter, Marcus},
	booktitle={International Conference on Algorithmic Learning Theory},
	pages={320--334},
	year={2012},
	organization={Springer}
}

@article{gheshlaghi2013minimax,
	title={Minimax PAC bounds on the sample complexity of reinforcement learning with a generative model},
	author={Gheshlaghi Azar, Mohammad and Munos, R{\'e}mi and Kappen, Hilbert J},
	journal={Machine Learning},
	volume={91},
	pages={325--349},
	year={2013},
	publisher={Springer}
}

@article{laurent2000adaptive,
	title={Adaptive estimation of a quadratic functional by model selection},
	author={Laurent, Beatrice and Massart, Pascal},
	journal={Annals of Statistics},
	pages={1302--1338},
	year={2000},
	publisher={JSTOR}
}

@article{borjesson1979simple,
	title={Simple approximations of the error function Q (x) for communications applications},
	author={Borjesson, P and Sundberg, C-E},
	journal={IEEE Transactions on Communications},
	volume={27},
	number={3},
	pages={639--643},
	year={1979},
	publisher={IEEE}
}

@article{auer2002nonstochastic,
	title={The nonstochastic multiarmed bandit problem},
	author={Auer, Peter and Cesa-Bianchi, Nicolo and Freund, Yoav and Schapire, Robert E},
	journal={SIAM Journal on Computing},
	volume={32},
	number={1},
	pages={48--77},
	year={2002},
	publisher={SIAM}
}

@article{tropp2015introduction,
	title={An introduction to matrix concentration inequalities},
	author={Tropp, Joel A and others},
	journal={Foundations and Trends{\textregistered} in Machine Learning},
	volume={8},
	number={1-2},
	pages={1--230},
	year={2015},
	publisher={Now Publishers, Inc.}
}

@inproceedings{tang2024reinforcement,
	title={Reinforcement learning from bagged reward},
	author={Tang, Yuting and Cai, Xin-Qiang and Ding, Yao-Xiang and Wu, Qiyu and Liu, Guoqing and Sugiyama, Masashi},
	booktitle={ICML 2024 Workshop: Aligning Reinforcement Learning Experimentalists and Theorists},
	year={2024}
}