\section{Related Works}
We summarize selected related works in this section and defer a more comprehensive survey to \cref{app:related-works}.

\subsection{Backdooring models for ownership verification}
There is a natural connection between model fingerprinting for authenticating ownership of a model and {\em backdoors} in secure machine learning ____, where an attacker injects maliciously corrupted training samples to control the output of the model.  ____ first used backdoor techniques for model authentication, which were applied to image classification models ____, pre-trained language models____, and more recently for large language models ____.  We refer the reader to ____ for a more comprehensive survey.    

\subsection{Fingerprinting LLMs}
There has been much recent interest in fingerprinting generative LLMs to detect model stealing. The main idea is to fine-tune the LLM on example \((\mathrm{key}, \mathrm{response})\) pairs. The model can then be authenticated by checking if it responds appropriately when prompted with the fingerprint \(\mathrm{key}\). This is adjacent to model watermarking, where one assumes access only to the outputs of an LLM, and aims to detect if a piece of text was generated from a particular model. We survey model watermarking in \cref{app:related-works}.

____ studied the problem of fingerprinting in both a white-box (i.e. with access to model weights) and black-box (i.e. access only to an API) settings. 
____ study fingerprinting where model owners can also be adversarial and can falsely claim another model as their own. 
The keys of the fingerprints considered by these works are either concatenations of random tokens or sensible English questions. We compare with these methods in \cref{fig:scalability} for Harmlessness and Persistence of fingerprints. ____ use backdoors to solve an adjacent problem of verifying whether a model has been fine-tuned on a specific dataset and outline a scheme to generate diverse and in-distribution fingerprints. Other works propose model merging as an attack against fingerprinting____ as well as a way to fingerprint models____. We survey other attacks as well as methods to fingerprint models in \cref{app:related-works}.








\subsection{Memorization and Forgetting in LLMs }
____ propose and study backdoor attacks which can persist after fine-tuning.   Other works ____ study how models acquire knowledge during pre-training, how this knowledge is forgotten and how to encourage retention. Similarly, ____ study 
the capacity of different sized models to memorize facts. These studies operate on fictional facts and synthetic strings, and can inspire better fingerprinting schemes. Conversely, fingerprints can also be used to gain further insights into memorization.