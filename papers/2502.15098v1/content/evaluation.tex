\section{Evaluation}\label{sec: Evaluation}
We next present the evaluation for \system{}.  
Section~\ref{subsec:experimental-setup} outlines the experimental setup for \system{}.
Section~\ref{subsec:monitoring-devices} presents the evaluation of \system{} in monitoring devices in three datasets.
Section~\ref{subsec:effectiveness-feedback-loop} presents a case study to illustrate the effectiveness of \system{}'s feedback loop, which is a main contribution in this paper.
Section~\ref{subsec:performance-overheads} characterizes \system{}'s performance overheads.
Section~\ref{subsec: comparison-prior-works} compares the performance of \system{} with three prior works. Finally, Section~\ref{subsec: energy-savings} illustrates the energy savings over periodic attestation due to the feedback loop.
\subsection{Experimental Setup}\label{subsec:experimental-setup}
Our experimental setup follows the \system{} system model and architecture shown in Figures~\ref{fig:system_model} and~\ref{fig: system overview} respectively. We use a Rasberry Pi 4 (RPi4)~\cite{raspberry_pi4} machine as the gateway, configured as a WiFi access point. It is based on quad-core Cortex-A72 (\ie{} ARMv8-M architecture) 64-bit Systems-on-Chip (SoC). The board runs at 1.5GHz with 8GB LPDDR4-2400 SDRAM. Additionally, it is equipped with 2.4GHz and 5.0GHz IEEE 802.11B/g/n/ac WLAN, Bluetooth 5.0, double-true Gigabit Ethernet, and a 32GB SD card as storage. Thus, with these specifications, RPi4 is comparable with commodity home routers. Profiler and Monitor are implemented as Python programs which run on the gateway.

\parheading{Sandbox for Malware.}
The gateway is connected to a NETGEAR 4G LTE Broadband Modem (LM1200)~\cite{netgear_modem} with Ethernet cable to access the Internet. NETGEAR Broadband Modem uses a T-Mobile SIM card for network connectivity. With this, we create a sandbox for safety reasons since we experiment with malware. Connecting the gateway directly to our institutional LAN would potentially make other LAN devices vulnerable to malware infection. 

\parheading{Smart Home Setup.}
We use a smart home setup to evaluate \system{}. However, \system{} can be implemented at scale to suit the deployment in a commercial setting. Our setup consists of 13 off-the-shelf devices and one RPi4 emulated smart bulb as the IoT device. 
Table~\ref{tab:device list} provides details about the devices. 

Off-the-shelf devices are chosen based on their popularity and ratings on Amazon~\cite{amazon}. We also consider a wide range of functionality: from plugs to cameras and vacuum-cleaning robots (\ie{} iRobot Roomba). The RPi smart bulb is implemented on a RPi4 with 2GB RAM. 
The RPi bulb is controlled by a Python program. This program can accept requests and send back responses over UDP connections. It has two main parts: bulb controller and attester. The bulb controller receives commands from the user device over the internet and turns on/off a LED based on the received command. Attester receives attestation request from the gateway, performs attestation, and sends back attestation result.

Additionally, we implement three malware CCC (Mirai, Bashlite, Lizkebab) on a Linux laptop with an Intel(R) Core(TM) i7-8550U CPU running at 1.80GHz and equipped with 8GB RAM. This Linux laptop is also connected to the gateway. Alternatively, malware CCC can be hosted outside the network, but we choose to host it inside our sandbox network due to safety issues.

We first collect network traffic (in the training phase) from the 13 devices to build \system{} dataset and, in turn, the device profiles without introducing any malware infection. 
Table~\ref{tab:device false positive} shows the numbers of packets from the traffic collection and profile entries for each device profile.

\begin{table}[t!]
        \scriptsize
	\centering
 \caption{Smart home devices used in \system{} evaluation.}
\begin{tabularx}{\linewidth}{p{26mm}p{48mm}} 
  \toprule
   \textbf{Device Name} & \textbf{Details} \\ 
  \midrule
   Amazon Smart Plug & Amazon Smart Plug \\ 
   HBN Smart Plug Mini & HBN Smart Plug Mini 15A \\ 
   Ring Doorbell & Ring Doorbell with camera (2020 release)\\ 
   Blink Mini Camera & Blink Mini compact indoor plug-in smart security camera \\ 
 Nest Camera & Nest indoor security camera \\ 
   Lumiman Smart Bulb & Lumiman multi-colored and warm-to-cool white LED light bulb\\ 
     Kasa Smart Bulb & Kasa Smart Bulb KL110 white light bulb \\ 
     LIFX Smart Bulb & LIFX A19 multi-colored light bulb \\ 
   ULTRALOQ U-Bolt Pro & ULTRALOQ U-Bolt Pro smart lock with Bluetooth and keypad\\ 
   Sensi Thermostat & Emerson Sensi smart thermostat \\ 
   Nest Protect Smoke Alarm & Nest Protect smoke alarm, smoke detector, and carbon monoxide detector\\ 
   Rachio Sprinkler & Rachio Sprinkler third generation with 8-zone sprinkler controller \\ 
   iRobot Roomba & iRobot Roomba 690 \\
  \midrule
     RPi Smart Bulb & Emulated smart bulb on Raspberry Pi 4 board \\ 
  \bottomrule
\end{tabularx}
\vspace{-1em}
\label{tab:device list}
\end{table}

\begin{table}[t!]
	\scriptsize
	\centering
        \caption{Experimental results of monitoring uninfected devices in smart home setup. The last row gives the \textbf{Total} for \textbf{\# Training Packets (Trng. Pkts.)}, \textbf{\# Monitoring Packets (Mnt. Pkts.)} and \textbf{\# Profile Entries}, and \textbf{Average} for \textbf{FPR}.}
	\begin{tabularx}{\linewidth}
{p{15mm} r r r r r}
  \toprule
  \textbf{Device Name} & \textbf{\# Trng.} &\textbf{\# Mnt.} & \textbf{\# Profile} & \multicolumn{2}{c}{\textbf{\underline{False Positive Rate (FPR)}}} \\
  & \textbf{Pkts.} & \textbf{Pkts.} & \textbf{Entries} & \textbf{End. \& Len.} & \textbf{End.}\\
  \midrule
  Amazon Plug & 8,317 & 11,017 & 119 & 0.87\% & 0.64\% \\ 
  HBN Plug Mini & 22,096 & 24,688 & 81 & 0.01\% & 0.00\% \\ 
  Ring Doorbell & 143,925 & 91,576 & 1590 & 0.39\% & 0.01\% \\ 
  Blink Mini Cam. & 52,839 & 1,477,004 & 132 & 0.00\% & 0.00\% \\ 
  Nest Cam. & 283,798 & 645,873 & 734 & 0.02\% & 0.02\% \\ 
  Lumiman Bulb & 42,274 & 49,855 & 113 & 0.07\% & 0.00\% \\ 
  Kasa Bulb & 8,667 & 6,434 & 146 & 1.09\% & 0.93\% \\ 
  LIFX Bulb & 1,207 & 408 & 21 & 0.00\% & 0.00\% \\ 
  ULTRALOQ U-Bolt Pro & 7,487 & 55541 & 137 & 0.05\% & 0.03\% \\ 
  Sensi Thermostat & 1,492 & 796 & 52 & 1.13\% & 0.00\% \\ 
  Nest Protect Smoke Alarm & 806 & 89 & 59 & 1.12\% & 1.12\% \\ 
  Rachio Sprinkler & 3,508 & 4,614 & 112 & 4.76\% & 0.11\% \\ 
  iRobot Roomba & 8,821 & 6,756 & 207 & 0.65\% & 0.25\% \\
  \midrule
  \textbf{Total/Average} & 585,239 & 2,374,651 & 3,503 & 0.78\% & 0.24\% \\
  \bottomrule
\end{tabularx}
\vspace{-1em}
\label{tab:device false positive}
\end{table}

\subsection{Monitoring Devices}\label{subsec:monitoring-devices}
\parheading{Monitoring Healthy Devices.}
First, we use the \system{} dataset to evaluate the performance of \system{}. In particular, we evaluate the performance of Monitor in monitoring uninfected devices using the created device profiles. 
Table \ref{tab:device false positive} provides FPR for each device. We measure FPR in two scenarios: (1) matching external address, packet direction, and length (see \textbf{End. \& Len.}); and (2) matching external address and packet direction (see \textbf{End.}) in Monitor's entry with the corresponding features in any profile entry in the device profile. \system{} incurs low FPR for all devices: 0.78\% and 0.24\% on average for both scenarios respectively.

\parheading{Public Dataset 1: BehavIoT.}
We also evaluate \system using a public dataset called BehavIoT~\cite{hu2023behaviot}. The BehavIoT dataset contains 32 uninfected IoT devices, among which three devices (\ie{} Amazon Plug, Ring Doorbell, and Nest Thermostat) are present in our setup as well. This dataset contains both LAN and WAN traffic for all possible events of each device. We only use the LAN traffic in alignment with our setup. 
We divide the LAN traffic per device per event into two equal parts. One part is used by Profiler to build device profiles (\ie{} training phase). The other part is used to evaluate the performance of Monitor (\ie{} monitoring phase). 

\begin{table}[t!]
\scriptsize
\centering
\caption{False Positive Rate of uninfected devices from BehavIoT dataset. The last row gives the \textbf{Total} for \textbf{\# Training Packets (Trng. Pkts.)}, \textbf{\# Monitoring Packets (Mnt. Pkts.)} and \textbf{\# Profile Entries (Prof. Ents.)}, and \textbf{Average} for \textbf{FPR}.}
\begin{tabularx}{\linewidth}{p{15mm} r r r r r}
  \toprule
  \textbf{Device Name} & \textbf{\# Trng.} &\textbf{\# Mnt.} & \textbf{\# Prof.} & \multicolumn{2}{c}{\textbf{\underline{False Positive Rate (FPR)}}} \\
  & \textbf{Pkts.} & \textbf{Pkts.} & \textbf{Ents.} & \textbf{End. \& Len.} & \textbf{End.}\\
  \midrule
 Tp-Link Bulb & 14,928 & 15,026 & 94 & 0.07\% & 0.00\% \\ 
Tp-Link Plug & 3,467 & 3,474 & 51 & 0.14\% & 0.00\% \\ 
Magic Home Strip Light & 2,592 & 2,597 & 19 & 0.00\% & 0.00\% \\ 
Smart Life Bulb & 5,599 & 5,511 & 23 & 0.18\% & 0.00\% \\ 
Nest Thermostat & 8,197 & 7662 & 245 & 1.59\% & 0.00\% \\ 
Bulb1 & 1,860 & 1,830 & 16 & 0.05\% & 0.00\% \\ 
Govee LED & 3,600 & 3,600 & 12 & 0.36\% & 0.36\%  \\ 
Gosund Bulb & 3,587 & 3,627 & 21 & 0.03\% & 0.00\% \\ 
Meross Door Opener & 621 & 647 & 21 & 2.94\% & 0.00\% \\ 
Amazon Plug & 1,297 & 1,263 & 41 & 0.39\% & 0.00\% \\ 
Echo Spot & 17,822 & 15,827 & 618 & 3.28\% & 1.24\% \\ 
Echo Show & 17,127 & 16,700 & 575 & 3.03\% & 0.25\% \\ 
Echo Dot & 3,803 & 4,247 & 131 & 2.33\% & 0.47\% \\ 
Philips Hub & 17,936 & 17,793 & 254 & 0.35\% & 0.00\%\\ 
SmartThings Hub & 1,568 & 1,498 & 81 & 0.47\% & 0.00\%\\ 
Aqara Hub & 862 & 801 & 40 & 0.49\% & 0.00\% \\ 
IKEA Hub & 2,170 & 2,172 & 51 & 0.00\% & 0.00\% \\
Wemo Plug & 11,390 & 10,795 & 87 & 0.17\% & 0.00\% \\ 
Wansview Cam. & 290,372 & 293,693 & 1104 & 0.05\% & 0.00\% \\ 
Lefun Cam. & 105,723 & 105,362 & 1,717 & 0.36\% & 0.00\%\\ 
Dlink Cam. & 229,960 & 236,918 & 1,576 & 0.04\% & 0.00\%\\ 
Microseven Cam. & 290,639 & 298,642 & 1,668 & 0.13\% & 0.00\%\\ 
Ring Door Bell & 238,173 & 234,583 & 3241 & 3.10\% & 0.00\% \\ 
Ring Cam. & 311,528 & 301520 & 12387 & 3.82\% & 0.00\% \\ 
Ubell Doorbell & 237,400 & 230,272 & 2581 & 0.06\% & 0.00\% \\ 
Wyze Cam. & 478,060 & 506,694 & 1,146 & 0.39\% & 0.00\% \\ 
Yi Cam. & 189,899 & 189,395 & 1,365 & 0.19\% & 0.00\% \\
Tuya Cam. & 477,039 & 497,072 & 293 & 0.01\% & 0.00\% \\
ICsee Doorbell & 268,628 & 271,611 & 1635 & 0.06\% & 0.00\% \\ 
SwitchBot Hub & 728 & 722 & 11 & 0.00\% & 0.00\% \\ 
iKettle & 18 & 33 & 6 & 6.06\% & 0.00\% \\
Google Home Mini & 8,089 & 7,900 & 861 & 9.29\% & 0.51\% \\
\midrule
\textbf{Total/Average} & 3,244,673
& 3,289,487 & 31,971 & 1.23\% & 0.09\% \\
\bottomrule
\end{tabularx}
\vspace{-1em}
\label{tab:device false positive behavIot}
\end{table}

Table \ref{tab:device false positive behavIot} provides the number of packets, profile entries, and FPR of each healthy device from this dataset.
\system{} shows relatively high FPR for a few devices from this dataset when the external address, packet direction, and length are matched. However, FPR is zero or very low when only the external address and packet direction are matched. Most of these devices are comparatively complex devices (\eg{} cameras and voice assistants). We observe that exact length matching is less effective for complex devices that may generate a more diverse traffic pattern compared to simpler devices (\eg{} plugs and bulbs). Instead, if we relax the matching criteria (\eg{} allowing a slight variation of 2 bytes in packet length for Google Home Mini), FPR is almost totally eliminated.

\parheading{Monitoring Infected Devices.}
We use the RPi smart bulb for this purpose. In the training phase, we build the device profile for the RPi smart bulb without infecting it with malware. Next, we infect the RPi smart bulb with Mirai, Lizkebab, Bashlite, and 100 randomly selected ARM malware binaries from~\cite{alrawi2021circle}. Monitor is able to detect suspicious packets with \textbf{100\% TPR} for all malware in the following aspects, namely: (1) the network payload sent from the malware CCC during bot installation, (2) the periodic heart-beat communication between the bot and the CCC, and (3) the attack commands sent from the CCC to the bot.

\parheading{Public Dataset 2: Cryptojacking.}
Finally, we evaluate \system{} using another public dataset that we call the Cryptojacking dataset \cite{tekiner2022lightweight}. The Cryptojacking dataset consists of both benign and IoT cryptojacking malware traffic collected from a Raspberry Pi, a laptop, a LG Smart TV, and a server. We exclude server data from our evaluation since it is not an IoT device.  
For each of these devices, \system{} successfully detects malware traffic with \textbf{100\% TPR}. 

Thus, our evaluation of \system{} on the three datasets and two scenarios (\ie{} healthy and infected devices) indicates that \system is effective in profiling and monitoring IoT devices.

\subsection{Effectiveness of Feedback Loop}\label{subsec:effectiveness-feedback-loop}
We use the RPi smart bulb to evaluate the feedback loop's effectiveness.
During the training phase, the bulb receives \textit{turn on, turn off} commands and sends responses. Entries for the corresponding packets generated by the two commands are included in the device profile of the RPi smart bulb. In the monitoring phase, we create two scenarios: \textbf{(1)} \textit{healthy bulb (Case 1)}: the user device sends a new command to the RPi smart bulb. The RPi smart bulb is uninfected at this stage, \textbf{(2)} \textit{infected bulb (Case 2)}: the RPi smart bulb becomes infected with malware and malware tries to communicate with its CCC.

\parheading{Healthy Bulb (Case 1).}
During the training phase the commands and responses exchanged between the user device and RPi smart bulb, when turning on and off the RPi smart bulb are:  
\begin{itemize}
    \item \textbf{Command}: turn\_on (packet length=49) \\ \textbf{response}: \{``status":``200",``message": ``Light bulb turned on."\}  (packet length=95)
    \item \textbf{Command}: turn\_off (packet length=50) \\ \textbf{response}: \{``status": ``200", ``message": ``Light bulb turned off."\}  (packet length=96)
\end{itemize}
From Figure \ref{fig: positive feedback} we can see that the profile of the RPi smart bulb includes profile entries for these packets. However, during the monitoring phase, another previously unseen command (\ie{} status message) is exchanged:
\begin{itemize}
    \item \textbf{Command}: status (packet length=48) \\ \textbf{response}: \{``status": ``200", ``message": ``Light bulb is currently off."\} \\ (packet length=102)\}
\end{itemize}

Monitor detects the command packet as suspicious and requests attestation from Attester inside the RPi smart bulb. Attester confirms that the RPi bulb is healthy since it does not find any new process or any expected process with a wrong hash value. As a result, Monitor adds the command packet to the bulb's profile. The same process is repeated for the response packet. Afterward, subsequent \texttt{status} command and response packets are treated as benign and not subject to further attestation.

\parheading{Infected Bulb (Case 2).}
The RPi smart bulb is intentionally infected with a malware binary. This binary is randomly selected from the malware repository of \cite{alrawi2021circle}.  Figure \ref{fig: positive feedback} shows some packets exchanged between the malware CCC and the zombified RPi smart bulb. All of those packets are confirmed as suspicious through the feedback loop. However, we illustrate the process for the first packet only.

Figure \ref{fig: positive feedback} shows that external address of the packet is \textit{198.98.50.97}, the packet length is 74 and direction is \textit{Device-to-Server}. However, no profile entry in the RPi smart bulb's profile matches those values. Thus, Monitor detects the packet as suspicious and calls Attester. Attester reports that new processes are running on the RPi smart bulb, which confirms that the RPi smart bulb is infected by malware, as shown in the warning message in the log file. 

\subsection{Performance Overheads}\label{subsec:performance-overheads}
The \ta{} technique deployed by \system{} to detect anomaly in the network traffic is very lightweight. The fourth column in Tables~\ref{tab:device false positive} and~\ref{tab:device false positive behavIot} denotes the number of profile entries, \ie{} maximum search space for matching packets of a specific device.
We observe that FPR is consistently low and TPR is consistently high in experimental settings and public datasets. 

\parheading{Runtime Overhead.}
In addition, the detection is fast. The total time for \system{} to extract endpoints and length properties from a packet, classify the packet as benign or suspicious, and verify the detection through the feedback loop is on average 1.6 ms. % +- 0.79 ms. 
Note that this is an upper bound since our proof of concept implementation is in Python. An implementation in low-level languages such as C/C++ would result in better timing performance. 

\parheading{Storage Overhead.}
We can also determine the absolute upper bound of the total number of device profile entries stored in the memory of the router during the monitoring phase: $n=d * e * l $,
where $n$ represents the number of profile entries of all devices being monitored, $d$ represents the number of devices being monitored, $e$ represents the average number of packet direction-external address pairs for each device, and $l$ represents the average number of unique packet lengths per packet direction-external address pair. 

The average value of $l$ is 23 for the \system{} dataset and 58 for the BehavIoT dataset. The average value of $e$ is 13 for the \system{} dataset and 18 for the BehavIoT dataset.

\subsection{Comparison with Prior Works}
\label{subsec: comparison-prior-works}
In this section, we compare the performance of \system{} with two \ta-based  \cite{meidan2018n,nguyen2019diot} and one \ra-based \cite{vrasedp} systems from prior work. Table~\ref{tab:performance comparison} presents the details. \system{}'s TPR is 100\%, which means that \system can detect every malware-generated packet correctly. In other words, \system{} is more robust than D\"IoT~\cite{nguyen2019diot} and the same as N-BaIoT~\cite{meidan2018n}, VRASED~\cite{vrasedp}. The attack/malware infection detection time of \system{} is far better than all other approaches. This is due to the simple heuristic algorithm of comparing only three features from each packet. \system{} is able to detect the very first packet generated by malware, and it requires only 1.6 ms on average to do so. In comparison, N-BaIoT needs 174 ms and D\"IoT requires 256 ms for detection. The heavy machine learning models used in N-BaIoT (Autoencoder) and D\"IoT (Gated Recurrent Unit) cause these longer detection times. The detection time of VRASED depends on the frequency of remote attestation, i.e., how soon it is performed after infection, plus the time required to complete attestation. Additionally, the attestation time is proportional to memory size since VRASED calculates HMAC over the entire memory as part of the operation. It takes 450 ms to complete attestation for 4KB memory. This attestation time is significantly longer compared to \system{}'s. \system{}'s FPR is slightly higher compared to the other approaches. However, this FPR for off-the-shelf devices is overestimated since it is calculated without considering the feedback loop. The same packet is counted as false positive many times. For example, the packet with external address \textit{www.google.com}, packet direction \textit{Server-to-Device}, and length \textit{409} is counted 13 times in the calculation of the FPR of the Google Home Mini device from BehavIoT dataset. With the feedback loop, the packet would only be considered suspicious once. 
\begin{table}[t!]
	\scriptsize
	\centering
        \caption{Performance comparison of \system{} with prior approaches.}
	\begin{tabularx}{\linewidth}
{r p{15mm} r r r}
  \toprule
  \textbf{Approach} & \textbf{\# Required Features} & \textbf{TPR} & \textbf{FPR} & \textbf{Detection Time (ms)} \\
  \midrule
  \textbf{\system{}} & \textbf{3} & \textbf{100.0\%} & \textbf{0.78\%} & \textbf{1.6}\\
  N-BaIoT \cite{meidan2018n} & 114 & 100.0\% & 0.007\% & 174 \\
  %\midrule
  D\"IoT \cite{nguyen2019diot} & 7 & 95.6\% & 0\% & 256 \\
  %\midrule
  VRASED \cite{vrasedp} & N/A & 100.0\% & 0\% & attestation freq. + 450\\
  %\midrule
  \bottomrule
\end{tabularx}
\vspace{-1em}
\label{tab:performance comparison}
\end{table}

\subsection{Energy Savings}
\label{subsec: energy-savings}
In this section, we attempt to quantify the energy saved by the feedback loop of \system{} over plain periodic remote attestation. For this purpose, we consider two IoT devices: (1) DCS-930L Security Camera \cite{DCS-930L}, a higher-end device that was compromised by Mirai \cite{nguyen2019diot}; and (2) TI MPS430, a bare metal IoT device, on top of which VRASED is implemented. Table~\ref{tab:attestation energy} shows the summary of the energy consumption rates for periodic \ra{} on these two devices in a year.

DCS-930L camera is not capable of \ra{}. However, if it was, we assume that its \ra{} time would be similar to the emulated RPi bulb since both have comparable operating systems and processing powers. The power consumption of the DCS-930L camera is 1.84 W~\cite{DCS-930L-specs}, whereas the \ra{} time is considered to be 1.6 ms. This results in 0.49 mWh energy consumption per \ra{}. If \ra{} is performed once every 5 minutes to detect an attack within a reasonable time frame, the total energy consumption to perform \ra{} over a year becomes 5,157.9 mWh. Energy consumption for ``somewhat instantaneous'' detection (\ie{} within 1 minute of infection) is even higher, namely 25,789.4 mWh or $\sim$26 Wh. \textit{In other words, the camera would need at least $\sim$14$\times$ the amount energy that it needs to operate in one hour, just to perform \ra{} in a year without any guarantee of \textit{actually} detecting the malware.}

TI MSP430 consumes 1.2 mWh power in active mode \cite{TI-MSP430-specs}, and the attestation time of VRASED is 450 ms. This results in 0.009 mWh energy per attestation, 946.1 mWh over the year when the attestation period is 5 minutes and 4,730.4 mWh for an attestation period of 1 minute. This is a critical energy burden for an ultra-low power device that requires only 400 $\mu$A current during the active period. 

Energy consumption of periodic attestation can be drastically reduced by adopting \system{} since \system{} triggers attestation \textit{only} when there is a suspicious packet because of the rare events: actual malware infections or firmware updates.
\begin{table}[t!]
	\scriptsize
	\centering
        \caption{Comparison on total yearly energy consumption of periodic \ra{} (Without \system{}) for various intervals.}
	\begin{tabularx}{\linewidth}
{r r r r r r}
  \toprule
  \textbf{Device Name} & \multicolumn{5}{c}{\textbf{Energy Consumption (mWh) for Attestation Intervals}} \\
  \cline{2-6}
  & \textbf{1 hour} & \textbf{30 mins} & \textbf{10 mins} & \textbf{5 mins} & \textbf{1 min}\\
  \midrule
  DCS-930L Cam. & 423.9 & 859.6 & 2,578.9 & 5,157.9 & 25,789.4 \\
  TI MPS430 & 77.8 & 157.7 & 473.0 & 946.1 & 4,730.4\\
  \bottomrule
\end{tabularx}
\vspace{-1em}
\label{tab:attestation energy}
\end{table}