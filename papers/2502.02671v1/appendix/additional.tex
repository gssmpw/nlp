\begin{figure}[ht]
    \centering
    \includegraphics[width=0.99\linewidth]{figures/plots/wmt_base_student_large_teacher_forward_kl_exp0.pdf}
    \includegraphics[width=0.99\linewidth]{figures/plots/natural_instructions_base_student_large_teacher_forward_kl_exp0.pdf}
    \caption{\textbf{Impact of the dataset choice: offline vs. online data sources.} 
    We verify our claims on the presence of teacher hacking in the case of offline data sources for two different tasks: the translation task on WMT-14 en-de (top row) and the instruction following task on Natural Instruction (bottom row). In general, the behavior of the curves is the same across all the datasets: for online data sources, both proxy and golden metrics are decreasing. At the same time, for offline data sources, the proxy metric is decreasing or stagnating, whereas the golden metric is clearly increasing.
    }
    \label{fig:datasets_exp_large_to_base_online_fwd_kl}
\end{figure}

\section{Additional experiments}\label{app:add_plots}

This section presents additional experiments on teacher hacking across various datasets, model sizes, and loss types, as well as an additional experiment on the effect of mixing offline and online data.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.99\linewidth]{figures/plots/wmt_base_student_large_teacher_forward_kl_exp1.pdf}
    \includegraphics[width=0.99\linewidth]{figures/plots/natural_instructions_base_student_large_teacher_forward_kl_exp1.pdf}
    \caption{\textbf{Impact of the dataset choice: dataset diversity.} Across other datasets, we can notice that the impact of diversity is still present for the instruction-following task but not for the translation task. It can be explained by the initially small diversity of the WMT-14 dataset.
    }
    \label{fig:datasets_exp_large_to_base_diversity_fwd_kl}
\end{figure}

\subsection{The impact of the dataset}

In this subsection, we validate our claims across various tasks, such as the translation task on the WMT-14 en-de dataset \cite{bojar2014findings} and the instruction-following task on the Natural Instructions dataset \cite{naturalinstructions,supernaturalinstructions}. We consider the same pair of models: T5-large as the teacher model and T5-base as the student model, utilizing forward KL token-level loss along with the corresponding proxy and golden metrics.

\paragraph{Online vs. offline data sources.}
The results of the comparison of online and offline data sources on the WMT-14 en-de and Natural Instruction datasets are presented in \Cref{fig:datasets_exp_large_to_base_diversity_fwd_kl}. 

Overall, we observe the same phenomenon as noted in the summarization task in \Cref{sec:results}. The general patterns are consistent: for all data sources, the training loss decreases slowly for online data sources, as expected, while the proxy metric decreases or stagnates, showing no signs of classical overfitting. However, the golden metric continues to decline in the case of offline data sources, and it starts declining in the case of offline data source, indicating the presence of teacher hacking.


\paragraph{Diversity of offline data sources.}

Next, we study the impact of the diversity of the dataset on teacher hacking, following the setup described in \Cref{sec:diversity}. The results are presented in \Cref{fig:datasets_exp_large_to_base_diversity_fwd_kl}. We observe the same detrimental effect of the decreasing of the dataset diversity in the case of the instruction following task. However, in the case of the translation task, it almost has no effect. We could connect this effect to the small diversity or difficulty of the initial dataset since it contains only relatively short sentences.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.99\linewidth]{figures/plots/wmt_base_student_large_teacher_forward_kl_exp2.pdf}
    \includegraphics[width=0.99\linewidth]{figures/plots/natural_instructions_base_student_large_teacher_forward_kl_exp2.pdf}
    \caption{\textbf{Impact of the dataset choice: generation budget.} 
    We additionally confirm the claim on the positive impact of a larger number of generations per prompt across two other datasets.
    }
    \label{fig:datasets_exp_large_to_base_gen_fwd_kl}
\end{figure}

\paragraph{Generation budget.} Finally, we verify the claims on increasing the generation budget for the offline data sources. The results are presented in \Cref{fig:datasets_exp_large_to_base_gen_fwd_kl}. In this case, for both tasks, we observe an improvement in the golden metric, especially for the translation task, and we observe a marginal improvement in the proxy metric. As in the case of the summarization task, it signals the decreasing teacher hacking effect.


\subsection{The impact of student and teacher model sizes}

In this subsection, we validate our findings across different student and teacher model sizes using the XSum dataset and forward KL token-level loss.

\paragraph{Online vs. offline data sources.}
We conduct distillation experiments from T5-base to T5-small and from T5-large to T5-small, evaluating performance across offline and online data sources. The results are shown in \Cref{fig:sizes_exp_large_to_base_online_fwd_kl}.

For online data sources, both the proxy and golden metrics decrease monotonically, regardless of the model sizes, confirming our earlier observations. In contrast, for offline data sources, the golden metric consistently increases. Notably, in the case of distilling T5-large to T5-small, the proxy metric also shows a slight increase, indicating standard overfitting rather than teacher hacking. Meanwhile, when distilling T5-base to T5-small, the proxy metric stagnates, suggesting the presence of teacher hacking.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.99\linewidth]{figures/plots/xsum_small_student_base_teacher_forward_kl_exp0.pdf}
    \includegraphics[width=0.99\linewidth]{figures/plots/xsum_small_student_large_teacher_forward_kl_exp0.pdf}
    \caption{\textbf{Impact of the model sizes: offline vs. online data sources.} 
    We examine the train loss and proxy/golden metrics for two model size pairs: T5-base as the teacher and T5-small as the student (top), and T5-large as the teacher and T5-small as the student (bottom). For both pairs, no teacher hacking occurs with online data generation. However, teacher hacking is observed during distillation from T5-base to T5-small, as the proxy metric stagnates while the golden metric decreases. In contrast, distillation from T5-large to T5-small shows behavior consistent with standard overfitting as the proxy metric slightly increases. This may be attributed to the larger difference in model sizes.
    }
    \label{fig:sizes_exp_large_to_base_online_fwd_kl}
\end{figure}

\subsection{The impact of token-level loss functions}


\begin{figure}[ht]
    \centering
    \includegraphics[width=0.99\linewidth]{figures/plots/xsum_base_student_large_teacher_js_05_exp0.pdf}
    \includegraphics[width=0.99\linewidth]{figures/plots/xsum_base_student_large_teacher_reverse_kl_exp0.pdf}
    \caption{\textbf{Impact of the loss type: offline vs. online data sources.} 
    We can observe that the effect of teacher hacking appears regardless of the choice of loss function.
    }
    \label{fig:losses_exp_large_to_base_online_fwd_kl}
\end{figure}

In this subsection, we examine how the choice of token-level loss function and proxy/golden metrics influences the teacher hacking phenomenon. The experiments are conducted using the XSum summarization dataset, with T5-base as the student model and T5-large as the teacher model.

\paragraph{Online vs. offline data sources.}
This experiment compares different data sources using two token-level loss functions: Jensen-Shannon divergence and reverse KL divergence, alongside their corresponding proxy and golden metrics. The results are shown in \Cref{fig:losses_exp_large_to_base_online_fwd_kl}.

The observed behavior across all plots closely resembles that of the forward KL loss. Specifically, when using online data sources, both proxy and golden metrics decrease monotonically. In contrast, for offline data sources, proxy metrics continue to decrease, but the golden metric increases, signaling the presence of teacher hacking.

Additional experiments were conducted using generalized Jensen-Shannon divergences with coefficients of $0.1$ and $0.9$. However, their performance was either comparable to or worse than reverse or forward KL divergence for the respective proxy and golden metrics. As a result, they are excluded from the comparison.


\subsection{Offline-online data mixtures}

In this subsection, we examine how varying mixtures of offline and online data influence the occurrence of teacher hacking. The experiment uses the XSum dataset, T5-base as the student model, T5-large as the teacher model, and forward KL token-level loss, following \Cref{sec:results}.

We use the following procedure to generate each training batch: with probability $\alpha$, the batch is sampled from a fixed offline dataset, and with probability $1-\alpha$, it is generated by the current student model. This process is repeated at each training step. We evaluate three values for $\alpha$: 0.1, 0.5, and 0.9, corresponding to 10\%, 50\%, and 90\%  offline data proportion, respectively. The results are shown in \Cref{fig:mixture_exp_large_to_base_online_fwd_kl}.

Our results show that increasing the proportion of \textit{online} data in the distillation process (that is equivalent to decreasing the proportion of offline data) significantly improves the golden metric. Even with 10\% online student data (corresponding to 90\% offline data), the golden metric plateaus, thus effectively reducing teacher hacking. Higher proportions of online data further mitigate the effect, with 90\% online student data resulting in training dynamics nearly identical to those observed when using only student-generated data.

\paragraph{Discussion.} These results suggest that exclusively using online-generated data is not required to avoid teacher hacking. Instead, incorporating a fraction of online-generated data during the distillation process is sufficient. In particular, as little as 10\% online data can substantially reduce the impact of teacher hacking.



\begin{figure}[ht]
    \centering
    \includegraphics[width=0.99\linewidth]{figures/plots/xsum_base_student_large_teacher_forward_kl_exp3.pdf}
    \caption{\textbf{Mixture of offline and online data.} 
    This plot compares strategies for combining offline and online data during the distillation process. The results show that incorporating just 10\% online student data significantly reduces the effect of teacher hacking, causing the golden metric to stabilize rather than increase.  At the same time, the usage of at least 50\% of the online generated data allows to avoid the effect of teacher hacking completely.
    }
    \label{fig:mixture_exp_large_to_base_online_fwd_kl}
\end{figure}