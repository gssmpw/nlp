\documentclass[letterpaper, conference]{IEEEtran}
\IEEEoverridecommandlockouts

\include{def.tex}
\allowdisplaybreaks

\newcommand{\lina}[1]{\textcolor{blue}{[Lina: #1]}}

% line breaks in equations
% \let\darray\relax
% \let\enddarray\relax
% \usepackage{breqn}

% --------------------------------------------------------------------------------%

\title{\vspace{0.5cm}Ergodic-Risk Constrained Policy Optimization:\\ The Linear Quadratic Case
\thanks{The authors are with the School of Engineering and Applied Sciences, Harvard University, Cambridge, USA. Emails: \textit{talebi@seas.harvard.edu} and  \textit{nali@seas.harvard.edu}. This work is supported by NSF AI Institute 2112085. }
}
% Riemannian Constrained Policy Optimization via Geometric Stability Certificates
% \author{Shahriar Talebi, \textit{Member, IEEE,} and Na Li, \textit{Member, IEEE}
% \thanks{The authors are with Harvard University;\\ emails: {\em\small talebi@seas.harvard.edu} and {\em\small nali@seas.harvard.edu}. }
% }
% 
% }
\author{ Shahriar Talebi,  \ Na Li

% \IEEEauthorblockN{ Shahriar Talebi, \textit{Member, IEEE}}
% \IEEEauthorblockA{\textit{Harvard University} \\
% % Cambridge, USA\\
% % talebi@seas.harvard.edu
% }
% \and
% \IEEEauthorblockN{Na Li, \textit{Member, IEEE}}
% \IEEEauthorblockA{\textit{Harvard University}\\
% Cambridge, USA\\
% nali@seas.harvard.edu
% }
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
\maketitle

\begin{abstract}
Risk-sensitive control balances performance with resilience to unlikely events in uncertain systems. This paper introduces \textit{ergodic-risk criteria}, which capture long-term cumulative risks through probabilistic limit theorems.
By ensuring the dynamics exhibit strong ergodicity, we demonstrate that the time-correlated terms in these limiting criteria converge even with potentially heavy-tailed process noises as long as the noise has a finite fourth moment. Building upon this, we proposed the ergodic-risk constrained policy optimization which incorporates an ergodic-risk constraint to the classical Linear Quadratic Regulation (LQR) framework. We then propose a primal-dual policy optimization method that optimizes the average performance while satisfying the ergodic-risk constraints. Numerical results demonstrate that the new risk-constrained LQR not only optimizes average performance but also limits the asymptotic variance associated with the ergodic-risk criterion, making the closed-loop system more robust against sporadic large fluctuations in process noise.



% thereby
% extending the Linear Quadratic Regulation (LQR) framework by incorporating constraints on the ergodic-risk criteria.
% For quadratic risk functionals, in addition to ensuring internal stability, this requires the process noise---potentially heavy-tailed---to have only a finite fourth moment.
% We also propose a primal-dual policy optimization method that optimizes the average performance while satisfying the ergodic-risk constraints. Our framework offers a theoretically guaranteed approach for long-term risk-sensitive control and is validated through simulations.
\end{abstract}

\begin{IEEEkeywords}
	    \textit{Ergodic-risk; Risk-aware Optimal Control; Risk-averse Decision Making; Linear Quadratic Regulator (LQR); Uniformly Ergodic Chains; Constrained Policy Optimization}
\end{IEEEkeywords}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}
\label{sec:intro}

Optimizing average performance, as is typical in standard stochastic optimal control, often fails to yield effective policies for decision making in stochastic environments where deviations from expected outcomes carry significant risk; e.g. in financial markets \cite{rockafellar_optimization_2000}, safe robotics and autonomous systems \cite{majumdar_how_2020}, and healthcare \cite{eichler_risks_2013}.
As such, incorporating risk measures become vital in such decision making problems for balancing the performance with resilience to rare events.

While robust control frameworks (e.g. the mixed $\mathcal{H}_2$-$\mathcal{H}_\infty$ in \cite{zhang_policy_2021}), focus on incorporating the worst-case scenario performance (e.g. $\mathcal{H}_\infty$-norm) as a constraint, they can be overly conservative (or occasionally unfeasible) when those unlikely events are (possibly) unbounded. Risk-aware approaches, on the other hand, offer a (probabilistic) compromise by building on available stochastic priors to manage both risk and performance, simultaneously. 
Consequently, there have been significant efforts \cite{whittle_risk-sensitive_1981,borkar_risk-constrained_2014,chow_risk-constrained_2018,sopasakis_risk-averse_2019} in developing risk-aware decision making frameworks using tools like Conditional Value at Risk (CVaR) \cite{rockafellar_optimization_2000}, Markov Risk Measure \cite{ruszczynski_risk-averse_2010}, and Entropic Value at Risk (EVaR) \cite{ahmadi-javid_entropic_2012}, offering a better balance by considering both risk and average performance. 

These measures are often deployed on finite-horizon variables \cite{sopasakis_risk-averse_2019}, under finite first-hitting time \cite{chow_risk-constrained_2018}, and/or in finite state-space models \cite{borkar_risk-constrained_2014}. While these settings avoid complications regarding limiting probabilities, they may not fully capture \emph{long-term risk} associated with the stochastic behaviors, especially in \emph{unbounded general-state} Markov processes--see the recent survey \cite{biswas_ergodic_2023}.
%
Also at the stationary limits of the process, the optimal policy that minimizes the worst-case CVaR of the quadratic cost is shown to be equivalent to that of the \ac{lqr} optimal \cite{kishida_risk-aware_2023}. This is yet another evidence suggesting that risk-sensitive design is particularly critical in \emph{nonstationary} processes, where their statistical properties are still changing over time.
%
Among these, the folklore risk-sensitive framework by Whittle \cite{whittle_risk-sensitive_1981}, aka Linear Exponential Quadratic Gaussian (LEQG), handles the general unbounded, nonstationary setting--which (in certain parameter regimes) can be interpreted as optimizing a specific mixture of the average performance and its higher moments (e.g. variance). However, the Gaussian noise (with finite moments of all orders) is critical for the exponentiation to be well-defined, and thus does not capture cases with \textit{heavy-tailed noise} distributions modeling rare events. This motivated \cite{tsiamis_risk-constrained_2020} to introduce a framework for constraining the uncertainty in the ``state-related portion'' of the finite-horizon \ac{lqr} cost, which is then extended to infinite-horizon through policy optimization techniques \cite{zhao_global_2023}.


% This paper considers the stochastic Linear Time Invariant (LTI) model with process noise having finite moments up to the \textit{fourth order}, prototyping a framework for risk-aware decision-making in unbounded, nonstationary Markov processes with (possibly) heavy-tailed noise.
This paper considers the stochastic Linear Time Invariant (LTI) model with (unbounded) \textit{heavy-tailed} process noise, providing a framework for risk-aware decision-making in \textit{unbounded}, \textit{nonstationary} Markov processes.
% \lina{revise the sentence to highlight the ``surprising'' part, contribution: I will first say unbounded, nonstationary Markov .. heavy-tailed noise. And then say as long as it has finite 4th order moments. Actually I don't think you need to talk about 4th order moments in the first sentence. This is just a first sentence to introduce the contribution} \shahriar{got it. let me try this...}
%
We introduce \emph{ergodic-risk criteria} to address risks in the long-term stochastic behavior, accounting for extreme deviations beyond mean performance (\Cref{sec:probSetup}). 
%
Built upon this, we propose the ergodic-risk constrained policy optimization which incorporates the ergodic-risk constraints in the classical LQR framework. 
%
By ensuring a strong ergodicity of the process \cite{meyn_markov_2009}, we handle system's state correlations and characterize \textit{quadratic} ergodic-risk criteria as long as the process noise has finite fourth moment (\Cref{sec:F-CLT}). 
%
This enables us to address long-term risk in non-stationary processes, previously excluded from the literature (see e.g. \cite{kishida_risk-aware_2023}).
%
We then consider a primal-dual policy optimization method based on strong duality that optimizes the average performance while meeting the risk constraints (\Cref{sec:primal-dual}), with convergence guarantee in \Cref{subsec:convergence}. 
Finally, we demonstrate the numerical performance of the algorithm over randomly sampled problem instances and contrast the quality of the ergodic-risk optimal policy against the LQR optimal policy (\Cref{subsec:simulations}). 
%


Finally, our ergodic-risk analysis is fundamentally different than that of \cite{tsiamis_risk-constrained_2020,zhao_global_2023} and in fact, the proposed Ergodic-risk framework (\Cref{thm:C-infty-N-convergence}) generalizes to provably capture the long-term risk associated with heavy-tailed noise for any quadratic functional of \emph{both} the states and the inputs. However similar to \cite{tsiamis_risk-constrained_2020,zhao_global_2023}, the strong duality (\Cref{sec:strong-duality}) and the resulting primal-dual algorithm (\Cref{sec:primal-dual-algo}) are established only for the case in which the risk functional does not explicitly depend on the input signal. 
% \lina{revise the contribution similar to the flow in the abstract.}

% Our contributions are: (1) formalizing the ergodic-risk criterion as an extension of risk-sensitive control (\Cref{sec:probSetup}) and studying its theoretical properties (\Cref{sec:F-CLT}), (2) integrating it into a ergodic-risk control synthesis (\Cref{sec:ergodic-risk-control}), and (3) proposing a constrained policy optimization framework using a primal-dual method that optimizes average performance while meeting risk constraints (\Cref{sec:primal-dual}), with a convergence guarantee and validations through simulations (\Cref{subsec:convergence-simulations}). Our framework generalizes that of \cite{zhao_global_2023} when the risk functional does not explicitly depend on the input signal (see \Cref{subseq:R-c-0}).

% In this paper, we focus on the stochastic Linear Time Invariant (LTI) model with process noise that has bounded moments only up to fourth order. This setup prototypes our framework for studying risk-aware decision making in unbounded general-state, nonstationary Markov processes with heavy-tailed process noise. Additionally, in order to capture the risk involved in the long-term stochastic behavior of the process, we propose the so-called the \emph{ergodic-risk constraints}, where risk measures are characterized by probabilistic limit theorems. By focusing on stochastic systems, we capture risks beyond mean performance, considering extreme deviations over time. Extending Linear Quadratic Regulation (LQR), we incorporate risk-sensitive constraints using stochastic processes and ergodic theory \cite{meyn_markov_2009}, applying Functional Central Limit Theorems (F-CLT) to manage system noise correlations. This enables us to reason about the risk occurred on limiting performance criteria for non-stationary processes (where neither the state space and nor the noise is bounded) that were excluded in the literature before (see e.g. \cite{kishida_risk-aware_2023}). 

% The contributions are threefold: (1) formalizing the ergodic-risk criterion as an extension of existing risk-sensitive control (\Cref{sec:probSetup}), (2) incorporating this criterion into a liming-risk aware control synthesis procedure (\Cref{sec:ergodic-risk-control}), and (3) proposing a practical policy optimization framework with a primal-dual method that optimizes average performance while satisfying the risk constraints, particularly in the linear case (\Cref{sec:primal-dual}). Our proposed framework recovers the one in \cite{zhao_global_2023} as a special case where the risk functional is chosen not to be a function of the input signal explicitly (see \Cref{subseq:R-c-0}).


% \newpage
% Risk-aware strategies are essential in decision making and control under uncertainty, where balancing performance with resilience to rare events is key. While robust control focuses on worst-case scenarios, it can be overly conservative and inefficient when those scenarios are unlikely. Risk-aware approaches, using tools like Conditional Value at Risk (CVaR) \cite{rockafellar_optimization_2000} and Entropic Value at Risk (EVaR) \cite{ahmadi-javid_entropic_2012}, offer a better balance by managing both risk and performance in areas like autonomous systems, finance, and industrial processes \cite{chow_risk-constrained_2018} \shahriar{I'll add another ref here as well.}. However, these measures are often used on finite-horizon variables, which may not fully capture long-term stochastic behaviors, especially in non-stationary systems (and general-state Markov chains) with heavy-tailed distributions.


% Recent work on policy optimization in constrained settings has focused on both the expectation of performance and the variance of costs, linking risk-constrained optimal control to coherent risk measures like worst-case CVaR \cite{kishida_risk-aware_2023}. In this context, the Linear Exponential Quadratic Gaussian (LEQG) framework can be interpreted as optimizing a specific mixture of the average performance and its variance for certain parameter regimes \cite{whittle_risk-sensitive_1981}. 
% Also, the mixed $\mathcal{H}_2$-$\mathcal{H}_\infty$ frameworks, as explored in \cite{zhang_policy_2021}, provide a robust synthesis approach, which builds upon incorporating $\mathcal{H}_\infty$ performance as a constraint to restrict the worst-case system norm. Also \cite{tsiamis_risk-constrained_2020} introduces a framework to constrain the cumulative variance of the state-related portion of LQR cost, which is then extended to infinite-horizon through policy optimization techniques \cite{zhao_global_2023}.

% In this paper, we propose the \emph{ergodic-risk constraints}, where risk measures are characterized by probabilistic limit theorems. By focusing on stochastic systems, we capture risks beyond mean performance, considering extreme deviations over time. Extending Linear Quadratic Regulation (LQR), we incorporate risk-sensitive constraints using stochastic processes and ergodic theory \cite{meyn_markov_2009}, applying Functional Central Limit Theorems (F-CLT) to manage system noise correlations. This enables us to reason about the risk occurred on limiting performance criteria for non-stationary processes (where neither the state space and nor the noise is bounded) that were excluded in the literature before (see e.g. \cite{kishida_risk-aware_2023}). 

% The contributions are threefold: (1) formalizing the ergodic-risk criterion as an extension of existing risk-sensitive control (\Cref{sec:probSetup}), (2) incorporating this criterion into a liming-risk aware control synthesis procedure (\Cref{sec:ergodic-risk-control}), and (3) proposing a practical policy optimization framework with a primal-dual method that optimizes average performance while satisfying the risk constraints, particularly in the linear case (\Cref{sec:primal-dual}). Our proposed framework recovers the one in \cite{zhao_global_2023} as a special case where the risk functional is chosen not to be a function of the input signal explicitly (see \Cref{subseq:R-c-0}).

% -------------------------------------------------------- %

\section{Ergodic-Risk Criteria and Problem Setup}
\label{sec:probSetup}
Consider the discrete-time stochastic linear system,
\begin{equation}\label{eq:dynamics}
    \x_{t+1} = A \x_{t} + B \u_{t} + H \w_{t+1}, \quad t\geq 0,
\end{equation}
where $A \in \Amatrices$, $B \in \Bmatrices$, and $H \in \Hmatrices$ are system parameter matrices, $\x_t$ and $\u_t$ denote the stochastic state and input (vectors), respectively. Also, $\w_t$ is denoting the process noise and $\x_0$ is the initial state vectors. $\w_t$ and $\x_0$ are independently sampled from zero-mean probability distributions $\prob[\w]{}$ and $\prob[0]{}$ with covariances $\Sigma_W$ and $\Sigma_0$, respectively. The history of state-input trajectory up to time $t$ is denoted by $\H_t = \{\x_j,\u_j\}_{j=0}^{t}$, and $\F_t = \sigma(\H_t)$ denotes the $\sigma$-algebra generated by $\H_t$. 
Each $\w_t$ is measurable with respect to $\F_{t}$, denoted by $\w_t \in\F_{t}$.
Let $\F_{-1}$ denote the trivial $\sigma$-algebra, and $\F_{t-1}\vee \sigma\{\x_t\}$ denote the smallest $\sigma$-algebra containing both $\F_{t-1}$ and $\sigma\{\x_t\}$. At each time $t\geq 0$, we can apply an \textit{admissible} input $\u_t \in \mathcal{L}_2(\F_{t-1}\vee \sigma\{\x_t\})$, i.e. a square-integrable, measurable function with respect to $\F_{t-1}\vee \sigma\{\x_t\}$, and then measure the next state $\x_{t+1}$. 
%
We restrict ourselves to \textit{stationary Markov policies} $\pi$, measurable mappings independent of time $t$ that generate an input sequence $\{\u_t = \pi(\H_{t-1},\x_t)\}_t$ such that $\u_t$ is admissible for all time $t$ and does not depend on the history $\H_{t-1}$--see \cite{meyn_markov_2009,durrett_probability_2019} for further details regarding probabilistic notions.


We require the process noise and initial states to be uncorrelated across time, i.e.,
$\E[\x_0 \w_t^\intercal]= 0$, and $\E[\w_{t+\tau} \w_t^\intercal]=0, \; \forall t,\tau \geq 1$, so that $\w_t$ is independent of $\F_{t-1}$ for all $t\geq1$.
For simplicity, we pose the following assumption:
\begin{assumption}\label{assmp:noise}
    The sequence $\{\w_t\}$ is i.i.d. samples of a common zero-mean probability measure $\P_W$ that is non-singular with respect to Lebesgue measure on $\R^d$ and has a non-trivial density, with a finite covariance $\Sigma_W \succ 0$.
    \qed
\end{assumption}

Given an (admissible) input signal $\u = \{\u_t\}$, we define the cumulative \emph{performance cost}
\(
    J_{T}(\u) = \sum_{t=0}^T \x_t^\intercal Q \x_t +  \u_t^\intercal R \u_t,
\)
with $Q \succeq 0$ and
$R\succ 0$ being positive semidefinite and positive definite matrices,
respectively. The standard infinite-horizon \ac{lqr} problem is then to design a sequence of admissible inputs $\u=\{\u_t\}_0^\infty$ that minimizes
\begin{equation}\label{eq:costx0}
\textstyle
     J(\u) =  \limsup_{T\to\infty} \frac{1}{T} \E [J_T(\u)],
\end{equation}
subject to dynamics in \Cref{eq:dynamics}.
It is well known \cite{goodwin_control_2001} 
that the optimal solution reduces to solving the \ac{dare} for a cost matrix $P_{\mathrm{LQR}}$ and the LQR optimal input is $\u_t^*= K_{\mathrm{LQR}} \x_t$ with the controller (or ``policy'') 
\(K_{\mathrm{LQR}} = - (R + B^\intercal P_{\mathrm{LQR}} B)^{-1} B^\intercal P_{\mathrm{LQR}}  A.\)
% \lina{I see that we have space now. We can use display math mode for more equations which help readability}
% \begin{multline*}
%     P_{\mathrm{LQR}} = A^\intercal P_{\mathrm{LQR}} A + Q\\
%     - A^\intercal P_{\mathrm{LQR}} B (R + B^\intercal P_{\mathrm{LQR}} B)^{-1} B^\intercal P_{\mathrm{LQR}} A, 
% \end{multline*}
% for the unknown matrix $P_{\mathrm{LQR}}$ that quadratically parameterizes the so-called cost-to-go.
% Subsequently, one sets $\u_t^*= K_{\mathrm{LQR}} \x_t$, where the optimal \ac{lqr} gain (policy) $K_{\mathrm{LQR}} \in \Kmatrices$ is given by $K_{\mathrm{LQR}} = - (R + B^\intercal P_{\mathrm{LQR}} B)^{-1} B^\intercal P_{\mathrm{LQR}}  A,$
% and the optimal cost $J(\u^*) = \tr{P_{\mathrm{LQR}}\Sigma_W}$ with $\Sigma_W$ denoting the covariance of $\prob[\w]{}$. Note that $\Sigma_0$ will not affect the optimal cost.
So, the optimal LQR policy is a \emph{linear} stationary Markov policy, and we restrict ourselves to the same class in this work.








\subsection{Ergodic-Risk Criterion for Stochastic Systems}
We propose a risk criterion that captures the long-term accumulative uncertainty by adding step-wise uncertainties as the system evolves. Since each state $\x_t$ is observed iteratively, it is natural to consider the uncertainty at each stage and accumulate these contributions over time to characterize the overall risk. This leads to a cumulative uncertainty variable, which converges to a limiting value if properly normalized.
 
To formalize this, let us consider any measurable functional of choice $g:\R^n\times\R^m \mapsto \R$, called ``risk functional,'' for example a quadratic (or affine) function in $\x_t$ and $\u_t$ which evaluates the behavior of each sample path (possibly different than the performance cost $J_T$). At each time $t-1$, we have access to the past information in $\F_{t-1}$, so the risk factor at time $t$ is the ``uncertain component'' of the risk functional $g(\x_t,\u_t)$.
This motivates the following definition
\begin{equation}
    C_t \coloneqq 
    g(\x_{t},\u_{t}) -\E[g(\x_{t},\u_{t}) | \F_{t-1}], \quad \text{for $t\geq 0$,}
\end{equation}
 capturing the uncertainty in $g(\x_{t},\u_{t})$ at time $t$ relative to that past information---see \Cref{fig:one-step-risk}.
% \footnote{In particular, the quadratic choice $g(\x_{t},\u_{t}) = \x_t^\intercal Q\x_t$ captures the state-related uncertainty in the original cost that we aim to minimize; also see \cite{tsiamis_risk-constrained_2020}.}
%
To account for the long-term risk behavior, especially in non-stationary processes with heavy-tailed noise, we define the \textit{ergodic-risk criterion}\footnote{A \emph{(uniformly) ergodic} Markov process visits all parts of the state space and uniformly converges to a unique stationary distribution, regardless of the starting point; see \cite{meyn_markov_2009}.} $C_\infty$ as the limit of the normalized cumulative uncertainty:
\begin{equation}\label{eq:def-C-infty}
\textstyle
    \frac{1}{\sqrt{t}} S_t \coloneqq \frac{1}{\sqrt{t}} \sum_{s=0}^t C_s \xrightarrow{d\;} C_\infty, \quad t\to\infty.
\end{equation}
We also consider the \emph{asymptotic conditional variance} $\gamma_N^2$ defined as the limit
\begin{equation}\label{eq:cond-var-def}
\textstyle
     \frac{1}{t} N_t\coloneqq \frac{1}{t} \sum_{s=1}^{t} \E[C_s^2|\F_{s-1}] \xrightarrow{a.s.} \gamma_N^2, \quad t\to \infty,
\end{equation}
which would serve as an ``estimate'' of the asymptotic variance of $C_\infty$, whenever well-defined (see \Cref{rem:asymp-var-conditional-var}).

\begin{figure}[!pt]
    \centering
    \begin{tikzpicture}[scale=0.8, transform shape] 
    % Draw the axes
    \draw[thick,->] (-0.5,0) -- (5,0) node[right] {$\mathcal{L}^2(\mathcal{F}_{t-1})$};
    \draw[thick,->] (0,-0.5) -- (0,2.5) node[above right] {\hspace{-1cm}$\mathcal{L}^2(\mathcal{F}_{t-1})^\perp \subset \mathcal{L}^2(\mathcal{F}_{t})$};
    
    % Define the vector
    \coordinate (O) at (0,0); % Origin
    \coordinate (V) at (3,2); % Vector coordinates
    
    % Draw the vector with thicker line and larger arrowhead
    \draw[thick,->,line width=1.5pt,>=latex] (O) -- (V) node[above right] {$g(\x_{t},\u_{t})$};
    
    % Draw the projections
    \draw[dashed] (V) -- (3,0) node[below] {\color{blue}$\E[g(\x_{t},\u_{t}) | \F_{t-1}]$};
    \draw[dashed] (V) -- (0,2) node[left] {\color{red}$C_t$};
    
    % Add right angle markers (small squares)
    \draw (3.2,0) -- ++(0,0.2) -- ++(-0.2,0); % Right angle marker on x-axis projection
    \draw (0,2.2) -- ++(0.2,0) -- ++(0, -0.2); % Right angle marker on y-axis projection
    
    % Add back vectors on the x-axis and y-axis
    \draw[thick,<-,blue,line width=1.5pt,>=latex] (3,0) -- (0,0);  % Back vector along the x-axis
    \draw[thick,<-,red,line width=1.5pt,>=latex] (0,2) -- (0,0);  % Back vector along the y-axis
\end{tikzpicture}
    \caption{\small The conditional expectation in blue is the orthogonal projection of $g(\x_{t},\u_{t})$ onto $\mathcal{L}^2(\mathcal{F}_{t-1})$, i.e. its best estimate by the information up to time $t-1$, solving $\arg\min_{\hat g \in \mathcal{L}^2(\mathcal{F}_{t-1})} \sqrt{\E[(g - \hat g)^2]}$. 
    % \lina{try to write the ``loss'' function so it is more clear for people to know the meaning of ``best'' estimate.}. \shahriar{Sure, I've clarified this}
    So, $C_t$ (in red) then retains the ``uncertain component'' of $g(\x_{t},\u_{t})$.}
    \label{fig:one-step-risk}
    \vspace{-0.4cm}
\end{figure}
%

\noindent \textbf{Problem.} We pose the so-called \textit{Ergodic-Risk Constrained Optimal Control Problem} (Ergodic-Risk COCP):
\begin{align}\label{eq:optimization}
   \displaystyle \min \; &J(U) \\
   \text{s.t.}~~ &\x_{t+1} = A \x_t + B U_t + H \w_{t+1}, \quad \forall t \geq0, \nonumber\\
  & \text{ constraints on risk measure over } C_\infty \nonumber.
\end{align}
As we will discuss further in \Cref{sec:primal-dual}, reasonable choices of constraints on (coherent) risk measure over $C_\infty$ or $\gamma_N^2$ (such as Conditional Value-at-Risk CVaR$_{\alpha}$ and the Entropic Value-at-Risk EVaR$_{\alpha}$ at a level $\alpha$), essentially reduces to an upperbound on a linear functional related to the variance of $C_\infty$, whenever is well-defined. Furthermore, as discussed later in \Cref{rem:asymp-var-conditional-var}, $\gamma_N^2$ will be used as the estimate of this variance, offering a more tractable form for policy optimization. 

The well-posedness of Ergodic-Risk COCP depends on the existence of $C_\infty$; so, we first discuss that $C_t$ has (at least) the \emph{necessary} properties to successfully capture this cumulative uncertainty.
% \begin{lemma}\label{lem:MDS}
%     Suppose   
%     \[|g(x,u)| \leq M(\|x\|^{p} + \|u\|^{p}),\; \forall (x,u) \in\R^n\times\R^m\]
%     for some non-negative constants $M,p \geq 1$.
%     Consider dynamics \cref{eq:dynamics} under linear stationary Markov policies, if the noise $\{\w_t\}$ and initial condition has finite moments of order $p$, then $\{C_t,\F_{t}\}_0^\infty$ is a Martingale Difference Sequence (MDS); i.e. for all $t$
%     \begin{inparaenum}[(i)]
%         \item $C_t$ is $\F_{t}$-adapted, and
%         \item $\E |C_t| < \infty$, and
%         \item $\E[C_t|\F_{t-1}] \stackrel{a.s.}{=} 0$.
%     \end{inparaenum}    
% \end{lemma}
Under continuity of risk functional $g$ and bounded moment conditions for the noise \cite[Lemma 2]{talebi_uniform_2024}, it can be shown that, $C_t$ is a Martingale Difference Sequence (MDS); i.e. for all $t$
    \begin{inparaenum}[(i)]
        \item $C_t$ is $\F_{t}$-adapted, and
        \item $\E |C_t| < \infty$, and
        \item $\E[C_t|\F_{t-1}] \stackrel{a.s.}{=} 0$;
    \end{inparaenum} however, guaranteeing that the limiting quantity $C_\infty$ is well-defined still requires careful analysis of convergence in distribution (and similarly for the limit in $\gamma_N^2$). 
Note that the summands in $C_\infty$ are highly correlated through the dynamics in \cref{eq:dynamics} and thus vanilla Central Limit Theorem does not apply as it requires independent summands. Even extended version of CLT for martingales \cite[Theorem 5.1]{komorowski_central_2012} is not directly useful here because the conditions translates to such strong stability conditions on \cref{eq:dynamics} that is not feasible by any feedback signal---unless the noise process $\{W_t\}$ is eventually vanishing, which is not the point of interest in this work.

% Next, 
% we present the recently tailored forms of the (Functional) Law of Large Numbers (LLN) and Central Limit Theorem (CLT), which enables us to guarantee existence of 
Next, we study the ergodic-risk criteria defined in \cref{eq:def-C-infty} for quadratic risk functionals in LTI systems which will be used in solving the Quadratic Ergodic-Risk COCP in \Cref{sec:primal-dual}.

\section{Quadratic Ergodic-Risk for LTI systems}\label{sec:F-CLT}
Herein, we aim to quantify the ergodic-risk criteria $C_\infty$ and $\gamma_N^2$ defined in \cref{eq:def-C-infty} and \cref{eq:cond-var-def}. While we consider the \emph{quadratic} risk functionals $g$, the approach is more general. Also, the case of linear $g$ requires the noise to have only finite \emph{second} moment and follows similarly; thus is left to the reader.



For simplicity, we restrict ourselves to linear stationary Markov policies $\pi:x\mapsto Kx$ for some matrix parameter $K$, such that at each time $t$, the input is designed to be $\u_t = K \x_t$. We define the set of (Schur) stabilizing policies as 
\[\mathcal{S}=\left\{K \in \R^{m \times n}\;:\; A_K \coloneqq A+BK \text{ is Schur stable}\right\},\]
i.e. the closed-loop dynamics $A_K$ has spectral radius less than 1.
We refer to $\pi$ and $K$ as the policy without ambiguity. For $\mathcal{S}$ to be non-empty, we consider the minimal assumption:
\begin{assumption}\label{assmp:stability}
    The pair $(A,B)$ is stabilizable.
\end{assumption}
Let us define the following processes that become particularly relevant when the risk functional $g$ is quadratic;
% , i.e. $g(x,u) = x^\intercal Q^c x + u^\intercal R^c u$ for some $Q^c,R^c \succeq 0$; 
% \lina{at the end of intro, provide a short section of ``notations" to clarify the use of capital letters and little letters} \shahriar{I'll defer the explicit definitions of $g$ to the next section.}
namely, the running average and the running covariance

\begin{equation}\label{eq:def-s-t-Gamma-t}
\textstyle
     \s_t \coloneqq \sum_{s=1}^t \x_s , \text{ and }  \Gamma_t \coloneqq \sum_{s=1}^t \x_s \x_s^\intercal.
\end{equation}
% \lina{$\s_t$ is not a good notation since $s$ is used as time... How about change $s=1$ to be $\tau=1$? Not sure whether you used $\tau$ already. Moreover, I might prefer using $S_t$ over $\s_t$ to be consistent with "random variables", "realizations" used in $X$ and $U$.} \lina{I changed your def.tex and directly changed the $\bm{s}_t$ to be $\s_t$} \shahriar{Thanks. It makes sense. I just changed it to $\Lambda$ because I was using $S$ elsewhere.}
Combining probabilistic tools (Markov's inequality) and system theoretic properties (exponential stability), one can characterize the expectation of running average and covariance, as well as boundedness in probability for the process $\{\x_t\}$ as summarized in the following result. Proof of this result combines \cite[Lemma 6]{talebi_data-driven_2023} with standard techniques and is deferred to the extended version \cite{talebi_uniform_2024}.

\begin{lemma}\label{lem:ave-conv}
    Under Assumptions \ref{assmp:noise} and \ref{assmp:stability}, for any stabilizing policy $K \in \mathcal{S}$, we have the following limits as $t\to\infty$:
    \(
        \E[\x_t] \to 0, \;\E[\s_t/t] \to 0, \text{ and } 
         \E[\Gamma_t/t] \to \Sigma_K,
    \)
    where $\Sigma_K$ is the unique positive definite solution to the Lyapunov equation:
    \begin{equation}\label{eq:Sigma-K}
        \Sigma_K = A_K \Sigma_K A_K^\intercal + H\Sigma_W H^\intercal.
    \end{equation}
    % If in addition, the law of $\x_0\sim \prob[0]{}$ and $\w\sim\prob[\w]{}$ are centered Gaussian then $\x_t$ converges in distribution to $\bar\x \sim \mathcal{N}(0,\Sigma_K)$.
    Furthermore, we obtain that
    \(\s_t/t \xrightarrow{p} 0, \text{ as } t\to\infty,\)
    and $\{\x_t\}$ is boundedness in probability. 
    % i.e., there exists an absolute constant $\bar c$ such that for any $m$
    % \[\P(\|\x_t\|\geq m) \leq \bar c/m^2, \quad \forall t\geq0.\]
\end{lemma}

\Cref{lem:ave-conv} enables us to reason about the first and second moment of the process, however, it still does not provide enough for the convergence of $C_\infty$ in distribution. 
%
% In particular, we need much more sophisticated tools to argue about convergence of terms like $\s_t/\sqrt{t}$, $\Gamma_t/\sqrt{t}$, or even $\Gamma_t/t$ as $t\to \infty$.
%
Here, we use another type of extensions to CLT known as ``Functional Central Limit Theorem'' that extends the Martingale CLT to Markov chains, connecting to their ``stochastic stability'' properties. It builds on the so-called ``uniform ergodicity'' \cite{meyn_markov_2009} as a stochastic stability notion that allows for such convergence to hold.
%
The next result shows convergence of $C_\infty$ for ``quadratic'' risk functionals which builds on
the Functional CLT recently tailored in \cite{talebi_uniform_2024}.

For that, let us consider the following stationary process: $\{Y_t: t\in\mathbb{Z}\}$ is the stationary process given by $Y_t = \sum_{n = 0}^\infty A_K^n H \w_{t-n}$ with $\{\w_t\}$ as i.i.d. samples of the same probability measure $\P_W$. Also, for any symmetric matrix $M = \sum_j \lambda_j v_j v_j^\intercal$, define
\(\textstyle \gamma_M^2 \coloneqq \sum_{j=1}^d \lambda_j^2 \gamma_{v_j}^2\)
where each 
\( \gamma_{v_j}^2 = \sum_{k=-\infty}^\infty \left( \E\left[(v_j^\intercal Y_0 Y_k^\intercal v_j)^2\right] - (v_j^\intercal \Sigma_K v_j)^2 \right).\)

% \begin{theorem}[{\cite{talebi_uniform_2024}}]\label{thm:CLT-vX}
%    Suppose Assumptions \ref{assmp:noise} and \ref{assmp:stability} holds and consider the dynamics in \cref{eq:dynamics} for any policy $K \in \mathcal{S}$ that is stabilizing and $(A_K,H)$ is controllable.
    
%     (i) If the noise process $\{W_t\}$ has finite second moment, then LLN and CLT hold: 
%     \[
%         \frac{1}{t} \s_t \xrightarrow{a.s.} 0, \quad \frac{1}{\sqrt{t}} \s_t \xrightarrow{d\;} \mathcal{N}(0,\Sigma_\Gamma(0)),
%     \]
%     with
%      \(\Sigma_\Gamma(\omega) = (I-e^{i\omega} A_K)^{-1} H \Sigma_W H^{\intercal}\left(I-e^{-i\omega} A_K^{\intercal}\right)^{-1}.\)
    
    
%     (ii) If the noise process $\{W_t\}$ has finite fourth moment, then for any constant matrix $M$, LLN and CLT hold:
%     \[ \frac{1}{t}\tr{M\Gamma_t} \xrightarrow{a.s.} \tr{M \Sigma_K}, \quad \frac{1}{\sqrt{t}}\tr{M(\Gamma_t- t \Sigma_K)} \xrightarrow{d\;} \Gamma_\infty,\]
%      where $\Sigma_K$ solves \cref{eq:Sigma-K}, $\Gamma_\infty \sim \mathcal{N}(0,\gamma_M^2 \coloneqq \sum_{j=1}^d \lambda_j^2 \gamma_{v_j}^2)$ where
%     $\bar M = \sum_j \lambda_j v_j v_j^\intercal$ forms the symmetric part of $M$, $\gamma_{v_j}^2$ is the asymptotic variance given by
%     \[ \gamma_{v_j}^2 = \sum_{k=-\infty}^\infty \left( \E\left[(v_j^\intercal Y_0 Y_k^\intercal v_j)^2\right] - (v_j^\intercal \Sigma_K v_j)^2 \right),\]
%      and $\{Y_t: t\in\mathbb{Z}\}$ is the stationary process given by $Y_t = \sum_{n = 0}^\infty A_K^n H \w_{t-n}$ with $\{\w_t\}$ as i.i.d. samples of the same probability measure $\P_W$. If, in addition, $\P_W$ is Gaussian then $\gamma_M^2$ admits the integral form
%     \[ \gamma_M^2 = \frac{1}{\pi} \int_{-\pi}^\pi \sum_{j=1}^d \lambda_j^2|v_j^\intercal \Sigma_\Gamma(\omega) v_j|^2 d\omega. \]
% \end{theorem} 





% \shahriar{It is not shown but the book claims the following, which essentially requires a vector form of Martingale CLT theorem:}

% An extension of Martingale CLT to vector-valued processes is possible, and from such a generalization we have under the conditions of above that
% $$
% \frac{1}{\sqrt{t}} \sum_{t=1}^n \x_t \x_t^{\intercal} \xrightarrow{\mathrm{d}} \mathcal{N}(0, \Sigma)
% $$
% where $\Sigma=(I-A_K)^{-1} H \Sigma_W H^{\intercal}\left(I-A_K^{\intercal}\right)^{-1}$. 

% \shahriar{What are the equivalent formulations of $\gamma_v$ and $\Sigma$ that relates better to convergent series form and Lyapunov equation? the martingale representation theorem should be useful for this.}



% \subsection{Quadratic Ergodic-Risk}\label{sec:ergodic-risk-control}

% \shahriar{I can also add the case of linear $g$ which will be useful for affine risk functionals, but is probably less interesting...}
% \begin{corollary}
% \shahriar{I'll complete the linear case...}
%     Consider the dynamics in \cref{eq:dynamics} under the premise of \Cref{thm:main-limiting} for some some policy $\pi=(K,\ell)$ and let 
%     \[g(x,u) = Q^c x + R^c u\]
%     for some constant matrices $Q^c$ and $R^c$ with appropriate dimensions. If the noise process $\{W_t\}$ has finite second moment, then 
%     \[\gamma_c^2 = \tr{(Q_K^c - A_K^\intercal Q_K^c A_K)\Sigma_\Gamma (Q_K^c - A_K^\intercal Q_K^c A_K)}.\]
%     with $Q_K^c = Q^c + K^\intercal R^c K$ and 
%     \[\Sigma_\Gamma = (I-A_K)^{-1} H \Sigma_W H^{\intercal}\left(I-A_K^{\intercal}\right)^{-1}.\]
% \end{corollary}
% \begin{proof}
%     Because $\E[\x_t] \to \bar{x}_K$, it suffices to show the claim for the centered process $\{\x_t -\bar{x}_K\}$ starting from a fixed $\x_0 = x_0$ and thus consider only the policies with $\ell=0$ and any $K\in\mathcal{S}$.
% \end{proof}
% Recall the risk criterion at each time $t$ defined as
% \[C_t \coloneqq 
%     g(\x_{t},\u_{t}) -\E[g(\x_{t},\u_{t}) | \F_{t-1}].\]


\begin{theorem}\label{thm:C-infty-N-convergence}
    Suppose Assumptions \ref{assmp:noise} and \ref{assmp:stability} holds and consider the dynamics in \cref{eq:dynamics} for any policy $K \in \mathcal{S}$ that is stabilizing and $(A_K,H)$ is controllable. Consider
    \[g(x,u) = x^\intercal Q^c x + u^\intercal R^c u\]
    for some $Q^c, R^c\succeq 0$ and define $Q_K^c = Q^c + K^\intercal R^c K$. If the noise process $\{W_t\}$ has finite fourth moment, then the asymptotic variance $\gamma_M^2(K)$ with $M\coloneqq Q_K^c -A_K^\intercal Q_K^c A_K$ is well-defined, non-negative and finite.
    Then, if $\gamma_M^2(K)>0$,
    \[\textstyle \frac{1}{\sqrt{t}} S_t \coloneqq \frac{1}{\sqrt{t}} \sum_{s=1}^t C_s \xrightarrow{d\;} C_\infty \sim \mathcal{N}(0, \gamma_M^2(K)), \quad t\to\infty;\]
    otherwise, $\frac{1}{\sqrt{t}}\sum_{s=0}^t C_s \xrightarrow{a.s.} 0$.
    Furthermore,
    \[\textstyle \frac{1}{t} \sum_{s=1}^{t} C_s \xrightarrow{a.s.} 0,
    \quad
    \frac{1}{t} \sum_{s=1}^{t} \E [C_s^2| \F_{s-1}] \xrightarrow{a.s.} \gamma_N^2(K),\]
    where 
    \begin{gather*}
        \gamma_N^2(K) = 4\tr{Q_K^c H \Sigma_W H^\intercal Q_K^c (\Sigma_K-H \Sigma_W H^\intercal)}
        + m_4[Q_K^c],
    \end{gather*}
    with 
    \(
        m_4[Q_K^c] \coloneq \E\left[\tr{Q_K^c H (\w_{1} \w_{1}^\intercal - \Sigma_W )H^\intercal}^2\right].
    \)
    % In this case, if $\gamma_N^2(K)>0$ then
    %  \[\frac{1}{\sqrt{t}} \sum_{s=0}^{t} \E [C_s^2| \F_{s-1}] \xrightarrow{p\;} \gamma_N^2(K),\]
    % \shahriar{I'm curious how does is behave if we have \textbf{Huber loss} instead of quadratic $g$, which intuitively should be more sensitive to outliers!}
\end{theorem}

\begin{remark}\label{rem:asymp-var-conditional-var}
First note that, by Tower property it also follows that
\(\frac{1}{t} \sum_{s=1}^{t} \E [C_s^2] \xrightarrow{a.s.} \gamma_N^2(K).\)
Second, the asymptotic conditional variance $\gamma_N^2(K)$ in \cref{eq:cond-var-def} serves as an ``estimate'' of $\gamma_M^2 = \lim_{t\to \infty} \E[S_t^2/t]$ with $S_t \coloneqq \sum_{s=1}^t C_s$ in the following sense: by Doob's decomposition we can show that
\(S_t^2 = M_t + N_t\)
where $(M_t,\F_t)$ is a martingale and $(N_t,\F_t)$ is predictable defined as
\(
    N_t - N_{t-1} = \E[S_t^2 - S_{t-1}^2|\F_{t-1}] %= \E[(S_t- S_{t-1})^2|\F_{t-1}] \\
    = \E[C_t^2|\F_{t-1}],
\)
where the second equality follows because $(S_t,\F_t)$ is a martingale.
Thus,
\(S_t^2  = M_t + \sum_{s=1}^{t} \E [C_s^2| \F_{s-1}].\)
So, $N_t$ can be interpreted as an intrinsic measure of time for the martingale $S_t$. Also, it can be interpreted as ``the amount of informaiton'' contained in the past history of the process, related to a standard Fisher information \cite[p. 54]{hall_martingale_1980}.
\end{remark}

\begin{proof}
    Consider the process $\{\x_t\}$ with any $K\in\mathcal{S}$ and starting from a fixed $\x_0 = x_0$.
    %
    For simplicity, we define $G_{t} := g(\x_{t},\u_{t}), ~t\geq 0$ and note that $G_0 = x_0^\intercal Q_K^c x_0$ and
    \(
        G_{t+1} = (A_K\x_t+H\w_{t+1})^\intercal Q_K^c (A_K\x_t+H\w_{t+1}),
    \)
    for $t\geq 0$. 
     This, together with \Cref{assmp:noise} imply  that
    \[
        \E[G_{t+1}|\F_{t}] = \x_t^\intercal A_K^\intercal Q_K^c A_K\x_t + \tr{Q_K^c H \Sigma_W H^\intercal},
    \]
    where $\Sigma_W$ denotes the covariance of $\w\sim\prob[\w]{}$. Thus,
    \begin{gather*}
        C_{t+1} = \x_{t+1}^\intercal Q_K^c \x_{t+1} -\x_t^\intercal A_K^\intercal Q_K^c A_K\x_t 
        - \tr{Q_K^c H \Sigma_W H^\intercal}
    \end{gather*}
    Now recall $S_{t} \coloneqq \sum_{s=1}^{t} C_s$ and therefore, the cyclic property of trace and definition of $\Gamma_t$ imply that
    \begin{multline}\label{eq:S-t-expression}
        S_{t} = \tr{Q_K^c \Gamma_{t}} 
        -\tr{A_K^\intercal Q_K^cA_K(\Gamma_{t-1} + x_0 x_0^\intercal)}  \\
        - t\, \tr{Q_K^c H \Sigma_W H^\intercal}
    \end{multline}
    Also, by Lyapunov equation \cref{eq:Sigma-K}, we have the identity 
    \[\tr{Q_K^c\Sigma_K -A_K^\intercal Q_K^c A_K \Sigma_K - Q_K^c H \Sigma_W H^\intercal} = 0.\]
    % \begin{equation}\label{eq:trace-lyap-identity}
    %     \tr{Q_K^c\Sigma_K -A_K^\intercal Q_K^c A_K \Sigma_K - Q_K^c H \Sigma_W H^\intercal} = 0.
    % \end{equation}
    Therefore, by applying the LLN in \cite[Corollary 12]{talebi_uniform_2024} to \cref{eq:S-t-expression} we conclude that as $t\to\infty$, 
        \( S_t/t \xrightarrow{a.s.}  0.\)
    Next, by applying the same Lyapunov identity, we can rewrite \cref{eq:S-t-expression} as 
    % \(S_{t} = \tr{(Q_K^c -A_K^\intercal Q_K^cA_K) (\Gamma_{t}-t\Sigma_K)} 
    %     +\tr{A_K^\intercal Q_K^cA_K(\x_t \x_t ^\intercal - x_0 x_0^\intercal)}.\)
    \begin{multline*}
        S_{t} = \tr{(Q_K^c -A_K^\intercal Q_K^cA_K) (\Gamma_{t}-t\Sigma_K)}  \\
        +\tr{A_K^\intercal Q_K^cA_K(\x_t \x_t ^\intercal - x_0 x_0^\intercal)}.
    \end{multline*}
    Recall that the CLT in \cite[Corollary 12]{talebi_uniform_2024} implies the convergence in distribution of $\frac{1}{\sqrt{t}}(\tr{M(\Gamma_{t} - t\Sigma_K)}$ for any constant matrix $M$. Furthermore, \Cref{lem:ave-conv} implies that $\tr{A_K^\intercal Q_K^c A_K \x_t \x_t^\intercal}/\sqrt{t}$ converges to zero in probability as $t\to\infty$.
    %    
    The first claim then follows by considering the linear (and thus continuous) mapping $\Gamma \mapsto \tr{(Q_K^c - A_K^\intercal Q_K^c A_K)\Gamma}$ and applying Continuous Mapping Theorem to this expression of $S_t$.
    % that $\frac{1}{\sqrt{t}}S_{t}$ converges in distribution to $\mathcal{N}(0,\gamma_M^2)$ whenever $\gamma_M^2>0$, and otherwise converges to zero almost surely.
    Finally, we show the convergence of $N_t/t$ in \cref{eq:cond-var-def}.
    For that, $C_{t+1}$ is rewritten as 
    \( C_{t+1} = 2 (A_K \x_t)^\intercal Q_K^c H \w_{t+1} 
        + \tr{Q_K^c H (\w_{t+1} \w_{t+1}^\intercal - \Sigma_W )H^\intercal},
    \)
    % \begin{align*}
    %     C_{t+1} =& 2 (A_K \x_t)^\intercal Q_K^c H \w_{t+1} \\
    %     &+ \tr{Q_K^c H (\w_{t+1} \w_{t+1}^\intercal - \Sigma_W )H^\intercal}
    %     % \\
    %     % =& 2 (A_K \x_t)^\intercal Q_K^c H \w_{t+1} \\
    %     % &+ \tr{Q_K^c H (\w_{t+1} \w_{t+1}^\intercal - \Sigma_W )H^\intercal}.
    % \end{align*}
    and thus
    \begin{gather*}
    \begin{aligned}
        &\E[C_{t+1}^2|\F_{t}] = 4 (A_K \x_t)^\intercal Q_K^c H \Sigma_W H^\intercal Q_K^c (A_K \x_t) \\
        &+ 4 \x_t^\intercal A_K^\intercal Q_K^c
        \E[H\w_{t+1}\tr{Q_K^c H (\w_{t+1} \w_{t+1}^\intercal - \Sigma_W )H^\intercal} |\F_{t}] \\
        &+\E[\tr{Q_K^c H (\w_{t+1} \w_{t+1}^\intercal - \Sigma_W )H^\intercal}^2|\F_{t}]\\
        % =& 4 (A_K \x_t)^\intercal Q_K^c H \Sigma_W H^\intercal Q_K^c (A_K \x_t) \\
        % &+ 4 (A_K \x_t)^\intercal Q_K^c M_3[Q_K^c] + m_4[Q_K^c]\\
        =& 4 \tr{ A_K^\intercal Q_K^c H \Sigma_W H^\intercal Q_K^c A_K \x_t \x_t^\intercal}  + 4 M_3^\intercal Q_K^c A_K \x_t  + m_4
    \end{aligned}
    \end{gather*}
    where we dropped the conditionals because $\w_{t+1}$ is independent of $\F_t$, with $m_4 = m_4[Q_K^c]$ as in the statement and \( M_3 = M_3[Q_K^c] \coloneq \E\big[H\w_{1}\tr{Q_K^c H (\w_{1} \w_{1}^\intercal - \Sigma_W )H^\intercal}\big]\), which are well-defined (bounded) by the moment condition on the noise.  
    %
    % Also, $\F_{-1}$ is trivial, so
    % \[C_0 = x_0^\intercal Q_K^c x_0 - \E[x_0^\intercal Q_K^c x_0] = x_0^\intercal Q_K^c x_0 - \tr{Q_K \Sigma_0},\]
    % where $\Sigma_0 = \E[x_0x_0^\intercal]$, and thus
    % \[N_0^2 = \E[C_{0}^2|\F_{-1}] =\E [(x_0^\intercal Q_K^c x_0)^2] - (\tr{Q_K \Sigma_0})^2,\]
    % which is finite by the moment assumption on the initial state distribution.
    %
    Therefore, by definition of $N_t$ and \cite[Corollary 12]{talebi_uniform_2024}, we obtain the almost sure convergence: 
    % \[\tr{A_K^\intercal Q_K^c H \Sigma_W H^\intercal Q_K^c A_K \Gamma_t}/t \xrightarrow{a.s.} \tr{A_K^\intercal Q_K^c H \Sigma_W H^\intercal Q_K^c A_K \Sigma_K},\]
    % and
    % \[M_3[Q_K^c]^\intercal Q_K^c A_K \s_t/t \xrightarrow{a.s.} 0.\]
    % Therefore, 
    \[
        \frac{1}{t}N_t \xrightarrow{a.s.} 4\tr{A_K^\intercal Q_K^c H \Sigma_W H^\intercal Q_K^c A_K \Sigma_K} + m_4[Q_K^c].
    \]
    But, by cyclic permutation property of the trace and the Lyapunov equation:
    \(
        \tr{A_K^\intercal Q_K^c H \Sigma_W H^\intercal Q_K^c A_K \Sigma_K} 
        = \tr{Q_K^c H \Sigma_W H^\intercal Q_K^c (\Sigma_K-H \Sigma_W H^\intercal)}.
    \)
    Combining the last two equations completes the proof.
\end{proof}

\section{Quadratic Ergodic-Risk COCP}\label{sec:primal-dual}
Herein, we show how the ergodic-risk criteria can be incorporated as a constraint in the optimal control framework posed in \cref{eq:optimization}.
%
The policy optimization (PO) approach to control design pivots on a parameterization of the feasible policies for the synthesis problem. 
%
One can view the \ac{lqr} cost naturally as a map $J(K) : K \mapsto J(\u=K \x)$. 
%
Also, for any stabilizing policy $K \in \mathcal{S}$, by using cyclic permutation property of trace, together with definitions in \cref{eq:def-s-t-Gamma-t}, we can compute the cost as $J_T(K) =\tr{Q_K\left(\x_0 \x_0^\intercal + \Gamma_T\right)}$
% \begin{multline*}
%     J_T(K) = \x_0^\intercal Q_K \x_0 + \sum_{t=1}^T \x_t^\intercal Q_K \x_t \\
%     =\tr{Q_K\left(\x_0 \x_0^\intercal + \Gamma_T\right)}
% \end{multline*}
where $Q_K \coloneqq Q+K^\intercal R K$. Now, by \Cref{lem:ave-conv} and \Cref{thm:C-infty-N-convergence} we obtain that
\[J(K) = \lim_{T\to \infty} E[J_T(K)/T] = \tr{Q_K \Sigma_K},\]
with $\Sigma_K$ in \cref{eq:Sigma-K}. Note that $J(K)$ does not depend on the distribution of $\x_0$--as long as it has bounded second moment.



Recall, \Cref{thm:C-infty-N-convergence} ensures that $C_\infty$ is indeed distributed normally as long as $K$ is stabilizing, $(A_K,H)$ is controllable, and the noise has finite fourth moment; in this case $C_\infty \sim \mathcal{N}(0,\gamma_M^2)$.
%
But, any reasonable choice of a coherent risk measure on $C_\infty$ (such as Conditional Value-at-Risk CVaR$_{\alpha}$ and the Entropic Value-at-Risk EVaR$_{\alpha}$ on $C_\infty$ at a level $\alpha$), essentially reduces to an upperbound on a linear functional of $\gamma_M^2$. As discussed in \Cref{rem:asymp-var-conditional-var}, the asymptotic conditional variance $\gamma_N^2(K)$ can be interpreted as an ``estimate'' of $\gamma_N^2(K)$ which has a more tractable expression. Thus, herein we only consider constraints on $\gamma_N^2(K)$ and defer the other one to the extended version.
%
Therefore, the problem in \cref{eq:optimization} with the constraints on $\gamma_N^2$ over linear policies reduces to
\begin{align}\label{eq:optimization-reform}
    &\displaystyle \min \; J(K)  = \tr{Q_K \Sigma_K} \\
   &\text{s.t.} ~\gamma_N^2(K) \leq \bar\beta,\quad  
   K \in \stableK \cap \{K: (A_K,H) \text{ controllable}\}, \nonumber
\end{align}
with $\Sigma_K$ solving \cref{eq:Sigma-K}, $\gamma_N^2(K)$ defined in \Cref{thm:C-infty-N-convergence}, and for a given constant $\bar\beta$ encapsulating the risk level.

In this rest of this section, we develop a primal-dual algorithm to solve \cref{eq:optimization-reform} using Lagrange duality. Let us consider the Lagrangian $L:\mathcal{S}  \times \R_{\geq 0} \mapsto \R$ defined as
\begin{align}
    L(K, \lambda) &\coloneqq \tr{Q_K \Sigma_K} + \lambda \left(\gamma_N^2(K)-\bar\beta  \right) \label{eq:lagrangian}\\
     &= \tr{(Q_K + 4\lambda Q_K^c H \Sigma_W H^\intercal Q_K^c) \Sigma_K} + \lambda \beta[Q_K^c], \nonumber
\end{align}
with 
\(
    \beta[Q_K^c] \coloneqq -4\tr{(Q_K^c H \Sigma_W H^\intercal)^2 } + m_4[Q_K^c] -\bar\beta,
\)
and $m_4[Q_K^c]$ in \Cref{thm:C-infty-N-convergence}. Hereafter, we focus on the case where the risk functional $g$ does not depend on the input explicitly\footnote{This relates with the setting studied in \cite{tsiamis_risk-constrained_2020, zhao_global_2023}, where, in addition, the assumptions $Q^c = Q$ and $H = I$ are imposed.}.

\subsection{Quadratic Ergodic-Risk Criteria with $R^c=0$} \label{subseq:R-c-0}
Let us assume that the risk measure $g$ does not depend on control input explicitly; i.e. $R^c=0$, and so $Q_K^c = Q^c$ is constant. 
%
In addition to system-theoretic assumptions in \Cref{assmp:stability} that is necessary for feasibility of the optimization (non-empty domain $\stableK$), in the following result we also need controllability of the pair $(A^\intercal, Q^{\frac{1}{2}})$ to guarantee regularity of the Lagrangian, i.e. coercivity of $L(\cdot,\lambda)$ for each $\lambda$.
%
For simplicity, we consider slightly stronger conditions:

\begin{assumption}\label{asmp:Q-H-full-row-rank}
    Assume $Q \succ 0 $ and $H$ is full row rank.
\end{assumption}

The next result is obtain by leveraging  \cite[Lemma 1 and 2]{talebi_data-driven_2023}, where a detailed proof is provided in \cite{talebi_uniform_2024}.

\begin{lemma}\label{lem:Lagrangian}
% \shahriar{revise the assumptions..}
Suppose Assumptions \ref{assmp:noise}, \ref{assmp:stability}, and \ref{asmp:Q-H-full-row-rank} hold.
% $(A_K,Q^{\frac{1}{2}})$ is observable, and $(A_K,H)$ is controllable. 
For each $\lambda\geq0$, consider the Lagrangian $L_\lambda(\cdot) = L(\cdot,\lambda):\stableK \to \R$.
The following statements are true:
\begin{inparaenum}[(i)]
    \item $L_\lambda(\cdot)$ and $\gamma_N^2(\cdot)$ are smooth with 
    \(
    \nabla L_\lambda(K) = 2(RK + B^\intercal P_{(K,\lambda)} A_K)\Sigma_K 
    \)
    where $P_{(K,\lambda)}$ is the unique solution to
    \[P_{(K,\lambda)} = A_K^\intercal P_{(K,\lambda)} A_K + Q_K + 4\lambda Q^c H \Sigma_W H^\intercal Q^c.\]
    \item $L_\lambda(\cdot)$ is coercive with compact sublevel sets $\stableK_\alpha$ for each $\alpha>0$.
    \item $L_\lambda(\cdot)$ admits a unique global minimizer $K^*(\lambda) = \arg \min_{K\in\stableK} L_\lambda(K)$ that is stabilizing, given by
    \[K^*(\lambda) = -(R + B^\intercal P_{(K^*(\lambda),\lambda)}B)^{-1}B^\intercal P_{(K^*(\lambda),\lambda)} A,\]
    and $L_\lambda(K^*(\lambda)) = \tr{P_{(K^*(\lambda),\lambda)} H \Sigma_W H^\intercal} + \lambda \beta[Q^c]$.
    \item The restriction $L_\lambda(\cdot) |_{\stableK_\alpha}$ for any (non-empty) sublevel set $\stableK_\alpha$ has Lipschitz continuous gradient, is gradient dominated, and has a quadratic lower model; in particular, for all $K,K'\in\stableK_\alpha$ the following inequalities are true: 
    \(\|\nabla L_\lambda(K) - \nabla L_\lambda(K')\|_F \leq \ell \|K - K'\|_F\)
    and
    \(c_2 \|K-K^*\|_F^2\leq c_1[L_\lambda(K) - L_\lambda(K^*)] \leq \|\nabla L_\lambda(K)\|_F^2,\)
    for some positive constants $\ell(\alpha),c_1(\alpha)$, and $c_2(\alpha)$ that only depend on $\alpha$ and are independent of $K$.
\end{inparaenum}

% and
% \begin{align*}
% \nabla_\lambda L(K,\lambda) =& 4 \tr{Q^c H \Sigma_W H^\intercal Q^c \Sigma_K} + \beta[Q^c].
% \end{align*}    
\end{lemma}


% \newpage
% Now, we can investigate the necessary conditions of optimality for a triple $(K^*,\lambda^*)$ by considering the Karush–Kuhn–Tucker (KKT) conditions associated with the Lagrangian in \cref{eq:lagrangian}. Note that for any $K\in\mathcal{S}$ and $\lambda\geq 0$, $\nabla_\ell(K,\lambda) = 0$ has a unique solution $\ell_K^*$ given by
% \begin{multline*}
%     \ell_K^* =\\
%     -2 \lambda [B^\intercal (I-A_K)^{-\intercal} ( Q_K + 4\lambda Q^c H \Sigma_W H^\intercal Q^c) (I-A_K)^{-1} B]^{-1} \\
% \cdot B^\intercal (I-A_K)^{-\intercal} Q^c M_3[Q^c].
% \end{multline*}
% Note that all of the inverses are well-defined because $K$ is stabilizing and always $Q_K + 4\lambda Q^c H \Sigma_W H^\intercal Q^c\succ 0$. Next, for such $\ell^*$ and any $\lambda>0$, we show that $\nabla_K(K,\ell^*,\lambda) = 0$ has a unique solution $K^*$ under conditions of \Cref{assmp:stability}. Note that the Lagrangian in \cref{eq:lagrangian} reduces to:
% \begin{multline*}
%     L(K, \ell^*, \lambda) = \tr{(Q_K + 4\lambda Q^c H \Sigma_W H^\intercal Q^c)\Sigma_K} \nonumber\\
%      + 2 \lambda M_3[Q^c]^\intercal Q^c \bar{x}_K^* + \lambda \beta[Q^c]
% \end{multline*}
% where $\bar{x}_K^* = (I-A_K)^{-1}B\ell_K^*$.

\subsection{Strong Duality}\label{sec:strong-duality}
Now that $K^*(\lambda)$ is uniquely well-defined for each $\lambda \geq 0$, the \emph{dual problem} can be written in following forms
\begin{multline*}
    \sup_{\lambda\geq0} \min_{K \in \stableK} L(K,\lambda) 
= \sup_{\lambda\geq0} \tr{P_{(K^*(\lambda),\lambda)} H \Sigma_W H^\intercal} + \lambda \beta[Q^c]\\
=  \sup_{\lambda\geq0} \tr{Q_{K^*(\lambda)} \Sigma_{K^*(\lambda)}} + \lambda \left(\gamma_N^2(K^*(\lambda))-\bar\beta  \right),
\end{multline*}
with $P_{(K^*(\lambda),\lambda)}$ defined in \Cref{lem:Lagrangian}.
It is standard to assume the primal problem is strictly feasible: 
\begin{assumption}[Slater's Condition]\label{asmp:slater}
    Assume $\bar\beta$ is large enough such that there exists $K\in\stableK$ with $\gamma_N^2(K) < \bar\beta$.
\end{assumption}
This enables us to establish \emph{strong duality} for $L$ meaning that both primal and dual problems are feasible with identical values.
Because we know the cost function is globally lower bounded, $\tr{Q_{K} \Sigma_{K}} \geq 0$, then Slater's condition implies feasibility of the dual problem, and that there exists a finite $\lambda_0\geq 0$ such that $\gamma_N^2(K^*(\lambda_0)) \leq \bar\beta$. Now, if we let 
\begin{equation}\label{eq:lambda-star}
\lambda^* = \min\{\lambda_0 \;:\; \lambda_0 \geq 0 \text{ and } \gamma_N^2(K^*(\lambda_0)) \leq \bar\beta\}, 
\end{equation}
then we claim that the pair $(K^*(\lambda^*), \lambda^*)$ is the saddle point of the Lagrangian $L(K,\lambda)$, and therefore obtain the strong duality. For this claim to hold, by the Karush–Kuhn–Tucker (KKT) conditions, it suffice to show that:
\begin{equation}\label{eq:comp-slack}
    \mathrm{CS}(\lambda^*) \coloneqq \lambda^*(\gamma_N^2(K^*(\lambda^*)) - \bar\beta) = 0,
\end{equation}
aka the complementary slackness holds.
But, we know that $P_{(K,\lambda)}$ is real analytic in $(K,\lambda)$ and is positive definite for each $\lambda\geq0$. Thus, $K^*(\lambda)$ as defined in \Cref{lem:Lagrangian} is smooth in $\lambda$. So, $\gamma_N^2 \circ K^*(\cdot)$ is continuous by composition and lower bounded by zero. Therefore, complementary slackness follows because the minimum of a strictly monotone function on a compact set in \cref{eq:lambda-star} is attained at the boundary.

\subsection{The Primal-Dual Algorithm}\label{sec:primal-dual-algo}
By establishing a strong duality, we can solve the dual problem without loss of optimality. In particular, using the properties of $L_\lambda(\cdot)$ obtained in \Cref{lem:Lagrangian}, we devise simple primal-dual updates to solve \cref{eq:optimization-reform} by accessing the gradient and constrained violation values, as proposed in \Cref{algo}.
\begin{algorithm}[ht]
\caption{Primal-Dual Ergodic-Risk Constrained LQR}
    \begin{algorithmic}[1]
\State Set $K_0 \in \stableK_\alpha$ for some $\alpha>0$, $\lambda_0 =1$, and tolerance $\epsilon>0$ and stepsize $\eta_m =(\gamma_N^2(K_0) - \bar\beta)^{-1} (m+1)^{-1/2}$
\For{$m=0,1,\cdots, T=\mathcal{O}(\ln(\ln(\epsilon))/\epsilon^2)$}
\While{$\|\nabla_K L_{\lambda_m}(K)\|_F \geq \sqrt{\epsilon}$}
    \State $G \gets -(R + B^\intercal P_{K,{\lambda_m}} B)^{-1} \nabla L_{\lambda_m}(K) \Sigma_K^{-1}$
    \State $K \gets K + \frac{1}{2} G$ 
\EndWhile
% \If{$\gamma_N^2(K) - \bar\beta \geq \epsilon$}
\State $\lambda_{m+1} \gets \max\left[0, \lambda_{m} + \eta_m (\gamma_N^2(K) - \bar\beta) \right]$
% \Else 
% \EndIf
\EndFor
\State \Return $(K,\lambda \coloneq \frac{1}{T}\sum_{m=1}^{T} \lambda_m)$
\end{algorithmic}
\label{algo}
\end{algorithm}
We next provide a convergence guarantee by combining recent LQR policy optimization \cite{fazel_global_2018, talebi_policy_2023} with saddle point optimization techniques \cite{nedic_subgradient_2009}, and illustrate the performance of \Cref{algo} through simulations.

% \begin{theorem}[Convergence]
%     Suppose Assumptions \ref{assmp:noise}, \ref{assmp:stability}, \ref{asmp:Q-H-full-row-rank}, and \ref{asmp:slater} hold. Then \Cref{algo} obtains an $\epsilon$-accurate solution to problem \cref{eq:optimization-reform} in $\mathcal{O}(\ln(\epsilon)/\epsilon^2)$ steps. 
% \end{theorem}

\subsection{Convergence Guarantee}\label{subsec:convergence}


The results in \Cref{lem:Lagrangian} and the initialization in \Cref{algo} ensure that the premise of \cite[Theorem 4.3]{talebi_policy_2023} is satisfied. Also, $G$ is the Riemannian quasi-Newton direction and the update on $K$ is known as the Hewer's algorithm which is proved to converge at a quadratic rate, as discussed in detail in \cite[Remark 5]{talebi_policy_2023}. And therefore, the inner loop terminates very fast in $\ln(\ln(\epsilon))$ steps and essentially returns an $\epsilon$ accurate estimate of $K^*(\lambda_m)$. We could instead use a pure gradient descent algorithm, but this would result in a slower convergence rate.

% We could similarly notice that the premises of Theorem 1 in \cite{talebi_data-driven_2023} are also satisfied using properties in \Cref{lem:Lagrangian}. Then, as a special case of \cite[Theorem 1]{talebi_data-driven_2023} where we have accurate gradient information $\nabla L_\lambda(K)$, and constants $\gamma, s$ and $s_0$ approach zero, we obtain the linear convergence of gradient descent to the unique global minimizer $K^*(\lambda)$. The inner loop then only utilizes the gradient information $\nabla_K L_\lambda(K)$, however, it takes $\mathcal{O}(\ln(\epsilon))$ steps to complete.

Furthermore, the outer loop is expected to take $\mathcal{O}(1/\epsilon^2)$ steps to obtain $\epsilon$ error on the functional $L(K^*(\lambda), \lambda)$ following standard primal-dual guarantees \cite{nedic_subgradient_2009}. Thus, assuming that Assumptions \ref{assmp:noise}, \ref{assmp:stability}, \ref{asmp:Q-H-full-row-rank}, and \ref{asmp:slater} hold, \Cref{algo} obtains an $\epsilon$ accurate solution to problem \cref{eq:optimization-reform} in $\mathcal{O}(\ln(\ln(\epsilon))/\epsilon^2)$ steps. 


\subsection{Simulations}\label{subsec:simulations}

% {\color{red} swap the Fig 3. with a simulation of the system response and the Ct values comparing with LQR optimal.}

% Next, we illustrate the performance of \Cref{algo} on randomly generated problem instances with 4 states and 2 inputs, where we set $\bar\beta$ such that any feasible policy is $10\%$ more conservative than the LQR optimal; i.e. $\bar\beta = 0.9 \gamma_N^2(K_{LQR})$. The progress on 100 randomly sampled problem instances is illustrated in \Cref{fig:mainfig}, where the errors in KKT conditions are considered as performance measures and $\overline{(\cdot)}$ denotes normalization of a sequence with respect to its first element. 
% As it can be seen, the algorithm always recovers $K^*(\lambda_t)$ at each iteration. But, as these instances are drawn at random, the Slater's condition may fail to hold, which essentially means such a conservative performance is not feasible by any policy $K$ and thus causing the algorithm to fail in such instances.
% \begin{figure}[pt]
%   \centering    \includegraphics[width=0.5\textwidth]{images/risk_lqr_parallel_ACC.pdf}
%   \caption{ Convergence of \Cref{algo} on 100 randomly sampled problem instances in terms of error in KKT conditions.}
%   \label{fig:mainfig}
  
% \end{figure}



% \begin{figure}[pt]
%     \centering
%     \includegraphics[width=0.5\textwidth]{images/Ct_and_NormX_comparison}
%         \caption{ The average running covariance $S_t^2/t$  over 100 system responses under LQR versus Ergodic-Risk optimal policies.}
%     \label{fig:S-2-t}
    
% \end{figure}

% We also show how the Ergodic-Risk optimal policy behaves compared to the LQR optimal policy. In addition to its resilience to large disturbances observed in \cite{tsiamis_risk-constrained_2020,zhao_global_2023}, here we compare their performance in terms of the running variance of the cumulative risk---which we have now guaranteed to be well-defined. In particular, we consider one of the random problem instances from the previous setup and this time set an even more risk-averse $\bar\beta = 0.7 \gamma_N^2(K_{LQR})$.
% In \Cref{fig:S-2-t}, we illustrate the average of $S_t^2/t$ with $S_t$ defined in \cref{eq:def-C-infty} over 1000 roll-outs of the dynamics in \cref{eq:dynamics} with $\P_W$ being Student's t-distribution with parameter $\nu =5$. Note that this noise distribution has finite fourth moment and unbounded fifth moment. Also, recall that $\gamma_N^2$ is an estimate of $\gamma_M^2 = \lim_{t\to \infty} \E[S_t^2/t]$ (\Cref{rem:asymp-var-conditional-var}); therefore, the simulation illustrates that the proposed Ergodic-Risk policy from \cref{eq:optimization-reform} results in smaller (empirical) values, confirming a more risk-averse behavior compared to the LQR optimal one.

Next, we compare the behavior of the ergodic-risk optimal policy with that of the LQR optimal policy on the Grumman X-29 aircraft dynamics, as studied in \cite{talebi_regularizability_2022}. We consider its longitudinal and lateral-directional dynamics in the Normal Digital Powered-Approach (ND-PA) mode, with a fixed discretization step size of $0.05$, following \cite[Tables 9 and 10]{bosworth_linearized_1992}. The system comprises four longitudinal states, four lateral-directional states, and five control inputs. Given the normalized state representation, we set $Q = Q_c = I_8$ and $R = R_c = I_5$.

The heavy-tailed process noise is drawn from a Student’s $t$-distribution with parameter $\nu = 5$, which has a finite fourth moment but unbounded fifth (and higher) moment. Additionally, to simulate external disturbances primarily affecting the unstable longitudinal dynamics, we introduce a longitudinal gust disturbance of magnitude $20$ at every $500$ time steps. As a consequence, standard risk-sensitive control methods such as Linear Exponential Quadratic Gaussian (LEQG), which rely on exponentiation of the cost functional, are inapplicable due to the non-existence of the required higher-order moments.

The optimal ergodic-risk policy $K^*$, corresponding to a ergodic-risk level of $\bar{\beta} = 0.8 \gamma_N^2(K_{\text{LQR}})$, is computed using Algorithm~\ref{algo}. The resulting cost values are given by $J(K^*) = 623432$ versus $J(K_{\text{LQR}}) = 621829$. While the ergodic-risk policy \( K^* \) increases risk sensitivity by \( 20\% \) (quantified via the asymptotic conditional variance \( \gamma_N^2 \)), its average cost is only \( 0.25\% \) higher than that of the optimal LQR policy.
Also, a comparative evaluation of the ergodic-risk and LQR optimal policies is presented in \Cref{fig:ergodic-vs-lqr-rollout}. As illustrated, the ergodic-risk policy demonstrates superior resilience against gust disturbances relative to the LQR policy. The simulation codes are available at \cite{talebi_ergodic-risk_2025}.



% Next, we compare the behavior of the Ergodic-risk optimal policy with that of the LQR optimal policy. To illustrate this, we use the Grumman X-29 aircraft dynamics considered in \cite{talebi_regularizability_2022}, which was intentionally designed with a high degree of longitudinal static instability to enhance maneuverability. The longitudinal and lateral-directional dynamics are considered in the Normal Digital Powered-Approach (ND-PA) mode, with a fixed discretization step size of 0.05 \cite[Tables 9 and 10]{bosworth_linearized_1992}. 
% The system consists of four longitudinal states, four lateral-directional states, and five control inputs. Since it is normalized, we set the cost matrices as $Q =Q_c = I_8$ and $R =R_c = I_5$.


% To simulate gust disturbances that predominantly impact the unstable longitudinal dynamics, we introduce a disturbance of magnitude 20 at every 500 time steps, in addition to random noise sampled from a Student’s t-distribution with parameter $\nu=5$. Notably, this distribution has a finite fourth moment but an unbounded fifth moment. Standard risk-sensitive control methods, such as LEQG, which rely on the exponentiation of the cost functional, are not applicable in this case since the required higher moments of the noise distribution do not exist.


% Notably, this distribution has a finite fourth moment but an unbounded fifth moment. Standard risk-sensitive control methods, such as LEQG, which rely on the exponentiation of the cost functional, are not applicable in this case since the required higher moments of the noise distribution do not exist.

% The optimal Ergodic-risk policy, corresponding to a risk level of  $\bar{\beta} = 0.8 \gamma_N^2(K_{\text{LQR}})$ is computed using Algorithm \ref{algo}. The resulting cost values are $J(K_{\text{LQR}}) = 621829$ and $J(K^*) = 623432$.
% While the Ergodic-risk policy \( K^* \) exhibits a \( 20\% \) increase in risk sensitivity (measured in terms of the asymptotic conditional variance \( \gamma_N^2 \)), its average cost is only \( 0.25\% \) higher compared to the optimal LQR policy.

% The comparative performance of the optimal Ergodic-risk and optimal LQR policies is depicted for a single rollout in \Cref{fig:ergodic-vs-lqr-rollout}.
% As shown in the figure, the Ergodic-risk policy demonstrates improved resilience to gust disturbances compared to the LQR policy. Similar robustness to large disturbances has been observed for Ergodic-risk-sensitive policies in prior studies \cite{tsiamis_risk-constrained_2020, zhao_global_2023}.

\begin{figure}[pt] \centering
\includegraphics[width=0.48\textwidth]{images/Ct_and_NormX_comparison_ACC} \caption{ \small Comparison of the optimal Ergodic-risk and optimal LQR policies for the Grumman X-29 aircraft under Student’s $t$-noise and simulated gust disturbances occurring every 500 time steps.} \label{fig:ergodic-vs-lqr-rollout} \vspace{-0.4cm} 
\end{figure}

\section{Conclusions}
We introduced ergodic-risk criteria in COCP as a flexible framework to account for long-term cumulative uncertainties. By incorporating linear constraints on $\gamma_N^2$ and leveraging recent advancements in policy optimization, we proposed a primal-dual algorithm with proven convergence guarantees. Key future directions of this work include further considering to develop policy optimization algorithms for directly constrain $\gamma_M^2$ where the risk functional also directly depends on the input signal, and developing sample-based algorithms.


\bibliographystyle{ieeetr}
\bibliography{citations}

% \appendix

% \begin{proof}[Proof of \Cref{lem:MDS}]
%     Note that $g(\x_t,\u_t) \in \F_t$ for each $t$. So, $C_t$ is $\F_{t}$-adapted.
%     By Conditional Jensen's Inequality we obtain that for each $t$
%     \begin{align*}
%         \E|C_t| &\leq \E |g(\x_t,\u_t)| + \E[\E[|g(\x_t,\u_t)|\; |\F_{t-1}] ] \\
%     &= 2 \E|g(\x_t,\u_t)| \\
%     &\leq 2 M \left( \E\|\x_t\|^p+\E\|\u_t\|^p \right) <\infty,
%     \end{align*}
%     where the equality follows the Tower property and the last inequality is due to the moment condition on the process noise, the linear dynamics, and the fact that $\pi$ is affine. Because in that case, there exists another constant $M_2$ such that 
%     \(\|\x_{t}\| \leq M_2(\|\x_{t-1}\| + \|\w_t\| + 1)\) and
%     \(\|\u_{t}\| \leq M_2(\|\x_{t-1}\| + 1),\)
%     which by Holder inequality imply that
%     \(\|\x_{t}\|^p + \|\u_{t}\|^p \leq 3^{p} M_2^p(\|\x_{t-1}\|^p + \|\w_t\|^p + 1).\)
%     If the process noise and initial condition has moments up to order $p$ then $\E (\|\x_t\|^p + \|\u_t\|^p)$ is bounded for each finite $t$.
%     Finally, $\E[C_t|\F_{t-1}] = 0$ by linearity of expectation and Tower property, and thus $\{C_t,\F_{t}\}$ is a MDS. 
% \end{proof}

% \begin{proof}[Proof of \Cref{lem:ave-conv}]
%     Note that 
%     \begin{equation}\label{eq:sys-traj}
%         \x_{t+1} = A_K^{t+1} \x_0 +  \sum_{\tau =0}^{t} A_K^{t-\tau}H\w_{\tau+1}.
%     \end{equation}
%     By \Cref{assmp:noise} on noise distribution, we observe that 
%     \[\Sigma_{t+1} \coloneqq \E[\x_{t+1} \x_{t+1}^\intercal]\]
%     must satisfy for all $t\geq0$:
%     \begin{equation*}
%         \Sigma_{t+1} =  A_K^{t+1}\Sigma_0 (A_K^\intercal)^{t+1} 
%         + \sum_{\tau =0}^{t} A_K^{\tau} H \Sigma_W H^\intercal (A_K^\intercal)^{\tau}.
%     \end{equation*}
%     As $K\in\stableK$, $A_K$ is stabilizing and so $A_K^t$ converges to zero geometrically fast as $t$ goes to infinity. Thus, the series is absolutely convergent and we observe that $\Sigma_t \to \Sigma_K$ where the existence, uniqueness, and positive-definiteness of $\Sigma_K$ follows from Discrete Lyapunov Equation. Additionally, as $t\to \infty$ we obtain that $\E[\x_{t+1}] = A_K^{t+1}m_0 \to 0$.
%     %
%     Therefore, for all $t\geq1$, 
%     \(
%         \E[\s_t] =  \sum_{s=1}^{t} A_K^s m_0,
%     \)
%     and thus 
%     $\E[\s_t/t] \to 0$.
%     Note that by exponential stability, $\sum_{s=1}A_K^s m_0$ converge exponentially fast as $t\to \infty$. Thus,  $\E[\Lambda_t/\sqrt{t}] \to 0$.
%     Similarly, 
%     \(
%         \E[\Gamma_t] = \sum_{s=1}^t \Sigma_{s}  
%     \)
%     and thus
%     $\E[\Gamma_t/t] \to \Sigma_K$ as $\Sigma_t \to \Sigma_K$.
%     Next, \cref{eq:sys-traj} implies
%         \begin{align*}
%             \s_{t+1} &= \sum_{s= 0}^t \x_{s+1}\\
%             &= \sum_{s=0}^t A_K^{s+1} \x_0 + \sum_{s=0}^t\sum_{\tau=0}^s A_K^{s-\tau} H \w_{\tau+1} \\
%             &= - \x_0 + \sum_{s=-1}^{t} A_K^{s+1} \x_0 + \sum_{\tau=0}^t \sum_{s=\tau}^t A_K^{s-\tau} H \w_{\tau+1}\\
%             &= -\x_0 + \sum_{\tau=-1}^t \mathcal{A}_{t-\tau} H \w_{\tau+1},
%         \end{align*}
%         where $\mathcal{A}_{t} \coloneqq \sum_{s=0}^t A_K^s$ and for simplicity we denote, with abuse of notation, $H\w_{0} \coloneqq \x_0$. Let us without loss of generality assume $\Sigma_W = \Sigma_0$ in the rest of the argument.
%         If $K\in\stableK$,  then there exists uniform constants $C,\rho$ such that \cite[Lemma 6]{talebi_data-driven_2023} $\|A_K^s\| \leq C \rho^s, \forall s$, implying that
%         \[\|\mathcal{A}_t\| \leq C \frac{1-\rho^{t}}{1-\rho} \leq \frac{C}{1-\rho}\]
%         %
%         Now, for any $\epsilon>0$, Markov Inequality implies
%         \begin{align*}
%             \P\{\|\s_{t+1}&+\x_0\| > \epsilon t\} \\
%             =& \P\{\tr{(\s_{t+1}+\x_0)(\s_{t+1}+\x_0)^\intercal} > \epsilon^2 t^2\}\\
%             \leq & \frac{1}{\epsilon^2 t^2} \E \tr{(\s_{t+1}+\x_0)(\s_{t+1}+\x_0)^\intercal} \\
%             = &  \frac{1}{\epsilon^2 t^2} \E \tr{\sum_{\tau=-1}^t \sum_{s=-1}^t \mathcal{A}_{t-\tau} H \w_\tau \w_s^\intercal H^\intercal \mathcal{A}_{t-s}^\intercal}\\
%             = &  \frac{1}{\epsilon^2 t^2} \tr{ \sum_{s=-1}^t \mathcal{A}_{t-s} H \Sigma_W H^\intercal \mathcal{A}_{t-s}^\intercal}\\
%             = &  \frac{1}{\epsilon^2 t^2} \tr{ H\Sigma_W H^\intercal \sum_{s=0}^{t+1} \mathcal{A}_{s}^\intercal \mathcal{A}_{s}}\\
%             \leq &  \frac{\|H\|^2\tr{ \Sigma_W}}{\epsilon^2 t^2}  \left\|\sum_{s=0}^{t+1} \mathcal{A}_{s}^\intercal \mathcal{A}_{s}\right\|\\
%             \leq &  \frac{\|H\|^2\tr{ \Sigma_W}}{\epsilon^2 t^2}  \sum_{s=0}^{t+1} \left\|\mathcal{A}_{s}\right\|^2\\
%             \leq & \frac{\|H\|^2\tr{ \Sigma_W}}{\epsilon^2 t^2} \frac{C^2 (t+1)}{(1-\rho)^2} \\
%             \leq & \mathcal{O}(\frac{1}{\epsilon^2 t})
%         \end{align*}
%         where we used $\E{\w_\tau\w_s^\intercal} =0$ for $\tau\neq s$ and bounded second-order moments of the noise and initial condition. This implies the convergence of $\s_t/t \xrightarrow{p} 0 $ in probability.
%         The last claim follows by a similar argument using Markov Inequality and convergence of $\Sigma_t$ and thus, is omitted.
% \end{proof}

% \begin{proof}[Proof of \Cref{lem:Lagrangian}]
%     The smoothness of $L_\lambda(\cdot)$ and $\gamma_N^2(\cdot)$ follows by smoothness of $\Sigma_K$ in $K$, which together with the expression for $\nabla_K L(K,\lambda)$ are obtained similar to derivations of \cite[Lemma 2]{talebi_data-driven_2023}, with $P_{(K,\lambda)}$ being the unique positive definite solution to the displayed Lyapunov equation whenever $K\in\mathcal{S}$ is stabilizing. Also, $Q_K + 4\lambda Q^c H \Sigma_W H^\intercal Q^c \succeq Q$ for each $\lambda \geq 0$, and thus
%     \(L(K,\lambda) - \lambda \beta[Q^c] \geq \tr{Q \Sigma_K} = \tr{P_{(K,0)} H \Sigma_W H^\intercal},\)
%     where the equality follows by the cyclic permutation property of trace with $P_{(K,0)}$ satisfying 
%     \(P_{(K,0)} = A_K^\intercal P_{(K,0)} A_K + Q_K.\)
%     Now, by a similar argument as \cite[Lemma 1]{talebi_data-driven_2023}, we can show that
%     \(L(K,\lambda) - \lambda \beta[Q^c] \geq \tr{P_n H_n \Sigma_W H_n^\intercal},\)
%     where $P_n$ is the unique solution to 
%     \(P_n = (A_K^n)^\intercal P_n A_K^n + Q_K\)
%     which is positive definite as $(A_K,Q^{\frac{1}{2}})$ is observable, and $H_n = [H \;\; A_K H \;\; \cdots \;\; A_K^{n-1} H]$ which is full-rank as $(A_K, H)$ is controllable; thus $H_n \Sigma_W H_n^\intercal$ is positive definite as also $\Sigma \succ 0$. Again, by a similar argument as \cite[Lemma 1]{talebi_data-driven_2023}, we can show that 
%     \(\tr{P_n H_n \Sigma_W H_n^\intercal} \geq \underline{\lambda}(H_n \Sigma_W H_n^\intercal) \underline{\lambda}(R)\|K\|_F^2.\)
%     Therefore, if $\|K\| \to \infty$, $L(K,\lambda)$ approaches $+\infty$; also, if $K\to \partial \stableK$, $P_n$ approaches $+\infty$, resulting in $L(K,\lambda)$ approaching $+\infty$ because $H_n \Sigma_W H_n^\intercal \succ 0$. So, we conclude the coercivity of $L(\cdot,\lambda)$ and thus, the resulting compact sublevel sets. The rest of the claims follows directly by observing that $P_{(K,\lambda)}$ essentially satisfies the dual Lyapunov equation as that $X_{(L)}$ in \cite[Lemma 2]{talebi_data-driven_2023} where $Q$ is replaced with $Q + 4 \lambda Q^c H \Sigma_W H^\intercal Q^c$. This completes the proof.
% \end{proof}

\end{document}
