

\paragraph{Overview}
{\ouralg} restructures the training process into multiple iterative learning cycles, each comprising two key components as illustrated in Figure \ref{fig:method}:
(i) \textit{\textbf{Inner Learner with Knowledge Identification:}} rapidly acquires new task knowledge while estimating the corresponding parameter importance, and
(ii) \textit{\textbf{Outer Learner with Knowledge Fusion:}} utilizes a memory buffer to retrieve historical task information. 
By leveraging the importance distributions of both current and historical tasks, it provides global control for effective knowledge transfer through redundant knowledge pruning and key knowledge merging.


%By comparing importance distributions of current and historical tasks, it provides global control over knowledge retention and transfer.
%Figure \ref{fig:method} illustrates the {\ouralg} framework, with the following subsections detailing each component.
%Figure \ref{fig:method} provides a comprehensive overview of {\ouralg}, and the following subsections elaborate on each component in detail.



\subsection{Inner Learner with Knowledge Identification}  
Assume the current task is \(\mathcal{T}_k\), and the iterative update for the model parameters $\theta^{k-1}$ at the $b$-th iteration are denoted by $\theta_b^{k-1}$ \footnote{For simplicity, we omit the superscripts $k-1$ in subsequent descriptions.}.
In the inner loop, the model initializes with $\theta_{b(0)} = \theta_b$ and is rapidly updated over \(Q\) gradient steps using batch data $\epsilon_{k}^q$ sampled from \(\mathcal{D}_k\) at the $q$-th step. 
%without any constraint.
After obtaining $\theta_{b(Q)}$ the task-specific updates are encapsulated in the task vector $\tau_b^{in} \in \mathbb{R}^n$:
\begin{equation}
\tau_b^{\text{in}} = \theta_{b(Q)} - \theta_{b(0)}
\end{equation}

This task vector captures the knowledge acquired for the current task. However, $\tau^{in}$ often contains redundant information, and directly merging it into the model may compromise historical knowledge, leading to catastrophic forgetting.
To address this, we propose a knowledge identification technique to identify the key parameters which storing critical knowledge within the task vector.
%enabling precise global control in the outer loop.

We use a commonly adopted importance metric in model pruning \cite{konishi2023spg}, defined as the magnitude of the gradient-weight product:
%Following commonly used importance metrics from the model pruning community \cite{konishi2023spg}, we define parameter importance as:
%we define parameter importance based on the magnitude of the gradient-weight product:  
\begin{equation}
\bar{I}\left(w_{i j}\right)=\left|w_{i j} \nabla_{w_{i j}} \mathcal{L}\right| \label{eq:1}
\end{equation}
where \(w_{ij}\) represents trainable parameters.  

Due to stochastic batch sampling and training dynamics, the metric in Eq. (\ref{eq:1}) may be unreliable, introducing variability \cite{zhang2022platon}. To mitigate this, we apply an exponential moving average \cite{zhang2023adalora} to smooth the trajectory gradients over $Q$ inner loop iterations:  
\begin{equation}
\begin{split}
I_{b(q)}   =\alpha_{1} I_{b(q-1)} + \left(1-\alpha_{1}\right) \bar{I}_{b(q)} \label{eq:I}
\end{split}
\end{equation}
where $\alpha_{1}$ is the smoothing factor, $q \in \left\{ 1, 2, ..., Q \right\}$ is the iteration number in the inner loop, and $I_{b(q)}$ represents smoothed importance.
The inner task vector \(\tau_b^{\text{in}}\) and its associated parameter importance \(I_b^{\text{in}}\) are then passed to the outer learner.


% Due to stochastic batch sampling and training dynamics, the metric in Eq. (\ref{eq:1}) may be unreliable, introducing variability and uncertainty \cite{zhang2022platon}. To mitigate this, we apply an exponential moving average \cite{zhang2023adalora} to smooth the trajectory gradients over $Q$ inner loop iterations:  
% \begin{equation}
% \begin{split}
% \bar{I}^{(q)}\left(w_{i j}\right)  =\alpha_{1} \bar{I}^{(q-1)}\left(w_{i j}\right)+ \left(1-\alpha_{1}\right) I^{(q)}\left(w_{i j}\right) \label{eq:I}
% \end{split}
% \end{equation}
% \begin{equation}
% \begin{split}
% \bar{U}^{(q)}\left(w_{i j}\right)  =\alpha_{2} \bar{U}^{(q-1)}\left(w_{i j}\right)+ \\ \left(1-\alpha_{2}\right)\left|I^{(q)}\left(w_{i j}\right)-\bar{I}^{(q)}\left(w_{i j}\right)\right| \label{eq:U}
% \end{split}
% \end{equation}
% where $\alpha_{1}$ and $\alpha_{2}$ are smoothing factors,
% $\bar{I}^{(q)}$ represents smoothed sensitivity and $\bar{U}^{(q)}$ quantifies uncertainty using the variation between $I^{(q)}$ and $\bar{I}^{(q)}$.
% Importance is then computed as:
% \begin{equation}
% I^{(q)}\left(w_{i j}\right)=\bar{I}^{(q)}\left(w_{i j}\right) \cdot \bar{U}^{(q)}\left(w_{i j}\right) \label{eq:2}
% \end{equation}

% The inner task vector \(\tau_b^{\text{in}}\) and its parameter importance \(I_b^{\text{in}}\) are then passed to the outer learner.



\subsection{Outer Learner with Knowledge Fusion}
The outer loop manages the global merging of knowledge, guided by parameter importance.
%From the inner loop, we obtain the current task vector $\tau_b^{\text{in}}$ and its parameter importance distribution \(I_b^{\text{in}}\).
To access historical knowledge, after acquiring $\theta_{b(Q)}$, the outer loop samples data $\phi_{b}$ from the memory buffer $\mathcal{M}_{<k}$. It then performs a single training iteration, updating the parameters to $\theta_{b(M)}$. Then the outer task vector $\tau_b^{\text{out}} \in \mathbb{R}^n$, capturing historical task information, is defined as:
\begin{equation}
\tau_b^{\text{out}} = \theta_{b(M)} - \theta_{b(Q)}
\end{equation}

\paragraph{Dynamic Update of Historical Importance Distribution.}
While obtaining the outer task vector, we calculate the historical task importance distribution based on the latest model state $\theta_{b(Q)}$, using Eq. (\ref{eq:1}).
The update process is then expressed as:
\begin{equation}
\bar{I}_b^{\text{out}} = \mathbb{P}(\bar{I}_b^{\text{out}} \mid \theta_{b(Q)})
\end{equation} 

This update, based on conditional probability, enables the computation of the historical importance distribution $I_b^{\text{out}}$ using the current model state.
This distinguishes it from traditional static importance estimation methods and ensures more accurate knowledge identification. 
However, the limited sample size from the memory buffer can introduce significant variance in the importance estimates.
%However, the limited sample size from the memory buffer and the use of a single outer loop iteration can introduce significant variance.
To address this, we also apply exponential smoothing to the previous outer loop distribution $I_{b-1}^{\text{out}}$:
\begin{equation}
I_b^{\text{out}} = \alpha_2 \bar{I}_b^{\text{out}} + (1 - \alpha_2) I_{b-1}^{\text{out}} \label{eq:out}
\end{equation} 
where $\alpha_2$ is the smoothing factor, enhancing stability and robustness in importance estimation.

% Similarly, the parameter importance distribution within $\tau_b^{\text{out}}$ is estimated using Eq. (\ref{eq:1}) and denoted as \(\bar{I}_b^{\text{out}}\). However, the limited sample size from the memory buffer and single outer loop iteration can introduce significant variance.
% To address this, we apply exponential smoothing using the previous outer loop distribution $I_{b-1}^{\text{out}}$:
% \begin{equation}
% I_b^{\text{out}} = \alpha_2 \bar{I}_b^{\text{out}} + (1 - \alpha_2) I_{b-1}^{\text{out}} \label{eq:out}
% \end{equation} 
% where $\alpha_2$ is a smoothing factor, enhancing stability and accuracy in importance estimation.
%This approach reduces uncertainty caused by single-sample mini-batch data and enhances the stability and accuracy of importance estimation.

\paragraph{Knowledge Fusion via Importance-based Binary Mask.}
Knowledge fusion is guided by the importance distributions $I_b^{\text{in}}$ and $I_b^{\text{out}}$.
To binarize the importance distributions, a quantile-based threshold $\delta$ is applied to select the top 20\% of parameters from both $I_b^{\text{in}}$ and $I_b^{\text{out}}$. This generates binary masks $m_b^{in} \in \mathbb{R}^n$ and $m_b^{out} \in \mathbb{R}^n$, defined as:
\begin{equation}
m_b^{\text{in}} = \mathbb{I}(I_b^{\text{in}} \geq \delta_b^{in}), m_b^{\text{out}} = \mathbb{I}(I_b^{\text{out}} \geq \delta_b^{out}) \label{eq:mask}
\end{equation} 
where $\mathbb{I}(\cdot)$ is the indicator function that outputs 1 if the condition is met and 0 otherwise.
Knowledge fusion is then performed as follows:
%Knowledge fusion is then performed as:
\begin{equation}
\theta_{b+1} = \theta_b + (m_b^{\text{in}} \odot \tau_b^{\text{in}} + m_b^{\text{out}} \odot \tau_b^{\text{out}}) \label{eq:fusion}
\end{equation} 
where $\odot$ denotes element-wise multiplication.

This knowledge fusion mechanism provides precise global control, effectively tackling key challenges in CL.
First, redundant information in the task vectors $\tau^{\text{in}}$ and $\tau^{\text{out}}$ is filtered out via the mask operation. Second, task-shared knowledge is effectively merged to facilitate knowledge transfer. Lastly, task-specific knowledge is preserved to prevent catastrophic forgetting.

The inner and outer loops operate iteratively, enabling multi-round fusion of knowledge. This iterative process facilitates the capture and absorption of useful information generated during training, providing smoother optimization compared to traditional post-training fusion methods.
Detailed implementation of {\ouralg} algorithm is provided in the Appendix (Algorithm~\ref{alg:my_algorithm}).


% Furthermore, our bi-level framework dynamically updates importance distributions of historical tasks during each outer loop iteration based on the latest model state. This ensures accurate and robust knowledge , addressing limitations of previous static importance estimations-based methods.
% Detailed implementation of {\ouralg} algorithm is provided in the Appendix (Algorithm~\ref{alg:my_algorithm}).