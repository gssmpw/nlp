\subsection{Continual Learning for LLMs}
Continual learning (CL) \cite{zhou2024continual} focuses on developing algorithms that accumulate knowledge from non-stationary data. In the LLM era, model mixture-based methods using PEFT have become dominant \cite{wang2023rehearsal, huang2024mitigating, wang2024inscl}, typically divided into model ensemble and merging approaches.

Model ensemble methods isolate parameters by assigning independent PEFT blocks to each task \cite{feng2023towards, pham2023continual, ke2023sub, li2024revisiting, he2024seekr, wang2024self}. For example, O-LoRA \cite{wang2023orthogonal} enforces orthogonality among LoRA adapters, while SAPT \cite{zhao2024sapt} uses a selection module to combine blocks based on task correlations. 
%Although these methods effectively preserve task-specific knowledge, they limit inter-task knowledge transfer and incur high memory overhead as the number of tasks increases, thus hindering scalability.
While preserving task-specific knowledge, they hinder inter-task transfer and incur high memory overhead as the number of tasks increases, limiting their scalability.
%Model ensemble methods adopt the concept of parameter isolation, learning tasks in a pipeline manner where each task is assigned an independent PEFT block \cite{wang2024rehearsal, he2024seekr, wang2024self}. For instance, \citet{wang2023orthogonal} proposed O-LoRA that constrains the learning of PEFT blocks to maintain orthogonality. Similarly, \citet{zhao2024sapt} introduced SAPT, which employs a learnable selection module to combine PEFT blocks based on task correlations, thereby enhancing KT. While such approaches can effectively prevent forgetting of old knowledge, they inherently restrict knowledge transfer across tasks. Moreover, as the number of tasks increases, the number of required PEFT blocks grows, resulting in significant memory storage demands and limiting their scalability for handling long task sequences. Model ensemble methods effectively isolate task-specific knowledge but impose high memory requirements as tasks accumulate. 

In contrast, model merging methods combine multiple models into a single model \cite{cheng2024dam, alexandrov2024mitigating, ren2024analyzing}, alleviating memory constraints.
%by eliminating the need for separate task blocks.
For example, global model merging approaches \cite{wortsman2022model, ilharco2023editing} perform a weighted fusion of models before and after training, typically assuming that all model weights contribute equally to each task.
However, determining which and how to merge parameters remains an open problem.
In this paper, we propose {\ouralg}, a novel framework that leverages the dynamic importance of parameters across different tasks by employing knowledge identification and fusion techniques to mitigate CF and promote KT.



\subsection{Parameter Importance Identification}
Identifying important parameters or knowledge regions within LLMs has gained significant attention in the NLP community \cite{zhao2023does, liu2023good, feng2024tasl2, xu2024parenting, shi2024understanding}. This research improves our understanding of LLMs and enhances their performance across a variety of tasks, including model editing \cite{wang2024editing}, compression \cite{zhang2023adalora}.

In the context of CL, \citet{du2024unlocking} use the gradient magnitudes to selectively update parameters. \citet{feng2024tasl} employ gradient-based metrics to compare the parameter importance distributions of current and historical tasks, merging task-shared regions to promote KT and retaining task-specific regions to prevent CF.
However, these approaches are limited by their reliance on static importance estimations for previous tasks, which become outdated as the model evolves. 
%Static importance estimations fail to capture the dynamic nature of knowledge acquisition and retention, leading to decreased robustness and accuracy in knowledge localization over time.

To address this limitation, \citet{wu2024meta} introduce VR-MCL, a replay-based method that dynamically updates importance information while reducing variance from random sampling. 
Although VR-MCL achieves dynamic importance estimation for historical tasks, it mainly focuses on preserving task-specific knowledge and does not update task-shared regions, thus limiting KT across tasks.
%As the closest related work, VR-MCL also achieves dynamic estimation of importance for historical tasks. However, this approach primarily focuses on preserving task-specific knowledge and neglects updates to task-shared regions, thereby limiting KT across tasks.
In contrast, inspired by the CLS theory, we propose a dynamic importance estimation method that iteratively updates parameter importance through inner and outer loops.
%we propose a dynamic importance estimation method that continuously updates parameter importance distributions through the iterative execution of inner and outer loops. 
Our approach performs multi-round knowledge fusion, adaptively adjusting the integration of new and historical knowledge based on the latest model state. This method outperforms traditional post-training fusion by enhancing robustness and enabling smoother optimization.
%Additionally, our multi-round knowledge fusion approach adaptively adjusts fusion weights for new and historical knowledge based on the latest model state, providing significant advantages over traditional post-training fusion by enhancing robustness and achieving smoother optimization.

%Unlike VR-MCL, which requires hyper-gradient updates and additional computational overhead, our method leverages residuals from the inner and outer loops, eliminating the need for extra gradient computations. This results in improved efficiency and ensures effective knowledge integration for CL.

%To address this, we propose a novel bi-level knowledge identification and fusion framework that enables dynamic importance estimations, improving robustness and accuracy in knowledge localization.
%To address these challenges, this paper introduces a dynamic importance estimation technique to continuously capture up-to-date importance distributions. By recalculating importance distributions multiple times, our method not only enhances robustness against biases but also improves the accuracy of knowledge localization.


% \subsection{Bi-level Optimization}
% Bi-level optimization models, which represent nested decision-making structures \cite{vicente1994bilevel}, has gained significant attention in CL \cite{pham2023continual, hao2024bilevel}. These studies aim to mitigate CF by introducing additional learning components \cite{qiang2024bilora, zhang2024blo} or memory units \cite{ren2024analyzing}. For example, \citet{pham2023continual} proposed DualNets, which maintain two separate systems with distinct supervised and unsupervised loss constraints. 
% However, such methods often prove inefficient for LLMs due to their high resource demands.

% The closest related work is \citet{wu2024meta}, which introduced VR-MCL, a replay-based method for updating importance information while reducing variance from random sampling. However, this approach mainly focuses on preserving task-specific knowledge and neglects updates to task-shared regions, which limits KT across tasks.

% In contrast, inspired by the CLS theory from neuroscience, we propose a novel bi-level optimization paradigm that integrates knowledge identification and fusion based on parameter importance. Unlike VR-MCL, which requires hyper-gradient updates and additional computational overhead, our method leverages residuals from the inner and outer loops, eliminating the need for extra gradient computations. This results in improved efficiency and ensures effective knowledge integration for CL.


%In contrast, inspired by the CLS theory in neuroscience, we propose a new bi-level optimization paradigm that integrates knowledge identification and fusion based on parameter importance. Unlike VR-MCL, which relies on hyper-gradient updates requiring additional computation, our approach directly utilizes residuals from the inner and outer loops, eliminating extra gradient computations and improving efficiency, while ensuring effective knowledge integration for CL.

%By leveraging parameter importance from both loops, our method enables more efficient and precise knowledge acquisition, facilitating continual learning.




%Furthermore, our fine-grained bi-level model training strategy dynamically and continuously captures up-to-date parameter importance distributions for both current and historical tasks multiple times during training, offering a more robust and adaptive solution compared to previous methods based on static importance estimation.








%useless


%However, these methods are hindered by static importance estimations, which are biased by random training data and become outdated as the model evolves. 
%Although these methods show promise in mitigating CF, they are limited by static importance estimations caused by two factors: bias introduced by the randomness in training data when importance is estimated only once, and outdated importance distributions as the model state evolves during training.
%For instance, in continual learning, knowledge localization techniques have proven effective for understanding task-specific and shared regions in LLMs. Researchers such as xxx and xxx have leveraged gradient-based metrics to estimate parameter importance, enabling effective parameter merging. These methods have shown promising results in mitigating catastrophic forgetting. However, a common limitation of these approaches is the issue of static importance estimations. This arises due to two key factors: 1.	The randomness inherent in training data can lead to biased importance estimations when conducted only once. 2.	As the model's state evolves during training, the previously estimated importance distribution may no longer remain accurate.