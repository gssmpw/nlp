
\begin{figure*}[t]
  \centering
  \includegraphics[width=0.95\linewidth]{imgs/method5.pdf}
  \caption{\textbf{Iterative update process of {\ouralg} for the $b$-th iteration.} 
  The notation $\epsilon_{k}^q$ represents training samples drawn from $\mathcal{D}_k$, while $\phi_{b}$ refers to samples drawn from $\mathcal{M}_{<k}$.
  \textbf{Inner Learner (Step 1):} Performs $Q$ iterations to rapidly adapt to the new task while identifying the parameter importance distribution.
    \textbf{Outer Learner (Step 2):} Retrieves historical task information using memory data and performs knowledge fusion, guided by the importance distributions of both current and historical tasks. 
    \textbf{Recurrent Updates (Step 3):} This inner-outer loop cycle is repeated, ensuring that each fusion knowledge step is based on up-to-date importance distributions.
    %Utilizes the memory buffer to retrieve historical task information and performs knowledge fusion guided by the importance distributions of current and historical tasks. This learning cycle is repeated iteratively, ensuring that each knowledge fusion step is based on up-to-date parameter importance distributions.
  }
  \label{fig:method}
\end{figure*}




\paragraph{Problem Formulation}
%\subsection{Continual Learning Setup}
Continual learning aims to progressively accumulate knowledge from a sequence of tasks $\{\mathcal{T}_1, \ldots, \mathcal{T}_K\}$. Each task $\mathcal{T}_k$ includes a distinct dataset $\mathcal{D}_k = \left\{ \left( x_i^k, y_i^k \right) \right\}_{i=1}^{N_k}$ of size $N_k$, where $x_i^k \in \mathcal{X}_k$ and $y_i^k \in \mathcal{Y}_k$.
The model, parameterized by $\Theta$, is trained sequentially on these tasks to minimize the following objective:
% \begin{equation}
% \max_{\Theta} \sum_{k=1}^{K} \sum_{x,y \in \mathcal{D}_k} \log p_{\Theta}(y \mid x)
% \end{equation}
\begin{equation}
\mathcal{L} = \mathbb{E}_{(x, y) \sim \bigcup_{k=1}^K \mathcal{D}_k} \left[ -\log p_\Theta(y \mid x) \right]
\end{equation}

In this work, we consider a practical scenario where a small portion of data from previous tasks is stored in a memory buffer to facilitate the CL process. 
Specifically, we randomly store $\left| \mathcal{M} \right|$ samples from each task $\mathcal{T}_i$ in memory $\mathcal{M}_i$. During training, the model is jointly optimized on the new task data $\mathcal{D}_k$ and the memory buffer $\mathcal{M}_{<k}$.
%which contains data from all preceding tasks.



\paragraph{Notation}
We consider a pre-trained model $\theta \in \mathbb{R}^n$ with $n$ parameters.
After training on task $\mathcal{T}_{k-1}$, the model are denoted as $\theta^{k-1}$.
Fine-tuning on a new task $\mathcal{T}_k$ produces updated parameters $\theta^k$.
The difference $\tau^k = \theta^k - \theta^{k-1}$, referred to as the \textit{task vector} or \textit{training residual} \cite{ilharco2023editing}, represents task-specific parameter updates.
In the {\ouralg} framework, we obtain transient training residuals through each iteration of the inner and outer loops. Specifically, two task vectors are employed to capture and quantify the new knowledge learned in the inner loop and the historical knowledge retrieved in the outer loop. %These represent residuals at different levels, thereby facilitating iterative knowledge fusion.


%In our {\ouralg} framework, two task vectors are employed to capture and quantify the new knowledge learned in the inner loop and the historical knowledge retrieved in the outer loop, thereby representing training residuals at different levels.

%In our {\ouralg} framework, task vectors are used to capture and quantify the knowledge learned by the model across different tasks. Specifically, two task vectors, $\tau^{\text{in}}$ and $\tau^{\text{out}}$, are generated by the inner and outer loops, respectively, to represent parameter residuals at different levels. These vectors are then employed in the knowledge fusion process to effectively merge task-specific and task-shared knowledge based on parameter importance.
