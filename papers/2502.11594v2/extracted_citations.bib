@inproceedings{activitynet,
  title={Activitynet: A large-scale video benchmark for human activity understanding},
  author={Caba Heilbron, Fabian and Escorcia, Victor and Ghanem, Bernard and Carlos Niebles, Juan},
  booktitle=CVPR,
  pages={961--970},
  year={2015}
}

@inproceedings{charades-sta,
  title={Tall: Temporal activity localization via language query},
  author={Gao, Jiyang and Sun, Chen and Yang, Zhenheng and Nevatia, Ram},
  booktitle=ICCV,
  pages={5267--5275},
  year={2017}
}

@article{hawkeye,
  title={Hawkeye: Training video-text llms for grounding text in videos},
  author={Wang, Yueqian and Meng, Xiaojun and Liang, Jianxin and Wang, Yuxuan and Liu, Qun and Zhao, Dongyan},
  journal={arXiv preprint arXiv:2403.10228},
  year={2024}
}

@article{munasinghe2023pgvideollava,
  title   = {PG-Video-LLaVA: Pixel Grounding Large Video-Language Models},
  author  = {Shehan Munasinghe and Rusiru Thushara and Muhammad Maaz and Hanoona Abdul Rasheed and Salman Khan and Mubarak Shah and Fahad Khan},
  year    = {2023},
  journal = {arXiv preprint arXiv: 2311.13435}
}

@article{peng2024instit,
  title   = {Inst-IT: Boosting Multimodal Instance Understanding via Explicit Visual Prompt Instruction Tuning},
  author  = {Wujian Peng and Lingchen Meng and Yitong Chen and Yiweng Xie and Yang Liu and Tao Gui and Hang Xu and Xipeng Qiu and Zuxuan Wu and Yu-Gang Jiang},
  year    = {2024},
  journal = {arXiv preprint arXiv: 2412.03565}
}

@inproceedings{pite,
  title={PiTe: Pixel-Temporal Alignment for Large Video-Language Model},
  author={Liu, Yang and Ding, Pengxiang and Huang, Siteng and Zhang, Min and Zhao, Han and Wang, Donglin},
  booktitle={European Conference on Computer Vision},
  pages={160--176},
  year={2024},
  organization={Springer}
}

@inproceedings{qvhighlights,
  title={Detecting moments and highlights in videos via natural language queries},
  author={Lei, Jie and Berg, Tamara L and Bansal, Mohit},
  booktitle=NIPS,
  pages={11846--11858},
  year={2021}
}

@article{sharegpt4video,
      title={ShareGPT4Video: Improving Video Understanding and Generation with Better Captions}, 
      author={Lin Chen and Xilin Wei and Jinsong Li and Xiaoyi Dong and Pan Zhang and Yuhang Zang and Zehui Chen and Haodong Duan and Bin Lin and Zhenyu Tang and Li Yuan and Yu Qiao and Dahua Lin and Feng Zhao and Jiaqi Wang},
      year={2024},
      journal={arXiv preprint arXiv:2406.04325},

}

@inproceedings{timechat,
  title={Timechat: A time-sensitive multimodal large language model for long video understanding},
  author={Ren, Shuhuai and Yao, Linli and Li, Shicheng and Sun, Xu and Hou, Lu},
  booktitle=CVPR,
  year={2024}
}

@inproceedings{video-chatgpt,
  title={Video-chatgpt: Towards detailed video understanding via large vision and language models},
  author={Maaz, Muhammad and Rasheed, Hanoona and Khan, Salman and Khan, Fahad Shahbaz},
  booktitle=ACL,
  year={2024}
}

@article{video-llama,
  title={Video-llama: An instruction-tuned audio-visual language model for video understanding},
  author={Zhang, Hang and Li, Xin and Bing, Lidong},
  journal={arXiv preprint arXiv:2306.02858},
  year={2023}
}

@article{videochat,
  title={Videochat: Chat-centric video understanding},
  author={Li, KunChang and He, Yinan and Wang, Yi and Li, Yizhuo and Wang, Wenhai and Luo, Ping and Wang, Yali and Wang, Limin and Qiao, Yu},
  journal={arXiv preprint arXiv:2305.06355},
  year={2023}
}

@inproceedings{vtimellm,
  title={Vtimellm: Empower llm to grasp video moments},
  author={Huang, Bin and Wang, Xin and Chen, Hong and Song, Zihan and Zhu, Wenwu},
  booktitle=CVPR,
  year={2024}
}

@article{wang2024elysium,
  title     = {Elysium: Exploring Object-level Perception in Videos via MLLM},
  author    = {Hang Wang and Yanjie Wang and Yongjie Ye and Yuxiang Nie and Can Huang},
  journal   = {ECCV},
  year      = {2024},
}

@article{yuan2024videorefer,
  title   = {VideoRefer Suite: Advancing Spatial-Temporal Object Understanding with Video LLM},
  author  = {Yuqian Yuan and Hang Zhang and Wentong Li and Zesen Cheng and Boqiang Zhang and Long Li and Xin Li and Deli Zhao and Wenqiao Zhang and Yueting Zhuang and Jianke Zhu and Lidong Bing},
  year    = {2024},
  journal = {arXiv preprint arXiv: 2501.00599}
}

@article{yuan2025sa2va,
  title   = {Sa2VA: Marrying SAM2 with LLaVA for Dense Grounded Understanding of Images and Videos},
  author  = {Haobo Yuan and Xiangtai Li and Tao Zhang and Zilong Huang and Shilin Xu and Shunping Ji and Yunhai Tong and Lu Qi and Jiashi Feng and Ming-Hsuan Yang},
  year    = {2025},
  journal = {arXiv preprint arXiv: 2501.04001}
}

@article{zhang2024llava-video,
  title   = {Video Instruction Tuning With Synthetic Data},
  author  = {Yuanhan Zhang and Jinming Wu and Wei Li and Bo Li and Zejun Ma and Ziwei Liu and Chunyuan Li},
  year    = {2024},
  journal = {arXiv preprint arXiv: 2410.02713}
}

