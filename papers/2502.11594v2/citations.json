[
  {
    "index": 0,
    "papers": [
      {
        "key": "video-llama",
        "author": "Zhang, Hang and Li, Xin and Bing, Lidong",
        "title": "Video-llama: An instruction-tuned audio-visual language model for video understanding"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "videochat",
        "author": "Li, KunChang and He, Yinan and Wang, Yi and Li, Yizhuo and Wang, Wenhai and Luo, Ping and Wang, Yali and Wang, Limin and Qiao, Yu",
        "title": "Videochat: Chat-centric video understanding"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "video-chatgpt",
        "author": "Maaz, Muhammad and Rasheed, Hanoona and Khan, Salman and Khan, Fahad Shahbaz",
        "title": "Video-chatgpt: Towards detailed video understanding via large vision and language models"
      },
      {
        "key": "zhang2024llava-video",
        "author": "Yuanhan Zhang and Jinming Wu and Wei Li and Bo Li and Zejun Ma and Ziwei Liu and Chunyuan Li",
        "title": "Video Instruction Tuning With Synthetic Data"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "sharegpt4video",
        "author": "Lin Chen and Xilin Wei and Jinsong Li and Xiaoyi Dong and Pan Zhang and Yuhang Zang and Zehui Chen and Haodong Duan and Bin Lin and Zhenyu Tang and Li Yuan and Yu Qiao and Dahua Lin and Feng Zhao and Jiaqi Wang",
        "title": "ShareGPT4Video: Improving Video Understanding and Generation with Better Captions"
      },
      {
        "key": "zhang2024llava-video",
        "author": "Yuanhan Zhang and Jinming Wu and Wei Li and Bo Li and Zejun Ma and Ziwei Liu and Chunyuan Li",
        "title": "Video Instruction Tuning With Synthetic Data"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "timechat",
        "author": "Ren, Shuhuai and Yao, Linli and Li, Shicheng and Sun, Xu and Hou, Lu",
        "title": "Timechat: A time-sensitive multimodal large language model for long video understanding"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "vtimellm",
        "author": "Huang, Bin and Wang, Xin and Chen, Hong and Song, Zihan and Zhu, Wenwu",
        "title": "Vtimellm: Empower llm to grasp video moments"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "hawkeye",
        "author": "Wang, Yueqian and Meng, Xiaojun and Liang, Jianxin and Wang, Yuxuan and Liu, Qun and Zhao, Dongyan",
        "title": "Hawkeye: Training video-text llms for grounding text in videos"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "charades-sta",
        "author": "Gao, Jiyang and Sun, Chen and Yang, Zhenheng and Nevatia, Ram",
        "title": "Tall: Temporal activity localization via language query"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "activitynet",
        "author": "Caba Heilbron, Fabian and Escorcia, Victor and Ghanem, Bernard and Carlos Niebles, Juan",
        "title": "Activitynet: A large-scale video benchmark for human activity understanding"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "qvhighlights",
        "author": "Lei, Jie and Berg, Tamara L and Bansal, Mohit",
        "title": "Detecting moments and highlights in videos via natural language queries"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "munasinghe2023pgvideollava",
        "author": "Shehan Munasinghe and Rusiru Thushara and Muhammad Maaz and Hanoona Abdul Rasheed and Salman Khan and Mubarak Shah and Fahad Khan",
        "title": "PG-Video-LLaVA: Pixel Grounding Large Video-Language Models"
      },
      {
        "key": "wang2024elysium",
        "author": "Hang Wang and Yanjie Wang and Yongjie Ye and Yuxiang Nie and Can Huang",
        "title": "Elysium: Exploring Object-level Perception in Videos via MLLM"
      },
      {
        "key": "pite",
        "author": "Liu, Yang and Ding, Pengxiang and Huang, Siteng and Zhang, Min and Zhao, Han and Wang, Donglin",
        "title": "PiTe: Pixel-Temporal Alignment for Large Video-Language Model"
      },
      {
        "key": "peng2024instit",
        "author": "Wujian Peng and Lingchen Meng and Yitong Chen and Yiweng Xie and Yang Liu and Tao Gui and Hang Xu and Xipeng Qiu and Zuxuan Wu and Yu-Gang Jiang",
        "title": "Inst-IT: Boosting Multimodal Instance Understanding via Explicit Visual Prompt Instruction Tuning"
      },
      {
        "key": "yuan2025sa2va",
        "author": "Haobo Yuan and Xiangtai Li and Tao Zhang and Zilong Huang and Shilin Xu and Shunping Ji and Yunhai Tong and Lu Qi and Jiashi Feng and Ming-Hsuan Yang",
        "title": "Sa2VA: Marrying SAM2 with LLaVA for Dense Grounded Understanding of Images and Videos"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "wang2024elysium",
        "author": "Hang Wang and Yanjie Wang and Yongjie Ye and Yuxiang Nie and Can Huang",
        "title": "Elysium: Exploring Object-level Perception in Videos via MLLM"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "peng2024instit",
        "author": "Wujian Peng and Lingchen Meng and Yitong Chen and Yiweng Xie and Yang Liu and Tao Gui and Hang Xu and Xipeng Qiu and Zuxuan Wu and Yu-Gang Jiang",
        "title": "Inst-IT: Boosting Multimodal Instance Understanding via Explicit Visual Prompt Instruction Tuning"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "yuan2024videorefer",
        "author": "Yuqian Yuan and Hang Zhang and Wentong Li and Zesen Cheng and Boqiang Zhang and Long Li and Xin Li and Deli Zhao and Wenqiao Zhang and Yueting Zhuang and Jianke Zhu and Lidong Bing",
        "title": "VideoRefer Suite: Advancing Spatial-Temporal Object Understanding with Video LLM"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "wang2024elysium",
        "author": "Hang Wang and Yanjie Wang and Yongjie Ye and Yuxiang Nie and Can Huang",
        "title": "Elysium: Exploring Object-level Perception in Videos via MLLM"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "peng2024instit",
        "author": "Wujian Peng and Lingchen Meng and Yitong Chen and Yiweng Xie and Yang Liu and Tao Gui and Hang Xu and Xipeng Qiu and Zuxuan Wu and Yu-Gang Jiang",
        "title": "Inst-IT: Boosting Multimodal Instance Understanding via Explicit Visual Prompt Instruction Tuning"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "yuan2024videorefer",
        "author": "Yuqian Yuan and Hang Zhang and Wentong Li and Zesen Cheng and Boqiang Zhang and Long Li and Xin Li and Deli Zhao and Wenqiao Zhang and Yueting Zhuang and Jianke Zhu and Lidong Bing",
        "title": "VideoRefer Suite: Advancing Spatial-Temporal Object Understanding with Video LLM"
      }
    ]
  }
]