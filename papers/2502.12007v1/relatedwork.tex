\section{Related Works}
\label{related_work}


%Recent breakthroughs in deep learning have enabled attribute prediction using models that offer high-dimensional representations of diverse speaker characteristics \cite{baevski2020wav2vec}. These models, frequently self-supervised and pretrained, produce embeddings suitable for downstream applications such demographic profile, age estimate, and gender categorization.
Recent advancements in deep learning, particularly self-supervised models, have revolutionized speaker attribute prediction by providing high-dimensional embeddings that capture diverse speech characteristics \cite{baevski2020wav2vec}. These embeddings are increasingly employed for all speech tasks, including speaker recognition.

\subsection{Foundational Models for Attribute Prediction}
%Foundational models are extensive pretrained neural networks engineered to provide high-dimensional features, appropriate for many downstream applications, including demographic profiling. Utilizing self-supervised techniques, these models discern intricate patterns in data without requiring labeled supervision. In speech analysis, models like WavLM offer speaker-specific embeddings that may be efficiently employed in attribute prediction tasks.
Foundational models, such as WavLM, leverage self-supervised learning to extract intricate patterns from speech without requiring labeled data. These models produce embeddings that are versatile for various downstream tasks, including demographic attribute prediction.

Based on the Wav2Vec 2.0 framework \cite{baevski2020wav2vec}, WavLM is a self-supervised model trained on diverse datasets to capture acoustic and speaker-specific features. Its embeddings excel in speech emotion recognition~\cite{wu2024emo} and speaker recognition tasks~\cite{ashihara2024investigation}.

% \begin{itemize}
% \item \textbf{WavLM}~\cite{wavlm}: WavLM is a self-supervised model designed to capture acoustic patterns and long-range relationships in speech, based on the Wav2Vec 2.0 framework~\cite{baevski2020wav2vec}. WavLM, trained on an extensive and varied English dataset, adeptly acquires resilient speech representations beneficial for demographic predictions, including age, gender, and linguistic background. Its architecture enables the generation of embeddings that are rich in subtle characteristics and adaptable to many speech-related activities.
% \end{itemize}

%Our approach harnesses WavLM embeddings, augmented with mean pooling and transformation methods, to deliver accurate demographic predictions across a wide range of speaker profiles.


\subsection{Speaker Attribute Prediction} 
Speaker attribute prediction has traditionally relied on handcrafted features or statistical models such as i-vectors \cite{dehak2010front}, which represent compact speaker-specific embeddings.
More recently, the statistical approaches were supplanted by the neural approaches such as x-vectors \cite{snyder2018x}.
%While effective for tasks like speaker verification, these methods often require extensive domain expertise.

Recent work has shifted towards deep neural network-based methods. Studies like those by Kwasny et al. \cite{kwasny2020agegender} and Hechmi et al. \cite{hechmi2021voxceleb} demonstrate that embeddings from pretrained models, such as WavLM and Wav2Vec, significantly outperform traditional approaches. These self-supervised embeddings capture general-purpose representations, enabling robust demographic profiling without task-specific feature engineering.

Speaker attribute prediction now primarily uses deep neural networks to predict demographics such as age and gender\cite{almomani2023age}. 
Kwasny et al. \cite{kwasny2020agegender} and Hechmi et al. \cite{hechmi2021voxceleb} illustrate that embeddings from pre-trained speaker verification models can achieve high scores on age and gender classification tasks. 
%Previous methods often relied on handcrafted features that are task specific and require considerable domain expertise. 
%However, self-supervised learning approaches such as Wav2Vec and WavLM offer embeddings containing general-purpose representations, making them easily accessible in many applications for demographic prediction.

Recent advances in x-vector-based techniques have given speaker analysis a new layer of analysis for prosody, dialect, and speaker identity. Such embeddings capture high-dimensional data that eliminates the need for tedious feature engineering. For example, traditional features like MFCCs require extensive preprocessing and domain expertise to extract meaningful information, while self-supervised embeddings, like those of Oord et al. \cite{oord2018cpc}, inherently encode rich speaker-specific attributes. Comparative experiments have shown that self-supervised embeddings frequently outperform manual feature sets for demographic profiling purposes \cite{ericsson2021selfsupervised}.
%These pretrained model for embedding extraction allow models to capture better speech features, and therefore can predict speaker demographics more accurately across many datasets.

%These studies leverage WavLM embeddings to implement advanced feature extraction algorithms to provide a foundation for demographic profiling. This method is designed to address critical challenges in both measuring speaker diversity and modeling demographic characteristics, by rigorously benchmarking model performance across a wide range of datasets.