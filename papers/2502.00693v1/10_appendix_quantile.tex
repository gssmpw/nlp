
\section{Proof for 
\texorpdfstring{$1 - \delta$}{} Quantile}\label{sec:appendix_quantile_proof}
In this section, we provide the calculation of the probability distribution of random variable $W := \sum_{j=1}^{m} \mathbbm 1\{g[j] \neq g'[j]\}$, which plays an important part in the proof of the privacy guarantee for our algorithm (see Section~\ref{sec:appendix_privacy_guarantees}).
In Section~\ref{sec:definition_quantile}, we present the definition of random variables $W, Y, Z$ used in this section.
In Section~\ref{sec:distribution_Y}, we calculate the probability distribution of $Y$.
In Section~\ref{sec:distribution_Z}, we calculate the probability distribution of $Z$ conditioned on $Y$.
In Section~\ref{sec:distribution_W}, we calculate the probability distribution of $W$.

\subsection{Definition} \label{sec:definition_quantile}
In this section, we present the definitions of random variables which will be used in the section.
\begin{definition}[Definition of $W$]\label{def:W}
Let $W := \sum_{j=1}^{m} \mathbbm 1\{g[j] \neq g'[j]\}$, where $g \in \{0, 1\}^m$ denotes the ground truth values generated by dataset $A$, and $g' \in \{0, 1\}^m$ denotes the ground truth values generated by neighboring dataset $A'$. 
\end{definition}

\begin{definition}[Definition of $Y$]\label{def:Y}
Consider a $x \in [n]$. 

Let $y_1, y_2, \cdots , y_k$ denotes the $k$ hash values generated by the standard Bloom filter (Definition~\ref{def:bloom_filter}). 

We define $Y$ as the set of distinct values among $y_1, y_2, \cdots, y_k$, where $|Y| \in { 1, 2, \cdots, k }$.

\end{definition}

\begin{definition}[Definition of $Z$]\label{def:Z}
Consider two data $x, x' \in [n]$. 

Let $y_1, y_2, \cdots , y_k$ denotes the $k$ hash values generated by $x$, and $y_1', y_2', \cdots , y_k'$ denotes the $k$ hash values generated by $x'$. 

Follow the Definition~\ref{def:Y}, let $Y_x$ denotes the set of distinct values in $y_1, y_2, \cdots , y_k$, and $Y_{x'}$ denotes the set of distinct values in $y_1', y_2', \cdots , y_k'$.

Suppose $|Y_x| = a, |Y_{x'}| = b$, where $a, b \in \{1, 2, \cdots , k \}$

We define $Z$ is the set of distinct values in $Y_x \cup Y_{x'}$, where $|Z| \in \{1, 2, \cdots , 2k \}$

\end{definition}


\subsection{Distribution of \texorpdfstring{$Y$}{}}\label{sec:distribution_Y}
Then we proceed to calculate the probability distribution of $Y$ in this section.
\begin{lemma}[Distribution of $Y$]\label{lem:distribution_of_Y}
If the following conditions hold
\begin{itemize}
    \item Let $y_1, y_2, \cdots , y_k$ be defined in Definition~\ref{def:Y}.
    \item Let $Y$ be defined as Definition~\ref{def:Y}.
\end{itemize}

Then, we can show, for $y = 1, 2, \cdots, k$, 
\begin{align*}
    & ~ \Pr[|Y| = y] \\
    = & ~ \begin{cases}
        1 / m^{k-1},  & y = 1 \\
        \binom{m}{y} \cdot y ^k / m^k
        - \sum_{i=1}^{k-1} \binom{m - i}{y -i} \Pr[Y = i], & y = 2, \cdots , k
    \end{cases}
\end{align*}
\end{lemma}

\begin{proof}

{\bf Step 1.} We consider $Y = 1$ case. 

Without any constraints, there are total $m^k$ situations. This is because each hash value can be freely chosen from $m$ positions, and there are $k$ hash values. Therefore, there are total $m^k$ situations. 

Then, with constraint $Y = 1$, $k$ hash values must be assigned to the same position. The position can be chosen from a total of $m$ positions. Therefore, in this case, there are $m$ situations. 

Combining the above two analysis, we have
\begin{align*}
    \Pr[Y = 1] = & ~ \frac{m}{m^k} \notag \\
    = & ~ \frac{1}{m^{k - 1}}.
\end{align*}

{\bf Step 2.} We consider $Y = 2, \cdots , k$ cases.

Similarly, without any constraints, there are total $m^k$ situations. 

Since we need $Y = y$, we must choose $y$ from different positions in the total $m$ positions. Therefore, we have $\binom{m}{y}$ term.

Note that in each position, we need at least one hash value. We first compute the number of freely assigning $k$ hash values to the $y$ positions. Then we remove the failure cases.  

As there are $y$ positions and $k$ hash values, we have the $y^k$ term for freely assigning $k$ hash values to $y$ positions.

For the failure case, we have $\sum_{i=1}^{k-1} \Pr[Y = i] \cdot \binom{m - i}{y -i}$. The $\binom{m - i}{y -i}$ term is due to repeated counting for each $i \in [k-1]$, where we first fix $i$ positions and then randomly pick the other $y-i$ different positions in the total $m-i$ positions. 

Thus, in all, we have the following formula,
\begin{align*}
    \Pr[Y = y] = \frac{\binom{m}{y} \cdot y ^k}{m^k} - \sum_{i=1}^{k-1} \Pr[Y = i] \cdot \binom{m - i}{y -i}.
\end{align*}

\end{proof}

\subsection{Distribution of \texorpdfstring{$Z$}{} conditioned on \texorpdfstring{$Y$}{}}\label{sec:distribution_Z}
In this section, we calculate the probability distribution of $Z$ condition on $Y$.

\begin{lemma}[Probability of $Z$ conditioned on $Y_x$ and $ Y_{x'}$]\label{lem:distribution_of_Z}
If the following conditions hold
\begin{itemize}
    \item Let $Y_x, Y_{x'}, Z$ be defined as Definition~\ref{def:Z}.
    \item Let $A_n^m$ denotes $n! / (n-m)!$.
    \item Let $t := z - \max(a, b)$. 
\end{itemize}

Then, we can show, for $z = \max(a, b), \cdots, (a + b)$, 
\begin{align*}
    \Pr[|Z| = z | |Y_x| = a, |Y_{x'}| = b] = \frac{A_m^a \cdot \binom{b}{t} \cdot A_{m - a}^t \cdot A_{a}^{b-t}}{A_m^a \cdot A_m^b}.
\end{align*}
\end{lemma}

\begin{proof}

Since the minimum value of $Z$ is $\max(a, b)$, without loss of generality, we assume $ a \geq b$. Then we have $a \leq z \leq (a + b)$.

Recall we have $t = z - \max(a, b) = z - a, t \in \{0, 1, \cdots , b\}$. Then we have
\begin{align*}
    & ~ \Pr[|Z| = a + t | |Y_x| = a, |Y_{x'}| = b] \\
    = & ~ \frac{A_m^a \cdot \binom{b}{t} \cdot A_{m - a}^t \cdot A_{a}^{b-t}}{A_m^a \cdot A_m^b}.
\end{align*}

We explain why we have the above equation in the following steps.

{\bf Step 1.} We consider the denominator. 

Without any constraints, since $|Y_x| = a$, we need to choose $a$ from different positions in the total $m$ positions. Therefore, we have the $A_m^a$ term in the denominator. Similarly, since $|Y_{x'}| = b$, we have the $A_m^b$ term in the denominator. 

{\bf Step 2.} We consider the numerator. 

Firstly, since $|Y_x| = a$, we need to choose $a$ different positions in total $m$ positions. Therefore, we have the $A_m^a$ term in the numerator. 

Since $Z$ is defined as Definition~\ref{def:Z}, we can have the following
\begin{align*}
    |Y_x \cap Y_{x'}| = & ~ a + b - z \notag \\
    |Y_{x'}| - |Y_x \cap Y_{x'}| = & ~ z - a \notag \\
    = & ~ t
\end{align*}

Then, we need to choose $t$ values from $Y_{x'}$ to construct $|Y_{x'}| - |Y_x \cap Y_{x'}|$ part. Therefore, we have the $\binom{b}{t}$ term in the numerator. 

We also need to choose $t$ different positions in the rest $m - a$ positions for  $|Y_{x'}| - |Y_x \cap Y_{x'}|$ part. Hence, we have the $A_{m - a} ^ t$ term in the numerator. 

Lastly, let's consider the $b - t$ part. For this part, we need to choose $b - t$ different positions from $a$ positions. Therefore, we have the $A_a^{b - t}$ term in the numerator. 

Combining all analyses together, finally, we have 
\begin{align*}
   \Pr[|Z| = z | |Y_x| = a, |Y_{x'}| = b] = \frac{A_m^a \cdot \binom{b}{t} \cdot A_{m - a}^t \cdot A_{a}^{b-t}}{A_m^a \cdot A_m^b}.
\end{align*}

\end{proof}

\subsection{Distribution of \texorpdfstring{$W$}{}}\label{sec:distribution_W}


\begin{figure}[!ht]
\centering
\includegraphics[width=0.45\textwidth]{w_figs/w_pmf.pdf}
\caption{
Let $W := |S|$ denote the number of bits in the Bloom filter changed by substituting an element in the inserted set $A$ (Definition~\ref{def:pre_neighbor_dataset}). We achieve $\epsilon_0$-DP for each single bit and $(\epsilon, \delta)$-DP for the entire Bloom filter via the random response (Definition~\ref{def:random_response}), where $\epsilon_0 = \epsilon / N$. 
The $N$ is $1 - \delta$ quantile of the random variable $W$. 
We visualize the distribution of the random variable $W$ (see Lemma~\ref{lem:distribution_of_W}) under the setting described in the experiments section (Section~\ref{sec:experiments}). Namely, we have the bit array length in the Bloom filter $m = 2^{19}$, the number of elements inserted into the Bloom filter $|A| = 10^{5}$, and the number of hash functions $k=3$. It can be inferred from this visualization that the values of random variable $W$ have good concentration properties, mostly concentrated around its mean. 
}
\label{fig:w_distribution}
\end{figure}

Finally, we present the calculation of the probability distribution of $W$ in this section.
\begin{lemma}[Distribution of $W$]\label{lem:distribution_of_W}
If the following conditions hold
\begin{itemize}
    \item Let $Y_x, Y_{x'}, Z$ be defined as Definition~\ref{def:Z}.
    \item Let $W$ be defined as Definition~\ref{def:W}.
    \item Let $A_n^m$ denotes $\frac{n!}{(n - m)!}$. 
    \item Let $p_0 := (1 - \frac{1}{m})^{(|A| - 1)k}$ denotes the proportion of bits which are still $0$ in the bit-array.
    \item Let $n_1 := |Y_x \cap Y_{x'}|= a + b - z$ denotes the number of overlap elements in $Y_x$ and $Y_{x'}$. 
    \item Let $n_2 := |Y_x \cup Y_{x'}| - |Y_x \cap Y_{x'}| =  z  -(a + b - z) = 2z -a -b$ denotes the number of exclusive or elements in $Y_x$ and $Y_{x'}$.
\end{itemize}

Then, we can show, for $w=0, \cdots 2k$,
\begin{align*}
    & ~ \Pr[W = w] \notag \\
    = & ~ \sum_{a = 1}^k \sum_{b = 1}^k \sum_{z = 1}^{a+b} \Pr[W = w | |Z| = z, |Y_x| = a, |Y_{x'}| = b] \notag \\
    & ~ \cdot \Pr[|Z| = z | |Y_x| = a, |Y_{x'}| = b] \\
    & ~ \cdot \Pr[|Y_x| = a] \cdot  \Pr[|Y_{x'}| = b].
\end{align*}

where

\begin{align*}
    & ~ \Pr[W = w | |Z| = z, |Y_x| = a, |Y_{x'}| = b] \\
    = & ~
    \begin{cases}
        0,  &  n_2 < w \\
        \binom{n_2}{w} \cdot p_0^w \cdot (1 - p_0)^{n_2 - w}, & n_2 \geq w
    \end{cases}
\end{align*}
\end{lemma}

\begin{proof}

By basic probability rules, we have the following equation
\begin{align*}
    & ~\Pr[W = w] \notag \\
    =& ~ \sum_{a = 1}^k \sum_{b = 1}^k \sum_{z = 1}^{a+b} \Pr[W = w | |Z| = z, |Y_x| = a, |Y_{x'}| = b] \notag \\
    & ~ \cdot \Pr[|Z| = z | |Y_x| = a, |Y_{x'}| = b] \\
    & ~ \cdot \Pr[|Y_x| = a, |Y_{x'}| = b] \notag \\
    =& ~ \sum_{a = 1}^k \sum_{b = 1}^k \sum_{z = 1}^{a+b} \Pr[W = w | |Z| = z, |Y_x| = a, |Y_{x'}| = b] \notag \\
    & ~ \cdot \Pr[|Z| = z | |Y_x| = a, |Y_{x'}| = b] \\
    & ~ \cdot \Pr[|Y_x| = a] \cdot \Pr[|Y_{x'}| = b].
\end{align*}
where the first step follows from basic probability rules, the second step follows from $Y_x$, and $Y_{x'}$ are independent. 

We can get the probability of $\Pr[|Y_x| = a]$ and $\Pr[|Y_{x'}| = b$ from Lemma~\ref{lem:distribution_of_Y}. 

We can get the probability of $\Pr[|Z| = z | |Y_x| = a, |Y_{x'}| = b]$ from Lemma~\ref{lem:distribution_of_Z}. 

Now, let's consider the $\Pr[W = w | |Z| = z, |Y_x| = a, |Y_{x'}| = b]$ term. 

Note that only elements in the exclusive-or set may contribute to the final $W$. Therefore, we have $w \leq n_2$. Namely, when $n_2 < w$, we have $\Pr[W = w | |Z| = z, |Y_x| = a, |Y_{x'}| = b] = 0$. 

Now, let's calculate $\Pr[W = w | |Z| = z, |Y_x| = a, |Y_{x'}| = b]$ under $n_2 \geq w$ condition. 

Recall $x$ denotes the element deleted from $A$, and $x'$ denotes the element added to $A$ for constructing the neighbor dataset $A'$. 

Let $A_{fix} := A - x$ denote the fixed set of elements during the modifications. We have $|A_{fix}| = |A| - 1$. 

Consider the following steps:
\begin{itemize}
    \item We construct a new Bloom filter.
    \item We insert all elements in $A_{fix}$ in the Bloom filter.
    \item We define $Z_{zero}$ as the set of positions of bits which are still $0$ after the insertion of $A_{fix}$.
\end{itemize}

We define $Z_{xor}$ as the exclusive-or set of $Y_x$ and $Y_{x'}$. We have
\begin{align*}
    Z_{xor} = & ~ (Y_x \cup Y_{x'}) - (Y_x \cap Y_{x'}), \notag \\
    |Z_{xor}| = & ~ |Y_x \cup Y_{x'}| - |Y_x \cap Y_{x'}| \notag \\
    = & ~ z - (a +b - z) \notag \\
    = & ~ 2z - a - b \notag \\
    = & ~ n_2.
\end{align*}

Note that only positions in $Z_{xor} \cap Z_{zero}$ will contribute to $W$. Namely, we need $|Z_{xor} \cap Z_{zero}| = w$. 

We achieve the above condition by selecting $w$ elements in $Z_{xor}$ and let them satisfy the condition of $Z_{zero}$. 

Therefore, we have 
\begin{align*}
    & ~ \Pr[|Z_{xor} \cap Z_{zero}| = w] \\
    = & ~ \binom{n_2}{w} \cdot (1 - \frac{1}{m})^{(|A| - 1)kw} \cdot (1 - (1 - \frac{1}{m})^{(|A| - 1)k})^{n_2 - w}.
\end{align*}

Combining the above analysis, we have
\begin{align*}
    & ~ \Pr[W = w | |Z| = z, |Y_x| = a, |Y_{x'}| = b] \\
    = & ~ 
    \begin{cases}
        0,  &  n_2 < w \\
        \binom{n_2}{w} \cdot p_0^w \cdot (1 - p_0)^{n_2 - w}, & n_2 \geq w
    \end{cases}.
\end{align*}


\end{proof}


