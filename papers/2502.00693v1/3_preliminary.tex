
\section{Preliminary}\label{sec:preliminary}
In Section~\ref{sec:pre_notations}, we describe the notations we use in this paper. 
Section~\ref{sec:pre_def_bf} provides the formal definition of Bloom Filter.
Section~\ref{sec:pre_def_dp} presents the formal definition of Differential Privacy, followed by a discussion on its basic composition in Section~\ref{sec:pre_def_bc}. 

\subsection{Notations}\label{sec:pre_notations}

For any positive integer $n$, let $[n]$ denote the set $\{1, 2, \cdots , n\}$. We use $\E[]$ to denote the expectation operator and $\Pr[]$ to denote probability. We use $n!$ to denote the factorial of integer $n$. We use $A_{m}^{n}:=\frac{m!}{(m-n)!}$ to denote the number of permutation ways to choose $n$ elements from $m$ elements considering the order of selection. We use $\binom{m}{n}:=\frac{m!}{n!(m-n!)}$ to denote the number of combination ways to choose $n$ elements from $m$ elements without considering the order of selection. We use $F_{X}(x)$ to denote the Cumulative Distribution Function (CDF) of a random variable $X$ and use $F_{X}^{-1}(1-\delta)$ to denote the $1-\delta$ quantile of $F_{X}(x)$.


\subsection{Bloom Filter}\label{sec:pre_def_bf}
A Bloom filter is a space-efficient probabilistic data structure used to test whether an element is a member of the set. Its formal definition is as follows.
\begin{definition}[Bloom Filter, \cite{b70}]\label{def:bloom_filter}
    A Bloom filter is used to represent a set $A = \{x_1,x_2,\dots,x_{|A|}\}$ of $|A|$ elements from a universe $U = [n]$. A Bloom filter consists of a binary array $g \in \{0,1\}^m$ of $m$ bits, which are initially all set to $0$, and uses $k$ independent random hash functions $h_1,\dots,h_k$ with range $\{0, \dots, m-1\}$. These hash functions map each element in the universe to a random number uniform over the range $\{0,\dots,m-1\}$ for mathematical convenience. The computation time per execution for all hash functions is $\mathcal{T}_h$. Bloom Filter supports the following operations:
    \begin{itemize}
        \item \textsc{Init}$(A)$. It takes dataset A as input. For each element $x \in A$, the bits $h_i(x)$ of array $g$ are set to $1$ for $1\leq i \leq k$.
        \item \textsc{Query}$(y \in [n])$. It takes an element $y$ as input. If all $h_i(y)$ are set to $1$, then it outputs a binary answer to indicate that $y \in A$. If not, then it outputs $y$ is not a member of $A$.
    \end{itemize}
\end{definition}
A Bloom Filter does not have false negative issues but may yield a \textit{false positive} issue, where it suggests that when a query is made to check if an element is in the set but all the positions it maps to are already set to $1$ (due to previous insertions of elements of dataset $A$). Following previous literature \cite{ll23, bcfm98, lk11, loz12}, we assume a hash function selects each array position with equal probability. Then, the false positive rate of the Bloom Filter defined above can be mathematically approximated by the formula below
\begin{align*}
    (1-e^{-\frac{k|A|}{m}})^k.
\end{align*}

\subsection{Differential Privacy}\label{sec:pre_def_dp}

We begin with introducing the neighboring dataset. We follow the standard definition in the DP literature of ``neighboring'' for binary data vectors: two datasets are adjacent if they differ in one element. The formal statement is as follows.

\begin{definition}[Neighboring Dataset, \cite{dmns06}]\label{def:pre_neighbor_dataset}
$A, A' \in \{0,1\}^n$ are neighboring datasets if they only differ in one element, i.e., $A_i \neq A'_i$ for one $i \in [n]$ and $A_j = A'_j$, for $j \neq i$.
\end{definition}

Differential Privacy (DP) ensures that the output of an algorithm remains statistically similar, under neighboring datasets introduced above,
thereby protecting individual privacy. 
Its formal definition is as follows.

\begin{definition}[Differential Privacy, \cite{dmns06}]\label{def:dp}
    For a randomized algorithm $M:U \rightarrow Range(M)$ and $\epsilon,\delta\geq 0$, if for any two neighboring data $u$ and $u'$, it holds for $\forall Z \subset Range(M)$
    \begin{align*}
        \Pr[M(u)\in Z] \leq e^{\epsilon} \Pr[M(u')\in Z]+\delta,
    \end{align*}
    then algorithm $M$ is said to satisfy $(\epsilon,\delta)$-differentially privacy. If $\delta = 0$, $M$ is called $\epsilon$-differentially private.
\end{definition}

Finally, we introduce the formal definition of the random response mechanism.

\begin{definition} [Random response mechanism] \label{def:random_response}
Let $g \in \{0, 1\}^m$ denote the $m$ bit array in the Bloom filter. For any $j \in [m]$, let $\wt{g}[j]$ denote the perturbed version of $g[j]$, using the random response mechanism. Namely, for any $j \in [m]$, we have
\begin{align*}
    \Pr [\wt{g}[j] = y] = 
    \begin{cases}
        e^{\epsilon_0} / (e^{\epsilon_0} + 1),  & y = g[j] \\
        1 / (e^{\epsilon_0} + 1), & y = 1 - g[j]
    \end{cases}
\end{align*}
\end{definition}

Let $a = e^{\epsilon_0} / (e^{\epsilon_0} + 1), b = 1 / (e^{\epsilon_0} + 1)$. Since $a / b = e^{\epsilon_0}$, this implies random response can achieve $\epsilon_0$-DP. 

\begin{algorithm}[!ht]\caption{Differentially Private Bloom Filter}\label{alg:init}
\begin{algorithmic}[1]
\State {\bf data structure } \textsc{DPBloomFilter} \Comment{Theorem~ \ref{thm:query_privacy:informal}, \ref{thm:dpbloom_true_accuracy:informal}, \ref{thm:running_complexity}}
\State  
\State {\bf members}
\State \hspace{4mm} $[n]$ is the set universe
\State \hspace{4mm} $k$ is the number of hash functions
\State \hspace{4mm} Let $g \in \{0,1\}^{m}$.
\State \hspace{4mm} Let $h_i : [n] \rightarrow [m]$ for each $i \in [k]$
\State {\bf end members}
\State
\Procedure{Init}{$A \subset [n], k \in \mathbb{N}_+, m \in \mathbb{N}_+$} \Comment{Lemma~\ref{lem:init_time}}
    \State Let $m$ denote the length of the filter
    \State We pick $k$ random hash functions, say they are $h_1, h_2, \cdots, h_k$, for each $i \in [k]$, $h_i : [n] \rightarrow [m]$
    \State Set every entry of $g$ to $0$.
    \State Let $N = F^{-1}(1 - \delta)$, and $\epsilon_0 := \epsilon / N$ 
    \For{$x \in A$}
        \For{$i=1 \to k$}
            \State Let $j\gets h_i[x]$
            \State $g[j] \gets 1$
        \EndFor
    \EndFor 
    \For{$j=1 \to m$}
        \State $\wt{g}[j] \gets g[j]$ with probability $\frac{e^{\epsilon_0}}{ e^{\epsilon_0} + 1}$
        \State $\wt{g}[j] \gets 1 - g[j]$ with probability $\frac{1}{ e^{\epsilon_0} + 1}$
    \EndFor    
\EndProcedure
\State
\Procedure{Query}{$y \in [n]$} \Comment{Lemma~\ref{lem:query_time}, Theorem~\ref{thm:query_privacy:informal}, Theorem~\ref{thm:dpbloom_true_accuracy:informal}}
    \For{$i = 1 \to k$}
        \State Let $j\gets h_i[y]$
        \If{$\wt{g}[j] \neq 1 $}
            \State \Return $\mathsf{false}$
        \EndIf
    \EndFor
    \State \Return $\mathsf{true}$
\EndProcedure
\State


\State {\bf data structure}
\end{algorithmic}
\end{algorithm}

\subsection{Basic Composition of Differential Privacy}\label{sec:pre_def_bc}
If multiple differential privacy algorithms are involved, a composition rule becomes necessary. This section presents the simplest form of composition, as stated in the following lemma.
\begin{lemma}[Basic composition, \cite{gkk+23}]\label{lem:pre_com_lem}
    Let $M_1$ be an $(\epsilon_1,\delta_1)$-DP algorithm and $M_2$ be an $(\epsilon_2,\delta_2)$-DP algorithm. 
    Then $M(X) = (M_1(X),M_2(M_1(X),X)$ is an $(\epsilon_1+\epsilon_2,\delta_1+\delta_2)$-DP algorithm.
\end{lemma}
The basic composition lemma quantifies the total privacy loss across all operations. This is essential for determining whether the overall privacy guarantee remains acceptable.




