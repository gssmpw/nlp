@inproceedings{alshahwan2024automated,
  title={Automated unit test improvement using large language models at meta},
  author={Alshahwan, Nadia and Chheda, Jubin and Finogenova, Anastasia and Gokkaya, Beliz and Harman, Mark and Harper, Inna and Marginean, Alexandru and Sengupta, Shubho and Wang, Eddy},
  booktitle={Companion Proceedings of the 32nd ACM International Conference on the Foundations of Software Engineering},
  pages={185--196},
  year={2024}
}

@article{austin2021program,
  title={Program synthesis with large language models},
  author={Austin, Jacob and Odena, Augustus and Nye, Maxwell and Bosma, Maarten and Michalewski, Henryk and Dohan, David and Jiang, Ellen and Cai, Carrie and Terry, Michael and Le, Quoc and others},
  journal={arXiv preprint arXiv:2108.07732},
  year={2021}
}

@misc{bogin2024superevaluatingagentssetting,
      title={SUPER: Evaluating Agents on Setting Up and Executing Tasks from Research Repositories}, 
      author={Ben Bogin and Kejuan Yang and Shashank Gupta and Kyle Richardson and Erin Bransom and Peter Clark and Ashish Sabharwal and Tushar Khot},
      year={2024},
      eprint={2409.07440},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2409.07440}, 
}

@inproceedings{chatunitest,
  title={Chatunitest: A framework for llm-based test generation},
  author={Chen, Yinghao and Hu, Zehao and Zhi, Chen and Han, Junxiao and Deng, Shuiguang and Yin, Jianwei},
  booktitle={Companion Proceedings of the 32nd ACM International Conference on the Foundations of Software Engineering},
  pages={572--576},
  year={2024}
}

@article{chen2021evaluating,
  title={Evaluating large language models trained on code},
  author={Chen, Mark and Tworek, Jerry and Jun, Heewoo and Yuan, Qiming and Pinto, Henrique Ponde De Oliveira and Kaplan, Jared and Edwards, Harri and Burda, Yuri and Joseph, Nicholas and Brockman, Greg and others},
  journal={arXiv preprint arXiv:2107.03374},
  year={2021}
}

@article{codellama,
  title={Code llama: Open foundation models for code},
  author={Roziere, Baptiste and Gehring, Jonas and Gloeckle, Fabian and Sootla, Sten and Gat, Itai and Tan, Xiaoqing Ellen and Adi, Yossi and Liu, Jingyu and Sauvestre, Romain and Remez, Tal and others},
  journal={arXiv preprint arXiv:2308.12950},
  year={2023}
}

@inproceedings{contest,
    title = "{C}on{T}est: A Unit Test Completion Benchmark featuring Context",
    author = "Villmow, Johannes  and
      Depoix, Jonas  and
      Ulges, Adrian",
    editor = "Lachmy, Royi  and
      Yao, Ziyu  and
      Durrett, Greg  and
      Gligoric, Milos  and
      Li, Junyi Jessy  and
      Mooney, Ray  and
      Neubig, Graham  and
      Su, Yu  and
      Sun, Huan  and
      Tsarfaty, Reut",
    booktitle = "Proceedings of the 1st Workshop on Natural Language Processing for Programming (NLP4Prog 2021)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.nlp4prog-1.2/",
    doi = "10.18653/v1/2021.nlp4prog-1.2",
    pages = "17--25",
    abstract = "We introduce CONTEST, a benchmark for NLP-based unit test completion, the task of predicting a test`s assert statements given its setup and focal method, i.e. the method to be tested. ConTest is large-scale (with 365k datapoints). Besides the test code and tested code, it also features context code called by either. We found context to be crucial for accurately predicting assertions. We also introduce baselines based on transformer encoder-decoders, and study the effects of including syntactic information and context. Overall, our models achieve a BLEU score of 38.2, while only generating unparsable code in 1.92{\%} of cases."
}

@inproceedings{crux,
  title={CRUXEval: A Benchmark for Code Reasoning, Understanding and Execution},
  author={Gu, Alex and Roziere, Baptiste and Leather, Hugh James and Solar-Lezama, Armando and Synnaeve, Gabriel and Wang, Sida},
  booktitle={Forty-first International Conference on Machine Learning},
  year={2024}
}

@misc{devbench,
      title={DevBench: A Comprehensive Benchmark for Software Development}, 
      author={Bowen Li and Wenhan Wu and Ziwei Tang and Lin Shi and John Yang and Jinyang Li and Shunyu Yao and Chen Qian and Binyuan Hui and Qicheng Zhang and Zhiyin Yu and He Du and Ping Yang and Dahua Lin and Chao Peng and Kai Chen},
      year={2024},
      eprint={2403.08604},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2403.08604}, 
}

@article{hsieh2024ruler,
  title={RULER: What's the Real Context Size of Your Long-Context Language Models?},
  author={Cheng-Ping Hsieh and Simeng Sun and Samuel Kriman and Shantanu Acharya and Dima Rekesh and Fei Jia and Yang Zhang and Boris Ginsburg},
  year={2024},
  journal={arXiv preprint arXiv:2404.06654},
}

@article{hui2024qwen2,
  title={Qwen2. 5-Coder Technical Report},
  author={Hui, Binyuan and Yang, Jian and Cui, Zeyu and Yang, Jiaxi and Liu, Dayiheng and Zhang, Lei and Liu, Tianyu and Zhang, Jiajun and Yu, Bowen and Dang, Kai and others},
  journal={arXiv preprint arXiv:2409.12186},
  year={2024}
}

@misc{jain2024testgenevalrealworldunit,
      title={TestGenEval: A Real World Unit Test Generation and Test Completion Benchmark}, 
      author={Kush Jain and Gabriel Synnaeve and Baptiste Rozière},
      year={2024},
      eprint={2410.00752},
      archivePrefix={arXiv},
      primaryClass={cs.SE},
      url={https://arxiv.org/abs/2410.00752}, 
}

@article{liu2024llm,
  title={LLM-Powered Test Case Generation for Detecting Tricky Bugs},
  author={Liu, Kaibo and Liu, Yiyang and Chen, Zhenpeng and Zhang, Jie M and Han, Yudong and Ma, Yun and Li, Ge and Huang, Gang},
  journal={arXiv preprint arXiv:2404.10304},
  year={2024}
}

@misc{luo2024repoagent,
      title={RepoAgent: An LLM-Powered Open-Source Framework for Repository-level Code Documentation Generation}, 
      author={Qinyu Luo and Yining Ye and Shihao Liang and Zhong Zhang and Yujia Qin and Yaxi Lu and Yesai Wu and Xin Cong and Yankai Lin and Yingli Zhang and Xiaoyin Che and Zhiyuan Liu and Maosong Sun},
      year={2024},
      eprint={2402.16667},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{nie2023learning,
  title={Learning deep semantics for test completion},
  author={Nie, Pengyu and Banerjee, Rahul and Li, Junyi Jessy and Mooney, Raymond J and Gligoric, Milos},
  booktitle={2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE)},
  pages={2111--2123},
  year={2023},
  organization={IEEE}
}

@inproceedings{r2e,
  title={R2E: Turning any Github Repository into a Programming Agent Environment},
  author={Jain, Naman and Shetty, Manish and Zhang, Tianjun and Han, King and Sen, Koushik and Stoica, Ion},
  booktitle={Forty-first International Conference on Machine Learning},
  year={2024}
}

@inproceedings{repobench,
  title={RepoBench: Benchmarking Repository-Level Code Auto-Completion Systems},
  author={Liu, Tianyang and Xu, Canwen and McAuley, Julian},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024}
}

@article{ryan2024code,
  title={Code-Aware Prompting: A Study of Coverage-Guided Test Generation in Regression Setting using LLM},
  author={Ryan, Gabriel and Jain, Siddhartha and Shang, Mingyue and Wang, Shiqi and Ma, Xiaofei and Ramanathan, Murali Krishna and Ray, Baishakhi},
  journal={Proceedings of the ACM on Software Engineering},
  volume={1},
  number={FSE},
  pages={951--971},
  year={2024},
  publisher={ACM New York, NY, USA}
}

@misc{starcoder2,
      title={StarCoder 2 and The Stack v2: The Next Generation}, 
      author={Anton Lozhkov and Raymond Li and Loubna Ben Allal and Federico Cassano and Joel Lamy-Poirier and Nouamane Tazi and Ao Tang and Dmytro Pykhtar and Jiawei Liu and Yuxiang Wei and Tianyang Liu and Max Tian and Denis Kocetkov and Arthur Zucker and Younes Belkada and Zijian Wang and Qian Liu and Dmitry Abulkhanov and Indraneil Paul and Zhuang Li and Wen-Ding Li and Megan Risdal and Jia Li and Jian Zhu and Terry Yue Zhuo and Evgenii Zheltonozhskii and Nii Osae Osae Dade and Wenhao Yu and Lucas Krauß and Naman Jain and Yixuan Su and Xuanli He and Manan Dey and Edoardo Abati and Yekun Chai and Niklas Muennighoff and Xiangru Tang and Muhtasham Oblokulov and Christopher Akiki and Marc Marone and Chenghao Mou and Mayank Mishra and Alex Gu and Binyuan Hui and Tri Dao and Armel Zebaze and Olivier Dehaene and Nicolas Patry and Canwen Xu and Julian McAuley and Han Hu and Torsten Scholak and Sebastien Paquet and Jennifer Robinson and Carolyn Jane Anderson and Nicolas Chapados and Mostofa Patwary and Nima Tajbakhsh and Yacine Jernite and Carlos Muñoz Ferrandis and Lingming Zhang and Sean Hughes and Thomas Wolf and Arjun Guha and Leandro von Werra and Harm de Vries},
      year={2024},
      eprint={2402.19173},
      archivePrefix={arXiv},
      primaryClass={cs.SE},
      url={https://arxiv.org/abs/2402.19173}, 
}

@article{tang2024chatgpt,
  title={Chatgpt vs sbst: A comparative assessment of unit test suite generation},
  author={Tang, Yutian and Liu, Zhijie and Zhou, Zhichao and Luo, Xiapu},
  journal={IEEE Transactions on Software Engineering},
  year={2024},
  publisher={IEEE}
}

@article{team2024codegemma,
  title={Codegemma: Open code models based on gemma},
  author={Team, CodeGemma and Zhao, Heri and Hui, Jeffrey and Howland, Joshua and Nguyen, Nam and Zuo, Siqi and Hu, Andrea and Choquette-Choo, Christopher A and Shen, Jingyue and Kelley, Joe and others},
  journal={arXiv preprint arXiv:2406.11409},
  year={2024}
}

@misc{testbench,
      title={TestBench: Evaluating Class-Level Test Case Generation Capability of Large Language Models}, 
      author={Quanjun Zhang and Ye Shang and Chunrong Fang and Siqi Gu and Jianyi Zhou and Zhenyu Chen},
      year={2024},
      eprint={2409.17561},
      archivePrefix={arXiv},
      primaryClass={cs.SE},
      url={https://arxiv.org/abs/2409.17561}, 
}

@article{tufano2020unit,
  title={Unit test case generation with transformers and focal context},
  author={Tufano, Michele and Drain, Dawn and Svyatkovskiy, Alexey and Deng, Shao Kun and Sundaresan, Neel},
  journal={arXiv preprint arXiv:2009.05617},
  year={2020}
}

@article{yuan2024evaluating,
  title={Evaluating and improving chatgpt for unit test generation},
  author={Yuan, Zhiqiang and Liu, Mingwei and Ding, Shiji and Wang, Kaixin and Chen, Yixuan and Peng, Xin and Lou, Yiling},
  journal={Proceedings of the ACM on Software Engineering},
  volume={1},
  number={FSE},
  pages={1703--1726},
  year={2024},
  publisher={ACM New York, NY, USA}
}

@inproceedings{zhang-etal-2024-bench,
    title = "$\infty${B}ench: Extending Long Context Evaluation Beyond 100{K} Tokens",
    author = "Zhang, Xinrong  and
      Chen, Yingfa  and
      Hu, Shengding  and
      Xu, Zihang  and
      Chen, Junhao  and
      Hao, Moo  and
      Han, Xu  and
      Thai, Zhen  and
      Wang, Shuo  and
      Liu, Zhiyuan  and
      Sun, Maosong",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.814",
    pages = "15262--15277",
}

@article{zhuo2024bigcodebench,
  title={BigCodeBench: Benchmarking Code Generation with Diverse Function Calls and Complex Instructions},
  author={Zhuo, Terry Yue and Vu, Minh Chien and Chim, Jenny and Hu, Han and Yu, Wenhao and Widyasari, Ratnadira and Yusuf, Imam Nur Bani and Zhan, Haolan and He, Junda and Paul, Indraneil and others},
  journal={CoRR},
  year={2024}
}

