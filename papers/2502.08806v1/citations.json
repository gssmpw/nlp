[
  {
    "index": 0,
    "papers": [
      {
        "key": "chen2021evaluating",
        "author": "Chen, Mark and Tworek, Jerry and Jun, Heewoo and Yuan, Qiming and Pinto, Henrique Ponde De Oliveira and Kaplan, Jared and Edwards, Harri and Burda, Yuri and Joseph, Nicholas and Brockman, Greg and others",
        "title": "Evaluating large language models trained on code"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "austin2021program",
        "author": "Austin, Jacob and Odena, Augustus and Nye, Maxwell and Bosma, Maarten and Michalewski, Henryk and Dohan, David and Jiang, Ellen and Cai, Carrie and Terry, Michael and Le, Quoc and others",
        "title": "Program synthesis with large language models"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "zhuo2024bigcodebench",
        "author": "Zhuo, Terry Yue and Vu, Minh Chien and Chim, Jenny and Hu, Han and Yu, Wenhao and Widyasari, Ratnadira and Yusuf, Imam Nur Bani and Zhan, Haolan and He, Junda and Paul, Indraneil and others",
        "title": "BigCodeBench: Benchmarking Code Generation with Diverse Function Calls and Complex Instructions"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "devbench",
        "author": "Bowen Li and Wenhan Wu and Ziwei Tang and Lin Shi and John Yang and Jinyang Li and Shunyu Yao and Chen Qian and Binyuan Hui and Qicheng Zhang and Zhiyin Yu and He Du and Ping Yang and Dahua Lin and Chao Peng and Kai Chen",
        "title": "DevBench: A Comprehensive Benchmark for Software Development"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "crux",
        "author": "Gu, Alex and Roziere, Baptiste and Leather, Hugh James and Solar-Lezama, Armando and Synnaeve, Gabriel and Wang, Sida",
        "title": "CRUXEval: A Benchmark for Code Reasoning, Understanding and Execution"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "repobench",
        "author": "Liu, Tianyang and Xu, Canwen and McAuley, Julian",
        "title": "RepoBench: Benchmarking Repository-Level Code Auto-Completion Systems"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "swebench",
        "author": "Carlos E Jimenez and John Yang and Alexander Wettig and Shunyu Yao and Kexin Pei and Ofir Press and Karthik R Narasimhan",
        "title": "{SWE}-bench: Can Language Models Resolve Real-world Github Issues?"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "r2e",
        "author": "Jain, Naman and Shetty, Manish and Zhang, Tianjun and Han, King and Sen, Koushik and Stoica, Ion",
        "title": "R2E: Turning any Github Repository into a Programming Agent Environment"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "chatunitest",
        "author": "Chen, Yinghao and Hu, Zehao and Zhi, Chen and Han, Junxiao and Deng, Shuiguang and Yin, Jianwei",
        "title": "Chatunitest: A framework for llm-based test generation"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "liu2024llm",
        "author": "Liu, Kaibo and Liu, Yiyang and Chen, Zhenpeng and Zhang, Jie M and Han, Yudong and Ma, Yun and Li, Ge and Huang, Gang",
        "title": "LLM-Powered Test Case Generation for Detecting Tricky Bugs"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "tang2024chatgpt",
        "author": "Tang, Yutian and Liu, Zhijie and Zhou, Zhichao and Luo, Xiapu",
        "title": "Chatgpt vs sbst: A comparative assessment of unit test suite generation"
      },
      {
        "key": "yuan2024evaluating",
        "author": "Yuan, Zhiqiang and Liu, Mingwei and Ding, Shiji and Wang, Kaixin and Chen, Yixuan and Peng, Xin and Lou, Yiling",
        "title": "Evaluating and improving chatgpt for unit test generation"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "alshahwan2024automated",
        "author": "Alshahwan, Nadia and Chheda, Jubin and Finogenova, Anastasia and Gokkaya, Beliz and Harman, Mark and Harper, Inna and Marginean, Alexandru and Sengupta, Shubho and Wang, Eddy",
        "title": "Automated unit test improvement using large language models at meta"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "tufano2020unit",
        "author": "Tufano, Michele and Drain, Dawn and Svyatkovskiy, Alexey and Deng, Shao Kun and Sundaresan, Neel",
        "title": "Unit test case generation with transformers and focal context"
      },
      {
        "key": "nie2023learning",
        "author": "Nie, Pengyu and Banerjee, Rahul and Li, Junyi Jessy and Mooney, Raymond J and Gligoric, Milos",
        "title": "Learning deep semantics for test completion"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "ryan2024code",
        "author": "Ryan, Gabriel and Jain, Siddhartha and Shang, Mingyue and Wang, Shiqi and Ma, Xiaofei and Ramanathan, Murali Krishna and Ray, Baishakhi",
        "title": "Code-Aware Prompting: A Study of Coverage-Guided Test Generation in Regression Setting using LLM"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "codellama",
        "author": "Roziere, Baptiste and Gehring, Jonas and Gloeckle, Fabian and Sootla, Sten and Gat, Itai and Tan, Xiaoqing Ellen and Adi, Yossi and Liu, Jingyu and Sauvestre, Romain and Remez, Tal and others",
        "title": "Code llama: Open foundation models for code"
      },
      {
        "key": "starcoder2",
        "author": "Anton Lozhkov and Raymond Li and Loubna Ben Allal and Federico Cassano and Joel Lamy-Poirier and Nouamane Tazi and Ao Tang and Dmytro Pykhtar and Jiawei Liu and Yuxiang Wei and Tianyang Liu and Max Tian and Denis Kocetkov and Arthur Zucker and Younes Belkada and Zijian Wang and Qian Liu and Dmitry Abulkhanov and Indraneil Paul and Zhuang Li and Wen-Ding Li and Megan Risdal and Jia Li and Jian Zhu and Terry Yue Zhuo and Evgenii Zheltonozhskii and Nii Osae Osae Dade and Wenhao Yu and Lucas Krau\u00df and Naman Jain and Yixuan Su and Xuanli He and Manan Dey and Edoardo Abati and Yekun Chai and Niklas Muennighoff and Xiangru Tang and Muhtasham Oblokulov and Christopher Akiki and Marc Marone and Chenghao Mou and Mayank Mishra and Alex Gu and Binyuan Hui and Tri Dao and Armel Zebaze and Olivier Dehaene and Nicolas Patry and Canwen Xu and Julian McAuley and Han Hu and Torsten Scholak and Sebastien Paquet and Jennifer Robinson and Carolyn Jane Anderson and Nicolas Chapados and Mostofa Patwary and Nima Tajbakhsh and Yacine Jernite and Carlos Mu\u00f1oz Ferrandis and Lingming Zhang and Sean Hughes and Thomas Wolf and Arjun Guha and Leandro von Werra and Harm de Vries",
        "title": "StarCoder 2 and The Stack v2: The Next Generation"
      },
      {
        "key": "hui2024qwen2",
        "author": "Hui, Binyuan and Yang, Jian and Cui, Zeyu and Yang, Jiaxi and Liu, Dayiheng and Zhang, Lei and Liu, Tianyu and Zhang, Jiajun and Yu, Bowen and Dang, Kai and others",
        "title": "Qwen2. 5-Coder Technical Report"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "starcoder2",
        "author": "Anton Lozhkov and Raymond Li and Loubna Ben Allal and Federico Cassano and Joel Lamy-Poirier and Nouamane Tazi and Ao Tang and Dmytro Pykhtar and Jiawei Liu and Yuxiang Wei and Tianyang Liu and Max Tian and Denis Kocetkov and Arthur Zucker and Younes Belkada and Zijian Wang and Qian Liu and Dmitry Abulkhanov and Indraneil Paul and Zhuang Li and Wen-Ding Li and Megan Risdal and Jia Li and Jian Zhu and Terry Yue Zhuo and Evgenii Zheltonozhskii and Nii Osae Osae Dade and Wenhao Yu and Lucas Krau\u00df and Naman Jain and Yixuan Su and Xuanli He and Manan Dey and Edoardo Abati and Yekun Chai and Niklas Muennighoff and Xiangru Tang and Muhtasham Oblokulov and Christopher Akiki and Marc Marone and Chenghao Mou and Mayank Mishra and Alex Gu and Binyuan Hui and Tri Dao and Armel Zebaze and Olivier Dehaene and Nicolas Patry and Canwen Xu and Julian McAuley and Han Hu and Torsten Scholak and Sebastien Paquet and Jennifer Robinson and Carolyn Jane Anderson and Nicolas Chapados and Mostofa Patwary and Nima Tajbakhsh and Yacine Jernite and Carlos Mu\u00f1oz Ferrandis and Lingming Zhang and Sean Hughes and Thomas Wolf and Arjun Guha and Leandro von Werra and Harm de Vries",
        "title": "StarCoder 2 and The Stack v2: The Next Generation"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "team2024codegemma",
        "author": "Team, CodeGemma and Zhao, Heri and Hui, Jeffrey and Howland, Joshua and Nguyen, Nam and Zuo, Siqi and Hu, Andrea and Choquette-Choo, Christopher A and Shen, Jingyue and Kelley, Joe and others",
        "title": "Codegemma: Open code models based on gemma"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "luo2024repoagent",
        "author": "Qinyu Luo and Yining Ye and Shihao Liang and Zhong Zhang and Yujia Qin and Yaxi Lu and Yesai Wu and Xin Cong and Yankai Lin and Yingli Zhang and Xiaoyin Che and Zhiyuan Liu and Maosong Sun",
        "title": "RepoAgent: An LLM-Powered Open-Source Framework for Repository-level Code Documentation Generation"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "bogin2024superevaluatingagentssetting",
        "author": "Ben Bogin and Kejuan Yang and Shashank Gupta and Kyle Richardson and Erin Bransom and Peter Clark and Ashish Sabharwal and Tushar Khot",
        "title": "SUPER: Evaluating Agents on Setting Up and Executing Tasks from Research Repositories"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "hsieh2024ruler",
        "author": "Cheng-Ping Hsieh and Simeng Sun and Samuel Kriman and Shantanu Acharya and Dima Rekesh and Fei Jia and Yang Zhang and Boris Ginsburg",
        "title": "RULER: What's the Real Context Size of Your Long-Context Language Models?"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "zhang-etal-2024-bench",
        "author": "Zhang, Xinrong  and\nChen, Yingfa  and\nHu, Shengding  and\nXu, Zihang  and\nChen, Junhao  and\nHao, Moo  and\nHan, Xu  and\nThai, Zhen  and\nWang, Shuo  and\nLiu, Zhiyuan  and\nSun, Maosong",
        "title": "$\\infty${B}ench: Extending Long Context Evaluation Beyond 100{K} Tokens"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "repobench",
        "author": "Liu, Tianyang and Xu, Canwen and McAuley, Julian",
        "title": "RepoBench: Benchmarking Repository-Level Code Auto-Completion Systems"
      }
    ]
  },
  {
    "index": 22,
    "papers": [
      {
        "key": "testbench",
        "author": "Quanjun Zhang and Ye Shang and Chunrong Fang and Siqi Gu and Jianyi Zhou and Zhenyu Chen",
        "title": "TestBench: Evaluating Class-Level Test Case Generation Capability of Large Language Models"
      }
    ]
  },
  {
    "index": 23,
    "papers": [
      {
        "key": "jain2024testgenevalrealworldunit",
        "author": "Kush Jain and Gabriel Synnaeve and Baptiste Rozi\u00e8re",
        "title": "TestGenEval: A Real World Unit Test Generation and Test Completion Benchmark"
      }
    ]
  },
  {
    "index": 24,
    "papers": [
      {
        "key": "swebench",
        "author": "Carlos E Jimenez and John Yang and Alexander Wettig and Shunyu Yao and Kexin Pei and Ofir Press and Karthik R Narasimhan",
        "title": "{SWE}-bench: Can Language Models Resolve Real-world Github Issues?"
      }
    ]
  },
  {
    "index": 25,
    "papers": [
      {
        "key": "contest",
        "author": "Villmow, Johannes  and\nDepoix, Jonas  and\nUlges, Adrian",
        "title": "{C}on{T}est: A Unit Test Completion Benchmark featuring Context"
      }
    ]
  }
]