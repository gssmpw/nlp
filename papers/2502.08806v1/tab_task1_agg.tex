
 \begin{table}[t] 
 
\centering
\small
  \begin{tabular}{lccc}                                   \toprule     & EM     & ER     & RER    \\ \midrule \codegemma                 & 30.3\% & 46.5\% & 43.7\% \\ \magicoder           & 23.3\% & 40.6\% & 34.3\% \\ \codellama   & 31.3\% & 52.6\% & 42.3\% \\ \starcoder   & 32.7\% & 52.4\% & 41.1\% \\ \mistral     & 21.5\% & 39.4\% & 37.2\% \\ \qwen        & 52.6\% & 64.7\% & 59.8\% \\ \codestral           & 45.5\% & 68.2\% & 63.3\% \\ \zeroone                 & 41.4\% & 61.7\% & 56.5\% \\ \llamasm  & 35.7\% & 57.4\% & 53.5\% \\ \llamamd & 49.9\% & 74.2\% & 69.0\% \\ 
  \midrule
  \gptm                 & 43.1\% & 70.8\% & 66.3\% \\ \gemini                   & 49.7\% & 71.9\% & 67.0\% \\ \claude             & 56.3\% & 78.2\% & 72.4\% \\ \gpto                      & 55.2\% & 72.0\% & 68.0\%  \\
  \bottomrule
  \end{tabular}
   \caption{Model performance on Task I in the Problem-Only setting. Refined execution rate (RER) is the recommended metric which reflects the models' ability in completing compilable and non-cheating assertion statements. Open source models are organized in ascending order based on their maximum supported length, followed by their model size. }
  \label{tb:task1}
  \end{table}