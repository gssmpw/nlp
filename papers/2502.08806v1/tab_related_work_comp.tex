
   \begin{table*}[!ht]
   \centering
   % \footnotesize
   \scriptsize
   \setlength{\tabcolsep}{3pt}

   \begin{tabularx}{\textwidth}{r|p{3.5cm}|p{1.6cm}|p{1.0cm}|p{1.6cm}|p{0.7cm}|p{2cm}|p{1.4cm}} % Replace some columns with X
   \toprule
               & Use Case & Data Source & PL & Size & Exec Repo & Constructed Context & Coverage \\ \midrule
   SWE-bench \cite{swebench} & issue resolution & SWE-Bench & Python & 2294 & $\surd$ & Up to 50k &$\times$\\ 
   TestEval  \cite{testeval}  & test case gen & Leetcode & Python & 210 &$\times$& $\times$ & $\surd$ \\ 
   TestBench \cite{testbench}  & test case gen & Github & Java & 108 & $\surd$ &$\times$& $\surd$ \\ 
   SWT-Bench \cite{swtbench} & tcg for issue reproduction & SWE-Bench & Python & 1900+ & $\surd$ &$\times$& $\surd$ \\ 
   TestGenEval \cite{jain2024testgenevalrealworldunit} & test case gen & SWE-Bench & Python & 1210 & $\surd$ &$\times$& $\surd$ \\ \midrule
   CLOVER & test case gen (3 tasks covering completion \& generation) & Github (new) & Python & 845 from 16,234 & $\surd$ & Up to 128k & $\surd$ \\   \bottomrule
   \end{tabularx}
   \caption{Comparison of CLOVER and other benchmarks pertaining to test case generation. CLOVER encompasses three unique tasks for generating test cases. It includes 845 problems, leading to a total of 5312 instances when accounting for different context settings. Numerous benchmarks for test case generation are based on the work by \citet{swebench}.}
   \label{tb:related}
   \end{table*}
   
