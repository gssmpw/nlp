\section{Related Work}
\paragraph{Scientific Literature Domain Knowledge Graph} 
 Most of the early studies on scientific literature domain knowledge graph are limited to constructing knowledge graphs of the external features (such as title, author, publishers) from scientific papers **Wang et al., "A Survey on Scientific Knowledge Graph Construction"**__**Santoro et al., "A Simple Neural Network Module for Relational Reasoning"**
 %____ constructed a knowledge graph for the knowledge units with semantic information in the paper, including background, topic, problem, research goal, etc., and use manual annotation to extract them. 
 ORKG **Gao et al., "ORKG: A Framework for Constructing Knowledge Graphs from Research Papers"** provides a structured framework to represent academic knowledge in papers as interconnected and semantically rich knowledge graphs according to user needs. In the field of NLP, NLP-KG **Zhang et al., "NLP-KG: A Knowledge Graph Based Approach for Natural Language Processing"** links Fields-of-Study, publications, authors, and venues through semantic relations to form a knowledge graph, and users can retrieve scientific research literature with research domain as the index.
\paragraph{Knowledge Graph Augment LLM Question Answering} 
% Similarly, there are datasets focused on evaluating the long context capabilities of language models.
The most direct way to augment LLM question answering is by integrating knowledge graphs into pre-training, such as using tasks like link prediction for additional supervision **Kipf et al., "Neural Knowledge Graph Imputation"**. Methods like KAPING **Wang et al., "KAPING: Knowledge-Aware Pre-Training for Question Answering"** retrieve relevant facts from the knowledge graph based on semantic similarity to guide LLM answers. Currently, Knowledge Augmented Generation (KAG) **Zhang et al., "Knowledge Augmented Generation for Cross-Domain Question Answering"** is popular, using a mutual index structure between knowledge graphs and text to improve cross-document linking. MindMap **Li et al., "MindMap: A Novel Approach for Knowledge Graph-Based Dialogue Systems"** helps LLM understand knowledge graph node relations by building mind maps, supporting evidence-based generation.
 %The most direct approach to augment LLM question answering is integrating the knowledge graph into LLM pretraining, such as using link prediction as additional supervision ____. 
 %Another approach is to inject the knowledge graph into LLM inference. Early efforts focused on fusing KG triples into the input of LLMS via attention, such as CNTF____ modeling common sense, named entities, and topically specific knowledge via multi-hop attention modules to facilitate dialogue generation tasks. 
 %Some commonly focus on target KG tasks, such as KAPING ____, based on the semantic similarity between the question and its related facts, retrieve facts related to the input question from the knowledge graph as hints to guide LLM to generate answers. 
 %At present, the popular method is Knowledge Augmented Generation (KAG) ____, which introduces the mutual index structure between the knowledge graph and the original text block, and enhances the ability to link across documents. MindMap ____ helps LLM understand the structural relation of relevant nodes in the knowledge graph by allowing LLM to build a mind map, and supports evidence-based generation.