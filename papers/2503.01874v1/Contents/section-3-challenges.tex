\section{Issues in Task Vector Sparsification for Model Merging}
\label{section-3}

In model merging, particularly when using sparse task vectors to combine models fine-tuned for different tasks, an unexpected phenomenon has emerged: magnitude-based pruning, which typically retains weights with larger absolute values, often underperforms compared to random pruning methods. 
This result contradicts the intuition that preserving critical knowledge, rather than randomly retaining information, within the task vectors should enhance the performance of the merged model.
Our investigation into this phenomenon reveals two key issues: the overlap between retained weights and their unbalanced distribution within each task vector.
\begin{figure}[t]
    \centering
    \includegraphics[width=0.9\linewidth]{Figures/overlap.pdf} 
    \vspace{-0.1in}
    \caption{The trend of overlap rate along the sparsity ratio shows that the overlap rate achieved by magnitude-based pruning decreases more slowly than that of random pruning, with the gap widening progressively.}
    \label{fig:weight_overlap}
    \vspace{-0.2in}
\end{figure}
\begin{figure}[t]
    \centering
    \includegraphics[width=0.9\linewidth]{Figures/compare_distribution.pdf}
    \vspace{-0.1in}
    \caption{Magnitude pruning results in a more concentrated and unbalanced distribution of weights compare to random pruning.}
    \vspace{-0.2in}
    \label{fig:weight_distribution}
\end{figure}

\textbf{High Parameter Overlap.} By comparing the overlap rate between magnitude-based and random pruning methods, our analysis demonstrates that magnitude-based pruning results in a significantly higher parameter overlap between task vectors compared to random pruning methods. As shown in Figure~\ref{fig:weight_overlap}, although the overlap rate of magnitude-pruned task vectors decreases gradually with increasing sparsity, it remains significantly higher than that of randomly pruned vectors, especially at higher sparsity levels. This disparity highlights the key issue with magnitude-based pruning, where high overlap persists even as the model becomes sparser.

This elevated overlap in magnitude-pruned vectors introduces conflicts during model merging, as overlapping parameters may have significantly different magnitudes or signs between task vectors.
% ~\qbh{I am concerned that the definition of conflict (i.e., what is conflict) could be abstract, as there is only one sentence to illustrate it. is it possible to give a brief example to illustrate it (like an example for different signs)}. 
For example, if a parameter in task vector $\tau_A$ has a positive value indicating its importance to task A, but the same parameter in $\tau_B$ has a negative value, this sign conflict leads to opposing contributions when merging the two vectors.
These conflicts are particularly challenging because they are primarily controlled through scaling coefficients \(\lambda\), which serve as key parameters for determining the relative contributions of task vectors during merging.
Adjusting \(\lambda_A\) for \(\tau_A\) can inadvertently affect the contribution of \(\tau_B\), reducing the modelâ€™s ability to perform optimally on individual tasks and ultimately leading to suboptimal task-specific performance.
The performance implications of these overlapping parameters are explored in detail in~\ref{section-ablation_studies}. 
For details on how the overlap rate is calculated, please refer to Appendix~\ref{appendix:overlap_rate_calculation}.

\textbf{Unbalanced Weight Distribution.}
By visualizing the weight distribution shown in Figure~\ref{fig:weight_distribution}, we identified another critical issue: the unbalanced distribution of retained weights caused by magnitude-based pruning. Magnitude pruning often leads to weight concentration in specific regions of the model's weights. This imbalance is further exacerbated by the rescaling process, where certain weights gain disproportionate influence over the model's output, often resulting in suboptimal performance. This uneven distribution is particularly detrimental after sparsification, as it hampers the merged model's ability to generalize effectively. The performance implications of these unbalanced weights are discussed in detail in~\ref{section-ablation_studies}. 

To comprehensively analyze this issue, we further examined the weight distributions across different layers of the model, including the query-key-value (QKV) projection and MLP layers, at various sparsity levels (e.g., 50\%, 75\%, and 90\%). These experimental results are provided in Appendix~\ref{appendix:weight_distribution_analysis}, demonstrating the pervasive nature of the imbalance across different layers and sparsity levels.
