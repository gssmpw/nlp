% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
% Change to "preprint" to generate a non-anonymous version with page numbers.
\usepackage[preprint]{acl}


% Standard package includes
\usepackage{times}
\usepackage{latexsym}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}

\usepackage{enumitem}
\usepackage{amsmath, amsthm, amssymb}
\usepackage{amsfonts}
\usepackage{graphicx}
\usepackage{multirow}
\usepackage{multicol}
\usepackage{booktabs}
\usepackage{arydshln}
\usepackage{color}
\usepackage{makecell}
\usepackage{subcaption}
\usepackage{xcolor}[dvipsnames]
\usepackage{epigraph}

\usepackage{colortbl}
\definecolor{mygray}{gray}{.9}
\definecolor{mygreen}{rgb}{0,0.7,0}
\definecolor{myorange}{RGB}{255, 218, 185}
\definecolor{mycolor}{rgb}{0.8157, 0.251, 0.2196}

% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

\title{Revisiting Robust RAG: Do We Still Need Complex Robust Training \\ in the Era of Powerful LLMs?}

\author{Hanxing Ding$^{1,2}$\thanks{\ \ Equal contributions.}\quad
Shuchang Tao\footnotemark[1] \quad
Liang Pang$^{1}$\thanks{\ \ Corresponding author}\quad
Zihao Wei$^{1,2}$\quad\\
\textbf{Liwei Chen}$^{3}$\quad
\textbf{Kun Xu}\quad
\textbf{Huawei Shen}$^{1,2}$
\textbf{Xueqi Cheng}$^{1,2}$\\
 $^{1}$Key Laboratory of AI Safety, Institute of Computing Technology, Chinese Academy of Sciences \\
 $^{2}$ University of Chinese Academy of Sciences \quad $^{3}$ Kuaishou Technology \\
 \texttt{\{dinghanxing18s, pangliang, weizihao22z, shenhuawei, cxq\}@ict.ac.cn} \\
 % \texttt{\{taoshuchang.tsc, jinyang.gjy, bolin.ding\}@alibaba-inc.com}
}

\begin{document}
\maketitle
\begin{abstract}
Retrieval-augmented generation (RAG) systems often suffer from performance degradation when encountering noisy or irrelevant documents, driving researchers to develop sophisticated training strategies to enhance their robustness against such retrieval noise. However, as large language models (LLMs) continue to advance, the necessity of these complex training methods is increasingly questioned. In this paper, we systematically investigate whether complex robust training strategies remain necessary as model capacity grows. Through comprehensive experiments spanning multiple model architectures and parameter scales, we evaluate various document selection methods and adversarial training techniques across diverse datasets. Our extensive experiments consistently demonstrate that as models become more powerful, the performance gains brought by complex robust training methods drop off dramatically.  We delve into the rationale and find that more powerful models inherently exhibit superior confidence calibration, better generalization across datasets (even when trained with randomly selected documents), and optimal attention mechanisms learned with simpler strategies. Our findings suggest that RAG systems can benefit from simpler architectures and training strategies as models become more powerful, enabling more scalable applications with minimal complexity.
\end{abstract}

\setlength{\epigraphrule}{0pt}
\epigraph{\emph{"Entities should not be multiplied unnecessarily."}}{--- Occam's razor}

\input{sec/1_introduction}
% \input{sec/2_related_work}
\input{sec/2_background}
\input{sec/4_experimental_setup}
\input{sec/5_experimental_result}
\input{sec/6_experimental_analysis}
\input{sec/7_future_application}
\input{sec/7_conclusion}

\section*{Limitations}  
While our study provides valuable insights into the impact of adversarial loss functions and document selection strategies on RAG model robustness, several limitations remain. First, our analysis is restricted to dense transformer-based models, leaving the effectiveness of these techniques on sparse models, such as mixture-of-experts (MoE) architectures, unexplored. Future work could investigate whether similar trends hold for sparsely activated models with dynamic routing mechanisms. Second, although we analyze the effectiveness of adversarial training, we do not explicitly examine its long-term stability or convergence properties, which may vary depending on hyperparameter choices and optimization dynamics. Additionally, while we demonstrate that stronger models exhibit diminishing returns from adversarial losses and document selection strategies, the precise mechanisms behind this phenomenon remain unclear. Further research is needed to understand how model capacity interacts with retrieval robustness.

\section*{Ethics Statements}  
Our study focuses on improving the robustness of RAG models, but several ethical considerations must be acknowledged. First, while adversarial training enhances model reliability, it does not eliminate the risk of biased or misleading outputs, particularly when retrieval sources contain inherent biases or misinformation. Future work should explore fairness-aware adversarial training to mitigate potential harms. Second, our findings suggest that stronger models require less intervention in document selection and loss design, which may influence resource allocation in real-world applications. Researchers and practitioners should ensure that model improvements do not disproportionately benefit well-resourced institutions while leaving smaller models less robust. Lastly, our experiments are conducted on widely used benchmark datasets, which may not fully reflect the diversity of real-world information needs. We encourage further research on robustness evaluation across varied domains, including low-resource languages and specialized knowledge fields, to ensure equitable advancements in RAG technology.


\bibliography{anthology,custom}

% \clearpage
\appendix
\input{sec/8_appendix}

\end{document}
