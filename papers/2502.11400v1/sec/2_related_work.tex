\section{Related Work}
\subsection{Retrieval-Augmented Generation}
Retrieval-Augmented Generation (RAG) has been developed to enhance the reasoning and generation capabilities of LLMs by integrating external information. RAG improves the overall performance of LLMs by retrieving relevant documents that provide additional context and support for the generation process. However, dense retrievers are not always perfect and can sometimes recall irrelevant or erroneous documents, which can degrade performance~\cite{jiang-etal-2023-active,deng-etal-2023-regavae,DBLP:journals/corr/abs-2402-10612}. To mitigate this issue, adaptive retrieval techniques and robust RAG training methods have been proposed. Adaptive retrieval techniques retrieve external information only when LLMs encounter unknowns, reducing the risk of integrating misleading or incorrect information~\cite{jiang-etal-2023-active,mallen-etal-2023-trust,DBLP:journals/corr/abs-2310-11511}. Additionally, robust training focuses on enhancing LLMs' response to various retrieval noises, aiming to efficiently obtain adversarial examples that improve model robustness while reducing training overhead~\cite{fang-etal-2024-enhancing,zhu-etal-2024-atm,DBLP:journals/corr/abs-2405-15556}.

% jeong-etal-2024-adaptive

\subsection{Robust Training for RAG Systems}
The performance of LLMs in RAG systems can be compromised by irrelevant context~\cite{DBLP:conf/sigir/CuconasuTSFCMTS24,DBLP:journals/corr/abs-2408-13533}. Recently, researchers have focused on this issue and proposed effective adversarial training methods to enhance the robustness of LLMs against noisy documents. RetRobust~\cite{DBLP:conf/iclr/YoranWRB24} suggests using a mix of relevant and irrelevant documents to train LLMs to withstand noisy contexts. RAAT~\cite{fang-etal-2024-enhancing} and ATM~\cite{zhu-etal-2024-atm} employ adversarial training to dynamically adjust the model’s training process, aiming to maintain robustness against noise and generate accurate answers. RobustRAG~\cite{DBLP:journals/corr/abs-2405-15556} proposes to enhances RAG model robustness against retrieval corruption attacks through an isolate-then-aggregate strategy to achieve certifiable robustness. Additionally, there is a body of work focused on identifying key documents from noisy contexts to facilitate effective question answering through knowledge rewriting, refinement, or filtering~\cite{zhu-etal-2024-information,DBLP:journals/corr/abs-2406-08116,jin-etal-2024-bider,DBLP:journals/corr/abs-2411-14572}. However, these robust training approaches are primarily applied to small or weak LMs with fewer than 7 billion parameters. Thus, there’s an urgent need to explore whether complex robust training is still necessary to improve the robustness and generalization of bigger or stronger models when dealing with noisy contexts.