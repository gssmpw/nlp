%\section{Satisfying \texorpdfstring{$\Pi_{\texttt{edgeless}}$}{} on Interval Graphs}\label{sec:edg_interval}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Satisfying \texorpdfstring{$\Pi_{\texttt{edgeless}}$}{} on Unit Interval Graphs in \texorpdfstring{$O(n\log n)$}{} time}\label{sec:edg_uig}

We show that $\Pi_{\texttt{edgeless}}$ can be satisfied in $O(n\log n)$ time given a unit interval graph of $n$ intervals.
%In particular, we design an algorithm to disperse unit intervals by a distance $s \ge 1$.
We start by defining a problem that we call {\idisp} and then use the algorithm designed to satisfy the properties $\Pi_{\texttt{edgeless}}$, $\Pi_{\texttt{acyc}}$ and $\overline{\Pi_{k\texttt{-clique}}}$. %and $\Pi_{\texttt{bipar}}$. 
\ifConf
{\idisp} receives as input a collection $\I$ of $n$ intervals and a real $s \ge 1$, and asks for the minimum value of the total moving distance to obtain a collection $\I'$ that satisfies $c(I'_j)-c(I'_i) \ge s$ for each $I'_i, I'_j \in \I'$, $i<j$.
\fi
\ifFull
The problem is defined as follows:

\begin{itembox}[l]{\idisp}
    \begin{description}%[itemsep=0pt,align=left,leftmargin=50pt,labelindent=5pt,style=multiline]
        \item[Input:] A collection $\I$ of $n$ intervals and a real $s \ge 1$.
        \item[Output:] The minimum value of the total moving distance for obtaining a collection $\I'$ that satisfies $c(I'_j)-c(I'_i) \ge s$ for each $I'_i, I'_j \in \I'$, $i<j$.
    \end{description}
\end{itembox}
\fi
When $s = 1$, {\idisp} is equivalent to {\gged} on unit interval graphs for satisfying $\Pi_{\texttt{edgeless}}$.
%We assume that the intervals $I \in \I$ move over the $L_2$ distance. 
%Definitions-%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\paragraph*{Preliminaries} 
%
%For simplicity, it is assumed that intervals are open. This assumption helps to avoid dealing with the infinitesimal small distance needed to be applied to separate closed intervals. 
%
For simplicity, the intervals are assumed to be open. This avoids the need to address infinitesimally small distances required to separate closed intervals.
%
We must first introduce some basic definitions and notation to describe the algorithm.
Given a collection of $n$ intervals $\I= \set{I_1,\ldots,I_{n}}$, let $D = (d_1,\ldots,d_{n})$ be a vector such that $d_i$ is the moving distance applied to $I_i$. 
We denote by $\I^D = \{I^D_1\ldots, I^D_{n}\}$ the collection of intervals such that $c(I^D_i) = c(I_i) +d_i$.
The set $\D(\I) \subseteq \mathbb{R}^n$ is the set of vectors that describe the moving distance applied to intervals such that the condition of {\idisp} is satisfied. 
In other words, for all $D = (d_1,\ldots,d_n) \in \D(\I)$, $c(I^D_{j})+c(I^D_{i}) \ge s$ holds for $i < j$.
We use $\D^{\mathit{opt}}(\I) \subseteq \D(\I)$ to denote the subset of vectors in $\D(\I)$ that minimises the total moving distance applied to intervals; i.e. $\D^{\mathit{opt}}(\I) = \set{D=(d_1,\ldots,d_n) \in \D(\I)\mid \sum_{1\le i \le n} |d_i| = \min_{D' = (d'_1,\ldots,d'_n) \in \D(\I)}{\sum_{1\le i \le n}|d'_i|}}$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%We are now ready to introduce some properties used in the algorithm.
Intuitively, we aim to find a vector $D \in \D^{\mathit{opt}}(\I)$ to move each interval so that the distance between each pair of intervals is at least $s$.
Given an arbitrary $D \in \D^{\mathit{opt}}(\I)$, the order of $\I^D$ may be different from the order of $\I$.
However, it was previously shown~\cite{HonoratoDroguett2024} that the there are always a vector $D \in \D^{\mathit{opt}}(\I)$ such that the order of $\I^D$ preserves the order of $\I$.
%However, the following lemma ensures that the order of $\I$ does not change for an arbitrary property $\Pi$.
%
%\begin{mlemmarep}\label{lem:edgeless:same}
%    Let $D = (d_1, \ldots, d_n)$ be a vector that describes the distances applied to each unit interval.
%    If $\I$ has a pair of unit intervals $I$ and $J$ that satisfy $c(I) \le c(J)$ and $c(I) + d_i > c(J) + d_j$, then the same collection of unit intervals exists such that the total moving distance is at most $\sum_{d_i \in D} |d_i|$.
%\end{mlemmarep}
%\begin{proof}
%    Let $I$ and $J$ be two intervals in $\I$.
%    Without loss of generality, assume that $c(I) \le c(J)$.
%    Suppose that $c(I) + d_i \ge c(J) + d_j$.
%    Since $c(I) \le c(J)$, $d_i \ge d_j$.
%    In this case, by replacing $d_i$ and $d_j$ with $c(J) - c(I) + d_j$ and $c(I) - c(J) + d_i$,
%    we obtain $c(I) + (c(J) - c(I) + d_j) = c(J) + d_j$ and $c(J) + (c(I) - c(J) + d_i) = c(I) + d_i$, respectively.
%    Hence the collection of intervals is the same.
%
%    We show that $|d_i| + |d_j| \ge |c(I) - c(J) + d_i| + |c(J) - c(I) + d_j|$.
%    We consider the following cases.
%    Suppose that $d_i \ge c(J) - c(I)$.
%    In this case, $|c(I) - c(J) + d_i| = (c(I) - c(J) + d_i)$.
%    If $c(J) - c(I) + d_j \ge 0$, then
%    \begin{align*}
%        |c(I) - c(J) + d_i| + |c(J) - c(I) + d_j| = d_i + d_j \le |d_i| + |d_j|.
%    \end{align*}
%    If $c(J) - c(I) + d_j  <  0$, then
%    \begin{align*}
%        |c(I) - c(J) + d_i| + |c(J) - c(I) + d_j| = d_i - d_j + 2(c(I) - c(J)).
%    \end{align*}
%    Since $c(J) \ge c(I)$, $d_j < 0$.
%    Therefore, $|d_i| + |d_j| = d_i - d_j$ and $d_i - d_j \ge d_i - d_j + 2(c(I) - c(J))$.
%
%    Suppose that $d_i < c(J) - c(I)$.
%    If $c(J) - c(I) + d_j < 0$, then 
%    \begin{align*}
%        |c(I) - c(J) + d_i| + |c(J) - c(I) + d_j| = -d_i - d_j \le |d_i| + |d_j|.
%    \end{align*}
%    If $c(J) - c(I) + d_j \ge 0$, then 
%    \begin{align*}
%        |c(I) - c(J) + d_i| + |c(J) - c(I) + d_j| = 2(c(J) - c(I)) - d_i + d_j.
%    \end{align*}
%    Since $d_j \ge c(J) - c(I)$, $|d_i| + |d_j| = |d_i| - d_j$.
%    Therefore, 
%    \begin{align*}
%        |d_i| - d_j + 2(c(J) - c(I)) - d_i + d_j & = |d_i| - d_i + 2(c(J) - c(I)).
%    \end{align*}
%    If $d_i \ge 0$, then the statement is true since $|d_i| - d_i = 0$ and $c(J) \ge c(I)$.
%    If $d_i  <  0$, then $-2(d_i - (c(J) - c(I)))$.
%    Since $d_i < c(J) - c(I)$, $-2(d_i - (c(J) - c(I))) < 0$ holds.
%\end{proof}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%\Cref{lem:edgeless:same} 
This implies that there always exists an optimal solution of {\idisp} for which checking the inequality $(c(I_{i+1})+d_{i+1}) - (c(I_{i})+d_{i}) \ge s \text{ for } \leq i \leq n-1$ is sufficient.

%
%We now define a function to move intervals so that the distance between the centres is \emph{exactly} equal to $s$ following the order induced by the centre of intervals. We call this function \emph{equispace function}.
%
We now define the \emph{equispace function}, which moves intervals so that the distance between their centres is exactly $s$, maintaining the order induced by interval centres.
%
\begin{definition}[\textit{Equispace function}]\label{def:tmd_equispace}
    Let $(\I,s)$ be an instance of {\idisp} where $\I$ is a collection of unit intervals. The \emph{equispace function} of $\I$ to a point $x$ is a function $E: \I\times \mathbb{R} \rightarrow \mathbb{R}$ defined as:
    \begin{align*}
        E(\I,x) = \sum_{i = 1}^n f_i(x),\quad f_i(x) = |x-c(I_i) - (n-i)s|.
    \end{align*}
    The vector that describes the moving distances given by $E(\I,x)$ is defined as $E_x(\I) = (e_1,\ldots,e_n)= \left(\alpha_1 f_1(x),\ldots,\alpha_n f_n(x)\right)$ where $\alpha_i = 1$ if $x\ge c(I_i)+(n-i)s$ and $\alpha_i = -1$ otherwise, for $1\le i \le n$.
    We also denote by $\I^{E_x(\I)} = \{I^{E_x(\I)}_1\ldots, I^{E_x(\I)}_{n}\}$ the collection of intervals where $c(I^{E_x(\I)}_i) = c(I_i) +\alpha_if_i(x)$ for $1\le i \le n$.
\end{definition}
%\Cref{fig:equispace_function} illustrates the movement represented by the equispace function. In the figure, a collection $\I = \set{I_1,\ldots,I_6}$ is moved to the point $x$ by the equispace function. In particular, the interval $I_6$ is centred at $x$ and subsequent intervals are positioned behind $I_6$ such that the distance between consecutive intervals is exactly $s$, while maintaining the order of $\I$. 
%\begin{figure}[bt]
%    \centering
%    \includegraphics[scale=1,page=1]{tex/Dispersal/fig/dispersal.pdf}
%    \caption{Equispace function: A collection $\I = \set{I_1,\ldots,I_6}$ is moved to the point $x$ by the equispace function. After moving the intervals, the distance between consecutive intervals is exactly $s$.}
%    \label{fig:equispace_function}
%\end{figure}
By the above, $E_x(\I) \in \D(\I)$ for all $x \in \mathbb{R}$.
Moreover, $c(I^{E_x(\I)}_{i+1}) - c(I^{E_x(\I)}_{i}) = s$ for all $1 \le i \le n-1$.
%As we shall prove, the advantage of using the equispace function is that its optimal solution can be found efficiently.
We first prove that for certain collections of intervals, minimising $E$ gives a vector contained in $\D^{\mathit{opt}}(\I)$.
\begin{mlemmarep}\label{lem:tmd_convex}
    The equispace function $E(\I,x)$ is a piecewise-linear convex function.
\end{mlemmarep}
\begin{proof}
    By \Cref{def:tmd_equispace}, the function $E(\I,x)$ is a function of the form $f(x) = f_n(x)+\cdots+ f_1(x) = |x - c(I_n)| + |x - c(I_{n-1}) - s| + \cdots + |x - c(I_1) - (n-1)s|$. 
    The absolute function is convex; hence each $f_i$ is convex.
    Consequently, $f(x)$ is also convex as it is a sum of convex functions.
    On the other hand, the piecewise linearity of $E$ is given by the fact that each absolute function is piecewise linear.
    Therefore, $E$ is a piecewise-linear convex function.
\end{proof}

%Let $\I = \set{I_1,\ldots,I_n}$ be a collection of $n$ unit intervals. 
We define the \emph{set of breakpoints of $E(\I,x)$} to be the set $B_\I =\set{b_1^\I,\ldots,b_n^\I} = \set{c(I_i) + (n-i)s\mid I_i \in \I,\: 1\le i\le n}$.
Given a collection of intervals $\I$, we define the equispace function $E(\I, x)$ as a sequence of linear functions $E_1(\I, x), \ldots, E_{\size{\I}+1}(\I, x)$. 
The slope of $E_i(\I, x)$ is less than the slope of $E_j(\I, x)$ for $1 \le i < j \le \size{\I}$.
Since the equispace function is convex and piecewise linear, the points that minimise $E$ are located within a range $b_\ell \leq x \leq b_r$, where $b_{\ell} \le b_r$ and $b_\ell, b_r \in B_\I$.
We prove that $b_\ell$ and $b_r$ can be easily found.

\begin{mlemmarep}\label{lem:tmd_opt}
     %Given an arbitrary collection $\I$ of $n$ unit intervals, t
     The minimum value of $E(\I,x)$ is given by the breakpoint $b^{\I}_{(n+1)/2}$ if $n$ is odd, and by breakpoints $b^{\I}_{n/2}$ and $b^{\I}_{(n/2)+1}$ otherwise.
\end{mlemmarep}
\begin{proof}
    Let $s_i$ be the slope of $E_i(\I,x)$.
    The function $E(\I,x)$ is a function of the form $f_1(x)+\cdots+f_n(x)$ where $f_i(x) = |x-c(I_i) -(n-i)s|$.
    The slope of $f_i$ is equal to $1$ if $x\ge c(I_i) +(n-i)s$ and $-1$ otherwise, which implies that $s_i = -n + 2(i-1)$ for $1\le i \le n +1$ and thus $s_{i+1}-s_i = 2$ for $1\le i \le n$.
    Suppose first that $n$ is odd.
    Then, 
    \begin{align*}
        s_{(n+1)/2} & = -n + 2((n+1)/2 - 1) = -n +n+1 - 2 = -1\text{ and}\\ 
        s_{(n+1)/2 + 1} &= -n + 2((n+1)/2 + 1 - 1) = -n+n+1 = 1.
    \end{align*}
    Hence, it follows that the $((n+1)/2)$th breakpoint minimises $E$.
    Suppose that $n$ is even.
    In this case, we have that
    \begin{align*}
        s_{n/2} & = -n + 2(n/2 - 1) = -n +n - 2 = -2,\\ 
        s_{n/2 + 1} &= -n + 2(n/2 + 1 - 1) = -n+n = 0\text{ and},\\
        s_{n/2 + 2} &= -n + 2(n/2+2 - 1) = -n + n +4 -2 = 2.
    \end{align*}
    Hence, any point $x\in \mathbb{R}$ such that $b^{\I}_{n/2} \le x \le b^{\I}_{n/2+1}$ minimises $E$, implying that $b^{\I}_{n/2}$ and $b^{\I}_{(n/2)+1}$ also minimise $E$.
    This concludes the proof.
\end{proof}

By \Cref{lem:tmd_opt}, the minimum value of $E$ for an arbitrary collection of intervals $\I$ is given by the median value(s) of $B_{\I}$.
%
%We now show for which collections of intervals it is sufficient to minimise $E$ to find a vector in $\D^{\mathit{opt}}(\I)$. We characterise such collections as follows.
%
We now show which collections allow minimising $E$ to obtain a vector in $\D^{\mathit{opt}}(\I)$, characterised as follows:
%
\begin{definition}[\textit{Optimally Equispaceable Collections}]\label{def:equispace_collections}
    Given a collection of intervals $\I$, we say that $\I$ is \emph{optimally equispaceable} if there exists a $D \in \D^{\mathit{opt}}(\I)$ such that $D = E_{x^*}(\I)$ and $x^* \in \argmin_{x \in \mathbb{R}} E(\I,x)$. Equivalently, $\I$ is optimally equispaceable if $E_{x^*}(\I) \in \D^{\mathit{opt}}(\I)$ for all $x^* \in \argmin_{x \in \mathbb{R}} E(\I,x)$.
\end{definition}

\begin{lemma}\label{lem:partition_opt}
    Let $\I = \set{I_1,\ldots,I_n}$ be a collection of unit intervals such that $c(I_{i+1}) - c(I_{i}) \le s$ for $1\le i \le n-1$.
    %and $D = (d_1,\ldots,d_n) \in \D(\I)$. 
    Then $\I$ is optimally equispaceable.
    Moreover, there exists a $D \in \D^{\mathit{opt}}(\I)$ such that $c(I^D_{i+1}) -c(I^D_i) = s$ holds for all $1 \le i \le n-1$.
\end{lemma}
\begin{proof}
    We only prove the latter, as the existence of $D$ in $\D^{\mathit{opt}}(\I)$ directly implies the optimal equispaceability of $\I$.
    That is, we show that $\I^D$ satisfies $c(I^D_{i+1}) - c(I^D_i) = s$, for $1 \le i \le n-1$.
    By the definition of {\idisp}, we have $c(I^D_{i+1}) \ge c(I^D_{i})$ and $c(I^D_{i+1}) - c(I^D_{i}) \ge s$ for $1\le i \le n-1$.
    Suppose that there exists a pair of intervals $I_i$ and $I_{i+1}$ that satisfies $c(I^D_{i+1}) - c(I^D_{i}) > s$. 
    Let $s' = c(I^D_{i+1}) - c(I^D_{i})$ and $\delta = s'-s$.
    We show how to obtain a total moving distance $D'$ such that $\sum_{d\in D'} |d|< \sum_{d\in D} |d|$ and $c(I^{D'}_{i+1}) - c(I^{D'}_{i}) = s$.
    
    We divide the proof into three cases: (i) $d_i \ge 0$, (ii) $d_{i+1} \le 0$ and (iii) $d_i\le 0$ and $d_{i+1}\ge 0$. 
    For case (i), it follows that $d_j \ge d_{j-1}\ge 0$ for $i+1\le j \le n$ and $(c(I^D_{i+1})-\delta) - c(I^D_{i})  = c(I_{i+1})+(d_{i+1}-\delta) - (c(I_i) + d_i) = s$ holds.
    Let $D' (d'_1,\ldots,d'_n) = (d_1,\ldots,d_i,d_{i+1}-\delta,\ldots,d_{n}-\delta)$.
    The dispersal condition is satisfied by $\I^{D'}$.
    Furthermore, since $\delta > 0$, the total moving distance satisfies 
    $\sum_{d\in D'} |d| = \sum_{j=1}^i |d_j| + \sum_{j=i+1}^n d_j - \delta < \sum_{d\in D} |d|$, which contradicts the optimality of $D$.
    
    For case (ii), $d_j \le d_{j+1}$ for $1\le j \le i$ holds, and the argument for case (i) applies analogously for $D' = (d'_1,\ldots,d'_n) = (d_1+\delta,\ldots,d_i+\delta,d_{i+1},\ldots,d_{n})$.
    
    We only need to prove case (iii).
    Let $\delta = s' - s$ as in the previous cases.
    If $\delta \le d_{i+1}$, then we move the intervals as in the first case. If $\delta \le -d_{i}$, then we move intervals as in the second case. 
    In both cases, the same argument applies and the total moving distance contradicts the optimality of $D$.
    Thus we assume that $\delta > d_{i+1}, -d_i$ holds.
    Without loss of generality, we move intervals $I_j$ for $i+1\le j \le n$ by $d_{i+1}$ to the left by $\delta' = d_{i+1}$ and intervals $I_j$ for $1\le j \le i$ to the right by $\delta'' = (c(I^D_{i+1})-\delta')- c(I^D_i) - s$. 
    Then $(c(I^D_{i+1})-\delta') - (c(I^D_i) +\delta'') = s$ holds since $d_{i+1}-\delta' = 0$. 
    Let $D' = (d'_1,\ldots,d'_n) = (d_1+\delta'',\ldots,d_i+\delta'',d_{i+1}-\delta',\ldots,d_n-\delta')$. 
    The inequality $\sum_{d\in D'} |d| = \sum_{j=1}^i d_j+\delta'' + \sum_{j=i+1}^n d_j - \delta' < \sum_{d\in D} |d|$ holds since $\delta',\delta''>0$, which contradicts the optimality of $D$.
    Therefore, in an optimal solution, $\I$ must satisfy $c(I_{i+1})+d_{i+1} - (c(I_i) + d_i) = c(I^D_{i+1})-c(I^D_i) = s$, for $1 \le i \le n-1$.
\end{proof}

Let $\I = \set{I_1,\ldots,I_n}$ and $\J = \set{J_1,\ldots,J_m}$ be two collections of unit intervals and let $x_1,x_2\in \argmin_{x\in\mathbb{R}} E(\I,x)$, $x_1\le x_2$, and $y_1,y_2\in \argmin_{x\in\mathbb{R}} E(\J,x)$, $y_1\le y_2$, be the breakpoints that minimise $E$ for $\I$ and $\J$, respectively.
We say that \emph{$\I$ and $\J$ intersect when equispaced} when $y_1 \le x_2 + \size{\J}s$.
In other words, $\I$ and $\J$ intersect when equispaced whenever there exist points $x_1\le x \le x_2$ and $y_1 \le y \le y_2$ such that there exist $I \in \I^{E_x(\I)}$ and $I \in \J^{E_y(\J)}$ for which $c(J) - c(I) < s$.

\begin{mlemmarep}\label{lem:tmd_opt_of_opts}
    %Let $\I = \set{I_1,\ldots,I_n}$ and $\J = \set{J_1,\ldots,J_m}$ be two optimally equispaceable collections of intervals and let $x_1,x_2\in \argmin_{x\in\mathbb{R}} E(\I,x)$, $x_1\le x_2$, and $y_1,y_2\in \argmin_{x\in\mathbb{R}} E(\J,x)$, $y_1\le y_2$, be the (at most) two breakpoints that minimise $E$ for $\I$ and $\J$, respectively. 
    Given that $\I \cup \J = \set{I_1,\ldots,I_n,J_1,\ldots,J_m}$, $\I \cup \J$ is optimally equispaceable if and only if $y_1 \le x_2 + \size{\J}s$.
\end{mlemmarep}
\begin{proof}
    Let $\H = \I \cup \J = \set{I_1,\ldots,I_n,J_1,\ldots,J_m}= \set{I_1,\ldots,I_{n+m}}$ and assume that $\H$ optimally equispaceable.
    In other words, there exists a vector $D = (d_1,\ldots,d_{n+m}) \in \D^{\mathit{opt}}(\H)$ such that $c(I^D_{i+1}) - c(I^D_{i}) = s$ for $1\le i\le n+m-1$.
    Suppose first that $y_1 > x_2 + \size{\J} s$.
    We show that this assumption contradicts the optimality of the vector $D$.
    First, assume that $c(I^D_{n+m}) \ge y_1$.
    Then, it follows that $x_2 < c(I^D_n)$ since $c(I^D_{n+m}) - c(I^D_n) = \size{\J}s$.
    Moreover, $\sum_{i=1}^n |d_i| = E(\I,c(I^D_{n}))$ holds.
    By \Cref{lem:tmd_convex}, $E(\I,x_2) < E(\I,c(I^D_{n}))$ also holds, which contradicts the optimality of the vector $D$.
    Moreover, $c(I^D_{n+1})-x_2 >s$ holds, and hence the inequality $c(I^D_{i+1}) - c(I^D_{i}) = s$ fails when $i=n$.
    Suppose instead that $c(I^D_{n+m}) < y_1$.
    In this case, \Cref{lem:tmd_convex} tells us that $\sum_{i=n}^{n+m} |d_i| = E(\J,c(I^D_{n+m})) > E(\J,y_1)$, which contradicts the optimality of $D$.
    Moreover, if $\delta = c(I^D_{n+m})-y_1$ is the value with which $\J$ is moved from $c(I^D_{n+m})$ to $y_1$, then $(c(I_{n+1}) + \delta) - c(I^D_n) > s$ holds.
    Consequently, $c(I^D_{i+1}) - c(I^D_{i}) = s$ fails when $i = n$.
    In both cases, the initial assumption that $D$ is an optimal solution is contradicted.
    Therefore, $y_1 \le x_2 + \size{\J}s$ must hold.

    In the other direction, assume that $y_1 \le x_2 + \size{\J}s$.
    We show that $\I\cup \J$ is optimally equispaceable.
    That is, we prove the existence of a vector $D = (d_1,\ldots,d_{n+m}) \in \D^{\mathit{opt}}(\I\cup \J)$ such that $c(I^D_{i+1}) - c(I^D_{i}) = s$ for $1\le i\le n+m-1$.
    Let $D' = (d'_1,\ldots,d'_{n+m}) \in \D^{\mathit{opt}}(\I\cup \J)$ be a vector for which the inequality $c(I^D_{i+1}) - c(I^D_{i}) = s$ does not hold for an $1\le i \le n+m-1$.
    We know that $\I$ and $\J$ are optimally equispaceable, thus we can assume that $c(I^{D'}_{i+1}) - c(I^{D'}_{i}) = s$ fails for $D'$ when $i=n$ without loss of generality.
    Let $x = c(I^{D'}_n)$ and $y=c(I^{D'}_{n+m})$.
    We have $x\le x_2$, $y\ge y_1$, and $\sum_{i=1}^{n+m} |d'_i| = E(\I,x) + E(\J,y)$.
    We show that $\sum_{i=1}^{n+m} |d_i| \le \sum_{i=1}^{n+m} |d'_i|$ for all values of $x$ and $y$.
    
    First, suppose that $x = x_2$.
    We have that $y_1 \le x+\size{\J}s$ and $x+\size{\J}s \le y$, otherwise $I^{D'}_n$ intersects with $I^{D'}_{n+1}$.
    Moreover, $x+\size{\J}s < y$, otherwise $c(I^{D'}_{i+1}) - c(I^{D'}_{i}) = s$ holds when $i=n$.
    Hence $E(\J,x+\size{\J}s) \le E(\J,y)$ holds by \Cref{lem:tmd_convex}.
    If we set $(d_n,\ldots,d_{n+m}) = E_{x+\size{\J}s}(\J)$ and $(d_1,\ldots,d_n) = (d'_1,\ldots,d'_n)$, then $c(I^D_{i+1}) - c(I^D_{i}) = s$ and $\sum_{i=1}^{n+m} |d_i| \le \sum_{i=1}^{n+m} |d'_i|$ hold.

    Suppose now that $y = y_1$.
    Analogously, $x< y - \size{\J}s$, otherwise $I^{D'}_n$ intersects with $I^{D'}_{n+1}$ or $c(I^{D'}_{i+1}) - c(I^{D'}_{i}) = s$ holds when $i=n$.
    Again, $E(\J,y-\size{\J}s) \le E(\J,x)$ holds by \Cref{lem:tmd_convex}.
    If we set $(d_1,\ldots,d_n) = E_{y-\size{\J}s}(\I)$  and $(d_n,\ldots,d_{n+m}) = (d'_n,\ldots,d'_{n+m})$, then $c(I^D_{i+1}) - c(I^D_{i}) = s$ and $\sum_{i=1}^{n+m} |d_i| \le \sum_{i=1}^{n+m} |d'_i|$ hold.

    Lastly, suppose that $x<x_2$ and $y>y_1$.
    Let $x',y'$ be two arbitrary points such that $x\le x' \le x_2$, $y_1 \le y' \le y$ and $y' = x'+\size{\J}s$.
    These points exist since $y > x+\size{\J}s$ and $y_1 \le x_2+\size{\J}s$.
    If we set $(d_1,\ldots,d_n) = E_{x'}(\I)$ and $(d_n,\ldots,d_{n+m}) = E_{y'}(\J)$, then $\sum_{i=1}^{n+m} |d_i| \le \sum_{i=1}^{n+m} |d'_i|$ holds by \Cref{lem:tmd_convex}.
    Moreover, $c(I^D_{i+1}) - c(I^D_{i}) = s$ also holds since $y' = x' +\size{\J}s$. %by the definition of $x'$ and $y'$.
    
    In all cases, we obtained a vector $D = (d_1,\ldots,d_{n+m})$ in $\D^{\mathit{opt}}(\I)$ such that $c(I^D_{i+1}) - c(I^D_{i}) = s$ for $1\le i\le n+m-1$.
    Consequently there exists a $D \in \D^{\mathit{opt}}(\I\cup \J)$ such that $D = E_{x^*}(\I\cup \J)$ and $x^* \in \argmin_{x \in \mathbb{R}} E(\I\cup\J,x)$.
    Therefore, $\I \cup \J$ is optimally equispaceable if and only if $y_1 \le x_2 + \size{\J}s$.
\end{proof}

\Cref{cor:tmd_opt_no_intersect} is directly implied by \Cref{lem:tmd_opt_of_opts}.

\begin{corollary}\label{cor:tmd_opt_no_intersect}
    %Let $\I = \set{I_1,\ldots,I_n}$ and $\J = \set{J_1,\ldots,J_m}$ be two optimally equispaceable collections of intervals and let $x_1,x_2\in \argmin_{x\in\mathbb{R}} E(\I,x)$, $x_1\le x_2$, and $y_1,y_2\in \argmin_{x\in\mathbb{R}} E(\J,x)$, $y_1\le y_2$, be the (at most) two breakpoints that minimise $E$ for $\I$ and $\J$, respectively. 
    If $y_1 > x_2 + \size{\J} s$, then $\I \cup \J$ is not optimally equispaceable.
    Moreover, the minimum total moving distance for dispersing $\I \cup \J$ is equal to $E(\I,x) + E(\J,y)$ for arbitrary $x_1\le x\le x_2$ and $y_1\le y\le y_2$.
\end{corollary}

Given a collection $\I$ of $n$ unit intervals, we note that $\I$ can be partitioned into $m\le n$ subcollections $\I_{a_1,b_1},\ldots,\I_{a_{m},b_{m}}$ such that for all $1\le i \le m$, $c(I_{j+1})-c(I_{j}) \le s$ for $a_i \le j \le b_i -1$.
By \Cref{lem:partition_opt}, each $\I_{a_i,b_i}$ is an optimally equispaceable collection.
We use \Cref{lem:tmd_opt_of_opts} and prove the statement of \Cref{lem:consec_partition_opt}.

\begin{mlemmarep}\label{lem:consec_partition_opt}
    Let $\I = \set{I_1,\ldots,I_n} = \I_{a_1,b_1}\cup\cdots\cup\I_{a_{m},b_{m}}$ be a collection of $n$ unit intervals partitioned as above.
    %Let $\I$ be a collection of $n$ unit intervals partitioned into $m\le n$ subcollections $\I_{a_1,b_1},\ldots,\I_{a_{m},b_{m}}$ such that for all $1\le i \le m$, $c(I_{j+1})-c(I_{j}) \le s$ for $a_i \le j \le b_i -1$.
    %Let $\S= \C_{a_1,b_1},\ldots,\C_{a_{m},b_{m}}$ be a family of $m$ consecutive clusters. 
    If there exist integers $\alpha_1, \ldots, \alpha_k$ such that $\I_{a_{\alpha_i},b_{\alpha_i}}$ and $\I_{a_{\alpha_i + 1},b_{\alpha_i + 1}}$ intersect when equispaced,
    then there exists an optimal solution for dispersing $\I$ that disperses the intervals in a way that $c(I_{j+1})+d_{j+1} - (c(I_j) + d_j) = s$ holds for $1 \le i \le k$ and $a_{\alpha_i} \le j < b_{\alpha_i + 1}$.
\end{mlemmarep}
\begin{proof}
    Consider the subcollections $\I_{a_{\alpha_{i}},b_{\alpha_{i}}}$ and $\I_{a_{\alpha_{i}+1},b_{\alpha_{i}+1}}$.
    These subcollections intersect when equispaced, hence $\I_{a_{\alpha_{i}},b_{\alpha_{i}}} \cup \I_{a_{\alpha_{i}+1},b_{\alpha_{i}+1}}$ is optimally equispaceable by \Cref{lem:tmd_opt_of_opts}.
    %Let $L_{x^*}$ be the vector given by $D(\C_{a_{\alpha_{i}},b_{\alpha_{i}}} \cup \C_{a_{\alpha_{i}+1},b_{\alpha_{i}+1}},x^*)$, where $x^* \in \argmin_{x\in\mathbb{R}} D(\C_{a_{\alpha_{i}},b_{\alpha_{i}}} \cup \C_{a_{\alpha_{i}+1},b_{\alpha_{i}+1}},x)$.
    Let $D^* \in \D^{\mathit{opt}}(\I_{a_{\alpha_{i}},b_{\alpha_{i}}} \cup \I_{a_{\alpha_{i}+1},b_{\alpha_{i}+1}})$.
    By the definition of $E$, we have that $c(I^{D^*}_{j+1}) - c(I^{D^*}_{j}) = s$ holds for $a_{\alpha_i} \le j < b_{\alpha_i + 1}$, which implies that the intervals are dispersed such that $c(I_{j+1})+d_{j+1} - \left(c(I_j) + d_j\right) = s$ holds for $1 \le i \le k$ and $a_{\alpha_i} \le j < b_{\alpha_i + 1}$.
    We only need to show that this dispersal is part of an optimal solution for dispersing $\I$.
    Without loss of generality, suppose that $\I_{a_{\alpha_{i}},b_{\alpha_{i}}} \cup \I_{a_{\alpha_{i}+1},b_{\alpha_{i}+1}}$ and $\I_{a_{\alpha_{i}+2},b_{\alpha_{i}+2}}$ intersect when equispaced. 
    Then, \Cref{lem:tmd_opt_of_opts} ensures that $\I_{a_{\alpha_{i}},b_{\alpha_{i}}} \cup \I_{a_{\alpha_{i}+1},b_{\alpha_{i}+1}} \cup \I_{a_{\alpha_{i}+2},b_{\alpha_{i}+2}}$ is optimally equispaceable.
    Applying \Cref{lem:tmd_opt_of_opts} recursively results in $k\le m$ partitions of $\I = \I_1,\ldots,\I_k$, where each $\I_i$ is dispersed to a point $x_i \in \argmin_{x\in \mathbb{R}} E(\I_i,x)$ and there exists no pair $\I_i,\I_{j}$, $i\neq j$, such that $\I_i$ and $\I_j$ intersect when equispaced.
    Moreover, the minimum total moving distance is given by $\sum_{i=1}^k E(\I_i,x_i)$ by \Cref{cor:tmd_opt_no_intersect}.
    In other words, $(x_1,\ldots,x_k)$ describes an optimal solution to disperse $\I$.
    Therefore, there exists an optimal solution to disperse $\I$ that disperses the intervals in a way that $c(I_{j+1})+d_{j+1} - \left(c(I_j) + d_j\right) = s$ holds for $1 \le i \le k$ and $a_{\alpha_i} \le j < b_{\alpha_i + 1}$.
\end{proof}

\paragraph*{Outline of \Cref{alg:dispersing-intervals}} 
%We are now ready to show the outline of the algorithm, illustrated in .
Given a collection of unit intervals $\I$ and a dispersal value $s\ge1$, the algorithm starts by sorting and partitioning $\I$ into $m\le n$ disjoint subcollections $\I_{a_1,b_1},\ldots,\I_{a_{m},b_{m}}$ such that each $\I_{a_{i},b_{i}}$ satisfies \Cref{lem:partition_opt}.
Subsequently, the optimal breakpoints are determined for each $E(\I_{a_{i},b_{i}},x)$.
Whenever there exist two subcollections $\I_{a_{i},b_{j}},\:i\le j$ and $\I_{a_{k},b_{\ell}},\:k\le \ell$ that intersect when equispaced, the algorithm considers both subcollections as a unique subcollection $\I_{a_i,b_{\ell}} = \I_{a_i,b_{j}} \cup \I_{a_k,b_{\ell}}$ and recursively determines the optimal breakpoints of $E(\I_{a_i,b_{\ell}},x)$ using the breakpoint sets of $E(\I_{a_i,b_{j}},x)$ and $E(\I_{a_k,b_{\ell}},x)$.
%
%It is ensured by \Cref{lem:consec_partition_opt} that this recursion gives a partition of $\I$ where each pair of subcollections does not intersect when equispaced.
%
\Cref{lem:consec_partition_opt} ensures that this recursion partitions $\I$ into non-intersecting subcollections when equispaced.
%
Lastly, the algorithm returns the total moving distance, which is calculated as the sum of the optimal values of $E$ for each subcollection.
%The \Cref{fig:alg_edg_outline} illustrates the overview of the algorithm for a collection $\I = \I_{1,2}\cup \I_{3,5}\cup \I_{6,8}$.
%After dispersing each subcollection using $E$, $\I_{1,2}$ and $\I_{3,5}$ intersect when equispaced. Hence, the subcollection $\I_{1,5} = \I_{1,2}\cup \I_{3,5}$ is obtained and the optimal breakpoints of $E(\I_{1,5},x)$ are determined. The optimal breakpoints of $E(\I_{1,5},x)$ and $E(\I_{6,8},x)$ give the solution to disperse $\I$ with minimum total moving distance.

%\begin{figure}[bt]
%    \centering
%    \includegraphics[scale=1,page=2]{tex/Dispersal/fig/dispersal.pdf}
%    \caption{Overview of the algorithm: (a) The given collection $I$ is partitioned into three sets $\I = \I_{1,2}$, $ \I_{3,5}$ and $\I_{6,8}$ according to \Cref{lem:partition_opt}; (b) The movement is represented by moving each subcollection to its optimal breakpoint using $E$. The subcollections $\I_{1,2}$ and $\I_{3,5}$ intersect when equispaced; (c) The subcollections $\I_{1,2}$ and $\I_{3,5}$ are merged and then the optimal breakpoints of $E(\I_{1,5},x)$ are determined. The resulting collection is dispersed with minimum total moving distance.}
%    \label{fig:alg_edg_outline}
%\end{figure}

Before showing the complexity of the algorithm, we must characterise the set of breakpoints further.
%Given a collection of unit intervals $\I =\set{I_1,\ldots,I_n}$, 
%observe that the set of breakpoints of $E(\I,x)$ is equal to $B_\I = \set{c(I_i)+(n-i)s\mid I_i\in \I,\:1\le i \le n}$.
When a collection of unit intervals $\I =\set{I_1,\ldots,I_n}$ is partitioned into $m$ disjoint subcollections $\I_{a_1,b_1},\ldots,\I_{a_{m},b_{m}}$ of intervals that satisfy \Cref{lem:partition_opt}, %the set of breakpoints $B_{\I}$ can be reformulated as
%\begin{align*}
%B_\I = \set{& c(I_1)+(\size{\I_{a_1,b_1}}+\cdots+\size{\I_{a_m,b_m}}-1)s,\ldots,\\
%& c(I_{a_i})+(\size{\I_{a_{i},b_{i}}}+\cdots+\size{\I_{a_m,b_m}}-1)s,\ldots,c(I_n)}.
%\end{align*}
%On the other hand, 
the set of breakpoints $B_{\I_{a_i,b_i}}$ is equal to $\set{c(I_j)+(\size{\I_{a_i,b_i}}-j)s\mid I_i\in \I,\:a_i\le j \le b_i}$ for each $1\le i \le m$.
%\begin{align*}
%B_{\I_{a_i,b_i}}& = \set{c(I_{a_i})+(\size{\I_{a_i,b_i}}-1)s,c(I_{a_{i+1}})+(\size{\I_{a_i,b_i}}-2)s,\ldots,c(I_{b_i})}\\
%&= \set{c(I_j)+(\size{\I_{a_i,b_i}}-j)s\mid I_i\in \I,\:a_i\le j \le b_i},  
%\end{align*}
%for each $1\le i \le m$.
Consequently, $B_\I$ can be reformulated as follows:
%\[
\begin{gather*}
    B_\I = \left\{c(I_j) + \left(\size{\I_{a_i,b_i}}-j + \sum_{k=i+1}^m \size{\I_{a_k,b_k}}\right)s\mid 1\le i \le m,\: a_i\le j \le b_i\right\}.
\end{gather*}
%\]
%By the above, if the index $i$ of the subcollection of an interval $I\in \I_i$ used to calculate a breakpoint $b$ of $B_\I$ is known, the value of the breakpoint $b'$ of $I$ in $B_{\I_{a_i,b_i}}$ can be directly calculated from $B_\I$. 
As a result, if $b$ and $b'$ are the breakpoints for $I$ in $B_{\I_{a_i,b_i}}$ and $B_\I$, respectively, then $b' = b -\sum_{j=i+1}^m \size{\I_{a_j,b_j}}$ holds. 
Moreover, the breakpoints of any union of subcollections $\I_{a_i,b_j} = \I_{a_i,b_i}\cup\cdots\cup\I_{a_j,b_j}$ can be calculated in the same way by subtracting $\sum_{k=j+1}^m \size{\I_{a_k,b_k}}$ from any breakpoint $b\in B_\I$ calculated using an interval $I \in \I_{a_i,b_j}$.
It follows that the order of $B_{\I_{a_i,b_j}}$ is the same as the order of the corresponding breakpoints in $B_\I$.

The above implies that the breakpoints of any (union of) subcollection(s) can be obtained from $B_\I$.
We denote the set $\bigcup_{i\le k \le j}\left\{b+s\sum_{l=k+1}^m \size{\I_{a_l,b_l}}\mid b \in B_{\I_{a_k,b_k}}\right\}$ by $B^*_{\I_{a_i,b_j}}$ and call it the \emph{cumulative set of breakpoints of $B_{\I_{a_i,b_j}}$}.
%In other words, $B^*_{\I_{a_i,b_j}}$ is simply the subset of elements of $B_\I$ that correspond to elements of $B_{\I_{a_i,b_j}}$.
We prove that $B^*_{\I_{a_1,b_1}},\ldots,B^*_{\I_{a_m,b_m}}$ can be found in $O(n\log n)$ time.

%\setlength{\intextsep}{1\baselineskip}
%\DontPrintSemicolon
\begin{algorithm}[tb]
    \caption{Dispersing $n$ unit intervals in $O(n\log n)$ time.}
    \label{alg:dispersing-intervals}
    \Procedure{\rm{DispersingIntervals}($\I$,$s$)}{
        Sort and partition $\I$ into $m\le n$ subcollections $\I_{a_1,b_1},\ldots,\I_{a_{m},b_{m}}$ such that for all $1\le i \le m$, $c(I_{j+1})-c(I_{j}) \le s$ for $a_i \le j \le b_i -1$.\;\nllabel{alg:disp-sort}
        Compute and sort $B^*_{\I_{a_i,b_i}}$ for all $1\le i \le n$.\;\nllabel{alg:breakpoint_sort}
        $x^1_{a_i,b_{i}},x^2_{a_i,b_{i}}$ are the breakpoint $b^{\I_{a_i,b_{i}}}_{(n+1)/2}$ if $\size{\I_{a_i,b_{i}}}$ is odd and $b^{\I_{a_i,b_{i}}}_{n/2}$ and $b^{\I_{a_i,b_{i}}}_{(n/2)+1}$ otherwise.\;\nllabel{alg:breakpoint_1}
        $D^{\mathit{opt}} \gets \bigcup_{1\le i \le n} \set{(B^*_{\I_{a_i,b_i}},x^1_{a_i,b_{i}},x^2_{a_i,b_{i}})}$\;
        \While{$x^1_{a_{k},b_{\ell}}\le x^2_{a_{i},b_{j}}+\size{\I_{a_{k},b_{\ell}}}s$, $1\le i\le j < k\le \ell \le n$}{\nllabel{alg:disp-while}
            %$\I_{a_i,b_{\ell}} \gets \I_{a_i,b_{j}} \cup \I_{a_k,b_{\ell}}$\;
            $B^*_{\I_{a_i,b_l}} \gets \mathit{merge}(B^*_{\I_{a_i,b_j}},B^*_{\I_{a_k,b_\ell}})$\;\nllabel{alg:merge}
            $x^1_{a_i,b_{\ell}}, x^2_{a_i,b_{\ell}} \gets b^{\I_{a_i,b_{\ell}}}_{(n+1)/2}$ if $\size{B^*_{\I_{a_i,b_{\ell}}}}$ is odd and $x^1_{a_i,b_{\ell}} \gets b^{\I_{a_i,b_{\ell}}}_{n/2}$,  $x^2_{a_i,b_{\ell}} \gets b^{\I_{a_i,b_{\ell}}}_{(n/2)+1}$ otherwise.\;
            $D^{\mathit{opt}} \gets \left(D^{\mathit{opt}} \setminus \left\{(B^*_{\I_{a_i,b_j}},x^1_{a_i,b_{j}},x^2_{a_i,b_{j}}),(B^*_{\I_{a_k,b_l}},x^1_{a_k,b_{\ell}},x^2_{a_k,b_{\ell}})\right\}\right) \cup \left\{(B^*_{\I_{a_i,b_\ell}},x^1_{a_i,b_{\ell}},x^2_{a_i,b_{\ell}})\right\}$\;\nllabel{alg:add_delete}
        }
        \Return $\sum_{(B^*_{\I_{a_i,b_j}},x_1,x_2) \in D^{\mathit{opt}}} E(\I_{a_i,b_i}\cup\cdots\cup \I_{a_j,b_j},x_1)$\;\nllabel{alg:disp_tmd_calc}
    }
\end{algorithm}

\begin{mlemmarep}\label{lem:breakpoint_sort}
    Let $\I = \set{I_1,\ldots,I_n} = \I_{a_1,b_1}\cup\cdots\cup\I_{a_{m},b_{m}}$ be a collection of $n$ unit intervals partitioned as above. %If $\I$ is 
    %sorted by centres of intervals and 
    %partitioned into $m\le n$ subcollections $\I_{a_1,b_1},\ldots,\I_{a_{m},b_{m}}$ such that for all $1\le i \le m$, $c(I_{j+1})-c(I_{j}) \le s$ for $a_i \le j \le b_i -1$, 
    Then the cumulative sets of breakpoints $\B^*_{\I_{a_1,b_1}},\ldots,\B^*_{\I_{a_m,b_m}}$ such that each $B^*_{\I_{a_i,b_i}}$ is sorted can be obtained in $O(n\log n)$ total time.
\end{mlemmarep}
\begin{proof}
    Let $n_i$ be the size $\size{\I_{a_i,b_i}}$ and $n_{i,j}$ be the cumulative sum of sizes $n_i+\cdots+n_j$, for $i\le j$.
    We observe that $n_1+\cdots+n_m = n$ since the given partitions are disjoint.
    We first determine $n_{i,m}$ for each $2\le i \le m$ in $O(m)$ time.
    For each $1\le i \le m$, we compute $\B^*_{\I_{a_i,b_i}} = \set{c(I_j)+(n_i-j + n_{i+1,m})s\mid a_i\le j \le b_i}$ in $O(n_i)$ time.
    The total running time of this procedure is $O(n_1+\cdots+n_m) = O(n)$ time.
    We then sort $B^*_{\I_{a_i,b_i}}$ for each $1\le i \le m$ in $O(n_i \log n_i)$ time. The total running time $T(n_1,\ldots,n_m)$ is given as follows:
    \begin{align*}
        T(n_1,\ldots,n_m) & = n_1 \log n_1 + \cdots + n_m\log n_m\le n_1\log{n} + \cdots +n_m\log{n}\\
        &= (n_1+\cdots+n_m)\log{n}= n \log{n}.
    \end{align*}
    Therefore, obtaining sets $\B^*_{\I_{a_1,b_1}},\ldots,\B^*_{\I_{a_m,b_m}}$ such that each $\B^*_{\I_{a_i,b_i}}$ is sorted can be done in $O(n\log n)$ total time.
\end{proof}
\begin{mlemmarep}\label{lem:total_merge_complexity}
    Let $\I = \set{I_1,\ldots,I_n} = \I_{a_1,b_1}\cup\cdots\cup\I_{a_{m},b_{m}}$ be a collection of $n$ unit intervals partitioned as above.
    %Let $\I = \set{I_1,\ldots,I_n}$ be a collection of $n$ unit intervals partitioned into $m\le n$ disjoint subcollections $\I_{a_1,b_1},\ldots,\I_{a_{m},b_{m}}$ such that for all $1\le i \le m$, $c(I_{j+1})-c(I_{j}) \le s$ for $a_i \le j \le b_i -1$.
    If cumulative breakpoint sets $B^*_{\I_{a_1,b_1}},\ldots,B^*_{\I_{a_m,b_m}}$ are given so that each $B^*_{\I_{a_i,b_i}}$ is sorted, then merging them into one sorted set can be done in $O(n\log n)$ total time.
\end{mlemmarep}
\begin{proof}
    We proceed using an unbalanced merge sort approach.
    Given two sorted sets $A$ and $B$ of numbers, it is known that $A$ and $B$ can be merged into one sorted set in $O(\size{A} \log{(\size{B}/\size{A})})$ time, assuming that $\size{A}\le \size{B}$~\cite{Brown1979}.
    We use this algorithm and show that the sets $B^*_{\I_{a_1,b_1}},\ldots,B^*_{\I_{a_m,b_m}}$ can be merged in $O(n \log n)$ total time.
    Let $n_i$ be the size $\size{\I_{a_i,b_i}}$ and $n_{i,j}$, $i\le j$, be the cumulative sum of sizes $n_i+\cdots+n_j$.
    We prove the lemma by induction on $m$.
    Given $m = 1$, no sort is performed since each $B^*_{\I_{a_i,b_i}}$ is already sorted, implying that the time is bounded by $n \log n$.
    Thus, we assume that the lemma holds for $1 < p \le m -1$ sets and prove that it also holds for $p = m$.
    Without loss of generality, assume that the merging of $B^*_{\I_{a_1,b_1}},\ldots,B^*_{\I_{a_m,b_m}}$ is done by merging two already merged sets $B^*_{\I_{a_1,b_i}} = B^*_{\I_{a_1,b_1}}\cup \cdots\cup B^*_{\I_{a_i,b_i}}$ and $B^*_{\I_{a_{i+1},b_m}} = B^*_{\I_{a_{i+1},b_{i+1}}}\cup \cdots \cup B^*_{\I_{a_m,b_m}}$, for an arbitrary $1\le i \le m-1$.
    Thus, we have $\size{B^*_{\I_{a_1,b_i}}},\size{B^*_{\I_{a_{i+1},b_m}}}\le m-1$ and $n = n_{1,i} + n_{i+1,m}$.
    Let $T(a,b)$ denote the number of steps necessary to merge two sets of size $a$ and $b$, $n_{1,i}$ be $ n_{1,j}+n_{j+1,i}$ and $n_{i+1,m}$ be $n_{i+1,k}+n_{k+1,m}$ for arbitrary $1\le j \le i$ and $i+1\le k \le m$.
    Without loss of generality, assume that $n_{1,i} \le n_{i+1,m}$.
    The value of $T(n_{1,i},n_{i+1,m})$ is bounded as follows:
    \begin{align*}
    T(n_{1,i}&,n_{i+1,m}) =\\
    & = T(n_{1,j},n_{j+1,i})+T(n_{i+1,k},n_{k+1,m}) + n_{1,i} \log{(n_{i+1,m}/n_{1,i})}\\
    & \le n_{1,i} \log n_{1,i} + n_{i+1,m} \log n_{i+1,m} + n_{1,i} \log{(n_{i+1,m}/n_{1,i})} & \text{(IH)}\\
    & = n_{1,i} \log n_{1,i} + n_{i+1,m} \log n_{i+1,m} + n_{1,i}\log{n_{i+1,m}} - n_{1,i} \log{n_{1,i}}\\
    & = n_{i+1,m} \log n_{i+1,m} + n_{1,i}\log{n_{i+1,m}}= (n_{1,i} + n_{i+1,m})\log{n_{i+1,m}}\\
    & \le n\log n.
    \end{align*}
    We have proved that if the lemma is true for $p \le m -1$ sets, then the lemma is also true for $p =m$.
    This concludes the induction and lemma proof.
\end{proof}
%\ifConf
%\begin{proofsketch}
    %We proceed using an unbalanced merge sort approach.
%    Given two sorted sets $A$ and $B$ of numbers, it is known that $A$ and $B$ can be merged into one sorted set in $O(\size{A} \log{(\size{B}/\size{A})})$ time, assuming that $\size{A}\le \size{B}$~\cite{Brown1979}.
%    We prove that this procedure allows us to merge the $m$ sets $B^*_{\I_{a_1,b_1}},\ldots,B^*_{\I_{a_m,b_m}}$ in total time $O(n\log n)$ time.
%\end{proofsketch}
%\fi

\begin{theorem}\label{thm:interval_dispersion}
    Given a collection of unit intervals $\I$ and a value $s\ge 1$, {\idisp} can be solved in $O(n\log n)$ time.
\end{theorem}
\begin{proof}
    We show the complexity of \Cref{alg:dispersing-intervals}. 
    Line~\ref{alg:disp-sort} can be done in $O(n\log n)$ time for sorting and $O(n)$ time to determine the initial $m$ partitions.
    Similarly, line~\ref{alg:breakpoint_sort} can be done in $O(n\log n)$ time by \Cref{lem:breakpoint_sort}.
    Given that each $\B^*_{\I_{a_i,b_i}}$ is sorted, the $((\size{\I_{a_i,b_i}}+1)/2)$th element (resp. $(\size{\I_{a_i,b_i}}/2)$th and $((\size{\I_{a_i,b_i}}/2)+1)$th element) can be calculated in $O(\log \size{\I_{a_i,b_i}})$ time using binary search on $\B^*_{\I_{a_i,b_i}}$.
    This ensures that line~\ref{alg:breakpoint_1} is done for all $1\le i \le m$ in $O(m\log n)$ total time.
    %The values of \cref{alg:disp-indp} can be calculated in $O(n)$ time by using the breakpoints obtained in the previous step.
    We initialise $D^{\mathit{opt}}$ as a doubly linked list where each node $i$ contains the information of $(B^*_{\I_{a_i,b_i}},x^1_{a_i,b_{i}},x^2_{a_i,b_{i}})$.
    We show the complexity of the loop in line~\ref{alg:disp-while}.
    We merge both $B^*_{\I_{a_i,b_j}}$ and $B^*_{\I_{a_k,b_\ell}}$ to obtain a sorted $B^*_{\I_{a_i,b_\ell}}$.
    Hence, the median value(s) of $B^*_{\I_{a_i,b_\ell}}$ can be calculated in $O(\log n)$ time by binary search.
    At each execution of line~\ref{alg:merge}, two partitions are merged; thus the number of partitions is reduced by one unit at each iteration.
    Initially, there exist $m$ partitions, and hence the loop of line~\ref{alg:disp-while} iterates at most $m-1$ times.
    Moreover, merging $m$ cumulative sets of breakpoints into one sorted set can be done in $O(n\log n)$ time by \Cref{lem:total_merge_complexity}, which implies that any partial merge of these sets is also bounded by $O(n\log n)$.
    Consequently, the total running time of line~\ref{alg:disp-while} is $O(n\log n)$ time.
    Lastly, in line~\ref{alg:add_delete} the two merged sets are deleted and the new one is added. 
    Since $D^{\mathit{opt}}$ is a doubly linked list, this can be done in $O(1)$ time by connecting the previous and next node of $B^*_{\I_{a_i,b_j}}$ and $B^*_{\I_{a_k,b_\ell}}$ to a new node containing $B^*_{\I_{a_i,b_\ell}}$, respectively.
    Once there is no pair of subcollections left to merge, the total moving distance is calculated in $O(n)$ time in line~\ref{alg:disp_tmd_calc} following the definition of cumulative set of breakpoints, which concludes that the total running time of \Cref{alg:dispersing-intervals} is $O(n\log n)$ time.
\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\Cref{thm:interval_dispersion} implies the following result for satisfying $\Pi_{\texttt{edgeless}}$ on unit interval graphs when $s=1$.

\begin{mcorollaryrep}
    Given a unit interval graph $(G,\I)$, {\gged} can be solved in $O(n\log n)$ time for satisfying $\Pi_{\texttt{edgeless}}$.
    %Given a collection of unit intervals $\I$, a solution where the total moving distance is minimum can be found in $O(n\log n)$ time for satisfying $\Pi_{\texttt{edgeless}}$.
\end{mcorollaryrep}
\begin{proof}
    %Let $\I = \{I_1,\ldots,I_n\}$ be a unit interval graph. 
    If $G$ is edgeless, then there exists an optimal solution that satisfies $c(I_{i+1}) - c(I_i) \ge 1$ for $1\le i \le n-1$. %by \Cref{lem:edgeless:same}. 
    Dispersing the intervals using $s = 1$ results in intervals separated by a distance of at least one unit. 
    That is, the resulting unit interval graph satisfies the edgeless condition. Therefore, \Cref{thm:interval_dispersion} works for satisfying $\Pi_{\texttt{edgeless}}$ on unit intervals graphs when $s=1$. 
\end{proof}

\subsection{Satisfying \texorpdfstring{$\Pi_{\texttt{acyc}}$}{} and \texorpdfstring{$\overline{\Pi_{k\texttt{-clique}}}$}{} on Unit Interval Graphs}
\label{ssec:acyc_kclique_uig}

This section shows how to use \Cref{alg:dispersing-intervals} for satisfying $\Pi_{\texttt{acyc}}$ and $\overline{\Pi_{k\texttt{-clique}}}$ on unit interval graphs. 
%A unit interval graph $(G,\I)$ is acyclic if the following inequality holds: $c(I_{i+2}) - c(I_i) \ge 1,\: 1\le i \le n-2$.
%Let $\I_{\texttt{odd}} = \{I_i \in \I\mid i\pmod{2} \neq 0 \}$ and $\I_{\texttt{even}} = \{I_i \in \I\mid i\pmod{2} = 0 \}$. It follows that $\I = \I_{\texttt{odd}}\,\cup\,\I_{\texttt{even}}$. The above inequality can be decomposed into the inequalities
%\begin{gather*}
%    $c(I_{i+2}) - c(I_i) \ge 1,\: 1\le i \le n-2,\: i\bmod{2} \neq 0$ and 
%    $c(I_{i+2}) - c(I_i) \ge 1,\: 1\le i \le n-2,\: i\bmod{2} = 0$.
%\end{gather*}
%In other words, $\I$ is contained in $\Pi_{\texttt{acyc}}$ if $\I_{\texttt{odd}}$ and $\I_{\texttt{even}}$ are contained in $\I_{\texttt{edgeless}}$. Consequently, \Cref{alg:dispersing-intervals} can be applied to $\I_{\texttt{odd}}$ and $\I_{\texttt{even}}$ independently for $s = 1$ to obtain optimal solutions for satisfying $\I_{\texttt{edgeless}}$ in the two subcollections, and combining both solutions gives the optimal solution for satisfying $\Pi_{\texttt{acyc}}$ in $\I$.
%\begin{corollary}
%    Given a unit interval graph $(G,\I)$, {\gged} can be solved in $O(n\log n)$ time for satisfying $\Pi_{\texttt{acyc}}$.
    %Given a collection of unit intervals $\I$, a solution where the total moving distance is minimum can be found in $O(n\log n)$ time for satisfying $\Pi_{\texttt{acyc}}$.
%\end{corollary}
%\subsection{Satisfying \texorpdfstring{$\overline{\Pi_{k\texttt{-clique}}}$}{} on Unit Interval Graphs}
We first show how to satisfy $\overline{\Pi_{k\texttt{-clique}}}$. %in $O(n\log n)$ time.


It is shown in~\cite{HonoratoDroguett2024} that given a unit interval graph $(G,\I)$, $G$ does not contain a $k$-clique if and only if $c(I_{i+k-1}) - c(I_i) \ge  1$ for all $1 \le i \le n-k+1$.
%
%We first give the following lemma regarding $k$-clique-free unit interval graphs.
%
%\begin{mlemmarep}
%    Given a unit interval graph $(G,\I)$ such that $\I = \{I_1,\ldots,I_n\}$, a $k$-clique exists in $G$ if and only if $c(I_{i+k-1}) - c(I_i) \le 1$ for $1 \le i \le n-k+1$.
%    \label{lem:kcliqueiff_updt}
%\end{mlemmarep}
%\begin{proof}
%    Suppose that there exists a $k$-clique $K_k$ in $G$. 
%    The clique $K_k$ consists of $k$ vertices, so the $k$ intervals intersect in $\I$. 
%    Let $I$ and $J$ be the leftmost and rightmost intervals that correspond to the vertices of $K_k$, respectively. 
%    Assume also that $I$ and $J$ are the $i$-th interval and the $j$-th interval in $\I$, respectively.
%    The inequality $c(J) - c(I) \le 1$ holds as $I$ and $J$ intersect. 
%    Since $\I$ is a collection of unit intervals, all intervals between $I$ and $J$ also intersect with $I$ and $J$.
%    Therefore, $j = i + k - 1$.
%
%   In the other direction, we assume that $c(I_{i+k-1}) - c(I_i) \le 1$ holds for $1 \le i \le n-k+1$.
%   By the index of both intervals, there exist other $k-2$ intervals between $I_{i}$ and $I_{i+k-1}$. Since $c(I_{i+k-1}) - c(I_i) \le 1$, the distance between all intervals $I_{i},I_{i+1},\ldots,I_{i+k-1}$ is also at most $1$.
%   It follows that this sequence forms a $k$-clique.
%\end{proof}
%
This inequality can be decomposed into $k-1$ inequalities of the following form:
%\begin{gather*}
    for each $0\le r \le k-2$, $c(I_{i+k-1}) - c(I_i) \ge 1$ for all $1\le i \le n-k+1$ such that $i\bmod{k-1} = r$.
%    \dots\\
%    c(I_{i+k-1}) - c(I_i) \ge 1,\: 1\le i \le n-k+1,\: i\bmod{k-1} = k-2
%\end{gather*}
If $\I$ is decomposed into $k-1$ subcollections such that $\I = \bigcup_{1\le i \le k-1} \I_i$, $\I_i = \{I_j \in \I\mid 1\le j \le n,\: j\pmod{k-1}=i\}$, then \Cref{alg:dispersing-intervals} can be applied to each $\I_i$ independently for $s = 1$ to satisfy the above inequalities.
Since unit interval graphs are chordal, $G$ is acyclic if it is triangle-free; i.e. $G$ is contained in $\overline{\Pi_{3\texttt{-clique}}}$.
Consequently $\Pi_{\texttt{acyc}}$ can be satisfied by satisfying $\overline{\Pi_{k\texttt{-clique}}}$ when $k = 3$.
%On the other hand, a unit interval graph $(G,\I)$ is acyclic if the following inequality holds: $c(I_{i+2}) - c(I_i) \ge 1,\: 1\le i \le n-2$.
The above ideas imply \Cref{cor:nokclique}.

\begin{corollary}\label{cor:nokclique}
    Given an interval graph $(G,\I)$, {\gged} can be solved in $O(n\log n)$ time for satisfying $\Pi_{\texttt{acyc}}$ and $\overline{\Pi_{k\texttt{-clique}}}$.
    %Given a collection of unit intervals $\I$, a solution where the total moving distance is minimum can be found in $O(n\log n)$ time for satisfying $\overline{\Pi_{k\texttt{-clique}}}$.
\end{corollary}

\ifFull
An interval graph $G$ is bipartite if $G$ does not contain an odd cycle. Since interval graphs are chordal, any existence of a cycle implies also the existence of an odd cycle. Thus it is sufficient to remove all cycles to obtain a bipartite graph. 
\begin{corollary}
    Given a unit interval graph $(G,\I)$, {\gged} can be solved in $O(n\log n)$ time for satisfying $\Pi_{\texttt{bipar}}$.
    %Given a collection of unit intervals $\I$, a solution where the total moving distance is minimum can be found in $O(n\log n)$ time for satisfying $\Pi_{\texttt{bipar}}$.
\end{corollary}
\fi
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Minimising the Total Moving Distance for Satisfying \texorpdfstring{$\Pi_{\texttt{edgeless}}$}{} on Weighted Interval Graphs is Hard}\label{sec:edg_ig}

In this section we show that {\gged} is strongly \NP-hard on weighted interval graphs for satisfying $\Pi_{\texttt{edgeless}}$. We show a reduction from {\threepartition}~\cite{garey1979}.
\ifConf
{\threepartition} receives as input a set $A$ of $3m$ elements, a bound $B \in \mathbb{Z}^+$ and a size $s(a) \in \mathbb{Z}^+$ such that $B/4 <s(a) < B/2$ and $\sum_{a \in A} s(a) = mB$, and the task is to decide whether $A$ can be partitioned into $m$ disjoint sets $A_1,\ldots,A_m$ such that for $1\le i \le m$, $\size{A_i} = 3$ and $\sum_{a\in A_i} s(a) = B$.
\fi
\ifFull
\begin{itembox}[l]{{\threepartition}~\cite{garey1979}}
    \begin{description}%[itemsep=0pt,align=left,leftmargin=43pt,labelindent=5pt,style=multiline]
        \item[Input:] Set $A$ of $3m$ elements; a bound $B \in \mathbb{Z}^+$; a size $s(a) \in \mathbb{Z}^+$ such that $B/4 <s(a) < B/2$ and $\sum_{a \in A} s(a) = mB$.
        \item[Task:] Decide whether $A$ can be partitioned into $m$ disjoint sets $A_1,\ldots,A_m$ such that for $1\le i \le m$, $\size{A_i} = 3$ and $\sum_{a\in A_i} s(a) = B$.
    \end{description}
\end{itembox}
\fi

Given an instance $(A,B,s)$ of {\threepartition}, we construct a collection of intervals $\I_A$ and show that $A$ can be partitioned if and only if $\Pi_{\texttt{edgeless}}$ can be satisfied on $\I_A$ with at most total moving distance $T$.
Given two intervals $I,I'$ such that $c(I)\le c(I')$, we say that $I$ and $I'$ intersect if $c(I')-c(I) < (\len{I'}+\len{I})/2$.

We show the construction of $\I_A$ (see \Cref{fig:reduction_overview_ig_hard}).
We define $\I_A$ as the collection $\I\cup \I^s \cup \I^b$ where $\I = \{I_1,\ldots,I_{3m}\},\: \I^s = \{I^s_1,\ldots,I^s_{m-1}\},\: \I^b =  \{I_\ell,I_r\}$ and,
\begin{description}%[itemsep=0pt,align=left,leftmargin=25pt,labelindent=5pt,style=multiline]
    \item[(i)] for $1\le i\le 3m$, $I_i$ is an interval such that $\len{I_i} = s(a_i)$ and $c(I_i) = -s(a_i)/2$ (that is, $r(I_i) = 0$),
    \item[(ii)] for $1\le i \le m-1$, $I^s_i$ is an interval such that $\len{I^s_i} = B$ and $c(I^s_i) = (2i-1)B + B/2$ and
    \item[(iii)] $I_\ell$ and $I_r$ are intervals such that $\len{I_\ell} = \len{I_r} = 3Bm^2 + \max_{a\in A}{s(a)}$, $c(I_\ell) = -3Bm^2/2$ and $c(I_r) = (2m-1)B+3Bm^2/2$.
\end{description}
%\begin{toappendix}
%    \Cref{fig:reduction_overview_ig_hard} shows the construction of $\I_A$.
    
    \begin{figure}[!b]
        \centering
        \includegraphics[scale=1,page=1]{media/IG_hard.pdf}
        %\includesvg[width=0.5\textwidth]{media/definitions.svg}
        \caption{Reduction Overview}
        \label{fig:reduction_overview_ig_hard}
    \end{figure}  
    
%\end{toappendix}
For an interval $I\in \I_A$, we define the moving distance function $d_I:\mathbb{R}\rightarrow\mathbb{R}$ as:
\begin{align*}
    d_I(x) = \begin{cases}
        |c(I)-x|,&\quad I \in \I,\\
        12Bm^2|c(I)-x|,& \quad I \in \I^s \cup \I^b.
    \end{cases}
\end{align*}
Given an instance $(A,B,s)$ of {\threepartition}, we show the following properties.
\begin{mlemmarep}\label{lem:cumulative_sum_bound}
    Given an arbitrary partition of $A$ of $m$ disjoint sets $A_1,\ldots,A_m$ such that $A_i =\set{a^i_1,a^i_2,a^i_3}$ for $1\le i \le m$, $\sum_{i=1}^m 6(i-1)B + \sum^m_{i=1} (3a^i_1+2a^i_2+a^i_3) < 3Bm^2$ holds.
\end{mlemmarep}
\begin{proof}
    We first simplify the first sum:
    \begin{align*}
        \sum_{i=1}^m 6(i-1)B & = 6B\left(\sum_{i=1}^m i-1\right) = 6B\left(\sum_{i=1}^m i - \sum_{i=1}^m 1\right)\\
        & = 6B\left(\frac{m(m+1)}{2} - m\right) = 6B\left(\frac{m(m-1)}{2}\right).
    \end{align*}
    We obtain the upper bound using the fact that $s(a)< B/2$ for any $a \in A$:
    \begin{align*} \sum^m_{i=1} (3a^i_1+2a^i_2+a^i_3) <\sum_{i=1}^m 3\frac{B}{2}+2\frac{B}{2}+\frac{B}{2} = \sum_{i=1}^m 6\frac{B}{2} = \sum_{i=1}^m 3B = 3mB.
    \end{align*}
    Now we have that
    \begin{align*}
        \sum_{i=1}^m 6(i-1)B + \sum^m_{i=1} (3a^i_1+2a^i_2+a^i_3) & < 6B\left(\frac{m(m-1)}{2}\right) + 3mB\\
        & = 3Bm^2 -3mB +3mB = 3Bm^2.
    \end{align*}
    Therefore, the lemma statement is true.
\end{proof}
We note that \Cref{lem:cumulative_sum_bound} works for any partition of $A$ as described above, even without the restrictions of the {\threepartition} output.
\begin{mlemmarep}\label{lem:3p_iff_gged_edgeless}
    Given an instance $(A,B,s)$ of {\threepartition}, $A$ can be partitioned into $m$ disjoint sets $A_1,\ldots,A_m$ such that for $1\le i \le m$ $A_i = \set{a^i_1,a^i_2,a^i_3}$, $\size{A_i} = 3$ and $\sum_{a\in A_i} s(a) = B$ if and only if $\Pi_{\texttt{edgeless}}$ can be satisfied on $\I_A$ with total moving distance of at most $3Bm^2$.
\end{mlemmarep}
\begin{proof}
    Assume that $A$ can be partitioned into $m$ disjoint sets $A_1,\ldots,A_m$ such that for $1\le i \le m$, $\size{A_i} = 3$ and $\sum_{a\in A_i} s(a) = B$.
    Let $D = (d_1,\ldots,d_{3m}),\:D^s = (d^s_{1},\ldots, d^s_{m-1}),\:D^b = (d^b_\ell, d^b_r)$ be vectors that describe the moving distances of $\I$, $\I^s$ and $\I^b$ for satisfying $\Pi_{\texttt{edgeless}}$, respectively.
    We show that $D,D^s,D^b$ exist such that $\sum_{d\in D\cup D^s \cup D^b} |d| \le 3Bm^2$.
    
    Without loss of generality, we assume that the first three elements of $\I$ correspond to $A_1$, the next three elements to $A_2$, and so forth.
    We start by setting $D^s = 0$ and $D^b = 0$.
    We set $d_1 = a^1_1 $, $d_2 = a^1_1 + a^1_2 $ and $d_3 = a^1_1 + a^1_2 + a^1_3$.
    The centre of $I^D_1$ is equal to $c(I^D_1) = c(I_1) + d_1 = -a^1_1/2 + a^1_1 = a^1_1/2$.
    Similarly, $c(I^D_2) = a^1_1 + a^1_2/2$ and $c(I^D_3) = a^1_1 + a^1_2 + a^1_3/2$.
    Furthermore, it holds that $c(I^D_{i+1}) - c(I^D_i) = (\len{I^D_{i+1}}+\len{I^D_i})/2$ for $i\in \set{1,2}$, hence $I^D_1,I^D_2,I^D_3$ do not intersect each other.
    %(\len{}+\len{})/2
    Moreover, $c(I^D_1) - c(I_\ell) = (\len{I^D_1}+\len{I_\ell})/2$ and $c(I^s_1) - c(I^D_3) = (\len{I^s_1}+\len{I^D_3})/2$.
    That is, $I_1,I_2,I_3$ were moved to the area of length $B$ between $I_\ell$ and $I^s_1$ without introducing new intersections.
    For $2 \le i \le m$, we set $d_{3i-2} = 2(i-1)B + a^i_1$, $d_{3i-1} = 2(i-1)B + a^i_1 + a^i_2$ and $d_{3i-1} = 2(i-1)B + a^i_1 + a^i_2 + a^i_3$.
    Analogous to $I_1,I_2,I_3$, it is easy to see that $I^D_{3i-2}, I^D_{3i-1}, I^D_{3i}$ are moved to the area of length $B$ between $I^s_{i-1}$ and $I^s_{i}$ without introducing intersections.
    This implies that $D$, $D^s$, and $D^b$ describe moving distances to make $\I_A$ satisfy $\Pi_{\texttt{edgeless}}$.
    For $1\le i \le m$, the total moving distance for moving $I_{3i-2},I_{3i-1},I_{3i}$ as described is given by $d_{3i-2}+d_{3i-1}+d_{3i} = 6B(i-1) + 3a^i_1+2a^i_2+a^i_3$.
    Consequently, $T = \sum D + \sum D^s + \sum D^b = \sum D = \sum_{i=1}^m 6B(i-1) + 3a^i_1+2a^i_2+a^i_3$.
    By \Cref{lem:cumulative_sum_bound}, $T< 3Bm^2$ holds.
    Therefore, $\Pi_{\texttt{edgeless}}$ can be satisfied on $\I_A$ with total moving distance of at most $3Bm^2$.

    In the other direction, assume that $\Pi_{\texttt{edgeless}}$ can be satisfied on $\I_A$ with total moving distance of at most $3Bm^2$.
    We let $D,D^s,D^b$ be the vectors that describe such a solution.
    We show that $A$ can be partitioned into $m$ disjoint sets $A_1,\ldots,A_m$ such that for $1\le i \le m$, $A_i = \set{a^i_1,a^i_2,a^i_3}$, $\size{A_i} = 3$ and $\sum_{a\in A_i} s(a) = B$.
    Observe that if an interval $I\in \I$ is moved to a point $x \le \ell(I_\ell)$, then $d_I(x) \ge \len{I_\ell}-\len{I}/2 = 3Bm^2 + \max_{a\in A}{s(a)} - \len{I}/2> 3Bm^2$.
    Thus no interval is moved to the left side of $I_\ell$.
    Analogously, no interval is moved to the right side of $I_r$.
    Moreover, for $I\in \I^b$, $c(I)-1/4\le c(I^{D^b})\le c(I)+1/4$ holds, otherwise $d_I(x) > 3Bm^2$ by the definition of the moving distance function.
    This argument also holds for any $I \in \I^s$, since the moving distance is the same.
    Hence the intervals in $\I^D$ must be between $r(I_\ell)$ and $\ell(I_r)$.
    
    There exist $m$ areas of length $B$ between $r(I_{\ell})$ and $\ell(I_r)$ divided by the $m-1$ intervals of $\I^s$. 
    By definition of $\I_A = \I \cup \I^s\cup \I^b$, $\sum_{I\in \I } \len{I} = mB$ and $\size{\I} = 3m$. 
    For any subcollection of intervals $\I' \subseteq \I$ such that $\size{\I'} \ge 4$, the constraint $B/4 < s(a) < B/2$ ensures that $\sum_{I \in \I'} \len{I} > B$ holds.
    Consequently, $\I$ must admit a partition into $m$ subcollections $\I_1,\dots,\I_m$ of three intervals such that $\sum_{I \in \I_i} \len{I} = B$ for each $i$.
    Otherwise the intervals do not fit into the $m$ areas divided intervals of $\I^s$.
    On the other hand, it holds that the length of an area is in the range of $B\pm 1/2$ since $c(I)-1/4\le c(I^{D^b})\le c(I)+1/4$ holds for $I \in \I^s\cup \I^b$.
    Given that $s(a) \in \mathbb{Z}^+$ for all $a \in A$, this ensures that regardless of the movement of intervals in $\I^s$, the three intervals in each area must satisfy $\sum_{I \in \I_i} \len{I} = B$ for each $i$.
    Without loss of generality, assume that $\I$ is moved such that $c(I^D_{i+1}) \ge c(I^D_i)$ for $1\le i \le 3m-1$ and that $\len{I^D_i} = s(a'_i)$ for $a'_i \in A$.
    The $m$ disjoint subcollections $\set{I_{3i-2},I_{3i-1},I_{3i}}$, $1\le i \le m$, satisfy $\len{I_{3i-2}}+\len{I_{3i-1}}+\len{I_{3i}} = B$. That is, this partition gives $m$ disjoint subsets of the form $A_i = \set{a'_{3i-2},a'_{3i-1},a'_{3i}}$ such that $\sum_{a\in A_i} s(a)  = B$.
    Therefore, $A$ can be partitioned into $m$ disjoint sets $A_1,\ldots,A_m$ such that for $1\le i \le m$ $A_i = \set{a^i_1,a^i_2,a^i_3}$, $\size{A_i} = 3$ and $\sum_{a\in A_i} s(a) = B$.
\end{proof}
Lastly, we remark that the polynomial construction of $\I_A$ is straightforward by iterating over $A$ and following the definitions given at the beginning of the section. We summarise the main result of this section as follows:
\begin{theorem}\label{thm:ig_nphard_edgeless}
    {\gged} is strongly \NP-hard on weighted interval graphs for satisfying $\Pi_{\texttt{edgeless}}$.
\end{theorem}

\ifFull
Let $\Pi_{k\texttt{-deg}}$ be the class of graphs with maximum degree $k$. 
%We have $\Pi_{\texttt{edgeless}} = \Pi_{0-\texttt{deg}}$ and $\Pi_{\texttt{acyc}} = \Pi_{1-\texttt{deg}}$.
We slightly modify the reduction of \Cref{thm:ig_nphard_edgeless} and show that {\gged} is also strongly \NP-hard for satisfying $\Pi_{k-\texttt{deg}}$.

\begin{mtheoremrep}\label{thm:ig_nphard_kdeg}
    {\gged} is strongly \NP-hard on weighted interval graphs for satisfying $\Pi_{k-\texttt{deg}}$.
\end{mtheoremrep}
\begin{proof}
    We extend the reduction from {\threepartition} of \Cref{thm:ig_nphard_edgeless}.
    Given an instance $(A,B,s)$ of {\threepartition} and $\I_A = \I \cup \I^s \cup \I^b$ as defined above, we construct an instance $\J_A = \J \cup \J^s \cup \J^b \cup \J^f$ such that (i) $\J = \I$, (ii) for each $I^s_i \in \I^s$, $\J$ contains $k+1$ intervals $J_1,\ldots,J_{k+1}$ such that $\len{J_j} = \len{I^s_i}$ and $c(J_j) = c(I^s_i)$ for $1\le j \le k+1$, and (iii) $\J^b = \set{J_\ell^1,\ldots,J_\ell^{k+1}}\cup \set{J_r^1,\ldots,J_r^{k+1}}$ such that $\len{J_\ell^j} = \len{I_\ell}$ and $c(J^j_\ell) = c(I_\ell)$ for $1\le j \le k+1$, and $\len{J_r^j} = \len{I_r}$ and $c(J^j_r) = c(I_r)$ for $1\le j \le k+1$.
    We define the moving distance function analogously for $\J$ and $\J^s \cup \J^b$.
    Let $c_1,\ldots,c_m = (\ell(I^s_1)-r(I_\ell))/2,(\ell(I^s_2)-r(I^s_1))/2,\ldots, (\ell(I^s_{m-1})-r(I^s_{m-2}))/2,(\ell(I_r)-r(I^s_{m-1}))/2$.
    For each $1\le i \le m$, the subcollection $\J^f$ contains $k$ intervals $J_1,\ldots,J_k$ such that $c(J_j) = c_i$, $\len{J_j} = B$ and $d_{J_j}(x) = 12Bm^2|c(J_j)-x|$ for all $1\le j \le k$.
    %Duplicate $\I^s$ and $\I^b$ $k+1$ times in $\I_A$ and add $k$ intervals of size $B$ to each area of size $B$. 
    The resulting collection consists of a $(k+1)$-clique for each copy of an interval $I \in \I^s\cup \I^b$ and $k$-cliques of intervals centred at $c_1,\ldots,c_m$ in the areas of size $B$.
    We set the maximum total moving distance to $T = 3Bm^2$ as above.
    Analogously to $\I_A$, the intervals in $\J$ must be placed in the areas of the $k$-cliques; otherwise, a $(k+2)$-clique is formed by intersecting with the intervals in $\J^s \cup \J^b$ or the total moving distance is greater than $3Bm^2$.
    This implies that the proof of \Cref{lem:3p_iff_gged_edgeless} also shows that $\Pi_{k-\texttt{deg}}$ can be satisfied on $\J_a$ with total moving distance of at most $3Bm^2$ if and only if $(A,B,s)$ is a yes-instance of {\threepartition}.
    Lastly, $\J_A$ is constructed in polynomial time by iterating $A$ since $k$ is bounded by $n$.
    Therefore, the theorem statement is true.
\end{proof}

We notice that \Cref{thm:ig_nphard_kdeg} can be used to show that the cases for properties $\Pi_{\texttt{acyc}}$ and $\overline{\Pi_{k\texttt{-clique}}}$ are also strongly \NP-hard.
In particular, for $\Pi_{1\texttt{-deg}}$, the intervals $I,J^1_\ell,J^2_\ell$ form a cycle in $\J_A$ for any $I \in \J$. Consequently, moving the intervals of $\J$ with total moving distance of at most $3Bm^2$ is equivalent to removing all cycles from $\J_A$ with total moving distance of at most $3Bm^2$.
Similarly, for any $I\in \J$, the intervals $I,J^1_\ell,\ldots,J^k_\ell$ form a $k$-clique in $\I_A$ for satisfying $\Pi_{(k-1)\texttt{-deg}}$. Consequently, moving the intervals of $\J$ with total moving distance of at most $3Bm^2$ is equivalent to removing all $k$-cliques from $\J_A$ with total moving distance of at most $3Bm^2$.
\fi
\ifConf
We notice that \Cref{thm:ig_nphard_edgeless} can be extended to show that satisfying $\Pi_{\texttt{acyc}}$ and $\overline{\Pi_{k\texttt{-clique}}}$ is also strongly \NP-hard.
%In particular, when satisfying $\Pi_{\texttt{acyc}}$, we make an overlapping copy of intervals in $\I^s\cup\I^b$ and add one interval of size $B$ into the spaces between intervals of  $\I^s\cup\I^b$ with the same moving distance function.
%By doing this, an arbitrary interval of $\I$ forms a cycle with $I_\ell$ and its overlapping copy.
%Consequently, moving the intervals of $\I$ with total moving distance of at most $3Bm^2$ is equivalent to removing all cycles from $\I_A$ with at most the same distance.
In particular, when satisfying $\overline{\Pi_{k\texttt{-clique}}}$, we create $k-1$ overlapping copies of the intervals in $\I^s\cup\I^b$ and add $k-1$ overlapping intervals of size $B$ into the spaces between intervals of $\I^s\cup\I^b$ with the same moving distance function.
Any interval forms a $k$-clique with the $k$ copies of overlapping intervals.
Consequently, moving the intervals of $\I$ with total moving distance of at most $3Bm^2$ is equivalent to removing all $k$-cliques from $\I_A$ with at most the same distance.
Moreover, by the chordality of interval graphs, it is sufficient to satisfy $\overline{\Pi_{k\texttt{-clique}}}$ when $k =3$ to satisfy $\Pi_{\texttt{acyc}}$.
\fi
%\warning{Add explanation of the corollaries.} 
As a result, \Cref{cor:ig_nphard_acyc_and_nokclique} is obtained.

\begin{corollary}\label{cor:ig_nphard_acyc_and_nokclique}
    {\gged} is strongly \NP-hard on weighted interval graphs for satisfying $\Pi_{\texttt{acyc}}$ and $\overline{\Pi_{k\texttt{-clique}}}$.
\end{corollary}
%\begin{corollary}
%    {\gged} is strongly \NP-hard on weighted interval graphs for satisfying $\overline{\Pi_{k\texttt{-clique}}}$.
%\end{corollary}