[
  {
    "index": 0,
    "papers": [
      {
        "key": "gpt3",
        "author": "Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others",
        "title": "Language models are few-shot learners"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "llama2",
        "author": "Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others",
        "title": "Llama 2: Open foundation and fine-tuned chat models"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "internlm",
        "author": "Team, InternLM",
        "title": "Internlm: A multilingual language model with progressively enhanced capabilities"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "baichuan2",
        "author": "Yang, Aiyuan and Xiao, Bin and Wang, Bingning and Zhang, Borong and Bian, Ce and Yin, Chao and Lv, Chenxu and Pan, Da and Wang, Dian and Yan, Dong and others",
        "title": "Baichuan 2: Open large-scale language models"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "clipvit",
        "author": "Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others",
        "title": "Learning transferable visual models from natural language supervision"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "blip",
        "author": "Li, Junnan and Li, Dongxu and Xiong, Caiming and Hoi, Steven",
        "title": "Blip: Bootstrapping language-image pre-training for unified vision-language understanding and generation"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "blip2",
        "author": "Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven",
        "title": "Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "llava",
        "author": "Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae",
        "title": "Visual instruction tuning"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "minigpt",
        "author": "Zhu, Deyao and Chen, Jun and Shen, Xiaoqian and Li, Xiang and Elhoseiny, Mohamed",
        "title": "Minigpt-4: Enhancing vision-language understanding with advanced large language models"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "instructblip",
        "author": "Wenliang Dai and Junnan Li and Dongxu Li and Anthony Meng Huat Tiong and Junqi Zhao and Weisheng Wang and Boyang Li and Pascale Fung and Steven Hoi",
        "title": "InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "gpt4",
        "author": "Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others",
        "title": "Gpt-4 technical report"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "lamm",
        "author": "Yin, Zhenfei and Wang, Jiong and Cao, Jianjian and Shi, Zhelun and Liu, Dingning and Li, Mukai and Huang, Xiaoshui and Wang, Zhiyong and Sheng, Lu and Bai, Lei and others",
        "title": "Lamm: Language-assisted multi-modal instruction-tuning dataset, framework, and benchmark"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "mimic",
        "author": "Li, Bo and Zhang, Yuanhan and Chen, Liangyu and Wang, Jinghao and Pu, Fanyi and Yang, Jingkang and Li, Chunyuan and Liu, Ziwei",
        "title": "Mimic-it: Multi-modal in-context instruction tuning"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "glm4v",
        "author": "GLM, Team and Zeng, Aohan and Xu, Bin and Wang, Bowen and Zhang, Chenhui and Yin, Da and Rojas, Diego and Feng, Guanyu and Zhao, Hanlin and Lai, Hanyu and others",
        "title": "ChatGLM: A Family of Large Language Models from GLM-130B to GLM-4 All Tools"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "qwenvl",
        "author": "Bai, Jinze and Bai, Shuai and Yang, Shusheng and Wang, Shijie and Tan, Sinan and Wang, Peng and Lin, Junyang and Zhou, Chang and Zhou, Jingren",
        "title": "Qwen-vl: A frontier large vision-language model with versatile abilities"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "internlm-xcomposer-2.5",
        "author": "Pan Zhang and Xiaoyi Dong and Yuhang Zang and Yuhang Cao and Rui Qian and Lin Chen and Qipeng Guo and Haodong Duan and Bin Wang and Linke Ouyang and Songyang Zhang and Wenwei Zhang and Yining Li and Yang Gao and Peng Sun and Xinyue Zhang and Wei Li and Jingwen Li and Wenhai Wang and Hang Yan and Conghui He and Xingcheng Zhang and Kai Chen and Jifeng Dai and Yu Qiao and Dahua Lin and Jiaqi Wang",
        "title": "InternLM-XComposer-2.5: A Versatile Large Vision Language Model Supporting Long-Contextual Input and Output"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "internlm2_5",
        "author": "Zhang, Pan and Dong, Xiaoyi and Zang, Yuhang and Cao, Yuhang and Qian, Rui and Chen, Lin and Guo, Qipeng and Duan, Haodong and Wang, Bin and Ouyang, Linke and others",
        "title": "InternLM-XComposer-2.5: A Versatile Large Vision Language Model Supporting Long-Contextual Input and Output"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "gpt4v",
        "author": "OpenAI",
        "title": "{GPT-4V(ision) System Card}"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "hurst2024gpt",
        "author": "Hurst, Aaron and Lerer, Adam and Goucher, Adam P and Perelman, Adam and Ramesh, Aditya and Clark, Aidan and Ostrow, AJ and Welihinda, Akila and Hayes, Alan and Radford, Alec and others",
        "title": "Gpt-4o system card"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "claude3.5",
        "author": "Anthropic",
        "title": "{Claude 3.5 Sonnet}"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "multiinstruct",
        "author": "Zhiyang Xu and Ying Shen and Lifu Huang",
        "title": "MultiInstruct: Improving Multi-Modal Zero-Shot Learning via Instruction Tuning"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "minigpt",
        "author": "Zhu, Deyao and Chen, Jun and Shen, Xiaoqian and Li, Xiang and Elhoseiny, Mohamed",
        "title": "Minigpt-4: Enhancing vision-language understanding with advanced large language models"
      }
    ]
  },
  {
    "index": 22,
    "papers": [
      {
        "key": "llava",
        "author": "Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae",
        "title": "Visual instruction tuning"
      }
    ]
  },
  {
    "index": 23,
    "papers": [
      {
        "key": "lamm",
        "author": "Yin, Zhenfei and Wang, Jiong and Cao, Jianjian and Shi, Zhelun and Liu, Dingning and Li, Mukai and Huang, Xiaoshui and Wang, Zhiyong and Sheng, Lu and Bai, Lei and others",
        "title": "Lamm: Language-assisted multi-modal instruction-tuning dataset, framework, and benchmark"
      }
    ]
  },
  {
    "index": 24,
    "papers": [
      {
        "key": "visionllmv2",
        "author": "Wu, Jiannan and Zhong, Muyan and Xing, Sen and Lai, Zeqiang and Liu, Zhaoyang and Wang, Wenhai and Chen, Zhe and Zhu, Xizhou and Lu, Lewei and Lu, Tong and others",
        "title": "VisionLLM v2: An End-to-End Generalist Multimodal Large Language Model for Hundreds of Vision-Language Tasks"
      }
    ]
  },
  {
    "index": 25,
    "papers": [
      {
        "key": "vision_flan",
        "author": "Xu, Zhiyang and Feng, Chao and Shao, Rulin and Ashby, Trevor and Shen, Ying and Jin, Di and Cheng, Yu and Wang, Qifan and Huang, Lifu",
        "title": "Vision-flan: Scaling human-labeled tasks in visual instruction tuning"
      }
    ]
  }
]