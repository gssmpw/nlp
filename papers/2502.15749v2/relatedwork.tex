\section{Related Works}
\subsection{SSL for Classification}
Data scarcity is a critical problem for various tasks.
More specifically, the problem occurs when there are only
a few labeled data even though there are tons of unlabeled data.
Generating labeled data is costly,
making research in these low-resource environments crucial.
Semi-supervised learning~(SSL) offers
an effective solution in such scenarios~\cite{SajjadiJT2016, XieDHLL2020, ChenZD2020, ChenHP2022, SohnBCZZ2020, ZhangWHW2021, WangCHH2022,ZouCZC23,Huang0Y0L23,NieDLWHZ24}.

One of the popularly used SSL techniques,
self-training is a learning mechanism that trains the student model with a few-shot labeled dataset~\cite{GengLLZJS19,BaoWCB20,ZhangB0CLXTCY21}
and then subsequently acts as a teacher model for generating pseudo-labels~\cite{Lee2013}.
Pseudo-labels are judged based on the predictions of the model for a given unlabeled data.
Co-training~\cite{BlumM98} is also the successful SSL mechanism
that simultaneously employs two networks.
Jointmatch~\cite{ZouC23} utilizes cross-labeling, inspired by co-training, that uses an additional loss based on pseudo-labels for more reliability
instead of augmenting pseudo-labels to the initial labeled dataset for additional training.
While this approach has been effective to some degree,
it lacks reliability as we cannot guarantee that the model generates `correct' pseudo-labels.
Recent approaches have incorporated symbolic modules
to enhance the reliability of pseudo-label generations or data augmentation~\cite{HahnCHLKH21,KimWOCH22}.

Likewise, data augmentation is also one of the fundamental methods that
is effective in the low-resource setting.
Data augmentation generates artificial data from the original dataset
without changing their labels.
Conventional data augmentations are synonym replacements, word insertion or deletion~\cite{WeiZ19}
More advanced methods involve Back-Translation~\cite{EdunovOAG18} and these days,
LLMs have gained popularity in generating various data but with accurate labels.
We utilize these insights to develop \texttt{TCProF},
an SSL framework for predicting code time complexity in low-resource environments.


\subsection{Code Time Complexity Prediction}
Computation of code time complexity has long been a theoretically undecidable problem
whereas classifying the code time complexity is a recently emerged problem.
\citet{SikkaSKUSZ20} first proposed this task and presented a labeled dataset with
five time complexity classes.
They propose a dataset named CorCoD,
composed of Java codes with $O(1)$, $O(\log N)$, $O(N)$, $O(N\log N)$ and $O(N^2)$ time complexity classes
and experimental results on the time complexity classification with baseline neural models.

Similar to CorCoD,
CODAIT\footnote{https://community.ibm.com/community/user/ai-datascience/blogs/sepideh-seifzadeh1/2021/10/05/ai-for-code-predict-code-complexity-using-ibms-cod}
tried to create good code embeddings by capturing manual features such 
as number of loops and breaks, and utilized graph-based representations
for predicting time complexities.
Afterward, \citet{MoudgalyaRCL23} proposed TasTy, consisting of Java and Python data, and \citet{BaikJHKHK24}
proposed CodeComplex, which consists of also Java and Python data with additional labels.
CodeComplex consists of seven different time complexity classes,
$O(N^3)$ and $O(2^N)$ in addition to those of CorCoD.

While time complexity prediction has been explored in these datasets,
the scarcity of labeled data remains a significant challenge.
Unlike runtime-based datasets from online judge platforms,
which can be influenced by hardware, input distributions,
and implementation-specific optimizations~\cite{IshimweNN21,ZhangWL23},
these datasets provide explicit theoretical complexity labels for the code snippets.
However, annotating such datasets requires expert knowledge, making them inherently low-resource.
We propose \texttt{TCProF}, the SSL framework designed to
alleviate this data scarcity challenge and enhance the accuracy of time complexity prediction.