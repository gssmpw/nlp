
\input{prompts/square}

\section{Introduction}
\label{sec:introduction}

Large Language Models (LLMs) have rapidly transformed Natural Language Processing (NLP), excelling in tasks like text generation, machine translation, and dialogue systems \cite{brownLanguageModelsAre2020,kojimaLargeLanguageModels2022}. These models owe their flexibility to the Transformer architecture \cite{vaswaniAttentionAllYou2017}, and benefit from large-scale pretraining followed by fine-tuning or instruction tuning to align with human objectives \cite{ouyangTrainingLanguageModels2022,weiFinetunedLanguageModels2022}. A key technique for enhancing these models is chain-of-thought (CoT) prompting, which has gained notable attention for its ability to improve reasoning by encouraging models to work through problems step by step \citep{weiChainofThoughtPromptingElicits2023}. This approach has shown efficacy in complex tasks like multi-step arithmetic and commonsense question answering, by making intermediate processes transparent and facilitating more accurate outcomes \cite{snellScalingLLMTestTime2024}. While some CoT variants explore iterative reasoning, there is still limited exploration of self-interrogation paradigms that prompt models to pose and resolve their own intermediate queries.

\input{figures/illustration}

In this paper, we introduce \rephrase{} (Sequential Question Answering Reasoning Engine), a prompting technique that instructs an LLM to generate and answer multiple sub-questions before addressing the main query. By decomposing queries into iterative steps, \rephrase{} draws on chain-of-thought frameworks and prior prompting methodologies~\citep{dengRephraseRespondLet2024} to produce more comprehensive solutions. In extensive evaluations on multiple question-answering datasets using Llama 3~\cite{grattafioriLlama3Herd2024} (3B and 8B) and \mbox{GPT-4o} \citep{openaiGPT4oSystemCard2024}, \mbox{\rephrase{} outperforms} chain-of-thought prompts and existing rephrase-and-respond strategies. This work highlights how systematically breaking down queries advances LLM reasoning capabilities.

