[
  {
    "index": 0,
    "papers": [
      {
        "key": "malinin2021uncertainty",
        "author": "Malinin, Andrey and Gales, Mark",
        "title": "Uncertainty estimation in autoregressive structured prediction"
      },
      {
        "key": "kuhn2023semantic",
        "author": "Kuhn, Lorenz and Gal, Yarin and Farquhar, Sebastian",
        "title": "Semantic uncertainty: Linguistic invariances for uncertainty estimation in natural language generation"
      },
      {
        "key": "manakul2023selfcheckgpt",
        "author": "Manakul, Potsawee and Liusie, Adian and Gales, Mark JF",
        "title": "Selfcheckgpt: Zero-resource black-box hallucination detection for generative large language models"
      },
      {
        "key": "tian2023fine",
        "author": "Tian, Katherine and Mitchell, Eric and Yao, Huaxiu and Manning, Christopher D and Finn, Chelsea",
        "title": "Fine-tuning language models for factuality"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "qiu2024semantic",
        "author": "Qiu, Xin and Miikkulainen, Risto",
        "title": "Semantic Density: Uncertainty Quantification in Semantic Space for Large Language Models"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "qiu2024semantic",
        "author": "Qiu, Xin and Miikkulainen, Risto",
        "title": "Semantic Density: Uncertainty Quantification in Semantic Space for Large Language Models"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "kadavath2022language",
        "author": "Kadavath, Saurav and Conerly, Tom and Askell, Amanda and Henighan, Tom and Drain, Dawn and Perez, Ethan and Schiefer, Nicholas and Hatfield-Dodds, Zac and DasSarma, Nova and Tran-Johnson, Eli and others",
        "title": "Language models (mostly) know what they know"
      },
      {
        "key": "tian2023just",
        "author": "Tian, Katherine and Mitchell, Eric and Zhou, Allan and Sharma, Archit and Rafailov, Rafael and Yao, Huaxiu and Finn, Chelsea and Manning, Christopher D",
        "title": "Just ask for calibration: Strategies for eliciting calibrated confidence scores from language models fine-tuned with human feedback"
      },
      {
        "key": "xiong2023can",
        "author": "Xiong, Miao and Hu, Zhiyuan and Lu, Xinyang and Li, Yifei and Fu, Jie and He, Junxian and Hooi, Bryan",
        "title": "Can llms express their uncertainty? an empirical evaluation of confidence elicitation in llms"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "xiao2022uncertainty",
        "author": "Xiao, Yuxin and Liang, Paul Pu and Bhatt, Umang and Neiswanger, Willie and Salakhutdinov, Ruslan and Morency, Louis-Philippe",
        "title": "Uncertainty quantification with pre-trained language models: A large-scale empirical analysis"
      },
      {
        "key": "ye2024benchmarking",
        "author": "Ye, Fanghua and Yang, Mingming and Pang, Jianhui and Wang, Longyue and Wong, Derek F and Yilmaz, Emine and Shi, Shuming and Tu, Zhaopeng",
        "title": "Benchmarking llms via uncertainty quantification"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "duan2024shifting",
        "author": "Duan, Jinhao and Cheng, Hao and Wang, Shiqi and Zavalny, Alex and Wang, Chenan and Xu, Renjing and Kailkhura, Bhavya and Xu, Kaidi",
        "title": "Shifting attention to relevance: Towards the predictive uncertainty quantification of free-form large language models"
      },
      {
        "key": "bakman2024mars",
        "author": "Bakman, Yavuz Faruk and Yaldiz, Duygu Nur and Buyukates, Baturalp and Tao, Chenyang and Dimitriadis, Dimitrios and Avestimehr, Salman",
        "title": "MARS: Meaning-Aware Response Scoring for Uncertainty Estimation in Generative LLMs"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "mielke2022reducing",
        "author": "Mielke, Sabrina J and Szlam, Arthur and Dinan, Emily and Boureau, Y-Lan",
        "title": "Reducing conversational agents\u2019 overconfidence through linguistic calibration"
      },
      {
        "key": "lin2022teaching",
        "author": "Lin, Stephanie and Hilton, Jacob and Evans, Owain",
        "title": "Teaching models to express their uncertainty in words"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "lin2022teaching",
        "author": "Lin, Stephanie and Hilton, Jacob and Evans, Owain",
        "title": "Teaching models to express their uncertainty in words"
      },
      {
        "key": "kapoor2024large",
        "author": "Kapoor, Sanyam and Gruver, Nate and Roberts, Manley and Collins, Katherine and Pal, Arka and Bhatt, Umang and Weller, Adrian and Dooley, Samuel and Goldblum, Micah and Wilson, Andrew Gordon",
        "title": "Large Language Models Must Be Taught to Know What They Don't Know"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "wei2022chain",
        "author": "Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others",
        "title": "Chain-of-thought prompting elicits reasoning in large language models"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "kojima2022large",
        "author": "Kojima, Takeshi and Gu, Shixiang Shane and Reid, Machel and Matsuo, Yutaka and Iwasawa, Yusuke",
        "title": "Large language models are zero-shot reasoners"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "chu2023survey",
        "author": "Chu, Zheng and Chen, Jingchang and Chen, Qianglong and Yu, Weijiang and He, Tao and Wang, Haotian and Peng, Weihua and Liu, Ming and Qin, Bing and Liu, Ting",
        "title": "A survey of chain of thought reasoning: Advances, frontiers and future"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "wang2022self",
        "author": "Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc and Chi, Ed and Narang, Sharan and Chowdhery, Aakanksha and Zhou, Denny",
        "title": "Self-consistency improves chain of thought reasoning in language models"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "feng2024towards",
        "author": "Feng, Guhao and Zhang, Bohang and Gu, Yuntian and Ye, Haotian and He, Di and Wang, Liwei",
        "title": "Towards revealing the mystery behind chain of thought: a theoretical perspective"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "liu2024era",
        "author": "Liu, Yanming and Peng, Xinyue and Du, Tianyu and Yin, Jianwei and Liu, Weihao and Zhang, Xuhong",
        "title": "ERA-CoT: Improving Chain-of-Thought through Entity Relationship Analysis"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "fu2025multiple",
        "author": "Fu, Tairan and Conde, Javier and Mart{\\'\\i}nez, Gonzalo and Grandury, Mar{\\'\\i}a and Reviriego, Pedro",
        "title": "Multiple Choice Questions: Reasoning Makes Large Language Models (LLMs) More Self-Confident Even When They Are Wrong"
      }
    ]
  }
]