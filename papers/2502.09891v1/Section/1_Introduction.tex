\section{Introduction}


% 1. LLM 的巨大应用价值和潜力
% 2.1 LLM 的问题：缺少外部知识，难以更新知识；对已有问题产生幻觉。
% 2.2 LLm 的推理和prompt能力使得以上问题可以低成本解决，即RAG技术。

% 3. 现有RAG虽然能解决一些问题，但存在limit：（3点 in Survey）
% 4. 以MS GraphRAG 为代表的Graph RAG解决了以上3个问题，但仍存在一些问题
% 4.1 在构建index的过程中没能考虑属性等因素
% 4.2 成本高昂
% 4.3 没法适应 fine and coarse granularities 的问题，尽管有global and local search method, 没法满足各种问题中的粒度信息。


% 5. motivation above and our ArchRAG
% 5.1 Hierarchical clustering framework -- 对应4.1
% 5.2 Fast hierarchical vector search method -- C-HNSW 对应4.2
% 5.3 fine and coarse RAG method -- high level and low level community for different meaning, leverage the hierarchical community structrure. -- 对应4.3
% 5.4 results

% For KDD, maybe we don't need to highlight the application of RAG in DB area. 
% built on Transformer ~\cite{} architectures and trained

% Large Language Models (LLMs) have emerged as revolutionary tools that show impressive performance in many tasks \cite{sarthi2024raptor}.
% 
% With the growing size of LLMs, they can serve standalone as very effective knowledge stores, with facts encoded within their parameters \cite{petroni2020kilt,jiang2020can,talmor2020olmpics,rae2021scaling,hoffmann2022training,chowdhery2023palm,bubeck2023sparks,kandpal2023large} and models can be further improved with fine-tuning on downstream tasks \cite{roberts2020much}.
% 
% Nevertheless, even LLMs do not contain sufficient domain-specific knowledge for particular tasks, and the world continues to change, invalidating facts in the LLM.
% 
% Moreover, LLMs have a tendency to generate hallucinations \cite{bang2023multitask,guerreiro2023hallucinations}, producing content that appears plausible but lacks factual accuracy or support\cite{huang2023survey}.
% the knowledge embedded within LLMs is encoded in their parameters, meaning that incorporating new knowledge requires further fine-tuning, which is both time-consuming and resource-intensive.

Large Language Models (LLMs) like GPT-4 ~\cite{achiam2023gpt}, Qwen2.5 ~\cite{yang2024qwen2}, and LLaMA3.1 ~\cite{dubey2024llama} have received tremendous attention from both industry and academia~\cite{huang2024survey,liu2024survey,wang2024survey,zheng2024large,li2023large,nie2024survey,ghimire2024generative,wang2024large}.
% 
Despite their remarkable success in question-answering (QA) tasks, they may still generate wrong answers due to a lack of domain-specific, real-time updated, and proprietary knowledge outside their pre-training corpus~\cite{peng2024graph}. 
% 
To enhance the trustworthiness and interpretability of LLMs, Retrieval-Augmented Generation (RAG)  methods~\cite{fan2024survey,gao2023retrieval,hu2024rag,huang2024survey,wu2024retrieval,yu2024evaluation,zhao2024retrieval} have emerged as a core approach, which often retrieve relevant information from documents, relational data, and graph data to facilitate the QA tasks.

The state-of-the-art RAG approaches often use the graph data as the external data since they capture the rich semantic information and link relationships between entities. 
% 
Given a question $Q$, the key idea of graph-based RAG is to retrieve relevant information (e.g., nodes, subgraphs, or textual information) from the graph, incorporate them with $Q$ as the prompt, and feed them into the LLM, as illustrated in Figure \ref{fig:dual-tasks}.
%
As shown in the literature, a few recent graph-based RAG methods have emerged for both {\it abstract question}~\cite{edge2024local,guo2024lightrag,sarthi2024raptor} and {\it specific question}~\cite{guo2024lightrag,sarthi2024raptor,wu2024medical,wang2024knowledge,li2024dalk,gutierrez2024hipporag},
where the former is more conceptual, encompassing broader topics, summaries, or overarching themes (e.g., ``What are the potential impacts of LLMs on education?''), while the latter is detail-oriented and typically references specific entities within the graph  (e.g., ``Who has won the Turing Award in 2024?'')~\cite{guo2024lightrag}.
%
Technically, the abstract questions need a comprehensive understanding to extract high-level insights, while the specific questions require multi-hop reasoning to connect discrete information.
%
Table \ref{tab:comparison} summarizes the key characteristics of three representative graph-based RAG methods, i.e.,  GraphRAG~\cite{edge2024local}, HippoRAG~\cite{gutierrez2024hipporag}, and LightRAG~\cite{guo2024lightrag}.

\begin{figure}[t]
    \centering
    % \setlength{\abovecaptionskip}{-0.05cm}
    % \setlength{\belowcaptionskip}{-0.2cm}
    \includegraphics[width=\linewidth]{Figure/alpha-figure-background.png}
    \caption{The general workflow of graph-based RAG, which retrieves relevant information (e.g., nodes, subgraphs, or textual information) to facilitate the LLM generation.}
    \label{fig:dual-tasks}
\end{figure}

Specifically, Microsoft first proposes a graph-based RAG system called GraphRAG \cite{edge2024local}, which first builds a knowledge graph (KG) by extracting entities and relationships from the external corpus, then employs the Leiden method~\cite{traag2019louvain} to detect communities and generates a summary for each community using LLMs.
%
When answering abstract questions, it uses a Global Search method, which traverses each community and uses LLMs to retrieve relevant communities to answer the questions; for specific questions, it presents a Local Search method, which retrieves entities, identifies the relevant chunk texts and low-level communities to augments the response.
% 
LightRAG~\cite{guo2024lightrag} addresses abstract questions by adding keywords to relations in the constructed KG, and during querying, it uses LLMs to extract keywords and searches for the most relevant entities and relationships, which are then combined with the corresponding chunks for generation.
%
HippoRAG~\cite{gutierrez2024hipporag} employs LLMs to extract tuples from the corpus to build a KG and connect edges between similar entities in KG to improve the quality of the KG.
%
To answer specific questions requiring multi-hop reasoning, HippoRAG utilizes the Personalized PageRank (PPR)~\cite{haveliwala2002topic} to identify the most relevant entities from the KG and augment the question with chunks containing these selected entities for LLM generation.


%
% This approach is limited to apply to the simple QA~\cite{peng2024graph}, where answers can be found in a single chunk.
% % 
% This is because traditional RAG simply retrieves and incorporates isolated chunks without considering their relationships or broader context.
% % 
% In contrast, users often seek to use LLMs for more complex questions, which can be generally divided into two main categories: (1) \emph{Specific QA}, requiring multi-hop reasoning, and (2) \emph{Abstract QA}, needing comprehensive understanding.



% In contrast, users often seek to use LLMs for more complex questions, which can be divided into two main categories: (1) \emph{Specific QA}, requiring multi-hop reasoning to connect discrete information, and (2) \emph{Abstract QA}, needing comprehensive understanding to extract high-level insights.
% 
% The success of {\it GraphRAG} lies in its ability to leverage the structural properties of the graph and build community-level summaries, demonstrating significant improvements in Abstract QA tasks. 
% 
% (e.g., ``Who is Trump?'')
% % that require advanced reasoning beyond simple fact retrieval~\cite{peng2024graph}. (e.g., ``Who has won both the Nobel Prize and Turing Award?''(e.g., ``What are the potential impacts of large language models on education?'').
% These models have been widely used in healthcare ~\cite{liu2024survey,wang2024survey,zheng2024large}, finance ~\cite{li2023large,nie2024survey}, and education~\cite{ghimire2024generative,wang2024large} fields.
% To enhance the trustworthiness and interpretability of LLMs, numerous methods have been proposed~\cite{}.
% TODO: lack one cite here
% Among these, Retrieval-Augmented Generation (RAG)~\cite{fan2024survey,gao2023retrieval,hu2024rag,huang2024survey,wu2024retrieval,yu2024evaluation,zhao2024retrieval} stands out as a core approach.


% Now you need to introduce the Graph-based RAG method. 

% Shot version of GraphRAG & Specific QA and Abstract QA
%1. Drawbacks
% The RAG is typically applied to question-answering (QA) scenarios, where for a given question $Q$, the key idea is first to retrieve relevant chunks (i.e., segmented texts) from a large corpus and then incorporate them into the response generation process of LLM. 
%

% , demanding thorough understanding of the technological landscape, educational context, and their evolving dynamics).


% 

% 
% To tackle diverse problems, these graph-based RAG methods \cite{edge2024local,gutierrez2024hipporag,sarthi2024raptor,peng2024graph,li2024dalk,wu2024medical,wang2024knowledge} retrieve and utilize different graph elements in various ways.
% 
% Generally, these methods differ in how they construct and utilize the graph structure. 
% For example, some methods utilize LLM to find relevant entities and relationships~\cite{sun2023think,ma2024think,wang2024knowledge}, while others employ the predefined rule~\cite{he2024g,gutierrez2024hipporag,li2024dalk,wu2024medical} to retrieve relevant structures from the constituted graph. 


% \zhou{Yingli stops here.}



% \zhou{Short version (1) Neglecting Relationships: 
% Traditional RAG cannot capture the structured relationships between different pieces of content.
% % 
% (2) Redundant Information: RAG often recounts content in the form of textual snippets when concatenated as prompts, leading to the ``lost in the middle" dilemma \cite{liu2024lost}.
% % 
% and (3) Lacking Global Information: RAG retrieves only a limited subset of documents, failing to capture comprehensive global information.}
% %
% To alleviate the above issues, Graph-based RAG proposed  by Graph-based RAG typically constructs knowledge graphs from raw corpus data to capture the semantic relationships within the knowledge.
% 
% 
% This limitation makes it ineffective for tasks like global sensemaking.


% \begin{table*}[ht]
%     \centering
%     \small
% \caption{Comparison of existing methods and our ArchRAG.}
%     \begin{tabular}{c|ccccc}
%         \toprule
% Methods & Index method & Specific QA & Abstract QA & Retrieval analysis & Low cost Generation  \\
%         \midrule
% Zero-shot / CoT \cite{kojima2022large} & None & \Yes & \No & \No & \Yes \\
% Vanilla RAG & Chunk text & \Yes & \No &\No & \Yes \\
% HippoRAG \cite{gutierrez2024hipporag} & Passage & \Yes & \No &\No & \Yes \\
% GraphRAG \cite{edge2024local}-Global Search & Community & \No & \Yes & \Yes & \No \\
% GraphRAG \cite{edge2024local}-Local Search & Community, Entity, Chunk text & \Yes & \No & \No & \Yes \\
% ArchRAG (ours) &  Community, Entity & \Yes & \Yes & \Yes & \Yes \\
%         \bottomrule
%     \end{tabular}
%     \label{tab:comparison}
% \end{table*}

\begin{table*}[ht]
    \centering
    \small
\caption{Comparison of representative RAG methods and our ArchRAG.}
    \begin{tabular}{c|ccccc}
        \toprule
RAG method & Retrieval method & Question & Attributed community & Hierarchical index & Retrieval filtering \\
        \midrule
Zero-shot / CoT \cite{kojima2022large} & None & Specific & \No & \No & \No \\
Vanilla RAG & Vector search & Specific & \No & \No & \No \\
GraphRAG \cite{edge2024local}  & Traverse & Specific\&abstract & \No & \Yes & \Yes \\
% GraphRAG \cite{edge2024local}-Local & Vector search & Specific & \No & \No & \Yes \\
LightRAG \cite{guo2024lightrag} & Extract keywords + Vector search & Abstract& \No & \No & \Yes \\
HippoRAG \cite{gutierrez2024hipporag} & PPR & Specific  & \No &\No & \Yes \\
\hline
{\bf ArchRAG (ours)}&  Hierarchical search & Specific\&abstract & \Yes & \Yes & \Yes \\
        \bottomrule
    \end{tabular}
    \label{tab:comparison}
\end{table*}

% \textbf{The SOTA works.}
%

% , the model can significantly enhance its performance in generating accurate and context-aware responses.
% On the other hand, {\tt GraphRAG}~\cite{edge2024local} enhances its performance on {\it Abstract QA} tasks by leveraging the community structure of KGs. It typically employs the Leiden method~\cite{traag2019louvain} for community detection, offering a global perspective to build relationships between textual information in chunks. Building on this structure, {\tt GraphRAG} introduces the {\tt Global Search} method, inspired by the {\it Map-Reduce} paradigm~\cite{dean2008mapreduce}. In the {\it Mapping} stage, all communities independently answer queries, generating partial responses. The {\it Reducing} stage then uses an LLM to analyze these answers, synthesizing them into a final, comprehensive response.
% In this approach, each community processes the query separately, generating partial answers based on its localized information. These partial responses are then aggregated into a final answer. 

While these approaches have achieved good performance in many scenarios, they still have some following limitations: 
% 
(1) GraphRAG detects communities by relying on the Leiden algorithm, which however only uses the graph structure without considering the rich semantic information carried by the nodes and edges. 
% 
As a result, the detected communities often consist of various different themes, which leads to the poor quality of community summaries and further decreases its performance.
% 
Besides, it uses LLMs to analyze all the communities when answering abstract questions, which is both time- and tokens-consuming.
% 
For example, the Leiden algorithm can detect 2,984 communities in the Multihop-RAG dataset, and to answer 100 questions, Global Search costs approximately \$650 and 106 million tokens\footnote{The cost of GPT-4o is \$10/M tokens for output and \$2.50/M tokens for input (for details, please refer to \href{https://openai.com/api/pricing/}{openai.com/api/pricing}).}, which is very token-consuming. 
% 
(2) LightRAG still cannot accurately identify the important keywords from the questions, which greatly affects its performance, and it does not generate community summaries in advance, making it difficult for the LLM to generate comprehensive summaries of all retrieved information.
% 
(3) HippoRAG fails to capture relationships between different chunks, making it susceptible to the ``lost in the middle'' dilemma \cite{liu2024lost}, which significantly prevents its ability to answer abstract questions, as it struggles to synthesize information across multiple chunks or understand overarching themes.

To tackle the above limitations, in this paper we propose a novel graph-based RAG approach, called \textbf{\underline{A}}tt\textbf{\underline{r}}ibuted \textbf{\underline{C}}ommunity-based \textbf{\underline{H}}ierarchical \textbf{\underline{RAG}} (ArchRAG), by augmenting the question using attributed communities from the knowledge graph built on the external corpus.
%
Unlike GraphRAG which detects communities purely using links, we propose to detect communities by exploiting both links and the attributes of nodes, and call them {\it attributed communities}.
%
Intuitively, an attributed community represents a group of nodes that are not only densely connected but also share similar themes, which provides detailed information for answering specific questions, and its summary offers a condensed view \cite{sarthi2024raptor,angelidis2018summarizing}, enabling more focused engagement with the content and making it suitable for answering abstract questions.
%
To effectively answer both abstract and specific questions, we then organize the attributed communities with summaries into a hierarchical structure, which provides different granularity of abstractions for the whole knowledge graphs.
% 
Besides, we develop a novel hierarchical data structure for searching the nearest neighbors and the corresponding efficient online retrieval method.

Specifically, to detect attributed communities that are organized in a hierarchical manner, we propose a novel LLM-based iterative framework, which can incorporate any existing attributed community detection method~\cite{zhou2009graph,traag2019louvain,von2007tutorial,xu2007scan,grover2016node2vec}.
%
In each iteration, we detect the attributed communities by considering both links and node attributes using a community detection method and generate a summary for each attributed community by using LLMs.
%
Afterwards, we build a new smaller attributed graph by abstracting each attributed community as a single node and then linking each pair of nodes together if their summary similarity exceeds a threshold.
%
By iterating the above steps multiple times, we can obtain a set of attributed communities that can be organized into a hierarchical tree structure.

Given the attributed communities organized hierarchically, to answer a question, a naive approach is to enumerate all the attributed communities and find the most relevant ones.
%
However, this approach, in line with that of GraphRAG, is very time and tokens-consuming.
%
To alleviate these issues, we propose to build a novel hierarchical index structure by borrowing some ideas from HNSW~\cite{malkov2018efficient}, which is a well-known approximate nearest neighbor (ANN) search method, and we call it C-HNSW (Community-based HNSW).
% 
C-HNSW index facilitates the fast retrieval of the $k$ most relevant elements from each layer of the hierarchy, optimizing the RAG process.
% 
Additionally, by using adaptive filtering, we identify the most relevant information, ensuring that complementary data are retrieved across all layers.
% 
Through hierarchical search, we achieve cost-efficient generation and optimize the retrieval process without sacrificing the quality of the generated output.

We have extensively evaluated ArchRAG by conducting various experiments on real-world datasets, and the results show that ArchRAG outperforms existing approaches in answering both abstract and specific questions.
% 
Particularly, ArchRAG achieves a 10\% high accuracy compared to state-of-the-art graph-based RAG methods when answering specific questions and also demonstrates significant improvement over others in answering abstract questions.
%
Moreover, ArchRAG is very token-efficient, saving up to 250 times the token usage compared to GraphRAG \cite{edge2024local}.

In summary, our main contributions are as follows:
\begin{itemize}%[left=0pt]
    \item We present a novel graph-based RAG approach by using attributed communities that are organized hierarchically and detected by an LLM-based hierarchical clustering method.
    
    %organized hierarchically and introducing a novel LLM-based hierarchical clustering method.

    \item To index attributed communities, we propose a novel hierarchical index structure called C-HNSW and also develop an efficient online retrieval method.
    
    %\item Extensive experiments show that ArchRAG achieves excellent performance in terms of accuracy and token cost.
    
    \item Extensive experiments show that ArchRAG is both highly effective and efficient, and achieves state-of-the-art performance in answering both abstract and specific QA tasks.
\end{itemize}



    %\item We propose an LLM-based attributed community detection framework that leverages the reasoning capabilities of LLMs while considering both nodes' textual attributes and graph structure.
    
    %\item {\tt ArchRAG} is a novel RAG method that adopts a hierarchical searching approach, providing both cost efficiency and suitability for Specific QA and Abstract QA tasks.
    % 
    % With this hierarchical community structure, we introduce a novel ANN method, C-HNSW, which supports nearest neighbor search at any layer, enabling rapid retrieval of the most relevant information in ArchRAG.


% 

% 
% Specifically, the community considers both the graph structure and textual attributes, leveraging LLMs to generate summaries and provide a global view \cite{edge2024local, sarthi2024raptor}. 
% 
% The hierarchical community index further matches problems across various layers, from detailed to global levels.
% % 
% Additionally, we propose a novel ANN method, C-HNSW, for rapidly retrieving the most relevant information at each layer.
% % 
% This method can handle data from all dimensions while reducing the need for LLM generation calls.
% % 
% Finally, by utilizing LLM analysis, ArchRAG adaptively identifies the most relevant contents from the retrieved information, ensuring complementary data across all layers.



% Besides, after carefully reviewing the existing graph-based RAG methods, we find that none effectively address both Specific QA and Abstract QA within a unified framework. 
% 
% 
% \emph{What we desire is a unified method capable of addressing both Specific QA and Abstract QA tasks while remaining cost-efficient.}
% 

% 

% \emph{What we desire is a both xxxxx and yyyyyy} In this paper, we xxxx. 



% 1. 介绍框架+方法：层次化社区+快速检索+LLM分析
% 2. 优势+如何整合：层次化社区同时考虑图结构和节点属性，借助LLM的能力生成摘要，总结全局信息；快速检索能够同时获取所有粒度下的信息，能够处理所有维度的数据，又能够节省LLM的生成调用；LLM分析能够稳定获得找到所有的结果。
% 3. contribution：新框架、新聚类算法+新C-HNSW、实验

% \textbf{Our contribution. }
% To address the above limitations, we propose \textbf{\underline{H}}ierarchical \textbf{\underline{C}}ommunity \textbf{\underline{A}}ugmented \textbf{\underline{R}}etrieval \textbf{\underline{A}}ugmented \textbf{\underline{G}}eneration framework (ArchRAG).

% 



% \textbf{Outline.}
% We present the preliminaries and problem formulation in Section \ref{sec:problem-formulation}.
% % 
% Section \ref{sec:motivation} analyzes the limitations of SOTA graph-based RAG methods.
% % 
% We introduce our ArchRAG framework in Section \ref{sec:ArchRAG}. 
% % 
% The experimental results are reported in Section \ref{sec:exp}.
% % 
% We review related work in Section \ref{sec:related-work} and conclude in Section \ref{sec:conclusion}.




% ToG \cite{sun2023think, ma2024think} proposes to prompt the LLM agent to perform the beam search on KGs and find multiple possible reasoning paths that help answer the question.

% 

% 

% Furthermore, most methods directly provide the retrieved data to the LLM for response generation without efficiently leveraging LLMs to analyze and select the retrieved information. 
% 
% For example, when the passages are lengthy, the data provided to the LLM by HippoRAG often contains significant redundant information.
% 
% It has been demonstrated that LLMs possess strong reasoning capabilities \cite{achiam2023gpt,hao2024llm,kojima2022large}, and by adopting a filtering approach, the ``lost in the middle'' dilemma \cite{liu2024lost} can be effectively mitigated.
% 
% Finally, GraphRAG's Global Search generates answers from many communities, which is inefficient and fails to generate responses cost-effectively, making it challenging to deploy in practice.
% 



% As a solution, both {\tt Global Search} and {\tt Local Search} are proposed.
% % 
% GraphRAG {\tt Global search} is a map-reduce approach: first, each community summary is used to answer the query independently and in parallel, and then all relevant partial answers are summarized into a final global answer.
% % 
% {\tt Local Search} first retrieves relevant entities, identifies the corresponding chunk texts and low-level communities, and directly generates the answer based on these retrieved content.
% 

% 1. 各种层次的问题
% 1. only sensemaking、only chunk not good
% 2 each for one task
% formor 处理sensemaking但high cost

% Although these two representative methods have achieved outstanding performance in detailed information retrieval for basic QA and high-level sensemaking tasks, they still exhibit certain limitations.
% % 
% In practice, users pose a wide range of questions to RAG systems. 


%  -- where the content in the middle of the prompt, even if it contains the correct answer, may be overlooked by the LLM. 

% \textbf{Motivations.} 



% 
% 4. 以MS GraphRAG 为代表的Graph RAG解决了以上3个问题，但仍存在一些问题
% 4.1 在构建index的过程中没能考虑属性等因素
% 4.2 成本高昂
% 4.3 没法适应 fine and coarse granularities 的问题，尽管有global and local search method, 没法满足各种问题中的粒度信息。
% 绘制表格，QA、summary task，打钩，low cost generation
% 
% However, the constructed KG may contain so many isolated vertices, due to the limited capability of LLM.
%
% That is, a similarity-based approach is employed to augment the constructed KG by connecting the edges that contain the two similar vertices to enhance its quality.
% u uses an LLM to transform a corpus into a schema-less KG and strengthens the connections between similar entities. 
% 
% It integrates information across passages for retrieval using  on the KG, with query concepts serving as seeds.
% 
% PPR enables HippoRAG to traverse KG paths and identify relevant subgraphs, thereby retrieving more accurate and relevant text passages.
