\subsection{Offline Indexing}


% 1. 整体流程 + 得到的index内容
% 2. Chunk2 Graph 详细介绍
% 3. LHC clustering+ motivation + 简要做法，提出详细做法在下一章节。
% 4. 构建C-HNSW + motivation : 节省查询token;提供全局视角;综合community+ entity
% Existing works \cite{peng2024graph,gutierrez2024hipporag,li2024dalk,wang2024knowledge} have shown that the text information dispersed within knowledge bases is rich in relationships, and methods such as extracting key entity relations and constructing knowledge graphs capture important semantic connections.

\subsubsection{KG construction.}
% \textbf{KG construction. }
Our first step is to build a KG by prompting the LLM to extract entities and relations from each chunk of the text corpus $D$.
% 
Specifically, all text contexts are segmented into chunks based on specified chunk length, enabling the LLM to extract entities and relations from each chunk using in-context learning~\cite{brown2020language}, thus forming subgraphs.
% 
These subgraphs are then merged, with entities and relations that appear repeatedly across multiple subgraphs being consolidated by the LLM to generate a complete description.
%
Finally, we get a KG, denoted by $G(V,E)$, where $V$ and $E$ are sets of vertices and edges, respectively, and each vertex and edge is associated with some textual attributes.


% % This process is referred to as Chunk2Graph construction, and formally, it is expressed as follows:

% \begin{align}
% G_i(V_i,E_i) &= LLM(P_e||C_i) \\
% \mathcal{G}(V,E)&=LLM(P_m||Merge(\bigcup_{i=1}^n G_i(V_i,E_i)))
% \end{align}

% Where $C_i$ represents a text chunk, with $i\in\{1..n\}$, and if $\mathcal{B}$ is divided into $n$ chunks, $G_i(V_i,E_i)$ is the subgraph extracted from each chunk,
% $P_e$ and $P_m$ are the prompts for extracting entities, relations, and merging entity-relations.

% LLM-based hierarchical clustering method to obtain the clustering result $HC$ can be implemented in the following steps: 
% \begin{enumerate}
%     \item Augment the KG with graph enhancements, such as KNN connections and CODICIL~\cite{CODICIL2013efficient}, to mitigate potential issues in the KG, including isolated nodes and missing relations.
%     \item Compute the attribute similarity between each pair of connected entities in the augmented graph and use these similarities as edge weights.
%     \item Apply a weighted graph clustering algorithm to detect communities, such as weighted Leiden \cite{traag2019louvain}, weighted spectral clustering, and SCAN \cite{xu2007scan}.
%     \item Use an LLM to generate a summary for each community.
%     \item Merge each community into a new node, using the summary as an attribute, and rebuild the graph based on the original connections.
%     \item Iteratively execute steps (1)–(5) until a terminal condition is met, such as insufficient nodes or reaching the specified level limit, ultimately yielding the result $HC$ with $L$ layer.
% \end{enumerate}

\subsubsection{LLM-based hierarchical clustering. } 
\label{sec:llm_cluster}
% 
As aforementioned, a high-quality hierarchical attributed community structure provides different granularities of abstraction for the entire knowledge graph, which is beneficial for answering both abstract and specific questions. 
% 
Therefore, we propose an iterative LLM-based hierarchical clustering framework that supports arbitrary graph augmentation (e.g., KNN connections and CODICIL~\cite{CODICIL2013efficient}) and graph clustering algorithms (e.g., weighted Leiden \cite{traag2019louvain}, weighted spectral clustering, and SCAN \cite{xu2007scan}).
% 
Specifically, we propose to augment the KG by linking entities if their attribute similarities are larger than a threshold (e.g., KNN connections), and then associate each pair of linked entities with a weight denoting their attribute similarity value.
%
Next, we generate the attributed communities using any given graph clustering algorithm.

Algorithm \ref{alg:LHC} shows the above iterative clustering process.
%
Given a graph augmentation method and clustering algorithm, we perform the following steps in each iteration:
(1) augmenting the graph (line 3);
(2) computing the edge weights (lines 4-5);
(3) clustering the augmented graph (line 6);
(4) generating a summary for each community using LLM (line 7);
and (5) building a new attributed graph where each node denotes an attributed community and two nodes are linked if their community members are connected (line 9).
%
We repeat the iterations until the stopping condition (such as insufficient nodes or reaching the specified level limit) is met.
%
Since each iteration corresponds to one layer, all the attributed communities $HC$ can be organized into a multi-layer hierarchical tree structure, denoted by $\Delta$, where each community in one layer includes multiple communities in the next layer.

Appendix \ref{sec:LHC} provides a running example for Algorithm \ref{alg:LHC}.

\begin{algorithm}[ht]
  \caption{LLM-based hierarchical clustering}
  \label{alg:LHC}
  \small
   \SetKwInOut{Input}{input}\SetKwInOut{Output}{output}
    \Input{KG ${G}(V,E)$, augment function \texttt{Aug}, graph clustering algorithm \texttt{GCluster}, and termination condition $T$}
    % \Output{The Hierarchical community ${HC}$}
    $T\gets$ {\tt False}, ${HC}\gets \emptyset$\;
    \Repeat{$T$={\tt True}}{
        % \tcp{\textcolor{teal}{(1) KG augmenting.}}
        ${G}'(V,E') \gets$ \texttt{Aug}(${G}(V,E)$)\;
        
        % \tcp{\textcolor{teal}{(2) Edge weight computing.}}
        \For{ each $e'=(u,v) \in E'$}{
            update the weight of $e'$ as $1 - \cos(z_u,z_v)$\;
        }

        % \tcp{\textcolor{teal}{(3) Weighted graph clustering.}}
        $C \gets$ \texttt{GCluster}(${G}'(V,E')$)\;
        \lFor{each $c \in C$}{
            generate the summary of $c$ by LLM
        }
        ${HC}\gets {HC} \cup C$\;
           
        % \tcp{\textcolor{teal}{(4) Graph reconstructing.}}
        ${G}(V,E) \gets$ build a new graph using $C$ and $E'$\; \tcp{\textcolor{teal}{update $T$ according to $G(V,E)$;}}
    }
    \Return{${HC}$;}
\end{algorithm}




% This method integrates graph structure and the attributions of the nodes, progressing from local details to high-level summaries and forming a hierarchical community structure.
% % leveraging the hierarchical structure to enhance the effectiveness of community-based retrieval and reasoning.
% % 


% The LHC clustering is a general clustering framework that leverages large models' reasoning capabilities to summarize each community's information and provide a global view.
% % 
% It is an iterative algorithm that transforms the attribute similarity of entities into edge weights, simultaneously capturing both the node attributes and the relationships between entities in the knowledge graph.
% % 

% LHC clustering first enhances the knowledge graph through a graph augmentation algorithm to increase the connections within the graph.
% % 
% While LLMs may merge subgraphs when constructing knowledge graphs, issues such as missing relations, entity duplication, and isolated nodes often remain. 
% % 
% Graph augmentation helps mitigate these problems, ensuring that semantically similar entities are grouped into the same community.
% % 
% Subsequently, the LHC clustering transforms the attribute similarity between nodes into edge weights, enabling the weighted clustering algorithm to capture both the node attribute relationships and the community structure based on the graph's topology. 
% % 
% For instance, the weighted Leiden \cite{traag2019louvain} algorithm can assign nodes with low similarity to different communities, which improves modularity.
% %
% After clustering, the nodes within the same cluster form a community and are merged into a new node. 
% % 
% We use an LLM to summarize each community, generating a synopsis of the relationships between the nodes within the community. 
% % 
% These summaries serve as the textual attributes of the community
% % 
% Based on the connections between nodes in different communities, we re-establish the connectivity between communities, thereby forming a new graph.
% % 
% The iterative process of LHC clustering ends when the number of nodes is insufficient or when the level reaches the specified limit.


% % 
% Algorithm \ref{alg:LHC} implements the procedure outlined above. 
% % 
 % After specifying the graph augmentation method and clustering algorithm, the process follows four steps: knowledge graph enhancement, weight computation, weighted clustering, and re-graphing. 
% % 
% Hierarchical clustering is completed once the iterative stopping condition is met, returning a community structure $\mathcal{HC}=\{C_1, C_2,\cdots, C_L\}$ with $L$ layers.
% % 


% For example, as shown in the second step of offline indexing in Figure \ref{fig:overview}, LHC clustering first enhances the original KG at layer $L_0$ by adding similar edges.
% % 
% Next, the weight of each edge is calculated based on the strength of the relationship between the node embeddings, and a weighted clustering algorithm is applied to obtain four communities.
% % 
% Based on the existence of links between nodes within a community, the topology of communities at layer $L_1$ is constructed, resulting in a graph of communities. 
% % 
% This process is repeated, ultimately generating a clustering result consisting of three layers of hierarchical communities.
% 
% We provide the algorithm of hierarchical clustering in the appendix.




% For large-scale corpora, existing methods either rely on semantic similarity to retrieve relevant information \cite{sarthi2024raptor,wang2024knowledge} or select a specific range of text \cite{edge2024local,li2024dalk}, which often leads to missing relevant content and excessive LLM calls. 
% 
% C-HNSW integrates the hierarchical structure of communities, unifies the storage of community and entity vector data, and supports fast retrieval of the most relevant communities and entities.
% 

\subsubsection{C-HNSW index.}
%
Given a query, to efficiently identify the most relevant information from each layer of the hierarchical tree $\Delta$, a naive method is to build a vector database for the attributed communities in each layer, which is costly in both time and space.
%
To tackle this issue, we propose to build a single hierarchical index for all the communities.
%
Recall that the attributed communities in $\Delta$ form a tree structure, and the number of nodes decreases as the layer level increases.
%
Since this tree structure is similar to the HNSW (Hierarchical Navigable Small World) index which is the most well-known index for efficient ANN search \cite{malkov2018efficient} (Appendix \ref{sec:c_hnsw} introduces its details), we propose to map entities and attributed communities of $\Delta$ into high-dimensional nodes, and then build a unified Community-based
HNSW (C-HNSW) index for them.


$\bullet$ \textbf{The structure of C-HNSW.}
%
Conceptually, the C-HNSW index is a list of simple graphs with links between them, denoted by $\mathcal{H} = ({\mathcal G},{L_{inter}})$ with $\mathcal{\mathcal G}=\{G_0=(V_0, E_0), G_1=(V_1, E_1), \cdots, G_L=(V_L, E_L)\}$, where $G_i$ is a simple graph and each node of the simple graph corresponds to an attributed community or entity.
%
%Conceptually, the C-HNSW index is a multi-layer graph with links between layers, denoted by $\mathcal{H} = ({\mathcal G},{L_{inter}})$, containing a set of simple graphs $\mathcal{\mathcal G}=\{G_0=(V_0, E_0), G_1=(V_1, E_1), \cdots, G_L=(V_L, E_L)\}$, where each node of a simple graph corresponds to an attributed community or entity.
%
The number $L$ of layers (simple graphs) of $\mathcal{H}$ is the same as the that of $\Delta$.
%
Specifically, for each attributed community or entity in the $i$-the layer of $\Delta$, we map it to a high-dimensional node in the $i$-th layer of $\mathcal H$ by using a language model (e.g., nomic-embed-text \cite{nussbaum2024nomic}).

After obtaining the high-dimensional nodes, we establish two types of links between them, i.e., {\it intra-layer} and {\it inter-layer} links:
%
\begin{itemize}
    \item {\bf Intra-layer links:} These links exist between nodes in the same layers. Specifically, for each node in each layer, we link it to at least $M$ nearest neighbors within the same layer, where $M$ is a predefined value, and the nearest neighbors are determined according to a given distance metric $d$.
    %
    Thus, all the intra-layer links are edges in all the simple graphs:
    \begin{equation}
        L_{intra}=\bigcup_{i=0}^{L}E_i
    \end{equation}

    \item {\bf Inter-layer links:} These links cross two adjacent layers. Specifically, we link each node in each layer to its nearest neighbor in the next layer. As a result, all the inter-layer links can be represented as follows:
        \begin{equation}
            L_{inter} = \bigcup_{i=1}^{L} \{(v,\psi(v))|v \in V_i,\psi(v)\in V_{i-1} \},
        \end{equation}
        where $\psi(\cdot):V_i \rightarrow V_{i-1}$ is the injective function that identifies the nearest neighbor of each node in the lower layer.
\end{itemize}

For example, in Figure \ref{fig:overview}, the C-HNSW index has three layers (simple graphs), incorporating all the attributed communities.
%
Within each layer, each node is connected to its two nearest neighbors via intra-layer links, denoted by undirected edges.
%
The inter-layer links are represented by arrows, e.g., the green community at layer $L_1$ is connected to the green entity (its nearest neighbor at layer $L_0$).

Intuitively, since the two types of links above are established based on nearest neighbors, C-HNSW allows us to quickly search the relevant information for a query by traversing along with these links.
%
Note that C-HNSW is different from HNSW since it has intra-layer links and each node exists in only one layer.

$\bullet$ \textbf{The construction of C-HNSW.}
A naive approach to build the C-HNSW index is to build nodes first and then establish the two types of links by finding the nearest neighbors of each node.
%
However, the process of finding the nearest neighbor is costly.
%
To accelerate the construction, we propose a top-down approach by borrowing the idea of HNSW construction.
% 
Specifically, by leveraging the query process of C-HNSW, which will be introduced in Section \ref{sec:search}, nodes are progressively inserted into the index starting from the top layer, connecting intra-layer links within the same layer and updating the inter-layer links.
%
For lack of space, we give the details of the construction algorithm in Appendix \ref{sec:c_hnsw}.


% reuses the community nodes $C_i$ ($i \in 1\cdots L$) at each layer of $HC$ and the entity nodes $V$ from the KG $G(V, E)$ to rebuild the nearest neighbor search structure.
% 
% Formally, C-HNSW is a multi-layer graph, denoted as $\mathcal{H} = ({\mathcal G},{\mathcal C})$, where $\mathcal{\mathcal G}=\{G_0=(V_0, E_0), G_1=(V_1, E_1), \cdots, G_L=(V_L, E_L)\}$ is a set of simple graphs formed by the nodes at each layer, and ${\mathcal C}$ records the {\tt cross-links} between communities and nearest neighbors in any two adjacent layers，i.e.,
% \begin{equation}
% \mathcal{C} = \bigcup_{i=1}^{L} \{(v,\psi(v))|v \in V_i,\psi(v)\in V_{i-1} \},
% \end{equation}
% where $\psi(\cdot):V_i \rightarrow V_{i-1}$ is the injective function that identifies the nearest neighbor of each node in the lower layer.

% At each layer, each node is connected to at least $M$ nearest neighbors, where $M$ is a predefined value, and the nearest neighbors are determined according to the given distance metric $d$.
% 
% To enable C-HNSW to perform indexing and retrieval at any layer, we connect each community to its nearest neighboring community or entity (for communities at layer 1) in the lower layer, denoted as the \texttt{cross-link}.
% 


% Motivated by this property, we use the hierarchical community structure to replace the repeated occurrence of the same node across multiple layers in HNSW, enabling C-HNSW to support the efficient retrieval of communities or entities at any layer.





% The construction algorithm of C-HNSW follows a top-down approach. 
% % 
% Using the query process of C-HNSW, we obtain the $M$ nearest neighbors of each node in its layer, and the \texttt{cross-links} are continuously updated during this process.
% % 
% When inserting a node $x$ at layer $i$ , if the nearest neighbor at the layer $i+1$ is $c_j$, the \texttt{cross-link} of $c_j$ is updated in the following two cases:
% \begin{itemize}
%     \item Node $c_j$ does not have a \texttt{cross-link} to the layer $i$.
%     \item The distance from node $c_j$ to node $x$ is smaller than the distance from $c_j$ to its previous nearest neighbor $x'$, i.e., $d(c_j,x) < d(c_j,x')$.
% \end{itemize}

% After all nodes at layer $i$ ($i<L$) have been inserted, we check each node at layer $i+1$ to ensure it has a \texttt{cross-link}, confirming the traverse from the higher layer to the lower layer.
% % 
% We provide the algorithm for the C-HNSW construction in the Appendix.






