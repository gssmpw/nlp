\subsection{Online retrieval}

% 1. 介绍motivation和整体步骤
% 2. 检索步骤
% 3. 生成步骤

%Our ArchRAG is a cost-efficient generation method designed to support both specific QA and abstract QA tasks.
%
In the online retrieval phase, after obtaining the query vector for a given question, ArchRAG generates the final answer by first conducting hierarchical search on the C-HNSW index, and then analyzing and filtering of retrieved information.

\subsubsection{Hierarchical search.} 
\label{sec:search}
% 
We first introduce the query process of C-HNSW and then describe the hierarchical search.
%
The query process is the core of C-HNSW, which can be used for constructing C-HNSW as illustrated in Algorithm \ref{alg:query}.

\begin{algorithm}[ht]
  \caption{{C-HNSW query}}
  \label{alg:query}
  \small
   \SetKwInOut{Input}{input}\SetKwInOut{Output}{output}
    \Input{$\mathcal{H} = ({\mathcal G},{L_{inter}})$, $q$, $k$, $l$.}
    % \Output{$k$ Nearest neighbor found by C-HNSW.}
    $s\gets $ a random node in the highest layer $L$\;
    \For{$i \gets L,\cdots,l+1$}{
        $c\gets$ SearchLayer(${ G_i}=(V_i,E_i), q, s, 1, i$)\;
        % $s\gets$ get the nearest node from $K$\;
$s\gets$ find the node in layer $i-1$ via the inter-layer links of $c$\;
    }
    $K\gets$ SearchLayer(${ G_l}=(V_l,E_l), q, s, k, l$)\;
    \Return{$K$;}
    
    \textbf{Procedure} SearchLayer(${G_i}=(V_i,E_i), q, s,k,i$)\;
    $V\gets \{s\}$,  $R\gets \{s\}$, $Q\gets $ initialize a queue containing $s$\; 
    \While{$|R|>0$}{
        $c \gets$ nearest node in $Q$\;
        $f \gets$ furthest node in $R$\;
        \lIf{$d(c,q)>d(f,q)$}{
            {\bf break}
        } 
        \For{each neighbor $x\in N(c)$ in $G_i$}{
            \lIf{$x \in V$}{\textbf{continue}}
            $V\gets V \cup \{x\}$\;
            $f \gets$ furthest node in $R$\;
            \If{$d(x,q)<d(f,q)$\text{ or }$|R|<k$ }{
                $Q\gets Q\cup \{x\}$, $R\gets R\cup \{x\}$\;
                \lIf{$|R|>k$}{remove $f$ from $R$}
            }
        }
    }
        
    \Return{${R}$;}
\end{algorithm}

Specifically, given a specified query layer $l$, query point $q$, and the number $k$ of nearest neighbors, the query algorithm can be implemented through the following iterative process:
\begin{enumerate}
    \item Start from a random node at the highest layer $L$, which serves as the starting node for layer $L$ (line 1).
    
    \item For each layer from layers $L$ to $l+1$, begin at the starting node and use a greedy traversal approach (i.e., the procedure SearchLayer) to find the nearest neighbor $c$ of $q$, and then traverse to the next layer using $c$'s inter-layer link as the starting node for the next layer (lines 2-4).
    
    \item In the query layer $l$, use the greedy traversal approach to find the $k$ nearest neighbors of $q$ (line 5).
\end{enumerate}

Specifically, the greedy traversal strategy compares the distance between the query point and the visited nodes during the search process.
% 
It achieves this by maintaining a candidate expansion queue $Q$ and a dynamic nearest neighbor set $R$, which contains $k$ elements:

\begin{itemize}
    \item Expansion Queue $Q$: For each neighbor $x$ of a visited node, if $d(x,q)<d(f,q)$, where $f$ is the furthest node from $R$ to $q$, then $x$ is added to the expansion queue.
    \item Dynamic Nearest Neighbor Set $R$: Nodes added to $C$ are used to update $R$, ensuring that it maintains no more than $k$ elements, where $k$ is the specified number of query results.
\end{itemize}

In the greedy traversal, if a node $x$ expanded from $Q$ satisfies $
d(n,q)>d(n,f)$, where $f$ is the furthest node from $R$ to $q$, then the traversal stops.


Based on the discussions above, we propose a hierarchical search approach, which retrieves the top $k$ relevant elements in each layer using the method outlined in Algorithm \ref{alg:query}.
% 
% We leverage the C-HNSW index and the C-HNSW query algorithm to retrieve the top $k$ nearest neighbors at each level, starting from the top layer.
% 
Once the query at a given layer is complete, we use the inter-layer link of the nearest neighbor in that layer to traverse to the next layer, repeating the process until reaching the bottom layer.
% 
At the bottom layer, we extract the relationships between connected retrieved entities, forming the text information $R_0$ for this subgraph.
% 
We represent the retrieved information from each layer as $R_i$, where $i \in \{0,1,\cdots, L\}$, to be used in the adaptive filtering-based generation process.

% C-HNSW leverages the structure of hierarchical communities and entities to efficiently query the most relevant information at any layer, including both communities and entities.
% % 
% At each layer, we select the top-k communities or entities most relevant to the query embedding to address queries with varying levels of detail.
% % 
% Specifically, starting from any point in the top layer, we progressively traverse and search, maintaining the nearest neighbor queue.
% 



\subsubsection{Adaptive filtering-based generation. }
While some optimized LLMs support longer text inputs, they may still encounter issues such as the ``lost in the middle'' dilemma \cite{liu2024lost}. 
% 
Thus, direct utilization of retrieved information comprising multiple text segments for LLM-based answer generation risks compromising output accuracy.

To mitigate this limitation, we propose an adaptive filtering-based method that harnesses the LLM’s inherent reasoning capabilities.
% 
We first prompt the LLM to extract and generate an analysis report from the retrieved information, identifying the parts that are most relevant to answering the query and assigning relevance scores to these reports.
% 
Then, all analysis reports are integrated and sorted, ensuring that the most relevant content is used to summarize the final response to the query, with any content exceeding the text limit being truncated.
% 
This process can be represented as:
\begin{align}
A_i &= LLM(P_{filter}||R_i) \\
Output&=LLM(P_{merge}||Sort(\{A_0,A_1,\cdots,A_n\}))
\end{align}
where $P_{filter}$ and $P_{merge}$ represent the prompts for extracting relevant information and summarizing, respectively, 
$A_i$, $i \in 0 \cdots n$ denotes the filtered analysis report.
% 
The sort function orders the content based on the relevance scores from the analysis report. 

We also analyze the complexity of ArchRAG in Appendix \ref{sec:complexity}.

% The Map-Reduce Analysis Generation approach enables the LLM to efficiently utilize a greater amount of retrieved information, leading to more accurate responses and summaries.
% % 
% By minimizing the number of LLM calls and leveraging the LLM's analytical reasoning, a more powerful RAG framework is achieved.