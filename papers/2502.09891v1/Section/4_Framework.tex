\section{Our Approach ArchRAG}
\label{sec:ArchRAG}

Unlike GraphRAG, which purely uses links to generate communities, we propose to detect communities that can be organized into a hierarchical tree structure by exploiting both links and attributes in the knowledge graph, also called attributed communities.
%
An attributed community is a group of entities with a summary, where the entities are not only densely connected but also share similar themes, providing detailed information for answering specific questions, and the summary can offer a condensed view for answering abstract questions since it enables more focused engagement with the entitiesâ€™ attributes.
%
Moreover, in the hierarchical tree structure, the lower-level communities and entities contain detailed knowledge from the KG, while higher-level communities provide global summaries, which naturally enable ArchRAG to address questions with different granularity in abstraction.

Moreover, to answer questions, we need to efficiently identify highly relevant attributed communities at different levels of the hierarchical structure.
% 
Considering that our hierarchical attributed communities and the HNSW index~\cite{malkov2018efficient} are similar in structure, we propose to map entities and attributed communities into high-dimensional nodes and then build a unified Community-based HNSW (C-HNSW) index for them, which allows us to efficiently identify the highly relevant attributed communities.

As illustrated in Figure~\ref{fig:overview}, our proposed ArchRAG consists of two phases. 
% 
In the {\it offline indexing} phase, ArchRAG first constructs a KG from the corpus, then detects attributed communities by a novel LLM-based hierarchical clustering method, and finally builds the C-HNSW index.
% Subsequently, to enable efficient retrieval, we propose a unified Community-based HNSW (C-HNSW) index to hierarchically organize both the attributed communities and entities, each of which is mapped into a high-dimensional vector.
% 
During the {\it online retrieval} phase, ArchRAG first converts the question into a query vector, then retrieves relevant information from the C-HNSW index, and finally generates answers through adaptive filtering-based generation process which identifies the most relevant information.

% 
%To avoid overwhelming the LLM with excessive retrieved information (e.g., the ``lost in the middle'' dilemma~\cite{liu2024lost}), we propose an adaptive filtering generation approach that first analyzes each retrieved information, then filters the content based on relevance, and finally generates the final response using the refined information.

% By efficiently searching and integrating retrieved information across various granularities, ArchRAG is highly cost-efficient and adaptable to questions of different levels of detail, namely, both specific and abstract questions.
%


% As illustrated in Figure~\ref{fig:overview}, our proposed ArchRAG also consists of two phases: {\it offline indexing} and {\it online retrieval}. 
% % 
% In the {\it offline indexing} phase, ArchRAG first constructs a KG by using LLM to extract entities and relationships from the corpus, and then detects attributed communities by a novel LLM-based hierarchical clustering method.
% %
% Subsequently, to enable efficient retrieval, we propose a unified Community-based HNSW (C-HNSW) index to hierarchically organize both the attributed communities and entities, each of which is mapped into a high-dimensional vector.

% During the {\it online retrieval} phase, ArchRAG first converts the question into a query vector, and then retrieve relevant information from the C-HNSW index by an efficient hierarchical search.
% % 
% To avoid overwhelming the LLM with excessive retrieved information (i.e., the ``lost in the middle'' dilemma~\cite{liu2024lost}), we propose an adaptive filtering generation approach that leverages LLM analysis to integrate the retrieved information, which first analyzes each retrieved information, filters the content based on relevance, and subsequently generates the final response using the refined information.
% % 
% By efficiently searching and integrating retrieved information across various granularities, ArchRAG is highly cost-efficient and adaptable to questions of different levels of detail, namely, both specific and abstract questions.
% %
% Next, we introduce the details of both offline and online phases of ArchRAG.

\input{Section/Framework/index}
\input{Section/Framework/online}
% \input{Section/Framework/complexity}



% \textbf{Motivation. } 
% Communities, which represent dense clusters of nodes within a graph network, have been widely applied across various domains \cite{dudleyExploitingDrugdiseaseRelationships2011,pesantez-cabreraEfficientDetectionCommunities2019,fortunatoCommunityDetectionGraphs2010,fangSurveyCommunitySearch2019,fortunatoCommunityDetectionNetworks2016,newmanFindingEvaluatingCommunity2004}. 
% % 
% Motivated by the ability of communities to capture both key information and provide a global perspective, we adopt an attributed community method.
% % 
% The lower-level communities and original node information contain detailed information from the KG, and the higher-level communities provide global summaries, enabling the framework to address both fine-grained specific questions and global abstract questions.
% % 
% Moreover, since only a small portion of the information in a query is relevant, we retrieve only the pertinent data at each layer and analyze it using the LLM, merging the information that satisfies the task requirements.
% % 
% This approach makes ArchRAG highly cost-efficient while integrating data across various granularities and adapting to questions of different levels of detail.



% by splitting the text into chunks and extracting entities and relations from the documents.
% % 
% Based on the KG, we iteratively perform attributed clustering and use an LLM to generate summaries for each community.
% 
% Finally, leveraging the attributed community structure, we construct C-HNSW to support the efficient retrieval of the most relevant community and entity information at each layer.

% During online retrieval, C-HNSW is utilized to search for the most relevant content related to the query at each layer.
% % 
% We then retrieve the most relevant communities and entities from C-HNSW for the query. 
% % 
% To leverage the analytical reasoning capabilities of the LLM, we adopt a Map-Reduce generation approach.
% % 
% In each map executor, the retrieved information is analyzed for relevant content that can assist in answering the query, and all the content is subsequently integrated to generate the final answer.


% In practice, RAG systems receive numerous query requests, and excessive retrieval of content can increase the generation load on the LLM, reducing the accuracy of the responses. 
% 
% Therefore, retrieving relevant content and leveraging large models for reasoning are critical steps in the RAG process.
% 


