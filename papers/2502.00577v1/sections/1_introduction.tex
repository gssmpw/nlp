\section{Introduction} \label{sec:1_introduction}
Multimodal large language models (MLLMs) have demonstrated remarkable capabilities in handling complex tasks that require reasoning over both visual and textual modalities. By leveraging {visual instruction tuning}~\cite{liu2023visual,dai2023instructblip,zhu2024minigpt}, 
MLLMs have shown promise in answering open-ended questions and generating contextually relevant captions.
As a critical aspect for real-world deployment, MLLMs are expected to operate robustly in the wild, where \textit{distribution shifts} occur---that is, when the evaluation data deviates from the instruction tuning data, whether due to changes in visual inputs (e.g, domain-specific images), textual inputs (e.g., linguistic variations), or the combination thereof. However, negative reports on MLLM failures under edge cases have steadily emerged, raising concerns about their reliability. 


For example, MLLMs struggle with queries in specialized domains such as medical and chemistry~\cite{zhang2024out,han2024well,zhou2024adapting}, perform poorly on simple image classification tasks compared with open-ended question answering~\cite{zhang2024vlmclf, zhai2024investigating}, and frequently exhibit hallucination \cite{li2023evaluating, ye2025beaf}. Given the increasing impact of MLLMs, it is crucial to understand their failure modes under distribution shifts. 
Despite the significance of the problem, existing works often lack a fine-grained diagnosis for various factors of shifts. More importantly, the absence of a formal framework to explain the underlying principle further hinders the systematic understanding of MLLMs' behavior. This motivates us to raise the research question:
\begin{center}
    \textit{\textbf{Could we derive a theoretical framework to characterize MLLM's behavior under distribution shifts?}}
\end{center}

To address this, we propose an information-theoretic framework that characterizes MLLM performance under distribution shifts with theoretical rigor and practical interpretability. Our framework is well-suited for analyzing instruction-tuned models, which effectively maximizes the lower bound of mutual information between input query and response. Under this framework, 
we introduce \emph{effective mutual information} (EMI) as a principled measurement for evaluating the relevance between an input query and model response. Intuitively, EMI is expected to be higher when a test input query originates from the in-distribution (ID) data similar to those used during instruction tuning, compared to when the input comes from out-of-distribution (OOD). To quantify this performance gap, we compute the difference in EMI between ID and OOD and derive an upper bound for this difference, expressed in terms of distributional discrepancies in input and output spaces (see Theorem~\ref{thm:emid_bound_simple} and~\ref{thm:emid_bound}). By grounding the measure in information theory, we provide the first theoretical framework to analyze and understand the impact of distribution shifts on MLLM performance.


Beyond the theoretical rigor, we further show that our framework holds practical value. In particular, we demonstrate that EMI is closely related to the widely used empirical evaluation metric for MLLMs, win rate~\cite{ouyang2022training} with an LLM judge~\cite{zheng2023judging}. The win rate commonly relies on external judge models such as GPT-4, thus it lacks mathematical guarantees due to the black-box nature of these evaluators. In contrast, EMI provides an \emph{theory-grounded measurement} of the relevance between input queries and the output responses of the MLLM being evaluated, offering a principled metric for assessing performance under distribution shifts.

Finally, we conduct empirical validation for the theoretical framework and show that our theorems empirically hold in real-world benchmarks. Our experiments comprehensively examine 34 synthetic and 27 natural distribution shift scenarios, resulting in a total number of 61 ID-OOD evaluations for each MLLM. Results confirm strong correlations between EMI and win rate, as well as between EMI difference and its upper bounds, demonstrating the effectiveness of our framework in capturing performance gaps under diverse shifts. Our contributions can be summarized as follows:
\begin{itemize}
    \item We propose a new framework, effective mutual information (EMI), to analyze MLLM under distribution shift, and justify the use of EMI by showing the theoretical connection between EMI and win rate.
    \vspace{-0.25em}
    \item We derive a theoretical upper bound of MLLM's performance gap which can be characterized by shifts over multimodal input queries and output discrepancies.
    \vspace{-0.25em}
    \item We empirically verify our theoretical statements on 61 real-world distribution shift scenarios of open-ended question-answering benchmarks with four MLLMs.
\end{itemize}