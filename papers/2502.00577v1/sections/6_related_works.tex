\vspace{-1em}
\section{Related Works} \label{sec:related_works}

\paragraph{Fine-tuned foundation models under distribution shifts.} 
Recent findings imply that fine-tuning on a relatively small amount of ID datasets hurts the OOD generalization capability of foundation models \cite{kumar2022fine, wortsman2022robust}. Although lots of follow-up studies \cite{goyal2023finetune, tian2023trainable, oh2025dawin} including theory-inspired methods \cite{kumar2022fine, pmlr-v162-ju22a, oh2024towards} have been proposed, almost all of them focused on a discriminative model such as CLIP \cite{radford2021learning} for the image classification task. Given the rapidly growing popularity of MLLMs, it is necessary to investigate the reliability of MLLMs under distribution shifts with a tangible formulation. We lay a cornerstone for this.
\vspace{-0.25em}
\paragraph{Performance analysis of MLLM.} There have been numerous reports on MLLMs' corner-case behaviors. \citet{zhang2024out}, \citet{zhou2024adapting}, and \citet{verma2024evaluating} observed that MLLMs poorly perform under specialized domains or synthetic perturbation, while  \citet{zhai2024investigating} and \citet{zhang2024vlmclf} showed that MLLMs are bad at some simple image classification tasks. Besides, \citet{li2023evaluating} and \citet{ye2025beaf} focused on the object hallucination of MLLM under spurious correlation. However, they all lacked a formal framework to explain such degradation of MLLMs. We recast the degeneration of MLLMs via robustness under distribution shifts between instruction-tuning and evaluation data \cite{liang2025aligning}, and devise the first theoretical framework to analyze MLLMs.

\paragraph{Information-theoretic approach for model evaluation.} As well as learning objectives \cite{alemi2016deep, chen2016infogan, Tschannen2020On, Kong2020A, wang2021infobert}, information-theoretic view has been steadily adopted to establish evaluation criteria for language model probing \cite{hewitt2021conditional}, prompt engineering \cite{sorensen2022information}, and rationale evaluation \cite{chen2023rev}, but relatively unexplored for MLLM yet. We also note some works adopting information-theoretic approaches to analyze models under distribution shifts \cite{federici2021information, shui2022novel}. Although they focused on classification tasks with discriminative models, we established new theorems for MLLM analysis based on our new metric, EMI.
