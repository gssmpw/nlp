%\vspace{-1em}
\section{Discussion} \label{sec:conclusion}
This work urged the development of a formal framework to understand MLLMs under distribution shifts which is unexplored yet crucial for reliable artificial intelligence in the wild. As a first step for this, we devised effective mutual information (EMI) as a metric for MLLM evaluation and showed its theoretical connection to an existing standard metric, win rate. Then, we provide a theoretical upper bound for an MLLM's EMI difference between ID and OOD that consists of JS divergence terms for marginal and conditional distributions of input/output variables. Through experiments on a benchmark spanning 61 distribution shifts, we show the correlation between win rate and EMI, and further show the correlation between EMI difference and its upper bound thereby empirically verifying our theoretical upper bound.

\vspace{-0.2cm}
\paragraph{Practical implication.} 
As shown in Table \ref{tab:wr_emi_corr}, EMI strongly correlates with win rate. Compared to the win rate, the MI estimator can be computed more efficiently without relying on computationally expensive judge LLM \cite{achiam2023gpt} (see Appendix \ref{appendix:experiment:practical} for details). Therefore, EMI can be leveraged as a cost-efficient and theoretically grounded evaluation metric that measures effective relevance between multimodal queries and open-ended responses. Besides, the upper bound of EMID can be adopted as a regularizer during post-training or test-time adaptation of MLLM to improve its robustness to distribution shifts \cite{li2023robust}.

\vspace{-0.2cm}
\paragraph{Limitation and future work.} 
Although input-output relevance measured by EMI is one of the most important properties for instruction-following assistant models, other crucial quality attributes are not captured by the form of relevance term. Extending the theory to support evaluation across multiple facets of MLLM will be promising future work direction. Besides, we have simulated some intuitive types of distribution shifts with the simplified assumption for data structure, while leaving some complex shifts driven by spurious correlation \cite{simon1954spurious} that may be covered by Theorem \ref{thm:emid_bound}. Validation of theorems on such non-trivial distribution shifts could be an important extension.