\begin{table}[]
\caption{\textbf{Runtime comparison on LLaVA-Bench COCO 90 samples.} We compare the actual wall-clock time (second) of EMI estimation and MLLM judgment protocols by evaluating model-generated response and reference response given input query from the LLaVA-Bench COCO dataset \cite{liu2023visual}. EMI estimation protocol on top of CLIP ViT-B/32 and XLM-RoBERTa-Base embedding achieves 138 times boosting from MLLM judgment protocol with GPT-4o. }
\centering
\scriptsize
\begin{tabular}{@{}l|cc|cc|cc|cc||c@{}}
\toprule
 & \multicolumn{2}{c}{LLaVA v1.5 7B} & \multicolumn{2}{c}{LLaVA v1.5 13B} & \multicolumn{2}{c}{LLaVA NeXT 7B} & \multicolumn{2}{c}{LLaVA NeXT 13B} & Total runtime              \\ 
 & per instance       & dataset      & per instance       & dataset       & per instance       & dataset      & per instance       & dataset       & \multicolumn{1}{l}{} \\ \midrule
%\rowcolor[HTML]{E8E8E8} 
\textcolor{gray}{MI estimator training} & \multicolumn{8}{c||}{\textcolor{gray}{663.45}}                                            & \textcolor{gray}{663.45}  \\ \midrule
EMI estimation      & 0.0388 & 3.5884 & 0.0392 & 3.5652 & 0.0412 & 3.7107 & 0.0411 & 3.7039 & 14.56 (\textcolor{teal}{$\times$ 138 boosting}) \\
MLLM judgment (GPT-4o API) & 5.49   & 493.75 & 5.48   & 493.59 & 5.52   & 496.66 & 5.83   & 524.45 & 2008.45 \\ \bottomrule
\end{tabular} \label{tab:runtime}
\end{table}