%-------------------------v2 version------------------------------
\section{Introduction}
\label{sec:intro}
\begin{figure}[t]
    \centering
    \includegraphics[width=0.9\linewidth]{sec/fig/teaser1_v2.pdf}
    \caption {MGM-in-the-wild\cite{park2023mgmwild} often fail in real-world applications, particularly when handling fine-grained object details and reducing edge errors. We propose \textbf{Mask2Alpha} to address the difficulties of real-world scenarios.}
    \label{fig:teaser}
\end{figure}

\begin{figure*}[t]
    \centering \includegraphics[width=0.8\linewidth]{sec/fig/teaser2-v2.pdf}
    \caption{\textbf{Iterative Optimization Process.} The Mask2Alpha framework operates in two stages: (a) Semantic Iterative Optimization - begins by refining high-confidence regions through a state transition matrix, where the first row represents the input mask, the second row displays the state transition, and the third row shows the resulting semantic output; (b) Detail Iterative Optimization - progressively enhances uncertain fine details following semantic refinement, aiming to recover the optimal solution across varying resolutions.}
    \label{fig:iterate}
\end{figure*}


Image matting is a fundamental problem in computer vision, aiming to separate foreground objects from the background through accurate alpha matte estimation. Traditional methods typically rely on user-defined trimaps~\cite{wang2007optimized, Sun2004PoissonM, aksoy2017designing}, which help reduce uncertainty by clearly delineating foreground, background, and unknown regions. Other approaches have incorporated scribbles~\cite{zheng2008fuzzymatte, wang2005iterative} or background knowledge~\cite{backgroundmatting, backgroundmattingv2} to assist in matting, while recent works have increasingly focused on using automatically generated segmentation masks~\cite{park2023mgmwild, yu2021mgm, huynh2024maggie}. Following this trend, we also leverage segmentation masks as key auxiliary information in our approach. 

Despite these advances, real-world image matting remains challenging due to the complexity of scenes, semantic ambiguity, and the need for high-resolution processing. As shown in \cref{fig:teaser}, real-world images often suffer from a lack of precise semantic information, particularly in regions where object boundaries are unclear, leading to errors in foreground-background separation. This is further compounded by the challenge of recovering fine details, which are essential for accurate matting but difficult to extract in complex scenes. Inspired by iterative image generation techniques~\cite{maskgit}, we propose a novel iterative framework, Mask2Alpha, which progressively refines alpha matte predictions. As shown in the process illustrated in \cref{fig:iterate}, our method begins by focusing on high-confidence regions and iteratively corrects low-confidence areas, thereby improving the overall accuracy of the matte. This iterative approach allows our model to better handle the inherent complexity of real-world scenes and recover fine details more effectively.

Another major challenge is the scarcity of large, diverse datasets that accurately capture the complexity of real-world scenes, limiting the generalization capabilities of existing matting models. Most available datasets focus on specific object categories or simple scenes, leaving a gap in the ability of models to generalize to more complex and diverse environments. To address this, we leverage visual foundation models(VFMs), which have shown great promise in capturing rich, semantic representations of images without the need for extensive labeled data~\cite{caron2021emerging}. By incorporating a mask-guided feature enhancement module, our approach refines the semantic understanding of the scene, enabling the model to focus on relevant features of the target instance while filtering out irrelevant background or noise. This explicit guidance improves the accuracy of alpha matte computation, even in the most challenging real-world settings.

Lastly, handling high-resolution images is crucial for preserving fine details, but it also brings substantial computational challenges, especially when iterative refinement is required. High-resolution image matting requires intense focus on fine details from high-resolution data, while other regions often introduce significant computational redundancy. Methods like SparseMat~\cite{sun2023sparsemat} leverage sparse convolution to enhance high-resolution processing. However, these methods rely on dilating low-resolution results to select sparse regions, which can lead to inefficient thresholds that either increase computational load or compromise detail retention. To address this, we propose a self-guided sparse region selection strategy that dynamically identifies key regions for refinement without morphological operations. This approach optimizes computational efficiency while preserving high-quality detail.

In summary, Mask2Alpha combines mask-guided input, VFMs feature enhancement, and a coarse-to-fine optimization strategy to tackle the complex challenges of matting in real-world environments. By addressing issues such as boundary confusion, dataset limitations, and high-resolution processing, we present a novel framework that advances the state-of-the-art in image matting.

Our contributions can be summarized as follow:

\begin{itemize} \item[$\bullet$] We propose a mask-guided image encoder, which leverages high-level contextual information from visual foundation models, resulting in enhanced matting quality in semantically complex scenes.

\item[$\bullet$] We propose an iterative refinement framework that progressively enhances alpha matte predictions by initially focusing on high-confidence regions, effectively improving detail in edge-confused areas where mask boundaries are ambiguous.

\item[$\bullet$] We introduce a self-guided sparse detail recovery module that dynamically targets key areas for refinement, ensuring efficient high-resolution processing and precise detail recovery. 
\end{itemize}

