\section{Conclusion}
In this work, we introduced Mask2Alpha, a novel framework designed to overcome the challenges of image matting. Our extensive experiments demonstrate that Mask2Alpha significantly outperforms existing methods, particularly in complex and cluttered environments. By integrating iterative refinement and instance-aware processing, our approach effectively addresses the challenges of matting in complex scenes, particularly in handling fine details and object boundaries. The integration of a mask-guided feature selection module enhances the model's ability to distinguish between multiple instances, which is crucial for matting in complex scenes. Additionally, the use of self-supervised ViT features allows the model to capture high-level contextual information, further improving its performance in diverse and semantically rich scenarios. The lightweight decoder effectively fuses low-level visual details with semantic understanding, ensuring computational efficiency without compromising performance.