\section{Method}
\label{sec:method}

\begin{figure*}[t!]
    \centering
    \includegraphics[width=\textwidth]{figures/meta_a.pdf}
    \caption{\textbf{Meta-architecture of the proposed \modelname}. \modelname builds on top of an off-the-shelf clustering-based mask transformer, incorporating dictionary components that function as the cluster centers for each semantic class. Throughout training, the dictionary components in \modelname are updated via both mask-wise objectives from the transformer and contrastive objectives from the dictionary. During testing, \modelname adopts a straightforward inference approach by executing nearest neighbor search of the pixel features on the dictionary components.}
    \label{fig:meta}
\end{figure*}

In this section, we begin with a brief overview of existing cluster-based mask transformer segmentation frameworks, providing context for the introduction of our key innovations. We then delve into the modifications we've made, particularly the integration of sets of dictionary components aligned with the semantic hierarchy. This tailored approach forms the basis of our dictionary-based mask transformer framework, specifically optimized for object parsing. Afterwards, our discussion focuses on two main aspects: the implementation of contrastive components, enhancing effectiveness and interpretability, and the incorporation of logical constraints, crucial for improving parsing consistency. Finally, we provide a detailed exploration of the meta-architecture of \modelname, elucidating the structural components and operational dynamics of the system.

\subsection{Recap of Cluster-based Mask Transformer}
\label{subsec:method-recap}
Cluster-based mask transformers~\cite{yu2022cmt,yu2022k,liang2023clustseg} have demonstrated considerable efficacy across a range of segmentation tasks. To provide a universal context, our discussion primarily focuses on semantic segmentation:

\noindent\textbf{Problem Statement}\quad
Semantic segmentation aims to divide an image $\mathbf{I} \in \mathbb{R}^{\mathit{H} \times \mathit{W} \times \mathit{3}}$ into distinct, non-overlapping masks, each associated with a semantic label. This process is formalized as follows:
\begin{equation}
\begin{aligned}
    \{y_{i}\}_{i=1}^{M_p} = \{(d_{i}, c_{i})\}_{i=1}^{M},
    \label{formula:mask_gt}
\end{aligned}
\end{equation}
where $d_{i} \in {\{0,1\}}^{H \times W}$ identifies whether a pixel is part of a specific region, $c_{i}$ represents the corresponding class label and $M$ denotes the total number of ground-truth masks.

In contrast to traditional approaches, cluster-based mask transformers generate a prediction set that mirrors the format of the ground-truth, comprising $N$ masks (where $N$ is a predetermined number satisfying $N \ge M$) along with their class associations:
\begin{equation}
\begin{aligned}
    \{\hat{y}_{i}\}_{pi=1}^{N} = \{(\hat{m}_{i}, \hat{c}_{i})\}_{pi=1}^{N}.
    \label{formula:mask_pred}
\end{aligned}
\end{equation}

These $N$ masks are derived from object queries that consolidate information from pixel features. The key distinction between cluster-based mask transformers and standard query-based transformers is evident in their respective updating mechanisms. Specifically, the query-based mask transformer updates the object queries as follows:

\begin{equation}
\begin{aligned}
    \mathbf{\hat{O}} &= \mathbf{O} + \operatornamewithlimits{softmax}_{HW}(\mathbf{Q}^{o} \times (\mathbf{K}^p)^\mathrm{T}) \times \mathbf{V}^p,
    \label{formula:cross-attn}
\end{aligned}
\end{equation}
while cluster-based mask transformer exploits:
\begin{equation}
\begin{aligned}
    \mathbf{\hat{O}} &= \mathbf{O} + \operatornamewithlimits{argmax}_{N}(\mathbf{Q}^{o} \times (\mathbf{K}^p)^\mathrm{T}) \times \mathbf{V}^p,
    \label{formula:kmeans-attn}
\end{aligned}
\end{equation}
where $\mathbf{O} \in \mathbb{R}^{N \times D}$ symbolizes the $N$ object queries with $D$ channels, and $\mathbf{\hat{O}}$ represents the updated queries. $\mathbf{Q}^{o} \in \mathbb{R}^{N \times D}, \mathbf{K}^p \in \mathbb{R}^{HW \times D}, \mathbf{V}^p \in \mathbb{R}^{HW \times D}$ represent the linearly projected features for the query, key, and value, respectively. The notations $HW$ and $N$ indicate the axes for the \textit{softmax} and \textit{argmax} operations on the pixel and query dimensions, respectively. The superscripts $p$ and $o$ denote the features projected from pixel features and object queries, correspondingly.

Intuitively, these update rules explicitly compute the affinity between object queries and pixel features (\ie, $\mathbf{Q}^{o} \times (\mathbf{K}^p)^\mathrm{T}$), followed by assigning a one-hot cluster assignment to each pixel via the \textit{argmax} operation. This assignment clusters affiliated pixel features to update the corresponding object queries. The updated queries $\mathbf{\hat{O}}$ are then used to generate the prediction set $\hat{y}$, which is matched with the ground-truth set $y$ through Hungarian Matching~\cite{Kuhn1955NAVAL} during training to compute the losses. For a more detailed exposition of cluster-based mask transformers, the reader is referred to kMaX-Deeplab~\cite{yu2022k}.

\subsection{Dictionary-based Mask Transformer Framework}
\label{subsec:method-dict}
Building upon the cluster-based mask transformers, we introduce the concept of dictionary-based mask transformer. This architecture primarily pivots on the integration of a set of dictionary components, which supersedes the use of object queries $C$ in traditional models. Specifically, the dictionary $\mathbf{C} \in \mathbb{R}^{P \times D}$ comprises $P$ learnable components, each dedicated to grouping pixels associated with a specific class, where $P$ also represents the number of classes.

A key distinction of the dictionary-based mask transformers, as compared to query-based or cluster-based mask transformers, lies in its structural efficiency. Traditional mask transformers typically encompass a larger number of object queries $\mathbf{O} \in \mathbb{R}^{N \times D}$ than the number of classes, necessitating the filtering of redundant queries through `void' classes. In contrast, our dictionary-based mask transformer maintains an exact one-to-one correspondence between the dictionary components and the classes. This direct alignment facilitates a streamlined training process, where $\mathbf{C}$ is updated following Eq.~\ref{formula:kmeans-attn}. Consequently, the Hungarian Matching process is replaced by fixed matching mechanism (\ie, $C_i$ corresponds to the cluster center of class $p_i$).
% , which is discussed in ~\ref{subsec:ablation-studies}.

In the testing phase, the dictionary-based mask transformer exhibits its efficiency through a parameter-free operation. It accomplishes this by conducting a per-pixel nearest neighbor search within the pixel feature maps, utilizing the dictionary $\mathbf{C}$. This method grants the dictionary-based mask transformer a cohesive, simplified, and easily interpretable architecture, both in training and testing, which is specially designed for object parsing.

\subsection{\modelname: Interpretable and Consistent Object Parsing}
\label{subsec:method-framework}
\noindent \textbf{Hierarchical Structure of Dictionaries Across Multiple Levels}\quad The classification labels for various parts inherently contain rich logical information within their structure. For example, the label `dog-head' logically suggests a closer relationship to `dog-torso' than to `fish-tail'. To utilize these implicit logical relationships inherent in structured labels, \modelname extends the dictionary-based mask transformer into a hierarchically structured framework.

Specifically, \modelname introduces an additional tier of object-level classes on top of the part-level classes, aligning with their semantic context. This structure mirrors the formulation used for parts, and we denote the object-level dictionary as $\mathbf{\widetilde{C}} \in \mathbb{R}^{\widetilde{P} \times D}$, where $\widetilde{P}$ is the number of learnable dictionary components corresponding to the number of object classes.

\noindent \textbf{Enhancing Dictionary Discrimination Through Contrastive Objectives}\quad
For the effective training of \modelname, we utilize contrastive learning to discern and learn discriminative dictionary components. The underlying principle is intuitive: components associated with the same class should exhibit similarity and, thus, are brought closer together, whereas those from different classes are separated.

Taking the part dictionary $\mathbf{C}$ as an example, \modelname incorporates a part memory bank $\mathbf{B} \in \mathbb{R}^{P \times S \times D}$, where $S$ represents the number of samples of each class stored in the dictionary. This memory bank stores the dictionary components for the observed parts during training. Given a ground-truth set $y$, \modelname retrieves the relevant dictionary components $\mathbf{C}(y)$ from $\mathbf{C}$. These components correspond to all the parts that have manifested in the training data. The contrastive loss is then computed based on these retrieved components.

This approach facilitates the creation of more distinct and separate clusters of dictionary components, thereby improving the accuracy and robustness of \modelname. By leveraging contrastive learning, \modelname not only distinguishes between different classes more effectively but also enhances the overall coherence and interpretability of the segmentation results. The contrastive loss is formulated as:
\begin{small}
\begin{equation}
    \mathcal{L}_{p\_con}(\mathbf{C}(y)) = \sum_{x \in M}\frac{-1}{|\mathbf{B}(x)|}\sum_{j \in \mathbf{B}(x)}\log\frac{\exp(\mathbf{C}(y)_i \cdot B_j / \tau)}{\sum_{k \in \mathbf{B}}\exp(\mathbf{C}(y)_i \cdot B_k / \tau)},
    \label{formula:contrast_p}
\end{equation}
\end{small}where $\mathbf{B}(x)$, $B_j$ and $\mathbf{C}(y)_i$ denote the memory bank components belonging to class $x$ in $\mathbf{B}$, memory bank components in $\mathbf{B}$ and dictionary components in $\mathbf{C}(y)$, respectively. $\tau \in R^+$ is a scalar temperature parameter. Motivated by~\cite{lin2017focal, robinson2020contrastive}, we additionally exploit hard negative mining to put more focus on hard examples, where we only select top-k hardest samples defined by the cosine similarity from $\mathbf{B}$ when calculating Eq. \ref{formula:contrast_p}. Similarly, we maintains the object memory bank $\widetilde{\mathbf{B}}$ and apply the same contrastive loss on the object dictionary $\mathbf{\widetilde{C}}$ as:
\begin{small}
\begin{equation}
    \mathcal{L}_{o\_con}(\mathbf{\widetilde{C}}(y)) = \sum_{x \in M}\frac{-1}{|\mathbf{\widetilde{B}}(x)|}\sum_{j \in \mathbf{\widetilde{B}}(x)}\log\frac{\exp(\mathbf{\widetilde{C}}(y)_i \cdot \widetilde{B}_j / \tau)}{\sum_{k \in \mathbf{\widetilde{B}}}\exp(\mathbf{\widetilde{C}}(y)_i \cdot \widetilde{B}_k / \tau)},
    \label{formula:contrast_o}
\end{equation}
\end{small}where $\mathbf{\widetilde{B}}(x)$, $\widetilde{B}_k$ and $\mathbf{\widetilde{C}}(y)_i$ denote the memory bank components belonging to class $x$ in $\mathbf{\widetilde{B}}$, memory bank components in $\mathbf{\widetilde{B}}$ and dictionary components in $\mathbf{\widetilde{C}}(y)$.

\begin{figure}[]
    \centering
    \includegraphics[width=0.5\textwidth]{figures/figure3.pdf}
    \caption{\textbf{Illustration of logical constraints at inference.} In this picture, a reptile-head and reptile-body are wrongly predicted as the snake-head and snake-body, respectively. \modelname corrects the wrong prediction by computing the logical path probability through multiplying the part-level probability and object-level probability and re-assigns the labels along the path thus producing the correct part prediction.}
    \label{fig:logical}
\end{figure}

\noindent \textbf{Logical constraints for consistent predictions}\quad
To alleviate the potential inconsistency in part class prediction within the same object or cross-level prediction, we explore logical constraints following the innate semantic hierarchy to encourage the consistency at training and put constraints at inference. Based on that, \modelname explores two crucial logical constraints. More specifically, motivated by the fact that the part dictionary components should be closer to its corresponding object dictionary components compared to other object dictionary components, we apply the cross-level contrastive loss as: 
\begin{small}
\begin{equation}
    \mathcal{L}_{logic}(\mathbf{C}(y)) = \sum_{x \in M}\frac{-1}{|\mathbf{\widetilde{B}}(x)|}\sum_{j \in \mathbf{\widetilde{B}}(x)}\log\frac{\exp(C(y)_i \cdot \widetilde{B}_j / \tau)}{\sum_{k \in \mathbf{\widetilde{B}}}\exp(C(y)_i \cdot \widetilde{B}_k / \tau)}.
    \label{formula:contrast_cross}
\end{equation}
\end{small}Note that Eq.~\ref{formula:contrast_cross} models the cross-level contrastive relations and encourages parts belonging to the same object to share similar features. As a result, different parts within one object will tend to have the same object class prediction thus effectively alleviates the inconsistency problem. Furthermore, \modelname takes the fact that if a pixel belongs to a certain part, it must also belongs to the corresponding object and models this as a post-processing function during testing. Concretely, as shown in Fig.~\ref{fig:logical}, \modelname first calculates the logical path probability through multiplying the part-level class probability and object-level class probability obtained through nearest neighbor search followed by assigning each pixel with the labels in the top-scoring path.

\noindent \textbf{Meta-Architecture Overview}\quad 
As illustrated in Fig.~\ref{fig:meta}, the meta-architecture of our proposed \modelname is a comprehensive framework that incorporates several crucial elements. It builds on top of an off-the-shelf cluster-based mask transformer, which is responsible for extracting pixel features. The core of the architecture is formed by the part and object dictionaries, crucial for storing discriminative dictionary components capable of grouping pixels based on their respective semantic classes. In tandem with these dictionaries, the part and object banks are meticulously designed to retain a history of observed components, a key element for contrastive loss calculation within and across semantic levels. Consequently, these modules collectively constitute \modelname, an innovative and cohesive dictionary-based framework for object parsing. This approach guarantees interpretability and consistency by embedding a logical, hierarchical structure into the segmentation process. Through this methodology, \modelname represents a significant advancement in object parsing, offering a structured and logical approach to comprehending complex image compositions.