[
  {
    "index": 0,
    "papers": [
      {
        "key": "sutton1988learning",
        "author": "Sutton, Richard S",
        "title": "Learning to predict by the methods of temporal differences"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "10124081",
        "author": "Shen, Han and Zhang, Kaiqing and Hong, Mingyi and Chen, Tianyi",
        "title": "Towards Understanding Asynchronous Advantage Actor-Critic: Convergence and Linear Speedup"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "nair2015massively",
        "author": "Nair, Arun and Srinivasan, Praveen and Blackwell, Sam and Alcicek, Cagdas and Fearon, Rory and De Maria, Alessandro and Panneershelvam, Vedavyas and Suleyman, Mustafa and Beattie, Charles and Petersen, Stig and others",
        "title": "Massively parallel methods for deep reinforcement learning"
      },
      {
        "key": "liang2018rllib",
        "author": "Liang, Eric and Liaw, Richard and Nishihara, Robert and Moritz, Philipp and Fox, Roy and Goldberg, Ken and Gonzalez, Joseph and Jordan, Michael and Stoica, Ion",
        "title": "RLlib: Abstractions for distributed reinforcement learning"
      },
      {
        "key": "pan2022optimizing",
        "author": "Pan, Lichen and Qian, Jun and Xia, Wei and Mao, Hangyu and Yao, Jun and Li, Pengze and Xiao, Zhen",
        "title": "Optimizing communication in deep reinforcement learning with xingtian"
      },
      {
        "key": "zhu2023msrl",
        "author": "Zhu, Huanzhou and Zhao, Bo and Chen, Gang and Chen, Weifeng and Chen, Yijie and Shi, Liang and Yang, Yaodong and Pietzuch, Peter and Chen, Lei",
        "title": "$\\{$MSRL$\\}$: Distributed Reinforcement Learning with Dataflow Fragments"
      },
      {
        "key": "mei2023srl",
        "author": "Mei, Zhiyu and Fu, Wei and Gao, Jiaxuan and Wang, Guangju and Zhang, Huanchen and Wu, Yi",
        "title": "SRL: Scaling Distributed Reinforcement Learning to Over Ten Thousand Cores"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "espeholt2019seed",
        "author": "Espeholt, Lasse and Marinier, Rapha{\\\"e}l and Stanczyk, Piotr and Wang, Ke and Michalski, Marcin",
        "title": "Seed rl: Scalable and efficient deep-rl with accelerated central inference"
      },
      {
        "key": "petrenko2020sample",
        "author": "Petrenko, Aleksei and Huang, Zhehui and Kumar, Tushar and Sukhatme, Gaurav and Koltun, Vladlen",
        "title": "Sample factory: Egocentric 3d control from pixels at 100000 fps with asynchronous reinforcement learning"
      },
      {
        "key": "zhu2023msrl",
        "author": "Zhu, Huanzhou and Zhao, Bo and Chen, Gang and Chen, Weifeng and Chen, Yijie and Shi, Liang and Yang, Yaodong and Pietzuch, Peter and Chen, Lei",
        "title": "$\\{$MSRL$\\}$: Distributed Reinforcement Learning with Dataflow Fragments"
      },
      {
        "key": "mei2023srl",
        "author": "Mei, Zhiyu and Fu, Wei and Gao, Jiaxuan and Wang, Guangju and Zhang, Huanchen and Wu, Yi",
        "title": "SRL: Scaling Distributed Reinforcement Learning to Over Ten Thousand Cores"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "mnih2016asynchronous",
        "author": "Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray",
        "title": "Asynchronous methods for deep reinforcement learning"
      },
      {
        "key": "assran2019gossip",
        "author": "Assran, Mahmoud and Romoff, Joshua and Ballas, Nicolas and Pineau, Joelle and Rabbat, Michael",
        "title": "Gossip-based actor-learner architectures for deep reinforcement learning"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "recht2011hogwild",
        "author": "Recht, Benjamin and Re, Christopher and Wright, Stephen and Niu, Feng",
        "title": "Hogwild!: A lock-free approach to parallelizing stochastic gradient descent"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "horgan2018distributed",
        "author": "Horgan, Dan and Quan, John and Budden, David and Barth-Maron, Gabriel and Hessel, Matteo and Van Hasselt, Hado and Silver, David",
        "title": "Distributed prioritized experience replay"
      },
      {
        "key": "espeholt2018impala",
        "author": "Espeholt, Lasse and Soyer, Hubert and Munos, Remi and Simonyan, Karen and Mnih, Vlad and Ward, Tom and Doron, Yotam and Firoiu, Vlad and Harley, Tim and Dunning, Iain and others",
        "title": "Impala: Scalable distributed deep-rl with importance weighted actor-learner architectures"
      },
      {
        "key": "assran2019gossip",
        "author": "Assran, Mahmoud and Romoff, Joshua and Ballas, Nicolas and Pineau, Joelle and Rabbat, Michael",
        "title": "Gossip-based actor-learner architectures for deep reinforcement learning"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "schaul2015prioritized",
        "author": "Schaul, Tom and Quan, John and Antonoglou, Ioannis and Silver, David",
        "title": "Prioritized experience replay"
      }
    ]
  }
]