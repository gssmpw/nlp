\documentclass[10pt,twocolumn,letterpaper]{article}
% \usepackage{cvpr}
\usepackage[pagenumbers]{cvpr}
\input{preamble}
\include{macros}


\definecolor{cvprblue}{rgb}{0.21,0.49,0.74}
\definecolor{skyblue}{rgb}{0.53, 0.81, 0.92}
\usepackage[pagebackref,breaklinks,colorlinks,allcolors=cvprblue]{hyperref}
\usepackage{textgreek}
\usepackage[utf8]{inputenc}
\usepackage{tipa}
\usepackage[subtle,mathdisplays=normal,wordspacing=normal]{savetrees}

\newcommand\blfootnote[1]{%
  \begingroup
  \renewcommand\thefootnote{}\footnote{#1}%
  \addtocounter{footnote}{-1}%
  \endgroup
}

\title{EmoTalkingGaussian: Continuous Emotion-conditioned Talking Head Synthesis}

\author{Junuk Cha\textsuperscript{1,2\dag} \qquad Seongro Yoon\textsuperscript{2} \qquad Valeriya Strizhkova\textsuperscript{2} \qquad Francois Bremond\textsuperscript{2} \qquad Seungryul Baek\textsuperscript{1} \vspace{0.3em} \\
{\normalsize $^1$UNIST} \qquad
{\normalsize $^2$Inria}
}

\begin{document}
\twocolumn[{
\maketitle
\begin{center}
    \captionsetup{type=figure}
    \vspace{-6mm}
    \includegraphics[width=0.96\textwidth]{images/main/teaser.pdf}
    %\vspace{-3mm}
    \captionof{figure}{The state-of-the-art 3D talking head synthesis method, TalkingGaussian~\cite{li2024talkinggaussian}, manipulates expressions based on action units~\cite{ekman1978facial}; however, its ability to express diverse emotions is limited, and the image quality becomes inferior when representing unseen emotional expression of the emotion source image~\cite{pexels}. Our method can reflect diverse expressions and emotions based on action units as well as valence/arousal~\cite{russell1980circumplex}, and it renders the talking head with lip shape well-aligned to the input audio (/\textit{ni}/ and \ \textless \textit{mute} \textgreater), as shown in the left panel. The right panel demonstrates our method's capability to convey continuous emotions through valence/arousal adjustments, while keeping the lip synchronized to the audio. The ``ce" in "nice," which the speaker is pronouncing, is highlighted in \textcolor{red}{red}.
    %However, it has limitations in expressing various emotions.
    }
    \label{fig:teaser}
\end{center}
}]

\blfootnote{$\dag$ This research was conducted when Junuk Cha was an intern at Inria.}

\input{sec/0_abstract}
\input{sec/1_intro}
\begin{figure*}
    \centering
    \includegraphics[width=0.99\linewidth]{images/main/pipeline.pdf}
    \vspace{-3mm}
    \caption{Overview of the EmoTalkingGaussian: Our EmoTalkingGaussian is composed of three branches. First, the inside-mouth branch estimates the position offsets of 3D Gaussians based on audio features $\mba$. Second, the face branch estimates the position, scaling factor, and quaternion offsets based on audio features $\mba$ and action units $\mbu$. Our inside-mouth branch and face branch are inherited from TalkingGaussian~\cite{li2024talkinggaussian}, indicated by the dashed rectangle. Finally, the third branch, the emotion branch, estimates the position, scaling factor, and quaternion offsets based on emotion inputs $\mbe$ (valence/arousal). We render the mouth region and face region $\hat{I}$ along the black arrow. Then, we render the mouth region and emotional face region $\hat{I}^\text{E}$ along the yellow arrow. We apply RGB loss, normal loss, along with audio and lip synchronization loss to improve visual fidelity and overall alignment.}
    \label{fig:pipeline}
    \vspace{-5mm}
\end{figure*}
\input{sec/2_related_work}
\input{sec/3_method}
\input{sec/4_experiments}
\input{sec/5_conclusion}
\setcounter{equation}{0}
\setcounter{figure}{0}
\setcounter{table}{0}
\setcounter{section}{0}
\makeatletter
\renewcommand{\theequation}{S\arabic{equation}}
\renewcommand{\thefigure}{S\arabic{figure}}
\renewcommand{\thetable}{S\arabic{table}}
\renewcommand{\thesection}{S\arabic{section}}
\input{sec/X_suppl}

{
    \small
    \bibliographystyle{ieeenat_fullname}
    \bibliography{main}
}
\end{document}
