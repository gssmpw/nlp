\section{Conclusion}
\label{sec:conclusion}

This paper introduces a novel 3D emotional talking head generation framework, EmoTalkingGaussian. Our framework can seamlessly utilize even new subject video containing highly sparse emotion representation without any need for additional data capturing. Benefiting from a lip-aligned emotional facial image generator, normal map loss, sync loss, and curated speech audio data, our method enables diverse emotion manipulation based on valence and arousal, synchronizing lip movements in the rendered image with the input audio while preserving high image quality.

\noindent\textbf{Limitation.} Depending on the emotion, the mouth in the synthesized image sometimes change dramatically, causing artifacts around the mouth region in the rendered image by EmoTalkingGuassian. This highlights a trade-off between image fidelity and the intensity of emotional expression.

\noindent\textbf{Ethical consideration.} There is potential for misuse, including in deepfake applications or deceptive media. To mitigate this, we strongly advocate for responsible use, ensuring that generated content is not used for misleading or harmful purposes. We aim to support efforts that aid in the detection and responsible development of deepfake technology.

