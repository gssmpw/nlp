\section{Related work}
\label{sec:related}


\paragraph{Autoencoders for Latent Generative Models}
Training diffusion models directly in pixel space is computationally inefficient, as most of the bits in a digital image correspond to subtle details with little perceptual significance. To overcome this issue, \citet{rombach2022high} propose latent diffusion models that operate in a compressed latent space produced in a separate stage by an autoencoder. Their KL-regularized autoencoder, \texttt{SD-VAE}, has been extensively utilized in numerous diffusion models \cite{yao2024fasterdit, ma2024sit, chen2024pixartalpha}. Subsequent research has primarily focused on minimizing the reconstruction error that sets an upper bound on generative performance,
% by utilizing a better training set \cite{podell2024sdxl},
by increasing the number of latent channels \cite{esser2024sd3, flux2023, dai2023emu} and incorporating task specific priors \cite{zhu2023designing}.
To enable efficient training on high-resolution images \citet{xie2025sana} and \citet{chen2025deep}  extensively increase the compression ratio without compromising the reconstruction quality.
\citet{hu2023complexity} investigate the ideal latent space for generative models and find that a relatively weak decoder produces a latent distribution that enhances generative performance. 
Discrete autoencoders are initially introduced with \texttt{VQ-VAE} \cite{oord2017vq} to quantize image patches into discrete visual tokens. \texttt{VQ-GAN} \cite{esser2021taming} further refines \texttt{VQ-VAE} by integrating adversarial and perceptual losses,
enabling more accurate and detailed representations. Subsequent works have focused on architectural improvements \cite{yu2022vectorquantized}, strategies to increase the codebook size and maximize its utilization \cite{yu2024language, zhu2024scaling}.
Unlike these prior approaches, we investigate a novel perspective—leveraging spatial equivariance—to shape a latent space better suited for generative modeling.



\paragraph{Auxiliary Objectives and Regularization in VAEs}
 Autoencoders are designed to learn latent spaces that compactly represent meaningful features of the observed data. However, without any regularization, their latent code lacks meaningful structure. Variational Autoencoders (VAEs) were introduced in \citet{kingma2014} to address this by minimizing the KL divergence between the latent distribution and a Gaussian prior. Many subsequent works have adopted and extended this framework \cite{Higgins2016betaVAELB, dilokthanakul2016deep, tomczak2018vae, takahashi2019variational}.
Other works have proposed alternative regularizations based on the Wasserstein distance \cite{tolstikhin2018wasserstein, kolouri2018sliced}, adversarial objectives \cite{zhao2018adversa, makhzani2015adversarial} and vector quantization (VQ) \cite{oord2017vq}. Closely related to our work, \citet{NEURIPS2021_6c19e0a6} proposes a consistency regularization enforcing the latent code to be invariant under spatial transformations.  Our \texttt{EQ-VAE} promotes \emph{equivariance} rather than invariance under spatial transformations and we extensively demonstrate the impact of equivariance regularization on latent generative modeling.


\paragraph{Equivariance in Computer Vision} The success of Convolutional neural networks (CNN) in numerous computer vision tasks can be largely attributed to their approximate translation equivariance that arises due to the nature of convolution.
To incorporate other symmetries in the data, various group-equivariant convolutional networks have been proposed, including roto-translation equivariance in 2D \cite{cohen2016group, hoogeboom2018hexaconv, weiler2019general}, extensions in 3D \cite{worrall2018cubenet, thomas2018tensor, kondor2018n}, and scale equivariance \cite{rahman2023truly, Sosnovik2020Scale-Equivariant}. The derivation of group equivariance constraint typically results in steerable filters constructed from a basis. Besides architectural constraints, equivariance can be achieved by parameter sharing \cite{ravanbakhsh2017equivariance}, frame averaging \cite{puny2022frame}, and canonicalization functions \cite{kaba2023equivariance}.  For autoencoder models, \citet{winter2022unsupervised} produce latent representations from data
that are separated into a group invariant and equivariant part, however, they do not investigate the impact of equivariant representations on latent generative modeling.
