\begin{table}[t]
\footnotesize
\centering
\setlength{\tabcolsep}{3pt}
\begin{tabular}{lccc} % Adjust the number of c's to match your actual columns
\toprule
\Th{Model} & \Th{Epoch} & \Th{gFID$\downarrow$} & \Th{IS$\uparrow$}  \\ 
\midrule 
\texttt{MaskGIT}
  & $300$ 
  & $6.19$  
  & $182.1$ \\  % Add placeholder if no IS

\grayhline
\texttt{MaskGIT}$^{\dagger}$
  & $300$ 
  & $6.80$  
  & $214.0$ \\  % Add placeholder if no IS

% --- Here is where we merge the 2nd column for the last two rows ---

\cellcolor{TableColor} w/ \our (ours)  
  &  \cellcolor{TableColor}$130$ 
  & \cellcolor{TableColor}$6.80$  
  & \cellcolor{TableColor}$188.1$ \\

\cellcolor{TableColor} w/ \our (ours) 
  & \cellcolor{TableColor}$300$ 
  & \cellcolor{TableColor}$5.91$  
  & \cellcolor{TableColor}$228.8$ \\ 

\bottomrule
\end{tabular}
\vspace{-3pt}
\caption{\textbf{Boosting Masked Generative Modeling.}  
Comparison of \Th{gFID} and \Th{IS} on ImageNet \(256\times256\) for \texttt{MaskGIT}~\cite{chang2022maskgit} and its open-source PyTorch reproduction$^{\dagger}$~\cite{besnier2023pytorch}, trained with either \texttt{VQ-GAN} or our \texttt{EQ-VAE}. \texttt{EQ-VAE} %Our regularization 
accelerates training by more than $\times 2$ (130 vs. 300 epochs), highlighting \texttt{EQ-VAE} can be effectively applied to vector-quantized autoencoders.}
\label{tab:maskgit}
\vspace{-3pt}
\end{table}