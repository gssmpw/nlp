\section{Introduction}

Imagine a technical product manager, Meena, overseeing the development of a fictional healthcare application predicting the efficacy of a recently manufactured tuberculosis drug. Distribution data is collected from a trusted federal agency, demographics are cleaned and sorted through manual categorization, and trends are validated by organizational expectations. The model finds that the drug is most likely to reach and be effective for young adults in suburban neighborhoods. Meena, when writing out the limitations section of the model documentation, reflects on personal choices made within the process. She reveals that the federal agency was the only considered data source due to its colloquial familiarity, the data annotations for age ranges reflected the bias of a younger development team, and the results reinforced positive business forecasts. 

As a reader, what immediately stands out to you in Meena's disclosure? Perhaps you hone in on the subjectivity of what constitutes the social category of ``young adult.'' Or perhaps you deliberate on the association with government procedures or business interests as precarious infusions of hidden agendas. Perhaps, with alternative personal decision-making, the model may have also found that the drug showed significant side effects for older patients in rural settings with less government oversight.

What you considered in this hypothetical story were \textit{assumptions}. Their recognition, particularly in machine learning (ML) ecosystems, has become prevalent through the integration of trust and safety teams and increased adoption of responsible ML frameworks \rev{\cite{mitchell2021algorithmic,aragon2022human,srivastava2019mathematical}.} The presence of assumptions in any workflow is inevitable---they drive institutional motivations \rev{\cite{cheng2022child,holten2020shifting,stevenson2019algorithmic,saxena2024algorithmic}}, inform model specifications \rev{\cite{robertson2021modeling,michel2023recalibrating,obermeyer2019dissecting,kilbertusTraditionalAssumptionsFair2020}}, and allow the project to exist in the first place \cite{mitchell2021algorithmic,kilbertus2021beyond,malik2020hierarchy,saxena2021framework}. What is seldom acknowledged is their nuance and how workflow interactions often fail to capture that nuance through reflective interventions. This gap perpetuates a logic of distancing sociotechnical enablers from purely technical ones, leading practitioners to form a superficial understanding and adversarial response to them \rev{\cite{yildirim2023investigating,rakovaWhereResponsibleAI2021,kaurInterpretingInterpretabilityUnderstanding2020,mcconvey2024not}}. In essence, assumptions are employed one way or another, and their manifestation is a key part of any ML workflow. However, the centrality of their effect conflicts with the marginalization of their conceptualization.

% In this qualitative study, we explore this marginalization through the lens of argumentation theory in \textit{Critical Thinking} and \textit{Informal Logic}, two fields that define assumptions as the premise of \textit{arguments} an individual posits in the service of achieving a goal. 
In this qualitative study, we explore this marginalization through the lens of argumentation theory in the field of  Informal Logic, where assumptions are defined as the premises of an \textit{argument} an individual posits in the service of achieving a goal \rev{\cite{hitchcock2007informal,johnson2012manifest,ennis2006probably}.} 
These arguments culminate in a conclusion that postulates a pillar of reasoning for the workflow to continue to exist \rev{\cite{goddu2018against}}. But because the rationale is composed of a weak relationship between the individual making the argument and their \textit{understanding} of the assumptive nature of its premises, there is often confusion in propagating any result and alleviating concern about harms. \textbf{The primary question we therefore ask is what contributes to this confusion about assumptions in an ML context}. Through unpacking the factors that allow assumptions to persist in an organization unchecked, this research attempts to explain how ML practitioners first understand assumptions and second, deal with them. Ultimately, we answer our inquiry by offering dual characterizations of the former and breaking down the procedural elements that may circumvent or subvert the latter.

While past works have heavily implied that assumptions play a crucial role in ML, few have positioned them directly in relation to workflow requirements and constraints (section \ref{rel:periphery}). As we describe in section \ref{sec:ontology}, assumptions can be ontologically categorized into an \textit{independent construction}---existing as an individual entity that maneuvers alongside a workflow---or a \textit{relative construction}---lurking within the fabric of technical or business processes. Both present implications for how assumptions are identified by practitioners, if at all, and what constitutes appropriate reactions when they reveal internal or external consequences. Section \ref{sec:procedure} elaborates on organizational patterns that actualize these constructions: first, we investigate how the realities of ML in practice contradict the constituents necessary to examine assumptions reflectively; second, we show how in-place structures intended to deal with assumptions are inadequate. Finally, in section \ref{sec:discussion}, we culminate the themes established prior to outline how practitioners can better articulate assumptions and set up internal processes to work \textit{with} assumptions rather than \textit{in spite} of them. In summary, our work contributes the following:

\begin{itemize}
    \item An investigation of an overlooked and consequential phenomenon in HCI and responsible ML discourse---the factors that contribute to the \textit{confusion} around assumptions in machine learning.
    \item A deconstruction of the vague conceptualizations and inconsistent views around assumptions and how they present themselves in documentation around limitations or requirements.
    \item An overview of how an assumption traverses the phases of a typical ML workflow and leads to downstream effects in data pipelines and modeling while possibly begetting more uncertainties.
    \item A framework to remedy the articulation and informal recording of assumptions by prompting practitioners to reflect on their structure and logic.
\end{itemize}

% In this view, our work is a qualitative empirical research study that explores an overlooked phenomenon---confusions around assumptions in machine learning---and investigates the factors contributing to this confusion. 
% We deconstruct the vague conceptualizations and inconsistent views of assumptions, and discuss how they transform assumptions into different entities such as limitations or requirements (section \ref{subsec:ind}) and influence downstream tasks on data pipelines and modeling (section \ref{subsec:rel}.)
% We also discuss how the trajectory of an assumption in a typical ML workflow may beget more uncertainties due to a reactive and unreflective handling of assumptions (section \ref{subsec:integrate}.) Our findings also call into question the site, content, and style of assumptions documentation process by examining how informal, implicit, and unjustified they are (section \ref{subsec:doc}.)

% In addition to its empirical contribution, our work also belongs to the under-represented conceptual category in \citet{oulasvirta2016hci}'s taxonomy of HCI studies, as we ground our findings in argumentation theory of Critical Thinking to explain the nagging confusions surrounding assumptions in ML. 

% In particular, by viewing assumptions through the premise-target lens of an argument (section \ref{rel:core}), our findings throw light on why and how assumptions are made in ML and support practitioners in understanding and resolving confusions around assumptions. Our study brings the discussion on assumptions to the center by unpacking the confusing factors, thereby contributing to how practitioners think about and work with an overlooked but significant phenomenon in ML. In contrast, prior works in HCI and responsible ML predominantly discuss assumptions only peripherally, obscuring various conceptual and procedural questions practitioners have in their work (section \ref{rel:periphery}.) 
