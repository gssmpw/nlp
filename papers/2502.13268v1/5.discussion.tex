\section{Discussion and Future Work}
\label{sec:discussion}

% Drawing on \citet{laudan1978progress}'s philosophy of scientific progress, \citet{oulasvirta2016hci} describe human-computer interaction research as \textit{problem-solving}\footnote{This view has its objection as problem-solving is argued to restrict HCI in including artistic, curiosity-driven, or societal-impact oriented research and drive down the road of solutionism \cite{morozov2013save}}. They use the term \textit{problem} to refer to stated absences in descriptions, knowledge, understanding, and construction about a particular phenomenon in human use of computing. The \textit{solution} offered by HCI research is then assessed based on its contribution to the problem-solving \textit{capacity}.

% In this view, our work is a qualitative empirical research study that explores an overlooked phenomenon---confusions around assumptions in machine learning---and investigates the factors contributing to this confusion. We deconstruct the vague conceptualizations and inconsistent views of assumptions, and discuss how they transform assumptions into different entities such as limitations or requirements (section \ref{subsec:ind}) and influence downstream tasks on data pipelines and modeling (section \ref{subsec:rel}.)
% We also discuss how the trajectory of an assumption in a typical ML workflow may beget more uncertainties due to a reactive and unreflective handling of assumptions (section \ref{subsec:integrate}.) Our findings also call into question the site, content, and style of assumptions documentation process by examining how informal, implicit, and unjustified they are (section \ref{subsec:doc}.)

% In addition to its empirical contribution, our work also belongs to the under-represented conceptual category in \citet{oulasvirta2016hci}'s taxonomy of HCI studies, as we ground our findings in argumentation theory of Critical Thinking to explain the nagging confusions surrounding assumptions in ML. In particular, by viewing assumptions through the premise-target lens of an argument (section \ref{rel:core}), our findings throw light on why and how assumptions are made in ML and support practitioners in understanding and resolving confusions around assumptions. Our study brings the discussion on assumptions to the center by unpacking the confusing factors, thereby contributing to how practitioners think about and work with an overlooked but significant phenomenon in ML. In contrast, prior works in HCI and responsible ML predominantly discuss assumptions only peripherally, obscuring various conceptual and procedural questions practitioners have in their work (section \ref{rel:periphery}.) 

We highlight throughout our findings that since arguments need not be explicit statements expressed in documentations, there is an inherent subjectivity in interpreting and analyzing assumptions in arguments, causing confusion when practitioners work with different stakeholders. Hence, adequately recording the assumptions and clearly situating them in arguments is essential to work through subjective interpretations. To motivate this line of work, in section \ref{disc:articulate}, by connecting the premise-target lens with our empirical findings, we derive a framework to \textit{articulate} assumptions for analysis. Then in section \ref{disc:creative}, we discuss how critical assessment of assumptions is also a lateral and creative activity \cite{fisher1997critical,delin1994assumption}. More broadly, our empirical findings and theoretical grounding lay out the foundation to strengthen the infrastructure for assumptions identification and handling in machine learning.


% As \citet{oulasvirta2016hci} argues, without strong conceptual understanding of how a problem is situated, 
% - cehck future roadmap last section:
%     - without conceptual rigor construcute solutions cannot happen - link both types - out wrosk contributes
% - we offer one example fo construcutvt snapshot - inferred form our findings - a frameworrk to articulate assumptiosn -t the first step - 
%     - see below point
% - this can also be assessed as improving other characteristc such as efficacy which we did not do with our findings and current RQ 
% - but we don't completely agree with this due to boudary objects which we discuss in 5.2, and discuss certain fuure directions inspired from our findings, grounding in theory

% -- significance: important to practtioers
% - what can they now acheive nefore reading the paper
%     - significance for them of the problem at hand
% - table - importance of the i m- provement for stakeholders
%     - capacity

\subsection{Explicating the Articulation of Assumptions}
\label{disc:articulate}

We discuss in section \ref{subsec:doc} that the documentation practice of assumptions is usually implicit and unstructured: it can be in the form of simply listing them in varied styles, inline recording their presence in change logs, or including/excluding justifications of claims. So when a practitioner attempts to analyze either their or another person's assumptions at a later point in time, they could have several unresolved questions and doubts, as evidenced throughout our findings. Further, how a practitioner conceptualizes an assumption, either as an independent axiom or in relation to existing phases of the development process (section \ref{sec:ontology}), influences their course of action in the ML workflow.
Therefore, explicating the articulation of an assumption is an essential ingredient to clearing out many surrounding confusions.

It should also be noted that explicating an assumption, in essence, implies clarifying or detailing the broader argument in which that assumption is embedded. In other words, in articulating an assumption (and thereby an argument), a clear distinction must be made between the premise (i.e., the assumption) and the target the premises are supporting to make an argument. Prior works argue that presenting an argument in this premise-target frame is one of the most effective strategies to communicate the proposal the argument is trying to make, where ``effective'' signifies the increase in likelihood of scrutiny from the audience of the argument \cite{innocenti2021constructing,kauffeld1998presumptions,jacobs2000rhetoric}.

Now, our findings describe that some practitioners attempt to ``justify'' their use of assumptions in their documentations (section \ref{subsec:doc}).
However, this reference to justification creates different interpretations of assumptions where the distinction is not always clear.
For instance, does justification imply the act of using assumptions for achieving something or refer to the conclusion the assumption is trying to support?
In philosophical terms, the illocutionary acts of justification could vary depending on the context and create more uncertainties\footnote{We discuss in section \ref{rel:core} that a premise is composed of the proposition and the illocutionary act (or the accompanying intentional state) but do not engage with this decomposition in our findings. We leave further exploration to future works.}.
In contrast, in articulating assumptions as premises to a target, the \textit{object} of scrutiny becomes much clearer. So, this premise-target complex becomes the \textit{core} of our articulation framework (Table \ref{tab:explicate}).

Our findings also discuss that practitioners can formulate different assumptions for the same target, depending on their conceptualization of assumptions, organizational constraints, or disciplinary backgrounds.
To accommodate such differences within the premise-target frame, we add a meta-layer to the explication---which we call the \textit{differentiator}---that distinguishes three broad categories in which the premises can be related to the target. 
We adapt the assumptional categories discussed by \citet{brookfield1995getting} to our findings and propose three types of differentiators that cluster different assumptions.
% as a function of state and action. 
First, assumptions can be about the structural \textit{understanding} of different elements of the target, such as a sociotechnical idea that underpins the target.
In the second category, the assumptions are about the \textit{appropriateness of the action(s)} performed to achieve the target. 
The final category is about how the performed action will \textit{address} the target.  
The framework also requires mentioning if the target and assumption are implicit. 

To illustrate, let's analyze the below excerpt from the technical report of a large language model, PaLM 2 \cite[p.~87]{anil2023palm}. 
\begin{quote}
    \textit{Are there certain annotator perspectives or subgroups whose participation was prioritized? If so, how were these perspectives sought out? \textbf{No.}}
\end{quote}
The object of scrutiny here is the response provided by the report's authors for a CrowdWorksheets question on how annotators were chosen \cite{diaz2022crowdworksheets}. 
We chose this example as many practitioners could (and did in our case studies) straightforwardly recognize the existence of assumptions within it.
\rev{Such responses also reflect how practitioners pay little attention when filling out details on biases or limitations in popularly used toolkits such as model cards \cite{liang2024systematic}.}

Table \ref{tab:explicate} presents our analysis.
Now, depending on the differentiator lens a practitioner takes, different assumptions can be articulated for the same identified target.
The first assumption from the left is about the assumer's understanding of the concepts within the target: the inclusivity of the annotator group.
The second category of articulation is about why the alternative course of action, such as leveling up or down the representation of a group \cite{mittelstadt2023unfairness,corbett-daviesMeasureMismeasureFairness2018}, is inferior to taking no action to achieve the target.
The last type of assumption discusses how when no group is explicitly prioritized, the hiring of annotators stays inclusive.
The assumptions in different categories can also relate to one another. 
For instance, in this case, the first assumption on understanding inclusion could inform the third assumption on how performing no action will address the target objective.
Finally, while we have discussed only a single assumption per category, in other situations, multiple assumptions may also be grouped just under one category.

\rev{In general, while commonly used toolkits simply prompt practitioners to list or explain why something is an assumption (section \ref{rel:periphery}), our framework presents a method to specifically break down the articulation of an assumption by considering the factors rooted in confusion we discussed in our findings. It is important to note that the tabular format we have used here is to illustrate the building blocks of \textit{one} assumption. However, in practice, we may want to articulate more complex and dynamic relations between assumptions in general, such as how the understanding of one assumption changes with another or how addressal of some assumptions updates others. Several works in Informal Logic have discussed the benefits of software programs and visual markers to interactively map and understand such changes in premises and targets \cite{daviesusing,harrell2008no,martin2009computer}. We encourage the HCI and responsible ML community to build on these works to logically understand the flow of assumptions.} 

% Though there is no tool such as an ``assumptions sheet,'' 

% -- used assumption is always about absene than about rpesne - discussion
% -- Another example is indigenous - explicating articulation discussion


\subsection{Assumptions Inquiry as a Lateral Thinking Process}
\label{disc:creative}

\begin{table*}[t]
\centering
\caption{\textbf{Articulation of \rev{an Assumption} in an Argument.} We offer a framework that breaks down the articulation of assumption through three differentiators: the \textit{understanding of the target}, the \textit{appropriateness of performed action}, and the \textit{addressal of the target}. These dimensions convey the primary components of a premise-target argument and how an assumption can be embedded within it.}
\resizebox{0.9\textwidth}{!}{%
\begin{tabular}{|llll|}
                          \hline
                          \multicolumn{4}{|c|}{}\\
                          & \multicolumn{1}{r}{\textbf{Target:}}                                                                                                                    & To perform inclusive hiring of annotators                                                                                                                       &                                                                                                         \\
                                                                             & \multicolumn{1}{r}{\textbf{Is Target Implicit?:}}                                                                                                       & No                                                                                                                                                              &                                                                                                         \\
 \multicolumn{4}{|c|}{}\\ \hline
                                                                             \multicolumn{4}{|c|}{}\\
\multicolumn{1}{|c}{\textbf{Differentiator:}}                                 & \multicolumn{1}{c}{\textit{Understanding of the target}}                                                                                                    & \multicolumn{1}{c}{\textit{Appropriateness of performed action}}                                                                                                & \multicolumn{1}{c|}{\textit{Addressal of the target}}                                                        \\
 \multicolumn{4}{|c|}{}\\ \hline
& & & \\
\multicolumn{1}{|c}{\textbf{Assumption:}}                                     & \begin{tabular}[c]{@{}l@{}}The default state of the world \\ has equal representation. \\ So there is no need to \\ prioritize any group.\end{tabular} & \begin{tabular}[c]{@{}l@{}}Of several actions that can be performed, \\ such as leveling up/down representation \\ of a group, doing nothing is the most \\ appropriate action.\end{tabular} & \begin{tabular}[c|]{@{}l@{}}When no group is explicitly\\ prioritized, hiring is inclusive. \end{tabular} \\
 \multicolumn{4}{|c|}{}\\ \hline
\multicolumn{4}{|c|}{}\\
\textbf{\begin{tabular}[c]{@{}c@{}}Is Assumption \\ Implicit?:\end{tabular}} & Yes                                                                                                                                                     & Yes                                                                                                                                                             & Yes                                                                                         \\ 
\multicolumn{4}{|c|}{}\\
\hline           
\end{tabular}
}
\label{tab:explicate}
\end{table*}

Section \ref{sec:procedure} discusses how, despite the rise in responsible AI toolkits, articulation of assumptions in practice is often informal and unreflective. 
However, the exercise in Table \ref{tab:explicate} suggests that the articulation of assumptions can involve deliberate effort and reflective thinking on how premises are connected to the target, and decides future course of action.
For instance, for the above example, a computationally-oriented practitioner might think about assumptions in terms of algorithmic fairness and analyze how performing no action provides more ``fair'' hiring outcomes than leveling down or up the fairness scores of particular sub-groups \cite{mittelstadt2023unfairness,corbett-daviesMeasureMismeasureFairness2018,cooper2020normative}.
Others might focus on the assumptions in the understanding of sociotechnical factors, such as inclusion or fairness, to analyze how it affects hiring and various decisions in the workflow \cite{wangFactorsInfluencingPerceived2020,pfeiffer2023algorithmic,dolata2022sociotechnical}.
Our framework simplifies this articulation process for practitioners in communicating their argument and supports them in deciding future courses of action while also revealing how articulation in an assumption inquiry requires practitioners to think more proactively about how and why an assumption is made.

Assumptions inquiry is \rev{broader and more} complicated than \textit{only} articulating. Our articulation framework in Table \ref{tab:explicate} presupposes that assumptions are already identified. While the premise-target-differentiator complex can help surface assumptions, for many cases, the assumptions identification process itself requires employing systematic exercise and techniques \cite{walton2012argument,palau2009argumentation}, as illustrated in our example. We discuss in section \ref{subsec:doc} that even for practitioners employing responsible AI toolkits to track down what they think are assumptions, there is little support provided to carefully reflect on assumptions; for instance, when they may inquire why they think something is an assumption or analyze what an assumption entails. Though our articulation framework sets up the stage for that reflection and subsequent course of action, practitioners may still face several questions on how to evaluate or respond to assumptions and arguments. We call the attention of HCI and responsible AI researchers to the analytical methods offered by related works in Informal Logic to systematically perform these functions \cite{walton2008argumentation,govier2018problems,govier2010practical,blair2019judging}. These works suggest that thinking about assumptions involving several non-sequential overlapping processes---such as identification, articulation, evaluating, and responding---demands lateral thinking and needs to be separated from the activities of a typical workflow. In other words, the \textit{thinking} process around assumptions must continue in parallel to the ML workflow.
 
Overall, our findings highlight an inadequacy in existing infrastructures of ML ecosystems in thinking about assumptions and discussing the contributing factors of the confusion resulting from this inadequacy. 
However, instead of focusing on the development of more toolkits exclusively for assumptions, we recommend practitioners to be more deliberate in their assumptions inquiry using the toolkits at their disposal. Prior works have argued against the techno-solutionist adoption of these toolkits where the mere \textit{following} of specific processes is often assumed to solve ethical or fairness issues \cite{wong2023seeing,balayn2023fairness,dengExploringHowMachine2022,lee2021landscape}. But this practice continues to exist and is reflected in how the technical reports and documentation of large language models are currently drafted, such as in the responses to model cards \cite{mitchellModelCardsModel2019} or datasheets \cite{gebruDatasheetsDatasets2021} where there is less clarity on the reflectivity that goes into this process \cite{wong2023seeing,madaioCoDesigningChecklistsUnderstand2020,crisan2022interactive,bhat2023aspirations}. The example we discussed in the previous section depicts this superficiality. Further, the assessment of these toolkits too, in practice, predominantly focuses  on the \textit{completion} of different sections of these toolkits \cite{liang2024systematic,yang2024navigating}.

This trend is particularly challenging for assumptions inquiry because, by definition, the steps that go into assumptions identification, articulation, and evaluation are not something that can be merely followed through instructions but rather need to have deeper engagement.
Similarly, the assessment process is further complicated because the analyst is now interpreting someone else's assumptions inquiry, which cannot be just evaluated based on rubrics or completeness \cite{govier2010practical,blair2019judging}. 
Having said that, we do not imply that toolkits should not be developed to bring structure to the assumptions inquiry process; in fact, \rev{as a first step,} we offered a framework to articulate assumptions in the previous section that \rev{future works can integrate} within existing or new toolkits. 
\rev{Prior works in Informal Logic appreciate the complexity of assessing arguments and their premises by considering several factors such as soundness, acceptability, relevance, sufficiency, and fallacies \cite{blair2019judging,govier2018problems}. Evaluating our articulation framework along these and other relevant dimensions to ML is an interesting area to explore in the future.}

\rev{Finally, it is important to note that we laid out our articulation framework from the perspective of an assumption \textit{analyst} who may use this framework in (in)formal discussions, business management platforms, quality assessment phases, or throughout the ML lifecycle. However, to guide an \textit{assumer} who wants to demonstrate accountability in their decisions, further research is required to assess how effectively constituents of an assumption can be presented, for instance, by integrating it with particular modules of existing toolkits and frameworks, or by consolidating all assumption break-downs in a dedicated place in the form of an ``assumptions sheet.''}

\section{Conclusion}
\rev{In this work, we explored an overlooked phenomenon---confusions around assumptions in machine learning---and investigated the factors contributing to this confusion.}
\rev{We ground our empirical contributions in the argumentation theory of Informal Logic to explain the nagging confusions surrounding assumptions in ML. In particular, by viewing assumptions through the premise-target lens of an argument, our findings throw light on why and how assumptions are made in ML and support practitioners in understanding and resolving confusions around assumptions.}
While we deconstruct these confusions that are peripherally discussed in prior works, more uncertainties still remain on the adoption of assumptions inquiry in practice. We invite other researchers to build off of our work and reflect critically on their \textit{own} assumptions in how they imagine and craft new ethical or fairness toolkits---not only as a function of data or model requirements or in the form of checklists and questionnaires, but through the logic and thinking of practitioners in pragmatic contexts.
% 

% 

% \textbf{This is one small step for human, but one giant leap for humankind.}

% In particular, the increased adoption of toolkits in responsible AI practice further confronts the development of toolkits exclusively for assumptions investigation, such as an \textit{assumptions sheet}.

% here too we have or get more questions - but they are about what needs to be done after knowing this assumptin unlike in other cases the uncertainints about why is this an assumption, what to do woth the assumption,etc.

% -Use different terms relevant to assumptions - not everything is assumption or limitation - if it’s confusion, say it's confusing
% -Failure-first to assumptions-first culture - good for all parties - need not necessarily reduce speed but just knowing itself is good
% -Boundary objects - correct use of assumptions structuring

% - llm should not be used to do this - report cards - can llm predict arguments paper - future work

% implications for NLP: how assumptions and arguments can be analyzed


% 2. fostering critico-creative thinking of assumption - just the tail of an elephant we have touched through epxliciating - there is a lot more - handling, training, juding etc. - take from crtiical thinkiing book and relate to findings and lay out fuure work - refer the future work in one note

% -- overall, separate thinking - lateral and creative process - and critical thinking works help us see how assumptions are treated to unpack some of the - seoncd order in and thierd oder

% - limitation in thinking 


% Historian - discussion

% -----
% Companies must operate off of the shared assumption that AI is inherently beneficial to society. Opposing assumptions must be tempered or vanquished. The demands of the job shape the assumptions being made.

% Nirmal's input - predicate, presupposition, declarative statements

% \begin{acks}
% We are thankful to the anonymous reviewers for their valuable suggestions and comments. This work was supported by the University of Toronto Data Sciences Institute (DSI) Doctoral Fellowship, the Schwartz Reisman Institute for Technology and Society (SRI) Faculty and Graduate Fellowships, and Sharifa Sultana's ICR-434053-200250-434533 fund at the University of Illinois Urbana-Champaign.
% \end{acks}