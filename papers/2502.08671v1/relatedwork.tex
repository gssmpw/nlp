\section{Related Works}
\subsection{Algorithm for color vision deficiency}
As per the color deficiency survey\cite{RG19a}, various approaches have been employed to address color deficiency by filtering or scaling different color spaces such as LMS, RGB, HSX, CIE Lab, and YCC in sequence. Iaccarino et al.'s method\cite{IMPS06} involves scaling the pixel value that satisfies the threshold of R and G colors and rotating the hue value of the reference color. In contrast, SPRWeb\cite{FRGG13} aims to satisfy both the perceptual experience of color vision deficiency and the subjective experience, while preserving color and contrast. Their method uses a two-pass hill-climbing algorithm to optimize the objective function with four components: color naturalness, perceptual color contrast, subjective color naturalness, and subjective color contrast. While it has the advantage of being applicable to natural images, most of the existing recoloring algorithms fail to account for image complexity, leading to the same adjustment filtering being applied to considerably simple images (with only two color tones, as illustrated in Figure \ref{fig:02}).


\subsection{Image-to-Image translation based on generative models}
Generative adversarial networks (GANs) have become a popular tool for image translation tasks, including image generation, style transfer, and colorization\cite{KWK21, IZZE17}. Among various GAN models, Cycle-GAN\cite{PEZZ20} has shown superior performance in enhancing the contrast of non-color-under-deficient (CUD) objects, as depicted in Figure \ref{fig:01}. However, to achieve color preservation, it is crucial to prevent the input image from losing its original color, even in the worst case scenario where the object is completely black. To address this issue, Enlighten-GAN\cite{JGL*21} has been proposed, which improves stability and generates more reliable results in terms of color preservation. 

\subsection{Image enhancement based on neural filter estimation}
In contrast to GANs, some studies have explored the approach of scaling pixel values of images through neural filter estimation techniques\cite{WZF*19, DLT18, BCPS19}. Zero-DCE\cite{GLG*20} and DeepLPF\cite{MMM*20} are two such studies that aim to enhance low-light images by estimating pixel-wise and high-order filters for dynamic range adjustment using lightweight deep networks. While Zero-DCE focuses on providing a brighter visual display of input images, DeepLPF attempts to enhance image contrast while maintaining color preservation through the use of graduated elliptical and polynomial filters that are easy to understand for viewers. However, in our problem, applying contrast factor yields similar results to the input image in both visions, indicating an overly stable filter. This may be attributed to the inability to comprehend the interaction of objects, leading to the development of an overly stable filter. We conducted additional assessments of the transformer-based neural architecture, yet its outcomes exhibit poor color harmony, consistent with the observations made in \cite{PEZZ20}.As a consequence, we have developed our backbone network utilizing a neural architecture based convolutional neural network.