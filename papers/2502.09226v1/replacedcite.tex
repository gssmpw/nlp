\section{Related Work}
\vspace{-0.09 in}
Various methods for generating counterfactual explanations in machine learning have been proposed. Wachter et al. ____ aimed to provide transparency in automated decision-making by suggesting changes individuals could make to achieve desired outcomes. However, they ignored causal dependencies, resulting in unrealistic suggestions. Utsun et al. ____ introduced algorithmic recourse, offering actionable paths to desired outcomes but assuming feature independence, which is often unrealistic. \textit{CoGS} rectifies this by incorporating causal dependencies. Karimi et al. ____ focused on feature immutability and diverse counterfactuals, ensuring features like gender or age are not altered and maintained model-agnosticism. 
 However, this method also assumes feature independence, limiting realism.
% However, they also assumed feature independence, limiting realism.
% Various methods for generating counterfactual explanations in machine learning have been proposed. Wachter et al.____ aimed to provide transparency in automated decision-making by suggesting changes individuals could make to achieve desired outcomes. However, they ignored causal dependencies, resulting in unrealistic suggestions. Utsun et al.____ introduced algorithmic recourse, offering actionable paths to desired outcomes. Karimi et al.____ focused on feature immutability and diverse counterfactuals, ensuring features like gender or age are not altered and maintain model-agnosticism. However, both of these method assumed feature independence, which is often unrealistic. \textit{CoGS} rectifies this by incorporating causal dependencies.  
White et al. ____ showed how counterfactuals can enhance model performance and explanation accuracy. Karimi et al. ____ further emphasized incorporating causal rules in counterfactual generation for realistic and achievable interventions. 
%Unlike previous methods assuming feature independence, this approach considers causal dependencies for valid counterfactuals. 
However, their method did not use the `if and only' property, which is vital in incorporating the effects of causal dependence. \textit{CoGS} rectified this by utilizing Answer Set Programming (ASP), which does not require grounding as it leverages s(CASP) to generate counterfactual explanations, providing a clear path from undesired to desired outcomes.

Bertossi ____ utilizes Answer Set Programming (ASP) to generate \textit{causal explanations} by identifying \textit{minimal cardinality sets} using counterfactuals. These \textit{minimal cardinality sets} are used to compute scores to identify causal explanations. Unlike their work, \textit{CoGS} focuses on defining the causal dependencies amongst features and incorporating them into the framework. As a result of this \textit{CoGS} returns a series of steps to take to go from an original instance to a counterfactual instance which accounts for the causal impact of making interventions when going from one state to another.


The main contribution of this paper is the Counterfactual Generation with s(CASP) (\textit{CoGS}) framework for automatically generating counterfactuals while taking causal dependencies into account to flip a negative outcome to a positive one. \textit{CoGS} has the ability to find minimal paths by iteratively adjusting the path length.
%, starting with a length of 1 and increasing until a solution is found. 
This ensures that explanations are both minimal and causally consistent. \textit{CoGS} is flexible, generating counterfactuals irrespective of the underlying rule-based machine learning (\textit{RBML}) algorithm. The causal dependencies can be learned from data using any \textit{RBML} algorithm, such as FOLD-SE. The goal-directed s(CASP) ASP system plays a crucial role, as it allows us to compute a possible world in which a query {\tt Q} fails by finding the world in which the query {\tt not Q} succeeds. \textit{CoGS} advances the state of the art by combining counterfactual reasoning, causal modelling, and ASP-based planning, offering a robust framework for realistic and actionable counterfactual explanations. Our experimental results show that counterfactuals can be computed for complex models in a reasonable amount of time.