\documentclass[conference,final]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{enumerate}
\usepackage{booktabs}
\usepackage{xspace}
\usepackage{multirow}
% \usepackage{hyperref}
\usepackage{url}
\urlstyle{rm}


% \usepackage{algpseudocode}

\usepackage{algorithm}
\makeatletter
\newcommand{\removelatexerror}{\let\@latex@error\@gobble}
\makeatother


\makeatletter
\DeclareRobustCommand\onedot{\futurelet\@let@token\@onedot}
\def\@onedot{\ifx\@let@token.\else.\null\fi\xspace}

\def\eg{\emph{e.g}\onedot} \def\Eg{\emph{E.g}\onedot}
\def\ie{\emph{i.e}\onedot} \def\Ie{\emph{I.e}\onedot}
\def\cf{\emph{c.f}\onedot} \def\Cf{\emph{C.f}\onedot}
\def\etc{\emph{etc}\onedot} \def\vs{\emph{vs}\onedot}
\def\wrt{w.r.t\onedot} \def\dof{d.o.f\onedot}
\def\etal{\emph{et al}\onedot}
\makeatother


\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{{\huge MixDec Sampling: A Soft Link-based Sampling Method of Graph Neural Network for Recommendation}\\
\thanks{$\star$ Xiangjin Xie, Yuxin Chen, Ruipeng Wang and Xianli Zhang contributed equally to this research.}
\thanks{$\dagger$ Hai-Tao Zheng and Buyue Qian is the corresponding authors.}
}
\author{Xiangjin Xie$^{1\star}$, Yuxin Chen$^{2\star}$, Ruipeng Wang$^{3\star}$, Xianli Zhang$^{4\star}$, Shilei Cao$^2$, Kai Ouyang$^1$,\\
  Zihan Zhang$^5$, Hai-Tao Zheng$^{1,7\dagger}$, Buyue Qian$^{6\dagger}$, Hansen Zheng$^4$, Bo Hu$^2$, Chengxiang Zhuo$^2$, Zang Li$^2$\\
$^1$Shenzhen International Graduate School, Tsinghua University, $^2$Tencent PCG,\\
$^3$School of Mathematical Science, University of Electronic Science and Technology of China,\\
$^4$School of Computer Science and Technology, Xiâ€™an Jiaotong University,\\ 
$^5$Beihang University, $^6$Beijing Chaoyang Hospital, Capital Medical University, $^7$Pengcheng Laboratory\\
$^1${\tt \{xxj20, oyk20\}@mails.tsinghua.edu.cn}, $^1${\tt zheng.haitao@sz.tsinghua.edu.cn},\\
$^2${\tt \{danikachen, eliasslcao, harryyfhu, felixzhuo, gavinzli\}@tencent.com},\\
$^3${\tt gavinwang@std.uestc.edu.cn}, $^4${\tt \{xlbryant, Hansen\}@stu.xjtu.edu.cn},\\
$^5${\tt zihanzhang@buaa.edu.cn}, $^6${\tt qianbuyue@bjcyh.com}
}



% \author{\IEEEauthorblockN{1\textsuperscript{st} Xiangjin Xie}
% \IEEEauthorblockA{
% \textit{Tsinghua University}\\
% xxj20@mails.tsinghua.edu.cn}
% \and
% \IEEEauthorblockN{2\textsuperscript{nd} Yuxin Chen}
% \IEEEauthorblockA{
% \textit{Tencent}\\
% email address or ORCID}
% \and
% \IEEEauthorblockN{3\textsuperscript{rd} Ruipeng Wang}
% \IEEEauthorblockA{
% \textit{University of Electronic Science and Technology of China}\\
% gavinwang@std.uestc.edu.cn}
% \and
% \IEEEauthorblockN{4\textsuperscript{th} Xianli Zhang}
% \IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
% \textit{name of organization (of Aff.)}\\
% email address or ORCID}
% \and
% \IEEEauthorblockN{5\textsuperscript{th} Shilei Cao}
% \IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
% \textit{name of organization (of Aff.)}\\
% email address or ORCID}
% \and
% \IEEEauthorblockN{6\textsuperscript{th} Kai Ouyang}
% \IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
% \textit{name of organization (of Aff.)}\\
% email address or ORCID}
% \and
% \IEEEauthorblockN{6\textsuperscript{th} Zihan zhang}
% \IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
% \textit{name of organization (of Aff.)}\\
% email address or ORCID}
% \and
% \IEEEauthorblockN{6\textsuperscript{th}  Hai-Tao Zheng}
% \IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
% \textit{name of organization (of Aff.)}\\
% email address or ORCID}
% \and
% \IEEEauthorblockN{6\textsuperscript{th} Buyue Qian}
% \IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
% \textit{name of organization (of Aff.)}\\
% email address or ORCID}
% \and
% \IEEEauthorblockN{6\textsuperscript{th} Bo Hu}
% \IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
% \textit{name of organization (of Aff.)}\\
% email address or ORCID}
% \and
% \IEEEauthorblockN{6\textsuperscript{th} Chengxiang Zhuo}
% \IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
% \textit{name of organization (of Aff.)}\\
% email address or ORCID}
% \and
% \IEEEauthorblockN{6\textsuperscript{th} Zang Li}
% \IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
% \textit{name of organization (of Aff.)}\\
% email address or ORCID}
% }

\maketitle

\begin{abstract}
Graph neural networks have been widely used in recent recommender systems, where negative sampling plays an important role.
Existing negative sampling methods restrict the relationship between nodes as either hard positive pairs or hard negative pairs. This leads to the loss of structural information, and lacks the mechanism to generate positive pairs for nodes with few neighbors.
To overcome limitations, we propose a novel soft link-based sampling method, namely MixDec Sampling, which consists of Mixup Sampling module and Decay Sampling module.
The Mixup Sampling augments node features by synthesizing new nodes and soft links, which provides sufficient number of samples for nodes with few neighbors.  
The Decay Sampling strengthens the digestion of graph structure information by generating soft links for node embedding learning.
To the best of our knowledge, we are the first to model sampling relationships between nodes by soft links in GNN-based recommender systems.
Extensive experiments demonstrate that the proposed MixDec Sampling can significantly and consistently improve the recommendation performance of
several representative GNN-based models on various recommendation benchmarks.


%negative sampling usually acts as a critical strategy to obtain negative supervision for training.
%Negative sampling is a way to obtain regular embedding representations for learning high-quality distributed vector representations. In graph representation learning, negative sampling is also a critical part of training high-quality node representations. However, negative sampling simply divides other nodes for a node into binary of positive and negative samples, which makes it difficult to obtain hierarchical representation of nodes embedding.
%However, negative sampling simply binaries the links between nodes into positive or negative, which makes it difficult to model the hierarchical distribution of nodes.

%In this paper, we propose \textbf{MixDec Sampling}, a sampling method that converts the links of nodes from hard to soft to obtain a more hierarchical distribution of nodes includes several methods to optimize the negative sampling of soft links, including: Mixup Samplig, Decay Sampling, MixDec Sampling, which convert the hard links between nodes into soft links so that the sampling and optimization process can be more accurate. These methods construct synthetic samples and corresponding links by setting links for all node pairs on the basis of BFS and Mixup of different links.

%Empirical results using GraphSAGE GCN, GAT on three public benchmarks show that mix sampling significantly outperforms negative sampling. We also conducted ablation experiments for the appropriate loss function of this soft link, and we matched the corresponding loss function for the soft link based on the experiments.
\end{abstract}
\begin{IEEEkeywords} Graph Neural Network, Negative Sampling, Recommendation System. \end{IEEEkeywords}


\section{Introduction}
\label{sec:intro}
\input{introduction}


\section{Preliminaries}
\label{sec:preliminaries}
\input{Preliminaries}

\section{Method}
\label{sec:method}
\input{Method}





\section{Experiments}
\label{sec:experiments}
\input{Experiments}


\section{Related Work}
\label{sec:Background}
\input{RelatedWork}



\section{Conclusion}
\label{sec:conclusion}
\input{conclusion}

\section{Acknowledge}
This research is supported by National Natural Science Foundation of China (Grant No.62276154 and 62011540405), Beijing Academy of Artificial Intelligence (BAAI), the Natural Science Foundation of Guangdong Province (Grant No. 2021A1515012640), Basic Research Fund of Shenzhen City (Grant No. JCYJ20210324120012033 and JCYJ20190813165003837), and Overseas Cooperation Research Fund of Tsinghua Shenzhen International Graduate School (Grant No. HW2021008).


\bibliographystyle{ieeetr}
\bibliography{ref}

\end{document}
