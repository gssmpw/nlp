\section{Related Works}
\subsection{Multimodal Large Language Models}
Multimodal Large Language Models (MLLMs) have significantly advanced AI-driven perception by integrating vision and language understanding. One of the most widely used closed-source MLLMs is OpenAI’s GPT-4 Omni (GPT-4o), which extends the capabilities of previous GPT models by incorporating a visual modality. However, its proprietary nature restricts transparency, self-hosting, and rigorous independent evaluation. Despite these limitations, GPT-4o has demonstrated state-of-the-art performance in multimodal reasoning tasks____. In contrast, open-source MLLMs such as LLaVA (Large Language and Vision Assistant) provide researchers with accessible model architectures, training frameworks, and weights. LLaVA extends LLaMA through CLIP-based vision-language integration and has become a benchmark for evaluating multimodal understanding. The latest stable iteration, LLaVA-1.5, is widely used for benchmarking, while LLaVA-1.6 introduces further refinements____. Other notable open-source MLLMs include MiniGPT-4____, BLIP-2____, OpenFlamingo____, Qwen-VL____, and DeepSeek Janus Pro____. While open-source models foster innovation and reproducibility, their exposed architectures also present a broader attack surface for adversarial vulnerabilities.

\subsection{Adversarial Attacks on MLLMs}
Adversarial attacks exploit model vulnerabilities by introducing imperceptible perturbations to input data, leading to erroneous predictions with high confidence. The foundational work of Goodfellow et al. demonstrated that neural networks, including vision-language models, are susceptible to adversarial manipulation____. Such attacks can be categorized into training-time and test-time perturbations. Training-time attacks poison the dataset to induce systematic errors in model learning____, whereas test-time attacks apply perturbations post-deployment, causing temporary misclassifications____. A well-known test-time adversarial attack involves Universal Adversarial Perturbations (UAPs), which generalize across multiple inputs to consistently degrade model performance____. Given the increasing adoption of MLLMs in critical applications, ensuring robustness against adversarial manipulations remains an open research challenge.

\subsection{Adversarial Vulnerabilities Across Domains}
Adversarial vulnerabilities extend beyond MLLMs to various domains, highlighting the broad impact of adversarial manipulations in AI systems. In the audio domain, Automatic Speech Recognition (ASR) systems can be deceived by carefully crafted audio perturbations, leading to incorrect transcriptions or commands____. In the video domain, adversarial attacks on video recognition systems can cause misclassification of actions or objects, which poses risks in surveillance and autonomous systems____. Large Language Models (LLMs) are also vulnerable to adversarial prompts or crafted textual inputs that manipulate their responses, potentially leading to the generation of harmful or misleading information____. Recent research has demonstrated that adversarial attack techniques using regularized relaxation can efficiently generate adversarial inputs against aligned LLMs, improving attack success rates while maintaining token validity____. Navigation systems, such as those used in autonomous vehicles, are similarly at risk, where adversarial attacks on perception models can cause incorrect path planning or obstacle avoidance, significantly compromising safety____. Additionally, vision-language navigation (VLN) systems have been shown to be vulnerable to imperceptible adversarial modifications in visual inputs, allowing malicious path manipulations that can mislead autonomous agents____. The pervasiveness of adversarial vulnerabilities across different modalities underscores the necessity for developing robust defense mechanisms to mitigate such threats.


\subsection{DeepSeek MLLMs}
The DeepSeek family of MLLMs, comprising Janus____, Janus Flow____, and Janus Pro____, represents a series of progressively refined open-source models. The latest iteration, Janus Pro, offers state-of-the-art multimodal reasoning with two model sizes—1B and 7B parameters—catering to different computational requirements. Compared to LLaVA-1.5, Janus Pro has demonstrated superior performance across multiple multimodal benchmarks. Unlike DeepSeek-R1 ____, which is limited to textual modalities, Janus Pro supports both textual and visual inputs, broadening its applicability. While DeepSeek Janus Pro has shown promising results, its susceptibility to adversarial perturbations remains underexplored. Comparative studies assessing its robustness against existing attack methodologies are essential to understanding its reliability in real-world applications.