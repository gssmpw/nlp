[
  {
    "index": 0,
    "papers": [
      {
        "key": "shahriar2024putting",
        "author": "Shahriar, Sakib and Lund, Brady D and Mannuru, Nishith Reddy and Arshad, Muhammad Arbab and Hayawi, Kadhim and Bevara, Ravi Varma Kumar and Mannuru, Aashrith and Batool, Laiba",
        "title": "Putting gpt-4o to the sword: A comprehensive evaluation of language, vision, speech, and multimodal proficiency"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "liu2024visual",
        "author": "Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae",
        "title": "Visual instruction tuning"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "zhu2023minigpt",
        "author": "Zhu, Deyao and Xu, Junnan and Zhang, Zhegan and Zhang, Xiaohua",
        "title": "MiniGPT-4: Enhancing vision-language understanding with advanced large language models"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "li2023blip",
        "author": "Li, Junnan and Hu, Dongxu and Xie, Jinyu and Wu, Lijuan and Jain, Anirudh and Liu, Pengchuan and Zhang, Lei and Hwang, Jenq-Neng and Gao, Jianfeng",
        "title": "BLIP-2: Bootstrapped Language-Image Pre-training with Frozen Image Encoders and Large Language Models"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "awadalla2023openflamingo",
        "author": "Awadalla, Awni and Prabhumoye, Shrimai and Singh, Amanpreet and Sun, Chunyuan and Hu, Junnan and Kale, Mihir and Jain, Vedanuj and Wang, Xin and and Liu, Jiahui and Soricut, Radu and others",
        "title": "OpenFlamingo: An Open-Source Framework for Training Large Autoregressive Vision-Language Models"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "bai2023qwenvl",
        "author": "Bai, Zihan and Wu, Qingqing and Zhang, Yue and Jiang, Yangyang and Li, Xu and others",
        "title": "Qwen-VL: A Scalable and Versatile Vision-Language Model"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "chen2025janus",
        "author": "Chen, Xiaokang and Wu, Zhiyu and Liu, Xingchao and Pan, Zizheng and Liu, Wen and Xie, Zhenda and Yu, Xingkai and Ruan, Chong",
        "title": "Janus-Pro: Unified Multimodal Understanding and Generation with Data and Model Scaling"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "goodfellow2014explaining",
        "author": "Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian",
        "title": "Explaining and harnessing adversarial examples"
      },
      {
        "key": "papernot2016limitations",
        "author": "Papernot, Nicolas and McDaniel, Patrick and Jha, Somesh and Fredrikson, Matt and Celik, Z Berkay and Swami, Ananthram",
        "title": "The limitations of deep learning in adversarial settings"
      },
      {
        "key": "mkadry2017towards",
        "author": "M{\\k{a}}dry, Aleksander and Makelov, Aleksandar and Schmidt, Ludwig and Tsipras, Dimitris and Vladu, Adrian",
        "title": "Towards deep learning models resistant to adversarial attacks"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "wan2023poisoning",
        "author": "Wan, Alexander and Wallace, Eric and Shen, Sheng and Klein, Dan",
        "title": "Poisoning language models during instruction tuning"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "chakraborty2021survey",
        "author": "Chakraborty, Anirban and Alam, Manaar and Dey, Vishal and Chattopadhyay, Anupam and Mukhopadhyay, Debdeep",
        "title": "A survey on adversarial attacks and defences"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "moosavidezfooli2017universaladversarialperturbations",
        "author": "Seyed-Mohsen Moosavi-Dezfooli and Alhussein Fawzi and Omar Fawzi and Pascal Frossard",
        "title": "Universal adversarial perturbations"
      },
      {
        "key": "lu2024test",
        "author": "Lu, Dong and Pang, Tianyu and Du, Chao and Liu, Qian and Yang, Xianjun and Lin, Min",
        "title": "Test-time backdoor attacks on multimodal large language models"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "carlini2018audioadversarialexamplestargeted",
        "author": "Nicholas Carlini and David Wagner",
        "title": "Audio Adversarial Examples: Targeted Attacks on Speech-to-Text"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "jiang2019blackboxadversarialattacksvideo",
        "author": "Linxi Jiang and Xingjun Ma and Shaoxiang Chen and James Bailey and Yu-Gang Jiang",
        "title": "Black-box Adversarial Attacks on Video Recognition Models"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "zou2023universaltransferableadversarialattacks",
        "author": "Andy Zou and Zifan Wang and Nicholas Carlini and Milad Nasr and J. Zico Kolter and Matt Fredrikson",
        "title": "Universal and Transferable Adversarial Attacks on Aligned Language Models"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "chacko2024adversarialattackslargelanguage",
        "author": "Samuel Jacob Chacko and Sajib Biswas and Chashi Mahiul Islam and Fatema Tabassum Liza and Xiuwen Liu",
        "title": "Adversarial Attacks on Large Language Models Using Regularized Relaxation"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "mahima2021adversarial",
        "author": "Mahima, KT Yasas and Ayoob, Mohamed and Poravi, Guhanathan",
        "title": "Adversarial Attacks and Defense Technologies on Autonomous Vehicles: A Review."
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "islam2024maliciouspathmanipulationsexploitation",
        "author": "Chashi Mahiul Islam and Shaeke Salman and Montasir Shams and Xiuwen Liu and Piyush Kumar",
        "title": "Malicious Path Manipulations via Exploitation of Representation Vulnerabilities of Vision-Language Navigation Systems"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "wu2024janus",
        "author": "Wu, Chengyue and Chen, Xiaokang and Wu, Zhiyu and Ma, Yiyang and Liu, Xingchao and Pan, Zizheng and Liu, Wen and Xie, Zhenda and Yu, Xingkai and Ruan, Chong and others",
        "title": "Janus: Decoupling visual encoding for unified multimodal understanding and generation"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "ma2024janusflow",
        "author": "Yiyang Ma and Xingchao Liu and Xiaokang Chen and Wen Liu and Chengyue Wu and Zhiyu Wu and Zizheng Pan and Zhenda Xie and Haowei Zhang and Xingkai yu and Liang Zhao and Yisong Wang and Jiaying Liu and Chong Ruan",
        "title": "JanusFlow: Harmonizing Autoregression and Rectified Flow for Unified Multimodal Understanding and Generation"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "chen2025janus",
        "author": "Chen, Xiaokang and Wu, Zhiyu and Liu, Xingchao and Pan, Zizheng and Liu, Wen and Xie, Zhenda and Yu, Xingkai and Ruan, Chong",
        "title": "Janus-Pro: Unified Multimodal Understanding and Generation with Data and Model Scaling"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "guo2025deepseek",
        "author": "Guo, Daya and Yang, Dejian and Zhang, Haowei and Song, Junxiao and Zhang, Ruoyu and Xu, Runxin and Zhu, Qihao and Ma, Shirong and Wang, Peiyi and Bi, Xiao and others",
        "title": "Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning"
      }
    ]
  }
]