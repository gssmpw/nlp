\vspace{-2mm}
\section{Preliminaries}
% \textbf{Latent Diffusion Models (LDM)} \citep{podell2023sdxl,rombach2022high} operate in a compressed latent space rather than directly in pixel space. They first encode an input image into a lower-dimensional latent representation using a VAE \citep{kingma2013auto} and then apply the diffusion process on this compressed space. Given an input image sampled from original data distribution $\mathbf{x}\sim \mathbb{P}_{\mathrm{data}}$, VAE encoder $\mathcal{E}$ encodes it to latent variable $\textbf{z}_0$, the LDM iteratively corrupts the latent representation by adding noise, then learns to reverse this process to generate a new sample coherent with the original data distribution $\mathbb{P}_{\mathrm{data}}$. The training objective involves minimizing the error between the noisy latent sample at time $t$ and the denoised prediction:
% \begin{equation}
%     \mathcal{L}_\mathrm{simple} = \mathbb{E}_{t \sim \mathcal{U}[0,1], \mathbf{x} \sim \mathbb{P}_{\mathrm{data}}, \mathbf{z}_0 = \mathcal{E}(\mathbf{x}) , \boldsymbol{\epsilon} \sim \mathcal{N}(\mathbf{0}, \mathbf{I})}\left[\left\Vert \boldsymbol{\epsilon} - \boldsymbol{\epsilon}_{\theta}(\mathbf{z}_t, t) \right\Vert^2\right],
% \end{equation}
% where $\mathbf{z}_t$ is the noisy latent variable at step $t$, $\boldsymbol{\epsilon}$ represents the Gaussian noise added to the latent, and $\boldsymbol{\epsilon}_{\theta}(\mathbf{z}_t, t)$ is the predicted noise by the UNet denoiser $\boldsymbol{\epsilon}_{\theta}$ at step $t$. 

\textbf{Latent Diffusion Models (LDM)} \citep{podell2023sdxl,rombach2022high} operate in a compressed latent space rather than directly in pixel space. Using a VAE \citep{kingma2013auto} encoder $\mathcal{E}$, they encode an input image $\mathbf{x} \sim \mathbb{P}_{\mathrm{data}}$ into a lower-dimensional latent variable $\mathbf{z}_0$, on which the diffusion process is applied. The model iteratively corrupts $\mathbf{z}_0$ with noise and learns to reverse this process to generate new samples coherent with the original data distribution. The training objective minimizes the error between the noisy latent sample at time $t$ and the denoised prediction: \begin{equation}  
\small
\mathcal{L}_\mathrm{simple} = \mathbb{E}_{t \sim \mathcal{U}[0,1], \mathbf{x} \sim \mathbb{P}_{\mathrm{data}}, \mathbf{z}_0 = \mathcal{E}(\mathbf{x}) , \boldsymbol{\epsilon} \sim \mathcal{N}(\mathbf{0}, \mathbf{I})}\left[\left\Vert \boldsymbol{\epsilon} - \boldsymbol{\epsilon}_{\theta}(\mathbf{z}_t, t) \right\Vert^2\right],\end{equation} where $\boldsymbol{\epsilon}_{\theta}(\mathbf{z}_t, t)$ represents UNet denoiser's \citep{ho2020denoising, rombach2022high} predicted noise.

% \textbf{UNet Denoiser} \citep{podell2023sdxl} is a neural network designed to perform the denoising task at each step of the diffusion process. The UNet $\boldsymbol{\epsilon}_{\theta}$ takes as input a noisy latent representation $\mathbf{z}_t$ and the corresponding timestep $t$, and it outputs the estimated noise that was added at that step.

% \textbf{Denoising Diffusion Implicit Models (DDIM)} \citep{song2021score} is a widely used technique that accelerates the sampling process in diffusion models while maintaining high sample quality. DDIM adjusts the reverse diffusion process by directly predicting the latent variable at the next timestep, skipping several intermediary steps while maintaining accuracy. This technique uses deterministic sampling, enabling faster convergence while reducing computational resources. With $\alpha_t$ as a noise scheduling parameter, the DDIM update step is defined as:

\textbf{Denoising Diffusion Implicit Models (DDIM)} \citep{song2021score} accelerate the sampling process in diffusion models while maintaining high-quality samples. DDIM adjusts the reverse diffusion process by directly predicting the latent variable at the next timestep using deterministic sampling, which allows for faster convergence. The DDIM update step is defined as:
\begin{equation}
\small
\mathbf{z}_{t-1}=\sqrt{\alpha_{t-1}}\frac{\mathbf{z}_t-\sqrt{1-\alpha_t} \boldsymbol{\epsilon}_\theta\left(\mathbf{z}_t, t\right)}{\sqrt{\alpha_t}}+\sqrt{1-\alpha_{t-1}} \cdot \boldsymbol{\epsilon}_\theta\left(\mathbf{z}_t, t\right).
\end{equation}
% \textbf{LoRA} \citep{hu2021lora} reduces the need for updating all model parameters during fine-tuning by introducing small trainable low-rank matrices into the network. This allows efficient adaptation of large models, reducing both memory usage and computational cost while preserving performance.