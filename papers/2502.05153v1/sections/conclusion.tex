% \vspace{-1em}
\section{Conclusion}
We introduce \method, a novel diffusion-based image generation algorithm that provides both high fidelity and diversity when generating images guided by multimodal context, consisting of a reference image and accompanying text guidance. By incorporating a Multimodal Context Evaluator and leveraging Global Semantic and Fine-Grained Consistency Rewards, \method ensures that the generated images accurately preserve specified scene attributes, such as object interactions and spatial relationships, while maintaining visual diversity. Our comprehensive experiments demonstrate that \method outperforms SOTA methods across multiple benchmarks, including VQA and HOI Reasoning, as well as object-centric benchmarks. The results validate \method's ability to generate high-fidelity, multimodal context-aligned images that improve scene-aware task performance while maintaining diversity of generated images. \method sets a new standard for scene-aware image generation, with potential applications for a wide range of multimodal tasks.

% In this paper, we introduce \method, a novel diffusion-based image generation method that balances high fidelity and diversity when generating images guided by multimodal context, consisting of a reference image and accompanying text guidance. By incorporating a Multimodal Context Evaluator and leveraging Global Semantic and Fine-Grained Consistency Rewards, \method ensures that the generated images accurately preserve key scene attributes, such as object interactions and spatial relationships, while maintaining visual diversity. Our comprehensive experiments demonstrate that \method outperforms SOTA methods across various benchmarks, including VQA and HOI Reasoning tasks, as well as object-centric benchmarks like ImageNet and its out-of-distribution variants. The results validate \method's ability to generate high-fidelity, contextually aligned images that improve context-aware task performance, while maintaining diversity in the generated outputs. \method sets a new standard for context-aware image generation, with potential applications across a wide range of multimodal tasks.