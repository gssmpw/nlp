Figure \ref{fig: system} illustrates the workflow of our \textbf{Co}de-Guided \textbf{Syn}thetic data generation system (\textbf{CoSyn}). 
The system takes a language input, such as ``generate a dataset of book covers'', and outputs a multimodal dataset. 
Based on the input query, CoSyn selects one of 20 generation pipelines built on 11 rendering tools.
The process starts with topic generation, conditioned on a sampled persona that guides the style and content. 
Next, the system generates data content and converts it into code, which is then executed to render synthetic images. 
Finally, using the code as context, we prompt the LLM to generate corresponding textual instructions.

In the following, we provide detailed explanations of the rendering tools supported by CoSyn, the tailored generation pipelines based on these tools, our persona-driven approach to diversify content and styles, and the large-scale dataset of 400K synthetic images generated by CoSyn. 

\smallbreak
\noindent \textbf{Rendering Tools.} We integrate various rendering tools to generate diverse types of images, forming the foundation of CoSyn’s ability for text-rich image generation. 
For example, \href{https://matplotlib.org/}{Matplotlib}, \href{https://plotly.com/}{Plotly}, and \href{https://vega.github.io/vega-lite/}{Vega-Lite} are used to create different types of charts.
LaTeX and HTML are used for documents and tables, while \href{https://mermaid.js.org/}{Mermaid} and \href{https://graphviz.org/}{Graphviz} generate diagrams.
We utilize SVG and \href{https://asymptote.sourceforge.io/}{Asymptote} to create vector graphics and math-related content. 
For specialized tasks, we rely on \href{http://lilypond.org/}{Lilypond} to generate music sheets and \href{https://www.rdkit.org/}{RDKit} for chemical structures.
We implement customized functions for each tool to execute LLM-generated code and obtain corresponding rendered images. 
These tools collectively enable CoSyn to produce a wide range of high-quality, text-rich synthetic images.
\begin{figure*}[!t]
    \centering
    \includegraphics[width=\textwidth]{images/dataset.pdf}
    \vspace{-.6cm}
    \caption{Our CoSyn-400K dataset consists of 9 categories of text-rich images with 2.7M instruction-tuning data. More qualitative examples, along with question-answer annotations, are available in Figure \ref{fig: chart_example} -\ref{fig: special_example} in Appendix \ref{appendix: example}.}
    \label{fig: dataset}
    \vspace{-.3cm}
\end{figure*}

\smallbreak
\noindent \textbf{Pipelines.} We design 20 pipelines based on 11 rendering tools.\footnote {Some tools are used in multiple pipelines, e.g., HTML is used for generating documents, tables, and charts.} 
Each pipeline follows the same procedure: (1) \textit{Topic generation} to define the theme of this synthetic example, (2) \textit{Data generation} to populate the detailed contents, (3) \textit{Code generation} to create executable code that renders the image, and (4) \textit{Instruction generation} conditioned on code to produce instructions, including questions, answers and explanations for chain-of-thought reasoning.
Each stage is controlled by a prompt customized for image category and rendering tool. Figure \ref{fig:prompt-html} shows all prompts of the HTML Document pipeline.
\smallbreak
\noindent \textbf{Use personas to enhance diversity.} 
LLMs often struggle to generate diverse synthetic data using sampling parameters alone \citep{yu2023large}, with biases leading to repetitive outputs across different runs. 
Recent work \citep{ge2024scalingsyntheticdatacreation} shows that incorporating personas in prompts can improve diversity by enabling models to generate from varied perspectives.
CoSyn adopts personas to enhance diversity during the Topic Generation stage. 
Each persona is a short sentence describing a personality or identity. 
For example, as shown in the middle of Figure \ref{fig: system}, we sample a persona ``\textit{a sci-fi novelist who likes alien worlds}'', which results in a topic of ``\textit{a novel about Extraterrestrial Flora \& Fauna}'' for generating the book cover image. 
We use the 200K personas released by \citet{ge2024scalingsyntheticdatacreation}.

\smallbreak
\noindent \textbf{Implementation details.} 
CoSyn is built on the DataDreamer library \citep{patel-etal-2024-datadreamer}, which supports robust multi-stage synthetic data generation pipelines that are easy to maintain, reproduce, and extend. 
DataDreamer documents the prompts and parameters used at each generation stage and implements several efficient techniques, such as parallel generation and response caching, to optimize performance.
For the data and code generation stages, we use Claude-3.5-Sonnet, which performs well in coding tasks \citep{Anthropic}. 
For instruction-tuning data generation, we select GPT-4o-mini \citep{gpt4} for its cost efficiency. 
% DataDreamer’s modular design makes the pipeline highly flexible, allowing users to switch LLMs as needed easily.

\smallbreak
\noindent \textbf{CoSyn-400K.} As shown in Figure \ref{fig: dataset}, we use CoSyn to generate a large-scale synthetic dataset of 400K images across nine categories: charts, documents, math problems, tables, diagrams, vector graphics, music sheets, electrical circuits, and chemical structures.
Since CoSyn is controlled via language inputs, it can easily generate diverse, fine-grained image types by varying the input queries. 
For instance, we use over 100 queries to generate document data covering \textit{receipts}, \textit{resumes}, \textit{meal plans}, etc. 
Some queries used for CoSyn-400K are provided in Appendix \ref{appendix: query}. 
This ensures that our dataset covers a broad range of domains.
The following sections validate how our synthetic datasets enhance the ability of VLMs to understand text-rich images.