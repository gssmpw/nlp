\clearpage
\appendix
\onecolumn
% \tableofcontents

% \section*{Appendix Contents}
% \begin{itemize}
%     \item Appendix A: Proof \dotfill Page \pageref{append_proof}
%     \item Appendix B: Implementation Details \dotfill Page \pageref{appendix_experimental_details}
%     \item Appendix C: Additional Experimental Results \dotfill Page \pageref{appendix_additional_results}
% \end{itemize}


\section*{Appendix Contents}
\begin{itemize}
    \item Appendix \ref{append_proof}: Proof \dotfill Page \pageref{append_proof}
    \begin{itemize}
        \item \ref{proof_theorem_4.1} Proof of Theorem 4.1 \dotfill Page \pageref{proof_theorem_4.1}
        \item \ref{proof_theorem_4.2} Proof of Theorem 4.2 \dotfill Page \pageref{proof_theorem_4.2}
        \item \ref{proof_proposition_4.3} Proof of Proposition 4.3 \dotfill Page \pageref{proof_proposition_4.3}
        \item \ref{proof_derivation_transition_prob} Derivation of the transition probability \eqref{mu_gamma_prime} \dotfill Page \pageref{proof_derivation_transition_prob}
        \item \ref{proof_derivation_transition_prob} Derivation of the training objective \eqref{objective_function} \dotfill Page \pageref{proof_objective_function}
        \item \ref{proof_proposition_4.4} Proof of Proposition 4.4 \dotfill Page \pageref{proof_proposition_4.4}
        \item \ref{proof_derivation_UniDB-GOU} Derivation of UniDB-GOU \dotfill Page \pageref{proof_derivation_UniDB-GOU}
        \item \ref{ve_vp_example} Examples of UniDB-VE and UniDB-VP \dotfill Page \pageref{ve_vp_example}
        \item \ref{proof_proposition_4.5} Proof of Proposition 4.5 \dotfill Page \pageref{proof_proposition_4.5}
    \end{itemize}
    \item Appendix \ref{append_pseudo}: Pseudocode Descriptions \dotfill Page \pageref{append_pseudo}
    % \item Appendix \ref{append_ablation}: Additional Ablation Study \dotfill Page \pageref{append_ablation}
    \item Appendix \ref{more_related_work}: More Related Work \dotfill Page \pageref{more_related_work}
    \item Appendix \ref{appendix_experimental_details}: Implementation Details \dotfill Page \pageref{appendix_experimental_details}
    \item Appendix \ref{appendix_additional_results}: Additional Experimental Results \dotfill Page \pageref{appendix_additional_results}
\end{itemize}



\section{Proof}\label{append_proof}
\subsection{Proof of Theorem \ref{theorem_4.1}} \label{proof_theorem_4.1}
\noindent \textbf{Theorem \ref{theorem_4.1}.} 
\textit{Consider the SOC problem \eqref{SOC_problem_generalized_ode}, denote $d_{t, \gamma} = \gamma^{-1} + e^{2\bar{f}_{T}} \bar{g}^2_{t:T}$, $\bar{f}_{s:t} = \int_{s}^{t} f_z dz$, $\bar{h}_{s:t} = \int_{s}^{t} e^{-\bar{f}_{z}} h_z dz$ and $\bar{g}^2_{s:t} = \int_{s}^{t} e^{-2\bar{f}_{z}}g^2_z dz$, denote $\bar{f}_{t}$, $\bar{h}_{t}$ and $\bar{g}^2_{t}$ for simplification when $s=0$, then the closed-form optimal controller $\mathbf{u}_{t,\gamma}^{*}$ is} 
\begin{equation}\tag{\ref{general_optimal_controller}}
\mathbf{u}_{t, \gamma}^{*} = g_t e^{\bar{f}_{t:T}} \frac{x_{T} - e^{\bar{f}_{t:T}} \mathbf{x}_t - \mathbf{m} e^{\bar{f}_{T}} \bar{h}_{t:T}}{d_{t, \gamma}},
\end{equation}
\textit{and the transition of $\mathbf{x}_t$ from $x_0$ and $x_T$ is}
\begin{equation}\tag{\ref{general_interpolant}}
\mathbf{x}_t = e^{\bar{f}_{t}} \Bigg(\frac{d_{t, \gamma}}{d_{0, \gamma}} x_0 + \frac{e^{\bar{f}_{T}} \bar{g}^2_{t}}{d_{0, \gamma}} x_T + \Big(\bar{h}_{t} - \frac{e^{2\bar{f}_{T}} \bar{h}_{T} \bar{g}^2_{t}}{d_{0, \gamma}}\Big) \mathbf{m}\Bigg). 
\end{equation}

\begin{proof}
% Consider the control problem \eqref{control_problem_ode}: 
% \begin{equation}
% \begin{aligned}
% \min_{\mathbf{u}_{t, \gamma} \in \mathcal{U}} &\int_{0}^{T} \frac{1}{2} \|\mathbf{u}_{t, \gamma}\|_2^2 dt + \frac{\gamma}{2} \| \mathbf{x}_T^u - x_T\|_2^2 \\
% \text{s.t.} \quad \mathrm{d} \mathbf{x}_t &= \left( f_t \mathbf{x}_t + h_t \mathbf{m} + g_t \mathbf{u}_{t, \gamma} \right) \mathrm{d} t, \quad \mathbf{x}_0 = x_0
% \end{aligned}
% \end{equation}

% where $\gamma$ is the terminal cost coefficient, $f, g, h : [0, T] \rightarrow \mathbb{R}$ and $\mathbf{m} \in \mathbb{R}^n$ is a given constant vector. \\
% According to Certainty Equivalence, the problem is equal to the following control problem: 
% \begin{equation}
% \begin{aligned}
% \min_{\mathbf{u}_{t, \gamma}} &\int_{0}^{T} \frac{1}{2} \|\mathbf{u}_t\|_2^2 dt + \frac{\gamma}{2} \| \mathbf{x}_T^u - x_T\|_2^2 \\
% \text{s.t.} \quad \mathrm{d} \mathbf{x}_t &= \left( f_t \mathbf{x}_t + h_t \mathbf{m} + g_t \mathbf{u}_{t, \gamma} \right) \mathrm{d} t, \quad \mathbf{x}_0 = x_0
% \end{aligned}
% \end{equation}

According to Pontryagin Maximum Principle \cite{1100008, Kirk1970OptimalCT} recipe, one can construct the Hamiltonian: 
\begin{equation}
H(t,\mathbf{x}_t,\mathbf{u}_{t,\gamma},\mathbf{p}_t)=\frac{1}{2}\|\mathbf{u}_{t, \gamma}\|_{2}^{2}+ \mathbf{p}_t^{T} \left( f_t \mathbf{x}_t + h_t \mathbf{m} + g_t \mathbf{u}_t \right).
\end{equation}

By setting: 
\begin{equation}
\frac{\partial H}{\partial \mathbf{u}_{t, \gamma}} = 0 \quad \Rightarrow \quad \mathbf{u}_{t, \gamma}^{*} = - g_t \mathbf{p}_t.
\end{equation}

% We get: 
% \begin{equation}
% \mathbf{u}_{t, \gamma}^{*} = - g_t \mathbf{p}_t
% \end{equation}

Then the value function becomes
\begin{equation}
V^*=\min_{\mathbf{u}_{t,\gamma}}H(t,\mathbf{x}_t,\mathbf{p}_t,\mathbf{u}_{t, \gamma})=H(t,\mathbf{x}_t,\mathbf{p}_t,\mathbf{u}_{t, \gamma}^*)= -\frac{g^2_t}{2}\left\|\mathbf{p}_t\right\|^2_2 + f_t \mathbf{p}_t^{T} \mathbf{x}_t + h_t \mathbf{p}_t^{T} \mathbf{m}.
\end{equation}

Now, according to minimum principle theorem to obtain the following set of differential equations: 
\begin{equation}\label{mpt1_general}
\frac{\mathrm{d}\mathbf{x}_{t}}{\mathrm{d}t}=\nabla_{\mathbf{p}_t}H\left(\mathbf{x}_{t},\mathbf{p}_{t},\mathbf{u}_{t, \gamma}^{*},t\right)= - g^2_t \mathbf{p}_{t} + f_t\mathbf{x}_t + h_t\mathbf{m},
\end{equation}
\begin{equation}\label{mpt2_general}
\frac{\mathrm{d}\mathbf{p}_{t}}{\mathrm{d}t}= -\nabla_{\mathbf{x}_t}H\left(\mathbf{x}_{t},\mathbf{p}_{t},\mathbf{u}_{t}^{*},t\right) = -\mathbf{p}_{t} f_t,
\end{equation}
\begin{equation}\label{mpt3_general}
\mathbf{x}_{0} = x_{0},
\end{equation}
\begin{equation}\label{mpt4_general}
\mathbf{p}_{T}=\gamma \left(\mathbf{x}_T-x_{T}\right).
\end{equation}

Solving the Equation \eqref{mpt2_general}, we have:
\begin{equation}
\begin{gathered}
\mathbf{p}_{t} = \mathbf{p}_{0} e^{-\bar{f}_{t}}, \\
\mathbf{p}_{T} = \mathbf{p}_{0} e^{-\bar{f}_{T}}.
\end{gathered}
\end{equation}

Solve the Equation \eqref{mpt1_general}:
\begin{align*}
    &\frac{\mathrm{d} \mathbf{x}_t}{\mathrm{d} t} = f_t\mathbf{x}_t + h_t\mathbf{m} - g^2_t \mathbf{p}_{t} \\
    \Rightarrow \quad &\frac{\mathrm{d} (e^{-\bar{f}_{t}} \mathbf{x}_t)}{\mathrm{d} t} = e^{-\bar{f}_{t}} h_t \mathbf{m} - e^{-\bar{f}_{t}} g^2_t \mathbf{p}_{t}, \\
    \Rightarrow \quad &e^{-\bar{f}_{t}} \mathbf{x}_t - \mathbf{x}_0 = \mathbf{m} \bar{h}_{t} - \mathbf{p}_{0} \bar{g}^2_{t},  \\
    \Rightarrow \quad &e^{-\bar{f}_{t}} \mathbf{x}_t - x_0 = \mathbf{m} \bar{h}_{t} - \mathbf{p}_{0} \bar{g}^2_{t}. \\
\end{align*}

Hence, we can get:
\begin{equation}\label{x1_general}
\mathbf{x}_T = e^{\bar{f}_{T}}x_0 + \mathbf{m} e^{\bar{f}_{T}} \bar{h}_{T} - \mathbf{p}_{T} e^{2\bar{f}_{T}} \bar{g}^2_{T},
\end{equation}
and
\begin{equation}\label{xt_general}
\mathbf{x}_t = e^{\bar{f}_{t}}x_0 + \mathbf{m} e^{\bar{f}_{t}} \bar{h}_{t} - \mathbf{p}_{T} e^{\bar{f}_{t}} e^{\bar{f}_{T}} \bar{g}^2_{t}.
\end{equation}

Take the Equation \eqref{x1_general} into the Equation \eqref{mpt4_general} and solve $\mathbf{p}_{T}$, 
\begin{align}\label{pT_general}
&\mathbf{p}_{T} = \gamma \left( e^{\bar{f}_{T}}x_0 + \mathbf{m} e^{\bar{f}_{T}} \bar{h}_{T} - \mathbf{p}_{T} e^{2\bar{f}_{T}} \bar{g}^2_{T} - x_{T} \right) \\
\Rightarrow \quad & \mathbf{p}_{T} = \frac{\gamma \left( e^{\bar{f}_{T}}x_0 + \mathbf{m} e^{\bar{f}_{T}} \bar{h}_{T} - x_{T} \right)}{1 + \gamma e^{2\bar{f}_{T}} \bar{g}^2_{T}}.
\end{align}

% If take $\gamma \to \infty$, 
% \begin{equation}\label{p1_general}
% \mathbf{p}_{T} = \frac{e^{\bar{f}_{T}}x_0 + \mathbf{m} e^{\bar{f}_{T}} \int_{0}^{T}e^{-\bar{f}_{z}} h_z dz - x_{T}}{e^{2\bar{f}_{T}} \int_{0}^{T} e^{-2\bar{f}_{z}}g^2_z dz}
% \end{equation}

Also, take the Equation \eqref{pT_general} into the equation \eqref{xt_general}, 
\begin{equation}\label{36}
\begin{split}
    \mathbf{x}_t 
    &= e^{\bar{f}_{t}}x_0 + \mathbf{m} e^{\bar{f}_{t}} \bar{h}_{t} - e^{\bar{f}_{t}} e^{\bar{f}_{T}} \bar{g}^2_{t} \frac{e^{\bar{f}_{T}}x_0 + \mathbf{m} e^{\bar{f}_{T}} \bar{h}_{T} - x_{T}}{\gamma^{-1} + e^{2\bar{f}_{T}} \bar{g}^2_{T}},  \\
    &= e^{\bar{f}_{t}} \Bigg(\frac{d_{t, \gamma}}{d_{0, \gamma}} x_0 + \frac{e^{\bar{f}_{T}} \bar{g}^2_{t}}{d_{0, \gamma}} x_T + \Big(\bar{h}_{t} - \frac{e^{2\bar{f}_{T}} \bar{h}_{T} \bar{g}^2_{t}}{d_{0, \gamma}}\Big) \mathbf{m}\Bigg). \\
\end{split}
\end{equation}

% Hence, 
% \begin{equation}
% \begin{split}
% g_t \mathbf{u}^{*}_{t, \infty} 
% &= - g^2_t \mathbf{p}_{t} \\
% &= - g^2_t e^{-\bar{f}_{t}} e^{\bar{f}_{T}} \frac{e^{\bar{f}_{T}}x_0 + \mathbf{m} e^{\bar{f}_{T}} \int_{0}^{T}e^{-\bar{f}_{z}} h_z dz - x_{T}}{e^{2\bar{f}_{T}} \int_{0}^{T} e^{-2\bar{f}_{z}}g^2_z dz} \\
% &= - g^2_t e^{-\bar{f}_{t}} \frac{e^{\bar{f}_{T}} x_0 + \mathbf{m} e^{\bar{f}_{T}} \int_{0}^{T}e^{-\bar{f}_{z}} h_z dz - x_{T}}{e^{\bar{f}_{T}} \int_{0}^{T} e^{-2\bar{f}_{z}}g^2_z dz}
% \end{split}
% \end{equation}

% The origin dynamics can be: 
% \begin{equation}
% \mathrm{d} \mathbf{x}_t = \left( f_t \mathbf{x}_t + h_t \mathbf{m} + g^2_t e^{-\bar{f}_{t}} \frac{x_{T} - e^{\bar{f}_{T}} x_0 - \mathbf{m} e^{\bar{f}_{T}} \int_{0}^{T}e^{-\bar{f}_{z}} h_z dz}{e^{\bar{f}_{T}} \int_{0}^{T} e^{-2\bar{f}_{z}}g^2_z dz} \right) \mathrm{d} t + g_t \mathrm{d} w_t
% \end{equation}

Preserve $\gamma$, 
\begin{equation}
\begin{split}
\mathbf{u}^{*}_{t, \gamma} 
&= - g_t \mathbf{p}_{t}, \\
&= - g_t e^{-\bar{f}_{t}} e^{\bar{f}_{T}} \frac{e^{\bar{f}_{T}}x_0 + \mathbf{m} e^{\bar{f}_{T}} \bar{h}_{T} - x_{T}}{\gamma^{-1} + e^{2\bar{f}_{T}} \bar{g}^2_{T}}, \\
&= - g_t e^{-\bar{f}_{t}} e^{\bar{f}_{T}} \frac{e^{\bar{f}_{T}} x_0 + \mathbf{m} e^{\bar{f}_{T}} \bar{h}_{T} - x_{T}}{\gamma^{-1}+ e^{2\bar{f}_{T}} \bar{g}^2_{T}}, \\
&= g_t e^{\bar{f}_{t:T}} \frac{x_{T} - e^{\bar{f}_{t:T}} \mathbf{x}_t - \mathbf{m} e^{\bar{f}_{T}} \bar{h}_{t:T}}{d_{t, \gamma}},
\end{split}
\end{equation}
with the fact \eqref{36}
\begin{equation}
\mathbf{x}_t = e^{\bar{f}_{t}} \Bigg(\frac{d_{t, \gamma}}{d_{0, \gamma}} x_0 + \frac{e^{\bar{f}_{T}} \bar{g}^2_{t}}{d_{0, \gamma}} x_T + \Big(\bar{h}_{t} - \frac{e^{2\bar{f}_{T}} \bar{h}_{T} \bar{g}^2_{t}}{d_{0, \gamma}}\Big) \mathbf{m}\Bigg),
\end{equation}
which concludes the proof of the Proposition \ref{theorem_4.1}.
\end{proof}




% \subsubsection{Solve the control problem for VE bridge}\label{app_subsub_ve}

% Consider the control problem: 
% \begin{equation}
% \begin{aligned}
% \min_{\mathbf{u}_t} &\int_{0}^{1} \frac{1}{2} \|\mathbf{u}_t\|_2^2 dt + \frac{\gamma}{2} \| \mathbf{x}_1^u - x_1\|_2^2 \\
% \text{s.t.} \quad \mathrm{d} \mathbf{x}_t &= g_t \mathbf{u}_t \mathrm{d} t + g_t \mathrm{d} w_t, \quad \mathbf{x}_0 = x_0
% \end{aligned}
% \end{equation}

% where $\gamma$ is the terminal cost coefficient. \\
% According to Certainty Equivalence, the problem is equal to the following control problem: 
% \begin{equation}
% \begin{aligned}
% \min_{\mathbf{u}_t} &\int_{0}^{1} \frac{1}{2} \|\mathbf{u}_t\|_2^2 dt + \frac{\gamma}{2} \| \mathbf{x}_1^u - x_1\|_2^2 \\
% \text{s.t.} \quad \mathrm{d} \mathbf{x}_t &= g_t \mathbf{u}_t \mathrm{d} t, \quad \mathbf{x}_0 = x_0
% \end{aligned}
% \end{equation}

% According to Pontryagin Maximum Principle \cite{1100008, Kirk1970OptimalCT} recipe, one can construct the Hamiltonian: 
% \begin{equation}
% H(t,\mathbf{x}_t,\mathbf{u}_t,\mathbf{p}_t)=\frac{1}{2}\|\mathbf{u}_{t}\|_{2}^{2}+g_t \mathbf{p}_t^{T} \mathbf{u}_t
% \end{equation}

% By setting: 
% \begin{equation}
% \frac{\partial H}{\partial \mathbf{u}_t} = 0
% \end{equation}

% We get: 
% \begin{equation}
% \mathbf{u}_t^{*} = - g_t \mathbf{p}_t
% \end{equation}

% Then the value function becomes
% \begin{equation}
% V^*=\min_{\mathbf{u}_t}H(t,\mathbf{x}_t,\mathbf{p}_t,\mathbf{u}_t)=H(t,\mathbf{x}_t,\mathbf{p}_t,\mathbf{u}_t^*)= -\frac{g^2_t}{2}\left\|\mathbf{p}_t\right\|^2_2
% \end{equation}

% Now, according to minimum principle theorem to obtain the following set of differential equations: 
% \begin{equation}\label{mpt1_ve}
% \frac{\mathrm{d}\mathbf{x}_{t}}{\mathrm{d}t}=\nabla_{\mathbf{p}_t}H\left(\mathbf{x}_{t},\mathbf{p}_{t},\mathbf{u}_{t}^{*},t\right)= - g^2_t \mathbf{p}_{t} 
% \end{equation}
% \begin{equation}\label{mpt2_ve}
% \frac{\mathrm{d}\mathbf{p}_{t}}{\mathrm{d}t}= -\nabla_{\mathbf{x}_t}H\left(\mathbf{x}_{t},\mathbf{p}_{t},\mathbf{u}_{t}^{*},t\right) = 0
% \end{equation}
% \begin{equation}\label{mpt3_ve}
% \mathbf{x}_{0} = x_{0}
% \end{equation}
% \begin{equation}\label{mpt4_ve}
% \mathbf{p}_{1}=\gamma \left(\mathbf{x}_1-x_{1}\right)
% \end{equation}

% Solving the equation \ref{mpt2_ve}, we have:
% \begin{equation}
% \mathbf{p}_{t} = \mathbf{p}_{0} = \mathbf{p}_{1}
% \end{equation}

% Then we solve the equation \ref{mpt1_ve}:
% \begin{align*}
%     &\frac{\mathrm{d} \mathbf{x}_t}{\mathrm{d} t} = - g^2_t \mathbf{p}_{t} \\
%     \Rightarrow \quad & \frac{\mathrm{d} \mathbf{x}_t}{\mathrm{d} t} = - g^2_t \mathbf{p}_{1} \\
%     \Rightarrow \quad & \mathbf{x}_1 - \mathbf{x}_t = - \mathbf{p}_{1} \int_{t}^{1} g^2_z dz 
% \end{align*}

% Hence, we can get:
% \begin{equation}\label{x1_ve}
% \mathbf{x}_1 = x_0 - \mathbf{p}_{1} \int_{0}^{1} g^2_z dz 
% \end{equation}
% and
% \begin{equation}\label{xt_ve}
% \mathbf{x}_t = \mathbf{x}_1 + \mathbf{p}_{1} \int_{t}^{1} g^2_z dz 
% \end{equation}

% Take the equation \ref{x1_ve} into the equation \ref{mpt4_ve} and solve $\mathbf{p}_{1}$ in the limit $\gamma \to \infty$, 
% \begin{align*}
% &\mathbf{p}_{1} = \gamma \left( x_0 - \mathbf{p}_{1} \int_{0}^{1} g^2_z dz - x_1 \right) \\
% \Rightarrow \quad & \mathbf{p}_{1} = \frac{\gamma (x_0 - x_1)}{1 + \gamma \int_{0}^{1} g^2_z dz }
% \end{align*}

% Take $\gamma \to \infty$, 
% \begin{equation}\label{p1_ve}
% \mathbf{p}_{1} = \frac{x_0 - x_1}{\int_{0}^{1} g^2_z dz}
% \end{equation}

% Also, take the equation \ref{p1_ve} into the equation \ref{xt_ve}, 
% \begin{equation}
% \begin{split}
%     \mathbf{x}_t 
%     &= \mathbf{x}_1 + \mathbf{p}_{1} \int_{t}^{1} g^2_z dz \\
%     &= x_0 - \mathbf{p}_{1} \int_{0}^{1} g^2_z dz + \mathbf{p}_{1} \int_{t}^{1} g^2_z dz \\
%     &= x_0 - \mathbf{p}_{1} \int_{0}^{t} g^2_z dz \\
%     &= x_0 - \frac{(x_0 - x_1)\int_{0}^{t} g^2_z dz}{\int_{0}^{1} g^2_z dz}  \\
%     &= \frac{\int_{t}^{1} g^2_z dz}{\int_{0}^{1} g^2_z dz} x_0 + \frac{\int_{0}^{t} g^2_z dz}{\int_{0}^{1} g^2_z dz} x_1
% \end{split}
% \end{equation}
% which is a kind of interpolant.

% Hence, 
% \begin{equation}
% g_t \mathbf{u}^{*}_{t} = - g^2_t \mathbf{p}_{t} = g^2_t \frac{x_1 - x_0}{\int_{0}^{1} g^2_z dz}
% \end{equation}

% The origin dynamics can be: 
% \begin{equation}
% \mathrm{d} \mathbf{x}_t = g^2_t \frac{x_1 - x_0}{\int_{0}^{1} g^2_z dz} \mathrm{d} t + g_t \mathrm{d} w_t
% \end{equation}


% \subsubsection{Solve the control problem for VP bridge}\label{app_subsub_vp}

% Consider the control problem: 
% \begin{equation}
% \begin{aligned}
% \min_{\mathbf{u}_t} &\int_{0}^{1} \frac{1}{2} \|\mathbf{u}_t\|_2^2 dt + \frac{\gamma}{2} \| \mathbf{x}_1^u - x_1\|_2^2 \\
% \text{s.t.} \quad \mathrm{d} \mathbf{x}_t &= \left( - \frac{1}{2} g^2_t \mathbf{x}_t + g_t \mathbf{u}_t \right) \mathrm{d} t + g_t \mathrm{d} w_t, \quad \mathbf{x}_0 = x_0
% \end{aligned}
% \end{equation}

% where $\gamma$ is the terminal cost coefficient. \\
% According to Certainty Equivalence, the problem is equal to the following control problem: 
% \begin{equation}
% \begin{aligned}
% \min_{\mathbf{u}_t} &\int_{0}^{1} \frac{1}{2} \|\mathbf{u}_t\|_2^2 dt + \frac{\gamma}{2} \| \mathbf{x}_1^u - x_1\|_2^2 \\
% \text{s.t.} \quad \mathrm{d} \mathbf{x}_t &=  \left( - \frac{1}{2} g^2_t \mathbf{x}_t + g_t \mathbf{u}_t \right) \mathrm{d} t, \quad \mathbf{x}_0 = x_0
% \end{aligned}
% \end{equation}

% According to Pontryagin Maximum Principle \cite{1100008, Kirk1970OptimalCT} recipe, one can construct the Hamiltonian: 
% \begin{equation}
% H(t,\mathbf{x}_t,\mathbf{u}_t,\mathbf{p}_t)=\frac{1}{2}\|\mathbf{u}_{t}\|_{2}^{2}+\mathbf{p}_t^{T} \left( - \frac{1}{2} g^2_t \mathbf{x}_t + g_t \mathbf{u}_t \right)
% \end{equation}

% By setting: 
% \begin{equation}
% \frac{\partial H}{\partial \mathbf{u}_t} = 0
% \end{equation}

% We get: 
% \begin{equation}
% \mathbf{u}_t^{*} = - g_t \mathbf{p}_t
% \end{equation}

% Then the value function becomes
% \begin{equation}
% V^*=\min_{\mathbf{u}_t}H(t,\mathbf{x}_t,\mathbf{p}_t,\mathbf{u}_t)=H(t,\mathbf{x}_t,\mathbf{p}_t,\mathbf{u}_t^*)= - \frac{g^2_t}{2} \mathbf{p}_t^{T} \mathbf{x}_t - \frac{g^2_t}{2}\left\|\mathbf{p}_t\right\|^2_2
% \end{equation}

% Now, according to minimum principle theorem to obtain the following set of differential equations: 
% \begin{equation}\label{mpt1_vp}
% \frac{\mathrm{d}\mathbf{x}_{t}}{\mathrm{d}t}=\nabla_{\mathbf{p}_t}H\left(\mathbf{x}_{t},\mathbf{p}_{t},\mathbf{u}_{t}^{*},t\right)= - \frac{g^2_t}{2} \mathbf{x}_t - g^2_t \mathbf{p}_{t} 
% \end{equation}
% \begin{equation}\label{mpt2_vp}
% \frac{\mathrm{d}\mathbf{p}_{t}}{\mathrm{d}t}=-\nabla_{\mathbf{x}_t}H\left(\mathbf{x}_{t},\mathbf{p}_{t},\mathbf{u}_{t}^{*},t\right) = \frac{g^2_t}{2} \mathbf{p}_t
% \end{equation}
% \begin{equation}\label{mpt3_vp}
% \mathbf{x}_{0} = x_{0}
% \end{equation}
% \begin{equation}\label{mpt4_vp}
% \mathbf{p}_{1}=\gamma \left(\mathbf{x}_1-x_{1}\right)
% \end{equation}

% Solving the equation \ref{mpt2_vp}, we have:
% \begin{equation}
% \begin{gathered}
% \mathbf{p}_{t} = \mathbf{p}_{0} e^{\int_{0}^{t} \frac{g^2_z}{2} dz} \\
% \mathbf{p}_{1} = \mathbf{p}_{0} e^{\int_{0}^{1} \frac{g^2_z}{2} dz}
% \end{gathered}
% \end{equation}

% Then we solve the equation \ref{mpt1_vp}:
% \begin{align*}
%     &\frac{\mathrm{d} \mathbf{x}_t}{\mathrm{d} t} = \frac{g^2_t}{2} \mathbf{x}_t - g^2_t \mathbf{p}_{t} \\
%     \Rightarrow \quad &\frac{\mathrm{d} (e^{\int_{0}^{t} \frac{g^2_z}{2} dz} \mathbf{x}_t)}{\mathrm{d} t} = - e^{\int_{0}^{t} \frac{g^2_z}{2} dz} g^2_t \mathbf{p}_{t} \\
%     \Rightarrow \quad &e^{\int_{0}^{t} \frac{g^2_z}{2} dz} \mathbf{x}_t - \mathbf{x}_0 = - \mathbf{p}_{0} \int_{0}^{t} g^2_z e^{\int_{0}^{z} g^2_m dm} dz  \\
%     \Rightarrow \quad &e^{\int_{0}^{t} \frac{g^2_z}{2} dz} \mathbf{x}_t - x_0 = - \mathbf{p}_{0} (e^{\int_{0}^{t} g^2_z dz} - 1) \\
% \end{align*}

% Hence, we can get:
% \begin{equation}\label{x1_vp}
% \mathbf{x}_1 = e^{-\int_{0}^{1} \frac{g^2_t}{2} dt}x_0 - \mathbf{p}_{1} (1 - e^{-\int_{0}^{1} g^2_t dt})
% \end{equation}
% and
% \begin{equation}\label{xt_vp}
% \mathbf{x}_t = e^{-\int_{0}^{t} \frac{g^2_z}{2} dz}x_0 - e^{-\int_{0}^{1} \frac{g^2_t}{2} dt} \mathbf{p}_{1} (e^{\int_{0}^{t} \frac{g^2_z}{2} dz} - e^{-\int_{0}^{t} \frac{g^2_z}{2} dz})
% \end{equation}

% Take the equation \ref{x1_vp} into the equation \ref{mpt4_vp} and solve $\mathbf{p}_{1}$ in the limit $\gamma \to \infty$, 
% \begin{align*}
% &\mathbf{p}_{1} = \gamma \left( e^{-\int_{0}^{1} \frac{g^2_t}{2} dt}x_0 - \mathbf{p}_{1} (1 - e^{-\int_{0}^{1} g^2_t dt}) - x_{1} \right) \\
% \Rightarrow \quad & \mathbf{p}_{1} = \frac{\gamma (e^{-\int_{0}^{1} \frac{g^2_t}{2} dt}x_0 - x_1) }{1 + \gamma (1 - e^{-\int_{0}^{1} g^2_t dt})}
% \end{align*}

% Take $\gamma \to \infty$, 
% \begin{equation}\label{p1_vp}
% \mathbf{p}_{1} = \frac{e^{-\int_{0}^{1} \frac{g^2_t}{2} dt}x_0 - x_1}{1 - e^{-\int_{0}^{1} g^2_t dt}}
% \end{equation}

% Also, take the equation \ref{p1_vp} into the equation \ref{xt_vp}, 
% \begin{equation}
% \begin{split}
%     \mathbf{x}_t 
%     &= e^{-\int_{0}^{t} \frac{g^2_z}{2} dz}x_0 - e^{-\int_{0}^{1} \frac{g^2_t}{2} dt} \frac{e^{-\int_{0}^{1} \frac{g^2_t}{2} dt}x_0 - x_1}{1 - e^{-\int_{0}^{1} g^2_t dt}} (e^{\int_{0}^{t} \frac{g^2_z}{2} dz} - e^{-\int_{0}^{t} \frac{g^2_z}{2} dz})  \\
%     &= \left(e^{-\int_{0}^{t} \frac{g^2_z}{2} dz} - e^{-\int_{0}^{1} \frac{g^2_z}{2} dz} \frac{e^{\int_{0}^{t} \frac{g^2_z}{2} dz} - e^{-\int_{0}^{t} \frac{g^2_z}{2} dz}}{e^{\int_{0}^{1} \frac{g^2_z}{2} dz} - e^{-\int_{0}^{1} \frac{g^2_z}{2} dz}} \right) x_0 + \left( \frac{e^{\int_{0}^{t} \frac{g^2_z}{2} dz} - e^{-\int_{0}^{t} \frac{g^2_z}{2} dz}}{e^{\int_{0}^{1} \frac{g^2_z}{2} dz} - e^{-\int_{0}^{1} \frac{g^2_z}{2} dz}} \right) x_1 \\
% \end{split}
% \end{equation}
% which is a kind of interpolant.

% Hence, 
% \begin{equation}
% g_t \mathbf{u}^{*}_{t} = - g^2_t \mathbf{p}_{t} = - g^2_t e^{-\int_{t}^{1} \frac{g^2_z}{2} dz} \frac{e^{-\int_{0}^{1} \frac{g^2_t}{2} dt}x_0 - x_1}{1 - e^{-\int_{0}^{1} g^2_t dt}} = g^2_t e^{\int_{0}^{t} \frac{g^2_z}{2} dz} \frac{x_1 - e^{-\int_{0}^{1} \frac{g^2_t}{2} dt}x_0}{e^{\int_{0}^{1} \frac{g^2_z}{2} dz} - e^{-\int_{0}^{1} \frac{g^2_z}{2} dz}}
% \end{equation}

% The origin dynamics can be: 
% \begin{equation}
% \mathrm{d} \mathbf{x}_t = \left( - \frac{1}{2} g^2_t \mathbf{x}_t + g^2_t e^{\int_{0}^{t} \frac{g^2_z}{2} dz} \frac{x_1 - e^{-\int_{0}^{1} \frac{g^2_t}{2} dt}x_0}{e^{\int_{0}^{1} \frac{g^2_z}{2} dz} - e^{-\int_{0}^{1} \frac{g^2_z}{2} dz}} \right) \mathrm{d} t + g_t \mathrm{d} w_t
% \end{equation}


% \subsubsection{Solve the control problem for GOUB}\label{app_subsub_goub}

% Consider the control problem: 
% \begin{equation}
% \begin{aligned}
% \min_{\mathbf{u}_{t, \gamma}} &\int_{0}^{T} \frac{1}{2} \|\mathbf{u}_{t,\gamma}\|_2^2 dt + \frac{\gamma}{2} \| \mathbf{x}_T^u - x_T\|_2^2 \\
% \text{s.t.} \quad \mathrm{d} \mathbf{x}_t &= \left( \theta_t(x_T - \mathbf{x}_t) + g_t \mathbf{u}_{t, \gamma} \right) \mathrm{d} t + g_t \mathrm{d} w_t, \quad \mathbf{x}_0 = x_0
% \end{aligned}
% \end{equation}

% where $\gamma$ is the terminal cost coefficient and the definition of $\mu$ and $g_t$ is the same as GOUB: $\mu = x_T$  $g_{t}^{2} = 2 \lambda^2 \theta_t $. \\
% According to Certainty Equivalence, the problem is equal to the following control problem: 
% \begin{equation}
% \begin{aligned}
% \min_{\mathbf{u}_{t, \gamma}} &\int_{0}^{T} \frac{1}{2} \|\mathbf{u}_{t,\gamma}\|_2^2 dt + \frac{\gamma}{2} \| \mathbf{x}_T^u - x_T\|_2^2 \\
% \text{s.t.} \quad \mathrm{d} \mathbf{x}_t &= \left( \theta_t(x_T - \mathbf{x}_t) + g_t \mathbf{u}_{t, \gamma} \right) \mathrm{d} t, \quad \mathbf{x}_0 = x_0
% \end{aligned}
% \end{equation}

% According to Pontryagin Maximum Principle \cite{1100008, Kirk1970OptimalCT} recipe, one can construct the Hamiltonian: 
% \begin{equation}
% H(t,\mathbf{x}_t,\mathbf{u}_{t, \gamma},\mathbf{p}_t)=\frac{1}{2}\|\mathbf{u}_{t, \gamma}\|_{2}^{2}+\mathbf{p}_t^{T} \left( \theta_t(x_T - \mathbf{x}_t) + g_t \mathbf{u}_{t, \gamma} \right)
% \end{equation}

% By setting: 
% \begin{equation}
% \frac{\partial H}{\partial \mathbf{u}_{t, \gamma}} = 0
% \end{equation}

% We get: 
% \begin{equation}
% \mathbf{u}_{t, \gamma}^{*} = - g_t \mathbf{p}_t
% \end{equation}

% Then the value function becomes
% \begin{equation}
% V^*=\min_{\mathbf{u}_{t, \gamma}}H(t,\mathbf{x}_t,\mathbf{p}_t,\mathbf{u}_{t, \gamma})=H(t,\mathbf{x}_t,\mathbf{p}_t,\mathbf{u}_{t, \gamma}^*)= \theta_t \mathbf{p}^T_t x_T - \theta_t \mathbf{p}^T_t \mathbf{x}_t - \frac{g^2_t}{2}\left\|\mathbf{p}_t\right\|^2_2
% \end{equation}

% Now, according to minimum principle theorem to obtain the following set of differential equations: 
% \begin{equation}\label{mpt1_goub}
% \frac{\mathrm{d}\mathbf{x}_{t}}{\mathrm{d}t}=\nabla_{\mathbf{p}_t}H\left(\mathbf{x}_{t},\mathbf{p}_{t},\mathbf{u}_{t, \gamma}^{*},t\right)= \theta_t x_1 - \theta_t \mathbf{x}_t - g^2_t \mathbf{p}_{t} 
% \end{equation}
% \begin{equation}\label{mpt2_goub}
% \frac{\mathrm{d}\mathbf{p}_{t}}{\mathrm{d}t}=-\nabla_{\mathbf{x}_t}H\left(\mathbf{x}_{t},\mathbf{p}_{t},\mathbf{u}_{t, \gamma}^{*},t\right) = \theta_t \mathbf{p}_t
% \end{equation}
% \begin{equation}\label{mpt3_goub}
% \mathbf{x}_{0} = x_{0}
% \end{equation}
% \begin{equation}\label{mpt4_goub}
% \mathbf{p}_{T}=\gamma \left(\mathbf{x}_T-x_{T}\right)
% \end{equation}

% Solving the equation \ref{mpt2_goub}, we have:
% \begin{equation}
% \begin{gathered}
% \mathbf{p}_{t} = \mathbf{p}_{0} e^{\bar{\theta}_{t}} \\
% \mathbf{p}_{T} = \mathbf{p}_{0} e^{\bar{\theta}_{T}}
% \end{gathered}
% \end{equation}

% Then we solve the equation \ref{mpt1_goub}:
% \begin{align*}
%     &\frac{\mathrm{d} \mathbf{x}_t}{\mathrm{d} t} = \theta_t x_T - \theta_t \mathbf{x}_t - g^2_t \mathbf{p}_{t} \\
%     \Rightarrow \quad &\frac{\mathrm{d} (e^{\bar{\theta}_{t}} \mathbf{x}_t)}{\mathrm{d} t} = e^{\bar{\theta}_{t}} \theta_t x_T - e^{\bar{\theta}_{t}} g^2_t \mathbf{p}_{t} \\
%     \Rightarrow \quad &e^{\bar{\theta}_{t}} \mathbf{x}_t - \mathbf{x}_0 = x_T \int_{0}^{t}e^{\bar{\theta}_{z}} \theta_z dz - \mathbf{p}_{0} \int_{0}^{t} g^2_z e^{2\bar{\theta}_{z}} dz  \\
%     \Rightarrow \quad &e^{\bar{\theta}_{t}} \mathbf{x}_t - x_0 = x_T (e^{\bar{\theta}_{t}} - 1) - \lambda^2 \mathbf{p}_{0} (e^{2\bar{\theta}_{t}} - 1) \\
% \end{align*}

% Hence, we can get:
% \begin{equation}\label{x1_goub}
% \mathbf{x}_T = e^{-\bar{\theta}_{T}}x_0 + x_T (1 - e^{-\bar{\theta}_{T}}) - \lambda^2 \mathbf{p}_{T} (1 - e^{-2\bar{\theta}_{T}})
% \end{equation}
% and
% \begin{equation}\label{xt_goub}
% \mathbf{x}_t = e^{-\bar{\theta}_{t}}x_0 + (1 - e^{-\bar{\theta}_{t}}) x_T - \lambda^2 e^{-\bar{\theta}_{T}} \mathbf{p}_{T}  (e^{\bar{\theta}_{t}} - e^{-\bar{\theta}_{t}})
% \end{equation}

% Take the equation \ref{x1_goub} into the equation \ref{mpt4_goub} and solve $\mathbf{p}_{T}$, 
% \begin{align*}
% &\mathbf{p}_{T} = \gamma \left( e^{-\bar{\theta}_{1}}x_0 + (1 - e^{-\bar{\theta}_{T}}) x_T - \lambda^2 \mathbf{p}_{T} (1 - e^{-2\bar{\theta}_{T}}) - x_{T} \right) \\
% \Rightarrow \quad & \mathbf{p}_{T} = \frac{\gamma e^{-\bar{\theta}_{T}} (x_0 - x_T)}{1 + \gamma \lambda^2 (1 - e^{-2\bar{\theta}_{T}})}
% \end{align*}

% Take $\gamma \to \infty$, 
% \begin{equation}\label{p1_goub}
% \mathbf{p}_{T} = \frac{e^{-\bar{\theta}_{1}}(x_0 - x_T)}{\lambda^2 (1 - e^{-2\bar{\theta}_{T}})}
% \end{equation}

% Also, take the equation \ref{p1_goub} into the equation \ref{xt_goub}, 
% \begin{equation}
% \begin{split}
%     \mathbf{x}_t 
%     &= e^{-\bar{\theta}_{t}}x_0 + (1 - e^{-\bar{\theta}_{t}}) x_T - \lambda^2 e^{-\bar{\theta}_{T}} (e^{\bar{\theta}_{t}} - e^{-\bar{\theta}_{t}}) \frac{e^{-\bar{\theta}_{T}}(x_0 - x_T)}{\lambda^2 (1 - e^{-2\bar{\theta}_{T}})}  \\
%     &= \Big(e^{-\bar{\theta}_{t}} - e^{-\bar{\theta}_{T}} \frac{e^{\bar{\theta}_{t}} - e^{-\bar{\theta}_{t}}}{e^{\bar{\theta}_{T}} - e^{-\bar{\theta}_{T}}} \Big) x_0 + \Big(1 - e^{-\bar{\theta}_{t}} + e^{-\bar{\theta}_{T}} \frac{e^{\bar{\theta}_{t}} - e^{-\bar{\theta}_{t}}}{e^{\bar{\theta}_{T}} - e^{-\bar{\theta}_{T}}} \Big) x_T \\
% \end{split}
% \end{equation}

% Hence, 
% \begin{equation}
% g_t \mathbf{u}^{*}_{t, \gamma} = - g^2_t \mathbf{p}_{t} = - 2 \theta_t e ^{\bar{\theta}_{t}} \frac{e^{-2\bar{\theta}_{T} } (x_T - x_0)}{1 - e^{-2\bar{\theta}_{T}}}
% \end{equation}

% The origin dynamics can be: 
% \begin{equation}
% \mathrm{d} \mathbf{x}_t = \Big( \theta_t(x_T - \mathbf{x}_t) + 2 \theta_t e ^{\bar{\theta}_{t}} \frac{e^{-2\bar{\theta}_{T} } (x_T - x_0)}{1 - e^{-2\bar{\theta}_{T}}} \Big) \mathrm{d} t + g_t \mathrm{d} w_t
% \end{equation}

% If we preserve $\gamma$, then 
% \begin{equation}\label{p1_goub_gamma}
% \mathbf{p}_{T} = \frac{\gamma e^{-\bar{\theta}_{T}} (x_0 - x_T)}{1 + \gamma \lambda^2 (1 - e^{-2\bar{\theta}_{T}})}
% \end{equation}

% Hence, the interpolant becomes
% \begin{equation}
% \begin{split}
%     \mathbf{x}_t 
%     &= e^{-\bar{\theta}_{t}}x_0 + (1 - e^{-\bar{\theta}_{t}}) x_T - \lambda^2 e^{-\bar{\theta}_{T}} (e^{\bar{\theta}_{t}} - e^{-\bar{\theta}_{t}}) \frac{\gamma e^{-\bar{\theta}_{T}} (x_0 - x_T)}{1 + \gamma \lambda^2 (1 - e^{-2\bar{\theta}_{T}})}  \\
%     &= \left(e^{-\bar{\theta}_{t}} - \frac{\gamma \lambda^2 e^{-2\bar{\theta}_{T}} (e^{\bar{\theta}_{t}} - e^{-\bar{\theta}_{t}})}{1 + \gamma \lambda^2 (1 - e^{-2\bar{\theta}_{T}})} \right) x_0 + \left(1 - e^{-\bar{\theta}_{t}} + \frac{\gamma \lambda^2 e^{-2\bar{\theta}_{T}} (e^{\bar{\theta}_{t}} - e^{-\bar{\theta}_{t}})}{1 + \gamma \lambda^2 (1 - e^{-2\bar{\theta}_{T}})} \right) x_T \\
%     &= \left(e^{-\bar{\theta}_{t}} \frac{1 + \gamma \lambda^2 (1 - e^{-2\bar{\theta}_{t:T}})}{1 + \gamma \lambda^2 (1 - e^{-2\bar{\theta}_{T}})} \right) x_0 + \left(1 - e^{-\bar{\theta}_{t}} \frac{1 + \gamma \lambda^2 (1 - e^{-2\bar{\theta}_{t:T}})}{1 + \gamma \lambda^2 (1 - e^{-2\bar{\theta}_{1}})}\right) x_T \\
% \end{split}
% \end{equation}
% And the origin dynamics can be: 
% \begin{equation}
% \mathrm{d} \mathbf{x}_t = \left( \left( \theta_t + 2 \theta_t \frac{\gamma \lambda^2 e^{-2\bar{\theta}_{t:T}}}{1 + \gamma \lambda^2 (1 - e^{-2\bar{\theta}_{t:T}})}\right) (x_T - \mathbf{x}_t) \right) \mathrm{d} t + g_t \mathrm{d} w_t
% \end{equation}
% GOUB: 
% \begin{equation}
% \mathrm{d} \mathbf{x}_t = \left( \left( \theta_t + 2 \theta_t \frac{e^{-2\bar{\theta}_{t:T}}}{1 - e^{-2\bar{\theta}_{t:T}}}\right) (x_T - \mathbf{x}_t) \right) \mathrm{d} t + g_t \mathrm{d} w_t
% \end{equation}


% \subsection{Proof of the equivalence between Doob's h-transform and stochastic optimal control in a general linear-SDE forward process (e.g. VE, VP and GOU process)}
% \subsubsection{General linear-SDE forward process}

% \begin{theorem}\label{theorem_4.2} 
% \textit{For the SOC problem \eqref{SOC_problem_generalized_ode}, when $\gamma \to \infty$, the optimal controller becomes $\mathbf{u}^{*}_{t, \infty} = g_t \nabla_{\mathbf{x}_t} \log p(\mathbf{x}_T \mid \mathbf{x}_t)$, and the corresponding forward and backward SDE with the linear SDE form \eqref{generalized_linear_SDE} are the same as Doob's $h$-transform as in \eqref{doob} and \eqref{reverse-bridge-sde}. 
% }
% \end{theorem}

\subsection{Proof of Theorem \ref{theorem_4.2}}\label{proof_theorem_4.2}
\noindent \textbf{Theorem \ref{theorem_4.2}.} 
\textit{For the SOC problem \eqref{SOC_problem_generalized_ode}, when $\gamma \to \infty$, the optimal controller becomes $\mathbf{u}^{*}_{t, \infty} = g_t \nabla_{\mathbf{x}_t} \log p(\mathbf{x}_T \mid \mathbf{x}_t)$, and the corresponding forward and backward SDE with the linear SDE form \eqref{generalized_linear_SDE} are the same as Doob's $h$-transform as in \eqref{doob} and \eqref{reverse-bridge-sde}.}

\begin{proof}
Since in Proposition \ref{theorem_4.1} we have solved the control problem and the optimal controller $\mathbf{u}^{*}_{t, \infty}$ is: 
\begin{equation}\tag{\ref{general_optimal_controller}}
\mathbf{u}^{*}_{t, \infty} = \lim_{\gamma \rightarrow \infty} \mathbf{u}^{*}_{t, \gamma} = g_t e^{\bar{f}_{t:T}} \frac{\mathbf{x}_{T} - e^{\bar{f}_{t:T}} \mathbf{x}_t - \mathbf{m} e^{\bar{f}_{T}} \bar{h}_{t:T}}{e^{2\bar{f}_{T}} \bar{g}^2_{t:T}}.
\end{equation}

Now we calculate the transition probability $p(\mathbf{x}_T \mid \mathbf{x}_t)$ and related $h$ function $\mathbf{h}(\mathbf{x}_t, t, \mathbf{x}_T, T)$. 

Consider $F(\mathbf{x}_t, t) = \mathbf{x}_t e^{-\bar{f}_t}$, according to the Ito differential formula, we get:
% TODO
\begin{align}\label{general_transition}
& \mathrm{d} F = -f_t \mathbf{x}_t e^{-\bar{f}_t} \mathrm{d} t + e^{-\bar{f}_t} \mathrm{d} \mathbf{x}_t\\
\Rightarrow \quad & \mathrm{d} F = -f_t \mathbf{x}_t e^{-\bar{f}_t} \mathrm{d} t + e^{-\bar{f}_t} \Big( \left(f_t \mathbf{x}_t + h_t \mathbf{m}\right) \mathrm{d} t + g_t \mathrm{d} \mathbf{w}_t \Big), \\
\Rightarrow \quad & \mathrm{d} F = h_t e^{-\bar{f}_t} \mathbf{m} \mathrm{d} t + e^{-\bar{f}_t} g_t \mathrm{d} \mathbf{w}_t, \\
\Rightarrow \quad & \mathbf{x}_T e^{-\bar{f}_T} - \mathbf{x}_t e^{-\bar{f}_t} = \mathbf{m}\bar{h}_{t:T} + \int_{t}^{T} e^{-\bar{f}_z} g_z \mathrm{d} w_z, \\
\Rightarrow \quad & \mathbf{x}_T \sim N\left( e^{\bar{f}_{t:T}} \mathbf{x}_t + \mathbf{m} e^{\bar{f}_T} \bar{h}_{t:T}, e^{2\bar{f}_T}\bar{g}^2_{t:T} \mathbf{I}\right),\\
\Rightarrow \quad & \nabla_{\mathbf{x}_t} \log p(\mathbf{x}_T | \mathbf{x}_t) = -\nabla_{\mathbf{x}_t} \frac{(\mathbf{x}_T - e^{\bar{f}_{t:T}} \mathbf{x}_t - \mathbf{m} e^{\bar{f}_T} \bar{h}_{t:T})^2}{2 e^{2\bar{f}_T}\bar{g}^2_{t:T}} = \frac{e^{\bar{f}_{t:T}}\left(\mathbf{x}_T - e^{\bar{f}_{t:T}} \mathbf{x}_t - \mathbf{m} e^{\bar{f}_T} \bar{h}_{t:T}\right)}{e^{2\bar{f}_T}\bar{g}^2_{t:T}}, \\
\Rightarrow \quad & \mathbf{u}^{*}_{t, \infty} = g_t e^{\bar{f}_{t:T}} \frac{\mathbf{x}_{T} - e^{\bar{f}_{t:T}} \mathbf{x}_t - \mathbf{m} e^{\bar{f}_{T}} \bar{h}_{t:T}}{e^{2\bar{f}_{T}} \bar{g}^2_{t:T}} = g_t \nabla_{\mathbf{x}_t} \log p(\mathbf{x}_T | \mathbf{x}_t) = g_t \mathbf{h}(\mathbf{x}_t, t, \mathbf{x}_T, T).
% \Rightarrow \quad & \mathrm{d} x_t = \left( f_t \mathbf{x}_t + h_t \mathbf{m} + g^2_t \nabla_{x_t} \log p(x_T | x_t) \right) \mathrm{d} t + g_t \mathrm{d} w_t \\
% \Rightarrow \quad & \mathrm{d} x_t= \left( f_t \mathbf{x}_t + h_t \mathbf{m} + g^2_t \frac{e^{\bar{f}_{t:T}}\left(x_T - e^{\bar{f}_{t:T}} x_t - \mathbf{m} e^{\bar{f}_T} \int_{t}^{T} e^{-\bar{f}_z}h_z dz\right)}{e^{2\bar{f}_T}\int_{t}^{T} e^{-2\bar{f}_z} g^2_z dz} \right) \mathrm{d} t + g_t \mathrm{d} w_t \\
\end{align}
The forward SDEs obtained through SOC and Doob's h-transform are both formed as 
\begin{equation}
\mathrm{d} \mathbf{x}_t = \left( f_t \mathbf{x}_t + h_t \mathbf{m} + g^2_t \frac{e^{\bar{f}_{t:T}}\left(\mathbf{x}_T - e^{\bar{f}_{t:T}} \mathbf{x}_t - \mathbf{m} e^{\bar{f}_T} \bar{h}_{t:T}\right)}{e^{2\bar{f}_T}\bar{g}^2_{t:T}} \right) \mathrm{d} t + g_t \mathrm{d} \mathbf{w}_t,
\end{equation}
and the both backward SDEs are 
\begin{equation}
\mathrm{d} \mathbf{x}_t = \left( f_t \mathbf{x}_t + h_t \mathbf{m} + g^2_t \frac{e^{\bar{f}_{t:T}}\left(\mathbf{x}_T - e^{\bar{f}_{t:T}} \mathbf{x}_t - \mathbf{m} e^{\bar{f}_T} \bar{h}_{t:T}\right)}{e^{2\bar{f}_T}\bar{g}^2_{t:T}} - g^2_t \nabla_{\mathbf{x}_t} p(\mathbf{x}_t | x_T) \right) \mathrm{d} t + g_t \mathrm{d} \mathbf{w}_t,
\end{equation}
which concludes the proof of the Theorem \ref{theorem_4.2}.

% Compare the two SDEs, the equivalence holds iff 
% \begin{align*}
% & \frac{e^{\bar{f}_{t:T}}\left(x_T - e^{\bar{f}_{t:T}} x_t - \mathbf{m} e^{\bar{f}_T} \int_{t}^{T} e^{-\bar{f}_z}h_z dz\right)}{e^{2\bar{f}_T}\int_{t}^{T} e^{-2\bar{f}_z} g^2_z dz} = e^{-\bar{f}_{t}} \frac{x_{T} - e^{\bar{f}_{T}} x_0 - \mathbf{m} e^{\bar{f}_{T}} \int_{0}^{T}e^{-\bar{f}_{z}} h_z dz}{e^{\bar{f}_{T}} \int_{0}^{T} e^{-2\bar{f}_{z}}g^2_z dz} \\
% \Leftrightarrow \quad & \frac{x_T - e^{\bar{f}_{t:T}} x_t - \mathbf{m} e^{\bar{f}_T} \int_{t}^{T} e^{-\bar{f}_z}h_z dz}{\int_{t}^{T} e^{-2\bar{f}_z} g^2_z dz} = \frac{x_{T} - e^{\bar{f}_{T}} x_0 - \mathbf{m} e^{\bar{f}_{T}} \int_{0}^{T}e^{-\bar{f}_{z}} h_z dz}{\int_{0}^{T} e^{-2\bar{f}_{z}}g^2_z dz} \\
% \Leftrightarrow \quad & x_t = e^{\bar{f}_{t}} \left( \frac{\int_{t}^{T} e^{-2\bar{f}_{z}}g^2_z dz}{\int_{0}^{T} e^{-2\bar{f}_{z}}g^2_z dz} \right) x_0 + e^{-\bar{f}_{t:T}}\left( \frac{\int_{0}^{t} e^{-2\bar{f}_{z}}g^2_z dz}{\int_{0}^{T} e^{-2\bar{f}_{z}}g^2_z dz} \right) x_T \\
% & \quad + e^{-\bar{f}_{t:T}}\left( -e^{\bar{f}_T} \int_{t}^{T} e^{-\bar{f}_z}h_z dz + e^{\bar{f}_{T}} \int_{0}^{T}e^{-\bar{f}_{z}} h_z dz \frac{\int_{t}^{T} e^{-2\bar{f}_{z}}g^2_z dz}{\int_{0}^{T} e^{-2\bar{f}_{z}}g^2_z dz} \right) \mathbf{m} \\
% \Leftrightarrow \quad & x_t = \left( \frac{e^{\bar{f}_{t}} \int_{t}^{T} e^{-2\bar{f}_{z}}g^2_z dz}{\int_{0}^{T} e^{-2\bar{f}_{z}}g^2_z dz} \right) x_0 + \left( \frac{e^{-\bar{f}_{t:T}} \int_{0}^{t} e^{-2\bar{f}_{z}}g^2_z dz}{\int_{0}^{T} e^{-2\bar{f}_{z}}g^2_z dz} \right) x_T \\
% & \quad + e^{\bar{f}_{t}}\left( \int_{0}^{t}e^{-\bar{f}_{z}} h_z dz - \frac{ \int_{0}^{t} e^{-2\bar{f}_{z}}g^2_z dz \int_{0}^{T}e^{-\bar{f}_{z}} h_z dz}{\int_{0}^{T} e^{-2\bar{f}_{z}}g^2_z dz} \right) \mathbf{m}
% \end{align*}
% with the fact that 
% \begin{align*}
% & e^{-\bar{f}_{t:T}}\left( -e^{\bar{f}_T} \int_{t}^{T} e^{-\bar{f}_z}h_z dz + e^{\bar{f}_{T}}  \frac{\int_{t}^{T} e^{-2\bar{f}_{z}}g^2_z dz \int_{0}^{T}e^{-\bar{f}_{z}} h_z dz}{\int_{0}^{T} e^{-2\bar{f}_{z}}g^2_z dz} \right)  \\
% &= e^{\bar{f}_{t}} \left( -\int_{t}^{T} e^{-\bar{f}_z}h_z dz + \frac{\int_{t}^{T} e^{-2\bar{f}_{z}}g^2_z dz \int_{0}^{T}e^{-\bar{f}_{z}} h_z dz}{\int_{0}^{T} e^{-2\bar{f}_{z}}g^2_z dz} \right) \\
% &= e^{\bar{f}_{t}} \left( -\int_{0}^{T} e^{-\bar{f}_z}h_z dz + \int_{0}^{t} e^{-\bar{f}_z}h_z dz + \frac{\int_{t}^{T} e^{-2\bar{f}_{z}}g^2_z dz \int_{0}^{T}e^{-\bar{f}_{z}} h_z dz}{\int_{0}^{T} e^{-2\bar{f}_{z}}g^2_z dz} \right) \\
% &= e^{\bar{f}_{t}} \left( \int_{0}^{t} e^{-\bar{f}_z}h_z dz-\int_{0}^{T} e^{-\bar{f}_z}h_z dz \left( 1- \frac{\int_{t}^{T} e^{-2\bar{f}_{z}}g^2_z dz}{\int_{0}^{T} e^{-2\bar{f}_{z}}g^2_z dz} \right) \right) \\
% &= e^{\bar{f}_{t}} \left( \int_{0}^{t} e^{-\bar{f}_z}h_z dz-\int_{0}^{T} e^{-\bar{f}_z}h_z dz \frac{\int_{0}^{t} e^{-2\bar{f}_{z}}g^2_z dz}{\int_{0}^{T} e^{-2\bar{f}_{z}}g^2_z dz} \right) \\
% \end{align*}
\end{proof}



% \subsubsection{VE bridge}
% Since in \ref{app_subsub_ve} we have solved the control problem and the results are: 
% \begin{equation}\label{control_ve}
% \mathrm{d} \mathbf{x}_t = g^2_t \frac{x_1 - x_0}{\int_{0}^{1} g^2_z dz} \mathrm{d} t + g_t \mathrm{d} w_t
% \end{equation}
% and 
% \begin{equation}\label{x_t_ve}
% x_t = \frac{\int_{t}^{1} g^2_z dz}{\int_{0}^{1} g^2_z dz} x_0 + \frac{\int_{0}^{t} g^2_z dz}{\int_{0}^{1} g^2_z dz} x_1
% \end{equation}

% And the VE process after the Doob's h-transform is: 
% \begin{align}\label{h-transform_ve}
% &\mathrm{d} x_t= g_t \mathrm{~d} \mathbf{w}_t \\
% \Rightarrow \quad & x_1 - x_t = \int_{t}^{1} g_z dw_t \\
% \Rightarrow \quad & x_1 \sim N \left(x_t, \int_{t}^{1} g^2_z dz \mathbf{I}\right) \\
% \Rightarrow \quad & \nabla_{x_t} \log p(x_1 | x_t) = -\nabla_{x_t} \frac{(x_1 - x_t)^2}{2 \int_{t}^{1} g^2_z dz} = \frac{x_1 - x_t}{\int_{t}^{1} g^2_z dz} \\
% \Rightarrow \quad & \mathrm{d} \mathbf{x}_t = g^2_t \nabla_{x_t} \log p(x_1 | x_t) \mathrm{d} t + g_t \mathrm{d} w_t = g^2_t\frac{x_1 - x_t}{\int_{t}^{1} g^2_z dz} \mathrm{d} t + g_t \mathrm{d} w_t
% \end{align}
% Compare the two SDEs, the equivalence holds iff 
% \begin{align*}
% & g^2_t\frac{x_1 - x_t}{\int_{t}^{1} g^2_z dz} = g^2_t\frac{x_1 - x_0}{\int_{0}^{1} g^2_z dz}\\
% \Leftrightarrow \quad & \frac{x_1 - x_t}{\int_{t}^{1} g^2_z dz} = \frac{x_1 - x_0}{\int_{0}^{1} g^2_z dz}\\
% \Leftrightarrow \quad & x_t = \frac{\int_{t}^{1} g^2_z dz}{\int_{0}^{1} g^2_z dz} x_0 + \frac{\int_{0}^{t} g^2_z dz}{\int_{0}^{1} g^2_z dz} x_1
% \end{align*}
% which is the same as equation \ref{x_t_ve}

% \subsubsection{VP bridge}
% Since in \ref{app_subsub_vp} we have solved the control problem and the results are: 
% \begin{equation}\label{control_vp}
% \mathrm{d} x_t = \left( - \frac{1}{2} g^2_t x_t + g^2_t e^{\int_{0}^{t} \frac{g^2_z}{2} dz} \frac{x_1 - e^{-\int_{0}^{1} \frac{g^2_t}{2} dt}x_0}{e^{\int_{0}^{1} \frac{g^2_z}{2} dz} - e^{-\int_{0}^{1} \frac{g^2_z}{2} dz}} \right) \mathrm{d} t + g_t \mathrm{d} w_t
% \end{equation}

% and 
% \begin{equation}\label{x_t_vp}
% x_t = \left(e^{-\int_{0}^{t} \frac{g^2_z}{2} dz} - e^{-\int_{0}^{1} \frac{g^2_z}{2} dz} \frac{e^{\int_{0}^{t} \frac{g^2_z}{2} dz} - e^{-\int_{0}^{t} \frac{g^2_z}{2} dz}}{e^{\int_{0}^{1} \frac{g^2_z}{2} dz} - e^{-\int_{0}^{1} \frac{g^2_z}{2} dz}} \right) x_0 + \left( \frac{e^{\int_{0}^{t} \frac{g^2_z}{2} dz} - e^{-\int_{0}^{t} \frac{g^2_z}{2} dz}}{e^{\int_{0}^{1} \frac{g^2_z}{2} dz} - e^{-\int_{0}^{1} \frac{g^2_z}{2} dz}} \right) x_1
% \end{equation}

% As for the VP process, first we calculate the transition probability. \\
% Take $F(x_t, t) = x_t e^{\int_{0}^{t} \frac{g^2_z}{2} dz}$, according to the Ito differential formula, we get:

% \begin{align*}
% & \mathrm{d} F = \frac{g^2_t}{2} x_t e^{\int_{0}^{t} \frac{g^2_z}{2} dz} \mathrm{d} t + e^{\int_{0}^{t} \frac{g^2_z}{2} dz} \mathrm{d} x_t\\
% \Rightarrow \quad & \mathrm{d} F = \frac{g^2_t}{2} x_t e^{\int_{0}^{t} \frac{g^2_z}{2} dz} \mathrm{d} t + e^{\int_{0}^{t} \frac{g^2_z}{2} dz} \left(- \frac{1}{2} g^2_t x_t \mathrm{d} t + g_t \mathrm{d} w_t \right) \\
% \Rightarrow \quad & \mathrm{d} F = e^{\int_{0}^{t} \frac{g^2_z}{2} dz} g_t \mathrm{d} w_t \\
% \Rightarrow \quad & x_1 e^{\int_{0}^{1} \frac{g^2_z}{2} dz} - x_t e^{\int_{0}^{t} \frac{g^2_z}{2} dz} = \int_{t}^{1} e^{\int_{0}^{z} \frac{g^2_m}{2} dm} g_z \mathrm{d} w_z \\
% \Rightarrow \quad & x_1 \sim N\left( e^{-\int_{t}^{1} \frac{g^2_z}{2} dz} x_t, \frac{\int_{t}^{1} e^{\int_{0}^{z} g^2_m dm} g^2_z dz}{e^{\int_{0}^{1} g^2_z dz}} \mathbf{I}\right)\\
% \Rightarrow \quad & x_1 \sim N\left( e^{-\int_{t}^{1} \frac{g^2_z}{2} dz} x_t, \left( 1 - e^{-\int_{t}^{1} g^2_z dz} \right) \mathbf{I}\right)\\
% \Rightarrow \quad & \nabla_{x_t} \log p(x_1 | x_t) = -\nabla_{x_t} \frac{(x_1 - e^{-\int_{t}^{1} \frac{g^2_z}{2} dz} x_t)^2}{2 \left( 1 - e^{-\int_{t}^{1} g^2_z dz} \right)} = \frac{x_1 - e^{-\int_{t}^{1} \frac{g^2_z}{2} dz} x_t}{\left(e^{\int_{t}^{1} \frac{g^2_z}{2} dz} - e^{-\int_{t}^{1} \frac{g^2_z}{2} dz} \right)} \\
% \Rightarrow \quad & \mathrm{d} x_t = \left( - \frac{1}{2} g^2_t x_t + g^2_t \nabla_{x_t} \log p(x_1 | x_t) \right) \mathrm{d} t + g_t \mathrm{d} w_t = \left( - \frac{1}{2} g^2_t x_t + g^2_t \frac{x_1 - e^{-\int_{t}^{1} \frac{g^2_z}{2} dz} x_t}{\left(e^{\int_{t}^{1} \frac{g^2_z}{2} dz} - e^{-\int_{t}^{1} \frac{g^2_z}{2} dz} \right)} \right) \mathrm{d} t + g_t \mathrm{d} w_t \\
% \end{align*}

% Compare the two SDEs, the equivalence holds iff 
% \begin{align*}
% & g^2_t \frac{x_1 - e^{-\int_{t}^{1} \frac{g^2_z}{2} dz} x_t}{\left(e^{\int_{t}^{1} \frac{g^2_z}{2} dz} - e^{-\int_{t}^{1} \frac{g^2_z}{2} dz} \right)} = g^2_t e^{\int_{0}^{t} \frac{g^2_z}{2} dz} \frac{x_1 - e^{-\int_{0}^{1} \frac{g^2_t}{2} dt}x_0}{e^{\int_{0}^{1} \frac{g^2_z}{2} dz} - e^{-\int_{0}^{1} \frac{g^2_z}{2} dz}}\\
% \Leftrightarrow \quad & \frac{e^{\int_{t}^{1} \frac{g^2_z}{2} dz} x_1 -  x_t}{e^{\int_{t}^{1} \frac{g^2_z}{2} dz} - e^{-\int_{t}^{1} \frac{g^2_z}{2} dz} } = \frac{e^{\int_{0}^{1} \frac{g^2_z}{2} dz}x_1 - x_0}{e^{\int_{0}^{1} \frac{g^2_z}{2} dz} - e^{-\int_{0}^{1} \frac{g^2_z}{2} dz}} \\
% \Leftrightarrow \quad & x_t = \frac{e^{\int_{t}^{1} \frac{g^2_z}{2} dz} - e^{-\int_{t}^{1} \frac{g^2_z}{2} dz}}{e^{\int_{0}^{1} \frac{g^2_z}{2} dz} - e^{-\int_{0}^{1} \frac{g^2_z}{2} dz}} x_0 + \left( e^{\int_{t}^{1} \frac{g^2_z}{2} dz} - e^{\int_{0}^{1} \frac{g^2_z}{2} dz} \frac{e^{\int_{t}^{1} \frac{g^2_z}{2} dz} - e^{-\int_{t}^{1} \frac{g^2_z}{2} dz}}{e^{\int_{0}^{1} \frac{g^2_z}{2} dz} - e^{-\int_{0}^{1} \frac{g^2_z}{2} dz}} \right) x_1 \\
% \Leftrightarrow \quad & x_t = \left(e^{-\int_{0}^{t} \frac{g^2_z}{2} dz} - e^{-\int_{0}^{1} \frac{g^2_z}{2} dz} \frac{e^{\int_{0}^{t} \frac{g^2_z}{2} dz} - e^{-\int_{0}^{t} \frac{g^2_z}{2} dz}}{e^{\int_{0}^{1} \frac{g^2_z}{2} dz} - e^{-\int_{0}^{1} \frac{g^2_z}{2} dz}} \right) x_0 + \left( \frac{e^{\int_{0}^{t} \frac{g^2_z}{2} dz} - e^{-\int_{0}^{t} \frac{g^2_z}{2} dz}}{e^{\int_{0}^{1} \frac{g^2_z}{2} dz} - e^{-\int_{0}^{1} \frac{g^2_z}{2} dz}} \right) x_1
% \end{align*}
% With the fact that 
% \begin{equation}
% e^{-\int_{0}^{t} \frac{g^2_z}{2} dz} - e^{-\int_{0}^{1} \frac{g^2_z}{2} dz} \frac{e^{\int_{0}^{t} \frac{g^2_z}{2} dz} - e^{-\int_{0}^{t} \frac{g^2_z}{2} dz}}{e^{\int_{0}^{1} \frac{g^2_z}{2} dz} - e^{-\int_{0}^{1} \frac{g^2_z}{2} dz}} = \frac{e^{\int_{t}^{1} \frac{g^2_z}{2} dz} - e^{-\int_{t}^{1} \frac{g^2_z}{2} dz}}{e^{\int_{0}^{1} \frac{g^2_z}{2} dz} - e^{-\int_{0}^{1} \frac{g^2_z}{2} dz}}
% \end{equation}
% and 
% \begin{equation}
% e^{\int_{t}^{1} \frac{g^2_z}{2} dz} - e^{\int_{0}^{1} \frac{g^2_z}{2} dz} \frac{e^{\int_{t}^{1} \frac{g^2_z}{2} dz} - e^{-\int_{t}^{1} \frac{g^2_z}{2} dz}}{e^{\int_{0}^{1} \frac{g^2_z}{2} dz} - e^{-\int_{0}^{1} \frac{g^2_z}{2} dz}} = \frac{e^{\int_{0}^{t} \frac{g^2_z}{2} dz} - e^{-\int_{0}^{t} \frac{g^2_z}{2} dz}}{e^{\int_{0}^{1} \frac{g^2_z}{2} dz} - e^{-\int_{0}^{1} \frac{g^2_z}{2} dz}}
% \end{equation}

% \subsubsection{GOUB}
% Since in \ref{app_subsub_goub} we have solved the control problem and the results are: 
% \begin{equation}\label{control_goub}
% \mathrm{d} x_t = \Big( \theta_t(x_1 - x_t) + 2 \theta_t e ^{\bar{\theta}_{t}} \frac{e^{-2\bar{\theta}_{1} } (x_1 - x_0)}{1 - e^{-2\bar{\theta}_{1}}} \Big) \mathrm{d} t + g_t \mathrm{d} w_t
% \end{equation}

% and 
% \begin{equation}\label{x_t_goub}
% x_t = \Big(e^{-\bar{\theta}_{t}} - e^{-\bar{\theta}_{1}} \frac{e^{\bar{\theta}_{t}} - e^{-\bar{\theta}_{t}}}{e^{\bar{\theta}_{1}} - e^{-\bar{\theta}_{1}}} \Big) x_0 + \Big(1 - e^{-\bar{\theta}_{t}} + e^{-\bar{\theta}_{1}} \frac{e^{\bar{\theta}_{t}} - e^{-\bar{\theta}_{t}}}{e^{\bar{\theta}_{1}} - e^{-\bar{\theta}_{1}}} \Big) x_1 
% \end{equation}

% And the GOU process after the Doob's h-transform is: 
% \begin{align}\label{h-transform_goub}
% &\mathrm{d} x_t=\left(\theta_t+g_t^2 \frac{e^{-2 \bar{\theta}_{t:1}}}{\bar{\sigma}_{t:1}^2}\right)\left(x_1-x_t\right) \mathrm{d} t+g_t \mathrm{~d} \mathbf{w}_t \nonumber\\
% \Leftrightarrow \quad & \mathrm{d} x_t = \left( \theta_t(x_1 - x_t) + \frac{2 \theta_t e^{-2\bar{\theta}_{t:1}}}{1 - e^{-2\bar{\theta}_{t:1}}} (x_1 - x_t)\right) \mathrm{d} t+g_t \mathrm{~d} \mathbf{w}_t 
% \end{align}

% Compare the two SDEs, the equivalence holds iff 
% \begin{align*}
% &2 \theta_t e ^{\bar{\theta}_{t}} \frac{e^{-2\bar{\theta}_{1} } (x_1 - x_0)}{1 - e^{-2\bar{\theta}_{1}}} = 2\theta_t \frac{ e^{-2\bar{\theta}_{t:1}} (x_1 - x_t)}{1 - e^{-2\bar{\theta}_{t:1}}} \\
% \Leftrightarrow \quad & \frac{(x_1 - x_0)}{e^{\bar{\theta}_{1}} - e^{-\bar{\theta}_{1}}} = \frac{(x_1 - x_t)}{e^{\bar{\theta}_{t:1}} - e^{-\bar{\theta}_{t:1}}} \\
% \Leftrightarrow \quad & x_t = \left( \frac{e^{\bar{\theta}_{t:1}} - e^{-\bar{\theta}_{t:1}}}{e^{\bar{\theta}_{1}} - e^{-\bar{\theta}_{1}}} \right) x_0 + \left( 1 - \frac{e^{\bar{\theta}_{t:1}} - e^{-\bar{\theta}_{t:1}}}{e^{\bar{\theta}_{1}} - e^{-\bar{\theta}_{1}}} \right) x_1 \\
% \Leftrightarrow \quad & x_t = \left( e^{-\bar{\theta}_{t}} - e^{-\bar{\theta}_{1}} \frac{e^{\bar{\theta}_{t}} - e^{-\bar{\theta}_{t}}}{e^{\bar{\theta}_{1}} - e^{-\bar{\theta}_{1}}} \right) x_0 + \left(1 - e^{-\bar{\theta}_{t}} + e^{-\bar{\theta}_{1}} \frac{e^{\bar{\theta}_{t}} - e^{-\bar{\theta}_{t}}}{e^{\bar{\theta}_{1}} - e^{-\bar{\theta}_{1}}} \right) x_1
% \end{align*}
% which is the same as equation \ref{x_t_goub} and with the fact that 
% \begin{equation}
% \begin{split}
% e^{-\bar{\theta}_{t}} - e^{-\bar{\theta}_{1}} \frac{e^{\bar{\theta}_{t}} - e^{-\bar{\theta}_{t}}}{e^{\bar{\theta}_{1}} - e^{-\bar{\theta}_{1}}} 
% &= \frac{e^{-\bar{\theta}_{t} + \bar{\theta}_{1}} - e^{-\bar{\theta}_{t}- \bar{\theta}_{1}} - e^{\bar{\theta}_{t} - \bar{\theta}_{1}} + e^{-\bar{\theta}_{t}- \bar{\theta}_{1}}}  {e^{\bar{\theta}_{1}} - e^{-\bar{\theta}_{1}}} \\
% &= \frac{e^{-\bar{\theta}_{t} + \bar{\theta}_{1}} - e^{\bar{\theta}_{t} - \bar{\theta}_{1}} }  {e^{\bar{\theta}_{1}} - e^{-\bar{\theta}_{1}}} \\
% &= \frac{e^{\bar{\theta}_{t:1}} - e^{-\bar{\theta}_{t:1}}}{e^{\bar{\theta}_{1}} - e^{-\bar{\theta}_{1}}}
% \end{split}
% \end{equation}

\subsection{Proof of Proposition \ref{proposition_4.3}}\label{proof_proposition_4.3}
\textbf{Proposition \ref{proposition_4.3}} \textit{Consider the SOC problem \eqref{SOC_problem_generalized_ode}, denote $\mathcal{J}(\mathbf{u}_{t, \gamma}, \gamma) \triangleq \int_0^T \frac{1}{2} \left\|\mathbf{u}_{t, \gamma}\right\|_2^2 d t+\frac{\gamma}{2}\left\|\mathbf{x}_T^{u}-x_T\right\|_2^2$ as the overall cost of the system, $\mathbf{u}_{t, \gamma}^{*}$ as the optimal controller \eqref{general_optimal_controller}, then}
\begin{equation}
\mathcal{J}(\mathbf{u}_{t, \gamma}^{*}, \gamma) \le \mathcal{J}(\mathbf{u}_{t, \infty}^{*}, \infty). 
\end{equation}

\begin{proof}
According to \eqref{general_optimal_controller} and \eqref{general_interpolant}, denote $a = e^{\bar{f}_{T}} x_0 - x_T + \mathbf{m} e^{\bar{f}_{T}} \bar{h}_{T}$, 
\begin{align*}
& \mathbf{u}_{t, \gamma}^{*} = g_t e^{\bar{f}_{t:T}} \frac{x_{T} - e^{\bar{f}_{t:T}} \mathbf{x}_t - \mathbf{m} e^{\bar{f}_{T}} \bar{h}_{t:T}}{d_{t, \gamma}} \\
\Rightarrow \quad & \mathbf{u}_{t, \gamma}^{*} = -g_t e^{-\bar{f}_{t}} e^{\bar{f}_{T}} \frac{e^{\bar{f}_{T}} x_0 + \mathbf{m} e^{\bar{f}_{T}} \bar{h}_{T} - x_{T}}{d_{t, \gamma}}, \\
\Rightarrow \quad & \|\mathbf{u}_{t, \gamma}^{*}\|_2^2 = g^2_t e^{-2\bar{f}_{t}} e^{2\bar{f}_{T}} \frac{\|e^{\bar{f}_{T}} x_0 + \mathbf{m} e^{\bar{f}_{T}} \bar{h}_{T} - x_{T}\|_2^2}{d_{t, \gamma}^2}, \\
\Rightarrow \quad & \|\mathbf{u}_{t, \gamma}^{*}\|_2^2 = g^2_t e^{-2\bar{f}_{t}} e^{2\bar{f}_{T}} \frac{\|a\|_2^2}{d_{t, \gamma}^2}. \\
\end{align*}
Similarly, 
\begin{equation}
\|\mathbf{u}_{t, \infty}^{*}\|_2^2 = g^2_t e^{-2\bar{f}_{t}} e^{2\bar{f}_{T}} \frac{\|a\|_2^2}{(e^{2\bar{f}_{T}} \bar{g}^2_{T})^2}.
\end{equation}

Furthermore, take $t = T$ in \eqref{general_interpolant},
\begin{equation}
\mathbf{x}_{T}^{u} = \left( \frac{\gamma^{-1} e^{\bar{f}_{T}}}{\gamma^{-1} + e^{2\bar{f}_{T}}\bar{g}^2_{T}} \right) x_0 + \left( \frac{e^{2\bar{f}_{T}} \bar{g}^2_{T}}{\gamma^{-1} + e^{2\bar{f}_{T}}\bar{g}^2_{T}} \right) x_T + e^{\bar{f}_{T}}\left(\frac{\gamma^{-1} \bar{h}_{T}}{\gamma^{-1} + e^{2\bar{f}_{T}}\bar{g}^2_{T}} \right) \mathbf{m},
\end{equation}
which implies
\begin{equation}
\| \mathbf{x}_{T}^{u} - x_T \|_2^2 = \frac{\|e^{\bar{f}_{T}} x_0 - x_T + \mathbf{m} e^{\bar{f}_{T}} \bar{h}_{T}\|_2^2}{(1 + \gamma e^{2\bar{f}_{T}}\bar{g}^2_{T})^2} = \frac{\|a\|_2^2}{(1 + \gamma e^{2\bar{f}_{T}}\bar{g}^2_{T})^2 } ,
\end{equation}
and 
\begin{equation}
\lim\limits_{\gamma \to \infty} \frac{\gamma}{2} \| \mathbf{x}_{T}^{u} - x_T \|_2^2 = \lim\limits_{\gamma \to \infty}\frac{\gamma}{2(1 + \gamma e^{2\bar{f}_{T}}\bar{g}^2_{T})^2} \|a\|_2^2 = 0.
\end{equation}

Hence, 
\begin{equation}
\begin{split}
\frac{1}{2}\int_{0}^{T} \left( \|\mathbf{u}_{t, \infty}^{*}\|_2^2 - \|\mathbf{u}_{t, \gamma}^{*}\|_2^2 \right) dt
&= \frac{1}{2}e^{2\bar{f}_{T}} \|a\|_2^2 \bar{g}^2_{T} \left( \frac{1}{(e^{2\bar{f}_{T}} \bar{g}^2_{T})^2} -\frac{1}{(\gamma^{-1}+ e^{2\bar{f}_{T}} \bar{g}^2_{T})^2} \right) \\ 
&= \frac{1}{2}e^{2\bar{f}_{T}} \|a\|_2^2 \bar{g}^2_{T} \frac{1 + 2\gamma e^{2\bar{f}_{T}} \bar{g}^2_{T}}{(e^{2\bar{f}_{T}} \bar{g}^2_{T})^2 (1+ \gamma e^{2\bar{f}_{T}} \bar{g}^2_{T})^2}  \\ 
&= \frac{1}{2}\frac{1 + 2\gamma e^{2\bar{f}_{T}} \bar{g}^2_{T}}{(e^{2\bar{f}_{T}} \bar{g}^2_{T}) (1+ \gamma e^{2\bar{f}_{T}} \bar{g}^2_{T})^2} \|a\|_2^2 \\ 
&\ge \frac{1}{2}\frac{\gamma e^{2\bar{f}_{T}} \bar{g}^2_{T}}{(e^{2\bar{f}_{T}} \bar{g}^2_{T}) (1+ \gamma e^{2\bar{f}_{T}} \bar{g}^2_{T})^2} \|a\|_2^2 \\
&= \frac{1}{2}\frac{\gamma }{(1+ \gamma e^{2\bar{f}_{T}} \bar{g}^2_{T})^2} \|a\|_2^2 \\
&= \frac{\gamma}{2} \| \mathbf{x}_{T}^{u} - x_T \|_2^2  \\
&= \frac{\gamma}{2} \| \mathbf{x}_{T}^{u} - x_T \|_2^2 - \lim\limits_{\gamma \to \infty} \frac{\gamma}{2} \| \mathbf{x}_{T}^{u} - x_T \|_2^2.
\end{split}
\end{equation}

Therefore, 
\begin{align}
& \frac{\gamma}{2} \| \mathbf{x}_{T}^{u} - x_T \|_2^2 - \lim\limits_{\gamma \to \infty} \frac{\gamma}{2} \| \mathbf{x}_{T}^{u} - x_T \|_2^2 \le \frac{1}{2}\int_{0}^{T} \left( \|\mathbf{u}_{t, \infty}^{*}\|_2^2 - \|\mathbf{u}_{t, \gamma}^{*}\|_2^2 \right) dt \\
\Leftrightarrow \quad & \frac{1}{2}\int_{0}^{T} \|\mathbf{u}_{t, \gamma}^{*}\|_2^2 dt + \frac{\gamma}{2} \| \mathbf{x}_{T}^{u} - x_T \|_2^2 \le \frac{1}{2}\int_{0}^{T} \|\mathbf{u}_{t, \infty}^{*}\|_2^2 dt + \lim\limits_{\gamma \to \infty} \frac{\gamma}{2} \| \mathbf{x}_{T}^{u} - x_T \|_2^2, \\
\Leftrightarrow \quad & \mathcal{J}(\mathbf{u}_{t, \gamma}^{*}, \gamma) \le \mathcal{J}(\mathbf{u}_{t, \infty}^{*}, \infty),
\end{align}
which concludes the proof of Proposition \ref{proposition_4.3}.
\end{proof}

\subsection{Derivation of the transition probability \eqref{mu_gamma_prime}}\label{proof_derivation_transition_prob}
\noindent \textit{Suppose $\bar{\boldsymbol{\mu}}_{t, \gamma}$ and $\bar{\sigma}_t^{\prime}$ denote the mean value and variance of the transition probability $p(\mathbf{x}_t \mid x_0, x_T)$, then}
\begin{equation}\tag{\ref{mu_gamma_prime}}
\begin{gathered}
p(\mathbf{x}_t\mid x_0, x_T)=\mathcal{N}(\bar{\boldsymbol{\mu}}_{t, \gamma},\bar{\sigma}_t^{\prime2}\mathbf{I}), \\
\bar{\boldsymbol{\mu}}_{t, \gamma} = e^{\bar{f}_{t}} \Big(\frac{d_{t, \gamma}}{d_{0, \gamma}} x_0 + \frac{e^{\bar{f}_{T}} \bar{g}^2_{t}}{d_{0, \gamma}} x_T + \big(\bar{h}_{t} - \frac{e^{2\bar{f}_{T}} \bar{h}_{T} \bar{g}^2_{t}}{d_{0, \gamma}}\big) \mathbf{m}\Big), \\
\bar{\sigma}_{s:t}^2 = e^{2\bar{f}_t} \bar{g}^2_{s:t}, \quad \quad \bar{\sigma}_t^{\prime2}=\frac{\bar{\sigma}_t^2\bar{\sigma}_{t:T}^2}{\bar{\sigma}_T^2}.
\end{gathered}
\end{equation}
\begin{proof}
Since $\bar{\boldsymbol{\mu}}_{t, \gamma}$ remains the same as the closed-form relationship \eqref{general_interpolant}, we would focus on how to obtain $\bar{\sigma}_{s:t}^2$ and $\bar{\sigma}_t^{\prime2}$.

In Equation \eqref{general_transition} of Theorem \ref{theorem_4.2}, we've obtained: 
\begin{equation}
\begin{aligned}
p(\mathbf{x}_t \mid \mathbf{x}_s) &\sim N\left( e^{\bar{f}_{s:t}} \mathbf{x}_s + \mathbf{m} e^{\bar{f}_t} \bar{h}_{s:t}, e^{2\bar{f}_t}\bar{g}^2_{s:t} \mathbf{I}\right), \\
&\sim N\left( e^{\bar{f}_{s:t}} \mathbf{x}_s + \mathbf{m} e^{\bar{f}_t} \bar{h}_{s:t}, \bar{\sigma}_{s:t}^{2} \mathbf{I}\right).
\end{aligned}
\end{equation}
Take $\bar{\sigma}_{s:t}^2 = e^{2\bar{f}_t} \bar{g}^2_{s:t}$ as the coefficient of the noise term, then, through Bayes' formula, 
\begin{align*}
& p (\mathbf{x}_t \mid x_0, x_T) = \frac{p (x_T \mid \mathbf{x}_t, x_0) p (\mathbf{x}_t \mid x_0)}{p (x_T \mid x_0)} = \frac{p (x_T \mid \mathbf{x}_t) p (\mathbf{x}_t \mid x_0)}{p (x_T \mid x_0)} \\
\Rightarrow \quad & \bar{\sigma}_t^{\prime2} = \frac{\bar{\sigma}_{t}^{2} \bar{\sigma}_{t:T}^{2}}{\bar{\sigma}_{T}^{2}} ,
\end{align*}
which concludes the derivation of the the transition probability \eqref{mu_gamma_prime}.
\end{proof}



\subsection{Derivation of the training objective \eqref{objective_function}}\label{proof_objective_function}
\noindent \textit{Denote $a_{t, \gamma} = e^{\bar{f}_{t}}d_{t, \gamma}$, assuming $\boldsymbol{\mu}_{t-1, \theta}$, $\sigma_{t-1, \theta}^2$ and $\boldsymbol{\mu}_{t-1, \gamma}$, $\sigma_{t-1, \gamma}^2$ are respectively the mean values and variances of $p_{\theta} (\mathbf{x}_{t-1} \mid \mathbf{x}_t, x_T)$ and $p (\mathbf{x}_{t-1} \mid \mathbf{x}_0, \mathbf{x}_t, x_T)$, suppose the score $\nabla_{\mathbf{x}_t} p(\mathbf{x}_t \mid x_T)$ is parameterized as $-\boldsymbol{\epsilon}_{\theta}(\mathbf{x}_t, x_T, t) / \bar{\sigma}_{t}^{\prime}$, the final training objective is as follows, }
\begin{equation}\tag{\ref{objective_function}}
\begin{gathered}
\mathcal{L}_{\theta} = \mathbb{E}_{t, \mathbf{x}_0, \mathbf{x}_t, \mathbf{x}_T} \left[ \frac{1}{2\sigma_{t-1, \theta}^2} \big \| \boldsymbol{\mu}_{t-1, \theta} - \boldsymbol{\mu}_{t-1, \gamma} \big \|_1 \right], \\
\boldsymbol{\mu}_{t-1, \theta} = \mathbf{x}_{t} - f_t \mathbf{x}_t - h_t \mathbf{m} - g_t \mathbf{u}_{t, \gamma}^{*} + \frac{g^2_t}{\bar{\sigma}_{t}^{\prime}} \boldsymbol{\epsilon}_{\theta}(\mathbf{x}_t, x_T, t), \\
\boldsymbol{\mu}_{t-1, \gamma} = \bar{\boldsymbol{\mu}}_{t-1, \gamma} + \frac{\bar{\sigma}_{t-1}^{\prime2}a_{t, \gamma}}{\bar{\sigma}_{t}^{\prime2}a_{t-1, \gamma} } (\mathbf{x}_t - \bar{\boldsymbol{\mu}}_{t, \gamma}),\ \sigma_{t-1, \theta} = g_t.
\end{gathered}
\end{equation}
\begin{proof}
Firstly, as for the training objective \eqref{objective_function}, according to GOUB \cite{yue2024imagerestorationgeneralizedornsteinuhlenbeck}:
\begin{equation}
\begin{aligned}
\mathbb{E}_{p(\mathbf{x}_0)} [\log p_{\theta}(\mathbf{x}_{0}\mid x_T)] &\geq \mathbb{E}_{p(\mathbf{x}_0)}\Bigg[ \mathbb{E} _{p\left( \mathbf{x}_1\mid \mathbf{x}_0 \right)}\left[ \log p_{\theta}\left( \mathbf{x}_0\mid \mathbf{x}_1, x_T \right) \right] \Bigg. \\ & \Bigg. \quad - \sum_{t=2}^T \mathbb{E}_{p(\mathbf{x}_t\mid \mathbf{x}_0)} [{KL\left( p\left( \mathbf{x}_{t-1}\mid \mathbf{x}_0, \mathbf{x}_t, x_T \right) ||p_{\theta}\left( \mathbf{x}_{t-1}\mid \mathbf{x}_t, x_T \right) \right)}]\Bigg]\\
&=ELBO.
\end{aligned}
\end{equation}

Accordingly, 
\begin{equation}
\begin{aligned}
&KL\left( p\left( \mathbf{x}_{t-1}\mid \mathbf{x}_0, \mathbf{x}_t, x_T \right) ||p_{\theta}\left( \mathbf{x}_{t-1}\mid \mathbf{x}_t,x_T \right) \right)\\
=&\mathbb{E}_{p\left( \mathbf{x}_{t-1}\mid \mathbf{x}_0, \mathbf{x}_t, x_T \right)}\left[\log \frac{ \frac{1}{\sqrt{2\pi}\sigma_{t-1}}e^{-(\mathbf x_{t-1}-\boldsymbol{\mu}_{t-1, \gamma})^2/{2\sigma_{t-1}^2}} } {\frac{1}{\sqrt{2\pi}\sigma_{\theta,t-1}}e^{-(\mathbf x_{t-1}-{\boldsymbol{\mu}}_{\theta,t-1})^2/{2\sigma_{\theta,t-1}^2}}} \right]\\ 
=&\mathbb{E}_{p\left( \mathbf{x}_{t-1}\mid \mathbf{x}_0, \mathbf{x}_t, x_T \right)}\left[\log\sigma_{\theta,t-1} - \log\sigma_{t-1} - (\mathbf x_{t-1}-\boldsymbol{\mu}_{t-1, \gamma})^2/{2\sigma^{2}_{t-1}} + (\mathbf x_{t-1}-{\boldsymbol{\mu}}_{\theta,t-1})^2/{2\sigma_{\theta,t-1}^{2}} \right]\\ 
=&\log\sigma_{\theta,t-1}-\log\sigma_{t-1}-\frac{1}{2} + \frac{\sigma_{t-1}^2}{2\sigma_{\theta,t-1}^2} + \frac{(\boldsymbol{\mu}_{t-1, \gamma}-{\boldsymbol{\mu}}_{\theta,t-1})^2}{2\sigma_{\theta,t-1}^2}.
\end{aligned}
\end{equation}

Hence, we ignore some constants and minimizing the negative ELBO, leading to the training objective: 
\begin{equation}
\mathcal{L} =\mathbb{E}_{t, \mathbf{x}_0, \mathbf{x}_t, \mathbf{x}_T} \left[ \frac{1}{2\sigma_{t-1, \theta}^2} \| \boldsymbol{\mu}_{t-1, \theta} - \boldsymbol{\mu}_{t-1, \gamma} \| \right] ,
\end{equation}

Then, as for solving the closed form of $\boldsymbol{\mu}_{t-1, \theta}$, $\sigma_{t-1, \theta}^2$ and $\boldsymbol{\mu}_{t-1, \gamma}$, through Bayes' formula, 
\begin{equation}
\begin{aligned}
p\left( \mathbf{x}_{t-1}\mid x_0, \mathbf{x}_t, x_T \right)
&=\frac{p(\mathbf{x}_t \mid x_0, \mathbf{x}_{t-1}, x_T) p(\mathbf{x}_{t-1} \mid \mathbf{x}_0, \mathbf{x}_T)}{p(\mathbf{x}_t \mid x_0, x_T)} \\
&= \frac{p(\mathbf{x}_t \mid \mathbf{x}_{t-1}, x_T)p(\mathbf{x}_{t-1} \mid x_0, \mathbf{x}_T)}{p(\mathbf{x}_t \mid x_0, x_T)}.\\
\end{aligned}
\end{equation}

According to Appendix \ref{proof_derivation_transition_prob}, applying the reparameterization tricks:
\begin{equation}
\begin{gathered}
\begin{aligned}
\mathbf{x}_{t} &= e^{\bar{f}_{t}} \Bigg(\frac{\gamma^{-1} + e^{2\bar{f}_{T}} \bar{g}^2_{t:T}}{\gamma^{-1} + e^{2\bar{f}_{T}} \bar{g}^2_{T}} x_0 + \frac{e^{\bar{f}_{T}} \bar{g}^2_{t}}{\gamma^{-1} + e^{2\bar{f}_{T}} \bar{g}^2_{T}} x_T + \left(\bar{h}_{t} - \frac{e^{2\bar{f}_{T}} \bar{h}_{T} \bar{g}^2_{t}}{\gamma^{-1} + e^{2\bar{f}_{T}} \bar{g}^2_{T}}\right) \mathbf{m}\Bigg) + \bar{\sigma}_t^{\prime} \epsilon_{t}\\
& \triangleq a_{t, \gamma} x_0 + b_{t, \gamma} x_T + c_{t, \gamma} \mathbf{m} + \bar{\sigma}_t^{\prime} \epsilon_{t},
\end{aligned}\\
\begin{aligned}
\mathbf{x}_{t-1} &= e^{\bar{f}_{t-1}} \Bigg(\frac{\gamma^{-1} + e^{2\bar{f}_{T}} \bar{g}^2_{t-1:T}}{\gamma^{-1} + e^{2\bar{f}_{T}} \bar{g}^2_{T}} x_0 + \frac{e^{\bar{f}_{T}} \bar{g}^2_{t-1}}{\gamma^{-1} + e^{2\bar{f}_{T}} \bar{g}^2_{T}} x_T + \left(\bar{h}_{t-1} - \frac{e^{2\bar{f}_{T}} \bar{h}_{T} \bar{g}^2_{t-1}}{\gamma^{-1} + e^{2\bar{f}_{T}} \bar{g}^2_{T}}\right) \mathbf{m}\Bigg) + \bar{\sigma}_{t-1}^{\prime} \epsilon_{t-1}\\
&= a_{t-1, \gamma} x_0 + b_{t-1, \gamma} x_T + c_{t-1, \gamma} \mathbf{m} + \bar{\sigma}_{t-1}^{\prime} \epsilon_{t-1}.
\end{aligned}
\end{gathered}
\end{equation}

Therefore, eliminating $x_0$ to obtain the relationships between $\mathbf{x}_t$, $\mathbf{x}_{t-1}$, $x_T$, $\mathbf{m}$ and noise $\epsilon$, 
\begin{equation}
\Rightarrow \quad \mathbf{x}_t = \frac{a_{t, \gamma}}{a_{t-1, \gamma}}\mathbf{x}_{t-1} + \left(b_{t, \gamma} - b_{t-1, \gamma}\frac{a_{t, \gamma}}{a_{t-1, \gamma}}\right) x_T + \left(c_{t, \gamma} - c_{t-1, \gamma}\frac{a_{t, \gamma}}{a_{t-1, \gamma}}\right) \mathbf{m} + \sqrt{\bar{\sigma}_{t}^{\prime2} - \bar{\sigma}_{t-1}^{\prime2} \frac{a^2_{t, \gamma}}{a^2_{t-1, \gamma}}} \epsilon .
\end{equation}

The mean value $\boldsymbol{\mu}_{t-1, \gamma}$ of $p(\mathbf{x}_{t-1}\mid x_0, \mathbf{x}_t, x_T)$ can be calculated as: 
\begin{equation}
\begin{aligned}
\boldsymbol{\mu}_{t-1, \gamma} &= \frac{\bar{\sigma}_{t-1}^{\prime2} \frac{a_{t, \gamma}}{a_{t-1, \gamma}} \left[\mathbf{x}_t - \left(b_{t, \gamma} - b_{t-1, \gamma}\frac{a_{t, \gamma}}{a_{t-1, \gamma}}\right) x_T - \left(c_{t, \gamma} - c_{t-1, \gamma}\frac{a_{t, \gamma}}{a_{t-1, \gamma}}\right) \mathbf{m}\right] + \left(\bar{\sigma}_{t}^{\prime2} - \bar{\sigma}_{t-1}^{\prime2} \frac{a^2_{t, \gamma}}{a^2_{t-1, \gamma}}\right) \bar{\boldsymbol{\mu}}_{t-1, \gamma}}{\bar{\sigma}_{t}^{\prime2}} \\
&= \bar{\boldsymbol{\mu}}_{t-1, \gamma} - \frac{a^2_{t, \gamma}\bar{\sigma}_{t-1}^{\prime2}}{a^2_{t-1, \gamma}\bar{\sigma}_{t}^{\prime2}} \bar{\boldsymbol{\mu}}_{t-1, \gamma} + \frac{a_{t, \gamma}\bar{\sigma}_{t-1}^{\prime2}}{a_{t-1, \gamma}\bar{\sigma}_{t}^{\prime2}} \left[ \mathbf{x}_t - \left(b_{t, \gamma} - \frac{a_{t, \gamma}b_{t-1, \gamma}}{a_{t-1, \gamma}}\right) x_T - \left(c_{t, \gamma} - \frac{a_{t, \gamma}c_{t-1, \gamma}}{a_{t-1, \gamma}}\right) \mathbf{m} \right] \\
&= \bar{\boldsymbol{\mu}}_{t-1, \gamma} + \frac{a_{t, \gamma}\bar{\sigma}_{t-1}^{\prime2}}{a_{t-1, \gamma}\bar{\sigma}_{t}^{\prime2}} \mathbf{x}_t - \frac{a_{t, \gamma}\bar{\sigma}_{t-1}^{\prime2}}{a_{t-1, \gamma}\bar{\sigma}_{t}^{\prime2}} \bar{\boldsymbol{\mu}}_{t, \gamma} \\
&= \bar{\boldsymbol{\mu}}_{t-1, \gamma} + \frac{\bar{\sigma}_{t-1}^{\prime2}a_{t, \gamma}}{\bar{\sigma}_{t}^{\prime2}a_{t-1, \gamma}} (\mathbf{x}_t - \bar{\boldsymbol{\mu}}_{t, \gamma}).
\end{aligned}
\end{equation}
with the fact that 
\begin{equation}
\bar{\boldsymbol{\mu}}_{t, \gamma} = \frac{a_{t, \gamma}}{a_{t-1, \gamma}} \bar{\boldsymbol{\mu}}_{t-1, \gamma} + \left(b_{t, \gamma} - \frac{a_{t, \gamma}b_{t-1, \gamma}}{a_{t-1, \gamma}}\right) x_T + \left(c_{t, \gamma} - \frac{a_{t, \gamma}c_{t-1, \gamma}}{a_{t-1, \gamma}}\right) \mathbf{m},
\end{equation}
which can be easily proved by expanding and comparing the both sides of the equation.

As for $\boldsymbol{\mu}_{\theta,t-1}$ and $\sigma_{t-1, \theta}^2$, parameterized from the SDE \eqref{ours_reverse_sde}:
\begin{equation}
\begin{aligned}
\mathbf{x}_{t-1} &= \mathbf{x}_{t} - \Bigg[ f_t \mathbf{x}_t + h_t \mathbf{m} + g^2_t \frac{x_{T} - e^{\bar{f}_{t:T}} \mathbf{x}_t - \mathbf{m} e^{\bar{f}_{T}} \bar{h}_{t:T}}{e^{-\bar{f}_{t:T}} (\gamma^{-1} + e^{2\bar{f}_{T}} \bar{g}^2_{t:T})} - g^2_t\nabla_{\mathbf x_t}\log p(\mathbf x_t\mid \mathbf x_T) \Bigg] - g_t \epsilon_t \\
&\approx \mathbf{x}_{t} - \Bigg[ f_t \mathbf{x}_t + h_t \mathbf{m} + g^2_t  \frac{x_{T} - e^{\bar{f}_{t:T}} \mathbf{x}_t - \mathbf{m} e^{\bar{f}_{T}} \bar{h}_{t:T}}{e^{-\bar{f}_{t:T}} (\gamma^{-1} + e^{2\bar{f}_{T}} \bar{g}^2_{t:T})} - \frac{g^2_t}{\bar{\sigma}_{t}^{\prime}} \boldsymbol{\epsilon}_{\theta}(\mathbf{x}_t, x_T, t) \Bigg] - g_t \epsilon_t,
\end{aligned}
\end{equation}
where $\epsilon_t \sim N(\mathbf{0}, \mathrm{d}t \boldsymbol{I})$.

Hence, 
\begin{equation}
\begin{gathered}
\boldsymbol{\mu}_{\theta,t-1} = \mathbf{x}_{t} - \Bigg[ f_t \mathbf{x}_t + h_t \mathbf{m} + g^2_t \frac{x_{T} - e^{\bar{f}_{t:T}} \mathbf{x}_t - \mathbf{m} e^{\bar{f}_{T}} \bar{h}_{t:T}}{e^{-\bar{f}_{t:T}} (\gamma^{-1} + e^{2\bar{f}_{T}} \bar{g}^2_{t:T})} - \frac{g^2_t}{\bar{\sigma}_{t}^{\prime}} \boldsymbol{\epsilon}_{\theta}(\mathbf{x}_t, x_T, t) \Bigg], \\
\sigma_{\theta,t-1}= g_t,
\end{gathered}
\end{equation}
which concludes the derivation of the training objective \eqref{objective_function}.
\end{proof}


% \subsection{Proof of Proposition}

% \textbf{Proposition} The coefficients of the interpolant obtained by SOC is equivalent to the mean value of $p(x_t | x_0, x_T)$ in the forward process which can be obtained by Bayesian.

% According to \ref{general_transition}, denote $\sigma_{s:t}^2 = e^{2\bar{f}_t}\int_{s}^{t} e^{-2\bar{f}_z} g^2_z dz$, $\sigma_{t}^2 = e^{2\bar{f}_t}\int_{0}^{t} e^{-2\bar{f}_z} g^2_z dz$, $c_{s:t} = e^{\bar{f}_t} \int_{s}^{t} e^{-\bar{f}_z}h_z dz$ and $c_{t} = e^{\bar{f}_t} \int_{0}^{t} e^{-\bar{f}_z}h_z dz$, we can also obtain the transition probability 
% \begin{equation}
% p(x_t | x_s) = N\left( e^{\bar{f}_{s:t}} x_s + c_{s:t}\mathbf{m}, \sigma_{s:t}^2 \mathbf{I}\right) 
% \end{equation}

% Hence, 
% \begin{equation}
% p(x_T | x_t) = N\left( e^{\bar{f}_{t:T}} x_t + c_{t:T}\mathbf{m}, \sigma_{t:T}^2 \mathbf{I}\right) 
% \end{equation}
% \begin{equation}
% p(x_t | x_0) = N\left( e^{\bar{f}_{t}} x_0 + c_{t} \mathbf{m}, \sigma_{t}^2 \mathbf{I}\right) 
% \end{equation}
% \begin{equation}
% p(x_T | x_0) = N\left( e^{\bar{f}_{T}} x_0 + c_{T} \mathbf{m}, \sigma_{T}^2 \mathbf{I}\right) 
% \end{equation}

% Using Bayes's rules, 
% \begin{equation}
% \begin{split}
% p (x_t | x_0, x_T)
% &= \frac{p (x_T | x_t, x_0) p (x_t | x_0)}{p (x_T | x_0)} \\
% &= \frac{p (x_T | x_t) p (x_t | x_0)}{p (x_T | x_0)}
% \end{split}
% \end{equation}

% Since each component is independently and identically distributed (i.i.d), by considering a single dimension, we have:
% \begin{equation}
% \begin{split}
% p (x_t | x_0, x_T) &\propto \frac{1}{\sqrt{2\pi} \frac{\sigma_{t:T} \sigma_{t}}{\sigma_{T}}} \exp{-\left\{ \frac{\left( x_T - e^{\bar{f}_{t:T}} x_t - c_{t:T} \mathbf{m} \right)^2}{2\sigma_{t:T}^2} + \frac{\left( x_t - e^{\bar{f}_{t}} x_0 - c_{t} \mathbf{m} \right)^2}{2\sigma_{t}^2} \right\} } \\
% &\propto \frac{1}{\sqrt{2\pi}\sigma^{\prime}_{t} } \exp{-\left\{ \left( \frac{1}{2\sigma_{t}^2} + \frac{e^{2\bar{f}_{t:T}}}{2\sigma_{t:T}^2}\right) x^2_t - \left( \frac{e^{\bar{f}_{t:T}}}{\sigma_{t:T}^2} x_T + \frac{e^{\bar{f}_{t}}}{\sigma_{t}^2} x_0 + (\frac{c_{t}}{\sigma_{t}^2} - \frac{e^{\bar{f}_{t:T}}c_{t:T}}{\sigma_{t:T}^2}) \mathbf{m} \right) x_t \right\} } \\
% \end{split}
% \end{equation}
% where $\sigma^{\prime}_{t} = \frac{\sigma_{t:T} \sigma_{t}}{\sigma_{T}}$.

% Observe that 
% \begin{equation}
% \begin{split}
% \frac{1}{2\sigma_{t}^2} + \frac{e^{2\bar{f}_{t:T}}}{2\sigma_{t:T}^2}
% &= \frac{\sigma_{t:T}^2 + e^{2\bar{f}_{t:T}} \sigma_{t}^2}{2\sigma_{t}^2\sigma_{t:T}^2} \\
% &= \frac{e^{2\bar{f}_T}\int_{t}^{T} e^{-2\bar{f}_z} g^2_z dz + e^{2\bar{f}_{t:T}} e^{2\bar{f}_t}\int_{0}^{t} e^{-2\bar{f}_z} g^2_z dz}{2\sigma_{t}^2\sigma_{t:T}^2} \\
% &= \frac{e^{2\bar{f}_T}\int_{0}^{T} e^{-2\bar{f}_z} g^2_z dz}{2\sigma_{t}^2\sigma_{t:T}^2} \\
% &= \frac{\sigma_{T}^2}{2\sigma_{t}^2\sigma_{t:T}^2} \\
% &= \frac{1}{2\sigma^{\prime2}_{t}}
% \end{split}
% \end{equation}

% Hence, 
% \begin{equation}
% \begin{split}
% p (x_t | x_0, x_T) &\propto \frac{1}{\sqrt{2\pi}\sigma^{\prime}_{t} } \exp{-\left\{ \frac{1}{2\sigma^{\prime2}_{t}} x^2_t - \left( \frac{e^{\bar{f}_{t:T}}}{\sigma_{t:T}^2} x_T + \frac{e^{\bar{f}_{t}}}{\sigma_{t}^2} x_0 + (\frac{c_{t}}{\sigma_{t}^2} - \frac{e^{\bar{f}_{t:T}}c_{t:T}}{\sigma_{t:T}^2}) \mathbf{m} \right) x_t \right\} } \\
% &\propto \frac{1}{\sqrt{2\pi}\sigma^{\prime}_{t} } \exp{-\left\{ \frac{1}{2\sigma^{\prime2}_{t}} \left( x_t - \left( \frac{e^{\bar{f}_{t:T}}\sigma_{t}^2}{\sigma_{T}^2} x_T + \frac{e^{\bar{f}_{t}}\sigma_{t:T}^2}{\sigma_{T}^2} x_0 + (\frac{c_{t}\sigma_{t:T}^2}{\sigma_{T}^2} - \frac{e^{\bar{f}_{t:T}}c_{t:T}\sigma_{t}^2}{\sigma_{T}^2}) \mathbf{m} \right) \right)^2 \right\}} \\ 
% \end{split}
% \end{equation}

% Hence, the mean value $\mu_t$ of $p (x_t | x_0, x_T)$ can be obtained, 
% $$\mu_t = \frac{e^{\bar{f}_{t:T}}\sigma_{t}^2}{\sigma_{T}^2} x_T + \frac{e^{\bar{f}_{t}}\sigma_{t:T}^2}{\sigma_{T}^2} x_0 + (\frac{c_{t}\sigma_{t:T}^2}{\sigma_{T}^2} - \frac{e^{\bar{f}_{t:T}}c_{t:T}\sigma_{t}^2}{\sigma_{T}^2}) \mathbf{m}$$

% We only need to validate that the coefficients of $x_T$
% \begin{equation}
% \begin{split}
% \frac{e^{\bar{f}_{t:T}}\sigma_{t}^2}{\sigma_{T}^2}
% &= e^{\bar{f}_{t:T}} \frac{e^{2\bar{f}_t}\int_{0}^{t} e^{-2\bar{f}_z} g^2_z dz}{e^{2\bar{f}_T}\int_{0}^{T} e^{-2\bar{f}_z} g^2_z dz} \\ 
% &= e^{-\bar{f}_{t:T}} \frac{\int_{0}^{t} e^{-2\bar{f}_z} g^2_z dz}{\int_{0}^{T} e^{-2\bar{f}_z} g^2_z dz}
% \end{split}
% \end{equation}
% and the coefficients of $x_0$
% \begin{equation}
% \begin{split}
% \frac{e^{\bar{f}_{t}}\sigma_{t:T}^2}{\sigma_{T}^2}
% &= e^{\bar{f}_{t}} \frac{e^{2\bar{f}_T}\int_{t}^{T} e^{-2\bar{f}_z} g^2_z dz}{e^{2\bar{f}_T}\int_{0}^{T} e^{-2\bar{f}_z} g^2_z dz} \\ 
% &= e^{\bar{f}_{t}} \frac{\int_{t}^{T} e^{-2\bar{f}_z} g^2_z dz}{\int_{0}^{T} e^{-2\bar{f}_z} g^2_z dz} 
% \end{split}
% \end{equation}
% and the coefficients of $\mathbf{m}$
% \begin{equation}
% \begin{split}
% \frac{c_{t}\sigma_{t:T}^2}{\sigma_{T}^2} - \frac{e^{\bar{f}_{t:T}}c_{t:T}\sigma_{t}^2}{\sigma_{T}^2}
% &= \frac{e^{2\bar{f}_T}(\int_{t}^{T} e^{-2\bar{f}_z} g^2_z dz) e^{\bar{f}_t} (\int_{0}^{t} e^{-\bar{f}_z}h_z dz) - e^{\bar{f}_{t:T}} e^{\bar{f}_T} (\int_{t}^{T} e^{-\bar{f}_z}h_z dz) e^{2\bar{f}_t}(\int_{0}^{t} e^{-2\bar{f}_z} g^2_z dz) }{e^{2\bar{f}_{T}} \int_{0}^{T} e^{-2\bar{f}_z} g^2_z dz } \\ 
% &= e^{\bar{f}_t} \frac{\int_{t}^{T} e^{-2\bar{f}_z} g^2_z dz \cdot \int_{0}^{t} e^{-\bar{f}_z}h_z dz - \int_{0}^{t} e^{-2\bar{f}_z} g^2_z dz \cdot \int_{t}^{T} e^{-\bar{f}_z}h_z dz}{\int_{0}^{T} e^{-2\bar{f}_z} g^2_z dz} \\
% &= e^{\bar{f}_t} \frac{\left(\int_{0}^{T} e^{-2\bar{f}_z} g^2_z dz -\int_{0}^{t} e^{-2\bar{f}_z} g^2_z dz \right) \cdot \int_{0}^{t} e^{-\bar{f}_z}h_z dz - \int_{0}^{t} e^{-2\bar{f}_z} g^2_z dz \cdot \int_{t}^{T} e^{-\bar{f}_z}h_z dz}{\int_{0}^{T} e^{-2\bar{f}_z} g^2_z dz} \\
% &= e^{\bar{f}_t} \left( \int_{0}^{t} e^{-2\bar{f}_z} g^2_z dz - \frac{\int_{0}^{t} e^{-2\bar{f}_z} g^2_z dz \cdot \int_{0}^{T} e^{-\bar{f}_z}h_z dz}{\int_{0}^{T} e^{-2\bar{f}_z} g^2_z dz} \right) \\
% \end{split}
% \end{equation}
% which can conclude the proposition.



% % proposition
% \textbf{Proposition} For sufficiently small $\theta_t = \beta_t$ where $\beta_t$ is defined in I2SB such that $e^{\bar{\theta}_{t}} \approx 1 + \bar{\theta}_{t}$, the interpolant obtained from the control problem of GOU process $x_t = \Big(e^{-\bar{\theta}_{t}} - e^{-\bar{\theta}_{1}} \frac{e^{\bar{\theta}_{t}} - e^{-\bar{\theta}_{t}}}{e^{\bar{\theta}_{1}} - e^{-\bar{\theta}_{1}}} \Big) x_0 + \Big(1 - e^{-\bar{\theta}_{t}} + e^{-\bar{\theta}_{1}} \frac{e^{\bar{\theta}_{t}} - e^{-\bar{\theta}_{t}}}{e^{\bar{\theta}_{1}} - e^{-\bar{\theta}_{1}}} \Big) x_1 $ becomes $x_t = \left( \frac{\int_{t}^{1} \theta_z dz}{\int_{0}^{1} \theta_z dz} \right) x_0 + \left( \frac{\int_{0}^{t} \theta_z dz}{\int_{0}^{1} \theta_z dz} \right) x_1$, which precisely corresponds to the sampling process of I2SB.

% According to the Taylor Expansion, 
% \begin{equation}
% \begin{split}
% e^{-\bar{\theta}_{t}} - e^{-\bar{\theta}_{1}} \frac{e^{\bar{\theta}_{t}} - e^{-\bar{\theta}_{t}}}{e^{\bar{\theta}_{1}} - e^{-\bar{\theta}_{1}}} 
% &= \frac{e^{\bar{\theta}_{t:1}} - e^{-\bar{\theta}_{t:1}}}{e^{\bar{\theta}_{1}} - e^{-\bar{\theta}_{1}}} \\
% &= \frac{\bar{\theta}_{t:1} + \sum_{i=1}^{\infty} \frac{(\bar{\theta}_{t:1})^{2i+1}}{(2i+1)!}} {\bar{\theta}_{1} + \sum_{i=1}^{\infty} \frac{(\bar{\theta}_{1})^{2i+1}}{(2i+1)!}} \\
% &\approx \frac{\bar{\theta}_{t:1}}{\bar{\theta}_{1}} \\
% &= \frac{\int_{t}^{1} \theta_z dz}{\int_{0}^{1} \theta_z dz}
% \end{split}
% \end{equation}
% Hence, 
% \begin{equation}
% x_t = \left( e^{-\bar{\theta}_{t}} - e^{-\bar{\theta}_{1}} \frac{e^{\bar{\theta}_{t}} - e^{-\bar{\theta}_{t}}}{e^{\bar{\theta}_{1}} - e^{-\bar{\theta}_{1}}} \right) x_0 + \left(1 - e^{-\bar{\theta}_{t}} + e^{-\bar{\theta}_{1}} \frac{e^{\bar{\theta}_{t}} - e^{-\bar{\theta}_{t}}}{e^{\bar{\theta}_{1}} - e^{-\bar{\theta}_{1}}} \right) x_1 \approx \left( \frac{\int_{t}^{1} \theta_z dz}{\int_{0}^{1} \theta_z dz} \right) x_0 + \left( \frac{\int_{0}^{t} \theta_z dz}{\int_{0}^{1} \theta_z dz} \right) x_1
% \end{equation}
% which can conclude the proposition.


\subsection{Proof of Proposition \ref{proposition_4.4}}\label{proof_proposition_4.4}
\noindent \textbf{Proposition \ref{proposition_4.4}.} \textit{UniDB encompasses existing diffusion bridge models by employing different hyper-parameter spaces $\mathcal{H}$ as follows: }
\begin{itemize}
\item DDBMs (VE) corresponds to UniDB with hyper-parameter $\mathcal{H}_\text{VE}(f_t=0, h_t=0, \gamma \rightarrow \infty)$
\item DDBMs (VP) corresponds to UniDB with hyper-parameter $\mathcal{H}_\text{VP}(f_t=-\frac{1}{2} g^2_t, h_t=0, \gamma \rightarrow \infty)$
\item GOUB corresponds to UniDB with hyper-parameter $\mathcal{H}_\text{GOU}(f_t=\theta_t, h_t=-\theta_t, \mathbf{m} = \boldsymbol{\mu}, \gamma \rightarrow \infty)$
\end{itemize}

\begin{proof} \textbf{DDBMs (VE).} 
\begin{align*}
&\mathcal{H}_\text{VE}(f_t=0, h_t=0, \gamma \rightarrow \infty) \\
\Leftrightarrow \quad & \text{SOC problem with SDE: }\mathrm{d} \mathbf{x}_t = g_t \mathrm{d} \mathbf{w}_t \text{ as $\gamma \rightarrow \infty$} \\
\Leftrightarrow \quad & \mathrm{d} \mathbf{x}_t = \frac{\mathbf{x}_T - \mathbf{x}_t}{\int_{t}^{T} g_z^2 dz} \mathrm{d}t + g_t \mathrm{d} \mathbf{w}_t  \\
\Leftrightarrow \quad & \mathrm{d} \mathbf{x}_t = \frac{\mathbf{x}_T - \mathbf{x}_t}{\sigma_T^2 - \sigma_t^2} \mathrm{d}t + g_t \mathrm{d} \mathbf{w}_t \text{ with $g^2_t = \frac{d}{dt} \sigma_t^2 $} \\
\Leftrightarrow \quad & \text{DDBMs (VE) with Doob's \textit{h}-transform}
\end{align*}

\textbf{DDBMs (VP).}
\begin{align*}
&\mathcal{H}_\text{VP}(f_t=-\frac{1}{2} g^2_t, h_t=0, \gamma \rightarrow \infty) \\
\Leftrightarrow \quad & \text{SOC problem with SDE: }\mathrm{d} \mathbf{x}_t = -\frac{1}{2} g_t^2 \mathbf{x}_t \mathrm{d} t + g_t \mathrm{d} \mathbf{w}_t \text{ as $\gamma \rightarrow \infty$}\\
\Leftrightarrow \quad & \mathrm{d} \mathbf{x}_t = \left( -\frac{1}{2} g_t^2 \mathbf{x}_t + g^2_t e^{\int_{0}^{t} \frac{g^2_z}{2} dz}\frac{e^{-\frac{1}{2}\int_{0}^{t} g_z^2 dz}\mathbf{x}_T - e^{-\frac{1}{2}\int_{0}^{T} g_z^2 dz}\mathbf{x}_t}{e^{\frac{1}{2}\int_{t}^{T} g_z^2 dz} - e^{-\frac{1}{2}\int_{t}^{T} g_z^2 dz}} \right) \mathrm{d}t + g_t \mathrm{d} \mathbf{w}_t \\
\Leftrightarrow \quad & \mathrm{d} \mathbf{x}_t = \left( -\frac{1}{2} g_t^2 \mathbf{x}_t + g^2_t\frac{\alpha_t\mathbf{x}_T - \alpha_T\mathbf{x}_t}{\frac{\alpha_t^2\sigma_T^2}{\alpha_T} - \sigma_t^2\alpha_T} \right) \mathrm{d}t + g_t \mathrm{d} \mathbf{w}_t \ \text{where $\alpha_t = e^{-\frac{1}{2}\int_{0}^{t} g_z^2 dz}$ and $g^2_t = \frac{d}{dt}\sigma^2_t + g^2_t$}\sigma^2_t \\
\Leftrightarrow \quad & \mathrm{d} \mathbf{x}_t = \left( -\frac{1}{2} g_t^2 \mathbf{x}_t + g^2_t\frac{\frac{\alpha_t}{\alpha_T}\mathbf{x}_T - \mathbf{x}_t}{\sigma_t^2(\frac{\text{SNR}_t}{\text{SNR}_T} - 1)} \right) \mathrm{d}t + g_t \mathrm{d} \mathbf{w}_t \ \text{where $\text{SNR}_t = \frac{\alpha^2_t}{\sigma^2_t} $}\\
\Leftrightarrow \quad & \text{DDBMs (VP) with Doob's \textit{h}-transform}
\end{align*}

\textbf{GOUB.}
\begin{align*}
&\mathcal{H}_\text{GOU}(f_t=\theta_t, h_t=-\theta_t, \mathbf{m} = \boldsymbol{\mu}, \gamma \rightarrow \infty) \\
\Leftrightarrow \quad & \text{SOC problem with SDE: }\mathrm{d}\mathbf{x}_t = \theta_t\left(\boldsymbol{\mu}-\mathbf{x}_t \right) \mathrm{d} t + g_t \mathrm{d}\mathbf{w}_t \text{ as $\gamma \rightarrow \infty$}\\
\Leftrightarrow \quad & \mathrm{d} \mathbf{x}_t = \left( \theta_t + g^2_t \frac{e^{-2\bar{\theta}_{t:T}}}{\bar{\sigma}^2_{t:T}}\right) (x_T - \mathbf{x}_t) \mathrm{d} t + g_t \mathrm{d} \mathbf{w}_t \\
\Leftrightarrow \quad & \text{GOUB with Doob's \textit{h}-transform}
\end{align*}
which concludes the proof of the Proposition \ref{proposition_4.4}.

% Obviously, 
% \begin{equation}
% \begin{aligned}
% \lim_{f \to 0, h \to 0} \mathrm{General} &= \lim_{f \to 0, h \to 0}\left\{ \mathrm{d} \mathbf{x}_t = \left( f_t \mathbf{x}_t + h_t \mathbf{m} \right) \mathrm{d} t + g_t \mathrm{d} \mathbf{w}_t \right\} \\
%  & = \lim_{f \to 0, h \to 0}\left\{\mathrm{d}\mathbf{x}_t = g_t \mathrm{d}\mathbf{w}_t\right\} \\
%  & = \mathrm{VE}
% \end{aligned}
% \end{equation}

% \begin{equation}
% \begin{aligned}
% \lim_{f \to -\frac{1}{2} g_t^2, h \to 0} \mathrm{General} &= \lim_{f \to -\frac{1}{2} g_t^2, h \to 0}\left\{ \mathrm{d} \mathbf{x}_t = \left( f_t \mathbf{x}_t + h_t \mathbf{m} \right) \mathrm{d} t + g_t \mathrm{d} \mathbf{w}_t \right\} \\
%  & = \lim_{f \to -\frac{1}{2} g_t^2, h \to 0}\left\{\mathrm{d}\mathbf{x}_t = -\frac{1}{2} g_t^2 \mathbf{x}_t \mathrm{d} t + g_t \mathrm{d}\mathbf{w}_t\right\} \\
%  & = \mathrm{VP}
% \end{aligned}
% \end{equation}

% \begin{equation}
% \begin{aligned}
% \lim_{f \to -\theta_t, h \to \theta_t, \mathbf{m} \to \boldsymbol{\mu}} \mathrm{General} &= \lim_{f \to -\theta_t, h \to \theta_t, \mathbf{m} \to \boldsymbol{\mu}}\left\{ \mathrm{d} \mathbf{x}_t = \left( f_t \mathbf{x}_t + h_t \mathbf{m} \right) \mathrm{d} t + g_t \mathrm{d} \mathbf{w}_t \right\} \\
%  & = \lim_{f \to -\theta_t, h \to \theta_t, \mathbf{m} \to \boldsymbol{\mu}}\left\{\mathrm{d}\mathbf{x}_t = \theta_t\left(\boldsymbol{\mu}-\mathbf{x}_t\right) \mathrm{d} t + g_t \mathrm{d}\mathbf{w}_t\right\} \\
%  & = \mathrm{GOU}
% \end{aligned}
% \end{equation}    
\end{proof}





\subsection{Derivation of UniDB-GOU (forward SDE \eqref{20} and mean value of forward transition \eqref{21})}\label{proof_derivation_UniDB-GOU}
\noindent \textit{Consider the SOC problem with GOU process \eqref{gou_process}, the optimally-controlled forward SDE is}
\begin{equation}\tag{\ref{20}}
\mathrm{d} \mathbf{x}_t = \left( \theta_t + g^2_t \frac{e^{-2\bar{\theta}_{t:T}}}{\gamma^{-1} + \bar{\sigma}^2_{t:T}}\right) (x_T - \mathbf{x}_t) \mathrm{d} t + g_t \mathrm{d} \mathbf{w}_t,
\end{equation}
\textit{and the mean value of the probability $p(\mathbf{x}_t \mid x_0, x_T)$ is}
\begin{equation}\tag{\ref{21}}
\bar{\boldsymbol{\mu}}_{t, \gamma} = e^{-\bar{\theta}_{t}} \frac{1 + \gamma \bar{\sigma}^2_{t:T}}{1 + \gamma \bar{\sigma}^2_{T}} x_0 + \left(1 - e^{-\bar{\theta}_{t}} \frac{1 + \gamma \bar{\sigma}^2_{t:T}}{1 + \gamma \bar{\sigma}^2_{T}}\right) x_T.
\end{equation}

\begin{proof}
Consider the SOC problem with GOU process \eqref{gou_process} in the deterministic form: 
\begin{equation}
\begin{aligned}
\min_{\mathbf{u}_{t, \gamma}} &\int_{0}^{T} \frac{1}{2} \|\mathbf{u}_{t,\gamma}\|_2^2 dt + \frac{\gamma}{2} \| \mathbf{x}_T^u - x_T\|_2^2 \\
\text{s.t.} \quad \mathrm{d} \mathbf{x}_t &= \left( \theta_t(x_T - \mathbf{x}_t) + g_t \mathbf{u}_{t, \gamma} \right) \mathrm{d} t, \quad \mathbf{x}_0 = x_0
\end{aligned}
\end{equation}

where the definition of $\boldsymbol{\mu}$ and $g_t$ is the same as GOUB: $\boldsymbol{\mu} = x_T$  $g_{t}^{2} = 2 \lambda^2 \theta_t $. \\

Similarly to the proof of Proposition \ref{proof_theorem_4.1}, according to minimum principle theorem to obtain the following set of differential equations: 
\begin{equation}\label{mpt1_goub}
\frac{\mathrm{d}\mathbf{x}_{t}}{\mathrm{d}t}=\nabla_{\mathbf{p}_t}H\left(\mathbf{x}_{t},\mathbf{p}_{t},\mathbf{u}_{t, \gamma}^{*},t\right)= \theta_t x_T - \theta_t \mathbf{x}_t - g^2_t \mathbf{p}_{t} ,
\end{equation}
\begin{equation}\label{mpt2_goub}
\frac{\mathrm{d}\mathbf{p}_{t}}{\mathrm{d}t}=-\nabla_{\mathbf{x}_t}H\left(\mathbf{x}_{t},\mathbf{p}_{t},\mathbf{u}_{t, \gamma}^{*},t\right) = \theta_t \mathbf{p}_t,
\end{equation}
\begin{equation}\label{mpt3_goub}
\mathbf{x}_{0} = x_{0},
\end{equation}
\begin{equation}\label{mpt4_goub}
\mathbf{p}_{T}=\gamma \left(\mathbf{x}_T-x_{T}\right).
\end{equation}

Solving the equation \eqref{mpt2_goub}, we have:
\begin{equation}
\begin{gathered}
\mathbf{p}_{t} = \mathbf{p}_{0} e^{\bar{\theta}_{t}}, \\
\mathbf{p}_{T} = \mathbf{p}_{0} e^{\bar{\theta}_{T}},
\end{gathered}
\end{equation}

Then we solve the equation \eqref{mpt1_goub}:
\begin{align*}
    &\frac{\mathrm{d} \mathbf{x}_t}{\mathrm{d} t} = \theta_t x_T - \theta_t \mathbf{x}_t - g^2_t \mathbf{p}_{t} \\
    \Rightarrow \quad &\frac{\mathrm{d} (e^{\bar{\theta}_{t}} \mathbf{x}_t)}{\mathrm{d} t} = e^{\bar{\theta}_{t}} \theta_t x_T - e^{\bar{\theta}_{t}} g^2_t \mathbf{p}_{t}, \\
    \Rightarrow \quad &e^{\bar{\theta}_{t}} \mathbf{x}_t - \mathbf{x}_0 = x_T \int_{0}^{t}e^{\bar{\theta}_{z}} \theta_z dz - \mathbf{p}_{0} \int_{0}^{t} g^2_z e^{2\bar{\theta}_{z}} dz,  \\
    \Rightarrow \quad &e^{\bar{\theta}_{t}} \mathbf{x}_t - x_0 = x_T (e^{\bar{\theta}_{t}} - 1) - \lambda^2 \mathbf{p}_{0} (e^{2\bar{\theta}_{t}} - 1). \\
\end{align*}

Hence, we can get:
\begin{equation}\label{x1_goub}
\mathbf{x}_T = e^{-\bar{\theta}_{T}}x_0 + (1 - e^{-\bar{\theta}_{T}}) x_T - \lambda^2 \mathbf{p}_{T} (1 - e^{-2\bar{\theta}_{T}}),
\end{equation}
and
\begin{equation}\label{xt_goub}
\mathbf{x}_t = e^{-\bar{\theta}_{t}}x_0 + (1 - e^{-\bar{\theta}_{t}}) x_T - \lambda^2 e^{-\bar{\theta}_{T}} \mathbf{p}_{T}  (e^{\bar{\theta}_{t}} - e^{-\bar{\theta}_{t}}).
\end{equation}

Take the equation \eqref{x1_goub} into the equation \eqref{mpt4_goub} and solve $\mathbf{p}_{T}$, 
\begin{align*}
&\mathbf{p}_{T} = \gamma \left( e^{-\bar{\theta}_{1}}x_0 + (1 - e^{-\bar{\theta}_{T}}) x_T - \lambda^2 \mathbf{p}_{T} (1 - e^{-2\bar{\theta}_{T}}) - x_{T} \right) \\
\Rightarrow \quad & \mathbf{p}_{T} = \frac{\gamma e^{-\bar{\theta}_{T}} (x_0 - x_T)}{1 + \gamma \lambda^2 (1 - e^{-2\bar{\theta}_{T}})}.
\end{align*}

% Take $\gamma \to \infty$, 
% \begin{equation}\label{p1_goub}
% \mathbf{p}_{T} = \frac{e^{-\bar{\theta}_{1}}(x_0 - x_T)}{\lambda^2 (1 - e^{-2\bar{\theta}_{T}})}
% \end{equation}

% Also, take the equation \ref{p1_goub} into the equation \ref{xt_goub}, 
% \begin{equation}
% \begin{split}
%     \mathbf{x}_t 
%     &= e^{-\bar{\theta}_{t}}x_0 + (1 - e^{-\bar{\theta}_{t}}) x_T - \lambda^2 e^{-\bar{\theta}_{T}} (e^{\bar{\theta}_{t}} - e^{-\bar{\theta}_{t}}) \frac{e^{-\bar{\theta}_{T}}(x_0 - x_T)}{\lambda^2 (1 - e^{-2\bar{\theta}_{T}})}  \\
%     &= \Big(e^{-\bar{\theta}_{t}} - e^{-\bar{\theta}_{T}} \frac{e^{\bar{\theta}_{t}} - e^{-\bar{\theta}_{t}}}{e^{\bar{\theta}_{T}} - e^{-\bar{\theta}_{T}}} \Big) x_0 + \Big(1 - e^{-\bar{\theta}_{t}} + e^{-\bar{\theta}_{T}} \frac{e^{\bar{\theta}_{t}} - e^{-\bar{\theta}_{t}}}{e^{\bar{\theta}_{T}} - e^{-\bar{\theta}_{T}}} \Big) x_T \\
% \end{split}
% \end{equation}

% Hence, 
% \begin{equation}
% g_t \mathbf{u}^{*}_{t, \gamma} = - g^2_t \mathbf{p}_{t} = - 2 \theta_t e ^{\bar{\theta}_{t}} \frac{e^{-2\bar{\theta}_{T} } (x_T - x_0)}{1 - e^{-2\bar{\theta}_{T}}}
% \end{equation}

% The origin dynamics can be: 
% \begin{equation}
% \mathrm{d} \mathbf{x}_t = \Big( \theta_t(x_T - \mathbf{x}_t) + 2 \theta_t e ^{\bar{\theta}_{t}} \frac{e^{-2\bar{\theta}_{T} } (x_T - x_0)}{1 - e^{-2\bar{\theta}_{T}}} \Big) \mathrm{d} t + g_t \mathrm{d} w_t
% \end{equation}

% If we preserve $\gamma$, then 
% \begin{equation}\label{p1_goub_gamma}
% \mathbf{p}_{T} = \frac{\gamma e^{-\bar{\theta}_{T}} (x_0 - x_T)}{1 + \gamma \lambda^2 (1 - e^{-2\bar{\theta}_{T}})}
% \end{equation}

Hence, 
\begin{equation}
\begin{split}
    \mathbf{x}_t 
    &= e^{-\bar{\theta}_{t}}x_0 + (1 - e^{-\bar{\theta}_{t}}) x_T - \lambda^2 e^{-\bar{\theta}_{T}} (e^{\bar{\theta}_{t}} - e^{-\bar{\theta}_{t}}) \frac{\gamma e^{-\bar{\theta}_{T}} (x_0 - x_T)}{1 + \gamma \lambda^2 (1 - e^{-2\bar{\theta}_{T}})}  \\
    &= \left(e^{-\bar{\theta}_{t}} - \frac{\gamma \lambda^2 e^{-2\bar{\theta}_{T}} (e^{\bar{\theta}_{t}} - e^{-\bar{\theta}_{t}})}{1 + \gamma \lambda^2 (1 - e^{-2\bar{\theta}_{T}})} \right) x_0 + \left(1 - e^{-\bar{\theta}_{t}} + \frac{\gamma \lambda^2 e^{-2\bar{\theta}_{T}} (e^{\bar{\theta}_{t}} - e^{-\bar{\theta}_{t}})}{1 + \gamma \lambda^2 (1 - e^{-2\bar{\theta}_{T}})} \right) x_T \\
    &= \left(e^{-\bar{\theta}_{t}} \frac{1 + \gamma \lambda^2 (1 - e^{-2\bar{\theta}_{t:T}})}{1 + \gamma \lambda^2 (1 - e^{-2\bar{\theta}_{T}})} \right) x_0 + \left(1 - e^{-\bar{\theta}_{t}} \frac{1 + \gamma \lambda^2 (1 - e^{-2\bar{\theta}_{t:T}})}{1 + \gamma \lambda^2 (1 - e^{-2\bar{\theta}_{1}})}\right) x_T \\
    &= e^{-\bar{\theta}_{t}} \frac{1 + \gamma \bar{\sigma}^2_{t:T}}{1 + \gamma \bar{\sigma}^2_{T}} x_0 + \left(1 - e^{-\bar{\theta}_{t}} \frac{1 + \gamma \bar{\sigma}^2_{t:T}}{1 + \gamma \bar{\sigma}^2_{T}}\right) x_T, \\
\end{split}
\end{equation}
which implies 
\begin{equation}
\bar{\boldsymbol{\mu}}_{t, \gamma} = e^{-\bar{\theta}_{t}} \frac{1 + \gamma \bar{\sigma}^2_{t:T}}{1 + \gamma \bar{\sigma}^2_{T}} x_0 + \left(1 - e^{-\bar{\theta}_{t}} \frac{1 + \gamma \bar{\sigma}^2_{t:T}}{1 + \gamma \bar{\sigma}^2_{T}}\right) x_T.
\end{equation}
Then, 
\begin{equation}
\begin{split}
\mathbf{u}^{*}_{t, \gamma} 
&= - g_t \mathbf{p}_{t} \\
&= - g_t e^{\bar{\theta}_{t}} e^{-\bar{\theta}_{T}} \frac{\gamma e^{-\bar{\theta}_{T}} (x_0 - x_T)}{1 + \gamma \lambda^2 (1 - e^{-2\bar{\theta}_{T}})} \\
&= - g_t e^{\bar{\theta}_{t}} e^{-\bar{\theta}_{T}} \frac{\gamma e^{-\bar{\theta}_{T}} (x_0 - x_T)}{1 + \gamma \bar{\sigma}^2_{T}} \\
&= - g_t e^{\bar{\theta}_{t}} e^{-\bar{\theta}_{T}} \frac{\gamma e^{-\bar{\theta}_{T}} e^{\bar{\theta}_{t}} (\mathbf{x}_t - x_T)}{1 + \gamma \bar{\sigma}^2_{t:T}} \\
&= g_t \frac{e^{-2\bar{\theta}_{t:T}} (x_T - \mathbf{x}_t)}{\gamma^{-1} + \bar{\sigma}^2_{t:T}}.
\end{split}
\end{equation}
And the optimally-controlled dynamics can be: 
\begin{equation}
\mathrm{d} \mathbf{x}_t = \left( \theta_t + g^2_t \frac{e^{-2\bar{\theta}_{t:T}}}{\gamma^{-1} + \bar{\sigma}^2_{t:T}}\right) (x_T - \mathbf{x}_t) \mathrm{d} t + g_t \mathrm{d} \mathbf{w}_t,
\end{equation}
which concludes the derivation of UniDB-GOU (forward SDE \eqref{20} and mean value of forward transition \eqref{21}).
\end{proof}


\subsection{Examples of UniDB-VE and UniDB-VP}\label{ve_vp_example}
Similar to section \ref{example}, we provide the other examples of UniDB-VE and UniDB-VP, highlighting the key difference of the coefficient of $x_0$ in the mean value of forward transition and $h$-function term between UniDB and them respectively. 

\textbf{UniDB-VE}
\begin{equation}
\begin{aligned}
\textcolor{gray} {\quad \quad \quad \frac{\sigma_T^2 - \sigma_t^2}{\sigma_T^2 - \sigma_0^2}} \ & \ \Rightarrow \ \frac{\gamma^{-1} + \sigma_T^2 - \sigma_t^2}{\gamma^{-1} + \sigma_T^2 - \sigma_0^2} \\
\underbrace{\textcolor{gray} {\mathbf{h} = \frac{x_T - \mathbf{x}_t}{\sigma_T^2 - \sigma_t^2}}}_{\text{VE}} \ & \ \Rightarrow \ \underbrace{\frac{\mathbf{u}_{t, \gamma}^{*}}{g_t} = \frac{x_T - \mathbf{x}_t}{\gamma^{-1} + \sigma_T^2 - \sigma_t^2}}_{\text{UniDB-VE}}
\end{aligned}
\end{equation}

\textbf{UniDB-VP}
\begin{equation}
\begin{aligned}
\textcolor{gray} {\quad \quad \quad \alpha_t\left(1 - \frac{\text{SNR}_T}{\text{SNR}_t}\right)} \ & \ \Rightarrow \ \alpha_t\left(1 - \frac{\frac{\alpha_t^2\alpha_T}{\sigma_t^2\sigma_T^2}\gamma^{-1}+\text{SNR}_T}{\frac{\alpha_t^2\alpha_T}{\sigma_t^2\sigma_T^2}\gamma^{-1}+\text{SNR}_t}\right) \\
\underbrace{\textcolor{gray} {\mathbf{h} = \frac{\frac{\alpha_t}{\alpha_T}x_T - \mathbf{x}_t}{\sigma_t^2(\frac{\text{SNR}_t}{\text{SNR}_T} - 1)}}}_{\text{VP}} \ & \ \Rightarrow \ \underbrace{\frac{\mathbf{u}_{t, \gamma}^{*}}{g_t} = \frac{\frac{\alpha_t}{\alpha_T}x_T - \mathbf{x}_t}{\gamma^{-1}\frac{\alpha_t}{\alpha_T} + \sigma_t^2(\frac{\text{SNR}_t}{\text{SNR}_T} - 1)}}_{\text{UniDB-VP}}
\end{aligned}
\end{equation}


\subsection{Proof of Proposition \ref{proposition_4.5}}\label{proof_proposition_4.5}
\noindent \textbf{Proposition \ref{proposition_4.5}.} \textit{Denote the initial state distribution $x_0$, the terminal distribution $\mathbf{x}_T^u$ by the controller and the pre-defined terminal distribution $x_T$, then}
\begin{equation}\tag{\ref{terminal_distance}}
    \| \mathbf{x}_T^u - x_T \|^2_2 = \frac{e^{-2\bar{\theta}_{T}}}{\left(1 + \gamma \lambda^2 (1 - e^{-2\bar{\theta}_{T}}) \right)^2} \| x_T - x_0 \|^2_2 .
\end{equation}

\begin{proof}
According to Appendix \ref{proof_derivation_UniDB-GOU}, we've learned that 
\begin{equation}
\mathbf{x}_t^u = e^{-\bar{\theta}_{t}} \frac{1 + \gamma \bar{\sigma}^2_{t:T}}{1 + \gamma \bar{\sigma}^2_{T}} x_0 + \left(1 - e^{-\bar{\theta}_{t}} \frac{1 + \gamma \bar{\sigma}^2_{t:T}}{1 + \gamma \bar{\sigma}^2_{T}}\right) x_T + 
\frac{\bar{\sigma}_t^2\bar{\sigma}_{t:T}^2}{\bar{\sigma}_T^2} \epsilon.
\end{equation}
Take $t = T$, then
\begin{equation}
\mathbf{x}_T^u = \frac{e^{-\bar{\theta}_{t}}}{1 + \gamma \bar{\sigma}^2_{T}} x_0 + \left(1 - \frac{e^{-\bar{\theta}_{t}}}{1 + \gamma \bar{\sigma}^2_{T}}\right) x_T.
\end{equation}
Therefore, since $\bar{\sigma}^2_{T} = \lambda^2 (1 - e^{-2\bar{\theta}_{T}})$, 
\begin{equation}
\begin{split}
\| \mathbf{x}_T^u - x_T \|^2_2
&= \Big\| \frac{e^{-\bar{\theta}_{t}}}{1 + \gamma \bar{\sigma}^2_{T}} x_0 + \left(1 - \frac{e^{-\bar{\theta}_{t}}}{1 + \gamma \bar{\sigma}^2_{T}}\right) x_T - x_T \Big\|^2_2 \\
&= \frac{e^{-2\bar{\theta}_{T}}}{\left(1 + \gamma \lambda^2 (1 - e^{-2\bar{\theta}_{T}}) \right)^2} \| x_T - x_0 \|^2_2 ,
\end{split}
\end{equation}
which concludes the proof of the Proposition \ref{proposition_4.5}.
\end{proof}




% \section{Discussion}
% 
\section{Pseudocode Descriptions}\label{append_pseudo}
We provide the relevant simple-version pseudo-code for our UniDB-GOU model as an example regarding the training and sampling process. The two algorithms encapsulate the core methodologies employed by our model to learn and explain how to restore HQ images from LQ images. Also, the red and the green parts highlight the main difference between UniDB and GOUB.


% \colorbox{blue!20}
% \colorbox{green!30}


\begin{algorithm}[h]
   \caption{UniDB Training}
   \label{training}
\begin{algorithmic}

    \REPEAT
        \STATE Take a pair of images $\mathbf{x}_0 = x_0$, $\mathbf{x}_T = x_T$
        \STATE  $t \sim \text{Uniform}(\{ 1, ..., T\})$
        \STATE {$\sigma_{t-1, \theta} = g_t$}
        \STATE \colorbox{red!30}{$a_{t, \gamma} = e^{-\bar{\theta}_{t}}${$\frac{\bar{\sigma}^2_{t:T}}{\bar{\sigma}^2_{T}}$} $\quad \leftarrow \quad$ GOUB }
        \STATE \colorbox{green!30}{$a_{t, \gamma} = e^{-\bar{\theta}_{t}}\frac{\gamma^{-1}+\bar{\sigma}^2_{t:T}}{\gamma^{-1}+\bar{\sigma}^2_{T}}\quad \leftarrow \quad \text{UniDB-GOU} $  }
        \STATE $\mathbf{x}_t = a_{t, \gamma} x_0 + \left(1 - a_{t, \gamma}\right) x_T + \bar{\sigma}_{t}^{\prime} \epsilon$
        \STATE $\bar{\boldsymbol{\mu}}_{t, \gamma} = a_{t, \gamma} x_0 + \left(1 - a_{t, \gamma}\right) x_T$
        \STATE \colorbox{red!30}{$\boldsymbol{\mu}_{t-1, \theta} = \mathbf{x}_{t} - \left( \theta_t + g^2_t \frac{e^{-2\bar{\theta}_{t:T}}}{\bar{\sigma}^2_{t:T}}\right) (x_T - \mathbf{x}_t) + \frac{g^2_t}{\bar{\sigma}_{t}^{\prime 2}} \boldsymbol{\epsilon}_{\theta}(\mathbf{x}_t, x_T, t) \quad \leftarrow \quad \text{GOUB}$} 
        \STATE \colorbox{green!30} {$\boldsymbol{\mu}_{t-1, \theta} = \mathbf{x}_{t} - \left( \theta_t + g^2_t \frac{e^{-2\bar{\theta}_{t:T}}}{\gamma^{-1} + \bar{\sigma}^2_{t:T}}\right) (x_T - \mathbf{x}_t) + \frac{g^2_t}{\bar{\sigma}_{t}^{\prime 2}} \boldsymbol{\epsilon}_{\theta}(\mathbf{x}_t, x_T, t) \quad \leftarrow \quad \text{UniDB + GOU}$} 
        \STATE $\boldsymbol{\mu}_{t-1, \gamma} = \bar{\boldsymbol{\mu}}_{t-1, \gamma} + \frac{\bar{\sigma}_{t-1}^{\prime}a_{t, \gamma}}{\bar{\sigma}_{t}^{\prime2}a_{t-1, \gamma}} (\mathbf{x}_t - \bar{\boldsymbol{\mu}}_{t, \gamma})$
        \STATE Take gradient descent step on $\nabla_{\theta} \left( \mathcal{L}_{\theta} = \mathbb{E}_{t, \mathbf{x}_0, \mathbf{x}_t, \mathbf{x}_T} \left[ \frac{1}{2\sigma_{t-1, \theta}^2} \| \boldsymbol{\mu}_{t-1, \theta} - \boldsymbol{\mu}_{t-1, \gamma} \| \right] \right)$
    \UNTIL converged
\end{algorithmic}



\end{algorithm}




\begin{algorithm}[h]
   \caption{UniDB Sampling}
   \label{sampling}
\begin{algorithmic}
    \STATE {\bfseries Input:} LQ images $\mathbf{x}_T = x_T$.
    \FOR{$t=T$ {\bfseries to} $1$}
        \STATE $ z \sim N(0, I)$ if $t > 1$, else $z = 0$  
        \STATE $\mathbf{x}_{t-1} = \mathbf{x}_{t} - \left( \theta_t + g^2_t \frac{e^{-2\bar{\theta}_{t:T}}}{\gamma^{-1} + \bar{\sigma}^2_{t:T}}\right) (x_T - \mathbf{x}_t) + \frac{g^2_t}{\bar{\sigma}_{t}^{\prime 2}} \boldsymbol{\epsilon}_{\theta}(\mathbf{x}_t, x_T, t) - g_t z $
   \ENDFOR
   \STATE \textbf{Return} HQ images $\mathbf{x}_0$
\end{algorithmic}
\end{algorithm}




\section{More Related Work}\label{more_related_work}
\textbf{Diffusion Schrdinger Bridge.} This approach aims to determine a stochastic process, $\pi^*$ that facilitates probabilistic transport between a given initial distribution $P_{\text{prior}}$, and a terminal distribution $P_{\text{data}}$ \cite{I2SB, shi2023diffusionschrodingerbridgematching,debortoli2023diffusionschrodingerbridgeapplications} while minimizing the Kullback-Leibler (KL) divergence. However, its training process is usually intricate, involving constraints that hinder direct optimization of the KL divergence, resulting in slow convergence and limited model fitting capability. For instance, DSB \cite{somnath2024aligneddiffusionschrodingerbridges} requires two independent forward passes during training to obtain the target distribution, thereby increasing both the complexity and time cost of training.





\newpage

% \section{Additional Ablation Study}\label{append_ablation}
% \textbf{Different Diffusion Bridges.} According to Proposition \ref{proposition_4.4}, UniDB unified some existing diffusion bridge models, so we conducted other ablation experiments about applying UniDB on different bridges, including DDBMs (VE), DDBMs (VP), and GOUB, and the results are listed in Table \ref{different_bridges} (DIV2K, Rain100H, and CelebA-HQ 256$\times$256 for three tasks) and Table \ref{sr_table_Celeba} (CelebA-HQ 256$\times$256 for $4\times$super-resolution). As can be seen in Table \ref{different_bridges} and Table \ref{sr_table_Celeba}, our UniDB performs better than each diffusion bridge, which proves the robustness of UniDB.
% \vspace{-0.2cm}
% \begin{table*}[htbp]
%   \centering
%   \caption{Qualitative comparison between different bridge models and ours on DIV2K, Rain100H, and CelebA-HQ 256$\times$256 datasets.}
%   % \vspace{-2mm}
%   \vskip 0.1in
%   \label{different_bridges}
%   \resizebox{\textwidth}{!}{
%   \begin{tabular}{ccccccccccccc}
%     \toprule
%     \multirow{2}*{\textbf{METHOD}} & \multicolumn{4}{c}{\textbf{Image 4$\times$ Super-Resolution}} & \multicolumn{4}{c}{\textbf{Image Deraining}} & \multicolumn{4}{c}{\textbf{Image Inpainting}} \\
%     \cmidrule(r){2-5} \cmidrule(r){6-9} \cmidrule(r){10-13}
%       & \textbf{PSNR}$\uparrow$ & \textbf{SSIM}$\uparrow$ & \textbf{LPIPS}$\downarrow$ & \textbf{FID}$\downarrow$ & \textbf{PSNR}$\uparrow$ & \textbf{SSIM}$\uparrow$ & \textbf{LPIPS}$\downarrow$ & \textbf{FID}$\downarrow$ & \textbf{PSNR}$\uparrow$ & \textbf{SSIM}$\uparrow$ & \textbf{LPIPS}$\downarrow$ & \textbf{FID}$\downarrow$ \\
%     \midrule
%     DDBMs (VE) & 23.34 & 0.4295 & 0.372 & 32.28 & 29.34 & 0.7654 & \textbf{0.185} & 43.22 & 25.37 & 0.5950 & 0.195 & 31.17\\
%     UniDB-VE & \textbf{23.84} & \textbf{0.4454} & \textbf{0.357} & \textbf{31.29} & \textbf{29.46} & \textbf{0.7671} & \textbf{0.185} & \textbf{42.57} &  &  &  &  \\
%     \toprule
%     DDBMs (VP) & 22.11 & 0.4059 & 0.491 & 48.09 & 29.58 & 0.828 & 0.113 & 35.46 &  &  &  &  \\
%     UniDB-VP & \textbf{22.42} & \textbf{0.4097} & \textbf{0.486} & \textbf{44.52} & \textbf{30.11} & \textbf{0.8414} & \textbf{0.102} & \textbf{33.17} & 27.56 & 0.778 & 0.095 & 20.95 \\
%     \toprule
%     GOUB (SDE) & 26.89 & 0.7478 & 0.220 & 20.85 & 31.96 & 0.9028 & 0.046 & 18.14 & 28.98 & 0.9067 & 0.037 & 4.30 \\
       
%     GOUB (ODE) & 28.50 & 0.8070 & 0.328 & 22.14 & 34.56 & 0.9414 & 0.077 & 32.83 & 31.39 & 0.9392 & 0.052 & 12.24 \\
          
%     UniDB-GOU (SDE) & 25.46 & 0.6856 & \textbf{0.179} & \textbf{16.21} & 32.05 & 0.9036 & \textbf{0.045} & \textbf{17.65} & 29.20 & 0.9077 & \textbf{0.036} & \textbf{4.08} \\
    
%     UniDB-GOU (ODE) & \textbf{28.64} & \textbf{0.8072} & 0.323 & 22.32 & \textbf{34.68} & \textbf{0.9426} & 0.074 & 31.16 & \textbf{31.67} & \textbf{0.9395} & 0.052 & 11.98 \\   
%     \bottomrule          
%   \end{tabular}
%   }
%   \vskip -0.1in
% \end{table*}






\section{Implementation Details}\label{appendix_experimental_details}
In Image Restoration Tasks (Image 4$\times$Super-resolution, Image Deraining and Image Inpainting), we follow the experiment setting of GOUB \cite{yue2024imagerestorationgeneralizedornsteinuhlenbeck}: the same noise network which is similar to U-Net structure \cite{chung2024diffusionposteriorsamplinggeneral}, steady variance level $\lambda^2 = 30^2 / 255^2$, coefficient $e^{\bar{\theta}_T} = 0.005$ instead of zero, sampling step number $T = 100$, 128 patch size with 8 batch size when training, Adam optimizer with $\beta_1 = 0.9$ and $\beta_2 = 0.99$ \cite{kingma2017adammethodstochasticoptimization}, 1.2 million total training steps with $10^{-4}$ initial learning rate and decaying by half at 300, 500, 600, and 700 thousand iterations. With respect to the schedule of $\theta_t$, we choose a flipped version of cosine noise schedule \cite{nichol2021improveddenoisingdiffusionprobabilistic, IRSDE}, 
\begin{equation}
    \theta_t = 1 - \frac{cos(\frac{t / T + s}{1 + s} \frac{\pi}{2})^2}{cos(\frac{s}{1 + s} \frac{\pi}{2})^2}
\end{equation}
where $s = 0.008$ to achieve a smooth noise schedule. $g_t$ is determined through $g_{t}^{2} = 2 \lambda^2 \theta_t$. As for the datasets of the three main experiments, we take 800 images for training and 100 for testing for the DIV2K dataset, 1800 images for training and 100 for testing for the Rain100H dataset, 27000 images for training and 3000 for testing for the CelebA-HQ 256$\times$256 dataset. Our models are trained on a single NVIDIA H20 GPU with 96GB memory for about 2 days.



\section{Additional Experimental Results}\label{appendix_additional_results}
Here we will illustrate more experimental results. 



% \begin{table*}[htbp]
%   \centering
%   \caption{Qualitative comparison between different bridge models and ours on DIV2K, Rain100H, and CelebA-HQ 256$\times$256 datasets.}
%   % \vspace{-2mm}
%   \vskip 0.1in
%   \label{different_bridges}
%   \resizebox{\textwidth}{!}{
%   \begin{tabular}{ccccccccccccc}
%     \toprule
%     \multirow{2}*{\textbf{METHOD}} & \multicolumn{4}{c}{\textbf{Image 4$\times$ Super-Resolution}} & \multicolumn{4}{c}{\textbf{Image Deraining}} & \multicolumn{4}{c}{\textbf{Image Inpainting}} \\
%     \cmidrule(r){2-5} \cmidrule(r){6-9} \cmidrule(r){10-13}
%       & \textbf{PSNR}$\uparrow$ & \textbf{SSIM}$\uparrow$ & \textbf{LPIPS}$\downarrow$ & \textbf{FID}$\downarrow$ & \textbf{PSNR}$\uparrow$ & \textbf{SSIM}$\uparrow$ & \textbf{LPIPS}$\downarrow$ & \textbf{FID}$\downarrow$ & \textbf{PSNR}$\uparrow$ & \textbf{SSIM}$\uparrow$ & \textbf{LPIPS}$\downarrow$ & \textbf{FID}$\downarrow$ \\
%     \midrule
%     DDBMs (VE) & 23.34 & 0.4295 & 0.372 & 32.28 & 29.34 & 0.7654 & \textbf{0.185} & 43.22 & 25.37 & 0.5950 & 0.195 & 31.17\\
%     UniDB-VE & \textbf{23.84} & \textbf{0.4454} & \textbf{0.357} & \textbf{31.29} & \textbf{29.46} & \textbf{0.7671} & \textbf{0.185} & \textbf{42.57} &  &  &  &  \\
%     \toprule
%     DDBMs (VP) & 22.11 & 0.4059 & 0.491 & 48.09 & 29.58 & 0.828 & 0.113 & 35.46 &  &  &  &  \\
%     UniDB-VP & \textbf{22.42} & \textbf{0.4097} & \textbf{0.486} & \textbf{44.52} & \textbf{30.11} & \textbf{0.8414} & \textbf{0.102} & \textbf{33.17} & 27.56 & 0.778 & 0.095 & 20.95 \\
%     % \toprule
%     % GOUB (SDE) & 26.89 & 0.7478 & 0.220 & 20.85 & 31.96 & 0.9028 & 0.046 & 18.14 & 28.98 & 0.9067 & 0.037 & 4.30 \\
       
%     % GOUB (ODE) & 28.50 & 0.8070 & 0.328 & 22.14 & 34.56 & 0.9414 & 0.077 & 32.83 & 31.39 & 0.9392 & 0.052 & 12.24 \\
          
%     % UniDB-GOU (SDE) & 25.46 & 0.6856 & \textbf{0.179} & \textbf{16.21} & 32.05 & 0.9036 & \textbf{0.045} & \textbf{17.65} & 29.20 & 0.9077 & \textbf{0.036} & \textbf{4.08} \\
    
%     % UniDB-GOU (ODE) & \textbf{28.64} & \textbf{0.8072} & 0.323 & 22.32 & \textbf{34.68} & \textbf{0.9426} & 0.074 & 31.16 & \textbf{31.67} & \textbf{0.9395} & 0.052 & 11.98 \\   
%     \bottomrule          
%   \end{tabular}
%   }
%   \vskip -0.1in
% \end{table*}


\begin{table*}[htbp]
  \centering
  \caption{Qualitative comparison between different bridge models (DDBMs (VE) and DDBMs (VP)) and ours (UniDB-VE and UniDB-VP) on DIV2K and Rain100H datasets.}
  \vskip 0.1in
  \label{different_bridges_sr_derain}
  \resizebox{0.8\textwidth}{!}{
  \begin{tabular}{ccccccccc}
    \toprule
    \multirow{2}*{\textbf{METHOD}} & \multicolumn{4}{c}{\textbf{Image 4$\times$ Super-Resolution}} & \multicolumn{4}{c}{\textbf{Image Deraining}}  \\
    \cmidrule(r){2-5} \cmidrule(r){6-9}
      & \textbf{PSNR}$\uparrow$ & \textbf{SSIM}$\uparrow$ & \textbf{LPIPS}$\downarrow$ & \textbf{FID}$\downarrow$ & \textbf{PSNR}$\uparrow$ & \textbf{SSIM}$\uparrow$ & \textbf{LPIPS}$\downarrow$ & \textbf{FID}$\downarrow$  \\
    \midrule
    DDBMs (VE) & 23.34 & 0.4295 & 0.372 & 32.28 & 29.34 & 0.7654 & \textbf{0.185} & 43.22 \\
    UniDB-VE & \textbf{23.84} & \textbf{0.4454} & \textbf{0.357} & \textbf{31.29} & \textbf{29.46} & \textbf{0.7671} & \textbf{0.185} & \textbf{42.57} \\
    \toprule
    DDBMs (VP) & 22.11 & 0.4059 & 0.491 & 48.09 & 29.58 & 0.828 & 0.113 & 35.46 \\
    UniDB-VP & \textbf{22.42} & \textbf{0.4097} & \textbf{0.486} & \textbf{44.52} & \textbf{30.11} & \textbf{0.8414} & \textbf{0.102} & \textbf{33.17} \\
    \bottomrule          
  \end{tabular}
  }
  \vskip -0.1in
\end{table*}

\begin{table*}[h]
    % \vspace{-0.5cm}
    \centering
    \caption{\textbf{Image 4$\times$Super-Resolution.} Qualitative evaluation of the CelebA-HQ 256$\times$256 datasets with baselines.}
    \vskip 0.1in
    \footnotesize

    \tabcolsep=0.3cm
    \resizebox{0.78\textwidth}{!}{
    \begin{tabular}{cccccc}
        \toprule[1.2pt]
          \textbf{METHOD} & \textbf{Penalty Coefficient $\boldsymbol{\gamma}$} & \textbf{PSNR}$\uparrow$ & \textbf{SSIM}$\uparrow$ & \textbf{LPIPS}$\downarrow$ & \textbf{FID}$\downarrow$ \\
        \toprule[0.6pt]

        DDBM (VE) & $\infty$ & \textbf{25.84} & \textbf{0.5099} & 0.381 & 67.98 \\
        
        UniDB-VE & $1\times10^7$ & 25.37 & 0.504 & \textbf{0.265} & \textbf{53.98} \\

        \toprule[0.6pt]

        DDBM (VP) & $\infty$ & 27.13 & 0.6497 & 0.194 & 42.54 \\
        
        UniDB-VP & $1\times10^7$ & \textbf{27.44} & \textbf{0.6631} & \textbf{0.174} & \textbf{42.06} \\

        \toprule[0.6pt]

        GOUB & $\infty$ & 28.63 & 0.7776 & 0.104 & 19.02 \\
        
        UniDB-GOU & $1\times10^7$ & \textbf{28.70} & \textbf{0.7894} & \textbf{0.090} & \textbf{17.59} \\
        \bottomrule[1.2pt]
    \end{tabular}
    }
    \label{sr_table_Celeba}
\end{table*}


\begin{table}[H]
    
  \centering
  \caption{\textbf{Image 4$\times$Super-Resolution.} Qualitative evaluation of the FFHQ 256$\times$256 dataset with baselines.}
  \label{sr_table_ffhq}
  \vskip 0.05in
  \begin{tabular}{lcc}
    \toprule
    \textbf{METHOD} & \textbf{LPIPS$\downarrow$} & \textbf{FID$\downarrow$}  \\
    \midrule
    DDRM & 0.339 & 59.57 \\  
    DPS & 0.214 & 39.35 \\
    DDBM (VE) & 0.239 & 42.85 \\
    DDBM (VP) & 0.177 & 39.63 \\
    GOUB & 0.072 & 21.77 \\
    \midrule
    UniDB-GOU & \textbf{0.069} & \textbf{20.24} \\ 
    \bottomrule			
  \end{tabular}
\vskip -0.1in
\end{table}


\begin{table}[H]
    
  \centering
  \caption{\textbf{Image Inpainting.} Qualitative comparison with the relevant baselines on CelebA-HQ with thick mask.}
  \label{inpainting_table_thick}
  \vskip 0.05in
  \begin{tabular}{lcccc}
    \toprule
    \textbf{METHOD} & \textbf{PSNR}$\uparrow$ & \textbf{SSIM}$\uparrow$ &  \textbf{LPIPS$\downarrow$}    &  \textbf{FID$\downarrow$}   \\
    \midrule
    DDRM      & 19.48 & 0.8154   & 0.1487  & 26.24     \\  
    IRSDE     & 21.12 & 0.8499   & 0.1046  & 11.12     \\
    GOUB      & 22.59 & \textbf{0.8573}   & 0.0917  & 8.49     \\
    \midrule
    UniDB-GOU & \textbf{23.02} & 0.8571   & \textbf{0.0884}  & \textbf{7.46}     \\ 
    \bottomrule			
  \end{tabular}
\vskip -0.1in
\end{table}



\begin{figure*}[htbp] % '!t' 
    \centering
    \includegraphics[width=\textwidth]{picture/derain.pdf}
    \caption{Additional visual results on deraining with Rain100H datasets.}
\end{figure*}
\vspace{-8mm}

\begin{figure*}[htbp] % '!t' 
    \centering
    \vspace{-8mm}
    \includegraphics[width=\textwidth]{picture/sr_ffhq.pdf}
    \caption{Additional visual results on 4$\times$super-resolution with FFHQ datasets.}
\end{figure*}




\begin{figure*}[htbp] % '!t' 
    \centering
    \includegraphics[width=\textwidth]{picture/sr_celaba.pdf}
    \caption{Additional visual results on 4$\times$super-resolution with CelebA-HQ datasets.}
\end{figure*}

\begin{figure*}[htbp] % '!t' 
    \centering
    \includegraphics[width=\textwidth]{picture/inpainting_more.pdf}
    \caption{Additional visual results on thin mask inpainting with CelebA-HQ datasets to show our excellence.}
\end{figure*}





\begin{figure*}[htbp] % '!t' 
    \centering
    \includegraphics[width=\textwidth]{picture/inpainting.pdf}
    \caption{Additional visual results on thin mask inpainting with CelebA-HQ datasets.}
\end{figure*}

\begin{figure*}[b] % '!t' 
    \centering
    \includegraphics[width=0.9 \textwidth]{picture/DIV2K-more.pdf}
    \caption{Additional visual results on 4$\times$super-resolution with DIV2K datasets.}
\end{figure*}

% \newpage

% \section{Mean-ODE Solver}
% As for the Mean-ODE model \eqref{reverse-mean-ode} introduced in GOUB \cite{yue2024imagerestorationgeneralizedornsteinuhlenbeck}: 
% \begin{equation}\label{gou_mean_ode}
% \mathrm{d} \mathbf{x}_t=\Bigg[\left(\theta_t+g_t^2 \frac{e^{-2 \bar{\theta}_{t: T}}}{\bar{\sigma}_{t: T}^2}\right)\left(\mathbf{x}_T-\mathbf{x}_t\right) - g_t^2\nabla_{\mathbf{x}_t} \log p(\mathbf{x}_t \mid \mathbf{x}_T) \Bigg] \mathrm{d} t.
% \end{equation}
% Suppose the score $\nabla_{\mathbf{x}_t} p(\mathbf{x}_t \mid x_T)$ is parameterized as $-\boldsymbol{\epsilon}_{\theta}(\mathbf{x}_t, x_T, t) / \bar{\sigma}_{t}^{\prime}$, then \eqref{gou_mean_ode} can be: 
% \begin{equation}\label{gou_mean_ode_score}
% \mathrm{d} \mathbf{x}_t=\Bigg[\left(\theta_t+g_t^2 \frac{e^{-2 \bar{\theta}_{t: T}}}{\bar{\sigma}_{t: T}^2}\right)\left(\mathbf{x}_T-\mathbf{x}_t\right) + \frac{g_t^2}{\bar{\sigma}_{t}^{\prime}}\boldsymbol{\epsilon}_{\theta}(\mathbf{x}_t, \mathbf{x}_T, t) \Bigg] \mathrm{d} t.
% \end{equation}
% Denote 
% \begin{equation}
% \begin{gathered}
% k_t = \theta_t + g_t^2 \frac{e^{-2 \bar{\theta}_{t: T}}}{\bar{\sigma}_{t: T}^2} = \theta_t + 2 \theta_t \frac{e^{-2 \bar{\theta}_{t: T}}}{1 - e^{-2 \bar{\theta}_{t: T}}}, \\
% \bar{k}_{s:t} = \int_s^t k_z dz, \quad \bar{k}_{t} = \int_0^t k_z dz, \\
% \alpha_t = e^{ \bar{\theta}_{t: T}}(1 - e^{-2 \bar{\theta}_{t: T}}), \quad \rho_t = e^{ \bar{\theta}_{t}}(1 - e^{-2 \bar{\theta}_{t}}). \\
% \end{gathered}
% \end{equation}
% Then 
% \begin{equation}
% \begin{aligned}
% \bar{k}_{s:t} &= \int_s^t \left[\theta_z + 2 \theta_z \frac{e^{-2 \bar{\theta}_{z: T}}}{1 - e^{-2 \bar{\theta}_{z: T}}} \right] dz = \bar{\theta}_{s:t} + \int_s^t 2 \theta_z \frac{e^{-2 \bar{\theta}_{z: T}}}{1 - e^{-2 \bar{\theta}_{z: T}}} dz \\
% &= \bar{\theta}_{s:t} + \Big( -\log \left( 1 - e^x\right) \Big)\Bigg|_{\bar{\theta}_{T:s}}^{\bar{\theta}_{T:s}} = \bar{\theta}_{s:t} + \log \frac{1 - e^{-2 \bar{\theta}_{s: T}}}{1 - e^{-2 \bar{\theta}_{t: T}}},
% \end{aligned}
% \end{equation}
% which implies 
% \begin{equation}
% e^{\bar{k}_{s:t}} = e^{\bar{\theta}_{s:t}} \frac{1 - e^{-2 \bar{\theta}_{s: T}}}{1 - e^{-2 \bar{\theta}_{t: T}}} = \frac{e^{\bar{\theta}_{s:T}} (1 - e^{-2 \bar{\theta}_{s: T}})}{e^{\bar{\theta}_{t:T}}(1 - e^{-2 \bar{\theta}_{t: T}})} = \frac{\alpha_s}{\alpha_t}.
% \end{equation}
% In addition, 
% \begin{equation}
% \begin{aligned}
% \bar{\sigma}_{t}^{\prime2} &= \frac{\bar{\sigma}_t^2\bar{\sigma}_{t:T}^2}{\bar{\sigma}_T^2} \\
% &= \frac{\lambda^2(1-e^{-2\bar{\theta}_{t}}) \lambda^2(1-e^{-2\bar{\theta}_{t:T}})}{\lambda^2(1-e^{-2\bar{\theta}_{T}})} \\
% &= \lambda^2 \frac{e^{\bar{\theta}_{t}}(1-e^{-2\bar{\theta}_{t}})e^{\bar{\theta}_{t:T}}(1-e^{-2\bar{\theta}_{t:T}})}{e^{\bar{\theta}_{T}}(1-e^{-2\bar{\theta}_{T}})} \\
% &= \lambda^2 \frac{\rho_t \alpha_t}{\rho_T},
% \end{aligned}
% \end{equation}

% Hence, the equation \eqref{gou_mean_ode_score} can be solved as follows: 
% \begin{align*}
% & \mathrm{d} \mathbf{x}_t=\Bigg[\left(\theta_t+g_t^2 \frac{e^{-2 \bar{\theta}_{t: T}}}{\bar{\sigma}_{t: T}^2}\right)\left(\mathbf{x}_T-\mathbf{x}_t\right) + \frac{g_t^2}{\bar{\sigma}_{t}^{\prime}}\boldsymbol{\epsilon}_{\theta}(\mathbf{x}_t, \mathbf{x}_T, t) \Bigg] \mathrm{d} t \\
% \Rightarrow \quad & \frac{\mathrm{d} \mathbf{x}_t}{\mathrm{d} t}=-k_t \mathbf{x}_t + k_t\mathbf{x}_T + \frac{g_t^2}{\bar{\sigma}_{t}^{\prime}}\boldsymbol{\epsilon}_{\theta}(\mathbf{x}_t, \mathbf{x}_T, t), \\
% \Rightarrow \quad & \frac{\mathrm{d} (e^{\bar{k}_{t}}\mathbf{x}_t)}{\mathrm{d} t}= e^{\bar{k}_{t}}k_t\mathbf{x}_T + e^{\bar{k}_{t}}\frac{g_t^2}{\bar{\sigma}_{t}^{\prime}}\boldsymbol{\epsilon}_{\theta}(\mathbf{x}_t, \mathbf{x}_T, t), \\
% \Rightarrow \quad & e^{\bar{k}_{t}}\mathbf{x}_t - e^{\bar{k}_{s}}\mathbf{x}_s = \int_{s}^{t} e^{\bar{k}_{z}}k_z\mathbf{x}_T dz + \int_{s}^{t} e^{\bar{k}_{\tau}}\frac{g_\tau^2}{\bar{\sigma}_{\tau}^{\prime}}\boldsymbol{\epsilon}_{\theta}(\mathbf{x}_\tau, \mathbf{x}_T, \tau) d\tau, \\
% \Rightarrow \quad & \mathbf{x}_t = e^{\bar{k}_{t:s}}\mathbf{x}_s + e^{-\bar{k}_{t}} (e^{\bar{k}_{t}} - e^{\bar{k}_{s}}) \mathbf{x}_T + e^{-\bar{k}_{t}} \int_{s}^{t} e^{\bar{k}_{\tau}}\frac{g_\tau^2}{\bar{\sigma}_{\tau}^{\prime}}\boldsymbol{\epsilon}_{\theta}(\mathbf{x}_\tau, \mathbf{x}_T, \tau) d\tau, \\
% \Rightarrow \quad & \mathbf{x}_t = \frac{\alpha_t}{\alpha_s}\mathbf{x}_s + \left(1 - \frac{\alpha_t}{\alpha_s}\right) \mathbf{x}_T + \int_{s}^{t} \frac{\alpha_t}{\alpha_\tau}\frac{g_\tau^2}{\bar{\sigma}_{\tau}^{\prime}}\boldsymbol{\epsilon}_{\theta}(\mathbf{x}_\tau, \mathbf{x}_T, \tau) d\tau. 
% \end{align*}
% Since $g_{t}^{2} = 2 \lambda^2 \theta_t$, we can learn that
% \begin{equation}
% \frac{g_{t}^{2}}{\bar{\sigma}_{t}^{\prime2}} = \frac{2\theta_t(1-e^{-2\bar{\theta}_{T}})}{(1-e^{-2\bar{\theta}_{t}})(1-e^{-2\bar{\theta}_{t:T}})} 
% \end{equation}
% Define $\beta_t = \ln \frac{e^{\bar{\theta}_{t:T}}(1-e^{-2\bar{\theta}_{t:T}})}{e^{\bar{\theta}_{t}}(1-e^{-2\bar{\theta}_{t}})} = \ln \frac{\alpha_t}{\rho_t}$ which implies $e^{\beta_t} = \frac{\alpha_t}{\rho_t}$, then
% \begin{equation}
% \frac{\mathrm{d} \beta_t}{\mathrm{d} t} = -\frac{2\theta_t(1-e^{-2\bar{\theta}_{T}})}{(1-e^{-2\bar{\theta}_{t}})(1-e^{-2\bar{\theta}_{t:T}})} = -\frac{g_{t}^{2}}{\bar{\sigma}_{t}^{\prime2}}
% \end{equation}
% and 
% \begin{equation}
% \frac{\bar{\sigma}_{t}^{\prime2}}{\alpha_t^2} = \frac{\lambda^2 \rho_t \alpha_t}{\alpha_t^2 \rho_T} = \frac{\lambda^2 \rho_t}{\alpha_t \rho_T} = \frac{\lambda^2}{\rho_T} e^{-\beta_t}
% \end{equation}
% Hence, 
% \begin{equation}
% \frac{\alpha_t}{\alpha_\tau}\frac{g_\tau^2}{\bar{\sigma}_{\tau}^{\prime}} = -\frac{\alpha_t}{\alpha_\tau} \frac{\mathrm{d} \beta_\tau}{\mathrm{d} \tau} \bar{\sigma}_{\tau}^{\prime} = -\frac{\lambda\alpha_t}{\sqrt{\rho_T}}e^{-\frac{1}{2}\beta_\tau} \frac{\mathrm{d} \beta_\tau}{\mathrm{d} \tau}
% \end{equation}
% and
% \begin{equation}
% \begin{aligned}
% \int_{s}^{t} \frac{\alpha_t}{\alpha_\tau}\frac{g_\tau^2}{\bar{\sigma}_{\tau}^{\prime}}\boldsymbol{\epsilon}_{\theta}(\mathbf{x}_\tau, \mathbf{x}_T, \tau) d\tau &= -\int_{s}^{t} \frac{\lambda\alpha_t}{\sqrt{\rho_T}}e^{-\frac{1}{2}\beta_\tau} \frac{\mathrm{d} \beta_\tau}{\mathrm{d} \tau}\boldsymbol{\epsilon}_{\theta}(\mathbf{x}_\tau, \mathbf{x}_T, \tau) d\tau \\
% &= -\frac{\lambda\alpha_t}{\sqrt{\rho_T}} \int_{\beta_s}^{\beta_t} e^{-\frac{1}{2}\beta} \hat{\boldsymbol{\epsilon}}_{\theta}(\mathbf{x}_\beta, \mathbf{x}_T, \beta) d\beta
% \end{aligned}
% \end{equation}
% where we further change the subscripts of $\mathbf{x}$ and from $t$ to $\beta$, as $\beta_t$ is a strictly decreasing function of $t$ so it has an inverse function $t_\beta(\cdot)$ satisfying $t = t_\beta(\beta_t)$, $\hat{\boldsymbol{\epsilon}}_\theta\left(\mathbf{x}_\beta, \beta\right):=\boldsymbol{\epsilon}_\theta\left(\mathbf{x}_{t_\beta(\beta)}, t_\beta(\beta)\right)$. 

% In conclusion, we obtain the following exact solution of Mean-ODE for GOUB,
% \begin{equation}
% \mathbf{x}_t = \frac{\alpha_t}{\alpha_s}\mathbf{x}_s + \left(1 - \frac{\alpha_t}{\alpha_s}\right) \mathbf{x}_T -\frac{\lambda\alpha_t}{\sqrt{\rho_T}} \int_{\beta_s}^{\beta_t} e^{-\frac{1}{2}\beta} \hat{\boldsymbol{\epsilon}}_{\theta}(\mathbf{x}_\beta, \mathbf{x}_T, \beta) d\beta. 
% \end{equation}

% \textbf{Mean-ODE-Solver-1.} Denote $M+1$ time steps $\left\{t_i\right\}_{i=0}^M$ decreasing from $t_0=T$ to $t_M=0$ and $h_i = \beta_{t_{i}} - \beta_{t_{i-1}}$, then
% \begin{equation}
% \mathbf{x}_{t_{i}} = \frac{\alpha_{t_{i}}}{\alpha_{t_{i-1}}}\mathbf{x}_{t_{i-1}} + \left(1 - \frac{\alpha_{t_{i}}}{\alpha_{t_{i-1}}}\right) \mathbf{x}_T - 2 \frac{\lambda\alpha_{t_{i}}}{\sqrt{\rho_T}} (e^{-\frac{1}{2}\beta_{t_{i-1}}} - e^{-\frac{1}{2}\beta_{t_{i}}}) \boldsymbol{\epsilon}_{\theta}(\mathbf{x}_{t_{i-1}}, \mathbf{x}_T, t_{i-1}). 
% \end{equation}

% \textbf{Mean-ODE-Solver-2.} Denote $M+1$ time steps $\left\{t_i\right\}_{i=0}^M$ decreasing from $t_0=T$ to $t_M=0$ and $h_i = \beta_{t_{i}} - \beta_{t_{i-1}}$, then
% \begin{equation}
% \mathbf{x}_{t_{i}} = \frac{\alpha_{t_{i}}}{\alpha_{t_{i-1}}}\mathbf{x}_{t_{i-1}} + \left(1 - \frac{\alpha_{t_{i}}}{\alpha_{t_{i-1}}}\right) \mathbf{x}_T - 2 \frac{\lambda\alpha_{t_{i}}}{\sqrt{\rho_T}} \int_{\beta_{t_{i-1}}}^{\beta_{t_{i}}} e^{-\frac{1}{2}\beta} [\hat{\boldsymbol{\epsilon}}_{\theta}(\mathbf{x}_\beta, \mathbf{x}_T, \beta) + (\beta - \beta_{t_{i-1}}) \hat{\boldsymbol{\epsilon}}^{(1)}_{\theta}(\mathbf{x}_\beta, \mathbf{x}_T, \beta)] d\beta. 
% \end{equation}

% Define $\bar{\beta} = \frac{\beta_{t_{i}} + \beta_{t_{i-1}}}{2}$ and Calculate $\int_{\beta_{t_{i-1}}}^{\beta_{t_{i}}} e^{-\frac{1}{2}\beta} (\beta - \beta_{t_{i-1}}) \hat{\boldsymbol{\epsilon}}^{(1)}_{\theta}(\mathbf{x}_\beta, \mathbf{x}_T, \beta) d\beta$: 
% \begin{equation}
% \begin{aligned}
% \hat{\boldsymbol{\epsilon}}^{(1)}_{\theta}(\mathbf{x}_\beta, \mathbf{x}_T, \beta) &\approx \hat{\boldsymbol{\epsilon}}^{(1)}_{\theta}(\mathbf{x}_{\beta_{t_{i-1}}}, \mathbf{x}_T, \beta_{t_{i-1}}) \\
% &\approx \frac{\hat{\boldsymbol{\epsilon}}_{\theta}(\mathbf{x}_{\bar{\beta}}, \mathbf{x}_T, \bar{\beta}) - \hat{\boldsymbol{\epsilon}}_{\theta}(\mathbf{x}_{\beta_{t_{i-1}}}, \mathbf{x}_T, \beta_{t_{i-1}})}{\bar{\beta} - \beta_{t_{i-1}}} \\
% &= \frac{\hat{\boldsymbol{\epsilon}}_{\theta}(\mathbf{x}_{\bar{\beta}}, \mathbf{x}_T, \bar{\beta}) - \hat{\boldsymbol{\epsilon}}_{\theta}(\mathbf{x}_{\beta_{t_{i-1}}}, \mathbf{x}_T, \beta_{t_{i-1}})}{\frac{1}{2} h_i} \\
% \end{aligned}
% \end{equation}

% \begin{equation}
% \begin{aligned}
% \int_{\beta_{t_{i-1}}}^{\beta_{t_{i}}} e^{-\frac{1}{2}\beta} (\beta - \beta_{t_{i-1}}) d\beta &= 4 e^{-\frac{1}{2}\beta_{t_{i-1}}} \int_{0}^{h_i} e^{-\frac{1}{2}x} x dx \\
% &= 4 e^{-\frac{1}{2}\beta_{t_{i-1}}} \left[ e^{-\frac{1}{2}h_i} (-\frac{1}{2}h_i - 1) + 1 \right] \\
% &= 4 e^{-\frac{1}{2}\beta_{t_{i}}} \left[ e^{\frac{1}{2}h_i} -\frac{1}{2}h_i - 1 \right] \\
% &\approx 4 e^{-\frac{1}{2}\beta_{t_{i}}} ( e^{\frac{1}{2}h_i} - 1 ) \frac{h_i}{4} \\
% &= e^{-\frac{1}{2}\beta_{t_{i}}} ( e^{\frac{1}{2}h_i} - 1 ) h_i \\
% &= e^{-\frac{1}{2}\beta_{t_{i-1}}} - e^{-\frac{1}{2}\beta_{t_{i}}}
% \end{aligned}
% \end{equation}
% with the fact that $e^{\frac{1}{2}h_i} -\frac{1}{2}h_i - 1 \approx (e^{\frac{1}{2}h_i} - 1) \frac{h_i}{4}$.

% Then, 
% \begin{equation}
% \mathbf{x}_{t_{i}} = \frac{\alpha_{t_{i}}}{\alpha_{t_{i-1}}}\mathbf{x}_{t_{i-1}} + \left(1 - \frac{\alpha_{t_{i}}}{\alpha_{t_{i-1}}}\right) \mathbf{x}_T - 2 \frac{\lambda\alpha_{t_{i}}}{\sqrt{\rho_T}} (e^{-\frac{1}{2}\beta_{t_{i-1}}} - e^{-\frac{1}{2}\beta_{t_{i}}}) \hat{\boldsymbol{\epsilon}}_{\theta}(\mathbf{x}_{\bar{\beta}}, \mathbf{x}_T, \bar{\beta}).
% \end{equation}

% Also, we can have a pseudocode for describing the Mean-ODE-Solver-1 and Mean-ODE-Solver-2: 
% \begin{algorithm}[htbp]
%    \caption{Mean-ODE-Solver-1 Sampling}
%    \label{ode_solver_sampling}
% \begin{algorithmic}
%     \STATE {\bfseries Input:} LQ images $\mathbf{x}_T$ and $M+1$ time steps $\left\{t_i\right\}_{i=0}^M$ decreasing from $t_0=T$ to $t_M=0$.
%     \FOR{$i=1$ {\bfseries to} $M$}
%         \STATE $\mathbf{x}_{t_{i}} = \frac{\alpha_{t_{i}}}{\alpha_{t_{i-1}}}\mathbf{x}_{t_{i-1}} + \left(1 - \frac{\alpha_{t_{i}}}{\alpha_{t_{i-1}}}\right)\mathbf{x}_T - 2 \frac{\lambda\alpha_{t_{i}}}{\sqrt{\rho_T}} (e^{-\frac{1}{2}\beta_{t_{i-1}}} - e^{-\frac{1}{2}\beta_{t_{i}}}) \boldsymbol{\epsilon}_{\theta}(\mathbf{x}_{t_{i-1}}, \mathbf{x}_T, t_{i-1}) $
%    \ENDFOR
%    \STATE \textbf{Return} HQ images $\mathbf{x}_0$
% \end{algorithmic}
% \end{algorithm}

% \begin{algorithm}[htbp]
%    \caption{Mean-ODE-Solver-2 Sampling}
%    \label{ode_solver_2_sampling}
% \begin{algorithmic}
%     \STATE {\bfseries Input:} LQ images $\mathbf{x}_T$ and $M+1$ time steps $\left\{t_i\right\}_{i=0}^M$ decreasing from $t_0=T$ to $t_M=0$.
%     \FOR{$i=1$ {\bfseries to} $M$}
%         \STATE $s_i = t_{\beta} (\frac{\beta_{t_{i-1}} + \beta_{t_{i}}}{2})$
%         \STATE $\mathbf{y}_i = \frac{\alpha_{s_{i}}}{\alpha_{t_{i-1}}}\mathbf{x}_{t_{i-1}} + \left(1 - \frac{\alpha_{s_{i}}}{\alpha_{t_{i-1}}}\right) \mathbf{x}_T - 2 \frac{\lambda\alpha_{s_{i}}}{\sqrt{\rho_T}} (e^{-\frac{1}{2}\beta_{t_{i-1}}} - e^{-\frac{1}{2}\beta_{s_{i}}}) \boldsymbol{\epsilon}_{\theta}(\mathbf{x}_{t_{i-1}}, \mathbf{x}_T, t_{i-1})$
%         \STATE $\mathbf{x}_{t_{i}} = \frac{\alpha_{t_{i}}}{\alpha_{t_{i-1}}}\mathbf{x}_{t_{i-1}} + \left(1 - \frac{\alpha_{t_{i}}}{\alpha_{t_{i-1}}}\right) \mathbf{x}_T - 2 \frac{\lambda\alpha_{t_{i}}}{\sqrt{\rho_T}} (e^{-\frac{1}{2}\beta_{t_{i-1}}} - e^{-\frac{1}{2}\beta_{t_{i}}}) \hat{\boldsymbol{\epsilon}}_{\theta}(\mathbf{y}_i, \mathbf{x}_T, s_i). $
%    \ENDFOR
%    \STATE \textbf{Return} HQ images $\mathbf{x}_0$
% \end{algorithmic}
% \end{algorithm}

% % \begin{table}[H]
    
% %   \centering
% %   \caption{Qualitative comparison with the corresponding Euler and Mean-ODE Solver.}
% %   \label{table_ode_solver}
% %   \vskip 0.05in
% %   \begin{tabular}{lcccccccccccc}
% %     \toprule
% %     \textbf{METHOD} & \textbf{PSNR}$\uparrow$ & \textbf{SSIM}$\uparrow$ &  \textbf{LPIPS$\downarrow$}    &  \textbf{FID$\downarrow$} & \textbf{PSNR}$\uparrow$ & \textbf{SSIM}$\uparrow$ &  \textbf{LPIPS$\downarrow$}    &  \textbf{FID$\downarrow$} & \textbf{PSNR}$\uparrow$ & \textbf{SSIM}$\uparrow$ &  \textbf{LPIPS$\downarrow$}    &  \textbf{FID$\downarrow$}   \\
% %     \midrule
% %     Euler               & 19.48 & 0.8154   & 0.1487  & 26.24  & 19.48 & 0.8154   & 0.1487  & 26.24 & 19.48 & 0.8154   & 0.1487  & 26.24   \\  
% %     Mean-ODE Solver     & 21.12 & 0.8499   & 0.1046  & 11.12  & 19.48 & 0.8154   & 0.1487  & 26.24 & 19.48 & 0.8154   & 0.1487  & 26.24   \\
% %     \bottomrule			
% %   \end{tabular}
% % \vskip -0.1in
% % \end{table}


% \begin{table*}[htbp]
%   \centering
%   \caption{Qualitative comparison with the corresponding Euler and Mean-ODE-Solver-1 with $n$ steps which describes the number of the sampling steps on DIV2K and Rain100H datasets.}
%   \vskip 0.1in
%   \label{table_ode_solver_1}
%   \resizebox{0.98\textwidth}{!}{
%   \begin{tabular}{ccccccccccccc}
%     \toprule
%     \multirow{2}*{\textbf{METHOD}} & \multicolumn{4}{c}{\textbf{Image 4$\times$ Super-Resolution}} & \multicolumn{4}{c}{\textbf{Image Deraining}} & \multicolumn{4}{c}{\textbf{Image Inpainting}} \\
%     \cmidrule(r){2-5} \cmidrule(r){6-9} \cmidrule(r){10-13}
%       & \textbf{PSNR}$\uparrow$ & \textbf{SSIM}$\uparrow$ & \textbf{LPIPS}$\downarrow$ & \textbf{FID}$\downarrow$ & \textbf{PSNR}$\uparrow$ & \textbf{SSIM}$\uparrow$ & \textbf{LPIPS}$\downarrow$ & \textbf{FID}$\downarrow$ & \textbf{PSNR}$\uparrow$ & \textbf{SSIM}$\uparrow$ & \textbf{LPIPS}$\downarrow$ & \textbf{FID}$\downarrow$ \\
%     \midrule
%     Euler (100 steps) & 28.50 & 0.8070 & 0.328 & 22.14 & \textbf{34.56} & \textbf{0.9414} & \textbf{0.077} & \textbf{32.83} & \textbf{31.39} & \textbf{0.9392} & \textbf{0.052} & 12.24   \\        
%     Mean-ODE-Solver-1 (10 steps) & \textbf{28.52} & \textbf{0.8072} & \textbf{0.326} & \textbf{21.96} & 34.25 & 0.9403 & 0.079 & 34.54 & 29.76 & 0.9346 & 0.056 & 13.14 \\
%     Mean-ODE-Solver-1 (20 steps) & 28.51 & 0.8071 & 0.327 & 22.02 & 34.24 & 0.9401 & 0.080 & 34.69 & 30.75 & 0.9359 & 0.053 & 12.10 \\ 
%     Mean-ODE-Solver-1 (25 steps) & 28.51 & 0.8071 & 0.327 & 22.01 & 34.24 & 0.9400 & 0.080 & 34.66 & 30.77 & 0.9359 & \textbf{0.052} & 12.08 \\
%     Mean-ODE-Solver-1 (50 steps) & 28.50 & 0.8071 & 0.327 & 22.04 & 34.23 & 0.9401 & 0.080 & 34.68 & 30.86 & 0.9359 & \textbf{0.052} & 12.00 \\
%     Mean-ODE-Solver-1 (100 steps) & 28.50 & 0.8070 & 0.327 & 22.07 & 34.22 & 0.9400 & 0.080 & 34.70 & 30.88 & 0.9359 & \textbf{0.052} & \textbf{11.97} \\
%     % \toprule
%     % DDBMs (VP) & 22.11 & 0.4059 & 0.491 & 48.09 & 29.58 & 0.828 & 0.113 & 35.46 \\
%     % UniDB-VP & \textbf{22.42} & \textbf{0.4097} & \textbf{0.486} & \textbf{44.52} & \textbf{30.11} & \textbf{0.8414} & \textbf{0.102} & \textbf{33.17} \\
%     \bottomrule          
%   \end{tabular}
%   }
%   \vskip -0.1in
% \end{table*}

% \begin{table*}[htbp]
%   \centering
%   \caption{Qualitative comparison with the corresponding Euler and Mean-ODE-Solver-2 with $n$ steps which describes the number of the sampling steps on DIV2K and Rain100H datasets.}
%   \vskip 0.1in
%   \label{table_ode_solver_2}
%   \resizebox{0.98\textwidth}{!}{
%   \begin{tabular}{ccccccccccccc}
%     \toprule
%     \multirow{2}*{\textbf{METHOD}} & \multicolumn{4}{c}{\textbf{Image 4$\times$ Super-Resolution}} & \multicolumn{4}{c}{\textbf{Image Deraining}} & \multicolumn{4}{c}{\textbf{Image Inpainting}} \\
%     \cmidrule(r){2-5} \cmidrule(r){6-9} \cmidrule(r){10-13}
%       & \textbf{PSNR}$\uparrow$ & \textbf{SSIM}$\uparrow$ & \textbf{LPIPS}$\downarrow$ & \textbf{FID}$\downarrow$ & \textbf{PSNR}$\uparrow$ & \textbf{SSIM}$\uparrow$ & \textbf{LPIPS}$\downarrow$ & \textbf{FID}$\downarrow$ & \textbf{PSNR}$\uparrow$ & \textbf{SSIM}$\uparrow$ & \textbf{LPIPS}$\downarrow$ & \textbf{FID}$\downarrow$ \\
%     \midrule
%     Euler (100 steps) & 28.50 & 0.8070 & 0.328 & 22.14 & \textbf{34.56} & \textbf{0.9414} & \textbf{0.077} & \textbf{32.83} & \textbf{31.39} & \textbf{0.9392} & \textbf{0.052} & 12.24   \\        
%     Mean-ODE-Solver-1 (10 steps) & \textbf{28.52} & \textbf{0.8072} & \textbf{0.326} & \textbf{21.96} & 34.25 & 0.9403 & 0.079 & 34.54 & 29.76 & 0.9346 & 0.056 & 13.14 \\
%     Mean-ODE-Solver-1 (20 steps) & 28.51 & 0.8071 & 0.327 & 22.02 & 34.24 & 0.9401 & 0.080 & 34.69 & 30.75 & 0.9359 & 0.053 & 12.10 \\ 
%     Mean-ODE-Solver-1 (25 steps) & 28.51 & 0.8071 & 0.327 & 22.01 & 34.24 & 0.9400 & 0.080 & 34.66 & 30.77 & 0.9359 & \textbf{0.052} & 12.08 \\
%     Mean-ODE-Solver-1 (50 steps) & 28.50 & 0.8071 & 0.327 & 22.04 & 34.23 & 0.9401 & 0.080 & 34.68 & 30.86 & 0.9359 & \textbf{0.052} & 12.00 \\
%     Mean-ODE-Solver-1 (100 steps) & 28.50 & 0.8070 & 0.327 & 22.07 & 34.22 & 0.9400 & 0.080 & 34.70 & 30.88 & 0.9359 & \textbf{0.052} & \textbf{11.97} \\
%     % \toprule
%     % DDBMs (VP) & 22.11 & 0.4059 & 0.491 & 48.09 & 29.58 & 0.828 & 0.113 & 35.46 \\
%     % UniDB-VP & \textbf{22.42} & \textbf{0.4097} & \textbf{0.486} & \textbf{44.52} & \textbf{30.11} & \textbf{0.8414} & \textbf{0.102} & \textbf{33.17} \\
%     \bottomrule          
%   \end{tabular}
%   }
%   \vskip -0.1in
% \end{table*}
