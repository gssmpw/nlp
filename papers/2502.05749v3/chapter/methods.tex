\section{Methods}
\subsection{Diffusion Bridges Constructed by SOC Problem}
The forward SDE of the Diffusion Bridge with Doob’s $h$-transform is enforced to pass from the predetermined origin $x_0$ to the terminal $x_T$. With a similar purpose, UniDB constructs a SOC problem where the constraints are an arbitrary linear SDE of the forward diffusion with a given initial state, while the objective incorporates a penalty term steering the forward diffusion trajectory towards the predetermined terminal $x_T$. Meanwhile, compared with the linear drift term \eqref{linear_form}, we combined a given state vector term $\mathbf{m}$ with the same dimension as $\mathbf{x}_t$ and its related coefficient $h_t$ to improve the generality of the linear SDE form: 
\begin{equation}\label{generalized_linear_SDE}
\mathbf{f}(\mathbf{x}_t, t) = f_t \mathbf{x}_t + h_t \mathbf{m}.
\end{equation}

Accordingly, our SOC problem with unified linear SDE \eqref{generalized_linear_SDE} is formed as: 
\begin{equation}\label{SOC_problem_generalized_sde}
\begin{aligned}
&\min_{\mathbf{u}_{t, \gamma}\in \mathcal{U} } \int_{0}^{T} \frac{1}{2} \|\mathbf{u}_{t, \gamma}\|_2^2 dt + \frac{\gamma}{2} \| \mathbf{x}_T^{u} - x_T\|_2^2 \\
\text{s.t.} \mathrm{d} \mathbf{x}_t &= \Big( f_t \mathbf{x}_t + h_t \mathbf{m} + g_t \mathbf{u}_{t, \gamma} \Big) \mathrm{d} t + g_t \mathrm{d} \mathbf{w}_t, \mathbf{x}_0^u = x_0.
\end{aligned}
\end{equation}

% paper
According to the certainty equivalence principle \cite{chen2024generativemodelingphasestochastic, RB}, the addition of noise or perturbations to a linear system with quadratic costs does not change the optimal control. Therefore, we can modify the SOC problem with the deterministic ODE condition to obtain the optimal controller $\mathbf{u}_{t, \gamma}^{*}$ as follows, 
\begin{equation}\label{SOC_problem_generalized_ode}
\begin{gathered}
\min_{\mathbf{u}_{t, \gamma}\in \mathcal{U} } \int_0^T \frac{1}{2} \left\|\mathbf{u}_{t, \gamma}\right\|_2^2 d t+\frac{\gamma}{2}\left\|\mathbf{x}_T^{u}-x_T\right\|_2^2 \\
\text{s.t.} \ \mathrm{d} \mathbf{x}_t = \Big( f_t \mathbf{x}_t + h_t \mathbf{m} + g_t \mathbf{u}_{t, \gamma} \Big) \mathrm{d} t, \ \mathbf{x}_0^u=x_0.
\end{gathered}
\end{equation}
We can derive the closed-form solution to the problem \eqref{SOC_problem_generalized_ode}, which leads to the following Theorem \ref{theorem_4.1}: 
\begin{theorem}\label{theorem_4.1} 
\textit{Consider the SOC problem \eqref{SOC_problem_generalized_ode}, denote $d_{t, \gamma} = \gamma^{-1} + e^{2\bar{f}_{T}} \bar{g}^2_{t:T}$, $\bar{f}_{s:t} = \int_{s}^{t} f_z dz$, $\bar{h}_{s:t} = \int_{s}^{t} e^{-\bar{f}_{z}} h_z dz$ and $\bar{g}^2_{s:t} = \int_{s}^{t} e^{-2\bar{f}_{z}}g^2_z dz$, denote $\bar{f}_{t}$, $\bar{h}_{t}$ and $\bar{g}^2_{t}$ for simplification when $s=0$, then the closed-form optimal controller $\mathbf{u}_{t,\gamma}^{*}$ is} 
\begin{equation}\label{general_optimal_controller}
\mathbf{u}_{t, \gamma}^{*} = g_t e^{\bar{f}_{t:T}} \frac{x_{T} - e^{\bar{f}_{t:T}} \mathbf{x}_t - \mathbf{m} e^{\bar{f}_{T}} \bar{h}_{t:T}}{d_{t, \gamma}},
\end{equation}
\textit{and the transition of $\mathbf{x}_t$ from $x_0$ and $x_T$ is}
\begin{equation}\label{general_interpolant}
\mathbf{x}_t = e^{\bar{f}_{t}} \Bigg(\frac{d_{t, \gamma}}{d_{0, \gamma}} x_0 + \frac{e^{\bar{f}_{T}} \bar{g}^2_{t}}{d_{0, \gamma}} x_T + \Big(\bar{h}_{t} - \frac{e^{2\bar{f}_{T}} \bar{h}_{T} \bar{g}^2_{t}}{d_{0, \gamma}}\Big) \mathbf{m}\Bigg). 
\end{equation}
\end{theorem}
The proof of Theorem \ref{theorem_4.1} is provided in Appendix \ref{proof_theorem_4.1}. With Theorem \ref{theorem_4.1}, we can obtain an optimally controlled forward SDE connected from $x_0$ to the neighborhood of the terminal $x_T$ and the transition of $\mathbf{x}_t$ for the forward process. As for the backward process, similar to \eqref{reverse-bridge-sde} and \eqref{reverse-mean-ode}, the backward reverse SDE and Mean-ODE are respectively formulated as: 
\begin{equation}\label{ours_reverse_sde}
\mathrm{d} \mathbf{x}_t = \Big[f_t \mathbf{x}_t + h_t \mathbf{m} + g_t  \mathbf{u}_{t, \gamma}^{*} - g^2_t \nabla_{\mathbf{x}_t} p(\mathbf{x}_t | x_T) \Big] \mathrm{d} t+ g_t \mathrm{d} \tilde{\mathbf{w}}_t,
\end{equation}
\begin{equation}\label{ours_reverse_ode}
\mathrm{d} \mathbf{x}_t = \Big[f_t \mathbf{x}_t + h_t \mathbf{m} + g_t  \mathbf{u}_{t, \gamma}^{*} - g^2_t \nabla_{\mathbf{x}_t} p(\mathbf{x}_t \mid x_T) \Big] \mathrm{d}t.
\end{equation}


\subsection{Connections between SOC and Doob's $h$-transform}
We can intuitively see from the SOC problem that when $\gamma \to \infty$ in Theorem \ref{theorem_4.1}, it means that the target of SDE process is precisely the predetermined endpoint \cite{chen2024generativemodelingphasestochastic}, which is also the purpose of Doob's $h$-transform and facilitates the following theorem:
\begin{theorem}\label{theorem_4.2} 
\textit{For the SOC problem \eqref{SOC_problem_generalized_ode}, when $\gamma \to \infty$, the optimal controller becomes $\mathbf{u}^{*}_{t, \infty} = g_t \nabla_{\mathbf{x}_t} \log p(\mathbf{x}_T \mid \mathbf{x}_t)$, and the corresponding forward and backward SDE with the linear SDE form \eqref{generalized_linear_SDE} are the same as Doob's $h$-transform as in \eqref{doob} and \eqref{reverse-bridge-sde}. 
}
\end{theorem}
The proof of Theorem \ref{theorem_4.2} is presented in Appendix \ref{proof_theorem_4.2}. This theorem shows that existing diffusion bridge models using Doob's $h$-transform are merely special instances of our UniDB framework, which offers a unified approach to diffusion bridges through the lens of SOC.

Furthermore, using Doob's $h$-transform in diffusion bridge models is not necessarily optimal, as letting the terminal penalty coefficient $\gamma \to \infty$ eliminates the consideration of control costs in SOC. To support this argument, we present Proposition \ref{proposition_4.3}, which asserts that the diffusion bridge with Doob's $h$-transform is not the most effective choice. 

\begin{proposition}\label{proposition_4.3} 
\textit{Consider the SOC problem \eqref{SOC_problem_generalized_ode}, denote $\mathcal{J}(\mathbf{u}_{t, \gamma}, \gamma) \triangleq \int_0^T \frac{1}{2} \left\|\mathbf{u}_{t, \gamma}\right\|_2^2 d t+\frac{\gamma}{2}\left\|\mathbf{x}_T^{u}-x_T\right\|_2^2$ as the overall cost of the system, $\mathbf{u}_{t, \gamma}^{*}$ as the optimal controller \eqref{general_optimal_controller}, then}
\begin{equation}
\mathcal{J}(\mathbf{u}_{t, \gamma}^{*}, \gamma) \le \mathcal{J}(\mathbf{u}_{t, \infty}^{*}, \infty).
\end{equation}
\end{proposition}
Detailed proof of Proposition \ref{proposition_4.3} is provided in Appendix \ref{proof_proposition_4.3}. Proposition \ref{proposition_4.3} shows that the overall cost when considering a finite $\gamma$ is more favorable than when $\gamma \rightarrow \infty$. Existing diffusion bridge models \cite{zhou2023denoisingdiffusionbridgemodels, yue2024imagerestorationgeneralizedornsteinuhlenbeck}, which inherently assume $\gamma \rightarrow \infty$, often result in suboptimal performance with blurred or overly smoothed image details. Therefore, maintaining the penalty coefficient $\gamma$ as a hyper-parameter is a more effective approach.  

\subsection{Training objective of UniDB}
In this section, we focus on constructing the training objective of UniDB. According to maximum log-likelihood \cite{ho2020denoisingdiffusionprobabilisticmodels} and conditional score matching \cite{song2021scorebasedgenerativemodelingstochastic}, the training objective is based on the forward transition $p(\mathbf{x}_t\mid\mathbf{x}_0,\mathbf{x}_T)$. Thus, we begin by deriving this probability. The closed-form expression in \eqref{general_interpolant} represents the mean value of the forward transition after applying reparameterization techniques. However, this expression lacks a noise component after the transformation based on the certainty equivalence principle. To address this issue, we employ stochastic interpolant theory \cite{albergo2023stochasticinterpolantsunifyingframework} to introduce a noise term $\bar{\sigma}_t^{\prime}\epsilon$ with $\bar{\sigma}_0^{\prime} = \bar{\sigma}_T^{\prime} = 0$. We define $\bar{\sigma}_t^{\prime2} = \bar{\sigma}_t^2\bar{\sigma}_{t:T}^2 / \bar{\sigma}_T^2$ similar to \eqref{gou_transition}, leading to the following forward transition: 
\begin{equation}\label{mu_gamma_prime}
\begin{gathered}
p(\mathbf{x}_t\mid x_0, x_T)=\mathcal{N}(\bar{\boldsymbol{\mu}}_{t, \gamma},\bar{\sigma}_t^{\prime2}\mathbf{I}), \\
\bar{\boldsymbol{\mu}}_{t, \gamma} = e^{\bar{f}_{t}} \Big(\frac{d_{t, \gamma}}{d_{0, \gamma}} x_0 + \frac{e^{\bar{f}_{T}} \bar{g}^2_{t}}{d_{0, \gamma}} x_T + \big(\bar{h}_{t} - \frac{e^{2\bar{f}_{T}} \bar{h}_{T} \bar{g}^2_{t}}{d_{0, \gamma}}\big) \mathbf{m}\Big), \\
\bar{\sigma}_{s:t}^2 = e^{2\bar{f}_t} \bar{g}^2_{s:t}, \quad \quad \bar{\sigma}_t^{\prime2}=\frac{\bar{\sigma}_t^2\bar{\sigma}_{t:T}^2}{\bar{\sigma}_T^2}.
\end{gathered}
\end{equation}
The derailed derivation is provided in Appendix \ref{proof_derivation_transition_prob}. 
Similar to \cite{yue2024imagerestorationgeneralizedornsteinuhlenbeck} using the $l_1$ loss form to bring improved visual quality and details at the pixel level \cite{boyd2004convex, hastie2009elements}, we can derive the training objective. Denote $a_{t, \gamma} = e^{\bar{f}_{t}}d_{t, \gamma}$, assuming $\boldsymbol{\mu}_{t-1, \theta}$, $\sigma_{t-1, \theta}^2$ and $\boldsymbol{\mu}_{t-1, \gamma}$, $\sigma_{t-1, \gamma}^2$ are respectively the mean values and variances of $p_{\theta} (\mathbf{x}_{t-1} \mid \mathbf{x}_t, x_T)$ and $p (\mathbf{x}_{t-1} \mid \mathbf{x}_0, \mathbf{x}_t, x_T)$, suppose the score $\nabla_{\mathbf{x}_t} p(\mathbf{x}_t \mid x_T)$ is parameterized as $-\boldsymbol{\epsilon}_{\theta}(\mathbf{x}_t, x_T, t) / \bar{\sigma}_{t}^{\prime}$, the final training objective is as follows, 
\begin{equation}\label{objective_function}
\begin{gathered}
\mathcal{L}_{\theta} = \mathbb{E}_{t, \mathbf{x}_0, \mathbf{x}_t, \mathbf{x}_T} \left[ \frac{1}{2\sigma_{t-1, \theta}^2} \big \| \boldsymbol{\mu}_{t-1, \theta} - \boldsymbol{\mu}_{t-1, \gamma} \big \|_1 \right], \\
\boldsymbol{\mu}_{t-1, \theta} = \mathbf{x}_{t} - f_t \mathbf{x}_t - h_t \mathbf{m} - g_t \mathbf{u}_{t, \gamma}^{*} + \frac{g^2_t}{\bar{\sigma}_{t}^{\prime}} \boldsymbol{\epsilon}_{\theta}(\mathbf{x}_t, x_T, t), \\
\boldsymbol{\mu}_{t-1, \gamma} = \bar{\boldsymbol{\mu}}_{t-1, \gamma} + \frac{\bar{\sigma}_{t-1}^{\prime2}a_{t, \gamma}}{\bar{\sigma}_{t}^{\prime2}a_{t-1, \gamma} } (\mathbf{x}_t - \bar{\boldsymbol{\mu}}_{t, \gamma}),\ \sigma_{t-1, \theta} = g_t.
\end{gathered}
\end{equation}

Please refer to Appendix \ref{proof_proposition_4.5} for detailed derivations. Therefore, we can recover or generate the origin image $\hat{x}_0$ through Euler sampling iterations. So far, we've built the UniDB framework, which establishes and expands the forward and backward process of the diffusion bridge model through SOC and comprises Doob's $h$-transform as a special case. 


\subsection{UniDB unifies diffusion bridge models}
Our UniDB is a unified framework for existing diffusion bridge models: DDBMs (VE) \cite{zhou2023denoisingdiffusionbridgemodels}, DDBMs (VP) \cite{zhou2023denoisingdiffusionbridgemodels} and GOUB \cite{yue2024imagerestorationgeneralizedornsteinuhlenbeck}.  
\begin{proposition}\label{proposition_4.4} UniDB encompasses existing diffusion bridge models by employing different hyper-parameter spaces $\mathcal{H}$ as follows:
\begin{itemize}


\item DDBMs (VE) corresponds to UniDB with hyper-parameter $\mathcal{H}_\text{VE}(f_t=0, h_t=0, \gamma \rightarrow \infty)$


\item DDBMs (VP) corresponds to UniDB with hyper-parameter $\mathcal{H}_\text{VP}(f_t=-\frac{1}{2} g^2_t, h_t=0, \gamma \rightarrow \infty)$


\item GOUB corresponds to UniDB with hyper-parameter $\mathcal{H}_\text{GOU}(f_t=\theta_t, h_t=-\theta_t, \mathbf{m} = \boldsymbol{\mu}, \gamma \rightarrow \infty)$
\end{itemize}
\end{proposition}


Details of the proposition \ref{proposition_4.4} are provided in Appendix \ref{proof_proposition_4.4}. 

\subsection{An Example: UniDB-GOU}\label{example}
It is evident that these diffusion bridge models like DDBMs (VE), DDBMs (VP) and GOUB all based on Doob's $h$-transform are all special cases of UniDB with $\gamma \rightarrow \infty$. However, according to Proposition \ref{proposition_4.3}, these models are not the effective choices. Therefore, we introduce UniDB based on the GOU process \eqref{gou_process}, hereafter referred to as UniDB-GOU, which retains the penalty coefficient $\gamma$ as the hyper-parameter. Considering the SOC problem with GOU process \eqref{gou_process}, the optimally controlled forward SDE is:
\begin{equation}\label{20}
\mathrm{d} \mathbf{x}_t = \left( \theta_t + g^2_t \frac{e^{-2\bar{\theta}_{t:T}}}{\gamma^{-1} + \bar{\sigma}^2_{t:T}}\right) (x_T - \mathbf{x}_t) \mathrm{d} t + g_t \mathrm{d} \mathbf{w}_t,
\end{equation}
and the mean value of forward transition $p(\mathbf{x}_t \mid x_0, x_T)$ is
\begin{equation}\label{21}
\bar{\boldsymbol{\mu}}_{t, \gamma} = e^{-\bar{\theta}_{t}} \frac{1 + \gamma \bar{\sigma}^2_{t:T}}{1 + \gamma \bar{\sigma}^2_{T}} x_0 + \left(1 - e^{-\bar{\theta}_{t}} \frac{1 + \gamma \bar{\sigma}^2_{t:T}}{1 + \gamma \bar{\sigma}^2_{T}}\right) x_T.
\end{equation}

Please refer to Appendix \ref{proof_derivation_UniDB-GOU} for detailed proof. 

\textbf{Remark 1.} It’s worth noting that our UniDB model can be a plugin module to the existing diffusion bridge with Doob's $h$-transform. Taking UniDB-GOU as an example, we highlight the key difference between UniDB-GOU and GOUB (the coefficient of $x_0$ in the mean value of forward transition and $h$-function term) as follows:


\begin{equation}
\begin{aligned}
\textcolor{gray} {e^{-\bar{\theta}_{t}} \frac{\bar{\sigma}^2_{t:T}}{\bar{\sigma}^2_{T}}} & \Rightarrow e^{-\bar{\theta}_{t}} \frac{\gamma^{-1} + \bar{\sigma}^2_{t:T}}{\gamma^{-1} + \bar{\sigma}^2_{T}} \\
\underbrace{\textcolor{gray} {g_t\mathbf{h} = \frac{g_t e^{-2\bar{\theta}_{t:T}}(x_T - \mathbf{x}_t)}{\bar{\sigma}^2_{t:T}}}}_{\text{GOUB}} & \Rightarrow \underbrace{ \mathbf{u}_{t, \gamma}^{*} = \frac{g_t e^{-2\bar{\theta}_{t:T}}(x_T - \mathbf{x}_t)}{\gamma^{-1} + \bar{\sigma}^2_{t:T}}}_{\text{UniDB-GOU}}
\end{aligned}
\end{equation}


Hence, only a few lines of code need to be adjusted to generate more realistic images using the same training method. Appendix \ref{append_pseudo} provides pseudo-code for the training and sampling process of UniDB-GOU. Beyond the GOUB model, our UniDB framework can be similarly extended to other diffusion bridge models, such as DDBMs (VE) and DDBMs (VP). For detailed information on UniDB-VE and UniDB-VP, please refer to Appendix \ref{ve_vp_example}. 

Building upon equations \eqref{20} and \eqref{21}, we further present a proposition to characterize how the penalty coefficient $\gamma$ affects the controlled terminal distribution as follows: 
\begin{proposition}\label{proposition_4.5}
\textit{Denote the initial state distribution $x_0$, the terminal distribution $\mathbf{x}_T^u$ by the controller and the pre-defined terminal distribution $x_T$, then}
\begin{equation}\label{terminal_distance}
    \| \mathbf{x}_T^u - x_T \|^2_2 = \frac{e^{-2\bar{\theta}_{T}}}{\left( 1 + \gamma \lambda^2 (1 - e^{-2\bar{\theta}_{T}}) \right)^2} \| x_T - x_0 \|^2_2.
\end{equation}
\end{proposition}


The detailed derivations of proposition \ref{proposition_4.5} are provided in Appendix \ref{proof_proposition_4.5}. Notably, as $\gamma$ approaches infinity, the control terminal converges to the predefined endpoint. However, as analyzed in Proposition \ref{proposition_4.3}, this can result in suboptimal outcomes with blurry or overly smoothed image details. To address this, it is crucial to balance the control cost and terminal term by selecting the value of $\gamma$. In the following section, we will present comprehensive experiments to evaluate the impact of different $\gamma$ values on the results. 