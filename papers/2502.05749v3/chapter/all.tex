
\begin{abstract}
Recent advances in diffusion bridge models leverage Doob’s $h$-transform to establish fixed endpoints between distributions, demonstrating promising results in image translation and restoration tasks. However, these approaches frequently produce blurred or excessively smoothed image details and lack a comprehensive theoretical foundation to explain these shortcomings. To address these limitations, we propose UniDB, a unified framework for diffusion bridges based on Stochastic Optimal Control (SOC). UniDB formulates the problem through an SOC-based optimization and derives a closed-form solution for the optimal controller, thereby unifying and generalizing existing diffusion bridge models. We demonstrate that existing diffusion bridges employing Doob’s $h$-transform constitute a special case of our framework, emerging when the terminal penalty coefficient in the SOC cost function tends to infinity. By incorporating a tunable terminal penalty coefficient, UniDB achieves an optimal balance between control costs and terminal penalties, substantially improving detail preservation and output quality. Notably, UniDB seamlessly integrates with existing diffusion bridge models, requiring only minimal code modifications. Extensive experiments across diverse image restoration tasks validate the superiority and adaptability of the proposed framework. Our code is available at \url{https://github.com/UniDB-SOC/UniDB/}.
\end{abstract} 

\vspace{-8mm}

\section{Introduction}
\begin{figure*}[t] % '!t' 表示尽可能靠近页面顶部
    \centering
    \includegraphics[width=0.94\textwidth]{picture/main_2.pdf}
    \vspace{-6mm}
    \caption{Here we briefly compare the performance of UniDB to diffusion bridge with Doob's $h$-transform \cite{yue2024imagerestorationgeneralizedornsteinuhlenbeck} across various tasks, including Super-resolution, Inpainting and Deraining. UniDB effectively balances control and terminal costs by modifying the terminal penalty coefficient, alleviating the problems caused by Doob's $h$-transform  in these applications. This framework significantly boosts the detail rendering ability of generated images while imposing minimal overhead in code modifications.}
    \label{fig:widefig}
    \vspace{-5mm}
\end{figure*}

% \vspace{-2mm}

The diffusion model has been extensively utilized across a range of applications, including image generation and editing \cite{ho2020denoisingdiffusionprobabilisticmodels, DDRM, song2021scorebasedgenerativemodelingstochastic, DiffIR, li2023diffusionmodelsimagerestoration}, imitation learning \cite{afforddp, dp, 3ddp} and reinforcement learning \cite{yang2023policyrepresentationdiffusionprobability, QVPO}, etc. Despite its versatility, the standard diffusion model faces limitations in transitioning between arbitrary distributions due to its inherent assumption of a Gaussian noise prior. To overcome this problem, diffusion models \cite{dhariwal2021diffusionmodelsbeatgans, ho2022classifier,  murata2023gibbsddrmpartiallycollapsedgibbs, CCDM, chung2024diffusionposteriorsamplinggeneral, tang2024unified} often rely on meticulously designed conditioning mechanisms and classifier/loss guidance to facilitate conditional sampling and ensure output alignment with a target distribution. However, these methods can be cumbersome and may introduce manifold deviations during the sampling process. Meanwhile, Diffusion Schrödinger Bridge \cite{shi2023diffusionschrodingerbridgematching, debortoli2023diffusionschrodingerbridgeapplications, somnath2024aligneddiffusionschrodingerbridges} involves constraints that hinder direct optimization of the KL divergence, resulting in slow convergence and limited model fitting capability.




To address this challenge, DDBMs \cite{zheng2024diffusionbridgeimplicitmodels} proposed a diffusion bridge model using Doob's $h$-transform. This framework is specifically designed to establish fixed endpoints between two distinct distributions by learning the score function of the diffusion bridge from data, and then solving the stochastic differential equation (SDE) based on these learned scores to transition from one endpoint distribution to another. However, the forward SDE in DDBMs lacks the mean information of the terminal distribution, which restricts the quality of the generated images, particularly in image restoration tasks. Subsequently, GOUB \cite{yue2024imagerestorationgeneralizedornsteinuhlenbeck} extends this framework by integrating Doob's $h$-transform with a mean-reverting SDE, achieving better results compared to DDBMs. 
Despite the promising results in diffusion bridge with Doob's $h$-transform, two fundamental challenges persist: 1) the theoretical mechanisms by which Doob's $h$-transform governs the bridging process remain poorly understood, lacking a rigorous framework to unify its empirical success; and 2) while effective for global distribution alignment, existing methods frequently degrade high-frequency details—such as sharp edges and fine textures—resulting in outputs with blurred or oversmoothed artifacts that compromise perceptual fidelity. These limitations underscore the need for both theoretical grounding and enhanced detail preservation in diffusion bridges. 

% Despite the notable performance of diffusion bridge models incorporating Doob's $h$-transform \cite{zheng2024diffusionbridgeimplicitmodels,yue2024imagerestorationgeneralizedornsteinuhlenbeck}, show notable performance, these methods often generate images with blurred or excessively smoothed details and are lacking a comprehensive theoretical framework to account for these shortcomings. 

In this paper, we revisit the diffusion bridges through the lens of stochastic optimal control (SOC) by introducing a novel framework called UniDB, which formulates an optimization problem based on SOC principles to implement diffusion bridges. It enables the derivation of a closed-form solution for the optimal controller, along with the corresponding training objective for the diffusion bridge. UniDB identifies Doob's $h$-transform as a special case when the terminal penalty coefficient in the SOC cost function approaches infinity. This explains why Doob's $h$-transform may result in suboptimal solutions with blurred or distorted details. To address this limitation, UniDB utilizes the penalty coefficient in SOC to adjust the expressiveness of the image details and enhance the authenticity of the generated outputs. Our main contributions are as follows: 

\begin{itemize}

\vspace{-4mm}
\item We introduce UniDB, a novel unified diffusion bridge framework based on stochastic optimal control. This framework generalizes existing diffusion bridge models like DDBMs and GOUB, offering a comprehensive understanding and extension of Doob’s $h$-transform by incorporating general forward SDE forms.

\vspace{-2mm}

\item We derive closed-form solutions for the SOC problem, demonstrating that Doob’s $h$-transform is merely a special case within UniDB when the terminal penalty coefficient in the SOC cost function approaches infinity. This insight reveals inherent limitations in the existing diffusion bridge approaches, which UniDB overcomes. Notably, the improvement of UniDB requires minimal code modification, ensuring easy implementation. 

\vspace{-2mm}

\item UniDB achieves state-of-the-art results in various image restoration tasks, including super-resolution (DIV2K), inpainting (CelebA-HQ), and deraining (Rain100H), which highlights the framework’s superior image quality and adaptability across diverse scenarios. 

\end{itemize}


\vspace{-6mm}


\section{Related Work}
% In this section, we will review the existing works that establish methods for transforming from distribution to distribution and analyze their advantages and insufficiency. 
\textbf{Diffusion with Guidance.} This technique tackles conditional generative tasks by leveraging a differentiable loss function for guidance without the need for additional training \cite{chung2024diffusionposteriorsamplinggeneral, shenoy2024gradientfreeclassifierguidancediffusion, bradley2024classifierfreeguidancepredictorcorrector}. However, it often yields suboptimal image quality and a prolonged sampling process due to the necessity of small step sizes.  Most importantly, the sampling process is prone to manifold deviations and detail losses \cite{yang2024guidancesphericalgaussianconstraint}. Furthermore, enhancing the guidance of the diffusion typically requires the introduction of additional modules, thereby increasing the model’s computational complexity. 

% \textbf{Diffusion Schrödinger Bridge.} This approach aims to determine a stochastic process, $\pi^*$ that facilitates probabilistic transport between a given initial distribution $P_{\text{prior}}$, and a terminal distribution $P_{\text{data}}$ \cite{I2SB, shi2023diffusionschrodingerbridgematching,debortoli2023diffusionschrodingerbridgeapplications} while minimizing the Kullback-Leibler (KL) divergence. However, its training process is usually intricate, involving constraints that hinder direct optimization of the KL divergence, resulting in slow convergence and limited model fitting capability. For instance, DSB \cite{somnath2024aligneddiffusionschrodingerbridges} requires two independent forward passes during training to obtain the target distribution, thereby increasing both the complexity and time cost of training. 

\textbf{Diffusion Bridge with Doob's $h$-transform.} Recent advances in diffusion bridging have demonstrated the efficacy of Doob's $h$-transform in enhancing transition quality between arbitrary distributions. Notably, DDBMs \cite{zhou2023denoisingdiffusionbridgemodels} pioneered this approach by employing a linear SDE combined with Doob's $h$-transform to construct direct diffusion bridges. Subsequently, GOUB \cite{yue2024imagerestorationgeneralizedornsteinuhlenbeck} extends this framework by integrating Doob's $h$-transform with a mean-reverting SDE, achieving state-of-the-art performance in image restoration tasks. Despite these empirical successes, the theoretical foundations of Doob's $h$-transform in this context remain insufficiently explored. In addition, these methods often result in images with blurred or oversmoothed features, particularly affecting the capture of high-frequency details crucial for perceptual fidelity. 
% To achieve the transition between two arbitrary distributions, some existing approaches \cite{zhou2023denoisingdiffusionbridgemodels, yue2024imagerestorationgeneralizedornsteinuhlenbeck} have demonstrated significant performance improvements by employing Doob's h-transform. Specifically, DDBMs \cite{zhou2023denoisingdiffusionbridgemodels} utilizes Doob's $h$-transform with a linear SDE while GOUB \cite{yue2024imagerestorationgeneralizedornsteinuhlenbeck} utilizes Doob's $h$-transform with a mean-reverting SDE. However, there is still a lack of a theoretical framework to understand the underlying of Doob's $h$-transform. Moreover, these methods can sometimes produce images with blurred or overly smoothed details. 
% Leveraging Doob's $h$-transform in Diffusion Bridge to fix the endpoints of two different distributions can achieve mutual transformation \cite{zhou2023denoisingdiffusionbridgemodels, yue2024imagerestorationgeneralizedornsteinuhlenbeck}, while this method faces challenges such as solving the complex Kolmogorov backward equation (a difficult partial differential equation, PDE) and difficulties in parameter optimization to find the optimal parameters. To address these issues, some approaches \cite{heng2022simulatingdiffusionbridgesscore} propose defining a reverse process and approximating the forward process by Doob's $h$-transform. They avoid the complexity of directly using the forward process by reverse-time representation and score matching methods. 

\textbf{Diffusion with Stochastic Optimal Control.} The integration of SOC principles into diffusion models has emerged as a promising paradigm for guiding distribution transitions. DIS \cite{berner2024optimalcontrolperspectivediffusionbased} established a foundational theoretical linkage between diffusion processes and SOC, while RB-Modulation \cite{RB} operationalized SOC via a simplified SDE structure for training-free style transfer using pre-trained diffusion models. Close to our work, DBFS \cite{park2024stochasticoptimalcontroldiffusion} leveraged SOC to construct diffusion bridges in infinite-dimensional function spaces and also established equivalence between SOC and Doob's $h$-transform. However, DBFS primarily extends Doob's $h$-transform to infinite Hilbert spaces via SOC, without addressing its intrinsic limitations. Our analysis reveals a critical insight: Doob's $h$-transform corresponds to a suboptimal solution that can inherently lead to artifacts such as blurred or distorted details. To resolve this, we introduce a unified SOC framework that jointly optimizes trajectory costs and terminal constraints, enhancing detail preservation and image quality. 

% However, DBFS doesn't clarify the equivalence holds under which cost functions and parameter settings, nor does it address potential issues of Doob's $h$-transform. 
% Doob's $h$-transform in infinite-dimensional spaces, derived from Stochastic Optimal Control (SOC) \cite{park2024stochasticoptimalcontroldiffusion}, is applicable to unpaired image transfer and functional Bayesian posterior sampling without resolution limits. However, the study does not clarify the cost functions and parameter settings under which SOC and Doob's $h$-transform are equivalent, nor does it address potential issues or propose solutions. RB-Modulation, based on SOC with a simple SDE \cite{RB}, enables training-free style and content fusion from reference images. 

% In contrast, the proposed UniDB overcomes these issues by formulating a SOC-based optimization problem. It identifies Doob's $h$-transform as a specific case when the terminal penalty coefficient in the SOC cost function approaches infinity, explaining why Doob's h-transform often leads to suboptimal solutions with blurred or distorted details. By introducing this terminal penalty coefficient, UniDB effectively balances control costs and terminal penalties, enhancing detail preservation and image quality.




% introduces the terminal penalty coefficient on addressing potential issues, clarifies the equivalence of SOC and Doob's $h$-transform under which situation, and applies to more complex SDE form.


% RB Modeling achieves personalized diffusion models without training through a stochastic optimal controller (SOC), which can accurately extract style and content from reference images, avoid content leakage, and achieve seamless combination of style and content

\vspace{-2mm}

\section{Preliminaries}

\subsection{Denoising Diffusion Bridge Models}

Starting with an initial $d$-dimensional data distribution $\mathbf{x}_0 \sim q_{\text{data}}(\mathbf{x})$, diffusion models \cite{song2021scorebasedgenerativemodelingstochastic, ho2020denoisingdiffusionprobabilisticmodels, sohldickstein2015deepunsupervisedlearningusing, song2020generativemodelingestimatinggradients} construct a diffusion process, which can be achieved by defining a forward stochastic process evolving from $\mathbf{x}_0$ through a stochastic differential equation (SDE):
\begin{equation}\label{diffusion_sde}
\mathrm{d} \mathbf{x}_t = \mathbf{f}(\mathbf{x}_t, t) \mathrm{d} t+g_t \mathrm{~d} \mathbf{w}_t,
\end{equation}
where $t$ ranges over the interval $[0, T]$, $\mathbf{f}: \mathbb{R}^d \times [0, T] \rightarrow \mathbb{R}^d$ is the vector-valued drift function, $g:[0, T] \rightarrow \mathbb{R}$ signifies the scalar-valued diffusion coefficient and $\mathbf{w}_t \in \mathbb{R}^d$ is the Wiener process, also known as Brownian motion. To promise the transition probability $p(\mathbf{x}_t \mid \mathbf{x}_s)$ remains Gaussian, almost all the diffusion SDEs take the following linear form \cite{zheng2024diffusionbridgeimplicitmodels} in \eqref{diffusion_sde}:
\begin{equation}\label{linear_form}
\mathbf{f}(\mathbf{x}_t, t) = f(t) \mathbf{x}_t,
\end{equation}
where $f(t)$ is some scalar-valued function. To realize transition between arbitrary distributions, DDBMs introduces Doob’s $h$-transform \cite{särkkä2019applied}, a mathematical technique applied to stochastic processes, which rectifies the drift term of the forward diffusion process to pass through a preset terminal point $\mathbf{x}_T \in \mathbb{R}^d$. Precisely, the forward process of diffusion bridges after Doob's $h$-transform becomes: 
\begin{equation}\label{doob}
\mathrm{d} \mathbf{x}_t = \left[ \mathbf{f}(\mathbf{x}_t, t) + g^2_t \mathbf{h}(\mathbf{x}_t, t, \mathbf{x}_T, T) \right] \mathrm{d} t+g_t \mathrm{~d} \mathbf{w}_t,
\end{equation}
where $\mathbf{h}(\mathbf{x}_t, t, \mathbf{x}_T, T) = \nabla_{\mathbf{x}_t} \log p(\mathbf{x}_T \mid \mathbf{x}_t)$ is the $h$ function. The diffusion bridge can connect the initial $\mathbf{x}_0$ to any given terminal $\mathbf{x}_T$ and thus is promising for various image restoration tasks. Meanwhile, its backward reverse SDE \cite{ANDERSON1982313} is given by
\begin{equation}\label{reverse-bridge-sde}
\begin{aligned}
\mathrm{d} \mathbf{x}_t = & \Big[ \mathbf{f}(\mathbf{x}_t, t) + g^2_t \nabla_{\mathbf{x}_t} \log p(\mathbf{x}_T \mid \mathbf{x}_t) \\
& - g_t^2\nabla_{\mathbf{x}_t} \log p(\mathbf{x}_t \mid \mathbf{x}_T) \Big] \mathrm{d} t+g_t \mathrm{~d} \tilde{\mathbf{w}}_t.
\end{aligned}
\end{equation}
where $\tilde{\mathbf{w}}_t$ is the reverse-time Wiener process and the unknown term $\nabla_{\mathbf{x}_t} \log p(\mathbf{x}_t \mid \mathbf{x}_T)$ can be estimated by a score prediction neural network $s_{\theta}$ \cite{song2021scorebasedgenerativemodelingstochastic}.
% \vspace{-2mm}
\subsection{Generalized Ornstein-Uhlenbeck Bridge}
Generalized Ornstein-Uhlenbeck (GOU) process describes a mean-reverting stochastic process commonly used in finance, physics, and other fields in the following SDE form \cite{ahmad1988introduction, Pavliotis2014, WANG2018921}:
\begin{equation}\label{gou_process}
\mathrm{d} \mathbf{x}_t=\theta_t\left(\boldsymbol{\mu}-\mathbf{x}_t\right) \mathrm{d} t+g_t \mathrm{~d} \mathbf{w}_t,
\end{equation}
where $\boldsymbol{\mu}$ is a given state vector, $\theta_t$ denotes a scalar drift coefficient and $g_t$ represents the diffusion coefficient with $\theta_t$, $g_t$ satisfying the specified relationship $g_{t}^{2} = 2 \lambda^2 \theta_t$ where $\lambda^2$ is a given constant scalar. Based on this, Generalized Ornstein-Uhlenbeck Bridge (GOUB) is a diffusion bridge model \cite{yue2024imagerestorationgeneralizedornsteinuhlenbeck}, which can address image restoration tasks without the need for specific prior knowledge. With the introduction of $\boldsymbol{\mu}$, $\mathbf{x}_t$ tends to $\boldsymbol{\mu}$ as time $t$ progresses. Through Doob's $h$-transform, denote $\bar{\theta}_{s:t} = \int_{s}^{t} \theta_z dz$, $\bar{\theta}_{t} = \int_{0}^{t} \theta_z dz$ for simplification when $s=0$ and $\bar{\sigma}^2_{s:t} = \lambda^2(1-e^{-2\bar{\theta}_{s:t}})$, the forward process of GOUB is formed as:
% \begin{equation}\label{goub_forward_sde}
% \begin{gathered}
% \mathrm{d} \mathbf{x}_t=\left(\theta_t+g_t^2 \frac{e^{-2 \bar{\theta}_{t: T}}}{\bar{\sigma}_{t: T}^2}\right)\left(\mathbf{x}_T-\mathbf{x}_t\right) \mathrm{d} t+g_t \mathrm{~d} \mathbf{w}_t, \\
% \bar{\theta}_{s:t} = \int_{s}^{t} \theta_z dz, \quad \quad \bar{\sigma}^2_{s:t} = \frac{g_t^2}{2\theta_t}(1-e^{-2\bar{\theta}_{s:t}}).
% \end{gathered}
% \end{equation}
\begin{equation}\label{goub_forward_sde}
\mathrm{d} \mathbf{x}_t=\left(\theta_t+g_t^2 \frac{e^{-2 \bar{\theta}_{t: T}}}{\bar{\sigma}_{t: T}^2}\right)\left(\mathbf{x}_T-\mathbf{x}_t\right) \mathrm{d} t+g_t \mathrm{~d} \mathbf{w}_t.
\end{equation}
And the forward transition $p(\mathbf{x}_t\mid\mathbf{x}_0,\mathbf{x}_T)$ is given by
\begin{equation}\label{gou_transition}
\begin{gathered}
p(\mathbf{x}_t\mid\mathbf{x}_0,\mathbf{x}_T)=\mathcal{N}(\bar{\boldsymbol{\mu}}_{t}^{\prime},\bar{\sigma}_t^{\prime2}\mathbf{I}), \\
\bar{\boldsymbol{\mu}}_{t}^{\prime}=e^{-\bar{\theta}_t}\frac{\bar{\sigma}_{t:T}^2}{\bar{\sigma}_T^2}\mathbf{x}_0 + ( 1 - e^{-\bar{\theta}_t}\frac{\bar{\sigma}_{t:T}^2}{\bar{\sigma}_T^2} )\mathbf{x}_T, \ \bar{\sigma}_t^{\prime2}=\frac{\bar{\sigma}_t^2\bar{\sigma}_{t:T}^2}{\bar{\sigma}_T^2}.
\end{gathered}
\end{equation}
Also, GOUB presents a new reverse ODE called Mean-ODE, which directly neglects the Brownian term of \eqref{reverse-bridge-sde}: 
\begin{equation}\label{reverse-mean-ode}
\begin{aligned}
\mathrm{d} \mathbf{x}_t = \Big[ \mathbf{f}&(\mathbf{x}_t, t) + g^2_t \nabla_{\mathbf{x}_t} \log p(\mathbf{x}_T \mid \mathbf{x}_t) \\
& - g_t^2\nabla_{\mathbf{x}_t} \log p(\mathbf{x}_t \mid \mathbf{x}_T) \Big] \mathrm{d} t.
\end{aligned}
\end{equation}

\vspace{-5mm}
\subsection{Stochastic Optimal Control}
% \textbf{Formulation of the Stochastic Optimal Control Problem:}
Stochastic Optimal Control (SOC) is a mathematical discipline that focuses on determining optimal control strategies for dynamic systems under uncertainty. By integrating stochastic processes with optimization theory, SOC seeks to identify the best control strategies in scenarios involving randomness, as commonly encountered in fields like finance \cite{Geering2010} and style transfer \cite{RB}. Considering the dynamics described in \eqref{diffusion_sde}, let us examine the following Linear Quadratic SOC problem \cite{4310229, OConnell2003ConditionedRW, Kappen2008StochasticOC, chen2024generativemodelingphasestochastic}: 
\begin{equation}\label{control_problem_sde}
\begin{gathered}
\min_{\mathbf{u}_{t, \gamma} \in \mathcal{U}} \int_0^T \frac{1}{2} \left\|\mathbf{u}_{t, \gamma}\right\|_2^2 d t+\frac{\gamma}{2}\left\|\mathbf{x}_T^{u}-x_T\right\|_2^2 \\
\text{s.t.} \ \mathrm{d} \mathbf{x}_t = \left( \mathbf{f}(\mathbf{x}_t, t) + g_t \mathbf{u}_{t, \gamma} \right) \mathrm{d} t + g_t \mathrm{~d} \mathbf{w}_t, \ \mathbf{x}_0^u=x_0,
\end{gathered}
\end{equation}
where $\mathbf{x}_t^u$ is the diffusion process under control, $x_0$ and $x_T$ represent for the initial state and the preset terminal respectively, $\left\|\mathbf{u}_{t, \gamma}\right\|_2^2$ is the instantaneous cost, $\frac{\gamma}{2}\left\|\mathbf{x}_T^{u}-x_T\right\|_2^2$ is the terminal cost with its penalty coefficient $\gamma$. The SOC problem aims to design the controller $\mathbf{u}_{t, \gamma}$ to drive the dynamic system from $x_0$ to $x_T$ with minimum cost. 


\section{Methods}
\subsection{Diffusion Bridges Constructed by SOC Problem}
The forward SDE of the Diffusion Bridge with Doob’s $h$-transform is enforced to pass from the predetermined origin $x_0$ to the terminal $x_T$. With a similar purpose, UniDB constructs a SOC problem where the constraints are an arbitrary linear SDE of the forward diffusion with a given initial state, while the objective incorporates a penalty term steering the forward diffusion trajectory towards the predetermined terminal $x_T$. Meanwhile, compared with the linear drift term \eqref{linear_form}, we combined a given state vector term $\mathbf{m}$ with the same dimension as $\mathbf{x}_t$ and its related coefficient $h_t$ to improve the generality of the linear SDE form: 
\begin{equation}\label{generalized_linear_SDE}
\mathbf{f}(\mathbf{x}_t, t) = f_t \mathbf{x}_t + h_t \mathbf{m}.
\end{equation}

Accordingly, our SOC problem with unified linear SDE \eqref{generalized_linear_SDE} is formed as: 
\begin{equation}\label{SOC_problem_generalized_sde}
\begin{aligned}
&\min_{\mathbf{u}_{t, \gamma}\in \mathcal{U} } \int_{0}^{T} \frac{1}{2} \|\mathbf{u}_{t, \gamma}\|_2^2 dt + \frac{\gamma}{2} \| \mathbf{x}_T^{u} - x_T\|_2^2 \\
\text{s.t.} \mathrm{d} \mathbf{x}_t &= \Big( f_t \mathbf{x}_t + h_t \mathbf{m} + g_t \mathbf{u}_{t, \gamma} \Big) \mathrm{d} t + g_t \mathrm{d} \mathbf{w}_t, \mathbf{x}_0^u = x_0.
\end{aligned}
\end{equation}

% paper
According to the certainty equivalence principle \cite{chen2024generativemodelingphasestochastic, RB}, the addition of noise or perturbations to a linear system with quadratic costs does not change the optimal control. Therefore, we can modify the SOC problem with the deterministic ODE condition to obtain the optimal controller $\mathbf{u}_{t, \gamma}^{*}$ as follows, 
\begin{equation}\label{SOC_problem_generalized_ode}
\begin{gathered}
\min_{\mathbf{u}_{t, \gamma}\in \mathcal{U} } \int_0^T \frac{1}{2} \left\|\mathbf{u}_{t, \gamma}\right\|_2^2 d t+\frac{\gamma}{2}\left\|\mathbf{x}_T^{u}-x_T\right\|_2^2 \\
\text{s.t.} \ \mathrm{d} \mathbf{x}_t = \Big( f_t \mathbf{x}_t + h_t \mathbf{m} + g_t \mathbf{u}_{t, \gamma} \Big) \mathrm{d} t, \ \mathbf{x}_0^u=x_0.
\end{gathered}
\end{equation}
We can derive the closed-form solution to the problem \eqref{SOC_problem_generalized_ode}, which leads to the following Theorem \ref{theorem_4.1}: 
\begin{theorem}\label{theorem_4.1} 
\textit{Consider the SOC problem \eqref{SOC_problem_generalized_ode}, denote $d_{t, \gamma} = \gamma^{-1} + e^{2\bar{f}_{T}} \bar{g}^2_{t:T}$, $\bar{f}_{s:t} = \int_{s}^{t} f_z dz$, $\bar{h}_{s:t} = \int_{s}^{t} e^{-\bar{f}_{z}} h_z dz$ and $\bar{g}^2_{s:t} = \int_{s}^{t} e^{-2\bar{f}_{z}}g^2_z dz$, denote $\bar{f}_{t}$, $\bar{h}_{t}$ and $\bar{g}^2_{t}$ for simplification when $s=0$, then the closed-form optimal controller $\mathbf{u}_{t,\gamma}^{*}$ is} 
\begin{equation}\label{general_optimal_controller}
\mathbf{u}_{t, \gamma}^{*} = g_t e^{\bar{f}_{t:T}} \frac{x_{T} - e^{\bar{f}_{t:T}} \mathbf{x}_t - \mathbf{m} e^{\bar{f}_{T}} \bar{h}_{t:T}}{d_{t, \gamma}},
\end{equation}
\textit{and the transition of $\mathbf{x}_t$ from $x_0$ and $x_T$ is}
\begin{equation}\label{general_interpolant}
\mathbf{x}_t = e^{\bar{f}_{t}} \Bigg(\frac{d_{t, \gamma}}{d_{0, \gamma}} x_0 + \frac{e^{\bar{f}_{T}} \bar{g}^2_{t}}{d_{0, \gamma}} x_T + \Big(\bar{h}_{t} - \frac{e^{2\bar{f}_{T}} \bar{h}_{T} \bar{g}^2_{t}}{d_{0, \gamma}}\Big) \mathbf{m}\Bigg). 
\end{equation}
\end{theorem}
The proof of Theorem \ref{theorem_4.1} is provided in Appendix \ref{proof_theorem_4.1}. With Theorem \ref{theorem_4.1}, we can obtain an optimally controlled forward SDE connected from $x_0$ to the neighborhood of the terminal $x_T$ and the transition of $\mathbf{x}_t$ for the forward process. As for the backward process, similar to \eqref{reverse-bridge-sde} and \eqref{reverse-mean-ode}, the backward reverse SDE and Mean-ODE are respectively formulated as: 
\begin{equation}\label{ours_reverse_sde}
\mathrm{d} \mathbf{x}_t = \Big[f_t \mathbf{x}_t + h_t \mathbf{m} + g_t  \mathbf{u}_{t, \gamma}^{*} - g^2_t \nabla_{\mathbf{x}_t} p(\mathbf{x}_t | x_T) \Big] \mathrm{d} t+ g_t \mathrm{d} \tilde{\mathbf{w}}_t,
\end{equation}
\begin{equation}\label{ours_reverse_ode}
\mathrm{d} \mathbf{x}_t = \Big[f_t \mathbf{x}_t + h_t \mathbf{m} + g_t  \mathbf{u}_{t, \gamma}^{*} - g^2_t \nabla_{\mathbf{x}_t} p(\mathbf{x}_t \mid x_T) \Big] \mathrm{d}t.
\end{equation}


\subsection{Connections between SOC and Doob's $h$-transform}
We can intuitively see from the SOC problem that when $\gamma \to \infty$ in Theorem \ref{theorem_4.1}, it means that the target of SDE process is precisely the predetermined endpoint \cite{chen2024generativemodelingphasestochastic}, which is also the purpose of Doob's $h$-transform and facilitates the following theorem:
\begin{theorem}\label{theorem_4.2} 
\textit{For the SOC problem \eqref{SOC_problem_generalized_ode}, when $\gamma \to \infty$, the optimal controller becomes $\mathbf{u}^{*}_{t, \infty} = g_t \nabla_{\mathbf{x}_t} \log p(\mathbf{x}_T \mid \mathbf{x}_t)$, and the corresponding forward and backward SDE with the linear SDE form \eqref{generalized_linear_SDE} are the same as Doob's $h$-transform as in \eqref{doob} and \eqref{reverse-bridge-sde}. 
}
\end{theorem}
The proof of Theorem \ref{theorem_4.2} is presented in Appendix \ref{proof_theorem_4.2}. This theorem shows that existing diffusion bridge models using Doob's $h$-transform are merely special instances of our UniDB framework, which offers a unified approach to diffusion bridges through the lens of SOC.

Furthermore, using Doob's $h$-transform in diffusion bridge models is not necessarily optimal, as letting the terminal penalty coefficient $\gamma \to \infty$ eliminates the consideration of control costs in SOC. To support this argument, we present Proposition \ref{proposition_4.3}, which asserts that the diffusion bridge with Doob's $h$-transform is not the most effective choice. 

\begin{proposition}\label{proposition_4.3} 
\textit{Consider the SOC problem \eqref{SOC_problem_generalized_ode}, denote $\mathcal{J}(\mathbf{u}_{t, \gamma}, \gamma) \triangleq \int_0^T \frac{1}{2} \left\|\mathbf{u}_{t, \gamma}\right\|_2^2 d t+\frac{\gamma}{2}\left\|\mathbf{x}_T^{u}-x_T\right\|_2^2$ as the overall cost of the system, $\mathbf{u}_{t, \gamma}^{*}$ as the optimal controller \eqref{general_optimal_controller}, then}
\begin{equation}
\mathcal{J}(\mathbf{u}_{t, \gamma}^{*}, \gamma) \le \mathcal{J}(\mathbf{u}_{t, \infty}^{*}, \infty).
\end{equation}
\end{proposition}
Detailed proof of Proposition \ref{proposition_4.3} is provided in Appendix \ref{proof_proposition_4.3}. Proposition \ref{proposition_4.3} shows that the overall cost when considering a finite $\gamma$ is more favorable than when $\gamma \rightarrow \infty$. Existing diffusion bridge models \cite{zhou2023denoisingdiffusionbridgemodels, yue2024imagerestorationgeneralizedornsteinuhlenbeck}, which inherently assume $\gamma \rightarrow \infty$, often result in suboptimal performance with blurred or overly smoothed image details. Therefore, maintaining the penalty coefficient $\gamma$ as a hyper-parameter is a more effective approach.  

\subsection{Training objective of UniDB}
In this section, we focus on constructing the training objective of UniDB. According to maximum log-likelihood \cite{ho2020denoisingdiffusionprobabilisticmodels} and conditional score matching \cite{song2021scorebasedgenerativemodelingstochastic}, the training objective is based on the forward transition $p(\mathbf{x}_t\mid\mathbf{x}_0,\mathbf{x}_T)$. Thus, we begin by deriving this probability. The closed-form expression in \eqref{general_interpolant} represents the mean value of the forward transition after applying reparameterization techniques. However, this expression lacks a noise component after the transformation based on the certainty equivalence principle. To address this issue, we employ stochastic interpolant theory \cite{albergo2023stochasticinterpolantsunifyingframework} to introduce a noise term $\bar{\sigma}_t^{\prime}\epsilon$ with $\bar{\sigma}_0^{\prime} = \bar{\sigma}_T^{\prime} = 0$. We define $\bar{\sigma}_t^{\prime2} = \bar{\sigma}_t^2\bar{\sigma}_{t:T}^2 / \bar{\sigma}_T^2$ similar to \eqref{gou_transition}, leading to the following forward transition: 
\begin{equation}\label{mu_gamma_prime}
\begin{gathered}
p(\mathbf{x}_t\mid x_0, x_T)=\mathcal{N}(\bar{\boldsymbol{\mu}}_{t, \gamma},\bar{\sigma}_t^{\prime2}\mathbf{I}), \\
\bar{\boldsymbol{\mu}}_{t, \gamma} = e^{\bar{f}_{t}} \Big(\frac{d_{t, \gamma}}{d_{0, \gamma}} x_0 + \frac{e^{\bar{f}_{T}} \bar{g}^2_{t}}{d_{0, \gamma}} x_T + \big(\bar{h}_{t} - \frac{e^{2\bar{f}_{T}} \bar{h}_{T} \bar{g}^2_{t}}{d_{0, \gamma}}\big) \mathbf{m}\Big), \\
\bar{\sigma}_{s:t}^2 = e^{2\bar{f}_t} \bar{g}^2_{s:t}, \quad \quad \bar{\sigma}_t^{\prime2}=\frac{\bar{\sigma}_t^2\bar{\sigma}_{t:T}^2}{\bar{\sigma}_T^2}.
\end{gathered}
\end{equation}
The derailed derivation is provided in Appendix \ref{proof_derivation_transition_prob}. 
Similar to \cite{yue2024imagerestorationgeneralizedornsteinuhlenbeck} using the $l_1$ loss form to bring improved visual quality and details at the pixel level \cite{boyd2004convex, hastie2009elements}, we can derive the training objective. Denote $a_{t, \gamma} = e^{\bar{f}_{t}}d_{t, \gamma}$, assuming $\boldsymbol{\mu}_{t-1, \theta}$, $\sigma_{t-1, \theta}^2$ and $\boldsymbol{\mu}_{t-1, \gamma}$, $\sigma_{t-1, \gamma}^2$ are respectively the mean values and variances of $p_{\theta} (\mathbf{x}_{t-1} \mid \mathbf{x}_t, x_T)$ and $p (\mathbf{x}_{t-1} \mid \mathbf{x}_0, \mathbf{x}_t, x_T)$, suppose the score $\nabla_{\mathbf{x}_t} p(\mathbf{x}_t \mid x_T)$ is parameterized as $-\boldsymbol{\epsilon}_{\theta}(\mathbf{x}_t, x_T, t) / \bar{\sigma}_{t}^{\prime}$, the final training objective is as follows, 
\begin{equation}\label{objective_function}
\begin{gathered}
\mathcal{L}_{\theta} = \mathbb{E}_{t, \mathbf{x}_0, \mathbf{x}_t, \mathbf{x}_T} \left[ \frac{1}{2\sigma_{t-1, \theta}^2} \big \| \boldsymbol{\mu}_{t-1, \theta} - \boldsymbol{\mu}_{t-1, \gamma} \big \|_1 \right], \\
\boldsymbol{\mu}_{t-1, \theta} = \mathbf{x}_{t} - f_t \mathbf{x}_t - h_t \mathbf{m} - g_t \mathbf{u}_{t, \gamma}^{*} + \frac{g^2_t}{\bar{\sigma}_{t}^{\prime}} \boldsymbol{\epsilon}_{\theta}(\mathbf{x}_t, x_T, t), \\
\boldsymbol{\mu}_{t-1, \gamma} = \bar{\boldsymbol{\mu}}_{t-1, \gamma} + \frac{\bar{\sigma}_{t-1}^{\prime2}a_{t, \gamma}}{\bar{\sigma}_{t}^{\prime2}a_{t-1, \gamma} } (\mathbf{x}_t - \bar{\boldsymbol{\mu}}_{t, \gamma}),\ \sigma_{t-1, \theta} = g_t.
\end{gathered}
\end{equation}

Please refer to Appendix \ref{proof_proposition_4.5} for detailed derivations. Therefore, we can recover or generate the origin image $\hat{x}_0$ through Euler sampling iterations. So far, we've built the UniDB framework, which establishes and expands the forward and backward process of the diffusion bridge model through SOC and comprises Doob's $h$-transform as a special case. 


\subsection{UniDB unifies diffusion bridge models}
Our UniDB is a unified framework for existing diffusion bridge models: DDBMs (VE) \cite{zhou2023denoisingdiffusionbridgemodels}, DDBMs (VP) \cite{zhou2023denoisingdiffusionbridgemodels} and GOUB \cite{yue2024imagerestorationgeneralizedornsteinuhlenbeck}.  
\begin{proposition}\label{proposition_4.4} UniDB encompasses existing diffusion bridge models by employing different hyper-parameter spaces $\mathcal{H}$ as follows:
\begin{itemize}


\item DDBMs (VE) corresponds to UniDB with hyper-parameter $\mathcal{H}_\text{VE}(f_t=0, h_t=0, \gamma \rightarrow \infty)$


\item DDBMs (VP) corresponds to UniDB with hyper-parameter $\mathcal{H}_\text{VP}(f_t=-\frac{1}{2} g^2_t, h_t=0, \gamma \rightarrow \infty)$


\item GOUB corresponds to UniDB with hyper-parameter $\mathcal{H}_\text{GOU}(f_t=\theta_t, h_t=-\theta_t, \mathbf{m} = \boldsymbol{\mu}, \gamma \rightarrow \infty)$
\end{itemize}
\end{proposition}

\vspace{-2mm}
Details of the proposition \ref{proposition_4.4} are provided in Appendix \ref{proof_proposition_4.4}. 

\subsection{An Example: UniDB-GOU}\label{example}
It is evident that these diffusion bridge models like DDBMs (VE), DDBMs (VP) and GOUB all based on Doob's $h$-transform are all special cases of UniDB with $\gamma \rightarrow \infty$. However, according to Proposition \ref{proposition_4.3}, these models are not the effective choices. Therefore, we introduce UniDB based on the GOU process \eqref{gou_process}, hereafter referred to as UniDB-GOU, which retains the penalty coefficient $\gamma$ as the hyper-parameter. Considering the SOC problem with GOU process \eqref{gou_process}, the optimally controlled forward SDE is:
\begin{equation}\label{20}
\mathrm{d} \mathbf{x}_t = \left( \theta_t + g^2_t \frac{e^{-2\bar{\theta}_{t:T}}}{\gamma^{-1} + \bar{\sigma}^2_{t:T}}\right) (x_T - \mathbf{x}_t) \mathrm{d} t + g_t \mathrm{d} \mathbf{w}_t,
\end{equation}
and the mean value of forward transition $p(\mathbf{x}_t \mid x_0, x_T)$ is
\begin{equation}\label{21}
\bar{\boldsymbol{\mu}}_{t, \gamma} = e^{-\bar{\theta}_{t}} \frac{1 + \gamma \bar{\sigma}^2_{t:T}}{1 + \gamma \bar{\sigma}^2_{T}} x_0 + \left(1 - e^{-\bar{\theta}_{t}} \frac{1 + \gamma \bar{\sigma}^2_{t:T}}{1 + \gamma \bar{\sigma}^2_{T}}\right) x_T.
\end{equation}

Please refer to Appendix \ref{proof_derivation_UniDB-GOU} for detailed proof. 

\textbf{Remark 1.} It’s worth noting that our UniDB model can be a plugin module to the existing diffusion bridge with Doob's $h$-transform. Taking UniDB-GOU as an example, we highlight the key difference between UniDB-GOU and GOUB (the coefficient of $x_0$ in the mean value of forward transition and $h$-function term) as follows:

\vspace{-6mm}

\begin{equation}
\begin{aligned}
\textcolor{gray} {e^{-\bar{\theta}_{t}} \frac{\bar{\sigma}^2_{t:T}}{\bar{\sigma}^2_{T}}} & \Rightarrow e^{-\bar{\theta}_{t}} \frac{\gamma^{-1} + \bar{\sigma}^2_{t:T}}{\gamma^{-1} + \bar{\sigma}^2_{T}} \\
\underbrace{\textcolor{gray} {g_t\mathbf{h} = \frac{g_t e^{-2\bar{\theta}_{t:T}}(x_T - \mathbf{x}_t)}{\bar{\sigma}^2_{t:T}}}}_{\text{GOUB}} & \Rightarrow \underbrace{ \mathbf{u}_{t, \gamma}^{*} = \frac{g_t e^{-2\bar{\theta}_{t:T}}(x_T - \mathbf{x}_t)}{\gamma^{-1} + \bar{\sigma}^2_{t:T}}}_{\text{UniDB-GOU}}
\end{aligned}
\end{equation}

\vspace{-2mm}

Hence, only a few lines of code need to be adjusted to generate more realistic images using the same training method. Appendix \ref{append_pseudo} provides pseudo-code for the training and sampling process of UniDB-GOU. Beyond the GOUB model, our UniDB framework can be similarly extended to other diffusion bridge models, such as DDBMs (VE) and DDBMs (VP). For detailed information on UniDB-VE and UniDB-VP, please refer to Appendix \ref{ve_vp_example}. 

Building upon equations \eqref{20} and \eqref{21}, we further present a proposition to characterize how the penalty coefficient $\gamma$ affects the controlled terminal distribution as follows: 
\begin{proposition}\label{proposition_4.5}
\textit{Denote the initial state distribution $x_0$, the terminal distribution $\mathbf{x}_T^u$ by the controller and the pre-defined terminal distribution $x_T$, then}
\begin{equation}\label{terminal_distance}
    \| \mathbf{x}_T^u - x_T \|^2_2 = \frac{e^{-2\bar{\theta}_{T}}}{\left( 1 + \gamma \lambda^2 (1 - e^{-2\bar{\theta}_{T}}) \right)^2} \| x_T - x_0 \|^2_2.
\end{equation}
\end{proposition}



% \vspace{-7mm}
The detailed derivations of proposition \ref{proposition_4.5} are provided in Appendix \ref{proof_proposition_4.5}. Notably, as $\gamma$ approaches infinity, the control terminal converges to the predefined endpoint. However, as analyzed in Proposition \ref{proposition_4.3}, this can result in suboptimal outcomes with blurry or overly smoothed image details. To address this, it is crucial to balance the control cost and terminal term by selecting the value of $\gamma$. In the following section, we will present comprehensive experiments to evaluate the impact of different $\gamma$ values on the results. 

\section{Experiments}
In this section, we evaluate our models in image restoration tasks including Image 4$\times$Super-resolution, Image Deraining, and Image Inpainting. We take four evaluation metrics: Peak Signal-to-Noise Ratio (PSNR, higher is better) \cite{fardo2016formalevaluationpsnrquality}, Structural Similarity Index (SSIM, higher is better) \cite{1284395}, Learned Perceptual Image Patch Similarity (LPIPS, lower is better) \cite{zhang2018unreasonableeffectivenessdeepfeatures} and Fréchet Inception Distance (FID, lower is better) \cite{heusel2018ganstrainedtimescaleupdate}. For simple expressions in the following sections, UniDB (SDE) and UniDB (ODE) are applied to represent the UniDB-GOU with reverse SDE and reverse Mean-ODE, respectively. Please refer to Appendix \ref{appendix_experimental_details} and \ref{appendix_additional_results} for all related implementation details and more experiment results, respectively. 

\vspace{-1mm}

\subsection{Experiments Setup}

According to Proposition \ref{proposition_4.5}, we first quantitatively analyze the $l_2$-norm distances between the two terminal distributions depicted in Figure \ref{experiment_gamma_difference}. We computed the average distances between high-quality and low-quality images in the three datasets (CelebA-HQ, Rain100H, and DIV2K) related to the subsequent experimental section as the distances $\| x_T - x_0 \|^2_2$ in \eqref{terminal_distance}. As can be seen, for all three datasets, these distances remain relatively small, ranging from $10^{-4}$ to $10^{-10}$ when $\gamma$ is within the range of $1\times10^5$ to $1\times10^9$. Therefore, our subsequent experiments will focus on the $\gamma$ of this range to further investigate the performance of UniDB-GOU. 

\begin{figure}[H] 
    \raggedright
    \includegraphics[width=0.48\textwidth]{picture/r.png}
    \vspace{-3mm}
    \caption{The distances between target and controlled terminal distributions for different datasets (CelebA-HQ, Rain100H, and DIV2K) with different penalty coefficients $\gamma$. The red shaded area and blue dotted line highlight our choice of $\gamma$.}
    \label{experiment_gamma_difference}
    \vspace{-3mm}
\end{figure}

\begin{figure*}[t] 
    \raggedright
    \centering
    \includegraphics[width=0.98\textwidth]{picture/DIV2K_4.pdf}
    \vspace{-3mm}
    \caption{Qualitative comparison of visual results between GOUB (SDE) and UniDB (SDE) on DIV2K with zoomed-in image local regions (UniDB based on GOU process).}
    \label{experiment_DIV2K}
    \vspace{-3mm}
\end{figure*}

% \vspace{-3mm}

\begin{table*}[t]
\setlength{\tabcolsep}{2pt}
  \centering
  \caption{Qualitative comparison with the relevant baselines on DIV2K, Rain100H, and CelebA-HQ 256$\times$256 datasets.}
  \vspace{-1mm}
  \vskip 0.1in
  \label{results}
  \renewcommand{\arraystretch}{1.1}
  \resizebox{\textwidth}{!}{
  \begin{tabular}{|c|cccc|c|cccc|c|cccc|}
    \hline
    \multirow{2}*{\textbf{METHOD}} & \multicolumn{4}{c|}{\textbf{Image Super-Resolution}} & \multirow{2}*{\textbf{METHOD}} & \multicolumn{4}{c|}{\textbf{Image Deraining}} & \multirow{2}*{\textbf{METHOD}} & \multicolumn{4}{c|}{\textbf{Image Inpainting}} \\
    \cline{2-5} \cline{7-10} \cline{12-15}
      & \textbf{PSNR}$\uparrow$ & \textbf{SSIM}$\uparrow$ & \textbf{LPIPS}$\downarrow$ & \textbf{FID}$\downarrow$ & &\textbf{PSNR}$\uparrow$ & \textbf{SSIM}$\uparrow$ & \textbf{LPIPS}$\downarrow$ & \textbf{FID}$\downarrow$ & & \textbf{PSNR}$\uparrow$ & \textbf{SSIM}$\uparrow$ & \textbf{LPIPS}$\downarrow$ & \textbf{FID}$\downarrow$ \\
    \hline
    Bicubic & 26.70 & 0.774 & 0.425 & 36.18 &  MAXIM & 30.81 & 0.902 & 0.133 & 58.72 & PromptIR & 30.22 & 0.918 & 0.068 & 32.69\\
     DDRM & 24.35 & 0.592 & 0.364 & 78.71 &  MHNet &31.08 & 0.899 & 0.126 & 57.93 & DDRM & 27.16 & 0.899 & 0.089 & 37.02 \\

    IR-SDE &  25.90 & 0.657 & 0.231 & 45.36 &  IR-SDE & 31.65 & 0.904 & 0.047 & 18.64 & IR-SDE & 28.37 & 0.916 & 0.046 & 25.13 \\

    GOUB (SDE) & 26.89 & 0.7478 & 0.220 & 20.85 & GOUB (SDE) & 31.96 & 0.9028 & 0.046 & 18.14 & GOUB (SDE) & 28.98 & 0.9067 & 0.037 & 4.30 \\
       
    GOUB (ODE) & 28.50 & 0.8070 & 0.328 & 22.14 & GOUB (ODE) & 34.56 & 0.9414 & 0.077 & 32.83 & GOUB (ODE)  & 31.39 & 0.9392 & 0.052 & 12.24 \\
    \hline  
    UniDB (SDE) & 25.46 & 0.6856 & \textbf{0.179} & \textbf{16.21} & UniDB (SDE) & 32.05 & 0.9036 & \textbf{0.045} & \textbf{17.65} & UniDB (SDE)  & 29.20 & 0.9077 & \textbf{0.036} & \textbf{4.08} \\
    
    UniDB (ODE) & \textbf{28.64} & \textbf{0.8072} & 0.323 & 22.32 & UniDB (ODE)  &\textbf{34.68} & \textbf{0.9426} & 0.074 & 31.16 & UniDB (ODE) & \textbf{31.67} & \textbf{0.9395} & 0.052 & 11.98 \\   
    \hline         
  \end{tabular}
  }
  \vskip -0.1in
  \vspace{-2mm}
\end{table*}

\begin{table*}[t]
    \centering
    \tabcolsep=0.4cm
    \caption{Quantitative evaluation results for DIV2K, CelebA-HQ and Rain100H of UniDB-GOU with different penalty coefficients $\gamma$.}
    \label{ablation_study_gamma}
    % \vspace{0.1cm}
    \begin{tabular}{ccccccc}
        \toprule[0.8pt]
        \multirow{2}{*}{\textbf{TASKS}} & \multirow{2}{*}{\textbf{METRICS}} & \multicolumn{5}{c}{\textbf{Different} $\boldsymbol{\gamma}$} \\ \cmidrule(l){3-7}
        & & $5\times10^5$ & $1\times10^6$ & $1\times10^7$ & $1\times10^8$ & $\infty$ \\ \toprule[0.8pt]
        \multirow{4}{*}{\textbf{Image 4$\times$Super-Resolution}} 
        & \textbf{PSNR}$\uparrow$ & 24.94 & 24.72 & 25.46 & 25.06 & \textbf{26.89} \\   
        & \textbf{SSIM}$\uparrow$ & 0.6419 & 0.6587 & 0.6856 & 0.6393 & \textbf{0.7478} \\
        & \textbf{LPIPS}$\downarrow$ & 0.234 & 0.199 & \textbf{0.179} & 0.289 & 0.220 \\
        & \textbf{FID}$\downarrow$ & 20.33 & 18.37 & \textbf{16.21} & 23.76 & 20.85 \\ \toprule[0.8pt]
        \multirow{4}{*}{\textbf{Image Inpainting}} 
        & \textbf{PSNR}$\uparrow$ & 28.73 & 29.15 & \textbf{29.20} & 28.65 & 28.98 \\
        & \textbf{SSIM}$\uparrow$ & 0.9065 & 0.9068 & \textbf{0.9077} & 0.9062 & 0.9067 \\
        & \textbf{LPIPS}$\downarrow$ & 0.038 & 0.036 & \textbf{0.036} & 0.039 & 0.037 \\   
        & \textbf{FID}$\downarrow$ & 4.49 & 4.12 & \textbf{4.08} & 4.64 & 4.30 \\ \toprule[0.8pt]
        \multirow{4}{*}{\textbf{Image Deraining}} 
        & \textbf{PSNR}$\uparrow$ & 29.44 & 31.96 & 32.00 & \textbf{32.05} & 31.96 \\
        & \textbf{SSIM}$\uparrow$ & 0.8715 & 0.9018 & 0.9029 & \textbf{0.9036} & 0.9028 \\   
        & \textbf{LPIPS}$\downarrow$ & 0.058 & 0.045 & 0.046 & \textbf{0.045} & 0.046 \\
        & \textbf{FID}$\downarrow$ & 24.96 & 18.37 & 17.87 & \textbf{17.65} & 18.14 \\ \bottomrule[1pt]
    \end{tabular}
\end{table*}


\begin{figure*}[t] %
    \centering
    \includegraphics[width=\textwidth]{picture/combine_3.pdf}
    \vspace{-8mm}
    \caption{Qualitative comparison of visual results between GOUB (SDE) and UniDB (SDE) on the Rain100H dataset on Image Deraining (Left) and CelebA-HQ dataset on Image Inpainting (Right)  with zoomed-in image local regions (UniDB based on GOU process).}
    \label{experiment_inpainting_celeba}
    \vspace{-3mm}
\end{figure*}  


% \vspace{-3mm}



\vspace{-2mm}






\subsection{Experimental Details}


\textbf{Image 4$\times$Super-Resolution Tasks.}
In super-resolution, we evaluated our models based on DIV2K dataset \cite{8014884}, which contains 2K-resolution high-quality images. During the experiment, all low-resolution images were 4$\times$ bicubic upscaling to the same image size as the paired high-resolution images. For comparison, we choose Bicubic interpolantion \cite{DDRM}, DDRM \cite{DDRM}, IR-SDE \cite{IRSDE}, GOUB (SDE) \cite{yue2024imagerestorationgeneralizedornsteinuhlenbeck} and GOUB (Mean-ODE) \cite{yue2024imagerestorationgeneralizedornsteinuhlenbeck} following abbreviated as GOUB (ODE) as the baselines. The qualitative and quantitative results are illustrated in Table \ref{results} and Figure \ref{experiment_DIV2K}. Visually, our proposed model demonstrates a significant improvement over the baseline across various metrics. It also excels by delivering superior performance in both visual quality and detail compared to other results.


\textbf{Image Deraining Tasks.}
For image deraining tasks, we conducted the experiments based on Rain100H datasets \cite{8099666}. Particularly, to be consistent with other deraining models \cite{ren2019progressiveimagederainingnetworks, zamir2021multistageprogressiveimagerestoration, IRSDE, yue2024imagerestorationgeneralizedornsteinuhlenbeck}, PSNR and SSIM scores on the Y channel (YCbCr space) are selected instead of the origin PSNR and SSIM. MAXIM \cite{MAXIM}, MHNet \cite{MHNet}, IR-SDE \cite{IRSDE}, GOUB (SDE) \cite{yue2024imagerestorationgeneralizedornsteinuhlenbeck} and GOUB (ODE) \cite{yue2024imagerestorationgeneralizedornsteinuhlenbeck} are chosen as the baselines. The relevant experimental results are shown in the Table \ref{results} and Figure \ref{experiment_inpainting_celeba}. Similarly, our model achieved state-of-the-art results in the deraining task. Visually, it can also be observed that our model excels in capturing details such as the eyebrows, eye bags, and lips.


\textbf{Image Inpainting Tasks.}
In image inpainting tasks, we evaluated our methods on CelebA-HQ 256$\times$256 datasets \cite{karras2018progressivegrowinggansimproved}. For comparison, we choose DDRM \cite{DDRM}, PromptIR \cite{PromptIR}, IR-SDE \cite{IRSDE}, GOUB (SDE) \cite{yue2024imagerestorationgeneralizedornsteinuhlenbeck} and GOUB (ODE) \cite{yue2024imagerestorationgeneralizedornsteinuhlenbeck} as the baselines. As for mask type, we take 100 thin masks consistent with the baselines. The relevant experimental results are shown in Table \ref{results} and Figure \ref{experiment_inpainting_celeba}. It is observed that our model achieved state-of-the-art results in all indicators and also delivered highly competitive outcomes on other metrics. From a visual perspective, our model excels in capturing details such as faces, eyes, chins, and noses.


% \vspace{-2mm}

\subsection{Ablation Study}


\textbf{Penalty Coefficient $\gamma$.} To evaluate the specific impact of different penalty coefficients $\gamma$ on model performance, we conducted the experiments above with several different $\gamma$. The final results are shown in Table \ref{ablation_study_gamma}. The results across all tasks show that the choice of $\gamma$ significantly influences the model's performance on all tasks, different optimal $\gamma$ for different tasks, and our UniDB achieves the best performance in almost all metrics. Particularly in super-resolution tasks, we focus more on the significantly better perceptual scores (LPIPS and FID) \cite{IRSDE}, demonstrating that UniDB ensures to capture and preserve more intricate image details and features as shown in Figure \ref{experiment_gamma_difference}. These findings underscore the importance of carefully tuning $\gamma$ to achieve the best performance for specific tasks.

% More ablation experiments are presented in Appendix \ref{append_ablation}.



\section{Conclusion}
In this paper, we presented UniDB, a unified diffusion bridge framework based on stochastic optimal control principles, offering a novel perspective on diffusion bridges. Through this framework, we unify and extend existing diffusion bridge models with Doob's $h$-transform like DDBMs and GOUB. Moreover, we demonstrate that the diffusion bridge with Doob's $h$-transform can be viewed as a specific case within UniDB when the terminal penalty coefficient approaches infinity. This insight helps elucidate why Doob's $h$-transform may lead to suboptimal image restoration, often resulting in blurred or distorted details. By simply adjusting this terminal penalty coefficient, UniDB achieves a marked improvement in image quality with minimal code modifications. Our experimental results underscore UniDB’s superiority and versatility across various image processing tasks, particularly in enhancing image details for more realistic outputs. Despite these advantages, UniDB, like other standard diffusion bridge models, faces the challenge of computationally intensive sampling processes, especially with high-resolution images or complex restoration tasks. Future work will focus on developing strategies to accelerate the sampling process, enhancing UniDB’s practicality, particularly for real-time applications. 
 
% In this article, we propose UniDB, which applies stochastic optimal control to diffusion bridges, achieving the transformation from one distribution to another. For any forward SDE process, we can derive a closed-form solution for its diffusion bridge, and we demonstrate that Doob's $h$-transform is a special case of our model when the terminal penalty coefficient of the SOC cost function approaches infinity. Additionally, this parameter significantly influences the details of the generated images. Therefore, by simply adjusting this parameter and a few related lines of code, we can achieve a substantial improvement in image quality. The experimental results show that our method can be applied to all models that implement diffusion bridge through Doob's $h$-transform and has achieved state-of-the-art results in various tasks, especially in details where it is more realistic, including super-resolution, inpainting, and deraining. The inherent limitations of the network structures could potentially be propagated into our framework. We believe that UniDB is significant in the realm of images as well as in propelling research advancements in areas such as robot motion transfer and biomedical synthesis.
