\section{Related work}
Data pricing has been extensively studied in two main contexts: {\em data marketplaces} and {\em model marketplaces}. %Below, we review key approaches in each area.

% \smallskip

\noindent {\bf Data Pricing in Data Marketplaces.}
In data marketplaces, pricing mechanisms revolve around trading raw datasets or simple queries. Previous work has focused on pre-purchase decisions, where data is evaluated before it is accessed, which aligns with our setting. For instance, the importance of datasets is often quantified by metrics such as size, as explored by \cite{kushal2012pricing}, or privacy levels, as in \cite{parra2018optimized}. Other studies, such as \cite{xu2015privacy} and \cite{jaisingh2008privacy}, assess data importance based on its utility to consumers, proposing auction mechanisms and contracts to compensate data owners accordingly.

When it comes to \emph{query-based data pricing}, metrics like privacy levels directly impact the accuracy of responses, thereby influencing data value.
% have a direct impact on the accuracy of responses, influencing the value of the data. 
For instance, \cite{ghosh2011selling,roth2012conducting} propose auction mechanisms that incorporate privacy in queries, while \cite{ligett2012take} introduces a take-it-or-leave-it contract for count queries. Further work by \cite{dandekar2012privacy,zhang2020selling} expands these ideas to linear predictor queries and broader query settings.
% For example, \cite{ghosh2011selling} and \cite{roth2012conducting} design auction mechanisms that account for the privacy of data in queries, while \cite{ligett2012take} offers a take-it-or-leave-it contract for count queries. Further studies by \cite{dandekar2012privacy} and \cite{zhang2020selling} extend these ideas to linear predictor queries and more general query settings.

In data marketplaces, data importance is often easily quantifiable using metrics like size or privacy levels. However, in the context of \emph{model marketplaces}, the contribution of individual data points to machine learning model performance is more complex and requires novel pricing methods.

% \smallskip

\noindent {\bf Data Pricing in Model Marketplaces.} 
% In model marketplaces, data pricing is typically based on how much a dataset improves the performance of a machine learning model. \cite{abernethy2015low} pioneered the study of data pricing for machine learning tasks by presenting a theoretical framework that balances budget constraints with model performance. Most subsequent works, such as those by \cite{agarwal2019marketplace} and \cite{ghorbani2019data}, assume the benefit of a trained model is known and focus on how to fairly distribute rewards among data owners. A common approach is the application of the \emph{Shapley value} \cite{shapley1951notes}, which ensures that each data owner is compensated according to their contribution to the overall model.
In model marketplaces, data pricing is typically based on how much a dataset improves a machine learning model's performance. \cite{abernethy2015low} introduced a theoretical framework for data pricing that balances budget constraints with model performance. Subsequent works, such as those by \cite{agarwal2019marketplace} and \cite{ghorbani2019data}, assume the model's benefit is known and focus on fairly distributing rewards among data owners. A common method for this is the \emph{Shapley value} \cite{shapley1951notes}, which compensates each data owner based on their contribution to the model.

Various studies have refined the utility function used in Shapley value calculations by incorporating additional factors. \cite{ghorbani2019data} and \cite{jia2019efficient}, for example, include $K$-nearest neighbors and privacy considerations in their utility designs. \cite{liu2020dealer} builds on this by extending the Shapley value framework to model marketplaces. Other research, such as \cite{sim2020collaborative} and \cite{ohrimenko2019collaborative}, explores utility design in \emph{collaborative machine learning} scenarios, where data owners also serve as model consumers. In these cases, utility is defined either as the sum of the model's value to the owner and its marginal value to others \cite{ohrimenko2019collaborative}, or through metrics like information gain \cite{sim2020collaborative}. \cite{xu2021gradient} and \cite{hu2020trading} further define utility based on the cosine similarity of parameters or the privacy leakage of shared model parameters.

A common limitation of these works is that they often require training models on the entire dataset before compensating data owners. In practice, this assumption is often unrealistic, as data owners are usually hesitant to contribute their data upfront without proper guarantees or compensation.

%Addressing Data Pricing Without Direct Data Inspection

A more realistic setting, which is closer to our approach, has been explored by studies \cite{cong2020vcg,zhang2021incentive,sun2022profit}. \cite{cong2020vcg} assume that data importance is known and apply a \emph{VCG auction mechanism} to select and compensate data owners. \cite{zhang2021incentive} propose an auction mechanism that incorporates the reputation of data owners as a reflection of their contribution, while \cite{sun2022profit} design an auction that selects data owners based on their privacy requirements. Although these approaches offer valuable insights, they rely on exogenous metrics, such as reputation or privacy, which are often difficult to obtain or may not accurately reflect the intrinsic value of data for model training.

% In contrast, our work introduces a novel approach to \emph{measure data importance} without the need for direct data inspection. By focusing on the structural properties of graph-structured data and leveraging methods like structural entropy, we aim to develop a fair and effective data pricing mechanism that addresses the limitations of previous approaches.
In contrast, our work proposes a novel method to \emph{measure data importance} without direct data inspection. By focusing on the structural properties of graph data and using techniques like structural entropy, we aim to create a fair and effective data pricing mechanism that overcomes the limitations of previous methods.


% \smallskip

\noindent {\bf Comparison with FL and AL.} While {\em Federated Learning} (FL) and {\em Active Learning} (AL) are well-known paradigms for training models with distributed data, our approach differs in key ways.
{\bf (1)} In FL, each data owner trains a local model on private data, which is then aggregated into a global model while preserving privacy \cite{zhang2021survey}. SIMT, by contrast, does not require data owners to train models. Instead, data is directly provided to a central model, allowing for optimizations like data augmentation that are not possible in FL's gradient-based aggregation. This eliminates the computational burden on data owners and allows for more flexible model improvements. {\bf (2)} In AL, the model iteratively queries data points to refine learning, typically in multiple rounds \cite{ren2021survey}. SIMT, however, collects data in a single round, reducing overhead and cost. Furthermore, while AL assumes access to unlabeled data with labels provided iteratively \cite{cai2017active,zhang2021alg}, SIMT addresses the real-world challenge of compensating data owners, ensuring they are fairly rewarded for their contributions upfront.