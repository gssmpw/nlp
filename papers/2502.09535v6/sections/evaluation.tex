\section{Evaluation} \label{sec:security-evaluation}

This section critically evaluates our sensor entropy findings using existing literature and relevant standards. We then discuss potential mitigations such as randomness extractors, outline inherent limitations of our study and sensor-based approaches, and propose avenues for future enhancements.


%\subsection{Reflecting on Standards}

%NIST SP 800-90B~\cite{turan2018recommendation} articulates two pivotal requirements for noise sources: \emph{stationarity} of the distribution and \emph{protection from adversarial influence}. Our results show that many mobile sensors fail these criteria. Firstly, sensor readings often exhibit strong distributional shifts over time, across environments, and between users. This non-stationary nature violates the principle of a fixed, time-invariant distribution, making entropy notoriously difficult to estimate at a global level.

%Secondly, the potential to \emph{force} certain sensor readings (e.g.\ by controlling device motion or environmental stimuli) undermines the assumption that the noise source is free from external tampering. Even a partial leak of real-time sensor data can guide attackers toward the most probable states, substantially reducing unpredictability.  Consequently, using raw or lightly post-processed sensor readings to instantiate a cryptographic random source would flout NIST's guidelines on safe noise-source design.

\subsection{Discussion}
Prior studies have claimed or implied that mobile sensors are suitable data sources for security-critical applications. Much work has relied on model evaluation metrics as a proxy for evaluating such claims~\cite{mehrnezhad2015tap,gurulian2018good,markantonakis2024using,shrestha2014drone}, with a smaller subset using more established entropy metrics~\cite{wu2024t2pair,li2020t2pair}. However, analyses have demonstrated that \emph{individual} sensors confer very little entropy, especially under worst-case assumptions \cite{lv2020analysis,hennebert2013entropy,voris2011accelerometers,krhovjak2007sources}. Our results, derived from an analysis of multiple datasets and modalities (see Tables~\ref{tab:top10-uci-har}--\ref{tab:top10-shl}), corroborate and challenge these claims.

\textbf{Single sensors yield low entropy.} Building on prior work, we find that min-entropy often remains significantly below the Shannon estimates (e.g., some single-sensor readings yield only 1--3 bits). Our min-entropy estimates often remain significantly lower than their Shannon counterparts (e.g.\ some single-sensor readings yield only 1--3 bits of min-entropy).  This exposes a major gap between average- and worst-case unpredictability across 25 widely used sensors, which is a critical distinction that existing schemes and evaluations do not fully capture.
%

\textbf{Multiple sensors improve worst-case entropy, but not dramatically.} While combining more modalities typically raises the upper bound (e.g.\ Hartley or Shannon entropy), our experiments reveal that min-entropy gains are far smaller than one might hope. In some cases, $H_{\infty}$ plateaus, indicating that a few highly probable outcomes still dominate the distribution. Our findings place stricter bounds on the benefits and risks of mobile-sensor-based approaches. We estimate that even the most complicated multi-modal combination provide relatively little worst-case entropy. It is important to note that our analysis does not even incorporate adversarial perturbations, meaning real-world attacks could degrade unpredictability even further. Hence, while mobile sensors can \emph{augment} other authentication or key-generation processes, they rarely suffice as a standalone source. They might be useful for tasks where strong assurances are not required, e.g.\ simple proximity checks; however, relying on sensor data as robust entropy sources is fraught with security risks. 

%Min-entropy to estimate the likelihood of an attacker guessing sensor values. With some knowledge of the underlying distribution, an attacker will logically focus on estimating the most likely sensor values first, i.e.\ those with the highest probability. This is the rationale behind using min-entropy, rather than alternative metrics such as Shannon or max-entropy, which do not consider particular properties of distributions. We examined these results \emph{without adversarial perturbations}. 


\textbf{What can be done?} One might hope that cryptographic extractors (e.g.\ Von Neumann extractors or more advanced schemes~\cite{von195113,trevisan2001extractors,barak2003true}) could make low-entropy sensors suitable for usage. Extractors are designed to reduce bias in a noisy or skewed source; however, they cannot \emph{increase} the total amount of unpredictability beyond the source's intrinsic min-entropy. If combined sensor data provides, say, 24 bits of min-entropy, then post-processing can at best produce a short, unbiased bitstring reflecting those 24 bits, and no more. This means that an extractor can \emph{improve the \textbf{quality} of the randomness} (i.e., make it more uniform) but not \emph{increase the \textbf{quantity}} (i.e., its total brute-force resistance). Extraction enhances the quality of the original source if it has enough min-entropy, but it cannot elevate a source that fundamentally lacks it.

Another avenue is to introduce additional unpredictability through user interaction or deliberate environmental perturbation. For example, requiring the user to perform a random shaking gesture during a pairing protocol could inject extra entropy into the sensor readings. Prior studies have found that deliberate device movements can, indeed, increase the usable entropy of motion sensors, albeit only by a modest amount (on the order of a few bits)~\cite{voris2011accelerometers,lv2020analysis}. While this boost is non-negligible, it remains far below the dozens or hundreds of bits typically desired for security-critical applications. 

One possibility is to incorporate sensor-based randomness into an entropy pool that seeds a cryptographically secure pseudorandom number generator (CSPRNG). By doing so, a hybrid design can mitigate bias in the raw sensor data and produce outputs that pass statistical randomness tests (see the designs by Suciu et al.~\cite{suciu2011unpredictable} and Wallace et al.~\cite{wallace2016toward}). However, such an approach implicitly contradicts the rationale for many existing sensor-based applications, which leverage \emph{similarity} or \emph{correlation} in sensor readings, such as matching motion traces for device pairing or zero-interaction authentication~\cite{fomichev2019perils,mehrnezhad2015tap,shrestha2014drone,shrestha2018sensor,markantonakis2024using,mayrhofer2009shake}. Here, the desired property is not pure unpredictability but rather \emph{shared information} between the sensor signals collected by one or more devices. We have shown that sensor signals inherently have low entropy, even when using multiple sensors simultaneously, exposing a fundamental security flaw in such designs.

We see no straightforward remedy for the entropy shortfall of mobile sensors. Extractors, user-assisted randomness, and entropy pools address different problems: reducing bias, injecting small amounts of fresh entropy, or improving output distribution. Nevertheless, they do not compensate for fundamentally weak signals, which we have shown to be the case across a range of modalities. Sensor data and its derivatives may still be appropriate for low-security purposes. However, relying on it alone for security applications is highly inadvisable due to the serious risk of adversaries who exploit statistical biases to reduce the effective search space.

\subsection{Limitations}

Despite our detailed analysis, this work has some notable limitations. Firstly, while we analyse four large datasets, they do not fully capture contexts all possible contexts. Some work has suggested that performing dedicated movements (e.g.\ gestures) can increase the amount of usable entropy from motion sensors by 5--6 bits~\cite{lv2020analysis,voris2011accelerometers}. Our datasets do not cover such dedicated movements; it is possible that the reported results are an underestimation of entropy for sensors which are deliberately perturbed as an entropy-generating action. Secondly, our choice of Freedman-Diaconis binning and Chow-Liu trees is a pragmatic compromise. Smaller bin sizes tend to over-simplify the distribution and underestimate entropy, whereas larger bins can lead to computational blowup. As such, although our approach outperforms na\"{i}ve joint entropy estimation, it is still an approximation.  Thirdly, we largely focus on a data-centric view of entropy and do not examine other threats, such as sensor spoofing~\cite{shrestha2018sensor}, hardware attacks~\cite{shepherd2021physical} and cross-device correlation attacks (see \cite{dautov2019effects} against wireless body area networks). It is possible that these threats may reduce the entropy of sensors even further.
