\documentclass[fleqn,10pt]{wlscirep}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{tabularray}
\usepackage{rotating}
\usepackage{multirow}
\usepackage{hyperref}
\usepackage{physics}

\providecommand{\keywords}[1]{\textbf{Mots-cl√©s :} #1}
% package used by \citep and \citet
%\usepackage[sort&compress,square,comma,authoryear]{natbib}
%\bibliographystyle{plainnat}


\UseTblrLibrary{diagbox}
\title{Supervised contrastive learning for cell stage classification of animal embryos}

\author[1,*]{Yasmine Hachani}
\author[1]{Patrick Bouthemy}
\author[1,2]{Elisa Fromont}
\author[3]{Sylvie Ruffini}
\author[3]{Ludivine Laffont}
\author[3,4]{Alline de Paula Reis}
\affil[1]{Inria center at Rennes University, France}
\affil[2]{University of Rennes, IRISA, France}
\affil[3]{Paris-Saclay University, UVSQ, INRAE, BREED, France}
\affil[4]{The National Veterinary School of Alfort (EnvA), France}


\affil[*]{yasmine.hachani@inria.fr}

%\affil[+]{these authors contributed equally to this work}



\begin{abstract}
Video microscopy, when combined with machine learning, offers a promising approach for studying the early development of \textit{in vitro} produced (IVP) embryos. However, manually annotating developmental events, and more specifically cell divisions, is time-consuming for a biologist and cannot scale up for practical applications. We aim to automatically classify the cell stages of embryos from 2D time-lapse microscopy videos with a deep learning approach. We focus on the analysis of bovine embryonic development using video microscopy, as we are primarily interested
in the application of cattle breeding, and we have created a Bovine Embryos Cell Stages (ECS) dataset. The challenges are three-fold: (1) low-quality images and bovine dark cells that make the identification of cell stages difficult, (2) class ambiguity at the boundaries of developmental stages, and (3) imbalanced data distribution. To address these challenges, we introduce CLEmbryo, a novel method that leverages supervised contrastive learning combined with focal loss for training, and the lightweight 3D neural network CSN-50 as an encoder. We also show that our method generalizes well. CLEmbryo outperforms state-of-the-art methods on both our Bovine ECS dataset and the publicly available NYU Mouse Embryos dataset.
\end{abstract}




\begin{document}
\keywords{Cell-stage classification, Deep learning, Supervised contrastive learning, Time-lapse video, Embryonic development, Morphokinetics}
\flushbottom
\maketitle
% * <john.hammersley@gmail.com> 2015-02-09T12:07:31.197Z:
%
%  Click the title above to edit the author information and abstract
%
\thispagestyle{empty}

\section*{Introduction}

The analysis of embryonic development is of key interest to better understand biological mechanisms and to address a range of human and animal concerns.
When studying \textit{in vitro} produced (IVP) embryos, analysis can benefit from image sequences obtained from a video microscopy setup. In this paper, we will study the embryonic developmental stages of IVP embryos from time-lapse video sequences. The normal development of a mammalian embryo is characterized by a series of mitoses, in which each cell divides into two daughter cells (also known as cleavage).  Successive developmental stages, or cell stages, are characterized by a given number of cells, starting from one cell. We formulate this analysis of embryonic development as a supervised classification problem. Each class corresponds to a cell stage, and is related to a number of cells. This problem is unbalanced, and a large majority of images show a number of cells that is of a power of two. In the sequel, we will call intermediate stages the other cell stages (3-cell, 5-cell, 6-cell, and 7-cell stages). We will not proceed to an explicit numbering of cells based on cell segmentation as done in \cite{stage-detection-yolo}, but to a direct classification from images based on a deep learning approach.

Observation of embryos by conventional microscopy requires them to be removed from the incubator, which leads to disturbances in temperature and pH of the culture medium that can be detrimental for embryo development\cite{NGUYEN201864}.%\cite{WALTERS2020494}
Video microscopy performed directly in the incubator provides a reliable way of capturing images of embryos at regular and short intervals. It enables embryologists to determine cell numbers almost in real time, without interfering with the culture conditions required for normal embryo development. It also has the advantage of being compatible with
further transfer to establish a pregnancy\cite{FumieMAGATA20232022-131}.%\cite{vanMarion2023}. 
However, manually determining the number of cells is a time-intensive task and limits the extent to which laboratories equipped with a video microscope can make more extensive use of this information. This argues for automation. 

%The aim of this work is to propose an automatic alternative to manual annotation of the number of cells in the embryo of mammalian animals, based on bovine and mice datasets.


%Video microscopy, when used to study embryonic development, has the advantages of being compatible with
%further transfer to establish a pregnancy, supplying information in real time, and avoiding environmental disturbances due to the removal of the embryo from the incubator to perform observations.
%thought to follow a monotonic order constraint.
%The embryo undergoes several cycles in which each cell cleavage results in two daughter cells, cell cleavage drives its progression from the 1-cell stage to successive multicellular stages (2, 4, 8 and 16 cells) before reaching morula and blastocyst stages.
%, as illustrated in Figure \ref{fig:fiv}. 
%However, morphokinetic studies have shown the existence of abnormal cleavages and delay of development. Therefore, the timing of the different cell cleavages is of major importance for embryo development studies.

%For example, video microscopy has been beneficial for the investigation of early mechanisms involved in the developmental competence of the \textit{in vitro} produced (IVP) embryo, that is, its capacity to reach blastocyst stage. Initial studies showed the relationship between morphokinetic events and oxygen consumption that is related to metabolism, or aneuploidy due to cleavage anomalies.

%For example, a recent study using artificial intelligence allowed the prediction of embryo transferability (i.e., the ability of an early zygote to reach the blastocyst stage, compatible with the uterine environment) based on the very first events of development. Morphokinetics helps study transferability by producing information on the whole set of events that occur over a given period of development.
%%This last developments widens its interest for field applications. 
%The timing of the different cell cleavages of each embryonic cycle is a major information to achieve early prediction of embryo transferability. By early prediction, we mean before the blastocyst stage can actually be observed. 

We will focus on the analysis of bovine embryonic development using video microscopy, as we are primarily interested in the application for cattle breeding. Its use in the bovine domain is recent but promising. More specifically, it allows one to assess whether embryos can be transferred to a cow uterus or not\cite{sfr}. From an image processing perspective, images of bovine embryos are especially difficult to process due to their dark appearance as shown in Figure \ref{fig:embryo-dev}. To demonstrate the generality of our method, we will also apply it to the analysis of mouse embryonic development.

%Yet, it is crucial to predict the transferability of these embryos at an early stage to enable embryologists to select such embryos early and study the processes that enable them to become transferable. The timing of the different cell cleavages of each embryonic cycle is a major information to achieve this early prediction of embryo transferability. 
%However, visual observation is demanding, and manual annotation of every cell cleavage is time-consuming (about 20 minutes per embryo). Therefore, automating the prediction of cell stages from embryonic development videos is a key objective for scaling up and concrete applications. 

 %This problem could be tackled in two ways. Rather than identifying the cell stage to which the video image belongs, we could aim to detect successive cell divisions, since the transition between two cell stages is supposed to correspond to a cell division. However, the cell division may have diverse duration, and it might be tricky to accurately find its beginning and end. Therefore, we prefer to cope with cell stage classification. As usual,
 %We can then retrieve the timing of the end of a cell cleavage through a change of stage. 

%\begin{figure}[bh!]
%\centering
%\resizebox{\columnwidth}{!}{
    %\centering
%    \includegraphics[scale=0.20]
        %\includegraphics{Figures/FIV.png}}
    %\caption{The \textit{in vitro} production (IVP) process for bovine embryos.}
    %\label{fig:fiv}
%\end{figure}


%to transfer current developments to other laboratories and to the field.
%Embryo stage development classification is also a crucial problem in human reproductive medicine. 

Existing work dealing with cell stage classification and making use of deep learning techniques can be divided into two categories. The first category of work considers every frame of a time-lapse video independently and employs 2D convolutional neural networks (CNNs) to achieve the classification\cite{emca}. This is usually followed by a post-processing step that enforces a monotonic progression of the number of cells as done in \cite{stage-detection-fusion}, \cite{stage-detection-multi-task}, \cite{celldivision} and \cite{stage-detection-resnext}, all using dynamic programming to apply that constraint. In \cite{stage-detection-resnext}, the development stages are identified through several sub-steps that also take into account the rate of embryo fragmentation. In \cite{stage-detection-yolo}, the authors adopt an approach based on object detection using the YOLO-v5 network \cite{yolov5} and perform cell counting. Very recently, the DLT-Embryo method was proposed\cite{dlt-embryo}. It combines dual-branch local feature fusion (DLF) modules and transformer encoder modules to extract both local and global features from each frame. These methods make limited use of temporal information.
%although it may be crucial to correctly classify frames located just before a stage change.

Embryologists take into account dynamic information to decide the completion of the cell cleavage event. In addition, temporal context helps maintain consistency  between time-lapse images.
%In addition, temporal context allows to overcome the data imbalance issue between cell stages. 
The second category of methods integrates temporal information in the architecture, and then, exploits it as soon as the training stage.
%to address the points mentioned earlier. 

The ESOD method \cite{stage-detection-synergic} employs a 2D-CNN followed by a Long Short-Term Memory (LSTM) network classifier, and involves a synergic loss to learn embryo-independent features. The CNNs-CRF method proposed in \cite{cnn-crf} involves a conditional random field (CRF) to favor the monotonic progression of the number of cells. In addition, the neural network leverages temporal information through two streams with different input, one single frame for the first one and two concatenated consecutive frames for the second one. The R2D1 method \cite{stage-detection-r2d1-vit} considers the spatio-temporal video as a volume, uses 3D-CNN (i.e, 2D+t) to work directly on video sub-sequences, and applies the Viterbi algorithm to enforce a monotonic order constraint. The EmbryosFormer framework \cite{embryosformer} is the first to involve transformer architecture, building a three-headed encoder-decoder transformer inspired by the Deformable DETR model \cite{def_detr}. All of these methods, were evaluated on datasets of human and mouse embryos, except R2D1 which was evaluated only on humans.

%However, in real-life cases, bovine embryos may present abnormal events such as cell death, direct cleavage (i.e., one cell originates three or four daughter cells) or even reverse cleavage (i.e., two daughter cells merge after cleavage), which overrides the strict monotonic development, adding complexity to the problem. 
%In the past decade, some works focused on how to combine video microscopy with machine learning techniques to provide powerful and automatic tools to help with early transferability evaluation.


\begin{figure*}
\centering
\resizebox{\columnwidth}{!}{
    %\centering
%    \includegraphics[scale=0.20]
        \includegraphics{Figures/monotonic_dev_bovine_mouse.png}}
\caption{Sample images of the different cell stages of bovine (top row) and mouse (bottom row) embryo development. The bovine embryo only occupies a small part of the image, it is located in a micro-well (light grey) within the Petri dish (black). The bovine embryo is darker. The mouse embryo is more transparent. Both embryos are surrounded by the zona pellucida. Images are taken from the Bovine Embryo CS dataset and from the NYU Mouse Embryo dataset respectively.}
\label{fig:embryo-dev}
\end{figure*}

%parler de supervised contrastive learning avant dans l'intro ?
As stated before, our objective is to classify the cell stages of an animal embryo from 2D time-lapse videos acquired by video-microscopy. 
This prediction will be based on a 3D-CNN architecture and will leverage supervised contrastive learning (SCL)\cite{scl}. 
%As motivated above, we will not enforce any monotonic order constraint. 
%Our work is focused on the early stages of development (1 to 9 cells) because these are the stages of interest for the early prediction of transferability and are of high interest for any study of the morphokinetic characteristics of an embryo. 
We assume that the $n$-cell stage lasts until the $n+1$-cell stage appears.
We formulate this problem as a multi-class supervised classification. Each frame of an input time-lapse video will be assigned a class from the one-cell stage to the nine-and-plus-cell stage.  
%in which we include the morula stage.
%None of the frames can correspond to a blastocyst state as all the processed videos end before this state.

The classification problem is challenging, even if it is supervised.
%along with transparency effects.
%In addition, bovine embryo cells are notably dark, as illustrated in Figure \ref{fig:embryo-dev}.
%All this makes cell counting really tricky.
The cell classes are heavily imbalanced. The intermediate cell-stages are largely underrepresented. Frames located just around the end of a cell cleavage, consequently, around a stage change, are particularly hard to classify. In fact, immediately before the end of the daughter-cell separation, %membranes of the 
two daughter %new 
cells can be seen despite the incomplete membrane separation. In addition, immediately after complete separation, cell movements due to rearrangement of newly created cells in the embryo can be confused with the movements required for cell separation.
Embryo images usually show low contrast, significant noise, and intricate motion.
Bovine embryos are harder to study using video microscopy than their human or mouse counterparts due to the darkness of their cells. Cell cleavage may last longer than for mouse embryos.
%Regarding bovine embryos, the problem is particularly challenging. First, the microscopy videos of bovine embryos show low contrast, significant noise, and intricate motion.

%Tasks like counting cells are made more difficult.
Work that combines video microscopy and machine learning for bovine embryos is rare. In\cite{bovine_embryo0}, a method was developed for the prediction of embryo transferability based on random forests. It requires very detailed manual annotations of each video. In \cite{sfr}, we have designed a 3D-CNN called SFR that includes three paths and the focal loss\cite{focal}, to achieve transferability prediction directly from videos. To our knowledge, we are the first to propose a deep learning-based model to classify the stages of early development of bovine embryos and to leverage SCL for this kind of task.

SCL \cite{scl} is a contrastive learning technique that uses labeled data to learn more robust and semantically meaningful representations. It extends the principle of contrastive learning, which aims to pull similar data points closer in the representation space and push dissimilar ones further apart. SCL incorporates label information to define similarity and dissimilarity between samples. SCL has been shown to be a promising approach in the field of medical image analysis. 
It has been applied to a variety of tasks, including medical image classification \cite{scl-histo-classif}
%\cite{medical_data_scl_class}
and segmentation \cite{medical-image-scl-seg}.

%This paper is organized as follows. In the \hyperlink{sec:method}{Materials and Methods} section, we first present the two datasets we have considered. Then, we describe our method based on the SCL framework. The \hyperlink{sec:results}{Results} section reports quantitative and comparative evaluations of our method. The \hyperlink{sec:discussion}{Discussion} section contains concluding remarks.

\section*{Materials and methods}
\hypertarget{sec:method}{}
This work had several objectives: 1) to propose a new method for classifying bovine embryo cell stages, 2) to verify that it generalizes well to other mammal species, 3) to compare its performance with four other existing methods (ESOD, CNNs-CRF, EmbryosFormer, R2D1) commented in the Introduction section. The method was tested on our Bovine Embryos Cell Stage dataset (or Bovine ECS dataset for short) and the NYU mouse embryos dataset described below.
\subsection*{Datasets}
\subsubsection*{Bovine Embryos Cell Stage dataset}
We have acquired a video dataset of IVP bovine embryos that we call the Bovine ECS dataset. The embryo production process and the acquisition of embryo videos are described in this section. The main features of our dataset are also specified in the following.

%The cumulus-oocyte complexes (COCs) were recovered from slaughterhouse ovaries, rinsed three times in a holding medium (Euroflush, IVM technologies) and submitted to \textit{in vitro} maturation (IVM) in groups of 50-60 COCs in 500¬µl TCM-199 (Sigma) complemented with 10\% fetal calf serum (FCS, Invitrogen), 10¬µg/ml FSH (Folltropin-V, Reprobiol) and LH (Lutropin-V, Reprobiol), 1¬µg/ml oestradiol (Sigma), 1¬µg/ml EGF (Epidermal Growth Factor, Sigma) and 50¬µg/ml Gentamycin, during 22 hours at 38.5¬∞C and 5\% CO2 in air. After IVM, COCs were brought into contact with frozen-thawed semen of Holstein bulls (in vitro fertilization). Briefly, the semen was thawed for 30 seconds at 37¬∞C and the motile spermatozo√Ødes were selected using a discontinuous gradient Bovipure (40/80) following the instructions of the producer. Groups of 50 COCs were placed in 500¬µl of Tyrode fertilization medium containing 10¬µg/ml heparine, 20¬µM p√©nicillamine, 10¬µM hypotaurine and 1¬µM √©pin√©phrine (Parrish et al. 1986) with 1x106 spz/ml, for 22 hours, at 38.5¬∞C in 5\% CO2 in humidified atmosphere. The start of the IVF process was defined as the starting point of the embryo biological development\cite{bovine_embryo0}. After IVF, the  COCs were gently denuded and the presumtive zygotes were placed individually in Primovision dishes containing 16 microwells filled with a unique 120¬µl drop of embryo culture (synthetic oviductal fluid -Minitub/Inventio- supplemented with homemade heifer serum collected at day 3 after oestrus, equilibrated overnight before culture) under oil (ART-4008-5, Origio) for eight days at 38.5¬∞C, in 5\% CO\textsubscript{2}, 5\% O\textsubscript{2} and 90\% N\textsubscript{2} in humidified atmosphere.

The bovine embryos were obtained from oocytes recovered \textit{post mortem} on slaughterhouse ovaries, fertilized \textit{in vitro} and placed in the incubator in Primovision dishes containing 16 individual microwells filled with SOF (Synthetic Oviduct Fluid) medium under oil and cultured for eight days at 38.5¬∞C in a 5\%CO\textsubscript{2}, 5\%O\textsubscript{2} and 90\%N\textsubscript{2} humidified atmosphere.
The PrimoVision system is equipped with a transmission light microscope. Images of the Petri dishes were automatically taken every fifteen minutes throughout the embryo culture (from 22 to 192 hours of development). The resulting 2D time-lapse videos were subsequently divided into sixteen individual time-lapse videos. %The time instants of the beginning and end of each cell division were annotated by an embryologist. The references of cell stages for every frame are inferred from these annotations, and used for training and for evaluation.
The different cell stages of each embryo were then annotated by an embryologist: the first image presenting two daughter cells and their entire membranes was considered as a stage change. These annotations were used for training and evaluation.
The videos used for this study 
comprises 300 frames of 256 x 256 pixels. Knowing that the first frame was taken at the beginning of the embryo culture (at $t_0=22h$), and that the interval between two successive images was 15 minutes, the end of the 300-frame video corresponds to the fourth day of embryo development and between 8 and 16 cells for normal development in bovine species.
%For now, we consider only embryos that do not show a decrease in the number of cells due to reverse cleavage or cell death. 
%Bovine embryos are harder to study than their human and mouse counterparts, which generates a gap in dataset difficulty, as proved in the Results section. 
%Abnormal events of bovine embryos will be dealt with in future works. It is worth mentioning that all existing methods have been developed solely for human or mouse embryos following a monotonic order constraint.

Our final data set consists of 485 videos, of which 345 are kept for training our models, 50 are kept for parameter validation, and 79 videos are kept for evaluating the performance (test). Details on the data distribution of each cell stage in the dataset are given in Table \ref{tab:data-distrib}.



\subsubsection*{Mouse Embryos dataset}
We also consider mouse embryos to evaluate the generality of our proposed method. The NYU Mouse Embryo dataset\cite{mouse-dataset} contains 100 videos of developing mouse embryos, originally created for the task of cell tracking. They were acquired with a Nikon Eclipse Ti inverted microscope and a heated stage-top Tokai incubator. Each time-lapse video consists of 480 √ó 480 pixel images captured every seven minutes, resulting in 314 images per sequence on average. The image capture frequency is higher than for bovine videos, as mouse embryos develop faster. After downloading the dataset, we had access to 99 videos, divided into 72 sequences for training, 8 for validation, and 19 for testing. We used the annotations provided by  the authors of the CNNs-CRF\cite{cnn-crf} method.
%labeling the video frames from the first one to the second occurrence of the 8-cell stage.
Details on the data distribution of each cell stage in the dataset are also given in Table \ref{tab:data-distrib}.

\begin{table}[ht]
\centering
\caption{Distribution of cell stages across the Bovine ECS and Mouse Embryos datasets, for training, validation and test. We excluded the 8-cell stage frames of the Mouse Embryos dataset as they appear only in the last two frames of each video, making it extremely underrepresented and with a high risk to bias the model training phases.}
\begin{tabular}{c|ccc|c||c|ccc|c} 
\hline
\multicolumn{5}{c||}{Bovine}                                                                                                                    & \multicolumn{5}{c}{Mouse}                                                           \\ 
\hline
Cell stage                 & Train                      & Val                       & Test                       & Total                        & Cell stage          & Train & Val  & Test                     & Total               \\ 
\hline
1                          & 14780                      & 2619                      & 3005                       & 20404                        & 1                   & 3496  & 485  & 998                      & 4979                \\
2                          & 12267                      & 1753                      & 2973                       & 16993                        & 2                   & 11971 & 1311 & 3090                     & 16372               \\
3                          & 1139                       & 184                       & 273                        & 1596                         & 3                   & 567   & 49   & 138                      & 754                 \\
4                          & 9391                       & 1125                      & 2601                       & 13117                        & 4                   & 6353  & 715  & 1689                     & 8757                \\
5                          & 1292                       & 253                       & 267                        & 1812                         & 5                   & 354   & 31   & 76                       & 461                 \\
6                          & 2369                       & 200                       & 803                        & 3372                         & 6                   & 472   & 54   & 155                      & 681                 \\
7                          & 3225                       & 806                       & 826                        & 4857                         & 7                   & 620   & 39   & 96                       & 755                 \\
8                          & 34716                      & 3045                      & 7467                       & 45228                        & \multirow{2}{*}{} & \multicolumn{3}{c|}{\multirow{2}{*}{}} & \multirow{2}{*}{}  \\
9+                         & 24921                      & 5015                      & 9385                       & 39321                        &                     & \multicolumn{3}{c|}{}                   &                     \\ 
\hline
\multicolumn{1}{l|}{Total} & \multicolumn{1}{l}{204100} & \multicolumn{1}{l}{15000} & \multicolumn{1}{l|}{27600} & \multicolumn{1}{l||}{246100} & Total               & 23833 & 2684 & 642                      & 32759              
\end{tabular}
\label{tab:data-distrib}
\end{table}


\subsection*{Description of our method (CLEmbryo)}
We propose an original method, called CLEmbryo, to classify the cell stages that appear during embryonic development. It integrates three key components: (1) a modified version of the SCL framework, (2) a loss function that combines focal loss (FL) and supervised contrastive loss (called SupCon\cite{scl}), and (3) the Channel-Separated Convolutional Network (CSN)\cite{CSN} 3D-CNN architecture as an encoder.
%Our method does not enforce explicit constraint on the order of the cell stages, so that the developed solution can effectively be used in everyday applications without major adaptations.

\subsubsection*{SCL framework}
Inspired by the original paper on supervised contrastive learning\cite{scl}, our framework consists of four components: the data augmentation module $Aug(.)$, the encoder network $Enc(.)$, the projection network $Proj(.)$ and the classification network $Class(.)$.
The overall framework is presented in Figure \ref{fig:clembryo}. In contrast to recent implementations of the SCL framework with two losses and a single training stage, we also carry out a single training stage with two losses but corresponding to two heads,  classification head and projection head.

At training time, each video sequence $\textbf{v}\in\mathbb{R}^{T\times H\times W\times C}$, where $H$ and $W$ respectively denote the height and width of every image, $T$ the temporal length of the sequence, and $C$ the number of image channels, passes through the data augmentation module that generates random augmentations $\textbf{v}_i\in\mathbb{R}^{T\times H\times W\times C}$ representing different views with distinct information derived from the original input. The list of the augmentations taken into account is provided in the dedicated section below. Then, each view $\textbf{v}_i$ is processed independently.

The encoder embeds each frame of each sequence in a vector, $Enc(\textbf{v}_{i,t}) = \textbf{r}_{i,t} \in \mathbb{R}^{d_{emb}}$, $t\in \mathopen{[}1, T\mathclose{]}$. Every representation vector is normalized to the unit hypersphere in $\mathbb{R}^{d_{emb}}$. The projection head and the classification head process the representation vectors simultaneously. The projection head maps $\textbf{r}_{i,t}$ to a vector $\textbf{z}_{i,t} = Proj(\textbf{r}_{i,t})\in\mathbb{R}^{d_{proj}}$ to reduce the number of operations required to compute the SupCon loss. $Proj(.)$ is a single linear layer and all projection vectors are normalized to the unit hypersphere in $\mathbb{R}^{d_{proj}}$. Likewise, the classification head is a single linear layer that maps $\textbf{r}_{i,t}$ to a classification vector $\textbf{l}_{i,t} = Proj(\textbf{r}_{i,t})\in\mathbb{R}^{K}$, with $K$ denoting the number of classes, from which the focal loss is computed. 
Once training is achieved, both the data augmentation module and the projection head are removed, and inference is performed on the resulting architecture.
%as if the model had been trained within the usual framework. 
% $d_{proj} = 128 $ in all the experiments in the paper, with $d_{emb}$ dependent on the chosen neural network,  i=1, 2

\begin{figure}[t!]
\centering
\resizebox{\columnwidth}{!}{
    %\centering
%    \includegraphics[scale=0.20]
        \includegraphics{Figures/scl_training.png}}
    \caption{The SCL framework of our CLEmbryo method with the data augmentation module $Aug(.)$, the encoder network $Enc(.)$, the projection network $Proj(.)$ and the classification network $Class(.)$. The SupCon loss $\mathcal{L}_{SupCon}$ is computed using the output of $Proj(.)$, while the focal loss $\mathcal{L}_{FL}$ is computed with the output of $Class(.)$. The data augmentation module generates two augmented version of the original sequence, and each version is processed independently. We set $d_{proj}=128$ in all the experiments. The value of $d_{emb}$ depends on the encoder CNN and is set to 512 when CSN-50 is involved.}
    \label{fig:clembryo}
\end{figure}

\subsubsection*{Loss function}
The training loss involves two loss terms as illustrated in Figure \ref{fig:clembryo}, the SupCon loss and the classification loss.

The SupCon loss is built on the concept of contrastive loss extended to supervised scenarios by the authors of\cite{scl}. This loss adds information on whether two elements belong to the same class, thus helping to fix the limitations of self-supervised contrastive learning, which might push apart the representations of same class samples. By enforcing clustering within classes, the SupCon loss ensures that the encoder produces representations that are more robust and discriminative, ultimately to the benefit of downstream classification tasks. Let us consider N video sequences; the data augmentation module generates two augmented versions of each sequence. We note $\mathcal{I} = \{1,...,2N\}$  the set of indexes of all the augmented videos $\textbf{v}_i$ and $\textbf{y}_i\in[1,K]^T$ their associated vector of class labels.  For a given frame $\textbf{v}_{i, t}$, let us also consider $A(i,t) = \mathcal{I}\times \mathopen{[}1, T\mathclose{]} \setminus \{(i,t)\}$, the set of indexes of all the augmented frames except $\textbf{v}_{i,t}$ and $P(i, t) = \{(p, s) \in A(i, t), y_{p,  s}=y_{i,t}\}$, the set of indexes of all the augmented frames different from $\textbf{v}_{i, t}$ but with the same label. The SupCon loss writes:
\begin{equation}
\mathcal{L}_{SupCon} = \sum_{i\in \mathcal{I}}\sum_{t=1}^{T}\mathcal{L}_{SupCon}(\textbf{v}_{i,t},y_{i,t}) = \sum_{i\in \mathcal{I}}\sum_{t=1}^{T} -\frac{1}{|P(i,t)|}\sum_{(p, s)\in P(i,t)}\log(\frac{\exp(\frac{\textbf{z}_{i,t} \cdot \textbf{z}_{p, s}}{\tau})}{\sum_{(a, x)\in A(i,t)}\exp(\frac{\textbf{z}_{i, t} \cdot \textbf{z}_{a, x}}{\tau})}),
\end{equation}
with $\textbf{z}_{i,t} = Proj(Enc(\textbf{v}_{i,t}))$, and $\tau\in\mathbb{R}_{+}^{\ast}$ a scalar temperature parameter. 
As illustrated in \cite{multimodal-scl}, this loss can be used as an auxiliary objective during the training process.

We could adopt different loss functions for the classification objective. Since our data are unbalanced with respect to the cell stages, we have considered the focal loss\cite{focal}, initially introduced for the object detection task. The focal loss helps to mitigate this imbalance, while focusing on the most difficult examples. The focal loss writes:
\begin{equation}
\mathcal{L}_{FL} = \sum_{i \in \mathcal{I}}\sum_{t=1}^{T}\mathcal{L}_{FL}(\textbf{v}_{i,t},y_{i,t}) = \sum_{i \in \mathcal{I}}\sum_{t=1}^{T}-\sum_{k=1}^{K}\alpha_k(1-\hat{p}(k|\textbf{v}_{i,t}))^\gamma p(k|\textbf{v}_{i,t})\log\hat{p}(k|\textbf{v}_{i,t}),
\end{equation}
where $k$ denotes one of the K classes, $\hat{p}(k|\textbf{v}_{i,t})$ the predicted probability of having class $k$ given video frame $\textbf{v}_{i,t}$, and $p(k|\textbf{v}_{i,t})$ the true one. The latter is equal to $1$ if the right class $k$ is assigned to $\textbf{v}_{i,t}$, since we are dealing with supervised classification. In addition, $\alpha_k$ is the weight for class $k$, $\gamma$ the focusing parameter. The larger $\gamma$, the less importance is given to well-classified samples.

Our final objective function combines the proposed SupCon loss for representation learning and the focal loss for classification, as follows:
\begin{equation}
\mathcal{L}_{train} = w\mathcal{L}_{SupCon} + (1-w)\mathcal{L}_{FL}.
\end{equation}
\noindent In all experiments, we set $w=0.5$, $\tau=0.5$ and $\gamma=2$, this value for $\gamma$ being recommended in \cite{berntsen2022} and \cite{sfr}.

\subsubsection*{Encoder neural network}
We believe that a 3D-CNN network is more adapted to properly capture the spatio-temporal features characterizing the embryonic development, than for instance a recurrent neural network as demonstrated previously \cite{sfr}, \cite{stage-detection-r2d1-vit}. 
By 3D, we mean two spatial dimensions and the temporal one (2D+t). The 3D-CNN selected for the encoder must be both accurate and lightweight as 3D convolutions are computationally costly. For this reason, we chose the CSN \cite{CSN}, which effectively meets these requirements. The CSN architecture leverages group convolution to separate channel interactions from spatio-temporal interactions. This significantly reduces computational cost while preserving sufficient channel interactions to maintain high accuracy. We use CSN-50 with 50 layers and 13.6M parameters. For comparison, 3D-ResNet-50 approximately comprises 45M parameters. We have adapted the CSN architecture to avoid any reduction in time resolution. To ensure that a prediction is made for each frame in the sequence, we set pooling and stride to one in the temporal dimension.

\subsubsection*{Data augmentation}
\label{subsubsec:data-aug}
Data augmentation should introduce sufficient diversity in the versions of the original input without altering the biological meaning of the videos.
%In the data augmentation module,
Each augmentation is selected at random in a set of augmentation types, and is applied to
%and are applied consistently across
all images of a given sequence. The set of augmentations includes random change in brightness and contrast, horizontal and vertical flipping, random rotation from 0 to 30 degrees, random translation, random cropping, and cutout\cite{cutout} that occludes a square region, chosen at random, of the input video.

\subsection*{Implementation details}

Each model was trained using the AdamW optimizer \cite{adamw}, with a learning rate of $5\times10^{-4}$ and the other parameters kept at their default values. We applied a learning rate reduction by a factor of 0.1 in the plateau scheduler. When training CLEmbryo,
a random subsequence of consecutive frames is selected from each video at each epoch.
%We prefer to use a subsequence rather than the whole video, as only local temporal information is needed to classify the cell stage.
We prefer to use a subsequence rather than a single frame, as local temporal information is beneficial to classify the cell stage.
As for the size of the subsequence, the larger the time window, the more temporal context is provided, but this leads to higher computational costs. We set the size at ten, this choice being motivated in the ablation study. We trained the models using mini-batches of 32 samples in total, meaning that within the SCL framework, 16 different subsequences are randomly selected. We applied the stochastic weight averaging (SWA)\cite{swa} technique, which improves the generalization of our models by averaging the network weights obtained at several well-chosen epochs. We used early stopping to end training, when the loss computed on the validation set increases ten epochs in a row. Then, we selected the model at the epoch with the lowest loss in the validation set, which is feasible for supervised training.

During inference of our method, we use an overlapping rolling window technique with ten consecutive frames and a step of four, meaning that for frames not located at the beginning or the end of the sequence, their classification vector is computed as the mean of three classification vectors from the different overlapping windows.

%that we have applied to the Mouse Embryos dataset. We wanted to assess how much we could improve the performance of our method by imposing a monotonicity constraint. %on an easier dataset like this one.
We also developed a simple post-processing step to apply a monotonic growth constraint on the number of cells over time. We denote our method augmented with this added post-processing step as CLEmbryo\_PP, and its results are reported in the last column of Table \ref{tab:bovine-classif} and Table \ref{tab:mouse-classif}.
%The results are further improved for all evaluation metrics, generally slightly but significantly for the 6- and 7-cell stages.
Our post-processing step consists of a simple temporal heuristic that maintains label consistency over time. We substitute, within a sequence of label $k$, short intervals of labels $k^\prime , k^\prime \neq k$ for label $k$. Our extended method is hence able to detect and correct local errors, that is, some inconsistent transitions in CLEmbryo label output.
%Next, it ensures that the predicted sequences are monotonically non-decreasing after the initial cleaning of anomalies. 


\subsection*{Evaluation metrics}
To evaluate the performance of all methods, we consider three metrics: global accuracy, F1-score per class, and temporal accuracy. 
Global accuracy $\vartheta$ is the ratio of images correctly classified by the model, and is given by $\text{N}_{corr}/\text{N}_{total}$, where $\text{N}_{corr}$ is the number of correctly classified images and $\text{N}_{total}$ the total number of images. The F1-score per class is defined as the harmonic mean of precision (P) and recall (R) per class: $\text{F1} = 2 \text{P} \text{R} / (\text{P} + \text{R})$.
%\begin{equation}
%    \text{F1} = 2 \frac{\text{P} \text{R}}{\text{P} + \text{R}}.
%\end{equation}
Precision (P) and recall (R) are respectively defined by $\text{P} = \frac{\text{TP}}{\text{TP} + \text{FP}}$, and $\text{R} = \frac{\text{TP}}{\text{TP} + \text{FN}}$, where TP, TN, FP, and FN represent the number of true positives, true negatives, false positives, and false negatives, respectively.
The F1-score provides a balanced measure of the method performance.
%particularly in cases of class imbalance. 
Introduced by R2D1\cite{stage-detection-r2d1-vit}, the temporal accuracy $\zeta$ is defined as the average proportion of cell stage transitions predicted within a specified time range of the corresponding actual transitions. In this context, the time difference between the predicted and actual transitions is considered acceptable if it is less than a threshold that we set to two frames. This threshold accounts for variability in label annotations by different expert biologists.
%may differ up to two frames in their labeling due to the physiological motions of the cells around the blastomere cleavage.
We have: 
$\zeta = \frac{\theta-\theta_{far}}{\theta}$,
%\begin{equation}
%\zeta = \frac{\theta-\theta_{far}}{\theta},
%\end{equation}
%\noindent
where $\theta$ is the total number of cell stage transitions and $\theta_{far}$ refers to the number of transitions predicted more than two frames away from the ground truth.

\section*{Results}
\hypertarget{sec:results}{}

The results of the ablation study performed on the Bovine ECS dataset is presented in Tables \ref{tab:ablation} and \ref{tab:seq-length}. The results of the comparison of the ESOD, CNNs-CRF, EmbryosFormer, R2D1 and our CLEmbryo without or with post-processing (\_PP) on the Bovine ECS and the NYU mouse datasets are presented in Tables \ref{tab:bovine-classif} and \ref{tab:mouse-classif}, respectively. The results obtained on bovine or mouse embryos with pre-training on the mouse or bovine embryos respectively are presented in Table \ref{tab:pretraining}.

\begin{table}[ht]
\centering
\caption{Ablation study on our Bovine ECS dataset in terms of per-class F1-score, global accuracy, and temporal accuracy obtained by our method with cross-entropy and without SCL, our method with cross-entropy, and our method with the R(2+1)D-18 architecture. we carried out five evaluations each time with different training seeds, and we provide the mean and standard deviation. The best scores are highlighted in bold.}
\begin{tabular}{cc|ccc|c} 
\hline
\multicolumn{2}{l|}{\diagbox{Metrics}{Configuration}} & Cross-entropy w/o SCL & Cross-entropy         & Cross-entropy and R(2+1)D-18 & CLEmbryo                \\ 
\hline
\multirow{9}{*}{F1-score per class} & 1               & 86.36 ¬± 1.98          & \textbf{91.47 ¬± 0.72} & 90.94 ¬± 3.85                 & 90.98 ¬± 0.67            \\
                                    & 2               & 78.32 ¬± 3.61          & 84.99 ¬± 0.56          & 83.15 ¬± 6.42                 & \textbf{85.85 ¬± 0.72}   \\
                                    & 3               & 9.86 ¬± 3.36           & 12.21 ¬± 6.88          & 1.83 ¬± 2.61                  & \textbf{22.46 ¬± 5.49}   \\
                                    & 4               & 68.36 ¬± 4.46          & 75.76 ¬± 0.73          & 73.28 ¬± 7.17                 & \textbf{77.43 ¬± 0.92}   \\
                                    & 5               & 4.65 ¬± 1.92           & 5.67 ¬± 3.13           & 0.92 ¬± 1.65                  & \textbf{11.41 ¬± 4.78}   \\
                                    & 6               & 4.77 ¬± 0.79           & 7.54 ¬± 3.97           & 0.87 ¬± 1.13                  & \textbf{16.17 ¬± 12.92}  \\
                                    & 7               & 1.47 ¬± 1.20           & 1.80 ¬± 1.51           & 0.93 ¬± 1.18                  & \textbf{12.34 ¬± 6.70}   \\
                                    & 8               & 62.02 ¬± 2.75          & \textbf{65.78 ¬± 1.81} & 61.48 ¬± 7.36                 & 65.41 ¬± 1.88            \\
                                    & 9+              & 73.80 ¬± 4.98          & \textbf{78.46 ¬± 1.05} & 76.19 ¬± 5.14                 & 78.10 ¬± 0.67            \\ 
\hline
\multicolumn{2}{c|}{Accuracy ($\vartheta$)}                         & 70.09 ¬± 1.05          & \textbf{73.77 ¬± 0.63} & 71.45 ¬± 5.43                 & 73.57 ¬± 0.48            \\ 
\hline
\multicolumn{2}{c|}{Temporal accuracy ($\zeta$)}                & 28.72 ¬± 4.24          & 40.42 ¬± 1.41          & 26.87 ¬± 9.60                 & \textbf{45.48 ¬± 2.49}   \\ 
\hline
\multicolumn{2}{c|}{Number of parameters}             & 13.6M                 & 13.6M                 & 31.5M                        & 13.6M                   \\
\hline
\end{tabular}
\label{tab:ablation}
\end{table}

\begin{table}[th!]
\centering
\caption{Results on our Bovine ECS dataset, in terms of global accuracy and temporal accuracy, obtained by our CLEmbryo method trained with input sequence lengths of 3, 5, and 10 frames. we carried out five evaluations each time with different training seeds, and we provide the mean and standard deviation. The best scores are highlighted in bold.}
\begin{tabular}{l|lll} 
\hline
\diagbox{Metrics}{Sequence length} & \multicolumn{1}{c}{3} & \multicolumn{1}{c}{5} & \multicolumn{1}{c}{10}  \\ 
\hline
Accuracy ($\vartheta$)                          & 70.70 ¬± 1.71          & 71.31 ¬± 1.14          & \textbf{73.57 ¬± 0.48}   \\
Temporal accuracy ($\zeta$)                & 22.04 ¬± 2.27          & 28.60 ¬± 6.25          & \textbf{45.48 ¬± 2.49}   \\
\hline
\end{tabular}
\label{tab:seq-length}
\end{table}

\subsection*{Ablation study}
We carried out an ablation study on the components of our method. All the results are collected in Table \ref{tab:ablation}. First, we conducted an ablation experiment on the classification loss. We tested the cross-entropy loss instead of the focal loss. These two losses have different behaviors. The former is expected to provide better F1-scores on the most represented classes,
%i.e., 1-cell, 8-cells and 9+-cells
which should result in a better global accuracy. The latter enhances the F1-scores on less-represented or underrepresented classes,
%2-cells, 4-cells and on the underrepresented classes 3-cells, 5-cells, 6-cells and 7-cells
improving the temporal accuracy. In our context, the behavior of the focal loss is \textit{a priori} more desirable, as we value the detection of cell stage changes, which is confirmed by the results reported in Table \ref{tab:ablation}.
The goal of the second ablation study was to verify if the supervised contrastive learning framework does improve performance. Indeed, training CSN-50 within our supervised contrastive learning framework yields accuracy and temporal accuracy gains of 3.68 and 11.7 respectively. We also observe less variability on most evaluation metrics. 
Our last ablation experiment dealt with the encoder neural network. We compared CSN-50 and R(2+1)D-18\cite{r2d1} that achieved better results than a standard 3D-ResNet-18\cite{stage-detection-r2d1-vit}. All evaluation metrics display higher values with CSN-50, which justifies the choice of this CNN. In addition, CSN-50 is significantly lighter (13.6M parameters versus 31.5M). Incidentally, a transformer module is even heavier, for instance, it contains 41M parameters in the EmbryosFormer method.

Finally, we investigated the influence of the length of the input sequence on the performance of our CLEmbryo method. We trained our method with input sequence lengths of 3, 5, and 10 frames. We set the maximum sequence length to ten frames to allow a large enough batch size, which is very important for the contrastive learning-based method to converge\cite{scl}. The results are reported in Table \ref{tab:seq-length}. Global accuracy and temporal accuracy increase as the temporal window widens. This highlights the importance of providing sufficient temporal context to the contrastive learning-based method to converge.


\subsection*{Classification results}
We carried out comparative experiments on the classification of the developmental stages of bovine and mouse embryos. We performed the cell stage classification with our CLEmbryo method and four existing state-of-the-art methods, including EmbryosFormer\cite{embryosformer}, R2D1\cite{stage-detection-r2d1-vit}, CNNs-CRF\cite{cnn-crf} and ESOD\cite{stage-detection-synergic}. We were unable to compare our method with DLT-embryo as we did not have access to their code. All methods were evaluated on the same data split with five evaluations performed using the same set of training seeds. We pre-trained the 2D-ResNet-50 used by EmbryosFormer to extract visual features of each frame before letting the transformer process the temporal information, with a contrastive learning task based on the SimCLR framework\cite{simCLR}, for both datasets. SimCLR has proven to be a good pre-training method to learn efficient representations, including for biomedical images\cite{simCLR-pretraining}. We trained and tested R2D1 just as our method, using subsequences of ten consecutive frames.
%The classification results on the Bovine and the Mouse datasets are reported in Table \ref{tab:bovine-classif} and Table \ref{tab:mouse-classif} respectively. 

Our CLEmbryo method outperforms the four other methods for both datasets. It achieves higher scores for all metrics and all stages except the five cell stage for the Bovine ECS dataset and for all metrics and all stages for the Mouse Embryos dataset.

The results of all the compared methods obtained on the Bovine ECS dataset are presented in Table \ref{tab:bovine-classif}. This dataset is highly unbalanced, making the correct classification of the intermediate stages difficult. This explains the low scores obtained for these classes. CLEmbryo achieves better performance for all the F1-scores per class, except the 5-cell class, where EmbryosFormer performs better. CLEmbryo reaches a global accuracy of 73.57\% with high stability (standard deviation of 0.48). The temporal accuracy of our method is also considerably better with a gain of 18 points compared to the second-best score obtained by R2D1. ESOD could not handle the class imbalance at all and is unable to make a right prediction of the minority classes. 

From Table \ref{tab:mouse-classif}, we can observe that the Mouse Embryos dataset is easier to work with than the Bovine one. Indeed, the global accuracy obtained by our CLEmbryo method is 97.73\% for the mouse %first 
dataset, while it was 73.57\% for the bovine dataset. %second one. 
CLEmbryo has the best results for all evaluation metrics for the mouse dataset.
We did not include the mouse 8-cell stage as
this dataset is very specific for this cell stage. The 8-class stage occurs only and systematically in the last two frames of each video. Then, this cell stage is largely under-represented and this constant configuration can bias training. 
%except 8-cells, where it fails to correctly predict the class without post-processing. 
%The same applies to R2D1 and ESOD, while CNNs-CRF  hardly makes a correct prediction either.
%Only EmbryosFormer, that process the video as a whole and enforce the presence of all classes with the segmentation head during training, achieves good results for this class. However, imposing the presence of all classes is a strong statement that cannot be applied in all situations.
%Our results obtained with the EmbryosFormer method are significantly lower than the results obtained by the authors that proposed the method \cite{embryosformer}.
Regarding EmbryosFormer, the results we obtained are significantly lower than those published by the authors in their paper\cite{embryosformer} (global accuracy of 98.4\%). This may be due to the way the 2D-ResNet-50 module was pre-trained, and to the choice of data split. In addition, the authors reported results obtained from one single experiment, which may unintentionally hide a variability issue.
%We contacted the authors who gave us their agreement to publish the results we obtained with their code.

We also applied to both datasets the simple post-processing step of CLEmbryo\_PP that is described in the section on implementation details. Results obtained with CLEmbryo\_PP are slightly better than CLEmbryo ones for the Mouse Embryos dataset as shown in Table \ref{tab:mouse-classif}. For the Bovine ECS dataset, results are mixed. 
This suggests that on a difficult dataset, where more prediction errors may occur and errors of different types, our heuristic may not be able to mitigate all the errors.
%and could have a detrimental effect in some cases.
%on predicted labels can propagate errors and lead to lower scores.

\begin{table}[ht]
\centering
\caption{Comparison of results obtained on our Bovine ECS dataset. For each method, we carried out five evaluations, each time with different training seeds, and we provide the mean and standard deviation for the per-class F1-score, global accuracy, and temporal accuracy. The best scores are highlighted in bold, excluding CLEmbryo\_PP. CLEmbryo\_PP
corresponds to our method with a post-processing step added.}
\begin{tabular}{cc|cccc|c||c} 
\hline
\multicolumn{2}{l|}{\multirow{2}{*}{\diagbox{Metrics}{Methods}}} & ESOD          & CNNs-CRF     & EmbryosFormer         & R2D1         & CLEmbryo               & CLEmbryo\_PP   \\ 
\cline{3-8}
\multicolumn{2}{l|}{}                                            & VGG-16        & ResNet-50    & ResNet-50             & R(2+1)D-18   & CSN-50                 & CSN-50         \\ 
\hline
\multirow{9}{*}{F1-score per class} & 1                          & 65.59 ¬± 36.70 & 84.60 ¬± 2.49 & 87.87 ¬± 1.87          & 89.90 ¬± 0.71 & \textbf{90.98 ¬± 0.67}  & 90.66 ¬± 0.62   \\
                                    & 2                          & 62.53 ¬± 6.38  & 77.87 ¬± 3.88 & 81.55 ¬± 0.55          & 81.09 ¬± 0.68 & \textbf{85.85 ¬± 0.72}  & 85.67 ¬± 0.50   \\
                                    & 3                          & 0 ¬± 0         & 4.67 ¬± 2.68  & 11.06 ¬± 3.93          & 9.08 ¬± 4.56  & \textbf{22.46 ¬± 5.49}  & 21.73 ¬± 5.42   \\
                                    & 4                          & 9.79 ¬± 11.88  & 66.21 ¬± 2.39 & 72.99 ¬± 1.60          & 69.52 ¬± 2.57 & \textbf{77.43 ¬± 0.92}  & 78.06 ¬± 2.22   \\
                                    & 5                          & 0 ¬± 0         & 7.92 ¬± 8.65  & \textbf{11.47 ¬± 2.65} & 5.91 ¬± 3.51  & 11.41 ¬± 4.78           & 10.52 ¬± 4.44   \\
                                    & 6                          & 0 ¬± 0         & 0.69 ¬± 0.39  & 5.67 ¬± 1.25           & 7.83 ¬± 7.04  & \textbf{16.17 ¬± 12.92} & 16.21 ¬± 14.92  \\
                                    & 7                          & 0 ¬± 0         & 9.23 ¬± 17.86 & 3.97 ¬± 1.35           & 5.34 ¬± 1.93  & \textbf{12.34 ¬± 6.70}  & 13.56 ¬± 12.15  \\
                                    & 8                          & 21.57 ¬± 22.74 & 49.63 ¬± 6.27 & 54.30 ¬± 1.54          & 57.85 ¬± 1.49 & \textbf{65.41 ¬± 1.88}  & 66.95 ¬± 2.28   \\
                                    & 9+                         & 64.48 ¬± 2.63  & 74.59 ¬± 1.15 & 68.16 ¬± 1.78          & 75.36 ¬± 1.49 & \textbf{78.10 ¬± 0.67}  & 77.29 ¬± 2.44   \\ 
\hline
\multicolumn{2}{c|}{Accuracy ($\vartheta$)}                                    & 51.54 ¬± 4.47  & 65.61 ¬± 1.89 & 65.04 ¬± 0.54          & 69.48 ¬± 0.33 & \textbf{73.57 ¬± 0.48}  & 73.05 ¬± 1.12   \\ 
\hline
\multicolumn{2}{c|}{Temporal accuracy ($\zeta$)}                           & 4.16 ¬± 1.61   & 26.10 ¬± 2.21 & 25.42 ¬± 2.65          & 27.26 ¬± 1.49 & \textbf{45.48 ¬± 2.49}  & 46.35 ¬± 2.53   \\
\hline
\end{tabular}
\label{tab:bovine-classif}
\end{table}

\begin{table}[ht]
\centering
\caption{Comparison of results obtained on the Mouse Embryos dataset\cite{mouse-dataset}. For each method, we carried out five evaluations, each time with different training seeds, and we provide the mean and standard deviation for the per-class F1-score, global accuracy, and temporal accuracy. The best scores are highlighted in bold, excluding CLEmbryo\_PP. CLEmbryo\_PP corresponds to our method with a post-processing step added.}
\begin{tabular}{cc|cccc|c||c} 
\hline
\multicolumn{2}{l|}{\multirow{2}{*}{\diagbox{Metrics}{Method}}} & ESOD         & CNNs-CRF       & EmbryosFormer & R2D1          & CLEmbryo               & CLEmbryo\_PP      \\ 
\cline{3-8}
\multicolumn{2}{l|}{}                                           & VGG-16       & ResNet-50      & ResNet-50     & R(2+1)D-18    & CSN-50                 & CSN-50         \\ 
\hline
\multirow{7}{*}{F1-score per class} & 1                         & 98.26 ¬± 1.08 & 98.66 ¬± 2.08   & 98.43 ¬± 0.59  & 95.65 ¬± 1.34  & \textbf{99.61 ¬± 0.04}  & 99.62 ¬± 0.03   \\
                                    & 2                         & 95.52 ¬±2.66  & 98.33¬± 0.72    & 98.16 ¬± 0.55  & 97.43 ¬± 0.97  & \textbf{99.58 ¬± 0.10}  & 99.58 ¬± 0.11   \\
                                    & 3                         & 0 ¬± 0        & 24.05 ¬± 37.38  & 70.68 ¬± 6.99  & 34.19 ¬± 23.97 & \textbf{90.20 ¬± 3.40}  & 90.92 ¬± 3.09   \\
                                    & 4                         & 86.18 ¬± 4.33 & 90.44 ¬± 2.50   & 94.58 ¬± 1.31  & 94.14 ¬± 1.04  & \textbf{98.97 ¬± 0.87}  & 99.50 ¬± 0.17   \\
                                    & 5                         & 0 ¬± 0        & 6.26 ¬± 10.86   & 28.62 ¬± 5.64  & 14.37 ¬± 11.17 & \textbf{70.36 ¬± 6.16}  & 72.69 ¬± 3.63   \\
                                    & 6                         & 8.71 ¬± 19.48 & 6.19 ¬± 11.54   & 45.56 ¬± 8.85  & 19.56 ¬± 3.76  & \textbf{69.32 ¬± 10.54} & 81.50 ¬± 6.91   \\
                                    & 7                         & 0 ¬± 0        & 0.51 ¬± 1.02    & 61.48 ¬± 0.51  & 40.52 ¬± 20.76 & \textbf{72.71 ¬± 5.51}  & 83.40 ¬± 7.43  \\ 
\hline
\multicolumn{2}{c|}{Accuracy ($\vartheta$)}                                   & 89.57 ¬± 2.67 & 92.24 ¬± 1.51   & 94.54 ¬± 0.71  & 91.98 ¬± 0.88  & \textbf{97.73 ¬± 0.61}  & 98.62 ¬± 0.44   \\ 
\hline
\multicolumn{2}{c|}{Temporal accuracy ($\zeta$)}                          & 2.91  ¬± 3.61 & 38.07  ¬± 17.43 & 69.69 ¬± 1.69  & 43.30 ¬± 9.34  & \textbf{85.14 ¬± 3.00}  & 85.69 ¬± 2.11   \\
\hline
\end{tabular}
\label{tab:mouse-classif}
\end{table}

\subsection*{Pretraining}

\begin{table}[ht!]
\centering
\caption{Results on our Bovine ECS (respectively Mouse Embryos) dataset, in terms of per-class F1-score, global accuracy, and temporal accuracy, obtained by our CLEmbryo method pre-trained on the Mouse Embryos (respectively Bovine Embryos) dataset. we carried out five evaluations each time with different training seeds, and we provide the mean and standard deviation. The best scores are highlighted in bold.}
\begin{tabular}{cc|cc|cc} 
\hline
\multicolumn{2}{l|}{\multirow{2}{*}{\diagbox{Metrics}{Pretraining}}} & \multicolumn{2}{c|}{Bovine}                    & \multicolumn{2}{c}{Mouse}                       \\ 
\cline{3-6}
\multicolumn{2}{l|}{}                                                & No pretraining         & Pretraining           & No pretraining         & Pretraining            \\ 
\hline
\multirow{9}{*}{F1-score per class} & 1                              & 90.98 ¬± 0.67           & \textbf{92.18 ¬± 0.79} & 99.61 ¬± 0.04           & \textbf{99.65 ¬± 0.05}  \\
                                    & 2                              & \textbf{85.85 ¬± 0.72}  & 85.08 ¬± 1.16          & 99.58 ¬± 0.10           & \textbf{99.70 ¬± 0.11}  \\
                                    & 3                              & 22.46 ¬± 5.49           & \textbf{28.60 ¬± 2.14} & 90.20 ¬± 3.40           & \textbf{93.98 ¬± 1.48}  \\
                                    & 4                              & 77.43 ¬± 0.92           & \textbf{77.84 ¬± 0.98} & 98.97 ¬± 0.87           & \textbf{99.09 ¬± 0.27}  \\
                                    & 5                              & 11.41 ¬± 4.78           & \textbf{15.83 ¬± 5.63} & \textbf{70.36 ¬± 6.16}  & 69.11 ¬± 7.11           \\
                                    & 6                              & \textbf{16.17 ¬± 12.92} & 15.27 ¬± 2.84          & \textbf{69.32 ¬± 10.54} & 64.31 ¬± 9.62           \\
                                    & 7                              & 12.34 ¬± 6.70           & \textbf{24.05 ¬± 5.53} & 72.71 ¬± 5.51           & \textbf{74.75 ¬± 3.94}  \\
                                    & 8                              & 65.41 ¬± 1.88           & \textbf{66.02 ¬± 1.40} &                        &                        \\
                                    & 9+                             & 78.10 ¬± 0.67           & \textbf{78.68 ¬± 0.68} &                        &                        \\ 
\hline
\multicolumn{2}{c|}{Accuracy ($\vartheta$)}                                        & 73.57 ¬± 0.48           & \textbf{74.17 ¬± 0.41} & 97.73 ¬± 0.61           & \textbf{97.85 ¬± 0.34}  \\ 
\hline
\multicolumn{2}{c|}{Temporal accuracy ($\zeta$)}                               & 45.48 ¬± 2.49           & \textbf{50.18 ¬± 2.82} & 85.14 ¬± 3.00           & \textbf{87.89 ¬± 2.19}  \\
\hline
\end{tabular}
\label{tab:pretraining}
\end{table}

Finally, we wanted to know if pretraining our method on the Mouse Embryos (respectively Bovine ECS) dataset could be beneficial on the Bovine ECS (respectively Mouse Embryos) dataset. Although the Bovine Embryos dataset is harder to process than its mouse counterpart, both datasets show similar events and patterns. It is now well-known that pretraining a deep learning model on another dataset is usually beneficial \cite{pretraining}. Results are reported in Table \ref{tab:pretraining}. In both cases, pretraining slightly improves performance as confirmed by almost all evaluation metrics. In particular, we achieve a significant gain in temporal accuracy. 
%Since pre-training is beneficial for the model, it is better able to detect changes in cell stages.

\section*{Discussion}
\hypertarget{sec:discussion}{}
We developed a novel method for predicting the cell stages of animal embryos and assessed its performance %evaluated it 
on embryo video datasets for two different species: bovine and mouse\cite{mouse-dataset}. We also elaborated a video dataset of annotated bovine embryos. %morphokinetic events. %algorithm adapted to predict the number of cells on the bovine embryo. 
This bovine biological material is particularly challenging because of the darkness of the cells due to the presence of high quantities of intracellular lipids\cite{Hirotada2001},\cite{Abe2002},\cite{GENICOT20051181}. This results in a lack of detail in the bovine embryo cells compared to mouse and human embryos that present a higher degree of transparency.
%Despite these difficulties, the pattern of embryonic development based on successive mitoses consisting of a sequence of division of the cells into daughter cells spaced apart by an interval allowing nuclear material to be duplicated for subsequent daughter cells separation is well conserved between mammalian species. This feature, common to the mammals, enabled us to compare the algorithm performance on bovine and mouse embryos.

%of bovine embryos from 2D time-lapse microscopy videos. 
In summary, we formulated the problem as a supervised multi-stage classification while overcoming imbalanced data distribution.
%a class ambiguity at the boundaries of cell stages, and a severe
%We do not enforce a monotonic order constraint on the cell stages unlike other existing methods. 
Our experiments demonstrated the interest of introducing, for this classification task, supervised contrastive learning, focal loss training, and the lightweight 3D convolutional network CSN-50 as sub-sequence encoder. 
We have shown that our CLEmbryo method generalizes well. CLEmbryo was able to produce convincing results on embryos from different animal species and on videos acquired with different setups.

We favorably compared our CLEmbryo method with other state-of-the-art methods on both the Bovine ECS dataset and the NYU Mouse Embryos dataset. CLEmbryo provides the best scores for almost all of the evaluation metrics, while remaining lightweight. This allowed us to efficiently and accurately predict the cell stages of animal embryos.
The improved performance of CLEmbryo is first due to the supervised contrastive learning framework. Adding this auxiliary head to the network to bring the embedding vectors of the same class of images closer together, results in a more robust and accurate model. The focal loss allowed us to improve the results on the less represented and underrepresented classes, thereby increasing the temporal accuracy of our method. %This characteristic is of major interest for embryonic stage analysis, because the intermediate stages of embryonic cycles (3, 5, 6 and 7 cells) are very dynamic and short-lived, resulting in a strong imbalance between these stages and the longer-lived stages 1, 2, 4 and 8 cells.
The choice of the network architecture is also impactful.
Unlike LSTM used in\cite{stage-detection-synergic}, 3D-CNN focuses on local temporal view of the input sequence\cite{lstm-3dcnn}, which allows it to better capture short intervals of intermediate cell stages. The LSTM architecture is more sensitive to this class imbalance, since it leads to a more global temporal view of the input, and therefore, is unable to focus on the short appearance of intermediate classes.
On our side, CLEmbryo does not require the integration of the monotonic growth constraint
%we did not need to integrate the monotonic order constraint on the cell number
to get better results than the other methods. This makes our method more flexible. Nevertheless,  the addition of a post-processing step may further improve results. In addition, our method provides results with low variability. This property of stability is of fundamental importance for biologists.

%CSN-50 is both efficient and effective as an encoder.
%comm

Although CLEmbryo performs very well on the Bovine ECS dataset, there is still room for extension. 
It is now known that IVP embryos can present variable cleavage durations and cleavage errors such as direct cleavage, i.e., division of a cell directly into three or four daughter cells, or reverse cleavage, i.e., cleavage followed by fusion of the daughter cells. These variations have a direct influence on embryo viability. Consequently, it is key to determine the number of cells in an embryo at any given time.
The CLEmbryo correctly manages normal and direct cleavage but has not yet been tested on reverse cleavage. It should be able to handle it since it does not involve the monotonic growth constraint. The frequency of reverse cleavage is not widely documented but may reach up to 25\% of transferable embryos in some studies and may reduce the quality of these embryos\cite{Jin2022},\cite{Sugimura2025}. Therefore, it deserves to be addressed in future work. This is challenging because reverse cleavage embryos have unstable developmental dynamics; after cell division, the number of cells can increase and then decrease to the initial number due to the fusion of two daughter cells.
Consequently, our future work will also involve the extension of our dataset of bovine embryo videos to include examples of such cleavage behavior.
%should be able to solve this problem because,
%unlike other methods, does not include the monotonic order constraint by design.
%A second step further will be to determine the duration of cleavages of an embryonic cycle. To do so, it would be necessary to step outside the classification framework and focus on detecting the specific patterns of cell cleavage including the formation of two new membranes from a single one. At present, existing works, including ours, focus solely on cell stage classification. 
%First, while we do not enforce the monotonic order constraint, we did not evaluate our method on videos that do not follow this constraint. Indeed, processing these videos implies further adaptations that still need to be developed such as detecting cellular deaths or reverse cleavages. This task would require the creation of a standardized dataset with annotations of these specific events. Furthermore, while cell stage classification provides important information for biologists studying morphokinetics, it would also be valuable to provide the exact cleavage timing. To do so, it would be necessary to step outside the classification framework and focus on detecting the specific movements of cell cleavage and the formation of two new membranes from a single one. At present, existing works, including ours, focuses solely on cell stage classification.
More research is also needed to determine the exact timing of cell divisions.  A cell division may last several minutes and be documented through successive frames.
%Cell divisions can take place over several frames, depending on the cell stage and the individual. 
The transition from one cell stage label to the next between two frames is not sufficient to infer the precise timing of the start and end of cell division. This would require going beyond the cell stage classification process.
%The transition from one cell stage label to the next, which now happens instantaneously between two frames, is not sufficient to infer the precise timing of the start and end of cell division. Including such transition labels might be necessary to extract richer information from these videos. To work on these transitions, it would be necessary to step outside the classification framework and focus on detecting the specific patterns of cell cleavage including the formation of two new membranes from a single one. At present, existing works, including ours, focus solely on cell stage classification.  

%The CLEmbryo developed in this work represents an important progress for biologists, especially those working on the bovine species because it allows rapid and efficient cell count with very low level of variation. Bovine embryos could be a good model for the development of algorithms devoted to the embryo, because their intrinsic characteristics impose demanding developments in image analysis that contribute to improving performances obtained on embryos of other species. 

\bibliography{sample}


\section*{Acknowledgements}
The authors would like to acknowledge the collaboration of Dr. V√©ronique Duranthon and Brigitte Marquant-LeGuienne for the experimental protocol design for the embryo production.
The production of the original embryo data was funded by CRB-Anim.
Yasmine Hachani's doctoral fellowship is funded by Inria-INRAE. Operation of the research project is also partly funded by the DIGIT-BIO program of INRAE.


\section*{Author contributions statement}
Y.H., P.B., E.F., and A.D.P.R. conceived this research work and the experiments. Y.H. implemented the software, ran the experiments. A.D.P.R., S.R and L.L produced the bovine embryos and acquired the videos with the Primovision system. A.D.P.R. annotated the videos. Y.H., P.B., E.F., and A.D.P.R wrote the paper. Y.H. drew the figures.

\section*{Additional Information}

\section*{Competing interests}
The authors declare no competing interests.

\section*{Approval for animal experiments}
This research study was conducted using data available in our laboratory. No live animals or euthanised animals were used to create the original data. The semen was acquired from a commercial company and the cumulus oocyte complexes were harvested from ovaries recovered \textit{post-mortem} in a commercial slaughterhouse. Both these companies and our laboratory are based in France and state-approved. The necessary authorisations for the use of \textit{post-mortem} biological material have been obtained from the responsible Ministry.







\end{document}
