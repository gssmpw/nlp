\section{Orchestration For Fat-Tree}
\label{appendix:orch-algo}
In this section, we introduce the orchestration algorithm under Fat-Tree DCN in detail.

\para{Notations}
\label{appendix:orch-algo:notation}
To ensure rigorous mathematical reasoning, we introduce the following notations:

\begin{itemize}
    \item {
        $n$: number of nodes in the data-center.
    }
    \item {
        $K$: \docs{} bundle (see \S\ref{section:design:topology}).
    }
    \item {
        $S_{all}$: ordered set, represents all nodes numbered from 1 according to their physical connection order in DCN fabric. $|S_{all}|=n$.
    }
    \item {
        $S$: ordered subset, represents nodes, $\forall u \in S, u \in S_{all}$. Adjacent elements in $S$ are also adjacent from the perspective of the \SYS{} topology. 
    }
    \item{
        $E$: The set of edges across $S$, should be equal to $\{ (S_i, S_j) \mid 1 \leq i < j \leq n, j - i \leq K \} $, representing the connections between nodes, including both primary and backup links, and $O(|E|) = O(K|S|)$.
    }
    \item {
        $InfHBD=<S,E>$: the topology of \SYS{} as an undirected graph.
    }
    \item {
        $F$: faulty nodes.
    }
    \item {
        $HealthyHBD=<H,HE>$: healthy node subgraph where the set of healthy nodes $H = S - F$ and the edge set $HE = \{ (u, v) \mid u \in H \text{ and } v \in H \text{ and } (u, v) \in E \}$.
    }
    \item{
        $t$: TP size, number of GPUs in one TP Group.
    }
    \item{
        $r$: GPU ranks per node.
    }
    \item{
        $m=t/r$: number of nodes in a TP group.
    }
    % \item{
    %     $k$: number of rails in rail-optimized network.
    % }
    \item{
        $s$: job scale, number of GPUs required for the job.
    }
    \item{
        $d$: Aggregation-Switches Domain size. Number of nodes under coverage of one group of Aggregation-Switches.
    }
    \item{
        $n_{constrains}$: number of applied constraints in binary-search-based orchestration algorithm.
    }
    \item{
        $p$: number of nodes under each ToR.
    }
    \item{
        $l$: shortest sub-line length under fat-tree orchestration.
    }
    \item{
        $n_{maxsubline}=\lfloor \frac{nd}{p} \rfloor$: max number of sub-lines.
    }
    \item{
        $G_{deploy}=<S_{deploy},E_{deploy}>$: deployed topology. After applying the deployment strategy, the topology from the perspective of \SYS{} is described as follows: $S_{\text{deploy}}$ is an ordered set where adjacent elements correspond to adjacent nodes in \SYS{}, and $E_{\text{deploy}}$ represents the connections between nodes.
    }
    
\end{itemize}


% For the \SYS{} the orchestration algorithm in ideal conditions is relatively straightforward. The detailed steps of the algorithm are outlined in \algref{alg:orchestration-ideal}.

% Assume that the \SYS{}(with \docs{} direction $K$) is represented as an undirected graph $ \text{InfHBD} = \langle S, E \rangle $, where the ordered set of nodes $ S $ represents nodes. Adjacent elements in $S$ are also adjacent from the perspective of the \SYS{} topology. The set of edges $E$ should be equal to $\{ (S_i, S_j) \mid 1 \leq i < j \leq n, j - i \leq K \} $, representing the connections between nodes, including both primary and backup links, and $O(|E|) = O(K|S|)$. The set of faulty nodes is denoted as $ F \subseteq S $.

% The algorithm proceeds as follows:

% \begin{enumerate}
%     \item {\textbf{Extract the Healthy Node Subgraph:} First, extract the subgraph $\text{HealthyHBD} = \langle H, HE \rangle$ where the set of healthy nodes $H = S - F$ and the edge set $HE = \{ (u, v) \mid u \in H \text{ and } v \in H \text{ and } (u, v) \in E \}$. See \algref{alg:orchestration-ideal}.
%     }
%     \item {\textbf{Identify Connected Components:} Next, identify all connected components in the graph $\text{HealthyHBD}$. Faulty nodes may cause disconnections in the \SYS{} fabric, splitting the original cluster into multiple sub-HBDs. These sub-HBDs are the connected components, and TP Groups cannot span across these disconnected sub-HBDs. We use a simple Depth-First Search (DFS) algorithm here. See \algref{alg:dfs}.}
%     \item {\textbf{Generate Placement Scheme:} Given the excellent physical properties of the \SYS{}, TP Groups can be arranged sequentially within each connected component to generate placement scheme maximizing GPU utilization. See \algref{alg:orchestration-ideal}.
%     }
% \end{enumerate}

% Since each of the three steps involves traversing the entire graph's edges and nodes only once, 
The orchestration algorithm (\algref{alg:orchestration-ideal}) without considering DCN has the overall time complexity $3\cdot O(|H| + |HE|) = O(|S| + |E|) = O((K+1)|S|) = O(|S|)$.

% \begin{algorithm}[!h]
% \small
% \caption{Connected-Component-DFS}
% \label{alg:dfs}
% \SetAlgoNlRelativeSize{-1}
% \SetAlgoNlRelativeSize{1}
%  \KwIn{ $node$, $HealthyHBD$, $visited$}
%  \KwOut{ $component$}

%  Initialize $stack = [node]$ \;
%  Initialize $component = []$\;

% \While{ stack is not empty}
% {
%      $current = stack.pop()$\;
%     \If{$current$ not in $visited$}
%     {
%          Add $current$ to $visited$\;
%          Add $current$ to $component$\;
%         \For{ each neighbor in $HealthyHBD.neighbors(current)$}
%         {
%              $stack.push(neighbor)$\;
%         }
%     }
% }
        
% \KwRet{$component$}
% \end{algorithm}

\begin{algorithm}[!h]
\small
\caption{Orchestration-DCN-Free}
\label{alg:orchestration-ideal}
\SetAlgoNlRelativeSize{-1}
\SetAlgoNlRelativeSize{1}
\KwIn{$\text{InfHBD}=\langle S, E \rangle$, $F$, $m$}
\KwOut{ Placement scheme maximizing GPU utilization}

 Initialize $H = S - F$\;
 Initialize $HE = \{ (u, v) \mid u \in H \text{ and } v \in H \text{ and } (u, v) \in E \}$\;
 Create subgraph $HealthyHBD = \langle H, HE \rangle$\;
 Initialize $component\_list = []$\;
 Initialize $visited = \{\}$\;
 Initialize $placement\_scheme= \{\}$\;

\For{ each node $s$ in $H$}
{
    \uIf{ $s$ not in $visited$}
    {
         $component = Connected-Component-DFS(s, HealthyHBD, visited)$\;
         Add $component.sortedinHBD()$ to $component\_list$\;
    }
}
\For{ each $component$ in $component\_list$}
{
    \While{ $component.size()\geq m$}
    {
         Add $component.pop(m)$ to $placement\_scheme$\;
    }
}
        
 \KwRet{$placement\_scheme$}
 \end{algorithm}
 
% \subsection{Algorithms under Rail-Optimized Network}
% \label{appendix:orch-algo:rail-optimized}

% This subsection provides a detailed description of the orchestration algorithm for Rail-Optimized network.  

% The rail-optimized network topology is specifically designed for highly regular machine learning workload traffic patterns, making it a commonly used and effective architecture. As illustrated in \fig{fig:rail-topo}, Rail Switch $i$ connects to GPU $i$ in node, dividing the network into multiple rails. Let $r$ denote the GPU ranks per node, and $k$ the number of rails. In traditional rail-optimized networks, $k = r$, and a typical training strategy involves running TP $r$ within the single-node HBD, while DP operates between HBDs. Since in DP, GPUs only communicate with GPUs of the same rank in different TP groups, in other words, DP traffic is confined to the rail itself. Therefore, the Rail-Optimized topology perfectly meets this requirement.

% % \begin{figure}[!h]
% %     \centering
% %     \includegraphics[width=\linewidth]{figs/design/Orchestration/rail-optimized.drawio.pdf}
% %     \caption{Rail-Optimized Network: GPU ranks per node $r=4$, Number of rails $k=8$, Aggregation-Switches Domain size $d$, Number of Aggregation-Switches Domain $nd$, Node IDs from 1 to $nd\cdot d$. }
% %     \label{fig:rail-topo}
% % \end{figure}

% \para{Orchestration Constraints. }To minimize the cross-rail traffic which can lead to congestion and latency, the rail-optimized network introduces two key constraints for orchestration algorithms:


% \begin{itemize}
%     \item {
%         \textbf{Aggregation-Switches Domain Coverage Constraint. }
%         The coverage domian of a group of Aggregation-Switches is limited, meaning that TP groups spanning across Aggregation-Switches domains would result in cross-rail traffic, which should be avoided as much as possible.
%     }
%     \item {
%         \textbf{Node Rail State Constraint. }When$ k = r$, this constraint does not apply, as there is no cross-rail traffic.However, as HBDs extend beyond single nodes and the need for larger DP scales due to the expansion of LLM scale, scenarios with $k = p \cdot r$ may arise. This results in $p$ different node states within the data center, with each state occupying $r$ rails, and inter-state communication leads to cross-rail traffic. The specific form of this constraint depends on the deployment strategy.
%     }
% \end{itemize}

% \para{Deployment Strategy. }If the \SYS{} connections continue to follow the physical layout of nodes on the DCN Fabric, avoiding cross-rail traffic would require each TP Group to have an equal number of nodes from each state, making the algorithm to maximize GPU Utilization NP-Complete (see Appendix.\ref{appendix:np-hard-orchestration}). However, by altering the physical connection sequence of \SYS{}, this NP-Complete problem can be reduced to polynomial time. As shown in \fig{fig:parallel-line}, nodes of each state are arranged into $p$ parallel sub-lines, which are then connected end-to-end to form a single line. By restricting DP to operate within sub-lines, all DP traffic remains within the rails, effectively reducing the $k = p * r$ scenario to $k = r$. 

% % \begin{figure}[!h]
% %     \centering
% %     \includegraphics[width=\linewidth]{figs/design/Orchestration/parallel-line.drawio.pdf}
% %     \caption{The deployment strategy example with $p=4$ and Aggregation-Switches Domain size $K=8$. Node IDs from 1 to n are arranged according to their connection order in the DCN Fabric.}
% %     \label{fig:parallel-line}
% % \end{figure}

% \para{The binary search-based Orchestration algorithm.} Based on the above-mentioned constraints and the deployment strategy, we developed an orchestration algorithm that maximizes the number of constraints satisfied while meeting the job scale requirements. This is achieved using a binary search approach with the number of satisfied constraints as the variable. Both types of constraints essentially involve splitting the Line into sub-lines. Therefore, controlling the number of constraints translates to managing the number of sub-lines: fewer sub-lines mean longer sub-lines, leading to higher GPU Utilization. Since the Ideal orchestration algorithm with complexity $O(n)$ can be applied within sub-lines.

% \algref{alg:orchestration-fat-tree} is the main binary-search-based orchestration algorithm. It begins by generating the topology from the perspective of \SYS{} based on the hardware deployment strategy (\algref{alg:deployment-strategy}). Using the number of satisfied constraints as a variable, the algorithm performs a binary search to identify the placement scheme that maximizes the number of satisfied constraints while meeting the job scale requirements.  

% \algref{alg:placement-rail-optimized} calculates the placement scheme for a given number of constraints. It divides the topology into multiple ideal sub-lines and applies the ideal-case orchestration algorithm (\algref{alg:orchestration-ideal}) to each sub-line.  

% Since the time complexity of \algref{alg:orchestration-ideal} is $O(|S|)$, the complexity of \algref{alg:placement-rail-optimized} is 

% \begin{align*}
% &\sum_{i=1}^{n_{constraints}} O(|S_{subline}|) \\
% &= O(\sum_{i=1}^{n_{constraints}} |S_{subline}|) \\
% &= O(|S_{all}|) = O(n)
% \end{align*}

% Thus, the overall time complexity of \algref{alg:orchestration-rail-optimized} is $O(n \log n)$.

\begin{algorithm}[!h]
\small
\caption{Deployment-Strategy}
\label{alg:deployment-strategy}
\SetAlgoNlRelativeSize{-1}
\SetAlgoNlRelativeSize{1}
 \KwIn{Node ordered set $S$, \docs{} direction $K$, parallel factor $p$}
 \KwOut{Deployment topology $G_{deploy}=<S_{deploy},E_{deploy}>$}
 Initialize ordered set $S_{deploy}=[]$\;
 Initialize $l=\lfloor \frac{|S|}{p}\rfloor$\;
\For{$i$ in $0...p-1$}
{
    \For{$j$ in $0...l-1$}{
         Add $i+j\cdot p$ to $S_{deploy}$\;}
}
 Create $E_{deploy}=\{(S_{deploy}^i,S_{deploy}^j)|1\leq i\le j\leq |S_{deploy}|, j-i\leq K \}$\;
 \KwRet{$G_{deploy}=<S_{deploy},E_{deploy}>$}
\end{algorithm}


% \begin{algorithm}[!h]
% \small
% \caption{Placement-Rail-Optimized}
% \label{alg:placement-rail-optimized}
% \SetAlgoNlRelativeSize{-1}
% \SetAlgoNlRelativeSize{1}
%  \KwIn{Deployment topology $G_{deploy}=<S_{deploy},E_{deploy}>$, Number of applied constraints $n_{constraints}$, Faulty node $F$, Sub-line length $l$, Number of node in one TP group $m$}
%  \KwOut{Placement scheme}
%  Initialize $placement\_scheme=\{\}$\;
% \For{$i$ in $1..n_{constraints}$}
% {
%      $S_{subline}=S_{deploy}.pop(l)$\;
%      $E_{subline}=\{(u,v)\mid u\in S_{subline} \text{ and } v\in S_{subline} \text{ and } (u,v)\in E_{subline}\}$\;
%      $F_{subline}=F\cap S_{subline}$\;
%      $placement\_scheme=placement\_scheme\cup \text{Orchestration-Ideal}(<S_{subline},E_{subline}>, F_{subline}, m)$\;
% }
%  $E_{res}=\{(u,v)\mid u \in S_{deploy} \text{ and } v \in S_{deploy} \text{ and } (u,v) \in E_{deploy}\}$\;
%  $F_{res}=F\cap S_{deploy}$\;
%  $placement\_scheme=placement\_scheme\cup \text{Orchestration-Ideal}(<S_{deploy},E_{res}>, F_{res},m)$\;
%  \KwRet{$placement\_scheme$}
% \end{algorithm}


% \begin{algorithm}[!h]
% \small
% \caption{Orchestration-Rail-Optimized}
% \label{alg:orchestration-rail-optimized}
% \SetAlgoNlRelativeSize{-1}
% \SetAlgoNlRelativeSize{1}
%  \KwIn{Node ordered set $S$ (from 1 to n in DCN Fabric), GPU ranks per node $r$, Number of rails $k$, Faulty set $F$, TP size $t$, Job scale $s$ (number of GPUs required for the job), Aggregation-Switches Domain size $d$, \docs{} directions $K$.}
%  \KwOut{Placement scheme that satisfies job scale and minimizes cross-rail traffic.}
%  Initialize $p=k/r$, $m=t/r$, $n=|S|$, $l=\lfloor \frac{d}{p}\rfloor$\;
%  Create graph $G_{deploy}=<S_{deploy},E_{deploy}>=\text{Deployment-Strategy}(S,K,p)$\;
%  Initialize $high=\lfloor\frac{nd}{p}\rfloor$\;
%  Initialize $low=0$\;
%  Initialize $placement\_scheme=\{\}$\;
% \While{ $low \leq$ high}
% {
%      $mid=\lfloor \frac{low+high}{2} \rfloor$\;
%      $placement\_scheme=\text{Placement-Rail-Optimized}(G_{deploy},mid,F,l,m)$\;
%     \eIf {$|placement\_scheme|\cdot m\cdot r\ge s$}
%     {
%          $low=mid+1$\;
%     }
%     {
%          $high=mid-1$\;
%     }
% }
    
% \eIf{$|placement\_scheme|\cdot m\cdot r\ge s$}
% {
%   \KwRet {$placement\_scheme$}
% }
% {
%     \KwRet {None}
% }
% \end{algorithm}
  

Fat-Tree topology is another common data center topology. A typical training strategy for this topology aims to maximize the bandwidth utilization under ToR (Top of Rack) Switches. Using Meta's two-stage clos topology\cite{sigcomm2024meta} as a reference, it can be observed that there is an attempt to run CP under ToR.

\para{Deployment Strategy:} Assuming there are $p$ nodes under each ToR, nodes with the same index under each ToR are deployed along the same parallel sub-line, and the $p$ sub-lines are connected end-to-end, as shown in \fig{fig:fat-tree-topo}. The training strategy involves running CP $p$ across the sub-lines and running TP within them.

\para{Orchestration Constraints. }To maximize the utilization of ToR bandwidth and minimize cross-ToR traffic, the fat-tree topology introduces two constraints:

\begin{packeditemize}
    \item {
        \textbf{Aggregation-Switches Domain Constraint: }The coverage domian of a group of Aggregation Switches is limited, meaning that TP groups spanning across Aggregation Switches domains would result in cross-rail traffic, which should be avoided as much as possible.
    }
    \item {
        \textbf{TP Group Alignment Constraint: } A CP Group consists of TP Groups across parallel sub-lines. To keep CP traffic within the ToR, the TP Groups must be aligned. If a node fails under one ToR, all nodes under that ToR are considered failed, expanding the failure radius by a factor of $p$. 
    }
\end{packeditemize}

\para{Binary-Search-Based Orchestration Algorithm.} Based on the constraints and deployment strategy, we develop a binary search orchestration algorithm (see \algref{alg:orchestration-fat-tree}) that adjusts the number of satisfied constraints. The binary search first relaxes the TP Group alignment constraints within the Aggregation-Switches Domain and then relaxes the TP Group crossing constraints between Aggregation-Switch domains (see \algref{alg:placement-fat-tree}). This process is monotonic.


% \begin{figure}[!h]
%     \centering
%     \includegraphics[width=\linewidth]{figs/design/Orchestration/meta-topo.drawio.pdf}
%     \caption{Orchestration example for Fat-Tree Topology under single Aggregation-Switches Domain with $p=2$. Green indicates active node, red indicates faulty node and yellow indicates idle nodes}
%     \label{fig:meta-topo}
% \end{figure}


The time complexity of \algref{alg:orchestration-ideal} is $O(|S|)$, and the complexity of \algref{alg:placement-fat-tree} is 

$$\sum_{i=1}^{n_{subline}} O(|S_{subline}|) = O(\sum_{i=1}^{n_{subline}} |S_{subline}|) = O(|S_{all}|) = O(n)$$  

Thus, the overall time complexity of \algref{alg:orchestration-fat-tree} is $O(n \log n)$.

\begin{algorithm}[!h]
\small
\caption{Placement-Fat-Tree}
\label{alg:placement-fat-tree}
\SetAlgoNlRelativeSize{-1}
\SetAlgoNlRelativeSize{1}
 \KwIn{$G_{deploy}=<S_{deploy},E_{deploy}>$, $n_{constraints}$, $F$, $l$, $m$, $n_{maxsubline}$, $d$, $p$}
 \KwOut{Placement scheme}
 Initialize $placement\_scheme=\{\}$\;
 Initialize $n_{align}=max(0,n_{constraints}-n_{maxsubline})$, $n_{subline}=min(n_{maxsubline},n_{constraints})$\;
 
\For{$i$ in $0..n_{align}-1$}
{
    \For{$j$ in $1..d$}
    {
        $sid=i*d+j$\;
        \If{$sid \in F$}
        {
            $F\cup \{\lfloor \frac{sid-1}{p}\rfloor\cdot p+1..(\lfloor \frac{sid-1}{p}\rfloor+1)\cdot p \}$\;
        }
    }
}
\For{$i$ in $1..n_{subline}$}
{
     $S_{subline}=S_{deploy}.pop(l)$\;
     $E_{subline}=\{(u,v)\mid u\in S_{subline} \text{ and } v\in S_{subline} \text{ and } (u,v)\in E_{subline}\}$\;
     $F_{subline}=F\cap S_{subline}$\;
     $placement\_scheme=placement\_scheme\cup \text{Orchestration-Ideal}(<S_{subline},E_{subline}>, F_{subline}, m)$\;
}
 $E_{res}=\{(u,v)\mid u \in S_{deploy} \text{ and } v \in S_{deploy} \text{ and } (u,v) \in E_{deploy}\}$\;
 $F_{res}=F\cap S_{deploy}$\;
 $placement\_scheme=placement\_scheme\cup \text{Orchestration-Ideal}(<S_{deploy},E_{res}>, F_{res},m)$\;
 \KwRet{$placement\_scheme$}
\end{algorithm}

\begin{algorithm}[!h]
\small
\caption{Orchestration-Fat-Tree}
\label{alg:orchestration-fat-tree}
\SetAlgoNlRelativeSize{-1}
\SetAlgoNlRelativeSize{1}
 \KwIn{$S$, $r$, $p$, $F$, $t$, $s$, $d$, $K$.}
 \KwOut{Placement scheme that satisfies job scale and minimizes cross-rail traffic.}
 Initialize $m=t/r$, $n=|S|$, $l=\lfloor\frac{d}{p}\rfloor$\, $n_{domain}=\lfloor\frac{n}{d}\rfloor$, $n_{maxsubline}=\lfloor\frac{nd}{p}\rfloor$\;
 Create graph $G_{deploy}=<S_{deploy},E_{deploy}>=\text{Deployment-Strategy}(S,K,p)$\;
 Initialize $high=n_{domain}+n_{maxsubline}$\;
 Initialize $low=0$\;
 Initialize $placement\_scheme=\{\}$\;
\While{ $low \leq$ high}
{
     $mid=\lfloor \frac{low+high}{2} \rfloor$\;
     $placement\_scheme=\text{Placement-Fat-Tree}(G_{deploy},mid,F,l,m,n_{maxsubline},d,p)$\;
    \eIf {$|placement\_scheme|\cdot m\cdot r\ge s$}
    {
         $low=mid+1$\;
    }
    {
         $high=mid-1$\;
    }
}
    
\eIf{$|placement\_scheme|\cdot m\cdot r\ge s$}
{
    \KwRet {$placement\_scheme$}
}
{
    \KwRet {None}
}
\end{algorithm}

