\clearpage
\begin{appendices}

\section{Production Fault Trace}
\label{appendix:production-fault-trace}
The production fault trace was collected from an 8-GPU node pretrain cluster with 2880 GPUs over a period of 160 days. The trace includes details such as fault start time, fault end time, and the ID of the faulty node. \figref{fig:simulation:trace:timetrace} and \figref{fig:simulation:trace:cdf} provide a macro-level overview of the production fault trace. On average, the ratio of faulty 8-GPU nodes at any given time is $3.83\%$, with a p99 value of $7.22\%$.

\begin{figure}[h!t]
    \centering
    \begin{subfigure}[b]{0.23\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figs/evaluation/fault_server_ratio.pdf}
        \caption{Fault Node Ratio Trace.}
        \label{fig:simulation:trace:timetrace}
    \end{subfigure}
    \hspace{2pt}
    \begin{subfigure}[b]{0.23\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figs/evaluation/fault_server_cdf.pdf}
        \caption{Cumulative Distribution.}
        \label{fig:simulation:trace:cdf}
    \end{subfigure}
    \vspace{-2ex}
    \caption{Fault node trace in the production AI DC.}
    \label{fig:simulation:trace}
\end{figure}

Since most of failure events are GPU faults, we normalized the trace of 8-GPU nodes to generate 4-GPU nodes trace. Assuming that the fault rates of GPUs are i.i.d. with a fault probability of $p$ for each GPU, and considering that a node is deemed faulty if any GPU within it fails, the fault rate of an 8-GPU node is calculated as:  

\vspace{-1em}
$$
P_{fault}(8\text{-GPU}) = 1 - (1-p)^8 = 3.83\%.
$$  

From this, we derive $p = 0.49\%$. The fault rate for a 4-GPU node is then:  
$$
P_{fault}(4\text{-GPU}) = 1 - (1-p)^4 = 1.93\%.
$$  

The fault event of 4-GPU node is generate with Bayesian Equation, as:


\begin{align*}\label{eq:convert-trace}
& P_{fault}( \text{4-GPU} \mid  \text{8-GPU})\\ 
    &=\frac{P_{fault}(\text{8-GPU} \mid \text{4-GPU}) P_{fault}(\text{4-GPU})}{P_{fault}(\text{8-GPU})} \\ 
    & =  \frac{1 \times 1.93\%}{3.83\%} = 50.39\% \\
\end{align*}

Thus, whenever a fault occurs in an 8-GPU node in the original trace, each of the two corresponding 4-GPU nodes at the same location has a $50.39\%$ probability of fault. This method is used to convert the traces.

As node faults are i.i.d., the simulator linearly maps the fault trace to different network architectures.

\section{GPT-MoE Architecture}
\label{appendix:gpt-moe}
This model is a mixture-of-experts (MoE) model with the following configuration:

\para{Model Configuration:}
\begin{itemize}
    \item \textbf{Number of Layers:} 192
    \item \textbf{Inner Layer Dimension:} 49152
    \item \textbf{Embedding Dimension:} 12288
    \item \textbf{Hidden Dimension:} 12288
    \item \textbf{Vocabulary Size:} 64000
    \item \textbf{Number of Attention Heads:} 128
    \item \textbf{Maximum Sequence Length:} 2048
    \item \textbf{Number of Experts:} 8
    \item \textbf{MoE Layer Ratio:} 0.5
    \item \textbf{Top-K Experts:} 2
\end{itemize}

\para{Runtime Configuration:}
\begin{itemize}
    \item \textbf{Virtual Pipeline Parallelism:} 3
    \item \textbf{Micro Batch Size:} 1
    \item \textbf{Global Batch Size:} 1536
    \item \textbf{Max Sequence Length:} 2048
\end{itemize}


\input{tex/ft-anay}

\input{tex/orch-algo}

\input{tex/eval-res}

\vspace{-12em}
\section{Detailed Cost and power consumption Analysis}
\label{appendix:cost}
In this section, \tabref{tab:eval:components} provides a detailed description of the quantity, cost, bandwidth, and power consumption of the interconnect components in various network architectures, including Google TPUv4~\cite{isca2023tpu}, NVIDIA GB200 NVL series~\cite{nvl72}, Alibaba HPN\cite{sigcomm2024hpn}, and \sys{}.


\begin{table*}[h!t] \small
    \centering
    \begin{tabular}{lllll}
    \toprule
    
    \textbf{Component} & \textbf{Quantity} & \textbf{Unit Cost (\$)}  & \textbf{Unit Bandwidth (GBps)} & \textbf{Unit Power (W)} \\

    \midrule
    \multicolumn{5}{c}{\textbf{Google TPUv4\cite{isca2023tpu} with 4096 GPU, bandwidth 300GBps/GPU}} \\
    
    \midrule
    OCS\cite{sigcomm2023lightwave} & 48 & 80000 & 6400 & 108 \\
    DAC Cable\cite{400G_DAC} & 5120 & 63.60 & 50 & 0.1 \\
    Optical Module\cite{400G_OPTICAL_MODULE} & 6144 & 360 & 50 & 12  \\
    Fiber\cite{FIBER}& 6144 & 6.80 & 50 & 0 \\
    
    \midrule
    \multicolumn{5}{c}{\textbf{NVIDIA GB200 NVL-36\cite{SEMIANALYSIS_GB200} with 36 GPU, bandwidth 900GBps/GPU}}\\
    \midrule
    NVLink Switch\cite{SEMIANALYSIS_Power} & 9 & 28000 & 3600 & 275 \\
    DAC Cable\cite{200G_DAC} & 2592 & 35.60 & 25 & 0.1 \\
    
    \midrule
    \multicolumn{5}{c}{\textbf{NVIDIA GB200 NVL-72\cite{nvl72}\cite{SEMIANALYSIS_GB200} with 72 GPU, bandwidth 900GBps/GPU}}\\
    \midrule
    NVLink Switch\cite{SEMIANALYSIS_Power} & 18 & 28000 & 3600 & 275 \\
    DAC Cable\cite{200G_DAC} & 5184 & 35.60 & 25 & 0.1 \\
    \midrule
    \multicolumn{5}{c}{\textbf{NVIDIA GB200 NVL-36x2\cite{SEMIANALYSIS_GB200} with 72 GPU, bandwidth 900GBps/GPU}}\\
    \midrule
    NVLink Switch\cite{SEMIANALYSIS_Power} & 36 & 28000 & 3600 &  275\\
    DAC Cable\cite{200G_DAC} & 6480 & 35.60 & 25 & 0.1 \\
    ACC Cable\cite{SEMIANALYSIS_Power} & 162 & 320 & 200 & 2.5 \\

    \midrule
    \multicolumn{5}{c}{\textbf{NVIDIA GB200 NVL-576\cite{SEMIANALYSIS_GB200} with 576 GPU, bandwidth 900GBps/GPU}}\\
    \midrule
    NVLink Switch\cite{SEMIANALYSIS_Power} & 432 & 28000 & 3600 & 275 \\
    DAC Cable\cite{200G_DAC} & 41472 & 35.60 & 25 & 0.1 \\
    Optical Module\cite{OSFPXD} & 4608 & 850 & 200 & 25 \\
    Fiber\cite{FIBER} & 4608 & 6.80 & 200 & 0 \\

    \midrule
    \multicolumn{5}{c}{\textbf{Alibaba HPN\cite{sigcomm2024hpn} with 16320 GPU, bandwidth 50GBps/GPU}}\\
    \midrule
    EPS\cite{51.2T_EPS} & 360 & 14960 & 6400 & 3145 \\
    DAC Cable\cite{200G_DAC} & 32640 & 35.60 & 25 & 0.1\\
    Optical Module\cite{400G_OPTICAL_MODULE} & 28800 & 360 & 50 & 12 \\
    Fiber\cite{FIBER} & 14400 & 6.80 & 50 & 0 \\

    \midrule
    \multicolumn{5}{c}{\textbf{\SYS{}($K=2$)  with 4 GPU, bandwidth 800GBps/GPU}}\\
    \midrule
    DAC Cable\cite{1.6T_DAC}& 4 & 199.60 & 200 & 0.1\\
    dOCS Module & 16 & 600 & 100 & 12 \\
    Fiber\cite{FIBER} & 16 & 6.80 & 100 & 0 \\

    \midrule
    \multicolumn{5}{c}{\textbf{\SYS{}($K=3$)  with 4 GPU, bandwidth 800GBps/GPU}}\\
    \midrule
    DAC Cable\cite{1.6T_DAC} & 2 & 199.60 & 200 & 0.1\\
    dOCS Module & 24 & 600 & 100 & 12 \\
    Fiber\cite{FIBER} & 24 & 6.80 & 100 & 0 \\
    \bottomrule
    \end{tabular}
    \caption{Interconnect cost and power consumption of components used in different network architectures.}
    \label{tab:eval:components}
\end{table*}


\end{appendices}



