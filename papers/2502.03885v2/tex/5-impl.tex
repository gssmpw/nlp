\vspace{-1em}
\section{Implementation}
\label{section:implementation}


\para{\docs \xspace :}
\label{sec:testbed:docs}
We have successfully built a test board featuring the OCS Controller chip and a pre-release Photonic Integrated Circuit (PIC) module without the MZI switch matrix, as shown in \fig{figure:design:evaluation-board}. The Controller Chip, measuring $4mm \times 4mm$, is manufactured using a 28nm process, while the PIC, sized at $10.5mm \times 13mm$, uses a 65nm CMOS process. The evaluation board supports 8 pairs of TX/RX SerDes at each end and has been validated for compatibility with various link layer protocols, including PCIe (32Gbps, 64Gbps) and Ethernet (56Gbps, 112Gbps). We assessed the power consumption of the peripheral circuitry using the test board. For an $8 \times 112G$ configuration, the power consumption was 8.5 watts. With the addition of 3.2 watts for the MZI switch matrix, the overall consumption totals approximately 12 watts, meeting the QSFP-DD 800Gbps standard\cite{qsfp-dd-15w}.

Notably, the full-featured version of the PIC chip has successfully completed tape-out and is currently in the packaging and testing phase. It will be available for evaluation prior to final publication.


\para{Small-scale Cluster:}
\label{sec:testbed:minipod}
We constructed a small-scale cluster to evaluate the communication performance of the ring topology. Using 32 experimental GPUs equipped with inter-host HBD support (96 lanes on PCIe 4 protocol), we formed a physical ring utilizing fixed optical modules. This mini-cluster was manually reconfigured for both 32-GPU and 16-GPU ring topology. The communication latency and AllReduce performance is evaluated.
For small packets, direct GPU-to-GPU links reduced latency by approximately 13\% compared to the NVLink switch design.
For large packets, the 16-GPU AllReduce utilized 77.11\% of the ring bandwidth, with the utilization rate increasing to 77.26\% for the 32-GPU configuration, showing minimal degradation with scaling. In comparison, the NVIDIA H100 8-GPU machine achieves an 81.77\% utilization rate without SHARP.
After deployment of \docs, the size of communication group can be reconfigured within $1ms$, while maintaining maximum throughput.


\begin{figure}[h!t]
    \vspace{-1em}
    \centering
    \includegraphics[width=0.48\textwidth]{figs/design/evaluation-board.pdf}
    \vspace{-20pt}
    \caption{Evaluation board for components of \docs.}
    \label{figure:design:evaluation-board}
    \vspace{-1em}
\end{figure}

