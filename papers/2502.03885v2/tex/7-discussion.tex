
\section{Discussion}

\para{AllToAll communication.}
Ring topology in \sys struggles with AllToAll communication (e.g., EP), exhibiting poor performance at $O(p^2)$, where $p$ is the group size. This can be improved by linking backup lines to nodes indexed at $n\pm 2^i$ instead of $n\pm i$ and Applying the Binary Exchange algorithm, and reduce time complexity to $O(p\log_2 p)$. During the algorithm, \ocstrx{} need to connect to different GPUs with runtime switching, since \ocstrx{} switches in under $1ms$, reconfiguration can be overlapped with computation. For $K=2$ \sys designs, performance matches the ideal Bruck algorithm~\cite{bruck} when $p<8$. However, this design introduces complexities in construction, failover, and orchestration, and necessitates GPU routing capabilities. So it is not applied.

\para{Simulation Scale. } Simulations using real 3,000 GPU fault traces, as detailed in \secref{sec:simulation:fault}, were conducted on a cluster comprising 2880 GPUs. The reason is that the simulation's GPU count must be less than the total GPUs in the fault trace, and 2880 is the largest number divisible by 576 and less than 3,000. This configuration allows the entire cluster to be divided into five NVL-576 units for the simulation.  Larger scales are simulated in other scenarios.

\para{Multi-dimension parallelism.}
\sys is optimized for single-dimension parallelism. To support multi dimensional communication, two approaches are viable. 1) \textit{Independent Interconnects: } Each \ocstrx{} bundle includes multiple \ocstrx{} units (e.g., 4 or 8), then link each of the unit to a separate inter-host topology. This isolates parallel dimensions but results in fixed bandwidth per dimension, leading to inefficiencies. 2) \textit{Time-Division multi-dimension: } Main and backup lines of \ocstrx{} can be used to form separated inter-host topology, rapidly switching between them can support multi-dimension parallelism. However, this introduces complexity in managing multi-dimensional overlap and reduces the fault tolerance of \sys.  


\para{Single-Job vs. Multi-Job.} Existing studies explore multi-job scheduling in GPU clusters~\cite{mlass,lyra}. Deploying certain small jobs, such as inference tasks, can mitigate GPU fragmentation. However, given the shortage of GPU in LLM training, any idle GPU—whether repurposed for small job or not—is undesirable. Thus, \sys prioritizes single-job execution for simplicity. 

\para{OCS vs. EPS.} \ocstrx{} enables multi-path selection, a feature also achievable with Electronic Packet Switching (EPS). For example, inter-host topology of \sys can be implemented using UBB 2.0-based servers by adding external optical interfaces to switches in server. However, this would require twice optical modules and numerous high-throughput switching chips for the entire system, significantly increasing cost and power consumption compared to \ocstrx{}.

