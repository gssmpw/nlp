\vspace{-1em}
\section{Related Work}

\para{HBD Architectures.}  
HBDs are crucial for enabling communication intensive parallelism strategies (TP/EP) for LLM training. NVIDIA DGX SuperPOD~\cite{superpod} and GB200 NVL series~\cite{nvl72} use any-to-any electrical switching, delivering high performance but suffering from high costs, scalability limitations, and fragmentation. In contrast, direct interconnect HBDs like Dojo~\cite{dojo}, TPUv3~\cite{cacm2020tpuv3}, and SiP-Ring~\cite{sip-ml} improve scalability but have a large fault explosion radius. TPUv4~\cite{isca2023tpu} and TPUv5p~\cite{tpuv5} attempts a middle ground but still lacks full node-level fault isolation. \sys introduces a novel architecture that reduces cost, improves scalability, minimizes fragmentation, enhances fault isolation, and dynamically supports TP.  

\para{AI DCN Architectures.}  
MegaScale~\cite{megascale} and Metaâ€™s~\cite{sigcomm2024rdmameta} AI DC use Clos-based topologies, while Rail-Optimized~\cite{rail-optimized} and Rail-Only~\cite{wang2024railonly} architectures optimize for LLM traffic patterns. Alibaba HPN~\cite{sigcomm2024hpn} enhances fault tolerance with a dual-plane design. \sys is compatible with all of them on LLM-training.  

\para{OCS Technologies.}  
OCS enables dynamic topology reconfiguration in datacenters~\cite{missionapollo, isca2023tpu, mfabric}. MEMS OCS-based switch supports high port counts~\cite{urata2022missionapollo, mems-320}, while silicon photonics (SiPh) achieves lower latency and cost~\cite{thermo-optic_2006}. This work proposes a SiPh-based OCS transceiver (\docs), constructing an interconnect fabric without centralized switches.  

\para{Reconfigurable Networks.}  
Traditional studies~\cite{helios,c-through,osa,mordia,sirius,xia2015enabling,megaswitch,rotornet,opera,firefly,shale} focus on generic DCN architectures without optimizing for LLM training traffic, leading to suboptimal topologies. Recent advancements like SiP-ML~\cite{sip-ml}, TopoOpt~\cite{topoopt2023}, and mFabric~\cite{mfabric} introduce dedicated training optimizations but still underutilize optical network reconfigurability for better fault tolerance and GPU utilization.  

\para{AI Job Schedulers.}  
Schedulers such as ~\cite{gandiva,themis,tiresias, {byteps_1}, {byteps_2}, pollux} aim to improve GPU utilization. However, they exhibit dual limitations: their designs are premised on non-reconfigurable network, while also failing to consider job scheduling within HBD for optimizing traffic patterns in DCN. This work proposes a HBD-DCN orchestration algorithm based on reconfigurable networks to address these limitations.
