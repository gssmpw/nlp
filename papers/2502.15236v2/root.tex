% here is an official guidline of the journal: https://ieeecss.org/publication/transactions-control-network-systems/information-authors

\documentclass[10pt,twocolumn,twoside]{IEEEtran}

\usepackage[linesnumbered,ruled,vlined]{algorithm2e}
\usepackage{amsmath, amssymb, amsfonts, amsthm}
\usepackage{orcidlink}
\usepackage{subfig}
\usepackage{multirow}
\usepackage{xcolor}

% define custom theorems
\newtheoremstyle{spacedef}
  {0.5em}   % Space above
  {0.5em}   % Space below
  {\itshape} % Body font
  {}      % Indent amount
  {\bfseries} % Theorem head font
  { }     % Punctuation after theorem head
  { }     % Space after theorem head
  {}      % Theorem head spec
\theoremstyle{spacedef}
\newtheorem{theorem}{Definition}[section]

% a handy abbreviation for the scientific notation
\usepackage{stackengine}
\newcommand{\scinot}[3]{$#1 (#2\mathrm{E}{#3})$}

\begin{document}

\title{Applicability of the Minimal Dominating Set for Influence Maximisation in Multilayer Networks}

\author{Micha{\l} Czuba\textsuperscript{*1,2}\orcidlink{0000-0001-8652-3678}, Mingshan Jia\textsuperscript{2}\orcidlink{0000-0001-8378-3407}, Piotr Br{\'o}dka\textsuperscript{1,2}\orcidlink{0000-0002-6474-0089}, Katarzyna Musial\textsuperscript{2}\orcidlink{0000-0001-6038-7647}\thanks{* corresponding author}
\thanks{[1] are with Department of Artificial Intelligence, Wroc{\l}aw University of Science and Technology, 27 wybrze{\.z}e Wyspia{\'n}skiego st, 50-370 Wroc{\l}aw, Poland, e-mails: {\tt \{michal.czuba, piotr.brodka\}@pwr.edu.pl}}
\thanks{[2] are with Complex Adaptive Systems Lab, Data Science Institute, School of Computer Science, University of Technology Sydney, Ultimo NSW 2007, Australia, e-mails: {\tt \{mingshan.jia, katarzyna.musial-gabrys\}@uts.edu.au}}
}

% \markboth{IEEE Transactions on Control of Network Systems,~Vol.~XX, No.~XX, February~2025}{}
\maketitle
%Not more than 1200 characters Excess text is truncated
\begin{abstract}
    The minimal dominating set (MDS) is a well-established concept in network controllability and has been successfully applied in various domains, including sensor placement, network resilience, and epidemic containment. In this study, we adapt the local-improvement MDS routine and explore its potential for enhancing seed selection for influence maximisation in multilayer networks (MLN). We employ the Linear Threshold Model (LTM), which offers an intuitive representation of influence spread or opinion dynamics by accounting for peer influence accumulation. To ensure interpretability, we utilise rank-refining seed selection methods, with the results further filtered with MDS. Our findings reveal that incorporating MDS into the seed selection process improves spread only within a specific range of situations. Notably, the improvement is observed for larger seed set budgets, lower activation thresholds, and when an "AND" strategy is used to aggregate influence across network layers. This scenario reflects situations where an individual does not require the majority of their acquaintances to hold a target opinion, but must be influenced across all social circles.
\end{abstract}

\begin{IEEEkeywords}
Minimal Dominating Set, Multilayer Networks, Influence Maximisation, Linear Threshold Model, Network Control
\end{IEEEkeywords}

\IEEEpeerreviewmaketitle

\section{Introduction}\label{sec:intro}

% multilayer networks
Traditionally, spreading processes, including influence diffusion, were studied on simple, undirected, and unlabelled networks. However, these models fail to realistically represent real-world relationships. With time, more and more complex graph representations were developed, and eventually, a multilayer network (MLN) concept was proposed. It offers a more nuanced depiction of social interactions than classical graphs. This model captures diverse types of connections --- such as communication, professional, family, or social ties, by distinguishing between different layers (i.e. types of relationships)~\cite{dickison2016multilayer, kivela2014multilayer}. Hence, incorporating such networks into research on diffusion increases the accuracy of modelling.

% spreading in multilayer networks
Information diffusion in such graphs is often analysed through cascade dynamics using mechanisms such as the Linear Threshold Model (LTM) and the Independent Cascade Model (ICM). LTM employs a threshold-based activation rule, where a node becomes active only if the total weight of its active neighbours exceeds a predefined threshold~\cite{granovetter1978threshold, watts2002simple}. In contrast, ICM activates nodes probabilistically through independent trials along each edge~\cite{goldenberg2001talk}. While ICM has been extended to multilayer settings~\cite{lin2023tensor, achour2024theoretical}, its limited flexibility in capturing heterogeneous link influences makes LTM a more suitable choice for modelling opinion dynamics in a multilayer environment~\cite{yaugan2012analysis, zhong2022mltm, czuba2024rankrefininginfmaxmln}. %Thus, researchers developed LTM extensions for multilayer networks, one approach~\cite{yaugan2012analysis} incorporates content-dependent parameters to differentiate link types, thereby moderating the aggregation of activations. Another~\cite{zhong2022mltm} introduces layer-specific activation thresholds and heterogeneous activation rules.

% influence maximisation in multilayer networks
One of the examples of spreading processes is influence spread, which is a key challenge in social network analysis, with applications in areas such as viral marketing, information diffusion, and public health interventions~\cite{salehi2015spreading}. One of the critical topics in this space is influence maximisation, which aims to identify seed agents that achieve the widest spread with minimal resources~\cite{kempe2003maximizing}. Numerous methods have been proposed for seed selection in multilayer networks and, as categorised in~\cite{singh2022influence}, can be grouped into heuristic techniques~\cite{venkatakrishna2023kpp_shell, czuba2024rankrefininginfmaxmln}, simulation-based approaches~\cite{chen2020maximizing}, and hybrid methods incorporating machine learning~\cite{yuan2024gbim, shu2025node}.

% control theory (reason and purpose) in classic an multiayer graphs
Influence maximisation can be viewed as a softer version of control, which motivates this study's exploration of incorporating concepts from context theory to assess their applicability in the realm of influence spread. Control theory in network science focuses on strategies to transition a system from one state to another within a defined number of steps~\cite{liu2011controllability}. To achieve this, control methods have been developed that identify a minimal set of driver nodes capable of steering the network toward the desired state~\cite{liu2016control}. For example, a study by~\cite{doostmohammadian2019minimal} discusses the identification of a minimal set of driver nodes for structural controllability in large-scale dynamical systems. Some researchers looked at the impact of multilayer networks on the controllability of those structures~\cite{jiang2022controllability}. However, real social networks often do not exhibit deterministic behaviours, making strict network control difficult.

% explanation for the paper
In this paper, we aim to bridge concepts from control theory with influence maximisation techniques, which have largely been independent of it. We address this through an exploratory study that employs the Minimal Dominating Set (MDS) in the seed selection process for multilayer networks. We explore the viability and potential advantages of using MDS to maximise influence. Previous research has shown that MDS is an effective seed selection method in single-layer networks~\cite{sadaf2024bridge}, but its performance in multilayer networks remains largely unexplored. Please note that the primary goal of this study is not to propose a new seed selection method but to assess the effectiveness and usefulness of MDS in improving existing methods.

% our findings
Our study demonstrates that incorporating MDS into the seed selection process enhances diffusion, but this improvement occurs only within a specific range of spreading parameters. The benefit is most noticeable when the activation thresholds are lower, the $AND$ strategy is used to aggregate influence across network layers, and the seed set budget is larger. Additionally, the enhancement is particularly pronounced in networks resembling Scale-free graphs. This scenario is especially relevant when an individual needs to be influenced across all social circles without requiring the majority of their acquaintances to share the target opinion. An example might be a presidential election with highly polarised candidates; we do not know the opinion of all our friends and family because not everyone wants to share it (for example, they are afraid of what others would think), or we just prefer not to discuss politics. However, we usually know the opinion of a few people in each of our social circles, and if the opinion in all (or most) of them is the same, we are more willing to adopt it as our view. 

% summary of the contents
The article is organised as follows. In Sec.~\ref{sec:mds_in_mln}, we present a formal definition of MDS, review state-of-the-art methods for obtaining it, and introduce our adaptation of the local-improvement algorithm to the context of multilayer networks. Sec.~\ref{sec:setup} outlines the experimental setup used in the study, including metrics and evaluated parameter space. The results of the analysis are discussed in Sec.~\ref{sec:results}, where we examine the properties of the MDSs obtained for the examined graphs, the similarity of seed sets drawn with and without incorporating MDS in the seed selection process, and the effectiveness of that in maximising influence. In Sec.~\ref{sec:conclusions}, we conclude the work.

\section{MDS in Multilayer Networks}\label{sec:mds_in_mln}

MDS is the smallest set of ''driver agents'' which are capable of controlling the entire network. A problem of identifying it is well known to be NP-hard~\cite{karp2010reducibility}, and numerous approaches have been proposed to solve it efficiently. In this section, we review related works that address this problem and introduce our extension of the local improvement algorithm to the multilayer setting.

\subsection{Multilayer Networks}

First, we clarify how we conceptualise multilayer networks. Specifically, we adopt the framework introduced by~\cite{dickison2016multilayer, kivela2014multilayer}. To ensure consistency in notation, we restate it as follows:

\begin{theorem}[Multilayer Network: MLN]\label{def:multilayer_net}
    A multilayer network can be described as a tuple $M = (A,L,V,E)$ consisting of the following sets:
    \begin{itemize}
        \item actors $A=\{a_1, a_2, \dots\}$,
        \item layers $L=\{l_1, l_2, \dots\}$, 
        \item nodes $V=\{v_1^{1}, v_1^{2}, \dots, v_2^{1}, v_2^{2}, \dots\}: V \subseteq A \times L$,
        \item edges $E=\{(v_1^{1}, v_2^{1}), \dots, (v_1^{2}, v_2^{2}), \dots\}: (v_1^{1}, v_2^{2}) \notin E \land (v_1^{1}, v_2^{1}) \equiv (v_2^{1}, v_1^{1})$.
    \end{itemize}
\end{theorem}

In other words, a multilayer network is a coupled set of single-layer networks, where each actor is represented in at most every layer by a corresponding node ($V \subseteq A \times L$), e.g. the representation of actor $a_1$ in layer $l_2$ is denoted as $v_1^{2}$. Another property of this model is that interlayer edges are not allowed, meaning links can only exist within the same layer: $(v_1^{1}, v_2^{2}) \notin E$. Additionally, to simplify the analysis, edges are considered undirected: $(v_1^{1}, v_2^{1}) \equiv (v_2^{1}, v_1^{1})$ and unweighted.

\subsection{MDS and Driver Nodes}

The classic greedy heuristic~\cite{Chvatal1979} offers a theoretical approximation guarantee and serves as a foundational method for tackling MDS. However, in practical scenarios, it often overestimates the true MDS size due to its myopic nature, leading to suboptimal solutions. Metaheuristic approaches have been widely explored to improve upon traditional greedy approaches. The Ant Colony Optimization Algorithm hybridised with a Local Search (ACO-LS) leverages pheromone trails for guiding the search process while refining solutions through local search~\cite{potluri2011two}. Building on this, an extended version, ACO-PP-LS, incorporates a pre-processing phase to generate initial solutions using a greedy heuristic, thereby accelerating convergence~\cite{potluri2013hybrid}. Beyond ACO-based methods, order-based Randomized Local Search has been proposed, representing solutions as permutations of vertices and applying a perturbation mechanism to refine dominating sets iteratively~\cite{chalupa2018order}. While RLS improves upon many existing methods, it remains computationally demanding and is sensitive to the choice of its perturbation operator. The Iterated Greedy (IG) algorithm has been introduced as an efficient and effective approach for finding MDS~\cite{casado2023iterated} to address these limitations. By iteratively destructing and reconstructing solutions while incorporating a specialised local search, IG achieves a superior balance between diversification and intensification. Empirical evaluations demonstrate that IG not only outperforms ACO-based methods and RLS in solution quality but also significantly reduces computational effort, making it a state-of-the-art approach.

\subsection{MDS in Multilayer Networks}\label{sec:MMDS}

Since most existing methods focus on single-layer networks, the problem of finding the MDS in multilayer networks remains largely unexplored. One of the most recent approaches, FAST-MDSM~\cite{nacher2019finding}, employs integer linear programming (ILP) combined with graph reduction heuristics to identify a minimal set of driver nodes across multiple interconnected layers. However, its reliance on ILP renders it computationally expensive and less adaptable to dense graphs. Notably, FAST-MDSM was designed for Scale-free networks and has been primarily tested on sparse biological networks, limiting its applicability to more general settings.

In this work, inspired by IG algorithm~\cite{casado2023iterated}, originally developed for single-layer networks, we propose a new approach to efficiently solve the MDS problem in multilayer networks. However, before discussing our approach, we first provide formal definitions of both the Dominating Set and the Minimal Dominating Set in a multilayer network, which follow the foundational concept introduced in~\cite{nacher2012dominating}.

\begin{theorem}[Dominating Set]\label{def:ds}
    A set of actors $D'$ dominates the multilayer network $M$ if for every actor $a \in A$, either $a$ belongs to $D'$, or for each layer where $a$ is represented, the corresponding node of $a$ is adjacent to a node that represents an actor in $D'$.
\end{theorem}

\begin{theorem}[Minimal Dominating Set]\label{def:mds}
    Let $\mathcal{D}$ be a family of dominating sets of the multilayer network $M$: $\mathcal{D} \subseteq powerset(A)$. A Minimal Dominating Set is a set $D: D \in \mathcal{D}$, and $|D| = \arg\min_{D' \in \mathcal{D}} |D'|$, i.e. $D$ is the smallest dominating set among all dominating sets in $\mathcal{D}$.
\end{theorem}

As we can see, many dominating sets can be obtained for a particular network, and in the edge case, the set of all actors is also a dominating set. Another implication of the definitions above is that multiple MDSs can exist for a given multilayer network. Finally, when applied to a single-layer network (a special case of MLN with $|L|=1$), both Def.~\ref{def:ds} and Def.~\ref{def:mds} align with the original concept of MDS.

Extension of the local improvement routine from~\cite{casado2023iterated} to multilayer networks is presented as Alg.~\ref{alg:driver_actor_selection}. As input, it accepts a multilayer network $M$ and an initial dominating set $D'$ obtained using a greedy routine as described in~\cite{czuba2024networkdiffusion}.

\begin{algorithm}[ht]
    \caption{MDS with Local Improvement for MLN}
    \label{alg:driver_actor_selection}
    \KwIn{ \\
        $M = (A, L, V, E)$ -- multilayer network \\
        $D'$ -- initial dominating set \\
    }
    \KwOut{$D$ -- improved dominating set}
    $domin \gets \text{CompDomination}(M, D')$ \\
    $improved \gets \text{True}$ \\
    $D \gets D'$ \\
    \While{$improved$}{
        $improved \gets \text{False}$ \\
        \For{$a_D \in \text{Shuffle}(D)$}{
            $C \gets \text{ReplacementCand}(M, a_D, D, domin)$ \\
            \For{$a_C \in \text{Shuffle}(C)$}{
                $D_{\text{old}} \gets D$ \\
                $D_{\text{new}} \gets (D \setminus \{a_D\}) \cup \{a_C\}$ \\
                \If{$\text{IsFeasible}(M, D_{\text{new}})$}{
                    $D_{\text{reduced}} \gets \text{PruneRedundant}(M, D_{\text{new}})$ \\
                    \If{$|D_{\text{reduced}}| < |D_{\text{old}}|$}{
                        $D \gets D_{\text{reduced}}$ \\
                        $domin \gets \text{CompDomination}(M, D)$ \\
                        $improved \gets \text{True}$ \\
                        \textbf{break}
                    }
                    \Else{$D \gets D_{\text{old}}$}
                }
            }
            \If{$improved$}{\textbf{break}}
        }
    }
    \Return $D$
\end{algorithm}

First (l. 1--3), we compute a domination map (\textit{CompDomination}) that, for each layer of $M$, associates nodes representing actors from $D'$ with sets of nodes they dominate. We then initialise a flag to control the termination of the routine and assign $D'$ as the current best solution.

The next step (l. 4--21) consists of a loop that explores alternative configurations of dominating sets derived from $D$ in an attempt to identify the smallest one. Specifically, the \textit{for} loop (l. 6) iterates over the actors in $D$ to assess whether replacing a particular actor $a_D$ leads to a reduction in $|D|$.

To achieve this, we identify a set of candidate replacements $C$ for each $a_D$ using the auxiliary function \textit{ReplacementCand}. For each actor $a_C \in C$, we construct a new set $D_{\text{new}}$ by substituting $a_D$ with $a_C$ in $D$. Then, using \textit{IsFeasible}, $D_{\text{new}}$ is examined to determine if it meets the criteria to dominate $M$. If the set remains feasible, we attempt to greedily minimise its size by iteratively removing redundant actors.

If the pruned set $D_{\text{reduced}}$ is not smaller than the current best solution, we continue iterating through $C$. Otherwise, we update $D$ with $D_{\text{reduced}}$, recompute the domination map for the updated $D$, and reset the $improved$ flag. At this point, we restart the outer loop, attempting further refinement of the dominating set. The iteration continues until no further refinements can be made. At this stage, the algorithm terminates and returns $D$, which is locally minimal in size.

Please note that despite calling the result a Minimal Dominating Set, it is not strictly speaking minimal (the smallest) in general. It is the smallest one found by a particular run of the algorithm. This is in line with the naming convention present in the related works. As shown in Tab.~\ref{tab:mds_networks}, the algorithm, over multiple runs, can identify MDSs of various sizes. 

\subsection{Example}

To illustrate both the MDS and an example of a multilayer network, we present Fig.~\ref{fig:toy_mds}. Note that even a small structural change can affect the MDS. For instance, adding an edge between nodes $n_9$ and $n_6$ in layer $l_1$ would allow actor $a_3$ to be removed from the MDS.

\begin{figure}[ht]
	\centering
	\includegraphics[width=.55\linewidth]{figures/toy_mds.pdf}
	\caption{An example of a multilayer network with three types of relations ($l_1$, $l_2$, $l_3$). Nodes representing actors that belong to the MDS are highlighted in green ($D={a_2, a_3, a_4, a_8, a_9, a_{11}}$).}
    \label{fig:toy_mds}
\end{figure}

\begin{table*}[ht]
    \caption{Networks used in the experiments.}
    \begin{tabular}{llrrrrp{9.8cm}}
    Type & Name & Layers & Actors & Nodes & Edges & Note \\ \hline \hline
    \multirow{3}*{\rotatebox[origin=c]{90}{E-R}} & er-2 & 2 & 1,000 & 2,000 & 5,459 & Erd\H{o}s-R\'{e}nyi artificial network~\cite{er_model} generated with multinet~\cite{magnani2021analysis} library. \\
    & er-3 & 3 & 1,000 & 3,000 & 7,136 & Erd\H{o}s-R\'{e}nyi artificial network~\cite{er_model} generated with multinet~\cite{magnani2021analysis} library. \\
    & er-5 & 5 & 1,000 & 5,000 & 15,109 & Erd\H{o}s-R\'{e}nyi artificial network~\cite{er_model} generated with multinet~\cite{magnani2021analysis} library. \\ \hline
    \multirow{3}*{\rotatebox[origin=c]{90}{S-F}} & sf-2 & 2 & 1,000 & 2,000 & 4,223 & Scale-free artificial network~\cite{sf_model} generated with multinet~\cite{magnani2021analysis} library. \\
    & sf-3 & 3 & 1,000 & 3,000 & 5,010 & Scale-free artificial network~\cite{sf_model} generated with multinet~\cite{magnani2021analysis} library. \\
    & sf-5 & 5 & 1,000 & 5,000 & 10,181 & Scale-free artificial network~\cite{sf_model} generated with multinet~\cite{magnani2021analysis} library. \\ \hline
    \multirow{7}*{\rotatebox[origin=c]{90}{REAL}} & aucs & 5 & 61 & 224 & 620 & Interactions between employees of \textbf{A}arhus \textbf{U}ni., Dep. of \textbf{C}omputer \textbf{S}cience~\cite{rossi2015towards}. \\
    & ckmp & 3 & 241 & 674 & 1,370 & A network depicting diffusion of innovations among physicians~\cite{coleman1957ckmp}. \\
    & lazega & 3 & 71 & 212 & 1,659 & A network of various types of  interactions between staff of a law corporation~\cite{snijders2006lazega}. \\
    & l2-course & 2 & 41 & 82 & 297 & A network built from interactions between students during a three-month-long abroad language course in Arabic, undertaken by 41 US students (first snapshot)~\cite{paradowski2024l2_course}. \\
    & timik & 3 & 61,702 & 102,247 & 881,676 & A graph of interactions between users of the virtual world platform for teenagers~\cite{jankowski2017timik}. \\
    \end{tabular}
    \label{tab:networks_eda}
\end{table*}

\section{Experimental Setup}\label{sec:setup}

In this section, we describe the simulation setup, including the dataset and the diffusion model applied. We then present the baseline seed selection methods and explain how MDS was incorporated into them. We also outline the metrics used to assess diffusion effectiveness and detail the experimental parameters, as well as the hardware / software specifications.

\subsection{Dataset}\label{subsec:dataset}

The efficiency of MDS depends on the structure of the underlying network. Furthermore, as mentioned in Sec.~\ref{sec:intro}, dynamics in multilayer networks often differ significantly from those observed in single-layer networks. Consequently, selecting appropriate data for experiments is crucial. To ensure a comprehensive evaluation, we utilise both real-world and artificially generated graphs. A summary of the networks used in this study, with a brief description of the domain context in which each was constructed, is provided in Tab.~\ref{tab:networks_eda}. All artificial networks were generated using the \textit{multinet} library~\cite{magnani2021analysis}. The real-world networks come from different domains, but all represent human-based relationships. %were processed directly from the raw data, with two exceptions: the \textit{timik} dataset, which was restricted to interactions from the first quarter of 2009 due to its large size, and since the \textit{l2-course-1} is a temporal network, we use the first snapshot.

\subsection{Speding Model}\label{subsec:ltm}

We use the Multilayer Linear Threshold Model (MLTM) introduced in~\cite{czuba2024rankrefininginfmaxmln}. It simulates diffusion in a multilayer network where actors are the subject of spreading. The model uses two thresholds: $\mu$, the traditional threshold from the classic LTM, which dictates that a node receives positive input when the sum of weighted influences from its neighbours exceeds this value, and $\delta$ (referred to as the protocol), which governs how inputs from nodes representing an actor across layers are aggregated. When the protocol threshold is exceeded, the actor (and all nodes representing it) becomes active; otherwise, the actor remains inactive, even if some of the corresponding nodes in the layers receive positive input. We specifically use two edge cases for the protocol: $AND$, where positive input at all layers is required to activate an actor, and $OR$, where positive input at just one layer is sufficient for activation. As in~\cite{czuba2024rankrefininginfmaxmln}, we will denote the set of active actors at time step $t$ as $S_t$ (with the seed set denoted as $S_0$). Moreover, to clarify the definitions of the performance metrics (see Sec.~\ref{subsec:metrics}) employed in this study, we introduce an additional function as in Def.~\ref{def:spreading_mltm}.

\begin{theorem}[Spreading Dynamics under MLTM]
    Let $Y$ be a function to measure the spreading dynamics in a network $M$ under the Multilayer Linear Threshold Model:
    \[
    Y(M, t) = \sum_{a \in A} y_a(t),
    \]
    $y_a(t) \in \{0, 1\}$ denotes the state of actor $a$ at time step $t$.
    \label{def:spreading_mltm}
\end{theorem}

\subsection{Seed Selection Methods}

\subsubsection{Basic Heuristics}\label{subsubsec:basic_ssm}

We employed five seed selection methods acting as a baseline for the further comparison with MDS: Degree Centrality (denoted as \textit{deg-c}), Degree Discount~\cite{chen2009degree_discount} (\textit{deg-cd}), One-Hop Neighbourhood Size~\cite{magnani2011ml} (\textit{nghb-1s}), Neighbourhood Size Discount~\cite{czuba2024rankrefininginfmaxmln} (\textit{nghb-sd}), and Random Choice (\textit{random}). These methods belong to the class of rank-refining techniques, and their selection was motivated by their ability to generate a complete ranking of all actors within the network, ensuring compatibility with the application of MDS. We use each of these methods as described in~\cite{czuba2024rankrefininginfmaxmln}.

\subsubsection{Sorting with MDS}\label{subsubsec:mds_ssm}

To evaluate the effectiveness of MDS, all of the methods above were modified to include additional steps for filtering out actors which do not belong to $D$ (see Alg.~\ref{alg:seed_selection_mds}). With such a setting, we were able to compare spreading efficiency on two versions of a particular seed selection method and assess the usefulness of MDS.

\begin{algorithm}[ht]
    \caption{Seed Selection with MDS}
    \label{alg:seed_selection_mds}
    \KwIn{ \\
        $M = (A, L, V, E)$ -- multilayer network \\
        $s$ -- seed set budget \\
        $\phi(M) \to A_{\phi}$ -- rank-refining seed selection heuristic \\
        $\kappa(M) \to D: D \subseteq A$ -- function returning MDS of $M$
    }
    \KwOut{$S$ -- selected seed set or \texttt{NaN} if selection fails} 
    $D \gets \kappa(M)$ \\
    \If{$|D| < s$}{
        \Return \texttt{NaN}
    }
    $A_{\phi} \gets \phi(M)$ \\
    $S \gets \emptyset$ \\
    \For{$a \in A_{\phi}$}{
        \If{$a \in D$}{
            $S \gets S \cup \{a\}$
        }
        \If{$|S| = s$}{
            \texttt{Break}
        }
    }
    \Return $S$
\end{algorithm}

Selecting a seed set with MDS consists of several steps. First, the minimal dominating set $D$ is obtained using Alg.~\ref{alg:driver_actor_selection}. Simultaneously, a sorted list of all actors, $A_{\phi}$, is created based on a particular heuristic $\phi$ listed in Sec.~\ref{subsubsec:basic_ssm}. The final seed set consists of the first $\lfloor s \cdot |A| \rfloor$ actors from $A_{\phi}$ that also belong to $D$. However, particularly for large budgets, $|D|$ can be smaller than a maximal number of actors that can be used as a seed set. In such cases, we exclude the simulation from the evaluation process, since assessing the effectiveness of MDS is impossible.

It is also good to note that we slightly modified Alg.~\ref{alg:driver_actor_selection} to address scalability issues. Specifically, for the largest evaluated network, we observed that the algorithm could not be completed within a reasonable time. To mitigate this, we introduced a timeout threshold for refining the initial solution. It was set to 5 minutes per 1000 actors, leading to a maximum runtime of over 5 hours per MDS search in the \textit{timik} network.

\subsection{Metrics}\label{subsec:metrics}

To assess the quality of a seed set, we employed two metrics: \textit{Gain} ($\Gamma$) for the overall effectiveness and the \textit{Area under Curve} ($\Lambda$) for the dynamics of the diffusion. Their formulas are presented in Tab.~\ref{tab:metrics}. This study aims to evaluate if the MDS can be used to improve seed sets in the influence maximisation problem. Thus, higher $\Gamma$ and $ \Lambda $ indicate a more effective seed set.

% The former one calculates the total network coverage achieved by seed set $S_0$ as a proportion of the actors activated during the diffusion and the total number of activatable actors: $\Gamma = \frac{|S_{\infty} - S_{0}|}{|A - S_{0}|}$, $\Gamma \in [0, 1]$. The latter one calculates the area under a normalised curve of spreading dynamics: $\Lambda = \int_{0}^{1}Y_{norm}(M, t) dt$, $\Lambda \in [0, 1]$.

\begin{table}[ht!]
    \caption{Spreading metrics employed in the study.}
    \begin{tabular}{lp{1.15cm}p{5.35cm}}
    Symbol & Name  & Description \\ \hline \hline
    $\Lambda$ & Area under Curve & Area under a normalised curve of spreading dynamics: $\Lambda = \int_{0}^{1}Y_{norm}(M, t) dt$, $\Lambda \in [0, 1]$ \\ \hline
    $\Gamma$ & Gain & Total network coverage achieved by a seed set $S_0$ as a proportion of the actors activated during the diffusion and the total number of activatable actors: $\Gamma = \frac{|S_{\infty} - S_{0}|}{|A - S_{0}|}, \Gamma \in [0, 1]$. \\
    \end{tabular}
    \label{tab:metrics}
\end{table}

A way how the metrics are calculated is presented in Fig.~\ref{fig:metrics}. We observe that the seed set obtained with an additional MDS filtering achieves better diffusion performance in terms of the final number of activations ($\Gamma$), yet it impairs the diffusion dynamics ($\Lambda$).

\begin{figure}[ht]
	\centering
	\includegraphics[width=1\linewidth]{figures/metrics.pdf}
	\caption{An example of $\Gamma$ and $\Lambda$ attained by the diffusion process within the \textit{er3} network under MLTM with $\mu = 0.4$, $\delta = \text{"AND"}$, initiated from a seed set selected using \textit{nghb-sd} with $s=35$. The black scale represents real values, whereas the red scale is used for computing $\Lambda$. Red lines indicate the number of pre-activated actors (i.e. those belonging to $S_0$) and the total number of actors in the network.}
    \label{fig:metrics}
\end{figure}

\subsection{Parameter Space}

To ensure the feasibility of the experiments, we selected the parameter space based on an initial series of trials. That allowed us to exclude cases where diffusion always failed to initiate as well as those where it saturated immediately. Notably, we decided to assign different budget sizes for the two protocols. We considered node activation thresholds ranging from $0.1$ to $0.9$ in increments of $0.1$. It is important to note that we did not introduce heterogeneity into the model --- all nodes were assigned the same threshold value. Despite the spreading under MLTM is deterministic, we repeated each experiment with a particular combination of $\delta$, $s$, $\mu$, and $\phi$ $30$ times, due to stohastic nature of MDS.

In total, each seed selection method was evaluated across $90$ different MLTM parameter combinations, resulting in $9900$ experiments. Tab.~\ref{tab:parameters} outlines the evaluated parameter space.

\begin{table}[ht]
    \centering
    \caption{Diffusion parameters evaluated in the study.}
    \begin{tabular}{lcc}
    Parameter & \multicolumn{2}{c}{Values range} \\ \hline \hline
    Protocol ($\delta$) & $OR$ & $AND$ \\
    Budget ($s$) [\% of $|A|$] & $\{5, 10, 15, 20, 25\}$ & $\{15, 20, 25, 30, 35\}$ \\
    Treshold ($\mu$) & \multicolumn{2}{c}{$\{0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9\}$} \\
    Seed selection method ($\phi$) & \multicolumn{2}{p{5cm}}{\{deg-c, deg-c-d, nghb-1s, nghb-sd, random\}} \\
    MDS repetitions & \multicolumn{2}{c}{$30$} \\ 
    \end{tabular}
    \label{tab:parameters}
\end{table}

\subsection{Implementation}

The experiments were implemented in Python 3.12, utilising spreading models and seed selection methods from the Network Diffusion library~\cite{czuba2024networkdiffusion}, version 0.17. The code was designed to ensure full reproducibility, even for stochastic simulations. All experiments were conducted on a workstation running Ubuntu 20.04.4 LTS with kernel 6.5.3-arch1-1, equipped with 376 GB of memory and an Intel(R) Xeon(R) Gold 6238 CPU @ 2.10 GHz with an x86\_64 architecture. The source code,  data, and results are available at: \url{https://github.com/network-science-lab/infmax-mds-ltm-mln}.

\section{Results Analysis}\label{sec:results}

We conduct the results analysis in three steps. First, we examine the MDSs obtained for each network to assess their variability with respect to the structural properties of the graphs. Next, we compare the seed sets used to initiate diffusion, focusing on the differences between those selected by the baseline heuristics and their MDS-filtered versions. Finally, based on the spreading metrics introduced in Sec.~\ref{subsec:metrics}, we evaluate the impact of incorporating MDS into the seed selection process on the influence spread process.

\subsection{Characteristics of MDSs}

We begin the analysis by examining the MDSs obtained for each network during the experiments to assess their variability. The results are presented in Tab.~\ref{tab:mds_networks}. The first column contains the size range of MDSs obtained during the experiments, followed by the average MDS size with standard deviation, both normalised by network size. Next, we report the number of unique MDSs out of the total computed in the experiments. The fourth column provides the average intersection over union (Jaccard similarity) between all MDS pairs. Finally, we include the entropy, calculated based on the frequency of each actor's occurrence across all MDSs.

\begin{table}[ht!]
    \centering
    \caption{Properties of MDSs obtained for each network.}
    \addtolength{\tabcolsep}{-0.05em}
    \begin{tabular}{lrrrrr}
        \multicolumn{1}{c}{Network} & \multicolumn{1}{c}{Size range} & \multicolumn{1}{c}{Avg. size} & \multicolumn{1}{c}{Unique} & \multicolumn{1}{c}{IoU} & \multicolumn{1}{c}{Entropy} \\ \hline \hline
        er-2 & $[0.26, 0.27]$ & \scinot{0.27}{3}{-3} & $300 / 300$ & $0.42$ & $9.13$ \\
        er-3 & $[0.34, 0.36]$ & \scinot{0.35}{4}{-3} & $300 / 300$ & $0.44$ & $9.41$ \\
        er-5 & $[0.34, 0.36]$ & \scinot{0.35}{4}{-3} & $300 / 300$ & $0.39$ & $9.54$ \\ \hline
        sf-2 & $[0.49, 0.50]$ & \scinot{0.50}{1}{-3} & $300 / 300$ & $0.88$ & $9.13$ \\
        sf-3 & $[0.75, 0.76]$ & \scinot{0.76}{1}{-3} & $298 / 300$ & $0.97$ & $9.60$ \\
        sf-5 & $[0.69, 0.70]$ & \scinot{0.70}{1}{-3} & $300 / 300$ & $0.92$ & $9.54$ \\ \hline
        aucs & $[0.28, 0.41]$ & \scinot{0.33}{2}{-2} & $77 / 300$ & $0.51$ & $5.01$ \\
        ckmp & $[0.32, 0.35]$ & \scinot{0.33}{6}{-3} & $300 / 300$ & $0.62$ & $6.94$ \\
        lazega & $[0.14, 0.17]$ & \scinot{0.15}{9}{-3} & $158 / 300$ & $0.31$ & $4.71$ \\
        l2-course & $[0.20, 0.22]$ & \scinot{0.21}{1}{-2} & $149 / 300$ & $0.34$ & $4.36$ \\
        timik & $[0.90, 0.91]$ & \scinot{0.91}{2}{-4} & $295 / 300$ & $0.99$ & $15.78$ \\
    \end{tabular}
    \label{tab:mds_networks}
\end{table}

It is interesting to observe the differences between Erd\H{o}s-R\'{e}nyi and Scale-free networks. The former can be controlled with significantly fewer driver actors than the latter. In both cases, nearly every simulation returned a different MDS. However, their similarity varies: Erd\H{o}s-R\'{e}nyi networks exhibit a much lower Jaccard similarity compared to Scale-free networks. This suggests that driver actors in that group can be assigned in a more random manner than in Scale-free graphs. 

With regards to real-world networks, MDS properties appear less regular. The average $|D|$ is comparable to that observed in Scale-free (\textit{timik}) and Erd\H{o}s-R\'{e}nyi models (\textit{aucs}, \textit{ckmp}, \textit{lazega}, \textit{l2-course}). In the following sections, we discuss the performance of real graphs in relation to their structural similarity to both artificial models.

Entropy values appear to correlate with network size. For instance, the smallest network, \textit{l2-course}, exhibits the lowest entropy, while the largest, \textit{timik}, has the highest. This suggests that larger networks provide more diverse MDS configurations. Regarding the relationship between network layers and MDS size, we observe that an increase in the number of layers corresponds to a larger MDS. Finally, the number of unique MDSs is correlated with network size. For smaller networks (e.g., \textit{aucs}, \textit{lazega}, \textit{l2-course}), it is likely that all possible MDS configurations were sampled.

Differences in MDS's properties regarding Erd\H{o}s-R\'{e}nyi and Scale-free models can be illustrated with Fig.~\ref{fig:mds_vis}. Since the degree distribution of the latter follows a power law, controlling the network requires selecting both the hubs (e.g., actors $A15$, $A32$) and outliers, which may have connections on only some layers (e.g., $A06$ or $A17$). Consequently, a larger number of actors must be selected to exert control over the network. On the other hand, Erd\H{o}s-R\'{e}nyi networks, which follow a Poisson distribution, exhibit a more even degree distribution. As a result, the MDS can be smaller (e.g., $|D|=4$ compared to $|D|=15$) and selected mostly from actors with the highest degree.

\begin{figure*}[t]
    \centering
    \subfloat[MDS on an exemplary two-layer Erd\H{o}s-R\'{e}nyi network; $|A|=35, |D|=4$]{
        \includegraphics[width=.95\linewidth]{figures/ER_1_manuscript.pdf}
        \label{subfig:er_mds}
    } \\
    \subfloat[MDS on an exemplary two-layer Scale-free network; $|A|=35, |D|=15$]{
        \includegraphics[width=.95\linewidth]{figures/PA_1_manuscript.pdf}
        \label{subfig:pa_mds}
    }
    \caption{Typical MDS alignment w.r.t. the actors' degree. The first two plots depict layers of the given network, while the third shows the degree distribution. Green stripes indicate the degrees of actors belonging to the MDS; the orange area marks the degree range of a set composed of the highest-degree actors with the same size as the MDS. In Fig.~\ref{subfig:er_mds}, the MDS exhibits a much stronger correlation with the highest-degree actors compared to Fig.~\ref{subfig:pa_mds}, where the MDS is larger and includes both hubs and low-degree actors.}
    \label{fig:mds_vis}
\end{figure*}

\subsection{Role of MDS in Seed Selection}

To assess the role of MDS in the seed selection process, we applied the following approach. All obtained seed sets (i.e., those from experiments where $|D| \geq s$) were grouped into pairs based on the protocol, budget size, experiment repetition, and network for both the baseline and MDS-filtered methods. The Jaccard similarity was computed for each of these pairs. Activation thresholds were intentionally omitted, as they do not affect seeding, while protocols were retained since budget sizes were assigned separately to each. Finally, the similarity scores were averaged over each network type, seed selection method, and budget size.

Tab.~\ref{tab:mds_role} presents the outcomes. A higher Jaccard similarity suggests a less prominent role of MDS, whereas smaller values indicate a greater impact of MDS on the given heuristic.

\begin{table}[ht!]
    \centering
    \caption{Similarities of seed sets selected with(out) MDS.}
    \addtolength{\tabcolsep}{-0.25em}

    \begin{tabular}{l|rrrrr}
    \multicolumn{6}{c}{Avg. $IoU(\phi, \phi_\kappa)$ --- Erd\H{o}s-R\'{e}ny networks} \\ \hline \hline
    \multicolumn{1}{c}{$s$} & \multicolumn{1}{c}{\textit{deg-c}} & \multicolumn{1}{c}{\textit{deg-cd}} & \multicolumn{1}{c}{\textit{nghb-1s}} & \multicolumn{1}{c}{\textit{nghb-sd}} & \multicolumn{1}{c}{\textit{random}} \\ \hline
     5 & $0.48$ $(0.08)$ & $0.50$ $(0.08)$ & $0.41$ $(0.07)$ & $0.42$ $(0.07)$ & $0.02$ $(0.02)$ \\
    10 & $0.41$ $(0.05)$ & $0.43$ $(0.04)$ & $0.37$ $(0.05)$ & $0.35$ $(0.04)$ & $0.05$ $(0.01)$ \\
    15 & $0.36$ $(0.03)$ & $0.39$ $(0.03)$ & $0.34$ $(0.03)$ & $0.33$ $(0.02)$ & $0.08$ $(0.02)$ \\
    20 & $0.34$ $(0.02)$ & $0.36$ $(0.02)$ & $0.32$ $(0.02)$ & $0.32$ $(0.02)$ & $0.11$ $(0.02)$ \\
    25 & $0.33$ $(0.02)$ & $0.34$ $(0.02)$ & $0.31$ $(0.02)$ & $0.31$ $(0.02)$ & $0.14$ $(0.02)$ \\
    30 & $0.31$ $(0.01)$ & $0.32$ $(0.02)$ & $0.30$ $(0.01)$ & $0.29$ $(0.01)$ & $0.17$ $(0.01)$ \\
    35 & $0.30$ $(0.01)$ & $0.31$ $(0.02)$ & $0.29$ $(0.01)$ & $0.29$ $(0.02)$ & $0.21$ $(0.01)$ \\
    \end{tabular} \\

    \begin{tabular}{l|rrrrr}
    \multicolumn{6}{c}{Avg. $IoU(\phi, \phi_\kappa)$ --- Scale-free networks} \\ \hline \hline
    \multicolumn{1}{c}{$s$} & \multicolumn{1}{c}{\textit{deg-c}} & \multicolumn{1}{c}{\textit{deg-cd}} & \multicolumn{1}{c}{\textit{nghb-1s}} & \multicolumn{1}{c}{\textit{nghb-sd}} & \multicolumn{1}{c}{\textit{random}} \\ \hline
     5 & $0.49$ $(0.07)$ & $0.53$ $(0.08)$ & $0.47$ $(0.06)$ & $0.46$ $(0.07)$ & $0.03$ $(0.02)$ \\
    10 & $0.37$ $(0.03)$ & $0.38$ $(0.04)$ & $0.34$ $(0.03)$ & $0.35$ $(0.03)$ & $0.05$ $(0.02)$ \\
    15 & $0.31$ $(0.04)$ & $0.34$ $(0.02)$ & $0.30$ $(0.02)$ & $0.32$ $(0.02)$ & $0.08$ $(0.02)$ \\
    20 & $0.29$ $(0.03)$ & $0.32$ $(0.02)$ & $0.28$ $(0.03)$ & $0.30$ $(0.04)$ & $0.11$ $(0.02)$ \\
    25 & $0.27$ $(0.03)$ & $0.30$ $(0.03)$ & $0.27$ $(0.05)$ & $0.29$ $(0.06)$ & $0.14$ $(0.01)$ \\
    30 & $0.27$ $(0.04)$ & $0.29$ $(0.05)$ & $0.26$ $(0.06)$ & $0.30$ $(0.07)$ & $0.18$ $(0.01)$ \\
    35 & $0.26$ $(0.06)$ & $0.28$ $(0.06)$ & $0.27$ $(0.08)$ & $0.30$ $(0.08)$ & $0.21$ $(0.02)$ \\
    \end{tabular} \\

    \begin{tabular}{r|rrrrr}
    \multicolumn{6}{c}{Avg. $IoU(\phi, \phi_\kappa)$ --- real networks} \\ \hline \hline
    \multicolumn{1}{c}{$s$} & \multicolumn{1}{c}{\textit{deg-c}} & \multicolumn{1}{c}{\textit{deg-cd}} & \multicolumn{1}{c}{\textit{nghb-1s}} & \multicolumn{1}{c}{\textit{nghb-sd}} & \multicolumn{1}{c}{\textit{random}} \\ \hline
     5 & $0.49$ $(0.21)$ & $0.53$ $(0.17)$ & $0.47$ $(0.23)$ & $0.45$ $(0.23)$ & $0.04$ $(0.06)$ \\
    10 & $0.43$ $(0.15)$ & $0.45$ $(0.14)$ & $0.39$ $(0.17)$ & $0.41$ $(0.18)$ & $0.06$ $(0.06)$ \\
    15 & $0.41$ $(0.14)$ & $0.42$ $(0.14)$ & $0.37$ $(0.16)$ & $0.39$ $(0.17)$ & $0.08$ $(0.06)$ \\
    20 & $0.41$ $(0.13)$ & $0.42$ $(0.13)$ & $0.40$ $(0.14)$ & $0.42$ $(0.16)$ & $0.11$ $(0.04)$ \\
    25 & $0.42$ $(0.14)$ & $0.43$ $(0.14)$ & $0.42$ $(0.15)$ & $0.45$ $(0.16)$ & $0.14$ $(0.04)$ \\
    30 & $0.41$ $(0.15)$ & $0.43$ $(0.14)$ & $0.41$ $(0.16)$ & $0.46$ $(0.16)$ & $0.18$ $(0.04)$ \\
    35 & $0.54$ $(0.17)$ & $0.62$ $(0.07)$ & $0.56$ $(0.16)$ & $0.66$ $(0.09)$ & $0.22$ $(0.02)$ \\
    \end{tabular}

    \label{tab:mds_role}
\end{table}

The results presented in Tab.~\ref{tab:mds_role} indicate that the average similarity between seed sets does not exceed $0.54$ across all cases, demonstrating that MDS filtering consistently influences the seed selection process. The standard deviation remains relatively small in all cases, confirming the observed trends.

As expected, the lowest similarity between seed sets is observed for the \textit{random} selection method, as it lacks a structured approach to choosing influential nodes. The remaining seed selection methods exhibit comparable IoU across different budget sizes, suggesting that MDS filtering affects them uniformly, thereby underscoring its universal applicability.

For both Erd\H{o}s-R\'{e}nyi and Scale-free networks, the similarity between seed sets obtained with and without MDS filtering consistently decreases as the budget size increases (with the exception of \textit{random}). This trend implies that the impact of MDS filtering becomes bigger as the seeding budget grows.

For smaller budget sizes, where the influence of MDS is less significant (i.e., IoU values are higher), the similarity between baseline and MDS-filtered seed sets is greater for Scale-free networks than for Erd\H{o}s-R\'{e}nyi graphs. This observation aligns with the findings presented in Tab.~\ref{tab:mds_networks}, which indicate that MDS exhibits higher variability in the latter network model. Consequently, there exist more possible MDS configurations which do not always align with the baseline ranking.

In real networks, trends reflect the diverse structural patterns present in these graphs, so they are not so straightforward. The higher standard deviation values further confirm the greater variability in seed set similarities within this cohort. However, the \textit{random} method maintains consistency with results obtained for synthetic networks. Nevertheless, when comparing IoU for edge $s$ values ($5$, $35$), a trend similar to that observed in artificial graphs emerges --- namely, the influence of MDS filtering increases as the budget size grows.

\subsection{Effectiveness of MDS in Influence Maximisation}

Since this study aims to evaluate the general usability of MDS for seed set creation, we have deliberately omitted the influence of specific seed selection methods. To keep the report concise, we have also aggregated the results across different network types. Figure~\ref{fig:heatmaps}, which is discussed below, presents a comprehensive summary of our experimental results in a structured format. Readers interested in a more detailed analysis are encouraged to explore the repository.

\begin{figure*}[hp]
    \centering
    % erdos renyi networks
    \subfloat[]{
        \includegraphics[page=10, width=.24\linewidth]{figures/heatmaps_aggregated.pdf}
        \label{subfig:er_and_heatmap_gain}
    }
    \subfloat[]{
        \includegraphics[page=9, width=.24\linewidth]{figures/heatmaps_aggregated.pdf}
        \label{subfig:er_and_heatmap_auc}
    }
    \subfloat[]{
        \includegraphics[page=12, width=.24\linewidth]{figures/heatmaps_aggregated.pdf}
        \label{subfig:er_or_heatmap_gain}
    }
    \subfloat[]{
        \includegraphics[page=11, width=.24\linewidth]{figures/heatmaps_aggregated.pdf}
        \label{subfig:er_or_heatmap_auc}
    } \\ \vspace{-.35cm}
    % scale free networks
    \subfloat[]{
        \includegraphics[page=2, width=.24\linewidth]{figures/heatmaps_aggregated.pdf}
        \label{subfig:sf_and_heatmap_gain}
    }
    \subfloat[]{
        \includegraphics[page=1, width=.24\linewidth]{figures/heatmaps_aggregated.pdf}
        \label{subfig:sf_and_heatmap_auc}
    }
    \subfloat[]{
        \includegraphics[page=4, width=.24\linewidth]{figures/heatmaps_aggregated.pdf}
        \label{subfig:sf_or_heatmap_gain}
    }
    \subfloat[]{
        \includegraphics[page=3, width=.24\linewidth]{figures/heatmaps_aggregated.pdf}
        \label{subfig:sf_or_heatmap_auc}
    } \\ \vspace{-.35cm}
    % real networks
    \subfloat[]{
        \includegraphics[page=6, width=.24\linewidth]{figures/heatmaps_aggregated.pdf}
        \label{subfig:real_and_heatmap_gain}
    }
    \subfloat[]{
        \includegraphics[page=5, width=.24\linewidth]{figures/heatmaps_aggregated.pdf}
        \label{subfig:real_and_heatmap_auc}
    }
    \subfloat[]{
        \includegraphics[page=8, width=.24\linewidth]{figures/heatmaps_aggregated.pdf}
        \label{subfig:real_or_heatmap_gain}
    }
    \subfloat[]{
        \includegraphics[page=7, width=.24\linewidth]{figures/heatmaps_aggregated.pdf}
        \label{subfig:real_or_heatmap_auc}
    }
    \caption{Improvement of MDS filtering across various network types and spreading regimes, measured using $\Gamma$ and $\Lambda$. Each tile presents six values. The \textbf{upper value} shows the mean difference between the baseline method and its MDS-filtered variant (in the range $[-1, 1]$), calculated across all feasible experiments. The \textbf{middle row} presents the number of feasible experiments, split into those with an absolute difference greater (\textbf{left}) or less than or equal to $0.01$ (\textbf{right}). The \textbf{lower row} indicates unfeasible experiments: where diffusion couldn't start due to an overly strict spreading regime for both methods (\textbf{left}), and where $|D| < s$ (\textbf{right}). The sum of numbers in the middle and lower rows equals the total number of networks in the category multiplied by the number of seed selection methods. The \textbf{tile colour} represents the percentage of feasible simulations where the MDS-filtered variant outperformed the baseline, computed over feasible simulations with an absolute difference greater than $0.01$.}
    \label{fig:heatmaps}
\end{figure*}

\subsubsection{Feasibility of the Experiments}

We begin our analysis with a quantitative summary of the experiments, focusing on the second and third rows of each tile in the heatmap. The former represents the number of experiments that were executed correctly, while the latter provides insights into the cases where simulations failed. Specifically, failures occurred either due to overly restrictive diffusion parameters (left value) or when the MDS was too small to select a seed set with it (right value). It is important to note that the corresponding values of failed experiments should be identical for pairs of $\Gamma$ and $\Lambda$ heatmaps that represent the same dataset fold and applied protocol. Moreover, the number of cases where MDS was too small to trigger diffusion is independent of $\mu$ and $\delta$. Consequently, these values should be the same for all experiments conducted for the given $s$ and the network type.

\paragraph{Failures due to Overly Demanding Parameters}

In Erd\H{o}s-R\'{e}nyi networks under the $AND$ protocol, failures occur for $\mu \geq 0.7$, with their number increasing as $\mu$ grows. Conversely, as the budget increases, the number of failures decreases. In the $OR$ regime, all experiments were feasible. A similar pattern is observed in Scale-free networks for $\delta = AND$; however, the reduction in failed experiments due to an increasing budget occurs at a higher rate. For $\delta = OR$, all experiments were feasible. Finally, for real networks and spreading under the $AND$ protocol, the region of overly strict parameters corresponds to $\mu \geq 0.4$ or a budget of $s \leq 30$. In the $OR$ regime, failures occur for $\mu \geq 0.5$ or $s \leq 10$. 

As expected, the number of failed experiments depends on both $\mu$ and $s$. The highest failure rates occur for large $\mu$ and small $s$, while relaxing at least one of these parameters increases the likelihood of triggering a spread. Compared to artificial networks, the subset of real networks in our study poses greater challenges in initiating the diffusion process.

\paragraph{Failures due to Insufficient Size of MDS}

In Erd\H{o}s-R\'{e}nyi networks, for budgets $s \geq 30$, failures resulting from an insufficiently large MDS accounted for 33.33\% of the cases. In contrast, in Scale-free networks, the MDS was consistently large enough to select a seed set that matched the budget, and no such failures were observed. For real networks, failures of this nature began to manifest for budgets $s \geq 20$, with the frequency of these failures increasing as the budget size grew. This trend aligns with the analysis of the MDS size, as presented in Tab.~\ref{tab:mds_networks}.

\paragraph{Feasible Experiments}

The conditions that affect the number of feasible experiments (represented by a sum of the middle row in the tiles of the heatmaps) are the opposite of those described in the previous subsection. Specifically, a smaller threshold makes it easier to trigger the diffusion. A similar effect is observed with $s$, although here we encounter an obstacle in the form of the MDS size, which may be smaller than $s$ and thus prevent the simulation from being executed.

\subsubsection{Average Performance Differences}

This section examines the average difference (the top value on each heatmap's tile and denoted as $\Delta$) between experiments with and without the MDS filtering operation, using both metrics employed.

\paragraph{Erd\H{o}s-R\'{e}nyi Networks}

Results for spreading triggered by the $AND$ protocol indicate that, in general, the differences for $\Gamma$ tend to increase with the budget across experiments with a similar $\mu$. For small thresholds, the average differences in spreading effectiveness favour MDS-backed methods, while for larger $\mu$, baseline methods tend to prevail. Similar trends are observed for $\Delta \Lambda$. For $\delta=OR$, $\Delta \Gamma$ shows no clear trends. The average difference fluctuates around 0 and is generally smaller than for $AND$. For the diffusion dynamics, the trends mirror those seen for $\Delta \Gamma$.

% The value ranges AND: $\Gamma \in [0.05; -0.13]$, $\Lambda \in [0.11; -0.15]$.
% The value ranges OR: $\Gamma \in [0.05; -0.11]$, $\Lambda \in [0.02; -0.05]$.

\paragraph{Scale-free Networks}

For the $AND$ protocol, significant differences are observed for $\Gamma$, with values reaching up to $0.26$. As the budget increases, so does the difference, and for small thresholds, MDS-backed methods outperform the baseline. However, for larger thresholds, baseline methods prevail. For $\Delta \Lambda$, similar trends to $\Delta \Gamma$ are observed, but the values are slightly smaller. For the $OR$ protocol, $\Delta \Gamma$ shows no strong trends. Positive values (favouring MDS) are very small and close to $0$, while negative values exhibit a larger magnitude. For $\Delta \Lambda$, most values are negative, suggesting that using MDS even slows down the diffusion.

% The value ranges AND: $\Gamma \in [0.26; -0.12]$, $\Lambda \in [0.20; -0.10]$.
% The value ranges OR: $\Gamma \in [0.02; -0.17]$, $\Lambda \in [0.00; -0.15]$.

\paragraph{Real Networks}

For the $AND$ protocol, $\Delta \Gamma$ values are smaller than those for Scale-free networks but larger than those in observed Erd\H{o}s-R\'{e}nyi graphs. For small $\mu$, MDS-backed methods tend to outperform the baseline, though less prominently than in Scale-free networks, while for larger thresholds, baseline methods prevail. However, the trend of increasing differences with the budget is weaker than in artificial graphs. A similar pattern holds for $\Delta \Lambda$. For $\delta = OR$, $\Delta \Gamma$ values are scattered around $0$ with no clear trends, similar to Erd\H{o}s-R\'{e}nyi networks. For $\Delta \Lambda$, values are more often negative than for $\Delta \Gamma$, but no strong trends emerge.

%PB Consider to add clases of real networks here - linking the results  an placing them between ER and SF
%MCz there's no space for that right now. maybe a reviewer will ask about it :)

% The value ranges AND: $\Gamma \in [0.11; -0.09]$, $\Lambda \in [0.08; -0.07]$.
% The value ranges OR: $\Gamma \in [-0.17, 0.05]$, $\Lambda \in [-0.06, 0.02]$.

\subsubsection{Seed Set Improvement by MDS}

The final part of the analysis in Fig.~\ref{fig:heatmaps} concerns the percentage of feasible simulations where MDS-backed methods "significantly" outperform their baseline versions, as indicated by colour. This comparison is intended to serve as a guideline for identifying conditions under which incorporating MDS into the seed selection process enhances diffusion, has no substantial impact, or even hinders the spreading process. In the following section, we provide a detailed discussion of each heatmap. Before that, we explain the methodology used to construct them.

For the purpose of analysis, we define a significant difference as an absolute difference according to $\Gamma$ or $\Lambda$ greater than $0.01$ (1 percentage point) between simulations conducted on the same network and under the same spreading regime but with seed sets selected using either the baseline method ($\phi$) or its MDS-backed variant ($\phi_\kappa$). The threshold of $0.01$ was chosen arbitrarily by the authors to exclude cases where the difference is negligible, i.e. when MDS neither significantly boosts nor disrupts diffusion.

To quantify the number of significantly different cases among all experiments, we split the count of feasible simulations into two values, represented in the second row of each tile: the left-hand value denotes the number of significantly different cases, while the right-hand value corresponds to cases where the difference is insignificant. The percentage of experiments in which $\phi_\kappa$ outperforms $\phi$ (i.e. represented by the tile colour) is computed using the former value as the denominator and, as the numerator, the count of significantly different cases where diffusion triggered with $\phi_\kappa$ was more effective than with $\phi$, according to the given metric.

Finally, it is important to note that the scale is symmetrical. The greener the tile, the more frequently MDS improves the seed selection process, whereas the less green it is, the more frequently the baseline method prevails. If no significantly different cases are observed for a given combination of network type, $s$, and $\mu$, the corresponding tile is displayed in grey. Naturally, MDS is not a favourable choice in such scenarios, as it provides no benefit while increasing the computational complexity of the seed selection process.

\paragraph{Erd\H{o}s-R\'{e}nyi Networks}

For the $AND$ protocol, MDS improves the overall effectiveness of diffusion in cases with small thresholds. The larger the budget, the greater the number of cases with a significant difference, and the average $\Delta \Gamma$ increases accordingly. We observe a transition boundary running diagonally across $\mu=0.4, s=25$, below which, regardless of $s$, the baseline methods remain more effective or the gain brought by MDS is insignificant. W.r.t. the spreading dynamics ($\Lambda$), we also observe a positive impact of MDS for diffusion with a small $\mu$ or a large $s$. Here, the transition between the region where baseline methods prevail is smoother, but in all cases with $\mu \geq 0.4$, classic approaches dominate.

For the $OR$ protocol, a different trend emerges for both metrics. MDS demonstrates its superiority in two regions corresponding to the extreme values of $\mu$. Between them, we identify a zone where baseline methods dominate, stretching diagonally from low values of both $s$ and $\mu$ to high values of these parameters. For $\Gamma$, this trend is compressed by the region of insignificantly differing runs, and MDS exhibits stronger dominance for $\mu \geq 0.8$ and $10 \leq s \leq 20$. For $\Lambda$, the aforementioned trend is more pronounced, with the region of the most significant improvement brought by MDS resembling that observed for $\Gamma$.

\paragraph{Scale-free Networks}

Under the $AND$ protocol, Scale-free networks exhibit the greatest improvement in spreading across both metrics. As in Erd\H{o}s-R\'{e}nyi graphs, experiments with $\mu > 0.4$ favour baseline methods, whereas below this threshold, MDS significantly enhances diffusion, both in terms of the proportion of superior cases and the average $\Delta \Gamma$. Notably, in this region, most feasible simulations show a substantial difference in $\Gamma$ between runs triggered by seed sets selected with baseline and MDS-backed methods, further reinforcing the advantage of the latter. A similar trend is observed for $\Lambda$, though the transition between MDS- and baseline-dominated regions appears rougher and more diagonally oriented, with $\Delta\Lambda$ generally lower than $\Delta\Gamma$.

For the $OR$ protocol, the heatmaps resemble those of Erd\H{o}s-R\'{e}nyi networks, forming a diagonal zone where baseline methods dominate. This region is broader for $\Lambda$ and narrower for $\Gamma$. Although the $\Gamma$ heatmap contains more green-coloured tiles, the improvement brought by MDS remains limited. In many cases, the observed advantage is deceptive --- the number of significantly differing results is small (at most $4$ out of $15$), and $\Delta\Gamma$ does not exceed $0.02$. Moreover, MDS-backed methods occasionally disrupt diffusion, as seen for $\mu=0.7, s=10$ or $\mu=0.8, s=25$. The results for spreading dynamics also support this finding, providing evidence that MDS does not improve diffusion in Scale-free networks under the $OR$ protocol.

\paragraph{Real Networks}

Heatmaps for the $AND$ protocol closely resemble those obtained for Scale-free networks. However, the values of $\Delta \Gamma$ and $\Delta \Lambda$ are generally more aligned with those observed in Erd\H{o}s-R\'{e}nyi graphs, meaning the results are more concentrated around zero. The diagonal transition boundary between regions dominated by MDS and baseline methods appears more vertical and less abrupt.

In the $OR$ protocol, the correlation between both heatmaps is weaker than in the $AND$ case. Nevertheless, the same pattern seen in Erd\H{o}s-R\'{e}nyi networks emerges, where zones of strong MDS dominance are divided by a diagonal region stretching from small $\mu$ and $s$ to large values of both parameters. For $\Gamma$, seed selection methods incorporating MDS filtering are favoured in most cases, but the average improvement remains modest, not exceeding $0.04$. In contrast, results for $\Lambda$ are more evenly distributed, with the proportion of significantly feasible cases where MDS-backed methods outperform their baseline counterparts fluctuating around $50\%$.

\section{Conclusions}\label{sec:conclusions}

% This chapter summarises the key findings of our study, discussing the effectiveness of MDS in influence maximisation. We highlight the conditions under which methods utilising MDS outperforms their baseline variants, address the study’s limitations, and outline potential directions for future research.

% \subsection{Contributions}

In this work, we examined the impact of using MDS for seed selection in a problem of influence maximisation in multilayer networks under the Linear Threshold Model. We conducted a comprehensive analysis across five rank-refining seed selection heuristics, eleven networks, and a wide range of diffusion regimes. Additionally, we adapted the local improvement algorithm for finding MDS to the multilayer network setting.

\subsection{Key Findings}

After analysing the results, we conclude that using MDS in seed selection benefits diffusion under low activation thresholds (up to $\mu=0.4$) and the $\delta=AND$, regardless of the network type. In real-world scenarios, this spreading regime may correspond to situations where convincing someone requires fewer acquaintances, but these connections must span all layers (see the election example in Sec.~\ref{sec:intro}). Higher seeding budgets further amplify this effect, as supported by Tab.~\ref{tab:mds_role}, which shows that the role of MDS becomes more significant with increasing $s$. The underlying reason is that MDS distributes seeds more widely across the network, including its periphery, whereas baseline methods concentrate them in the core. At lower $\mu$, this ensures faster coverage of the entire network. Baseline methods, confined to the core, lack seeds in the periphery. As the threshold increases, MDS-backed methods cease to be effective sooner, as their influence is split between the core and periphery.

Under the $OR$ protocol, where spreading is inherently easier, the effects observed in $AND$ are far less pronounced. A seed set strong on a single layer is often sufficient to drive diffusion across the entire network, which baseline methods achieve more effectively. However, when traditional approaches fail under high thresholds, MDS can offer an advantage. In situations where convincing individuals through standard methods becomes challenging, MDS-selected seeds facilitate diffusion that would otherwise not occur.

We also observe that Scale-free networks are the most susceptible to diffusion improvement with MDS. This stems from the presence of both hub and peripheral nodes in MDS (see Fig.~\ref{fig:mds_vis}). Unlike Erd\H{o}s-R\'{e}nyi networks, which distribute connections more evenly, Scale-free graphs benefit from seed sets that span both the core and periphery, making MDS-backed methods more effective in triggering diffusion. Moreover, the role of MDS in seed selection is the most pronounced for this network type compared to the others (see Tab.~\ref{tab:mds_role}). In contrast, Erd\H{o}s-R\'{e}nyi networks are less suitable for MDS-based approaches due to their degree distribution, which results in MDS being more randomised and typically too small (see Tab.~\ref{tab:mds_networks}) to meet the budget requirements.

For the real networks analysed, MDS sizes (Tab.~\ref{tab:mds_networks}) suggest this subset includes both networks resembling Scale-free and Erd\H{o}s-R\'{e}nyi models, making it the most representative of real-world scenarios. As shown in Fig.~\ref{fig:heatmaps}, MDS offers the greatest benefit under the $AND$ protocol with lower activation thresholds, improving overall coverage and diffusion dynamics.

Finally, despite improving the spreading process in some scenarios, using MDS comes with additional computational costs (see Sec.~\ref{subsubsec:mds_ssm}) that need to be taken into consideration when choosing a seed selection approach. Nonetheless, in some cases, the increase in $\Lambda$ or $\Gamma$ might be big enough to justify the additional time needed to compute MDS.

\subsection{Limitations of the Study and Next Steps}

This study includes three types of networks; however, many other models could be considered. Future work could explore whether our findings are applicable to other graph models, such as Small-world networks. Similarly, alternative spreading models, such as the Independent Cascade, or different methods for identifying MDS could be investigated. A potential direction for further research would be to address these limitations.

% Although MDS improves diffusion for only a specific subset of parameters, it could be used to develop more sophisticated heuristics that leverage this property. For example, it could be made size-adaptive (therefore no longer minimal, but still dominant), thus enhancing its applicability to cases that were excluded from this study due to the small size of the MDS and the resulting inability to meet the seeding budget requirements.

While the steps outlined here are only examples of potential directions for deeper exploration of the problem undertaken in this work, the primary conclusion remains clear: if one seeks to persuade a wide audience, particularly those whose conviction is easily swayed but must be thoroughly convinced across all aspects of their lives, MDS is a good choice.

% if have a single appendix:
%\appendix[Proof of the Zonklar Equations]
% or
%\appendix  % for no appendix heading
% do not use \section anymore after \appendix, only \section*
% is possibly needed

% use appendices with more than one appendix
% then use \section to start each appendix
% you must declare a \section before using any
% \subsection or using \label (\appendices by itself
% starts a section numbered zero.)

\section*{Acknowledgment}

This research was partially supported by the Australian Research Council, Grant No. DP190101087, the National Science Centre, Poland, Grant No. 2022/45/B/ST6/04145, the Polish Ministry of Education and Science programme “International Projects Co-Funded”, and the EU under the Horizon Europe, Grant No. 101086321. Views and opinions expressed are those of the authors and do not necessarily reflect those of the funding agencies. 

% Can use something like this to put references on a page
% by themselves when using endfloat and the captionsoff option.
\ifCLASSOPTIONcaptionsoff
  \newpage
\fi



% trigger a \newpage just before the given reference
% number - used to balance the columns on the last page
% adjust value as needed - may need to be readjusted if
% the document is modified later
%\IEEEtriggeratref{8}
% The "triggered" command can be changed if desired:
%\IEEEtriggercmd{\enlargethispage{-5in}}

% references section

% can use a bibliography generated by BibTeX as a .bbl file
% BibTeX documentation can be easily obtained at:
% http://mirror.ctan.org/biblio/bibtex/contrib/doc/
% The IEEEtran BibTeX style support page is at:
% http://www.michaelshell.org/tex/ieeetran/bibtex/

%Papers should cite the most relevant related work and avoid excessive citations to the work of the authors or others. In particular, self-citations should be kept to an appropriate minimum (no more than five). The connection of each reference to the paper should be apparent from the text. The Editorial Board reserves the right to reject papers that it considers violate the above policy and include citations for the purpose of influencing bibliometric indices.
\bibliographystyle{IEEEtran}
% argument is your BibTeX string definitions and bibliography database(s)
\bibliography{references.bib}
%
% <OR> manually copy in the resultant .bbl file
% set second argument of \begin to the number of references
% (used to reserve space for the reference number labels box)
%\begin{thebibliography}{1}

%\end{thebibliography}

% biography section
% 
% If you have an EPS/PDF photo (graphicx package needed) extra braces are
% needed around the contents of the optional argument to biography to prevent
% the LaTeX parser from getting confused when it sees the complicated
% \includegraphics command within an optional argument. (You could create
% your own custom macro containing the \includegraphics command to make things
% simpler here.)
%\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{mshell}}]{Michael Shell}
% or if you just want to reserve a space for a photo:

\vskip -1\baselineskip plus -1fil

\begin{IEEEbiographynophoto}
{Micha{\l} Czuba}
is a PhD candidate at Wroc{\l}aw University of Science and Technology (WUST), Poland, in the discipline of Information and Communication Technology. He received an BSc in Control Engineering and Robotics from WUST in 2018, MSc in Mechatronics from WUST in 2019, and BSc in Computer Science from WUST in 2020. His research interests are focused on problems of spreading phenomena in multilayer networks.
\end{IEEEbiographynophoto}

\vskip -1\baselineskip plus -1fil

\begin{IEEEbiographynophoto}{Mingshan Jia}
is a Lecturer at the School of Computer Science, University of Technology Sydney (UTS). He received a BE degree in information engineering from Xi’an Jiaotong University, Xi’an, China, in 2008, an ME degree in information and telecommunication systems from the University of Technology of Troyes, France, in 2011, and a PhD from the UTS in 2022.
\end{IEEEbiographynophoto}

\vskip -1\baselineskip plus -1fil

\begin{IEEEbiographynophoto}{Piotr Br{\'o}dka}
is an Associate Professor at WUST. In 2008, he received an MSc in Computer Science from WUST and Blekinge Institute of Technology, Sweden. In 2012 he received PhD from WUST. Six years later, he was awarded DSc in Information and Communication Technology. He was a Visiting Scholar at Stanford University in 2013 and a Visiting Professor at UTS between 2018 and 2025. He has authored over 100 research articles related to computational network science. More: \url{https://linktr.ee/piotrbrodka} 
\end{IEEEbiographynophoto}

\vskip -1\baselineskip plus -1fil

\begin{IEEEbiographynophoto}{Katarzyna Musial}
was awarded her PhD in Computer Science in 2009 from WUST, and in 2010 she was appointed a Lecturer in Informatics at Bournemouth University, UK. She joined King’s College London in 2011 as a Lecturer in Computer Science. In 2015, she returned to Bournemouth as an associate professor of computing. Since 2017, she has been a Professor of Network Science at the School of Computer Science and a Co-Director of the Complex Adaptive Systems Lab at UTS. More: \url{http://katarzyna-musial.com}
\end{IEEEbiographynophoto}

\vskip -1\baselineskip plus -1fil

% You can push biographies down or up by placing
% a \vfill before or after them. The appropriate
% use of \vfill depends on what kind of text is
% on the last page and whether or not the columns
% are being equalized.

\vfill

% Can be used to pull up biographies so that the bottom of the last one
% is flush with the other column.
%\enlargethispage{-5in}

% that's all folks
\end{document}


% cover note

Dear Professor Giacomo Como,

I kindly request the consideration of our manuscript for publication in CONES. This study aims to bridge concepts from network control with the problem of influence spreading in multilayer networks. By incorporating the minimal dominating set into the process of selecting diffusion seeds, we explore its potential to enhance influence maximisation strategies under the Linear Threshold Model. Given this focus, we believe that CONES is a highly suitable venue for our research.

I look forward to your feedback.

Best regards,
Michał Czuba
