\section{Introduction}

% Semantic parsing is the task of converting natural language (NL) into logical, symbolic meaning representations \citep{survey_semanticparsing}. 
% \heng{maybe it's better to call it as logical semantic parsing. because usually semantic parsing refers to semantic role labeling} \jinu{although the most popular semantic parsing is SRL, the general definition of semantic parsing includes logic/DB query\citep{spider}/...}

First-order logic (FOL) expressions are frequently used as a semantic representation of natural language (NL) \citep{bos-nli, folio, malls}. FOL representations are well-suited for expressing the semantics of \textit{logical entailment}, where the hypothesis \textit{necessarily follows} from the lexical meaning of the premises and the logical rules (\textit{e.g.} syllogisms). Furthermore, logical entailment can be easily determined with FOL representations by using the automatic theorem prover.

On the other hand, recognizing textual entailment (RTE) tasks \citep{rte, esnli, entailmentbank} adopt a broader definition of entailment, hereby referred to as \textbf{natural language entailment}. Natural language entailment can be defined as: "$P$ entails $h$ if a human reading $P$ would infer that $h$ \textit{is most likely true}" \citep{rte}, which is a strictly looser condition compared to logical entailment.

\begin{figure}[tp]
    \centering
    \includegraphics[width=\linewidth]{figures/entailment_preserving.pdf}
    \caption{Overview of Entailment-Preserving FOL representations (EPF). When premises entail a hypothesis (gray), the model (green) should produce FOL representations (orange) that preserve the entailment, which can be checked by an automatic theorem prover.}
    \label{fig:entailment-preserving}
\end{figure}

% Can we simulate natural entailment using logical entailment (Figure \ref{fig:entailment-preserving})?
Can we determine natural language entailment using FOL representations?
% \heng{[Iâ€™m not sure what you mean by simulate here.} \jinu{fixed}
% \heng{the motivations are still not very clear. My understanding is that you are trying to say the traditional way is to convert NL to logical form as intermediate step which requires annotation itself. You propose an end to end NL to NL entailment task?} \jinu{The task is NL->FOL semantic parsing. Editing to make it more clearer..}
% \heng{I also still don't get why you use T5 instead of more modern LLMs?} \jinu{1) this is sentence-to-sentence translation task, solvable using T5 2) BRIO, which I believe is much more numerically stable and fast than PPO, suits T5 well 3) computation budget was not enough}
To date, no prior work on \nltofol\ translation has successfully tackled the question. Classic \nltofol\ parsing approaches that translate syntactic and semantic parses to first-order logic often failed to preserve entailment in single-premise RTE tasks \citep{bos-markert-2005-recognising, bos-nli}. 
Recent methods use large language models (LLMs) to generate FOL representations from NL, and apply an automatic theorem prover to prove or disprove the given hypothesis \citep{linc, logiclm}. While these methods achieve high performance in multi-premise logical entailment tasks \citep{tafjord-etal-2021-proofwriter, folio}, the generalizability of these methods to natural language entailment is not yet tested.
% As natural entailment often relies on pragmatic and commonsense inference, the semantic representation might fail to capture some of the covert assumptions conveyed by the original sentence (\textit{brittleness}) \citep{bos-nli}. Furthermore, predicate signatures (name and number of arguments) can be chosen arbitrarily, requiring mapping various synonymous phrases into a single symbol (\textit{arbitrariness}) \citep{linc}. Another practical issue is that textual entailment datasets do not provide a gold FOL parse, complicating the training of a machine learning-based semantic parser.

As a systematic approach to this long-standing problem, we formalize the \textbf{Entailment-Preserving FOL representations (EPF)} task. In the EPF task, one must generate FOL representations for each premise and hypothesis in a multi-premise RTE dataset that preserves the entailment label. This task is challenging because as no reference FOL representation is provided, the model can only learn from the execution results of the theorem prover. Along with the task, we present a suite of \textit{reference-free} metrics for the EPF task, namely the \textbf{entailment-preserving rate (EPR)} family.
% \heng{this is also a good contribution, highlight it in abstract too} \jinu{added to abstract}

We empirically show that existing approaches for obtaining FOL representations, including classic meaning representations-based methods and end-to-end generative models, cannot effectively solve the EPF task. To advance the state-of-the-art, we develop a novel \textbf{iterative learning-to-rank} training method. It rewards FOL representations that preserve the entailment and penalizes ones that cannot, pushing the model to produce more entailment-preserving FOL representations. Experiments show that a T5 \citep{t5} model trained using the proposed method significantly outperforms baselines on the EPF task on three multi-premise entailment datasets (EntailmentBank \citep{entailmentbank}, eQASC \citep{eqasc}, and e-SNLI \citep{esnli}). Furthermore, we provide analyses that show the proposed training method can reduce the unwanted arbitrariness in FOL predicates, and generalize to diverse inference types and out-of-domain data.

Our key contributions can be summarized as follows.

\begin{itemize}
    \item We formalize the Entailment-Preserving FOL representations (\textbf{EPF}) task, where one must produce FOL representations that preserve the entailment in multi-premise RTE datasets. We empirically show that the task is challenging for diverse \nltofol\ translator baselines.
    \item We develop a suite of reference-free metrics, Entailment-Preserving Rate (EPR) family, for evaluating EPF.
    \item We propose \textbf{iterative learning-to-rank} training for EPF that significantly outperforms baselines. We perform multiple analyses to show that the method effectively reduces arbitrariness and is robust to various in-domain and out-of-domain data distributions.
\end{itemize}

% Quantitative and qualitative analyses on the trained model reveal that optimizing entailment preserving data



% Recent advances in large language models (LLMs) and their ability to reason and generate code opened a new direction for applying semantic parsing to complex reasoning tasks, namely \textit{parse-then-execute} \citep{logiclm, linc}. Given a set of natural language premises $\{p_1, \dots, p_N\}$ and a hypothesis $h$, the language model first translates each sentence into first-order logic (FOL) representation, and an automatic theorem prover is applied to find the entailment label. The objective is to preserve the entailment relationship in natural language after parsing them into FOL, \textit{i.e.} maximizing the \textbf{entailment preserving rate}. These approaches arguably achieve stronger performance in a number of reasoning datasets than natural language-based reasoning methods such as Chain-of-thoughts \citep{chain-of-thoughts}.

% However, parse-then-execute methods have been strictly limited to datasets that are either directly synthesized from FOL representations \citep{proofwriter, logicnli} or at least designed to be solved by a theorem prover \citep{folio}, which often drifts from real-world problems. These methods often suffer from brittleness (pragmatic information lost during parsing) and arbitrariness (predicate names and logical forms can be arbitrarily chosen) \citep{bos-nli, linc}, which has not been properly addressed in previous work on the parse-then-execute paradigm.

% FOL semantic representations provide a robust framework for defining \textit{entailment} in NL. In FOL semantics, a set of NL sentences (premise) ${p_1, \dots, p_N}$ entails another sentence (hypothesis) $h$ if and only if their FOL representations preserve the entailment relationship; that is, $FOL(p_1), \dots, FOL(p_N) \vdash FOL(h)$. This concept underlies several reasoning benchmarks, such as FOLIO \citep{folio}, ProofWriter \citep{tafjord-etal-2021-proofwriter}, and LogicNLI \citep{logicnli}. These datasets adopt the classic 3-way \textit{recognizing textual entailment} (RTE; also known as \textit{natural language inference}) framework, in which both the NL sentences and their gold FOL representations point to the same entailment label (entailment, contradiction, neutral).