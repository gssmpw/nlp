\paragraph{Machine Learning on Tabular Data.} Machine learning on single tables is a well-studied area with diverse paradigms. Deep tabular learning methods~\cite{gorishniy2024tabm, gorishniy2021revisiting, ye2024ptarl} utilize deep neural networks to learn tabular data representations, while tree-based approaches like XGBoost~\cite{chen2016xgboost} and CatBoost~\cite{prokhorenkova2018catboost} rely on gradient boosting decision trees. \citet{mcelfresh2024neural} observed that the performance of these methods varies across datasets. The extension of such models to multiple tables without shared features remains an unexplored area of research.

\paragraph{Multi-Modal Learning.} Multimodal learning~\cite{xu2023multimodal} focuses on integrating information from multiple data modalities, such as images and text. Most multimodal learning algorithms, including VisualBERT~\cite{li2019visualbert} and VL-BERT~\cite{su2019vl}, rely on pre-aligned pairs to supervise alignment, which is incompatible with the Leal setting. Other multimodal learning methods, such as U-VisualBERT~\cite{li2020unsupervised} and VLMixer~\cite{wang2022vlmixer}, achieve self-supervised learning using externally pretrained models for specific modalities to extract features or representations for alignment. However, these approaches are not applicable to heterogeneous tabular data, where universally effective pretrained models are unavailable. None of these multi-modal models can be directly applied to latent alignment learning between relational tabular data.

\paragraph{Vertical Federated Learning.} Vertical Federated Learning (VFL)~\cite{liu2024vertical} is a privacy-preserving learning paradigm for training models across distributed datasets with distinct feature sets. Although privacy is not a concern in the context of Leal, techniques developed to address data heterogeneity in VFL are relevant. Semi-supervised VFL~\cite{kang2022fedcvt, sun2023communication} focuses on the challenge of partial data alignment. They learns to complete missing data based on the aligned data. Fuzzy VFL~\cite{wu2022coupled, wu2024federated} handles scenarios when keys are not precise. \citet{wu2022coupled} use key similarity as the weight for aligned records. \citet{wu2024federated} encode the keys into data embedding by postional encoding~\cite{li2021learnable} and use attention mechanism to align the data. However, these methods rely on the assumption of shared features across datasets, which does not hold in latent alignment learning.
