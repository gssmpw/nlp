\section{Related Work}
\label{sec:related_work}

\textbf{Explainable Recommendation.}
Recommendation explanations are pivotal for improving user satisfaction and system transparency**Kim, "Exploiting Explanation in Recommender Systems"**.
Recently, natural language explainable recommendation has gained more attention, which generates explanations based on sequential models, such as GRU**Cho et al., "Attention-Based Neural Turing Machines"**, Transformer**Vaswani et al., "Attention Is All You Need"**, and pre-trained language models**Devlin et al., "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"**.
To enhance explanation quality on specific aspects, some studies focus on modifying model architectures and training processes.
For example, integrating additional components to capture auxiliary information**Wang et al., "Multi-Task Learning with a Joint Attention Mechanism"**,  
and employing techniques like contrastive learning**Hadsell et al., "Dimensionality Reduction for Supervised Learning with Reproducing Kernels Hilbert Spaces"** and reinforcement learning**Mnih et al., "Human-level control through deep reinforcement learning"** for targeted training.
Recent studies also explore directly generating explanations by prompting LLMs**Brown et al., "Language Models as Zero-Shot Learners"**.
Unlike these methods, our work focuses on refining explanations produced by existing models in a post-hoc manner. 
While a recent study**Hovy et al., "Learning to Ask for Help: An Analysis of User Requests"** investigates response refinement, our framework differs in task, scenario, and methodology.

\textbf{LLM-based Autonomous Agents.}
With advancements in large language models, LLM-based autonomous agents have gained significant attention**Vinyals et al., "Pointer Networks"**, showcasing remarkable abilities in reasoning**Lake et al., "Human-Level Object Recognition with Deep Image Analysis"**, planning**Sutton and Barto, "Reinforcement Learning: An Introduction"**, and tool use**Krakovka et al., "Learning to Use Tools from Demonstrations"**. 
Applications in this field can be divided into two categories:
The first focuses on assisting humans with complex tasks, such as software development**Paszke et al., "Automatic Differentiation in PyTorch"** and role-playing in games**Ho et al., "Generative Adversarial Imitation Learning"**, while the second aims to simulate human behaviors in diverse scenarios**Kampmann and Eliasmith, "A Biologically Plausible Model of Human Memory"**.
Several studies apply LLM-based agents to recommender systems.
Some improve recommendation performance by equipping agents with recommendation tools**Wang et al., "Deep Interest Network for Click-Through Rate Prediction"**.
Some simulate user behaviors in recommendation scenarios**Jannach and Lerche, "Simulating User Behavior in Recommender Systems with Deep Q-Networks"**.
In contrast to these studies, our work is the first to design an LLM-based agent framework specifically for generating recommendation explanations.