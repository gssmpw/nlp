@article{chow1957,
  title={An optimum character recognition system using decision function},
  author={Chow, C K},
  journal={IEEE Transactions on Computers},
  volume={6},
  number={4},
  pages={247--254},
  year={1957},
  publisher={IEEE}
}

@article{chow1970,
  title={On optimum recognition error and reject trade-off},
  author={Chow, C K},
  journal={IEEE Transactions on Information Theory},
  volume={16},
  pages={41--36},
  year={1970},
  publisher={IEEE}
}

@article{elyaniv2010,
  title={On the Foundations of Noise-free Selective Classification},
  author={El-Yaniv, Ran and Wiener, Yair},
  journal={Journal of Machine Learning Research},
  volume={11},
  pages={1605--1641},
  year={2010},
  month={May},
  publisher={JMLR.org}
}

@misc{geifman2017,
      title={Selective Classification for Deep Neural Networks}, 
      author={Yonatan Geifman and Ran El-Yaniv},
      year={2017},
      eprint={1705.08500},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1705.08500}, 
}

@misc{madaan2024,
      title={AutoMix: Automatically Mixing Language Models}, 
      author={Pranjal Aggarwal and Aman Madaan and Ankit Anand and Srividya Pranavi Potharaju and Swaroop Mishra and Pei Zhou and Aditya Gupta and Dheeraj Rajagopal and Karthik Kappaganthu and Yiming Yang and Shyam Upadhyay and Manaal Faruqui and Mausam},
      year={2024},
      eprint={2310.12963},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2310.12963}, 
}

@inproceedings{xin2021,
    title = "The Art of Abstention: Selective Prediction and Error Regularization for Natural Language Processing",
    author = "Xin, Ji  and
      Tang, Raphael  and
      Yu, Yaoliang  and
      Lin, Jimmy",
    editor = "Zong, Chengqing  and
      Xia, Fei  and
      Li, Wenjie  and
      Navigli, Roberto",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-long.84/",
    doi = "10.18653/v1/2021.acl-long.84",
    pages = "1040--1051",
    abstract = "In selective prediction, a classifier is allowed to abstain from making predictions on low-confidence examples. Though this setting is interesting and important, selective prediction has rarely been examined in natural language processing (NLP) tasks. To fill this void in the literature, we study in this paper selective prediction for NLP, comparing different models and confidence estimators. We further propose a simple error regularization trick that improves confidence estimation without substantially increasing the computation budget. We show that recent pre-trained transformer models simultaneously improve both model accuracy and confidence estimation effectiveness. We also find that our proposed regularization improves confidence estimation and can be applied to other relevant scenarios, such as using classifier cascades for accuracy{--}efficiency trade-offs. Source code for this paper can be found at \url{https://github.com/castorini/transformers-selective}."
}

@inproceedings{yoshikawa2023,
    title = "Selective-{LAMA}: Selective Prediction for Confidence-Aware Evaluation of Language Models",
    author = "Yoshikawa, Hiyori  and
      Okazaki, Naoaki",
    editor = "Vlachos, Andreas  and
      Augenstein, Isabelle",
    booktitle = "Findings of the Association for Computational Linguistics: EACL 2023",
    month = may,
    year = "2023",
    address = "Dubrovnik, Croatia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-eacl.150/",
    doi = "10.18653/v1/2023.findings-eacl.150",
    pages = "2017--2028",
    abstract = "Recent studies have suggested that neural language models learn and store a large amount of facts and commonsense knowledge from training data. The ability of language models to restore such knowledge is often evaluated via zero-shot cloze-style QA tasks. However, such evaluations rely only on prediction accuracy without punishing the systems for their mistakes, e.g., simply guessing or hallucinating likely answers. Selective prediction is a more informative evaluation framework that takes the confidence of predictions into account. Under the selective prediction setting, a model is evaluated not only by the number of correct predictions, but also by the ability to filter out dubious predictions by estimating the confidence of individual predictions. Such confidence-aware evaluation is crucial for determining whether to trust zero-shot predictions of language models. In this paper, we apply the selective prediction setting to an existing benchmark, LAMA probe, and conduct extensive experiments with recent neural language models and different confidence functions. We empirically show that our Selective-LAMA evaluation is more robust to the effect of simple guesses than the conventional accuracy-based evaluation. Our evaluation reveals the importance of the choice of confidence functions by showing that simply relying on token probabilities is not always the best choice. Further analysis shows that various confidence functions exhibit different preferences over predicted tokens for a given context."
}

@misc{zellinger2025,
      title={Rational Tuning of LLM Cascades via Probabilistic Modeling}, 
      author={Michael J. Zellinger and Matt Thomson},
      year={2025},
      eprint={2501.09345},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2501.09345}, 
}

