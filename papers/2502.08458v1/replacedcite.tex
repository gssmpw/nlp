\section{Related Work}
The language used in counseling varies based on the demographic and cultural background of both counselors and patients ____, underscoring the importance of considering diversity in user identities when designing NLP systems for mental health. 

%clinical coding taks are also relevant to our work https://ieeexplore.ieee.org/abstract/document/9430499

% dataset in Chinese https://aclanthology.org/2021.findings-acl.130/
Despite growing interest in developing NLP methods for understanding counseling conversations, very few non-English datasets are publicly available, further limiting NLP research in multilingual mental healthcare. GlobHCD
____
is a German dataset with naturalistic interactions around changing health behavior. The interactions were obtained from participants in an online mental health forum and annotated with MI labels. Although the code to replicate the dataset is available, the annotated dataset is not publicly available.
BiMISC is a Dutch dataset that contains bilingual MI conversations manually annotated with counselor and client behaviors____. Similarly,  ____ collected a dataset of real conversations between patients and mental health counselors and annotated the conversations with behavioral codes based on the contribution of the speaker.%––for instance, the clarification tag can apply to the MI reflection category. 

The broader landscape of mental health applications for non-English NLP contains a larger body of work. Social media and text communication platforms are popular avenues for sourcing data.
The Chinese PsyQA dataset contains annotated question-answer pairs from an online mental health service ____. The HING-POEM dataset in Hinglish examines politeness in mental health and legal counseling conversations ____, and research on interactions in Kenyan WhatsApp groups for peer support studies sentiment among youth living with HIV ____. Additionally, previous work  has sourced data from social media for mental illness prediction ____. 
An alternative to direct data collection  is to use machine translation from high-resource to low-resource languages ____, but this comes with the potential cost of cultural information loss.

%The dataset is derived from actual counseling conversations with patients discussing a variety of health issues such as alcohol consumption, managing stress, or diabetes management. %, demonstrating the potential of large language models (LLMs) in automating MI coding ____
%rather than transcripts of mental health counseling sessions. Any significant changes to the website additionally limit this work the code is designed to scrape from. Their 
%annotated dataset is not publicly available. Furthermore, the . 
%For English MI, ____ developed a dataset in a similar method to GlobHCD by scraping interactions from online forums. ____ created a dataset of transcripts of MI sessions between real patients and providers, and ____ expanded upon this dataset. 
%Languages such as English and German are high-resource; to the best of our knowledge, there are no MI-specific therapy datasets available for lower-resource languages such as Spanish, annotated or not. 
%A few counseling datasets address mental and behavioral issues. Among them, t

Our study introduces the first Spanish MI dataset, filling a critical gap in the literature and offering a valuable resource for NLP researchers working on mental health applications.

%on cultural sentivity
%-https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6698383/

%\subsection{Cross-lingual Transfer}

% Finally, also relevant to our work is 
% Cross-lingual transfer methods fall into two categories: those relying on parallel corpora and those that do not. The former class of methods often struggles with limited available parallel corpora, which can be mitigated by generating pseudo-parallel corpora via high-quality machine translation ____. The latter class of ``unsupervised'' methods focus on learning multilingual embeddings or embedding documents from multiple languages into a shared space ____, enabling classification models to be trained on these embeddings ____.

% Similar to the task we approach in this work, ____ fine-tune BERT-based models for automatically coding clinical notes in Spanish. However, there remains a lack of work in behavioral coding in the \textit{mental health} domain for Spanish. This work highlights the differences between Spanish and English through linguistic analyses and cross-lingual classification experiments. We implicitly demonstrate that cultural differences exist between these two languages and call attention to the need to collect and develop mental health datasets in different languages.   

% In traditional cross-lingual transfer, multilingual language models ____ are fully fine-tuned in one language and evaluated in others. Despite the strong zero-shot performance of full-model fine-tuning ____, it is time-consuming and expensive. 
% Prompt-tuning is a fine-tuning paradigm that keeps the original model frozen and tunes only the prompt weights, offering a lightweight, efficient alternative. Studies have shown prompt-tuning can outperform fine-tuning in cross-lingual tasks ____, particularly in low-resource languages ____, which motivates our experimentation with this technique. However, performance is influenced by factors like prompt length ____ and language ____. 

% In this paper, we focus on p-tuning ____, a prompt-tuning method that utilizes trainable prompt embeddings. These embeddings are optimized by a prompt encoder, which eliminates the need for prompt engineering. 
% We evaluate this method on zero-shot cross-lingual transfer tasks and explore the impact of prompt length on performance.


%\subsection{Cross-lingual Projection}

% cite sample works -- aligned corpora 
% ____ introduced T-Projection, a method for cross-lingual projection of sequence labeling annotations. T-Projection is composed of two steps: generating candidates in a target language for a given label in the source language using mT5 ____, and selecting the best candidate by scoring the candidates by machine translation probability. 
% for my own understanding: given two sentences that are aligned (e.g. 'i love new york', 'me encanta nueva york'), they generate candidates (i.e. i *think* just tokens from the target sentence (e.g. ['encanta', 'nueva york']) and then look at the probability that the source label (e.g. new york->LOCATION) is translated to 'encanta' or 'nueva york'

% cite sample works -- un-aligned corpora
% ____
% ____

% With the recent rise of LLMs, there has been some exploratory work done towards 
% ____

% \subsection{misc, dialogue}
% %sequence modeling stuff related to dialogue; conversation trajectory modeling 

% ____ --> cool paper on how the use of reflections or other types of utterances from counselors can 'shape' the conversation