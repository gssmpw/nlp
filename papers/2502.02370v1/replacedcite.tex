\section{Related Work}
\subsection{Technological Adaptations of Cognitive and Behavioral Interventions}

% Mindfulness, which originates from the Buddhist concept of ``sati'', encompasses attention, awareness, and being present. It is like a mirror that clearly reflects what comes before it ____. 

% Mindfulness has been integrated into psychology research ____ and therapeutic practices like Mindfulness-Based Stress Reduction (MBSR) ____. Farb et al. describe how mindfulness practices can intervene in automatic cognitive-emotional processing ____. Instead of implementing cognitive reappraisal and reflection after an event or response has occurred, mindfulness can be situated on \textit{attention deployment} ____, which allows time for generating new perceptions of the situation.

Cognitive-behavioral therapy (CBT) and mindfulness practices have been influential in psychology and therapeutic practices. CBT focuses on identifying and reframing maladaptive thought patterns, while mindfulness emphasizes present-moment awareness and nonjudgmental attention – often intersecting in interventions such as Mindfulness-Based Cognitive Therapy (MBCT) ____. Research has explored how these practices intervene in automatic cognitive-emotional processes, enabling more adaptive responses to challenging situations ____.


In Human-Computer Interaction (HCI), researchers have explored how digital systems can support practices like CBT and mindfulness. For example, CBT has inspired interventions in digital mental health tools, such as apps designed to identify and challenge cognitive distortions or to guide structured problem-solving ____. Mindfulness-oriented systems have often focused on facilitating meditation practice or fostering mindful awareness during everyday interactions ____. More recently, many used Large Language Models for technology-mediated reflection, such as reflective conversational agents ____ and LLM-assisted journaling ____. 

Unlike prior work that focuses on training mindfulness as an end goal, we integrate technology more directly and make it ``exercise'' mindfulness via situational awareness. The emergence of proactive AI agents has created new possibilities for dynamically understanding and responding to users’ contexts and create systems that seamlessly integrate cognitive and emotional support into daily life. In the next section, we describe more related work in the areas of context-aware computing and proactive systems.


% Within HCI, many focused on technologies that facilitate meditation practice or cultivate mindfulness in interactions and behavior ____. 



\subsection{Proactive Context-Aware Systems}
Context-aware computing, first introduced in the early 1990s, represents a paradigm shift in human-computer interaction by enabling systems to sense, adapt, and respond to their environment based on contextual information such as location, activity, time, and user preferences ____. Since its inception, it has evolved from location-based services into sophisticated systems leveraging multimodal data to create personalized, adaptive experiences. Today, these systems utilize data from multimodal sources such as cameras, microphones, motion sensors, and physiological monitors, enabling real-time context-sensitive support ____.

Recent advancements in wearables, such as smart glasses, smartwatches, and head-mounted displays equipped with always-on egocentric cameras and microphones, have significantly enhanced their ability to continuously capture real-time data. These devices now enable detailed understanding of users' environments and activities, transforming them into proactive assistants ____. For instance, PAL ____ demonstrates how wearables with egocentric cameras analyze visual contexts such as objects, locations, and surroundings to identify activities like working, relaxing, or commuting. This capability supports tailored habit interventions, personalized health and cognitive assistance, and intelligence augmentation.

Recent advancements in Multimodal Large Language Models (MLLMs) have further expanded the capabilities of context-aware computing by enabling the integration and interpretation of complex multimodal data. These models process visual, conversational, and contextual inputs to deliver deep understanding of environments and activities ____. For example, WorldScribe ____ leverages GPT-4v ____ to provide live visual descriptions of environments tailored to the needs of blind and low-vision users. Similarly, Memoro ____ utilizes GPT-3 ____ to process conversational data and infer environmental and social contexts through situationally relevant prompts.

The evolution from reactive context-aware systems to proactive agents marks a significant shift in delivering timely and anticipatory support. The concept of "just-in-time adaptive interventions" (JITAIs) exemplifies this shift by focusing on delivering the right type and amount of support at the right moment, adapting to an individual’s dynamic internal and contextual state ____. Salber et al. introduced the context toolkit and widgets ____, which mediate between the environment and applications, enabling dynamic and adaptive interactions inspired by graphical user interfaces.

Building on these foundations, our work applies MLLMs for enhanced contextual understanding of user activities and their surrounding environments from a first-person view, enabling systems to deliver proactive and personalized interventions through AI self-cloned voice agents.

\subsection{AI-generated Synthetic Selves for Behavior Change}
Research on behavior change interventions have primarily focused on their ability to support goal setting, tracking, and sustaining motivation toward goals ____. Despite their widespread appeal, they often suffer from high dropout rates and low user engagement ____. To address these issues, ____ suggested embedding goals into one’s sense of identity, (e.g., ``I will think of myself as someone who eats healthy and works out'') leads to more goal-aligned behavior than simply setting the goal (e.g., ``I will be mindful about what I eat''). 

%BJ Fogg behavior change is identity change

Digital representations of oneself have been shown to influence behavior. The Proteus effect ____ describes how individual's behaviors adapt to align with the characteristics of their virtual avatars. Advancements in machine learning and generative AI have enabled the creation of synthetic self-similar media. For example, researchers have examined applications to enhance engagement in physical activity ____ or to develop public speaking skills by generating personalized videos of individuals confidently delivering speeches ____. 

More related to our work are ones on synthetic voices. ____ demonstrated that hearing a modified version of one’s voice, such as a calmer tone, helped reduce anxiety during relationship conflicts, while a deeper voice fostered a sense of empowerment during debates. Researchers have also explored leveraging one’s own voice ____ or the voices of familiar people (e.g., family and friends) to enhance the effectiveness of notifications ____.  Fang et al. developed Emotional Self-Voice (ESV), which generates cognitive behavioral therapy strategies in first-person delivered in the user's own voice. They show that the ESV intervention led to an increase in positive sentiment when reflecting on past negative events and significant improvements in confidence, motivation, and resilience to failure. Unlike ESV, Mirai allows back-and-forth real-time conversation with one's ideal self, with responses adapted based on new information from the user and the environment.