\section{Omitted content of Section~\ref{sec:max-cut}}
\label{appendix:mc-proofs}


\subsection{Proof of Lemma~\ref{lem:max-cut-generalization}} 
Let $G=(V,E,w)$ and $k$ be an input for \ccmaxcut. The goal is to find $C \subseteq V$ such that $\cut{C}$ is maximized. 
Suppose we have an algorithm~$\algo$ for \maxcutkc. We apply~$\algo$ with input $(G = (V, E, w), U=\emptyset, k)$. 
Now~$\algo$ returns a set~$\SelectSet$ of size $|\SelectSet|=k$ to maximize $\cut{U \symm C}$.
Given that $U=\emptyset$, $\cut{U \symm C} = \cut{C}$.

As the constraint and the objective function for these two problems are the same, if~$\algo$ is $\alpha_{k}$-approximation algorithm for \maxcutkc, then it is $\alpha_{k}$-approximation for \ccmaxcut. 
As we directly use $C$ as the solution for \ccmaxcut, the running time is $\bigO(T(m,n, k))$. 

\subsection{Proof of Corollary~\ref{cor:max-cut-hardness}}
This is a direct result from Lemma~\ref{lem:max-cut-generalization} and the
hardness results of \cite{DBLP:conf/approx/AustrinS19}.

\subsection{Pseudocode for the black-box-based algorithm for \maxcutkc from Section~\ref{sec:max-cut:black-box}}
\label{appendix:maxcutkc:blackbox:pseudocode}

The pseudocode for black-box-based algorithm for \maxcutkc, assuming access to a solver to \maxcut. As we discussed in Section~\ref{sec:max-cut:black-box}, is illustrated in Algorithm~\ref{algo:maxcutkc-blackbox}.

\begin{algorithm}[H]
\caption{An algorithm for \maxcutkc, assuming access to a black-box \maxcut solver}
\label{algo:maxcutkc-blackbox}
\begin{algorithmic}[1]
\Require{$(G(V, E, w), \OldSet, k)$, access to a \maxcut solver}
\State Let $\SelectSet \leftarrow \{i \colon x_i \neq x^0_i\}$ be the solution
	of applying our black-box \maxcut solver on $G$
\State \textbf{Fixing $\SelectSet$:} Set $\FixSelectSet \gets \SelectSet$ 
\While{$\abs{\FixSelectSet} \neq k$}
    \If{$\abs{\FixSelectSet} < k$}
        \State $u^* \leftarrow \arg\max_{u \in V \setminus \FixSelectSet} \cut{\OldSet \symm (\FixSelectSet \cup \{u\})}$
        \State $\FixSelectSet \leftarrow \FixSelectSet \cup \{u^*\}$
    \ElsIf{$\abs{\FixSelectSet} > k$}
        \State $u^* \leftarrow \arg\max_{u \in \FixSelectSet} \cut{\OldSet \symm (\FixSelectSet \setminus \{u\})}$
        \State $\FixSelectSet \leftarrow \FixSelectSet \setminus \{u^*\}$
    \EndIf
\EndWhile
\State \Return{$\FixSelectSet$}
\end{algorithmic}
\end{algorithm}

\subsection{Proof of Theorem~\ref{thm:max-cut-black-box}}
\label{appendix:mc-proofs:blackbox}
Let $(G=(V, E, w), \OldSet, k = \tau n)$ be an instance of \maxcutkc, and let
$(\OldSet, \OldComSet)$ be the initial cut of the graph $G$.
After running the \maxcut solver on $G$ (without the given cut), we obtain a cut $(\TempSet, \TempComSet)$. 
Set $\SelectSet$ such that $\TempSet = \OldSet \symm \SelectSet$. Let $\mu$ be
such that $\abs{\SelectSet} = \mu n$. 
Now we make changes to $C$ until we have that $\abs{C}=k$. If $\abs{C}>k$ this
is done by greedily removing the vertices from~$C$ which have the smallest
contribution to the cut; if $\abs{C}<k$, this is done by greedily adding the
vertices to~$C$ which increase the cut the most.
We present the pseudocode of our reduction in Algorithm~\ref{algo:maxcutkc-blackbox}. 


For each node $a \in V$, let $\cutnode{a}{\OldSet}$ be the sum of edge weights of node $a$ in the cut
$(\OldSet, \OldComSet)$, i.e.,
$\cutnode{a}{\OldSet} = \sum_{(a, v)\in E[\OldSet, \OldComSet]} w(a, v)$. 

We will calculate how much the greedy algorithm reduces to the approximation ratio. To do so, we make case distinctions on $\abs{\SelectSet} > k$ or $\abs{\SelectSet} <k$, and we give the following Lemma~\ref{lem:cut-blackbox-deduction}.  

\begin{lemma}
	\label{lem:cut-blackbox-deduction}
	Let $\tau$ be such that $k = \tau n$ and assume a \maxcut solver returns a
	cut with $\abs{\SelectSet} = \mu n$. Suppose the initial cut has cut value $M_0$.
	After the greedy procedure to meet the cardinality constraint, the sum of edge weights of the cut is lower bounded by $(1 - \Theta(\frac{1}{n}))\min \{\frac{\tau^2}{\mu^2}, \frac{(1-\tau)^2}{(1-\mu)^2}\} M_0$. 
\end{lemma}

\begin{proof}
	Let $M$ be the sum of edge weights in the cut at any stage of the greedy
	procedure. Note that initially $M$ is equal to $M_0$, and let the initial
	$\SelectSet$ be equal to $\SelectSet_0$. At the $i$th round of the greedy
	algorithm, $M$ becomes $M_i$, and $\SelectSet$ becomes $\SelectSet_i$. 
	
\emph{Case~1:} $\abs{\SelectSet} > \tau n$.
	We notice that $\sum_{u\in \SelectSet} \cutnode{u}{\OldSet \symm \SelectSet} \leq  2M$. 
Since the algorithm always selects a node in $C$ to maximize the cut for the
next round, i.e., $u^* = \arg \max_{u \in \SelectSet} \cut{\OldSet \symm (\SelectSet \setminus \{u\})}$,
the cut value drops by at most a factor of $\frac{2M}{\abs{\SelectSet}}$. 


It follows from the previous analysis that $M_i \geq M_{i-1} - \frac{2M_{i-1}}{\abs{\SelectSet_{i-1}}}$. 
Thus at the $t$-th step, 
\begin{displaymath}
	M_t \geq M_0 \prod_{i=1}^t \left(1 - \frac{2}{\abs{C_{i-1}}}\right)
	= M_0 \prod_{i=1}^t \left(\frac{\abs{C_{i-1}} - 2}{\abs{C_{i-1}}}\right).
\end{displaymath}

Note that $\abs{\SelectSet_{i -2}} = \abs{\SelectSet_{i}} + 2$, and in the end
$|\SelectSet_t| = \tau n$. Therefore, we can cancel out most of the terms and
obtain:
\begin{displaymath}
	\begin{aligned}
		M_{t} &\geq \frac{(\abs{\SelectSet_{t-2}}-2)(\abs{\SelectSet_{t-1}}-2)}{\abs{\SelectSet_0}\abs{\SelectSet_1}}M_{0} \\
		&= \frac{\tau n(\tau n - 1)}{\mu n (\mu n - 1)}M_{0} \\
		&\geq \frac{\tau^2 - \frac{\tau}{n}}{\mu^2} M_0 \\
		&= \frac{\tau^2}{\mu^2}\left(1 - \frac{1}{n\tau}\right) M_0.
	\end{aligned}
\end{displaymath}


\emph{Case~2:} $\abs{\SelectSet} < \tau n$.
Similarly, we notice that $\sum_{u\in \vertices \setminus \SelectSet} \cutnode{u}{\OldSet \symm \SelectSet} \leq  2M$. 
As the algorithm always selects a node in $\vertices \setminus \SelectSet$ to
maximize the cut for the next round, i.e., $u^* = \arg \max_{u \in \vertices \setminus \SelectSet} \cut{\OldSet \symm (\SelectSet \cup \{u\})}$, the cut
value drops by at most a factor of $\frac{2M}{n - \abs{\SelectSet}}$. 

It follows from the previous analysis that $M_i \geq M_{i-1} - \frac{2M_{i-1}}{n-\abs{\SelectSet_{i-1}}}$. Thus at the $t$-th step, 
\begin{displaymath}
	M_t \geq M_0 \prod_{i=1}^t \left(1 - \frac{2}{n-\abs{C_{i-1}}}\right). 
\end{displaymath}

Note that $\abs{\SelectSet_{i-2}} = \abs{\SelectSet_{i}} - 2$, and in the end $\abs{\SelectSet_t} = \tau n$. 
Thus,
\begin{displaymath}
	\begin{aligned}
		M_{t} &\geq \frac{(n - \abs{\SelectSet_{t-2}}-2)(n - \abs{\SelectSet_{t-1}}-2)}{(n - \abs{\SelectSet_{0}})(n - \abs{\SelectSet_{1}})} M_{0} \\
		&= \frac{(n - \abs{\SelectSet_{t}})(n - \abs{\SelectSet_{t}}-1)}{(n - \abs{\SelectSet_{0}})(n - \abs{\SelectSet_{0}}+1)} M_{0} \\
		&= \frac{(n - \tau n)(n - \tau n - 1)}{(n - \mu n) (n - \mu n + 1)} M_{0}\\
		&= \frac{(1- \tau )(1 - \tau  - 1/n)}{(1 - \mu ) (1 - \mu  + 1/n)} M_{0}\\
		&= \frac{(1- \tau )^2}{(1 - \mu )^2}\frac{(1- \mu )(1 - \tau  - 1/n)}{(1 - \tau) (1 - \mu  + 1/n)} M_{0} \\
  		&= \frac{(1- \tau )^2}{(1 - \mu )^2}\frac{(1- \mu )\cdot n - \frac{(1-\mu)}{1-\tau})}{(1 - \mu) n + 1} M_{0} \\
        &\geq \frac{(1- \tau )^2}{(1 - \mu )^2} \left(1 - \frac{\frac{2 - \tau - \mu}{1 - \tau}}{(1 - \mu) n + 1}\right) M_0.
	\end{aligned}
\end{displaymath}

Combining the bounds of these two cases, we obtain that
$M_{t} \geq \min \left\{\frac{\tau^2}{\mu^2}(1 - \frac{1}{n\tau}),
		\frac{(1- \tau )^2}{(1 - \mu)^2} \left(1 - \frac{\frac{2 - \tau - \mu}{1 - \tau}}{(1 - \mu) n + 1}\right)\right\}M_0$.
Both $\frac{1}{n \tau}$ and $\frac{\frac{2 - \tau - \mu}{1 - \tau}}{(1 - \mu)n + 1}$ are in $\Theta(\frac{1}{n})$. 
We thus conclude $M_{t} \geq (1 - \Theta(\frac{1}{n}))\min \left\{\frac{\tau^2}{\mu^2}, \frac{(1-\tau)^2}{(1 - \mu)^2}\right\} M_0$. 
\end{proof}

Lemma~\ref{lem:cut-blackbox-deduction} implies that, if the \maxcut solver obtains any constant approximation ratio result, and that $\tau$ is a constant (i.e., $k = \Omega(n)$). We obtain a constant approximation algorithm for \maxcutkc. 
Specifically, let the approximation ratio for \maxcut be $\alpha$ (for instance,
$\alpha > 0.87$ for the algorithm of \citet{goemans1994approximation}),
the approximation for \maxcutkc becomes at least $(1 - \Theta(\frac{1}{n}))\min\{\tau^2, (1-\tau)^2\} \alpha$ in the worst
case, where we used that $\mu^2 < 1$ and $(1-\mu)^2 < 1$. The approximation
ratio in the theorem follows since $k = \tau n$.
The time complexity comes from solving the \maxcut problem using a blackbox solver and constructing and maintaining a priority queue for the greedy procedure.
