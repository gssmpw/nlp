\section{Experiments}
\label{sec:Experiments}


We conducted comprehensive experiments to evaluate KaSLA and address the following research questions: \textbf{RQ1:} Does KaSLA enhance existing text-to-SQL baselines by improving their schema linking capabilities? \textbf{RQ2:} Does KaSLA demonstrate superior schema linking performance by handling element missing and redundancy? \textbf{RQ3:} Does each component in KaSLA contribute to the overall performance, and is KaSLA an efficient model for real-world text-to-SQL applications?


\subsection{Experiment Setup}\label{sec: Experiment Setup}
We conducted experiments on two well-know large-scale text-to-SQL datasets, BIRD~\citep{li2023BIRD} and Spider~\citep{yu2018Spider}, incorporating multiple robust baselines based on LLMs with in-context learning and fine-tuning. For evaluating text-to-SQL, we utilized Execution Accuracy (EX)~\citep{yu2018Spider,li2023BIRD} and Valid Efficiency Score (VES)~\citep{li2023BIRD}. We included multiple robust baselines from two categories:\emph{(i) LLMs + in-context learning baselines:} C3-SQL~\citep{dong2023c3}, DIN-SQL~\citep{pourreza2023dinsql}, MAC-SQL~\citep{wang2024macsql}, DAIL-SQL~\citep{gao2023dailsql}, SuperSQL~\citep{li2024dawn}, Dubo-SQL~\citep{thorpe2024dubo}, TA-SQL~\citep{qu2024before}, E-SQL~\citep{caferouglu2024sql}, CHESS~\citep{talaei2024chess}; and \emph{(ii) LLMs + fine-tuning baselines:} DTS-SQL~\citep{pourreza2024dtssql}, CodeS~\citep{li2024codes}.

\subsection{Main Results of SQL Generation (\textbf{RQ1})}
To address \textbf{RQ1}, we conducted experiments to evaluate the SQL generation capabilities of state-of-the-art (SOTA) baselines enhanced by our KaSLA, with results presented in Table~\ref{tb:main_results}. KaSLA replaces the original schema linking component in models that already have schema linking capabilities or implements a full schema prompt substitution for those that do not.

The results demonstrate that incorporating KaSLA consistently improves both Execution Accuracy (EX) and Valid Efficiency Score (VES) across baselines with diverse base models, including GPT-4, CodeS-15B, StarCoder2-15B, and Deepseek-v3. Notably, in the BIRD-dev dataset, KaSLA enhances the EX of CHESS with Deepseek-v3 from 61.34\% to 63.30\%. For local LLMs, both "CodeS + KaSLA" and "TA-SL + KaSLA" with CodeS-15B and StarCoder-15B achieve impressive increases in Execution Accuracy compared to their original versions. These results underscore KaSLA's effectiveness and flexibility as a plug-in, showing that KaSLA plays an important role in improving complex text-to-SQL tasks. This adaptability not only confirms its robustness but also broadens its applicability across different models, achieving superior performance outcomes and making it a versatile addition to existing systems.

\begin{table*}[!h]
   \begin{center}
   \belowrulesep=0pt
   \aboverulesep=0pt
   \resizebox{\linewidth}{!}{
   \scalebox{1}{
   \begin{tabular}{>{\centering}p{0.115\textwidth}|>{\centering}p{0.22\textwidth}|>{\centering}p{0.07\textwidth}
      >{\centering}p{0.07\textwidth}
      >{\centering}p{0.075\textwidth}
      |>{\centering}p{0.07\textwidth}|>{\centering}p{0.07\textwidth}|>{\centering}p{0.07\textwidth}>{\centering}p{0.07\textwidth}>{\centering}p{0.074\textwidth}>{\centering}p{0.074\textwidth}|>{\centering}p{0.07\textwidth}|>{\centering\arraybackslash}p{0.07\textwidth}}
   \toprule[1pt]
   \multirow{3}{*}{\makecell[c]{Base Model}}& \multirow{3}{*}{\makecell[c]{Method}} &\multicolumn{5}{c|}{BIRD-dev} &\multicolumn{6}{c}{Spider-dev} \\
   \cline{3-7}\cline{8-13}
   & &\multicolumn{4}{c|}{EX} &  VES     &\multicolumn{5}{c|}{EX} &  VES \\
   \cline{3-7}\cline{8-13}
   & &Easy&Medium & Hard & Total &   Total                              &Easy &Medium &Hard &Extra &Total&Total \\
   \midrule
   \multirow{7}{*}{\makecell[c]{GPT-4}}& MAC-SQL   &-  &-  &-  &57.56  &  58.76                             &- &-  &-  &-    &86.75    &-          \\
    &DIN-SQL   &-  &-  &-  &50.72    & 58.79                             &92.34  &87.44  &76.44  &62.65  &82.79  &81.70         \\
    &DAIL-SQL   &62.49  &43.44  &38.19  &54.43      & 55.74                   &91.53  &89.24  &77.01  &60.24  &83.08   &83.11          \\
    &DAIL-SQL (SC)  &63.03  &45.81  &43.06  &55.93     & 57.20                &91.53  &90.13  &75.29  &62.65  &83.56  &-          \\
    &TA-SQL   &63.14 &{48.82} &36.81 &56.32               &  -               &93.50 &90.80 &77.60 &64.50 &85.00         & -        \\
    &SuperSQL  &{66.92}  &46.67  &{43.75}  &58.60   & 60.62       &{94.35} &{91.26}  &{{83.33}}  &{{68.67}}  &{87.04} &{85.92}  \\
   & Dubo-SQL   &-  &-  &-  &{59.71} & {66.01}            &- &-  &-  &-  &-  & -           \\
   \midrule
     \multirow{2}{*}{\makecell[c]{CodeS-15B}}  & CodeS  &65.19&48.60&38.19&57.63   & 63.22 &94.76&91.26  &72.99  &{64.46}   &84.72   & 83.52     \\
     & \textbf{CodeS   + KaSLA}      &68.32&50.75&38.19&60.17  &64.52    &\textbf{96.37}&89.46&76.44&63.86&84.82& 84.46 \\
     \midrule
   \multirow{6}{*}{\makecell[c]{StarCoder2\\-15B}}   &TA-SL  &  59.89&45.38&34.72&53.13   & 60.51            &95.56&92.38&78.16&63.25& 85.98 &  85.03       \\ 
     & \textbf{TA-SL  + KaSLA}      &66.59  & 49.46  & 38.89 & 58.80  &63.56    &94.76&92.15&77.59&66.87&86.27 &85.47  \\
    &  DTS-SQL &  63.03&46.02&34.72&55.22 &64.17 & 91.94&90.58&78.74&66.87&85.11  &  85.49  \\ 
    &  \textbf{ DTS-SQL  + KaSLA}      &63.89 &50.11   &39.58   &57.43  &65.20     &94.76&90.81&\textbf{80.46}&\textbf{68.07}&\textbf{86.36}&85.81 \\
   &  CodeS     &{68.00}  &{51.40}  &{39.58}  &{60.30}  & {65.04}  &94.76&91.26  &72.99  &{64.46}   &84.72   & {83.52}       \\
   &  \textbf{  CodeS + KaSLA}     &67.68   &\textbf{54.84}  &42.36  &61.41  &66.87    &94.76 &91.03 &78.74 &66.27 &85.88& 84.46  \\
     \midrule
    \multirow{4}{*}{\makecell[c]{Deepseek\\-V3}} & E-SQL  &67.24  &51.61  &41.67 &60.10   & 62.16   &95.57&91.93&72.99&64.46& 85.21 &    83.81   \\ 
   & \textbf{ E-SQL + KaSLA}  &69.40   &53.55 &43.75  &62.18  &65.32   &95.97 &92.38 & 73.56 & 65.06 &85.69& 85.72   \\
    &  CHESS   &67.89  &52.90 &46.53 & 61.34  &65.28 & 95.57&92.16&73.56& 65.06& 85.50  & 85.33   \\ 
    & \textbf{  CHESS + KaSLA}   &\textbf{69.94}   &\textbf{54.84} & \textbf{47.92} &\textbf{63.30}  &\textbf{67.21}  &\textbf{96.37}&\textbf{92.83}&74.14&65.66 &86.17 & \textbf{86.35} \\
   \bottomrule[1pt]
   \end{tabular}}}
   \caption{The SQL generation performance of enhanced text-to-SQL models using KaSLA, which features 1.6 B parameters combining DeepSeek-coder-1.3B and RoBERTa-Large, is evaluated in terms of Execution Accuracy (EX) (\%) and Valid Efficiency Score (VES) (\%) on the BIRD-dev and Spider-dev datasets. We utilize KaSLA to substitute the original schema linking component in models that already incorporate schema linking, or to replace the full schema prompt for models that do not.}
   \label{tb:main_results}
   \end{center}
   \end{table*}

\subsection{Experimental Results of Schema Linking (\textbf{RQ2})} \label{sec: Schema Linking Results} 
To answer the \textbf{RQ2}, we conduct the experiments and report the evaluation results of schema linking methods on BIRD-dev in Figure~\ref{fig: Schema linking evaluation.}. We measured the performance of these schema linking methods in both table linking and column linking. The results indicate that, under the enhanced F1 score which specifically evaluates missing elements, only KaSLA achieves high accuracy in the challenging task of column linking. Schema linking models using LLMs often perform well in table linking but fall short in column linking due to the lack of additional optimizations for missing elements. This highlights the advantages of KaSLA's framework and demonstrates how enhanced metrics can reveal the significant issue of element missing in current schema linking practices.


   
\begin{table}[!h]
   \begin{center}
   \resizebox{\linewidth}{!}{
   \scalebox{1}{ 
   \begin{tabular}{c |c c c}
   \toprule[1pt]
   Schema linking method & Table linking & Column linking\\
   \midrule
   DTS-SL (starcoder2-15b) &61.94  &23.71 \\
   CodeS-SL (starcoder2-15b) &58.21  &29.56 \\
   RSL-SQL (deepseek-v3) &67.11  & 17.20 	\\
   KaSLA (deepseek-coder-1.3B)  &\textbf{81.92} &\textbf{62.78}	\\
   \bottomrule[1pt]
   \end{tabular}}}
   \caption{Schema linking performance with the proposed enhanced linking metric on BIRD-dev.}
\label{fig: Schema linking evaluation.}
\vspace{-2mm}
   \end{center}
   \end{table}





   
\begin{table}[!h]
   \begin{center}
   \resizebox{0.7\linewidth}{!}{
   \scalebox{1}{ 
   \begin{tabular}{c |c}
   \toprule[1pt]
   Ablation &  EX \\
   \midrule
   CodeS + KaSLA & 	60.17  \\
   \midrule
   w/o Binary scoring model &   56.06 	\\
   w/o Probabilistic scoring model &  57.82  	\\
   w/o Hierarchical strategy & 58.34   	\\
   w/o upper limit 1 in Eq.~\ref{Relevance scoring estimation} &  53.26  	\\
   \bottomrule[1pt]
   \end{tabular}}}
   \caption{Ablation studies of the key components of KaSLA. We conduct the experiments for CodeS + KaSLA on BIRD-dev and use CodeS with CodeS-15B as the text-to-SQL backbone.}
\label{tb: ablation study}
\vspace{-5mm}
   \end{center}
   \end{table}


\begin{table*}[!h]
   \begin{center}
   \resizebox{\linewidth}{!}{
   \scalebox{1}{
   \begin{tabular}{c |c c  c c  c | c | c}
   \toprule
   Dataset &\makecell[c]{Schema linking \\ model} 
   &\makecell[c]{ Binary scoring function \\ with deepseek-coder-1.3B} & \makecell[c]{Probabilistic scoring model \\ with RoBERTa-Large}&\makecell[c]{Estimation and \\ dynamic programming} &Text-to-SQL  &Total time & EX\\
   \midrule
   \multirow{2}{*}{BIRD-dev}
    &Full Schema & 		/ & 	/ & 	/ & 5.15 s  & 5.15 s &57.63\\
     &KaSLA &3.5 s  &0.12 s     &	$<$ 0.01 s    &1.85 s  &  5.48 s  &60.17\\
   \bottomrule
   \end{tabular}}}
   \caption{Inference time cost per instance of each component in KaSLA using CodeS-15B as the text-to-SQL model.}
   \label{tb: Inference time cost}
   \end{center}
   \end{table*}
   
\begin{table}[!h]
   \begin{center}
   \resizebox{\linewidth}{!}{
   \scalebox{1}{
   \begin{tabular}{c |c c  c | c  }
   \toprule[1pt]
   Model & SuperSQL & CodeS &  \makecell[c]{CodeS \\+ KaSLA}& \makecell[c]{CodeS \\+ KaSLA  (Transfer)} \\
   \midrule
   BIRD-dev & 58.60  &60.30 &\textbf{60.17}& 60.02 \\
   Spider-dev & 87.40 &	84.72 	&\textbf{84.82 }&84.56\\
   \bottomrule[1pt]
   \end{tabular}}}
   \caption{Execution Accuracy (EX) (\%) of KaSLA trained on Spider-train but evaluated on BIRD-dev, and vice versa, for cross-scenario transfer ability evaluation.}
   \label{tb: trained on Spider-train but evaluated on BIRD-dev.}
\vspace{-4mm}
   \end{center}
   \end{table}
\subsection{Empirical studies (\textbf{RQ3})}
\paragraph{Ablation Study.}
We presented the ablation study results for the key components in KaSLA in Table~\ref{tb: ablation study}, the results concerning the choice of language model for the probabilistic scoring model are shown in Table~\ref{tb: ablation study about the choice of language model.} in Apendix and the scaling up performance of the scoring model are shown in Table~\ref{tb: ablation study about the choice of LLMs.} in Apendix, respectively.

As shown in Table~\ref{tb: ablation study}: (i) Removing the binary scoring model results in a lack of confirmation for high-confidence elements, leading to the inclusion of more redundant ones. This underscores the binary model's role in filtering out less relevant elements by ensuring that elements with high certainty are correctly identified. (ii) Omitting the probabilistic scoring model risks missing potentially relevant elements, resulting in gaps within schema linking. The probabilistic model is essential for assigning a non-zero probability to all elements, thus capturing those with potential relevance. (iii) The hierarchical strategy effectively reduces the number of candidate columns, thereby lowering complexity and improving efficiency. By structuring the linking process in stages, KaSLA can more precisely target relevant schema components. (iv) Without the upper limit set at 1, the model introduces disproportionate comparisons among similarly relevant items, potentially excluding some relevant elements. This constraint is crucial to maintain balanced relevance assessments, preventing the overshadowing of items that might otherwise contribute positively to SQL generation.
These ablation study highlights the significance of key components within KaSLA.

\paragraph{Transferability.}\label{sec: Transferability of KaSLA}
We conducted two experiments to evaluate KaSLA's performance in cross-scenario transfer. We trained the binary and probabilistic scoring models on the Spider training dataset and evaluated it on the BIRD dev dataset, and vice versa, to explore its cross-scenario transfer ability. Results are provided in Table~\ref{tb: trained on Spider-train but evaluated on BIRD-dev.}. We can find that pre-training KaSLA on public datasets yields results that outperform the baselines and are only slightly lower than what domain-specific fine-tuning would achieve. The results show that KaSLA demonstrates strong cross-scenario transferability, highlighting its robustness and adaptability across different data domains.

\paragraph{Inference time cost.}
We evaluated the inference time cost of integrating KaSLA into text-to-SQL frameworks in Table~\ref{tb: Inference time cost}. By utilizing the lightweight LLM DeepSeek-coder-1.3B and significantly reducing the number of tokens in the input prompts through optimized schema linking, KaSLA achieves improved SQL generation accuracy with only a modest increase in inference time. This showcases KaSLA's efficiency in balancing performance and computational demands.