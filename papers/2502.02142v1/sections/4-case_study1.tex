%%% START GUIDELINE %%%

% 1) CASE STUDY FOR BULK OPERATIONS: Our scheme can operate multiple operations at one time with one constraint. operations have to have the same first operand and they can have different op2 which is the case while doing mult of an operand of a matrix into all its corresponded values. We kept the architecture of commodity DRAM + repeat col counter per MAT in order to be able to read different places in each MAT + mask logic (serializer). we use index of op1 as index of row addr and index of op2 as col addr + Figure4.

% 2) Discuss on different precision support and changes in the level of parallelism.

%% Methodology and Evaluation %%

%1) The hardware caracteristics of our scheme are summerized in Table 2. HBM timings, energy, num of MAC, SAs, FAW window (like TransPIM), in the related paragraph, mention bandwidth. 16 col counters, temp size

%2) Overhead breakdown of ourscheme and the power of each added module + area of HBM like table 2 in TransPIM. In the related paragraph mention how we scaled the implementation technology to 22nm to match the memory technology. we implement our scheme using verilog, synopsis, etc.

%3) For the first case studY: We evaluate ourscheme in case of performing INT4-8 multiplications and compared it with pLUTo baseline and SIMDRAM. In all cases CPU is the baselineour implementation assumes the parralel operation of 4banks at the same time, so in the pLUTo baseline, the same level of parralelism withh 4 SA is implemented. We assume 1024 multiplication operations

%%% END GUIDELINE %%%

\section{Case study 1: Lama for Bulk Multiplications}
In this section, we detail how the Lama technique handles bulk multiplications for one operand-coalesced batch. To simplify the explanation, we first describe the process for 4-bit bulk multiplications and then discuss the differences when scaling up to 8-bit bulk multiplications.

As outlined in Section~\ref{HBM_organization}, each memory bank in DRAM is organized into subarrays, with each subarray consisting of 16 mats. Lama leverages both bank-level parallelism and mat-level parallelism within each bank, using all 16 mats in a subarray to perform simultaneous arithmetic operations, thereby enabling efficient bulk execution. Figure~\ref{fig:case_study1} illustrates the DRAM bank structure with the modifications of Lama to carry out bulk multiplications. To allow multiple subarrays to keep their rows open simultaneously, the global row buffer must be isolated from the local row buffers within each subarray. To achieve this, Lama employs a technique proposed in \cite{salp}, which involves adding a tri-state buffer per mat after the column-selection logic (CSL). This prevents short circuits in the master data line (MDL) for activated mats aligned in the same vertical position. This method ensures that multiple rows in different subarrays can remain open, while only one \textit{designated} subarray is used to handle column commands at any given time.

% Additionally, the bus arbiter manages data communication through the global I/O bus, coordinating interactions between the mask logic, temporary buffer, and global row-buffer.

\begin{figure}[t!]
\centering
\includegraphics[width=1.0\columnwidth]{figures/case_study1_new.pdf}
%\vskip -0.15in
\caption{Detailed steps to perform bulk 4-bit multiplications using Lama.}
\label{fig:case_study1}
\vskip -0.15in
\end{figure}

Figure~\ref{fig:case_study1} provides an overview of the DRAM bank structure and the execution flow required to implement Lama. Lama involves several key components: the \textbf{source subarray}, which stores the vector operands $b$ for all operand-coalesced batches, with the elements in each vector organized across one or more rows; the \textbf{compute subarray}, which holds the LUT data following the layout shown in Figure~\ref{fig:lut_data_layout} (for 4-bit operations each LUT for $f(a,b_{i})$ occupies a single mat and it is replicated in 16 mats); the \textbf{temporary buffer}, a small buffer used to temporarily store elements of the vector operand $b$ fetched from the source subarray; the \textbf{mask logic}, which filters and processes fetched data as needed; the \textbf{column counters}, previously described in Section \ref{LamaOverview}; and finally, the \textbf{bus arbiter}, responsible for managing data transfers through the global I/O bus and coordinating interactions between the mask logic, temporary buffer, and global row buffer.

In addition, for simplicity, we refer to the process of reading elements of the vector operand $b$ from the source subarray and storing them in the temporary buffer as an \textit{internal memory read} operation. Each internal read consists of two consecutive \textbf{internal column accesses (ICAs)} that fetch the entire 32-byte DRAM atom, corresponding to 8 bits per mat in each ICA. It is important to note that the key distinction between an internal read and a standard memory read is that the internal read does not transfer data to the I/O buffer nor sends it to the host; instead, it stores the data locally in the temporary buffer.

% ...corresponding to 32 different operands $b$ in 8-bit precision. ---> Fixed amount due to padding.

As previously mentioned, Lama decomposes the vector-matrix multiplication into multiple operand-coalesced batches. Each batch corresponds to a scalar-vector operation with a scalar operand $a$ and a vector operand $b$, where the elements of $b$ are stored across one or more rows in the memory. To manage row addressing in the \textit{source subarray}, Lama relies on the \textit{positional index} of the scalar operand $a$ within its original vector before decomposing the vector-matrix multiplication. This positional index is used to issue the ACT command to the corresponding row in the source subarray, which holds the coalesced batch related to that scalar operand. If the vector operand $b$ of the coalesced batch exceeds the storage capacity of a single row, Lama scales the positional index to span multiple rows. In contrast, for the \textit{compute subarray}, the \textit{value} of $a$ is used to ACTIVATE the appropriate LUT row where the function results are stored. Further details on this activation process are provided later in the section.

% For example, in Figure~\ref{fig:vector_matrix_mult}, row 1 in the source subarray holds the operand-coalesced batch {$M_{11}, M_{12}, M_{13}$}, which is associated with the first scalar element $V_{1}$ in vector $V$.

Lama execution flow employs a systematic approach to perform bulk multiplications for one of the operand-coalesced batches residing in the source subarray. Here we explain the process for 4-bit bulk multiplications as an example. First, in the source subarray, a row is activated based on the corresponding positional index of the scalar operand $a$ through an ACT command (\circled{1}), and all elements of vector operand $b$ in the selected row are stored in the local-row buffer of the source subarray, where they will remain for multiple iterations. Then, an internal read command is issued to fetch 32 different elements of $b$ and store them in the temporary buffer (\circled{2}). It is important to note that Lama statically performs zero-padding on elements of $b$ to match the fixed bitwidth of the hardware no matter the precision, that is, 4-bit elements are padded to 8-bit, which corresponds to the reading granularity of each mat. The indexed row in the source subarray is left open after the internal read operation, and remains open until all elements of $b$ in that row have been processed to finish the computations of the operand-coalesced batch.

% The indexed row in the source subarray remains open after the internal read operation, until finishing the computation iteration on all subset of the operand-coalesced batch.

Next, the LUT-based computation begins in the compute subarray by performing a LUT activation based on the \textit{value} of the scalar $a$ as an index (\circled{3}). After the desired row is activated and resides in the local row buffer, the column address counter/latch units initiate the LUT retrieval operation using the first 16 elements of $b$ stored in the temporary buffer ($b_{0}$ to $b_{15}$) as shown in\circled{4}. In the first LUT retrieval, each mat outputs an 8-bit result for the operation $f(a,b_{i})$. These results are directly transferred to the host via the global I/O bus. For the next set of 16 elements of $b$, the column counters perform an additional LUT retrieval, and the results are again transferred to the host.

This iterative process continues until all operations for the entire operand-coalesced batch are completed. Once all computations are finalized, a PRECHARGE command is issued to close the open rows in both the source and compute subarrays. In the event that the elements of $b$ span over several rows, additional ACT and PRECHARGE commands are issued per row, requiring more iterations to complete the batch. Note that with a parallelism degree of $p = 16$, all LUT-retrieved values are valid, leaving the mask logic idle throughout the entire process for 4-bit bulk multiplications.

% The temp buffer size is chosen as 64-byte in order to keep the multiplication results while keeping the remaining $b$ operands that do not perform the LUT retrieval yet.

\subsection{8-bit Multiplications}
Figure~\ref{fig:timeline_multiplication} depicts the timeline of performing 8-bit bulk multiplications within a memory bank using Lama. The process for accessing elements of $b$ from the source subarray remains consistent with the 4-bit operation, where Lama fetches 32 different $b$ elements per internal memory read. However, the LUT-based computation differs in two key aspects when scaling up to 8-bit operations.

\begin{figure*}[t!]
\centering
\includegraphics[width=1.0\textwidth]{figures/timeline_multiplication.pdf}
%\vskip -0.15in
\caption{Timeline of performing multiplications using Lama. Each read operation includes two internal column accesses (ICA). The "M" block represents the latency of the mask logic. LUT retrieval includes one ICA followed by the mask logic. An ACT command is issued only once to access the row indexed by the scalar operand $a$ in both the source and compute subarrays. For subsequent iterations with new elements of $b$, no additional ACT commands are needed (indicated by the red block) due to the open-page policy.}
\label{fig:timeline_multiplication}
\vskip -0.15in
\end{figure*}

First, the LUT data for an 8-bit multiplication spans across eight mats (Figure~\ref{fig:lut_data_layout}b), reducing the parallelism degree to $p=2$. During one LUT retrieval, only two elements of $b$ are selected from the temporary buffer and broadcasted to all 16 column counters, with each set of eight consecutive column counters processing the same element $b$. While this procedure limits the parallelism within each bank, Lama compensates it by leveraging bank-level parallelism, maintaining high throughput even when handling higher operand precision.

% ...meaning each set of 8 column counters receives the same operand $b$. This limits the number of simultaneous operations but ensures the integrity of the computation across higher operand precision.

Second, after performing the LUT retrieval for these two elements of $b$, not all fetched values are valid. Consequently, the mask logic filters out invalid results within each set of eight mats, by using the three MSBs of $b$ elements to select the mat containing the valid result of each set. The valid results are stored in the mask logic buffer until gathering 16 bytes, and then they are outputted. The mask logic operates in two cycles (since $p=2$) to serially select the valid $f(a,b_{i})$ for each element of $b$, and its latency is added to the LUT retrieval operation as illustrated in Figure~\ref{fig:timeline_multiplication} by the "M" block. As demonstrated in the evaluation section~\ref{eval_mult8b}, this added latency hardly impacts performance compared to state-of-the-art PuM techniques.

To complete the fetching of a 16-bit multiplication result for each of the two elements of $b$, two LUT retrieval operations are done. This is because each internal column access (ICA) retrieves 8 bits from each mat, and only two of the 16 mats provide valid data. During the first LUT retrieval, data is accessed according to the two elements of $b$. For the second LUT retrieval, the column counters increment the previously determined addresses by one, to access the subsequent 8 bits in each mat.

This procedure continues until all computations related to the current operand-coalesced batch are completed. However, the ACT command in both the source and compute subarray is only issued once during the initial iteration. For all subsequent iterations, Lama efficiently reuses the already-opened row in the local row buffer of both subarrays, eliminating the need for additional ACT commands. Additional memory commands are only necessary when the $b$ elements are stored in multiple rows of the source subarray.

% For other operand precision, the latency of the mask logic varies based on the parallelism level $p$ associated with that precision. However, when $p=16$ the mask logic is bypassed resulting in no additional latency overhead.

Lama is not limited to multiplication operations; it can execute any arithmetic function $f(a,b)$, including addition, division, and other complex functions. Multiplication is used as an example in this context due to its relevance, and the computational complexity it introduces when handled within memory systems.

\subsection{Column Addressing for Varying Operand Precision}
For all supported operand precisions except 4-bit, the LUT multiplication results are extended to a 16-bit format to be word aligned in memory, requiring two Internal Column Accesses (ICAs) to fetch the complete result. During each ICA, the column counter selects from 64 possible positions (each mat has 64 8-bit columns), using the elements of $b$ to determine the correct address. The 5 least significant bits (LSBs) of $b$ with a zero bit appended to the right,\{$b_{i}[4:0], 0$\}, is used as the 6-bit column address for the first ICA. For the second ICA, the appended bit is changed to one to fetch the next 8 bits from each mat to complete the 16-bit result. For 5-bit precision, all 16 mats provide a valid result (the LUT occupies a single mat and is replicated 16 times in each bank), each mat providing the result for a different $b_{i}$. For precisions higher than 5 bits, the LUT occupies multiple mats, so the remaining most significant bits (MSBs) of $b_{i}$ are used by the mask logic to select the valid results. For instance, for 6-bit precision, the LUT occupies 2 mats, and the most significant bit of $b_{i}$ is used to select which one of each pair of mats provides the desired result. In this case, each bank can process 8 operations in parallel, each corresponding to a different element of $b$.

Table~\ref{t:mult_different_precisions} shows the degree of parallelism per bank ($p$) and the number of bits from $b$ required for column addressing across varying operand precisions. For 4-bit and 5-bit multiplications, the parallelism level $p$ reaches its maximum value, utilizing all 16 mats within a subarray. The mask logic is bypassed in these cases, as all fetched results are valid. In 6-bit multiplication, $p$ is reduced to 8, as the LUT data spans two mats. The 5 LSBs of $b_i$ are used for column selection, while the MSB is used by the mask logic to select one data element out of two consecutive mats. In 7-bit multiplication, the LUT data spans four mats, decreasing $p$ to 4. In this case, the two MSBs of $b_i$ are used by the mask logic to select a valid mat among four consecutive mats. For 8-bit multiplication, the three MSBs select one element among eight consecutive mats.

\begin{table}[t!]
%\scriptsize
\caption{Parallelism Degree ($p$), Column Addressing, and Masking Requirements for Different Operand Bitwidths in Lama MUL.}
\label{t:mult_different_precisions}
\vskip -0.20in
\begin{center}
\resizebox{1.0\columnwidth}{!}{%
    \begin{tabular}{|c|c|c|c|c|}
    \hline
    \textbf{bitwidth}                  & \textbf{p}                 & \textbf{\#LSBs for Column Addressing}        & \textbf{\#MSBs for Masking}          & \textbf{\#ICAs}  \\
    \hline
               4-bit                   &   16                       & 4                                                            &  $\times$                                            & 1                \\
    \hline
               5-bit                   &   16                       & 5                                                            &  $\times$                                            & 2                \\
    \hline
               6-bit                   &   8                        & 5                                                            &  1                                                   & 2                \\
    \hline
               7-bit                   &   4                        & 5                                                            &  2                                                   & 2                \\
    \hline
               8-bit                   &   2                        & 5                                                            &  3                                                   & 2                \\
    \hline
    \end{tabular}%
}
\end{center}
\vskip -0.20in
\end{table}

\subsection{Column Addressing for Varying Precision}
For operand precisions greater than 4 bits, LUT multiplication results are extended to a 16-bit format to be word-aligned in memory, requiring two ICAs to fetch the complete result. During each ICA, the column counter selects from 64 possible positions (each mat has 64 8-bit columns), using the elements of $b$ to determine the correct address. The 5 least significant bits (LSBs) of $b$ with a zero bit appended to the right, \{$b_{i}[4:0], 0$\}, serve as the 6-bit column address for the first ICA. For the second ICA, the appended bit is changed to one to fetch the next 8 bits from each mat, completing the 16-bit result. For 5-bit precision, all 16 mats provide a valid result (the LUT data occupies a single mat and is replicated 16 times in each bank), each mat providing the result for a different $b_{i}$. For precisions higher than 5 bits, the LUT spans multiple mats, so the remaining MSBs of $b_{i}$ are used by the mask logic to select the valid results. For instance, in 6-bit precision, the LUT occupies 2 mats, and the MSB of $b_{i}$ selects which one of each pair of mats provides the desired result. In this case, each bank can process 8 operations in parallel, each corresponding to a different element of $b$.

Table~\ref{t:mult_different_precisions} summarizes the degree of parallelism per bank ($p$) and the number of bits from $b$ required for column addressing across varying operand precisions. For 4-bit and 5-bit multiplications, $p$ reaches its maximum value, utilizing all 16 mats within a subarray, with the mask logic bypassed since all fetched results are valid. In 6-bit multiplication, $p$ is reduced to 8, as the LUT data spans two mats, using the 5 LSBs of $b_i$ for column selection and the MSB by the mask logic to select one data element out of two consecutive mats. In 7-bit multiplication, the LUT data spans four mats, decreasing $p$ to 4, with the two MSBs of $b_i$ are used by the mask logic to select a valid mat among four consecutive mats. For 8-bit multiplication, the three MSBs select one element among eight consecutive mats.

\begin{table}[t!]
%\captionsetup{font=small}
%\scriptsize
%\caption{Parallelism Degree ($p$), Column Addressing, and Masking Requirements for Different Operand Bitwidths in Lama MUL.}
\caption{Parameters for different operand bitwidths in Lama MUL.}
\label{t:mult_different_precisions}
\begin{center}
%\vskip -0.20in
\resizebox{1.0\columnwidth}{!}{%
    \begin{tabular}{|c|c|c|c|c|}
    \hline
    \textbf{bitwidth}                  & \textbf{p}                 & \textbf{\# $b_{i}$ LSBs for Column Addressing}        & \textbf{\# $b_{i}$ MSBs for Masking}          & \textbf{\#ICAs}  \\
    \hline
               4-bit                   &   16                       & 4                                                            &  $\times$                                            & 1                \\
    \hline
               5-bit                   &   16                       & 5                                                            &  $\times$                                            & 2                \\
    \hline
               6-bit                   &   8                        & 5                                                            &  1                                                   & 2                \\
    \hline
               7-bit                   &   4                        & 5                                                            &  2                                                   & 2                \\
    \hline
               8-bit                   &   2                        & 5                                                            &  3                                                   & 2                \\
    \hline
    \end{tabular}%
}
\end{center}
\vskip -0.1in
\end{table}


\subsection{Methodology and Configuration}
This section presents the methodology for evaluating Lama's performance and energy consumption in the case study of bulk multiplications. Table~\ref{t:configuration} outlines the hardware characteristics of Lama's evaluation platform. Our implementation assumes a memory setup based on the standard HBM2 specification~\cite{jedec}. The timing and energy parameters are derived from \cite{fine-grained}.

As shown in Table~\ref{t:configuration}, the evaluation of Lama also considers bank-level parallelism by distributing different coalesced batches across various banks. As shown in Figure~\ref{fig:timeline_multiplication}, performing all computations for a coalesced batch requires only two ACT commands. Consequently, when all banks within a channel are utilized for computation, a total of 32 ACT commands are issued. To accommodate these 32 ACT commands, 8 {\fontfamily{cmss}\selectfont tFAW} windows are needed. To avoid any stalls while all banks are operational, the computation time for each coalesced batch must exceed 8 times the {\fontfamily{cmss}\selectfont tFAW} window duration. For 4-bit precision, which has the shortest computation time, the coalesced batch size must be greater than 128 elements of $b$ to avoid being limited by the {\fontfamily{cmss}\selectfont tFAW} constraint. For other precision, this restriction is less stringent since the computation time per batch is longer.

Furthermore, within each bank, only one subarray is required and enabled to perform arithmetic operations for a given function, including those with 8-bit precision operands. To accommodate various functions, additional subarrays can be allocated for LUT computation. The host-to-HBM bandwidth is assumed to be 256 GB/s, consistent with the specifications in \cite{fine-grained}.

\begin{table}[t!]
%\scriptsize
\caption{Architectural Parameters for Lama.}
\label{t:configuration}
%\vskip -0.20in
\begin{center}
%\vskip -0.22in
\resizebox{1.0\columnwidth}{!}{%
    \begin{tabular}{|>{\centering\arraybackslash}m{3.3cm}|m{7.4cm}|}
    \hline
    \makecell{\textbf{HBM Organization}}  &    channels/die (4-die stack) = 2 (8), pch/channel = 2,\newline  banks/channel = 16  (banks/pch = 8),  banks/group = 4,  \newline subarrays/bank = 64, bank rows = 32k, row buffer size/channel (row buffer size/pch)= 2KB (1KB), mat size = $512\times512$, DQ size = 128-bit/channel            \\
    \hline
    \textbf{HBM Timing (ns)}              &  t\textsubscript{RC} = 45, t\textsubscript{RCD} = 16, t\textsubscript{RAS} = 29, t\textsubscript{CL} = 16, t\textsubscript{RRD} = 2, t\textsubscript{WR} = 16, \newline t\textsubscript{CCD\textsubscript{S}} = 2, t\textsubscript{CCD\textsubscript{L}} = 4, t\textsubscript{FAW} = 12,  \# of activates in t\textsubscript{FAW} = 8  \\
    \hline
    \textbf{HBM Energy (pJ)}              &    e\textsubscript{ACT} = 909, e\textsubscript{Pre-GSA} = 1.51, e\textsubscript{Post-GSA} = 1.17, e\textsubscript{I/O} = 0.80  \\
    \hline
    \textbf{Bank-level Configuration}              &        Clock = 500MHz, Column Counter/Latch = $16(8b)$,  \newline  Mask Logic = $1$, Temporary Buffer = $1(64B)$               \\
    \hline
    \end{tabular}%
}
\end{center}
%\vskip -0.20in
\end{table}

The objective of our evaluation is to demonstrate that Lama significantly reduces the number of memory commands, particularly activation (ACT) commands, compared to previous PuM techniques. This reduction leads to notable energy savings and performance improvements in bulk multiplications, while also providing flexibility to support up to 8-bit operand precision.

\textit{Simulation.} We developed an in-house simulator to model the performance and energy characteristics of Lama and all PuM baselines. The simulator leverages the HBM2 architectural configuration and the timing/energy parameters shown in Table~\ref{t:configuration} to calculate the number of commands, energy consumption, and latency, for bulk multiplications at 4-bit and 8-bit integer precision.

\textit{Baselines.} For comparison, we evaluate a baseline CPU on a real system equipped with an Intel\textsuperscript{\circledR} Xeon W-2245 CPU~\cite{intel}, utilizing AVX-512 Intel\textsuperscript{\circledR} Streaming SIMD Extensions for 8-bit multiplications. We also evaluate prior PuM approaches including pLUTo~\cite{pluto}, as a LUT-based technique, and SIMDRAM~\cite{simdram}, as a charge-sharing-based PuM technique. To ensure a fair comparison, the level of parallelism is consistent across all the baselines and our Lama implementation.

\subsection{Overheads}\label{overhead}
We assume an 8GB HBM with 4 layers (1GB per channel) as the memory configuration for Lama. Lama introduces two major components to the commodity DRAM: $(i)$ column counters and $(ii)$ mask logic. In addition, it includes a temporary buffer. These components were implemented using Verilog HDL and synthesized on the Synopsys Design Compiler with a 28nm technology library. In order to match the rate of column access time $t_{CCD} = 2$ns, the added bank-level components are configured to run at 500 MHz clock frequency. The area and power data obtained from the synthesis are scaled to 22nm to match the memory technology. We take into account the difference in manufacturing process between logic and DRAM similar to previous studies~\cite{technology_difference, transpim, drisa, fulcrum}, where the DRAM process incurs around 50\% additional area overhead for the logic.

Table~\ref{t:overhead} summarizes the area and power consumption of each unit. Each memory bank in Lama is equipped with sixteen column counters, one mask logic unit, and a temporary buffer. Assuming that all banks across the HBM2 channels are equipped with these units, the additional components consume approximately 1.32 mm\textsuperscript{2}, resulting in a 2.47\% area overhead. This is significantly lower than the area overheads reported in \cite{pluto, simdram}, thus preventing any significant loss in DRAM density and memory capacity.

% Furthermore, the power consumption of the added components is only Y\% of the total power budget of HBM2.

\begin{table}[t!]
%\scriptsize
\caption{Summary of the area and power consumption of the added logic in the Lama architecture.}
\label{t:overhead}
%\vskip -0.40in
\begin{center}
\resizebox{1.0\columnwidth}{!}{%
    \begin{tabular}{|c|cc|}
    \hline
    \textbf{Units}     &  \textbf{Area(um\textsuperscript{2} per Bank}) & \textbf{Power (mW) per Bank}        \\
    \hline
    Column Counter/Latch   &     5002.8                            &       1.49             \\
    Mask Logic             &     1628                              &       1.01             \\
    Temporary Buffer       &     3636.6                            &       3.76             \\
    Others                 &     19.73                             &       0.09             \\
    \hline
    \end{tabular}%
\quad
    \begin{tabular}{|c|c|}
    \hline
    \textbf{Lama}         &  \textbf{Area(mm\textsuperscript{2}})       \\
    \hline
    8GB HBM2              &     53.15                                   \\
    Overhead              &     1.32                                    \\
    \hline
    \end{tabular}%
}
\end{center}
%\vskip -0.20in
\end{table}

\subsection{Evaluation}\label{eval_mult8b}
Previous PuM architectures have demonstrated promising results in executing bulk operations. However, these gains come at the cost of frequent ACT commands, which significantly increase energy consumption. Additionally, they face significant challenges in supporting operand sizes greater than 4-bit precision. For higher precision, their performance deteriorates due to the substantial increase in the number of issued commands, particularly for complex arithmetic operations.

To demonstrate Lama's higher performance in bulk multiplications, we compare it against existing proposals using 4-bit and 8-bit operand precisions. Table~\ref{t:cs1_eval_baselines} presents the latency, energy consumption, performance and command count for both precisions. To ensure a fair comparison, the level of parallelism is set to four for all schemes, which is consistent with the parallelism level used in the evaluation section of the pLUTo paper~\cite{pluto}. In Lama, this parallelism is achieved by executing operations across four different banks, where each bank performs operations required for one operand-coalesced batch, with one subarray per bank dedicated to LUT computation. Meanwhile, the other baselines employ subarray-level parallelism, using four subarrays within a single bank.

All techniques perform the same 1024 multiplication operations using 4 scalar operands, meaning that each bank (or subarray) handles computations related to one coalesced batch, with each bank or subarray executing 256 multiplication operations. Four key conclusions can be drawn from the results in Table~\ref{t:cs1_eval_baselines}.

First, Lama significantly reduces the number of ACT commands compared to other schemes. The ACT command count in Lama involves both reading the elements of $b$ from the source subarray and performing the LUT computation in the compute subarray. As precision increases from 4-bit to 8-bit, Lama requires the same ACT command count because row accesses are independent of operand precision. The only increase is in the number of read commands, which have a much lower energy impact compared to ACT commands.

Second, the SIMDRAM~\cite{simdram} baseline is based on the Triple Row Activation (TRA) mechanism in \cite{ambit}, which executes bitwise operations using a sequence of commands for MAJ/NOT operations. As shown in the study, each additional simultaneous row activation increases energy consumption by 22\% over a single-row activation. SIMDRAM also requires multiple execution cycles, and as operand precision increases, the number of cycles grows exponentially, leading to significant latency inefficiency. Lama achieves $13.7\times$ $(13.4\times)$ throughput for 4-bit (8-bit) precision and $5.8\times$ $(5.4\times)$ energy improvement over SIMDRAM.

Third, the pLUTo~\cite{pluto} baseline can perform 256 simultaneous bulk operations per subarray. However, multiple ACT commands are required to search all the LUT rows for the matching results, which increases energy consumption, particularly for 8-bit multiplication, where the number of rows activated rises exponentially. Lama shows $9.6\times$ $(8.3\times)$ energy savings over pLUTo in 4-bit (8-bit) multiplication. In terms of speedup, Lama achieves $3.8\times$ $(3.5\times)$ throughput for 4-bit (8-bit) precision. The decrease in throughput at 8-bit precision is due to the reduced parallelism and the extra cycles for filtering invalid data in the mask logic.

% CPU comparision
Fourth, compared to the CPU baseline for 8-bit multiplication, the LUT-based PuM architectures, Lama and pLUTo, show performance improvements of $3.8\times$ and $1.09\times$, respectively. For energy efficiency, all PuM architectures demonstrate greater energy savings than the CPU, with Lama obtaining the highest energy savings at $8\times$ over the CPU baseline.

%%% Original Version %%%
Overall, Lama effectively handles multiplications of up to 8-bit operands while reducing the number of memory commands required to perform the computations in-memory, resulting in higher performance and a more energy-efficient solution for complex operations.

\begin{table}[t!]
%\scriptsize
\caption{Comparison of Lama for bulk multiplication vs. prior PuM works. All methods execute 1024 multiplications in both 4-bit and 8-bit integers with a parallelism level of 4. Results are calculated based on the HBM2 configuration provided in Table~\ref{t:configuration}.}
\label{t:cs1_eval_baselines}
%\vskip -0.40in
\begin{center}
%\vskip -0.2in
\resizebox{1.0\columnwidth}{!}{%
    \begin{tabular}{|c|c|c|c|c|}
    \hline
    \makecell{Methods}                        &  \textbf{pLUTo~\cite{pluto}}    &   \textbf{SIMDRAM~\cite{simdram}}   &    \textbf{Lama} &    \textbf{CPU}   \\
    \hline
    \multicolumn{4}{|c|}{{\textbf{INT-4 multiplication}}}  \\  %\multicolumn{6}{q}{\textbf{INT-8 multiplication}}
    \hline
    {Latency (ns)}              &              2240               &              7964                 &           583       &    -\\
    \hline
    {Energy (nJ)}               &              247.4             &              151.23                &           25.8      &    -\\
    \hline
    {Performance (GOPs/s)}      &              0.46               &              0.13                 &           1.75      &    -\\
    \hline
    {Num ACT commands}          &              1088               &              310                  &            8        &    -\\
    \hline
    {Num Total commands}        &              2176               &              465                  &           112       &    -\\
    \hline
    \multicolumn{4}{|c|}{{\textbf{INT-8 multiplication}}}  \\
    \hline
    {Latency (ns)}              &              8963              &              34065                &           2534      &    9760.4\\
    \hline
    {Energy (nJ)}               &              989.7             &              646.9               &           118.8     &    7900\\
    \hline
    {Performance (GOPs/s)}      &              0.11               &               0.03                &           0.4      &    0.1\\
    \hline
    {Num ACT commands}          &              4352               &               1326                &            8        &    -\\
    \hline
    {Num Total commands}        &              8704               &               1989                &           592      &    -\\
    \hline
    \end{tabular}%
}
\end{center}
\vskip -0.24in
\end{table}

% Add the CPU comparision
