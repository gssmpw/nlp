\section{Lama Overview}\label{LamaOverview}
Lama is a lightweight LUT-based mechanism designed to efficiently execute complex arithmetic operations in bulk. Our primary goal is to address the critical inefficiencies of existing LUT-based PuM approaches, particularly those caused by the need for successive ACT commands during bulk operations, as well as the challenges associated with supporting operands larger than 4 bits. Additionally, Lama tackles the performance limitations imposed by DRAM's structural constraints. To overcome these challenges, Lama introduces a novel execution scheme that eliminates the reliance on successive ACT commands for performing bulk arithmetic operations. As shown previously in Figure~\ref{fig:vector_matrix_mult}, Lama clusters operations into batches, which are defined for simpler use as \textit{operand-coalesced batches}, where each batch consists of multiple operations that share a scalar operand. In other words, an operand-coalesced batch is a function $f$ whose inputs are a scalar $a$ and a vector $b$, and the result is another vector that consists of applying the function $f$ to each pair of elements $a$ and $b_{i}$.

To perform LUT-based computing and derive the result of a function $f$ applied to operands $a$ and $b$ (i.e., $f(a,b)$), Lama defines two key operations: \textbf{\textit{LUT activation}} which involves a memory ACT operation that activates a row, with the row index determined by the value of $a$, and \textbf{\textit{LUT retrieval}}, where the actual results for concurrent operations $f(a,b_{i})$ are fetched through one internal column access (ICA). The starting point for the column access is determined by the value of $b_{i}$, which addresses the specific column positions in the activated row. These two operations are executed consecutively to efficiently compute the desired function result.

% Alternative name instead of LUT retrieval: LUT readout
Lama supports LUT retrieval for any given function $f$, enabling arithmetic operations on operands with bit-widths of up to 8-bit. Depending on the specific operation, the result $f(a,b_{i})$ can have a bit-width of up to 16-bit (e.g., multiplication).

Figure~\ref{fig:lut_data_layout} illustrates the data layout for a set of LUTs used to perform bulk operations on operand-coalesced batches. Each LUT is dedicated to one independent function $f(a,b_{i})$. The size of the LUT varies based on the operands and result precision of function $f$. For example, a 4-bit multiplication LUT occupies one mat, while an 8-bit multiplication LUT requires eight mats to fit its data. To enable parallel processing, the LUT is replicated across the entire subarray. The \textit{degree of parallelism}, denoted as $p$, reflects the number of simultaneous operations that can be performed through a LUT retrieval, and is influenced by the LUT data size. In scenarios where the LUT data size is small, such as 4-bit multiplications, $p$ can reach up to 16, i.e., the number of mats available in HBM2. On the other hand, for larger LUT data sizes like 8-bit multiplications, $p$ is reduced to 2 due to the increased data requirements.

If the number of parallel operations ($p$) that can be executed simultaneously is less than the size of the operand-coalesced batch, completing all operations within the batch requires issuing additional memory commands. However, Lama avoids the need for extra LUT activations in this scenario. The reason is that the LUT activation, which is based on the scalar operand, remains valid for the entire operand-coalesced batch. Consequently, Lama reuses the already activated row in the local row buffer by taking advantage of the open-page policy. Only the LUT retrievals for the subsequent sets of $p$ operations are performed, ensuring that only a single ACT command is required for the entire batch of operand-coalesced operations.

\begin{figure}[t!]
\centering
\includegraphics[height=2.7cm, width=8.9cm]{figures/lut_data_layout_small.pdf}
%\vskip -0.15in
\caption{LUT data layout for (a) 4-bit and (b) 8-bit multiplications.}
\label{fig:lut_data_layout}
\vskip -0.15in
\end{figure}

\subsection{Enabling Independent Column Selection in DRAM Mats}
In conventional commodity DRAMs, memory read operations involve a column-address counter/latch that selects the same column position across all mats within a subarray using Column Select Lines (CSLs). Since each mat provides 8-bit data per column access, the column counter can select from 64 different data positions in HBM2. However, to efficiently execute operand-coalesced batches in bulk, independent column access across mats is essential. This capability allows each mat to access different data positions within the same row.

To facilitate this, Lama replicates the column counter/latch within each bank to match the number of mats in a subarray. In HBM2, where each subarray consists of 16 mats, Lama introduces 16 column counters/latches per bank, enabling independent column selection across all mats. This setup is suitable because only one subarray can connect its local data lines to the global sense amplifiers at a time for read or write operations, and thus there is no need to replicate per subarray.

Moreover, to accommodate both conventional memory operations and LUT-based modes, Lama's column counters are designed to receive the column selection signal from the address register or from a temporary buffer via a multiplexer. The added area overhead of these replicated column counters is minimal, and their impact on overall memory capacity and performance is negligible, as will be detailed in Section~\ref{overhead}.

\subsection{Mask Logic}
When performing a LUT retrieval operation, each mat transfers consecutive column positions, but not all of the fetched data from mats may correspond to the desired result $f(a,b_{i})$. This issue arises when the LUT data for the function $f$ spans across multiple mats, reducing the degree of parallelism ($p$) to less than 16. In such cases, the mask logic selects valid results while filtering out irrelevant data from the remaining mats.

The mask logic's functionality is illustrated in Figure~\ref{fig:mask_logic}. The design features a multiplexer with sixteen inputs, each connected to a different mat in the subarray. To filter out irrelevant data and retain the target values, the mask logic operates in a serial manner, where in each iteration, the select port of the multiplexer is determined by a small finite-state machine that uses the most significant bits (MSBs) of the vector element $b_{i}$ and the precision of the operation to choose the correct value.

% A small state machine determines the number of MSB bits required for selection, depending on the precision of the operation.

Because the number of valid results $f(a,b)$ retrieved in a single LUT access depends on the precision and degree of parallelism, the size of the result can vary. To handle this variation, a buffer is placed after the multiplexer, concatenating results until they reach 16 bytes before outputting. This ensures a consistent bitwidth across different precision levels and parallelism degrees.

% The mask logic's functionality is illustrated in Figure~\ref{fig:mask_logic}. It consists of a multiplexer with sixteen inputs, each connected to one of the mats in a subarray, a state machine responsible for generating the selection signal, and a fifo to concatenate the selected values. The state machine determines the correct multiplexer selection based on the precision of the operands and the 3-bit MSB of operand $b$. The selected values are then stored in the shift register, which aligns the data with the read/write bitwidth in each read cycle.

\begin{figure}[t!]
\centering
\includegraphics[height=1.8cm, width=4cm]{figures/mask_logic_new.pdf}
%\vskip -0.15in
\caption{Mask logic.}
\label{fig:mask_logic}
%\vskip -0.15in
\end{figure}

% When $p=16$, all retrieved results are valid, and the mask logic is bypassed. However, when $p<16$, the mask logic ensures that only the relevant results are processed, minimizing unnecessary data transfers. These added components incur minimal area overhead and do not interfere with the memory's normal operations, allowing seamless switching between storage and computation modes.

% The number of cycles is at most 8 while $p=8$ with the latency of internal cycles which is very short compared with cycles is needed to perform READ command operations ($t_{CL} = 16ns$).
