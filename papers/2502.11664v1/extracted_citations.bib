@article{agrawal2024pixtral,
  title={Pixtral 12B},
  author={Agrawal, Pravesh and Antoniak, Szymon and Hanna, Emma Bou and Bout, Baptiste and Chaplot, Devendra and Chudnovsky, Jessica and Costa, Diogo and De Monicault, Baudouin and Garg, Saurabh and Gervet, Theophile and others},
  journal={arXiv preprint arXiv:2410.07073},
  year={2024}
}

@inproceedings{jin2024chat,
  title={Chat-univi: Unified visual representation empowers large language models with image and video understanding},
  author={Jin, Peng and Takanobu, Ryuichi and Zhang, Wancai and Cao, Xiaochun and Yuan, Li},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={13700--13710},
  year={2024}
}

@online{kexuefm-10040,
  title={A Brief Reflection on Multimodal Position Embedding.},
  author={Su, Jianlin},
  year={2024},
  month={Mar},
  url={https://kexue.fm/archives/10040},
}

@article{li2023videochat,
  title={Videochat: Chat-centric video understanding},
  author={Li, KunChang and He, Yinan and Wang, Yi and Li, Yizhuo and Wang, Wenhai and Luo, Ping and Wang, Yali and Wang, Limin and Qiao, Yu},
  journal={arXiv preprint arXiv:2305.06355},
  year={2023}
}

@inproceedings{li2024llama,
  title={Llama-vid: An image is worth 2 tokens in large language models},
  author={Li, Yanwei and Wang, Chengyao and Jia, Jiaya},
  booktitle={European Conference on Computer Vision},
  pages={323--340},
  year={2024},
  organization={Springer}
}

@inproceedings{li2024mvbench,
  title={Mvbench: A comprehensive multi-modal video understanding benchmark},
  author={Li, Kunchang and Wang, Yali and He, Yinan and Li, Yizhuo and Wang, Yi and Liu, Yi and Wang, Zun and Xu, Jilan and Chen, Guo and Luo, Ping and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={22195--22206},
  year={2024}
}

@article{maaz2023video,
  title={Video-chatgpt: Towards detailed video understanding via large vision and language models},
  author={Maaz, Muhammad and Rasheed, Hanoona and Khan, Salman and Khan, Fahad Shahbaz},
  journal={arXiv preprint arXiv:2306.05424},
  year={2023}
}

@article{su2024roformer,
  title={Roformer: Enhanced transformer with rotary position embedding},
  author={Su, Jianlin and Ahmed, Murtadha and Lu, Yu and Pan, Shengfeng and Bo, Wen and Liu, Yunfeng},
  journal={Neurocomputing},
  volume={568},
  pages={127063},
  year={2024},
  publisher={Elsevier}
}

@article{wang2024qwen2,
  title={Qwen2-vl: Enhancing vision-language model's perception of the world at any resolution},
  author={Wang, Peng and Bai, Shuai and Tan, Sinan and Wang, Shijie and Fan, Zhihao and Bai, Jinze and Chen, Keqin and Liu, Xuejing and Wang, Jialin and Ge, Wenbin and others},
  journal={arXiv preprint arXiv:2409.12191},
  year={2024}
}

@article{xu2024pllava,
  title={Pllava: Parameter-free llava extension from images to videos for video dense captioning},
  author={Xu, Lin and Zhao, Yilin and Zhou, Daquan and Lin, Zhijie and Ng, See Kiong and Feng, Jiashi},
  journal={arXiv preprint arXiv:2404.16994},
  year={2024}
}

