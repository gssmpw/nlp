\subsection{Methodology Design}
% Trace sensitive functions and sensitive operations.
Initially, considering the characteristics of TEEs, including resource constraints and limited support for high-level programming languages, our solution focuses on protecting the parts of the program that involve sensitive operations.
Developers often struggle to clearly identify which sections of their programs contain sensitive operations.
To address this issue, we leverage large language models (LLMs), which excel in code semantic analysis~\cite{yan2023closer,wu2023effective,ren2023misuse}, to identify the code that contains sensitive operations within the program.
To enhance the accuracy of the LLM's analysis, we designed a series of prompts to evaluate its judgments.

% Only port part of them,
For the identified code, we transform it into native code (specifically Rust in our work) to ensure it is executable within the TEE.
Our solution adapts LLMs with the \tool{ReAct} strategy to implement automatic transformation.
To ensure the TEE-executable nature and functional consistency of the transformed code, we introduce external compiler checks and consistency validations.
Specifically, we utilize compiler checks to identify issues in the transformed code and provide feedback to the LLM for adjustments.
We employ consistency validations to verify the output of the transformed code before and after transformation using test inputs.

% Link to the original program
Following the successful transformation, we adjust the relevant API calls in the code (such as timestamps and environment variables) to align with those provided by the TEE.
After this, we integrate the transformed code into the original program, modifying the original sensitive code to function as an external call, referencing the transformed code.
Finally, we implement TEE protection for the original program, minimizing code modifications and manual intervention.

\subsection{Overview}
Figure~\ref{fig:system:overview} illustrates the overview of our approach.
\system consists of three modules: 
(1) \textbf{Sensitive Function Identifier} uses LLMs to identify the sensitive functions in the program;
(2) \textbf{Content Transformer} utilizes the \tool{ReAct} strategy to transform sensitive functions; specifically, it integrates compiler checks and consistency validation to ensure functional consistency after the transformation;
(3) \textbf{Execution Linker} ports the transformed code to TEEs and integrates it with the original programs, ensuring that the original functionality is preserved.

\begin{figure*}[ht]
    \centering
    \includegraphics[width=0.9\linewidth]{fig/design/overview.pdf}
    \caption{Workflow and three modules of \textsc{AutoTEE}. }
    \label{fig:system:overview}
\end{figure*}

Given a program, \system first constructs the abstract syntax tree and then extracts the leaf functions from the source code.
It then employs an LLM agent to identify snippets containing sensitive operations while generating test inputs.
We execute the functions using generated inputs and measure the line coverage (using \tool{JaCoCo}~\cite{jacoco} and \tool{Pytest-cov}~\cite{pytestcov}).
Subsequently, \system uses a few transformation examples for the agent to generate new native code.
\system checks whether the transformed code can be compiled and assesses the functional consistency by comparing outputs from the original and transformed code using the same inputs.
If the code passes the check and validation, the transformation is considered successful.
Otherwise, \system leverages the \tool{ReAct} strategy to iteratively modify the code until it successfully passes the check and validation.
The transformed code is then compiled as an execution file and placed into the TEE.
Finally, \system modifies the original code to incorporate an external call or network communication that references the execution file located in the TEE.

\subsection{Sensitive Function Identifier}
This module extracts functions from the program and identifies those that are sensitive for further transformation.

\subsubsection{Candidate Code}
\system scans the source program and employs static analysis tools, such as \tool{Python-AST} and \tool{JavaParser}, to generate the Abstract Syntax Tree (AST). 
As outlined in Section~\ref{sec:back}, TEEs operate within constrained resource environments. Increasing the scale and complexity of code executed within a TEE can introduce performance bottlenecks and security vulnerabilities, as noted by Liu et al.~\cite{LiuDT22jss}. 
Consequently, \system prioritizes retaining only leaf functions, which are located at the lowest level of the AST. 
These functions do not invoke other developer-defined functions but may utilize standard or trusted third-party libraries for executing complex operations. 
Their design is confined to specific logical tasks with arguments limited to base data types such as integers, arrays, and strings. 
Since these functions are self-contained and do not depend on others in the program, they serve as reliable foundational units. 
By focusing protection on leaf functions within TEEs, \system effectively reduces the volume of code requiring safeguarding, thereby enhancing operational efficiency and minimizing associated costs.


\subsubsection{Sensitive Function Identification}
For the functions, \system employs a LLM to identify those that contain sensitive operations.
\system uses multi-round chats, asking a series of prompts one by one.
Each prompt builds on the previous one, allowing the model to review its responses and correct prior errors.
Figure~\ref{box:sen_prompt} provides a visual overview of our prompts, with further elaboration below: green \textcolor{green!60!black}{\{Prompt\}} represents the prompt, red \textcolor{red!80!black}{\{Response\}} represents the response, orange \textcolor{orange}{\{Type\}} indicates the specific sensitive type, and cyan \textcolor{cyan}{\{Code\}} indicates the code.

\input{table/design/sen_prompt}
\begin{description}[leftmargin = 0pt]
    \item [Prompt 1:] \textbf{Code context.} 
    The initial prompt instructs the agent to check whether it uses cryptography or serialization operations.
    Furthermore, it specifies that the response should be either \dquote{Yes} or \dquote{No}, as this minimizes response time.

    \item [Prompt 2:] \textbf{Sensitive type.} 
    The second prompt identifies the type of operation involved.
    The agent will return specific types in a list, for example, \func{[Decryption, Verification]}.
    Otherwise, the agent will rectify the previous response as \dquote{No} upon realizing that the current code does not contain the corresponding operation. 
    
    \item [Prompt 3:] \textbf{Statements.}
    The final prompt requests the agent to enumerate the statements that provide evidence for sensitive judgments. 
    Similarly, the agent may identify any earlier errors in its analysis.
\end{description}
If, after these three prompts, the agent still determines that the function contains sensitive operations, \system will label the snippet as \dquote{sensitive}; \dquote{non-sensitive} otherwise.

\subsubsection{Test Inputs Generation}
After identifying sensitive functions, \system generates multiple test inputs for those functions to facilitate subsequent consistency validation.
The prompt states: \dquote{\textit{Please design different test inputs to call this function to maximize line coverage of the function.}}
For test inputs, \system then employs tools (e.g., \tool{JaCoCo} and \tool{Pytest-cov}) to assess their line coverage. 
If the line coverage does not achieve 100\%, the agent will add more test inputs to enhance coverage. 
If there is no improvement in coverage over three consecutive assessments, the agent will stop the process.

\subsection{Content Transformer}
For the identified sensitive functions, \system transforms them into native code.
To mitigate potential vulnerabilities within the TEE, such as buffer overflows, dangling pointers, and uninitialized memory, we consider \tool{Rust}, a \emph{memory-safe} native programming language~\cite{wang2019towards,Wan3427262}, as the target for transformation.
% The essence of this transformation lies in understanding the semantics of the code and restructuring it using Rust's syntax.

\subsubsection{Initial Transformation}\label{subsub:initial_transformation}
Initially, \system prompts the agent to analyze the code and utilizes few-shot learning techniques~\cite{snell2017prototypical} to produce an initial transformation:

\begin{description}[leftmargin = 0pt]
    \item [Prompt 1:] \textbf{What objective does this function accomplish?}
    The initial question prompts the agent to understand the objective of the code.

    \item [Prompt 2:] \textbf{Transform this code into Rust. 
    For example, \textcolor{cyan}{\{source code\}} to \textcolor{cyan}{\{rust code\}} with dependency \textcolor{cyan}{[A, B]}.}
    \system provides the agent with three transformation examples manually generated by ourselves, which the agent can use as a reference to generate the initial transformation.
\end{description}

\subsubsection{Compiler Check and Consistency Validation}
\label{subsubsec:check_validate}
\system first checks whether the code is executable for the initially transformed code.
It uses \tool{Cargo} (compiler for Rust) to compile the code.
If no issues are detected, \system proceeds to validate the functional consistency of the transformed code.
Specifically, Figure~\ref{fig:system:consistent} shows the process of this consistency validation.
\system compiles the transformed code into an executable file.
Subsequently, \system modifies the original code function with an external call pointing to the Rust executable file.
\system then executes all test inputs to verify whether the outputs of the original and transformed code are identical. 
Note that, since some cryptographic operations contain randomly generated variables, like seed generation and random keys, inconsistent outputs may occur even when the functionalities of the two codes remain equivalent.
Thus, for each pair of outputs, \system checks whether the output string qualifies as a valid \emph{Base64} encoding.
In such cases, \system determines they are consistent as long as they have the same length.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.75\linewidth]{fig/design/consistent.pdf}
    \caption{The Process of Consistency Verification. The term BIN refers to the executable file that has been compiled into the format suitable for the TEE.}
    \label{fig:system:consistent}
\end{figure}

If the code fails to compile or if the consistency verification does not succeed, \system carries out subsequent \tool{ReAct} actions to iteratively refine the code.

\subsubsection{Iterative Refinement}
This step requires the agent to modify the code to ensure that it successfully passes both the compiler check and the consistency validation.
\system uses the \tool{ReAct} strategy, which is an iterative process that involves the agent taking actions to refine the code.
Figure~\ref{box:react_prompt} illustrates example prompts utilized by \tool{ReAct}, where the blue \textcolor{blue!70!black}{{Thought/Action}} represents the thought process of \tool{ReAct}.
Following the \tool{ReAct} format, each response from the agent will contain its \emph{Thought}, along with the corresponding \emph{Action}. 
The agent will take actions to refine the code, with each action generating feedback referred to as an observation.

\input{table/design/react_prompt}

The action space defines the capacity of the LLM agent to refine the code. 
\system provides the following actions for adoption:
\begin{description}[leftmargin=0pt]
    \item [Action 1:] \textbf{Compiler check.}
    This action invokes the compiler (Cargo) to check the code.
    The compiler will return the check results, indicating the issues present within the code, such as the absence of packages and erroneous API calls.
    This information will serve as guidance on how to modify the code, ensuring that the transformed code is executable.
    
    \item [Action 2:] \textbf{Issues search.} 
    The check process of the compiler also generates an error index for specific issues (e.g., \dquote{Rust E0308}).
    The Rust official documentation includes descriptions of the index, along with example solutions.
    The agent can leverage this action to acquire information concerning the issue and its solutions.

    \item [Action 3:] \textbf{Code modification.}
    This action provides the agent with an interface to modify the code and write it into the Rust file.

    \item [Action 4:] \textbf{Dependency update.} 
    This action adds the corresponding Rust library to the Rust project, such as \func{use md5}.

    \item [Action 5:] \textbf{Consistency validation.} 
    When the code is executable (compiler check generates no issues), the agent will invoke this action to perform the consistency validation.
    The process of consistency validation is consistent with the description provided in Section~\ref{subsubsec:check_validate}.
    If all outputs are consistent, the agent will receive \dquote{consistent} feedback; 
    Otherwise, it will receive \dquote{inconsistent} feedback along with an indication of which test input is inconsistent.
\end{description}

The entire iterative process continues until the program is executable and passes consistency validation, or until the number of iterations reaches a threshold $TH$.
$TH$ is set to 20 in our evaluation, while in actual use, developers need to set it according to their LLM's capability.

\subsubsection{Platform Adaptation}
After several rounds of refinement, a functionally consistent and TEE-executable code is achieved.
As discussed in Section~\ref{sec:back}, the current TEE implementations are divided into VM-based (e.g., AMD SEV and Intel TDX) and Process-based (e.g., Intel SGX, OpenTEE, ARM TrustZone) approaches. 
The VM-based approach generally maintains compatibility with the standard library, while the Process-based approach requires certain adaptations. 
Consequently, for the \emph{Process-based} TEEs, \system modifies some statements to address the compatibility issues:

\begin{description}[leftmargin=0pt]
\item [Environment variables.] 
In TEEs, programs are launched with an empty environment.
Therefore, there are no existing environment variables.
If the code involves environment variables, \system reads these variables and hardcodes them directly into the code.

\item [Timer.] 
Some platforms, such as SGX and OpenTEE, do not support CPU timers.
If the code utilizes timers for only timing, \system directly deletes those statements.
If the code uses a timer as a seed, \system replaces it with a random number of the same bit length.
\end{description}

\subsection{Execution Linker}
When the sensitive function is successfully transformed, \system links the original program to it.
\system leverages different linking methods for different types of TEEs.

First, for both Process-based and VM-based types, to ensure secure interaction between TEE and the normal world, \system generates a key pair (private and public).
The private key (for decryption) is hardcoded in the transformed code, and the public key (for encryption) is hardcoded in the original code.
Note that, since the TEE is an isolated device memory, the hardcoded private key will not result in a leakage to the normal world.

Figure~\ref{fig:system:modify} illustrates the linking methods for different TEE types, where the green area indicates the code that needs to be added, while the blue area represents the unchanged code.
\begin{description}[leftmargin=0pt]
\item [Process-based TEEs] (Figure~\ref{subfig:process_based})\textbf{.} 
For the original code, \system replaces its statements with argument decryption and a local system call.
In the Rust code, the transformed code is encapsulated within a main function.
The invocation of sensitive functions in the original code use this local system call as the entry point for the TEE.
Upon entering the Rust environment, the arguments are decrypted using the private key and then passed to the transformed code for execution.

\item [VM-based TEEs] (Figure~\ref{subfig:vm_based})\textbf{.} 
For the original code, \system replaces its statements with argument decryption and network socket communication.
In the Rust code, similarly, the transformed code is encapsulated within a main function, which is designed to receive socket transmissions. 
Upon receiving the encrypted arguments, it decrypts them using the private key and then passes them to the transformed code for execution.
\end{description}

\begin{figure}[htb]
    \centering
    \subfloat[Process-based TEEs.]{
    \label{subfig:process_based}
    \includegraphics[width=0.98\linewidth]{fig/design/linker1.pdf}}

    \subfloat[VM-based TEEs.]{
    \label{subfig:vm_based}
    \includegraphics[width=0.98\linewidth]{fig/design/linker2.pdf}}
    \caption{Code modification in different TEEs.}
    \label{fig:system:modify}
\end{figure}
