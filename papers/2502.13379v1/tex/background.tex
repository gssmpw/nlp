\subsection{Trusted Execution Environments}
Software programs face various security risks, such as unauthorized access~\cite{9664230,han2023mytee,tkdeMaLLXJSM24,wang2023tee,ait2025tee} and data leakage~\cite{liu2022extending,zhang2020privacyscope}.
To provide stronger protection against such risks, hardware platforms and operating systems offer Trusted Execution Environments (TEEs), which are special areas in the device memory.
Logically, the memory in a device is separated into the TEE part and the normal world part.
Any computation within the TEE part is not accessible by the part of normal world, and thus the TEEs naturally provide security protection over many sensitive operations like algorithms, encryption keys, passwords, and personal identification information.
Developers are encouraged to run their programs involving such sensitive operations within the TEEs to minimize potential risks.
For instance, starting from version 6.0, the Android OS stores the encrypted biometric information (like fingerprints) of users and conducts the verification process within TEEs.
The normal world can only see the verification result and has no access to the actual verification process.
Thus, placing such sensitive operations inside TEEs can enhance the security and integrity of programs.

% TEE Type
Currently, TEEs have become an essential part of various hardware platforms with different architectures, including Intel SGX~\cite{Intel_SGX}, Intel TDX~\cite{Intel_TDX}, AMD SEV~\cite{AMD_SEV}, ARM TrustZone~\cite{ARM_TrustZone}, and OpenTEE~\cite{OpenTEE}.
Modern TEEs can be categorized into two types: Process-based, exemplified by Intel SGX~\cite{Intel_SGX}, and Virtual Machine-based (VM-based), represented by AMD SEV~\cite{AMD_SEV} and Intel TDX~\cite{Intel_TDX}.
Process-based TEEs create isolated device memory for processes to ensure secure execution of processes.
VM-based TEEs utilize virtualization technology to create a new independent operating system, which is isolated from the host system.

\subsection{Large Language Models \& ReAct Prompting}
% what is LLMs
Recent developments in natural language processing (NLP) have led to significant advancements in large language models (LLMs). 
These models have demonstrated remarkable improvements and have found extensive applications across various fields such as code generation~\cite{yan2023closer,zeng2022extensive}, document summary~\cite{mastropaolo2021empirical,geng2024large}, and security analysis~\cite{wu2023effective,ren2023misuse}.
LLMs have the capability to analyze the context of a given text and make corresponding decisions based on the requirements of the task.

However, complex tasks that require logical reasoning abilities, such as code generation, bug repair, and code transformation, continue to pose challenges for LLMs. 
These tasks necessitate that LLMs decompose the complex task into simpler sub-tasks, complete these sub-tasks after giving reasoning, and subsequently make a final decision. 
For instance, in code transformation tasks, LLMs must first understand the original code, then transform it into a new form, and finally validate the transformed code to ensure its consistency with the original code.
LLMs rely on static internal knowledge, which renders them incapable of assessing the quality of their transformation completion.

% ReAct prompting
\tool{ReAct}~\cite{yaoZYDSN023} is a prompting strategy that introduces external actions (e.g., accessing databases, performing computations, or utilizing search engines) to LLMs to enhance their reasoning capabilities.
\tool{ReAct} enables LLMs to interact with external tools to obtain additional information and validate their decisions.
It decomposes tasks into smaller sub-tasks and adapts various actions to acquire information relevant to or to complete these sub-tasks.
Therefore, LLMs can review their responses to the task and make appropriate adjustments accordingly.
Taking code transformation as an example, compiler messages can help LLMs understand whether the transformed code can be compiled, a basic requirement for successful transformation.

\subsection{Sensitive Operations}
% what is sensitive operation
%we refer to previous research related to TEEs~\cite{alam2025tee,li2024sedcpt,zhang2024no} and summarize the sensitive operations that are commonly placed within TEEs.
While developers may classify any operation they consider important as a sensitive operation, this article specifically focuses on operations that directly affect the integrity and security of programs. 
In particular, the sensitive operations include those that involve cryptographic operations and serialization:
\begin{description}[leftmargin = 0pt]
    \item [Cryptographic operation.]
    The purpose of cryptographic operations is to ensure the security, confidentiality, and integrity of critical data.
    Previous research indicates that cryptographic operations also pose risks of leakage~\cite{han2023credential,feng2022automated} and potential attacks~\cite{dziembowski2011leakage,arikan2024tee}.
    Protective methods~\cite{alam2025tee,li2024sedcpt} reveal that if these operations are conducted within TEEs, such vulnerabilities can be effectively mitigated.
    Consequently, we classify code that contains cryptographic operations as sensitive functions, specifically related to encryption, decryption, signature generation, verification, hashing, seed generation, and random number generation.
    
    \item [Serialization.]
    % Memory Sequence Leak
    Serialization also poses certain risks, as discussed in several studies~\cite{chen2020countermeasures,zoni2018comprehensive,graux2021preventing,chen2023tabby}, which can lead to information leakage and, in extreme cases, remote code execution~\cite{sayar2023depth}. 
    To address these vulnerabilities, placing the associated operations within a TEE could serve as an effective mitigation strategy.
\end{description}

\subsection{Motivation}
To avoid exposing more vulnerabilities, most TEEs only support low-level programming languages (native code) such as C and Rust. 
Such a requirement creates an accessibility barrier for the vast ecosystem of popular programming languages (e.g., Java and Python) developers. Supporting secure execution of these programs can expand the pool of developers capable of leveraging confidential computing while preserving existing functionality. 
The tight memory constraints (e.g., SGX's 128MB limit) demand accurate partitioning that places security-critical code rather than the full program into TEEs. 
This would enable developers to maximize security benefits without sacrificing application functionality or requiring manual code surgery.
However, adapting existing programs to leverage TEE protections is non-trivial. 
This process requires extensive domain knowledge and manual intervention.
Additionally, the APIs and system calls available in TEEs may differ from those in the normal world, requiring modifications to execute correctly in TEEs.
Besides, the current practice of porting programs to TEEs is mainly a human-in-the-loop process that requires substantial effort in manual intervention. 
This motivates us to propose \system, an approach that leverages Large Language Models (LLMs) to automatically identify, partition, and transform sensitive functions, facilitating their integration into TEEs with minimal manual effort.
