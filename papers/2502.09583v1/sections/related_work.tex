\section{Related Work}\label{sec:related_work}

\textbf{Human-AI Collaboration and Assistance}.
Recent years have seen growing interest in systems that effectively combine human and AI capabilities \citep{wu2022ai, pflanzer2023ethics,fragiadakis2024evaluating,vats2024survey}. A central challenge in this domain is designing human-in-the-loop systems that strategically leverage human expertise while minimizing intervention costs \citep{10.5555/3237383.3238074, nguyen2021learning}. \citet{reddy2018shared} developed shared autonomy frameworks in robotics that balance user preferences with autonomous capabilities, while \citet{retzlaff2024human} demonstrated the importance of AI systems signaling uncertainty and requesting assistance in reinforcement learning (RL) settings.

Closest to our work are approaches that enable agents to request human assistance. \citet{trinh2024getting} made early contributions to studying yield-or-control scenarios in human-AI collaboration, laying valuable groundwork in this space. Building on their insights, our work provides formal problem definitions, novel validation approaches, and extensive empirical evaluation across multiple environments. \citet{nguyen-daume-iii-2019-help} and \citet{Nguyen_2019_CVPR} investigated agents that request step-by-step instructions for navigation tasks, while \citet{da2020uncertainty} and \citet{singh2022ask4help} studied action-state queries. \citet{xie2022ask} proposed proactive interventions using reversibility labeling.
\citet{nguyen2021learning} extended these ideas with hierarchical RL for structured information-seeking.
Many recent papers \citep{shi2022learning,singh2022ask4help,liu2022asking,knowno2023} adopt similar interactive settings.
While the agent in these frameworks only has the option of yielding control to experts, our work considers a more expressive class of coordination policies that can also request back control from experts. 
% However, unlike these works that focus on \textit{how} to assist through granular instructions or targeted queries, \ourMethod addresses the orthogonal problem of \textit{when} to fully delegate control-a critical requirement in safety-critical domains where partial assistance is insufficient. 
% \ben{Hmm Khanh doesn't some of your earlier work also involve deciding when to ask to help?} \mohamad{I beleive they're cited already.} 
Moreover, our setting uniquely combines multi-agent coordination with OOD generalization challenges. Our \ourMethod-Bench establishes the first testbed for this problem, facilitating extensive, systematic comparison of various approaches and future development of generalizable solutions. 



% \textbf{Learning to Query External Knowledge}.
% A parallel research direction explores how agents can learn to query external knowledge sources, particularly through language. \citet{liu2022asking} proposed the AFK framework where agents generate natural language queries to gather task-relevant information from an oracle. Similarly, \citet{knowno2023} developed uncertainty-driven approaches for triggering knowledge queries. While these works focus on gathering information to enhance autonomous decision-making, our setting studies the more fundamental question of when to fully defer decisions to an expert.

% \textbf{Adaptation to Distribution Shift}.
% \khanh{perhaps this section should just compare with standard RL+OOD work that only features environmental changes and without humans. e.g., procgen}
% Our work introduces a novel challenge in OOD generalization, as the distribution shift is caused by both environmental changes and the novel presence of the expert \citep{danesh2021out, haider2023out, yang2024generalized, paudel2022learning}\khanh{why cite these papers here? do they introduce similar settings where the introduction of humans cause distribution shift. if not, make a new sentence to cite them with a different statement}. This connects to recent work on zero-shot adaptation \citep{huang2022inner} and contextual MDPs with external information sources \citep{azran2024contextual}\khanh{do these works consider ood generalization?}. However, existing approaches typically assume access to context descriptors of the shift.\khanh{what is context descriptors? use a more understandable term?} Our setting is more challenging as the novice policy must learn to coordinate with an expert whose decision-making process and internal representations are unobservable.


\textbf{Adaptation to Environmental Distribution Shifts}.
Previous work in OOD generalization has primarily addressed distribution shifts caused by dynamic environmental changes \citep{danesh2021out, liu2021towards, paudel2022learning, haider2023out, yang2024generalized, nasvytis2024rethinking}. However, these approaches assume that such shifts arise solely from the environment's stochastic dynamics or system noise. In contrast, our setting is more challenging because the novice policy must learn to coordinate with an expert whose decision-making process remains unobserved prior to inference, and whose novel presence—absent during training—induces additional distributional shifts.











\textbf{Expert Behavior Understanding}.
While not our primary focus, our work relates to research on inferring expert mental models. Recent work in text-based games has explored building external knowledge representations through knowledge graphs \citep{adhikari2020learning, ammanabrolu2020graph} or language models \citep{safavi2021relational}. However, these approaches focus on static environmental knowledge rather than dynamic expert behavior. 
%Parallel work on querying external knowledge \citep{liu2022asking, knowno2023} develops uncertainty-driven approaches for triggering information queries, but focuses on enhancing autonomous decisions rather than studying fundamental delegation tradeoffs.
% \khanh{i don't these two papers really model expert cognition or behavior. this paper is relevant: https://arxiv.org/pdf/2005.00728}
Closer to our goal, \citet{roman-roman-etal-2020-rmm} model recursive mental reasoning for human-agent dialogue, but their work targets collaborative question generation rather than delegation tradeoffs in decision-making.


% Our work advances this literature by introducing a more challenging and practical framework for expert-novice coordination. Unlike prior work that assumes full observability of expert behavior or requires extensive guidance, we study how agents can learn to coordinate with experts whose decision-making processes are unobserved, while minimizing the expert's cognitive burden. Our proposed \ourMethod framework provides a principled approach to this fundamental coordination problem. 
% \khanh{maybe don't say much here, as we have said the modeling expert is not the main focus. just saying these methods may be relevant to future development of solutions to YRC}
While prior work often assumes full observability of expert behavior or relies on extensive guidance, we focus on how agents can coordinate with experts whose decision-making processes remain unobserved, reducing the expert's cognitive burden. Although expert modeling is not our primary focus, these methods may inform future \ourMethod solutions. Our proposed \ourMethod framework thus offers a principled approach to this coordination challenge.

