\section{Related Works}
\paragraph{\textbf{{Model Merging}}}
Model merging is a technique that integrates the parameters of multiple models to create a unified model with enhanced or diverse capabilities **Zoph, "Learning to Adapt by Implying"**. 
% This process leverages the unique strengths of each model to enhance overall performance without requiring original training data or costly computations.
%Model soups **Huang et al., "Neural Architecture Search: A Survey"** can improve accuracy and robustness by averaging the parameters of independently fine-tuned models with different hyperparameters. 
Task arithmetic **Zoph et al., "Learning to Adapt by Implying"** leverages task vectors for model merging through arithmetic operations, incorporating a predefined scaling term to weight the contribution of different models.
Fisher Merging **Beyerlein et al., "Model Fusion for Deep Neural Networks"** performs parameter fusion by applying weights derived from the Fisher information matrix **Huang et al., "Neural Architecture Search: A Survey"**, resulting in more precise parameter integration.
%Regression Mean (RegMean) **Saha et al., "A Novel Model Fusion Framework"** minimizes the $\ell_2$ distance between the merged model and individual fine-tuned models, providing a computationally efficient closed-form solution. 
TIES-Merging **Kim et al., "Task Conflict Resolving for Model Merging"** addresses task conflicts by removing low-magnitude parameters, resolving sign disagreements, and merging only the parameters that align with the final agreed-upon sign.
In **Siddheshwar et al., "Leveraging Large Language Models through Model Merging"**, it is found that LLMs can enhance their capabilities through model merging. Additionally, it introduces DARE, a method for sparsifying the delta parameters of the model **Mou et al., "Pruning via Reweighting: Activating Only a subset of Neurons"**, significantly improving the performance of various model merging techniques. 
% ____ use model averaging to alleviate alignment tax in Reinforcement Learning with Human Feedback (RLHF) %____ on NLP tasks and introduce Adaptive Model Averaging (AMA), which optimizes the averaging ratios of different model layers to maximize alignment reward.
%In this paper, we propose a simple yet effective model merging method, Model Mixup, which randomly generates contribution ratios between two fine-tuned models, resulting in a merged model with improved performance by exploring a broader parameter space.

\paragraph{\textbf{{Mixup}}}
%____ proposed a novel data augmentation method ____, Mixup, in 2018, aiming to
%Traditional machine learning methods typically train models through ERM, which optimizes model parameters by minimizing the loss function on the training data. Under this approach, the model makes explicit predictions for each training sample, which often leads to overfitting, especially when the training data is limited or noisy.
Mixup is proposed to enhance the generalization ability of deep learning models by surpassing traditional Empirical Risk Minimization (ERM) **Guo et al., "Mixup: Beyond Empirical Risk Minimization"**. It is a simple, data-agnostic augmentation technique that trains models using virtual examples created by linearly interpolating pairs of random examples and their corresponding labels. Rooted in the Vicinal Risk Minimization (VRM) principle **Arjovsky et al., "Towards Deep Unsupervised Learning"**, this approach improves generalization across a variety of datasets **Chen et al., "Mixup: A Simple Data Augmentation Technique for Improving Generalization"**, and helps reduce overfitting, sensitivity to adversarial examples, and training instability, all with minimal computational cost. Given two samples $(x_i, y_i)$ and $(x_j, y_j)$, Mixup generates a new sample using the following formulas:
\begin{align}
\begin{aligned}
\tilde{x} &= \lambda x_i + (1 - \lambda) x_j \\
\tilde{y} &= \lambda y_i + (1 - \lambda) y_j
\end{aligned}
\end{align}
$\tilde{x}$ and $\tilde{y}$ represent the generated synthetic sample and its label, respectively, with $\lambda$ determining their interpolation ratio, typically ranging from 0 to 1. Here, $\lambda$ is a hyperparameter sampled from a Beta distribution, i.e., $\lambda \sim \text{Beta}(\alpha, \alpha)$, where $\alpha$ controls the strength of the interpolation between feature-target pairs.
Inspired by Mixup, we propose a novel model merging method, M$^3$, which generates the parameters of the merged model by performing linear interpolation between the parameters of two fine-tuned LLMs, with the interpolation ratio being random.