\appendix

\section{Proofs}
\label{sec:proof}

\begin{definition}{\rm (R\'{e}nyi differential privacy~\citep{renyi})} A randomized mechanism $\gM : \gD \rightarrow \gR$ over domain $\gD$ and
range $\gR$ satisfies $(\alpha, \epsilon)$-RDP if for any two adjacent $d, d' \in D$: $\gD_\alpha(\gM(d)|\gM(d')) \leq \epsilon$, 
where $D_\alpha$ denotes the R\'{e}nyi divergence of order $\alpha$.
\end{definition}

RDP can be converted to DP. If an mechanism satisfies $(\alpha, \epsilon)$-RDP, it also satisfies $(\epsilon + \frac{\log 1/\delta}{\alpha - 1}, \delta)$-DP~\citep{renyi}.

Notably, Gaussian mechanism can provide RDP. Specifically, for function $f$ with sensitivity $\Delta f = \max_{d,d'} \|f(d)-f(d') \|_2$, releasing $f(d) + \gN(0, \sigma^2)$ satisfies $(\alpha, \frac{\alpha \Delta f}{2\sigma^2})$-RDP~\citep{renyi-gm}.

Now, we prove Theorem~\ref{the:main}. Recall that Algorithm~\ref{alg:rapid} computes the per-sample gradient $\rvg(\rvx)$ and clips it to bound its influence $\tilde{\rvg}(\rvx) \gets \rvg(\rvx) / \max(1, \frac{\|\rvg(\rvx)\|}{C})$. It then computes the per-batch gradient 
$\rvg(\gB) \leftarrow \frac{1}{B} \sum_{\rvx \in \gB} \tilde{\rvg}(\rvx)$ and applies Gaussian noise:
$\tilde{\rvg}(\gB) \gets \rvg(\gB)  + \frac{C}{B} \gN(\mathbf{0}, \sigma^2 \mathbf{I})$.
\begin{proof}
Consider two adjacent mini-batches $\gB$ and $\gB'$ that differ by one sample $\rvx^-/\rvx^+$:
$ \gB' = \gB  \setminus  \{\rvx^-\} \cup \{\rvx^+\}$. We bound the difference of their batch-level gradients as follows: 
\begin{equation}
\begin{split}
\| \rvg(\gB)  - \rvg(\gB')  \|_2  & =  
\| \frac{1}{B} \sum_{\rvx \in \gB} \tilde{\rvg}(\rvx) - \frac{1}{B} \sum_{\rvx \in \gB'} \tilde{\rvg}(\rvx)\|_2
\\
& = \| \frac{1}{B}\tilde{g}(\rvx^-) -  \frac{1}{B}\tilde{g}(\rvx^+) \|_2 \\
& = \frac{1}{B} \sqrt{ 
\| \tilde{g}(\rvx^-) \|^2_2  + \| \tilde{g}(\rvx^+) \|^2_2 - 2 \tilde{g}^T(\rvx^-) \tilde{g}(\rvx^+)
}\\
& \leq \frac{1}{B} \sqrt{C^2 + C^2 + 2C^2} \\
& = \frac{2C}{B}
\end{split}
\end{equation}
where we use the fact that $\tilde{g}(\rvx^-)$
and $\tilde{g}(\rvx^+)$ are bounded by $C$ and the Cauchy-Schwarz inequality.

Thus, the sensitivity of $\rg(\gB)$ is $\frac{2C}{B}$. Following the RDP Gaussian mechanism, releasing the sanitized batch-level gradient $\tilde{g}(\gB)$ provides $(\alpha, \frac{2\alpha}{\sigma^2})$-RDP, corresponding to 
$(\frac{2\alpha}{\sigma^2} + \frac{\log 1/\delta}{ \alpha -1}, \delta)$-DP.
\end{proof}



\section{Experimental Setting}
\label{sec:setting}

Table~\ref{table:setting} summarizes the setting of public and private datasets in our experiments.

\begin{table}[ht!]\small
\centering
\renewcommand{\arraystretch}{1.2}
\begin{tabular}{c|c|l}
\multicolumn{2}{c|}{Public dataset $\gD^\mathrm{pub}$} & \multirow{2}{*}{Private dataset $\gD^\mathrm{prv}$} \\
\cline{1-2}
Pre-training ($\gD^\mathrm{pub}_\mathrm{pre}$ & Trajectory knowledge base $\gD^\mathrm{pub}_\mathrm{ref}$ &  \\
 \hline
 EMNIST (50K) & EMNIST (10K) &  MNIST \\
 ImageNet32 (1.2M)  &  ImageNet32 (70K)~\citep{darlow2018cinic}   & CIFAR10  \\
 FFHQ32 (60K)&FFHQ32 (10K)  & CelebA32\\
 FFHQ64 (60K)& FFHQ64 (10K) & CelebA64 \\
\end{tabular}
\caption{Setting of public/private datasets in experiments. \label{table:setting}}
\end{table}

Table~\ref{tab:autoencoder} lists the default parameter setting for training the autoencoder in the latent diffusion model under different settings, while Table~\ref{tab:pub_diff} summarizes the default parameter setting for training the diffusion model.

\begin{table}\small
\centering
\renewcommand{\arraystretch}{1.2}
\setlength{\tabcolsep}{1pt}
\begin{tabular}{r|c|c|c|c}
& EMNIST$\rightarrow$MNIST & ImageNet$\rightarrow$CIFAR10 & FFHQ32$\rightarrow$CelebA32 & FFHQ64$\rightarrow$CelebA64 \\ \hline
Input size & 32$\times$32$\times$3 & 32$\times$32$\times$3 & 32$\times$32$\times$3 & 64$\times$64$\times$3 \\ 
$z$-shape & $4 \times 4 \times 3$ & $16 \times 16 \times 3$ & $16 \times 16 \times 3$ & $64 \times 64 \times 3$ \\ 
Channels & 128 & 128 & 128 & 192 \\ 
Channel multiplier & $[1,2,3,5]$ & $[1,2]$ & $[1,2]$ & $[1,2]$ \\ 
Attention resolutions & $[32,16,8]$ & $[16,8]$ & $[16,8]$ & $[16,8]$ \\
\# ResBlocks & 2 & 2 & 2 & 2 \\ 
Batch size & 64 & 64 & 64 & 64 \\ 
\end{tabular}
\caption{Hyper-parameters for training autoencoders under different settings.}
\label{tab:autoencoder}
\end{table}

\begin{table}\small
\centering
\renewcommand{\arraystretch}{1.2}
\setlength{\tabcolsep}{1pt}
\begin{tabular}{r|c|c|c|c}
& EMNIST$\rightarrow$MNIST & ImageNet$\rightarrow$CIFAR10 & FFHQ32$\rightarrow$CelebA32 & FFHQ64$\rightarrow$CelebA64 \\ \hline
Input size & 32$\times$32$\times$3 & 32$\times$32$\times$3 & 32$\times$32$\times$3 & 64$\times$64$\times$3 \\ 
$z$-shape & $4 \times 4 \times 3$ & $16 \times 16 \times 3$ & $16 \times 16 \times 3$ & $32 \times 32 \times 3$ \\ 
\# Channels & 64 & 128 & 192 & 192 \\ 
Channel multiplier & $[1,2]$ & $[1,2,2,4]$ & $[1,2,4]$ & $[1,2,4]$ \\ 
Attention resolutions & $[1,2]$ & $[1,2,4]$ & $[1,2,4]$ & $[1,2,4]$ \\ 
\# ResBlocks & 1 & 2 & 2 & 2 \\ 
\# Heads & 2 & 8 & 8 & 8 \\ 
Batch size & 64 & 64 & 64 & 32 \\ 
Spatial transformer & True & True & False & False \\ 
Cond\_stage\_key & class\_label & class\_label & class\_label & class\_label \\ 
Conditioning\_key & crossattn & crossattn & crossattn & crossattn \\ 
\# Classes & 26 & 1000 & 1000 & 1000 \\ 
Embedding dimensions & 5 & 512 & 512 & 512 \\ 
Transformer depth & 1 & 2 & 2 & 2 \\ 
\end{tabular}
\caption{Hyper-parameters for diffusion models under different settings.}
\label{tab:pub_diff}
\end{table}

\section{Additional Results}
\label{sec:additional}

\subsection{Qualitative Comparison}

Figure~\ref{fig:CelebA32} illustrates random samples synthesized by \system and baselines under the setting of FFHQ32$\rightarrow$CelebA32 (with $\epsilon = 10$).

\begin{figure}
    \centering
    \includegraphics[width=0.95\textwidth]{figs/celeba32.pdf}
    \caption{Random samples synthesized by \system and baselines trained under the FFHQ32$\rightarrow$CelebA32 setting (with $\epsilon = 10$).}
    \label{fig:CelebA32}
\end{figure}


\subsection{Dissimilar Public/Private Data}

To evaluate \system's robustness to the distributional shift between public and private data, we conduct additional experiments to evaluate \system's performance when using dissimilar public/private datasets. Specifically, we use ImageNet32 as the public dataset with added Gaussian noise $\mathcal{N}(0, 0.1)$ to degrade its quality. For the private dataset, we use VOC2005~\citep{voc} (resized to 32$\times$32), a dataset used for object detection challenges in 2005, which significantly differs from ImageNet32 and contains only about 1K images. We apply \system in this challenging setting, with results shown in Table~\ref{tab:voc}. Notably, \system outperforms baselines (e.g., \dpldm) in terms of FID scores across varying $\epsilon$, indicating its robustness to dissimilar public/private datasets.

\begin{table}[!ht]\small
\renewcommand{\arraystretch}{1.2}
\centering
\begin{tabular}{c|c|c|c|c}
Privacy ($\epsilon)$ & \dpldm & \dpsda & {\sc PrivImage} & \system \\
\hline
1  &  164.85 & 142.20 & 139.07 & 93.17 \\
10  & 147.86 & 130.42 & 123.89  & 82.56  \\
\end{tabular}
\caption{Performance of \system and baselines (measured by FID scores) in the ImageNet32$\rightarrow$VOC2005 case. \label{tab:voc}}
\end{table}

Moreover, we compare \system's performance (without DP) to direct training on the VOC2005 dataset. \system improves the FID score from 77.83 to 54.60, highlighting its ability to effectively leverage the public data even when it differs substantially from the private data.

\subsection{Additional Baselines}

We further compare \system with more recent work on DP diffusion models.
\dpsda~\citep{dpsda} synthesizes a dataset similar to the private data by iteratively querying commercial image generation APIs (e.g., DALL-E 2) in a DP manner. For fair comparison with \system, instead of using commercial APIs trained on vast datasets (hundreds of millions of images), following the setting of~\cite{privimage} that replicates \dpsda's results, we use ImageNet32 for pre-training the public model (also as the query API for \dpsda) and CIFAR10 as the private dataset.


\begin{table}[!ht]\small
\renewcommand{\arraystretch}{1.2}
\centering

\begin{tabular}{c|c|c|c|c}
\multirow{2}{*}{Privacy ($\epsilon)$} & \multicolumn{2}{c|}{Model Size = 90M} & \multicolumn{2}{c}{Model Size = 337M} \\
\cline{2-5}
& \dpsda & \system & \dpsda & \system \\
\hline
1  &  113.6 & 63.2 &  89.1 &   66.5  \\
10  & 60.9 & 25.4 & 43.8  & 29.0 \\
\end{tabular}
\caption{Performance of \dpsda and \system (measured by FID scores) in the ImageNet32$\rightarrow$CIFAR10 case. \label{tab:dpsda}}
\end{table}

Note \system and \dpsda represent two distinct approaches to training DP diffusion models, with the pre-trained model size affecting their performance differently.


For \dpsda, which uses DP evolution rather than DP training to synthesize data, larger pre-trained models tend to lead to better performance. This is demonstrated in \dpsda's ablation study~\citep{dpsda}, where increasing the model size from 100M to 270M parameters improves results by enhancing the quality of selected data.
In contrast, methods involving DP training (such as \dpdm, \dpldm, {\sc PrivImage}, and \system) may not benefit from heavily over-parameterized models, as shown in~\citep{dockhorn2022differentially}. This is because the $\ell_2$-norm noise added in DP-SGD typically grows linearly with the number of parameters.

To empirically evaluate how model complexity affects different approaches, we conduct experiments varying the size of the pre-trained model from 90M to 337M parameters (by increasing the latent diffusion model's architecture from 128 to 192 channels and expanding its residual blocks from 2 to 4).
Table~\ref{tab:dpsda} compares the performance (measured by FID scores) of \dpsda and \system across different pre-trained model sizes. As model complexity increases, \dpsda achieves better FID scores, while \system shows only marginal performance degradation. Notably, when using the same public dataset and pre-trained model, \system consistently outperforms \dpsda, suggesting that it is more effective at leveraging public data under DP constraints.

{\sc PrivImage}~\citep{privimage} uses the fine-tuning approach, querying the private data distribution to select semantically similar public samples for pretraining, followed by DP-SGD fine-tuning on the private data. The table below compares \system and {\sc PrivImage}'s performance across different $\epsilon$ values on CIFAR10 and CelebA64.


\begin{table}[!ht]\small
\renewcommand{\arraystretch}{1.2}
\centering

\begin{tabular}{c|c|c|c|c}
\multirow{2}{*}{Privacy ($\epsilon)$} & \multicolumn{2}{c|}{CIFAR10} & 
\multicolumn{2}{c}{CelebA64}\\
\cline{2-5}
&{\sc PrivImage} & \system & {\sc PrivImage} & \system \\
\hline
1  &  29.8 & 63.2 &  71.4 & 60.5 \\
10  & 27.6 & 25.4 &  49.3 & 37.3 \\
\end{tabular}
\caption{Performance comparison of {\sc PrivImage} and \system (measured by FID scores). \label{tab:privimage}}
\end{table}

Notably, \system outperforms {\sc PrivImage} in most scenarios, with one exception: CIFAR10 under $\epsilon = 1$. This likely occurs because {\sc PrivImage} selects public data similar to the private data for pre-training. With clearly structured private data (for instance, CIFAR10 contains 10 distinct classes), using a targeted subset rather than all the public data tends to improve DP fine-tuning, especially under strict privacy budgets. However, this advantage may diminish with less structured private data (e.g., CelebA64). We consider leveraging the {\sc PrivImage}'s selective data approach to enhance \system as our ongoing research.





\subsection{Impact of Retrieval-Augmented Training}

\system can integrate with existing methods for training DP diffusion models since it is agnostic to model training, though its neighbor retrieval operates on latents, making it compatible only with latent diffusion models. To measure the impact of \system, we use a latent diffusion model as the backbone model for both \dpldm and \dpdm, evaluating their performance with and without RAPID. Table~\ref{tab:rgt} shows results on MNIST and CIFAR10 at $\epsilon = 10$. The substantial FID score improvement demonstrates the effectiveness of retrieval-augmented training.

\begin{table}[!ht]\small
\renewcommand{\arraystretch}{1.2}
\centering

\begin{tabular}{c|c|c|c|c}
\multirow{2}{*}{Dataset} & \multicolumn{2}{c|}{\dpdm} & 
\multicolumn{2}{c}{\dpldm}\\
\cline{2-5}
& w/o & w/ & w/o & w/ \\
\hline
MNIST  &42.9 & 25.4 & 27.2 & 14.1\\
CIFAR10  & 82.2 & 54.1 & 33.3 & 25.4\\
\end{tabular}
\caption{Impact of retrieval-augmented training on existing methods ($\epsilon = 10$). \label{tab:rgt}}
\end{table}

\subsection{Knowledge Base Generation}

While prior work on retrieval augmented generation (e.g., {\sc ReDi}~\cite{zhang2023redi}) requires all the trajectories to share the same latent, building the knowledge base needs to iteratively sample tens of thousands of trajectories from a pre-trained diffusion model (e.g., Stable Diffusion), which is highly expensive. For instance, on a workstation running one Nvidia RTX 6000 GPU, {\sc ReDi} requires over 8 hours to build a 10K-sample knowledge base.

\begin{table}[!ht]\small
\renewcommand{\arraystretch}{1.2}
\centering

\begin{tabular}{c|c|c|c|c|c|c|c}
Knowledge Base Size & 10K      &    20K      &  30K  &        40K &       50K    &     60K    &        70K\\
\hline
\system &  2.10s  &    4.17s  &   6.12s    &  8.23s   &  10.33s    &12.19s   &  14.48s\\
\end{tabular}
\caption{Runtime of \system for knowledge base construction. \label{tab:runtime}}
\end{table}

In comparison, \system eliminates this constraint, which allows it to directly compute the trajectory for each sample in the public dataset in a forward pass. Table~\ref{tab:runtime} shows \system's runtime efficiency for various knowledge base sizes, achieving orders of magnitude faster performance than prior work.

\subsection{Performance with Varying $\epsilon$}


\begin{figure}[!ht]
    \centering
    \includegraphics[width=1.0\linewidth]{figs/FID2.pdf}
      \caption{Performance of \system and baselines with varying $\epsilon$ on EMNIST$\rightarrow$MNIST: (a) FID scores and (b) downstream classification accuracy}
    \label{fig:epsilon-curve}
\end{figure}

Figure~\ref{fig:epsilon-curve} compares the performance (measured by FID scores and downstream classification accuracy) of \system and baselines (\dpdm,  \dpldm, \dpsda, and {\sc PrivImage}) in the case of EMNIST$\rightarrow$MNIST under varying $\epsilon$ settings. Observe that, under the same
privacy budget, \system considerably outperforms the baselines across most cases.

\section{Discussion}

\subsection{Comparison of \system and {\sc ReDi}}

{\sc ReDi}~\cite{zhang2023redi} also employs some strategies similar to \system such as constructing trajectory knowledge bases at early stages to bypass intermediate steps in the generation process. However, the two methods differ in several fundamental aspects. 

First, {\sc ReDi} employs RAG in the inference stage to improve generative efficiency, while \system integrates RAD into the DP training of diffusion models. Second, unlike {\sc ReDi} that builds its knowledge base by iteratively sampling tens of thousands of diffusion trajectories from a pre-trained latent diffusion model (e.g., Stable Diffusion), \system constructs the knowledge base by directly computing the diffusion trajectories via adding a scaled version of the initial latent to each sample in the public dataset, which greatly reduces the computational cost. Last, all the trajectories in {\sc ReDi} share the same initial latent. In contrast, the initial latents in  \system are randomly sampled, significantly improving the diversity of generated samples.

% To build its knowledge base for retrieval, {\sc ReDi} iteratively samples tens of thousands of diffusion trajectories from a pre-trained latent diffusion model (e.g., Stable Diffusion). This procedure alone requires over 10 hours of computation. Moreover, to ensure successful image retrieval, {\sc ReDi} must enforce all diffusion trajectories to share the same initial latent $\rvx_T$, because matching image pairs composed of over 80\% random noises is impractical. Consequently, to restore the full functionality of the diffusion model, {\sc ReDi} must spend over 10 hours building a new knowledge base to match each initial latent $\rvx_{T_i}$ every time it performs sampling.

% The fundamental difference between our work and {\sc ReDi} lies in recognizing the significant disparity in computational costs between the forward and reverse sampling processes of diffusion models. Instead of employing the computationally intensive reverse sampling process, \system constructs its knowledge base by directly computing the diffusion trajectories via adding a scaled version of the initial latent $\rvx_{T_i}$ to each public image in the dataset. This design reduces the time required to build the trajectory database from over ten hours to mere seconds, enabling dynamic computation of knowledge bases for each distinct $\rvx_{T_i}$ at runtime.



\subsection{Impact of Public/Private Data Similarity}

Like other DP diffusion model approaches (e.g., \dpdm, \dpldm, {\sc PrivImage}) and the broader pre-training/fine-tuning paradigm, \system assumes access to a diverse public dataset that captures a range of patterns. However, \system is more flexible: the public and private datasets need not closely match in distribution, as long as the public dataset contains similar high-level layouts. Here, we explore the possible explanations.


\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.85\textwidth]{figs/disentangle.pdf}
    \caption{Disentanglement effects of diffusion models.}
    \label{fig:disentangle}
\end{figure}


Existing studies~\citep{sdedit,zhang2023redi} establish that in diffusion models, early stages determine image layouts that can be shared across many generation trajectories, while later steps define specific details. \cite{disentangle} further discover diffusion models' disentanglement capability, allowing generation of images with different styles and attributes from the same intermediate sampling stage, as shown in Figure~\ref{fig:disentangle}. This disentanglement property enables \system to maintain robust performance even when public and private dataset distributions differ significantly, provided their high-level layouts remain similar.

