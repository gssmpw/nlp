
\begin{abstract} \label{abstract}
Differentially private diffusion models (DPDMs) harness the remarkable generative capabilities of diffusion models while enforcing differential privacy (DP) for sensitive data. However, existing DPDM training approaches often suffer from significant utility loss, large memory footprint, and expensive inference cost, impeding their practical uses.  
To overcome such limitations, we present \system\footnote{\system: \ul{R}etrieval-\ul{A}ugmented \ul{P}r\ul{I}vate \ul{D}iffusion model.}, a novel approach that integrates retrieval augmented generation (RAG) into DPDM training. Specifically, \system leverages available public data to build a knowledge base of sample trajectories; when training the diffusion model on private data, \system computes the early sampling steps as queries, retrieves similar trajectories from the knowledge base as surrogates, and focuses on training the later sampling steps in a differentially private manner. Extensive evaluation using benchmark datasets and models demonstrates that, with the same privacy guarantee, \system significantly outperforms state-of-the-art approaches by large margins in generative quality, memory footprint, and inference cost, suggesting that retrieval-augmented DP training represents a promising direction for developing future privacy-preserving generative models. The code is available at: \url{https://github.com/TanqiuJiang/RAPID}.
\end{abstract}
