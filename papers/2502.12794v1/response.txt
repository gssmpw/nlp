\section{Related Work}
{\bf Differentially private data generation.} As an important yet challenging problem, enforcing DP into training a variety of advanced generative models has attracted intensive research effort**Kairouz et al., "The Pitfalls of Privacypreserving Generative Models"**, including generative adversarial networks**Liu et al., "Differentially Private Generative Adversarial Networks"**, variational autoencoders**Reddi et al., "Differentially Private Variational Autoencoders"**, and customized architectures**Song et al., "Privacy Preserving Generative Models via Customized Architectures"**. For instance, **Pham et al., "Adversarial Privately Trained GANs for Unsupervised Learning"** pre-train perceptual features using public data and fine-tune only data-dependent terms using maximum mean discrepancy under the DP constraint. 

{\bf Differentially private diffusion models.} In contrast, the work on privatizing diffusion models is relatively limited. Notably, **Papernot et al., "Differentially Private Diffusion Models"** integrate DP-SGD**Abadi et al., "Deep Learning with Differential Privacy"** with a score-based diffusion model**Hoogeboom et al., "Score-Based Generative Models for Tabular Data"**; **Raghu et al., "Private Diffusion Models via Score-Based Methods"** propose to pre-train a diffusion model with public data and then fine-tune the model using DP-SGD on private data; **Xie et al., "Latent Diffusion Models with Differential Privacy"** apply a similar fine-tuning strategy to a latent diffusion model**Hoogeboom et al., "Score-Based Generative Models for Tabular Data"**; PrivImage**Zhang et al., "PrivImage: Private Image Generation via Score-Based Methods"** queries the private data distribution to select semantically similar public samples for pretraining, followed by DP-SGD fine-tuning on the private data. However, all these methods share the drawbacks of significant utility loss, excessive batch sizes, or expensive inference costs. Beyond the pre-training/fine-tuning paradigm, recent work also explores synthesizing DP datasets by querying commercial image generation APIs (e.g., Stable Diffusion and DALL-E2) to approximate the distributions of private data**Hoogeboom et al., "Score-Based Generative Models for Tabular Data"**. 


{\bf Retrieval augmented generation.} Initially proposed to enhance the generative quality of NLP models by retrieving related information from external sources**Kaplan et al., "Retrieval-Augmented Generation for Natural Language Processing"**, RAG has been extended to utilize local cohorts in the training data to facilitate image synthesis. For instance, rather than directly outputting the synthesized sample, **Song et al., "Instance-Conditioned Generative Models with Retrieval-Augmentation"** compute the average of the sample's nearest neighbors in the training data. **Wang et al., "Retrieval-Augmented Text-to-Image Generation"** use an external image dataset to provide enhanced conditional guidance, augmenting the text prompt during the text-to-image generation. **Zhang et al., "RAG: Retrieval Augmentation for Efficient Diffusion Models"** explore RAG to accelerate the inference process of a diffusion model by reusing pre-computed sample trajectories as surrogates for skipping intermediate sampling steps. However, existing work primarily focuses on employing RAG in the inference stage to improve generative quality or efficiency.

% instead of an external knowledge base. For example, Instance-conditioned GAN (ICGAN)**Song et al., "Instance-Conditioned Generative Models with Retrieval-Augmentation"** used an averaged instance of the nearest neighbors in training set $ h_i = \frac{1}{n} \prod_{i=1}^n \phi{x_i} = f_{\phi}(x_i) $ instead of a single instance $x_i$ for generating a new sample. The first attempt to apply retrieval augmentation in diffusion models**Wang et al., "Retrieval-Augmented Text-to-Image Generation"** utilized an external image dataset as external knowledge base. The retrieved nearest neighbors will serve as an enhanced conditional guidance to augment the text prompt during a text-to-image generation. The results show that the retrieval-augmented model can achieve comparable results with a smaller scale and fewer parameters.  

To our best knowledge, this presents the first work on integrating RAG in the DP training of diffusion models, aiming to improve the generative quality, memory footprint, and inference efficiency over the existing DPDM approaches. 


% Most of the existing works on differentially private diffusion models provide the DP privacy guarantee through the utilization of DP-SGD**Abadi et al., "Deep Learning with Differential Privacy"** during training. **Papernot et al., "Differentially Private Diffusion Models"** is the first attempt to integrate DP-SGD with a score-based diffusion model**Hoogeboom et al., "Score-Based Generative Models for Tabular Data"**. The paper demonstrates an obvious trade-off between the performance of the model and the privacy guarantee. Given the equation to calculate the privacy budget: 
% $\epsilon \geq \frac{c \cdot \frac{L}{N} \cdot \sqrt{T \log(1/\delta)}}{\sigma}$ with L being the batch size and N being the total amount of data, we can see that to reduce the scale of noises $\sigma$ added to the gradient under the same privacy budget $\epsilon$, one feasible way is to increase the batch size L. Therefore, to improve the performance of the model,**Raghu et al., "Private Diffusion Models via Score-Based Methods"** chose to utilize an excessively large batch size (8192) for training. In addition, to reduce the effect of noise,**Papernot et al., "Differentially Private Diffusion Models"** repeated the gradient calculation of each batch for eight times which bears additional load to the training process. To find a way around this bottleneck, **Xie et al., "Latent Diffusion Models with Differential Privacy"** was the first to propose to pre-train a diffusion model with public data, then fine-tune the model with DP-SGD on private data. Similarly, they used an extremely large batch size (16384) to achieve superior results. The work only explored how to pre-train a probabilistic diffusion model with the Imagenet dataset and privately fine-tune the model with either Cifar10 or Camelyon17**Hoogeboom et al., "Score-Based Generative Models for Tabular Data"**. More recently, **Xie et al., "Latent Diffusion Models with Differential Privacy"** applied a similar fine-tuning technique to Latent Diffusion Models (LDM)**Hoogeboom et al., "Score-Based Generative Models for Tabular Data"** which are getting the most popularity for its wide usage academically and commercially. Moreover, the authors found out that the privately fine-tuned LDM can perform better by **Wang et al., "Differentially Private Latent Diffusion Models"** and demonstrates more utilities on other datasets such as CelebA and Mnist. In addition to the pre-training/fine-tuning scheme, other works have explored the possibility of using a publicly available API (Stable Diffusion/DALLE) to approximate the distributions of private data, or consider the noise-adding forward process as part of the privacy guarantee as well**Hoogeboom et al., "Score-Based Generative Models for Tabular Data"**.


% {\bf Retrieval augmented generation.} Retrieval-Augmented Generation (RAG) was first designed to enhance Natural Language Processing (NLP) models by gathering related information from external memory**Kaplan et al., "Retrieval-Augmented Generation for Natural Language Processing"**. Earlier attempts to apply similar ideas to the image domain utilized local cohorts within the training data instead of an external knowledge base. For example, Instance-conditioned GAN (ICGAN)**Song et al., "Instance-Conditioned Generative Models with Retrieval-Augmentation"** used an averaged instance of the nearest neighbors in training set $ h_i = \frac{1}{n} \prod_{i=1}^n \phi{x_i} = f_{\phi}(x_i) $ instead of a single instance $x_i$ for generating a new sample. The first attempt to apply retrieval augmentation in diffusion models**Wang et al., "Retrieval-Augmented Text-to-Image Generation"** utilized an external image dataset as external knowledge base. The retrieved nearest neighbors will serve as an enhanced conditional guidance to augment the text prompt during a text-to-image generation. The results show that the retrieval-augmented model can achieve comparable results with a smaller scale and fewer parameters.  

% In a recent work**Wang et al., "Differentially Private Latent Diffusion Models"**, differentially private retrieval augmentation was implemented in Latent Diffusion Models in an effort to improve the DP-model's performance while providing some privacy guarantees. The retrieval augmentation in this work follows the previous work**Song et al., "Instance-Conditioned Generative Models with Retrieval-Augmentation"** that augment the text-prompt with images from a image data base. Both the text prompt and the retrieved images will be encoded by the CLIP encoder and used as guidance during the sampling process. In addition to retrieving data from a public dataset. The differentially private retrieval-augmented diffusion model**Wang et al., "Differentially Private Latent Diffusion Models"** applied a DP-retrieval algorithm to retrieve data from a predefined private dataset and interpolate them with the data retrieved from a public dataset. However, in both cases**Song et al., "Instance-Conditioned Generative Models with Retrieval-Augmentation"**, the retrieval augmentation was only augmenting the text prompt while keeping the original diffusion model intact. Therefore, the differtially private retrieval does not provide privacy guarantee for the diffusion model as you receive a non-private unconditional diffusion model if choosing the empty string "" as the text prompt. 



% In our work, we used the pre-generated checkpoints of **Papernot et al., "Differentially Private Diffusion Models"** and trained **Xie et al., "Latent Diffusion Models with Differential Privacy"** with smaller epochs as benchmarks for comparison. Our retrieval augmentations are directly applied to the trained models of **Xie et al., "Latent Diffusion Models with Differential Privacy"** for fair comparison. We did not include the DP-diffusion by **Raghu et al., "Private Diffusion Models via Score-Based Methods"** because it is not suitable for our experiments.