

\section{RAPID}

Next, we present \system, a novel approach for training differentially private diffusion models by leveraging retrieval-augmented generation.


\begin{figure}[!t]
    \centering
    \includegraphics[width=0.72\textwidth]{figs/NNsearch.pdf}
        \caption{Overall framework of \system.}
    \label{fig:NNflow}
\end{figure}

\subsection{Preliminaries}

A diffusion model consists of a forward diffusion process that converts original data $\rvx_0$ to its latent $\rvx_t$ (where $t$ denotes the timestep) via progressive noise addition and a reverse sampling process that starts from latent $\rvx_t$ and generates data $\rvx_0$ via sequential denoising steps. 

Take the denoising diffusion probabilistic model (DDPM)~\citep{ho2020denoising} as an example. Given $\rvx_0$ sampled from the real data distribution $q_\mathrm{data}$, the diffusion process is formulated as a Markov chain: 
\begin{equation}
\label{eq:sampling}
q(\rvx_t | \rvx_{t-1}) = \gN(\rvx_t ; \sqrt{1 - \beta_t}\rvx_{t-1}, \beta_t \mathbf{I}) 
\end{equation}
where $\{\beta_t\in (0,1)\}_{t=1}^T$ specifies the variance schedule. For sufficiently large $T$, the latent $\rvx_T$ approaches an isotropic Gaussian distribution. Starting from $p(\rvx_T) = \gN(\rvx_T; \bm{0}, \bm{\text{I}})$, the sampling process maps latent $\rvx_T$ to data $\rvx_0$ in $q_\mathrm{data}$ as a Markov chain with a learned Gaussian transition:
\begin{equation}
p_\theta(\rvx_{t-1} | \rvx_t) = \gN( \rvx_{t-1}; \bm{\mu}_\theta(\rvx_t, t), \bm{\Sigma}_\theta(\rvx_t, t)) 
\end{equation}
To train the diffusion model $\rveps_\theta(\rvx_t, t)$ that predicts the cumulative noise up to timestep $t$ for given latent $\rvx_t$, DDPM aligns the mean of the transition $p_\theta(\rvx_{t-1} | \rvx_t)$ with the posterior $q(\rvx_{t-1}| \rvx_t, \rvx_0)$: 
\begin{equation}
\label{eq:mean-align}
\min_\theta \E_{\rvx_0 \sim q_\mathrm{data}, t \sim \gU(1, T), \rveps \sim \gN(\mathbf{0},  \mathbf{I})} \| \rveps - \rveps_\theta(\sqrt{\bar{\alpha}_t} \rvx_0 + \sqrt{1-\bar{\alpha}_t}\rveps, t)  \|^2  \nonumber  \quad \text{where} \quad  \bar{\alpha}_t = \prod_{\tau=1}^t (1  - \beta_\tau)
\end{equation}
Once trained, starting from $\rvx_T \sim \gN(\mathbf{0}, \mathbf{I})$, the sampling process iteratively invokes $\rveps_\theta$:
\begin{equation}
\label{eq:sample}
\rvx_{t-1} = \rveps_\theta(\rvx_t, t),
\end{equation}
which generates the following trajectory $\{\rvx_T, \rvx_{T-1}, \ldots, \rvx_0\}$.

\subsection{Design of \system}

Prior work on training DPDMs~\citep{dockhorn2022differentially,ghalebikesabi2023differentially,lyu2023differentially} often applies DP-SGD~\citep{abadi2016deep} to fine-tune the entire sampling process using private data, resulting in significant utility loss and inference cost. However, it is known that, within a given sampling trajectory $\{\rvx_T, \rvx_{T-1}, \ldots, \rvx_0\}$, the early steps only determine the high-level image layout shared by many latents, while the later steps determine the details~\citep{sensitivity,sdedit}. Thus, instead of privatizing the end-to-end sampling process, by fully utilizing the public data, we may skip intermediate steps and focus on fine-tuning the later steps using private data.


Motivated by this idea, as illustrated in Figure~\ref{fig:NNflow}, \system first pre-trains a diffusion model $\rveps_\theta$ using the public data $\gD^\mathrm{pub}$. Further, \system builds a knowledge base $\gK\gB$ by calculating the diffusion trajectories of $\gD^\mathrm{pub}$. \system then fine-tunes $\rveps_\theta$ using the private data $\gD^\mathrm{prv}$ as follows. Corresponding to each input $\rvx \in \gD^\mathrm{prv}$, it generates its initial steps $\rvx_{T : k}$ in the sampling process, uses $\rvx_k$ (at timestep $k$) as a query to retrieve a similar trajectory $\hat{\rvx}_{T : 0}$ from $\gK\gB$, and resumes DP training the sampling process, starting from $\hat{\rvx}_v$ (at timestep $v$) of the retrieved trajectory, to reconstruct $\rvx$.
Intuitively, this RAG strategy skips the sampling process from timestep $k$ to $v$, thereby improving privacy saving, generative quality, and inference efficiency. Next, we elaborate on the implementation of \system's key components.



% We divide the sample trajectory from $\rvx_T$ to $\hat{\rvx}_0$  into three stages: i) early phase from $\rvx_T$ to $\hat{\rvx}_{T_q}$, ii) intermediate phase from $\hat{\rvx}_{T_q}$ to $\hat{\rvx}_{T_s}$, and iii) final phase from $\hat{\rvx}_{T_s}$ to from $\hat{\rvx}_{0}$.  


% \subsection{Trajectory Knowledge Base}
% Given a diffusion model $\rveps_\theta$ pre-trained on the public data $\gD^\mathrm{pub}$, we build a trajectory knowledge base $\gK\gB$ as follows. For each input $(\rvx, y) \in \gD^\mathrm{pub}$ where $\rvx$ is the input and $y$ is its guidance signal (e.g., its class label), we generate its latent at timestep $T$ as:
% \begin{equation}
% \label{eq:T}
% \rvx_T = \sqrt{\bar{\alpha}_T} \rvx + \sqrt{1 - \bar{\alpha}_T} \bm{\epsilon} \qquad 
% \bar{\alpha}_T = \prod_{t=1}^T (1 - \beta_t)
% \end{equation}
% where $\bm{\epsilon} \sim  \gN(\bm{0}, \bm{\text{I}})$ is a random Gaussian noise while the coefficient $\bar{\alpha}_T$ is determined by a pre-defined variance schedule $\{\beta_t\}_{t=1}^T$. 
% Starting from this initial noise vector $\rvx_T$, we apply the pre-trained diffusion model to iteratively reconstruct the original input as:
% \begin{equation}
% \label{eq:sample}
% \rvx_{t-1} = \rveps_\theta(\rvx_t, t, y),
% \end{equation}
% which generates the trajectory $\{\rvx_T, \rvx_{T-1}, \ldots, \rvx_0\}$. From this trajectory, we pick $\rvx_k$ as the key and $\rvx_v$ ($T >  k > v$) as the value and store the pair $(\rvx_k, \rvx_v)$ in the knowledge base $\gK\gB$.

% The entire diffusion trajectory is divided into 100 timesteps. We select the first 20 steps from the pre-set Gaussian vector $x_T$ as keys for searching similar trajectories. Then we need to store one more intermediate forward diffusion result $x_{t^*}$ where the model will resume the generation. In this work, we set $t^*$ as 30 in all of our experiments. Therefore, in total, our trajectory knowledge base comprises the set $\{x_{T-i}\}_{i=1}^{20} + x_{30}$ of the forward diffusion processes. 


\subsection{Building Trajectory Knowledge Base}

We divide the public data $\gD^\mathrm{pub}$ into two parts $\gD^\mathrm{pub}_\mathrm{pre}$ and $\gD^\mathrm{pub}_\mathrm{ref}$ to avoid overfitting, with $\gD^\mathrm{pub}_\mathrm{pre}$ to pre-train the diffusion model $\rveps_\theta$ and $\gD^\mathrm{pub}_\mathrm{ref}$ to
construct the trajectory knowledge base $\gK\gB$. 


\begin{algorithm}[!t]\small
\KwIn{reference data $\gD$, pre-trained diffusion model $\rveps_\theta$, timestep $k$}
\KwOut{latent feature extractor $h$}
\While{not converged yet}{
\ForEach{$\rvx \in \gD$}{
\tcp{\rm generate positive and negative pairs}
 generate $\tilde{\rvx}$, $\tilde{\rvx}^+$, and $\gN_\rvx^-$ with random augmentations\; 
\tcp{\rm generate latents at timestep $k$}
sample $\tilde{\rvx}_k$, $\tilde{\rvx}^+_k$, and $\tilde{\rvx}^-_k$ for $\tilde{\rvx}^- \in \gN_\rvx^-$ following \meq{eq:sample}\;
\tcp{\rm compute contrastive loss}
compute $\ell_\mathrm{CL}(\rvx)$ following \meq{eq:cl}\; 
\tcp{\rm update feature extractor}
update $h$ to minimize $\ell_\mathrm{CL}(\rvx)$\;
}
}
\Return $h$\;
\caption{Training latent feature extractor. \label{alg:extractor}}
\end{algorithm}



For each $\rvx \in \gD^\mathrm{pub}_\mathrm{ref}$, we construct its sampling trajectory by iteratively applying \meq{eq:sampling} to generate a sequence of latents $\{\rvx_1, \ldots, \rvx_T \}$, and store $(\rvx_k, \rvx_v)$ as a key-value pair ($k > v$) in $\gK\gB$. During RAG, 
%gradually apply Gaussian noises and receive a collection of noisy latents $\{\rvx_0,\rvx_1, \ldots, \rvx_{T-1}, \rvx_T\}$ as one of the stored trajectories in $\gK\gB$. To retrieve a neighboring trajectory from $\gK\gB$, 
we may sample a random latent $\rvx_T$ at timestep $T$ and generate its  early trajectory by iteratively invoking $\rveps_\theta$ (\meq{eq:sample}) until timestep $k$: $\{\rvx_T, \rvx_{T-1}, \ldots, \rvx_k\}$ and use $\rvx_k$ as a query to search for its nearest neighbors (in terms of $\ell_2$-norm) in $\gK\gB$.
%use it as a query. One straightforward approach to query $\gK\gB$ is to use $(\rvx_k, \rvx_v)$ as the key-value pair and directly apply similarity search on latents $\{\rvx_k\}$ for nearest neighbors with the lowest L2 distances. 
For simple datasets (e.g., MNIST), due to their distributional sparsity, this straightforward approach is effective as it is possible to enforce all the trajectories to share a fixed initial latent  $\rvx_T$~\citep{zhang2023redi}. However, for more complex datasets (e.g., CIFAR10), their distributional density necessitates allowing different trajectories to have distinct 
initial latents, making this approach much less effective. More importantly, enforcing the same initial latent severely limits the model's generative quality and diversity.  %or we must generate a new $\gK\gB$ at every start of the sampling process. 

%For example, our experiments show that, on CIFAR10, applying the search directly on different latents $\{\rvx_k\}$ (with $k$ close to $T$) tends to fetch almost the identical nearest neighbor with large areas of gray backgrounds. 


% to retrieve the neighbors with the lowest L2 distances. Specifically, for searching nearest neighbors with closest diffusion trajectories, Redi flattened and concatenated all latents of the first i steps in the diffusion trajectory as keys, and then found the nearest trajectories with the smallest Euclidean distances to the keys. 

% This simple yet effective searching approach works because they are matching the trajectories generated by the same model from the same starting point. When matching forward trajectories with the reverse de-noising steps from a diffusion model, the neighbor matching becomes much trickier. For simple image datasets such as MNIST~\citet{deng2012mnist}, the retrieved nearest concatenated trajectory usually fits the expected outcome because of the dataset's simplicity and the sparsity among the distribution of images of different classes. In contrast, the samples retrieved from the database are mostly identical when conducting the same experiment on more diverse datasets such as Cifar10~\citet{krizhevsky2009learning} and CelebA~\citet{liu2015faceattributes}. One possible reason is that, unlike the forward process where each part of the image gradually immerses into the Gaussian noise. The diffusion model focuses on generating the foundational layouts and the most significant features at the early stages. In other words, when a diffusion model $\epsilon_{\theta}$ tries to predict $\hat{x_0}$ from a very noisy image $x_{t}$ where t is close to T, the only thing the model can do is to provide its best guess on the general layouts and main features which are much easier to detect. Meanwhile, the model can hardly make any prediction to the background details based on a very noisy image. Therefore, to minimize the loss, the diffusion models are likely to provide the mean values of all the pixels that resemble the color grey. As a result, almost all of the nearest neighbor samples retrieved from Cifar10 or CelebA datasets have a large proportion of plain, grey backgrounds. 


\begin{wrapfigure}{r}{0.3\textwidth}
    \centering
    \vspace{5pt}
    \includegraphics[width=0.22\textwidth]{figs/feature.pdf}
    \caption{Contrastive learning of noise-augmented latents $\{\rvx_k\}$.}
    \label{fig:feature_extractor}
\end{wrapfigure}
Thus, instead of applying the similarity search on the latents $\{\rvx_k\}$ directly, we first extract their features (by applying a feature extractor $h$) and perform the search in their feature space. To this end, we first project $\rvx_k$ to the input space by applying one-step denoising on $\rvx_k$ using the pre-trained diffusion model $\rveps_\theta$, and then apply the feature extractor $h$ on the denoised $\rvx_k$ to extract its feature: $\rvz_k = h(\rveps_\theta(\rvx_k, k))$. For simplicity, we omit the one-step denoising in the following notations: $\rvz_k = h(\rvx_k)$.  

We employ contrastive learning~\citep{chen2020simple,chen2020improved} to train the feature extractor $h$. Intuitively, contrastive learning learns representations by aligning the features of the same input under various augmentations (e.g., random cropping) while separating the features of different inputs. In our current implementation, we extend the SimCLR~\citep{chen2020simple} framework, as illustrated in Figure~\ref{fig:feature_extractor}. Specifically, for each input $\rvx \in \gD^\mathrm{pub}_\mathrm{ref}$, a pair of its augmented views $(\tilde{\rvx}, \tilde{\rvx}^+)$ forms a ``positive'' pair, while a set of augmented views of other inputs $\gN_\rvx^-$ forms the ``negative'' samples. The contrastive loss is defined by the InfoNCE loss~\citep{oord2018representation}, which aims to maximize the similarity of positive pairs relative to that of negative pairs:
\begin{equation}
\label{eq:cl}
\ell_\mathrm{CL}(\rvx) = -  \log  \frac{\exp(\mathrm{sim}(h(\tilde{\rvx}_k), h(\tilde{\rvx}_k^+)) / \tau)}{\sum_{\tilde{\rvx}^- \in \gN_\rvx^-}  \exp(\mathrm{sim}(h(\tilde{\rvx}_k), h(\tilde{\rvx}_k^-))/\tau) + \exp(\mathrm{sim}(h(\tilde{\rvx}_k), h(\tilde{\rvx}_k^+)) / \tau)}
\end{equation}
where $\tilde{\rvx}_k$ denotes the sampled latent at timestep $k$ corresponding to $\tilde{\rvx}$ (similar for $\tilde{\rvx}_k^+$ and $\tilde{\rvx}_k^-$), $\mathrm{sim}$ is the similarity function (e.g., cosine similarity), and $\tau$ is the hyper-parameter of temperature. Algorithm~\ref{alg:extractor} sketches the training of the latent feature extractor. 
%Here, we randomly sample $\rvx$ from $\gD^\mathrm{pub}$ and $t$ from $[T, k]$.



After training the latent feature extractor $h$, we build the trajectory knowledge base $\gK\gB$. For each $\rvx \in \gD^\mathrm{pub}_\mathrm{ref}$, we sample its trajectory as $(\rvx_1, \rvx_{2}, \ldots, \rvx_T)$; we consider $\rvx_k$'s feature, $\rvz_k = h(\rvx_k)$, as the key and $\rvx_v$ as the value, and store the key-value pair $(\rvz_k, \rvx_v)$ into $\gK\gB$. 
%as illustrated in Figure~\ref{fig:NNflow}.


% After training the feature extractor $h$, we perform the nearest neighbor search in the feature space $\{\rvz_k\}$, which significantly improves the effectiveness of fetching semantically relevant trajectories (evaluation in \msec{sec:ablation}). 


% To resolve this issue, we propose to build a feature extractor that projects the noisy latents at the early stages of sampling into a feature space before searching for their nearest neighbors. The goal of this feature extractor is to search for similar features among highly noisy images. Similarly, ~\citet{deng2019arcface} extracted facial features from human face images by introducing intra and inter-class losses. Essentially, their model aimed to minimize the distances between images of the same class while maximizing the distances between images of different classes. This concept happens to coincide with the designs of contrastive learning models such as SimCLR~\citet{chen2020simple} and MOCO~\citet{chen2020improved}. Similarly, contrastive learning models adopt an InfoNCE~\citet{oord2018representation} loss function which treats the two augmentations of the same images as positive pairs from the same class and all other images as negative classes. In our work, we choose to adopt the contrastive learning strategy to train our feature extractor as demonstrated in Figure~\ref{fig:feature_extractor}:

% $\mathcal{L}_{feature} = -\sum_{i=1}^{N} \log \frac{\exp({sim}(z_i, z_{j(i)}) / \tau)}{\sum_{{k=1},{k \neq i}}^{2N} \exp({sim}(z_i, z_k) / \tau)}$

% where ${\exp({sim}(z_i, z_{j(i)}) / \tau)}$ represents the cosine similarities between the augmented pairs of the same image, and ${\sum_{{k=1},{k \neq i}}^{2N} \exp({sim}(z_i, z_k) / \tau)}$ represents the sum of the cosine similarities of all negative pairs. The only difference is that we randomly choose a timestep $t$ for adding a specific scale of Gaussian noises into the latent z and converting them into noisy latents $z_{t}^{*}$ before performing any data augmentation. 

% $\mathcal{L}_{{noisy}} = -\sum_{i=1}^{N} \log \frac{\exp({sim}(z_{i,t}^*, z_{j(i),t}^*) / \tau)}{\sum_{{k=1},{k \neq i}}^{2N}  \exp({sim}(z_{i,t}^*, z_{k,t}^*) / \tau)}$

% Through 40 epochs of contrastive learning, our feature extractor becomes capable of identifying features underlying the noisy latents, significantly reducing the issue of repetitive occurrence of the same latents during neighbor retrieval. 





% \begin{algorithm}[!ht]\small
% \KwIn{reference data $\gD$, pre-trained diffusion model $\rveps_\theta$, feature extractor $h$, timesteps $k, v$}
% \KwOut{trajectory knowledge base $\gK\gB$}
% $\gK\gB \gets \emptyset$\;
% \ForEach{$\rvx \in \gD$}{
% \tcp{generate latents at timesteps $k,q$}
% sample $\rvx_k$, $\rvx_v$ following \meq{eq:T} and \meq{eq:sample}\;
% \tcp{update knowledge base}
% add $(h(\rvx_k), \rvx_v)$ to $\gK\gB$\;
% }
% \Return $\gB$\;
% \caption{Building knowledge base. \label{alg:kb}}
% \end{algorithm}




\begin{algorithm}[!t]\small
\KwIn{private data $\gD^\mathrm{prv}$, pre-trained denoiser $\rveps_\theta$, feature extractor $h$, trajectory knowledge base $\gK\gB$, batch size $B$, timestep $k$, number of iterations $I$, gradient norm bound $C$, noise scale $\sigma$}
\KwOut{fine-tuned diffusion model $\rveps_\theta$}
\For{$i \in [I]$}{
sample a batch $\gB$ of size $B$ from $\gD^\mathrm{prv}$ via Poisson sampling\;
\ForEach{$\rvx \in \gB$}{
\tcp{\rm find nearest neighbor}
sample $\rvx_k$ following \meq{eq:sample}\;
find key $\hat{\rvz}_k$ closest to $h(\rvx_k)$ in $\gK\gB$\;
\tcp{\rm skip intermediate steps}
fetch value $\hat{\rvx}_v$ corresponding to $\hat{\rvz}_k$\;
compute gradient $\rvg(\rvx) \gets \nabla_\theta \ell_\mathrm{DM}(\rvx, \hat{\rvx}_v)$ following \meq{eq:diffloss}\;
\tcp{\rm clip gradient}
$\tilde{\rvg}(\rvx) \gets \rvg(\rvx) / \max(1, \frac{\|\rvg(\rvx)\|}{C})$\;
}
\tcp{\rm apply DP noise}
$\tilde{\rvg}(\gB) \gets \frac{1}{B} \sum_{\rvx \in \gB} \tilde{\rvg}(\rvx) + \frac{C}{B} \gN(\mathbf{0}, \sigma^2 \mathbf{I})$ \;
$\theta \gets \mathrm{Adam}(\theta,  \rev{\tilde{\rvg}}(\gB))$\;
}
\Return $\rveps_\theta$\;
\caption{\system. \label{alg:rapid}}
\end{algorithm}


\subsection{Training Differentially Private Diffusion Model}

Leveraging the trajectory knowledge base $\gK\gB$, we further train the denoiser $\rveps_\theta$ on private data $\gD^\mathrm{prv}$. Notably, we focus on training $\rveps_\theta$ from timestep $v$ to $0$, leading to the advantages of fully utilizing limited private data and reducing overall privacy costs. 



As outlined in Algorithm~\ref{alg:rapid}, at each iteration, we sample batch $\gB$ from $\gD^\mathrm{prv}$ using Poisson sampling for privacy amplification~\citep{renyi-gm}. For each input $\rvx \in \gB$, we \mct{i} sample its early trajectory $\rvx_k$ up to timestep $k$, \mct{ii} use its feature $\rvz_k = h(\rvx_k)$ as a query to find $\rvz_k$'s nearest neighbor $\hat{\rvz}_k$ in $\gK\gB$, \mct{iii}
reuse the value $\hat{\rvx}_v$ corresponding to $\hat{\rvz}_k$ in $\gK\gB$ as the starting point at timestep $v$, and \mct{iv} train $\rveps_\theta$ to reconstruct $\rvx$. In other words, $\rveps_\theta$ is fine-tuned to predict the random noise $(\rvx - \hat{\rvx}_v)$ at timestep $v$. 
To make the training differentially private, we extend DP-SGD~\citep{abadi2016deep} during updating $\rveps_\theta$. For each input $\rvx$ in a batch $\gB$, we compute its diffusion loss as: 
\begin{equation}
\label{eq:diffloss}
\ell_\mathrm{DM}(\rvx, \hat{\rvx}_v) = \sE_{v' \sim \gU(1, v) } \| \frac{\hat{\rvx}_v -\sqrt{\bar{\alpha}_v}\rvx}{\sqrt{1-\bar{\alpha}_v}} - \rveps_\theta( 
\sqrt{\bar{\alpha}_{v'}}\rvx + \frac{\sqrt{1-\bar{\alpha}_{v'}}}{\sqrt{1-\bar{\alpha}_{v}}} (\hat{\rvx}_v -\sqrt{\bar{\alpha}_v}\rvx)
, v')  \|
\end{equation}
where the random noise $(\rvx - \hat{\rvx}_v)$ is scaled with a randomly sampled timestep $v'$. We compute the  gradient $\rvg(\rvx) = \nabla_\theta \ell_\mathrm{DM}(\rvx, \hat{\rvx}_v)$. To bound $\rvg(\rvx)$'s influence on $\rveps_\theta$, we clip 
$\rvg(\rvx)$ using its $\ell_2$ norm. We then sanitized the per-batch gradient as $\tilde{\rvg}(\gB)$ by applying random Gaussian noise before updating $\rveps_\theta$ using the Adam optimizer~\citep{adam}. 

We prove the privacy guarantee of Algorithm~\ref{alg:rapid} under R\'{e}nyi differential privacy (RDP)~\citep{renyi}, which can be converted to $(\epsilon, \delta)$-DP. The following theorem formulates the guarantee provided by \system (proof deferred to \msec{sec:proof}).  
\begin{theorem}
\label{the:main}
Using the sanitized per-batch gradient 
$\tilde{\rvg}(\gB)$ to update $\rveps_\theta$ satisfies $(\alpha, \frac{2\alpha}{ \sigma^2})$-RDP.
\end{theorem}
The overall privacy cost of \system is computed via RDP composition~\citep{renyi}, which can be further improved using more advanced privacy accounting~\citep{privacy-accounting}.


% \begin{algorithm}
% \caption{Feature extraction using contrastive learning}
% \begin{algorithmic}[1] % The [1] argument enables line numbering
%     \State \textbf{Input:} Initial noisy latents $Z^*_{t}$ for $t = 0, \ldots, 20$
%     \State  Pre-trained latent diffusion model$f(\cdot)$
%     \State {Initialize:} Feature Extractor $g(\cdot)$
%     \State Gaussian noise vector $X_T$
%     \State Data augmentation $Transform()$
    
%     \For{$t = 1$ to $20$}
%         \State $X_{T-t} \gets {Denoise}(X_T)$ using diffusion model
%     \EndFor
    
%     \For{$t = 0$ to $20$}
%         \State $Z^*_{i,t}, Z^*_{j,t} \gets {Transform}(Z^*_{t})$ using random crop, color jitters
%     \EndFor
    
%     \For{$iter = 1$ to $40$}
%         \State $\mathcal{L}_{{noisy}} \gets 0$
%         \For{$i = 1$ to $N$}
%             \State Compute $\mathcal{L}_{{noisy}}$ using:
%             \[
%             \mathcal{L}_{{noisy}} \mathrel{{+}{=}} -\log \frac{\exp({sim}(z_{i,t}^*, z_{j(i),t}^*) / \tau)}{\sum_{k=1, k \neq i}^{2N}  \exp({sim}(z_{i,t}^*, z_{k,t}^*) / \tau)}
%             \]
%         \EndFor
%         \State Update $g(\cdot)$ parameters to minimize $\mathcal{L}_{{noisy}}$
%     \EndFor
    
%     \State \textbf{Output:} $g(\cdot)$ trained to extract features from noisy latents
% \end{algorithmic}
% \end{algorithm}


%\subsection{Inferencing with \system}

% After the nearest neighbors are found, the intermediate steps of the diffusion will be replaced with known trajectories from the trajectory knowledge base. The diffusion model will continue the generation of the remaining steps using the stored latents at the preset timestep $x_{t^{*}}$ as our new starting point and finish the generation process. 

The inference of \system runs as follows. By sampling random Gaussian noise $\rvx_T$ at timestep $T$, we generate its early trajectory $\rvx_k$ up to timestep $k$; using the feature $\rvz_k$ of $\rvx_k$ as the query, we search for $\rvz_k$'s nearest neighbor $\hat{\rvz}_k$ in $\gK\gB$; we then use the corresponding value $\hat{\rvx}_v$ as the starting point at timestep $v$ to resume the sampling. Compared with prior work~\citep{lyu2023differentially,dockhorn2022differentially}, this RAG-based inference also significantly improves inference efficiency. 


% Our retreival-augmented generation of diffusion models reduces computation resources required for the generation by skipping intermediate steps of the diffusion process. Meanwhile, we have observed that the second generation phase from $x_{t^{*}}$ to $\hat{x_0}$ is a relatively easier task than sampling from Gaussian noises $x_T$. Recent work~\citet{lebensold2024dp} has also shown that such retrival-based augmentation methods can be applied to diffusion models. 

% Base on these observations, we propose a Retrieval-Augmented Differentially Private Diffusion Model framework. We first use public data to train a public diffusion model $\epsilon_{\theta}^{pb}$ from scratch. We then use the public model $\epsilon_{\theta}^{pb}$ to generate a diffusion trajectory from $x_T$ to $X_{T-20}$ for the nearest-neighbor matching. The trajectory knowledge base will be generated using a public dataset as well, and we will replace the intermediate steps with the matched neighbor in the knowledge base. For the simpler generation task from $x_{t^{*}}$ to $\hat{x_0}$, we can train another private diffusion model $\epsilon_{\theta}^{pv}$ with DP-SGD~\citet{abadi2016deep} on a private dataset and outperform previous work on DP-diffusion models~\citet{lyu2023differentially,dockhorn2022differentially}. 


