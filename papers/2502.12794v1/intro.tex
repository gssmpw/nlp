
\section{Introduction} \label{Introduction}

The recent advances in diffusion models have led to unprecedented capabilities of generating high-quality, multi-modal data~\citep{ho2020denoising,kong2020diffwave,bar2024lumiere}. However, training performant diffusion models often requires massive amounts of training data, raising severe privacy concerns in domains wherein data is sensitive. For instance,  \citet{carlini2023extracting} show that compared with other generative models, diffusion models are especially vulnerable to membership inference attacks, due to their remarkable modeling capabilities; meanwhile, \citet{wen2023detecting} show that text-conditional diffusion models trained with text-image pairs can produce images almost identical to certain training samples with proper prompting.


% The advent of Generative Artificial Intelligence marks a transformative era in how technological advancements are integrating into human life. At the forefront of this innovation are diffusion models, which have shown great capabilities in a variety of applications, including image synthesis~\citet{ho2020denoising}, audio generation~\citet{kong2020diffwave}, and text-to-video generation~\citet{bar2024lumiere}. These models stand out for their ability to produce visual content of high resolution with exceptional quality given a specific text prompt. 

% However, training and sampling from these models necessitates the use of extensive, meticulously annotated datasets. This reliance not only demands significant resources but also raises pivotal concerns regarding privacy, as it may entail accessing and processing large volumes of personal data. It is well established that over-parameterized deep learning networks often suffer from privacy leakage. For example, an adversary can easily perform a membership inference attack by training a second model that distinguishes if the data is part of the training set. Unfortunately, diffusion models are particularly vulnerable to privacy attacks such as membership inference attacks or even worse direct training data extractions. For example,~\citet{carlini2023extracting} showed that a text-conditional diffusion model trained with text-image pairs can produce images that are almost identical to the training images upon receiving certain prompts. 



This pressing need has spurred intensive research on enforcing privacy protection in diffusion model training. Notably, \citet{dockhorn2022differentially} proposed the concept of differentially private diffusion models (DPDMs), which incorporate DP-SGD~\citep{abadi2016deep} into diffusion model training, providing guaranteed privacy; \citet{ghalebikesabi2023differentially} further applied DP during diffusion model fine-tuning, first pre-training a denoising diffusion probabilistic model~\citep{ho2020denoising} on public data and then fine-tuning the model on private data under DP constraints. Similarly, \citet{lyu2023differentially} employed the same strategy but extended it to latent diffusion models~\citep{rombach2022high}. However,  existing methods suffer from major limitations. \mct{i} Significant utility loss -- The quality of generated samples often drops sharply under tightened privacy budgets. For instance, \dpdm~\citep{dockhorn2022differentially} fails to synthesize recognizable images on CIFAR10 under a DP budget of $\epsilon = 1$. \mct{ii} Large memory footprint -- To reduce the noise magnitude applied at each iteration, most approaches adopt excessive batch sizes (e.g., $B$ = 8,192 samples per batch). As common DP frameworks (e.g., {\sc Opacus}~\citep{opacus}) have peak memory requirements of $\mathcal{O}(B^2)$, this severely limits the size of usable diffusion models. \mct{iii} Expensive inference cost -- Similar to non-private diffusion models, existing methods require expensive, iterative sampling at inference, impeding them from synthesizing massive amounts of data. 

% However, the fine-tuning process described in these studies typically limits the model to shifting the model's task into generating a different set of images
% Although DPDM offers a certain degree of privacy protection, the quality of the resultant images from the model remains relatively limited, especially when trying to generate images of higher resolution. Addressing this limitation, \citet{ghalebikesabi2023differentially} advanced the field by introducing differentially private fine-tuning for the diffusion models. This approach involves pre-training the Denoising Diffusion Probabilistic Models (DDPM) with public data and subsequently fine-tuning the model using the private data under differential privacy measures. Similarly, ~\citet{lyu2023differentially} employed the same fine-tuning strategy with Latent Diffusion Models (LDM). However, the fine-tuning process described in these studies typically limits the model to shifting the model's task into generating a different set of images. In other words, possessing a more comprehensive and powerful model has become a prerequisite for privately fine-tuning it into a "private" model with reduced functionalities. In addition, to minimize the noise scale applied at each epoch, all of the DP-diffusion models adopted a excessive This relatively impractical setting limits the utilization of any DP-diffusion models. This constraint significantly hampers the practical application of DP-diffusion models, underscoring the necessity for more effective and feasible approaches to constructing Differentially Private Diffusion Models. 



To address such challenges, we present \system, a novel approach that integrates retrieval augmented generation (RAG)~\citep{lewis2020retrieval,blattmann2022retrieval} into DPDM training. Our approach is based on the key observation that small perturbations to the early sampling steps of diffusion models have a limited impact on the overall sampling trajectory~\citep{sensitivity}. This allows us to reuse previously generated trajectories, if similar to the current one, as effective surrogates to reduce both training and inference costs~\citep{zhang2023redi}. Leveraging this idea, \system utilizes available public data to pre-train a diffusion model and build a knowledge base of sampling trajectories. It further refines the model using private data: it first computes the early sampling steps, retrieves similar trajectories from the knowledge base as surrogates, and focuses on training the later sampling steps under DP constraints. Compared to prior work, \system offers several major advantages: 

\begin{mitemize}
    \item  It achieves a more favorable privacy-utility trade-off by fully utilizing public data and only training the later sampling steps on private data;
\item It significantly reduces batch-size requirements by leveraging the retrieved sample trajectories, making the use of large diffusion models feasible; 
\item It greatly improves inference efficiency by skipping intermediate sampling steps via RAG. 
\end{mitemize}

Extensive evaluation using benchmark datasets and models demonstrates that \system outperforms state-of-the-art methods by large margins in there key areas: \mct{i} generative quality (e.g., improving FID score to 63.2 on CIFAR10 under a DP budget $\epsilon = 1$), \mct{ii} memory footprint (e.g., reducing the required batch size to just 64 samples per batch), and \mct{iii} inference efficiency (e.g., saving up to 50\% of the inference cost). Our findings suggest that integrating RAG into DP training represents a promising direction for developing future privacy-preserving generative models.
%Our contributions can be summarized as follows. 

% \begin{itemize}

% \end{itemize}


% Retrieval Augmented Generation (RAG) emerged as a pivotal innovation in the field of generative AI. Initially introduced by ~\citet{lewis2020retrieval}, this groundbreaking approach sought to enhance the fidelity and reliability of generative models within the realm of Natural Language Processing (NLP) by leveraging established knowledge bases. The essence of RAG lies in its ability to dynamically fetch pertinent information from external sources, thereby enriching the generative output with a depth of knowledge and context previously unattainable. Building on this foundation, ~\citet{blattmann2022retrieval} extended the concept of retrieval augmentation to the domain of image generation with diffusion models. Their novel contribution aimed at reducing the parameters of the diffusion models through the incorporation of more flexible conditioning inputs, sourced from closely related images. This was achieved by employing a fixed encoder, such as CLIP, to encode both texts and images into the same embedding space and then replace the original conditioning of the model with the encodings of the images from the nearest-neighbor search. Advancing the frontier further, ~\citet{zhang2023redi}, unveiled a pioneering approach called Redi wherein retrieval augmentation plays an integral role not merely in conditioning but directly in the generative process of Diffusion models. This innovative method utilizes the initial 20$\%$ of the sampling steps as keys to identify the nearest matching diffusion trajectories, allowing these matched trajectories to replace the model's original sampling steps. Consequently, the model is required to complete only the remaining 20$\%$ of the generation process, heralding a significant leap in the efficiency of the sampling steps of the diffusion models while reducing the cost of computation. However, Redi relies on utilizing the deterministic generation process from the same random seed of a pre-trained diffusion model. Building such a trajectory knowledge base is not only computation-heavy, time-consuming, but also has limited practical usage because the knowledge base can only be used for pairing with sampling steps from the same starting point $X_{T}$. 

% To address the issues mentioned above, we propose xxx, a latent diffusion framework that utilizes retrieval augmentation to improve the efficiency of the sampling steps, hence improving the quality of outputs of the model especially when there are limited resources for training. Figure 1 demonstrates the full network of xxx, instead of relying on a pre-trained model to generate the trajectory database, we propose to simulate the diffusion trajectory by dynamically calculating the forward process of the diffusion models. Such a modification allows a much more flexible and efficient retrieval augmentation because it: 1, we no longer need a pre-trained model to generate the sampling trajectories; 2, the method can be applied to the diffusion model without limiting random seeds or deterministic generations; 3, our method takes much less time because the forward process involves only simple calculations for each image in the knowledge base. In addition, we also discovered that the retrieval-augmented framework can boost the performances of the differentially private diffusion models by using images from the public datasets to build the diffusion trajectory database and training the DP-diffusion models on the private data. 

% Our contributions are as follows:\newline
% 1, We have designed a new methodology for retrieval augmented diffusion models that skips sampling steps by matching the trajectories of the forward processes with the earlier sampling steps of the diffusion models.\newline
% 2, We have applied the retrieval augmentation to the differential private models and improved the quality of outputs while using the public data as the knowledge base without breaching privacy. \newline
% 3, We show empirically that the differentially private retrieval-augmented diffusion model outperforms other models by producing samples with higher quality and requiring much smaller batch size and computing resources. \newline
