@misc{chen-etal-2024-holistic,
      title={Holistic Visual-Textual Sentiment Analysis with Prior Models}, 
      author={Junyu Chen and Jie An and Hanjia Lyu and Christopher Kanan and Jiebo Luo},
      year={2024},
      eprint={2211.12981},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2211.12981}, 
}


@misc{he-etal-2015-deep,
      title={Deep Residual Learning for Image Recognition}, 
      author={Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
      year={2015},
      eprint={1512.03385},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{sarakon-etal-2014-face,
    title={Face shape classification from 3D human data by using SVM},
    author={Pornthep Sarakon and Theekapun Charoenpong and Supiya Charoensiriwath},
    journal={The 7th 2014 Biomedical Engineering International Conference},
    year={2014},
    pages={1-5},
    url={https://api.semanticscholar.org/CorpusID:24210558}
}

@inproceedings{sohn-2016-improve,
author = {Sohn, Kihyuk},
title = {Improved deep metric learning with multi-class N-pair loss objective},
year = {2016},
isbn = {9781510838819},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
booktitle = {Proceedings of the 30th International Conference on Neural Information Processing Systems},
pages = {1857–1865},
numpages = {9},
location = {Barcelona, Spain},
series = {NIPS'16}
}

@article{guo-etal-2019-survey,
    title = {A survey on deep learning based face recognition},
    journal = {Computer Vision and Image Understanding},
    volume = {189},
    pages = {102805},
    year = {2019},
    issn = {1077-3142},
    doi = {https://doi.org/10.1016/j.cviu.2019.102805},
    url = {https://www.sciencedirect.com/science/article/pii/S1077314219301183},
    author = {Guodong Guo and Na Zhang}
}

@misc{tio-etal-2019-face,
      title={Face shape classification using Inception v3}, 
      author={Adonis Emmanuel Tio},
      year={2019},
      eprint={1911.07916},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{dao-etal-2021-multilabel,
      title={Multi-Label Image Classification with Contrastive Learning}, 
      author={Son D. Dao and Ethan Zhao and Dinh Phung and Jianfei Cai},
      year={2021},
      eprint={2107.11626},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{wang-etal-2022-survey,
    title={A Survey of Face Recognition}, 
    author={Xinyi Wang and Jianteng Peng and Sufang Zhang and Bihui Chen and Yi Wang and Yandong Guo},
    year={2022},
    eprint={2212.13038},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@misc{dalvi-etal-2022-survey,
    title={A Survey on Face Recognition Systems}, 
    author={Jash Dalvi and Sanket Bafna and Devansh Bagaria and Shyamal Virnodkar},
    year={2022},
    eprint={2201.02991},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@article{salim-etal-2023-face,
title = {Face Shape Classification Using Swin Transformer Model},
journal = {Procedia Computer Science},
volume = {227},
pages = {557-562},
year = {2023},
note = {8th International Conference on Computer Science and Computational Intelligence (ICCSCI 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.10.558},
url = {https://www.sciencedirect.com/science/article/pii/S1877050923017258},
author = {Brigita Vanessa Salim and  Chyntia and Jason Orlando Indrawan and Jessica Hidayat and Steven Matthew and Tesalonika Abigail Eikwine Mangkang and Silviya Hasana and Ivan Halim Permonangan},
}
@misc{yang-etal-2023-dawn,
      title={The Dawn of LMMs: Preliminary Explorations with GPT-4V(ision)}, 
      author={Zhengyuan Yang and Linjie Li and Kevin Lin and Jianfeng Wang and Chung-Ching Lin and Zicheng Liu and Lijuan Wang},
      year={2023},
      eprint={2309.17421},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{sun-etal-2023-aligning,
      title={Aligning Large Multimodal Models with Factually Augmented RLHF}, 
      author={Zhiqing Sun and Sheng Shen and Shengcao Cao and Haotian Liu and Chunyuan Li and Yikang Shen and Chuang Gan and Liang-Yan Gui and Yu-Xiong Wang and Yiming Yang and Kurt Keutzer and Trevor Darrell},
      year={2023},
      eprint={2309.14525},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{naveed-etal-2023-comprehensive,
      title={A Comprehensive Overview of Large Language Models}, 
      author={Humza Naveed and Asad Ullah Khan and Shi Qiu and Muhammad Saqib and Saeed Anwar and Muhammad Usman and Naveed Akhtar and Nick Barnes and Ajmal Mian},
      year={2023},
      eprint={2307.06435},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{gandhi-etal-2023-multi,
      title = {Multimodal sentiment analysis: A systematic review of history, datasets, multimodal fusion methods, applications, challenges and future directions},
      author = {Ankita Gandhi and Kinjal Adhvaryu and Soujanya Poria and Erik Cambria and Amir Hussain},
      journal = {Information Fusion},
      volume = {91},
      pages = {424-444},
      year = {2023},
      issn = {1566-2535},
      doi = {https://doi.org/10.1016/j.inffus.2022.09.025},
      url = {https://www.sciencedirect.com/science/article/pii/S1566253522001634},

}

@inproceedings{lopes-etal-2021-automl,
   title={An AutoML-based Approach to Multimodal Image Sentiment Analysis},
   url={http://dx.doi.org/10.1109/IJCNN52387.2021.9533552},
   DOI={10.1109/ijcnn52387.2021.9533552},
   booktitle={2021 International Joint Conference on Neural Networks (IJCNN)},
   publisher={IEEE},
   author={Lopes, Vasco and Gaspar, Antonio and Alexandre, Luis A. and Cordeiro, Joao},
   year={2021},
   month=jul }


@misc{zhang-etal-2023-provable,
      title={Provable Dynamic Fusion for Low-Quality Multimodal Data}, 
      author={Qingyang Zhang and Haitao Wu and Changqing Zhang and Qinghua Hu and Huazhu Fu and Joey Tianyi Zhou and Xi Peng},
      year={2023},
      eprint={2306.02050},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{wang-etal-2023-exploring,
      title={Exploring Multimodal Sentiment Analysis via CBAM Attention and Double-layer BiLSTM Architecture}, 
      author={Huiru Wang and Xiuhong Li and Zenyu Ren and Dan Yang and chunming Ma},
      year={2023},
      eprint={2303.14708},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{liu-etal-2023-visual-arxiv,
      title={Visual Instruction Tuning}, 
      author={Haotian Liu and Chunyuan Li and Qingyang Wu and Yong Jae Lee},
      year={2023},
      eprint={2304.08485},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{liu-etal-2023-improved,
      title={Improved Baselines with Visual Instruction Tuning}, 
      author={Haotian Liu and Chunyuan Li and Yuheng Li and Yong Jae Lee},
      year={2023},
      eprint={2310.03744},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{peng-etal-2022C-cross,
  title={Cross-modal complementary network with hierarchical fusion for multimodal sentiment classification},
  author={Cheng Peng and Chunxia Zhang and Xiaojun Xue and Jiameng Gao and Hongjian Liang and Zhengdong Niu},
  journal={Tsinghua Science and Technology},
  year={2022},
  url={https://api.semanticscholar.org/CorpusID:245025098}
}

@misc{radford-etal-2021-learning,
      title={Learning Transferable Visual Models From Natural Language Supervision}, 
      author={Alec Radford and Jong Wook Kim and Chris Hallacy and Aditya Ramesh and Gabriel Goh and Sandhini Agarwal and Girish Sastry and Amanda Askell and Pamela Mishkin and Jack Clark and Gretchen Krueger and Ilya Sutskever},
      year={2021},
      eprint={2103.00020},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{cheema-etal-2021-fair,
      title={A Fair and Comprehensive Comparison of Multimodal Tweet Sentiment Analysis Methods}, 
      author={Gullal S. Cheema and Sherzod Hakimov and Eric Müller-Budack and Ralph Ewerth},
      year={2021},
      eprint={2106.08829},
      archivePrefix={arXiv},
      primaryClass={cs.SI}
}

@misc{hu-etal2021-lora,
      title={LoRA: Low-Rank Adaptation of Large Language Models}, 
      author={Edward J. Hu and Yelong Shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen},
      year={2021},
      eprint={2106.09685},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{jiang-etal-2020-fusion,
      title = {Fusion-Extraction Network for Multimodal Sentiment Analysis},
      author = {Jiang, Tao and Wang, Jiahai and Liu, Zhiyue and Ling, Yingbiao},
      year = {2020},
      isbn = {978-3-030-47435-5},
      publisher = {Springer-Verlag},
      address = {Berlin, Heidelberg},
      url = {https://doi.org/10.1007/978-3-030-47436-2_59},
      doi = {10.1007/978-3-030-47436-2_59},
      pages = {785–797},
      numpages = {13},
      keywords = {Fusion-Extraction Model, Multimodal, Sentiment analysis},
      location = {Singapore, Singapore}
}

@misc{liu-etal-2019-roberta,
      title={RoBERTa: A Robustly Optimized BERT Pretraining Approach}, 
      author={Yinhan Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and Mike Lewis and Luke Zettlemoyer and Veselin Stoyanov},
      year={2019},
      eprint={1907.11692},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{woo-etal-2018-cbam,
      title={CBAM: Convolutional Block Attention Module}, 
      author={Sanghyun Woo and Jongchan Park and Joon-Young Lee and In So Kweon},
      year={2018},
      eprint={1807.06521},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{xu-etal-2017-multi, 
      title = {MultiSentiNet: A Deep Semantic Network for Multimodal Sentiment Analysis}, 
      author = {Xu, Nan and Mao, Wenji}, 
      year = {2017}, 
      isbn = {9781450349185}, 
      publisher = {Association for Computing Machinery}, 
      address = {New York, NY, USA}, 
      url = {https://doi.org/10.1145/3132847.3133142}, 
      doi = {10.1145/3132847.3133142},
      booktitle = {Proceedings of the 2017 ACM on Conference on Information and Knowledge Management}, 
      pages = {2399–2402}, 
      numpages = {4}, 
      location = {Singapore, Singapore}, 
      series = {CIKM '17} 
}
