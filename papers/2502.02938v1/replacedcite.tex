\section{Background and Related Work}
\subsection{Multimodal Sentiment Analysis}
MSA is an evolving research field focused on analyzing sentiments in various data types, such as images, videos, audio, and text ____. By combining computer vision, natural language processing, and machine learning, MSA has shown success in areas such as social media, customer service, and product reviews ____.

Previous work has focused on fusing multiple modalities with pre-trained models to predict a multimodal label that encapsulates sentiment labels for each modality. For example, ____ concatenated image and text features initialized from CLIP ____ and RoBERTa ____, respectively. ____ fused both features through Convolutional Neural Networks (CNNs) along with Convolutional Block Attention Module (CBAM) ____ where the image and text features were initialized from Residual Networks (ResNet) ____ and BERT ____. 

In addition, recent works such as ____ introduced auxiliary losses to align and minimize discrepancies between text and image representations, while ____ utilized several pre-trained models in combination to enhance sentiment analysis performance.

Although these approaches have achieved state-of-the-art performance, they primarily focus on the multimodal label, often overlooking the contributions of unimodal labels from image and text modalities. Furthermore, existing methods, such as those proposed by ____, rely on complex fusion strategies, leaving the potential of MLLMs for MSA remains largely unexplored. To the best of our knowledge, the role of MLLMs as a classifier for MSA has not been adequately examined, prompting this study to explore their effectiveness in addressing this task.

\subsection{MLLMs as a Classifier}
Recent advances in LLMs have demonstrated their effectiveness in NLP tasks, inspiring the development of MLLMs capable of integrating multiple modalities, such as images, videos, and audio ____. These models combine the strengths of vision, language, and other modalities, enabling more comprehensive and context-aware understanding across multimodal data. 

However, the use of MLLMs as classifiers for MSA remains relatively unexplored. For instance, ____ utilized RoBERTa and GPT-3 with prompts to build a classifier for unimodal sentiment analysis but did not extend their approach to MSA. To address this limitation, we aim to develop a classifier for MSA by leveraging a MLLM, specifically LLaVA ____.