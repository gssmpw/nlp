\section{Experiment 1: Few-shot Semi-supervised Medical Image Segmentation (FS-Semi)}
\label{sec:task2}
We implement our GEMINI learning on few-shot semi-supervised (FS-Semi) medical image segmentation (GEMINI-Semi) providing a variant on the situation that labels are very few. Three public-available tasks are enrolled in our experiments for a very complete evaluation.
\subsection{Experiments configurations}
\label{sec:configurations2}
\subsubsection{Variant design} The variant of our GEMINI-Semi learns a segmentation head $Seg_{\kappa}$ on the extracted dense features $f^{A},f^{B}$. Therefore, except the optimization for deformable homeomorphism learning $\mathcal{L}_{DHL}$, the GEMINI-Semi also has an additional optimization for segmentation $\mathcal{L}_{Seg}$:
\begin{equation}\label{equ:variant2}
\underset{\xi,\theta,\kappa}{\arg\min}\ (\mathcal{L}_{DHL}(\theta,\xi,\mathcal{S}_{ul})+\mathcal{L}_{Seg}(\theta,\kappa,\mathcal{S}_{l})),
\end{equation}
where the $\mathcal{S}_{ul}$ and the $\mathcal{S}_{l}$ are the unlabeled dataset and the labeled dataset. In our experiment, we utilize the sum of Dice loss and cross-entropy loss \cite{ma2021loss} to train segmentation objective $\mathcal{L}_{Seg}$. The other compared DCRL methods (Sec.\ref{sec:comparison2}) also use the same setting as this variant which adds the $\mathcal{L}_{Seg}$ in the training to learn segmentation.
\begin{table}
  \centering
  \caption{Total seven publicly available datasets are involved in this paper for the experiments of our GEMINI's variants, achieving great reproducibility.}\label{dataset}
\resizebox{\linewidth}{!}{
  \begin{tabular}{lccccccccc}
  \toprule
  \textbf{Dataset}                       &\textbf{Type}    &\textbf{Num}  &\textbf{FS-Semi} &\textbf{SS-MIP}\\
  \midrule
  %\midrule
  ASOCA \cite{gharleghi2022automated}    &3D cardiac CT    &60            &$\surd$          &\\
  CAT08 \cite{schaap2009standardized}    &3D cardiac CT    &32            &$\surd$          &\\
  WHS-CT \cite{zhuang2019evaluation}     &3D cardiac CT    &60            &$\surd$          &\\
  CANDI \cite{kennedy2012candishare}     &3D brain MRI     &103           &$\surd$          &$\surd$\\
  SCR \cite{van2006segmentation}         &2D chest X-ray   &247           &$\surd$          &$\surd$\\
  KiPA22 \cite{he2021meta}               &3D kidney CT     &130           &                 &$\surd$\\
  %CARDIAC               &3D cardiac CT              &302                 &                 &$\surd$\\
  ChestX-ray8 \cite{wang2017chestx}      &2D chest X-ray   &112,120       &                 &$\surd$\\
  \bottomrule
  \end{tabular}}
\end{table}

\subsubsection{Datasets} We evaluate GEMINI on three public tasks in 2D and 3D dimensions, showcasing its powerful representation ability in semi-supervised tasks \cite{you2024mine,you2024rethinking} with minimal labels (Tab.\ref{dataset}). \textbf{Task 1: FS-Semi cardiac structure segmentation (3D)} targets seven cardiac structures on 3D CT images, combining WHS-CT \cite{zhuang2019evaluation} (20 labeled, 40 unlabeled), ASOCA \cite{gharleghi2022automated} (60 unlabeled), and CAT08 \cite{schaap2009standardized} (32 labeled from\footnote{\url{http://www.sdspeople.fudan.edu.cn/zhuangxiahai/0/mmwhs/}}). Images are cropped and resampled to $144\times144\times128$, with a five-shot evaluation (5, 100, and 47 images as labeled training, unlabeled training, and testing sets). \textbf{Task 2: FS-Semi brain tissue segmentation (3D)} involves 27 brain tissues on 3D T1 MR images from the CANDI dataset \cite{kennedy2012candishare} (103 labeled). Cropped volumes of $160\times160\times128$ undergo five-shot evaluation (5, 78, and 20 images as labeled training, unlabeled training, and testing sets). \textbf{Task 3: FS-Semi chest structure segmentation (2D)} focuses on three chest-related structures in 2D chest X-rays using the SCR dataset \cite{van2006segmentation} (247 labeled) whose images are from the JSRT database \cite{shiraishi2000development}, split into 5 labeled, 142 unlabeled, and 100 testing images for five-shot evaluation. All tasks use rotation [$-20^\circ$, $20^\circ$] and scaling [0.75, 1.25] for data augmentation.

\subsubsection{Comparison setting} \label{sec:comparison2}
We compare GEMINI-Semi with 19 widely-used methods and our GVSL \cite{He_2023_CVPR} (CVPR 2023) to demonstrate its superiority. \textbf{1)} We train a U-Net \cite{ronneberger2015u} to establish upper and lower bounds using 5 labeled images (Five) and all labeled training data (Full). \textbf{2) Semi-supervised methods} without homeomorphism prior (UA-MT \cite{yu2019uncertainty}, MASSL \cite{chen2019multi}, DPA-DBN \cite{he2020dense}, CPS \cite{chen2021semi}) highlight the significance of prior knowledge for semi-supervised learning with limited labels. \textbf{3) Atlas-based methods} with homeomorphism prior (VM \cite{ba2018un}, LC-VM \cite{BalakrishnanVoxelMorph(u)}, LT-Net \cite{wang2020lt}) illustrate the limitation caused by the inefficient correspondence learning. \textbf{4) Learning registration to learn segmentation methods} with homeomorphism prior (DeepAtlas \cite{xu2019deepatlas}, DataAug \cite{zhao2019data}, DeepRS \cite{he2020deep}, PC-Reg-RT \cite{he2021few}, BRBS \cite{he2022learning}) show gains from improved correspondence but are limited by pseudo-labels from unreliable GVS. \textbf{5) Dense contrastive representation learning methods} without homeomorphism prior (VADeR \cite{o2020unsupervised}, GLCL \cite{chaitanya2020contrastive}, DSC-PM \cite{li2021dense}, PixPro \cite{xie2021propagate}, DenseCL \cite{wang2022densecl}, SetSim \cite{wang2022exploring}) reveal FP\&N problem in DCRL. For fairness, all methods use 2D/3D U-Net \cite{ronneberger2015u} with group normalization \cite{wu2018group} as the backbone.

\subsubsection{Implementation and evaluation metrics} In this task, our GEMINI-Semi is implemented by PyTorch \cite{paszke2019pytorch} on NVIDIA GeForce RTX 3090 GPUs with 24 GB memory. We take Adam whose learning rate is $1\times10^{-4}$ to optimize our framework for fast convergence. For task 1 and task 2, we sample two unlabeled images and one labeled image randomly in each iteration to save the memory for large 3D images, and for task 3, we sample 10 unlabeled images and 5 labeled images randomly in each iteration for 2D images. Following \cite{he2022learning}, we perform an affine transformation on these images via AntsPy\footnote{\url{https://github.com/ANTsX/ANTsPy}} to normalize the spatial system. We utilize the DSC [\%] to evaluate the area-based overlap index and the average Hausdorf distances (AVD) to evaluate the coincidence of the surface \cite{taha2015metrics}.

\subsection{Results and Analysis}
\label{sec:results2}
\begin{table*}
\centering
\caption{The quantitative evaluation demonstrates our powerful representation ability in FS-Semi tasks. Our GEMINI-Semi achieves the best performance on CT, MR, and X-ray images compared with 19 popular methods and the GVSL. The ``unable" means that the extremely poor results make the AVD unable to be calculated. The ``-" means that the setting is unable to be implemented. The ``HP" means these methods have or do not have homeomorphism prior. ``T1", ``T2", ``T3" are the task 1, task 2, task 3. The red and blue values are the highest and the second-highest values in the columns.}
\resizebox{\textwidth}{!}{
\begin{tabular}{clccccccccccccccc}
  \toprule
  \multirow{2}{*}{\textbf{Type}}
  &\multirow{2}{*}{\textbf{Method}}
  &\multirow{2}{*}{\textbf{HP}}
  &\multicolumn{2}{c}{\textbf{T1: 3D cardiac structures}}
  &\multicolumn{2}{c}{\textbf{T2: 3D brain tissues}}
  &\multicolumn{2}{c}{\textbf{T3: 2D chest structures}}
  &\textbf{AVG}\\ \cmidrule(r){4-5}\cmidrule(r){6-7}\cmidrule(r){8-9}\cmidrule(r){10-10}
  &
  &
  &DSC$_{\pm std}\uparrow$
  &AVD$_{\pm std}\downarrow$
  &DSC$_{\pm std}\uparrow$
  &AVD$_{\pm std}\downarrow$
  &DSC$_{\pm std}\uparrow$
  &AVD$_{\pm std}\downarrow$
  &DSC$_{\pm std}\uparrow$
  \\
  \midrule
  Full
  &U-Net \cite{ronneberger2015u}
  &$\times$
  &-
  &-
  &88.7$_{\pm1.2}$
  &0.31$_{\pm0.04}$
  &96.1$_{\pm1.4}$
  &2.28$_{\pm1.00}$
  &-
  \\
  Five
  &U-Net \cite{ronneberger2015u}
  &$\times$
  &84.3$_{\pm9.6}$
  &2.43$_{\pm2.14}$
  &69.5$_{\pm8.8}$
  &1.59$_{\pm0.84}$
  &83.4$_{\pm6.9}$
  &10.34$_{\pm4.80}$
  &79.1$_{\pm8.4}$
  \\
  \cdashline{1-10}[0.8pt/2pt]
  Semi
  &UA-MT \cite{yu2019uncertainty}
  &$\times$
  &66.4$_{\pm16.2}$
  &4.69$_{\pm2.27}$
  &75.5$_{\pm3.4}$
  &1.31$_{\pm0.95}$
  &83.9$_{\pm6.2}$
  &9.52$_{\pm4.03}$
  &75.3$_{\pm8.6}$
  \\
  &CPS \cite{chen2021semi}
  &$\times$
  &87.4$_{\pm5.4}$
  &1.40$_{\pm0.76}$
  &37.1$_{\pm1.8}$
  &unable
  &63.2$_{\pm1.4}$
  &19.57$_{\pm5.67}$
  &62.6$_{\pm2.9}$
  \\
  &MASSL \cite{chen2019multi}
  &$\times$
  &77.4$_{\pm8.7}$
  &9.07$_{\pm3.11}$
  &80.5$_{\pm3.1}$
  &0.92$_{\pm0.43}$
  &81.9$_{\pm7.0}$
  &10.99$_{\pm4.58}$
  &79.9$_{\pm6.3}$
  \\
  &DPA-DBN \cite{he2020dense}
  &$\times$
  &68.0$_{\pm14.5}$
  &5.75$_{\pm3.89}$
  &68.7$_{\pm8.2}$
  &3.90$_{\pm2.39}$
  &67.4$_{\pm8.7}$
  &24.05$_{\pm6.75}$
  &68.0$_{\pm10.5}$
  \\
  %\midrule
  Atlas
  &VM \cite{ba2018un}
  &$\surd$
  &81.0$_{\pm6.1}$
  &2.13$_{\pm0.78}$
  &83.1$_{\pm1.8}$
  &0.56$_{\pm0.08}$
  &59.9$_{\pm5.0}$
  &15.36$_{\pm4.34}$
  &74.7$_{\pm4.3}$
  \\
  &LC-VM \cite{BalakrishnanVoxelMorph(u)}
  &$\surd$
  &81.7$_{\pm6.0}$
  &2.04$_{\pm0.77}$
  &83.0$_{\pm1.8}$
  &0.56$_{\pm0.07}$
  &60.2$_{\pm7.4}$
  &14.72$_{\pm4.89}$
  &74.9$_{\pm5.1}$
  \\
  &LT-Net \cite{wang2020lt}
  &$\surd$
  &77.8$_{\pm7.8}$
  &2.25$_{\pm0.95}$
  &82.6$_{\pm1.2}$
  &0.57$_{\pm0.05}$
  &60.4$_{\pm7.4}$
  &14.62$_{\pm4.84}$
  &73.6$_{\pm5.5}$
  \\
  %\hline
  LRLS
  &DeepAtlas \cite{xu2019deepatlas}
  &$\surd$
  &87.9$_{\pm4.3}$
  &1.30$_{\pm0.57}$
  &79.3$_{\pm2.6}$
  &0.74$_{\pm0.12}$
  &64.8$_{\pm9.6}$
  &12.87$_{\pm3.56}$
  &77.3$_{\pm5.5}$
  \\
  &DataAug \cite{zhao2019data}
  &$\surd$
  &82.2$_{\pm5.2}$
  &2.04$_{\pm0.73}$
  &83.9$_{\pm1.2}$
  &0.55$_{\pm0.06}$
  &22.2$_{\pm2.8}$
  &unable
  &62.8$_{\pm3.1}$
  \\
  &DeepRS \cite{he2020deep}
  &$\surd$
  &87.0$_{\pm5.0}$
  &1.60$_{\pm0.90}$
  &73.0$_{\pm5.9}$
  &0.93$_{\pm0.25}$
  &86.0$_{\pm5.6}$
  &8.55$_{\pm3.98}$
  &82.0$_{\pm5.5}$
  \\
  &PC-Reg-RT \cite{he2021few}
  &$\surd$
  &88.5$_{\pm4.9}$
  &1.23$_{\pm0.72}$
  &73.1$_{\pm3.1}$
  &1.09$_{\pm0.17}$
  &59.1$_{\pm3.6}$
  &20.71$_{\pm5.21}$
  &73.6$_{\pm3.9}$
  \\
  &BRBS \cite{he2022learning}
  &$\surd$
  &\color{blue}91.1$_{\pm3.9}$
  &\color{red}\textbf{0.93$_{\pm0.57}$}
  &\color{blue}87.2$_{\pm1.0}$
  &0.43$_{\pm0.05}$
  &71.5$_{\pm6.4}$
  &10.85$_{\pm2.99}$
  &83.3$_{\pm3.8}$
  \\
  %\hline
  DCRL
  &VADeR \cite{o2020unsupervised}
  &$\times$
  &85.4$_{\pm4.7}$
  &1.69$_{\pm0.77}$
  &81.2$_{\pm3.2}$
  &0.59$_{\pm0.13}$
  &79.9$_{\pm5.8}$
  &8.95$_{\pm3.37}$
  &82.2$_{\pm4.6}$
  \\
  &DenseCL \cite{wang2022densecl}
  &$\times$
  &87.3$_{\pm4.3}$
  &1.52$_{\pm0.79}$
  &83.9$_{\pm1.9}$
  &0.48$_{\pm0.09}$
  &77.1$_{\pm8.8}$
  &12.11$_{\pm6.51}$
  &82.8$_{\pm5.0}$
  \\
  &SetSim \cite{wang2022exploring}
  &$\times$
  &87.0$_{\pm4.5}$
  &1.60$_{\pm0.84}$
  &81.2$_{\pm3.0}$
  &0.58$_{\pm0.13}$
  &79.0$_{\pm7.3}$
  &11.72$_{\pm5.03}$
  &82.4$_{\pm4.9}$
  \\
  &DSC-PM \cite{li2021dense}
  &$\times$
  &87.0$_{\pm4.6}$
  &1.60$_{\pm0.86}$
  &82.6$_{\pm2.1}$
  &0.53$_{\pm0.09}$
  &85.7$_{\pm6.2}$
  &7.33$_{\pm3.32}$
  &85.1$_{\pm4.3}$
  \\
  &PixPro \cite{xie2021propagate}
  &$\times$
  &89.5$_{\pm3.9}$
  &1.31$_{\pm0.75}$
  &86.3$_{\pm1.2}$
  &\color{blue}0.38$_{\pm0.04}$
  &83.3$_{\pm8.7}$
  &8.73$_{\pm4.55}$
  &\color{blue}86.4$_{\pm4.6}$
  \\
  &GLCL\cite{chaitanya2020contrastive}
  &$\times$
  &84.5$_{\pm7.0}$
  &1.82$_{\pm1.09}$
  &83.0$_{\pm2.7}$
  &0.52$_{\pm0.11}$
  &85.5$_{\pm8.9}$
  &8.65$_{\pm5.18}$
  &84.3$_{\pm6.2}$
  \\
  %\hline
  \cdashline{1-10}[0.8pt/2pt]
  \textbf{DCRL}
  &\textbf{GVSL-Semi (CVPR)} \cite{He_2023_CVPR}
  &$\surd$
  &90.0$_{\pm3.7}$
  &1.21$_{\pm0.81}$
  &82.3$_{\pm5.9}$
  &0.55$_{\pm0.27}$
  &\color{blue}86.3$_{\pm5.5}$
  &\color{blue}7.18$_{\pm4.01}$
  &86.2$_{\pm5.0}$
  \\
  \textbf{(Ours)}
  &\textbf{GEMINI-Semi}
  &$\surd$
  &\color{red}\textbf{91.2$_{\pm3.6}$}
  &\color{blue}0.97$_{\pm0.56}$
  &\color{red}\textbf{87.3$_{\pm1.0}$}
  &\color{red}\textbf{0.35$_{\pm0.03}$}
  &\color{red}\textbf{87.7$_{\pm5.2}$}
  &\color{red}\textbf{7.14$_{\pm3.63}$}
  &\color{red}\textbf{88.7$_{\pm3.3}$}
  \\
  \bottomrule
\end{tabular}
}
\label{tab:metrics2}
\end{table*}
\begin{figure}
  \centering
  \includegraphics[width=\linewidth]{./picture/results2.pdf}
  \caption{Our GEMINI-Semi has significant visual superiority on three FS-Semi medical image segmentation tasks.}\label{Fig:results2}
\end{figure}
\subsubsection{Quantitative evaluation shows metric superiority}
As shown in Tab.\ref{tab:metrics2}, 19 compared methods demonstrate that the DCRL will greatly improve the representability, and the homeomorphism prior (``HP") further improves the reliability of the representation learning. There are three interesting observations in Tab.\ref{tab:metrics2}: \textbf{1)} The semi-supervised methods are limited by the extremely few labels. They utilize the pseudo-label generation (UA-MT, CPS) or multi-task learning (MASSL, DPA-DBN) to improve the representation, but the extremely few labels have no enough ability to give them reliable optimization directions to overcome the noise in pseudo labels or multiple tasks. As a result, the UA-MT, MASSL, and DPA-DBN have worse performance than U-Net on task 1, and the CPS is worse on task 2 and 3. \textbf{2)} With the ``HP", the Atlas and LRLS methods achieve robust performance in task 1 and task 2, but are limited in task 3. The ``HP" brings an alignment between labeled and unlabeled images for numerous reliable pseudo labels. Therefore, they have achieved significant improvement on task 1 and task 2 compared with the semi-supervised methods. However, the X-ray images in task 3 have low contrast and their appearances are varied caused by the 2D projection of 3D human body, this makes inefficient GVS brings large misalignment between images, thus interfering with the learning and reducing the performance. \textbf{3)} The DCRL methods have robust performance in all three tasks compared with the LRLS methods, although the VADeR, DenseCL, SetSim, DSC-PM, PixPro and GLCL have no homeomorphism prior. Because their feature-level learning reduce the direct interference caused by misalignment in LRLS's pseudo labels and the supervision from the few labels bring basic representability which will promote their correspondence discovery. However, the FP\&N problem is still a problem in the learning and their performance on task 3 is poor without ``HP" like the semi-supervised methods.

Compared with the LRLS, other DCRL methods, and our previous GVSL-Semi, our GEMINI-Semi achieves the best performance on three tasks with four observations: \textbf{1)} Compared with the LRLS methods which have ``HP", our method has better performance on all tasks. Although the BRBS has similar performance as our GEMINI-Semi on task 1 and task 2, our method achieves 16.2\% DSC and 3.71 AVD higher and lower than it on task 3. This is because our GEMINI-Semi utilizes our GSS for alignment measurement and shares the representation between the segmentation and deformation learning, bringing more efficient and robust learning for alignment. It has a great ability to construct positive feature pairs even with varied appearances. The gradient from our DHL also trains the soft negative feature pairs to drive the learning of distinct representations for potentially different semantics in shared backbones, bringing a regularization for potential mispaired positive pairs. \textbf{2)} Compared with the other DCRL methods which have no ``HP", our GEMINI-Semi shows great improvements in all three tasks. It achieves more than 1.7\%, 1.0\%, and 2.0\% DSC improvements on task 1, 2, and 3 compared with the best DCRL models without ``HP" (PixPro in task 1 and 2, DSC-PM in task 3). Because the ``HP" in our GEMINI-Semi constructs a more reliable correspondence discovery process which reduces the production risk of the FP\&N pairs, bringing comprehensive improvement for the DCRL. \textbf{3)} Compared to our CVPR vision (GVSL-Semi), we find even though the GVSL utilizes the visual similarity like the BRBS, it also achieves great performance in task 3, demonstrating the superiority of the DCRL paradigm. The GVSL-semi avoids the interference of pseudo labels like BRBS reducing the noisy information from the extremely mis-alignment, so that it takes the advantage of DCRL and our homeomorphism prior and achieves good performance in all three tasks. Our GEMINI-Semi promotes the GVSL and utilizes the GSS for a more powerful dense representation learning, thus achieving the highest 88.7\% average DSC in this experiment. \textbf{4)} Compared with the fully supervised setting (``Full") in task 2 (83 labeled images), our GEMINI-Semi achieves a similar performance only with 5 labeled images demonstrating our great potential in reducing of annotation costs. In the task 3, our framework is lower than the upper bound (96.1\%) only with five annotations, but it still achieves significant improvement (4.3\%) compared with the model directly trained on five labeled images.

\subsubsection{Qualitative evaluation shows visual superiority}
As shown in Fig.\ref{Fig:results2}, we show typical cases on the three tasks in this experiment and our framework has higher accuracy on thin regions and fewer outliers. In the task 1, the segmentation result of our method has better integrity, and the different semantic structures have good adjacency without outliers. However, the other four DCRL methods have discontinuous mis-segmentation which destroys the heart topology. This is because the pairing strategies in the DCRL methods are unable to make the pairs under the condition of topology consistency, so the large-scale mispaired features interrupt the learning and make numerous outliers. The same as the task 3, there are also serious outlier problems in the four typical DCRL methods and the GVSL, and our GEMINI-Semi has fine segmentation. In the task 2, our GEMINI and GVSL show finer segmentation on the thin brain structures which is sensitive and will be interrupted by the noise in the semi-supervised learning process. In some prominent and gully regions of task 2 (enlarged part), the compared four DCRL methods have numerous distortions due to their unreliable correspondence discovery, showing their fragility.


