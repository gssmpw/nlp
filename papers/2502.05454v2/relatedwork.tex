\section{Related Work}
\label{sec:background}

Our approach builds upon prior work on goal- and language-conditioned control, focusing particularly on the problem of compositional generalization.

\paragraph{Robot manipulation with language and goals.}Recent improvements in robot learning datasets have enabled the development of robot policies that can be commanded with image goals and language instructions~\citep{ahn2022can,walke2023bridgedata,shridhar2021cliport}.
These policies can be trained with goal- and language-conditioned imitation learning from human demonstrations~\citep{chowdhery2023palm,jiang2023vima,lynch2021language,lynch2023interactive,brohan2023rt2}, reinforcement learning~\citep{chebotar2023qtransformer,chen2021decisiona}, or other forms of supervision~\citep{bobu2023sirl,cui2023no}.
When trained to reach goals, methods can additionally use hindsight relabeling~\citep{andrychowicz2017hindsight,kaelbling1993learning} to improve performance~\citep{walke2023bridgedata,myers2023goal,dehaene2022symbols,ding2019goal}.
Our work shows how the benefits of goal-conditioned and language-conditioned supervised learning can be combined with temporal representation alignment to enable compositionality that would otherwise require planning or reinforcement learning.

\paragraph{Compositional generalization in sequential decision making.}
In the context of decision making, compositional generalization refers to the ability to generalize to new behaviors that are composed of known sub-behaviors~\citep{rubino2023compositionality,steedman2004where}.
Biological learning systems show strong compositional generalization abilities~\citep{ciranka2022asymmetric,dehaene2022symbols,dickins2011transitive,lake2019human}, and recent work has explored how similar capabilities can be achieved in artificial systems~\citep{akyurek2021learning,ito2022compositional,lewis2024does}.
In the context of policy learning, exploiting the compositionality of the behaviors can lead to generalization to unseen and temporarily extended tasks~\citep{ghugare2023closing,kumar2023pre, fang2019cavin, fang2022generalization, mandlekar2021learning, nasiriany2019planning}.

Hierarchical and planning-based approaches also aim to enable compositional behavior by explicitly partitioning a task into its components~\citep{fang2022planning,myers2024policy,zhang2021c,park2023hiql}.
With improvements in vision-language models (VLMs), many recent works have explored using a pre-trained VLM to decompose a task into subtasks that are more attainable for the low-level manipulation policy~\citep{ahn2022can,attarian2022see,belkhale2024rth,kwon2023grounded,myers2024policy,singh2023progprompt,zhang2023universal}.
These approaches are limited by the need for robust pre-trained models that can be fine-tuned and prompted for embodied tasks.
Our contribution is to show compositional properties can be achieved \textit{without} any explicit hierarchical structure or planning, by learning a structured representation through time-contrastive representation alignment.

\paragraph{Representation learning for states and tasks.}State and task representations for decision making aim to improve generalization and exploit additional sources of data.
Recent work in the robotics domain have explored the use of pre-trained representations across multimodal data, including images and language, for downstream tasks~\citep{karamcheti2023languagedrivena,li2022grounded,ma2023liv,myers2023goal,nair2022r3m,pari2022surprising,shah2021rrl,cui2022can,jang2021bcz}.
In reinforcement learning problems, representations are often trained to predict future states, rewards, goals, or actions~\citep{anand2019unsupervised,ma2022vip,zhang2020learning,fan2022minedojo}, and can improve generalization and sample efficiency when used as value functions~\citep{barreto2017successor,blier2021learning,dayan1993improvinga,dosovitskiy2017learning,choi2021variational}.
Some recent works have explored the use of additional structural constraints on representations to enable planning~\citep{fang2022planning,zhang2021c,eysenbach2024inference,hafner2019learning,myers2025horizon}, or enforced metric properties to improve compositional generalization~\citep{liu2023metric,myers2024learning,wang2023optimal}.

The key distinction between our approach and past contrastive representation methods for robotics like VIP~\citep{ma2022vip}, GRIF~\citep{myers2023goal}, and R3M~\citep{nair2022r3m} is that we focus on the real-world compositional generalization capabilities enabled by simply aligning representations across time in addition to the task modalities, without using the learned representations for policy extraction or defining a value function.