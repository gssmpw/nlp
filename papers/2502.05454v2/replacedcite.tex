\section{Related Work}
\label{sec:background}

Our approach builds upon prior work on goal- and language-conditioned control, focusing particularly on the problem of compositional generalization.

\paragraph{Robot manipulation with language and goals.}Recent improvements in robot learning datasets have enabled the development of robot policies that can be commanded with image goals and language instructions____.
These policies can be trained with goal- and language-conditioned imitation learning from human demonstrations____, reinforcement learning____, or other forms of supervision____.
When trained to reach goals, methods can additionally use hindsight relabeling____ to improve performance____.
Our work shows how the benefits of goal-conditioned and language-conditioned supervised learning can be combined with temporal representation alignment to enable compositionality that would otherwise require planning or reinforcement learning.

\paragraph{Compositional generalization in sequential decision making.}
In the context of decision making, compositional generalization refers to the ability to generalize to new behaviors that are composed of known sub-behaviors____.
Biological learning systems show strong compositional generalization abilities____, and recent work has explored how similar capabilities can be achieved in artificial systems____.
In the context of policy learning, exploiting the compositionality of the behaviors can lead to generalization to unseen and temporarily extended tasks____.

Hierarchical and planning-based approaches also aim to enable compositional behavior by explicitly partitioning a task into its components____.
With improvements in vision-language models (VLMs), many recent works have explored using a pre-trained VLM to decompose a task into subtasks that are more attainable for the low-level manipulation policy____.
These approaches are limited by the need for robust pre-trained models that can be fine-tuned and prompted for embodied tasks.
Our contribution is to show compositional properties can be achieved \textit{without} any explicit hierarchical structure or planning, by learning a structured representation through time-contrastive representation alignment.

\paragraph{Representation learning for states and tasks.}State and task representations for decision making aim to improve generalization and exploit additional sources of data.
Recent work in the robotics domain have explored the use of pre-trained representations across multimodal data, including images and language, for downstream tasks____.
In reinforcement learning problems, representations are often trained to predict future states, rewards, goals, or actions____, and can improve generalization and sample efficiency when used as value functions____.
Some recent works have explored the use of additional structural constraints on representations to enable planning____, or enforced metric properties to improve compositional generalization____.

The key distinction between our approach and past contrastive representation methods for robotics like VIP____, GRIF____, and R3M____ is that we focus on the real-world compositional generalization capabilities enabled by simply aligning representations across time in addition to the task modalities, without using the learned representations for policy extraction or defining a value function.