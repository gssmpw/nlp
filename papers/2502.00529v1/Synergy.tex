\documentclass{sig-alternate-10pt}

\usepackage{pslatex}
\usepackage{balance}
\usepackage{xcolor}
\usepackage{url}
\paperwidth=8.5in
\paperheight=11in
\usepackage[margin=1in]{geometry}

\newcommand{\spara}[1]{\smallskip\noindent{\bf #1}}

\newcommand{\eat}[1]{}


\begin{document}
\pagestyle{empty}

\title{Graph Data Management and Graph Machine Learning: Synergies and Opportunities}

\author{Arijit Khan$^1$ \,\, Xiangyu Ke$^2$ \,\, Yinghui Wu$^3$  \\
\affaddr{$^1$Aalborg University, Denmark \,\, $^2$Zhejiang University, China \,\, $^3$Case Western Reserve University, USA}\\
\email{$^1$arijitk@cs.aau.dk \,\, $^2$xiangyu.ke@zju.edu.cn \,\, $^3$yxw1650@case.edu}
}



\maketitle


\vspace{-1in}


\begin{abstract}
The ubiquity of machine learning, particularly deep learning, applied to graphs is evident in applications ranging from cheminformatics (drug discovery) and bioinformatics (protein interaction prediction) to knowledge graph-based query answering, fraud detection, and social network analysis.
Concurrently, graph data management deals with the research and development of effective, efficient, scalable, robust, and user-friendly systems and algorithms for storing, processing, and analyzing vast quantities of heterogeneous and complex graph data.
Our survey provides a comprehensive overview of the synergies between graph data management and graph machine learning, illustrating how they intertwine and mutually reinforce each other across the entire spectrum of the graph data science and machine learning pipeline. Specifically, the survey highlights two crucial aspects:
{\bf (1)} How graph data management enhances graph machine learning, including contributions such as improved graph neural network performance through graph data cleaning, scalable graph embedding, efficient graph-based vector data management, robust graph neural networks, user-friendly explainability methods; and
{\bf (2)} how graph machine learning, in turn, aids in graph data management, with a focus on applications like query answering over knowledge graphs and various data science tasks.
We discuss pertinent open problems and delineate crucial research directions.
\end{abstract}


\section{Introduction}
\label{sec:introduction}

\medskip
\medskip

Graph data, ranging from social and biological networks to financial transactions, knowledge bases, and transportation systems,
permeates various domains. In these graphs, nodes represent entities with distinct features, while edges capture relationships between them.
The growing volume of graph data and the increasing demand to extract value in real applications necessitate effective graph data management (GDM).
Broadly speaking, data management encompasses a suite of algorithms and systems for acquiring, validating, storing, organizing, protecting, and processing data so they can be easily found and queried effectively, efficiently, securely, and cost-effectively.
The principle of data management is to optimize data usage and comply with regulations, so to enable fair and responsible decision making, while maximizing the utility in downstream tasks.
Modern data management challenges include the three V's of big data (volume, velocity, and veracity), dirty data, secure and distributed data processing, cloud computing, usability, new data types, emerging applications, etc.
While general data management focuses on handling structured or semi-structured data such as tables and logs, graph data management presents unique challenges due to the interconnected nature of graph data.
Managing relationships, traversals, and graph-specific queries (e.g., communities or reachabilities) demand specialized algorithms and data structures. Additionally, the irregularity and scale of graphs introduce challenges in indexing, storage, and real-time updates that go beyond traditional DM solutions.
Specialized graph database management systems (graph DBMS), e.g., Neo4j, TigerGraph, Microsoft Cosmos DB, and Amazon Neptune were developed supporting graph transactions, queries, visualization, and diverse data models \cite{Tian22}.


Machine learning (ML), a subfield of artificial intelligence (AI), uses algorithms to learn knowledge from data and generalize to unseen cases, often without explicit programming.
Key principles of ML include data representation, performance evaluation on downstream tasks, and iterative optimization to improve accuracy.
Based on the above requirements, ML models and systems are developed and deployed ensuring that they are effective, efficient, robust, and user-friendly.
As ML becomes mainstream, there is a growing focus on explainability, transparency, fairness, safety, trust,  and ethical decision-making.
Graph machine learning (GML), in particular, graph neural networks (GNNs) have shown great promises for graph data-centric applications, such as classification, link prediction, community detection, question answering, and recommendation \cite{wu2020comprehensive}.


\begin{figure}[t!]
 \centering
 \includegraphics[scale=0.43]{pipeline.eps}
 \caption{Graph data pipeline in data science and machine learning applications. Graph embedding can be task-specific or task-agnostic. Graph neural network (GNN) training can be end-to-end based on downstream tasks. We show which phases belong to GDM and which belong to GML, and can benefit from each other.}
 \label{fig:pipeline}
 \vspace{-5mm}
\end{figure}

While data management (DM) and machine learning (ML) serve distinct purposes, their synergy is essential, as data is foundational to both.
{\bf First,} effective collaboration between data management and ML is necessary to unleash the full potential of an organization's data. For instance, data management techniques ensure clean, reliable, and up-to-date datasets, enabling ML models to generate accurate and trustworthy insights.
{\bf Second}, in modern data science applications, complex data undergo various processes involved in machine learning to generate the final predictive output, collectively forming a data pipeline \cite{Polyzotis0WZ17, Kumar0017}.
Figure~\ref{fig:pipeline} illustrates a representative graph data pipeline, encompassing the early stages of the graph data extraction, integration, cleaning, acquisition, validation, and enrichment;
intermediate stages dealing with graph embedding, vector data, graph neural network (GNN) training, AutoML;
and concluding stages involving downstream tasks and human-in-the-loop interactions, such as explaining the results of black-box GNN models.
Managing effective and efficient data pipelines increases the need for robust data management solutions.
{\bf Third}, ML approaches enhance DM functionalities, e.g., ML can automate data transformation processes and might also understand a user's query intent to improve querying performance.
Recent graph systems with ML capabilities \cite{abs-2303-14617,HorchidanC23,
Abdallah023} highlight the need to explore the synergies between two related fields: GDM and GML.
Emerging technology landscapes such as AI, ML, edge computing, serverless and cloud computing, modern hardware, Internet-of-Things, data lakes, and Large Language Models (LLMs) are expanding the domain of data-driven downstream applications and what is feasible including real-time decision-making capabilities, streamlining integration, and enhanced security, making the synergy even more critical.


This survey examines the interplay between GDM and GML across different stages of the data pipeline depicted in Figure~\ref{fig:pipeline}.
We identify three key scenarios to structure the survey:
{\bf (a)} when GDM benefits GML; {\bf (b)} when GML enhances GDM; and finally {\bf (c)} when GDM + GML integration facilitates downstream tasks.
For example, the initial phase of graph data cleaning is a GDM task, where we explore GML's contributions (\S \ref{sec:cleaning}).
In contrast, stages like graph embedding, GNN training, and explainability focus on GML objectives, with GDM systems improving their efficiency and effectiveness (\S \ref{sec:embedding}, \S \ref{sec:index}, and \S \ref{sec:explainability}).
The fourth phase about downstream tasks benefits significantly from the synergy of GDM and GML, as discussed in \S \ref{sec:gml4gdm}.


\spara{Motivation: What are new in GDM and GML?}
With the rapid advances of graph machine learning (GML) techniques, such as graph embedding \cite{00010YAWP021}, GNNs \cite{WuPCLZY21,ZhangCZ22,ma2021deep}, graph transformers \cite{abs-2202-08455}, graphGPT \cite{abs-2310-13023}, foundation models \cite{abs-2310-11829}, and LLMs for graphs \cite{jin2023large, abs-2311-12399}, the role of graph data management (GDM) in the GML lifecycle has become increasingly vital.
This spans all stages of the data pipeline, including preparation, improvement, embedding, training, and explanation.
Recently, both academia and industry have emphasized the need for high-quality, large-scale data and robust, scalable, secure, and explainable models in ML systems \cite{Polyzotis0WZ17,abs-2309-10979}.
While there exist surveys and tutorials
discussing the synergy between data management and ML -- primarily focusing on
relational data and relational database management systems \cite{ChaiWLNL23,
Kumar0017,Polyzotis0WZ17}, similar resources about graph data are comparatively scarce.
Both GDM and GML pose significant challenges as follows.

In terms of GDM, graph data are inherently irregular, with nodes and edges forming complex, variable-length connections. This contrasts with the strict schema of relational data, where rows and columns provide a predictable structure.
Therefore, specialized GDM systems are often required to quickly navigate and retrieve complex multi-hop neighbors.
This places unique demands on GDM for efficient sampling and traversal strategies.


Due to their interconnected nature, partitioning graph nodes without disrupting critical structural properties, such as community boundaries, poses significant challenges.
Unlike traditional data partitioning, where rows in tables can often be divided without impacting data relationships, graph partitioning must preserve inter-node dependencies to maintain the graph's integrity, typically requiring extensive communication between nodes or servers.
GDM systems have to manage this inter-partition communication efficiently to support applications at scale -- a challenge that is usually less pronounced in relational data management where tables can often be processed more independently.

Last but not least, graphs can be both high-dimensional and sparse, especially real-world graphs containing billions of nodes, but relatively few edges per node. Storing and efficiently retrieving meaningful patterns from these sparse yet high-dimensional graphs cause difficulties that do not typically arise with dense tabular data.

Analogously, GML poses significant challenges due to the non-IID and unnormalized nature of graph data, the absence of strict schema, and irregular structures.
Unlike traditional ML, where data samples are often processed independently, graph data require interdependent computations, leading to increased computational costs.
Optimizing GML systems for model training, such as by supporting distributed training with efficient data loading and caching, is essential but challenging.

GML also generates high-dimensional embeddings for nodes and edges, which are crucial for tasks like node classification, link prediction, and similarity search. Managing these embeddings is more demanding than handling traditional ML data with simpler numeric or categorical features. Efficient storage, indexing, and retrieval mechanisms, such as vector databases or hybrid storage solutions, are essential for managing the large-volume high-dimensional embeddings produced by GML.

Additionally, reasoning in GML relies heavily on combining intricate feature interactions with graph topology.
Graph data often require advanced feature engineering based on structural motifs or specific subgraph patterns.
This demands robust support for pattern matching and subgraph extraction within GML systems, capabilities that are rarely needed in tabular ML.
Scaling these operations for large graphs is particularly challenging and requires effective indexing and optimization strategies.


Finally, heterogeneity and multimodal graph data (e.g., graphs with nodes and edges having text and image-based features), along with emerging applications beyond classification and prediction (e.g., entity resolution \cite{Li0SZAW20}, knowledge graphs question-answering \cite{YasunagaRBLL21}, graph combinatorial optimizations \cite{VelickovicYPHB20}), and ``black-box'' deep learning approaches introduce further complexities to the deployment of GNNs.

Against this backdrop, our survey
covering a set of the latest solutions that integrate GDM and GML techniques is both timely and relevant.
We believe that our survey will attract and promote interdisciplinary research
that advances
scalable and explainable data pipelines for new data challenges in graph analysis.
%

\spara{Roadmap.}
%
In this survey, we demonstrate how graph data management and machine learning facilitate each other at different stages
in a graph data pipeline. In particular, we delve into the following topics:

\noindent$\bullet$ Benefits of graph data cleaning and augmentation in improving the GNN performance (\S \ref{sec:cleaning});

\noindent$\bullet$ Application of graph data management algorithms and systems for scalable graph embedding learning (\S \ref{sec:embedding});

\noindent$\bullet$ Vector data management using graph-based indexes (\S \ref{sec:index});

\noindent$\bullet$ GNN explainability methods, focusing on their usability and robustness (\S \ref{sec:explainability});

\noindent$\bullet$ Application of graph machine learning in knowledge graphs query answering (\S \ref{sec:kg}); and

\noindent$\bullet$  Applications of graph-based retrieval augmented generation (graph RAG) in large language models (LLMs) for data science tasks (\S \ref{sec:graphrag}).

We discuss background and related work in \S \ref{sec:background} and \S \ref{sec:related}, respectively, and conclude with future work in \S \ref{sec:conclusions}.


\section{Background}
\label{sec:background}

\medskip
\medskip

We introduce background materials on graph neural networks and graph embeddings.

{\bf Graph neural networks (GNNs)} are deep learning models to tackle graph-related
tasks in an end-to-end manner \cite{WuPCLZY21}. GNNs have many variants, e.g.,
graph convolutional network (GCN) \cite{KipfW17}, graph attention network (GAT) \cite{VelickovicCCRLB18},
graph isomorphism network (GIN) \cite{XuHLJ19}, GraphSAGE \cite{HamiltonYL17}, graph auto-encoder \cite{KW16},
graph generative adversarial network (GraphGAN) \cite{WangWWZZZXG18}, and APPNP \cite{KlicperaBG19}, etc.
Specifically, graph convolution operations can be categorized as spectral \cite{BrunaZSL13}
and spatial \cite{DuvenaudMABHAA15}
approaches. In spectral methods, filters are applied on a graph's frequency modes computed via graph Fourier transform.
Spectral formulations rely on the fixed spectrum of the graph Laplacian, and are suitable only for graphs with a single
structure (and varying features on nodes), as well as are computationally expensive. On the other hand, spatial methods
are not restricted to a fixed graph structure, as they extract local information by propagating features between neighboring nodes.
Kipf and Welling \cite{KipfW17} also develop a first-order approximation of the spectral convolution, which results
in propagation between neighboring nodes. In particular, GCN
adopts a general form as follows.
\begin{equation}
\label{eq-prop}
    X^k = \delta(\Hat{D}^{-\frac{1}{2}} \Hat{A} \Hat{D}^{-\frac{1}{2}} X^{k-1}  \Theta^{k})
\end{equation}

Here $\Hat{A} = A + I$, where $I$ represents the identity matrix and $A$ is the adjacency matrix of graph $G$. $X^k$ indicates node feature representation in the $k$-th GCN layer, (with $X^0=X$ a matrix of input node features). $\Hat{D}$ represents the diagonal node degree matrix of $\Hat{A}$, $\delta(.)$ is the non-linear activation function, and $\Theta^{k}$ represents the learnable weight matrix for the $k$-th layer.
State-of-the-art GNNs follow a similar feature learning paradigm: Update the features of every node by aggregating the counterparts from its neighbors.
The inference cost of feature propagation-based GNNs is usually polynomial-time \cite{ChenWDL00W20,KlicperaBG19}.
GNNs have been employed in node and graph classification (e.g., GCN \cite{KipfW17}, GAT \cite{VelickovicCCRLB18},
GraphSAGE \cite{HamiltonYL17}, GIN \cite{XuHLJ19}), link prediction (e.g., LGLP \cite{CaiLWJ22}), and entity resolution
(e.g., GraphER \cite{Li0SZAW20}), etc.

{\bf Graph embedding} or {\bf representation learning} \cite{CaiZC18,CuiWPZ19} generates low-dimensional
representation vectors of nodes, edges, and graphs that capture the structure and features of graphs accurately for downstream ML tasks.
Graph embedding algorithms can be categorized into three classes. {\bf (1)} {\em Matrix factorization} methods \cite{QiuDMLWT18}
construct feature representations based on
the adjacency or Laplacian matrix, and exploit spectral techniques.
{\bf (2)} {\em Random-walk} methods \cite{GroverL16} transform a graph into a set of random walks via sampling and then employ
Skip-Gram to generate embeddings.
{\bf (3)} {\em Graph neural networks} (GNNs)-based approaches \cite{HamiltonYL17,VelickovicCCRLB18} focus on generalizing graph spectra into semi-supervised or
supervised graph learning. They often follow a recursive neighborhood aggregation
scheme to generate embeddings. State-of-the-art matrix factorization and random walk methods
generally work on homogeneous graphs where nodes and edges share the same type, and the algorithms
consider only graph structures. In contrast, GNN-based approaches exploit both graph structures
and node features. They can be end-to-end, implying that the learning of embeddings is
implicit within the GNN model and computed in a task-dependent manner. Embeddings of more complex networks such as
heterogeneous information networks \cite{Sun00CXWY18}, relational graphs \cite{SchlichtkrullKB18}, hypergraphs \cite{ACPSSY23},
knowledge graphs \cite{AliBHVGSFTL22}, uncertain graphs \cite{HuCHFL17}, signed networks \cite{YuanWX17},
dynamic graphs \cite{BMVZ21}, spatio-temporal networks \cite{SiGXYDP22} have been studied.


\section{Graph Data Management \\ for Graph ML}
\label{sec:gdm4gml}

\medskip
\medskip

We discuss applications of graph data management such as data cleaning and augmentation in improving the GNN performance, graph algorithms, databases, and systems for scalable embedding learning, graph indexes for vector data management, and graph view-based explanation generation to enhance usability.

%
\subsection{Graph Data Cleaning and \\ Augmentation}
\label{sec:cleaning}

\medskip
\medskip

Enhancing graph data to improve
the performance of graph learning has seen an increased interest \cite{abs-2309-10979}.
Existing data augmentation techniques from computer vision and natural language processing research cannot be easily generalized to irregular-shaped graph data.
Graph data augmentation (GDA) \cite{abs-2202-08871} specifies enriching graph data to improve graph learning, which is categorized into
``editing-based'' and ``representation-based''.
Editing-based methods aim to
derive graph editing operations,
such as removal, addition, or modify
nodes, edges, features, or (sub)graphs
~\cite{0003LNW0S21,ZhaoZW21,ZhangZSKK22,HanJLH22,gdet}, to improve the model performance
such as graph neural networks.
These methods may follow a deterministic
process, learning to derive editing operations, or
via a stochastic editing process.
Graph sparsification \cite{ZhengZCSNYC020}, condensation \cite{JinZZLTS22}, and diffusion \cite{ZhaoDDKT21} are also
applied to improve GNN-based analysis.

Instead of deriving graph
editing operators, representation based GDA
directly learns to refine graph representation
to improve follow-up analytical tasks.
These methods train learnable parameters to generate augmented samples or graph representation
and may adopt
structure learning, adversarial training, contrastive learning, or automated augmentation \cite{0001XYLWW21,ZhaoTZJ0SASYJ22,SureshLHN21}.
Compared with representation-based approaches, editing-based
GPA may be more
interpretable and explainable, by performing data provenance
analysis over the derived editing operators.
On the other hand,
representation-based approaches
can be readily streamlined
as input for downstream
(graph) learning tasks,
hence, may serve better
in the need of
end-to-end learning pipelines.


Error detection and repairing
have been studied for graphs using rules and logic-based
solutions, such as graph dependencies \cite{FanL19} and graph keys \cite{FanFTD15}, neighborhood constraints \cite{JBM24,linrepairing},
uncertain edges cleaning \cite{LinPCX17}.
Graph association rules (GARs) \cite{FanJLLTZ20}
detect missing links and semantic errors in graphs, while assisting in link prediction.
GNNCleaner \cite{XLXTWLL23} repairs node labels to improve GNN robustness against label noise.
Recent work such as SHACTOR~\cite{rabbani2023shactor}
extracts validated shapes (a graph pattern carrying
value, topological or cardinality constraints) with configurable
measurements such as support to
detect anomalies in knowledge graphs for
error detection and cleaning.
In general,
rule-based error detection treats and
deals with each error scenario
in an isolated manner and
often falls short of capturing
complex scenarios
where errors are from multiple
sources with different forms,
and may require additional effort to
be adapted for general error detection.


Graph learning
has been introduced to improve
error detection and repairing for graphs.
 Generative adversarial learning and
active learning has been
exploited to improve
error detection in
graphs~\cite{gdet, guan2023gale}. For example, GALE~\cite{guan2023gale}
supports an interactive
active, generative adversarial detection framework
for graph error detection.
The method applies few-shot learning
to learn an error generation model
that best fits a limited number of
examples of different types of errors, and applies the
model to augment
the detected errors via a generative
adversarial model to detect more
errors. Active learning is adopted in
this process to assist the
error generation in the GAN-based
error detection.

\spara{Synergy.} There are good  opportunities to integrate and interact with machine learning and graph data cleaning towards ML-based
graph data cleaning systems.
(1) Graph data constraints and
rules can be exploited to characterize
domain knowledge and context for
ML data cleaning models.
These graph data constraints and
rules also provide a validation mechanism to make ML-based data cleaning reasonable.
For example, graph association rules~\cite{FanJLLTZ20} or
validation shapes~\cite{rabbani2023shactor}
can be equipped with
learnable domain-specific patterns to
improve the quality of domain-specific knowledge graphs.
(2) The domain knowledge, context, and data constraints may also be properly featurized for potential
training of foundational data cleaning
models. The expressive ML models can be fine-tuned to perform downstream data cleaning
tasks without conducting isolated,
from-scratch data cleaning pipelines.

On the other hand,
 learning for
graph error detection still requires
a properly large amount of
high-quality annotated
examples, which remain a luxury for many applications such as
domain sciences. Scaling
ML solutions to large-scale
graph cleaning also calls for efficient graph
learning algorithms.
Moreover, making ML-empowered
data cleaning explainable
with domain knowledge
remains desirable yet a missing
feature in current data systems.
These provide opportunities for
emerging needs such as
fact checking tools
in scientific knowledge graphs.

\subsection{Scalable Graph Embedding \\ and GNN Training}
\label{sec:embedding}

\medskip
\medskip

The surge of billion-scale graphs emphasizes the importance of efficient embedding learning on large graphs, as well as GNN training with them,
such as for link prediction on Twitter with over one billion edges \cite{GuptaGLSWZ13}, users and products recommendation at Alibaba \cite{WangHZZZL18}, etc.
To scale GNNs to large
graphs, various sampling strategies, e.g.,  node-wise sampling, layer-wise sampling, and graph-wise sampling are adopted \cite{LinYYFPCX23}.

To resolve efficiency and scalability issues with large graphs, recent works mainly focus on parallel computation,
distributed systems, CPU-GPU hybrid architecture, and  new hardware. PANE enables scalable and attributed networks
embedding by measuring node attribute affinity with random walks, embedding computation via joint matrix factorization,
and using multi-core parallelization \cite{YangSX0LB20}. DistGER exploits information oriented distributed random walks
and distributed Skip-Gram learning for scalable graph embedding \cite{FangKLWFLYC23}.
GraphVite \cite{ZhuXTQ19} employs a CPU-GPU hybrid architecture, simultaneously performing graph random walks on
CPUs and embedding training on GPUs. Marius \cite{MohoneyWXRV21} optimizes data movements between CPU and GPU on a
single machine for large KG embedding. Seastar \cite{WuMCJLZCY21} develops a novel GNN training
framework on GPUs with a vertex-centric programming paradigm.
XGNN \cite{TWCWYZL24} designs a multi-GPU GNN training system to fully utilize GPU and CPU memory and high-speed interconnects.
Amazon released DistDGL \cite{Zheng0WZSSGZK20},
a distributed graph embedding framework
with mini-batch training using the Deep Graph Library (DGL).
Facebook's Pytorch Biggraph \cite{LererWSLWBP19} exploits graph partitioning and parameter servers to learn large-graph
embeddings on multiple CPUs using PyTorch. ReGNN develops ReRAM-based  architecture for GNN acceleration \cite{LLJLZDXL22}.

\spara{Synergy.}
Both graph embedding and GNN training are GML tasks. We showcase how GDM techniques can enhance them in four major ways: algorithms and systems, software-hardware co-design, and graph databases.

\noindent $\bullet$ {\em Efficient algorithms}. To improve efficiency and scalability of GNN training often at the cost of accuracy loss, mini-batch training and sampling strategies are developed, which can scale with data parallelism. Parallel and distributed training algorithms aim at reducing computation and communication overheads and design effective graph partitioning methods, all of which deal with irregularity, inter-connectedness, and sparseness in graph structure. Random walks approximate GNN message passing (e.g., APPNP \cite{KlicperaBG19}) and capture neighborhood structures for generating graph embedding. Therefore, improving the effectiveness of random walks, reducing their numbers and path lengths, as well as distributed random walk mechanisms have great potentials to improve the efficiency and scalability of GNN training and graph embedding. Efficient matrix factorization techniques can also gain superior performance and scale to embeddings of large-scale graphs.

\noindent $\bullet$ {\em Scalable systems}.
Multi-CPU and multi-GPU platforms are widely-adopted scalable systems for distributed GNN training and graph embedding. Multi-CPU platforms enable distributed GNN training across multiple machines. Multi-GPU platforms employ CPU-GPU collaborative solutions, where GPUs conduct GNN training/ embedding, whereas CPUs handle computationally intensive tasks, including sampling, random walks, and workload partition. Modern hardware, e.g., FPGA, SSD, and ReRAM enable training larger graphs on a single machine, while providing accelerations, fault-awareness, and energy-efficiency.

\noindent $\bullet$ {\em Software-Hardware co-design}. PyTorch Geometric (PyG) and Deep Graph Library (DGL) are common software paradigms for GNN training. They support CPU and GPU computing, full-batch and mini-batch training, also provide APIs and user-defined functions to abstract computation and communication. Using them, more advanced software frameworks, e.g., AliGraph \cite{ZhuZYLZALZ19}, DistGNN \cite{MdMMMGHKAA21}, and DistDGL \cite{Zheng0WZSSGZK20} are developed which define user-friendly programming models (e.g., vertex-centric paradigm) and efficient data structures. They employ software-hardware co-design to reduce computation and communication costs via different parallelization schemes (e.g., pipeline parallelism), optimization strategies (e.g., synchronous vs. asynchronous communication, parameter server),
on-chip data reuse, etc.


\noindent $\bullet$ {\em Graph databases}. Popular graph databases (graph DBs), e.g., Neo4J, ArangoDB, Amazon Neptune, TigerGraph, and K\`{u}zu provide data science libraries and ML tools to support a number of graph embedding methods and GNN training \cite{Khan23}. Graph DB's disk-based storage systems can be used with PyG remote backend to train a GNN model on very large graphs that do not fit on the main memory of a single server \footnote{\scriptsize{{https://blog.kuzudb.com/post/kuzu-pyg-remote-backend/}}}. While graph DBs currently provide only basic graph ML functionalities such as node classification and regression, link prediction, it would be interesting to seamlessly integrate graph embeddings and GNN's capabilities into graph query processing and question answering (QA) (\S\ref{sec:kg}), also enabling vector indexes for efficient similarity search to facilitate graph RAG paradigm in LLMs (\S\ref{sec:graphrag}). These highlight the potential of graph DBs to be coupled with ML-based QA systems and LLMs \cite{abs-2410-03867}.


\noindent $\bullet$ {\em Improving graph data pipeline}. Finally, efficient graph embedding and GNN training are key to many downstream applications, e.g., graph data cleaning, entity resolution, and knowledge graph question answering, ensuring effective, efficient, and robust graph data pipelines.

\subsection{Graph-based Vector Data Indexes}
\label{sec:index}

\medskip
\medskip

The management of vector data intersects with graph data management, particularly in systems that support graph-based machine learning (GML).
A prime example is the use of graph-based vector indices, e.g., HNSW~\cite{DML11, MYD18HNSW, FXWC19} to organize high-dimensional embeddings for retrieval tasks.
These embeddings often originate from GML models like Graph Neural Networks (GNNs)~\cite{KLJZL20, BMHCRMKD22}, where node or graph-level representations are computed for downstream applications.
This synergy between graph-based indices and GML pipelines positions GDM systems, including Neo4j and TigerGraph, as comprehensive platforms for building GML workflows, integrating data storage, embedding generation, and similarity search functionalities.


Graph-based indices~\cite{PWL23Survey} diverge from traditional indexing methods, such as inverted indices~\cite{BL14II,jds10ii}, locality-sensitive hashing~\cite{AILRS15, TZZ23DB}, and tree-based indices~\cite{BCG05, KS18TB}, which typically partition vectors into buckets.
Instead, graph-based indices construct proximity graphs, where nodes represent data points and edges denote neighbor relationships.
These graph-based approaches present unparalleled effectiveness by leveraging semantic similarities through the principle that a neighbor's neighbor is likely to be a neighbor and iteratively expanding neighbors' neighbors through a best-first search~\cite{FanL19, wang2022crux}.
Recent works substantiate their scalability, positioning them for handling billion-scale datasets~\cite{WXYW21}.
Unlike traditional graph data structures used for representing networked information, these indices are optimized for the Approximate Nearest Neighbor Search (ANNS)~\cite{AIR18anns, LZSWLZL19, WXYW21}, a task foundational to many AI-driven applications.
This makes them particularly relevant to GDM systems that serve as infrastructure for hybrid tasks combining traditional graph analysis and ML-based embedding retrieval.
The implications of such methods extend beyond ANNS, permeating into the fabric of LLMs~\cite{KLJZL20} and unstructured data management~\cite{HHGDAH13, WWWLZLC20}, heralding a new era in the intersection of graph-based data management and real-world applications.

Graph-based vector indices have been subject to a range of optimizations aimed at improving both the index structure and search procedures, which can be categorized into four key areas:

The first major category, {\em graph index optimization}, focuses on diversifying neighbor connections to enhance graph navigability and capture semantic relationships between embeddings, such as refining the quality of the edge set~\cite{FXWC19}, leveraging more sophisticated distance functions~\cite{DML11}, adaptive neighbor selection~\cite{peng2023efficient}, and hierarchical layouts~\cite{MYD18HNSW}.
These ensure that similar embeddings are efficiently connected and easily discoverable during search.
The index graph quality directly impacts downstream GML tasks like node classification and link prediction, where effective and efficient similarity assessments are critical for model performance.

The second set of optimizations focuses on enhancing search strategies to reduce traversal overhead while maintaining high query accuracy. This is particularly important when scaling graph-based models to larger datasets, as the cost of inefficient traversal can quickly overwhelm the benefits of an optimized index.
{\em Routing optimizations} address this challenge by refining key aspects such as entry point acquisition~\cite{lu2021hvs, zhao2023towards}, routing strategy~\cite{gao2023high, yue2023routing, LXI24Pro, yue2023routing}, and termination conditions~\cite{li2020improving, zhang2023vbase}.
By combining these strategies, routing optimization ensures that even in large-scale GML datasets, searches remain fast and precise, minimizing the impact of increasing data size on performance.

Building on these search optimizations, the third category focuses on scaling solutions through {\em hardware-aware optimizations}, which adapt the index layout and search strategies to specific hardware capabilities~\cite{WXYWPKGXGX24}.
Graph-based methods have been implemented in {\em external memory} such as heterogeneous memory (HM)~\cite{ren2020hm} and solid-state disk (SSD)~\cite{jayaram2019diskann}, to scale the system beyond traditional memory limitations.
A recent work~\cite{jang2023cxl} has adapted graph-based indexes to the cutting-edge compute express link (CXL) architecture.
In addition, {\em acceleration hardware} such as GPUs and FPGAs are utilized to parallelize vector computation~\cite{zhao2020song, ootomo2024cagra, manohar2024parlayann} or data structure maintenance~\cite{yu2022gpu}, providing an order of magnitude increase in efficiency for both index construction and search,
These innovations exemplify how {\em software-hardware collaboration} enables scalable solutions for embedding-intensive GML tasks, addressing computational bottlenecks in GML workflows.

The fourth line of research integrates additional information into graph indices to further support more sophisticated retrieval scenarios, a critical need for complex graph ML workflows.
Techniques such as attribute-based filtering~\cite{wang2023efficient, gollapudi2023filtered, PKGZ24ACORN, ZQZLD4SERF} incorporate structured attributes directly into the index, enabling hybrid queries that combine structured and unstructured data.
For instance, in {\em multimodal search} scenarios, where each entity comprises multiple vectors, {\em multiple} graph indexes may be constructed and scanned to address a multi-vector query~\cite{wang2021milvus,zhang2023vbase}.
An innovative approach \cite{WKXCGHZ24} has fused multiple embeddings into a unified graph index with automatic weight learning, enabling efficient and accurate multimodal queries.
These methods have demonstrated applicability in ML-powered systems, such as LLM-based online query answering~\cite{WWKGXC24}, further bridging the gap between advanced data management and real-world applications.

\spara{Synergy.}
We illustrate how advancements in graph-based vector indices, a core GDM technique, significantly contribute to the scalability and efficacy of GML systems.

\noindent $\bullet$ {\em Efficient embedding management.}
Graph indices excel at managing high-dimensional embeddings generated by GML tasks, such as node classification and link prediction. By leveraging optimizations in graph structure and search procedures, including neighbor diversification, efficient routing, and hardware acceleration, these indices enable faster and more precise similarity searches essential for embedding-driven GML workflows.

\noindent $\bullet$ {\em Scalable multimodal integration.}
For multimodal GML tasks, where nodes or entities are represented by multiple embeddings, graph indices adapt to efficiently handle hybrid and multimodal queries. Techniques like fused graph indices allow simultaneous processing of multiple data modalities, directly benefiting use cases like multimodal knowledge retrieval and enhanced representation learning in large-scale systems.

\noindent $\bullet$ {\em Hardware acceleration for GML.}
The alignment of graph indices with emerging hardware architectures, such as GPUs, FPGAs, and CXL, drives substantial improvements in computation and memory efficiency. These optimizations enable graph ML systems to scale effectively, overcoming the limitations of traditional memory-based approaches for embedding-intensive workloads.

\noindent $\bullet$ {\em Enhanced machine learning pipelines.}
By integrating attribute filtering, handling incomplete data, and accommodating large-scale retrieval, graph indices bolster the robustness of GML pipelines. This ensures reliable and efficient data processing for tasks such as hybrid query answering, anomaly detection, and fair representation learning. The adaptability of graph indices to evolving GML requirements demonstrates their critical role in enabling complex, real-world applications.


\subsection{GNN Explainability}
\label{sec:explainability}

\medskip
\medskip

To safely and trustfully deploy deep neural models, it is critical to provide human-intelligible explanations to end users and domain experts: {\em Which aspects of the input data drive the decisions of the model?} Therefore, explainability methods for GNNs are becoming popular.

Deriving and comparing GNN explanations are difficult. {\bf (1)} There is no unique notion of explainability -- the requirements arise due to many factors, e.g., trust, causality, transferability, fair decision making,  model debugging, informativeness, etc. \cite{Lipton18,KimD21}. {\bf (2)} Analogously, several quantitative metrics
such as fidelity, sparsity, contrastivity, and stability are proposed to evaluate explanation quality. It may be required to modify these metrics to capture the complex dependency of structure and feature in the graph space. For instance,
perturbation-based metrics (e.g., fidelity) can drastically change the graph's structure, resulting in data outside the training distribution. Instead, a standard practice is to consider ``milder'' perturbations by removing associated features of important nodes and edges, while keeping the graph structure intact \cite{PKRMH18,yuan2022explainability}. {\bf (3)} Due to the emerging nature of graph data and downstream tasks, there has been less qualitative evaluation of GNN explainability (e.g., human grounded evaluation) \cite{VT20,abs-2206-13983}. Lack of real-world ground-truth explanations, complexity in graph data, and requirement of expert domain knowledge are key bottlenecks behind qualitative evaluation. {\bf (4)} The output of GNN explainability (e.g., nodes, edges, features, subgraphs) and their categories (e.g., factual vs. counterfactual, instance vs. model-level) are different. For a holistic evaluation, such factors must be considered \cite{KM23}. {\bf (5)} Other concerns include non-robust GNN models and training bias \cite{FMW21}.

Recently, many explainability methods for GNNs have been developed, which can be categorized across several dimensions \cite{yuan2022explainability,KJSAM23,KM23}.
{\em Self-explanatory} approaches incorporate explainability directly into GNN models, e.g., \cite{DW21,ZhangLWLL22}.
{\em Post-hoc} methods \cite{YingBYZL19,FKA21,LCXYZCZ20,YTHJ20,SCT21,VT20,YuanYWLJ21} create a separate model to provide explanations for an existing GNN.
In {\em global} explanation methods, users understand how the model works globally by inspecting the structures and parameters of a GNN model, or by generating graph patterns which maximize a certain prediction of the model \cite{YTHJ20}. In contrast, {\em local} methods examine an individual prediction of a model, figuring out why the model makes the decision on a specific test instance \cite{YingBYZL19,FKA21,SCT21,VT20,YuanYWLJ21}. {\em Forward} explainability methods are GNN model-agnostic by learning evidences about graphs or nodes passed through the GNN. They can be {\em perturbation-based}, that is, masking some node features and/or edge features and analyzing the changes when the modified graphs are passed through GNNs \cite{YingBYZL19}. They might also employ a simple, explainable {\em surrogate model} to approximate the predictions of a complex GNN \cite{VT20}. In contrast, {\em backward} interpretability methods are GNN model-specific and can be either {\em gradient-based} \cite{PKRMH18} -- backpropagating importance signals backward from the output neuron of the model to the individual nodes of the input graph, or {\em decomposition-based} \cite{SchnakeELNSMM22} -- distributing the prediction score in a backpropagation manner until the input layer. Thus, one identifies which nodes, edges, and features contribute the most to the specific output label in the GNN. Furthermore, GNN explainability methods can be classified as {\em factual} (i.e., finding a subgraph whose information is sufficient -- which, if retained, will result in the same prediction), {\em counterfactual} (i.e., finding a subgraph that is necessary -- which, if removed, will result in a different prediction), or both \cite{TGFGXLZ22}.


However, existing approaches in this field are limited to providing explanations for individual instances or specific class labels.
The main focus of these methods is on defining
explanations as crucial input features, often in the shape of numerical encoding.
These methods generally fall short in {\em providing targeted and configurable explanations for multiple class labels of interest}.
Additionally, existing methods may return large explanation structures
and hence are not easily comprehensible. These explanation structures often lack direct accessibility
and cannot be queried easily, posing a challenge for expert users who seek to
inspect the specific reasoning behind a GNN's decision based on domain knowledge.

A recent work, GVEX \cite{ChenQWKKG24} proposes a novel two-tier explanation
structure called {\em explanation views}. An explanation view (similar to {\em graph view}) comprises a collection of graph patterns along with a set of induced explanation subgraphs.
Given a database of multiple graphs and a specific class label assigned by a GNN-based classifier, lower-tier
subgraphs provide insights into the reasons behind the assignment of the label by the classifier. They
serve as both factual (that preserves the result of classification) and counterfactual explanations
(which flips the result if removed). On the other hand, the higher-tier patterns summarize the subgraphs
using common substructures for efficient search and exploration
of these subgraphs. Analogously, RoboGExp \cite{QWKW24} introduces a new class of explanation structures to provide robust, both counterfactual and factual explanations for graph neural networks. Given a GNN, a robust explanation refers to the fraction of
a graph that are counterfactual and factual explanation of the results of the GNN over the graph, but also remains so for any ``disturbance'' by flipping up to $k$ of its node pairs.
In particular, such explanation indicates ``invariant'' representative structures
for similar graphs that fall into the same group, i.e., be ``robust'' to small
changes of the graphs, and be both ``factual'' and
``counterfactual''. Both GVEX and RoboGExp also emphasize effective, efficient, and scalable explanation generation by providing theoretical approximation guarantees and developing parallel and streaming algorithms.

\spara{Synergy.} We depict how GDM assists in generating better GNN explanations, which is a GML task.

\noindent $\bullet$ {\em Useful explanations}. First, explanations should not only dissect the decision-making process of GNN models, but can also {\em zoom in/out} on how certain features, nodes, or subgraphs contribute to specific classifications, that is, explanations can be provided across multiple granularity of concept hierarchy depending on the needs of end users. Moreover, enhancing the {\em accessibility}, {\em configurability}, and {\em queryability} of explanations
is crucial. Graph view-based two-tier explanations in GVEX \cite{ChenQWKKG24} provide the first step in this direction, and a natural extension might be generating an explanation OLAP cube that can be drill up/down based on domain-specific requirements.
Second, explanations should be presented in a {\em user-friendly} manner, possibly through
visualizations or interactive tools that allow users to explore and interrogate GNNs' decisions. These tools could enable desirable capabilities, e.g., highlighting critical substructures, providing interactive interfaces, and allowing tunable parameters for domain experts to ``query'' the model about its decisions. It is paramount to think beyond ``explanation of GNN models'' and towards ``explanations for users'' to enable trust and effective deployment.


\noindent $\bullet$ {\em Efficient explanations}. Past research on explanation generation often does not emphasize on efficiency and scalability, e.g., requiring more than one day to generate an explanation over large-scale graphs \cite{ChenQWKKG24}. Real-time explanations are key to interactiveness, configurability, queryability, and in-depth exploration of GNNs' decision making process.
Parallel, streaming, and anytime algorithms, modern hardware, and software-hardware co-design have potentials to reduce explanation time.


\noindent $\bullet$ {\em Diversified explanations}.
As stated earlier, several quantitative metrics, e.g., fidelity, sparsity, contrastivity, and stability are designed to evaluate explanation quality; however, no single measure is the best. It is important to pursue explanations that optimize
multi-objective quality criteria, while also improving diversity. Concepts from databases, such as Pareto optimality and a skyline set
of explanatory subgraphs can be useful.


\noindent $\bullet$ {\em Better explanations to improve data pipeline}.
Finally, explanations can reveal unfairness in GNN's decision making process, detect anomalies and potential threats, help in model debugging, and  assist organizations in meeting compliance and regulations, thereby improving the robustness of graph data pipeline.



\section{Graph ML for Graph \\ Data Management}
\label{sec:gml4gdm}

\medskip
\medskip

We illustrate applications of graph machine learning and graph-based LLMs in knowledge graphs
query answering and other data science tasks.

\subsection{Knowledge Graphs Query Answering}
\label{sec:kg}

\medskip
\medskip


Query answering over datasets is an important data management task. We consider knowledge graph (KG) -- a graph-based data model to store facts -- denoted as $\langle$subject, predicate, object$\rangle$ triples, or a large-scale graph having nodes (subjects and objects) and edges (predicates) \cite{WeikumDRS21}. Querying KGs is critical for web search, semantic search, fact checking, and personal assistants. However, it is difficult due to their massive volume, heterogeneity, incompleteness, and schema flexibility. Additionally, a user's query (e.g., natural language query or query graph) may not match exactly w.r.t. entities, relations, and structure of the KG, requiring approximate matches to retrieve relevant answers \cite{Khan23}.


Machine learning assists in {\bf (1)} inferencing over KGs to identify missing relations during query answering, and also {\bf (2)} finding approximate matches for queries \cite{Abdallah023,HorchidanC23,abs-2303-14617}. {\bf (3)} Natural language queries (NLQs) are semantically parsed to structured queries (e.g., SPARQL queries over KGs) using neural approaches \cite{QuamarELO22}. {\bf (4)} More recent techniques employ sequential models for end-to-end answering of NLQs over KGs, e.g., KEQA \cite{HuangZLL19} for simple NLQs and EmbedKGQA \cite{SaxenaTT20} for multi-hop NLQs. {\bf (5)} KG embedding methods can be useful as well. Wang et al. \cite{WangKXJHF22,0001KWJY20} decompose multi-hop and complex queries into smaller subqueries, answer each subquery via single-hop reasoning with KG embedding, and then assemble the answers. In contrast,  Query2box \cite{RenHL20}  and follow-up works
train on multi-hop queries
â€“ they embed multi-hop logic queries and their answers (i.e., entities
from a KG) in the same embedding space to reduce the query processing cost via inference.

Domain-specific knowledge graphs (KGs)~\cite{wang2022crux, li2020kg}
have been curated to host scientific,
factual knowledge rather than
generic Web or common knowledge,
such as KGs in material
science, healthcare, medicine, education,
cybersecurity, biology, and chemistry.
While knowledge curation has been extensively
studied, searching
domain data remains nontrivial.
Domain experts are still expected to
write complex declarative queries (such as
SPARQL), or data scripts to access KGs. There is a
gap between the need of accessing KGs with
(domain) languages
and optimized
query processing within
state-of-the-art KG data systems.
The rise of large language models (LLMs),
such as GPT provides promising capabilities in
generating natural language solutions in response to
users' prompts.
There are efforts on linking
LLMs to KG search and exploration~\cite{PanLWCWW24}, as well as LLM-based
knowledge graph
exploratory search~\cite{graphlingo}.
KG-enhanced, LLM-based QA is also studied: QAGNN \cite{YasunagaRBLL21} and GreaseLM \cite{ZBYRLML22} fine-tune a vanilla LM with a KG on downstream tasks, whereas DRAGON \cite{YasunagaBR0MLL22} and JAKET \cite{Yu0Y022} perform self-supervised pre-training from both text and KGs at scale.

\spara{Synergy.}
Query processing is the bread-and-butter for the data management community.
We highlight how GML and LLMs assist in KG querying and QA.

\noindent $\bullet$ {\em Natural language query processing}. Natural language interfaces to databases (NLIDB) is the holy grail for query interface to DBs -- automatically translating natural language questions (NLQs) to structured queries (e.g., SQL) that can be processed by a database management system. With the prevalence of graph data (e.g., domain-specific KGs) and the standardization of graph query languages (GQL), there is an emerging need to covert NLQs to graph queries, e.g., Cypher, SPARQL, Gremlin, GSQL, PGQL, etc. This is more challenging due to the complexity and expressivity of graph queries, coupled with the schema-flexibility and heterogeneity in graph data. GNNs and LLMs can assist in these tasks because of their understanding of contexts in conversational QA, background knowledge, and capability of dealing with natural language text. For instance, Neo4J recently developed NeoDash\footnote{\scriptsize{{https://neo4j.com/labs/neodash/2.4/user-guide/extensions/natural-language-queries/}}} which leverages LLMs to interpret user's input NLQs and generates Cypher queries based on the provided schema definition.


\noindent $\bullet$ {\em Approximate query processing}.
KGs are schema flexible, i.e., similar relationships between entity pairs can be represented in different ways. Therefore, one needs to construct various query patterns to retrieve all relevant answers from the underlying dataset, which is challenging. This necessitates approximate matches w.r.t. users' queries by understanding the query intent -- KG embedding and KG + query embedding approaches can support approximate matching via inference.


\noindent $\bullet$ {\em Query processing over incomplete data}.
KGs follow the open-world assumption, i.e., they are incomplete. To retrieve the complete set of answers for a given query, one must infer missing relations in KGs. In contrast, relational DBs generally follow the closed-world assumption with the presumption that all relevant knowledge is explicitly stored within the DB. Additionally, dealing with missing graph structure is more challenging than imputing missing feature values. ML-based link prediction and multi-hop inference techniques can be coupled with graph queries to resolve these problems.


\noindent $\bullet$ {\em Multimodal and multilingual data and queries}.
Entities and relations in a KG can have features with different data modalities, e.g., text, images, and multimedia data. Analogously, text data in node features and queries can be in different languages. Dense vector embedding of multimodal and multilingual data, obtained via deep models, provide a unique opportunity to query such heterogeneous data. Data management techniques can also contribute in querying vector data with high-dimensional indexes and join, leveraging modern hardware and geometric data processing.


\noindent $\bullet$ {\em Graph databases and query optimization}.
ML approaches, e.g., deep learning, reinforcement learning, and LLMs have shown promises in optimizing database queries and enhancing database administration functions such as query optimization, workload management, indexing, and storage layouts. Although there are recent developments in deep learning methods for graph pattern search and cardinality estimation \cite{ZYZLR21},
more work is needed in AI-facilitated graph databases and query optimization.
Graph ML algorithms could play a pivotal role in predicting access patterns, node importance, learning graph indexes based on query characteristics. By leveraging historical usage data and graph topology, these systems can autonomously adapt storage strategies and retrieval
mechanisms to match the evolving needs.


\subsection{Graph RAG-based LLMs in Data Science Applications}
\label{sec:graphrag}

\medskip
\medskip

LLMs which are a category of generative AI models and proficient at generating new text contents, offer a myriad of opportunities in data science by automating data analysis, manipulation, querying, and interpretation, as well as in code synthesis, digital assistants, finance, law, and education. Nevertheless, due to poor reasoning capacity, outdated or lack of domain knowledge, expensive re-training costs, and limited context lengths of LLMs, LLM-based data science pipelines often struggle with complex tasks -- they hallucinate, i.e., generate factually incorrect, or even harmful contents. To address these issues, KGs are used as background knowledge to enhance LLMs for downstream tasks. The questions are parsed to identify relevant subgraphs from KGs, then they are integrated and fused with LLMs based on knowledge integration, prompt augmentation, and retrieval augmented generation (RAG). This framework, known as graph RAG or KG-RAG \cite{XuCGWDWL24}, is increasingly becoming popular due to its ability
to capture the global context, compared to conventional RAG that retrieves knowledge from embeddings of textual chunks.


Recent works \cite{mavromatis2024gnnraggraphneuralretrieval,he2024g,WLRSZD24,WHBQRXS23} develop
KG-unified language models in a graph RAG style.
They can be broadly categorized into two groups according to the roles of KGs: {\bf (1)} KGs as background knowledge, and {\bf (2)} KGs as reasoning
guidelines. While the former only retrieves relevant subgraphs as contexts based on input questions, the later retrieves the most relevant paths adaptively to guide the LLMâ€™s reasoning process \cite{SXTWLGSG24}. Graph RAG is further added within LLM-based agent systems to leverage structured knowledge for enhanced decision-making and problem-solving capabilities \cite{SunTLA24}.


\spara{Synergy}.
Besides GDM, effective text or vector processing may benefit graph RAG. For example, {\bf (1)} What is the proper data model to represent and feed the retrieved knowledge to the LLM? Options include prompt-based or embedding-based data model.
For the former, prompt engineering can be explored, such as serializing subgraphs to token sequences or $\langle$subject, predicate, object$\rangle$ triples, to best exploit LLMs'
ability of text (natural language) processing.
The latter can be better supported by vector databases (see \S~\ref{sec:index}).
{\bf (2)} How to design indexes, search algorithms, and systems for more complex and hybrid vector search, including graph traversal with vector retrieval? Those may require unifying graph DBs and vector DBs as external memory of LLMs. {\bf (3)} Graph query optimization, (explanatory) views, and provenance can help in making graph RAG
 better grounded by linking LLM response to
 factual knowledge at scale. {\bf (4)} Last but not least,  graph DBs may be used as ``semantic caches'' of LLMs by indexing previous question-answer pairs into a graph or vector space, enabling semantic
matching with new queries instead of more expensive LLM API calls.
These create new opportunities for GDM and broader data management
techniques to play
critical roles for graph RAG systems.


\section{Related Work}
\label{sec:related}

\medskip
\medskip

The closest to our work are surveys and tutorials on ML for data management
and data management for ML, emphasizing on relational
data and RDBMS \cite{ChaiWLNL23,
Kumar0017,Polyzotis0WZ17,HulsebosDSP23}.
However, graph data result in unique challenges to both data management and ML (\S\ref{sec:introduction}), justifying the importance of our survey.


Additionally, there are related surveys and tutorials on, e.g., graph representation learning \cite{CaiZC18,CuiWPZ19}, graph neural networks \cite{WuPCLZY21,ZhangCZ22,ma2021deep}, AI for data preparation \cite{Chai0FL23}, the role of graph data in graph ML \cite{abs-2309-10979}, distributed GNN training \cite{ShaoLGYLMZCC24}, explainable AI in data management \cite{PradhanLGS22}, ML explainability and robustness \cite{DattaFLLSW21}, LLM+KG \cite{PanLWCWW24}, and high-dimensional vector similarity search \cite{EchihabiPZ21}, etc.
However, none of them investigate the synergy of GDM and GML. To the best of our knowledge, ours is the first survey exploring the synergies between graph data management and graph ML over the end-to-end graph data pipeline. We hope that our survey will bridge the gap between these two popular domains -- GDM and GML, and would inspire others to work on the emerging graph data challenges at their intersection.

\section{Future Directions}
\label{sec:conclusions}

\medskip
\medskip

Future work can be in several directions.

\spara{Real-time Graph Learning and Inference}.
The integration of
spatiotemporal GNNs
and dynamic graphs would enable
the real-time decision that can rapidly
explore evolving nodes and links. This calls for
adaptive graph query processing and optimization,
online graph learning, and real-time inference at scale.
Graph analysis in finance, healthcare,
security, and
manufacturing will
benefit significantly from this capability.

\spara{Privacy-preserving Graph ML}.
As the usage of graph data expands, so does the concern for privacy and security. Future developments in the synergy between graph machine learning and data management could delve into advanced privacy-preserving techniques for graph data. This might involve the integration of federated learning approaches, differential privacy, or novel encryption methods tailored to the unique characteristics of graph structures. Ensuring the confidentiality of sensitive graph information, while still extracting valuable insights, poses an exciting challenge.

\spara{Robust Graph ML}.
GNNs can be sensitive under a set of link perturbations or adversarial attacks. ML communities have investigated several approaches on how to quantify and improve the robustness of graph learning, e.g.,  certifiable robustness. Data management techniques such as graph sparsification and cleaning can also be employed. In the past, data imputation and integration for graphs
have been extensively studied with the objective of data correctness and completeness, instead it would be interesting to clean graphs for optimizing the robustness of graph learning.


\spara{Unifying LLMs+KGs+Vector DBs}.
Knowledge bases such as KGs and data lakes support holistic integration for multimodal
data arriving from heterogeneous sources, including tabular, key-value pairs, text, images, and multimedia data. Vector embedding represents each predicate and entity from diverse sources as a low-dimensional vector,
such that the original structures and relations in the knowledge base are approximately preserved.
Querying these vectors are essential for a wide range of applications, e.g., question answering and
semantic search.
Finally, LLM pipelines are generally faster than traditional ML lifecycles --
thanks to simpler prompt-based interactions without any requirement of re-training, making it easy to build AI pipelines around LLMs. Thus, the unification of three modern technologies LLMs, KGs, and vector DBs seem indispensable.
There also remain many fundamental challenges, e.g.,  how to create a holistic embedding across multiple modalities and diverse data formats?
It remains a desirable yet nontrivial task to explain the results of LLMs and to incorporate domain knowledge -- KGs could assist in both objectives following graph RAG approaches. Analogously, adding human-in-the-loop and analyzing utility vs. privacy, bias, and fairness to derive quality solutions are important.

\section{Acknowledgment}
\label{sec:ack}

\medskip
\medskip

Khan acknowledges support from the Novo Nordisk Foundation grant NNF 22OC0072415. Ke is supported by Zhejiang Province's ``Lingyan'' R\&D Project under Grant No. 2024C01259 and Yongjiang Talent Introduction Programme (2022A-237-G). Wu is supported by NSF under CNS-1932574, CNS-2028748, and OAC-2104007.

\balance


\begin{small}
\bibliographystyle{abbrv}
\bibliography{ref}
\end{small}

\end{document}
