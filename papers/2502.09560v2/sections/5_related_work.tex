\section{Related Work}

% \heng{also add discussion about VLM learned from instruction videos and game videos; add more papers related to digital twin and simulation} # we can add more citations in appendix due to the limited space



In embodied agent research, LLMs are primarily used to support high-level planning \cite{ahn2022can, huang2022language, huang2022inner, yao2022react, huang2023grounded, rana2023sayplan, chen2023robogpt, gao2024physically}. MLLMs are then integrated for perception-related tasks \cite{ViStruct2023, actionpatch2023, gao2024physically}. Beyond perception, MLLMs also contribute to decision-making, either by directly generating actions in an end-to-end manner \cite{shridhar2022cliport, driess2023palm, du2023video, mu2024embodiedgpt} or by producing code to develop policy or value functions \cite{liang2023code, huang2023voxposer}.


As this field rapidly evolves, a variety of simulators \cite{kolve2017ai2, shridhar2020alfred, xiang2020sapien, li2021igibson, li2023behavior} and evaluation benchmarks \cite{shridhar2020alfworld,shridhar2020alfred,james2020rlbench,zheng2022vlmbench,szot2023large,liu2023agentbench,liu2024visualagentbench,choi2024lota,li2024embodied,zhang2024vlabench,cheng2025embodiedeval} have emerged. Table \ref{table:comparison} provides a comprehensive comparison with existing works, highlighting how \name sets itself apart from prior works in several aspects. More related works are listed in Appendix \ref{ap:additional_related_works}.



