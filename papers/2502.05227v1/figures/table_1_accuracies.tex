\begin{table}[!h]
    \small
    \centering
    \begin{tabular}{llllllll}
        \toprule
        & \multicolumn{3}{c}{\textbf{Synchronous (\%)}} & \multicolumn{3}{c}{\textbf{Asynchronous (\%)}} \\ 
        \cmidrule(r){2-4} \cmidrule(r){5-7}
        & \textbf{I/O} & \textbf{I/O CoT} & \textbf{ReAct} & \textbf{I/O} & \textbf{I/O CoT} & \textbf{ReAct} \\ 
        \midrule
        \gptfo{} & 4.00 & 14.0 & \textbf{47.0} & 1.00 & 1.00 & \textbf{11.0}       \\
        \texttt{gpt-4o-mini} & 4.00 & 10.0 & 11.0 & 0.00    & 1.00 & 0.00     \\
        % \texttt{gpt-4-0125-preview}   &     &               &       \\
        % \texttt{gpt-4-0613}   &     &               &       \\
        % \texttt{gpt-3.5-turbo-0125} &     &               &       \\
        \texttt{gemini-1.5-flash} & 0.00 & 13.0 & 0.00 & 0.00 & 0.00 & 0.00      \\
        % \texttt{gemini-1.5-pro} &     &               &       &     &               &       \\
        % \texttt{gemini-1.0-pro} &     &               &       \\
        % \texttt{claude-3.5-sonnet} &     &               &       &     &               &       \\
        % \texttt{claude-3-opus} &     &               &       \\
        % \texttt{claude-3-sonnet} &     &               &       \\
        \texttt{claude-3-haiku} & 1.00 & 2.00 & 2.00 & 0.00 & 0.00 & 0.00      \\
        % \midrule
        % \texttt{Meta-Llama-3.1-70b-Instruct}  &     &               &       &     &               &       \\
        % \texttt{Meta-Llama-3.1-8b-Instruct}  &     &               &       &     &               &       \\
        % \texttt{Meta-Llama-8b-Instruct}  &     &               &       &     &               &       \\
        % \texttt{Llama-2-70b-chat-hf}  &     &               &       &     &               &       \\
        % \texttt{Llama-2-13b-chat-hf}  &     &               &       &     &               &       \\
        % \texttt{Llama-2-7b-chat-hf}  &     &               &       &     &               &       \\
        % % \texttt{Qwen2-72B-Instruct}  &     &               &       &     &               &       \\
        % % \texttt{Qwen2-7B-Instruct}  &     &               &       &     &               &       \\
        % \texttt{Mixtral-8x22B-Instruct-v0.1}  &     &               &       &     &               &       \\
        % \texttt{Codestral-22B-v0.1}  &     &               &       &     &               &       \\
        % \texttt{Mamba-Codestral-7B-v0.1} &     &               &       &     &               &       \\
        % \texttt{Phi-3.5-MoE-instruct}  &     &               &       &     &               &       \\
        % \texttt{Phi-3-medium-4k-instruct}  &     &               &       &     &               &       \\
        % \texttt{Phi-3-small-128k-instruct}  &     &               &       &     &               &       \\
        % \texttt{gemma-2-27b-it} &     &               &       &     &               &       \\
        % \texttt{gemma-2-9b-it} &     &               &       &     &               &       \\
        \bottomrule
    \end{tabular}
    \caption{Success rates of state-of-the-art LLMs on the synchronous and asynchronous datasets.}
    \label{tab:successes}
\end{table}