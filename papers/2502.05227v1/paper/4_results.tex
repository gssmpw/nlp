\vspace{-1em}
\section{Experiments}
\vspace{-1em}

\subsection{Baselines}

We evaluate LLMs on \robotouille{} using the following baselines: \io{}, \iocot{}, and \react{}. \io{} takes as input the initial state, including valid actions and goal, and outputs an plan directly. \iocot{} \citep{wei2023chainofthoughtpromptingelicitsreasoning} also takes as input the initial state but outputs a plan with chain of thought before each action that estimates the resulting state. Instead of outputting the entire plan, \react{} \citep{yao2022react} outputs reasoning and the next action given the current state, and receives the next state before repeating. 
We use an ablated version of \react{} that only keeps the reasoning and action of the previous timestep in context (along with the base prompt and in-context examples); the improved performance and cost-effectiveness is detailed in Appendix~\ref{app:react-ablations}. 
Each baseline receives a single in-context example on a training example excluded from the testing set. We use temperature 0.7 for all models. All prompts and few-shot examples are located in our codebase \href{https://github.com/portal-cornell/robotouille}{here}.
%are included in Appendix~\ref{app:prompts}.

% \textbf{Metrics} We use 4 different metrics to evaluate LLM baselines. Success rate is determined by reaching the goal within 1.5 times the optimal number of steps for the given instance. Steps to go is the optimal number of steps to reach the goal from the final state of a failure; this metric is normalized with the optimal number of steps to reach the goal from the initial state. Optimality rate is the ratio between the number of steps taken and the optimal steps to reach the goal. Repeated transitions are the number of duplicate transitions included in the plan.
% % \GG{Some formulas here would make things more concrete. Can introduce after problem formulation has consistent math}

\subsection{Results and Analysis}

% \subsubsection{Overall Results}
% \begin{itemize}[leftmargin=*]
%     \item The best baseline, \gptfo{} \react{}, only achieves 47\% on the synchronous dataset and 11\% on the asynchronous dataset. See Sec~\ref{sec:success}.
%     \item Dominant failure modes on the asynchronous dataset are similar to those in the synchronous dataset indicating that simple LLM failures are inhibiting asynchronous planning. See Sec~\ref{sec:failures}.
%     \item Further investigations on the low asynchronous performance reveal that better feedback incorporation and reliable self-verification are crucial future work directions to boost performance. See Sec~\ref{sec:follow-ups}.
% \end{itemize}

\subsubsection{Overall Takeaways}
\begin{itemize}[leftmargin=*]
    \item \textbf{Closed-loop agents are superior}: The best baseline, \gptfo{} \react{}, achieves 47\% on the synchronous dataset and 11\% on the asynchronous dataset, surpassing open-loop approaches \io{} and \iocot{} (Finding 1, Sec~\ref{sec:success}).
    \item \textbf{Poor feedback incorporation leads to decreased asynchronous performance}: Despite being closed-loop, \gptfo{} \react{} failures often make little progress towards the goal (Finding 3, Sec~\ref{sec:success}) due to poor failure recovery (Finding 5, Sec~\ref{sec:failures}). We find that boosting priors improves performance (Finding 7, Sec~\ref{sec:follow-ups}) but discuss better feedback methods in Section~\ref{dis:feedback}.
    \item \textbf{Synchronous and asynchronous failures are closely related}: Both synchronous and asynchronous failures are dominated by rule violations and goal misinterpretation (Finding 4, Sec~\ref{sec:failures}). We hypothesize that this is due to poor failure recovery (Finding 5, Sec~\ref{sec:failures}) and agents that recover efficiently could boost performance in both settings.
    \item \textbf{Task prioritization is critical in asynchronous planning}: Proper prioritization of subtasks in asynchronous settings significantly boosts performance (Finding 6, Sec~\ref{sec:follow-ups}).
\end{itemize}

\subsubsection{Success and Optimality}
\label{sec:success}

\input{paper/4.1_success_and_optimality}

\subsubsection{Failure Mode Analysis}
\label{sec:failures}

\input{paper/4.2_failure_modes}

\subsubsection{Follow-Up Investigation}
\label{sec:follow-ups}

\input{paper/4.3_follow_ups}