We attempted to increase performance on the asynchronous dataset by benchmarking 2 new baselines. We introduced PLaG (BaG) \cite{lin2024graphenhancedlargelanguagemodels}, which creates an explicit graph representation of the task with an adjacency list. We adapt this method to multi-turn settings by making \react{} construct the graph representation at each step. We also introduce Reflexion \cite{shinn2023reflexionlanguageagentsverbal} by allowing \react{} 2 attempts at an environment, keeping a reflection of the first failed attempt in context. We present results in Table~\ref{tab:other-async-baselines}.

\begin{table}[H]
    \small
    \centering
    \begin{tabular}{llll}
        \toprule
        & \textbf{ReAct} & \textbf{PLaG} & \textbf{Reflexion} \\
        & & \textbf{(BaG)} & \\
        \midrule
        \multicolumn{4}{c}{\textbf{Asynchronous (\%)}} \\
        \midrule
        $\hyperref[fig:0_async]{[1 ]}$ \includegraphics[width=1.5cm]{assets/task_specific_assets_expanded_svg/0_async.pdf} & 20.0 & 20.0 & \textbf{30.0}       \\
        $\hyperref[fig:1_async]{[2 ]}$ \includegraphics[width=1.5cm]{assets/task_specific_assets_expanded_svg/1_async.pdf} & 30.0 & 30.0 & \textbf{50.0}       \\
        $\hyperref[fig:2_async]{[3 ]}$ \includegraphics[width=2cm]{assets/task_specific_assets_expanded_svg/2_async.pdf} & \textbf{40.0} & 20.0 & \textbf{40.0}      \\
        $\hyperref[fig:3_async]{[4 ]}$ \includegraphics[width=2cm]{assets/task_specific_assets_expanded_svg/3_async.pdf} & 10.0 & \textbf{30.0} & 10.0      \\
        $\hyperref[fig:4_async]{[5 ]}$ \includegraphics[width=2.5cm]{assets/task_specific_assets_expanded_svg/4_async.pdf} & 0.00 & 10.0 & 10.0 \\
        $\hyperref[fig:5_async]{[6 ]}$ \includegraphics[width=1.0cm]{assets/task_specific_assets_expanded_svg/5_async.pdf} & 10.0 & 20.0 & \textbf{30.0}      \\
        $\hyperref[fig:6_async]{[7 ]}$ \includegraphics[width=2.0cm]{assets/task_specific_assets_expanded_svg/6_async.pdf} & 0.00 & 0.00 & 0.00      \\
        $\hyperref[fig:7_async]{[8 ]}$ \includegraphics[width=2.5cm]{assets/task_specific_assets_expanded_svg/7_async.pdf} & 0.00 & 0.00 & 0.00      \\
        $\hyperref[fig:8_async]{[9 ]}$ \includegraphics[width=3.5cm]{assets/task_specific_assets_expanded_svg/8_async.pdf} & 0.00 & 0.00 & 0.00      \\
        $\hyperref[fig:9_async]{[10]}$ \includegraphics[width=5cm]{assets/task_specific_assets_expanded_svg/9_async.pdf} & 0.00 & 0.00 & 0.00      \\
        \midrule
        \textbf{Total}   & 11.0 & 13.0 & \textbf{17.0} \\
        \addlinespace[0.5em]
        \bottomrule
    \end{tabular}
    \caption{\gptfo{} performance on the asynchronous dataset over various baselines.}
    \label{tab:other-async-baselines}
\end{table}

We observe that PLaG (BaG) achieves a 2\% performance increase over \react{} and Reflexion achieves a 6\% performance increase over \react{}. We expected PLaG (BaG) to perform relatively similar to our \react{} baseline because our few-shot examples for \react{} construct a language graph representation for the task. Reflexion has a larger performance increase but at the cost of retrying runs which is very expensive for long horizon tasks. These results highlight that future work should investigate how LLM agents can optimally represent asychronous tasks and cost-effective methods for incorporating feedback to recover from errors.