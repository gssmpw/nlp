\documentclass{article} % For LaTeX2e
\usepackage{style/iclr2025_conference,times}

% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{style/math_commands.tex}

\usepackage{hyperref}
\usepackage{url}
\iclrfinalcopy

\input{misc/packages}
% \title{Robotouille: Benchmarking Temporal Planning for Language Models in Cooking Tasks}
% \title{Robotouille: Asynchronous Planning for Language Models in Cooking Tasks}
\title{Robotouille: An Asynchronous Planning \\ Benchmark for LLM Agents}
\input{misc/authors}
\input{misc/macros}

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

% \iclrfinalcopy % Uncomment for camera-ready version, but NOT for submission.

\begin{document}

\maketitle

\input{paper/0_abstract}

% Focus: Robotouille: A Benchmark for async planning for language models

\input{paper/1_introduction}

\input{paper/2_robotouille}

\input{paper/3_datasets}

% Need to have some focus on async planning in results (optimality)
% sanjiban i look at this title: asynchronous planning. what is asynchronous planning? (i'll explain this to sanjiban) why is this hard (i explain). what is the headroom for improvement - can I solve async planning by pretending its synchronous. basic question for language models. funny async models resulting in failures but not what i expect - i expect them to not be as efficient at solving. some of the results aren't making sense to me. first make x then make y. asyc reminiscent of websockets. gokul read RSS mosaic, looks like class project report. couldn't articulate very well. you've done something and wrote up a project report. research paper is arguing an argument for research community. robotouille looking like a project report. prefix of an argument but no suffix. something missing from all planning benchmarks (related works table). its fine hitting 3 points, since we want ot motivate that these are important aspects of home robots.
% what is focus, why llms, insight, clarityo n the messaging (fine with async planning all in or 1 of the 3 things but there needs to be clarity in messaging)
% like async planning, needs to be defined articulate. some part of the approach trying to leverage this fact. odd that not showing how async planning. what is the ramification on the agent. is it not exploiting this structure. if we deleay the discussions and we don't understand the story. maybe all is workable but what is missing is - suddenly not a premise when we started this paper. here is a benchmark fo rcooking blah thats fine low intellectual bar. we've discovered something good / intersting with this paper now we need to crank it out. what hypothesis do we have a priori about llm agents - they're not gonna exploit this structure. async plan short horizon, doing sequentially long horizon async its short horizon. what is the failure / what is the solution. if llm had input manual how to paralleize, if we give it this info does it immediately exploit this. not a gap but extra information, human prior knowledge brand it given this gap i see a jump in async performance. llm planners need to come up with this structure in their chain of thought before they start doing ReAct. we made the argument more crisper, arc is stronger. less open-ended. we had a hypothesis, why do these fail. we show this now.
% maybe we can flounder around get metrics, or have a clear argument and spend time showing another method that given extra information there is an improvement on the performance.
\input{paper/4_results}

\input{paper/5_discussion}

% \input{paper/6_related_works}

\input{paper/7_acknowledgements}

\input{main.bbl}

\input{appendix/_appendix}

\end{document}
