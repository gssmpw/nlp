\section{Related Work}
\label{sec:related-work}
This section separately details related work on PLL and on making predictions more robust regarding aspects (a)\,--\,(c).

\subsection{Partial-Label Learning (PLL)}
PLL is a typical weakly-supervised learning problem.
Early approaches apply common supervised learning frameworks to the PLL context:
____ propose a logistic regression formulation,
____ propose an expectation-maximization strategy,
____ propose a nearest-neighbors method,
____ propose an extension of support-vector machines,
and ____ introduce an average loss formulation allowing the use of any supervised method.

As most of the aforementioned algorithms struggle with non-uniform noise, several extensions and novel methods have been proposed:
____ leverage ideas from representation learning,
____ extend the maximum-margin idea,
____ propose extensions of the expectation-maximization strategy,
____ propose stacking and boosting ensembles,
and ____ introduce a minimum loss formulation, which iteratively disambiguates the partial labels.

The progress of deep-learning techniques also yields advances in PLL.
____ provide risk-consistent loss formulations for PLL and ____ use advances in deep representation learning and data augmentation to strengthen inference from PLL data.
Similar to our approach, \textsc{Cavl} ____ makes use of the class activation values to identify the correct labels in the candidate sets.
While they use the activation values as a feature map, we use the activation values to build multinomial opinions in subjective logic, which reflect the involved uncertainty in prediction-making.

Similar to \textsc{Proden} ____, \textsc{Pop} ____, and \textsc{CroSel} ____, among many others, we iteratively update a label weight vector keeping track of the model's knowledge about the labeling of all instances.
However, those three methods do not provide any formal reasoning for their respective update rules.
In contrast, we prove our update rule's optimality in Proposition~\ref{prop:optimal} and Proposition~\ref{prop:optimal-ce} for the mean-squared error and cross-entropy error, respectively.

We note that, at a first glance, our update rule also appears to be similar to the label smoothing proposed by ____.
Based on a smoothing hyperparameter~$r \in [0, 1]$, they iteratively update the label weights: $r = 1$ uniformly allocates weight among all class labels, while $r = 0$ only allocates label weight on the most likely label.
In contrast, our update strategy does not involve any hyperparameter and allocates probability mass based on the uncertainty involved in prediction-making.

\subsection{Robust Prediction-Making}
Robust prediction-making encompasses a variety of aspects out of which we consider (a) good predictive performance under high PLL noise ____, (b) robustness against out-of-distribution examples (OOD; ____), and (c) robustness against adversarial examples ____ to be the most important in PLL.
Real-world applications of PLL often entail web mining use cases, where the closed-world assumption usually does not hold (requiring (b)).
Also, PLL training data is commonly human-based and therefore a possible surface for adversarial attacks (requiring (c)).
Other robustness objectives that we do \emph{not} consider are, for example, the decomposition of the involved uncertainties ____ or the calibration of the prediction confidences ____.

To address (a) in the supervised setting, one commonly employs Bayesian methods ____ or ensembles\footnote{Ensemble techniques also benefit (b) and (c) and are easy to implement. Therefore, we also consider an ensemble approach of one of our competitors in our experiments as a strong baseline in Section~\ref{sec:exp}.} ____.
To recognize OOD samples (b), one commonly employs techniques from representation learning ____ or leverages negative examples using regularization or contrastive learning ____.
To address (c), methods incorporate adversarially corrupted features already in the training process to strengthen predictions ____.
To the best of our knowledge, we are the first to propose a method that addresses (a), (b), and (c) in PLL.
Tackling all three aspects is particularly challenging in the PLL domain as there is no exact ground truth on which an algorithm can rely to build robust representations.