\section{Literature Review}
In this study, we aimed to develop an easy-to-use, automated, iterative prompt engineering pipeline to generate realistic synthetic medical data. We based our approach on a systematic review that followed PRISMA guidelines to select relevant studies on iterative prompt engineering techniques \cite{liberati2009prisma}. This approach demonstrates notable strengths, as we ensured transparency and reproducibility by adhering to the PRISMA guidelines. 
By employing a detailed search strategy and applying rigorous inclusion and exclusion criteria, we captured a focused set of studies highly relevant to the specific objectives of this research.
We tailored these criteria, such as including only papers published post-2020 and focusing solely on techniques that do not rely on training datasets, to meet the goal of identifying methods capable of optimizing prompts without traditional fine-tuning, a critical constraint in the medical data context.
However, we also identified limitations in our literature review process. While using Google Scholar allowed us to benefit from its comprehensive indexing, it might have restricted the scope to certain types of publications, potentially excluding niche studies from specialized databases. Furthermore, our decision to exclude studies requiring training datasets, although justifiable, may have overlooked techniques with adaptable components for iterative prompt engineering. While these exclusion criteria ensured relevance, they may have unintentionally limited the range of methodologies available for synthesis, potentially bypassing hybrid approaches that could be modified to function without training data.