\section{Introduction}
\label{sec:intro}

Since their emergence, large language models (LLMs) have spread rapidly across many sectors, including education. Using deep learning techniques, LLMs can be trained on extensive text datasets, allowing them to generate high-quality natural language text and demonstrate contextual understanding, which makes them appealing to a wide range of user groups \cite{watson2024chatgpt}. Among these transformer-based models, the Generative Pre-trained Transformer (GPT) series has emerged as a prominent leader due to its enhanced capabilities, scalability, and ability to operate across multiple channels and use cases, among other advantages~\cite{bird2023chatbot, garcia2024review, bansal2024transforming}. In November 2023, only one year after the initial public release of ChatGPT, OpenAI announced that 100 million people were using its chatbot each week \cite{TheVerge, lieb2024student}. 

The rapid rise of generative AI, especially LLM-powered chatbots, presents both opportunities and challenges for educational institutions, prompting them to take a stand on their use \cite{woodruff2023perceptions}.  In this context, 2023 proved to be a pivotal year for AI in education. In the United States, the year began with school districts rushing to address the sudden emergence of ChatGPT, with some implementing bans that were later reversed \cite{Rosenblatt.2023}. The year ended with the technology being integrated into school curricula, as evidenced by over 40 districts and 28,000 students and teachers testing Khan Academy's LLM-powered tutor and teaching assistant, Khanmigo~\cite{Khanmigo}, in classrooms~\cite{Yamkovenko.2024}. 

While some have welcomed this technology into the classroom with excitement and openness, occasionally comparing the adoption of ChatGPT to the introduction of calculators and computers~\cite{shoufan2023exploring}, its use has also sparked concerns and mixed reactions among stakeholders, particularly students and teachers \cite{Engle.2023, Ravaglia.2024}. 

The position we take in this paper is that \emph{stakeholders}---individuals or groups impacted by the adoption of technology directly or indirectly---should play an integral role in the design, development, implementation, and oversight of AI in socially-salient contexts.  Further, we posit that, when it comes to AI systems such as LLM-based chatbots in educational contexts, the number of agents considered as stakeholders should be extended beyond students and teachers to include families, school administrators, ed-tech professionals, and government institutions. We will explore a specific dimension of stakeholder engagement, namely, understanding \emph{stakeholder perceptions}, which involves eliciting and analyzing what goals the stakeholders pursue and how they view the AI system (\eg in terms of opportunities and concerns). Understanding perceptions enables key dimensions of the responsible use of technology, including trustworthiness, safety, fairness, transparency, and usability~\cite{DOE2023}.


\subsection{Motivating example: LLM-based chatbots in New York City public schools}
\label{sec:intro:example}

In March 2023, OpenAI released a new model, GPT-4. As a launch partner, Khan Academy had early access to the model, and on March 14, they released their GPT-4-powered tutoring bot, Khanmigo, in a limited pilot period \cite{Yamkovenko.2024}. Newark Public Schools was one of the first school districts in the U.S. to pilot the tool \cite{Yamkovenko.2024}. The model initially followed a fee-per-student structure, and later became available for free, thanks to a partnership between Khan Academy and Microsoft, which donated its Azure AI-optimized infrastructure. This helped address one of the key obstacles that educational innovations face, namely securing funding~\cite{Ravaglia.2024, Engle.2023}. 

Following this initiative, similar efforts were launched in New York City. In September 2023, the NYC Department of Education (DOE) partnered with Microsoft to create a custom AI-powered teaching assistant designed to answer students' questions and provide personalized, real-time feedback in the classroom \cite{Donaldson.2023}. The tool was first piloted in high school computer science courses, after which, a feature called Microsoft's Math Solver was incorporated to the tool to improve accuracy on math problems in 15 public schools \cite{Donaldson.2023}. At the same time, teachers in Northern Brooklyn were being trained on how to use YourWai, an AI teaching assistant created by  the company Learning Innovation Catalyst, which was later on criticized for displaying made-up reviews on their website \cite{bardolf.2023}. More recently, NYC schools were forced to withdraw a \$1.9 million proposal for an AI-based reading tutor, Amira, designed to assess students’ reading abilities. The proposal was halted by the city Comptroller until the DOE established clearer policies and student privacy safeguards \cite{zimmerman.2024}. The tool was reportedly used by 46,000 students across 162 NYC public schools~\cite{zimmerman.2024}.

In the article ``Would You Want an A.I. Tutor?'', the New York Times invited students to submit comments, sharing their perspectives on using Khanmigo in the classroom~\cite{Engle.2023}.\footnote{The title of our paper makes a direct reference to Engle's New York Times article~\cite{Engle.2023}, which inspired our work.}  Opinions were mixed, with some students expressing a range of concerns, such as the lack of human interaction: ``I think having A.I. tutoring is not a great idea, because human interaction is a really good way to learn''; the risk of over-reliance: ``I’d say there should be a limit that students should know when using A.I. for help. When an assignment is obviously involving critical thinking, you need to exercise your brain by thinking outside the box''; or concerns about accuracy: ``In some cases, one may ask a simple question to Artificial Intelligence, and the answer may be correct, but how would we know for certain? Where is the evidence of said ‘correct answers’?''. Positive perceptions were also expressed, with some students appreciating the wide knowledge base of the chatbot: ``I think that A.I. can be helpful because the information A.I. have could be endless''; its accessibility: ``with a AI tutor you can get help anywhere in seconds''; and the personalized tutoring feature: ``I am 100\% in the belief that an AI tutor that's personalized for students and maybe in the future, personal tutoring profiles would be an extreme benefit for students and teachers in terms of saving time and learning more.''  

\subsection{Research gap: Lack of systematic understanding of stakeholder perceptions of educational chatbots}

Systemic concerns regarding the lack of stakeholder engagement have been raised in the literature.  For example, \citet{zeide2019robot} writes that ``[...] school procurement and implementation of these systems are rarely part of public discussion. Students and parents cannot observe, let alone challenge, the many decisions that shape academic outcomes and subsequent life trajectories. Teachers and school officials cannot assess the accuracy, efficacy, and fairness of individual determinations or group outcomes. Private companies, rather than community members and public servants, set pedagogy and policy in practice.'' Further, a growing body of research has in recent times emphasized the need for \emph{stakeholder-first approaches} in the development and deployment of AI systems, as well as the need for actions by governments and civil society to establish more rigorous standards and regulatory measures, grounded in international human rights frameworks, that can hold Big Tech and other powerful actors accountable \cite{fukuda2021emerging, bell2023think}.

Limited stakeholder involvement contrasts sharply with the recommendations in the U.S. Department of Education's May 2023 report, ``Artificial Intelligence (AI) and the Future of Teaching and Learning: Insights and Recommendations''~\cite{DOE2023}. The report outlines four foundational principles for policy development: Centering People (parents, educators, and students); Advancing Equity; Ensuring Safety, Ethics, and Effectiveness; and Promoting Transparency \cite{DOE2023}. Its first key recommendation, ``human in the loop,'' underscores the importance of educators, parents, families, students, policymakers, and system leaders in exercising judgment and control over AI's role in education.

Ed-tech vendors are also increasingly recognizing the importance of stakeholder engagement. For instance, Microsoft's Technical Implementation Guide for New York City Public Schools highlights community engagement as a key step for successfully implementing their AI teaching assistant \cite{Microsoft2023}. The guide emphasizes ``Building trust and support with stakeholders'' through feedback, input, and addressing concerns.


And yet, while initiatives to implement LLM-powered aids in the classroom have been proliferating, no systematic methodology has been established to assess stakeholder perceptions of the newly introduced technology, either before or after its rollout. Our paper aims to contribute to this literature by illustrating the current landscape of stakeholder perceptions of LLM-based aids in the classroom, and providing a framework for contextualizing these perceptions within the educational setting.

\input{framework_image}


\subsection{Contributions and paper organization}
\label{sec:intro:contrib}

Initially, we set out to conduct a literature review of stakeholder perceptions of LLM-powered chatbots in the classroom.  We were hoping to learn how a school district such as New York City's might ``do things right'' --- ask the right stakeholders the right questions about whether and how to deploy chatbots in the classroom.  However, we quickly realized that there are significant gaps in the literature: \first only students and teachers have been considered, while other stakeholders (\eg parents) have been overlooked; and \second the context of use of a chatbot in the classroom (\eg whether it is used for language or math instruction, in elementary school or in a high school) is underspecified.  Nonetheless, we were able to distill a \emph{taxonomy of perceptions} that can be used to characterize stakeholder attitudes towards LLM-based tutors.  Our literature review, and the taxonomy that emerged, is the first contribution of this paper.  Our second contribution is  the \frameworklong (\framework) framework, summarized in Figure~\ref{fig:framework}.

This paper is organized as follows. Section~\ref{sec:related} summarizes related work, Section~\ref{sec:survey} describes our literature review of perceptions of LLM-based chatbots. Section~\ref{sec:framework} presents the \framework framework, which encompasses the taxonomy of perceptions. Section~\ref{sec:conclusion} concludes the work, acknowledges limitations, and outlines future directions.