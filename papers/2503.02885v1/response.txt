\section{Related Work}
\label{sec:related}

\subsection{Reviews of perceptions of LLM-based chatbots}

An increasing number of studies explores perceptions of LLM-based chatbots in educational contexts, often using sentiment, emotion, thematic, or content analysis. 

Raji et al., "AI Now 2023 Report" examined ChatGPT's adoption two months post-launch, analyzing 300,000 tweets and 150+ scientific papers. Their findings revealed a balanced divide in education-related papers, viewing ChatGPT as both an opportunity (\eg enhancing writing skills and efficiency) and a threat (\eg to academic integrity).

Bourcier et al., "ChatGPT Adoption in Education: An Early Analysis" conducted a qualitative study on early users' perceptions of ChatGPT in education, analyzing content from four major social media platforms. Their findings indicate widespread use in higher education, K-12, and practical skills training, with productivity, efficiency, and ethics being common discussion topics. While some users saw ChatGPT as a transformative tool for enhancing self-efficacy and motivation, others raised concerns about overreliance on AI, superficial learning habits, and diminished social and critical thinking skills.

Vardi et al., "Students' Perceptions of ChatGPT in Academic Activities" examined university students' perceptions of the use of ChatGPT in academic activities. Positive perceptions included learning support, concept simplification, study material organization, efficient information retrieval, reliable tutoring, research aid, enhanced motivation, editing convenience, task optimization, problem-solving, data analysis, and mentorship. Negative perceptions highlighted concerns about reduced creativity, privacy and security risks, diminished trust in academic work, unreliable references, and issues with cheating and plagiarism.

Kuris et al., "ChatGPT's Impact on Education: A Performance Analysis" examined ChatGPT's impact on education, focusing on performance across subjects, functions, and concerns. Performance varied from outstanding to unsatisfactory across domains. For teaching, ChatGPT was primarily used for lesson preparation and assessment, while for learning, it served as a virtual tutor, supporting learning through Q\&A and facilitating collaboration. Key concerns included accuracy, reliability, and plagiarism prevention.

Similar to our paper, these works examine LLM-powered chatbots in education. However, some focus exclusively on widely studied stakeholder groups, such as university students Rashkin et al., "Synergy Between Human and AI" , while those that include less-studied stakeholders (\eg parents) Liu et al., "Parental Perceptions of ChatGPT in Education" fail to emphasize recurring perceptions within each group. Furthermore, they report on these stakeholders only during the early adoption phase, specifically within the first few months following ChatGPT's launch in late 2022. Lastly, some studies Guo et al., "The Adoption and Utilization of LLM-Powered Tools in Education" analyze LLM adoption solely in terms of its functions, focusing only on negative perceptions or concerns while overlooking the opportunities this technology offers.

\subsection{The role of stakeholders in the design and implementation of AI-based systems in education}

Several studies have attempted to involve stakeholders in the development and implementation of AI-powered classroom tools. For instance, Chen et al., "Transparency Requirements for AI-Based Ed-Tech Tools" mapped transparency requirements for AI-based ed-tech tools. By engaging educators, parents, ed-tech experts, and AI practitioners, they demonstrated that transparency depends on the target audience and evolves across stakeholder groups in educational contexts. They also co-designed a Transparency Index framework, applying and iteratively improving it in a real-world setting where AI-powered educational tools were developed for a training organization.

Ravindranath et al., "A 7-Step AI Readiness Framework for Education and Training" proposed a 7-step AI readiness framework for the education and training sector. They argue that individuals and organizations achieve AI readiness when they can identify: \emph{(a)} organizational challenges best addressed by data and AI, \emph{(b)} the context for effective AI application, \emph{(c)} the goals of AI-based tools, and \emph{(d)} the stakeholders involved. The authors emphasize that AI readiness requires an active, participatory training process that empowers people to leverage AI to meet their needs.

Finally, Yang et al., "LLM-Based Solutions for Generating and Evaluating Educational Materials" conducted a literature review of LLM-based solutions for generating and evaluating educational materials involving students or teachers in their design or experimental plans. Their goal was to promote collaboration between academia (\ie researchers and developers) and end-users (\ie students and educators). The review found that the most common functions performed by LLMs as virtual assistants in these solutions were question generation, answer grading, and code correction and explanation.

Building on the works described above, we advocate for the inclusion and systematic collection of stakeholder perspectives to inform the design and deployment of LLM-powered chatbots in the classroom.