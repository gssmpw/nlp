%\documentclass[lettersize,journal]{IEEEtran}
\documentclass[journal]{IEEEtran}
\usepackage{amsmath,amsfonts}
\usepackage{mathtools}
\usepackage{algorithmic}
\usepackage{algorithm}
\usepackage{array}
\usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
\usepackage{textcomp}
\usepackage{stfloats}
\usepackage{url}
\usepackage{verbatim}
\usepackage{graphicx}
\usepackage{cite}
\usepackage{booktabs}
\hyphenation{op-tical net-works semi-conduc-tor IEEE-Xplore}
\usepackage{makecell}
% updated with editorial comments 8/9/2021

\usepackage[table,xcdraw]{xcolor}
\usepackage{amssymb}
\newcommand{\YKL}[1]{\textcolor{red}{#1}}
\definecolor{rblue}{rgb}{0,0.5,1}
\definecolor{awesome}{rgb}{1.0, 0.13, 0.32}
\definecolor{hollywoodcerise}{rgb}{0.96, 0.0, 0.63}
\definecolor{lasallegreen}{rgb}{0.03, 0.47, 0.19}
\definecolor{hanpurple}{rgb}{0.32, 0.09, 0.98}
\definecolor{green(pigment)}{rgb}{0.0, 0.65, 0.31}

\usepackage[pagebackref=false,breaklinks=true,colorlinks,bookmarks=false]{hyperref}
\hypersetup{colorlinks=true,linkcolor={red},citecolor={hanpurple},urlcolor={magenta}}

\begin{document}

\title{CT-UIO: Continuous-Time UWB-Inertial-Odometer Localization Using Non-Uniform B-spline with Fewer Anchors}

\author{Jian Sun, Wei Sun, Genwei Zhang, Kailun Yang, Song Li, Xiangqi Meng, Na Deng, and Chongbin Tan
        % <-this % stops a space
\thanks{This work is supported by the National Natural Science Foundation of China (U22A2059 and No. 62473139); Project of State Key Laboratory of Advanced Design and Manufacturing Technology for Vehicle; Open Foundation of Engineering Research Center of Multi-Mode Control Technology and application for Intelligent System, Ministry of Education.
(\textit{Corresponding authors: Wei Sun; Genwei Zhang; Kailun Yang.})
}
\thanks{J. Sun, K. Yang, S. Li, X. Meng, N. Deng, and C. Tan  are with the National Engineering Research Center of Robot Visual Perception and Control Technology, 
%College of Electrical and Information Engineering, 
Hunan University, Changsha 410012, China (e-mail: sunjian1993@hnu.edu.cn).}
\thanks{W. Sun is with the College of Electrical and Information Engineering, Hunan University, and also with the School of Robotics, Hunan University, Changsha 410012, China (e-mail: wei\_sun@hnu.edu.cn).}
\thanks{K. Yang is also with the School of Robotics, Hunan University, Changsha 410012, China (e-mail: kailun.yang@hnu.edu.cn).}
\thanks{G. Zhang is with the State Key Laboratory of NBC Protection for Civilian, Beijing 102205, China (e-mail: zhanggenwei@sklnbcpc.cn).}
}

\maketitle

\begin{abstract}
Ultra-wideband (UWB) based positioning with fewer anchors has attracted significant research interest in recent years, especially under energy-constrained conditions. However, most existing methods rely on discrete-time representations and smoothness priors to infer a robot’s motion states, which often struggle with ensuring multi-sensor data synchronization. In this paper, we present an efficient UWB-Inertial-odometer localization system, utilizing a non-uniform B-spline framework with fewer anchors. Unlike traditional uniform B-spline-based continuous-time methods, we introduce an adaptive knot-span adjustment strategy for non-uniform continuous-time trajectory representation. This is accomplished by adjusting control points dynamically based on movement speed. To enable efficient fusion of IMU and odometer data,  we propose an improved Extended Kalman Filter (EKF) with innovation-based adaptive estimation to provide short-term accurate motion prior. Furthermore, to address the challenge of achieving a fully observable UWB localization system under few-anchor conditions, the Virtual Anchor (VA) generation method based on multiple hypotheses is proposed. At the backend, we propose a CT-UIO factor graph with an adaptive sliding window for global trajectory estimation. Comprehensive experiments conducted on corridor and exhibition hall datasets validate the proposed system's high precision and robust performance. The codebase and datasets of this work will be open-sourced at~\url{https://github.com/JasonSun623/CT-UIO}.
\end{abstract}

\begin{IEEEkeywords}
UWB-Inertial-Odometer Fusion, Continuous-Time Trajectory, Factor Graph, Few Anchors.
\end{IEEEkeywords}

\section{Introduction}
\IEEEPARstart{L}{ocation-based} services~\cite{10260266,10268655,10239248,10014536} such as trajectory prediction, object tracking, and automatic picking operations, have become an integral part of robotics research. Global Navigation Satellite Systems (GNSS) can achieve meter-level accuracy in outdoor clear sky environments. However, reliable localization of GNSS is impractical indoors due to the attenuation of GNSS signals. 
To achieve robust indoor positioning services in GPS-denied environments, Ultra-wideband (UWB) technology is considered as a promising alternative solution benefiting from its stability, low-cost, and more scalable in large-scale deployment~\cite{10400775,10704747}. 
Based on UWB signal ranging, most of the current range-based localization schemes require at least three anchors to determine a moving target’s 2D position, which is also referred to as multilateration~\cite{2013.0815,PARK2024103234}. 
However, in energy-constrained UWB networks or deployment scenarios with spatial limitations, such as narrow corridors or tunnels, only one or two anchors may be available. 
This limitation renders traditional multilateration positioning methods ineffective in such environments.

In such situations, range-based localization with few anchors is challenging and has become an attractive research direction. Existing methods~\cite{10268655,tong2022single,9829196} usually require special anchor’s antenna arrays or integrate additional sensors, such as Inertial Measurement Unit (IMU), wheel odometers, and cameras, to provide supplementary velocity or angle measurements. 
IMU and odometers are environment-independent and provide instantaneous response speeds, enabling the construction of relative position constraints between consecutive UWB ranging measurements.
Conventional sensor fusion schemes~\cite{10268655,9440987,Xiong2022} such as Extended Kalman Filter (EKF) and Particle Filter (PF), typically rely on smoothness priors to infer a robot’s motion states. 
However, these methods are based on Discrete-Time (DT) trajectory estimation, which may fail to adequately represent smoothness. 
Interpolation schemes used to infer robot motion between discrete states may be inaccurate. Furthermore, multi-modal sensor setups often involve asynchronous measurements from different sensors, which causes difficulty in fusing data at the same time instants during the estimation process. 

Within recent years, continuous-time representation has been increasingly applied to multi-sensors calibration, motion planning, and target tracking~\cite{10311080,lang2023coco,cioffi2022continuous,nguyen2024eigen}. 
The key advantage of continuous-time formulation lies in its ability to generate smooth trajectories with continuous data streams. 
In particular, B-spline defines temporal polynomials to represent trajectories by a set of control points, which enables pose querying at any time instant with locality. 
Most existing methods~\cite{li2023continuous,10045587,9636676} adopt uniform the B-spline-based strategy for continuous-time trajectory smooth updates, where control points are spaced uniformly and typically predetermined. 
However, these methods often rely on the assumption of a constant velocity model, which is unsuitable for many real-world applications. 
Since the robot's velocity is constantly changing, smaller control point spacing may result in overfitting and increased computational complexity, while larger spacing reduces overall accuracy. Benefiting from dynamic control point distribution, non-uniform B-spline is becoming an attractive alternative. 
Related works by Lang~\textit{et al.}~\cite{lang2023coco} and Dubé~\textit{et al.}~\cite{dube2016non} illustrate that non-uniform knot sampling strategies can accommodate trajectory complexity more effectively. 
These methods have also proved that the non-uniform sampling strategy can be superior to the uniform strategy in terms of trajectory estimation accuracy and time performance.

However, research on non-uniform B-spline methods has primarily focused on LiDAR~\cite{lang2023coco} and cameras~\cite{9320417} applications for SLAM, it has not been applied to few-anchor UWB-based positioning. Moreover, existing non-uniform strategies for determining appropriate knot spans often rely solely on velocity estimates from IMU measurements, which are prone to noise, resulting in inaccurate spacing interval divisions.

In this work, we propose CT-UIO, a continuous-time UWB-inertial-Odometer system using non-uniform B-splines with few anchors.
CT-UIO dynamically adjusts control point spacing based on changes in motion trajectories. In general, although continuous-time methods have been extensively studied, most existing works rely on uniform B-splines to achieve continuous-time representations and estimation. 
To the best of the authors’ knowledge, this paper is the first to utilize non-uniform continuous-time representation for UWB/IMU/odometer fusion localization, we can achieve efficient pose estimation in few-anchor scenes or with fast motions through extensive experiments. 

The contributions of this paper are summarized as follows.
\begin{itemize}
    \item{We propose a continuous-time UWB-Inertial-Odometer (CT-UIO) localization system that adopts an adaptive knot span adjustment strategy for non-uniform continuous-time trajectory representation. CT-UIO fuses time-unsynchronized UWB ranging, IMU, and odometer data, enabling accurate pose estimation even in few-anchor scenes and during time-varying motions.}
 
    \item{We construct an IMU/odometer fusion model using an improved Extended Kalman Filter (EKF) with innovation-based adaptive estimation, providing short-term accurate motion priors. Leveraging this, the adaptive knot span adjustment strategy dynamically adjusts the number of control points based on movement speed.}

    \item{We generate virtual anchors by combining UWB ranging with motion priors from the IMU/odometer fusion model, constructing a fully observable UWB localization system under few-anchor conditions. Additionally, we propose a virtual anchors deployment scheme based on multiple hypotheses to avoid collinearity.}

    \item{The CT-UIO system is evaluated on several real-world datasets, including comparison with state-of-the-art methods. Extensive experimental results demonstrate the system's superiority, particularly in handling fast motion. To benefit the community, the relevant datasets and source codes are made publicly available at \url{https://github.com/JasonSun623/CT-UIO}.}
\end{itemize}

\section{Related Work}
\subsection{Few-Anchor UWB Localization}
Few-anchor UWB localization has recently attracted increasing attention and has been widely studied due to its low complexity and cost-effective deployment~\cite{tong2022single,9829196,penggang2022novel}. 
These research works focus exclusively
on fusion schemes that integrate UWB measurements with other motion sensors. Mainstream works primarily employ filter-based, optimization-based, and two-stage methods to incorporate additional velocity observations. 
In filter-based solutions, Cao~\textit{et al.}~\cite{cao2020accurate} employed Extended Kalman Filtering (EKF) to combine a single UWB anchor with a nine-DOF IMU for velocity and orientation estimation. Qin~\textit{et al.}~\cite{qin2024single} designed a Set Membership Filter (SMF) method based on constrained zonotopes for single-beacon localization problems. 
Gao~\textit{et al.}~\cite{penggang2022novel} introduced UWB ranging, non-holonomic constraints from the carrier, and trajectory constraints as observations of the EKF system. The proposed method can realize positioning in corridor-like areas. However, it relies on non-holonomic and corridor-specific trajectory constraints, which may not be applicable in unknown environmental structures. 
In optimization-based solutions, Li~\textit{et al.}~\cite{li2021computationally} proposed a Moving Horizon Estimation (MHE) algorithm, which utilizes historical measurement data from a single UWB anchor and IMU during a time horizon. Additionally, a Gradient Aware Levenberg-Marquardt (GALM) algorithm was further proposed to solve the optimization problem with a calculation cost. 
For two-stage methods, Yang~\textit{et al.}~\cite{yang2023novel} proposed an improved positioning method that leverages Bayesian optimization to provide the estimated IMU data based on an error model. A filter then updates the position at the ranging time using the prior position error. 
Zhou~\textit{et al.}~\cite{zhou2024optimization} proposed a two-stage optimization method that could yield accurate solutions with the single-anchor and odometer.
In the first stage, they construct a factor graph that incorporates odometry positions and UWB measurements to optimize state estimation. In the second stage, an adaptive trust region algorithm is performed to refine the location estimate and maintain robustness with inequality constraints.  While these methods approximate the time offsets between state estimation and sensor measurements, the hypothesis of time synchronization may not always hold in practical scenarios. Unlike the existing few-anchor UWB localization methods, our method
formulates the trajectory in continuous-time with B-spline, which allows asynchronous, high-frequency sensor measurements to be aligned at any time instants along the trajectory, rather than relying on linear interpolation of discrete-time poses only at measurement times.

\subsection{Continuous-Time Representation Using B-spline}
Continuous-time representation is a popular and natural choice for formulating trajectories and ensuring smoothness. 
It can estimate the robot's pose as a continuous function of time without the need to introduce additional states at every measurement time. The most common continuous-time-based model is based on splines and Gaussian processes~\cite{cioffi2022continuous}. 
In this article, we focus on B-spline-based trajectory representation,  current literature has paid increasing attention to applying B-splines for continuous-time state estimation in multi-sensor fusion systems, including the LiDAR-Inertial system, visual-inertial system, ultra-wideband-inertial and so on.
Nguyen~\textit{et al.}~\cite{nguyen2024eigen} developed a real-time continuous-time LiDAR-inertial odometry (SLICT2), which achieved efficient optimization with few iterations using a simple solver.
Lu~\textit{et al.}~\cite{lu2023event} proposed an event-based visual-inertial velometer that incrementally incorporates measurements from a stereo event camera and IMU. 
Li~\textit{et al.}~\cite{li2023continuous} proposed a spline-based approach (SFUISE) for continuous-time Ultra-wideband-Inertial sensor fusion, which addressed the limitations of discrete-time sensor fusion schemes in asynchronous multi-sensor fusion and online calibration. 
These methods generally employ uniform knot B-splines for trajectory modeling, relying on assumptions of zero velocity or constant speed. However, these assumptions often fail to capture the dynamic nature of real-world motion. Non-uniform B-splines offer a more flexible distribution of control points, enabling a different density of control points based on the smoothness of the trajectory segment. 
Ovrén~\textit{et al.}~\cite{ovren2018spline} introduced an energy proportionality index in spline fitting to optimize the selection of knot spacing. 
By leveraging the different frequency response characteristics of spline basis functions and specific energy values, appropriate knot spacing can be automatically selected. 
Lang~\textit{et al.}~\cite{lang2023coco} tightly coupled the measurements from LiDAR, IMU, and cameras using non-uniform B-spline curves. 
They adaptively adjusted the number of control points based on IMU observations to detect different motion patterns, thereby improving adaptability to complex environments and motion patterns. However, relying solely on IMU data leads to velocity estimate divergence, which impacts the distribution of control points and ultimately reduces positioning accuracy. 
In contrast, the proposed method integrates an IMU/Odometer fusion model to provide short-term accurate velocity estimates, enabling the dynamic adjustment of control point density for more precise trajectory modeling. 

\begin{figure*}[!t]
\centering
\includegraphics[width=\linewidth,trim=1cm 7cm 2cm 2cm,clip]{1.pdf}
\caption{The framework of CT-UIO: In the preprocessing stage, UWB ranging data is detected, and outliers are removed. Simultaneously,  incoming IMU and odometer data are fused using an adaptive EKF to provide short-term accurate motion priors. In the front-end, the results of the IMU/odometer fusion model are combined with UWB ranging to generate virtual anchors. Additionally,  Based on the motion estimates from the IMU/odometer fusion model, the adaptive knot span adjustment strategy non-uniformly places control points. In the back-end, we conduct a CT-UIO factor graph with an adaptive sliding window for global trajectory estimation.}
\label{fig_0}
\end{figure*}

\section{System Overview}
Fig.~\ref{fig_0} shows the overviews of our CT-UIO. 
In the beginning, we assume that the UWB-Inertial-Odometer system is calibrated and IMU bias and odometer scale are initialized. 
In the preprocessing, we apply inequality constraints to remove UWB-ranging outliers and build the IMU/odometer fusion model (Sec.~\ref{sec:preprocessing}). 
Next, we propose a non-uniform continuous-time state estimation method, using the adaptive knot span adjustment strategy to tightly fuse the high-frequency measurements from UWB ranging, IMU, and odometer (Sec.~\ref{sec:Adaptive_Knot}). 
To make the few-anchor UWB localization system fully observable, we combine the UWB ranging measurements with short-term position estimates from the IMU/odometer fusion model to generate virtual UWB anchors (Sec.~\ref{sec:optimization}). 
In the backend, we conduct a UWB-Inertial-Odometer factor graph with an adaptive sliding window to perform joint optimization to obtain optimal estimations (Sec.~\ref{sec:Sliding-Window}). 
For UWB/IMU/Odometer integrated (UIO) system, we use ${U}$ to denote the UWB frame, {$I$} for the IMU frame, {$O$} for the wheel odometer frame, {$W$} for the world coordinate frame.

\subsection{Preprocessing}
\label{sec:preprocessing}
\subsubsection{IMU/Odometer Fusion Model}
IMU and odometer offer fast response speeds and are environment-independent. For ground robot navigation, it appears to be straightforward in to fuse IMU data with wheel odometer measurements to provide motion priors over short time periods~\cite{Bai_Lai_Lyu_Cen_Wang_Sun_2022}. 
The raw IMU measurements include the angular velocity \begin{math}\omega_{t}\end{math} and local linear acceleration \begin{math}a_{t}\end{math}
\begin{equation}
\omega_{t_{k}}=\tilde{\omega}_{t_{k}}+\varepsilon_{g}+n_{g},
\end{equation}
\begin{equation}
a_{t_{k}} = \tilde{a}_{t_{k}} + \varepsilon_{a} + 
\prescript{I}{W}{\textbf{R}} g^W + n_{a},
\end{equation}
where \begin{math}\tilde{\omega}_{t_{k}}\end{math} and \begin{math} \tilde{a}_{t_{k}} \end{math} are true values of angular velocity and linear
acceleration at time $t$, respectively.  \begin{math} \varepsilon_{g}\end{math} and \begin{math} \varepsilon_{a}\end{math} denote accelerometer’s bias and gyroscope’s bias 
in the IMU body frame. $\prescript{I}{W}{\textbf{R}}$ denotes the rotation matrix from frame $\left \{ W \right \} $ to $\left \{ I \right \} $, \begin{math}g^W\end{math} is the gravity vector in the world frame, \begin{math}n_g\end{math} and \begin{math}n_a\end{math} are zero-mean Gaussian noises.
We then integrate the wheel odometer measurements between IMU times [\begin{math}t_{k-1}\end{math}, \begin{math}t_k\end{math}] and 2D relative motion as follows:
\begin{equation}
z_o=:\begin{bmatrix}
 ^o\theta\\^o\textbf{d}
\end{bmatrix}=\begin{bmatrix}
-\int\limits_{t\in [t_{k-1},t_k] }{^o\omega_{t_k}dt} 
 \\
\int\limits_{t\in [t_{k-1},t_k] }{^ov_{t_k}\text{cos}^o\theta dt} 
 \\
-\int\limits_{t\in [t_{k-1},t_k] }{^ov_{t_k}\text{sin}^o\theta dt} 
\end{bmatrix},
\label{2dIMU}
\end{equation}
where \begin{math} ^o\theta \end{math} and \begin{math}^o\textbf{d}\end{math} are the yaw angle and 2D relative motion position in odometer frame from \begin{math} t_{k-1} \end{math} to \begin{math} t_k\end{math}. \begin{math} ^o\omega \end{math} and \begin{math} ^ov \end{math} are 2D angular and linear velocities with zero-mean white Gaussian noises in the odometer frame. 
The relative motion position can also be derived from the IMU pose:
\begin{equation}
\tilde{z}_o=:\begin{bmatrix}
 _{I}^{o}\theta\\_{I}^{o}\textbf{d}

\end{bmatrix}=\begin{bmatrix}
\textbf{e}_{3}^\text{T}{^oR_{t_k}}
 \\
{^oR_{t_k}}(_{I}^{o}R{^I\textbf{d}})
\end{bmatrix}.
\end{equation}
The attitude update is formulated as
\begin{equation}
{^oR_{t_k}}={^oR_{t_{k-1}}}\otimes R_{\bigtriangleup t_k }^{b}.
\end{equation}
\begin{math}{^oR_{t_k}}\end{math} represents the rotation matrices transformed from \begin{math} ^o\theta_{t_k}\end{math}, \begin{math}\textbf{e}_3\end{math} is the unit bias vector.
We construct the observation measurement vector composed of the pose of IMU and odometer as
\begin{equation}
Z(k)=z_o-\tilde{z}_o=H(k)X(k)+\eta(k), 
\end{equation}
where \begin{math} \eta(k)  \sim (0,\sigma ^2) \end{math} means the measurement noise with zero mean and standard Gaussian distribution.
The Jacobian matrix \begin{math}H(k)\end{math} can be indicated by 
\begin{equation}  
H(k)=\frac{Z(k)}{\partial X(k)}. 
\end{equation}
The innovation \begin{math}\tilde{Z}_k\end{math}  can be calculated as 
\begin{equation}
\tilde{Z}(k)=Z(k)-\bar{Z}_k=H(k)X(k)+\eta(k)-H(k)\bar{X}(k),
\end{equation}
where \begin{math} \tilde{Z}(k)\sim N(0,\textbf{e}_k) \end{math}, the correlation covariance matrix of the innovation is defined as
\begin{equation}
\textbf{e}_k=E(\tilde{Z}(k)(\tilde{Z}(k))^\text{T}),
\end{equation} 
\begin{equation}
e(k)=(\tilde{Z}(k))^\text{T}(E(k))^{-1}\tilde{Z}(k).
\end{equation}
During the above EKF fusion process, abnormal IMU measurement noise can directly impact the filtering robustness and observation accuracy. 
To improve the accuracy of model parameters and observation matrix,   
 an adaptive innovation chi-square statistics test is designed to assess the reliability of IMU measurements.
\begin{equation}
E(k)=\frac{1}{M}\sum_{i=k-M+1}^{k}\tilde{Z}(i)^\text{T}e(i)^{-1}\tilde{Z}(i),  
\end{equation}
\begin{equation}
E(k)\sim{\chi^2},
\end{equation}
\begin{equation}
\begin{aligned}
    M=\left\{\begin{matrix}
1,e(k)\ge \lambda_\text{max}, 
 \\
\xi,e(k)\le \lambda_\text{min},
 \\
\xi \times \mu^{\frac{e(k)-\lambda_\text{min}}{\alpha } },\lambda_\text{min}< e(k)<\lambda_\text{max}. 
\end{matrix}\right.
\end{aligned}
\end{equation}
where $M$ is the adaptive size of the observation statistics, which controls the trade-off between estimation accuracy and computational complexity. \begin{math}\mu\end{math} is the convergence rate.
There is the rejection domain of the \begin{math}E(k)\end{math}
\begin{equation}
\left\{\begin{matrix}
E(k)>thr& \text{Reject}
 \\
E(k)\le thr& \text{Accept}
\end{matrix}\right.
\end{equation}
when \begin{math}E(k)\end{math} exceeds the threshold \begin{math}thr\end{math}, the abnormal fault in  IMU measurements is detected by chi-square test statistic, we reject this IMU measurement and do not perform the EKF update.

\subsubsection{UWB Ranging Outlier Rejection}
\label{sec:outlier_rejection}
UWB ranging outliers occur regularly under Non-line-of-sight (NLOS) and multipath conditions~\cite{10458971}. 
If these outliers are not treated properly during data processing, the performance of UWB-based localization can be degraded due to the fusion of inaccurate ranging measurements. 
Therefore, we filter the UWB-ranging outliers using an inequality constraint. The ranging measurement $r_{t_{k+1}}$ at the $t_{k+1}$ time should satisfy:
\begin{equation}
   \sigma_r <\left |{\left \| \hat{d}_{t_k}-\textbf{p}_n \right \| }_2-r_{t_{k+1}}\right | <\gamma \hat{v}_{t_k}\left ( t_{k+1}- t_k\right ),   
\end{equation}
 where $\hat{d}_{t_k}$ and $\hat{v}_{t_k}$ are the estimated robot's position and velocity derived from the IMU/odometer fusion model, respectively. $\textbf{p}_n $ is the position of the fixed anchor. 
 \begin{math}\sigma_r\end{math} denotes the confidence intervals for the individual ranging measurements, $\gamma$ is the outlier rejection gating threshold. 

\subsection{Adaptive Knot Span Adjustment Strategy}
\label{sec:Adaptive_Knot}
\subsubsection{Non-Uniform Continuous-Time Trajectory Representation}
In this paper, we use the split non-uniform B-spline representation to
separately represent the translation part $\textbf{p}(t)$ in \begin{math}\mathbb{R}^3\end{math} and the rotation part $\textbf{R}(t)$ in the Lie group \begin{math}SO(3)\end{math}   with two splines. 
The sampled translation vector in trajectory of the order $k$ B-spline at time \begin{math}t\in[t_k,t_{k-1}]\end{math}, can be denoted as:
\begin{equation}
\textbf{p}(t)=\textbf{p}_{i}+\sum_{j=1}^{k}\lambda_j(t)\cdot \textbf{d}_{j}^{i},
\end{equation}
with
\begin{equation}
\boldsymbol{\lambda}(t) =\tilde{\boldsymbol{\Lambda}}^{(k+1)}(i)\textbf{u}(t),  
\end{equation}
where \begin{math}\textbf{p}_{i}\end{math} denotes the $i$-th  control point, \begin{math}\textbf{p}_{i}\in \mathbb{R}^3 \end{math}, \begin{math}t\in T =\left \{ t_0,t_1,...,t_n \right \} \end{math} is the arbitrarily independent knot time of B-splines. The coefficients \begin{math}{\lambda}_j(t)\end{math} represents the $j$th column of \begin{math}\boldsymbol{\lambda}(t)\end{math}. \begin{math}\tilde{\boldsymbol{\Lambda}}^{(k+1)}(i)\end{math} is a non-constant cumulative basis matrix which is defined by its order $k$. 
\begin{math} \textbf{u}(t)=\begin{bmatrix}
1& u(t) & ... & u^k(t)
\end{bmatrix}^\text{T} \end{math} is the normalized time vector:
\begin{equation}
u(t)=\frac{t-t_i}{t_{i+1}-t_i}. 
\end{equation}
\begin{math}
    \textbf{d}_{j}^{i}
\end{math} is the difference distance vector,
\begin{equation}
\textbf{d}_{j}^{i}=\textbf{p}_{i+j}-\textbf{p}_{i+j-1}. 
\end{equation}
Analogically, the orientation of the trajectory in SO(3) in Lie groups can be expressed as follows:
\begin{equation}
\begin{aligned}
\textbf{R}(t)=\textbf{R}_{i}\cdot \prod_{j=1}^{k}\text{Exp}(\lambda_j(t)\cdot \boldsymbol{\Psi }_{j}^{i}), \\
\boldsymbol{\Psi }_{j}^{i}=\text{Log}(\textbf{R}_{i+j-1}^{-1}\textbf{R}_{i+j}),
\end{aligned}
\label{liegroup}
\end{equation}
where \begin{math}\textbf{R}_{i}\end{math} denotes the $i$-th rotation control points, \begin{math}\textbf{R}_{i}\in SO(3) \end{math}. \begin{math}\text{Exp}(\cdot)\end{math} is the exponential mapping that maps the Lie algebra to the Lie group, and \begin{math}\text{Log}(\cdot)\end{math} is the inverse operation, $\boldsymbol{\Psi }_{j}^{i}\in \mathbb{R}^3$.

To balance the overall accuracy and convergence speed, we exploit a cumulative cubic B-spline function ($k=3$) in this article,  the order of the spline is set to $4$.

\subsubsection{Adaptive Knot Spans Adjustment}
For uniform-spline-based methods, control points are temporally uniformly distributed, knot spans between them are equal to construct the B-spline.
However, this uniform placement does not guarantee optimal trajectory interpolation performance, especially when encoding time-varying states. 
We argue that it is reasonable to reduce redundant control points for steady movement. 
In addition, when the robot's motion with significant velocity fluctuations over short time intervals, a finer granularity of knots is required to capture rapid changes, which requires inserting additional control points. To solve this problem, we propose an adaptive knot span adjustment strategy that dynamically adjusts the distribution of control points to flexibly accommodate varying motion speeds, as shown in Fig.~\ref{cp}. 
Namely, the current pose is registered as a Key Pose (KP) if the tracked trajectory segment has a local linear velocity or angular velocity change above a certain threshold. 
Specifically, we obtain the linear velocity and angular velocity respectively in a sliding window:
\begin{equation}
\begin{aligned}
v(T_{i-1},T_i) &= \frac{1}{n(T_{i-1},T_i)} \sum_{k \in n(T_{i-1},T_i)} &  \\ \Big(v_k 
& - \frac{1}{n(T_{i-1},T_i)} \sum_{k \in n(T_{i-1},T_i)} v_k \Big)^2,
\end{aligned}
\end{equation}
\begin{equation}
\begin{aligned}
\omega(T_{i-1},T_i) &= \frac{1}{n(T_{i-1},T_i)} \sum_{k \in n(T_{i-1},T_i)} &  \\ \Big( \omega_k\
& - \frac{1}{n(T_{i-1},T_i)} \sum_{k \in n(T_{i-1},T_i)} \omega_k \Big)^2
\end{aligned}.
\end{equation}
We associate each KP with the number of control points 
\begin{math} n_{cp}\end{math}
\begin{equation}
n_{cp} =
\begin{cases}
1, & \text{if } v(T_{i-1},T_i) \in [0, v_{\max}] \\
    & \text{or } \omega \in [0, \lambda_1 \omega_{\max}],\\
2, & \text{if } v \in [\theta_1 v_{\max}, \theta_2 v_{\max}] \\
    & \text{or } \omega \in [\lambda_1 \omega_{\max}, \lambda_2 \omega_{\max}], \\
3, & \text{if } v \in [\theta_2 v_{\max}, \theta_3 v_{\max}] \\
    & \text{or } \omega \in [\lambda_2 \omega_{\max}, \lambda_3 \omega_{\max}],\\
4, & \text{if } v \in [\theta_3 v_{\max}, v_{\max}] \\
    & \text{or } \omega \in [\lambda_3 \omega_{\max}, \omega_{\max}].
\end{cases}
\end{equation}
We know that the knot span is actually influenced by the number of control points at a specific time interval. Each of the knot spans is independent of others, and  knot spans are divided by control points
\begin{equation}\bigtriangleup t_k=\frac{1}{n_{cp}}(T_i-T_{i-1}).\end{equation} 
The non-uniform nature of the B-spline, characterized by its dynamic knot span adjustment strategy, contributes to the generation of smooth and adaptable trajectories that can better accommodate the dynamics of motion,  thereby, improving the rationality of knot assignment.

\begin{figure}[!t]
\centering
\includegraphics[width=\linewidth,trim=9cm 4cm 11.5cm 0cm,clip]{CP.pdf}
\caption{Illustrations of the proposed adaptive knot span adjustment strategy. The top shows the robot's velocity and the bottom shows that the distribution of control points is adaptive to speed variations.
}
\label{cp}
\end{figure}

Then, the trajectory segment over the sliding window \begin{math}[T_{i-1},T_i]\end{math} consists of  \begin{math}n_{cp}\end{math} piecewise
functions. We can query the pose with arbitrary timestamp \begin{math}t_{i}\end{math} in this segment. 
The control points of the active trajectory segment are further optimized and updated within the sliding window by a factor graph optimization. 
Meanwhile, control points outside the active segment remain static in the optimization but still retain marginalization priors for the next sliding window.

\subsection{UWB-Inertial-Odometer Factor-Graph Framework}
\label{sec:optimization}

\subsubsection{Virtual UWB Anchor Ranging Factor}
Since directly fusing range measurements can lead to unobservability when only one or two anchors are available~\cite{10268655}, we utilize Virtual Anchors (VA) to construct a fully observable UWB-based localization system.
Inspired by~\cite{9119679,9520065}, we propose a VA generation method based on multiple hypotheses. 
This method introduces location reference points that are virtually placed in the UWB network,  providing additional constraints for the robot's global localization, as shown in Fig.~\ref{virtual}. 
The VA is established by a location estimator from the IMU/odometer fusion model. In this paper, considering a mobile robot equipped with a UWB tag that receives a signal from a UWB anchor, the corresponding virtual anchor can be generated by range measurements and the estimated position using the IMU/odometer fusion model. The range residual is established as
\begin{equation}
\textbf{e}_{j}^{r}=r_j-\left \| \textbf{x}_j-\textbf{p}_n \right \|_2, \label{range res}
\end{equation}
where \begin{math}r_j\end{math} is range measurement received at time  \begin{math}j\end{math}, $\textbf{x}_j$ denotes the location of the UWB tag in the world frame at time \begin{math}j\end{math}, \begin{math}\textbf{p}_n\end{math} is the position of UWB anchor \begin{math}n\end{math}.

\begin{figure}[!htbp]
\centering
\includegraphics[width=\linewidth,trim=2.5cm 5cm 13cm 2cm,clip]{virtual.pdf}
\caption{Illustrations of the Virtual Anchor (VA) generation process.
}
\label{virtual}
\end{figure}

We can obtain a model of the IMU/odometer system and derive the relative position transform between \begin{math}\textbf{x}_i\end{math} and \begin{math}\textbf{x}_j\end{math} over a short time \begin{math}i\end{math} to \begin{math}j\end{math}
\begin{equation}
\textbf{x}_j=\textbf{x}_i+\text{Exp}(\textbf{q}^\omega)\triangle\textbf{d}_{ij}.
\end{equation}
Since \begin{math}\textbf{q}^\omega\end{math} and \begin{math}\triangle\textbf{d}_{ij}\end{math} can be derived from Eq.~\eqref{2dIMU}, the robot’s pose and derived the relative position can be expressed as the virtual anchor’s position.
Eq.~\eqref{range res} can be further reformulated as follows: 
\begin{equation}
\begin{split}
\textbf{e}_{j}^{r} &= r_j - \left \| \textbf{x}_i - (\textbf{p}_n - \text{Exp}(\textbf{q}^\omega) \triangle \textbf{d}_{ij}) \right \|_2 \\
&= r_j - \left \| \textbf{x}_i - \hat{\textbf{p}}_{n}^{j} \right \|_2,
\end{split}
\end{equation}
where \begin{math}\hat{\textbf{p}}_{n}^{j}\end{math} is regarded as the position of the virtual UWB anchor. 
Based on this, the virtual anchor is generated through the ranging-gathering process that involves a set of robot waypoints. 
However, the random waypoints are often ill-posed in practice, resulting in suboptimal solutions. 
Selecting a proper information metric and determining the optimal waypoint placement is critical for improving accuracy.
The Fisher information Matrix (FIM)~\cite{6882246} is considered to evaluate the performance of VA's position estimation, and it is defined as:
\begin{equation}\textbf{F}_i=\frac{1}{\sigma_{r}^{2}}\textbf{J}^\text{T}\textbf{J},\end{equation}
\begin{equation}\textbf{J}=\frac{\partial\textbf{e}_{j}^{r}}{\partial \hat{\textbf{p}}_{n}^{j} },\end{equation}
 where \begin{math}\sigma_{r}\end{math} is the standard deviation of the ranging measurements. \begin{math}
     \textbf{J}
 \end{math} represents the Jacobian matrix of the ranging measurement model with respect to anchor’s position \begin{math}\hat{\textbf{p}}_{n}^{j}\end{math}. The determinant of the FIM \begin{math}det(\textbf{F}_i)\end{math} contains all the ranging measurement received during time \begin{math}i\end{math} to \begin{math}j\end{math}. 
 We can set a threshold \begin{math}\tau\end{math} and generate the virtual UWB anchor when \begin{equation}
    det(\textbf{F}_i)>\tau.
\end{equation}  
By maximizing \begin{math}det(\textbf{F}_i)\end{math}, the lower bound of the VA’s position estimation error can be directly determined and the optimal VA placement can be decided.

\subsubsection{Multiple Hypotheses-based Criteria for Virtual Anchors} 
We present the multiple hypotheses-based criteria to avoid collineation of generated virtual anchors.
The virtual anchor is derived from the IMU/odometer fusion model, if all the VA’s 2D positions constitute a straight line, it becomes difficult to obtain a unique solution for the target’s position without additional constraints. To
mitigate this problem, we use the determinant to ensure that generated virtual anchors are non-collinear. 
Assuming the locations of three virtual UWB anchors are
\begin{math}
\hat{\textbf{p}}_{n}^{j}=(\hat{x}_{n}^{j},\hat{y}_{n}^{j}),
\hat{\textbf{p}}_{n}^{j1}=(\hat{x}_{n}^{j1},\hat{y}_{n}^{j1}),
\hat{\textbf{p}}_{n}^{j2}=(\hat{x}_{n}^{j2},\hat{y}_{n}^{j2})
\end{math}.
The determinant $D$ is defined as:
\begin{equation}
D=\begin{vmatrix}
 \hat{x}_{n}^{j} & \hat{y}_{n}^{j} & 1\\
  \hat{x}_{n}^{j1} & \hat{y}_{n}^{j1} & 1\\
  \hat{x}_{n}^{j2} & \hat{y}_{n}^{j2} & 1
\end{vmatrix}.
\end{equation}
If \begin{math}
D=0\end{math}, the three virtual UWB anchors are collinear. We use a sample circle with multiple virtual anchor position hypotheses to avoid collinearity.
Thus, assuming \begin{math}h_j\end{math} different hypotheses  for position \begin{math}\hat{\textbf{p}}_{n}^{j}\end{math}, the UWB virtual anchor position will be written in the following form: \begin{equation}\textbf{b}_{n}^{j}=\textbf{H}_{j}^{k}\hat{\textbf{p}}_{n}^{j}\end{equation}
 \begin{equation}
 \textbf{H}_{j}^{k}=\begin{bmatrix}
 r_j & cos(2\pi(k-1)/h_j) & 0\\
  0&r_jsin(2\pi(k-1))/h_j)  & 0\\
  0& 0 &1
\end{bmatrix},k=1,...,h_j
\end{equation}
the resultant virtual anchor positions are obtained by minimizing the following expression: 
\begin{equation}\text{arg min} \sum_{j\in \Omega}\frac{1}{h_j}\sum_{m=1}^{h_j}(r_j-\left \| \textbf{x}_i-\textbf{b}_{n}^{jm} \right \| )\end{equation}
where \begin{math}\Omega\end{math} is the set of location information of the generated VAs.

\subsubsection{IMU Factor}
\label{imu_factor}
If raw IMU measurements are directly used to formulate the IMU factor, the optimization processes incur high computational costs. 
To avoid this, we use the IMU pre-integration between two sequential UWB ranging measurements. Given IMU angular velocity and linear acceleration \begin{math}\left \{ (\boldsymbol{\omega}_I,\textbf{a}_I)_t \right \}\end{math} and the start robot state \begin{math}\textbf{x}_{t-1}\end{math}, we have
\begin{equation}
\textbf{e}_{t}^\text{IMU}=\left \| \textbf{x}_t-\xi (\textbf{x}_{t-1},\boldsymbol{\omega}_I(t),\textbf{a}_I(t),\varepsilon_g,n_g,n_a ) \right \|  _2,
\end{equation}
where \begin{math}\varepsilon(\cdot)\end{math} represents the predicting function.
\begin{math}\boldsymbol{\omega}_I(t)\end{math} and \begin{math}
\textbf{a}_I(t)\end{math} can be obtained from the derivatives of the continuous-time B-splines in Eq.~\eqref{liegroup}, respectively. 
\begin{equation}
\begin{aligned}
\mathbf{a}_{I}(t) & ={ }_{I}^{W} \mathbf{R}^\text{T}(t)\left(\ddot{\mathbf{p}}_{I}(t)+g^{W}\right)+\varepsilon_{a}+n_{a}, \\
\boldsymbol{\omega}_{I}(t) & =\left({ }_{I}^{W} \mathbf{R}^\text{T}(t){ }_{I}^{W} \dot{\mathbf{R}}(t)\right)^{v}+\varepsilon_{g}+n_{g},
\end{aligned}
\end{equation}
where \begin{math}(\cdot)^v\end{math} maps the skew-symmetric matrix to the corresponding  3D vector, \begin{math}\ddot{\mathbf{p}}_{I}(t) \end{math} represents the translational component submatrices of the second order derivatives, 
 \begin{math}_{I}^{W} \dot{\mathbf{R}}(t)\end{math} is the rotational component submatrices of the first order derivatives. The continuous-time trajectory of IMU in the world frame is denoted as 
\begin{equation}
    { }_{I}^{W} \mathbf{T}(t)  =\left[{ }_{I}^{W} \mathbf{R}(t),{ }_{I}^{W} \mathbf{p}(t)\right].
\end{equation}

\subsubsection{Odometer Factor}
We assume all intrinsic and extrinsic parameters in UWB/IMU/odometer are pre-calibrated~\cite{bai2022graph,LI2024115186}, so we can handily get odometer trajectory  \begin{math}_{O}^{W}\mathbf{T}(t)\end{math}. The odometer factor can be defined as
\begin{equation}
\mathbf{e}_{t}^{o d o m}=\left\|\mathbf{x}_{t}-\psi\left(\mathbf{x}_{t-1}, \boldsymbol{\omega}_{o}(t), \mathbf{v}_{o}(t), \eta^{o}\right)\right\|_{2},
\end{equation}
where \begin{math}\psi(\cdot)\end{math} denotes the pre-integration of odometer measurements, 
\begin{math}\boldsymbol{\omega}_o(t)\end{math} and \begin{math}\boldsymbol{v}_o(t)\end{math} can be computed from the derivatives of the continuous-time trajectory, respectively.
\begin{equation}
\omega_{o}(t)=\left({ }_{o}^{W} \mathbf{R}^\text{T}(t){ }_{o}^{W} \mathbf{R}(t)\right)^{v}+\eta^{o}, 
\end{equation}
\begin{equation}
\mathbf{v}_{o}(t)={ }_{o}^{W} \mathbf{R}^\text{T}(t) \dot{\mathbf{p}}_{o}(t)+\eta^{o}.
\end{equation}
\begin{math}\dot{\mathbf{p}}_{o}(t)\end{math} represents the translational component submatrices of the first-order derivatives. 

\subsection{Adaptive Sliding-Window Continuous-time Trajectory Optimization}
\label{sec:Sliding-Window}

We design a continuous-time factor graph optimization for robot trajectory estimation based on the association between UWB/IMU/odometer data stream. 
Non-uniform B-splines are employed to obtain the optimal trajectory estimation continuously over time. To keep the computation tractable for online performance, an adaptive sliding window is designed to maintain a limited number of control points. 
The window length is adaptively updated based on the control point density as follows: 
\begin{equation}
\Delta L=\left\{\begin{array}{lc}
L_{\min } & \alpha \geq \lambda_{1}, \\
\beta \frac{\left(L_{\max }-L_{\min }\right)\left(\lambda_{1}-\alpha\right)}{\lambda_{1}-\lambda_{0}} & \lambda_{1}<\alpha<\lambda_{2}, \\
L_{\max } & \alpha \leq \lambda_{0},
\end{array}\right. \\
\end{equation}
where \begin{math}\alpha\end{math} is the control point density
\begin{equation}
\alpha=\frac{n}{\triangle T}.
\end{equation}
\begin{math}\triangle T\end{math} is the given time interval, $n$ is the number of control points in the trajectory segment in \begin{math}[t,t+\triangle T]\end{math}.
\begin{math}\lambda_0\end{math} and \begin{math}\lambda_1\end{math} denote the upper and lower thresholds of \begin{math}\alpha\end{math}, \begin{math}L_{min}\end{math} and \begin{math}L_{max}\end{math} denote the minimum and maximum length values of the sliding window, respectively. The setting of \begin{math}L_{min}\end{math} and \begin{math}L_{max}\end{math} are adjusted based on the intrinsic correlations of historical data and the the system’s available resources. \begin{math}\beta\end{math} is a constant related to the measurement frequency.

The factor graph optimization is solved consists of UWB ranging factor, IMU factor, odometer factor, the optimal state \begin{math}\hat{\mathbf{X}}\end{math} over an adaptive window of recent \begin{math}\tau\end{math} control points can be solved as follows:
\begin{equation}
\begin{split}
\hat{\mathbf{X}} = \arg \min \sum_{k=t-\tau}^{t} \Bigg( &\left\|\mathbf{e}_{k}^{\text{Range}}\right\|_{\Sigma_{k}^{\text{Range}}}^{2} + \left\|\mathbf{e}_{k}^{\text{IMU}}\right\|_{\Sigma_{k}^{\text{IMU}}}^{2}, \\
&+ \left\|\mathbf{e}_{k}^{\text{Odom}}\right\|_{\Sigma_{k}^{\text{odom}}}^{2} + \left\|\mathbf{e}_{k}^{\text{Prior}}\right\|_{\Sigma_{k}^{\text{prior}}}^{2} \Bigg),
\end{split}
\end{equation}
\begin{equation}
\mathbf{X}^{\text {prior }}=\left\{\mathbf{x}_{t-\tau-\kappa}, \ldots, \mathbf{x}_{t-\tau}, \Sigma_{t}^{\text {Prior }}\right\},
\end{equation}
where \begin{math}\sum_{k}^\text{Range}\end{math},
\begin{math}\sum_{k}^\text{IMU}\end{math},
\begin{math}\sum_{k}^\text{Odom}\end{math},
\begin{math}\sum_{k}^\text{Prior}\end{math} is the covariance matrix associated with UWB ranging, IMU, odometer measurements, and prior factor from marginalization, respectively. 
\begin{math}\textbf{X}^\text{prior}\end{math} represents the set of control points shared by adjacent adaptive sliding windows. We maintain a temporal sliding window within an adaptive length, where the active control points within the current window are optimized and updated. As the adaptive window slides forward, old control points \begin{math}\textbf{x}_{t-\tau-\kappa}\end{math} are removed from the sliding window.  However, they are still involved in constructing residuals within the current window to ensure continuance in motion estimation.

\begin{figure}[!t]
\centering
\includegraphics[width=\hsize,trim=0.1cm 0.55cm 0.1cm 0.1cm,clip]{2.pdf}
\caption{The experimental configurations in the corridor and exhibition hall environments. The red circles represent the positions of the UWB anchor.}
\label{fig_1}
\end{figure}

\section{Experiments}
\subsection{Experimental Setup}

Considering that there are no publicly available datasets for the UWB-Inertial-odometer system, we validated the effectiveness of the proposed CT-UIO on self-collected datasets.
Experimental campaigns are conducted in the corridor and exhibition hall scenes with different numbers of UWB anchors, as shown in Fig.~\ref{fig_1}.
The UWB tag, namely, Nooploop LinkTrack, IMU, and odometer are integrated into the Turtlebot3 Waffle Pi, as shown in Fig.~\ref{fig_0}. The maximum translational velocity and rotational velocity of the robot are $0.26m/s$ and $1.82rad/s$, respectively. 
The calibration of spatial position between these sensors is predefined. 
The measurement rate for each UWB anchor is set to $32Hz$, while odometer and IMU measurements are recorded at $28Hz$ and $127Hz$, respectively. 
UWB anchors are mounted on the tripods at a preset height, and the position of UWB anchors deployed in the environment has been calibrated.

The proposed CT-UIO is compared with three state-of-the-art UIO methods in the same experimental environments. These include discrete-time methods (Optimization+Filtering~\cite{yang2023novel} and Optimization+Trust Region~\cite{zhou2024optimization}), uniform B-spline-based continuous-time method (SFUISE)~\cite{li2023continuous}. The robot trajectories, generated by the LaMa framework\footnote{https://github.com/iris-ua/iris\_lama} through the fusion of  LIDAR and IMU data,  are regarded as the ground truth. All methods are designed with C++ and operated on the robot with the CPU of ARMv8 (NVIDIA JetsonTX2) in Melodic ROS (Robot Operating System).

The basic performance metric for CT-UIO evaluation by evo\footnote{https://github.com/MichaelGrupp/evo} is Absolute Positioning Error (APE). This metric is used to calculate the position deviation between the estimated robot trajectory and the ground truth trajectory after aligning to the same coordinate system. 

\begin{figure*}[t]
  \centering
  \subfloat[A-S1\label{fig:A-S1}]{
    \includegraphics[width=6cm]{fig/A/A-s1.pdf}
  }\hspace{-5mm}
  \subfloat[A-S2\label{fig:A-S2}]
  {
    \includegraphics[width=6cm]{fig/A/A-s2.pdf}
  }\hspace{-5mm}
  \subfloat[A-J1\label{fig:A-J1}]
  {
    \includegraphics[width=6cm]{fig/A/A-J1.pdf}
}
  \vspace{-4mm}
  \subfloat[A-J2\label{fig:mad}]{
    \includegraphics[width=6cm]{fig/A/A-J2.pdf}
  }\hspace{-5mm}
  \subfloat[A-H1\label{fig:irmad}]
  {
    \includegraphics[width=6cm]{fig/A/A-H1.pdf}
  }\hspace{-5mm}
  \subfloat[A-H2\label{fig:isfa}]
  {
    \includegraphics[width=6cm]{fig/A/A-H2.pdf}
  }
  \caption{We query the estimated trajectory from the obtained continuous-time trajectory and evaluate it against the ground-truth trajectory. The absolute translation error is mapped onto the estimated trajectory for each sequence in the corridor dataset. Our proposed CT-UIO not only achieves high accuracy in trajectory estimation but also effectively fits translational velocity variations.}
  \label{fig:A}
\end{figure*}


\subsubsection{Corridor Dataset}
The proposed algorithm is first evaluated in the corridor environment, where four UWB anchors are set within a $16.2m \times 15.6m$ area. 
These anchors are placed at the corners of the area, with coordinates $(0.88,2.99)m$, $(3.36,13.64)m$, $(15.01,-0.19)m$, and $(17.03,10.65)m$, respectively. 
Due to physical barriers, such as walls or metal structures, between  UWB anchors, only one or two UWB anchors are available under this non-fully observable condition. The robot's motion mode is varied by adjusting its linear acceleration. A total of six sequences are collected, consisting of three types of motion modes, that is slow, fast, and hybrid, as shown in Table~\ref{table0}.

\begin{table}[!htb]
\centering
\caption{Description of the sequences of the corridor dataset.}
\label{table0}
\fontsize{9}{11}\selectfont
\setlength{\tabcolsep}{0.5mm}
\begin{tabular}{ccccc}
\toprule
\makecell{\textbf{Seq}} & 
\makecell{\textbf{Duration} \\ (second)} & 
\makecell{\textbf{Length} \\ {(m)}} & 
\makecell{\textbf{Translational velocity} \\ {max/min (m/s)}} & 
\makecell{\textbf{Description}} \\
\midrule
A-S1 & 380.1 & 65.03 & 0.18/0.13 & Slow sequences \\
A-S2 & 376.0 & 62.99 & 0.16/0.12 & Slow sequences \\
A-J1 & 214.9 & 53.66 & 0.26/0.22 & Fast sequences \\
A-J2 & 199.2 & 51.49 & 0.26/0.22 & Fast sequences \\
A-H1 & 251.0 & 54.64 & 0.26/0.18 & Hybrid sequences \\
A-H2 & 232.7 & 52.55 & 0.26/0.16 & Hybrid sequences \\
\bottomrule
\end{tabular}
\end{table}
\begin{itemize}
\item Slow sequences: The robot moves gently at a slow translational velocity with gentle speed variations, following a square path.
\item Fast sequences: The robot moves at a large translational velocity with intense speed variations, following a square path. 
\item Hybrid sequences: 
The robot follows a square trajectory that combines both slow and fast translational motion, incorporating a mix of low and high-speed phases.
\end{itemize}


We compute the RMSE of APE error for each sequence across different methods. 
\begin{table}[!htb]
\centering
\caption{Performance comparison in APE (RMSE, Meter) of different methods on the corridor dataset. The best results are marked in bold.}
\label{table1}
\fontsize{9}{11}\selectfont
\setlength{\tabcolsep}{1.7mm}
\begin{tabular}{ccccc}
\toprule
\makecell{\textbf{Seq}} & 
\makecell{\textbf{Optimization+} \\ \textbf{Filtering}\cite{yang2023novel}} & 
\makecell{\textbf{Optimization+} \\ \textbf{Trust Region}\cite{zhou2024optimization}} & 
\makecell{\textbf{SFUISE}\\\cite{li2023continuous}} & 
\makecell{\textbf{Ours}} \\
\midrule
A-S1 & 0.756 & 0.550 & 0.210 & \textbf{0.208} \\
A-S2 & 0.605 & 0.520 & 0.262 & \textbf{0.242} \\
A-J1 & 0.248 & 0.575 & 0.229 & \textbf{0.181} \\
A-J2 & 0.382 & 0.593 & 0.208 & \textbf{0.153} \\
A-H1 & 0.447 & 0.658 & 0.487 & \textbf{0.403} \\
A-H2 & 0.548 & 0.671 & 0.448 & \textbf{0.416 }\\
\bottomrule
\end{tabular}
\end{table}
The results are summarized in Table~\ref{table1}, showing that our CT-UIO achieves the best accuracy when compared with the state-of-the-art methods. 
Due to the lack of sufficient available UWB anchors in the corridor environment, leading to fewer constraints in the pose graph optimization process and reduced localization accuracy for Optimization+Filtering~\cite{yang2023novel} and Optimization+Trust Region~\cite{zhou2024optimization} methods. 
In contrast, our CT-UIO introduces virtual UWB anchors to ensure full observability in the few-anchor localization system. This allows for the incorporation of multiple constraints into the factor graph optimization, resulting in more accurate localization estimates. 






In sequences such as A-S1 and A-S2, the improvement in APE is relatively minor when compared with the uniform B-spline-base method SFUISE.
In these sequences, where the robot’s movement is relatively slow, the proposed adaptive knot span adjustment does not necessarily lead to a significant improvement in performance. However, in sequences involving fast linear motion, such as A-J1 and A-J2, the errors in SFUISE  increase significantly.  In contrast, CT-UIO outperforms state-of-the-art methods in terms of the overall performance of pose interpolation.  
Across hybrid sequences, CT-UIO can improve localization accuracy significantly by $38.75\%$ in APE. 
This improvement is attributed to the adaptive knot span adjustment strategy, which allows dynamic adjustment of the number of control points by either lowering or increasing the knot span to accommodate varying motion speeds. Fig.~\ref{fig:A} shows the overview of trajectories in the corridor dataset, our method achieves consistent moving trajectories in most sequences.
Fig.~\ref{A-h2-cp} shows the illustration of the proposed adaptive knot span adjustment strategy in sequence A-H2. 

\begin{figure}[!t]
\centering
\includegraphics[width=\linewidth,trim=2cm 0.6cm 2.5cm 1.8cm,clip]{fig/A/A-h2-cp.pdf}
\caption{The distribution of control points in sequence A-H2.
}
\label{A-h2-cp}
\end{figure}
 
\subsection{Exhibition Hall Dataset}
We also evaluate CT-UIO and competing state-of-the-art methods on the exhibition hall dataset. 
In this case, two UWB anchors are placed at positions $(4.52,10.68)m$, $(-1.71,-2.29)m$ to create the non-fully observable condition within an area of $20.0m \times 11.6 m$ and there is no occlusion between UWB anchors. 
To evaluate the effectiveness of the methods under aggressive turns, we provide the corresponding range of rotational velocity readings, which indicate instances of aggressive motion. A total of six sequences are detailed in Table~\ref{table2}.

\begin{table}[!t]
\centering
\caption{Description of the sequences of the exhibition hall dataset.}
\label{table2}
\fontsize{9}{11}\selectfont
\setlength{\tabcolsep}{0.5mm}
\begin{tabular}{ccccc}
\toprule
\makecell{\textbf{Seq}} & 
\makecell{\textbf{Duration} \\ {(second)}} & 
\makecell{\textbf{Length} \\ {(m)}} & 
\makecell{\textbf{Rotational velocity} \\ {max/min (rad/s)}} & 
\makecell{\textbf{Description}} \\
\midrule
B-S1 & 224.2 & 30.37 & 0.20/0.14 & Slow sequences \\
B-S2 & 185.3 & 30.05 & 0.22/0.16 & Slow sequences \\
B-J1 & 135.7 & 31.09 & 1.76/0.22 & Fast sequences \\
B-J2 & 98.3 & 22.99 & 1.72/0.20 & Fast sequences \\
B-H1 & 84.1 & 18.02 & 1.70/0.15 & Hybrid sequences \\
B-H2 & 102.0 & 19.41 & 1.75/0.16 & Hybrid sequences \\
\bottomrule
\end{tabular}
\end{table}
\begin{itemize}
\item Slow sequences: the robot moves gently with low rotational velocity and gentle speed variations, following a wave path.
\item Fast sequences: the robot moves at large rotational velocity with intense speed variations, following a wave path.  
\item Hybrid sequences: The robot follows a wave trajectory that combines both slow and fast rotational motion, incorporating a mix of low and high-speed phases.
\end{itemize}

\begin{figure}[!htb]
\centering
\includegraphics[width=\linewidth,trim=0.5cm 0.6cm 2.5cm 1.8cm,clip]{fig/B/B-h2-cp.pdf}
\caption{The distribution of control points in sequence B-H2.
}
\label{B-h2-cp}
\end{figure}

Fig.~\ref{B-h2-cp} shows the distribution of control points in sequence B-H2. Fig.~\ref{fig:B} shows the overview of trajectories in the exhibition hall dataset. The APE results of the compared methods on the six sequences are summarized in Table~\ref{table3}. 

\begin{table}[!b]
\centering
\caption{Performance comparison in APE (RMSE, Meter) of different methods on the exhibition hall dataset. The best results are marked in bold.}
\label{table3}
\fontsize{9}{11}\selectfont
\setlength{\tabcolsep}{1.5mm}
\resizebox{\linewidth}{!}{
\begin{tabular}{ccccc}
\toprule
\makecell{\textbf{Seq}} & 
\makecell{\textbf{Optimization} \\ \textbf{+Filtering}\cite{yang2023novel}} & 
\makecell{\textbf{Optimization+} \\ \textbf{Trust Region}\cite{zhou2024optimization}} & 
\makecell{\textbf{SFUISE}\cite{li2023continuous}} & 
\makecell{\textbf{Ours}} \\
\midrule
B-S1 & 0.432 & 0.393 & 0.042 & \textbf{0.040} \\
B-S2 & 0.372 & 0.405 & 0.127 & \textbf{0.122} \\
B-J1 & 0.760 & 0.588 & 0.243 & \textbf{0.219} \\
B-J2 & 0.391 & 0.562 & 0.168 & \textbf{0.098} \\
B-H1 & 0.885 & 0.543 & 0.203 & \textbf{0.150} \\
B-H2 & 0.728 & 0.413 & 0.358 & \textbf{0.311} \\
\bottomrule
\end{tabular}
}
\end{table}

\begin{figure}[!htb]
  \centering
  \subfloat[B-S1\label{fig:B-S1}]{
    \includegraphics[width=0.45\linewidth]{fig/B/B-S1.pdf}
  }
  \subfloat[B-S2\label{fig:B-S2}]
  {
    \includegraphics[width=0.45\linewidth]{fig/B/B-S2.pdf}
  }
  
  \subfloat[B-J1\label{fig:B-J1}]
  {
    \includegraphics[width=0.45\linewidth]{fig/B/B-J1.pdf}
}
  \subfloat[B-J2\label{fig:B-J2}]{
    \includegraphics[width=0.45\linewidth]{fig/B/B-J2.pdf}
  }
  
  \subfloat[B-h1\label{fig:B-h1}]
  {
    \includegraphics[width=0.45\linewidth]{fig/B/B-h1.pdf}
  }
  \subfloat[B-h2\label{fig:B-h2}]
  {
    \includegraphics[width=0.36\linewidth]{fig/B/B-h2.pdf}
  }
  \caption{We align the obtained continuous-time trajectory for all sequences in the exhibition hall dataset with the ground-truth trajectories at the same frequency. The absolute translation error is mapped onto the estimated trajectory for each sequence. It can be observed that our CT-UIO achieves high accuracy in trajectory estimation, closely matching the ground-truth trajectories across all sequences, even in those involving fast turns. }
  \label{fig:B}
\end{figure}
The results notably indicate that CT-UIO achieves an overall improvement in localization performance, even in sequences involving fast turning, thereby verifying the effectiveness of its dynamic knot span adjustment strategy. 


Furthermore, it is noteworthy that the discrete-time methods (Optimization+Filtering~\cite{yang2023novel} and Optimization+Trust Region~\cite{zhou2024optimization}) lead to an increase of APE or even exhibit obvious location deviations when the robot undergoes rapid rotational motion. 
Compared with the uniform B-splines method (SFUISE), CT-UIO ensures a better capture of motion characteristics by adjusting the control point density. Specifically, CT-UIO  reduces the density of control points in sections with less speed variation and increases it during significant speed changes. SFUISE cannot adapt to trajectory complexity, as it sets the knot span as a constant value throughout the trajectory.  Besides, in the case of only two UWB anchors, UWB positioning suffers a notable accuracy degradation. To address the observability issue in a few-anchor system, CT-UIO introduces virtual anchors by coupling UWB-ranging data and motion priors from the IMU/odometer fusion model to provide more comprehensive constraints. Based on this, the proposed CT-UIO exhibits robustness performance through multiple virtual anchor ranging constraints even with limited anchor availability.

The results of these experiments in corridor and exhibition hall datasets prove that the proposed CT-UIO is highly effective in situations involving fast translational and rotational motion. Across all sequences, the  CT-UIO system maintains more stable and consistent accuracy by utilizing a non-uniform continuous-time trajectory representation. This strategy effectively adjusts the control point interval and ensures better capture of motion pattern characteristics.

\section{Conclusion}
In this article, we present the CT-UIO, a continuous-time UWB-Inertial-odometer localization system designed to achieve accurate and robust localization under few-anchor conditions. CT-UIO tightly integrates UWB ranging, IMU, and odometer data using non-uniform B-spline trajectory representation. Specifically, the proposed system enhances state estimation accuracy in fast-moving scenarios by adaptively placing control points according to varying motion speeds. 
To ensure the UWB-based localization system is fully observable, CT-UIO combines UWB ranging with motion prior from the IMU/odometer fusion model to generate virtual anchors. 
Additionally, CT-UIO’s backend conducts adaptive sliding window factor pose graph optimization, incorporating constraints from virtual UWB anchor ranging, IMU, and odometer measurements.  The proposed CT-UIO system is evaluated in several real-world few-anchor situations using self-collected datasets. 
Compared to state-of-the-art discrete-time and continuous-time estimation methods, CT-UIO consistently produces more consistent and robust trajectory estimation, particularly in fast-motion scenes.

In the future, it is worthwhile exploring the implementation of the proposed CT-UIO localization system with unknown anchor positions, as well as incorporating complementary sensors, such as cameras, to enhance the accuracy of short-term pose estimates.


\bibliography{references}
\bibliographystyle{IEEEtran}

\end{document}


