\section{Introduction}
\label{sec: intro}

Denoising diffusion probabilistic models (DDPMs) \citep{ho2020denoising,sohl2015deep} are latent variable generative models consisting of i) the \textit{forward process}, where the original data samples are gradually corrupted by adding Gaussian noise to eventually become a standard normal prior; ii) the \textit{reverse process}, in which a neural network is responsible for recovering the original data from the corrupted samples by learning to sequentially reverse the diffusion process. With their exceptional capabilities of generating high-quality data, DDPMs can be applied to various signal restoration tasks -- recovering the missing components in a signal due to contamination (e.g., audio recorded with environmental noises \citep{lu2021study,lu2022conditional,tai2023revisiting}, images obstructed by various measurement noises \citep{ozdenizci2023restoring,croitoru2023diffusion}), by conditioning the DDPM on the degraded observations.

However, for the diffusion model to adequately learn the reverse process, a large number of training iterations may be required, leading to potentially slow model convergence. Such inefficiency was recently related to the discrepancy between the real data distribution and the accustomed choice of the standard Gaussian prior by \citet{lee2021priorgrad}. They have thus proposed a simple yet effective approach called PriorGrad, whose main idea is to construct a better prior by using some rule-based approaches to extract useful information from the conditioner data. However, despite improving performance on some generative speech tasks, handcrafting a ``better'' prior requires certain knowledge about the data characteristics, and such guidance may not always exist. 

In this paper, our main focus is to investigate the question: \textit{Can we systematically obtain a better prior distribution that improves the efficiency of the diffusion generative process?} In other words, we aim to develop a framework of \textit{learning-based} diffusion priors for improved DDPM efficiency. A high-level view of our approach is depicted in Figure \ref{fig: overview}, where the conditional DDPM (parameterized by $\theta$) samples the latent noise $\boldsymbol{\epsilon}$ from a learned prior distribution estimated by a \textit{prior encoder} $\psi$, which takes the conditioner $\mathbf{y}$ as input. 
The prior encoder is jointly trained with the DDPM $\theta$ to synthesize the data $\mathbf{x}_0$, and a \textit{posterior encoder} $\phi$ that exploits information from both $\mathbf{x}_0$ and $\mathbf{y}$, to align the prior and posterior distributions. The main idea here is that, if there is a certain correlation between the conditioner $\mathbf{y}$ and the target data $\mathbf{x}_0$, e.g., in signal restoration problems where $\mathbf{y}$ is typically a degraded version of $\mathbf{x}_0$, our framework can exploit such correlation to construct a more informative prior in an automatic and systematic manner.

\begin{figure}[!t]
    \centering
     \includegraphics[width=0.9\linewidth]{Figs/overview_2.pdf}
     \vspace{-0.25cm}
    \caption{High-level view of the proposed method.} 
\label{fig: overview}
\end{figure}

To explore the idea, we introduce RestoreGrad, a new paradigm for improving conditional DDPM by jointly learning the prior distribution with the diffusion model, focusing on signal restoration applications. We apply RestoreGrad to speech enhancement (SE) and image restoration (IR) tasks to demonstrate its generality for signals of different nature. 
For SE, we compare with PriorGrad \citep{lee2021priorgrad} which provides guidance on handcrafting suitable priors in the speech domain. For IR, we show that RestoreGrad serves as a promising solution for improving the baseline DDPM even in a domain that lacks such a recipe for engineering the prior. As shown in Figure \ref{fig: training_curve}, models trained using RestoreGrad are more data and compute-efficient than the baseline DDPM and PriorGrad; they converge faster to achieve higher quality of the restored signal. Further shown in Figure \ref{fig: learned priors}, the learned prior is more informative as it better correlates with the desired signal than an isotropic covariance, potentially simplifying the diffusion trajectory for improved model efficiency. 

Our main contributions are summarized as follows:
\begin{itemize}[leftmargin=*]
\vspace{-0.25cm}
    \item We study the problem of learning the prior distribution \textit{jointly} with the conditional DDPM for signal restoration applications, aiming at providing a more systematic, \textit{learning-based} treatment to address the inefficiency incurred by existing selections of the prior distribution. 
    \vspace{-0.05cm}
    \item We propose a new framework called RestoreGrad that learns the prior in conjuncture with the DDPM model through a \textit{prior encoder}, by exploiting the correlation between the targe signal and input degraded signal encoded by an auxiliary \textit{posterior encoder}, for improved model efficiency. 
    Our \textit{two-encoder} learning framework is established based on a novel evidence lower bound (ELBO) that seamlessly integrates the DDPM into the variational autoencoder (VAE) \citep{kingma2013auto} to harness the advantages of both methodologies.
    \vspace{-0.05cm}
    \item Experiments demonstrate that the proposed paradigm is quite general and can benefit both training and sampling of DDPMs, achieving considerable improvements with lightweight encoders in high quality signal restoration tasks of various modalities including images and audio.
\end{itemize}

\begin{figure}[!t]
    \centerline{\includegraphics[width=1\linewidth]{Figs/training_curves_3.pdf}}
    \vspace{-0.3cm}
    \caption{Model learning performance. (Top) In speech domain, RestoreGrad outperforms PriorGrad \citep{lee2021priorgrad}, a recently proposed improvement to baseline DDPM (CDiffuSE) by leveraging handcrafted priors. (Bottom) In image domain, RestoreGrad provides a paradigm to improve DDPM baseline (RainDropDiff) where there is no existing recipe for computing better priors.} 
\label{fig: training_curve}
\end{figure} 

\begin{figure}[!t]  
    \centerline{\includegraphics[width=1\linewidth]{Figs/learned_prior_SE_IR_2.pdf}}
    \vspace{-0.3cm}
    \caption{Visualizing the learned prior distribution. Here, the assumed prior form is: $p_\psi(\boldsymbol{\epsilon}|\mathbf{y})\coloneq\mathcal{N}(\boldsymbol{\epsilon}; \mathbf{0},\mbox{diag}\{\boldsymbol{\sigma}^2_{\text{prior}}(\mathbf{y};\psi)\})$, where $\boldsymbol{\sigma}_{\text{prior}}$ is estimated by the prior encoder $\psi$ with input $\mathbf{y}$. It appears that $\boldsymbol{\sigma}_{\text{prior}}$ follows the level variation of the speech waveform and preserves the structure of the original image. This indicates that an informative prior approximating the data distribution has been obtained for improved efficiency of the diffusion process.} 
\label{fig: learned priors}
\end{figure} 
