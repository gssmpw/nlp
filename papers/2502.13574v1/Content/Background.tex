\section{Background on DDPMs}

\noindent\textbf{Forward Process:}
DDPMs \citep{ho2020denoising,sohl2015deep} slowly corrupt the training data using Gaussian noise in the forward process. Let $q_{\text{data}}(\mathbf{x}_0)$ be the data density of the original data $\mathbf{x}_0$. The forward process is a fixed Markov Chain that sequentially corrupts
the data $\mathbf{x}_0 \sim q_{\text{data}}(\mathbf{x}_0)$ in $T$ diffusion steps, by injecting Gaussian noise according to a variance schedule $\{\beta_t\}_{t=1}^{T}\in[0,1)$:
\begin{equation}
    q(\mathbf{x}_{1:T}|\mathbf{x}_0)\coloneq\prod_{t=1}^Tq(\mathbf{x}_t|\mathbf{x}_{t-1}),
\label{eq: ddpm forward}
\end{equation}
where $q(\mathbf{x}_t|\mathbf{x}_{t-1})\coloneq\mathcal{N}(\mathbf{x}_t;\sqrt{1-\beta_t}\mathbf{x}_{t-1}, \beta_t\mathbf{I})$ is the transition probability at step $t$. It allows the direct sampling of $\mathbf{x}_t$ according to $q(\mathbf{x}_t|\mathbf{x}_0)=\mathcal{N}(\mathbf{x}_t;\sqrt{\bar{\alpha}_t}\mathbf{x}_0,\sqrt{1-\bar{\alpha}_t}\mathbf{I})$, where $\bar{\alpha}_t\coloneq\prod_{i=1}^t\alpha_i$ with $\alpha_t\coloneq 1-\beta_t$; i.e., we can sample $\mathbf{x}_t=\sqrt{\bar{\alpha}_t}\mathbf{x}_0+\sqrt{1-\bar{\alpha}_t}\boldsymbol{\epsilon}$, where $\boldsymbol{\epsilon}\sim\mathcal{N}(\mathbf{0},\mathbf{I})$. A notable assumption is that with a carefully designed variance schedule $\beta_t$ and large enough $T$, such that $\bar{\alpha}_T$ is sufficiently small, $q(\mathbf{x}_T|\mathbf{x}_0)$ converges to $\mathcal{N}(\mathbf{x}_T;\mathbf{0},\mathbf{I})$ so that the distribution of $\mathbf{x}_T$ is well approximated by the standard Gaussian.

\noindent\textbf{Reverse Process:}
One can generate new data samples from $q_{\text{data}}(\mathbf{x}_0)$ by reversing the predefined forward process utilizing the same functional form. That is, we can progressively transform a noise $\mathbf{x}_T\sim p(\mathbf{x}_T)=\mathcal{N}(\mathbf{x}_T; \mathbf{0}, \mathbf{I})$ back into the data by approximating the reverse of the forward transition probability. This process is defined by the joint distribution $p_\theta(\mathbf{x}_{0:T})$ of a Markov Chain with learned transitions:
\begin{equation}
    p_\theta(\mathbf{x}_{0:T})\coloneq p(\mathbf{x}_T)\prod_{t=1}^Tp_\theta(\mathbf{x}_{t-1}|\mathbf{x}_t),
\label{eq: ddpm reverse}
\end{equation}
where $p_\theta(\mathbf{x}_{t-1}|\mathbf{x}_t)\coloneq\mathcal{N}(\mathbf{x}_{t-1};\boldsymbol{\mu}_\theta(\mathbf{x}_t,t), \boldsymbol{\Sigma}_\theta(\mathbf{x}_t,t))$ is the reverse transition probability parameterized by a network $\theta$. 

\noindent\textbf{DDPM Learning Framework:} Ideally, we would train the model $\theta$ with a maximum likelihood objective such that $p_\theta(\mathbf{x}_0)$ is as large as possible, which is unfortunately intractable. To circumvent such difficulty, DDPMs \citep{ho2020denoising} instead maximize an ELBO of the data log-likelihood, by introducing a sequence of hidden variables $\mathbf{x}_{1:T}$ and the approximate variational distribution $q(\mathbf{x}_{1:T}|\mathbf{x}_0)$: 
\begin{equation}
    \log p_\theta(\mathbf{x}_0)\geq\mathbb{E}_{q(\mathbf{x}_{1:T}|\mathbf{x}_0)}\left[\log\frac{p_\theta({\mathbf{x}_{0:T}})}{q(\mathbf{x}_{1:T}|\mathbf{x}_0)}\right].
\label{eq: ddpm log likelihood}
\end{equation}
With the above parametric modeling of the forward and reverse processes, the ELBO (\ref{eq: ddpm log likelihood}) suggests training the network $\theta$ such that, at each time step $t$, $p_\theta(\mathbf{x}_{t-1}|\mathbf{x}_t)$ is as close as possible to the true forward process posterior conditioned on $\mathbf{x}_0$ \citep{luo2022understanding,croitoru2023diffusion}, i.e., $q(\mathbf{x}_{t-1}|\mathbf{x}_t,\mathbf{x}_0)=\mathcal{N}(\mathbf{x}_{t-1};\tilde{\boldsymbol{\mu}}_t(\mathbf{x}_t,\mathbf{x}_0),\tilde{\beta}_t\mathbf{I})$,
where $\tilde{\beta}_t\coloneq\frac{1-\bar{\alpha}_{t-1}}{1-\bar{\alpha}_t}\beta_t$ and  $\tilde{\boldsymbol{\mu}}_t(\mathbf{x}_t,\mathbf{x}_0)\coloneq\frac{\sqrt{\bar{\alpha}_{t-1}}\beta_t}{1-\bar{\alpha}_t}\mathbf{x}_0+\frac{\sqrt{\alpha_t}(1-\bar{\alpha}_{t-1})}{1-\bar{\alpha}_t}\mathbf{x}_t$.

Based on using a fixed covariance $\boldsymbol{\Sigma}_\theta(\mathbf{x}_t,t)=\sigma_t^2\mathbf{I}$ (e.g., $\sigma_t^2=\tilde{\beta}_t$) as in \citet{ho2020denoising}, maximizing (\ref{eq: ddpm log likelihood}) corresponds to training a network $\boldsymbol{\mu}_\theta(\mathbf{x}_t,t)$ that predicts $\tilde{\boldsymbol{\mu}}_t(\mathbf{x}_t,\mathbf{x}_0)$. Alternatively, \citet{ho2020denoising} suggested the following reparameterization to rewrite the mean as a function of noise: 
\begin{equation}
       \boldsymbol{\mu}_\theta(\mathbf{x}_t,t)=\frac{1}{\sqrt{\alpha_t}}\left(\mathbf{x}_t-\frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}}\boldsymbol{\epsilon}_\theta(\mathbf{x}_t,t)\right).
\label{eq: mean}
\end{equation}
They train a network $\boldsymbol{\epsilon}_\theta(\mathbf{x}_t,t)$ to predict the real noise $\boldsymbol{\epsilon}\sim\mathcal{N}(\mathbf{0},\mathbf{I})$ and use (\ref{eq: mean}) to compute the mean. Practically it is carried out by minimizing a simplified training objective: 
\begin{equation}
    \mathcal{L}_{\text{simple}}(\theta)\coloneq\mathbb{E}_{\mathbf{x}_0,\boldsymbol{\epsilon},t}\left[\norm{\boldsymbol{\epsilon}-\boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t)}^2\right],
\label{eq: ddpm loss simple}
\end{equation}
which measures, for a random time step $t\sim\mathcal{U}(\{1,\dots,T\})$, the distance between the actual noise and estimated noise.

\noindent\textbf{Signal Restoration by Conditional DDPMs:}
Signal restoration problems are concerned with recovering the original signals from their degraded observations, which are of paramount importance in reality while remaining challenging, as noises are ubiquitous and may be strong enough to cause significant degradation of the signal quality. Recently, adoption of deep generative models \citep{kingma2013auto,goodfellow2014generative,ho2020denoising} for signal restoration tasks has considerably increased due to their remarkable capabilities of generating missing components in the data, with conditional DDPMs \citep{croitoru2023diffusion,cao2024survey} demonstrating substantial promise. More formally, let $\mathbf{y}$ denote the degraded observation of the clean signal $\mathbf{x}_0$. Recovering $\mathbf{x}_0$ given $\mathbf{y}$ by a model $\theta$ can be cast as maximizing the conditional likelihood of data $p_\theta(\mathbf{x}_0|\mathbf{y})$. The problem is in general intractable, but can be approximated by using a DDPM conditioned on $\mathbf{y}$. The main idea is, without modifying the forward diffusion process (\ref{eq: ddpm forward}), to learn a conditional diffusion model $\theta$ with $\mathbf{y}$ provided as input to the reverse process \citep{ozdenizci2023restoring}:
\vspace{-0.2cm}
\begin{equation}
    p_\theta(\mathbf{x}_{0:T}|\mathbf{y})\coloneq p(\mathbf{x}_T)\prod_{t=1}^Tp_\theta(\mathbf{x}_{t-1}|\mathbf{x}_t,\mathbf{y}),
\label{eq: cddpm reverse}
\end{equation}
where $p_\theta(\mathbf{x}_{t-1}|\mathbf{x}_t,\mathbf{y})\coloneq\mathcal{N}(\mathbf{x}_{t-1};\boldsymbol{\mu}_\theta(\mathbf{x}_t,\mathbf{y},t), \sigma_t^2\mathbf{I})$.
%, such that the sample has high fidelity to the target data distribution conditioned on $\mathbf{y}$. 
Typically, a fixed covariance is assumed and the noise estimator network $\boldsymbol{\epsilon}_\theta(\mathbf{x}_t, \mathbf{y}, t)$ is used to predict the mean.
