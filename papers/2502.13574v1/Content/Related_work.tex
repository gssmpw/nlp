\section{Related Work}

\noindent\textbf{Diffusion Efficiency Improvements:} 
\citet{das2023image} utilized the shortest path between two Gaussians and \citet{song2020denoising} generalized DDPMs via a class of non-Markovian diffusion processes to reduce the number of diffusion steps. \citet{nichol2021improved} introduced a few simple modifications to improve the log-likelihood. \citet{pandey2022diffusevae, pandey2021vaes} used DDPMs to refine VAE-generated samples. \citet{rombach2022high} performed the diffusion process in the lower dimensional latent space of an autoencoder to achieve high-resolution image synthesis, and \citet{liu2023audioldm} studied using such latent diffusion models for audio. \citet{popov2021grad} explored using a text encoder to extract better representations for continuous-time diffusion-based text-to-speech generation. More recently, \citet{nielsendiffenc} explored using a time-dependent image encoder to parameterize the mean of the diffusion process. Orthogonal to the above, PriorGrad \citep{lee2021priorgrad} and follow-up work \citep{koizumi22_interspeech} studied utilizing informative prior extracted from the conditioner data for improving learning efficiency. \textit{However, they become sub-optimal when the conditioner are degraded versions of the target data, posing challenges in applications like signal restoration tasks.}

\noindent\textbf{Diffusion-Based Signal Restoration:}
Built on top of the diffusion models for audio generation, e.g., \citet{kong2020diffwave,chen2020wavegrad,leng2022binauralgrad}, many SE models have been proposed. The pioneering work of \citet{lu2022conditional} introduced conditional DDPMs to the SE task and demonstrated the potential. Other works \citep{serra2022universal,welker2022speech,richter2023speech,yen2023cold,lemercier2023storm,tai2024dose} have also attempted to improve SE by exploiting diffusion models. In the vision domain, diffusion models have demonstrated impressive performance for IR tasks \citep{li2023diffusion,zhu2023denoising,huang2024wavedm,luo2023refusion,xia2023diffir,fei2023generative,hurault2022gradient,liu20232,chung2024direct,chungdiffusion,zhoudenoising,xiaodreamclean,zheng2024diffusion}. A notable IR work is \cite{ozdenizci2023restoring} that achieved impressive performance on several benchmark datasets for restoring vision in adverse weather conditions. \textit{Despite showing promising results, existing works have not fully exploited prior information about the data as they mostly settle on standard Gaussian priors.} 