\documentclass[11pt]{article}

% Basic packages
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{url}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{multirow}
\usepackage{array}
\usepackage[table]{xcolor}
\usepackage{threeparttable}
\usepackage{makecell}
\usepackage{subfig}
\usepackage{times}
\usepackage{soul}
\usepackage{lineno}
\usepackage{amssymb}


% Page layout
\usepackage[margin=1in]{geometry}

% Theorem environments
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}{Definition}

% Custom commands
\newcommand{\eg}{e.g.,\xspace}
\newcommand{\ie}{i.e.,\xspace}

% Title and author information
\title{Graph Anomaly Detection via Adaptive Test-time Representation Learning across Out-of-Distribution Domains}

\author{
Delaram Pirhayati \\
Rice University, Houston, TX, USA \\
\texttt{dp43@rice.edu}
\and
Arlei Silva \\
Rice University, Houston, TX, USA \\
\texttt{arlei@rice.edu}
}

\date{}

\begin{document}

\maketitle

\begin{abstract}
Graph Anomaly Detection (GAD) has demonstrated great effectiveness in identifying unusual patterns within graph-structured data. However, while labeled anomalies are often scarce in emerging applications, existing supervised GAD approaches are either ineffective or not applicable when moved across graph domains due to distribution shifts and heterogeneous feature spaces. To address these challenges, we present AdaGraph-T3, a novel test-time training framework for cross-domain GAD. AdaGraph-T3 combines supervised and self-supervised learning during training while adapting to a new domain during test time using only self-supervised learning by leveraging a homophily-based affinity score that captures domain-invariant properties of anomalies. Our framework introduces four key innovations to cross-domain GAD: an effective self-supervision scheme, an attention-based mechanism that dynamically learns edge importance weights during message passing, domain-specific encoders for handling heterogeneous features, and class-aware regularization to address imbalance. Experiments across multiple cross-domain settings demonstrate that AdaGraph-T3 significantly outperforms existing approaches, achieving average improvements of over 6.6\% in AUROC and 7.9\% in AUPRC compared to the best competing model.
\end{abstract}

\section{Introduction}

Graph Anomaly Detection (GAD) is a critical task to identify unusual patterns (or outliers) in graph-structured data \cite{ma2021comprehensive,akoglu2015graph}. This problem has many real-world applications such as in 
e-commerce \cite{zhang2022efraudcom}, social networks \cite{venkatesan2019graph}, fraud detection \cite{jiang2019anomaly}, and cybersecurity \cite{lazarevic2003comparative}. A key limitation of existing GAD models is that they face unique cross-domain challenges that distinguish them from general graph learning tasks. These include inconsistent definitions of normal/anomalous patterns and heterogeneous feature spaces between domains (e.g., Facebook vs. Amazon datasets). These applications would benefit from GAD models capable of adapting across Out-Of-Distribution (OOD) and heterogeneous graphs.

A major motivation for our work is cybersecurity. Network intrusion detection systems play a key role in identifying malicious network activity associated with cyberattacks \cite{tsai2009intrusion,kilincer2021machine}. Due to the volume and dynamic nature of these attacks, modern intrusion detection systems increasingly rely on large amounts of data and machine learning to assist cybersecurity experts in detecting potential intrusions. However, one of the major challenges in data-driven cybersecurity is the lack of sufficient labeled data for training supervised models. This is particularly critical for emerging applications, where traces
of labeled intrusions are scarce and the ability to leverage attacks or other types of anomalous behavior from existing labeled datasets would be greatly beneficial. 

In this paper, we investigate the task of unsupervised domain adaptation for GAD focusing on the transfer of knowledge from a labeled source to an unlabeled target domain. While domain adaptation for graphs has been extensively studied \cite{shi2024graph,wang2021one,zheng2019addgraph,yin2023coco,wang2023tdan, ding2018graph}, cross-domain graph anomaly detection is an emerging area \cite{wang2023cross,ding2021cross}. We propose using Test-Time Training (TTT) \cite{sun2020test} to address key challenges in cross-domain graph anomaly detection. Unlike traditional domain adaptation methods that require continuous access to source data, TTT allows us to distill source knowledge into model parameters and adapt to target domains using only self-supervision. This is particularly advantageous for graph anomaly detection where source data may be sensitive or unavailable during the adaptation phase to new domains. %Our TTT framework enables efficient adaptation through a homophily-based self-supervised objective that captures universal properties of graph anomalies---as anomalous nodes typically exhibit lower homophily than normal nodes across domains \cite{qiao2024truncated,chen2024consistency}---combined with dataset-specific encoders that capture domain-dependent patterns and enable the transfer of supervised knowledge from the source to the target domain.

%Test-Time Training (TTT) framework has achieved promising results for domain adaptation, including on graphs \cite{li2022out,wu2024graph,zhang2024test}. In the training phase, AdaGraph-T3 combines a supervised and a self-supervised loss to learn model parameters based on a source dataset. In the TTT phase, the model is adapted to the target dataset using the self-supervised loss only. 


Our approach, Adaptive Graph Test-Time Training (AdaGraph-T3), has four major innovations compared to existing work on cross-domain GAD. First, it leverages a homophily-based affinity score \cite{qiao2024truncated,chen2024consistency} for self-supervised learning based on the observation that normal nodes are more similar to their neighbors than anomalous ones, a pattern that remains consistent across domains (see Figure \ref{fig:homophily}). Second, it introduces Normal Structure-preserved Attention Weighting (NSAW), which dynamically learns continuous edge importance weights through the attention mechanism. Third, AdaGraph-T3 applies source and target-specific encoders that are trained end-to-end to handle both distribution shifts and heterogeneous feature spaces. Fourth, to address the extreme class imbalance challenge in GAD \cite{ma2024graph}, our approach employs class-aware regularization during source training---with a stronger regularization to the minority class. %Finally, we design a Maximum Mean Discrepancy (MMD) based stopping criterion for test-time training.

We compare our solution against both graph domain adaptation and graph anomaly detection approaches from the literature using multiple cross-domain datasets. For instance, we show that labeled anomalies in the Amazon dataset (source) can improve the GDA accuracy on the Facebook dataset (target). The experiments show that AdaGraph-T3 significantly outperforms the alternatives in most of the settings.
The contributions of this paper can be summarized as:

%A key obstacle in developing effective GAD models is the issue of class imbalance. Our approach tackles this by leveraging the distinct homophily distributions of normal and anomalous nodes. Normal nodes are likely to be adjacent to other normal nodes. As a result, they typically exhibit significantly higher homophily, providing a distinctive pattern for differentiating between normal and anomalous nodes, as illustrated in Figure \ref{fig:homophily} \cite{qiao2024truncated, chen2024consistency}. We formulate a self-supervised task that maximizes node homophily scores, enabling effective differentiation between node types.





\begin{itemize}
    % \item We address the novel research problem of graph anomaly detection with domain adaptation through test-time training. To the best of our knowledge, it is the first test time adaptation method tailored for GADs.
    \item We propose the first test-time training (TTT) framework for cross-domain graph anomaly detection (AdaGraph-T3). TTT enables adaptation to new target domains without requiring direct access to source data or target labels at test time. Our approach leverages homophily-based self-supervision which captures universal patterns, as anomalous nodes typically exhibit lower homophily compared to normal nodes.
    % providing a more flexible and learnable alternative to edge removal approaches previously applied in GAD.
    \item Our message-passing technique introduces homophily-based attention weights that naturally suppress anomalous influences on normal nodes while preserving graph structure, enabling robust anomaly detection.
    \item We propose several strategies specifically designed for the cross-domain GAD problem such as data-specific encoders, class-aware regularization, and an effective early-stopping strategy to prevent overfitting during test-time adaptation.
    \item AdaGraph-T3's performance is demonstrated through extensive experiments on cross-network tasks using multiple datasets and baselines that span both the domain adaptation and the anomaly detection literature. Our approach achieves average improvements of over 6.6\% in AUROC and 7.9\% in AUPRC compared to the best competing model.
\end{itemize}

\section{Related Work}
\subsection{Graph Domain Adaptation (GDA)}
While graph domain adaptation (GDA) methods have shown success in transferring knowledge across different domains \cite{shi2024graph}, they face fundamental limitations when applied to anomaly detection tasks. As traditional GDA methods are designed for node classification scenarios with balanced classes and consistent label semantics. 

% Unlike in-domain GAD which primarily deals with evolving patterns within the same domain, cross-domain GAD must handle additional challenges including heterogeneous feature spaces between domains (e.g., Facebook vs. Amazon datasets), varying definitions of normal behavior, and domain-specific structural patterns that define anomalies.

Traditional Graph Domain Adaptation (GDA) approaches, such as GRADE \cite{wu2023non}, AdaGCN \cite{dai2022graph}, and UDA-GCN \cite{wu2020unsupervised} and spectral regularization methods \cite{you2023graph} focus on minimizing distribution shifts across domains but require training samples during inference, limiting their real-time adaptation capabilities. Test-time training (TTT) \cite{sun2020test} has emerged as a powerful framework for handling distribution shifts \cite{li2022out,wu2024graph,zhang2024fully}. Methods like GTrans \cite{jin2022empowering}, GraphCL \cite{you2020graph}, and GT3 \cite{wang2022test} propose graph-specific approaches. TENT \cite{wang2020tent}
uses prediction entropy minimization, while GraphTTA \cite{chen2022graphtta} leverages information theory for TTT on graphs. However, existing GDA approaches, including both traditional methods and TTT-based solutions, face key limitations for anomaly detection as they (1) don't account for extreme class imbalance within domains, (2) lack mechanisms to preserve anomaly-indicating patterns during transfer, and (3) don't handle heterogeneous feature spaces across domains. While there exists limited research on cross-domain graph anomaly detection, prior approaches require direct access to the source dataset during adaptation \cite{ding2021cross, wang2023cross}. Our approach offers key advantages over these methods by eliminating the need to store and access the full source dataset during adaptation. This makes AdaGraph-T3 both privacy-preserving and memory-efficient, making it more practical for real-world deployment where data privacy and computational resources are concerns.

Our work addresses key challenges in deploying GDA in anomaly detection through dataset-specific encoders for heterogeneous feature spaces and a homophily-based unsupervised learning approach that extracts domain-invariant properties of anomalies that generalize across different graph domains. In our experiments, we show that AdaGraph-T3 often outperforms multiple GDA baselines, including GRADE, AdaGCN, TENT, and GTrans.


\begin{figure}[t]
   \centering
   \includegraphics[width=0.6\linewidth]{Figures/homophily_analysis.pdf}
   \caption{Distributions of homophily scores show normal nodes (blue) higher than anomalous nodes (orange) across domains, indicating homophily as a domain-invariant anomaly detector.}
   \label{fig:homophily}
\end{figure}
\subsection{Graph Anomaly Detection (GAD)}
Graph Anomaly Detection (GAD) \cite{ma2021comprehensive,akoglu2015graph} focuses on identifying abnormal nodes in graph-structured data. Traditional approaches like Oddball \cite{akoglu2010oddball} rely on power-law relationships between local graph features, while more recent deep learning-based approaches are more generalizable. For instance, DOMINANT \cite{ding2019deep} employs a graph autoencoder to identify anomalies based on graph reconstruction. ComGA \cite{luo2022comga} introduces a tailored GCN to learn distinguishable node representations by explicitly capturing community structure. Self-supervised techniques have emerged as powerful tools for GAD, with methods like CoLA \cite{liu2021anomaly}, SL-GAD \cite{zheng2021generative}, HCM-A \cite{huang2022hop}, and TAM \cite{qiao2024truncated} introducing various approaches to handle node interactions and structural patterns. While these methods have shown success in single-domain scenarios, they don't address the challenges of cross-domain knowledge transfer. First,
anomalies behave differently across domains-- fraudulent users in e-commerce networks exhibit different patterns compared to social networks. Second, domains often have different feature spaces and graph structures.

% -- social networks have profile-based feature and dense community structures, while e-commerce networks have transaction-based features and sparse connections \cite{shu2017user}.

AdaGraph-T3 bridges both GDA and GAD through a unified approach that combines (1) test-time training with a homophily-based loss for capturing domain-invariant properties of anomalies
(2) enhanced message-passing using normal structure-preserved attention weighting (NSAW) that reduces the irrelevant impact of anomalous nodes on normal nodes' representations, and (3) class-aware regularization that prevents minority class patterns from being overshadowed by majority class during source training. We compare a source-free version of AdaGraph-T3 against GAD baselines (e.g. TAM, ComGA, DOMINANT) to highlight the impact of its GAD-specific features.

\section{Problem Definition}

We address unsupervised node-level anomaly detection with domain adaptation, aiming to identify abnormal nodes in a target graph by leveraging information from both the target and a source graph. The source dataset may contain labeled information but is assumed to be out-of-distribution (OOD) relative to the target, with different feature sets and label distributions. Given source dataset $D_s = (\mathcal{G}_s, X_s, Y_s)$ and target dataset $D_t = (\mathcal{G}_t, X_t)$, where \mbox{$\mathcal{G}_s/\mathcal{G}_t = (\mathcal{V},\mathcal{E})$} represents a (source or target) underlying graph with nodes \mbox{$\mathcal{V}$} and edges \mbox{$\mathcal{E}\subset \mathcal{V} \times \mathcal{V}$} such that \mbox{$uv\in\mathcal{E}$} if there is a link between nodes $u$ and $v$. Here, \mbox{$X_s=\{\mathbf{x}_{v}|\, \forall v \in \mathcal{V}_s\}$} and \mbox{$Y_s= \{y_{v}|\, \forall v \in \mathcal{V}_s\}$} represent the node features and their corresponding labels, respectively, and the same holds for target data $(X_t, Y_t)$. Notably, $y_{v} \in \{0, 1\}$ (normal or anomaly) for nodes in both $\mathcal{V}_s$ and $\mathcal{V}_t$. Our goal is to detect anomalies in the target graph. The key challenge is that target labels are completely unavailable (unsupervised setting), requiring us to leverage source labels $Y_s$ as auxiliary information, even though source and target features may have different dimensionalities ($\mathbf{x}_v \in \mathbb{R}^{p_s}$ for source nodes and $\mathbf{x}_u \in \mathbb{R}^{p_t}$ for target nodes).


\section{Adaptive Graph Anomaly Detection via Test-Time Training (AdaGraph-T3)} 
We propose AdaGraph-T3 (Adaptive Graph Anomaly Detection via Test-Time Training), a domain adaptation method particularly designed for graph anomaly detection that integrates attention-based message-passing, node homophily patterns, and domain-specific encoders to handle feature shifts and heterogeneous features across domains. AdaGraph-T3 addresses the challenging and novel scenario where the target data is out of distribution (OOD) relative to the source data and where source and target datasets have different feature spaces. 

An overview of our approach is provided in Figure \ref{fig:model}. AdaGraph-T3 leverages the advantages of Test-time Training, especially the ability to adapt to new target datasets in the TTT phase without the need for labeled anomalies. Moreover, AdaGraph-T3 incorporates technical innovations tailored for cross-domain GAD, including the use of domain-specific encoders, Normal Structure-preserved Attention Weighting (NSAW), and class-aware regularization.

%AdaGraph-T3 consists of two key components, Normal Structure-preserved Attention Weighting (NSAW) and dataset-specific encoders. NSAW dynamically learns edge importance weights through the attention mechanism.  More specifically, rather than making binary edge removal as in prior work \cite{qiao2024truncated}, NSAW learns continuous attention weights to smoothly adjust neighbor influences during message passing. Dataset-specific encoders are trained end-to-end to handle distribution shifts and heterogeneous features across domains.

Our framework operates in two phases. The training phase combines supervised and self-supervised losses to learn from the source dataset. The test-time training phase only uses self-supervised learning to adapt to the target data. We will detail each stage of our solution together with our key contributions in the next sections.


\begin{figure*}[t]
    \centering
    \includegraphics[width=1\textwidth]{Figures/diagram.pdf}
    \caption{Overview of AdaGraph-T3, our test-time training framework for node-level cross-domain anomaly detection. In the training phase (top), AdaGraph-T3 learns an encoder $\theta_{s}$,  a decoder $\theta_m$, and a prediction $\theta_{pred}$ by jointly minimizing supervised ($\mathcal{L}_{\text{sup}}$) and self-supervised homophily-based loss ($\mathcal{L}_{\text{self}}$). We propose using Normal Structure-preserved Attention Weights to defend against the adversarial influence of anomalous nodes during message passing in the GNN training. In the test-time training (TTT) phase (bottom), AdaGraph-T3 learns a target encoder $\theta_{t}$ using only the self-supervised loss $\mathcal{L}_{\text{self}}$. The decoder $\theta_m$ and prediction $\theta_{pred}$ are shared across phases to enable the cross-domain knowledge transfer while handling heterogeneous feature spaces.
    }
    \label{fig:model}
\end{figure*}


\subsection{Backbone GNN and Projection head}
\label{sec::gnn-proj}

The backbone architecture of AdaGraph-T3 is a Graph Neural Network (GNN) that operates on source and target graph data. Our model can apply any GNN architecture, including Message-passing Neural Networks (MPNNs). We denote the set of neighbors at node $v$ as \mbox{$\mathcal{N}(v)=\{u|(u,v) \in\mathcal{E}\}$}. For each layer $\ell \in \{1, 2, \ldots L\}$ of the GNN the information from neighboring nodes of $v$ is aggregated via message-passing as follows:
\begin{align} \label{eq:h_n_v}
    \mathbf{h}_{\mathcal{N}(v)}^{\ell} = M\left(\left\{\mathbf{h}_{u}^{\ell-1}|u \in \mathcal{N}(v) \right\}\right),
\end{align}
where $M(\cdot)$ is an element-wise and permutation-invariant operator (e.g., average, max, or min). The embedding of node $v$ at the $\ell$-th layer is derived from the aggregated neighbors' embeddings and the previous embedding of $v$:
% \begin{align}\label{eq:h_v}
%     \mathbf{h}_v^{\ell} = \sigma \left(W^{\ell} . \mathbf{h}_{\mathcal{N}(v)}^{\ell} + \mathbf{b}^{\ell}\right),
% \end{align}
\begin{align}\label{eq:h_v}
    \mathbf{h}_v^{\ell} = \sigma \left(W^{\ell} . [\mathbf{h}_{\mathcal{N}(v)}^{\ell} || \mathbf{h}_{v}^{\ell-1} ] + \mathbf{b}^{\ell}\right),
\end{align}
where $\sigma(\cdot)$ is a non-linear activation function, $||$ denotes the concatenation operator, \mbox{$W^{\ell}\in\mathbb{R}^{p_{\ell+1}\times 2p_{\ell}}$}, and \mbox{$\mathbf{b}^{\ell}\in\mathbb{R}^{p_{\ell+1}}$} are trainable weight matrices and bias vectors. 
%(e.g. ReLU) for $\ell\in\{1,\dots,L-1\}$ and $\mathrm{Softmax}(\cdot)$ operator for $\ell=L$,
%and \mbox{$\mathbf{W}^{\ell}\in\mathbb{R}^{p_{\ell+1}\times p_{\ell}}$} and \mbox{$\mathbf{b}^{\ell}\in\mathbb{R}^{p_{\ell+1}}$} are trainable weights and biases filters. 
Representations from the last layer ($\ell=L$) can be converted to binary class probabilities using the $\mathrm{sigmoid}$ function.

To generate initial representations $\mathbf{h}_v^0$ for nodes with different feature sets in $D_s$ and $D_t$, GATD3 learns projection matrices (or encoders) $P_s$ and $P_t$ as follows:
\begin{align}\label{eq:P_s}
\mathbf{h}_{v}^{0}=P_s.\mathbf{x}_{v},
\end{align}
where \mbox{$P_s\in\mathbb{R}^{p\times p_s}$} represents a trainable projection for the source data and $\mathbf{x}_v$ are node features. The same is performed for target data using a projection matrix $P_t$. These encoders enable projecting source and target data into a shared representation space not only for transfer learning but also for interpreting target predictions as we will show in the experiments.

Without loss of generality, we apply GraphSAGE  \cite{hamilton2017inductive} as AdaGraph-T3's backbone MPNN architecture. GraphSAGE applies node sampling in the aggregation phase to increase its scalability.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Homophily-based Self-supervised Loss}
\label{sec::homo-scores}

Test-time training requires a self-supervised loss $\mathcal{L}_{self}$ applied during both training and test-time training stages. We propose the use of a previously introduced homophily-based affinity score, which is tailored for unsupervised anomaly detection \cite{qiao2024truncated,chen2024consistency}. 

The local affinity score measures the similarity or connection strength between a node and its neighbors. It is based on the one-class homophily phenomenon, where normal nodes tend to have a stronger affinity with their neighbors compared with anomalies. This enables these scores to be applied for unsupervised GAD. To the best of our knowledge, our work is the first to apply affinity scores for the GAD problem within the test-time training framework. 

More formally, the local affinity score is computed by comparing a node's representation against those of its immediate neighbors in the graph using various similarity metrics such as cosine similarity, Euclidean distance, Jensen-Shannon divergence, and Wasserstein distance \cite{lin1991divergence,chen2020structure,shen2018wasserstein}. By taking the average similarity with neighbors of a node $v$, we obtain a single anomaly score $s(v)$ based on how well a node is associated with its local graph structure: 

\begin{align}\label{eq:score}
s({v})=\frac{1}{|N(v)|}\sum_{u \in N(v)}\mathrm{sim}(\mathbf{h}_v^L, \mathbf{h}_u^L),
\end{align}
 % f(v) = -s({v})
where $N(v_i)$ denotes the neighbors of node $v_i$,  $\mathbf{h}_u^L$ represents the learned node embedding for $u$, and $\mathrm{sim}(\mathbf{a}, \mathbf{b}) = \frac{\mathbf{a}^T \mathbf{b}}{\lVert\mathbf{a}\rVert \lVert\mathbf{b}\rVert}$ describes the cosine similarity.  The unsupervised task consists of maximizing the affinity score for each node.

This test-time task is scalable, as it only requires local computations, making it efficient even for large graphs. Additionally, it can be adapted to different types of graphs and node features by choosing appropriate node representation learning techniques and similarity measures. The total self-supervised loss combines the homophily-based loss with a regularization term:
\begin{equation}\label{eg:self}
\mathcal{L}_{\text{self}} = s({v}) + \lambda_{\text{reg}} \mathcal{L}_{\text{reg}},
\end{equation}
where $\mathcal{L}_{\text{reg}} = \sum_{i\in\mathcal{V}} \left(\frac{\sum_{j \in \mathcal{N}_i^-} \text{sim}(h_i, h_j)}{|\mathcal{N}_i^-|}\right)$ minimizes the similarity between non-connected nodes to maintain structural distinctiveness in the embedding space, with $\mathcal{N}_i^-$ representing the set of nodes not connected to node $i$ and $\lambda$ controlling the regularization strength.

It has been noted by previous work \cite{qiao2024truncated,chen2024consistency} that enforcing similarity across all connected nodes might inadvertently cause non-homophily nodes to become similar. Normal Structure-preserved Graph Truncation (NSGT) attempts to preserve normal node structure by making binary decisions to remove edges between dissimilar nodes based on distance. However, this approach risks losing important structural information and requires setting explicit thresholds for edge removal decisions. In the next section, we introduce our enhanced message-passing approach through attention-based NSAW, a simpler and more flexible approach to suppress the adversarial effect of non-homophily edges in equation \ref{eg:self}.


\subsection{Normal Structure-preserved Attention Weighting (NSAW)}\label{section:NSAW}

We propose Normal Structure-preserved Attention Weighting (NSAW) as an alternative to Normal Structure-preserved Graph Truncation \cite{qiao2024truncated}. NSAW applies a robust extension to graph attention \cite{velivckovic2017graph} as a more flexible way to suppress the effect of anomalous nodes on the representation of normal nodes during message-passing. These attention weights are learned end-to-end as part of the GNN training process. 

%We introduce an adaptive message-weighting mechanism that can be integrated with the GNN architecture to robustify the node representation learning and suppress the adversarial effect of non-homophilic edges. Unlike existing attention mechanisms for general graph representation learning like GAT, NSAW is specifically designed for anomaly detection by computing attention through symmetric min operation that is naturally designed to suppress anomalous influences. It leverages both node attributes and graph structure to dynamically adjust the influence of nodes on each other during message passing \cite{velivckovic2017graph}. Our approach improves NSGT \cite{qiao2024truncated} by replacing binary edge removal decisions with a learnable attention mechanism that produces continuous edge importance weights. Our approach has several advantages over NSGT: it is more flexible and robust to errors because it can adjust these importance levels during end-to-end training, and maintains structural information that might be lost through edge removal.

%\textbf{Structure-Aware Attention Module.}
For each layer $\ell$, we compute attention weights between connected nodes using a learnable transformation matrix $U^\ell \in \mathbb{R}^{p_\ell \times \tilde{p}}$, where $\tilde{p}$ represents the attention dimension. Given representations $H^\ell \in \mathbb{R}^{N \times p_\ell}$ at layer $\ell$, the attention scores are computed as:
\begin{equation}
    A^\ell = \mathrm{softmax}(\phi(H^\ell U^\ell)(\phi(H^\ell U^\ell))^\top \odot M),
\end{equation}
\noindent where $\phi$ is ReLU activation, $M$ is the adjacency matrix, and $\odot$ is element-wise multiplication. The use of $M$ ensures that attention weights are only computed between connected nodes in the graph.

\textbf{Robust Symmetric Attention.}
To defend against the adversarial influence of anomalous nodes, we enforce symmetry in the attention weights through a symmetric minimum operation:
\begin{equation}
   \widetilde{A}^\ell_{i,j} = \min \{A^\ell_{i,j}, A^\ell_{j,i}\}, \quad \text{for all } i\neq j
\end{equation}
% and $\widetilde{A}^\ell_{i,i} = 1 - \sum_{i\neq j} \widetilde{A}^\ell_{i,j}$.
% We choose the minimum operation rather than alternatives like averaging or geometric mean because it provides stronger defensive properties - a single low attention weight from either direction is sufficient to limit influence. This aligns with the intuition that normal nodes should have mutual high attention with other normal nodes, while connections involving anomalous nodes should be suppressed if either node in the pair identifies the edge as potentially anomalous.

NSAW's symmetric construction provides a crucial defensive mechanism through two complementary aspects. First, when a normal node $v$ connects to both normal nodes $\{v_1, v_2, \ldots, v_k\}$ and anomalous nodes $\{a_1, a_2, \ldots, a_m\}$, the attention naturally assigns high weights to normal neighbors and low weights to anomalous ones due to feature similarity.  As illustrated in the Figure \ref{fig:symmetry}, when a normal node assigns low attention $\alpha(v\rightarrow a) \approx 0$ to an anomalous node (thin arrow), even if the anomalous node attempts to assign high attention back (thick arrow), the minimum operation then ensures that the reverse influence is also minimized as $\alpha(a\rightarrow v) = \min(\alpha(a\rightarrow v), \alpha(v\rightarrow a)) \approx 0$ (shown by the dashed arrow), regardless of the original attention weight. Second, through the learnable attention parameters $U^l$ and the self-supervised loss, the architecture gradually learns to suppress the influence of anomalous patterns during training, further strengthening this defensive mechanism through the GNN's message passing structure.

\begin{figure}[t]
  \centering
  \includegraphics[width=0.5\linewidth]{Figures/homophily.pdf}
  \caption{Illustration of the symmetric attention mechanism. Node $a$ assigns a high attention weight $\alpha_1$ to node $v$, while node $v$ assigns a lower attention weight $\alpha_2$ to node $a$. Using the minimum operation, the final symmetric attention weight becomes $\alpha_2$.}
  \label{fig:symmetry}
\end{figure}

%\textbf{Enhanced Message Passing.}
The computed attention weights modulate the message passing in the GNN architecture. For a node $v$, the attention-weighted messages from its neighbors are aggregated as follows:
\begin{equation}
    \mathbf{h}_v^{\ell}\!=\! M(\{\widetilde{A}^{\ell-1}[u,v] \cdot \mathbf{h}_u^{\ell-1}
    \!\mid\!u\!\in \mathcal{N}(v)\})
\end{equation}
\noindent where $M(\cdot)$ combines the weighted messages using sum aggregation followed by ReLU activation.

\subsection{Class-aware Regularization}
\label{sec::reg}
Class imbalance poses a major challenge in GAD. As shown in Table \ref{table:datasets}, the abnormality rate of all datasets we're using is less than 7\%. 
Our class-aware regularization enhances the model's ability to handle class imbalance during the source training phase by applying stronger regularization to the minority class (i.e., anomalous nodes). When minimizing similarity between non-connected nodes, it assigns higher weights to anomalous nodes, ensuring they maintain their distinctive patterns rather than being overshadowed by the majority class representations. Here's the mathematical formulation:
\begin{equation}
\mathcal{L}_{s} = \sum_{i\in\mathcal{V}} \left(\frac{\sum_{j \in \mathcal{N}_i^-} w_j \cdot \text{sim}(h_i, h_j)}{|\mathcal{N}_i^-|}\right)
\end{equation}
where $\mathcal{N}_i^-$ represents the set of nodes not connected to node $i$, $\text{sim}(h_i, h_j)$ is the cosine similarity between node embeddings, and $w_j$ is the class-based weight defined as:
\begin{equation}
w_j = \begin{cases} 
\alpha & \text{if node } j \text{ is anomalous} \\
1 & \text{otherwise}
\end{cases}
\end{equation}
where $\alpha > 1$ is the weighting factor for anomalous nodes. We set $\alpha$ inversely proportional to the class ratio
This regularization can only be applied during source training where we have access to node labels, while target training relies solely on the homophily-based loss due to its unsupervised nature.

\subsection{Test-Time Training}\label{sec:TTT}

We can now describe our framework for anomaly detection with domain adaptation (AdaGraph-T3), summarized in Figure \ref{fig:model}. Following the test-time training paradigm, AdaGraph-T3 is based on two tasks, the \textit{main (supervised) task} and the \textit{auxiliary self-supervised learning (SSL) task}. In the training phase, AdaGraph-T3 is trained based on both tasks using a joint loss minimized based on the source dataset. Subsequently, the test-time training phase leverages only the SSL task using the target dataset, which is assumed to be unlabeled. 

\textbf{Training phase.} During training phase, AdaGraph-T3 applies the source graph $\mathcal{G}_s$ to learn an encoder $\theta_{s}$, a decoder $\theta_{m}$, and a predictor $\theta_{\text{pred}}$ by minimizing a loss function $\mathcal{L}_{\text{train}}$ that is a combination of a supervised loss $\mathcal{L}_{\text{sup}}$, for which we apply cross-entropy, and a self-supervised loss $\mathcal{L}_{\text{self}}$, for which we apply the homophily-based affinity scores introduced in Section \ref{sec::homo-scores}: 
\begin{align}\label{eq:score}
\mathcal{L}_{\text{sup}} = \sum_{v\in\mathcal{V}_s} y_v\log {\hat{y}_v} + \lambda_s\mathcal{L}_s
\end{align}

\begin{align}\label{eq:score}
\mathcal{L}_{\text{self}} = \frac{1}{|N(v)|}\sum_{u \in N(v)}\mathrm{sim}(\mathbf{h}_v^L, \mathbf{h}_u^L) + \lambda_{\text{reg}}\mathcal{L}_{\text{reg}}
\end{align}

\begin{align}\label{eq:score2}
%\mathcal{L}_{\text{train}}(D_s; \theta_m) = \sum_{v\in\mathcal{V}_s} \Bigl( \mathcal{L}_{\text{sup}}(v, y; \theta_m) + \lambda \mathcal{L}_{\text{self}}(v; \theta_m) \Bigr)
\mathcal{L}_{\text{train}} = \sum_{v\in\mathcal{V}_s} \Bigl( \mathcal{L}_{\text{sup}}(v, y; \theta_m, \theta_{s}, \theta_{\text{pred}}) + \lambda \mathcal{L}_{\text{self}}(v; \theta_m, \theta_{s}) \Bigr)
\end{align}
where $\hat{y}$ is the predicted label (normal or anomaly) and $\lambda$, $\lambda_s$, and $\lambda_{\text{reg}}$ are weight hyperparameters. 

We describe the source encoder $\theta_{s}$ (projection) and decoder $\theta_m$ (GNN) in Section \ref{sec::gnn-proj}. The predictor $\theta_{\text{pred}}$ is a multi-layer perception that maps node embeddings to label predictions.

\textbf{Test-time training phase.} During the test-time training (TTT) phase, we apply the target graph $\mathcal{G}_t$ to optimize a target encoder $\theta_{t}$ by minimizing the TTT loss $\mathcal{L}_{\text{TTT}}$: 
\begin{align}\label{eq:score3}
%\mathcal{L}_{\text{TTT}}(D_t; \theta_{\text{p}_t}) = \sum_{v\in\mathcal{V}_t} \lambda \mathcal{L}_{\text{self}}(v; \theta_{\text{p}_t})
\mathcal{L}_{\text{TTT}} = \sum_{v\in\mathcal{V}_t} \lambda_t \mathcal{L}_{\text{self}}(v; \theta_{t},\theta_m)
\end{align}
where $\mathcal{L}_{\text{self}}$ is defined in Equation \ref{eq:score} and the GNN decoder $\theta_m$ is re-used from the training phase to embed target nodes. 

\textbf{Inference.} After the TTT phase, anomalies are detected in the target dataset by combining the target encoder $\theta_{t}$ learned during the TTT phase with the GNN decoder $\theta_m$ and the predictor $\theta_{\text{pred}}$, both learned during the training phase. Intuitively, the source $\theta_{s}$ and target $\theta_{t}$ encoders project features from the source and target graph, respectively, into a new shared feature space. The GNN $\theta_m$ operates over this shared space to generate node embeddings where anomalies can be distinguished from normal nodes using the predictor $\theta_{\text{pred}}$.

\textbf{Stopping criteria.} We propose an adaptive early-stopping strategy based on Maximum Mean Discrepancy (MMD) ratios between source and target domains. Our method computes MMD between target features and two distinct source feature distributions---normal and anomalous cases. The ratio of maximum to minimum MMD serves as our stopping criterion, where a higher ratio indicates better domain adaptation as it reflects stronger alignment between target samples and their corresponding source class features. The training stops when no improvement in this ratio is observed for a predefined number of epochs. Our ratio-based approach measures relative alignment between target samples and source class distributions, rather than just overall domain similarity. See Appendix \ref{appendix:early-stopping} for more details about our stopping criteria. 


% \textbf{Discussion.} Our approach introduces two innovations to the test-time training framework for graph tasks motivated by the cross-domain graph anomaly detection problem. First, instead of simply adapting the source encoder during the TTT phase, we apply a different encoder for target data to enable source and target datasets with different feature spaces. Moreover, instead of a contrastive loss for self-supervised learning, we propose applying a homophily-based affinity score that is particularly tailored for the graph anomaly detection task.
\begin{table}[t]
% \small
\centering
\caption{Statistics of the datasets.}
\label{table:datasets}
\begin{tabular}{@{}lrrrr@{}}
\toprule
Metric & \# nodes & \# edges & \# features & Abnormal(\%) \\
\midrule
\textit{Amazon (AMZ)} & 10,244 & 175,608 & 25 & 6.66 \\
\textit{Reddit (RDT)} & 10,984 & 168,016 & 64 & 3.33 \\
\textit{Facebook (FB)} & 1,081 & 55,104 & 576 & 2.49 \\
\textit{YelpChi (YC)} & 24,741 & 49,315 & 32 & 4.91 \\
\textit{YelpHotel (HTL)} & 4,322 & 101,800 & 8,000 & 5.78 \\
\textit{YelpRes (RES)} & 5,012 & 355,144 & 8,000 & 4.99 \\
\bottomrule
\end{tabular}
\end{table}

\section{Experiments}

\begin{table*}[t]
\centering
\caption{Cross-domain (Source $\rightarrow$ Target) node-level graph anomaly detection performance of the proposed model (AdaGraph-T3) compared to state-of-the-art baselines. We have shown the results for domain pairs with both homogeneous and heterogeneous feature spaces across domains. Results show that AdaGraph-T3 significantly outperforms baselines in most settings.}
\label{table:domain-adaptation}
\fontsize{8}{10}\selectfont
\setlength{\tabcolsep}{2.2pt}
\renewcommand{\arraystretch}{1}
\begin{tabular}{@{}llc|cccccc|cc|c@{}}
\toprule
& & & \multicolumn{6}{c|}{\textbf{Heterogeneous Features}} & \multicolumn{2}{c|}{\textbf{Homogeneous Features}} & \\
\cmidrule(lr){4-9} \cmidrule(lr){10-11}
\textbf{Metric (\%)} & \textbf{Type} & \textbf{Method} & 
AMZ$\to$RDT & 
AMZ$\to$FB & 
RDT$\to$AMZ & 
RDT$\to$FB & 
FB$\to$AMZ & 
FB$\to$RDT & 
HTL$\to$RES & 
RES$\to$HTL & 
\textbf{Avg.} \\
\midrule
\multirow{8}{*}{\begin{tabular}[c]{@{}l@{}}\textbf{AUROC}\end{tabular}} 
& \multirow{4}{*}{CDA} 
& GRADE & 61.80 & 84.96 & 70.38 & 85.53 & 72.06 & 61.27 & 75.51 & 73.80 & 73.16 \\
& & AdaGCN & 58.86 & 72.35 & 70.43 & 75.89 & 64.86 & 61.62 & 79.50 & 81.18 & 70.59 \\
& & UDA-GCN & 60.37 & 80.80 & 67.36 & 84.98 & 67.55 & \textbf{61.95} & 85.36 & 78.24 & 73.33 \\
& & ACT & 59.24 & 81.97 & 71.16 & 75.74 & 71.98 & 60.52 & 89.20 & 80.40 & 73.78 \\
\cmidrule{2-12}
& \multirow{3}{*}{TTT} 
& TENT & 59.01 & 76.15 & 71.51 & 83.43 & 66.88 & 58.20 & 75.11 & 79.27 & 71.20 \\
& & GraphCL & 60.37 & 88.46 & 68.71 & 88.81 & 61.91 & 61.64 & 79.05 & 74.20 & 72.89 \\
& & GTrans & 60.64 & 89.35 & 73.93 & 90.18 & 68.03 & 61.90 & 79.86 & 83.49 & 75.92 \\
\cmidrule{2-12}
& Ours & AdaGraph-T3 & \textbf{62.55} & \textbf{91.04} & \textbf{80.56} & \textbf{94.84} & \textbf{86.11} & 60.96 & \textbf{93.73} & \textbf{90.49} & \textbf{82.53} \\
\midrule
\multirow{8}{*}{\begin{tabular}[c]{@{}l@{}}\textbf{AUPRC}\end{tabular}} 
& \multirow{4}{*}{CDA} 
& GRADE & 4.92 & 18.44 & 11.87 & 16.10 & 13.00 & 4.34 & 18.81 & 22.53 & 13.75 \\
& & AdaGCN & 4.51 & 9.04 & 12.15 & 5.72 & 10.23 & 4.64 & 22.15 & 35.15 & 12.95 \\
& & UDA-GCN & 4.65 & 6.73 & 10.85 & 22.04 & 10.89 & \textbf{5.55} & 26.02 & 27.31 & 14.26 \\
& & ACT & 4.22 & 8.16 & 13.20 & 26.52 & 12.26 & 4.88 & 33.00 & 28.70 & 16.37 \\
\cmidrule{2-12}
& \multirow{3}{*}{TTT} 
& TENT & 4.60 & 11.69 & 12.49 & 18.81 & 12.32 & 4.79 & 13.12 & 28.31 & 13.27 \\
& & GraphCL & 4.69 & 21.09 & 14.36 & 30.86 & 11.12 & 5.44 & 21.27 & 25.55 & 16.80 \\
& & GTrans & 4.78 & 25.95 & 17.02 & 29.11 & 11.91 & 5.15 & 21.03 & 36.20 & 18.89 \\
\cmidrule{2-12}
& Ours & AdaGraph-T3 & \textbf{6.02} & \textbf{31.71} & \textbf{19.02} & \textbf{34.76} & \textbf{29.19} & 4.97 & \textbf{45.65} & \textbf{43.49} & \textbf{26.85} \\
\bottomrule
\end{tabular}
\vspace{2mm}
\scriptsize

%\textbf{Notes:} Bold numbers indicate the best performance for each metric and domain pair. CDA: Cross-Domain Adaptation methods; TTT: Test-Time Training methods.
\end{table*}

We will compare the proposed approach (AdaGraph-T3) against multiple baselines using six graph datasets.

\textbf{Code availability:} Our source code is available for reproducibility purposes as an anonymous repository.\footnote{\url{https://github.com/delaramphf/GADT3-Algorithm}}

\subsection{Experimental Setup}
\textbf{Datasets.} We apply six datasets from diverse domains such as online shopping reviews, including Amazon (AMZ) \cite{mcauley2013amateurs}, YelpChi  \cite{rayana2015collective}, YelpHotel (HTL), and YelpRes (RES) \cite{ding2021cross}, and social networks, including Reddit (RDT) \cite{kumar2018community} and Facebook (FB)\cite{leskovec2012learning}. For our cross-domain analysis, we examine scenarios where feature spaces are homogeneous (same features) and heterogeneous (same features) across domains. Table \ref{table:datasets} presents a summary of the dataset statistics. A detailed description of each dataset is provided in Appendix \ref{appendix: data}. 


\textbf{Baselines and Evaluation Criteria.}
We evaluate our method against state-of-the-art baselines both for cross-domain domain adaptation and (single-graph) unsupervised anomaly detection. Cross-domain baselines include GRADE \cite{wu2023non}, AdaGCN \cite{dai2022graph}, UDA-GCN \cite{wu2020unsupervised}, and ACT \cite{wang2023cross}. Test-time training baselines include TENT \cite{wang2020tent}, GraphCL \cite{you2020graph}, and GTrans \cite{jin2022empowering}. As GAD baselines, we consider self-supervised learning-based methods CoLA \cite{liu2021anomaly}, SL-GAD \cite{zheng2021generative}, and HCM-A \cite{huang2022hop},  reconstruction-based methods DOMINANT \cite{ding2019deep} and ComGA \cite{luo2022comga}, and a local affinity-based method TAM \cite{qiao2024truncated}. 

We utilize two evaluation metrics to assess the performance of anomaly detection models: the Area Under the Receiver Operating Characteristic Curve (AUROC) and the Area Under the Precision-Recall Curve (AUPRC). Higher values of AUROC and AUPRC indicate superior model performance. For all experiments, we report average results for 10 repetitions. 
% These metrics are widely recognized for their effectiveness in evaluating classification models, particularly in the context of imbalanced datasets. 


\textbf{Implementation details.} We developed AdaGraph-T3 using Python 3.11.9 and PyTorch 2.1.0. All the experiments were conducted on an NVIDIA A40 GPU with 48GB. The core model is a 2-layer GraphSAGE GNN with weight parameters optimized via the Adam optimizer \cite{kingma2014adam} with a dropout rate of 0.7. The source model underwent training for 100 epochs with early stopping employed to determine the target epochs. Both the source and target models were trained with a learning rate of 0.001. We trained all baseline models using their provided source code and the hyperparameters recommended in their respective papers.

\subsection{Cross-domain Graph Anomaly Detection}

We present the results comparing our approach against various domain adaptation baselines in Table \ref{table:domain-adaptation}. We use different datasets as source and target domains. We incorporated a projection head into all baseline models to address feature sets' mismatches across source and target domain datasets. This addition enables fair comparison by allowing each method to handle the discrepancy in feature spaces.

Our proposed method (AdaGraph-T3) outperformed the baselines in most scenarios. AdaGraph-T3 achieved the highest AUROC and AUPRC scores in 5 out of 6 tasks. For instance, in terms of AUROC, in the Reddit$\to$Amazon task, AdaGraph-T3 surpassed the next best method (GTrans) by 6.6\%. In the Reddit$\to$Facebook task, AdaGraph-T3 outperformed the closest competitor (GTrans) by 4.7\%. The only task where AdaGraph-T3 did not lead in terms of AUROC and AUPRC was Facebook$\to$Reddit, where it performed competitively but slightly below UDA-GCN. On average, our method outperformed the second-best baseline by 5.3\% in both AUROC and AUPRC. 

In Appendix \ref{sec::perf-homo}, we provide further insights into the performance of AdaGraph-T3. We have found that high target performance is often correlated with high source homophily. This can be explained by our use of a homophily-based self-supervised loss for test-time training.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.6\textwidth]{Figures/combined_figures.pdf}
    \caption{Kernel PCA embeddings of node representations for (left) source domain (Amazon) and (right) target domain (Reddit). The shared representation enables the transfer of decision boundaries from the source to the target domain.}
   \label{fig:vis}
\end{figure}

\vspace{-1em}

\subsection{Representation Embedding}

The effectiveness of our test-time training approach is visually demonstrated in Figure \ref{fig:vis}, which presents the two-dimensional Kernel PCA (polynomial kernel) embeddings of the GNN outputs for both source and target models. Importantly, we have used the same embedding space derived from the source data to project the target data, enabling the mapping of model predictions across domains.

On the left side, we observe a clear separation between normal and anomalous samples in the source domain (Amazon), indicating that the source model has effectively learned to distinguish between these classes. The right figure shows the transferability of our approach to the target domain (Reddit). Despite the inherent differences between source and target datasets, the decision boundary learned from the source domain maintains its discriminative power when applied to the target, demonstrating that our test-time training strategy successfully adapts the pre-trained source model to the new domain.

We provide additional visualizations of source and target embeddings for other datasets in Appendix \ref{sec::add-emb}.

\subsection{Early Stopping}
This section evaluates our MMD ratio-based early-stopping strategy across different domain adaptation scenarios. Figure \ref{fig:early-stopping} illustrates how the MMD ratio evolves together with the Area Under the Precision-Recall Curve (AUPRC) during training. We marked the specific epoch when the model was selected. The results show that the ratio effectively captures the convergence of domain adaptation without the need for labeled validation data. %After the training stopped, we selected the model from the epoch that achieved the highest MMD ratio score as our final model. This model selection strategy ensures we capture the point of optimal domain alignment, rather than potentially overfitted later stages of training.

% This captures whether samples align with their correct class patterns, which is particularly crucial for security applications where proper attack pattern transfer is more important than raw distribution matching.
% See Appendix \ref{appendix:early-stopping} for detailed methodology.


\begin{table}[t]
\footnotesize
\centering
\renewcommand{\arraystretch}{1.1}  % Slightly increased row spacing
\setlength{\tabcolsep}{5pt}       % Slightly wider column spacing
\caption{Ablation study on GAD performance. Source-free AdaGraph-T3 and all baseline methods were trained and evaluated on the target dataset only (no source domain data). AdaGraph-T3 outperforms specialized GAD baselines on most datasets.}
\label{table:anomaly-detection}
\begin{tabular}{l c c c c c | c}
\toprule
\multirow{2}{*}[-2pt]{\makecell[l]{\textbf{Metric (\%)}}} & 
\multirow{2}{*}[-2pt]{\textbf{Method}} & 
\multirow{2}{*}[-2pt]{\textbf{AMZ}} & 
\multirow{2}{*}[-2pt]{\textbf{RDT}} & 
\multirow{2}{*}[-2pt]{\textbf{FB}} & 
\multirow{2}{*}[-2pt]{\textbf{YC}} & 
\multirow{2}{*}[-2pt]{\textbf{Avg.}} \\ 
\\[-8pt] % Reduced empty space after header
\midrule
\multirow{7}{*}{\textbf{AUROC}} 
& CoLA & 58.98 & 60.28 & 84.34 & 46.36 & 62.49 \\
& SL-GAD & 59.37 & 56.77 & 79.36 & 33.12 & 57.16 \\
& HCM-A & 39.56 & 45.93 & 73.87 & 45.93 & 51.32 \\ 
& DOMINANT & 59.96 & 55.55 & 56.77 & 41.33 & 53.40 \\
& ComGA & 58.95 & 54.53 & 60.55 & 43.91 & 54.48 \\
& TAM & 70.64 & 60.23 & 91.44 & \textbf{56.43} & 69.69 \\ 
\cmidrule{2-7}
& \textbf{AdaGraph-T3} & \textbf{84.76} & \textbf{61.54} & \textbf{91.74} & 48.67 & \textbf{71.68} \\ 
\midrule
\multirow{7}{*}{\textbf{AUPRC}}
& CoLA & 6.77 & 4.49 & 21.06 & 4.48 & 9.20 \\
& SL-GAD & 6.34 & 4.06 & 13.16 & 3.50 & 6.76 \\
& HCM-A & 5.27 & 2.87 & 7.13 & 2.87 & 4.54 \\
& DOMINANT & 14.24 & 3.56 & 3.14 & 3.95 & 6.22 \\
& ComGA & 11.53 & 3.74 & 3.54 & 4.23 & 5.76 \\
& TAM & 26.34 & 4.46 & 22.33 & \textbf{7.78} & 15.23 \\
\cmidrule{2-7}
& \textbf{AdaGraph-T3} & \textbf{27.53} & \textbf{6.01} & \textbf{26.13} & 6.14 & \textbf{16.45} \\
\bottomrule
\end{tabular}
\end{table}
\section{Ablation Studies}

We perform four ablation studies to evaluate different aspects of AdaGraph-T3. The results support the design of our model and demonstrate the relevance of each of its components.

\noindent
\textbf{GAD Results (Source-free)}.
We evaluate a single-domain version of AdaGraph-T3 against six state-of-the-art GAD baselines using four datasets. Our goal is to isolate the impact of GATD3's self-supervised learning from its cross-domain adaptation. The results are shown in Table \ref{table:anomaly-detection}. We follow the same protocol and use the same datasets as \cite{qiao2024truncated}, so we report their results for the baselines. AdaGraph-T3 outperforms the GAD baselines across most of the datasets. %AdaGraph-T3 detects anomalies by leveraging the node homophily patterns. It weighs the connections based on node similarity scores and weakens connections between dissimilar nodes, making it effective at finding anomalies even within a single domain. 
% It's worth noting that single domain AdaGraph-T3 required a 20\% validation set for early stopping, whereas the original domain adaptation version of AdaGraph-T3 includes a mechanism for early stopping without needing validation data. Even with this additional data requirement and operating in a single-domain setting, 


\begin{table*}[t]
\centering
\caption{Ablation study comparing the domain adaptation performance when the source model is trained with the supervised loss only (AdaGraph-T3-sup-source) vs. with a combination of the supervised and self-supervised loss (AdaGraph-T3). The results show that the combined loss leads to significant gains compared with the supervised loss alone.}
\label{table:supervised-only}
\fontsize{8}{10}\selectfont
\setlength{\tabcolsep}{1.4pt}
\renewcommand{\arraystretch}{1.3}
\begin{tabular}{@{}lc|cccccc|cc|c@{}}
\toprule
& & \multicolumn{6}{c|}{\textbf{Heterogeneous Features}} & \multicolumn{2}{c|}{\textbf{Homogeneous Features}} & \\
\cmidrule(lr){3-8} \cmidrule(lr){9-10}
\textbf{Metric (\%)} & \textbf{Method} & 
AMZ$\to$RDT & 
AMZ$\to$FB & 
RDT$\to$AMZ & 
RDT$\to$FB & 
FB$\to$AMZ & 
FB$\to$RDT & 
HTL$\to$RES & 
RES$\to$HTL & 
\textbf{Avg.} \\
\midrule
\multirow{3}{*}{\begin{tabular}[c]{@{}l@{}}\textbf{AUROC}\end{tabular}} 
& GTrans & 60.64 & 89.35 & 73.93 & 90.18 & 68.03 & \textbf{61.90} & 79.86 & 83.49 & 75.92 \\ 
& AdaGraph-T3-sup-source & 60.92 & 90.27 & 75.60 & 92.98 & 70.52 & 59.20 & 92.02 & 84.06 & 78.20 \\ 
\cmidrule{2-11} 
& AdaGraph-T3 (Ours) & \textbf{62.55} & \textbf{91.04} & \textbf{80.56} & \textbf{94.84} & \textbf{81.48} & 60.96 & \textbf{93.73} & \textbf{90.49} & \textbf{81.96} \\ 
\midrule
\multirow{3}{*}{\begin{tabular}[c]{@{}l@{}}\textbf{AUPRC}\end{tabular}} 
& GTrans & 4.78 & 25.95 & 17.02 & 29.11 & 11.91 & 5.15 & 21.03 & 36.20 & 18.89 \\  
& AdaGraph-T3-sup-source & 4.63 & 22.45 & 18.42 & 34.38 & 13.63 & \textbf{5.20} & 44.17 & 34.81 & 22.21 \\ 
\cmidrule{2-11} 
& AdaGraph-T3 (Ours) & \textbf{6.02} & \textbf{31.71} & \textbf{19.02} & \textbf{34.76} & \textbf{23.50} & 4.97 & \textbf{45.65} & \textbf{43.49} & \textbf{26.14} \\ 
\bottomrule
\end{tabular}

\end{table*}

\noindent
\textbf{NSAW as a learnable and flexible edge weighting approach.}
We proposed NSAW as a learnable edge-weighting mechanism to suppress the adverse effect of non-homophily edges in anomaly detection. %While previous work, NSGT (Normal Structure-preserved Graph Truncation) \cite{qiao2024truncated}, relied on binary edge removal. 
Table \ref{table:anomaly-detection} compares our method against TAM \cite{qiao2024truncated} (using Normal Structure-preserved Graph Truncation). The results show that AdaGraph-T3 outperforms TAM using most datasets. This is evidence that NSAW is a more flexible alternative to NSGT by allowing GATD3 to learn continuous attention weights.%While TAM directly removes edges based on calculated node distances to preserve homophily structure through NSGT, our NSAW approach provides a more flexible and learnable alternative by dynamically weighting the importance of edges through the attention mechanism. Rather than making binary decisions about edge removal, NSAW allows the model to learn continuous attention weights that can smoothly adjust the influence of different neighbors during message passing. This soft weighting scheme has two key advantages over NSGT: (1) it preserves the original graph structure while still being able to effectively suppress the influence of anomalous patterns, making it more robust to potential errors in structure modification, and (2) it adapts automatically through end-to-end training without requiring explicit threshold parameters for edge removal. Additionally, NSAW's symmetric attention construction provides similar protective benefits to NSGT's edge truncation by ensuring that if either node in a connection identifies it as potentially anomalous, the influence will be minimized in both directions. 


\noindent
\textbf{Class-aware regularization.} In Table \ref{tab:reg}, we compare the performance of AdaGraph-T3 with and without the class-aware source regularization approach described in \ref{sec::reg}. The results show that the regularization helps increase the sensitivity of the source model to anomalous nodes. Regularization improves the accuracy of the model in most settings. In particular, the results show that regularization improves the performance in terms of AUPRC, which is better at capturing class imbalance than AUROC.


% \begin{table}[t]
% \centering
% \caption{Ablation study of AdaGraph-T3 with and without class-aware regularization. Results show AUROC (\%) and AUPRC (\%) metrics across different source$\rightarrow$target domain pairs. Bold indicates better performance.}
% \label{tab:reg}
% \begin{tabular}{@{}lccc@{}}
% \toprule
% Datasets & Metric & w/ & w/o \\
% \midrule
% \multirow{2}{*}{\makecell{AMZ$\rightarrow$RDT}} 
% & AUROC (\%) & \textbf{62.55} & 62.35 \\
% & AUPRC (\%) & \textbf{6.02} & 5.52 \\
% \midrule
% \multirow{2}{*}{\makecell{AMZ$\rightarrow$FB}}
% & AUROC (\%) & \textbf{91.04} & 90.83 \\
% & AUPRC (\%) & \textbf{31.71} & 29.63 \\
% \midrule
% \multirow{2}{*}{\makecell{RDT$\rightarrow$AMZ}}
% & AUROC (\%) & 80.56 & \textbf{82.33} \\
% & AUPRC (\%) & \textbf{19.02} & 18.20 \\
% \midrule
% \multirow{2}{*}{\makecell{RDT$\rightarrow$FB}}
% & AUROC (\%) & \textbf{94.84} & 90.27 \\
% & AUPRC (\%) & \textbf{34.76} & 32.50 \\
% \midrule
% \multirow{2}{*}{\makecell{FB$\rightarrow$AMZ}}
% & AUROC (\%) & \textbf{86.11} & 82.97 \\
% & AUPRC (\%) & \textbf{29.19} & 24.85 \\
% \midrule
% \multirow{2}{*}{\makecell{FB$\rightarrow$RDT}}
% & AUROC (\%) & 60.96 & \textbf{61.27} \\
% & AUPRC (\%) & \textbf{4.97} & 4.24 \\
% \bottomrule
% \end{tabular}
% \end{table}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.65\textwidth]{Figures/early-stopping.pdf}
    \caption{Relationship between target anomaly detection accuracy (AUPRC) and our MMD-based adaptation score for Reddit$\to$Amazon and Amazon$\to$Facebook. We use the adaptation score as an early stopping criterion, which is triggered at epochs 42 (top) and 27 (bottom). These results demonstrate how our model can be deployed without the need for labeled anomalies in the test domain.}
    \label{fig:early-stopping}
\end{figure}

\begin{table}[t]
\setlength{\tabcolsep}{11pt} 
\small
\centering
\caption{Ablation study of AdaGraph-T3 with and without class-aware regularization. Results show AUROC (\%) and AUPRC (\%) metrics across different source$\rightarrow$target domain pairs. Bold indicates better performance.}
\label{tab:reg}
\begin{tabular}{@{}l|cc|cc@{}}
\toprule
\multirow{2}{*}{Datasets} & \multicolumn{2}{c|}{AUROC (\%)} & \multicolumn{2}{c}{AUPRC (\%)} \\
& w/ & w/o & w/ & w/o \\
\midrule 
\vspace{0.1em} AMZ$\rightarrow$RDT & \textbf{62.55} & 62.35 & \textbf{6.02} & 5.52 \\
\vspace{0.1em} AMZ$\rightarrow$FB & \textbf{91.04} & 90.83 & \textbf{31.71} & 29.63 \\
\vspace{0.1em} RDT$\rightarrow$AMZ & 80.56 & \textbf{82.33} & \textbf{19.02} & 18.20 \\
\vspace{0.1em} RDT$\rightarrow$FB & \textbf{94.84} & 90.27 & \textbf{34.76} & 32.50 \\
\vspace{0.1em} FB$\rightarrow$AMZ & \textbf{86.11} & 82.97 & \textbf{29.19} & 24.85 \\
\vspace{0.1em} FB$\rightarrow$RDT & 60.96 & \textbf{61.27} & \textbf{4.97} & 4.24 \\
\bottomrule
\end{tabular}
\vspace{-0.5em}
\end{table}

\noindent
\textbf{Self-supervised learning during the training phase}.
To highlight the effectiveness of self-supervision in source training, we compared two scenarios in Table \ref{table:supervised-only}: one where the source model was trained using only the supervised loss (AdaGraph-T3-sup-source) and another where it used both supervised and self-supervised losses (AdaGraph-T3). We then evaluated how these different source model training approaches affected the performance of the target model. The results demonstrate that using self-supervision during the training phase is often beneficial. Self-supervision leads to a higher average performance and greater improvement compared to the best baseline (GTrans).

\section{Conclusion}

In this paper, we have introduced AdaGraph-T3, a novel test-time training framework for graph anomaly detection when the testing data is out-of-distribution and from heterogeneous application domains. Specifically, our approach addresses scenarios where the distributions and feature spaces differ between the source and target datasets using dataset-specific encoders. AdaGraph-T3 combines the advantages of test-time training with multiple innovations focused on graph anomaly detection. For instance, by leveraging the distinctive distribution pattern of node homophily between normal and anomalous nodes, we have presented a tailored SSL task along with a robust attention-based edge-weighting mechanism (NSAW) to enhance the generalization of the learned representations. Moreover, AdaGraph-T3 performs model election using an MMD-based early-stopping criterion. Our experiments have illustrated that AdaGraph-T3 outperforms state-of-the-art graph domain adaptation baselines.

Our work opens several avenues for future investigation. We are interested in applying AdaGraph-T3 to cybersecurity applications, where label scarcity and distribution shifts are a challenge. Moreover, we want to understand how explainers trained in the source domain can improve the interpretability of target anomalies. Finally, we will study theoretical guarantees for cross-domain GAD based on the similarity between source and target datasets. 

% achieving average performance improvements of over 7\% in AUROC and 16\% in AUPRC compared to the next best-competing model.

\clearpage
% \section{Acknowledgments}

\bigskip

\bibliographystyle{plain}
\bibliography{references}
\newpage
\onecolumn
\appendix
% \section{Cross-Domain Graph Anomaly Detection via Test-time Training: Supplementary Material}

\section{Early stopping criterion} \label{appendix:early-stopping}

We propose an adaptive early-stopping strategy that monitors distribution shifts between source and target domains using Maximum Mean Discrepancy (MMD). Let $f_t \in \mathbb{R}^{n_t \times p}$ denote the target embedding, $f_s^n \in \mathbb{R}^{n_n \times p}$ and $f_s^a \in \mathbb{R}^{n_a \times p}$ denote the normal and attack source embeddings respectively, where $n_t$, $n_n$, $n_a$ are the number of samples and $p$ is the common feature dimension. The MMD ratio score at epoch $t$ is computed as:

\begin{equation}
\begin{split}
    \text{MMD}_n(t) &= \text{MMD}(f_t, f_s^n) \\
\end{split}
\end{equation}

\begin{equation}
    \text{MMD}_a(t) = \text{MMD}(f_t, f_s^a)
\end{equation}

\begin{equation}
    \text{score}(t) = \frac{1}{|\mathcal{V}|}\sum_{i \in \mathcal{V}} \frac{\max(\text{MMD}_{n}^i, \text{MMD}_{a}^i)}{\min(\text{MMD}_{n}^i, \text{MMD}_{a}^i)}
\end{equation}

% where $k(x,y) = \exp(-\frac{\|x-y\|^2}{2\sigma^2})$ is the RBF kernel with bandwidth $\sigma$. 

For target attack samples, $\text{MMD}_n(t)$ would be larger than $\text{MMD}_a(t)$, making the score $\text{MMD}_n(t)/\text{MMD}_a(t)$, which increases as samples align better with attack source features. Conversely, for target normal samples, the score becomes $\text{MMD}_a(t)/\text{MMD}_n(t)$, increasing as samples align with normal source features. The training stops at epoch $T$ if:

\begin{equation}
    \text{score}(t) \leq \text{score}^*(t-r) \quad \forall t \in [T-r+1, T]
\end{equation}
where $\text{score}^*(t)$ is the best score up to epoch $t$ and $r$ is the patience parameter. A higher score indicates better domain adaptation as it represents a stronger alignment with the correct source class features.


\section{Data description}\label{appendix: data}
\textbf{Amazon}
\cite{mcauley2013amateurs}: The Amazon dataset consists of product reviews from the Musical Instruments category. Users with more than 80\% helpful votes are labeled as benign entities, while those with less than 20\% helpful votes are considered fraudulent entities. For each user (represented as a node in the graph), 25 handcrafted features are used as raw node features. The graph structure is defined by the U-P-U (User-Product-User) relation, which connects users who have reviewed at least one common product.

\noindent
\textbf{Reddit} \cite{kumar2018community}: The Reddit dataset consists of forum posts from the Reddit platform, focusing on user behavior and content. In this dataset, users who have been banned from the platform are labeled as anomalies. Each post's textual content has been vectorized to serve as one of the 64 attributes for the corresponding user or post.

\noindent
\textbf{Facebook} \cite{leskovec2012learning}: The Facebook dataset represents a social network structure derived from the Facebook platform. Users establish connections with other users, forming a network of relationships. Fraudulent users are assumed to be anomalies of the network. Each node represents one user with 576 node attributes.

\noindent
\textbf{YelpChi} \cite{rayana2015collective}: The Yelp spam review dataset comprises hotel and restaurant reviews, categorized as either filtered (spam) or recommended (legitimate) by Yelp. We utilize 32 handcrafted features as raw node features for each review in the Yelp dataset. In the graph the reviews serve as nodes. The graph's structure is defined by the R-U-R (Review-User-Review) relation, which connects reviews posted by the same user.

\noindent
\textbf{YelpHotel} \cite{ding2021cross}: A graph dataset focused on hotel reviews from Yelp, where users and hotels are nodes connected by review edges. Each review contains ratings, text, and detailed metadata about both hotels and reviewers.

\noindent
\textbf{YelpRes} \cite{ding2021cross}: A graph dataset containing restaurant reviews from Yelp, where users and restaurants are nodes connected by review edges. Each review has ratings, text, and metadata about both users and restaurants

\section{Cross-domain performance}

Tables \ref{tab:cross-domain-ROC} and \ref{tab:cross-domain-AP} present the cross-domain and in-domain adaptation performance of AdaGraph-T3. The results are shown using AUROC (\%) and AUPRC (\%) metrics, respectively. We evaluated every possible combination of four real-world datasets (Amazon, Facebook, YelpChi, and Reddit) as source and target domains.

\begin{table}[htbp]
%\begin{minipage}{.5\linewidth}
  \centering
  \begin{tabular}{lcccc}
  \toprule
  \textbf{Source} & \multicolumn{4}{c}{\textbf{Target}} \\
  \cmidrule(lr){2-5}
   & Amazon & Facebook & YelpChi & Reddit \\
  \midrule
  Amazon & 77.19 & 91.04 & 65.54 & 62.55 \\
  Facebook & 86.11 & 95.11 & 72.30 & 60.96 \\
  YelpChi & 74.02 & 93.07 & 73.30 & 61.29 \\
  Reddit & 80.56 & 94.84 & 70.59 & 64.78 \\
  \bottomrule
  \end{tabular}
  \caption{Cross-domain anomaly detection performance of \textbf{AdaGraph-T3} (AUROC \%)}
  \label{tab:cross-domain-ROC}
%\end{minipage}%
\end{table}
\begin{table}[htbp]
%\hspace{0.5in}
%\begin{minipage}{.5\linewidth}
  \centering
  \begin{tabular}{lcccc}
  \toprule
  \textbf{Source} & \multicolumn{4}{c}{\textbf{Target}} \\
  \cmidrule(lr){2-5}
   & Amazon & Facebook & YelpChi & Reddit \\
  \midrule
  Amazon & 15.19 & 31.71 & 8.83 & 6.02 \\
  Facebook & 29.19 & 29.38 & 16.67 & 4.97 \\
  YelpChi & 15.87 & 33.89 & 17.38 & 5.31 \\
  Reddit & 19.02 & 34.76 & 13.36 & 6.97 \\
  \bottomrule
  \end{tabular}
  \caption{Cross-domain anomaly detection performance of \textbf{AdaGraph-T3} (AUPRC \%)}
  \label{tab:cross-domain-AP}
%\end{minipage}
\end{table}

% \section{Representation embedding}
% Figure \ref{fig:vis_s} illustrates the PCA embedding of learned representations on Amazon$\to$Reddit transfer, our lowest-performing case as shown in Table \ref{table:domain-adaptation}. Subfigure \ref{fig:pca_s1} shows the embedding of Amazon data (Source), while subfigure \ref{fig:pca_s2} shows the embedding of Reddit data (Target).

% \begin{figure}[H]
%    \centering
%    \subfloat[Source (Amazon)]{\includegraphics[width=0.25\linewidth]{Figures/figure1_s.pdf}\label{fig:pca_s1}}
%    \hspace{0.3in}
%    \subfloat[Target (Reddit)]{\includegraphics[width=0.25\linewidth]{Figures/figure2_t.pdf}\label{fig:pca_s2}}
%    \caption{PCA embedding of node representations. (a) shows the embeddings for the source domain (Amazon). (b) shows the embeddings learned on the target domain (Reddit). Normal and anomalous samples are shown in different colors. The shared representation enables using the boundaries learned using the source data to label the target.}
%    \label{fig:vis_s}
% \end{figure}


% \section{Effect of self-supervised learning during the training phase}

% To highlight the effectiveness of self-supervision in source training, we compared two scenarios in Table \ref{table:supervised-only}: one where the source model was trained using only the supervised loss, and another where it used both supervised and self-supervised losses. We then evaluated how these different source model training approaches affected the performance of the target model. The results demonstrate that using self-supervision during the training phase is crucial. Self-supervision leads to a higher average performance and greater improvement compared to the best competing model.

% \begin{table*}[t]
% \centering
% \caption{Ablation study comparing the domain adaptation performance when the source model training with supervised loss only vs. with a combination of the supervised and self-supervised loss. The results show that the combined loss leads to significant gains compared with the supervised loss alone.}
% \label{table:supervised-only}
% \fontsize{8}{10}\selectfont
% \setlength{\tabcolsep}{3.5pt}
% \renewcommand{\arraystretch}{1.1}
% \begin{tabular}{@{}lc|cccccc|cc|c@{}}
% \toprule
% & & \multicolumn{6}{c|}{\textbf{Heterogeneous Features}} & \multicolumn{2}{c|}{\textbf{Homogeneous Features}} & \\
% \cmidrule(lr){3-8} \cmidrule(lr){9-10}
% \textbf{Metric} & \textbf{Method} & 
% AMZ$\to$RDT & 
% AMZ$\to$FB & 
% RDT$\to$AMZ & 
% RDT$\to$FB & 
% FB$\to$AMZ & 
% FB$\to$RDT & 
% HTL$\to$RES & 
% RES$\to$HTL & 
% \textbf{Avg.} \\
% \midrule
% \multirow{3}{*}{\begin{tabular}[c]{@{}l@{}}\textbf{AUROC}\\\textbf{(\%)}\end{tabular}} 
% & GTrans & 60.64 & 89.35 & 73.93 & 90.18 & 68.03 & \textbf{61.90} & 79.86 & 83.49 & 75.92 \\ 
% & AdaGraph-T3-sup-source & 60.92 & 90.27 & 75.60 & 92.98 & 70.52 & 59.20 & 92.02 & 84.06 & 78.20 \\ 
% \cmidrule{2-11} 
% & AdaGraph-T3 (Ours) & \textbf{62.55} & \textbf{91.04} & \textbf{80.56} & \textbf{94.84} & \textbf{81.48} & 60.96 & \textbf{93.73} & \textbf{90.49} & \textbf{81.96} \\ 
% \midrule
% \multirow{3}{*}{\begin{tabular}[c]{@{}l@{}}\textbf{AUPRC}\\\textbf{(\%)}\end{tabular}} 
% & GTrans & 4.78 & 25.95 & 17.02 & 29.11 & 11.91 & 5.15 & 21.03 & 36.20 & 18.89 \\  
% & AdaGraph-T3-sup-source & 4.63 & 22.45 & 18.42 & 34.38 & 13.63 & \textbf{5.20} & 44.17 & 34.81 & 22.21 \\ 
% \cmidrule{2-11} 
% & AdaGraph-T3 (Ours) & \textbf{6.02} & \textbf{31.71} & \textbf{19.02} & \textbf{34.76} & \textbf{23.50} & 4.97 & \textbf{45.65} & \textbf{43.49} & \textbf{26.14} \\ 
% \bottomrule
% \end{tabular}

% \vspace{2mm}
% \scriptsize
% \textbf{Notes:} Bold numbers indicate the best performance for each metric and domain pair.
% \end{table*}
\section{Transfer performance with respect to source-target homophily}
\label{sec::perf-homo}

Our analysis reveals that the direction of transfer plays a crucial role in cross-domain anomaly detection performance. Transferring from a higher homophily domain to a lower homophily domain generally results in better performance improvements. This suggests that when the source domain has higher homophily, the homophily-based test-time training loss function is more effective at guiding the model's adaptation to the target domain. For example, transferring from Reddit (higher homophily) to Facebook (lower homophily) achieves significantly better performance than the reverse direction. This finding provides practical guidance, indicating that domains with stronger homophilic structures may serve as better source domains for transfer learning in cross-domain anomaly detection tasks (see Figure \ref{fig:homophily-comparison}).

\begin{figure}[t]
   \centering
   \includegraphics[width=0.9\linewidth]{Figures/homophily_comparison_plot.pdf}
   \caption{Domains with higher homophily (h) generally serve as better source domains when transferring to domains with lower homophily.}
   \label{fig:homophily-comparison}
\end{figure}

\section{Additional embedding visualizations}
\label{sec::add-emb}
In Figure \ref{fig:embed}, we show 2D embeddings of the learned model for different pairs of source and target (similar to Figure \ref{fig:vis}).
\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{Figures/domain_visualization_pca_1.pdf}
\end{figure}
\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{Figures/domain_visualization_tsne_2.pdf}
\end{figure}
\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{Figures/domain_visualization_tsne_3.pdf}
\end{figure}
\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{Figures/domain_visualization_tsne_4.pdf}
\end{figure}
\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{Figures/domain_visualization_tsne_5.pdf}
   \label{fig:embed}
   \caption{Learned 2D embeddings of various domain pairs as source/target data}\label{fig:embed}
\end{figure}

\end{document}