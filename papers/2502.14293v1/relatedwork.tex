\section{Related Work}
\subsection{Graph Domain Adaptation (GDA)}
While graph domain adaptation (GDA) methods have shown success in transferring knowledge across different domains \cite{shi2024graph}, they face fundamental limitations when applied to anomaly detection tasks. As traditional GDA methods are designed for node classification scenarios with balanced classes and consistent label semantics. 

% Unlike in-domain GAD which primarily deals with evolving patterns within the same domain, cross-domain GAD must handle additional challenges including heterogeneous feature spaces between domains (e.g., Facebook vs. Amazon datasets), varying definitions of normal behavior, and domain-specific structural patterns that define anomalies.

Traditional Graph Domain Adaptation (GDA) approaches, such as GRADE \cite{wu2023non}, AdaGCN \cite{dai2022graph}, and UDA-GCN \cite{wu2020unsupervised} and spectral regularization methods \cite{you2023graph} focus on minimizing distribution shifts across domains but require training samples during inference, limiting their real-time adaptation capabilities. Test-time training (TTT) \cite{sun2020test} has emerged as a powerful framework for handling distribution shifts \cite{li2022out,wu2024graph,zhang2024fully}. Methods like GTrans \cite{jin2022empowering}, GraphCL \cite{you2020graph}, and GT3 \cite{wang2022test} propose graph-specific approaches. TENT \cite{wang2020tent}
uses prediction entropy minimization, while GraphTTA \cite{chen2022graphtta} leverages information theory for TTT on graphs. However, existing GDA approaches, including both traditional methods and TTT-based solutions, face key limitations for anomaly detection as they (1) don't account for extreme class imbalance within domains, (2) lack mechanisms to preserve anomaly-indicating patterns during transfer, and (3) don't handle heterogeneous feature spaces across domains. While there exists limited research on cross-domain graph anomaly detection, prior approaches require direct access to the source dataset during adaptation \cite{ding2021cross, wang2023cross}. Our approach offers key advantages over these methods by eliminating the need to store and access the full source dataset during adaptation. This makes AdaGraph-T3 both privacy-preserving and memory-efficient, making it more practical for real-world deployment where data privacy and computational resources are concerns.

Our work addresses key challenges in deploying GDA in anomaly detection through dataset-specific encoders for heterogeneous feature spaces and a homophily-based unsupervised learning approach that extracts domain-invariant properties of anomalies that generalize across different graph domains. In our experiments, we show that AdaGraph-T3 often outperforms multiple GDA baselines, including GRADE, AdaGCN, TENT, and GTrans.


\begin{figure}[t]
   \centering
   \includegraphics[width=0.6\linewidth]{Figures/homophily_analysis.pdf}
   \caption{Distributions of homophily scores show normal nodes (blue) higher than anomalous nodes (orange) across domains, indicating homophily as a domain-invariant anomaly detector.}
   \label{fig:homophily}
\end{figure}
\subsection{Graph Anomaly Detection (GAD)}
Graph Anomaly Detection (GAD) \cite{ma2021comprehensive,akoglu2015graph} focuses on identifying abnormal nodes in graph-structured data. Traditional approaches like Oddball \cite{akoglu2010oddball} rely on power-law relationships between local graph features, while more recent deep learning-based approaches are more generalizable. For instance, DOMINANT \cite{ding2019deep} employs a graph autoencoder to identify anomalies based on graph reconstruction. ComGA \cite{luo2022comga} introduces a tailored GCN to learn distinguishable node representations by explicitly capturing community structure. Self-supervised techniques have emerged as powerful tools for GAD, with methods like CoLA \cite{liu2021anomaly}, SL-GAD \cite{zheng2021generative}, HCM-A \cite{huang2022hop}, and TAM \cite{qiao2024truncated} introducing various approaches to handle node interactions and structural patterns. While these methods have shown success in single-domain scenarios, they don't address the challenges of cross-domain knowledge transfer. First,
anomalies behave differently across domains-- fraudulent users in e-commerce networks exhibit different patterns compared to social networks. Second, domains often have different feature spaces and graph structures.

% -- social networks have profile-based feature and dense community structures, while e-commerce networks have transaction-based features and sparse connections \cite{shu2017user}.

AdaGraph-T3 bridges both GDA and GAD through a unified approach that combines (1) test-time training with a homophily-based loss for capturing domain-invariant properties of anomalies
(2) enhanced message-passing using normal structure-preserved attention weighting (NSAW) that reduces the irrelevant impact of anomalous nodes on normal nodes' representations, and (3) class-aware regularization that prevents minority class patterns from being overshadowed by majority class during source training. We compare a source-free version of AdaGraph-T3 against GAD baselines (e.g. TAM, ComGA, DOMINANT) to highlight the impact of its GAD-specific features.