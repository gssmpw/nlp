\section{Related Work}
\label{Related Works}


{\bf Diffusion Models for Image Restoration.}
Recent years have witnessed the success of diffusion models in image synthesis~\cite{sohl2015deep,song2019generative,Song_Meng_Ermon_2020,ho2020denoising,rombach2022high,ye2023ip,cheng2024autostudio}. These methods are pre-trained from large-scale text-image pair data~\cite{schuhmann2022laion,krylov2021open} and possess strong generative capabilities in producing realistic images and aesthetically pleasing contents~\cite{dhariwal2021diffusion,ho2022classifier}. Consequently, some recent works have leveraged these models for image restoration. These approaches can be broadly classified into three paradigms: zero-shot, training from scratch, and training from pre-trained models. 


Zero-shot methods~\cite{pan2021exploiting,chung2022improving,wang2022zero,chung2022diffusion,kawar2022denoising} leverage pre-trained diffusion models as generative priors. During sampling, they incorporate degraded images as conditioning factors to tackle linear and non-linear image restoration tasks. However, these methods frequently yield suboptimal results with unpredictable artifacts when applied to real-world data. Other approaches train a conditional diffusion model from scratch~\cite{li2022srdiff, ozdenizci2023restoring, ren2023multiscale}. However, they do not possess the advantages of pre-trained Text-to-Image (T2I) diffusion models and require more training resources. In contrast, some recent works have attempted to utilize T2I diffusion models such as Stable Diffusion~\cite{rombach2022high} for image super-resolution~\cite{wang2024exploiting,lin2025diffbir} and deblurring~\cite{luo2023controlling,zhang2024diff,liu2024diff}. These methods train a lightweight adapter to provide structural conditions for restoration. However, when faced with the unpaired deblurring task, limited realistic blurry-sharp image pairs are available for supervised learning. On the other hand, relying solely on synthetic data often leads to overfitting, resulting in unsatisfactory performance when encountering unseen blur patterns. In our work, BD-Diff is developed based on a pre-trained T2I diffusion model and leverages unpaired data for unsupervised blur pattern learning to facilitate the structure extraction process in real-world blur patterns.


{\bf Image Deblurring}


\textit{Supervised Deblurring with Paired Data.}
With the rapid advances of deep learning and large-scale synthetic blurry-sharp image pairs~\cite{hendrycks2019benchmarking,rim2022realistic}, supervised learning based approaches attempt to learn the transfer function from the blurry domain to the sharp domain. These methods can be generally categorized into two main types: prior-free and prior-related models. The former attempt to directly develop a robust model for blur removal, leveraging CNNs~\cite{chen2022simple,cho2021rethinking,li2022learning,mao2023intriguing} or Transformers~\cite{tsai2022stripformer,kong2023efficient,liang2024image,liu2024deblurdinat}. However, the performance of these methods deteriorates significantly when they encounter unseen blur patterns in real-world scenarios. 
%
On the other hand, the latter approaches aim to learn the blur prior to guide the deblurring network. They predict the prior representations through flow based~\cite{fang2023self,liu2024motion} or diffusion based models~\cite{chen2024hierarchical,laroche2024fast}. Although these approaches achieve improved performance, they cannot learn the prior from unpaired data. This limitation hinders their application in real-world deblurring tasks, where only unpaired data is available.


\textit{Unsupervised Deblurring with Unpaired Data.} Supervised methods trained on synthetic data often underperform on real-world blur patterns due to overfitting. A promising approach to tackle this issue is by leveraging unpaired data from a specific domain. Some works use unpaired data to perform deblurring directly~\cite{zhao2022fcl,zhang2023neural,jiangxin2021learning,ren2020neural,jiang2023uncertainty}, while use auxiliary tasks to enhance the performance of supervised models~\cite{pham2024blur2blur,wu2024id}. 
For the first category, some methods restore missing details in blurry input images by blur-sharp conversion cycles~\cite{yi2017dualgan,zhao2022fcl}. On the other hand, some models estimate prior knowledge from unpaired data ~\cite{zhang2023neural,jiangxin2021learning,ren2020neural,jiang2023uncertainty,dong2021learning}. These approaches usually underestimate the diversity of blur patterns. Furthermore, they require specific adversarial training~\cite{goodfellow2014generative}, which limits their application to diffusion based models. While the methods in the second category~\cite{pham2024blur2blur,wu2024id} aim to transfer unknown blur into a certain known blur pattern. Unfortunately, these approaches entail additional computational costs and are limited by their inability to conduct large-scale training with various synthetic blur patterns. In our work, BD-Diff tends to decouple the learning process of structural features and blur patterns to integrate the generative diffusion model into the unpaired deblurring task.
