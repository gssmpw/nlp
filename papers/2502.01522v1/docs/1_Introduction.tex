\section{Introduction}
\label{Introduction}

Dynamic blur occurs when the camera and subject move relative to each other during the exposure time, resulting in a smeared and blurred image. Deblurring, the process of removing the blur pattern while preserving the underlying structure of degraded images, is essential for restoring high-quality images for human perception and low-level computer vision applications.

\begin{figure}[!t]
  \centering
  \setlength{\tabcolsep}{1pt} 
  \begin{tabular}{c}
    \includegraphics[width=.5\textwidth]{images/0130_tiser1.jpg} \\
    \multicolumn{1}{c}{\vspace{-17pt}} \\
    \small (a) Existing generative-diffusion-based Method \\
    \multicolumn{1}{c}{\vspace{-8pt}} \\
    \includegraphics[width=.5\textwidth]{images/0130_tiser2.jpg} \\
    \multicolumn{1}{c}{\vspace{-12pt}} \\
    \small (b) BD-Diff \\
  \end{tabular}
  \caption{Comparison of BD-Diff with existing generative-diffusion-based deblurring methods. BD-Diff extracts blur patterns from unpaired data to facilitate the supervised structure learning process, thus generalizes well to handle blur images from unknown domains that lack paired data.}
%MH: explain the main point of your approach, why it is different from others. need to make it self-explanatory
   \label{fig:introduction}
\end{figure}

With the rapid advancement of photographic technology, a wide range of imaging devices are now employed to capture images in real-world scenarios. Due to their diverse lenses and structural designs, these devices may produce various and distinct blur patterns~\cite{zhang2023neural,pham2024blur2blur,zhang2020deblurring}. This diversity makes it challenging to develop an all-in-one method for deblurring images from arbitrary and varied sources. Consequently, focusing on deblurring algorithms tailored to specific devices (domains) has become increasingly significant. 


As deep learning has advanced in recent years, existing deblurring models predominantly build on data-driven approaches that employ neural networks trained through supervised learning on synthetic paired data. Existing works have made efforts to develop deblurring models upon CNN~\cite{tao2018scale,nah2017deep}, Transformer~\cite{potlapalli2024promptir,chee2018airnet}, and GAN~\cite{kupyn2018deblurgan,zhang2019gan}. Recently, a new wave of research~\cite{zhang2024diff,lin2025diffbir,liu2024diff} has begun to investigate the integration of pre-trained generative diffusion models~\cite{ho2020denoising}, such as Stable Diffusion (SD)~\cite{rombach2022high}, with an adapter designed to provide structural guidance for deblurring. These approaches aim to harness the generative capabilities of diffusion models to supplement missing details and generate aesthetically pleasing outputs. However, since paired blurry-sharp training data is limited in practical scenarios, these supervised methods often encounter overfitting issues~\cite{pham2024blur2blur}, particularly when dealing with new blur patterns in specific scenarios not captured in the training datasets. 


When relying solely on synthetic data is unsuitable, a promising alternative is to develop an unsupervised method that utilizes the unpaired data from a specific domain to perform deblurring directly or serve as an auxiliary for the supervised models. Existing GAN based methods attempt to reproduce the missing fine details in blurry input images~\cite{yi2017dualgan,zhao2022fcl} or estimate prior knowledge from unpaired data~\cite{zhang2023neural,jiangxin2021learning,ren2020neural,jiang2023uncertainty}. Such approaches tend to underestimate the diversity of blur patterns and are prone to overfitting to a single blur template. Furthermore, they require specific adversarial training~\cite{goodfellow2014generative}, which limits their application to diffusion-based models. Other methods~\cite{pham2024blur2blur,wu2024id} try to transfer unseen blur to a certain blur pattern. Unfortunately, these approaches entail additional computational costs and are limited by their inability to conduct large-scale training with a wide variety of synthetic blurs. Consequently, only a few unsupervised approaches for generative-diffusion-based methods have been developed to handle blur images from unknown domains.


In this work, we propose BD-Diff, a generative-diffusion-based model for image deblurring in unknown domains with blur-decoupled learning. As illustrated in Figure~\ref{fig:introduction}, the core concept of BD-Diff lies in its ability to decouple structural features and blur patterns via joint training on supervised structural learning tasks and unsupervised blur pattern learning tasks. 
Specifically, we employ two Q-Formers~\cite{li2023blip} to extract the structure and blur pattern separately. 
The structure extractor is trained on synthetic data to capture structural features from blurry images as conditioning for SD to perform deblurring. Meanwhile, the blur pattern extractor is trained to identify the blur representation of a specific domain by performing unsupervised blur-transfer tasks. 
In addition, we use a reconstruction task to ensure that the extracted structural features and blur patterns are complementary. As such, BD-Diff generalizes well to handle images from blur domains lacking paired data.

We make the following contributions in this work:
\begin{itemize}
    \item We present BD-Diff, a generative-diffusion-based model for image deblurring on unknown domains. To the best of our knowledge, this is the first work that integrates the generative diffusion model into unpaired deblurring tasks.
    \item We introduce an unsupervised learning strategy in the form of the blur-transfer task, which aims to extract blur patterns by leveraging unpaired data from a specific domain, thereby facilitating structure decoupling.
    \item We propose a joint training strategy to better disentangle the blur pattern and structure features. We prove its effectiveness via experiments on real-world datasets.
\end{itemize}