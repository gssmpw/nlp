\section{Conclusion}

In this work, we propose a Multi-granularity Contrastive Training framework, to perform complex instruction alignment without the introduction of external supervision. Experiment results show our method achieves significant improvement on instruction alignment benchmarks, surpassing previous self-improvement methods by a large margin.
% With the exhaustion of high-quality data, self-alignment is becoming essential for the continuous evolvement of LLMs. 
In the future, we will apply our MuSC on the improvement of other capabilities, such as long-form generation, multi-modal generation, etc.

\section*{Limitations}

Our work still has some limitations: 1) Due to time and resource limitation, we did not validate our method on larger models, such as LLaMA-70B. Validation on larger models could help to improve the credibility of our method. 2) We mainly relied on GPT-4 based LLM-as-a-Judge to evaluate the results. Despite it has been verified that GPT-4 based evaluation achieves high correlation with human evaluators \cite{zheng2023judging}, incorporating human evaluation would further improve the credibility of our methods. 3) We did not scale our method to PPO-based optimization methods, which are also wildly used in recent alignment practice. The application of our method on traditional RL methods could further improve its utility.