\section{Analysis}

\begin{table}[t]
\centering
\resizebox{0.48\textwidth}{!}{
\begin{tabular}{c|ccc|cc}
\toprule
\multirow{2}{*}{\textbf{Method}} & \multicolumn{3}{c|}{\textbf{CF-Bench}}         & \multicolumn{2}{c}{\textbf{AlpacaEval2}}  \\
                                 & \textbf{CSR}  & \textbf{ISR}  & \textbf{PSR}  & \textbf{LC}     & \textbf{Len}    \\ \midrule
Baseline                         & 0.64          & 0.24          & 0.34          & 21.07                & 1702               \\ \midrule
                                 % & MuSC w/o conf                    & 0.70          & 0.30          & 0.41          & 21.19                & 1703 \\ \cline{2-12} 
Perplexity                    & 0.70          & 0.32          & 0.43          & 22.99                & 1744               \\
PMI                           & 0.69          & 0.29          & 0.41          & 21.92                & 1713               \\
KLDiv                         & 0.69          & 0.31          & 0.42          & 21.86                & 1686               \\ \midrule
\textbf{Entropy}              & \textbf{0.71} & \textbf{0.34} & \textbf{0.44} & \textbf{23.74}       & 1631               \\
w/o calib                     & 0.68          & 0.28          & 0.39          & 21.49                & 1735               \\\bottomrule
\end{tabular}}
\caption{Results of different confidence metrics as the fine-grained weight on LLaMA-3-8B-Instruct.}
\label{tab:confidence}
\end{table}

\begin{table}[t]
\resizebox{0.48\textwidth}{!}{
\begin{tabular}{cccccc}
\toprule
\multicolumn{1}{c|}{\multirow{2}{*}{\textbf{Method}}} & \multicolumn{3}{c|}{\textbf{CF-Bench}}                             & \multicolumn{2}{c}{\textbf{AlpacaEval2}} \\
\multicolumn{1}{c|}{}                                 & \textbf{CSR}  & \textbf{ISR}  & \multicolumn{1}{c|}{\textbf{PSR}}  & \textbf{LC}         & \textbf{Len}       \\ \midrule
\multicolumn{1}{c|}{Baseline}                         & 0.64          & 0.24          & \multicolumn{1}{c|}{0.34}          & 21.07               & 1702               \\ \midrule
\multicolumn{6}{l}{\textit{Results on SelfInst}}                                                                                                                      \\ \midrule
\multicolumn{1}{c|}{SimPO$_{MuSC}$}                            & \textbf{0.70} & \textbf{0.31} & \multicolumn{1}{c|}{\textbf{0.42}} & \textbf{22.92}      & \textbf{1716}      \\ 
\multicolumn{1}{c|}{w/o fgct}                            & 0.67          & 0.30          & \multicolumn{1}{c|}{0.40}          & 19.59               & 1637        \\ \midrule
\multicolumn{1}{c|}{IPO$_{MuSC}$}                            & \textbf{0.73} & \textbf{0.37} & \multicolumn{1}{c|}{\textbf{0.48}} & \textbf{23.18}      & \textbf{1650}      \\ 
\multicolumn{1}{c|}{w/o fgct}                              & 0.70          & 0.33          & \multicolumn{1}{c|}{0.44}          & 20.42               & 1686        \\ \midrule
\multicolumn{6}{l}{\textit{Results on PreInst}}                                                                                                                     \\ \midrule
\multicolumn{1}{c|}{SimPO$_{MuSC}$}                            & \textbf{0.69} & \textbf{0.31} & \multicolumn{1}{c|}{\textbf{0.42}} & \textbf{23.28}      & \textbf{1625}      \\
\multicolumn{1}{c|}{w/o fgct}                            & 0.67          & 0.31          & \multicolumn{1}{c|}{0.41}          & 22.02               & 1570        \\ \midrule
\multicolumn{1}{c|}{IPO$_{MuSC}$}                            & \textbf{0.68} & \textbf{0.32} & \multicolumn{1}{c|}{\textbf{0.44}} & \textbf{24.56}      & \textbf{1601}      \\
\multicolumn{1}{c|}{w/o fgct}                              & 0.68          & 0.30          & \multicolumn{1}{c|}{0.42}          & 22.04               & 1531        \\ \bottomrule
\end{tabular}}
\caption{Results of our method on different preference optimization methods on Llama-3-8B-Instruct.}
\label{tab:xpo}
\end{table}

\subsection{MuSC on SFT model}
In Section \ref{sec:experiments}, our main experiments are conducted on the Instruction-version models. To exclude the influence of an initial preference optimization process, we apply our method on SFT models.

Specifically, we selected two SFT-versions of LLaMA models, LLaMA-3-8B-UltraChat-200K and LLaMA-3-8B-Tulu-330K\footnote{\url{https://huggingface.co/Magpie-Align}}. Both models have gone through and only through SFT process on open-sourced datasets. As shown in Table \ref{tab:sft}, our proposed MuSC can improve both the complex and general instruction-following ability of SFT models by a large margin. Notice we only apply 2K samples when performing preference optimization, which is roughly 1\% of the amount of SFT data. This again verifies that learning from negative samples is comparatively more efficient than learning solely from positive samples.

\subsection{The Influence of Confidence Metrics}

Various confidence metrics have been established in the domain of LLM \cite{geng-etal-2024-confidence-survey}. This section aims to provide a comparison across different metrics as the token weight, under the framework of MuSC. We include the following metrics:

\vspace{-2mm}

\begin{itemize}[itemsep=1mm, parsep=0pt]
    \item \textbf{Perplexity}: The exponential of the negative log-likelihood of the token.
    \item \textbf{PMI}: Pointwise Mutual Information as defined in \citet{takayama-arase-2019-relevant}. 
    \item \textbf{KIDiv}: Kullbackâ€“Leibler divergence between the token probability distribution under chosen and rejected instructions.
\end{itemize}

\vspace{-2mm}

As shown in Table \ref{tab:confidence}, entropy-based token weight achieves the best result among all metrics, verifying its effectiveness. Both the perplexity and PMI-based score underperforms, as they only consider the probability of the selected token instead of the whole distribution, leading to biased evaluation. KLDiv-based score also underperforms, this is because KLDiv is essentially a distance measurement instead of a confidence measurement, which is not adapted to our scenario.

We also experiment with removing the calibration proposed in Section \ref{sec:entropy}. As can be seen, calibration is important for the effectiveness of confidence-based fine-grained weight, as it can exclude other factors such as fluency, thereby focusing the contrast on instruction alignment.

\subsection{Can MuSC Scale to Other xPO Method?}
While our experiments primarily focus on the DPO method, the overall framework is not limited to a single preference optimization technique. Therefore, we extended our framework to two additional xPO methods: SimPO \cite{meng2024simpo} and IPO \cite{azar2024general}. We utilized the same constructed preference data and applied the entropy-based score as the token-level supervision\footnote{Please refer to Appendix \ref{sec:impl-dpo} for detailed implementation.}.
Note that for ``w/o fgct'', we just remove the fine-grained contrast in the MuSC method.
In Table \ref{tab:xpo}, our approach has shown consistent improvements across both SimPO and IPO, validating its scalability. 
% Our proposed data construction method, which is based on constraint decomposition and recombination, is not tied to any specific optimization method. 
% Moreover, the token-level fine-grained supervision is also easily integrated due to its simplicity.

\subsection{Is Fundamental Capability Harmed?}

\begin{table}[t]
\resizebox{0.48\textwidth}{!}{
\begin{tabular}{ccccc}
\toprule
\multicolumn{1}{c|}{}                                  &                                 &                                  & \multicolumn{1}{c|}{}                                     &                                \\
\multicolumn{1}{c|}{\multirow{-2}{*}{\textbf{Method}}} & \multirow{-2}{*}{\textbf{MMLU}} & \multirow{-2}{*}{\textbf{GSM8K}} & \multicolumn{1}{c|}{\multirow{-2}{*}{\textbf{HumanEval}}} & \multirow{-2}{*}{\textbf{Avg.}} \\ \midrule
\multicolumn{5}{l}{\textit{Results on Meta-LLaMA-3-8B-Instruct}}                                                                                                                                                         \\ \midrule
\multicolumn{1}{c|}{Baseline}                          & 68.29                           & 79.08                            & \multicolumn{1}{c|}{59.15}                                & 51.63                          \\ \midrule
\multicolumn{1}{c|}{MuSC}                            & 68.24                           & \textbf{79.23}                   & \multicolumn{1}{c|}{\textbf{62.20}}                       & \textbf{52.42}                 \\
\multicolumn{1}{c|}{w/o fgct}                      & {\color[HTML]{9B9B9B} 67.97}    & {\color[HTML]{9B9B9B} 78.62}     & \multicolumn{1}{c|}{{\color[HTML]{9B9B9B} 56.71}}         & {\color[HTML]{9B9B9B} 50.83}   \\ \midrule
\multicolumn{1}{c|}{MuSC}                            & 68.17                           & 77.41                            & \multicolumn{1}{c|}{\textbf{62.80}}                       & \textbf{52.10}                 \\
\multicolumn{1}{c|}{w/o fgct}                      & 67.80                           & 77.71                            & \multicolumn{1}{c|}{\textbf{60.98}}                       & 51.62                          \\ \midrule
\multicolumn{5}{l}{\textit{Results on Qwen2-7B-Instruct}}                                                                                                                                                                \\ \midrule
\multicolumn{1}{c|}{Baseline}                          & 70.76                           & 83.09                            & \multicolumn{1}{c|}{75.61}                                & 57.37                          \\ \midrule
\multicolumn{1}{c|}{MuSC}                            & 70.63                           & \textbf{84.09}                   & \multicolumn{1}{c|}{75.61}                                & \textbf{57.58}                 \\
\multicolumn{1}{c|}{w/o fgct}                      & 70.81                           & 82.94                            & \multicolumn{1}{c|}{{\color[HTML]{9B9B9B} 71.34}}         & {\color[HTML]{9B9B9B} 56.27}   \\\midrule
\multicolumn{1}{c|}{MuSC}                            & 70.46                           & \textbf{84.38}                   & \multicolumn{1}{c|}{75.78}                                & \textbf{57.66}                 \\ 
\multicolumn{1}{c|}{w/o fgct}                      & 70.63                           & \textbf{84.53}                   & \multicolumn{1}{c|}{{\color[HTML]{9B9B9B} 73.78}}         & {\color[HTML]{9B9B9B} 57.24}   \\\bottomrule
\end{tabular}}
\caption{Experiment results of our proposed methods on fundamental capability benchmarks.}
\label{tab:fundamental}
\end{table}

% Previous research have proposed that during the alignment process, the fundamental ability of model may suffer degradation due to alignment tax \cite{ouyang2022training}. Therefore, we evaluated our proposed method on three fundamental benchmarks: 1) MMLU \cite{hendrycks2021measuring}: This data aims to evaluate the ability of knowledge and cognitive abilities. We use the averaged EM score at 0-shot setting as the metric. 2) GSM8K \cite{cobbe2021trainingverifierssolvemath}: This is to assess the capabilities of multi-step mathematical reasoning. We use the EM score at 0-shot with CoT as the metric. 3) HumanEval \cite{chen2021evaluatinglargelanguagemodels}: This is designed to evaluate the code generation capabilities. We use pass@1 at 0-shot as the metric.

Previous research have proposed that during the alignment process, the fundamental ability of model may suffer degradation due to alignment tax \cite{ouyang2022training}. Therefore, we evaluated our proposed method on three fundamental capability benchmarks: MMLU \cite{hendrycks2021measuring}, GSM8K \cite{cobbe2021trainingverifierssolvemath} and HumanEval \cite{chen2021evaluatinglargelanguagemodels}.

% \begin{table}[t]
% \centering
% \resizebox{0.48\textwidth}{!}{
% \begin{tabular}{c|ccc|cc}
% \toprule
% \multirow{3}{*}{\textbf{Method}} & \multicolumn{3}{c|}{\textbf{CF-Bench}}         & \multicolumn{2}{c}{\textbf{AlpacaEval2}} \\
%                                  & \textbf{CSR}  & \textbf{ISR}  & \textbf{PSR}  & \textbf{LC}        & \textbf{Len}     \\ \midrule
% baseline                         & 0.64          & 0.24          & 0.34          & 21.07              & 1702             \\ \midrule
% Const-Drop                       & \textbf{0.71} & \textbf{0.34} & \textbf{0.45} & \textbf{23.43}     & 1682             \\
% Const-Negate                     & 0.68          & 0.28          & 0.39          & 18.94              & 1688             \\
% Const-Sub                        & 0.68          & 0.28          & 0.40          & 20.48              & 1706             \\ \bottomrule
% \end{tabular}}
% \caption{Experiment results of different noising strategies on instruction following benchmarks.}
% \label{tab:noising}
% \end{table}

As shown in Table \ref{tab:fundamental}, while the results of naive MuSC may suffer slight degradation, the introduction of fine-grained contrast mitigates the degradation, which verifies the significance of token-level supervision. Under the scenario of complex instruction, the response is lengthy and should not be uniformly approved or disapproved. With fine-grained supervision, we focus the optimization on complex instruction alignment, thereby avoiding the disruption of other capabilities.

\subsection{The Variation of Statistical Indicators}

\begin{figure}[t]
\centering
\begin{subfigure}{0.48\textwidth}
    \includegraphics[width=\textwidth]{figures/llama_v87v68v70.jpg}
    \caption{Experiment Results on Llama3-8B-Instruct.}
    \label{fig:first}
\end{subfigure}
\hfill
\begin{subfigure}{0.48\textwidth}
    \includegraphics[width=\textwidth]{figures/qwen_v89v73v75.jpg}
    \caption{Experiment Results on Qwen2-7B-Instruct.}
    \label{fig:second}
\end{subfigure}        
\caption{Different statistical indicators during the training steps, upon different methods.}
\label{fig:indicator}
\end{figure}

As different methods start from the same group of instructions, training statistics can be comparable as a quality indicator. Therefore, we display the variation of both loss and reward margins between chosen and rejected samples on different methods. 

% We mainly compare the statistical features of loss and reward margin (which is the reward assigned to the positive sample and the negative sample during training).

As shown in Figure \ref{fig:indicator}, Self-Reward presents both higher loss and lower reward margin during training. This is because there is too much noise between the chosen and rejected pairs, making the model unable to capture the contrast related to constraint alignment. Notice that both indicators start to change drastically at the 2nd epoch, which means the learned knowledge cannot transfer between different samples at the 1st epoch. On the other hand, the optimization based on MuSC converges faster and more smoothly, verifying the effectiveness of the contrast samples.

Comparing the indicators of MuSC with and without fine-grained supervision, it can also be noticed that with the introduction of fine-grained supervision, both indicators converge faster. The introduction of token-level supervision is a cheap yet effective method to improve xPO methods.

For the analysis of different instruction noising schemes and the visualization of token-level weight, please refer to Appendix \ref{app:noising} and \ref{sec:app-results}.