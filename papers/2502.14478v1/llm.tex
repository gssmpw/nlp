\subsection{Why not just use Large Language Models?}

Though \tool has non-negligible runtime for synthesising complex
predicates, its completeness guarantees
(\cf~\autoref{thm:completeness}) ensure that the synthesised
predicates are the best (\ie, the most specific ones) in the
respective search space.
%
Large Language Models (LLMs), as a powerful tool for learning, have
been used extensively in the recent works for synthesising
specifications \cite{wen2024enchanting,ma2024specgen}, with faster
runtime but without completeness guarantees.
%
One may wonder: why not just ask an LLM to synthesise a specification,
and use \prolog to test it against the provided examples, mimicking the
loop of \autoref{alg:popper}?
%
To assess whether our synthesiser with proven completeness guarantees
provides better solutions compared to a state-of-the-art LLM, we pose
SL predicate synthesis as a task for the latter by designing a
detailed prompt outlining our intentions, followed by a series of
queries with inputs similar to what is required by \tool (\ie,
positive examples).
%
%This is done in the following two phase.

% Can LLMs synthesise the heap predicates? We answer this question by
% initial experiments that (1) simply prompt by providing one initial
% example for LLM to learn and (2) try synthesising more complex
% predicates with the same input as \tool.

\subsubsection*{Phase 1: Simple Prompt for Learning}

Before the synthesis, we provide a detailed prompt to an LLMs as
outlinining the required background knowledge, which includes the
following parts:

\begin{enumerate}
\item The task: synthesising SL predicates in \prolog for linked heap
  structures given the graphs.
%
\item An example of the predicate ``sll'' for singly-linked list and
  its graphs, with the explanation. 
%
\item Other synthesis settings,
  such as the predicates
  that can be used for pure constraints, the option to invent
  auxiliary predicates, and the requirements on the size of the
  results. 
\end{enumerate}

\subsubsection*{Phase 2: Synthesising Complex Predicates}

A synthesis prompt for each task is given via the following template,
along with graphs and positive examples in the same format as taken by
\tool:

\begin{verbatim}
  For the next task, here are the graphs: (Graphs)
  And here are the positive examples: (Positive examples)
  Please, synthesise the predicate.
\end{verbatim}


\noindent
%
Our experiments were done on latest ChatGPT-4o.\footnote{The
  conversation snapshot is available
  at~\url{https://chatgpt.com/share/66f266a5-0338-8006-8bb9-1ef61c33d437}.}
%
% , whose detailed
% conversation is provided in supplementary material. 
%
Below, we summarise the outcomes.
%
\begin{enumerate}
%
\item We noticed that LLMs can correctly synthesise the predicates for
  simple cases (\eg, doubly-linked list), but it fails to synthesise
  predicates for more structures with non-trivial constraints (\eg, binary search
  trees and balanced tree): its result often don't type check or miss
  constraints.
%
\item Unsurprisingly, an LLM benefitted from the predicate names we
  provided to it. For example, with providing the name \code{rose_tree}
  in the prompt, the output predicates are mostly correct.
%
\item As LLMs have quick turnaround compared to running \tool, one
  promising direction is to use
  LLMs for the initial exploration of the search space and then use
  \tool to refine the results. 
%
\end{enumerate}

\noindent
%
We conclude that LLMs can be used for synthesising simple predicates,
and have a potential accelerate the synthesis process by deriving
plausible candidates, which can be checked by \prolog and, possibly,
repaired.
%
That said, completeness guarantees of \tool provide tangible benefits,
allowing it derive correct solutions for complex examples, which an
LLM failed to discover.
