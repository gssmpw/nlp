% \vspace{-5pt}

\section{Introduction}
\label{sec:intro}

Separation Logic (SL) is a popular Hoare-style formalism for
specifying and verifying imperative programs that manipulate mutable
pointer-based data
structures~\cite{reynolds2002separation,OHearn-al:CSL01}. 
%
SL has been successfully applied to a wide range of applications,
including program verification~\cite{Appel-al:BOOK14,Jacobs-al:NFM11}, static
analysis~\cite{Calcagno-Distefano:NFM11}, bug
detection~\cite{LeRVBDO22}, invariant inference~\cite{le2019sling,DBLP:phd/basesearch/Dohrau22},
program synthesis~\cite{WatanabeGPPS21,polikarpova2019structuring}, and
repair~\cite{Tonder-LeGoues:ICSE18,NguyenTSC21}.
%
The key to the practical success of SL is its ability to enable
\emph{compositional} reasoning about programs in the presence of
potential pointer aliasing by exploiting the \emph{locality} of common
heap-manipulating operations. 
%
% one can ascribe a declarative specification to a program (\ie, a
% pre- and a postcondition) stated only in terms of its
% \emph{footprint}---the portion of the heap that is required for the
% program to execute safely and without crashes.
% 
% In practice, this means that SL-based reasoning is \emph{modular}: a
% unit of code (\eg, a function) can be verified once and for all \wrt a
% suitable specification and never revisited again, making the SL-based
% verification \emph{scalable} for large codebases.
% %
% Thanks to its scalability and modularity, the last two decades have
% seen proliferation of SL-based tools for program verification (both
% interactive~\cite{Appel-al:BOOK14} and
% automated~\cite{Berdine-al:APLAS05,Jacobs-al:NFM11}), static
% analysis~\cite{Calcagno-Distefano:NFM11}, bug
% detection~\cite{LeRVBDO22}, invariant inference~\cite{le2019sling},
% program synthesis~\cite{WatanabeGPPS21,polikarpova2019structuring} and
% repair~\cite{Tonder-LeGoues:ICSE18,NguyenTSC21}.
To enable expressive specifications, Separation Logic offers a
powerful mechanism to declaratively describe the shape and data
properties of linked heap-based structures, such as lists and trees:
\emph{inductive heap predicates}.
%
% One of the trade-offs of SL-style reasoning is, rtherefore, the need
% to define those predicates so they could be employed in program
% specifications taken as inputs by the verifiers or synthesisers.
%
% As is well-known, the guarantees delivered by formal verification are
% only as good as a specification ascribed to the code, hence one might
% desire those predicates to be as precise as possible, so they would
% capture all important properties of the data structures, required to
% verify programs that manipulate with them.
%
Unsurprisingly, defining precise and useful inductive predicates for
non-trivial data structures in general requires a good grasp of the
structure's \emph{internal invariants}.
%
Most existing SL-based reasoning frameworks require
defining predicates \emph{manually};
%
a few come with a set of pre-defined predicates for the most commonly
used data structures~\cite{Calcagno-al:JACM11,le2019sling},---thus, limiting the
ability of those approaches to verify or generally utilise \emph{data-specific} program
properties, such as, \eg, correctness of searching
an element in a binary search tree.

% What makes things worse is that the diversity of SL dialects hinder reusing the predicates defined for one tool in another.

% So as the current SL-based tools are not easy to be approached by
% non-experts, 

The aim of this work is to offer a methodology for \emph{automatically
  synthesising} inductive predicates for linked structures, where not
only the \emph{shape} but also the \emph{properties} of the stored
data (\eg, a binary tree being \emph{balanced}) would be captured.
%
To achieve this goal, we develop an approach for inferring inductive
SL predicates by synthesising them from \emph{memory graphs}, \ie,
concrete examples of data structure memory layouts, as produced by
programs that generate them.
%
Our work is closely related to two research themes: (1)~synthesising
formal representations of data
structures~\cite{guo2007shape,zhu2016automatically,LPAR23:Learning_Data_Structure_Shapes,molina2021evospex},
and (2)~using machine learning to infer data structure
invariants~\cite{brockschmidt2017learning,molina2019training,DBLP:conf/spin/UsmanWWYDK19}.
%
Existing approachers either impose specific restrictions on the inputs
of the synthesiser by, \eg, requiring functions constructing the data
structure \cite{zhu2016automatically,molina2021evospex} or a large
number of both positive \emph{and} negative
examples~\cite{molina2019training,DBLP:conf/spin/UsmanWWYDK19}; or
produce weaker specification, \eg, only inferring the structure shape,
but not its
properties~\cite{guo2007shape,LPAR23:Learning_Data_Structure_Shapes}.
%

To deliver an effective solution to this problem, our key idea is to
consider inductive heap predicates as \emph{logic programs} in a
\prolog-style language, and concrete memory graphs as \emph{logic
  facts}.
%
This perspective allows us to cast predicate synthesis as a classic
instance of Inductive Logic Programming~(ILP)---synthesising a logic
program by generalising concrete examples and facts about concrete
data instances that are also defined as logic
programs~\cite{Muggleton91,CropperDEM22}.
%
That said, to harness the power of ILP for synthesising SL predicates,
we have to overcome the following two challenges:

\begin{enumerate}[label=\textbf{C\arabic*},topsep=2pt,leftmargin=17pt]
%
\item \label{c1} For \emph{effectively} learning logic programs, ILP
  requires both \emph{positive} and \emph{negative} examples; the
  representative (\ie, non-trivial) negative examples are essential to
  ILP (\cf~\autoref{sec:popper}) but difficult to acquire without a
  human in the loop (\cf \autoref{sec:generator} for a discussion).
%
\item \label{c2} Synthesis of predicates in Separation Logic with
  arbitrary data constraints features a large search space, making it
  difficult to be \emph{efficient}.
%
\end{enumerate}

\noindent
%
To address the challenge \ref{c1}, we propose a novel
\textit{positive-only learning} approach to infer the \emph{most
  specific} logic predicate from a set of positive examples by
incorporating as many of the available (yet non-redundant) pre-defined
constraints as possible.
%
This is achieved by (1)~eliminating logically \emph{redundant}
restrictions featured in generated predicate candidates (as, \eg, the
last one in the series \pcode{A < B, B < C, A < C}) and
%
(2)~by introducing the notion of \emph{specificity} that selects a
locally-optimal inductive SL predicate from a set
of candidates with no redundancies.

Having phrased the inductive heap predicate synthesis as a search
for a local optimum, we inevitably face its large
computational complexity, which brings us to the challenge~\ref{c2}:
\emph{efficiency} of the search.
%
We address this challenge by exploiting the nature of our target
domain, \ie, Separation Logic. The key insight that allows us to prune
many non-viable candidates is to perform early detection of
\emph{invalid} combinations of heap constraints, \eg, those implying
that the same symbolic heap location can be \code{null} and not
\code{null} at the same time.
%
Combined, our solutions to the challenges~\ref{c1} and~\ref{c2}
deliver an approach for effective and efficient inductive synthesis of
inductive heap predicates from concrete memory graphs.

In summary, this work makes the following contributions:
%

% \vspace{-5pt}
%
\begin{itemize}
\item The first inductive synthesis approach of inductive heap
  predicates with arbitrary data constraints, requiring only positive
  examples of memory graphs, achieved by (1)~positive-only learning
  for ILP, (2)~exploiting the domain-specific properties of SL.
%
\item \tool---an automated tool for synthesising SL predicates from
  memory graphs, showcasing the \emph{effectiveness} of our approach
  for synthesising non-trivial predicates in a series of benchmarks.
%
\item \ggen---a memory graph generator that can automatically produce
  positive examples for the predicate synthesis via \tool, given
  data-manipulating programs, which it uses as test oracles.
%
\item Demonstration of utility of \tool by (a)~learning the predicates
  for verification from real-world heap-manipulating programs by
  obtaining memory graphs automatically via \ggen, and (b)~using the
  synthesised predicates for automated deductive synthesis.
\end{itemize}

% \subsubsection*{Related Work.}

% The challenge~\ref{c1} has been to some extent addressed by the prior
% work on the tool \shape~\cite{LPAR23:Learning_Data_Structure_Shapes}
% implementing an approach to infer shapes of linked structures from
% valid memory graphs, without requiring negative examples via
% \emph{meta-interpretative learning} (MIL)~\cite{muggleton2014meta}.
% Unfortunately, \shape is only capable to infer predicates that
% restrict the \emph{shape} of a structure, not allowing for constraints
% on the \emph{data} stored in it.
% %
% The reason is that MIL can only express the learning space within
% certain forms of predicate bodies, while more complex forms are
% required to learn the layout restriction, \eg, capture ordering in a
% sorted list. \tname{DOrder}~\cite{zhu2016automatically} and
% \tname{Evospex}~\cite{molina2021evospex} are two later works on
% learning the data invariants from the \emph{constructors} of the data
% structures (in OCaml or Java), which is a stronger requirement
% compared to taking memory graphs only.

% Our work can be regarded as an instance of \emph{specification
%   synthesis}
% \cite{park2023synthesizing,DBLP:conf/popl/AlbarghouthiDG16}: the
% inferred specifications in our work is are Separation Logic
% predicates. 
% %
% % \is{The rest of this paragraph is unclear, please, rewrite. Explain:
% %   (1) what does Precis learn? (2) How its method is different from
% %   ours? (3) How its goals to similar to ours? (4) Why it doesn't
% %   subsume our results. No technical mumbo-jumbo such as ``one-class
% %   specification''. }
% %
% Our challenge~\ref{c1} is also addressed by
% \tname{Precis} \cite{DBLP:journals/pacmpl/AstorgaSDWMX21},
% %
% which synthesises program contracts from positive-only examples
% provided by tests. Though we share the similar concepts to express
% optimality of a specification, their method is not applicable to our
% domain: \tname{Precis} assumes that predicates in the synthesised
% specifications are \emph{functional} relations on data, which is not
% expressive enough to describe either the data or heap shape properties
% as captured by inductive SL definitions.

% Therefore,
% our synthesis domain is more general, then also introduces more
% challenges (\eg, the redundancy problem in \autoref{sec:normalise}) to
% be solved.

% (as
% one-class classification), but their learning domain is different from
% ours: \tname{Precis} learns a specification withing a search space of
% decision trees, where the definition of tightness of a specification
% is given by the number of conjunctions. 
% %
% Our synthesis domain is not the only case where the properties of the
% predicates should be considered: in \tname{Precis}'s search space, the
% predicates are synthesised by SyGuS solver, so the predicates can only
% describe functional relation among input and output, which is not
% extensible to synthesise SL predicates.
