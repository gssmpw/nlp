%\vspace{-15pt}

\section{Separation Logic Predicate Synthesis via \tool}
\label{sec:SLsynthesis}

Having described the enhanced \emph{general-purpose} predicate
synthesis algorithm from positive-only examples,
%
we now show how to instantiate it for synthesis of inductive SL
predicates and improve the efficiency of the search algorithm by
exploiting domain-specific SL insights. We further discuss the
SL-validity of the synthesised predicates and the completeness of the
search algorithm.

\subsection{SL Predicates: Basics and Intricacies}
\label{sec:default}
 
\begin{figure}[!t]
  \centering
  \[
\begin{aligned}
  \sym{predicate} & ::= \sym{main\_pred} \;|\; \sym{main\_pred}  \sym{invented\_pred}\ast \\
  \sym{main\_pred} & ::= \sym{base\_clause}(\pre{main\_head}) \;|\; \sym{rec\_clause}(\pre{main\_head})\ast \\
  \sym{invented\_pred} & ::= \sym{base\_clause}(\pre{inv\_head}) \;|\; \sym{rec\_clause}(\pre{inv\_head})\ast \\
  \sym{base\_clause}(H) & ::= H(\codeinmath{This}, \sym{args}) \leftarrow \sym{base\_lit}\ast, \sym{pure\_lit}\ast \\
  \sym{rec\_clause}(H) & ::= H(\codeinmath{This}, \sym{args}) \leftarrow \sym{pointer\_lit}\ast, \sym{rec\_lit}\ast, \sym{pure\_lit}\ast \\
  \sym{literal}(R) & ::= R(\sym{args}) \\
  % Define the specific types of literals
  \sym{base\_lit} & ::= \sym{literal}(\pre{base\_pred}) \qquad\qquad \texttt{\% Pre-defined  for spatial relations} \\
  \sym{pure\_lit} & ::= \sym{literal}(\pre{pure\_pred}) \qquad \qquad\enspace \quad \texttt{\% Pre-defined  for pure relations} \\
  \sym{pointer\_lit} & ::= \pre{domain}(\codeinmath{This}, \sym{var}) \qquad\qquad\quad\enspace \texttt{\% Extract from the memory graphs} \\
  \sym{rec\_lit} & ::= \sym{literal}(\sym{head}) \\
  % General concepts
  \sym{args} & ::= \sym{var} \;|\; \sym{var}, \sym{args} \\
  \sym{var} & ::= \codeinmath{X1} \;|\; \codeinmath{X2} \;|\; \dots \;|\; \codeinmath{This} \\
  \sym{head} & ::= \pre{main\_head} \;|\; \pre{inv\_head} \quad \texttt{\% From the task or randomly generated}
\end{aligned}
\]
\caption{The grammar of the SL predicates, in basic Backusâ€“Naur form
  (BNF), extended with (1) meta-variables $(\cdot)$ for specialising
  the symbols, and (2) pre-defined atoms denoted by $\pre{X}$ (with
  comments of their origins).}
  \label{fig:grammar}
\end{figure}

We define the space of SL predicates in a way standard for
Syntax-Guided Synthesis (SyGuS)~\cite{Alur-al:FMCAD13}.
%
The grammar of the SL predicates is shown in \autoref{fig:grammar}. An
SL predicate is either having a shape with a single main predicate, or
shaped by a main predicate together with a set of invented
\emph{auxiliary} predicates, which are required in the case of nested
linked structures.
%

Specific to the predicates,
both main predicate and invented predicates consist of the base and recursive clauses, where the base clause is the one that does not have any recursive calls, and the recursive clause is the one that has recursive calls. The head literal (\ie, before $\leftarrow$) in each clause has a fixed argument \pcode{This} that denotes the base address of the data structure (similar to the \textit{this} reference in object-oriented programming).
% 
The body literals (\ie, after $\leftarrow$) in the clauses are defined in terms of different predicates: the base (and pure) predicates are pre-defined, but extensible, to capture the spatial relation among the pointer for the base clause (the pure constraints among variables in clauses, respectively); the domain predicates describe the points-to relations can be obtained from the memory graphs; the recursive predicates are the recursive calls to the main or invented predicates.

% To define a tractable search procedure


Three aspects in the grammar in \autoref{fig:grammar} contribute to the
infinite synthesis search space: (1) the length of clauses, (2) the
number of sub-clauses for each predicate, (3) the arity of the
invented predicates. 
%
% As customary in SyGuS, we bound them with constants.
%
For our task, we noticed that predicates for real-world structures
rarely require more than 10 literals in their bodies; two sub-clauses
for each predicate are sufficient to capture the common structures;
and the arity of the invented predicates is set to be not more than
the arity of the main predicates. Such bounds for hypothesis space are
common in almost all synthesis-by-example tools~(\eg,
\cite{cropper2021learning,lee2021combining,Si-al:FSE18}), not only to
make the synthesis tractable, but also to avoid
overfitting~\cite{PadhiMN019} (\eg, a predicate disjointing facts of
all examples).
%

Below, we discuss two challenges in make SL predicate synthesis
effective and efficient, together with how we address them in \tool.

% %
% The restriction of the search space is also a
% common solution to \emph{overfitting}, which is common in
% synthesis-by-example methods: there is always a
% predicate disjointing facts of all examples, but it is
% likely to be overfitted for specific examples. By providing a finite
% search space, such problem is eliminated.

% The outline  approaches here are
% presented in the context of our SL-specific setting, but are also
% applicable to other ILP tasks.


\subsubsection{Semantic-Based Pruning.}
\label{sec:semantics}

In most existing syntax-guided synthesisers \cite{cropper2021learning,Alur-al:FMCAD13,Si-al:FSE18}, the search is accelerated by pruning of the hypothesis search
space by employing the general \emph{syntax}
restrictions.
%
Other than limiting the syntax, we apply the following \emph{semantic}
properties' restriction of Separation Logic predicates to the search.
%
% Specifically, we encode the properties of SL predicates (\eg, \emph{minimum
%   reachability, pointer functionality}) with ASP so that many invalid
% outputs from \popper are eliminated. 
%
\begin{enumerate}
  \item \emph{Basic reachability}: no points-to relation appears in the
    body other than the ones from the \pcode{this} pointer. Thus, the clause \pcode{p(X, Y) :- next(X, Y), next(Y, Z), ...} is not 
    allowed as a candidate, because we expect all locations in the body to be
    accessible from \pcode{this} via fields.
  %
  \item \emph{Basic assumptions}: the base (non-recursive) clause
    restricts \pcode{this} pointer to either be \code{null} or to equal to
    another pointer parameter variable. \Eg, \pcode{p(X, Y) :-
      nullptr(X), ...} is allowed, but \pcode{p(X, Y) :-
      next(X, Y), ...} cannot be a base clause.
  %
  \item \emph{Restricted use of} \code{null}: if a variable \pcode{X} is
    a null-pointer (denoted by \pcode{nullptr(X)}), no
    more \pcode{X} occurs in the clause. \Eg, the clause \pcode{p(X, Y) :- nullptr(X), next(X, Y)}
    is not allowed.
  %
  \item \emph{Quasi-well-founded recursion of payload}: the pure argument passed to a
    recursive call should (non-strictly) decrease. \Eg, for a clause
    \pcode{p(X, S) :- next(X, Z), p(Z, S1), ...}, the set \pcode{S} should contains \pcode{S1}. This
    is a common assumption in recursive program synthesis \cite{albarghouthi2013recursive,lee2021combining}.
  %
  \item \emph{Heap functionality}: points-to relations of the same field
    should not target different locations. \Eg, a candidate clause cannot be \pcode{p(X, Y) :- next(X, Z), next(X, Z1), ...}.
  %
  \end{enumerate}

\noindent
%
This list of search constraints represents a combination of the
properties implied by SL semantics (in a Java-style field-based memory
model) as well as by common properties of data structures, which are
essential for the efficient search of SL predicates.
%
The exact encodings of these constraints in ASP are provided and explained in \autoref{app:slsemantics}.

\subsubsection{Free Variables and Auxiliary Placeholders.}
\label{sec:auxiliary}

Free variables are common in SL predicates, \eg, the (implicitly
existentially-quantified) location \pcode{Y} in the base clause of the
 doubly linked list below:
%
\begin{minted}[fontsize=\small]{prolog}
  dll(X, Y) :- nullptr(X).
  dll(X, Y) :- next(X, Z), prev(X, Y), dll(Z, X).
\end{minted}
%
Unfortunately, completeness guarantees of pruning discussed in \autoref{sec:popper2}  do not hold for
predicates with free variables in the sense that
 a complete (\ie, valid) hypothesis with free
variables might  be wrongfully pruned during the search~\cite[\S{4.5}]{cropper2021learning}.
%
To address this problem, we introduce \emph{auxiliary placeholders}
into the search as a way to express predicate clauses with free
variables.
%
For example, the following doubly linked list predicate can be
regarded the same as the one above with \pcode{anypointer()}
placeholder, and \emph{can} be synthesised.
%
\begin{minted}[fontsize=\small]{prolog}
  dll(X, Y) :- nullptr(X), anypointer(Y).
  dll(X, Y) :- next(X, Z), prev(X, Y), dll(Z, X).
\end{minted}
%
On a technical level, this requires adding an ASP constraint (shown in \autoref{app:auxiliary})
that forces the parameter of the placeholder predicate (\pcode{Y}
here) to appear \emph{twice} in the whole clause, so it could be later
translated into a single occurrence of a free variable.

% \subsubsection{Hypothesis Specificity.}
% \label{sec:specificity}

% Having applied the clause minimisation for redundancy elimination, the
% synthesiser is often left with the problem to choose the best
% hypothesis from the set of ``canonical'' candidates, none of which
% entail each other.
% %
% Our novel notion of specificity is aimed to provide an ordering that
% helps to make such a choice.
% %
% As an example, consider
% %
% the predicates \pcode{p()} and \pcode{q()} of the same size, defined
% as \pcode{p(A, B) :- succ(A, B)} and \pcode{q(A, B) :- less_than(A,
%   B)}.
% %
% But based on the meaning of the predicates, we should know
% that \pcode{succ(A, B)} is a stronger statement than
% \pcode{less_than(A, B)}, so \pcode{p(A, B)} is more specific than
% \pcode{q(A, B)}. With this to be considered, the specificity of a
% hypothesis is defined by the following (strict) partial order.


% \begin{definition}[Hypothesis Specificity]
% \label{def:spec}
% Given two hypotheses $A, B$ with the same arity and the same number of
% clauses, $A$ is \emph{more specific than} $B$ (denoted by $A \prec B$)
% \Iff either ($i$) $\mathit{size}(B) < \mathit{size}(A)$ (\ie, $A$ has
% strictly more literals), or ($ii$)
% $\mathit{size}(A)=\mathit{size}(B)$, and $\exists\mathit{l}_1$,
% $\mathit{l}_2$, s.t. $B(\mathit{l}_1/\mathit{l}_2) = A$, and
% $\mathit{l}_1 \models \mathit{l}_2$, and
% $\mathit{l}_2 \not\models \mathit{l}_1$, where
% $\mathit{l}_1/\mathit{l}_2$ denotes the replacement of the literal
% $\mathit{l}_2$ in a sub-clause of $B$ by $\mathit{l}_1$.
% \end{definition}

% \todo{}
% We conclude this section with the following formal proposition stating
% that our synthesis algorithm returns a \emph{locally-optimal} hypothesis 
%  in the search space with specificity as the
% metric.

% \begin{theorem}
%   \label{thm:specific}
%   The hypothesis returned by the positive-only learning in
%   \emph{\autoref{alg:popper}} is the most specific (i.e., the local
%   minimum of the specificity) predicate that is complete in the search
%   space defined by the algorithm's initial constraints
%   (\pcode{in_cons}) and the size limit (\pcode{max_size}) parameters.
% \end{theorem}
% \begin{proof}[Proof]
%   By induction on the size limit \pcode{max_size} of the predicate: when \pcode{max_size} is 0, there is no predicate hypotheses, so \pcode{None} is the most specific one. Then assume that the theorem holds for \pcode{max_size} $n$, \ie, \pcode{sol_i} is the most specific; we prove it for \pcode{max_size} $n+1$.

%   When \pcode{max_size} is $n+1$, based on the while loop in
%   \autoref{alg:popper}, the search space for $n+1$ is the search space
%   for $n$ plus when \pcode{size} is $n+1$. By the induction
%   hypothesis, \pcode{sol_i} is the most specific in the search space
%   for $n$, and the output \pcode{sol} is either \pcode{sol_i} or the
%   more specific one in $n+1$. Therefore, \pcode{sol} is the most
%   specific in the search space with $n+1$ as \pcode{max_size}.

% \end{proof}

\subsection{Ensuring SL Validity in \prolog}
\label{sec:sldomain}

An astute reader can notice that the validity of the synthesised
predicates is not immediate due to our treatment of \prolog clauses as
SL assertions: the conjunction in \prolog does not guarantee the
\emph{separating conjunction} (\pcode{*}) in the SL sense. As an
example, consider the following simplified \prolog predicate for
binary trees:
%
\begin{minted}[fontsize=\small]{prolog}
  bi_tree(X) :- nullptr(X). 
  bi_tree(X) :- t1(X, L), t2(X, R), bi_tree(L), bi_tree(R).
\end{minted}
%
In this case, an instance of \pcode{bi_tree(X)} being evaluated to be
\emph{true} in \prolog can imply \emph{false} under SL semantics that
enforces heap disjointness: considering a memory graph with two nodes
%
\begin{minted}[fontsize=\small]{prolog}
  t1(n1, n2). t2(n1, n2). t1(n2, null). t2(n2, null).
\end{minted}
%
so that the graph fact \pcode{bi_tree(n1)} is provable in \prolog, but
the clauses \pcode{bi_tree(L)} and \pcode{bi_tree(R)} are
\emph{non-disjoint}.
%
Notice that, in our inductive synthesis setting, this situation would
correspond to having \emph{multiple} occurrences of the same points-to
fact in a memory graph representing a positive example for the
predicate, but should not be allowed by the definition of separating
conjunction.

To avoid this source of unsoundness, we use a straightforward solution
that enforces such separating conjunction semantics in \prolog: a
valid SL predicate is a complete \prolog predicate where the positive
examples succeed using each points-to fact \emph{exactly} one time (a
semantic property of SL assertions known as \emph{linearity}).
%
For the complete \prolog but invalid SL predicates, we also use the
\textit{specialisation} rule in \autoref{sec:popper2} to prune them:
if a predicate violates the linearity, then a more constrained one
will also violate it; this contributes to the new pruning in
line~15 of \autoref{alg:popper}.

We establish the following property of our SL-specific predicate
synthesis stating that, for the predicates in \tool's search space in
\autoref{sec:default}, if a memory graph is provable in \prolog with
linearity, then the corresponding heap is valid under SL semantics.

\begin{theorem}[SL Validity]
\label{thm:validity}
Let \pcode{F(h)} denote the memory graph of a heap \pcode{h}. For any
output predicate \pcode{p(X)} of \tool and any heap \pcode{h}, the
following fact holds: 
%
  \pcode{F(h)} $\models_{\prolog+\text{Lin}}$
\pcode{p(X)} $\Rightarrow$ \pcode{h} $\models_{\text{SL}}$ \pcode{p(X)}.
% \begin{center}
% \end{center}
\end{theorem}




\subsection{The \tool Algorithm}
\label{sec:tool}

The only remaining step before putting all the pieces together is to
select the desired predicate from the set of non-comparable solutions
of positive-only learning. 
%
Even though predicates from POL can be conjuncted in general, the
semantics of SL predicates following the definition in
\autoref{sec:default} is more restrictive and the conjunction of valid
SL predicates may result in an ill-formed or a constantly false one. 
%
We found in practice that after the semantics-based normalisation from
\autoref{sec:normalise}, the number of literals can serve as a
\emph{good enough} specificity metric among incomparable predicates,
since containing more literals is likely to contain more information
or constraints about the heap structure. 
%
Following this intuition, we define the synthesis algorithm with
MAX\_POL function, which obtains the largest predicate from POL as per
\autoref{alg:popper}.

\begin{algorithm}[!t]
  \caption{The \tool loop for inductive predicate synthesis}
  \label{alg:sippy}
  \begin{algorithmic}[1]
  \small
  \Require memory graphs consist of \pcode{graph_bk, exs}
  \Procedure{Sippy}{\pcode{graph_bk, exs}}
      \State \pcode{graph_cons, shapes} = \pcode{graph_info(graph_bk, exs)}
      \State \pcode{max_var} = \pcode{max_body} = 1
      \State \pcode{sol} = \pcode{True} \Comment{The most general solution as initialisation}
      \For{\pcode{shape} in \pcode{shapes}}
        \State \pcode{max_size} = \pcode{maxsize(max_body, shape)}
        \State \pcode{h} = \Call{MAX\_POL}{\pcode{graph_bk, exs, graph_cons, max_size}}
        \If{\pcode{h} $\prec$ \pcode{sol}} \Comment{A more specific predicate is obtained}
            \State \pcode{max_var, max_body} = \pcode{(var_of(h), size_of(h))} + $\delta$
            \State \pcode{sol} = \pcode{h}
        \ElsIf{\pcode{sol} == True} \Comment{No predicate is yet learned}
            \If{\pcode{max_var} == \pcode{upper_bound}}
                \State \textbf{continue} \Comment{Try the next shape}
            \EndIf
            \State \pcode{max_var, max_body} += (1, 1)
        \Else
            \State \textbf{break} \Comment{No more specific predicate is found}
        \EndIf
      \EndFor
      \State \Return \pcode{sol}
  \EndProcedure
  \end{algorithmic}
\end{algorithm}



\autoref{alg:sippy} summarises the internal workings of \tool.
%
Our synthesiser takes as inputs memory graphs encoded as sets of logic
facts (\eg, \pcode{graph_bk}, such as \pcode{next(..)} and
\pcode{value(..)} from \autoref{fig:sorted-list}), positive examples of
heaps on which a predicate holds (\eg, \pcode{exs} as \pcode{srtl(..)}
from \autoref{fig:sorted-list}), so that the shape (matched with
pre-defined shapes in \autoref{sec:default}) a set of ASP constraints
(\pcode{graph_cons}) describing the information in the graphs (such as
the arity and types of the predicates to be learned) are obtained
(line~2).
%
Two parameters (line~3) for positive-only learning (MAX\_POL), (1)~the maximum number of
variables and (2)~the maximum size of the body of a predicate clause
for restricting the search space, are gradually increased during the
search using the following empirical strategy:
%
if no solution is valid (line~11), we either increase both parameters
by one to enlarge the space until finding one (line~14), or the
attempt on the current predicate shape fails (\ie, the upper bound of
the search space is reached), then
\tool will try synthesising using the next shape (line~13, \ie, more auxiliary predicates);
%
when obtaining one new better predicate than the existing, the search
parameters are both increased by a parameter~$\delta$ to find a
possibly more specific predicate (line~9), and the solution is
updated (line~10); if the learned predicate in the larger search space
is not better than the previous, we stop the search and output
(line~15-16).
%
The role of the parameter $\delta$ is, thus, to provide a ``margin''
for the completeness of the search: it is not guaranteed that \tool
will find the most specific solution \emph{across all possible search
  spaces}, but only in the search-space that is bound by the returned
output's parameters \emph{plus}~$\delta$.\footnote{We choose it to be (1,2) in our experiment from the natural observation: for our domain, we expect to have one body literal where the predicate is generating a new variable, and one more body literal that uses the new variable.}
%
Note that line~6 of \autoref{alg:sippy} features a function
\pcode{maxsize()} that calculates the maximum size of the search space based on the maximum number of variables and the predicate shape setting.

Finally, we provide a correctness argument for \tool. The soundness of
synthesising \emph{consistent} (\ie, inhabited) and \emph{well-formed}
(\ie, finitely provable) SL predicates is guaranteed by the soundness
of classic ILP and \autoref{thm:validity}. The following ``local''
completeness states that, given the output of \tool, no more specific
output can be discovered, \emph{even in} the larger search space
obtained by increasing the search parameters \emph{once} by $\delta$
at the line~9 of \autoref{alg:sippy}.

\begin{theorem}[Local Completeness of \tool]
\label{thm:completeness}
If the output of \tool is a predicate with the maximum number of
variables $m$ and the maximum length of the body $n$, then there is no
predicate with the maximum length of the body $m'$ and the maximum
number of variables $n'$, where $(m',~n')-(m,~n) = \delta$, that is
more specific than the output predicate.
\end{theorem}
\begin{proof}[Proof]
  Directly by contradiction and Theorem 3.1. Assume that the output solution \pcode{sol} is with size $(m,~n)$, and it is not the most specific one in size $(m',~n') = (m,~n) + \delta$.

 Because \pcode{sol} is the output, the search space is set to be $(m',~n')$ after the loop it is obtained. With Theorem 3.1 and the assumption, there is a solution \pcode{sol}$'$ in $(m',~n')$ that is more specific than \pcode{sol}, which is a contradiction with the output \pcode{sol}. Thus, \pcode{sol} is the most specific one in $(m',~n')$.
\end{proof}







% \subsection{Domain-Specific Pruning}
% \label{sec:dsc}

% So far we have shown how to encode the syntax of SL predicates
% (\autoref{sec:default}) as well as their basic semantic properties
% that guarantee validity of the solutions (\autoref{sec:sldomain}).
% %
% To enable even more aggressive yet sound search space pruning, we have
% encoded more SL properties as ASP search constraints:
% %
% \begin{enumerate}
% \item \emph{Basic Reachability}: no points-to relation appears in the
%   body other than the ones from the \pcode{this} pointer. For instance, the
%   predicate like \pcode{p(X, Y) :- next(X, Y), next(Y, Z), ...}, is not
%   allowed, because we expect all locations in the body to be
%   accessible from \pcode{this} via fields.
% %
% \item \emph{Basic Assumptions}: the base (non-recursive) clause
%   restricts \pcode{this} pointer to either be \code{null} or to equal to
%   another pointer parameter variable. For instance, \pcode{p(X, Y) :-
%     nullptr(X), ...} can be the base clause, but \pcode{p(X, Y) :-
%     next(X, Y), ...} cannot.
% %
% \item \emph{Restricted use of} \code{null}: if a variable \pcode{X} is
%   a null-pointer (denoted by \pcode{nullptr(X)}), no
%   more \pcode{X} should occur in the clause body. For example, \pcode{p(X, Y) :- nullptr(X), next(X, Y)}
%   is not allowed.
% %
% \item \emph{Quasi-well-founded recursion}: the pure argument passed to a
%   recursive call should (non-strictly) decrease. For instance,
%   \pcode{p(X, Y) :- next(X, Z), Y1 == Y+1, p(Z, Y1)} is not valid. This
%   is a common assumption in recursive program synthesis, which is also
%   suitable for our task.
% %
% \item \emph{Heap functionality}: points-to relations of the same field
%   should not target different locations. For instance, \pcode{p(X, Y)
%     :- next(X, Z), next(X, Z1), ...} is not allowed.
% %
% \end{enumerate}
% %
% This list of search constraints represents a combination of the
% properties implied by SL semantics (in a Java-style field-based memory
% model) as well as by common properties of shapes of data structures
% considered.
% %
% The rules above are merely optimisations: they are not necessary to
% ensure correctness of \tool and serve to restrict the search space to
% be a refined (but expressive) domain of SL predicate. 


