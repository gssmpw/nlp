\section{Related Works}
\textbf{Time Series Forecasting} is a well-established problem that involves using historical data, often referred to as ``context,'' to predict future values, known as the ``forecast.'' 
It has been extensively studied across various domains, including finance, healthcare, and weather prediction. 
Traditional approaches have relied on statistical methods, such as ARIMA, which use autoregression and moving averages to model time series data and are widely adopted for their simplicity and interpretability \cite{box2015time}.

In recent decades, neural network-based solutions have gained popularity, particularly with the advent of Convolutional Neural Networks (CNNs) \cite{cnn} and Long Short-Term Memory (LSTM) \cite{lstm} networks, which excel at capturing long-term dependencies in sequential data through their memory cells and gating mechanisms.
More recently, transformer-based architectures have been explored for time series forecasting, leveraging self-attention mechanisms to capture long-range dependencies efficiently, as demonstrated in prior works such as \cite{NEURIPS2019_6775a063}, which addresses locality and memory bottlenecks in transformers, and \cite{liu2022pyraformer}, which introduces pyramidal attention for low-complexity long-range modeling.
Foundation Models (FMs) are large-scale, pretrained machine learning models trained on large amounts of data at scale, which can be adapted (fine-tuned) to a wide range of downstream tasks across diverse domains \cite{bommasani2022opportunitiesrisksfoundationmodels}.
Initially popularized in NLP and CV, they are now being applied to time series data to overcome the limited application-specific data available. 
Notable works in this area include Amazon's Chronos \cite{chronos}, Google's timesFM \cite{timesFM}, and Lag-llama \cite{lagllama}, all of which have demonstrated the potential of FMs in time series forecasting.

\textbf{Federated Learning (FL)} has also seen substantial research interest in recent years, particularly in addressing the challenges of systems and statistical heterogeneity. 
Systems heterogeneity refers to the variation in computational and network resources among clients, while statistical heterogeneity deals with non-IID data across clients.
While systems heterogeneity is crucial, our work focuses primarily on statistical heterogeneity, which poses significant challenges in FL.

% To address systems heterogeneity, several methods have been proposed. 
% For example, FedProx \cite{fedprox} introduces partial updates from clients to accommodate varying resource constraints. 
% It does so by adding a proximal term to the client's local loss function, arguing that doing so would allow clients to train for a lower number of steps.
% PruneFL \cite{prunefl}, another solution that counters systems heterogeneity, offers adaptive model serving that accounts for differences in clients' computational and network capabilities. 

To address statistical heterogeneity, several methods have been proposed. 
% Recent studies have tackled statistical heterogeneity. 
FedProx introduces partial updates to handle resource constraints and reduce local model deviation from the global model \cite{fedprox}, with convergence analysis demonstrating its potential to mitigate statistical heterogeneity challenges.
FedOpt introduces federated versions of popular optimizers like Adam and Adagrad to mitigate the effects of non-IID data \cite{fedopt}. 
SCAFFOLD focuses on reducing variance between clients and the central server, thus improving model convergence in heterogeneous environments \cite{scaffold}.
Although these strategies have been developed to handle non-IID data within FL, they have largely focused on class imbalance and classification tasks rather than time series.

While a few works have investigated FL on time series data in the medical domain on problems such as arrhythmia classification using 12-lead ECG signals  \cite{10301542} and personal identification using vital signs data \cite{10.1007/978-3-031-49361-4_3}, they have not focused on time series forecasting. 
Several studies have applied FL to time series forecasting in domains such as base station traffic prediction \cite{PERIFANIS2023109950} and generalized benchmarks \cite{yuan2024tacklingdataheterogeneityfederated}, with a strong focus on non-IID data. 
However, they have not explored the use of FMs in the medical domain.
Our work is novel in that it explores the fine-tuning of pretrained FMs using FL for medical time series forecasting, with a particular focus on exploring FL under statistical heterogeneity.
