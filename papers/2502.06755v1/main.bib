# Scientific Method #
#-------------------#

@book{poincare1914science,
  title={Science and Method},
  author={Poincar{\'e}, Henri},
  year= {1914},
  publisher={Thomas Nelson},
  address={London}
}

@book{popper1959logic,
    title={The Logic of Scientific Discovery},
    author={Popper, Karl},
    year={1959},
    publisher={Julius Springer, Hutchinson \& Co},
    address={Berlin}
}

@inproceedings{pennington2014glove,
  title={Glove: Global vectors for word representation},
  author={Pennington, Jeffrey and Socher, Richard and Manning, Christopher D},
  booktitle={Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)},
  pages={1532--1543},
  year={2014}
}
@article{mikolov2013word2vec,
  title={Distributed representations of words and phrases and their compositionality},
  author={Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg S and Dean, Jeff},
  journal={Advances in neural information processing systems},
  volume={26},
  year={2013}
}



#----------------------------------------------#
#              Sparse Autoencoders
#----------------------------------------------#
@article{makhzani2013k,
  title={K-sparse autoencoders},
  author={Makhzani, Alireza and Frey, Brendan},
  journal={arXiv preprint arXiv:1312.5663},
  year={2013}
}

@article{makhzani2015winner,
  title={Winner-take-all autoencoders},
  author={Makhzani, Alireza and Frey, Brendan J},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}


@inproceedings{subramanian2018spine,
  title={Spine: Sparse interpretable neural embeddings},
  author={Subramanian, Anant and Pruthi, Danish and Jhamtani, Harsh and Berg-Kirkpatrick, Taylor and Hovy, Eduard},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={32},
  year={2018}
}

@article{zhang2019word,
  title={Word embedding visualization via dictionary learning},
  author={Zhang, Juexiao and Chen, Yubei and Cheung, Brian and Olshausen, Bruno A},
  journal={arXiv preprint arXiv:1910.03833},
  year={2019}
}


@article{yun2021transformer,
  title={Transformer visualization via dictionary learning: contextualized embedding as a linear superposition of transformer factors},
  author={Yun, Zeyu and Chen, Yubei and Olshausen, Bruno A and LeCun, Yann},
  journal={arXiv preprint arXiv:2103.15949},
  year={2021}
}


@inproceedings{huben2024sparse,
    title={Sparse Autoencoders Find Highly Interpretable Features in Language Models},
    author={Robert Huben and Hoagy Cunningham and Logan Riggs Smith and Aidan Ewart and Lee Sharkey},
    booktitle={The Twelfth International Conference on Learning Representations},
    year={2024},
    url={https://openreview.net/forum?id=F76bwRSLeK}
}

@article{gao2024scaling,
  title={Scaling and evaluating sparse autoencoders},
  author={Gao, Leo and la Tour, Tom Dupr{\'e} and Tillman, Henk and Goh, Gabriel and Troll, Rajan and Radford, Alec and Sutskever, Ilya and Leike, Jan and Wu, Jeffrey},
  journal={arXiv preprint arXiv:2406.04093},
  year={2024}
}

@article{chowdhury2025prompt,
  title={Prompt-CAM: A Simpler Interpretable Transformer for Fine-Grained Analysis},
  author={Chowdhury, Arpita and Paul, Dipanjyoti and Mai, Zheda and Gu, Jianyang and Zhang, Ziheng and Mehrab, Kazi Sajeed and Campolongo, Elizabeth G and Rubenstein, Daniel and Stewart, Charles V and Karpatne, Anuj and others},
  journal={arXiv preprint arXiv:2501.09333},
  year={2025}
}

@inproceedings{paul2024simple,
  title={A simple interpretable transformer for fine-grained image classification and analysis},
  author={Paul, Dipanjyoti and Chowdhury, Arpita and Xiong, Xinqi and Chang, Feng-Ju and Carlyn, David and Stevens, Samuel and Provost, Kaiya L and Karpatne, Anuj and Carstens, Bryan and Rubenstein, Daniel and others},
  booktitle={International Conference on Learning Representations},
  year={2024}
}

@article{zhou2018interpreting,
  title={Interpreting deep visual representations via network dissection},
  author={Zhou, Bolei and Bau, David and Oliva, Aude and Torralba, Antonio},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={41},
  number={9},
  pages={2131--2145},
  year={2018},
  publisher={IEEE}
}

@inproceedings{bau2017broden,
  author={Bau, David and Zhou, Bolei and Khosla, Aditya and Oliva, Aude and Torralba, Antonio},
  booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Network Dissection: Quantifying Interpretability of Deep Visual Representations}, 
  year={2017},
  volume={},
  number={},
  pages={3319-3327},
  keywords={Visualization;Training;Detectors;Image color analysis;Semantics;Image segmentation},
  doi={10.1109/CVPR.2017.354}
}
@inproceedings{hernandez2021natural,
  title={Natural language descriptions of deep visual features},
  author={Hernandez, Evan and Schwettmann, Sarah and Bau, David and Bagashvili, Teona and Torralba, Antonio and Andreas, Jacob},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@inproceedings{kalibhat2023identifying,
  title={Identifying interpretable subspaces in image representations},
  author={Kalibhat, Neha and Bhardwaj, Shweta and Bruss, C Bayan and Firooz, Hamed and Sanjabi, Maziar and Feizi, Soheil},
  booktitle={International Conference on Machine Learning},
  pages={15623--15638},
  year={2023},
  organization={PMLR}
}


@article{bricken2023monosemanticity,
    title={Towards Monosemanticity: Decomposing Language Models With Dictionary Learning},
    author={Bricken, Trenton and Templeton, Adly and Batson, Joshua and Chen, Brian and Jermyn, Adam and Conerly, Tom and Turner, Nick and Anil, Cem and Denison, Carson and Askell, Amanda and Lasenby, Robert and Wu, Yifan and Kravec, Shauna and Schiefer, Nicholas and Maxwell, Tim and Joseph, Nicholas and Hatfield-Dodds, Zac and Tamkin, Alex and Nguyen, Karina and McLean, Brayden and Burke, Josiah E and Hume, Tristan and Carter, Shan and Henighan, Tom and Olah, Christopher},
    year={2023},
    journal={Transformer Circuits Thread},
    note={https://transformer-circuits.pub/2023/monosemantic-features/index.html}
}

@article{templeton2024scaling,
    title={Scaling Monosemanticity: Extracting Interpretable Features from Claude 3 Sonnet},
    author={Templeton, Adly and Conerly, Tom and Marcus, Jonathan and Lindsey, Jack and Bricken, Trenton and Chen, Brian and Pearce, Adam and Citro, Craig and Ameisen, Emmanuel and Jones, Andy and Cunningham, Hoagy and Turner, Nicholas L and McDougall, Callum and MacDiarmid, Monte and Freeman, C. Daniel and Sumers, Theodore R. and Rees, Edward and Batson, Joshua and Jermyn, Adam and Carter, Shan and Olah, Chris and Henighan, Tom},
    year={2024},
    journal={Transformer Circuits Thread},
    url={https://transformer-circuits.pub/2024/scaling-monosemanticity/index.html}
}

@article{jermyn2024ghostgrads,
    title={Ghost Grads: An improvement on resampling},
    author={Jermyn, Adam and Templeton, Adly},
    year={2024},
    journal={Transformer Circuits Thread},
    url={https://transformer-circuits.pub/2024/jan-update/index.html#dict-learning-resampling}
}

@article{alexey2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Alexey, Dosovitskiy},
  journal={arXiv preprint arXiv: 2010.11929},
  year={2020}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@misc{oquab2023dinov2,
  title={DINOv2: Learning Robust Visual Features without Supervision},
  author={Oquab, Maxime and Darcet, Timothée and Moutakanni, Theo and Vo, Huy V. and Szafraniec, Marc and Khalidov, Vasil and Fernandez, Pierre and Haziza, Daniel and Massa, Francisco and El-Nouby, Alaaeldin and Howes, Russell and Huang, Po-Yao and Xu, Hu and Sharma, Vasu and Li, Shang-Wen and Galuba, Wojciech and Rabbat, Mike and Assran, Mido and Ballas, Nicolas and Synnaeve, Gabriel and Misra, Ishan and Jegou, Herve and Mairal, Julien and Labatut, Patrick and Joulin, Armand and Bojanowski, Piotr},
  journal={arXiv:2304.07193},
  year={2023}
}

@misc{darcet2023vitneedreg,
  title={Vision Transformers Need Registers},
  author={Darcet, Timothée and Oquab, Maxime and Mairal, Julien and Bojanowski, Piotr},
  journal={arXiv:2309.16588},
  year={2023}
}



@misc{loshchilov2019decoupledweightdecayregularization,
    title={Decoupled Weight Decay Regularization}, 
    author={Ilya Loshchilov and Frank Hutter},
    year={2019},
    eprint={1711.05101},
    archivePrefix={arXiv},
    primaryClass={cs.LG},
    url={https://arxiv.org/abs/1711.05101}, 
}

@inproceedings{stevens2024bioclip,
  title = {{B}io{CLIP}: A Vision Foundation Model for the Tree of Life}, 
  author = {Samuel Stevens and Jiaman Wu and Matthew J Thompson and Elizabeth G Campolongo and Chan Hee Song and David Edward Carlyn and Li Dong and Wasila M Dahdul and Charles Stewart and Tanya Berger-Wolf and Wei-Lun Chao and Yu Su},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year = {2024},
  pages = {19412-19424}
}

@article{geva2020transformer,
  title={Transformer feed-forward layers are key-value memories},
  author={Geva, Mor and Schuster, Roei and Berant, Jonathan and Levy, Omer},
  journal={arXiv preprint arXiv:2012.14913},
  year={2020}
}

@article{elhage2021mathematical,
   title={A Mathematical Framework for Transformer Circuits},
   author={Elhage, Nelson and Nanda, Neel and Olsson, Catherine and Henighan, Tom and Joseph, Nicholas and Mann, Ben and Askell, Amanda and Bai, Yuntao and Chen, Anna and Conerly, Tom and DasSarma, Nova and Drain, Dawn and Ganguli, Deep and Hatfield-Dodds, Zac and Hernandez, Danny and Jones, Andy and Kernion, Jackson and Lovitt, Liane and Ndousse, Kamal and Amodei, Dario and Brown, Tom and Clark, Jack and Kaplan, Jared and McCandlish, Sam and Olah, Chris},
   year={2021},
   journal={Transformer Circuits Thread},
   note={https://transformer-circuits.pub/2021/framework/index.html}
}

@article{nanda2023progress,
  title={Progress measures for grokking via mechanistic interpretability},
  author={Nanda, Neel and Chan, Lawrence and Lieberum, Tom and Smith, Jess and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2301.05217},
  year={2023}
}


@inproceedings{kingma2015adam,
    title={Adam: A Method for Stochastic Optimization},
    author={Kingma, Diederik P. and Ba, Jimmy},
    booktitle={The Third International Conference on Learning Representations},
    year={2015}
}

@inproceedings{hernandez2022natural,
    title={Natural Language Descriptions of Deep Visual Features},
    author={Hernandez, Evan and Schwettmann, Sarah and Bau, David and Bagashvili, Teona and Torralba, Antonio and Andreas, Jacob},
    booktitle={International Conference on Learning Representations},
    year={2022},
    url={https://arxiv.org/abs/2201.11114}
}
@inproceedings{dehghani2023scaling,
  title={Scaling vision transformers to 22 billion parameters},
  author={Dehghani, Mostafa and Djolonga, Josip and Mustafa, Basil and Padlewski, Piotr and Heek, Jonathan and Gilmer, Justin and Steiner, Andreas Peter and Caron, Mathilde and Geirhos, Robert and Alabdulmohsin, Ibrahim and others},
  booktitle={International Conference on Machine Learning},
  pages={7480--7512},
  year={2023},
  organization={PMLR}
}

@article{ghiasi2022vision,
  title={What do vision transformers learn? a visual exploration},
  author={Ghiasi, Amin and Kazemi, Hamid and Borgnia, Eitan and Reich, Steven and Shu, Manli and Goldblum, Micah and Wilson, Andrew Gordon and Goldstein, Tom},
  journal={arXiv preprint arXiv:2212.06727},
  year={2022}
}

@inproceedings{zhai2022scaling,
  title={Scaling vision transformers},
  author={Zhai, Xiaohua and Kolesnikov, Alexander and Houlsby, Neil and Beyer, Lucas},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={12104--12113},
  year={2022}
}

@article{sun2024eva,
  title={Eva-clip-18b: Scaling clip to 18 billion parameters},
  author={Sun, Quan and Wang, Jinsheng and Yu, Qiying and Cui, Yufeng and Zhang, Fan and Zhang, Xiaosong and Wang, Xinlong},
  journal={arXiv preprint arXiv:2402.04252},
  year={2024}
}


@inproceedings{tishby2015deep,
  title={Deep learning and the information bottleneck principle},
  author={Tishby, Naftali and Zaslavsky, Noga},
  booktitle={2015 ieee information theory workshop (itw)},
  pages={1--5},
  year={2015},
  organization={IEEE}
}

@article{achille2018emergence,
  title={Emergence of invariance and disentanglement in deep representations},
  author={Achille, Alessandro and Soatto, Stefano},
  journal={Journal of Machine Learning Research},
  volume={19},
  number={50},
  pages={1--34},
  year={2018}
}
############### ERROR BELOW #################

@inproceedings{kornblith2019better,
  title={Do better imagenet models transfer better?},
  author={Kornblith, Simon and Shlens, Jonathon and Le, Quoc V},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={2661--2671},
  year={2019}
}

@article{templeton2024update,
    title={Update on Dictionary Learning Improvements},
    author={Templeton, Adly and Conerly, Tom and Marcus, Jonathan and Henighan, Tom},
    year={2024},
    journal={Transformer Circuits Thread},
    url={https://transformer-circuits.pub/2024/march-update/index.html\#dl-update}
}

@inproceedings{zhou2017ade20k,
  title={Scene parsing through ade20k dataset},
  author={Zhou, Bolei and Zhao, Hang and Puig, Xavier and Fidler, Sanja and Barriuso, Adela and Torralba, Antonio},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={633--641},
  year={2017}
}

################## ERROR ABOVE ###################





@article{rajamanoharan2024improving,
  title={Improving dictionary learning with gated sparse autoencoders},
  author={Rajamanoharan, Senthooran and Conmy, Arthur and Smith, Lewis and Lieberum, Tom and Varma, Vikrant and Kram{\'a}r, J{\'a}nos and Shah, Rohin and Nanda, Neel},
  journal={arXiv preprint arXiv:2404.16014},
  year={2024}
}

@article{rajamanoharan2024jumping,
  title={Jumping ahead: Improving reconstruction fidelity with jumprelu sparse autoencoders},
  author={Rajamanoharan, Senthooran and Lieberum, Tom and Sonnerat, Nicolas and Conmy, Arthur and Varma, Vikrant and Kram{\'a}r, J{\'a}nos and Nanda, Neel},
  journal={arXiv preprint arXiv:2407.14435},
  year={2024}
}


@article{elhage2022toy,
  title={Toy models of superposition},
  author={Elhage, Nelson and Hume, Tristan and Olsson, Catherine and Schiefer, Nicholas and Henighan, Tom and Kravec, Shauna and Hatfield-Dodds, Zac and Lasenby, Robert and Drain, Dawn and Chen, Carol and others},
  journal={arXiv preprint arXiv:2209.10652},
  year={2022}
}

@article{fei2006caltech,
  title={One-shot learning of object categories},
  author={Fei-Fei, Li and Fergus, Robert and Perona, Pietro},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={28},
  number={4},
  pages={594--611},
  year={2006},
  publisher={IEEE}
}


#---------------#
# Model Editing #
#---------------#

# ROME
@article{meng2022rome,
  title={Locating and editing factual associations in GPT},
  author={Meng, Kevin and Bau, David and Andonian, Alex and Belinkov, Yonatan},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={17359--17372},
  year={2022}
}

@inproceedings{meng2023memit,
    title={Mass-Editing Memory in a Transformer},
    author={Kevin Meng and Arnab Sen Sharma and Alex J Andonian and Yonatan Belinkov and David Bau},
    booktitle={The Eleventh International Conference on Learning Representations },
    year={2023},
    url={https://openreview.net/forum?id=MkbcAHIYgyS}
}

#---------------#
# Model Control #
#---------------#

@article{szegedy2013intriguing,
  title={Intriguing properties of neural networks},
  author={Szegedy, C},
  journal={arXiv preprint arXiv:1312.6199},
  year={2013}
}

@article{goodfellow2014explaining,
  title={Explaining and harnessing adversarial examples},
  author={Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian},
  journal={arXiv preprint arXiv:1412.6572},
  year={2014}
}

@inproceedings{moosavi2016deepfool,
  title={Deepfool: a simple and accurate method to fool deep neural networks},
  author={Moosavi-Dezfooli, Seyed-Mohsen and Fawzi, Alhussein and Frossard, Pascal},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2574--2582},
  year={2016}
}

@inproceedings{moosavi2017universal,
  title={Universal adversarial perturbations},
  author={Moosavi-Dezfooli, Seyed-Mohsen and Fawzi, Alhussein and Fawzi, Omar and Frossard, Pascal},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1765--1773},
  year={2017}
}

@article{elsayed2018adversarial,
  title={Adversarial reprogramming of neural networks},
  author={Elsayed, Gamaleldin F and Goodfellow, Ian and Sohl-Dickstein, Jascha},
  journal={arXiv preprint arXiv:1806.11146},
  year={2018}
}


@article{ilyas2019adversarial,
  title={Adversarial examples are not bugs, they are features},
  author={Ilyas, Andrew and Santurkar, Shibani and Tsipras, Dimitris and Engstrom, Logan and Tran, Brandon and Madry, Aleksander},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@inproceedings{jia2022visual,
  title={Visual prompt tuning},
  author={Jia, Menglin and Tang, Luming and Chen, Bor-Chun and Cardie, Claire and Belongie, Serge and Hariharan, Bharath and Lim, Ser-Nam},
  booktitle={European Conference on Computer Vision},
  pages={709--727},
  year={2022},
  organization={Springer}
}


#----------------------------------------------#
#                 Vision Models 
#----------------------------------------------#

# U-Net
@inproceedings{ronneberger2015u,
  title={U-net: Convolutional networks for biomedical image segmentation},
  author={Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  booktitle={Medical image computing and computer-assisted intervention--MICCAI 2015: 18th international conference, Munich, Germany, October 5-9, 2015, proceedings, part III 18},
  pages={234--241},
  year={2015},
  organization={Springer}
}

# MAE ViT
@inproceedings{he2022masked,
  title={Masked autoencoders are scalable vision learners},
  author={He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={16000--16009},
  year={2022}
}

@inproceedings{le2013building,
  title={Building high-level features using large scale unsupervised learning},
  author={Le, Quoc V},
  booktitle={2013 IEEE international conference on acoustics, speech and signal processing},
  pages={8595--8598},
  year={2013},
  organization={IEEE}
}


#---------------------------#
# SAEs for Other Modalities #
#---------------------------#

@article{lim2024sparse,
  title={Sparse autoencoders reveal selective remapping of visual concepts during adaptation},
  author={Lim, Hyesu and Choi, Jinho and Choo, Jaegul and Schneider, Steffen},
  journal={arXiv preprint arXiv:2412.05276},
  year={2024}
}
@misc{thasarathan2025universal,
  title={Universal Sparse Autoencoders: Interpretable Cross-Model Concept Alignment}, 
  author={Harrish Thasarathan and Julian Forsyth and Thomas Fel and Matthew Kowal and Konstantinos Derpanis},
  year={2025},
  eprint={2502.03714},
  archivePrefix={arXiv},
  primaryClass={cs.CV},
  url={https://arxiv.org/abs/2502.03714}, 
}

@article{simon2024interplm,
  title={InterPLM: Discovering Interpretable Features in Protein Language Models via Sparse Autoencoders},
  author={Simon, Elana and Zou, James},
  journal={bioRxiv},
  pages={2024--11},
  year={2024},
  publisher={Cold Spring Harbor Laboratory}
}


#----------------------------------------------#
#       Interpretability / Explainability
#----------------------------------------------#

# Feature visualization

@article{simonyan2013deep,
  title={Deep inside convolutional networks: Visualising image classification models and saliency maps},
  author={Simonyan, Karen},
  journal={arXiv preprint arXiv:1312.6034},
  year={2013}
}
@inproceedings{zeiler2014visualizing,
  title={Visualizing and Understanding Convolutional Networks},
  author={Zeiler, MD},
  booktitle={European conference on computer vision/arXiv},
  volume={1311},
  year={2014}
}
@article{mordvintsev2015inceptionism,
  title={Inceptionism: Going deeper into neural networks},
  author={Mordvintsev, Alexander and Olah, Christopher and Tyka, Mike},
  journal={Google research blog},
  volume={20},
  number={14},
  pages={5},
  year={2015}
}
@article{olah2017feature,
  author = {Olah, Chris and Mordvintsev, Alexander and Schubert, Ludwig},
  title = {Feature Visualization},
  journal = {Distill},
  year = {2017},
  note = {https://distill.pub/2017/feature-visualization},
  doi = {10.23915/distill.00007}
}
@article{olah2018building,
  author = {Olah, Chris and Satyanarayan, Arvind and Johnson, Ian and Carter, Shan and Schubert, Ludwig and Ye, Katherine and Mordvintsev, Alexander},
  title = {The Building Blocks of Interpretability},
  journal = {Distill},
  year = {2018},
  note = {https://distill.pub/2018/building-blocks},
  doi = {10.23915/distill.00010}
}
@article{mordvintsev2015deepdream,
  title={Deepdream-a code example for visualizing neural networks},
  author={Mordvintsev, Alexander and Olah, Christopher and Tyka, Mike},
  journal={Google Research},
  volume={2},
  number={5},
  year={2015}
}

@article{erhan2009visualizing,
  title={Visualizing higher-layer features of a deep network},
  author={Erhan, Dumitru and Bengio, Yoshua and Courville, Aaron and Vincent, Pascal},
  journal={University of Montreal},
  volume={1341},
  number={3},
  pages={1},
  year={2009}
}


# CAM
@inproceedings{zhou2016learning,
  title={Learning deep features for discriminative localization},
  author={Zhou, Bolei and Khosla, Aditya and Lapedriza, Agata and Oliva, Aude and Torralba, Antonio},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2921--2929},
  year={2016}
}

# Grad-CAM
@inproceedings{selvaraju2017grad,
  title={Grad-cam: Visual explanations from deep networks via gradient-based localization},
  author={Selvaraju, Ramprasaath R and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={618--626},
  year={2017}
}
# DeepLIFT
@inproceedings{shrikumar2017deeplift,
  title={Learning important features through propagating activation differences},
  author={Shrikumar, Avanti and Greenside, Peyton and Kundaje, Anshul},
  booktitle={International conference on machine learning},
  pages={3145--3153},
  year={2017},
  organization={PMlR}
}
@inproceedings{sundararajan2017axiomatic,
  title={Axiomatic attribution for deep networks},
  author={Sundararajan, Mukund and Taly, Ankur and Yan, Qiqi},
  booktitle={International conference on machine learning},
  pages={3319--3328},
  year={2017},
  organization={PMLR}
}
@inproceedings{chefer2021transformer,
  title={Transformer interpretability beyond attention visualization},
  author={Chefer, Hila and Gur, Shir and Wolf, Lior},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={782--791},
  year={2021}
}

@inproceedings{geirhos2024dont,
    title={Don't trust your eyes: on the (un)reliability of feature visualizations},
    author={Robert Geirhos and Roland S. Zimmermann and Blair Bilodeau and Wieland Brendel and Been Kim},
    booktitle={Forty-first International Conference on Machine Learning},
    year={2024},
    url={https://openreview.net/forum?id=s0Jvdolv2I}
}

# TCAV
@inproceedings{kim2018tcav,
  title={Interpretability beyond feature attribution: Quantitative testing with concept activation vectors (tcav)},
  author={Kim, Been and Wattenberg, Martin and Gilmer, Justin and Cai, Carrie and Wexler, James and Viegas, Fernanda and others},
  booktitle={International conference on machine learning},
  pages={2668--2677},
  year={2018},
  organization={PMLR}
}

# Concept bottleneck models

@InProceedings{koh2020concept,
  title = 	 {Concept Bottleneck Models},
  author =       {Koh, Pang Wei and Nguyen, Thao and Tang, Yew Siang and Mussmann, Stephen and Pierson, Emma and Kim, Been and Liang, Percy},
  booktitle = 	 {Proceedings of the 37th International Conference on Machine Learning},
  pages = 	 {5338--5348},
  year = 	 {2020},
  editor = 	 {III, Hal Daumé and Singh, Aarti},
  volume = 	 {119},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {13--18 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v119/koh20a/koh20a.pdf},
  url = 	 {https://proceedings.mlr.press/v119/koh20a.html},
}
@inproceedings{yuksekgonul2023posthoc,
title={Post-hoc Concept Bottleneck Models},
author={Mert Yuksekgonul and Maggie Wang and James Zou},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=nA5AZ8CEyow}
}

@article{schrodi2024concept,
  title={Concept Bottleneck Models Without Predefined Concepts},
  author={Schrodi, Simon and Schur, Julian and Argus, Max and Brox, Thomas},
  journal={arXiv preprint arXiv:2407.03921},
  year={2024}
}
@inproceedings{tan2024explain,
  title={Explain via any concept: Concept bottleneck model with open vocabulary concepts},
  author={Tan, Andong and Zhou, Fengtao and Chen, Hao},
  booktitle={European Conference on Computer Vision},
  pages={123--138},
  year={2024},
  organization={Springer}
}





@InProceedings{goyal2019counterfactual,
  title = 	 {Counterfactual Visual Explanations},
  author =       {Goyal, Yash and Wu, Ziyan and Ernst, Jan and Batra, Dhruv and Parikh, Devi and Lee, Stefan},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {2376--2384},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--15 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v97/goyal19a/goyal19a.pdf},
  url = 	 {https://proceedings.mlr.press/v97/goyal19a.html},
}

@inproceedings{ghorbani2019towards,
 author = {Ghorbani, Amirata and Wexler, James and Zou, James Y and Kim, Been},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Towards Automatic Concept-based Explanations},
 url = {https://proceedings.neurips.cc/paper_files/paper/2019/file/77d2afcb31f6493e350fca61764efb9a-Paper.pdf},
 volume = {32},
 year = {2019}
}



# Proto-P-Net
@article{chen2019looks,
  title={This looks like that: deep learning for interpretable image recognition},
  author={Chen, Chaofan and Li, Oscar and Tao, Daniel and Barnett, Alina and Rudin, Cynthia and Su, Jonathan K},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}
@inbook{nauta2021looks,
   title={This Looks Like That, Because ... Explaining Prototypes for Interpretable Image Recognition},
   ISBN={9783030937362},
   ISSN={1865-0937},
   url={http://dx.doi.org/10.1007/978-3-030-93736-2_34},
   DOI={10.1007/978-3-030-93736-2_34},
   booktitle={Machine Learning and Principles and Practice of Knowledge Discovery in Databases},
   publisher={Springer International Publishing},
   author={Nauta, Meike and Jutte, Annemarie and Provoost, Jesper and Seifert, Christin},
   year={2021},
   pages={441–456}
}
@InProceedings{donnelly2022deformable,
    author    = {Donnelly, Jon and Barnett, Alina Jade and Chen, Chaofan},
    title     = {Deformable ProtoPNet: An Interpretable Image Classifier Using Deformable Prototypes},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2022},
    pages     = {10265-10275}
}
@article{willard2024looks,
  title={This looks better than that: Better interpretable models with protopnext},
  author={Willard, Frank and Moffett, Luke and Mokel, Emmanuel and Donnelly, Jon and Guo, Stark and Yang, Julia and Kim, Giyoung and Barnett, Alina Jade and Rudin, Cynthia},
  journal={arXiv preprint arXiv:2406.14675},
  year={2024}
}

# PURE
@InProceedings{dreyer2024pure,
    author    = {Dreyer, Maximilian and Purelku, Erblina and Vielhaben, Johanna and Samek, Wojciech and Lapuschkin, Sebastian},
    title     = {PURE: Turning Polysemantic Neurons Into Pure Features by Identifying Relevant Circuits},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
    month     = {June},
    year      = {2024},
    pages     = {8212-8217}
}


@inproceedings{le2013building,
  title={Building high-level features using large scale unsupervised learning},
  author={Le, Quoc V},
  booktitle={2013 IEEE international conference on acoustics, speech and signal processing},
  pages={8595--8598},
  year={2013},
  organization={IEEE}
}



# ---- #
# VLMS #
# ---- #

@article{tong2024cambrian,
  title={Cambrian-1: A fully open, vision-centric exploration of multimodal llms},
  author={Tong, Shengbang and Brown, Ellis and Wu, Penghao and Woo, Sanghyun and Middepogu, Manoj and Akula, Sai Charitha and Yang, Jihan and Yang, Shusheng and Iyer, Adithya and Pan, Xichen and others},
  journal={arXiv preprint arXiv:2406.16860},
  year={2024}
}

@inproceedings{tong2024eyes,
  title={Eyes wide shut? exploring the visual shortcomings of multimodal llms},
  author={Tong, Shengbang and Liu, Zhuang and Zhai, Yuexiang and Ma, Yi and LeCun, Yann and Xie, Saining},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9568--9578},
  year={2024}
}

@article{jiang2023clip,
  title={From clip to dino: Visual encoders shout in multi-modal large language models},
  author={Jiang, Dongsheng and Liu, Yuchen and Liu, Songlin and Zhao, Jin'e and Zhang, Hao and Gao, Zhen and Zhang, Xiaopeng and Li, Jin and Xiong, Hongkai},
  journal={arXiv preprint arXiv:2310.08825},
  year={2023}
}

@inproceedings{liu2024llava1_5,
  title={Improved baselines with visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Li, Yuheng and Lee, Yong Jae},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={26296--26306},
  year={2024}
}

@article{liu2024llava,
  title={Visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
  journal={Advances in neural information processing systems},
  volume={36},
  year={2024}
}


@article{lu2024deepseek_vl,
  title={Deepseek-vl: towards real-world vision-language understanding},
  author={Lu, Haoyu and Liu, Wen and Zhang, Bo and Wang, Bingxuan and Dong, Kai and Liu, Bo and Sun, Jingxiang and Ren, Tongzheng and Li, Zhuoshu and Yang, Hao and others},
  journal={arXiv preprint arXiv:2403.05525},
  year={2024}
}


@article{grant2006evolution,
  title={Evolution of character displacement in {D}arwin's finches},
  author={Grant, Peter R and Grant, B Rosemary},
  journal={Science},
  volume={313},
  number={5784},
  pages={224--226},
  year={2006},
  publisher={American Association for the Advancement of Science}
}

@book{losos2011lizards,
  title={Lizards in an evolutionary tree: ecology and adaptive radiation of anoles},
  author={Losos, Jonathan B},
  volume={10},
  year={2011},
  publisher={Univ of California Press}
}

@article{brawand2014genomic,
  title={The genomic substrate for adaptive radiation in African cichlid fish},
  author={Brawand, David and Wagner, Catherine E and Li, Yang I and Malinsky, Milan and Keller, Irene and Fan, Shaohua and Simakov, Oleg and Ng, Alvin Y and Lim, Zhi Wei and Bezault, Etienne and others},
  journal={Nature},
  volume={513},
  number={7518},
  pages={375--381},
  year={2014},
  publisher={Nature Publishing Group UK London}
}


# Datasets #
#----------#

@techreport{wah2011cub,
	title={Caltech-UCSD Birds-200-2011},
	author={Wah, C. and Branson, S. and Welinder, P. and Perona, P. and Belongie, S.},
	year={2011},
	institution={California Institute of Technology},
	number={CNS-TR-2011-001}
}

@article{russakovsky2015imagenet,
  title={Imagenet large scale visual recognition challenge},
  author={Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and others},
  journal={International journal of computer vision},
  volume={115},
  pages={211--252},
  year={2015},
  publisher={Springer}
}

@inproceedings{van2021inat21,
  title={Benchmarking representation learning for natural world image collections},
  author={Van Horn, Grant and Cole, Elijah and Beery, Sara and Wilber, Kimberly and Belongie, Serge and Mac Aodha, Oisin},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={12884--12893},
  year={2021}
}


@article{loshchilov2017adamw,
  title={Decoupled weight decay regularization},
  author={Loshchilov, I},
  journal={arXiv preprint arXiv:1711.05101},
  year={2017}
}
