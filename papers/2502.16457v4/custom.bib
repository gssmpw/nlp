@article{olivetti2020data,
  title={Data-driven materials research enabled by natural language processing and information extraction},
  author={Olivetti, Elsa A and Cole, Jacqueline M and Kim, Edward and Kononova, Olga and Ceder, Gerbrand and Han, Thomas Yong-Jin and Hiszpanski, Anna M},
  journal={Applied Physics Reviews},
  volume={7},
  number={4},
  year={2020},
  publisher={AIP Publishing}
}
@article{song2023matsci,
  title={Matsci-nlp: Evaluating scientific language models on materials science language tasks using text-to-schema modeling},
  author={Song, Yu and Miret, Santiago and Liu, Bang},
  journal={arXiv preprint arXiv:2305.08264},
  year={2023}
}

@article{dunn2020benchmarking,
  title={Benchmarking materials property prediction methods: the Matbench test set and Automatminer reference algorithm},
  author={Dunn, Alexander and Wang, Qi and Ganose, Alex and Dopp, Daniel and Jain, Anubhav},
  journal={npj Computational Materials},
  volume={6},
  number={1},
  pages={138},
  year={2020},
  publisher={Nature Publishing Group UK London}
}
@article{polak2024extracting,
  title={Extracting accurate materials data from research papers with conversational language models and prompt engineering},
  author={Polak, Maciej P and Morgan, Dane},
  journal={Nature Communications},
  volume={15},
  number={1},
  pages={1569},
  year={2024},
  publisher={Nature Publishing Group UK London}
}
@article{sun2025critical,
  title={A critical reflection on attempts to machine-learn materials synthesis insights from text-mined literature recipes},
  author={Sun, Wenhao and David, Nicholas},
  journal={Faraday Discussions},
  year={2025},
  publisher={Royal Society of Chemistry}
}

@article{huang2023application,
  title={Application of machine learning in material synthesis and property prediction},
  author={Huang, Guannan and Guo, Yani and Chen, Ye and Nie, Zhengwei},
  journal={Materials},
  volume={16},
  number={17},
  pages={5977},
  year={2023},
  publisher={MDPI}
}
@article{merchant2023scaling,
  title={Scaling deep learning for materials discovery},
  author={Merchant, Amil and Batzner, Simon and Schoenholz, Samuel S and Aykol, Muratahan and Cheon, Gowoon and Cubuk, Ekin Dogus},
  journal={Nature},
  volume={624},
  number={7990},
  pages={80--85},
  year={2023},
  publisher={Nature Publishing Group UK London}
}

@article{szymanski2023autonomous,
  title={An autonomous laboratory for the accelerated synthesis of novel materials},
  author={Szymanski, Nathan J and Rendy, Bernardus and Fei, Yuxing and Kumar, Rishi E and He, Tanjin and Milsted, David and McDermott, Matthew J and Gallant, Max and Cubuk, Ekin Dogus and Merchant, Amil and others},
  journal={Nature},
  volume={624},
  number={7990},
  pages={86--91},
  year={2023},
  publisher={Nature Publishing Group UK London}
}
@article{gupta2022matscibert,
  title={MatSciBERT: A materials domain language model for text mining and information extraction},
  author={Gupta, Tanishq and Zaki, Mohd and Krishnan, NM Anoop and Mausam},
  journal={npj Computational Materials},
  volume={8},
  number={1},
  pages={102},
  year={2022},
  publisher={Nature Publishing Group UK London}
}
@article{song2023honeybee,
  title={Honeybee: Progressive instruction finetuning of large language models for materials science},
  author={Song, Yu and Miret, Santiago and Zhang, Huan and Liu, Bang},
  journal={arXiv preprint arXiv:2310.08511},
  year={2023}
}
@article{na2023artificial,
  title={Artificial intelligence for learning material synthesis processes of thermoelectric materials},
  author={Na, Gyoung S},
  journal={Chemistry of Materials},
  volume={35},
  number={19},
  pages={8272--8280},
  year={2023},
  publisher={ACS Publications}
}
@misc{semanticscholar2023,
    title={Semantic Scholar Academic Graph API},
    author={{Semantic Scholar}},
    year={2023},
    howpublished={\url{https://www.semanticscholar.org/product/api}},
    note={Accessed: January 2025}
}
@software{pymupdf4llm2024,
    title={PyMuPDF4LLM: PDF Text Extraction Library for LLM Applications},
    author={{Artifex Software}},
    year={2024},
    howpublished={\url{https://github.com/artifex-com/pymupdf4llm}},
    note={Accessed: January 2024}
}

@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@article{luo2024large,
  title={Large language models surpass human experts in predicting neuroscience results},
  author={Luo, Xiaoliang and Rechardt, Akilles and Sun, Guangzhi and Nejad, Kevin K and Y{\'a}{\~n}ez, Felipe and Yilmaz, Bati and Lee, Kangjoo and Cohen, Alexandra O and Borghesani, Valentina and Pashkov, Anton and others},
  journal={Nature human behaviour},
  pages={1--11},
  year={2024},
  publisher={Nature Publishing Group UK London}
}

@article{lei2024materials,
  title={Materials science in the era of large language models: a perspective},
  author={Lei, Ge and Docherty, Ronan and Cooper, Samuel J},
  journal={Digital Discovery},
  year={2024},
  publisher={Royal Society of Chemistry}
}
@article{kim2024large,
  title={Large language models for inorganic synthesis predictions},
  author={Kim, Seongmin and Jung, Yousung and Schrier, Joshua},
  journal={Journal of the American Chemical Society},
  volume={146},
  number={29},
  pages={19654--19659},
  year={2024},
  publisher={ACS Publications}
}
@article{jia2024llmatdesign,
  title={LLMatDesign: Autonomous Materials Discovery with Large Language Models},
  author={Jia, Shuyi and Zhang, Chao and Fung, Victor},
  journal={arXiv preprint arXiv:2406.13163},
  year={2024}
}
@article{yanguas2024benchmarking,
  title={Benchmarking large language models for materials synthesis: the case of atomic layer deposition},
  author={Yanguas-Gil, Angel and Dearing, Matthew T and Elam, Jeffrey W and Jones, Jessica C and Kim, Sungjoon and Mohammad, Adnan and Nguyen, Chi Thang and Sengupta, Bratin},
  journal={arXiv preprint arXiv:2412.10477},
  year={2024}
}
@article{kononova2019text,
  title={Text-mined dataset of inorganic materials synthesis recipes},
  author={Kononova, Olga and Huo, Haoyan and He, Tanjin and Rong, Ziqin and Botari, Tiago and Sun, Wenhao and Tshitoyan, Vahe and Ceder, Gerbrand},
  journal={Scientific data},
  volume={6},
  number={1},
  pages={203},
  year={2019},
  publisher={Nature Publishing Group UK London}
}
@article{wang2022dataset,
  title={Dataset of solution-based inorganic materials synthesis procedures extracted from the scientific literature},
  author={Wang, Zheren and Kononova, Olga and Cruse, Kevin and He, Tanjin and Huo, Haoyan and Fei, Yuxing and Zeng, Yan and Sun, Yingzhi and Cai, Zijian and Sun, Wenhao and others},
  journal={Scientific data},
  volume={9},
  number={1},
  pages={231},
  year={2022},
  publisher={Nature Publishing Group UK London}
}
@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

@misc{OpenAIEmbeedings2022,
	author = {OpenAI},
	title = {{I}ntroducing text and code embeddings},
	howpublished = {\url{https://openai.com/index/introducing-text-and-code-embeddings/}},
	year = {2022},
	note = {[Accessed 11-02-2025]},
}

@article{lewis2020retrieval,
  title={Retrieval-augmented generation for knowledge-intensive nlp tasks},
  author={Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and K{\"u}ttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rockt{\"a}schel, Tim and others},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={9459--9474},
  year={2020}
}

@article{mcgraw1996forming,
  title={Forming inferences about some intraclass correlation coefficients.},
  author={McGraw, Kenneth O and Wong, Seok P},
  journal={Psychological methods},
  volume={1},
  number={1},
  pages={30},
  year={1996},
  publisher={American Psychological Association}
}

@article{spearman1904proof,
  title={The proof and measurement of association between two things},
  author={Spearman, Charles},
  journal={The American Journal of Psychology},
  volume={15},
  number={1},
  pages={72--101},
  year={1904},
  publisher={University of Illinois Press}
}

@article{pearson1896mathematical,
  title={VII. Mathematical contributions to the theory of evolution. III. Regression, heredity, and panmixia},
  author={Pearson, Karl},
  journal={Philosophical Transactions of the Royal Society of London. A},
  volume={187},
  pages={253--318},
  year={1896},
  publisher={The Royal Society},
  doi={10.1098/rsta.1896.0007}
}

@misc{kumbhar2025hypothesisgenerationmaterialsdiscovery,
      title={Hypothesis Generation for Materials Discovery and Design Using Goal-Driven and Constraint-Guided LLM Agents}, 
      author={Shrinidhi Kumbhar and Venkatesh Mishra and Kevin Coutinho and Divij Handa and Ashif Iquebal and Chitta Baral},
      year={2025},
      eprint={2501.13299},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2501.13299}, 
}

@misc{rubungo2023llmproppredictingphysicalelectronic,
      title={LLM-Prop: Predicting Physical And Electronic Properties Of Crystalline Solids From Their Text Descriptions}, 
      author={Andre Niyongabo Rubungo and Craig Arnold and Barry P. Rand and Adji Bousso Dieng},
      year={2023},
      eprint={2310.14029},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2310.14029}, 
}
@misc{chiang2024llamplargelanguagemodel,
      title={LLaMP: Large Language Model Made Powerful for High-fidelity Materials Knowledge Retrieval and Distillation}, 
      author={Yuan Chiang and Elvis Hsieh and Chia-Hong Chou and Janosh Riebesell},
      year={2024},
      eprint={2401.17244},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2401.17244}, 
}
@inproceedings{mishra2024llamat,
  title={LLaMat: Large Language Models for Materials Science},
  author={Mishra, Vaibhav and Singh, Somaditya and Zaki, Mohd and Grover, Hargun Singh and Miret, Santiago and Krishnan, NM Anoop and others},
  booktitle={AI for Accelerated Materials Design-Vienna 2024}
}
@inproceedings{papineni2002bleu,
  title={Bleu: a method for automatic evaluation of machine translation},
  author={Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
  booktitle={Proceedings of the 40th annual meeting of the Association for Computational Linguistics},
  pages={311--318},
  year={2002}
}
@inproceedings{lin2004rouge,
  title={Rouge: A package for automatic evaluation of summaries},
  author={Lin, Chin-Yew},
  booktitle={Text summarization branches out},
  pages={74--81},
  year={2004}
}
@misc{gu2025surveyllmasajudge,
      title={A Survey on LLM-as-a-Judge}, 
      author={Jiawei Gu and Xuhui Jiang and Zhichao Shi and Hexiang Tan and Xuehao Zhai and Chengjin Xu and Wei Li and Yinghan Shen and Shengjie Ma and Honghao Liu and Saizhuo Wang and Kun Zhang and Yuanzhuo Wang and Wen Gao and Lionel Ni and Jian Guo},
      year={2025},
      eprint={2411.15594},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2411.15594}, 
}
@article{zhang2019bertscore,
  title={Bertscore: Evaluating text generation with bert},
  author={Zhang, Tianyi and Kishore, Varsha and Wu, Felix and Weinberger, Kilian Q and Artzi, Yoav},
  journal={arXiv preprint arXiv:1904.09675},
  year={2019}
}
@article{mikolov2013efficient,
  title={Efficient estimation of word representations in vector space},
  author={Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  journal={arXiv preprint arXiv:1301.3781},
  year={2013}
}
@article{shrout1979intraclass,
  title={Intraclass correlations: uses in assessing rater reliability.},
  author={Shrout, Patrick E and Fleiss, Joseph L},
  journal={Psychological bulletin},
  volume={86},
  number={2},
  pages={420},
  year={1979},
  publisher={American Psychological Association}
}
@article{himanen2019data,
  title={Data-driven materials science: status, challenges, and perspectives},
  author={Himanen, Lauri and Geurts, Amber and Foster, Adam Stuart and Rinke, Patrick},
  journal={Advanced Science},
  volume={6},
  number={21},
  pages={1900808},
  year={2019},
  publisher={Wiley Online Library}
}
@article{xu2023small,
  title={Small data machine learning in materials science},
  author={Xu, Pengcheng and Ji, Xiaobo and Li, Minjie and Lu, Wencong},
  journal={npj Computational Materials},
  volume={9},
  number={1},
  pages={42},
  year={2023},
  publisher={Nature Publishing Group UK London}
}
@techreport{authorsalliance2024tdm,
  title = {Text and Data Mining Under U.S. Copyright Law: Landscape, Flaws \& Recommendations},
  author = {{Authors Alliance}},
  year = {2024},
  url = {https://www.authorsalliance.org/wp-content/uploads/2024/11/Text-and-Data-Mining-Report-102024.pdf}
}

@article{douze2024faiss,
      title={The Faiss library},
      author={Matthijs Douze and Alexandr Guzhva and Chengqi Deng and Jeff Johnson and Gergely Szilvasy and Pierre-Emmanuel Mazaré and Maria Lomeli and Lucas Hosseini and Hervé Jégou},
      year={2024},
      eprint={2401.08281},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{litellm,
  author = {BerriAI},
  title = {LiteLLM},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/BerriAI/litellm}},
  commit = {0ffd99afff449b9e79c5f5316bf14fe011eb98df}
}

@inproceedings{lhoest-etal-2021-datasets,
    title = "Datasets: A Community Library for Natural Language Processing",
    author = "Lhoest, Quentin  and
      Villanova del Moral, Albert  and
      Jernite, Yacine  and
      Thakur, Abhishek  and
      von Platen, Patrick  and
      Patil, Suraj  and
      Chaumond, Julien  and
      Drame, Mariama  and
      Plu, Julien  and
      Tunstall, Lewis  and
      Davison, Joe  and
      {\v{S}}a{\v{s}}ko, Mario  and
      Chhablani, Gunjan  and
      Malik, Bhavitvya  and
      Brandeis, Simon  and
      Le Scao, Teven  and
      Sanh, Victor  and
      Xu, Canwen  and
      Patry, Nicolas  and
      McMillan-Major, Angelina  and
      Schmid, Philipp  and
      Gugger, Sylvain  and
      Delangue, Cl{\'e}ment  and
      Matussi{\`e}re, Th{\'e}o  and
      Debut, Lysandre  and
      Bekman, Stas  and
      Cistac, Pierric  and
      Goehringer, Thibault  and
      Mustar, Victor  and
      Lagunas, Fran{\c{c}}ois  and
      Rush, Alexander  and
      Wolf, Thomas",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-demo.21",
    pages = "175--184",
    abstract = "The scale, variety, and quantity of publicly-available NLP datasets has grown rapidly as researchers propose new tasks, larger models, and novel benchmarks. Datasets is a community library for contemporary NLP designed to support this ecosystem. Datasets aims to standardize end-user interfaces, versioning, and documentation, while providing a lightweight front-end that behaves similarly for small datasets as for internet-scale corpora. The design of the library incorporates a distributed, community-driven approach to adding datasets and documenting usage. After a year of development, the library now includes more than 650 unique datasets, has more than 250 contributors, and has helped support a variety of novel cross-dataset research projects and shared tasks. The library is available at https://github.com/huggingface/datasets.",
    eprint={2109.02846},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
}
@article{zhao2020synthesis,
  title={Synthesis of a three-dimensional cross-linked Ni--V 2 O 5 nanomaterial in an ionic liquid for lithium-ion batteries},
  author={Zhao, Yu and Gao, Dongru and Guan, Ruxin and Li, Hongwei and Li, Ning and Li, Guixian and Li, Shiyou},
  journal={RSC advances},
  volume={10},
  number={64},
  pages={39137--39145},
  year={2020},
  publisher={Royal Society of Chemistry}
}
@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}
@article{anisuzzaman2025fine,
  title={Fine-Tuning Large Language Models for Specialized Use Cases},
  author={Anisuzzaman, DM and Malins, Jeffrey G and Friedman, Paul A and Attia, Zachi I},
  journal={Mayo Clinic Proceedings: Digital Health},
  volume={3},
  number={1},
  year={2025},
  publisher={Elsevier}
}