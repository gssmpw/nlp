\section{Data Collection and Preparation}
\label{sec:data_collection}

\subsection{Motivation}
\label{subsec:motivation}

Prior attempts to extract synthesis procedures from materials science literature~\cite{kononova2019text,wang2022dataset} suffer from three critical limitations. First, keyword-based and Word2Vec-driven~\cite{mikolov2013efficient} methods introduce excessive noise, making over \textbf{92\%} of \citeauthor{kononova2019text} and \textbf{98\%} of \citeauthor{wang2022dataset} lack necessary synthesis parameters (e.g., heating temperature, duration, mixing conditions). This issue is particularly severe in solution-based synthesis, where multi-step dependencies lead to incomplete extractions. Second, existing datasets are constrained to a few synthesis techniques (solid-state, solution-based, sol-gel), limiting generalizability. Third, commercial journal restrictions prevent dataset sharing, impeding open-access research.

To address these challenges, we introduce three key innovations:  
1) LLM-driven parsing with GPT-4o for high-accuracy extraction,  
2) A broad synthesis method collection covering ten synthesis techniques,  
3) Exclusive use of open-access sources, ensuring legal dataset distribution.  

\subsection{Collection and Extraction}
\label{subsec:collection_extraction}

Our pipeline retrieves 28,685 open-access articles from the 400K searched articles using the Semantic Scholar API~\cite{semanticscholar2023}, employing 50 expert-selected domain-specific search terms (e.g., “sol-gel synthesis”, “thin film deposition”). PDFs are converted into structured Markdown using \texttt{PyMuPDFLLM}~\cite{pymupdf4llm2024}, preserving paragraph structures and metadata.

We employ GPT-4o~\cite{achiam2023gpt} for multi-stage annotation:
\begin{itemize}
    \item Document categorization: Identifies articles with synthesis procedures and classifies them by material type, synthesis route, and application domain.
    \item Recipe segmentation: Extracts five critical components from each identified article:
    \begin{enumerate}
        \item \textbf{X}: Target material, synthesis method, and application summary.
        \item \(\mathbf{Y_M}\): Raw materials with quantitative details.
        \item \(\mathbf{Y_E}\): Equipment specifications.
        \item \(\mathbf{Y_P}\): Step-by-step procedures.
        \item \(\mathbf{Y_C}\): Characterization methods/results.
    \end{enumerate}
\end{itemize}

Figure~\ref{fig:data-example} presents an example of an extracted synthesis recipe.

\begin{figure*}[!ht]
    \begin{subfigure}{.55\textwidth}
        \centering
        \includegraphics[width=\linewidth]{image/data/element_freq_heatmap.png}
        \caption{Distribution of synthesized elements in the dataset}
        \label{fig:data-element-distribution}
    \end{subfigure}
    \begin{subfigure}{.43\textwidth}
        \centering
        \includegraphics[width=\linewidth]{image/data/top10process.png}
        \caption{Diversity of synthesis methods covered}
        \label{fig:data-process-distribution}
    \end{subfigure}
    \caption{Dataset composition highlighting broad material and synthesis technique coverage.}
    \label{fig:main-data-distribution}
\end{figure*}

This process yielded 17,667 high-quality recipes (\(\sim\) 62\% yield) across 10 synthesis techniques.

\subsection{Quality Verification}
\label{subsec:quality_verification}

To assess the accuracy of extracted recipes, we conducted a manual review with eight domain experts (materials scientists with at least a master’s degree). Evaluators rated sampled recipes based on:

\begin{itemize}
    \item \textbf{Completeness:} Does the extraction capture all synthesis details (\textbf{X}, \(\mathbf{Y_M}\), \(\mathbf{Y_E}\), \(\mathbf{Y_P}\), \(\mathbf{Y_C}\))?
    \item \textbf{Correctness:} Are critical synthesis parameters (e.g., temperature, reagent amounts) accurately extracted?
    \item \textbf{Coherence:} Is the extracted recipe logically structured and internally consistent?
\end{itemize}

\input{table/data/human_verification}

Preliminary evaluations indicate that the majority of extracted recipes exhibit high accuracy, particularly when the original articles contain well-structured experimental sections. Completeness was slightly lower than correctness and coherence due to occasional omissions in fine details (e.g., exact molar ratios or characterization parameters). The main sources of extraction variability stem from minor inconsistencies in reagent terminology and missing processing conditions. These findings underscore the need for refined annotation guidelines to ensure consistency.

While manual verification provides useful insights, it cannot scale to evaluate large datasets comprehensively. To systematically assess extraction quality at scale, we introduce a benchmarking framework in the following section (Section~\ref{sec:benchmark}), evaluating models on precursor identification, equipment inference, procedure generation, and characterization forecasting.
