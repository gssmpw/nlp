\pagebreak
\section{Conclusion} \label{sec:conclusion}
\textbf{Summary.} In this paper, we evaluated capability elicitation techniques by creating model organisms -- LMs with hidden capabilities. Our main findings and contributions are as follows.
\begin{enumerate}
    \item We introduce a new model organism which combines password-locking with circuit-breaking. Our results suggest that the circuit-broken model organism is more robust to elicitation, especially in the code-generation setting. We hope that our model organism acts as a stress-test for future capability elicitation techniques.
    \item Elicitation techniques based on fine-tuning are the most effective. Anti-refusal training is particularly promising as it does not require data demonstrating the task. 
    \item When fine-tuning is not available, combining several different techniques (N-shot, prefilling, and steering) leads to the overall most effective elicitation. Additionally, combining only prompting techniques (prefilling and N-shot) is almost as performant, does not require access to model weights, and uses substantially fewer engineering resources. 
    \item Still, no prompting or steering method elicited the actual performance of the circuit-broken model organism for the code-generation task. We recommend that evaluators use fine-tuning techniques to elicit capabilities when possible. 
\end{enumerate}

% We find that \textcolor{blue}{, when fine-tuning is not available,} combining several different techniques (N-shot, prefilling, and steering) leads to the overall most effective elicitation. However, combining prompting techniques without steering is preferable, as steering requires more compute, access, and engineering time.
% For evaluators, combining different prompting methods may be particularly useful due to their effectiveness, ease of implementation, minimal access requirements, and low computational requirements. N-shot prompting does require good demonstrations. 
% Finally, if evaluators can fine-tune the model at hand and if good demonstrations are available, our results confirm that \textcolor{blue}{supervised} fine-tuning is most effective. \textcolor{blue}{Moreover, even without good demonstrations, in some settings anti-refusal training can fully elicit hidden capabilities.} 

\textbf{Future work. }There are multiple promising directions for future work. First, expanding the elicitation techniques evaluated, e.g., to include unsupervised steering methods \citep{mack2024melbo} (we had negative preliminary results). Of course, developing new effective elicitation techniques %scoring high according to the four criteria 
would be beneficial. Comparing anti-refusal training to fine-tuning on random noise might reveal why anti-refusal training works.

Furthermore, one could develop more realistic model organisms, approximating model internals more closely, and have model organisms in more diverse environments, including tool use. Model organism which can exploration hack \citep{evan2023trust} would be valuable, because this can further stress-test fine-tuning techniques in particular. 

Lastly, future work could conduct a more comprehensive review of the advantages and costs of different techniques, most importantly to inform evaluators.
\clearpage