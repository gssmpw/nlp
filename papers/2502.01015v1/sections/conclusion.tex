In this work, we revisited task vectors as a practical approach for model editing. By providing a theoretical foundation for task arithmetic, we addressed key gaps in understanding its underlying mechanisms and identified the conditions for its success. Building on these insights, we introduced a scalable framework that reduces the memory footprint of task vector arithmetic through clustered task bases, significantly improving efficiency while maintaining high performance, and demonstrated the flexibility of bases arithmetic. Looking forward, we foresee several future directions. First, the creation of our task vector bases depends on the task relationship, and there are additional opportunities to improve memory efficiency from hardware perspectives. Additionally, by clustering, we assume that there are disjoint groups of tasks for the initial task vectors. Therefore, it might be interesting to further decompose and reorganize task vectors to boost performance for more complicated task relationships.
