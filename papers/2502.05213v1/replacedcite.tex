\section{Related Work}
% 自2023年，首篇单bit水印被提出后，大量工作被提出，以达到xxxxxx的效果。然而，单bit的工作无法同时标识多个大模型或标识给不同用户的输出。为此，多bit工作被提出，工作1，2，3，4，5分别作了什么事，有什么缺点。
% 为此,我们想要做一个什么样的.
Since 2023, a series of efforts have been dedicated to embedding watermarks into LLM-generated text ____. These works fall into two main categories: one-bit watermarking and multi-bit watermarking.
One-bit watermarking is used to determine whether a given text has been generated by a specified LLM.
However, they cannot be directly extended to multi-bit watermarking scenarios to meet the requirements of watermarking LLM-generated text from different LLMs for different users.
To address the above problem, multi-bit watermarking methods have been proposed to embed 0/1 strings into LLM-generated text. Given the diversity of watermarks, these methods can watermark different LLM-generated texts. Among them, ____ proposes adding an additional watermark loss in the inference phase to embed each bit of the watermark into a fixed-length segment. ____ proposes training a model to encode the watermark into the LLM-generated text. However, it is unreliable to embed the watermark directly into a fixed-length segment without considering its capacity. Intuitively, the watermark capacity varies from text to text. However, none of the current multi-bit watermarking methods account for the LLM-generated text's capacity. This can lead to embedding failure when the text has low watermark capacity.



Therefore, we aim to dynamically assign different segments to each bit of the multi-bit watermark based on the watermark capacity of the LLM-generated text and embed each bit into the corresponding segment.

% --------------------------------Problem Formulation-----------------------------------------