\begin{abstract}
% Model Merging is a cost-effective merging technique 
% Model Merging has emerged as a technique without
% Large Language Models (LLMs) are often fine-tuned for specific tasks, which improves performance, while leading to high storage and training costs. To mitigate this, model merging combines multiple fine-tuned models into one in a training-free manner to fuse different knowledge from multiple models. 
% However, naively merging multiple LLMs can introduce safety-utility conflicts, where enhancements in utility come at the expense of safety.
% Existing solutions often require additional training or significant computational resources.
% In this paper, We propose LED-Merging, a simple and effective method to resolve these conflicts. LED-Merging addresses two key issues: (i) single score misidentification, and (ii) cross-task interference. Through a three-step process—Location-Election-Disjoint Merging—we dynamically elect safety neurons and reduce interference, preserving safety without sacrificing utility.
% Extensive experiments on models like Llama-3-8B and Mistral-7B show that LED-Merging improves safety performance (e.g., a 9.44\% increase on Llama-3-8B) while maintaining utility. Our approach offers a training-free solution that resolves safety-utility conflicts with minimal data annotations.

%Large Language Models (LLMs) finetuned for specific tasks face significant storage and computational costs, prompting the adoption of model merging to fuse multiple specialized models into a single unified model. However, existing merging methods often introduce safety-utility conflicts, where improvements in task performance degrade safety capabilities. Previous works require additional alignment training, failing to address these conflicts effectively. In this paper, we propose LED-Merging, a training-free approach that: (1) locates critical neurons via gradient-based scores, (2) elects safety-critical neurons by fusing multi-model signals, and (3) disjoints conflicting updates to mitigate interference. Extensive experiments on models like Llama-3-8B and Mistral-7B show that LED-Merging improves safety performance (e.g., a 9.44\% increase on Llama-3-8B) while maintaining utility. Our approach offers a training-free solution that resolves safety-utility conflicts with minimal data annotations (e.g., GSM8K, MBPP). This method offers a lightweight, data-efficient solution for reliable multi-task LLMs. Code will be released in GitHub.

% Fine-tuning pre-trained Large Language Models are common practice for improving their performance for specific tasks with significant data and computational costs. To this end, model merging fuses multiple specialized models into a single unified model without training. However, existing merging methods often introduce safety-utility conflicts, where the improvement of general utility degrades safety capabilities. In this paper, we discover that neuron misidentification and interference are the essential reasons for the conflict. To address the problem, we propose a training-free approach, \textit{LED-Merging}, to accurately identify the task-specific neurons and disjoint different task-specific neurons to mitigate the interference. Extensive experiments on models like Llama-2-13B, Llama-3-8B, and Mistral-7B show that LED-Merging improves safety performance (\emph{e.g.}, a 31.4\% increase on Llama-3-8B-Instruct in HarmBench) while maintaining utility. LED-Merging resolves safety-utility conflicts and offers a lightweight solution for reliable multi-task LLMs. %Code will be released in GitHub.

Fine-tuning pre-trained Large Language Models (LLMs) for specialized tasks incurs substantial computational and data costs. While model merging offers a training-free solution to integrate multiple task-specific models, existing methods suffer from safety-utility conflicts where enhanced general capabilities degrade safety safeguards. 
We identify two root causes: \textbf{neuron misidentification} due to simplistic parameter magnitude-based selection, and \textbf{cross-task neuron interference} during merging.
To address these challenges, we propose \textbf{LED-Merging}, a three-stage framework that \textbf{L}ocates task-specific neurons via gradient-based attribution, dynamically \textbf{E}lects critical neurons through multi-model importance fusion, and \textbf{D}isjoints conflicting updates through parameter isolation.
Extensive experiments on Llama-3-8B, Mistral-7B, and Llama2-13B demonstrate that LED-Merging reduces harmful response rates(\emph{e.g.}, a 31.4\% decrease on Llama-3-8B-Instruct on HarmBench) while preserving 95\% of utility performance(\emph{e.g.}, 52.39\% accuracy on GSM8K).
LED-Merging resolves safety-utility conflicts and provides a lightweight, training-free paradigm for constructing reliable multi-task LLMs.

\end{abstract}