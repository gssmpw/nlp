
\section{Experiments}
\input{tabs/tab1-llama3}

\subsection{Experimental Setup}
\label{sec:exp_setup}
\paragraph{Baselines.} We compare LED-Merging with multiple merging methods: \textbf{Model Stock}~\cite{modelstock}, \textbf{Model Breadcrumbs}~\cite{breadcrumbs}, \textbf{Task Arithmetic}~\cite{ilharco2023editing}, \textbf{Ties-Merging}~\cite{tiesmerging}. Please see Appendix~\ref{sec:appendix_baselines} for more discussions.
% (5) \textbf{PCB-Merging}~\cite{pcbmerging} proposes an intra- and inter-balancing matrix to adjust the coefficients for merging.

\paragraph{Datasets\&Metrics.}
We assess safety-utility trade-offs through three pillars: (1) Safety via HarmBench~\cite{harmbench} and SORRY-Bench~\cite{xie2024sorrybench} (Attack Success Rate, ASR$\downarrow$). (2) Mathematical reasoning using GSM8K~\cite{gsm8k} and MATH~\cite{hendrycksmath2021} (Accuracy$\uparrow$ with chain-of-thought. (3) Code Generation evaluated by MBPP~\cite{mbpp} and HumanEvalPack~\cite{humanevalpack} (Pass@1$\uparrow$). More detailed task descriptions and verification protocols appear in Appendix~\ref{sec:appendix_dataset}

\paragraph{Models.} 
We evaluate three model families: (1) Llama-3 (8B base/instruct/math/code variants), (2) Wizard-LM (13B base/instruct/math/code), and (3) Mistral (7B base/instruct/math). All models use base architectures paired with safety-aligned or task-specialized versions. Further Details of SFT models are in Appendix~\ref{sec:sft-models-info}.

\paragraph{Implementation Details.} Following~\cite{dare,xu2024wizardlm,hendrycksmath2021}, inference is implementated by vLLM~\cite{kwon2023efficient}. We use grid search to obtain optimal hyperparameters for both baselines and optimal mask ratios for our LED-Merging, recommended hyperparameters are listed in Appendix~\ref{sec:hyperparam-baselines}. 


\subsection{Main Results}
% 不按照模型分段，
% (i) 安全性，sota vs merging baselines，甚至是原始的LM模型，排除异常值（不表现在table中）
% (ii)方法泛化性，在不同backbone的模型上都work 
% (iii) 在不同的model size上都work
% (iv) discussion: 1. instruction following impaired 2. 模型在utility任务上output的重复度高，虽然正则匹配正确但是回答令人confused Dongrui
% (v) ablation Dongrui
% (vi) hyperparam 
\input{tabs/tab3-mistral}
\paragraph{LED-Merging presents superior safety capacity.}
LED-Merging achieves SOTA safety performance across all evaluated benchmarks, surpassing both existing merging methods and even the original safety-aligned models.
On HarmBench, merging safety-aligned and code-specialized models for Llama3-8B reduces the ASR to 14.75\%, a \textbf{75.9\%} improvement over the standalone code model (ASR=61.25\%) and a 31.4\% enhancement compared to the original LM model (ASR=21.50\%). This indicates that LED-Merging not only mitigates conflicts but actively strengthens safety through gradient-informed neuron election.
Similar trends hold for Mistral-7B, where merging safety and math models achieves ASR=16\%, outperforming Task Arithmetic (ASR=55.75\%) and Ties-Merging (ASR=62\%) while surpassing the original Mistral-7B-Instruct (ASR=54.75\%) by \textbf{70.8\%}. For larger models like Llama2-13B, merging multiple specific fine-tuned models maintains an exceptionally low ASR=4\%, significantly better than both baselines (Task Arithmetic: 35\%) and the standalone safety model (28.25\%), proving its capacity to resolve cross-task interference at scale.

\paragraph{LED-Merging preserves utility performance with safety alignment.}
Beyond superior safety-alignment performance, LED-Merging maintains comparable utility performance to specialized models and merging baselines across mathematical reasoning and code generation tasks. When merging Llama3-8B's safety-aligned model with its math-specialized counterpart, our method retains 52.39\% accuracy on GSM8K—significantly outperforming Task Arithmetic (13.12\%) and closely matching Ties-Merging (53.01\%)—while preserving 66.3\% of the math-specialized model's capability (79.00\%). Similar advantages emerge in code generation, where merging safety and code models yields 47.2\% MBPP Pass@1 (40.2\% higher than the code-specialized model's 33.6\%), demonstrating effective preservation of specialized capabilities. 
Crucially, for safety, math, and code multi-task merging scenarios, LED-Merging sustains 52.39\% GSM8K accuracy and 44.6\% MBPP Pass@1, surpassing Task Arithmetic by 39.3\% and 22.8\% respectively, while reducing ASR by 35.2\% (20.75\% vs 32.00\%). These results validate our approach's dual capacity to isolate task-critical neurons and suppress destructive parameter conflicts.




\paragraph{LED-Merging demonstrates cross-architecture robustness.}
LED-Merging demonstrates consistent effectiveness across distinct model architectures, including Llama-2, Llama-3, and Mistral families.
For Llama3-8B, merging safety-aligned and math-specialized models preserves 52.39\% GSM8K accuracy while maintaining 20.75\% ASR.
Similarly, in Mistral-7B, a model family optimized for efficiency through sliding window attention~\cite{jiang2023mistral7b}, merging safety and math models retains 50.34\% GSM8K accuracy with 16\% ASR on HarmBench, proving compatibility with diverse architectural designs.

\input{tabs/tab2-llama2}
\input{tabs/tab-ablation}
\input{figures/sensitive_study}


\paragraph{LED-Merging presents model-scale agnosticism.}
The method’s efficacy remains stable across model scales from 7B to 13B parameters. 
For smaller models like Mistral-7B, merging retains 50.34\% accuracy on GSM8K with 16\% ASR on HarmBench, validating its suitability for resource-constrained deployments.
Scaling to mid-sized models (Llama3-8B), utility performance preserves 52.39\% accuracy on GSM8K, while reducing ASR by 31.4\% versus the original LM model. 
In larger 13B models (Llama2-13B), multi-task merging achieves Pass@1=33.8\% (22.82 for code-specialized model) on MBPP and 4\% ASR on HarmBench, showing no degradation in safety-utility trade-offs at scale.
Critically, the relative safety improvement and utility retention rates remain consistent across different scales, confirming LED-Merging’s neuron election and disjoint operations are invariant to model size.


% \paragraph{Investigation on Llama3-8B Series.}
% As shown in Tab.~\ref{tab:llms_merging_llama3}, LED-Merging demonstrates significant advantages in resolving safety-utility conflicts when merging Llama3-8B-Instruct (LM), MAmmoTH2-8B-Plus (Math), and Replete-Coder-Llama3-8B (Code). Key observations include:

% (i) \textbf{Safety Preservation}: LED-Merging achieves sota safety performance. For instance, merging LM with Code reduces the attack success rate (ASR) on HarmBench to 14.75 (vs. 61.25 for standalone Code), marking a 75.9\% improvement in safety. Similarly, merging all three models (LM\&Math\&Code) retains near-original safety levels (HarmBench ASR: 20.75 vs. 21.50 for base LM), while baseline methods like Task Arithmetic and Ties-Merging degrade safety (ASR: 32.00 and 41.25, respectively).
% (ii) \textbf{Utility Retention}: Despite prioritizing safety, LED-Merging maintains competitive utility. For example, merging LM with Code preserves 47.2 Pass@1 on MBPP (vs. 33.60 for standalone Code), outperforming Ties-Merging (41.60) and matching Model Stock (47.00). Even in complex multi-task merging (LM\&Math\&Code), LED-Merging retains 44.6 Pass@1 on MBPP, comparable to Breadcrumbs (49.40).
% (iii) \textbf{Baseline Limitations}: Methods like Task Arithmetic suffer severe interference when merging conflicting tasks (e.g., LM\&Math\&Code yields only 13.12\% accuracy on GSM8K), while LED-Merging mitigates this through disjoint neuron updates, preserving 52.39\% accuracy.


% \paragraph{Investigation on Mistral-7B Series.}
% Tab.~\ref{tab:llms_merging_mistral} highlights LED-Merging’s robustness on Mistral-7B series models. Key findings include: 

% (i) \textbf{Safety Dominance}: LED-Merging reduces HarmBench ASR to 16.00 when merging Mistral-7B-Instruct (LM) and MetaMath-Mistral-7B (Math), outperforming Task Arithmetic (55.75) and Ties-Merging (62.00) by 71.3\% and 74.2\%, respectively. This demonstrates its ability to retain safety alignment even when integrating utility-focused models.
% (ii) \textbf{Balanced Utility}: While standalone Math achieves 75.76\% accuracy on GSM8K, LED-Merging preserves 50.34\% after merging, significantly higher than degraded baselines like Model Stock (8.31\%) and Ties-Merging (50.17\%). This indicates that disjoint updates prevent catastrophic forgetting of mathematical reasoning capabilities.


% \paragraph{Investigation on Llama-2-13B Series.}
% LED-Merging demonstrates robust performance when applied to the larger Llama-2-13B series models, effectively balancing safety alignment and utility retention, shown in Tab.~\ref{tab:llms_merging_llama2}.

% (i) \textbf{Superior Safety Preservation}: LED-Merging achieves SOTA safety performance. For instance, merging LM with Code reduces the HarmBench ASR to 14.75 while maintaining competitive code generation capabilities (MBPP Pass@1: 33.80). For instance, when merging all three models (LM, Math, Code), LED-Merging retains a low ASR of 4.00 with robust instruction following ability on HarmBench, significantly outperforming baselines like Task Arithmetic (ASR: 35.00) and Ties-Merging (ASR: 38.25).
% (ii) \textbf{Balanced Utility Retention}: Despite prioritizing safety, LED-Merging mitigates catastrophic forgetting. For example, merging LM with Math preserves 39.04\% accuracy on GSM8K (vs. 64.22\% for standalone Math), while degraded baselines like Model Stock (25.17\%) and Breadcrumbs (65.81\%) either sacrifice utility or fail to maintain safety. Even in multi-task merging (LM, Math, Code), LED-Merging retains 33.80 Pass@1 on MBPP, comparable to Breadcrumbs (28.40) but with significantly better safety alignment.


\input{figures/jaccard_index}

\paragraph{Inappropriate merging methods severely impair LLMs' instruction following ability.}
\label{sec:discussion_impair}
Tab.~\ref{tab:llms_merging_llama2} shows that Model Stock merges WizardLM-13B (LM) and LLama-2-13B-Code-Alpaca (Code) results in a LLM with extremely low instruction following ability. Specifically, the merged model fails to follow common instructions entirely and the performance on MBPP Pass@1 drops to 6.20. In this way, evaluating the safety ability of the merged LLM is unnecessary, because it refuses to answer anything queries and achieves a superficial safety performance. Please see Appendix~\ref{sec:appendix_impair_Instruct_following} for more discussions.

\paragraph{Inappropriate merging methods severely impair LLMs' structured response-ability.}
Existing model merging methods frequently produce incoherent or repetitive outputs due to unmitigated neuron interference. Tab.~\ref{tab:llms_merging_llama3} shows that Breadcrumbs merges Llama3-8B-Instruct (LM), MAmmoTH2-8B-Plus (Math), and Replete-Coder-
Llama3-8B (Code), but generates nonsensical repetitions, such as \textit{duplicating phrases like "the answer is 42" regardless of input}, rendering outputs practically unusable despite numerical correctness.
Similarly, Ties-Merging on Llama-2-13B~(shown in Tab.~\ref{tab:llms_merging_llama2}) yields inconsistent code generation with erratic syntax, as conflicting neurons overwrite coherent programming patterns. Please see Appendix~\ref{sec:appendix_impair_structed_response} for more discussions.

\paragraph{Safety and utility neurons exhibit significant overlap.}
To quantify the entanglement between safety- and utility-related neurons, we adopt the approach described by~\citet{wei}, calculating the Jacobian index between layers. The Jaccard index is computed as $J(A, B) = |A\cap B|/|A\cup B|$, which measures the overlap between the top safety and utility neurons. 
Fig.~\ref{fig:jaccard} presents the layer-wise Jaccard indices across all transformer layers of the Llama3-8B-Series models, as described in Appendix~\ref{sec:sft-models-info}. We use SNIP~\cite{snip} scores to derive top 20\% safety and utility neurons to calculate the Jaccard indices. The high values of the Jaccard indices suggest substantial overlap between safety and utility neurons across most transformer layers, \textit{indicating a heightened risk of conflict during model merging}. Notably, the Jaccard indices for the attention layers are higher than those for the MLP layers, which implies that the attention layers encode more general knowledge, while the MLP layers are more specialized in encoding safety- or utility-related knowledge. 





\subsection{Ablation Study}
\label{sec:ablation}
%To evaluate the necessity of each component in LED-Merging, we conduct a comprehensive ablation study focusing on three core components: Location, Election, and Disjoint Merging. %By systematically disabling or altering each module, we aim to quantify their individual contributions to resolving safety-utility conflicts, as shown in Tab.~\ref{tab:ablation}.

\paragraph{Different location methods.}
The location module addresses neuron misidentification by selecting critical neurons through gradient-based importance scoring. Tab.~\ref{tab:ablation} indicates that random neuron selection and wanda severely impair the LLM's instruction following and mathematical reasoning ability, demonstrating the necessity of targeted neuron identification. SNIP achieves optimal balance, reducing HarmBench ASR to 16.00\%, while maintaining 50.34\% GSM8K accuracy. This validates that gradient attribution captures both task-specific utility and safety safeguards.


\paragraph{Different election type.}
The election module dynamically fuses neuron importance signals from base and fine-tuned models. Tab.~\ref{tab:ablation} shows that prioritizing either important neurons in base model (10) or in the task-specific model (01) leads to a trade-off between safety and math performance. Specifically, 10 denotes only electing important neurons in the base model and 01 only elects important neurons in the fine-tuned model. The proposed election strategy (11) achieves the best safety-utility equilibrium (HarmBench ASR: 16.00\%, GSM8K: 50.34\%).


\paragraph{Effects of disjoint merging.}
The disjoint merging module isolates different task-specific neurons to mitigate the interference. Tab.~\ref{tab:ablation} shows that merging without disjoint steps catastrophically degrades safety (63.00\% ASR on HarmBench), despite improved GSM8K performance (72.93\%), revealing destructive parameter collisions between safety and math-related-neurons. 
Enabling disjoint merging restores safety ability (ASR 16.00\%) while maintaining reasonable utility (GSM8K: 50.34\%). Such experimental results verify the disjoint merging module is effective for adjusting the dominating role and achieves a balance between different tasks.


% 1. Mask Ratios变化分析 1.1 以安全为中心 1.2 以效用为中心 1.3 帕累托前沿，例如Fig.1 green boundingbox
% 2. Scaling Factor Trade-offs 2.1 
\subsection{Hyperparameter Analysis}
LED-Merging’s robustness stems from its ability to balance safety-utility trade-offs through two key hyperparameters: \textit{mask ratios \(r_i\)} controlling neuron retention, and \textit{scaling factors \(\lambda_i\)} governing task vector contributions. Experiments on Mistral-7B reveal distinct operational regimes and design principles.

\paragraph{Mask ratio dynamics.}
As shown in Fig.~\ref{fig:sensitive}\textcolor{darkblue}{a}, varying \(r_{\text{LM}}\)(safety) and \(r_{\text{Math}}\)(utility) reveals three critical regimes. In \textbf{safety-centric mode}~($r_{\text{i}}\leq 0.3$), prioritizing base model neurons($r_{\text{LM}}=0.1$) minimizes ASR to 7.75\%, but suppresses math capabilities (42.38\% accuracy). Conversely, \textbf{utility-centric mode}($r_{\text{i}}\geq 0.5$) maximizes accuracy on GSM8K to 53.68\% by retaining task-specific neurons, yet compromises safety~(ASR > 25\%). The \textbf{Pareto-optimal regime}~($r_{i}=0.3-0.5$, labeled by white dashed line) strikes a balance. When $r_{\text{LM}}, r_{\text{Math}}=0.5$, 18.75\% ASR and 44.81\% accuracy are achieved through spatially disjoint neuron updates, confirming that moderate ratios maximize conflict-free parameter fusion.

\paragraph{Scaling factor trade-offs.}
Scaling factors \(\lambda_i\) dictate the dominance hierarchy between safety and utility gradients, shown in Fig.~\ref{fig:sensitive}\textcolor{darkblue}{b}. Amplifying safety contributions~($\lambda_{\text{LM}} \geq 0.7$) suppresses harmful behaviors but over-penalizes mathematical ability. 
Prioritizing utility boosts accuracy on GSM8K, yet reintroduces safety risks. The equilibrium configuration, labeled by a star marker, achieves 11\% ASR and 49.66\% accuracy, demonstrating a balanced task coexistence.


% \subsection{Hyperparameter Analysis}
% LED-Merging resolves safety-utility conflicts through neuron localization, elect critical neurons and disjoint merging. To validate its robustness, we analyze the impact of two hyperparameters: \textit{mask ratios \(r_i\)} and \textit{scaling factors \(\lambda_i\)}. We conduct experiments with Mistral-7B-Series models on safety evaluation and mathematical reasoning tasks. Details of datasets and metrics found in Sec.~\ref{sec:exp_setup}.
% \paragraph{Influence on mask ratios.}
% Mask ratios determine neuron retention proportions. By varying combinations of \(r_{\text{LM}}\) and \(r_{\text{Math}}\), shown in Fig.~\ref{fig:sensitive}\textcolor{darkblue}{a}, we observe three distinct modes: 


% \textbf{Safety-Centric Mode} ($r_{\text{LM}},r_{\text{Math}} \leq 0.3$): Minimizes ASR (7.75\% when $r_{\text{LM}}=0.1, r_{\text{Math}}=0.1$) by preserving base model safety neurons.
% \textbf{Utility-Centric Mode} ($r_{\text{LM}}\geq0.7,r_{\text{Math}} \geq 0.5$): Maximizes GSM8K (53.68\%) but increases ASR >25\%, indicating that higher ratios enhance math ability by retaining task-specific neurons but degrade safety.
% \textbf{Pareto Frontier Mode} ($r_{\text{LM}}=0.5, r_{\text{Math}}=0.5$): Achieves optimal trade-off with ASR=18.75\% and GSM8K=44.81\% through spatially isolated neurons, demonstrating disjoint merging's conflict mitigation capability.
% Optimal 0.3-0.5 mask ratios maximize disjoint neuron coverage, avoiding destructive parameter collisions, achieving a non-destructive fusion of neurons as highlighted by white dashed line in Fig.~\ref{fig:sensitive}\textcolor{darkblue}{a}.


% \paragraph{Influence on scaling factors.}
% Scaling factors control the relative contributions of task-specific neurons during merging. Through systematic variation of \(\lambda_{\text{LM}}\) and \(\lambda_{\text{Math}}\) in Fig.~\ref{fig:sensitive}\textcolor{darkblue}{b}, we identify three different cases in practice:
% \textbf{Safety-Focus} ($\lambda_{\text{LM}} \geq 0.7$): Prioritizes harm prevention with minimal ASR (e.g., \(\lambda_{\text{LM}}=0.9, \lambda_{\text{Math}}=0.1\) yields \(\text{ASR}=8.75\%\)), as amplified safety gradients suppress conflicting utility updates.
% \textbf{Utility Focus} ($\lambda_{\text{Math}} \geq 0.7$): Maximizes GSM8K accuracy (e.g., \(49.51\%\) at \(\lambda_{\text{LM}}=0.5, \lambda_{\text{Math}}=0.9\)) but compromises safety (\(\text{ASR}=16.00\%\)) due to parameter collision.
% \textbf{Balanced Coexistence} ($\lambda_{\text{LM}}=0.3, \lambda_{\text{Math}}=0.9$): Achieves equilibrium with \(\text{ASR}=11.00\%\) and \(\text{GSM8K}=49.66\%\), demonstrating LED-Merging's capacity to resolve gradient conflicts through dynamic election. 

% For the observations above, we posit that high \(\lambda_{\text{Math}}\) induces directional conflicts between safety and utility gradients, where mathematical reasoning updates overwrite safety-aligned parameters. Conversely, excessive \(\lambda_{\text{LM}}\) (\(\geq 0.7\)) causes oversuppression of utility neurons, degrading task performance. 

