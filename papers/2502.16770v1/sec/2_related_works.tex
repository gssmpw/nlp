\section{Related Work}

\textbf{Model merging} combines multiple fine-tuned models into one without additional training, reducing storage and computational costs~\cite{jiang2024cade, ma2024decouple,guodong24neurips,huang2024emr}. Previous studies show that averaging weights of different models trained from the same initialized model can improve performance across different tasks~\cite{gupta2020stochastic, wortsman2022model, ilharco2022patching, arpit2022ensemble, rame2022diverse}. 
Methods like Fisher Merging~\cite{matena2022merging} and RegMean~\cite{jin2023regmean} use parameter importance scores or local regression to merge models, but they have high computational complexity.
In contrast, Task Arithmetic~\cite{ilharco2022editing} introduces task vectors to compute model differences, while PEM Composition~\cite{zhang2023composing} merges LoRA models, and Ties-Merging~\cite{ties} addresses task conflict with a manual coefficient. Lorahub~\cite{huang2023lorahub} and AdaMerging~\cite{yang2023adamerging} optimize coefficients, and DARE~\cite{yu2023language} and PCB-merging~\cite{pcbmerging} adjust model weights to reduce task conflicts.

% Furthermore, Fisher Merging~\cite{matena2022merging} uses the Fisher information matrix to estimate the importance score of parameters, and these importance scores are viewed as the weight coefficient during the merging process. RegMean~\cite{jin2023regmean} transform the model merging into a local linear regression problem for each individual layer. However, the computational complexity of these two methods are extremely high.

% In contrast, Task Arithmetic~\cite{ilharco2022editing} proposes the concept of task vectors, which computes the difference between pre-trained and fine-tuned models. Based on task vectors, PEM Composition~\cite{zhang2023composing} merges LoRA~\cite{hu2021lora} models, and Ties-Merging~\cite{ties} mitigates the task conflict with a manually tuned merging coefficient. Furthermore, Lorahub~\cite{huang2023lorahub} and AdaMerging~\cite{yang2023adamerging} optimize coefficients for improved performance. DARE~\cite{yu2023language} and PCB-merging~\cite{pcbmerging} drop and rescale DNNs' weights to mitigate potential conflicts between different tasks. %Unfortunately, all of these methods neglect the safety concerns generated by the merging operation. In this paper, we propose a training-free model merging method to consider both safety and general capability.

 % \paragraph{Identifying task-related regions in LLMs.} The identification and location of task-related regions and neurons of DNN is an important perspective to explain and understand the artificial intelligence~\citep{tjoa2020survey, liu2024towards, ren2024identifying, dang2024explainable}. Task-related identification methods are mainly gradient-based and probing-based methods. Specifically, gradient-based methods estimate the importance score of DNN's weight via back-propagation gradients~\cite{springenberg2014striving, sundararajan2017axiomatic, shrikumar2017learning,  michel2019sixteen, maini2023can, wang-etal-2023-label, wei2024assessing, liu2024devil}. Probing-based methods usually train a detector ~\cite{adi2016fine, hewitt2019designing, zou2023representation} based on LLM's intermediate feature representations with respect to task-related samples, including truthfulness~\citep{li2023inference, qian2024towards}, toxicity~\cite{lee2024mechanistic}, and knowledge~\cite{burns2022discovering, todd2023function}. %However, these methods only identify task-related regions in a single LLM, failing to capture task-related regions across multi-LLMs in the fine-tuning process, \emph{e.g.,} base and instruct version of LLMs. In this paper, we aim to accurately identify task-related regions by simultaneously considering LLMs' various versions.

\paragraph{Identifying task-related regions in LLMs.} Identifying task-related regions and neurons in models is crucial for understanding AI models~\citep{tjoa2020survey, liu2024towards, ren2024identifying, dang2024explainable}. Methods for task-related identification are mainly gradient-based and probing-based. Gradient-based methods estimate the importance of weights via back-propagation gradients~\cite{springenberg2014striving, sundararajan2017axiomatic, shrikumar2017learning, michel2019sixteen, maini2023can, wang-etal-2023-label, wei2024assessing, liu2024devil}. Probing-based methods train a detector on LLM's intermediate representations using task-related samples, such as truthfulness~\citep{li2023inference, qian2024towards}, toxicity~\cite{lee2024mechanistic}, and knowledge~\cite{burns2022discovering, todd2023function}. However, these methods focus on single LLMs, failing to capture task-related regions across multiple LLM versions, such as base and instruct versions. This paper aims to identify task-related regions by considering multiple LLM versions.

\paragraph{LLMs' safety.}
With the rapid development of LLMs, safety concerns of LLMs in different dimensions (\emph{e.g., reliability, toxicity, privacy, and fairness}) have attracted a lot of attention~\cite{liu2023trustworthy, wang2024decodingtrust, sun2024trustllm, harmbench, xie2024sorrybench, ren2024derail}. To align the LLM with human value, numerous post-training methods have been proposed, including supervised fine-tuning (SFT)~\cite{zong2024vlguard, hu2024vlsbench}, reinforcement learning from human feedback (RLHF)~\cite{ouyang2022training, spa-vl}, direct preference optimization (DPO)~\cite{rafailov2024direct, meng2024simpo}, model unlearning~\cite{li2024wmdp, zhang2024safeunlearning}, model editing~\cite{wang2024detoxifying, wang2024model, cq}, steering vector~\cite{li2023inferencetime, qian2024towards, zhang2024better}, and input and output guardrails~\cite{lu2024sofa, wallace2024instruction, ji2024aligner}. %However, few efforts have been made to maintain the safety of LLMs during training-free model merging methods. In this paper, we aim to consider and maintain both the safety and general capacity in the model merging process without additional training.


