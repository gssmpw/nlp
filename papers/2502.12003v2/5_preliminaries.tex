\section{Preliminaries}
\label{sec:preliminaries}

\paragraph{U-Net \cite{ronneberger2015u}} The U-Net is a widely-used architecture for segmentation, including for remote sensing applications \cite{li2024review}.  There are now many variations of the U-Net, including modern variants that utilize attention (e.g., SwinUnet \cite{cao2022swin}).  The U-Net typically includes three distinguishing architectural features: an encoder, $f_{\theta_{En}}$ with parameters $\theta_{En}$; a decoder, $f_{\theta_{De}}$ with parameters $\theta_{De}$; and skip connections between the encoder and decoder, as is illustrated in \cref{fig:utae_and_unet_illustration}.  The original U-Net in \cite{ronneberger2015u} employed an encoder with relatively few layers that were trained from scratch.  It has been found, however, that utilizing larger pre-trained encoders (e.g., ResNet models \cite{he2016deep}) can be beneficial, including specifically when applied to remote sensing data\cite{iglovikov2018ternausnet}.     

\paragraph{UTAE \cite{garnot2021panoptic}} The UTAE was originally developed for satellite imagery, and is essentially a U-Net that has been modified to process a time-series of imagery.  The UTAE encodes each entry in the time-series independently using a shared encoder, and then fuses the resulting embeddings from each day using a Lightweight Temporal Self-Attention (LTAE) block \cite{garnot2020lightweight}. This process is illustrated in \cref{fig:utae_and_unet_illustration} in the context of our wildfire spread problem.  Given a $T$-length time-series of input, the encoder produces a series of $T$ embeddings $z(t)= \{ \tilde{z}(t-i) \}_{i=1}^{T}$ where $\tilde{z}(t) \in \mathbb{R}^{D_{4} \times \frac{H}{8} \times \frac{W}{8}}$ at the output of the last layer of the encoder, as illustrated in \cref{fig:utae_and_unet_illustration}.  Then the LTAE computes an attention mask, $a \in \mathbb{R}^{T \times \frac{H}{8} \times \frac{W}{8}}$, which is utilized to combine the $T$ embeddings. Before computing the temporal attention, LTAE adds a sinusoidal positional embedding, $p(\bar{t})$ to each input embedding, where $\bar{t} \in [1,365]$ is an integer representing the day of the year, and $p(\bar{t})$ maps $\bar{t}$ to a unique sinusoidal representation.  This positional embedding is motivated by the original application of UTAE to agricultural segmentation, where the appropriate segmentation depends heavily upon the day of the year.  Once the attention mask is computed, it is then upsampled, and applied to the encoder embeddings output at each resolution to collapse the temporal dimension. After all temporal dimensions are collapsed, a conventional U-Net-like decoder is applied to the collapsed embeddings.  


\begin{figure}
    \centering
    \includegraphics[width=0.95\linewidth]{utae_and_unet_illustration_v1.PNG}
    \caption{Illustration of the U-Net and UTAE models, adapted from \cite{garnot2021panoptic} to our wildfire problem. The U-Net consists of (a) an encoder and (b) a decoder, with skip connections connecting intermediate layers. For a U-Net we have $T=1$ and temporal fusion, part (c), would not be present.  The UTAE is similar to the U-Net except $T>1$ and it includes Temporal Fusion, specifically with an LTAE.}
    \label{fig:utae_and_unet_illustration}
\end{figure}
