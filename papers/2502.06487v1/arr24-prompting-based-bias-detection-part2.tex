\section{Related work}
\label{sec:related-work}

Discrete prompts for LLMs have been evaluated for various tasks and applications. For example,  \citet{zamfirescu-pereira2023} and \citet{arroyo2024} investigate how sub-optimal prompts affect outputs and \citet{hida2024} study how different prompts influence social bias exhibited by LLMs.

Several techniques have been proposed to optimize discrete prompts. Popular techniques include personas for perspective taking \cite{sheng2021,xu2023,liu2024}, in-context demonstrations to provide application examples \cite{dong2024}, and reasoning steps that divide the tasks into sub-tasks \cite{wei2022}. In this work, we do not consider single prompting techniques but rather evaluate prompt compositions to take advantage of several techniques. Some related works also explore the effect of combining techniques \cite{stahl:2024}, aiming to find the best composition on average. In contrast, we aim to find the optimal composition on each text.

Among existing approaches to automatic prompt optimization, continuous prompt optimization learns to adjust the latent space \cite{li2021b,liu2022a}, whereas several studies generate discrete optimized instructions from task examples, to easier adapt to unseen data \cite{zhou2023,honovich2023,ha2023} or new LLMs \cite{memon2024}. Other works focus on iteratively optimizing prompts \cite{zhang2022,shum2023,tian2024} or predicting the suitability of prompts  \cite{yang2024}.
Instead of optimizing the latent space or single techniques, we propose to automatically find optimal prompt compositions for unseen inputs.

Related to the idea of prompt compositions, \citet{khattab2023} propose a framework to optimize the use of multiple techniques by training a parameterized model that automatically optimizes the prompt. We do not optimize techniques but learn to predict the optimal composition of techniques for a given setting. We further analyze the importance of each technique using Shapley values.

While several other studies aim to detect social bias in text corpora \cite{spliethover2020,asr2021,toroisaza2023,derner2024}, we aim to identify bias in single text instances, similar to \citet{schick2021,spliethover2024,powers2024}, by optimizing prompt compositions.

\hwfigure{approach}{The three steps of our adaptive prompting approach: (1)~Bias labels are collected for all considered prompt compositions. (2)~A model is trained on the collected labels to predict the optimal composition for any given text. (3)~Given an unknown text, the model is applied to predict and use the optimal prompt composition for that text.}

Detecting social bias reliably requires understanding of social language and pragmatics to interpret the implications of text \cite{choi2023}. \citet{hovy2021} identify seven factors of language (e.g., receiver information) to successfully model social aspects. \citet{choi2023} and \citet{zhou2023a} design social language benchmarks and find that LLMs are still limited in this regard. In this work, prompt compositions enable the inclusion of social aspects (e.g., receiver information with persona prompts) and can, therefore, provide helpful context for social language tasks.
