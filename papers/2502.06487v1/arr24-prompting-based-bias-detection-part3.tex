\section{Approach}
\label{sec:method}

We evaluate instruction-tuned LLMs to identify social bias using compositions of prompting techniques. Specifically, we propose a three-step approach to predict the optimal composition ad-hoc per input text. The process is illustrated in Figure~\ref{approach}.

The first step is to create prompt compositions that represent order-sensitive combinations of one or more prompting techniques. We prompt an LLM with each of these compositions to collect social bias classification labels. In the second step, we use the collected labels to train an adaptive prompting model that finds the optimal prompt composition for a given text instance. Aside from the main task, we also conduct a Shapley value analysis to determine the importance of prompting techniques. We then apply adaptive prompting to unknown texts to find the optimal prompt composition for each.



\subsection{Composition and Label Collection}

We start by collecting bias label predictions for all possible prompt compositions, emanating from our base composition, a set of prompting techniques, and constraints for their ordering and compatibility.

\paragraph{Base Composition}
As the minimal prompt to solve the task, we consider the \emph{task description} and \emph{input instance} to be always present (cf. Figure~\ref{composition-example}).

\paragraph{Ordering and Compatibility Constraints}
Not all orderings and combinations of prompting techniques create meaningful prompts. For example, if both a \emph{definition} (e.g., of social bias) and \emph{in-context demonstrations} (e.g., a biased text) are present, demonstrations make sense after the definition only. To ensure meaningful prompts, we pre-define a general ordering. Further, variants of the same technique (e.g., demonstrations sampled randomly or by similarity) should not appear together in the same composition; they are mutually exclusive.

\paragraph{Prompting Techniques}
Let a set of $n \geq 1$ prompting techniques, $T = \{t_1,\dots,t_n\}$, be given with fixed order $t_i$ before $t_j$, if $i<j$. We distinguish techniques with one variant, $T_{1}$, and with multiple variants, $T_{2}$, that is, $T = T_{1} \sqcup T_{2}$, where each $t \in T_{2}$ has $\vert t \vert$ variants. Concretely, each technique in $T_1$ may or may not be used, and any or none of the techniques in $T_2$ may be used.
Let the set of distinct compositions be denoted as $C$. Then, the number of compositions is
\begin{equation}
    \label{eqn:number-of-compositions}
    \vert C \vert = 2^{ \vert T_1 \vert} \cdot \prod_{t \in T_2} (\vert t \vert + 1).
\end{equation}




\subsection{Composition Prediction and Selection}
\label{sec:composition-prediction}

As visualized in the second step of Figure~\ref{approach}, we use the results of the label collection described above to train a prompt composition \emph{prediction model}. The model is then used for \emph{adaptive prompting} (Step~3).

\paragraph{Prediction Model}
The model is an encoder model with a regression head that is fine-tuned on the collected social bias labels to predict the \textit{optimal} prompt composition
$c_o$ from the set of possible compositions $C$. Here, \textit{optimal} refers to the composition with the highest predicted likelihood to generate a correct bias label for an input.
We formulate the prediction of the optimal prompt composition as a regression problem using a sigmoid output layer, followed by binary cross-entropy loss \cite{ridnik2021,grivas2024}. The model's output is a $|C|$-dimensional vector, $\hat{y}$, in which each value represents an independent likelihood estimation for one of the $|C|$ compositions to be optimal.%
\footnote{We refrain from a multi-class setup, where the optimal composition is determined over a probability distribution spanning all compositions to avoid a few dominant compositions from possibly being preferred over others consistently.}

\paragraph{Adaptive Prompting}
Given an unknown text, the composition with the highest likelihood is assumed to be an optimal prompt composition $c_o$, where $o := \argmax(\hat{y})$. Thereby, we adaptively select a prompt depending on the text at hand.

\subsection{Shapley-Based Composition Analysis}

Analyzing the impact of individual prompting techniques and their interactions is crucial to evaluate outputs of the adaptive prompting model. To gain these insights, we rely on Shapley values  \cite{shapley1953}, modeling the predictive performance across all possible compositions as a cooperative game:

\paragraph{Prompt Composition Game}
Given the set of techniques $T$, let $\nu: 2^T \to \mathbb{R}$ be the performance of the techniques $T_c \subseteq T$ of a composition $c$:
\begin{equation}\label{def-prompt-composition}
    \nu(c) := \lambda(y,\hat y_c)
\end{equation}
Here, $\lambda$ is a performance metric, $y$ are the ground-truth bias labels, and $\hat y_c$ the predictions of $c$.
For techniques in $T_2$, a specific choice must be fixed.

We compute one Shapley value (SV) for each prompting technique $t \in T$, which provides contribution values $\phi(t)$. The SV quantifies the impact of a prompting technique across all possible compositions.
Beyond individual contributions, we compute pairwise Shapley interactions
\cite{Lundberg.2020} that additionally assign contributions to all pairs of techniques. Shapley interactions (SIs) reveal \emph{synergies} and \emph{redundancies} among prompting techniques, capturing the behavior of the game with greater fidelity \cite{Tsai.2022,fumagalli2024kernelshapiq}. Akin to Shapley-based feature or data selection \cite{Rozemberczki2022}, we select optimal compositions based on SVs and SIs.
