\section{Introduction}
\label{sec:introduction}

The development of instruction-tuned large language models (LLMs) has led to an increased interest in prompting techniques to augment inputs \cite{tian2024}. Whereas prompts for earlier generative language models consisted only of the input text and special tokens \cite{radford2018,raffel2020}, they may now encompass complex and explicit task instructions with ancillary information. Among others, successful prompting techniques include personas \cite{liu2024}, in-context demonstrations \cite{liu2023,dong2024}, and reasoning steps \cite{wei2022}.

\bsfigure{composition-example}{Exemplary excerpt of a prompt composition for social bias detection. While certain techniques might benefit detection performance (say, those with green squares), others might not (red squares). Some parts always need to be present (blue squares). A full prompt example is shown in Figure~\ref{fig:example-prompt}.}


The success and applicability of prompting techniques does, however, depend on several parameters, including the target task, the language model and its size, %
and the context provided \cite{brown2020,schick2021,mosbach2023,dong2024,arroyo2024}.
Finding an effective prompt is, therefore, often still a time-consuming process that needs re-evaluation should any of the parameters change. Recent automated prompting methods either address the lexical aspect by finding the best formulation \cite{honovich2023} or manipulate the latent space \cite{liu2022a}. Most automatic methods, however, focus on optimizing a single technique and do not consider a composition of techniques that could take advantage of their individual strengths.

The example in Figure~\ref{composition-example} visualizes a prompt composition of several techniques. While a \emph{definition} provides a theoretical background, \emph{in-context demonstrations} clarify its application. As recent works indicate that LLMs cannot attend equally to all available information \cite{liu2024a,plepi2024}, simply using more techniques may add noise and reduce performance. Finding an optimal prompt composition is, therefore, desirable.

To this end, we propose an \textit{adaptive prompting} approach to predict the optimal composition of discrete prompt techniques \emph{ad-hoc}, i.e., for each input instance. First, an encoder model learns to predict \textit{optimal compositions} based on a pool of individual prompting techniques. Consecutively, the approach predicts the best composition for each instance and prompts the LLM accordingly.

We evaluate adaptive prompting for five techniques and their compositions for the task of social bias detection. The task requires semantic understanding and world knowledge \cite{zhou2023a}, likely benefitting from using multiple prompting techniques, making it a good candidate to evaluate prompt compositions. To better understand the importance of each technique and their second-order interactions, we further conduct a Shapley interaction analysis \cite{fumagalli2023}.

We test our adaptive prompting approach on three social bias datasets for three open-weight LLMs, namely Mistral (7B) \cite{jiang2023}, Command-R (35B) \cite{cohereforai2024}, and Llama 3 (70B) \cite{dubey2024}. We compare to baselines within and across datasets, including a fine-tuned model and a composition ensemble. The results suggest that our approach robustly ensures high classification performance; in many cases, it even outperforms all baselines and fixed compositions. Moreover, follow-up experiments on three other NLP tasks stress the generalizability of our approach beyond social bias.

To summarize, our main contributions are:
\begin{itemize}
\setlength{\itemsep}{0pt}
    \item We present a novel discrete prompt optimization approach to predict the optimal prompt composition for a given model and input. It improves over several baselines and individual prompting techniques on selected datasets.
    \item We evaluate the utility of generative LLMs and prompting for social bias detection for three state-of-the-art LLMs on three datasets and with five prompting techniques.
    \item We provide insights into the performance and interaction of prompting techniques, finding that well-performing techniques can also interact negatively when used with others.%
\footnote{Code at: \url{https://github.com/webis-de/NAACL-25}.}
\end{itemize}
