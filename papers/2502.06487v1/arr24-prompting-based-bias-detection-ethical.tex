\section*{Ethical Considerations}
\label{sec:ethical}

We aim to contribute towards a better detection of social biases in texts using current LLMs, considering different aspects, definitions, and scenarios of social bias by including diverse datasets. While this can be seen as a starting point towards a more reliable social bias detection, it is not a comprehensive evaluation of potential real-world scenarios. Therefore, the developed and published tools and data are research artifacts that are not ready for production. We, therefore, see the possibility that, when applied in real-world scenarios, the systems developed might elicit a false sense of trust in texts regarding their level of social bias, for example, due to misclassifications.

Another noteworthy aspect of this study is the environmental footprint. As discussed above, our experiments are extensive and require many GPU hours to be conducted. We, therefore, contributed to the growing carbon footprint of LLMs. However, we are confident that the data gathered can contribute towards using fewer computational resources, as predicting a prompt composition is computationally efficient (i.e., inference with a pre-trained model) and avoids constant re-prompting to find the best prompt. Furthermore, we hope that the publication of models and data helps to avoid the need to redo such experiments in the near future.
