\section{RELATED WORK}
In application scenarios such as virtual reality (VR) and augmented reality (AR), gesture recognition systems must capture and interpret gestures on edge devices as quickly as possible ____. This stringent real-time requirement arises not only from limited power and computing resources, but also from the need to simultaneously handle tasks such as spatial localization, motion tracking, and multi-channel interaction ____. If the recognition process is delayed until after the gesture ends, users may experience discomfort, and the immersion and fluidity required for VR/AR interaction will be compromised ____. Consequently, achieving stable real-time gesture recognition on these edge devices has become a pressing technical challenge. The following content briefly reviews algorithmic designs in the field of gesture recognition and extends to relevant real-time research.

\subsection{Deep Learning in Gesture Recognition}
Many technologies introduced from other domains into gesture recognition often overlook custom optimizations for edge devices and continue to rely on generalized model designs and neural network architectures. A common practice is to adopt window-based methods for processing continuous input ____, where raw frames are stacked over a certain time span to capture contextual information along the temporal dimension ____. However, an excessively large window significantly increases model size and latency, while a window that is too small fails to provide sufficient temporal context; frame-based approaches, as an extreme case (window size of 1), are nearly incapable of recognizing dynamic gestures ____. Moreover, for VR/AR devices requiring high-frequency interaction, pixel-based sliding window approaches impose additional costs for buffering raw video data, and this burden is projected to expand further with the advent of next-generation ultra-high-definition standards such as 8K.

At the algorithmic level, existing research primarily concentrates on CNN, LSTM, Transformer, and GNN architectures ____. While CNNs offer automatic feature extraction and often involve fewer parameters, convolutional operations can be time-consuming ____. LSTMs excel at capturing temporal dependencies but typically rely on larger parameter sets ____. Transformers can model long-range dependencies and allow parallel computation, yet their computation remains considerable when handling linear, streaming inputs in real-world scenarios ____. GNNs are suitable for modeling skeletal data but demand manually designed preprocessing and graph generation pipelines, making direct adaptation to diverse settings challenging ____. Consequently, most of these methods still require multiple frames to be accumulated within a window for stable training and inference, falling short of the real-time requirements on edge devices.

Another challenge for real-time recognition lies in the need to repeatedly invoke the model on the input stream ____. When gestures are sparse and irregular, window-based recognition systems must frequently perform inference to align with potential incoming gestures ____, which boosts recall but also raises false positive rates. To suppress false positives, some window-based approaches introduce lengthy “ignore periods” ____, resulting in delayed recognition or even missed detections and conflicting with low-latency requirements. In scenarios demanding high recall, relying heavily on windows and frequent model invocation creates a dilemma between latency and accuracy.

In recent years, to balance performance and real-time needs, researchers have integrated deep learning with various data sources by leveraging ultrasound ____ or electromyography (EMG) ____ as event-driven inputs to support recognition, or adopting knowledge distillation, quantization, and pruning to deploy lightweight models ____. Meanwhile, some studies focus on the robustness of actual deployments—considering factors such as environmental lighting, background complexity, and user variability ____—and employ adaptive or transfer learning ____ to maintain accuracy and real-time performance. Overall, deep learning methods have already demonstrated strong capabilities in gesture recognition, including CNNs for visual feature extraction and LSTMs for capturing temporal dependencies ____. Key directions for further improvement include multi-stream architectures ____, lightweight designs ____, and adaptive technologies ____. Nonetheless, in high-interaction yet resource-constrained scenarios like VR/AR, it remains necessary to further reduce latency, power consumption, and storage requirements.

\subsection{Streaming Model}

Streaming methods prioritize real-time performance and have been extensively studied in areas such as speech recognition and autonomous driving, offering important references for gesture recognition. Unlike batch-based approaches, streaming models aim to produce predictions immediately upon data arrival, significantly reducing latency and enabling continuous online inference ____.

In speech recognition, the Recurrent Neural Network Transducer (RNN-T) has been specifically optimized for low-latency scenarios by processing inputs incrementally, eliminating the need to wait for the complete sequence before generating outputs ____. Some variants of RNN-T also introduce boundary-aware training strategies that restrict the evaluation scope to key regions, reducing computational overhead and improving speed ____. Meanwhile, in streaming Attention Encoder-Decoder (AED) models, a technique known as monotonic attention sequentially focuses only on the relevant parts of the input, thus reducing repeated access to earlier segments and lowering computational load and latency ____.

In the field of autonomous driving, some studies have adapted existing mature visual recognition schemes to implement streaming models. For instance, multispectral pedestrian detection based on the YOLOv4 architecture leverages lightweight design to achieve efficient computation and low latency ____. In addition, for efficient motion prediction, researchers have introduced a simplified Transformer architecture—reducing pre-training complexity and combining simple linear and Transformer layers to shorten prediction time and cut resource consumption ____.

Similar approaches are gradually being applied to gesture recognition ____, where models can parse incoming frames continuously upon data arrival, eliminating the need to wait for a full window and thus outputting predictions with minimal delay. Once integrated with lightweight neural networks or incremental learning techniques ____ at the system level, this method may overcome the high-latency bottleneck of traditional batch-based inference. Moreover, tree models (e.g., Hoeffding trees), online linear models ____, and adaptive ensemble approaches can handle concept drift in dynamic environments. Finally, incorporating physiological signals ____ or multimodal information ____ may further enhance overall performance while enabling early recognition.