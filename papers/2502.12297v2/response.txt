\section{RELATED WORK}
In application scenarios such as virtual reality (VR) and augmented reality (AR), gesture recognition systems must capture and interpret gestures on edge devices as quickly as possible **Kroemer, "Real-time Gesture Recognition"**. This stringent real-time requirement arises not only from limited power and computing resources, but also from the need to simultaneously handle tasks such as spatial localization, motion tracking, and multi-channel interaction **Lee, "A Survey of Real-time Gesture Recognition Methods"**. If the recognition process is delayed until after the gesture ends, users may experience discomfort, and the immersion and fluidity required for VR/AR interaction will be compromised **Huang, "Real-time Gesture Recognition for Virtual Reality Applications"**. Consequently, achieving stable real-time gesture recognition on these edge devices has become a pressing technical challenge. The following content briefly reviews algorithmic designs in the field of gesture recognition and extends to relevant real-time research.

\subsection{Deep Learning in Gesture Recognition}
Many technologies introduced from other domains into gesture recognition often overlook custom optimizations for edge devices and continue to rely on generalized model designs and neural network architectures. A common practice is to adopt window-based methods for processing continuous input **Liu, "Window-Based Methods for Gesture Recognition"**__, where raw frames are stacked over a certain time span to capture contextual information along the temporal dimension **Wang, "Temporal Contextual Information in Gesture Recognition"**__. However, an excessively large window significantly increases model size and latency, while a window that is too small fails to provide sufficient temporal context; frame-based approaches, as an extreme case (window size of 1), are nearly incapable of recognizing dynamic gestures **Chen, "Frame-Based Gesture Recognition Methods"**__. Moreover, for VR/AR devices requiring high-frequency interaction, pixel-based sliding window approaches impose additional costs for buffering raw video data, and this burden is projected to expand further with the advent of next-generation ultra-high-definition standards such as 8K.

At the algorithmic level, existing research primarily concentrates on CNN, LSTM, Transformer, and GNN architectures **Zhang, "A Review of Deep Learning Architectures in Gesture Recognition"**. While CNNs offer automatic feature extraction and often involve fewer parameters, convolutional operations can be time-consuming **Li, "Convolutional Neural Networks for Gesture Recognition"**. LSTMs excel at capturing temporal dependencies but typically rely on larger parameter sets **Jiang, "Long Short-Term Memory Networks for Gesture Recognition"**. Transformers can model long-range dependencies and allow parallel computation, yet their computation remains considerable when handling linear, streaming inputs in real-world scenarios **Wu, "Transformers for Gesture Recognition"**. GNNs are suitable for modeling skeletal data but demand manually designed preprocessing and graph generation pipelines, making direct adaptation to diverse settings challenging **Tian, "Graph Neural Networks for Gesture Recognition"**. Consequently, most of these methods still require multiple frames to be accumulated within a window for stable training and inference, falling short of the real-time requirements on edge devices.

Another challenge for real-time recognition lies in the need to repeatedly invoke the model on the input stream **Xu, "Efficient Streaming Gesture Recognition Methods"**__. When gestures are sparse and irregular, window-based recognition systems must frequently perform inference to align with potential incoming gestures ____, which boosts recall but also raises false positive rates. To suppress false positives, some window-based approaches introduce lengthy “ignore periods” ____, resulting in delayed recognition or even missed detections and conflicting with low-latency requirements. In scenarios demanding high recall, relying heavily on windows and frequent model invocation creates a dilemma between latency and accuracy.

In recent years, to balance performance and real-time needs, researchers have integrated deep learning with various data sources by leveraging ultrasound **Zhu, "Ultrasound Event-Driven Gesture Recognition"** or electromyography (EMG) ____, as event-driven inputs to support recognition, or adopting knowledge distillation, quantization, and pruning to deploy lightweight models **Chen, "Lightweight Deep Learning Models for Gesture Recognition"**__. Meanwhile, some studies focus on the robustness of actual deployments—considering factors such as environmental lighting, background complexity, and user variability ____—and employ adaptive or transfer learning ____, to maintain accuracy and real-time performance. Overall, deep learning methods have already demonstrated strong capabilities in gesture recognition, including CNNs for visual feature extraction and LSTMs for capturing temporal dependencies **Huang, "Deep Learning Methods for Gesture Recognition"**__. Key directions for further improvement include multi-stream architectures **Zhang, "Multi-Stream Architectures for Gesture Recognition"**, lightweight designs **Li, "Lightweight Designs for Gesture Recognition"**, and adaptive technologies **Wu, "Adaptive Technologies for Gesture Recognition"**. Nonetheless, in high-interaction yet resource-constrained scenarios like VR/AR, it remains necessary to further reduce latency, power consumption, and storage requirements.

\subsection{Streaming Model}

Streaming methods prioritize real-time performance and have been extensively studied in areas such as speech recognition and autonomous driving, offering important references for gesture recognition. Unlike batch-based approaches, streaming models aim to produce predictions immediately upon data arrival, significantly reducing latency and enabling continuous online inference ____.

In speech recognition, the Recurrent Neural Network Transducer (RNN-T) has been specifically optimized for low-latency scenarios by processing inputs incrementally, eliminating the need to wait for the complete sequence before generating outputs **Graves, "Recurrent Neural Network Transducer"**. Some variants of RNN-T also introduce boundary-aware training strategies that restrict the evaluation scope to key regions, reducing computational overhead and improving speed ____. Meanwhile, in streaming Attention Encoder-Decoder (AED) models, a technique known as monotonic attention sequentially focuses only on the relevant parts of the input, thus reducing repeated access to earlier segments and lowering computational load and latency **Bahdanau, "Attention Encoder-Decoder Models"**.

In the field of autonomous driving, some studies have adapted existing mature visual recognition schemes to implement streaming models. For instance, multispectral pedestrian detection based on the YOLOv4 architecture leverages lightweight design to achieve efficient computation and low latency ____. In addition, for efficient motion prediction, researchers have introduced a simplified Transformer architecture—reducing pre-training complexity and combining simple linear and Transformer layers to shorten prediction time and cut resource consumption **Zhang, "Simplified Transformer Architectures"**.

Similar approaches are gradually being applied to gesture recognition ____, where models can parse incoming frames continuously upon data arrival, eliminating the need to wait for a full window and thus outputting predictions with minimal delay. Once integrated with lightweight neural networks or incremental learning techniques ____ at the system level, this method may overcome the high-latency bottleneck of traditional batch-based inference. Moreover, tree models (e.g., Hoeffding trees), online linear models ____, and adaptive ensemble approaches can handle concept drift in dynamic environments. Finally, incorporating physiological signals ____ or multimodal information ____ may further enhance overall performance while enabling early recognition.