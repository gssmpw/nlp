\section{Related Work}
\label{sec:relwork}

\paragraph{Dialog games}

Various forms of dialog reference games have been known in linguistics since a long time **Brewer, "Dialogue Games"**.
In computer science, prior work on multimodal dialog games is primarily focused on collecting datasets of grounded dialogs **Henderson et al., "Discourse Generation for Grounded Dialogue Systems"** or more recently, evaluating the capabilities of VLMs **Radford et al., "Learning to Generate Long-Term Structured Representations for Conversational AI"**.  
These existing games vary in design, including the number of images involved (single or multiple), the roles of the agents (symmetric, sharing the same goal, or asymmetric), and the interaction length (single-turn or multi-turn).

In contrast to these evaluation and data collection efforts, our work leverages dialog games for self-improvement, creating synthetic datasets to enhance VLM capabilities.
To the best of our knowledge, this is a novel use of the dialog games.

\paragraph{Self-Improvement}

Self-improvement **Brown et al., "Measuring Massive Multitask Learning"** techniques have gained significant interest in both language and multimodal learning.
A prevalent approach involves using an LLM to critique and refine its own responses **Raffel et al., "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"**.
For instance, **Zhang et al., "Improving Language Understanding by Generative Reasoning"** demonstrate that fine-tuning on self-generated rationale-augmented answers, without ground truth labels, enhances LLM reasoning. 
**Pang et al., "Meta-Learning for Multimodal Dialogue Systems with Transferable Representations"** propose a multi-agent framework where diverse responses from a society of LLMs drive iterative fine-tuning and continuous improvement.

Self-improvement has also shown promise in enhancing multimodal understanding of VLMs, albeit with fewer existing studies.
A prominent technique in VLM self-improvement is cycle consistency, initially developed for image-to-image translation **Zhu et al., "Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks"**.
It enforces that a transformation from a source domain to a target domain, and back, yields an output similar to the input.
This principle has been successfully extended to the multimodal domain **Chen et al., "Cycle-Consistent Multimodal Translation with Self-Supervised Learning"**, often exploiting the symmetry between image captioning and text-to-image generation.
Cycles such as text1 $\rightarrow$ image  $\rightarrow$ text2 or image1  $\rightarrow$ text  $\rightarrow$ image2 aim to ensure similarity between the initial and final elements (text1 \& text2, or image1 \& image2) while producing data for self-improvement. 
Cycle consistency is particularly valuable when paired text-image data is limited **Alayrac et al., "Worlds in Miniature: Multi-Task Learning of Image Generation and Representation"**, but can also facilitate the generation of novel image compositions with abundant data **Zhang et al., "Compositional GANs for Multimodal Compositions"**. 
Another approach to improving VMLs performance is through generating synthetic datasets by eliciting detailed question-answer datasets **Xu et al., "Question-Answering Game for Multimodal Dialogue Systems"**.
Furthermore, self-improvement in VLMs is often tailored to specific applications, such as medical imaging, where data acquisition is challenging **Chen et al., "Medical Image Generation with Cycle-Consistent Adversarial Networks"**.

In contrast to many LLM self-improvement methods that rely on agent-based response generation and critique, we propose a novel self-improvement framework based on games. 
While inspired by the underlying principle of cycle consistency, our approach deviates from the traditional image-text-image cycle.
Instead of direct image generation, we map a target image to a dialog, and then back to the target image through contrastive image selection thus eliminating the need for text-to-image model.