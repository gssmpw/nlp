\section{Method}
\label{sec:method}

This section introduces our method for iterative self-improvement through VLM Dialog Games.
We first describe the VLM Dialog Game mechanism and its key properties: self-play and goal-oriented nature, which are crucial for self-improvement (Section~\ref{method:game-desc}).
We then detail the complete self-improvement workflow, including game setup, dialog generation and filtering, model finetuning, final evaluation on the target task, and potentially repeating these steps (Section~\ref{method:workflow}).

\subsection{VLM Dialog Game Description}
\label{method:game-desc}

We introduce a VLM Dialog Game which is constructed using unlabelled images and two VLM agents.
The first agent, the \textbf{Describer}, is presented with a single target image and is instructed to faithfully answer questions about it. 
The second agent, the \textbf{Guesser}, receives a set of $N$ images, including the target image and several distractor images.
The \textbf{Guesser}'s objective is to identify the target image by posing questions to the \textbf{Describer}.
The agents' behaviour is controlled by prompting mechanism for VLMs which is described further in Section~\ref{method:impldet}.

Figure~\ref{fig:game-example} shows an illustrative example of the VLM Dialog Game in action. 
All images that the Guesser sees contain white and blue objects on an orange background, thus, to identify the target image the Guesser should focus on more specific properties of the images.
To disambiguate, the Guesser initiates a series of clarifying questions, such as "How many objects can you see?" and "Are the objects squares or circles?".
Once the responses uniquely define the target image (in this case, by pointing to "\num{9} square objects"), the Guesser successfully identifies it.
While resembling a classic reference game used for human data collection and VLM evaluation, this specific design features two key elements enabling VLM self-improvement: self-play for data generation and automatic success determination.

\paragraph{Self-play}
Current VLMs, thanks to their instruction-following capabilities, demonstrate a non-trivial success rate in playing this dialog game \citep{hakimov2024usinggameplayinvestigate}.
This capability enables a scalable approach to data collection through self-play of two prompted models.

\paragraph{Success Determination}
We use the Guesser's final selection to determine the success of the dialog: If the selected image matches the target image, the dialog is considered successful and added to the synthetic training data, otherwise it is discarded. 
This mechanism provides crucial, automatic quality control.

\subsection{Workflow}
\label{method:workflow}

The properties of the VLM Dialog Game enable the following workflow for self-improvement:

\begin{itemize}
    \item \textbf{Game setup}: Configure the dialog game with a designated unlabelled image dataset.
    \item \textbf{Dialog generation}: Generate dialogs via self-play between the VLM agents.
    \item \textbf{Dialog filtering}: Filter generated dialogs based on the success criteria.
    \item \textbf{Model improvement}: Fine-tune the VLM using the filtered dialog data and evaluate its performance on the target task.
    \item \textbf{Repeat the above steps (if needed)}: Repeat dataset generation with an improved version of VLM.
\end{itemize}

\subsubsection{Game Setup}
\label{method:impldet}

This section details the setup of the VLM Dialog Game, including agent instructions and image selection strategies.

\paragraph{Agent instructions}
We provide precise instructions to both the Describer and Guesser agents to guide their interaction in the game. 
The Describer is instructed to answer questions about the target image truthfully and accurately.
The Guesser agent operates in two stages:

\begin{enumerate}
    \item Questioning/Guessing: Initially provided with an empty image description, the Guesser must either:
    \begin{itemize}
        \item Ask a clarifying question to distinguish the target image from the distractors, or
        \item Make a guess identifying image X as the target image where X is the index of the hypothesized target image among the distractors.
    \end{itemize}
    \item Summarisation: The Guesser must create a concise summary of the target image description given the initial image description (or the previous summary), a question and an answer.
\end{enumerate}
Specific prompt texts for both agents are provided in Appendix~\ref{game-prompts}.

\paragraph{Image selection and game difficulty}
The images used in the game can be sourced from various datasets, including general datasets of natural images like OpenImages~\citep{kuznetsova2020openimages} or DOCCI~\citep{OnoeDocci2024}, or domain-specific datasets tailored to applications such as robotics~\citep{zhao2023learning}.
The game's difficulty is controlled through two primary factors related to which images are selected for a game:
\begin{itemize}
    \item Number of distractors: Increasing the number of distractor images directly increases difficulty. This is due to: (1) the Guesser needing to attend to a larger context, and (2) an increased likelihood of a distractor closely resembling the target image.
    \item Image similarity in each game: Randomly selecting images from the dataset creates an easier game, while grouping visually or semantically similar images increases the challenge.
\end{itemize}

We select the appropriate settings in the game so that the games are sufficiently difficult to produce interesting dialogs, but still feasible so that we generate sufficient amount of synthetic training data.

\subsubsection{Dialog Generation}
During this stage, the Describer and Guesser agents engage in an interactive dialog.
We construct the training dataset from examples of successful behavior by both the Describer and the Guesser:
\begin{itemize}
    \item \textbf{Describer examples.} Input: a single image and a question about it; Output: the corresponding answer.
    \item \textbf{Guesser examples.} Input: $N$ images (including the target and distractors) and a cumulative summary of the target image description; Output: either a clarifying question or a guess identifying the target image.
\end{itemize}
Each successful VLM Dialog Game generates multiple training examples of both types.

\subsubsection{Dialog Filtering}
\label{method-filtering}

The game's design allows us to directly verify the Guesser's final selection.
However, to mitigate the possibility of correct guess occurring by chance, we perform an additional validation step. 
We re-run the dialog without the final selection using the same images but in a permuted order and verify that the correct target image is identified in all cases.
Empirically, we observed that the position of the \textit{target} image has the most significant impact on the Guesser's accuracy, while the relative order of the distractors (given a fixed dialog) has a smaller effect.
Therefore, for computational efficiency we limit the tested permutations to $N$ where we ensure that the target image appears at each possible position (\num{1} to $N$), while the distractors order can remain fixed.
The datapoints from these consistently successful games form the filtered dataset for subsequent model training.

\subsubsection{Model Improvement}

The filtered dataset from successful dialog games is then used to fine-tune the VLM in a standard supervised fine-tuning way.
If the gains in playing the VML Dialog Games are large, we can use the improved model in order to collect the new synthetic dataset for further model improvement.
While this process directly affects the VLM's performance within the dialog game itself, our primary focus is on evaluating its capabilities on downstream tasks.
For instance, if the dialog game utilizes images from a robotics domain, we assess the fine-tuned VLM's performance on tasks such as robotic success detection, and for general images we test the performance on visual question answering (VQA) on the unseen images.