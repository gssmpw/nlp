@article{bai2022constitutional,
  title={Constitutional {AI}: Harmlessness from {AI} feedback},
  author={Bai, Yuntao and Kadavath, Saurav and Kundu, Sandipan and Askell, Amanda and Kernion, Jackson and Jones, Andy and Chen, Anna and Goldie, Anna and Mirhoseini, Azalia and McKinnon, Cameron and others},
  journal={arXiv:2212.08073},
  year={2022}
}

@inproceedings{chalamalasetti2023clembench,
  title={clembench: Using Game Play to Evaluate Chat-Optimized Language Models as Conversational Agents},
  author={Chalamalasetti, Kranti and G{\"o}tze, Jana and Hakimov, Sherzod and Madureira, Brielen and Sadler, Philipp and Schlangen, David},
  booktitle={EMNLP},
  year={2023}
}

@inproceedings{chen2024selfplay,
title={Self-Play Fine-Tuning Converts Weak Language Models to Strong Language Models},
author={Zixiang Chen and Yihe Deng and Huizhuo Yuan and Kaixuan Ji and Quanquan Gu},
booktitle={ICML},
year={2024}
}

@inproceedings{das2017visual,
  title={Visual dialog},
  author={Das, Abhishek and Kottur, Satwik and Gupta, Khushi and Singh, Avi and Yadav, Deshraj and Moura, Jos{\'e} MF and Parikh, Devi and Batra, Dhruv},
  booktitle={CVPR},
  year={2017}
}

@inproceedings{de2017guesswhat,
  title={Guesswhat?! visual object discovery through multi-modal dialogue},
  author={De Vries, Harm and Strub, Florian and Chandar, Sarath and Pietquin, Olivier and Larochelle, Hugo and Courville, Aaron},
  booktitle={CVPR},
  year={2017}
}

@inproceedings{haber2019photobook,
    title = "The {P}hoto{B}ook Dataset: Building Common Ground through Visually-Grounded Dialogue",
    author = {Haber, Janosch  and Baumg{\"a}rtner, Tim  and Takmaz, Ece  and Gelderloos, Lieke  and Bruni, Elia  and Fern{\'a}ndez, Raquel},
    booktitle = "ACL",
    year = "2019",
}

@article{hakimov2024usinggameplayinvestigate,
      title={Using Game Play to Investigate Multimodal and Conversational Grounding in Large Multimodal Models}, 
      author={Sherzod Hakimov and Yerkezhan Abdullayeva and Kushal Koshti and Antonia Schmidt and Yan Weiser and Anne Beyer and David Schlangen},
      year={2024},
      journal={arXiv:2406.14035},
}

@inproceedings{huang2022large,
  title={Large language models can self-improve},
  author={Huang, Jiaxin and Gu, Shixiang Shane and Hou, Le and Wu, Yuexin and Wang, Xuezhi and Yu, Hongkun and Han, Jiawei},
  booktitle={EMNLP},
  year={2023}
}

@article{krauss1964changes,
  title={Changes in reference phrases as a function of frequency of usage in social interactions},
  author={Krauss, RM and Weinheimer, S},
  journal={Psychonomic Science},
  year={1964}
}

@inproceedings{li2023dalle,
  title={Do {DALL-E} and {F}lamingo understand each other?},
  author={Li, Hang and Gu, Jindong and Koner, Rajat and Sharifzadeh, Sahand and Tresp, Volker},
  booktitle={ICCV},
  year={2023}
}

@article{li2023leveraging,
  title={Leveraging Unpaired Data for Vision-Language Generative Models via Cycle Consistency},
  author={Li, Tianhong and Bhardwaj, Sangnie and Tian, Yonglong and Zhang, Han and Barber, Jarred and Katabi, Dina and Lajoie, Guillaume and Chang, Huiwen and Krishnan, Dilip},
  journal={arXiv 2310.03734},
  year={2023}
}

@inproceedings{luu2024questioning,
  title={Questioning, Answering, and Captioning for Zero-Shot Detailed Image Caption},
  author={Luu, Duc-Tuan and Le, Viet-Tuan and Vo, Duc Minh},
  booktitle={Proceedings of the Asian Conference on Computer Vision},
  year={2024}
}

@article{sharifzadeh2024synth,
  title={Synth$^2$: Boosting Visual-Language Models with Synthetic Captions and Image Embeddings},
  author={Sharifzadeh, Sahand and Kaplanis, Christos and Pathak, Shreya and Kumaran, Dharshan and Ilic, Anastasija and Mitrovic, Jovana and Blundell, Charles and Banino, Andrea},
  journal={arXiv:2403.07750},
  year={2024}
}

@article{subramaniam2025multiagent,
  title={Multiagent Finetuning: Self Improvement with Diverse Reasoning Chains},
  author={Subramaniam, Vighnesh and Du, Yilun and Tenenbaum, Joshua B and Torralba, Antonio and Li, Shuang and Mordatch, Igor},
  journal={arXiv:2501.05707},
  year={2025}
}

@article{wang2024self,
  title={Self-improving generative foundation model for synthetic medical image generation and clinical applications},
  author={Wang, Jinzhuo and Wang, Kai and Yu, Yunfang and Lu, Yuxing and Xiao, Wenchao and Sun, Zhuo and Liu, Fei and Zou, Zixing and Gao, Yuanxu and Yang, Lei and others},
  journal={Nature Medicine},
  year={2024},
  publisher={Nature Publishing Group}
}

@inproceedings{yuan2024selfrewarding,
title={Self-Rewarding Language Models},
author={Weizhe Yuan and Richard Yuanzhe Pang and Kyunghyun Cho and Xian Li and Sainbayar Sukhbaatar and Jing Xu and Jason E Weston},
booktitle={ICML},
year={2024},
}

@inproceedings{zhu2017cyclegan,
  title={Unpaired image-to-image translation using cycle-consistent adversarial networks},
  author={Zhu, Jun-Yan and Park, Taesung and Isola, Phillip and Efros, Alexei A},
  booktitle={ICCV},
  year={2017}
}

