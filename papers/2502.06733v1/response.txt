\section{Related work}
\vspace{-3mm}
\textbf{Training Data Re-weighting/Selection for LLMs.}
Several recent studies **Devlin, "BERT Pre-Training of Deep Bidirectional Transformers for Language Understanding"**__**Howard, "Universal Language Model Fine-tuning for Text Classification"**__**Phang et al., "Sentence-Embeddings with Subword POS Tagging and Enriched Lexicon"**
have explored various reweighting techniques to enhance the generalization and efficiency of language models pretraining. For instance, **Liakos et al., "Towards Optimal Weighting for Pre-training Neural Language Models"**__**Zhang et al., "Adversarial Training on Pre-trained Monolingual and Multilingual Models"**__**Kim et al., "Improving Word Embeddings with a Novel Data Selection Method"**
optimize the composition of pretraining corpora to achieve better performance across pretraining domains or for out-of-domain generalization. **Liu et al., "A Framework for Ordered Skill Learning in Continual Pre-training and Fine-tuning Regimes"**
introduce a framework for ordered skill learning, optimizing data selection based on how effectively it teaches interdependent skills for continual pretraining and fine-tuning regimes. Although effective, these techniques operate at the group level, whereas our work explores reweighting at the instance level, offering finer control over how individual samples are treated based on their loss values. Furthermore, we demonstrate that combining domain-level methods such as DoReMi **Li et al., "Domain Knowledge Enhanced Pre-training for Adversarial Robustness"** or DoGE **Hao et al., "DoGE: Domain Guided Entity Embedding"**
with our instance-level reweighting methods results in improved performance across multiple domains.
Instance-level reweighting has been used in post-training settings of LLMs ____ boost the self-improvement abilities of LLMs by employing sample reweighting to filter out self-generated data that have correct answers but exhibit high distribution shifts. **Zhang et al., "Self-Improving Neural Language Models for Adversarial Robustness"**
reweight individual samples during continual training/instruction-tuning to focus on medium-loss samples. In contrast, our work systematically studies the effects of various sample-level, loss-based reweighting strategies on the efficiency and effectiveness of LLMs \emph{pretraining}.
The approach in **Liu et al., "A Curriculum Learning Framework for Pre-training Neural Language Models"**
offers a curriculum learning framework that prioritizes samples with a higher learnability score, which is precomputed using another auxiliary model similar to DoReMi and DoGE. While we do not explicitly address curriculum learning in this work, our re-weighting mechanisms naturally allow for implementing a form of loss-based curriculum learning algorithms without the need to train and store additional proxy models as in ____.
 
\textbf{Sample-level Re-weighting as generic ML solution.} 
Sample-level reweighting has been extensively explored in other machine learning areas. For image classification, **Cui et al., "Training Deep Neural Networks with Sampling"**__**Wang et al., "Data Sampling and Distribution Adaptation for Image Classification"**__**He et al., "A Novel Data Sampling Method for Accelerating Training Speed"**
introduce pioneering approaches that prioritize samples based on loss values or gradient norms with the goal of accelerating training speed. Although these methods emphasize the importance of selecting high-loss samples during training, they typically require additional forward/backward passes on each training sample and are primarily designed for multi-epoch training, limiting their applicability with the vast pretraining corpus used for LLMs. Using bilevel optimization, **Zhang et al., "Adaptation of Data Distribution using Bilevel Optimization"**
adapt the data distribution during training to focus more on relevant samples for a target data distribution. Similarly, ____ employ a meta-learning approach to adjust sample weights based on validation set performance, which excels in noisy and imbalanced datasets. In this work, we introduce and investigate various lightweight, loss-based reweighting techniques that add little to no computational overhead compared to uniform sampling and do not require any nested optimization routines, often arising with bilevel optimization and/or meta-learning.
Sample-level reweighting has also been explored in the context of adversarial machine learning ____ , domain adaptation ____ , data augmentation ____ , and imbalanced classification ____ . Our reweighting mechanisms also have the potential to be studied under these contexts, which we leave as future work.