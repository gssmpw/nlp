[
  {
    "index": 0,
    "papers": [
      {
        "key": "xie2023doremi",
        "author": "Xie, Sang Michael and Pham, Hieu and Dong, Xuanyi and Du, Nan and Liu, Hanxiao and Lu, Yifeng and Liang, Percy and Le, Quoc V and Ma, Tengyu and Yu, Adams Wei",
        "title": "DoReMi: Optimizing Data Mixtures Speeds Up Language Model Pretraining"
      },
      {
        "key": "chen2023skill",
        "author": "Mayee F Chen and Nicholas Roberts and Kush Bhatia and Jue WANG and Ce Zhang and Frederic Sala and Christopher Re",
        "title": "Skill-it! A data-driven skills framework for understanding and training language models"
      },
      {
        "key": "fan2023doge",
        "author": "Simin Fan and Matteo Pagliardini and Martin Jaggi",
        "title": "{DOGE}: Domain Reweighting with Generalization Estimation"
      },
      {
        "key": "thakkar2023self",
        "author": "Thakkar, Megh and Bolukbasi, Tolga and Ganapathy, Sriram and Vashishth, Shikhar and Chandar, Sarath and Talukdar, Partha",
        "title": "Self-influence guided data reweighting for language model pre-training"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "xie2023doremi",
        "author": "Xie, Sang Michael and Pham, Hieu and Dong, Xuanyi and Du, Nan and Liu, Hanxiao and Lu, Yifeng and Liang, Percy and Le, Quoc V and Ma, Tengyu and Yu, Adams Wei",
        "title": "DoReMi: Optimizing Data Mixtures Speeds Up Language Model Pretraining"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "fan2023doge",
        "author": "Simin Fan and Matteo Pagliardini and Martin Jaggi",
        "title": "{DOGE}: Domain Reweighting with Generalization Estimation"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "chen2023skill",
        "author": "Mayee F Chen and Nicholas Roberts and Kush Bhatia and Jue WANG and Ce Zhang and Frederic Sala and Christopher Re",
        "title": "Skill-it! A data-driven skills framework for understanding and training language models"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "xie2023doremi",
        "author": "Xie, Sang Michael and Pham, Hieu and Dong, Xuanyi and Du, Nan and Liu, Hanxiao and Lu, Yifeng and Liang, Percy and Le, Quoc V and Ma, Tengyu and Yu, Adams Wei",
        "title": "DoReMi: Optimizing Data Mixtures Speeds Up Language Model Pretraining"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "fan2023doge",
        "author": "Simin Fan and Matteo Pagliardini and Martin Jaggi",
        "title": "{DOGE}: Domain Reweighting with Generalization Estimation"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "chen2024take",
        "author": "Chen, Xuxi and Wang, Zhendong and Sow, Daouda and Yang, Junjie and Chen, Tianlong and Liang, Yingbin and Zhou, Mingyuan and Wang, Zhangyang",
        "title": "Take the Bull by the Horns: Hard Sample-Reweighted Continual Training Improves LLM Generalization"
      },
      {
        "key": "jiang2024importance",
        "author": "Jiang, Chunyang and Chan, Chi-min and Xue, Wei and Liu, Qifeng and Guo, Yike",
        "title": "Importance Weighting Can Help Large Language Models Self-Improve"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "jiang2024importance",
        "author": "Jiang, Chunyang and Chan, Chi-min and Xue, Wei and Liu, Qifeng and Guo, Yike",
        "title": "Importance Weighting Can Help Large Language Models Self-Improve"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "chen2024take",
        "author": "Chen, Xuxi and Wang, Zhendong and Sow, Daouda and Yang, Junjie and Chen, Tianlong and Liang, Yingbin and Zhou, Mingyuan and Wang, Zhangyang",
        "title": "Take the Bull by the Horns: Hard Sample-Reweighted Continual Training Improves LLM Generalization"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "fan2023irreducible",
        "author": "Fan, Simin and Jaggi, Martin",
        "title": "Irreducible Curriculum for Language Model Pretraining"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "fan2023irreducible",
        "author": "Fan, Simin and Jaggi, Martin",
        "title": "Irreducible Curriculum for Language Model Pretraining"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "loshchilov2015online",
        "author": "Loshchilov, Ilya and Hutter, Frank",
        "title": "Online batch selection for faster training of neural networks"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "jiang2019accelerating",
        "author": "Jiang, Angela H and Wong, Daniel L-K and Zhou, Giulio and Andersen, David G and Dean, Jeffrey and Ganger, Gregory R and Joshi, Gauri and Kaminksy, Michael and Kozuch, Michael and Lipton, Zachary C and others",
        "title": "Accelerating deep learning by focusing on the biggest losers"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "katharopoulos2018not",
        "author": "Katharopoulos, Angelos and Fleuret, Fran{\\c{c}}ois",
        "title": "Not all samples are created equal: Deep learning with importance sampling"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "grangier2023adaptive",
        "author": "Grangier, David and Ablin, Pierre and Hannun, Awni",
        "title": "Adaptive training distributions with scalable online bilevel optimization"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "ren2018learning",
        "author": "Ren, Mengye and Zeng, Wenyuan and Yang, Bin and Urtasun, Raquel",
        "title": "Learning to reweight examples for robust deep learning"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "zhang2020geometry",
        "author": "Zhang, Jingfeng and Zhu, Jianing and Niu, Gang and Han, Bo and Sugiyama, Masashi and Kankanhalli, Mohan",
        "title": "Geometry-aware instance-reweighted adversarial training"
      },
      {
        "key": "liu2021probabilistic",
        "author": "Liu, Feng and Han, Bo and Liu, Tongliang and Gong, Chen and Niu, Gang and Zhou, Mingyuan and Sugiyama, Masashi and others",
        "title": "Probabilistic margins for instance reweighting in adversarial training"
      },
      {
        "key": "zeng2021adversarial",
        "author": "Zeng, Huimin and Zhu, Chen and Goldstein, Tom and Huang, Furong",
        "title": "Are adversarial examples created equal? A learnable weighted minimax risk for robustness under non-uniform attacks"
      },
      {
        "key": "sow2023doubly",
        "author": "Sow, Daouda and Lin, Sen and Wang, Zhangyang and Liang, Yingbin",
        "title": "Doubly Robust Instance-Reweighted Adversarial Training"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "jiang2007instance",
        "author": "Jiang, Jing  and\nZhai, ChengXiang",
        "title": "Instance Weighting for Domain Adaptation in {NLP}"
      },
      {
        "key": "fang2020rethinking",
        "author": "Fang, Tongtong and Lu, Nan and Niu, Gang and Sugiyama, Masashi",
        "title": "Rethinking importance weighting for deep learning under distribution shift"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "yi2021reweighting",
        "author": "Yi, Mingyang and Hou, Lu and Shang, Lifeng and Jiang, Xin and Liu, Qun and Ma, Zhi-Ming",
        "title": "Reweighting augmented samples by minimizing the maximal expected loss"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "qi2021online",
        "author": "Qi, Qi and Guo, Zhishuai and Xu, Yi and Jin, Rong and Yang, Tianbao",
        "title": "An online method for a class of distributionally robust optimization with non-convex objectives"
      },
      {
        "key": "ren2018learning",
        "author": "Ren, Mengye and Zeng, Wenyuan and Yang, Bin and Urtasun, Raquel",
        "title": "Learning to reweight examples for robust deep learning"
      }
    ]
  }
]