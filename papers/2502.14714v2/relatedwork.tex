\section{Literature review}
Prior to the emergence of ChatGPT, research efforts focused on examining misinformation and developing fact-checking strategies. Several studies investigated the authenticity of information and explored fact-checking methods to mitigate misinformation risks~\cite{ciampaglia2015computational,luengo2020performance,nyhan2020taking,rodriguez2021debunking}. Surveys provided a comprehensive overview of automated fact-checking models and databases~\cite{zeng2021automated,guo2022survey}, while others employed Natural Language Processing techniques to verify news articles and social media content~\cite{lazarski2021using,oshikawa2018survey}. Additionally, machine learning approaches were applied to combat fake news, fake science, and fake social media posts~\cite{anusree2022factorfake,khalil2021detecting,zhou2019physiological,vo2019learning}. The urgency of these efforts was further underscored during the global pandemic, as misinformation raised significant health and public safety concerns~\cite{krause2020fact,luengo2020performance,abdeen2021fighting,siwakoti2021covid}.

The release of ChatGPT, alongside other generative AI and large language models, expanded research opportunities while intensifying concerns about misinformation. On one hand, these models have unlocked new scientific possibilities~\cite{koohi2023generative,degrave2023dissection,trabassi2024optimizing,wang2023applications}; on the other, they have raised issues regarding hallucinations and the lack of citations, which challenge scientific authenticity~\cite{tian2024opportunities,van2024chatgpt,barreto2023generative,giannakos2024promise}. In response, new fact-checking approaches emerged. For instance, one study addressed the verification of simulated medical abstracts by examining disease and gene names~\cite{Hamed_FC2004}, while another explored fact-checking solutions to mitigate risks associated with factuality in large language models~\cite{augenstein2024factuality}. Additional systems, such as LLM-Augmenter, have been designed to cross-verify content against external resources, and deep-learning classifiers have been used to check AI-generated radiology reports~\cite{peng2023check,mahmood2023fact}. Moreover, SelfCheckGPT has been developed to assess factuality on a sentence-by-sentence basis by ranking text chunks~\cite{manakul2023selfcheckgpt}.

Biomedical research has benefited from early models like BioBART, which assisted with Named Entity Recognition (NER), Entity Linking, and Question Answering tasks at a limited scale~\cite{yuan2022BioBART}. Following ChatGPT’s debut, studies began exploring its utility in biomedical question-answering~\cite{jin2023retrieve,hou2023answers}. Concurrently, researchers have investigated the use of large language models to generate knowledge directly or via Retrieval-Augmented Generation (RAG) methods. RAG integrates contextual prompts to enhance the freshness and accuracy of the generated information~\cite{huly2024old,jeong2023generative,arslan2024business,ng2024rag}. For example, one study employed ChatGPT as a decision support system for self-screening by embedding screening guidelines into hypothetical cases~\cite{khan10803468MedAI}. Another used RAG-based prompt engineering to extract structured representations of drug combinations from clinical trials~\cite{Hamed10803434MedAI}. Similar approaches have also improved PubMed’s retrieval capabilities~\cite{thomo2024pubmed}.

Beyond biomedical applications, large language models have been evaluated for their fact-checking abilities in news and multilingual settings. Comparative studies of ChatGPT, Bing AI CoPilot, and Gemini (formerly Bard) have highlighted both their potential and the continuing need for human oversight in news verification~\cite{chatgpt2025,copilot2025,gemini2025,caramancion2023news}. In the multilingual arena, research employing techniques such as zero-shot, chain-of-thought, and cross-lingual prompting has shown that languages with fewer resources may sometimes yield more accurate fact-checking results~\cite{singhal2024multilingual}. Additionally, studies have underscored the importance of developing guidelines for using AI in fact-checking news headlines~\cite{DeVerna_pnas_2322823121}.