In recent years, the growing use of deep learning across various fields~\cite{yang2021intelligent, macas2022survey, grigorescu2020survey} has highlighted the need for efficient, safe, and private deployment methods, driving the adoption of edge computing. By bringing computation closer to the data source, edge computing reduces latency, saves bandwidth, and enhances privacy and security. However, deploying deep neural networks (DNNs) on edge devices poses challenges due to limited computational resources and energy constraints~\cite{alvear2023edge}.

To tackle these challenges, researchers have focused on improving the accuracy and efficiency of DNNs for edge applications. Traditional approaches, such as manual model optimization~\cite{Marchisio_2018IJCNN_PruNet, vadera2021methods, Hanif_2022MICPRO_EfficientEmbeddedDL, chen2021quantization, matsubara2020head}, often fail to balance multiple objectives effectively. The emergence of Hardware-aware Neural Architecture Search (HW-NAS) has automated the search for optimal architectures, improving model efficiency and accuracy in resource-constrained settings~\cite{benmeziane2021comprehensive}.

HW-NAS uses machine learning to explore architecture spaces and identify designs that balance performance and resource consumption, accelerating edge DNN deployment~\cite{zhang2020fast}. Unlike traditional NAS, which prioritizes accuracy~\cite{he2021automl, elsken2019neural}, HW-NAS employs multi-objective optimization to enhance both accuracy and efficiency (e.g., latency, size)\cite{wistuba2019survey, Marchisio_2020ICCAD_NASCaps, Prabakaran_2021JIOT_BioNetExplorer}, generating Pareto-optimal solutions\cite{Kaisa1999MultiObjective}.



\subsection{Target Research Problem and Associated Challenges}

While advancements in edge DNN design have improved accuracy and computational efficiency, critical performance metrics like fairness, robustness, and generalization remain underexplored~\cite{sheng2022larger}. Fairness ensures equitable performance across diverse user groups, robustness measures reliability under varying conditions (e.g., lighting, weather, visibility)\cite{drenkow2021systematic, porrello2020robust}, and generalization evaluates performance on unseen data\cite{zhou2022domain}.

Enhancing these metrics is essential for edge DNNs, particularly in safety-critical applications like medical diagnostics~\cite{esteva2021deep}. However, achieving this faces challenges such as (1) ensuring data quality and balance~\cite{mehrabi2021survey}, (2) addressing insufficient data diversity~\cite{recht2019imagenet}, and (3) overcoming the computational limitations of edge devices~\cite{ibrahim2022robustness, feuerriegel2020fair, hickey2021fairness}.

Most existing work addresses these challenges by improving data quality~\cite{pitoura2020social} or training procedures~\cite{jain2024fairness}, with limited focus on architecture design. Studies targeting architecture often prioritize a single metric, such as fairness~\cite{sheng2022larger}. Comprehensive approaches that consider fairness, robustness, and generalization together are scarce. To fill this gap, we aim to propose a design methodology ensuring edge DNNs are not only efficient and high-performing but also fair and robust.



\subsection{Analysis: Fairness, Robustness, Generalization in Edge DNNs} \label{intro:pre-analysis}
To highlight the limitations of edge DNN designs in addressing fairness, robustness, and generalization, we evaluated 12 state-of-the-art (SOTA) edge DNNs on person classification (binary classification of images with or without a person) using a COCO dataset subset~\cite{lin2014microsoft}. We measured overfitting, sensitivity to light, and accuracy across different skin tones using the FACET dataset~\cite{gustafson2023facet}.

Figure~\ref{fig:sota_rob} presents robustness and generalization results, revealing notable gaps: validation and test accuracies differ significantly, and accuracies under varying lighting conditions drop by up to 15\%. This indicates potential overfitting and poor robustness to light changes in SOTA models. Figure~\ref{fig:sota_fair} shows a concerning fairness issue: average accuracy declines from 85.0\% for the lightest skin tone category to 70.9\% for the darkest.

Further analysis (Figure~\ref{fig:sota_graph}) demonstrates the influence of model architecture and size on fairness. Models with similar sizes but different architectures exhibit varying fairness scores, indicating that fairness is highly architecture-dependent. Moreover, increasing model size tends to enhance test accuracy but worsens fairness disparities, as larger channel sizes (depth) and more feature representations (width) amplify biases. These findings reveal the need for novel scaling strategies that explicitly target fairness and robustness without solely relying on traditional size scaling techniques.

\begin{figure}
\centering
\begin{subfigure}[b]{0.48\linewidth}
\includegraphics[width=1.\linewidth]{figures/sota_rob-gen.pdf}
    \caption{Overfitting and Sensitivity to light conditions of edge SOTA DNNs.}
    \label{fig:sota_rob}
    \end{subfigure}
%\hspace{.3cm}
\hfill
\begin{subfigure}[b]{0.48\linewidth}
\includegraphics[width=1.\linewidth]{figures/res_plot_skintone_.pdf}
    \caption{Average Accuracy of SOTA edge DNNs across 10 levels of skin tones (from lightest=1 to darkest=10) on FACET~\cite{gustafson2023facet}. }
    \label{fig:sota_fair}
\end{subfigure} 
    \caption{Evaluation of Fairness, Robustness, and Generalization of SOTA edge DNNs on FACET.}
    \label{fig:sota}
    %\vspace{-10pt}
\end{figure}





%\textit{These findings highlight the unintended consequence of current edge DNN designs: a significant bias that disadvantages individuals with darker skin tones and exhibits poor robustness and generalization capabilities.} This consequence not only raises serious ethical and reliability concerns about edge DNNs performance, but also underscores the need for a shift in the design paradigm towards creating edge DNNs that are high-performing, inclusive, and robust.


%models sharing the same architecture shown in 
%In Figure~\ref{fig:sota_graph}, we illustrate the impact of model architecture and size on its skin fairness. \textit{(1) The results reveal that model architecture and size indeed influence model fairness score}. Models with different architectures but similar sizes exhibit varied skin fairness scores. Moreover, \textit{ (2) we observe that increasing model size tends to enhance test accuracy, but leads to a reduction in the model`s skin fairness despite the benefits of larger channel sizes (depth) and more features (width)}. Observations (1) and (2) underscore the need for different model scaling approaches that can improve performance without compromising fairness in edge DNNs.

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/sota_fair_ppt2.pdf}
    %\vspace{-8pt}
    \caption{Test Accuracy vs. Skin Fairness of SOTA edge DNNs: Models sharing the same architecture are connected by straight lines. The Pareto front is illustrated with a dashed line. }
    \label{fig:sota_graph}
    %\vspace{-10pt}
\end{figure}

\subsection{Contributions}

Our key contributions (listed below and summarized in Figure~\ref{fig:MoENAS_overview}), enable the design of fair, robust, and general edge DNNs.
%
%\vspace{-8pt}
%
\begin{enumerate}[leftmargin=*]
%
    \item \textbf{Dynamic Feature Extraction via Model Scaling}: We propose a scaling approach that varies the number of feature extractors dynamically (inspired by Mixture of Experts (MoE) and Switch layer architectures~\cite{fedus2022switch}), enabling adaptive feature extraction tailored to specific inputs. This flexibility indirectly benefits fairness and robustness by allowing more efficient and context-aware use of resources.
%\vspace{-5pt}    
    \item \textbf{HW-NAS with Fairness and Robustness Optimization}: We propose a HW-NAS method with a search space over switching architectures, varying the number of experts per block. Using machine-learning-based performance predictors, the search strategy identifies architectures optimized for accuracy, fairness, robustness, and model size.
%\vspace{-5pt}  
    \item \textbf{Expert Pruning for Efficiency}: We introduce an expert pruning method that helps reduce the sizes of models discovered by the search method by iteratively pruning the least used experts. This approach aims to enhance the efficiency of the resulting models without sacrificing performance.
\end{enumerate}
%\vspace{-5pt}  
%
\begin{figure*}[ht]
    \centering \includegraphics[width=.9\linewidth]{figures/BmoENAS_introver_1.pdf}
    \caption{Summary of MoENAS contributions: (1) Replace the FFN layer with a Switch FFN layer, (2) Search within the expert mixing space for optimal architectures (according to accuracy, fairness, robustness, generalization). (3) Pruning based on expert importance for better efficiency. }
    \label{fig:MoENAS_overview}
    %\vspace{-10pt}
\end{figure*}

%The rest of this paper will be structured as follows: Section 2 discusses the current state of the art in HW-NAS, MoE, fairness, and DNN robustness. Section 3 details our methodology and key contributions. Section 4 compares our model results with SOTA edge DNNs, followed by an ablation study and conclusion.
