\documentclass[pdflatex,sn-mathphys-num]{sn-jnl}% Math and Physical Sciences 
\usepackage{graphicx}%
\usepackage{amsmath,amssymb,amsfonts}%
\usepackage{amsthm}%
\usepackage[title]{appendix}%
\usepackage{xcolor}%
\usepackage{textcomp}%
\usepackage{booktabs}%
\usepackage{multirow}%
%\usepackage[]{nohyperref} %Allows \url but no links in pdf.
%\usepackage{url} %Allows \url but no links in pdf.
%\usepackage{hyperref} %Removing this breaks http links.

\usepackage{float}
\usepackage[T1]{fontenc}
\usepackage{lmodern}

%% as per the requirement, new theorem styles can be included as shown below
%%\theoremstyle{thmstyleone}%
\newtheorem{theorem}{Theorem}% meant for continuous numbers
\newtheorem{proposition}[theorem]{Proposition}% 
%%\theoremstyle{thmstyletwo}%
\newtheorem{example}{Example}%
\newtheorem{remark}{Remark}%
%%\theoremstyle{thmstylethree}%
\newtheorem{definition}{Definition}%


\newcommand\Missing[1]{{\color{blue}\em Missing: #1}}
\newcommand\Ehsan[1]{{\color{blue!40!black!30!red}\em Ehsan TODO: #1 }}

\raggedbottom

%Journal: 

\begin{document}

\title[Article Title]{ViSIR: Vision Transformer Single Image Reconstruction Method for Earth System Models}


\author[1]{\fnm{Ehsan} \sur{Zeraatkar}}\email{ehsanzeraatkar@txstate.edu}

\author[2]{\fnm{Salah} \sur{Faroughi}}\email{salah.faroughi@utah.edu}

\author*[1]{\fnm{Jelena} \sur{Te\v{s}i\'c}}\email{jtesic@txstate.edu}


\affil[1]{\orgdiv{Computer Science}, \orgname{Texas State University}, \orgaddress{\city{San Marcos}, \postcode{78666}, \state{Texas}}}

\affil[2]{\orgdiv{Chemical Engineering}, \orgname{University of Utah}, \orgaddress{\city{Salt Lake City}, \postcode{84112}, \state{Utah}}}


\abstract{\textbf{Purpose:} Earth system models (ESMs) integrate the interactions of the atmosphere, ocean, land, ice, and biosphere to estimate the state of regional and global climate under a wide variety of conditions. The ESMs are highly complex, and thus, deep neural network architectures are used to model the complexity and store the down-sampled data. In this paper, we propose the Vision Transformer Sinusoidal Representation Networks (ViSIR) to improve the single image SR (SR) reconstruction task for the ESM data. 

\textbf{Methods:} ViSIR combines the SR capability of Vision Transformers (ViT) with the high-frequency detail preservation of the Sinusoidal Representation Network (SIREN) to address the spectral bias observed in SR tasks. 

\textbf{Results:} The ViSIR outperforms ViT by 4.1 dB, SIREN by 7.5 dB, and SR-Generative Adversarial (SR-GANs) by 7.1dB PSNR on average for three different measurements.

\textbf{Conclusion:} The proposed ViSIR is evaluated and compared with state-of-the-art methods. The results show that the proposed algorithm is outperforming other methods in terms of Mean Square Error(MSE), Peak-Signal-to-Noise-Ratio(PSNR), and Structural Similarity Index Measure(SSIM).}

\keywords{Single Image Super Resolution, Earth Model System, ESM, Implicit Neural Representation, SIREN, Vision Transformers.}


\maketitle

\section{Introduction}\label{sec1}

An Earth System Model (ESM) is a computer simulation with heavy computational complexity that integrates the interactions between the Earth's various components, such as the atmosphere, ocean, land, ice, and biosphere. The results help scientists study how physical, chemical, and biological processes influence the planet's climate and environmental conditions, particularly in the context of climate change \cite{climate2013ems}. Moreover, the ESM is a comprehensive climate model, including detailed representations of biological and chemical cycles rather than just physical atmospheric and oceanic processes. This integration allows the ESM to simulate various aspects of the Earth system, such as atmospheric circulation, ocean currents, land surface processes, ice dynamics, and vegetation distribution.

The ESM is considered a complex modeling tool compared with traditional climate models, mainly due to their inclusion of biological and chemical processes, such as the carbon cycle, which can provide critical feedback on the physical climate. Accordingly, this powerful tool helps scientists to use ESMs to study and predict how climate change might impact various aspects of the Earth system, including sea level rise, extreme weather events, and water availability\cite{heinze2019}. However, it is essential to recognize that ESMs are not only large and complex, but also the scale varies considerably based on the modeled locality \cite{eyring2016}. For instance, a high-resolution ESM designed for a global scale, as illustrated in Figure~\ref{fig-Motivation}, yields a very low-resolution output when limited to a county scale. This challenging issue affects local agencies inversely, while they typically lack the capacity and resources to develop ESMs comparable to those produced by federal agencies \cite{vandal2017}.

Thus, the task of \textbf{Super Resolution (SR)} emerges as a powerful solution. SR aims to build a deep neural network model that can up-sample any segment of the low-resolution ESM to a high-resolution for a specific region \cite{rahaman2019}.
In the computer vision field, the image SR task refers to the task of enhancing the resolution of an image from low-resolution (LR) to high-resolution (HR) one \cite{yang2019}. There is a wide variety of applications for SR tasks, including surveillance, medical, and media content fields \cite{Dong2016}. 

The traditional approaches have shown to be insufficiently effective in the SR task \cite{ledig2017,tai2017}. The super-resolution task we are solving in this paper is to effectively model a high-resolution ESM image using the associated low-resolution image and a model. The model introduced in this paper is a new hybrid algorithm based on Vision Transformer (ViT) and Sinusoidal Representation Network (SIREN). Although ViT emerged as a powerful tool capable of modeling long-range dependencies in images\cite{touvron2021, Dosovitskiy2020}, it may not be adequately enough to capture high-frequency components pivotal for achieving high-quality Super Resolution\cite{bai2022}. The SIRENs have approved their capability to represent high-frequency details in images\cite{SIREN}, and we propose ViSIR. This new hybrid network replaces the final fully connected layer of ViT with SIREN to address the spectral bias issue in the SR tasks for the Earth System Model images. We will share the code and the data upon publication. 
%All codes and the input data used can be found on the DataLab webpage \url{https://git.txstate.edu/DataLab/INR4climate}\\

\section{Related Work}
\label{sec-related}
%\vspace*{-1em}
Introducing Convolutional Neural Networks (CNNs), the field of SR reconstruction revolutionized\cite{Dong2016}. The CNNs capture smooth and slowly varying features of data while struggling to represent finer details and rapid variations accurately, thus introducing the challenge of spectral bias in the super-resolution (SR) task \cite{Zhang2019}. Next, the Single Image Super Resolution CNN (SRCNN) architecture jointly optimizes all layers and three color channels simultaneously \cite{Dong2016}. The performance comparison of the SRCNN, Fast SRCNN-ESM, Efficient Sub-pixel CNN, Enhanced Deep Residual Network, and SRGANs in \cite{Nikhil2024} indicate that the performance of the EDRN is better in terms of PSNR, and it can capture the high-frequency components of the ESM images more efficiently. Very Deep SR (VDSR) further improved the accuracy of the HR images utilizing a deep architecture\cite{Kim2016VDSR}. Enhanced Deep SR (EDSR) uses more residual blocks in VDSR for better HR image reconstruction \cite{Kim2016EDSR}. A combination of residual learning with dense connection (Residual Dense Network) proved to be effective in capturing more detailed features of image too\cite{Zhang2018}. A generalized Implicit Neural Representation (GINR) network approximates the discreet sample locations with a spectral embedding of the graph to train INRs independent of any choice of coordinate system \cite{grattarola2022ginr}. The Higher-Order Implicit Neural Representation (HOIN) approach fosters the high-order interactions among features and mitigates spectral bias through its neural tangent kernel's (NTK) \cite{chen2024hoin}. Deep generative models applied to SR task (SRGANs) proved to be effective in downscaling climate data, specifically projecting the low-resolution to high-resolution ESM data for the regional precipitation \cite{shidqi2023}. The multimodal temperature forecast combines the numerical weather prediction model with U-net and attention mechanism.\cite{Ding2024}.

\noindent \textbf{The Sinusoidal Representation Network (SIREN)} captures high-frequency details in images by utilizing a periodic activation function, thus enhancing the quality of the SR output \cite{SIREN}. SIREN mitigates the frequency characteristics of an image through its periodic activation function and could demonstrate improved spectral bias in the SR task \cite{SIREN}. 

\noindent \textbf{The Vision Transformer (ViT)} architecture introduced a pipeline where a pure transformer is applied directly to sequences of image patches that perform well for the image classification tasks while requiring substantially fewer computational resources to train\cite{Dosovitskiy2020}. ViT can model long-range dependencies and global context, making it particularly suitable for complex datasets like those found in climate research and SR applications \cite{Dosovitskiy2020}.


% They call it a downscaling task, while we call it an SR task

In Section~\ref{sec-method}, we introduce the methodology behind \textbf{ViSIR}, the hybrid vision transformer algorithm. In Section~\ref{sec-data}, we describe the ESM dataset and how the RGB image collection was derived, and the Proof of Concept in Section~\ref{sec-POC} for the three experiments and the summary of findings we present in Section~\ref{sec-Exp}.

\begin{figure}[!ht]
 \centering
 \includegraphics[width=\linewidth]{figures/Fig1-FlowchartNew1.png} 
 \vspace*{-2em}
 \caption{ViSIR divides the input image into patches, pre-processes them using embedding and position encoding, and finally feeds the input to a visual transformer followed by the SIREN architecture.}
 \label{fig-Flowchart}
 \vspace*{-1em}
\end{figure}

\section{Methodology}
\label{sec-method}

Figure~\ref{fig-Flowchart} illustrates ViSIR pipeline flow. In the proposed pipeline, the ViT processes the input images to capture global dependencies and essential contextual information for Super Resolution. The SIREN then uses this information to address the spectral bias in the input image, resulting in higher-resolution output. Accordingly, the ViSIR integrates ViT's global context modeling capabilities with SIREN's high-frequency representation strength. 


Transformer-based architectures, particularly ViT, can effectively analyze satellite imagery and predict weather patterns with high accuracy\cite{garnot2021}. In Super Resolution, these architectures enhance image quality by reconstructing high-resolution images from low-resolution inputs, offering finer details and improved visual fidelity \cite{yang2020l}. It divides the low-resolution image into fixed patches and linearly embeds them into a sequence of tokens. 

\noindent The proposed \textbf{ViSIR} method integrates the strengths of ViT and SIREN to address the SR spectral bias problem: ViT is responsible for learning the long-range dependencies and capturing the global context from the input images \cite{carion2020}, while SIREN captures high-frequency details \cite{SIREN}. These tokens then pass through transformer layers where multi-head self-attention mechanisms and feed-forward neural networks capture global context and long-range dependencies. The final step of the ViSIR pipeline is the SIREN architecture instead of the conventional fully connected neural network. Using sinusoidal activation functions, the SIREN captures high-frequency details to refine and enhance the final image's resolution. This ViSIR modeling pipeline preserves both global and local information in the model to reconstruct the Earth System Model while preserving high-frequency details and complex patterns. Figure~\ref{fig-Flowchart} illustrates the flow chart of the proposed method from a low-resolution image to a high-resolution one. 


\section{Benchmark Dataset}
\label{sec-data}

In this research, we evaluate our findings using the image set extracted from the Energy Exascale Earth System Model (E3SM) simulation outputs. The E3SM model is an open-access, state-of-the-art, fully coupled model of the Earth's climate, including critical bio-geochemical and cryospheric processes \cite{E3SM2018}. This interpolated model data E3SM-FR is mapped from the E3SM original non-orthogonal cubed-sphere grid simulation data to a regular $0.25^{\circ} \times 0.25^{\circ}$ longitude-latitude grid using a bilinear method. Next, the E3SM-FR data is interpolated onto a $1^{\circ} \times 1^{\circ}$ grid using a bicubic (BC) interpolation method \cite{Passarella2022}. 

\begin{figure}[!ht]
\centering
\begin{minipage}{0.49\linewidth} 
 \includegraphics[width=\linewidth]{figures/Fig2-1.png} 
\end{minipage}
\hfill 
\begin{minipage}[t]{0.49\linewidth} 
 % \vspace{-5.2cm}
 \raggedleft
 \includegraphics[width=\linewidth]{figures/Fig2-2.png}
 \caption{Panels (a), (b), and (c) show surface temperature, shortwave heat flux, and longwave heat flux, respectively, for the first month of year one obtained from the global fine-resolution configuration of E3SM\cite{Nikhil2024}.}
 \label{fig-Motivation}
\end{minipage}
\end{figure}

In our image dataset, each of these grid points is a pixel, and the entire grid is a high-resolution image with dimensions of $720 \times $1440 pixels. We derive the R G and B components from the normalized values of surface temperature, shortwave, and longwave heat fluxes data at specific grid points, respectively, as illustrated in Figure~\ref{fig-Motivation}. Note that the corresponding coarse-resolution data has dimensions of $180 \times $360 pixels, simulating the 4x upsampling. Next, we split the big image into 18 non-overlapping images. The fine-resolution images are now $240 \times 240$ pixels in size, and coarse-resolution images are now $60 \times 60$ pixels in size\cite{Nikhil2024}. In our current dataset, we have $10$ months $\times 18$ images per one of the three measures, a total of 540 images. 
% The total number of images in the dataset is 11 (years) × 12 (months)× 18 (slices)X 3(measures). 



\section{Proof Of Concept}
\label{sec-POC}

First, we define three measures of algorithmic performance. Then, we compare the original high-resolution image $I_O$ with the image reconstructed $I_R$ to show the proposed algorithm's performance. 

\noindent \textbf{The Mean Squared Error (MSE)} is defined as the mean difference in pixel intensity between $I_O $ image and $I_R $ image in Eq.~\ref{eq-mse}. The $M $ and $N $ are the dimensions of the images (height and width), and $ I_O(i,j) $ and $ I_R(i,j) $ are the pixel values at position $(i,j) $ in the original and reconstructed images, respectively. While we have RGB images and The three channels, the final values are the mean values calculated for all pixels in all channels.
\begin{equation}
\text{MSE} = \frac{1}{MN} \sum_{i=1}^{M} \sum_{j=1}^{N} \left( I_O(i,j) - I_R(i,j) \right)^2
\label{eq-mse} \end{equation}
A higher MSE means a higher mean discrepancy between the original image $I_O $ and the reconstructed image $I_R$. 

\noindent \textbf{The peak signal-to-noise ratio (PSNR)} measures the quality of reconstructed images in image compression and SR tasks. The PSNR is the ratio between the maximum possible pixel intensity of the image and MSE (Eq.~\ref{eq-mse}) for that image in Eq.~\ref{eq-PSNR}. \begin{equation}
\text{PSNR} = 10 \cdot \log_{10} \left(\frac{\text{MAX}^2}{\text{MSE}}\right) \label{eq-PSNR}
\end{equation} A higher PSNR value means better image quality and less distortion or error in the reconstructed image.

\noindent \textbf{The Structural Similarity Index Measure (SSIM)} considers changes in structural information, luminance, and contrast for comparing the original image $I_O $ with the reconstructed on $I_R $ images. The $\mu_{I_O} $ and $\sigma_{I_O}^2 $ are the mean and the variance of the original image $I_O$, and the $\mu_{I_R} $ and $\sigma_{I_R}^2 $ are the mean and the variance of the reconstructed image $I_R$, while $\sigma_{I_O*I_R} $ is the covariance between original image ${I_O}$ and reconstructed image ${I_R}$ in Eq~\ref{eq-SSIM}.


\begin{equation}
\text{SSIM}(x, y) = \frac{(2*\mu_{I_O} \mu_{I_R} + C_1)(2*\sigma_{I_O*I_R} + C_2)}{(\mu_{I_O}^2 + \mu_{I_R}^2 + C_1)(\sigma_{I_O}^2 + \sigma_{I_R}^2 + C_2)} \label{eq-SSIM}
\end{equation} $ C_1 $ and $ C_2 $ are constants to stabilize the division in Eq~\ref{eq-SSIM}. The SSIM value ranges from -1 to 1, where one means two images are identical, 0 means two images have no structural similarity, and negative values indicate that two images are structurally dissimilar. 

\begin{table}[!ht]
\centering
\caption{(Max, {\em Mean}, Min) values of MSE \%, PSNR dB and SSIM for original $I_O$ and reconstructed $I_R$ images for three measurements, Source Temperature, shortwave heat flux, and longwave heat flux, and FOUR different models.}
\begin{tabular}{lcccccc}
\textbf{Measures $\rightarrow$} & \textbf{ MSE \%} & \textbf{PSNR dB} & \textbf{SSIM [0,1]}\\ 
\toprule
\textbf{Models $\downarrow$} & \multicolumn{3}{c}{\bf Source Temperature}\\
\midrule
ViT &(1.5,{\em 0.49}, 0.42)&(24.3,{\em 23.2}, 18.2)&(0.66,{\em 0.54}, 0.48)\\
SIREN &(2,{\em 0.93}, 0.56)&(21.5,{\em 20.2}, 17.3)&(0.61,{\em 0.57}, 0.4) \\
SRGANS &(1.5,{\em 0.61}, 0.49)&(22.9,{\em 21.4}, 18.02)&(0.64,{\em 0.6}, 0.48) \\
\textbf{ViSIR} &\textbf{(0.42, {\em 0.13}, 0.06)}&\textbf{(32.1,{\em 28.5}, 23.9)}&\textbf{(0.85,{\em 0.76}, 0.62)} \\
\toprule
\textbf{} & \multicolumn{3}{c}{\bf Shortwave heat flux}\\ \midrule
ViT &(1.18,{\em 0.42}, 0.31)&(24.5,{\em 23.9}, 18.7)&(0.69,{\em 0.66}, 0.52)\\
SIREN &(1.4,{\em 0.73}, 0.62)&(21.5,{\em 20.5}, 17.9)&(0.62,{\em 0.58}, 0.49) \\
SRGANS &(1.5,{\em 0.67}, 0.56)&(22.1,{\em 21.2}, 18.1)&(0.62,{\em 0.61}, 0.49) \\
\textbf{ViSIR} &\textbf{(0.38, {\em 0.14}, 0.04)}&\textbf{(33.1,{\em 28}, 24.5)}&\textbf{(0.87,{\em 0.75}, 0.66)} \\
\toprule
\textbf{} & \multicolumn{3}{c}{\bf Longwave heat flux}\\
\midrule
ViT &(1.38,{\em 0.73}, 0.42)&(23.8,{\em 20.5}, 18.2)&(0.66,{\em 0.58}, 0.49)\\
SIREN &(1.5,{\em 0.67}, 0.56)&(22,{\em 21}, 18.1)&(0.62,{\em 0.6}, 0.49) \\
SRGANS &(1.5,{\em 0.73}, 0.56)&(22.1,{\em 20.5}, 17.9)&(0.6,{\em 0.58}, 0.48) \\
\textbf{ViSIR} &\textbf{(0.41, {\em 0.08}, 0.04)}&\textbf{(33.5,{\em 30.5}, 24.2)}&\textbf{(0.88,{\em 0.81}, 0.66)} \\
\bottomrule
\end{tabular}\label{tab-Compare}
\end{table} 

\begin{figure}[!ht] 
 \centering
 \includegraphics[width=\linewidth]{figures/Fig3.png} 
 \caption{2D (left) and 3D (right) illustration of the PSNR values for different Frequencies and different numbers of hidden layers used in the proposed ViSIR applied to 180 images of the Surface Temperature variable. }
 \label{fig-FreqVsLayer} 
\end{figure} 

%\vspace*{-2em}
\section{Experimental Results}
\label{sec-Exp}

In this section, we conduct experiments to compare ViSIR performance with that of ViT \cite{Dosovitskiy2020}, SIREN \cite{SIREN}, and SRGANs \cite{ledig2017}. For the model training and evaluation, we use the University's LEAP2 (Learning, Exploration, Analysis, and Process) Cluster processing. The LEAP2 Dell PowerEdge C6520 Cluster enjoys 108 compute nodes, each with 48 CPU cores via two (24-core) 2.4 GHz 6336Y Intel Xeon Gold (IceLake) processors. With 256 GBs of memory and 400 GBs of SSD storage per node, the compute nodes provide an aggregate of 27 TBs of memory and 42 TBs of local storage. We have used 48 CPU cores, with 256GB RAM and 800GB SSD, to run the methods. We applied the hyper-parameter searches with different sinusoidal activation function frequencies ranging from 10 to 60 Hz while varying the number of hidden layers in the SIREN ranging from 1 to 6 to get the best hyper-parameters. Figure~\ref{fig-FreqVsLayer} illustrates the effect of the changing hyper-parameters and the best parameters based on the mean PSNR values. The best PSNR value for EMS images is two hidden layers with a frequency of 20. These are the hyper-parameters used for the rest of the methods in terms of frequency and layers to perform a fair comparison.

\subsection{Experiment 1: Performance Comparison} 
In this experiment, we compare ViSIR to ViT, SIREN, and SRGANS models in terms of PSNR and SSIM ( (Fig.~\ref{fig-Mean}) scores for three measurements. Table~\ref{tab-Compare} summarizes the superiority of the ViSIR performance against three state-of-the-art (SOTA) techniques, ViT, SIREN, and the state-of-the-art SRGANS. ViSIR exhibits the highest PSNR and SSIM, as illustrated in Figure~\ref{fig-Mean}, for all three measurements. 






\begin{figure}[!ht]
 \centering
 \includegraphics[width=\textwidth]{figures/Error_Visualnn.png} 
 \caption{Image reconstruction from low-resolution Surface Temperature image using ViSIR.}
 \label{fig-Visual}
\end{figure}

First, the ViSIR improvement over SOTA SIREN is over 10.6dB PSNR and 35.9\% in SSIM improvement. Second, if we compare ViSIR to the next best performer, ViT, it results in 7.8 dB in PSNR improvement and 28\% SSIM improvement. In summary, the strength of ViSIR compared to SOTA for the task is that we combine transformers with the SIREN structure to address the spectral bias that GANS failed to tackle for the single-resolution image reconstruction task. These results highlight ViSIR's superiority in capturing the higher-frequency components in the images and reconstructing high-resolution output effectively.

%high-frequency details even in complex and intricate images, thereby underscoring its effectiveness in maintaining high performance across varied image conditions. 
\subsection{Experiment 2: Corner Case Reconstruction}

In this experiment, we focus on evaluating the corner case scenarios to assess the ViSIR model's performance in handling challenging scenarios. Figure~\ref{fig-Example} (left) is the image in the Surface Temperature dataset with the highest ViSIR PSNR of 32.1dB. We see that ViSIR handles high-frequency spectral bias well, and the ViSIR algorithm can achieve a notably high PSNR for an image featuring pronounced edges and abrupt color transitions. Figure~\ref{fig-Example} (right) is the image in the dataset with the lowest ViSIR PSNR of 23.9DdB. Table~\ref{tab-Compare} summarizes the numerical scores of the maximum (Max), average (Mean), and minimum (min) values per method per evaluation measure. ViSIR is clearly superior in all corner cases as its mean MSE associated with all three variables is lower than the best MSEs of ViT, SRGANs, and SIREN, and its best MSE of 0.08\% is lower than the next MSE score by more than 100\% (0.42\% MSE). SIREN and SRGANS paint almost the same picture in terms of MSE, PSNR, and SSIM, while the SRGANs illustrate better results. The ViSIR best PSNR is \textbf{36.7\%} better than ViT.

\begin{figure*}[!ht]
 \centering
 \includegraphics[width=0.48\textwidth]{figures/PSNR.png} 
 \includegraphics[width=0.48\textwidth]{figures/SSIM.png} 
  \caption{Max Mean, and Min PSNR and SSIM values over all three measurements.}
 \label{fig-Mean}
\end{figure*}

\subsection{Experiment 3: Reconstruction}

The single-image SR Task for Reconstruction decomposes the large, high-resolution image into the low-resolution image and the model. Figure~\ref{fig-Visual} illustrates the potential application of the proposed ViSIR model by comparing the low-resolution and ViSIR output in terms of MSE, PSNR, and SSIM. This illustration visualizes the performance of the ViSIR in capturing high-frequency components of the image. It ensures the capability of the efficient replacement of ViSIR and low-resolution images with 4X high-resolution photos. Table\ref{tab-Compare} summarizes the model performance in terms of best result, mean result, and worst result for all three measures. The findings indicate that the algorithm is effective when processing images containing relatively high-frequency components. Figure~\ref{fig-Example} illustrates input images associated with the best and worst PSNR values achieved by ViSIR.

\begin{figure}[!ht] 
 \centering
  \centering
  \includegraphics[width=\linewidth]{figures/Figure-7n.png}
 \caption{The input images with the highest (Up) and the lowest (Down) PSNR values are associated with each variable.}
 \label{fig-Example}
\end{figure}

\noindent \textbf{Summary:} The PSNR and SSIM value range comparison in Figure~\ref{fig-Mean} illustrates the dominance of ViSIR for a single image reconstruction task. Figure~\ref{fig-Visual} demonstrates the performance of the ViSIR in reconstructing the Surface Temperature high-resolution image from low resolution one. 

\section{Conclusion and Future Work}
\label{sec-conclusion}

In this paper, we introduce ViSIR, a new approach for high-resolution image reconstruction using Earth System Models (ESM). ViSIR's superior performance lies in its ability to combine ViT's global context modeling with SIREN's high-frequency representation capabilities. The proof of concept comparison on images constructed from ESM simulations shows that ViSIR outperforms three state-of-the-art methods significantly in low MSE and higher PSTNR and SSIM measures. The ViSIR approach effectively mitigates the spectral bias challenge and produces negligible reconstruction error. Future work will extend ViSIR to multiple images of SR reconstruction and reduce the footprint of the model for practical scenarios. 


\input{ViSIR_VisionTransformer_SIREN.bbl}
\end{document}
