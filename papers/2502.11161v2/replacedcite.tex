\section{RELATED WORK}
\subsection{View Planning in Manipulation}

View planning in robotics has been widely introduced in ____, ____, which seeks to determine the maximum information gain viewpoint and ensure the sequence of sensors. Among the various domains of view planning, one key area of interest is manipulation , which has been explored through various approaches to optimize task performance.
Arruda et al. ____ proposed a geometry-based method that prioritizes object visibility and graspability, improving both the quality of reconstruction and the success of grasp. Alternatively, Jun Lv et al. ____ introduced the differentiates between the manipulation arm and viewpoint arm, magnifying the operation area through viewpoint following to enhance grasping stability. 
Other methods____ selected the view with the greatest information gain during operation to address issues such as occlusion.
In recent years, learning-based approaches have been increasingly used to optimize view planning. Some approaches____ optimizes viewpoints planning process via reward functions during manipulation.
Additionally, Multi-View Picking____ applied a self-supervised state representation methods to focus on the target by changing views, enabling the completion of complex manipulation tasks.

%View planning for robotic manipulation has been explored through various approaches to optimize task performance. Arruda et al. ____ proposed a geometry-based method that prioritizes object visibility and graspability, improving both reconstruction quality and grasp success. Subsequent work____ focuses on maximizing information gain to address occlusion challenges. Recent advances leverage learning-based strategies: reinforcement learning____ optimizes viewpoints via reward functions, while self-supervised multi-view picking____ dynamically adjusts perspectives to handle complex manipulation tasks.

\begin{figure*}[htbp]
    \centering
    \includegraphics[width=1\textwidth]{figures/BFA-main-4.pdf}
    \vspace{-0.8cm}
    \caption{The overall pipeline of best feature aware fusion strategy applied in the end-to-end policy network. The multi-view images captured by the top-view and wrist cameras, are input to visual backbones for feature extraction. The multi-view features are then injected into a lightweight score network to produce the importance scores for each view. The importance scores are further used to reweight and fuse the multi-view features. The fused features are finally served as the input of the policy network to generate the action sequence for real-arm deployment. During training, the whole network is jointly optimized by the score loss and the policy loss.}
    \label{fig:BFA-main}
\end{figure*}



\subsection{Fine-Grained Robotic Manipulation}
Current methods often employ imitation learning strategies to complete fine-grained manipulation tasks. By leveraging expert demonstrations, imitation learning enables the agent to efficiently acquire complex skills.
% ____. For instance
Some methods____, proposed an imitation learning framework based on transformer architecture ____, leveraging multi-view information and joint data as demonstration inputs to predict future action sequences. Additionally, Some works____ integrate the diffusion process into imitation learning. Moreover, Some works____ have introduced a multi-task approach within these two paradigms, aiming to use a single model for handling multiple tasks.
However, all these methods integrate multi-view information by directly concatenating all visual representations, without considering the unequal information provided by different viewpoints.

% \begin{figure*}[t]
% \centering
% \includegraphics[width=\linewidth]{figs/framework.pdf}
% \vspace{-.2in}
% \caption{\textbf{Conceptual comparison of four depth supervision frameworks.} }
% \label{fig:framework}
% \end{figure*}