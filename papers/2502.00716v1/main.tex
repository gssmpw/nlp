%%%%%%%% ICML 2025 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}

\usepackage[accepted]{icml2025}

\usepackage[toc,page,header]{appendix}
\usepackage{minitoc}
\renewcommand \thepart{}
\renewcommand \partname{}
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables
\usepackage{tcolorbox}
\usepackage{float}

% \usepackage{icml2025} with \usepackage[nohyperref]{icml2025} above.
\usepackage{hyperref}

%%%%%%%%%%%%%%%%%%%%%%%
%From log this is
\usepackage{algorithm}
\usepackage{algorithmic}

\usepackage{makecell}
\usepackage{booktabs}       % professional-quality tables
\usepackage{color}
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{enumerate}   
\usepackage{bm}
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors
\usepackage{bbm}
\usepackage{xfrac}
\usepackage{tocbibind}
% \usepackage[title]{appendix}
\usepackage{tikz}
\usepackage{physics}
\usepackage{hyperref}       % hyperlinks
\usepackage{dsfont}
\usepackage{graphicx}
\usepackage{url} 

\usepackage{caption}
% \usepackage{subcaption}

\usepackage{listofitems} % for \readlist to create arrays
\usepackage{subfiles}
\usepackage[
  separate-uncertainty = true,
  multi-part-units = repeat
]{siunitx}



\usepackage{enumitem}
\usepackage{arydshln}
\usepackage{multirow}


%%%%%%%%%%%%%%%%%%%%%

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2025} with \usepackage[nohyperref]{icml2025} above.
\usepackage{hyperref}


% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
% \usepackage{icml2025}

% If accepted, instead use the following line for the camera-ready submission:
% \usepackage[accepted]{icml2025}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}


\theoremstyle{plain}
\theoremstyle{definition}
\theoremstyle{remark}
\newtheorem{example}[theorem]{Example}

\makeatletter
\newtheorem*{rep@theorem}{\rep@title}
\newcommand{\newreptheorem}[2]{%
\newenvironment{rep#1}[1]{%
 \def\rep@title{#2 \ref{##1}}%
 \begin{rep@theorem}}%
 {\end{rep@theorem}}}
\makeatother

\newreptheorem{theorem}{Theorem}
\newreptheorem{lemma}{Lemma}
\newreptheorem{proposition}{Proposition}
\newreptheorem{corollary}{Corollary}
\newreptheorem{assumption}{Assumption}
% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
% \usepackage[textsize=tiny]{todonotes}

\newenvironment{calculations}  {\color{blue}     }    {     }
\newenvironment{calc}    {\color{blue}     }    {     }
\newcommand{\cnewline}{\\}
\newcommand{\cand}{&}
\newcommand{\nn}{\nonumber}
\newcommand{\blue}{\color{blue}}
\newcommand{\black}{\color{black}}
\newcommand{\mrd}{\mathrm{d}}
\newcommand{\mbX}{\mathbf{X}}
\newcommand{\mbx}{\mathbf{x}}
\newcommand{\mbF}{\mathbf{F}}
\newcommand{\mbf}{\mathbf{f}}
\newcommand{\bbE}{\mathbb{E}}
\newcommand{\bbR}{\mathbb{R}}
\newcommand{\mrR}{\mathrm{R}}
\newcommand{\mbA}{\mathbf{A}}
\newcommand{\mrm}{\mathrm{m}}
\newcommand{\mdens}{\mrm_{w}}
\newcommand{\KLr}{\mathrm{KL}}
\newcommand{\mbR}{\mathbb{R}}
\newcommand{\mbZ}{\mathbf{Z}}
\newcommand{\mun}{\mbZ_n}
\newcommand{\mur}{\mu_{n,(1)}}
\newcommand{\genb}{\overline{\mathrm{gen}}}
\newcommand{\gen}{\mathrm{gen}}
\newcommand{\agg}{\mathrm{Agg}}
\newcommand{\degmax}{\mathrm{deg}^{\max}}
\newcommand{\degmin}{\mathrm{deg}^{\min}}

\newcommand{\ba}{\mathbf{a}}
\newcommand{\be}{\mathbf{e}}
\newcommand{\bx}{\mathbf{x}}
\newcommand{\bw}{\mathbf{w}}
\newcommand{\bg}{\mathbf{g}}
\newcommand{\bb}{\mathbf{b}}
\newcommand{\bu}{\mathbf{u}}
\newcommand{\bv}{\mathbf{v}}
\newcommand{\bz}{\mathbf{z}}
\newcommand{\bc}{\mathbf{c}}
\newcommand{\bd}{\mathbf{d}}
\newcommand{\bh}{\mathbf{h}}
\newcommand{\by}{\mathbf{y}}
\newcommand{\bn}{\mathbf{n}}
\newcommand{\bs}{\mathbf{s}}
\newcommand{\bq}{\mathbf{q}}
\newcommand{\Lcal}{\mathcal{L}}
\newcommand{\Ocal}{\mathcal{O}}
\newcommand{\Acal}{\mathcal{A}}
\newcommand{\Gcal}{\mathcal{G}}
\newcommand{\Ccal}{\mathcal{C}}
\newcommand{\Xcal}{\mathcal{X}}
\newcommand{\Vcal}{\mathcal{V}}
\newcommand{\Jcal}{\mathcal{J}}
\newcommand{\Dcal}{\mathcal{D}}
\newcommand{\Fcal}{\mathcal{F}}
\newcommand{\Hcal}{\mathcal{H}}
\newcommand{\Rcal}{\mathcal{R}}
\newcommand{\Ncal}{\mathcal{N}}
\newcommand{\Scal}{\mathcal{S}}
\newcommand{\Pcal}{\mathcal{P}}
\newcommand{\Qcal}{\mathcal{Q}}
\newcommand{\Wcal}{\mathcal{W}}
\newcommand{\reals}{\mathbb{R}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\LL}{\mathbb{L}}
\newcommand{\sign}{\mathrm{sign}}
\newcommand{\half}{\frac{1}{2}}
\newcommand{\argmin}[1]{\underset{#1}{\mathrm{argmin}}}
\newcommand{\argmax}[1]{\underset{#1}{\mathrm{argmax}}}
\newcommand{\summ}{\displaystyle \sum}
\newcommand{\intt}{\displaystyle\int}
% \newcommand{\var}{\text{Var}}
\newcommand{\nchoosek}[2]{\left(\begin{array}{*{20}c}#1\\#2\end{array}\right)}

% \newcommand{\mbR}{\mathbb{R}}
\newcommand{\rademacher}{ \hat{\mathfrak{R}}}


% \newcommand{\mrm}{\mathrm{m}}
% \newcommand{\mrd }{\mathrm{d}}
% \newcommand{\mdens}{\mrm_{\theta}}
\newcommand{\lipd}{{\mathrm{Lip}_{(d)}}}
\newcommand{\nupop}{\mu_{\mathrm{pop}}}
\newcommand{\Vari}{\mathbb{V}}

\usepackage{xspace}
\usepackage[colorinlistoftodos, color=blue!30!white %   ,shadow
	% ,disable
]{todonotes}                                        
% \setlength{\marginparwidth}{12ex}
\newcommand{\todoa}[2][]{\todo[size=tiny,color=blue!20!white,#1]{GA: #2}\xspace}
\newcommand{\todot}[2][]
{\todo[size=tiny,color=green!20!white,#1]{T: #2}\xspace}
\newcommand{\todoz}[2][]{\todo[size=tiny,color=orange!20!white,#1]{Z: #2}\xspace}
\newcommand{\todos}[2][]
{\todo[size=tiny,color=green!20!white,#1]{T: #2}\xspace}

% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Imbalance Transductive Node Classification}

\begin{document}
\doparttoc % Tell to minitoc to generate a toc for the parts
\faketableofcontents % Run a fake tableofcontents command for the partocs



\twocolumn[
\icmltitle{UPL: Uncertainty-aware Pseudo-labeling \\ for
Imbalance Transductive Node Classification}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2025
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
\icmlsetsymbol{equal}{*}
\begin{icmlauthorlist}
\icmlauthor{Mohammad T. Teimuri}{sharif}
\icmlauthor{Zahra Dehghanian}{sharif}
\icmlauthor{Gholamali Aminian}{turing}
\icmlauthor{Hamid R. Rabiee}{sharif}
\end{icmlauthorlist}

\icmlaffiliation{sharif}{Sharif University of Technology}
\icmlaffiliation{turing}{Alan Turing Institute}

\icmlcorrespondingauthor{Hamid R. Rabiee}{rabiee@sharif.edu}
% \begin{icmlauthorlist}
% \icmlauthor{Firstname1 Lastname1}{equal,yyy}
% \icmlauthor{Firstname2 Lastname2}{equal,yyy,comp}
% \icmlauthor{Firstname3 Lastname3}{comp}
% \icmlauthor{Firstname4 Lastname4}{sch}
% \icmlauthor{Firstname5 Lastname5}{yyy}
% \icmlauthor{Firstname6 Lastname6}{sch,yyy,comp}
% \icmlauthor{Firstname7 Lastname7}{comp}
% %\icmlauthor{}{sch}
% \icmlauthor{Firstname8 Lastname8}{sch}
% \icmlauthor{Firstname8 Lastname8}{yyy,comp}
% %\icmlauthor{}{sch}
% %\icmlauthor{}{sch}
% \end{icmlauthorlist}

% \icmlaffiliation{yyy}{Department of XXX, University of YYY, Location, Country}
% \icmlaffiliation{comp}{Company Name, Location, Country}
% \icmlaffiliation{sch}{School of ZZZ, Institute of WWW, Location, Country}

% \icmlcorrespondingauthor{Firstname1 Lastname1}{first1.last1@xxx.edu}
% \icmlcorrespondingauthor{Firstname2 Lastname2}{first2.last2@www.uk}

% % You may provide any keywords that you
% % find helpful for describing your paper; these are used to populate
% % the "keywords" metadata in the PDF but will not be shown in the document
% \icmlkeywords{Machine Learning, ICML}

\vskip 0.3in
]


\begin{abstract}
Graph-structured datasets often suffer from class imbalance, which complicates node classification tasks. In this work, we address this issue by first providing an upper bound on population risk for imbalanced transductive node classification. We then propose a simple and novel algorithm, Uncertainty-aware Pseudo-labeling  (UPL). Our approach leverages pseudo-labels assigned to unlabeled nodes to mitigate the adverse effects of imbalance on classification accuracy. Furthermore, the UPL algorithm enhances the accuracy of pseudo-labeling by reducing training noise of pseudo-labels through a novel uncertainty-aware approach. We comprehensively evaluate the UPL algorithm across various benchmark datasets, demonstrating its superior performance compared to existing state-of-the-art methods.
\end{abstract}
\vspace{-.2in}
\section{Introduction}
Graphs are fundamental data structures that are universally utilized in various applications. The flexibility and expressiveness of graph representations enable us to model complex relationships and interactions within several types of data across numerous fields. From social networks, where individuals are connected by various kinds of relationships, to biological networks that represent protein interactions, graphs provide a powerful way to encapsulate the inherent complexities of many natural and human-made systems \citep{mohammadrezaei2018identifying, ying2018graph, perozzi2016recommendation, hamilton2017inductive}.
In tackling the task of learning from graph data, Graph Neural Networks (GNNs) play an important role \citep{hamilton2017inductive, kipf2016semi, velickovic2017graph}. GNNs leverage the rich relational information within graphs, allowing for the effective propagation of information through the network structure. And their ability to generalize deep learning approaches to non-Euclidean data. 
However, despite their advantages, GNNs encounter significant challenges when dealing with imbalanced data in transductive scenarios where the unlabeled nodes are utilized during the training phase, a common scenario in real-world graphs \citep{park2022graphens}. In many graph-based applications, some classes of nodes are vastly underrepresented compared to others, leading to a problem in the learning process \citep{song2022tam, park2022graphens}. In particular, this imbalance can result in biased models towards the majority class, which can also depend on graph structure. For instance, in social networks, minority groups might be underrepresented in friendship suggestions; rare protein interactions could be overlooked in biological networks. 

The problem of imbalance in graphs thus poses unique challenges that require specialized strategies to address. Standard imbalance handling techniques, such as re-weighting and re-sampling, may work in fields such as image classification but face significant obstacles when applied to graphs. Re-weighting methods, which assign higher weights to minor nodes, do not alter the connectivity patterns of these nodes, leaving their neighborhood influences unchanged. Re-sampling strategies, intended to balance class representation, can disrupt the graph's structure, potentially altering critical message-passing pathways and affecting the semantic integrity of node classes and embedded features.

Despite these developments, balancing the enhancement of minority class representation against the integrity of majority classes remains a technical challenge due to overemphasis on minority classes can degrade the model’s ability to accurately represent more common classes \citep{yan2024rethinking, song2022tam, park2022graphens,jervakani2024klce}. Furthermore, the generalization error and population risk study of imbalanced node classification is overlooked. Our contributions in this work can be summarized as follows:
\vspace{-.1in}
\begin{itemize}[noitemsep,nolistsep,leftmargin=*]
    \item  We study the population risk of transductive node classification under an imbalance scenario and derive an upper bound on population risk which depends on different graph properties of each class in the graph.
    \item We present a novel algorithm, uncertainty-aware pseudo-labeling that demonstrates superior performance compared to existing approaches in many homophilic and heterophilic graph datasets. 
\end{itemize}


\section{Related works}

\textbf{Imbalance Graph Classification:}
Due to the non-Euclidean characteristics of graph data, the imbalance problem in this type of data necessitates additional attention and specialized focus. Following the categorization of imbalance classification methodologies, we similarly categorize imbalance graph classification models into two main groups: data-level and algorithm-level methods.

\textit{Data-level methodologies} try to rebalance the learning environment by manipulating training data in feature or label spaces. Fundamental approaches such as over-sampling and under-sampling, prevalent in traditional class-imbalanced learning, require adaptation to suit the complexities inherent in graph data, characterized by intricate node dependencies and interconnections. Data-level methods could subcategorized into data interpolation, adversarial generation, and pseudo-labeling \citep{ma2023class}. Data interpolation techniques, exemplified by SMOTE \citep{chawla2002smote} and its graph-oriented variant, GraphSMOTE \citep{zhao2021graphsmote}, generate synthetic minority nodes by interpolating between existing node representations. Methods like GATSMOTE \citep{liu2022gatsmote} and GNN-CL \citep{li2024graph} enhance this process through attention mechanisms, ensuring quality edge predictions between synthetic and real nodes. Moreover, Mixup strategies, as seen in GraphMixup \citep{wu2022graphmixup} and GraphENS \citep{park2022graphens}, introduce sophisticated blending techniques to combat neighbor memorization issues and prevent out-of-domain sample generation.

\textit{Algorithm-level methodologies} focus on refining learning algorithms to accommodate class imbalance effectively. Model refinement strategies adapt graph representation learning architectures to improve performance by incorporating class-specific adjustments and modules tailored to handle imbalance. For instance, approaches like ACS-GNN \citep{ma2022attention} and EGCN \citep{wang2022effective} modify aggregation operations within graph neural networks to prioritize minority class information, ultimately enhancing classification accuracy. Additionally, loss function engineering tries to design customized loss functions to prioritize minority class errors or encourage wider class separations, a challenging task given the connectivity properties of nodes in graphs. Recent innovations like ReNode \citep{chen2021topology} and TAM \citep{song2022tam} integrate graph topology information into loss function designs, showcasing advancements in addressing class imbalance within the graph context. \citet{jervakani2024klce} proposed a KL regularization for imbalance node classification.

\textbf{Generalization Error and Node Classification:} There are two different scenarios in node classification, including inductive and transductive scenarios. Inductive learning node classification involves (semi-)supervised learning on graph data samples where the test data are unseen during training. In Inductive node classification For node classification tasks, \citep{verma2019stability} discussed the generalization error under node classification for GNNs via algorithm stability analysis in an inductive learning setting based on the SGD optimization algorithm. The work by \citet{zhou2021generalization} extended the results in \citep{verma2019stability} and found that increasing the depth of Graph Convolutional Neural Network (GCN) enlarges its generalization error for the node classification task. In Transductive Node Classification, based on transductive Rademacher complexity, a high-probability upper bound on the generalization error of the transductive node classification task was proposed by \citet{esser2021learning}. The transductive modeling of node classification was studied in \citep{oono2020optimization} and \citep{tang2023towards}. \citep{cong2021provable} presented an upper bound on the generalization error of GCNs for node classification via transductive uniform stability, building on the work of \citep{el2006stable}. In contrast, our research focuses on the task of imbalance transductive node classification and we provide an upper bound on population risk.

\textbf{Uncertainty in Self-training: }
The integration of uncertainty estimation in GNNs has been extensively explored, particularly in self-training frameworks \cite{wang2021be,yang2021self,zhao2021entropy}. Early contributions, such as \cite{li2018deeper}, introduced a simple strategy that selects the top K most confident nodes based on softmax probabilities for pseudo-labeling, expanding the labeled set iteratively. This approach was later refined by \cite{sun2020multi}, which employed a multi-stage self-training method, iteratively updating node labels to enhance GNN performance in sparse label settings. Extending these ideas, \cite{yang2021self} proposed a self-enhanced GNN framework that utilizes an ensemble of models to ensure consistency in pseudo-label predictions, thereby improving robustness against label noise. A common technique for uncertainty estimation in these methods is the use of entropy, as demonstrated in \cite{cai2017active, zhang2021alg}, which measures prediction confidence to guide node selection. Building on this, \cite{zhao2021entropy} introduced an entropy-aware self-training framework, incorporating an entropy-aggregation layer to account for graph structural information in uncertainty estimation. While traditional approaches in entropy-based uncertainty estimation, prioritize high-confidence nodes for pseudo-labeling, this practice might unintentionally reinforce distributional biases, as highlighted by \cite{liu2022confidence}, where over-reliance on highly certain nodes risks a distribution shift between the original labeled set and the expanded pseudo-labeled set. Furthermore, \cite{li2023informative} observed that nodes with very high confidence often contribute redundant information, limiting the diversity of the labeled dataset and potentially biased learning process. To address this concerning issue, in this work, we suggest to balance node selection across a broader confidence range to improve the performance of our model.
% \vspace{-1em}
\section{Preliminaries}

\paragraph{Notations:}We adopt the following convention for random variables and their distributions in the sequel. 
A random variable is denoted by an upper-case letter (e.g., $Z$), its space of possible values is denoted with the corresponding calligraphic letter (e.g., $\mathcal{Z}$), and an arbitrary value of this variable is denoted with the lower-case letter (e.g., $z$). We denote the set of integers from 1 to $N$ by $[N]\triangleq \{1,\dots,N\}$; the set of 
measures over a space $\mathcal{X}$ with finite variance
is denoted
$\mathcal{P}(\mathcal{X})$. For a matrix $\mbX\in\bbR^{k\times q}$, we denote the $i-$th row of the matrix by $\mbX[i,:]$. The Euclidean norm of a vector
$X\in\bbR^q$ 
is $\norm{X}_2:=(\sum_{j=1}^q x_j^2)^{1/2}$. For a matrix $\mathbf{Y}\in\bbR^{k\times q}$, we let
$\norm{\mathbf{Y}}_{\infty}:=\max_{1\leq j\leq k}\sum_{i=1}^q|\mathbf{Y}[j,i]|$ and $\norm{\mathbf{Y}}_{F}:=\sqrt{\sum_{j=1}^k\sum_{i=1}^q\mathbf{Y}^2[j,i]}$.

\paragraph{Information Measures:} The KL divergence $\KLr(P\|Q)$ is given by
$\KLr(P\|Q):=\int_{\mathcal{Z}}\log\bigl(\frac{dP}{dQ}\bigr) dP$. We also define the cross-entropy between $P$ and $Q$, as  $H(P,Q)=-\int_{\mathcal{Z}}\log\bigl(dP\bigr) dQ$.

\paragraph{Graph data samples:} We consider transductive node classification for undirected graphs with $N$ nodes that have no self-loops or multiple edges.
Inputs to GNNs are node samples, 
which are comprised of their features and 
graph adjacency matrices. We denote the space of node feature for a node in the graph by $\mathcal{X}$. We consider the adjacency matrix $\mbA\in\mathcal{A}\subset \{0,1\}^{N\times N}$ to be fixed  with maximum node degree for $i$-th class
$\degmax_i$ and minimum node degree for $i$-th class
$\degmin_i$. The input pair of $i$-th node feature with dimension $k$ is denoted by $\mathbf{x}_i$. The GNN output (label) is denoted by $y\in \mathcal{Y}$ where $\mathcal{Y}$ is the space of labels and $|\mathcal{Y}|=k$.  Define $\mathcal{Z}=\mathcal{X}\times \mathcal{Y}$. Let $\mbZ_m=\{Z_i\}_{i=1}^m\in\mathcal{Z}$ denote the training of labeled dataset, where the $i-$th node sample is $Z_i=(X_i,Y_i)$. For transductive learning in node classification, we denote $\mbZ_u=\{Z_i\}_{i=1+m}^{m+u}\in\mathcal{Z}$ as the set of unlabeled dataset. We assume that the feature of nodes are i.i.d samples from the the feature space $\mathcal{X}$. We also denote the matrix of node features in the graph with $\mathbf{X}\in\mathbb{R}^{N\times k}$. We denote the learned distribution over classes as $P(\hat{\mathbf{Y}}|\mbX):=\{P(\hat{Y}=j|\mathbf{X})\}_{j=1}^k$ where $P(\hat{Y}=j|\mathbf{X}):=\frac{1}{n}\sum_{i=1}^{n} P(\hat{Y}=j|X_i)$ is the prediction of model for $j$-th class for given node-features $\{X_i\}_{i=1}^n$. Furthermore, we define $\mathbf{P}_k:=\{P_j\}_{j=1}^k$ as the target class distribution where $P_j = \frac{|m_j|}{\sum_{i=1}^k |m_i|}$ shows the probability of $j$-th class within the dataset.

\textbf{Graph filters:} Graph filters are linear functions of the adjacency matrix, $\mbA$, defined by $\mathrm{G}_f:\mathcal{A}\mapsto \bbR^{N \times N}$ where $N$ is the size of the graph, see in~\citep{defferrard2016convolutional}. Graph filters model the aggregation of node features in a GNN. For example, the symmetric normalized graph filter proposed by \citet{kipfsemi} is  $\mathrm{G}_f(\mbA)=\tilde{L}:=\tilde{D}^{-1/2}\Tilde{\mbA}\tilde{D}^{-1/2}$ where $\Tilde{\mbA}=I+\mbA$ is the augmented adjacency matrix, $\tilde{D}$ is the degree-diagonal matrix of $\Tilde{\mbA}$, and $I$ is the identity matrix. Furthermore, $\mathrm{deg}_i^{\max}$ and $\mathrm{deg}_i^{\min}$ are the maximum and minimum degree of nodes among $i$-th class of the graph with the augmented adjacency matrix, $\Tilde{\mbA}$. Another normalized filter, a.k.a. random walk graph filter~\citep{xupowerful2019}, is $\mathrm{G}_f(\mbA)=D^{-1}\mbA+I$, where $D$ is the degree-diagonal matrix of $\mbA$. The mean-aggregator is also a well-known aggregator defined as $\mathrm{G}_f(\mbA)=\tilde{D}^{-1}(\mbA+I)$. The sum-aggregator graph filter is defined by $\mathrm{G}_f(\mbA)=(\mbA+I)$.

\textbf{Loss function:} With $\mathcal{Y}$ the label space, the loss function $\ell: \mathbb{R} \times \mathcal{Y} \to \bbR$ is denoted as $\ell(\widehat{y},y)$, where $\widehat{y}$ is defined as the output of model, e.g., $\ell(h_\theta(\mathrm{G}_f(\mbA)[i,:]\mbX),y_i)$ is the loss function for $i$-th node in the graph where $h_\theta:\mathcal{X}\mapsto\mathcal{Y}$ is the hypothesis of our parameterized model which belongs to $\mathcal{H}$ with $\theta\in\Theta$.

\textbf{True and empirical risks:} The empirical risk function for labeled node samples $\mbX_m$ is given by 
\begin{equation} \label{eq: emp risk}
\begin{split}
     &\mrR(\mbZ_m,h_\theta):= \frac{1}{m}\sum_{i=1}^m \ell(h_\theta(\mathrm{G}_f(\mbA)[i,:]\mbX_m),y_i)\,.
     \end{split}
\end{equation}
We also define the true risk as the average of loss function over unlabeled nodes, $\mbX_u$, in transductive learning,
\begin{equation} \label{eq: true risk}
\begin{split}
     &\mrR(\mbZ_u,h_\theta):= \frac{1}{u}\sum_{i=m+1}^{m+u} \ell(h_\theta(\mathrm{G}_f(\mbA)[i,:]\mbX_u),y_i)\,.
     \end{split}
\end{equation}
We would like to study the performance of the model trained with the labeled data set $\mbZ_m=\{(\mbX_i,Y_i)\}_{i=1}^m$ and evaluated against the unlabeled dataset $\mbZ_u=\{(X_i,Y_i)\}_{i=m+1}^{m+u}$ loss, using transductive Rademacher complexity analysis~\citep{el2009transductive}.
% \vspace{-1em}
\section{The Generalization Error of Imbalance Transductive Node Classification}\label{sec: gen analysis}
This section provides a generalization error upper bound under an imbalance scenario for transductive node classification via Rademacher complexity analysis. All proof details are deferred to Appendix~\ref{app: sec: gen analysis}.

For theoretical analysis, we need the following assumptions.
\begin{assumption}[Bounded node features]\label{Ass: Feature node bounded}
For every node, the features are contained in an $\ell_2$-ball of radius $B_f$. In particular, $\|\mbX [i;]\|_2\leq B_f$ for all nodes.
\end{assumption}
\begin{assumption}[Bounded norm of parameters]\label{ass: bounded param}
 There exists $U_F(i)\in\mbR$ such that $\norm{\theta_i}_{F}\leq U_F(i) $   where $\theta_i$ is parameter matrix of $i$-th layer.
\end{assumption}
\begin{assumption}[Activation functions]\label{ass: bounded activation function} The activation function $\varphi:\mathbb{R}\mapsto\mathbb{R}$ is $1$-Lipschitz \footnote{For the Tanh and Relu activation function satisfy this assumption.}, so that $|\varphi(x_1)-\varphi(x_2)|\leq  |x_1-x_2|$ for all $x_1,x_2\in \mbR$,  and zero-centered, i.e., $\varphi(0)=0$.  
\end{assumption}

In theoretical analysis, we consider binary classification, based on \citep{bartlett2017spectrally}, where $\gamma$-margin loss function for binary classification is proposed. For a positive $\gamma\in\mbR^{+}$,we have, $\ell_\gamma(y_1,y_2)=0$ and $\ell_\gamma(y_1,y_2)=\min(1,1-\frac{y_1y_2}{\gamma})$ for $y_1y_2\geq \gamma$ and $y_1y_2<\gamma$, respectively.

For transductive learning analysis, inspired by \citet{el2009transductive}, we define empirical transductive Rademacher complexity as for $p\in[0,1/2]$ and let the set $\pmb{\epsilon}:=\{\epsilon_i\}_{i=1}^{m+u}$ be i.i.d. with probability $P(\epsilon_i=1)=P(\epsilon_i=-1)=p$ and $P(\epsilon_i=0)=1-2p$ for all $i\in[m+u]$ and assuming $p=\frac{m+u}{(m+u)^2}$, \[\mathfrak{R}_{m+u}(\mathcal{H}):= (\frac{1}{m}+\frac{1}{u})\mathbb{E}_{\pmb{\epsilon}}\Big[\sum_{i=1}^{m+u}\epsilon_i h_\theta(x_i)\Big].\]
Similarly, we can define the empirical transductive Rademacher complexity for $i$-th class with $\mathfrak{R}_{m_i+u_i}(\mathcal{H})$.
Furthermore, in transductive learning, we consider $m_i$ and $u_i$ as labeled nodes and unlabeled nodes belong to the $i$-th class. We first provide an upper bound on population risk for transductive learning under the imbalance scenario.

\begin{proposition}\label{prop: general bound}
    Let $Q_i=(\frac{1}{u_i}+\frac{1}{m_i})$, $S_i=\frac{m_i+u_i}{(m_i+u_i-1/2)(1-1/(2\max(m_i,u_i)))}$  for $i=1,2$. Then, with probability at least $(1-\delta)$ over the choice of the training set from nodes of graphs, for all $h_\theta\in\mathcal{H}$,
   \begin{equation*}
    \begin{split}
         &R(\mbZ_u,h_\theta)\leq \sum_{i=1}^2 R_{\gamma}(\mbZ_{m_i},h_{\theta})+\frac{u_i}{u}\Big(\frac{1}{\gamma}\mathfrak{R}_{m_i+u_i}(\mathcal{H})
       \\&\qquad +c_0 Q_i\sqrt{\min(m_i,u_i)}+\sqrt{\frac{S_iQ_i}{2}\log(1/\delta)}\Big),
    \end{split}
    \end{equation*}
    where $\mathfrak{R}_{m_i+u_i}(\mathcal{H})$ is the transductive Rademacher complexity for $i$-th class, $R_{\gamma}(\mbZ_{m_i},h_{\theta})$ is the empirical risk based on $\gamma$-margin loss for $i$-th class  and $c_0=\sqrt{\frac{32\ln(4e)}{3}}$.
\end{proposition}
Next, we provide an upper bound on the transductive Rademacher complexity for general deep GNN.
\begin{proposition}\label{prop: TR RC bound}
    Given Assumptions~\ref{Ass: Feature node bounded}, \ref{ass: bounded param} and \ref{ass: bounded activation function}, then the following upper bound holds on the transductive Rademacher complexity of node classification for GNN with depth $d$ and graph filter $\mathrm{G}_f(\mbA)$,
    \begin{equation*}
        \mathfrak{R}_{m_i+u_i}(\mathcal{H})\leq \frac{C_1\|\mathrm{G}_f(\mbA)[i]\|_{\infty}^{2(d-1)}\Pi_{j=1}^{d} U_F(j) }{\sqrt{m_i+u_i}},
    \end{equation*}
    where $C_1=B_f (\sqrt{2\log(2) d}+1)$ and $\|\mathrm{G}_f(\mbA)[i]\|_{\infty}$ is the infinite norm of graph filter among $i$-th class.
\end{proposition}
Combining Proposition~\ref{prop: TR RC bound} with Proposition~\ref{prop: general bound}, we can derive the following upper bound on population risk.
\begin{theorem}\label{thm: main result}
     Under the same Assumptions in Proposition~\ref{prop: general bound} and Proposition~\ref{prop: TR RC bound}, the following upper bound holds on population risk for imbalance transductive node classification under a GCN model,
     \begin{equation*}
    \begin{split}
         &R(\mbZ_u,h_\theta)\leq \sum_{i=1}^2 R_{\gamma}(\mbZ_{m_i},h_{\theta})\\&\quad+\frac{u_i}{u}\Big(\frac{B_f (\sqrt{2\log(2) d}+1)\Pi_{j=1}^{d} U_F(j) }{\gamma\sqrt{(m_i+u_i)}}\times \Bigg(\frac{\degmax_i+1}{\deg^{\min}+1}\Bigg)^{d-1}
        \\&\quad +c_0 Q_i\sqrt{\min(m_i,u_i)}+\sqrt{\frac{S_iQ_i}{2}\log(1/\delta)}\Big),
    \end{split}
    \end{equation*}
where $U_F(i)$ is the maximum of Frobenius norm of $i$-th layer parameter. 
\end{theorem}
% \begin{remark}\label{rem: gcn deg}
%     For GCN model with $\mathrm{G}_f(\mbA)=\tilde{D}^{-1/2}\tilde{A}\tilde{D}^{-1/2}$, we have $\|\mathrm{G}_f(\mbA)[i]\|_{\infty}^2=\sqrt{\frac{\deg^{\max}+1}{\deg^{\min}+1}}.$
% \end{remark}
\textbf{Convergence rate discussion:} For large values of $u_i$ and $m_i$ $(i\in{1,2})$, the value of $S_i$ approaches one. Moreover, we find $Q_i = O(1/\min(m_i,u_i))$ and $\mathfrak{R}_{m_i+u_i}(\mathcal{H})=O(1/(\sqrt{m_i+u_i}))$. Consequently, assuming $u_i\ll m_i$ for both $i=1,2$, yields an overall convergence rate of $O(1/u)$. Conversely, when $m_i \ll u_i$, the convergence rate becomes $O(\max(\frac{1}{\sqrt{m_1}},\frac{1}{\sqrt{m_2}})$. It's noteworthy that in the balanced case, where $u_1=u_2$ and $m_1=m_2$, assuming $m_i \ll u_i$ for $i=1,2$ recover the convergence rate applicable to balanced node classification, dependent on the maximum degree per class and the minimum degree.

\textbf{Maximum and Minimum Degrees:}  In balance transductive node classification, e.g., \citep{oono2019graph,cong2021provable,tang2023towards}, the upper bound on population risk is dependent on the maximum and minimum degree of all nodes. Our bound in Theorem~\ref{thm: main result} reveals that for an imbalance scenario, the upper bound depends on the maximum degree of nodes per class and the minimum degree of all graph nodes. Note that, this result can also be applied to balance scenario by assuming $m_i=m$ for all classes.

\textbf{Discussion:} Theorem \ref{thm: main result} reveals that the population risk upper bound is fundamentally dominated by the number of samples in the minority class. This theoretical insight suggests a straightforward yet powerful approach: increasing the representation of minority classes can improve classification performance. While this observation emerges directly from our theoretical analysis, its implications are significant as it applies broadly to any transductive imbalanced node classification task. In the following section, we propose an algorithm that leverages this insight by strategically assigning pseudo-labels to unlabeled nodes, thereby effectively augmenting the minority class representation and improving node-classification performance.

\section{UPL Algorithm}

\begin{figure*}[t]
    \centering
    \includegraphics[width=0.7\textwidth]{figures/nips/Input_Graph.pdf}
    \caption{Pipeline of the UPL Algorithm}
    \label{fig:pipline}
\end{figure*}
In this section, we introduce the Uncertainty-aware Pseudo-labeling  (UPL) Algorithm to mitigate the imbalance effect in transductive node classification.

In the UPL algorithm, we add pseudo-labels to unlabeled nodes of minority classes to mitigate the effect of imbalance node classification. Our UPL algorithm contains two blocks: uncertainty-aware pseudo-labeling, and balanced-softmax loss function. The pipeline of the UPL algorithm is shown in Figure~\ref{fig:pipline}. Our UPL algorithm involves an iterative training approach, leveraging the pseudo-labeling technique to enhance the model's performance on graph-based data.

\subsection{Uncertainty-aware Pseudo-labeling}

Pseudo-labeling is a semi-supervised learning technique that enhances model performance by generating synthetic labels for unlabeled data using a previously trained model. This method effectively expands the training dataset, allowing the model to learn from a broader range of examples and improve accuracy. Different strategies for Pseudo-labeling are proposed. In this work inspired by the technique in \citep{rizve2021in}, we propose an iterative uncertainty-aware pseudo-labeling method where the uncertainty is computed based on the graph's topology. 

\textbf{Pseudo-labeling:} To refine the selection of pseudo-labels, we incorporate two thresholds: a lower threshold ($\eta_l$) and an upper threshold ($\eta_u$). As proposed by \citet{rizve2021in}, the lower threshold selects high-confidence samples. To avoid overfitting to these high-confidence samples, we introduce an upper threshold, $\eta_u$, which selects samples with intermediate confidence levels. This can be seen as a band-pass filter on the nodes, including those within a specific probability range. This method balances the use of confident predictions with the exploration of less certain ones, preventing the model from becoming biased towards the nodes' most confident nodes. To mitigate, the noise of pseudo-lableling process, we also add pseudo-labels to minority classes and avoid the pseudo-labels for majority classes during training.

\textbf{Uncertainty-Aware:} Our proposed Selective Edge Removal (SER) method addresses the challenge of poor calibration in GNN pseudo-labeling by introducing a topology-aware uncertainty estimation approach. The method works by strategically removing edges based on node degrees, where highly-connected nodes have a higher probability of edge removal, then making multiple inferences on these perturbed graph versions. By measuring the entropy of predictions across different perturbed versions and computing the variance of these entropy values, we can effectively estimate prediction uncertainty for each unlabeled node. Nodes showing consistent predictions (low entropy variance) across perturbations are considered more reliable and selected for pseudo-labeling, specifically retaining the lowest 90\% based on uncertainty values. This approach naturally accounts for both aleatoric and epistemic uncertainty while preserving the graph's core structure, offering a computationally efficient way to improve pseudo-label quality in GNN applications.

Finally, combining the thresholds for the pseudo-labeling process and the uncertainty estimation, we can select the pseudo-label for an unlabeled node, i.e.,
\begin{equation}
\begin{split}
     \tilde{Y}_i&=\mathds{1}(P(\hat{Y}_i|X_i) \geq \eta_l)\mathds{1}(P(\hat{Y}_i|X_i)\leq \eta_u)\\ &\mathds{1}\big(\mathrm{U}(P(\hat{Y}_i|X_i)) \leq Q_{\alpha}\big) ,
\end{split}
\end{equation}
where $P(\hat{Y}_i|X_i)$ is the prediction of our model for node sample $X_i$ over classes and $\mathrm{U}(\cdot)$ is variance of entropy of each nodes predictions among different perturbations,$\mathrm{U}(P(\hat{Y}_i|X_i)) = \mathbb{VAR}_k(H_k(i))$
where $H_k(i)$ is the entropy of predictions for $i$-th node in the $k$-th perturbed graph. Also $Q_{\alpha}$ represent the quantile function for some $\alpha\in(0,1)$ as follows:
\begin{equation}
\begin{split}
Q_{\alpha} = \text{quantile}\big({\mathrm{U}(P(\hat{Y}_j|X_j)) : j = 1, \dots, n}, \alpha\big).
\end{split}
\end{equation}



% \vspace{-1em}
% \subsection{Regularization}
% In our regularization, we incorporate two terms within our GNN model, including, $\mathrm{H}( P(\hat{\mathbf{Y}} |\mathbf{X}) ,\mathbf{P}_k)$ as cross-entropy between the learned distribution across classes and the target class distribution and $\KLr( P(\hat{\mathbf{Y}} |\mathbf{X}) \|\mathbf{P}_k)$ as the KL-divergence between the learned distribution across classes and the target class distribution.
% % \begin{equation}\begin{split}
% % \label{eq:RKC_equation}
% % \text{RKC}\ :=\  \lambda_{\mathrm{RKC}} +,
% % \end{split}\end{equation}
% % where 
% % $\KLr(P(\hat{\mathbf{Y}}|\mathbf{X})\|\mathbf{P}_k)=\sum_{j=1}^k P(\hat{Y}=j|\mathbf{X}) \log(P(\hat{Y}=j|\mathbf{X})/P_j)$ and
% % $\mathrm{H}(P(\hat{\mathbf{Y}}|\mathbf{X}),\mathbf{P}_k)=-\sum_{j=1}^k P(\hat{Y}=j|\mathbf{X}) \log(P_j),$
% % is  and .
% Note that minimizing the KL divergence would cause the model to have an empirical learned distribution over classes close to the target distribution over classes.

% Regarding the target class distribution, we can assign more probability mass points to minority classes while reducing them for the majority classes. We can also consider the uniform distribution if the test dataset is assumed to be balanced. Integrating these specific regularization terms during training encourages the model to acquire a distribution that aligns more closely with this target class distribution over classes. We are applying these particular regularization terms to address imbalance classification, especially in the context of node classification. We also discuss the combination of this regularization with other methods in literature in Appendix~\ref{app-sec: experiments}.
%  % To the best of our knowledge, 
% \vspace{-1em}
\subsection{Balanced Softmax loss function}
The balanced softmax loss function~\citep{ren2020balanced} is a variant of the traditional softmax loss designed to address the issue of class imbalance in multi-class classification problems. The primary idea is to introduce a class-specific weighting factor, $\beta_c$, which adjusts the contribution of each class to the overall loss. This weighting factor is inversely proportional to the class frequency, assigning higher weights to underrepresented classes and lower weights to overrepresented classes. The formulation of the balanced softmax loss is given by
\begin{equation}
 -\frac{1}{N} \sum_{i=1}^{N} \sum_{c=1}^{k} \beta_c y_{ic} \log(p_{ic}),
\end{equation}
where $N$ is the number of training samples, $k$ is the number of classes, $y_{ic}$ is the ground truth label (0 or 1) for sample $i$ and class $c$, $p_{ic}$ is the predicted probability for sample $i$ and $c$-th class , and $\beta_c$ is the weighting factor calculated as $\beta_c = \frac{(1 - \alpha)}{(1 - \alpha^{m_c})} \alpha^{(1 - m_c)}$. Here, $\alpha$ is a hyperparameter controlling the degree of balancing, and $m_c$ is the number of training samples belonging to $c$-th class. This adjustment ensures that the model pays more attention to the minority classes during training, improving performance on imbalanced datasets. Finally, the details and operational steps of the UPL algorithm are outlined in Appendix~\ref{app: UPL alg detail}.
 \vspace{-1em}
\section{Experiment}\label{sec: experiments}
In this section, we provide the results of experiments for our UPL algorithm. All experiments setup details are provided in Appendix~\ref{app: Exp details}. All experiments are conducted on GCN models. More GNN architectures, e.g., GAT and GraphSage, are studied in Appendix~\ref{App: more exp}.
\paragraph{Baselines:} In our experiments, we compare our proposed method against a blend of both foundational and state-of-the-art (SOTA) methods. In particular, we include
foundational baselines: Vanila, Re-weight \citep{japkowicz2002class}, DR-GCN~\citep{shi2020multi} and Balanced Softmax~\citep{ren2020balanced}. Furthermore, we also consider recent SOTA methods, including, PC Softmax~\citep{hong2021disentangling}, GraphSMOTE~\citep{zhao2021graphsmote}, GraphENS~\citep{park2022graphens}, TAM~\citep{song2022tam}, and Unreal \citep{yan2023unreal}.

\paragraph{Datasets:} In our experiments, we utilize citation network datasets—CiteSeer, Cora, and Pubmed \citep{sen2008collective}—which we categorize as homophilic graphs, where nodes represent documents and edges represent citation links. For heterophilic graphs, we employ Chameleon and Squirrel \citep{rozemberczki2021multi}, where nodes represent Wikipedia pages and edges denote links between them, as well as Wisconsin, a graph composed of web pages crawled from the Internet by \citet{craven2000learning}. Furthermore, we use the Amazon Computers and Amazon Photos datasets \cite{shchur2019pitfallsgraphneuralnetwork} in Appendix \ref{App: more exp}.

 \textbf{Imbalance Learning:} In a classification scenario with training dataset $z = \{z_1, \ldots, z_n\}$ where $z_i=(x_i,y_i)$, the imbalance occurs when the distribution $\mathbf{P}_k$ over $k$ classes within the dataset has larger probability mass points over some classes. The imbalance severity is often quantified using an imbalance ratio $\rho$, which measures the ratio between the number of samples in the most populated class (majority class) and the least populated class (minority class) and can be defined as follows,
\begin{equation}
     \quad \rho = \frac{\max_{j\in[k]} |m_j|}{\min_{j\in[k]} |m_j|}.
\end{equation} 
\vspace{-1em}

\textbf{Hyper-parameter Sensitivity}: We conducted a sensitivity analysis on the two thresholds used in pseudo-labeling to evaluate the model's performance at various values of $\eta_l$ and $\eta_u$. The results of this parameter sweep are presented in Figure \ref{fig:sweep_bounds}.

The chart on the left shows the F1-score as $\eta_l$ is varied within the range $(0.25, 1.0)$, while $\eta_u$ is set to $\min(\eta_l + 0.3, 1.0)$. Based on this lower-threshold sweep, we observe that the optimal value of $\eta_l$ for this case lies within the range $(0.25, 0.45)$. A similar trend is observed across other datasets.

The right plot in Figure \ref{fig:sweep_bounds} depicts the results of varying $\eta_u$ within the range $(0.3, 1.0)$, with $\eta_l$ fixed at 0.3. These results further support the importance of using an upper threshold. Specifically, setting $\eta_u$ within the range $(0.35, 0.45)$ improves the overall F1-score on both the validation and test sets.

\begin{figure}[ h!]
    \centering
    \includegraphics[width=1.0\columnwidth]{figures/nips/destination_path.pdf}
    \caption{F1-score for different values of upper and lower thresholds for pseudo-labeling. The Figure on the left indicates the sweeping over $\eta_l$ while $\eta_u=0.3+\eta_l$ for the CiteSeer dataset. The Figure on the right represents sweeping over $\eta_u$ from $0.3$ to $1.0$ for Cora. In both Figures, the red line represents the validation results, and blue shows the result for the test set.}
    \label{fig:sweep_bounds}
\end{figure}

% \begin{figure*}[t]
%     \centering
%     \includegraphics[width=0.8\textwidth]{figures/nips/Input Graph v2.pdf}
%     \caption{Pipeline of the UPL Algorithm}
%     \label{fig:pipline}
% \end{figure*}

\subsection{Experiment results}
To further study the effect of UPL, we have conducted experiments on multiple datasets, a fraction of which has been shown in Table \ref{tb:main_chart_homo} and \ref{tb:main_chart_hetero}.
We report averaged balanced accuracy (bAcc)\footnote{Balanced accuracy is calculated as $\frac{1}{2}\big(\frac{\mathrm{TP}}{\mathrm{TP}+\mathrm{FN}}+\frac{\mathrm{TN}}{\mathrm{TN}+\mathrm{FP}} \big)$ where $\mathrm{TP}$ is true positive, $\mathrm{FN}$ is false negative and $\mathrm{TN}$ is true negative.} and F1-score with the standard errors for 10 repetitions on the GCN model. In our experiments, datasets are generated with an imbalance ratio of $\rho=10$. We explore other imbalance ratios in Appendix~\ref{App: more exp}.

\input{Results/nips/Main_chart_homo}
\input{Results/nips/Main_chart_hetero}
As shown in Tables \ref{tb:main_chart_homo} and \ref{tb:main_chart_hetero}, our UPL algorithm outperforms other baselines across both homophilic and heterophilic datasets in most cases. Notably, UPL demonstrates significantly lower performance variance than competing methods, indicating better reliability in its predictions. Table \ref{tb:main_chart_hetero} also highlights a common challenge which is a marked decline in performance on heterophilic datasets. In contrast, our method consistently delivers better results in most cases, even in these challenging scenarios. Moreover, based on theoretical results and the fact that the maximum degree of nodes per class in heterophilic datasets is large, then we expect lower accuracy over these datasets.

\input{Results/nips/Ablation_homo}
\vspace{-0.05in}

\textbf{Uncertainty methods:} We evaluate our approach's uncertainty estimation on the Cora dataset, comparing against two uncertainty estimation methods for GNN as baselines: CaGCN~\cite{wang2021be} and ALG~\cite{zhang2021alg} in Table~\ref{tb:uncertainty_methods}. Our results show that imbalanced data significantly impacts uncertainty estimation performance in existing graph-based models.
% \todoa{Could you add other dataset also? }\todot{(Done)}
\begin{table}[H]
\centering
\caption{Comparison of our model with CaGCN and Alg as uncertainty estimation in GNN utilizing uncertainty in graphs has been tested under the imbalance scenario with ratio $\rho=10$.}
\label{tb:uncertainty_methods}
\vspace{-0.5em}
\resizebox{0.6\columnwidth}{!}{\begin{tabular}{c|c|c}
\toprule
\textbf{Methods} & \textbf{Cora} & \textbf{CiteSeer} \\ \cline{1-3}
CaGCN 
& $46.23$ \tiny{$\pm 0.49$}
& $23.42$ \tiny{$\pm 0.74$}
\\ 
Alg   
& $67.48$ \tiny{$\pm 0.76$}
& $27.50$ \tiny{$\pm 0.85$}
\\ 
UPL   
& $74.51$ \tiny{$\pm 0.65$}
& $67.78$ \tiny{$\pm 0.25$}
\\
\bottomrule
\end{tabular}}
\end{table}
 
\textbf{Comparison with UNREAL:} Our algorithm, UPL, demonstrates notable computational advantages over the UNREAL algorithm \citep{yan2023unreal}. UPL's efficiency stems from two key factors: first, it employs a more selective pseudo-labeling process that focuses on minority classes, resulting in fewer pseudo-labeled nodes overall. Second, UPL eliminates the need for two computationally intensive components present in UNREAL—node reordering and clustering—which contribute significantly to that algorithm's complexity. Instead, UPL introduces a novel framework that incorporates uncertainty estimation and an upper threshold for pseudo-labeling. In contrast, the UNREAL algorithm operates through a series of three main steps, 
\begin{itemize}[nosep, leftmargin=*]
    \item Dual Pseudo-tag Alignment Mechanism (DPAM): This step involves clustering all nodes, which inherently have a complexity of $O(N^2)$ for $N$ nodes, and then inferring the GCN model.
    \item Node-Reordering: Utilizes the Rank-Biased Overlap (RBO) algorithm \citep{webber2010similarity} to merge two sorted lists generated by clustering and GCN inference. This merging process also presents a complexity of $O(N^2 )$ for $N$ nodes.
    \item Discarding Geometrically Imbalanced Nodes (DGIN): This step computes the second nearest cluster center for each node, leading to a complexity of $O(Nk)$, where $k$ is the predefined number of clusters,
\end{itemize}
where each iterated $T$ times, potentially leading to increased computational overhead. By reducing both the number of operations each step, UPL achieves improved efficiency without sacrificing performance. In particular, our UPL algorithm simplifies the computational process significantly,
\begin{itemize}[nosep, leftmargin=*]
    \item Uncertainty estimation: UPL involves sampling the edges to be removed based on their distribution to estimate the uncertainty. This process is iterated $S_k$ times.
    \item Subsequently, similar to UNREAL, we infer the GCN model.
\end{itemize}
Notably our complexity is less than the UNREAL, as we avoid DGIN and RBO processes in UNREAL. More discussion is provided in App.~\ref{app:comp_unreal}.
% \input{Results/nips/Ablationـhomo}
\vspace{-0.1in}
\subsection{Ablation study}
We evaluate key components' individual and combined effects on our UPL algorithm to discover their contributions in transductive node classification tasks under imbalance scenario, for both homophilic and heterophilic datasets, in Table~\ref{tb:Ablation_homo}, respectively. For this purpose, we use BalancedSoftmax \textbf{(BS)}, which adjusts softmax to favor minority classes; Uncertainty-aware Pseudo-labeling \textbf{(UPL)}, which uses generated pseudo-labeled samples to generate more training data; aiming to align predicted class distributions with actual distributions. In Tables~\ref{tb:Ablation_homo}, The Vanilla model serves as our baseline which is log-loss function.  \newline The results demonstrate the effectiveness of various strategies for addressing class imbalance in node classification tasks. Across all datasets, the UPL method consistently excels, showcasing the robustness of integrating approaches. Notably, combinations like BS + UPL frequently lead to significant performance improvements, highlighting the synergy between direct imbalance mitigation and the strategic use of pseudo-labeled data. 
\vspace{-1em}
\section{Conclusion and Future Works}
In this study, we make several key contributions to transductive node classification in imbalanced scenarios. First, we establish a theoretical upper bound on the population risk that depends on the maximum degree node within each class. Second, we develop an uncertainty-aware algorithm for identifying pseudo-labels for minority class nodes, introducing a novel selective edge removal method for uncertainty estimation. Our approach demonstrates superior performance compared to baseline methods across both homophilic and heterophilic datasets.

 While our theoretical analysis currently focuses on $\gamma$-margin loss functions in binary classification, several promising directions emerge for future work. From a theoretical perspective, we aim to extend our results to multi-class scenarios and broader loss functions, as well as expand the analysis to Inductive node classification settings where unlabeled nodes are not observed during training. Additionally, we plan to investigate theoretical bounds for heterophilic graphs to strengthen our framework's theoretical foundation.

As future work, we envision integrating our approach with H2GCN approach~\citep{zhu2020beyond} to enhance performance on heterophilic datasets. We also plan to incorporate advanced pseudo-labeling techniques such as Meta-Pseudo Label \citep{pham2021meta} or Flexmatch \citep{zhang2021flexmatch} to improve label quality. Finally, we intend to explore subgraph-based selective edge removal approaches for more sophisticated uncertainty estimation.
% \clearpage
% \newpage

\clearpage
\section*{Impact Statement}
This paper presents work whose goal is to advance the field of 
Machine Learning. There are many potential societal consequences 
of our work, none which we feel must be specifically highlighted here.

\bibliographystyle{icml2025}
\bibliography{biblography}

\newpage
\appendix
\onecolumn

\addcontentsline{toc}{section}{Appendix} % Add the appendix text to the document TOC
\part{Appendix} % Start the appendix part
\parttoc % Insert the appendix TOC

\newpage
\section{Notations}\label{app:notation}
Notations in this paper are summarized in Table~\ref{Table: notation}.

\begin{table}[ht]
    \centering
    \caption{Summary of notations in the paper}
    \resizebox{\linewidth}{!}{
    \begin{tabular}{cl|cl}
        \toprule
        Notation & Definition & Notation & Definition \\
        \midrule
        $\mathcal{A}$ & Adjacency matrices space & $X_i$ & $i$-th node feature \\
        $\degmax_i$ & Maximum node degree i-th class & $\degmin_i$ & Minimum node degree i-th class \\
        $Y_i$ & $i$-th node's label & $Z_i$ & $i$-th node sample pair $(X_i, Y_i)$ \\
        $\mbZ_m$ & The set of data training samples & $\mbZ_u$ & The unlabeled samples \\
        $P(.)$ & Prediction of model & $m_i$ & Number of nodes in $i$-th class \\
        $k$ & Number of classes & $P_j$ & $\frac{|m_j|}{\sum_{i=1}^k{|m_i|}}$ \\
        $d_{\min}$ & Minimum node degree of among all classes & $\mathrm{G}_f(\mbA)$ & Graph filter with input matrix $\mbA$ \\
        $l(\hat y , y)$ & Loss function & $h_\theta$ & Parameterized model \\
        $B_f$ & $l_2$-ball of radius & $\theta_i$ & Parameter matrix of i-th layer \\
        $\varphi$ & Activation function &  $\mathfrak{R}_{m+u}(\mathcal{H})$ & Empirical Rademacher complexity   \\
       
          $R(Z_u, h_\theta)$ & True risk over unlabeled dataset  & $R(Z_m, h_\theta)$ & Empirical risk over labeled dataset\\
        $U_F(i)$ & Maximum of Frobenius norm i-th layer parameters & $U(.)$ & Uncertainty Function \\
        $\eta_l$ & Lower thresholds of Pseudo-labeling process & $\eta_u$ & Upper thresholds of Pseudo-labeling process \\
        $\KLr(P\|Q)$ & $\int_{\mathbb{Z}} \log(\mrd P/\mrd Q) \mrd P$ & $H(P,Q)$ & $\int_{\mathbb{Z}} \log(\mrd P) \mrd Q$
        \\$B_f$ & Bound on node features  & $\rho$ & Imbalance Ratio \\
        $\norm{\mathbf{Y}}_{F}$ & $\sqrt{\sum_{j=1}^k\sum_{i=1}^q\mathbf{Y}^2[j,i]}$ & $\norm{\mathbf{Y}}_{\infty}$ & $\max_{1\leq j\leq k}\sum_{i=1}^q|\mathbf{Y}[j,i]|$ \\
        $\norm{\mathbf{Y}}_{2}$ & $\left(\sum_{j=1}^q |q| x_j^2\right)^{1 / 2}$  & $Q_{\alpha}$ & Quantile of order $\alpha$\\
        $t$ & Number of itterations & $S_k$ & Number of edges removed in each itteration\\
        \bottomrule
    \end{tabular}}
    \label{Table: notation}
\end{table}

% \begin{table}[ht]
%     \centering
%     \caption{Summary of notations in the paper}
%    \resizebox{\linewidth}{!}{ \begin{tabular}{cl|cl}
%          \toprule
%          Notation&  Definition & Notation&  Definition\\
%          \midrule
%          % $\mathcal{W}$ & Parameter space of the model &
%          % $\mathcal{F}$ & Feature matrices space\\
%          $\mathcal{A}$ & Adjacency matrices space&
%          % $\mbF$ & Matrix of feature nodes of a graph sample\\
%          % $\mbA$ & Adjacency matrix of a graph sample\\
%          $x$ & Node feature \\
%          % $D$ & Degree matrix of $A$\\
%          % & $\mbX$ & input graph sample where $\mbX=(\mbA,\mbF)$\\
%          $deg_i ^{\max} $ & maximum node degree i-th class & $deg_i ^{\min} $ & minimum node degree i-th class \\
%          $Y$ & Label of input graph &
%          $Z_i$ & $i$-th graph sample $(\mbX,Y)$\\
%          $\mbZ_m$ & The set of data training samples&  $\mbZ_u$ & The unlabeld samples& 
%          \\$P(.)$ & Prediction of model &
%          % $\tilde{L}$ & Symmetric normalized graph filter&
%          $m_i$ & number of node with i label\\
%         % $n$ & Number of graph data samples  \\
%         $k$ & number of labels&
%         $P_j$ & ${|m_j|}/\sum_{i=1}^k{|m_i|}$\\
%         % $N_{\max}$ & Maximum number of nodes of all graph samples&
%         % $d_{\max}$ & Maximum node degree of all graph samples \\
%         $d_{\min}$ & Minimum node degree of all graph samples &
%         $\mathrm{G}_f(\mbA)$ & Graph filter with input matrix $\mbA$\\
%         $l(\hat y , y) $ & loss function&
%         % $\mun$ & Empirical data measure &
%         % $\mur$ & Replace-one sample empirical data measure \\
%         $h_\theta$ & parameterized model\\
%         $B_f$ & $l_2-ball$ of radius & 
%         $\theta_i$& parameter matrix of i-layer
%         % $M_{\phi}$ & Bound on unit function &
%         % $M_{\ell'}$ & Bound on $|\partial_{\hat y}\ell(\hat y, y)|$\\
%         $\varphi$ & activation function &
%         $L_\varphi$ &???? \\
%         $\mathfrak{R}_{m+u}(\mathcal{H})$& ????& 
%         $Q_i$ & ??? theory\\
%         $S_i$& ??? theory &
%         $R(Z_u,h_\theta)$ & ??? theory\\
%         $U_F(i)$ & maximum of Frobenius norm i-th layer param & $UT(.)$ & Uncertainty Function\\
%         $\eta_l$& lower  boundary of UPL Algorithm
%         & \eta_u$ & Upper boundary of UPL Algorithm\\
%         $\kappa$ & ??? pseudo code&
%         $MM_{v,\mathrm{argmax}(P_k^v)}$ & ??? pseudo code\\
%         $y^P$ & Pseudo labels??? & $H(P,Q)$ & $\int_{\mathbb{Z}} \log(\mrd P)\mrd Q$\\
%         $\zeta(\cdot)$&
%         $L_\rho$& Lipschitz parameter of function $\rho(\cdot)$\\
%         $L_\kappa$& Lipschitz parameter of function $\kappa(\cdot)$&
%         $L_\psi$ & Lipschitz parameter of readout function $\psi(\cdot)$\\
%         $L_{\varphi}$& Lipschitz parameter of activation function $\psi(\cdot)$&
%         $B_f$ & Bound on node features\\
%         $\alpha$ & Inverse temperature&
%         $h$ & Width of hidden layer\\
%         $\pi$ & Prior measure over parameters&
%         $\mrm^{\alpha}$ & The Gibbs measure for General GNN model\\
%         $\mrm^{\alpha,c}$ & The Gibbs measure for GCN model&
%         % $\mrm^{\alpha,p}$ & The Gibbs measure for MPGNN model\\
%         $m_{\mathrm{true}}$ & True distribution over data samples&
%         $G_{\max}$ & $\min(\norm{G(\mathcal{A})}_{\infty}^{\max},\norm{G(\mathcal{A})}_{F}^{\max})$\\
%         $\Psi(\cdot)$ & Readout function & $(W_{1,c},W_{2,c})$ & Parameters of Neuron unit\\
%         $(W_{1,p},W_{2,p},W_{3,p})$ & Parameters of MPU unit & $\genb(\mrm(\mun),\mu)$ & Generalization error under parameter measure $\mrm(\mun)$\\ $\beta_{\mathrm{sup}}$ & Supervised ratio & $\norm{\mathbf{Y}}_{F}$ & $\sqrt{\sum_{j=1}^k\sum_{i=1}^q\mathbf{Y}^2[j,i]}$ \\
%         $\norm{\mathbf{Y}}_{\infty}$& $\max_{1\leq j\leq k}\sum_{i=1}^q|\mathbf{Y}[j,i]|$ &\\
%         $\norm{\mathbf{Y}}_{2}$& $\sum_{j=1}^q|q|x_j^2)^{1 / 2}$ &\\
%         $\KLr(P\|Q)$ & $\int_{\mathbb{Z}} \log(\mrd P/\mrd Q)\mrd P$\\
        
%          \bottomrule
%     \end{tabular}}
%     \label{Table: notation}
% \end{table}
\section{Other Related Works}\label{app:other_related_work}
\textbf{Pseudo-labeling in semi-supervised learning:} Pseudo-labeling, introduced in~\citep{lee2013pseudo}, involves training a model using labeled data and assigning pseudo-labels to the unlabeled data based on the model's predictions. These pseudo-labels are then used to construct another model, which is trained in a supervised manner using both labeled and pseudo-labeled data. Under different scenarios, it is shown that the pseudo-labeling is effective,  \citep{arazo2020pseudolabeling} and \citep{rizve2021in}. \citep{kou2023how} shows that semi-supervised learning with pseudo-labeling can achieve near-zero test loss under some conditions. The study by \citet{DBLP:journals/corr/abs-2003-10580} introduced meta pseudo-labeling. This method enhanced pseudo-labels' accuracy by incorporating feedback from the student model. \citep{rizve2021in} proposed confidential-based pseudo-label generation for training a network with unlabeled data. \citep{arazo2020pseudolabeling} suggests soft-labeling with the MixUp method to reduce over-fitting to
model predictions and confirmation bias. In contrast, our work is focused on transductive node classification, and we employed the Pseudo-labels to mitigate the imbalance effect.

\textbf{Imbalance Classification:} Effective classification in the presence of imbalanced data is an important research field in supervised and semi-supervised learning, given that a significant class imbalance is commonly found in numerous real-world contexts \citep{herland2018big,rao2006data,cieslak2006combating} such as fraud detection in finance applications \citep{wei2013effective}. This imbalance often presents challenges, as many classifiers tend to prefer the majority class, sometimes to the extent of completely overlooking the minority class. 
Traditional Class Imbalance Learning methods typically fall into two broad categories: data-level methods and algorithm-level methods. Data-level techniques aim to rebalance the training data itself to mitigate class imbalance. This includes strategies like over-sampling the minority class \citep{chawla2002smote,he2008adasyn,mullick2019generative}, under-sampling the majority class \citep{laurikkala2001improving,mani2003knn}, and hybrid methods that combine both over-sampling and under-sampling \citep{ramentol2012smote,saez2015smote}. On the other hand, algorithm-level methods focus on modifying the learning algorithms to better handle class imbalance. These methods encompass cost-sensitive learning \citep{tang2008svms,zhou2005training}, ensemble learning \citep{seiffert2009rusboost, guo2004learning, chawla2003smoteboost}, and engineering of specialized loss functions \citep{cao2019learning, dong2018imbalanced, cui2019class}.


\section{Proof and details of Section~\ref{sec: gen analysis}}\label{app: sec: gen analysis}

\begin{lemma}[Bound on infinite norm of the symmetric normalized graph filter]\label{lem: bound on inf norm of L}
Consider a graph sample $G$ with adjacency matrix $A$. For the symmetric normalized graph filter, we have $\norm{\tilde{D}^{-1/2}(A+I)\tilde{D}^{-1/2}}_{\infty}[k]\leq \sqrt{\frac{\deg^{\max}_k+1}{\deg^{\min}+1}}$ where $\deg^{\max}_k$ is the maximum degree of graph $G$ with adjacency matrix $A$ among the nodes in $k$-th class. 
\end{lemma}
\begin{proof}
Recall that $\tilde{A}=A+I$. We have,
\begin{equation}
\begin{split}
\norm{\tilde{L}}_{\infty}[k]&=
\norm{\tilde{D}^{-1/2}\tilde{A}\tilde{D}^{-1/2}}_{\infty}[k]\\
&=\max_{i\in[N_k]}\sum_{j=1}^N \frac{\tilde{A}_{ij}}{\sqrt{\deg_{i}+1}\sqrt{\deg_{j}+1}}\\
&\leq\frac{1}{\sqrt{\deg^{\min}+1}} \max_{i\in[N_k]}\sum_{j=1}^{N} \frac{\tilde{A}_{ij}}{\sqrt{\deg_{i}+1}}\\
&\leq  \sqrt{\frac{\deg^{\max}_k+1}{\deg^{\min}+1}}.
\end{split}
\end{equation}
where $N_k$ is the number nodes in $k$-th class.
\end{proof}
\begin{repproposition}{prop: general bound}[\textbf{Restated}]
    Let $Q_i=(\frac{1}{u_i}+\frac{1}{m_i})$, $S_i=\frac{m_i+u_i}{(m_i+u_i-1/2)(1-1/(2\max(m_i,u_i)))}$  for $i=1,2$. Then, with probability at least $(1-\delta)$ over the choice of the training set from nodes of graphs, for all $h_\theta\in\mathcal{H}$,
    \begin{equation*}
    \begin{split}
         R(\mbZ_u,h_\theta)\leq \sum_{i=1}^2 R_{\gamma}(\mbZ_{m_i},h_{\theta})+\frac{u_i}{u}\Big(\frac{1}{\gamma}\mathfrak{R}_{m_i+u_i}(\mathcal{H})
        +c_0 Q_i\sqrt{\min(m_i,u_i)}+\sqrt{\frac{S_iQ_i}{2}\log(1/\delta)}\Big),
    \end{split}
    \end{equation*}
    where $\mathfrak{R}_{m_i+u_i}(\mathcal{H})$ is the transductive Rademacher complexity for $i$-th class, $R_{\gamma}(\mbZ_{m_i},h_{\theta})$ is the empirical risk based on $\gamma$-margin loss for $i$-th class  and $c_0=\sqrt{\frac{32\ln(4e)}{3}}$.
\end{repproposition}
\begin{proof}
    Let's decompose the true risk as follows,
    \begin{equation}\label{eq: v1}
        R(\mbZ_u,h_\theta)=\sum_{i=1}^2\frac{u_i}{u} R(\mbZ_{u_i},h_\theta),
    \end{equation}
    where $R(\mbZ_{u_i},h_\theta)$ is true risk of $i$-th class. Inspired by \citep[Corollary~1]{el2009transductive}, we have,
     \begin{equation}\label{eq: v2}
     \begin{split}
           R(\mbZ_{u_i},h_\theta)\leq R_{\gamma}(\mbZ_{m_i},h_{\theta})+\frac{1}{\gamma}\mathfrak{R}_{m_i+u_i}(\mathcal{H})
        +c_0 Q_i\sqrt{\min(m_i,u_i)}+\sqrt{\frac{S_iQ_i}{2}\log(1/\delta)}.
     \end{split}
    \end{equation}
    Combining \eqref{eq: v2} with \eqref{eq: v1}, we have,
    \begin{equation}
        \begin{split}
            R(\mbZ_u,h_\theta)&=\sum_{i=1}^2\frac{u_i}{u} R(\mbZ_{u_i},h_\theta)\\
            &\leq \sum_{i=1}^2 \frac{u_i}{u} \Big(R_{\gamma}(\mbZ_{m_i},h_{\theta})+\frac{1}{\gamma}\mathfrak{R}_{m_i+u_i}(\mathcal{H})
        +c_0 Q_i\sqrt{\min(m_i,u_i)}+\sqrt{\frac{S_iQ_i}{2}\log(1/\delta)}\Big).
        \end{split}
    \end{equation}
    It completes the proof by considering $\frac{u_i}{u}\leq 1$.
\end{proof}

\begin{repproposition}{prop: TR RC bound}[\textbf{Restated}]
    Given Assumptions~\ref{Ass: Feature node bounded} , \ref{ass: bounded param} and \ref{ass: bounded activation function}, then the following upper bound holds on the transductive Rademacher complexity of node classification,
    \begin{equation*}
        \mathfrak{R}_{m_k+u_k}(\mathcal{H})\leq \frac{B_f (\sqrt{2\log(2) d}+1)\Pi_{j=1}^{d} U_F(i) \|\mathrm{G}_f(\mbA)[i]\|_{\infty}^{2(d-1)}}{\sqrt{m_k+u_k}}
    \end{equation*}
    where $\|\mathrm{G}_f(\mbA)[k]\|_{\infty}$ is the infinite norm of graph filter among $k$-th class.
\end{repproposition}
\begin{proof}
      Fix $\lambda>0$, to be chosen later.
      Let us denote the output of $q$-th layer of GCN as, 
      \[N_{\theta_q}(\mathbf{X}_{u_k+m_k})=\sigma(\theta_{q-1}\mathrm{G}_f(\mbA)[i,:](\cdots\sigma(\theta_1\mathrm{G}_f(\mbA)[i,:]\mathbf{X}_{u_k+m_k}))).\]
      For the last layer, we do not consider aggregation.
      The Rademacher complexity can be 
    upper bounded as
    \begin{align*}
    \Big(\frac{m_k u_k}{m_k+u_k}\Big)\mathfrak{R}_{m_k+u_k}(\mathcal{H}) &= \E_{\boldsymbol{\epsilon}} 
    \sup_{N_{\theta_{d-1}},\theta_d} \sum_{i=1}^{m_k+u_k} 
    \epsilon_i \theta_d \sigma(\theta_{d-1}\mathrm{G}_f(\mbA)[i,:]N_{\theta_{d-1}}(\mathbf{X}_{u_k+m_k}))  \\
    &\leq \frac{1}{\lambda} \log \E_{\boldsymbol{\epsilon}} \sup 
    \exp\left( \lambda \sum_{i=1}^{m_k+u_k} 
    \epsilon_i \theta_d \sigma(\theta_{d-1}\mathrm{G}_f(\mbA)[i,:]N_{\theta_{d-1}}(\mathbf{X}_{u_k+m_k}))\right) \\
    &\leq \frac{1}{\lambda} \log \E_{\boldsymbol{\epsilon}} \sup \exp  
    \left( U_F(d)\cdot 
    \left\|\lambda \sum_{i=1}^{m_k+u_k} \epsilon_i 
    \sigma\big(\theta_{d-1}\mathrm{G}_f(\mbA)[i,:]N_{\theta_{d-1}}(\mathbf{X}_{u_k+m_k})\big) \right\| \right).
    \end{align*}
    We write this last expression as
    \begin{align*}
    &\frac{1}{\lambda} \log \E_{\boldsymbol{\epsilon}} \sup_{f, 
        \|\theta_{d-1}\|_F \leq U_F(d-1)} 
    \exp  \left( U_F(d)\cdot \lambda \left\| \sum_{i=1}^{m_k+u_k} \epsilon_i 
    \sigma(\theta_{d-1} \mathrm{G}_f(\mbA)[i,:]N_{\theta_{d-1}}(\mathbf{X}_{u_k+m_k})) \right\| \right)\\
    &\leq \frac{1}{\lambda} \log \left( 2\cdot 
    \E_{\boldsymbol{\epsilon}} \sup_{f} \exp \left( 
    U_F(d)\cdot U_F(d-1) \cdot  \|\mathrm{G}_f(\mbA)\|_{\infty}^{2} \lambda \left\| \sum_{i=1}^{m_k+u_k} \epsilon_i 
    N_{\theta_{d-1}}(\mathbf{X}_{u_k+m_k}) \right\| \right) \right).
    \end{align*}
     Repeating the process, we arrive at
    \begin{align}
     \Big(\frac{m_k u_k}{m_k+u_k}\Big)\hat{\Rcal}_{m_i+u_i}(\Hcal) &\leq \frac{1}{\lambda} \log \left(2^d \cdot 
    \E_{\boldsymbol{\epsilon}} 
    \exp \left( M \lambda \left\| \sum_{i=1}^{m_k+u_k} \epsilon_i \mathbf{X}_{i} \right\| 
    \right) \right).
    \label{eq:softmax_bd}
    \end{align}
    where $V= \|\mathrm{G}_f(\mbA)\|_{\infty}^{2(d-1)} \prod_{j=1}^d U_F(j)$.
    Define a random variable
    $$Z = V\cdot\left\|\sum_{i=1}^{m}\epsilon_i \mathbf{X}_{i}\right\|,$$
    (random as a function of the random variables 
    $\epsilon_1,\ldots,\epsilon_m$). Then
    \begin{align}
    \label{eq:softmax_bd2}
    \frac{1}{\lambda} \log \left\{ 2^d \cdot \E \exp \lambda Z \right\} 
    &= \frac{d\log(2)}{\lambda} +  \frac{1}{\lambda} \log \left\{ \E 
    \exp 
    \lambda (Z-\E Z) \right\} + \E Z.
    \end{align}
    By Jensen's inequality, $\E[Z]$ can be upper bounded by using the Rademacher complexity random variables
    \[
    V\sqrt{\E_{\boldsymbol{\epsilon}}\left[\left\|\sum_{i=1}^{m}\epsilon_i\mathbf{X}_{i}\right\|^2\right]}
    ~=~
    V\sqrt{\E_{\boldsymbol{\epsilon}}\left[\sum_{i,i'=1}^{m}\epsilon_i\epsilon_{i'}\mathbf{X}_{i}^\top\bx_{i'}\right]}
    ~=~
    2Vp\sqrt{\sum_{i=1}^{m}\norm{\mathbf{X}_{i}}^2},
    \]
    where $p=\frac{m_k u_k}{(m_k+u_k)^2}$. To handle the $ \log \left\{ \E 
    \exp 
    \lambda (Z-\E Z) \right\}$ term in \eqref{eq:softmax_bd2}, note that 
    $Z$ is 
    a deterministic function of the i.i.d. random variables 
    $\epsilon_1,\ldots,\epsilon_m$, and satisfies
    \begin{align*}
    Z(\epsilon_1,\ldots,\epsilon_i, \ldots,\epsilon_m) - 
    Z(\epsilon_1,\ldots,-\epsilon_i, \ldots,\epsilon_m) \leq 2V \|\mathbf{X}_{i}\|~.
    \end{align*}
    This means that $Z$ satisfies a bounded-difference condition, which by 
    the 
    proof of Theorem 6.2 in \citep{boucheron2013concentration}, implies 
    that 
    $Z$ is sub-Gaussian, with variance factor
    $$v = \frac{1}{4} \sum_{i=1}^{m_k+u_k} (2V\|\mathbf{X}_{i}\|)^2 = 4 p^2 V^2\sum_{i=1}^{m_k+u_k} 
    \|\mathbf{X}_{i}\|^2,$$
    and satisfies
    $$ \frac{1}{\lambda} \log \left\{ \E \exp \lambda (Z-\E Z) \right\} 
    \leq 
    \frac{1}{\lambda} \frac{\lambda^2 4 V^2 p^2 \sum_{i=1}^{m_k+u_k} \|\mathbf{X}_{i}\|^2}{2} =  
    \frac{\lambda 4 V^2 p^2  \sum_{i=1}^{m_k+u_k} \|\mathbf{X}_{i}\|^2}{2}.$$
    Choosing $\lambda = \frac{\sqrt{2\log(2)d}}{2pV \sqrt{\sum_{i=1}^{m_k+u_k} \| 
    \mathbf{X}_{i} 
            \|^2}}$ 
    and using the above, we get that \eqref{eq:softmax_bd} can be upper 
    bounded 
    as follows:
    \begin{align*}
    \frac{1}{\lambda} \log \left\{ 2^d \cdot \E \exp \lambda Z \right\} 
    &\leq \E Z + \sqrt{2\log(2)d} \cdot 2p V\sqrt{\sum_{i=1}^{m_k+u_k} \|\mathbf{X}_{i}\|^2} 
    \\&\leq 2pV 
    \left(\sqrt{2\log(2)d}+1\right)\sqrt{\sum_{i=1}^{m_k+u_k} \|\mathbf{X}_{i}\|^2}\\
     &\leq2pV 
    \left(\sqrt{2\log(2)d}+1\right)B_f\sqrt{m_k+u_k }\\
    &= 2pV 
    \left(\sqrt{2\log(2)d}+1\right)B_f\sqrt{m_k+u_k }
    ~,
    \end{align*}
    from which the result follows.
\end{proof}
\begin{reptheorem}{thm: main result}[\textbf{Restated}]
     Under the same Assumptions in Proposition~\ref{prop: general bound} and Proposition~\ref{prop: TR RC bound}, the following upper bound holds on population risk for imbalance transductive node classification under a GCN model,
     \begin{equation*}
    \begin{split}
         R(\mbZ_u,h_\theta)&\leq \sum_{i=1}^2 R_{\gamma}(\mbZ_{m_i},h_{\theta})+\frac{u_i}{u}\Big(\frac{B_f (\sqrt{2\log(2) d}+1)\Pi_{j=1}^{d} U_F(j) }{\gamma\sqrt{(m_i+u_i)}}\times \Bigg(\frac{\degmax_i+1}{\deg^{\min}+1}\Bigg)^{d-1}
        \\&\qquad +c_0 Q_i\sqrt{\min(m_i,u_i)}+\sqrt{\frac{S_iQ_i}{2}\log(1/\delta)}\Big),
    \end{split}
    \end{equation*}
where $U_F(i)$ is the maximum of Frobenius norm of $i$-th layer parameter. 
\end{reptheorem}
\begin{proof}
    The proof follows directly from combining Proposition~\ref{prop: general bound} with Proposition~\ref{prop: TR RC bound} and substituting $\|\mathrm{G}_f(\mbA)\|_{\infty}$ for the GCN model using Lemma~\ref{lem: bound on inf norm of L}.
\end{proof}
\clearpage
% \todo{pls update this pseudo-algorithm.}\todot{Done}
\section{UPL Algorithm Details}\label{app: UPL alg detail}
\begin{algorithm}[H]
\caption{Uncertainty-aware Pseudo-labeling  (UPL) Algorithm }
\label{alg1}
 % \scriptsize
\begin{scriptsize} % Choose the size here
\begin{algorithmic}[1] % The [1] ensures that lines are numbered
\STATE \textbf{Input:} Graph $G(X,V,E,Y)$, set of known train labels $\mathcal{Y}_{t}$, Number of classes $C$, set of edges $\mathcal{E}$, Number of Iterations $k$
\STATE \textbf{Output:} Model parameters
\STATE Initialize empty pseudo labels set $\mathcal{Y}_{p}$
% \STATE Initialize train set $D_{train}$ with known labels
\FOR{ $1$ to $k$}
    \STATE Initialize new model
    \STATE Train  $model$ on $\mathcal{Y}_{t}\cup \mathcal{Y}_{p}$ utilizing BS
    \STATE Initialize results set $R$ with known labels
    \FOR{$i \leftarrow 1 $ to $ t$}
        \STATE $G_{\mathrm{Aug}} \leftarrow $ Selective Edge Removal on $G$ for $S_k$ times
        \STATE  $R_i \leftarrow $ \{Inference Model on $G_{\mathrm{Aug}}$\} \% Add output to $R$
    \ENDFOR
    % \FOR{$v$ in $G_{\mathrm{Aug}}(V)$}
    %     \FOR{$c \leftarrow$ 1 to $C$}
    %         \STATE $\mathrm{mean}=\frac{\sum R_{k,v,c}}{t}$
    %         \STATE $M_{v,c} =\sqrt{\sum\frac{(R_{k,v,c}-\mathrm{mean})^2}{t}}$
    %     \ENDFOR
    % \ENDFOR
    % \STATE $M_{uncertinty} \leftarrow STD\{R\}$ \% Standard Deviation of R
    \STATE $P \leftarrow $ \{Inference Model on $G$\} \% probs is the class-wise probability
    \STATE Initialize the set $\mathcal{Y}^{\mathrm{new}}$ for new pseudo labels
    \FOR{$v$ in $G(V)$}
        \IF{$v$ not in $\mathcal{Y}_{t}$}    
            \IF{$\eta_l<\max(P_k^v)<\eta_u$}
                \IF{$U(v)<Q_\alpha$}
                    \STATE Add $v$ and $\mathrm{argmax}(P_k^v)$ to $\mathcal{Y}^{\mathrm{new}}$ as node and pseudo label
                \ENDIF
            \ENDIF
        \ENDIF
        % \STATE $M^{probs}_v \leftarrow max(P_k^v)$
        % \STATE $M^{preds}_v \leftarrow argmax(P_k^v)$
        % \STATE $M^{uncertainty}_v \leftarrow M_{v,M^{preds}_v}$
    \ENDFOR
    % \STATE $preds \leftarrow argmax\{probs\}$ \% Class wise argmax for each node
    % \STATE $V_{uncertinty} \leftarrow M_{uncertinty}[preds]$
    % \STATE Apply pseudo-labeling threshold on $probs[preds]$ and make $mask_1$
    % \STATE Apply uncertainty threshold on $M_{uncertinty}[preds]$ and make $mask_2$
    % \STATE $mask_{pseduo} \leftarrow$ Intersection of $mask_1$ and $mask_2$
    \STATE $\mathcal{Y}^{p}  \leftarrow \mathcal{Y}^{\mathrm{new}}$    
\ENDFOR
\STATE \textbf{return}  $best\_model$ parameters
\end{algorithmic}
\end{scriptsize}
\end{algorithm}

\section{Experiment Details}\label{app: Exp details}

% \subsection{Experiment Details}

\textbf{Datasets:} We summarized the dataset statistics in Table \ref{tab:datasets}.  Note that in the Amazon Computers and Amazon Photos datasets \cite{shchur2019pitfallsgraphneuralnetwork}, nodes represent products and edges denote co-purchasing relationships between them.
 
\begin{table}[htp]
\centering
\caption{\label{tab:datasets}Dataset statistics.}
\begin{tabular}{l c r r r r}
\toprule
\textbf{Dataset} & \textbf{Nodes} & \textbf{Edges} & \textbf{Classes} & \textbf{Features}   \\
\midrule
CiteSeer &  3,327 & 4,732 & $6$ & 3,703  \\
Cora &  2,708 & 5,429 & $7$ & 1,433  \\
Pubmed &  19,717 & 44,338 & $3$ & 500  \\
Chameleon &  2277 & 36101 & 5 & 2325\\
Squirrel &  5201 & 217073 & 5 & 2089\\ 
Wisconsin & 251 & 515 & 5 &1703\\
Computers & 13,381 & 245,778 & 10 & 767\\
Photo & 7,650 & 119,081 & 8 & 745\\
\bottomrule
\end{tabular}
\end{table}

\textbf{Hyperparameters:} To attain the best results we have fine-tuned three hyperparameters for our model. These hyperparameters and their tune range along with hyperparameters from some of the previous have been displayed in Table \ref{tb:hyperparameters}.
% \todoa{Add the table of hyper-parameter for all methods.} \todot{Done}
\input{figures/hyperparameters_table}
\section{Experiments Setup}\label{app:Exp_set}
% \subsection{Hyperparameters:}
UPL contains two tunable hyperparameters used for the pseudo labels threshold and three fixed ones which have approximated using a few experiments. Other extra hyperparameters have been adjusted according to \citep{song2022tam}. We will discuss the setting for these parameters in the following sections.
\subsection{UPL}\label{app:UPL}
We employ two thresholds for pseudo-labeling. As mentioned in Table \ref{tb:hyperparameters}, $\eta_l$ and $\eta_u$ are chosen respectively from $\{0.25 + 0.05n \mid 0\leq n \leq 8, n\in \mathbb{N}\}$ and $\eta_u \in \{min(\eta_l + 0.25n,1) \mid n\leq3, n \in \mathbb{N}\}$. Both $S_k$ and $t$ are fixed to 100, and the quantile for uncertainty-based node selection is chosen from $\{Q_{0.7},Q_{0.8},Q_{0.9}\}$.
% To reduce the complexity of the algorithm, instead of using a constant value for $\kappa$, we have utilized the following formula,
% \begin{equation}\begin{split}
%     \label{eq:uncertain_thr}
%  \kappa_c = \mathrm{mean}(M)-\mathrm{mean}\big(\{M_{v,\mathrm{argmax}(P_k^v)}| \mathrm{argmax}(P_k^v)=c \}\big),
% \end{split}\end{equation}
% where $M$ is the matrix of uncertainty values, and $P_k^v$ is the output of inference on the model in the pseudo-labeling pipeline for $v$-th node. Using this equation prevents the uncertainty module from removing all pseudo labels as the variation of $\mathrm{mean}(M)$ with the overall trend of the sampled will always allow some nodes to pass the threshold. Furthermore, the second term in equation \ref{eq:uncertain_thr} is added to prioritize over more confident samples. This way, the classes with a lower overall uncertainty mean are more likely to pass this threshold.


% \subsection{RKC}\label{app:RKC}
% The RKC regularizer, requires two hyperparameters. To reduce the complexity of the model, we only consider $\lambda_{RKC} \in \{0,1\}$ as we have found these two values to be a good balance between all datasets. $\lambda$ is found through sweeping in the range of 0.001 and 1 using the Bayesian optimized sweep algorithm~\cite{snoek2012practical}.
% To further simplify the training process we have set the $\lambda_{\mathrm{RKC}}$ in the RKC to 0 as we have found this value to be a good balance between all datasets. We also use a dynamic method for acquiring the uncertainty threshold, to have the 
% We utilize two hyper-parameters $\lambda$ and $\lambda_{\mathrm{RKC}}$ for our regularization method when added to a baseline,
% \begin{equation}\begin{split}
% \lambda \big( \lambda_{\mathrm{RKC}}\mathrm{H}( P(\hat{\mathbf{Y}} |\mathbf{X}) ,\mathbf{P}_k) +\KLr( P(\hat{\mathbf{Y}} |\mathbf{X}) \|\mathbf{P}_k)\big)\\
% \end{split}\end{equation}
% where $\mathrm{RKC}$ as the regularization loss is added directly to the baseline, e.g., BalancedSoftmax (+TAM) or GraphENS(+TAM). We have used Optuna to find the best hyperparameter for each model and dataset. We chose $\lambda$ in the range of $(0,1)$ and $\lambda_{\mathrm{RKC}}$ from the range of $(-1,1)$.
% We have used Optuna under multiple settings and have found
% that the default searching setting works best in terms of the trade-off between optimal results and time complexity. We have used the Tree-structured Parzen Estimator, which is used by Optuna by default, and for the target function of Optuna, we have aimed to maximize the average of validation F1 score and accuracy.
\subsection{BalancedSoftmax}\label{app:BalancedSoftmax}
Another part of UPL is BalancedSoftmax (BS) presented in \citep{ren2020balanced}. We have used the same values found in \citep{song2022tam} to prevent increasing the number of hyperparameters in the UPL algorithm.
\subsection{Other Details}\label{app:Other_details}
More minor details concerning the experiments have been explained in the following sections.

\textbf{Imbalance Ratio:} The distribution of training sets for each dataset can be seen in Table \ref{tb:datastat}. All datasets follow a 10:1 imbalance ratio, except for Wisconsin, which has an imbalance ratio ($\rho$) of 11.63. By analyzing Table \ref{tb:datastat}, it is evident from the results in Tables \ref{tb:apendix_homo} and \ref{tb:apendix_hetero} that our model generally performs significantly better when the node with the maximum degree is present in one of the majority classes.

% \todoa{It would be great to add a discussion in which dataset we have better performance and how maximum degree is distrbuted among majority and minority?}\todot{Done}
% \textbf{Target class distribution:} 
% For each dataset, 
% % the computation of $P_{k}$ for the regularization term involves two steps. Firstly,
% we calculate the ratio of each class within all six datasets, as detailed in Table~\ref{tb:datastat}.
\begin{table}[h] %{r}{4.3cm}
\center
\caption{\small Number of training nodes per class}
\begin{small}
\setlength{\tabcolsep}{3pt} 
\begin{tabular}{l|cccccccccc}
\toprule
    \textbf{Dataset} ($\rho=10$) & $\mathbf{C}_0$ & $\mathbf{C}_1$ & $\mathbf{C}_2$ & $\mathbf{C}_3$ & $\mathbf{C}_4$ & $\mathbf{C}_5$ & $\mathbf{C}_6$ & $\mathbf{C}_7$ & $\mathbf{C}_8$ & $\mathbf{C}_9$ \\
    \hline
    Cora  & 20 & 20 & 20 & 20 & 2 & 2 & 2 & - & - & - \\    
    CiteSeer & 20 & 20 & 20 & 2 & 2 & 2 & - & - & - & - \\
    PubMed & 20 & 20 & 2 &- &- &- &- & - & - & - \\
    Chameleon & 225 & 220 & 218 & 22 & 22 & - & - & - & - & - \\
    Squirrel & 487 & 494 & 501 & 50 & 50 & - & - & - & - & - \\ 
    Wisconsin ($\rho=11.63$) & 4 & 38 & 50 & 5 & 5 & - & - & - & - & - \\ 
    Computers & 20 & 20 & 20 & 20 & 20 & 2 & 2 & 2 & 2 & 2 \\ 
    Photo & 20 & 20 & 20 & 20 & 2 & 2 & 2 & 2 & - & - \\ 
\bottomrule
\end{tabular}
\end{small}
\label{tb:datastat}
\end{table}

\input{Results/nips/max_degree_dist}
% \todot{Clean the table}
% Subsequently, we derive a normalized inverse ratio for each specific dataset for each class. The inversion is intended to emphasize the significance of the minority class, and normalization is applied to the output to transform it into a probability distribution.

\paragraph{Hardware and setup:} All of our Experiments were conducted on a single server containing an Nvidia RTX 3090 GPU, AMD Ryzen 5 3600x CPU @ 3.80GHz, and 48GB of RAM. 

% \paragraph{Code:} Anonymized code is provided at \url{.....}. 

\paragraph{Training:} To choose the training mask, we use the training masks provided by Pytorch Geometric. We train each model for 1000 epochs with an early stopping patience of 100. For each dataset $\eta_l$ is chosen from $(0.25,0.90)$ and the value of $\eta_u$ is chosen from $(\eta_u,1.00)$.
% Based on observations on the Cora dataset, we have chosen a value for each hyperparameter and applied the same setting for all datasets. The hyperparameter values are as follows: $\lambda=0.1$, which is the regularization coefficient, $\eta_l=0.3$, and $\eta_u=0.6$, which are the lower and upper thresholds, respectively.
We also perform each experiment with 10 iterations of pseudo-labeling.

\paragraph{Optimizer:} 
% Considering the regularization terms,
we use PyTorch Adaptive Moment Estimation (ADAM) as the optimizer. Also, $\ell_2$ regularization with weight decay of $5e^{-4}$ for the first layer and dropout in some layers are used to prevent over-fitting. We use a learning rate of 0.01.

\section{More Experiments}\label{App: more exp}

In this section, we present the performance outcomes for three prominent GNN architectures: Graph Convolutional Network (GCN), Graph Attention Network (GAT), and Graph SAGE (SAGE). These models were evaluated across six diverse datasets with three different imbalance ratios to assess their effectiveness in various scenarios. The results for the imbalance ratio of 10 are detailed in Table \ref{tb:apendix_homo} and Table \ref{tb:apendix_hetero}.

Tables \ref{tb:Homo_ir_5} and \ref{tb:Hetero_ir_5} present the performance evaluation of UPL with an imbalance ratio of 5, while Tables \ref{tb:Homo_ir_2} and \ref{tb:Hetero_ir_2} show the corresponding results for a lower imbalance ratio of $\rho=2$.
\input{Results/nips/apendix_homo}
\input{Results/nips/apendix_hetero}
\input{Results/nips/All_Homo_ir_5}
\input{Results/nips/All_Hetero_ir_5}
\input{Results/nips/All_Homo_ir_2}
\input{Results/nips/All_Hetero_ir_2}
\clearpage

\subsection{Additional Datasets}
To further test UPL, we have included additional experiments with Amazon datasets \citep{shchur2018pitfalls}, comparing them to other previous works in Table~\ref{tb:Amazon}, and ablation studies in Table \ref{tb:Amazon_ablation}.

\input{Results/nips/Amazon_ir_10}
\input{Results/nips/Amazon_ablation}
% \subsubsection{Integration}

\subsection{Discussion}

Both Table \ref{tb:apendix_homo} and Table \ref{tb:apendix_hetero} demonstrate a clear superiority of our method across various architectures and datasets. A particularly notable aspect of our experiments is the significant margin by which our results surpass the second-best outcomes. This pronounced difference underscores the effectiveness of our approach, setting a new benchmark for performance in this field.

Our experimental analysis investigated the impact of varying the number of edge removal iterations ($t$) and the number of edges removed in each iteration ($S_k$) on model performance. The results, provided in Figure \ref{fig:augmentation_sweep}, demonstrate that choosing both $t=100$ and $S_k=100$ yields the best results in both studied datasets. Notably, the computation of uncertainty values does not require any training steps, which significantly reduces the computational overhead. Given that typical model training procedures require over 1000 epochs, the time needed to calculate uncertainty values is negligible in comparison to the overall training process.
% \todoa{Do we have experiment for this part?}\todot{Done}
\begin{figure}[ h!]
    \centering
    \includegraphics[width=0.6\columnwidth]{figures/nips/aug_vs_edge.pdf}
    \caption{Selection Edge Removal: F1 score versus number of iterations and number of edges for removal. Each plot is normalized to it's lowest value.}
    \label{fig:augmentation_sweep}
\end{figure}
% \todoa{Add some discussion of tables here.}\todot{Done}
\input{Results/ICML/performance_comparison}

For a summary of the performance of UPL, We have provided Table \ref{tb:performance_comparison}, Comparing our model with previous methods in term of F1 score ranking based on topological nature of the dataset and the employed backbone. Performance ranking is measured in terms of \textcolor{red}{Best}\textbar Second, It is worth noting that this ranking is adequate as UPL hasn't performed lower than second compared to previous methods in any of the experiments
\section{Detailed Comparison with UNREAL}\label{app:comp_unreal}

To assess practical efficiency, we conducted time measurements for both UNREAL and UPL under identical experimental conditions. Our findings demonstrate that UPL’s streamlined approach, which employs fewer and less complex iterative processes, substantially reduces both time and computational resource requirements, resulting in superior empirical efficiency. This advantage is clearly illustrated in our experiments with the PubMed dataset: UPL completed 10 runs in an average runtime of 0.66 minutes, while UNREAL required an average runtime of 14.1 minutes for the same number of runs. These timing tests were performed on a server equipped with an Nvidia RTX 3090 GPU and AMD Ryzen 5 3600x CPU @ 3.80GHz, ensuring consistent and comparable results. While UPL uses less time to run, it also delivers better performance, as shown in Tables \ref{tb:main_chart_homo}, \ref{tb:main_chart_hetero}, \ref{tb:apendix_homo}, and \ref{tb:apendix_hetero}. Our extensive evaluation across 24 different experimental setups reveals that UPL consistently outperforms UNREAL. In 17 out of these 24 setups, UPL achieved better results in both balanced accuracy and F1 score, while in the remaining cases, it secured second place, highlighting its robustness and consistent performance across a variety of conditions.
% \todot{Add other timings}

% To assess practical efficiency, we conducted time measurements for both UNREAL and UPL under identical experimental conditions. Our findings demonstrate that UPL's streamlined approach, which employs fewer and less complex iterative processes, substantially reduces both time and computational resource requirements, resulting in superior empirical efficiency. This advantage is clearly illustrated in our experiments with the PubMed dataset: UPL completed 10 runs in an average runtime of 1.2 minutes, while UNREAL required an average runtime of 1.9 minutes for the same number of runs. These timing tests were performed on a server equipped with an Nvidia RTX 4090 GPU and an Intel 12900k CPU, ensuring consistent and comparable results. The significant time savings observed with UPL show its potential for enhancing productivity in real-world applications, particularly when dealing with large-scale datasets or time-sensitive analyses.

% \todoa{Add discussion about our performance.}
% \section{Integration with other methods}\label{app-sec: experiments}
% In this section, we present experiments that combine our method's components with other approaches. Table \ref{tb:integration_homo} and Table~\ref{tb:integration_hetro} show the results of integrating our RKC regularization with various methods in homophilic and heterophilic datasets, respectively. Inspired by the baselines in \citep{song2022tam}, we tested our RKC regularization loss and compared it with other baselines under the GCN model \citep{kipfsemi}, as shown in Table \ref{tb:integration_homo}. Our RKC regularization improves the performance (accuracy and F1 scores) of several imbalance algorithm baselines, such as BalancedSoftmax and GraphENS, when integrated with them. Additionally, it significantly reduces variance across most experiments, indicating enhanced stability.
% \input{Results/nips/Integration_homo}
% \input{Results/nips/Integration_hetero}




\end{document}

% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was created
% by Iain Murray in 2018, and modified by Alexandre Bouchard in
% 2019 and 2021 and by Csaba Szepesvari, Gang Niu and Sivan Sabato in 2022.
% Modified again in 2023 and 2024 by Sivan Sabato and Jonathan Scarlett.
% Previous contributors include Dan Roy, Lise Getoor and Tobias
% Scheffer, which was slightly modified from the 2010 version by
% Thorsten Joachims & Johannes Fuernkranz, slightly modified from the
% 2009 version by Kiri Wagstaff and Sam Roweis's 2008 version, which is
% slightly modified from Prasad Tadepalli's 2007 version which is a
% lightly changed version of the previous year's version by Andrew
% Moore, which was in turn edited from those of Kristian Kersting and
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.
