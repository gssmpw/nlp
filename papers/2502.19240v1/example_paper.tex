%%%%%%%% ICML 2025 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{diagbox} % 导入 diagbox 宏包
\usepackage{slashbox}
\usepackage{multirow}  % 用于表格中的跨行合并
\usepackage{makecell}  % 用于表格内的多行文本格式
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfig}
\usepackage{bm}
% \usepackage{subfigure}
\usepackage{booktabs} % for professional tables
\usepackage{algorithm, algorithmic}
\newcommand{\fs}[1]{\scriptsize $\pm$#1}
% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2025} with \usepackage[nohyperref]{icml2025} above.
\usepackage{hyperref}


% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
%\usepackage{icml2025}

% If accepted, instead use the following line for the camera-ready submission:
\usepackage[accepted]{icml2025}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage[T1]{fontenc}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}
\crefname{assumption}{Assumption}{Assumptions}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{example}[theorem]{Example}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}


% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Enhancing Gradient-based Discrete Sampling via Parallel Tempering}

\begin{document}

\twocolumn[
\icmltitle{Enhancing Gradient-based Discrete Sampling via Parallel Tempering}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2025
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Luxu LIANG}{ruc_math}
\icmlauthor{Yuhang JIA}{thu}
\icmlauthor{Feng ZHOU}{ruc_stats}

\end{icmlauthorlist}

\icmlaffiliation{ruc_math}{School of Mathematics, Renmin University of China}
\icmlaffiliation{thu}{Department of Mathematical Sciences, Tsinghua University}
\icmlaffiliation{ruc_stats}{Center for Applied Statistics and School of Statistics, Renmin University of China}

\icmlcorrespondingauthor{Luxu Liang}{lianglux@ruc.edu.cn}
\icmlcorrespondingauthor{Feng Zhou}{feng.zhou@ruc.edu.cn}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
%\icmlkeywords{Machine Learning, ICML}

\vskip 0.3in
]
\makeatletter\def\Hy@Warning#1{}\makeatother 
\printAffiliationsAndNotice{} 
% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

%\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
% \printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.

\begin{abstract}

While gradient-based discrete samplers are effective in sampling from complex distributions, they are susceptible to getting trapped in local minima, particularly in high-dimensional, multimodal discrete distributions, owing to the discontinuities inherent in these landscapes. To circumvent this issue, we combine parallel tempering, also known as replica exchange, with the discrete Langevin proposal and develop the Parallel Tempering enhanced Discrete Langevin Proposal~(PTDLP), which are simulated at a series of temperatures. Significant energy differences prompt sample swaps, which are governed by a Metropolis criterion specifically designed for discrete sampling to ensure detailed balance is maintained. Additionally, we introduce an automatic scheme to determine the optimal temperature schedule and the number of chains, ensuring adaptability across diverse tasks with minimal tuning. Theoretically, we establish that our algorithm converges non-asymptotically to the target energy and exhibits faster mixing compared to a single chain. Empirical results further emphasize the superiority of our method in sampling from complex, multimodal discrete distributions, including synthetic problems, restricted Boltzmann machines, and deep energy-based models.
\end{abstract}

\section{Introduction}\label{introduction}
Discrete structures are common in the real world, including statistics~\citep{robert1999monte, doucet2000sequential, ait2003effects, neal2000markov, ishwaran2001gibbs}, physics~\citep{baumgartner2012monte, zarfaty2022discrete, negri2015efficient}, bioinformatics~\citep{bollback2006simmap, yu2013shrinkage, wang2010gibbs}, and computer science~\citep{wang2019bert, peters2018probabilistic, meng2022concrete, dawid2024introduction}, which highlights the need for discrete samplers. Since sampling from a target probability distribution $\pi(\theta) \propto \exp (U(\theta))$ defined on a discrete space $\Theta$ is typically intractable, one usually resorts to Markov chain Monte Carlo (MCMC) methods. 
Recent studies~\citep{zanella2020informed, grathwohl2021oops, zhang2022langevin, sun2021path, sun2022optimal, sun2023any, xiang2023efficient, pynadath2024gradient} leverage gradient information within discrete distributions to refine proposal distributions, achieving notable advancements in sampling efficiency.

A key limitation of gradient-based methods is their susceptibility to being trapped in local modes due to the reliance on local gradient information~\citep{ziyin2021sgd, pynadath2024gradient}, particularly when dealing with well-separated modes, which hinders both accuracy and efficiency in sampling. In continuous domains, various techniques, such as parallel tempering~(PT)~\citep{swendsen1986replica, chen2020accelerating}, cyclical step sizes~\citep{zhang2019cyclical}, and flat histograms~\citep{berg1991multicanonical, deng2020contour}, have been proposed to mitigate this issue. Among these methods, PT is widely used for its ease of implementation and parallelization. By simulating Langevin chains at varying temperatures and incorporating a swap mechanism, PT accelerates convergence while balancing exploration and exploitation. However, in discrete domains, where distributions are inherently more multimodal due to their discontinuous nature, the problem is further exacerbated. Despite the pressing need, limited research has focused on developing gradient-based discrete samplers that can effectively explore multimodal distributions. %raising a critical question: \textit{How can the trade-off between global exploration and local exploitation be effectively balanced in discrete sampling?}


In this paper, we introduce the Parallel Tempering enhanced Discrete Langevin Proposal (PTDLP) algorithm, which leverages PT to improve the efficiency and accuracy of gradient-based samplers when sampling from discrete, multimodal distributions. Intuitively, the high-temperature chains act as bridges, facilitating the connection between the various modes. To ensure detailed balance, we employ a tailored Metropolis step to determine swaps. Additionally, with the introduction of multiple chains, we design an automatic scheme to obtain the optimal temperature settings and number of chains for different scenarios. Specifically, we make several contributions: 
% \begin{itemize}

1) We improve the discrete Langevin proposal~\citep{zhang2022langevin} for multimodal distributions via PT, optimizing temperature schedules and chain numbers. This method allows easy, customizable adjustments for different datasets with minimal manual input, balancing exploration and exploitation in discrete distributions.

2) We provide a non-asymptotic convergence analysis for our method in general discrete distributions, theoretically demonstrating the acceleration effect of multiple chains and explaining the necessity of the Metropolis-Hastings step.

3) We demonstrate the superiority of our method for both sampling and learning tasks, including synthetic mixture models, restricted Boltzmann machines, and deep energy-based models.
    % The codes are available at \textbf{Github}
% \end{itemize}

\section{Related Works}\label{sec:2}
\subsection{Gradient-based Discrete Sampling}\label{sec:2.1}
Gradient-based discrete sampling has gained popularity for tackling complex discrete sampling tasks, with its origins rooted in Local Balance Proposals~(LBP)~\citep{zanella2020informed}, which leverage local density ratios to enhance sampling efficiency. \citet{grathwohl2021oops} expanded LBP by incorporating first-order Taylor approximations, ensuring computational feasibility and improving performance. To facilitate sampling in high-dimensional discrete spaces, LBP were further extended to explore larger neighborhoods through a sequence of small moves~\citep{sun2021path}. \citet{zhang2022langevin} proposed Discrete Langevin Proposal~(DLP) by adapting continuous Langevin MCMC methods to discrete spaces, allowing parallel updates of all coordinates based on gradient information. Additionally, DLP was refined with an adaptive mechanism to automatically adjust step sizes for better efficiency~\citep{sun2023any}. While these approaches have shown promise, challenges persist in sampling from discrete, multimodal distributions.

\subsection{Sampling on Multimodal Distributions}\label{sec:2.2}
Various algorithms have been proposed to enhance exploration in complex, multimodal distributions, including importance sampling~\citep{wang2001efficient}, simulated annealing~\citep{kirkpatrick1983optimization}, simulated tempering~\citep{marinari1992simulated}, cyclic step-size scheduling~\citep{zhang2019cyclical}, dynamic weighting~\citep{wong1997dynamic}, and replica exchange Monte Carlo~\citep{swendsen1986replica, earl2005parallel}. Among these advancements, simulated annealing stochastic gradient Markov chain Monte Carlo~(SGMCMC)~\citep{mangoubi2018convex} and simulated tempering SGMCMC~\citep{ge2018simulated} show how dynamical temperatures speed up the convergence. However, simulated annealing is very sensitive to the fast-decaying temperatures, and simulated tempering requires a lot on the approximation of the normalizing constant. The replica exchange Markov chain Monte Carlo~(reMCMC) leverages multiple chains operating at different temperatures and allows exchanges between chains, which is easier to implement and suitable for parallelism. \citet{chen2020accelerating} analyzed the acceleration effect of replica exchange in $\chi^2$ divergence and large deviation principle. \citet{dong2022spectral} analyzed the mixing properties of reMCMC by evaluating its spectral gap, while \citet{deng2020non, deng2020accelerating} demonstrated its efficiency in large-scale deep learning applications. 

Despite the more pronounced multimodal nature of discrete domains due to their inherent discontinuities, research on sampling from multimodal distributions in discrete domains remains limited. \citet{pynadath2024gradient} proposed a cyclic scheduling strategy that alternates step sizes, enhancing the handling of multimodal distributions. \citet{zhengexploring} attempted to integrate replica exchange with gradient-based sampling; however, their approach lacks a rigorous theoretical foundation, and the two replicas encounter a specific issue, as discussed in \cref{sec_4_1}.

\section{Preliminaries}
In this section, we provide a formal definition of the problem and present an overview of the relevant methods.

\subsection{Problem Definition}
We are concerned with the task of sampling from some target distribution defined over a discrete space $\pi: \Theta \to [0, 1]$, which is given by
\begin{equation}\label{pi}
\pi(\theta) = \frac{1}{Z} \exp\left(\beta U(\theta)\right), \quad \forall \theta \in \Theta, \quad \Theta \subseteq \mathbb{R}^d,
\end{equation}
where $\theta$ is a $d$-dimensional variable, $\beta=1$ denotes the inverse temperature parameter, $\Theta$ is a finite domain, $U$ represents the energy function, and $Z$ is the normalizing constant. 
We adopt the following assumptions regarding the domain and the energy function, as commonly found in the literature on gradient-based discrete sampling~\citep{grathwohl2021oops, zhang2022langevin}. Specifically, the sampling domain is factorized coordinate-wise, so that $\Theta = \prod_{i=1}^d \Theta_i$, where we primarily consider binary cases $\Theta = \{0, 1\}^d$ or categorical $\{0, 1, \dots, N\}^d$. 
The energy function is differentiable\footnote{Noted that this assumption can be relaxed via Newton’s Series Approximation~\citep{xiang2023efficient}.} across $\mathbb{R}^d$.

\subsection{Replica Exchange Langevin Dynamics}
The replica exchange Langevin Dynamics~(reLD) is a widely used sampling method for non-convex exploration in continuous spaces. The method updates according to the following dynamics, for $k = 1, \dots, K$ and $i = 1, 2, \dots, I$,
\[
\theta^{(k)}_{i+1} = \theta^{(k)}_i + \frac{\alpha_k}{2} \nabla U(\theta^{(k)}_i) + \sqrt{\frac{\alpha_k}{\beta_k}} \xi_k,
\]
where $\{\alpha_k\}_{k=1}^{K}$ represents the step sizes, $\{\beta_k\}_{k=1}^{K}$ are the inverse temperature parameters, and $\{\xi_k\}_{k=1}^{K}$ are independent Gaussian noises drawn from $\mathcal{N}(0, I_{d \times d})$. In the typical set-up, the first chain is designated as the low-temperature chain. The gradient $\nabla U(\cdot)$ guides the algorithm toward high-probability regions.


To further improve the mixing rate over Langevin dynamics, reLD enables interaction through a chain-swap mechanism between neighboring replicas. Specifically, the probability to swap the $i$-th samples between $\theta_i^{(k)}$ and $\theta_i^{(k+1)}$ is determined by $\rho s_k\left(\theta_i^{(k)}, \theta_i^{(k+1)}\right)$ with $\rho>0$ being the swapping intensity. The swap function $s_k : \Theta \times \Theta \to \mathbb{R}^+$ for $k=1, \cdots, K-1$ is given by
$$
\!s_k\!\left(\theta_i^{(k)}, \theta_i^{(k+1)}\!\right)\!=\! \min\!\left\{1,  e^{\left(\beta_{k}- \beta_{k+1}\right)\! \left[U(\theta_i^{(k)}) - U(\theta_i^{(k+1)})\right]}\!\right\}.
$$
Intuitively, the probability of swap in reLD depends on the energy values in $\theta_i^{(k)}$ and $\theta_i^{(k+1)}$. When the low-temperature chain is trapped in a local minimum and the high-temperature chain explores modes with much lower energy, swapping allows the former to escape and characterize new modes, while the latter continues broader exploration. %As highlighted by \citet{chen2020accelerating}, reLD operates as a reversible Markov jump process due to its swap mechanism. This property ensures convergence to the target distribution in \cref{pi}, allowing the algorithm to effectively explore the entire space.

\vspace{-1mm}
\subsection{Discrete Langevin Sampler}
The Discrete Langevin Proposal~(DLP) is a gradient-based approach for sampling from high-dimensional discrete distributions~\citep{zhang2022langevin}. Inspired by Langevin Dynamics, DLP updates all coordinates in parallel using a single gradient computation to function effectively in discrete settings. Specifically, for a target distribution $\pi(\theta) \propto \exp\left(U(\theta)\right)$, DLP generates a new sample $\theta^{\prime}$ inspired by the Taylor expansion:
$$
q(\theta^{\prime} | \theta) = \frac{\exp\left(-\frac{1}{2\alpha} \left\| \theta^{\prime} - \theta - \frac{\alpha}{2} \nabla U(\theta) \right\|_2^2 \right)}{Z_\Theta(\theta)}, 
$$
where $\theta, \ \theta^{\prime}\in \Theta$, $\nabla U(\theta)$ is the gradient of the energy function evaluated at $\theta$, and $Z_\Theta(\theta)$ normalizes the distribution: $Z_\Theta(\theta) = \sum_{\theta^{\prime} \in \Theta} \exp\left(-\frac{1}{2\alpha} \left\| \theta^{\prime} - \theta - \frac{\alpha}{2} \nabla U(\theta) \right\|_2^2 \right)$. A key insight is that, for $i=1, \cdots, d$, the update rule can be factorized by coordinate:
\begin{equation}\label{factorize}
\text{Cat} \left[ \text{Softmax} \left( 
\frac{1}{2} \nabla U(\theta)_i (\theta_{i}^{\prime} - \theta_{i}) 
- \frac{1}{2\alpha}(\theta_{i}^{\prime} - \theta_{i})^2 
\right)\right], 
\end{equation}
with $\theta_i^{\prime} \in \Theta_i$, which makes DLP scalable and computationally efficient for complex distributions. DLP can be implemented with or without the Metropolis-Hastings~(MH) step, corresponding to the discrete Metropolis adjusted Langevin algorithm (DMALA) and the discrete unadjusted Langevin algorithm~(DULA), respectively.

\vspace{-2mm}
\section{Methodology}\label{sec_4}
In this section, we introduce our proposed algorithm in~\cref{sec_4_1} and discuss the optimal temperature schedule and the number of chains in \cref{sec_4_2,sec_4_3}.
\vspace{-2mm}
\subsection{Parallel Tempering Enhanced Discrete Langevin Sampler}\label{sec_4_1}


\begin{figure}[t]
  \begin{center}
    \begin{minipage}{0.23\textwidth}
      \includegraphics[width=\textwidth]{figs/intuition_1.pdf}
    \end{minipage}
    \begin{minipage}{0.23\textwidth}
      \includegraphics[width=\textwidth]{figs/intuition_2.pdf}
    \end{minipage}
  \end{center}
  \vspace{-10pt}
  \caption{The blue, green, and red dots correspond to probability functions at three temperatures. The high-probability areas to sample from are indicated by dashed lines.}
  \label{fig:intuition}
  \vspace{-10pt}
\end{figure}


One major issue with two replicas is that the swaps may not happen often enough. To see this, denote by $R(r, M):=\{x:\|x - r\| \leq M\}$. As shown in \cref{fig:intuition},
the figure on the left illustrates the swap between two chains. The high-probability regions for $\theta_i^{(1)}$ and $\theta_i^{(3)}$ are defined by $R\left(2, r_1\right) \cup R\left(-2, r_1\right)$ and $R\left(0, r_3\right)$. Swaps between $\theta_i^{(1)}$ and $\theta_i^{(3)}$ are unlikely to occur frequently, as $\theta_i^{(3)}$ has a low probability of falling within the region $R\left(2, r_1\right) \cup R\left(-2, r_1\right)$. However, when the number of chains increases to three, the high-probability region for $\theta_i^{(2)}$ becomes $R\left(2, r_2\right) \cup R\left(-2, r_2\right)$ with $r_1 < r_2 < r_3$, making it easier for $\theta_i^{(3)}$ to lie within this region, thereby increasing the frequency of swaps. In light of the fact that non-adjacent chain swaps are unlikely to occur, we exclusively consider adjacent swaps in this paper.

Building on the previous discussion, we propose a method that incorporates multiple chains to further enhance performance:
\begin{equation}\label{PTDLP_1}
\begin{aligned}
&\textbf{Exploitation:}\ \\ &q_1\!\left(\theta^{\prime} \!\mid \!{\theta}\right)\! \propto\! \exp \bigg\{\!-\!\frac{\beta_1}{2} \nabla U({\theta})^{\top}\left({\theta}^{\prime}\!-\!{\theta}\right)-\frac{1}{2 \alpha_1}\left\|{\theta}^{\prime}-{\theta}\right\|_p^p\bigg\},
\end{aligned}
\end{equation}
\begin{equation}\label{PTDLP_2}
\begin{aligned}
&\textbf{Exploration:}\ \\ &q_k\!\left({\theta}^{\prime}\! \mid\! {\theta}\right)\!\propto\! \exp \bigg\{\!-\!\underbrace{\frac{\beta_k}{2} \nabla U({\theta})^{\top}\left({\theta}^{\prime}\!-\!{\theta}\right)}_{\text {First-order Taylor Expansion}}-\underbrace{\frac{1}{2 \alpha_k}\left\|{\theta}^{\prime}-{\theta}\right\|_p^p}_{\text {Regularizer}}\bigg\},
\end{aligned}
\end{equation}
where $k=2,\cdots, K$ and $1=\beta_1>\cdots >\beta_K=0$. Note that the above proposals can also be factorized by coordinates, as shown in \cref{factorize}, which allows us to update each coordinate in parallel after computing $\nabla U(\theta)$. \citet{zhang2022langevin} emphasize the importance of the regularizer term, as it introduces a parameter similar to the step size. Note that we have chosen the 
$\textit{p}$-norm instead of the $2$-norm, considering that in certain tasks, selecting alternative norms may improve model performance, which could be due to the geometric structure of specific discrete domain distributions~\citep{park2023linear,jiang2024uncovering}. We denote the proposal in \cref{PTDLP_1,PTDLP_2} by Parallel Tempering enhanced Discrete Langevin Proposal~(PTDLP), which needs a MH step~\citep{metropolis1953equation}. Specifically, for each $k=1, \cdots, K$, after generating the next position $\theta^{\prime}$ from a distribution $q_k(\cdot \mid \theta)$, the MH step accepts it with the following probability:
\begin{equation}\label{MH}
\min \left\{1, \exp \left(\beta_k\left(U\left(\theta^{\prime}\right) - U(\theta)\right)\right) \frac{q_k\left(\theta \mid \theta^{\prime}\right)}{q_k\left(\theta^{\prime} \mid \theta\right)}\right\}.
\end{equation}
Marginally, $\theta_i^{(k)}$ has its invariant distribution $\pi^{\beta_k}(\theta)\propto \exp(\beta_k U(\theta))$. Unless noted, our algorithm all includes the MH step. The exchange takes place between neighboring replicas.  In particular, for each $1 \leq k \leq K-1$, $\theta_{i+1}^{(k)}$ and $\theta_{i+1}^{(k+1)}$ are swapped with rate $\rho s_k$, where $s_k$ is a tailored Metropolis criterion: 
\begin{equation}\label{swap_function}
\begin{aligned}
&s_k\left(\theta_{i+1}^{(k)}, \theta_{i+1}^{(k+1)}\mid \theta_i^{(k)}, \theta_i^{(k+1)}\right)\\&\!=\! \max\left\{\!1, e^{\beta_{\delta, k}\left[U\left({\theta}_{i+1}^{(k)}\right)+U\left({\theta}_i^{(k)}\right)-U\left({\theta}_{i+1}^{(k+1)}\right)-U\left({\theta}_i^{(k+1)}\right)\right]}\!\right\}, 
\end{aligned}
\end{equation}
where $\beta_{\delta, k}:= \beta_k - \beta_{k+1}$. This approach involves running multiple chains in parallel, with each chain exploring a unique region of the parameter space. By exchanging information through swaps, the chains can effectively traverse diverse areas of the solution space, reducing the risk of becoming trapped in local minima. This mechanism significantly enhances the algorithm's capacity to effectively explore multimodel distributions. As the number of chains increases, additional parameters, such as the chain number and temperature schedule, must be specified, as discussed in the following sections. 
\begin{algorithm}[t]
  \caption{Parallel Tempering Discrete Langevin Proposal~(PTDLP for short).}
  \begin{algorithmic}
    \label{alg:dlp}
    \STATE \textbf{given:} Stepsize $\boldsymbol{\alpha}$, sampling steps $\hat{n}$, temperatures $\mathcal{T}_K$, chain number $K$, swap intensity $\rho$, initial samples $\boldsymbol{\theta_0}$.
    \LOOP
    \FOR[{{\color{black} Can be done in parallel}}]{$k = 1, \cdots, K$}
      \STATE {\color{blue} Sampling step}
      \FOR[{{\color{black} Can be done in parallel}}]{$i = 1, \cdots, d$}
      \STATE \textbf{construct} $q_{n}^{(i)}(\cdot|\theta)$ as in \cref{factorize}
      \STATE \textbf{sample} $\theta_n^{\prime  (i)} \sim q_n^{(i)}(\cdot|\theta)$
      \ENDFOR
    %\vspace{0.5em}
    \STATE {\color{blue} MH step}
    \STATE \textbf{compute} $q(\theta'|\theta) = \prod_i q_i(\theta'_i|\theta)$ 
    \STATE\hspace{4em} and $q(\theta|\theta') = \prod_i q_i(\theta_i|\theta')$
    \STATE \textbf{set} $\theta \leftarrow \theta'$ with probability in \cref{MH}
    \ENDFOR
    \STATE {\color{blue} Swapping step}
    \STATE $u\leftarrow \operatorname{Unif}(0,1)$
    \FOR{$k = 1, \cdots, K-1$}
    \STATE \textbf{construct} $s_n$ as in \cref{swap_function}
    \STATE $\hat{s}_n \leftarrow \hat{s}_n + s_n$
    \STATE \textbf{exchange} $\theta_{k}$ and $\theta_{k+1}$ if $u \leq \rho s_n$
    \ENDFOR
    \ENDLOOP
    \STATE $\hat{s}_k \leftarrow \hat{s}_k /\hat{n}$ for all $k \in\{1, \ldots, K-1\}$
    \STATE \textbf{output}: Samples $\{\theta_1(t)\}_{t=1}^{\hat{n}}$ and acceptance rates $\{\hat{s}_k\}_{k=1}^{K-1}$.  
  \end{algorithmic}
\end{algorithm}
\vspace{-1mm}
\subsection{Optimal Temperature Schedule}\label{sec_4_2}
Poor spacing of the temperatures can cause the replica systems to be either too far apart, reducing the chances of exchange, or too close, limiting the diversity of the samples~\citep{kone2005selection}.  We are interested in determining the optimal distribution of transition probabilities that maximizes the flow across the inverse temperature space. To this end, we adopt the following assumption, as stated in~\citet[Assumption 2]{syed2022non}.
\begin{assumption}\label{asm_1}
    For any $k=1, \cdots, K$ and $\theta \sim \pi^{\beta_k}$ and $\theta^{\prime} \sim q_k\!\left({\theta}^{\prime}\! \mid\! {\theta}\right)$, the r.v. $U(\theta)$ and $U\left(\theta^{\prime}\right)$ are independent.
\end{assumption}
Note that \cref{asm_1} is not expected to hold exactly in real scenarios. \citet{syed2022non} has shown that even when \cref{asm_1} is violated, the key results made by the theory still closely match empirical behavior. Furthermore, this simplifying assumption on the local exploration moves allows us to decouple the sampler and specifically analyze the impact of temperature selection on the efficiency of PT. In PT literature, $\tau$ is commonly referred to as the round trip rate and has been used to compare the effectiveness of various PT algorithms~\citep{katzgraber2006feedback,lingenheil2009efficiency}. In the next theorem, we calculate the round trip rate of the algorithm we propose.
\begin{theorem}\label{round_trip_rate}
Let \cref{asm_1} hold. For any fixed chain number $K$ and temperature schedule $\mathcal{T}_K=\left\{\beta_1, \ldots, \beta_K\right\}$, the non-asymptotic~(in $K$) round trip rate of PT with all neighboring chains swapping is 
$$
\tau\left(\mathcal{T}_K\right)=\frac{K}{ \left(K+1\right)\sum_{k=1}^{K-1}\left(1 / s_k\right)}, 
$$
where $s_k$, defined in \cref{swap_function}, is the probability of swapping between chains $k$ and $k+1$.
\end{theorem}
We first discuss how to optimize the temperature schedule $\mathcal{T}_K$ to maximize the round trip rate $\tau(\mathcal{T}_K)$ when $K$ is fixed. Let $\tilde{s}\left(\beta_k, \beta_{k+1}\right):=s_k$, where $s_k$ is defined in \cref{swap_function}, and define $\lambda(\beta):=\lim _{\delta \rightarrow 0} \frac{1 - \tilde{s}(\beta, \beta+\delta)}{|\delta|}$. The communication barrier is expressed as the integral of $\lambda$, given by $\Lambda(\beta)=\int_0^\beta \lambda\left(t\right) \mathrm{d}t$, with $\Lambda$ denoting $\Lambda(1)$ and $\Lambda(0)=0$. By using~\citet[Corollary 2]{syed2022non}, we obtain $\sum_{k=1}^{K-1}(1 - s_k) \approx \Lambda$ for all temperature schedules. Therefore, our task becomes to maximize $\tau\left(\mathcal{T}_K\right)$, subject to the constraint $\sum_{k=1}^{K-1} (1 - s_k)=\Lambda$ and $0\leq s_k\leq1$, which implies that the non-asymptotic round trip rate is maximized when the swap rates are all equal\footnote{This result of the identical acceptance rate is highly consistent with the predictions of other existing theoretical frameworks~\citep{atchade2011towards, predescu2004incomplete, syed2022non}.}. Then we get
\begin{equation}\label{lambda_app}
\Lambda\left(\beta_k^*\right) /  \Lambda \approx 1 - \frac{k-1}{K-1}. 
\end{equation}
To obtain the estimation of the communication barrier $\Lambda$, we first perform a short pilot run and have access to a collection of samples $\left(\boldsymbol{\tilde{\theta}_1}, \boldsymbol{\tilde{\theta}_2}, \ldots, \boldsymbol{\tilde{\theta}_{\tilde{n}}}\right)$ with $\boldsymbol{\tilde{\theta_i}}:=(\tilde{\theta_i}^{(1)},\cdots, \tilde{\theta_i}^{(K)})^\top$ from our algorithm based on an arbitrary temperature schedule $\mathcal{T}_K$.
For the given schedule $\mathcal{T}_K$, the Monte Carlo estimates for the acceptance rates satisfy
$$
\hat{s}_k \approx\frac{1}{\tilde{n}-1} \sum_{i=1}^{\tilde{n}-1} s_k\left(\tilde{\theta}_{i+1}^{(k)}, \tilde{\theta}_{i+1}^{(k+1)}\mid \tilde{\theta}_i^{(k)}, \tilde{\theta}_i^{(k+1)}\right). 
$$
\Cref{lambda_app} motivates the following approximation for $\Lambda\left(\beta_k\right)$, for $k=1, \cdots, K-1$, 
\begin{equation}\label{lambda_beta}
\hat{\Lambda}\left(\beta_k\right)=\sum_{i=k}^{K-1} \left(1 - \hat{s}_i\right).
\end{equation}
Given $\hat{\Lambda}\left(\beta_1\right), \ldots, \hat{\Lambda}\left(\beta_K\right)$, we estimate the function $\Lambda(\beta)$ via a monotone piecewise cubic
interpolation~\citep{fritsch1980monotone}. The optimal temperature schedule can be determined using the bisection method based on \cref{lambda_app}.


% \begin{algorithm}[H]
% \caption{\textsc{UpdateSchedule} (communication barrier $\Lambda(\cdot)$, schedule size $N$)}
% \begin{algorithmic}[1]
% \STATE $\Lambda \gets \Lambda(1)$\\
% \FOR{$k$ in $0, 1, 2, \dots, N$}
%     \STATE Find $\beta_k^*$ such that $\Lambda(\beta_k^*) = \frac{k}{N} \Lambda$ using e.g. bisection.
% \ENDFOR\\
% $\textbf{return}$ $\mathbf{P}^*_N = (\beta_0^*, \beta_1^*, \beta_2^*, \dots, \beta_N^*)$
% \end{algorithmic}
% \end{algorithm}


% \begin{algorithm}[H]
% \caption{\textsc{CommunicationBarrier} (acceptance rate $\{s_i\}$, schedule $\mathcal{T}_N$)}
% \begin{algorithmic}[1]
% \FOR{each $\beta_i \in \mathcal{T}_N$}
%     \STATE Compute $\hat{\Lambda}(\beta_i)$ \hfill $\triangleright$ 
% \ENDFOR
% \STATE $S \gets \{(\beta_0, \hat{\Lambda}(\beta_0)), (\beta_1, \hat{\Lambda}(\beta_1)), \dots, (\beta_N, \hat{\Lambda}(\beta_N))\}$
% \STATE Compute a monotone increasing interpolation $\hat{\Lambda}(\cdot)$ of the points $S$ \hfill $\triangleright$\\
% $\textbf{return}$ $\hat{\Lambda}(\cdot)$
% \end{algorithmic}
% \end{algorithm}


\subsection{Optimal Chain Number}\label{sec_4_3}
Fixing the temperature schedule, we now aim to improve the algorithm by modifying the number of chains. Suppose there are $\mathcal{B}$ copies of PT running in parallel, each consisting of $K$ chains with their optimal temperature schedules. If $\bar{K}$ represents the total number of available machines, then $K$ must satisfy the constraint $\mathcal{B} K \leq \bar{K}$. The total round trip rate across all $\mathcal{B}$ copies of PT is
$$
\tau_{\Lambda}(K)=\mathcal{B}\tau\left(\mathcal{T}_K\right) = \frac{\mathcal{B}K}{(K+1)\sum_{k=1}^{K-1} \frac{1}{s_k}}.
$$
The next proposition explains how to determine the optimal number of chains, given the optimal temperature schedule.
\begin{proposition}\label{prop_4_3}
$\tau_{\Lambda}(\cdot)$ is optimized when we run $\mathcal{B}^*=\bar{K} /K^*$ copies of PT with $K^{\ast}=\frac{2+3 \Lambda+\sqrt{9 \Lambda^2+20 \Lambda+4}}{4}$ chains to achieve an optimum round trip rate. 
\end{proposition}
Details of the iterative schedule tuning algorithm can be found in \cref{tuning_algo}.
\section{Theoretical Analysis}
In this section, we present an asymptotic convergence analysis of PTDLP without MH step, along with its mixing time, and a non-asymptotic convergence analysis for PTDLP with MH step, which extends the previous analysis~\citep{grathwohl2021oops,zhang2022langevin,pynadath2024gradient}. We further highlight the acceleration benefits achieved through swapping mechanism.

\subsection{Asymptotic Convergence Analysis}\label{sec_5_1}
First, we prove the asymptotic convergence of PTDLP without MH. \citet{zhang2022langevin} showed that a discrete Langevin-like sampler with temperature 1 is reversible for log-quadratic energy distributions with small step sizes. However, this does not directly extend to the proposed algorithm due to the multi-chain structure, swap mechanism, and higher temperatures. We focus on the case of three chains, with the result extendable to more.

\begin{theorem}\label{thm:5.1}
    Let $\pi^{\beta_1} \propto \exp(\beta_1U(\theta))$ be the target distribution and $\tilde{\pi}^{\beta_1} (\theta)\propto \exp \left(\beta_1\left(\theta^{\top} W \theta+b \theta\right)\right)$ be the log-quadratic distribution satisfying that $\exists W \in \mathbb{R}^{d \times d}$, $b \in \mathbb{R}$, $\epsilon \in \mathbb{R}^{+}$, such that $\|\nabla U(\theta)-(2 W \theta+b)\|_1 \leq \epsilon$ for any $\theta \in \Theta$, then the stationary distribution of PTDLP without MH satisfies
\begin{equation}
\begin{aligned}
&\left\|\pi_\alpha-\pi\right\|_1 \leq \\
&Z_1\left(\exp\left(Z_2\epsilon\right)-1\right) + Z_3 \exp \left(-\frac{1+\alpha\beta_1 \lambda_{\min }}{2 \alpha}\right), 
\end{aligned}
\label{thm:5.1_eq}
\end{equation}
where $\lambda_{\text {min }}$ is the smallest eigenvalue of $W$, $Z_1$ is a constant determined by $\tilde{\pi}^{\beta_1}$ and $\alpha$, $Z_2$ denotes a constant influenced by $\Theta$ and $\max_{\theta, \theta^{\prime} \in \Theta}\|\theta^{\prime} - \theta\|_{\infty}$, while $Z_3$ corresponds to a constant that is dependent on $\tilde{\pi}^{\beta_1}$.
\end{theorem}

The first term represents the bias due to $\pi$ deviating from log-quadratic, while the second term reflects the bias from using a non-zero step size. However, as shown in the following theorem, reducing the step size to mitigate the second-term error is impractical in real-world applications. 

\begin{theorem}\label{thm:5.2}
    If the target distribution is assumed to be log-quadratic, i.e., for any $\theta \in \Theta$, $\pi(\theta) \propto \exp \left\{\theta^{\top} W \theta+b^{\top} \theta\right\}$ with some constants $W \in \mathbb{R}^{d \times d}$ and $b \in \mathbb{R}^{d}$. Denote by $\mathcal{D} = \sup _{\theta, \theta^{\prime} \in \Theta}\left\|\theta-\theta^{\prime}\right\|$. 
    The mixing time of PTDLP without MH step defined in \cref{q_first_chain} satisfies
$$
\begin{aligned}
&t_{\operatorname{mix}}(\varepsilon)\geq\\
&\left(\frac{1}{4 Z}\exp \left(\frac{1}{2} \lambda_{\min }(W) \mathcal{D}^2+\frac{1}{2 \alpha} \mathcal{D}^p\right)-1\right) \log \left(\frac{1}{2 \varepsilon}\right).
\end{aligned}
$$
\end{theorem}
Without the MH step, the error between our algorithm's stationary distribution and the target distribution arises from two sources: the distance to the log-quadratic distribution (quantified by the first term in \cref{thm:5.1_eq}) and the error introduced by the step size. \citet{zhang2022langevin} noted that for small step sizes, this error can be neglected, and removing the MH step reduces computational costs. However, \cref{thm:5.2} shows that as the step size decreases, mixing time increases exponentially, adding computational costs. Furthermore, in discrete domains, the decaying step sizes used in continuous settings are not applicable. To ensure convergence with fixed step sizes, the MH step is required.

\subsection{Non-asymptotic Convergence Analysis}\label{sec_5_2}
Next, we focus on proving the non-asymptotic convergence of PTDLP with MH. We have the following assumptions:
\begin{assumption}\label{asm_2}
The function \(U(\cdot)\in C^{2}(\mathbb{R}^{d})\) has \(M\)-Lipschitz gradient. That is
\[
\|\nabla U(\theta)-\nabla U(\theta^{\prime})\|\leq M\|\theta-\theta^{\prime}\|\,.\]
\end{assumption}
% We define \(conv(\Theta)\) as the convex hull of the set \(\Theta\).
\begin{assumption}\label{asm_3}
For each \(\theta\in\Theta\), there exists an open ball containing \(\theta\) of some radius \(r_{\theta}\), denoted by \(R(\theta,r_{\theta})\), such that the function \(U(\cdot)\) is \(m\)-strongly concave in \(R(\theta,r_{\theta})\) for some \(m>0\).
\end{assumption}
\cref{asm_2,asm_3} are standard in optimization and sampling literature~\citep{dalalyan2017theoretical}. For simplicity of the proof, we consider the case of three chains. Denote by 
\begin{equation}\label{diam}
\tilde{\mathcal{D}}(\Theta):=\max\left\{\sup _{\theta, \theta^{\prime} \in \Theta}\left\|\theta-\theta^{\prime}\right\|, \sqrt{\frac{2\log(1 / \epsilon_0)}{\|\mathcal{T}_K\| (M - \frac{m}{2})}}\right\},
\end{equation}
where $0<\epsilon_0<1$ is given by \cref{epsilon_0} and $\|\mathcal{T}_K\|:=\min_{k=1, \cdots, K-1}\left|\beta_k - \beta_{k+1}\right|$.
\begin{theorem}\label{thm:4}
Let \cref{asm_2,asm_3} hold. Then for the Markov chain \(P\) with three chains, we have, for any $\theta^{\prime}$, $\theta^{(1)}$, and $\theta^{(2)}\in \Theta$,
$$
p(\theta^{\prime}\mid\theta^{(1)}_{i})\geq\epsilon\frac{\exp\left\{\beta_{3} U (\theta^{\prime})\right\}}{\sum_{\theta^{\prime}\in\Theta}\exp\left\{\beta_{3} U(\theta^{\prime})\right\}}, 
$$
where $\epsilon=\epsilon_{0}^2\epsilon_{\beta_3, \alpha}$ with $\epsilon_{0}$ given in~\cref{epsilon_0} and 
$$
\begin{aligned}
\epsilon_{\beta_{3},\alpha}&=\exp\bigg\{-\left(\beta_3 M-\frac{\beta_3 \,m}{2}\right)\, \tilde{\mathcal{D}}(\Theta)^{2} \\&\quad -\beta_{3}\|\nabla U(a)\|\,\tilde{\mathcal{D}}(\Theta) - \frac{1}{\alpha}\tilde{\mathcal{D}}(\Theta)^{p} \bigg\}, 
\end{aligned}
$$
with $a\in\arg\min_{\theta\in\Theta}\|\nabla U(\theta)\|$.
\end{theorem}

\begin{corollary}\label{cor:5.6}
    Let \cref{asm_2,asm_3} hold. Then for the Markov chain $P$ with three chains, the following hold:

%\begin{enumerate}
1) $P$ is uniformly ergodic with
$$\|P^n - \pi\|_{\text{TV}} \leq (1 - \epsilon)^n.$$

2) For any real-valued function $f$ and samples $\theta_1, \dots, \theta_n$ from $P$, one has
$$
\sqrt{n} \left( \frac{1}{n} \sum_{i=1}^n f(X_i) - \sum_{\theta \in \Theta} f(\theta) \pi(\theta) \right) \xrightarrow{d} N(0, \tilde{\sigma}_*^2),
$$
for some $\tilde{\sigma}_* > 0$ as $n \to \infty$.
%\end{enumerate}
\end{corollary}
The proof follows directly from \cref{thm:4} and ~\citet{jones2004markov} [Corollary 5]. \cref{cor:5.6} shows that swapping increases $\epsilon$, leading to a faster convergence rate to the invariant distribution. Thus, we have the following corollary.
\begin{corollary}\label{col:5.7}
Let \cref{asm_2,asm_3} hold. Assume that $$\|\nabla U(a)\| < (M-\frac{m}{2})\tilde{\mathcal{D}}(\Theta) - \frac{2\log(1 / \epsilon_0)}{\|\mathcal{T}_K\| \tilde{\mathcal{D}}(\Theta)},$$ where $a\in\arg\min_{\theta\in\Theta}\|\nabla U(\theta)\|$ and $\tilde{\mathcal{D}}(\Theta)$ is in \cref{diam}. Then, our algorithm converges faster than DLP. 
\end{corollary}


\section{Experiments}
In this section, we evaluate the newly proposed method on four problem types: \textbf{(1)} sampling from synthetic distributions, \textbf{(2)} sampling from restricted Boltzmann machines on real-world datasets, \textbf{(3)} learning restricted Boltzmann machines and \textbf{(4)} deep energy-based models parameterized by a convolutional neural network. 

%\subsection{Baselines}
For sampling tasks, we compare our algorithm with several popular gradient-based discrete samplers: the discrete Langevin-like samplers~(\textbf{DULA} and \textbf{DMALA}) \citep{zhang2022langevin}, the any-scale balanced sampler (\textbf{AB}) \citep{sun2023any}, and the automatic cyclical sampler (\textbf{ACS}) \citep{pynadath2024gradient}. 
For learning tasks, we exclude the AB sampler, as it is not originally designed for model learning applications. More details such as experimental setups, hyper-parameters, and additional experimental results can refer to~\cref{App_ex}. We released the code of the synthetic task at \href{https://github.com/LuxLiang/PTDLP/tree/main}{https://github.com/LuxLiang/PTDLP/tree/main}. 

\subsection{Synthetic Problems}
We first address the challenges of sampling from two-dimensional discrete multimodal distributions, specifically mixtures of Gaussian components~(MoG) and mixtures of Student's t-distributions~(MoS), defined over the domain $\Theta = \{1, 2, \ldots, 101\}^2$. To quantify the ability to avoid mode collapse, we use Maximum Mean Discrepancy (MMD)~\citep{gretton2012kernel}, forward Kullback-Leibler divergence~\citep{kullback1951information}, and Entropic Mode
Coverage (EMC)~\citep{blessing2024beyond} as quantitative performance metrics. EMC $\in[0,1]$ is a heuristic metric for mode collapse detection, where 0 indicates samples come from a single mode, and 1 indicates samples cover all modes.
\begin{figure}[t]
  \begin{center}
    \begin{minipage}{0.23\textwidth}
      \includegraphics[width=\textwidth]{figs/synthetic_sampling/G.pdf}
    \end{minipage}
    \begin{minipage}{0.23\textwidth}
      \includegraphics[width=\textwidth]{figs/synthetic_sampling/T.pdf}
    \end{minipage}
  \end{center}
  \vspace{-10pt}
  \caption{Sampling performance (measured by EMC) of various methods for Mixture of Gaussian (left) and Mixture of Student’s t-distributions (right) with varying components. PTDLP consistently outperforms baselines across random seeds.}
  \label{fig_synthetic}
  \vspace{-10pt}
\end{figure}
\begin{table}[t]
    \caption{Experiment results with exploring MoG and MoS, measured by KL and MMD (c denotes the number of components).}
    \label{kl_mmd}
    \centering
    \resizebox{\linewidth}{!}{
    \begin{tabular}{cccccc}
    \toprule
        \multicolumn{2}{c}{Metrics / Samplers}  & MoG~(c=8) & MoG~(c=16) & MoS~(c=8) & MoS~(c=16)\\
    \midrule
        \multirow{4}{*}{\makecell{MMD~($\downarrow$)}} 
        & DMALA & 2.077 \fs{0.022}&2.030\fs{0.012} &2.017\fs{0.021}& 2.158 \fs{0.023}  \\
        & ACS &2.004 \fs{0.011} &2.006 \fs{0.013} &2.006 \fs{0.017}&2.013 \fs{0.021}\\
        & AB &2.019 \fs{0.036}  & 2.001 \fs{0.012} & 2.005 \fs{0.024} &2.015 \fs{0.018}\\
        & PTDLP &$\textbf{1.996 \fs{0.025}}$  & \textbf{1.924 \fs{0.011}}&  \textbf{1.934\fs{0.038}} & \textbf{1.967 \fs{0.015}} \\
    \midrule
        \multirow{4}{*}{\makecell{KL~($10^{-2}$) ($\downarrow$)}}
        & DMALA &1.331 \fs{0.032}&7.660 \fs{0.043} & 2.017 \fs{0.026}&7.674 \fs{0.029}\\
        & ACS & 0.662\fs{0.012} & 2.177 \fs{0.023}& 3.117 \fs{0.041}&3.112 \fs{0.017}\\
        & AB & 0.851 \fs{0.011} & 3.216 \fs{0.022}& 2.801 \fs{0.026}&2.871 \fs{0.021}\\
        & PTDLP &\textbf{0.617 \fs{ 0.009}} & \textbf{2.133 \fs {0.017}} & \textbf{0.667 \fs {0.017}} & \textbf{1.948 \fs {0.014}}\\
    \bottomrule % \multirow{5}{*}{\diagbox[width=5em,height=5\line]{}{}}
    \end{tabular}}
    \vspace{-10pt}
\end{table}
\paragraph{Results}
As shown in \cref{kl_mmd,fig_synthetic}, the PTDLP algorithm consistently outperforms other methods on both mixed Gaussian and t-distributions with varying components across different metrics. While methods like AB and ACS attempt to alleviate this issue through variable step sizes, their effectiveness still falls short compared to our approach. These results underscore the algorithm's exceptional performance in these synthetic problems, while effectively mitigating mode collapse.

\paragraph{Analysis}
The superior performance of our algorithm arises from simultaneously simulating multiple chains at different temperatures. As the number of modes in synthetic distributions increases or the modes become well-separated, a single chain often fails to effectively explore the global distribution, becoming vulnerable to local minima. Using multiple chains, however, allows for a more thorough exploration of the different modes, enhancing coverage of the entire distribution and mitigating the risk of getting trapped in local minima.


% \begin{figure*}[t]
%   \begin{center}
%     \begin{minipage}{0.23\textwidth}
%       \includegraphics[width=\textwidth]{figs/synthetic_sampling/G.pdf}
%     \end{minipage}
%     \hfill
%     \begin{minipage}{0.23\textwidth}
%       \includegraphics[width=\textwidth]{figs/synthetic_sampling/T.pdf}
%     \end{minipage}
%     \hfill
%     \begin{minipage}{0.23\textwidth}
%       \includegraphics[width=\textwidth]{figs/synthetic_sampling/G.pdf}
%     \end{minipage}
%     \hfill
%     \begin{minipage}{0.23\textwidth}
%       \includegraphics[width=\textwidth]{figs/synthetic_sampling/T.pdf}
%     \end{minipage}
%   \end{center}
%   \vspace{-10pt}
%   \caption{Sampling performance (measured by EMC) of various methods for Mixture of Gaussian (left) and Mixture of Student’s t-distributions (right) with varying components. PTDLP consistently outperforms baselines across random seeds.}
%   \label{fig_synthetic}
%   \vspace{-10pt}
% \end{figure*}

\subsection{Sampling From Restricted Boltzmann Machines}
Restricted Boltzmann Machines (RBMs) are generative artificial neural networks, which learn an unnormalized probability over inputs: 
$$
U(\theta)=\sum_i \operatorname{Softplus}(W \theta+a)_i+b^{\top} \theta, 
$$
where $\{W, a, b\}$ are parameters and $\theta \in\{0,1\}^d$. Following~\citet{grathwohl2021oops} and~\citet{zhang2022langevin}, we train $\{W, a, b\}$ with contrastive divergence~\citep{carreira2005contrastive} on various datasets for one epoch. We measure the MMD between the obtained samples and those from block-Gibbs sampling, which utilizes the known structure and can be regarded as the ground truth. To further test whether our method can escape local modes, we initialize all samplers to start
within the most likely mode of the dataset as measured by
the model distribution.
\begin{figure}[t]
  \begin{center}
    \begin{minipage}{0.23\textwidth}
      \includegraphics[width=\textwidth]{figs/rbm_sampling/test_EMNIST.pdf}
    \end{minipage}
    \begin{minipage}{0.23\textwidth}
      \includegraphics[width=\textwidth]{figs/rbm_sampling/test_CALTECH.pdf}
    \end{minipage}
  \end{center}
  \vspace{-10pt}
  \caption{RBM sampling results with mode initialization. PTDLP achieves faster convergence, while baseline methods converge slower due to being trapped in the mode.}
  \label{fig_mode_int}
  \vspace{-10pt}
\end{figure}

\paragraph{Results} As shown in \cref{tab_rbm_sampling_learning}, our algorithm consistently demonstrates superior performance across a diverse array of complex real-world datasets, with notable improvements in datasets like Caltech. AB and ACS perform nearly as well but with slightly higher MMD values. In \cref{fig_mode_int}, our approach converges more quickly than other samplers, yielding competitive results across different random seeds. In contrast, the DULA algorithm with an optimal step size easily becomes trapped in a single mode. These results suggest that our method effectively avoids getting trapped in the initial mode, a challenge faced by the baseline methods. %These results underscore PTDLP’s ability to efficiently explore and accurately capture multiple modes.

\paragraph{Analysis}
These results underscore PTDLP’s ability to efficiently explore and accurately capture multiple modes. In RBM sampling task, the energy landscapes contain many local minima, making it difficult for baseline sampling methods to explore the entire distribution effectively. Our algorithm addresses this and provides the most
robust sampling by running multiple chains at different temperatures, allowing higher-temperature chains to explore the space more freely and avoid getting stuck in local minima.


% we achieved faster convergence compared to ACS and AB. In contrast, the DULA algorithm with an optimal step size easily becomes trapped in a single mode, which suggests that decreasing step sizes may not be as effective as using MH corrections in discrete settings.

\begin{table*}[ht]
    \caption{RBM sampling results with random initialization and RBM learning results. The top table shows results quantified by $\textit{log-MMD}$ ($\downarrow$), where PTDLP outperforms all gradient-based baselines across datasets. The bottom table presents $\textit{log-likelihood scores}$ ($\uparrow$) for RBM learning on test data, as estimated by AIS. PTDLP demonstrates competitive, and sometimes superior, performance across all datasets.}
    \label{tab_rbm_sampling_learning}
    %\vspace{1mm}
    \centering
    % \renewcommand\arraystretch{1.2}  % 设置表格行间距
    \resizebox{0.9\textwidth}{!}{
    \begin{tabular}{cccccccc}
    \toprule
        \multicolumn{2}{c}{Dataset}  & DULA & DMALA & AB & ACS & PTDLP~\textit{(Ours)}& \\
    \midrule
        \multirow{5}{*}{\makecell{RBM Sampling\\(\textit{log-MMD} $\downarrow$)}} 
        & MNIST & -4.77\fs{0.34} & -6.45\fs{0.29} & -6.65\fs{0.10} & -6.66\fs{0.20} & \textbf{-6.68\fs{0.19}} \\
        & eMNIST & -3.19\fs{0.07} & -3.85\fs{0.10} & -4.01\fs{0.12} & -3.97\fs{0.09} & \textbf{-4.05\fs{0.09}} \\
        & kMNIST & -4.03\fs{0.10} & -4.62\fs{0.17} & -4.71\fs{0.11} & -4.58\fs{0.12} & \textbf{-4.77\fs{0.20}} \\
        & Omniglot & -6.45\fs{0.15} & -6.48\fs{0.08} & -6.48\fs{0.11} & -6.49\fs{0.18} & \textbf{-6.56\fs{0.05}} \\
        & Caltech & -3.09\fs{0.10} & -4.10\fs{0.28} & -4.21\fs{0.33} & -4.21\fs{0.20} & \textbf{-4.98\fs{0.23}} \\
    \midrule
        \multirow{5}{*}{\makecell{Learning RBM\\(\textit{log-likelihood} $\uparrow$)}}
        & MNIST & -386.21\fs{2.32} & -264.83\fs{1.51} & ---& -231.12\fs{2.10} & \textbf{-225.56\fs{2.25}} \\
        & eMNIST & -337.27\fs{4.21} & -324.34\fs{2.13} & ---& \textbf{-301.42\fs{1.99}} & -302.78\fs{1.95} \\
        & kMNIST & -502.22\fs{3.76} & -436.35\fs{2.76} & ---& -407.39\fs{3.46} & \textbf{-362.85\fs{3.97}} \\
        & Omniglot & -228.23\fs{2.12} & -222.61\fs{1.33} &--- & -220.71\fs{1.65} & \textbf{-179.54\fs{2.01}} \\
        & Caltech & -452.97\fs{6.10} & -427.29\fs{3.99} &---& -380.67\fs{3.01} & \textbf{-346.65\fs{2.76}} \\
    \bottomrule % \multirow{5}{*}{\diagbox[width=5em,height=5\line]{}{}}
    \end{tabular}}
    \vspace{-10pt}
\end{table*}

% \begin{table*}[ht]
%     \centering
%     \resizebox{0.99\textwidth}{!}{
%     \renewcommand\arraystretch{1.2}{
%     \begin{tabular}{cc|cccccc}
%     \hline \hline
%         %\multirow{1}{2}{Dataset}& &\multicolumn{5}{c}{Test Log-MMD ($\downarrow$)} \\ \cline{3-8}
%          \multicolumn{2}{c}{Dataset}  &DULA & DMALA& AB & ACS & \textit{p}-PTDLP &  \\ \hline
%         \multirow{6}{*}{\makecell{RBM Sampling\\(log-MMD $\downarrow$)}} &MNIST & -4.774\fs{0.335}& -6.454\fs{0.285} & -6.645\fs{0.103} & -6.663\fs{0.202}  & \textbf{-6.681\fs{0.187}}   \\
%         & eMNIST & -3.191\fs{0.074} & -3.660\fs{0.101} & -4.011\fs{0.116}& -3.846\fs{0.092} & \textbf{-4.047\fs{0.087}} \\
%         & kMNIST &-4.025\fs{0.104}  & -4.620\fs{0.167} & -4.714\fs{0.111} &-4.578\fs{0.118}  & \textbf{-4.771\fs{0.202}} \\ 
%         & Omniglot & -6.447\fs{0.147} & -6.479\fs{0.080}& -6.475\fs{0.105} & -6.489\fs{0.176} & \textbf{-6.560\fs{0.051}} \\
%         & Caltech & -3.086\fs{0.102} &  -4.100\fs{0.279}& -4.205\fs{0.333} &  -4.208\fs{0.199}& \textbf{-4.981\fs{0.234}}\\
% \hline
%         \multirow{6}{*}{\makecell{Learning RBM\\ (log-likelihood $\uparrow$)}} &MNIST & -387.34 & -264.83 & -259.71& -231.12& \textbf{-225.56} \\
%         & eMNIST & -337.27&-324.34 & \textbf{-297.64} & -304.96 & -302.78 \\
%         & kMNIST & -502.22 &-436.35 & -467.65 & -407.39& \textbf{-362.85}\\ 
%         & Omniglot &-228.23  & -222.61 & -197.827 & -220.71& \textbf{-179.54} \\
%         & Caltech & -452.97 & -427.29 &-448.38 &-380.67 &\textbf{-346.65}\\
%     \hline \hline
%     \end{tabular}}}
%     \caption{RBM sampling results, quantified by $\log$(MMD)~$(\downarrow)$, on different datasets.}
%     \label{tab:bayesbnn}
% \end{table*}

% \begin{table*}
%     \centering
%     \begin{tabular}{c c c c c c}
%     \toprule\toprule
%          Dataset & Method & Perplexity ($\downarrow$) & CoLA ($\uparrow$) & Self-Bleu ($\downarrow$) & \begin{tabular}{c c} \multicolumn{2}{c}{Unique n-gram ($\uparrow$)} \\ \midrule \quad n=2 & n=3 \end{tabular} \\
%          \midrule 
%          \multirow{3}{*}{Grimm} 
%          & DMALA & \textbf{280.82\fs{27.26}} & 50.46 \fs{1.25} & 41.83\fs{6.85} & \begin{tabular}{c c} 48.55 & 70.56 \end{tabular} \\
%          & ACS & 369.44\fs{30.85} & \textbf{53.42\fs{1.26}}$ & \textbf{36.70\fs{6.42}}$ & \begin{tabular}{c c} 53.91 & 74.70 \end{tabular} \\ 
%          & \textit{p}-PTDLP &  &  &  & \begin{tabular}{c c} 1 & 1 \end{tabular} \\ 
%          \midrule 
%          \multirow{3}{*}{SST2} 
%          & DMALA & \textbf{256.66\fs{10.53}} & 42.62\fs{1.14} &37.47\fs{0.79} & \begin{tabular}{c c} 57.68 & 75.21 \end{tabular} \\
%          & ACS & 307.05\fs{14.84} & \textbf{47.12\fs{1.20}}$ & \textbf{32.42\fs{0.75}}$ & \begin{tabular}{c c} 62.54 & 78.87 \end{tabular} \\
%          & \textit{p}-PTDLP &  &  &  & \begin{tabular}{c c} 1 & 1 \end{tabular} \\
%     \bottomrule
%     \end{tabular}
%     \caption{Empirical evaluation of the generated sentences. ACS outperforms DMALA for all metrics related to diversity.}
%     \label{tab:text_infilling_metrics}
% \end{table*}
\subsection{Learning Energy Based Models}
Energy-based models (EBMs) have achieved notable success in machine learning~\citep{lecun2006tutorial, ngiam2011learning}. In EBMs, the probability of a data point \(x\) is given by 
$P_\theta(x) = \exp\left[E_\theta(x)\right] / Z_\theta$, where \(E_\theta(x)\) is the energy function and $Z_\theta = \mathbb{E}_{\theta \sim \Theta} \left[\exp\left[E_\theta(x)\right]\right]$
is the partition function. MCMC methods are widely used for training EBMs, enabling efficient sampling.

\subsubsection{Learning RBM}
We begin with learning RBM, use the same RBM structure as the sampling task, and apply the samplers of interest to the PCD algorithm introduced by \citet{tieleman2008training}. To evaluate the learned model, we employ Annealed Importance Sampling (AIS)~\citep{neal2001annealed} with Block-Gibbs to calculate the log-likelihood values. We run AIS for 100,000 steps, which is adequate given the efficiency of Block Gibbs for this specific model.
\vspace{-2mm}
\paragraph{Results}
In~\cref{tab_rbm_sampling_learning}, we find that our algorithm produces competitive results compared to the baselines, and in many cases outperforms them across all datasets, demonstrating the superiority and robustness of using multiple chains. 



\subsubsection{Learning Deep EBM}
We train deep EBMs using a ResNet~\citep{he2016deep} with Persistent Contrastive Divergence (PCD)~\citep{tieleman2009using} and a replay buffer~\citep{du2019implicit} on the MNIST, Omniglot, and Caltech datasets, following the approach outlined by~\citet{grathwohl2021oops, zhang2022langevin}. We use 10 sample steps per iteration on all datasets except Caltech, where we use 30. After training, we use AIS to estimate the likelihood. 
\vspace{-2mm}
\paragraph{Results}
The results in~\cref{tab_ebm_learning} show that our method is capable of learning better quality EBMs than DMALA and ACS, which can be attributed to the fact that our method employs different temperatures to simultaneously explore diverse regions, enabling the identification of more modes.

\paragraph{Analysis}
In learning tasks, data typically comes from complex, high-dimensional distributions. Our approach runs multiple chains in parallel, where high-temperature chains provide greater exploration capabilities and low-temperature chains focus on more precisely exploiting the existing mode. This strategy effectively overcomes the problem of local minima, allowing the model to navigate the energy barriers between multiple modes, resulting in better solutions for complex distributions. Furthermore, the outstanding results also demonstrate the proposed swap mechanism in~\cref{swap_function} effectively corrects imbalance, which leads to improved log-likelihood estimates across diverse image datasets.


\begin{table}
\caption{Deep Convolution EBM \textit{log likelihood scores}~($\uparrow$) on test data as estimated by AIS.}\label{tab_ebm_learning}
%\vspace{1mm}
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}{lcccc}
\toprule
       &  DMALA  & ACS & PTDLP~\textit{(Ours)} \\
\midrule
Static MNIST & -80.031\fs{0.038} &-79.905\fs{0.057} &\textbf{-79.622\fs{0.063}}\\
Dynamic MNIST &-80.120\fs{0.036} &-79.634\fs{0.024}&\textbf{-79.463\fs{0.076}}\\
Omniglot & -99.243\fs{2.101} &-91.487\fs{0.128} &\textbf{-90.976\fs{0.316}}\\
Caltech & -98.001\fs{0.371} &-89.262\fs{0.290} &\textbf{-87.192\fs{0.343}}
\\
\bottomrule
\end{tabular}}
\vspace{-10pt}
\end{table}
% \subsection{Text Infilling}
% Text infilling~\citep{zhu2019text, zhang2022langevin} represents a challenging application of discrete MCMC methods, where the task is to complete a sentence by recovering missing words. In this approach, a dataset of sentences is utilized, where 50\% of the words are randomly masked, and the missing words are subsequently filled in based on the probability distribution provided by a pretrained RoBERTa model. 
% \paragraph{Results}


\section{Conclusions}
In this paper, we propose the \textit{Parallel Tempering enhanced Discrete Langevin Proposal} algorithm to better capture multimodal distributions in discrete spaces. Gradient-based samplers are prone to getting trapped in local modes, hindering full exploration of target distributions. To address this, we incorporate parallel tempering for more effective mode exploration. We also optimize the extra hyperparameters, such as the temperature schedule and the number of chains, by maximizing the round trip rate. Additionally, we establish the non-asymptotic convergence bound and provide extensive experimental results.

\textbf{Limitations and future work:} While we have developed a reversible algorithm with a non-asymptotic result, \citet{syed2022non,deng2023non} showed that non-reversible parallel tempering often outperforms the reversible version. Future work could explore combining non-reversible methods with discrete samplers. Another limitation is the tailored Metropolis criterion, which may fail in mini-batch settings. Approaches from the continuous domain~\citep{seita2016efficient,deng2020non} could be applied in future research.

%Additionally, this paper assumes a uniform reference distribution and a linear temperature path. Future research could extend this to adaptive (variational) reference distributions and non-linear temperature paths.

%	1. adaptive (variational) reference distribution
%	2. Non-Reversible Sampler, which could swap simultaneously         for all different machines, 更加并行化
%   3. correction bias



% Note use of \abovespace and \belowspace to get reasonable spacing
% above and below tabular lines.


% \section*{Accessibility}
% Authors are kindly asked to make their submissions as accessible as possible for everyone including people with disabilities and sensory or neurological differences.
% Tips of how to achieve this and what to pay attention to will be provided on the conference website \url{http://icml.cc/}.

% \section*{Software and Data}

% If a paper is accepted, we strongly encourage the publication of software and data with the
% camera-ready version of the paper whenever appropriate. This can be
% done by including a URL in the camera-ready copy. However, \textbf{do not}
% include URLs that reveal your institution or identity in your
% submission for review. Instead, provide an anonymous URL or upload
% the material as ``Supplementary Material'' into the OpenReview reviewing
% system. Note that reviewers are not required to look at this material
% when writing their review.

% % Acknowledgements should only appear in the accepted version.
% %\section*{Acknowledgements}

% %\textbf{Do not} include acknowledgements in the initial version of
% the paper submitted for blind review.

% %If a paper is accepted, the final camera-ready version can (and usually should) include acknowledgements.  Such acknowledgements should be placed at the end of the section, in an unnumbered section that does not count towards the paper page limit. Typically, this will  include thanks to reviewers who gave useful comments, to colleagues  who contributed to the ideas, and to funding agencies and corporate  sponsors that provided financial support.

\section*{Impact Statement}

% Authors are \textbf{required} to include a statement of the potential 
% broader impact of their work, including its ethical aspects and future 
% societal consequences. This statement should be in an unnumbered 
% section at the end of the paper (co-located with Acknowledgements -- 
% the two may appear in either order, but both must be before References), 
% and does not count toward the paper page limit. In many cases, where 
% the ethical impacts and expected societal implications are those that 
% are well established when advancing the field of Machine Learning, 
% substantial discussion is not required, and a simple statement such 
% as the following will suffice:

This paper presents work whose goal is to advance the field of 
Machine Learning. There are many potential societal consequences 
of our work, none which we feel must be specifically highlighted here.

% The above statement can be used verbatim in such cases, but we 
% encourage authors to think about whether there is content which does 
% warrant further discussion, as this statement will be apparent if the 
% paper is later flagged for ethics review.


% In the unusual situation where you want a paper to appear in the
% references without citing it in the main text, use \nocite
% \nocite{langley00}

\bibliography{example_paper}
\bibliographystyle{icml2025}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix
\onecolumn


\section{Algorithm with Different Variables}
\paragraph{Binary Variables}
When the variable domain $\Theta$ is binary, i.e., $\{0,1\}^d$, the algorithm in \cref{alg:dlp} can be further simplified for each chain update, which clearly shows that our method can be efficiently computed in parallel on both CPUs and GPUs.
\begin{algorithm}[H]
  \caption{Each chain with Binary Variables}
  \begin{algorithmic}
    \label{alg:binary}
    \STATE \textbf{given:} Stepsize $\alpha$.
      \LOOP
      \STATE \textbf{compute} $p(\theta) = \frac{\exp(-\frac{1}{2}\nabla U(\theta)\odot (2\theta-1) - \frac{1}{2\alpha})}{\exp(-\frac{1}{2}\nabla U(\theta)\odot (2\theta-1) - \frac{1}{2\alpha})+1}$
      \STATE \textbf{sample} $\mu \sim \text{Unif}(0,1)^d$
      \STATE $I \leftarrow \texttt{dim}(\mu\le p(\theta))$
    \STATE $\theta'\leftarrow \texttt{flipdim}(I)$
    \STATE \textbf{compute} $q(\theta'|\theta) = \prod_i q_i(\theta'_i|\theta)=\prod_{i\in I} p(\theta)_i \cdot \prod_{i\notin I} (1-p(\theta)_i)$
    \STATE \textbf{compute} $p(\theta') = \frac{\exp(-\frac{1}{2}\nabla U(\theta')\odot (2\theta'-1) - \frac{1}{2\alpha})}{\exp(-\frac{1}{2}\nabla U(\theta')\odot (2\theta'-1) - \frac{1}{2\alpha})+1}$
    \STATE \textbf{compute} $q(\theta|\theta') = \prod_i q_i(\theta_i|\theta')=\prod_{i\in I} p(\theta')_i \cdot \prod_{i\notin I} (1-p(\theta')_i)$
    \STATE \textbf{set} $\theta \leftarrow \theta'$ with probability in \cref{MH}
    \ENDLOOP
    \STATE \textbf{output}: samples $\{\theta_k\}$
  \end{algorithmic}
\end{algorithm}


\paragraph{Category Variables}
When using one-hot vectors to represent categorical variables, our discrete Langevin proposal becomes
$$
\text { Categorical }\left(\operatorname{Softmax}\left(\frac{\beta}{2} \nabla U(\theta)_i^{\top}\left(\theta_i^{\prime}-\theta_i\right)-\frac{\left\|\theta_i^{\prime}-\theta_i\right\|_p^p}{2 \alpha}\right)\right),
$$
where $\theta_i, \theta_i^{\prime}$ are one-hot vectors.

\section{Iterative Tuning Algorithm}\label{tuning_algo}

\begin{algorithm}[h]
  \caption{Iterative Tuning Algorithm}
  \begin{algorithmic}
    \label{alg:ITA}
    \STATE \textbf{given:} Initial temperature schedule $\mathcal{T}_{K}$ of size $K$, tuning steps $n_{\max}$, sampling steps $\hat{n}$, and $\epsilon$,
    \FOR{$n = 1, \cdots, n_{\max}$}
    \STATE $\left\{\hat{s}_k\right\}_{k=1}^{K-1} \leftarrow$ PTDLP $\left(\mathcal{T}_{K}, \hat{n}\right)$
    \STATE \textbf{calculate} points $\{(\beta_1, \hat{\Lambda}_n(\beta_1)), \cdots, (\beta_K, \hat{\Lambda}_n(\beta_K))\}$ using \cref{lambda_beta} 
    \STATE \textbf{compute} $\hat{\Lambda}(\cdot)$ by using monotone piecewise cubic interpolation~\citep{fritsch1980monotone}
        \FOR{$k=1, \cdots, K$}
        \STATE \textbf{find} $\beta_k^*$ using \cref{lambda_app} and bisection
        \STATE $\beta_k \leftarrow \beta_k^{\ast}$  
        \ENDFOR
    \IF{$\left|\hat{\Lambda}_n - \hat{\Lambda}_{n-1}\right| < \epsilon$}
        \STATE $\hat{\Lambda}_{n_{\max}}(\cdot) \leftarrow \hat{\Lambda}_{n}(\cdot)$
        \STATE \textbf{break}
    \ENDIF
    \ENDFOR
    \STATE $K^{\ast}\! \leftarrow\! \left(2\!+\!3\hat{\Lambda}_{n_{\max}}\!+\!\sqrt{9 \hat{\Lambda}_{n_{\max}}^2\!+\!20 \hat{\Lambda}_{n_{\max}}\!+\!4}\right) / 4$
    \FOR{$k=1, \cdots, K^{\ast}$}
        \STATE \textbf{find} $\beta_k^*$ using \cref{lambda_app} and bisection
    \ENDFOR
    % \STATE $\mathcal{B} \leftarrow \bar{K} /\left(N^{\ast}+1\right)$
    \STATE \textbf{output}: Optimal temperature schedule $\mathcal{T}^{\ast}_{K^{\ast}}$ and chain number $K^{\ast}$
    
  \end{algorithmic}
\end{algorithm}

\section{Proofs in \cref{sec_4}}
In this section, we provide a proof of \cref{sec_4} in the main paper.
\begin{proof}[Proof of \cref{round_trip_rate}]
We follow the proof of~\citet[Theorem 1]{syed2022non} and extend to our algorithm. We define the index process for machine $k$ as $\left(I_i^k, \varepsilon_i^k\right) \in\{1, \ldots, K\} \times\{-1,1\}$, where $\varepsilon_i^k=1$ if the temperature parameter on machine $k$ is proposed an increase after step $i$, and $-1$ otherwise. To simplify notation for the rest of the proof, let $T_{\uparrow}$ and $T_{\downarrow}$ be the hitting times to the target and reference defined by,
$$
T_{\uparrow}=\min \left\{n:\left(I_n, \varepsilon_n\right)=(K, 1)\right\}, \quad T_{\downarrow}=\min \left\{n:\left(I_n, \varepsilon_n\right)=(0,-1)\right\}
$$
Denote by $a^i_{\bullet} = \mathbb{E}\left(T_{\bullet} \mid I_0=i\right)$ and $\bullet \in\{\uparrow, \downarrow\}$, Then we have
$$
\mathbb{E}(T)=a^0_{\uparrow} + a^K_{\downarrow}.
$$
By using the Markov property and we have the recursion, for $k=1,\cdots, K-1$,
$$
a^k_{\bullet} = s_k \left(a^{k+1}_{\bullet} + 1\right) + s_{k-1}\left(a^{k-1}_{\bullet} + 1\right) + \left(1 - s_{k-1} - s_{k}\right)\left(a^k_{\bullet} +  1\right)
$$
Then we have $-1 = s_{k}\left(a^{k+1}_{\bullet} - a^{k}_{\bullet}\right) - s_{k-1}\left(a^{k} - a^{k-1}\right)$, which implies that 
\begin{equation}\label{thm1:1}
-k + 1= s_{k}\left(a^{k+1}_{\bullet} - a^{k}_{\bullet}\right)  - s_1\left(a^{2}_{\bullet} - a^{1}_{\bullet}\right) 
\end{equation}
and 
\begin{equation}\label{thm1:2}
-(K-k + 1) = s_K \left(a^K_{\bullet} - a^{K-1}_{\bullet}\right) - s_{k-1}\left(a^k_{\bullet} - a^{k-1}_{\bullet}\right).
\end{equation}
Consider that $a_{\uparrow}^1 = s_1 \left(a_{\uparrow}^2 + 1\right) + \left(1 - s_1\right)\left(a_{\uparrow}^1 + 1\right)$, which implies that 
\begin{equation}\label{thm1:3}
-1 = s_1\left(a_{\uparrow}^2 - a_{\uparrow}^1\right).
\end{equation}
Substituting \cref{thm1:3} into \cref{thm1:1} and using the fact that $a_{\uparrow}^K=0$ yield $a_{\uparrow}^1 = \sum_{k=1}^{K-1} \left(k/s_k\right)$. Similarly, we obtain $a_{\downarrow}^K = \sum_{k=1}^{K-1} (K-k+1) / s_k$. Therefore, we have 
\begin{equation}\label{thm1:4}
\mathbb{E}\left[ T \right] = a^0_{\uparrow} + a^K_{\downarrow}=\left(K+1\right)\sum_{k=1}^{K-1}\frac{1}{s_k}.
\end{equation}
We say a round trip has occurred on machine $k$ when $I_i^k$goes from $1$ to $K$ and then goes back to 0. Note that by \cref{asm_1}, the round trip $\mathcal{R}_n^j$ is a delayed renewal process. By using the key renewal theorem, we obtain
\begin{equation}\label{thm1:5}
\tau=\sum_{k=1}^K \lim _{i \rightarrow \infty} \frac{\mathbb{E}\left[\mathcal{R}_i^k\right]}{i}=\frac{K}{\mathbb{E}[T]}.
\end{equation}
Substituting~\cref{thm1:4} into~\cref{thm1:5} yields
$$
\tau\left(\mathcal{T}_K\right)=\frac{K}{\mathbb{E}[T]}=\frac{K}{ \left(K+1\right)\sum_{k=1}^{K-1}1 / s_k}.
$$

\end{proof}

\begin{proof}[Proof of \cref{prop_4_3}]
Recall that the round trip rate of our algorithm with $\mathcal{B}$ copies is 
\begin{equation}\label{tau_Lambda}
\tau_{\Lambda}(K)=\frac{\mathcal{B} K}{(K+1) \sum_{k=1}^{K-1} \frac{1}{s_k}}.
\end{equation}
By using the fact that the swap rates are all equal, we obtain, for any $k=1, \cdots, K-1$, 
$$
\sum_{k=1}^{K-1} \frac{1}{s_k} = \frac{K-1}{1 - \frac{\Lambda}{K-1}}.
$$
Substituting the above equation into \cref{tau_Lambda} yields
\begin{equation}\label{tao_Lambda_1}
\tau_{\Lambda} = \frac{\bar{K}(K-1-\Lambda)}{(K+1)(K-1)^2}.
\end{equation}
To maximize \cref{tao_Lambda_1}, we need to take the derivative and find the critical points. Denote by $f(K):=\frac{(K-1-\Lambda)}{(K+1)(K-1)^2}$ and let $f^{\prime}(K)=0$, we obtain, 
$$
K^{\ast}=\frac{2+3 \Lambda+\sqrt{9 \Lambda^2+20 \Lambda+4}}{4}.
$$
Finally, by verifying the second derivative, we determine that this point corresponds to a maximum.

\end{proof}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Proofs in \cref{sec_5_1}}
\begin{lemma}\label{lm:1}
    If the target distribution is assumed to be log-quadratic, i.e., for any $\theta \in \Theta$, $\pi^{\beta_k}(\theta) \propto \exp \left(\beta_k(\theta^{\top} W \theta+b^{\top} \theta)\right)$ with some constants\footnote{ Without loss of generality, we assume $W$ is symmetric, otherwise we can replace $W$ with $\left(W+W^{\top}\right) / 2$ for the eigendecomposition.} $W \in \mathbb{R}^{d \times d}$ and $b \in \mathbb{R}^d$. Then the Markov chain following transition $q_{\alpha, k}(\cdot \mid \theta)$ in \cref{PTDLP_2} for any $k$ is reversible with respect to some distribution $\pi_\alpha^{\beta_k}$, and $\pi_\alpha^{\beta_k}$ converges weakly to $\pi^{\beta_k}$ as $\alpha \rightarrow 0$. 
\end{lemma}
\begin{proof}
    The main idea of the proof is to replace the gradient term in the proposal by the energy difference $U(\theta^{\prime}) - U(\theta)$ using Taylor series approximation, and then show the reversibility of the chain based on the proofs in \citet{zanella2020informed, zhang2022langevin}. We divide the proof into two parts. In the first part, we prove the convergence of our algorithm to $\pi_{\alpha}^{\beta_k}$, and in the second part, we derive the distance between $\pi_{\alpha}^{\beta_k}$ and $\pi_{\alpha}$.
    
    Recall that the target distribution is $\pi^{\beta_k}(\theta)=\exp \left(\beta_k(\theta^{\top} W \theta+b^{\top} \theta)\right) / Z$. We have that $\nabla \log(\pi(\theta))=\beta_k(2 W^{\top} \theta+b)$, $\nabla^2 \log(\pi(\theta))=2\beta_k W$. Then, by using the fact that $U\left(\theta^{\prime}\right)-U(\theta)=\nabla U(\theta)^{\top}\left(\theta^{\prime}-\theta\right)+\frac{1}{2}\left(\theta^{\prime}-\theta\right)^{\top} 2 W\left(\theta^{\prime}-\theta\right)$ by Taylor series approximation, we can rewrite the proposal distribution as the following
\begin{equation}\label{log_quatratic}
\begin{aligned}
q_\alpha^{\beta_k}\left(\theta^{\prime} \mid \theta\right)
& =\frac{\exp \left(\frac{\beta_k}{2} \nabla U(\theta)^{\top}\left(\theta^{\prime}-\theta\right)+\frac{\beta_k}{2}\left(\theta^{\prime}-\theta\right)^{\top} W\left(\theta^{\prime}-\theta\right)- \frac{\beta_k}{2} \left(\theta^{\prime}-\theta\right)^{\top} W\left(\theta^{\prime}-\theta\right) - \frac{1}{2\alpha}||\theta^{\prime} - \theta||_p^p\right)}{\sum_x \exp \left(\frac{\beta_k}{2} \nabla U(\theta)^{\top}(x-\theta)+\frac{\beta_k}{2}(x-\theta)^{\top} W(x-\theta)- \frac{\beta_k}{2}(x-\theta)^{\top} W(x-\theta) - \frac{1}{2\alpha}||\theta^{\prime} - \theta||_p^p\right)} \\
& =\frac{\exp \left(\frac{\beta_k}{2}\left(U\left(\theta^{\prime}\right)-U(\theta)\right)-\frac{\beta_k}{2}\left(\theta^{\prime}-\theta\right)^{\top} W\left(\theta^{\prime}-\theta\right) - \frac{1}{2\alpha}||\theta^{\prime} - \theta||_p^p\right)}{\sum_x \exp \left(\frac{\beta_k}{2}(U(x)-U(\theta))-\frac{\beta_k}{2}(x-\theta)^{\top} W(x-\theta) - \frac{1}{2\alpha}||\theta^{\prime} - \theta||_p^p\right)}.
\end{aligned}
\end{equation}
Debote by $Z_\alpha^{\beta_k}(\theta)=\sum_x \exp \left(\frac{\beta_k}{2}(U(x)-U(\theta))-\frac{\beta_k}{2}(x-\theta)^{\top} W(x-\theta) - \frac{1}{2\alpha}||\theta^{\prime} - \theta||_p^p\right)$, and $\pi_\alpha^{\beta_k}=\frac{Z_\alpha^{\beta_k}(\theta) \pi^{\beta_k}(\theta)}{\sum_x Z_\alpha^{\beta_k}(x) \pi^{\beta_k}(x)}$, now we will show that $q_\alpha^{\beta_k}$ is reversible w.r.t. $\pi_\alpha^{\beta_k}$. We have that
\begin{equation}\label{reverse}
\begin{aligned}
\pi_\alpha^{\beta_k}(\theta) q_\alpha^{\beta_k}\left(\theta^{\prime} \mid \theta\right) & =\frac{Z_\alpha^{\beta_k}(\theta) \pi^{\beta_k}(\theta)}{\sum_x Z_\alpha^{\beta_k}(x) \pi^{\beta_k}(x)} \frac{\exp \left(\frac{\beta_k}{2}\left(U\left(\theta^{\prime}\right)-U(\theta)\right)-\frac{\beta_k}{2}\left(\theta^{\prime}-\theta\right)^{\top} W\left(\theta^{\prime}-\theta\right)- \frac{1}{2\alpha}||\theta^{\prime} - \theta||_p^p\right)}{Z_\alpha^{\beta_k}(\theta)} \\
& =\frac{\exp \left(\frac{\beta_k}{2}\left(U\left(\theta^{\prime}\right)+U(\theta)\right)-\frac{\beta_k}{2}\left(\theta^{\prime}-\theta\right)^{\top} W\left(\theta^{\prime}-\theta\right) - \frac{1}{2\alpha}||\theta^{\prime} - \theta||_p^p\right)}{Z^{\beta_k} \cdot \sum_x Z_\alpha^{\beta}(x) \pi^{\beta_k}(x)}.
\end{aligned}
\end{equation}
We note that \cref{reverse} is symmetric in $\theta$ and $\theta^{\prime}$. Therefore $q_\alpha^{\beta_k}$ is reversible and its stationary distribution is $\pi_\alpha^{\beta_k}$. Next, we will prove that $\pi_\alpha^{\beta_k}$ converges weakly to $\pi^{\beta_k}$ as $\alpha \rightarrow 0$. Notice that for any $\theta$,
$$
\begin{aligned}
Z_\alpha^{\beta_k}(\theta) & =\sum_x \exp \left(\frac{\beta_k}{2}(U(x)-U(\theta))-\frac{\beta_k}{2}(x-\theta)^{\top} W (x-\theta)-\frac{1}{2\alpha}\left\|\theta^{\prime} - \theta\right\|_p^p\right)\\&
\stackrel{\alpha \downarrow 0}=1
\end{aligned}
$$
By Scheffé's Lemma, we attain that $\pi_\alpha$ converges weakly to $\pi$.

\end{proof}


\begin{proof}[\textbf{Proof of \cref{thm:5.1}}]
    To explore the reversibility of our algorithm, we follow the proof of \citet{zhang2022langevin}. We first consider the transition probability of the first chain~(with temperature equals to one) $q_{\alpha}(\theta^{\prime} | \theta_i^{(1)})$. Considering the presence of the swap mechanism, we write $q_{\alpha}(\theta^{\prime}| \theta_i^{(1)})$ as follows,
\small{
\begin{equation}\label{q_first_chain}
\begin{aligned}
&q_{\alpha}\left( {\theta}^{\prime} \mid  {\theta}_i^{(1)}\right)\\&= \sum_{ {\theta}_i^{(2)}} \sum_{ {\theta}_{i+1}^{(2)}} \pi_{\alpha}^{\beta_2}\left( {\theta}_i^{(2)}\right) q_{\alpha, 2}\left( {\theta}_{i+1}^{(2)} \mid  {\theta}_i^{(2)}\right)\left[1-s_{1}\left( {\theta}^{\prime},  {\theta}_{i+1}^{(2)}\right)\right] q_{\alpha, 1}\left( {\theta}^{\prime} \mid  {\theta}_i^{(1)}\right) \\
& \quad +\!\sum_{ {\theta}_i^{(3)}}\sum_{ {\theta}_{i+1}^{(3)}}\sum_{ {\theta}_i^{(2)}} \sum_{ {\theta}_{i+1}^{(1)}} \pi_{\alpha}^{\beta_2}\!\left( {\theta}_i^{(2)}\right) q_{\alpha, 2}\left( {\theta}^{\prime} \mid  {\theta}_i^{(2)}\right) s_{1}\left( {\theta}_{i+1}^{(1)},  {\theta}^{\prime}\right) q_{\alpha, 1}\left( {\theta}_{i+1}^{(1)} \mid  {\theta}_i^{(1)}\right)\left(1 \!-\! s_2(\theta^{\prime}, \theta_{i+1}^{(3)})\right)q_{\alpha, 3}\left(\theta_{i+1}^{(3)}|\theta_i^{(3)}\right)\pi_{\alpha}^{\beta_3}(\theta_i^{(3)})\\
&\quad +\!\sum_{ {\theta}_i^{(3)}}\sum_{ {\theta}_{i}^{(2)}}\sum_{ {\theta}_{i+1}^{(2)}} \sum_{ {\theta}_{i+1}^{(1)}} \pi_{\alpha}^{\beta_2}\!\left( {\theta}_i^{(2)}\right) q_{\alpha, 2}\left( {\theta}_{i+1}^{(2)} \mid  {\theta}_i^{(2)}\right) s_{1}\left( {\theta}_{i+1}^{(1)},  {\theta}^{\prime}\right) q_{\alpha, 1}\left( {\theta}_{i+1}^{(1)} \mid  {\theta}_i^{(1)}\right)s_2\left(\theta_{i+1}^{(2)}, \theta^{\prime}\right)q_{\alpha, 3}\left(\theta^{\prime}|\theta_i^{(3)}\right)\pi_{\alpha}^{\beta_3}(\theta_i^{(3)}).
\end{aligned}
\end{equation}}
To demonstrate the reversibility, we multiply $\pi_\alpha^{\beta_1}(\theta)$ from both sides:
\begin{align*}
& \pi_\alpha^{\beta_1}\left( {\theta}_i^{(1)}\right) q_{\alpha}\left( {\theta}^{\prime} \mid  {\theta}_i^{(1)}\right) \\
& =\sum_{ {\theta}_i^{(2)}} \sum_{ {\theta}_{i+1}^{(2)}} \pi_\alpha^{\beta_2}\left( {\theta}_i^{(2)}\right) q_{\alpha, 2}\left( {\theta}_{i+1}^{(2)} \mid  {\theta}_i^{(2)}\right)\left[1-s_1\left( {\theta}^{\prime},  {\theta}_{i+1}^{(2)}\right)\right] \pi_\alpha^{\beta_1}\left( {\theta}_i^{(1)}\right) q_{\alpha, 1}\left( {\theta}^{\prime} \mid  {\theta}_i^{(1)}\right) \\
& \quad +\!\sum_{ {\theta}_i^{(3)}}\sum_{ {\theta}_{i+1}^{(3)}}\sum_{ {\theta}_i^{(2)}} \sum_{ {\theta}_{i+1}^{(1)}} \bigg(\pi_{\alpha}^{\beta_2}\!\left( {\theta}_i^{(2)}\right) q_{\alpha, 2}\left( {\theta}^{\prime} \mid  {\theta}_i^{(2)}\right) s_{1}\left( {\theta}_{i+1}^{(1)},  {\theta}^{\prime}\right) \pi_\alpha^{\beta_1}\left( {\theta}_i^{(1)}\right) q_{\alpha, 1}\left( {\theta}_{i+1}^{(1)} \mid  {\theta}_i^{(1)}\right)\\ & \quad \times \left(1 \!-\! s_2(\theta^{\prime}, \theta_{i+1}^{(3)})\right)q_{\alpha, 3}\left(\theta_{i+1}^{(3)}|\theta_i^{(3)}\right)\pi_{\alpha}^{\beta_3}(\theta_i^{(3)})\bigg)\\
&\quad +\!\sum_{ {\theta}_i^{(3)}}\sum_{ {\theta}_{i}^{(2)}}\sum_{ {\theta}_{i+1}^{(2)}} \sum_{ {\theta}_{i+1}^{(1)}} \pi_{\alpha}^{\beta_2}\!\left( {\theta}_i^{(2)}\right) q_{\alpha, 2}\left( {\theta}_{i+1}^{(2)} \mid  {\theta}_i^{(2)}\right) s_{1}\left( {\theta}_{i+1}^{(1)},  {\theta}^{\prime}\right) \pi_\alpha^{\beta_1}\left( {\theta}_i^{(1)}\right) q_{\alpha, 1}\left( {\theta}_{i+1}^{(1)} \mid  {\theta}_i^{(1)}\right) \\ & \quad \times s_2\left(\theta_{i+1}^{(2)}, \theta^{\prime}\right)q_{\alpha, 3}\left(\theta^{\prime}|\theta_i^{(3)}\right)\pi_{\alpha}^{\beta_3}(\theta_i^{(3)}),
\end{align*}
where $s_1$ and $s_2$ are defined in \cref{swap_function}. Note that, by using \cref{lm:1}, $\pi_\alpha^{\beta_1}\left(\theta_i^{(1)}\right) q_{\alpha, 1}\left(\cdot \mid \theta_i^{(1)}\right)$, $\pi_\alpha^{\beta_2}\left(\theta_i^{(2)}\right) q_{\alpha, 2}\left(\cdot \mid \theta_i^{(2)}\right)$, and $\pi_\alpha^{\beta_3}\left(\theta_i^{(3)}\right) q_{\alpha, 3}\left(\cdot \mid \theta_i^{(3)}\right)$ are symmetric, which indicates that $\pi_\alpha\left( {\theta}_i^{(1)}\right) q_{\alpha}\left( {\theta}^{\prime} \mid  {\theta}_i^{(1)}\right)$ is also symmetric. Therefore, we conclude that $q_{\alpha}\left( {\theta}^{\prime} \mid  {\theta}_i^{(1)}\right)$ in~\cref{q_first_chain} is reversible and the stationary distribution is $\pi_\alpha^{\beta_1}\left( {\theta}_i^{(1)}\right)$.

Next, to generalize the convergence result from log-quadratic
distributions to general distributions, we follow the assumption in~\citet{zhang2022langevin}, i.e., we assume that $\exists W \in$ $\mathbb{R}^{d \times d}, b \in \mathbb{R}, \epsilon \in \mathbb{R}^{+}$, such that
$$
\|\nabla U(\theta)-(2 W \theta+b)\|_1 \leq \epsilon, \forall \theta \in \Theta .
$$
Then, we consider the convergence rate with respect to step size in terms of the $L_1$ norm. Recall that $\pi^{\beta_1}$ is the target distribution, $\tilde{\pi}^{\beta_1}$ is the log-quadratic distribution that is close to $\pi^{\beta_1}$, $\pi_{\alpha}^{\beta_1}$ is the stationary distribution of our algorithm without MH step. $\tilde{\pi}_{\alpha}^{\beta_1}$ is the stationary distribution of our algorithm targeting $\tilde{\pi}^{\beta_1}$. By using triangle inequation, we obtain
$$
\left\|\pi_\alpha^{\beta_1}-\pi^{\beta_1}\right\|_1 \leq \underbrace{\left\|\pi_\alpha^{\beta_1} - \tilde{\pi}_{\alpha}^{\beta_1}\right\|_1}_{\mathfrak{T}_1} + \underbrace{\left\|\tilde{\pi}_{\alpha}^{\beta_1} - \tilde{\pi}^{\beta_1}\right\|_1}_{\mathfrak{T}_2} + \underbrace{\left\| \tilde{\pi}^{\beta_1}-\pi^{\beta_1}\right\|_1}_{\mathfrak{T}_3}.
$$

For $\mathfrak{T}_3$, let the energy function of $\tilde{\pi}^{\beta_1}$ be $\beta_1 V(\theta)=\beta_1(\theta^{\top} W \theta+b \theta)$. Since $\Theta$ is a discrete space, there exists a bounded subset $\Omega \in \mathbb{R}^d$ such that $\Theta$ is a subset of $\Omega$. By Poincaré inequality, we get
$$
|U(\theta)-V(\theta)| \leq C_1 \cdot\|\nabla U(\theta)-(W \theta+b)\|_1 \leq C_1 \epsilon, \quad \forall \theta \in \Theta,
$$
where the constant $C_1$ depends on $\Omega$.
Recall that $\pi^{\beta_1}(\theta)=\frac{\exp (\beta_1U(\theta))}{Z^{\beta_1}}$ and $\tilde{\pi}^{\beta_1}(\theta)=\frac{\exp (\beta_1V(\theta))}{\tilde{Z}^{\beta_1}}$, where $\tilde{Z}^{\beta_1}$ is the normalizing constant to make $\tilde{\pi}^{\beta_1}$ a distribution. Then
\begin{equation}\label{term_3_1}
\left\|\pi^{\beta_1}-\tilde{\pi}^{\beta_1}\right\|_1=\sum_{\theta \in \Theta}\left|\frac{\exp (\beta_1 U(\theta))}{Z^{\beta_1}}-\frac{\exp (\beta_1 V(\theta))}{\tilde{Z}^{\beta_1}}\right|.
\end{equation}
We notice that, for any $\theta$,
$$
\frac{\exp (\beta_1 U(\theta))}{\exp (\beta_1 V(\theta))}=\exp (\beta_1(U(\theta)-V(\theta))) \leq \exp (\beta_1 |U(\theta)-V(\theta)|) \leq \exp ( \beta_1 C_1 \epsilon)
$$
and similarly $\frac{\exp (\beta_1 V(\theta))}{\exp (\beta_1 U(\theta))} \leq \exp (\beta_1 C_1 \epsilon)$.
Therefore we have, for any $\theta$,
$$
\begin{aligned}
\left|\frac{\exp (\beta_1 U(\theta))}{Z^{\beta_1}}-\frac{\exp (\beta_1V(\theta))}{\tilde{Z}^{\beta_1}}\right| &\leq(\exp (\beta_1 C_1 \epsilon)-1) \max \left\{\frac{\exp (\beta_1 U(\theta))}{Z^{\beta_1}}, \frac{\exp (\beta_1 V(\theta))}{\tilde{Z}^{\beta_1}}\right\}\\ & \leq 
(\exp (\beta_1 C_1 \epsilon)-1) \left(\frac{\exp (\beta_1 U(\theta))}{Z^{\beta_1}} + \frac{\exp (\beta_1 V(\theta))}{\tilde{Z}^{\beta_1}}\right)
\end{aligned}
$$
Plugging the above in \cref{term_3_1}, we obtain
\begin{equation}\label{term_1}
\left\|\pi^{\beta_1}-\tilde{\pi}^{\beta_1}\right\|_1\leq 2(\exp (\beta_1 C_1\epsilon)-1).
\end{equation}
For $\mathfrak{T}_2 $, 
$$
\left\|\tilde{\pi}_\alpha^{\beta_1}-\tilde{\pi}^{\beta_1}\right\|_1=\sum_\theta\left|\frac{Z_\alpha^{\beta_1}(\theta) \tilde{\pi}^{\beta_1}(\theta)}{\sum_x Z_\alpha^{\beta_1}(x) \tilde{\pi}^{\beta_1}(x)}-\tilde{\pi}^{\beta_1}(\theta)\right| .
$$
For each absolute value term, we have
\begin{align*}
&\left|\frac{\tilde{Z}_\alpha^{\beta_1}(\theta) \tilde{\pi}^{\beta_1}(\theta)}{\sum_x \tilde{Z}_\alpha^{\beta_1}(x) \tilde{\pi}^{\beta_1}(x)}-\tilde{\pi}^{\beta_1}(\theta)\right|
\\& =\tilde{\pi}^{\beta_1}(\theta)\left|\frac{1+\sum_{x \neq \theta} \exp \left(\frac{\beta_1}{2} (V(x)- V(\theta))-\frac{\beta_1}{2}(x-\theta)^{\top}W(x-\theta) - \frac{1}{2\alpha}\left\|\theta^{\prime} - \theta\right\|_p^p\right)}{1+\sum_x \frac{1}{\tilde{Z}^{\beta_1}} \exp (\beta_1 V(x)) \sum_{y \neq x} \exp \left(\frac{\beta_1}{2} (V(y)- V(x))-\frac{\beta_1}{2}(y-x)^{\top} W(y-x) - \frac{1}{2\alpha}\left\|\theta^{\prime} - \theta\right\|_p^p\right)}-1\right|.
\end{align*}
By using the fact that $x^{\top} W x\geq \lambda_{\min }(W)\|x\|^2, \forall x$, it follows that,
$$
\begin{aligned}
&\frac{\beta_1}{2}(x-\theta)^{\top} W(x-\theta) \geq \frac{\beta_1\lambda_{\min }}{2}\|x-\theta\|^2.
\end{aligned}
$$
We also notice that $\min _{x \neq \theta}\|x-\theta\|=1$, thus when $\frac{\tilde{Z}_\alpha^{\beta_1}(\theta)}{\sum_x \tilde{Z}_\alpha^{\beta_1}(x) \tilde{\pi}^{\beta_1}(x)}-1>0$, we get
\begin{align*}
&\left|\frac{\tilde{Z}_\alpha^{\beta_1}(\theta) \tilde{\pi}^{\beta_1}(\theta)}{\sum_x \tilde{Z}_\alpha^{\beta_1}(x) \tilde{\pi}^{\beta_1}(x)}-\tilde{\pi}^{\beta_1}(\theta)\right| \\& =\tilde{\pi}^{\beta_1}(\theta)\left(\frac{1+\sum_{x \neq \theta} \exp \left(\frac{\beta_1}{2} (V(x)- V(\theta))-\frac{\beta_1}{2}(x-\theta)^{\top} W(x-\theta) -\frac{1}{2\alpha}\left\|\theta^{\prime} - \theta\right\|_p^p \right)}{1+\sum_y \frac{1}{\tilde{Z}^{\beta_1}} \exp (\beta_1 V(y)) \sum_{x \neq y} \exp \left(\frac{\beta_1}{2}( V(x) - V(y))-\frac{\beta_1}{2}(x-y)^{\top} W(x-y) - \frac{1}{2\alpha}\left\|\theta^{\prime} - \theta\right\|_p^p\right)}-1\right) \\
& \leq \tilde{\pi}^{\beta_1}(\theta)\left(1+\sum_{x \neq \theta} \exp \left(\frac{\beta_1}{2}\left(V(x)- V(\theta)\right)-\frac{\beta_1\lambda_{\min}}{2}\left\|x-\theta\right\|_2^2 - \frac{1}{2\alpha}\left\|x-\theta\right\|_p^p\right)-1\right) \\
%& \leq \pi^{\beta_1}(\theta)\left(1+\exp \left(-\frac{1+\alpha \beta_1\lambda_{\min }}{2 \alpha}\right) \sum_{x \neq \theta} \exp \left(\frac{\beta_1}{2}( V(x)- V(\theta))\right)-1\right) \\
& \leq\tilde{\pi}^{\beta_1}(\theta)\left(\sum_{x \neq \theta} \exp \left(\frac{\beta_1}{2}(V(x)- V(\theta))\right)\right) \cdot \exp \left(-\frac{1+\alpha\beta_1 \lambda_{\min }}{2 \alpha}\right) \\
& =\tilde{\pi}^{\beta_1}(\theta)\left(\sum_{x} \exp \left(\frac{\beta_1}{2}V(x)\right)\right)\exp(-\beta_1 V(\theta)) \cdot \exp \left(-\frac{1+\alpha\beta_1 \lambda_{\min }}{2 \alpha}\right) \\
& = \left(\sum_{x} \exp \left(\frac{\beta_1}{2}V(x)\right)/ \tilde{Z}^{\beta_1} \right) \cdot \exp \left(-\frac{1+\alpha\beta_1 \lambda_{\min }}{2 \alpha}\right) .
\end{align*}
Then, we obtain,
$$
\sum_\theta \left|\frac{\tilde{Z}_\alpha^{\beta_1}(\theta) \tilde{\pi}^{\beta_1}(\theta)}{\sum_x \tilde{Z}_\alpha^{\beta_1}(x) \tilde{\pi}(x)}-\tilde{\pi}^{\beta_1}(\theta)\right| \leq \left(\sum_\theta 1\right) \left(\sum_{x} \exp \left(\frac{\beta_1}{2}V(x)\right)/ \tilde{Z}^{\beta_1} \right) \exp \left(-\frac{1+\alpha\beta_1 \lambda_{\min }}{2 \alpha}\right)
$$
Similarly, when $\frac{Z_\alpha^{\beta_1}(\theta)}{\sum_x Z_\alpha^{\beta_1}(x) \pi^{\beta_1}(x)}-1<0$, we have,
\begin{align*}
&\left|\frac{\tilde{Z}_\alpha^{\beta_1}(\theta) \tilde{\pi}^{\beta_1}(\theta)}{\sum_x \tilde{Z}_\alpha^{\beta_1}(x) \tilde{\pi}^{\beta_1}(x)}-\tilde{\pi}^{\beta_1}(\theta)\right| \\& =\tilde{\pi}^{\beta_1}(\theta)\left(1-\frac{1+\sum_{x \neq \theta} \exp \left(\frac{\beta_1}{2} V(x)-\frac{\beta_1}{2} V(\theta)-\frac{\beta_1}{2}(x-\theta)^{\top} W(x-\theta) - \frac{1}{2\alpha}\left\|\theta^{\prime} - \theta\right\|_p^p\right)}{1+\sum_y \frac{1}{\tilde{Z}} \exp (V(y)) \sum_{x \neq y} \exp \left(\frac{\beta_1}{2} V(x)-\frac{\beta_1}{2} V(y)-\frac{\beta_1}{2}(x-y)^{\top} W(x-y) - \frac{1}{2\alpha}\left\|\theta^{\prime} - \theta\right\|_p^p\right)}\right) \\
& \leq \tilde{\pi}^{\beta_1}(\theta)\left(1-\frac{1}{1+\sum_y \frac{1}{\tilde{Z}^{\beta_1}} \exp (\beta_1 V(y)) \sum_{x \neq y} \exp \left(\frac{\beta_1}{2} V(x)-\frac{\beta_1}{2} V(y)-\frac{1+\alpha \beta_1 \lambda_{\min }}{2 \alpha}\right)}\right)\\
& =\tilde{\pi}^{\beta_1}(\theta)\left(\frac{\sum_y \frac{1}{\tilde{Z}^{\beta_1}} \exp (\beta_1 V(y)) \sum_{x \neq y} \exp \left(\frac{\beta_1}{2} V(x)-\frac{\beta_1}{2} V(y)-\frac{1+\alpha \beta_1\lambda_{\min }}{2 \alpha}\right)}{1+\sum_y \frac{1}{\tilde{Z}^{\beta_1}} \exp (\beta_1 V(y)) \sum_{x \neq y} \exp \left(\frac{\beta_1}{2} V(x)-\frac{\beta_1}{2} V(y)-\frac{1+\alpha \beta_1\lambda_{\min }}{2 \alpha}\right)}\right)\\
& \leq \tilde{\pi}^{\beta_1}(\theta)\left(\sum_y \frac{1}{\tilde{Z}^{\beta_1}} \exp (\beta_1 V(y)) \sum_{x} \exp \left(\frac{\beta_1}{2} V(x)-\frac{\beta_1}{2} V(y)\right)\right) \exp \left(-\frac{1+\alpha \beta_1\lambda_{\min }}{2 \alpha}\right) \\
& \leq \tilde{\pi}^{\beta_1}(\theta)\sum_{x} \exp \left(\frac{\beta_1}{2} V(x)\right)\left(\sum_y \frac{1}{\tilde{Z}^{\beta_1}} \exp \left(\beta_1 V(y) - \frac{\beta_1}{2} V(y)\right)\right)  \exp \left(-\frac{1+\alpha \beta_1\lambda_{\min }}{2 \alpha}\right) \\
&= \tilde{\pi}^{\beta_1}(\theta)\left(\sum_{x} \exp \left(\frac{\beta_1}{2} V(x)\right)\right)^2 \exp \left(-\frac{1+\alpha \beta_1\lambda_{\min }}{2 \alpha}\right) / \tilde{Z}^{\beta_1}.
\end{align*}
Then, we obtain,
$$
\sum_\theta \left|\frac{\tilde{Z}_\alpha^{\beta_1}(\theta) \tilde{\pi}^{\beta_1}(\theta)}{\sum_x \tilde{Z}_\alpha^{\beta_1}(x) \tilde{\pi}(x)}-\tilde{\pi}^{\beta_1}(\theta)\right| \leq \frac{\left(\sum_{x} \exp \left(\frac{\beta_1}{2} V(x)\right)\right)^2}{\tilde{Z}^{\beta_1}} \exp \left(-\frac{1+\alpha \beta_1\lambda_{\min }}{2 \alpha}\right).
$$
Therefore, the difference between $\pi_\alpha$ and $\pi$ can be bounded as follows
\begin{equation}\label{term_2}
\left\|\tilde{\pi}_\alpha^{\beta_1}-\tilde{\pi}^{\beta_1}\right\|_1 \leq  \frac{\left(\sum_{x} \exp \left(\frac{\beta_1}{2}V(x)\right)\right)^2}{\tilde{Z}^{\beta_1}} \exp \left(-\frac{1+\alpha\beta_1 \lambda_{\min }}{2 \alpha}\right).
\end{equation}
For $\mathfrak{T}_1 $, let $P_\alpha, \tilde{P}_\alpha$ be the transition matrices of PTDLP without MH targeting $\pi^{\beta_1}$ and $\tilde{\pi}^{\beta_1}$. We consider the difference between these two matrices.
$$
\left\|P_\alpha-\tilde{P}_\alpha\right\|_{\infty}=\max _\theta \sum_{\theta^{\prime}}\left|\frac{\exp \left(\frac{1}{2} \nabla U(\theta)^{\top}\left(\theta^{\prime}-\theta\right)-\frac{1}{2 \alpha}\left\|\theta^{\prime}-\theta\right\|_p^p\right)}{Z_\alpha^{\beta}(\theta)}-\frac{\exp \left(\frac{1}{2} \nabla V(\theta)^{\top}\left(\theta^{\prime}-\theta\right)-\frac{1}{2 \alpha}\left\|\theta^{\prime}-\theta\right\|_p^p\right)}{\tilde{Z}_\alpha^{\beta}(\theta)}\right|,
$$
where
$$
Z_\alpha^{\beta}(\theta)=\sum_x \exp \left(\frac{1}{2} \nabla U(\theta)^{\top}(x-\theta)-\frac{1}{2 \alpha}\|x-\theta\|_p^p\right), \tilde{Z}_\alpha^{\beta}(\theta)=\sum_x \exp \left(\frac{1}{2} \nabla V(\theta)^{\top}(x-\theta)-\frac{1}{2 \alpha}\|x-\theta\|_p^p\right).
$$
We denote $\mathcal{D}=\max _{\theta, \theta^{\prime} \in \Theta}\left\|\theta^{\prime}-\theta\right\|_{\infty}$. By the assumption $\|\nabla U(\theta)-\nabla V(\theta)\|_1 \leq \epsilon$, we have
$$
\begin{aligned}
& \left|\frac{\exp \left(\frac{\beta_1}{2} \nabla U(\theta)^{\top}\left(\theta^{\prime}-\theta\right)-\frac{1}{2 \alpha}\left\|\theta^{\prime}-\theta\right\|_p^p\right)}{Z_\alpha^{\beta_1}}-\frac{\exp \left(\frac{\beta_1}{2} \nabla V(\theta)^{\top}\left(\theta^{\prime}-\theta\right)-\frac{1}{2 \alpha}\left\|\theta^{\prime}-\theta\right\|_p^p\right)}{\tilde{Z}_\alpha^{\beta_1}(\theta)}\right| \\
& \leq(\exp (\mathcal{D} \epsilon)-1) \\
& \quad \times \max \left\{\frac{\exp \left(\frac{1}{2} \nabla U(\theta)^{\top}\left(\theta^{\prime}-\theta\right)-\frac{1}{2 \alpha}\left\|\theta^{\prime}-\theta\right\|_p^p\right)}{Z_\alpha^{\beta_1}(\theta)}, \frac{\exp \left(\frac{1}{2} \nabla V(\theta)^{\top}\left(\theta^{\prime}-\theta\right)-\frac{1}{2 \alpha}\left\|\theta^{\prime}-\theta\right\|_p^p\right)}{\tilde{Z}_\alpha^{\beta_1}(\theta)}\right\} \\
& \leq(\exp (\mathcal{D} \epsilon)-1) \\
& \quad \times\left(\frac{\exp \left(\frac{1}{2} \nabla U(\theta)^{\top}\left(\theta^{\prime}-\theta\right)-\frac{1}{2 \alpha}\left\|\theta^{\prime}-\theta\right\|_p^p\right)}{Z_\alpha^{\beta_1}(\theta)}+\frac{\exp \left(\frac{1}{2} \nabla V(\theta)^{\top}\left(\theta^{\prime}-\theta\right)-\frac{1}{2 \alpha}\left\|\theta^{\prime}-\theta\right\|_p^p\right)}{\tilde{Z}_\alpha^{\beta_1}(\theta)}\right).
\end{aligned}
$$
Then, we have
$$
\|P-\tilde{P}\|_{\infty} \leq 2(\exp (\mathcal{D} \epsilon)-1)
$$
By using the perturbation bound in~\citet{schweitzer1968perturbation}, we obtain
\begin{equation}\label{term_3}
\left\|\pi_\alpha^{\beta_1}-\tilde{\pi}_\alpha^{\beta_1}\right\|_1 \leq C_2 \cdot\left\|P_\alpha-\tilde{P}_\alpha\right\|_{\infty}=2 C_2(\exp (\mathcal{D} \epsilon)-1)
\end{equation}
where $C_2$ is a constant depending on $\tilde{\pi}^{\beta_1}$ and $\alpha$. Combining~\cref{term_1,term_2,term_3}, we have
$$
\begin{aligned}
&\left\|\pi_\alpha^{\beta_1}-\pi^{\beta_1}\right\|_1 \\&\leq\left\|\pi_\alpha^{\beta_1}-\tilde{\pi}_\alpha^{\beta_1}\right\|_1+\left\|\tilde{\pi}_\alpha^{\beta_1}-\tilde{\pi}^{\beta_1}\right\|_{1}+\left\|\tilde{\pi}^{\beta_1}-\pi^{\beta_1}\right\|_1\\&
\leq 2 C_2(\exp (\mathcal{D} \epsilon)-1) +  2(\exp (\beta_1 C_1\epsilon)-1) + \frac{\left(\sum_{x} \exp \left(\frac{\beta_1}{2}V(x)\right)\right)^2}{\tilde{Z}^{\beta_1}} \exp \left(-\frac{1+\alpha\beta_1 \lambda_{\min }}{2 \alpha}\right)\\ & 
\leq Z_1\left(\exp\left(Z_2\epsilon\right)-1\right) + Z_3 \exp \left(-\frac{1+\alpha\beta_1 \lambda_{\min }}{2 \alpha}\right),
\end{aligned}
$$
where we denote by $Z_1 := 2\left(C_2 + 1\right)$, $Z_2:=\mathcal{D}+\beta_1 C_1$, and $Z_3:=\left(\sum_{x} \exp \left(\frac{\beta_1}{2}V(x)\right)\right)^2 / \tilde{Z}^{\beta_1}$.
\end{proof}

\begin{proof}[\textbf{Proof of \cref{thm:5.2}}]
Recall~\cref{q_first_chain}, we have
\small{
\begin{equation}\label{sum_q_alpha}
\begin{aligned}
&\sum_{\theta^{\prime}\neq \theta_i^{(1)}}q_{\alpha}\left( {\theta}^{\prime} \mid  {\theta}_i^{(1)}\right)
\\&= \sum_{\theta^{\prime}\neq \theta_i^{(1)}}\sum_{ {\theta}_i^{(2)}} \sum_{ {\theta}_{i+1}^{(2)}} \pi_{\alpha}^{\beta_2}\left( {\theta}_i^{(2)}\right) q_{\alpha, 2}\left( {\theta}_{i+1}^{(2)} \mid  {\theta}_i^{(2)}\right)\left[1-s_{1}\left( {\theta}^{\prime},  {\theta}_{i+1}^{(2)}\right)\right] q_{\alpha, 1}\left( {\theta}^{\prime} \mid  {\theta}_i^{(1)}\right) \\
& \quad +\!\sum_{\theta^{\prime}\neq \theta_i^{(1)}}\!\sum_{ {\theta}_i^{(3)}}\sum_{ {\theta}_{i+1}^{(3)}}\sum_{ {\theta}_i^{(2)}} \sum_{ {\theta}_{i+1}^{(1)}} \pi_{\alpha}^{\beta_2}\!\left( {\theta}_i^{(2)}\right) q_{\alpha, 2}\left( {\theta}^{\prime} \!\mid\!  {\theta}_i^{(2)}\right) s_{1}\left( {\theta}_{i+1}^{(1)},  {\theta}^{\prime}\right) q_{\alpha, 1}\left( {\theta}_{i+1}^{(1)} \!\mid\!  {\theta}_i^{(1)}\right)\left(\!1 \!-\! s_2(\theta^{\prime}, \theta_{i+1}^{(3)})\!\right)q_{\alpha, 3}\left(\theta_{i+1}^{(3)}|\theta_i^{(3)}\right)\pi_{\alpha}^{\beta_3}(\theta_i^{(3)})\\
&\quad +\!\sum_{\theta^{\prime}\neq \theta_i^{(1)}}\sum_{ {\theta}_i^{(3)}}\sum_{ {\theta}_{i}^{(2)}}\sum_{ {\theta}_{i+1}^{(2)}} \sum_{ {\theta}_{i+1}^{(1)}} \pi_{\alpha}^{\beta_2}\!\left( {\theta}_i^{(2)}\right) q_{\alpha, 2}\left( {\theta}_{i+1}^{(2)} \mid  {\theta}_i^{(2)}\right) s_{1}\left( {\theta}_{i+1}^{(1)},  {\theta}^{\prime}\right) q_{\alpha, 1}\left( {\theta}_{i+1}^{(1)} \mid  {\theta}_i^{(1)}\right)s_2\left(\theta_{i+1}^{(2)}, \theta^{\prime}\right)q_{\alpha, 3}\left(\theta^{\prime}|\theta_i^{(3)}\right)\pi_{\alpha}^{\beta_3}(\theta_i^{(3)})\\
&\leq \sum_{\theta^{\prime}\neq \theta_i^{(1)}}\left(q_{\alpha, 1}\left( {\theta}^{\prime} \mid  {\theta}_i^{(1)}\right) + \sum_{ {\theta}_i^{(2)}} \pi_{\alpha}^{\beta_2}\!\left( {\theta}_i^{(2)}\right) q_{\alpha, 2}\left( {\theta}^{\prime} \mid  {\theta}_i^{(2)}\right) + \sum_{ {\theta}_i^{(3)}}  \pi_{\alpha}^{\beta_3}(\theta_i^{(3)}) q_{\alpha, 3}\left(\theta^{\prime}|\theta_i^{(3)}\right)\right)\\
&\leq \sum_{\theta^{\prime}\neq \theta_i^{(1)}}q_{\alpha, 1}\left( {\theta}^{\prime} \mid  {\theta}_i^{(1)}\right) + 2
\end{aligned}
\end{equation}}
By using~\cref{log_quatratic} and letting $\beta_1 = 1$, we have
\begin{equation}\label{q_1_leq}
\begin{aligned}
q_{\alpha, 1}\left(\theta^{\prime} \mid \theta\right)
& =\frac{\exp \left(\frac{1}{2}\left(U\left(\theta^{\prime}\right)-U(\theta)\right)-\frac{1}{2}\left(\theta^{\prime}-\theta\right)^{\top} W\left(\theta^{\prime}-\theta\right) - \frac{1}{2\alpha}||\theta^{\prime} - \theta||_p^p\right)}{\sum_x \exp \left(\frac{1}{2}(U(x)-U(\theta))-\frac{1}{2}(x-\theta)^{\top} W(x-\theta) - \frac{1}{2\alpha}||\theta^{\prime} - \theta||_p^p\right)}\\
&= \frac{\exp \left(\frac{1}{2}\left(U\left(\theta^{\prime}\right)-U(\theta)\right)-\frac{1}{2}\left(\theta^{\prime}-\theta\right)^{\top} W\left(\theta^{\prime}-\theta\right) - \frac{1}{2\alpha}||\theta^{\prime} - \theta||_p^p\right)}{1 + \sum_{x \neq \theta} \exp \left(\frac{1}{2}(U(x)-U(\theta))-\frac{1}{2}(x-\theta)^{\top} W(x-\theta) - \frac{1}{2\alpha}||\theta^{\prime} - \theta||_p^p\right)}\\
&\leq \exp \left\{\frac{1}{2}\left(U\left(\theta^{\prime}\right)-U(\theta)\right)-\frac{1}{2}\left(\theta^{\prime}-\theta\right)^{\top} W\left(\theta^{\prime}-\theta\right) - \frac{1}{2\alpha}||\theta^{\prime} - \theta||_p^p\right\}.
\end{aligned}
\end{equation}
By substituting~\cref{q_1_leq} into~\cref{sum_q_alpha} and the fact that $\frac{{x}^{\top} W {x}}{{x}^{\top} {x}} \geq \lambda_{\min }(W)$ for any $x\neq 0$, one writes
$$
\begin{aligned}
\sum_{\theta^{\prime}\neq \theta_i^{(1)}}q_{\alpha}\left( {\theta}^{\prime} \mid  {\theta}_i^{(1)}\right) &\leq \sum_{\theta^{\prime}\neq \theta_i^{(1)}}\exp \left\{\frac{1}{2}\left(U\left(\theta^{\prime}\right)-U(\theta_i^{(1)})\right)-\frac{1}{2}\left(\theta^{\prime}-\theta_i^{(1)}\right)^{\top} W\left(\theta^{\prime}-\theta_i^{(1)}\right) - \frac{1}{2\alpha}||\theta^{\prime} - \theta_i^{(1)}||_p^p\right\} + 2\\
&\leq 2 \sum_{\theta^{\prime}}\exp \left\{\frac{1}{2}\left(U\left(\theta^{\prime}\right)-U(\theta_i^{(1)})\right)-\frac{1}{2}\left(\theta^{\prime}-\theta_i^{(1)}\right)^{\top} W\left(\theta^{\prime}-\theta_i^{(1)}\right) - \frac{1}{2\alpha}||\theta^{\prime} - \theta_i^{(1)}||_p^p\right\}\\
&\leq 2 \sum_{\theta^{\prime}}\exp \left\{\frac{1}{2}\left(U\left(\theta^{\prime}\right)-U(\theta_i^{(1)})\right)-\frac{1}{2}\lambda_{\min}(W)\mathcal{D}^2 - \frac{1}{2\alpha}\mathcal{D}^p\right\}\\
&\leq 2 \exp \left\{-\frac{1}{2}\lambda_{\min}(W)\mathcal{D}^2 - \frac{1}{2\alpha}\mathcal{D}^p\right\}\sum_{\theta^{\prime}}\exp \left\{\frac{1}{2}\left(U\left(\theta^{\prime}\right)-U(\theta_i^{(1)})\right)\right\}\\
&\leq  2 Z \exp \left\{-\frac{1}{2}\lambda_{\min}(W)\mathcal{D}^2 - \frac{1}{2\alpha}\mathcal{D}^p\right\},
\end{aligned}
$$
where $Z$ is the normalizing constant of the target distribution $\pi$. Note that $q_\alpha$ is reversible and the transition matrix of a reversible Markov chain has only real eigenvalues. By using~\citet[Theorem 6.1.1]{horn2012matrix}, there at least exists one $\theta \in \Theta$ such that
$$
\left|\lambda_2-q_\alpha(\theta \mid \theta)\right| \leq Z \exp \left(-\frac{1}{2} \lambda_{\min }(W) \mathcal{D}^2-\frac{1}{2 \alpha} \mathcal{D}^p\right),
$$
where $\lambda_2$ is the second largest eigenvalue of the transition matrix. Then we consider the spectral gap~\citep[Chaper 12]{levin2017markov},
\begin{equation}\label{lambda_2}
\begin{aligned}
1-\lambda_2 & \leq\left|1-q_\alpha(\theta \mid \theta)\right|+\left|q_\alpha(\theta \mid\theta)-\lambda_2\right| \\
& \leq\left|1-q_\alpha(\theta \mid\theta)\right| + 2Z \exp \left(-\frac{1}{2} \lambda_{\min }(A) d_2-\frac{1}{2 \alpha} d_p\right) \\
& =\sum_{\theta^{\prime} \neq \theta} q_\alpha(\theta^{\prime} \mid \theta)+2Z \exp \left(-\frac{1}{2} \lambda_{\min}(W) \mathcal{D}^2-\frac{1}{2 \alpha} \mathcal{D}^p\right) \\
& \leq 4 \cdot Z \exp \left(-\frac{1}{2} \lambda_{\min }(W) \mathcal{D}^2-\frac{1}{2 \alpha} \mathcal{D}^p\right) .
\end{aligned}
\end{equation}
Denote by $t_{\operatorname{mix}}(\varepsilon):=\min \{t: d(t) \leq \varepsilon\}$ with $d(t):=\max _{\theta \in \Theta}\left\|P_\alpha(\theta, \cdot)-\pi_\alpha\right\|_{\mathrm{TV}}$. By using~\citet[Theorem 12.5]{levin2017markov} and~\cref{lambda_2}, we obtain
$$
\begin{aligned}
t_{\operatorname{mix}}(\varepsilon) &\geq\left(\frac{1}{1-\lambda_2}-1\right) \log \left(\frac{1}{2 \varepsilon}\right)\\
&\geq \left(\frac{1}{4 \cdot Z}\exp \left(\frac{1}{2} \lambda_{\min }(W) \mathcal{D}^2+\frac{1}{2 \alpha} \mathcal{D}^p\right)-1\right) \log \left(\frac{1}{2 \varepsilon}\right).
\end{aligned}
$$
\end{proof}


\section{Proofs in \cref{sec_5_2}}
We define the problem setting in more detail. We have a target that is of the form
$$
\pi(\theta)=\frac{1}{Z} \exp (U(\theta)).
$$
We consider the proposal kernel as
$$
q\left(\theta^{\prime} \mid \theta\right) \propto \exp \left\{\beta \nabla U(\theta)^\top\left(\theta^{\prime}-\theta\right)-\frac{1}{2 \alpha}\left\|\theta^{\prime}-\theta\right\|_p^p\right\}
$$
and consider the transition kernel as
$$
p\left(\theta^{\prime} \mid \theta\right)=\left(\frac{\pi\left(\theta^{\prime}\right) q\left(\theta \mid \theta^{\prime}\right)}{\pi(\theta) q\left(\theta^{\prime} \mid \theta\right)} \wedge 1\right) q\left(\theta^{\prime} \mid \theta\right)+(1-L(\theta)) \delta_\theta\left(\theta^{\prime}\right),
$$
where
$$
L(\theta)=\sum_{\theta^{\prime} \in \Theta}\min\left\{\frac{\pi\left(\theta^{\prime}\right) q\left(\theta \mid \theta^{\prime}\right)}{\pi(\theta) q\left(\theta^{\prime} \mid \theta\right)}, 1\right\} q\left(\theta^{\prime} \mid \theta\right)
$$
is the total rejection probability from $\theta$. Finally, recall that the total variation distance between two probability measures $\mu$ and $\nu$, defined on some space $\Theta \subset \mathbb{R}^d$ is
$$
\|\mu-\nu\|_{T V}=\sup _{A \in \mathcal{B}(\Theta)}|\mu(A)-\nu(A)|,
$$
where $\mathcal{B}(\Theta)$ is the set of all measurable sets in $\Theta$.

\begin{lemma}\label{lm:3}
Let \cref{asm_2,asm_3} hold. Then we have, for any $\theta$, $\theta^{\prime} \in \Theta$,
$$
p(\theta^{\prime}\mid\theta)\geq\epsilon_{\beta,\alpha}\,\frac{\exp\left\{\beta U (\theta^{\prime})\right\}}{\sum_{\theta^{\prime}\in\Theta}\exp\left\{\beta U( \theta^{\prime})\right\}},
$$
where
$$
\epsilon_{\beta,\alpha}=\exp\left\{-\beta\left(M-\frac{m}{2}\right)\,\tilde{\mathcal{D}}(\Theta)^{2}-\beta\|\nabla U(a)\|\,\tilde{\mathcal{D}}(\Theta) - \frac{1}{\alpha}\tilde{\mathcal{D}}(\Theta)^{p} \right\}
$$
with $a\in\arg\min_{\theta\in\Theta}\|\nabla U(\theta)\|$.

\end{lemma}

%\subsection{Efficiency Analysis}
%Asyptotic variance, spectral gap.
\begin{proof}
We start by noting that
\begin{equation}\label{q_w_MH}
q(\theta^{\prime}|\theta)=\frac{\exp\left\{\beta\nabla U(\theta )^{\top}\left(\theta^{\prime}-\theta\right)-\tfrac{1}{2\alpha}\|\theta^{\prime}- \theta\|_p^{p}\right\}}{\sum_{\theta^{\prime}\in\Theta}\exp\left\{\beta\nabla U(\theta)^{\top}\left(\theta^{\prime}-\theta\right)-\tfrac{1}{2\alpha}\|\theta^{\prime}-\theta\|_p^{p}\right\}}.
\end{equation}
Consider the term,
\begin{equation}\label{q_w_MH_term1}
\beta\,\nabla U(\theta)^{\top}\left(\theta^{\prime}-\theta\right)=\beta\,\left(-U (\theta)+U(\theta^{\prime})\right)-\frac{\beta}{2}(\theta-\theta^{\prime})^{\top}\left(\int_{0}^{1}\nabla^{2}U((1-s)\theta+s\theta^{\prime})\,ds\right)(\theta-\theta ^{\prime}).
\end{equation}
Plugging \cref{q_w_MH_term1} into \cref{q_w_MH} yields the numerator of \(q(\theta,\theta^{\prime})\)
$$
\begin{aligned}
&\beta\nabla U(\theta)^{\top}\left(\theta^{\prime}-\theta\right) -\frac{1}{2\alpha}\|\theta^{\prime}-\theta\|_p^{p}\\& =\beta\,\left(-U( \theta)+U(\theta^{\prime})\right) - \frac{\beta}{2}(\theta-\theta^{\prime})^{\top}\left(\int_{0}^{1} \nabla^{2}U((1-s)\theta+s\theta^{\prime})\,ds\right)(\theta-\theta^{\prime}) -\frac{1}{2\alpha}\|\theta^{\prime}-\theta\|_p^{p}.
\end{aligned}
$$
By using \cref{asm_2}, we have
\[
\beta\int_{0}^{1}\nabla^{2}U((1-s)\theta+s\theta^{\prime})\,ds)( \theta-\theta^{\prime}) \geq -\beta M.
\]
Since \(\alpha<1/\beta M\), the matrix \(\left(\frac{1}{\alpha}-\beta M\right)\)\(I\) is positive definite. We note that
\begin{equation}\label{p_ineq}
\begin{aligned}
p(\theta^{\prime}|\theta) \geq\left(\frac{\pi(\theta^{\prime})q(\theta| \theta^{\prime})}{\pi(\theta)q(\theta^{\prime}|\theta)}\wedge 1 \right)q(\theta^{\prime}|\theta) =\left(\frac{Z_{\alpha,\beta}(\theta)}{Z_{\alpha,\beta}(\theta^{ \prime})}\wedge 1\right)q(\theta^{\prime}|\theta),
\end{aligned}
\end{equation}
where
$$
\begin{aligned}
&Z_{\alpha,\beta}(\theta) \\&=\sum_{x\in\Theta}\exp\left\{-\beta\,\left(U(\theta)-U(x)\right)- \frac{1}{2}(\theta-x)^{\top}(\beta\int_{0}^{1}\nabla^{2}U((1-s)\theta+sx)\,ds)( \theta-x))(\theta-x) -\frac{1}{2 \alpha}\left\|\theta^{\prime}-\theta\right\|_p^p \right\}.  
\end{aligned}
$$
%This can be seen as
%$$
%\begin{aligned}
%&\pi(\theta)Q_{\alpha,\beta}(\theta^{\prime}|\theta)\\&=\frac{1}{Z\,Z_{\alpha,\beta }(\theta)}\exp\left\{\left((1-\beta)U(\theta)+\beta U(\theta^{\prime})\right)-(\theta^{ \prime}-\theta)^{\top}\left(\frac{1}{2\alpha}I+\frac{\beta}{2}\int_{0}^{1}\nabla^{ 2}U((1-s)\theta+s\theta^{\prime})\,ds\right)(\theta^{\prime}-\theta)\right\}.    
%\end{aligned}
%$$
We define \(conv(\Theta)\) as the convex hull of the set \(\Theta\). Since \cref{asm_2} holds in this setting, we have an $m>0$ such that for any $\theta\in conv(\Theta)$, 
$-\nabla^{2}U(\theta)\geq m I$. From this, one notes that
$$
\exp\left(-\beta U(\theta)+\frac{1}{2}\beta m\tilde{\mathcal{D}}(\Theta)^{2} - \frac{1}{2\alpha}\tilde{\mathcal{D}}(\Theta)^{p}\right)\leq \frac{Z_{ \alpha,\beta}(\theta)}{\sum_{x\in\Theta}\exp\left(\beta U(x)\right)}\leq\exp\left(-\beta U(\theta)\right).
$$
where the right-hand side follows from the fact that \(\alpha<1/(\beta M)\). Therefore,
\begin{equation}\label{Z_ineq}
\frac{Z_{\alpha,\beta}(\theta)}{Z_{\alpha,\beta}(\theta^{\prime})}\geq\frac{ \exp\left\{\beta\left(-U(\theta)+U(\theta^{\prime})\right)\right\}}{\exp\left \{\frac{1}{2}\left(\frac{1}{\alpha}\tilde{\mathcal{D}}(\Theta)^{p}-\beta m\tilde{\mathcal{D}}(\Theta)^{2}\right)\right\}}.
\end{equation}
We also note that
\begin{equation}\label{Q_ineq}
\begin{aligned}
q(\theta^{\prime}|\theta) &=\frac{\exp\left\{\beta\left(-U(\theta)+U(\theta^{\prime})\right )-(\theta-\theta^{\prime})^{\top}\left(\frac{\beta}{2}\int_{0}^ {1}\nabla^{2}U((1-s)\theta+s\theta^{\prime})\right)(\theta-\theta^{\prime})- \frac{1}{2\alpha}\left\|\theta^{\prime}-\theta\right\|_p^p \right\}}{\sum_{\theta^{\prime}\in\Theta}\exp\left\{\beta\left(-U(\theta)+U( \theta^{\prime})\right)-(\theta-\theta^{\prime})^{\top}\left( \frac{\beta}{2}\int_{0}^{1}\nabla^{2}U((1-s)\theta+s\theta^{\prime})\right)( \theta-\theta^{\prime}) - \frac{1}{2\alpha}\left\|\theta^{\prime}-\theta\right\|_p^p\right\}}
\\&\geq\frac{\exp\left\{\beta\left(\nabla U(\theta),\theta^{\prime}- \theta\right)-\frac{1}{2\alpha}\|\theta-\theta^{\prime}\|_p^{p}\right\}}{\sum_{ \theta^{\prime}\in\Theta}\exp\left\{\beta\left(-U(\theta)+U(\theta^{\prime}) \right)\right\}}.
\end{aligned}
\end{equation}
We also note that
\begin{equation}\label{Q_ineq_part}
\begin{aligned}
-\beta\left(\nabla U(\theta),\theta^{\prime}-\theta\right)+\frac{1}{2 \alpha}\|\theta-\theta^{\prime}\|_p^{p} &=\beta\left(-\nabla U(\theta)+\nabla U(a),\theta^{\prime}-\theta \right)+\beta\left(-\nabla U(a),\theta^{\prime}-\theta\right)+\frac{1}{2\alpha }\|\theta-\theta^{\prime}\|_p^{p}\\ &
\leq\beta\left(-\nabla U(\theta)+\nabla U(a),\theta^{\prime}-\theta \right)+\beta\left(-\nabla U(a),\theta^{\prime}-\theta\right)+\frac{1}{2\alpha }\tilde{\mathcal{D}}(\Theta)^{p}\\ &
\leq\beta\left\|-\nabla U(\theta)+\nabla U(a)\right\|\|\theta^{ \prime}-\theta\|+\beta\left\|\nabla U(a)\right\|\|\theta^{\prime}-\theta\|+ \frac{1}{2\alpha}\tilde{\mathcal{D}}(\Theta)^{p}\\ &
\leq\beta\|-\nabla U(\theta)+\nabla U(a)\|\tilde{\mathcal{D}}(\Theta)+\beta\| \nabla U(a)\|\tilde{\mathcal{D}}(\Theta)+\frac{1}{2\alpha}\tilde{\mathcal{D}}(\Theta)^{p}\\ &
\leq \beta M \tilde{\mathcal{D}}(\Theta)^{2}+\beta \|\nabla U(a)\|\,\tilde{\mathcal{D}}(\Theta) + \frac{1}{2\alpha}\tilde{\mathcal{D}}(\Theta)^{p}.
\end{aligned}
\end{equation}
Combining~\cref{p_ineq,Z_ineq,Q_ineq,Q_ineq_part}, we obtain
$$
p(\theta^{\prime}|\theta)\geq\epsilon_{\beta,\alpha}\,\frac{\exp\left\{\beta U( \theta^{\prime})\right\}}{\sum_{\theta^{\prime}\Theta}\exp\left\{\beta U( \theta^{\prime})\right\}}
$$
where
$$
\epsilon_{\beta,\alpha}=\exp\left\{-\left(\beta M-\frac{\beta \,m}{2}\right)\,\tilde{\mathcal{D}}(\Theta)^{2}-\beta\|\nabla U(a)\|\,\tilde{\mathcal{D}}(\Theta) - \frac{1}{\alpha}\tilde{\mathcal{D}}(\Theta)^{p} \right\}.
$$
\end{proof}


Since the state space is finite, for any $\theta\in\Theta$, we can denote the maximum and minimum values of $U(\theta)$  as $L$ and $l$, respectively. Therefore, for any $k=1, \cdots, K-1$, we obtain
$$
\begin{aligned}
s_k\left(\theta^{(k)}_{i+1},\theta^{(k+1)}_{i+1}\ |\ \theta^{(1)}_{i},\theta ^{(2)}_{i}\right)&=e^{\left(\beta_{k+1}-\beta_{k}\right)\left[U( \theta^{(k)}_{i+1})+U(\theta^{(k)}_{i})-U(\theta^{(k+1)}_{i+1})-U(\theta^{(k+1)}_{i })\right]}
\\& \geq e^{\left(\beta_{k+1}-\beta_{k}\right)\left(2L-2l\right)}.
\end{aligned}
$$
Denote by 
\begin{equation}\label{epsilon_0}
\epsilon_{0}:=\min\limits_{k=1, \cdots, K-1}\left\{\exp\left\{\left(\beta_{k+1}-\beta_{k}\right)\left(2L-2l\right)\right\}\right\}.
\end{equation}
Then, for any $k=1, \cdots, K-1$, we can get that, $1\geq s_k\geq\epsilon_{0}> 0$. For brevity, we take three chains as an example.

\begin{proof}[\textbf{Proof of \cref{thm:4}}]
By using \cref{epsilon_0,lm:3}, we obtain
\begin{align*}
&q\left( {\theta}^{\prime} \mid  {\theta}_i^{(1)}\right)\\&= \sum_{ {\theta}_i^{(2)}} \sum_{ {\theta}_{i+1}^{(2)}} \pi_{\alpha}^{\beta_2}\left( {\theta}_i^{(2)}\right) q_2\left( {\theta}_{i+1}^{(2)} \mid  {\theta}_i^{(2)}\right)\left[1-s_{1}\left( {\theta}^{\prime},  {\theta}_{i+1}^{(2)}\right)\right] q_1\left( {\theta}^{\prime} \mid  {\theta}_i^{(1)}\right) \\
& \quad +\!\sum_{ {\theta}_i^{(3)}}\sum_{ {\theta}_{i+1}^{(3)}}\sum_{ {\theta}_i^{(2)}} \sum_{ {\theta}_{i+1}^{(1)}} \pi_{\alpha}^{\beta_2}\!\left( {\theta}_i^{(2)}\right) q_2\left( {\theta}^{\prime} \mid  {\theta}_i^{(2)}\right) s_{1}\left( {\theta}_{i+1}^{(1)},  {\theta}^{\prime}\right) q_1\left( {\theta}_{i+1}^{(1)} \mid  {\theta}_i^{(1)}\right)\left(1 \!-\! s_2(\theta^{\prime}, \theta_{i+1}^{(3)})\right)q_3\left(\theta_{i+1}^{(3)}|\theta_i^{(3)}\right)\pi_{\alpha}^{\beta_3}(\theta_i^{(3)})\\
&\quad +\!\sum_{ {\theta}_i^{(3)}}\sum_{ {\theta}_{i}^{(2)}}\sum_{ {\theta}_{i+1}^{(2)}} \sum_{ {\theta}_{i+1}^{(1)}} \pi_{\alpha}^{\beta_2}\!\left( {\theta}_i^{(2)}\right) q_2\left( {\theta}_{i+1}^{(2)}\!\mid\!  {\theta}_i^{(2)}\right) s_{1}\left( {\theta}_{i+1}^{(1)},  {\theta}^{\prime}\right) q_1\left( {\theta}_{i+1}^{(1)}\!\mid\!  {\theta}_i^{(1)}\right)s_2\left(\theta_{i+1}^{(2)}, \theta^{\prime}\right)q_3\left(\theta^{\prime}|\theta_i^{(3)}\right)\pi_{\alpha}^{\beta_3}(\theta_i^{(3)})\\
&\geq \epsilon_{0}^2\sum_{ {\theta}_i^{(3)}}\sum_{ {\theta}_{i}^{(2)}}\sum_{ {\theta}_{i+1}^{(2)}} \sum_{ {\theta}_{i+1}^{(1)}} \pi_{\alpha}^{\beta_2}\!\left( {\theta}_i^{(2)}\right) q_2\left( {\theta}_{i+1}^{(2)} \mid  {\theta}_i^{(2)}\right) q_1\left( {\theta}_{i+1}^{(1)} \mid  {\theta}_i^{(1)}\right) q_3\left(\theta^{\prime}|\theta_i^{(3)}\right)\pi_{\alpha}^{\beta_3}(\theta_i^{(3)})\\
%&=\epsilon_{0}^2\sum_{\theta_i^{(2)}} \pi_{\alpha}^{\beta_2}\left( \theta_i^{(2)}\right) q_2\left( \theta^{\prime} \mid \theta_i^{(2)}\right)\\
&\geq \epsilon_{0}^2\left(\epsilon_{\beta_3, \alpha}\frac{\exp\left\{\beta_{3} U (\theta^{\prime})\right\}}{\sum_{\theta^{\prime}\in\Theta}\exp\left\{\beta_{3} U(\theta^{\prime})\right\}}\right) \sum_{ {\theta}_i^{(3)}}\sum_{ {\theta}_{i}^{(2)}}\sum_{ {\theta}_{i+1}^{(2)}} \sum_{ {\theta}_{i+1}^{(1)}} \pi_{\alpha}^{\beta_2}\!\left( {\theta}_i^{(2)}\right) q_2\left( {\theta}_{i+1}^{(2)} \mid  {\theta}_i^{(2)}\right) q_1\left( {\theta}_{i+1}^{(1)} \mid  {\theta}_i^{(1)}\right)\pi_{\alpha}^{\beta_3}(\theta_i^{(3)}) \\
&=\epsilon_{0}^2\epsilon_{\beta_3, \alpha}\frac{\exp\left\{\beta_{3} U (\theta^{\prime})\right\}}{\sum_{\theta^{\prime}\in\Theta}\exp\left\{\beta_{3} U(\theta^{\prime})\right\}}.
\end{align*}
\end{proof}



\begin{proof}[\textbf{Proof of \cref{col:5.7}}]
By using \cref{thm:4} and the fact $0<\epsilon<1$, we note that as the $\epsilon$ approaches $1$, the sampling algorithm converges faster in terms of total variance. Specifically, we consider $$k:=\frac{\epsilon_0^2 \epsilon_{\beta_3, \alpha}}{\epsilon_{\beta_1, \alpha}}= \frac{\epsilon_0^2\exp\left\{-\beta_3\left((M-\frac{m}{2})\tilde{\mathcal{D}}(\Theta)^2 - \|\nabla U(a)\| \tilde{\mathcal{D}}(\Theta)\right)-\frac{1}{\alpha}\tilde{\mathcal{D}}(\Theta)^p\right\}}{\exp\left\{-\beta_1\left((M-\frac{m}{2})\tilde{\mathcal{D}}(\Theta)^2 - \|\nabla U(a)\| \tilde{\mathcal{D}}(\Theta)\right)-\frac{1}{\alpha}\tilde{\mathcal{D}}(\Theta)^p\right\}}.$$ 
The multi-chain algorithm converges faster than single chain if $k > 1$. By using the definition of $\tilde{\mathcal{D}}$ and $\|\nabla U(a)\| < (M-\frac{m}{2})\tilde{\mathcal{D}}(\Theta) - \frac{2\log(1 / \epsilon_0)}{\|\mathcal{T}_K\| \tilde{\mathcal{D}}(\Theta)}$ and the fact that $\beta_3 < \beta_1$, we obtain
$$
\begin{aligned}
k& = \epsilon_0^2 \exp\left\{\left(-\beta_3 + \beta_1\right) \left(\left(M-\frac{m}{2}\right)\tilde{\mathcal{D}}(\Theta)^2 - \|\nabla U(a)\|\tilde{\mathcal{D}}(\Theta)\right)\right\}\\ &
> 1
\end{aligned}
$$
Thus, we could conclude that the replica exchange algorithm converges faster than single chain langevin-like sampler in terms of Total Variance. 


\end{proof}




\section{Additional Experiments Results and Setting Details}\label{App_ex}
This section complements the main text by providing details on additional experimental procedures.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Sampling from Synthetic Energies}
\paragraph{Synthetic Distribution}
We examine  energy functions with varying components of Mixture of Gaussian Distributions~(MoG) and Mixture of Student's t-Distributions~(MoS)~\citep{blessing2024beyond}, and use MMD and EMC to evaluate the algorithms' capability to navigate through complex terrains with multiple local minima and discontinuities. 


The probability density function of \textbf{MoG} is given by:
\[
p_{\text{MoG}}(\mathbf{x}) = \sum_{k=1}^{K_1} \pi_k \cdot \mathcal{N}(\mathbf{x} \mid \boldsymbol{\mu}_k, \boldsymbol{\Sigma}_k),
\]
where $K_1$ denotes the number of Gaussian components, $\pi_k$ denotes the mixing weight of the $k$-th component satisfying $\sum_{k=1}^{K_1} \pi_k = 1$ and $\pi_k > 0$, and $\mathcal{N}(\mathbf{x} \mid \boldsymbol{\mu}_k, \boldsymbol{\Sigma}_k)$ denotes the probability density function of a d-dimensional Gaussian distribution. 


Similarly, the probability density function of \textbf{MoS} is given by:
\[
p_{\text{MoS}}(\mathbf{x}) = \sum_{j=1}^{K_2} \pi_j \cdot t(\mathbf{x} \mid \boldsymbol{\mu}_j, \boldsymbol{\Sigma}_j, \nu_j),
\]
where $K_2$ denotes the number of Student's t components, $\pi_j$ denotes the mixing weight of the $j$-th component satisfying $\sum_{j=1}^{K_2} \pi_j = 1$ and $\pi_j > 0$, and $t(\mathbf{x} \mid \boldsymbol{\mu}_j, \boldsymbol{\Sigma}_j, \nu_j)$ denotes the probability density function of a  d-dimensional Student's t-distribution.



\textbf{EMC} is the expected entropy of the auxiliary distribution, that is,
\[
\text{EMC} := \mathbb{E}^{q_\theta} \mathcal{H} \big( p(\xi \mid \mathbf{x}) \big)
\approx -\frac{1}{N} \sum_{\mathbf{x} \sim q_\theta} \sum_{i=1}^M p(\xi_i \mid \mathbf{x}) \log_M p(\xi_i \mid \mathbf{x}),
\]
where $N$ denotes the number of samples drawn from $q_\theta$.\\
\textbf{MMD} is a kernel-based test used to compare distributions which is computed as:
\[
\text{MMD}^2(\pi, \tilde{\pi}) = \mathbb{E}_{\mathbf{x}, \mathbf{x}' \sim \pi} \big[k(\mathbf{x}, \mathbf{x}')\big] + 
\mathbb{E}_{\mathbf{y}, \mathbf{y}' \sim \tilde{\pi}} \big[k(\mathbf{y}, \mathbf{y}')\big] - 
2\mathbb{E}_{\mathbf{x} \sim \pi, \mathbf{y} \sim \tilde{\pi}} \big[k(\mathbf{x}, \mathbf{y})\big],
\]
where $k(\mathbf{x}, \mathbf{y})$ is a positive-definite kernel function. MMD measures the similarity between the empirical distributions of the generated and target samples. In practice, however, directly computing MMD is computationally expensive. Therefore, we use an
approximation based on Random Fourier Features (RFF). The feature mapping is defined as:
\[
\phi(X) = \sqrt{\frac{2}{D}} \cos(WX^\top + \mathbf{b}),
\]
where $W \in \mathbb{R}^{D \times d}$ are random Gaussian variables sampled from $\mathcal{N}(0, 1 / \sigma^2)$, and $\mathbf{b}$ are random uniform variables in the range $[0, 2\pi]$. The parameter $\sigma$ controls the kernel bandwidth, and $D$ is the number of random features. For two distributions $\pi$ and $\tilde{\pi}$, the empirical mean feature embeddings for $X \sim \pi$ and $Y \sim \tilde{\pi}$ are computed for both distributions:
\[
\bm{\mu}_X = \frac{1}{n} \sum_{i=1}^n \phi(X_i), \quad 
\bm{\mu}_Y = \frac{1}{m} \sum_{i=1}^m \phi(Y_i).
\]
The following approach allows us to efficiently compute the MMD between two distributions using RFF:
\[
\text{MMD}^2(\pi, \tilde{\pi}) \approx \|\bm{\mu}_X - \bm{\mu}_Y\|^2.
\]
\textbf{KL divergence} measures the difference between two probability distributions. Given the distributions $\pi$ and $\tilde{\pi}$, the KL divergence is defined as:

$$
D_{\text{KL}}(\pi \parallel \tilde{\pi}) = \sum_{\theta \in \Theta} \pi(\theta) \log \left( \frac{\pi(\theta)}{\tilde{\pi}(\theta)} \right),
$$

where $\pi(\theta)$ represents the probability of $\theta$ under the target distribution $\pi$, and $\tilde{\pi}(\theta)$ represents the probability of $\theta$ under the empirical distribution $\tilde{\pi}$ obtained from sampling. This metric quantifies the information loss incurred when approximating the target distribution $\pi$ using the empirical distribution $\tilde{\pi}$. A lower value of the KL divergence indicates better performance in approximating the target distribution.

\begin{table}[htbp]
\centering
\caption{MMD~($\downarrow$) results~(MoG) across different components~(c denotes the number of components)}
\begin{tabular}{lcccc}
\toprule
\textbf{Task} & \textbf{DMALA} & \textbf{ACS} & \textbf{AB} & \textbf{\textbf{PTDLP}} \\
\midrule
c=2 & 2.024 \fs{0.026} & 1.981 \fs{0.021} & 2.009 \fs{0.039} & \textbf{1.929 \fs{0.027}} \\
c=4 & 2.042 \fs{0.023} & 1.994 \fs{0.016} & 1.992 \fs{0.012} & \textbf{1.924 \fs{0.032}} \\
c=6 & 2.016 \fs{0.025} & 1.984 \fs{0.013} & 2.001 \fs{0.013} & \textbf{1.981 \fs{0.025}} \\
c=8 & 2.077 \fs{0.022} & 2.004 \fs{0.011} & 2.019 \fs{0.036} & \textbf{1.996 \fs{0.025}} \\
c=10 & 2.021 \fs{0.023} & 1.999 \fs{0.008} & 2.001 \fs{0.011} & \textbf{1.992 \fs{0.009}} \\
c=12 & 2.089 \fs{0.043} & 2.033 \fs{0.039} & 2.024 \fs{0.012} & \textbf{2.002 \fs{0.022}} \\
c=14 & 2.048 \fs{0.009} & 1.984 \fs{0.010} & 1.968 \fs{0.007} & \textbf{1.915 \fs{0.024}} \\
c=16 & 2.030 \fs{0.012} & 2.006 \fs{0.013} & 2.001 \fs{0.012} & \textbf{1.924 \fs{0.011}} \\
\bottomrule
\end{tabular}
\end{table}
\begin{table}[htbp]
\centering
\caption{MMD~($\downarrow$) results(MoS) across different components~(c denotes the number of components)}
\begin{tabular}{lcccc}
\toprule
\textbf{Task} & \textbf{DMALA} & \textbf{ACS} & \textbf{AB} & \textbf{\textbf{PTDLP}} \\
\midrule
c=2 & 2.018 \fs{0.034} & 1.996 \fs{0.016} & 1.996 \fs{0.033} & \textbf{1.893 \fs{0.029}} \\
c=4 & 2.109 \fs{0.012} & 1.997 \fs{0.009} & 1.994 \fs{0.007} & \textbf{1.957 \fs{0.022}} \\
c=6 & 2.019 \fs{0.011} & 2.001 \fs{0.021} & 2.003 \fs{0.041} & \textbf{1.963 \fs{0.019}} \\
c=8 & 2.017 \fs{0.021} & 2.006 \fs{0.017} & 2.005 \fs{0.024} & \textbf{1.934 \fs{0.038}} \\
c=10 & 2.030 \fs{0.016} & 2.009 \fs{0.021} & 2.008 \fs{0.028} & \textbf{1.989 \fs{0.012}} \\
c=12 & 2.014 \fs{0.024} & 1.994 \fs{0.030} & 2.001 \fs{0.017} & \textbf{1.964 \fs{0.023}} \\
c=14 & 2.095 \fs{0.019} & 2.001 \fs{0.022} & 2.003 \fs{0.028} & \textbf{1.944 \fs{0.016}} \\
c=16 & 2.158 \fs{0.023} & 2.013 \fs{0.021} & 2.015 \fs{0.018} & \textbf{1.967 \fs{0.015}} \\
\bottomrule
\end{tabular}
\end{table}



\paragraph{Sampler Configuration}
DMALA  is implemented with a step size of $0.15$. For AB, the parameters are set to $\sigma = 0.1$ and $\alpha = 0.5$. ACS employs a cyclical step size scheduler with an initial step size of $0.6$ over $10$ cycles.  For PTDLP, we set the step size to $0.2$ for all chains.

\paragraph{Results}
When the number of components in both MoG and MoS varies, our sampler consistently achieves significantly superior MMD and EMC scores compared to DMALA, ACS, and AB. Its capacity to effectively distribute samples, even in scenarios characterized by disconnected modes and steep energy barriers, underscores its robustness in navigating intricate discrete energy landscapes.

% \begin{table*}[ht]
%     \centering
%     \resizebox{0.99\textwidth}{!}{
%     \renewcommand\arraystretch{1.2}{
%     \begin{tabular}{c|cccc|cccc}
%     \hline \hline
%         \multirow{2}{*}{Sampler}&  \multicolumn{4}{c|}{Maximum Mean Discrepancy($\downarrow$)} & \multicolumn{4}{c}{KL Divergence ($\downarrow$)} \\ \cline{2-9}
%         & component=10 & component=10 & component=10 & component=10 & component=10& component=10 & component=10 & component=10 \\ \hline
%         DMALA & -0.2355 \fs{0.0002} & -0.2342 \fs{0.0001} &   -0.2344 \fs{0.0006} & -0.2339 \fs{0.0003} & 0.1072 \fs{0.0013} & 0.0971 \fs{0.0026} & 0.0976 \fs{0.0009} &0.0971 \fs{0.0012} \\
%         AB & -0.3738 \fs{0.0039} & -0.3275 \fs{0.0006} & -0.3233 \fs{0.0009} & -0.3287 \fs{0.0027} & 0.4309 \fs{0.0027} & 0.3963 \fs{0.0016} & 0.3954 \fs{0.0015} &0.3971 \fs{0.0014}\\
%         ACS & -0.3738 \fs{0.0039} & -0.3275 \fs{0.0006} & -0.3233 \fs{0.0009} & -0.3287 \fs{0.0027} & 0.4309 \fs{0.0027} & 0.3963 \fs{0.0016} & 0.3954 \fs{0.0015} &0.3971 \fs{0.0014}\\
%         PTDLP & -0.3199 \fs{0.0072} & -0.2710 \fs{0.0009} & -0.2689 \fs{0.0024} & -0.2694 \fs{0.0025} & 0.3533 \fs{0.0043} & 0.3202 \fs{0.0018} & 0.3198 \fs{0.0026} & 0.3193 \fs{0.0021} \\
%     \hline \hline
%     \end{tabular}}}
%     \caption{}
%     \label{tab_synthetic}
% \end{table*}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{RBM Sampling}\label{rbm_sampling_app}
\paragraph{RBM introduction}We will give a brief introduction of the Block-Gibbs sampler used to represent the ground truth of the RBM distribution. For a more in-depth explanation, see~\citet{grathwohl2021oops}. Given the hidden units $h$ and the sample $\theta$, we define the RBM distribution as follows:
$$
\log p(\theta, h)=h^\top W \theta + b^\top \theta+c^\top-\log Z
$$
As before, Z is the normalizing constant for the distribution. The sample $x$ is represented by the visible layer with units corresponding to the sample space dimension and $h$ represents the model capacity. It can be shown that the marginal distributions are as follows:
$$
\begin{gathered}
p(x \mid h)=\operatorname{Bernoulli}(W x+c) \\
p(h \mid x)=\operatorname{Bernoulli}\left(W^\top h+b\right)
\end{gathered}
$$
The Block-Gibbs sampler updates $\theta$ and $h$ alternatively, allowing for many of the coordinates to get changed at the same time, due to utilizing the specific structure of the RBM model.

\paragraph{Experiment Setup}We follow the experimental setup of~\citet{zhang2022langevin} and use RBM models with 500 hidden units and 784 visible units. We adopt the same training protocol, except we train the RBM with 100 steps of Contrastive Divergence as opposed to 10 . We train the models for one pass through the dataset.


\paragraph{Sampler Configuration}
For DMALA, we set step size to $0.2$ , and for AB we use the default hyper-parameters for the first order sampler.
For ACS, we use $\rho^*=0.5$, $\beta_{\max }=0.95$, $\zeta=0.5$, cycle length $s=20$ for all the datasets. We also fix the total overhead of the tuning algorithm to $10 \%$ of the total sampling steps. For PTDLP, we set the step size to $0.15 \sim 0.45$ for all chains.


\paragraph{Escape from Local Modes}
In addition to using the same initialization as~\citet{grathwohl2021oops, zhang2022langevin}, we extend the experiment to measure the ability of a sampler to escape from local modes. We initialize the sampler within the most likely mode, as measured by unnormalized energy of the RBM. Samplers that are less prone to getting trapped in local modes will be able to converge quicker to the ground truth, as measured by $\log$ MMD. We include the performance of the various samplers across 5 random seeds in~\cref{fig_mode_int}. PTDLP demonstrates superior robustness to mode-specific initialization due to its capability to escape from local modes.

\paragraph{Generated Images}
We found that a visual inspection of the generated images demonstrates the ability of PTDLP to escape local modes. We include the generated images in \cref{img_rbm_sampling_app}.
\begin{figure}[htbp]
\centering
\subfloat[DULA]{\includegraphics[width=3cm]{figs/rbm_sampling/rbm_mode_escape_dula.pdf}}\hspace*{0pt}
\subfloat[DMALA]{\includegraphics[width=3cm]{figs/rbm_sampling/rbm_mode_escape_dmala.pdf}}\hspace*{0pt}
\subfloat[AB]{\includegraphics[width=3cm]{figs/rbm_sampling/rbm_mode_ecape_ab.pdf}}\hspace*{0pt}
\subfloat[ACS]{\includegraphics[width=3cm]{figs/rbm_sampling/rbm_mode_escape_acs.pdf}}\hspace*{0pt}
\subfloat[PTDLP]{\includegraphics[width=3cm]{figs/rbm_sampling/rbm_mode_escape_ptdlp.pdf}}
\caption{Images sampled from RBM trained on MNIST when the sampler is initialized to most likely mode. Our algorithm is able to generate a diverse range of digits, demonstrating its ability to escape from modes.}
\label{img_rbm_sampling_app}
\end{figure}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{RBM Learning}
\paragraph{Experiment Design}
We use the same RBM structure as the sampling task, with 500 hidden units and 784 visible units. We apply the samplers of interest to the PCD algorithm introduced by~\citet{tieleman2008training}. The model parameters are tuned via the Adam optimizer with a learning rate of
.001.


\paragraph{Sampler Configuration}
For DMALA, we set step size to $0.2$ , and for AB we use the default hyper-parameters for the first order sampler. For ACS, we follow the setting in \citet{pynadath2024gradient} and use $\rho^*=0.5, \beta_{\max }=0.95, \zeta=0.5$, cycle length $s=20$ for all the datasets. We also fix the total overhead of the tuning algorithm to $10 \%$ of the total sampling steps.

% \paragraph{Results}
% We include the AIS results for RBMs trained with different sampling methods in Table 4. We see that PTDLP achieves superior log likelihood results when compared to other sampling methods across all datasets. Furthermore, the AIS results are consistently close to those achieved by Block-Gibbs, which can be considered close to ideal for RBMs since it leverages the known structure of the model.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Learning EBMs}
\paragraph{Experiment Setup} We adopt the same ResNet structure and experiment protocol as in~\citet{grathwohl2021oops}, where the network has 8 residual blocks with 64 feature maps. There are 2 convolutional layers for each residual block. The network uses Swish activation function~\citep{ramachandran2017searching}. For static/dynamic MNIST and Omniglot, we use a replay buffer with 10,000 samples. For Caltech, we use a replay buffer with 1,000 samples. We evaluate the models every 5,000 iterations by running AIS for 10,000 steps. The reported results are from the model which performs the best on the validation set. The final reported numbers are generated by running 300,000 iterations of AIS. All the models are trained with Adam~\citep{kingma2014adam} with a learning rate of 0.001 for 50,000 iterations.

\paragraph{Sampler Configuration} For DMALA, we use a step size of $0.15$ as used in~\citet{zhang2022langevin}. For ACS, we follow the setting in~\citet{pynadath2024gradient} and use $200$ sampling steps for EstimateAlphaMax and EstimateAlphaMin. For Static MNIST, Dynamic MNIST, and Omniglot, we set the algorithm to tune $\alpha_{\max }$ and $\alpha_{\min }$ every $25$ cycles, where each cycle has $50$ training iterations. For Caltech Silhouettes, we have to adapt every $10$ cycles with the same number of training iterations. We set the step sizes as $0.05 \sim 0.4$ for all chains in our algorithm.

\paragraph{Generated Images}
Here we provide the generated results in~\cref{img_ebm_learn_genimgs} from our algorithm across Static MNIST, Dynamic MNIST, Omniglot, and Caltech Silhouettes. These images demonstrate the ability of trained deep EBMs to capture the underlying data distribution. The deep EBM is capable of producing high-quality samples that visually resemble the training data, which indicates that the learned energy function effectively models the complex, high-dimensional structure of the data.
\begin{figure}[htbp]
\def\imgvspace{0.25cm}
\def\imghspace{.25cm}
\def\imghwidth{2.5cm}
\centering
\subfloat{\includegraphics[width=\imghwidth]{figs/ebm_learning/static_ex.pdf}}\hspace*{\imghspace}
\subfloat{\includegraphics[width=\imghwidth]{figs/ebm_learning/dynamic_ex.pdf}}\hspace*{\imghspace}
\subfloat{\includegraphics[width=\imghwidth]{figs/ebm_learning/omniglot_ex.pdf}}\hspace*{\imghspace}
\subfloat{\includegraphics[width=\imghwidth]{figs/ebm_learning/caltech_ex.pdf}} 

\vspace{\imgvspace}

\centering
\hspace{.15cm}
\subfloat[Static]{\includegraphics[width=\imghwidth]{figs/ebm_learning/static_pt.pdf}}\hspace*{\imghspace}
\subfloat[Dynamic]{\includegraphics[width=\imghwidth]{figs/ebm_learning/dynamics_pt.pdf}}\hspace*{\imghspace}
\subfloat[Omniglot]{\includegraphics[width=\imghwidth]{figs/ebm_learning/omniglot_pt.pdf}}\hspace*{\imghspace}
\subfloat[Caltech]{\includegraphics[width=\imghwidth]{figs/ebm_learning/caltech_pt.pdf}} \hspace*{\imghspace}
\caption{The images on the top row are examples from the dataset, while the bottom row are from the trained EBM. The images generated from our algorithm are similar to those from the dataset, demonstrating that the model is capable of generating high-quality samples.}
\label{img_ebm_learn_genimgs}
\end{figure}

% \subsection{Text Infilling}

% \paragraph{Experimental Setup}
% Experimental Design For both datasets, we sample 100 sentences randomly and mask $50 \%$ of the tokens. We use a pretrained RoBERTa model available through the Hugging Face API~\citep{wolf2019huggingface}. We run 25 separate copies for each example and take the final state of each chain to be a sample. We then take the top-5 most likely samples and use these for empirical comparisons. 

% We define the energy function the same as in~\citet{zhang2022langevin}. Let us define a sentence of length $d:\ \theta=\left\{\theta_1, \theta_2, \ldots \theta_d\right\}$, where $\theta_i$ is a one hot vector over vocabulary $V$. Let $M \subset\{1,2, \ldots d\}$ the set of indices we wish to sample. We define the function $f\left(\theta_i \mid \theta_{\neg i}\right)$ to be the $\log$ probability distribution over $V$ for the $i$ position conditioned on all other positions. Given this, we define the energy function for the sentence $\theta$ to be as follows:
% $$
% U(\theta)=\sum_{m \in M} f\left(\theta_m \mid \theta_{\neg m}\right)
% $$


% \paragraph{Sampler Configuration}



\end{document}


% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was created
% by Iain Murray in 2018, and modified by Alexandre Bouchard in
% 2019 and 2021 and by Csaba Szepesvari, Gang Niu and Sivan Sabato in 2022.
% Modified again in 2023 and 2024 by Sivan Sabato and Jonathan Scarlett.
% Previous contributors include Dan Roy, Lise Getoor and Tobias
% Scheffer, which was slightly modified from the 2010 version by
% Thorsten Joachims & Johannes Fuernkranz, slightly modified from the
% 2009 version by Kiri Wagstaff and Sam Roweis's 2008 version, which is
% slightly modified from Prasad Tadepalli's 2007 version which is a
% lightly changed version of the previous year's version by Andrew
% Moore, which was in turn edited from those of Kristian Kersting and
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.
