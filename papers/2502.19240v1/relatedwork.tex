\section{Related Works}
\label{sec:2}
\subsection{Gradient-based Discrete Sampling}\label{sec:2.1}
Gradient-based discrete sampling has gained popularity for tackling complex discrete sampling tasks, with its origins rooted in Local Balance Proposals~(LBP)~\citep{zanella2020informed}, which leverage local density ratios to enhance sampling efficiency. \citet{grathwohl2021oops} expanded LBP by incorporating first-order Taylor approximations, ensuring computational feasibility and improving performance. To facilitate sampling in high-dimensional discrete spaces, LBP were further extended to explore larger neighborhoods through a sequence of small moves~\citep{sun2021path}. \citet{zhang2022langevin} proposed Discrete Langevin Proposal~(DLP) by adapting continuous Langevin MCMC methods to discrete spaces, allowing parallel updates of all coordinates based on gradient information. Additionally, DLP was refined with an adaptive mechanism to automatically adjust step sizes for better efficiency~\citep{sun2023any}. While these approaches have shown promise, challenges persist in sampling from discrete, multimodal distributions.

\subsection{Sampling on Multimodal Distributions}\label{sec:2.2}
Various algorithms have been proposed to enhance exploration in complex, multimodal distributions, including importance sampling~\citep{wang2001efficient}, simulated annealing~\citep{kirkpatrick1983optimization}, simulated tempering~\citep{marinari1992simulated}, cyclic step-size scheduling~\citep{zhang2019cyclical}, dynamic weighting~\citep{wong1997dynamic}, and replica exchange Monte Carlo~\citep{swendsen1986replica, earl2005parallel}. Among these advancements, simulated annealing stochastic gradient Markov chain Monte Carlo~(SGMCMC)~\citep{mangoubi2018convex} and simulated tempering SGMCMC~\citep{ge2018simulated} show how dynamical temperatures speed up the convergence. However, simulated annealing is very sensitive to the fast-decaying temperatures, and simulated tempering requires a lot on the approximation of the normalizing constant. The replica exchange Markov chain Monte Carlo~(reMCMC) leverages multiple chains operating at different temperatures and allows exchanges between chains, which is easier to implement and suitable for parallelism. \citet{chen2020accelerating} analyzed the acceleration effect of replica exchange in $\chi^2$ divergence and large deviation principle. \citet{dong2022spectral} analyzed the mixing properties of reMCMC by evaluating its spectral gap, while \citet{deng2020non, deng2020accelerating} demonstrated its efficiency in large-scale deep learning applications. 

Despite the more pronounced multimodal nature of discrete domains due to their inherent discontinuities, research on sampling from multimodal distributions in discrete domains remains limited. \citet{pynadath2024gradient} proposed a cyclic scheduling strategy that alternates step sizes, enhancing the handling of multimodal distributions. \citet{zhengexploring} attempted to integrate replica exchange with gradient-based sampling; however, their approach lacks a rigorous theoretical foundation, and the two replicas encounter a specific issue, as discussed in \cref{sec_4_1}.