\section{Introduction}
\label{sec:introduction}
%Printed Electronics (\gls{pe}) have emerged as a transformative technology designed to address the limitations of traditional silicon-based systems, particularly in cost-sensitive and flexible applications~\cite{Bleier:ISCA:2020:printedml}.
\gls{pe} have emerged as a complement to silicon-based technology, meeting demands that are untouchable by the latter, such as mechanical flexibility, non-toxicity, conformability, and ultra-low cost~\cite{Bleier:ISCA:2020:printedml}. 
Target applications include smart packaging~\cite{smartpackaging2022, disposable:JSNB:2023}, forensics~\cite{salivary:Talanta:2020}, and accessible healthcare products and wearables~\cite{bodytemperature:sna:2020,pressuresensor:research:2022,wearable:adma:2022,Wearable:acssensors:2019,healthcare:Nanoscale:2024}.
Unlike conventional silicon technologies, which are constrained by high manufacturing and assembly costs, \gls{pe} leverage additive, mask-less printing processes that enable on-demand production of flexible circuits at significantly lower costs~\cite{cui2016printed}.
%\gls{pe} systems, although manufactured with micrometer-scale features and limited in performance compared to silicon-based devices, excel in domains requiring conformality, low power consumption, and non-toxicity~\cite{Armeniakos:TCAD2023:cross}.
%Importantly, recent advancements in \gls{pe} have enabled the development of low-voltage circuits powered by printed batteries, or even self-sustaining energy sources, further enhancing their potential in applications where traditional electronics fail to meet cost, stretchability, or flexibility demands~\cite{Mubarik:MICRO:2020:printedml}.

% Challenges for ML in PE - Bespoke ML classifiers
Such application domains stand to greatly benefit from the infiltration of \gls{ml} algorithms~\cite{Mubarik:MICRO:2020:printedml}.
%The ability to embed intelligence into low-cost printed devices could enable real-time monitoring, product tracking, and enhanced interactivity, all while keeping application costs low~\cite{Mubarik:MICRO:2020:printedml}.
However, \gls{pe} face significant challenges in implementing complex circuits such as \gls{ml} classifiers, due to the large feature sizes and the corresponding power and area overheads, thus hindering the ubiquitous integration of \gls{ml} in \gls{pe} applications.
To overcome these limitations, leveraging the low \gls{nre} and fabrication costs in PE, bespoke circuits have been proposed as a promising solution~\cite{Mubarik:MICRO:2020:printedml}.
They refer to fully customized designs tailored to a specific \gls{ml} model and dataset, optimizing hardware for a particular application.
Such tailored designs allow for significant reductions in power and area, by hardwiring the parameters of the \gls{ml} model into the circuit implementation.
This level of customization is infeasible in conventional lithography-based silicon technologies, due to elevated costs (e.g., \gls{nre}, maskset, etc.), particularly at low to moderate volumes;
even FPGA-based systems are constrained by the architecture, multiplexing, and routing of the underlying fabric.
%While traditional design techniques struggle to meet the constraints of \gls{pe}, bespoke architectures leverage the low \gls{nre} costs and high degree of customization, making it feasible to implement on-demand, resource-efficient \gls{ml} classifiers.
%Printed bespoke architectures leverage the low \gls{nre} costs and high degree of customization, making it feasible to implement on-demand, resource-efficient \gls{ml} classifiers.
Additionally, exploiting the intrinsic error resilience of ML circuits~\cite{Henkel:ICCAD2022:expedition}, state-of-the-art approaches combine bespoke circuits with approximate computing to boost hardware efficiency~\cite{Armeniakos:DATE2022:axml,Armeniakos:TCAD2023:cross,Armeniakos:TC2023:codesign,Afentaki:ICCAD23:hollistic,Afentaki:DATE2024:embedding,Mrazek:ICCAD2024}.
However, they often lead to significant accuracy loss in order to meet the tight power and area constraints inherent in PE. 

% % Printed SVMs - Limitations of SOTA
% A wide range of printed \gls{ml} classifiers have been showcased in the literature, ranging from \glspl{dt}~\cite{Balaskas:ISQED2022:axDT} and \glspl{svm}~\cite{Mubarik:MICRO:2020:printedml, Armeniakos:DATE2022:axml, Armeniakos:TCAD2023:cross} to \glspl{mlp}~\cite{Afentaki:DATE2024:embedding, Afentaki:ICCAD23:hollistic,Kokkinis:DATE2023:minimization}.
% At the higher end of the area consumption spectrum stand more complex models (e.g., \glspl{mlp}), which may be sub-optimal in delivering ultra-low area for printed circuits.
% Printed \glspl{svm} on the other hand offer much lower area at comparable accuracy levels in the form of regression-based~\cite{Mubarik:MICRO:2020:printedml}, classification-based~\cite{Armeniakos:TCAD2023:cross} and \gls{lut}-based architectures~\cite{Mubarik:MICRO:2020:printedml}.
% All the above constitute fully-parallel classifiers, opting for memory-less implementations, however without taking hardware re-use into account as an area reduction mechanism.

% Our solution: sequential SVMs
A wide range of digital printed \gls{ml} classifiers have been showcased in the literature, with the main focus lying on fully parallel implementations of shallow Neural Networks~\cite{Armeniakos:TC2023:codesign,Afentaki:ICCAD23:hollistic,Afentaki:DATE2024:embedding,Mrazek:ICCAD2024}. 
In this work, we leverage the high accuracy of \glspl{svm} in target applications and propose, for the first time, \emph{printed sequential \gls{svm} classifiers}.
Our goal is to minimize area while maintaining high accuracy.
We design a compute engine with just one \gls{mac}, folding each support vector computation over it, maximizing hardware reuse and significantly reducing area.
Additionally, we reduce the area requirements associated with sequential elements by minimizing the use of registers--which are costly in PE--and we use bespoke multiplexers (MUXs) for storing model parameters.
A bespoke control unit further folds the entire \gls{svm} computation over the single support vector engine.
We implement the One-vs-One (OvO) algorithm~\cite{ovo} into a binary decision tree, simplifying the control circuitry and eliminating the need for a voter and additional registers.
Compared to printed parallel SVMs, our sequential ones achieve more than $5$x lower area at similar accuracy.
\textbf{Our novel contributions within this work are as follows}:
\begin{enumerate}[topsep=0pt,leftmargin=*]
\item We propose, design, and evaluate, for the first time, printed sequential \gls{svm} circuits targeting printed \gls{ml} classification.
The hardware description of our \glspl{svm} is automatically generated\footnote{Our circuits are available on:
\href{https://github.com/floAfentaki/Support-Vector-Machine-Circuits-Targeting-Printed-Electronics/tree/main/Compact-And-Highly-Accurate-Printed-Sequential-SVMs_ISCAS2025}{https://github.com/floAfentaki/Support-Vector-Machine-Circuits-Targeting-Printed-Electronics}}. 
\item
% To the best of our knowledge, 
\blue{Our \glspl{svm} constitute} the most accurate digital printed \gls{ml} classifiers that feature acceptable area and power overheads, and also meet the strict physical constraints and limited power sources of PE. 
\end{enumerate}




%In our work, we address the aforementioned limitations and propose for the first time \emph{printed sequential \glspl{svm}}.
% Our objective is to design and evaluate architectures that effectively minimize both the area and power consumption of printed hardware.
% \TODO{Training with power-of-two?}
% We fold the entire \gls{svm} model over a single \gls{mac} unit serving as our computational engine, thus exploiting hardware re-use to its maximum potential and significantly minimizing area.
% Memory units are implemented using \glspl{mux} instead of costly register files or ROMs, further enhancing the area efficiency of our design.
% Finally, we modify the established OvO selection algorithm into a binary search tree, which simplifies our control unit and alleviates the need for voting circuitry.
% Compared to \red{XX}, our printed sequential \glspl{svm} deliver \red{XX} area reduction on average, while adhering to the imposed accuracy constraints.
% Contributions
%  \textbf{In summary, we make the following novel contributions:}
% \TODO{Write these better}
% \begin{enumerate}
% % [wide, labelindent=0pt, label=\textbf{(\arabic*)}, ref=(\arabic*), itemjoin=\;]
% \item 
% We propose, for the first time, printed bespoke sequential \glspl{svm} for \gls{ml} classification.
% Our \glspl{svm} rely on maximum hardware re-use with a single \gls{mac} unit for the computational engine, an \gls{fsm} for fetching support vectors from our \gls{mux}-based memory unit.
% \item 
% Our sequential \glspl{svm} deliver on average \red{XX} area reduction compared to the state of the art, for up to \red{XX} classification accuracy loss.
% \end{enumerate}