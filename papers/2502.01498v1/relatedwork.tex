\section{Related Work}
\label{sec:elated}
In recent years, research on printed \gls{ml} classifiers has proliferated, with a primary focus on improving hardware efficiency while adhering to the strict area and power budget of \gls{pe} systems.
As a result, classification accuracy is often compromised in favor of design feasibility.
The authors in~\cite{Mubarik:MICRO:2020:printedml} introduced printed \gls{ml} classifiers by exploring various models and architectures, and concluding that only simpler models like decision trees and \gls{svm} regressors could be implemented in \gls{pe}.
Furthermore,~\cite{Mubarik:MICRO:2020:printedml} determined that fully parallel architectures should be used in \gls{pe}. %, while sequential designs can be prohibitive due to the costs associated with registers.
Since then, significant research efforts have focused on fully parallel approximate neural networks (\glspl{mlp}~\cite{Armeniakos:DATE2022:axml, Armeniakos:TCAD2023:cross, Armeniakos:TC2023:codesign,Afentaki:ICCAD23:hollistic,Afentaki:DATE2024:embedding} and \glspl{bnn}~\cite{Mrazek:ICCAD2024}) and also approximate \glspl{svm} classifiers~\cite{Armeniakos:DATE2022:axml, Armeniakos:TCAD2023:cross}.
%Approximate computing has proven effective in reducing complexity, with approaches spanning hardware, software, and co-design techniques.
While works like~\cite{Afentaki:ICCAD23:hollistic,Afentaki:DATE2024:embedding,Mrazek:ICCAD2024} achieve impressive area efficiency, they often report accuracy losses around 4\%-5\% or more, due to employing aggressive power-of-two or ternary quantization and approximate additions.
On the other hand,~\cite{Armeniakos:DATE2022:axml} introduced a more conservative post-training approximation technique involving hardware-friendly weight replacement to approximate the multiplications in \glspl{svm} and \glspl{mlp}.
\cite{Armeniakos:DATE2022:axml} also applied a gate-level pruning approximation.
The authors in~\cite{Armeniakos:TCAD2023:cross} expand upon~\cite{Armeniakos:DATE2022:axml} by additionally incorporating voltage over-scaling.
In-training hardware-friendly weight replacement along with truncated addition is proposed in~\cite{Armeniakos:TC2023:codesign} for \glspl{mlp}.
%Due to the more conservative approximation nature in~\cite{Armeniakos:DATE2022:axml,Armeniakos:TCAD2023:cross,Armeniakos:TC2023:codesign} acceptable accuracy is mostly achieved. 
Similar to the aforementioned works, we consider the Electrolyte-Gated FET (EGFET) technology~\cite{Bleier:ISCA:2020:printedml}, which offers good mobility characteristics and operation at low supply voltages ($0.6$V-$1$V~\cite{Marques:Materials:2019}), aligning well with printed battery-powered applications. 

% Our work differs from existing approaches by designing the first printed sequential \gls{svm} classifiers, demonstrating for the first time that digital printed \gls{ml} classifiers can meet the power and area constraints of \gls{pe} with no loss in accuracy.
Our work distinguishes from existing approaches by introducing the first design of printed sequential \gls{svm} classifiers, demonstrating for the first time that digital printed classifiers can meet the physical constraints of \gls{pe} with high accuracy.


%Recent years have witnessed a significant surge in research interest surrounding \gls{pe}, driven by advancements in manufacturing techniques and demands for cost-effective, flexible solutions.
%Printed microprocessors were proposed in~\cite{Bleier:ISCA:2020:printedml} for battery-powered applications. 
%\gls{ml} classification with \gls{pe} was introduced in~\cite{Mubarik:MICRO:2020:printedml}, where diverse models and architectures were implemented, and a proof-of-concept for bespoke \gls{ml} classifiers was given.
%Several works followed, targeting specific \gls{ml} classifiers, such as \glspl{dt}~\cite{Armeniakos:DATE:2024:bespokeDT, Balaskas:ISQED2022:axDT}, \glspl{svm}~\cite{Mubarik:MICRO:2020:printedml, Armeniakos:DATE2022:axml, Armeniakos:TCAD2023:cross}, and more prominently, \glspl{mlp}~\cite{Mubarik:MICRO:2020:printedml, Armeniakos:TC2023:codesign, Kokkinis:DATE2023:minimization, Afentaki:ICCAD23:hollistic, Afentaki:DATE2024:embedding, Pal:ETS:2024:fault_mlp}.
%The latter however proved inefficient to implement with printed devices, due to their increased computational complexity.
%In turn, approximate computing was deemed a suitable solution for alleviating that complexity, with approximation techniques spanning over hardware, software and co-design approaches~\cite{Armeniakos:DATE2022:axml, Armeniakos:TC2023:codesign, Armeniakos:TCAD2023:cross, Kokkinis:DATE2023:minimization, Armeniakos:TCAD2023:cross, Balaskas:ISQED2022:axDT, Afentaki:ICCAD23:hollistic, Afentaki:DATE2024:embedding}.
% Except for~\cite{Mubarik:MICRO:2020:printedml}, none of the aforementioned works designed sequential printed \gls{ml} classifiers.
% The sequential paradigm prioritizes area and power efficiency over system performance, which is less important in \gls{pe}.
% Still, only sequential \glspl{dt} were proposed in~\cite{Mubarik:MICRO:2020:printedml}, which featured a large number of costly registers~\cite{Bleier:ISCA:2020:printedml}.

% In our work we fill these research gaps, and propose for the first time bespoke sequential \glspl{svm} in \gls{pe}.
% We strive for maximum area efficiency and substitute costly register files or memristor-based \glspl{rom} with \gls{mux}-based storage units.
% We also propose a novel \gls{fsm}-based control unit which omits voting modules for further area savings.