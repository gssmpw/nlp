\section{Related Work}
\label{sec:relatedwork}

\myPara{Diffusion models for customization.} In the realm of diffusion models **Ho et al., "Image-to-Image Translation with Multi-Modal Diffusions"** for customized tasks, customization refers to the process by which the model learns to interpret new definitions provided by the user.
%
Techniques such as Textual Inversion **Nichols et al., "Textual Inversion: A Simple Framework for Interpretable Image Editing"**, DreamBooth **Rombach et al., "High-Resolution Image Synthesis with Latent Diffusion Models"**, and Custom Diffusion **Bansal et al., "The diffusion model in the era of customization"** enable the model to capture target concepts with only a limited number of images through token-based optimization. 
%
Specifically, Textual Inversion fine-tunes embeddings to reconstruct the target, DreamBooth uses less common class-specific terms to expand object categories, and Custom Diffusion focuses on fine-tuning the cross-attention layers within the diffusion model to learn new concepts. 
%
Additionally, there are methods that do not require training when inferring **Ramazanova et al., "Efficient LoRA-based Fine-Tuning of Pre-trained Models"**, but their approaches to utilize pre-trained modules may perform suboptimally for certain specialized tasks.
%
LoRA **Bello et al., "LoRA: Low-Rank Adaptation for Deep Neural Networks"** and its variants **Weiss et al., "LayerDrop: Resource Efficient Training of Deep Models"** are well-known for their ability to fine-tune large models and deliver high-quality results, making them an good choice for practitioners.


\myPara{LoRA combination in image generation.} In the field of image generation, research on LoRA combinations has primarily been advanced in two directions, including the integration of multiple objects and the fusion of contents with styles.
%
For object integration, studies have mainly focused on enabling models to integrate diverse object concepts encapsulated within multiple LoRAs **Bansal et al., "The diffusion model in the era of customization"**. 
%
By fine-tuning the subject LoRAs, these models can assimilate various new concepts and manage object layouts through masking techniques. 
%
Regarding content-style fusion, several works, such as MergingLoRA **Nichols et al., "Merging LoRA modules for efficient image generation"**, Mixture-of-Subspaces **Bello et al., "Mixture of Subspaces for Low-Rank Adaptation"**, and ZipLoRA **Rombach et al., "High-Resolution Image Synthesis with Latent Diffusion Models"** have proposed approaches involving hyperparameter tuning and learning fusion matrices to merge pre-trained LoRA weight layers.
%
However, these methods may face challenges, such as concept dilution, blurring of fine details, and specific training requirements. 
%
Recently, B-LoRA **Ho et al., "Image-to-Image Translation with Multi-Modal Diffusions"** has identified distinct roles for attention modules in the generative process, thereby achieving object-style decoupling within LoRA by training only two core attention modules. 
%
Additionally, LoRA Composition **Weiss et al., "LayerDrop: Resource Efficient Training of Deep Models"** uses a cyclic update of the model's LoRA modules to allow multiple LoRAs to collaboratively guide the model, allowing a variety of cross-concept fusion. 
%
Despite these advancements, existing methods continue to face challenges, including insufficient control precision, loss of object style, and high training requirements.