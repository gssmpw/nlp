[
  {
    "index": 0,
    "papers": [
      {
        "key": "xie2021explanation",
        "author": "Xie, Sang Michael and Raghunathan, Aditi and Liang, Percy and Ma, Tengyu",
        "title": "An explanation of in-context learning as implicit {B}ayesian inference"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "li2023transformers",
        "author": "Li, Yingcong and Ildiz, Muhammed Emrullah and Papailiopoulos, Dimitris and Oymak, Samet",
        "title": "Transformers as algorithms: Generalization and stability in in-context learning"
      },
      {
        "key": "zhang2023and",
        "author": "Zhang, Yufeng and Zhang, Fengzhuo and Yang, Zhuoran and Wang, Zhaoran",
        "title": "What and how does in-context learning learn? {B}ayesian model averaging, parameterization, and generalization"
      },
      {
        "key": "bai2024transformers",
        "author": "Bai, Yu and Chen, Fan and Wang, Huan and Xiong, Caiming and Mei, Song",
        "title": "Transformers as statisticians: Provable in-context learning with in-context algorithm selection"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "li2023transformers",
        "author": "Li, Yingcong and Ildiz, Muhammed Emrullah and Papailiopoulos, Dimitris and Oymak, Samet",
        "title": "Transformers as algorithms: Generalization and stability in in-context learning"
      },
      {
        "key": "li2023transformers_topic",
        "author": "Li, Yuchen and Li, Yuanzhi and Risteski, Andrej",
        "title": "How do transformers learn topic structure: Towards a mechanistic understanding"
      },
      {
        "key": "zhang2023and",
        "author": "Zhang, Yufeng and Zhang, Fengzhuo and Yang, Zhuoran and Wang, Zhaoran",
        "title": "What and how does in-context learning learn? {B}ayesian model averaging, parameterization, and generalization"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "zhang2023and",
        "author": "Zhang, Yufeng and Zhang, Fengzhuo and Yang, Zhuoran and Wang, Zhaoran",
        "title": "What and how does in-context learning learn? {B}ayesian model averaging, parameterization, and generalization"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "zhang2023and",
        "author": "Zhang, Yufeng and Zhang, Fengzhuo and Yang, Zhuoran and Wang, Zhaoran",
        "title": "What and how does in-context learning learn? {B}ayesian model averaging, parameterization, and generalization"
      },
      {
        "key": "jeon2024information",
        "author": "Jeon, Hong Jun and Lee, Jason D and Lei, Qi and Van Roy, Benjamin",
        "title": "An information-theoretic analysis of in-context learning"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "garg2022can",
        "author": "Garg, Shivam and Tsipras, Dimitris and Liang, Percy S and Valiant, Gregory",
        "title": "What can transformers learn in-context? A case study of simple function classes"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "raventos2024pretraining",
        "author": "Ravent{\\'o}s, Allan and Paul, Mansheej and Chen, Feng and Ganguli, Surya",
        "title": "Pretraining task diversity and the emergence of non-{B}ayesian in-context learning for regression"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "pathak2023transformers",
        "author": "Pathak, Reese and Sen, Rajat and Kong, Weihao and Das, Abhimanyu",
        "title": "Transformers can optimally learn regression mixture models"
      },
      {
        "key": "panwar2023context",
        "author": "Panwar, Madhur and Ahuja, Kabir and Goyal, Navin",
        "title": "In-context learning through the {B}ayesian prism"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "von2023transformers",
        "author": "Von Oswald, Johannes and Niklasson, Eyvind and Randazzo, Ettore and Sacramento, Jo{\\~a}o and Mordvintsev, Alexander and Zhmoginov, Andrey and Vladymyrov, Max",
        "title": "Transformers learn in-context by gradient descent"
      },
      {
        "key": "akyurek2022learning",
        "author": "Aky{\\\"u}rek, Ekin and Schuurmans, Dale and Andreas, Jacob and Ma, Tengyu and Zhou, Denny",
        "title": "What learning algorithm is in-context learning? Investigations with linear models"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "chen2023extending",
        "author": "Chen, Shouyuan and Wong, Sherman and Chen, Liangjian and Tian, Yuandong",
        "title": "Extending context window of large language models via positional interpolation"
      },
      {
        "key": "su2024roformer",
        "author": "Su, Jianlin and Ahmed, Murtadha and Lu, Yu and Pan, Shengfeng and Bo, Wen and Liu, Yunfeng",
        "title": "Roformer: Enhanced transformer with rotary position embedding"
      },
      {
        "key": "press2021train",
        "author": "Press, Ofir and Smith, Noah A and Lewis, Mike",
        "title": "Train short, test long: Attention with linear biases enables input length extrapolation"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "li2023_manydems",
        "author": "Li, Mukai and Gong, Shansan and Feng, Jiangtao and Xu, Yiheng and Zhang, Jun and Wu, Zhiyong and Kong, Lingpeng",
        "title": "In-context learning with many demonstration examples"
      },
      {
        "key": "agarwal2024many",
        "author": "Agarwal, Rishabh and Singh, Avi and Zhang, Lei M and Bohnet, Bernd and Rosias, Luis and Chan, Stephanie and Zhang, Biao and Anand, Ankesh and Abbas, Zaheer and Nova, Azade and others",
        "title": "Many-shot in-context learning"
      },
      {
        "key": "anil2024many",
        "author": "Anil, Cem and Durmus, Esin and Rimsky, Nina and Sharma, Mrinank and Benton, Joe and Kundu, Sandipan and Batson, Joshua and Tong, Meg and Mu, Jesse and Ford, Daniel J and others",
        "title": "Many-shot jailbreaking"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "bertsch2024context",
        "author": "Bertsch, Amanda and Ivgi, Maor and Alon, Uri and Berant, Jonathan and Gormley, Matthew R and Neubig, Graham",
        "title": "In-context learning with long-context models: An in-depth exploration"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "hu2021lora",
        "author": "Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu",
        "title": "Lora: Low-rank adaptation of large language models"
      }
    ]
  }
]