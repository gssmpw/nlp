@Article{Afshar2021,
author={Afshar, Parnian
and Heidarian, Shahin
and Enshaei, Nastaran
and Naderkhani, Farnoosh
and Rafiee, Moezedin Javad
and Oikonomou, Anastasia
and Fard, Faranak Babaki
and Samimi, Kaveh
and Plataniotis, Konstantinos N.
and Mohammadi, Arash},
title={COVID-CT-MD, COVID-19 computed tomography scan dataset applicable in machine learning and deep learning},
journal={Scientific Data},
year={2021},
month={Apr},
day={29},
volume={8},
number={1},
pages={121},
abstract={Novel Coronavirus (COVID-19) has drastically overwhelmed more than 200 countries affecting millions and claiming almost 2 million lives, since its emergence in late 2019. This highly contagious disease can easily spread, and if not controlled in a timely fashion, can rapidly incapacitate healthcare systems. The current standard diagnosis method, the Reverse Transcription Polymerase Chain Reaction (RT- PCR), is time consuming, and subject to low sensitivity. Chest Radiograph (CXR), the first imaging modality to be used, is readily available and gives immediate results. However, it has notoriously lower sensitivity than Computed Tomography (CT), which can be used efficiently to complement other diagnostic methods. This paper introduces a new COVID-19 CT scan dataset, referred to as COVID-CT-MD, consisting of not only COVID-19 cases, but also healthy and participants infected by Community Acquired Pneumonia (CAP). COVID-CT-MD dataset, which is accompanied with lobe-level, slice-level and patient-level labels, has the potential to facilitate the COVID-19 research, in particular COVID-CT-MD can assist in development of advanced Machine Learning (ML) and Deep Neural Network (DNN) based solutions.},
issn={2052-4463},
doi={10.1038/s41597-021-00900-3},
url={https://doi.org/10.1038/s41597-021-00900-3}
}


@Article{Alharbi2022,
AUTHOR = {Alharbi, Amal H. and Hosni Mahmoud, Hanan A.},
TITLE = {Pneumonia Transfer Learning Deep Learning Model from Segmented X-rays},
JOURNAL = {Healthcare},
VOLUME = {10},
YEAR = {2022},
NUMBER = {6},
ARTICLE-NUMBER = {987},
URL = {https://www.mdpi.com/2227-9032/10/6/987},
PubMedID = {35742039},
ISSN = {2227-9032},
ABSTRACT = {Pneumonia is a common disease that occurs in many countries, more specifically, in poor countries. This disease is an obstructive pneumonia which has the same impression on pulmonary radiographs as other pulmonary diseases, which makes it hard to distinguish even for medical radiologists. Lately, image processing and deep learning models are established to rapidly and precisely diagnose pneumonia disease. In this research, we have predicted pneumonia diseases dependably from the X-ray images, employing image segmentation and machine learning models. A public labelled database is utilized with 4000 pneumonia disease X-rays and 4000 healthy X-rays. ImgNet and SqueezeNet are utilized for transfer learning from their previous computed weights. The proposed deep learning models are trained for classifying pneumonia and non-pneumonia cases. The following processes are presented in this paper: X-ray segmentation utilizing BoxENet architecture, X-ray classification utilizing the segmented chest images. We propose the improved BoxENet model by incorporating transfer learning from both ImgNet and SqueezeNet using a majority fusion model. Performance metrics such as accuracy, specificity, sensitivity and Dice are evaluated. The proposed Improved BoxENet model outperforms the other models in binary and multi-classification models. Additionally, the Improved BoxENet has higher speed compared to other models in both training and classification.},
DOI = {10.3390/healthcare10060987}
}





@INPROCEEDINGS{Alom2018,
  author={Alom, Md Zahangir and Yakopcic, Chris and Taha, Tarek M. and Asari, Vijayan K.},
  booktitle={NAECON 2018 - IEEE National Aerospace and Electronics Conference}, 
  title={Nuclei Segmentation with Recurrent Residual Convolutional Neural Networks based U-Net (R2U-Net)}, 
  year={2018},
  volume={},
  number={},
  pages={228-233},
  keywords={Deep learning;Image segmentation;Pathology;Thresholding (Imaging);Feature extraction;Convolutional neural networks;Task analysis;Deep Learning;Convolutional Neural Networks;UNet;R2U-Net;Nuclei Segmentation},
  doi={10.1109/NAECON.2018.8556686}}

@article{Amyar2020,
title = {Multi-task deep learning based CT imaging analysis for COVID-19 pneumonia: Classification and segmentation},
journal = {Computers in Biology and Medicine},
volume = {126},
pages = {104037},
year = {2020},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2020.104037},
url = {https://www.sciencedirect.com/science/article/pii/S0010482520303681},
author = {Amine Amyar and Romain Modzelewski and Hua Li and Su Ruan},
keywords = {Deep learning, Multitask learning, Image classification, Image segmentation, Coronavirus (COVID-19), Computed tomography images},
abstract = {This paper presents an automatic classification segmentation tool for helping screening COVID-19 pneumonia using chest CT imaging. The segmented lesions can help to assess the severity of pneumonia and follow-up the patients. In this work, we propose a new multitask deep learning model to jointly identify COVID-19 patient and segment COVID-19 lesion from chest CT images. Three learning tasks: segmentation, classification and reconstruction are jointly performed with different datasets. Our motivation is on the one hand to leverage useful information contained in multiple related tasks to improve both segmentation and classification performances, and on the other hand to deal with the problems of small data because each task can have a relatively small dataset. Our architecture is composed of a common encoder for disentangled feature representation with three tasks, and two decoders and a multi-layer perceptron for reconstruction, segmentation and classification respectively. The proposed model is evaluated and compared with other image segmentation techniques using a dataset of 1369 patients including 449 patients with COVID-19, 425 normal ones, 98 with lung cancer and 397 of different kinds of pathology. The obtained results show very encouraging performance of our method with a dice coefficient higher than 0.88 for the segmentation and an area under the ROC curve higher than 97% for the classification.}
}

@ARTICLE{Anthimopoulos2016,
  author={Anthimopoulos, Marios and Christodoulidis, Stergios and Ebner, Lukas and Christe, Andreas and Mougiakakou, Stavroula},
  journal={IEEE Transactions on Medical Imaging}, 
  title={Lung Pattern Classification for Interstitial Lung Diseases Using a Deep Convolutional Neural Network}, 
  year={2016},
  volume={35},
  number={5},
  pages={1207-1216},
  keywords={Lungs;Computed tomography;Diseases;Feature extraction;Convolution;Design automation;Neural networks;Convolutional neural networks;interstitial lung diseases;texture classification},
  doi={10.1109/TMI.2016.2535865}}

@Article{Esteva2017,
author={Esteva, Andre
and Kuprel, Brett
and Novoa, Roberto A.
and Ko, Justin
and Swetter, Susan M.
and Blau, Helen M.
and Thrun, Sebastian},
title={Dermatologist-level classification of skin cancer with deep neural networks},
journal={Nature},
year={2017},
month={Feb},
day={01},
volume={542},
number={7639},
pages={115-118},
abstract={An artificial intelligence trained to classify images of skin lesions as benign lesions or malignant skin cancers achieves the accuracy of board-certified dermatologists.},
issn={1476-4687},
doi={10.1038/nature21056},
url={https://doi.org/10.1038/nature21056}
}

@ARTICLE{Fan2020,
  author={Fan, Deng-Ping and Zhou, Tao and Ji, Ge-Peng and Zhou, Yi and Chen, Geng and Fu, Huazhu and Shen, Jianbing and Shao, Ling},
  journal={IEEE Transactions on Medical Imaging}, 
  title={Inf-Net: Automatic COVID-19 Lung Infection Segmentation From CT Images}, 
  year={2020},
  volume={39},
  number={8},
  pages={2626-2637},
  keywords={Computed tomography;Image segmentation;Lung;Training;Data models;Diseases;X-rays;COVID-19;COVID-19;CT image;infection segmentation;semi-supervised learning},
  doi={10.1109/TMI.2020.2996645}}


@Article{Gai2024,
author={Gai, Lulu
and Xing, Mengmeng
and Chen, Wei
and Zhang, Yi
and Qiao, Xu},
title={Comparing CNN-based and transformer-based models for identifying lung cancer: which is more effective?},
journal={Multimedia Tools and Applications},
year={2024},
month={Jun},
day={01},
volume={83},
number={20},
pages={59253-59269},
abstract={Lung cancer constitutes the most severe cause of cancer-related mortality. Recent evidence supports that early detection by means of computed tomography (CT) scans significantly reduces mortality rates. Given the remarkable progress of Vision Transformers (ViTs) in the field of computer vision, we have delved into comparing the performance of ViTs versus Convolutional Neural Networks (CNNs) for the automatic identification of lung cancer based on a dataset of 212 medical images. Importantly, neither ViTs nor CNNs require lung nodule annotations to predict the occurrence of cancer. To address the dataset limitations, we have trained both ViTs and CNNs with three advanced techniques: transfer learning, self-supervised learning, and sharpness-aware minimizer. Remarkably, we have found that CNNs achieve highly accurate prediction of a patient's cancer status, with an outstanding recall (93.4{\%}) and area under the Receiver Operating Characteristic curve (AUC) of 98.1{\%}, when trained with self-supervised learning. Our study demonstrates that both CNNs and ViTs exhibit substantial potential with the three strategies. However, CNNs are more effective than ViTs with the insufficient quantities of dataset.},
issn={1573-7721},
doi={10.1007/s11042-023-17644-4},
url={https://doi.org/10.1007/s11042-023-17644-4}
}


@article{Gordaliza2018,
  author = {Gordaliza, Pedro M. and Mu{\~{n}}oz-Barrutia, Arrate and Abella, M{\'o}nica and Desco, Manuel and Sharpe, Sally and Vaquero, Juan Jos{\'e}},
  title = {Unsupervised CT Lung Image Segmentation of a Mycobacterium Tuberculosis Infection Model},
  journal = {Scientific Reports},
  year = {2018},
  month = {Jun},
  day = {28},
  volume = {8},
  number = {1},
  pages = {9802},
  abstract = {Tuberculosis (TB) is an infectious disease caused by Mycobacterium tuberculosis that produces pulmonary damage. Radiological imaging is the preferred technique for the assessment of TB longitudinal course. Computer-assisted identification of biomarkers eases the work of the radiologist by providing a quantitative assessment of disease. Lung segmentation is the step before biomarker extraction. In this study, we present an automatic procedure that enables robust segmentation of damaged lungs that have lesions attached to the parenchyma and are affected by respiratory movement artifacts in a Mycobacterium Tuberculosis infection model. Its main steps are the extraction of the healthy lung tissue and the airway tree followed by elimination of the fuzzy boundaries. Its performance was compared with respect to a segmentation obtained using: (1) a semi-automatic tool and (2) an approach based on fuzzy connectedness. A consensus segmentation resulting from the majority voting of three experts' annotations was considered our ground truth. The proposed approach improves the overlap indicators (Dice similarity coefficient, 94{\%}{\thinspace}{\textpm}{\thinspace}4{\%}) and the surface similarity coefficients (Hausdorff distance, 8.64{\thinspace}mm{\thinspace}{\textpm}{\thinspace}7.36{\thinspace}mm) in the majority of the most difficult-to-segment slices. Results indicate that the refined lung segmentations generated could facilitate the extraction of meaningful quantitative data on disease burden.},
  issn = {2045-2322},
  doi = {10.1038/s41598-018-28100-x},
  url = {https://doi.org/10.1038/s41598-018-28100-x}
}


@Article{Hosny2018,
author={Hosny, Ahmed
and Parmar, Chintan
and Quackenbush, John
and Schwartz, Lawrence H.
and Aerts, Hugo J. W. L.},
title={Artificial intelligence in radiology},
journal={Nature Reviews Cancer},
year={2018},
month={Aug},
day={01},
volume={18},
number={8},
pages={500-510},
abstract={Artificial intelligence (AI) algorithms, particularly deep learning, have demonstrated remarkable progress in image-recognition tasks. Methods ranging from convolutional neural networks to variational autoencoders have found myriad applications in the medical image analysis field, propelling it forward at a rapid pace. Historically, in radiology practice, trained physicians visually assessed medical images for the detection, characterization and monitoring of diseases. AI methods excel at automatically recognizing complex patterns in imaging data and providing quantitative, rather than qualitative, assessments of radiographic characteristics. In this Opinion article, we establish a general understanding of AI methods, particularly those pertaining to image-based tasks. We explore how these methods could impact multiple facets of radiology, with a general focus on applications in oncology, and demonstrate ways in which these methods are advancing the field. Finally, we discuss the challenges facing clinical implementation and provide our perspective on how the domain could be advanced.},
issn={1474-1768},
doi={10.1038/s41568-018-0016-5},
url={https://doi.org/10.1038/s41568-018-0016-5}
}



@article{Jain2020,
title = {Pneumonia detection in chest X-ray images using convolutional neural networks and transfer learning},
journal = {Measurement},
volume = {165},
pages = {108046},
year = {2020},
issn = {0263-2241},
doi = {https://doi.org/10.1016/j.measurement.2020.108046},
url = {https://www.sciencedirect.com/science/article/pii/S0263224120305844},
author = {Rachna Jain and Preeti Nagrath and Gaurav Kataria and V. {Sirish Kaushik} and D. {Jude Hemanth}},
keywords = {Convolutional neural networks, Pneumonia detection, VGG Net, ResNet and Inception-v3},
abstract = {A large number of children die due to pneumonia every year worldwide. An estimated 1.2 million episodes of pneumonia were reported in children up to 5 years of age, of which 880,000 died in 2016. Hence, pneumonia is a major cause of death amongst children, with high prevalence rate in South Asia and Sub-Saharan Africa. Even in a developed country like the United States, pneumonia is among the top 10 causes of deaths. Early detection and treatment of pneumonia can reduce mortality rates among children significantly in countries having a high prevalence. Hence, this paper presents Convolutional Neural Network models to detect pneumonia using x-ray images. Several Convolutional Neural Networks were trained to classify x-ray images into two classes viz., pneumonia and non-pneumonia, by changing various parameters, hyperparameters and number of convolutional layers. Six models have been mentioned in the paper. First and second models consist of two and three convolutional layers, respectively. The other four models are pre-trained models, which are VGG16, VGG19, ResNet50, and Inception-v3. The first and second models achieve a validation accuracy of 85.26% and 92.31% respectively. The accuracy of VGG16, VGG19, ResNet50 and Inception-v3 are 87.28%, 88.46%, 77.56% and 70.99% respectively.}
}


@ARTICLE{Jiang2019,
  author={Jiang, Jue and Hu, Yu-Chi and Liu, Chia-Ju and Halpenny, Darragh and Hellmann, Matthew D. and Deasy, Joseph O. and Mageras, Gig and Veeraraghavan, Harini},
  journal={IEEE Transactions on Medical Imaging}, 
  title={Multiple Resolution Residually Connected Feature Streams for Automatic Lung Tumor Segmentation From CT Images}, 
  year={2019},
  volume={38},
  number={1},
  pages={134-144},
  keywords={Image resolution;Tumors;Streaming media;Lung;Cancer;Feature extraction;Image segmentation;Deep learning;segmentation;longitudinal;lung cancer;detection},
  doi={10.1109/TMI.2018.2857800}}


@article{Kong2020,
title = {Learning tree-structured representation for 3D coronary artery segmentation},
journal = {Computerized Medical Imaging and Graphics},
volume = {80},
pages = {101688},
year = {2020},
issn = {0895-6111},
doi = {https://doi.org/10.1016/j.compmedimag.2019.101688},
url = {https://www.sciencedirect.com/science/article/pii/S089561111930103X},
author = {Bin Kong and Xin Wang and Junjie Bai and Yi Lu and Feng Gao and Kunlin Cao and Jun Xia and Qi Song and Youbing Yin},
keywords = {Coronary computed tomography angiography, Coronary artery segmentation, Vessel segmentation, Tree-structured segmentation, Tree-structured ConvGRU},
abstract = {Extensive research has been devoted to the segmentation of the coronary artery. However, owing to its complex anatomical structure, it is extremely challenging to automatically segment the coronary artery from 3D coronary computed tomography angiography (CCTA). Inspired by recent ideas to use tree-structured long short-term memory (LSTM) to model the underlying tree structures for NLP tasks, we propose a novel tree-structured convolutional gated recurrent unit (ConvGRU) model to learn the anatomical structure of the coronary artery. However, unlike tree-structured LSTM proposed for semantic relatedness as well as sentiment classification in natural language processing, our tree-structured ConvGRU model considers the local spatial correlations in the input data as the convolutions are used for input-to-state as well as state-to-state transitions, thus more suitable for image analysis. To conduct voxel-wise segmentation, a tree-structured segmentation framework is presented. It consists of a fully convolutional network (FCN) for multi-scale discriminative feature extraction and the final prediction, and a tree-structured ConvGRU layer for anatomical structure modeling. The proposed framework is extensively evaluated on four large-scale 3D CCTA dataset (the largest to the best of our knowledge), and experiments show that our method is more accurate as well as efficient, compared with other coronary artery segmentation approaches.}
}


@article{Krittanawong2017,
title = {Artificial Intelligence in Precisi on Cardiovascular Medicine},
journal = {Journal of the American College of Cardiology},
volume = {69},
number = {21},
pages = {2657-2664},
year = {2017},
issn = {0735-1097},
doi = {https://doi.org/10.1016/j.jacc.2017.03.571},
url = {https://www.sciencedirect.com/science/article/pii/S0735109717368456},
author = {Chayakrit Krittanawong and HongJu Zhang and Zhen Wang and Mehmet Aydar and Takeshi Kitai},
keywords = {big data, cognitive computing, deep learning, machine learning},
abstract = {Artificial intelligence (AI) is a field of computer science that aims to mimic human thought processes, learning capacity, and knowledge storage. AI techniques have been applied in cardiovascular medicine to explore novel genotypes and phenotypes in existing diseases, improve the quality of patient care, enable cost-effectiveness, and reduce readmission and mortality rates. Over the past decade, several machine-learning techniques have been used for cardiovascular disease diagnosis and prediction. Each problem requires some degree of understanding of the problem, in terms of cardiovascular medicine and statistics, to apply the optimal machine-learning algorithm. In the near future, AI will result in a paradigm shift toward precision cardiovascular medicine. The potential of AI in cardiovascular medicine is tremendous; however, ignorance of the challenges may overshadow its potential clinical impact. This paper gives a glimpse of AI’s application in cardiovascular clinical care and discusses its potential role in facilitating precision cardiovascular medicine.}
}

@Article{Liu2019,
author={Liu, Xiaoxuan
and Faes, Livia
and Kale, Aditya U.
and Wagner, Siegfried K.
and Fu, Dun Jack
and Bruynseels, Alice
and Mahendiran, Thushika
and Moraes, Gabriella
and Shamdas, Mohith
and Kern, Christoph
and Ledsam, Joseph R.
and Schmid, Martin K.
and Balaskas, Konstantinos
and Topol, Eric J.
and Bachmann, Lucas M.
and Keane, Pearse A.
and Denniston, Alastair K.},
title={A comparison of deep learning performance against health-care professionals in detecting diseases from medical imaging: a systematic review and meta-analysis},
journal={The Lancet Digital Health},
year={2019},
month={Oct},
day={01},
publisher={Elsevier},
volume={1},
number={6},
pages={e271-e297},
issn={2589-7500},
doi={10.1016/S2589-7500(19)30123-2},
url={https://doi.org/10.1016/S2589-7500(19)30123-2}
}

@article{Manickam2021,
title = {Automated pneumonia detection on chest X-ray images: A deep learning approach with different optimizers and transfer learning architectures},
journal = {Measurement},
volume = {184},
pages = {109953},
year = {2021},
issn = {0263-2241},
doi = {https://doi.org/10.1016/j.measurement.2021.109953},
url = {https://www.sciencedirect.com/science/article/pii/S0263224121008885},
author = {Adhiyaman Manickam and Jianmin Jiang and Yu Zhou and Abhinav Sagar and Rajkumar Soundrapandiyan and R. {Dinesh Jackson Samuel}},
keywords = {Pneumonia Detection, Deep Learning, Transfer Learning, ResNet 50, Inception V3, Adam Optimizer, Stochastic Gradient Descent Optimizer, U-Net, Convolutional Neural Networks, Accuracy},
abstract = {Pneumonia is a disease that leads to the death of individuals within a short period since the flow of fluid in the lungs. Hence, initial diagnosis and drugs are very important to avoid the progress of the disease. This paper proposes a novel deep learning approach for automatic detection of pneumonia using deep transfer learning to simplify the detection process with improved accuracy. This work was aimed to preprocess the input chest X-ray images to identify the presence of pneumonia using U-Net architecture based segmentation and classifies the pneumonia as normal and abnormal (Bacteria, viral) using pre-trained on ImageNet dataset models such as ResNet50, InceptionV3, InceptionResNetV2. Besides, to extract the efficient features and improve accuracy of pre-trained models two optimizers, namely, Adam and Stochastic Gradient Descent (SGD) used and its performances are analyzed with batch sizes of 16 and 32. Based on the values obtained, the performances of undertaken pre-trained models are analyzed and compared with other Convolutional Neural Network (CNN) models such as DenseNet-169+SVM, VGG16, RetinaNet + Mask RCNN, VGG16 and Xception, Fully connected RCNN, etc using various measures. From the results observed that the proposed ResNet50 model work achieved 93.06% accuracy, 88.97 % precision rate, 96.78% Recall rate and 92.71% F1-score rate, which than is higher than the other models aforementioned.}
}

@Article{Negi2020,
author={Negi, Anuja
and Raj, Alex Noel Joseph
and Nersisson, Ruban
and Zhuang, Zhemin
and Murugappan, M.},
title={RDA-UNET-WGAN: An Accurate Breast Ultrasound Lesion Segmentation Using Wasserstein Generative Adversarial Networks},
journal={Arabian Journal for Science and Engineering},
year={2020},
month={Aug},
day={01},
volume={45},
number={8},
pages={6399-6410},
abstract={Early-stage detection of lesions is the best possible way to fight breast cancer, a disease with the highest malignancy ratio among women. Though several methods primarily based on deep learning have been proposed for tumor segmentation, it is still a challenging problem due to false positives and the precise boundary detection required for segmentation. In this paper, we propose a Generative Adversarial Network (GAN) based algorithm for segmenting the tumor in Breast Ultrasound images. The GAN model comprises of two modules: generator and discriminator. Residual-Dilated-Attention-Gate-UNet (RDAU-NET) is used as the generator which serves as a segmentation module and a CNN classifier is employed as the discriminator. To stabilize training, Wasserstein GAN (WGAN) algorithm has been used. The proposed hybrid deep learning model is called the WGAN-RDA-UNET. The model is assessed with several quantitative metrics and is also compared with existing methods both quantitatively and qualitatively. The overall Accuracy, PR-AUC, ROC-AUC and F1-score achieved were 0.98, 0.95, 0.89 and 0.88 respectively which are better than most conventional deep net models. The results also showcase the shortcomings of CNN, RDA U-Net and other models and how they can be rectified using the WGAN-RDA-UNET model.},
issn={2191-4281},
doi={10.1007/s13369-020-04480-z},
url={https://doi.org/10.1007/s13369-020-04480-z}
}

@misc{Rajpurkar2017,
      title={CheXNet: Radiologist-Level Pneumonia Detection on Chest X-Rays with Deep Learning}, 
      author={Pranav Rajpurkar and Jeremy Irvin and Kaylie Zhu and Brandon Yang and Hershel Mehta and Tony Duan and Daisy Ding and Aarti Bagul and Curtis Langlotz and Katie Shpanskaya and Matthew P. Lungren and Andrew Y. Ng},
      year={2017},
      eprint={1711.05225},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1711.05225}, 
}




@Article{Salehi2023,
AUTHOR = {Salehi, Ahmad Waleed and Khan, Shakir and Gupta, Gaurav and Alabduallah, Bayan Ibrahimm and Almjally, Abrar and Alsolai, Hadeel and Siddiqui, Tamanna and Mellit, Adel},
TITLE = {A Study of CNN and Transfer Learning in Medical Imaging: Advantages, Challenges, Future Scope},
JOURNAL = {Sustainability},
VOLUME = {15},
YEAR = {2023},
NUMBER = {7},
ARTICLE-NUMBER = {5930},
URL = {https://www.mdpi.com/2071-1050/15/7/5930},
ISSN = {2071-1050},
ABSTRACT = {This paper presents a comprehensive study of Convolutional Neural Networks (CNN) and transfer learning in the context of medical imaging. Medical imaging plays a critical role in the diagnosis and treatment of diseases, and CNN-based models have demonstrated significant improvements in image analysis and classification tasks. Transfer learning, which involves reusing pre-trained CNN models, has also shown promise in addressing challenges related to small datasets and limited computational resources. This paper reviews the advantages of CNN and transfer learning in medical imaging, including improved accuracy, reduced time and resource requirements, and the ability to address class imbalances. It also discusses challenges, such as the need for large and diverse datasets, and the limited interpretability of deep learning models. What factors contribute to the success of these networks? How are they fashioned, exactly? What motivated them to build the structures that they did? Finally, the paper presents current and future research directions and opportunities, including the development of specialized architectures and the exploration of new modalities and applications for medical imaging using CNN and transfer learning techniques. Overall, the paper highlights the significant potential of CNN and transfer learning in the field of medical imaging, while also acknowledging the need for continued research and development to overcome existing challenges and limitations.},
DOI = {10.3390/su15075930}
}

@Article{Sarvamangala2022,
author={Sarvamangala, D. R.
and Kulkarni, Raghavendra V.},
title={Convolutional neural networks in medical image understanding: a survey},
journal={Evolutionary Intelligence},
year={2022},
month={Mar},
day={01},
volume={15},
number={1},
pages={1-22},
abstract={Imaging techniques are used to capture anomalies of the human body. The captured images must be understood for diagnosis, prognosis and treatment planning of the anomalies. Medical image understanding is generally performed by skilled medical professionals. However, the scarce availability of human experts and the fatigue and rough estimate procedures involved with them limit the effectiveness of image understanding performed by skilled medical professionals. Convolutional neural networks (CNNs) are effective tools for image understanding. They have outperformed human experts in many image understanding tasks. This article aims to provide a comprehensive survey of applications of CNNs in medical image understanding. The underlying objective is to motivate medical image understanding researchers to extensively apply CNNs in their research and diagnosis. A brief introduction to CNNs has been presented. A discussion on CNN and its various award-winning frameworks have been presented. The major medical image understanding tasks, namely image classification, segmentation, localization and detection have been introduced. Applications of CNN in medical image understanding of the ailments of brain, breast, lung and other organs have been surveyed critically and comprehensively. A critical discussion on some of the challenges is also presented.},
issn={1864-5917},
doi={10.1007/s12065-020-00540-3},
url={https://doi.org/10.1007/s12065-020-00540-3}
}


@misc{Shamshad2022,
      title={Transformers in Medical Imaging: A Survey}, 
      author={Fahad Shamshad and Salman Khan and Syed Waqas Zamir and Muhammad Haris Khan and Munawar Hayat and Fahad Shahbaz Khan and Huazhu Fu},
      year={2022},
      eprint={2201.09873},
      archivePrefix={arXiv},
      primaryClass={eess.IV},
	  doi={https://doi.org/10.48550/arXiv.2201.09873},
      url={https://arxiv.org/abs/2201.09873}, 
}


@article{Sharma2023,
title = {A Deep Learning based model for the Detection of Pneumonia from Chest X-Ray Images using VGG-16 and Neural Networks},
journal = {Procedia Computer Science},
volume = {218},
pages = {357-366},
year = {2023},
note = {International Conference on Machine Learning and Data Engineering},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.01.018},
url = {https://www.sciencedirect.com/science/article/pii/S1877050923000182},
author = {Shagun Sharma and Kalpna Guleria},
keywords = {Deep Learning, VGG16, CNN, Pneumonia, Neural Networks, X-ray},
abstract = {Pneumonia is a viral infection which affects a significant proportion of individuals, especially in developing and penurious countries where contamination, overcrowded, and unsanitary living conditions are widespread, along with the lack of healthcare infrastructures. Pneumonia produces pericardial effusion, a disease wherein fluids fill the chest and create inhaling problems. It is a difficult step to recognize the presence of pneumonia quickly in order to receive treatment services and improve survival chances. Deep learning, is a field of artificial intelligence which is used in the successful development of prediction models. There are various ways of detecting pneumonia such as CT-scan, pulse oximetry, and many more among which the most common way is X-ray tomography. On the other hand, examining chest X-rays (CXR) is a tough process susceptible to subjective variability. In this work, a deep learning(DL) model using VGG16 is utilized for detecting and classifying pneumonia using two CXR image datasets. The VGG16 with Neural Networks (NN) provides an accuracy value of 92.15%, recall as 0.9308, precision as 0.9428, and F1-Score0.937 for the first dataset. Furthermore, the experiment using NN with VGG16 has been performed on another CXR dataset containing 6,436 images of pneumonia, normal and covid-19. The results for the second dataset provide accuracy, recall, precision, and F1-score as 95.4%, 0.954, 0.954, and 0.954, respectively. The research outcome exhibits that VGG16 with NN provides better performance than VGG16 with Support Vector Machine (SVM), VGG16 with K-Nearest Neighbor (KNN), VGG16 with Random Forest (RF), and VGG16 with Naïve Bayes (NB) for both datasets. Further, the proposed work results exhibit improved performance results for both datasets 1 and 2 in comparison to existing models.}
}

@misc{Simonyan2015,
      title={Very Deep Convolutional Networks for Large-Scale Image Recognition}, 
      author={Karen Simonyan and Andrew Zisserman},
      year={2015},
      eprint={1409.1556},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1409.1556}, 
}

@INPROCEEDINGS{Szegedy2016,
  author={Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jon and Wojna, Zbigniew},
  booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Rethinking the Inception Architecture for Computer Vision}, 
  year={2016},
  volume={},
  number={},
  pages={2818-2826},
  keywords={Convolution;Computer architecture;Training;Computational efficiency;Computer vision;Benchmark testing;Computational modeling},
  doi={10.1109/CVPR.2016.308}}


@InProceedings{Cicek2016,
author="{\c{C}}i{\c{c}}ek, {\"O}zg{\"u}n
and Abdulkadir, Ahmed
and Lienkamp, Soeren S.
and Brox, Thomas
and Ronneberger, Olaf",
editor="Ourselin, Sebastien
and Joskowicz, Leo
and Sabuncu, Mert R.
and Unal, Gozde
and Wells, William",
title="3D U-Net: Learning Dense Volumetric Segmentation from Sparse Annotation",
booktitle="Medical Image Computing and Computer-Assisted Intervention -- MICCAI 2016",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="424--432",
abstract="This paper introduces a network for volumetric segmentation that learns from sparsely annotated volumetric images. We outline two attractive use cases of this method: (1) In a semi-automated setup, the user annotates some slices in the volume to be segmented. The network learns from these sparse annotations and provides a dense 3D segmentation. (2) In a fully-automated setup, we assume that a representative, sparsely annotated training set exists. Trained on this data set, the network densely segments new volumetric images. The proposed network extends the previous u-net architecture from Ronneberger et al. by replacing all 2D operations with their 3D counterparts. The implementation performs on-the-fly elastic deformations for efficient data augmentation during training. It is trained end-to-end from scratch, i.e., no pre-trained network is required. We test the performance of the proposed method on a complex, highly variable 3D structure, the Xenopus kidney, and achieve good results for both use cases.",
isbn="978-3-319-46723-8"
}



@INPROCEEDINGS{He2016,
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Deep Residual Learning for Image Recognition}, 
  year={2016},
  volume={},
  number={},
  pages={770-778},
  keywords={Training;Degradation;Complexity theory;Image recognition;Neural networks;Visualization;Image segmentation},
  doi={10.1109/CVPR.2016.90}}


@Article{Shastri2022,
author={Shastri, Sourabh
and Kansal, Isha
and Kumar, Sachin
and Singh, Kuljeet
and Popli, Renu
and Mansotra, Vibhakar},
title={CheXImageNet: a novel architecture for accurate classification of Covid-19 with chest x-ray digital images using deep convolutional neural networks},
journal={Health and Technology},
year={2022},
month={Jan},
day={01},
volume={12},
number={1},
pages={193-204},
abstract={Many countries around the world have been influenced by Covid-19 which is a serious virus as it gets transmitted by human communication. Although, its syndrome is quite similar to the ordinary flu. The critical step involved in Covid-19 is the initial screening or testing of the infected patients. As there are no special detection tools, the demand for such diagnostic tools has been increasing continuously. So, it is eminently admissible to find out positive cases of this disease at the earliest so that the spreading of this dangerous virus can be controlled. Although, some methods for the detection of Covid-19 patients are available, which are performed upon respiratory based samples and among them, a critical approach for treatment is radiologic imaging or X-ray imaging. The latest conclusions obtained from X-ray digital imaging based algorithms and techniques recommend that such type of digital images may consist of significant facts regarding the SARS-CoV-2 virus. The utilization of Deep Neural Networks based methodologies clubbed with digital radiological imaging has been proved useful for accurately identifying this disease. This could also be adjuvant in conquering the problem of dearth of competent physicians in far-flung areas. In this paper, a CheXImageNet model has been introduced for detecting Covid-19 disease by using digital images of Chest X-ray with the help of an openly accessible dataset. Experiments for both binary class and multi-class have been performed in this work for benchmarking the effectiveness of the proposed work. An accuracy of 100{\$}{\$}{\backslash}{\%}{\$}{\$}is reported for both binary classification (having cases of Covid-19 and Normal X-Ray) and classification for three classes (including cases of Covid-19, Normal X-Ray and, cases of Pneumonia disease) respectively.},
issn={2190-7196},
doi={10.1007/s12553-021-00630-x},
url={https://doi.org/10.1007/s12553-021-00630-x}
}

@Article{Singh2024,
author={Singh, Sukhendra
and Kumar, Manoj
and Kumar, Abhay
and Verma, Birendra Kumar
and Abhishek, Kumar
and Selvarajan, Shitharth},
title={Efficient pneumonia detection using Vision Transformers on chest X-rays},
journal={Scientific Reports},
year={2024},
month={Jan},
day={30},
volume={14},
number={1},
pages={2487},
abstract={Pneumonia is a widespread and acute respiratory infection that impacts people of all ages. Early detection and treatment of pneumonia are essential for avoiding complications and enhancing clinical results. We can reduce mortality, improve healthcare efficiency, and contribute to the global battle against a disease that has plagued humanity for centuries by devising and deploying effective detection methods. Detecting pneumonia is not only a medical necessity but also a humanitarian imperative and a technological frontier. Chest X-rays are a frequently used imaging modality for diagnosing pneumonia. This paper examines in detail a cutting-edge method for detecting pneumonia implemented on the Vision Transformer (ViT) architecture on a public dataset of chest X-rays available on Kaggle. To acquire global context and spatial relationships from chest X-ray images, the proposed framework deploys the ViT model, which integrates self-attention mechanisms and transformer architecture. According to our experimentation with the proposed Vision Transformer-based framework, it achieves a higher accuracy of 97.61{\%}, sensitivity of 95{\%}, and specificity of 98{\%} in detecting pneumonia from chest X-rays. The ViT model is preferable for capturing global context, comprehending spatial relationships, and processing images that have different resolutions. The framework establishes its efficacy as a robust pneumonia detection solution by surpassing convolutional neural network (CNN) based architectures.},
issn={2045-2322},
doi={10.1038/s41598-024-52703-2},
url={https://doi.org/10.1038/s41598-024-52703-2}
}

@Article{Sivarajah2023,
author={Sivarajah, Uthayasankar
and Wang, Yichuan
and Olya, Hossein
and Mathew, Sherin},
title={Responsible Artificial Intelligence (AI) for Digital Health and Medical Analytics},
journal={Information Systems Frontiers},
year={2023},
month={Dec},
day={01},
volume={25},
number={6},
pages={2117-2122},
issn={1572-9419},
doi={10.1007/s10796-023-10412-7},
url={https://doi.org/10.1007/s10796-023-10412-7}
}


@article{Smith2020,
author = {Anthony C Smith and Emma Thomas and Centaine L Snoswell and Helen Haydon and Ateev Mehrotra and Jane Clemensen and Liam J Caffery},
title ={Telehealth for global emergencies: Implications for coronavirus disease 2019 (COVID-19)},
journal = {Journal of Telemedicine and Telecare},
volume = {26},
number = {5},
pages = {309-313},
year = {2020},
doi = {10.1177/1357633X20916567},
note ={PMID: 32196391},
URL = {https://doi.org/10.1177/1357633X20916567},
eprint = {https://doi.org/10.1177/1357633X20916567}
}


@article{Tong2018,
title = {Improved U-NET network for pulmonary nodules segmentation},
journal = {Optik},
volume = {174},
pages = {460-469},
year = {2018},
issn = {0030-4026},
doi = {https://doi.org/10.1016/j.ijleo.2018.08.086},
url = {https://www.sciencedirect.com/science/article/pii/S003040261831235X},
author = {Guofeng Tong and Yong Li and Huairong Chen and Qingchun Zhang and Huiying Jiang},
keywords = {U-NET network, Pulmonary nodules, Segmentation, Deep learning},
abstract = {Since pulmonary nodules in CT images are very small and easily confusing with other tissues, there are still many problems in the pulmonary nodule segmentation. This paper presents an improved lung nodule segmentation algorithm based on U-NET network. Firstly, CT images are transformed and normalized, and the lung parenchyma is obtained by simple and efficient morphological method. Then, the U-NET network is improved, which mainly includes the dataset rebuilding, convolutional layer, pooling layer and upsampled layer. And we introduced residual network, which has improved the network training effect. Besides, we designed batch standardization operation, which has speeded up the network training and improves the network stability. Finally, we used the new dataset to train and test the improved U-NET network. A large number of experiments show that the proposed method can effectively improve the segmentation accuracy of pulmonary nodules. It is a great work with theoretical and practical value.}
}


@inbook{Wang2019,
  author = {Wang, Xiaosong and Peng, Yifan and Lu, Le and Lu, Zhiyong and Bagheri, Mohammadhadi and Summers, Ronald M.},
  editor = {Lu, Le and Wang, Xiaosong and Carneiro, Gustavo and Yang, Lin},
  title = {ChestX-ray: Hospital-Scale Chest X-ray Database and Benchmarks on Weakly Supervised Classification and Localization of Common Thorax Diseases},
  booktitle = {Deep Learning and Convolutional Neural Networks for Medical Imaging and Clinical Informatics},
  year = {2019},
  publisher = {Springer International Publishing},
  address = {Cham},
  pages = {369--392},
  abstract = {The chest X-ray is one of the most commonly accessible radiological examinations for screening and diagnosis of many lung diseases. A tremendous number of X-ray imaging studies accompanied by radiological reports are accumulated and stored in many modern hospitals' picture archiving and communication systems (PACS). On the other side, it is still an open question how this type of hospital-size knowledge database containing invaluable imaging informatics (i.e., loosely labeled) can be used to facilitate the data-hungry deep learning paradigms in building truly large-scale high-precision computer-aided diagnosis (CAD) systems. In this chapter, we present a chest X-ray database, namely, "ChestX-ray," which comprises 121,120 frontal-view X-ray images of 30,805 unique patients with text-mined eight disease image labels (where each image can have multi-labels) from the associated radiological reports using natural language processing (NLP). Importantly, we demonstrate that these commonly occurring thoracic diseases can be detected and even spatially located via a unified weakly supervised multi-label image classification and disease localization framework, which is validated using our proposed dataset. Although the initial quantitative results are promising as reported, deep convolutional neural network-based "reading chest X-rays" (i.e., recognizing and locating the common disease patterns trained with only image-level labels) remains a strenuous task for fully automated high-precision CAD systems.},
  isbn = {978-3-030-13969-8},
  doi = {https://doi.org/10.1007/978-3-030-13969-8\_18}
}


@InProceedings{Ronneberger2015,
author="Ronneberger, Olaf
and Fischer, Philipp
and Brox, Thomas",
editor="Navab, Nassir
and Hornegger, Joachim
and Wells, William M.
and Frangi, Alejandro F.",
title="U-Net: Convolutional Networks for Biomedical Image Segmentation",
booktitle="Medical Image Computing and Computer-Assisted Intervention -- MICCAI 2015",
year="2015",
publisher="Springer International Publishing",
address="Cham",
pages="234--241",
abstract="There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net.",
isbn="978-3-319-24574-4"
}


@INPROCEEDINGS{Selvaraju2017,
  author={Selvaraju, Ramprasaath R. and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
  booktitle={2017 IEEE International Conference on Computer Vision (ICCV)}, 
  title={Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization}, 
  year={2017},
  volume={},
  number={},
  pages={618-626},
  keywords={Visualization;Cats;Dogs;Computer architecture;Knowledge discovery},
  doi={10.1109/ICCV.2017.74}}


@INPROCEEDINGS{Wang2017,
  author={Wang, Xiaosong and Peng, Yifan and Lu, Le and Lu, Zhiyong and Bagheri, Mohammadhadi and Summers, Ronald M.},
  booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={ChestX-Ray8: Hospital-Scale Chest X-Ray Database and Benchmarks on Weakly-Supervised Classification and Localization of Common Thorax Diseases}, 
  year={2017},
  volume={},
  number={},
  pages={3462-3471},
  keywords={Diseases;X-ray imaging;Pathology;Databases;Biomedical imaging;Machine learning;Image segmentation},
  doi={10.1109/CVPR.2017.369}}



@ARTICLE{Chowdhury2020,
  author={Chowdhury, Muhammad E. H. and Rahman, Tawsifur and Khandakar, Amith and Mazhar, Rashid and Kadir, Muhammad Abdul and Mahbub, Zaid Bin and Islam, Khandakar Reajul and Khan, Muhammad Salman and Iqbal, Atif and Emadi, Nasser Al and Reaz, Mamun Bin Ibne and Islam, Mohammad Tariqul},
  journal={IEEE Access}, 
  title={Can AI Help in Screening Viral and COVID-19 Pneumonia?}, 
  year={2020},
  volume={8},
  number={},
  pages={132665-132676},
  keywords={Diseases;Lung;Databases;X-ray imaging;Machine learning;Tools;COVID-19;Artificial intelligence;COVID-19 pneumonia;machine learning;transfer learning;viral pneumonia;computer-aided diagnostic tool},
  doi={10.1109/ACCESS.2020.3010287}}


@article{Rahman2021,
title = {Exploring the effect of image enhancement techniques on COVID-19 detection using chest X-ray images},
journal = {Computers in Biology and Medicine},
volume = {132},
pages = {104319},
year = {2021},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2021.104319},
url = {https://www.sciencedirect.com/science/article/pii/S001048252100113X},
author = {Tawsifur Rahman and Amith Khandakar and Yazan Qiblawey and Anas Tahir and Serkan Kiranyaz and Saad Bin {Abul Kashem} and Mohammad Tariqul Islam and Somaya {Al Maadeed} and Susu M. Zughaier and Muhammad Salman Khan and Muhammad E.H. Chowdhury},
keywords = {COVID-19, Image enhancement, Chest X-ray images, Convolutional neural networks, Lung segmentation},
abstract = {Computer-aided diagnosis for the reliable and fast detection of coronavirus disease (COVID-19) has become a necessity to prevent the spread of the virus during the pandemic to ease the burden on the healthcare system. Chest X-ray (CXR) imaging has several advantages over other imaging and detection techniques. Numerous works have been reported on COVID-19 detection from a smaller set of original X-ray images. However, the effect of image enhancement and lung segmentation of a large dataset in COVID-19 detection was not reported in the literature. We have compiled a large X-ray dataset (COVQU) consisting of 18,479 CXR images with 8851 normal, 6012 non-COVID lung infections, and 3616 COVID-19 CXR images and their corresponding ground truth lung masks. To the best of our knowledge, this is the largest public COVID positive database and the lung masks. Five different image enhancement techniques: histogram equalization (HE), contrast limited adaptive histogram equalization (CLAHE), image complement, gamma correction, and balance contrast enhancement technique (BCET) were used to investigate the effect of image enhancement techniques on COVID-19 detection. A novel U-Net model was proposed and compared with the standard U-Net model for lung segmentation. Six different pre-trained Convolutional Neural Networks (CNNs) (ResNet18, ResNet50, ResNet101, InceptionV3, DenseNet201, and ChexNet) and a shallow CNN model were investigated on the plain and segmented lung CXR images. The novel U-Net model showed an accuracy, Intersection over Union (IoU), and Dice coefficient of 98.63%, 94.3%, and 96.94%, respectively for lung segmentation. The gamma correction-based enhancement technique outperforms other techniques in detecting COVID-19 from the plain and the segmented lung CXR images. Classification performance from plain CXR images is slightly better than the segmented lung CXR images; however, the reliability of network performance is significantly improved for the segmented lung images, which was observed using the visualization technique. The accuracy, precision, sensitivity, F1-score, and specificity were 95.11%, 94.55%, 94.56%, 94.53%, and 95.59% respectively for the segmented lung images. The proposed approach with very reliable and comparable performance will boost the fast and robust COVID-19 detection using chest X-ray images.}
}



@Article{Degerli2021,
author={Degerli, Aysen
and Ahishali, Mete
and Yamac, Mehmet
and Kiranyaz, Serkan
and Chowdhury, Muhammad E. H.
and Hameed, Khalid
and Hamid, Tahir
and Mazhar, Rashid
and Gabbouj, Moncef},
title={COVID-19 infection map generation and detection from chest X-ray images},
journal={Health Information Science and Systems},
year={2021},
month={Apr},
day={01},
volume={9},
number={1},
pages={15},
abstract={Computer-aided diagnosis has become a necessity for accurate and immediate coronavirus disease 2019 (COVID-19) detection to aid treatment and prevent the spread of the virus. Numerous studies have proposed to use Deep Learning techniques for COVID-19 diagnosis. However, they have used very limited chest X-ray (CXR) image repositories for evaluation with a small number, a few hundreds, of COVID-19 samples. Moreover, these methods can neither localize nor grade the severity of COVID-19 infection. For this purpose, recent studies proposed to explore the activation maps of deep networks. However, they remain inaccurate for localizing the actual infestation making them unreliable for clinical use. This study proposes a novel method for the joint localization, severity grading, and detection of COVID-19 from CXR images by generating the so-called infection maps. To accomplish this, we have compiled the largest dataset with 119,316 CXR images including 2951 COVID-19 samples, where the annotation of the ground-truth segmentation masks is performed on CXRs by a novel collaborative human--machine approach. Furthermore, we publicly release the first CXR dataset with the ground-truth segmentation masks of the COVID-19 infected regions. A detailed set of experiments show that state-of-the-art segmentation networks can learn to localize COVID-19 infection with an F1-score of 83.20{\%}, which is significantly superior to the activation maps created by the previous methods. Finally, the proposed approach achieved a COVID-19 detection performance with 94.96{\%} sensitivity and 99.88{\%} specificity.},
issn={2047-2501},
doi={10.1007/s13755-021-00146-8},
url={https://doi.org/10.1007/s13755-021-00146-8}
}

@ARTICLE{9144185,
  author={Chowdhury, Muhammad E. H. and Rahman, Tawsifur and Khandakar, Amith and Mazhar, Rashid and Kadir, Muhammad Abdul and Mahbub, Zaid Bin and Islam, Khandakar Reajul and Khan, Muhammad Salman and Iqbal, Atif and Emadi, Nasser Al and Reaz, Mamun Bin Ibne and Islam, Mohammad Tariqul},
  journal={IEEE Access}, 
  title={Can AI Help in Screening Viral and COVID-19 Pneumonia?}, 
  year={2020},
  volume={8},
  number={},
  pages={132665-132676},
  keywords={Diseases;Lung;Databases;X-ray imaging;Machine learning;Tools;COVID-19;Artificial intelligence;COVID-19 pneumonia;machine learning;transfer learning;viral pneumonia;computer-aided diagnostic tool},
  doi={10.1109/ACCESS.2020.3010287}}

