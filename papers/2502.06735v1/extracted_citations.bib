@INPROCEEDINGS{Alom2018,
  author={Alom, Md Zahangir and Yakopcic, Chris and Taha, Tarek M. and Asari, Vijayan K.},
  booktitle={NAECON 2018 - IEEE National Aerospace and Electronics Conference}, 
  title={Nuclei Segmentation with Recurrent Residual Convolutional Neural Networks based U-Net (R2U-Net)}, 
  year={2018},
  volume={},
  number={},
  pages={228-233},
  keywords={Deep learning;Image segmentation;Pathology;Thresholding (Imaging);Feature extraction;Convolutional neural networks;Task analysis;Deep Learning;Convolutional Neural Networks;UNet;R2U-Net;Nuclei Segmentation},
  doi={10.1109/NAECON.2018.8556686}}

@InProceedings{Cicek2016,
author="{\c{C}}i{\c{c}}ek, {\"O}zg{\"u}n
and Abdulkadir, Ahmed
and Lienkamp, Soeren S.
and Brox, Thomas
and Ronneberger, Olaf",
editor="Ourselin, Sebastien
and Joskowicz, Leo
and Sabuncu, Mert R.
and Unal, Gozde
and Wells, William",
title="3D U-Net: Learning Dense Volumetric Segmentation from Sparse Annotation",
booktitle="Medical Image Computing and Computer-Assisted Intervention -- MICCAI 2016",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="424--432",
abstract="This paper introduces a network for volumetric segmentation that learns from sparsely annotated volumetric images. We outline two attractive use cases of this method: (1) In a semi-automated setup, the user annotates some slices in the volume to be segmented. The network learns from these sparse annotations and provides a dense 3D segmentation. (2) In a fully-automated setup, we assume that a representative, sparsely annotated training set exists. Trained on this data set, the network densely segments new volumetric images. The proposed network extends the previous u-net architecture from Ronneberger et al. by replacing all 2D operations with their 3D counterparts. The implementation performs on-the-fly elastic deformations for efficient data augmentation during training. It is trained end-to-end from scratch, i.e., no pre-trained network is required. We test the performance of the proposed method on a complex, highly variable 3D structure, the Xenopus kidney, and achieve good results for both use cases.",
isbn="978-3-319-46723-8"
}

@INPROCEEDINGS{He2016,
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Deep Residual Learning for Image Recognition}, 
  year={2016},
  volume={},
  number={},
  pages={770-778},
  keywords={Training;Degradation;Complexity theory;Image recognition;Neural networks;Visualization;Image segmentation},
  doi={10.1109/CVPR.2016.90}}

@article{Jain2020,
title = {Pneumonia detection in chest X-ray images using convolutional neural networks and transfer learning},
journal = {Measurement},
volume = {165},
pages = {108046},
year = {2020},
issn = {0263-2241},
doi = {https://doi.org/10.1016/j.measurement.2020.108046},
url = {https://www.sciencedirect.com/science/article/pii/S0263224120305844},
author = {Rachna Jain and Preeti Nagrath and Gaurav Kataria and V. {Sirish Kaushik} and D. {Jude Hemanth}},
keywords = {Convolutional neural networks, Pneumonia detection, VGG Net, ResNet and Inception-v3},
abstract = {A large number of children die due to pneumonia every year worldwide. An estimated 1.2 million episodes of pneumonia were reported in children up to 5Â years of age, of which 880,000 died in 2016. Hence, pneumonia is a major cause of death amongst children, with high prevalence rate in South Asia and Sub-Saharan Africa. Even in a developed country like the United States, pneumonia is among the top 10 causes of deaths. Early detection and treatment of pneumonia can reduce mortality rates among children significantly in countries having a high prevalence. Hence, this paper presents Convolutional Neural Network models to detect pneumonia using x-ray images. Several Convolutional Neural Networks were trained to classify x-ray images into two classes viz., pneumonia and non-pneumonia, by changing various parameters, hyperparameters and number of convolutional layers. Six models have been mentioned in the paper. First and second models consist of two and three convolutional layers, respectively. The other four models are pre-trained models, which are VGG16, VGG19, ResNet50, and Inception-v3. The first and second models achieve a validation accuracy of 85.26% and 92.31% respectively. The accuracy of VGG16, VGG19, ResNet50 and Inception-v3 are 87.28%, 88.46%, 77.56% and 70.99% respectively.}
}

@article{Manickam2021,
title = {Automated pneumonia detection on chest X-ray images: A deep learning approach with different optimizers and transfer learning architectures},
journal = {Measurement},
volume = {184},
pages = {109953},
year = {2021},
issn = {0263-2241},
doi = {https://doi.org/10.1016/j.measurement.2021.109953},
url = {https://www.sciencedirect.com/science/article/pii/S0263224121008885},
author = {Adhiyaman Manickam and Jianmin Jiang and Yu Zhou and Abhinav Sagar and Rajkumar Soundrapandiyan and R. {Dinesh Jackson Samuel}},
keywords = {Pneumonia Detection, Deep Learning, Transfer Learning, ResNet 50, Inception V3, Adam Optimizer, Stochastic Gradient Descent Optimizer, U-Net, Convolutional Neural Networks, Accuracy},
abstract = {Pneumonia is a disease that leads to the death of individuals within a short period since the flow of fluid in the lungs. Hence, initial diagnosis and drugs are very important to avoid the progress of the disease. This paper proposes a novel deep learning approach for automatic detection of pneumonia using deep transfer learning to simplify the detection process with improved accuracy. This work was aimed to preprocess the input chest X-ray images to identify the presence of pneumonia using U-Net architecture based segmentation and classifies the pneumonia as normal and abnormal (Bacteria, viral) using pre-trained on ImageNet dataset models such as ResNet50, InceptionV3, InceptionResNetV2. Besides, to extract the efficient features and improve accuracy of pre-trained models two optimizers, namely, Adam and Stochastic Gradient Descent (SGD) used and its performances are analyzed with batch sizes of 16 and 32. Based on the values obtained, the performances of undertaken pre-trained models are analyzed and compared with other Convolutional Neural Network (CNN) models such as DenseNet-169+SVM, VGG16, RetinaNet + Mask RCNN, VGG16 and Xception, Fully connected RCNN, etc using various measures. From the results observed that the proposed ResNet50 model work achieved 93.06% accuracy, 88.97 % precision rate, 96.78% Recall rate and 92.71% F1-score rate, which than is higher than the other models aforementioned.}
}

@misc{Rajpurkar2017,
      title={CheXNet: Radiologist-Level Pneumonia Detection on Chest X-Rays with Deep Learning}, 
      author={Pranav Rajpurkar and Jeremy Irvin and Kaylie Zhu and Brandon Yang and Hershel Mehta and Tony Duan and Daisy Ding and Aarti Bagul and Curtis Langlotz and Katie Shpanskaya and Matthew P. Lungren and Andrew Y. Ng},
      year={2017},
      eprint={1711.05225},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1711.05225}, 
}

@InProceedings{Ronneberger2015,
author="Ronneberger, Olaf
and Fischer, Philipp
and Brox, Thomas",
editor="Navab, Nassir
and Hornegger, Joachim
and Wells, William M.
and Frangi, Alejandro F.",
title="U-Net: Convolutional Networks for Biomedical Image Segmentation",
booktitle="Medical Image Computing and Computer-Assisted Intervention -- MICCAI 2015",
year="2015",
publisher="Springer International Publishing",
address="Cham",
pages="234--241",
abstract="There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net.",
isbn="978-3-319-24574-4"
}

@Article{Salehi2023,
AUTHOR = {Salehi, Ahmad Waleed and Khan, Shakir and Gupta, Gaurav and Alabduallah, Bayan Ibrahimm and Almjally, Abrar and Alsolai, Hadeel and Siddiqui, Tamanna and Mellit, Adel},
TITLE = {A Study of CNN and Transfer Learning in Medical Imaging: Advantages, Challenges, Future Scope},
JOURNAL = {Sustainability},
VOLUME = {15},
YEAR = {2023},
NUMBER = {7},
ARTICLE-NUMBER = {5930},
URL = {https://www.mdpi.com/2071-1050/15/7/5930},
ISSN = {2071-1050},
ABSTRACT = {This paper presents a comprehensive study of Convolutional Neural Networks (CNN) and transfer learning in the context of medical imaging. Medical imaging plays a critical role in the diagnosis and treatment of diseases, and CNN-based models have demonstrated significant improvements in image analysis and classification tasks. Transfer learning, which involves reusing pre-trained CNN models, has also shown promise in addressing challenges related to small datasets and limited computational resources. This paper reviews the advantages of CNN and transfer learning in medical imaging, including improved accuracy, reduced time and resource requirements, and the ability to address class imbalances. It also discusses challenges, such as the need for large and diverse datasets, and the limited interpretability of deep learning models. What factors contribute to the success of these networks? How are they fashioned, exactly? What motivated them to build the structures that they did? Finally, the paper presents current and future research directions and opportunities, including the development of specialized architectures and the exploration of new modalities and applications for medical imaging using CNN and transfer learning techniques. Overall, the paper highlights the significant potential of CNN and transfer learning in the field of medical imaging, while also acknowledging the need for continued research and development to overcome existing challenges and limitations.},
DOI = {10.3390/su15075930}
}

@INPROCEEDINGS{Selvaraju2017,
  author={Selvaraju, Ramprasaath R. and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
  booktitle={2017 IEEE International Conference on Computer Vision (ICCV)}, 
  title={Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization}, 
  year={2017},
  volume={},
  number={},
  pages={618-626},
  keywords={Visualization;Cats;Dogs;Computer architecture;Knowledge discovery},
  doi={10.1109/ICCV.2017.74}}

@article{Sharma2023,
title = {A Deep Learning based model for the Detection of Pneumonia from Chest X-Ray Images using VGG-16 and Neural Networks},
journal = {Procedia Computer Science},
volume = {218},
pages = {357-366},
year = {2023},
note = {International Conference on Machine Learning and Data Engineering},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.01.018},
url = {https://www.sciencedirect.com/science/article/pii/S1877050923000182},
author = {Shagun Sharma and Kalpna Guleria},
keywords = {Deep Learning, VGG16, CNN, Pneumonia, Neural Networks, X-ray},
abstract = {Pneumonia is a viral infection which affects a significant proportion of individuals, especially in developing and penurious countries where contamination, overcrowded, and unsanitary living conditions are widespread, along with the lack of healthcare infrastructures. Pneumonia produces pericardial effusion, a disease wherein fluids fill the chest and create inhaling problems. It is a difficult step to recognize the presence of pneumonia quickly in order to receive treatment services and improve survival chances. Deep learning, is a field of artificial intelligence which is used in the successful development of prediction models. There are various ways of detecting pneumonia such as CT-scan, pulse oximetry, and many more among which the most common way is X-ray tomography. On the other hand, examining chest X-rays (CXR) is a tough process susceptible to subjective variability. In this work, a deep learning(DL) model using VGG16 is utilized for detecting and classifying pneumonia using two CXR image datasets. The VGG16 with Neural Networks (NN) provides an accuracy value of 92.15%, recall as 0.9308, precision as 0.9428, and F1-Score0.937 for the first dataset. Furthermore, the experiment using NN with VGG16 has been performed on another CXR dataset containing 6,436 images of pneumonia, normal and covid-19. The results for the second dataset provide accuracy, recall, precision, and F1-score as 95.4%, 0.954, 0.954, and 0.954, respectively. The research outcome exhibits that VGG16 with NN provides better performance than VGG16 with Support Vector Machine (SVM), VGG16 with K-Nearest Neighbor (KNN), VGG16 with Random Forest (RF), and VGG16 with NaÃ¯ve Bayes (NB) for both datasets. Further, the proposed work results exhibit improved performance results for both datasets 1 and 2 in comparison to existing models.}
}

@misc{Simonyan2015,
      title={Very Deep Convolutional Networks for Large-Scale Image Recognition}, 
      author={Karen Simonyan and Andrew Zisserman},
      year={2015},
      eprint={1409.1556},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1409.1556}, 
}

@INPROCEEDINGS{Szegedy2016,
  author={Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jon and Wojna, Zbigniew},
  booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Rethinking the Inception Architecture for Computer Vision}, 
  year={2016},
  volume={},
  number={},
  pages={2818-2826},
  keywords={Convolution;Computer architecture;Training;Computational efficiency;Computer vision;Benchmark testing;Computational modeling},
  doi={10.1109/CVPR.2016.308}}

@INPROCEEDINGS{Wang2017,
  author={Wang, Xiaosong and Peng, Yifan and Lu, Le and Lu, Zhiyong and Bagheri, Mohammadhadi and Summers, Ronald M.},
  booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={ChestX-Ray8: Hospital-Scale Chest X-Ray Database and Benchmarks on Weakly-Supervised Classification and Localization of Common Thorax Diseases}, 
  year={2017},
  volume={},
  number={},
  pages={3462-3471},
  keywords={Diseases;X-ray imaging;Pathology;Databases;Biomedical imaging;Machine learning;Image segmentation},
  doi={10.1109/CVPR.2017.369}}

@inbook{Wang2019,
  author = {Wang, Xiaosong and Peng, Yifan and Lu, Le and Lu, Zhiyong and Bagheri, Mohammadhadi and Summers, Ronald M.},
  editor = {Lu, Le and Wang, Xiaosong and Carneiro, Gustavo and Yang, Lin},
  title = {ChestX-ray: Hospital-Scale Chest X-ray Database and Benchmarks on Weakly Supervised Classification and Localization of Common Thorax Diseases},
  booktitle = {Deep Learning and Convolutional Neural Networks for Medical Imaging and Clinical Informatics},
  year = {2019},
  publisher = {Springer International Publishing},
  address = {Cham},
  pages = {369--392},
  abstract = {The chest X-ray is one of the most commonly accessible radiological examinations for screening and diagnosis of many lung diseases. A tremendous number of X-ray imaging studies accompanied by radiological reports are accumulated and stored in many modern hospitals' picture archiving and communication systems (PACS). On the other side, it is still an open question how this type of hospital-size knowledge database containing invaluable imaging informatics (i.e., loosely labeled) can be used to facilitate the data-hungry deep learning paradigms in building truly large-scale high-precision computer-aided diagnosis (CAD) systems. In this chapter, we present a chest X-ray database, namely, "ChestX-ray," which comprises 121,120 frontal-view X-ray images of 30,805 unique patients with text-mined eight disease image labels (where each image can have multi-labels) from the associated radiological reports using natural language processing (NLP). Importantly, we demonstrate that these commonly occurring thoracic diseases can be detected and even spatially located via a unified weakly supervised multi-label image classification and disease localization framework, which is validated using our proposed dataset. Although the initial quantitative results are promising as reported, deep convolutional neural network-based "reading chest X-rays" (i.e., recognizing and locating the common disease patterns trained with only image-level labels) remains a strenuous task for fully automated high-precision CAD systems.},
  isbn = {978-3-030-13969-8},
  doi = {https://doi.org/10.1007/978-3-030-13969-8\_18}
}

