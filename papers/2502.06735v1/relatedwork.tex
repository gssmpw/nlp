\section{Related Work}
The related work encompasses a breadth of research efforts to leverage deep learning techniques for COVID-19 diagnosis, pneumonia detection, and semantic segmentation in medical imaging. Wang et al. \cite{Wang2019} have explored deep learning models for COVID-19 diagnosis using chest X-ray and CT images, showcasing promising accuracy in distinguishing COVID-19 cases from other pneumonia types. Semantic segmentation techniques, notably exemplified by the U-Net architecture as introduced by Ronneberger et al. \cite{Ronneberger2015}, have been employed by Salehi et al. \cite{Salehi2023} and Çiçek et al. (2016) to segment lung regions and identify abnormalities in chest X-ray and CT images. Additionally, the importance of explainable deep learning in healthcare, exemplified by attention mechanisms and Grad-CAM visualization as discussed by Rajpurkar et al. \cite{Rajpurkar2017} and Selvaraju et al. \cite{Selvaraju2017}, has been emphasized to aid clinicians in understanding and validating AI-driven diagnostic outcomes. Pneumonia detection studies, including CheXNet by Rajpurkar et al. \cite{Rajpurkar2017}, have demonstrated the feasibility of deep learning models in accurately identifying pneumonia on chest X-rays. Finally, rigorous validation efforts, such as those conducted by Wang et al. \cite{Wang2019} with the COVID-Net initiative and Wang et al. \cite{Wang2017} with the ChestX-ray8 dataset, have provided benchmark datasets and evaluation frameworks for assessing the performance of deep learning models in COVID-19 diagnosis and pneumonia detection tasks. By building upon these foundational works, our research aims to contribute novel methodologies and insights to enhance the accuracy and efficiency of COVID-19 diagnosis and pneumonia assessment in medical imaging.

\subsection{VGG-16}
The VGG-16 model, a CNN architecture, was introduced by Simonyan and Zisserman \cite{Simonyan2015} \cite{Sharma2023}. It is renowned for its simplicity and effectiveness in image classification tasks. The "16" in its name refers to the total number of layers in the network, including 13 convolutional layers and 3 fully connected layers. VGG-16 has a uniform architecture with small 3x3 convolutional filters, followed by max-pooling layers to downsample the spatial dimensions of the feature maps. This architecture helps in learning hierarchical features of increasing complexity from input images. Despite its effectiveness, VGG-16 is computationally expensive and memory-intensive, which limits its usage in resource-constrained environments. However, it serves as a foundational model in deep learning. It has paved the way for more advanced architectures, such as ResNet and Inception, while still being widely used as a benchmark in research and industry applications.

\subsection{VGG-19 Model}
The VGG-19 model, an extension of the VGG-16 architecture, was also developed by Simonyan and Zisserman \cite{Simonyan2015} \cite{Jain2020}. Like VGG-16, it is a CNN designed for image classification tasks. The "19" in its name denotes the total number of layers, which includes 16 convolutional layers and 3 fully connected layers. VGG-19 follows a similar architecture to VGG-16, with stacks of 3x3 convolutional layers and max-pooling layers to downsample the feature maps. However, VGG-19 includes more convolutional layers than VGG-16, allowing it to capture more intricate features from input images. This deeper architecture enables VGG-19 to learn more complex representations but also increases computational requirements. As with VGG-16, VGG-19 is widely used as a benchmark in deep learning for tasks such as image classification, object detection, and feature extraction. While its deep architecture contributes to its effectiveness in capturing detailed features, it also makes it computationally expensive, limiting its usage in resource-constrained environments.

\subsection{InceptionV3 Model}
The Inception v3 model, developed by Szegedy et al. \cite{Szegedy2016} \cite{Jain2020}, is a CNN architecture designed for image classification and object recognition tasks. It improves upon its predecessor, Inception v1, with enhancements to improve accuracy and efficiency. One of the key features of Inception v3 is its use of "inception modules," which perform parallel convolutions at different spatial scales and concatenate their outputs. This design allows the network to capture a wide range of features at multiple levels of abstraction, leading to improved performance. Additionally, Inception v3 incorporates techniques such as batch normalization, factorized convolutions, and aggressive regularization to enhance performance further and reduce overfitting. Inception v3 is known for its high accuracy on benchmark datasets such as ImageNet, where it achieved top results in image classification competitions. It has also been widely used in various applications such as image recognition, object detection, and image segmentation. Despite its effectiveness, Inception v3 is computationally intensive, requiring significant computational resources for training and inference.

\subsection{ResNet-50 Model}
The ResNet-50 model, introduced by He et al. \cite{He2016} \cite{Manickam2021}, is a CNN architecture that belongs to the ResNet (Residual Network) family. It addresses the problem of vanishing gradients in deep neural networks by introducing skip connections or "residual blocks." ResNet-50 consists of 50 layers and employs these residual blocks to enable the training of very deep neural networks. These blocks contain shortcut connections that allow gradients to flow directly through the network, mitigating the degradation problem commonly encountered in deep networks. This architecture facilitates the training of deeper models without suffering from diminishing performance. ResNet-50 has achieved notable success in various computer vision tasks, including image classification, object detection, and image segmentation. It has been widely adopted in both research and industry due to its effectiveness in learning highly complex features from images while maintaining relatively efficient computational requirements compared to other deep architectures. Additionally, pre-trained versions of ResNet-50 on large datasets such as ImageNet are often used as feature extractors or fine-tuned for specific tasks, leveraging the learned representations for transfer learning.

\subsection{CheXNet}
CheXNet, developed by Rajpurkar et al. \cite{Rajpurkar2017}, is a deep learning model that targets explicitly detecting pneumonia from chest X-rays. Utilizing DenseNet,a 121-layer CNN, CheXNet surpasses previous approaches and even outperforms radiologists regarding pneumonia detection accuracy. The model is trained on a large dataset of chest X-ray images labeled with up to 14 different thoracic pathologies, making it a robust solution for identifying pneumonia and other common thorax diseases. CheXNet's effectiveness has been proven through extensive testing, where it achieved a high level of precision and recall, demonstrating the significant potential of deep learning technologies in transforming diagnostic practices in the healthcare sector.

\subsection{U-Net Architecture}
The U-Net architecture, initially developed by Ronneberger et al. \cite{Ronneberger2015}, has become a cornerstone in medical image segmentation. Its unique design, characterized by a contracting path to capture context and a symmetric expanding path that enables precise localization, has proven particularly effective for segmenting lung tissue and identifying pathologies in chest X-rays and CT images. The U-Net's ability to operate with limited training data while still producing high-quality segmentations has made it especially valuable in medical applications where annotated images are scarce. This architecture has been adapted and extended in numerous studies, such as those by Çiçek et al. \cite{Cicek2016} and Alom et al. \cite{Alom2018}, who have introduced modifications to enhance its performance and adaptability to new challenges within medical imaging.