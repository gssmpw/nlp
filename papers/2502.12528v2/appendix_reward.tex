\section{Omitted Details for Delay-as-Reward}\label{app: reward}
In this section, we show our results for the delay-as-reward setting. The difference compared with the delay-as-loss setting is that now, $\mu_a=\inner{a,\theta}+\epsilon_a\in[0,1]$ represents the expected reward of picking action $a$, where $|\epsilon_a|\leq \epsilon$ for all $a\in\calA$. The learner's goal is to minimize the pseudo regret defined as follows:
\begin{align}\label{eqn:reward-regret}
    \Reg\triangleq T\max_{a\in\calA}\inner{a,\theta} - \E\left[\sum_{t=1}^T\inner{a_t,\theta}\right].
\end{align}
 Define $\Delta_a = \inner{a^\star-a,\theta}$ as the suboptimality gap of action $a$, where $a^\star \in \argmax_{a\in\calA}\inner{a, \theta}$, and $\mu^\star \triangleq \max_{a\in\calA}\mu_a$ as the reward of the optimal action. Again, note that due to the misspecification, $\mu^\star$ may not necessarily be $\mu_{a^\star}$. Define $\Delta_{\min} = \min_{a\in \calA, \Delta_a>0}\Delta_a$ to be the minimum non-zero sub-optimality gap. The delay at round $t$ is still defined as $d_t=D\cdot u_t$, and $d^\star = D\cdot \mu^\star$ is  the expected delay of the optimal action. We also define $d(a)=D\mu_a$ to be the expected delay for action $a$.

\newpage
\subsection{Algorithm for Linear Bandits with Delay-as-Reward}
We list our algorithm for the reward case in \pref{alg:rewardLBmis} for completeness. The algorithm shares the same idea as \pref{alg:lossLBmis}.

\setcounter{AlgoLine}{0}
\begin{algorithm}[H]
\caption{Phased Elimination for Linear Bandits with Delay-as-Reward}\label{alg:rewardLBmis}

\nl Input: maximum possible delay $D$, action set $\calA$, $\beta>0$, a misspecification level $\epsilon$. 

\nl Initialize optimal reward guess $B=1$.

\nl Initialize active action set $\calA_1=\calA$.  \label{line:reward-restart} 

\nl \For{$m=1,2,\dots,$}{
    \nl Find $\calS_m=\{a_{m,1},\dots,a_{m,|\calS_m|}\}$ to be the volumetric spanner of $\calA_m$, where $|\calS_m|= 3n$. \label{line:volume-reward}
    
    \nl Pick each $a\in \calS_m$ $2^m$ times in a round-robin way. \label{line:round-robin-reward}

    \nl Let $\calI_m$ contain all the rounds in this epoch.
    
    \nl For all $a\in \calS_m$, calculate the following quantities
    \begin{align}
        &\hat{\mu}_{m}^+(a)=\frac{1}{2^m}\Big(\sum_{\tau\in \obs_m(a)}u_{\tau} + \sum_{\tau\in \unobs_m(a)}1\Big), \\
        &\hat{\mu}_{m}^-(a)=\frac{1}{2^m}\sum_{\tau\in \obs_m(a)}u_{\tau}, \\
        &\hat{\mu}_{m,1}^{+}(a)=\hat{\mu}^{+}_{m}(a)+\frac{\beta}{2^{m/2}}\|a\|_2, \label{eqn:reward-ucb-linear-1-mis}\\
        &\hat{\mu}_{m,1}^{-}(a)=\hat{\mu}^{-}_{m}(a)-\frac{\beta}{2^{m/2}}\|a\|_2,\label{eqn:reward-lcb-linear-1-mis}\\
        &\hat{\mu}_m^{F}(a)=\frac{1}{\unbiasSize_m(a)}\sum_{\tau\in \unbias_m(a)}u_{\tau},\\
        &\hat{\mu}_{m,2}^{+}(a)=\hat{\mu}_m^F(a)+\frac{\beta}{\sqrt{\unbiasSize_m(a)}}\|a\|_2, \label{eqn:reward-ucb-linear-2-mis}\\
        &\hat{\mu}_{m,2}^{-}(a)=\hat{\mu}_m^F(a)-\frac{\beta}{\sqrt{\unbiasSize_m(a)}}\|a\|_2, \label{eqn:reward-lcb-linear-2-mis}
    \end{align}
    where $\unbiasSize_m(a) = |\unbias_m(a)|$, $\unbias_m(a) = \{\tau\in \calI_m: \tau+D\in\calI_m, a_{\tau}=a\}$, $\obs_m(a) = \{\tau\in \calI_m: \tau+d_{\tau}\in\calI_m, a_{\tau}=a\}$, and
    $\unobs_m(a)= \{\tau\in \calI_m: a_{\tau}=a\}\setminus\obs_m(a)$.

    \nl \For{each $a\in \calA_m$}{
        \nl \label{line: decompose-rewward}
        Decompose $a$ as $a=\sum_{i=1}^{|S_m|}\lambda_{m,i}^{(a)}a_{m,i}$ with $\|\lambda_{m}^{(a)}\|_2\leq 1$ and calculate 
        {\small
        \begin{align}
            &\LCB_{m}(a)=\sum_{i=1}^{|\calS_m|}\lambda_{m,i}^{(a)}\cdot\hat{\mu}_{m,2}^{-\sgn(\lambda_{m,i}^{(a)})}(a_{m,i}), \label{eqn:reward-ucb-f-all-action-mis} \\
            &\UCB_m(a) = \max_{j\in \{1,2\}}\{\UCB_{m,j}(a)\} \;\;\text{where} \nonumber  \\
            & \UCB_{m,j}(a)=\sum_{i=1}^{|\calS_m|}\lambda_{m,i}^{(a)}\cdot\hat{\mu}_{m,j}^{\sgn(\lambda_{m,i}^{(a)})}(a_{m,i}),\label{eqn:reward-lcb-f-all-action-mis}
        \end{align}
        }
    }
    
    \nl Set $\calA_{m+1} = \calA_m$.
    
    \nl \For{$a_1\in \calA_m$}{
        \nl \label{line:reward_eliminate_miss}\If{$\exists a_2\in \calA_m$, such that $\max\{\LCB_m(a_2),B\} \geq \UCB_m(a_1)+4\sqrt{3n}\epsilon $}
        {
         \nl Eliminate $a_1$ from $\calA_{m+1}$.
        }
    }
    \nl \If{$\calA_{m+1}$ is empty}{
        Set $B\leftarrow B/2$ and go to \pref{line:reward-restart}.
    }
}
\end{algorithm}

\subsection{Regret Guarantees}\label{app: reward-regret}
In this section, we show the theoretical guarantees for our algorithm in the delay-as-reward setting.

\begin{theorem}\label{thm:reward-main}
    \pref{alg:rewardLBmis} with $\beta = \sqrt{2\log(KT^3)}$ guarantees that
    \begin{align*}
        \Reg &\leq \order\left(\min\left\{\frac{n^2\log(KT)\log(T/n)\log(1/\mu^\star)}{\Delta_{\min}}, n\sqrt{T\log(KT)\log(1/\mu^\star)}\right\}+\epsilon\sqrt{n}T\right)\\
        &\qquad+\order\left(\min\left\{\sum_{j=0}^{\lceil\log_2(1/\mu^\star)\rceil}\sum_{m=1}^{\lceil\log_2(|\calT_{2^{-j}}|/3n\rceil}\sum_{i=1}^{3n} d(a_{m-1,i}^{(2^{-j})}), D\Delta_{\max}\log(1/\mu^\star)\log(T/n)\right\}\right),
    \end{align*}
    where $\{a_{m,i}^{(B)}\}_{i=1}^{3n}$ represents the set of volumetric spanner at epoch $m$ with the optimal reward guess $B$. 
\end{theorem}

Similar to the analysis in \pref{app:loss}, our analysis is based on the condition that \pref{event:misLoss} holds, which happens with probability $1-\frac{2}{T^2}$ according to \pref{lem:high-prob-event}. The following lemma is a counterpart of \pref{lem:end-of-B}, providing an upper bound of the number of guesses on the optimal reward $B$.

\begin{lemma}\label{lem:end-of-B-reward}
    Suppose that \pref{event:misLoss} holds. If $B\leq \mu^\star$, then $a^\star\in \calA_m$ for all $m$.
\end{lemma}
\begin{proof}
    Since \pref{event:misLoss} holds, we have, we know that for all $a\in\calA_m$, $\UCB_m(a)+\sqrt{|\calS_m|}\epsilon\geq \inner{a,\theta}$, $\LCB_m(a)+\sqrt{|\calS_m|}\epsilon\leq \inner{a,\theta}$
    If $B\leq \mu^\star$, then we have $a^\star$ never eliminated since for any $a\in\calA_m$,
    \begin{align*}
         \UCB_{m}(a^\star) +2\epsilon\sqrt{|\calS_m|} &\geq \max_{a\in\calA}\{\inner{a,\theta}+\epsilon_a\} \geq \mu^\star \geq B,\\
         \UCB_{m}(a^\star) +4\epsilon\sqrt{|\calS_m|} &\geq \mu^\star + 2\epsilon\sqrt{|\calS_m|} \geq \inner{a,\theta}  + \epsilon\sqrt{|\calS_m|}\geq \LCB_m(a).
    \end{align*}
    Therefore, $a^\star$ never satisfy the elimination condition.
\end{proof}

The following lemma is a counterpart of \pref{lem:delta_1_loss_miss}.

\begin{lemma}\label{lem:delta_1_reward_miss}
    Suppose that \pref{event:misLoss} holds. \pref{alg:rewardLBmis} guarantees that if $a\in\calA$ is not eliminated at the end of epoch $m$ (meaning that $a\in \calA_{m+1}$), then 
    \begin{align*}
        2^m\cdot \Delta_a\leq 2^m\cdot 24\sqrt{n}\epsilon+\frac{256n\beta^2}{\Delta_a} + \frac{2D\Delta_a}{|\calS_m|}.
    \end{align*}
\end{lemma}
\begin{proof}
    Since \pref{event:misLoss} holds, we know that for all $a\in\calA_m$, $\LCB_m(a)\leq \mu_a + \sqrt{|\calS_m|}\epsilon$, $\UCB_m(a)\geq \mu_a - \sqrt{|\calS_m|}\epsilon$. Moreover, as $\UCB_m(a)=\min\{\UCB_{m,1}(a),\UCB_{m,2}(a)\}$, we know that for all $a\in \calA_m$
    \begin{align*}
        \UCB_{m,1}(a) - 2\rad_{m,a}^{N} - 2\epsilon\sqrt{|\calS_m|}=  \hat{\mu}_{m,1}(a) - \rad_{m,a}^{N} - 2\epsilon\sqrt{|\calS_m|}\leq \inner{a,\theta},\\
        \UCB_{m,2}(a) - 2\rad_{m,a}^{F} - 2\epsilon\sqrt{|\calS_m|}=  \hat{\mu}_{m,2}(a) - \rad_{m,a}^{F} - 2\epsilon\sqrt{|\calS_m|}\leq \inner{a,\theta},\\
        \LCB_{m}(a) + 2\rad_{m,a}^{F} + 2\epsilon\sqrt{|\calS_m|} = \hat{\mu}_{m,2}(a) + \rad_{m,a}^{F}+2\epsilon\sqrt{|\calS_m|}\geq \inner{a,\theta}.        
    \end{align*}
    If $B\leq \mu^\star$, then $a^\star\in \calA_m$ according to \pref{lem:end-of-B-reward}.
    Moreover, if $a$ is not eliminated in epoch $m$, we have $\UCB_m(a)+4\sqrt{|S_m|}\epsilon\geq \max\{\LCB_m(a^\star),B\}$, meaning that
    \begin{align*}
        &\inner{a,\theta} + 2\rad_{m,a}^{F} + 2\epsilon\sqrt{|\calS_m|} \\
        &\geq \wh{\mu}_{m,2}(a) + \rad_{m,a}^{F} \\
        &\geq \UCB_m(a) \\
        &\geq \max\{\LCB_m(a^\star),B\}-4\sqrt{|S_m|}\epsilon \\
        &\geq \LCB_m(a^\star) - 4\sqrt{|S_m|}\epsilon \\
        &= \wh{\mu}_{m,2}(a^\star) - \rad_{m,a^\star}^{F} - 4\sqrt{|S_m|}\epsilon \\
        &\geq \inner{a^\star,\theta}  - 2\rad_{m,a^\star}^{F} - 6\sqrt{|S_m|}\epsilon.
    \end{align*}
    Since $\rad_{m,a}^F = \sum_{i=1}^{|\calS_m|}|\lambda_{m,i}^{(a)}|\cdot \rad_{m,a_{m,i}}^{F}$ with $\|\lambda_{m}^{(a)}\|_2\leq 1$, we have that $\|\lambda_{m}^{(a)}\|_1\leq \sqrt{|\calS_m|}$ and
    \begin{align*}
        &\Delta_a\leq 4\sqrt{|\calS_m|}\left(\max_{a\in S_m}\rad_{m,a}^{F}+2\epsilon\right)= 4\sqrt{3n}\max_{a\in S_m}\rad_{m,a}^{F}+8\sqrt{3n}\epsilon \leq \frac{8\sqrt{n}\beta}{\min_{a'\in \calS_m}\sqrt{\unbiasSize_m(a')}}+16\sqrt{n}\epsilon.
    \end{align*}
    
    If $B\geq \mu^\star$, then we have
    \begin{align*}
        \mu^\star\leq B \leq \UCB_{m}(a) + 4\sqrt{|\calS_m|}\epsilon \leq \mu_a + 2\rad_{m,a}^{F} + 6\sqrt{|\calS_m|}\epsilon,
    \end{align*}
    where the second inequality is because $a$ is not eliminated in epoch $m$. Therefore, we always have
    \begin{align*}
        \Delta_a &\leq 2\rad_{m,a}^{F} + 6\sqrt{|\calS_m|}\epsilon \leq \frac{8\sqrt{n}\beta}{\min_{a'\in \calS_m}\sqrt{\unbiasSize_m(a')}} + 12\sqrt{n}\epsilon.
    \end{align*} 
    In addition, we know that for all $a\in \calS_m$,
    \begin{align*}
        2^m &= |\calS_m| \leq \unbiasSize_m(a) + \frac{D}{|S_m|} + 1 \leq \unbiasSize_m(a) + \frac{2D}{|S_m|}.
    \end{align*}
    Therefore, if $12\sqrt{n}\epsilon\geq \frac{\Delta_a}{2}$, then we have
    \begin{align*}
        2^m\Delta_a\leq 2^m\cdot 24\sqrt{n}\epsilon;
    \end{align*}
    otherwise, we have $\Delta_a \leq \frac{8\sqrt{n}\beta}{\min_{a\in \calS_m}\sqrt{\unbiasSize_m(a)}} + 12\sqrt{n}\epsilon \leq \frac{8\sqrt{n}\beta}{\min_{a\in S_m}\sqrt{\unbiasSize_m(a)}}  + \frac{\Delta_a}{2}$ and
    \begin{align*}
        \Delta_a \leq \frac{16\sqrt{n}\beta}{\min_{a'\in \calS_m}\sqrt{\unbiasSize_m(a')}},
    \end{align*}
    and we can obtain that
    \begin{align*}
        \min_{a'\in S_m}{\unbiasSize_m(a')}\cdot \Delta_a\leq \frac{256d\beta^2}{\Delta_a}.
    \end{align*}
    Combining the above two cases, we know that for all $a\in\calA_m$, $$2^m\cdot \Delta_a\leq 2^m\cdot 24\sqrt{n}\epsilon+ \min_{a'\in \calS_m}\unbiasSize_m(a')\cdot \Delta_a + \frac{2D\Delta_a}{|\calS_m|} \leq  2^m\cdot 24\sqrt{n}\epsilon+\frac{256n\beta^2}{\Delta_a} + \frac{2D\Delta_a}{|\calS_m|}.$$
\end{proof}

The following lemma is a counterpart of \pref{lem:epoch_B_with_mis}. 

\begin{lemma}\label{lem:epoch_B_with_mis-reward}
    \pref{alg:rewardLBmis} guarantees that under \pref{event:misLoss}, if an action $a$ is eliminated at the end of epoch $m$ (meaning that $a\in \calA_m$), then
    \begin{align*}
    B\leq \inner{a,\theta} +\rad_{m,a}^{N}+ \sum_{i=1}^{|\calS_m|}|\lambda_{m,i}^{(a)}|\cdot\left(\frac{2d(a_{m,i})}{2^m|\calS_m|}+\frac{16\log T +2}{2^m}\right) + 8\sqrt{|\calS_m|}\epsilon,
\end{align*}
where $d(a)=D\mu_a$.
\end{lemma}
\begin{proof}
Under \pref{event:misLoss}, we know that for all $a\in \calA_m$,
\begin{align*}
    \inner{a,\theta} &= \sum_{i=1}^{|\calS_m|}\lambda_{m,i}^{(a)}\inner{a_{m,i},\theta^\star} \\
    &= \sum_{i=1}^{|\calS_m|}\lambda_{m,i}^{(a)}(\mu_{a_{m,i}}-\epsilon_{a_{m,i}}) \tag{since $\mu_a = \inner{a,\theta^\star}+\epsilon_a$}\\
    &\geq \sum_{i=1}^{|\calS_m|}\lambda_{m,i}^{(a)}\cdot \mu_{a_{m,i}} - \sqrt{|\calS_m|}\epsilon \tag{since $\|\lambda_{m}^{(a)}\|_1\leq \sqrt{|\calS_m|}$} \\
    &\geq \sum_{i=1}^{|\calS_m|}\lambda_{m,i}^{(a)}\cdot \hat{\mu}_{m}(a_{m,i}) - \rad_{m,a}^{N} - 3\sqrt{|\calS_m|}\epsilon \tag{since \pref{event:misLoss} holds}\\
    &\geq \sum_{i=1}^{|\calS_m|}\lambda_{m,i}^{(a)}\cdot\hat{\mu}_{m}^{sgn(\lambda_{m,i}^{(a)})}(a_{m,i}) - \rad_{m,a}^{N} -\sum_{i=1}^{|\calS_m|}|\lambda_{m,i}^{(a)}|\cdot \frac{|\unobs_m(a_{m,i})|}{2^m} - 3\sqrt{|\calS_m|}\epsilon \tag{using \pref{eqn:pos-bias} and \pref{eqn:neg-bias}}\\
    &= \UCB_{m,1}(a) - \rad_{m,a}^{N} -\sum_{i=1}^{|\calS_m|}|\lambda_{m,i}^{(a)}|\cdot \frac{|\unobs_m(a_{m,i})|}{2^m} - 3\sqrt{|\calS_m|}\epsilon\\
    &\geq \UCB_{m,1}(a) - \rad_{m,a}^{N} - \sum_{i=1}^{|\calS_m|}|\lambda_{m,i}^{(a)}|\cdot\left(\frac{2d(a_{m,i})}{2^m|\calS_m|}+\frac{16\log KT +2}{2^m}\right) - 4\sqrt{|\calS_m|}\epsilon. \tag{since \pref{event:misLoss} holds}
\end{align*}
Since $\UCB_{m,1}(a)\geq B - 4\sqrt{|\calS_m|}\epsilon$ (as $a$ is not eliminated at the end of epoch $m$), we have
\begin{align*}
    B\leq \inner{a,\theta} +\rad_{m,a}^{N}+ \sum_{i=1}^{|\calS_m|}|\lambda_{m,i}^{(a)}|\cdot\left(\frac{2d(a_{m,i})}{2^m|\calS_m|}+\frac{16\log T +2}{2^m}\right) + 8\sqrt{|\calS_m|}\epsilon.
\end{align*}
\end{proof}

The following lemma is a counterpart of \pref{lem:bound_2_mis}.

\begin{lemma}\label{lem:bound_2_mis_reward}
    If $B\geq \frac{\mu^\star}{2}$ and \pref{event:misLoss} holds, \pref{alg:rewardLBmis} guarantees that if $a$ is not eliminated at the end of epoch $m$, then we also have
    \begin{align*}
        2^m\Delta_a\leq \frac{256n\beta^2}{\Delta_a} +\frac{12\sum_{i=1}^{|\calS_m|}|\lambda_{m,i}^{(a)}|\cdot d(a_{m,i})}{|\calS_m|}+(128\log T +16)\sqrt{n}+2^m\cdot 64\sqrt{n}\epsilon,
    \end{align*}
    where $d(a)=D\mu_a$.
\end{lemma}
\begin{proof}
    If $\inner{a,\theta}\geq \frac{B}{2}$, we know that $\Delta_a = \inner{a^\star-a,\theta} \leq 3\inner{a,\theta}$. Using \pref{lem:delta_1_reward_miss}, we can obtain that
    \begin{align*}
        2^m\cdot \Delta_a &\leq 2^m\cdot 24\sqrt{n}\epsilon+\frac{256n\beta^2}{\Delta_a} + \frac{2D\inner{a,\theta}}{|\calS_m|} \\
        &\leq 2^m\cdot 24\sqrt{n}\epsilon+\frac{256n\beta^2}{\Delta_a} + \frac{2\sum_{i=1}^{|\calS_m|}|\lambda_{m,i}^{(a)}|\cdot d(a_{m,i})}{|\calS_m|}.
    \end{align*}
    If $\inner{a,\theta} \leq \frac{B}{2}$, we have $3(B-\inner{a,\theta} ) \geq \frac{3B}{2} \geq \inner{a^\star-a,\theta}$. Using \pref{lem:epoch_B_with_mis}, we know that
    \begin{align*}
        \Delta_a &\leq \mu_a \leq \underbrace{3\cdot \rad_{m,a}^{N}}_{\term{1}}+ \underbrace{3\sum_{i=1}^{|\calS_m|}|\lambda_{m,i}^{(a)}|\cdot\left(\frac{2d(a_{m,i})}{2^m|\calS_m|}+\frac{16\log T +2}{2^m}\right) + 24\sqrt{|\calS_m|}\epsilon}_{\term{2}}.
    \end{align*}

    If $\term{1}\geq \term{2}$, we have
    \begin{align*}
        \Delta_a &\leq \mu_a \leq 6\rad_{m,a}^{N} \epsilon \leq 6\sqrt{|\calS_m|}\max_{a_m\in\calS_m}\rad_{m,a_m}^N \leq \frac{12\beta\sqrt{n}}{2^{m/2}},
    \end{align*}
    meaning that $2^m\Delta_a \leq \frac{144n\beta^2}{\Delta_a}$.
    Otherwise, we have
    \begin{align*}
        \Delta_a\leq 6\sum_{i=1}^{|\calS_m|}|\lambda_{m,i}^{(a)}|\cdot \left(\frac{2d(a_{m,i})}{2^m|\calS_m|}+\frac{16\log T +2}{2^m}\right) + 96\sqrt{n}\epsilon,
    \end{align*}
    meaning that
    \begin{align*}
        2^m\Delta_a\leq \frac{12\sum_{i=1}^{|\calS_m|}|\lambda_{m,i}^{(a)}|\cdot d(a_{m,i})}{|\calS_m|}+(96\log T +12)\sqrt{n}+2^m\cdot 96\sqrt{n}\epsilon.
    \end{align*}
    Combining both cases, we know that
    \begin{align*}
        2^m\Delta_a\leq \frac{256n\beta^2}{\Delta_a} +\frac{12\sum_{i=1}^{|\calS_m|}|\lambda_{m,i}^{(a)}|\cdot d(a_{m,i})}{|\calS_m|}+(96\log T +12)\sqrt{n}+2^m\cdot 96\sqrt{n}\epsilon.
    \end{align*}
\end{proof}

Now we are ready to prove our main result \pref{thm:reward-main}.
\begin{proof}[Proof of Theorem~\ref{thm:reward-main}]
Combining \pref{lem:delta_1_reward_miss} and \pref{lem:bound_2_mis_reward} and following the exact same process of obtaining \pref{eqn:reg_b} in \pref{thm:lossLBmis}, we can obtain that for a fixed value of $B$, \pref{alg:rewardLBmis} guarantees that
    \begin{align*}
        \Reg_B &\leq \order\left(\min\left\{\frac{n^2\log(KT)\log(T/n)}{\Delta_{\min}}, n\sqrt{|\calT_B|\log(KT)}\right\}+\epsilon\sqrt{n}|\calT_B|\right)\\
        &\qquad + \sum_{m= 1}^{\lceil\log_2(|\calT_B|/3n\rceil}\sum_{a\in \calS_m}\order\left(\min\left\{\frac{\sum_{i=1}^{|\calS_{m-1}|}|\lambda_{m-1,i}^{(a)}|\cdot d(a_{m-1,i})}{n}, \frac{D\Delta_a}{n}\right\}\right) \\
        &\leq \order\Bigg(\min\left\{\frac{n^2\log(KT)\log(T/n)}{\Delta_{\min}}, n\sqrt{|\calT_B|\log(KT)}\right\}+\epsilon\sqrt{n}|\calT_B|\\
        &\qquad \left.+\min\left\{\sum_{m= 1}^{\lceil\log_2(|\calT_B|/3n\rceil}\sum_{i=1}^{|\calS_{m-1}|} d(a_{m-1,i}), D\Delta_{\max}\log(T/n)\right\}\right).
    \end{align*}
    According to \pref{lem:end-of-B-reward}, there are at most $\lceil\log_2(1/\mu^\star)\rceil$ different values of $B$. With an abuse of notation, we define $\calS_{m}^{(B)}=\{a_{m,i}^{(B)}\}_{i\in [3n]}$ to be the volumetric spanner at epoch $m$ with the reward guess $B$.
    Taking summation over all these values, we can obtain that
    \begin{align*}
        \Reg &\leq \order\left(\min\left\{\frac{n^2\log(KT)\log(T/n)\log(1/\mu^\star)}{\Delta_{\min}}, n\sqrt{T\log(KT)\log(1/\mu^\star)}\right\}+\epsilon\sqrt{n}T\right)\\
        &\qquad+\order\left(\min\left\{\sum_{j=0}^{\lceil\log_2(1/\mu^\star)\rceil}\sum_{m=1}^{\lceil\log_2(|\calT_{2^{-j}}|/3n\rceil}\sum_{i=1}^{3n} d(a_{m-1,i}^{(2^{-j})}), D\Delta_{\max}\log(1/\mu^\star)\log(T/n)\right\}\right),
    \end{align*}
    completing the proof.
\end{proof}    

    While we can further apply a similar analysis to the one in \pref{thm:lossLBmis} to bound the term $\sum_{j=0}^{\lceil\log_2(1/\mu^\star)\rceil}\sum_{m=1}^{\lceil\log_2(|\calT_{2^{-j}}|/3n\rceil}\sum_{i=1}^{3n} d(a_{m-1,i}^{(2^{-j})})$ and obtain a bound with respect to $d^\star$, since $d^\star\geq D\Delta_{\max}+\epsilon$, this $d^\star$ dependent bound does not provide a significantly better regret guarantee in the worst case. This  difference in loss versus reward is also pointed out in \citep{schlisselberg2024delay} in the MAB setting. We keep this term in the upper bound since this quantity can still be potentially smaller than $D\Delta_{\max}\log(1/\mu^\star)\log(T/n)$.
