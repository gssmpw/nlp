\setcounter{AlgoLine}{0}
\begin{algorithm}
\caption{Phased Elimination via Volumetric Spanner for Linear Bandits with Delay-as-Loss with misspecification}\label{alg:lossLBmis}

\nl Input: maximum possible delay $D$, action set $\calA$, $\beta>0$, a misspecification level $\epsilon$. 

\nl Initialization: optimal loss guess $B=1/D$.

\nl Initialization: active action set $\calA_1=\calA$. \label{line: restart-mis}

 \For{$m=1,2,\dots,$}{
    \nl Find $\calS_m=\{a_{m,1},\dots,a_{m,|\calS_m|}\}$, a volumetric spanner of $\calA_m$ with $|\calS_m|= 3n$. \label{line:volume-mis}
    
    \nl Pick each $a\in \calS_m$ $2^m$ times in a round-robin way. \label{line:round-robin-mis}

    \nl Let $\calI_m$ contain all the rounds in this epoch.
    
    \nl For each $a\in \calS_m$, calculate the following quantities: \label{line:spanner-ucb-lcb-mis}
    {\small
    \begin{align}
        &\hat{\mu}_{m}^+(a)=\frac{1}{2^m}\Big(\sum_{\tau\in \obs_m(a)}u_{\tau} + \sum_{\tau\in \unobs_m(a)}1\Big), \label{eqn:mean-up-mis}\\
        &\hat{\mu}_{m}^-(a)=\frac{1}{2^m}\sum_{\tau\in \obs_m(a)}u_{\tau}, \label{eqn:mean-low-mis}\\
        &\hat{\mu}_{m,1}^{+}(a)=\hat{\mu}^{+}_{m}(a)+\frac{\beta}{2^{m/2}}\|a\|_2, \label{eqn:loss-ucb-linear-1-mis}\\
        &\hat{\mu}_{m,1}^{-}(a)=\hat{\mu}^{-}_{m}(a)-\frac{\beta}{2^{m/2}}\|a\|_2,\label{eqn:loss-lcb-linear-1-mis}\\
        &\hat{\mu}_m^{F}(a)=\frac{1}{\unbiasSize_m(a)}\sum_{\tau\in \unbias_m(a)}u_{\tau}, \label{eqn:mean_unbiased-mis}\\
        &\hat{\mu}_{m,2}^{+}(a)=\hat{\mu}_m^F(a)+\frac{\beta}{\sqrt{\unbiasSize_m(a)}}\|a\|_2, \label{eqn:loss-ucb-linear-2-mis}\\
        &\hat{\mu}_{m,2}^{-}(a)=\hat{\mu}_m^F(a)-\frac{\beta}{\sqrt{\unbiasSize_m(a)}}\|a\|_2, \label{eqn:loss-lcb-linear-2-mis}
    \end{align}
    }
    where $\unbiasSize_m(a) = |\unbias_m(a)|$, $\unbias_m(a) = \{\tau\in \calI_m: \tau+D\in\calI_m, a_{\tau}=a\}$, $\obs_m(a) = \{\tau\in \calI_m: \tau+d_{\tau}\in\calI_m, a_{\tau}=a\}$, and
    $\unobs_m(a)= \{\tau\in \calI_m: a_{\tau}=a\}\setminus\obs_m(a)$.

    \For{each $a\in \calA_m$}{
        \nl \label{line: decompose-mis}
        Decompose $a$ as $a=\sum_{i=1}^{|S_m|}\lambda_{m,i}^{(a)}a_{m,i}$ with $\|\lambda_{m}^{(a)}\|_2\leq 1$ and calculate 
        {\small
        \begin{align}
            &\UCB_{m}(a)=\sum_{i=1}^{|\calS_m|}\lambda_{m,i}^{(a)}\cdot\hat{\mu}_{m,2}^{\sgn(\lambda_{m,i}^{(a)})}(a_{m,i}), \label{eqn:loss-ucb-f-all-action-mis} \\
            &\LCB_m(a) = \max_{j\in \{1,2\}}\{\LCB_{m,j}(a)\} \;\;\text{where} \nonumber  \\
            & \LCB_{m,j}(a)=\sum_{i=1}^{|\calS_m|}\lambda_{m,i}^{(a)}\cdot\hat{\mu}_{m,j}^{\sgn(-\lambda_{m,i}^{(a)})}(a_{m,i}),\label{eqn:loss-lcb-all-action-mis}
        \end{align}
        }
    }
    
    \nl Set $\calA_{m+1} = \calA_m$.
    
    \For{$a\in \calA_m$}{
        \nl \label{line:eliminate-mis}  
        \If{$\exists a'\in \calA_m$, s.t. $\LCB_m(a) \geq \min\{\UCB_m(a'),B\} + 4\sqrt{3n}\epsilon$}
        {
          Eliminate $a$ from $\calA_{m+1}$.
        }
    }
    \nl \If{$\calA_{m+1}=\emptyset$}{
        Set $B\leftarrow 2B$ and go to \pref{line: restart-mis}.
    }
}
\end{algorithm}

In this section, we provide the detailed proof for \pref{thm:main-non-contextual}. Specifically, as mentioned in \pref{sec: contextual}, we prove the guarantee of a modified algorithm (\pref{alg:lossLBmis}) for the more general $\epsilon$-misspecified linear bandits. 

Recall that in misspecified linear bandits, $\mu_a = \inner{a,\theta}+\epsilon_a\in[0,1]$ with $|\epsilon_a|\leq\epsilon$ for all $a\in\calA$. Due to this difference, we clarify on the definitions of $\Delta_a$, $a^\star$, $\mu^\star$, $\Delta_{\min}$, $\Delta_{\max}$, and $d^\star$ in misspecified linear bandits as follows. We still define $\Delta_a = \inner{a^\star-a,\theta}$ as the suboptimality gap of action $a$, where $a^\star \in \argmin_{a\in\calA}\inner{a, \theta}$, but $\mu^\star \triangleq \min_{a\in\calA}\mu_a$ as the loss of the optimal action. Note that due to the misspecification, $\mu^\star$ may not necessarily be $\mu_{a^\star}$. Define $\Delta_{\min} = \min_{a\in \calA, \Delta_a>0}\Delta_a$ and $\Delta_{\max} = \max_{a\in \calA}\Delta_a$ to be the minimum non-zero, and maximum sub-optimality gap. The delay at round $t$ is still defined as $d_t=D\cdot u_t$ and $d^\star = D\cdot \mu^\star$ is the expected delay of the optimal action.

As for the algorithm, \pref{alg:lossLBmis} differs from \pref{alg:lossLB} only in \pref{line:eliminate-mis} where we add one misspecification term $4\sqrt{3n}\epsilon$ in the criteria of eliminating an action. 

The following theorem shows the guarantee of our algorithm in the misspecified linear bandits.

\begin{theorem}\label{thm:lossLBmis}
    \pref{alg:lossLBmis} with $\beta = \sqrt{2\log(KT^3)}$ guarantees that
    \begin{align*}
        \Reg &\leq \order\left(\min\left\{\frac{n^2\log(KT)\log(T/n)\log(d^\star)}{\Delta_{\min}},n\sqrt{T\log(d^\star)\log(KT)}\right\}+\epsilon\sqrt{n}T\right) \\
        &\qquad + \log(d^\star)\cdot \order\left( \min\left\{nd^\star\log (T/n)+D\Delta_{\max},D\Delta_{\max}\log (T/n)\right\}\right).
    \end{align*}
\end{theorem}

To prove \pref{thm:lossLBmis}, recall the following quantities
\begin{align}
    \wh{\mu}_{m}(a) &= \frac{1}{2^m}\sum_{\tau\in\obs_m(a)\cup\unobs_m(a)}u_{\tau},~~~\forall a\in \calS_m,\label{eqn:loss-all-mean-app}\\
    \hat{\mu}_{m,1}(a)&=\sum_{i=1}^{|\calS_m|}\lambda_{m,i}^{(a)}\cdot\hat{\mu}_{m}(a_{m,i}),~~~\forall a\in \calA_m,\\
    \hat{\mu}_{m,2}(a)&=\sum_{i=1}^{|\calS_m|}\lambda_{m,i}^{(a)}\cdot\hat{\mu}_{m}^{F}(a_{m,i}),~~~\forall a\in \calA_m.
\end{align}
We then define the following event and show that the event holds with high probability.

\begin{event}\label{event:misLoss}
    For all action $a\in \calA_m$, $m\in[T]$,
    \begin{align}
        \left|\inner{a,\theta}-\hat{\mu}_{m,1}(a)\right|&\leq \sqrt{|\calS_m|}\epsilon + \beta\sum_{i=1}^{|\calS_m|}\left|\lambda_{m,i}^{(a)}\right|\sqrt{\frac{1}{2^{m}}}, \label{eqn:concentr-1}\\
        \left|\inner{a,\theta}-\hat{\mu}_{m,2}(a)\right|&\leq \sqrt{|\calS_m|}\epsilon +\beta \sum_{i=1}^{|\calS_m|}\left|\lambda_{m,i}^{(a)}\right|\sqrt{\frac{1}{\unbiasSize_m(a_{m,i})}}, \label{eqn:concentr-2}\\
        |\unobs_m(a)| &\leq \frac{2D\mu_a}{|\calS_m|}+16\log KT+2,\label{eqn:concentr-3}
    \end{align}
    where $\beta = \sqrt{2\log KT^3}$.
\end{event}
\begin{lemma}\label{lem:high-prob-event}
    \pref{alg:lossLBmis} guarantees that \pref{event:misLoss} holds with probability at least $1-\frac{2}{T^2}$.
\end{lemma}
\begin{proof}
    Fix an action $a\in \calS_m$ in epoch $m\in[T]$. According to standard Azuma's inequality, we know that with probability at least $1-\delta$,
    \begin{align*}
        \left|\mu_a-\hat{\mu}_{m,1}(a)\right|&\leq \sqrt{\frac{2\log(2/\delta)}{2^m}}\|a\|_2,\\
        \left|\mu_a-\hat{\mu}_{m,2}(a)\right|&\leq \sqrt{\frac{2\log(2/\delta)}{\unbiasSize_m(a)}}\|a\|_2.
    \end{align*}
    Taking union bound over all possible $a\in \calA$ and all $m\in[T]$, we know that with probability at least $1-\delta$, for all $a\in \calS_m$ and all $m\in [T]$,
    \begin{align*}
        \left|\mu_a-\hat{\mu}_{m,1}(a)\right|&\leq \sqrt{\frac{2\log(2TK/\delta)}{n_t(a)}}\|a\|_2,\\
        \left|\mu_a-\hat{\mu}_{m,2}(a)\right|&\leq \sqrt{\frac{2\log(2TK/\delta)}{\unbiasSize_m(a)}}\|a\|_2.
    \end{align*}
    Then, given that the above equation holds, for $a\in \calA_m$, due to the property of volumetric spanners, we have $\mu_a = \inner{a,\theta^\star}+\epsilon_a =  \sum_{i=1}^{|\calS_m|}\lambda_{m,i}^{(a)}\inner{a_{m,i},\theta^\star}+ \epsilon_a$. Therefore, we can obtain that
    \begin{align*}
        \left|\inner{a,\theta}-\hat{\mu}_{m,1}(a)\right|
        &\leq \left|\sum_{i=1}^{|\calS_m|}\lambda_{m,i}^{(a)}(\inner{a_{m,i},\theta^\star}-\mu_{a_{m,i}})\right| + \sum_{i=1}^{|\calS_m|}\left|\lambda_{m,i}^{(a)}\right|\cdot\left|\mu_{a_{m,i}}-\hat{\mu}_{m}(a_{m,i})\right| \\
        &\leq \sum_{i=1}^{|\calS_m|}\left|\lambda_{m,i}^{(a)}\right|\left(\epsilon_{a_{m,i}}+\sqrt{\frac{2\log(2TK/\delta)}{2^{m}}}\right) \\
        &\leq \sqrt{|\calS_m|}\epsilon + \sum_{i=1}^{|\calS_m|}\left|\lambda_{m,i}^{(a)}\right|\sqrt{\frac{2\log(2TK/\delta)}{2^{m}}},
    \end{align*}
    where the last inequality uses $\|\lambda_{m}^{(a)}\|_1\leq \sqrt{|\calS_m|}\cdot \|\lambda_{m}^{(a)}\|_2\leq \sqrt{|\calS_m|}$. A similar analysis proves \pref{eqn:concentr-2}. \pref{eqn:concentr-3} holds with probability at least $1-\frac{1}{T^2}$ according to Lemma 4.1 of \citep{schlisselberg2024delay}. Picking $\delta = \frac{1}{T^2}$ finishes the proof.
\end{proof}

The next lemma shows that if $B\geq \mu^\star$, then \pref{alg:lossLBmis} will not reach an empty active set.
\begin{lemma}\label{lem:end-of-B}
    Suppose that \pref{event:misLoss} holds. If $B\geq \mu^\star$, then $a^\star\in \calA_m$ for all $m$.
\end{lemma}
\begin{proof}
    Since \pref{event:misLoss} holds, we have, we know that for all $a\in\calA_m$, $\LCB_m(a)\leq \inner{a,\theta} + \sqrt{|\calS_m|}\epsilon $ and $\UCB_m(a)\geq \inner{a,\theta} - \sqrt{|\calS_m|}\epsilon$. If $B\geq \mu^\star$, then we have $a^\star$ never eliminated since for any $a\in \calA_m$
    \begin{align*}
        \LCB_{m}(a^\star) &\leq \inner{a^\star,\theta} + \epsilon\sqrt{|\calS_m|} \leq \mu^\star + \epsilon + \epsilon\sqrt{|\calS_m|} \leq \mu^\star + 2\epsilon\sqrt{|\calS_m|},\\
        \LCB_{m}(a^\star) &\leq \inner{a^\star,\theta} + \epsilon\sqrt{|\calS_m|} \leq \inner{a,\theta} + 2\epsilon\sqrt{|\calS_m|} \leq \UCB_m(a) + 4\epsilon\sqrt{|\calS_m|}.
    \end{align*}
    Therefore, $a^\star$ never satisfy the elimination condition.
\end{proof}

The following lemma shows that the regret within epoch $m$ can be well-controlled.

\begin{lemma}\label{lem:delta_1_loss_miss}
    Suppose that \pref{event:misLoss} holds. \pref{alg:lossLBmis} guarantees that if $a\in\calA$ is not eliminated at the end of epoch $m$ (meaning that $a\in \calA_{m+1}$), then 
    \begin{align*}
        2^m\cdot \Delta_a\leq 2^m\cdot 24\sqrt{n}\epsilon+\frac{256n\beta^2}{\Delta_a} + \frac{2D\Delta_a}{|\calS_m|}.
    \end{align*}
\end{lemma}
\begin{proof}
    For notational convenience, define $\rad_{m,a}^{N} = \frac{\beta}{\sqrt{2^m}}\|a\|_2$ and $\rad_{m,a}^{F} = \frac{\beta}{\sqrt{\unbiasSize_m(a)}}\|a\|_2$ for all $a\in \calS_m$. In addition, we also define $\rad_{m,a}^{N}$ and $\rad_{m,a}^{F}$ for $a\notin \calS_m$ as follows:
    \begin{align*}
        \rad_{m,a}^{N} &= \sum_{i=1}^{|\calS_m|}|\lambda_{m,i}^{(a)}|\cdot \rad_{m,a_{m,i}}^{N}, \\
        \rad_{m,a}^{F} &= \sum_{i=1}^{|\calS_m|}|\lambda_{m,i}^{(a)}|\cdot \rad_{m,a_{m,i}}^{F}.
    \end{align*}
    Since \pref{event:misLoss} holds, we know that for all $a\in\calA_m$, $\LCB_m(a)\leq \inner{a,\theta} + \sqrt{|\calS_m|}\epsilon$, $\UCB_m(a)\geq \inner{a,\theta} - \sqrt{|\calS_m|}\epsilon$. Moreover, as $\LCB_m(a)=\max\{\LCB_{m,1}(a),\LCB_{m,2}(a)\}$, we know that for all $a\in \calA_m$
    \begin{align*}
        \LCB_{m,1}(a) + 2\rad_{m,a}^{N} + 2\epsilon\sqrt{|\calS_m|}\geq  \hat{\mu}_{m,1}(a) + \rad_{m,a}^{N} + 2\epsilon\sqrt{|\calS_m|}\geq \inner{a,\theta},\\
        \LCB_{m,2}(a) + 2\rad_{m,a}^{F} + 2\epsilon\sqrt{|\calS_m|}\geq  \hat{\mu}_{m,2}(a) + \rad_{m,a}^{F} + 2\epsilon\sqrt{|\calS_m|}\geq \inner{a,\theta},\\
        \UCB_{m}(a) - 2\rad_{m,a}^{F} - 2\epsilon\sqrt{|\calS_m|} = \hat{\mu}_{m,2}(a) - \rad_{m,a}^{F}-2\epsilon\sqrt{|\calS_m|}\leq \inner{a,\theta}.        
    \end{align*}
    If $B\geq \mu^\star$, then $a^\star\in \calA_m$ according to \pref{lem:end-of-B}.
    Moreover, if $a$ is not eliminated in epoch $m$, we have $\LCB(a)\leq \min\{\UCB_m(a^\star),B\}+4\sqrt{|S_m|}\epsilon$, meaning that
    \begin{align*}
        &\inner{a,\theta} - 2\rad_{m,a}^{F} - 2\epsilon\sqrt{|\calS_m|} \\
        &\leq \wh{\mu}_{m,2}(a) - \rad_{m,a}^{F} \\
        &\leq \LCB_m(a) \\
        &\leq \min\{\UCB_m(a^\star),B\}+4\sqrt{|S_m|}\epsilon \\
        &\leq \UCB_m(a^\star) + 4\sqrt{|S_m|}\epsilon \\
        &= \wh{\mu}_{m,2}(a^\star) + \rad_{m,a^\star}^{F}+ 4\sqrt{|S_m|}\epsilon \\
        &\leq \inner{a^\star,\theta} + 2\rad_{m,a^\star}^{F} + 6\sqrt{|S_m|}\epsilon.
    \end{align*}
    Since $\rad_{m,a}^F = \sum_{i=1}^{|\calS_m|}|\lambda_{m,i}^{(a)}|\cdot \rad_{m,a_{m,i}}^{F}$ with $\|\lambda_{m}^{(a)}\|_2\leq 1$, we have that $\|\lambda_{m}^{(a)}\|_1\leq \sqrt{|\calS_m|}$ and
    \begin{align*}
        &\Delta_a\leq 4\sqrt{|\calS_m|}\left(\max_{a\in \calS_m}\rad_{m,a}^{F}+2\epsilon\right)= 4\sqrt{3n}\max_{a\in \calS_m}\rad_{m,a}^{F}+8\sqrt{3n}\epsilon \leq \frac{8\sqrt{n}\beta}{\min_{a'\in \calS_m}\sqrt{\unbiasSize_m(a')}}+16\sqrt{n}\epsilon.
    \end{align*}
    
    If $B\leq \mu^\star$, then we have
    \begin{align*}
        \inner{a^\star,\theta}+\epsilon\geq \mu^\star\geq B \geq \LCB_{m}(a) - 4\sqrt{|\calS_m|}\epsilon \geq \inner{a,\theta} - 2\rad_{m,a}^{F} - 5\sqrt{|\calS_m|}\epsilon,
    \end{align*}
    where the second inequality is because $a$ is not eliminated in epoch $m$. Therefore, we always have
    \begin{align*}
        \Delta_a &\leq 2\rad_{m,a}^{F} + 6\sqrt{|\calS_m|}\epsilon \leq \frac{8\sqrt{n}\beta}{\min_{a'\in \calS_m}\sqrt{\unbiasSize_m(a')}} + 12\sqrt{n}\epsilon.
    \end{align*}
    In addition, we know that for all $a\in \calS_m$,
    \begin{align*}
        2^m \leq \unbiasSize_m(a) + \frac{D}{|\calS_m|} + 1 \leq \unbiasSize_m(a) + \frac{2D}{|\calS_m|}.
    \end{align*}
    Therefore, if $12\sqrt{n}\epsilon\geq \frac{\Delta_a}{2}$, then we have
    \begin{align*}
        2^m\Delta_a\leq 2^m\cdot 24\sqrt{n}\epsilon;
    \end{align*}
    otherwise, we have $\Delta_a \leq \frac{8\sqrt{n}\beta}{\min_{a\in \calS_m}\sqrt{\unbiasSize_m(a)}} + 12\sqrt{n}\epsilon \leq \frac{8\sqrt{n}\beta}{\min_{a\in \calS_m}\sqrt{\unbiasSize_m(a)}}  + \frac{\Delta_a}{2}$ and
    \begin{align*}
        \Delta_a \leq \frac{16\sqrt{n}\beta}{\min_{a'\in \calS_m}\sqrt{\unbiasSize_m(a')}},
    \end{align*}
    and we can obtain that
    \begin{align*}
        \min_{a'\in \calS_m}{\unbiasSize_m(a')}\cdot \Delta_a\leq \frac{256d\beta^2}{\Delta_a}.
    \end{align*}
    Combining the above two cases, we know that for all $a\in\calA_m$, $$2^m\cdot \Delta_a\leq 2^m\cdot 24\sqrt{n}\epsilon+ \min_{a'\in \calS_m}\unbiasSize_m(a')\cdot \Delta_a + \frac{2D\Delta_a}{|\calS_m|} \leq  2^m\cdot 24\sqrt{n}\epsilon+\frac{256n\beta^2}{\Delta_a} + \frac{2D\Delta_a}{|\calS_m|}.$$
\end{proof}

In fact, the bound above can be obtained by only using $\LCB_{m,1}$. Next, we provide yet-another regret bound within epoch $m$, which utilizes $\LCB_{m,2}$.

\begin{lemma}\label{lem:epoch_B_with_mis}
    \pref{alg:lossLBmis} guarantees that under \pref{event:misLoss}, if action $a$ is not eliminated at the end of epoch $m$ (meaning that $a\in \calA_{m+1}$), then
    \begin{align*}
    \inner{a,\theta}\leq B +\rad_{m,a}^{N}+ \sum_{i=1}^{|\calS_m|}|\lambda_{m,i}^{(a)}|\cdot\left(\frac{2D\mu_{a_{m,i}}}{2^m|\calS_m|}+\frac{16\log T +2}{2^m}\right) + 8\sqrt{|\calS_m|}\epsilon.
\end{align*}
\end{lemma}
\begin{proof}
For all $a\in \calS_m$, since $u_{t}\in[0,1]$, we know that
\begin{align}
    \hat{\mu}_{m}^+(a) &=\frac{1}{2^m}\left(\sum_{\tau\in \obs_m(a)}u_{\tau} + \sum_{\tau\in \unobs_m(a)}1\right) \leq \hat{\mu}_{m,a} + \frac{|\unobs_m(a)|}{2^m}, \label{eqn:pos-bias}\\
    \hat{\mu}_{m}^-(a) &=\frac{1}{2^m}\left(\sum_{\tau\in \obs_m(a)}u_{\tau} \right) \geq \hat{\mu}_{m,a} - \frac{|\unobs_m(a)|}{2^m} \label{eqn:neg-bias}.
\end{align}
Then, under \pref{event:misLoss}, we know that for all $a\in \calA_m$,
\begin{align*}
    \inner{a,\theta} &= \sum_{i=1}^{|\calS_m|}\lambda_{m,i}^{(a)}\inner{a_{m,i},\theta^\star}\\
    &= \sum_{i=1}^{|\calS_m|}\lambda_{m,i}^{(a)}(\mu_{a_{m,i}}-\epsilon_{a_{m,i}}) \tag{since $\mu_a = \inner{a,\theta^\star}+\epsilon_a$}\\
    &\leq \sum_{i=1}^{|\calS_m|}\lambda_{m,i}^{(a)}\cdot \mu_{a_{m,i}} + \sqrt{|\calS_m|}\epsilon \tag{since $\|\lambda_{m}^{(a)}\|_1\leq \sqrt{|\calS_m|}$} \\
    &\leq \sum_{i=1}^{|\calS_m|}\lambda_{m,i}^{(a)}\cdot \hat{\mu}_{m}(a_{m,i}) + \rad_{m,a}^{N} + 3\sqrt{|\calS_m|}\epsilon \tag{since \pref{event:misLoss} holds}\\
    &\leq \sum_{i=1}^{|\calS_m|}\lambda_{m,i}^{(a)}\cdot\hat{\mu}_{m}^{sgn(-\lambda_{m,i}^{(a)})}(a_{m,i}) + \rad_{m,a}^{N}+\sum_{i=1}^{|\calS_m|}|\lambda_{m,i}^{(a)}|\cdot \frac{|\unobs_m(a_{m,i})|}{2^m} + 3\sqrt{|\calS_m|}\epsilon \tag{using \pref{eqn:pos-bias} and \pref{eqn:neg-bias}}\\
    &= \LCB_{m,1}(a) + \rad_{m,a}^{N}+\sum_{i=1}^{|\calS_m|}|\lambda_{m,i}^{(a)}|\cdot \frac{|\unobs_m(a_{m,i})|}{2^m} + 3\sqrt{|\calS_m|}\epsilon\\
    &\leq \LCB_{m,1}(a) +\rad_{m,a}^{N}+ \sum_{i=1}^{|\calS_m|}|\lambda_{m,i}^{(a)}|\cdot\left(\frac{2D\mu_{a_{m,i}}}{2^m|\calS_m|}+\frac{16\log KT +2}{2^m}\right) + 3\sqrt{|\calS_m|}\epsilon. \tag{since \pref{event:misLoss} holds}
\end{align*}
Since $\LCB_{m,1}(a)\leq B+4\sqrt{|\calS_m|}\epsilon$ (as $a$ is not eliminated at the end of epoch $m$), we have
\begin{align*}
    \inner{a,\theta}\leq B +\rad_{m,a}^{N}+ \sum_{i=1}^{|\calS_m|}|\lambda_{m,i}^{(a)}|\cdot\left(\frac{2D\mu_{a_{m,i}}}{2^m|\calS_m|}+\frac{16\log T +2}{2^m}\right) + 8\sqrt{|\calS_m|}\epsilon.
\end{align*}
\end{proof}

\begin{lemma}\label{lem:bound_2_mis}
    If \pref{event:misLoss} holds, \pref{alg:lossLBmis} guarantees that if $a$ is not eliminated at the end of epoch $m$, then we also have
    \begin{align*}
        2^m\Delta_a\leq \frac{256n\beta^2}{\Delta_a} +\frac{4DB + 12\sum_{i=1}^{|\calS_m|}|\lambda_{m,i}^{(a)}|\cdot D\mu_{a_{m,i}}}{|\calS_m|}+(128\log T +16)\sqrt{n}+2^m\cdot 64\sqrt{n}\epsilon.
    \end{align*}
\end{lemma}
\begin{proof}
    If $\inner{a,\theta}\leq 2B$, we know that $\Delta_a = \inner{a-a^\star,\theta} \leq 2B$. Using \pref{lem:delta_1_loss_miss}, we can obtain that
    \begin{align*}
        2^m\cdot \Delta_a &\leq 2^m\cdot 24\sqrt{n}\epsilon+\frac{256n\beta^2}{\Delta_a} + \frac{2D\Delta_a}{|\calS_m|} \\
        &\leq 2^m\cdot 24\sqrt{n}\epsilon+\frac{256n\beta^2}{\Delta_a} + \frac{4DB}{|\calS_m|}
    \end{align*}
    If $\inner{a,\theta}\geq 2B$, we have $B\leq \frac{\inner{a,\theta}}{2}$. Using \pref{lem:epoch_B_with_mis}, we know that
    \begin{align*}
        \Delta_a &\leq \inner{a,\theta} \leq \underbrace{2\cdot \rad_{m,a}^{N}}_{\term{1}}+ \underbrace{2\sum_{i=1}^{|\calS_m|}|\lambda_{m,i}^{(a)}|\cdot\left(\frac{2D\mu_{a_{m,i}}}{2^m|\calS_m|}+\frac{16\log T +2}{2^m}\right) + 16\sqrt{|\calS_m|}\epsilon}_{\term{2}}.
    \end{align*}

    If $\term{1}\geq \term{2}$, we have
    \begin{align*}
        \Delta_a &\leq 4\rad_{m,a}^{N} \epsilon \leq 4\sqrt{|\calS_m|}\max_{a_m\in\calS_m}\rad_{m,a_m}^N \leq \frac{8\beta\sqrt{n}}{2^{m/2}},
    \end{align*}
    meaning that $2^m\Delta_a \leq \frac{64n\beta^2}{\Delta_a}$.
    Otherwise, we have
    \begin{align*}
        \Delta_a\leq 4\sum_{i=1}^{|\calS_m|}|\lambda_{m,i}^{(a)}|\cdot \left(\frac{2D\mu_{a_{m,i}}}{2^m|\calS_m|}+\frac{16\log T +2}{2^m}\right) + 64\sqrt{n}\epsilon,
    \end{align*}
    meaning that
    \begin{align*}
        2^m\Delta_a\leq \frac{8\sum_{i=1}^{|\calS_m|}|\lambda_{m,i}^{(a)}|\cdot D\mu_{a_{m,i}}}{|\calS_m|}+(128\log T +16)\sqrt{n}+2^m\cdot 64\sqrt{n}\epsilon.
    \end{align*}
    Combining both cases, we know that
    \begin{align*}
        2^m\Delta_a\leq \frac{256n\beta^2}{\Delta_a} +\frac{4DB + 12\sum_{i=1}^{|\calS_m|}|\lambda_{m,i}^{(a)}|\cdot D\mu_{a_{m,i}}}{|\calS_m|}+(128\log T +16)\sqrt{n}+2^m\cdot 64\sqrt{n}\epsilon.
    \end{align*}
\end{proof}

Now we are ready to prove our main result \pref{thm:lossLBmis}.
\begin{proof}[Proof of Theorem~\ref{thm:lossLBmis}]
    We analyze the regret when \pref{event:misLoss} holds, which happens with probability at least $1-\frac{2}{T^2}$. When \pref{event:misLoss} does not hold, the expected regret is bounded by $\frac{2}{T}$.
    
    We then bound the regret with a fixed choice of $B$. Combining \pref{lem:delta_1_loss_miss} and \pref{lem:epoch_B_with_mis}, if action $a$ is not eliminated at the end of epoch $m$, we have
    \begin{align*}
        2^{m}\cdot \Delta_a&\leq \frac{256n\beta^2}{\Delta_a} +\frac{4DB + 12\sum_{i=1}^{|\calS_{m}|}|\lambda_{m,i}^{(a)}|\cdot D\mu_{a_{m,i}}}{|\calS_m|}+(128\log T +16)\sqrt{n}+2^m\cdot 64\sqrt{n}\epsilon, \\
        2^m\cdot \Delta_a&\leq 2^m\cdot 24\sqrt{n}\epsilon+\frac{256n\beta^2}{\Delta_a} + \frac{2D\Delta_a}{|\calS_m|}.
    \end{align*}
    Therefore, we have
    \begin{align*}
        \Delta_a \leq \order\left(\frac{n\beta^2}{2^m\cdot \Delta_a} + \sqrt{n}\epsilon + \frac{\sqrt{n}\log T}{2^m}\right) +  \frac{1}{2^m}\min\left\{\frac{4DB+12\sum_{i=1}^{|\calS_m|}|\lambda_{m,i}^{(a)}|\cdot D\mu_{a_{m,i}}}{n}, \frac{D\Delta_a}{n}\right\}.
    \end{align*}
    Denote $\calT_B$ to be the number of rounds \pref{alg:lossLBmis} proceeds with $B$ and define $\Reg_B$ be the expected regret within $\calT_B$ rounds.
    Then, for any $\alpha_m\geq 0$,  the overall regret is then upper bounded as follows:
    \begin{align*}
        \Reg_B &\triangleq \sum_{m= 1}^{\lceil\log_2(|\calT_B|/3n\rceil}\sum_{a\in \calS_m}2^{m}\cdot\Delta_a \\
        &\leq \sum_{m=1}^{\lceil\log_2(|\calT_B|/3n\rceil}\sum_{a\in \calS_m}\mathbbm{1}\{\Delta_a> \alpha_m\}\left(\order\left(\frac{n\beta^2}{\Delta_a} + 2^m\sqrt{n}\epsilon + \sqrt{n}\log T\right) \right.\\
        &\qquad +\left.\min\left\{\frac{4DB+12\sum_{i=1}^{|\calS_{m-1}|}|\lambda_{m-1,i}^{(a)}|\cdot d(a_{m-1,i})}{n}, \frac{2D\Delta_a}{n}\right\}\right) \tag{since $a$ is not eliminated in epoch $m-1$ for all $a\in\calS_m$} \\
        &\qquad + \sum_{m\geq 1}\sum_{a\in \calS_m}\mathbbm{1}\{\Delta_a\leq \alpha_m\}2^m\Delta_a.
    \end{align*}
    Picking $\alpha_m = \beta\sqrt{\frac{n}{2^m}}$, we can obtain that
    \begin{align*}
        \Reg_B &=\sum_{m= 1}^{\lceil\log_2(|\calT_B|/3n\rceil}\sum_{a\in \calS_m}\left(\order\left(\beta\sqrt{n\cdot 2^m} +2^m\sqrt{n}\epsilon+ \sqrt{n}\log T \right) \right.\\
        &\qquad +\left.\min\left\{\frac{4DB+12\sum_{i=1}^{|\calS_{m-1}|}|\lambda_{m-1,i}^{(a)}|\cdot d(a_{m-1,i})}{n}, \frac{2D\Delta_a}{n}\right\}\right) \\
        &\leq \order\left(|\calT_B|\sqrt{n}\epsilon + \beta n\sqrt{|\calT_B|}+\sqrt{n}\log T\log(T/n)\right) \\
        &\qquad + \sum_{m= 1}^{\lceil\log_2(|\calT_B|/3n)\rceil}\sum_{a\in \calS_m}\min\left\{\frac{4DB+12\sum_{i=1}^{|\calS_{m-1}|}|\lambda_{m-1,i}^{(a)}|\cdot d(a_{m-1,i})}{n}, \frac{2D\Delta_a}{n}\right\}.
    \end{align*}
    
    On the other hand, picking $\alpha_m=0$, we have
    \begin{align*}
        \Reg_B &\leq \sum_{m=1}^{\lceil\log_2(|\calT_B|/3n\rceil}\sum_{a\in \calS_m}\left(\order\left(\frac{n\beta^2}{\Delta_{\min}} + 2^m\sqrt{n}\epsilon + \sqrt{n}\log T\right) \right.\\
        &\qquad +\left.\min\left\{\frac{4DB+12\sum_{i=1}^{|\calS_{m-1}|}|\lambda_{m-1,i}^{(a)}|\cdot d(a_{m-1,i})}{n}, \frac{2D\Delta_a}{n}\right\}\right) \\
        &\leq \order\left(\frac{n^2\beta^2\log(T/n)}{\Delta_{\min}}+\epsilon\sqrt{n}|\calT_B|+\sqrt{n}\log T\log(T/n)\right)\\
        &\qquad + \sum_{m= 1}^{\lceil\log_2(|\calT_B|/3n\rceil}\sum_{a\in \calS_m} \min\left\{\frac{4DB+12\sum_{i=1}^{|\calS_{m-1}|}|\lambda_{m-1,i}^{(a)}|\cdot d(a_{m-1,i})}{n}, \frac{2D\Delta_a}{n}\right\}.
    \end{align*}

    Using the fact that $\beta=\sqrt{2\log(KT^3)}$ and combining both bounds, we can obtain that
    \begin{align}
        \Reg_B &\leq \order\left(\min\left\{\frac{n^2\log(KT)\log(T/n)}{\Delta_{\min}}, n\sqrt{|\calT_B|\log(KT)}\right\}+\epsilon\sqrt{n}|\calT_B|\right)\nonumber\\
        &\qquad + \sum_{m= 1}^{\lceil\log_2(|\calT_B|/3n\rceil}\sum_{a\in \calS_m}\min\left\{\frac{4DB+12\sum_{i=1}^{|\calS_{m-1}|}|\lambda_{m-1,i}^{(a)}|\cdot d(a_{m-1,i})}{n}, \frac{2D\Delta_a}{n}\right\}. \label{eqn:reg_b}%
    \end{align}
    For notational convenience, let $R_B=\order\left(\min\left\{\frac{n^2\log(KT)\log(T/n)}{\Delta_{\min}},n\sqrt{|\calT_B|\log(KT)}\right\}+\epsilon\sqrt{n}|\calT_B|\right)$. To further analyze this bound, we first upper bound $\min\left\{\frac{4DB+12\sum_{i=1}^{|\calS_{m-1}|}|\lambda_{m-1,i}^{(a)}|\cdot d(a_{m-1,i})}{n}, \frac{2D\Delta_a}{n}\right\}$ by $\frac{2D\Delta_a}{n}$ and obtain that
    \begin{align}\label{eqn:reg_B_1}
        \Reg_B \leq R_B + \order\left(D\Delta_{\max}\log(T/n)\right).
    \end{align}

    On the other hand, we can also upper bound $\min\left\{\frac{4DB+12\sum_{i=1}^{|\calS_{m-1}|}|\lambda_{m-1,i}^{(a)}|\cdot d(a_{m-1,i})}{n}, \frac{2D\Delta_a}{n}\right\}$ by $\frac{12\sum_{i=1}^{|\calS_{m-1}|}|\lambda_{m-1,i}^{(a)}|\cdot d(a_{m-1,i})}{n}$ and obtain that
    \begin{align*}
        \Reg_B \leq R_B + \left(\sum_{m=1}^{\lceil\log_2(|\calT_B|/3n\rceil}\sum_{a\in\calS_m}\frac{4DB+12\sum_{i=1}^{|\calS_{m-1}|}|\lambda_{m-1,i}^{(a)}|\cdot d(a_{m-1,i})}{n}\right).
    \end{align*} 

    Let $L_{\Alg}^m=\sum_{a\in \calS_m}2^m\mu_a$ be the total expected loss within epoch $m$ and $L_{\star}^m=|\calS_m|\cdot 2^m\cdot\mu^\star$ be the total expected loss for the optimal action. Define $\Reg_m=L_{\Alg}^m-L_{\star}^m$. Direct calculation shows that
    \begin{align*}
        &\sum_{a\in \calS_m}\frac{\sum_{i=1}^{|\calS_{m-1}|}|\lambda_{m-1,i}^{(a)}|\cdot d(a_{m-1,i})}{n} \\
        &\leq \frac{3D}{2^{m-1}}\cdot 2^{m-1}\sum_{i=1}^{|\calS_{m-1}|}\mu_{a_{m-1,i}}\tag{since $|\lambda_{m-1,i}^{(a)}|\leq 1$ and $|\calS_m|=3n$}\\
        &= \frac{3D}{2^{m-1}}L_{\Alg}^{m-1}.
    \end{align*}
    Using the fact that $\Reg_B = \sum_{m=1}^{\lceil\log(|\calT_B|/3n)\rceil}\Reg_m$, we know that
    \begin{align*}
        &\sum_{m=1}^{\lceil\log(|\calT_B|/3n)\rceil} (L_{\Alg}^m-L^m_{\star})\\
        &\leq \sum_{m=1}^{\lceil\log(|\calT_B|/3n)\rceil}\Reg_m + 2\epsilon\cdot |\calT_B|\\
        &\leq R_B + \sum_{m=\lceil\log_2(72D)\rceil+1}^{\lceil\log(|\calT_B|/3n)\rceil}\frac{36D}{2^{m-1}}\cdot L_{\Alg}^{m-1} + \sum_{m=1}^{\lceil\log_2(72D)\rceil}2^m\Delta_{\max} + 12DB\log(T/n) \tag{$2\epsilon\cdot |\calT_B|$ is subsumed in $R_B$}\\
        &\leq R_B + \sum_{m=\lceil\log_2(72D)\rceil+1}^{\lceil\log(|\calT_B|/3n)\rceil}\frac{36D}{2^{m-1}}\cdot \left(L_{\Alg}^{m-1}-L_{\star}^{m-1}\right) + \sum_{m=\lceil\log_2(72D)\rceil+1}^{\lceil\log(|\calT_B|/3n)\rceil}\frac{36D}{2^{m-1}}\cdot L_{\star}^{m-1} + \sum_{m=1}^{\lceil\log_2(72D)\rceil}2^m\Delta_{\max} +12DB\log(T/n)\\
        &\leq R_B + \frac{1}{2}\sum_{m=\lceil\log_2(72D)\rceil+1}^{\lceil\log(|\calT_B|/3n)\rceil} \left(L_{\Alg}^{m-1}-L_{\star}^{m-1}\right) + 36nD\mu^\star\log(T/(216nD))+144D\Delta_{\max} +12DB\log(T/n)\\
        &= R_B + \frac{1}{2}\sum_{m=\lceil\log_2(72D)\rceil+1}^{\lceil\log(|\calT_B|/3n)\rceil} \left(L_{\Alg}^{m-1}-L_{\star}^{m-1}\right) + 36nd^\star\log(T/(216nD))+144D\Delta_{\max}+12DB\log(T/n).
    \end{align*}
    Rearranging the terms, we can obtain that
    \begin{align}\label{eqn:reg_B_2}
        \Reg_B \leq R_B + 72nd^\star\log(T/(216nD))+288D\Delta_{\max}+12DB\log(T/n).
    \end{align}
    Combining \pref{eqn:reg_B_1} and \pref{eqn:reg_B_2}, we know that
    \begin{align}
        \Reg_B &\leq \order\left(\min\left\{\frac{n^2\log(KT)\log(T/n)}{\Delta_{\min}},n\sqrt{|\calT_B|\log(KT)}\right\}+\epsilon\sqrt{n}|\calT_B|\right) \nonumber \\
        &\qquad +\order\left( \min\left\{nd^\star\log (T/nD)+D\Delta_{\max}+DB\log(T/n),D\Delta_{\max}\log (T/n)\right\}\right).\label{eqn:reg_B_final}
    \end{align}
    Finally, according to \pref{lem:end-of-B}, \pref{alg:lossLBmis} fails at most $\lceil\log_2(D\mu^\star))\rceil = \lceil\log_2(d^\star))\rceil$ times. Summing up the regret over all rounds, we know that the overall regret is bounded as follows
    \begin{align*}
        \Reg \leq \sum_{r=0}^{\lceil\log_2(d^\star))\rceil}\Reg_{2^r/D} &\leq \order\left(\min\left\{\frac{n^2\log(KT)\log(T/n)\log(d^\star)}{\Delta_{\min}},n\sqrt{T\log(d^\star)\log(KT)}\right\}+\epsilon\sqrt{n}T\right) \\
        &\qquad + \log(d^\star)\cdot \order\left( \min\left\{nd^\star\log (T/n)+D\Delta_{\max},D\Delta_{\max}\log (T/n)\right\}\right),
    \end{align*}
	which finishes the proof.
\end{proof}