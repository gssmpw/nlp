\section{First Step: Non-Contextual Linear Bandits}\label{sec: linear}

In this section, we focus on the non-contextual case, which serves as a building block for eventually solving the contextual case. Before introducing our algorithm, we first briefly introduce the successive arm elimination algorithm for the simpler MAB setting proposed by \citet{schlisselberg2024delay} and their ideas of handling payoff-dependent delay. Specifically, their algorithm starts with a guess $B=1/D$ on the optimal action's loss, and maintains an active set of arms. The algorithm pulls each arm in the active set once, and constructs two LCB's (lower confidence bound) and one UCB (upper confidence bound) for each action in the active set as follows (supposing the current round being $t$):
\begin{align}
        \LCB_{t,1}(a) &= \frac{1}{\cnt_t(a)}\sum_{\tau\in\obs_t(a)}u_\tau - \sqrt{\frac{2\log T}{\cnt_t(a)}}, \label{eqn:lcb-1-mab}\\
        \LCB_{t,2}(a) &= \frac{1}{\unbiasSize_t(a)}\sum_{\tau\in\unbias_t(a)}u_{\tau} - \sqrt{\frac{2\log T}{\unbiasSize_t(a)\vee 1}}, \label{eqn:lcb-2-mab}\\
        \UCB_{t}(a) &= \frac{1}{\unbiasSize_t(a)}\sum_{\tau\in\unbias_t(a)}u_{\tau} + \sqrt{\frac{2\log T}{\unbiasSize_t(a)\vee 1}},\label{eqn:ucb-mab}
\end{align}
where $\cnt_t(a) = \sum_{\tau=1}^t\mathbbm{1}\{a_t=a\}$ is the total number of pulls of action $a$ till round $t$, $\obs_t(a) = \{\tau: \tau+d_{\tau}\leq t \text{~and~} a_{\tau}=a\}$ is the set of rounds where action $a$ is chosen and its loss has been received by the end of round $t$, $\unbias_t(a) = \{\tau \leq t-D: a_\tau = a\}$ is the set of rounds up to $t-D$ where action $a$ is chosen (so its loss has for sure been received by the end of round $t$), 
and $\unbiasSize_t(a)=|\unbias_t(a)|$. Specifically, \pref{eqn:lcb-1-mab} constructs an LCB of action $a$ assuming all the action's unobserved loss to be $0$ (the smallest possible), while \pref{eqn:lcb-2-mab} and \pref{eqn:ucb-mab} construct an LCB and a UCB using only the losses no later than round $t-D$ (which must have been received by round $t$), making the empirical average a better estimate of the expected loss. With $\UCB_t(a)$ and $\LCB_t(a) = \max\{\LCB_{t,1}(a), \LCB_{t,2}(a)\}$ constructed, the algorithm eliminates an action $a$ if its $\LCB_t(a)$ is larger than $\min\{\UCB_t(a'),B\}$ for some $a'$ in the active set. If all the actions are eliminated, this means that the guess $B$ on the optimal loss is too small, and the algorithm starts a new epoch with $B$ doubled.\footnote{In fact, \citet{schlisselberg2024delay} construct yet another LCB based on the number of unobserved losses. We omit this detail since we are not able to use this to further improve our bounds for linear bandits.}

\paragraph{Challenges} However, this approach cannot be directly applied to linear bandits. Specifically, standard algorithms for stochastic linear bandits without delay (e.g., \citet{li2010contextual,abbasi2011improved}) all construct  UCB/LCB for each action by constructing an ellipsoidal confidence set for $\theta$. In the delay-as-payoff model, while it is still viable to construct UCB/LCB similar to \pref{eqn:lcb-2-mab} and \pref{eqn:ucb-mab} via a standard confidence set of $\theta$, it is difficult to construct an LCB counterpart similar to \pref{eqn:lcb-1-mab}.
This is because one action's loss is estimated using observations of all other actions in linear bandits, and naively treating the unobserved loss of one action as zero might not necessarily lead to an underestimation of another action. 

\paragraph{Our ideas} To bypass this barrier, we give up on estimating $\theta$ itself and propose to construct UCB/LCB for each action using the observed losses of the \emph{volumatric spanner} of the action set. A volumetric spanner of an action set $\calA$ is defined such that every action in $\calA$ can be expressed as a linear combination of the spanner. 

\begin{definition}[Volumetric Spanner~\citep{hazan2016volumetric}]\label{def:volume}
Suppose that $\calA = \{a_1, a_2, \dots , a_N\}$ is a set of vectors in $\R^n$. We say $\calS\subseteq \calA$ is a \emph{volumetric spanner} of $\calA$ if for any $a\in \calA$, we can write it as $a=\sum_{b\in \calS}\lambda_b\cdot b$ for some $\lambda\in \R^{|\calS|}$ with $\|\lambda\|_2\leq 1$. 
\end{definition}

Due to the linear structure, it is clear that the loss $\mu_a$ of action $a$ can be decomposed in a similar way as $\sum_{b\in \calS}\lambda_b \mu_b$,
making it possible to estimate every action's loss by only estimating the loss of the spanner.
Moreover, such a spanner can be efficiently computed:
\begin{proposition}[\citet{bhaskara2023tight}]\label{prop:volume}
Given a finite set $\calA$ of size $K$, there exists an efficient algorithm finding a volumetric spanner $\calS$ of $\calA$ with $|\calS|=3n$ within $\order(Kn^3\log n)$ runtime.
\end{proposition}

\setcounter{AlgoLine}{0}
\begin{algorithm}
\caption{Phased Elimination via Volumetric Spanner for Linear Bandits with Delay-as-Loss}\label{alg:lossLB}

\nl Input: maximum possible delay $D$, action set $\calA$, $\beta>0$. 

\nl Initialization: optimal loss guess $B=1/D$.

\nl Initialization: active action set $\calA_1=\calA$. \label{line: restart}

 \For{$m=1,2,\dots,$}{
    \nl Find $\calS_m=\{a_{m,1},\dots,a_{m,|\calS_m|}\}$, a volumetric spanner of $\calA_m$ with $|\calS_m|= 3n$. \label{line:volume}
    
    \nl Pick each $a\in \calS_m$ $2^m$ times in a round-robin way. \label{line:round-robin}

    \nl Let $\calI_m$ contain all the rounds in this epoch.
    
    \nl For each $a\in \calS_m$, calculate the following quantities: \label{line:spanner-ucb-lcb}
    {\small
    \begin{align}
        &\hat{\mu}_{m}^+(a)=\frac{1}{2^m}\Big(\sum_{\tau\in \obs_m(a)}u_{\tau} + \sum_{\tau\in \unobs_m(a)}1\Big), \label{eqn:mean-up}\\
        &\hat{\mu}_{m}^-(a)=\frac{1}{2^m}\sum_{\tau\in \obs_m(a)}u_{\tau}, \label{eqn:mean-low}\\
        &\hat{\mu}_{m,1}^{+}(a)=\hat{\mu}^{+}_{m}(a)+\frac{\beta}{2^{m/2}}\|a\|_2, \label{eqn:loss-ucb-linear-1}\\
        &\hat{\mu}_{m,1}^{-}(a)=\hat{\mu}^{-}_{m}(a)-\frac{\beta}{2^{m/2}}\|a\|_2,\label{eqn:loss-lcb-linear-1}\\
        &\hat{\mu}_m^{F}(a)=\frac{1}{\unbiasSize_m(a)}\sum_{\tau\in \unbias_m(a)}u_{\tau}, \label{eqn:mean_unbiased}\\
        &\hat{\mu}_{m,2}^{+}(a)=\hat{\mu}_m^F(a)+\frac{\beta}{\sqrt{\unbiasSize_m(a)}}\|a\|_2, \label{eqn:loss-ucb-linear-2}\\
        &\hat{\mu}_{m,2}^{-}(a)=\hat{\mu}_m^F(a)-\frac{\beta}{\sqrt{\unbiasSize_m(a)}}\|a\|_2, \label{eqn:loss-lcb-linear-2}
    \end{align}
    }
    where $\unbiasSize_m(a) = |\unbias_m(a)|$, $\unbias_m(a) = \{\tau\in \calI_m: \tau+D\in\calI_m, a_{\tau}=a\}$, $\obs_m(a) = \{\tau\in \calI_m: \tau+d_{\tau}\in\calI_m, a_{\tau}=a\}$, and
    $\unobs_m(a)= \{\tau\in \calI_m: a_{\tau}=a\}\setminus\obs_m(a)$.

    \For{each $a\in \calA_m$}{
        \nl \label{line: decompose}
        Decompose $a$ as $a=\sum_{i=1}^{|S_m|}\lambda_{m,i}^{(a)}a_{m,i}$ with $\|\lambda_{m}^{(a)}\|_2\leq 1$ and calculate 
        {\small
        \begin{align}
            &\UCB_{m}(a)=\sum_{i=1}^{|\calS_m|}\lambda_{m,i}^{(a)}\cdot\hat{\mu}_{m,2}^{\sgn(\lambda_{m,i}^{(a)})}(a_{m,i}), \label{eqn:loss-ucb-f-all-action} \\
            &\LCB_m(a) = \max_{j\in \{1,2\}}\{\LCB_{m,j}(a)\} \;\;\text{where} \nonumber  \\
            & \LCB_{m,j}(a)=\sum_{i=1}^{|\calS_m|}\lambda_{m,i}^{(a)}\cdot\hat{\mu}_{m,j}^{\sgn(-\lambda_{m,i}^{(a)})}(a_{m,i}),\label{eqn:loss-lcb-all-action}
        \end{align}
        }
    }
    
    \nl Set $\calA_{m+1} = \calA_m$.
    
    \For{$a\in \calA_m$}{
        \nl \label{line:eliminate}  
        \If{$\exists a'\in \calA_m$, s.t. $\LCB_m(a) \geq \min\{\UCB_m(a'),B\} $}
        {
          Eliminate $a$ from $\calA_{m+1}$.
        }
    }
    \nl \If{$\calA_{m+1}=\emptyset$}{
        Set $B\leftarrow 2B$ and go to \pref{line: restart}.
    }
}
\end{algorithm}

Equipped with the concept of volumetric spanner, we are now ready to introduce our algorithm (see \pref{alg:lossLB}). 
Specifically, our algorithm also makes a guess $B$ on the loss of the optimal action. 
With this guess, it proceeds to multiple epochs of arm elimination procedures, with the active action set initialized as $\calA_1 = \calA$.
In each epoch $m$, instead of picking every action in the active set $\calA_m$, we first compute a volumetric spanner $\calS_m$ of $\calA_m$ with $|\calS_m|=3n$ (\pref{line:volume}), which can be done efficiently according to \pref{prop:volume}, 
and then pick each action in the spanner set $\calS_m$ for $2^m$ rounds in a round-robin way (\pref{line:round-robin}).

After that, we calculate two UCBs and two LCBs for actions in the spanner, in a way similar to the simpler MAB setting discussed earlier (\pref{line:spanner-ucb-lcb}).
Specifically, 
the first one is in the same spirit of \pref{eqn:lcb-1-mab}:
we calculate $\hat{\mu}_m^+(a)$ ( $\hat{\mu}_m^-(a)$) as an overestimation (underestimation) of the expected loss of action $a$ by averaging over all observed losses from the rounds in $\obs_m(a)$ as well as the maximum (minimum) possible value of unobserved losses from the rounds in $\unobs_m(a)$; see \pref{eqn:mean-up} and \pref{eqn:mean-low}.
The first UCB (LCB) $\hat{\mu}_{m,1}^+(a)$ ($\hat{\mu}_{m,1}^-(a)$) is then computed based on $\hat{\mu}_m^+(a)$ ($\hat{\mu}_m^-(a)$) by incorporating a standard confidence width $\frac{\beta}{\sqrt{2^m}}\|a\|_2$ for some coefficient $\beta$; see \pref{eqn:loss-ucb-linear-1} and \pref{eqn:loss-lcb-linear-1}.
Then, to compute the second UCB/LCB, which is in the same spirit as \pref{eqn:lcb-2-mab} and \pref{eqn:ucb-mab}, we calculate an unbiased estimation $\hat{\mu}_m^F(a)$ of the expected loss of $a$ by averaging losses from the rounds in $\unbias_m(a)$, that is, all the rounds where the observation must have been revealed; see \pref{eqn:mean_unbiased}.
Note that the number of such rounds, $\unbiasSize_m(a) = |\unbias_m(a)|$, is a fixed number, and thus $\hat{\mu}_m^F(a)$ is indeed unbiased.
Similarly, we incorporate a standard confidence width $\frac{\beta}{\sqrt{c_m(a)}}\|a\|_2$ to arrive at the second UCB $\hat{\mu}_{m,2}^+(a)$ and LCB $\hat{\mu}_{m,2}^-(a)$; see \pref{eqn:loss-ucb-linear-2} and \pref{eqn:loss-lcb-linear-2}.

The next step of our algorithm is to use these UCBs/LCBs for the spanner to compute corresponding UCBs/LCBs for every active action in $\calA_m$ (\pref{line: decompose}). Specifically, for each action $a\in \calA_m$, according to the definition of a volumetric spanner (\pref{def:volume}), we can write $a$ as a linear combination of actions in $\calS_m$: $\sum_{i=1}^{|S_m|}\lambda_{m,i}^{(a)}a_{m,i}$. As mentioned, due to the linear structure of losses, we also have $\mu_a = \sum_{i=1}^{|S_m|}\lambda_{m,i}^{(a)}\mu_{a_{m,i}}$.
Thus, when constructing a UCB (or similarly LCB) for $a$, based on whether $\lambda_{m,i}^{(a)}$ is positive or not, we decide whether to use the UCB or LCB of $a_{m,i}$; see \pref{eqn:loss-ucb-f-all-action}, a counterpart of \pref{eqn:ucb-mab}, and \pref{eqn:loss-lcb-all-action}, a counterpart of \pref{eqn:lcb-1-mab} and \pref{eqn:lcb-2-mab}.\footnote{This also explains why we need $\hat{\mu}_m^+(a)$, a quantity not used in~\citet{schlisselberg2024delay}.}

At the end of an epoch, we eliminate all actions from the active action set if their LCB is either larger than the UCB of certain action or the guess $B$ on the optimal loss  (\pref{line:eliminate}). 
If the active set becomes empty, this means that the guess $B$ is too small, and the algorithm restarts with the guess doubled; 
otherwise, we continue to the next epoch.

\paragraph{Theoretical performance}
We prove the following regret bound for our algorithm. 
\begin{restatable}{theorem}{lossLB}
\label{thm:main-non-contextual}
    \pref{alg:lossLB} with $\beta=\sqrt{2\log(KT^3)}$ guarantees: 
\begin{align*}
        \Reg &\leq \order\left(\min\left\{V_1,V_2\right\}\right) + \log(d^\star)\cdot \order\left( \min\left\{W_1,W_2\right\}\right),
    \end{align*}
    where $V_1=\frac{n^2\log(KT)\log(T/n)\log(d^\star)}{\Delta_{\min}}$, $V_2=n\sqrt{T\log(d^\star)\log(KT)}$, $W_1=nd^\star\log (T/n)+D\Delta_{\max}$, and $W_2=D\Delta_{\max}\log (T/n)$. 
\end{restatable}
The first term in the regret bound $\order\left(\min\left\{V_1,V_2\right\}\right)$ is of order $\otil(\min\{\frac{n^2}{\Delta_{\min}}, n\sqrt{T}\})$, which matches the standard regret bound of LinUCB in the case without delay~\citep{abbasi2011improved}.
The second term is the overhead caused by delay and is in the same spirit as the result of~\citet{schlisselberg2024delay}:
focusing only on the part that grows in $T$, 
we see that $W_1$ only depends on $d^\star$, the expected delay of the optimal action (and hence the smallest delay among all actions),
while $W_2$ depends on the maximum possible delay $D$ but scaled by $\Delta_{\max}$, the largest sub-optimality gap.
Therefore, the delay overhead of our algorithm is small when either the shortest delay is small or all actions have similar losses.
We remark again that in the delay-as-reward setting, we obtain similar results; see \pref{app: reward} for details.

\input{algorithm_analysis}








