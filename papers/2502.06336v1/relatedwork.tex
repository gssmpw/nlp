\section{Related Work}
\label{RelatedWork}
In recent years, the use of transformers and DGCNN-based approaches for non-rigid point cloud registration has increased. This section presents a review of several registration methods based on these two approaches. A summary of some notable methods is provided in Table \ref{table:LearningMethod}.


\begin{table*}
\footnotesize
\centering
\caption{Overview of some learning-based non-rigid point cloud registration methods based on Transformers and DGCNN}
\label{table:LearningMethod}
\begin{tabular}{p{2.25cm} p{1cm} p{2.5cm} p{4cm} p{6cm}} 
\hline
Methods&Year& \raggedright Network Architecture & Robustness & Experimental Data \\
\hline

\citep{hansen2019learning}&2019& DGCNN & Noise, outliers & Medical dataset \\
\hline


PRNet \citep{wang2019prnet}&2019 & \raggedright DGCNN, Transformer  & Noise, partial & ShapeNetCore\citep{chang2015shapenet}, ModelNet40 \citep{wu20153d}  \\
\hline

CoFiNet \cite{yu2021cofinet}&2021& Transformer& Outlier, partial & odometryKITTI \cite{geiger2013vision}, 3Dmatch \cite{zeng20173dmatch}, 3DLoMatch \cite{huang2021predator}\\\hline

NrtNet \citep{hu2022nrtnet}&2022  &  \raggedright DGCNN, Transformer & Deformation levels & SURREAL \citep{varol2017learning}, SHRECâ€™19 \citep{melzi2019shrec}, MIT \citep{grosse2009ground}\\
\hline

\cite{qin2022geometric}&2022&Transformer&Outlier, partial&odometryKITTI \cite{geiger2013vision}, 3Dmatch \cite{zeng20173dmatch}, 3DLoMatch \cite{huang2021predator}\\\hline

\cite{yew2022regtr} &2022&Transformer&Outlier, partial&3Dmatch \cite{zeng20173dmatch}, 3DLoMatch \cite{huang2021predator}, ModelNet \cite{wu20153d}\\\hline
Lepard \cite{li2022lepard} &2022&Transformer&Outlier, partial, deformation levels&3Dmatch \cite{zeng20173dmatch}, 3DLoMatch \cite{huang2021predator}, 4DMatch \cite{li2022lepard} \\\hline

OIF-PCR \cite{yang2022one} &2022&Transformer&Outlier, partial&odometryKITTI \cite{geiger2013vision}, 3Dmatch \cite{zeng20173dmatch}, 3DLoMatch \cite{huang2021predator}\\\hline

GraphSCNet \cite{qin2023deep}&2023&GCNN&Outliers, deformation levels, partial & 4DMatch \cite{li2022lepard}, CAPE \cite{pons2017clothcap}, DeepDeform \cite{bozic2020deepdeform}\\
\hline

NIE \cite{jiang2023neural}&2023&DGCNN&Noise, partial &SURREAL \citep{varol2017learning}, FAUST \cite{bogo2014faust}, SCAPE \cite{anguelov2005scape}\\
\hline

MAFNet \cite{chen2024mafnet}&2024&Transformer&Noise, partial&7-Scenes \citep{shotton2013scene}, ModelNet \citep{wu20153d}\\
\hline

Robust-DefReg\cite{monji2024robust} &2024&GCNN&Noise, outliers, deformation levels&SynBench\cite{DataSynBench}, ModelNet \citep{wu20153d}\\
\hline

\end{tabular}
\end{table*}

Transduction models refer to machine learning models that convert one type of data (usually a sequence) into another type, while preserving the input-output structure \cite{belhasin2022transboost}. In the context of sequence transduction, the goal is to map an input sequence (e.g., a sentence in one language) to an output sequence (e.g., the translated sentence in another language). Transduction models typically use architectures like Recurrent Neural Networks (RNNs), Convolutional Neural Networks (CNNs), or Transformers, which are designed to handle sequential data efficiently. Most sequence transduction models use complex recurrent or convolutional neural networks with an encoder-decoder structure, often improved by attention mechanisms \cite{chalvidal2024learning}. This setup is particularly effective for tasks such as machine translation, where maintaining contextual relevance between input and output is crucial.

In \cite{vaswani2017attention}, the transformer is introduced as a model in the field of deep learning, particularly for natural language processing (NLP) tasks like machine translation. The authors propose the transformer, an architecture that relies solely on attention mechanisms, eliminating the need for recurrence or convolutions entirely. This innovation allows for faster training through parallelization and easier modeling of long-range dependencies in sequences. This paper became the foundation for subsequent advancements, including BERT, GPT, and other transformer-based models that dominate NLP today. Notably, the flexibility and power of transformers have led to their adaptation beyond language tasks, with applications in 3D point cloud processing. For instance, among the initial studies using transformers to process point clouds, \cite{zhao2021point} introduces an approach to 3D point cloud processing by adapting self-attention mechanisms, which have been highly successful in natural language processing and image analysis. The authors design self-attention layers specifically for 3D point clouds and construct networks to tackle tasks like semantic scene segmentation, object part segmentation, and object classification. Further expanding on this, \cite{guo2021pct} presents a Transformer-based framework for processing 3D point clouds, addressing challenges like their irregular domain and lack of order. Unlike traditional deep learning methods, PCT is inherently permutation invariant, making it well-suited for unordered point cloud data. To capture local geometric context effectively, the framework enhances input embedding through farthest point sampling and nearest neighbor search. PCT demonstrates state-of-the-art performance across various tasks, including shape classification, part segmentation, semantic segmentation, and normal estimation, showcasing its effectiveness and versatility for point cloud learning in applications such as autonomous driving, robotics, and 3D modeling.

While transformers have seen widespread use in classification and segmentation tasks, their application in point cloud registration (PCR) remains limited. Early methods like Deep Closest Point \cite{wang2019deep} employ transformers for rigid PCR, incorporating three main components: a point cloud embedding network to extract meaningful features, an attention-based module with a pointer generation layer for estimating combinatorial matches between points, and a differentiable singular value decomposition (SVD) layer to compute the rigid transformation. To address the challenges of point cloud registration, \cite{qin2022geometric} introduces a Geometric Transformer that improves the extraction of accurate correspondences in low-overlap scenarios, bypassing traditional keypoint detection. This keypoint-free approach matches superpoints (downsampled clusters of points) based on the overlap of their neighboring patches, further enhancing robustness and ensuring invariance to rigid transformations. Similarly, CoFiNet (Coarse-to-Fine Network) \cite{yu2021cofinet} tackles point cloud registration without relying on keypoint detection. It operates in a hierarchical manner, first matching down-sampled nodes at a coarse scale, where the model uses a weighting scheme to focus on areas with more overlap, thus reducing the search space for the next stage. At a finer scale, the model refines these matches by expanding node proposals into patches of points with associated descriptors. A density-adaptive matching module is then used to further refine point correspondences based on overlap in corresponding patches, effectively handling varying point densities. These techniques highlight the ongoing efforts to enhance the accuracy and efficiency of point cloud registration, particularly when facing complex real-world challenges such as varying densities and overlapping regions.

Another notable contribution in point cloud registration is OIF-PCR \cite{yang2022one}, a position encoding method that improves correspondence accuracy by using one inlier as a reference. The method finds a single correspondence through a differentiable optimal transport layer, then normalizes each point for position encoding. This approach addresses issues related to differing reference frames between point clouds and reduces feature ambiguity by learning spatial consistency. The integration of correspondence and position encoding in an iterative optimization process allows for progressive refinement of point cloud alignment and feature learning. Along these lines, \cite{yew2022regtr} proposes an end-to-end point cloud registration framework that eliminates the need for traditional feature matching and outlier filtering methods like RANSAC, replacing them with attention mechanisms. The network, built around transformer layers, incorporates self- and cross-attention mechanisms to directly predict the final set of correspondences, which can then be used to estimate the required rigid transformation without the need for post-processing steps.

For partial point cloud matching, Lepard \cite{li2022lepard} integrates 3D positional knowledge into the registration process. This method begins by combining the KPFCN feature extractor with the Transformer model and differentiable matching techniques, and introduces three key innovations to enhance the use of 3D positional information. These include disentangling point cloud representations into feature and position spaces, developing a position encoding method to capture 3D relative distances, and implementing a repositioning module that adjusts relative positions between points across point clouds. These improvements enable more accurate matching in partial point cloud registration tasks, further illustrating the potential of transformer-based methods for dealing with complex point cloud data.

Shifting focus to Graph Convolutional Neural Networks (GCNNs), \cite{zhang2019graph} shows how these networks process data structured as graphs, learning geometric features based on the relationships between neighboring nodes. This approach is particularly effective for point clouds, where the structure of data is inherently graph-like. In the medical domain, GCNNs have shown promise for tasks like 3D lung registration \cite{hansen2021deep}, where edge convolutions are used to extract geometric features, and Loopy Belief Propagation (LBP) regularizes displacements on a k-nearest neighbor graph. Additionally, \cite{hansen2019learning} introduces a dynamic GCNN approach for point cloud registration, which refines correspondences probabilistically using the Coherent Point Drift (CPD) algorithm. These approaches demonstrate the versatility of GCNNs in handling various point cloud registration challenges, particularly when dealing with complex deformable structures.

Continuing this line of research, \cite{hu2022nrtnet} introduces NrtNet, an unsupervised transformer-based network designed for non-rigid point cloud registration. This method leverages self-attention mechanisms to extract feature correspondences between large deformations. NrtNet's three main componentsâ€”a feature extraction module, a correspondence matrix generation module, and a reconstruction moduleâ€”work together to align point clouds by learning and normalizing correspondence probabilities. This approach is designed to handle large-scale deformations, a significant challenge in non-rigid point cloud registration. Extending this work, \cite{qin2023deep} proposes GraphSCNet, a network that tackles outlier correspondence pruning, particularly in non-rigid point cloud registration. GraphSCNet addresses the challenge of local rigidity in non-rigid deformations by using a local spatial consistency measure to evaluate correspondence compatibility, ensuring better outlier discrimination and improving the overall accuracy of registration.

Building on the concept of structural alignment, \cite{jiang2023neural} presents NIE, a method for embedding vertices of point clouds into a high-dimensional space to preserve intrinsic structural properties. This technique is particularly useful for aligning point clouds sampled from deformable shapes, which often lack explicit structural information. NIE forms the foundation for a weakly-supervised framework for non-rigid point cloud registration, avoiding expensive preprocessing steps and the reliance on ground-truth correspondence labels. Finally, Robust-DefReg \cite{monji2024robust} leverages graph convolutional networks in a coarse-to-fine framework to handle large deformations, noise, and outliers. This end-to-end approach focuses on global feature learning to establish accurate correspondences and transformations across varying deformation scales. Another key contribution of this work is the development of SynBench \cite{DataSynBench}, a comprehensive benchmark dataset for evaluating non-rigid registration methods, which supports further advancements in the field.