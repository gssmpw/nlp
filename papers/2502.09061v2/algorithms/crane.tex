% \begin{algorithm}
% \small
% \caption{LLM Generation with \Tool{}}
% \label{alg:crane}
% \begin{flushleft}
% \textbf{Inputs:} 
% \begin{itemize}
%     \item LLM: A language model capable of generating token scores.
%     \item curr\_tokens: The current sequence of tokens.
%     \item tokenizer: A tokenizer for encoding and decoding tokens.
%     \item constraint\_tool: A tool for enforcing grammatical constraints.
%     \item output\_grammar: The grammar to be enforced during generation.
%     \item start\_symbol: The symbol indicating the start of a constrained generation.
%     \item end\_symbol: The symbol indicating the end of a constrained generation.
% \end{itemize}

% \textbf{Output:} A generated sequence of tokens adhering to the specified grammar.

% \begin{algorithmic}[1]
% \Function{crane}{LLM, curr\_tokens, tokenizer, constraint\_tool, output\_grammar, start\_symbol, end\_symbol}
% \State $\text{output\_grammar} \gets \text{add\_special\_symbols}(\text{output\_grammar}, \text{start\_symbol}, \text{end\_symbol})$
% \State $\text{constraint\_tool.initialize}(\text{output\_grammar})$
% \State $\text{overall\_gen} \gets \text{''}$
% \State $\text{structured\_gen} \gets \text{''}$
% \State $\text{current\_state} \gets \text{Unconstrained}$
% \State $\text{last\_constrained\_end} \gets \text{len}(\text{curr\_tokens}) - 1$

% \While{True}
%     \If{$\text{current\_state} == \text{Constrained}$ \textbf{and} $\text{structured\_gen.endswith}(\text{end\_symbol})$}
%         \State $\text{constraint\_tool.parser.reset}()$
%         \State $\text{current\_state} \gets \text{Unconstrained}$
%         \State $\text{last\_constrained\_end} \gets \text{len}(\text{curr\_tokens}) - 1$
%     \EndIf

%     \State $\text{scores} \gets \text{LLM}(\text{curr\_tokens})$

%     \If{$\text{current\_state} == \text{Constrained}$}
%         \State $\text{structured\_gen} \gets \text{detokenize}(\text{tokenizer}, \text{curr\_tokens}[:, \text{start\_constrained\_from}:])$
%         \State $\text{constraint\_tool.parser.update}(\text{start\_symbol} + \text{structured\_gen})$
%         \State $\text{m} \gets \text{generate\_mask}(\text{constraint\_tool.parser})$
%         \State $\text{scores} \gets \text{m} \odot \text{scores}$
%     \EndIf

%     \State $\text{t\_i} \gets \text{decoding\_algorithm}(\text{scores})$

%     \If{$\text{t\_i} == \text{EOS}$}
%         \State \textbf{break}
%     \EndIf

%     \State $\text{curr\_tokens} \gets \text{append}(\text{curr\_tokens}, \text{t\_i})$

%     \If{$\text{current\_state} == \text{Unconstrained}$}
%         \State $\text{unstructured\_gen} \gets \text{detokenize}(\text{tokenizer}, \text{curr\_tokens}[:, \text{last\_constrained\_end} + 1:])$
%         \If{$\text{start\_symbol} \in \text{unstructured\_gen}$}
%             \State $\text{start\_constrained\_from} \gets \text{len}(\text{curr\_tokens})$
%             \State $\text{current\_state} \gets \text{Constrained}$
%         \EndIf
%     \EndIf

%     \State $\text{overall\_gen} \gets \text{detokenize}(\text{tokenizer}, \text{curr\_tokens})$

%     \If{$\text{len}(\text{curr\_tokens}) > \text{max\_tokens}$}
%         \State \textbf{break}
%     \EndIf
% \EndWhile

% \State \textbf{return} $\text{overall\_gen}$
% \EndFunction
% \end{algorithmic}
% \end{flushleft}
% \end{algorithm}