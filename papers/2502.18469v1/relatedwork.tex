\section{Related Work}
Research in the field of topic naming has evolved significantly over the years, starting from early probabilistic and bag-of-words approaches to more recent applications of deep learning and contextual embeddings.

Mei et al. \citep{mei2007} used probabilistic methods for automatic labeling, looking at the problem as an optimization task to minimize the Kullback-Leibler divergence between topic word distributions and label word distributions. Aletras and Stevenson \citep{aletras2014} proposed a graph-based approach, generating topic labels by querying topic keywords and constructing a graph from the resulting search words, which are then ranked. Lau et al. \citep{lau2011} used top-ranking topic keywords to generate a candidate label set from Wikipedia titles, which was then ranked to identify the best label based on association measures and lexical features.

Wan and Wang \citep{wan2016} utilized text summarization techniques to generate topic labels. Their method applied submodular optimization to extract sentences from the most relevant documents within a topic, summaries with high relevance and coverage. More recently, Alokaili et al. \citep{alokaili2020} trained a sequence-to-sequence neural model on a synthetic dataset derived from Wikipedia to automate topic labeling. The performance of their approach was evaluated using BERTScore, which measures the similarity between the generated labels and the gold standard labels \citep{zhang2020}.

The development of Large Language Models (LLMs) marked a major shift in labeling approaches. LLMs can process vast amounts of text data and are highly effective in capturing semantic meaning and identifying similarities in documents to generate meaningful topic labels. Kozlowski et al. applied BERTopic \citep{grootendorst2022} to extract the top 10 words for each topic, and then used the Flan, GPT-4o, and GPT-4 mini models to generate topic labels from these keywords \citep{kozlowski2024}. The accuracy of the labels in representing the topics was evaluated qualitatively.

\newcolumntype{C}[1]{>{\centering\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}

\begin{table*}
    \centering
    \scalebox{1.35}{
        \begin{tabular}{|C{1in}|C{1in}|C{1in}|} \hline   
            \centering \textbf{Approach}& \centering \textbf{BBC}& \textbf{20 Newsgroup} \\ \hline
            \centering 1& \centering 0.0989 &  0.1183\\\hline
            \centering 2& \centering 0.0665 & \textbf{0.1324} \\ \hline  
            \centering 3& \centering \textbf{0.1200} & 0.1295 \\\hline
            \centering 4& \centering 0.0853& 0.1202 \\\hline 
        \end{tabular}
    }
    \caption{The values calculated by our metric for the various approaches described above on the BBC and 20 Newsgroups dataset.}
    \label{tab:my_label1}
\end{table*}