\section{Related Work}
\paragraph{Language understanding benchmarks}
Multi-task language understanding evaluation benchmarks play an important role in the evaluation of LLMs. Early benchmarks concentrated on general natural language understanding. GLUE ____ and SuperGLUE ____ were two such benchmarks that were widely adopted by the research community. These benchmarks were saturated quickly, due to the development of better LLMs. However, LLMs struggled more against benchmarks that required knowledge and reasoning. MMLU ____ and MMLU-Pro ____ were more challenging since they required not only language understanding but also world knowledge. These general-purpose benchmarks gradually gave way to higher-level and more specialized benchmarks such as MATH ____, GPQA ____, and MUSR ____.

\paragraph{Multilingual benchmarks}
The development of multilingual LLMs also necessitated challenging multilingual benchmarks. Most of these benchmarks were developed through machine translation ____. However, such datasets have been shown to contain cultural biases and translation artifacts ____. Global MMLU relied on machine and professional translation to ____. INCLUDE consists of native data ____, but it is imbalanced, with different subject distributions in different languages. There is also a significant difference in required knowledge levels between languages, making a direct comparison impossible.

\paragraph{Benchmarks for Turkic languages}
SeaEval was one of the first LLM benchmarks to include Turkish ____. Global MMLU contains Kyrgyz and Turkish subsets. INCLUDE contains Azerbaijani and Kazakh. MRL 2024 Shared Task on Multi-lingual Multi-task Information Retrieval ____ contains an Azerbaijani dataset, but it contains general language understanding tasks rather than world knowledge. Karde≈ü-NLU has introduced a multilingual language understanding benchmark ____. But again, this benchmark contains general language understanding tasks that require no world knowledge. There are also monolingual benchmarks. Mukayese was one of the earliest general language understanding benchmarks in Turkish ____. TurkishMMLU and TR-MMLU ____ were the first native MMLU alternatives for the Turkish language. Another pilot study was performed to evaluate LLMs in Kazakh language ____. While there are no peer-reviewed monolingual MMLU alternatives for Azerbaijani, there is a general language understanding benchmark ____.

\begin{figure}
    \centering
    \includegraphics[width=0.9\linewidth]{latn_vs_cyrl.png}
    \caption{A sample question from the parallel Uzbek dataset, available in both Cyrillic and Latin alphabets. This enables comparison of LLM performance across different scripts. English translation is provided for clarity.}
    \label{fig:dual_dataset}
\end{figure}