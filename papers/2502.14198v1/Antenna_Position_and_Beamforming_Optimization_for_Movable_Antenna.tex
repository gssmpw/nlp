\documentclass[lettersize,journal]{IEEEtran}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{algorithm}
\usepackage{array}
\usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
\usepackage{textcomp}
\usepackage{stfloats}
\usepackage{url}
\usepackage{verbatim}
\usepackage{graphicx,psfrag,epsfig}
\usepackage{cite}
\usepackage{amssymb}
\usepackage{amsmath,lipsum}
\usepackage{cuted}
\usepackage{balance}
\usepackage{arydshln}
\usepackage{bm}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{subeqnarray}
\usepackage{cases}
\usepackage{xcolor}
\usepackage{soul}
\sethlcolor{green}


\graphicspath{{./}}
\newtheorem{Theorem}{Theorem}
\newtheorem{Lemma}{Lemma}
\newtheorem{Proof}{Proof}
\newtheorem*{remark}{Remark}
\hyphenation{op-tical net-works semi-conduc-tor IEEE-Xplore}
% updated with editorial comments 8/9/2021

\def\linspread{0.94}
\def\linspreadalgr{0.75}
\linespread{\linspread}		
\setlength{\textfloatsep}{0.1cm} 

\setlength{\skip\footins}{5pt}

\IEEEaftertitletext{\vspace{-27pt}}
\begin{document}

\title{Antenna Position and Beamforming Optimization for Movable Antenna Enabled ISAC: Optimal Solutions and Efficient Algorithms}

\author{Lebin Chen, \IEEEmembership{Student Member,~IEEE,} Ming-Min Zhao,
	\IEEEmembership{Senior Member,~IEEE}, Min-Jian Zhao, \IEEEmembership{Member,~IEEE}, and Rui Zhang, \IEEEmembership{Fellow,~IEEE}
	\thanks{L. Chen, M. M. Zhao, and M. J. Zhao are with the College of Information Science and Electronic
		Engineering, Zhejiang University, Hangzhou 310027, China (e-mail:
		12431101@zju.edu.cn; zmmblack@zju.edu.cn; mjzhao@zju.edu.cn).}
	\thanks{
		R. Zhang is with School of Science and Engineering, Shenzhen Research Institute of Big Data, The Chinese University of Hong Kong, Shenzhen, Guangdong 518172, China (e-mail: rzhang@cuhk.edu.cn). He is also with the Department of Electrical and Computer Engineering, National University of Singapore, Singapore 117583 (e-mail: elezhang@nus.edu.sg).}
        % <-this % stops a space
%\thanks{}% <-this % stops a space
%\thanks{}
}

% The paper headers
%\markboth{Journal of \LaTeX\ Class Files,~Vol.~14, No.~8, August~2021}%
%{Shell \MakeLowercase{\textit{et al.}}: A Sample Article Using IEEEtran.cls for IEEE Journals}

%\IEEEpubid{0000--0000/00\$00.00~\copyright~2021 IEEE}
% Remember, if you use this you must call \IEEEpubidadjcol in the second
% column for its text to clear the IEEEpubid mark.

\maketitle


\begin{abstract}
In this paper, we propose an integrated sensing and communication (ISAC) system enabled by movable antennas (MAs), which can dynamically adjust antenna positions to enhance both sensing and communication performance for future wireless networks.	
%In this paper, we propose a integrated sensing and communication (ISAC) system enabled by the movable antenna (MA) for future 6G networks. 
%The proposed MA-based ISAC design overcomes the inherent limitations of traditional fixed-position antenna (FPA) arrays by introducing dynamic antenna positioning, which significantly enhances both sensing and communication performance. 
To characterize the benefits of MA-enabled ISAC systems, we first derive the Cramér-Rao bound (CRB) for angle estimation error, which is then minimized for optimizing the antenna position vector (APV) and beamforming design, subject to a pre-defined signal-to-noise ratio (SNR) constraint to ensure the communication performance.
In particular, for the case with receive MAs only, we provide a closed-form optimal antenna position solution, and show that employing MAs over conventional fixed-position antennas (FPAs) can achieve a sensing performance gain upper-bounded by 4.77 dB.
%a sensing performance gain of up to 4.77 dB can be achieved by employing MAs over conventional fixed-position antennas (FPAs). 
On the other hand, for the case with transmit MAs only, we develop a boundary traversal breadth-first search (BT-BFS) algorithm to obtain the global optimal solution in the line-of-sight (LoS) channel scenario, along with a lower-complexity boundary traversal depth-first search (BT-DFS) algorithm to find a local optimal solution efficiently. While in the scenario with non-LoS (NLoS) channels, a majorization-minimization (MM) based Rosen's gradient projection (RGP) algorithm with an efficient initialization method is proposed to obtain stationary solutions for the considered problem, which can be extended to the general case with both transmit and receive MAs. 
Extensive numerical results are presented to verify the effectiveness of the proposed algorithms, and demonstrate the superiority of the considered MA-enabled ISAC system over conventional ISAC systems with FPAs in terms of sensing and communication performance trade-off.
\end{abstract}


\begin{IEEEkeywords}
Integrated sensing and communication (ISAC), movable antenna (MA), Cramér-Rao bound (CRB), beamforming design, antenna position optimization.
\end{IEEEkeywords}
\vspace{-0.3cm}
\section{Introduction}
\IEEEPARstart{I}{ntegrated} sensing and communication (ISAC) has been identified as a key enabling technology for the future/six-generation (6G) wireless networks, with the ability to offer unified communication and sensing functionalities in a single system\cite{6gWCsystems}. This integration is particularly important for emerging applications such as autonomous driving, smart cities, and immersive virtual reality, all of which require not only high-speed data transmission but also precise sensing capabilities\cite{Avisionof6g}. 
ISAC enables simultaneous sensing and communication by leveraging shared hardware and spectrum, which reduces deployment costs and energy consumption. Moreover, ISAC offers potential performance improvements through joint optimization of communication and sensing tasks, allowing for dynamic trade-offs depending on real-time requirements\cite{intro16}. As a result, ISAC is expected to play a critical role in the deployment of future wireless systems, where diverse and dynamic demands will need to be met seamlessly\cite{ISACsurvey}.
%\cite{ISACsurvey,Aroadtowards6g}.

In many communication and sensing systems, fixed-position antenna (FPA) arrays, such as uniform linear/planar arrays (ULAs/UPAs) and sparse arrays\cite{sparse}, are usually employed. While FPAs are widely used in existing applications\cite{intro7,intro9,ap1},
%\cite{intro6,intro7,intro9,ap1}, 
their limitations become evident in the context of ISAC, where flexibility and adaptability are crucial. FPAs consist of antennas fixed in place with pre-defined geometries, which restrict their ability to adapt to varying sensing and communication environments \cite{ma2024movableantennaenhancedwireless,fpa1,fpa2}.
One major drawback of FPAs is their inability to optimize the antenna configuration in real-time. In wireless sensing tasks, the system performance such as radar resolution, heavily depends on the geometry of the antenna array. 
From a communication perspective, FPAs also face significant limitations, especially in multiple-input multiple-output (MIMO) systems, since the channel capacity in MIMO systems is closely tied to the spatial configuration of antennas, and FPAs are unable to leverage the full potential of spatial diversity due to their static positions\cite{10243545,MAsurvey}. This rigidity constrains their ability to dynamically reshape the MIMO channel matrix to improve the communication performance. In rich multipath environments, where spatial diversity is crucial for improving receiver signal-to-noise ratio (SNR) and channel capacity, FPAs are unable to adapt to substantial spatial/time variations of wireless channels and thus may result in poor  performance. Additionally, attempts to improve the performance by increasing the number of antennas lead to higher hardware costs and energy consumption, making large-scale FPA deployment practically challenging in many real-world scenarios\cite{10243545}.
%\cite{10243545,MAWC}.

\vspace{-0.1cm}
Fortunately, movable antenna (MA) system, also known as fluid antenna system (FAS) \cite{zhu2024historicalreviewfluidantenna}, offers a promising alternative solution to overcome the limitations of FPAs in ISAC applications. Unlike FPAs, MAs can dynamically adjust their positions, allowing for real-time optimization of both communication and sensing tasks. This new degree of freedom is envisioned to significantly enhance the system performance, particularly in complex and dynamic environments.
In wireless sensing, MAs provide substantial improvements in tasks such as angle of arrival (AoA) estimation and target detection \cite{ma2024movableantennaenhancedwireless}. By allowing antenna elements to move and reconfigure, MA systems can increase the effective aperture of the array by spreading the antennas over a larger area, resulting in higher angular resolution without increasing the number of antennas, thus maximizing antenna cost-efficiency\cite{ma2024movableantennaenhancedwireless}.
For communication systems, MA-enabled MIMO systems offer significant advantages in terms of channel capacity and spatial multiplexing gain\cite{10243545}. By optimizing the positions of both transmit and receive antennas, MA systems can reconfigure the MIMO channel matrix to enhance channel quality and improve data throughput. This adaptability allows MA systems to maximize the use of spatial diversity in multipath environments, leading to higher capacity compared to traditional FPA systems\cite{MA2}. 
%\cite{MA1,MA2,MA3}. 
Additionally, MA systems are particularly beneficial in multi-user communication environments, where precise control over antenna positions can help mitigate interference and improve performance for all users\cite{MA5}.
Furthermore, the dynamic nature of MA systems enables them to switch seamlessly between communication and sensing modes, making them ideal for ISAC applications. This flexibility is especially crucial in dynamic scenarios, such as vehicle-to-everything (V2X) communication networks, where both high-performance sensing and reliable communication are necessary\cite{MAsurvey}. 
Besides antenna position optimization, antenna rotation adjustment can also be leveraged to improve wireless communication and/or sensing performance, as investigated in recent works on six-dimensional MA (6DMA) systems \cite{6DMA1,6DMA2}.


MA-enabled ISAC systems have gained considerable attention for future 6G networks, as they provide enhanced flexibility and performance. MA-enabled wireless sensing was first studied in \cite{ma2024movableantennaenhancedwireless}, by focusing on movable receive antennas. While this study provided valuable insights into the benefits of receive MAs for sensing performance enhancement, it did not explore the potential advantages of movable transmit antennas. Subsequently, \cite{FASforISAC1} and \cite{FASforISAC2} extended the MA-ISAC framework by incorporating movable transmit antennas and employing alternating optimization based algorithm to optimize beamforming and antenna positions, while \cite{FASforISAC3} leveraged the deep reinforcement learning (DRL) technique.
However, these approaches have their limitations, primarily due to their reliance on local optimization methods and the absence of optimal strategies for the joint optimization of transmit and receive MAs.
%Despite these advancements, both approaches yielded sub-optimal solutions, primarily due to their reliance on local optimization methods and the lack of comprehensive strategies for joint optimization of transmit and receive antennas. 
%Furthermore, these studies did not fully address the challenges associated with global optimization in diverse propagation environments. Addressing these gaps, this paper proposes an enhanced MA-based ISAC system that simultaneously optimizes both transmit and receive antennas using advanced global optimization techniques, thereby offering a more robust and efficient solution for dynamic and complex 6G network scenarios.

Motived by the above discussions, we focus on developing optimal solutions and efficient algorithms for MA-enabled ISAC systems in this work, where the Cram\'{e}r-Rao bound (CRB) is used as the objective function to optimize the antenna position vector (APV) and beamforming vectors, while a pre-defined SNR level is imposed as a constraint to guarantee communication performance.
The main contributions of this work are summarized as follows:
\begin{itemize}
	\item First, for the case with receive MAs only, we derive an optimal closed-form solution for the antenna positions, despite the non-convexity of the objective function and variable-coupling issue. 
	Besides, we show that the sensing performance gain 
	obtained via receive MAs  is upper-bounded by 4.77 dB.
	\item Next, for the case with transmit MAs only, we propose a boundary traversal breadth-first search (BT-BFS) algorithm to obtain the global optimal solution of the considered problem in the line-of-sight (LoS) channel scenario.
	Besides, to reduce the complexity of the BT-BFS algorithm, a boundary traversal depth-first search (BT-DFS) algorithm is further proposed to obtain a local optimal solution with only linear computational complexity.  
	Then, for the non-line-of-sight (NLoS) channel scenario, we propose a majorization-minimization (MM) based Rosen's gradient projection (RGP) algorithm to obtain a stationary solution for the considered problem, together with a meticulously designed method to attain a high-quality initial solution.
	Furthermore, we theoretically show that utilizing movable transmit antenna array is able to enlarge the SNR-CRB region, and the corresponding performance gain is determined by the directional channel response, which is defined as the magnitude of the inner product between the channel vector and the steering vector.
	\item Finally, we show that the general case with MAs for both receiving and transmitting can be simply addressed by combining the above techniques. 
	Numerical results are presented to show the effectiveness of the proposed algorithms and validate the significant ISAC performance gain achieved by using MA array over traditional FPAs. 
	%Moreover, the simulation reveals that the beampattern of MA array exhibits a higher energy main lobe and narrower bandwidth in the sensing direction, which can greatly enhance the reliability of angle estimation.
\end{itemize}

The remainder of this paper is organized as follows. Section \uppercase\expandafter{\romannumeral2} introduces the system model and problem formulation. Sections \uppercase\expandafter{\romannumeral3} and \uppercase\expandafter{\romannumeral4} provide the joint antenna position and beamforming designs for the cases with receive/transmit MAs, respectively. Section \uppercase\expandafter{\romannumeral4}
provides numerical results. Finally, conclusions are drawn in Section \uppercase\expandafter{\romannumeral5}.

\textit{Notations:}
Scalars, vectors, and matrices are denoted by lower/upper case, bold-face lower-case, and bold-face uppercase letters, respectively.
$(\cdot)^T$, $(\cdot)^*$ and $(\cdot)^H$ denote the transpose, conjugate and conjugate transpose operators, respectively. We use $\operatorname{Re}\{x\}$ and $\angle x $ to denote the real part and the phase of a complex number $x$. $\mathbf{I}$, $\mathbf{J}$, $\mathbf{0}$ and $\mathbf{1}$  are used to represent identity matrix, all-one matrix, all-zero vector and all-one vector with proper dimensions, respectively. 
$\begin{Vmatrix}\cdot\end{Vmatrix}$ denotes the Euclidean norm of a complex vector/matrix, and $|\cdot|$ denotes the absolute value of a complex number. 
$\mathbf{y} \backslash y_i$ denotes the set/vector obtained by removing the element $y_i$ from $\mathbf{y}$, where $\mathbf{y}$ is a set or vector and $y_i$ is one of its elements. 
The set of integers is denoted by $\mathbb{Z}$, and the sets of $P \times Q$ dimensional complex, real and positive real matrices are denoted by $\mathbb{C}^{P\times Q}$, $\mathbb{R}^{P\times Q}$ and $\mathbb{R}^{P\times Q}_{++}$, respectively.



\vspace{-0.2cm}
\section{System Model And Problem Formulation}
\subsection{System Setting}
\begin{figure}[t]
	\centering
	\includegraphics[width=3.0in]{model_modify.eps}\vspace{-0.2cm}
	\caption{An MA-enabled ISAC system.}
	\label{model}
	\vspace{-0.1cm}
\end{figure}
In this work, we consider a MIMO ISAC base station (BS) with $N_t$ transmit MAs and $N_r$ receive MAs, which is serving a downlink user with a single antenna while detecting a single point target, as depicted in Fig. \ref{model}. 
In order to avoid information loss of the sensed target, the number of receive antennas is assumed to be greater than that of transmit antennas, i.e., $N_r>N_t$ \cite{9652071}. Additionally, the transmit and receive MAs can be dynamically repositioned in real-time through flexible cables linked to the RF chains \cite{MAsurvey}. Furthermore, we assume narrow-band quasi-static channels, such that the time overhead for adjusting MA positions is tolerable compared to the much longer channel coherence time of both the user and target\cite{MAsurvey}. 
\footnote{We assume that the user/target is static for a long period or moves at a much lower speed as compared to that of the antenna movement.}   
As shown in Fig. \ref{model}, we consider linear MA arrays of sizes $N_t$ and $N_r$ at the transmitter and receiver sides, respectively. Denote $\mathbf{x}=[x_1,x_2,...,x_{N_t}]^T\in\mathbb{R}^{N_t}$ and $\mathbf{y}=[y_1,y_2,...,y_{N_r}]^T\in\mathbb{R}^{N_r}$ as the APVs of the transmit and receive MA arrays, respectively. The steering vectors of the transmit and receive MA arrays can be respectively written as \vspace{-0.2cm}
\begin{equation}
	\label{s1}
	\small
	\mathbf{a}(\mathbf{x},\theta)=\begin{bmatrix}e^{-j\frac{2\pi}{\lambda}x_1\sin\theta},e^{-j\frac{2\pi}{\lambda}x_2\sin\theta},...,e^{-j\frac{2\pi}{\lambda}x_{N_t}\sin\theta}\end{bmatrix}^T,
\end{equation}
 \begin{equation}
 	\label{s2}\small
 	\mathbf{b}(\mathbf{y},\theta)=\begin{bmatrix}e^{-j\frac{2\pi}{\lambda}y_1\sin\theta},e^{-j\frac{2\pi}{\lambda}y_2\sin\theta},...,e^{-j\frac{2\pi}{\lambda}y_{N_r}\sin\theta}\end{bmatrix}^T,
 \end{equation}
where $\lambda$ denotes the carrier wavelength and $\theta$ is the azimuth angle of the point target relative to the BS. Due to the monostatic radar setting, the direction of arrival (DoA) and the direction of departure (DoD) are the same for the same target.

In our considered system, the channel vector is determined by the signal propagation environment and the positions of the transmit MAs. We consider the field-response based channel model \cite{10243545}, where the number of transmit paths is denoted as $L_t$. The azimuth AoDs of the $k$th ($k=1,2,...,L_t$) transmit path is denoted by $\theta_t^k\in[0,\pi]$. Thus, the field response vector of the $i$th  transmit MA can be defined as $\mathbf{g}(x_i)=[e^{-j\frac{2\pi}{\lambda}x_i\sin\theta_t^1},e^{-j\frac{2\pi}{\lambda}x_i\sin\theta_t^2},...,e^{-j\frac{2\pi}{\lambda}x_i\sin\theta_t^{L_t}}]^T$.
%\begin{equation}
%	\mathbf{g}(x_i)=\begin{bmatrix}e^{-j\frac{2\pi}{\lambda}x_i\sin\theta_t^1},e^{-j\frac{2\pi}{\lambda}x_i\sin\theta_t^2},...,e^{-j\frac{2\pi}{\lambda}x_i\sin\theta_t^{L_t}}\end{bmatrix}^T.
%\end{equation}
By stacking $\mathbf{g}(x_i)$ of all $N_t$ transmit MAs, the field response matrix of the transmit MA array is given by $\mathbf{G}(\mathbf{x})=[\mathbf{g}(x_1),\mathbf{g}(x_2),...,\mathbf{g}(x_{N_t})]\in\mathbb{C}^{L_t\times{N_t}}$.
%\begin{equation}
%	\mathbf{G}(\mathbf{x})=\begin{bmatrix}\mathbf{g}(x_1),\mathbf{g}(x_2),...,\mathbf{g}(x_{N_t})\end{bmatrix}\in\mathbb{C}^{L_t\times{N_t}}.
%\end{equation}
Furthermore, we define the path response vector as $\bm{\sigma}\in\mathbb{C}^{L_t\times1}$, where ${\sigma}_k$ is the response between the $k$th transmit path and the user's receive path. As a result, the channel vector from the transmitter to the downlink user is given by\vspace{-0.1cm}
\begin{equation}
	\label{q18}\small
%	\vspace{-0.1cm}
	\mathbf{h}^H(\mathbf{x})=\bm{\sigma}^H\mathbf{G}(\mathbf{x}),
	\vspace{-0.1cm}
\end{equation}
which is assumed to be known to the BS \cite{10243545,9652071}.
Let $\mathbf{X}\in\mathbb{C}^{N_t\times{L}}$ be a narrowband ISAC signal matrix, with $L>N_t$ being the length of the radar pulse/communication frame. 
Furthermore, let $\mathbf{X}=\mathbf{w}\mathbf{s}^H$,
%\begin{equation}
%	\mathbf{X}=\mathbf{w}\mathbf{s}^H,
%\end{equation}
where $\mathbf{w}$ is the dual-functional beamforming vector to be designed, and $\mathbf{s}\in\mathbb{C}^{L\times1}$ contains the unit-power data stream intended for the communication user. The data stream $\mathbf{s}$ is assumed to have independent entries and satisfy $\frac{1}{L}\mathbf{s}^H\mathbf{s}=1$.
%, which
%%\begin{equation}
%%\label{q1}
%%	\frac{1}{L}\mathbf{s}^H\mathbf{s}\approx1.
%%\end{equation}
%holds asymptotically for, e.g., white Gaussian signaling, provided that the block length $L$ is sufficiently large. 
By transmitting $\mathbf{X}$ to the communication user, the received signal vector is \vspace{-0.1cm}
\begin{equation}
	\mathbf{y}_C^H=\mathbf{h}^H\mathbf{X}+\mathbf{z}_C^H,
	\vspace{-0.1cm}
\end{equation}
where $\mathbf{z}_C\in\mathbb{C}^{{L}\times1}$ is an additive white Gaussian noise (AWGN) vector with zero mean and covariance matrix $\sigma_C^2 \mathbf{I}$. 
By transmitting $\mathbf{X}$ to sense the target, the reflected echo signal at the receiver of the ISAC BS is given by \vspace{-0.1cm}
\begin{equation}
	\mathbf{Y}_R=\mathbf{B}\mathbf{X}+\mathbf{Z}_R,
	\vspace{-0.1cm}
\end{equation}
where  $\mathbf{Z}_R\in\mathbb{C}^{N_r\times{L}}$ denotes an AWGN matrix with zero mean and the variance of each its entry is $\sigma_R^2$, $\mathbf{B}\in\mathbb{C}^{N_r\times{N_t}}$ represents the target response matrix. Since the target is modeled as an unstructured point that is far away from the BS, the target response matrix $\mathbf{B}$ can be written as $\mathbf{B}=\alpha\mathbf{b}(\mathbf{y},\theta)\mathbf{a}^H(\mathbf{x},\theta)
\triangleq\alpha\mathbf{A}(\mathbf{x},\mathbf{y},\theta)$,
%\begin{equation}
%	\mathbf{B}=\alpha\mathbf{b}(\mathbf{y},\theta)\mathbf{a}^H(\mathbf{x},\theta)
%	\triangleq\alpha\mathbf{A}(\mathbf{x},\mathbf{y},\theta),
%\end{equation}
where $\alpha\in\mathbb{C}$ represents the reflection coefficient, which contains both the round-trip path-loss and the radar cross-section (RCS) of the target.


\vspace{-0.2cm}
\subsection{Problem Formulation}
In this paper, we aim to optimize the sensing performance under the communication quality-of-service (QoS) constraint by jointly optimizing the transmit and/or receive MA positions ${\mathbf{x}}$, ${\mathbf{y}}$, and the transmit beamforming vector ${\mathbf{w}}$.
In particular, we adopt the CRB for evaluating the target estimation performance, which is a lower bound on the variance of any unbiased estimators, and employ the user SNR to measure the communication performance.

For the considered point target case, the \text{CRB} for $\theta$ was derived in \cite{Kay1993FundamentalsOS}, \cite{1703855}, and is given by (\ref{q2}) at the bottom of the next page, where
\begin{figure*}[hb] % hb底部，ht为头部
	\centering % 公式居中
	\vspace*{-12pt}
	\hrulefill % 添加一条水平线
	\vspace*{-5pt} % 调整线与公式之间的距离
	\begin{equation}
		\label{q2}\small
		\begin{aligned}
			\text{CRB}(\theta)=\frac{\sigma_R^2\text{tr}\Big(\mathbf{A}^H(\theta)\mathbf{A}(\theta)\mathbf{R}_X\Big)}
			{
				2\begin{vmatrix}
					\alpha
				\end{vmatrix}^2L\Big(\text{tr}\big(\dot{\mathbf{A}}^H(\theta)\dot{\mathbf{A}}(\theta)\mathbf{R}_X\big)
				\text{tr}\big(\mathbf{A}^H(\theta)\mathbf{A}(\theta)\mathbf{R}_X\big)
				-\begin{vmatrix}
					\text{tr}\big(\dot{\mathbf{A}}^H(\theta){\mathbf{A}}(\theta)\mathbf{R}_X\big)
				\end{vmatrix}^2\Big)
			}.
		\end{aligned}
	\end{equation}
\end{figure*}

\vspace{-0.3cm}
\begin{equation}
	\label{q3}\small
	\mathbf{R}_X=\frac{1}{L}\mathbf{X}\mathbf{X}^H=
	\frac{1}{L}\mathbf{w}\mathbf{s}^H\mathbf{s}\mathbf{w}^H=
	\mathbf{w}\mathbf{w}^H,
	\vspace{-0.2cm}
\end{equation}
is the sample covariance matrix of $\mathbf{X}$, and $\dot{\mathbf{A}}\triangleq\frac{\partial\mathbf{A}(\theta)}{\partial\theta}$.
Furthermore, the receive SNR at the user is given as
$	\gamma=\frac{|\mathbf{h}^H\mathbf{w}|^2}{\sigma_C^2}$.
%\begin{equation}
%	\gamma=\frac{\begin{vmatrix}
%			\mathbf{h}^H\mathbf{w}
%		\end{vmatrix}^2}{\sigma_C^2}.
%\end{equation}
%Specifically, we aim to minimize the \text{CRB} of radar sensing while guaranteeing a pre-defined level of SNR for the communication user by jointly optimizing the MA positions $\mathbf{x},\mathbf{y}$ and the beamforming vector $\mathbf{w}$. 
Thus, the corresponding joint optimization problem 
%of beamforming and antenna distribution with fixed $\theta$ under communication user's SNR and power budget constraints 
can be formulated as \vspace{-0.1cm}
\begin{subequations}
	\label{p1}\small
	\begin{align}
		\min\limits_{\mathbf{x},\mathbf{y},\mathbf{w}}&\;\;\text{CRB}(\theta)\\
		\text{s.t.}&\;\;\gamma\ge\Gamma,
		\begin{vmatrix}
			\mathbf{w}
		\end{vmatrix}^2\le{P_T},\\
		&\;\;D_x\ge\begin{vmatrix}
			x_m-x_n
		\end{vmatrix}\ge{d},1\le{m},{n}\le{N_t},m\neq{n}, \label{q4}\\
		&\;\;D_y\ge\begin{vmatrix}
			y_m-y_n
		\end{vmatrix}\ge{d},1\le{m},{n}\le{N_r},m\neq{n}, \label{q5}
%		\min\limits_{\mathbf{x},\mathbf{y},\mathbf{w}}&\;\;\text{CRB}(\theta)\\
%		\text{s.t.}&\;\;\gamma\ge\Gamma,
%		\begin{vmatrix}
%			\mathbf{w}
%		\end{vmatrix}^2\le{P_T},\\
%		&\;\;D_x\ge\begin{vmatrix}
%			x_m-x_n
%		\end{vmatrix}\ge{d}, \label{q4}\\
%		&\;\;D_y\ge\begin{vmatrix}
%			y_m-y_n
%		\end{vmatrix}\ge{d},\forall m,n,\;m\neq{n}, \label{q5}
	\end{align}
\end{subequations}
where $\Gamma$ is the required SNR level for the user, $P_T$ is the transmit power budget, $d$ is the minimum distance (usually we set $d=\frac{\lambda}{2}$) between any two MAs to avoid the coupling effect, and $D_x$ ($D_y$) is the aperture of the overall transmit (receive) antenna array. Due to the equivalence between the antennas, we can assume $x_1<x_2<...<x_{N_t}$ and $y_1<y_2<...<y_{N_r}$ without loss of optimality. Thus, constraints (\ref{q4}) and (\ref{q5}) can be equivalently transformed into linear inequality constraints $\mathbf{U}\mathbf{x}\preceq\mathbf{l}_u$ and $\mathbf{V}\mathbf{y}\preceq\mathbf{l}_v$, respectively,
%\begin{equation}
%	\mathbf{U}\mathbf{x}\preceq\mathbf{l}_u,\mathbf{V}\mathbf{y}\preceq\mathbf{l}_v,
%\end{equation}
where \vspace{-0.1cm}
\begin{equation}
	\label{q16}\small
	\begin{aligned}
	\mathbf{U}&=\left[\begin{array} {ccccccc}
		1 & -1 & 0 & 0 & \cdots & 0 & 0\\
		0 & 1 & -1 & 0 & \cdots & 0 & 0\\
		\vdots & \vdots & \vdots & \vdots & \ddots & \vdots & \vdots\\
		0 & 0 & 0 & 0 & \cdots & 1 & -1\\
		-1 & 0 & 0 & 0 & \cdots & 0 &1
	\end{array}\right]_{N_t\times{N_t}},\\
			\mathbf{l}_u&=\left[
	-d,  -d ,\cdots , -d , D_x
	\right]^T_{N_t\times1},
\end{aligned}
\end{equation}
%\vspace{-0.8em}
%\begin{equation}
%	\begin{aligned}\small
%		\mathbf{l}_u=\left[
%			-d,  -d ,\cdots , -d , D_x
%	\right]^T_{N_t\times1},
%	\end{aligned}\vspace{-0.1cm}
%\end{equation}
and $\{\mathbf{V},\mathbf{l}_v\}$ are similarly defined.
 
Based on the properties of the steering vectors in (\ref{s1}), (\ref{s2}) and their derivatives, it can be easily verified that \vspace{-0.1cm}
\begin{equation}
	\label{q6}\small
	\dot{\mathbf{a}}^H(\mathbf{x},\theta)\mathbf{a}(\mathbf{x},\theta)=j\frac{2\pi}{\lambda}\cos\theta
	\sum_{i=1}^{N_t}x_i,\forall\theta,
\end{equation}
\vspace{-0.6em}
\begin{equation}
	\label{q7}\small
	\dot{\mathbf{b}}^H(\mathbf{y},\theta)\mathbf{b}(\mathbf{y},\theta)=
	j\frac{2\pi}{\lambda}\cos\theta
	\sum_{i=1}^{N_r}y_i,\forall\theta.
	\vspace{-0.1cm}
\end{equation}
Leveraging (\ref{q3}), (\ref{q6}) and (\ref{q7}) yields (\ref{q8})-(\ref{q9}), i.e.,\vspace{-0.1cm}
\begin{equation}
	\label{q8}\small
	\text{tr}\big({{\mathbf{A}^H}\mathbf{A}{\mathbf{R}_X}}\big) =
	 {N_r}{\begin{vmatrix}{{\mathbf{a}^H}{\mathbf{w}}}\end{vmatrix}^2},
\end{equation}
\vspace{-0.5cm}
\begin{equation}\small
	\text{tr}\big({{\dot{\mathbf{A}}^H}\mathbf{A}{\mathbf{R}_X}}\big) =
	j\frac{2\pi}{\lambda}\cos\theta
	{\begin{vmatrix}{{\mathbf{a}^H}{\mathbf{w}}}\end{vmatrix}^2}
	\sum_{i=1}^{N_r}y_i
	+N_r\mathbf{a}^H\mathbf{w}\mathbf{w}^H\dot{\mathbf{a}},
	\vspace{-0.1cm}
\end{equation}
\begin{figure*}[hb] % hb底部，ht为头部
	\centering % 公式居中
	\vspace*{-28pt}
	\begin{equation}\small
		\label{q9}
		\text{tr}\big({{\dot{\mathbf{A}}^H}\dot{\mathbf{A}}{\mathbf{R}_X}}\big) =
		(\frac{2\pi}{\lambda}\cos\theta)^2
		{\begin{vmatrix}{{\mathbf{a}^H}{\mathbf{w}}}\end{vmatrix}^2}
		\sum_{i=1}^{N_r}y_i^2
		+j\frac{2\pi}{\lambda}\cos\theta
		\sum_{i=1}^{N_r}y_i
		(\dot{\mathbf{a}}^H\mathbf{w}\mathbf{w}^H{\mathbf{a}}-\mathbf{a}^H\mathbf{w}\mathbf{w}^H\dot{\mathbf{a}})
		+{N_r}{\begin{vmatrix}{{\dot{\mathbf{a}}^H}{\mathbf{w}}}\end{vmatrix}^2}.
	\end{equation}
%	\hrulefill % 添加一条水平线
	\vspace*{-16pt} % 调整线与公式之间的距离
\end{figure*}where $\mathbf{A}\triangleq\mathbf{A}(\mathbf{x},\mathbf{y},\theta)$ and $\dot{\mathbf{A}}\triangleq\dot{\mathbf{A}}(\mathbf{x},\mathbf{y},\theta)$, and (\ref{q9}) is shown at the bottom of the next page. Substituting (\ref{q8})-(\ref{q9}) into (\ref{q2}), the objective function of problem (\ref{p1}), i.e., $\text{CRB}(\theta)$, can be simplified to\vspace{-0.2cm}
\begin{equation}
	\label{CRB_expression}\small
	\begin{aligned}
		\text{CRB}(\theta)=
		\frac{\sigma_R^2/
			(2\begin{vmatrix}
				\alpha
			\end{vmatrix}^2L)}
		{
			(\frac{2\pi}{\lambda}\cos\theta)^2
			{\begin{vmatrix}{{\mathbf{a}^H}{\mathbf{w}}}\end{vmatrix}^2}
			\big(\sum\limits_{i=1}^{N_r}y_i^2
			-\frac{1}{N_r}(\sum\limits_{i=1}^{N_r}y_i)^2\big)
		}.
	\end{aligned}\vspace{-0.1cm}
\end{equation}
Thus, problem (\ref{p1}) can be equivalently recast as\vspace{-0.2cm}
\begin{subequations}
	\label{p2}\small
\begin{align}
(\text{P})	\quad \quad	\max\limits_{\mathbf{x},\mathbf{y},\mathbf{w}}\;\;
&{\begin{vmatrix}{{\mathbf{a}^H}{\mathbf{w}}}\end{vmatrix}^2}
\left(\sum\limits_{i=1}^{N_r}y_i^2
-\frac{1}{N_r}\left(\sum\limits_{i=1}^{N_r}y_i\right)^2\right)\label{p2a}\\
\text{s.t.}\;\;&\begin{vmatrix}{{\mathbf{h}^H}{\mathbf{w}}}\end{vmatrix}^2
\ge\Gamma\sigma_C^2,
\|
\mathbf{w}
\|^2\le{P_T},\\
&\mathbf{U}\mathbf{x}\preceq\mathbf{l}_u,\mathbf{V}\mathbf{y}\preceq\mathbf{l}_v.
	\end{align}
\end{subequations}
In this work, we aim to obtain the optimal solution of problem (P), i.e., derive the optimal beamforming vector and antenna positions for the considered MA-assisted ISAC system. However, problem (P) is a highly non-convex optimization problem and very difficult to solve due to the coupling between the beamforming and antenna
position variables, as well as the fact that the position variables appear in the exponential terms of each channel coefficient. 
%Generally, there is no efficient method for solving the non-convex problem (\ref{p2}) optimally. In the next two sections, we propose an efficient boundary traversal algorithm to solve problem (\ref{p2}) optimally in the LoS channel case, and then MM based algorithm and RGPM based technique are proposed for the more general NLoS case.
Generally, there is no efficient method for solving the non-convex problem (P) optimally.
To address the abovementioned difficulties, we first examine two special cases of problem (P) in the next two sections respectively, i.e., 1) only the receive antennas are movable, and 2) only the transmit antennas are movable. 
%For the first case, we manage to provide the optimal closed-form solution of problem (\ref{p2}); for the second, we propose two efficient boundary traversal based algorithms to solve problem (\ref{p2}) in the LoS channel scenario, and then MM based algorithm and RGPM technique are proposed for the NLoS scenario.
Then, for the general case where both receive and transmit antennas are movable, we show that the corresponding optimization problem can be efficiently solved by combining the techniques proposed in the above two special cases. 

 \vspace{-0.2cm}
\section{Receive MA Case}
%To address the abovementioned difficulties, we first examine two special cases of problem (\ref{p2}), i.e., 1) only the receive antennas are movable, and 2) only the transmit antennas are movable. 
%For the first case, we discover that variable decoupling can be achieved by substituting the closed-form solution of the optimal beamforming vector (in terms of the APVs) into the objective function of problem (\ref{p2}), i.e., (\ref{p2a}). Then, we exploit the translational invariance and symmetry properties of (\ref{p2a}) over the receive antenna distribution vector $\mathbf{y}$ and provide the optimal closed-form solution of problem (\ref{p2}) in this case. 
%For the second case, we show that the coupling between the steering vector $\mathbf{a}(\mathbf{x})$ and the channel vector $\mathbf{h}(\mathbf{x})$ results in a ``quasi-harmonic" behavior of the objective function (\ref{p2a}), which in turn has many local optimal solutions as well as saddle points. Thus it is almost impossible to find the global optimal solution using existing algorithms. To address this difficulty, we first analyze the LoS channel scenario and propose a boundary traversal breadth-first search (BT-BFS) algorithm, which is proved to obtain the global optimal solution of problem (\ref{p2}). Additionally, to reduce the computational complexity of the BT-BFS algorithm, we further introduce a boundary traversal depth-first search (BT-DFS) algorithm to obtain a local optimal solution with quadratic polynomial complexity. For the general NLoS channel scenario, we propose a majorization-minimization (MM) based optimization algorithm with the help of the gradient projection technique, where a novel meticulously designed approach is presented to determine a high-performance initial point which can effectively prevent the algorithm from converging to a poorer stationary point.
%Finally, for the general case where both the receive and transmit antennas are movable, we show that the corresponding optimization problem can be efficiently solved by combining the techniques proposed in the above two special cases. 
%
%Moreover, we characterize the asymptotic CRB performance gain provided by movable receive antennas as the antenna aperture goes to infinity, which is shown to be upper bounded by 4.77dB.
%Besides, we discover that as the SNR threshold required for communication exceeds a certain value, the sensing CRB will inevitably increase, which cannot be avoided even when the receive antenna aperture is infinitely large. 
%However, for the case where the transmit antennas are movable, we can significantly raise this threshold with the help of our proposed algorithm, allowing the CRB to remain at the lowest level even at higher required communication SNR threshold.




In this section, we investigate the case with receive MAs only, and show that variable decoupling can be achieved by substituting the closed-form solution of the optimal beamforming vector (as a function of the APVs) into the objective function of problem (P), i.e., (\ref{p2a}). Then, we exploit the translational invariance and symmetry properties of (\ref{p2a}) over the receive MAs' APV $\mathbf{y}$ and provide the optimal closed-form solution to problem (P).
Moreover, we characterize the sensing performance gain provided by receive MAs, which is shown to be capped at 4.77 dB.
\vspace{-0.3cm}
\subsection{Optimal Solution}
In this subsection, a closed-form optimal solution to problem (P) is derived, where we assume that the transmit antennas are in the form of a uniform linear array (ULA) with half wavelength spacing. Under this assumption, problem (P) can be reduced to\vspace{-0.2cm} 
\begin{equation}
	\label{p3}\small
	\begin{aligned}
	(\text{AP})	\quad \quad	\max\limits_{\mathbf{y},\mathbf{w}}\;\;
		&{\begin{vmatrix}{{\mathbf{a}^H}{\mathbf{w}}}\end{vmatrix}^2}
		\underbrace{\left(\sum\limits_{i=1}^{N_r}y_i^2
		-\frac{1}{N_r}\left(\sum\limits_{i=1}^{N_r}y_i\right)^2\right)}_{\triangleq{f(\mathbf{y})}}\\
		\text{s.t.}\;\;&\begin{vmatrix}{{\mathbf{h}^H}{\mathbf{w}}}\end{vmatrix}^2\ge\Gamma\sigma_C^2,\\
		&\|
			\mathbf{w}
		\|^2\le{P_T},
		\mathbf{V}\mathbf{y}\preceq\mathbf{l}_v.
	\end{aligned} \vspace{-0.1cm}
\end{equation}
As can be seen, addressing problem (AP) is challenging even in this simplified scenario due to its highly non-convexity and the coupling between the variables $\mathbf{y}$ and $\mathbf{w}$. However, we also observe that $\mathbf{y}$ and $\mathbf{w}$ are decoupled in the constraints of problem (AP), and the objective function can be separated into two terms, i.e., ${|{{\mathbf{a}^H}{\mathbf{w}}}|}$ and $f(\mathbf{y})$. 
%Besides, we can infer that the gains provided by adjusting the receive antennas are relatively limited as compared to the case with movable transmit antennas.
This is intuitive, as the sensing antennas (i.e., the receive MAs) do not affect the information transmission and thus do not relate to the transmit beamforming. %The detailed analysis will be provided in the following. 

%To proceed, we first obtain the following optimal solution of $\mathbf{w}$ \cite{9652071}:
To proceed, we obtain the optimal solution of $\mathbf{w}$ as \cite{9652071}\vspace{-0.1cm}
\begin{subequations}
	\label{q11}\small
	\begin{numcases}{\mathbf{w}=}
%		\sqrt{P_T}\dfrac{\mathbf{a}}{\|\mathbf{a}\|}, 
		\sqrt{P_T} {\mathbf{a}}/{\|\mathbf{a}\|}, 
		& \text{if $P_T\begin{vmatrix}{{\mathbf{h}^H}{\mathbf{a}}}\end{vmatrix}^2>N_t\Gamma\sigma_C^2$,}
		\label{q11a} \\
		c_1\mathbf{u}_1+c_2\mathbf{a}_u,
		& \text{otherwise,} \label{q11b}
\end{numcases}
\end{subequations}
where
$		\mathbf{u}_1=\frac{\mathbf{h}}{\|\mathbf{h}\|} $,
		$\mathbf{a}_u=\frac{\mathbf{a}-(\mathbf{u}_1^H\mathbf{a})\mathbf{u}_1}
		{\|\mathbf{a}-(\mathbf{u}_1^H\mathbf{a})\mathbf{u}_1\|}$,
	$	c_1=\sqrt{\frac{\Gamma\sigma_C^2}{\|\mathbf{h}\|^2}}
		\frac{\mathbf{u}_1^H\mathbf{a}}{\|\mathbf{u}_1^H\mathbf{a}\|}$ and 
		$c_2=\sqrt{P_T-\frac{\Gamma\sigma_C^2}{\|\mathbf{h}\|^2}}
		\frac{\mathbf{a}_u^H\mathbf{a}}{\|\mathbf{a}_u^H\mathbf{a}\|}.$
%\begin{equation}\small
%	\begin{aligned}
%		&\mathbf{u}_1={\mathbf{h}}/{\|\mathbf{h}\|}, 
%		\mathbf{a}_u={(\mathbf{a}-(\mathbf{u}_1^H\mathbf{a})\mathbf{u}_1)}/
%		{\begin{Vmatrix}\mathbf{a}-(\mathbf{u}_1^H\mathbf{a})\mathbf{u}_1\end{Vmatrix}},\\
%		&c_1=\sqrt{\frac{\Gamma\sigma_C^2}{\|\mathbf{h}\|^2}}
%		\dfrac{\mathbf{u}_1^H\mathbf{a}}{\begin{vmatrix}\mathbf{u}_1^H\mathbf{a}\end{vmatrix}}, 
%		c_2=\sqrt{P_T-\frac{\Gamma\sigma_C^2}{\|\mathbf{h}\|^2}}
%		\dfrac{\mathbf{a}_u^H\mathbf{a}}{\begin{vmatrix}\mathbf{a}_u^H\mathbf{a}\end{vmatrix}}.
%	\end{aligned}
%\end{equation}
Consequently, problem (AP) can be equivalently transformed into the following problem without loss of optimality:
	\begin{flalign}
		\label{p4}\small
	\quad\quad\quad\quad\quad\;\; (\text{AP-m})	\quad \quad  &\max\limits_{\mathbf{y}}\;\;
		f(\mathbf{y}) \notag &&
		%=\sum\limits_{i=1}^{N_r}y_i^2
		%-\frac{1}{N_r}\left(\sum\limits_{i=1}^{N_r}y_i\right)^2
		\\
		&\;\;\;\text{s.t.}\;\;\mathbf{V}\mathbf{y}\preceq\mathbf{l}_v. &&
	\end{flalign}
Although problem (AP-m) is still non-convex due to the non-convex $f(\mathbf{y})$, we will prove that it admits a closed-form optimal solution.\footnote{Problem (AP-m) is similar to the one considered in \cite{ma2024movableantennaenhancedwireless}, where mathematical induction is used to derive the corresponding optimal solution. However, different from  \cite{ma2024movableantennaenhancedwireless}, this paper presents a completely different proof based on the translational invariance and symmetry properties of $f(\mathbf{y})$.} 
Before providing the formal proof, we first present the following lemmas, which state the properties of \( f(\mathbf{y}) \) and the conditions that the optimal solution must satisfy.
\begin{Lemma}
	For any $a\in\mathbb{R}$, $f(\mathbf{y})$ must satisfy the following translational invariance property:
	$f(\mathbf{y})=f(\mathbf{y}+a)$.
%	\begin{equation}
%		\begin{aligned}
%			f(\mathbf{y})=f(\mathbf{y}+a).
%		\end{aligned}
%	\end{equation}
\end{Lemma}

\begin{proof}
Please refer to Appendix A. 
\end{proof}

\begin{Lemma}
	For any $D_y\in\mathbb{R}$, $f(\mathbf{y})$ must satisfy the following symmetry property:
	$f(\mathbf{y})=f(D_y-\mathbf{y})$. 
%\begin{equation}
%	\begin{aligned}
%		f(\mathbf{y})=f(D_y-\mathbf{y}).
%	\end{aligned}
%\end{equation}
\end{Lemma}

\begin{proof}
	This lemma can be similarly proved as Lemma 1, and the detailed proof is omitted here due to space limitation.
\end{proof}

\begin{Lemma}
The optimal solution of problem (AP-m) satisfies $y_i=y_{i-1}+d,\;2\le{i}\le\left\lfloor{\frac{N_r}{2}}\right\rfloor$.
%\begin{equation}
%	\begin{aligned}
%		y_i=y_{i-1}+d,\;2\le{i}\le\left\lfloor{\frac{N_r}{2}}\right\rfloor.
%	\end{aligned}
%\end{equation}
\end{Lemma}

\begin{proof}
	Please see Appendix B. 
\end{proof}


%Using Lemmas 1 and 2, we can derive two useful properties of the objective function. Combining these with Lemma 3, we conclude that the optimal solution to problem (AP-m) under the given constraints must satisfy specific conditions.
Based on the above lemmas, we have the following theorem that provides the optimal antenna positions in the receive-MA-only case.

\begin{Theorem}
The optimal solution of problem (AP-m) is given by \vspace{-0.2cm}
\begin{equation}
	\label{q10}\small
	\mathbf{y}_\text{opt}=
	\left\{
	\begin{aligned}
		[
		&0,d,\cdots,(\frac{N_r}{2}-1)d,D_y-(\frac{N_r}{2}-1)d,\\
		&D_y-(\frac{N_r}{2}-2)d,\cdots,D_y-d,D_y
		]^T,N_r\;\text{is even};\\
		[&0,\cdots,(\frac{N_r-3}{2})d
		,(\frac{N_r-1}{2})d\;\text{or}\;D_y-(\frac{N_r-1}{2})d,\\
		&D_y-(\frac{N_r-3}{2})d
		,\cdots,D_y-d,D_y
		]^T,N_r \;\text{is odd}.
	\end{aligned}
	\right.\vspace{-0.2cm}
\end{equation}
\end{Theorem}

%\begin{figure*}[hb] % hb底部，ht为头部
%	\centering % 公式居中
%	\hrulefill % 添加一条水平线
%	\vspace*{8pt} % 调整线与公式之间的距离
%	\begin{equation}
%		\label{q10}
%		\mathbf{y}_\text{opt}=
%		\left\{
%		\begin{aligned}
%			&\left[
%			\begin{array}{ccccccccc}0,d,\cdots,(\frac{N_r}{2}-1)d,D_y-(\frac{N_r}{2}-1)d
%				,D_y-(\frac{N_r}{2}-2)d,\cdots,D_y-d,D_y
%			\end{array}
%			\right]^T,N_r\;\text{is even},\\
%			&\left[\begin{array}{ccccccccc}0,d,\cdots,(\frac{N_r-3}{2})d
%				,(\frac{N_r-1}{2})d\;\text{or}\;D_y-(\frac{N_r-1}{2})d,D_y-(\frac{N_r-3}{2})d
%				,\cdots,D_y-d,D_y
%			\end{array}\right]^T,N_r \;\text{is odd}.
%		\end{aligned}
%		\right.
%	\end{equation}
%\end{figure*}

\begin{proof}
From Lemma 3, we can assert that the first $\lfloor\frac{N_r}{2}\rfloor$ antennas must form a ULA with spacing \( d \) starting from zero to $\left(\lfloor\frac{N_r}{2}\rfloor-1\right)d$. Similarly, based on the symmetry property of $f(\mathbf{y})$ proved in Lemma 2, the last $\lfloor\frac{N_r}{2}\rfloor$ antennas must also form a ULA starting from $D_y-\left(\lfloor\frac{N_r}{2}\rfloor-1\right)d$ to \( D_y \).
Therefore, (\ref{q10})
%when \( N_r \) is even, i.e., $\lfloor\frac{N_r}{2}\rfloor=\frac{N_r}{2}$, $\mathbf{y}_\text{opt}$ must satisfy $\mathbf{y}_\text{opt}=[0,d,\cdots,(\frac{N_r-2}{2})d,D_y-(\frac{N_r-2}{2})d,D_y-(\frac{N_r-4}{2})d,\cdots,D_y]^T$, while when \( N_r \) is odd, $\mathbf{y}_\text{opt}=[0,\cdots,(\frac{N_r-3}{2})d,(\frac{N_r-1}{2})d\;\text{or}\;D_y-(\frac{N_r-1}{2})d,D_y-(\frac{N_r-3}{2})d
%,\cdots,D_y
%]^T$ 
must hold, which completes the proof.
\end{proof}
 As can be seen from (\ref{q10}), in order to maximize the sensing performance, the MAs should be divided into two groups with equal size, each forming a ULA with antenna spacing \( d \). With given antenna aperture $D_y$, these two groups of MAs should be positioned as far apart from each other as possible, thus maximizing the antenna aperture utilization. It is important to mention that this result is quite intuitive, which resembles how our eyes function, i.e., wider spacing between our eyes enables us to better perceive the object positions in space and also enhances our depth perception and spatial awareness. 
 %For ease of illustration, we plot in Fig. 2 the optimal antenna distribution provided in (\ref{q10}). 
 \vspace{-0.3cm}
 \subsection{CRB Performance Gain Analysis}
 To explore the sensing performance limit brought by the movable receive antennas, we further analyze the ratio between the CRB with receive MAs and the CRB with conventional receive ULA.
 For ease of analysis and without loss of generality, we assume that the number of receive antennas, i.e., \(N_r\), is even. Then, by substituting (\ref{q10}) and  $\mathbf{y}_\text{ULA}=[0,\frac{D_y}{N_r-1},\frac{2D_y}{N_r-1},...,D_y]^T$ into \(f(\mathbf{y})\), we obtain\vspace{-0.1cm}
\begin{equation}
	\label{approx1}\small
	\begin{aligned}
	&\frac{\text{CRB}_\text{ULA}}{\text{CRB}_\text{MA}}=\frac{f(\mathbf{y}_\text{opt})}{f(\mathbf{y}_\text{ULA})}\\
	&=\frac{N_r-2}{N_r+1}\frac{(N_r-1)d}{D_y}\left(\frac{(N_r-1)d}{D_y}-3\right)
		+3\frac{N_r-1}{N_r+1}
		\\&<3\frac{N_r-1}{N_r+1},
%	&\;{\approx}\left(\frac{(N_r-1)d}{D_y}\right)^2-3\left(\frac{(N_r-1)d}{D_y}\right)+3,
	\end{aligned}\vspace{-0.1cm}
\end{equation}
%where 
%%the subscript ``ULA" indicates that the receive antennas are arranged in ULA with a total span of \(D\), the subscript ``opt" denotes that the receive antennas optimally deployed as in (\ref{q10}) and 
%the approximation holds under the condition that \(N_r\gg1\).
where the inequality holds due to the fact that the antenna aperture $D_y$ satisfies $D_y \ge (N_r - 1)d$ and ${\text{CRB}_\text{ULA}}/{\text{CRB}_\text{MA}}$ is a monotonically decreasing function of ${(N_r-1)d}/{D_y}$.
%Since the antenna aperture $D_y$ satisfies $D_y \ge (N_r - 1)d$, we can see that ${\text{CRB}_\text{ULA}}/{\text{CRB}_\text{MA}}$ is a monotonically decreasing function of ${(N_r-1)d}/{D_y}$, and thus $ {{\text{CRB}_\text{ULA}}/{\text{CRB}_\text{MA}}}<3\frac{N_r-1}{N_r+1}<3$. 
%Therefore, the sensing performance gain brought by receive MAs is upper-bounded by 4.77 dB.\footnote{\hl{The CRB gain is given by  
%$
%10 \lg\left({\text{CRB}_{\text{MA}}}/{\text{CRB}_{\text{ULA}}}\right) < 10 \lg 3 = 4.77\,\text{dB},
%$
%which can only be achieved when both $D_y$ and $N_r$ approach infinity. Since we are considering a far-field channel model, under this condition, the CRB gain at the receiver is guaranteed to be less than 4.77 dB.}} 
Therefore, the sensing performance gain brought by receive MAs is upper-bounded by \footnote{This upper bound is only achieved when both \( D_y \) and \( N_r \) approach infinity. Since we are considering a far-field channel model, the CRB gain at the receiver is restricted to less than 4.77 dB.}\vspace{-0.2cm}
\begin{equation}\small
	10 \lg\left(\frac{\text{CRB}_{\text{ULA}}}{\text{CRB}_{\text{MA}}}\right) < 10 \lg 3 = 4.77\,\text{dB}.
\end{equation}

 \vspace{-0.4cm}
\section{Transmit MA Case}
In this section, we focus on the case with transmit MAs only, while the receive antennas are assumed to be a ULA with half wavelength spacing. 
First, we show that the coupling between the steering vector $\mathbf{a}(\mathbf{x})$ and the channel vector $\mathbf{h}(\mathbf{x})$ results in a ``quasi-harmonic" behavior of the objective function (\ref{p2a}). Thus, problem (P) has many local optimal solutions as well as saddle points, thus it is almost impossible to find its global optimal solution using existing algorithms. To address this difficulty, we analyze the LoS channel scenario first and propose a BT-BFS algorithm, which is proved to obtain the global optimal solution of problem (P) in the case with transmit MAs only. Additionally, to reduce the computational complexity of the BT-BFS algorithm, we further introduce a BT-DFS algorithm to obtain a local optimal solution with only linear complexity. Then, for the general NLoS channel scenario, we propose an MM-based RGP algorithm, where a meticulously designed method is presented to determine a high-performance initial point which can effectively prevent the algorithm from converging to a bad stationary point.
Besides, we discover that as the SNR threshold required for communication exceeds a certain value, the sensing CRB will inevitably increase, which cannot be avoided even when the receive antenna aperture is infinitely large. 
However, with movable transmit antennas, we can significantly raise this threshold with the help of our proposed algorithm, allowing the CRB to remain at the lowest level even at higher required communication SNR threshold.
\vspace{-0.1cm}
\subsection{Problem Transformation}
In the case with transmit MAs only, problem (P) can be rewritten as \vspace{-0.2cm}
\begin{subequations}
	\label{p5}\small
	\begin{align}
		  (\text{BP})	\quad \quad\max\limits_{\mathbf{x},\mathbf{w}}\;\;
		&{\begin{vmatrix}{{\mathbf{a}^H}{\mathbf{w}}}\end{vmatrix}^2} &&
		\label{p5a}\\
		\text{s.t.}\;\;&\begin{vmatrix}{{\mathbf{h}^H}{\mathbf{w}}}\end{vmatrix}^2\ge\Gamma\sigma_C^2,&&
		\label{p5b}\\
		&\|
			\mathbf{w}
		\|^2\le{P_T},
		\mathbf{U}\mathbf{x}\preceq\mathbf{l}_u.&&\label{p5c}
	\end{align}
\end{subequations}
Although problem (BP) looks very similar to problem (AP), they are fundamentally different because the receive antennas in (AP) do not participate in the information transmission process, whereas the transmit antenna positions in (BP) will affect the communication channel significantly, which further impacts the transmit beamforming design as well as both communication and sensing performance. Generally, problem (BP) is more challenging to solve than problem (AP) since the transmit APV \(\mathbf{x}\) appears in the exponential parts of the steering vector \(\mathbf{a}\) and the channel vector \(\mathbf{h}\) (see (\ref{s1}) and (\ref{q18})), and \(\mathbf{w}\) and \(\mathbf{x}\) are tightly coupled in both the constraints and objective function. 

To address problem (BP), we first propose to adopt the optimal closed-form solution for \(\mathbf{w}\) in (\ref{q11}), which is able to reduce the number of optimization variables and decouple the variables. Then, through some mathematical manipulations,
we can show that problem (BP) can be equivalently decomposed into the following two subproblems:\vspace{-0.5cm}

\begin{subequations}
	\label{p6}\small
	\begin{align}
	(\text{SP1})	\quad \quad 	\text{Find}&\;\;\mathbf{x}\label{p6a}&&
		\\
		\text{s.t.}&\;\;\begin{vmatrix}{{\mathbf{h}^H}{\mathbf{a}}}\end{vmatrix}^2>\frac{N_t}{P_T}\Gamma\sigma_C^2,\label{p6b}&&\\
		&\;\;\mathbf{U}\mathbf{x}\preceq\mathbf{l}_u,\label{p6c}&&
	\end{align}
\end{subequations}
\vspace{-0.7cm}
\begin{subequations}
	\label{p7}\small
	\begin{align}
\;	(\text{SP2})	\quad \quad\; \max\limits_{\mathbf{x}}&\;\;
		{f_t}{(\mathbf{x})}\label{p7a}&&
		\\
		\text{s.t.}&\;\;\begin{vmatrix}{{\mathbf{h}^H}{\mathbf{a}}}\end{vmatrix}^2\le
		\frac{N_t}{P_T}\Gamma\sigma_C^2,\label{p7b}&&\\ 
		&\quad \text{(\ref{p6c})},&&\nonumber 
	\end{align}
	\vspace{-0.2cm}
\end{subequations}
where \vspace{-0cm}
\begin{equation}
	\label{ft}\small
	\begin{aligned}
{f_t}{(\mathbf{x})}
\triangleq{{\frac{\sqrt{\Gamma\sigma_C^2}}{\|\mathbf{h}\|^2}
		{\begin{vmatrix}{{\mathbf{h}^H}{\mathbf{a}}}\end{vmatrix}}
		+\sqrt{P_T-\frac{\Gamma\sigma_C^2}{\|\mathbf{h}\|^2}}
		\sqrt{\frac{\|\mathbf{h}\|^2\|\mathbf{a}\|^2
				-|{{\mathbf{h}^H}{\mathbf{a}}}|^2}
			{\|\mathbf{h}\|^2}}}}.
	\end{aligned}\vspace{-0.1cm}
\end{equation}
Thus, if subproblem (SP1) has a feasible solution,
it is also the optimal solution of problem (BP); otherwise, the solution of subproblem (SP2) would be the optimal solution.
 
Then, without loss of optimality, subproblem (SP1) can be further transformed into \vspace{-0.1cm}
\begin{equation}
	\label{p8}\small
	\begin{aligned}
		(\text{BP1})	\quad \quad  \max\limits_{\mathbf{x}}\;\;&p_1(\mathbf{x})\triangleq\begin{vmatrix}{{\mathbf{h}^H}{\mathbf{a}}}\end{vmatrix}^2
		&&\\
		\text{s.t.}\;\;&\text{(\ref{p6b})},\text{(\ref{p6c})}.&&
	\end{aligned}\vspace{-0.1cm}
\end{equation}
Next, we resort to the following trigonometric transformations to simplify subproblem (SP2):\vspace{-0.2cm}
\begin{equation}
	\label{q12}\small
	\begin{aligned}
		\cos\upsilon(\mathbf{x})={{\begin{vmatrix}{{\mathbf{h}^H}{\mathbf{a}}}\end{vmatrix}}}/
		{({\|{\mathbf{h}}\|}\|\mathbf{a}\|)},\upsilon(\mathbf{x})\in[0,\frac{\pi}{2}],
	\end{aligned}
\end{equation}
\vspace{-0.4cm}
\begin{equation}
	\label{q13}\small
	\begin{aligned}
		\sin\phi(\mathbf{x})=
		\sqrt{{\Gamma\sigma_C^2}/{(P_T\|\mathbf{h}\|^2})}
		,\phi(\mathbf{x})\in[0,\frac{\pi}{2}],
	\end{aligned}\vspace{-0.2cm}
\end{equation}
based on which, $f_t(\mathbf{x})$ can be equivalently rewritten as \vspace{-0.1cm}
\begin{equation}
	\label{q20}\small
	\begin{aligned}
		f_t(\mathbf{x})&\overset{(a)}{=}\sqrt{N_t}\bigg(\frac{\sqrt{\Gamma\sigma_C^2}}{\|\mathbf{h}\|}
		\cos\upsilon
		+\sqrt{P_T-\frac{\Gamma\sigma_C^2}{\|\mathbf{h}\|^2}}\sin\upsilon\bigg)
		\\&=\sqrt{N_tP_T}\sin\left(\upsilon(\mathbf{x})+\phi(\mathbf{x})\right),
	\end{aligned}\vspace{-0.1cm}
\end{equation}
where $(a)$ holds due to the fact that $\|\mathbf{a}\|=\sqrt{N_t}$. Besides, by substituting (\ref{q12}) and (\ref{q13}) into $|{{\mathbf{h}^H}{\mathbf{a}}}|^2\le
\frac{N_t}{P_T}\Gamma\sigma_C^2$, we obtain\vspace{-0.1cm}
\begin{equation}
	\label{q15}\small
	 \phi(\mathbf{x})+\upsilon(\mathbf{x})\ge\frac{\pi}{2}.
%     \cos \upsilon(\mathbf{x})\le\sin \phi(\mathbf{x}).
\vspace{-0.1cm}
\end{equation}
Therefore, subproblem (SP2) can be equivalently recast as \vspace{-0.1cm}
\begin{equation}
	\label{p9}\small
	\begin{aligned}
	(\text{BP2})	\quad \quad 	\max\limits_{\mathbf{x}}\;\;&\sqrt{N_tP_T}\sin(\upsilon(\mathbf{x})+\phi(\mathbf{x}))\\
		\text{s.t.}\;\;&\text{(\ref{q15})}
		,\text{(\ref{p6c})}.
	\end{aligned}\vspace{-0.1cm}
\end{equation}
The advantages of adopting these trigonometric transformations will be explained later.

After the above decomposition and transformations, we observe that although the subproblems only contain a single variable \(\mathbf{x}\), they are still challenging to solve due to the term $|{{\mathbf{h}^H}{\mathbf{a}}}|$. Specifically, when expanding $|{{\mathbf{h}^H}{\mathbf{a}}}|$ using Euler's formula, it becomes the sum of multiple sine and cosine functions with different periods, exhibiting a harmonic-like characteristic. Thus, it is almost impossible to find the global optimal solutions of problems (BP1) and (BP2) using existing algorithms. Fortunately, when the channel between the BS and the user follows the LoS model, i.e., \(L_t = L_r = 1\), these two subproblems can be further simplified, and the corresponding optimal solutions can be obtained. Therefore, in the following, we will consider the LoS channel scenario first and then address the more general NLoS channel scenario.
\vspace{-0.3cm}
\subsection{LoS Channel Scenario}
In this scenario, the channel vector in (\ref{q18}) can be re-expressed as \vspace{-0.2cm}
\begin{equation}
	\label{q19}\small
	\mathbf{h}^H(\mathbf{x})=\sigma_1^*\begin{bmatrix}e^{-j\frac{2\pi}{\lambda}x_1\sin\theta_t^1},...,e^{-j\frac{2\pi}{\lambda}x_{N_t}\sin\theta_t^1}\end{bmatrix}.
\end{equation}
Thus, $\sin\phi(\mathbf{x})$ in (\ref{q13})  becomes a constant $\sqrt{\frac{\Gamma\sigma_C^2}{P_T|\sigma_1|^2N_t}}$ that is independent of $\mathbf{x}$. Note that this observation can be easily obtained after converting $f_t(\mathbf{x})$ into $\sqrt{N_tP_T}\sin(\upsilon+\phi)$ via the trigonometric transformations introduced in (\ref{q12}) and (\ref{q13}), whereas the same does not hold true for the original subproblem (SP2). 
Based on this key observation, problem (BP2) can be further converted into the following more concise form without loss of optimality:\vspace{-0cm}
\begin{equation}
	\label{p10}\small
	\begin{aligned}
		\max\limits_{\mathbf{x}}\;\;&\sqrt{N_tP_T}\cos\upsilon(\mathbf{x})\\
		\text{s.t.}\;\;&\text{(\ref{q15})},\text{(\ref{p6c})}.
	\end{aligned}\vspace{-0.1cm}
\end{equation}
Furthermore, for ease of analysis, we substitute (\ref{q12}) back into subproblem (\ref{p10}) and obtain \vspace{-0.1cm}
\begin{equation}
	\label{p11}\small
	\begin{aligned}
		\max\limits_{\mathbf{x}}\;\;&\sqrt{{P_T}/{(N_t\begin{vmatrix}\sigma_1\end{vmatrix}^2)}}
		\begin{vmatrix}\mathbf{h}^H\mathbf{a}\end{vmatrix}\\
		\text{s.t.}\;\;&\text{(\ref{p7b})},\text{(\ref{p6c})}.
	\end{aligned}\vspace{-0.1cm}
\end{equation}
To this end, the subproblems (BP1) and (\ref{p11}) (equivalent to problem (BP2)) can be recombined into a simpler problem under the LoS scenario, which is given by\vspace{-0.1cm}
\begin{equation}
	\label{p12}\small
		 \begin{aligned}
		 	(\text{CP})	\quad \quad 
		\max\limits_{\mathbf{x}}\;\;&g(\mathbf{x})\triangleq
%		\begin{vmatrix}\mathbf{h}^H\mathbf{a}\end{vmatrix}=
		\begin{vmatrix}\sum\limits_{i=1}^{N_t}e^{-j\frac{2\pi}{\lambda}(\sin\theta_t^1+\sin\theta)x_i}\end{vmatrix}\\
		\text{s.t.}\;\;&\text{(\ref{p6c})}.
	\end{aligned}\vspace{-0.1cm}
\end{equation}
Problem (CP) contains \(N_t\) linear inequalities and its objective function is the modulus of the sum of \(N_t\) unit-magnitude complex numbers, i.e., $e^{-j\frac{2\pi}{\lambda}(\sin\theta_t^1+\sin\theta)x_i}$, $i=1,2,...,N_t$. In the real domain, this translates to the sum of \(N_t\) sine functions with different periods, which introduces strong periodicity in each dimension of \(\mathbf{x}\). 
%Moreover, it can be seen that the complexity of solving problem (CP) depends on the transmit antenna aperture, i.e., \( D_x \).
In the following, we analyze and solve problem (CP) under different values of \(D_x\).

First, when $D_x$ is sufficiently large and satisfies $D_x\ge\frac{(N_t-1)\lambda}{\sin\theta_t^1+\sin\theta}$, aligning the $N_t$ complex numbers along the same line in the complex plane yields the optimal solution of problem (CP), which is given by \vspace{-0.1cm}
\begin{equation}
	\label{q17}\small
	\begin{aligned}
		\mathbf{x}_\text{opt}=\left[
			0,  \frac{\lambda}{\sin\theta_t^1+\sin\theta} ,\cdots , \frac{(N_t-1)\lambda}{\sin\theta_t^1+\sin\theta}\right]^T.
	\end{aligned}\vspace{-0.1cm}
\end{equation}
Although the above optimal antenna positions are equidistant as in a conventional ULA, the antenna spacing bocomes \(\frac{\lambda}{\sin\theta_t^1 + \sin\theta}\), instead of \(\frac{\lambda}{2}\).\footnote{This implies that when the azimuth AoD \(\theta_t^1\) of the LoS channel transmit path and the target angle \(\theta\) are relatively small, the antenna aperture \(D_x\) needs to be very large in order to satisfy (\ref{q17}).}


Second, when  $D_x<\frac{(N_t-1)\lambda}{\sin\theta_t^1+\sin\theta}$ (note that $D_x$ should satisfy $D_x\ge(N_t-1)d$), problem (CP) becomes more challenging to solve due to the insufficient space to align the \(N_t\) complex numbers. 
%Additionally, in the real domain, each variable \(x_i\) exhibits significant periodicity, which complicates the search process for the global optimum. 
To proceed, we first consider a general function defined as ${E(\bm{\beta})=|\sum\nolimits_{i=1}^{N}\rho_ie^{j\beta_i}|}$, where $
\bm{\beta}\triangleq [\beta_1, \cdots, \beta_N]^T \in\mathbb{R}^{N\times1}$ and $\rho_i \geq 0, \forall i$, then a useful property of $E(\bm{\beta})$ can be exploited to further simplify problem (CP), which is given as follows.
\begin{Lemma}
	%For $\forall\bm{\rho}\in\mathbb{R}^{N\times1}_{++}$, there exists a unique maximum $\sum\limits_{i=1}^{N}\rho_i$ for the function $E(\bm{\beta})=\begin{vmatrix}\sum\limits_{i=1}^{N}\rho_ie^{j\beta_i}\end{vmatrix}$ with $\bm{\beta}\in\mathbb{R}^{N\times1}$ as the vector variable, satisfying $\beta_m-\beta_n=2\pi{k},1\le{m},{n}\le{N},k\in\mathbb{Z}$.%
$E(\bm{\beta})$ has a unique local maximum value of $\sum\nolimits_{i=1}^{N}\rho_i$, and to attain this local maximum, $\bm{\beta}$ must satisfy \vspace{-0.1cm}
	\begin{equation}
		\label{Econ}\small
		\begin{aligned}
			\beta_m-\beta_n=2\pi{k},1\le{m},{n}\le{N},k\in\mathbb{Z}.
		\end{aligned}\vspace{-0.1cm}
	\end{equation}
\end{Lemma}

\begin{proof}
	See Appendix C.
\end{proof}

Lemma 4 indicates that \( E(\bm{\beta}) \) only has one local maximum value which is also the global maximum value.
Besides, it can be observed that the objective function of problem (CP), i.e.,  \( g(\mathbf{x}) \), is a special case of \( E(\bm{\beta}) \) by setting $\bm{\rho} \triangleq [\rho_1,\cdots, \rho_N]^T=\mathbf{1}$ and $\bm{\beta}={-j\frac{2\pi}{\lambda}(\sin\theta_t^1+\sin\theta)}\mathbf{x}$.
Since the feasible region of problem (CP) is a compact set and \( g(\mathbf{x}) \) is a continuous function, its maximum must be achieved either at a local maximum point or on the boundary.
%According to Lemma 4, the unique local maximum of \( g(\mathbf{x}) \) satisfies (\ref{Econ}), and the corresponding solution is given by (\ref{q17}) when $D_x$ is sufficiently large. 
According to Lemma 4,  when $D_x\ge\frac{(N_t-1)\lambda}{\sin\theta_t^1+\sin\theta}$, satisfying condition (\ref{Econ}) actually implies that (\ref{q17}) is fulfilled. Therefore, when $D_x<\frac{(N_t-1)\lambda}{\sin\theta_t^1+\sin\theta}$, the optimal solution of problem (CP) must lie on the boundary%However, since $D_x<\frac{(N_t-1)\lambda}{\sin\theta_t^1+\sin\theta}$, neither criteria (\ref{Econ}) nor solution (\ref{q17}) is satisfied. 
%Consequently, the maximum solution of problem (CP) in the case of $D_x<\frac{(N_t-1)\lambda}{\sin\theta_t^1+\sin\theta}$ must lie on the boundary of its feasible region
, which means that some of the linear inequalities in $\mathbf{U}\mathbf{x}\preceq\mathbf{l}_u$ must be active.
We assume that the number of active constraints is \( c \), with \( 1 \leq c \leq N_t-1 \).\footnote{If \( c=N_t \), then \( \mathbf{U}\mathbf{x} = \mathbf{l}_u \) and \( D_x = (N_t - 1)\lambda/2 \) hold, which implies that the transmit antennas should be arranged at equal spacing with an interval of $\lambda/2$. This is equivalent to the conventional ULA and thus we can safely ignore the case of $c=N_t$.} 


Based on the above analysis, it follows that to obtain the optimal solution of problem (CP), we can check the corresponding Karush-Kuhn-Tucker (KKT) conditions. To describe the optimality conditions for a nonlinear optimization problem such as problem (CP), it is often required to assume that some regularity conditions are met \cite{book1}. Here, we employ a commonly used condition, known as the linear independence constraint qualification (LICQ), and the detailed verification is provided in Appendix D.


%\textit{Definition (LICQ \cite{book1}):}
%Given a point \( \mathbf{x} \) and an active set of a given nonlinear optimization problem, we say that the LICQ holds if the set of active constraint gradients 
%at \( \mathbf{x} \) is linearly independent.
%
%According to the above definition, we now compute the gradients of the inequality constraints in problem (CP), i.e., $\nabla_{\mathbf{x}}^T{\left(\mathbf{U}\mathbf{x}-\mathbf{l}_u\right)}=\mathbf{U}$,
%%\begin{equation}
%%	\begin{aligned}
%%		\nabla_{\mathbf{x}}^T{\left(\mathbf{U}\mathbf{x}-\mathbf{l}_u\right)}=\mathbf{U},
%%	\end{aligned}
%%\end{equation}
%where \(\mathbf{U}\) is an \( N_t \times N_t \) matrix given in (\ref{q16}) with \(\text{Rank}(\mathbf{U}) = N_t - 1\), and it can be easily verified that any 
%\( N_t-1 \) rows in \(\mathbf{U}\) are linearly independent. 
%As some of the constraints in problem (CP) must be active when $D_x<\frac{(N_t-1)\lambda}{\sin\theta_t^1+\sin\theta}$, let us assume that the number of active constraints is \( c \), where \( 1 \leq c \leq N_t-1 \).\footnote{If \( c=N_t \), then \( \mathbf{U}\mathbf{x} = \mathbf{l}_u \) and \( D_x = (N_t - 1)\lambda/2 \) hold, which implies that the transmit antennas should be arranged at equal spacing with an interval of $\lambda/2$. This is equivalent to the conventional ULA scheme and thus we can safely ignore the case $c=N_t$.} Based on the properties of \( \mathbf{U} \), we can infer that any \( c \) rows of \( \mathbf{U} \) must also be linearly independent, which indicates that problem (CP) satisfies the LICQ condition.


Now we are ready to establish the KKT conditions of problem (CP).
Suppose that \( \mathbf{x}^* \) is a local maximum point of (CP), and the LICQ holds at \( \mathbf{x}^* \), then there exists a Lagrange multiplier 
vector \( \bm{\lambda}^*=[\lambda_1^*, \lambda_2^*, \cdots, \lambda_{N_t}^*]^T\), such that the following conditions are satisfied at 
\( (\mathbf{x}^*, \bm{\lambda}^*) \):\vspace{-0.4cm}

\begin{subequations}
	\label{kkt}\small
	\begin{align}
		&\nabla_{\mathbf{x}} \mathcal{L}(\mathbf{x}^*, \bm{\lambda}^*) = \mathbf{0}, \label{kkt1}\\
		&\mathbf{U}\mathbf{\mathbf{x}^*}-\mathbf{l}_u\preceq\mathbf{0},\label{kkt2}\\
		&\bm{\lambda}^*\succeq\mathbf{0},\label{kkt3}\\
		&\bm{\lambda}^*\circ(\mathbf{U}\mathbf{\mathbf{x}^*}-\mathbf{l}_u)=\mathbf{0},\label{kkt4}
	\end{align}
\end{subequations}
where $\mathcal{L}(\mathbf{x}, \bm{\lambda})$ is the Lagrangian function defined as $	 	\mathcal{L}(\mathbf{x}, \bm{\lambda})=g(\mathbf{x})+
\bm{\lambda}^T(\mathbf{U}\mathbf{\mathbf{x}}-\mathbf{l}_u)$.
%\begin{equation}
%	\begin{aligned}
%	 	\mathcal{L}(\mathbf{x}, \bm{\lambda})=g(\mathbf{x})+
%	 	\bm{\lambda}^T(\mathbf{U}\mathbf{\mathbf{x}}-\mathbf{l}_u).
%	\end{aligned}
%\end{equation}
It is important to mention that solutions that satisfy the KKT conditions are not necessarily local optimum, but any local optimum must satisfy the KKT conditions. 
Furthermore, due to the highly non-convexity of $\nabla_{\mathbf{x}} \mathcal{L}(\mathbf{x}^*, \bm{\lambda}^*)$, it is generally impossible to find all the points that satisfy the KKT conditions, which means that obtaining the global optimal solution of problem (CP) is very difficult.
To tackle this difficulty, we will first present the proposed BT-BFS algorithm in the following to identify
all the local optimum of problem (CP) by utilizing the special properties of $E(\bm{\beta})$ given in Lemma 4. Then, we will provide the detailed proof for that the proposed algorithm is guaranteed to find the global optimal solution.

Without loss of generality, 
let $\mathcal{A}_c \triangleq \{ a_i|\mathbf{U}_{a_i}\mathbf{x} = ({\mathbf{l}_u})_{a_i},1\le{i}\le{c},a_1<a_2<\cdots<a_c \}$ denote the set of active constraint indices, where  
\(\mathbf{U}_{a_i}\) and \((\mathbf{l}_u)_{a_i}\) refer to the \(a_i\)-th row of \(\mathbf{U}\) and the \(a_i\)-th entry of \(\mathbf{l}_u\), respectively.
Due to the \textit{particularity} of the \(N_t\)-th constraint, i.e., $x_{N_t} -x_1 \le D_x$,  we propose to analyze problem (CP) by considering the following two cases.
%which means that \(\lambda^*_{a_1}\geq0, \lambda^*_{a_2}\geq0, \dots, \lambda^*_{a_c}\geq0\), while the remaining constraints are set to be inactive with corresponding \(\lambda^*_i=0,i\neq{a_1, a_2, \dots, a_c}\). The above assumption ensures that (\ref{kkt3}) and (\ref{kkt4}) are satisfied.
%Moreover, by analyzing the constraint conditions, we can identify the existence of a constant, denoted as \( D_{\text{min}} \), such that when \( D \geq D_{\text{min}} \), the local optimum \( \mathbf{x}^* \) can be solved under the aforementioned constraints. 
%However, when \( D < D_{\text{min}} \), the local optimum \( \mathbf{x}^* \) becomes unattainable. 
%We will illustrate the role of \( D_{\text{min}} \) in detail through the following two cases: one where the \(c\) constraints set as active exclude the \(N_t\)th constraint(i.e., \( a_c \leq N_t - 1 \)), and the other where the \(N_t\)th constraint is included(i.e., \( a_c = N_t \)).
%By substituting the variables into the objective function using the active constraint conditions, we can obtain an unconstrained problem in the neighborhood of \(\mathbf{x}^*\). After substituting the variables, we obtain an objective function that takes a form similar to the function described in Lemma 4. From Lemma 4, we know that the local maximum of a function in the form of \( E \) is unique. Therefore, once we find a local optimum that satisfies the remaining inactive constraints, it must be the unique solution for that specific case.
%Thus, we can initially treat some constraints as active and investigate whether the local maximum point in this scenario satisfies the overall antenna size \(D\). Consequently, we can determine that there exists a minimum \(D\) (denoted as \(D_{\text{min}}\)) such that the previously obtained local maximum value exists in this condition. 
%Next, we will explain the determination of \(D_{\text{min}}\) by analyzing two cases: one where the \(k\) constraints set as active exclude the \(N_t\)th constraint, and the other where the \(N_t\)th constraint is included.
\iffalse 
\begin{Lemma}
For problem (CP), if any $k$ out of its $N_t$ constraints are active, there exists a minimum $D$ (denoted as $D_{\min}$) such that the objective function $g(\mathbf{x})$ has a maximum value under these constraints, i.e., with \(k\) equality constraints and \(N_t-k\) inequality constraints.
 \end{Lemma}
 
 
\begin{proof}
Let's first consider the \( k \) active constraints excluding \( x_n - x_1 = D \).
 By substituting \(k\) equations, the dimension of the original problem can be reduced from \(N_t\) to \(N_t - k\). After reassigning indices to the remaining variables as $\mathbf{x}'$, the original objective function can be expressed as 
 \begin{equation}
 	\begin{aligned}
 		{\tilde{g}}(\mathbf{x})=
 		\begin{vmatrix}
 			\sum\limits_{i=1}^{N_t-k}r_ie^{-j\frac{2\pi}{\lambda}(\sin\theta_t^1+\sin\theta)x'_i}
 		\end{vmatrix},
 	\end{aligned}
 \end{equation}
 where 
\begin{equation}
	\label{q21}
	\begin{aligned}
	r_i=1+e^{-j\frac{2\pi}{\lambda}(\sin\theta^1_t+\sin\theta)d}+\cdots+
	e^{-j\frac{2\pi}{\lambda}(\sin\theta^1_t+\sin\theta)n_id},
	\end{aligned}
\end{equation}
with $n_i$ denoting the number of active constraints related to $x'_i$. According to Lemma 5, when $D$ is sufficiently large, function 
${\tilde{g}}(\mathbf{x})$ is guaranteed to have a unique maximum. We now present Algorithm 1 to determine the minimum \( D \) such that the aforementioned objective function attains a maximum value within its feasible region. 
\begin{algorithm}[!h]
	\caption{$D$-Minimization}
	\label{A1}
	\renewcommand{\algorithmicrequire}{\textbf{Input:}}
	\renewcommand{\algorithmicensure}{\textbf{Output:}}
	\begin{algorithmic}[1]
		\REQUIRE $N_t$, $k$, $p$, $D$, $d$, $\theta$, $\theta_t^1$, $\lambda$, $\{n_i\}_{i=1}^{N_t-k}$. %%input
		\ENSURE $D_{min}$ and the corresponding vector $\mathbf{x}$.    %%output
		\STATE  Initialization: $i\leftarrow1$.
		\STATE Compute $\{r_i\}_{i=1}^{N_t-k}$ via (\ref{q21}).
		\STATE $x_1\leftarrow\frac{\lambda{Angle(r_1)}}{2\pi(\sin\theta_t^1+\sin\theta)}$.
		\WHILE{$i\le{N_t}-k-1$}
		\STATE $x'_{i+1}\leftarrow{\frac{\lambda{Angle(r_{i+1})}}{2\pi(\sin\theta_t^1+\sin\theta)}}$.
		\WHILE{$x'_{i+1}-x'_i<n_id$}
		\STATE $x'_{i+1}\leftarrow{x'_{i+1}}+{\frac{\lambda}{\sin\theta_t^1+\sin\theta}}$.
		\ENDWHILE
		\STATE $i\leftarrow{i+1}$.
		\ENDWHILE
		\STATE $D_{min}\leftarrow{x'_{N_t-k}-x'_1+n_{N_t-k}d}$.
		\STATE \text{Substitute} $\mathbf{x}'$ \text{into the active constraints to obtain} $\mathbf{x}$.
		\RETURN $D_{min}$, $\mathbf{x}$.
	\end{algorithmic}
\end{algorithm}
The general idea of Algorithm 1 is to use the smallest \( D \) to align each $r_ie^{-j\frac{2\pi}{\lambda}(\sin\theta_t^1+\sin\theta)x'_i}$ into a straight line, thereby maximizing the function. Specifically, the $Angle$ function in step 3 is used to compute the phase angle of complex variables. From step 4 to step 10, we use the conclusion provided by Lemma 5 to compute the value of \(\mathbf{x}' \) that satisfies the remaining inequality constraints at the objective function's maximum. Step 6 to step 8 ensure that when $\mathbf{x}'$ is within the feasible region, the \( D_{\text{min}} \) obtained in Step 11 is minimized. Finally, \(\mathbf{x}' \) is restored to \(\mathbf{x}\) via active constraints and we output $D_{min}$ and the corresponding $\mathbf{x}$ in step 13.


Now let us discuss the case where the $N_t$th constraint is active, i.e., \(x_{N_t} - x_1 = D\). Similar to Algorithm \ref{A1}'s approach, we only need to redefine \(D_{min} = x^{\star}_p + (N_t - p)d\), where \(\mathbf{x}^{\star}\) is when the objective function reaches its maximum, and \(p\) is the largest index of the variable satisfying the inequality constraints (for example, if $x_{n-2}-x_{n-3}>d$, \(x_{n-1} - x_{n-2} = d\), and \(x_{N_t} - x_1 = D\), then \(p = n-2\)). Therefore, by using Algorithm \ref{A1}, we can obtain \( D_{\text{min}} \), which completes the proof.

\end{proof}
\fi

\textbf{Case}\;\textbf{\uppercase\expandafter{\romannumeral1}}:
 \( a_c \leq N_t - 1 \). 
In this case, by substituting the \( c \) active constraints into $g(\mathbf{x})$, i.e., retaining $x_{a_i},1\le{i}\le{c-1}$ as free variables and substituting \( x_{a_i+1} = x_{a_i} + d \) into $g(\mathbf{x})$, the dimension of the original problem (CP) can be reduced from \(N_t\) to \(N_t - c\). 
After relabeling the remaining \( N_t - c \) variables to form a new vector variable $\mathbf{x}'$, problem (CP) can be reduced to \vspace{-0.1cm}
\begin{equation}
	\label{pcase1}\small
	\begin{aligned}
	(\text{CP-m})	\quad  \max\limits_{\mathbf{x}'}\;\;&{\tilde{g}}(\mathbf{x}')\triangleq
		\begin{vmatrix}
			\sum\limits_{i=1}^{N_t-c}r_ie^{-j\frac{2\pi}{\lambda}(\sin\theta_t^1+\sin\theta)x'_i}
		\end{vmatrix}\\
		\text{s.t.}\;\;&\mathbf{U}'\mathbf{x}'\preceq\mathbf{l}'_{u}.
	\end{aligned}\vspace{-0.2cm}
\end{equation}
where \vspace{-0.2cm}
%\begin{equation}
%	\small
%	\begin{aligned}
%		r_i=\sum\limits_{p=0}^{n_i}
%		e^{-j\frac{2\pi}{\lambda}(\sin\theta^1_t+\sin\theta)pd},
%	\end{aligned}
%\end{equation}
%\vspace{-0.3cm}
%\begin{equation}\small
%	\begin{aligned}
%		\mathbf{U}'=\left[\begin{array} {cccccc}
%			1 & -1 & 0 & \cdots & 0 & 0\\
%			0 & 1 & -1  & \cdots & 0 & 0\\
%			\vdots & \vdots  & \vdots & \ddots & \vdots & \vdots\\
%			0 & 0 & 0 &  \cdots & 1 & -1\\
%			-1 & 0 & 0 &  \cdots & 0 &1
%		\end{array}\right]_{(N_t-c)\times{(N_t-c)}},
%	\end{aligned}
%\end{equation}
%\vspace{-0.3cm}
%\begin{equation}\small
%	\begin{aligned}
%		\mathbf{l}'_u=\left[
%			-(n_1+1)d,  -(n_2+1)d ,\cdots , D_x-n_{N_t-c}d \right]^T,
%	\end{aligned}
%\end{equation}
\begin{equation}
	\small
	\begin{aligned}
		r_i &= \sum\limits_{p=0}^{n_i}
		e^{-j\frac{2\pi}{\lambda}(\sin\theta^1_t+\sin\theta)pd}, \\
		\mathbf{U}' &= \left[\begin{array} {cccccc}
			1 & -1 & 0 & \cdots & 0 & 0\\
			0 & 1 & -1  & \cdots & 0 & 0\\
			\vdots & \vdots  & \vdots & \ddots & \vdots & \vdots\\
			0 & 0 & 0 &  \cdots & 1 & -1\\
			-1 & 0 & 0 &  \cdots & 0 & 1
		\end{array}\right]_{(N_t-c)\times{(N_t-c)}}, \\
		\mathbf{l}'_u &= \left[
		-(n_1+1)d,  -(n_2+1)d ,\cdots , D_x-n_{N_t-c}d 
		\right]^T,
	\end{aligned}\vspace{-0.1cm}
\end{equation}
with $n_i$ denoting the number of active constraints related to $x'_i$. 
%Based on Lemma 4, it is evident that when $D$ is sufficiently large, function ${\tilde{g}}(\mathbf{x}')$ is guaranteed to have a unique local maximum value, which is also the global optimal solution for problem (CP-m). 
%In this case, \( D_{\text{min}} \) represents the minimum value of \( D \) required to align the remaining \( N_t - c \) complex numbers, i.e., $r_ie^{-j\frac{2\pi}{\lambda}(\sin\theta_t^1+\sin\theta)x'_i}$, $i=1,2,...,N_t$, along the same line in complex plain.
%The $D$-Minimization Algorithm is presented in Algorithm 1 to determine the minimum \( D \) such that ${\tilde{g}}(\mathbf{x}')$ attains its maximum value within its feasible region.
\iffalse
\begin{algorithm}[!h]
	\caption{$D$-Minimization}
	\label{A1}
	\renewcommand{\algorithmicrequire}{\textbf{Input:}}
	\renewcommand{\algorithmicensure}{\textbf{Output:}}
	\begin{algorithmic}[1]
		\REQUIRE $N_t$, $c$, $D$, $d$, $\theta$, $\theta_t^1$, $\lambda$, $\{n_i\}_{i=1}^{N_t-c}$. %%input
		\ENSURE $D_\text{min}$ and the corresponding vector $\mathbf{x}$.    %%output
		\STATE  Initialization: $i\leftarrow1$.
		\STATE Compute $\{r_i\}_{i=1}^{N_t-c}$ via (\ref{q21}).
		\FOR{$j=1\rightarrow{N_t-c}$}
		\STATE $x'_j\leftarrow\frac{\lambda{\angle{r_j}}}{2\pi(\sin\theta_t^1+\sin\theta)}$.
		\ENDFOR
		\WHILE{$i\le{N_t}-c-1$}
		\STATE $x'_{i+1}\leftarrow{x'_{i+1}}+{\frac{\lambda}{\sin\theta_t^1+\sin\theta}}
		\lceil(x'_{i}-x'_{1}){\frac{\sin\theta_t^1+\sin\theta}{\lambda}}\rceil$.
		\IF{$x'_{i+1}-x'_i<{(n_i+1)}d$}
		\STATE $x'_{i+1}\leftarrow{x'_{i+1}}+{\frac{\lambda}{\sin\theta_t^1+\sin\theta}}$.
		\ELSIF {$x'_{i+1}-x'_i-{\frac{\lambda}{\sin\theta_t^1+\sin\theta}}\geq{(n_i+1)}d$}
		\STATE $x'_{i+1}\leftarrow{x'_{i+1}}-{\frac{\lambda}{\sin\theta_t^1+\sin\theta}}$.
		\ENDIF
		\STATE $i\leftarrow{i+1}$.
		\ENDWHILE
		\STATE \text{Substitute} $\mathbf{x}'$ \text{into the active constraints to obtain} $\mathbf{x}$.
		\STATE $D_\text{min}\leftarrow{x'_{N_t-c}-x'_1+n_{N_t-c}d}$.
		\RETURN $D_\text{min}$, $\mathbf{x}$.
	\end{algorithmic}
\end{algorithm} 
\fi
%The general idea of $D$-Minimization Algorithm is to use the smallest \( D \) to align each $r_ie^{-j\frac{2\pi}{\lambda}(\sin\theta_t^1+\sin\theta)x'_i}$ into a straight line, thereby maximizing the function. 
%Specifically, the process in step 3 to step 5 initializes \( \mathbf{x}' \) such that the phase angle of $r_ie^{-j\frac{2\pi}{\lambda}(\sin\theta_t^1+\sin\theta)x'_i}$ is zero, $i=1,2,...,N_t$. From step 6 to step 14, we use the conclusion provided by lemma 4 to compute \(\mathbf{x}' \) at ${\tilde{g}}(\mathbf{x}')$'s maximum that satisfies the inactive constraints. Step 8 to step 12 ensure that when $\mathbf{x}'$ is within the feasible domain, the \( D_{\text{min}} \) obtained in step 16 is minimized. Finally, \(\mathbf{x}' \) is restored to \(\mathbf{x}\) via active constraints and we output $D_\text{min}$ and the corresponding $\mathbf{x}$ in step 17.
Let $\mathbf{x}^{\prime *}$ denote  the optimal solution of problem (CP-m). Then, as ${\tilde{g}}(\mathbf{x}')$ is a special case of $E(\bm{\beta})$, \( {\mathbf{x}{'}}^* \) must satisfy condition (\ref{Econ}) in Lemma 4, which is given below:\vspace{-0.1cm}
\begin{equation}
	\label{criteria}\small
	\begin{aligned}
		\frac{2\pi}{\lambda}(\sin\theta_t^1+\sin\theta)({x}_{i+1}^{\prime*}-{x}_{i}^{\prime*}){-(\angle{r_{i+1}}-\angle{r_{i}})}=2\pi{k_i},
	\end{aligned}\vspace{-0.1cm}
\end{equation}
where $1\le{i}\le{N_t-c-1},{k_i}\in\mathbb{Z}$.
Additionally, by combining (\ref{criteria}) with the constraint of problem (CP-m), i.e., ${x}_{i+1}^{\prime*}-{x}_{i}^{\prime*}\ge (n_i+1)d$, we can see that $k_i$ must satisfy \vspace{-0.1cm}
\begin{equation}
	\label{k_i_ineq}\small
	\begin{aligned}
		\frac{{\lambda(2\pi{k_i}+\angle{r_{i+1}}-\angle{r_{i}})}}{2\pi(\sin\theta_t^1+\sin\theta)}\ge{(n_i+1)d}.
	\end{aligned}\vspace{-0.1cm}
\end{equation}
Furthermore, let $D_\text{min}={{{x}_{N_t-c}^{\prime{*}}-{x}_{1}^{\prime*}}+n_{N_t-c}d}$ denote the smallest \( D_x \) to align the $N_t-c$ complex numbers $r_ie^{-j\frac{2\pi}{\lambda}(\sin\theta_t^1+\sin\theta)x_i^{\prime}},i=1,2,\cdots,N_t-c$. Then, by substituting (\ref{criteria}) into $D_\text{min}$, we have \vspace{-0.1cm}
	\begin{align}
		\label{Dmin}\small
		D_\text{min}=&\sum\limits_{i=1}^{N_t-c-1}({x}_{i+1}^{\prime*}-{x}_{i}^{\prime*})+n_{N_t-c}d
		\\=&
		\frac{\lambda}{\sin\theta_t^1+\sin\theta}\sum\limits_{i=1}^{N_t-c-1}{\!\!\!\!}\left( {k_i}+
		\frac{{\angle{r_{i+1}}-\angle{r_{i}}}}{2\pi}\right)+n_{N_t-c}d.\nonumber
	\end{align}
To determine the minimum value of \( D_x \) that satisfies (\ref{criteria}), we minimize \( D_{\text{min}} \), thereby obtaining the minimum \( k_i \) from (\ref{k_i_ineq}) as\vspace{-0.0cm}
\begin{equation}
	\label{k_i}\small
	\begin{aligned}
		k_i=\left\lceil{
			\frac{\sin\theta_t^1+\sin\theta}{\lambda}(n_i+1)d-\frac{{\angle{r_{i+1}}-\angle{r_{i}}}}{2\pi}
			}\right\rceil.
	\end{aligned}\vspace{-0.1cm}
\end{equation}
%Therefore, when \(D_x \geq D_{\text{min}}\), the optimal solution of problem (CP-m) is as follows:
%\begin{equation}
%	\label{pcase1opt}
%	\begin{aligned}
%		{x}_{i+1}^{\prime*}={x}_{i}^{\prime*}+\frac{k_i\lambda}{\sin\theta_t^1+\sin\theta}+\frac{{\lambda(\angle{r_{i+1}}-\angle{r_{i}})}}{2\pi(\sin\theta_t^1+\sin\theta)},
%	\end{aligned}
%\end{equation}
%and \({x}_{1}^{\prime*}\) can be assumed to be 0 without loss of generality (In fact, (\ref{q17}) is a special case of (\ref{pcase1opt}) when $c=0$.). And when \( D_x < D_{\text{min}} \), the optimal solution of problem (CP-m) will be attained when some of its constraints become active. 


\textbf{Case}\;\textbf{\uppercase\expandafter{\romannumeral2}}: \( a_c = N_t \). 
Now we consider the case when the $N_t$-th constraint is active, i.e., \(x_{N_t} - x_1 = D_x\). 
Let \(l\) denote the smallest index of $\mathbf{x}$ such that the $(l+1)$-th to the $N_t$-th constraints are active.
Similar to the previous case, by substituting the \( c \) active constraints into $g(\mathbf{x})$, i.e., retaining $x_{a_i},1\le{i}\le{c-(N_t-l)+1}$ and $x_1$ as free variables and substituting \( x_{a_i+1} = x_{a_i} + d \) and $x_{N_t-j}=x_1+D_x-jd,0\le{j}\le{N_t-l-1}$ into $g(\mathbf{x})$, 
we can obtain a similar problem as (CP-m), with\vspace{-0.1cm}
%\begin{equation}\small
%	\begin{aligned}
%		r_1=
%		\sum\limits_{p=0}^{n_1+l-N_t}
%		{\!\!\!}e^{-j\frac{2\pi}{\lambda}(\sin\theta^1_t+\sin\theta)pd}+
%		\sum\limits_{p=0}^{N_t-l-1}
%		{\!\!\!}e^{j\frac{2\pi}{\lambda}(\sin\theta^1_t+\sin\theta)(pd-D_x)},
%	\end{aligned}
%\end{equation}
%\vspace{-1em}
%\begin{equation}\small
%	\begin{aligned}
%		\mathbf{U}'=\left[\begin{array} {ccccccc}
%			1 & -1 & 0 & 0 & \cdots & 0 & 0\\
%			0 & 1 & -1 & 0 & \cdots & 0 & 0\\
%			\vdots & \vdots & \vdots & \vdots & \ddots & \vdots & \vdots\\
%			0 & 0 & 0 & 0 & \cdots & 1 & -1
%		\end{array}\right]_{(N_t-c)\times{(N_t-c)}},
%	\end{aligned}
%\end{equation}
%\vspace{-1em}
%\begin{equation}\small
%	\begin{aligned}
%		\mathbf{l}'_u=\left[
%			-(n_1+1)d,  -(n_2+1)d ,\cdots , -(n_{N_t-c}+1)d\right]^T.
%	\end{aligned}
%\end{equation}
\begin{equation}\small
	\begin{aligned}
		r_1 &=
		\sum\limits_{p=0}^{n_1+l-N_t}
		{\!\!\!}e^{-j\frac{2\pi}{\lambda}(\sin\theta^1_t+\sin\theta)pd}
		+ \sum\limits_{p=0}^{N_t-l-1}
		{\!\!\!}e^{j\frac{2\pi}{\lambda}(\sin\theta^1_t+\sin\theta)(pd-D_x)},\\
		\mathbf{U}' &= 
		\left[\begin{array} {ccccccc}
			1 & -1 & 0 & 0 & \cdots & 0 & 0\\
			0 & 1 & -1 & 0 & \cdots & 0 & 0\\
			\vdots & \vdots & \vdots & \vdots & \ddots & \vdots & \vdots\\
			0 & 0 & 0 & 0 & \cdots & 1 & -1
		\end{array}\right]_{(N_t-c)\times{(N_t-c)}},\\
		\mathbf{l}'_u &=
		\left[
		-(n_1+1)d,  -(n_2+1)d ,\cdots , -(n_{N_t-c}+1)d
		\right]^T.
	\end{aligned}
\end{equation}
Due to the \textit{particularity} of the \(N_t\)-th constraint, we re-denote \(D_{\text{min}}\) in this case as follows:\vspace{-0.1cm}
\begin{align}
	\label{Dmin_2}\small
	D_\text{min}=&{{x}_{N_t-c}^{\prime*}-{x}_{1}^{\prime*}}+({N_t-l})d
	\\=&
	\frac{\lambda}{\sin\theta_t^1+\sin\theta}{\!\!\!\!}\sum\limits_{i=1}^{N_t-c-1}{\!\!\!\!}\left( {k_i}  + 
	\frac{{\angle{r_{i+1}}-\angle{r_{i}}}}{2\pi}\right)\!+\!({N_t-l})d,\nonumber
\end{align}
and the minimum $k_i$ to minimize $D_{\text{min}}$ is also given by (\ref{k_i}).

Therefore, we can see that with given $c$ and $a_c$, there exists a constant $D_{\text{min}}$ such that when $D_{\text{min}}\le D_x <\frac{(N_t-1)\lambda}{\sin\theta_t^1+\sin\theta} $, the local optimal solution of problem (CP) can also be easily obtained without exploiting the KKT conditions in (\ref{kkt}). Specifically, for both cases of $a_c \le N_t-1$ and $a_c=N_t$, the optimal solution of problem (CP-m) is as follows if \(D_x \geq D_{\text{min}}\):\vspace{-0.1cm}
\begin{equation}
	\label{pcase1opt}\small
	\begin{aligned}
		{x}_{i+1}^{\prime*}={x}_{i}^{\prime*}+\frac{k_i\lambda}{\sin\theta_t^1+\sin\theta}+\frac{{\lambda(\angle{r_{i+1}}-\angle{r_{i}})}}{2\pi(\sin\theta_t^1+\sin\theta)},
	\end{aligned}\vspace{-0.1cm}
\end{equation}
and \({x}_{1}^{\prime*}\) can be assumed to be 0 without loss of generality (in fact, (\ref{q17}) is a special case of (\ref{pcase1opt}) when $c=0$). When \( D_x < D_{\text{min}} \), however, the optimal solution of problem (CP-m) must lie on the boundary of its feasible region, which means that it can only be attained by considering all possible combinations of \(a_1, a_2, \dots, a_c\) and the value of $c$ should be enumerated from $1$ to $N_t-1$, such that  
%Since we have the method to derive \(D_{\text{min}}\), we can deduce that when \(D_x \geq D_\text{min}\), we can directly obtain the optimal solution \(\mathbf{x}^*\) of problem (CP) using (\ref{pcase1opt}), with the \(a_1, a_2, \dots, a_c\)th constraints  being active.
%Conversely, when $D_x<D_\text{min}$, the local maximum value of ${\tilde{g}}(\mathbf{x}')$ must lie on the boundary of its feasible region, which means it is obtained when one or more of the remaining inequality constraints become active. 
all local optimal values of problem (CP) are obtained. 
In this way, the most challenging part of the KKT conditions, i.e., (\ref{kkt1}), is automatically satisfied. Thus, by comparing these local optimal values, the global optimal solution can be determined.


\begin{figure}[t]
	\centering
	\includegraphics[width=3.2in]{BFSDFS.eps}
	\caption{Illustration of the BT-BFS and BT-DFS algorithms when \( N_t = 4 \).}
	\label{BFSDFS}
	\vspace{-0.0cm}
\end{figure}
To traverse all the boundaries of the feasible region (\ref{p6c}), $2^{N_t}$ cases are required to be evaluated which results in extremely high computational complexity. %Thus, we aim to develop a search algorithm that can also obtain the global optimal solution but with higher efficiency.
%Based on the absolute value inequality, it is evident that, when the \(N_t\)-th constraint is not considered, the fewer active constraints there are, the better the resulting solution will be. 
To lower the computational complexity and in the meantime still achieve the global optimal solution of problem (CP), we propose a BFS strategy, as shown in Fig. \ref{BFSDFS} (for a toy example with $N_t=4$), where the $c$-th ``layer" represents that $c$ constraints are active and \( \binom{N_t}{c} \) combinations of possible active constraints should be considered in this layer. These layers are traversed in a breadth-first manner from $c=0$.
In the example given in Fig. \ref{BFSDFS}, the overall search process is divided into four layers, i.e., \( c \in \{ 0, 1, 2, 3\} \), and $c$ also represents the size of the active set \( \mathcal{A}_c \). In each layer, there are a total number of \( \binom{4}{c} \) subsets. For each subset, if \( D_x \geq D_{\text{min}} \), a local optimum solution of problem (CP) can be easily found through (\ref{pcase1opt}).
On the other hand, if \( D_x < D_{\text{min}} \), the proposed algorithm will continue searching downward to the next layer until \( D_x \geq D_{\text{min}} \) is satisfied.
%This allows us to avoid the process of traversing all \(2^{N_t}\) possible cases, but still obtain the optimal solution efficiently.
Generally, the solutions obtained from the upper layers are better than those from the lower layers, as fewer active constraints are imposed in the upper layers and the corresponding objective function is supposed to have a higher degree of freedom.
However, since the \(N_t\)-th constraint is special as it limits the overall antenna size, it is possible that when the \(N_t\)-th constraint is active, the solutions obtained under fewer active constraints lead to worse outcomes. Therefore, in such cases, we need to perform an additional layer of traversal to ensure that the solution obtained after BFS is indeed optimal.
The detailed steps of the proposed BT-BFS algorithm to solve problem (CP) are summarized in Algorithm $\ref{A2}$. 
%Thus, the BFS algorithm identifies the local maximum value all on the boundary and selects the global maximum to obtain the optimal solution for problem (CP).
%The main idea of the algorithm is that the maximum value of $g(\mathbf{x})$ must be achieved at either a local maximum or on the boundary of the feasible domain.
%Now that we have a method to obtain \(D_{\text{min}}\), we can conduct a boundary traversal search to find the maximum value, based on the idea that the maximum value of $g(\mathbf{x})$ must be achieved at either a local maximum or on the boundary of the feasible domain. To ensure obtaining the optimal solution, we utilize breadth-first search as our method for traversing the boundary.
%The main idea of the algorithm is to traverse the previous \(k\) active constraints from 1 to \(N_t - 1\). If \(D_{\text{min}} \leq D\) for a given \(k\), it indicates that $g(\mathbf{x})$ can reach a maximum value under these constraints. Conversely, if \(D_{\text{min}} > D\), it implies that $g(\mathbf{x})$ does not have a maximum value under these constraints, so the maximum value of $g(\mathbf{x})$ must be found within the remaining boundaries.
%\begin{algorithm}[t]
%	\caption{Proposed BT-BFS Algorithm}
%	\label{A2}
%	\renewcommand{\algorithmicrequire}{\textbf{Input:}}
%	\renewcommand{\algorithmicensure}{\textbf{Output:}}
%	\begin{algorithmic}[1]
%		\REQUIRE $N_t$, $D_x$, $d$, $\theta$, $\theta_t^1$,$\lambda$  %%input
%		\ENSURE The returned optimal vector $\mathbf{x}$    %%output
%		
%		\STATE  Initialization: $L\leftarrow0$, $c\leftarrow1$,  $g_\text{max}\leftarrow0$, $D_\text{check}\leftarrow0$
%		\IF {$D_x\ge\frac{(N_t-1)\lambda}{\sin\theta_t^1+\sin\theta}$}
%		\STATE Obtain $\mathbf{x}_\text{opt}$ via (\ref{q17}).
%		\ELSE
%		\WHILE{$c\le{N_t}-1$}
%		\STATE $j\leftarrow1$.
%		\WHILE{$j\le{\binom{N_t}{c}
%			}$}
%		\STATE Obtain $\mathcal{A}_c$ and $\{n_i\}_{i=1}^{N_t-c}$ by traversing through ${\binom{N_t}{c}
%		}$ combinations of the constraints for each $j$.
%		\IF {$a_c<N_t$}
%		\STATE  Compute $D_\text{min}$ via (\ref{Dmin}).
%		\ELSE
%		\STATE  Compute $D_\text{min}$ via (\ref{Dmin_2}).
%		\ENDIF
%		\STATE Obtain $\mathbf{x}'$ via (\ref{pcase1opt}).
%		\IF {$D_\text{min}\le{D_x}$ and $\tilde{g}_\text{max}<{\tilde{g}}(\mathbf{x}')$}
%		\STATE $\mathbf{x}'_\text{opt}\leftarrow\mathbf{x}'$, $\tilde{g}_\text{max}\leftarrow{\tilde{g}(\mathbf{x}')}$, $L\leftarrow{c}.$
%		\ENDIF
%		\STATE $j\leftarrow{j+1}$.
%		\ENDWHILE
%		\IF {$D_\text{check}=1$}
%		\STATE Break.
%		\ELSIF {$L>0$}
%		\STATE $c\leftarrow{L}+1$, $D_\text{check}\leftarrow1$.
%		\ELSE
%		\STATE $c\leftarrow{c+1}$.
%		\ENDIF
%		\ENDWHILE
%		\ENDIF
%		\STATE Obtain $\mathbf{x}_\text{opt}$ from $\mathbf{x}'_\text{opt}$.
%		\RETURN $\mathbf{x}_\text{opt}$.
%	\end{algorithmic}
%\end{algorithm}
\begin{algorithm}[t]
	\caption{Proposed BT-BFS Algorithm}
	\label{A2}
	\renewcommand\baselinestretch{\linspreadalgr}\selectfont
	\renewcommand{\algorithmicrequire}{\textbf{Input:}}
	\renewcommand{\algorithmicensure}{\textbf{Initialize:}}
	\begin{algorithmic}[1]
		\REQUIRE $N_t$, $D_x$, $d$, $\theta$, $\theta_t^1$,$\lambda$.  %%input
		\ENSURE $L\leftarrow0$, $c\leftarrow1$,  $g_\text{max}\leftarrow0$, $D_\text{check}\leftarrow0$.

		\STATE \textbf{if} {$D_x\ge\frac{(N_t-1)\lambda}{\sin\theta_t^1+\sin\theta}$} \textbf{then} obtain $\mathbf{x}_\text{opt}$ via (\ref{q17}).
		\STATE \textbf{else} \textbf{while} {$c\le{N_t}-1$} \textbf{do} 
		\STATE \;\;\;\;\;\;\;\;\;\;\;$j\leftarrow1$.
		\STATE \;\;\;\;\;\;\;\;\;\;\;\textbf{while} {$j\le{\binom{N_t}{c}}$} \textbf{do}
		\STATE \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;Obtain $\mathcal{A}_c$ and $\{n_i\}_{i=1}^{N_t-c}$. %by traversing through ${\binom{N_t}{c}}$ \text{\quad\quad} combinations of the constraints for each $j$.
		\STATE \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\textbf{if} {$a_c<N_t$} \textbf{then} compute $D_\text{min}$ via (\ref{Dmin}).
		\STATE \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\textbf{else} Compute $D_\text{min}$ via (\ref{Dmin_2}). \textbf{end if}
		\STATE \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;Obtain $\mathbf{x}'$ via (\ref{pcase1opt}), $j\leftarrow{j+1}$.
		\STATE \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\textbf{if} {$D_\text{min}\le{D_x}$ and $\tilde{g}_\text{max}<{\tilde{g}}(\mathbf{x}')$} \textbf{then} 
		\STATE \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;$\mathbf{x}'_\text{opt}\leftarrow\mathbf{x}'$, $\tilde{g}_\text{max}\leftarrow{\tilde{g}(\mathbf{x}')}$, ${L}\leftarrow{c}.$ \textbf{end if}
		\STATE \;\;\;\;\;\;\;\;\;\;\;\textbf{end while}
		\STATE \;\;\;\;\;\;\;\;\;\;\;\textbf{if} {$D_\text{check}=1$}  \textbf{then} \textbf{break}.
		\STATE \;\;\;\;\;\;\;\;\;\;\;\textbf{else if} {$L>0$} \textbf{then} $c\leftarrow{L}+1$, $D_\text{check}\leftarrow1$.
		\STATE \;\;\;\;\;\;\;\;\;\;\;\textbf{else} {$c\leftarrow{c+1}$.} \textbf{end if}
		\STATE \;\;\;\;\;\;\;\textbf{end while} 
		\STATE \textbf{end if}
		\RETURN $\mathbf{x}_\text{opt}$ obtained from $\mathbf{x}'_\text{opt}$.
	\end{algorithmic}
	\vspace{-0.1cm}
\end{algorithm}



\begin{algorithm}[t]
	\caption{Proposed BT-DFS Algorithm}
	\label{A3}
	\renewcommand\baselinestretch{\linspreadalgr}\selectfont
	\renewcommand{\algorithmicrequire}{\textbf{Input:}}
	\renewcommand{\algorithmicensure}{\textbf{Initialize:}}
	\begin{algorithmic}[1]
		\REQUIRE $N_t$, $D_x$, $d$, $\theta$, $\theta_t^1$,$\lambda$.  %%input
		\ENSURE $\mathcal{I}\leftarrow{\text{a random sequence from $1$ to $N_t$}}$, $c\leftarrow1$.
		\STATE \textbf{if} {$D_x\ge\frac{(N_t-1)\lambda}{\sin\theta_t^1+\sin\theta}$} \textbf{then} obtain $\mathbf{x}_\text{opt}$ via (\ref{q17}).
		\STATE \textbf{else} \textbf{while} {$c\le{N_t}-1$} \textbf{do} 		
		\STATE \;\;\;\;\;\;\;\;\;\;\;Add ${\mathcal{I}(c)}$ into $\mathcal{A}_c$ and obtain $\{n_i\}_{i=1}^{N_t-c}$. 
		\STATE \;\;\;\;\;\;\;\;\;\;\;\textbf{if} {$a_c<N_t$} \textbf{then} compute $D_\text{min}$ via (\ref{Dmin}).
		\STATE \;\;\;\;\;\;\;\;\;\;\;\textbf{else} Compute $D_\text{min}$ via (\ref{Dmin_2}). \textbf{end if}
		\STATE \;\;\;\;\;\;\;\;\;\;\;Obtain $\mathbf{x}'$ via (\ref{pcase1opt}), $c\leftarrow{c+1}$.
		\STATE \;\;\;\;\;\;\;\;\;\;\;\textbf{if} $D_\text{min}\le{D_x}$ \textbf{then} 
		$\mathbf{x}'_\text{local}\leftarrow\mathbf{x}',$ \textbf{break}. \textbf{end if}
		\STATE \;\;\;\;\;\;\;\textbf{end while} 
		\STATE\textbf{end if}
		\RETURN $\mathbf{x}_\text{local}$ obtained from $\mathbf{x}'_\text{local}$.
	\end{algorithmic}\vspace{-0.1cm}
\end{algorithm}
%The detailed steps of the proposed BT-BFS algorithm to solve problem (CP) are summarized in Algorithm $\ref{A2}$. 






To further reduce the computational complexity, we propose in the following the BT-DFS algorithm. 
%Different from the BT-BFS algorithm, the BT-DFS algorithm adds constraints to the active set \(\mathcal{A}_c\) one by one until \(D_x \geq D_{\text{min}}\) is achieved.
Different from the BT-BFS algorithm, the BT-DFS algorithm adds constraints to the active set \(\mathcal{A}_c\) one by one until \(D_x \geq D_{\text{min}}\) is achieved.
As shown in the example in Fig. \ref{BFSDFS} (b), a random sequence \( \mathcal{I} = \{2, 1, 3, 4\} \) is chosen to represent the searching path of the proposed depth-first traversal, which means that the 2nd, 1st, 3rd, and 4th constraints are sequentially activated in each layer until \( D_x \geq D_{\text{min}} \) holds.
Although this algorithm does not guarantee the optimal solution for problem (CP) generally, it can achieve a local optimal solution with reasonably good performance, and the corresponding details are provided in Algorithm \ref{A3}.


%\begin{algorithm}[t]
%	\caption{Proposed BT-DFS Algorithm}
%	\label{A3}
%	\renewcommand\baselinestretch{\linspreadalgr}\selectfont
%	\renewcommand{\algorithmicrequire}{\textbf{Input:}}
%	\renewcommand{\algorithmicensure}{\textbf{Initialize:}}
%	\begin{algorithmic}[1]
%		\REQUIRE $N_t$, $D_x$, $d$, $\theta$, $\theta_t^1$,$\lambda$.  %%input
%		\ENSURE $\mathcal{I}\leftarrow{\text{a random sequence from $1$ to $N_t$}}$, $c\leftarrow1$.
%		\STATE \textbf{if} {$D_x\ge\frac{(N_t-1)\lambda}{\sin\theta_t^1+\sin\theta}$} \textbf{then} obtain $\mathbf{x}_\text{opt}$ via (\ref{q17}).
%		\STATE \textbf{else} \textbf{while} {$c\le{N_t}-1$} \textbf{do} 		
%		\STATE \;\;\;\;\;\;\;\;\;\;\;Add ${\mathcal{I}(c)}$ into $\mathcal{A}_c$ and obtain $\{n_i\}_{i=1}^{N_t-c}$. 
%		\STATE \;\;\;\;\;\;\;\;\;\;\;\textbf{if} {$a_c<N_t$} \textbf{then} compute $D_\text{min}$ via (\ref{Dmin}).
%		\STATE \;\;\;\;\;\;\;\;\;\;\;\textbf{else} Compute $D_\text{min}$ via (\ref{Dmin_2}). \textbf{end if}
%		\STATE \;\;\;\;\;\;\;\;\;\;\;Obtain $\mathbf{x}'$ via (\ref{pcase1opt}), $c\leftarrow{c+1}$.
%		\STATE \;\;\;\;\;\;\;\;\;\;\;\textbf{if} $D_\text{min}\le{D_x}$ \textbf{then} 
%		$\mathbf{x}'_\text{local}\leftarrow\mathbf{x}',$ \textbf{break}. \textbf{end if}
%		\STATE \;\;\;\;\;\;\;\textbf{end while} 
%		\STATE\textbf{end if}
%		\RETURN $\mathbf{x}_\text{local}$ obtained from $\mathbf{x}'_\text{local}$.
%	\end{algorithmic}\vspace{-0.1cm}
%\end{algorithm}


\vspace{-0.2cm}
\subsection{NLoS Channel Scenario}
For the general NLoS channel scenario, the channel vector $\mathbf{h}$ becomes more complex, and it is not feasible to recombine the two subproblems (BP1) and (BP2) into a single problem, as in Section \uppercase\expandafter{\romannumeral4}. B. Therefore, we propose an MM-based RGP algorithm to solve these two subproblems.

First, we focus on subproblem (BP1). 
As can be seen, its objective function, i.e., $p_1(\mathbf{x})$, can be equivalently transformed into
$p_1(\mathbf{x})={\bm{\psi}(\mathbf{x})}^H\bm{\Sigma}\bm{\psi}(\mathbf{x})$, 
%\begin{equation}
%	\begin{aligned}
%		p_1(\mathbf{x})={\bm{\psi}(\mathbf{x})}^H\bm{\Sigma}\bm{\psi}(\mathbf{x}),
%	\end{aligned}
%\end{equation}
where $\bm{\Sigma}\triangleq\bm{\sigma}{\bm{\sigma}}^H$ is a positive semi-definite matrix and 
$\bm{\psi}(\mathbf{x})\triangleq\mathbf{G}_{L_t\times{N_t}}\mathbf{a}_{N_t\times{1}}=[
\sum\nolimits_{i=1}^{N_t}e^{-j\frac{2\pi}{\lambda}(\sin\theta_t^1+\sin\theta)x_i},\cdots,
\sum\nolimits_{i=1}^{N_t}e^{-j\frac{2\pi}{\lambda}(\sin\theta_t^{L_t}+\sin\theta)x_{i}} ]^T.$
%\begin{align}
%\bm{\psi}&(\mathbf{x})\triangleq\mathbf{G}_{L_t\times{N_t}}\mathbf{a}_{N_t\times{1}}\\=&\left[
%\sum\limits_{i=1}^{N_t}e^{-j\frac{2\pi}{\lambda}(\sin\theta_t^1+\sin\theta)x_i},\cdots,
%\sum\limits_{i=1}^{N_t}e^{-j\frac{2\pi}{\lambda}(\sin\theta_t^{L_t}+\sin\theta)x_{i}} \right]^T.\nonumber
%\end{align}
Since \( p_1(\mathbf{x}) \) is convex with respect to (w.r.t.) \( {\bm{\psi}(\mathbf{x})} \), we can derive the following lower bound of \( {\bm{\psi}(\mathbf{x})}^H\bm{\Sigma}\bm{\psi}(\mathbf{x}) \) with given local point \( \mathbf{x}^i \) in the \( i \)-th iteration of the proposed MM-based algorithm based on the first-order Taylor expansion of $p_1(\mathbf{x})$:
\begin{equation}\small
	\begin{aligned}
	p_1(\mathbf{x})\ge
	\underbrace{\operatorname{Re} \left\{ \bm{\psi}(\mathbf{x}^i)^H \bm{\Sigma} \bm{\psi}(\mathbf{x}) \right\}}_{\triangleq\bar{p}_1(\mathbf{x})} - \underbrace{\bm{\psi}(\mathbf{x}^i)^H \bm{\Sigma} \bm{\psi}(\mathbf{x}^i)}_{\text{constant}}.
	\end{aligned}	\vspace{-0.2cm}
\end{equation}
Apparently, \( {\bar{p}_1(\mathbf{x})} \) is still neither concave nor convex over \( \mathbf{x} \), which cannot be regarded as the surrogate function of \( {{p}_1(\mathbf{x})} \) according to the MM principle \cite{MMorigin}. To address this difficulty, we propose to construct a surrogate function by using the second-order Taylor expansion of \( {{p}_1(\mathbf{x})} \).
Let \( \nabla {\bar{p}_1(\mathbf{x})} \in \mathbb{R}^{N_t} \) and \( \nabla^2 {\bar{p}_1(\mathbf{x})} \in \mathbb{R}^{N_t \times N_t} \) denote the gradient and Hessian matrix of \( {\bar{p}_1(\mathbf{x})} \) w.r.t. \( \mathbf{x} \), respectively. 
Then, we can always find a positive real number \( \delta_1 \) that satisfies \( \delta_1 \mathbf{I}_{N_t} \succeq \nabla^2 {\bar{p}_1(\mathbf{x})} \). 
%The detailed expressions of \( \nabla {\bar{p}_1(\mathbf{x})}  \) and \( \nabla^2 {\bar{p}_1(\mathbf{x})}  \) are presented in Appendix D, while the process to find an appropriate value of $\delta_1$ is given in Appendix E.
The detailed expressions of \( \nabla {\bar{p}_1(\mathbf{x})}  \) and \( \nabla^2 {\bar{p}_1(\mathbf{x})}  \) as well as the process to find an appropriate value of $\delta_1$ are given in Appendix E.
Thus, the following quadratic surrogate function can be employed to globally lower-bound \( \bar{p}_1(\mathbf{x}) \): $\bar{p}_1(\mathbf{x}) \geq \bar{p}_1(\mathbf{x}^i) + \nabla \bar{p}_1(\mathbf{x}^i)^T (\mathbf{x} - \mathbf{x}^i)
- \frac{\delta_1}{2} (\mathbf{x} - \mathbf{x}^i)^T (\mathbf{x} - \mathbf{x}^i)$.
%\begin{align}
%\bar{p}_1(\mathbf{x}) \geq& \bar{p}_1(\mathbf{x}^i) + \nabla \bar{p}_1(\mathbf{x}^i)^T (\mathbf{x} - \mathbf{x}^i)
%- \frac{\delta_1}{2} (\mathbf{x} - \mathbf{x}^i)^T (\mathbf{x} - \mathbf{x}^i)\nonumber
%\\=& \underbrace{-\frac{\delta_1}{2} \mathbf{x}^T \mathbf{x} + \left(\nabla \bar{p}_1(\mathbf{x}^i) + \delta_1 \mathbf{x}^i\right)^T \mathbf{x}}_{\triangleq\tilde{p}_1(\mathbf{x})}\nonumber
%\\
%&+ \underbrace{\bar{p}_1(\mathbf{x}^i) - \nabla \bar{p}_1(\mathbf{x}^i)^T \mathbf{x}^i - \frac{\delta_1}{2} (\mathbf{x}^i)^T \mathbf{x}^i}_{\text{constant}}. 
%\end{align}
Thus, subproblem (BP1) in the $i$-th iteration of the proposed MM-based algorithm  can be relaxed as\vspace{-0.1cm}
\begin{equation}
	\label{MM1}\small
	\begin{aligned}
		(\text{BP1-m})	\quad \quad
&\max_{\mathbf{x}} \quad {-\frac{\delta_1}{2} \mathbf{x}^T \mathbf{x} + \left(\nabla \bar{p}_1(\mathbf{x}^i) + \delta_1 \mathbf{x}^i\right)^T \mathbf{x}}
\\
&\;\;\;\text{s.t. } \;\;\; \text{(\ref{p6c})},
	\end{aligned}\vspace{-0.1cm}
\end{equation}
where constraint (\ref{p6b}) can be safely omitted because the objective function of subproblem (BP1) already incorporates this constraint and if the final solution of (BP1-m) after a sufficient number of iterations violates (\ref{p6b}), this implies that we need to solve subproblem (BP2) instead.
Since problem (BP1-m) is a typical convex quadratic programming (QP) problem, its global optimal solution, denoted by $\mathbf{x}^{i+1}$, can be efficiently obtained by off-the-shelf solvers, such as CVX \cite{cvx}.
%The above analysis pertains to subproblem (BP1); however, recall that the actual problem we need to solve is subproblem (SP1), which is actually easier than (BP1) since we only need to find a $\mathbf{x}$ that satisfies \( p_1(\mathbf{x}) \ge \frac{N_t}{P_T}\Gamma\sigma_C^2 \).
Therefore, if $\mathbf{x}^{i+1}$ satisfies (\ref{p6b}), we can find a feasible solution of subproblem (SP1), which is also the optimal solution of the original problem (BP). Otherwise, we continue to compute $\mathbf{x}^{i+1}$ in the next iteration. 
The details of the proposed algorithm to solve problem (SP1) are summarized in Algorithm 3, which is guaranteed to converge to the set of stationary solutions \cite{MMconvergence}. 
%and $\mathbf{x}^{i}$ is assured to converge to a stationary point.
It is noteworthy that in step 6 of Algorithm 3, if we are unable to obtain a feasible solution for subproblem (SP1), then -1 is returned and in this case, we should turn to subproblem (BP2) for solving the original problem (BP). 
\begin{algorithm}[t]
	\caption{MM for Solving Problem (SP1)}
	\renewcommand\baselinestretch{\linspreadalgr}\selectfont
	\renewcommand{\algorithmicrequire}{\textbf{Input:}}
	\renewcommand{\algorithmicensure}{\textbf{Initialize:}}
	\begin{algorithmic}[1]
		\REQUIRE  $N_t$, $D_x$, $d$, $\theta$, $\theta_t^1$, $\lambda$, $L_t$, $\bm{\sigma}$, $\epsilon_1$.
		\ENSURE $i \leftarrow 0$.

		\REPEAT 
		\STATE Compute $\nabla \bar{p}_1(\mathbf{x}^i)$ and $\nabla^2 \bar{p}_1(\mathbf{x}^i)$. 
		%via (\ref{gradient1}) and (\ref{hessian1}).
		\STATE Update $\delta_1$, 
		%via (\ref{delta1}), 
		and obtain $\mathbf{x}^{i+1}$ by solving (BP1-m).
%		\STATE \textbf{if} {$\mathbf{x}^{i+1}$ satisfies (\ref{p6b})} \textbf{then} \textbf{return} $\mathbf{x}^{i+1}$. \textbf{end if}
		\STATE $i \leftarrow i + 1$.
		\UNTIL {$\begin{vmatrix} p_1(\mathbf{x}^{i})-p_1(\mathbf{x}^{i-1})\end{vmatrix}<\epsilon_1$}
		\RETURN -1.
	\end{algorithmic}\vspace{-0.1cm}
\end{algorithm}

\begin{algorithm}[t]
	\caption{Proposed MM-based RGP algorithm}
	\renewcommand\baselinestretch{\linspreadalgr}\selectfont
	\renewcommand{\algorithmicrequire}{\textbf{Input:}}
	\renewcommand{\algorithmicensure}{\textbf{Initialize:}}
	\begin{algorithmic}[1]
		\REQUIRE $N_t$, $D_x$, $d$, $\theta$, $\theta_t^1$, $\lambda$, $L_t$, $\bm{\sigma}$, $\epsilon_2$, \( M \).
		\ENSURE \( i \leftarrow 0 \), obtain \( \mathbf{x}^1 \) via Algorithm 3.
		
		\STATE \textbf{while} \( i < M \) \textbf{do}
		\STATE \;\;\;\; \( i \leftarrow i + 1 \).
		\STATE \;\;\;\;Calculate \( \mathbf{M} \) and \( \mathbf{P}\).
		\STATE \;\;\;\;\textbf{if} \( \| \mathbf{P} \nabla p_2 (\mathbf{x}^i) \|< \epsilon_2 \) \textbf{then}
		\STATE \;\;\;\;\;\;\;\;\textbf{if} \( \mathbf{M} \) is an empty matrix \textbf{then} \textbf{break}.
		\STATE \;\;\;\;\;\;\;\;\textbf{else} \( \mathbf{u} = -(\mathbf{M}\mathbf{M}^T)^{-1} \mathbf{M} \nabla p_2 (\mathbf{x}^i) \), \( u_j \leftarrow \min (\mathbf{u}) \).
		\STATE \;\;\;\;\;\;\;\;\;\;\;\;\textbf{if} \( u_j \geq 0 \) \textbf{then} \textbf{break}.
		\STATE \;\;\;\;\;\;\;\;\;\;\;\;\textbf{else} remove \( \mathbf{M}_j \) and go to step 3. \textbf{end if}
		\STATE \;\;\;\;\;\;\;\;\textbf{end if}
		\STATE \;\;\;\;\textbf{else} obain $\alpha^i$ via Armijo step-size rule.	
		\STATE  \;\;\;\;\;\;\;\;\;\;\;\;\( \mathbf{x}^{i+1}\leftarrow \mathbf{x}^i- \alpha^i\mathbf{P}\nabla p_2 (\mathbf{x}^i)\).
		\STATE \;\;\;\;\textbf{end if}
		\STATE \textbf{end while}
		\RETURN \( \mathbf{x}^{i+1} \).
	\end{algorithmic}\vspace{-0.1cm}
\end{algorithm}
\iffalse
Next, we consider subproblem (BP2) and can easily have the following lower bound of its objective function:
\begin{equation}
	\label{ft}
	\begin{aligned}
		{f_t}{(\mathbf{x})} \ge &
		\sqrt{N_tP_T}\left(1 + \sin \phi(\mathbf{x})\cos \upsilon(\mathbf{x})- \sin^2\phi(\mathbf{x})\right)\\
		= & \sqrt{N_tP_T} + \sqrt{\Gamma \sigma_C^2}\left( 
		\frac{{\begin{vmatrix}{{\mathbf{h}^H}{\mathbf{a}}}\end{vmatrix} - \sqrt{\frac{N_t}{P_T}\Gamma \sigma_C^2}}}
		{{\|{\mathbf{h}}\|}^2}
		\right) ,
	\end{aligned}
\end{equation}
where the inequality holds because of (\ref{q15}), i.e., $\cos \upsilon(\mathbf{x})\le\sin \phi(\mathbf{x})$.
Due to the complexity of $	{f_t}{(\mathbf{x})}$, we relax it and reformulate subproblem (BP2) as follows:
\begin{equation}
	\label{p9_relax}
	\begin{aligned}
		\max\limits_{\mathbf{x}}\;\;&	\frac{{\begin{vmatrix}{{\mathbf{h}^H}{\mathbf{a}}}\end{vmatrix} - \sqrt{\frac{N_t}{P_T}\Gamma \sigma_C^2}}}
		{{\|{\mathbf{h}}\|}^2}\\
		\text{s.t.}\;\;&\text{(\ref{q15})}
		,\text{(\ref{p6c})}.
	\end{aligned}
\end{equation}



\begin{equation}
	\label{p9_relax_Dinkelbach}
	\begin{aligned}
		\max\limits_{\mathbf{x}}\;\;& \begin{vmatrix}{{\mathbf{h}^H(\mathbf{x})}{\mathbf{a}(\mathbf{x})}}\end{vmatrix}- \alpha^i
		{{\|{\mathbf{h}(\mathbf{x})}\|}^2}\\
		\text{s.t.}\;\;&\text{(\ref{q15})}
		,\text{(\ref{p6c})}.
	\end{aligned}
\end{equation}

$\alpha^{i+1} = \frac{{\begin{vmatrix}{{\mathbf{h}^H(\mathbf{x}^i)}{\mathbf{a}(\mathbf{x}^i)}}\end{vmatrix} - \sqrt{\frac{N_t}{P_T}\Gamma \sigma_C^2}}}
{{\|{\mathbf{h}(\mathbf{x}^i)}\|}^2}$

\fi






Next, we consider subproblem (BP2).
Since its objective function is a sine function with its domain restricted to $[0,\pi]$ and subject to the constraint (\ref{q15}), i.e., $\upsilon(\mathbf{x})+\phi(\mathbf{x})\ge \frac{\pi}{2}$, it can be equivalently reformulated as \vspace{-0.1cm}
\begin{equation}
	\label{MM2}\small
	\begin{aligned}
		(\text{BP2-m})	\quad \quad\quad
		\min\limits_{\mathbf{x}}\;\;&p_2(\mathbf{x})\triangleq\upsilon(\mathbf{x})+\phi(\mathbf{x})&&\\
		\text{s.t.}\;\;&\text{(\ref{q15})},\text{(\ref{p6c})}.&&
	\end{aligned}\vspace{-0.1cm}
\end{equation}
It is noteworthy that the constraint (\ref{q15}) in problem (BP2-m) is equivalent to \( p_1(\mathbf{x}) \leq \frac{N_t}{P_T} \Gamma \sigma_C^2 \) and it can also be omitted
because if the solution of the resulting problem violates (\ref{q15}), i.e., \( \upsilon(\mathbf{x}) + \phi(\mathbf{x}) < \frac{\pi}{2} \), then this solution becomes a feasible solution of subproblem (SP1), thus serving as the optimal solution to the original problem (BP).
Therefore, by enlarging the feasible region via ignoring (\ref{q15}), we increase the probability of obtaining the optimal solution of the original problem (BP).
Furthermore, by substituting (\ref{q12}) and (\ref{q13}) into $p_2(\mathbf{x})$, $p_2(\mathbf{x})$ can be equivalently rewritten as follows:\vspace{-0.1cm}
%\begin{align}
%	\label{p_2}
%	p_2(\mathbf{x})=&\upsilon(\mathbf{x})+\phi(\mathbf{x})=
%	\arccos\frac{{\begin{vmatrix}{{\mathbf{h}^H}{\mathbf{a}}}\end{vmatrix}}}
%	{{\|{\mathbf{h}}\|}\|\mathbf{a}\|}+
%	\arcsin\sqrt{\frac{\Gamma\sigma_C^2}{P_T\|\mathbf{h}\|^2}}\nonumber\\=&
%	\arccos\sqrt{\frac{{p_1(\mathbf{x})}}
%		{N_t{\|{\mathbf{h}}\|}^2}}+
%	\arcsin\sqrt{\frac{\Gamma\sigma_C^2}{P_T\|\mathbf{h}\|^2}}.
%\end{align}
\begin{equation}\small
\begin{aligned}
	\label{p_2}
	p_2(\mathbf{x})=
	\arccos\sqrt{\frac{{p_1(\mathbf{x})}}
		{N_t{\|{\mathbf{h}}\|}^2}}+
	\arcsin\sqrt{\frac{\Gamma\sigma_C^2}{P_T\|\mathbf{h}\|^2}},
\end{aligned}\vspace{-0.1cm}
\end{equation}
which is much more complex than \( p_1(\mathbf{x}) \). Thus, finding a proper surrogate function based on the MM principle is quite challenging. 
However, we find that \(\phi(\mathbf{x})\), i.e., $\arcsin\sqrt{{\Gamma\sigma_C^2}/({P_T\|\mathbf{h}\|^2})}$, does not make a significant contribution to the overall optimization process, because \(\|\mathbf{h}\|^2\) is not sensitive to the changes in \(\mathbf{x}\). This can be seen from the following expression of \(\|\mathbf{h}\|^2\):\vspace{-0.1cm}
\begin{equation}
	\label{h2expand}\small
	 \|\mathbf{h}(\mathbf{x})\|^2=
	\sum\limits_{k=1}^{N_t}\begin{vmatrix}
	\sum\limits_{i=1}^{L_t}\sigma_ie^{-j\frac{2\pi}{\lambda}\sin\theta_t^ix_k}
	\end{vmatrix}^2,\vspace{-0.1cm}
\end{equation}
%as different values of \( x_k \) induce different phases in the corresponding exponential term in (\ref{h2expand}), and thus the magnitude of the sum of a number of complex numbers with different phases, i.e.,
%\(
%| \sum\nolimits_{i=1}^{L_t} \sigma_ie^{-j\frac{2\pi}{\lambda} \sin(\theta_t^i) x_k} |,
%\)
%tends to stabilize. 
%%When \( L_t \) is sufficiently large, the law of large numbers implies that the magnitude of the sum of a large number of unit-length complex numbers with different phases, i.e.,
%%\(
%%| \sum\nolimits_{i=1}^{L_t} e^{-j\frac{2\pi}{\lambda} \sin(\theta_t^i) x_k} |,
%%\)
%%tends to stabilize. 
%%Although the value of \( \|\mathbf{h}(\mathbf{x})\|^2 \) becomes less sensitive to the variations of \( \mathbf{x} \),
%%Although \(\|\mathbf{h}(\mathbf{x})\|^2\) does not make a significant contribution to problem (\ref{MM2further}), 
%Furthermore, the value of \( \|\mathbf{h}(\mathbf{x})\|^2 \) is composed of the sum of numerous periodic functions with varying periods, resulting in numerous fluctuations, which can easily cause the optimization process to converge to a stationary point with poorer performance. 
which comprises multiple periodic components with distinct phases and frequencies, resulting in numerous oscillations w.r.t. $ \mathbf{x} $. Despite their relatively small amplitudes, $ \|\mathbf{h}(\mathbf{x})\|^2 $ exhibits frequent but low-magnitude fluctuations, which may induce the optimization algorithm to converge to a bad stationary point.
As shown in the toy example depicted in Fig. \ref{MM_illustration}, directly minimizing \( p_2(\mathbf{x}) \) using a gradient descent type algorithm with a random initial point often converges to a bad stationary point, as indicated by the red circle. In contrast, by minimizing \( \upsilon(\mathbf{x}) \) first and using its solution as the initial point for minimizing \( p_2(\mathbf{x}) \), the performance of the final solution can be significantly improved, as shown by the green circle.
\begin{figure}[!t]
	\centering
	\vspace{-0.4cm}
	\includegraphics[width=2.5in]{MM_illustration.eps}\vspace{-0.2cm}
	\caption{Example of \( \upsilon(\mathbf{x}) \), $\phi(\mathbf{x})$ and \( \upsilon(\mathbf{x})+\phi(\mathbf{x}) \) over ${x_1}$.}
	\label{MM_illustration}
	\vspace{-0cm}
\end{figure}

Consequently, we proceed to analyze \(  \upsilon(\mathbf{x})  \), i.e., $\arccos\sqrt{{{p_1(\mathbf{x})}}/
({N_t{\|{\mathbf{h}}\|}^2})}$.
Note that \( \arccos(x) \) is a monotonically decreasing function of \(x \in [0, 1]\), thus minimizing \( \upsilon(\mathbf{x}) \) is equivalent to maximizing \(\bar{p}_2(\mathbf{x}) \triangleq \frac{{p_1(\mathbf{x})}}{\|{\mathbf{h}}\|^2}\).
Since $\frac{p_1(\mathbf{x})}{\|{\mathbf{h}}\|^2}$ is jointly convex in $\{\bm{\psi},\|{\mathbf{h}}\|^2\}$, we can derive the following lower bound with given local point \( \mathbf{x}^i \) in the \( i \)-th iteration of the proposed MM-based algorithm:\vspace{-0.1cm}
%\begin{align}
%	\frac{{\bm{\psi}}^H\bm{\Sigma}\bm{\psi}}{t}\ge&
%	\frac{2\operatorname{Re} \left\{ \bm{\psi}(\mathbf{x}^i)^H \bm{\Sigma} \bm{\psi}(\mathbf{x}) \right\}}{\|{\mathbf{h}(\mathbf{x}^i)}\|^2}-
%	\frac{p_1(\mathbf{x}^i)}{\|{\mathbf{h}(\mathbf{x}^i)}\|^4}\|{\mathbf{h}(\mathbf{x})}\|^2\nonumber
%	\\=&\frac{1}{\|{\mathbf{h}(\mathbf{x}^i)}\|^2}\left(2\bar{p}_1(\mathbf{x})-\frac{p_1(\mathbf{x}^i)}{\|{\mathbf{h}(\mathbf{x}^i)}\|^2}\|{\mathbf{h}(\mathbf{x})}\|^2\right)\nonumber
%	\\
%	\approx&\frac{2}{\|{\mathbf{h}(\mathbf{x}^i)}\|^2}\bar{p}_1(\mathbf{x})-\text{constant},
%\end{align}
\begin{equation}\small
\begin{aligned}
	\label{MM2RPGM}
	\frac{{\bm{\psi}}(\mathbf{x})^H\bm{\Sigma}\bm{\psi}(\mathbf{x})}{\|{\mathbf{h}(\mathbf{x})}\|^2}\ge
	\frac{2\bar{p}_1(\mathbf{x})}{\|{\mathbf{h}(\mathbf{x}^i)}\|^2}-
	\frac{p_1(\mathbf{x}^i)}{\|{\mathbf{h}(\mathbf{x}^i)}\|^4}\|{\mathbf{h}(\mathbf{x})}\|^2.
\end{aligned}\vspace{-0.1cm}
\end{equation}
%where the approximation holds due to the nature of $\|{\mathbf{h}(\mathbf{x})}\|^2$ that has already been clearly explained above.
Building upon the previous analysis on the insensitivity of ${\|\mathbf{h}(\mathbf{x})\|^2}$ w.r.t. $\mathbf{x}$, we first omit the term $\|\mathbf{h}(\mathbf{x})\|^2$ in (\ref{MM2RPGM}),
where Algorithm 3 can be immediately used to obtain $\mathbf{x}^1$ as an initial point for problem (BP2-m). Subsequently, an MM-based RGP algorithm (summarized in Algorithm 4) is proposed to solve problem (BP2-m), where a projection matrix 
\(
\mathbf{P} = \mathbf{I} - \mathbf{M}^T (\mathbf{M}\mathbf{M}^T)^{-1} \mathbf{M}
\) 
(\( \mathbf{M} \) is composed of the row vectors from \( \mathbf{U} \) that satisfy \(\mathbf{U}_k \mathbf{x}^i = (\mathbf{l}_u)_k \) in the $i$-th iteration) is introduced to project the updated gradient descent step back onto the feasible region. Furthermore, we denote the gradient vector of \( {{p}_2(\mathbf{x})} \) w.r.t. \( \mathbf{x} \) by \( \nabla {{p}_2(\mathbf{x})} \in \mathbb{R}^{N_t} \), which can be simply obtained by the chain rule.
%is provided in Appendix F. 
%The overall algorithm for solving (BP2-m) is summarized in Algorithm 4.
With the proposed initialization method, Algorithm 4 only requires a relatively small number of iterations to converge to a good stationary point of problem (BP2-m) \cite{rosen}.

\begin{remark}
In the most general scenario where both the transmit and receive antennas are movable, it can be readily seen that the transmit and receive MAs can be designed separately without loss of optimality and the corresponding problems can be efficiently solved by using the techniques proposed in the above two special cases, respectively. 
\end{remark}
%\begin{algorithm}[t]
%	\caption{Proposed RGPM based algorithm}
%	\renewcommand{\algorithmicrequire}{\textbf{Input:}}
%	\renewcommand{\algorithmicensure}{\textbf{Initialize:}}
%	\begin{algorithmic}[1]
%	\REQUIRE $N_t$, $D_x$, $d$, $\theta$, $\theta_t^1$, $\lambda$, $L_t$, $\bm{\sigma}$, $\epsilon_2$, \( M \).
%	\ENSURE \( i \leftarrow 0 \), obtain \( \mathbf{x}^0 \) via Algorithm 3.
%
%	\WHILE{ \( i < M \)}
%	\STATE \( i \leftarrow i + 1 \).
%	\STATE Calculate \( \mathbf{M} \) and \( \mathbf{P}\).
%	\IF { \( \| \mathbf{P} \nabla p_2 (\mathbf{x}^i) \|< \epsilon_2 \)}
%	\IF { \( \mathbf{M} \) is an empty matrix }
%	\STATE Break.
%	\ELSE
%	\STATE \( \mathbf{u} = -(\mathbf{M}(\mathbf{M})^T)^{-1} \mathbf{M} \nabla p_2 (\mathbf{x}^i) \), \( u_j \leftarrow \min (\mathbf{u}) \);
%	\IF { \( u_j \geq 0 \)}
%	\STATE Break.
%	\ELSE
%	\STATE Update \( \mathbf{M} \) by removing the $j$-th row in \( \mathbf{M} \) and go to step 4.
%	\ENDIF
%	\ENDIF
%	\ELSE
%	\STATE Obain $\alpha^i$ via Armijo step-size rule.	
%	\STATE  \( \mathbf{x}^{i+1}\leftarrow \mathbf{x}^i- \alpha^i\mathbf{P}\nabla p_2 (\mathbf{x}^i)\) ;
%	\ENDIF
%	\ENDWHILE
%	\RETURN \( \mathbf{x} \);
%	\end{algorithmic}
%\end{algorithm}

%\begin{algorithm}[t]
%	\caption{Proposed MM-based RGP algorithm}
%	\renewcommand\baselinestretch{\linspreadalgr}\selectfont
%	\renewcommand{\algorithmicrequire}{\textbf{Input:}}
%	\renewcommand{\algorithmicensure}{\textbf{Initialize:}}
%	\begin{algorithmic}[1]
%		\REQUIRE $N_t$, $D_x$, $d$, $\theta$, $\theta_t^1$, $\lambda$, $L_t$, $\bm{\sigma}$, $\epsilon_2$, \( M \).
%		\ENSURE \( i \leftarrow 0 \), obtain \( \mathbf{x}^1 \) via Algorithm 3.
%		
%		\STATE \textbf{while} \( i < M \) \textbf{do}
%		\STATE \;\;\;\; \( i \leftarrow i + 1 \).
%		\STATE \;\;\;\;Calculate \( \mathbf{M} \) and \( \mathbf{P}\).
%		\STATE \;\;\;\;\textbf{if} \( \| \mathbf{P} \nabla p_2 (\mathbf{x}^i) \|< \epsilon_2 \) \textbf{then}
%		\STATE \;\;\;\;\;\;\;\;\textbf{if} \( \mathbf{M} \) is an empty matrix \textbf{then} \textbf{break}.
%		\STATE \;\;\;\;\;\;\;\;\textbf{else} \( \mathbf{u} = -(\mathbf{M}\mathbf{M}^T)^{-1} \mathbf{M} \nabla p_2 (\mathbf{x}^i) \), \( u_j \leftarrow \min (\mathbf{u}) \).
%		\STATE \;\;\;\;\;\;\;\;\;\;\;\;\textbf{if} \( u_j \geq 0 \) \textbf{then} \textbf{break}.
%		\STATE \;\;\;\;\;\;\;\;\;\;\;\;\textbf{else} remove \( \mathbf{M}_j \) and go to step 3. \textbf{end if}
%		\STATE \;\;\;\;\;\;\;\;\textbf{end if}
%		\STATE \;\;\;\;\textbf{else} obain $\alpha^i$ via Armijo step-size rule.	
%		\STATE  \;\;\;\;\;\;\;\;\;\;\;\;\( \mathbf{x}^{i+1}\leftarrow \mathbf{x}^i- \alpha^i\mathbf{P}\nabla p_2 (\mathbf{x}^i)\).
%		\STATE \;\;\;\;\textbf{end if}
%		\STATE \textbf{end while}
%		\RETURN \( \mathbf{x}^{i+1} \);
%	\end{algorithmic}\vspace{-0.2cm}
%\end{algorithm}




\vspace{-0.2cm}
\subsection{CRB Performance Analysis}
In this subsection, we analyze the impacts of movable transmit antennas on the sensing performance under varying user communication SNR thresholds.
We can see that the constraints of subproblems (SP1) and (SP2), i.e., (\ref{p6b}) and (\ref{p7b}), are both related to the user's communication SNR threshold, $\Gamma$. 
%Now, we take a closer look at subproblems (SP1) and (SP2). The constraint \(|{{\mathbf{h}^H}{\mathbf{a}}}|^2 > \frac{N_t}{P_T}\Gamma\sigma_C^2\) belongs to subproblem (SP1) (derived by substituting (\ref{q11a}) into the original problem (BP)), while \(|{{\mathbf{h}^H}{\mathbf{a}}}|^2 \le \frac{N_t}{P_T}\Gamma\sigma_C^2\) corresponds to subproblem (SP2) (derived by (\ref{q11b})). We can see that both constraints are related to the user's communication SNR threshold $\Gamma$. 


Consequently, we can regard subproblem (SP1) as a sensing performance optimization problem under low communication SNR threshold. 
%From the optimal beamforming solution in (\ref{q11a}), i.e., \(\mathbf{w}_\text{opt} = \sqrt{P_T}\frac{\mathbf{a}}{\|\mathbf{a}\|}\), and the objective function of the original maximization problem (BP), i.e., \(|{{\mathbf{a}^H}{\mathbf{w}}}|^2\), we can see that the solution of subproblem (SP1) corresponds to the minimum CRB, which can be obtained by (\ref{CRB_expression}) as:
By substituting the optimal beamforming solution \(\mathbf{w}_\text{opt} = \sqrt{P_T}\frac{\mathbf{a}}{\|\mathbf{a}\|}\) into the CRB expression, i.e., (\ref{CRB_expression}), we can obtain the global minimum of the CRB in terms of \( \mathbf{w} \) and \( \mathbf{x} \) as\vspace{-0.1cm}
\begin{equation}
	\label{CRB_expression_min}\small
	\begin{aligned}
		\text{CRB}(\theta)_\text{min}=
		\frac{\sigma_R^2/
			(2\begin{vmatrix}
				\alpha
			\end{vmatrix}^2L{N_tP_T})}
		{
			(\frac{2\pi}{\lambda}\cos\theta)^2
			\big(\sum\limits_{i=1}^{N_r}y_i^2
			-\frac{1}{N_r}(\sum\limits_{i=1}^{N_r}y_i)^2\big)
		}.
	\end{aligned}\vspace{-0.1cm}
\end{equation}
However, due to the transmit power budget constraint on the beamforming vector, i.e., $\|\mathbf{w}\|^2\le{P_T}$, this minimum value cannot be sustained as the user's communication SNR threshold $\Gamma$ increases.
Specifically, as $\Gamma$ increases, the constraint set of (\ref{p5b}) in problem (BP) shrinks, which will prevent the beamforming vector from remaining at $\sqrt{P_T}\frac{\mathbf{a}}{\|\mathbf{a}\|}$ and finally leads to sensing performance degradation. 
In this case, by deploying movable transmit antenna array, an additional degree of freedom is introduced by allowing the CRB to remain at its lowest level (\ref{CRB_expression_min}) until the user's SNR threshold reaches \(\Gamma_0=\frac{|{{\mathbf{h}(\mathbf{x}^{\star})^H}{\mathbf{a}(\mathbf{x}^{\star})}}|^2}{N_t\sigma_C^2/P_T} \) (as indicated by either constraint (\ref{p6b}) or (\ref{p7b})), where $\mathbf{x}^{\star}$ is the optimal transmit APV obtained by Algorithm 1 or Algorithm 3.
To be specific, the movable transmit antenna array can increase $\Gamma$ by \(\Delta_{\Gamma}=20\lg(\frac{|{{\mathbf{h}(\mathbf{x}^{\star})^H}{\mathbf{a}(\mathbf{x}^{\star})}}|}
{|{{\mathbf{h}^H}{\mathbf{a}}}|_\text{ULA}} )\) dB while maintaining the same sensing performance.


In contrast, subproblem (SP2) addresses the high communication SNR scenario. If no feasible solution exists for subproblem (SP1), i.e., $\Gamma > \Gamma_0$, the solution of subproblem (SP2) results in a higher CRB than the minimum value specified in (\ref{CRB_expression_min}). Therefore, we can intuitively conclude that when the user's communication SNR threshold exceeds $\Gamma_0$, the sensing performance will inevitably degrade.

The above analysis embodies the trade-off between sensing and communication performance inherent in ISAC systems, and it shows that movable transmit antenna arrays can significantly enhance both performance by introducing an additional degree of freedom.
\vspace{-0.2cm}
\subsection{Computational Complexity Analysis}
In this subsection, we analyze the computational complexity of the proposed Algorithms 1-4, where we focus exclusively on the number of multiplication operations.
First, we consider the worst-case complexity of  Algorithms 1 and 2 (i.e., the BT-BFS and BT-DFS algorithms).
Since the complexity of calculating the value of $D_\text{min}$ in (\ref{Dmin}) or (\ref{Dmin_2}) is \(\mathcal{O}(1)\), the worst-case complexity of the BT-BFS algorithm is \(\mathcal{O}(\sum\nolimits_{c=1}^{N_t-1}{\binom{N_t}{c}
})=\mathcal{O}(2^{N_t})\).
Following a similar analysis, the worst-case complexity of the BT-DFS algorithm is \(\mathcal{O}( N_t)\).
Then, for Algorithm 3, its computational complexity is dominated by solving the QP problem (BP1-m) which is $\mathcal{O}(N_t^{1.5} \ln(1/\beta))$ with $\beta$ denoting the accuracy of the interior-point method \cite{book3}. Let $\gamma_r$ denote the maximum iteration number, the total complexity of Algorithm 3 can be expressed as $\mathcal{O}(N_t^{1.5} \ln(1/\beta)\gamma_r)$. 
For Algorithm 4, the complexity of calculating $\nabla_{\mathbf{x}}{p_2{(\mathbf{x})}}$ is $\mathcal{O}(N_tL_t^2+2L_t^2+3N_tL_t)$, thus the overall complexity of Algorithm 4 is $\mathcal{O}(M(N_tL_t^2+2L_t^2+3N_tL_t))$.





\vspace{-0.2cm}
\section{Numerical Results}
This section presents numerical results to evaluate the effectiveness of the proposed algorithms for optimizing the sensing performance of the MA-enabled ISAC system while ensuring the communication quality. 
Without loss of generality, we consider a MISO ISAC BS that is equipped with \( N_t = 18 \) and \( N_r = 20 \) MAs at its transmitter and receiver, respectively. The power budget is \( P_T = 20 \) dBm, the noise power is set as \( \sigma_C^2 = \sigma_R^2 = 0 \) dBm, and the frame length is set as \( L = 30 \). The apertures of both transmit and receive antenna arrays are set to be \( D_x = D_y = 13.55 \lambda \) unless otherwise specified. 
The geometry channel model is considered \cite{10243545}, where the number of transmit paths is set to $L_t = 18$. The path response vector is assumed to follow Rician fading with ${\sigma}_1 \sim \mathcal{CN}(0, \kappa / (\kappa + 1))$ and $\sigma_p \sim \mathcal{CN}(0, 1 / ((\kappa + 1)(L_t - 1)))$ for $p = 2, 3, \dots, L_t$, where $\kappa = 3$ denotes the ratio of the average power for LoS paths to that for NLoS paths. The azimuth AoDs are assumed to be i.i.d. variables that are uniformly distributed over $[-\pi/2, \pi/2]$. The minimum distance between the MAs is set as $d = \lambda / 2$.
%We set convergence thresholds for the relative increment of the objective value as $\epsilon_1 = \epsilon_2 = 10^{-3}$ in Sections IV-C.
%The target angle is assumed to be $\theta = 0$. 
Other parameters are set as follows unless otherwise specified: $\epsilon_1 = \epsilon_2 = 10^{-3}$ and $\theta = 0 ^\circ$.
The following benchmark schemes are considered in our simulations: 1) ULA with half-wavelength spacing (ULAH); 2) ULA with full aperture (ULAF), i.e., the inner-antenna spacings for the transmit and receive antennas are \( D_x / (N_t-1) \) and \( D_y / (N_r-1) \), respectively;
3) a scheme based on the successive convex approximation (SCA) technique for solving problems (AP-m), (BP1) and (BP2);
4) a scheme based on RGP algorithm with random initialization for solving problems (BP1) and (BP2).

\begin{figure}[t]
	\centering
	\includegraphics[width=2.5in]{Rx_CRB_SNR_CRB_Dx_CRB_Nr.eps}\vspace{-0.4cm}
	\caption{CRB versus the required communication SNR threshold $\Gamma$, antenna aperture $D_y$ and antenna number $N_r$ in the case of receive MAs.}
	\label{Rx_CRB_SNR}
	\vspace{-0cm}
\end{figure}


\begin{figure}[t]
	\centering
	\includegraphics[width=2.7in]{LOS_NLOS_CRB_SNR.eps}\vspace{-0.4cm}
	\caption{CRB versus the required communication SNR threshold $\Gamma$ in the case of transmit MAs.}
	\label{LOS_CRB_SNR}
	\vspace{-0.4cm}
\end{figure}



\begin{figure}[t]
	\centering
	\includegraphics[width=3.0in]{LOS_NLOS_CRB_Nt_Dx.eps}\vspace{-0.4cm}
	\caption{CRB versus antenna number $N_t$ and antenna aperture $D_x$ in the case of transmit MAs.}
	\label{LOS&NLOS_CRB_Nt_Dx}
	\vspace{-0cm}
\end{figure}


%\begin{figure}[t]
%	\centering
%	\includegraphics[width=3.0in]{LOS_CRB_SNRto31_noGA}
%	\caption{CRB versus the required communication SNR threshold $\Gamma$ in the LoS channel scenario (movable transmit antenna case).}
%	\label{LOS_CRB_SNR}
%	\vspace{-0.3cm}
%\end{figure}
%
%
%
%\begin{figure}[t]
%	\centering
%	\includegraphics[width=3.0in]{NLOS_CRB_SNR_1}
%	\caption{CRB versus the required communication SNR threshold $\Gamma$ in the NLoS channel scenario (movable transmit antenna case).}
%	\label{NLOS_CRB_SNR}
%	\vspace{-0.3cm}
%\end{figure}




\begin{figure}[t]
	\centering
	\includegraphics[width=2.7in]{LOS_NLOS_beampattern_magnify.eps}\vspace{-0.4cm}
	\caption{Comparison of beampatterns with different antennas' positions.}
	\label{LOS_beampattern}
	\vspace{-0cm}
\end{figure}





%\begin{figure}[t]
%	\centering
%	\includegraphics[width=3.0in]{LOS_beampattern_addDFS}
%	\caption{Comparison of beampatterns with different antennas' positions in the LoS channel scenario.}
%	\label{LOS_beampattern}
%	\vspace{-0.3cm}
%\end{figure}
%
%
%\begin{figure}[t]
%	\centering
%	\includegraphics[width=3.0in]{beampattern_NLOS_addRGPMrandomInit}
%	\caption{Comparison of beampatterns with different antennas' positions in the NLoS channel scenario.}
%	\label{NLOS_beampattern}
%	\vspace{-0.3cm}
%\end{figure}


%\begin{figure}[t]
%	\centering
%	\includegraphics[width=3.0in]{together_los_nlos_sca}
%	\caption{CRB versus the required communication SNR threshold $\Gamma$ when both transmit and receive antenna movable.}
%	\label{CRB_SNR_TxRx}
%	\vspace{-0.3cm}
%\end{figure}



%
%\begin{figure}[t]
%	\centering
%	\includegraphics[width=3.5in]{LOS_CRB_SNR_TxRx}
%	\caption{CRB versus the required communication SNR in the case of LoS channel when both transmit and receive antenna movable.}
%	\label{LOS_CRB_SNR_TxRx}
%\end{figure}
%
%\begin{figure}[t]
%	\centering
%	\includegraphics[width=3.5in]{NLOS_CRB_SNR_TxRx}
%	\caption{CRB versus the required communication SNR in the case of NLoS channel when both transmit and receive antenna movable.}
%	\label{NLOS_CRB_SNR_TxRx}
%\end{figure}
%
%
%\begin{figure}[t]
%	\centering
%	\includegraphics[width=3.8in]{LOS_N}
%	\caption{CRB versus the number of MAs in the case of LoS channel when both transmit and receive antenna movable.}
%	\label{LOS_N}
%\end{figure}
%
%\begin{figure}[t]
%	\centering
%	\includegraphics[width=3.8in]{NLOS_N}
%	\caption{CRB versus the number of MAs in the case of NLoS channel when both transmit and receive antenna movable.}
%	\label{NLOS_N}
%\end{figure}


%\begin{figure}[t]
%	\centering
%	\includegraphics[width=3.0in]{untitled}
%	\caption{CRB versus the required communication SNR threshold $\Gamma$ when both transmit and receive antenna movable.}
%	\label{CRB_SNR_TxRxuntitled}
%	\vspace{-0.3cm}
%\end{figure}



\vspace{-0.2cm}
\subsection{Receive MA Case}
Fig. \ref{Rx_CRB_SNR} demonstrates the sensing performance (in terms of root-CRB) achieved by movable receive antennas under various user communication SNR thresholds, receive antenna apertures and numbers.
As shown in Fig. \ref{Rx_CRB_SNR} (a), the root-CRB performance achieved by the optimal receive MA positions given in (\ref{q10}) is significantly lower than those of ULAH and ULAF with the same antenna aperture.
In the meantime, from Fig. \ref{Rx_CRB_SNR} (b), we can see that increasing the antenna aperture from \(D_x = 10\lambda\) to \(D_x = 40\lambda\) is able to reduce the root-CRB consistently, which validates the analysis in Section \uppercase\expandafter{\romannumeral3}.
%Specifically, at SNR = 20 dB, the proposed scheme demonstrates a 4.33 dB and 1.25 dB CRB gain over the ULAH and ULAF scheme, respectively, when \(D_x = 13.55\lambda\); when \(D_x = 27.1\lambda\), this performance gain increases to 11.93 dB and 2.83 dB, respectively.
Furthermore, as $D_x$ increases, the performance of the proposed scheme will gradually approach the lower-bound root-CRB given in (\ref{approx1}), and a 4.77 dB CRB gain can be achieved over the ULAF scheme.
In Fig. \ref{Rx_CRB_SNR} (c), it is observed that under a given antenna aperture $ D_y = 13.55\lambda $, increasing the number of receive antennas improves the sensing performance, but the performance gain cannot grow unboundedly. This is because the value of $ N_t$ is limited by $ D_y / d + 1$ with fixed $D_y$, corresponding to the case that all antennas are arranged in a ULA with a spacing of $ \lambda/2 $.
\vspace{-0.4cm}
\subsection{Transmit MA Case}
Next, we evaluate the effectiveness of our proposed algorithms for movable transmit antennas, as illustrated in Fig. \ref{LOS_CRB_SNR}.
From Fig. \ref{LOS_CRB_SNR} (a), we can see that the proposed BT-BFS algorithm achieves the minimum CRB among the considered schemes across all user communication SNR thresholds. 
Besides, the proposed BT-BFS algorithm is able to maintain the minimum CRB level of target angle estimation specified in (\ref{CRB_expression_min}) until the SNR threshold reached about $\Gamma_0 = 27$ dB, which is $\Delta_{\Gamma}=12$ dB larger than those of the traditional ULAs (about 15 dB). Additionally, the proposed low-complexity BT-DFS algorithm also significantly outperforms the traditional ULAs as well as the SCA scheme. %providing a 1.16 dB CRB gain over the ULAH scheme at $\Gamma = 27$ dB.
Under the NLoS channel scenario (Fig. \ref{LOS_CRB_SNR} (b)), the proposed MM-based RGP algorithm maintains the CRB at the minimum specified in (\ref{CRB_expression_min}) across an SNR range of \(\Delta_{\Gamma} = 14\) dB, which is also larger than those of the benchmark schemes.
%and achieves a 1.43 dB CRB gain over traditional ULAs at a user SNR threshold of \(\Gamma = 30\) dB as demonstrated in Fig. \ref{NLOS_CRB_SNR}. 
Furthermore, we can see that initializing the RGP by the solution derived from the MM algorithm (as in Algorithm 3) yields superior performance as compared to random initialization, which validates the superiority of our proposed initialization method.

Next, we show in Fig. \ref{LOS&NLOS_CRB_Nt_Dx} the sensing performance achieved by the proposed algorithms under various transmit antenna numbers and apertures. 
From Fig. \ref{LOS&NLOS_CRB_Nt_Dx} (a) and Fig. \ref{LOS&NLOS_CRB_Nt_Dx} (c), we can observe that increasing the number of transmit antennas, i.e., \(N_t\), enhances the sensing performance (measured by root-CRB) of all schemes. 
Fig. \ref{LOS&NLOS_CRB_Nt_Dx} (b) and Fig. \ref{LOS&NLOS_CRB_Nt_Dx} (d) show that increasing the transmit antenna aperture \(D_x\) only improves the sensing performance of the MA-enabled scheme, and the root-CRB performance eventually saturates with the increasing of $D_x$, which is consistent with our analysis in Section \uppercase\expandafter{\romannumeral4}.  Moreover, we can see that our proposed algorithms outperform all benchmark schemes under different settings.

%\subsection{General Case}
Finally, to gain more insights, we illustrate in Fig. \ref{LOS_beampattern} the beampatterns of different schemes where the required SNR level is set to be $\Gamma = 30$ dB and the azimuth AoD of the LoS path is set to $\theta_t^1 = {\pi}/{3}$.
Under the LoS channel scenario, as illustrated in Fig. \ref{LOS_beampattern} (a), all four beamformers direct their mainlobes towards $0^\circ$ (the target direction), and allocate a large amount of  energy at $60^\circ$ (the communication user's direction). 
The proposed BT-BFS algorithm achieves the highest peak power and the narrowest mainlobe width towards the target angle, followed by the BT-DFS algorithm. 
Both proposed algorithms demonstrate substantial improvements over the traditional ULAs.  %with BT-BFS additionally attaining the highest beam energy at the user communication direction.
Under the NLoS scenario, we observe that although the considered four schemes still direct their mainlobes towards $0^\circ$, the energy allocated to $60^\circ$ is reduced as compared to the LoS case due to dispersion across other NLoS paths (Fig. \ref{LOS_beampattern} (b)). The proposed MM-based RGP algorithm exhibits the highest peak power and the narrowest mainlobe width at the target direction, followed by the SCA algorithm. Similar to the LoS case, both algorithms significantly outperform the traditional ULAs. 
%with the MM-based RGPM algorithm also achieving the highest beam energy in the user communication direction.


%Finally, Fig. \ref{CRB_SNR_TxRx} illustrates the relationship between root-CRB performance and user communication SNR threshold where both transmit and receive antennas are movable.
%Under the LoS channel scenario, the optimal scheme employs the BT-BFS algorithm for transmit movable antenna position optimization, while under the NLoS channel scenario, the proposed scheme utilizes the MM-based RGPM algorithm.
%Under both scenarios, the optimal solution in (\ref{q10}) is utilized for receive antenna position optimization.  
%As can be observed from Fig. \ref{CRB_SNR_TxRx}, MA arrays significantly enhance the target CRB compared to the considered benchmarks at the same user communication SNR threshold. 


%Specifically, at a user threshold of $\Gamma = 30$ dB, the optimal scheme achieves CRB gains of 7.25 dB and 3.88 dB over the ULAH and ULAF schemes under LoS channels, respectively, and 5.42 dB and 2.78 dB under NLoS channels, respectively.

\vspace{-0.2cm}
\section{Conclusion}\vspace{-0.1cm}
This paper presented an MA-enabled ISAC system for future wireless networks, and provided optimal solutions and efficient algorithms for joint antenna position and beamforming optimization.
Specifically, for the case with receive MAs, we derived an optimal antenna position solution, which is able to achieve a CRB gain of at most 4.77 dB over the traditional FPAs. 
While for the case with transmit MAs, we proposed the BT-BFS and BT-DFS algorithms to obtain global optimal and local optimal solutions in the LoS channel scenario, respectively. 
In the NLoS scenario, we also proposed an MM-based RGP algorithm (together with an efficient initialization method) to obtain stationary solutions of the considered problem. 
Numerical results demonstrate the superiority of transmit/receive MAs in improving the ISAC performance over traditional FPAs, and the effectiveness of the proposed algorithms.


\vspace{-0.2cm}
{\appendices
	\vspace{-0.2cm}
\section{Proof of Lemma 1}\vspace{-0.1cm}
To prove this lemma, we first simplify $f(\mathbf{y})$ and express it in a quadratic form given by $f(\mathbf{y})=\mathbf{y}^T\mathbf{Q}\mathbf{y}$,
where $\mathbf{Q}=\mathbf{I}_{N_r}-\frac{1}{N_r}\mathbf{J}_{N_r}$.
Then, for any $a\in\mathbb{R}$, we have
$		f(\mathbf{y}+a)
=\mathbf{y}^T\mathbf{Q}\mathbf{y}+a\mathbf{y}^T\mathbf{Q}\mathbf{1}
+a\mathbf{1}^T\mathbf{Q}\mathbf{y}+a^2\mathbf{1}^T\mathbf{Q}\mathbf{1}
{=}f(\mathbf{y}),$
%\begin{equation}
%	\begin{aligned}
%		f(\mathbf{y}+a)
%		&=\mathbf{y}^T\mathbf{Q}\mathbf{y}+a\mathbf{y}^T\mathbf{Q}\mathbf{1}
%		+a\mathbf{1}^T\mathbf{Q}\mathbf{y}+a^2\mathbf{1}^T\mathbf{Q}\mathbf{1}\\
%		&\overset{(b)}{=}f(\mathbf{y}),
%	\end{aligned}
%\end{equation}
where the second equality holds because $\mathbf{1}^T\mathbf{Q}=\mathbf{0}^T$ and $\mathbf{1}^T\mathbf{Q}\mathbf{1}=0$. This completes the proof. 



\vspace{-0.3cm}
\section{Proof of Lemma 3}\vspace{-0.1cm}
First, we analyze the property of the local maxima of $f(\mathbf{y})$ by examining its second-order derivatives, which can be obtained as
$	\frac{\partial^2{f(\mathbf{y})}}{\partial{y_i}^2}=2-\frac{2}{N_r},\;
\frac{\partial^2{f(\mathbf{y})}}{\partial{y_i}\partial{y_j}}=-\frac{2}{N_r}(i\neq{j})$.
%\begin{equation}
%	\label{AC2}
%	\begin{aligned}
%		\frac{\partial^2{f(\mathbf{y})}}{\partial{y_i}^2}=2-\frac{2}{N_r},\;
%		\frac{\partial^2{f(\mathbf{y})}}{\partial{y_i}\partial{y_j}}=-\frac{2}{N_r}(i\neq{j}).
%	\end{aligned}
%\end{equation}
It can be readily seen that the Hessian matrix of $f(\mathbf{y})$ 
%can be derived as
%\begin{equation}
%	\begin{aligned}
%		\nabla^2f(\mathbf{y})=\left[\begin{array} {cccc}
%			2-\frac{2}{N_r} & -\frac{2}{N_r} & \cdots & -\frac{2}{N_r}\\
%			-\frac{2}{N_r} & 2-\frac{2}{N_r} & \cdots & -\frac{2}{N_r}\\
%			\vdots & \vdots & \ddots & \vdots\\
%			-\frac{2}{N_r} & -\frac{2}{N_r} & \cdots & 2-\frac{2}{N_r} 
%		\end{array}\right]_{N_r\times{N_r}},
%	\end{aligned}
%\end{equation}
%which 
is a positive definite matrix, and thus 
$f(\mathbf{y})$ is a convex continuous function with its maximum value always achieved at the boundary points. 
This implies that when 
%$y_1,\cdots,y_{i-1},y_{i+1},\cdots,y_{N_r}$ 
$\mathbf{y} \backslash y_i $
are determined, the maximum value of $f(\mathbf{y})$ must be attained at the boundary of the feasible region of \( y_i \), i.e., $y_i=y_{i-1}+d\;\;\text{or}\;\;y_i=y_{i+1}-d.$

Next, we prove that compared to $y_i=y_{i+1}-d$, $y_i=y_{i-1}+d$ is better in terms of maximizing \( f(\mathbf{y}) \) when \( i\le\left\lfloor\frac{{N_r}}{2}\right\rfloor \).
Due to the translational invariance property of \( f(\mathbf{y}) \) as proved in Lemma 1, we can assume \( y_1 = 0 \) without loss of generality. Now, let
$\hat{y}_k=y_{k-1}+d$ and $\tilde{y}_k=y_{k+1}-d$, \( 2\le{k}\le\left\lfloor\frac{{N_r}}{2}\right\rfloor \), which satisfy $\hat{y}_k\neq{\tilde{y}_k}$.\footnote{If $ \hat{y}_k = \tilde{y}_k $, then $ y_{k+1} = y_{k-1} + 2d $ holds, which implies that $y_k$ is a constant.} 
By substituting  $\hat{\mathbf{y}} \triangleq [y_1,\cdots,y_{k-1},\hat{y}_k,y_{k+1},\cdots,y_{N_r}]^T$ and $\tilde{\mathbf{y}} \triangleq[y_1,\cdots,y_{k-1},\tilde{y}_k,y_{k+1},\cdots,y_{N_r}]^T$ into $f(\mathbf{y})$, we obtain
$		f(\hat{\mathbf{y}})=
(\sum\nolimits_{\substack{{i=1},i\neq{k}}}^{N_r}{y_i^2}+\hat{y}_k^2)
-\frac{1}{N_r}(\sum\nolimits_{\substack{{i=1},  i\neq{k}}}^{N_r}{y_i}+\hat{y}_k)^2$ and 
$f(\tilde{\mathbf{y}})=
(\sum\nolimits_{\substack{{i=1},i\neq{k}}}^{N_r}{y_i^2}+\tilde{y}_k^2)
-\frac{1}{N_r}(\sum\nolimits_{\substack{{i=1},i\neq{k}}}^{N_r}{y_i}+\tilde{y}_k)^2.$
%\begin{equation}
%	\begin{aligned}
%		f_{\hat{y}_k}(\mathbf{y})=
%		\left(\sum\limits_{\substack{{i=1},i\neq{k}}}^{N_r}\!\!\!{y_i^2}+\hat{y}_k^2\right)
%		-\frac{1}{N_r}\left(\sum\limits_{\substack{{i=1},  i\neq{k}}}^{N_r}\!\!\!{y_i}+\hat{y}_k\right)^2,\\
%		f_{\tilde{y}_k}(\mathbf{y})=
%		\left(\sum\limits_{\substack{{i=1},i\neq{k}}}^{N_r}\!\!\!{y_i^2}+\tilde{y}_k^2\right)
%		-\frac{1}{N_r}\left(\sum\limits_{\substack{{i=1},i\neq{k}}}^{N_r}\!\!\!{y_i}+\tilde{y}_k\right)^2.
%	\end{aligned}
%\end{equation}
Hence, to establish Lemma 3,  we need to prove that $f(\hat{\mathbf{y}})>f(\tilde{\mathbf{y}})$ holds for  \( 2\le{k}\le\left\lfloor\frac{{N_r}}{2}\right\rfloor \).
By subtracting $f(\hat{\mathbf{y}})$ from $f(\tilde{\mathbf{y}})$, we can obtain
$f(\tilde{\mathbf{y}})-f(\hat{\mathbf{y}})=
\frac{y_{k-1}-{y}_{k+1}+2d}{N_r}
[(N_r-1)(y_{k-1}+{y}_{k+1})-2\sum\nolimits_{\substack{{i=1},i\neq{k}}}^{N_r}y_i].$
%	\begin{align}
%		&f_{\tilde{y}_k}(\mathbf{y})-f_{\hat{y}_k}(\mathbf{y})\\
%		&=
%		\frac{y_{k-1}-{y}_{k+1}+2d}{N_r}
%		\bigg[\left(N_r-1\right)\left(y_{k-1}+{y}_{k+1}\right)-2\sum\limits_{\substack{{i=1}\\i\neq{k}}}^{N_r}y_i\bigg].\nonumber
%	\end{align}
Since ${y}_{k+1}\ge{y_{k}+d}$, ${y}_{k}\ge{y_{k-1}+d}$ and $\hat{y}_k\neq{\tilde{y}_k}$, we have $y_{k-1}-{y}_{k+1}+2d<0$. 
Therefore, proving $f(\hat{\mathbf{y}})-f(\tilde{\mathbf{y}})>0$ is equivalent to proving $\left(N_r-1\right)\left(y_{k-1}+{y}_{k+1}\right)-2\sum\nolimits_{i=1,i\neq{k}}^{N_r}y_i<0$.
To prove the latter, we resort to the following result:\vspace{-0.2cm}
\begin{equation}
	\label{L3}\small
	\begin{aligned}
		\sum\limits_{{{i=1},i\neq{k}}}^{N_r}y_i
		\ge\sum\limits_{i=1}^{k-1}(i-1)d+\sum\limits_{i=k+1}^{N_r}(i-1)d
		\overset{(b)}{>}\frac{(N_r-1)^2}{2}d,
	\end{aligned}\vspace{-0.2cm}
\end{equation}
where the inequality $(b)$ holds due to the fact that $k\le\lfloor\frac{N_r}{2}\rfloor\le\frac{N_r}{2}<\frac{N_r+1}{2}$.
Since $y_{k-1}+y_{k+1}\le(k-2)d+kd<(N_r-1)d$ holds, by combining it with (\ref{L3}), we can obtain $\left(N_r-1\right)\left(y_{k-1}+{y}_{k+1}\right)-2\sum\nolimits_{i=1,i\neq{k}}^{N_r}y_i
<0$,
%\begin{equation}
%	\begin{aligned}
%&\left(N_r-1\right)\left(y_{k-1}+{y}_{k+1}\right)-2\sum\limits_{i=1,i\neq{k}}^{N_r}y_i
%<0,
%	\end{aligned}
%\end{equation}
which directly leads to $f(\hat{\mathbf{y}})>f(\tilde{\mathbf{y}})$. This thus completes the proof. 


%\section{Proof of Theorem 1}
%From Lemma 3, the first $\lfloor\frac{N_r}{2}\rfloor$ antennas must form a ULA with spacing \( d \) starting from zero to $\left(\lfloor\frac{N_r}{2}\rfloor-1\right)d$. Similarly, based on the symmetry in Lemma 2, the last $\lfloor\frac{N_r}{2}\rfloor$ antennas must form the same ULA starting from \( D \) to $D-\left(\lfloor\frac{N_r}{2}\rfloor-1\right)d$.

%In summary, when \( N_r \) is even, i.e., $\lfloor\frac{N_r}{2}\rfloor=\frac{N_r}{2}$, $\mathbf{y}_{opt}$ satisfies $[0,d,\cdots,(\frac{N_r-2}{2})d,D-(\frac{N_r-2}{2})d,D-(\frac{N_r-4}{2})d,\cdots,D]^T$; when \( N_r \) is odd, $\mathbf{y}_{opt}$ satisfies $[0,\cdots,(\frac{N_r-3}{2})d,(\frac{N_r-1}{2})d\;or\;D-(\frac{N_r-1}{2})d,D-(\frac{N_r-3}{2})d,\cdots,D]^T$. Thus, Theorem 1 is proven.
\vspace{-0.1cm}
\section{Proof of Lemma 4}\vspace{-0.1cm}
First, we show that \( \bm{\beta^*} \) is a local maximum of \( E(\bm{\beta}) \) if and only if \( \bm{\beta^*} \) is a local maximum of \( E^2(\bm{\beta}) \).
Given that \( E(\bm{\beta}) \ge 0 \), if \( \bm{\beta^*} \) is a local maximum of \( E(\bm{\beta}) \), then there must exist a neighborhood \( \mathcal{N} \) of \( \bm{\beta^*} \) such that \( E(\bm{\beta^*}) \ge E(\bm{\beta}) \) for \( \forall\bm{\beta} \in \mathcal{N} \), which is equivalent to \( E^2(\bm{\beta^*}) \ge E^2(\bm{\beta}) \) and thus \( \bm{\beta^*} \) is a local maximum of \( E^2(\bm{\beta}) \), and vice versa. Consequently, we only need to verify that \( ( \sum\nolimits_{i=1}^{N} \rho_i )^2 \) is the unique local maximum value of \( E^2(\bm{\beta}) \).

Then, we prove the existence of the local maximum value $(\sum\nolimits_{i=1}^{N}\rho_i)^2$ of \( E^2(\bm{\beta}) \) and that the corresponding solution satisfies condition (\ref{Econ}), where we only need to verify that \(\nabla E^2(\bm{\beta}) =0\) and \(\nabla^2 E^2(\bm{\beta}) \prec 0\) when condition (\ref{Econ}) is satisfied.
% Using Euler's formula, we rewrite $E(\bm{\beta})$ as 
% \begin{equation}
% 	\label{L4_2}
% 	\begin{aligned}
% 		E(\bm{\beta})=
% 		\sqrt{\left(\sum\limits_{i=1}^{N}\rho_i{\cos{\beta_i}}\right)^2+
% 			\left(\sum\limits_{i=1}^{N}\rho_i{\sin{\beta_i}}\right)^2}.
% 	\end{aligned}
% \end{equation}
Since \( E^2(\bm{\beta}) \) is twice continuously differentiable, we can simply verify that the each entry of the gradient of $E^2(\bm{\beta})$, i.e., \vspace{-0.2cm}
\begin{equation}
	\label{Egradient}\small
	\begin{aligned}
		\frac{\partial}{\partial{\beta_i}}{E^2(\bm{\beta})}=-2\sum\limits_{k=1}^{N}
		\rho_k\rho_i\sin({{\beta}_i-{\beta}_k}),
	\end{aligned}\vspace{-0.1cm}
\end{equation}
is zero when (\ref{Econ}) is satisfied. 
The second-order derivatives of $E^2(\bm{\beta})$ can be similarly determined as 
$		\frac{\partial^2}{\partial{\beta_i}^2}{E^2(\bm{\beta})}=-2\sum\nolimits_{k=1,k\neq{i}}^{N}\rho_k\rho_i\cos({{\beta}_i-{\beta}_k})$ and $
\frac{\partial^2}{\partial{\beta_i}\partial{\beta_j}}{E^2(\bm{\beta})}=2\rho_j\rho_i\cos({{\beta}_i-{\beta}_j}),(i\neq{j})$.
%\begin{equation}
%	\label{EHessian_derivatives}
%	\begin{aligned}
%		\frac{\partial^2}{\partial{\beta_i}^2}{E^2(\bm{\beta})}=-2\sum\limits_{k=1,k\neq{i}}^{N}\rho_k\rho_i\cos({{\beta}_i-{\beta}_k}),\\
%		\frac{\partial^2}{\partial{\beta_i}\partial{\beta_j}}{E^2(\bm{\beta})}=2\rho_j\rho_i\cos({{\beta}_i-{\beta}_j})(i\neq{j}).
%	\end{aligned}
%\end{equation} 
We can also obtain that when (\ref{Econ}) is satisfied, the following inequality holds:
$\mathbf{x}^T \nabla^2 \left(E^2(\bm{\beta})\right) \mathbf{x} = -2 \sum_{i\neq{j}}  \rho_i \rho_j \cos(\beta_i - \beta_j) (x_i - x_j)^2 < 0,$ $\forall\mathbf{x} \in \mathbb{R}^N$
%\begin{equation}
%	\label{EHessian_semi_neg}
%	\begin{aligned}
%\mathbf{x}^T \nabla^2 \left(E^2(\bm{\beta})\right) \mathbf{x} = -2 \sum_{i\neq{j}}  \rho_i \rho_j \cos(\beta_i - \beta_j) (x_i - x_j)^2 < 0, 
%	\end{aligned}
%\end{equation}
if $\mathbf{x} \neq \mathbf{0} $.
This implies that the Hessian matrix \(\nabla^2 \left(E^2(\bm{\beta})\right)\) is negative definite. 
Thus, by substituting (\ref{Econ}) into $E^2(\bm{\beta})$, the local maximum value $(\sum\nolimits_{i=1}^{N}\rho_i)^2$ can be obtained.

Next, we prove the uniqueness of this local maximum value.
From the triangle inequality, we have 
$|\sum\nolimits_{i=1}^{N}\rho_ie^{j\beta_i}|^2\le
( {\sum\nolimits_{i=1}^{N}|\rho_ie^{j\beta_i}|})^2 =( \sum\nolimits_{i=1}^{N}\rho_i)^2$.
% \begin{equation}
%	\begin{aligned}
%\begin{vmatrix}\sum\limits_{i=1}^{N}\rho_ie^{j\beta_i}\end{vmatrix}^2\le
%\left( {\sum\limits_{i=1}^{N}\begin{vmatrix}\rho_ie^{j\beta_i}\end{vmatrix}}\right)^2 =\left( \sum\limits_{i=1}^{N}\rho_i\right)^2.
%	\end{aligned}
%\end{equation}
Therefore, this local maximum is also the global maximum of \( E^2(\bm{\beta}) \). Now, we prove that there is no other local maximum that is smaller than \( (\sum\nolimits_{i=1}^{N}\rho_i)^2 \) by contradiction.
Suppose that there exists another local maximum solution $\bm{\beta}^0$, and the corresponding local maximum value $E^2(\bm{\beta}^0)$ satisfies $E^2(\bm{\beta}^0)< (\sum\nolimits_{i=1}^{N}\rho_i)^2$.
Since $\bm{\beta}^0$ does not satisfy condition (\ref{Econ}), it must belong to one of the following two cases.

\textbf{Case}\;\textbf{\uppercase\expandafter{\romannumeral1}}:
For all \( N \) complex numbers, i.e., \( \rho_i e^{j\beta^0_i} \), \( 1 \leq i \leq N \), they are not all collinear, which indicates that there exists a positive integer \(1\le{t}\le{N-1}\) such that \(0<{\eta^0}<{\pi}\), where $\eta^0=\min\left\lbrace \varphi,2\pi-\varphi \right\rbrace$ and 
$\varphi= |\angle(\sum\nolimits_{i=1}^{t}\rho_ie^{j\beta_i^0})
	-\angle(\sum\nolimits_{i=t+1}^{N}\rho_ie^{j\beta_i^0})|$.
% \begin{equation}
%	\begin{aligned}
%		\eta^0=\min\left\lbrace \varphi,2\pi-\varphi \right\rbrace,
%	\end{aligned}
%\end{equation}
%and 
% \begin{equation}
%	\begin{aligned}
%		\varphi= \begin{vmatrix}\angle\left(\sum\limits_{i=1}^{t}\rho_ie^{j\beta_i^0}\right)
%			-\angle\left(\sum\limits_{i=t+1}^{N}\rho_ie^{j\beta_i^0}\right)
%		\end{vmatrix}.
%	\end{aligned}
%\end{equation}
Additionally, using the cosine rule, we can obtain
$E^2(\bm{\beta}^0)={\begin{vmatrix}E_1\end{vmatrix}^2+
	\begin{vmatrix}E_2\end{vmatrix}^2+
	2\begin{vmatrix}E_1\end{vmatrix}\begin{vmatrix}E_2\end{vmatrix}\cos{\eta^0}}$,
%\begin{equation}
%	\begin{aligned}
%%		E(\bm{\beta}^0)&=\begin{vmatrix}\sum\limits_{i=1}^{t}\rho_ie^{j\beta_i^0}+\sum\limits_{i=t+1}^{N}\rho_ie^{j\beta_i^0}\end{vmatrix}
%%		\\
%		E^2(\bm{\beta}^0)={\begin{vmatrix}E_1\end{vmatrix}^2+
%			\begin{vmatrix}E_2\end{vmatrix}^2+
%			2\begin{vmatrix}E_1\end{vmatrix}\begin{vmatrix}E_2\end{vmatrix}\cos{\eta^0}},
%	\end{aligned}
%\end{equation}
where $E_1\triangleq\sum\nolimits_{i=1}^{t}\rho_ie^{j\beta_i^0}$ and $E_2\triangleq\sum\nolimits_{i=t+1}^{N}\rho_ie^{j\beta_i^0}$.
Since \(\bm{\beta}^0\) is a local maximum of $E^2(\bm{\beta})$, there must exist a positive number \(\delta\) such that for any $\bm{\beta}$ that satisfies  \(\|\bm{\beta} - \bm{\beta}^0\| \leq \delta\), \(E(\bm{\beta}) \le E(\bm{\beta}^0)\) holds.
The neighborhood of \(\bm{\beta}^0\), i.e., \(\|\bm{\beta} - \bm{\beta}^0\| \leq \delta\), corresponds to the neighborhood of \({\eta}^0\) which is denoted as \(|\eta-\eta^0| \leq \eta'\). 
However, since \(0<{\eta^0}<{\pi}\), if we take \(\eta^1 = \eta^0 -\eta''\), where $0<\eta''<\eta'$ and $\eta''$ is small enough to ensure that \({\eta^1}>0\) is satisfied, we will have \(\cos\eta^1>\cos\eta^0\), which further implies \(E^2(\bm{\beta}^1)> E^2(\bm{\beta}^0)\), 
where $\bm{\beta}^1$ is the vector corresponding to $\eta^1$, analogous to how $\bm{\beta}^0$ corresponds to $\eta^0$. 
This contradicts the assumption that \(E^2(\bm{\beta}^0)\) is a local maximum value. 


\textbf{Case}\;\textbf{\uppercase\expandafter{\romannumeral2}}:
If all $N$ complex numbers are collinear but do not satisfy condition (\ref{Econ}), that is, there must exist at least one positive integer \(1\le{t}\le{N-1}\) such that \(\beta_t^0-\beta_{t+1}^0=(2k+1){\pi}\), $k\in\mathbb{Z}$. 
%In this case, we can easily derive the following corollary: 
%$\exists{1\le{t'}\le{N}}$, such that $\rho_{t'}\le\begin{vmatrix}\sum\limits_{{i=1},i\neq{{t'}}}^{N}\rho_ie^{j\beta_i^0}\end{vmatrix}$ and $\begin{vmatrix}\beta_{t'}-\angle{\left(\sum\limits_{{i=1},i\neq{{t'}}}^{N}\rho_ie^{j\beta_i^0}\right)}\end{vmatrix}=\pi$.
%Similarly, in the $\delta$-neighborhood of \(\beta_{t'}\), by perturbing \(\beta_{t'}^0\) to \(\beta_{t'}^1=\beta_{t'}^0+\frac{\delta}{2}\), it can be deduced that
% 	
%	\begin{align}\label{L4_3}
%		E(\bm{\beta}^0)&=\begin{vmatrix}\sum\limits_{{{i=1},i\neq{{t'}}}}^{N}\rho_ie^{j\beta_i^0}+\rho_{t'}e^{j\beta_{t'}^0}\end{vmatrix}\nonumber\\
%		&=\begin{vmatrix}\sum\limits_{{{i=1},i\neq{{t'}}}}^{N}\rho_ie^{j\beta_i^0}\end{vmatrix}-\rho_{t'}\nonumber\\
%		&<\sqrt{\begin{vmatrix}\sum\limits_{\substack{{i=1}\\i\neq{{t'}}}}^{N}\rho_ie^{j\beta_i^0}\end{vmatrix}^2+
%			\rho_{t'}^2-
%			2\rho_{t'}\begin{vmatrix}\sum\limits_{\substack{{i=1}\\i\neq{{t'}}}}^{N}\rho_ie^{j\beta_i^0}\end{vmatrix}\cos{\frac{\delta}{2}}}\nonumber\\
%		&=E(\bm{\beta}^1).
%	\end{align}
%In this case, (\ref{L4_3}) also leads to contradiction to the previous assumption.
In this case, we can verify from (\ref{Egradient}) that $\nabla E^2(\bm{\beta})=\bm{0}$ is satisfied. However, since \(\beta_t^0-\beta_{t+1}^0=(2k+1){\pi}\), we have \(\cos(\beta_t^0-\beta_{t+1}^0)=-1 \), which allows for the existence of a vector  $\hat{\mathbf{x}} \in \mathbb{R}^N$ such that forces \(-\rho_t\rho_{t+1}\cos(\beta_t^0-\beta_{t+1}^0)(\hat{x}_t-\hat{x}_{t+1})^2 \) go to positive infinity. 
Therefore,  $\hat{\mathbf{x}}^T \nabla^2 \left(E^2(\bm{\beta}^0)\right) \hat{\mathbf{x}}>0$ implies that $\nabla^2 \left(E^2(\bm{\beta}^0)\right)$ is not a negative semi-definite matrix, which also contradicts the assumption that $\bm{\beta}^0$ is a local maximum.

In summary, based on the above two cases, the uniqueness of the local maximum value $ (\sum\nolimits_{i=1}^{N}\rho_i)^2$ is proved. Thus, Lemma 4 can be proved by combining the proofs of the existing and uniqueness of the local maximum value $ (\sum\nolimits_{i=1}^{N}\rho_i)^2$ of \( E^2(\bm{\beta}) \).
\iffalse
\section{}
To prove that the method of traversing all boundaries to determine whether \(D\) is greater than \(D_\text{min}\) can indeed find all local optimal solutions of problem (CP), we only need to prove that this approach is effective for any arbitrary local optimal solution.
Suppose that when $D<\frac{(N_t-1)\lambda}{\sin\theta_t^1+\sin\theta}$, there is an arbitrary local maximum solution $\hat{\mathbf{x}}$ of problem (CP).
Since $D<\frac{(N_t-1)\lambda}{\sin\theta_t^1+\sin\theta}$, the solution \(\hat{\mathbf{x}}\) must lie on the boundary of the feasible region of problem (CP), which implies that there must be certain active constraints.
Similarly, by substituting the active constraints into the objective function \(g(\mathbf{x})\) for elimination and re-indexing the resulting variables, we obtain new variables \(\mathbf{x}'\) and a new objective function \(\tilde{g}(\mathbf{x}')\). Since \(\hat{\mathbf{x}}\) is a local optimal solution, the corresponding new variable \(\hat{\mathbf{x}}'\) is a local maximum solution of \(\tilde{g}(\mathbf{x}')\) after substituting the active constraints. Thus, there is a neighborhood \(\mathcal{N}\) of \(\hat{\mathbf{x}}'\) such that \(\tilde{g}(\hat{\mathbf{x}}') \geq \tilde{g}(\mathbf{x}')\) and $\tilde{g}({\mathbf{x}}')$ becomes unconstrained for ${\mathbf{x}}'\in\mathcal{N}$.
According to Lemma 4, in the unconstrained case, the function \(\tilde{g}(\mathbf{x}')\) has a unique local maximum, which satisfies condition (\ref{Econ}).
Thus, \(D\) must be greater than \(D_\text{min}\), as determined by condition (\ref{Econ}), which means that the solution \(\hat{\mathbf{x}}\) can be obtained using Algorithm 1.
Thus, any local optimal solution \(\hat{\mathbf{x}}\) can be identified by traversing the boundaries and comparing whether \(D\) is greater than \(D_\text{min}\).
\fi
\vspace{-0.2cm}
\section{Verification for LICQ}\vspace{-0.1cm}
\textit{Definition (LICQ \cite{book1}):}
Given a point \( \mathbf{x} \) and an active set of a given nonlinear optimization problem, we say that the LICQ holds if the set of active constraint gradients 
at \( \mathbf{x} \) is linearly independent.

According to the above definition, we now compute the gradients of the inequality constraints in problem (CP), i.e., $\nabla_{\mathbf{x}}^T{\left(\mathbf{U}\mathbf{x}-\mathbf{l}_u\right)}=\mathbf{U}$,
%\begin{equation}
%	\begin{aligned}
	%		\nabla_{\mathbf{x}}^T{\left(\mathbf{U}\mathbf{x}-\mathbf{l}_u\right)}=\mathbf{U},
	%	\end{aligned}
%\end{equation}
where \(\mathbf{U}\) is an \( N_t \times N_t \) matrix given in (\ref{q16}) with \(\text{Rank}(\mathbf{U}) = N_t - 1\), and it can be easily verified that any 
\( N_t-1 \) rows in \(\mathbf{U}\) are linearly independent. 
%As some of the constraints in problem (CP) must be active when $D_x<\frac{(N_t-1)\lambda}{\sin\theta_t^1+\sin\theta}$, let us assume that the number of active constraints is \( c \), where \( 1 \leq c \leq N_t-1 \).\footnote{If \( c=N_t \), then \( \mathbf{U}\mathbf{x} = \mathbf{l}_u \) and \( D_x = (N_t - 1)\lambda/2 \) hold, which implies that the transmit antennas should be arranged at equal spacing with an interval of $\lambda/2$. This is equivalent to the conventional ULA scheme and thus we can safely ignore the case $c=N_t$.} 
Based on the properties of \( \mathbf{U} \), we can infer that any \( c \) rows of \( \mathbf{U} \) must also be linearly independent, which indicates that problem (CP) satisfies the LICQ condition.



\vspace{-0.2cm}
\section{Derivations of \( \nabla {\bar{p}_1(\mathbf{x})} , \nabla^2 {\bar{p}_1(\mathbf{x})} \) and  $\delta_1$}\vspace{-0.1cm}
For ease of exposition, we define
$
	\mathbf{z} \triangleq \bm{\Sigma} \bm{\psi}(\mathbf{x}^i) \in \mathbb{C}^{L_t}.
$
Further let \(z_p = b_p+jq_p\) denote the \(p\)-th entry of \(\mathbf{z}\),
with  \(b_p,q_p\in \mathbb{R}\). Then, \(\bar{p}_1(\mathbf{x})\) can be written as
$\bar{p}_1(\mathbf{x}) = \operatorname{Re} \left\{ \mathbf{z}^H\bm{\psi}(\mathbf{x}) \right\}
= \sum_{i=1}^{N_t}\sum_{p=1}^{L_r}  \left( b_p\cos(\alpha^px_i)-
q_p\sin(\alpha^px_i)
\right), $
%\begin{align}
%&\bar{p}_1(\mathbf{x}) = \operatorname{Re} \left\{ \mathbf{z}^H\bm{\psi}(\mathbf{x}) \right\}\nonumber \\
%&= \sum_{i=1}^{N_t}\sum_{p=1}^{L_r}  \left( b_p\cos(\alpha^px_i)-
%q_p\sin(\alpha^px_i)
% \right), 
%\end{align}
where
\(
\alpha^p \triangleq \frac{2\pi}{\lambda}(\sin\theta_t^{p}+\sin\theta).
\)
Thus, for $1\leq{i{\neq}k}\leq{N_t}$, we have $\frac{\partial \bar{p}_1(\mathbf{x})}{\partial x_{i}} = \sum_{p=1}^{L_r}  
\left( 
-b_p\alpha^p\sin(\alpha^px_i)-q_p\alpha^p\cos(\alpha^px_i)
\right),  
\frac{\partial^2 \bar{p}_1(\mathbf{x})}{\partial x_{i}^2} =   \sum_{p=1}^{L_r}   
\left( 
-b_p(\alpha^p)^2\cos(\alpha^px_i)+q_p(\alpha^p)^2\sin(\alpha^px_i)
\right)$, and $ 
\frac{\partial^2 \bar{p}_1(\mathbf{x})}{\partial x_{i} \partial x_{k}} = 0.$
%\begin{align}
%	\label{gradient1}
%\frac{\partial \bar{p}_1(\mathbf{x})}{\partial x_{i}} = \sum_{p=1}^{L_r}  
%\left( 
%-b_p\alpha^p\sin(\alpha^px_i)-q_p\alpha^p\cos(\alpha^px_i)
%\right), 
%\end{align}
%and
%\begin{align}
%	\label{hessian1}
%\frac{\partial^2 \bar{p}_1(\mathbf{x})}{\partial x_{i}^2} =&   \sum_{p=1}^{L_r}  
%\left( 
%-b_p(\alpha^p)^2\cos(\alpha^px_i)+q_p(\alpha^p)^2\sin(\alpha^px_i)
%\right),
%\nonumber\\
%\frac{\partial^2 \bar{p}_1(\mathbf{x})}{\partial x_{i} \partial x_{k}} =& 0.
%\end{align}
We observe that \( \nabla^2 \bar{p}_1(\mathbf{x}) \) is a diagonal matrix.
%, as derived from (\ref{hessian1}).
Thus, since \( \max\nolimits_{1\leq{i}\leq{N_t}}\{\frac{\partial^2 \bar{p}_1(\mathbf{x})}{\partial x_{i}^2}\} \mathbf{I}_{N_t} \succeq \nabla^2 \bar{p}_1(\mathbf{x}) \), we can select 
$\delta_1 = \sum_{p=1}^{L_r}  
\sqrt{b_p^2(\alpha^p)^4+q_p^2(\alpha^p)^4}$,
%\begin{align}
%	\label{delta1}
%\delta_1 = \sum_{p=1}^{L_r}  
%\sqrt{b_p^2(\alpha^p)^4+q_p^2(\alpha^p)^4},
%\end{align}
which can be simply obtained by $-b_p(\alpha^p)^2\cos(\alpha^px_i)+q_p(\alpha^p)^2\sin(\alpha^px_i)\le\sqrt{b_p^2(\alpha^p)^4+q_p^2(\alpha^p)^4}$.





\iffalse
\section{Derivations of $\nabla{p_2}(\mathbf{x})$}
The gradient of \( p_2(\mathbf{x}) \) can be obtained by using the chain rule as follows:
\begin{align}
	\label{gradient_p2}
\mathbf{\nabla_x}p_2(\mathbf{x}) = &
\frac{\bm{\psi}^H \mathbf{\Sigma} \bm{\psi}\frac{\mathbf{\nabla_x} \|\mathbf{h}\|^2}{2 \|\mathbf{h}\|^2}-\operatorname{Re}\left\{ (\mathbf{\nabla_x} \bm{\psi}^H)\bm{\Sigma} \bm{\psi} \right\}} 
{\sqrt{N_t \|\mathbf{h}\|^2 \bm{\psi}^H \mathbf{\Sigma} \bm{\psi} - (\bm{\psi}^H \mathbf{\Sigma} \bm{\psi})^2}}\nonumber
\\&-  
 \sqrt{\frac{\Gamma \sigma_c^2}{P_T{\|\mathbf{h}\|^2}-\Gamma \sigma_c^2}} 
\frac{ \mathbf{\nabla_x} \|\mathbf{h}\|^2}{2 \|\mathbf{h}\|^2},
\end{align}
where the element in the \( i \)-th row and \( k \)-th column of \( \mathbf{\nabla_x} \bm{\psi}^H \) is expressed as $		[  \mathbf{\nabla_x} \bm{\psi}^H] _{ik}=
j\frac{2\pi}{\lambda}(\sin{{\theta}_t^k}+\sin\theta){e^{j\frac{2\pi}{\lambda}x_i(\sin{{\theta}_t^k}+\sin\theta)}}$,
%\begin{equation}
%	\begin{aligned}
%		\left[  \mathbf{\nabla_x} \bm{\psi}^H\right] _{ik}=
%		j\frac{2\pi}{\lambda}(\sin{{\theta}_t^k}+\sin\theta){e^{j\frac{2\pi}{\lambda}x_i(\sin{{\theta}_t^k}+\sin\theta)}},
%	\end{aligned}
%\end{equation}
and the $p$-th entry of $\mathbf{\nabla_x} \|\mathbf{h}\|^2$ can be written as
$[  \mathbf{\nabla_x}  \|\mathbf{h}\|^2] _{p}=
\sum\nolimits_{i=1}^{L_t}\sum\nolimits_{k=1}^{L_t}
{j\frac{2\pi}{\lambda}(\sin{{\theta}_t^i}-\sin{{\theta}_t^k})}{\sigma_i{\sigma_k^*}e^{j\frac{2\pi}{\lambda}x_p(\sin{{\theta}_t^i}-\sin{{\theta}_t^k})}}$.
%	\begin{align}
%		\left[  \mathbf{\nabla_x}  \|\mathbf{h}\|^2\right] _{p}&=\\
%				 \sum\limits_{i=1}^{L_t}&\sum\limits_{k=1}^{L_t}
%		{j\frac{2\pi}{\lambda}(\sin{{\theta}_t^i}-\sin{{\theta}_t^k})}{\sigma_i{\sigma_k^*}e^{j\frac{2\pi}{\lambda}x_p(\sin{{\theta}_t^i}-\sin{{\theta}_t^k})}}.\nonumber
%	\end{align}
\fi




}



\vspace{-0.2cm}

\bibliography{ref1.bib}
\bibliographystyle{IEEEtran}

\end{document}


