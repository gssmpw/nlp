\section{Conclusion}
In this work, we addressed several critical gaps in memory-enhanced RL research: the lack of standardized agents' evaluation methods, the absence of a unified taxonomy for memory tasks, and the disconnect between abstract memory challenges and practical robotics applications. 
We addressed these through three key contributions.
First, we developed a comprehensive classification framework that categorizes memory tasks into four distinct classes: object memory, spatial memory, sequential memory, and memory capacity. 
This taxonomy provides a structured approach to understanding and evaluating different aspects of memory in RL agents. 
Second, we introduced \textbf{MIKASA-Base}, a unified benchmark that consolidates diverse memory-intensive environments into a single, standardized framework. 
By carefully selecting representative tasks from each memory category, our benchmark enables systematic comparison and evaluation of memory-enhanced RL agents across a broad spectrum of memory challenges. 
Third, we presented \textbf{MIKASA-Robo}, a novel benchmark comprising 32 carefully designed memory-intensive tasks for robotic manipulation, which bridges the gap between abstract memory challenges and practical robotics applications.
We hope that our contributions will serve as a foundation for future research in memory-enhanced RL, accelerating the development of more capable and reliable autonomous systems for real-world applications.