\newpage
\section{MIKASA-Base}
\label{sec:rl-memory-benchmark}
\input{tables/popular_robo_frameworks}
\paragraph{Motivation and Overview.}
The RL domain currently lacks standardized benchmarks for evaluating agents' memory capabilities. While numerous memory-intensive environments exist, their dispersion across different research projects makes systematic comparison challenging. Moreover, existing frameworks often focus on narrow aspects of memory, failing to capture the diverse memory requirements found in real-world applications. To address these limitations, we introduce MIKASA-Base, a unified benchmark that systematically evaluates memory capabilities across diverse tasks while maintaining practical simplicity.

\textbf{}

\paragraph{Benchmark Design Principles.}
Our benchmark follows key design principles that ensure comprehensive evaluation of memory capabilities. To isolate memory mechanisms from other learning challenges, MIKASA-Base implements a two-tiered task structure. The first tier consists of \textbf{diagnostic} vector-based environments, enabling direct validation of specific memory mechanisms in atomic tasks. The second tier comprises \textbf{complex} image-based environments that introduce additional challenges through 2D observation processing, more closely approximating real-world scenarios. This hierarchical approach allows researchers to first validate fundamental memory capabilities before progressing to more sophisticated tasks.

\paragraph{Task Classification and Selection.}
Building upon our taxonomy presented in \autoref{sec:mem-class}, we conducted a systematic analysis of existing open-source memory-intensive environments from \autoref{tab:behcmark-baseline}. Our analysis revealed four distinct classes of memory tasks. This classification enabled us to identify a minimal yet representative set of environments that spans the large spectrum of memory utilization patterns, from object permanence to sequential decision-making, while maintaining practical simplicity. Detailed descriptions of all considered environments are provided in \autoref{app:unif-memory-tasks-description}, while \autoref{tab:memory-tasks-bench} in the Appendix presents an analysis of MIKASA-Base memory-intensive environments.

We unified these environments under the Gymnasium API~\citep{towers2024gymnasium}, enabling seamless integration with existing RL tools (see~\autoref{tab:recommended-environments}). This standardization facilitates direct architectural comparisons. Implementation details are provided in~\autoref{app:mikasa-code}.

\begin{table}[t]
    \small
    \centering
    \caption{Recommended memory-intensive environments for comprehensive agent evaluation.}
    \vspace{-10pt}
    \label{tab:recommended-environments}
    \begin{adjustbox}{width=1\textwidth}
    \begin{tabular}{lll}
        \toprule
        \textbf{Memory Type} & \textbf{Diagnostic Tasks} & \textbf{Complex Tasks} \\
        \midrule
        \textbf{Object Memory} & Passive T-Maze~\citep{shine_rl} & ViZDoom-Two-Colors~\citep{sorokin2022explain} \\
        \textbf{Spatial Memory} & POPGym Labyrinth~\citep{popgym2023} & Memory Maze~\citep{memory_maze} \\
        \textbf{Sequential Memory} & POPGym Autoencode~\citep{popgym2023} & Ballet~\citep{hcam} \\
        \textbf{Memory Capacity} & Memory Cards~\citep{esslinger2022dtqn} & MemoryGym Mortar Mayhem~\citep{pleines2023memory} \\
        \bottomrule
    \end{tabular}
    \end{adjustbox}
\vspace{-15pt}
\end{table}

To evaluate agents in realistic memory-intensive scenarios, we introduce our MIKASA-Robo benchmark (\autoref{sec:maniskill-memory}). This benchmark provides a suite of robotic manipulation tasks that systematically assess all four memory types in practical, real-world-inspired contexts.

MIKASA-Base standardizes memory evaluation in RL through organized environment selection and structured task progression. Through its carefully curated environment selection and hierarchical structure, MIKASA-Base enables systematic evaluation of memory-enhanced architectures, facilitates direct comparison between different memory mechanisms, and provides a clear progression path from fundamental to complex memory tasks. This structured approach allows precise identification of memory-related limitations in RL agents while maintaining practical utility.