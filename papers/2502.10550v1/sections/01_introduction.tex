\section{Introduction}
\label{sec:introduction}

\begin{wrapfigure}{r}{0.5\textwidth}
    \vspace{-25pt}
    \centering
    \includegraphics[width=0.5\textwidth]{images/visual-abstract-scheme_v2.pdf}
    \vspace{-15pt}
    \caption{Systematic classification of problems with memory in RL reveals distinct memory utilization patterns and enables objective evaluation of memory mechanisms across different agents.}
    \label{fig:visualiabstract}
    \vspace{-15pt}
\end{wrapfigure}
Many real-world problems involve partial observability~\citep{KAELBLING199899}, where an agent lacks full access to the environmentâ€™s state. 
These tasks often include sequential decision-making~\citep{chen2021decision}, delayed or sparse rewards, and long-term information retention~\citep{gtrxl,hcam}. One approach to tackling these challenges is to equip the agent with memory, allowing it to utilize historical information~\citep{meng2021memory,ni2021recurrent}.

While there are well-established benchmarks in Natural Language Processing~\citep{bai2023longbench,an2023eval}, the evaluation of memory in reinforcement learning (RL) remains fragmented. Existing benchmarks, such as POPGym~\citep{popgym2023}, DMLab-30~\citep{dmlab} and MemoryGym~\citep{pleines2023memory}, focus on specific aspects of memory utilization, as they are designed around particular problem domains. 

In contrast to classical RL, where benchmarks like Atari~\citep{atari} and MuJoCo~\citep{mujoco} serve as universal standards, memory-enhanced agents are typically evaluated on custom environments developed alongside their proposals~\autoref{tab:behcmark-baseline}. This fragmented evaluation landscape obscures important performance variations across different memory tasks. For instance, an agent might excel at maintaining object attributes over extended periods while struggling with sequential recall challenges. Such task-specific strengths and limitations often remain hidden due to narrow evaluation scopes, underscoring the need for a comprehensive benchmark that spans diverse memory-intensive scenarios.

The challenge of memory evaluation becomes particularly evident in robotics. While some robotic tasks naturally involve partial observability, e.g. navigation tasks~\citep{ai2022deep,habitatchallenge2023}, many studies artificially create partially observable scenarios from Markov Decision Processes (MDPs)~\citep{pomdp_new} by introducing observation noise or masking parts of the state space~\citep{Spaan12pomdp,meng2021memory,kurniawati2022partially,Lauri_2023}. However, these approaches do not fully capture the complexity of real-world robotic challenges~\citep{Lauri_2023}, where tasks may require the agent to recall past object configurations, manipulate occluded objects, or perform multi-step procedures that depend heavily on memory.

In this paper, we aim to address these challenges with the following three contributions:

\begin{enumerate}
    \item \textbf{Memory Tasks Classification}: We develop a comprehensive yet practically simple classification of memory-intensive tasks. Our classification framework distills the complex landscape of memory challenges into four essential categories, enabling systematic evaluation while avoiding unnecessary complexity (\autoref{fig:visualiabstract}). This approach provides a clear, actionable framework for categorizing and selecting environments that capture fundamental memory challenges in RL and robotics (\autoref{sec:tasks-classification}).

    \item \textbf{Unified Benchmark}: We introduce \textbf{MIKASA-Base}, a Gymnasium-based~\citep{towers2024gymnasium} framework for evaluating memory-enhanced RL agents (\autoref{sec:rl-memory-benchmark}).
    
    \item \textbf{Robotic Manipulation Tasks}: We develop \textbf{MIKASA-Robo}, a suite of 32 carefully designed robotic manipulation tasks that isolate and evaluate specific memory-dependent skills in realistic scenarios (\autoref{sec:maniskill-memory}). 
\end{enumerate}

\input{tables/envs_table}