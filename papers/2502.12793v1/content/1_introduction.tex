\section{Introduction}\label{sec:intro}

An anomaly, or an outlier, is a data point that is significantly different from the remaining data~\citep{aggarwal2017introduction}, to such an extent that it was likely generated by a different mechanism~\citep{hawkins1980identification}. From the perspective of machine learning, \gls{ad} wants to determine, from a set of examples, which ones are likely anomalies, typically through a score. This problem finds applications in many different fields, such as medicine~\cite{salem2013sensor}, cyber-security~\cite{siddiqui2019detecting}, and system monitoring~\cite{isermann2006fault}, to name a few. As reviewed in~\cite{han2022adbench}, existing techniques for \gls{ad} are usually divided into unsupervised, semi-supervised and supervised approaches, with an increasing need for labeled data. In this paper, we focus on unsupervised \gls{ad}, which does not need further labeling effort in constituting datasets. As discussed in~\cite{livernoche2024on}, the growing number of applications involving high-dimensional and complex data begs the need for non-parametric algorithms.

Meanwhile, \gls{ot} is a field of mathematics concerned with the transportation of masses at least effort~\cite{villani2009optimal}. In its modern treatment, one can conceive transportation problems between probability distributions, which has made an important impact in machine learning research~\citep{montesuma2024recentadvancesoptimaltransport}. Hence, \gls{ot} is an appealing tool, as it can be estimated non-parametrically from samples from probability distributions. Likewise, the plethora of computational tools for computing \gls{ot}~\citep{peyre2020computationaloptimaltransport,flamary2021pot} further stresses its usability.

% In this context, previous works~\citep{alaoui2019unsupervised,alaoui2020semi} have considered \gls{ot}, especially through the Wasserstein geometry, for \gls{ad}. However, as we discuss below, the applicability of these methods are restricted to 

In this context, the application of \gls{ot} for \gls{ad} is not straightforward, as we are interested in analyzing a single probability distribution, rather than 2. This paper puts forth a new \gls{ot} problem between a distribution and itself, by restricting \emph{where} a sample can send its mass to. More specifically, we design an \emph{exclusion zone}, prohibiting samples from keeping its mass, or sending its mass to a small vicinity. Especially, we assume that anomalies lie in low density regions of space, with only a few samples in their vicinity. By restricting the transport of mass in the vicinity of samples, anomalies are naturally forced to send its mass to the high density region, which is assumed to be far away from the anomaly samples. Hence, anomalies will make a larger \emph{transportation effort} than normal samples, which can find nearby samples outside the exclusion zone. We show a conceptual illustration of our method in Figure.

While \gls{ot} has been previously used to compare and aggregate signals in the context of \gls{ad}~\citep{alaoui2019unsupervised,alaoui2020semi}, to the best of our knowledge ours is the first general purpose \gls{ot}-based algorithm for \gls{ad}. Furthermore, we propose a new \gls{ot} problem based on the engineering of the ground-cost, which has links to \gls{ot} with repulsive costs~\citep{di2017optimal}. We benchmark our algorithm in a comprehensive list of datasets, including tabular, computer vision, and natural language processing proposed by~\cite{han2022adbench}, besides fault detection~\citep{reinartz2021extended,montesuma2024benchmarking}.


This paper is organized as follows. Section~\ref{sec:related_work} discusses related work in \gls{ad} and \gls{ot}. Section~\ref{sec:methodology} discusses our proposed method, called \gls{munot}. Section~\ref{sec:experiments} covers our experiments. Finally, section~\ref{sec:conclusion} concludes this paper.