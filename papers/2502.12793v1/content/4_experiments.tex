% \newpage

\section{Experiments}\label{sec:experiments}

We divide our experiments in 4 parts. Section~\ref{ex:toy} shows a toy example, going through all the steps in our algorithm. Section~\ref{ex:adbench} shows our results on AdBench~\citep{han2022adbench}. Section~\ref{ex:cdfd} shows our experiments in fault detection on the Tennessee Eastman Process~\citep{montesuma2024benchmarking,reinartz2021extended}. Finally, Section~\ref{sec:ablations} explores the robustness of our methods to various hyper-parameters and design choices.

\subsection{An introductory toy example}\label{ex:toy}

Before diving into comparing our method with prior art, we give an introductory example that illustrates how we create anomaly scores out of samples. In this example, we sample normal examples $\mathbf{x}_{i} \sim \mathcal{N}(\mathbf{0}, 0.25\mathbf{I}_{2})$, and anomalous samples $\mathbf{y}_{j} \sim \mathcal{N}([-3, -3], 0.01\mathbf{I}_{d})$, where $\mathbf{I}_{2}$ is a $2 \times 2$ identity matrix. The dataset for this toy example consists of the concatenation $\{\mathbf{x}_{1},\cdots,\mathbf{x}_{n},\mathbf{y}_{1},\cdots,\mathbf{y}_{m}\}$, where $n=500$ and $m=25$, which means that roughly $5\%$ of the total number of samples are anomalies. In the following, we compare our engineered cost with a regularized Coulomb interaction, $C_{ij} = (1+\lVert \mathbf{x}_{i}^{(P)} - \mathbf{x}_{j}^{(P)} \rVert_{2})^{-1}$. This cost is shown alongside our proposed engineered cost in Figure~\ref{fig:toy-example}. \emph{Note that, in Figures~\ref{fig:toy-example} (b - d) the lower-right corner of the matrices correspond to anomalies.}

\begin{figure}[ht]
    \centering
    \begin{subfigure}{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{Figures/ToyExample.pdf}
        \caption{Toy example.}
    \end{subfigure}\hfill
    \begin{subfigure}{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{Figures/EuclideanCost.pdf}
        \caption{Euclidean cost.}
    \end{subfigure}\hfill
    \begin{subfigure}{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{Figures/EngineeredCost.pdf}
        \caption{Engineered cost.}
    \end{subfigure}\hfill
    \begin{subfigure}{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{Figures/CoulombCost.pdf}
        \caption{Coulomb cost.}
    \end{subfigure}\hfill
    \caption{In (a), we show the samples for our toy example. In (b), (c) and (d), we show the ground-cost $C_{ij}$ between samples in (a), using the Euclidean distance, our engineered ground-cost (equation~\ref{eq:engineered_cost}), and the regularized Coulomb interaction cost.}
    \label{fig:toy-example}
\end{figure}


Figure~\ref{fig:toy-example} clearly illustrates that directly using the Euclidean cost results in a trivial \gls{ot} solution, because the diagonal entries of $C_{ij}$ are zero. This is not the case for our engineered cost, and the regularized Coulomb interaction, shown in Figures~\ref{fig:toy-example} (c) and (d). To stress this idea, we show in Figure~\ref{fig:toy-example-transport-plans} the transportation plans acquired by \gls{munot} and using the regularized Coulomb cost. While both strategies achieve similar transportation matrices, in the second case the anomalies send and receive less mass than normal samples. This is somewhat expected, as the anomalous samples are clustered together in a tight region of $\mathbb{R}^{2}$, resulting in a high cost. As a result, these samples are encouraged to send their mass elsewhere.

\begin{figure}[ht]
    \centering
    \begin{subfigure}{0.48\linewidth}
        \centering
        \includegraphics[width=0.48\linewidth]{Figures/MROT_Plan_Sinkhorn.pdf}
        \includegraphics[width=0.48\linewidth]{Figures/TransportStrategy.pdf}
        \caption{\gls{munot}.}
    \end{subfigure}\hfill
    \begin{subfigure}{0.48\linewidth}
        \centering
        \includegraphics[width=0.48\linewidth]{Figures/CoulombCost_OTPlan_Sinkhorn.pdf}
        \includegraphics[width=0.48\linewidth]{Figures/CoulombCost_TransportStrategy.pdf}
        \caption{\gls{ot} with the regularized Coulomb cost.}
    \end{subfigure}\hfill
    \caption{In (a), we show the \gls{munot} transportation plan (left side) and strategy (right side). Likewise, in (b) we show the transportation plan and strategy for the regularized Coulomb cost. While both transportation strategies achieve similar results, in (b) the anomalies (lower right corner) sends and receives much less mass than other normal samples.}
    \label{fig:toy-example-transport-plans}
\end{figure}

Here comes an important distinction between our approach and simply using repulsive costs in \gls{ot}. Considering our last remark about the regularized Coulomb interaction, samples send their mass to distant regions of space, thus reducing $C_{ij}$. As a result, \emph{anomalies will incur in a smaller transportation cost than normal samples}. Although counterintuitive, one can still construct a detection rule out of this idea, as we show below.

In Figure~\ref{fig:toy-example-transport-costs}, we present the anomaly scores derived from our \gls{munot} strategy and the regularized Coulomb cost. These scores are computed by first determining the transportation effort (c.f., equation~\ref{eq:score}) for each sample $x_{i}^{(P)}$, then estimating the density of these efforts, and finally transforming the density into a $[0, 1]$ score via its \gls{cdf}, as outlined in section~\ref{sec:building-anomaly-score}. As shown in Figure~\ref{fig:toy-example-transport-costs}, the \gls{munot} approach assigns higher anomaly scores to anomalous samples compared to normal ones, simplifying the process of setting a threshold for anomaly detection. In contrast, the regularized Coulomb cost exhibits the opposite behavior. Indeed, anomalous samples send their mass to distant parts of space (i.e., to normal samples), which, due the nature of the Coulomb cost, lead to a smaller transportation effort. Nevertheless, as discussed previously, it is still possible to establish a detection rule, albeit being counterintuitive.

\begin{figure}[ht]
    \centering
    \begin{subfigure}{0.48\linewidth}
        \centering
        \includegraphics[width=0.48\linewidth]{Figures/MROT_AnomalyScore_OverSamples.pdf}
        \includegraphics[width=0.48\linewidth]{Figures/MROT_AnomalyScoreDistribution.pdf}
        \caption{\gls{munot} anomaly score.}
    \end{subfigure}\hfill
    \begin{subfigure}{0.48\linewidth}
        \centering
        \includegraphics[width=0.48\linewidth]{Figures/CoulombCost_AnomalyScore_OverSamples.pdf}
        \includegraphics[width=0.48\linewidth]{Figures/CoulombCost_AnomalyScoreDistribution.pdf}
        \caption{regularized Coulomb cost anomaly score.}
    \end{subfigure}\hfill
    \caption{Anomaly score comparison between the \gls{munot} (ours, a) and \gls{ot} with repulsive costs (b).  Scores are computed by calculating the transportation effort (Eq.~\ref{eq:score}) for each sample \(x_{i}^{(P)}\), estimating their density, and normalizing to the \([0, 1]\) range via the \gls{cdf} (c.f., section~\ref{sec:building-anomaly-score}). Overall, our strategy assigns higher scores (close to $1.0$) to anomalous samples, while assigning smaller scores to normal samples.}
    \label{fig:toy-example-transport-costs}
\end{figure}

As we discussed throughout section~\ref{sec:building-anomaly-score}, the scores in Figure~\ref{fig:toy-example-transport-costs} are only defined in the support of $\hat{P}$. We then explore the regression of this score through regression, which can be done with a variety of standard regression algorithms. In Figure~\ref{fig:toy-example-regression-scores} we show the results for \gls{xgboost}~\citep{chen2016xgboost} and \gls{svr}~\citep{smola2004tutorial}, which both define the anomaly score over the whole ambient space $\mathbb{R}^{2}$. As an important remark, the relationship between $x_{i}^{(P)}$ and its score is likely non-linear. Indeed, this idea is evidenced in Figure~\ref{fig:toy-example-regression-scores}. As a result, one needs a non-linear regression algorithm.

\begin{figure}[ht]
    \centering
    \begin{subfigure}{0.48\linewidth}
        \centering
        \includegraphics[width=0.48\linewidth]{Figures/MROT_XGBoost.pdf}
        \includegraphics[width=0.48\linewidth]{Figures/MROT_SVR.pdf}
        \caption{\gls{munot} regressed score.}
    \end{subfigure}\hfill
    \begin{subfigure}{0.48\linewidth}
        \centering
        \includegraphics[width=0.48\linewidth]{Figures/CoulombCost_XGBoost.pdf}
        \includegraphics[width=0.48\linewidth]{Figures/CoulombCost_SVR.pdf}
        \caption{regularized Coulomb cost regressed score.}
    \end{subfigure}\hfill
    \caption{Regression of the anomaly score for \gls{munot} (ours, a) and \gls{ot} with repulsive costs (b).}
    \label{fig:toy-example-regression-scores}
\end{figure}

% \newpage

\subsection{Comparison on AdBench}\label{ex:adbench}

AdBench~\citep{han2022adbench} is a benchmark in \gls{ad} with 57 different kinds of datasets, grouped into 47, 5 and 5 real-world, vision and \gls{nlp} datasets. In our experiments, we focus on real-world and natural-language datasets. We compare, in total, 17 methods, grouped into classical, diffusion-based and our proposed methods based on \gls{ot}. For classic methods, we consider \gls{isof}~\citep{liu2008isolation}, \gls{ocsvm}~\citep{scholkopf1999support}, \gls{knn}, \gls{lof}~\citep{breunig2000lof}, \gls{cblof}~\citep{he2003discovering}, \gls{ecod}~\citep{li2022ecod}, \gls{copod}~\citep{li2020copod}, \gls{loda}~\citep{pevny2016loda}, Feature Bagging~\citep{lazarevic2005feature}, and \gls{hbos}~\citep{goldstein2012histogram}. For diffusion based, we consider the 4 variants of \gls{dte}~\citep{livernoche2024on}. Finally, we consider \gls{ot} with repulsive costs~\cite{di2017optimal}, and our proposed \gls{munot}.

\begin{figure}[ht]
    \centering
    \begin{subfigure}{0.32\linewidth}
        \centering
        \includegraphics[width=\linewidth]{Figures/AdBench_Results.pdf}
        \caption{Real-world.}
    \end{subfigure}\hspace{0.1\linewidth}
    \begin{subfigure}{0.32\linewidth}
        \centering
        \includegraphics[width=\linewidth]{Figures/AdBench_NLP_Results.pdf}
        \caption{\gls{nlp}}
    \end{subfigure}
    \caption{AdBench result summary. AUC-ROC per dataset is available in the appendix. We compare, in total, 17 algorithms over 47 real-world datasets (a) and 5 \gls{nlp} datasets (b). For real-world datasets, our \gls{munot} has state-of-the-art performance, especially when compared with recently proposed flow-based models. For higher dimensional data, our method}
    \label{fig:adbench-results}
\end{figure}

We show our summarized results in Figures~\ref{fig:adbench-results} (a) and (b), for real-world and NLP datasets, respectively. First, we note that \gls{munot} and \gls{ot} with repulsive costs have superior performance with respect other methods on real-world datasets. This result highlights the usefulness of \gls{ot} theory in the analysis of probability distributions. Furthermore, on average, our \gls{munot} has better performance than \gls{ot} (77.36\% versus 75.97\% ROC-AUC), proving the effectiveness of our cost engineering strategy. We refer readers to our appendix for detailed results per dataset.

Even though our method has superior performance on real-world datasets, the \gls{nlp} benchmarks reveal limitations of \gls{ot} based \gls{ad}. A first limitation of using \gls{munot} comes from the scalability of \gls{ot}. As a linear program, it has at least $\mathcal{O}(n^{2})$ storage, and $\mathcal{O}(n^{3}\log n)$ computational complexity, where $n$ is the number of samples. In our experiments, we limited the number of samples to $n = 20,000$, by down-sampling bigger datasets. As reported in Figure~\ref{fig:adbench-results} (a), and our detailed results are given in the Appendix, this process does not affect performance. Furthermore, from Figure~\ref{fig:adbench-results} (b), we see that our method struggles in high dimensional anomaly detection, such as those in the \gls{nlp} datasets of~\cite{han2022adbench}. This limitation stems from the use of \gls{ot} in high-dimensions~\citep[Section 8.1]{montesuma2025optimal}.

\subsection{Tennessee Eastman Process}\label{ex:cdfd}

In this section, we focus in comparing anomaly detection methods for fault detection. To that end, we use the \gls{te} process benchmark~\citep{downs1993plant}, especially the simulations of~\cite{reinartz2021extended}, pre-processed by~\cite{montesuma2024benchmarking}. This benchmark is composed by simulations of a large-scale chemical plant. Besides the normal state, there are 28 faults associated with different parts of the plant. An interesting feature of this benchmark is that there are different modes of operation. Ideally, an anomaly detection algorithm trained in one mode should generalize to other modes, but this is not guaranteed due to distributional shift. Such challenge is the subject of domain adaptation~\citep{montesuma2023multi,montesuma2024benchmarking,montesuma2024lighter,montesuma2025optimal}, which is beyond the scope of this work. We refer readers to the aforementioned papers for further details.

From the original simulations in~\cite{reinartz2021extended}, we consider $100$ simulations for the normal state. These simulations last for $600$ hours, with a time-step of $1$ hour, and concern $34$ sensors measuring different physical and chemical properties. On top of these $100$ simulations, we take $1$ faulty simulation for each kind of fault, leading to a total of $128$ simulations. Based on this set of simulations, we extract windows of $20$ hours from the original signals. Each window is then considered a sample for anomaly detection. On each window, we compute the mean, and standard deviation of each variable, leading to vectors $\mu, \sigma \in \mathbb{R}^{34}$. We use the concatenation of these vectors as features for anomaly detection. These steps lead to $6$ datasets with $3840$ samples, $840$ ($21.875\%$) of them being anomalous, one for each mode of operation. We thus divide our discussion into two parts: fault detection, and cross-domain fault detection.

\begin{figure}[ht]
    \centering
    \begin{subfigure}{0.31\linewidth}
        \centering
        \includegraphics[width=\linewidth]{Figures/tep_tSNE_mode1.pdf}
        \caption{Mode 1.}
    \end{subfigure}\hfill
    \begin{subfigure}{0.31\linewidth}
        \centering
        \includegraphics[width=\linewidth]{Figures/tep_tSNE_mode2.pdf}
        \caption{Mode 2.}
    \end{subfigure}\hfill
    \begin{subfigure}{0.31\linewidth}
        \centering
        \includegraphics[width=\linewidth]{Figures/tep_tSNE_mode3.pdf}
        \caption{Mode 3.}
    \end{subfigure}\hfill
    \begin{subfigure}{0.31\linewidth}
        \centering
        \includegraphics[width=\linewidth]{Figures/tep_tSNE_mode4.pdf}
        \caption{Mode 4.}
    \end{subfigure}\hfill
    \begin{subfigure}{0.31\linewidth}
        \centering
        \includegraphics[width=\linewidth]{Figures/tep_tSNE_mode5.pdf}
        \caption{Mode 5.}
    \end{subfigure}\hfill
    \begin{subfigure}{0.31\linewidth}
        \centering
        \includegraphics[width=\linewidth]{Figures/tep_tSNE_mode6.pdf}
        \caption{Mode 6.}
    \end{subfigure}\hfill
    \caption{t-SNE embeddings of the Tennessee Eastman process data per mode. In blue, we show the normal samples, whereas we show anomalous samples in shades of reds, corresponding to the actual fault category they correspond. While most anomalous samples do cluster in a region outside the non-faulty cluster, some faulty samples do not.}
    \label{fig:tep-results}
\end{figure}

In Figure~\ref{fig:tep-results}, we visualize the Tennessee Eastman data using t-SNE. We scatter the embeddings of each mode's data, showing that most faulty samples cluster outside the normal data cluster. However, some faulty samples are close to normal ones. This phenomenon is expected, as the effect of faults evolves over time. As a result, windows taken in early stages of simulation resemble those of normal samples.

Next, we benchmark the \gls{ad} performance of algorithms, and their capability to generalize to unseen that within the same mode of operation. In this experiment, we downsample the number of anomalous samples per fault category to $\{5, 10, \cdots, 30\}$. This results in a percentage of $\{4.45\%, 8.53\%, 12.28\%, 15.73\%, 18.92\%, 21.87\%\}$ of anomalous samples. In Figure~\ref{fig:tep-aggregated-results}, we report our aggregated results over all percentage of anomalies. We refer readers to our appendix for results per percentage.

The main idea of this methodology is evaluating how different algorithms perform, under a variable percentage of faults. Our results are shown in Figure~\ref{fig:tep-results} (b). Among the tested methods, \gls{munot} has a better performance and remains stable throughout the range of percentage of anomalies.

\begin{figure}[ht]
    \centering
    \begin{subfigure}{0.31\linewidth}
        \centering
        \includegraphics[width=\linewidth]{Figures/TEP_Aggregated_Results1.pdf}
        \caption{Mode 1.}
    \end{subfigure}\hfill
    \begin{subfigure}{0.31\linewidth}
        \centering
        \includegraphics[width=\linewidth]{Figures/TEP_Aggregated_Results2.pdf}
        \caption{Mode 2.}
    \end{subfigure}\hfill
    \begin{subfigure}{0.31\linewidth}
        \centering
        \includegraphics[width=\linewidth]{Figures/TEP_Aggregated_Results3.pdf}
        \caption{Mode 3.}
    \end{subfigure}\hfill
    \begin{subfigure}{0.31\linewidth}
        \centering
        \includegraphics[width=\linewidth]{Figures/TEP_Aggregated_Results4.pdf}
        \caption{Mode 4.}
    \end{subfigure}\hfill
    \begin{subfigure}{0.31\linewidth}
        \centering
        \includegraphics[width=\linewidth]{Figures/TEP_Aggregated_Results5.pdf}
        \caption{Mode 5.}
    \end{subfigure}\hfill
    \begin{subfigure}{0.31\linewidth}
        \centering
        \includegraphics[width=\linewidth]{Figures/TEP_Aggregated_Results6.pdf}
        \caption{Mode 6.}
    \end{subfigure}\hfill
    \caption{Aggregated anomaly detection on the Tennessee Eastman data per mode of operation. First, MROT outperforms OT with repulsive costs over all modes. Second, MROT and DTE-C have state-of-the-art performance, superior to previously proposed methods.}
    \label{fig:tep-aggregated-results}
\end{figure}

\subsection{Robustness}\label{sec:ablations}

\begin{figure}[ht]
    \centering
    \begin{subfigure}{0.8\linewidth}
        \centering
        \includegraphics[width=\linewidth]{Figures/Hyperparameters_MROT.pdf}
        \caption{MROT.}
    \end{subfigure}
    \begin{subfigure}{0.18\linewidth}
        \centering
        \includegraphics[width=\linewidth]{Figures/Hyperparameters_ROT.pdf}
        \caption{ROT.}
    \end{subfigure}
    \caption{Hyper-parameter sensitivity. In (a), we show the performance of \gls{munot} for a variable number of nearest neighbors $k$, and entropic regularization $\epsilon$. Overall, our method is robust to the choices of these hyper-parameters, but using a lower $\epsilon$ is generally better. In contrast, we show in (b) the performance of \gls{ot}-based \gls{ad} with the regularized Coulomb cost, for which using a higher entropic penalty $\epsilon$ improves performance.}
    \label{fig:hyper-parameters-sensitivity}
\end{figure}

Our method has two hyper-parameters, the entropic regularization penalty $\epsilon$, and the number of nearest neighbors $k$. In our experiments, we evaluated our methods over the values $\epsilon \in \{0, 10^{-2}, 10^{-1}, 10^{0}\}$, where $\epsilon = 0$ implies using exact \gls{ot}, i.e., linear programming. For \gls{munot}, we use $k\in\{5, 10, 20, \cdots, 50\}$. Note that, while $\epsilon$ is linked to the \emph{transportation plan}, $k$ is linked to the \emph{ground-cost}. We summarize our results in Figure~\ref{fig:hyper-parameters-sensitivity}, where we present \glspl{kde} over the AUC-ROC scores of each dataset, for each combination of hyper-parameters.

From Figure~\ref{fig:hyper-parameters-sensitivity}, we note that both \gls{munot} is robust to the choice of entropic regularization and number of nearest neighbors. As a general guideline, it is better to limit the number of nearest neighbors, as anomalous examples are likely rare. As a consequence, using a high value for $k$ may lead to the inclusion of normal points in the neighborhood of anomalous ones.

% \newpage