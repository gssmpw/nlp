\section{Related work}
In traditional pathology,  WSI inspection by pathologists remains the gold standard for clinical diagnosis ____. However, the conventional diagnostic process is labor-intensive and time-consuming ____, with the shortage of experienced pathologists further exacerbating the challenge. DL-based methods ____, which employ biologically-inspired neural networks to utilize the rich information contained in WSIs. are advancing computer-aided pathology diagnosis. In this section, we firstly review DL-based digital pathology methods for cancer diagnosis, and then focus on  methods specific to glioma diagnosis, and finally review methods that integrate histology and molecular markers for precision oncology.


\subsection{Digital pathology for cancer diagnosis}



DL-based digital pathology methods are generally  categorized into low (cell)-level modelling and high (tissue)-level modelling. These approaches address downstream tasks such as cell segmentation ____ and tissue phenotyping  ____, respectively. Specifically, cell segmentation models primarily focus on assigning pixel-level labels for cells and nuclei ____, further used as biomarkers for disease diagnosis. For instance, ____ proposed Hover-Net, which performs simultaneous nuclear segmentation and classification by leveraging the distances of nuclear pixels to the mass centre. Similarly, ____  developed a DL-based pipeline to generate an embedded map profiling cell composition,  further utilized to extract texture patterns for tumour and immune cells. 
In contrast to cell-level modelling, tissue-level modelling is more efficient in capturing global phenotype features,  providing a more comprehensive understanding of tissue architecture and pathology that is crucial for accurate and effective clinical assessments. Particularly, recent DL-based approaches  have significantly improved computer-aided classification of various diseases ____, including membranous nephropathy ____, interstitial lung disease ____. 


  \begin{figure*}[t]
    \centering
    \includegraphics[width=1\linewidth]{pdf/fig1_after_review.pdf}
    \caption{Framework of our M3C2 method, including (A) multi-scale disentangling module, (B) molecular prediction module, (C) cross-module interaction module and (D) histology prediction module. Note that IM, SM, IH and SH denote independent molecular features, shared molecular features, independent histology features and shared histology features, respectively.}
    \label{fig:framework}
\end{figure*}



DL-based tissue-level modelling has been widely researched in cancer diagnosis, promising to enhance the accuracy and efficiency of cancer classification ____. For instance, ____ devised ScanNet, a fast and dense scanning framework utilizing asynchronous sample prefetching and hard negative mining for efficient breast cancer detection. Additionally, ____ proposed FA-MSCN, a feature aligned multi-scale convolutional network, to achieve liver tumour diagnosis. FA-MSCN integrates features from multiple magnifications to improve the performance by referencing more neighboring information. Similarly, ____ designed an end-to-end, high-generalizable, weakly supervised deep convolutional network, which achieved great performance in lung cancer classification. Despite the success in many cancers, DL-based algorithms still face significant challenges in brain tumors, particularly glioma, due to its remarkable heterogeneity, complex diagnostic criteria and limited samples ____.



\subsection{Automatic glioma grading with WSIs}


In recent years, several models ____ have been proposed to classify glioma based on WSIs. For instance, ____ designed a mutual contrastive low-rank learning (MCL) scheme, where formalin-fixed paraffin-embedded (FFPE)-based  and frozen-based WSIs are integrated for better glioma grading performance. Additionally, ____ proposed a novel DL-based classification method that fuses genomic features with cellularity features for glioma prediction. However, most existing DL methods are based on the obsolete glioma taxonomy criteria ____, which only focuses on histology features, such as NMP. Therefore, it is in demand to develop DL-based methods consistent with the latest glioma diagnosis criteria, which jointly concsider histology and molecular markers in the taxonomy pipeline.



Most recently, a few DL-based methods ____ have achieved automatic glioma diagnosis using the up-to-date criteria. For example, ____ proposed a hierarchical vision transformer-based method to separately predict molecular markers and histology features, which are then combined for final diagnosis. Similarly, ____ devised a ResNet-50-based DL structure with a novel patch selection strategy for classifying glioma according to the latest criteria. Despite their potentials, significant limitations remain in existing methods: \textbf{(i)} Current methods are incapable of achieving efficient interaction between the histology features and molecular markers for clinically interpretable diagnosis; \textbf{(ii)} The diagnosis scheme used in existing works are incomplete or inconsistent with the latest criteria. For instance, in \citep {hollon2023artificial}, grade 4 astrocytoma, a newly defined class in WHO 2021 criteria, was ignored in the training process. 
\textbf{(iii)} Most models were trained with a single type of WSIs, i.e., either FFPE or frozen tissue sections, whereas in real-world practice, both FFPE- and   frozen-based WSIs are commonly used for diagnosis in different clinical scenarios. To address these gaps, the proposed M3C2 achieves explicit interaction between histology features and molecular markers aligned with the WHO 2021 criteria and trained on both FFPE and frozen sections.



\vspace{-.5em}
\subsection{Integration of histology and molecular markers}


\noindent\textbf{Multi-modal learning for precision oncology.}
Recently, joint modeling of multi-modal data of histology and molecular markers has achieved progress in precision oncology, advancing AI towards practical clinical application in various cancers ____.
Multi-modal algorithms are generally categorized into three types: early, intermediate, and late fusion. Early fusion integrates raw data or extracted features before inputting them into the proposed algorithms. Intermediate fusion ____ modulates multi-modal feature embeddings at specific fusion modules or different layers within the model. Late fusion ____ involves modality-specific models that aggregate predictions from each modality for the final classification. For example, ____ proposed an intermediate fusion framework (CMAT), which explores intrinsic associations between histopathology images and gene expression profiles through a cross-modal attention module and a modality alignment and fusion module. Similarly,  ____ developed a late fusion framework named SURVPATH, a memory-efficient multimodal transformer that integrates gene pathways and histopathology images for pan-cancer survival prediction.



For gliomas, several multi-modal data fusion methods have  been proposed ____. Specifically, ____ introduced the Pathomic Fusion method that integrates gene expression  and WSI for jointly predicting survival and glioma classification. ____ devised a disentangled multi-modal framework that can handle both complete and incomplete samples for glioma diagnosis and prognosis.  Despite the effectiveness, most current multi-modal methods face practical limitations in clinical scenarios, as they  rely on the input of molecular information, which is expensive and time-consuming to obtain. This dependence hampers their applicability and widespread adoption in clinical practice.


To tackle this challenge, ____ proposed a novel discrepancy and gradient-guided modality distillation framework. In this approach, WSIs and gene expressions are combined during training, while the branch for gene expressions is distilled during testing. However, despite this innovative approach, modality distillation-based multi-modal learning methods are fall short in  generating molecular markers. This limitation renders them impractical for clinical use according to the latest diagnosis criteria. 



\noindent\textbf{Multi-task learning for precision oncology}
Multi-task learning shows promise to improve on existing methods, which can predict both histology features and molecular markers only using WSIs as input. For instance, ____ proposed an Inception-v3 ____-based DL method to separately predict both classification and mutation from nonâ€“small cell lung cancer histopathology images. However, most existing methods perform multiple tasks separately, without explicit interaction between histology and molecular marker predictions. In comparison, we proposed a novel multi-task learning method with efficient modality interaction via the DCC loss and the specially designed gradient modulation strategy. This approach facilitates explicit task interplay, enhancing the predictive power and clinical applicability of the model by integrating histology and molecular marker more effectively.


\vspace{-.5em}
\subsection{Differences from the conference paper}

This paper is an extended version of our conference paper ____ (Nominated for Best Paper Award) with substantial improvements by:
(1) adding a thorough literature review and an extensive discussion.
(2) fulfilling the details of the proposed method and improving the original structure as follows.
We first propose a multi-scale disentangling module to extract multi-magnification WSI features for both histology and molecular marker predictions.
We design a CMG-Modu strategy to harmonize the training process of multiple tasks and achieve cross-modal task interplay.
In addition, an attention mechanism is further involved in our framework to extract more relevant features. 
(3) Consequently, the performance of our method has been improved in all tasks of glioma classification (by 5.6$\%$ in accuracy), molecular markers (e.g., by 4.3$\%$ in accuracy of IDH) and histology (by 4.3$\%$ in accuracy) prediction.
(4) We comprehensively validate the model with diverse experimental settings. First, we perform additional ablation experiments to evaluate the newly proposed modules. Secondly, we add an external validation set of 753 WSIs, verifying the generalizability of our method.  Thirdly, we  evaluate the model performance with varied experimental settings on input magnifications and incorporation of auxiliary tasks. Finally we compare our model with more SOTA methods.






\vspace{-.5em}