\begin{table*}[h!]
    \centering
    \resizebox{\textwidth}{!}{
    \begin{tabular}{l|rr|rrrrrrrrrr}
    \toprule
    & \multicolumn{2}{c}{\textbf{Avg. Relative}} & \multicolumn{2}{c}{\textbf{Ll-3B}} & \multicolumn{2}{c}{\textbf{Ge-2B}} & \multicolumn{2}{c}{\textbf{Qw-3B}} & \multicolumn{2}{c}{\textbf{QM-1.5B}} & \multicolumn{2}{c}{\textbf{DM-7B}} \\
    \cmidrule(lr){2-3} \cmidrule(lr){4-5} \cmidrule(lr){6-7} \cmidrule(lr){8-9} \cmidrule(lr){10-11} \cmidrule(lr){12-13}
    \textbf{Method} & Acc & Len & Acc & Len & Acc & Len & Acc & Len & Acc & Len & Acc & Len \\
    \midrule
    Default \scriptsize{\cite{pang2024iterative}} & 100.0 & 100.0 & 44.4 & 511.8 & 24.0 & 376.0 & 56.8 & 605.5 & 69.8 & 551.4 & 37.0 & 357.3 \\
    \midrule
    Be Concise \scriptsize{\cite{renze2024benefits}} & 102.7 & 92.7 & 47.2 & 477.5 & \textcolor{BrickRed}{22.2} & 307.1 & 60.2 & 541.9 & 68.0 & \textcolor{gray}{550.2} & 41.2 & \textcolor{gray}{353.8} \\
    Est. Budget \scriptsize{\cite{han2024token}} & \textcolor{BrickRed}{80.7} & \textcolor{gray}{132.7} & 45.6 & \textcolor{gray}{907.4} & \textcolor{BrickRed}{16.2} & 255.1 & \textcolor{BrickRed}{20.4} & 125.7 & 70.0 & \textcolor{gray}{1070.0} & 36.0 & \textcolor{gray}{726.3} \\
    Fixed Budget \scriptsize{\cite{nayab2024concise}} & \textcolor{BrickRed}{88.1} & 70.8 & \textcolor{BrickRed}{42.6} & 413.1 & \textcolor{BrickRed}{22.0} & 193.6 & \textcolor{BrickRed}{33.0} & 170.3 & 69.6 & \textcolor{gray}{536.7} & \textcolor{BrickRed}{35.2} & \textcolor{gray}{344.8} \\
    Hand Crafted 1 (ours) & 100.5 & 86.6 & 46.8 & 481.1 & \textcolor{BrickRed}{20.2} & 241.6 & 56.8 & 446.3 & 68.0 & \textcolor{gray}{548.8} & 42.8 & \textcolor{gray}{362.3} \\
    Hand Crafted 2 (ours) & 101.6 & 85.3 & 46.6 & 445.9 & 24.0 & 275.7 & \textcolor{BrickRed}{54.8} & 393.8 & 68.8 & \textcolor{gray}{543.7} & \textcolor{BrickRed}{40.0} & \textcolor{gray}{365.2} \\
    Hand Crafted 3 (ours) & \textcolor{BrickRed}{84.9} & 80.1 & \textcolor{BrickRed}{24.4} & 283.0 & \textcolor{BrickRed}{22.0} & 365.7 & \textcolor{BrickRed}{46.0} & 272.9 & 67.6 & \textcolor{gray}{552.3} & 37.0 & \textcolor{gray}{367.7} \\
    Hand Crafted 4 (ours) & \textcolor{BrickRed}{63.9} & 45.9 & \textcolor{BrickRed}{13.2} & 65.7 & \textcolor{BrickRed}{13.0} & 88.7 & \textcolor{BrickRed}{16.2} & 9.4 & 69.4 & \textcolor{gray}{535.5} & 39.8 & 337.9 \\
    \bottomrule
    \end{tabular}
    }
    \caption{
    \textbf{Inconsistency of zero-shot prompting methods on MATH.} Zero-shot prompting methods for concise reasoning on MATH.
    Relative accuracy (\%) and length (\%) compared to default prompting are shown, averaged over five main models: Llama-3.2-3B, Gemma-2-2B, Qwen2.5-3B, Qwen2.5-Math-1.5B, and DeepSeekMath-7B.  
    Absolute accuracy (\%) and length (tokens) are reported for each individual model.  
    Values in red indicate \textcolor{BrickRed}{significant relative accuracy drop} greater than 5\%. Values in gray indicate \textcolor{gray}{negligible relative length reduction} less than 5\%.
    }
    \label{tab:zero_shot_prompting_math}
    \vspace{10pt}
\end{table*}