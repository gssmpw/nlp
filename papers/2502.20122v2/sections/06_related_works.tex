
\section{Related work}
\label{sec:related_work}


% Existing work on zero-shot prompting approaches to concise reasoning were limited to few models and show performance degradation. Our analysis shows that methods are inconsistent across models and datasets.
% Concurrent work on fine-tuning for concise reasoning show these limitations.
% \textcolor{gray}{Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus nec risus leo. Nullam sollicitudin malesuada nisl at interdum. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Donec eget laoreet odio. In lobortis, elit porta molestie sagittis, urna enim feugiat orci, eu laoreet leo enim id dolor. Curabitur dictum nisi sit amet libero rutrum, sed tempor nisl vestibulum. Fusce sed blandit nisl. Cras volutpat ante in pretium feugiat. Donec posuere justo eget sem malesuada scelerisque. }

% % \paragraph{Concise reasoning}
% % \textbf{Previous work \cite{renze2024benefits} conduct preliminary investigation of a zero-shot prompt, `Be concise', to reduce the length of reasoning chains. However this was limited to GPT variants and came with performance degradation.
% % }A previous fine-grained benchmark on LMs measures the `efficiency' of the logical process of LMs–without unnecessary reasoning steps.

% \paragraph{Mechanism behind chain-of-thought reasoning}

% \paragraph{Efficient reasoning by improving small models}
% A practical approach to reducing the cost of reasoning is to simply improve the reasoning ability of small models, reducing the model size requirements for a given task.
% This includes reasoning distillation, self-improvement of reasoning, thinking models--though these require more tokens.
% This is orthogonal to our approach to improving the efficiency of reasoning models.
% We show that our method works well on top of these methods. \textbf{TODO}

% \paragraph{Reasoning in \textit{system-1}}
% Recent work \cite{deng2023implicit, deng2024explicit, su2024dualformer, yu2024distilling} have studied training methodologies to enable LMs to reason implicitly, without any intermediate reasoning tokens.
% In other words, they enable LMs to solve complex reasoning tasks using "system 1" thinking, rather than "system 2", albeit typically with a penalty in performance on common tasks such as GSM8K \cite{cobbe2021training}.
% This approach is related to ours, as it enables LMs to solve reasoning tasks with few tokens–the answer itself.
% However, we aim to maximize the efficiency of "system-2" thinking, reducing token costs by removing redundant tokens, but maintaining critical reasoning tokens to preserve performance.
% Moreover, we find that this ability is inherent to pretrained LMs, and we exploit this with subsampling to enable efficient reasoning through few-shot prompting or lightweight fine-tuning, as opposed to multi-epoch training on heavily augmented datasets as in previous work \cite{deng2023implicit, deng2024explicit}.


\subsection{Chain-of-thought Reasoning}

% CoT good
CoT reasoning enables LMs to solve diverse tasks~\citep{wei2022chain, kojima2022large} by leveraging an arbitrarily large amount of computation for next-word prediction~\citep{merrill2023expresssive, nowak2024representational, xiang2025towards}. 
% long cot (recent thinking model) vs short cot (classical cot)
Recently, additional lines of research have expanded~\citep{openai2024systemcard, guo2025deepseek} basic CoT by adding in-context search~\citep{ye2024physics, kumar2024training}, often termed as meta-CoT~\citep{xiang2025towards} or long-CoT~\citep{yeo2025demystifying}.
% The position of our paper 
This paper focuses on original CoT framework to investigate the simplest ways to reduce the number of tokens, which could potentially be applied to long-CoT as well.



\subsection{Concise Reasoning}
% Overthinking
Many studies have shown that LLMs tend to overthink during CoT, often including unnecessary words in their reasoning~\citep{zhang2024verbosity, chiang2024reasoning, wang2024chain}, which can negatively impact efficiency.
% Generally, long reasoning is better
However, simply reducing the number of tokens often leads to significantly lower performance
% , especially for difficult questions
~\citep{merrill2023expresssive, jin2024impact}.
% zero-shot
To address this, some works have explored prompting techniques to elicit concise reasoning~\citep{renze2024benefits, nayab2024concise, han2024token}, but these methods are highly model-dependent.
% , and certain key prompts may fail to reduce token count for specific models.
% fine-tuning based
Another line of work has focused on fine-tuning methods to balance efficiency and reasoning quality~\citep{de2024rational}, but these approaches are insufficient in reducing token usage.
% for mathematical reasoning tasks.
% position of our paper
In this work, we investigate how to efficiently generate concise reasoning samples and use them for fine-tuning, improving model efficiency without sacrificing accuracy.
% \red{TODO - shorten to like half}

Several concurrent works also address redundancies in LLM outputs. Some approaches \cite{chen2024not, luo2025o1} focus on how o1-like models overthink and propose methods for pruning extraneous reasoning steps. Another approach, TokenSkip \cite{xia2025tokenskip}, first identifies and discards low-importance tokens from self-generated CoT outputs while preserving crucial ones, then fine-tunes the model on these compressed examples to enable efficient inference. 
In contrast, our method elicits concise reasoning more simply yet effectively by training on a self-generated dataset of shorter rationales, using best-of-N sampling and few-shot conditioning.
