\section{Related Works}
\label{append:related_works}

\paragraph{Graph Neural Networks and Different Types of Graphs}
GNNs were originally proposed to resolve the challenge of data point dependencies via the traditional convolution neural networks, which, in general, treat every input data point independently of each other **Kipf et al., "Semi-Supervised Classification with Graph Convolutional Networks"**. By considering the so-called adjacency information stored in the graph, GNNs propagate graph node features by aggregating its neighboring information **Hamilton et al., "Inductive Representation Learning on Large Graphs"**. Such propagation paradigm has made GNNs one of the most successful tools in generating predictions via various types of graphs, such as citation networks **Klicpera et al., "Diffusion Improves Graph Neural Networks"**, social networks **Scarselli et al., "Graph Embeddings for Large-Scale Network-Based Data Analysis"**, molecules (as well as protein and ligands) **Duvenaud et al., "Convolutional Networks on Graphs for Learning Molecular Fingerprints"**, traffic networks **Monti et al., "Geometric Deep Learning on Manifolds"**, to name a few. These graphs vary from different levels of measurements of the data, e.g., scientific papers in citation networks **Kipf et al., "Semi-Supervised Classification with Graph Convolutional Networks"**, atoms, and amino acids in protein and ligand graphs **Duvenaud et al., "Convolutional Networks on Graphs for Learning Molecular Fingerprints"** and nodes are connected with different types of attributes (e.g., citations and chemical bonds). In this work, we provide a \textbf{novel graph dataset} (known as JR5558, more details see Section \ref{sec:preliminaries}) in which graphs are formed by the genetic pathways (as nodes) and pathway similarities (as edges), serving as the profiles of the experimental objects (e.g., mice). In addition, we also label these graphs with mice's lesion severity scores (as a continuous variable) obtained from fundus photographs of these mice, where severity was quantified by measuring subretinal lesion size.We train two different types of GNNs to capture the patterns between genetic pathways and mice lesion severity scores: one that does not consider temporal information, and another designed to account for temporal information from the estimated disease progression in the mice.



\paragraph{Pseudotime Analysis and Stochastic Differential Equations}
Pseudotime analysis (PA) was originally developed in single-cell transcriptomics to reconstruct cell differentiation trajectories from static snapshots of gene expression profiles **Becker et al., "Single-Cell RNA-Seq Enables Comparative Analysis of Transcriptional Cohorts"**. Since time-resolved measurements of individual cells are often infeasible, pseudotime methods infer an intrinsic ordering (e.g., trajectories) of cells based on their transcriptional similarities, providing insights into dynamic biological processes. While it is a powerful tool widely applied in biology and medical science, its adoption in the machine learning community has only gained significant attention in recent years. For example, recent work has explored using diffusion models to infer pseudotime from single-cell transcriptomic data **Liu et al., "Diffusion-Based Methods for Single-Cell RNA-Seq Data Analysis"**. In this work, we apply PA to the embeddings of graphs constructed from the genetic pathways of the mice and analyze the estimated trajectories via neural stochastic differential equations **Chen et al., "Neural Stochastic Differential Equations for Physics-Informed Neural Networks"** (see Section \ref{sec:nsde} for more details), which allow us to further exploit pathway stability and disease bifurcation points. This paradigm paves the path of incorporating advanced machine learning approaches to the exploration of the fundamental problems in complex biological systems.