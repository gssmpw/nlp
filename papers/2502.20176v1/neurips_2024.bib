@inproceedings{li2021ai,
  title={Ai choreographer: Music conditioned 3d dance generation with aist++},
  author={Li, Ruilong and Yang, Shan and Ross, David A and Kanazawa, Angjoo},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={13401--13412},
  year={2021}
}

@article{fan2011example,
  title={Example-based automatic music-driven conventional dance motion synthesis},
  author={Fan, Rukun and Xu, Songhua and Geng, Weidong},
  journal={IEEE transactions on visualization and computer graphics},
  volume={18},
  number={3},
  pages={501--515},
  year={2011},
  publisher={IEEE}
}

@article{ofli2011learn2dance,
  title={Learn2dance: Learning statistical music-to-dance mappings for choreography synthesis},
  author={Ofli, Ferda and Erzin, Engin and Yemez, Y{\"u}cel and Tekalp, A Murat},
  journal={IEEE Transactions on Multimedia},
  volume={14},
  number={3},
  pages={747--759},
  year={2011},
  publisher={IEEE}
}


@article{copet2024simple,
  title={Simple and controllable music generation},
  author={Copet, Jade and Kreuk, Felix and Gat, Itai and Remez, Tal and Kant, David and Synnaeve, Gabriel and Adi, Yossi and D{\'e}fossez, Alexandre},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{mittal2021symbolic,
  title={Symbolic music generation with diffusion models},
  author={Mittal, Gautam and Engel, Jesse and Hawthorne, Curtis and Simon, Ian},
  journal={arXiv preprint arXiv:2103.16091},
  year={2021}
}
@inproceedings{cheng2023ssvmr,
  title={Ssvmr: Saliency-based self-training for video-music retrieval},
  author={Cheng, Xuxin and Zhu, Zhihong and Li, Hongxiang and Li, Yaowei and Zou, Yuexian},
  booktitle={ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={1--5},
  year={2023},
  organization={IEEE}
}
@inproceedings{mckee2023language,
  title={Language-guided music recommendation for video via prompt analogies},
  author={McKee, Daniel and Salamon, Justin and Sivic, Josef and Russell, Bryan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={14784--14793},
  year={2023}
}
@article{huang2024mavil,
  title={Mavil: Masked audio-video learners},
  author={Huang, Po-Yao and Sharma, Vasu and Xu, Hu and Ryali, Chaitanya and Li, Yanghao and Li, Shang-Wen and Ghosh, Gargi and Malik, Jitendra and Feichtenhofer, Christoph and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{ma2024foundation,
  title={Foundation Models for Music: A Survey},
  author={Ma, Yinghao and {\O}land, Anders and Ragni, Anton and Del Sette, Bleiz MacSen and Saitis, Charalampos and Donahue, Chris and Lin, Chenghua and Plachouras, Christos and Benetos, Emmanouil and Quinton, Elio and others},
  journal={arXiv preprint arXiv:2408.14340},
  year={2024}
}
@article{dhariwal2020jukebox,
  title={Jukebox: A generative model for music},
  author={Dhariwal, Prafulla and Jun, Heewoo and Payne, Christine and Kim, Jong Wook and Radford, Alec and Sutskever, Ilya},
  journal={arXiv preprint arXiv:2005.00341},
  year={2020}
}

@article{baevski2020wav2vec,
  title={wav2vec 2.0: A framework for self-supervised learning of speech representations},
  author={Baevski, Alexei and Zhou, Yuhao and Mohamed, Abdelrahman and Auli, Michael},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={12449--12460},
  year={2020}
}
@article{li2023mert,
  title={Mert: Acoustic music understanding model with large-scale self-supervised training},
  author={Li, Yizhi and Yuan, Ruibin and Zhang, Ge and Ma, Yinghao and Chen, Xingran and Yin, Hanzhi and Xiao, Chenghao and Lin, Chenghua and Ragni, Anton and Benetos, Emmanouil and others},
  journal={arXiv preprint arXiv:2306.00107},
  year={2023}
}
@inproceedings{wu2023large,
  title={Large-scale contrastive language-audio pretraining with feature fusion and keyword-to-caption augmentation},
  author={Wu, Yusong and Chen, Ke and Zhang, Tianyu and Hui, Yuchen and Berg-Kirkpatrick, Taylor and Dubnov, Shlomo},
  booktitle={ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={1--5},
  year={2023},
  organization={IEEE}
}
@article{liu2023audioldm,
  title={Audioldm: Text-to-audio generation with latent diffusion models},
  author={Liu, Haohe and Chen, Zehua and Yuan, Yi and Mei, Xinhao and Liu, Xubo and Mandic, Danilo and Wang, Wenwu and Plumbley, Mark D},
  journal={arXiv preprint arXiv:2301.12503},
  year={2023}
}
@inproceedings{wu2022wav2clip,
  title={Wav2clip: Learning robust audio representations from clip},
  author={Wu, Ho-Hsiang and Seetharaman, Prem and Kumar, Kundan and Bello, Juan Pablo},
  booktitle={ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={4563--4567},
  year={2022},
  organization={IEEE}
}


@article{chen2021choreomaster,
  title={Choreomaster: choreography-oriented music-driven dance synthesis},
  author={Chen, Kang and Tan, Zhipeng and Lei, Jin and Zhang, Song-Hai and Guo, Yuan-Chen and Zhang, Weidong and Hu, Shi-Min},
  journal={ACM Transactions on Graphics (TOG)},
  volume={40},
  number={4},
  pages={1--13},
  year={2021},
  publisher={ACM New York, NY, USA}
}


@inproceedings{aksan2019structured,
  title={Structured prediction helps 3d human motion modelling},
  author={Aksan, Emre and Kaufmann, Manuel and Hilliges, Otmar},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={7144--7153},
  year={2019}
}

@inproceedings{qiu2019cross,
  title={Cross view fusion for 3d human pose estimation},
  author={Qiu, Haibo and Wang, Chunyu and Wang, Jingdong and Wang, Naiyan and Zeng, Wenjun},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={4342--4351},
  year={2019}
}
@article{galata2001learning,
  title={Learning variable-length Markov models of behavior},
  author={Galata, Aphrodite and Johnson, Neil and Hogg, David},
  journal={Computer Vision and Image Understanding},
  volume={81},
  number={3},
  pages={398--413},
  year={2001},
  publisher={Elsevier}
}
@article{holden2016deep,
  title={A deep learning framework for character motion synthesis and editing},
  author={Holden, Daniel and Saito, Jun and Komura, Taku},
  journal={ACM Transactions on Graphics (TOG)},
  volume={35},
  number={4},
  pages={1--11},
  year={2016}
}
@incollection{holden2015learning,
  title={Learning motion manifolds with convolutional autoencoders},
  author={Holden, Daniel and Saito, Jun and Komura, Taku and Joyce, Thomas},
  booktitle={SIGGRAPH Asia 2015 technical briefs},
  pages={1--4},
  year={2015},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
}
@inproceedings{butepage2017deep,
  title={Deep representation learning for human motion prediction and classification},
  author={Butepage, Judith and Black, Michael J and Kragic, Danica and Kjellstrom, Hedvig},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={6158--6166},
  year={2017}
}
@inproceedings{chiu2019action,
  title={Action-agnostic human pose forecasting},
  author={Chiu, Hsukuang and Adeli, Ehsan and Wang, Borui and Huang, De-An and Niebles, Juan Carlos},
  booktitle={2019 IEEE winter conference on applications of computer vision (WACV)},
  pages={1423--1432},
  year={2019},
  organization={IEEE}
}
@article{du2019bio,
  title={Bio-lstm: A biomechanically inspired recurrent neural network for 3-d pedestrian pose and gait prediction},
  author={Du, Xiaoxiao and Vasudevan, Ram and Johnson-Roberson, Matthew},
  journal={IEEE Robotics and Automation Letters},
  volume={4},
  number={2},
  pages={1501--1508},
  year={2019},
  publisher={IEEE}
}
@article{fan2022bi,
  title={A bi-directional attention guided cross-modal network for music based dance generation},
  author={Fan, Di and Wan, Lili and Xu, Wanru and Wang, Shenghui},
  journal={Computers and Electrical Engineering},
  volume={103},
  pages={108310},
  year={2022},
  publisher={Elsevier}
}
@article{li2020learning,
  title={Learning to generate diverse dance motions with transformer},
  author={Li, Jiaman and Yin, Yihang and Chu, Hang and Zhou, Yi and Wang, Tingwu and Fidler, Sanja and Li, Hao},
  journal={arXiv preprint arXiv:2008.08171},
  year={2020}
}
@inproceedings{huang2022genre,
  title={Genre-conditioned long-term 3d dance generation driven by music},
  author={Huang, Yuhang and Zhang, Junjie and Liu, Shuyan and Bao, Qian and Zeng, Dan and Chen, Zhineng and Liu, Wu},
  booktitle={ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={4858--4862},
  year={2022},
  organization={IEEE}
}
@inproceedings{li2022danceformer,
  title={Danceformer: Music conditioned 3d dance generation with parametric motion transformer},
  author={Li, Buyu and Zhao, Yongchi and Zhelun, Shi and Sheng, Lu},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={36},
  number={2},
  pages={1272--1279},
  year={2022}
}
@article{yang2023longdancediff,
  title={Longdancediff: Long-term dance generation with conditional diffusion model},
  author={Yang, Siqi and Yang, Zejun and Wang, Zhisheng},
  journal={arXiv preprint arXiv:2308.11945},
  year={2023}
}
@article{zhuang2022music2dance,
  title={Music2dance: Dancenet for music-driven dance generation},
  author={Zhuang, Wenlin and Wang, Congyi and Chai, Jinxiang and Wang, Yangang and Shao, Ming and Xia, Siyu},
  journal={ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM)},
  volume={18},
  number={2},
  pages={1--21},
  year={2022},
  publisher={ACM New York, NY}
}
@inproceedings{gong2023tm2d,
  title={Tm2d: Bimodality driven 3d dance generation via music-text integration},
  author={Gong, Kehong and Lian, Dongze and Chang, Heng and Guo, Chuan and Jiang, Zihang and Zuo, Xinxin and Mi, Michael Bi and Wang, Xinchao},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={9942--9952},
  year={2023}
}
@inproceedings{siyao2022bailando,
  title={Bailando: 3d dance generation by actor-critic gpt with choreographic memory},
  author={Siyao, Li and Yu, Weijiang and Gu, Tianpei and Lin, Chunze and Wang, Quan and Qian, Chen and Loy, Chen Change and Liu, Ziwei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={11050--11059},
  year={2022}
}

@inproceedings{tseng2023edge,
  title={Edge: Editable dance generation from music},
  author={Tseng, Jonathan and Castellon, Rodrigo and Liu, Karen},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={448--458},
  year={2023}
}
@inproceedings{li2023finedance,
  title={Finedance: A fine-grained choreography dataset for 3d full body dance generation},
  author={Li, Ronghui and Zhao, Junfan and Zhang, Yachao and Su, Mingyang and Ren, Zeping and Zhang, Han and Tang, Yansong and Li, Xiu},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={10234--10243},
  year={2023}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}
@inproceedings{chen2020vggsound,
  title={Vggsound: A large-scale audio-visual dataset},
  author={Chen, Honglie and Xie, Weidi and Vedaldi, Andrea and Zisserman, Andrew},
  booktitle={ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={721--725},
  year={2020},
  organization={IEEE}
}

@inproceedings{mcfee2015librosa,
  title={librosa: Audio and music signal analysis in python.},
  author={McFee, Brian and Raffel, Colin and Liang, Dawen and Ellis, Daniel PW and McVicar, Matt and Battenberg, Eric and Nieto, Oriol},
  booktitle={SciPy},
  pages={18--24},
  year={2015}
}

@article{zhou2022learning,
  title={Learning to prompt for vision-language models},
  author={Zhou, Kaiyang and Yang, Jingkang and Loy, Chen Change and Liu, Ziwei},
  journal={International Journal of Computer Vision},
  volume={130},
  number={9},
  pages={2337--2348},
  year={2022},
  publisher={Springer}
}

@incollection{loper2023smpl,
  title={SMPL: A skinned multi-person linear model},
  author={Loper, Matthew and Mahmood, Naureen and Romero, Javier and Pons-Moll, Gerard and Black, Michael J},
  booktitle={Seminal Graphics Papers: Pushing the Boundaries, Volume 2},
  pages={851--866},
  year={2023}
}
@article{ho2020denoising,
  title={Denoising diffusion probabilistic models},
  author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={6840--6851},
  year={2020}
}

@inproceedings{perez2018film,
  title={Film: Visual reasoning with a general conditioning layer},
  author={Perez, Ethan and Strub, Florian and De Vries, Harm and Dumoulin, Vincent and Courville, Aaron},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={32},
  number={1},
  year={2018}
}
@inproceedings{tevethuman,
  title={Human Motion Diffusion Model},
  author={Tevet, Guy and Raab, Sigal and Gordon, Brian and Shafir, Yoni and Cohen-or, Daniel and Bermano, Amit Haim},
  booktitle={The Eleventh International Conference on Learning Representations}
}

@article{onuma2008fmdistance,
  title={FMDistance: A Fast and Effective Distance Function for Motion Capture Data.},
  author={Onuma, Kensuke and Faloutsos, Christos and Hodgins, Jessica K},
  journal={Eurographics (Short Papers)},
  volume={7},
  year={2008}
}

@incollection{muller2005efficient,
  title={Efficient content-based retrieval of motion capture data},
  author={M{\"u}ller, Meinard and R{\"o}der, Tido and Clausen, Michael},
  booktitle={ACM SIGGRAPH 2005 Papers},
  pages={677--685},
  year={2005}
}
@article{huang2020dance,
  title={Dance revolution: Long-term dance generation with music via curriculum learning},
  author={Huang, Ruozi and Hu, Huang and Wu, Wei and Sawada, Kei and Zhang, Mi and Jiang, Daxin},
  journal={arXiv preprint arXiv:2006.06119},
  year={2020}
}


@article{van2017neural,
  title={Neural discrete representation learning},
  author={Van Den Oord, Aaron and Vinyals, Oriol and others},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}
@article{defossez2022high,
  title={High fidelity neural audio compression},
  author={D{\'e}fossez, Alexandre and Copet, Jade and Synnaeve, Gabriel and Adi, Yossi},
  journal={arXiv preprint arXiv:2210.13438},
  year={2022}
}

@article{abdul2022mel,
  title={Mel frequency cepstral coefficient and its applications: A review},
  author={Abdul, Zrar Kh and Al-Talabani, Abdulbasit K},
  journal={IEEE Access},
  volume={10},
  pages={122136--122158},
  year={2022},
  publisher={IEEE}
}
@inproceedings{qi2023diffdance,
  title={Diffdance: Cascaded human motion diffusion model for dance generation},
  author={Qi, Qiaosong and Zhuo, Le and Zhang, Aixi and Liao, Yue and Fang, Fei and Liu, Si and Yan, Shuicheng},
  booktitle={Proceedings of the 31st ACM International Conference on Multimedia},
  pages={1374--1382},
  year={2023}
}