\documentclass[letterpaper, journal, twoside]{IEEEtran}

\IEEEoverridecommandlockouts % This command is only needed if you want to use the \thanks command

\usepackage{graphics} % for pdf, bitmapped graphics files
\usepackage{epsfig} % for postscript graphics files
\usepackage{amsmath} % assumes amsmath package installed
\usepackage{amssymb} % assumes amsmath package installed

\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}
\renewcommand{\arraystretch}{1.1}

\usepackage{epstopdf}

\usepackage{verbatim}
\let\proof\relax 
\let\endproof\relax
\usepackage{amsthm}

\usepackage{color}
\usepackage{cancel}

\usepackage{enumitem}

\usepackage{tikz} 
\usepgflibrary{arrows}

\pagestyle{empty} 

\usepackage{hyperref}

\usepackage[normalem]{ulem}
\usepackage{enumitem}

\newtheorem{assumption}{\bf Assumption}
\newtheorem{definition}{\bf Definition}
\newtheorem{theorem}{\bf Theorem}
\newtheorem{proposition}{\bf Proposition}
\newtheorem{lemma}{\bf Lemma}
\newtheorem{corollary}{\bf Corollary}
\newtheorem{remark}{\bf Remark}

\usepackage{cite}

\usepackage{enumitem}

\renewcommand{\qedsymbol}{$\blacksquare$}

\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\myset}[2]{\left\{#1\,\left|\, #2\right.\right\}}
\newcommand{\nnorm}[1]{\lVert#1\rVert}

\begin{document}
\title{Stochastic MPC with Online-optimized Policies and Closed-loop Guarantees}
\author{
Marcell Bartos, Alexandre Didier, Jerome Sieber, Johannes K\"ohler$^\dagger$, Melanie N. Zeilinger$^\dagger$
\thanks{$^\dagger$: joint supervision. All authors are with the Institute for Dynamic Systems and Control, ETH Zurich, 8092 ZÃ¼rich, Switzerland (e-mail: [mbartos, adidier, jsieber, jkoehle, mzeilinger]@ethz.ch). Johannes K\"ohler has been supported by the Swiss National Science Foundation under NCCR Automation (grant agreement 51NF40 180545).}
}

\maketitle
\thispagestyle{empty}
\begin{abstract} 
This paper proposes a stochastic model predictive control method for linear systems affected by additive Gaussian disturbances. Closed-loop satisfaction of probabilistic constraints and recursive feasibility of the underlying convex optimization problem is guaranteed. Optimization over feedback policies online increases performance and reduces conservatism compared to fixed-feedback approaches. The central mechanism is a finitely determined maximal admissible set for probabilistic constraints, together with the reconditioning of the predicted probabilistic constraints on the current knowledge at every time step. The proposed method's reduced conservatism and improved performance in terms of the achieved closed-loop cost is demonstrated in a numerical example.
\end{abstract}
\begin{IEEEkeywords}
Predictive control for linear systems, chance constraints, stochastic optimal control, constrained control
\end{IEEEkeywords}

\section{Introduction}
Model predictive control (MPC)~\cite{rawlings2017model, kouvaritakis2016model} is a powerful approach for the optimal control of constrained systems, by solving shorter, finite horizon optimization problems in a receding horizon manner. For deterministic systems, MPC offers strong theoretical guarantees in terms of constraint satisfaction, stability, and performance.

However, ensuring constraint satisfaction for stochastic dynamical systems is challenging. To address this issue, stochastic MPC (SMPC) schemes~\cite{farina2016stochastic, mesbah2016stochastic} consider a probabilistic description of the uncertainty and enforce safety-critical constraints with a user-chosen probability.
In this work, we propose an SMPC scheme for linear time-invariant systems affected by additive Gaussian disturbances that
\begin{enumerate}[label=\emph{\alph*})]
    \item guarantees recursive feasibility and satisfaction of the chance constraints in closed loop, \label{req:guarantees}
    \item and improves performance by using online-optimized affine feedback policies, while preserving convexity. \label{req:optimized_feedback}
\end{enumerate}
\subsubsection*{Related work} 
If the support of the distribution of the disturbance is bounded, recursive feasibility of SMPC optimization problems can be ensured by adopting robust constraint tightening approaches, see, e.g.,~\cite{cannon2010stochastic, lorenzen2016constraint}. However, in the unbounded support case (such as the Gaussian distribution considered in this paper), guaranteeing recursive feasibility becomes nontrivial~\cite{farina2016stochastic, ono2012joint}.
A common solution is to use recovery mechanisms~\cite{farina2013probabilistic}, or soften the constraints~\cite{paulson2020stochastic}, but this often leads to the loss of closed-loop chance constraint satisfaction guarantees, unless stronger assumptions are used~\cite{hewing2018stochastic, kohler2022recursively, schluter2022stochastic}.
In contrast,~\cite{hewing2020recursively, arcari2023stochastic, mark2024stochastic} achieve~\ref{req:guarantees} by introducing feedback only indirectly, via the cost function. These methods do not initialize the predicted trajectories that enter the online constraints based on the measurements, i.e., they do not \emph{recondition} on current knowledge.
All of the aforementioned methods that achieve~\ref{req:guarantees} rely on offline-designed feedback policies to construct probabilistic reachable sets, and thus they do not offer~\ref{req:optimized_feedback}, which limits their performance.
\par As for requirement~\ref{req:optimized_feedback}, optimization over linear state feedback policies in MPC can be written as a convex problem using a parameterization in terms of disturbance feedbacks~\cite{goulart2006optimization} or equivalently by using the system level parameterization~\cite{anderson2019system}.
Corresponding SMPC schemes with online optimized policies have been proposed in~\cite{oldewurtel2008tractable, prandini2012randomized, mark2022recursively, pan2023data, li2024distributionally, knaup2024recursively}.
However,~\cite{oldewurtel2008tractable} can only guarantee recursive feasibility for bounded disturbances,~\cite{prandini2012randomized} does not provide recursive feasibility guarantees, and~\cite{mark2022recursively, pan2023data, li2024distributionally, knaup2024recursively} utilize a recovery mechanism to ensure recursive feasibility, but they do not guarantee chance constraint satisfaction for the closed-loop system.
That is, while these methods achieve~\ref{req:optimized_feedback}, they do not achieve~\ref{req:guarantees}. 
\par Overall, to the authors' best knowledge, there does not exist an SMPC scheme in the literature that can address requirements~\ref{req:guarantees}--\ref{req:optimized_feedback} simultaneously.
Furthermore, existing SMPC schemes with closed-loop guarantees cannot be directly extended to use online-optimized feedback.
In particular, the constraint satisfaction guarantees of~\cite{hewing2020recursively, arcari2023stochastic, mark2024stochastic} heavily rely on the independent evolution of the closed-loop error from the optimization problem, while unimodality of its distribution is utilized in~\cite{hewing2018stochastic, kohler2022recursively, schluter2022stochastic}. In case of receding horizon SMPC using online-optimized feedback, the feedback matrices become random variables, meaning that the error is neither unimodal nor independent from the optimization problem.
\subsubsection*{Contribution}
This paper proposes a novel SMPC scheme for linear systems affected by additive Gaussian disturbances that uses online-optimized feedback policies, while ensuring recursive feasibility, closed-loop chance constraint satisfaction, and bounded asymptotic average cost. This is achieved via three technical contributions.
\begin{enumerate}
    \item We propose a general receding horizon reconditioning SMPC formulation, based on the shrinking horizon formulation of~\cite{wang2021recursive}, where the probabilistic constraints are reconditioned on all past disturbances at every time step.
    \item Inspired by~\cite{li2021chance}, we construct a finitely determined maximal admissible set for probabilistic constraints that can function as the terminal set of SMPC problems with online-optimized feedback.
    \item We formulate a tractable SMPC scheme that optimizes over linear causal feedback policies online (achieving~\ref{req:optimized_feedback}), while also addressing~\ref{req:guarantees}.
\end{enumerate}

\subsubsection*{Outline}
Section~\ref{sec:preliminaries} contains the problem setup and preliminaries on convex optimization over feedback policies. In Section~\ref{sec:DMC}, we formulate a finite horizon optimal control problem that yields a sequence of optimized policies that guarantee chance constraint satisfaction for all times. Then, we present a general receding horizon SMPC framework using the concept of reconditioning in Section~\ref{sec:reconditioning}. Building on the previous two sections, Section~\ref{sec:RHC} contains the proposed receding horizon scheme that resolves the optimization problem at every time step, along with a theoretical closed-loop analysis. Then, the proposed approach is compared to the indirect feedback approach of~\cite{hewing2020recursively} on a numerical example in Section~\ref{sec:numerical}, followed by a conclusion in Section~\ref{sec:conclusion}. Finally, some proofs and auxiliary results can be found in the Appendix.

\section{Setup and Preliminaries} \label{sec:preliminaries}
After a summary of the used notation, the problem setup is presented, which is followed by a brief summary of relevant results from system level synthesis.

\subsection{Notation}
The set of positive (non-negative) reals is denoted by $\mathbb{R}_{> 0}$ ($\mathbb{R}_{\geq 0}$), the set of integers bigger (not smaller) than $a \in \mathbb{R}$ is denoted by $\mathbb{I}_{> a}$ ($\mathbb{I}_{\geq a}$), and the set of integers in the interval $[a, b]$ is denoted by $\mathbb{I}_{[a, b]}$. The interior of set $\mathcal{A}$ is denoted by $\mathrm{int}(\mathcal{A})$.
$I_n$ represents the $n\times n$ identity matrix, positive (semi-)definiteness of a matrix $A$ is indicated by $A\succ(\succeq)\ 0$, and the Kronecker product of two matrices is denoted by $\otimes$. For a square matrix $A$, $\mathrm{tr}(A)$ and $\rho(A)$ denote its trace and spectral radius, respectively. The 2-norm of vector $x$ is denoted by $\norm{x}$, while $\norm{x}_P := \sqrt{x^\top P x}$ for $P = P^\top \succeq 0$. For a real matrix $B$, $\norm{B} := \sqrt{\rho(B^\top B)}$. For $0 \preceq \Sigma = \Sigma^\top \in \mathbb{R}^{n\times n}$, $\Sigma^{1/2}$ is the unique matrix that satisfies $\Sigma^{1/2} = \Sigma^{1/2,\top} \succeq 0,\ \Sigma^{1/2}\Sigma^{1/2} = \Sigma$. For a sequence of vectors $\{a_i\}$, $a_{j:k}$ denotes the stacked vector $\begin{bmatrix} a_j^\top & ... & a_k^\top\end{bmatrix}^\top$, and we use the convention that $\sum_{i=j}^k a_i = 0$, whenever $k<j$. The vectorization of a matrix $B \in \mathbb{R}^{n\times m}$ is denoted by $\mathrm{vec}(B) \in \mathbb{R}^{nm}$, which is obtained by stacking the columns of $B$ on top of one another. We sometimes use the abbreviation $XAX^\top = XA[*]^\top$ for symmetric matrix expressions. If $x$ is a decision variable in an optimization problem, $x^\star$ denotes its optimal value. By $x_{i|k}$ we denote the prediction of a variable $x$ computed at time $k$ for $i$ steps in the future, i.e., for time step $k+i$. The probability of some event $A$ and its conditional probability conditioned on event $B$ is denoted by $\mathrm{Pr}[A]$ and $\mathrm{Pr}[A | B]$, respectively. Similarly, for random variables $x$ and $y$, $\mathbb{E}[x]$, $\mathbb{E}[x|y]$, $\mathrm{Var}[x]$, $\mathrm{Var}[x|y]$, $p(x)$, $p(x|y)$ refer to the (conditional) expected value, variance, and probability density function, respectively. The multivariate normal distribution with mean $\mu \in \mathbb{R}^n$ and variance $0 \preceq \Sigma = \Sigma^\top \in \mathbb{R}^{n\times n}$ is denoted by $\mathcal{N}(\mu, \Sigma)$, while $\chi^2(\cdot)$ denotes the inverse cumulative distribution function of the chi-squared distribution with a single degree of freedom.

\subsection{Problem Setup}
We consider a discrete-time linear time-invariant system that is affected by additive independent and identically distributed (i.i.d.) zero-mean Gaussian disturbances with variance $\Sigma^\mathrm{w}\succ~0$:
\begin{equation} \label{eq:system}
    x_{k+1} = A x_k + B u_k + w_k, \quad w_k~\sim~\mathcal{N}(0, \Sigma^\mathrm{w})
\end{equation}
with state $x_k \in \mathbb{R}^n$, input $u_k \in \mathbb{R}^m$, disturbance $w_k \in \mathbb{R}^n$, time $k \in \mathbb{I}_{\geq 0}$, and stabilizable pair $(A,B)$. We assume that the state can be directly measured. The system is subject to half-space chance constraints
\begin{equation} \label{eq:chance_constraints}
    \mathrm{Pr}[(x_k, u_k) \in \mathcal{C}^j] \geq p^j,\ \forall j \in \mathbb{I}_{[1,c]},\ \forall k \in \mathbb{I}_{\geq 0},
\end{equation}
with user-defined probability $p^j \in (0.5,1)$ and
\begin{equation*}
    \mathcal{C}^j = \myset{(x,u) \in \mathbb{R}^n \times \mathbb{R}^m}{G_jx + H_ju \leq b_j },
\end{equation*}
where $G_j$, $H_j$, and $b_j$ denote the $j$-th row of $G \in \mathbb{R}^{c\times n}$, $H \in \mathbb{R}^{c\times m}$, and $b \in \mathbb{R}^{c}_{> 0}$, respectively. The goal is to satisfy~\eqref{eq:chance_constraints}, while minimizing the sum of the expected value of the quadratic stage cost
\begin{equation*}
    \ell(x, u) = \norm{x}^2_Q + \norm{u}^2_R
\end{equation*}
over an infinite horizon, where $Q, R \succeq 0$.
\par The corresponding stochastic optimal control problem initialized at some known deterministic state $x_0$ is then given by
\begin{subequations} \label{eq:ideal_ocp}
    \begin{align}
        \min_{\pi_:} \quad &\mathbb{E}\left[\sum_{k=0}^\infty \ell(x_k, u_k) \right] \label{eq:ideal_ocp:cost}\\
        \text{s.t.} \quad
        &u_k = \pi_k(x_{0:k}, w_{0:k-1}), \\
        &\eqref{eq:system},\ \eqref{eq:chance_constraints},\ \forall k \in \mathbb{I}_{\geq 0},
    \end{align}
\end{subequations}
where $\pi_: := \{\pi_k\}_{k=0}^\infty$ denotes the sequence of causal control policies. However, solving such an optimization problem is intractable in general~\cite{kouvaritakis2016model}, due to the presence of an infinite number of optimization variables and constraints, and due to the fact that~\eqref{eq:ideal_ocp} optimizes over arbitrary causal policies $\pi_k$. In order to overcome these challenges, we propose a stochastic MPC scheme that approximates~\eqref{eq:ideal_ocp}, resulting in a feasible but suboptimal policy. In particular, the former issue is addressed in Sections~\ref{sec:DMC} and~\ref{sec:RHC} by considering a finite horizon approximation of the problem, and the latter issue is addressed by restricting the considered policies to the class of causal linear feedback laws, see Section~\ref{sec:SLP}.

\subsection{System Level Parameterization} \label{sec:SLP}
Next, we show how to leverage the system level parameterization~\cite{anderson2019system} (or equivalently disturbance feedback~\cite{goulart2006optimization}) to propagate uncertainty and optimize feedback policies in a convex manner.
\par Consider a finite horizon with length $N \in \mathbb{I}_{> 0}$ and define the nominal system that evolves in a disturbance-free manner as
\begin{equation*}
    z_{k+1} = A z_k + B v_k,
\end{equation*}
initialized at $z_0 = x_0$, where $z_k \in \mathbb{R}^n$ and $v_k \in \mathbb{R}^m$ denote the nominal state and input at time $k$, respectively. After defining the error system
\begin{equation*}
    e^\mathrm{x}_{k+1} = A e^\mathrm{x}_k + B e^\mathrm{u}_k + w_k,\  e^\mathrm{x}_0 = 0,
\end{equation*}
where $x_k = z_k + e^\mathrm{x}_k$ and $u_k = v_k + e^\mathrm{u}_k$, we consider the feedback parameterization
\begin{equation} \label{eq:e^u_k}
    e^\mathrm{u}_k = \sum_{i=1}^k \Phi^\mathrm{u}_{k,i} w_{i-1},
\end{equation}
in which case the resulting error trajectory can be expressed as
\begin{equation} \label{eq:e^x_k}
    e^\mathrm{x}_k = \sum_{i=1}^k \Phi^\mathrm{x}_{k,i} w_{i-1},
\end{equation}
where the system response $\Phi^\mathrm{x}_{k,i}$ evolves according to
\begin{equation} \label{eq:SLP}
    \Phi^\mathrm{x}_{k+1,i} = A \Phi^\mathrm{x}_{k,i} + B \Phi^\mathrm{u}_{k,i},\ \Phi^\mathrm{x}_{k,k} = I,\ \forall i \in \mathbb{I}_{[1,k]} \forall k \in \mathbb{I}_{[1,N]}
\end{equation}
which is commonly referred to as the system level parameterization (SLP). As~\eqref{eq:SLP} is an affine constraint in the system response matrices, we can leverage the SLP to formulate convex optimization problems that simultaneously optimize the system responses and thereby the disturbance feedback.


\section{Stochastic Optimal Control} \label{sec:DMC} 

In the following, a tractable approximation of the infinite horizon optimal control problem~\eqref{eq:ideal_ocp} is presented,
where the prediction horizon is divided into two parts. In the first part, a finite prediction horizon $N\in\mathbb{I}_{>0}$ is used over which the affine policy is optimized (see Section~\ref{sec:Mode_1}). As for the infinite-horizon tail, a fixed linear feedback is applied, which, using the maximal probabilistic admissible set designed in Section~\ref{sec:Mode_2}, is able to guarantee chance constraint satisfaction for the infinite horizon. The resulting finite horizon optimal control problem is summarized in Section~\ref{sec:FHOCP}, which forms the basis for the receding horizon control scheme presented later, in Section~\ref{sec:RHC}.

\subsection{Probabilistic Constraints with Optimized Feedback} \label{sec:Mode_1}

Consider system~\ref{eq:system} subject to chance constraints~\ref{eq:chance_constraints}, and the SLP presented in Section~\ref{sec:SLP}:
\begin{equation} \label{eq:SLP:ux}
    \begin{split}
    u_{i|0} &= v_{i|0} + e^\mathrm{u}_{i|0},\ \forall i \in \mathbb{I}_{[0,N-1]},\\
    x_{i|0} &= z_{i|0} + e^\mathrm{x}_{i|0},\ \forall i \in \mathbb{I}_{[0,N]},
    \end{split}
\end{equation}
where $e^\mathrm{u}_{i|0}$ and $e^\mathrm{x}_{i|0}$ are defined in~\eqref{eq:e^u_k},~\eqref{eq:e^x_k}. Due to the i.i.d. Gaussian assumption on the disturbance sequence, $x_{i|0}$ and $u_{i|0}$ are Gaussian random variables with means
\begin{align*}
    \mathbb{E}[u_{i|0}] &= v_{i|0},\ \forall i \in \mathbb{I}_{[0,N-1]},\\
    \mathbb{E}[x_{i|0}] &= z_{i|0},\ \forall i \in \mathbb{I}_{[0,N]},
\end{align*}
and the variance of the joint distribution is given by
\begin{equation*}
    \mathrm{Var}[[x_{i|0}^\top, u_{i|0}^\top]^\top] = \begin{bmatrix}
        \mathbf{\Phi}^\mathrm{x}_{i|0} \\ \mathbf{\Phi}^\mathrm{u}_{i|0}
    \end{bmatrix} \mathbf{\Sigma}^\mathrm{w}_i \begin{bmatrix}
        \mathbf{\Phi}^{\mathrm{x}\top}_{i|0} & \mathbf{\Phi}^{\mathrm{u}\top}_{i|0}
    \end{bmatrix},\ \forall i \in \mathbb{I}_{[0,N-1]},
\end{equation*}
where $\mathbf{\Sigma}^\mathrm{w}_i = I_i \otimes \Sigma^\mathrm{w}$ and
\begin{align*}
    \mathbf{\Phi}^\mathrm{x}_{i|0} &= \begin{bmatrix} \Phi^\mathrm{x}_{i,1|0} & ... & \Phi^\mathrm{x}_{i,i|0}\end{bmatrix},\\
    \mathbf{\Phi}^\mathrm{u}_{i|0} &= \begin{bmatrix} \Phi^\mathrm{u}_{i,1|0} & ... & \Phi^\mathrm{u}_{i,i|0}\end{bmatrix}.
\end{align*}

The following lemma provides an exact reformulation of the probabilistic half-space chance constraints~\eqref{eq:chance_constraints} as equivalent tightened deterministic constraints on the means.
\begin{lemma} \label{lem:SOC_reform}
    Consider the parameterization~\eqref{eq:SLP:ux}. Then, the chance constraint
    \begin{equation} \label{eq:chance_constraint_j}
        \mathrm{Pr}[(x_{i|0}, u_{i|0}) \in \mathcal{C}^j] \geq p^j
    \end{equation}
    is equivalent to the second-order cone constraint
    \begin{equation} \label{eq:SOC_k=0_Psi}
    \begin{split}
         G_j z_{i|0} &+ H_j v_{i|0} \leq b_j \\&- \sqrt{\tilde{p}^j} \norm{\mathbf{\Sigma}^{\mathrm{w},1/2}_i \begin{bmatrix} \mathbf{\Phi}^{\mathrm{x}\top}_{i|0} & \mathbf{\Phi}^{\mathrm{u}\top}_{i|0}\end{bmatrix} \begin{bmatrix} G_j^\top \\ H_j^\top \end{bmatrix}}
    \end{split}
    \end{equation}
    which is further equivalent to
    \begin{equation} \label{eq:SOC_k=0}
    \begin{split}
        G_j z_{i|0} &+ H_j v_{i|0} \leq b_j \\ &- \sqrt{\tilde{p}^j} \norm{\left(\begin{bmatrix} G_j & H_j \end{bmatrix} \otimes \mathbf{\Sigma}^{\mathrm{w},1/2}_i\right) \psi_{i|0}}.
    \end{split}
    \end{equation}
     where $\tilde{p}^j := \chi^2(2p^j-1)$ and $\psi_{i|0} := \mathrm{vec}\left(\begin{bmatrix} \mathbf{\Phi}^{\mathrm{x}\top}_{i|0} & \mathbf{\Phi}^{\mathrm{u}\top}_{i|0}\end{bmatrix}\right)$.
\end{lemma}
\begin{proof}
    A probabilistic half-space constraint of the form
    \begin{equation*}
        \mathrm{Pr}[h^\top y \leq g] \geq p_\mathrm{y},
    \end{equation*}
    with $y \sim \mathcal{N}(\mu_\mathrm{y}, \Sigma_\mathrm{y}),\ y \in \mathbb{R}^{n_\mathrm{y}}$, $h \in  \mathbb{R}^{n_\mathrm{y}}$, $g \in \mathbb{R}$, and $p_\mathrm{y} \in [0.5, 1)$ is equivalent to
    \begin{equation*}
        h^\top \mu_\mathrm{y} \leq g - \sqrt{\chi^2(2p_\mathrm{y}-1)}\sqrt{h^\top \Sigma_\mathrm{y} h},
    \end{equation*}
    see, e.g.,~\cite{hewing2020recursively}. Applying this result to~\eqref{eq:chance_constraint_j} combined with~\eqref{eq:SLP:ux} results in~\eqref{eq:SOC_k=0_Psi}. Furthermore, using
    \begin{equation*}
        \mathrm{vec}(ABC) = (C^\top \otimes A) \mathrm{vec}(B),
    \end{equation*}
    we obtain
    \begin{equation*}
    \begin{split}
       \mathbf{\Sigma}^{\mathrm{w},1/2}_i& \begin{bmatrix} \mathbf{\Phi}^{\mathrm{x}\top}_{i|0} & \mathbf{\Phi}^{\mathrm{u}\top}_{i|0}\end{bmatrix} \begin{bmatrix} G_j^\top \\ H_j^\top \end{bmatrix} \\ &= \mathrm{vec}\left(\mathbf{\Sigma}^{\mathrm{w},1/2}_i \begin{bmatrix} \mathbf{\Phi}^{\mathrm{x}\top}_{i|0} & \mathbf{\Phi}^{\mathrm{u}\top}_{i|0}\end{bmatrix} \begin{bmatrix} G_j^\top \\ H_j^\top \end{bmatrix}\right) \\
        &= \left(\begin{bmatrix} G_j & H_j \end{bmatrix} \otimes \mathbf{\Sigma}^{\mathrm{w},1/2}_i\right) \mathrm{vec}\left(\begin{bmatrix} \mathbf{\Phi}^{\mathrm{x}\top}_{i|0} & \mathbf{\Phi}^{\mathrm{u}\top}_{i|0}\end{bmatrix}\right) \\
        & = \left(\begin{bmatrix} G_j & H_j \end{bmatrix} \otimes \mathbf{\Sigma}^{\mathrm{w},1/2}_i\right) \psi_{i|0},
    \end{split}
    \end{equation*}
    and thus the equivalence of~\eqref{eq:SOC_k=0} and~\eqref{eq:SOC_k=0_Psi} is proven.
\end{proof}
\begin{remark}
    With a slight abuse of notation, for $i=0$ the matrices $\mathbf{\Phi}^\mathrm{x}_{0|0}$ and $\mathbf{\Phi}^\mathrm{u}_{0|0}$ are `empty', in which case~\eqref{eq:SOC_k=0_Psi} results in an untightened half-space constraint on $z_{0|0}$ and $v_{0|0}$.
\end{remark}

\subsection{Probabilistic Constraints with Terminal Controller} \label{sec:Mode_2}
In order to ensure that the number of decision variables is finite, a fixed stabilizing linear state feedback $K$ is used in the tail of the horizon:
\begin{equation} \label{eq:Mode_2_terminal_controller}
    u_{N+i|0} = Kx_{N+i|0},\ \forall i \in \mathbb{I}_{\geq 0},
\end{equation}
where $K \in \mathbb{R}^{m\times n}$ is chosen such that $A_K := A + BK$ is Schur stable. Therefore,
\begin{align*}
    \mathbb{E}[u_{N+i|0}] &= KA_K^iz_{N|0},\ \forall i \in \mathbb{I}_{\geq 0},\\
    \mathbb{E}[x_{N+i|0}] &= A_K^iz_{N|0},\ \forall i \in \mathbb{I}_{\geq 0},
\end{align*}
and
\begin{equation*}
\begin{split}
    \mathrm{Var}[[x_{N+i|0}^\top,&\, u_{N+i|0}^\top]^\top] = \\ &\begin{bmatrix}
        I_n \\ K
    \end{bmatrix}\begin{bmatrix}
        A_K^i\mathbf{\Phi}^\mathrm{x}_{N|0} & I_n
    \end{bmatrix} \begin{bmatrix}
        \mathbf{\Sigma}^\mathrm{w}_N & \\ & \Sigma^\mathrm{x}_i
    \end{bmatrix} [*]^\top,
\end{split}
\end{equation*}
where $\Sigma^\mathrm{x}_i$ is defined by the recursion
\begin{equation*}
    \Sigma^\mathrm{x}_{i+1} = A_K\Sigma^\mathrm{x}_iA_K^\top + \Sigma^\mathrm{w},\ \Sigma^\mathrm{x}_0 = 0.
\end{equation*}
Note that since $A_K$ is Schur stable, the
limit $\lim_{i \rightarrow \infty} \Sigma^\mathrm{x}_i = \Sigma^\mathrm{x}_\infty$ exists, and it is given by the Lyapunov equation
\begin{equation*}
    \Sigma^\mathrm{x}_\infty = A_K \Sigma^\mathrm{x}_\infty A_K^\top + \Sigma^\mathrm{w}.
\end{equation*}
\par Following similar arguments to Lemma~\ref{lem:SOC_reform}, the chance constraint
\begin{equation} \label{eq:chance_constraint_tail}
    \mathrm{Pr}[(x_{N+i|0}, u_{N+i|0}) \in \mathcal{C}^j] \geq p^j,
\end{equation}
is equivalent to the second-order cone constraint
\begin{equation} \label{eq:SOC_k=0_tail_psi}
    G_{K,j} A_K^i z \leq b_j - \sqrt{\tilde{p}^j} \norm{\begin{bmatrix}
        \left( G_{K,j} A_K^i \otimes \mathbf{\Sigma}^{\mathrm{w},1/2}_N\right) \psi\\ \Sigma_i^{\mathrm{x},1/2} G_{K,j}^\top
    \end{bmatrix}},
\end{equation}
where $G_{K,j}$ is the $j$-th row of $G_K = G + HK \in \mathbb{R}^{c \times n}$, $z := z_{N|0}$ is used for notational convenience, and $\psi := \mathrm{vec}(\mathbf{\Phi}^{\mathrm{x}\top}_{N|0})$. As~\eqref{eq:SOC_k=0_tail_psi} needs to hold for all $i \in \mathbb{I}_{\geq 0}$, the number of constraints is infinite. We address this issue by proving that imposing a finite subset of the constraints is equivalent to imposing all infinite constraints. 
\par
Consider the tightened version of inequality~\eqref{eq:SOC_k=0_tail_psi}:
\begin{equation}
     G_{K,j} A_K^i z \leq b_j - \sqrt{\tilde{p}^j} \norm{\begin{bmatrix}
        \left( G_{K,j} A_K^i \otimes \mathbf{\Sigma}^{\mathrm{w},1/2}_N\right) \psi\\ \Sigma_\infty^{\mathrm{x},1/2} G_{K,j}^\top
    \end{bmatrix}}, \label{eq:SOC_k=0_tail_psi_tightened}
\end{equation}
where $\Sigma^\mathrm{x}_i$ has been replaced by $\Sigma^\mathrm{x}_\infty \succeq \Sigma^\mathrm{x}_i$. Let
\begin{align*}
    \mathcal{D}_i = \myset{(z, \psi)}{\eqref{eq:SOC_k=0_tail_psi} \text{ holds for }i,\ \forall j \in \mathbb{I}_{[1, c]}}, \\
    \bar{\mathcal{D}}_i = \myset{(z, \psi)}{\eqref{eq:SOC_k=0_tail_psi_tightened} \text{ holds for }i,\ \forall j \in \mathbb{I}_{[1, c]}},
\end{align*}
and define the $i$-step maximal admissible set for probabilistic constraints~\eqref{eq:chance_constraint_tail} via the recursion
\begin{equation} \label{eq:S_sequence}
    \mathcal{S}_i = \mathcal{S}_{i-1} \cap \mathcal{D}_i,\quad \mathcal{S}_0 = \mathcal{D}_0.
\end{equation}
Finally, the maximal admissible set is defined as
\begin{equation*}
    \mathcal{S}_\infty = \myset{(z, \psi)}{\eqref{eq:SOC_k=0_tail_psi} \text{ holds}\ \forall i \in \mathbb{I}_{\geq 0}, \forall j \in \mathbb{I}_{[1, c]}}.
\end{equation*}
Note that sequence~\eqref{eq:S_sequence} converges to $\mathcal{S}_\infty$ and 
$\mathcal{S}_\infty \subseteq \mathcal{S}_i \subseteq \mathcal{S}_{i-1}$. Using $\bar{\mathcal{D}}_i$, sets $\bar{\mathcal{S}}_i$ and $\bar{\mathcal{S}}_\infty$ are defined analogously.
\begin{assumption} \label{ass:L}
    Consider the decomposition $G = LC$ and $H = LD$, where $L \in \mathbb{R}^{c\times d}$, $C \in \mathbb{R}^{d\times n}$, $D \in \mathbb{R}^{d\times m}$. We assume that the set $\mathcal{L} = \myset{y \in \mathbb{R}^d}{Ly\leq b}$ is bounded, and the pair $(C_K, A_K)$ is observable, where $A_K = A + BK$ and $C_K = C + DK$ for the stabilizing terminal feedback gain $K$. Finally,
    \begin{equation} \label{eq:b_j-norm>0}
        b_j -  \sqrt{\tilde{p}^j}\norm{\Sigma_\infty^{\mathrm{x},1/2} C_K^\top L_j^\top} > 0,\ \forall j \in \mathbb{I}_{[1,c]}.
    \end{equation}
    where $L_j$ denotes the $j$-th row of $L$.
\end{assumption}
\begin{remark} \label{rem:L_decomposition}
    The decomposition in Assumption~\ref{ass:L} naturally occurs whenever the system is subject to polytopic constraints with respect to the lower dimensional variable $y = Cx + Du$. Furthermore, note that $(x,Kx) \in \cap_{j=1}^c \mathcal{C}^j \iff C_K x \in \mathcal{L}$. The boundedness of $\mathcal{L}$ is a standard technical assumption in the maximal admissible set literature~\cite{gilbert1991linear}.
\end{remark}
\begin{remark}
    If~\eqref{eq:b_j-norm>0} does not hold, then applying the linear feedback $K$ does not ensure constraint satisfaction, even when initialized at $x=0$. Note that a similar condition is required by any SMPC approach using a fixed feedback, e.g.,~\cite{hewing2018stochastic, hewing2020recursively, schluter2022stochastic, kohler2022recursively}. A convex optimization problem that produces a suitable $K$ is presented in Appendix~\ref{app:K_design}.
\end{remark}

\begin{theorem}[Finitely determined terminal set] \label{thm:terminal_set}
    Suppose Assumption~\ref{ass:L} holds. Then, the maximal admissible set $\mathcal{S}_\infty$ is finitely determined, i.e., there exists $\mu \in \mathbb{I}_{\geq 0}$ such that $\mathcal{S}_\infty = \mathcal{S}_\mu$. Furthermore, the finite determination index $\mu$ is the smallest non-negative integer that satisfies
    \begin{equation} \label{eq:terminal_set_Smu_inclusion}
        \mathcal{S}_\mu \subseteq \bigcap_{i=\mu+1}^\infty \bar{\mathcal{D}}_i.
    \end{equation}
\end{theorem}
\begin{proof}
    The proof can be found in Appendix~\ref{app:terminal_set_proof}.
\end{proof}

While Theorem~\ref{thm:terminal_set} ensures the existence of index $\mu$, its computation involves checking the set inclusion~\eqref{eq:terminal_set_Smu_inclusion}, which is non-trivial, as the right hand side is an intersection of an infinite number of sets. In order to address this, we propose Algorithm~\ref{alg:terminal_set} for finding $\mu$, leveraging results on maximal admissible sets~\cite[Sec.~III--IV]{gilbert1991linear}.

\begin{algorithm}
\caption{Terminal set design} \label{alg:terminal_set}
\begin{algorithmic}[1]
    \State Increase $\nu \in \mathbb{I}_{\geq 0}$ until $\bar{\mathcal{S}}_\nu \subseteq \bar{\mathcal{D}}_{\nu+1}$. \label{algstep:nu}
    \State Increase $\mu \in \mathbb{I}_{\geq 0}$ until $\mathcal{S}_\mu \subseteq \cap_{i=\mu+1}^{\nu+\mu+1}\bar{\mathcal{D}}_i$. \label{algstep:mu}
    \State Construct $\mathcal{S}_\mu$ according to~\eqref{eq:S_sequence}.
    \Ensure $\mathcal{S}_\mu$
\end{algorithmic}
\end{algorithm}

\begin{proposition} \label{prop:terminal_set_alg}
    Suppose Assumption~\ref{ass:L} holds. Then, Algorithm~\ref{alg:terminal_set} is guaranteed to terminate and the set $\mathcal{S}_\mu$ that it returns satisfies~\eqref{eq:terminal_set_Smu_inclusion}, and hence $\mathcal{S}_\mu = \mathcal{S}_\infty$.
\end{proposition}
\begin{proof}
    The proof can be found in Appendix~\ref{app:algorithm_proof}.
\end{proof}

\begin{remark} \label{rem:lossy_S_procedure}
    While Algorithm~\ref{alg:terminal_set} addresses the issue of computing the intersection of infinite number of sets in~\eqref{eq:terminal_set_Smu_inclusion}, the set inclusions in Steps~\ref{algstep:nu}--\ref{algstep:mu} are still challenging, as they require testing containment of second-order cones. We propose sufficient conditions utilizing the `lossy' S-procedure~\cite{boyd1994linear} in Appendices~\ref{app:finding_nu}--\ref{app:finding_mu}. However, if these sufficient conditions are used, then Algorithm~\ref{alg:terminal_set} may not terminate, which is a general issue when constructing maximal admissible sets for nonlinear constraints~\cite[Section~III]{gilbert1991linear}.
\end{remark}
\begin{remark} \label{rem:can_still_converge}
    Assumption~\ref{ass:L} is a sufficient but not necessary condition for the existence of a finite $\mu$, i.e., it is still possible that $\mathcal{S}_\infty$ is finitely determined, even when Assumption~\ref{ass:L} does not hold (e.g. when $\mathcal{L}$ is not bounded). In particular, if Algorithm~\ref{alg:terminal_set} converges, then $\mathcal{S}_\infty = \mathcal{S}_\mu$, i.e., the terminal set design is still successful, regardless of Assumption~\ref{ass:L}.
\end{remark}

\subsection{Proposed Optimization Problem} \label{sec:FHOCP}

Sections~\ref{sec:Mode_1} and~\ref{sec:Mode_2} presented an exact reformulation of the chance constraint~\eqref{eq:chance_constraints} in the first $N$ steps using optimized affine feedback, and in the infinite-horizon tail given the fixed linear controller~\eqref{eq:Mode_2_terminal_controller}, respectively. Using these results, this section will present the proposed approximation of~\eqref{eq:ideal_ocp}.
\par For predictions at a general time $k \in \mathbb{I}_{\geq 0}$, let $\mathbf{z}_k = z_{0:N|k}$, $\mathbf{v}_k = v_{0:N-1|k}$, and define $\mathbf{\Phi}^\mathrm{x}_{:|k}$ and $\mathbf{\Phi}^\mathrm{u}_{:|k}$ as block-lower-triangular matrices, where the $i$-th row of the lower triangular part is $\mathbf{\Phi}^\mathrm{x}_{i|k}$ and $\mathbf{\Phi}^\mathrm{u}_{i|k}$, respectively. Then, at $k=0$, we consider the following convex second-order cone program (SOCP):
\begin{subequations} \label{eq:DMC}
    \begin{align}
        \min_{\substack{\mathbf{z}_0, \mathbf{v}_0\\ \mathbf{\Phi}^\mathrm{x}_{:|0}, \mathbf{\Phi}^u_{:|0}}} \quad &J(\mathbf{z}_0, \mathbf{v}_0, \mathbf{\Phi}^\mathrm{x}_{:|0}, \mathbf{\Phi}^\mathrm{u}_{:|0})\\
        \text{s.t.} \quad\ \ 
        &z_{0|0} = x_0, \\
        &z_{i+1|0} = A z_{i|0} + B v_{i|0},\\
        &(z_{i|0}, v_{i|0}, \mathbf{\Phi}^\mathrm{x}_{i|0}, \mathbf{\Phi}^\mathrm{u}_{i|0}) \in \mathcal{C}_{i|0}, \label{eq:DMC:constraints_N}\\
        &(z_{N|0}, \mathrm{vec}(\mathbf{\Phi}^\mathrm{x}_{N|0})) \in \mathcal{S}_\mu, \label{eq:DMC:constraints_terminal}\\
        &\text{the SLP~\eqref{eq:SLP} is satisfied},\\
        &\forall i \in \mathbb{I}_{[0,N-1]},
    \end{align}
\end{subequations}
where
\begin{equation*}
    \mathcal{C}_{i|0} = \myset{(z_{i|0}, v_{i|0}, \mathbf{\Phi}^\mathrm{x}_{i|0}, \mathbf{\Phi}^\mathrm{u}_{i|0})}{\eqref{eq:SOC_k=0_Psi}\text{ is satisfied }\forall j \in \mathbb{I}_{[1,c]}},
\end{equation*}
and the cost function to be minimized is defined as
\begin{equation} \label{eq:J}
    \begin{split}
        J(\mathbf{z}_k,&\, \mathbf{v}_k, \mathbf{\Phi}^\mathrm{x}_{:|k}, \mathbf{\Phi}^\mathrm{u}_{:|k}) = \sum_{i=0}^{N-1}(\nnorm{z_{i|k}}^2_Q + \nnorm{v_{i|k}}^2_R) \\
        &+ \sum_{i=1}^{N-1}(\mathrm{tr}(Q\mathbf{\Phi}^\mathrm{x}_{i|k}\mathbf{\Sigma}^\mathrm{w}_i\mathbf{\Phi}^{\mathrm{x}\top}_{i|k}) + \mathrm{tr}(R\mathbf{\Phi}^\mathrm{u}_{i|k}\mathbf{\Sigma}^\mathrm{w}_i\mathbf{\Phi}^{\mathrm{u}\top}_{i|k})) \\ 
        &+ \nnorm{z_{N|k}}^2_P + \mathrm{tr}(P\mathbf{\Phi}^\mathrm{x}_{N|k}\mathbf{\Sigma}^\mathrm{w}_N\mathbf{\Phi}^{\mathrm{x}\top}_{N|k}),
    \end{split}
\end{equation}
where the terminal weight $P$ is the unique positive definite solution of the discrete-time Lyapunov equation
    \begin{equation} \label{eq:P_Lyapunov}
        A_K^\top P A_K + Q + K^\top R K = P.
    \end{equation}
\par After solving optimization problem~\eqref{eq:DMC} once at time step $k=0$, we apply
\begin{equation} \label{eq:dual_mode_law}
\begin{split}
    u_k &= v^\star_{k|0} + \sum_{j=1}^k \Phi^{\mathrm{u}\star}_{k,j|0} w_{j-1},\ \forall k \in \mathbb{I}_{[0, N-1]}, \\
    u_k &= K x_k,\ \forall k \in \mathbb{I}_{\geq N}.
\end{split}
\end{equation}
\begin{proposition}[Closed-loop chance constraint satisfaction and bounded asymptotic average cost.] \label{prop:DMC}
    Suppose that Assumption~\ref{ass:L} holds and optimization problem~\eqref{eq:DMC} is feasible. Then, system~\eqref{eq:system} controlled by policy~\eqref{eq:dual_mode_law} satisfies chance constraints~\eqref{eq:chance_constraints}. Furthermore, the asymptotic average cost is upper bounded by the performance of the static state feedback $K$:
    \begin{equation} \label{eq:lavg}
        \limsup_{T \rightarrow \infty} \frac{1}{T}\sum_{k=0}^{T-1}\mathbb{E}[\norm{x_k}_Q^2 + \norm{u_k}_R^2] \leq \mathrm{tr}(P\Sigma^\mathrm{w}).
    \end{equation}
\end{proposition}
\begin{proof}
    \textit{Part I: Closed-loop chance constraint satisfaction.} Constraint~\eqref{eq:DMC:constraints_N} corresponds to~\eqref{eq:SOC_k=0_Psi}, which is equivalent to the original chance constraint~\eqref{eq:chance_constraints} for $k \in \mathbb{I}_{[0,N-1]}$. Furthermore, the terminal constraint~\eqref{eq:DMC:constraints_terminal} ensures that the terminal controller satisfies~\eqref{eq:chance_constraints} $k \in \mathbb{I}_{\geq N}$, since it uses the terminal set $\mathcal{S}_\infty$ satisfying chance constraints~\eqref{eq:chance_constraints} by definition, due to the equivalence of~\eqref{eq:chance_constraint_tail} and~\eqref{eq:SOC_k=0_tail_psi}.
\par \textit{Part II: Bounded asymptotic average cost}. 
The expected cost incurred in the first $N$ steps is a finite number, and thus it does not contribute to the asymptotic average cost in the infinite limit. Furthermore, since $P$ satisfies the Lyapunov equation~\eqref{eq:P_Lyapunov}, the asymptotic average cost associated with the infinite tail can be shown to be bounded by $\mathrm{tr}(P\Sigma^\mathrm{w})$ (cf.~\cite[Chapter~8]{kouvaritakis2016model}).
\end{proof}

\par Since~\eqref{eq:DMC} is solved only once at time $k=0$, only the first $N$ control inputs use an optimized control policy. 
Furthermore, the control policy is not updated based on the information available up to the current time step (i.e. based on $w_{0:k-1}$).
This limitation is addressed in the following sections.

\section{General Reconditioning Framework for SMPC} \label{sec:reconditioning}

In the following, we present a general receding horizon reconditioning SMPC framework, which is then used in Section~\ref{sec:RHC} to propose the receding horizon implementation of the finite horizon optimization problem derived in Section~\ref{sec:DMC}. This method is inspired by~\cite{wang2021recursive}, where a shrinking horizon reconditioning SMPC is applied for the case of mission-wide (joint-in-time) state constraints. 
\par Although we consider linear time-invariant systems~\eqref{eq:system} with half-space chance constraints~\eqref{eq:chance_constraints}, the following exposition \textit{directly applies to general nonlinear systems} affected by i.i.d. disturbances subject to chance constraints, without any modifications.
\par An SMPC scheme is adopted that solves the following optimization problem at each time step $k \in \mathbb{I}_{\geq 0}$:
\begin{subequations} \label{eq:Rec-SMPC}
    \begin{align}
        \min_{\pi_{:|k}} \quad &\mathcal{J}(x_k, \pi_{:|k})\\
        \text{s.t.} \quad\, &x_{0|k} = x_k,\ u_{i|k} = \pi_{i|k}(w_{k:k+i-1}),\label{eq:Rec-SMPC:init}\\
        &\mathrm{Pr}[(x_{i|k}, u_{i|k}) \in \mathcal{C}^j | w_{0:k-1}] \geq p^j_{i|k},\label{eq:Rec-SMPC:constraints} \\
        &\eqref{eq:system},\ \forall j \in \mathbb{I}_{[1,c]},\ \forall i \in \mathbb{I}_{\geq 0},
    \end{align}
\end{subequations}
where $\mathcal{J}$ is some suitable cost function. The optimization is carried out over a sequence of causal policies $\pi_{:|k}$, where each policy $\pi_{i|k}$ maps the disturbances $w_{k:k+i-1}$ to a control input $u_{i|k}$ for $i \in \mathbb{I}_{> 0}$, and $\pi_{0|k} \in \mathbb{R}^m$ is a vector. Note that the state trajectory is initialized at $x_k$ in~\eqref{eq:Rec-SMPC:init}, and the probabilistic constraints~\eqref{eq:Rec-SMPC:constraints} condition on all available knowledge at time $k$, hence the name reconditioning SMPC. The required probability levels are also updated according to
\begin{equation} \label{eq:initial_prob}
    p^j_{i|0} = p^j
\end{equation}
and
\begin{equation} \label{eq:pjik}
    p^j_{i|k} = \mathrm{Pr}[(x^\star_{i+1|k-1}, u^\star_{i+1|k-1}) \in \mathcal{C}^j | w_{0:k-1}], \ \forall k \in \mathbb{I}_{> 0},
\end{equation}
$\forall j \in \mathbb{I}_{[1,c]},\ \forall i \in \mathbb{I}_{\geq 0}$. That is, at time $k \in \mathbb{I}_{>0}$, the probability that the policy sequence $\pi_{:|k}$ satisfies the constraints must not be lower than the probability achieved by $\pi^\star_{:|k-1}$, when conditioned on all realized disturbances $w_{0:k-1}$. Note that $\pi^\star_{:|k-1}$ was computed when $w_{k-1}$ has not been realized yet, so one can think of~\eqref{eq:pjik} as the constraint satisfaction probability achieved by the previous policy sequence in hindsight, knowing the value of the disturbance $w_{k-1}$. After solving the optimization problem, the first element of the optimal input sequence is applied to the system:
\begin{equation} \label{eq:Rec-SMPC:control_law}
    u_k = \pi^\star_{0|k} = u^\star_{0|k}.
\end{equation}
\begin{proposition}[Recursive feasibility and closed-loop chance constraint satisfaction of reconditioning SMPC] \label{prop:Rec-SMPC}
    Assume that~\eqref{eq:Rec-SMPC} is feasible at time step $k=0$. Then, problem~\eqref{eq:Rec-SMPC} remains feasible $\forall k \in \mathbb{I}_{\geq 0}$ for the closed-loop system resulting from applying feedback~\eqref{eq:Rec-SMPC:control_law} to system~\eqref{eq:system}, and the chance constraints~\eqref{eq:chance_constraints} are satisfied.
\end{proposition}
\begin{proof}
    The proof is inspired by~\cite[Proposition~1]{wang2021recursive}. \par \textit{Part I: Recursive feasibility.} Consider the candidate solution
    \begin{equation*}
        \hat{\pi}_{i|k}(\cdot) = \pi^\star_{i+1|k-1}(w_{k-1}, \cdot),
    \end{equation*}
    i.e., it is the same as $\pi^\star_{i+1|k-1}$ but the first argument is fixed to the realized value of disturbance $w_{k-1}$. Therefore,
    \begin{equation*}
        p(u_{i|k}| w_{0:k-1}) = p(u^\star_{i+1|k-1} | w_{0:k-1}),\quad \forall i \in \mathbb{I}_{\geq 0},
    \end{equation*}
    resulting in
    \begin{equation*}
        p(x_{i|k}| w_{0:k-1}) = p(x^\star_{i+1|k-1} | w_{0:k-1}),\quad \forall i \in \mathbb{I}_{\geq 0},
    \end{equation*}
    where $x_{i|k}$ and $x^\star_{i+1|k-1}$ are the state distributions resulting from the dynamics and from applying $\pi_{:|k}$ and $\pi^\star_{:|k-1}$, respectively. Consequently,
    \begin{align*}
         \mathrm{Pr}[(x_{i|k},&\, u_{i|k}) \in \mathcal{C}^j | w_{0:k-1}] =  \\ &= \mathrm{Pr}[(x^\star_{i+1|k-1}, u^\star_{i+1|k-1}) \in \mathcal{C}^j | w_{0:k-1}] = p^j_{i|k},
    \end{align*}
    $\forall j \in \mathbb{I}_{[1,c]}$, that is, the candidate solution satisfies all constraints in~\eqref{eq:Rec-SMPC}, proving recursive feasibility.
    \par \textit{Part II: Closed-loop chance constraint satisfaction.}
    Let $k \in \mathbb{I}_{> 0}$ and let $\mathbf{w}_k := w_{0:k-1}$. Then
    \begin{equation*}
        \begin{split}
            &\mathrm{Pr}[(x^\star_{i|k}, u^\star_{i|k}) \in \mathcal{C}^j]  \\&\stackrel{(*)}{=} \int \mathrm{Pr}[(x^\star_{i|k}, u^\star_{i|k}) \in \mathcal{C}^j | \mathbf{w}_k]\ p(\mathbf{w}_k)\ \mathrm{d}\mathbf{w}_k  \\
            &\stackrel{\eqref{eq:Rec-SMPC:constraints}}{\geq} \int p^j_{i|k}\ p(\mathbf{w}_k)\ \mathrm{d}\mathbf{w}_k \\
            &\stackrel{\eqref{eq:pjik}}{=} \int \mathrm{Pr}[(x^\star_{i+1|k-1}, u^\star_{i+1|k-1}) \in \mathcal{C}^j | \mathbf{w}_k]\ p(\mathbf{w}_k)\ \mathrm{d}\mathbf{w}_k  \\
            &\stackrel{(*)}{=} \mathrm{Pr}[(x^\star_{i+1|k-1}, u^\star_{i+1|k-1}) \in \mathcal{C}^j],
        \end{split}
    \end{equation*}
    $\forall j \in \mathbb{I}_{[1,c]},\ \forall i \in \mathbb{I}_{\geq 0}$, where $(*)$ is the law of total probability. Applying this procedure recursively for $i=0$ and using $x_{0|k} = x^\star_k$, $u_k = u^\star_{0|k}$, and $\eqref{eq:Rec-SMPC:constraints}$ together with~\eqref{eq:initial_prob} yields
    \begin{align*}
        \mathrm{Pr}[(x_k, u_k) \in \mathcal{C}^j] &= \mathrm{Pr}[(x^\star_{0|k}, u^\star_{0|k}) \in \mathcal{C}^j] \\ &\geq \mathrm{Pr}[(x^\star_{k|0}, u^\star_{k|0}) \in \mathcal{C}^j]  \geq p^j,\forall j \in \mathbb{I}_{[1,c]}. \qedhere
    \end{align*}
\end{proof}
\begin{remark} \label{rem:vanishing_constraints}
    An interesting consequence of using constraint~\eqref{eq:Rec-SMPC:constraints} is that it can happen that $p^j_{i|k} = 0$ for some specific $i$, $k$ and $j$, meaning that that constraint completely vanishes. This degenerate case can happen in particular for input constraints at $i=0$.
\end{remark}

\section{Receding Horizon Control} \label{sec:RHC}
In this section, we build on the results of Sections~\ref{sec:DMC} and~\ref{sec:reconditioning} to formulate an SMPC method that comes with the desired closed-loop guarantees in terms of constraint satisfaction and performance. As standard in MPC, we re-optimize the policy in a receding-horizon fashion to improve performance by leveraging the most recent state measurement and also reduce the effects of using a finite horizon.
The proposed SMPC scheme is presented in Section~\ref{sec:RHC_SMPC} and the closed-loop analysis is carried out in Section~\ref{sec:RHC_analysis}.

\subsection{Proposed SMPC Scheme} \label{sec:RHC_SMPC}
In the following, a tractable receding horizon SMPC scheme is proposed that builds on the idea of reconditioning to re-optimize the feedback policies while ensuring recursive feasibility and closed-loop chance constraint satisfaction. We combine the reconditioning idea from Section~\ref{sec:reconditioning} with the tractable SOCP formulation for optimized SLP-based feedback from Section~\ref{sec:DMC}. In particular, we consider~\eqref{eq:DMC} at $k=0$, and in the following it is explained how reconditioning can be used for $k \in \mathbb{I}_{>0}$.
\par For the first $N$ steps, the SLP-based feedback parameterization results in
\begin{equation} \label{eq:RHC:SLS-based_param}
    \begin{split}
        u_{i|k} &= v_{i|k} + \sum_{j=1}^i \Phi^\mathrm{u}_{i,j|k} w_{k+j-1},\ \forall i \in \mathbb{I}_{[0,N-1]}, \\
        x_{i|k} &= z_{i|k} + \sum_{j=1}^i \Phi^\mathrm{x}_{i,j|k} w_{k+j-1},\ \forall i \in \mathbb{I}_{[0,N]}.
    \end{split}
\end{equation}
When conditioned on $w_{0:k-1}$, the system response matrices in~\eqref{eq:RHC:SLS-based_param} are known, and thus $p(x_{i|k}, u_{i|k}|w_{0:k-1})$ and $p(x^\star_{i+1|k-1}, u^\star_{i+1|k-1}|w_{0:k-1})$ in~\eqref{eq:Rec-SMPC:constraints} and~\eqref{eq:pjik} are Gaussian. Thus, we can construct a deterministic reformulation of the probabilistic constraint~\eqref{eq:Rec-SMPC:constraints}, similarly to Section~\ref{sec:DMC}. We will use the following notation for the shifted policy from time step $k-1$ reconditioned on $w_{k-1}$:

\begin{equation} \label{eq:hat_zvPsi_def}
    \begin{split}
        \hat{z}_{i|k} &:= z^\star_{i+1|k-1} + \Phi^{\mathrm{x}\star}_{i+1,1|k-1}w_{k-1},\\
    \hat{v}_{i|k} &:= v^\star_{i+1|k-1} + \Phi^{\mathrm{u}\star}_{i+1,1|k-1}w_{k-1},\\
     \hat{\mathbf{\Phi}}^\mathrm{x}_{i|k} &:= \begin{bmatrix} \Phi^{\mathrm{x}\star}_{i+1,2|k-1} & ... & \Phi^{\mathrm{x}\star}_{i+1,i+1|k-1}\end{bmatrix},\\
    \hat{\mathbf{\Phi}}^\mathrm{u}_{i|k} &:= \begin{bmatrix} \Phi^{\mathrm{u}\star}_{i+1,2|k-1} & ... & \Phi^{\mathrm{u}\star}_{i+1,i+1|k-1}\end{bmatrix},
    \end{split}
\end{equation}
$\forall i \in \mathbb{I}_{[0,N-1]}$, where

\begin{equation}
    \begin{split}
         v^\star_{N|k-1} &:= Kz^\star_{N|k-1}, \\
    \Phi^{\mathrm{u}\star}_{N,j|k-1} &:= K\Phi^{\mathrm{x}\star}_{N,j|k-1},\ \forall j \in \mathbb{I}_{[1,N]};
    \end{split}
\end{equation}
furthermore,

\begin{equation} \label{eq:hat_zNPsiN_def}
    \begin{split}
        \hat{z}_{N|k} &:= A_Kz^\star_{N|k-1} + A_K\Phi^{\mathrm{x}\star}_{N,1|k-1}w_{k-1}, \\
    \hat{\mathbf{\Phi}}^\mathrm{x}_{N|k} &:= \begin{bmatrix} A_K\hat{\mathbf{\Phi}}^\mathrm{x}_{N-1|k} & I_n\end{bmatrix}.
    \end{split}
\end{equation}
\par First, consider $i \in \mathbb{I}_{[0:N-1]}$. It is possible that the conditional distribution in~\eqref{eq:pjik} is degenerate (has zero variance), which occurs exactly when 
\begin{equation} \label{eq:pjik_degenerate}
    G_j\hat{\mathbf{\Phi}}^\mathrm{x}_{i|k} + H_j\hat{\mathbf{\Phi}}^\mathrm{u}_{i|k} = 0.
\end{equation}
In this case, $p^j_{i|k} = 1$ whenever
\begin{equation} \label{eq:previous_satisfied}
    G_j\hat{z}_{i|k} +H_j\hat{v}_{i|k} \leq b_j,
\end{equation}
and $p^j_{i|k} = 0$ otherwise. In particular, in the special case of $i=0$, the variance of $p(x^\star_{1|k-1}, u^\star_{1|k-1}|w_{0:k-1})$ is always 0 (cf. Remark~\ref{rem:vanishing_constraints}). By using the convention that the empty matrices $\hat{\mathbf{\Phi}}^\mathrm{x}_{0|k}$ and $\hat{\mathbf{\Phi}}^\mathrm{u}_{0|k}$ always satisfy~\eqref{eq:pjik_degenerate}, this case is also covered by the general rule discussed above. To handle the degenerate cases, we define the following constraint sets:
\begin{align} 
    \mathcal{C}^{j,(1)}_{i|k} &= \myset{(z_{i|k}, v_{i|k}, \mathbf{\Phi}^\mathrm{x}_{i|k}, \mathbf{\Phi}^\mathrm{u}_{i|k})}{\begin{aligned}
            G_j z_{i|k} + H_j v_{i|k} \leq b_j \\
            G_j\mathbf{\Phi}^\mathrm{x}_{i|k} + H_j\mathbf{\Phi}^\mathrm{u}_{i|k} = 0
         \end{aligned}}, \label{eq:Cijk1} \\
    \mathcal{C}^{j,(2)}_{i|k} &= \mathbb{R}^n \times \mathbb{R}^m \times \mathbb{R}^{n \times in} \times \mathbb{R}^{m \times in}. \nonumber
\end{align}
As for the non-degenerate case (i.e., when~\eqref{eq:pjik_degenerate} does not hold), following similar derivations as in Section~\ref{sec:DMC}, we arrive at inequality
\begin{equation} \label{eq:RHC_SOC_k>0}
\begin{split}
    G_j z_{i|k} &+ H_j v_{i|k} \leq b_j \\ &- \alpha^j_{i|k} \norm{\mathbf{\Sigma}^{\mathrm{w},1/2}_i \begin{bmatrix} \mathbf{\Phi}^{x\top}_{i|k} & \mathbf{\Phi}^{u\top}_{i|k}\end{bmatrix} \begin{bmatrix} G_j^\top \\ H_j^\top \end{bmatrix}},
\end{split}
\end{equation}
where
\begin{equation} \label{eq:alpha_ijk}
    \alpha^j_{i|k} := \frac{b_j-G_j \hat{z}_{i|k}-H_j \hat{v}_{i|k}}{\norm{\mathbf{\Sigma}^{\mathrm{w},1/2}_i \begin{bmatrix} \hat{\mathbf{\Phi}}^{\mathrm{x}\top}_{i|k} & \hat{\mathbf{\Phi}}^{\mathrm{u}\top}_{i|k}\end{bmatrix} \begin{bmatrix} G_j^\top \\ H_j^\top \end{bmatrix}}}.
\end{equation}
Compared to~\eqref{eq:SOC_k=0_Psi} derived for $k=0$, $\alpha^j_{i|k}$ takes the place of $\sqrt{\tilde{p}^j}$. However, unlike $\sqrt{\tilde{p}^j}$, it is possible that $\alpha^j_{i|k}$ is negative, in which case~\eqref{eq:RHC_SOC_k>0} is non-convex. Thus, whenever $\alpha^j_{i|k} < 0$, we enforce the following convex sufficient condition instead:
\begin{equation} \label{eq:suff_convex_neg_alpha}
\begin{split}
     G_j z_{i|k} + H_j v_{i|k} &\leq G_j \hat{z}_{i|k} + H_j \hat{v}_{i|k}, \\
     G_j\mathbf{\Phi}^\mathrm{x}_{i|k} + H_j\mathbf{\Phi}^\mathrm{u}_{i|k} &= G_j\hat{\mathbf{\Phi}}^\mathrm{x}_{i|k} + H_j\hat{\mathbf{\Phi}}^\mathrm{u}_{i|k},
\end{split}
\end{equation}
which simplifies~\eqref{eq:RHC_SOC_k>0} to an inequality on the means by enforcing that the variances are matched. Using this, we define the following constraint sets:
\begin{align*}
    \mathcal{C}^{j,(3)}_{i|k} &= \myset{(z_{i|k}, v_{i|k}, \mathbf{\Phi}^\mathrm{x}_{i|k}, \mathbf{\Phi}^\mathrm{u}_{i|k})}{\eqref{eq:RHC_SOC_k>0} \text{ is satisfied}}, \\
    \mathcal{C}^{j,(4)}_{i|k} &= \myset{(z_{i|k}, v_{i|k}, \mathbf{\Phi}^\mathrm{x}_{i|k}, \mathbf{\Phi}^\mathrm{u}_{i|k})}{\eqref{eq:suff_convex_neg_alpha} \text{ is satisfied}}.
\end{align*}

\par Following a similar derivation for the tail of the infinite horizon, we obtain the constraints
\begin{equation} \label{eq:SOC_k>0_tail}
\begin{split}
        G_{K,j} A_K^i &z_{N|k} \leq b_j \\ &- \alpha^j_{N+i|k} \norm{\begin{bmatrix}
        \mathbf{\Sigma}^{\mathrm{w},1/2}_N \mathbf{\Phi}^{\mathrm{x}\top}_{N|k}A_K^{i\top}G_{K,j}^\top \\ \Sigma^{\mathrm{x},1/2}_i G_{K,j}^\top
    \end{bmatrix}}
\end{split}
\end{equation}
$\forall i \in \mathbb{I}_{\geq 0}$, where
\begin{equation*}
    \alpha^j_{N+i|k} = \frac{b_j-G_{K,j}A_K^i\hat{z}_{N|k}}{\norm{\begin{bmatrix}
        \mathbf{\Sigma}^{\mathrm{w},1/2}_N \hat{\mathbf{\Phi}}^{\mathrm{x}\top}_{N|k}A_K^{i\top}G_{K,j}^\top \\ \Sigma^{\mathrm{x},1/2}_i G_{K,j}^\top
    \end{bmatrix}}}.
\end{equation*}
Similarly to~\eqref{eq:SOC_k=0_tail_psi} in Section~\ref{sec:Mode_2}, this is a collection of infinite constraints. However, for each $i$ it contains a different factor $\alpha^j_{N+i|k}$ multiplying the norm term (instead of the fixed $\sqrt{\tilde{p}^j}$), meaning that we cannot directly invoke Theorem~\ref{thm:terminal_set}. Thus, in this work, we propose to use the following terminal set for $k > 0$:
\begin{equation} \label{eq:C_Nk_def}
    \mathcal{C}_{N|k} = \myset{(z_{N|k}, \mathbf{\Phi}^\mathrm{x}_{N|k})}{z_{N|k} = \hat{z}_{N|k},\ \mathbf{\Phi}^\mathrm{x}_{N|k} = \hat{\mathbf{\Phi}}^\mathrm{x}_{N|k}},
\end{equation}
trivially satisfying~\eqref{eq:SOC_k>0_tail} $\forall j \in \mathbb{I}_{[1,c]},\ \forall i \in \mathbb{I}_{\geq 0}$ with equality.
\par The proposed reconditioning SMPC scheme uses the following SOCP for all time steps $k>0$:
\begin{subequations} \label{eq:RHC}
    \begin{align}
        \min_{\substack{\mathbf{z}_k, \mathbf{v}_k\\ \mathbf{\Phi}^\mathrm{x}_{:|k}, \mathbf{\Phi}^\mathrm{u}_{:|k}}} \quad &J(\mathbf{z}_k, \mathbf{v}_k, \mathbf{\Phi}^\mathrm{x}_{:|k}, \mathbf{\Phi}^\mathrm{u}_{:|k})\\
        \text{s.t.} \quad\ \ 
        &z_{0|k} = x_k, \label{eq:RHC:init}\\
        &z_{i+1|k} = A z_{i|k} + B v_{i|k},\\
        &(z_{i|k}, v_{i|k}, \mathbf{\Phi}^\mathrm{x}_{i|k}, \mathbf{\Phi}^\mathrm{u}_{i|k}) \in \mathcal{C}^j_{i|k}, \label{eq:RHC:constraints_N}\\
        &(z_{N|k}, \mathbf{\Phi}^\mathrm{x}_{N|k}) \in \mathcal{C}_{N|k}, \label{eq:RHC:constraints_terminal}\\
        &\text{the SLP~\eqref{eq:SLP} is satisfied}, \\
        &\forall{j} \in \mathbb{I}_{[1,c]},\ \forall i \in \mathbb{I}_{[0,N-1]}.
    \end{align}
\end{subequations}
The cost function $J(.)$ is defined in~\eqref{eq:J}, and

\begin{equation} \label{eq:Cijk}
    \mathcal{C}^j_{i|k} := \begin{cases}
        \mathcal{C}^{j,(1)}_{i|k} \ \text{ if~\eqref{eq:pjik_degenerate} and~\eqref{eq:previous_satisfied}} \\ \mathcal{C}^{j,(2)}_{i|k} \ \text{ if~\eqref{eq:pjik_degenerate} but not~\eqref{eq:previous_satisfied}} \\
        \mathcal{C}^{j,(3)}_{i|k} \ \text{ if not~\eqref{eq:pjik_degenerate} and $\alpha^j_{i|k} \geq 0$} \\
        \mathcal{C}^{j,(4)}_{i|k} \ \text{ if not~\eqref{eq:pjik_degenerate} and $\alpha^j_{i|k} < 0$}
    \end{cases}.
\end{equation}
After solving optimization problem~\eqref{eq:RHC} at time step $k$, apply
\begin{equation} \label{eq:RHC:control_law}
    u_k = v_{0|k}^\star.
\end{equation}
The proposed SMPC scheme is summarized in Algorithm~\ref{alg:SMPC}.

\begin{algorithm}
\caption{Proposed SMPC scheme} \label{alg:SMPC}
\begin{algorithmic}[1]
\Statex \textbf{Offline design:}
\State Choose terminal controller $K$ satisfying~\eqref{eq:b_j-norm>0}.
\State Design terminal set $\mathcal{S}_\mu$ via Algorithm~\ref{alg:terminal_set}.
\Statex \textbf{Online operation:} 
\State \textbf{Given} initial state $x_0$
\For{$k \in \mathbb{I}_{\geq 0}$}
    \State Measure $x_k$.
    \If{$k=0$}
        \State Solve~\eqref{eq:DMC}.
    \Else

        \State Update $\mathcal{C}^j_{i|k}$ $\forall i \in \mathbb{I}_{[0,N-1]},\forall j \in \mathbb{I}_{[1,c]}$ (see~\eqref{eq:Cijk}).
        \State Solve~\eqref{eq:RHC}.
    \EndIf
    \State Apply $u_k = v^\star_{0|k}$.
\EndFor
\end{algorithmic}
\end{algorithm}

\begin{remark}
    While constraints $\mathcal{C}^{j,(1)}_{i|k}$, $\mathcal{C}^{j,(2)}_{i|k}$, and $\mathcal{C}^{j,(3)}_{i|k}$ are exact reformulations of the original chance constraint~\eqref{eq:Rec-SMPC:constraints} (meaning that they are non-conservative), $\mathcal{C}^{j,(4)}_{i|k}$ is only a sufficient condition, introducing some conservatism. However, $\mathcal{C}^{j,(4)}_{i|k}$ is only used whenever $\alpha^j_{i|k} < 0$.
    Note that $\mathrm{Pr}[\alpha^j_{i|k} \geq 0] \geq p^j,\ \forall j \in \mathbb{I}_{[1,c]},\forall i \in \mathbb{I}_{[0,N-1]},\forall k \in \mathbb{I}_{> 0}$ and hence $\alpha^j_{i|k} < 0$ occurs with low probability.
\end{remark}

\begin{remark}
    The terminal set~\eqref{eq:C_Nk_def} is more conservative than enforcing~\eqref{eq:SOC_k>0_tail} $\forall i \in \mathbb{I}_{\geq 0}$. The reason we employ this terminal set is that even if Theorem~\ref{thm:terminal_set} was extended for the case when the varying $\alpha^j_{N+i|k}$ factors take the place of $\sqrt{\tilde{p}^j}$, the obtained finite determination index $\mu$ would vary based on the $\alpha^j_{N+i|k}$ values. This means that an online redesign of the terminal set would be required for each time step $k$. Hence, in this work, we use the more conservative terminal set defined in~\eqref{eq:C_Nk_def}.
\end{remark}

\subsection{Closed-loop Analysis} \label{sec:RHC_analysis}
In this section, we show that the proposed SMPC method (Algorithm~\ref{alg:SMPC}) ensures the desired closed-loop properties.

\begin{theorem}[Closed-loop properties of Algorithm~\ref{alg:SMPC}] \label{thm:RHC}
    Suppose Assumption~\ref{ass:L} holds and~\eqref{eq:DMC} is feasible at time step $k=0$. Then, system~\eqref{eq:system} controlled by the SMPC scheme summarized in Algorithm~\ref{alg:SMPC} ensures that
    \begin{enumerate}
        \item optimization problem~\eqref{eq:RHC} remains feasible $\forall k \in \mathbb{I}_{> 0}$,
        \item chance constraints~\eqref{eq:chance_constraints} are satisfied in closed-loop, and
        \item the asymptotic average cost is upper bounded by the performance of the static state-feedback controller $K$, i.e.,~\eqref{eq:lavg} is satisfied.
    \end{enumerate}
\end{theorem}
\begin{proof}
    The proof can be found in Appendix~\ref{app:RHC_proof}.
\end{proof}

The derived asymptotic average cost bound is consistent with the performance bounds of existing SMPC methods. However, compared to existing SMPC methods that use online-optimized policies~\cite{oldewurtel2008tractable, prandini2012randomized, mark2022recursively, pan2023data, li2024distributionally, knaup2024recursively}, we uniquely ensure closed-loop chance constraint satisfaction.
The improved performance of the proposed method compared to the fixed-feedback methods of~\cite{hewing2018stochastic, hewing2020recursively, kohler2022recursively, schluter2022stochastic} comes at an increased computational cost: instead of solving an SOCP, those methods require solving a QP, with significantly fewer optimization variables. 

\section{Numerical Example} \label{sec:numerical}
This section aims to highlight the advantages of the proposed SMPC method (Algorithm~\ref{alg:SMPC}) compared to indirect feedback SMPC~\cite{hewing2020recursively} (IF-SMPC) that uses fixed feedback, and to a reconditioning SMPC scheme with fixed feedback (RC-SMPC). RC-SMPC is identical to the proposed method with fixed system response matrices:
\begin{equation*}
    \mathbf{\Phi}^{\mathrm{u},\text{RC-SMPC}}_{:|k} = \begin{bmatrix}
        K & \\
        KA_K & K \\
        \vdots & & \ddots\\
        KA_K^{N-2} & ... & ... & K
    \end{bmatrix}.
\end{equation*}
Existing methods that use online-optimized feedback are not considered for comparison, due to their lack of closed-loop chance constraint satisfaction guarantees. The simulations are carried out using Python on a machine equipped with an Intel i7-12700H (2.30 GHz) processor with 32 GB of RAM. The SOCPs~\eqref{eq:DMC} and~\eqref{eq:RHC}are solved with ECOS~\cite{domahidi2013ecos}, the optimization problem of IF-SMPC is solved with OSQP~\cite{osqp}, and the solvers are interfaced using CVXPY~\cite{diamond2016cvxpy}.\footnote{The code is available online: https://gitlab.ethz.ch/ics/online-optimized-smpc.}

\par Consider a mass-spring-damper system with discretized system matrices
\begin{equation*}
    A = \begin{bmatrix}
        1 & 0.1 \\ -0.1 & 0.9
    \end{bmatrix},\quad B = \begin{bmatrix}
        0 \\ 1
    \end{bmatrix},
\end{equation*}
where the position is the first state $[x]_1$, and the velocity is the second state $[x]_2$. The system is affected by the additive i.i.d. disturbance $w_k~\sim~\mathcal{N}(0, 0.05I_2)$. The goal is to regulate the system to the origin from the initial state $x_0^\top = \begin{bmatrix} -4 & 0 \end{bmatrix}$ with cost
\begin{equation*}
    Q = \begin{bmatrix}
        1 & 0 \\ 0 & 0
    \end{bmatrix},\quad R = 0.1,
\end{equation*}
which mainly minimizes position deviation.
\par All controllers use a prediction horizon length of $N = 8$, and the simulation length is 15 time steps in all cases. The terminal controller of the proposed method and the fixed feedback matrix used by IF-SMPC and RC-SMPC is chosen to be the LQR feedback gain corresponding to the cost matrices $Q$ and $R$. The terminal weight $P$ is taken from the discrete algebraic Riccati equation in all cases, and IF-SMPC uses the maximal positively invariant set~\cite{gilbert1991linear} as its terminal set. 

\subsubsection*{Case 1: Chance constraint on the velocity}  \label{case:velocity}
We first consider a single half-space chance constraint that limits the velocity of the mass:
\begin{equation} \label{eq:num:original_constraint}
    \mathrm{Pr}[[x]_2 \leq 5] \geq p,
\end{equation}
with $p = 0.8$. Note that this means that $\mathcal{L}$ is not bounded, therefore Assumption~\ref{ass:L} is not satisfied. However, Algorithm~\ref{alg:terminal_set} still converges, and the terminal set design of the proposed method is successful with $\nu = 16$ and $\mu = 17$ (cf. Remark~\ref{rem:can_still_converge}).

\par The simulation is carried out with $5\cdot 10^4$ random disturbance sequence realizations. For this example, IF-SMPC and RC-SMPC result in the same closed-loop trajectories, therefore, in the following, the trajectories of RC-SMPC are not shown. This also means that the differences between the methods highlighted with this example arise purely due to the fact that the proposed method uses online-optimized feedback instead of a fixed one, and not because of using a reconditioning SMPC technique.

\begin{figure}
	\centering
	\includegraphics[scale=1]{figures/paper_x2.pdf}
	\caption{The evolution of the second state (velocity) over time using the proposed method (red) and IF-SMPC (blue). The thin lines correspond to 500 randomly picked disturbance sequence realizations (out of the $5\cdot 10^4$), the thick lines are the means, and the dashed lines show the empirical probability of constraint satisfaction  (Case~\hyperref[case:velocity]{1}).} 
 \label{fig:velocity}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[scale=1]{figures/paper_ss.pdf}
	\caption{Closed-loop trajectories in the state space using the proposed method (red) and IF-SMPC (blue). The thin lines correspond to 500 randomly picked disturbance sequence realizations (out of the $5\cdot 10^4$), the thick lines are the means (Case~\hyperref[case:velocity]{1}).} 
 \label{fig:state_space}
\end{figure}

\par Figure~\ref{fig:velocity} shows the evolution of the velocity over time. As it can be clearly seen, the proposed method is able to approach the constraint much closer than IF-SMPC, highlighting the increased flexibility provided by the online-optimized feedback policies. The figure also shows that both methods tightly satisfy the chance constraint with $p=0.8$.
The state-space diagram shown in Figure~\ref{fig:state_space} also points out that the proposed method is able to safely drive the system closer to the constraint. Since the proposed method can achieve a larger velocity, it is able to decrease the cost compared to IF-SMPC, as shown by 
Table~\ref{tab:cost}. It also compares the time it took to solve the underlying optimization problems: as expected, IF-SMPC requires less computational effort. 

\begin{table}
\caption{Comparison of the proposed method and IF-SMPC in terms of the mean and the standard deviation of the accumulated closed-loop costs and the solution times (Case~\hyperref[case:velocity]{1})}
\label{tab:cost}
\begin{center}
    \begin{tabular}{||c || c | c ||} 
         \hline
         & Closed-loop cost & Solvetime [ms] \\ [0.2ex] 
         \hline
         IF-SMPC & 76.71 $\pm$ ~9.71 & 1.35 $\pm$ 3.89  \\ 
         \hline
         Algorithm~\ref{alg:SMPC} & 74.07 $\pm$ 12.63 & 7.07 $\pm$ 5.42  \\ 
         \hline
    \end{tabular}
\end{center}
\end{table}

\subsubsection*{Case 2: Additional input constraints} \label{case:input}
Next, consider a modification to the original example, where the following chance constraint is enforced, in addition to~\eqref{eq:num:original_constraint}:
\begin{equation*}
    \mathrm{Pr}[u \geq -1] \geq p,
\end{equation*}
where the probability level $p \in \{0.65,\ 0.7,\ 0.75,\ 0.8 \}$ is the same for both constraints for simplicity. As in Case~\hyperref[case:velocity]{1}, $\mathcal{L}$ is not bounded, but the terminal set design is successful with $\mu = 12$ for all four values of $p$. The simulation is carried out with $10^4$ random disturbance sequence realizations.
\par As highlighted by Table~\ref{tab:p_effect}, the proposed method (Algorithm~\ref{alg:SMPC}) achieves the lowest cost, and the difference increases with the increase of $p$. It can also be seen that IF-SMPC slightly outperforms RC-SMPC for this example. This suggests that adopting a reconditioning scheme over the indirect feedback scheme may have a slight negative effect depending on the example, but
this effect is significantly smaller compared to the advantage of using online-optimized feedback. Finally, Table~\ref{tab:p_effect} also shows that only the proposed method is able to retain feasibility when the required probability level is increased to $p=0.8$, highlighting its reduced conservatism in comparison with the fixed-feedback approaches.

\begin{table}
\caption{The effect of $p$ on the closed-loop cost achieved achieved by IF-SMPC, RC-SMPC and the proposed method (Case~\hyperref[case:input]{2})}
\label{tab:p_effect}
\begin{center}
    \begin{tabular}{||c || c | c | c | c ||} 
         \hline
         & \multicolumn{4}{c||}{Mean closed-loop cost} \\ 
         \hline
         & $p = 0.65$ & $p = 0.7$ & $p = 0.75$ & $p = 0.8$ \\  
         \hline
         IF-SMPC & 73.86 & 74.59 & 75.66 & infeasible\\ 
         \hline
         RC-SMPC & 73.86 & 74.63 & 75.74 & infeasible \\ 
         \hline
         Algorithm~\ref{alg:SMPC} & 73.04 & 73.32 & 73.87 & 74.24 \\ 
         \hline
    \end{tabular}
\end{center}
\end{table}

\section{Conclusion} \label{sec:conclusion}

We proposed an SMPC method for linear time-invariant systems affected by additive Gaussian disturbances. The proposed method optimizes affine feedback policies online in a receding horizon fashion, by solving a finite-horizon convex optimization problem at every time step. A finitely determined maximal admissible set was designed, which, combined with the idea of reconditioning on the current knowledge at every time step, guarantees closed-loop chance constraint satisfaction and recursive feasibility. The improved flexibility provided by optimizing over the feedback policies online was shown via numerical examples.

\appendix

\subsection{Terminal controller synthesis satisfying Assumption~\ref{ass:L}} \label{app:K_design}
In order to formulate a convex optimization problem that can be solved in practice, the strict inequality~\eqref{eq:b_j-norm>0} in Assumption~\ref{ass:L} is approximated by $b_j -  \sqrt{\tilde{p}^j}\norm{\Sigma_\infty^{\mathrm{x},1/2} C_K^\top L_j^\top} \geq \varepsilon_j$, where $\varepsilon_j \in \mathbb{R}_{>0}$ is sufficiently small. Then, using the Schur complement, we can formulate the following convex semidefinite program (SDP) to design $K$:
\begin{subequations} \label{eq:K_design}
    \begin{align}
        \min_{\Sigma^{\mathrm{x}}_\infty,Y,t} \quad &t \\
        \mathrm{s.t.} \quad\ &\Sigma^{\mathrm{x}}_\infty = \Sigma^{\mathrm{x}\top}_\infty \preceq tI_n, \\
        &\begin{bmatrix}
            \Sigma^{\mathrm{x}}_\infty - \Sigma^\mathrm{w} & A\Sigma^{\mathrm{x}}_\infty + BY \\ (A\Sigma^{\mathrm{x}}_\infty + BY)^\top & \Sigma^{\mathrm{x}}_\infty
        \end{bmatrix} \succeq 0, \\
         &\begin{bmatrix}
            (b_j - \varepsilon_j)^2 & L_j(C\Sigma^{\mathrm{x}}_\infty + DY) \\ (C\Sigma^{\mathrm{x}}_\infty + DY)^\top L_j^\top & (1/\tilde{p}_j)\Sigma^{\mathrm{x}}_\infty
        \end{bmatrix} \succeq 0, \\
        &\forall j \in \mathbb{I}_{[1,c]},
    \end{align}
\end{subequations}
where $t \in \mathbb{R}_{\geq 0}$, $\Sigma^{\mathrm{x}}_\infty \in \mathbb{R}^{n\times n}$, $Y \in \mathbb{R}^{m\times n}$. Infeasibility of~\eqref{eq:K_design} means that the desired probability level $p^j$ is too high for the given constraint and disturbance covariance. If~\eqref{eq:K_design} is feasible, a suitable choice for $K$ satisfying Assumption~\ref{ass:L} is
\begin{equation*}
    K = Y^\star (\Sigma^{\mathrm{x}\star}_\infty)^{-1}.
\end{equation*}



\subsection{Proof of Theorem~\ref{thm:terminal_set}} \label{app:terminal_set_proof}
    Throughout the proof, we will make use of the relaxed version of inequality~\eqref{eq:SOC_k=0_tail_psi} and set $\mathcal{D}_i$:
    \begin{equation}
         G_{K,j} A_K^i z \leq b_j - \sqrt{\tilde{p}^j} \norm{
            \left( G_{K,j} A_K^i \otimes \mathbf{\Sigma}^{\mathrm{w},1/2}_N\right) \psi}, \label{eq:SOC_k=0_tail_psi_relaxed}
    \end{equation}
    which corresponds to~\eqref{eq:SOC_k=0_tail_psi} with $\Sigma^\mathrm{x}_i = 0$, and
    \begin{equation*}
         \hat{\mathcal{D}}_i = \myset{(z, \psi)}{\eqref{eq:SOC_k=0_tail_psi_relaxed} \text{ holds for }i,\ \forall j \in \mathbb{I}_{[1, c]}};
    \end{equation*}
    furthermore, $\hat{\mathcal{S}}_i$ and $\hat{\mathcal{S}}_\infty$ can be defined analogously to $\mathcal{S}_i$ and $\mathcal{S}_\infty$. Then, it is easy to see that
    \begin{equation} \label{eq:hat_tilde_order}
        \bar{\mathcal{D}}_i \subseteq \mathcal{D}_i \subseteq \hat{\mathcal{D}}_i, \quad \bar{\mathcal{S}}_i \subseteq \mathcal{S}_i \subseteq \hat{\mathcal{S}}_i, \quad \bar{\mathcal{S}}_\infty \subseteq \mathcal{S}_\infty \subseteq \hat{\mathcal{S}}_\infty.
    \end{equation}
    Finally, consider inequality
    \begin{equation} \label{eq:proofs:L_hat_ineq}
        L_jy + \sqrt{\tilde{p}^j}\norm{(L_j \otimes \mathbf{\Sigma}^{\mathrm{w},1/2}_N)\tilde{y}}\leq b_j,
    \end{equation}
    where $y \in \mathbb{R}^d$, $\tilde{y} \in \mathbb{R}^{Nnd}$, and define the set
    \begin{equation} \label{eq:proofs:L_hat}
        \hat{\mathcal{L}} = \myset{\begin{bmatrix} y \\\tilde{y}\end{bmatrix} \in \mathbb{R}^{d+Nnd}}{\eqref{eq:proofs:L_hat_ineq}\text{ holds }\forall j \in \mathbb{I}_{[1,c]}}.
    \end{equation}
\begin{proof}    
    The proof extends arguments from the maximal admissible set characterizations presented in~\cite{gilbert1991linear, li2021chance}. In Part I, we establish the boundedness of $\hat{\mathcal{L}}$, which is then combined with observability and Schur stability to prove finite determination and boundedness of $\hat{\mathcal{S}}_\infty$ in Part II. Finally, Part III proves the finite determination of $\mathcal{S}_\infty$ based on $\hat{\mathcal{S}}_\infty$.
    \par \textit{Part I: Boundedness of $\hat{\mathcal{L}}$.} It can be seen that~\eqref{eq:proofs:L_hat_ineq} is equivalent to the following pair of inequalities:
    \begin{equation} \label{eq:proofs:L_hat_ineq_pair_1}
        \tilde{p}^j\tilde{y}^\top(L_j^\top L_j \otimes \mathbf{\Sigma}^\mathrm{w}_N)\tilde{y} \leq (b_j-L_jy)^2,\quad L_jy \leq b_j.
    \end{equation}
    Using the fact that 
    \begin{equation*}
        L_j^\top L_j \otimes \mathbf{\Sigma}^\mathrm{w}_N = \mathcal{P}^\top(\mathbf{\Sigma}^\mathrm{w}_N \otimes L_j^\top L_j)\mathcal{P},
    \end{equation*}
    where $\mathcal{P}$ is a permutation matrix (see, e.g.,~\cite{henderson1981vec}), and introducing
    \begin{equation} \label{eq:eta_def}
        \eta := (\mathbf{\Sigma}^{\mathrm{w},1/2}_N \otimes I_d)\mathcal{P}\tilde{y},
    \end{equation}
    inequality~\eqref{eq:proofs:L_hat_ineq_pair_1} can be further written as
    \begin{equation} \label{eq:proofs:L_hat_ineq_pair_2}
        \eta^\top(\tilde{p}^jI_{Nn} \otimes L_j^\top L_j)\eta \leq (b_j-L_jy)^2,\quad L_jy \leq b_j.
    \end{equation}
    Note that $(\mathbf{\Sigma}^{\mathrm{w},1/2}_N \otimes I_d)\mathcal{P}$ is invertible, since $\mathcal{P}$ is orthogonal and $\mathbf{\Sigma}^{\mathrm{w},1/2}_N \succ 0$. Taking the partition
    \begin{equation*}
        \eta^\top = \begin{bmatrix} \eta_1^\top & ... & \eta_{Nn}^\top\end{bmatrix},\quad \eta_i \in \mathbb{R}^d,\ \forall i \in \mathbb{I}_{[1,Nn]},
    \end{equation*}
    conditions~\eqref{eq:proofs:L_hat_ineq_pair_2} can be written as
    \begin{equation*} \label{eq:proofs:L_hat_ineq_pair_3}
        \tilde{p}^j\sum_{i=1}^{Nn}\eta_i^\top L_j^\top L_j \eta_i \leq (b_j-L_jy)^2,\quad L_jy \leq b_j,
    \end{equation*}
    which implies
    \begin{equation} \label{eq:proofs:L_hat_ineq_pair_4}
        \tilde{p}^j(L_j \eta_i)^2 \leq (b_j-L_jy)^2,\ \forall i \in \mathbb{I}_{[1,Nn]},\quad L_jy \leq b_j,
    \end{equation}
    due to $L_j^\top L_j \succeq 0$. Finally,~\eqref{eq:proofs:L_hat_ineq_pair_4} further implies
    \begin{equation*}
        \sqrt{\tilde{p}^j}L_j\eta_i \leq b_j - L_j y,\ \forall i \in \mathbb{I}_{[1,Nn]},\quad L_jy \leq b_j.
    \end{equation*}
    We know that if $\begin{bmatrix}y^\top & \tilde{y}^\top\end{bmatrix}^\top \in \hat{\mathcal{L}}$, then $Ly\leq b$, i.e., $y \in \mathcal{L}$, which is bounded, implying that $\underline{b}_j = \min_{y\in \mathcal{L}} L_jy$ is a well-defined finite number; furthermore, due to $b > 0$, $\underline{b}_j \leq 0$. Therefore, if $\begin{bmatrix}y^\top & \tilde{y}^\top \end{bmatrix}^\top \in \hat{\mathcal{L}}$, then 
    \begin{equation*}
        \sqrt{\tilde{p}^j}L_j\eta_i \leq \max_{y\in \mathcal{L}}(b_j - L_j y),\ \forall i \in \mathbb{I}_{[1,Nn]},\ \forall j \in \mathbb{I}_{[1,c]},
    \end{equation*}
    i.e.,
    \begin{equation*}
        \sqrt{\tilde{p}^j}L_j\eta_i \leq b_j - \underline{b}_j,\ \forall i \in \mathbb{I}_{[1,Nn]},\ \forall j \in \mathbb{I}_{[1,c]}.
    \end{equation*}
    Define $\bar{b} \in \mathbb{R}^c_{> 0}$, the $j$-th row of which is $\bar{b}_j = 1/\sqrt{\tilde{p}^j} (b_j - \underline{b}_j) > 0$. Since $\mathcal{L}$ is bounded, the set $\myset{\eta_i}{L\eta_i \leq \bar{b}}$ is also bounded $\forall i \in \mathbb{I}_{[1, Nn]}$. Thus, $\exists M \in \mathbb{R}_{>0}$ such that $\norm{\eta} \leq M,\ \forall \begin{bmatrix}y^\top & \tilde{y}^\top \end{bmatrix}^\top \in \hat{\mathcal{L}} $, i.e., according to~\eqref{eq:eta_def},
    \begin{equation*}
        \norm{(\mathbf{\Sigma}^{\mathrm{w},1/2}_N \otimes I_d)\mathcal{P}\tilde{y}} \leq M,
    \end{equation*}
    and thus
     \begin{equation*}
        \begin{split}
        \norm{\tilde{y}} &= \norm{\left((\mathbf{\Sigma}^{\mathrm{w},1/2}_N \otimes I_d)\mathcal{P}\right)^{-1}(\mathbf{\Sigma}^{\mathrm{w},1/2}_N \otimes I_d)\mathcal{P}\tilde{y}} \\
        &\leq \norm{\left((\mathbf{\Sigma}^{\mathrm{w},1/2}_N \otimes I_d)\mathcal{P}\right)^{-1}} M.
        \end{split}
    \end{equation*}
    That is, both $y$ and $\tilde{y}$ are bounded, proving that the set $\hat{\mathcal{L}}$ is bounded.
    \par \textit{Part II: Finite determination of $\hat{\mathcal{S}}_\infty$.} Note that $L_jC_K = G_{K,j}$ due to $G = LC$ and $H = LD$, and thus~\eqref{eq:SOC_k=0_tail_psi_relaxed} can be equivalently written as
    \begin{equation*} \label{eq:proofs:L_hat_ineq_CA}
        L_jC_KA_K^iz + \sqrt{\tilde{p}^j}\norm{(L_jC_KA_K^i \otimes \mathbf{\Sigma}^{\mathrm{w},1/2}_N)\psi}\leq b_j.
    \end{equation*}
    Introducing the notation
    \begin{align*}
        \zeta^\top &= \begin{bmatrix}z^\top & \psi^\top \end{bmatrix} \in \mathbb{R}^{Nn^2+n}, \\
        \mathbf{A} &= \begin{bmatrix}
            A_K & \\ & A_K \otimes I_{Nn}
        \end{bmatrix} \in \mathbb{R}^{(Nn+1)n \times (Nn+1)n}, \\
        \mathbf{C} &= \begin{bmatrix}
            C_K & \\ & C_K \otimes I_{Nn}
        \end{bmatrix} \in \mathbb{R}^{(Nn+1)d \times (Nn+1)n},
    \end{align*}
    it can be seen that $(z, \psi)\in \hat{\mathcal{D}}_i \iff \mathbf{C} \mathbf{A}^i \zeta \in \hat{\mathcal{L}}$ and thus $(z, \psi)\in \hat{\mathcal{S}}_k \iff \mathbf{C} \mathbf{A}^i \zeta \in \hat{\mathcal{L}},\ \forall i \in \mathbb{I}_{[1,k]}$. Furthermore,
    \begin{align*}
        \mathbf{C} \mathbf{A}^i &= \begin{bmatrix}
            C_KA_K^i & \\ & C_KA_K^i \otimes I_{Nn}
        \end{bmatrix} \nonumber \\
        &= \begin{bmatrix}
            C_KA_K^i & \\ & \mathcal{P}_1(I_{Nn}  \otimes C_KA_K^i)\mathcal{P}_2
        \end{bmatrix} \nonumber \\
        &= \begin{bmatrix}
            I_d & \\ & \mathcal{P}_1
        \end{bmatrix}\begin{bmatrix}
            C_KA_K^i & \\ & I_{Nn}  \otimes C_KA_K^i
        \end{bmatrix} \begin{bmatrix}
            I_n & \\ & \mathcal{P}_2
        \end{bmatrix} \nonumber \\
        &= \mathcal{P}_3(I_{Nn+1}  \otimes C_KA_K^i)\mathcal{P}_4 \nonumber \\
        &= \mathcal{P}_3\mathcal{P}_5(C_KA_K^i \otimes I_{Nn+1})\mathcal{P}_6\mathcal{P}_4 \nonumber \\
        &= \mathcal{P}_7(C_KA_K^i \otimes I_{Nn+1})\mathcal{P}_8, 
    \end{align*}
    where $\mathcal{P}_j, j \in \mathbb{I}_{[1,8]}$ are permutation matrices that depend only on the dimensions of $C_KA_K^i$ and $I_{Nn}$, i.e., they are the same for every $i$. Define observability matrices $\mathcal{O}^\top = \begin{bmatrix} C_K^\top & A_K^\top C_K^\top & ... & A_K^{n-1\top} C_K^\top\end{bmatrix}$ and
    \begin{equation*}
        \begin{split}
            \hat{\mathcal{O}} &= \begin{bmatrix}
                \mathbf{C} \\ \mathbf{C}\mathbf{A} \\ \vdots \\ \mathbf{C}\mathbf{A}^{n-1}
            \end{bmatrix} =
            \begin{bmatrix}
                \mathcal{P}_7(C_K \otimes I_{Nn+1})\mathcal{P}_8 \\ \mathcal{P}_7(C_KA_K \otimes I_{Nn+1})\mathcal{P}_8 \\ \vdots \\ \mathcal{P}_7(C_KA_K^{n-1} \otimes I_{Nn+1})\mathcal{P}_8
            \end{bmatrix}\\
            &= (I_n \otimes \mathcal{P}_7) \begin{bmatrix}
                C_K \otimes I_{Nn+1} \\ C_KA_K \otimes I_{Nn+1} \\ \vdots \\ C_KA_K^{n-1} \otimes I_{Nn+1}
            \end{bmatrix} \mathcal{P}_8 \\
            &= (I_n \otimes \mathcal{P}_7) (\mathcal{O} \otimes I_{Nn+1}) \mathcal{P}_8.
        \end{split}
    \end{equation*}
    As $(C_K, A_K)$ is observable, $\mathrm{rank}(\mathcal{O}) = n$. Since row and column permutations do not change the rank,
    \begin{equation*}
        \begin{split}
            \mathrm{rank}(\hat{\mathcal{O}}) &= \mathrm{rank}(\mathcal{O} \otimes I_{Nn+1}) \\ & =\mathrm{rank}(\mathcal{O})\mathrm{rank}(I_{Nn+1}) = n(Nn+1),
        \end{split}
    \end{equation*}
    proving that $(\mathbf{C},\mathbf{A})$ is observable. Furthermore, $\mathbf{A}$ is Schur due to $A_K$ being Schur. This, combined with the boundedness of $\hat{\mathcal{L}}$ and the fact that $0 \in \mathrm{int}(\hat{\mathcal{L}})$ (owing to $b > 0$), implies that $\hat{\mathcal{S}}_\infty$ is bounded and it is finitely determined, according to~\cite[Theorems~2.1 and 4.1]{gilbert1991linear}. That is, $\exists \mu_0 \in \mathbb{I}_{\geq 0}$ such that $\hat{\mathcal{S}}_{\mu_0} = \hat{\mathcal{S}}_\infty$ and $\hat{\mathcal{S}}_{\mu_0}$ is bounded.
    \par \textit{Part III: Finite determination of $\mathcal{S}_\infty$.} From~\eqref{eq:hat_tilde_order}, the boundedness of $\hat{\mathcal{S}}_{\mu_0}$ implies that $\mathcal{S}_\mu \subseteq \mathcal{S}_{\mu_0} \subseteq \hat{\mathcal{S}}_{\mu_0}$ is also bounded $\forall \mu \in \mathbb{I}_{\geq \mu_0}$. Combining this result with $\lim_{i \rightarrow \infty} A_K^i = 0$, it is true that $\forall \varepsilon_j \in \mathbb{R}_{>0}\ \exists \mu \in \mathbb{I}_{\geq\mu_0}$ such that
    \begin{align*}
        G&_{K,j}A_K^i z + \sqrt{\tilde{p}^j} \norm{\begin{bmatrix}
            \left( G_{K,j} A_K^i \otimes \mathbf{\Sigma}^{\mathrm{w},1/2}_N\right) \psi\\ \Sigma_\infty^{\mathrm{x},1/2} G_{K,j}^\top
        \end{bmatrix}} \\
        &- \sqrt{\tilde{p}^j}\norm{\Sigma_\infty^{\mathrm{x},1/2} G_{K,j}^\top} \leq \varepsilon_j,\quad \forall (z,\psi) \in \mathcal{S}_\mu,\ \forall i \in \mathbb{I}_{> \mu}. \nonumber
    \end{align*}
    Thus, for $\varepsilon_j = b_j - \sqrt{\tilde{p}^j}\norm{\Sigma_\infty^{\mathrm{x},1/2} G_{K,j}^\top} > 0: \exists \mu \in \mathbb{I}_{\geq \mu_0}$ such that
    \begin{equation*}
        G_{K,j} A_K^i z + \sqrt{\tilde{p}^j} \norm{\begin{bmatrix}
            \left( G_{K,j} A_K^i \otimes \mathbf{\Sigma}^{\mathrm{w},1/2}_N\right) \psi\\ \Sigma_\infty^{\mathrm{x},1/2} G_{K,j}^\top
        \end{bmatrix}} \leq b_j,
    \end{equation*}
    $\forall i \in \mathbb{I}_{> \mu},\ \forall j \in \mathbb{I}_{[1,c]},\ \forall (z,\psi) \in \mathcal{S}_\mu$, in other words,
    \begin{equation*}
        \mathcal{S}_\mu \subseteq \bigcap_{i=\mu+1}^\infty \bar{\mathcal{D}}_i \stackrel{\eqref{eq:hat_tilde_order}}{\subseteq} \bigcap_{i=\mu+1}^\infty \mathcal{D}_i.
    \end{equation*}
    Consequently,
    \begin{equation}
        \mathcal{S}_\infty = \mathcal{S}_\mu \cap  \left(\bigcap_{i=\mu+1}^\infty \mathcal{D}_i\right) \supseteq \mathcal{S}_\mu \cap \mathcal{S}_\mu = \mathcal{S}_\mu,
    \end{equation}
    i.e., $\mathcal{S}_\infty \supseteq \mathcal{S}_\mu$. On the other hand, $\mathcal{S}_\infty \subseteq\mathcal{S}_\mu$ by construction, resulting in $\mathcal{S}_\infty = \mathcal{S}_\mu$, concluding the proof.
\end{proof}

\subsection{Proof of Proposition~\ref{prop:terminal_set_alg}} \label{app:algorithm_proof}

\begin{proof}
    Let
    \begin{equation} \label{eq:proofs:L_tilde_ineq}
        L_jy + \sqrt{\tilde{p}^j}\norm{\begin{bmatrix}
            (L_j \otimes \mathbf{\Sigma}^{\mathrm{w},1/2}_N)\tilde{y} \\ \Sigma^{\mathrm{x},1/2}_\infty C_K^\top L_j^\top
        \end{bmatrix}} \leq b_j,
    \end{equation}
    \begin{equation} \label{eq:proofs:L_tilde}
        \bar{\mathcal{L}} = \myset{\begin{bmatrix} y \\\tilde{y}\end{bmatrix} \in \mathbb{R}^{d+Nnd}}{\eqref{eq:proofs:L_tilde_ineq}\text{ holds }\forall j \in \mathbb{I}_{[1,c]}},
    \end{equation}
    be defined analogously to~\eqref{eq:proofs:L_hat_ineq}-\eqref{eq:proofs:L_hat} and note that $\bar{\mathcal{L}} \subseteq \hat{\mathcal{L}}$ is bounded due to $\hat{\mathcal{L}}$ being bounded. Moreover, $0 \in \mathrm{int}(\bar{\mathcal{L}})$ due to Assumption~\ref{ass:L}. Finally, $(\mathbf{C}, \mathbf{A})$ is observable and $\mathbf{A}$ is Schur, and thus~\cite[Theorem~4.1]{gilbert1991linear} guarantees that $\exists \nu \in \mathbb{I}_{\geq 0}$ such that $\bar{\mathcal{S}}_\infty = \bar{\mathcal{S}}_\nu$.
    In other words,
    \begin{equation} \label{eq:nu_equivalence}
        \mathbf{C}\mathbf{A}^i\zeta \in \bar{\mathcal{L}},\ \forall i \in \mathbb{I}_{[0,\nu]} \iff \mathbf{C}\mathbf{A}^i\zeta \in \bar{\mathcal{L}},\ \forall i \in \mathbb{I}_{\geq 0}.
    \end{equation}
    According to~\cite[Algorithm~3.1]{gilbert1991linear}, $\nu$ is the smallest non-negative integer for which $\bar{\mathcal{S}}_\nu \subseteq \bar{\mathcal{S}}_{\nu+1}$, i.e., we can find $\nu$ by finding the smallest non-negative integer satisfying
    \begin{equation} \label{eq:nu_containment}
         \bar{\mathcal{S}}_\nu \subseteq \bar{\mathcal{D}}_{\nu+1},
    \end{equation}
    which is exactly Step~\ref{algstep:nu} of Algorithm~\ref{alg:terminal_set}.
    \par After obtaining $\nu$, we know that~\eqref{eq:nu_equivalence} holds for any $\zeta \in \mathbb{R}^{Nn^2+n}$, meaning that it also holds for $\mathbf{A}^{\mu+1}\xi,\ \xi \in \mathbb{R}^{Nn^2+n}$ (where $\mu \in \mathbb{I}_{\geq 0}$):
    \begin{equation*} \label{eq:mu_nu_equivalence}
        \mathbf{C}\mathbf{A}^i\xi \in \bar{\mathcal{L}},\forall i \in \mathbb{I}_{[\mu+1,\mu+\nu+1]} \iff \mathbf{C}\mathbf{A}^i\xi \in \bar{\mathcal{L}},\forall i \in \mathbb{I}_{\geq \mu+1},
    \end{equation*}
    or equivalently,
    \begin{equation*}
        \bigcap_{i=\mu+1}^{\nu+\mu+1} \bar{\mathcal{D}}_i = \bigcap_{i=\mu+1}^\infty \bar{\mathcal{D}}_i.
    \end{equation*}
    Consequently, the set inclusion
    \begin{equation} \label{eq:mu_containment}
        \mathcal{S}_\mu \subseteq \bigcap_{i=\mu+1}^{\nu+\mu+1} \bar{\mathcal{D}}_i
    \end{equation}
    in Step~\ref{algstep:mu} of Algorithm~\ref{alg:terminal_set} is equivalent to checking the original set inclusion~\eqref{eq:terminal_set_Smu_inclusion} in Theorem~\ref{thm:terminal_set}, concluding the proof.
   \end{proof}

\subsection{S-procedure to find \texorpdfstring{$\nu$}{v} in Step~\ref{algstep:nu} of Algorithm~\ref{alg:terminal_set}} \label{app:finding_nu}
In the following, it is shown how to use the S-procedure to formulate a sufficient condition for the set containment~\eqref{eq:nu_containment}. For any given $i$, $\mathbf{C}\mathbf{A}^i\zeta \in \bar{\mathcal{L}}$ is 
equivalent to the following pair of inequalities:
\begin{equation} \label{eq:L_quadratic}
    \begin{split} 
        \zeta^\top \mathbf{A}^{i\top} \mathbf{C}^\top F_j \mathbf{C} \mathbf{A}^i \zeta + 2f_j^\top\mathbf{C}\mathbf{A}^i \zeta + \varphi_j &\geq 0, \\
        2g_j^\top \mathbf{C} \mathbf{A}^i \zeta + b_j &\geq 0,
    \end{split}
\end{equation}
$\forall j \in \mathbb{I}_{[1,c]}$, where
\begin{equation} \label{eq:Ffg}
    \begin{split}
        F_j &= \begin{bmatrix}
        L_j^\top L_j & \\ & -\tilde{p}^j L_j^\top L_j \otimes \mathbf{\Sigma}^\mathrm{w}_N
        \end{bmatrix},\\
        f_j^\top &= \begin{bmatrix}
            -b_jL_j & 0%_{1,Nnd}
        \end{bmatrix}, \\
        \varphi_j &= b_j^2 - \tilde{p}^jL_jC_K\Sigma^\mathrm{x}_\infty C_K^\top L_j^\top, \\
        g_j^\top &= \frac{1}{2}\begin{bmatrix} -L_j & 0%_{1,Nnd}
        \end{bmatrix}.
    \end{split}
\end{equation}
Thus, the goal is to find $\nu$ such that~\eqref{eq:L_quadratic} $ \forall i \in \mathbb{I}_{[0, \nu]},\, \forall j \in \mathbb{I}_{[1,c]}$ implies~\eqref{eq:L_quadratic} for $i=\nu+1,\, \forall j \in \mathbb{I}_{[1,c]}$.
According to the S-procedure for quadratic functions and nonstrict inequalities (see~\cite[Section~2.6.3]{boyd1994linear}), a sufficient condition for this implication is the existence of non-negative scalars $\alpha_{k,l}^{(j)}, \beta_{k,l}^{(j)}, \gamma_{k,l}^{(j)}, \delta_{k,l}^{(j)}$ ($k \in \mathbb{I}_{[0,\nu]}$, $l \in \mathbb{I}_{[1,c]}$) such that the following LMIs hold for all $j \in \mathbb{I}_{[1,c]}$:
\begin{equation*} \label{eq:nu_LMI_f}
    \begin{split}
        &\begin{bmatrix}
            \mathbf{A}^{\nu+1\top} \mathbf{C}^\top F_j \mathbf{C} \mathbf{A}^{\nu+1} & \mathbf{A}^{\nu+1\top} \mathbf{C}^\top f_j\\ f_j^\top\mathbf{C}\mathbf{A}^{\nu+1} & \varphi_j
        \end{bmatrix} \\
        &\ -\sum_{k=0}^\nu \sum_{l=1}^c \alpha_{k,l}^{(j)} \begin{bmatrix}
            \mathbf{A}^{k\top} \mathbf{C}^\top F_l \mathbf{C} \mathbf{A}^k & \mathbf{A}^{k\top} \mathbf{C}^\top f_l\\ f_l^\top\mathbf{C}\mathbf{A}^k & \varphi_l
        \end{bmatrix} \\
        &\ -\sum_{k=0}^\nu \sum_{l=1}^c \beta_{k,l}^{(j)} \begin{bmatrix}
            0 & \mathbf{A}^{k\top} \mathbf{C}^\top g_l\\ g_l^\top\mathbf{C}\mathbf{A}^k & b_l
        \end{bmatrix}\succeq 0,
        \end{split}
\end{equation*}
and
\begin{equation*} \label{eq:nu_LMI_g}
    \begin{split}
        &\begin{bmatrix}
            0 & \mathbf{A}^{\nu+1\top} \mathbf{C}^\top g_j\\ g_j^\top\mathbf{C}\mathbf{A}^{\nu+1} & b_j
        \end{bmatrix} \\
        &\ -\sum_{k=0}^\nu \sum_{l=1}^c \gamma_{k,l}^{(j)} \begin{bmatrix}
            \mathbf{A}^{k\top} \mathbf{C}^\top F_l \mathbf{C} \mathbf{A}^k & \mathbf{A}^{k\top} \mathbf{C}^\top f_l\\ f_l^\top\mathbf{C}\mathbf{A}^k & \varphi_l
        \end{bmatrix} \\
        &\ -\sum_{k=0}^\nu \sum_{l=1}^c \delta_{k,l}^{(j)} \begin{bmatrix}
            0 & \mathbf{A}^{k\top} \mathbf{C}^\top g_l\\ g_l^\top\mathbf{C}\mathbf{A}^k & b_l
        \end{bmatrix}\succeq 0.
        \end{split}
\end{equation*}

\subsection{S-procedure to find \texorpdfstring{$\mu$}{u} in Step~\ref{algstep:mu} of Algorithm~\ref{alg:terminal_set}} \label{app:finding_mu}
Similarly to~\eqref{eq:L_quadratic}, $(z, \psi) \in \mathcal{S}_\mu$ is equivalent to the following pair of inequalities:
\begin{equation} \label{eq:mu_L_quadratic}
    \begin{split} 
        \zeta^\top \mathbf{A}^{i\top} \mathbf{C}^\top F_j \mathbf{C} \mathbf{A}^i \zeta + 2f_j^\top\mathbf{C}\mathbf{A}^i \zeta + \phi_{i,j} &\geq 0, \\
        2g_j^\top \mathbf{C} \mathbf{A}^i \zeta + b_j &\geq 0,
    \end{split}
\end{equation}
$\forall j \in \mathbb{I}_{[1,c]}$ and $\forall i \in \mathbb{I}_{[0,\mu]}$, where $F_j$, $f_j$, and $g_j$ are defined in~\eqref{eq:Ffg}, and
\begin{equation*}
    \phi_{i,j} = b_j^2 - \tilde{p}^j L_jC_K\Sigma^\mathrm{x}_iC_K^\top L_j^\top.
\end{equation*}
Once again, the S-procedure provides a sufficient condition for~\eqref{eq:mu_L_quadratic}. If there exist non-negative scalars $\alpha_{k,l}^{(i,j)}, \beta_{k,l}^{(i,j)}, \gamma_{k,l}^{(i,j)}, \delta_{k,l}^{(i,j)}$ ($k \in \mathbb{I}_{[0,\mu]}$, $l \in \mathbb{I}_{[1,c]}$) such that the following LMIs hold $\forall j \in \mathbb{I}_{[1,c]}, \forall i \in \mathbb{I}_{[\mu+1,\mu+\nu+1]}$
\begin{equation*} \label{eq:mu_LMI_f}
    \begin{split}
        &\begin{bmatrix}
            \mathbf{A}^{i\top} \mathbf{C}^\top F_j \mathbf{C} \mathbf{A}^i & \mathbf{A}^{i\top} \mathbf{C}^\top f_j\\ f_j^\top\mathbf{C}\mathbf{A}^i & \varphi_j
        \end{bmatrix} \\
        &\ -\sum_{k=0}^\mu \sum_{l=1}^c \alpha_{k,l}^{(i,j)} \begin{bmatrix}
            \mathbf{A}^{k\top} \mathbf{C}^\top F_l \mathbf{C} \mathbf{A}^k & \mathbf{A}^{k\top} \mathbf{C}^\top f_l\\ f_l^\top\mathbf{C}\mathbf{A}^k & \phi_{l,k}
        \end{bmatrix} \\
        &\ -\sum_{k=0}^\mu \sum_{l=1}^c \beta_{k,l}^{(i,j)} \begin{bmatrix}
            0 & \mathbf{A}^{k\top} \mathbf{C}^\top g_l\\ g_l^\top\mathbf{C}\mathbf{A}^k & b_l
        \end{bmatrix}\succeq 0,
        \end{split}
\end{equation*}
and
\begin{equation*} \label{eq:mu_LMI_g}
    \begin{split}
        &\begin{bmatrix}
            0 & \mathbf{A}^{i\top} \mathbf{C}^\top g_j\\ g_j^\top\mathbf{C}\mathbf{A}^i & b_j
        \end{bmatrix} \\
        &\ -\sum_{k=0}^\mu \sum_{l=1}^c \gamma_{k,l}^{(i,j)} \begin{bmatrix}
            \mathbf{A}^{k\top} \mathbf{C}^\top F_l \mathbf{C} \mathbf{A}^k & \mathbf{A}^{k\top} \mathbf{C}^\top f_l\\ f_l^\top\mathbf{C}\mathbf{A}^k & \phi_{l,k}
        \end{bmatrix} \\
        &\ -\sum_{k=0}^\mu \sum_{l=1}^c \delta_{k,l}^{(i,j)} \begin{bmatrix}
            0 & \mathbf{A}^{k\top} \mathbf{C}^\top g_l\\ g_l^\top\mathbf{C}\mathbf{A}^k & b_l
        \end{bmatrix}\succeq 0,
        \end{split}
\end{equation*}
then $\mu$ satisfies~\eqref{eq:mu_containment}. 

\subsection{Proof of Theorem~\ref{thm:RHC}} \label{app:RHC_proof}
\begin{proof}
    \textit{Part I: Recursive feasibility.} Given the optimal solution of~\eqref{eq:RHC} at time step $k \in \mathbb{I}_{> 0}$ (or that of~\eqref{eq:DMC} at time $k = 0$), consider the candidate solution $\hat{\mathbf{z}}_k$, $\hat{\mathbf{v}}_k$, $\hat{\mathbf{\Phi}}^\mathrm{x}_{:|k}$, and $\hat{\mathbf{\Phi}}^\mathrm{u}_{:|k}$, defined in~\eqref{eq:hat_zvPsi_def}-\eqref{eq:hat_zNPsiN_def}. As the constraints of~\eqref{eq:RHC} are constructed based on this exact candidate sequence, they are satisfied with equality, proving recursive feasibility.
    \par \textit{Part II: Closed-loop chance constraint satisfaction.} 
    The proof follows the arguments in Part II of the proof of Proposition~\ref{prop:Rec-SMPC}, by proving that the proposed method ensures
    \begin{equation} \label{eq:CS_requirement}
        \mathrm{Pr}[(x^\star_{i|k}, u^\star_{i|k}) \in \mathcal{C}^j|w_{0:k-1}] \geq p^j_{i|k},\ \forall j \in \mathbb{I}_{[1,c]}.
    \end{equation}
    \par Let $\mathbf{w}_k := w_{0:k-1}$. It is known that for $a \in \mathbb{R}$ and scalar Gaussian random variable $y$ with mean $\mu_\mathrm{y}$ and variance $\sigma_\mathrm{y}^2$,
    \begin{equation} \label{eq:Gaussian_CDF}
        \mathrm{Pr}[y \leq a] = \Phi\left(\frac{a - \mu_\mathrm{y}}{\sigma_\mathrm{y}}\right),
    \end{equation}
    where $\Phi$ denotes the cumulative distribution function of the standard normal distribution. Given the Gaussian disturbance~\eqref{eq:system}, it can be seen that $p(x^\star_{i|k}, u^\star_{i|k}|\mathbf{w}_k)$ and $p(x^\star_{i+1|k-1}, u^\star_{i+1|k-1}|\mathbf{w}_k)$ are Gaussian distributed, with means and variances as follows:
    \begin{align*}
        \mathbb{E}[[x_{i|k}^{\star\top}, u_{i|k}^{\star\top}]^\top|\mathbf{w}_k] &= [z_{i|k}^{\star\top}, v_{i|k}^{\star\top}]^\top \\
         \mathrm{Var}[[x_{i|k}^{\star\top}, u_{i|k}^{\star\top}]^\top|\mathbf{w}_k] &= \begin{bmatrix}
            \mathbf{\Phi}^{\mathrm{x}\star}_{i|k} \\ \mathbf{\Phi}^{\mathrm{u}\star}_{i|k}
        \end{bmatrix} \mathbf{\Sigma}^\mathrm{w}_i [*]^\top,
    \end{align*}
    $\forall i \in \mathbb{I}_{[0:N-1]}$, and in the tail of the horizon, 
    \begin{equation*}
        \mathbb{E}[[x_{N+i|k}^{\star\top}, u_{N+i|k}^{\star\top}]^\top|\mathbf{w}_k] = [I_n, K^\top]^\top A_K^iz^\star_{N|k},
    \end{equation*}
    \begin{equation*}
    \begin{split}
        \mathrm{Var}[[&x_{N+i|k}^{\star\top}, u_{N+i|k}^{\star\top}]^\top|\mathbf{w}_k] = \\ &\begin{bmatrix}
            I_n \\ K
        \end{bmatrix}
        \begin{bmatrix}
            A_K^i\mathbf{\Phi}^{\mathrm{x}\star}_{N|k} & I_n
        \end{bmatrix} \begin{bmatrix}
            \mathbf{\Sigma}^\mathrm{w}_N & \\ & \Sigma^\mathrm{x}_i
        \end{bmatrix} [*]^\top,
    \end{split}
    \end{equation*}
    $\forall i \in \mathbb{I}_{\geq 0}$. Similarly,
    \begin{align*}
        \mathbb{E}[[x^{\star\top}_{i+1|k-1} u^{\star\top}_{i+1|k-1}]^\top|\mathbf{w}_k] &= [\hat{z}^\top_{i|k}, \hat{v}_{i|k}^\top]^\top \\
        \mathrm{Var}[[x_{i+1|k-1}^{\star\top}, u_{i+1|k-1}^{\star\top}]^\top|\mathbf{w}_k] &= \begin{bmatrix}
            \hat{\mathbf{\Phi}}^\mathrm{x}_{i|k} \\ \hat{\mathbf{\Phi}}^\mathrm{u}_{i|k} 
        \end{bmatrix} \mathbf{\Sigma}^\mathrm{w}_i [*]^\top
    \end{align*}
    $\forall i \in \mathbb{I}_{[0:N-1]}$, and finally,
    \begin{equation*}
        \mathbb{E}[[x^{\star\top}_{N+i+1|k-1}, u^{\star\top}_{N+i+1|k-1}]^\top|\mathbf{w}_k] = [I_n, K^\top]^\top A_K^i\hat{z}_{N|k}
    \end{equation*}
    \begin{equation*}
    \begin{split}
        \mathrm{Var}[[&x_{N+i+1|k-1}^{\star\top}, u_{N+i+1|k-1}^{\star\top}]^\top|\mathbf{w}_k] = \\ 
        &\begin{bmatrix}
            I_n \\ K
        \end{bmatrix}
        \begin{bmatrix}
            A_K^i\hat{\mathbf{\Phi}}^\mathrm{x}_{N|k} & I_n
        \end{bmatrix} \begin{bmatrix}
            \mathbf{\Sigma}^\mathrm{w}_N & \\ & \Sigma^\mathrm{x}_i
        \end{bmatrix} [*]^\top
    \end{split}
    \end{equation*}
    $\forall i \in \mathbb{I}_{\geq 0}$. 
    \par First, consider $i \in \mathbb{I}_{[0,N-1]}$. Due to~\eqref{eq:Gaussian_CDF} combined with the fact that $\Phi$ is strictly monotonically increasing and using the derived formulae for the means and variances, we can see that~\eqref{eq:CS_requirement} is equivalent to
    \begin{equation*}
        \frac{b_j-G_j z^\star_{i|k} -H_j v^\star_{i|k}}{\norm{\mathbf{\Sigma}^{\mathrm{w},1/2}_i \begin{bmatrix} \mathbf{\Phi}^{\mathrm{x}\star\top}_{i|k} & \mathbf{\Phi}^{\mathrm{u}\star\top}_{i|k}\end{bmatrix} \begin{bmatrix} G_j^\top \\ H_j^\top \end{bmatrix}}} \geq \alpha^j_{i|k};
    \end{equation*}
    in the non-degenerate case (i.e., when~\eqref{eq:pjik_degenerate} does not hold). In the degenerate case,~\eqref{eq:CS_requirement} vanishes whenever~\eqref{eq:previous_satisfied} does not hold, and otherwise it leads to the constraint set~\eqref{eq:Cijk1}. Thus,~\eqref{eq:RHC:constraints_N} ensures that~\eqref{eq:CS_requirement} holds $\forall k \in \mathbb{I}_{> 0}, \forall i \in \mathbb{I}_{[0,N-1]}$
    \par As for $i \in \mathbb{I}_{\geq N}$, similar arguments can be used to show that~\eqref{eq:CS_requirement} is equivalent to~\eqref{eq:SOC_k>0_tail}. Therefore,~\eqref{eq:RHC:constraints_terminal} implies~\eqref{eq:CS_requirement} $\forall k \in \mathbb{I}_{> 0}, \forall i \in \mathbb{I}_{\geq N}$. Furthermore,~\eqref{eq:DMC} ensures that~\eqref{eq:CS_requirement} holds $\forall i \in \mathbb{I}_{\geq 0}$ at $k=0$. Thus~\eqref{eq:CS_requirement} holds $\forall k \in \mathbb{I}_{\geq 0}, \forall i \in \mathbb{I}_{\geq 0}$ and hence closed-loop chance constraint satisfaction follows analogously to Proposition~\ref{prop:Rec-SMPC}.
    \par \textit{Part III: Bounded asymptotic average cost}.
    Let $J^\star_k$ denote the optimal cost of~\eqref{eq:DMC} and~\eqref{eq:RHC}, for $k=0$ and $k \in \mathbb{I}_{> 0}$, respectively, and define $\hat{J}_k$ as the cost associated with the candidate solution:
    \begin{align*}
        J^\star_k &= \sum_{i=0}^{N-1}(\nnorm{z^\star_{i|k}}^2_Q + \nnorm{v^\star_{i|k}}^2_R)  \\
        &+ \sum_{i=1}^{N-1}(\mathrm{tr}(Q\mathbf{\Phi}^{\mathrm{x}\star}_{i|k}\mathbf{\Sigma}^\mathrm{w}_i\mathbf{\Phi}^{\mathrm{x}\star\top}_{i|k}) + \mathrm{tr}(R\mathbf{\Phi}^{\mathrm{u}\star}_{i|k}\mathbf{\Sigma}^\mathrm{w}_i\mathbf{\Phi}^{\mathrm{u}\star\top}_{i|k}))  \\ 
        &+ \nnorm{z^\star_{N|k}}^2_P + \mathrm{tr}(P\mathbf{\Phi}^{\mathrm{x}\star}_{N|k}\mathbf{\Sigma}^\mathrm{w}_N\mathbf{\Phi}^{\mathrm{x}\star\top}_{N|k}),
    \end{align*}
    and
    \begin{align*}
        \hat{J}&_{k+1} = \sum_{i=0}^{N-1}(\nnorm{\hat{z}_{i|k+1}}^2_Q + \nnorm{\hat{v}_{i|k+1}}^2_R) \\
        &+ \sum_{i=1}^{N-1}(\mathrm{tr}(Q\hat{\mathbf{\Phi}}^\mathrm{x}_{i|k+1}\mathbf{\Sigma}^\mathrm{w}_i\hat{\mathbf{\Phi}}^{\mathrm{x}\top}_{i|k+1}) + \mathrm{tr}(R\hat{\mathbf{\Phi}}^\mathrm{u}_{i|k+1}\mathbf{\Sigma}^\mathrm{w}_i\hat{\mathbf{\Phi}}^{\mathrm{u}\top}_{i|k+1}))  \\ 
        & + \nnorm{\hat{z}_{N|k+1}}^2_P +\mathrm{tr}(P\hat{\mathbf{\Phi}}^\mathrm{x}_{N|k+1}\mathbf{\Sigma}^\mathrm{w}_N\hat{\mathbf{\Phi}}^{\mathrm{x}\top}_{N|k+1}).
    \end{align*}
    Then,
    \begin{align} \label{eq:proofs:beg_difference}
        \mathbb{E}_{w_k}[J^\star_{k+1} | w_{0:k-1}] - J^\star_k  \leq \mathbb{E}_{w_k}[\hat{J}_{k+1} | w_{0:k-1}] - J^\star_k.
    \end{align}
    Using~\eqref{eq:hat_zvPsi_def}-\eqref{eq:hat_zNPsiN_def}, it can be seen that
    \begin{align*}
        \underset{w_k}{\mathbb{E}}[\nnorm{\hat{z}_{i|k+1}}_Q^2 + \nnorm{\hat{v}_{i|k+1}}_R^2 | w_{0:k-1}] = \nnorm{z^\star_{i+1|k}}_Q^2 +\nnorm{v^\star_{i+1|k}}_R^2 \\+ \mathrm{tr}(Q\Phi^{\mathrm{x}\star}_{i+1,1|k}\Sigma^\mathrm{w}\Phi^{\mathrm{x}\star\top}_{i+1,1|k}) + \mathrm{tr}(R\Phi^{\mathrm{u}\star}_{i+1,1|k}\Sigma^\mathrm{w}\Phi^{\mathrm{u}\star\top}_{i+1,1|k}),
    \end{align*}
    $\forall i \in \mathbb{I}_{[0,N-1]}$, and
    \begin{equation*}
    \begin{split}
        \underset{w_k}{\mathbb{E}}[\nnorm{\hat{z}_{N|k+1}}&_P^2 =\nnorm{A_Kz^\star_{N|k}}_P^2 \\ +& \mathrm{tr}(PA_K\Phi^{\mathrm{x}\star}_{N,1|k}\Sigma^\mathrm{w}\Phi^{\mathrm{x}\star\top}_{N,1|k}A_K^\top).
    \end{split}
    \end{equation*}
    Therefore, using the cyclic property and linearity of the trace operator,
    \begin{align}
        \mathbb{E}_{w_k}[&\hat{J}_{k+1} | w_{0:k-1}] - J^\star_k  = \mathrm{tr}(P\Sigma^\mathrm{w}) -\nnorm{z^\star_{0|k}}^2_Q - \nnorm{v^\star_{0|k}}^2_R \nonumber\\
        &+ \mathrm{tr}((Q + K^\top R K + A_K^\top P A_K - P)\mathbf{\Phi}^{\mathrm{x}\star}_{N|k}\mathbf{\Sigma}^\mathrm{w}_N\mathbf{\Phi}^{\mathrm{x}\star\top}_{N|k}), \nonumber \\
        &+ \nnorm{z^\star_{N|k}}_{Q + K^\top R K + A_K^\top P A_K - P}^2 \label{eq:proofs:end_difference}
    \end{align}
    where the last two terms vanish since $P$ satisfies the Lyapunov equation~\eqref{eq:P_Lyapunov}. Thus,~\eqref{eq:RHC:init},~\eqref{eq:RHC:control_law}, and~\eqref{eq:proofs:beg_difference} combined with~\eqref{eq:proofs:end_difference} results in the cost decrease
    \begin{equation} \label{eq:proofs:cost_decrease}
        \mathbb{E}_{w_k}[J^\star_{k+1} | w_{0:k-1}] - J^\star_k \leq\mathrm{tr}(P\Sigma^\mathrm{w}) -\nnorm{x_k}^2_Q - \nnorm{u_k}^2_R.
    \end{equation}
    Following standard arguments from the SMPC literature using the law of total expectation and non-negativity of the cost (e.g.~\cite[Corollary~1]{hewing2020recursively}),~\eqref{eq:proofs:cost_decrease} leads to~\eqref{eq:lavg}. 
\end{proof}
    
\bibliographystyle{IEEEtran} 
\bibliography{Literature} 

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{figures/marcell_bartos.jpg}}]{Marcell Bartos}  \looseness -1 
 is a Ph.D. student under the supervision of Prof. Melanie Zeilinger and Prof. Florian DÃ¶rfler at ETH ZÃ¼rich. He obtained his B.Sc. degree in Mechatronics Engineering from the Budapest University of Technology and Economics in 2021, and his M.Sc. degree in Robotics, Systems and Control at ETH ZÃ¼rich in 2024. His areas of interest are model predictive control and online learning for control.
\end{IEEEbiography}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{figures/didier.jpg}}]{Alexandre Didier} \looseness -1 received his BSc. in Mechanical Engineering from ETH Zurich in 2018 and his MSc. in Robotics, Systems and Control from ETH Zurich in 2020. He is now pursuing a Ph.D. under the supervision of Prof. Dr. Melanie Zeilinger in the Intelligent Control Systems Group at the Institute for Dynamic Systems and Control (IDSC) at ETH Zurich. His research interests lie especially in Model Predictive Control and Regret Minimisation for safety-critical and uncertain systems.
\end{IEEEbiography}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{figures/sieber.jpg}}]{Jerome Sieber} \looseness -1 received his MSc. in Robotics, Systems and Control from ETH Zurich, Switzerland, in 2019, where he is currently pursuing a Ph.D. degree at the Institute for Dynamic Systems and Control (IDSC) under the supervision of Prof. Dr. Melanie N. Zeilinger. His research focuses on robust model predictive control, its applications on real-world problems, and novel neural network architectures.
\end{IEEEbiography}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{figures/koehler.png}}]{Johannes K\"ohler} \looseness -1  received the Ph.D. degree from the University of Stuttgart, Germany, in 2021. 
He is currently a postdoctoral researcher at ETH Zurich, Switzerland.
His research interests are in the area of model predictive control and control and estimation for nonlinear uncertain systems. 
He has received various awards for his work, including the 2021 European Systems \& Control PhD Thesis Award, the IEEE CSS George S. Axelby Outstanding Paper Award 2022, and the Journal of Process Control Paper Award 2023. 
\end{IEEEbiography}
\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{figures/melanie_zeilinger.jpg}}]{Melanie N. Zeilinger}  \looseness -1 is an Associate Professor at ETH Zurich, Switzerland. She received the Diploma degree in engineering cybernetics from the University of Stuttgart, Germany, in 2006, and the Ph.D. degree with honors in electrical engineering from ETH Zurich, Switzerland, in 2011. From 2011 to 2012 she was a Postdoctoral Fellow with the Ecole Polytechnique Federale de Lausanne (EPFL), Switzerland. She was a Marie Curie Fellow and Postdoctoral Researcher with the Max Planck Institute for Intelligent Systems, TÃ¼bingen, Germany until 2015 and with the Department of Electrical Engineering and Computer Sciences at the University of California at Berkeley, CA, USA, from 2012 to 2014. From 2018 to 2019 she was a professor at the University of Freiburg, Germany. She was awarded the ETH medal for her PhD thesis, an SNF Professorship, the ETH Golden Owl for exceptional teaching in 2022 and the European Control Award in 2023. Her research interests include learning-based control with applications to robotics and human-in-the-loop control.
\end{IEEEbiography}
\end{document}