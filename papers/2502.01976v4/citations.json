[
  {
    "index": 0,
    "papers": [
      {
        "key": "jang2023exploring",
        "author": "Jang, Joel and Kim, Seungone and Ye, Seonghyeon and Kim, Doyoung and Logeswaran, Lajanugen and Lee, Moontae and Lee, Kyungjae and Seo, Minjoon",
        "title": "Exploring the benefits of training expert language models over instruction tuning"
      },
      {
        "key": "chronopoulou2023adaptersoupweightaveragingimprove",
        "author": "Alexandra Chronopoulou and Matthew E. Peters and Alexander Fraser and Jesse Dodge",
        "title": "AdapterSoup: Weight Averaging to Improve Generalization of Pretrained Language Models"
      },
      {
        "key": "diao2023mixtureofdomainadaptersdecouplinginjectingdomain",
        "author": "Shizhe Diao and Tianyang Xu and Ruijia Xu and Jiawei Wang and Tong Zhang",
        "title": "Mixture-of-Domain-Adapters: Decoupling and Injecting Domain Knowledge to Pre-trained Language Models Memories"
      },
      {
        "key": "lu2023routing",
        "author": "Lu, Keming and Yuan, Hongyi and Lin, Runji and Lin, Junyang and Yuan, Zheng and Zhou, Chang and Zhou, Jingren",
        "title": "Routing to the expert: Efficient reward-guided ensemble of large language models"
      },
      {
        "key": "cheng2024damdynamicadaptermerging",
        "author": "Feng Cheng and Ziyang Wang and Yi-Lin Sung and Yan-Bo Lin and Mohit Bansal and Gedas Bertasius",
        "title": "DAM: Dynamic Adapter Merging for Continual Video QA Learning"
      },
      {
        "key": "lu2024twinmergingdynamicintegrationmodular",
        "author": "Zhenyi Lu and Chenghao Fan and Wei Wei and Xiaoye Qu and Dangyang Chen and Yu Cheng",
        "title": "Twin-Merging: Dynamic Integration of Modular Expertise in Model Merging"
      },
      {
        "key": "chen2023frugalgpt",
        "author": "Chen, Lingjiao and Zaharia, Matei and Zou, James",
        "title": "Frugalgpt: How to use large language models while reducing cost and improving performance"
      },
      {
        "key": "wang2024fusing",
        "author": "Hongyi Wang and Felipe Maia Polo and Yuekai Sun and Souvik Kundu and Eric Xing and Mikhail Yurochkin",
        "title": "Fusing Models with Complementary Expertise"
      },
      {
        "key": "srivatsa-etal-2024-harnessing",
        "author": "Srivatsa, Kv Aditya  and\nMaurya, Kaushal  and\nKochmar, Ekaterina",
        "title": "Harnessing the Power of Multiple Minds: Lessons Learned from {LLM} Routing"
      },
      {
        "key": "stripelis-etal-2024-tensoropera",
        "author": "Stripelis, Dimitris  and\nXu, Zhaozhuo  and\nHu, Zijian  and\nShah, Alay Dilipbhai  and\nJin, Han  and\nYao, Yuhang  and\nZhang, Jipeng  and\nZhang, Tong  and\nAvestimehr, Salman  and\nHe, Chaoyang",
        "title": "{T}ensor{O}pera Router: A Multi-Model Router for Efficient {LLM} Inference"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "mohammadshahi2024routoolearningroutelarge",
        "author": "Alireza Mohammadshahi and Arshad Rafiq Shaikh and Majid Yazdani",
        "title": "Routoo: Learning to Route to Large Language Models Effectively"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "ding2024hybridllmcostefficientqualityaware",
        "author": "Dujian Ding and Ankur Mallick and Chi Wang and Robert Sim and Subhabrata Mukherjee and Victor Ruhle and Laks V. S. Lakshmanan and Ahmed Hassan Awadallah",
        "title": "Hybrid LLM: Cost-Efficient and Quality-Aware Query Routing"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "ong2024routellm",
        "author": "Isaac Ong and Amjad Almahairi and Vincent Wu and Wei-Lin Chiang and Tianhao Wu and Joseph E. Gonzalez and M Waleed Kadous and Ion Stoica",
        "title": "RouteLLM: Learning to Route LLMs with Preference Data"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "pfeiffer2021adapterfusion",
        "author": "Pfeiffer, Jonas  and\nKamath, Aishwarya  and\nR{\\\"u}ckl{\\'e}, Andreas  and\nCho, Kyunghyun  and\nGurevych, Iryna",
        "title": "{A}dapter{F}usion: Non-Destructive Task Composition for Transfer Learning"
      },
      {
        "key": "belofsky2023tokenleveladaptationloraadapters",
        "author": "Joshua Belofsky",
        "title": "Token-Level Adaptation of LoRA Adapters for Downstream Task Generalization"
      },
      {
        "key": "muqeeth2024learningroutespecializedexperts",
        "author": "Mohammed Muqeeth and Haokun Liu and Yufan Liu and Colin Raffel",
        "title": "Learning to Route Among Specialized Experts for Zero-Shot Generalization"
      },
      {
        "key": "wang2024loraflowdynamiclorafusion",
        "author": "Hanqing Wang and Bowen Ping and Shuo Wang and Xu Han and Yun Chen and Zhiyuan Liu and Maosong Sun",
        "title": "LoRA-Flow: Dynamic LoRA Fusion for Large Language Models in Generative Tasks"
      },
      {
        "key": "wu2024mixtureloraexperts",
        "author": "Xun Wu and Shaohan Huang and Furu Wei",
        "title": "Mixture of LoRA Experts"
      },
      {
        "key": "xu2024meteoramultipletasksembeddedlora",
        "author": "Jingwei Xu and Junyu Lai and Yunpeng Huang",
        "title": "MeteoRA: Multiple-tasks Embedded LoRA for Large Language Models"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "ostapenko2024modularllmsbuildingreusing",
        "author": "Oleksiy Ostapenko and Zhan Su and Edoardo Maria Ponti and Laurent Charlin and Nicolas Le Roux and Matheus Pereira and Lucas Caccia and Alessandro Sordoni",
        "title": "Towards Modular LLMs by Building and Reusing a Library of LoRAs"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "shen2024learning",
        "author": "Shen, Shannon Zejiang and Lang, Hunter and Wang, Bailin and Kim, Yoon and Sontag, David",
        "title": "Learning to Decode Collaboratively with Multiple Language Models"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "miao2023specinfer",
        "author": "Miao, Xupeng and Oliaro, Gabriele and Zhang, Zhihao and Cheng, Xinhao and Wang, Zeyu and Zhang, Zhengxin and Wong, Rae Ying Yee and Zhu, Alan and Yang, Lijie and Shi, Xiaoxiang and others",
        "title": "SpecInfer: Accelerating Generative Large Language Model Serving with Tree-based Speculative Inference and Verification"
      },
      {
        "key": "kwon2023efficient",
        "author": "Kwon, Woosuk and Li, Zhuohan and Zhuang, Siyuan and Sheng, Ying and Zheng, Lianmin and Yu, Cody Hao and Gonzalez, Joseph and Zhang, Hao and Stoica, Ion",
        "title": "Efficient memory management for large language model serving with pagedattention"
      },
      {
        "key": "chen2024magicdec",
        "author": "Chen, Jian and Tiwari, Vashisth and Sadhukhan, Ranajoy and Chen, Zhuoming and Shi, Jinyuan and Yen, Ian En-Hsu and Chen, Beidi",
        "title": "MagicDec: Breaking the Latency-Throughput Tradeoff for Long Context Generation with Speculative Decoding"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "leviathan2023fastinferencetransformersspeculative",
        "author": "Yaniv Leviathan and Matan Kalman and Yossi Matias",
        "title": "Fast Inference from Transformers via Speculative Decoding"
      },
      {
        "key": "chen2023accelerating",
        "author": "Chen, Charlie and Borgeaud, Sebastian and Irving, Geoffrey and Lespiau, Jean-Baptiste and Sifre, Laurent and Jumper, John",
        "title": "Accelerating large language model decoding with speculative sampling"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "bhendawade2024speculativestreamingfastllm",
        "author": "Nikhil Bhendawade and Irina Belousova and Qichen Fu and Henry Mason and Mohammad Rastegari and Mahyar Najibi",
        "title": "Speculative Streaming: Fast LLM Inference without Auxiliary Models"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "cai2024medusa",
        "author": "Tianle Cai and Yuhong Li and Zhengyang Geng and Hongwu Peng and Jason D. Lee and Deming Chen and Tri Dao",
        "title": "Medusa: Simple LLM Inference Acceleration Framework with Multiple Decoding Heads"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "miao2023specinfer",
        "author": "Miao, Xupeng and Oliaro, Gabriele and Zhang, Zhihao and Cheng, Xinhao and Wang, Zeyu and Zhang, Zhengxin and Wong, Rae Ying Yee and Zhu, Alan and Yang, Lijie and Shi, Xiaoxiang and others",
        "title": "SpecInfer: Accelerating Generative Large Language Model Serving with Tree-based Speculative Inference and Verification"
      },
      {
        "key": "chen2024sequoia",
        "author": "Chen, Zhuoming and May, Avner and Svirschevski, Ruslan and Huang, Yuhsun and Ryabinin, Max and Jia, Zhihao and Chen, Beidi",
        "title": "Sequoia: Scalable, Robust, and Hardware-aware Speculative Decoding"
      }
    ]
  }
]