\section{Social Impact and Limitation}
\label{app:discussion}

\textbf{Potential Social Impact.} Our work offers critical insights into the superficial aspects of alignment, potentially guiding future methodologies for robust and secure alignment. The implications regarding the transferability and restorability of superficial knowledge present mitigation for potential risks associated with alignment. Consequently, we envision that improved alignment, rooted in our findings, could yield significant positive social impacts for the proper use of AI. However, we also acknowledge that the misuse of superficial knowledge could pose risks to alignment in the short term. Specifically, an overreliance on superficial knowledge may obscure or ignore deeper, underlying knowledge essential to true alignment. This can lead to AI systems that seem aligned on the surface but fail to account for complex or nuanced factors. Thus, we call for more efforts to be devoted to enhancing the alignment with non-superficial knowledge.

\textbf{Limitation.} In this paper, we measure the portion of such knowledge in existing aligned LLMs and use examples to demonstrate what is superficial knowledge and what is beyond superficial.While the non-superficial part in alignment is not fully understood. The problem remains challenging as the rest of knowledge could be multi-faceted, and could be complicated with diverse sequential dependencies.