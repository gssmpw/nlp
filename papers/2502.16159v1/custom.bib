@article{jiang2023mistral,
  title={Mistral 7B},
  author={Jiang, Albert Q and Sablayrolles, Alexandre and Mensch, Arthur and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Bressand, Florian and Lengyel, Gianna and Lample, Guillaume and Saulnier, Lucile and others},
  journal={arXiv preprint arXiv:2310.06825},
  year={2023}
}

@article{lei2024finlangnet,
  title={FinLangNet: A Novel Deep Learning Framework for Credit Risk Prediction Using Linguistic Analogy in Financial Data},
  author={Lei, Yu and Wang, Zixuan and Liu, Chu and Wang, Tongyao and Lee, Dongyang},
  journal={arXiv preprint arXiv:2404.13004},
  year={2024}
}
@article{feng2023empowering,
  title={Empowering many, biasing a few: Generalist credit scoring through large language models},
  author={Feng, Duanyu and Dai, Yongfu and Huang, Jimin and Zhang, Yifang and Xie, Qianqian and Han, Weiguang and Chen, Zhengyu and Lopez-Lira, Alejandro and Wang, Hao},
  journal={arXiv preprint arXiv:2310.00566},
  year={2023}
}

@article{hu2021lora,
  title={Lora: Low-rank adaptation of large language models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  journal={arXiv preprint arXiv:2106.09685},
  year={2021}
}

@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@article{touvron2023llama,
  title={Llama: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}

@inproceedings{zhang2023xuanyuan,
  title={Xuanyuan 2.0: A large chinese financial chat model with hundreds of billions parameters},
  author={Zhang, Xuanyu and Yang, Qing},
  booktitle={Proceedings of the 32nd ACM international conference on information and knowledge management},
  pages={4435--4439},
  year={2023}
}

@article{zhou2024lima,
  title={Lima: Less is more for alignment},
  author={Zhou, Chunting and Liu, Pengfei and Xu, Puxin and Iyer, Srinivasan and Sun, Jiao and Mao, Yuning and Ma, Xuezhe and Efrat, Avia and Yu, Ping and Yu, Lili and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{pruthi2020estimating,
  title={Estimating training data influence by tracing gradient descent},
  author={Pruthi, Garima and Liu, Frederick and Kale, Satyen and Sundararajan, Mukund},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={19920--19930},
  year={2020}
}
@article{liu2024deepseek,
  title={Deepseek-v3 technical report},
  author={Liu, Aixin and Feng, Bei and Xue, Bing and Wang, Bingxuan and Wu, Bochao and Lu, Chengda and Zhao, Chenggang and Deng, Chengqi and Zhang, Chenyu and Ruan, Chong and others},
  journal={arXiv preprint arXiv:2412.19437},
  year={2024}
}

@article{huang2024survey,
  title={A survey on hallucination in large language models: Principles, taxonomy, challenges, and open questions},
  author={Huang, Lei and Yu, Weijiang and Ma, Weitao and Zhong, Weihong and Feng, Zhangyin and Wang, Haotian and Chen, Qianglong and Peng, Weihua and Feng, Xiaocheng and Qin, Bing and others},
  journal={ACM Transactions on Information Systems},
  year={2024},
  publisher={ACM New York, NY}
}

@article{luo2023empirical,
  title={An empirical study of catastrophic forgetting in large language models during continual fine-tuning},
  author={Luo, Yun and Yang, Zhen and Meng, Fandong and Li, Yafu and Zhou, Jie and Zhang, Yue},
  journal={arXiv preprint arXiv:2308.08747},
  year={2023}
}

@article{zhao2024revolutionizing,
  title={Revolutionizing finance with llms: An overview of applications and insights},
  author={Zhao, Huaqin and Liu, Zhengliang and Wu, Zihao and Li, Yiwei and Yang, Tianze and Shu, Peng and Xu, Shaochen and Dai, Haixing and Zhao, Lin and Mai, Gengchen and others},
  journal={arXiv preprint arXiv:2401.11641},
  year={2024}
}

@inproceedings{lin2024data,
  title={Data-efficient Fine-tuning for LLM-based Recommendation},
  author={Lin, Xinyu and Wang, Wenjie and Li, Yongqi and Yang, Shuo and Feng, Fuli and Wei, Yinwei and Chua, Tat-Seng},
  booktitle={Proceedings of the 47th international ACM SIGIR conference on research and development in information retrieval},
  pages={365--374},
  year={2024}
}

@article{li2023one,
  title={One shot learning as instruction data prospector for large language models},
  author={Li, Yunshui and Hui, Binyuan and Xia, Xiaobo and Yang, Jiaxi and Yang, Min and Zhang, Lei and Si, Shuzheng and Liu, Junhao and Liu, Tongliang and Huang, Fei and others},
  journal={arXiv preprint arXiv:2312.10302},
  year={2023}
}
@article{xia2024less,
  title={Less: Selecting influential data for targeted instruction tuning},
  author={Xia, Mengzhou and Malladi, Sadhika and Gururangan, Suchin and Arora, Sanjeev and Chen, Danqi},
  journal={arXiv preprint arXiv:2402.04333},
  year={2024}
}