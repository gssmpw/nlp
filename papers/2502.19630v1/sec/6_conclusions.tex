

\section{Conclusions}
This paper proposes Ev-3DOD, a novel method to utilize an event camera in 3D detection for detecting objects in blind time. To transfer information from active times to the current blind time, we estimate 3D motion based on event data. To effectively fuse sparse LiDAR data with events, we propose a Virtual 3D Event Fusion (V3D-EF) and introduce a motion confidence estimator to define confidence for 3D detection during blind times. For this study, we introduce the first event-based 3D detection dataset, emphasizing its 100 FPS annotations. We hope this work showcases the potential of neuromorphic cameras, inspiring future research.




