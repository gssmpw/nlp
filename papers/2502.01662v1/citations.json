[
  {
    "index": 0,
    "papers": [
      {
        "key": "lu2024merge",
        "author": "Lu, Jinliang and Pang, Ziliang and Xiao, Min and Zhu, Yaochen and Xia, Rui and Zhang, Jiajun",
        "title": "Merge, ensemble, and cooperate! a survey on collaborative strategies in the era of large language models"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "shnitzer2023large",
        "author": "Shnitzer, Tal and Ou, Anthony and Silva, Mirian and Soule, Kate and Sun, Yuekai and Solomon, Justin and Thompson, Neil and Yurochkin, Mikhail",
        "title": "Large Language Model Routing with Benchmark Datasets"
      },
      {
        "key": "lu2023routing",
        "author": "Lu, Keming and Yuan, Hongyi and Lin, Runji and Lin, Junyang and Yuan, Zheng and Zhou, Chang and Zhou, Jingren",
        "title": "Routing to the expert: Efficient reward-guided ensemble of large language models"
      },
      {
        "key": "lu2024blending",
        "author": "Lu, Xiaoding and Liu, Zongyi and Liusie, Adian and Raina, Vyas and Mudupalli, Vineet and Zhang, Yuwen and Beauchamp, William",
        "title": "Blending is all you need: Cheaper, better alternative to trillion-parameters llm"
      },
      {
        "key": "ding2024hybrid",
        "author": "Ding, Dujian and Mallick, Ankur and Wang, Chi and Sim, Robert and Mukherjee, Subhabrata and Ruhle, Victor and Lakshmanan, Laks VS and Awadallah, Ahmed Hassan",
        "title": "Hybrid LLM: Cost-efficient and quality-aware query routing"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "chen2023frugalgpt",
        "author": "Chen, Lingjiao and Zaharia, Matei and Zou, James",
        "title": "Frugalgpt: How to use large language models while reducing cost and improving performance"
      },
      {
        "key": "lee2023ensemble",
        "author": "Lee, Young-Suk and Sultan, Arafat and El-Kurdi, Yousef and Naseem, Tahira and Munawar, Asim and Florian, Hans and Roukos, Salim and Astudillo, Ram{\\'o}n Fernandez",
        "title": "Ensemble-Instruct: Generating Instruction-Tuning Data with a Heterogeneous Mixture of LMs"
      },
      {
        "key": "jiang2023llm",
        "author": "Jiang, Dongfu and Ren, Xiang and Lin, Bill Yuchen",
        "title": "LLM-Blender: Ensembling Large Language Models with Pairwise Ranking and Generative Fusion"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "li2024purifying",
        "author": "Li, Tianlin and Liu, Qian and Pang, Tianyu and Du, Chao and Guo, Qing and Liu, Yang and Lin, Min",
        "title": "Purifying large language models by ensembling a small language model"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "li2023contrastive",
        "author": "Li, Xiang Lisa and Holtzman, Ari and Fried, Daniel and Liang, Percy and Eisner, Jason and Hashimoto, Tatsunori B and Zettlemoyer, Luke and Lewis, Mike",
        "title": "Contrastive Decoding: Open-ended Text Generation as Optimization"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "furkan2024llm",
        "author": "Furkan Tekin, Selim and Ilhan, Fatih and Huang, Tiansheng and Hu, Sihao and Liu, Ling",
        "title": "LLM-TOPLA: Efficient LLM Ensemble by Maximising Diversity"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "leviathan23",
        "author": "Leviathan, Yaniv and Kalman, Matan and Matias, Yossi",
        "title": "Fast inference from transformers via speculative decoding"
      },
      {
        "key": "chen23",
        "author": "Chen, Charlie and Borgeaud, Sebastian and Irving, Geoffrey and Lespiau, Jean-Baptiste and Sifre, Laurent and Jumper, John",
        "title": "Accelerating large language model decoding with speculative sampling"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "zhou24",
        "author": "Yongchao Zhou and Kaifeng Lyu and Ankit Singh Rawat and Aditya Menon and Afshin Rostamizadeh and Sanjiv Kumar and Jean-Fran\u00e7ois Kagy and Rishabh Agarwal",
        "title": "DistillSpec: Improving speculative decoding via knowledge distillation"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "zhang2024",
        "author": "Jun Zhang and Jue Wang and Huan Li and Lidan Shou and Ke Chen and Gang Chen and Sharad Mehrotra",
        "title": "Draft\\&Verify: Lossless Large Language Model Acceleration via Self-Speculative Decoding"
      },
      {
        "key": "elhoushi2024",
        "author": "Mostafa Elhoushi and Akshat Shrivastava and Diana Liskovich and Basil Hosmer and Bram Wasti and Liangzhen Lai and Anas Mahmoud and Bilge Acun and Saurabh Agarwal and Ahmed Roman and Ahmed Aly and Beidi Chen and Carole-Jean Wu",
        "title": "LayerSkip: Enabling Early Exit Inference and Self-Speculative Decoding"
      },
      {
        "key": "monea23",
        "author": "Giovanni Monea and Armand Joulin and Edouard Grave",
        "title": "PaSS: Parallel Speculative Sampling"
      },
      {
        "key": "yi2024",
        "author": "Hanling Yi and Feng Lin and Hongbin Li and Peiyang Ning and Xiaotian Yu and Rong Xiao",
        "title": "Generation Meets Verification: Accelerating Large Language Model Inference with Smart Parallel Auto-Correct Decoding"
      },
      {
        "key": "monea23",
        "author": "Giovanni Monea and Armand Joulin and Edouard Grave",
        "title": "PaSS: Parallel Speculative Sampling"
      },
      {
        "key": "li24a",
        "author": "Li, Yuhui and Wei, Fangyun and Zhang, Chao and Zhang, Hongyang",
        "title": "EAGLE: Speculative Sampling Requires Rethinking Feature Uncertainty"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "miao2023specinfer",
        "author": "Xupeng Miao and Gabriele Oliaro and Zhihao Zhang and Xinhao Cheng and Zeyu Wang and Zhengxin Zhang and Rae Ying Yee Wong and Alan Zhu and Lijie Yang and Xiaoxiang Shi and Chunan Shi and Zhuoming Chen and Daiyaan Arfeen and Reyna Abhyankar and Zhihao Jia",
        "title": "SpecInfer: Accelerating Large Language Model Serving with Tree-based Speculative Inference and Verification"
      },
      {
        "key": "cai24",
        "author": "Cai, Tianle and Li, Yuhong and Geng, Zhengyang and Peng, Hongwu and Lee, Jason D. and Chen, Deming and Dao, Tri",
        "title": "Medusa: Simple LLM Inference Acceleration Framework with Multiple Decoding Heads"
      },
      {
        "key": "li24b",
        "author": "Li, Yuhui and Wei, Fangyun and Zhang, Chao and Zhang, Hongyang",
        "title": "EAGLE-2: Faster Inference of Language Models with Dynamic Draft Trees"
      },
      {
        "key": "gong24",
        "author": "Gong, Zhuocheng and Liu, Jiahao and Wang, Ziyue and Wu, Pengfei and Wang, Jingang and Cai, Xunliang and Zhao, Dongyan and Yan, Rui",
        "title": "Graph-Structured Speculative Decoding"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "anonymous24a",
        "author": "Anonymous",
        "title": "Optimized Multi-Token Joint Decoding With Auxiliary Model for LLM Inference"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "hu24",
        "author": "Zhengmian Hu and Heng Huang",
        "title": "Accelerated Speculative Sampling Based on Tree Monte Carlo"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "anonymous24b",
        "author": "Anonymous",
        "title": "Judge Decoding: Faster Speculative Sampling Requires Going Beyond Model Alignment"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "scd",
        "author": "Yuan, Hongyi  and\nLu, Keming  and\nHuang, Fei  and\nYuan, Zheng  and\nZhou, Chang",
        "title": "Speculative Contrastive Decoding"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "leviathan23",
        "author": "Leviathan, Yaniv and Kalman, Matan and Matias, Yossi",
        "title": "Fast inference from transformers via speculative decoding"
      },
      {
        "key": "chen23",
        "author": "Chen, Charlie and Borgeaud, Sebastian and Irving, Geoffrey and Lespiau, Jean-Baptiste and Sifre, Laurent and Jumper, John",
        "title": "Accelerating large language model decoding with speculative sampling"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "leviathan23",
        "author": "Leviathan, Yaniv and Kalman, Matan and Matias, Yossi",
        "title": "Fast inference from transformers via speculative decoding"
      },
      {
        "key": "chen23",
        "author": "Chen, Charlie and Borgeaud, Sebastian and Irving, Geoffrey and Lespiau, Jean-Baptiste and Sifre, Laurent and Jumper, John",
        "title": "Accelerating large language model decoding with speculative sampling"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "leviathan23",
        "author": "Leviathan, Yaniv and Kalman, Matan and Matias, Yossi",
        "title": "Fast inference from transformers via speculative decoding"
      },
      {
        "key": "chen23",
        "author": "Chen, Charlie and Borgeaud, Sebastian and Irving, Geoffrey and Lespiau, Jean-Baptiste and Sifre, Laurent and Jumper, John",
        "title": "Accelerating large language model decoding with speculative sampling"
      }
    ]
  }
]