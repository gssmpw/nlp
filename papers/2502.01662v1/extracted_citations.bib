@inproceedings{anonymous24a,
  author    = {Anonymous},
  title     = {Optimized Multi-Token Joint Decoding With Auxiliary Model for LLM Inference},
  year      = {2025},
  booktitle = {The Thirteenth International Conference on Learning Representations (ICLR 2025)},
}

@inproceedings{anonymous24b,
  author    = {Anonymous},
  title     = {Judge Decoding: Faster Speculative Sampling Requires Going Beyond Model Alignment},
  year      = {2025},
  booktitle = {The Thirteenth International Conference on Learning Representations (ICLR 2025)},
}

@inproceedings{cai24,
  author    = {Cai, Tianle and Li, Yuhong and Geng, Zhengyang and Peng, Hongwu and Lee, Jason D. and Chen, Deming and Dao, Tri},
  title     = {Medusa: Simple LLM Inference Acceleration Framework with Multiple Decoding Heads},
  year      = {2024},
  booktitle = {Proceedings of the 41st International Conference on Machine Learning (ICML 2024)},
  address   = {Vienna, Austria},
}

@article{chen2023frugalgpt,
  title={Frugalgpt: How to use large language models while reducing cost and improving performance},
  author={Chen, Lingjiao and Zaharia, Matei and Zou, James},
  journal={arXiv preprint arXiv:2305.05176},
  year={2023}
}

@article{chen23,
  title={Accelerating large language model decoding with speculative sampling},
  author={Chen, Charlie and Borgeaud, Sebastian and Irving, Geoffrey and Lespiau, Jean-Baptiste and Sifre, Laurent and Jumper, John},
  journal={arXiv preprint arXiv:2302.01318},
  year={2023}
}

@article{ding2024hybrid,
  title={Hybrid LLM: Cost-efficient and quality-aware query routing},
  author={Ding, Dujian and Mallick, Ankur and Wang, Chi and Sim, Robert and Mukherjee, Subhabrata and Ruhle, Victor and Lakshmanan, Laks VS and Awadallah, Ahmed Hassan},
  journal={arXiv preprint arXiv:2404.14618},
  year={2024}
}

@inproceedings{elhoushi2024,
  author    = {Mostafa Elhoushi and Akshat Shrivastava and Diana Liskovich and Basil Hosmer and Bram Wasti and Liangzhen Lai and Anas Mahmoud and Bilge Acun and Saurabh Agarwal and Ahmed Roman and Ahmed Aly and Beidi Chen and Carole-Jean Wu},
  title     = {LayerSkip: Enabling Early Exit Inference and Self-Speculative Decoding},
  year      = {2024},
  booktitle = {Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (ACL 2024)},
  address   = {Bangkok, Thailand},
}

@article{furkan2024llm,
  title={LLM-TOPLA: Efficient LLM Ensemble by Maximising Diversity},
  author={Furkan Tekin, Selim and Ilhan, Fatih and Huang, Tiansheng and Hu, Sihao and Liu, Ling},
  journal={arXiv e-prints},
  pages={arXiv--2410},
  year={2024}
}

@inproceedings{gong24,
  author    = {Gong, Zhuocheng and Liu, Jiahao and Wang, Ziyue and Wu, Pengfei and Wang, Jingang and Cai, Xunliang and Zhao, Dongyan and Yan, Rui},
  title     = {Graph-Structured Speculative Decoding},
  year      = {2024},
  booktitle = {Findings of the Association for Computational Linguistics (ACL 2024)},
  address   = {Bangkok, Thailand},
}

@inproceedings{hu24,
  author    = {Zhengmian Hu and Heng Huang},
  title     = {Accelerated Speculative Sampling Based on Tree Monte Carlo},
  year      = {2024},
  booktitle = {Forty-first International Conference on Machine Learning (ICML 2024)},
  url       = {https://openreview.net/forum?id=stMhi1Sn2G},
}

@inproceedings{jiang2023llm,
  title={LLM-Blender: Ensembling Large Language Models with Pairwise Ranking and Generative Fusion},
  author={Jiang, Dongfu and Ren, Xiang and Lin, Bill Yuchen},
  booktitle={Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={14165--14178},
  year={2023}
}

@inproceedings{lee2023ensemble,
  title={Ensemble-Instruct: Generating Instruction-Tuning Data with a Heterogeneous Mixture of LMs},
  author={Lee, Young-Suk and Sultan, Arafat and El-Kurdi, Yousef and Naseem, Tahira and Munawar, Asim and Florian, Hans and Roukos, Salim and Astudillo, Ram{\'o}n Fernandez},
  booktitle={Conference on Empirical Methods in Natural Language Processing},
  year={2023}
}

@inproceedings{leviathan23,
  author    = {Leviathan, Yaniv and Kalman, Matan and Matias, Yossi},
  title     = {Fast inference from transformers via speculative decoding},
  year      = {2023},
  booktitle = {Proceedings of the 40th International Conference on Machine Learning (ICML 2023)},
  address   = {Honolulu, Hawaii, USA},
}

@inproceedings{li2023contrastive,
  title={Contrastive Decoding: Open-ended Text Generation as Optimization},
  author={Li, Xiang Lisa and Holtzman, Ari and Fried, Daniel and Liang, Percy and Eisner, Jason and Hashimoto, Tatsunori B and Zettlemoyer, Luke and Lewis, Mike},
  booktitle={Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={12286--12312},
  year={2023}
}

@article{li2024purifying,
  title={Purifying large language models by ensembling a small language model},
  author={Li, Tianlin and Liu, Qian and Pang, Tianyu and Du, Chao and Guo, Qing and Liu, Yang and Lin, Min},
  journal={arXiv preprint arXiv:2402.14845},
  year={2024}
}

@inproceedings{li24a,
  author    = {Li, Yuhui and Wei, Fangyun and Zhang, Chao and Zhang, Hongyang},
  title     = {EAGLE: Speculative Sampling Requires Rethinking Feature Uncertainty},
  year      = {2024},
  booktitle = {Proceedings of the 41st International Conference on Machine Learning (ICML 2024)},
  address   = {Vienna, Austria},
}

@inproceedings{li24b,
  author    = {Li, Yuhui and Wei, Fangyun and Zhang, Chao and Zhang, Hongyang},
  title     = {EAGLE-2: Faster Inference of Language Models with Dynamic Draft Trees},
  year      = {2024},
  booktitle = {Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing (EMNLP 2024)},
  address   = {Miami, Florida, USA},
}

@article{lu2023routing,
  title={Routing to the expert: Efficient reward-guided ensemble of large language models},
  author={Lu, Keming and Yuan, Hongyi and Lin, Runji and Lin, Junyang and Yuan, Zheng and Zhou, Chang and Zhou, Jingren},
  journal={arXiv preprint arXiv:2311.08692},
  year={2023}
}

@article{lu2024blending,
  title={Blending is all you need: Cheaper, better alternative to trillion-parameters llm},
  author={Lu, Xiaoding and Liu, Zongyi and Liusie, Adian and Raina, Vyas and Mudupalli, Vineet and Zhang, Yuwen and Beauchamp, William},
  journal={arXiv preprint arXiv:2401.02994},
  year={2024}
}

@article{lu2024merge,
  title={Merge, ensemble, and cooperate! a survey on collaborative strategies in the era of large language models},
  author={Lu, Jinliang and Pang, Ziliang and Xiao, Min and Zhu, Yaochen and Xia, Rui and Zhang, Jiajun},
  journal={arXiv preprint arXiv:2407.06089},
  year={2024}
}

@inproceedings{miao2023specinfer,
  author    = {Xupeng Miao and Gabriele Oliaro and Zhihao Zhang and Xinhao Cheng and Zeyu Wang and Zhengxin Zhang and Rae Ying Yee Wong and Alan Zhu and Lijie Yang and Xiaoxiang Shi and Chunan Shi and Zhuoming Chen and Daiyaan Arfeen and Reyna Abhyankar and Zhihao Jia},
  title     = {SpecInfer: Accelerating Large Language Model Serving with Tree-based Speculative Inference and Verification},
  year      = {2024},
  booktitle = {Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS 2024)},
}

@article{monea23,
  author       = {Giovanni Monea and Armand Joulin and Edouard Grave},
  title        = {PaSS: Parallel Speculative Sampling},
  year         = {2023},
  journal = {arXiv preprint arXiv:2302.01318},
  url          = {https://arxiv.org/abs/2311.13581},
}

@inproceedings{scd,
    title = "Speculative Contrastive Decoding",
    author = "Yuan, Hongyi  and
      Lu, Keming  and
      Huang, Fei  and
      Yuan, Zheng  and
      Zhou, Chang",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-short.5/",
    doi = "10.18653/v1/2024.acl-short.5",
    pages = "56--64",
}

@inproceedings{shnitzer2023large,
  title={Large Language Model Routing with Benchmark Datasets},
  author={Shnitzer, Tal and Ou, Anthony and Silva, Mirian and Soule, Kate and Sun, Yuekai and Solomon, Justin and Thompson, Neil and Yurochkin, Mikhail},
  booktitle={Annual Conference on Neural Information Processing Systems},
  year={2023}
}

@article{yi2024,
      title={Generation Meets Verification: Accelerating Large Language Model Inference with Smart Parallel Auto-Correct Decoding}, 
      author={Hanling Yi and Feng Lin and Hongbin Li and Peiyang Ning and Xiaotian Yu and Rong Xiao},
      year={2024},
      journal = {arXiv preprint arXiv:2402.11809},
      url= {https://arxiv.org/abs/2402.11809},
}

@inproceedings{zhang2024,
  author    = {Jun Zhang and Jue Wang and Huan Li and Lidan Shou and Ke Chen and Gang Chen and Sharad Mehrotra},
  title     = {Draft\&Verify: Lossless Large Language Model Acceleration via Self-Speculative Decoding},
  year      = {2024},
  booktitle = {Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (ACL 2024)},
  address   = {Bangkok, Thailand},
}

@inproceedings{zhou24,
  author    = {Yongchao Zhou and Kaifeng Lyu and Ankit Singh Rawat and Aditya Menon and Afshin Rostamizadeh and Sanjiv Kumar and Jean-Fran√ßois Kagy and Rishabh Agarwal},
  title     = {DistillSpec: Improving speculative decoding via knowledge distillation},
  year      = {2024},
  booktitle = {The Thirteenth International Conference on Learning Representations (ICLR 2024)},
  url       = {https://openreview.net/forum?id=rsY6J3ZaTF},
}

