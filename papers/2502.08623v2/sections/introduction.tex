\section{Introduction}

Supervised learning via maximum likelihood estimation, i.e., attempting to reproduce the training distribution, underpins several recent advancements in deep learning. 
% Maximum likelihood estimation attempts to reproduce the training distribution. This seemingly innocuous fact underpins several recent advancements in deep learning: 
Due to the broad availability of high-quality data on the internet, models in vision \citep{radford2021learning} and language \citep{radford2019language} have continued to improve through supervised learning on larger and larger datasets \citep{kaplan2020scaling, zhai2022scaling}.
The observed trend of more data leading to more performance has inspired parts of robot learning community, spurring increased investment in data collection across both academia and industry \citep{openx, rh20t, droid, bridge} in hopes of training better imitation learning policies, often with similar maximum likelihood objectives \citep{octo,rt1}. However, MLE-based approaches benefit most from high-quality data, and as we have seen in vision and language, not all data is equal \citep{xu2024demystifying}. In other words, we should expect the performance of a large behavior cloning policies to mirror the quality of the collected data, and we may not be gathering the most optimal data. As an example, the recent DROID dataset \citep{droid} contains 76K demonstrations collected across 13 institutions. Despite being one of the largest and most diverse datasets in robotics, the DROID dataset was significantly down-weighted when training OpenVLA \citep{kim2024openvla} as it was found to hurt performance rather than help. While many hypotheses surrounding this exist, e.g., insufficient operator supervision leading to an excessively broad data distribution, one conclusion we can draw is that we should pay more attention to data \emph{quality}, not just quantity. This is particularly important in robotics, as every demonstration requires labor, time, and capital. 

Even though data quality is critical to the performance of imitation learning algorithms, little work has sought to measure it \citep{belkhale2024data} and unfortunately, techniques used for data curation in vision and language do not transfer well to robotics. For example, \textit{n}-gram classifiers have been extremely effective for web text \citep{albalak2024survey} but are unable to handle high-dimensional continuous states and actions. Pre-trained models have been used to curate vision datasets \citep{schuhmann2022laion}, but are incapable of reasoning about actions. In contrast, we believe metrics for imitation learning should be able to measure both the diversity of states, which has been correlated with generalization performance \citep{gao2024efficient, lin2024datascalinglawsimitation}, and the relative quality of actions, which affects how well a policy is able to fit the expert distribution \citep{belkhale2024data}. In this work we explore how both of these desiderata can be captured by the mutual information between states and actions. 

Mutual information, or the bits of information learned about one random variable by observing another, precisely measures the difference between the marginal entropy of one variable and the conditional entropy of another. In the context of states and actions, this means that high mutual information encourages a large diversity of states (state entropy) but a predictable action distribution (low entropy of actions given a particular state). We thus propose using mutual information as a desirable metric for measuring data quality in imitation learning.

Unfortunately, estimating mutual information is particularly hard especially with low amounts of data. Common estimation techniques like InfoNCE \citep{oord2018representation} used for models such as CLIP \citep{radford2021learning} often require millions of data points from the same distribution. In robotics, we often do not have access to data at a similar scale due to the difficulty and cost of collection. Moreover, even if we assume access to more data, existing large robot datasets such as OpenX Embodiment \citep{openx} have sporadic support across a few highly varied environments likely containing little to no overlap with new data collected across different labs, platforms, and tasks. To address this problem, we introduce \fullname or \abv for short. We design \abv to work across both low- and high-data regimes in robotics. To do so, \abv first learns a structured low-dimensional representation of the state and action space using variational autoencoders. Then, \abv leverages mutual information estimators based on $k$-nearest neighbors to estimate the quality of state and action chunk pairs. Critically we found these non-parametric estimators to be more stable with datasets of 50-300 demonstrations commonly used in robotics. Finally, we average mutual information estimates across time to identify the highest and lowest quality demonstrations.

When applying \abv to a number of different robot platforms and environments, we find that it is able to consistently partition high- and low-quality data as scored by expert human annotators, outperforming both contemporary baselines and alternative mutual information estimators like InfoNCE \citep{oord2018representation}. Furthermore, using \abv to subsample demonstration data, we are able to attain higher performing imitation learning policies across the RoboMimic \citep{robomimic} benchmark and real ALOHA policies on RoboCrowd \citet{mirchandani2024robocrowd}.
