\section{Related Work}
The $k$-core decomposition problem has been extensively studied since the introduction by Seidman~\cite{seidman1983network}.
The first sequential algorithm was proposed by Matula and Beck~\cite{matula1983smallest},
using a bucket sort to arrange vertices by degree and iteratively deleting vertices with degree $k$ (peeling) until all are removed.
The algorithm runs in $O(m + n)$.
Batagelj and Zaversnik (\BZ)~\cite{batagelj2003m} provided a sequential implementation with the same time complexity. 

The \kcore{} problem is also carefully studied in the shared-memory parallel setting~\cite{dasari2014park,kabir2017parallel,dhulipala2017,montresor2011distributed,khaouid2015k,li2021k}, as well as included in many parallel graph libraries such as GraphX~\cite{gonzalez2014graphx}, Powergraph~\cite{gonzalez2012powergraph}, Ligra~\cite{shun2013ligra} and Julienne~\cite{dhulipala2017} (later integrated into the GBBS library~\cite{gbbs2021}).
In this paper, we compared to the three state-of-the-part solutions, including \ParK~\cite{dasari2014park}, \PKC~\cite{kabir2017parallel}, and \Julienne{}~\cite{dhulipala2017}.
Among them, \ParK and \PKC use the online peeling process, and \Julienne is offline.
More details about them were overviewed in \cref{sec:peeling}.

Given the wide applicability, \kcore is also extensively studied in other settings, such as on GPUs~\cite{mehrafsa2020vectorising, ahmad2023accelerating, zhao2024pico, li2021k, tripathy2018scalable, zhao2024speedcore, zhang2017accelerating, wang2016gunrock}, the external memory (disk) setting~\cite{cheng2011efficient, wen2018efficient}, and the low-memory setting~\cite{khaouid2015k}.
The techniques proposed in these papers mostly focused on the specific challenges in each setting, and have small overlaps with the new techniques introduced in this paper.

We are also aware of variants of $k$-core decomposition.
A direct extension is to maintain \kcore with vertex and edge updates.
Research has been done on this topic, for both the dynamic (online) setting~\cite{aksu2014distributed, aridhi2016distributed, gabert2022batch,liu2022parallel} and the streaming (offline) setting~\cite{sariyuce2013streaming, esfandiari2018parallel, sariyuce2016incremental}.
Another direction is computing approximate $k$-core decomposition, both in sequential settings~\cite{king2022computing} 
and parallel settings~\cite{esfandiari2018parallel,liu2022parallel, liu2024parallel, dhulipala2022differential}.
On directed graphs, s similar problem is referred to as $D$-core decomposition.
Algorithms for it have also been studied recently~\cite{luo2024efficient, liao2022distributed, giatsidis2013d}.
The $k$-core decomposition also relates to many other problems, 
such as dense subgraph discovery~\cite{luo2023scalable} and hierarchical core decomposition~\cite{chu2022hierarchical}.
How to apply our new techniques in these related problems can be an interesting future work.

\hide{are two state-of-the-art parallel algorithms using the online peeling process. 
They both use $O(n \maxcoreness + m)$ work. 
We introduced both of them in \cref{sec:peeling}. 
\PKC{} introduces optimizations, such as packing the remaining vertices after 98\% have been peeled, 
and using a local buffer to avoid subrounds.
While \PKC{} performs well on sparse graphs, 
both \Park{} and \PKC{} suffer from poor performance on dense graphs due to work-inefficiency and contention in updating induced degrees.

Dhulipala et al.~\cite{dhulipala2017} proposed a parallel \kcore{} algorithm in the \Julienne{} paper. 
In their paper, they use a bucketing structure that that maps each value $d$ to all vertices with induced degree $d$.
They proved that this algorithm has $O(m+n)$ work. In their implementation, they used a simplified bucketing structure that only 
maintains up to $b$ buckets. Our analysis proves the work-efficiency of their implementation, 
and an even simpler version without bucketing structure is also work-efficient. 
% Their algorithm is base on the offline peeling algorithm, 
\Julienne{} is based on the offline peeling approach, 
as we introduced in \cref{sec:peeling},
which is fully synchronized and race-free. 
It performs well on dense graphs but has unsatisfactory performance on sparse graphs, 
where synchronization overhead can be comparable to the computation cost.



We select the state-of-the-art exact \kcore{} algorithms mentioned above as our baselines for comparison,
given their performance and more general applicability to various graph types. 
Besides, \emph{MPM} algorithm solves \kcore{} problem in distributed settings ~\cite{montresor2011distributed}.
There are also studies focusing on optimizing \kcore{} decomposition in
low-memory settings~\cite{khaouid2015k} with implementation on GraphChi~\cite{KBG12},
as well as external memory settings~\cite{cheng2011efficient, wen2018efficient}.
Li et al.~\cite{li2021k} uses GraphBLAS to
adapt linear algebraic language to the \kcore{} problem on sparse graphs.

There are also recent studies based on GPU settings~\cite{mehrafsa2020vectorising, ahmad2023accelerating, zhao2024pico, li2021k, tripathy2018scalable, zhao2024speedcore, zhang2017accelerating, wang2016gunrock},
Many of them focus on adapting the peeling framework with different optimizations on GPU settings~\cite{mehrafsa2020vectorising,ahmad2023accelerating, zhao2024pico, tripathy2018scalable, zhao2024speedcore, wang2016gunrock}.
Specifically, \emph{PeelBlock}~\cite{ahmad2023accelerating} follows the \PKC{} design with buffer optimizations for GPUs.
\emph{SpeedCore} ~\cite{zhao2024speedcore} improves the performance of \emph{PeelBlock} by further optimizations.

Several shared-memory parallel and distributed computing frameworks support $k$-core decomposition as part of graph analytics,
including GraphX~\cite{gonzalez2014graphx}, Powergraph~\cite{gonzalez2012powergraph}, Ligra~\cite{shun2013ligra} and Julienne~\cite{dhulipala2017} (later integrated into the GBBS library~\cite{gbbs2021}).
While these frameworks provide primitives for parallel or distributed graph processing, 
they do not specifically optimize for the \kcore{} problem.
} 