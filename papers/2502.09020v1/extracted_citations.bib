@INPROCEEDINGS{Guan2023CCD,
  author={Guan, Tongkun and Shen, Wei and Yang, Xue and Feng, Qi and Jiang, Zekun and Yang, Xiaokang},
  booktitle={2023 IEEE/CVF International Conference on Computer Vision (ICCV)}, 
  title={Self-supervised Character-to-Character Distillation for Text Recognition}, 
  year={2023},
  volume={},
  number={},
  pages={19416-19427},
  keywords={Charge coupled devices;Representation learning;Image segmentation;Visualization;Text recognition;Superresolution;Self-supervised learning},
  doi={10.1109/ICCV51070.2023.01784}}

@article{Wei2024BUSNet, 
    title={Image as a Language: Revisiting Scene Text Recognition via Balanced, Unified and Synchronized Vision-Language Reasoning Network}, 
    volume={38}, 
    url={https://ojs.aaai.org/index.php/AAAI/article/view/28402}, 
    DOI={10.1609/aaai.v38i6.28402}, 
    number={6}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, 
    author={Wei, Jiajun and Zhan, Hongjian and Lu, Yue and Tu, Xiao and Yin, Bing and Liu, Cong and Pal, Umapada}, 
    year={2024}, 
    month={Mar.}, 
    pages={5885-5893} 
}

@inproceedings{bautista2022PARseq,
  title={Scene text recognition with permuted autoregressive sequence models},
  author={Bautista, Darwin and Atienza, Rowel},
  booktitle={European conference on computer vision},
  pages={178--196},
  year={2022},
  organization={Springer}
}

@inproceedings{da2022levocr,
  title={Levenshtein ocr},
  author={Da, Cheng and Wang, Peng and Yao, Cong},
  booktitle={European Conference on Computer Vision},
  pages={322--338},
  year={2022},
  organization={Springer}
}

@inproceedings{fang2021ABINet,
  title={Read like humans: Autonomous, bidirectional and iterative language modeling for scene text recognition},
  author={Fang, Shancheng and Xie, Hongtao and Wang, Yuxin and Mao, Zhendong and Zhang, Yongdong},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={7098--7107},
  year={2021}
}

@article{feng2023docpedia,
  title={Docpedia: Unleashing the power of large multimodal model in the frequency domain for versatile document understanding},
  author={Feng, Hao and Liu, Qi and Liu, Hao and Zhou, Wengang and Li, Houqiang and Huang, Can},
  journal={arXiv preprint arXiv:2311.11810},
  year={2023}
}

@article{gallego2020event,
  title={Event-based vision: A survey},
  author={Gallego, Guillermo and Delbr{\"u}ck, Tobi and Orchard, Garrick and Bartolozzi, Chiara and Taba, Brian and Censi, Andrea and Leutenegger, Stefan and Davison, Andrew J and Conradt, J{\"o}rg and Daniilidis, Kostas and others},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={44},
  number={1},
  pages={154--180},
  year={2020},
  publisher={IEEE}
}

@article{gallego2020eventsurvey,
  title={Event-based vision: A survey},
  author={Gallego, Guillermo and Delbr{\"u}ck, Tobi and Orchard, Garrick and Bartolozzi, Chiara and Taba, Brian and Censi, Andrea and Leutenegger, Stefan and Davison, Andrew J and Conradt, J{\"o}rg and Daniilidis, Kostas and others},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={44},
  number={1},
  pages={154--180},
  year={2020},
  publisher={IEEE}
}

@inproceedings{gehrig2023RVTs,
  title={Recurrent vision transformers for object detection with event cameras},
  author={Gehrig, Mathias and Scaramuzza, Davide},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={13884--13893},
  year={2023}
}

@inproceedings{guan2023SIGA,
  title={Self-supervised implicit glyph attention for text recognition},
  author={Guan, Tongkun and Gu, Chaochen and Tu, Jingzheng and Yang, Xue and Feng, Qi and Zhao, Yudi and Shen, Wei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={15285--15294},
  year={2023}
}

@article{han2024spotlight,
  title={Spotlight text detector: Spotlight on candidate regions like a camera},
  author={Han, Xu and Gao, Junyu and Yang, Chuang and Yuan, Yuan and Wang, Qi},
  journal={IEEE Transactions on Multimedia},
  year={2024},
  publisher={IEEE}
}

@article{hu2024mplug,
  title={mplug-docowl 1.5: Unified structure learning for ocr-free document understanding},
  author={Hu, Anwen and Xu, Haiyang and Ye, Jiabo and Yan, Ming and Zhang, Liang and Zhang, Bo and Li, Chen and Zhang, Ji and Jin, Qin and Huang, Fei and others},
  journal={arXiv preprint arXiv:2403.12895},
  year={2024}
}

@article{jiang2024evcslr,
  title={EvCSLR: Event-guided Continuous Sign Language Recognition and Benchmark},
  author={Jiang, Yu and Wang, Yuehang and Li, Siqi and Zhang, Yongji and Guo, Qianren and Chu, Qi and Gao, Yue},
  journal={IEEE Transactions on Multimedia},
  year={2024},
  publisher={IEEE}
}

@article{li2023semantic,
title = {Semantic-aware frame-event fusion based pattern recognition via large visionâ€“language models},
journal = {Pattern Recognition},
volume = {158},
pages = {111080},
year = {2025},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2024.111080},
author = {Dong Li and Jiandong Jin and Yuhao Zhang and Yanlin Zhong and Yaoyang Wu and Lan Chen and Xiao Wang and Bin Luo}
}

@article{li2024volter,
  title={VOLTER: Visual Collaboration and Dual-Stream Fusion for Scene Text Recognition},
  author={Li, Jia-Nan and Liu, Xiao-Qian and Luo, Xin and Xu, Xin-Shun},
  journal={IEEE Transactions on Multimedia},
  year={2024},
  publisher={IEEE}
}

@inproceedings{liao2019scene,
  title={Scene text recognition from two-dimensional perspective},
  author={Liao, Minghui and Zhang, Jian and Wan, Zhaoyi and Xie, Fengming and Liang, Jiajun and Lyu, Pengyuan and Yao, Cong and Bai, Xiang},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={33},
  number={01},
  pages={8714--8721},
  year={2019}
}

@article{liu2024focus,
  title={Focus Anywhere for Fine-grained Multi-page Document Understanding},
  author={Liu, Chenglong and Wei, Haoran and Chen, Jinyue and Kong, Lingyu and Ge, Zheng and Zhu, Zining and Zhao, Liang and Sun, Jianjian and Han, Chunrui and Zhang, Xiangyu},
  journal={arXiv preprint arXiv:2405.14295},
  year={2024}
}

@article{liu2024textmonkey,
  title={Textmonkey: An ocr-free large multimodal model for understanding document},
  author={Liu, Yuliang and Yang, Biao and Liu, Qiang and Li, Zhang and Ma, Zhiyin and Zhang, Shuo and Bai, Xiang},
  journal={arXiv preprint arXiv:2403.04473},
  year={2024}
}

@article{long2021STRDsurvey,
  title={Scene text detection and recognition: The deep learning era},
  author={Long, Shangbang and He, Xin and Yao, Cong},
  journal={International Journal of Computer Vision},
  volume={129},
  number={1},
  pages={161--184},
  year={2021},
  publisher={Springer}
}

@inproceedings{na2022matrn,
  title={Multi-modal text recognition networks: Interactive enhancements between visual and semantic features},
  author={Na, Byeonghu and Kim, Yoonsik and Park, Sungrae},
  booktitle={European Conference on Computer Vision},
  pages={446--463},
  year={2022},
  organization={Springer}
}

@article{shi2016end,
  title={An end-to-end trainable neural network for image-based sequence recognition and its application to scene text recognition},
  author={Shi, Baoguang and Bai, Xiang and Yao, Cong},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={39},
  number={11},
  pages={2298--2304},
  year={2016},
  publisher={IEEE}
}

@inproceedings{wang2011end,
  title={End-to-end scene text recognition},
  author={Wang, Kai and Babenko, Boris and Belongie, Serge},
  booktitle={2011 International conference on computer vision},
  pages={1457--1464},
  year={2011},
  organization={IEEE}
}

@article{wang2023MMPTMsurvey,
  title={Large-scale multi-modal pre-trained models: A comprehensive survey},
  author={Wang, Xiao and Chen, Guangyao and Qian, Guangwu and Gao, Pengcheng and Wei, Xiao-Yong and Wang, Yaowei and Tian, Yonghong and Gao, Wen},
  journal={Machine Intelligence Research},
  volume={20},
  number={4},
  pages={447--482},
  year={2023},
  publisher={Springer}
}

@inproceedings{wang2024eventvot,
  title={Event stream-based visual object tracking: A high-resolution benchmark dataset and a novel baseline},
  author={Wang, Xiao and Wang, Shiao and Tang, Chuanming and Zhu, Lin and Jiang, Bo and Tian, Yonghong and Tang, Jin},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={19248--19257},
  year={2024}
}

@inproceedings{wang2024hardvs,
  title={Hardvs: Revisiting human activity recognition with dynamic vision sensors},
  author={Wang, Xiao and Wu, Zongzhen and Jiang, Bo and Bao, Zhimin and Zhu, Lin and Li, Guoqi and Wang, Yaowei and Tian, Yonghong},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={6},
  pages={5615--5623},
  year={2024}
}

@article{wei2024OCR2.0,
  title={General ocr theory: Towards ocr-2.0 via a unified end-to-end model},
  author={Wei, Haoran and Liu, Chenglong and Chen, Jinyue and Wang, Jia and Kong, Lingyu and Xu, Yanming and Ge, Zheng and Zhao, Liang and Sun, Jianjian and Peng, Yuang and others},
  journal={arXiv preprint arXiv:2409.01704},
  year={2024}
}

@inproceedings{wei2025vary,
  title={Vary: Scaling up the vision vocabulary for large vision-language model},
  author={Wei, Haoran and Kong, Lingyu and Chen, Jinyue and Zhao, Liang and Ge, Zheng and Yang, Jinrong and Sun, Jianjian and Han, Chunrui and Zhang, Xiangyu},
  booktitle={European Conference on Computer Vision},
  pages={408--424},
  year={2025},
  organization={Springer}
}

@article{ye2023ureader,
  title={Ureader: Universal ocr-free visually-situated language understanding with multimodal large language model},
  author={Ye, Jiabo and Hu, Anwen and Xu, Haiyang and Ye, Qinghao and Yan, Ming and Xu, Guohai and Li, Chenliang and Tian, Junfeng and Qian, Qi and Zhang, Ji and others},
  journal={arXiv preprint arXiv:2310.05126},
  year={2023}
}

@article{zhao2023survey,
  title={A survey of large language models},
  author={Zhao, Wayne Xin and Zhou, Kun and Li, Junyi and Tang, Tianyi and Wang, Xiaolei and Hou, Yupeng and Min, Yingqian and Zhang, Beichen and Zhang, Junjie and Dong, Zican and others},
  journal={arXiv preprint arXiv:2303.18223},
  year={2023}
}

@inproceedings{zhao2024E2STR,
  title={Multi-modal In-Context Learning Makes an Ego-evolving Scene Text Recognizer},
  author={Zhao, Zhen and Tang, Jingqun and Lin, Chunhui and Wu, Binghong and Huang, Can and Liu, Hao and Tan, Xin and Zhang, Zhizhong and Xie, Yuan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={15567--15576},
  year={2024}
}

@article{zheng2023tps++,
  title={Tps++: Attention-enhanced thin-plate spline for scene text recognition},
  author={Zheng, Tianlun and Chen, Zhineng and Bai, Jinfeng and Xie, Hongtao and Jiang, Yu-Gang},
  journal={arXiv preprint arXiv:2305.05322},
  year={2023}
}

@article{zheng2024cdistnet,
  title={Cdistnet: Perceiving multi-domain character distance for robust text recognition},
  author={Zheng, Tianlun and Chen, Zhineng and Fang, Shancheng and Xie, Hongtao and Jiang, Yu-Gang},
  journal={International Journal of Computer Vision},
  volume={132},
  number={2},
  pages={300--318},
  year={2024},
  publisher={Springer}
}

