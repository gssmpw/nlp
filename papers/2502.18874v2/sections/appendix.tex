\section{Training Settings}\label{train_detail}

We train Qwen2.5-7B-Instruct\footnote{https://huggingface.co/Qwen/Qwen2.5-7B-Instruct} to perform as the Analyzer. The number of training samples in the Composite Analysis Corpus is around 25K, including 7.7K evaluation question generation samples, 6K code-driven analysis samples, and 11K text-based analysis samples. The corpus is constructed based on instructions from Auto-J\footnote{https://github.com/GAIR-NLP/auto-j} \cite{auto-j}. We train it for 2 epochs with a global batch size of 96 and we save checkpoints for every 50 steps. The learning rate is set to 1e-5. We use DeepSpeed ZeRO3 and FlashAttention to reduce computational memory usage. The training is implemented on 6 computing devices. We use Pytorch with the 2.4.0 version, Transformers with the 4.44.2 version, and deepspeed with the 0.14.4 version. 

\section{Prompt Templates}

\begin{figure*}[t!]
	\centering
	\includegraphics[width=1.0\linewidth]{figures/prompt_question.pdf}
	\caption{Prompt template for evaluation question generation.}
	\label{prompt_question}
\end{figure*}

\begin{figure*}[t!]
	\centering
	\includegraphics[width=1.0\linewidth]{figures/prompt_constraint.pdf}
	\caption{Prompt template for objective constraint generation.}
	\label{prompt_constraint}
\end{figure*}

\begin{figure*}[t!]
	\centering
	\includegraphics[width=1.0\linewidth]{figures/prompt_text_eval.pdf}
	\caption{Prompt template for text-based evaluation.}
	\label{prompt_text_eval}
\end{figure*}

\begin{figure*}[t!]
	\centering
	\includegraphics[width=1.0\linewidth]{figures/prompt_code_eval.pdf}
	\caption{Prompt template for code-driven evaluation.}
	\label{prompt_code_eval}
\end{figure*}

\begin{figure*}[t!]
	\centering
	\includegraphics[width=1.0\linewidth]{figures/prompt_reverse.pdf}
	\caption{Prompt template for reverse validation.}
	\label{prompt_reverse}
\end{figure*}

Prompt templates used for dataset construction are shown in Figure \ref{prompt_question}, Figure \ref{prompt_constraint}, Figure \ref{prompt_text_eval}, Figure \ref{prompt_code_eval}, and Figure \ref{prompt_reverse}.

\begin{figure*}[t!]
	\centering
	\includegraphics[width=1.0\linewidth]{figures/prompt_analyzer_question.pdf}
	\caption{Prompt template for question generation of the Analyzer.}
	\label{prompt_analyzer_question}
\end{figure*}

\begin{figure*}[t!]
	\centering
	\includegraphics[width=1.0\linewidth]{figures/prompt_analyzer_analysis.pdf}
	\caption{Prompt template for multi-faceted analysis of the Analyzer.}
	\label{prompt_analyzer_analysis}
\end{figure*}

\begin{figure*}[t!]
	\centering
	\includegraphics[width=1.0\linewidth]{figures/prompt_refiner.pdf}
	\caption{Prompt template for refinement of the Refiner.}
	\label{prompt_refiner}
\end{figure*}

Prompt templates used for the Analyzer and Refiner of our ARJudge are shown in Figure \ref{prompt_analyzer_question}, Figure \ref{prompt_analyzer_analysis}, and Figure \ref{prompt_refiner}.